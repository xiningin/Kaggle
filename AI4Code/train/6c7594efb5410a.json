{"cell_type":{"f74b876a":"code","5c15ba5f":"code","f5975e44":"code","1c464dfa":"code","7c65fb0c":"code","16a5bd20":"code","f1f724fd":"code","0dbee325":"code","f51d103c":"code","9d75e309":"code","d5e3e206":"code","9c014599":"code","410fec5b":"code","9ead6dbf":"code","43dbf637":"code","01456fd0":"code","37d9b6ee":"code","7eb408e3":"code","5b216dc7":"code","d31baafd":"code","2fb54c33":"code","8f6b84de":"code","8ab30565":"code","ce7f60b8":"code","21a975d0":"code","42c3a5f0":"code","247f74c6":"code","58cda844":"code","df79d241":"code","174497ec":"code","d64f4415":"code","480c23a5":"code","8a6e1e50":"code","4e78c121":"code","3188627f":"code","72236cb7":"code","52ef1361":"code","2a039d31":"code","624f6e78":"code","a0fcf213":"code","30fcbd8e":"code","e2130acf":"code","c38bea06":"code","fa415433":"code","1437ab95":"code","77f2201f":"code","41fcaa02":"code","8e73bfd8":"code","7afcb1ec":"code","bb8e7e04":"code","ccaf4668":"code","f4c0b443":"code","cb77d1db":"code","fde57c2b":"code","a8137818":"code","64256804":"code","d540a14e":"code","cdd40b0c":"code","87aa8012":"code","e0584be0":"code","7573d1fe":"code","dd6fa8e8":"code","0f7ba4ef":"code","61ffb236":"code","a500b82e":"code","6e3262a4":"code","1a9d0e0f":"code","032f87c5":"code","7f8700a4":"code","4172bc7a":"code","eb6cbbee":"code","71d6fcff":"code","5c7e1255":"code","8bccde22":"code","620fb1cd":"code","3e778b9f":"code","459f5773":"code","991df052":"code","c4284720":"code","4f101ff0":"code","1d29c1a2":"code","6d061d89":"code","9de51a06":"code","912490a4":"code","0110fe4d":"code","df4a5a7a":"code","e61e5426":"code","2867faa4":"code","98204bdd":"code","f0bb94e1":"code","e4ca6d3c":"code","8b3f0a0c":"code","dc28de4b":"code","eb826c03":"code","ea597a27":"code","56befe2a":"markdown","0d5e7a1c":"markdown","e9e7703a":"markdown","c9d93bd1":"markdown","5c6829cb":"markdown","b5ca523a":"markdown","d89b2ebc":"markdown","40b7eac0":"markdown","a71a6dea":"markdown","8c92476c":"markdown","f351e523":"markdown","3b4e7711":"markdown","765b323a":"markdown","ac07ba5c":"markdown","764f11c5":"markdown","be1a919d":"markdown","27c11076":"markdown","c126288d":"markdown","64a1dd97":"markdown","9dbc6d55":"markdown","e56051e4":"markdown","59d80cdd":"markdown","9bfc5f40":"markdown","8bb2d5ef":"markdown","86259899":"markdown","e2a56973":"markdown","9a5c9334":"markdown","26c159c4":"markdown","d8bc825b":"markdown","31b1b0c2":"markdown","aea3f176":"markdown"},"source":{"f74b876a":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport missingno as msno\n\nfrom glob import glob\nimport os, random, time, gc, warnings\n\nfrom tqdm import tqdm_notebook\n\nimport lightgbm as lgbm\nfrom sklearn.linear_model import Ridge, Lasso\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import mean_squared_error\n\nfrom catboost import CatBoostRegressor\nfrom sklearn.feature_selection import RFECV\n\n\nfrom sklearn.cluster import KMeans\n\nfrom datetime import datetime\n\nfrom math import sqrt\n\nimport folium\nfrom folium import Marker, Icon, CircleMarker\n\nfrom pdpbox import pdp, info_plots\n\nwarnings.filterwarnings('ignore')\n\npd.set_option('max_columns', 500)\npd.set_option('max_rows', 500)\n\n%matplotlib inline","5c15ba5f":"# \uc0c1\uc704 directory\uc778 input\uc5d0 \ubb34\uc5c7\uc774 \ub4e4\uc5b4\uc788\ub098 \ud655\uc778\ud569\ub2c8\ub2e4.\nos.listdir('..\/input\/')","f5975e44":"# glob \ud568\uc218\ub97c \uc774\uc6a9\ud558\uc5ec \uc8fc\ucd5c \uce21\uc774 \uc81c\uacf5\ud55c \ub370\uc774\ud130\uc14b\uc744 \ud655\uc778\ud569\ub2c8\ub2e4.\nglob('..\/input\/dacon-bus-dataset\/*.*')","1c464dfa":"# \uccab 10\uac1c\uc758 row\ub97c \ucd9c\ub825\ud574\ubcf4\ub3c4\ub85d \ud569\uc2dc\ub2e4.\n!head ..\/input\/dacon-bus-dataset\/train.csv","7c65fb0c":"# \ub370\uc774\ud130\ub97c load\ud569\ub2c8\ub2e4.\n# train\/test --> string\ud615\uc2dd\uc73c\ub85c \uc800\uc7a5\ub418\uc5b4 \uc788\ub294 `date` column\uc740 datetime\ud615\uc2dd\uc73c\ub85c \uc218\uc9d1\ud569\ub2c8\ub2e4.\n# bus_bts    --> string\ud615\uc2dd\uc73c\ub85c \uc800\uc7a5\ub418\uc5b4 \uc788\ub294 `geton_date`, `getoff_date` columns\uc740 datetime\ud615\uc2dd\uc73c\ub85c \uc218\uc9d1\ud569\ub2c8\ub2e4.\ndef load_dataset(path):\n    train = pd.read_csv(path + 'train.csv', parse_dates=['date'])\n    test  = pd.read_csv(path + 'test.csv', parse_dates=['date'])\n    df_bus = pd.read_csv(path + 'bus_bts.csv', parse_dates = ['geton_date', 'getoff_date'] )\n    sample_submission = pd.read_csv(path + 'submission_sample.csv')\n    return train, test, df_bus, sample_submission\n\npath = '..\/input\/dacon-bus-dataset\/'\n%time train, test, df_bus, sample_submission = load_dataset(path)","16a5bd20":"# Train\/Test-set\uc744 \uac01\uac01 \uccb4\ud06c\ud574\ubd05\ub2c8\ub2e4.\ndisplay(train.head(3))\n\ndisplay(test.head(3))","f1f724fd":"print(\"-- Size -- \")\nprint(f\"Train-set : {train.shape}\")\nprint(f\"Test-set  : {test.shape}\")","0dbee325":"# Train-set\uc5d0\ub9cc \uc788\ub294 \uce7c\ub7fc\uc740?\ntrain.columns.difference( test.columns )","f51d103c":"# Train\/Test-set\uc740 \uc5b4\ub5bb\uac8c \ubd84\ub9ac\ub418\uc5c8\uc744\uae4c?\ndisplay(train.head(3))\ndisplay(test.head(3))","9d75e309":"# Train-set\uc758 id\ub294?\nprint(\"Min\/Max of id in Train-set\")\ndisplay( train['id'].agg(['min','max']) )\n\nprint('='* 80)\nprint(f'Size : {len(train)}')","d5e3e206":"# test-set\uc758 id\ub294?\nprint(\"Min\/Max of id in Test-set\")\ndisplay( test['id'].agg(['min','max']) )\n\nprint('='* 80)\nprint(f'Size : {len(test)}')","9c014599":"# Train-set\uc758 date\ub294?\nprint(\"Min\/Max of date in Train-set\")\ndisplay( train['date'].agg(['min','max']) )\n\nprint('='* 80)\nprint(f'Size : {len(train)}')","410fec5b":"# Train-set\uc758 date\ub294?\nprint(\"Min\/Max of date in Test-set\")\ndisplay( test['date'].agg(['min','max']) )\n\nprint('='* 80)\nprint(f'Size : {len(test)}')","9ead6dbf":"# Train\/Test\uc758 date \ubd84\ud3ec\ub294?\n\n# Figure\uc744 \uc815\uc758\nplt.figure(figsize = (12,8))\n\n# Train\/Test-set \uac01\uac01\uc5d0\uc11c \ud2b9\uc815 date\uac00 \uba87 \ubc88 \ub4f1\uc7a5\ud588\ub294\uc9c0 \uc2dc\uac01\ud654 \uc2dc\ud0b4\ntrain['date'].value_counts().sort_index().plot(color='b', lw=2, label='train')\ntest['date'].value_counts().sort_index().plot(color='r',  lw=2, label='test')\n\nplt.legend()\nplt.xlabel(\"date\")\nplt.ylabel(\"# of rows\")\nplt.title(\"Distribution of date in Train\/Test-set\");","43dbf637":"# Train\/Test-set\uc758 \uace0\uc720\ud55c bus_route_id\ub97c \uad6c\ud568.\ntrain_bus_route_id_set = set(train['bus_route_id'])\ntest_bus_route_id_set  = set(test['bus_route_id'])\n\n\n# Train\/Test-set \uace0\uc720\ud55c bus_route\uc758 \uac1c\uc218\ub97c \uad6c\ud568.\nprint(f\"Train-set\uc5d0 \uc788\ub294 \uace0\uc720\ud55c bus_route\uc758 \uac1c\uc218 : { len(train_bus_route_id_set) }\")\nprint(f\"Test-set\uc5d0 \uc788\ub294 \uace0\uc720\ud55c bus_route\uc758 \uac1c\uc218 : { len(test_bus_route_id_set) }\")\n\n# Train\/Test-set \ubaa8\ub450\uc5d0 \ud3ec\ud568\ub418\uc5b4\uc788\ub294 bus_route\ub97c \uad6c\ud568.\nprint('='* 80)\ncommon_bus_route_id = train_bus_route_id_set.intersection(test_bus_route_id_set)\nprint(f\"Train\/Test-set\uc5d0 \uacf5\ud1b5\uc73c\ub85c \ud3ec\ud568\ub418\uc5b4 \uc788\ub294 bus_route \uac1c\uc218 : {len(common_bus_route_id)}\")\n\n# Train-set\uc5d0\ub9cc \uc788\ub294 bus_route\ub97c \uad6c\ud568.\nprint('='* 80)\nonly_train_bus_route = train_bus_route_id_set.difference(test_bus_route_id_set)\nprint(f\"Train-set\uc5d0\ub9cc \uc788\ub294 bus_route\ub294 \ucd1d { len(only_train_bus_route) }\uac1c \uc785\ub2c8\ub2e4.\")\nprint(f\"Train-set\uc5d0\ub9cc \uc788\ub294 bus_route\ub294 : { sorted(only_train_bus_route ) }\")\n\n# Test-set\uc5d0\ub9cc \uc788\ub294 bus_route\ub97c \uad6c\ud568.\nprint('='* 80)\nonly_test_bus_route = test_bus_route_id_set.difference(train_bus_route_id_set)\nprint(f\"Test-set\uc5d0\ub9cc \uc788\ub294 bus_route\ub294 \ucd1d { len(only_test_bus_route) }\uac1c \uc785\ub2c8\ub2e4.\")\nprint(f\"Test-set\uc5d0\ub9cc \uc788\ub294 bus_route\ub294 : { sorted( only_test_bus_route ) }\")","01456fd0":"# Test-set\uc5d0\ub9cc \uc788\ub294 bus_route_id\uc640 Train\/Test-set\ubaa8\ub450\uc5d0 \ub4f1\uc7a5\ud558\ub294 bus_route_id\uc758 \ud0d1\uc2b9\/\ud558\ucc28 \uce7c\ub7fc\ub4e4\uc758 \ud569\uc744 \ube44\uad50\ud574\ubcf4\uc790\n\nprint(\"\uc624\uc9c1 Test-set\uc5d0\ub9cc \uc874\uc7ac\ud558\ub294 bus_route_id\")\ndisplay(test[test['bus_route_id'].isin(only_test_bus_route)].head() )\n\nprint(\"=\"*80)\nprint(\"Train\/Test-set \ubaa8\ub450\uc5d0 \uc874\uc7ac\ud558\ub294 bus_route_id\")\ndisplay(test[test['bus_route_id'].isin(common_bus_route_id)].head() )","37d9b6ee":"# \ud0d1\uc2b9 \uad00\ub828 columns & \ud558\ucc28 \uad00\ub828 columns\nride_columns = [col for col in test.columns if '_ride' in col] + ['bus_route_id','date']\ntake_off_columns = [col for col in test.columns if '_takeoff' in col] + ['bus_route_id','date']","7eb408e3":"# \ub450 \uacbd\uc6b0\uc758 \ud0d1\uc2b9 \uad00\ub828 columns \ube44\uad50\nplt.figure(figsize=(12,5))\n\ntest[test['bus_route_id'].isin(only_test_bus_route)][ride_columns].groupby(['date','bus_route_id'])['8~9_ride'].sum().groupby('date').mean().plot(color='b', lw=2, label='only in Test-set')\ntest[test['bus_route_id'].isin(common_bus_route_id)][ride_columns].groupby(['date','bus_route_id'])['8~9_ride'].sum().groupby('date').mean().plot(color='r', lw=2, label='Both in Train\/Test-set')\nplt.legend()\nplt.title(\"Average number of passengers\\nbus_route_id only in Test-set VS bus_route_id both in Train\/Test-set \");","5b216dc7":"# Missing Values\nmsno.matrix(train)","d31baafd":"# Missing Value \ud655\uc778\nprint(\"Train-set\")\ndisplay( train.isnull().sum() )\n\nprint('=' * 80)\n\nprint(\"Test-set\")\ndisplay( test.isnull().sum() )\n","2fb54c33":"# Target Variable\uc758 \ubd84\ud3ec\ub97c \uc0b4\ud3b4\ubcf4\uc790\ntarget_col = '18~20_ride'\n\ntrain[target_col].value_counts().sort_index()","8f6b84de":"# Dist-plot\uc744 \uadf8\ub824\ubcf4\ub3c4\ub85d \ud55c\ub2e4.\n# --> (1) 0\uc774 \uad49\uc7a5\ud788 \ub9ce\ub2e4. \n# --> (2) right-skewed\ub41c \ud615\ud0dc\uc774\uba70, \uac12\uc774 \ub9e4\uc6b0 \ud070 outlier\ub4e4\uc774 \uc874\uc7ac\ud55c\ub2e4.\nsns.distplot( train[target_col] )","8ab30565":"# log1p transformation\uc744 \uc801\uc6a9\ud574\ubd10\ub3c4 \uc815\uaddc\ubd84\ud3ec\uc5d0 \uadfc\uc0ac\ud55c \ubaa8\uc591\uc744 \ubcf4\uc774\uc9c0 \uc54a\ub294\ub2e4.\nsns.distplot( np.log1p( train[target_col] ) )","ce7f60b8":"# \ud0d1\uc2b9 \uad00\ub828 columns & \ud558\ucc28 \uad00\ub828 columns\nride_columns = [col for col in test.columns if '_ride' in col]\ntake_off_columns = [col for col in test.columns if '_takeoff' in col] ","21a975d0":"# Train-set\uc758 \uc2b9\ucc28\uad00\ub828 \uce7c\ub7fc\ub4e4\uc758 rowsum\ndisplay( train[train[target_col]==0][ride_columns].sum(axis=1).agg(['min','max']) )\n\n# Train-set\uc758 \ud558\ucc28\uad00\ub828 \uce7c\ub7fc\ub4e4\uc758 rowsum\ndisplay( train[train[target_col]==0][take_off_columns].sum(axis=1).agg(['min','max']) )\n\n# Train-set\uc758 \uc2b9\ud558\ucc28\uad00\ub828 \uce7c\ub7fc\ub4e4\uc758 rowsum\ndisplay( train[train[target_col]==0][ride_columns + take_off_columns].sum(axis=1).agg(['min','max']) )","42c3a5f0":"# (1)\uc758 \uacbd\uc6b0\uc5d0\ub294 \uc5b4\ub5a4 \uac83\ub4e4\uc774 \uc788\ub098 \uc608\uc2dc\ub97c \ud1b5\ud574 \uc0b4\ud3b4\ubcf4\ub3c4\ub85d \ud558\uc790\n# \ud558\ub098\uc758 station_name\uc5d0 \uc5ec\ub7ec \uac1c\uc758 station_code\uac00 \uae30\ub85d\ub418\uc5b4 \uc788\ub294 \uacbd\uc6b0\ub294 \uc5b4\ub5a4 \uc0c1\ud669\uc778\uac00?\nmultiple_station_name = train.groupby('station_name')['station_code'].nunique()\nmultiple_station_name = multiple_station_name[multiple_station_name>=7]\nprint(multiple_station_name)\n\ndf_sample = train[train['station_name'].isin(multiple_station_name.index)][['station_code','station_name','latitude','longitude']]\ndf_sample = df_sample.drop_duplicates().reset_index(drop=True)\ndf_sample","247f74c6":"def generateMap(default_location=[33.35098, 126.79807], default_zoom_start=10):\n    base_map = folium.Map(location=default_location, \n                          control_scale=True, \n                          zoom_start=default_zoom_start)\n    \n    # \uc5ec\ub7ec \uac1c\uc758 \uc815\uac70\uc7a5\uc5d0 \ub300\ud574\uc11c Icon \uc0dd\uc131\ud558\uae30\n    for row in df_sample.itertuples():\n        station_code, station_name, latitude, longitude = row[1:]\n        \n        # Create Icon\n        if station_name == '\uae08\uc545\ub9ac':\n            icon = Icon(color='red',icon='station')\n        else:\n            icon = Icon(color='blue',icon='station')\n                \n        # Add Marker\n        Marker(location=[ latitude , longitude], \n               popup=f'station_code : {station_code} station_name : {station_name}',\n               icon = icon).add_to(base_map)\n        \n    \n    base_map.save('\ud558\ub098\uc758 station_name\uc5d0 \uc5ec\ub7ec\uac1c\uc758 station_code.html')\n    return base_map\n\ngenerateMap()","58cda844":"display( train.groupby('station_name')['station_code'].nunique().value_counts() )","df79d241":"# station_name\ub97c \uae30\uc900\uc73c\ub85c \uc0bc\ub294\ub2e4\uba74?\n# --> \ud558\ub098\uc758 station_name\uac00 \uc5ec\ub7ec \uac1c\uc758 latitude, longitude\ub97c \uac16\ub294 \uac83\uc73c\ub85c \ubcf4\uc784\ndisplay( train.groupby('station_name')['latitude'].nunique().value_counts() )\ndisplay( train.groupby('station_name')['longitude'].nunique().value_counts() )","174497ec":"# station_code\ub97c \uae30\uc900\uc73c\ub85c \uc0bc\ub294\ub2e4\uba74?\n# --> station_code\uc5d0\ub294 1\uac1c\uc758  station_name\uc774 \ub9e4\ud551\ub418\uc5b4\uc788\uc74c.\ndisplay( train.groupby('station_code')['station_name'].nunique().value_counts() )","d64f4415":"# station_code\ub97c \uae30\uc900\uc73c\ub85c \uc0bc\ub294\ub2e4\uba74?\n# --> station_code\ub294 latitude, longitude\uc640 1\ub3001 \uad00\uacc4\ub97c \ub9cc\uc871\ud568\ndisplay( train.groupby('station_code')['latitude'].nunique().value_counts() )\ndisplay( train.groupby('station_code')['longitude'].nunique().value_counts() )","480c23a5":"# station_code\ub97c \uae30\uc900\uc73c\ub85c \uc0bc\ub294\ub2e4\uba74?\n# --> station_code\ub294 in_out\uc640 1\ub3001 \uad00\uacc4\ub97c \ub9cc\uc871\ud568\ndisplay( train.groupby('station_code')['in_out'].nunique().value_counts() )","8a6e1e50":"# date, bus_route_id, station_code\uc774 \ud2b9\uc815 \ub0a0\uc9dc\uc5d0 \uba87\ubc88 \ub4f1\uc7a5\ud588\ub294\uc9c0 \uc7ac\ud655\uc778\ud558\uae30 \ndisplay( train.groupby(['date','bus_route_id','station_code']).size().value_counts() )\nprint('='* 80)\nprint(f'Train-set size : {len(train)}')","4e78c121":"# local_train\/local_test\ub97c \ub9cc\ub4e0\ub2e4.\nlocal_train = train[train['date']<='2019-09-24'].reset_index(drop=True)\nlocal_test  = train[train['date']>'2019-09-24'].reset_index(drop=True)","3188627f":"# categorical variable\uc778 'bus_route_id','in_out','station_code','station_name' \uc5d0 \ub300\ud574\uc120 label_encoding\uc744 \uc801\uc6a9\ud574\uc8fc\uace0,\n# numeric variable\ub4e4\uc5d0 \ub300\ud574\uc120 \uc788\ub294 \uadf8\ub300\ub85c \ud559\uc2b5\uc744 \uc2dc\ucf1c\ubcf4\ub3c4\ub85d \ud55c\ub2e4.\nlbl = LabelEncoder()\n\n# Implement Label Encoding \ncat_cols = ['bus_route_id','in_out','station_code','station_name']\nfor col in tqdm_notebook( cat_cols ):\n    # local_train\uacfc local_test\ub97c concat\ud558\uc5ec temp_df\uc5d0 \uc800\uc7a5\n    temp_df = pd.concat([ local_train[[col]], local_test[[col]] ] , axis=0)\n    \n    # Label-Encoding\uc744 fitting\ud568\n    lbl.fit( temp_df[col] )\n    \n    # local_train\/local_test\uc5d0 label_encoding\ud55c \uac12\uc744 \ub300\uc785\ud568\n    local_train[col] = lbl.transform(local_train[col])\n    local_test[col] = lbl.transform(local_test[col])","72236cb7":"local_train.head()","52ef1361":"# \ubaa8\ub378\uc5d0 \uc4f0\uc77c parameter \uc815\uc758\ud558\uae30\nn_splits= 5\nNUM_BOOST_ROUND = 100000\nSEED = 1993\nlgbm_param = {'objective':'rmse',\n              'boosting_type': 'gbdt',\n              'random_state':1993,\n              'learning_rate':0.3,\n              'subsample':0.7,\n              'tree_learner': 'serial',\n              'colsample_bytree':0.78,\n              'early_stopping_rounds':50,\n              'subsample_freq': 1,\n              'reg_lambda':7,\n              'reg_alpha': 5,\n              'num_leaves': 96,\n              'seed' : SEED\n            }","2a039d31":"# \uc81c\uac70\ud574\uc57c\ud558\ub294 columns\ub4e4 \uc815\uc758\ndrop_cols = ['id','date', target_col]\n\n# local_train\/local_test\uc5d0 \ub300\ud55c label \uc815\uc758\nlocal_train_label = local_train[target_col]\nlocal_test_label  = local_test[target_col]","624f6e78":"# local_train\/local_test\uc758 \uc608\uce21\uac12\uc744 \uc800\uc7a5\ud558\uae30 \uc704\ud55c OOF \ub9cc\ub4e4\uae30 & CV\ub97c \uc800\uc7a5\ud560 list \uc815\uc758\noof_train = np.zeros((local_train.shape[0], ))\noof_test = np.zeros((local_test.shape[0], ))\n\ncv_list = []\n\n\n# Kfold \uc815\uc758\nkfolds = KFold(n_splits=n_splits, random_state=1993, shuffle=True)\n\n# Fold\ubcc4\ub85c \ud559\uc2b5\uc9c4\ud589\nfor ind, (trn_ind, val_ind) in tqdm_notebook( enumerate( kfolds.split( X = local_train, y = local_train_label ) ) ):\n    \n    # Train\/Valid-set\uc744 \uc815\uc758\ud558\uae30\n    X_train , y_train = local_train.iloc[trn_ind].drop(drop_cols, 1), local_train_label[trn_ind]\n    X_valid , y_valid = local_train.iloc[val_ind].drop(drop_cols, 1), local_train_label[val_ind]\n    \n    # dtrain\/dvalid \uc815\uc758\n    dtrain = lgbm.Dataset(X_train, y_train)\n    dvalid = lgbm.Dataset(X_valid, y_valid)\n    \n    # model \uc815\uc758&\ud559\uc2b5\n    model = lgbm.train(lgbm_param , dtrain, NUM_BOOST_ROUND, \n                       valid_sets=(dtrain, dvalid), \n                       valid_names=('train','valid'), \n                       verbose_eval= 100)\n    \n    # local_valid\/local_test\uc5d0 \ub300\ud55c \uc608\uce21\n    valid_pred = model.predict(X_valid)\n    test_pred  = model.predict( local_test.drop(drop_cols,1) )\n    \n    # CV\ub97c \uc800\uc7a5\n    cv_list.append( sqrt( mean_squared_error( y_valid, valid_pred )  ) )\n    \n    # OOF\uc5d0 \uc608\uce21\uac12\uc744 \uc800\uc7a5\n    oof_train[val_ind] = valid_pred\n    oof_test += test_pred\/n_splits\n    print('='*80)\n    \nprint(f\"<LOCAL_TRAIN> OVERALL RMSE : {sqrt( mean_squared_error( local_train_label, oof_train ) )}\")\nprint(f\"<LOCAL_TEST>  OVERALL RMSE : {sqrt( mean_squared_error( local_test_label, oof_test ) )}\")","a0fcf213":"# \uc2e4\uc81c\uac12\uacfc \uc608\uce21\uac12\uc758 \ubd84\ud3ec \ube44\uad50\nfig, axes = plt.subplots( 1, 2, figsize=(20, 8), sharex=True, sharey=True)\n\n# y=x\ub97c \uadf8\ub9ac\uae30 \uc704\ud558\uc5ec\nx_range = np.linspace(0, 300, 1000)\n\n# <SUBPLOT 1> : local_train\uc5d0 \ub300\ud55c \uc608\uce21\/\uc2e4\uc81c\uac12 \ube44\uad50\naxes[0].scatter( local_train_label, oof_train )\naxes[0].set_xlabel(\"Prediction\")\naxes[0].set_ylabel(\"Real\")\n\n# y=x \uadf8\ub9ac\uae30\naxes[0].plot(x_range, x_range, color='r')\n\n# <SUBPLOT 2> : local_test\uc5d0 \ub300\ud55c \uc608\uce21\/\uc2e4\uc81c\uac12 \ube44\uad50\naxes[1].scatter( local_test_label, oof_test )\naxes[1].set_xlabel(\"Prediction\")\naxes[1].set_ylabel(\"Real\")\n\n# y=x \uadf8\ub9ac\uae30\naxes[1].plot(x_range, x_range, color='r');\n\n# Super Title \nplt.suptitle('Comparison between Prediction VS Real');","30fcbd8e":"# \uc2e4\uc81c\uac12 vs \uc608\uce21\uac12 \ube44\uad50\nplt.figure(figsize=(12,6))\n\nsns.distplot( oof_train, color='r' , label='Prediction for Local-Train')\nsns.distplot( local_train_label, color='b', label='Real' )\nplt.legend()\nplt.title(\"Comparing the real vs prediction in Local-Train\");\n","e2130acf":"# \uc2e4\uc81c\uac12 vs \uc608\uce21\uac12 \ube44\uad50\nplt.figure(figsize=(12,6))\n\nsns.distplot( oof_test, color='r' , label='Prediction for Local-Test')\nsns.distplot( local_test_label, color='b', label='Real' )\nplt.legend()\nplt.title(\"Comparing the real vs prediction in Local-Test\");","c38bea06":"del local_train, local_test, local_train_label, local_test_label; gc.collect();","fa415433":"# train_label \uc815\uc758\ntrain_label = train[target_col]","1437ab95":"# categorical variable\uc5d0 \ub300\ud574\uc11c\ub294 Label-Encoding\uc744 \uc218\ud589 \n# --> One-Hot Encoding\uac00 \ubc14\ub78c\uc9c1\ud558\ub2e4\uace0 \uc0dd\uac01\ub418\ub098 \uba54\ubaa8\ub9ac \ubb38\uc81c\ub85c \uc2e4\ud589\ud560 \uc218 \uc5c6\uc74c.\nlbl = LabelEncoder()\n\n# Implement Label Encoding \ncat_cols = ['bus_route_id','in_out','station_code','station_name']\nfor col in tqdm_notebook( cat_cols ):\n    \n    # Label-Encoding\uc744 fitting\ud568\n    lbl.fit( train[col] )\n    \n    # local_train\/local_test\uc5d0 label_encoding\ud55c \uac12\uc744 \ub300\uc785\ud568\n    train[col] = lbl.transform(train[col])","77f2201f":"# \uac01 \ubaa8\ub378\uc5d0 \ub300\ud55c oof \uc815\uc758\nridge_oof_train = np.zeros((train.shape[0]))\nlasso_oof_train = np.zeros((train.shape[0]))\ndt_oof_train = np.zeros((train.shape[0]))\nrf_oof_train = np.zeros((train.shape[0]))\nlgbm_oof_train = np.zeros((train.shape[0]))\n\n# Kfold \uc815\uc758\nkfolds = KFold(n_splits=n_splits, random_state=1993, shuffle=True)\n\n# Fold\ubcc4\ub85c \ud559\uc2b5\uc9c4\ud589\nfor ind, (trn_ind, val_ind) in tqdm_notebook( enumerate( kfolds.split( X = train, y = train_label ) ) ):\n    \n    # Train\/Valid-set\uc744 \uc815\uc758\ud558\uae30\n    X_train , y_train = train.iloc[trn_ind].drop(drop_cols, 1), train_label[trn_ind]\n    X_valid , y_valid = train.iloc[val_ind].drop(drop_cols, 1), train_label[val_ind]\n    \n    # (1) Ridge\n    print(\"---TRAINING RIDGE---\")\n    ridge = Ridge(random_state = 1993)\n    \n    ridge.fit(X_train, y_train)\n    \n    ridge_valid_pred = ridge.predict(X_valid)\n    ridge_oof_train[val_ind] = ridge_valid_pred\n    \n    # (2) Lasso\n    print(\"---TRAINING LASSO---\")\n    lasso = Lasso(random_state = 1993)\n    \n    lasso.fit(X_train, y_train)\n    \n    lasso_valid_pred = lasso.predict(X_valid)\n    lasso_oof_train[val_ind] = lasso_valid_pred\n    \n    # (3) Decision Tree\n    print(\"---TRAINING DECISION TREE---\")\n    dt = DecisionTreeRegressor(random_state=231)\n    \n    dt.fit(X_train, y_train)\n    \n    dt_valid_pred = dt.predict(X_valid)\n    dt_oof_train[val_ind] = dt_valid_pred\n    \n    \n    # (4) Random Forest\n    print(\"---TRAINING RANDOM FOREST---\")\n    rf = RandomForestRegressor(random_state=231, n_estimators=20 )\n    \n    rf.fit(X_train, y_train)\n    \n    rf_valid_pred = rf.predict(X_valid)\n    rf_oof_train[val_ind] = rf_valid_pred\n    \n    # (5) Light GBM\n    print(\"---TRAINING LIGHT GBM---\")\n    # dtrain\/dvalid \uc815\uc758\n    dtrain = lgbm.Dataset(X_train, y_train)\n    dvalid = lgbm.Dataset(X_valid, y_valid)\n    \n    # model \uc815\uc758&\ud559\uc2b5\n    model = lgbm.train(lgbm_param , dtrain, NUM_BOOST_ROUND, \n                       valid_sets=(dtrain, dvalid), \n                       valid_names=('train','valid'), \n                       verbose_eval= 0)\n    \n    # local_valid\/local_test\uc5d0 \ub300\ud55c \uc608\uce21\n    lgbm_valid_pred = model.predict(X_valid)\n        \n    lgbm_oof_train[val_ind] = lgbm_valid_pred\n    print('='*80)\n    \nprint(f\"<Ridge> OVERALL RMSE         : {sqrt( mean_squared_error( train_label, ridge_oof_train ) )}\")\nprint(f\"<Lasso> OVERALL RMSE         : {sqrt( mean_squared_error( train_label, lasso_oof_train ) )}\")\nprint(f\"<Decision-Tree> OVERALL RMSE : {sqrt( mean_squared_error( train_label, dt_oof_train ) )}\")\nprint(f\"<Random-Forest> OVERALL RMSE : {sqrt( mean_squared_error( train_label, rf_oof_train ) )}\")\nprint(f\"<Light-GBM> OVERALL RMSE     : {sqrt( mean_squared_error( train_label, lgbm_oof_train ) )}\")","41fcaa02":"# Figure\uc744 \uc815\uc758\ud55c\ub2e4.\nplt.figure(figsize=(24,5))\n\n# Ridge\uc758 Coef\ub97c barplot\uc73c\ub85c \uadf8\ub9b0\ub2e4.\nplt.bar( train.drop(drop_cols,1).columns,  ridge.coef_ )\n\n# y=0\uc778 horizental\ud55c \uc120\uc744 \uadf8\ub9b0\ub2e4.\nplt.axhline(y=0, color='r', linestyle='-')\n\nplt.xticks(rotation=45)\nplt.title(\"Coef of Ridge Model\");","8e73bfd8":"# Figure\uc744 \uc815\uc758\ud55c\ub2e4.\nplt.figure(figsize=(24,5))\n\n# lasso\uc758 Coef\ub97c barplot\uc73c\ub85c \uadf8\ub9b0\ub2e4.\nplt.bar( train.drop(drop_cols,1).columns,  lasso.coef_ )\n\n# y=0\uc778 horizental\ud55c \uc120\uc744 \uadf8\ub9b0\ub2e4.\nplt.axhline(y=0, color='r', linestyle='-')\n\nplt.xticks(rotation=45)\nplt.title(\"Coef of lasso Model\");","7afcb1ec":"# \uc0c1\uad00\uad00\uacc4\ub97c \uc0b4\ud3b4\ubcf4\ub3c4\ub85d \ud558\uc790.\ntrain.corr()[target_col].sort_values()","bb8e7e04":"# Figure\uc744 \uc815\uc758\ud55c\ub2e4.\nplt.figure(figsize=(24,5))\n\n# Ridge\uc758 Coef\ub97c barplot\uc73c\ub85c \uadf8\ub9b0\ub2e4.\nplt.bar( train.drop(drop_cols,1).columns,  rf.feature_importances_ )\n\n# y=0\uc778 horizental\ud55c \uc120\uc744 \uadf8\ub9b0\ub2e4.\nplt.axhline(y=0, color='r', linestyle='-')\n\nplt.xticks(rotation=45)\nplt.title(\"Coef of Random Forest Model\");","ccaf4668":"# Figure\uc744 \uc815\uc758\ud55c\ub2e4.\nplt.figure(figsize=(24,5))\n\n# Ridge\uc758 Coef\ub97c barplot\uc73c\ub85c \uadf8\ub9b0\ub2e4.\nplt.bar( train.drop(drop_cols,1).columns,  model.feature_importance() )\n\n# y=0\uc778 horizental\ud55c \uc120\uc744 \uadf8\ub9b0\ub2e4.\nplt.axhline(y=0, color='r', linestyle='-')\n\nplt.xticks(rotation=45)\nplt.title(\"Coef of Random Forest Model\");","f4c0b443":"# \uc804\uccb4 \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud560 \uc2dc \ub108\ubb34 \ub9ce\uc740 \uc2dc\uac04\uc774 \uc18c\uc694\ub418\uc5b4 \uc77c\ubd80 \uc0d8\ud50c\ub9cc \uc0ac\uc6a9\ud558\ub3c4\ub85d \ud558\uaca0\uc2b5\ub2c8\ub2e4.\nsample = train.drop(drop_cols,1).sample(1000)","cb77d1db":"# PDP Plot For 11~12_ride\npdp_ = pdp.pdp_isolate(\n    model= model, dataset=sample, model_features=list(sample), feature='11~12_ride'\n)\nfig, axes = pdp.pdp_plot(pdp_, '11~12_ride')","fde57c2b":"# PDP Plot For 8~9_takeoff\npdp_ = pdp.pdp_isolate(\n    model= model, dataset=sample, model_features=list(sample), feature='8~9_takeoff'\n)\nfig, axes = pdp.pdp_plot(pdp_, '8~9_takeoff')\n","a8137818":"# PDP Plot For latitude\npdp_ = pdp.pdp_isolate(\n    model= model, dataset=sample, model_features=list(sample), feature='latitude'\n)\nfig, axes = pdp.pdp_plot(pdp_, 'latitude')\n","64256804":"# PDP Plot For longitude\npdp_ = pdp.pdp_isolate(\n    model= model, dataset=sample, model_features=list(sample), feature='longitude'\n)\nfig, axes = pdp.pdp_plot(pdp_, 'longitude')\n","d540a14e":"# Interactive PDP Plot For latitude,longitude\npdp_ = pdp.pdp_interact(\n    model= model, dataset=sample, model_features=list(sample), features=['latitude','longitude']\n)\n\nfig, axes = pdp.pdp_interact_plot(pdp_interact_out=pdp_,\n                                  feature_names=['latitude','longitude'],\n                                  plot_type='grid',\n                                  x_quantile=True,\n                                  plot_pdp=False)","cdd40b0c":"# \ubaa8\ub378\uc5d0 \uc4f0\uc77c parameter \uc815\uc758\ud558\uae30\nn_splits= 5\nNUM_BOOST_ROUND = 100000\nSEED = 1993\nlgbm_param = {'objective':'rmse',\n              'boosting_type': 'gbdt',\n              'random_state':1993,\n              'learning_rate':0.1,\n              'subsample':0.7,\n              'tree_learner': 'serial',\n              'colsample_bytree':0.78,\n              'early_stopping_rounds':50,\n              'subsample_freq': 1,\n              'reg_lambda':7,\n              'reg_alpha': 5,\n              'num_leaves': 96,\n              'seed' : SEED\n            }","87aa8012":"# \ub370\uc774\ud130\ub97c load\ud569\ub2c8\ub2e4.\n# train\/test --> string\ud615\uc2dd\uc73c\ub85c \uc800\uc7a5\ub418\uc5b4 \uc788\ub294 `date` column\uc740 datetime\ud615\uc2dd\uc73c\ub85c \uc218\uc9d1\ud569\ub2c8\ub2e4.\n# bus_bts    --> string\ud615\uc2dd\uc73c\ub85c \uc800\uc7a5\ub418\uc5b4 \uc788\ub294 `geton_date`, `getoff_date` columns\uc740 datetime\ud615\uc2dd\uc73c\ub85c \uc218\uc9d1\ud569\ub2c8\ub2e4.\ndef load_dataset(path):\n    train = pd.read_csv(path + 'train.csv', parse_dates=['date'])\n    test  = pd.read_csv(path + 'test.csv', parse_dates=['date'])\n    df_bus = pd.read_csv(path + 'bus_bts.csv', parse_dates = ['geton_date', 'getoff_date'] )\n    sample_submission = pd.read_csv(path + 'submission_sample.csv')\n    return train, test, df_bus, sample_submission\n\npath = '..\/input\/dacon-bus-dataset\/'\n%time train, test, df_bus, sample_submission = load_dataset(path)","e0584be0":"# categorical variable\uc5d0 \ub300\ud574\uc11c\ub294 Label-Encoding\uc744 \uc218\ud589 \n# --> One-Hot Encoding\uac00 \ubc14\ub78c\uc9c1\ud558\ub2e4\uace0 \uc0dd\uac01\ub418\ub098 \uba54\ubaa8\ub9ac \ubb38\uc81c\ub85c \uc2e4\ud589\ud560 \uc218 \uc5c6\uc74c.\nlbl = LabelEncoder()\n\n# Implement Label Encoding \ncat_cols = ['bus_route_id','in_out','station_code','station_name']\nfor col in tqdm_notebook( cat_cols ):\n    \n    # Label-Encoding\uc744 fitting\ud568\n    lbl.fit( train[[col]].append(test[[col]]) )\n    \n    # train\/test label_encoding\ud55c \uac12\uc744 \ub300\uc785\ud568\n    train[col] = lbl.transform(train[col])\n    test[col] = lbl.transform(test[col])","7573d1fe":"# \uac01 \ubaa8\ub378\uc5d0 \ub300\ud55c oof \uc815\uc758\nlgbm_oof_train = np.zeros((train.shape[0]))\n\n# Kfold \uc815\uc758\nkfolds = KFold(n_splits=n_splits, random_state=1993, shuffle=True)\n\n# Fold\ubcc4\ub85c \ud559\uc2b5\uc9c4\ud589\nfor ind, (trn_ind, val_ind) in tqdm_notebook( enumerate( kfolds.split( X = train, y = train_label ) ) ):\n    \n    # Train\/Valid-set\uc744 \uc815\uc758\ud558\uae30\n    X_train , y_train = train.iloc[trn_ind].drop(drop_cols, 1), train_label[trn_ind]\n    X_valid , y_valid = train.iloc[val_ind].drop(drop_cols, 1), train_label[val_ind]\n    \n    \n    \n    # (5) Light GBM\n    print(\"---TRAINING LIGHT GBM---\")\n    # dtrain\/dvalid \uc815\uc758\n    dtrain = lgbm.Dataset(X_train, y_train)\n    dvalid = lgbm.Dataset(X_valid, y_valid)\n    \n    # model \uc815\uc758&\ud559\uc2b5\n    model = lgbm.train(lgbm_param , dtrain, NUM_BOOST_ROUND, \n                       valid_sets=(dtrain, dvalid), \n                       valid_names=('train','valid'), \n                       verbose_eval= 100)\n    \n    # local_valid\/local_test\uc5d0 \ub300\ud55c \uc608\uce21\n    lgbm_valid_pred = model.predict(X_valid)\n        \n    lgbm_oof_train[val_ind] = lgbm_valid_pred\n    print('='*80)\n    \nprint(f\"<Light-GBM> OVERALL RMSE     : {sqrt( mean_squared_error( train_label, lgbm_oof_train ) )}\")","dd6fa8e8":"# \ud53c\uccd0 \uc911\uc694\ub3c4 \ud655\uc778\ndf_imp = pd.DataFrame(data = {'col': model.feature_name(),\n                              'imp': model.feature_importance()})\ndf_imp = df_imp.sort_values(by='imp', ascending=False).reset_index(drop=True)\ndf_imp ","0f7ba4ef":"# \uc2b9\ud558\ucc28 \uac04\uaca9\uc744 2\uc2dc\uac04 \uac04\uaca9\uc73c\ub85c \uc124\uc815\ud560 \uc218\ub294 \uc5c6\ub294\uac00? (3\uc2dc\uac04\uc73c\ub85c \uc124\uc815\ud574\ub3c4 ok -> \uacb0\uad6d \uc2e4\ud5d8\uc758 \uc601\uc5ed)\ndawn_ride_cols, dawn_takoff_cols = ['6~7_ride','7~8_ride'], ['6~7_takeoff','7~8_takeoff']\nmorning_ride_cols, morning_takeoff_cols = ['8~9_ride','9~10_ride'], ['8~9_takeoff','9~10_takeoff']\nnoon_ride_cols, noon_takeoff_cols = ['10~11_ride','11~12_ride'], ['10~11_takeoff','11~12_takeoff']\n\n# df \uac00\uacf5\ndef modify_terms(df):\n    # ride columns\n    df['dawn_ride'] = df[dawn_ride_cols].sum(axis=1)\n    df['morning_ride'] = df[morning_ride_cols].sum(axis=1)\n    df['noon_ride'] = df[noon_ride_cols].sum(axis=1)\n    \n    # takeoff columns\n    df['dawn_takeoff'] = df[dawn_takoff_cols].sum(axis=1)\n    df['morning_takeoff'] = df[morning_takeoff_cols].sum(axis=1)\n    df['noon_takeoff'] = df[noon_takeoff_cols].sum(axis=1)\n    \n    # drop columns\n    drop_cols = dawn_ride_cols + morning_ride_cols + noon_ride_cols + dawn_takoff_cols + morning_takeoff_cols + noon_takeoff_cols\n    df = df.drop(drop_cols, 1)\n    \n    return df\n    \n\ntrain = modify_terms(train)\ntest = modify_terms(test)","61ffb236":"# \uac01 \ubaa8\ub378\uc5d0 \ub300\ud55c oof \uc815\uc758\nlgbm_oof_train = np.zeros((train.shape[0]))\n\n# Kfold \uc815\uc758\nkfolds = KFold(n_splits=n_splits, random_state=1993, shuffle=True)\n\n# Fold\ubcc4\ub85c \ud559\uc2b5\uc9c4\ud589\nfor ind, (trn_ind, val_ind) in tqdm_notebook( enumerate( kfolds.split( X = train, y = train_label ) ) ):\n    \n    # Train\/Valid-set\uc744 \uc815\uc758\ud558\uae30\n    X_train , y_train = train.iloc[trn_ind].drop(drop_cols, 1), train_label[trn_ind]\n    X_valid , y_valid = train.iloc[val_ind].drop(drop_cols, 1), train_label[val_ind]\n    \n    \n    \n    # (5) Light GBM\n    print(\"---TRAINING LIGHT GBM---\")\n    # dtrain\/dvalid \uc815\uc758\n    dtrain = lgbm.Dataset(X_train, y_train)\n    dvalid = lgbm.Dataset(X_valid, y_valid)\n    \n    # model \uc815\uc758&\ud559\uc2b5\n    model = lgbm.train(lgbm_param , dtrain, NUM_BOOST_ROUND, \n                       valid_sets=(dtrain, dvalid), \n                       valid_names=('train','valid'), \n                       verbose_eval= 100)\n    \n    # local_valid\/local_test\uc5d0 \ub300\ud55c \uc608\uce21\n    lgbm_valid_pred = model.predict(X_valid)\n        \n    lgbm_oof_train[val_ind] = lgbm_valid_pred\n    print('='*80)\n    \nprint(f\"<Light-GBM> OVERALL RMSE     : {sqrt( mean_squared_error( train_label, lgbm_oof_train ) )}\")","a500b82e":"# \ud53c\uccd0 \uc911\uc694\ub3c4 \ud655\uc778\ndf_imp = pd.DataFrame(data = {'col': model.feature_name(),\n                              'imp': model.feature_importance()})\ndf_imp = df_imp.sort_values(by='imp', ascending=False).reset_index(drop=True)\ndf_imp ","6e3262a4":"# \uc694\uc77c \uc815\ubcf4 \ucd94\uac00\ntrain['weekday'] = train['date'].dt.weekday\ntest['weekday']  = test['date'].dt.weekday\n\n# \uacf5\ud734\uc77c \uc815\ubcf4 \ucd94\uac00\n# -> EDA\ud544\uc694\nholidays = [datetime(2019, 9 ,12), datetime(2019, 9, 13), datetime(2019, 9 ,14), datetime(2019, 10,3), datetime(2019, 10,9) ]\ntrain['is_holiday'] = train['date'].apply(lambda x: x in holidays).astype(np.int8)\ntest['is_holiday']  = test['date'].apply(lambda x: x in holidays).astype(np.int8)","1a9d0e0f":"# Mean Encoding\n# (1) \uc77c\uc790\ubcc4\ub85c dawn, morning, noon\uc5d0 \uac01\uac01 \uba87\uba87\uc758 \uc2b9\uac1d\uc774 \ud0d1\uc2b9\ud558\uc600\ub294\uac00\n# (2) \uc77c\uc790\ubcc4\ub85c dawn, morning, noon\uc5d0 \uac01\uac01 \uba87\uba87\uc758 \uc2b9\uac1d\uc774 \ud558\ucc28\ud558\uc600\ub294\uac00\n# - \uae30\uc900 :\n# - (1) bus_route_id\n# - (2) bus_route_id , station_code\n# - (3) station_code\n\n# (1) bus_route_id \uae30\uc900\n\n# \ud0d1\uc2b9\ntrain['avg_dawn_ride_bus_route_id'] = train.groupby(['date','bus_route_id'])['dawn_ride'].transform('mean') \ntrain['avg_morning_ride_bus_route_id'] = train.groupby(['date','bus_route_id'])['morning_ride'].transform('mean') \ntrain['avg_noon_ride_bus_route_id'] = train.groupby(['date','bus_route_id'])['noon_ride'].transform('mean') \n\ntest['avg_dawn_ride_bus_route_id'] = test.groupby(['date','bus_route_id'])['dawn_ride'].transform('mean') \ntest['avg_morning_ride_bus_route_id'] = test.groupby(['date','bus_route_id'])['morning_ride'].transform('mean') \ntest['avg_noon_ride_bus_route_id'] = test.groupby(['date','bus_route_id'])['noon_ride'].transform('mean') \n\n# \ud558\ucc28\ntrain['avg_dawn_takeoff_bus_route_id'] = train.groupby(['date','bus_route_id'])['dawn_takeoff'].transform('mean') \ntrain['avg_morning_takeoff_bus_route_id'] = train.groupby(['date','bus_route_id'])['morning_takeoff'].transform('mean') \ntrain['avg_noon_takeoff_bus_route_id'] = train.groupby(['date','bus_route_id'])['noon_takeoff'].transform('mean') \n\ntest['avg_dawn_takeoff_bus_route_id'] = test.groupby(['date','bus_route_id'])['dawn_takeoff'].transform('mean') \ntest['avg_morning_takeoff_bus_route_id'] = test.groupby(['date','bus_route_id'])['morning_takeoff'].transform('mean') \ntest['avg_noon_takeoff_bus_route_id'] = test.groupby(['date','bus_route_id'])['noon_takeoff'].transform('mean') \n\n# (2) bus_route_id, station_code \uae30\uc900\n# train['avg_dawn_ride_bus_route_id_station_code'] = train.groupby(['date','bus_route_id','station_code'])['dawn_ride'].transform('mean') \n# train['avg_morning_ride_bus_route_id_station_code'] = train.groupby(['date','bus_route_id','station_code'])['morning_ride'].transform('mean') \n# train['avg_noon_ride_bus_route_id_station_code'] = train.groupby(['date','bus_route_id','station_code'])['noon_ride'].transform('mean') \n\n# test['avg_dawn_ride_bus_route_id_station_code'] = test.groupby(['date','bus_route_id','station_code'])['dawn_ride'].transform('mean') \n# test['avg_morning_ride_bus_route_id_station_code'] = test.groupby(['date','bus_route_id','station_code'])['morning_ride'].transform('mean') \n# test['avg_noon_ride_bus_route_id_station_code'] = test.groupby(['date','bus_route_id','station_code'])['noon_ride'].transform('mean') \n\n# (3) station_code \uae30\uc900\n# train['avg_dawn_ride_station_code'] = train.groupby(['date','station_code'])['dawn_ride'].transform('mean') \n# train['avg_morning_ride_bus_station_code'] = train.groupby(['date','station_code'])['morning_ride'].transform('mean') \n# train['avg_noon_ride_station_code'] = train.groupby(['date','station_code'])['noon_ride'].transform('mean') \n\n# test['avg_dawn_ride_station_code'] = test.groupby(['date','station_code'])['dawn_ride'].transform('mean') \n# test['avg_morning_ride_bus_station_code'] = test.groupby(['date','station_code'])['morning_ride'].transform('mean') \n# test['avg_noon_ride_station_code'] = test.groupby(['date','station_code'])['noon_ride'].transform('mean') \n\n","032f87c5":"# \uac01 \ubaa8\ub378\uc5d0 \ub300\ud55c oof \uc815\uc758\nlgbm_oof_train = np.zeros((train.shape[0]))\n\n# Kfold \uc815\uc758\nkfolds = KFold(n_splits=n_splits, random_state=1993, shuffle=True)\n\n# Fold\ubcc4\ub85c \ud559\uc2b5\uc9c4\ud589\nfor ind, (trn_ind, val_ind) in tqdm_notebook( enumerate( kfolds.split( X = train, y = train_label ) ) ):\n    \n    # Train\/Valid-set\uc744 \uc815\uc758\ud558\uae30\n    X_train , y_train = train.iloc[trn_ind].drop(drop_cols, 1), train_label[trn_ind]\n    X_valid , y_valid = train.iloc[val_ind].drop(drop_cols, 1), train_label[val_ind]\n    \n    # Target- Mean Encoding\n    X_train['label'] = y_train\n    d = X_train.groupby(['station_code'])['label'].mean().to_dict()\n    X_train['station_code_te'] = X_train['station_code'].apply(lambda x: d.get(x))\n    X_valid['station_code_te'] = X_valid['station_code'].apply(lambda x: d.get(x))\n    \n    X_train= X_train.drop('label',1)\n    \n    \n    # (5) Light GBM\n    print(\"---TRAINING LIGHT GBM---\")\n    # dtrain\/dvalid \uc815\uc758\n    dtrain = lgbm.Dataset(X_train, y_train)\n    dvalid = lgbm.Dataset(X_valid, y_valid)\n    \n    # model \uc815\uc758&\ud559\uc2b5\n    model = lgbm.train(lgbm_param , dtrain, NUM_BOOST_ROUND, \n                       valid_sets=(dtrain, dvalid), \n                       valid_names=('train','valid'), \n                       verbose_eval= 100)\n    \n    # local_valid\/local_test\uc5d0 \ub300\ud55c \uc608\uce21\n    lgbm_valid_pred = model.predict(X_valid)\n        \n    lgbm_oof_train[val_ind] = lgbm_valid_pred\n    print('='*80)\n    \nprint(f\"<Light-GBM> OVERALL RMSE     : {sqrt( mean_squared_error( train_label, lgbm_oof_train ) )}\")","7f8700a4":"# \ub0a0\uc528 \uc815\ubcf4\ndf_weather = pd.read_csv('..\/input\/dacon-bus-dataset\/jeju_weather_dataset', encoding='cp949')\ndf_weather = df_weather[['\uc77c\uc2dc','\uac15\uc218\ub7c9(mm)']]\ndf_weather.columns = ['date','precipitation']\n\n# date\uc758 type\uc744 string\uc5d0\uc11c datetime\uc73c\ub85c \ubcc0\ud658\ndf_weather['date'] = pd.to_datetime( df_weather['date'] )\n\n# \ub300\ud68c \uae30\uac04\uc5d0 \ud574\ub2f9\ud558\ub294 \ub370\uc774\ud130\ub9cc \uc0ac\uc6a9\ud558\ub3c4\ub85d \ud568\ndf_weather = df_weather[(df_weather['date']>='2019-08-31 00:00:00')&(df_weather['date']<='2019-10-16 23:00:00')].reset_index(drop=True)\n\n# \ub300\ud68c \uaddc\uc815\uc0c1 \ud574\ub2f9 \ub0a0\uc9dc\uc758 15\uc2dc\uae4c\uc9c0 \uc815\ubcf4\ub9cc \uc0ac\uc6a9\ud560 \uc218 \uc788\uc74c\ndf_weather['hour'] = df_weather['date'].dt.hour\ndf_weather['date'] = df_weather['date'].dt.date\n\n# \uc804\ub0a0\uc758 \uac15\uc218\ub7c9\uc744 \uc815\ubcf4\ub97c \ub300\uc785\ud560 \ub54c \uc0ac\uc6a9\ndf_prevday_weather = df_weather.groupby('date')['precipitation'].sum().reset_index()\ndf_prevday_weather.columns = ['prev_date', 'prevday_precipitation']\n\n# \ud574\ub2f9 \ub0a0\uc9dc\uc758 \uac15\uc218\ub7c9\uc744 \uad6c\ud568\ndf_weather = df_weather[df_weather['hour']<=15].reset_index(drop=True)\n\n# 00~15\uc2dc\uae4c\uc9c0\uc758 \uac15\uc218\ub7c9\uc744 \ud53c\uccd0\ub85c \uc0ac\uc6a9\ndf_weather = df_weather.groupby('date')['precipitation'].sum().reset_index()\n\n# Train\/Test-set\uacfc join\ud558\uae30 \uc704\ud558\uc5ec column\uc758 \ud0c0\uc785\uc744 datetime\uc73c\ub85c \ubcc0\ud658\ud55c\ub2e4.\ndf_prevday_weather['prev_date'] = pd.to_datetime( df_prevday_weather['prev_date']  )\ndf_weather['date'] = pd.to_datetime( df_weather['date']  )","4172bc7a":"# \uc804\ub0a0\uc9dc\uc5d0 \ub300\ud558\uc5ec Train\/Test-set\uacfc \uac15\uc218\ub7c9 \uc815\ubcf4\ub97c join\n\n# Train\/Test-set\uc5d0 \ub300\ud558\uc5ec \uc804\ub0a0\uc744 \uad6c\ud568\ntrain['prev_date'] = train['date'] - pd.Timedelta('1 day')\ntest['prev_date'] = test['date'] - pd.Timedelta('1 day')\n\ntrain = pd.merge(train, df_prevday_weather , on ='prev_date',  how ='left')\ntest = pd.merge(test, df_prevday_weather , on ='prev_date',how ='left')\n\n# prev_date \uce7c\ub7fc\uc740 \uc0ad\uc81c\ud574\uc90c\ntrain = train.drop('prev_date',1)\ntest = test.drop('prev_date',1)\n\n\n# \ud574\ub2f9\ub0a0\uc9dc\uc5d0 \ub300\ud558\uc5ec Train\/Test-set\uacfc \uac15\uc218\ub7c9 \uc815\ubcf4\ub97c join\ntrain = pd.merge( train, df_weather , on ='date', how='left')\ntest = pd.merge( test, df_weather , on ='date', how='left')","eb6cbbee":"# \uac01 \ubaa8\ub378\uc5d0 \ub300\ud55c oof \uc815\uc758\nlgbm_oof_train = np.zeros((train.shape[0]))\n\n# Kfold \uc815\uc758\nkfolds = KFold(n_splits=n_splits, random_state=1993, shuffle=True)\n\n# Fold\ubcc4\ub85c \ud559\uc2b5\uc9c4\ud589\nfor ind, (trn_ind, val_ind) in tqdm_notebook( enumerate( kfolds.split( X = train, y = train_label ) ) ):\n    \n    # Train\/Valid-set\uc744 \uc815\uc758\ud558\uae30\n    X_train , y_train = train.iloc[trn_ind].drop(drop_cols, 1), train_label[trn_ind]\n    X_valid , y_valid = train.iloc[val_ind].drop(drop_cols, 1), train_label[val_ind]\n    \n    # Target- Mean Encoding\n    X_train['label'] = y_train\n    d = X_train.groupby(['station_code'])['label'].mean().to_dict()\n    X_train['station_code_te'] = X_train['station_code'].apply(lambda x: d.get(x))\n    X_valid['station_code_te'] = X_valid['station_code'].apply(lambda x: d.get(x))\n    \n    X_train= X_train.drop('label',1)\n    \n    \n    # (5) Light GBM\n    print(\"---TRAINING LIGHT GBM---\")\n    # dtrain\/dvalid \uc815\uc758\n    dtrain = lgbm.Dataset(X_train, y_train)\n    dvalid = lgbm.Dataset(X_valid, y_valid)\n    \n    # model \uc815\uc758&\ud559\uc2b5\n    model = lgbm.train(lgbm_param , dtrain, NUM_BOOST_ROUND, \n                       valid_sets=(dtrain, dvalid), \n                       valid_names=('train','valid'), \n                       verbose_eval= 100)\n    \n    # local_valid\/local_test\uc5d0 \ub300\ud55c \uc608\uce21\n    lgbm_valid_pred = model.predict(X_valid)\n        \n    lgbm_oof_train[val_ind] = lgbm_valid_pred\n    print('='*80)\n    \nprint(f\"<Light-GBM> OVERALL RMSE     : {sqrt( mean_squared_error( train_label, lgbm_oof_train ) )}\")","71d6fcff":"print(f\"<Light-GBM> OVERALL RMSE     : {sqrt( mean_squared_error( train_label, lgbm_oof_train ) )}\")","5c7e1255":"train.head()","8bccde22":"# \ud574\ub2f9 \ub515\uc154\ub108\ub9ac\uc5d0 bus_route_id \ubcc4 \uc815\ucc28 \uc21c\uc11c\ub97c \uad6c\ud558\ub3c4\ub85d \ud568\nbus_route_sequence = {}\n\n# \ubaa8\ub4e0 bus_route_id \uc218\uc9d1\ncombined = train.append(test, ignore_index=True)\nall_bus_route_ids = set(combined['bus_route_id'])\n\nfor bus_route_id in tqdm_notebook( all_bus_route_ids ) :\n    # bus_route_id\ubcc4 station_code\ub97c \uc624\ub984\ucc28\uc21c\uc73c\ub85c \uc21c\uc11c\ub9e4\uae40\ud568\n    df_bus_route = combined[combined['bus_route_id']==bus_route_id]\n    sorted_station_codes = np.unique(df_bus_route['station_code'])\n    \n    # dictionary\uc5d0 \ud574\ub2f9 \uc815\ub958\uc7a5\uc774 \uba87\ubc88\uc9f8 \uc815\ucc28 \uc815\ub958\uc7a5\uc778\uc9c0 \uae30\uc785\n    bus_route_sequence[bus_route_id] = {station_code: ind for ind, station_code in enumerate( list(sorted_station_codes) )}","620fb1cd":"# \uba87 \ubc88\uc9f8 \uc815\ub958\uc7a5\uc778\uc9c0\ub97c \ud53c\uccd0\ub85c \uc0dd\uc131\ntrain['nth_station']= train[['bus_route_id','station_code']].apply(lambda x: bus_route_sequence.get(x[0]).get(x[1]), axis=1)\ntest['nth_station'] = test[['bus_route_id','station_code']].apply(lambda x: bus_route_sequence.get(x[0]).get(x[1]), axis=1)","3e778b9f":"# \ud574\ub2f9 bus_route_id\uc5d0\ub294 \uba87 \uac1c\uc758 \uc815\ub958\uc7a5\uc774 \uc788\ub294\uc9c0\nbus_route_id_total_station_count_dict = combined.groupby('bus_route_id')['station_code'].nunique().to_dict()\n\ntrain['bus_route_id_total_staion_count'] = train['bus_route_id'].apply(lambda x: bus_route_id_total_station_count_dict.get(x) )\ntest['bus_route_id_total_staion_count']  = test['bus_route_id'].apply(lambda x: bus_route_id_total_station_count_dict.get(x) )","459f5773":"# \ub4a4\uc5d0\uc11c\ubd80\ud130 \uba87 \ubc88\uc9f8 \uc815\ub958\uc815\uc778\uc9c0\ntrain['nth_station_backward']= train['nth_station'] - train['bus_route_id_total_staion_count']\ntest['nth_station_backward'] = test['nth_station'] - test['bus_route_id_total_staion_count']","991df052":"# \uac01 \ubaa8\ub378\uc5d0 \ub300\ud55c oof \uc815\uc758\nlgbm_oof_train = np.zeros((train.shape[0]))\n\n# Kfold \uc815\uc758\nkfolds = KFold(n_splits=n_splits, random_state=1993, shuffle=True)\n\n# Fold\ubcc4\ub85c \ud559\uc2b5\uc9c4\ud589\nfor ind, (trn_ind, val_ind) in tqdm_notebook( enumerate( kfolds.split( X = train, y = train_label ) ) ):\n    \n    # Train\/Valid-set\uc744 \uc815\uc758\ud558\uae30\n    X_train , y_train = train.iloc[trn_ind].drop(drop_cols, 1), train_label[trn_ind]\n    X_valid , y_valid = train.iloc[val_ind].drop(drop_cols, 1), train_label[val_ind]\n    \n    # Target- Mean Encoding\n    X_train['label'] = y_train\n    d = X_train.groupby(['station_code'])['label'].mean().to_dict()\n    X_train['station_code_te'] = X_train['station_code'].apply(lambda x: d.get(x))\n    X_valid['station_code_te'] = X_valid['station_code'].apply(lambda x: d.get(x))\n    \n    X_train= X_train.drop('label',1)\n    \n    \n    # (5) Light GBM\n    print(\"---TRAINING LIGHT GBM---\")\n    # dtrain\/dvalid \uc815\uc758\n    dtrain = lgbm.Dataset(X_train, y_train)\n    dvalid = lgbm.Dataset(X_valid, y_valid)\n    \n    # model \uc815\uc758&\ud559\uc2b5\n    model = lgbm.train(lgbm_param , dtrain, NUM_BOOST_ROUND, \n                       valid_sets=(dtrain, dvalid), \n                       valid_names=('train','valid'), \n                       categorical_feature= ['bus_route_id','station_code'],\n                       verbose_eval= 100)\n    \n    # local_valid\/local_test\uc5d0 \ub300\ud55c \uc608\uce21\n    lgbm_valid_pred = model.predict(X_valid)\n        \n    lgbm_oof_train[val_ind] = lgbm_valid_pred\n    print('='*80)\n    \nprint(f\"<Light-GBM> OVERALL RMSE     : {sqrt( mean_squared_error( train_label, lgbm_oof_train ) )}\")","c4284720":"# \uc911\ubcf5\ub418\uc9c0 \uc54a\ub294 \uc704\uacbd\ub3c4 \uac12\ub4e4\uc744 \uc218\uc9d1\ud568\ncombined = train[['latitude','longitude']].append(test[['latitude','longitude']])\ncombined = combined.drop_duplicates()\n\n# kmeans\ub97c \ud1b5\ud558\uc5ec \uad70\uc9d1\ud654\nkmeans = KMeans(n_clusters= int(sqrt(len(combined)) ), random_state=1993)\nkmeans.fit( combined )\n\ntrain['station_code_kmeans'] = kmeans.predict(train[['latitude','longitude']])\ntest['station_code_kmeans']  = kmeans.predict(test[['latitude','longitude']])","4f101ff0":"# \uac01 \ubaa8\ub378\uc5d0 \ub300\ud55c oof \uc815\uc758\nlgbm_oof_train = np.zeros((train.shape[0]))\n\n# Kfold \uc815\uc758\nkfolds = KFold(n_splits=n_splits, random_state=1993, shuffle=True)\n\n# Fold\ubcc4\ub85c \ud559\uc2b5\uc9c4\ud589\nfor ind, (trn_ind, val_ind) in tqdm_notebook( enumerate( kfolds.split( X = train, y = train_label ) ) ):\n    \n    # Train\/Valid-set\uc744 \uc815\uc758\ud558\uae30\n    X_train , y_train = train.iloc[trn_ind].drop(drop_cols, 1), train_label[trn_ind]\n    X_valid , y_valid = train.iloc[val_ind].drop(drop_cols, 1), train_label[val_ind]\n    \n    # Target- Mean Encoding\n    X_train['label'] = y_train\n    d = X_train.groupby(['station_code'])['label'].mean().to_dict()\n    X_train['station_code_te'] = X_train['station_code'].apply(lambda x: d.get(x))\n    X_valid['station_code_te'] = X_valid['station_code'].apply(lambda x: d.get(x))\n    \n    X_train= X_train.drop('label',1)\n    \n    \n    # (5) Light GBM\n    print(\"---TRAINING LIGHT GBM---\")\n    # dtrain\/dvalid \uc815\uc758\n    dtrain = lgbm.Dataset(X_train, y_train)\n    dvalid = lgbm.Dataset(X_valid, y_valid)\n    \n    # model \uc815\uc758&\ud559\uc2b5\n    model = lgbm.train(lgbm_param , dtrain, NUM_BOOST_ROUND, \n                       valid_sets=(dtrain, dvalid), \n                       valid_names=('train','valid'), \n                       categorical_feature= ['bus_route_id','station_code', 'station_code_kmeans'],\n                       verbose_eval= 100)\n    \n    # local_valid\/local_test\uc5d0 \ub300\ud55c \uc608\uce21\n    lgbm_valid_pred = model.predict(X_valid)\n        \n    lgbm_oof_train[val_ind] = lgbm_valid_pred\n    print('='*80)\n    \nprint(f\"<Light-GBM> OVERALL RMSE     : {sqrt( mean_squared_error( train_label, lgbm_oof_train ) )}\")","1d29c1a2":"lgbm_param = {'objective': 'rmse',\n             'boosting_type': 'gbdt',\n             'random_state': 1993,\n             'learning_rate': 0.1,\n             'subsample': 0.7,\n             'tree_learner': 'serial',\n             'colsample_bytree': 0.78,\n#              'early_stopping_rounds': 50,\n             'subsample_freq': 1,\n             'reg_lambda': 7,\n             'reg_alpha': 5,\n             'num_leaves': 96,\n             'seed': 1993}","6d061d89":"reg_model = lgbm.LGBMRegressor(**lgbm_param)\nrfe = RFECV(estimator=reg_model, step=1, cv=KFold(n_splits=5, shuffle=False, random_state=231), scoring='neg_mean_squared_error', verbose=2)\nrfe.fit(train.drop(drop_cols,1), train_label)","9de51a06":"df_rank = pd.DataFrame(data = {'col': list(train.drop(drop_cols,1)) , 'imp': rfe.ranking_})\nuse_cols = list(df_rank[df_rank['imp']==1]['col'])","912490a4":"lgbm_param = {'objective': 'rmse',\n             'boosting_type': 'gbdt',\n             'random_state': 1993,\n             'learning_rate': 0.1,\n             'subsample': 0.7,\n             'tree_learner': 'serial',\n             'colsample_bytree': 0.78,\n             'early_stopping_rounds': 50,\n             'subsample_freq': 1,\n             'reg_lambda': 7,\n             'reg_alpha': 5,\n             'num_leaves': 96,\n             'seed': 1993}","0110fe4d":"# \uac01 \ubaa8\ub378\uc5d0 \ub300\ud55c oof \uc815\uc758\nlgbm_oof_train = np.zeros((train.shape[0]))\n\n# Kfold \uc815\uc758\nkfolds = KFold(n_splits=n_splits, random_state=1993, shuffle=True)\n\n# Fold\ubcc4\ub85c \ud559\uc2b5\uc9c4\ud589\nfor ind, (trn_ind, val_ind) in tqdm_notebook( enumerate( kfolds.split( X = train, y = train_label ) ) ):\n    \n    # Train\/Valid-set\uc744 \uc815\uc758\ud558\uae30\n    X_train , y_train = train.iloc[trn_ind].drop(drop_cols, 1), train_label[trn_ind]\n    X_valid , y_valid = train.iloc[val_ind].drop(drop_cols, 1), train_label[val_ind]\n    \n    # Target- Mean Encoding\n    X_train['label'] = y_train\n    d = X_train.groupby(['station_code'])['label'].mean().to_dict()\n    X_train['station_code_te'] = X_train['station_code'].apply(lambda x: d.get(x))\n    X_valid['station_code_te'] = X_valid['station_code'].apply(lambda x: d.get(x))\n    \n    X_train= X_train.drop('label',1)\n    \n    \n    # (5) Light GBM\n    print(\"---TRAINING LIGHT GBM---\")\n    # dtrain\/dvalid \uc815\uc758\n    dtrain = lgbm.Dataset(X_train[use_cols], y_train)\n    dvalid = lgbm.Dataset(X_valid[use_cols], y_valid)\n    \n    # model \uc815\uc758&\ud559\uc2b5\n    model = lgbm.train(lgbm_param , dtrain, NUM_BOOST_ROUND, \n                       valid_sets=(dtrain, dvalid), \n                       valid_names=('train','valid'), \n                       categorical_feature= ['bus_route_id','station_code', 'station_code_kmeans'],\n                       verbose_eval= 100)\n    \n    # local_valid\/local_test\uc5d0 \ub300\ud55c \uc608\uce21\n    lgbm_valid_pred = model.predict(X_valid[use_cols])\n        \n    lgbm_oof_train[val_ind] = lgbm_valid_pred\n    print('='*80)\n    \nprint(f\"<Light-GBM> OVERALL RMSE     : {sqrt( mean_squared_error( train_label, lgbm_oof_train ) )}\")","df4a5a7a":"# \ubaa8\ub378\uc5d0 \uc4f0\uc77c parameter \uc815\uc758\ud558\uae30\nn_splits= 5\nNUM_BOOST_ROUND = 100000\nSEED = 1993\nlgbm_param = {'objective':'rmse',\n              'boosting_type': 'gbdt',\n              'random_state':1993,\n              'learning_rate':0.01,\n              'subsample':0.7,\n              'tree_learner': 'serial',\n              'colsample_bytree':0.68,\n              'early_stopping_rounds':50,\n              'subsample_freq': 1,\n              'reg_lambda':7,\n              'reg_alpha': 5,\n              'num_leaves': 96,\n              'seed' : SEED\n            }\n\nn_rounds = 100000\ncat_params = {\n        'n_estimators': n_rounds,\n        'learning_rate': 0.08,\n        'eval_metric': 'RMSE',\n        'loss_function': 'RMSE',\n        'random_seed': 42,\n        'metric_period': 500,\n        'od_wait': 500,\n        'task_type': 'GPU',\n       'l2_leaf_reg' : 3,\n        'depth': 8,\n    }","e61e5426":"target_col = '18~20_ride'\ndrop_cols = ['date','id',target_col]\ntrain_label = train[target_col]","2867faa4":"# \ud615\uc2dd\uc744 \ub9de\ucdb0\uc8fc\uae30 \uc704\ud574\uc11c Test-set\uc5d0 '18~20_ride' columns\uc744 \ub9cc\ub4e4\uc5b4\uc90c\ntest[target_col] = np.NaN","98204bdd":"# \uac01 \ubaa8\ub378\uc5d0 \ub300\ud55c oof \uc815\uc758\nlgbm_oof_train = np.zeros((train.shape[0]))\nlgbm_oof_test = np.zeros((test.shape[0]))\n\n# Kfold \uc815\uc758\nkfolds = KFold(n_splits=n_splits, random_state=1993, shuffle=True)\n\n\n# Fold\ubcc4\ub85c \ud559\uc2b5\uc9c4\ud589\nfor ind, (trn_ind, val_ind) in tqdm_notebook( enumerate( kfolds.split( X = train, y = train_label ) ) ):\n    \n    # Train\/Valid-set\uc744 \uc815\uc758\ud558\uae30\n    X_train , y_train = train.iloc[trn_ind].drop(drop_cols, 1), train_label[trn_ind]\n    X_valid , y_valid = train.iloc[val_ind].drop(drop_cols, 1), train_label[val_ind]\n    \n    # Target- Mean Encoding\n    X_train['label'] = y_train\n    d = X_train.groupby(['station_code'])['label'].mean().to_dict()\n    X_train['station_code_te'] = X_train['station_code'].apply(lambda x: d.get(x))\n    X_valid['station_code_te'] = X_valid['station_code'].apply(lambda x: d.get(x))\n    test['station_code_te'] = test['station_code'].apply(lambda x: d.get(x))\n    \n    X_train= X_train.drop('label',1)\n    \n    \n    # (5) Light GBM\n    print(\"---TRAINING LIGHT GBM---\")\n    # dtrain\/dvalid \uc815\uc758\n    dtrain = lgbm.Dataset(X_train, y_train)\n    dvalid = lgbm.Dataset(X_valid, y_valid)\n    \n    # model \uc815\uc758&\ud559\uc2b5\n    model = lgbm.train(lgbm_param , dtrain, NUM_BOOST_ROUND, \n                       valid_sets=(dtrain, dvalid), \n                       valid_names=('train','valid'), \n                       categorical_feature= ['bus_route_id','station_code', 'station_code_kmeans'],\n                       verbose_eval= 100)\n    \n    # local_valid\/local_test\uc5d0 \ub300\ud55c \uc608\uce21\n    lgbm_valid_pred = model.predict(X_valid)\n    lgbm_test_pred = model.predict(test.drop(drop_cols, 1))\n        \n    lgbm_oof_train[val_ind] = lgbm_valid_pred\n    lgbm_oof_test += lgbm_test_pred\/ n_splits\n    print('='*80)\n    \nprint(f\"<Light-GBM> OVERALL RMSE     : {sqrt( mean_squared_error( train_label, lgbm_oof_train ) )}\")","f0bb94e1":"# \uac01 \ubaa8\ub378\uc5d0 \ub300\ud55c oof \uc815\uc758\ncat_oof_train = np.zeros((train.shape[0]))\ncat_oof_test = np.zeros((test.shape[0]))\n\n# Kfold \uc815\uc758\nkfolds = KFold(n_splits=n_splits, random_state=1993, shuffle=True)\n\n\n# Fold\ubcc4\ub85c \ud559\uc2b5\uc9c4\ud589\nfor ind, (trn_ind, val_ind) in tqdm_notebook( enumerate( kfolds.split( X = train, y = train_label ) ) ):\n    \n    # Train\/Valid-set\uc744 \uc815\uc758\ud558\uae30\n    X_train , y_train = train.iloc[trn_ind].drop(drop_cols, 1), train_label[trn_ind]\n    X_valid , y_valid = train.iloc[val_ind].drop(drop_cols, 1), train_label[val_ind]\n    \n    # Target- Mean Encoding\n    X_train['label'] = y_train\n    d = X_train.groupby(['station_code'])['label'].mean().to_dict()\n    X_train['station_code_te'] = X_train['station_code'].apply(lambda x: d.get(x))\n    X_valid['station_code_te'] = X_valid['station_code'].apply(lambda x: d.get(x))\n    test['station_code_te'] = test['station_code'].apply(lambda x: d.get(x))\n    \n    X_train= X_train.drop('label',1)\n    \n    \n    # (5) CATBOOST\n    print(\"---TRAINING CATBOOST---\")\n    \n    # model \uc815\uc758&\ud559\uc2b5\n    model = CatBoostRegressor(**cat_params)\n    \n    model.fit( X_train, y_train, eval_set = (X_valid, y_valid), \n              cat_features  = ['bus_route_id','station_code', 'station_code_kmeans'],\n              use_best_model=True,\n              verbose=True)\n    \n    # local_valid\/local_test\uc5d0 \ub300\ud55c \uc608\uce21\n    cat_valid_pred = model.predict(X_valid)\n    cat_test_pred = model.predict(test.drop(drop_cols, 1))\n        \n    cat_oof_train[val_ind] = cat_valid_pred\n    cat_oof_test += cat_test_pred\/ n_splits\n    print('='*80)\n    \nprint(f\"<CATBOOST> OVERALL RMSE     : {sqrt( mean_squared_error( train_label, cat_oof_train ) )}\")","e4ca6d3c":"# \uc81c\ucd9c \ud30c\uc77c \ub9cc\ub4e4\uae30\nensemble_pred = 0.5 * ( lgbm_oof_test+ cat_oof_test )\nsample_submission[target_col] = np.clip( ensemble_pred, 0 , max(ensemble_pred) )","8b3f0a0c":"# Train-set\uc758 \uc2e4\uc81c\uac12\uacfc \uc608\uce21\uac12 \ube44\uad50\nplt.figure(figsize=(12,6))\n\nsns.distplot( train_label, color='r' , label='real')\nsns.distplot( 0.5*(lgbm_oof_train + cat_oof_train), color='b', label='prediction' )\nplt.legend()\nplt.title(\"Real Vs Prediction\");\n","dc28de4b":"# Train-set\/Test-set\uc758  \uc608\uce21\uac12 \ube44\uad50\nplt.figure(figsize=(12,6))\n\nsns.distplot( 0.5*(lgbm_oof_train + cat_oof_train), color='r' , label='Train')\nsns.distplot( ensemble_pred, color='b', label='Test' )\nplt.legend()\nplt.title(\"Prediction for Train\/Test-set\");\n","eb826c03":"from IPython.display import FileLink\n\nsample_submission.to_csv('lgbm_catboost_ensemble.csv', index=False)","ea597a27":"FileLink('lgbm_catboost_ensemble.csv')","56befe2a":"#### (2) date\uc5d0 \ucc28\uc774\uac00 \uc788\ub294\uac00?\n\n--> \ub9de\ub2e4. \uc804\uccb4 \ub370\uc774\ud130\ub294 \uc2dc\uac04\uc744 \uae30\uc900\uc73c\ub85c Train\/Test-set\uc73c\ub85c \ub098\ub258\uc5b4\uc84c\ub2e4.\n\n- 2019-09-01 ~ 2019-09-30\uc5d0 \ud574\ub2f9\ud558\ub294 \ub370\uc774\ud130\ub294 Train-set\n- 2019-10-01 ~ 2019-10-16\uc5d0 \ud574\ub2f9\ud558\ub294 \ub370\uc774\ud130\ub294 Test-set","0d5e7a1c":"## Load Dataset\n\n\uc8fc\ucd5c \uce21\uc5d0\uc11c \uc81c\uacf5\ud55c \ub370\uc774\ud130\ub97c \ud655\uc778 & Load \ud569\ub2c8\ub2e4.","e9e7703a":"#### station_code\ub294 \uc5b4\ub5a8\uae4c?\n\n--> \uc801\ud569\ud558\ub2e4\uace0 \uc0dd\uac01\ub41c\ub2e4.\n\n\ub530\ub77c\uc11c \"\ud2b9\uc815 \ub0a0\uc9dc\"\uc5d0 \"\ud2b9\uc815 \ubc84\uc2a4 \ub178\uc120\"\uc758 \"\ud2b9\uc815 \uc815\uac70\uc7a5\"\uc5d0\uc11c \"\uba87 \uba85\uc758 \uc2b9\uac1d\uc774 \uc2b9\ud558\ucc28\ud588\ub294\uc9c0\"\ub97c \ud30c\uc545\ud558\uae30 \uc704\ud574\uc120\n`date, bus_route_id, station_code`\ub85c \uadf8\ub8f9\ud654\ub97c \uc2dc\ucf1c\uc11c \ud30c\uc545\ud574\uc57c \ud55c\ub2e4.","c9d93bd1":"### PDP PLOT\n\n\ub2e4\uc74c\uc73c\ub85c PDP(Partial Dependency Plot)\uc744 \ud1b5\ud558\uc5ec \ud2b9\uc815 \uce7c\ub7fc\uc758 \uac12\uc774 \ubcc0\ud560 \ub54c Target Variable\uc774 \uc5b4\ub5a4 \uc2dd\uc73c\ub85c \uc601\ud5a5\uc744 \ubc1b\ub294\uc9c0 \uc0b4\ud3b4\ubcf4\ub3c4\ub85d \ud569\uc2dc\ub2e4.","5c6829cb":"### \ub0a0\uc9dc\n\n- \uc694\uc77c \uc815\ubcf4\n    - \ud3c9\uc77c\uacfc \uc8fc\ub9d0\uc758 \uc2b9\ud558\ucc28 \ud328\ud134\uc774 \ub2e4\ub974\uc9c0 \uc54a\uc744\uae4c?\n        - \ucd08\uc911\uace0 \uadfc\ucc98 \uc815\ub958\uc7a5\uc740 \uc8fc\ub9d0\uc758 \ud558\ucc28 \uc2b9\uac1d \uc218\uac00 \uae09\uaca9\ud788 \uc904\uc5b4\ub4e4 \uac83\n        - \uac19\uc740 \uc8fc\uc911\uc774\ub77c\uace0 \ud560\uc9c0\ub77c\ub3c4 \uae08\uc694\uc77c \ubc24\uc758 \ud328\ud134\uc740 \ub2e4\ub974\uc9c0 \uc54a\uc744\uae4c?\n    - \uacf5\ud734\uc77c \uc815\ubcf4\n        - \ucd94\uc11d\uc758 \uc601\ud5a5\uc740?\n        - 10\uc6d4\uc5d0\ub294 2\uac1c\uc758 \uacf5\ud734\uc77c\uc774 \uc874\uc7ac\ud568(\uac1c\ucc9c\uc808, \ud55c\uae00\ub0a0)\n            - \uac19\uc740 \uc815\ub3c4\uc758 \ud734\uc77c\uc774\ub77c\uace0 \ud560 \uc218 \uc788\uc744\uae4c?\n    - \ub0a0\uc528 \uc815\ubcf4\n    - \uc2dc\uac04\ub300\ubcc4\ub85c \uc2b9\uac1d\ub4e4\uc774 \uc5bc\ub9c8\ub098 \ubc84\uc2a4\ub97c \uc774\uc6a9\ud558\uc600\ub294\uac00?(\uc624\uc804\uc758 \uc2b9\ud558\ucc28 \ud328\ud134 - Mean Encoding \/ \ud1f4\uadfc \uc2dc\uac04\uc758 \ud558\ucc28 \ud328\ud134 - Target Mean Encoding)\n","b5ca523a":"### 4. Target Variable\uc758 \ubd84\ud3ec\ub294?","d89b2ebc":"## Import library \n\n\ud544\uc694\ud55c library\ub97c \uc218\uc9d1\ud569\ub2c8\ub2e4.","40b7eac0":"### 3. Missing Value\ub294 \uc874\uc7ac\ud558\ub294\uac00?\n\n--> \uc874\uc7ac\ud558\uc9c0 \uc54a\ub294\ub2e4","a71a6dea":"#### 1. \uac19\uc740 \uc815\ub958\uc7a5 \uc774\ub984\uc774 \uc5ec\ub7ec \ubc88 \ub098\uc624\ub294 \uacbd\uc6b0?","8c92476c":"## \uc5d4\ud2f0\ud2f0 \uac1c\ub150\uc744 \ud65c\uc6a9\ud55c \ud53c\uccd0 \uc0dd\uc131\n\n- \ubc84\uc2a4 \ub178\uc120\n    - \uc2dc\uac04\ub300\ubcc4\ub85c \uc2b9\uac1d\ub4e4\uc774 \uc5bc\ub9c8\ub098 \ubc84\uc2a4\ub97c \uc774\uc6a9\ud558\uc600\ub294\uac00?(\uc624\uc804\uc758 \uc2b9\ud558\ucc28 \ud328\ud134 - Target Mean Encoding)\n    - \ub0a0\uc9dc\ubcc4\ub85c \uc624\uc804 \uc2dc\uac04 \uc2b9\uac1d\ub4e4\uc774 \uc5bc\ub9c8\ub098 \ubc84\uc2a4\ub97c \uc774\uc6a9\ud558\uc600\ub294\uac00?\n- \ubc84\uc2a4 \n    - \ubc30\ucc28\uc2dc\uac04\n- \uc2b9\uac1d\n    - \uc2b9\ud558\ucc28\ub97c 1\uc2dc\uac04 \ub2e8\uc704\ub85c \ud574\uc57c\ud558\ub294\uac00?\n- \uc815\ub958\uc7a5\n    - \uc815\ub958\uc7a5\uc758 \uc21c\uc11c \n    - \ud2b9\uc815 \uc815\ub958\uc7a5\uc774 \ub370\uc774\ud130\uc5d0 \uc5bc\ub9c8\ub098 \uc790\uc8fc \ub4f1\uc7a5\ud558\uc600\ub294\uac00?(\uace0\uc815\uc801\uc73c\ub85c \ud0c0\ub294 \uc2b9\uac1d\uc774 \uc788\ub294\uac00 - Frequency Encoding)\n    - \uc9c0\uc5ed\uc801 \ud2b9\uc131(\uc0c1\uc5c5 \uc9c0\uad6c, \uc8fc\uac70 \uc9c0\uad6c, \ud559\uc6d0\uac00)\ub4f1\uc758 \ud2b9\uc9d5\uc744 \ud30c\uc545\ud560 \uc218 \uc788\ub294\uac00?\n        - \ucd9c\uadfc \uc2dc\uac04\uc5d0 \uc2b9\ucc28\uac00 \ub9ce\uace0 \ud1f4\uadfc \uc2dc\uac04\uc5d0 \ud558\ucc28\uac00 \ub9ce\ub2e4\uba74? -> \uc8fc\uac70\uc9c0\uad6c\n        - \ucd9c\uadfc \uc2dc\uac04\uc5d4 \ud558\ucc28 \ub0b4\uc5ed\uc774 \ub9ce\uace0 \ud1f4\uadfc \uc2dc\uac04\uc5d0 \uc2b9\ucc28\uac00 \ub9ce\ub2e4\uba74? -> \ud559\uad50, \uc9c1\uc7a5 \uadfc\ucc98 \uc0ac\ubb34 \uc9c0\uad6c\n- \ud2b9\uc815 \ub0a0\uc9dc\n    - \uc694\uc77c \uc815\ubcf4\n        - \ud3c9\uc77c\uacfc \uc8fc\ub9d0\uc758 \uc2b9\ud558\ucc28 \ud328\ud134\uc774 \ub2e4\ub974\uc9c0 \uc54a\uc744\uae4c?\n            - \ucd08\uc911\uace0 \uadfc\ucc98 \uc815\ub958\uc7a5\uc740 \uc8fc\ub9d0\uc758 \ud558\ucc28 \uc2b9\uac1d \uc218\uac00 \uae09\uaca9\ud788 \uc904\uc5b4\ub4e4 \uac83\n            - \uac19\uc740 \uc8fc\uc911\uc774\ub77c\uace0 \ud560\uc9c0\ub77c\ub3c4 \uae08\uc694\uc77c \ubc24\uc758 \ud328\ud134\uc740 \ub2e4\ub974\uc9c0 \uc54a\uc744\uae4c?\n    - \uacf5\ud734\uc77c \uc815\ubcf4\n        - \ucd94\uc11d\uc758 \uc601\ud5a5\uc740?\n        - 10\uc6d4\uc5d0\ub294 2\uac1c\uc758 \uacf5\ud734\uc77c\uc774 \uc874\uc7ac\ud568(\uac1c\ucc9c\uc808, \ud55c\uae00\ub0a0)\n            - \uac19\uc740 \uc815\ub3c4\uc758 \ud734\uc77c\uc774\ub77c\uace0 \ud560 \uc218 \uc788\uc744\uae4c?\n    - \ub0a0\uc528 \uc815\ubcf4\n    - \uc2dc\uac04\ub300\ubcc4\ub85c \uc2b9\uac1d\ub4e4\uc774 \uc5bc\ub9c8\ub098 \ubc84\uc2a4\ub97c \uc774\uc6a9\ud558\uc600\ub294\uac00?(\uc624\uc804\uc758 \uc2b9\ud558\ucc28 \ud328\ud134 - Mean Encoding \/ \ud1f4\uadfc \uc2dc\uac04\uc758 \ud558\ucc28 \ud328\ud134 - Target Mean Encoding)\n- \uc81c\uc8fc\ub3c4   ","f351e523":"## \ub370\uc774\ud130 \uc774\ud574\ud558\uae30\n\n1. \ub370\uc774\ud130\uc758 \uc0ac\uc774\uc988\ub294 ?\n 1.1 \ubaa8\ub378 \ud559\uc2b5\uc5d0 \uc801\ud569\ud55c \ud615\ud0dc\uc778\uac00?\n2. Train\/Test\ub294 \uc5b4\ub5bb\uac8c \ubd84\ub9ac\ub418\uc5b4 \uc788\ub294\uac00?\n3. Missing Value\ub294?\n4. Target Variable\uc758 \ubd84\ud3ec\ub294?\n5. \ub370\uc774\ud130\uc758 \ud2b9\uc774\ud55c\/\uc8fc\ubaa9\ud574\uc57c\ud560 \ubd80\ubd84\uc740?","3b4e7711":"## \ubaa8\ub378 \ud559\uc2b5\uc5d0 \uc788\uc5b4 \uc911\uc694\ud55c \ud53c\uccd0\ub294 \ubb34\uc5c7\uc778\uac00?!","765b323a":"#### (1) id\uc5d0 \ucc28\uc774\uac00 \uc788\ub294\uac00?\n\n--> id\ub294 Train\/Test-set \uac01\uac01\uc758 key\ub85c \uc0ac\uc6a9\ub428. \ud2b9\ubcc4\ud55c \uc758\ubbf8\ub97c \uc9c0\ub2c8\uc9c0 \uc54a\uace0 \ud14c\uc774\ube14\uc758 \uac01 row\ub97c \uad6c\ubd84\uc9d3\ub294\ub370\ub9cc \uc0ac\uc6a9\ub418\uae30\uc5d0 \ubaa8\ub378\ub9c1 \uc2dc \uc81c\uac70\ud574\uc918\uc57c\ud558\ub294 column","ac07ba5c":"#### 1.1 \uace0\uc720\ud55c \uc815\uac70\uc7a5\uc758 \uae30\uc900\uc740?\n\n\ub2e4\uc74c\uc73c\ub85c `\uace0\uc720\ud55c \uc815\uac70\uc7a5`\uc744 \uc5b4\ub5bb\uac8c \ubd84\ub9ac\ud560 \uc218 \uc788\ub294\uc9c0 \uc54c\uc544\ubcf4\ub3c4\ub85d \ud558\uaca0\uc2b5\ub2c8\ub2e4.\n\n\uba3c\uc800 `\uace0\uc720\ud55c \uc815\uac70\uc7a5`\uc740 \uc544\ub798\uc640 \uac19\uc740 \uc870\uac74\uc744 \ub9cc\uc871\ud574\uc57c\ud55c\ub2e4\uace0 \uc0dd\uac01\ud569\ub2c8\ub2e4.\n    1. \uc704\uacbd\ub3c4\uac00 1\uac1c\uc5ec\uc57c\ud55c\ub2e4.\n    2. \uc2dc\ub0b4\ubc84\uc2a4 \ud639\uc740 \uc2dc\ub0b4\ubc84\uc2a4 1\uac1c\uc758 \ub178\uc120\ub9cc \uc788\uc5b4\uc57c \ud55c\ub2e4.\n    3. \ud2b9\uc815 \ub0a0\uc9dc\uc5d0 \ud2b9\uc815 \ub178\uc120\uc5d0\uc11c \ud2b9\uc815 \uc815\uac70\uc7a5\uc758 \uc2b9\uac1d \uc218\ub97c \uae30\ub85d\ud55c row\ub294 1\uac1c\uc5ec\uc57c \ud55c\ub2e4.","764f11c5":"## BASELINE MODEL \ub9cc\ub4e4\uae30\n\n\uc544\ub798\uc640 \uac19\uc740 \ubaa8\ub378\ub4e4\uc744 \ub9cc\ub4e4\uc5b4\ubcf4\uace0, \uc5b4\ub5a4 \ud0c0\uc785\uc758 \ubaa8\ub378\uc774 \ubcf8 \ubb38\uc81c\ub97c \ud480\uae30 \uc801\ud569\ud55c\uac00 \uc0b4\ud3b4\ubcf4\ub3c4\ub85d \ud558\uc790.\n\ucd94\uac00\uc801\uc73c\ub85c linear model\uc5d0\uc11c\ub294 coefficient\ub97c \ud1b5\ud558\uc5ec, tree-based model\uc5d0\uc11c\ub294 feature_importance\ub97c \ud1b5\ud558\uc5ec \ubcc0\uc218\uc758 \uc911\uc694\ub3c4\ub97c \uc0b4\ud3b4\ubcf4\uba70,\n\ud5a5\ud6c4 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ub192\uc774\uae30 \uc704\ud574\uc120 \uc5b4\ub5a4 \ubc29\ubc95\uc774 \uc788\uc744\uae4c \uc0dd\uac01\ud574\ubcf4\uc790.\n\n- Linear Regression \n    - Ridge\n    - Lasso\n- Tree-Based \n    - Decision Tree\n    - Random Forest\n    - Light GBM","be1a919d":"### linear model\n\nlinear model\uc5d0\uc11c coef\ub97c \ud1b5\ud558\uc5ec \uc5b4\ub5a4 \uce7c\ub7fc\uc758 weight\uac00 \ub192\uc740\uc9c0 \ud30c\uc545\ud560 \uc218 \uc788\ub2e4.\n\n- Ridge \n    - latitude\uc640 longitude\uc758 weight\ub97c \ud1b5\ud574\uc11c \ub3d9\ucabd\uc5d0 \uc704\uce58\ud55c \ubc84\uc2a4 \uc815\ub958\uc7a5\uc77c\uc218\ub85d \ud0d1\uc2b9 \uc2b9\uac1d\uc774 \ub9ce\uc73c\uba70, \ubd81\ucabd\uc5d0 \uc704\uce58\ud55c \ubc84\uc2a4 \uc815\ub958\uc7a5\uc77c\uc218\ub85d \ud0d1\uc2b9 \uc2b9\uac1d\uc774 \uc801\ub2e4\uace0 \ud310\ub2e8\ud55c\ub2e4.\n        -> \ub0a9\ub4dd\uc774 \uac00\uc9c0 \uc54a\ub294 \ubd80\ubd84\uc77c\uc218\ub3c4..?\n    - \ud558\ucc28 \uc2b9\uac1d \uc218 \ubcf4\ub2e4\ub294 \uc2b9\ucc28 \uc2b9\uac1d \uc218\uac00 \"\ud1f4\uadfc \uc2dc\uac04 \ud0d1\uc2b9 \uc2b9\uac1d\"\uc5d0 \ubcf4\ub2e4 \ud070 \uc601\ud5a5\uc744 \ubbf8\uce68\n    - \ucd9c\ud1f4\uadfc \uc2dc\uac04\ubcf4\ub2e4\ub294 \uc815\uc624 \uc988\uc74c \uc2b9\uac1d\uc774 \uc5bc\ub9c8\ub098 \ud0d4\ub294\uc9c0\uc5d0 \ub300\ud55c \uc815\ubcf4\uac00 \uc911\uc694\ud560 \uc218\ub3c4?\n","27c11076":"### Tree-based Model\n\n- random forest \n    - \uc120\ud615 \ubaa8\ub378\uacfc \ube44\uc2b7\ud558\uac8c \uc815\uc624 \uc988\uc74c\uc758 \ud0d1\uc2b9 \uc2b9\uac1d\uc218\uac00 \uc911\uc694\ud55c \ubcc0\uc218\ub77c\uace0 \ud310\ub2e8\n- light gbm\n    - \uac00\uc7a5 \uc88b\uc740 \uc131\ub2a5\uc744 \ubcf4\uc778 \ubaa8\ub378\n    - \uacf5\uac04\uc801 \uc815\ubcf4\ub97c \uac16\ub294 bus_route_id, station_code, station_name, latitude, longitude\uc758 \uc911\uc694\ub3c4\uac00 \ub2e4\ub978 \ubaa8\ub378\ubcf4\ub2e4 \ub192\uc740 \uac83\uc744 \ud655\uc778 \uac00\ub2a5\n    - \ud558\ucc28 \uc2b9\uac1d\uc218 \ubcf4\ub2e4\ub294 \uc2b9\ucc28 \uc2b9\uac1d\uc218\uc758 \ubcc0\uc218 \uc911\uc694\ub3c4\uac00 \ub354 \ub192\uc740 \uac83\uc73c\ub85c \ubcf4\uc784","c126288d":"####  **station_name\ub97c \uae30\uc900\uc73c\ub85c \uc0bc\ub294\ub2e4\uba74?**\n\n--> station_name\uc5d0\ub294 \uc5ec\ub7ec\uac1c\uc758  station_code\uac00 \ub9e4\ud551\ub418\uc5b4\uc788\uc74c & \uc5ec\ub7ec \uac1c\uc758 \uc704\uce58 \uc815\ubcf4\ub97c \uac16\ub294 \uac83\uc73c\ub85c \ubcf4\uc784\n\n--> \uace0\uc720\ud55c \uc815\uac70\uc7a5\uc758 \uae30\uc900\uc744 station_name\uc73c\ub85c \uc7a1\uae30\uc5d0\ub294 \uc5b4\ub824\uc6cc\ubcf4\uc784","64a1dd97":"## \uc81c\ucd9c \ud30c\uc77c \ub9cc\ub4e4\uae30","9dbc6d55":"### LightGBM\uc744 \ud1b5\ud558\uc5ec \ubaa8\ub378\ub9c1 \ud558\uae30","e56051e4":"- LOCAL_TRAIN\uc5d0 \ud574\ub2f9\ud558\ub294 \ubd80\ubd84\ubcf4\ub2e4 LOCAL_TEST\uc5d0 \ud574\ub2f9\ud558\ub294 \ubd80\ubd84\uc758 \uc608\uce21\ub825\uc774 \ub5a8\uc5b4\uc9c0\ub294 \ubaa8\uc2b5\uc744 \ubcf4\uc774\uae34 \ud55c\ub2e4.\n- \uc2e4\uc81c \uac12\ubcf4\ub2e4 \uc608\uce21 \uac12\uc774 \uc9c0\ub098\uce58\uac8c \ud070 \uacbd\uc6b0\ub4e4\uc774 \uc874\uc7ac\ud558\ub294\ub370, \ud574\ub2f9 \uacbd\uc6b0\ub4e4\uc774 \uc5b4\ub5a4 \uac83\ub4e4\uc778\uc9c0 \uc0b4\ud3b4\ubd10\uc57c\uaca0\ub2e4.\n- \uc544\ub798\uc640 \uac19\uc740 \ub2e4\ub978 validation \uae30\ubc95\ub4e4\ub3c4 \uace0\ub824\ud574\ubcfc \uc218 \uc788\uc744 \uac83\uc774\ub2e4.\n - HOLD OUT\n - GROUP FOLD BY weekofmonth \n- \ubcf8 \uac15\uc758\uc5d0\uc11c\ub294 KFOLD\ub97c \uac00\uc9c0\uace0 baseline model\uc744 \ub9cc\ub4e4\uc5b4 \ubcf4\uae30\ub85c \ud55c\ub2e4.","59d80cdd":"#### 3. \uc815\ub958\uc7a5\uc5d0 \ucc28\uc774\uac00 \uc788\ub294\uac00?\n\n--> \ud070 \ucc28\uc774\ub294 \uc5c6\ub2e4. \n\n\ub2e4\ub9cc,\n- Train-set\uc5d0\ub294 \uc788\uc9c0\ub9cc, Test-set\uc5d0\ub294 \uc5c6\ub294 bus_route_id\uac00 30\uac1c \uc874\uc7ac\ud558\uba70\n- Test-set\uc5d0\ub294 \uc788\uc9c0\ub9cc,  Train-set\uc5d0\ub294 \uc5c6\ub294 bus_route_id\uac00 18\uac1c \uc874\uc7ac\ud55c\ub2e4.\n\nTrain-set\uc5d0 \ub4f1\uc7a5\ud558\uc9c0 \uc54a\uc73c\ub098, Test-set\uc5d0 \ub4f1\uc7a5\ud558\ub294 \uacbd\uc6b0 \ubaa8\ub378\uc740 \ud559\uc2b5\ub418\uc9c0 \uc54a\uc740 \ub370\uc774\ud130\ub97c \uac00\uc9c0\uace0 \uc608\uce21\uc744 \ud574\uc57c\ud558\ub294 \ubb38\uc81c\uac00 \uc788\ub2e4.\n\n\ud574\ub2f9 \ubd80\ubd84\ub4e4\uc744 \uc5b4\ub5bb\uac8c \ubcf4\uc644\ud560 \uc9c0 \uc0dd\uac01\ubcf4\ub294 \uac83\ub3c4 \uc88b\uc744 \ub4ef\ud558\ub2e4.\n\n--> \uc544\ub798\uc5d0\uc11c \ud655\uc778\ud560 \uc218 \uc788\ub4ef\uc774, Test-set\uc5d0\ub9cc \ub4f1\uc7a5\ud558\ub294 bus_route_id\ub294 Train\/Test-set \ubaa8\ub450\uc5d0 \ub4f1\uc7a5\ud558\ub294 bus_route_id\ubcf4\ub2e4 \ud3c9\uade0 \ud0d1\uc2b9\uc2b9\uac1d\uc218\uac00 \uc801\uc740 \uacbd\ud5a5\uc774 \uc788\ub294 \ub4ef\uc774 \ubcf4\uc778\ub2e4.\n\n--> \ud574\uacb0\ucc45 \uc911 \ud558\ub098\ub85c, Train-set\uae30\uac04\ub3d9\uc548\uc5d0 \ud574\ub2f9 bus_route_id\uc758 \ud1f4\uadfc \uc2dc\uac04\uc758 \ud0d1\uc2b9 \uc2b9\uac1d\uc218\ub97c \"0\"\uc73c\ub85c \ub808\uc774\ube14\ub9c1\ud558\uc5ec \uc0c8\ub85c\uc6b4 row\ub97c \ucd94\uac00\ud560 \uc218 \uc788\uc744 \uac83\uc774\ub2e4.","9bfc5f40":"## \uc815\ub958\uc7a5\n\n- Kmeans\ub4f1\uc744 \uc774\uc6a9\ud558\uc5ec \uc815\ub958\uc7a5\uc744 \uad70\uc9d1\ud654 \uc2dc\ud0a8\ub2e4\uba74?\n- \uc704\uacbd\ub3c4 \uc88c\ud45c\ub97c \ud1b5\ud558\uc5ec \ud589\uc815\ub3d9 or \ubc95\uc815\ub3d9 \uc815\ubcf4\ub97c \uc218\uc9d1\ud560 \uc218 \uc788\ub2e4\uba74?","8bb2d5ef":"## Feature \uc120\ud0dd\/\uc81c\uac70","86259899":"### 2. Train\/Test\ub294 \uc5b4\ub5bb\uac8c \ubd84\ub9ac\ub418\uc5b4 \uc788\ub294\uac00?","e2a56973":"####  Target Variable\uc774 0\uc778 \ub370\uc774\ud130\ub294 \uc5b4\ub5a4 \ud2b9\uc9d5\uc744 \uac00\uc9c0\uace0 \uc788\ub294\uac00?\n\n--> \ud14c\uc774\ube14\uc5d0 \uc801\uc7ac\ub41c row\ub4e4\uc740 \ud574\ub2f9 \uc2b9\ucc28\/\ud558\ucc28 \uad00\ub828 \uce7c\ub7fc\ub4e4\uc758 rowsum\uc774 1\uc774\uc0c1\uc778 \ub370\uc774\ud130\n--> \ud1f4\uadfc\uc2dc\uac04\uc5d0 \uc2b9\ucc28\ud55c \uc2b9\uac1d\uc774 \uc788\ub354\ub77c\ub3c4 \uc2b9\ucc28\/\ud558\ucc28 \uad00\ub828 \uce7c\ub7fc\ub4e4\uc758 rowsum\uc774 0\uc778 \uacbd\uc6b0\ub294 \uc6b0\ub9ac\uac00 \ubcfc \uc218 \uc788\ub294 \ud14c\uc774\ube14\uc5d0 \uc801\uc7ac\ub418\uc9c0 \ubabb\ud558\uc600\ub2e4.\n\n--> \ub098\uc911\uc5d0 data-augmentation\uc744 \uc2dc\ub3c4\ud558\uace0\uc790 \ud558\ub294 \uacbd\uc6b0 \uc720\uc6a9\ud55c \uc815\ubcf4\uac00 \ub420 \uc218\ub3c4..?","9a5c9334":"### 5. \ub370\uc774\ud130\uc758 \ud2b9\uc774\ud55c\/\uc8fc\ubaa9\ud574\uc57c\ud560 \ubd80\ubd84\uc740?\n\n1. \ud574\ub2f9 \ubc84\uc2a4\uc815\ub958\uc7a5\uc5d0 \ub300\ud55c \uac01\uac01\uc758 \uc704\ub3c4, \uacbd\ub3c4\uac00 \uc81c\uacf5\uc774 \ub418\uc5b4\uc788\ub294 \uc0c1\ud0dc\ub85c \uac19\uc740 \uc815\ub958\uc7a5 \uc774\ub984\uc774\uc9c0\ub9cc \uc704\ub3c4\uc640 \uacbd\ub3c4\uac00 \uc11c\ub85c \ub2e4\ub978 \uacbd\uc6b0\uac00 \uc874\uc7ac\ud569\ub2c8\ub2e4. \ud574\ub2f9 \uacbd\uc6b0\ub294, \uac19\uc740 \uc815\ub958\uc7a5 \uc774\ub984\uc744 \uac00\uc9c0\uace0 \uc788\ub294 \uae38 \uac74\ub108\ud3b8\uc758 \uc815\ub958\uc7a5\uc5d0 \ud574\ub2f9\uc774 \ub429\ub2c8\ub2e4.\n\n1. \ud574\ub2f9 \ub370\uc774\ud130\uc5d0\ub294 \ubc84\uc2a4\uce74\ub4dc\ub97c \ud1b5\ud574 \uacb0\uc81c\ub97c \ud55c \uacbd\uc6b0\uc5d0 \ub300\ud55c \uc815\ub958\uc18c \uc2b9, \ud558\ucc28 \ub370\uc774\ud130\ub85c \ubaa8\ub4e0 \uc2b9\ucc28\uc815\ubcf4\uc758 \uacbd\uc6b0\ub294 \uae30\ub85d\uc774 \ub418\uc5b4\uc788\uc9c0\ub9cc, \ubc84\uc2a4\uc5d0\uc11c \ud558\ucc28\ub97c \ud560 \ub54c, \ubc84\uc2a4\uce74\ub4dc\ub97c \ucc0d\uc9c0 \uc54a\ub294 \uacbd\uc6b0, \ud574\ub2f9 \uae30\ub85d\uc774 \ube44\uc5b4 \uc788\ub294 \uc0c1\ud0dc\uc785\ub2c8\ub2e4. \ub530\ub77c\uc11c, \uc2b9\ucc28 \uc778\uc6d0\uc218\uc640 \ud558\ucc28 \uc778\uc6d0\uc218\uac00 \ub3d9\uc77c\ud558\uc9c0 \uc54a\uace0 \ub2e4\uc18c \ucc28\uc774\uac00 \uc788\uc74c\uc744 \ubbf8\ub9ac \uc54c\ub824\ub4dc\ub9bd\ub2c8\ub2e4.\n","26c159c4":"## Test-set \uac12 \uc608\uce21 (Ensemble)","d8bc825b":"## Validation \uc804\ub7b5\n\n\uc2dc\uac04\uc744 \uae30\uc900\uc73c\ub85c \uc55e\uc758 3\uc8fc\ub97c local_train\uc73c\ub85c, \ub4a4\uc758 1\uc8fc\ub97c local_test\ub97c \ub9cc\ub4e4\uc5b4 \ubcf8\ub2e4.\n\n1. local_train\uc744 \ud1b5\ud558\uc5ec validation \uc804\ub7b5\uc744 \uc2e4\ud5d8\ud574\ubcf4\uace0\n2. \ud574\ub2f9 \ubaa8\ub378\ub85c local_test\uc758 \uac12\uc744 \uc608\uce21\ud55c \uac12\uc774 \uc5b4\ub290\uc815\ub3c4 \ucc28\uc774\uac00 \ub098\ub294\uc9c0 \uc0b4\ud3b4\ubcf8\ub2e4.","31b1b0c2":"## \ubc84\uc2a4 \ub178\uc120\n\n- \ud574\ub2f9 \uc815\uac70\uc7a5\uc774 \ud2b9\uc815 \ub178\uc120 \uc911 \uba87 \ubc88\uc9f8 \uc815\uac70\uc7a5\uc778\uac00?\n    - \ud574\ub2f9 \uc815\uac70\uc7a5\uc5d0\ub294 \uba87 \uac1c\uc758 \uc815\uac70\uc7a5\uc774 \uc788\ub294\uac00?\n    - bus_route_id \ubcc4 station_code \uc21c\uc73c\ub85c \ubc84\uc2a4\uac00 \uc815\ucc28\ud558\ub294 \uac83\ucc98\ub7fc \ubcf4\uc784\n- \ub178\uc120\uc744 numeric type\uc73c\ub85c \ud559\uc2b5\uc2dc\ud0a4\ub294 \uac83\uc774 \uc801\ud569\ud55c\uac00?\n    - categorical vairable\ub85c \ud559\uc2b5\uc2dc\ud0a8\ub2e4\uba74?","aea3f176":"### 1. \ub370\uc774\ud130\uc758 \uc0ac\uc774\uc988\ub294?"}}