{"cell_type":{"54cf6341":"code","34d5b30d":"code","ee3b31a9":"code","136e8c10":"code","00cf73bf":"code","3449ecf3":"code","286273ee":"code","5ea10aac":"code","1a5346fa":"code","59ac99a9":"code","736fc3e0":"code","72f8f19e":"code","a0be1590":"code","299292b7":"code","33d7cb69":"code","fe9a0f19":"code","fe820085":"code","d9e2896a":"code","9ad834c7":"code","126c72ca":"code","e53e8b0e":"code","b3f421ea":"code","b6319c32":"code","a114a9fe":"markdown"},"source":{"54cf6341":"import cv2 \nimport copy\nimport math\nimport sys\nimport gc\nimport numpy as np\nimport pandas as pd\n\nimport os\nfrom os import listdir\n\nfrom matplotlib import pyplot as plt","34d5b30d":"def count_files_number(x, y, z):\n    path = x; file = y; file_1 = z\n    c = 0\n    for a in os.listdir(path + \"\/\" + file + \"\/\" + file_1):\n        c = c + 1\n    return(c)","ee3b31a9":"%%time\npath = '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train'\nnumber_of_files_Same = []\ncount_file_in_same_subfolder = []\nfor file in os.listdir(path):                                \n    temp = []\n    for file_1 in os.listdir(path + \"\/\" + file): \n        count_file_in_each_folder = count_files_number(path, file, file_1)\n        temp.append(count_file_in_each_folder)\n    if temp[0]==temp[1] and temp[0]==temp[2] and temp[0]==temp[3]:\n        number_of_files_Same.append(file)\n        count_file_in_same_subfolder.append(temp)\ncount_file_in_same_subfolder = np.array(count_file_in_same_subfolder)","136e8c10":"del temp, file, file_1, count_files_number\ngc.collect()","00cf73bf":"csv_dataframe = pd.read_csv('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train_labels.csv')\nlabel_dataframe = copy.deepcopy(csv_dataframe)\n\nlabel_dataframe.insert(1, 'With_zero', np.ones(len(label_dataframe['BraTS21ID']), dtype=str))\n\ncount = 0\nfor i in label_dataframe['BraTS21ID']:\n    if i>=0 and i<10:                \n        i = '0000' + str(i)\n    elif i>=10 and i<100:            \n        i = '000' + str(i)\n    elif i>=100 and i<1000:          \n        i = '00' + str(i)\n    elif i>=1000 and i<10000:        \n        i = '0' + str(i)\n    label_dataframe['With_zero'][count] = i\n    count = count + 1","3449ecf3":"del csv_dataframe, count, label_dataframe['BraTS21ID']\ngc.collect()","286273ee":"csv_dataframe = pd.read_csv('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train_labels.csv')\nlist_label = []\nfor i in range(len(label_dataframe['With_zero'])):\n    for j in range(len(number_of_files_Same)):\n        if label_dataframe['With_zero'][i] == number_of_files_Same[j]:\n            list_label.append(label_dataframe.iloc[i]['MGMT_value']) \nlist_label = np.array(list_label)\ns = 0; t = 0\nfor i in list_label:\n    if i == 1:\n        s = s + 1\n    else:\n        t = t + 1","5ea10aac":"del csv_dataframe, s, t, label_dataframe\ngc.collect()","1a5346fa":"new_list_label = []\nfor i in range(len(list_label)):\n    if list_label[i] == 1:\n        a = np.ones(count_file_in_same_subfolder[i][0], dtype=int)\n        new_list_label.append(a)             \n        new_list_label.append(a)\n        new_list_label.append(a)\n        new_list_label.append(a)\n    elif list_label[i] == 0:\n        b = np.zeros(count_file_in_same_subfolder[i][0], dtype=int)\n        new_list_label.append(b)             \n        new_list_label.append(b)\n        new_list_label.append(b)\n        new_list_label.append(b)\n        \nnew_list_label = np.array(new_list_label)\n\nnew_list_label_2 = []                 \nfor i in new_list_label:\n    for j in i:\n        new_list_label_2.append(j)\nnew_list_label_2 = np.array(new_list_label_2)","59ac99a9":"del list_label, count_file_in_same_subfolder, a, b, i, j\ngc.collect()","736fc3e0":"import pydicom\nfrom pydicom import dcmread\nfrom pydicom.data import get_testdata_files","72f8f19e":"%%time\ntraining_set = []\nfor a in range(len(number_of_files_Same)):\n    for b in os.listdir(path + \"\/\" + number_of_files_Same[a]):     \n        temp = []\n        for c in os.listdir(path + \"\/\" + number_of_files_Same[a] + \"\/\" + b):\n            temp.append(c)\n            temp = sorted(temp)\n        for d in range(len(temp)):\n            ds = dcmread(path + \"\/\" + number_of_files_Same[a] + \"\/\" + b + \"\/\" + temp[d], force=True)\n            training_set.append(ds.pixel_array)\n\nreshape_training_set = []\nfor i in range(len(training_set)):\n    reshape_training_set.append(cv2.resize(training_set[i], (32, 32)))\nreshape_training_set = np.array(reshape_training_set)","a0be1590":"del number_of_files_Same, training_set, a, b, c, d, i\ngc.collect()","299292b7":"print(\"{}{: >25}{}{: >10}{}\".format('|','Variable Name','|','Memory','|'))\nprint(\" ------------------------------------ \")\nfor var_name in dir():\n    if not var_name.startswith(\"_\") and sys.getsizeof(eval(var_name)) > 50: \n        print(\"{}{: >25}{}{: >10}{}\".format('|',var_name,'|',sys.getsizeof(eval(var_name)),'|'))","33d7cb69":"from sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential, load_model       \nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam","fe9a0f19":"X = copy.deepcopy(reshape_training_set)           \ny = copy.deepcopy(new_list_label_2)\n\nX_128_128_1 = []\nfor i in range(len(X)):\n    q = np.reshape(X[i], (32,32,1))\n    X_128_128_1.append(q)\nX_128_128_1 = np.array(X_128_128_1)\nprint(X_128_128_1.shape)","fe820085":"del X, reshape_training_set, new_list_label, new_list_label_2, i, q\ngc.collect()","d9e2896a":"X_train, X_test, y_train, y_test = train_test_split(X_128_128_1, y, test_size=0.2, random_state=0)\nprint('x_train:', X_train.shape)\nprint('label_train:', y_train.shape)\nprint('x_test:', X_test.shape)\nprint('label_test:', y_test.shape)","9ad834c7":"del y, X_128_128_1\ngc.collect()","126c72ca":"#16,(32),16,0.5,64,2 \/\/\/ img:128*128 \/\/\/ epoch:40, batch:all -> 0.89\n#32,32,64,0.4,128,2 \/\/\/ img:128*128 \/\/\/ epoch:100, batch:all -> 0.89\n#32,32,32,0.4,128,2 \/\/\/ img:32*32   \/\/\/ epoch:100, batch:all -> 0.84\n#32,32,32,0.4,128,2 \/\/\/ img:32*32   \/\/\/ epoch:50, batch:all -> 0.80\n#32,32,32,0.4,128,2 \/\/\/ img:32*32   \/\/\/ epoch:50, batch:150 -> 0.75\n#16,(16),16,0.4,64,2\nmodel = Sequential()\n\nmodel.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\", input_shape=(32,32,1)))\nmodel.add(MaxPooling2D())\n\n#model.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\n#model.add(MaxPooling2D())\n\nmodel.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPooling2D())\n\nmodel.add(Dropout(0.5))\n\nmodel.add(Flatten())\nmodel.add(Dense(64, activation=\"relu\"))\nmodel.add(Dense(2, activation=\"softmax\"))             \n\nmodel.summary()","e53e8b0e":"model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\nhistory = model.fit(X_train, y_train, epochs=100, batch_size=100, validation_data=(X_test,y_test)) ","b3f421ea":"del X_train, X_test, y_train, y_test, temp, Adam, Conv2D, Dense, Dropout, Flatten, MaxPooling2D, Sequential\ngc.collect()","b6319c32":"model.save('model.h5')","a114a9fe":"### CNN "}}