{"cell_type":{"e0418a04":"code","6be8d951":"code","34446061":"code","3987303f":"code","d9b2dcc1":"code","b5fc5079":"code","1f05fefd":"code","43269617":"code","b30bb9ef":"code","8b2de9df":"code","349f575d":"code","c4d5c218":"code","d7f7a31a":"code","612819da":"code","a6079171":"code","926cb310":"code","7e6c26fd":"code","195009e8":"code","e48a2bed":"code","26511a3e":"code","371c507a":"markdown","a5a3d793":"markdown","7a3eb1c3":"markdown","adb1ce06":"markdown","8c402f0a":"markdown","a3284183":"markdown","3ded243f":"markdown","5b829c73":"markdown","9e7a4377":"markdown"},"source":{"e0418a04":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style\nstyle.use('ggplot')\n\nimport os\nfrom datetime import datetime\n\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly as py\nimport plotly.graph_objs as go\n\ninit_notebook_mode(connected=True)\n\nfrom gensim import corpora, models, similarities\n\nimport warnings\nwarnings.filterwarnings('ignore')","6be8d951":"df = pd.read_csv('..\/input\/datadog-reddit\/DataDog.csv')\ndf.head()","34446061":"trace = go.Histogram(\n    x=df['timestamp'],\n    marker=dict(\n        color='blue'\n    ),\n    opacity=0.75\n)\n\nlayout = go.Layout(\n    title='Comment Activity',\n    height=450,\n    width=1200,\n    xaxis=dict(\n        title='Month'\n    ),\n    yaxis=dict(\n        title='Comment Quantity'\n    ),\n    bargap=0.2,\n)\n\ndata= [trace]\n\nfig = go.Figure(data=data, layout=layout)\npy.offline.iplot(fig)","3987303f":"corpus = df.title.values\ncorpus[0:5]","d9b2dcc1":"from sklearn.feature_extraction.text import CountVectorizer\n\ndef get_top_n_words(corpus, n=None):\n    vec = CountVectorizer().fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]\n\ncommon_words = get_top_n_words(corpus, 75)\nfor word, freq in common_words:\n    pass\n    #print(word, freq)\ndf1 = pd.DataFrame(common_words, columns = ['word' , 'count'])","b5fc5079":"import plotly.express as px\ndata = px.data.gapminder()\n\nfig = px.bar(df1.iloc[:50], x='word', y='count', labels={'word':'Word'}, height=400)\nfig.show()","1f05fefd":"import gensim\nimport logging\nimport tempfile\n\nTEMP_FOLDER = tempfile.gettempdir()\nprint('We will save the temporary dictionary and corpus at this location: {}'.format(TEMP_FOLDER))\n\nfrom gensim import corpora\nlogging.basicConfig(format = '%(ascitime)s: %(levelname)s: %(message)s', level=logging.INFO)","43269617":"from nltk.corpus import stopwords\nfrom string import punctuation\n\nstoplist = stopwords.words('english') + list(punctuation) + ['datadog', 'monitoring', 'summit']\n\ntexts = [[word for word in str(document).lower().split() if word not in stoplist] for document in corpus]","b30bb9ef":"dictionary = corpora.Dictionary(texts)\ndictionary.save(os.path.join(TEMP_FOLDER, 'onceUponATime.dict'))\nprint(dictionary)","8b2de9df":"corpus = [dictionary.doc2bow(text) for text in texts]\ncorpora.MmCorpus.serialize(os.path.join(TEMP_FOLDER,  'onceUponATime.dict'), corpus)","349f575d":"tfidf = models.TfidfModel(corpus)","c4d5c218":"corpus_tfidf = tfidf[corpus]","d7f7a31a":"total_topics = 3","612819da":"lda = models.LdaModel(corpus, id2word=dictionary, num_topics=total_topics)\ncorpus_lda = lda[corpus_tfidf]","a6079171":"lda.show_topics(total_topics,8)","926cb310":"from collections import OrderedDict\n\ndata_lda = {i: OrderedDict(lda.show_topic(i, 25)) for i in range(total_topics)}\n#data_lda","7e6c26fd":"df_lda = pd.DataFrame(data_lda)\nprint(df_lda.shape)\ndf_lda = df_lda.fillna(0).T\nprint(df_lda.shape)","195009e8":"df_lda","e48a2bed":"g = sns.clustermap(df_lda.corr(), center=0, cmap='RdBu', metric='cosine', linewidth=0.75, figsize=(12, 12))\nplt.setp(g.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\nfig = plt.gcf()\nfig.set_size_inches(24, 24)\nplt.show()","26511a3e":"import pyLDAvis.gensim\n\npyLDAvis.enable_notebook()\npanel = pyLDAvis.gensim.prepare(lda, corpus_lda, dictionary, mds='tsne')\npanel","371c507a":"# Create a transformation","a5a3d793":"## LDA (Latent Dirichlet Allocation)","7a3eb1c3":"## Create a corpus","adb1ce06":"DataDog was founded in 2010. We see the first comment in 2011. There is a clear spike in comments in the second half of 2016 from a few threads to > 20. The number for the second half of 2019 is considerably lower but that's because we don't have all the data yet (four months to go)","8c402f0a":"Step 2: we use the model to transform all the vectors in the corpus.","a3284183":"# Load data","3ded243f":"Step 1: initialize the model (following erreanhas I'm using Tfidf).","5b829c73":"# Comment activity vs. time","9e7a4377":"With three clusters LDA picked out three topics:\n1. posts with a big data slant - 'spark', 'terraform', 'pagerduty', 'spark', 'cluster'\n2. general discussions - the most frequently occuring words are 'monitor', 'management', 'understand', 'announcing'\n3. technical software posts -containing largely words that indicate a technical slant ('python', 'java', 'logs') "}}