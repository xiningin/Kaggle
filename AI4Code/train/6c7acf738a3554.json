{"cell_type":{"08efafc0":"code","1c14fea5":"code","23c59b98":"code","2419889e":"code","e03b6e4f":"code","9310667e":"code","a17ce17c":"code","16460394":"code","7d21c31d":"code","a87a34a6":"code","03168e2c":"code","9ef2d271":"code","5c6b22b5":"code","803e0ee5":"code","d74c65b4":"code","f1c39d1e":"code","6541725a":"code","f5903387":"code","0f093391":"code","790bfb76":"code","eb375934":"code","d4cfa687":"code","78735537":"code","0bd3c404":"code","35ae4cba":"code","0416a9ba":"code","c2763dea":"code","18f8f736":"code","10f3135a":"code","e7bc2e2d":"code","2440360f":"code","d62dbe2e":"code","52bf7abd":"code","88a28d0a":"code","c424a9f5":"code","388c918b":"code","8b58e56a":"code","b002268b":"code","1a89fa3b":"code","40d5f262":"code","422176de":"code","f5e5a808":"code","839d7406":"code","36819853":"code","dbe4e42f":"code","4e5b4939":"code","2712a93b":"code","13305832":"code","6afc9d43":"code","ccdba498":"code","b0e6a979":"code","1740275f":"code","f9f52ad5":"code","036e5f98":"code","d07309a1":"code","b6b0f39b":"code","7f4fbaa9":"code","6dc07984":"code","7725c5b1":"code","c834e773":"code","ab0813a5":"code","0428fb26":"code","b9b3598d":"code","443593d6":"code","0502bf32":"code","fed3bf51":"code","da4f816d":"code","6d08200c":"code","a6230cf6":"code","e24b8cfc":"code","24d3ccf5":"code","b57417e6":"code","5fb403e2":"code","913e36f5":"code","47072a12":"code","72d32fc4":"code","478969d0":"code","4e5887aa":"code","f8c76d31":"code","94c07d85":"code","297d5731":"code","f90ac4d6":"code","6393da0c":"markdown","213a6440":"markdown","079254ca":"markdown","3d6b8b7f":"markdown","b54cead2":"markdown","de261eff":"markdown","7e840419":"markdown","8d9b9875":"markdown","9f22a8d9":"markdown","361953ab":"markdown","31f310a5":"markdown","69966626":"markdown","a4771a5e":"markdown","9d1c3677":"markdown","eb83c27d":"markdown","09c922d0":"markdown","fed58d72":"markdown","ad7c4f07":"markdown","18956197":"markdown","074d2023":"markdown","cb57c673":"markdown","66a72582":"markdown","604db9e5":"markdown","5b0b87e6":"markdown","295e335e":"markdown","63d19a90":"markdown","c516e90a":"markdown","10d6830b":"markdown","7f163dc5":"markdown","86854128":"markdown","2cd70030":"markdown","109d0285":"markdown","82291b1f":"markdown","3cad4f58":"markdown","1eba8ce4":"markdown","821b09e2":"markdown","7f1cb71c":"markdown","a47a831c":"markdown","c42ade2e":"markdown","3c670a24":"markdown","95e84869":"markdown","615b3922":"markdown","db67fd0a":"markdown","69e8bbdb":"markdown","4a63ddaf":"markdown","53c8ab6b":"markdown","3c8ffdb6":"markdown"},"source":{"08efafc0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-whitegrid')\nimport seaborn as sns\nfrom collections import Counter\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1c14fea5":"train_df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest_passenger_id = test_df[\"PassengerId\"]","23c59b98":"train_df.columns","2419889e":"train_df.describe()","e03b6e4f":"train_df.info()","9310667e":"def bar_plot(variable):\n    \"\"\"\n        input: variable ex: \"Sex\"\n        output: bar plot & value count\n    \"\"\"\n    # get features\n    var = train_df[variable]\n    # count number of categorical varianle(value\/sample)\n    varValue = var.value_counts()\n    \n    # visualize\n    plt.figure(figsize = (9,3))\n    plt.bar(varValue.index, varValue)\n    plt.xticks(varValue.index, varValue.index.values)\n    plt.ylabel(\"Frequency\")\n    plt.title(variable)\n    plt.show()\n    print('{}: \\n {}'.format(variable, varValue))","a17ce17c":"category1 = [\"Survived\", \"Sex\", \"Pclass\", \"Embarked\", \"SibSp\", \"Parch\"]\nfor c in category1:\n    bar_plot(c)","16460394":"category2 = [\"Cabin\", \"Name\", \"Ticket\"]\nfor c in category2:\n    print(\"{} \\n\".format(train_df[c].value_counts()))","7d21c31d":"def plot_hist(variable):\n    plt.figure(figsize = (9,3))\n    plt.hist(train_df[variable], bins=50)\n    plt.xlabel(variable)\n    plt.ylabel(\"Frequency\")\n    plt.title(\"{} Distribution with Hist.\".format(variable))\n    plt.show()","a87a34a6":"numericVar = [\"Fare\", \"Age\", \"PassengerId\"]\nfor n in numericVar:\n    plot_hist(n)","03168e2c":"# Pclass vs Survived\ntrain_df[[\"Pclass\", \"Survived\"]].groupby([\"Pclass\"], as_index = False).mean().sort_values(by = \"Survived\", ascending = False)","9ef2d271":"# Sex vs Survived\ntrain_df[[\"Sex\", \"Survived\"]].groupby([\"Sex\"], as_index = False).mean().sort_values(by = \"Survived\", ascending = False)","5c6b22b5":"# SibSp vs Survived\nb = train_df[[\"SibSp\", \"Survived\"]].groupby([\"SibSp\"], as_index = False).mean().sort_values(by = \"Survived\", ascending = False)\nb[\"count\"] = train_df['SibSp'].value_counts()\nb","803e0ee5":"# Parch vs Survived\na = train_df[[\"Parch\", \"Survived\"]].groupby([\"Parch\"], as_index = False).mean().sort_values(by = \"Survived\", ascending = False)\na['count'] = train_df['Parch'].value_counts()\na","d74c65b4":"train_df['family_sit'] = train_df['Parch'] + train_df['SibSp']\nc = train_df[[\"family_sit\", \"Survived\"]].groupby([\"family_sit\"], as_index = False).mean().sort_values(by = \"Survived\", ascending = False)\nc['count'] = train_df['family_sit'].value_counts()\nc","f1c39d1e":"# Sex vs Survived ????\nage_groups = pd.cut(train_df['Age'], bins=[0, 15, 30, 55, np.inf])\nb = train_df.groupby(age_groups, as_index = False)[\"Survived\"].mean().sort_values(by = \"Survived\", ascending = False)\nb[\"count\"] = train_df.groupby(age_groups, as_index = False)[\"Survived\"].transform(\"count\")\nb","6541725a":"def detect_outliers(df, features):\n    outlier_indices = []\n    \n    for c in features:\n        # 1st quartile\n        q1 = np.percentile(df[c], 25)\n        \n        # 3rd quartile\n        q3 = np.percentile(df[c], 75)\n        \n        # IQR\n        iqr = q3 - q1\n        \n        # Outlier step\n        outlier_step = iqr * 1.5\n        \n        # Detect outlier and their indices\n        outlier_list_col = df[(df[c] < q1 - outlier_step) | (df[c] > q3 + outlier_step)].index\n        \n        # Store indices\n        outlier_indices.extend(outlier_list_col)\n    \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2)\n    \n    return multiple_outliers","f5903387":"train_df.loc[detect_outliers(train_df, [\"Age\", \"SibSp\", \"Parch\", \"Fare\"])]","0f093391":"# Drop outliers","790bfb76":"train_df = train_df.drop(detect_outliers(train_df, [\"Age\", \"SibSp\", \"Parch\", \"Fare\"]), axis = 0).reset_index(drop=True)","eb375934":"train_df_len = len(train_df)\ntrain_df = pd.concat([train_df, test_df], axis = 0).reset_index(drop = True)","d4cfa687":"train_df.head()","78735537":"train_df.columns[train_df.isnull().any()]","0bd3c404":"train_df.isnull().sum()","35ae4cba":"train_df[train_df[\"Embarked\"].isnull()]","0416a9ba":"train_df.boxplot(column=\"Fare\", by = \"Embarked\")\nplt.show()","c2763dea":"train_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(\"C\")\ntrain_df[train_df[\"Embarked\"].isnull()]","18f8f736":"train_df[train_df[\"Fare\"].isnull()]","10f3135a":"train_df[train_df[\"Pclass\"] == 3][\"Fare\"]","e7bc2e2d":"np.mean(train_df[train_df[\"Pclass\"] == 3][\"Fare\"])","2440360f":"train_df[\"Fare\"] = train_df[\"Fare\"].fillna(np.mean(train_df[train_df[\"Pclass\"] == 3][\"Fare\"]))\ntrain_df[train_df[\"Embarked\"].isnull()]","d62dbe2e":"list1 = [\"SibSp\", \"Parch\", \"Age\", \"Fare\", \"Survived\"]\nsns.heatmap(train_df[list1].corr(), annot = True, fmt = \".2f\")","52bf7abd":"g = sns.factorplot(x = \"SibSp\", y = \"Survived\", data = train_df, kind = \"bar\", size = 6)\ng.set_ylabels(\"Survived Probability\")\nplt.show()\n","88a28d0a":"g = sns.factorplot(x = \"Parch\", y = \"Survived\", data = train_df, kind = \"bar\", size = 6)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","c424a9f5":"g = sns.factorplot(x = \"Pclass\", y = \"Survived\", data = train_df, kind = \"bar\", size = 6)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","388c918b":"g = sns.FacetGrid(train_df, col = 'Survived')\ng.map(sns.distplot, \"Age\", bins = 25)\nplt.show()","8b58e56a":"g = sns.FacetGrid(train_df, col = 'Survived', row = \"Pclass\", size = 2)\ng.map(plt.hist, \"Age\", bins = 25)\ng.add_legend()\nplt.show()","b002268b":"g = sns.FacetGrid(train_df, row = \"Embarked\", size = 2)\ng.map(sns.pointplot, \"Pclass\", \"Survived\", \"Sex\")\ng.add_legend()\nplt.show()","1a89fa3b":"g = sns.FacetGrid(train_df, row = \"Embarked\", col = \"Survived\", size = 3)\ng.map(sns.barplot, \"Sex\", \"Fare\")\ng.add_legend()\nplt.show()","40d5f262":"train_df[train_df[\"Age\"].isnull()]","422176de":"sns.factorplot(x = \"Sex\", y = \"Age\", data = train_df, kind = \"box\")\nplt.show()","f5e5a808":"sns.factorplot(x = \"Sex\", y = \"Age\", hue = \"Pclass\", data = train_df, kind = \"box\")\nplt.show()","839d7406":"sns.factorplot(x = \"family_sit\", y = \"Age\", data = train_df, kind = \"box\")\nsns.factorplot(x = \"Parch\", y = \"Age\", data = train_df, kind = \"box\")\nsns.factorplot(x = \"SibSp\", y = \"Age\", data = train_df, kind = \"box\")\nplt.show()","36819853":"train_df[\"Sex\"] = [1 if i == \"male\" else 0 for i in train_df[\"Sex\"]]\nsns.heatmap(train_df[[\"Age\", \"Sex\", \"SibSp\", \"Parch\", \"Pclass\", \"family_sit\"]].corr(), annot = True)\nplt.show()","dbe4e42f":"index_nan_age = list(train_df[\"Age\"][train_df[\"Age\"].isnull()].index)\nfor i in index_nan_age:\n    age_pred = train_df[\"Age\"][((train_df[\"SibSp\"] == train_df.iloc[i][\"SibSp\"]) & (train_df[\"Parch\"] == train_df.iloc[i][\"Parch\"]) & (train_df[\"Pclass\"] == train_df.iloc[i][\"Pclass\"]))].median()\n    age_med = train_df[\"Age\"].median()\n    if not np.isnan(age_pred):\n        train_df[\"Age\"].iloc[i] = age_pred\n    else:\n        train_df[\"Age\"].iloc[i] = age_med","4e5b4939":"train_df[train_df[\"Age\"].isnull()]","2712a93b":"train_df[\"Name\"].head(10)","13305832":"name = train_df[\"Name\"]\ntrain_df[\"Title\"] = [i.split(\".\")[0].split(\",\")[-1].strip() for i in name]","6afc9d43":"train_df[\"Title\"].head(10)","ccdba498":"sns.countplot(x = \"Title\", data = train_df)\nplt.xticks(rotation = 60)\nplt.show()","b0e6a979":"# Convert to Categorical\ntrain_df[\"Title\"] = train_df[\"Title\"].replace([\"Lady\", \"the Countess\", \"Don\", \"Rev\", \"Dr\", \"Major\", \"Sir\", \"Col\", \"Capt\", \"Jonkheer\", \"Dona\"], \"other\")\ntrain_df[\"Title\"] = [0 if i == \"Master\" else 2 if i == \"Mr\" else 3 if i == \"other\" else 1 for i in train_df[\"Title\"]]\nsns.countplot(x = \"Title\", data = train_df)\nplt.xticks(rotation = 0)\nplt.show()","1740275f":"g = sns.factorplot(x = \"Title\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_xticklabels([\"Master\", \"Mrs\", \"Mr\", \"other\"])\ng.set_ylabels(\"Survival Probability\")\nplt.show()","f9f52ad5":"train_df.drop(labels = [\"Name\"], axis = 1, inplace = True)","036e5f98":"train_df.head(10)","d07309a1":"train_df = pd.get_dummies(train_df, columns = [\"Title\"])\ntrain_df.head()","b6b0f39b":"train_df[\"family_size\"] = [1 if i == 0 else 0 if i < 4 else 2 for i in train_df[\"family_sit\"]]","7f4fbaa9":"train_df.head()","6dc07984":"sns.countplot(x = \"family_size\", data = train_df)\nplt.show()","7725c5b1":"g = sns.factorplot(x = \"family_size\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_ylabels(\"Survival Probability\")\nplt.show()","c834e773":"train_df = pd.get_dummies(train_df, columns = [\"family_size\"])\ntrain_df.head()","ab0813a5":"train_df[\"Embarked\"].head()","0428fb26":"sns.countplot(x = \"Embarked\", data = train_df)\nplt.show()","b9b3598d":"train_df = pd.get_dummies(train_df, columns = [\"Embarked\"])\ntrain_df.head()","443593d6":"train_df[\"Ticket\"].head(20)","0502bf32":"ticket_list = []\nfor i in list(train_df.Ticket):\n    if not i.isdigit():\n        ticket_list.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(\" \")[0])\n    else:\n        ticket_list.append(\"x\")\n\ntrain_df[\"Ticket\"] = ticket_list\ntrain_df[\"Ticket\"].head(20)","fed3bf51":"train_df = pd.get_dummies(train_df, columns = [\"Ticket\"], prefix = \"T\")\ntrain_df.head()","da4f816d":"sns.countplot(x = \"Pclass\", data = train_df)\nplt.show()","6d08200c":"train_df[\"Pclass\"] = train_df[\"Pclass\"].astype(\"category\")\ntrain_df = pd.get_dummies(train_df, columns = [\"Pclass\"])\ntrain_df.head()","a6230cf6":"train_df[\"Sex\"] = train_df[\"Sex\"].astype(\"category\")\ntrain_df = pd.get_dummies(train_df, columns = [\"Sex\"])\ntrain_df.head()","e24b8cfc":"try:\n    train_df.drop(labels = [\"PassengerId\", \"Cabin\", \"family_sit\"], axis = 1, inplace = True)\nexcept KeyError:\n    pass","24d3ccf5":"train_df.columns","b57417e6":"from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\n","5fb403e2":"test = train_df[train_df_len:]\ntest.drop(labels = [\"Survived\"], axis = 1, inplace = True)","913e36f5":"test.head()","47072a12":"train = train_df[:train_df_len]\nx_train = train.drop(labels = [\"Survived\"], axis = 1)\ny_train = train[\"Survived\"]\nx_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size = 0.33, random_state = 42)\nprint(\"x_train\", len(x_train))\nprint(\"x_test\", len(x_test))\nprint(\"y_train\", len(y_train))\nprint(\"y_test\", len(y_test))\nprint(\"train\", len(train))","72d32fc4":"logreg = LogisticRegression(solver = 'liblinear')\nlogreg.fit(x_train, y_train)\nacc_log_train = round(logreg.score(x_train, y_train) * 100, 2)\nacc_log_test = round(logreg.score(x_test, y_test) * 100, 2)\nprint(\"Training Accuracy: % {}\".format(acc_log_train))\nprint(\"Test Accuracy: % {}\".format(acc_log_test))","478969d0":"random_state = 42\nclassifier = [DecisionTreeClassifier(random_state = random_state),\n            SVC(random_state = random_state),\n            RandomForestClassifier(random_state = random_state),\n            LogisticRegression(random_state = random_state, solver = 'liblinear'),\n            KNeighborsClassifier()]\n\ndt_parameter_grid = {\"min_samples_split\": range(10,500,20),\n                    \"max_depth\": range(1,20,2)}\n\nsvc_param_grid = {\"kernel\": [\"rbf\"],\n                 \"gamma\": [0.001, 0.01, 0.1, 1],\n                 \"C\": [1, 10, 50, 100, 200, 300, 1000]}\n\nrf_param_grid = {\"max_features\": [1, 3, 10],\n                \"min_samples_split\": [2, 3, 10],\n                \"min_samples_leaf\": [1, 3, 10],\n                \"bootstrap\": [False],\n                \"n_estimators\": [100, 300],\n                \"criterion\": [\"gini\"]}\n\nlogreg_param_grid = {\"C\": np.logspace(-3, 3, 7),\n                    \"penalty\": [\"l1\",\"l2\"]}\n\nknn_param_grid = {\"n_neighbors\": np.linspace(1,19,10, dtype = int).tolist(),\n                 \"weights\": [\"uniform\", \"distance\"],\n                 \"metric\": [\"euclidean\", \"manhattan\"]}\n\nclassifier_param = [dt_parameter_grid,\n                   svc_param_grid,\n                   rf_param_grid,\n                   logreg_param_grid,\n                   knn_param_grid]","4e5887aa":"cv_results = []\nbest_estimator = []\nfor i in range(len(classifier)):\n    clf = GridSearchCV(classifier[i], param_grid = classifier_param[i], cv = StratifiedKFold(n_splits = 10), scoring = \"accuracy\", n_jobs = -1, verbose = 1)\n    clf.fit(x_train, y_train)\n    cv_results.append(clf.best_score_)\n    best_estimator.append(clf.best_estimator_)\n    print(cv_results[i])","f8c76d31":"cv_result = pd.DataFrame({\"Cross Validation Means\": cv_results, \"ML Models\": [\"DecisionTreeClassifier\", \"SVM\", \"RandomForest\", \"LogisticRegression\", \"KNN\"]})\ng = sns.barplot(\"Cross Validation Means\", \"ML Models\", data = cv_result)\ng.set_xlabel(\"Mean Accuracy\")\ng.set_title(\"Cross Validation Scores\")\nplt.show()","94c07d85":"votingC = VotingClassifier(estimators = [(\"dt\", best_estimator[0]),\n                                        (\"rfc\", best_estimator[2]),\n                                        (\"lr\", best_estimator[3])],\n                          voting = \"soft\", n_jobs = -1)\n\nvotingC = votingC.fit(x_train, y_train)\nprint(accuracy_score(votingC.predict(x_test), y_test))","297d5731":"test_survived = pd.Series(votingC.predict(test), name = \"Survived\").astype(int)\nresults = pd.concat([test_passenger_id, test_survived], axis = 1)\nresults.to_csv(\"submission.csv\", index = False)","f90ac4d6":"test_survived","6393da0c":"<a id = 13 ><\/a>\n## SibSp -- Survived","213a6440":"<a id = 32><\/a>\n## Hyperparameter Tuning -- Grid Search -- Cross Validation\nWe will compare 5 ML classifier and evaluate mean accuracy of each of them by stratified cross validation.\n\n* Decision Tree\n* SVM\n* Random Forest\n* KNN\n* Logistic Regression","079254ca":"<a id = 3><\/a>\n# Univariate Variable Analysis\n* Categorical Variable: Survived, Sex, Pclass, Embarked, Cabin, Name, Ticket, SibSp and Parch\n* Numerical Variable: Age, PassengerId, Fare","3d6b8b7f":"<a id = 29><\/a>\n# Modelling","b54cead2":"<a id = 4><\/a>\n## Categorical Variable","de261eff":"<a id = 19><\/a>\n## Embarked -- Sex -- Fare -- Survived","7e840419":"<a id = 23><\/a>\n## Family Size","8d9b9875":"<a id = 26><\/a>\n## Pclass","9f22a8d9":"* Pclass is important feature to train data","361953ab":"<a id = 14 ><\/a>\n## Parch -- Survived","31f310a5":"Fare feature seems to have correlation with survived feature (0.26).","69966626":"* When ticket price is high, survival rate is high, too.","a4771a5e":"<a id = 15 ><\/a>\n## Pclass -- Survived","9d1c3677":"* SipSp and Parch can be used for new feature extraction with th = 3\n* Small families have more chance to survive\n* There is a high std in survival of passenger with parch = 3 ","eb83c27d":"<a id = 12 ><\/a>\n## Correlation Between SibSp -- Parch -- Age -- Fare -- Survived","09c922d0":"<a id = 5><\/a>\n## Numerical Variable Analysis","fed58d72":"<a id = 10><\/a>\n## Fill Missing Values\n\n* Embarked has 2 missing value\n* Fare has only 1","ad7c4f07":"<a id = 34><\/a>\n## Prediction and Submission","18956197":"<a id = 16 ><\/a>\n## Age -- Survived","074d2023":"* float64(2): Fare and Age\n* int64(5): PassengerId, Survived, Pclass, SibSp, Parch\n* object(5): Name, Sex, Ticket, Cabin, Embarked","cb57c673":"<a id = 7><\/a>\n# Outlier Detection","66a72582":"# Introduction\nOne of the most tragic and notorious shipwrecks is the sinking of the Titanic. Most people thought that the passenger liner will not sink ever. But the reality did not match with the thoughts. Titanic collided iceberg and began to sink with many innocent people who cruise with it. Approximately 1500 passengers and crew died in a horrifying accident.\n\n<font color = 'blue'>\nContent: \n\n1. [Load and Check Data](#1)\n2. [Variable Description](#2)\n    * [Univariate Variable Analysis](#3)\n        * [Categorical Variable Analysis](#4)\n        * [Numerical Variable Analysis](#5)\n3. [Basic Data Analysis](#6)\n4. [Outlier Detection](#7)\n5. [Missing Values](#8)\n    * [Find Missing Value](#9)\n    * [Fill Missing Value](#10)\n6. [Visualization](#11)\n    * [Correlation Between SibSp -- Parch -- Age -- Fare -- Survived](#12)\n    * [SibSp -- Survived](#13)\n    * [Parch -- Survived](#14)\n    * [Pclass -- Survived](#15)\n    * [Age -- Survived](#16)\n    * [Pclass -- Survived -- Age](#17)\n    * [Embarked -- Sex -- Pclass -- Survived](#18)\n    * [Embarked -- Sex -- Fare -- Survived](#19)\n    * [Fill Missing: Age Feature](#20)\n7. [Feature Engineering](#21)\n    * [Name -- Title](#22)\n    * [Family Size](#23)\n    * [Embarked](#24)\n    * [Ticket](#25)\n    * [Pclass](#26)\n    * [Sex](#27)\n    * [Drop PassengerId and Cabin](#28)\n8. [Modelling](#29)\n    * [Train Test Split](#30)\n    * [Simple Logistic Regression](#31)\n    * [Hyperparameter Tuning -- Grid Search -- Cross Validation](#32)\n    * [Ensemble Modeling](#33)\n    * [Prediction and Submission](#34)\n        ","604db9e5":"<a id = 24><\/a>\n## Embarked","5b0b87e6":"<a id = 17 ><\/a>\n## Pclass -- Survived -- Age","295e335e":"* age <= 15 has a high survival rate\n* oldest passengers(80)survived,\n* large number of 20 years old did not survive,\n* most passengers are in 15-35 age range,\n* use age feature in training\n* use age distribution for missing values of age","63d19a90":"* Sex is not informative for age prediction, age distribution seems to be same.","c516e90a":"<a id = 8><\/a>\n# Missing Values\n\n* Find Missing Values\n* Fill Missing Values","10d6830b":"<a id = 22><\/a>\n## Name -- Title","7f163dc5":"<a id = 6><\/a>\n# Basic Data Analysis\n* Pclass - Survived\n* Sex - Survived\n* SibSp - Survived\n* Parch - Survived","86854128":"<a id = 25><\/a>\n## Ticket","2cd70030":"<a id = 9><\/a>\n## Find Missing Values","109d0285":"* 1st class passengers are older than 2nd and that are older than 3rd.","82291b1f":"<a id = 20><\/a>\n## Fill Missing: Age Feature","3cad4f58":"<a id = 31><\/a>\n## Simple Logistic Regression","1eba8ce4":"<a id = 28><\/a>\n## Drop PassengerId and Cabin","821b09e2":"* Age is not correlated with sex but it is corraleted with parch, sibsp, and pclass","7f1cb71c":"<a id = 21><\/a>\n# Feature Engineering]","a47a831c":"<a id = 18><\/a>\n## Embarked -- Sex -- Pclass -- Survived","c42ade2e":"<a id = 30><\/a>\n## Train Test Split","3c670a24":"* Female passengers have much better survival rate than males.\n* Male passengers have better survival rate in Pclass 3 in C.\n* Embarked and sex will be used in training.","95e84869":"<a id = 11 ><\/a>\n# Visualization","615b3922":"* Having lots of SibSp gives less chance to survive\n* if SibSp == 0 or 1 or 2, passenger has more chance to survive but a number of data is important here. if data which more than 2 siblings are fewer, being categorized as having or not having a sibling is a better solution.\n* I want to consider this feature as having SibSp or not having.","db67fd0a":"<a id = 27><\/a>\n## Sex","69e8bbdb":"* Individual passengers have more chance to survive than people who have small families and people who have small families have more chance to survive than large families","4a63ddaf":"<a id = 33><\/a>\n## Ensemble Modeling","53c8ab6b":"<a id = 2><\/a>\n# Variable Description\n1. PassengerId: Unique id for each passenger \n1. Survived: Passenger survive(1) or died(0)\n1. Pclass: Passenger class\n1. Name: Name\n1. Sex: Gender of passenger\n1. Age: Age of passenger\n1. SibSp: Number of siblings\/spouses\n1. Parch: Number of parents\/children\n1. Ticket: Ticket number\n1. Fare: Amount of money spent on ticket\n1. Cabin: Cabin category\n1. Embarked: Port where passenger embarked (C = Cherbourg, Q = Queenstown, S = Southampton) \n","3c8ffdb6":"<a id = \"1\"><\/a>\n# Load and Check Data"}}