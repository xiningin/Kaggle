{"cell_type":{"8293097f":"code","de9bac75":"code","c07a77a4":"code","763090ee":"code","46d4875e":"code","2334be8c":"code","4d896526":"code","86330480":"code","7535b854":"code","a9c31c1a":"code","65c280b7":"code","316673cd":"markdown","914ebcf2":"markdown","d34a2f81":"markdown"},"source":{"8293097f":"!pip install -U sentence-transformers > silent.txt","de9bac75":"import os\nimport json\nimport warnings\nwarnings.simplefilter('ignore')\n\nJSON_PATH = '\/kaggle\/input\/CORD-19-research-challenge\/comm_use_subset\/comm_use_subset\/'\nNLP_MODEL = 'bert-base-nli-mean-tokens'\n\n#json_files = [pos_json for pos_json in os.listdir(JSON_PATH) if pos_json.endswith('.json')]\n# take all json files available\n\njson_files = []\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        if filename.endswith('.json'):\n            json_files.append(os.path.join(dirname, filename))\n\ncorpus = []\n\n# loop through the files\nfor jfile in json_files[::]:\n    # for each file open it and read as json\n    with open(os.path.join(JSON_PATH, jfile)) as json_file:\n        covid_json = json.load(json_file)\n        # read abstract\n        for item in covid_json['abstract']:\n            corpus.append(item['text'])\n        # read body text\n        #for item in covid_json['body_text']:\n        #    corpus.append(item['text'])\n            \nprint(\"Corpus size = %d\"%(len(corpus)))\n\nfrom sentence_transformers import SentenceTransformer\nimport scipy\n\nembedder = SentenceTransformer(NLP_MODEL)\ncorpus_embeddings = embedder.encode(corpus)","c07a77a4":"from IPython.display import display, Markdown, Latex\n\n# inputs text query and results top 5 matching answers\ndef ask_question(query):\n    queries = [query]\n    query_embeddings = embedder.encode(queries)\n\n    # Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n    closest_n = 5\n    for query, query_embedding in zip(queries, query_embeddings):\n        distances = scipy.spatial.distance.cdist([query_embedding], corpus_embeddings, \"cosine\")[0]\n\n        results = zip(range(len(distances)), distances)\n        results = sorted(results, key=lambda x: x[1])\n        display(Markdown('## Question -> %s'%query))\n        display(Markdown('**Top 5 answers compiled below by running AI algorithm on research text.**<hr>')) \n        \n        # get the closest answers\n        count = 0\n        for idx, distance in results[0:closest_n]:\n            display(Markdown('- ### ' + corpus[idx].strip() + \" (Score: %.4f)\" % (1-distance)))\n        display(Markdown('<hr>'))","763090ee":"ask_question('Does smoking or pre-existing pulmonary disease increase risk of COVID-19?')","46d4875e":"ask_question('Are neonates and pregnant women ar greater risk of COVID-19?')","2334be8c":"ask_question('Severity of disease, including risk of fatality among symptomatic hospitalized patients, and high-risk patient groups')","4d896526":"ask_question('Are there socio-economic and behavioral factors that help understand economic impact of the virus COVID-19 and whether there were differences?')","86330480":"ask_question('What is the severity of disease, including risk of fatality among symptomatic hospitalized patients, and high-risk patient groups?')","7535b854":"ask_question('Does rise in pollution increase risk of COVID-19?')","a9c31c1a":"ask_question('Are there public health mitigation measures that could be effective for control of COVID-19?')","65c280b7":"ask_question('What do we know about COVID-19 risk factors? What have we learned from epidemiological studies?')","316673cd":"## We will use the Sentence Transformers library\nApproach is to encode sentences from COVID-19 dataset into a list. Then match the question with embedding to find the top matching sencences as answers.","914ebcf2":"## Lets define the ask_question method\nIt takes the question string as input and prints out list of answers.","d34a2f81":"# *Questions on risks of COVID-19 and answers from Research text dataset *\n\n**We will use universal sentence encoder to encode text from COVID-19 dataset and use to answer queries. Approach is to encode sentences from COVID-19 dataset into a list. Then match the question with embedding to find the top matching sencences as answers.**\n![COVID-19](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/0\/09\/Covid-19-4855688_640.png)\n\nBased on Google's Universal Sentence Encoder: https:\/\/static.googleusercontent.com\/media\/research.google.com\/en\/\/pubs\/archive\/46808.pdf\n\nDataset available at: https:\/\/pages.semanticscholar.org\/coronavirus-research\n\nBy Dattaraj J Rao (Persistent Systems) - https:\/\/www.linkedin.com\/in\/dattarajrao\n\n(Image courtesy: WikiMedia - \u010ce\u0161tina: Grafick\u00fd odkaz na str\u00e1nku koronavirus.mzcr.cz)"}}