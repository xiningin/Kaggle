{"cell_type":{"e632f1df":"code","29c60699":"code","8c235a7b":"code","87a60461":"code","c1d91ad5":"code","3dfa0257":"code","e6d68a52":"code","f942e91f":"code","aff5efd9":"code","6a3ea780":"code","177a5e5a":"code","718194ad":"code","6497938c":"code","6e6816a5":"code","070a7913":"code","5f4b64d9":"code","5c1429fc":"code","1f5eb7f0":"code","d4950fb0":"code","117d6248":"code","6a831213":"code","1f1566c9":"code","f0b8a44a":"code","e0b614f9":"code","d1aa4911":"code","658c966b":"code","655660d2":"code","47691406":"code","d8e5ae6b":"code","ab87815e":"code","1791bdca":"code","d11f61ce":"code","c9aeaf02":"code","5b0b76c6":"code","3ca02f5f":"code","efcc6a7f":"code","695a63a9":"code","11f8693b":"code","3b118eae":"code","24bc04ba":"code","ac840724":"code","697f35aa":"code","3d7a6e1f":"code","4e7f5f15":"code","7b76fcf7":"code","90c85250":"code","3c3ba56b":"code","89755ac8":"code","1e6882d7":"code","41c572ef":"code","bafb66e7":"code","028a1687":"code","1ab34af7":"code","b0e8d9a8":"code","00cac7d5":"code","5fa433a0":"markdown","1c3aee50":"markdown","d9f1d2e1":"markdown","57814a84":"markdown","ec181ff4":"markdown","5cc2d713":"markdown","982376eb":"markdown","0ae7f9a4":"markdown","9e713bdc":"markdown","a286bbf5":"markdown","6606f1bf":"markdown","132dd548":"markdown","e02b079c":"markdown","a4d8e74f":"markdown","fa57dd39":"markdown","67c3c4c7":"markdown","b6fdb9f6":"markdown","fdbeea2a":"markdown"},"source":{"e632f1df":"# Importing necessary Library\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\n%matplotlib inline","29c60699":"train=pd.read_csv('..\/input\/titanic\/train.csv')\ntest=pd.read_csv('..\/input\/titanic\/test.csv')\ndf_train=pd.DataFrame(train)\ndf_test=pd.DataFrame(test)","8c235a7b":"# Here we will combine our datasets to manipulate them together with ease.\ncombine=[df_train,df_test]\ndf_train.head()","87a60461":"df_train.info()","c1d91ad5":"# We will first observe the correlations between the columns\nplt.figure(figsize=(12,5))\nplt.title('Correlation between Columns')\nsns.heatmap(df_train.corr(),annot=True,cmap='Greens')","3dfa0257":"plt.figure(figsize=(12,5))\nsns.countplot(x='Survived',hue='Pclass',data=df_train)","e6d68a52":"plt.figure(figsize=(12,5))\nsns.boxplot(x='Pclass',y='Age',data=df_train)","f942e91f":"#Quick details of the training data \ndf_train.info()\ndef missing_values(df,columns):\n    mvalues={}\n    for col in columns:\n        c=df[col].isnull().sum()\n        mvalues[col]=c\n    return mvalues\nprint('Missing Value count for each column:')\nmissingvalue=missing_values(train,train.columns)\nmissingvalue","aff5efd9":"def age_fill(col):\n    Age=col[0]\n    Pclass=col[1]\n    if pd.isnull(Age):\n        if Pclass==1:\n            return 37\n        elif Pclass==2:\n            return 28\n        else:\n            return 24\n    else:\n        return Age\nfor i in combine:\n    i['Age']=i[['Age','Pclass']].apply(age_fill, axis=1)","6a3ea780":"df_train.Age.isna().sum()","177a5e5a":"df_test.Age.isna().sum()","718194ad":"for dataset in combine:\n    dataset['AgeBin'] = pd.cut(dataset['Age'].astype(int), 5)","6497938c":"# Extracting title column from name column\ndef Title_extract(name):\n    name=name.split(',')[1].split('.')[0].strip()\n    return name\nfor dataset in combine:\n    dataset['Title']=dataset['Name'].apply(Title_extract)","6e6816a5":"df_train.Title.value_counts().to_frame()","070a7913":"df_test.Title.value_counts().to_frame()","5f4b64d9":"for dataset in combine:\n    dataset.Title.replace(['Major','Capt','Jonkheer','Sir','Don','Col','Rev'],'Mr',inplace=True)\n    dataset.Title.replace(['Mme','Ms','Lady','the Countess','Mlle','Dona'],'Miss',inplace=True)","5c1429fc":"plt.figure(figsize=(15,6))\nsns.countplot(x='Title',hue='Survived',data=df_train)","1f5eb7f0":"plt.figure(figsize=(10,5))\nsns.heatmap(df_train.isnull(),yticklabels=False)","d4950fb0":"#PassengerId column is not giving any info regarding survival probablity. So, we are removing them.\nfor dataset in combine:\n    dataset.drop(['PassengerId','Cabin','Name'], inplace=True, axis=1)","117d6248":"plt.figure(figsize=(10,5))\nsns.countplot(x='Survived',hue='SibSp',data=df_train)","6a831213":"for dataset in combine:\n    dataset['Familysize']=dataset['SibSp']+dataset['Parch']+1","1f1566c9":"plt.figure(figsize=(10,5))\nsns.countplot(x='Familysize',hue='Survived',data=df_train)","f0b8a44a":"def Family_Value(size):\n    if size==1:\n        return 'alone'\n    elif size>1 and size<5:\n        return 'small'\n    else:\n        return 'big'","e0b614f9":"for dataset in combine:\n    dataset['Familysize']=dataset['Familysize'].apply(Family_Value)\n    dataset.drop(['SibSp','Parch'], axis=1, inplace=True)","d1aa4911":"sns.pointplot(x='Familysize',y='Survived',data=df_train)\n","658c966b":"# Fare Column \ndf_train.Fare.describe()","655660d2":"df_train.Fare.isna().sum()","47691406":"df_test.Fare.isna().sum()","d8e5ae6b":"df_test[df_test.Fare.isna()]","ab87815e":"def missing_fare(df):\n    median_fare=df[(df['Pclass'] == 3) & (df['Embarked'] == 'S')]['Fare'].median()\n    df[\"Fare\"] = df[\"Fare\"].fillna(median_fare)\n    return df\n\ndf_test=missing_fare(df_test)","1791bdca":"for dataset in combine:\n    dataset.drop('Ticket',inplace=True,axis=1)\n    dataset['FareBin'] = pd.qcut(dataset['Fare'], 4)\n# In training data the embarked column has two null values \ndf_train[df_train.Embarked.isna()]","d11f61ce":"sns.boxplot(x='Embarked',y='Fare',data=df_train)","c9aeaf02":"df_train.Embarked=df_train.Embarked.fillna('C')","5b0b76c6":"print(df_test.columns)\nprint(df_train.columns)","3ca02f5f":"from sklearn.preprocessing import StandardScaler,LabelEncoder\nscaled=StandardScaler()\nlabel_encoded=LabelEncoder()","efcc6a7f":"# Label Encoding of Categorical Columns\ncat=['Embarked','Title','Familysize','Sex','AgeBin','FareBin']\nfor i in cat:\n    df_train[i]=label_encoded.fit_transform(df_train[i])\n    df_test[i]=label_encoded.fit_transform(df_test[i])","695a63a9":"def alone_column(familysize):\n    if int(familysize)>1:\n        return 0\n    else:\n        return 1\nfor dataset in combine:\n    dataset['Alone']=dataset['Familysize'].apply(alone_column)","11f8693b":"plt.title('Surviving probability against Alone ')\nsns.pointplot(x='Alone',y='Survived',data=df_train)","3b118eae":"df_train.head()","24bc04ba":"plt.figure(figsize=(12,6))\nplt.title('Correlation Table of training data')\nsns.heatmap(df_train.corr(),annot=True,cmap='Reds')","ac840724":"plt.figure(figsize=(10,5))\nsns.countplot(x='Familysize',hue='Survived',data=df_train)\nplt.title('Surviving Probabillity by Familysize')","697f35aa":"print(df_test.isna().sum())\nprint('-'*16)\nprint(df_train.isna().sum())","3d7a6e1f":"df_train.head()\ny=df_train.Survived\ndf_train.drop('Survived',axis=1,inplace=True)","4e7f5f15":"# Standard scaling all the data and test data   (Optional)\n#ss=StandardScaler()\n#scale_train=ss.fit_transform(df_train)\n#df_scaled_train=pd.DataFrame(scale_train,columns=df_train.columns)\n#scale_test=ss.fit_transform(df_test)\n#df_scaled_test=pd.DataFrame(scale_test,columns=df_test.columns)","7b76fcf7":"dropping_columns=['Age','Fare','FareBin','AgeBin','Sex','Familysize']\nX=df_train.drop(dropping_columns,axis=1)\nY=df_test.drop(dropping_columns,axis=1)\nX.columns","90c85250":"from sklearn.model_selection import cross_val_score, GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC","3c3ba56b":"lg=LogisticRegression()\ntr=DecisionTreeClassifier(max_depth=7,min_samples_split=2,random_state=1)\nknn=KNeighborsClassifier(n_neighbors=10)\nrf=RandomForestClassifier(n_estimators=50)\nsvm=SVC()\nparam_grid={'C':[0.1,1,10,100],'gamma':[1,0.1,0.01]}  # We will find the best parameters using gridsearch\ngrid=GridSearchCV(SVC(),param_grid,verbose=3)","89755ac8":"print('KNeighborsClassifier:',cross_val_score(knn, X,y, cv=20,scoring='accuracy').mean())\nprint('LogisticRegression:',cross_val_score(lg, X,y, cv=20,scoring='accuracy').mean())\nprint('DecisionTreeClassifier:',cross_val_score(tr, X,y, cv=20,scoring='accuracy').mean())\nprint('RandomForestClassifier:',cross_val_score(rf, X,y, cv=20,scoring='accuracy').mean())\nprint('SupportVectorClassifier:',cross_val_score(svm, X,y, cv=20,scoring='accuracy').mean())","1e6882d7":"#Now grid_search\ngrid.fit(X,y)","41c572ef":"grid.best_estimator_","bafb66e7":"#error_rate=[]\n#for i in range(1,40):\n    #knn=KNeighborsClassifier(n_neighbors=i)\n    #print(i,cross_val_score(knn, X,y, cv=5,scoring='accuracy').mean())","028a1687":"#lg=LogisticRegression()\n#knn=KNeighborsClassifier(n_neighbors=10)\n#tr=DecisionTreeClassifier(max_depth=7,min_samples_split=2,random_state=1)\n#rf=RandomForestClassifier(n_estimators=50)","1ab34af7":"#lg.fit(X,y)\n#knn.fit(X,y)\n#tr.fit(X,y)\n#rf.fit(X,y)","b0e8d9a8":"#predict_lg=lg.predict(Y)\n#predict_knn=knn.predict(Y)\n#predict_tr=tr.predict(Y)\n#predict_rf=rf.predict(Y)\ngrid_predictions=grid.predict(Y)","00cac7d5":"submission=pd.DataFrame({'PassengerId':test.PassengerId,'Survived':grid_predictions})\nsubmission.to_csv('submission_grid.csv',index=False)","5fa433a0":"**Model Training, cross-validating and predicting**","1c3aee50":"***We can see 'Cabin', 'Age' and 'Embarked' columns are missing some values. Cabin columns are missing a large portion of data.* \nMissing Value Imputation in Age Column:**","d9f1d2e1":"**Chosing best k value for kneighbors algorithm**","57814a84":"**From the above graph it is evident that embarked from 'C' has a median of 80(Fare).**","ec181ff4":"**> I have got the best result from training only the 'Pclass', 'Embarked',,'Title','Alone' columns.**","5cc2d713":"**Low frequent Titles are grouped in one category**","982376eb":"**Now we train the whole train set and test the data against the model**","0ae7f9a4":"***> We could make the 'Alone' column earlier. But it seemed easier now after Label Encoding the 'Familysize' column.***","9e713bdc":"**Converting Age into AgeBin**","a286bbf5":"**We can see from the above two countplots that those who had neither any spouse\/children nor any parents were mostly died. So, we can create a new column: 'Familysize'.**","6606f1bf":"**Preprocessing of Data for categorical and numerical values**","132dd548":"**We will drop the Cabin column and also Ampute those two null('Embarked') columns in the df_train dataframe.**","e02b079c":"We will plot some figures to get a better understanding of the correlating data columns. ","a4d8e74f":"**Now here, we will divide the Family size category into 3 values. Alone 1, 2-4 size into 2 and rest of them in the 3 value.**","fa57dd39":"> **Double Checking for Null values**","67c3c4c7":"**Dropping the Ticket column and creating FareBin column from Fare.**","b6fdb9f6":"**The name column can be used to extract titles which could be helpful data**","fdbeea2a":"**Splitting the 'Survived' Column and droping columns from combine**"}}