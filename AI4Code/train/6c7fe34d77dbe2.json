{"cell_type":{"dc726463":"code","586e99a1":"code","9865b415":"code","6b9b67be":"code","4711d69b":"code","bbd623b8":"code","437215df":"code","56d55b3a":"code","9aa48a02":"code","8178e2e1":"code","76f02724":"code","d3fa85e6":"code","a798a052":"code","260b713c":"code","b3ea3f2b":"code","55d78dd7":"code","d163efdd":"code","02fa0262":"code","c13d964e":"code","758449b3":"code","f533403c":"code","9f564896":"code","d2696ecb":"code","c1565b19":"code","8551f43b":"code","156aa9a1":"code","ec648ce7":"code","e6cc7e55":"code","b5843408":"code","9e15203f":"code","d90ca762":"code","3c51cb3e":"code","f6df2698":"code","7e342dcd":"code","7e8ad645":"code","1c218858":"code","d09db6eb":"code","1ffc8148":"code","75ecb705":"code","43ce5b7c":"code","a976a333":"code","e2971caa":"code","48d2518f":"code","0a8cd4ec":"code","0b9123d3":"code","9fef3d10":"code","ad5a30fa":"code","d0a09e05":"code","61c1c1ea":"code","9f29b309":"code","04274e94":"code","22ffe289":"code","e20b2e2c":"markdown","911840d8":"markdown","3cab4c62":"markdown","90017a05":"markdown","f612a615":"markdown","b648f3d7":"markdown","6aef791c":"markdown","856dfbff":"markdown","ddcac3f5":"markdown"},"source":{"dc726463":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","586e99a1":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","9865b415":"app_df=pd.read_csv('..\/input\/googleplaystore.csv')","6b9b67be":"app_df.head(10)","4711d69b":"app_df.shape","bbd623b8":"#App, Category, Content rating, Genres, Current Ver and Android Ver are consided as less relative to Rating\n#and Type & Price are repesent same meaning, so just keep one, use Price can also show whether it is free or not.\n#we keep Category temporarily for later usage as groupby() function.\ndrop_list=['App','Content Rating', 'Genres', 'Current Ver', 'Android Ver','Type']\napp_df2=app_df.drop(drop_list,axis=1)\napp_df2.head()","437215df":"app_df2.isna().sum()","56d55b3a":"app_df2.groupby('Category')['Rating'].mean()","9aa48a02":"#The mean of Rating with different Category is similar so just fill the null value with the mean of Rating\n#instead of drop them.\napp_df2.fillna(app_df2['Rating'].mean(),inplace= True)\napp_df2.isna().sum()","8178e2e1":"#it also finds a abnormal value in Caategory = 1.9 and relative Rating is 19.0\napp_df2[app_df2['Category']=='1.9']","76f02724":"#delete this abnormal recorde \napp_df2=app_df2[app_df2.Rating!=19.0]","d3fa85e6":"#Here, we assume the purpose is to predict whether a possible rating is positive or not. \n#we can set that rating higher than 4 as a positive rating transformed as 1 and others as 0, \n\napp_df2.Rating=np.where(app_df2.Rating<4,0,1)","a798a052":"app_df2.Rating.value_counts()","260b713c":"#change date type to numerical.\napp_df2.dtypes","b3ea3f2b":"#transform values in Installs to numerical by applying function delete '+' and ','\napp_df2['Installs']=app_df2['Installs'].astype('str')\napp_df2['Installs'] = app_df2['Installs'].apply(lambda x : x.strip('+').replace(',', ''))","55d78dd7":"#change data type of Installs and Reviews to int\napp_df2['Installs']=app_df2['Installs'].astype(int)\napp_df2['Reviews']=app_df2['Reviews'].astype(int)","d163efdd":"app_df2.head()","02fa0262":"#define a function to clean Size, first delete 'k' and 'M' and then transform to float\n#change units of kb to Mb (1 Mb = 1024 kb) \n#'Various of device' change to NaN.\ndef k_transform(size):\n    if 'k' in size:\n        x=float(size.strip('k'))\n        return round((x\/1024),3)\n    elif 'M' in size:\n        x=float(size.strip('M'))\n        return x\n    else:\n        size = np.nan\n        return size","c13d964e":"#apply k_transform to Size.\napp_df2['Size']=app_df2['Size'].apply(k_transform)","758449b3":"#fill Nan value in Size with mean of different Category, by groupby()\n#instead of drop them.\napp_df2['Size'].fillna(app_df2.groupby('Category')['Size'].transform('mean'), inplace=True)","f533403c":"app_df2['Size'].isna().sum()","9f564896":"app_df2.head()","d2696ecb":"# delete $ in Price and transform to float.\napp_df2.Price=app_df2.Price.astype('str')\napp_df2.Price=app_df2.Price.apply(lambda x : x.strip('$'))\napp_df2.Price=app_df2.Price.astype(float)","c1565b19":"app_df2.Price.unique()","8551f43b":"#Last updated can be transform to year only, set 2019 as 0, 2018 as 1, 2016 as 2 and so on\napp_df2['Last Updated'] = app_df2['Last Updated'].str[-4:]","156aa9a1":"app_df2['Last Updated'].unique()","ec648ce7":"app_df2['Last Updated']= np.where(app_df2['Last Updated']=='2018',1,\n                        np.where(app_df2['Last Updated']=='2017',2,\n                        np.where(app_df2['Last Updated']=='2016',3,\n                        np.where(app_df2['Last Updated']=='2015',4,\n                        np.where(app_df2['Last Updated']=='2014',5,\n                        np.where(app_df2['Last Updated']=='2013',6,\n                        np.where(app_df2['Last Updated']=='2012',7,\n                        np.where(app_df2['Last Updated']=='2011',8,9))))))))","e6cc7e55":"app_df2['Last Updated'].unique()","b5843408":"#after clean and transform all columns, delete Category \napp_df2.drop('Category',inplace=True,axis=1)\napp_df2.head()","9e15203f":"app_df2.Rating.hist()","d90ca762":"from sklearn.model_selection import train_test_split\n#split train data and test data\nX_train, X_test, Y_train, Y_test = train_test_split(app_df2[['Reviews','Size','Installs','Price','Last Updated']], app_df2['Rating'], test_size = 0.2, random_state=5)\n\n# print the shapes to check everything is OK\nprint(X_train.shape)\nprint(X_test.shape)\nprint(Y_train.shape)\nprint(Y_test.shape)","3c51cb3e":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\ntuned_parameters = [{'penalty': ['l1', 'l2'],\n                     'C': [0.5, 1, 5, 10]}]\n\nscores = ['precision', 'recall', 'f1']\n\nfor score in scores:\n    print(\"# Tuning hyperparameters for %s\" % score)\n    print(\"\\n\")\n    clf = GridSearchCV(LogisticRegression(), tuned_parameters, cv=5,\n                       scoring='%s_macro' % score)\n    clf.fit(X_train, Y_train)\n    print(\"Best parameters set found on the training set:\")\n    print(clf.best_params_)\n    print(\"\\n\")","f6df2698":"#use the best parameters for f1 socre\nlr = LogisticRegression(C= 0.5, penalty = 'l2')\n\n# fit the model using some training data\nlr_fit = lr.fit(X_train, Y_train)\n\n# generate a mean accuracy score for the predicted data\ntrain_score = lr.score(X_train, Y_train)\n\n# print the mean accuracy of testing predictions\nprint(\"Accuracy score = \" + str(round(train_score, 4)))","7e342dcd":"predicted = lr.predict(X_test)\n\n# generate a mean accuracy score for the predicted data\ntest_score = lr.score(X_test, Y_test)\n\n# print the mean accuracy of testing predictions\nprint(\"Accuracy score = \" + str(round(test_score, 4)))","7e8ad645":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.utils.multiclass import unique_labels\nfrom sklearn.metrics import confusion_matrix\n\nclass_names=np.array(['negative','positive'])\n\ndef plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    # Only use the labels that appear in the data\n    classes = classes[unique_labels(y_true, y_pred)]\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    fig, ax = plt.subplots()\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           # ... and label them with the respective list entries\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax\n\n\nnp.set_printoptions(precision=2)\n\n# Plot non-normalized confusion matrix\nplot_confusion_matrix(Y_test, predicted, classes=class_names,\n                      title='Confusion matrix, without normalization')\n\n# Plot normalized confusion matrix\nplot_confusion_matrix(Y_test, predicted, classes=class_names, normalize=True,\n                      title='Normalized confusion matrix')\n\nplt.show()","1c218858":"#install imblearn package firstly if it is not installed.\ntry:\n    import imblearn\nexcept ImportError:\n    !pip install -U imbalanced-learn","d09db6eb":"# import SMOTE model and fit model with X_train and Y_train\n#we just want to oversmaple training data and keep testing data unchanged.\nfrom imblearn.over_sampling import SMOTE\nimport collections\nX=X_train\nY=Y_train\nX_resampled, Y_resampled = SMOTE().fit_resample(X, Y)\n#print the count of each class (0 and 1 ).\nprint(sorted(collections.Counter(Y_resampled).items()))\n#Now we have balanced class number.","1ffc8148":"tuned_parameters = [{'penalty': ['l1', 'l2'],\n                     'C': [0.5, 1, 5, 10]}]\n\nscores = ['precision', 'recall', 'f1']\n\nfor score in scores:\n    print(\"# Tuning hyperparameters for %s\" % score)\n    print(\"\\n\")\n    clf = GridSearchCV(LogisticRegression(), tuned_parameters, cv=5,\n                       scoring='%s_macro' % score)\n    #use resampled data\n    clf.fit(X_resampled, Y_resampled)\n    print(\"Best parameters set found on the training set:\")\n    print(clf.best_params_)\n    print(\"\\n\")","75ecb705":"#use the best parameters for f1 socre\nlr = LogisticRegression(C= 1, penalty = 'l1')\n\n# fit the model using some resample data\nlr_fit = lr.fit(X_resampled, Y_resampled)\n\n# generate a mean accuracy score for the predicted data\ntrain_score = lr.score(X_resampled, Y_resampled)\n\n# print the mean accuracy of testing predictions\nprint(\"Accuracy score = \" + str(round(train_score, 4)))","43ce5b7c":"predicted = lr.predict(X_test)\n\n# generate a mean accuracy score for the predicted data\ntest_score = lr.score(X_test, Y_test)\n\n# print the mean accuracy of testing predictions\nprint(\"Accuracy score = \" + str(round(test_score, 4)))","a976a333":"# Plot non-normalized confusion matrix\nplot_confusion_matrix(Y_test, predicted, classes=class_names,\n                      title='Confusion matrix, without normalization')\n\n# Plot normalized confusion matrix\nplot_confusion_matrix(Y_test, predicted, classes=class_names, normalize=True,\n                      title='Normalized confusion matrix')\n\nplt.show()\n#after oversampling, the prediction of negative improved highly.","e2971caa":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\ntuned_parameters = [{'criterion': ['gini','entropy'],\n                     'splitter':['random','best'],\n                     'max_depth': [1,2,3], \n                     'max_features': ['sqrt','log2',None]}]\nscores = ['precision', 'recall', 'f1']\n\nfor score in scores:\n    print(\"# Tuning hyperparameters for %s\" % score)\n    print(\"\\n\")\n    clf = GridSearchCV(DecisionTreeClassifier(), tuned_parameters, cv=5,\n                       scoring= '%s_macro' % score)\n    clf.fit(X_resampled, Y_resampled)\n    print(\"Best parameters set found on the training set:\")\n    print(clf.best_params_)\n    print(\"\\n\")","48d2518f":"#use the best parameters for f1 socre\ndec = DecisionTreeClassifier(criterion='gini',max_depth=2, max_features='sqrt', splitter='best')\n\n# fit the model using some resample data\ndec_fit = dec.fit(X_resampled, Y_resampled)\n\n# generate a mean accuracy score for the predicted data\ntrain_score = dec.score(X_resampled, Y_resampled)\n\n# print the mean accuracy of testing predictions\nprint(\"Accuracy score = \" + str(round(train_score, 4)))","0a8cd4ec":"predicted = dec.predict(X_test)\n\n# generate a mean accuracy score for the predicted data\ntest_score = dec.score(X_test, Y_test)\n\n# print the mean accuracy of testing predictions\nprint(\"Accuracy score = \" + str(round(test_score, 4)))","0b9123d3":"# Plot non-normalized confusion matrix\nplot_confusion_matrix(Y_test, predicted, classes=class_names,\n                      title='Confusion matrix, without normalization')\n\n# Plot normalized confusion matrix\nplot_confusion_matrix(Y_test, predicted, classes=class_names, normalize=True,\n                      title='Normalized confusion matrix')\n\nplt.show()","9fef3d10":"from sklearn.neighbors import KNeighborsClassifier\ntuned_parameters = [{'weights': ['uniform','distance'], \n                    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}]\n\nscores = ['precision', 'recall', 'f1']\n\nfor score in scores:\n    print(\"# Tuning hyperparameters for %s\" % score)\n    print(\"\\n\")\n    clf = GridSearchCV(KNeighborsClassifier(), tuned_parameters, cv=5,\n                       scoring= '%s_macro' % score)\n    clf.fit(X_resampled, Y_resampled)\n    print(\"Best parameters set found on the training set:\")\n    print(clf.best_params_)\n    print(\"\\n\")","ad5a30fa":"#use the best parameters for f1 socre\nknn = KNeighborsClassifier(algorithm= 'brute', weights='distance')\n\n# fit the model using some training data\nknn_fit = knn.fit(X_train, Y_train)\n\n# generate a mean accuracy score for the predicted data\ntrain_score = knn.score(X_train, Y_train)\n\n# print the mean accuracy of testing predictions\nprint(\"Accuracy score = \" + str(round(train_score, 4)))","d0a09e05":"predicted = knn.predict(X_test)\n\n# generate a mean accuracy score for the predicted data\ntest_score = knn.score(X_test, Y_test)\n\n# print the mean accuracy of testing predictions\nprint(\"Accuracy score = \" + str(round(test_score, 4)))","61c1c1ea":"# Plot non-normalized confusion matrix\nplot_confusion_matrix(Y_test, predicted, classes=class_names,\n                      title='Confusion matrix, without normalization')\n\n# Plot normalized confusion matrix\nplot_confusion_matrix(Y_test, predicted, classes=class_names, normalize=True,\n                      title='Normalized confusion matrix')\n\nplt.show()","9f29b309":"from sklearn.ensemble import VotingClassifier\nclf1 = LogisticRegression(C= 1, penalty = 'l1')\nclf2 = DecisionTreeClassifier(criterion='gini',max_depth=2, max_features='sqrt', splitter='best')\nclf3 = KNeighborsClassifier(algorithm= 'brute', weights='distance')\n# 'soft' voting is choosed, because the result is better comparing with 'hard'.\neclf1 = VotingClassifier(estimators=[('lr', clf1), ('dec',clf2),('knn', clf3)], voting='soft')\n#fit with resampled data as usual.\neclf1 = eclf1.fit(X_resampled, Y_resampled)\ntrain_score = eclf1.score(X_resampled, Y_resampled)\nprint(\"Accuracy score = \" + str(round(train_score, 4)))","04274e94":"predicted = eclf1.predict(X_test)\n\n# generate a mean accuracy score for the predicted data\ntest_score = eclf1.score(X_test, Y_test)\n\n# print the mean accuracy of testing predictions\nprint(\"Accuracy score = \" + str(round(test_score, 4)))","22ffe289":"np.set_printoptions(precision=2)\n\n# Plot non-normalized confusion matrix\nplot_confusion_matrix(Y_test, predicted, classes=class_names,\n                      title='Confusion matrix, without normalization')\n\n# Plot normalized confusion matrix\nplot_confusion_matrix(Y_test, predicted, classes=class_names, normalize=True,\n                      title='Normalized confusion matrix')\n\nplt.show()","e20b2e2c":"#  Imbalance\n\n### We can see from the matrix result, it is very good at predict positive rating, but bad at negative rating. That is beacuse the sample is imbalanced. Marjor class is usual better predicted. Here, we are going to use SMOTE method to handle this imbalanced data. Just oversmaple training data.","911840d8":"##  K-NN","3cab4c62":"# Algorithm Voting\n    \n### from matrix results of three algoritms, it can be seen that Logistic Regression is better at prediction of negative, while Decision Tree and K-NN are better at prediction of positive. Thence, we need build a voting model to imporve prediction on both.  ","90017a05":"## Logistic Regression","f612a615":"# Conclusion\n\n### After voting, we can see the result is imporved a lot than single algorithm, it predicts negative and positive both good.","b648f3d7":"##  Decision tree","6aef791c":"##  Logistic Regression","856dfbff":"#  Model Tuning\n    \n### After cleaning and transforming data, we can move to model tuning, Rating is discrete data, binary model is suggested. here is going to use Decision tree, logistic Regression and K-NN as selected model.","ddcac3f5":"# Clean and Transfrom data\n    \n### Keep columns maybe related to Rating, and clean them for example delete Nan value and change data type. Besides, it needs to transfrom some data like date and categroies for further model tuning."}}