{"cell_type":{"820695e8":"code","6d95cad2":"code","13c5b8ec":"code","30149dde":"code","475b029e":"code","1bbca568":"code","67fda8de":"code","c63bc6a2":"code","4da1b3b8":"code","80bbad0c":"code","09469d1d":"code","11ffd4bb":"code","76fe3c19":"markdown","2c4a271b":"markdown","6443f2a0":"markdown","63ad2304":"markdown","bad63d2b":"markdown","f7d887b4":"markdown","4c9affae":"markdown"},"source":{"820695e8":"CKPT_PATH1 = '..\/input\/v5testpt\/best.pt'\nCONF1      = 0.16\nIOU1       = 0.45\nCKPT_PATH2 = '..\/input\/v5testpt\/best.pt'\nCONF2      = 0.17\nIOU2       = 0.45\nCKPT_PATH3 = '..\/input\/v5testpt\/best.pt'\nCONF3      = 0.25\nIOU3       = 0.45","6d95cad2":"import warnings\nimport os\nimport cv2\n\nimport glob\nimport shutil\nimport sys\nimport torch\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nwarnings.filterwarnings(\"ignore\")\nimport numpy as np\nfrom tqdm.notebook import tqdm\ntqdm.pandas()\nimport pandas as pd\n\nfrom tqdm.notebook import tqdm\n\nimport ast\nsys.path.append('..\/input\/ensemble-boxes-104\/ensemble_boxes-1.0.4')\nfrom ensemble_boxes import *","13c5b8ec":"!mkdir -p \/root\/.config\/Ultralytics\n!cp \/kaggle\/input\/yolo-arial\/Arial.ttf \/root\/.config\/Ultralytics\/","30149dde":"def voc2yolo(bboxes, image_height=720, image_width=1280):\n    \"\"\"\n    voc  => [x1, y1, x2, y1]\n    yolo => [xmid, ymid, w, h] (normalized)\n    \"\"\"\n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]\/ image_width\n    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]\/ image_height\n    w = bboxes[..., 2] - bboxes[..., 0]\n    h = bboxes[..., 3] - bboxes[..., 1]\n    bboxes[..., 0] = bboxes[..., 0] + w\/2\n    bboxes[..., 1] = bboxes[..., 1] + h\/2\n    bboxes[..., 2] = w\n    bboxes[..., 3] = h\n    return bboxes\n\ndef yolo2voc(bboxes, image_height=720, image_width=1280):\n    \"\"\"\n    yolo => [xmid, ymid, w, h] (normalized)\n    voc  => [x1, y1, x2, y1]\n\n    \"\"\"\n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]\/2\n    bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n    return bboxes\n\ndef coco2yolo(bboxes, image_height=720, image_width=1280):\n    \"\"\"\n    coco => [xmin, ymin, w, h]\n    yolo => [xmid, ymid, w, h] (normalized)\n    \"\"\"\n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    # normolizinig\n    bboxes[..., [0, 2]]= bboxes[..., [0, 2]]\/ image_width\n    bboxes[..., [1, 3]]= bboxes[..., [1, 3]]\/ image_height\n    # converstion (xmin, ymin) => (xmid, ymid)\n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\/2\n    return bboxes\n\ndef yolo2coco(bboxes, image_height=720, image_width=1280):\n    \"\"\"\n    yolo => [xmid, ymid, w, h] (normalized)\n    coco => [xmin, ymin, w, h]\n    \"\"\"\n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    # denormalizing\n    bboxes[..., [0, 2]]= bboxes[..., [0, 2]]* image_width\n    bboxes[..., [1, 3]]= bboxes[..., [1, 3]]* image_height\n    # converstion (xmid, ymid) => (xmin, ymin)\n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]\/2\n    return bboxes\n\ndef voc2coco(bboxes, image_height=720, image_width=1280):\n    bboxes  = voc2yolo(bboxes, image_height, image_width)\n    bboxes  = yolo2coco(bboxes, image_height, image_width)\n    return bboxes\n\ndef load_image(image_path):\n    return cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n\ndef plot_one_box(x, img, color=None, label=None, line_thickness=None):\n    # Plots one bounding box on image img\n    tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) \/ 2) + 1  # line\/font thickness\n    color = color or [random.randint(0, 255) for _ in range(3)]\n    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n    cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n    if label:\n        tf = max(tl - 1, 1)  # font thickness\n        t_size = cv2.getTextSize(label, 0, fontScale=tl \/ 3, thickness=tf)[0]\n        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n        cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled\n        cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl \/ 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n\ndef draw_bboxes(img, bboxes, classes, class_ids, colors = None, show_classes = None, bbox_format = 'yolo', class_name = False, line_thickness = 2):\n\n    image = img.copy()\n    show_classes = classes if show_classes is None else show_classes\n    colors = (0, 255 ,0) if colors is None else colors\n\n    if bbox_format == 'yolo':\n\n        for idx in range(len(bboxes)):\n\n            bbox  = bboxes[idx]\n            cls   = classes[idx]\n            cls_id = class_ids[idx]\n            color = colors[cls_id] if type(colors) is list else colors\n\n            if cls in show_classes:\n\n                x1 = round(float(bbox[0])*image.shape[1])\n                y1 = round(float(bbox[1])*image.shape[0])\n                w  = round(float(bbox[2])*image.shape[1]\/2) #w\/2\n                h  = round(float(bbox[3])*image.shape[0]\/2)\n\n                voc_bbox = (x1-w, y1-h, x1+w, y1+h)\n                plot_one_box(voc_bbox,\n                             image,\n                             color = color,\n                             label = cls if class_name else str(get_label(cls)),\n                             line_thickness = line_thickness)\n\n    elif bbox_format == 'coco':\n\n        for idx in range(len(bboxes)):\n\n            bbox  = bboxes[idx]\n            cls   = classes[idx]\n            cls_id = class_ids[idx]\n            color = colors[cls_id] if type(colors) is list else colors\n\n            if cls in show_classes:\n                x1 = int(round(bbox[0]))\n                y1 = int(round(bbox[1]))\n                w  = int(round(bbox[2]))\n                h  = int(round(bbox[3]))\n\n                voc_bbox = (x1, y1, x1+w, y1+h)\n                plot_one_box(voc_bbox,\n                             image,\n                             color = color,\n                             label = cls if class_name else str(cls_id),\n                             line_thickness = line_thickness)\n\n    elif bbox_format == 'voc_pascal':\n\n        for idx in range(len(bboxes)):\n\n            bbox  = bboxes[idx]\n            cls   = classes[idx]\n            cls_id = class_ids[idx]\n            color = colors[cls_id] if type(colors) is list else colors\n\n            if cls in show_classes:\n                x1 = int(round(bbox[0]))\n                y1 = int(round(bbox[1]))\n                x2 = int(round(bbox[2]))\n                y2 = int(round(bbox[3]))\n                voc_bbox = (x1, y1, x2, y2)\n                plot_one_box(voc_bbox,\n                             image,\n                             color = color,\n                             label = cls if class_name else str(cls_id),\n                             line_thickness = line_thickness)\n    else:\n        raise ValueError('wrong bbox format')\n\n    return image\n\ndef show_img(img, bboxes, bbox_format='yolo', bbox_colors = None):\n    names  = ['starfish']*len(bboxes)\n    labels = [0]*len(bboxes)\n    img    = draw_bboxes(img = img,\n                           bboxes = bboxes,\n                           classes = names,\n                           class_ids = labels,\n                           class_name = True,\n                           colors = colors if bbox_colors is None else bbox_colors,\n                           bbox_format = bbox_format,\n                           line_thickness = 2)\n    return Image.fromarray(img).resize((800, 400))\n\ndef get_bbox(annots):\n    bboxes = [list(annot.values()) for annot in annots]\n    return bboxes\n\ndef get_imgsize(row):\n    row['width'], row['height'] = imagesize.get(row['image_path'])\n    return row\n\nnp.random.seed(32)\ncolors = [(np.random.randint(255), np.random.randint(255), np.random.randint(255))\\\n          for idx in range(1)]\n\n\ndef load_model(ckpt_path, conf=0.25, iou=0.50):\n    model = torch.hub.load('\/kaggle\/input\/yolov5-lib-ds',\n                           'custom',\n                           path=ckpt_path,\n                           source='local',\n                           force_reload=True)  # local repo\n    model.conf = conf  # NMS confidence threshold\n    model.iou  = iou  # NMS IoU threshold\n    return model\n\ndef predict(model, img, size=768, augment=False):\n    height, width = img.shape[:2]\n    results = model(img, size=size, augment=augment)  # custom inference size\n    preds   = results.pandas().xyxy[0]\n    bboxes  = preds[['xmin','ymin','xmax','ymax']].values\n    if len(bboxes):\n        bboxes  = voc2coco(bboxes,height,width).astype(int)\n        confs   = preds.confidence.values\n        classes  = preds.name.values\n        return bboxes, confs,classes\n    else:\n        return [],[],[]\n\ndef format_prediction(bboxes, confs):\n    annot = ''\n    if len(bboxes)>0:\n        for idx in range(len(bboxes)):\n            xmin, ymin, w, h = bboxes[idx]\n            conf             = confs[idx]\n            annot += f'{conf} {xmin} {ymin} {w} {h}'\n            annot +=' '\n        annot = annot.strip(' ')\n    return annot\n\n","475b029e":"CKPT_PATH1 = '..\/input\/v5testpt\/best.pt'\nCONF1      = 0.16\nIOU1       = 0.45\nCKPT_PATH2 = '..\/input\/v5testpt\/best.pt'\nCONF2      = 0.17\nIOU2       = 0.45\nCKPT_PATH3 = '..\/input\/v5testpt\/best.pt'\nCONF3      = 0.25\nIOU3       = 0.45\n#--------------------------------------------------------------------------\nmodel1 = load_model(CKPT_PATH1, conf=CONF1, iou=IOU1) \nmodel2 = load_model(CKPT_PATH2, conf=CONF2, iou=IOU2)\nmodel3 = load_model(CKPT_PATH3, conf=CONF3, iou=IOU3)","1bbca568":"\nTEST_IMAGE_PATH = \"\/kaggle\/input\/tensorflow-great-barrier-reef\/train_images\/video_2\/5747.jpg\"\nimg = cv2.imread(TEST_IMAGE_PATH)\n#--------------------------------------------------------------------------\nIMG_SIZE  = 3600\nAUGMENT   = True\n#--------------------------------------------------------------------------\nbboxes1, scores1 ,bbclasses1  = predict(model1, img, size=IMG_SIZE, augment=AUGMENT)\nbboxes2, scores2 ,bbclasses2  = predict(model2, img, size=IMG_SIZE, augment=AUGMENT)\nbboxes3, scores3 ,bbclasses3  = predict(model3, img, size=IMG_SIZE, augment=AUGMENT)\n#--------------------------------------------------------------------------\nout_image=draw_bboxes(img = img,\n                        bboxes = bboxes1, \n                        classes = [\"model1\"]*len(bboxes1),\n                        class_ids = [0]*len(bboxes1),\n                        class_name = True, \n                        colors = (0,0,130), \n                        bbox_format = 'coco',\n                        line_thickness = 2)\n\nout_image=draw_bboxes(img = out_image,\n                        bboxes = bboxes2, \n                        classes = [\"    model2\"]*len(bboxes2),\n                        class_ids = [0]*len(bboxes2),\n                        class_name = True, \n                        colors = (0,130,0), \n                        bbox_format = 'coco',\n                        line_thickness = 2)\nout_image=draw_bboxes(img = out_image,\n                        bboxes = bboxes3, \n                        classes = [\"     model3\"]*len(bboxes3),\n                        class_ids = [0]*len(bboxes3),\n                        class_name = True, \n                        colors = (255,0,0), \n                        bbox_format = 'coco',\n                        line_thickness = 2)\n\nout_image = cv2.cvtColor(out_image, cv2.COLOR_BGR2RGB)\ndisplay(Image.fromarray(out_image))\n\n\n\n\nbboxes1[:, 2] = bboxes1[:, 2] + bboxes1[:, 0]\nbboxes1[:, 3] = bboxes1[:, 3] + bboxes1[:, 1]\nbboxes2[:, 2] = bboxes2[:, 2] + bboxes2[:, 0]\nbboxes2[:, 3] = bboxes2[:, 3] + bboxes2[:, 1]\nbboxes3[:, 2] = bboxes3[:, 2] + bboxes3[:, 0]\nbboxes3[:, 3] = bboxes3[:, 3] + bboxes3[:, 1]\n\n\n\n\n\n","67fda8de":"\n\n\ndef run_wbf(bboxes, confs,classs, image_size, iou_thr=0.50, skip_box_thr=0.0001, weights=None):\n    boxes =  [bbox\/(image_size-1) for bbox in bboxes]\n    scores = [conf for conf in confs]    \n    labels = [np.ones(conf.shape[0]) for conf in confs]\n    boxes, scores, labels = weighted_boxes_fusion(boxes, scores, labels, weights=None, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n    boxes = boxes*(image_size-1)\n    return boxes, scores, labels","c63bc6a2":"#--------------------------------- Aug -----------------------------------------\niou_thr = 0.5\nskip_box_thr = 0.0001\nsigma = 0.01\nweights = [1, 1 ,1]\n#--------------------------------- List -----------------------------------------\nboxes_list=[bboxes1,bboxes2,bboxes3]\nscores_list=[scores1,scores2,scores3]\nlabels_list=[bbclasses1,bbclasses2,bbclasses3]\n\n\n\n\n\n#####################################  WBF  #####################################\nboxes, scores, labels  = run_wbf(boxes_list, scores_list,labels_list,IMG_SIZE, iou_thr, skip_box_thr,weights=weights)\nboxes[:, 2] = boxes[:, 2] - boxes[:, 0]\nboxes[:, 3] = boxes[:, 3] - boxes[:, 1]\nout_image_esemble=draw_bboxes(img = img,\n                        bboxes = boxes, \n                        classes = [\"WBF\"]*len(boxes),\n                        class_ids = [0]*len(boxes),\n                        class_name = True, \n                        colors = (50,50,50), \n                        bbox_format = 'coco',\n                        line_thickness = 2)\nout_image_esemble = cv2.cvtColor(out_image_esemble, cv2.COLOR_BGR2RGB)\nprint(\"------------------------------  WBF   ---------------------------------------\")\ndisplay(Image.fromarray(out_image_esemble))","4da1b3b8":"%cd \/kaggle\/working\/","80bbad0c":"import greatbarrierreef\nenv = greatbarrierreef.make_env()   # initialize the environment\niter_test = env.iter_test()  ","09469d1d":"Method =\"WBF\" # NMS,Soft-NMS,NMW or WBF\nIMG_SIZE  = 3600\nAUGMENT   = True\n#--------------------------------------------------------------------------\nmodel1 = load_model(CKPT_PATH1, conf=CONF1, iou=IOU1) \nmodel2 = load_model(CKPT_PATH2, conf=CONF2, iou=IOU2)\nmodel3 = load_model(CKPT_PATH3, conf=CONF3, iou=IOU3)\n#--------------------------------------------------------------------------\nfor idx, (img, pred_df) in enumerate(tqdm(iter_test)):\n    bboxes1, scores1,bbclasses1  = predict(model1, img, size=IMG_SIZE, augment=AUGMENT)\n    bboxes2, scores2,bbclasses2  = predict(model2, img, size=IMG_SIZE, augment=AUGMENT)\n    bboxes3, scores3,bbclasses3  = predict(model3, img, size=IMG_SIZE, augment=AUGMENT)\n    boxes_list=[]\n    scores_list=[]\n    labels_list=[]\n    \n    if len(bboxes1)>0:\n        boxes_list.append(bboxes1)\n        scores_list.append(scores1)\n        labels_list.append(bbclasses1) \n        bboxes1[:, 2] = bboxes1[:, 2] + bboxes1[:, 0]\n        bboxes1[:, 3] = bboxes1[:, 3] + bboxes1[:, 1]\n    if len(bboxes2)>0:\n        boxes_list.append(bboxes2)\n        scores_list.append(scores2)\n        labels_list.append(bbclasses2)\n        bboxes2[:, 2] = bboxes2[:, 2] + bboxes2[:, 0]\n        bboxes2[:, 3] = bboxes2[:, 3] + bboxes2[:, 1]\n    if len(bboxes3)>0:\n        boxes_list.append(bboxes3)\n        scores_list.append(scores3)\n        labels_list.append(bbclasses3)\n        bboxes3[:, 2] = bboxes3[:, 2] + bboxes3[:, 0]\n        bboxes3[:, 3] = bboxes3[:, 3] + bboxes3[:, 1]\n\n    if (len(bboxes1) + len(bboxes2) + len(bboxes3))>0:\n       \n\n        boxes, scores, labels  = run_wbf(boxes_list, scores_list,labels_list,IMG_SIZE, iou_thr, skip_box_thr,weights=weights)\n\n        boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n        boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n    else: boxes=[]\n    annot = format_prediction(boxes, scores)\n    pred_df['annotations'] = annot\n    env.predict(pred_df)\n    print(\"------------------------------  \" + Method +\"   ---------------------------------------\")\n    if idx<3:\n        display(show_img(img, boxes, bbox_format='coco'))","11ffd4bb":"sub_df = pd.read_csv('submission.csv')\nsub_df.head()","76fe3c19":"# \u73af\u5883\u51c6\u5907","2c4a271b":"# YoloV5","6443f2a0":"# Ensemble","63ad2304":"# \u6d4b\u8bd5","bad63d2b":"# \u5f00\u59cb\u9884\u6d4b","f7d887b4":"# \u6570\u636e\u8f93\u5165\n## ---- \u5b66\u4e60 \u81ea \u5176\u4ed6\u516c\u5f00\u4ee3\u7801","4c9affae":"# \u540e\u5904\u7406\u51fd\u6570\u5e93"}}