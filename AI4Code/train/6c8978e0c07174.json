{"cell_type":{"8f510221":"code","33be1799":"code","263493ec":"code","2ead51b0":"code","e4c121b9":"code","4a8e8517":"code","53bad229":"code","9760e759":"code","b6df2078":"code","f1a228ea":"code","2023fcd9":"code","afef2368":"code","61d432e3":"code","ef07cd77":"code","50cb5108":"code","a9d096c2":"code","fbb60f3e":"code","4031c7e2":"code","46ecd9ce":"code","04bf9b7e":"code","49446962":"code","965c548e":"code","2496366f":"code","58f8fda6":"code","bbf875ad":"code","c697871a":"code","524e8365":"code","c6d16ccc":"code","1d62081d":"code","70291582":"code","674f01e4":"code","a9e80d62":"code","d58553f3":"code","2b64e363":"code","70fa28fd":"code","cbbe4527":"code","63ff49d8":"code","78e66955":"code","3c288b5b":"code","1dc4a822":"code","ca445fee":"code","340a06ff":"code","b883523b":"code","5edca041":"code","e226eb64":"code","83c60c91":"code","be2b3312":"code","3bd55ab1":"code","a65b0e02":"code","f4bb846f":"code","06e0a470":"code","5698de5f":"code","9ab79c31":"code","0f298571":"code","2f31f736":"code","b7de2256":"code","78cfc059":"code","4d9d126d":"code","82362d4d":"code","d3bf6b8c":"code","ca1e55aa":"code","595d7259":"code","3f1f6397":"code","6c33f34f":"code","94fc17a8":"code","36fdecde":"code","aa6f757a":"code","378b1774":"code","21264c76":"code","86e31609":"code","be1d0621":"code","9e766b2d":"code","e686c725":"code","10a6b745":"code","022d5504":"code","db099860":"code","72222593":"code","1551ae98":"code","475d6996":"code","bb663ded":"code","47e5cbb7":"code","26841a66":"code","9a8e56d9":"code","34e6c455":"code","620e68b6":"code","01dabfb9":"code","cdc713a4":"code","faa89a0c":"code","48f43992":"code","846e0398":"code","397bc5f9":"code","1309a9a2":"code","846a36c1":"code","40034693":"code","e9929149":"code","1e8a6d6c":"code","39c7ed22":"markdown","8dbfcae3":"markdown","a85bcf6b":"markdown","6d20d4a7":"markdown","4c86d52c":"markdown","ea240aa2":"markdown","6069e1ce":"markdown","aa86feec":"markdown","646bc6ba":"markdown","acce195b":"markdown","975367cd":"markdown","cc39f3b1":"markdown","9dcc487b":"markdown","b631b86b":"markdown","8269440c":"markdown","3841824b":"markdown","18bb632c":"markdown","d43134b4":"markdown","e2567643":"markdown","41ba8ae7":"markdown","3990755b":"markdown","a9b7413b":"markdown","27cda5c4":"markdown","dfa8a026":"markdown","c9db700c":"markdown","01463b70":"markdown","efb8d8de":"markdown","8cf104b9":"markdown","06cb4b80":"markdown","94b3369b":"markdown","88ee02f2":"markdown","85679555":"markdown","7bc4b353":"markdown","9cd41832":"markdown","7939588a":"markdown","08d8588a":"markdown","ed787b34":"markdown","baef284c":"markdown","282f9ef1":"markdown","f9272090":"markdown","8cef9f3b":"markdown","6a23831e":"markdown","46e3de4c":"markdown"},"source":{"8f510221":"import numpy as np, pandas as pd\nimport matplotlib.pyplot as plt \nfrom sklearn.cluster import KMeans\nimport seaborn as sns\n%matplotlib inline","33be1799":"df=pd.read_csv('..\/input\/customer-personality-analysis\/marketing_campaign.csv',header=0,sep = '\\t')\ndf.head()","263493ec":"df.shape","2ead51b0":"df.isnull().sum()","e4c121b9":"df.dropna(inplace=True)","4a8e8517":"df.isnull().sum().sum()","53bad229":"df.dtypes","9760e759":"df.describe()","b6df2078":"df[['Year_Birth','Income','Kidhome','Teenhome', 'MntWines', 'MntFruits',\n           'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts',\n           'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases',\n           'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth',\n           'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1',\n           'AcceptedCmp2', 'Complain', 'Z_CostContact', 'Z_Revenue']].hist(figsize=[13,12])","f1a228ea":"df[df.Income>600000]","2023fcd9":"df.drop(index=2233,inplace=True)","afef2368":"df['Dt_Customer']=pd.to_datetime(df['Dt_Customer'])","61d432e3":"pie1=pd.DataFrame(df['Education'].value_counts())\npie1.reset_index(inplace=True)\npie1.plot(kind='pie', title='Pie chart of Education level',y = 'Education', \n          autopct='%1.1f%%', shadow=False, labels=pie1['index'], legend = False, fontsize=14, figsize=(12,12))","ef07cd77":"pie2=pd.DataFrame(df['Marital_Status'].value_counts())\npie2.reset_index(inplace=True)\npie2.plot(kind='pie', title='Pie chart of Marital_Status',y = 'Marital_Status',\n          autopct='%1.1f%%', shadow=False, labels=pie2['index'], legend = False, fontsize=14, figsize=(12,12))","50cb5108":"df.dtypes","a9d096c2":"for x in ['Education','Marital_Status']:\n    print(x,len(df[x].unique()))","fbb60f3e":"for x in ['Education','Marital_Status']:\n    print(x,df[x].unique())","4031c7e2":"df.Education=df.Education.replace('Basic',0).replace('2n Cycle',1).replace('Graduation',2).replace('Master',3).replace('PhD',4)","46ecd9ce":"df.Education.unique()","04bf9b7e":"df.Marital_Status=df.Marital_Status.replace(['Divorced','Widow','Alone','Absurd','YOLO'],'Single').replace(['Together','Married'],'In couple')","49446962":"df.Marital_Status.unique()","965c548e":"df.head()","2496366f":"df.Dt_Customer.min()","58f8fda6":"df.Dt_Customer.max()","bbf875ad":"df.Year_Birth=(2014-df.Year_Birth)","c697871a":"df.rename(columns={'Year_Birth':'Age'},inplace=True)","524e8365":"df['Months being customer']=round(((pd.to_datetime('2014-12-07')-df.Dt_Customer).dt.days)\/30,1)","c6d16ccc":"df.drop(['Dt_Customer'],axis=1,inplace=True)","1d62081d":"df['N\u00b0 children']=df['Kidhome']+df['Teenhome']","70291582":"df.drop(['Kidhome','Teenhome'],axis=1,inplace=True)","674f01e4":"df['Spending']=df['MntWines']+df['MntFruits']+df['MntMeatProducts']+df['MntFishProducts']+df['MntSweetProducts']+df['MntGoldProds']","a9e80d62":"df.head()","d58553f3":"print('Number of web purchases: ',df.NumWebPurchases.sum())\nprint('Number of catalog purchases: ',df.NumCatalogPurchases.sum())\nprint('Number of store purchases: ',df.NumStorePurchases.sum())","2b64e363":"df.Age.min(), df.Age.max()","70fa28fd":"bins = [18, 29, 39, 49, 59, 69, 130]\nlabels = ['18-29', '30-39', '40-49', '50-59', '60-69', '70+']\ndf['Age_class'] = pd.cut(df.Age, bins, labels = labels,include_lowest = True)\n\ndf[['Age','Age_class']].head()","cbbe4527":"df[['Age_class','NumWebPurchases','NumCatalogPurchases','NumStorePurchases','NumDealsPurchases']].groupby('Age_class').sum()","63ff49d8":"df['Spending'].describe()","78e66955":"sns.boxplot(x='Spending',data=df)","3c288b5b":"df[df.Spending>1048].describe().T","1dc4a822":"plt.figure(figsize=(5, 12))\nheatmap = sns.heatmap(df[['Age', 'Education', 'Income', 'Recency',\n                          'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts',\n                          'MntSweetProducts', 'MntGoldProds', 'NumDealsPurchases',\n                          'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases',\n                          'NumWebVisitsMonth', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5',\n                          'AcceptedCmp1', 'AcceptedCmp2', 'Complain', 'Z_CostContact',\n                          'Z_Revenue', 'Months being customer', 'N\u00b0 children', 'Spending']].corr()[['Spending']].sort_values(by='Spending', ascending=True), vmin=-1, vmax=1, annot=True, cmap='BrBG')\nheatmap.set_title('Features Correlating with Spending', fontdict={'fontsize':18}, pad=22)\nheatmap.set_ylim([0,24])","ca445fee":"df[['Age','Education','Marital_Status','Income','N\u00b0 children','Months being customer','Spending']].head()","340a06ff":"df2=df[['Age','Education','Income','Months being customer','Spending']]","b883523b":"df2.dtypes","5edca041":"cols=['Age','Education','Income','Months being customer','Spending']","e226eb64":"df2[cols].hist(bins=30, figsize=(15,13))","83c60c91":"df3=df2.copy(deep=True)","be2b3312":"from sklearn.preprocessing import StandardScaler\nss=StandardScaler()\ndf3[cols]=ss.fit_transform(df2[cols])","3bd55ab1":"df3[cols]","a65b0e02":"from sklearn.cluster import AgglomerativeClustering\nag = AgglomerativeClustering(n_clusters=3, linkage='ward', compute_full_tree=True)\nag = ag.fit(df3[cols])","f4bb846f":"df2['agglom'] = ag.fit_predict(df3[cols])\ndf3['agglom'] = ag.fit_predict(df3[cols])","06e0a470":"df3.groupby('agglom').mean()","5698de5f":"df2.groupby('agglom').mean()","9ab79c31":"df2.agglom.value_counts()","0f298571":"import seaborn as sns\ncoloribm = {\"Magenta 100\":\"2A0A16\", \"Magenta 90\":\"57002B\", \"Magenta 80\":\"760A3A\", \"Magenta 70\":\"A11950\", \"Magenta 60\":\"D12765\", \"Magenta 50\":\"EE538B\", \"Magenta 40\":\"FA75A6\", \"Magenta 30\":\"FFA0C2\", \"Magenta 20\":\"FFCFE1\", \"Magenta 10\":\"FFF0F6\", \"Purple 100\":\"1E1033\", \"Purple 90\":\"38146B\", \"Purple 80\":\"4F2196\", \"Purple 70\":\"6E32C9\", \"Purple 60\":\"8A3FFC\", \"Purple 50\":\"A66EFA\", \"Purple 40\":\"BB8EFF\", \"Purple 30\":\"D0B0FF\", \"Purple 20\":\"E6D6FF\", \"Purple 10\":\"F7F1FF\", \"Blue 100\":\"051243\", \"Blue 90\":\"061F80\", \"Blue 80\":\"0530AD\", \"Blue 70\":\"054ADA\", \"Blue 60\":\"0062FF\", \"Blue 50\":\"408BFC\", \"Blue 40\":\"6EA6FF\", \"Blue 30\":\"97C1FF\", \"Blue 20\":\"C9DEFF\", \"Blue 10\":\"EDF4FF\", \"Teal 100\":\"081A1C\", \"Teal 90\":\"003137\", \"Teal 80\":\"004548\", \"Teal 70\":\"006161\", \"Teal 60\":\"007D79\", \"Teal 50\":\"009C98\", \"Teal 40\":\"00BAB6\", \"Teal 30\":\"20D5D2\", \"Teal 20\":\"92EEEE\", \"Teal 10\":\"DBFBFB\", \"Gray 100\":\"171717\", \"Gray 90\":\"282828\", \"Gray 80\":\"3D3D3D\", \"Gray 70\":\"565656\", \"Gray 60\":\"6F6F6F\", \"Gray 50\":\"8C8C8C\", \"Gray 40\":\"A4A4A4\", \"Gray 30\":\"BEBEBE\", \"Gray 20\":\"DCDCDC\", \"Gray 10\":\"F3F3F3\"} \ncolors = []\ncolornum = 60\nfor i in [f'Blue {colornum}', f'Teal {colornum}', f'Magenta {colornum}', f'Purple {colornum}', f'Gray {colornum}']:\n    colors.append(f'#{coloribm[i]}')\npalette = sns.color_palette(colors)","2f31f736":"from scipy.cluster import hierarchy\n\nZ = hierarchy.linkage(ag.children_, method='ward')\n\nfig, ax = plt.subplots(figsize=(15,5))\n\n# Some color setup\nred = colors[2]\nblue = colors[0]\n\nhierarchy.set_link_color_palette([red, 'gray'])\n\nden = hierarchy.dendrogram(Z, orientation='top', \n                           p=30, truncate_mode='lastp',\n                           show_leaf_counts=True, ax=ax,\n                           above_threshold_color=blue)","b7de2256":"inertia = []\nlist_num_clusters = list(range(1,20))\nfor num_clusters in list_num_clusters:\n    km = KMeans(n_clusters=num_clusters)\n    km.fit(df3[cols])\n    inertia.append(km.inertia_)\n    \nplt.plot(list_num_clusters,inertia)\nplt.scatter(list_num_clusters,inertia)\nplt.xlabel('Number of Clusters')\nplt.ylabel('Inertia')","78cfc059":"km = KMeans(n_clusters=3, random_state=42)\nkm = km.fit(df3[cols])\ndf3['kmeans'] = km.predict(df3[cols])","4d9d126d":"km.inertia_","82362d4d":"df3[['Age','Education','Income','Months being customer','Spending','kmeans']].groupby('kmeans').mean()","d3bf6b8c":"df2['kmeans'] = km.predict(df3[cols])","ca1e55aa":"df2[['Age','Education','Income','Months being customer','Spending','kmeans']].groupby('kmeans').agg([np.mean,np.median])","595d7259":"df3.kmeans.value_counts()","3f1f6397":"from mpl_toolkits.mplot3d import Axes3D","6c33f34f":"fig, ax = plt.subplots(figsize=(8,5))\n\nscatter = ax.scatter(df2['Age'], df2['Income'], s=(df2['Spending']\/12), c=km.labels_.astype(np.float), alpha=0.5)\nlegend1 = ax.legend(*scatter.legend_elements(), loc=\"upper right\", title=\"Clusters\")\n#ax.add_artist(legend1)\nplt.xlabel('Age', fontsize=18)\nplt.ylabel('Income', fontsize=16)\nplt.show()","94fc17a8":"fig, ax = plt.subplots(figsize=(8,5))\n\nscatter = ax.scatter(df2['Age'], df2['Income'], s=(df2['Education']**4), c=km.labels_.astype(np.float), alpha=0.5)\nlegend1 = ax.legend(*scatter.legend_elements(), loc=\"upper right\", title=\"Clusters\")\n#ax.add_artist(legend1)\nplt.xlabel('Age', fontsize=18)\nplt.ylabel('Income', fontsize=16)\nplt.show()","36fdecde":"fig, ax = plt.subplots(figsize=(8,5))\n\nscatter = ax.scatter(df2['Income'], df2['Spending'], s=(df2['Education']**4), c=km.labels_.astype(np.float), alpha=0.5)\nlegend1 = ax.legend(*scatter.legend_elements(), loc=\"upper right\", title=\"Clusters\")\n#ax.add_artist(legend1)\nplt.xlabel('Income', fontsize=18)\nplt.ylabel('Spending', fontsize=16)\nplt.show()","aa6f757a":"fig, ax = plt.subplots(figsize=(8,5))\n\nscatter = ax.scatter(df2['Months being customer'], df2['Spending'], s=(df2['Income']\/2000), c=km.labels_.astype(np.float), alpha=0.8)\nlegend1 = ax.legend(*scatter.legend_elements(), loc=\"upper right\", title=\"Clusters\")\n#ax.add_artist(legend1)\nplt.xlabel('Months being customer', fontsize=18)\nplt.ylabel('Spending', fontsize=16)\nplt.show()","378b1774":"fig = plt.figure(figsize = (8,9))\n#ax = fig.add_subplot(1,1,1) \nax = fig.add_subplot(111, projection='3d')\nax.set_xlabel('Months being customer', fontsize = 15)\nax.set_ylabel('Income', fontsize = 15)\nax.set_zlabel('Spending', fontsize = 15)\nax.set_title('3 component', fontsize = 20)\ntargets = [0, 1, 2]\ncolors = ['purple', 'c', 'y']\nfor target, color in zip(targets,colors):\n    indicesToKeep = (df2['kmeans'] == target)\n    ax.scatter(df2.loc[indicesToKeep, 'Months being customer']\n               , df2.loc[indicesToKeep, 'Income']\n               , df2.loc[indicesToKeep, 'Spending']\n               , c = color\n               , s = 50)\nax.legend(targets)\nax.grid()","21264c76":"df4=df.copy(deep=True)","86e31609":"df4['kmeans']=df2['kmeans']\ndf4.head()","be1d0621":"df4[['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds', 'kmeans']].groupby('kmeans').mean()","9e766b2d":"df4[['NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases', 'Age', 'kmeans']].groupby('kmeans').mean()","e686c725":"pd.crosstab(df4['Marital_Status'], df4['kmeans'], rownames=['Marital_Status'], colnames=['kmeans'])","10a6b745":"pd.crosstab(df4['N\u00b0 children'], df4['kmeans'], rownames=['N\u00b0 children'], colnames=['kmeans'])","022d5504":"from sklearn.cluster import DBSCAN\nfrom sklearn import metrics","db099860":"# Compute DBSCAN\ndb = DBSCAN(eps=0.99, min_samples=5).fit(df3[cols])\ncore_samples_mask = np.zeros_like(db.labels_, dtype=bool)\ncore_samples_mask[db.core_sample_indices_] = True\nlabels = db.labels_\n\n# Number of clusters in labels, ignoring noise if present.\nn_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\nn_noise_ = list(labels).count(-1)","72222593":"print('Estimated number of clusters: %d' % n_clusters_)\nprint('Estimated number of noise points: %d' % n_noise_)","1551ae98":"df2['dbscan']=labels\ndf3['dbscan']=labels","475d6996":"df3.dbscan.value_counts()","bb663ded":"df2[['Age','Education','Income','Months being customer','Spending','dbscan']].groupby('dbscan').mean()","47e5cbb7":"df3[['Age','Education','Income','Months being customer','Spending','dbscan']].groupby('dbscan').mean()","26841a66":"df4['dbscan']=df2['dbscan']\ndf4[['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds', 'dbscan']].groupby('dbscan').mean()","9a8e56d9":"fig, ax = plt.subplots(figsize=(8,5))\n\nscatter = ax.scatter(df2['Age'], df2['Income'], s=(df2['Spending']\/25), c=labels.astype(np.float), alpha=0.7)\nlegend1 = ax.legend(*scatter.legend_elements(), loc=\"upper right\", title=\"Clusters\")\n#ax.add_artist(legend1)\nplt.xlabel('Age', fontsize=18)\nplt.ylabel('Income', fontsize=16)\nplt.show()","34e6c455":"fig, ax = plt.subplots(figsize=(8,5))\n\nscatter = ax.scatter(df2['Age'], df2['Income'], s=(df2['Education']**3), c=labels.astype(np.float), alpha=0.7)\nlegend1 = ax.legend(*scatter.legend_elements(), loc=\"upper right\", title=\"Clusters\")\n#ax.add_artist(legend1)\nplt.xlabel('Age', fontsize=18)\nplt.ylabel('Income', fontsize=16)\nplt.show()","620e68b6":"fig, ax = plt.subplots(figsize=(8,5))\n\nscatter = ax.scatter(df2['Income'], df2['Spending'], s=(df2['Education']**4), c=labels.astype(np.float), alpha=0.5)\nlegend1 = ax.legend(*scatter.legend_elements(), loc=\"upper right\", title=\"Clusters\")\n#ax.add_artist(legend1)\nplt.xlabel('Income', fontsize=18)\nplt.ylabel('Spending', fontsize=16)\nplt.show()","01dabfb9":"fig, ax = plt.subplots(figsize=(8,5))\n\nscatter = ax.scatter(df2['Months being customer'], df2['Spending'], s=(df2['Income']\/2000), c=labels.astype(np.float), alpha=0.8)\nlegend1 = ax.legend(*scatter.legend_elements(), loc=\"upper right\", title=\"Clusters\")\n#ax.add_artist(legend1)\nplt.xlabel('Months being customer', fontsize=18)\nplt.ylabel('Spending', fontsize=16)\nplt.show()","cdc713a4":"fig = plt.figure(figsize = (8,9))\n#ax = fig.add_subplot(1,1,1) \nax = fig.add_subplot(111, projection='3d')\nax.set_xlabel('Months being customer', fontsize = 15)\nax.set_ylabel('Income', fontsize = 15)\nax.set_zlabel('Spending', fontsize = 15)\nax.set_title('3 component', fontsize = 20)\ntargets = [0, 1, 2, 3, 4, -1]\ncolors = ['purple', 'c', 'y', 'c', 'm', 'k']\nfor target, color in zip(targets,colors):\n    indicesToKeep = (df2['dbscan'] == target)\n    ax.scatter(df2.loc[indicesToKeep, 'Months being customer']\n               , df2.loc[indicesToKeep, 'Income']\n               , df2.loc[indicesToKeep, 'Spending']\n               , c = color\n               , s = 50)\nax.legend(targets)\nax.grid()","faa89a0c":"from sklearn.decomposition import PCA\n\nPCA2=PCA(n_components=3)\nPCA2=PCA2.fit(df3[cols])","48f43992":"PCA2.explained_variance_ratio_","846e0398":"PCA2.explained_variance_ratio_.sum()","397bc5f9":"pd.DataFrame(abs(PCA2.components_)*100)","1309a9a2":"PCA3=PCA(n_components=3)\nPCA3=PCA3.fit_transform(df3[cols])","846a36c1":"PCA3=pd.DataFrame(PCA3, columns = ['principal component 1', 'principal component 2', 'principal component 3'])","40034693":"PCA3.head()","e9929149":"PCA3_final = pd.concat([PCA3, df3['dbscan']], axis = 1)\nPCA3_final.head()","1e8a6d6c":"from mpl_toolkits.mplot3d import Axes3D\nfig = plt.figure(figsize = (8,9))\n#ax = fig.add_subplot(1,1,1) \nax = fig.add_subplot(111, projection='3d')\nax.set_xlabel('Principal Component 1', fontsize = 15)\nax.set_ylabel('Principal Component 2', fontsize = 15)\nax.set_zlabel('Principal Component 3', fontsize = 15)\nax.set_title('3 component PCA', fontsize = 20)\ntargets = [0, 1, 2, 3, 4, -1]\ncolors = ['r', 'g', 'b', 'c', 'm', 'k']\nfor target, color in zip(targets,colors):\n    indicesToKeep = (PCA3_final['dbscan'] == target)\n    ax.scatter(PCA3_final.loc[indicesToKeep, 'principal component 1']\n               , PCA3_final.loc[indicesToKeep, 'principal component 2']\n               , PCA3_final.loc[indicesToKeep, 'principal component 3']\n               , c = color\n               , s = 50)\nax.legend(targets)\nax.grid()","39c7ed22":"## Modeling\n\nIn order to choose the best model the number of clusters is defined as 3, but this can be changed to a higher number if there is a model which can differentiate these clearly. The following models will be built and compared using their corresponding cluster interpretation.  \n1. Hierarchical Agglomerative clustering with ward linkage.  \n2. DBSCAN with suit values for epsilon and min_samples.   \n3. K-means.  \n\nFor the first model the unique hyperparameter set was ward linkage, the following is a figure showing the centroids of each cluster generated and take into account that these correspond to the mean of each group, early we could say this model mainly doesn\u2019t differentiate well the age of  customers as the 3 of them are between 43 and almost 47 years old.","8dbfcae3":"**Main Objectives:**\n\nThe scope of this project is to build several machine learning algorithms which can segment our customers by similar characteristics and choose the best one based on their interpretability and best representation of our data. This can be broken down into the following milestones:  \n1. Data Cleaning and Exploration.  \n2. Modeling.  \n3. Interpretation of clusters.  \n4. Selection of best model.  \n\nThe best model built could benefit the company in the task of focusing marketing strategies to specific groups of customers improving their experience and satisfaction.","a85bcf6b":"As in K-means let's see in the table below the average spending by type of product for each cluster:","6d20d4a7":"### DBSCAN","4c86d52c":"### K-means:","ea240aa2":"The following plot will show the correlation of Spending with every other feature:","6069e1ce":"Clearly it can't be well differentiated and also results complex to explain what each one represents: ","aa86feec":"For this model we could certainly say that it differentiated a bit better than HAC by age and spending, but it is still hard to explain each of them. ","646bc6ba":"Let's analyze the type of purchase so the supermarket can know how their customers do it and if there is a pattern or relation with Age, for this process will be created a new feature called Age_class in order to analyze by groups:","acce195b":"In the table above we don't see a tendency in young aged people to purchase by web, every class shows the same behaviour to prefer purchasing in store, then in web and finally by catalog.","975367cd":"Let's see the education level of the customers displayed as a pie chart:","cc39f3b1":"Let's drop the rows containing null values:","9dcc487b":"Dt_Customer is a feature which must be set as date type so as to compute later how long has the person been customer:","b631b86b":"In order to know the distribution of each feature will be plotted a histogram for each of them:","8269440c":"### Suggestions\n\n1. Firstly I personally found this was without a doubt the most difficult subject in the program, because of that I would love to receive your feed-back to improve it.    \n2. Would be fascinating to see a better segmentation with easier representation but using different features as those selected in this project. I've tried several combinations and this one gave me the most notable difference.   \n3. Spend more time in DBSCAN and choosing their right hyperparameters to obtain less clusters, because it always created more than 5 and these were complex to explain.","3841824b":"Finally the Spending is obtained by adding MntWines,MntMeatProducts,MntFishProducts,MntSweetProducts,MntGoldProds which shows how much of each type of product has been purchased by instance.","18bb632c":"Despite the fact that some features are highly skewed all values were validated by the publisher, but there is a value which couldn\u2019t go unnoticed in our dataset and corresponds to a customer with an income which looks like it was miswritten or is an extreme outlier, but also their spending was considerably low so because of this the record will be dropped in order to have a better representation of the data to be clustered.","d43134b4":"There is not enough to explicitly say that there is an elbow point because the inertia is decreasing gradually as clusters increase.","e2567643":"Still wines and meat are the top products and the spending of only cluster 2 reachs 73% of total sales. About the type of purchase \u2018In Store\u2019 continues being the most frequent.","41ba8ae7":"The classes in categorical variables will be reduced as follows:","3990755b":"We can see there is a strong correlation with Wines and Meat products, but as all of these were added before there is a nice representation of them as only one feature. Income is considered to have a high correlation too and it makes sense as it is expected that someone with high income will spend more on their purchases. About the type of purchase it can be in store, web or catalog as we saw before, this information is crucial as the supermarket can know how their customers prefer to purchase leading to improve their experience and facilitate the process.  \nAs this is a project which aims to know more about the customer, their needs, behaviours, etc. some features will be selected to better interpret the clusters to be generated:  \nNow the dataframe is cleaned and reduced to the following columns:","a9b7413b":"### Key Findings\n\nThe HAC and DBSCAN models did not represent uniformly our dataset, the clusters looked like in some features were almost the same but in other were totally different and the scope of this is to find the best differentiation between them so we can focus more on specific characteristics of the customer with highest spending and how to always offer what people with low income are looking for. The figures already shown related to K-means can help us to best interpret and infer key data from the clusters. For example from the first and second figures we can say:  \n- cluster 2 corresponds to those customers with highest income and spending who also are between 40 and 50 years old.  \n- cluster 1 represents people with middle income and spending who are after 50 years old.   \n- cluster 0 are young people with low income and spending who highly likely are in 2nd grade or undergraduate.  \n\nAnother key insight is the fact that in the table shown before about customers with spending over third quartile have characteristics considerably similar to cluster 2, because of this we could assign the name \u2018Golden\u2019 or \u2018Top\u2019 customers to this specific group.\n","27cda5c4":"The following tables show how many records of each cluster are single or in couple and how many children each one has. Focusing on cluster 2 something interesting inferred is that 94% of them do not have children or have only one, whereas 63% are in a couple.","dfa8a026":"Age of the customer will be obtained by subtracting Year birth to 2014 (Year when was done the analysis):","c9db700c":"The classes in Marital Status is being summarized as Single or In couple:","01463b70":"We can certainly say there is a notable difference between clusters standing out the age, spending, education and income. Also the amount of records in the clusters was quite balanced.","efb8d8de":"Number of children will be obtained by adding Kidhome and Teenhome:","8cf104b9":"For three clusters the inertia value was 6719 and the mean and median value of each one is summarized in the second table below:","06cb4b80":"Firstly, for this model was computed the inertia values by number of clusters between 1 and 20, giving the following curve shown in the figure below: ","94b3369b":"Another insight that companies loves is to know more about those customers with the highest spendings, so let\u2019s firstly define an interval to research and this will be equal to those values above the third quartile so the following should help us to find the such value:","88ee02f2":"The first figure below shows the age by income and relates the education of the customer with the size of each circle, clearly the clusters can\u2019t be differentiated and in the last figure we see how tight they actually are:","85679555":"In the following figures the clusters can be clearly characterized because of their separation between each other:","7bc4b353":"Let's see the marital status of the customers displayed as a pie chart:","9cd41832":"### Agglomerative clustering:","7939588a":"The level of Education is being encoded to numerical ascendingly:","08d8588a":"Time being customer will be computed in months by subtracting Dt_Customer to 2014-12-07 (Date when was done the analysis):","ed787b34":"The threshold is $1048 and thus customers with spending higher than this will be described below:","baef284c":"The following 5 features are the most important when trying to cluster the customer's characteristics, thus we will see their corresponding histogram before scaling:","282f9ef1":"Create a copy of the original dataset cleaned just to analyze more the clusters and their characteristics:","f9272090":"One interesting insight about the clusters built are the products purchased, in the table below is shown the average of each product by cluster:","8cef9f3b":"Just to see the distribution of records by clusters created in DBSCAN let's reduce components to 3 using PCA:","6a23831e":"Above we see every feature looks suitable to be used in the modeling process, but as we will see later some features were originally wrongly encoded or typed and this was corrected during the cleaning process.","46e3de4c":"For the last model it was a huge task the setting of its hyperparameters as always it created more than 5 clusters and for this reason the following were used: epsilon=0.99 and  min_samples=5. This created five clusters and 46 noise points which are labeled as cluster \u2018-1\u2019, representing actually six segments and their centroids are in the table below: "}}