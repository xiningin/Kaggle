{"cell_type":{"30b83ed7":"code","6cde84d1":"code","f00b0a6f":"code","637625bb":"code","25572613":"code","03163813":"code","12232c19":"code","79dc3523":"code","fb17ea71":"code","13298860":"code","dd69e49b":"code","804d7f19":"code","59d2d797":"code","cf5ba76e":"code","f7a8d38b":"code","4783e198":"code","b0798074":"code","ea76542b":"code","3529789c":"code","6799394e":"code","5f37b115":"code","1f9b2e7b":"code","097f35d7":"code","d6b4493a":"code","739681ea":"code","b8f562b2":"code","853b467b":"code","23759186":"code","b260c13f":"code","d1a041f4":"markdown","ef3d61ae":"markdown","abc1e472":"markdown","02c4866b":"markdown","c009625b":"markdown","4ff39432":"markdown","03ac4751":"markdown","985a37c9":"markdown","a90eb38d":"markdown","8b5f30ac":"markdown"},"source":{"30b83ed7":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport cv2\nimport random\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import RMSprop, Adam, SGD\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Input, Dense, Flatten\nfrom tensorflow.keras.models import Model\nfrom shutil import copyfile, rmtree\nfrom timeit import default_timer as timer","6cde84d1":"# \u0412\u0441\u043f\u043e\u043c\u043e\u0433\u0430\u0442\u0435\u043b\u044c\u043d\u0430\u044f \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u0434\u043e\u0441\u0442\u0443\u043f\u0430 \u043a \u0444\u0430\u0439\u043b\u0430\u043c \u043e\u0442\u043d\u043e\u0441\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u043a\u043e\u0440\u043d\u044f \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u044f \u0441 \u0434\u0430\u043d\u043d\u044b\u043c\u0438.\nINPUT_ROOT = \"..\/input\/gtsrb-german-traffic-sign\"\ndef from_input(path):\n    return os.path.join(INPUT_ROOT, path)","f00b0a6f":"# \u0417\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u0442\u0430\u0431\u043b\u0438\u0446\u0443 \u0441 \u0434\u0430\u043d\u043d\u044b\u043c\u0438 \u043e \u0434\u0430\u043d\u043d\u044b\u0445.\ntrain_info = pd.read_csv(from_input(\"Train.csv\"))\ntrain_info.head()","637625bb":"# \u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043a\u0430\u043a \u0432\u044b\u0433\u043b\u044f\u0434\u044f\u0442 \u043d\u0430\u0448\u0438 \u0434\u0430\u043d\u043d\u044b\u0435.\ntrain_info.describe()","25572613":"# \u0441\u043a\u043e\u043b\u044c\u043a\u043e \u043f\u0440\u0438\u043c\u0435\u0440\u043e\u0432 \u0432 \u043a\u0430\u0436\u0434\u043e\u043c \u0438\u0437 \u043a\u043b\u0430\u0441\u0441\u043e\u0432\ntrain_info.groupby('ClassId')['ClassId'].count()","03163813":"test_info =  pd.read_csv(from_input(\"Test.csv\"))\ntest_info.head()","12232c19":"test_info.describe()","79dc3523":"# \u0441\u043a\u043e\u043b\u044c\u043a\u043e \u043f\u0440\u0438\u043c\u0435\u0440\u043e\u0432 \u0432 \u043a\u0430\u0436\u0434\u043e\u043c \u0438\u0437 \u043a\u043b\u0430\u0441\u0441\u043e\u0432\ntest_info.groupby('ClassId')['ClassId'].count()","fb17ea71":"%matplotlib inline\n\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n\n# \u041f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u043c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0432 \u0441\u0435\u0442\u043a\u0435 6\u04458.\nnrows = 8\nncols = 6\n\npic_offset = 0 # \u0427\u0442\u043e\u0431\u044b \u0438\u0442\u0435\u0440\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u043f\u043e \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\u043c \u043a\u0430\u0436\u0434\u044b\u0439 \u0440\u0430\u0437 \u043a\u043e\u0433\u0434\u0430 \u0437\u0430\u043f\u0443\u0441\u0442\u0438\u043c \u043a\u043e\u0434 \u043d\u0438\u0436\u0435.","13298860":"def show_images(offset):\n    fig = plt.gcf()\n    fig.set_size_inches(ncols*3, nrows*3)\n\n    for i in range(43):\n        # subplot \u0438\u043d\u0434\u0435\u043a\u0441\u044b \u043d\u0430\u0447\u0438\u043d\u0430\u044e\u0442\u0441\u044f \u0441 1\n        sp = plt.subplot(nrows, ncols, i + 1)\n        sp.axis('Off')\n        subdir = os.path.join(from_input('train'), str(i))\n        files = os.listdir(subdir)\n        img_path = os.path.join(subdir, files[offset % len(files)])\n        img = mpimg.imread(img_path)\n        #print(img.shape)\n        plt.imshow(img)\n\n    plt.show()","dd69e49b":"show_images(pic_offset)\npic_offset += 1","804d7f19":"TARGET_SIZE = (40, 40) # \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0431\u0443\u0434\u0443\u0442 \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u044b \u0434\u043e \u044d\u0442\u043e\u0433\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u0430\nBATCH_SIZE=300","59d2d797":"paths = train_info['Path'].values\ny_train = train_info['ClassId'].values\n\nindices = np.arange(y_train.shape[0])\nrandgen = random.Random(62)\nrandgen.shuffle(indices)\n\npaths = paths[indices]\ny_train = y_train[indices]\ny_train = to_categorical(y_train, 43)\n\ndata=[]\n\nfor i, f in enumerate(paths):\n    print('\\rLoading data {0:.1f}%...'.format((i \/ len(paths)) * 100), end = '\\r')\n    image = Image.open(os.path.join(from_input('train'), f.replace('Train\/', '')))\n    resized_image = image.resize(TARGET_SIZE)\n    data.append(np.array(resized_image))\n\nX_train = np.array(data).astype('float32') \/ 255.0\n\nprint('Data loaded.              ')\n\ntrain_datagen = ImageDataGenerator()\ntrain_generator = train_datagen.flow(X_train,\n                                    y_train,\n                                    batch_size=BATCH_SIZE,\n                                    shuffle=True,\n                                    seed=17)","cf5ba76e":"paths = test_info['Path'].values\ny_test = test_info['ClassId'].values\ny_test = to_categorical(y_test, 43)\n\ndata=[]\n\nfor i, f in enumerate(paths):\n    print('\\rLoading data {0:.1f}%...'.format((i \/ len(paths)) * 100), end = '\\r')\n    image = Image.open(os.path.join(from_input('test'), f.replace('Test\/', '')))\n    resized_image = image.resize(TARGET_SIZE)\n    data.append(np.array(resized_image))\n\nprint('Data loaded.              ')\n\nX_test = np.array(data).astype('float32') \/ 255.0 \n\ntest_datagen = ImageDataGenerator()\ntest_generator = test_datagen.flow(X_test,\n                                    y_test,\n                                    batch_size=BATCH_SIZE,\n                                    shuffle=False,\n                                    seed=17)","f7a8d38b":"def plot(history):\n    %matplotlib inline\n\n    import matplotlib.image  as mpimg\n    import matplotlib.pyplot as plt\n\n    acc=history.history['acc']\n    loss=history.history['loss']\n    epochs=range(len(acc))\n\n    plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n    plt.title('Training accuracy')\n    plt.xlabel('Epoch')\n    plt.figure()\n\n    plt.plot(epochs, loss, 'r', \"Training Loss\")\n    plt.xlabel('Epoch')\n    plt.title('Training loss')","4783e198":"def show_layers(model):\n    print('Name\\tOutput shape\\tActivation\\tInitializer')\n    for l in model.layers:\n        print('{0}({1})\\t{2}\\t{3}\\t{4}'\n            .format(l.name,\n              l.__class__.__name__,\n              l.output_shape,\n              l.activation.__name__ if hasattr(l, 'activation') else '<none>',\n              l.kernel_initializer.__class__.__name__ if hasattr(l, 'kernel_initializer') else '<none>'))\n\n\ndef custom_summary(model):\n    model.summary()\n    show_layers(model)","b0798074":"VERBOSE=0","ea76542b":"def train_model(model, kernel_initializer, optimizer, epochs):\n    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n    start_time = timer()\n    history = model.fit_generator(train_generator,\n                        epochs=epochs,\n                        verbose=VERBOSE,\n                        steps_per_epoch= round(X_train.shape[0] \/ BATCH_SIZE))\n    end_time = timer()\n    \n    custom_summary(model)\n    print('==============================')\n    print('Initializer: ', kernel_initializer)\n    print('Optimizer: ', optimizer.__class__.__name__)\n    print('Learning rate: ', optimizer.get_config()['learning_rate'])\n    print('Epochs: ', epochs)\n    print('==============================')\n    print('Trained in {0:.2f} minutes'.format((end_time - start_time) \/ 60))\n    \n    acc=history.history['acc'][-1]\n    test_acc = model.evaluate_generator(test_generator)[1]\n    \n    print('Results at the end of training: acc={1:.02f}%, test_acc={2:.02f}%'\n          .format(i, acc*100, test_acc*100))\n\n    plot(history)","3529789c":"kernel_initializer='glorot_uniform'\noptimizer=Adam(learning_rate=0.0005)\nepochs=20\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(43, activation='softmax')\n])\n\ntrain_model(model, kernel_initializer, optimizer, epochs)","6799394e":"kernel_initializer='glorot_uniform'\noptimizer=Adam(learning_rate=0.0005)\nepochs=20\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(43, activation='softmax')\n])\n\ntrain_model(model, kernel_initializer, optimizer, epochs)","5f37b115":"kernel_initializer='glorot_uniform'\noptimizer=Adam(learning_rate=0.0005)\nepochs=20\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(43, activation='softmax')\n])\n\ntrain_model(model, kernel_initializer, optimizer, epochs)","1f9b2e7b":"kernel_initializer='glorot_uniform'\noptimizer=Adam(learning_rate=0.0005)\nepochs=20\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(256, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(43, activation='softmax')\n])\n\ntrain_model(model, kernel_initializer, optimizer, epochs)","097f35d7":"kernel_initializer='glorot_uniform'\noptimizer=Adam(learning_rate=0.0005)\nepochs=20\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(256, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(43, activation='softmax')\n])\n\ntrain_model(model, kernel_initializer, optimizer, epochs)","d6b4493a":"kernel_initializer='glorot_uniform'\noptimizer=Adam(learning_rate=0.0005)\nepochs=20\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(43, activation='softmax')\n])\n\ntrain_model(model, kernel_initializer, optimizer, epochs)","739681ea":"kernel_initializer='glorot_uniform'\noptimizer=Adam(learning_rate=0.0005)\nepochs=20\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(256, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(512, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(43, activation='softmax')\n])\n\ntrain_model(model, kernel_initializer, optimizer, epochs)","b8f562b2":"kernel_initializer='glorot_uniform'\noptimizer=Adam(learning_rate=0.0005)\nepochs=20\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(256, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(512, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(43, activation='softmax')\n])\n\ntrain_model(model, kernel_initializer, optimizer, epochs)","853b467b":"kernel_initializer='glorot_uniform'\noptimizer=Adam(learning_rate=0.0005)\nepochs=20\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(256, (5, 5), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(512, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(43, activation='softmax')\n])\n\ntrain_model(model, kernel_initializer, optimizer, epochs)","23759186":"kernel_initializer='glorot_uniform'\noptimizer=Adam(learning_rate=0.0005)\nepochs=20\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(256, (7, 7), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(512, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(43, activation='softmax')\n])\n\ntrain_model(model, kernel_initializer, optimizer, epochs)","b260c13f":"kernel_initializer='glorot_uniform'\noptimizer=Adam(learning_rate=0.0005)\nepochs=20\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(256, (7, 7), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(512, (3, 3), activation='tanh', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(1024, (3, 3), activation='tanh', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(43, activation='softmax')\n])\n\ntrain_model(model, kernel_initializer, optimizer, epochs)","d1a041f4":"\u0422\u0440\u0435\u043d\u0438\u0440\u0443\u0435\u043c \u0441\u0435\u0442\u0438:","ef3d61ae":"\u041f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u0434\u043e\u0431\u0430\u0432\u043b\u044f\u0442\u044c \u0441\u043b\u043e\u0438:","abc1e472":"\u0421\u0442\u0430\u043b\u043e \u043b\u0443\u0447\u0448\u0435. \u041f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u0443\u043c\u0435\u043d\u044c\u0448\u0438\u0442\u044c \u0438 \u0443\u0432\u0435\u043b\u0438\u0447\u0438\u0442\u044c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0444\u0438\u043b\u044c\u0442\u0440\u043e\u0432.","02c4866b":"\u0420\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u043e\u0447\u0435\u0432\u0438\u0434\u043d\u043e \u0437\u043d\u0430\u0447\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u0445\u0443\u0436\u0435 \u043f\u043e \u0441\u0440\u0430\u0432\u043d\u0435\u043d\u0438\u044e \u0441 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043do\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u043e\u0439, \u043d\u043e \u0442\u0435\u043c \u043d\u0435 \u043c\u0435\u043d\u0435\u0435 \u0445\u043e\u0440\u043e\u0448\u0438\u0435. \u041f\u0440\u0438\u0447\u0438\u043d \u043c\u043e\u0436\u0435\u0442 \u0431\u044b\u0442\u044c \u043c\u043d\u043e\u0433\u043e, \u0440\u0430\u0437\u043d\u0438\u0446\u0430 \u043c\u0435\u0436\u0434\u0443 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u043c\u0438 \u0438 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u044b\u043c\u0438 \u0434\u0430\u043d\u043d\u044b\u043c\u0438 \u043c\u043e\u0436\u0435\u0442 \u0431\u044b\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u043e\u0439. \u041c\u043e\u0436\u0435\u0442 \u0441\u0442\u043e\u0438\u0442 \u0434\u043e\u0431\u0430\u0432\u043b\u044f\u0442\u044c \u0440\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u0430\u0446\u0438\u044e, Dropout, \u0430 \u0442\u0430\u043a\u0436\u0435 \u0438\u0441\u043a\u0443\u0441\u0441\u0442\u0432\u0435\u043d\u043d\u043e \u0438\u0437\u043c\u0435\u043d\u044f\u0442\u044c \u0438 \u0434\u043e\u0431\u0430\u0432\u043b\u044f\u0442\u044c \u0434\u0430\u043d\u043d\u044b\u0435 \u0432 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u0443\u044e \u0432\u044b\u0431\u043e\u0440\u043a\u0443 (augmentation).","c009625b":"\u041f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u043e\u0431\u0440\u0430\u0442\u043d\u044b\u0439 \u043f\u043e\u0434\u0445\u043e\u0434, \u0434\u043e\u043b\u0436\u0435\u043d \u0434\u0430\u0442\u044c \u043f\u043e\u043b\u0443\u0447\u0448\u0435 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b.","4ff39432":"\u041d\u0435\u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0432\u0441\u043f\u043e\u043c\u043e\u0433\u0430\u0442\u0435\u043b\u044c\u043d\u044b\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438:","03ac4751":"\u041f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u0442\u0430\u043d\u0433\u0435\u043d\u0441 \u0433\u0438\u043f\u0435\u0440\u0431\u043e\u043b\u0438\u0447\u0435\u0441\u043a\u0438\u0439, \u043d\u043e \u0432 \u043f\u0435\u0440\u0432\u043e\u043c \u0441\u043b\u043e\u0435 \u043e\u0441\u0442\u0430\u0432\u0438\u043c relu \u0447\u0442\u043e \u0431\u043e\u0440\u043e\u0442\u044c\u0441\u044f \u0441 \u0438\u0441\u0447\u0435\u0437\u0430\u044e\u0449\u0438\u043c \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043e\u043c.","985a37c9":"\u041f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u0443\u0432\u0435\u043b\u0438\u0447\u0438\u0442\u044c \u0440\u0430\u0437\u043c\u0435\u0440 \u044f\u0434\u0440\u0430 \u0432 \u043f\u0435\u0440\u0432\u043e\u043c \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u043e\u043c \u0441\u043b\u043e\u0435, \u0442\u0430\u043a \u043a\u0430\u043a \u0442\u0443\u0442 \u0440\u0430\u0437\u043c\u0435\u0440 \u043a\u0430\u0440\u0442\u044b \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 \u0434\u043e\u0441\u0442\u0430\u0442\u043e\u0447\u043d\u043e \u0431\u043e\u043b\u044c\u0448\u043e\u0439.","a90eb38d":"\u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0438 \u043f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445:","8b5f30ac":"\u041d\u0435 \u0441\u0442\u043e\u0438\u0442 \u0434\u043e\u0431\u0430\u0432\u043b\u044f\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u0435 \u043e\u0434\u0438\u043d\u0430\u043a\u043e\u0432\u044b\u0445 \u0441\u043b\u043e\u0451\u0432. \u041f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u0438\u0437\u043c\u0435\u043d\u044f\u0442\u044c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0444\u0438\u043b\u044c\u0442\u0440\u043e\u0432."}}