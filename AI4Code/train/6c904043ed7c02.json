{"cell_type":{"cb5a62cc":"code","a5773d2c":"code","0c9d0550":"code","840795dc":"code","4acdf776":"code","60003a01":"code","f8fd75bb":"code","7ec6c045":"code","1ccc6581":"code","732bf89d":"code","0061e793":"code","90a3d095":"code","ee600746":"code","c8d92aa8":"code","7710e976":"code","17aaf630":"code","b7602bd5":"code","1ceb356d":"code","9493c7e6":"code","0af087bc":"code","f0d86dae":"code","a0a7be24":"code","09461196":"code","0bdbf04c":"code","b7e029b9":"code","42397cc0":"code","81c074ff":"code","d7c88708":"code","60293fd5":"code","cd8ffeb0":"code","21ad2388":"code","de9b8ccf":"code","be0de672":"code","fd9395d4":"code","7405436f":"code","a3001bc3":"code","4a4e8e24":"code","104b66a6":"code","a14027c2":"code","e64c47ba":"code","eaf2dca8":"code","89ab0072":"code","960329f8":"markdown","16cc2932":"markdown","9cdc58e0":"markdown","f1db366e":"markdown","e3e60f62":"markdown","8c853e3b":"markdown","a1084d34":"markdown","045871db":"markdown","6716fe51":"markdown"},"source":{"cb5a62cc":"import os\nimport cv2\nimport subprocess\nfrom tqdm.auto import tqdm\nimport pandas as pd\nfrom IPython.display import Video, display, HTML\nimport warnings; warnings.simplefilter(\"ignore\")\n\n\nBASE_PATH = '..\/input\/tensorflow-great-barrier-reef\/train_images\/'\n\ndf = pd.read_csv(\"\/kaggle\/input\/tensorflow-great-barrier-reef\/train.csv\")\ndf['annotations'] = df['annotations'].apply(eval)\ndf['n_annotations'] = df['annotations'].str.len()\ndf['has_annotations'] = df['annotations'].str.len() > 0\ndf['has_2_or_more_annotations'] = df['annotations'].str.len() >= 2\ndf['doesnt_have_annotations'] = df['annotations'].str.len() == 0\ndf['image_path'] = BASE_PATH + \"video_\" + df['video_id'].astype(str) + \"\/\" + df['video_frame'].astype(str) + \".jpg\"","a5773d2c":"df","0c9d0550":"df['sequence'].unique()","840795dc":"df['sequence'].nunique()","4acdf776":"df.groupby(\"sequence\")['video_id'].nunique()","60003a01":"# Videos 0 and 1 have 8 sequences, while video 2 has 4\ndf.groupby(\"video_id\")['sequence'].nunique()","f8fd75bb":"df_agg = df.groupby([\"video_id\", 'sequence']).agg({'sequence_frame': 'count', 'has_annotations': 'sum', 'doesnt_have_annotations': 'sum'})\\\n           .rename(columns={'sequence_frame': 'Total Frames', 'has_annotations': 'Frames with at least 1 object', 'doesnt_have_annotations': \"Frames with no object\"})\ndf_agg","7ec6c045":"df_agg.sort_values(\"Total Frames\")","1ccc6581":"df_agg.sort_values(\"Frames with at least 1 object\")","732bf89d":"# image_id is a unique identifier for a row\ndf['image_id'].nunique() == len(df)","0061e793":"df_agg.loc[[(0, 40258)]]","90a3d095":"pd.set_option(\"display.max_rows\", 500)\ndf[df['sequence'] == 40258]","ee600746":"df['start_cut_here'] = df['has_annotations'] & df['doesnt_have_annotations'].shift(1)  & df['doesnt_have_annotations'].shift(2)\ndf['end_cut_here'] = df['doesnt_have_annotations'] & df['has_annotations'].shift(1)  & df['has_annotations'].shift(2)\ndf['sequence_change'] = df['sequence'] != df['sequence'].shift(1)\ndf['last_row'] =  df.index == len(df)-1\ndf['cut_here'] = df['start_cut_here'] | df['end_cut_here'] | df['sequence_change'] | df['last_row']","c8d92aa8":"start_idx = 0\nfor subsequence_id, end_idx in enumerate(df[df['cut_here']].index):\n    df.loc[start_idx:end_idx, 'subsequence_id'] = subsequence_id\n    start_idx = end_idx","7710e976":"df['subsequence_id'] = df['subsequence_id'].astype(int)","17aaf630":"df['subsequence_id'].nunique()","b7602bd5":"drop_cols = ['start_cut_here', 'end_cut_here', 'sequence_change', 'last_row', 'cut_here', 'has_2_or_more_annotations', 'doesnt_have_annotations']\ndf = df.drop(drop_cols, axis=1)\ndf.head()","1ceb356d":"df.groupby(\"subsequence_id\")['has_annotations'].mean().round(2).sort_values().value_counts()","9493c7e6":"df_subseq_agg = df.groupby(\"subsequence_id\")['has_annotations'].mean()\ndf_subseq_agg[~df_subseq_agg.isin([0, 1])]","0af087bc":"df[df['subsequence_id'] == 52]","f0d86dae":"df[df['subsequence_id'] == 53]","a0a7be24":"df[df['subsequence_id'] == 54]","09461196":"! mkdir videos\/","0bdbf04c":"def load_image(img_path):\n    assert os.path.exists(img_path), f'{img_path} does not exist.'\n    img = cv2.imread(img_path)\n    return img\n\ndef load_image_with_annotations(img_path, annotations):\n    img = load_image(img_path)\n    if len(annotations) > 0:\n        for ann in annotations:\n            cv2.rectangle(img, (ann['x'], ann['y']),\n                (ann['x'] + ann['width'], ann['y'] + ann['height']),\n                (255, 255, 0), thickness=2,)\n    return img\n\ndef make_video(df, part_id, is_subsequence=False):\n    \"\"\"\n    Args:\n        - part_id: either a sequence or a subsequence id\n    \"\"\"\n    \n    if is_subsequence:\n        part_str = \"subsequence_id\"\n    else:\n        part_str = \"sequence\"\n    \n    print(f\"Creating video for part={part_id}, is_subsequence={is_subsequence} (querying by {part_str})\")\n    # partly borrowed from https:\/\/github.com\/RobMulla\/helmet-assignment\/blob\/main\/helmet_assignment\/video.py\n    fps = 15 # don't know exact value\n    width = 1280\n    height = 720\n    save_path = f'videos\/video_{part_str}_{part_id}.mp4'\n    tmp_path = f'videos\/tmp_video_{part_str}_{part_id}.mp4'\n    \n    \n    output_video = cv2.VideoWriter(tmp_path, cv2.VideoWriter_fourcc(*\"MP4V\"), fps, (width, height))\n    \n    df_part = df.query(f'{part_str} == @part_id')\n    for _, row in tqdm(df_part.iterrows(), total=len(df_part)):\n        img = load_image_with_annotations(row.image_path, row.annotations)\n        output_video.write(img)\n    \n    output_video.release()\n    # Not all browsers support the codec, we will re-load the file at tmp_output_path\n    # and convert to a codec that is more broadly readable using ffmpeg\n    if os.path.exists(save_path):\n        os.remove(save_path)\n    subprocess.run(\n        [\"ffmpeg\", \"-i\", tmp_path, \"-crf\", \"18\", \"-preset\", \"veryfast\", \"-vcodec\", \"libx264\", save_path],\n        stdout=subprocess.DEVNULL,\n        stderr=subprocess.DEVNULL\n    )\n    os.remove(tmp_path)\n    print(f\"Finished creating video for {part_id}... saved as {save_path}\")\n    return save_path","b7e029b9":"video_path = make_video(df, 40258)","42397cc0":"Video(video_path, width= 1280\/2, height= 720\/2)","81c074ff":"subsequences = df.loc[df['sequence'] == 40258, 'subsequence_id'].unique()\nsubsequences","d7c88708":"for subsequence in subsequences:\n    video_path = make_video(df, subsequence, is_subsequence=True)\n    display(HTML(f\"<h2>Subsequence ID: {subsequence}<\/h2>\"))\n    display(Video(video_path, width= 1280\/2, height= 720\/2))","60293fd5":"from sklearn.model_selection import train_test_split, StratifiedKFold\ndf.head()","cd8ffeb0":"df_split  = df.groupby(\"subsequence_id\").agg({'has_annotations': 'max', 'video_frame': 'count'}).astype(int).reset_index()\ndf_split.head()","21ad2388":"!mkdir train-validation-split\/","de9b8ccf":"def analize_split(df_train, df_val, df):\n     # Analize results\n    print(f\"   Train images                 : {len(df_train) \/ len(df):.3f}\")\n    print(f\"   Val   images                 : {len(df_val) \/ len(df):.3f}\")\n    print()\n    print(f\"   Train images with annotations: {len(df_train[df_train['has_annotations']]) \/ len(df[df['has_annotations']]):.3f}\")\n    print(f\"   Val   images with annotations: {len(df_val[df_val['has_annotations']]) \/ len(df[df['has_annotations']]):.3f}\")\n    print()\n    print(f\"   Train images w\/no annotations: {len(df_train[~df_train['has_annotations']]) \/ len(df[~df['has_annotations']]):.3f}\")\n    print(f\"   Val   images w\/no annotations: {len(df_val[~df_val['has_annotations']]) \/ len(df[~df['has_annotations']]):.3f}\")\n    print()\n    print(f\"   Train mean annotations       : {df_train['n_annotations'].mean():.3f}\")\n    print(f\"   Val   mean annotations       : {df_val['n_annotations'].mean():.3f}\")\n    \n    print()","be0de672":"for test_size in [0.01, 0.05, 0.1, 0.2]:\n    print(f\"Generating train-validation split with {test_size*100}% validation\")\n    df_train_idx, df_val_idx = train_test_split(df_split['subsequence_id'], stratify=df_split[\"has_annotations\"], test_size=test_size, random_state=42)\n    df['is_train'] = df['subsequence_id'].isin(df_train_idx)\n    df_train, df_val = df[df['is_train']], df[~df['is_train']]\n    \n    # Print some statistics\n    analize_split(df_train, df_val, df)\n    \n    # Save to file\n    f_name = f\"train-validation-split\/train-{test_size}.csv\"\n    print(f\"Saving file to {f_name}\")\n    df.to_csv(f_name, index=False)\n    print()","fd9395d4":"!ls -l train-validation-split\/","7405436f":"df = df.drop(\"is_train\", axis=1)","a3001bc3":"n_splits = 5\nkf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=2021)\nfor fold_id, (_, val_idx) in enumerate(kf.split(df_split['subsequence_id'], y=df_split[\"has_annotations\"])):\n    subseq_val_idx = df_split['subsequence_id'].iloc[val_idx]\n    df.loc[df['subsequence_id'].isin(subseq_val_idx), 'fold'] = fold_id\n    \ndf['fold'] = df['fold'].astype(int)\ndf['fold'].value_counts(dropna=False)","4a4e8e24":"for fold_id in df['fold'].sort_values().unique():\n    print(\"=============================\")\n    print(f\"Analyzing fold {fold_id}\")\n    df_train, df_val = df[df['fold'] != fold_id], df[df['fold'] == fold_id]\n    analize_split(df_train, df_val, df)\n    print()","104b66a6":"!mkdir cross-validation\/","a14027c2":"df.to_csv(\"cross-validation\/train-5folds.csv\", index=False)","e64c47ba":"n_splits = 10\nkf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=2021)\nfor fold_id, (_, val_idx) in enumerate(kf.split(df_split['subsequence_id'], y=df_split[\"has_annotations\"])):\n    subseq_val_idx = df_split['subsequence_id'].iloc[val_idx]\n    df.loc[df['subsequence_id'].isin(subseq_val_idx), 'fold'] = fold_id\n    \ndf['fold'] = df['fold'].astype(int)\ndf['fold'].value_counts(dropna=False)","eaf2dca8":"for fold_id in df['fold'].sort_values().unique():\n    print(\"=============================\")\n    print(f\"Analyzing fold {fold_id}\")\n    df_train, df_val = df[df['fold'] != fold_id], df[df['fold'] == fold_id]\n    analize_split(df_train, df_val, df)\n    print()","89ab0072":"df.to_csv(\"cross-validation\/train-10folds.csv\", index=False)","960329f8":"# Create 5-folds cross validation","16cc2932":"# Let's see how a sequence and a subsequence look like as videos!!","9cdc58e0":"# **Analyze sequences**","f1db366e":"# Generate some common splits based on subsequences\u00b6","e3e60f62":"# **Reference**\n###  [\ud83d\udc20 Reef - A CV strategy: subsequences!](https:\/\/www.kaggle.com\/julian3833\/reef-a-cv-strategy-subsequences?scriptVersionId=80623179)","8c853e3b":"#### You can criticize my work or give your suggestion, your comment is a treasure of knowledge for me\n##### P.S. sorry for a poor grammar","a1084d34":"# Create 10-fold cross validation","045871db":"# Train-validation splits for 1%, 5%, 10% and 20%","6716fe51":"# **About author: I'm a beginner in this field trying to learn and discovering the enjoyment of Data Science**\n### Note1: This notebook is a copy version of the reference, there're no editing yet because I'm trying to learn and uderstand the process.\n### Note2: If this notebook is useful for you in anyway, please give an upvote or commenting your gratitude on the notebook in the reference section. "}}