{"cell_type":{"13746726":"code","53607d9a":"code","bfc88827":"code","3f367e84":"code","676e9889":"code","0e9085f9":"code","42819621":"code","27cb2fa2":"code","71ee5c47":"code","d753f0ba":"code","6c445947":"code","f79e3286":"code","81d001f8":"code","3b1b4b45":"markdown","b383cee9":"markdown","4737ef4c":"markdown"},"source":{"13746726":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom pandas import read_csv\nimport math\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","53607d9a":"df = pd.read_csv('\/kaggle\/input\/5) Recurrent Neural Network\/international-airline-passengers.csv',skipfooter=5)","bfc88827":"df.head()","3f367e84":"dataset = df.iloc[:,1].values\nplt.plot(dataset)\nplt.xlabel('time')\nplt.ylabel('number of passengers')\nplt.title('Internatoinal Airline Passenger')\nplt.show()","676e9889":"dataset = dataset.reshape(-1,1)\ndataset = dataset.astype('float32')\ndataset.shape","0e9085f9":"scaler = MinMaxScaler(feature_range=(0,1))\ndataset = scaler.fit_transform(dataset)","42819621":"train_size = int(len(dataset)*0.50)\ntest_size = len(dataset) - train_size\ntrain = dataset[0:train_size,:]\ntest = dataset[train_size:len(dataset),:]\nprint('train_size : {}, test_size : {}'.format(len(train),len(test)))","27cb2fa2":"timestamp=10\ndataX = []\ndataY = []\nfor i in range(len(train)-timestamp-1):\n    a = train[i:(i+timestamp),0]\n    dataX.append(a)\n    dataY.append(train[i+timestamp,0])\ntrainX = np.array(dataX)\ntrainY = np.array(dataY)\n","71ee5c47":"timestep=10\ndataX = []\ndataY = []\nfor i in range(len(test)-timestamp-1):\n    a = test[i:(i+timestamp),0]\n    dataX.append(a)\n    dataY.append(test[i+timestamp,0])\ntestX = np.array(dataX)\ntestY = np.array(dataY)","d753f0ba":"trainX = np.reshape(trainX,(trainX.shape[0],1,trainX.shape[1]))\ntestX = np.reshape(testX,(testX.shape[0],1,testX.shape[1]))","6c445947":"# model\nmodel = Sequential()\nmodel.add(LSTM(10, input_shape=(1, timestamp))) # 10 lstm neuron(block)\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nmodel.fit(trainX, trainY, epochs=50, batch_size=1)","f79e3286":"trainPredict = model.predict(trainX)\ntestPredict = model.predict(testX)\n\ntrainPredict = scaler.inverse_transform(trainPredict)\ntrainY = scaler.inverse_transform([trainY])\ntestPredict = scaler.inverse_transform(testPredict)\ntestY = scaler.inverse_transform([testY])\n\ntrainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\nprint('Test Score: %.2f RMSE' % (testScore))","81d001f8":"trainPredictPlot = np.empty_like(dataset)\ntrainPredictPlot[:, :] = np.nan\ntrainPredictPlot[timestamp:len(trainPredict)+timestamp, :] = trainPredict\n\ntestPredictPlot = np.empty_like(dataset)\ntestPredictPlot[:, :] = np.nan\ntestPredictPlot[len(trainPredict)+(timestamp*2)+1:len(dataset)-1, :] = testPredict\n\nplt.plot(scaler.inverse_transform(dataset))\nplt.plot(trainPredictPlot)\nplt.plot(testPredictPlot)\nplt.show()","3b1b4b45":"## Create LSTM Model","b383cee9":"## Preprocessing","4737ef4c":"## Input"}}