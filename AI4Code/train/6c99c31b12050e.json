{"cell_type":{"78860715":"code","e0d326c9":"code","a6e3c548":"code","241d172a":"code","7c8892cf":"code","fb95fb92":"code","c8bc82aa":"code","73182490":"code","4b392ecc":"code","507b0a90":"code","14066aae":"code","d6a9adf7":"code","bc848f3a":"code","12025a0e":"code","896e4ed3":"code","fa3f1948":"code","29ee6bc8":"code","46c050c7":"code","d8ad6633":"code","ce29c774":"code","23da741e":"code","bbd7ad6f":"code","52483b96":"code","826535e9":"code","cf3d8ed7":"code","d9c1189e":"code","42f0236b":"code","5d8b4eff":"code","2898feb4":"code","9d158b1e":"code","90513093":"code","12eb204f":"code","f2c7f1fd":"code","80b2bf9f":"code","f7419141":"code","1da264f1":"code","9984c1a2":"code","1f4bb42e":"code","2da57f84":"code","3806395a":"code","f2f0a98d":"code","be34aabd":"code","8529a684":"code","2475325b":"code","e98eb9ad":"code","fd0ed9e7":"code","0b5f8d2f":"code","08126100":"code","12a02fd6":"markdown"},"source":{"78860715":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e0d326c9":"train_path = '\/kaggle\/input\/global-wheat-detection\/train.csv'\npath = '\/kaggle\/input\/global-wheat-detection\/train\/'\ntest_path = '\/kaggle\/input\/global-wheat-detection\/test\/'\ntemp_path = '\/kaggle\/working\/'","a6e3c548":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport urllib\nimport cv2\nfrom matplotlib import pyplot as plt\n\n%matplotlib inline\n","241d172a":"data_table = pd.read_csv(train_path)\ndata_table.head()","7c8892cf":"annotations = pd.DataFrame(columns=['id_path', 'x1','y1','w','h','class'])\nannotations.head()","fb95fb92":"a = 0\nfor id in data_table['image_id']:\n  jpg_path = os.path.join(path, id + '.jpg')\n  data_table.iat[a,0]=jpg_path\n  a+=1\n","c8bc82aa":"annotations['id_path']=data_table['image_id']\nannotations.head()","73182490":"annotations['id_path'][0]","4b392ecc":"a = 0\nfor i in data_table['bbox']:\n  item = i.split(',')\n  annotations.iat[a,1] = item[0]\n  annotations.iat[a,2] = item[1]\n  annotations.iat[a,3] = item[2]\n  annotations.iat[a,4] = item[3]\n  a+=1\nannotations.head() ","507b0a90":"annotations['x1'].replace({'\\[':''}, regex=True, inplace=True)\nannotations['h'].replace({']':''}, regex=True, inplace=True)","14066aae":"annotations['class']='wheat'","d6a9adf7":"annotations['x1']=pd.to_numeric(annotations['x1'])\nannotations['y1']=pd.to_numeric(annotations['y1'])\nannotations['w']=pd.to_numeric(annotations['w'])\nannotations['h']=pd.to_numeric(annotations['h'])\nannotations['x1']=annotations['x1'].astype(int)\nannotations['y1']=annotations['y1'].astype(int)\nannotations['w']=annotations['w'].astype(int)\nannotations['h']=annotations['h'].astype(int)","bc848f3a":"for i in range(len(annotations['w'])):\n    annotations['w'][i]=annotations['x1'][i]+annotations['w'][i]","12025a0e":"for i in range(len(annotations['h'])):\n    annotations['h'][i]=annotations['y1'][i]+annotations['h'][i]","896e4ed3":"annotations.head()","fa3f1948":"annotations.info()","29ee6bc8":"annotations.to_csv(temp_path + 'annot.csv', header=False, index=False)","46c050c7":"class_df = pd.DataFrame(columns=['class','class_id'],index=[0])","d8ad6633":"class_df['class']='wheat'\nclass_df['class_id']=0\nclass_df","ce29c774":"class_df.to_csv(temp_path + 'class.csv', header=False, index=False)","23da741e":"im_path = annotations['id_path'][0]\nim_path","bbd7ad6f":"x1 = annotations['x1'][1]\nw = annotations['w'][1]\ny1 = annotations['y1'][1]\nh = annotations['h'][1]","52483b96":"im= cv2.imread(im_path)\nim = cv2.rectangle(im, (x1, y1), (w, h), (255,0,0), 2)\nplt.imshow(im)\nplt.show()","826535e9":"!git clone https:\/\/github.com\/fizyr\/keras-retinanet.git","cf3d8ed7":"%cd keras-retinanet\/\n!pip install .","d9c1189e":"!python setup.py build_ext --inplace","42f0236b":"PRETRAINED_MODEL = '.\/snapshots\/_pretrained_model.h5'\nPRETRAINED_MODEL1 = '\/kaggle\/working\/keras-retinanet\/snapshots\/resnet50_csv_06.h5'\n\nURL_MODEL = 'https:\/\/github.com\/fizyr\/keras-retinanet\/releases\/download\/0.5.1\/resnet50_coco_best_v2.1.0.h5'\nurllib.request.urlretrieve(URL_MODEL, PRETRAINED_MODEL)\n\nprint('Downloaded pretrained model to ' + PRETRAINED_MODEL)","5d8b4eff":"EPOCHS = 6\nBATCH_SIZE=8\nSTEPS = 100 \nLR=0.0001","2898feb4":"!keras_retinanet\/bin\/train.py --random-transform --weights {PRETRAINED_MODEL1} --lr {LR} --batch-size {BATCH_SIZE} --steps {STEPS} --epochs {EPOCHS} --no-resize csv \/kaggle\/working\/annot.csv \/kaggle\/working\/class.csv","9d158b1e":"test_images = os.listdir(test_path)","90513093":"import tensorflow as tf\nfrom keras_retinanet import models\nfrom keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\nfrom keras_retinanet.utils.visualization import draw_box, draw_caption\nfrom keras_retinanet.utils.colors import label_color","12eb204f":"!ls snapshots","f2c7f1fd":"removing_path = '\/kaggle\/working\/keras-retinanet\/snapshots\/'\nos.remove(removing_path+'resnet50_csv_01.h5')\nos.remove(removing_path+'resnet50_csv_06.h5')\nos.remove(removing_path+'resnet50_csv_03.h5')\nos.remove(removing_path+'resnet50_csv_04.h5')\nos.remove(removing_path+'resnet50_csv_05.h5')","80b2bf9f":"model_path = os.path.join('snapshots', 'resnet50_csv_02.h5')\n\nmodel = models.load_model(model_path, backbone_name='resnet50')\nmodel = models.convert_model(model)","f7419141":"def prediction(image):\n    image = preprocess_image(image.copy())\n    boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n    return boxes, scores, labels","1da264f1":"thres = 0.5","9984c1a2":"def draw_detections(image, boxes, scores, labels):\n    for box, score, label in zip(boxes[0], scores[0], labels[0]):\n        if score < thres:\n            break\n\n        color = label_color(label)\n\n        b = box.astype(int)\n        draw_box(image, b, color=color)\n\n        caption = \"{:.3f}\".format(score)\n        draw_caption(image, b, caption)","1f4bb42e":"def show_detected_objects(image_name):\n    img_path = test_path+'\/'+image_name\n  \n    image = read_image_bgr(img_path)\n\n    boxes, scores, labels = prediction(image)\n    print(boxes[0,0].shape)\n    draw = image.copy()\n    draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n\n    draw_detections(draw, boxes, scores, labels)\n    plt.figure(figsize=(15,10))\n    plt.axis('off')\n    plt.imshow(draw)\n    plt.show()","2da57f84":"for img in test_images:\n  \n    show_detected_objects(img)","3806395a":"preds=[]\nimgid=[]\nfor img in test_images:\n    img_path = test_path+'\/'+img\n    image = read_image_bgr(img_path)\n    boxes, scores, labels = prediction(image)\n    boxes=boxes[0]\n    scores=scores[0]\n    for idx in range(boxes.shape[0]):\n        if scores[idx]>thres:\n            box,score=boxes[idx],scores[idx]\n            imgid.append(img.split(\".\")[0])\n            preds.append(\"{} {} {} {} {}\".format(score, int(box[0]), int(box[1]), int(box[2]-box[0]), int(box[3]-box[1])))\n    ","f2f0a98d":"preds[0]","be34aabd":"sub={\"image_id\":imgid, \"PredictionString\":preds}\nsub=pd.DataFrame(sub)\nsub.head()","8529a684":"sub_=sub.groupby([\"image_id\"])['PredictionString'].apply(lambda x: ' '.join(x)).reset_index()\nsub_","2475325b":"submiss=pd.read_csv(\"\/kaggle\/input\/global-wheat-detection\/sample_submission.csv\")\nsubmiss.head()","e98eb9ad":"for idx,imgid in enumerate(submiss['image_id']):\n    submiss.iloc[idx,1]=sub_[sub_['image_id']==imgid].values[0,1]\n    \nsubmiss.head()","fd0ed9e7":"submiss.to_csv('\/kaggle\/working\/submission.csv',index=False)","0b5f8d2f":"annot = '\/kaggle\/working\/annot.csv'\nclass_cs = '\/kaggle\/working\/class.csv'\nretina = '\/kaggle\/working\/keras-retinanet'\n\nos.remove(annot)\nos.remove(class_cs)","08126100":"import shutil\nshutil.rmtree(retina)","12a02fd6":"**Retina Net**"}}