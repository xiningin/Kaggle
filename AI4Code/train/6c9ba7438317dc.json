{"cell_type":{"954502db":"code","61240e91":"code","59dae459":"code","acfea629":"code","d92abf87":"code","0c0c7716":"code","79c65598":"code","9229b9df":"code","da887b86":"code","b8a80dff":"code","2656ae99":"code","e2c50d66":"code","3a0abb77":"code","7690bb25":"code","d65c58d9":"code","71ec6fbc":"code","ebe15c2b":"code","71e39a37":"code","fa5bdff7":"code","52d56f7d":"code","090523c2":"code","e7dba18c":"code","1578f1dc":"code","7390f8dd":"code","84d1ad93":"code","afc282b6":"code","6fb90977":"code","ff2abbb9":"code","ab8abdf2":"code","69192691":"code","9c1ea5a5":"code","3db0b69a":"code","4b577fbb":"code","e79cdd13":"code","0c8f1178":"code","9485e665":"markdown","8d110e76":"markdown","4b4d35af":"markdown","5ad1417c":"markdown","343e9bdc":"markdown","88d37d14":"markdown","33567438":"markdown","a9815da2":"markdown","d53beacf":"markdown","5254f46a":"markdown","440786ee":"markdown","f2a7467a":"markdown","423476a5":"markdown","15b7440f":"markdown","89c73c8e":"markdown","808903fe":"markdown","5215bc6b":"markdown","50c9e285":"markdown","e2c41404":"markdown","427cb591":"markdown","a7ce100e":"markdown","5cf51871":"markdown","7465c431":"markdown","7aba3ecf":"markdown","daffeca8":"markdown","d3ea93d4":"markdown","9fa13a9a":"markdown","c8e1ca9d":"markdown","181b4e61":"markdown"},"source":{"954502db":"!conda install -c conda-forge gdcm -y","61240e91":"from IPython.display import display_html\ndef restartkernel() :\n    display_html(\"<script>Jupyter.notebook.kernel.restart()<\/script>\",raw=True)\nrestartkernel()","59dae459":"import gdcm","acfea629":"import plotly.graph_objs as go\nimport pydicom as dicom\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport cv2\nimport torch\nimport torchvision\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\nimport pandas as pd\nimport numpy as np\nimport gc\nimport os\nimport time\nimport datetime\nimport warnings\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math\nfrom sklearn import preprocessing\nfrom sklearn.compose import ColumnTransformer","d92abf87":"folder_path = '..\/input\/osic-pulmonary-fibrosis-progression'\ntrain_csv = folder_path + '\/train.csv'\ntest_csv = folder_path+ '\/test.csv'\nsample_csv = folder_path + '\/sample_submission.csv'\n\ntrain_data = pd.read_csv(train_csv)\ntest_data = pd.read_csv(test_csv)\nsample = pd.read_csv(sample_csv)\n\nprint(train_data.shape)\nprint(test_data.shape)\nprint(sample.shape)\n\ntrain_data.head()\n","0c0c7716":"test_data.head()","79c65598":"grouped=train_data.groupby('Patient')\npid=[]\nfor name,group in grouped:\n    if np.var(group.FVC)>100000:\n        pid.append(name)\n        print(name)\n        print(np.var(group.FVC),np.std(group.FVC))\n        \nfig =go.Figure()\n\nfor patient in pid:\n    df = train_data[train_data[\"Patient\"] == patient]\n    fig.add_trace(go.Scatter(x=df.Weeks,y=df.FVC,\n                            mode='lines',\n                            name=str(patient)))\nfig.show()","9229b9df":"train=train_data\nfor patient in pid:\n    train=train[train[\"Patient\"] != patient]","da887b86":"grouped=train_data.groupby('Patient')\npid=[]\nfor name,group in grouped:\n    pid.append(name)\n        \nfig =go.Figure()\n\nfor patient in pid:\n    df = train_data[train_data[\"Patient\"] == patient]\n    fig.add_trace(go.Scatter(x=df.Weeks,y=df.FVC,\n                            mode='lines',\n                            name=str(patient)))\nfig.show()","b8a80dff":"\ntrain.drop_duplicates(keep=False, inplace=True, subset=['Patient','Weeks'])\nchunk=test_data\n\nprint(\"add infos\")\nsub =sample\nsub['Patient'] = sub['Patient_Week'].apply(lambda x:x.split('_')[0])\nsub['Weeks'] = sub['Patient_Week'].apply(lambda x: int(x.split('_')[-1]))\nprint(sub.index.size)\nsub =  sub[['Patient','Weeks','Confidence','Patient_Week']]\nsub = sub.merge(test_data.drop('Weeks', axis=1), on=\"Patient\")\nsub.head()","2656ae99":"tr=train\ntr['WHERE'] = 'train'\nchunk['WHERE'] = 'val'\nsub['WHERE'] = 'test'\ndata = tr.append([chunk, sub])","e2c50d66":"data['min_week'] = data['Weeks']\ndata.loc[data.WHERE=='test','min_week'] = np.nan\ndata['min_week'] = data.groupby('Patient')['min_week'].transform('min')\ndata.loc[data.Weeks == data.min_week]","3a0abb77":"base = data.loc[data.Weeks == data.min_week]\nbase = base[['Patient','FVC']].copy()\nbase.columns = ['Patient','min_FVC']\nbase['nb'] = 1\nbase['nb'] = base.groupby('Patient')['nb'].transform('cumsum')\nbase = base[base.nb==1]\nbase.drop('nb', axis=1, inplace=True)\nbase[base.Patient=='ID00419637202311204720264']","7690bb25":"data = data.merge(base, on='Patient', how='left')\ndata['base_week'] = data['Weeks'] - data['min_week']\n#del base\ndata['diff_fvc_prev']=data['FVC'].diff(1)\/data['FVC'].shift(1)\ndata[data.Patient=='ID00007637202177411956430']","d65c58d9":"COLS = ['Sex','SmokingStatus'] #,'Age'\nFE = []\nfor col in COLS:\n    for mod in data[col].unique():\n        FE.append(mod)\n        data[mod] = (data[col] == mod).astype(int)","71ec6fbc":"data['age'] = (data['Age'] - data['Age'].min() ) \/ ( data['Age'].max() - data['Age'].min() )\ndata['BASE'] = (data['min_FVC'] - data['min_FVC'].min() ) \/ ( data['min_FVC'].max() - data['min_FVC'].min() )\ndata['week'] = (data['base_week'] - data['base_week'].min() ) \/ ( data['base_week'].max() - data['base_week'].min() )\ndata['percent'] = (data['Percent'] - data['Percent'].min() ) \/ ( data['Percent'].max() - data['Percent'].min() )\n\nFE += ['age','percent','week','BASE']\ndata[FE]","ebe15c2b":"data=data.fillna(0)\n\ndata.head()","71e39a37":"tr = data.loc[data.WHERE=='train']\nchunk = data.loc[data.WHERE=='val']\nsub = data.loc[data.WHERE=='test']","fa5bdff7":"count=0\nfor dirname, _, filenames in os.walk('..\/input\/osic-pulmonary-fibrosis-progression\/test'):\n    for filename in filenames:\n        count=count+1\nprint(\"Count of total files in test data:\",count)","52d56f7d":"patients = train['Patient'].unique()\ndata_dir = '..\/input\/osic-pulmonary-fibrosis-progression' + '\/train\/'\n\nfor patient in patients[0:5]:\n    #patient='ID00026637202179561894768'\n    #label = labels_df.get_value(patient, 'cancer')\n    path = data_dir + patient\n\n    # a couple great 1-liners from: https:\/\/www.kaggle.com\/gzuidhof\/data-science-bowl-2017\/full-preprocessing-tutorial\n    slices = [dicom.dcmread(path + '\/' + s) for s in os.listdir(path)]\n    try:\n        slices.sort(key = lambda x: int(x.ImagePositionPatient[2]))\n    except:\n        print(patient,slices.ImagePositionPatient[2])\n        break\n    print(patient,slices[0].pixel_array.shape, len(slices))","090523c2":"samp=['ID00009637202177434476278','ID00014637202177757139317']","e7dba18c":"IMG_PX_SIZE = 150\n\nfor patient in patients[:1]:\n    \n    path = data_dir + patient\n    slices = [dicom.read_file(path + '\/' + s) for s in os.listdir(path)]\n    slices.sort(key = lambda x: int(x.ImagePositionPatient[2]))\n    fig = plt.figure()\n    for num,each_slice in enumerate(slices[:12]):\n        y = fig.add_subplot(3,4,num+1)\n        new_img = cv2.resize(np.array(each_slice.pixel_array),(IMG_PX_SIZE,IMG_PX_SIZE))\n        y.imshow(new_img,cmap='gray')\n    plt.show()","1578f1dc":"MIN_BOUND = -1000.0\nMAX_BOUND = 400.0\n    \n\ndef get_pixels_hu(slices):\n    image = np.stack([s.pixel_array for s in slices])\n    # Convert to int16 (from sometimes int16), \n    # should be possible as values should always be low enough (<32k)\n    image = image.astype(np.int16)\n\n    # Set outside-of-scan pixels to 0\n    # The intercept is usually -1024, so air is approximately 0\n    image[image == -2000] = 0\n    \n    # Convert to Hounsfield units (HU)\n    for slice_number in range(len(slices)):\n        \n        intercept = slices[slice_number].RescaleIntercept\n        slope = slices[slice_number].RescaleSlope\n        \n        if slope != 1:\n            image[slice_number] = slope * image[slice_number].astype(np.float64)\n            image[slice_number] = image[slice_number].astype(np.int16)\n            \n        image[slice_number] += np.int16(intercept)\n    return np.array(image, dtype=np.int16)\n\n\n\ndef normalize(image):\n    image = (image - MIN_BOUND) \/ (MAX_BOUND - MIN_BOUND)\n    image[image>1] = 1.\n    image[image<0] = 0.\n    return image\n\n\nPIXEL_MEAN = 0.25\ndef zero_center(image):\n    image = image - PIXEL_MEAN\n    return image","7390f8dd":"from PIL import Image\ndef process_data(patient,data_dir,img_px_size=64, HM_SLICES=10, visualize=False,):\n    def chunks(l, n):\n    # Credit: Ned Batchelder\n    # Link: http:\/\/stackoverflow.com\/questions\/312443\/how-do-you-split-a-list-into-evenly-sized-chunks\n   \n        for i in range(0, len(l), n):\n            yield l[i:i + n]\n\n    def mean(l):\n        return sum(l) \/ len(l)\n    #patient='ID00422637202311677017371'\n    \n    path = data_dir + patient\n    slices = [dicom.read_file(path + '\/' + s) for s in os.listdir(path)]\n    try:\n        print(patient)\n        # sorting the ct scan of a patient based on the 3D position of the scan\n        slices.sort(key = lambda x: int(x.ImagePositionPatient[2]))\n    except:\n        print(patient,\"No Image position patient\")\n        return []\n        \n    new_slices = []\n    # 1-Converting pixel data to HU\n    slices= get_pixels_hu(slices)\n    # 2-Chunking the overall images in to 10 images for each patient\n    chunk_sizes = round(len(slices) \/ HM_SLICES)\n    if(len(slices)%HM_SLICES!=0):\n        a=math.floor((len(slices) \/ HM_SLICES))\n        b=math.ceil(len(slices) \/ HM_SLICES)\n        x=abs((len(slices)-(b*HM_SLICES))\/(b-a))\n        y=HM_SLICES - x         \n\n        split=int(x*a)\n\n        for slice_chunk in chunks(slices[:split], a):\n            slice_chunk = list(map(mean, zip(*slice_chunk)))\n            new_slices.append(slice_chunk)\n        for slice_chunk in chunks(slices[split:], b):\n            slice_chunk = list(map(mean, zip(*slice_chunk)))\n            new_slices.append(slice_chunk)\n    else:\n        chunk_sizes = round(len(slices) \/ HM_SLICES)\n        for slice_chunk in chunks(slices, chunk_sizes):\n            slice_chunk = list(map(mean, zip(*slice_chunk)))\n            #3-Normalising the values of images(slices)\n            b=normalize(np.array(slice_chunk))\n            #4-Zero centering the above pixels\n            slice_chunk=zero_center(b)\n            new_slices.append(slice_chunk)\n    real_slices = []\n    fig = plt.figure()\n    for num,each_slice in enumerate(new_slices):\n        #5- Resizing the Images\n        each_slice = cv2.resize(np.array(each_slice),(IMG_PX_SIZE,IMG_PX_SIZE))\n        real_slices.append(each_slice)\n        #print(np.array(each_slice).shape)\n        y = fig.add_subplot(4,5,num+1)\n        y.imshow(each_slice, cmap='gray')\n    plt.show()\n    return np.array(real_slices),\n\nIMG_PX_SIZE = 64\nHM_SLICES = 64\n\ndata_dir = '..\/input\/osic-pulmonary-fibrosis-progression' + '\/train\/'\nmuch_data = []\n\n\n    ","84d1ad93":"for num,patient in enumerate(patients[:2]):\n    if num % 100 == 0:\n        print(num)\n    try:\n        \n        img_data = process_data(patient,data_dir)\n        #print(img_data.shape,label)\n        much_data.append([img_data])\n    except KeyError as e:\n        print('This is unlabeled data!')\n\n#np.save('..\/input\/osic-pulmonary-fibrosis-progression\/images\/muchdata-{}-{}-{}.npy'.format(64,64,64), much_data)\n","afc282b6":"tr.head()","6fb90977":"tr.columns","ff2abbb9":"columns=['Weeks','Percent','Age','WHERE','SmokingStatus','Sex']\ntr=tr.drop(columns,axis=1)\ntr.head()\n","ab8abdf2":"#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nclass CtscanDataset(Dataset):\n    def __init__(self, df: pd.DataFrame, imfolder: str, train: bool = True,  meta_features = None):\n        \"\"\"\n        Class initialization\n        Args:\n            df (pd.DataFrame): DataFrame with data description\n            imfolder (str): folder with images\n            train (bool): flag of whether a training dataset is being initialized or testing one\n            transforms: image transformation method to be applied\n            meta_features (list): list of features with meta information, such as sex and age\n            \n        \"\"\"\n        self.df = df\n        self.imfolder = imfolder        \n        self.train = train\n        self.meta_features = meta_features\n        \n    def __getitem__(self, index):\n        im_path = os.path.join(self.imfolder, self.df.iloc[index]['Patient'] + '.dcm')\n        patient=self.df.iloc[index]['Patient']\n        x = process_data(patient,self.imfolder)\n        \n        try:\n            meta = np.array(self.df.iloc[index,1:].values, dtype=np.float32)\n            meta=torch.tensor(meta,dtype=torch.float32)\n            x=torch.tensor(x,dtype=torch.float32)\n            if self.train:\n                y = self.df.iloc[index]['FVC']\n                y=torch.tensor(y,dtype=torch.float32)\n                return (x, meta), y\n            else:\n                return (x, meta)\n        except:\n            print('error')\n    \n    def __len__(self):\n        return len(self.df)","69192691":"train_1 = CtscanDataset(df=tr.loc[tr['Patient'].isin(samp)],\n                       imfolder='..\/input\/osic-pulmonary-fibrosis-progression\/train\/', \n                       train=True,  )","9c1ea5a5":"train_1[0][0][0].shape","3db0b69a":"class Model(nn.Module):\n\n    def __init__(self):\n\n        \n        super(Model, self).__init__()\n\n        self.conv_layer1 = self._make_conv_layer(1, 32)\n        self.conv_layer2 = self._make_conv_layer(32, 64)\n        self.conv_layer4 = self._make_conv_layer(64, 256)\n        self.conv_layer5=nn.Conv3d(256, 256, kernel_size=(1, 3, 3), padding=0)\n        \n        self.fc5 = nn.Linear(4096, 256)\n        self.relu = nn.LeakyReLU()\n        self.batch0=nn.BatchNorm1d(256)\n        self.drop=nn.Dropout(p=0.15)        \n        self.fc6 = nn.Linear(256, 124)\n        self.relu = nn.LeakyReLU()\n        self.batch1=nn.BatchNorm1d(124)\n        \n        self.drop=nn.Dropout(p=0.15)\n        self.fc7 = nn.Linear(124, 128)\n        \n        \n        self.layer1 = nn.Linear(16,128)\n        self.relu1 = nn.LeakyReLU()\n        self.layer2 = nn.Linear(128,128)\n        self.relu2 = nn.LeakyReLU()\n        self.out1 = nn.Linear(256,3)\n        self.relu3 = nn.ReLU()\n        self.out2 = nn.Linear(256,3)\n\n    def _make_conv_layer(self, in_c, out_c):\n        conv_layer = nn.Sequential(\n        nn.Conv3d(in_c, out_c, kernel_size=(2, 3, 3), padding=0),\n        nn.LeakyReLU(),\n        nn.Conv3d(out_c, out_c, kernel_size=(2, 3, 3), padding=1),\n        nn.LeakyReLU(),\n        nn.MaxPool3d((2, 2, 2)),\n        )\n        return conv_layer\n\n    def forward(self, inputs):\n        #print(x.size())\n        x,meta=inputs\n        meta = self.relu1(self.layer1(meta))\n        meta = self.relu2(self.layer2(meta))\n        x = self.conv_layer1(x)\n        #print(x.size())\n        x = self.conv_layer2(x)\n        x = self.conv_layer4(x)\n        #print(x.size())\n        x=self.conv_layer5(x)\n        #print(x.size())\n        x = x.view(x.size(0), -1)\n        x = self.fc5(x)\n        x = self.relu(x)\n        x = self.batch0(x)\n        x = self.drop(x)\n        x = self.fc6(x)\n        x = self.relu(x)\n        x = self.batch1(x)\n        x = self.drop(x)\n        x = self.fc7(x)\n        feat = torch.cat((x, meta), dim=1)\n        o1 = self.out1(feat)\n        o2 = F.relu(self.out2(feat))\n        return o1 + torch.cumsum(o2,dim=1)","4b577fbb":"\n\ndef score(outputs,target):\n    confidence = outputs[:,2] - outputs[:,0]\n    clip = torch.clamp(confidence,min=70)\n    target=torch.reshape(target,outputs[:,1].shape)\n    delta = torch.abs(outputs[:,1] - target)\n    delta = torch.clamp(delta,max=1000)\n    sqrt_2 = torch.sqrt(torch.tensor([2.])).to(device)\n    metrics = (delta*sqrt_2\/clip) + torch.log(clip*sqrt_2)\n    return torch.mean(metrics)\n\ndef qloss(outputs,target):\n    qs = [0.25,0.5,0.75]\n    qs = torch.tensor(qs,dtype=torch.float).to(device)\n    e =  target - outputs\n    e.to(device)\n    v = torch.max(qs*e,(qs-1)*e)\n    v = torch.sum(v,dim=1)\n    return torch.mean(v)\n\ndef loss_fn(outputs,target,l):\n    return l * qloss(outputs,target) + (1- l) * score(outputs,target)\n\ndef train_loop(train_loader,model,loss_fn,device,optimizer,lr_scheduler=None):\n    model.train()\n    losses = list()\n    metrics = list()\n    for i, (data, labels) in enumerate(train_loader):\n        data[0] = data[0].to(device)\n        data[1] = data[1].to(device)\n        labels = labels.to(device)\n\n        optimizer.zero_grad()\n        with torch.set_grad_enabled(True):           \n            outputs = model(data)                 \n            metric = score(outputs,labels)\n\n            loss = loss_fn(outputs,labels,0.8)\n            metrics.append(metric.cpu().detach().numpy())\n            losses.append(loss.cpu().detach().numpy())\n\n            loss.backward()\n\n            optimizer.step()\n            if lr_scheduler != None:\n                lr_scheduler.step()\n\n    return losses,metrics\n\ndef valid_loop(valid_loader,model,loss_fn,device):\n    model.eval()\n    losses = list()\n    metrics = list()\n    for i, (inputs, labels) in enumerate(valid_loader):\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        outputs = model(inputs)                 \n        metric = score(outputs,labels)\n\n        loss = loss_fn(outputs,labels,0.8)\n        metrics.append(metric.cpu().detach().numpy())\n        losses.append(loss.cpu().detach().numpy())\n\n    return losses,metrics    \n","e79cdd13":"batch_size =16\ntrain_1 = CtscanDataset(df=tr.loc[tr['Patient'].isin(samp)][:3],\n                       imfolder='..\/input\/osic-pulmonary-fibrosis-progression\/train\/', \n                       train=True,  )\ntrain_loader = torch.utils.data.DataLoader(dataset=train_1,\n                                           batch_size=batch_size, shuffle=True)\n","0c8f1178":"import torch.optim as optim\nn_epochs = 10\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = Model()\nmodel.to(device)\noptimizer = optim.Adam(model.parameters(),lr=0.1)\nlr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n\nfor epoch in range(n_epochs):\n    print(epoch)\n    train_loop(train_loader,model,loss_fn,device,optimizer,lr_scheduler)\n    #evaluate(train_loader)","9485e665":"Finding the shape of each image of a patient and the no of files related to a patient","8d110e76":"### Defining the loss function and training loop","4b4d35af":"## Processing Image files","5ad1417c":"# Loading files","343e9bdc":"Splitting the combined data back to train,test,submission data","88d37d14":"Filling Null values","33567438":"# Cleaning Tabular data","a9815da2":"### Training the dataset","d53beacf":"### Concatinating the tabular data with image data using the CtscanDataset function","5254f46a":"I have observed lot of varince in the FVC of few patients so I have decided to drop them","440786ee":"Improvements:\n- Better Image processing\n- Playing with the model\n    ","f2a7467a":"## Preprocessing of the image dataset","423476a5":"**Importing Libraries **","15b7440f":"Credits to the following note books for haleping me finish this:\n- For Model,loss function: https:\/\/www.kaggle.com\/maunish\/osic-super-cool-eda-and-pytorch-baseline\n- For concatinating image and tabular data: https:\/\/www.kaggle.com\/nroman\/melanoma-pytorch-starter-efficientnet\n- For chinking the image data: https:\/\/www.kaggle.com\/sentdex\/first-pass-through-data-w-3d-convnet\n- For preprocessing of the image data: https:\/\/www.kaggle.com\/gzuidhof\/full-preprocessing-tutorial","89c73c8e":"# I have found a way to combine a way to combine 3d images with the tabular data for thefinal prediction","808903fe":"# Normalising Tabular data","5215bc6b":"For Preprocessing of data\nCredits: https:\/\/www.kaggle.com\/jaideepvalani\/updated-pytorch-osic-starter-6-88-6-91","50c9e285":"Dropping the above Patients","e2c41404":"viewing the sample of after processing image data, Dont run below cell while forking ","427cb591":"## Step involved:\n\n- Converting pixel data to HU( a measurement used in CT scans)\n- Chunking the overall images in to 10 images for each patient:\n    we can see that every patient has several different counts of CT scans (patient1-30, patient2-394,..) I want these count to be same inorder to feed to the neural network.\n- Normalising the above values\n- Zero centering the above pixels\n- Resizin the image: all the images are of several different shapes so I resized them to a 64X64 images.","a7ce100e":"# Neural network model to work with 3d data and the tabular data combined","5cf51871":"Combining all the data to perform same type of transformation on train,test, submission dataset","7465c431":"Displaying FVC of patients after Dropping ","7aba3ecf":"Getting the min FVC(first FVC recorded) of every patient.","daffeca8":"cleaning the submission data","d3ea93d4":"## Below patient have lot of variance in their FVC so I have decided to drop those Patients data","9fa13a9a":"### Viewing the ct scans of one of the patient","c8e1ca9d":"While forking run first to cell will restart the kernel and continue running from the 3rd cell.","181b4e61":"Getting the min weeks(first record) of every patient"}}