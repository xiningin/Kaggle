{"cell_type":{"6a0c626b":"code","490c6236":"code","e0a3e0aa":"code","34b8b48b":"code","96040784":"code","a9a4db4b":"code","1c9a3996":"code","bef05fe5":"code","82c2d9e8":"code","262a5b61":"code","06ef6b4c":"code","d843738f":"code","efe4ecdf":"code","8a291a46":"code","11ce723a":"code","bf6bab20":"code","60c9d4c9":"code","1e3ceb94":"code","89f19e61":"code","ec4634a0":"code","7751a67e":"code","b7729828":"code","d3398bd2":"code","089f0fac":"code","2f616e6c":"code","83c82b1b":"code","88128770":"code","348f2df6":"code","830c0f9c":"code","42b345a2":"code","c4103873":"code","8f2bf690":"code","d6054a50":"code","953a1945":"code","c77c7bfd":"code","4eff486e":"markdown","2f86da93":"markdown","04609a6c":"markdown","efda5e8c":"markdown","2dc0fda3":"markdown","ca01d46a":"markdown","5bc0a6ae":"markdown","5af1d696":"markdown","4c6eed9e":"markdown","6a3ae33e":"markdown","9f26bd40":"markdown"},"source":{"6a0c626b":"import sys\nsys.path.append('..\/input\/timm-pytorch-image-models\/pytorch-image-models-master')\nfrom timm import create_model\nimport pandas as pd\nfrom torch import tensor\nimport numpy as np","490c6236":"from fastai.vision.all import *","e0a3e0aa":"set_seed(365, reproducible=True)\nBATCH_SIZE = 32","34b8b48b":"dataset_path = Path('..\/input\/petfinder-pawpularity-score-clean\/')\ndataset_path.ls()","96040784":"train_df = pd.read_csv(dataset_path\/'train.csv')\ntrain_df.head()","a9a4db4b":"train_df['path'] = train_df['Id'].map(lambda x:str(dataset_path\/'train'\/x)+'.jpg')\ntrain_df = train_df.drop(columns=['Id'])\ntrain_df = train_df.sample(frac=1).reset_index(drop=True) #shuffle dataframe\ntrain_df.head()","1c9a3996":"len_df = len(train_df)\nprint(f\"There are {len_df} images\")","bef05fe5":"train_df['Pawpularity'].hist(figsize = (10, 5))\nprint(f\"The mean Pawpularity score is {train_df['Pawpularity'].mean()}\")\nprint(f\"The median Pawpularity score is {train_df['Pawpularity'].median()}\")\nprint(f\"The standard deviation of the Pawpularity score is {train_df['Pawpularity'].std()}\")","82c2d9e8":"print(f\"There are {len(train_df['Pawpularity'].unique())} unique values of Pawpularity score\")","262a5b61":"train_df['norm_score'] = train_df['Pawpularity']\/100\ntrain_df['norm_score']","06ef6b4c":"im = Image.open(train_df['path'][1])\nwidth, height = im.size\nprint(width,height)","d843738f":"im","efe4ecdf":"if not os.path.exists('\/root\/.cache\/torch\/hub\/checkpoints\/'):\n    os.makedirs('\/root\/.cache\/torch\/hub\/checkpoints\/')\n!cp '..\/input\/swin-transformer\/swin_large_patch4_window7_224_22kto1k.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/swin_large_patch4_window7_224_22kto1k.pth'","8a291a46":"seed=365\nset_seed(seed, reproducible=True)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.use_deterministic_algorithms = True","11ce723a":"import math\n#Rice rule\nnum_bins = int(np.ceil(2*((len(train_df))**(1.\/3))))\nnum_bins","bf6bab20":"train_df['bins'] = pd.cut(train_df['norm_score'], bins=num_bins, labels=False)\ntrain_df['bins'].hist()","60c9d4c9":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\n\ntrain_df['fold'] = -1\n\n\nN_FOLDS = 10\nstrat_kfold = StratifiedKFold(n_splits=N_FOLDS, random_state=seed, shuffle=True)\nfor i, (_, train_index) in enumerate(strat_kfold.split(train_df.index, train_df['bins'])):\n    train_df.iloc[train_index, -1] = i\n    \ntrain_df['fold'] = train_df['fold'].astype('int')\n\ntrain_df.fold.value_counts().plot.bar()","1e3ceb94":"train_df[train_df['fold']==0].head()","89f19e61":"train_df[train_df['fold']==0]['bins'].value_counts()","ec4634a0":"train_df[train_df['fold']==1]['bins'].value_counts()","7751a67e":"def petfinder_rmse(input,target):\n    return 100*torch.sqrt(F.mse_loss(F.sigmoid(input.flatten()), target))","b7729828":"def get_data(fold):\n#     train_df_no_val = train_df.query(f'fold != {fold}')\n#     train_df_val = train_df.query(f'fold == {fold}')\n    \n#     train_df_bal = pd.concat([train_df_no_val,train_df_val.sample(frac=1).reset_index(drop=True)])\n    train_df_f = train_df.copy()\n    # add is_valid for validation fold\n    train_df_f['is_valid'] = (train_df_f['fold'] == fold)\n    \n    dls = ImageDataLoaders.from_df(train_df_f, #pass in train DataFrame\n#                                valid_pct=0.2, #80-20 train-validation random split\n                               valid_col='is_valid', #\n                               seed=365, #seed\n                               fn_col='path', #filename\/path is in the second column of the DataFrame\n                               label_col='norm_score', #label is in the first column of the DataFrame\n                               y_block=RegressionBlock, #The type of target\n                               bs=BATCH_SIZE, #pass in batch size\n                               num_workers=8,\n                               item_tfms=Resize(224), #pass in item_tfms\n                               batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation()])) #pass in batch_tfms\n    \n    return dls","d3398bd2":"# #Valid Kfolder size\n# the_data = get_data(0)\n# assert (len(the_data.train) + len(the_data.valid)) == (len(train_df)\/\/BATCH_SIZE)","089f0fac":"A = get_data(0).valid.dataset\nvalid = [A[i][1] for i in range(len(A))] \nassert len(valid) == len(A)","2f616e6c":"def get_learner(fold_num):\n    data = get_data(fold_num)\n    \n    model = create_model('swin_large_patch4_window7_224', pretrained=True, num_classes=data.c)\n\n    learn = Learner(data, model, loss_func=BCEWithLogitsLossFlat(), metrics=petfinder_rmse).to_fp16()\n    \n    return learn,data","83c82b1b":"test_df = pd.read_csv(dataset_path\/'test.csv')\ntest_df.head()","88128770":"test_df['Pawpularity'] = [1]*len(test_df)\ntest_df['path'] = test_df['Id'].map(lambda x:str(dataset_path\/'test'\/x)+'.jpg')\ntest_df = test_df.drop(columns=['Id'])\ntrain_df['norm_score'] = train_df['Pawpularity']\/100","348f2df6":"# get_learner(fold_num=0).lr_find(end_lr=3e-2)","830c0f9c":"import gc","42b345a2":"!pwd","c4103873":"all_preds = []\n\nfor i in range(1):\n\n    print(f'Fold {i} results')\n    \n    learn,train_data = get_learner(fold_num=i)\n\n    learn.fit_one_cycle(5, 2e-5, cbs=[SaveModelCallback(), EarlyStoppingCallback(monitor='petfinder_rmse', comp=np.less, patience=2)]) \n    \n    learn.recorder.plot_loss()\n    \n    A = train_data.valid.dataset\n    valid = [A[i][1] for i in range(len(A))] \n    assert len(valid) == len(A)\n    \n    valid_dls = train_data.valid\n    val_preds, _ = learn.tta(dl=valid_dls, n=5, beta=0)\n    valid_df = pd.DataFrame({'preds':val_preds.to('cpu').numpy().reshape(1,-1).flatten(),'actual':np.array([valid[i].item() for i in range(len(valid))])})\n    print(valid_df)\n    valid_df.to_csv(f'learner_1_validataion_fold{i}.csv')\n    #learn = learn.to_fp32()\n    \n    #learn.export(f'model_fold_{i}.pkl')\n    #learn.save(f'model_fold_{i}.pkl')\n    \n    dls = ImageDataLoaders.from_df(train_df, #pass in train DataFrame\n                               valid_pct=0.2, #80-20 train-validation random split\n                               seed=365, #seed\n                               fn_col='path', #filename\/path is in the second column of the DataFrame\n                               label_col='norm_score', #label is in the first column of the DataFrame\n                               y_block=RegressionBlock, #The type of target\n                               bs=BATCH_SIZE, #pass in batch size\n                               num_workers=8,\n                               item_tfms=Resize(224), #pass in item_tfms\n                               batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation()])) \n    \n    test_dl = dls.test_dl(test_df)\n    \n    preds, _ = learn.tta(dl=test_dl, n=5, beta=0)\n    \n    all_preds.append(preds)\n    \n    del learn\n\n    torch.cuda.empty_cache()\n\n    gc.collect()","8f2bf690":"all_preds","d6054a50":"np.mean(np.stack(all_preds*100))","953a1945":"sample_df = pd.read_csv(dataset_path\/'sample_submission.csv')\npreds = np.mean(np.stack(all_preds), axis=0)\nsample_df['Pawpularity'] = preds*100\nsample_df.to_csv('submission.csv',index=False)","c77c7bfd":"pd.read_csv('submission.csv').head()","4eff486e":"# Model","2f86da93":"# Import","04609a6c":"# Data loading","efda5e8c":"# Find optimal number of bins","2dc0fda3":"# Datasets","ca01d46a":"### Swin-Transformer document [click here](https:\/\/github.com\/microsoft\/Swin-Transformer)","5bc0a6ae":"# **Reference**\n###  [Petfinder Pawpularity EDA & fastai starter \ud83d\udc31\ud83d\udc36](https:\/\/www.kaggle.com\/tanlikesmath\/petfinder-pawpularity-eda-fastai-starter)\n###  [Petfinder& fastai with DataAugmentation KFold 10](https:\/\/www.kaggle.com\/bobber\/petfinder-fastai-with-dataaugmentation-kfold-10)","5af1d696":"#### You can criticize my work or give your suggestion, your comment is a treasure of knowledge for me\n##### P.S. sorry for a poor grammar","4c6eed9e":"# Constants","6a3ae33e":"### source for optimal bins formula [click here](https:\/\/www.statology.org\/sturges-rule\/)","9f26bd40":"# **About author: I'm a beginner in this field trying to learn and discovering the enjoyment of Data Science.**\n### Note1: This notebook is a copy version plus some editing and experimenting for my own understanding and learning.\n### Note2: If this notebook is useful for you in anyway, please give an upvote or commenting your gratitude on the notebook in the reference section. "}}