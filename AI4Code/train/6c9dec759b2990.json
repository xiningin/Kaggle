{"cell_type":{"77027525":"code","185a93c6":"code","f532eb44":"code","8f85b938":"code","41f976c3":"code","7c26293a":"code","ae002de5":"code","7f6b034a":"code","28bc86a3":"code","0782372b":"code","0c759cd9":"code","8bee77aa":"code","7d72090c":"code","67b1ee16":"code","34c6ed03":"code","1db3fc5a":"code","a369740a":"code","e4fca854":"code","e675ee9b":"code","245299e6":"code","5d3945b0":"code","9a9b8e57":"code","757ecbd7":"markdown"},"source":{"77027525":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","185a93c6":"import numpy as np\nimport pandas as pd\nimport os\nimport tarfile\nimport keras","f532eb44":"def png_files(members):\n    print(members)\n    for tarinfo in members:\n        if os.path.splitext(tarinfo.name)[1] == \".png\":\n            yield tarinfo\n\ntar = tarfile.open(\"\/kaggle\/input\/english-typed-alphabets-and-numbers-dataset\/EnglishFnt.tgz\")\n#tar1 = tarfile.open(\"\/kaggle\/input\/english-typed-alphabets-and-numbers-dataset\/EnglishImg.tgz\")\ntar.extractall('.\/EnglishFnt',members=png_files(tar))\n#tar1.extractall('.\/EnglishImg',members=png_files(tar1))\n#print(tar.getnames())\ntar.close()","8f85b938":"os.listdir()","41f976c3":"PATH = os.getcwd()\nPATH","7c26293a":"data_path = os.path.join(PATH, '.\/EnglishFnt\/English\/Fnt')\ndata_dir_list = os.listdir(data_path)\nprint(data_dir_list)","ae002de5":"import cv2\n\n#Read the images and store them in the list\nclass_count_start = 0\n\nclass_label = 0\nclasses = []\nimg_data_list=[]\nclasses_names_list=[]\nimg_rows=50\nimg_cols=50\n\n\nold_name = data_dir_list[0]\n\nfor dataset in data_dir_list:\n    classes_names_list.append(dataset) \n    print ('Loading images from {} folder\\n'.format(dataset)) \n    img_list=os.listdir(data_path+'\/'+ dataset)\n    if(old_name != dataset):\n        class_count_start = class_count_start + 1\n        old_name = dataset\n    for img in img_list:\n        input_img=cv2.imread(data_path + '\/'+ dataset + '\/'+ img )\n        #input_img1 = cv2.cvtColor(input_img, cv2.COLOR_BGR2RGB)\n        input_img_resize=cv2.resize(input_img, (img_rows, img_cols))\n\n        img_data_list.append(input_img_resize)\n        classes.append(class_label)\n        #print(class_count_start,img)\n        class_count_start = class_count_start + 1\n    class_count_start = class_count_start - 1\n    class_label = class_label + 1\n    ","7f6b034a":"import matplotlib.pyplot as plt\nimport numpy\n\nplt.figure(figsize=(20, 4))\nplt.imshow(img_data_list[8545])","28bc86a3":"from collections import Counter\nlen(Counter(classes).keys())\nclass_labels = list(range(0,62,1))","0782372b":"map_labels = dict(zip(class_labels,classes_names_list))\nprint(map_labels)","0c759cd9":"#Convert class labels to numberic using on-hot encoding\nfrom keras.utils import to_categorical\n\nclasses = to_categorical(classes, 62)\nclasses","8bee77aa":"from sklearn.model_selection import train_test_split\n\nxtrain=[]\nytrain = []\nxtest=[]\nytest = []\n\nxtrainlist,  xtest_list, ytrainlist, ytest_list = train_test_split(img_data_list, classes, random_state=1234, test_size=0.02,shuffle = True)\nxtrain.extend(xtrainlist)\nytrain.extend(ytrainlist)\nxtest.extend(xtest_list)\nytest.extend(ytest_list)\n","7d72090c":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D,BatchNormalization\nfrom keras.optimizers import Adam","67b1ee16":"num_classes=62\nmodel = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(50,50,3)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(32, (3, 3), activation='tanh'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, (3, 3), activation='tanh'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))","34c6ed03":"#complie the model\nopt =Adam(lr=0.01)\nmodel.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\"])","1db3fc5a":"model.summary()","a369740a":"#training and fitting the model\nhist = model.fit(np.array(xtrain), np.array(ytrain), epochs=15, verbose=1, batch_size =34,validation_split = 0.20)","e4fca854":"#plot the evaluation of loss and accuracy on the train and validation sets\nimport matplotlib.pyplot as plt\nplt.figure(figsize =(10,5))\nplt.subplot(1,2,1)\nplt.suptitle('Optimizer : Adam with learning rate 0.001', fontsize=10)\nplt.ylabel('Loss', fontsize = 16)\nplt.plot(hist.history['loss'], label = 'Training Loss')\nplt.plot(hist.history['val_loss'], label = 'Validation Loss')\nplt.legend(loc = 'upper right')\n\nplt.subplot(1,2,2)\nplt.ylabel('Accuracy', fontsize = 16)\nplt.plot(hist.history['accuracy'], label = 'Training Accuracy')\nplt.plot(hist.history['val_accuracy'], label = 'Validation Accuracy')\nplt. legend(loc = 'lower right')\nplt.show()","e675ee9b":"#training and fitting the model with validation\npred = model.predict(np.array(xtest))\npred","245299e6":"y_pred = [np.argmax(probas) for probas in pred]\nprint(y_pred)","5d3945b0":"# serialize model structure to JSON\nfrom keras.models import model_from_json\nmodel_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)","9a9b8e57":"with open('model.json', \"r\") as json_file:\n    loaded_model_json = json_file.read()\n    loaded_model = model_from_json(loaded_model_json)\n","757ecbd7":"so our dataset has 3 main categories:\n0-9 : dgits\nA-Z : alphabets\na-z :small case alphabets\nNOTE:\nUsing ASCII values:\nASCII value of uppercase alphabets \u2013 65 to 90.\nASCII value of lowercase alphabets \u2013 97 to 122."}}