{"cell_type":{"f6b72a05":"code","5cb8e106":"code","2ceefb6e":"code","7a01b288":"code","1c868e6f":"code","7871a381":"code","2b4d2b10":"code","8ec281c4":"code","75f03288":"code","53349d10":"code","a2e1acce":"code","ba70c0d6":"code","bf038ed3":"markdown"},"source":{"f6b72a05":"import numpy as np \nimport pandas as pd\nimport tensorflow as tf\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D,DepthwiseConv2D, Dense, Flatten, Dropout, BatchNormalization, LeakyReLU,GlobalAveragePooling2D, Activation, Average,AveragePooling2D\nimport matplotlib.pyplot as plt\nfrom keras.optimizers import Adam,Adamax\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, TensorBoard\nimport seaborn as sns\nimport os\nprint(os.listdir(\"..\/input\"))","5cb8e106":"bas_dir=os.path.join('..','input')\ncsv_train=pd.read_csv(os.path.join(bas_dir,'train.csv'))\ntrain_dir=os.path.join(bas_dir,'train\/train')\ntest_dir=os.path.join(bas_dir,'test\/test')","2ceefb6e":"csv_train.head()","7a01b288":"'''count=csv_train['has_cactus'].value_counts()\nprint(count)\ncount.plot(kind=\"bar\")\nplt.show()'''\nsns.countplot(x = 'has_cactus',\n              data = csv_train,\n              order = csv_train['has_cactus'].value_counts().index)\nplt.show()","1c868e6f":"# Using Image Generator to preprocess the data\ncsv_train['has_cactus']=csv_train['has_cactus'].astype('str')\nbatch_size = 100\ntrain_size = 15750\nvalidation_size = 1750\n\ndatagen = ImageDataGenerator(\n    rescale=1.\/255,\n    horizontal_flip=True,\n    vertical_flip=True,\n    validation_split=0.1,\n    zoom_range =0.3,\n    zca_whitening = False\n    )\n\ndata_args = {\n    \"dataframe\": csv_train,\n    \"directory\": train_dir,\n    \"x_col\": 'id',\n    \"y_col\": 'has_cactus',\n    \"featurewise_center\" : True,\n    \"featurewise_std_normalization\" : True,\n    \"samplewise_std_normalization\" : False,\n    \"samplewise_center\" : False,\n    \"shuffle\": True,\n    \"target_size\": (32, 32),\n    \"batch_size\": batch_size,\n    \"class_mode\": 'binary'\n}\n\ntrain_generator = datagen.flow_from_dataframe(**data_args, subset='training')\nvalidation_generator = datagen.flow_from_dataframe(**data_args, subset='validation')","7871a381":"\n# Plotting Images\ndef plot_images():\n    f,ax=plt.subplots(3,20,figsize=(10,10))\n    print(ax.shape)\n    for j in range(ax.shape[0]):\n        for i  in range(ax.shape[1]):\n            image = next(train_generator)\n            img = array_to_img(image[0][0])\n            ax[j][i].imshow(img)\n            ax[j][i].axis(\"off\")\n    plt.subplots_adjust(wspace=0, hspace=1)\n    plt.show()\n    plt.axis(\"off\")\n    plt.title(\"Images\", fontsize=18)\n    \nplot_images()","2b4d2b10":"def Le_Conv():\n    model = Sequential()\n    model.add(Conv2D(6, kernel_size=(3, 3), strides=(1, 1), activation='relu', input_shape=(32, 32, 3), padding=\"same\"))\n    model.add(AveragePooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid'))\n    model.add(Conv2D(16, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding='valid'))\n    model.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n    model.add(Conv2D(120, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding='valid'))\n    model.add(Flatten())\n    model.add(Dense(84, activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(optimizer =  Adamax(lr =0.001) , loss = \"binary_crossentropy\", metrics=[\"acc\"])\n    return model","8ec281c4":"model_history=Le_Conv().fit_generator(train_generator,\n              validation_data=validation_generator,\n              steps_per_epoch=train_size\/\/batch_size,\n              validation_steps=validation_size\/\/batch_size,\n              epochs=100, verbose=1, \n              shuffle=True)","75f03288":"test_df = pd.read_csv(os.path.join(bas_dir, \"sample_submission.csv\"))\ntest_df.head()","53349d10":"test_df = pd.read_csv(os.path.join(bas_dir, \"sample_submission.csv\"))\nimport cv2\ntest_images = []\nimages = test_df['id'].values\nfor image_id in images:\n    test_images.append(cv2.imread(os.path.join(test_dir, image_id)))\n    \ntest_images = np.asarray(test_images)\ntest_images = test_images \/ 255.0\nprint(\"Number of Test set images: \" + str(len(test_images)))","a2e1acce":"predict = Le_Conv().predict(test_images)","ba70c0d6":"test_df['has_cactus'] = predict\ntest_df.round(2)\ntest_df.to_csv('aerial-cactus-submission.csv', index = False)","bf038ed3":"# Model Architecture\n"}}