{"cell_type":{"aac0c84b":"code","5de0082e":"code","dee82a87":"code","09de4d89":"code","b697c3ec":"code","009eb614":"code","f71114f2":"code","6eb2c384":"code","b93d7b6c":"code","ecfd756f":"code","e1ba9d85":"code","5c1e0805":"code","8daf5061":"code","b24d7afb":"code","b81a9ef3":"code","1ed3f900":"code","0854437f":"code","8b24482c":"code","774541a1":"code","d4d9a202":"code","254bddc6":"code","c7f90dbb":"code","62d51171":"code","c3e37716":"code","54d83974":"code","48c21d95":"code","03b27dd2":"code","0962056c":"code","0ad5d58a":"code","92581539":"code","94a64425":"code","bdc87e6a":"code","96ba5bb8":"code","b9463772":"code","9922e726":"code","03bc9efd":"code","3e939644":"code","b3c13346":"code","3bf63eff":"code","6ae3f7e6":"code","afbcf7a9":"code","89ee1028":"code","01cdee6a":"code","e138e543":"code","ca1b2616":"code","8da5d598":"code","28176e2d":"code","352e37df":"code","f6be0bfa":"markdown","528f7a7c":"markdown","8c39e7e6":"markdown","9f525b1d":"markdown","b97c038b":"markdown","ff26bfea":"markdown","d8164f00":"markdown","f8305df7":"markdown","807a43fb":"markdown","fab168b5":"markdown","d79e98a0":"markdown","72abe4b1":"markdown","d9e96f9c":"markdown","2db8f75a":"markdown","0c4d3553":"markdown","173b6296":"markdown","3424826b":"markdown"},"source":{"aac0c84b":"import numpy as np \nimport pandas as pd\nfrom pandas import DataFrame\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\nimport seaborn as sns\n% matplotlib inline\nimport os\nprint(os.listdir(\"..\/input\"))","5de0082e":"# read data in pandas dataframe\ndf_train =  pd.read_csv('..\/input\/train.csv',nrows= 5000000,parse_dates=[\"pickup_datetime\"])\n\n# list first few rows (datapoints)\ndf_train.head()","dee82a87":"df_train.columns.values","09de4d89":"df_train.describe()","b697c3ec":"df_train.dtypes","009eb614":"df_train.isnull().sum()","f71114f2":"df_train = df_train.dropna()","6eb2c384":"#calculate trip distance in miles\ndef distance(lat1, lat2, lon1,lon2):\n    p = 0.017453292519943295 # Pi\/180\n    a = 0.5 - np.cos((lat2 - lat1) * p)\/2 + np.cos(lat1 * p) * np.cos(lat2 * p) * (1 - np.cos((lon2 - lon1) * p)) \/ 2\n    return 0.6213712 * 12742 * np.arcsin(np.sqrt(a))","b93d7b6c":"df_train['trip_distance']=df_train.apply(lambda row:distance(row['pickup_latitude'],row['dropoff_latitude'],row['pickup_longitude'],row['dropoff_longitude']),axis=1)","ecfd756f":"df_train['trip_distance'].head(10)","e1ba9d85":"\n# Cab rides should not have negative numbers, along with that, taxi standarad fares begin at $2.50\ndf_train = df_train[df_train['fare_amount'] >= 2.5]\n    \n# our latitude and longitude should not be equal to 0 becuase the dataset is based in NY\ndf_train = df_train[df_train['pickup_latitude']!= 0]\ndf_train = df_train[df_train['pickup_longitude'] != 0]\ndf_train = df_train[df_train['dropoff_latitude'] != 0]\ndf_train = df_train[df_train['dropoff_longitude'] != 0]\n\n# latitude and longitude are bounded by 90 and -90. We shouldnt have any coordiantes out of that range\ndf_train = df_train[(df_train['pickup_latitude']<=90) & (df_train['pickup_latitude']>=-90)]\ndf_train = df_train[(df_train['pickup_longitude']<=90) & (df_train['pickup_longitude']>=-90)]\ndf_train = df_train[(df_train['dropoff_latitude']<=90) & (df_train['dropoff_latitude']>=-90)]\ndf_train = df_train[(df_train['dropoff_longitude']<=90) & (df_train['dropoff_longitude']>=-90)]\n    \n# I dont want to include destinations that have not moved from there pickup coordinates to there dropoff coordinates\ndf_train = df_train[(df_train['pickup_latitude'] != df_train['dropoff_latitude']) & (df_train['pickup_longitude'] != df_train['dropoff_longitude'])]","5c1e0805":"# list first few rows (datapoints)\ndf_train.head()","8daf5061":"sns.distplot(df_train['fare_amount'])\n\nplt.title('Distribution of Fare Amount')","b24d7afb":"%matplotlib inline\nsns.boxplot(df_train['fare_amount'], palette=\"Set2\" )\n\nplt.title('Looking for Outliers with a Boxplot')","b81a9ef3":"df_train = df_train[(df_train['fare_amount'] >= 2.5) & (df_train['fare_amount'] <= 800) ]","1ed3f900":"mean = np.mean(df_train['fare_amount'])\nsd = np.std(df_train['fare_amount'])    \ndf_train = df_train[(df_train['fare_amount'] > mean - 3*sd) & (df_train['fare_amount'] < mean + 3*sd)]","0854437f":"sns.distplot(df_train['fare_amount'])\n\nplt.title('Distribution of Fare Amount after removing outliers')","8b24482c":"len(df_train)","774541a1":"# Double check the coordinate by adding new features 'abs_diff_longitude' and 'abs_diff_latitude'\ndef add_travel_vector_features(df):\n    df['abs_diff_longitude'] = (df.dropoff_longitude - df.pickup_longitude).abs()\n    df['abs_diff_latitude'] = (df.dropoff_latitude - df.pickup_latitude).abs()\n\nadd_travel_vector_features(df_train)","d4d9a202":"plot = df_train.iloc[:4714682].plot.scatter('abs_diff_longitude', 'abs_diff_latitude')","254bddc6":"print('Old size: %d' % len(df_train))\ndf_train = df_train[(df_train.abs_diff_longitude < 5.0) & (df_train.abs_diff_latitude < 5.0)]\nprint('New size: %d' % len(df_train))","c7f90dbb":"# Check the distribution of \"passenger_count\"\npassenger_count = df_train.groupby(['passenger_count']).count()\n\nfig, ax = plt.subplots(figsize=(15,8))\n\nsns.barplot(passenger_count.index, passenger_count['key'], palette = \"Set3\")\n\nplt.xlabel('Number of Passengers')\nplt.ylabel('Count')\nplt.title('Count of Passengers')\nplt.show()","62d51171":"passenger_fare = df_train.groupby(['passenger_count']).mean()\n\nfig, ax = plt.subplots(figsize=(15,8))\n\nsns.barplot(passenger_fare.index, passenger_fare['fare_amount'], palette = \"Set3\")\n\nplt.xlabel('Number of Passengers')\nplt.ylabel('Average Fare Price')\nplt.title('Average Fare Price for Number of Passengers')\nplt.show()","c3e37716":"df_train = df_train[(df_train['passenger_count']<=7) & (df_train['passenger_count']>=1)]","54d83974":"import folium","48c21d95":"\ncoordinates = [[40.711303, -74.016048],[40.782004, -73.979268],]\n\n# Create the map and add the line\nm = folium.Map(location=[40.730610,-73.935242], zoom_start=12)\nmy_PolyLine=folium.PolyLine(locations=coordinates,weight=5, color = \"black\")\nm.add_children(my_PolyLine)\n\n\n\n","03b27dd2":"# Add some useful features instead of the feature \"key\" (Date)\ndef date_columns(data):\n    data['key'] = pd.to_datetime(data['key'], yearfirst=True)\n    data['year'] = data['key'].dt.year\n    data['month'] = data['key'].dt.month\n    data['day'] = data['key'].dt.day\n    data['weekday'] = data['key'].dt.weekday\n    data['hour'] = data['key'].dt.hour\n    #data['day_of_week'] = data['key'].dt.day_name()","0962056c":"date_columns(df_train)\ndf_train.columns.values","0ad5d58a":"df_train.dtypes","92581539":"df_train.head(10)","94a64425":"#Hours_Plot\ntime_of_day = df_train.groupby(['hour']).mean()\n\nplt.figure(figsize=(20,8))\nplt.plot(time_of_day.index, time_of_day.fare_amount, color = 'blue')\n\nplt.xlabel('Hour')\nplt.ylabel('Fare Price')\nplt.title('Average Fare Price During Time of Day')\nplt.show()","bdc87e6a":"#Time Series Plot\n\ntaxi = df_train.sort_values(by='key').reset_index()\n\nyear = taxi['key'].dt.year.astype(str)\nmonth = taxi['key'].dt.month.astype(str)\nday = taxi['key'].dt.day.astype(str)\n\ndate = year+\"-\"+month+\"-\"+day\ndate = pd.to_datetime(date)\nyear_month = year +'-'+month\nyear_month = pd.to_datetime(year_month)\ntaxi['year_month'] = year_month\ntaxi['date'] = date\n\n\ntaxi_rate = taxi.groupby(['date']).mean()\n\n\n","96ba5bb8":"\nplt.figure(figsize=(20,8))\n\nplt.plot(taxi_rate.index, taxi_rate.fare_amount, color = \"#C2A0FA\")\n\n\n\nplt.xlabel('Year')\nplt.ylabel('Average Fare Price Per Day')\nplt.title('Average Fare Price Over the Years')\nplt.show()","b9463772":"df_train = df_train[(df_train['year']>=2013)]\n\ndf_train.sort_values(by='year',ascending= True)","9922e726":"from  sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split, cross_val_score \nfrom sklearn.linear_model import LinearRegression \nimport xgboost as xgb","03bc9efd":"import statsmodels.api as sm # import statsmodels \n","3e939644":"X = df_train.drop(['fare_amount','key', 'pickup_datetime'],axis = 1)\ny = df_train['fare_amount']\nX = sm.add_constant(X) ## let's add an intercept (beta_0) to our model\n\n# Note the difference in argument order\nmodel = sm.OLS(y, X).fit() ## sm.OLS(output, input)\npredictions = model.predict(X)\n\n# Print out the statistics\nmodel.summary()","b3c13346":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=46)\nprint (X_train.shape, y_train.shape)\nprint (X_test.shape, y_test.shape)","3bf63eff":"\nlm = LinearRegression()\nlm.fit(X_train,y_train)\nprint(lm.score(X_train,y_train))\nprint(lm.score(X_test,y_test))","6ae3f7e6":"y_pred = lm.predict(X_test)\nlrmse = np.sqrt(metrics.mean_squared_error(y_pred, y_test))\nlrmse","afbcf7a9":"print ('Score:', lm.fit(X_train,y_train).score(X_test, y_test))","89ee1028":"from sklearn.ensemble import RandomForestRegressor\n\nrandomForest = RandomForestRegressor(random_state=42)\nrandomForest.fit(X_train, y_train)","01cdee6a":"randomForestPredict = randomForest.predict(X_test)\nrandomForest_mse = mean_squared_error(y_test, randomForestPredict)\nrandomForestMSE = np.sqrt(randomForest_mse)\nrandomForestMSE","e138e543":"from sklearn.ensemble import GradientBoostingRegressor\nmodel_gradient= GradientBoostingRegressor(n_estimators=100, learning_rate=1, max_depth=3, random_state=0)\ngradientBoost = model_gradient.fit(X_train, y_train)","ca1b2616":"predicted = model_gradient.predict(X_test)\ngrmse = np.sqrt(metrics.mean_squared_error(predicted, y_test))\ngrmse","8da5d598":"regression = pd.DataFrame({\"regression\": ['Multi Linear Regression','Random Forest',  'Gradient Boosting Regrssion'], \n                           \"rmse\": [lrmse,randomForestMSE,grmse]},columns = ['regression','rmse'])","28176e2d":"regression = regression.sort_values(by='rmse', ascending = False)","352e37df":"sns.barplot(regression['rmse'], regression['regression'], palette = 'Set2')\nplt.xlabel(\"Root Mean Square Error\")\nplt.ylabel('Regression Type')\nplt.title('Comparing the different types of Regressions used')","f6be0bfa":"*** Modelling**","528f7a7c":"Linear Regression","8c39e7e6":"<img src=\"https:\/\/www.brickunderground.com\/sites\/default\/files\/styles\/blog_primary_image\/public\/blog\/images\/4859177053_c3fb190917_o.jpg\" width = 100% >","9f525b1d":"*** Feature Engineering**","b97c038b":"*** Trip Distance**","ff26bfea":"*** Check for Missing Data**","d8164f00":"*** Load Data**","f8305df7":"#there had been a significant increase in fare price since 2013.","807a43fb":"We expect most of these values to be very small (likely between 0 and 1) since it should all be differences between GPS coordinates within one city. For reference, one degree of latitude is about 69 miles. ","fab168b5":"Double check to make sure there are no outliers of coordinate","d79e98a0":"Remove rows with more than 7 passengers or 0 passenger.","72abe4b1":"*** Preknoledges and Findings based on the Dataset:**\n\n*     Initial charge: $2.50 ( Taxi fares begin at $2.50 regardless of distance)\n\n*     Mileage: 40 cents per 1\/5 mile\n\n*     Waiting charge: 40 cents per 120 seconds\n\n*     JFK flat fare: $45. (was $35)\n\n*     Newark surcharge: $15. (was $10) 4 p.m.\u20138 p.m. weekday\n\n*     The coordinate system  is bounded by (-90,90) for latitude and (-90,90) for longitude, so anything outside this range is an error \n\n*     Locations where drivers pick you up from shouldn't be the same locations where they drop you off at.\n\n*    Any value that is unrealistic or abnormal should be treated as an outlier\n","d9e96f9c":"*** Glimpse of Data**","2db8f75a":"*** Exploratory Analysis**","0c4d3553":"Gradient Boost Regression","173b6296":"* Map Plot","3424826b":"Random Forest"}}