{"cell_type":{"c86f7bf4":"code","67bccbce":"code","fc520f5e":"code","bae9546e":"code","16d28019":"code","177ebb8b":"code","8cd51ffb":"code","678b7324":"code","a3e3f9b1":"code","e870eecf":"code","252e4d2b":"code","ec46071e":"code","4d417dc9":"code","b9ad2aab":"code","c5962877":"code","6d97c3bb":"code","9139668e":"code","6a779d75":"code","393a8de3":"code","60f606c7":"code","73ff9c16":"code","1ab4d01c":"code","339357bc":"code","ae3b7edc":"code","9f61751c":"code","6f6e9e13":"code","912c2788":"code","15324bf2":"code","c8d36a5e":"code","f21ee89d":"code","751bb11e":"code","99a96a7e":"code","c55576ec":"code","2fed2d7b":"code","ad9d348a":"code","00c1c43a":"code","71a56bab":"code","fbc72c38":"code","a7d50cc3":"code","690c5b69":"code","af6a4850":"code","ced28945":"code","2025c597":"markdown","7d52f583":"markdown","dc44d0e4":"markdown","a0bd7d09":"markdown","930e10c8":"markdown","1383c426":"markdown","f3a0119e":"markdown","8904b0ae":"markdown","4664511b":"markdown"},"source":{"c86f7bf4":"DATA_DIR = \"..\/input\/animefacedataset\/\"","67bccbce":"import os\nos.listdir(DATA_DIR)","fc520f5e":"os.listdir(DATA_DIR + '\/images')[:10]","bae9546e":"from torch.utils.data import DataLoader\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms as T","16d28019":"image_size = 64\nbatch_size = 128\nstats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)","177ebb8b":"train_ds = ImageFolder(DATA_DIR, transform = T.Compose([\n                        T.Resize(image_size),\n                        T.CenterCrop(image_size),\n                        T.ToTensor(),\n                        T.Normalize(*stats)]))\n\ntrain_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)","8cd51ffb":"import torch\nfrom torchvision.utils import make_grid\nimport matplotlib.pyplot as plt\n%matplotlib inline","678b7324":"def denorm(img_tensors):\n    return img_tensors * stats[1][0] + stats[0][0]","a3e3f9b1":"def show_images(images, nmax=64):\n    fig, ax = plt.subplots(figsize=(8, 8))\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.imshow(make_grid(denorm(images.detach()[:nmax]), nrow=8).permute(1,2, 0))\n    \ndef show_batch(dl ,nmax=64):\n    for images, _ in dl:\n        show_images(images, nmax)\n        break","e870eecf":"show_batch(train_dl)","252e4d2b":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","ec46071e":"device = get_default_device()\ndevice","4d417dc9":"train_dl = DeviceDataLoader(train_dl , device)","b9ad2aab":"import torch.nn as nn","c5962877":"discriminator = nn.Sequential(\n    # in: 3 x 64 x 64\n    \n    nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(64),\n    nn.LeakyReLU(0.2, inplace=True),\n    # out: 64 x 32 x 32\n\n    nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(128),\n    nn.LeakyReLU(0.2, inplace=True),\n    #out: 128 x 16 x 16\n    \n    nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(256),\n    nn.LeakyReLU(0.2, inplace=True),\n    #out: 256 x 8 x 8\n    \n    nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(512),\n    nn.LeakyReLU(0.2, inplace=True),\n    #out: 512 x 4 x 4\n    \n    nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False),\n    #out: 1 x 1 x 1\n    \n    nn.Flatten(),\n    nn.Sigmoid())","6d97c3bb":"discriminator = to_device(discriminator, device)","9139668e":"latent_size = 128","6a779d75":"generator = nn.Sequential(\n    # in: latent_size x 1 x 1\n\n    nn.ConvTranspose2d(latent_size, 512, kernel_size=4, stride=1, padding=0, bias=False),\n    nn.BatchNorm2d(512),\n    nn.ReLU(True),\n    # out: 512 x 4 x 4\n    \n    nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(256),\n    nn.ReLU(True),\n    # out: 256 x 8 x 8\n\n    nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(128),\n    nn.ReLU(True),\n    #out: 128 x 16 x 16\n\n    nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(64),\n    nn.ReLU(True),\n    #out: 64 x 32 x 32\n\n    nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.Tanh()\n    #out: 3 x 64 x 64\n)","393a8de3":"# Let's generate some outputs using the generator and view them as images by transforming and denormalizing the output.\n\nxb = torch.randn(batch_size, latent_size, 1, 1)\nfake_images = generator(xb)\nprint(fake_images.shape)\nshow_images(fake_images)","60f606c7":"generator = to_device(generator, device)","73ff9c16":"def train_discriminator(real_images, opt_d):\n    #clear discriminator gradients\n    opt_d.zero_grad()\n    \n    #pass real images through discriminator\n    real_preds = discriminator(real_images)\n    real_targets = torch.ones(real_images.size(0), 1, device=device)\n    real_loss = F.binary_cross_entropy(real_preds, real_targets)\n    real_score = torch.mean(real_preds).item()\n    \n    #generate fake images\n    latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n    fake_images = generator(latent)\n    \n    #pass fake images through discriminator\n    fake_targets = torch.zeros(fake_images.size(0), 1, device=device)\n    fake_preds = discriminator(fake_images)\n    fake_loss = F.binary_cross_entropy(fake_preds, fake_targets)\n    fake_score = torch.mean(fake_preds).item()\n    \n    #update discriminator weights\n    loss = real_loss + fake_loss\n    loss.backward()\n    opt_d.step()\n    return loss.item(), real_score, fake_score","1ab4d01c":"def train_generator(opt_g):\n    #clear generator gradients\n    opt_g.zero_grad()\n    \n    #generate fake images\n    latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n    fake_images = generator(latent)\n    \n    #Try to fool the discriminator\n    preds = discriminator(fake_images)\n    targets = torch.ones(batch_size, 1, device=device)\n    loss = F.binary_cross_entropy(preds, targets)\n    \n    #update generator weights\n    loss.backward()\n    opt_g.step()\n    \n    return loss.item()","339357bc":"from torchvision.utils import save_image","ae3b7edc":"sample_dir = 'generated'\nos.makedirs(sample_dir, exist_ok=True)","9f61751c":"def save_samples(index, latent_tensors, show=True):\n    fake_images = generator(latent_tensors)\n    fake_fname = 'generated-images-{0:0=4d}.png'.format(index)\n    save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=8)\n    print('Saving', fake_fname)\n    if show:\n        fig, ax = plt.subplots(figsize=(8, 8))\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.imshow(make_grid(fake_images.cpu().detach(), nrow=8).permute(1, 2, 0))","6f6e9e13":"fixed_latent = torch.randn(64, latent_size, 1, 1, device=device)","912c2788":"save_samples(0, fixed_latent)","15324bf2":"from tqdm.notebook import tqdm\nimport torch.nn.functional as F","c8d36a5e":"def fit(epochs, lr, start_idx=1):\n    torch.cuda.empty_cache()\n    \n    # Losses & scores\n    losses_g = []\n    losses_d = []\n    real_scores = []\n    fake_scores = []\n    \n    # Create optimizers\n    opt_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n    opt_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n    \n    for epoch in range(epochs):\n        for real_images, _ in tqdm(train_dl):\n            # Train discriminator\n            loss_d, real_score, fake_score = train_discriminator(real_images, opt_d)\n            # Train generator\n            loss_g = train_generator(opt_g)\n            \n        # Record losses & scores\n        losses_g.append(loss_g)\n        losses_d.append(loss_d)\n        real_scores.append(real_score)\n        fake_scores.append(fake_score)\n        \n        # Log losses & scores\n        print(\"Epoch [{}\/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}\".format(\n                epoch+1, epochs, loss_g, loss_d, real_score, fake_score))\n        \n        # Save generated images\n        save_samples(epoch+start_idx, fixed_latent, show=False)\n        \n    return losses_g, losses_d, real_scores, fake_scores","f21ee89d":"lr = 0.0002\nepochs = 25","751bb11e":"history = fit(epochs, lr)","99a96a7e":"losses_g, losses_d, real_scores, fake_scores = history","c55576ec":"# Save the model checkpoints \ntorch.save(generator.state_dict(), 'G.ckpt')\ntorch.save(discriminator.state_dict(), 'D.ckpt')","2fed2d7b":"from IPython.display import Image","ad9d348a":"Image('.\/generated\/generated-images-0001.png')","00c1c43a":"Image('.\/generated\/generated-images-0005.png')","71a56bab":"Image('.\/generated\/generated-images-0010.png')","fbc72c38":"Image('.\/generated\/generated-images-0020.png')","a7d50cc3":"Image('.\/generated\/generated-images-0025.png')","690c5b69":"import cv2\nimport os\n\nvid_fname = 'gans_training.avi'\n\nfiles = [os.path.join(sample_dir, f) for f in os.listdir(sample_dir) if 'generated' in f]\nfiles.sort()\n\nout = cv2.VideoWriter(vid_fname,cv2.VideoWriter_fourcc(*'MP4V'), 1, (530,530))\n[out.write(cv2.imread(fname)) for fname in files]\nout.release()","af6a4850":"plt.plot(losses_d, '-')\nplt.plot(losses_g, '-')\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend(['Discriminator', 'Generator'])\nplt.title('Losses')","ced28945":"plt.plot(real_scores, '-')\nplt.plot(fake_scores, '-')\nplt.xlabel('epoch')\nplt.ylabel('score')\nplt.legend(['Real', 'Fake'])\nplt.title('Scores')","2025c597":"### Using a GPU","7d52f583":"We'll use a fixed set of input vectors to the generator to see how the individual generated images evolve over time as we train the model. Let's save one set of images before we start training our model.","dc44d0e4":"## Full Training Loop\n\nLet's define a `fit` function to train the discriminator and generator in tandem for each batch of training data. We'll use the Adam optimizer. We will also save some sample generated images at regular intervals for inspection.","a0bd7d09":"### Discriminator Network","930e10c8":"### Lading the Data","1383c426":"### Helper function to denormalize the image tensors","f3a0119e":"We will create a directory where we can save intermediate outputs from the generator to visually inspect the progress of the model. We'll also create a helper function to export the generated images.","8904b0ae":"We can visualize the training process by combining the sample images generated after each epoch into a video using OpenCV.","4664511b":"Visualizing the losses"}}