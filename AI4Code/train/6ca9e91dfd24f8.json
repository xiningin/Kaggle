{"cell_type":{"8fb28422":"code","d76d2dc3":"code","fc4e1085":"code","6c545678":"code","d06d1028":"code","c4096003":"code","0bede4e7":"code","c1c5abf2":"code","d22d24df":"code","8ad84228":"code","4fe85831":"code","1f20c74a":"code","6e232be3":"code","03cf8457":"code","21bf2d9a":"code","19c233f9":"markdown","3ca684a0":"markdown","ed05f0e7":"markdown","24dfa3bd":"markdown","fc9e3284":"markdown","421d3e76":"markdown","26f92ff6":"markdown","25e3a4b2":"markdown","991fe674":"markdown"},"source":{"8fb28422":"# install dependencies: (use cu100 because colab is on CUDA 10.0)\n!pip install -U torch==1.4+cu100 torchvision==0.5+cu100 -f https:\/\/download.pytorch.org\/whl\/torch_stable.html \n!pip install cython pyyaml==5.1\n!pip install -U 'git+https:\/\/github.com\/cocodataset\/cocoapi.git#subdirectory=PythonAPI'\nimport torch, torchvision\ntorch.__version__\n!gcc --version\n# opencv is pre-installed on colab","d76d2dc3":"# install detectron2:\n!pip install detectron2 -f https:\/\/dl.fbaipublicfiles.com\/detectron2\/wheels\/cu100\/index.html","fc4e1085":"import detectron2\nfrom detectron2.utils.logger import setup_logger\nsetup_logger()\n\n# import some common libraries\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n\n# import some common detectron2 utilities\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import MetadataCatalog","6c545678":"import pandas as pd\n\ndf = pd.read_csv('..\/input\/microcontroller-detection\/Microcontroller Detection\/train_labels.csv')\n\ndf.head()","d06d1028":"import os\nimport numpy as np\nimport json\nfrom detectron2.structures import BoxMode\nimport itertools\nimport cv2\n\n# write a function that loads the dataset into detectron2's standard format\ndef get_microcontroller_dicts(csv_file, img_dir):\n    df = pd.read_csv(csv_file)\n    df['filename'] = df['filename'].map(lambda x: img_dir+x)\n\n    classes = ['Raspberry_Pi_3', 'Arduino_Nano', 'ESP8266', 'Heltec_ESP32_Lora']\n\n    df['class_int'] = df['class'].map(lambda x: classes.index(x))\n\n    dataset_dicts = []\n    for filename in df['filename'].unique().tolist():\n        record = {}\n        \n        height, width = cv2.imread(filename).shape[:2]\n        \n        record[\"file_name\"] = filename\n        record[\"height\"] = height\n        record[\"width\"] = width\n\n        objs = []\n        for index, row in df[(df['filename']==filename)].iterrows():\n          obj= {\n              'bbox': [row['xmin'], row['ymin'], row['xmax'], row['ymax']],\n              'bbox_mode': BoxMode.XYXY_ABS,\n              'category_id': row['class_int'],\n              \"iscrowd\": 0\n          }\n          objs.append(obj)\n        record[\"annotations\"] = objs\n        dataset_dicts.append(record)\n    return dataset_dicts","c4096003":"from detectron2.data import detection_utils as utils\nimport detectron2.data.transforms as T\nimport copy\n\ndef custom_mapper(dataset_dict):\n    dataset_dict = copy.deepcopy(dataset_dict)  # it will be modified by code below\n    image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n    transform_list = [\n        T.Resize((800,600)),\n        T.RandomBrightness(0.8, 1.8),\n        T.RandomContrast(0.6, 1.3),\n        T.RandomSaturation(0.8, 1.4),\n        T.RandomRotation(angle=[90, 90]),\n        T.RandomLighting(0.7),\n        T.RandomFlip(prob=0.4, horizontal=False, vertical=True),\n    ]\n    image, transforms = T.apply_transform_gens(transform_list, image)\n    dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n\n    annos = [\n        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n        for obj in dataset_dict.pop(\"annotations\")\n        if obj.get(\"iscrowd\", 0) == 0\n    ]\n    instances = utils.annotations_to_instances(annos, image.shape[:2])\n    dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n    return dataset_dict","0bede4e7":"from detectron2.engine import DefaultTrainer\nfrom detectron2.data import build_detection_test_loader, build_detection_train_loader\n\nclass CustomTrainer(DefaultTrainer):\n    @classmethod\n    def build_train_loader(cls, cfg):\n        return build_detection_train_loader(cfg, mapper=custom_mapper)","c1c5abf2":"from detectron2.data import DatasetCatalog, MetadataCatalog\n\nclasses = ['Raspberry_Pi_3', 'Arduino_Nano', 'ESP8266', 'Heltec_ESP32_Lora']\n\nfor d in [\"train\", \"test\"]:\n    DatasetCatalog.register('microcontroller\/' + d, lambda d=d: get_microcontroller_dicts('..\/input\/microcontroller-detection\/Microcontroller Detection\/' + d + '_labels.csv', '..\/input\/microcontroller-detection\/Microcontroller Detection\/' + d+'\/'))\n    MetadataCatalog.get('microcontroller\/' + d).set(thing_classes=classes)\nmicrocontroller_metadata = MetadataCatalog.get('microcontroller\/train')","d22d24df":"import random\nfrom detectron2.utils.visualizer import Visualizer\n\ndataset_dicts = DatasetCatalog.get('microcontroller\/train')\nfor d in random.sample(dataset_dicts, 10):\n    img = cv2.imread(d[\"file_name\"])\n    v = Visualizer(img[:, :, ::-1], metadata=microcontroller_metadata, scale=0.5)\n    v = v.draw_dataset_dict(d)\n    plt.figure(figsize = (14, 10))\n    plt.imshow(cv2.cvtColor(v.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))\n    plt.show()","8ad84228":"from detectron2.config import get_cfg\n\ncfg = get_cfg()\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection\/faster_rcnn_R_101_FPN_3x.yaml\"))\ncfg.DATASETS.TRAIN = ('microcontroller\/train',)\ncfg.DATASETS.TEST = ()   # no metrics implemented for this dataset\ncfg.DATALOADER.NUM_WORKERS = 2\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection\/faster_rcnn_R_101_FPN_3x.yaml\")\ncfg.SOLVER.IMS_PER_BATCH = 16\ncfg.SOLVER.MAX_ITER = 1000\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 4\n\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\ntrainer = CustomTrainer(cfg) \ntrainer.resume_or_load(resume=False)\ntrainer.train()","4fe85831":"# code from https:\/\/www.kaggle.com\/julienbeaulieu\/detectron2-wheat-detection-eda-training-eval\ntrain_data_loader = trainer.build_train_loader(cfg)\ndata_iter = iter(train_data_loader)\nbatch = next(data_iter)","1f20c74a":"rows, cols = 3, 3\nplt.figure(figsize=(20,20))\n\nfor i, per_image in enumerate(batch[:int(rows*cols)]):\n    \n    plt.subplot(rows, cols, i+1)\n    \n    # Pytorch tensor is in (C, H, W) format\n    img = per_image[\"image\"].permute(1, 2, 0).cpu().detach().numpy()\n    img = utils.convert_image_to_rgb(img, cfg.INPUT.FORMAT)\n\n    visualizer = Visualizer(img, metadata=microcontroller_metadata, scale=0.5)\n\n    target_fields = per_image[\"instances\"].get_fields()\n    labels = None\n    vis = visualizer.overlay_instances(\n        labels=labels,\n        boxes=target_fields.get(\"gt_boxes\", None),\n        masks=target_fields.get(\"gt_masks\", None),\n        keypoints=target_fields.get(\"gt_keypoints\", None),\n    )\n    plt.imshow(vis.get_image()[:, :, ::-1])","6e232be3":"cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8   # set the testing threshold for this model\ncfg.DATASETS.TEST = ('microcontroller\/test', )\npredictor = DefaultPredictor(cfg)","03cf8457":"df_test = pd.read_csv('..\/input\/microcontroller-detection\/Microcontroller Detection\/test_labels.csv')\ndf_test","21bf2d9a":"from detectron2.utils.visualizer import ColorMode\nimport random\n\ndataset_dicts = DatasetCatalog.get('microcontroller\/test')\nfor d in random.sample(dataset_dicts, 5):    \n    im = cv2.imread(d[\"file_name\"])\n    outputs = predictor(im)\n    v = Visualizer(im[:, :, ::-1], metadata=microcontroller_metadata, scale=0.8)\n    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n    plt.figure(figsize = (14, 10))\n    plt.imshow(cv2.cvtColor(v.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))\n    plt.show()","19c233f9":"We can check if our code works correctly by plotting a few images.","3ca684a0":"## Register data-set\n\nIn order to use a dataset with Detectron2 we need to register it. For more information check out the [official documentation](https:\/\/detectron2.readthedocs.io\/tutorials\/datasets.html#register-a-dataset).","ed05f0e7":"## Get data","24dfa3bd":"<table align=\"left\"><td>\n  <a target=\"_blank\"  href=\"https:\/\/colab.research.google.com\/github\/TannerGilbert\/Microcontroller-Detection-with-Detectron2\/blob\/master\/Detectron2_Detect_Microcontrollers_with_data_augmentation.ipynb\">\n    <img src=\"https:\/\/www.tensorflow.org\/images\/colab_logo_32px.png\" \/>Run in Google Colab\n  <\/a>\n<\/td><td>\n  <a target=\"_blank\"  href=\"https:\/\/github.com\/TannerGilbert\/Microcontroller-Detection-with-Detectron2\/blob\/master\/Detectron2_Detect_Microcontrollers_with_data_augmentation.ipynb\">\n    <img width=32px src=\"https:\/\/www.tensorflow.org\/images\/GitHub-Mark-32px.png\" \/>View source on GitHub<\/a>\n<\/td><\/table>","fc9e3284":"## Install detectron2\n\n> **Important**: If you're running on a local machine, be sure to follow the [installation instructions](https:\/\/github.com\/facebookresearch\/detectron2\/blob\/master\/INSTALL.md). This notebook includes only what's necessary to run in Colab.","421d3e76":"## Train model\n\nNow, let's fine-tune a pretrained FasterRCNN object detection model to detect the different microcontrollers.","26f92ff6":"## Use model for inference\n\nNow, we can perform inference on our validation set by creating a predictor object.","25e3a4b2":"## Visualize augmentations","991fe674":"# Detectron2 train microcontroller detector with data augmentation\n![detection example](https:\/\/github.com\/TannerGilbert\/Microcontroller-Detection-with-Detectron2\/blob\/master\/doc\/detection.png?raw=1)"}}