{"cell_type":{"b5d1ef8a":"code","562e0f8e":"code","557fe94d":"code","bb8f0740":"code","556f072f":"code","10af93de":"code","895fde8d":"code","66f51f5b":"code","da7e3952":"code","7519a5bd":"code","18d59613":"code","d8335049":"code","f3218d31":"code","bba7e9f0":"code","8af96128":"code","14c1bacd":"code","6fe29e01":"code","1a0d2d5f":"code","bfd19360":"code","543d7e84":"code","f79e1afb":"code","ca5b2068":"code","8582fc97":"code","e36ba1ff":"code","71e67d7c":"code","97bf36b5":"code","5ab7525c":"code","d20af963":"code","aa97d294":"code","9aa675f0":"code","d701a13f":"code","8937400b":"code","b286b3a6":"code","f213cedc":"code","de8155a1":"markdown","45b36d04":"markdown","72002d36":"markdown","edb6923f":"markdown","4e5d2dfb":"markdown","8acf6fdf":"markdown","c7208025":"markdown","5bd4274d":"markdown","6bfcadbd":"markdown","bc59b635":"markdown","49ffa54d":"markdown","c761e21b":"markdown","6db53954":"markdown","220f5229":"markdown","e97016ad":"markdown","f871df5e":"markdown","d3da7101":"markdown","f614d465":"markdown","fb9ce3d5":"markdown","a4439fe7":"markdown","9d66da24":"markdown","3b7b225b":"markdown","b8b5f286":"markdown","d2fd8d1c":"markdown"},"source":{"b5d1ef8a":"from fastai.vision import *\nfrom fastai.widgets import DatasetFormatter\nfrom fastai.widgets import ImageCleaner\n\nfrom pathlib import Path\n\nimport pandas as pd\nimport numpy as np\n\nimport shutil\nimport os\n\npd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)","562e0f8e":"classes = {'man': '..\/input\/manvswoman\/man_download.csv',\n           'woman': '..\/input\/manvswoman\/woman_download.csv'\n           }","557fe94d":"path = Path('data\/')\n\nfor label in classes:\n    dest = path\/label\n    print(path\/label)\n    dest.mkdir(parents=True, exist_ok=True)\n    classes[label]\n    download_images(classes[label], dest, max_pics=200)","bb8f0740":"for c in classes:\n    print(c)\n    verify_images(path\/c, delete=True, max_size=500)","556f072f":"np.random.seed(42)\ndata = ImageDataBunch.from_folder(path, train=\".\", valid_pct=0.3,\n        ds_tfms=get_transforms(), size=224, num_workers=4).normalize(imagenet_stats)","10af93de":"data.classes","895fde8d":"data.show_batch(rows=3, figsize=(7,8))","66f51f5b":"data.classes, data.c, len(data.train_ds), len(data.valid_ds)","da7e3952":"learn = cnn_learner(data, models.resnet34, metrics=error_rate)","7519a5bd":"learn.fit_one_cycle(4)","18d59613":"learn.save('stage-1')","d8335049":"learn.unfreeze()","f3218d31":"learn.lr_find()","bba7e9f0":"learn.recorder.plot()","8af96128":"learn.fit_one_cycle(2, max_lr=slice(1e-05,1e-04))","14c1bacd":"learn.save('stage-2')","6fe29e01":"learn.load('stage-2');","1a0d2d5f":"interp = ClassificationInterpretation.from_learner(learn)\n\nlosses,idxs = interp.top_losses()\n\nlen(data.valid_ds)==len(losses)==len(idxs)","bfd19360":"interp.plot_confusion_matrix()","543d7e84":"n_mistakes = 15\ninterp.plot_top_losses(n_mistakes, figsize=(15,11))","f79e1afb":"db = (ImageList.from_folder(path)\n                   .split_none()\n                   .label_from_folder()\n                   .transform(get_transforms(), size=224)\n                   .databunch()\n     )","ca5b2068":"learn_cln = cnn_learner(db, models.resnet34, metrics=error_rate)\n\nlearn_cln.load('stage-2');","8582fc97":"ds, idxs = DatasetFormatter().from_toplosses(learn_cln)","e36ba1ff":"ImageCleaner(ds, idxs, path)","71e67d7c":"new_classes = pd.read_csv('.\/data\/cleaned.csv')\nnew_classes.head()","97bf36b5":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nroot_path = '..\/working\/data\/{0}'\nimg=mpimg.imread(root_path.format('woman') + '\/00000002.jpg')\nimgplot = plt.imshow(img)\nplt.show()","5ab7525c":"path = Path('clean_data\/')\n\nclasses = new_classes['label'].unique()\n\nfor label in classes:\n    folder_name = label\n    dest = path\/folder_name\n    dest.mkdir(parents=True, exist_ok=True)    ","d20af963":"counter = 0\n\nfor label in classes:\n    root_path = '..\/working\/data\/{0}'\n    dest_path = '..\/working\/clean_data\/{0}'\n    temp_df = new_classes.loc[new_classes['label'] == label]    \n    files = list(temp_df['name'])\n    for f in files:\n        img_origin = '\/'.join([root_path.format(label), f.split('\/')[1]])\n        img_dest = '\/'.join([dest_path.format(label), str(counter) + '.jpg'])\n        shutil.copy(img_origin, img_dest)\n        counter += 1","aa97d294":"np.random.seed(42)\ndata = ImageDataBunch.from_folder(path, train=\".\", valid_pct=0.3,\n        ds_tfms=get_transforms(), size=224, num_workers=4).normalize(imagenet_stats)","9aa675f0":"new_learn = cnn_learner(data, models.resnet34, metrics=error_rate)","d701a13f":"new_learn.fit_one_cycle(4)","8937400b":"new_learn.save('stage-3')","b286b3a6":"interp = ClassificationInterpretation.from_learner(new_learn)\n\nlosses,idxs = interp.top_losses()\n\nlen(data.valid_ds)==len(losses)==len(idxs)\ninterp.plot_confusion_matrix()\nn_mistakes = 3\ninterp.plot_top_losses(n_mistakes, figsize=(15,11))","f213cedc":"learn.export()","de8155a1":"> Retrain the model on the clean images - 3.4","45b36d04":"> Train model- 2.2\n\n**Note** in order for the results to be really good you have to provide alot of images.","72002d36":"> Get a list of URLs - 1.1\n\n* Search and scroll\n    Go to [Google Images](https:\/\/images.google.com\/?gws_rd=ssl) and search for the images you are interested in. The more specific you are in your Google Search, the better the results and the less manual pruning you will have to do.\n\n    Scroll down until you've seen all the images you want to download, or until you see a button that says 'Show more results'. All the images you scrolled past are now available to download. To get more, click on the button, and continue scrolling. The maximum number of images Google Images shows is 700.\n\n* Download into file\n    In Google Chrome press Ctrl+Shift+j and paste this code-\n    `urls=Array.from(document.querySelectorAll('.rg_i')).map(el=> el.hasAttribute('data-src')?el.getAttribute('data-src'):el.getAttribute('data-iurl'));`\n    `window.open('data:text\/csv;charset=utf-8,' + escape(urls.join('\\n')));`\n\n****Note**** It'll save locally the list of urls so you could just go to Data section in your notebook and upload to files from your local computer into the kaggle computer","edb6923f":"Note- Sometimes you'll see that there are images in the data set that shouldn't be there (class man with image of woman for example).\nFor now we'll let them stay and we'll clean them later.","4e5d2dfb":"> Create new folders for the cleaned pictures- 3.2","8acf6fdf":"**Note**- I'm following the [tutorial](https:\/\/www.youtube.com\/watch?v=ccMHJeQU4Qw&t=1435s) by dear Jeremy Howard so if you want you could follow the tutorial too.","c7208025":"> # Interpretation- 3\n\nTLDR; why the model decides this or that\n\nInterpretable is to understand what your model is really doing.\n\nModel Interpretability also helps you debug your model by giving you a chance to see what the model really thinks is important.","5bd4274d":"> Remove any images that can't be opened- 1.2","6bfcadbd":"Interesting... some mistakes were made due to wrong classification at the dataset, while other mistakes were without any connection to bad clasification in the dataset.\n\n**Note** the probabillity indicates the probabillity of the actual class of the image. While loss is loss and it just tells you have good was your prediction.","bc59b635":"As you can see we still have some misslabeled data in our dataset that could be fixed with doing the same procedure iteratively, but for now we'll move on (:","49ffa54d":"> Download images - 1.1","c761e21b":"> # Putting your model in production- 4\n\n> exporting the model- 4.1\n\nThis line of code will create a file `export.pkl` which is a pickle of your model.","6db53954":"> # Data preprocessing- 2\n\n> View the data 2.1","220f5229":"> # Creating your own dataset from Google Images - 1","e97016ad":"> Clean the images- 3.1","f871df5e":"So in this one we'll create our own data set of images and train our own classifier using [Transfer learning](https:\/\/en.wikipedia.org\/wiki\/Transfer_learning) method with fastai on the resnet34","d3da7101":"We can prune our top losses, removing photos that don't belong using the ImageCleaner widget from `fastai.widgets`.\n\n**Note** the widget will not delete images directly from disk but it will create a new csv file cleaned.csv from where you can create a new ImageDataBunch with the corrected labels to continue training your model.","f614d465":"> Relocate clean images to their folders- 3.3","fb9ce3d5":"> Now we'll try to tune the learning rate- 2.3\n\n**Note**\nLearning rate- the amount that the weights are updated during training is referred to as the step size or the \u201clearning rate.\u201d","a4439fe7":"In order to use your new algorithm follow these instructions:\n\n1. Basically, you need to export the model using\n`learn.export(file = Path(\"\/kaggle\/working\/export.pkl\"))`\n\n2. Then commit your code. This will make it available in the \"Output\" section of the kernel.\n\n3. Download this pkl file (locally)\n\n4. Upload this as a dataset into Kaggle (an example of my uploaded dataset can be found here)\n\n5. Add that dataset to your Kernel where you want to use this (same as the one in step 1). It should appear in the \"Input\" folder and can be accessed as follows\n`deployed_path = \"..\/input\/kannada-mnist-resnet50\/\" # If using a deployed model`\n\n6. Load from that location using (for example)\n`learn = load_learner(deployed_path)`","9d66da24":"> # Modeling- 2\n\n> Build model 2.1","3b7b225b":"**Note** the following cells are commented since it could be some hard work to sit down and make sure that the labelling is correct.\n\nYou could uncomment it and do the procedure (:","b8b5f286":"> # Thanks for making it to the end of my notebook! Please leave your thought down below and if you liked it I'd appreciate an upvote(:","d2fd8d1c":"So we see that there are some mistakes that the model made, maybe due to actual mistakes in the data or just mistakes of the model it self.\n\n**Note** \nI'll take some material that was provided in the [first tutorial](https:\/\/www.youtube.com\/watch?v=XfoYk_Z5AkI&t=4190s) of Jeremy Howard fastai so you might as well check that out too."}}