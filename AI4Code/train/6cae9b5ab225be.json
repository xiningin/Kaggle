{"cell_type":{"f8872d0f":"code","798e117f":"code","61dc2c96":"code","83a95ace":"code","f871aae7":"code","7a801183":"code","909906ca":"code","43424d6d":"code","eef43165":"code","15f4136f":"code","697bdc84":"code","05698e15":"code","a50bb909":"code","20a82a5a":"code","3d11ff43":"code","8ccae602":"code","2639b42f":"code","f112a80e":"code","90c44df7":"code","64c4ec8a":"markdown","211bc6af":"markdown","b19d536d":"markdown","fecaf5f1":"markdown","d360c8ff":"markdown","972aba1f":"markdown","65453c48":"markdown","94c1e92e":"markdown","c7da4bfc":"markdown","57a4306f":"markdown"},"source":{"f8872d0f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport xgboost as xgb\nfrom sklearn import model_selection\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.metrics import plot_confusion_matrix\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","798e117f":"df = pd.read_csv('\/kaggle\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ndf = df.set_index('customerID')","61dc2c96":"def utils_recognize_type(dtf, col, max_cat=20):\n    if (dtf[col].dtype == \"O\") | (dtf[col].nunique() < max_cat):\n        return \"cat\"\n    else:\n        return \"num\"\n    \ndic_cols = {col:utils_recognize_type(df, col, max_cat=20) for col in df.columns}\nheatmap = df.isnull()\n#print(heatmap)\nfor k,v in dic_cols.items():\n if v == \"num\":\n   heatmap[k] = heatmap[k].apply(lambda x: 0.5 if x is False else 1)\n else:\n   heatmap[k] = heatmap[k].apply(lambda x: 0 if x is False else 1)\n   \nsns.heatmap(heatmap, cbar=False).set_title('Dataset Overview')\n\nplt.show()\n\nprint(\"\\033[1;37;40m Categerocial \", \"\\033[1;30;41m Numeric \", \"\\033[1;30;47m NaN \")","83a95ace":"df.dtypes","f871aae7":"df.loc[(df['TotalCharges'] == ' '), 'TotalCharges'] = 0\ndf.loc[df['tenure'] == 0]","7a801183":"df['TotalCharges'] = pd.to_numeric(df['TotalCharges']) #make sure the TotalCharges column is actually a number\ndf.replace(' ', '_', regex=True, inplace = True) #replace all the white space in the entire dataframe\n\ndf['Churn_value'] = np.where(df['Churn'] == 'Yes', 1, 0)\ndf.drop('Churn', axis =1, inplace = True)\ndf.head()","909906ca":"X = df.drop('Churn_value', axis = 1).copy()\nX.head()","43424d6d":"y = df['Churn_value'].copy()\ny.head()","eef43165":"df_object = df.select_dtypes(exclude=[np.number])\ndf_object.columns","15f4136f":"X_encoded = pd.get_dummies(X, columns = df_object.columns)\nX_encoded","697bdc84":"sum(y)\/ len(y)","05698e15":"X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, random_state = 42, stratify = y)","a50bb909":"sum(y_train)\/ len(y_train)","20a82a5a":"sum(y_test)\/ len(y_test)","3d11ff43":"clf_xgb = xgb.XGBClassifier(objective='binary:logistic', seed = 42)\nclf_xgb.fit(X_train,y_train, verbose = False, eval_metric='aucpr', eval_set=[(X_test,y_test)])\nplot_confusion_matrix(clf_xgb,X_test,y_test,values_format = 'd',display_labels=['Did not leave','Left'])","8ccae602":"(237 \/ 467)* 100","2639b42f":"#Round 2\nparam_grid1 = {\n    'max_depth': [3,4],\n    'learning_rate': [0.01,0.05,0.03],\n    'gamma': [0.25,1.0,1.5],\n    'reg_lamda': [0],\n    'scale_pos_weight': [3,4,5]\n}\n\noptimal_params = GridSearchCV(\n    estimator=xgb.XGBClassifier(objective='binary:logistic',\n    seed = 42,\n    use_label_encoder=False,\n    subsample=0.9,\n    colsample_bytree=0.5),\n    param_grid=param_grid1,\n    scoring='roc_auc',\n    verbose=0,\n    n_jobs=10,\n    cv=3\n)\n\n\"\"\" optimal_params.fit(\n    X_train,\n    y_train,\n    early_stopping_rounds = 10,\n    eval_metric='auc',\n    eval_set=[(X_test, y_test)],\n    verbose = False)\n \"\"\"\noptimal_params.fit(X_train,y_train)\nprint(optimal_params.best_params_)","f112a80e":"clf_xgb = xgb.XGBClassifier(\n    seed=42,\n    objective='binary:logistic',\n    gamma = 0.25,\n    learn_rate = 0.05,\n    max_depth=3,\n    reg_lamda = 0,\n    scale_pos_weight = 3,\n    subsample =0.9,\n    colsample_bytree=0.5)\n\nclf_xgb.fit(\n    X_train,\n    y_train,\n    verbose=False,\n    early_stopping_rounds=10,\n    eval_metric='aucpr',\n    eval_set=[(X_test,y_test)])\n\nplot_confusion_matrix(clf_xgb,X_test,y_test,values_format = 'd',display_labels=['Did not leave','Left'])","90c44df7":"(1- (85\/467))*100","64c4ec8a":"Create training data dataframe","211bc6af":"Select all the columns of the X dataframe that are objects. We are going to One-hot encode these columns","b19d536d":"26.5% of customers leave","fecaf5f1":"Our training and test datasets retain the same percentage of customers who leave","d360c8ff":"Create y value series","972aba1f":"We correctly identify ~50% of customers that leave ","65453c48":"Total charges columns has some whitespace in the column- only occurs when tenure = 0 meaning the customer hasn't been billed yet, so we make totalcharges=0.0","94c1e92e":"We will split using stratification in order to maintain the same percentage of people who left in both the training and test set","c7da4bfc":"We caught 82% of the people that left.","57a4306f":"## Illustrates the data types in the Telco data"}}