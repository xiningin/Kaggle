{"cell_type":{"afd413e3":"code","06c3befd":"code","58717814":"code","0e95cca6":"code","5d66523e":"code","397cbb04":"code","db02ac04":"code","f234354e":"code","fd529d7e":"code","ed665139":"code","0bb5517a":"code","febd7a06":"code","2709d810":"code","7e4be6a0":"code","77ee748a":"code","38611c94":"code","6145a449":"code","d03c1050":"code","9f15c292":"code","34833453":"code","dc4e0e14":"code","d4dbf920":"code","e8620437":"code","835cf4e7":"markdown","bf04ba06":"markdown","6b035598":"markdown"},"source":{"afd413e3":"import sys\nsys.path.append('..\/input\/timm-pytorch-image-models\/pytorch-image-models-master')","06c3befd":"from transformers import DistilBertModel, DistilBertTokenizer, DistilBertConfig\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\n\nMAX_LEN = 128\n\ntokenizers = [DistilBertTokenizer.from_pretrained(\"\/kaggle\/input\/db-tokenizer\", do_lower_case=True),\n              AutoTokenizer.from_pretrained(\"\/kaggle\/input\/db-tokenizer2\", do_lower_case=True)]","58717814":"import os\nimport cv2\nimport math\nimport random\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\n\nimport albumentations\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport torch\nimport timm\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import Dataset,DataLoader\n\nimport gc\nimport matplotlib.pyplot as plt\nimport cudf\nimport cuml\nimport cupy\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom cuml import PCA\nfrom cuml.neighbors import NearestNeighbors","0e95cca6":"class CFG:\n    seed = 54\n    classes = 11014 \n    scale = 30 \n    margin = 0.5\n    model_name =  'tf_efficientnet_b4'\n    fc_dim = 512\n    img_size = 512\n    batch_size = 20\n    num_workers = 4\n    device = device = 'cuda' if torch.cuda.is_available() else 'cpu'","5d66523e":"import codecs\nfrom unicodedata import normalize\n\n\nUNIT_TEST_SIZE = 256\n\ndef fix_encoding(x):\n    return normalize(\"NFD\", codecs.escape_decode(x, 'hex')[0].decode(\"utf-8\"))\n\ndef read_dataset():\n    df = pd.read_csv('..\/input\/shopee-product-matching\/test.csv')\n    df[\"path\"] = \"test\"\n    fp_df = pd.read_csv('..\/input\/shopee-product-matching\/train.csv')\n    \n    if df.shape[0] == 3:\n        df = pd.read_csv('..\/input\/shopee-product-matching\/train.csv').head(UNIT_TEST_SIZE).drop(\"label_group\", axis=1)\n        df[\"path\"] = \"train\"\n        fp_df = pd.read_csv('..\/input\/shopee-product-matching\/train.csv').tail(UNIT_TEST_SIZE).drop(\"label_group\", axis=1)\n        \n    df[\"title\"] = df[\"title\"].apply(fix_encoding)\n    fp_df[\"title\"] = fp_df[\"title\"].apply(fix_encoding)\n    fp_df[\"path\"] = \"train\"\n    return df, fp_df\n\ndf, fp_df = read_dataset()\ndf.shape, fp_df.shape","397cbb04":"def seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_torch(CFG.seed)","db02ac04":"img_backbones = [\"swin_base_patch4_window12_384\", \n                 'tf_efficientnet_b4', \n                 \"vit_base_resnet50_384\"]\nimg_model_paths = ['..\/input\/shopee-img-models\/img_model_i15.pth', \n                   '..\/input\/shopee-img-models\/img_model_i04.pth',\n                   '..\/input\/shopee-img-models\/img_model_i11.pth']\n\n\nclass ShopeeModel(nn.Module):\n    def __init__(self, model_name, pretrained, fc_dim=512):\n        super(ShopeeModel, self).__init__()\n        self.model_name = model_name\n        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n        if model_name != \"tf_efficientnet_b4\":\n            in_features = self.backbone.head.in_features\n            self.backbone.head = nn.Identity()\n        else:\n            in_features = self.backbone.classifier.in_features\n            self.backbone.classifier = nn.Identity()\n        self.backbone.global_pool = nn.Identity()\n        self.pooling = nn.AdaptiveAvgPool2d(1)\n        \n        self.dropout = nn.Dropout(p=0.1)\n        self.classifier = nn.Linear(in_features, fc_dim)\n        self.bn = nn.BatchNorm1d(fc_dim)\n        self._init_params()\n        self.vector_size = fc_dim\n        \n    def _init_params(self):\n        nn.init.xavier_normal_(self.classifier.weight)\n        nn.init.constant_(self.classifier.bias, 0)\n        nn.init.constant_(self.bn.weight, 1)\n        nn.init.constant_(self.bn.bias, 0)\n        \n    def forward(self, x):\n        batch_size = x.shape[0]\n        x = self.backbone(x)\n        if self.model_name == \"tf_efficientnet_b4\":\n            x = self.pooling(x)\n        x = x.view(batch_size, -1)\n\n        x = self.dropout(x)\n        x = self.classifier(x)\n        x = self.bn(x)\n        \n        x = F.normalize(x)\n        return x","f234354e":"from transformers import DistilBertModel, DistilBertTokenizer\n\n\nclass Text2Vec(nn.Module):\n    def __init__(self, bert):\n        super(Text2Vec, self).__init__()\n        self.top = nn.Sequential(nn.BatchNorm1d(768), nn.Dropout(0.2), nn.Linear(768, 256))\n        self.bert = bert\n        \n    def forward(self, ids, mask):\n        return F.normalize(self.top(self.bert(ids, mask)[0][:, 0, :]))\n\n    \nclass ShopeeDataset(Dataset):\n    \n    def __init__(self, df):\n        super().__init__()\n        self.df = df.reset_index(drop=True)\n        self.img_sizes = [(512, 512), (384, 384)]\n        self.tokenizers = tokenizers\n\n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        \n        img = cv2.imread(f\"\/kaggle\/input\/shopee-product-matching\/{row.path}_images\/{row.image}\")\n        \n        outs = [torch.FloatTensor(cv2.resize(img, size)).permute(2, 0, 1)\/255.0 for size in self.img_sizes]\n        \n        for i in range(len(tokenizers)):\n            inputs = self.tokenizers[i].encode_plus(\n                row.title,\n                None,\n                add_special_tokens=True,\n                max_length=MAX_LEN,\n                padding=\"max_length\",\n                return_token_type_ids=True,\n                truncation=True\n            )\n            outs.append(torch.LongTensor(inputs['input_ids']))\n            outs.append(torch.LongTensor(inputs['attention_mask']))\n        return tuple(outs)\n\n    def __len__(self):\n        return self.df.shape[0]","fd529d7e":"def get_embeddings(df):\n    conf = AutoConfig.from_pretrained(\"\/kaggle\/input\/db-tokenizer2\/config.json\")\n    text2vecs = [Text2Vec(DistilBertModel(DistilBertConfig())), Text2Vec(DistilBertModel(conf))]\n\n    text2vecs[0].load_state_dict(torch.load(\"\/kaggle\/input\/shopee-text-models\/text_model_t08full_0.pth\"))\n    text2vecs[1].load_state_dict(torch.load(\"\/kaggle\/input\/shopee-text-models\/text_model_t08full_1.pth\"))\n\n    text2vecs[0] = text2vecs[0].cuda()\n    text2vecs[1] = text2vecs[1].cuda()\n    text2vecs[0].eval()\n    text2vecs[1].eval()\n\n    models = [None, None, None]\n    for i in range(3):\n        models[i] = ShopeeModel(img_backbones[i], pretrained=False).to(CFG.device)\n        models[i].load_state_dict(torch.load(img_model_paths[i]))\n        models[i].eval()\n\n    image_dataset = ShopeeDataset(df)\n    image_loader = torch.utils.data.DataLoader(\n        image_dataset,\n        batch_size=CFG.batch_size,\n        num_workers=CFG.num_workers\n    )\n\n    V_img1, V_img2, V_img3, V_text1, V_text2 = [], [], [], [], []\n    with torch.no_grad():\n        for x in tqdm(image_loader): \n            inputs = [inp.cuda() for inp in x]\n            im_vector1 = models[0](inputs[1])#\/(6**0.5)\n            im_vector2 = models[1](inputs[0])#\/(6**0.5)\n            im_vector3 = models[2](inputs[1])#\/(6**0.5)\n            text_vector1 = text2vecs[0](inputs[2], inputs[3])#\/(4**0.5)\n            text_vector2 = text2vecs[1](inputs[4], inputs[5])#\/(4**0.5)\n            \n            V_img1.append(im_vector1.detach().cpu().numpy().astype(np.float32))\n            V_img2.append(im_vector2.detach().cpu().numpy().astype(np.float32))\n            V_img3.append(im_vector3.detach().cpu().numpy().astype(np.float32))\n            V_text1.append(text_vector1.detach().cpu().numpy().astype(np.float32))\n            V_text2.append(text_vector2.detach().cpu().numpy().astype(np.float32))\n            \n    V_img1, V_img2, V_img3, V_text1, V_text2 = np.concatenate(V_img1), np.concatenate(V_img2), np.concatenate(V_img3), np.concatenate(V_text1), np.concatenate(V_text2)\n\n    return np.concatenate([V_img1, V_img2, V_img3], axis=1)\/np.sqrt(3), np.concatenate([V_text1, V_text2], axis=1)\/np.sqrt(2)","ed665139":"V_img, V_text = get_embeddings(df)\nV_img.shape, V_text.shape","0bb5517a":"V_img_fp, V_text_fp = get_embeddings(fp_df)\nV_img_fp.shape, V_text_fp.shape","febd7a06":"def db_aug(V):\n    model = NearestNeighbors(n_neighbors=2, metric=\"cosine\")\n    model.fit(V)\n    distances, indices = model.kneighbors(V)\n    \n    w = np.power(np.clip(2.0 - distances, 0, 2.0), 0.5)\n    \n    V = (w[:, 0, None]*V[indices[:, 0]] + w[:, 1, None]*V[indices[:, 1]])\/w.sum(axis=1)[:, None]\n    \n    return V\n\n\nV = db_aug(np.concatenate([V_img\/np.sqrt(2), V_text\/np.sqrt(2)], axis=1))\nV.shape","2709d810":"model = NearestNeighbors(n_neighbors=50, metric=\"cosine\")\nmodel.fit(V)\ndistances, indices = model.kneighbors(V)","7e4be6a0":"def get_min_dist(V, V_fp):\n    d = []\n    bs = 256\n    for begin in tqdm(range(0, V.shape[0], bs)):\n        end = min(V.shape[0], begin + bs)\n        d.append(np.dot(V[begin:end], V_fp).max(axis=1))\n    \n    return 1 - np.concatenate(d)\n\n\nD_img_fp_min = get_min_dist(V_img, V_img_fp.T)\nD_text_fp_min = get_min_dist(V_text, V_text_fp.T)\n\nD_img_fp_min.shape, D_text_fp_min.shape","77ee748a":"postings = df[\"posting_id\"].values\nres_df = []\n\nfor i in tqdm(range(df.shape[0])):\n    dix = np.where(distances[i] < 0.37)[0]\n    ix = indices[i][dix]\n    img_fp_min = D_img_fp_min[i]\n    text_fp_min = D_text_fp_min[i]\n    \n    for index, j in enumerate(ix):\n        img_fp_min2 = D_img_fp_min[j]\n        text_fp_min2 = D_text_fp_min[j]\n        res_df.append({\"posting_id\": postings[i], \"matches\": postings[j], \"dist\": distances[i, dix[index]], \n                       \"img_dist\": 1 - (V_img[i]*V_img[j]).sum(), \"text_dist\": 1 - (V_text[i]*V_text[j]).sum(),\n                       \"img_fp_min\": img_fp_min, \"text_fp_min\": text_fp_min, \"img_fp_min2\": img_fp_min2, \"text_fp_min2\": text_fp_min2})\n        \nres_df = pd.DataFrame(res_df)\nprint(res_df.shape)\nres_df.head()","38611c94":"res_df[\"dist_rank\"] = res_df.groupby(\"posting_id\")[\"dist\"].rank()","6145a449":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf = TfidfVectorizer(ngram_range=(1,1), binary=True)\ntfidf.fit(df[\"title\"])\n\ntfidf2 = TfidfVectorizer(analyzer=\"char\", ngram_range=(5, 5))\ntfidf2.fit(df[\"title\"])","d03c1050":"preds_df = res_df[res_df[\"posting_id\"] < res_df[\"matches\"]]\npreds_df = preds_df.merge(df[[\"posting_id\", \"title\"]], on=\"posting_id\", how=\"left\")\npreds_df = preds_df.merge(df[[\"posting_id\", \"title\"]].rename(columns={\"posting_id\": \"matches\"}), on=\"matches\", how=\"left\")\n\n\npreds_df[\"cos_sim\"] = tfidf.transform(preds_df[\"title_x\"]).multiply(tfidf.transform(preds_df[\"title_y\"])).sum(axis=1)\npreds_df[\"cos_sim2\"] = tfidf2.transform(preds_df[\"title_x\"]).multiply(tfidf2.transform(preds_df[\"title_y\"])).sum(axis=1)\n\npreds_df.shape","9f15c292":"import xgboost as xgb\n\nfeatures = [\"img_dist\", \"text_dist\", \"dist\", \"dist_rank\", \"cos_sim\", \"cos_sim2\",\n            \"img_fp_min\", \"text_fp_min\", \"img_fp_min2\", \"text_fp_min2\"]\n\nxgb_model = xgb.XGBClassifier()\nxgb_model.load_model(\"\/kaggle\/input\/shopee-xgb-models\/xgb_821_new.json\")\n\npreds_df[\"pred\"] = xgb_model.predict_proba(preds_df[features])[:, 1]\/2\n\n\npreds_df[features] = preds_df[features].rank(pct=True, axis=0)\nxgb_model = xgb.XGBClassifier()\nxgb_model.load_model(\"\/kaggle\/input\/shopee-xgb-models\/xgb_821b_new.json\")\n\npreds_df[\"pred\"] += xgb_model.predict_proba(preds_df[features])[:, 1]\/2\n\npreds_df.head()","34833453":"def agglomerative_clustering(preds_df, single_link_threshold=0.30, group_link_threshold=0.70, group_merge_threshold=0.80):\n\n    groups = dict()\n    group_members = dict()\n\n    gix = 0\n    for i, row in tqdm(preds_df.sort_values(\"pred\", ascending=False).iterrows(), total=preds_df.shape[0]):\n        if row.pred > single_link_threshold:\n            g1 = groups.get(row.posting_id)\n            g2 = groups.get(row.matches)\n\n            if g1 is None and g2 is None:\n                groups[row.posting_id] = gix\n                groups[row.matches] = gix\n                group_members[gix] = {row.posting_id, row.matches}\n                gix += 1\n            elif g1 is None:\n                if row.pred > group_link_threshold:\n                    groups[row.posting_id] = g2\n                    group_members[g2].add(row.posting_id)\n            elif g2 is None:\n                if row.pred > group_link_threshold:\n                    groups[row.matches] = g1\n                    group_members[g1].add(row.matches)\n            elif (g1 != g2) and (row.pred > group_merge_threshold):\n                groups[row.matches] = g1\n                group_members[g1].update(group_members[g2])\n\n                del group_members[g2]\n\n                for k, v in groups.items():\n                    if v == g2:\n                        groups[k] = g1\n\n\n    print(len(groups))\n\n    out_df = []\n\n    for k, v in groups.items():\n        for k2 in group_members[v]:\n            if k != k2:\n                out_df.append({\"posting_id\": k, \"matches\": k2})\n\n    return pd.DataFrame(out_df)\n\nout_df = agglomerative_clustering(preds_df)\nout_df.shape","dc4e0e14":"same_df = df[[\"posting_id\"]].copy()\nsame_df[\"matches\"] = same_df[\"posting_id\"].values\n\nout_df = out_df.append(same_df)\nout_df.shape","d4dbf920":"out_df = out_df.groupby(\"posting_id\")[\"matches\"].agg(list).reset_index()\nout_df[\"matches\"] = out_df[\"matches\"].apply(lambda x: \" \".join(x))\nout_df.head()","e8620437":"out_df.to_csv('submission.csv', index=False, columns=['posting_id', 'matches'])","835cf4e7":"# Config","bf04ba06":"# Image Predictions","6b035598":"# Utils"}}