{"cell_type":{"bcee4274":"code","f271dcdf":"code","cda5b5d9":"code","dd15ec32":"code","4a3ba244":"code","9cfd5f8e":"code","7d3b558b":"code","e689457f":"code","c56c2b67":"code","44b194de":"code","0e4c3cf8":"code","95344ba6":"code","02366332":"code","93304b7c":"code","8a2561ed":"code","c3204fc2":"code","c5b2b770":"code","c59428fc":"code","6802693b":"code","b843fdd0":"code","c9129ec4":"code","4e740e0d":"code","8b8c49e4":"code","a4617381":"markdown","f3c6206e":"markdown","23ad5744":"markdown","91528d1b":"markdown","f72f61ed":"markdown","d7198c0d":"markdown","48737c10":"markdown","0cf221cc":"markdown","413ce129":"markdown","d96b9d54":"markdown","5dbb522d":"markdown","0e30c799":"markdown","018ad514":"markdown","43029ff1":"markdown","0e749520":"markdown","203722a5":"markdown","56419143":"markdown","ff875266":"markdown"},"source":{"bcee4274":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","f271dcdf":"train_df=pd.read_csv('\/kaggle\/input\/iba-ml1-mid-project\/train.csv')\ntrain_df.head()","cda5b5d9":"train_df.isnull().sum()","dd15ec32":"from sklearn.impute import SimpleImputer","4a3ba244":"#Filling Age\nimputer=SimpleImputer(strategy='median')\nimputer.fit_transform(train_df[['age']])\ntrain_df[['age']]=imputer.fit_transform(train_df[['age']])\n\n#Filling number_dependent_family_members\nimputer=SimpleImputer(strategy='median')\nimputer.fit_transform(train_df[['number_dependent_family_members']])\ntrain_df[['number_dependent_family_members']]=imputer.fit_transform(train_df[['number_dependent_family_members']])\n\n#Filling monthly_income\nimputer=SimpleImputer(strategy='median')\nimputer.fit_transform(train_df[['monthly_income']])\ntrain_df[['monthly_income']]=imputer.fit_transform(train_df[['monthly_income']])\n\n#Filling number_of_credit_lines\nimputer=SimpleImputer(strategy='median')\nimputer.fit_transform(train_df[['number_of_credit_lines']])\ntrain_df[['number_of_credit_lines']]=imputer.fit_transform(train_df[['number_of_credit_lines']])\n\n#Filling real_estate_loans\nimputer=SimpleImputer(strategy='median')\nimputer.fit_transform(train_df[['real_estate_loans']])\ntrain_df[['real_estate_loans']]=imputer.fit_transform(train_df[['real_estate_loans']])\n\n#Filling ratio_debt_payment_to_income\nimputer=SimpleImputer(strategy='median')\nimputer.fit_transform(train_df[['ratio_debt_payment_to_income']])\ntrain_df[['ratio_debt_payment_to_income']]=imputer.fit_transform(train_df[['ratio_debt_payment_to_income']])\n\n#Filling credit_line_utilization\n#But we need to convert datatype of column to float, cuz datas are numeric but they are in string datatype\ntrain_df['credit_line_utilization'] = pd.to_numeric(train_df['credit_line_utilization'],errors='coerce')\nimputer=SimpleImputer(strategy='median')\nimputer.fit_transform(train_df[['credit_line_utilization']])\ntrain_df[['credit_line_utilization']]=imputer.fit_transform(train_df[['credit_line_utilization']])\n\n#Filling number_of_previous_late_payments_up_to_59_days\nimputer=SimpleImputer(strategy='median')\nimputer.fit_transform(train_df[['number_of_previous_late_payments_up_to_59_days']])\ntrain_df[['number_of_previous_late_payments_up_to_59_days']]=imputer.fit_transform(train_df[['number_of_previous_late_payments_up_to_59_days']])\n\n#Filling number_of_previous_late_payments_up_to_89_days\nimputer=SimpleImputer(strategy='median')\nimputer.fit_transform(train_df[['number_of_previous_late_payments_up_to_89_days']])\ntrain_df[['number_of_previous_late_payments_up_to_89_days']]=imputer.fit_transform(train_df[['number_of_previous_late_payments_up_to_89_days']])\n\n#Filling number_of_previous_late_payments_90_days_or_more\nimputer=SimpleImputer(strategy='median')\nimputer.fit_transform(train_df[['number_of_previous_late_payments_90_days_or_more']])\ntrain_df[['number_of_previous_late_payments_90_days_or_more']]=imputer.fit_transform(train_df[['number_of_previous_late_payments_90_days_or_more']])","9cfd5f8e":"train_df.isnull().sum()","7d3b558b":"from sklearn.model_selection import train_test_split #for split the data\nfrom sklearn.metrics import accuracy_score  #for accuracy_score\nfrom sklearn.metrics import confusion_matrix #for confusion matrix\n\n\nall_features = train_df.drop(\"defaulted_on_loan\",axis=1)\nTargeted_feature = train_df[\"defaulted_on_loan\"]\n\nX_train,X_test,y_train,y_test = train_test_split(all_features,Targeted_feature,test_size=0.3,random_state=42)\nX_train.shape,X_test.shape,y_train.shape,y_test.shape\n","e689457f":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import roc_auc_score\n\nmodel = KNeighborsClassifier(n_neighbors = 5)\nmodel.fit(X_train,y_train)\nprediction_knn=model.predict_proba(X_test)[:,1]\n\nroc_auc_score(y_test,prediction_knn)","c56c2b67":"from sklearn.linear_model import LogisticRegression \nmodel = LogisticRegression()\nmodel.fit(X_train,y_train)\nprediction_lr=model.predict_proba(X_test)[:,1]\nroc_auc_score(y_test,prediction_lr)","44b194de":"from sklearn.naive_bayes import GaussianNB\nmodel= GaussianNB()\nmodel.fit(X_train,y_train)\nprediction_gnb=model.predict_proba(X_test)[:,1]\nroc_auc_score(y_test,prediction_gnb)","0e4c3cf8":"from sklearn.tree import DecisionTreeClassifier\nmodel= DecisionTreeClassifier(criterion='gini',min_samples_split=10,min_samples_leaf=1,max_features='auto')\nmodel.fit(X_train,y_train)\nprediction_tree=model.predict_proba(X_test)[:,1]\nroc_auc_score(y_test,prediction_tree)","95344ba6":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score #score evaluation\nfrom sklearn.model_selection import cross_val_predict #prediction\n\nmodel = Pipeline(steps=[\n    ('imputer',SimpleImputer(strategy='median')),\n    ('scaler',StandardScaler()),\n\n    ('classifier',RandomForestClassifier())\n])\nmodel.fit(X_train,y_train)\nprediction_rm=model.predict_proba(X_test)[:,1]\nroc_auc_score(y_test,prediction_rm)\nprint('The accuracy of the Random Forest Classifier is',round(roc_auc_score(y_test,prediction_rm)*100,2),\"%\")","02366332":"model.get_params().keys()","93304b7c":"parameters={\n    'classifier__n_estimators':[700],\n    'classifier__bootstrap':[True],\n    'classifier__max_depth':range(1,7),\n    'classifier__max_features':['sqrt'],\n    'classifier__min_samples_split':[5],\n    'classifier__min_samples_leaf':[4]\n}","8a2561ed":"#gridsearch.best_params_","c3204fc2":"from sklearn.model_selection import GridSearchCV\ngridsearch=GridSearchCV(model,parameters,cv=4)","c5b2b770":"gridsearch.fit(X_train,y_train)","c59428fc":"test_df=pd.read_csv('\/kaggle\/input\/iba-ml1-mid-project\/test.csv')\ntest_df.head()","6802693b":"#Filling Age\nimputer=SimpleImputer(strategy='median')\nimputer.fit_transform(test_df[['age']])\ntest_df[['age']]=imputer.fit_transform(test_df[['age']])\n\n#Filling number_dependent_family_members\nimputer=SimpleImputer(strategy='median')\nimputer.fit_transform(test_df[['number_dependent_family_members']])\ntest_df[['number_dependent_family_members']]=imputer.fit_transform(test_df[['number_dependent_family_members']])\n\n#Filling monthly_income\nimputer=SimpleImputer(strategy='median')\nimputer.fit_transform(test_df[['monthly_income']])\ntest_df[['monthly_income']]=imputer.fit_transform(test_df[['monthly_income']])\n\n#Filling number_of_credit_lines\nimputer=SimpleImputer(strategy='median')\nimputer.fit_transform(test_df[['number_of_credit_lines']])\ntest_df[['number_of_credit_lines']]=imputer.fit_transform(test_df[['number_of_credit_lines']])\n\n#Filling real_estate_loans\nimputer=SimpleImputer(strategy='median')\nimputer.fit_transform(test_df[['real_estate_loans']])\ntest_df[['real_estate_loans']]=imputer.fit_transform(test_df[['real_estate_loans']])\n\n#Filling ratio_debt_payment_to_income\nimputer=SimpleImputer(strategy='median')\nimputer.fit_transform(test_df[['ratio_debt_payment_to_income']])\ntest_df[['ratio_debt_payment_to_income']]=imputer.fit_transform(test_df[['ratio_debt_payment_to_income']])\n\n#Filling credit_line_utilization\n#But we need to convert datatype of column to float, cuz datas are numeric but they are in string datatype\ntest_df['credit_line_utilization'] = pd.to_numeric(test_df['credit_line_utilization'],errors='coerce')\nimputer=SimpleImputer(strategy='median')\nimputer.fit_transform(test_df[['credit_line_utilization']])\ntest_df[['credit_line_utilization']]=imputer.fit_transform(test_df[['credit_line_utilization']])\n\n#Filling number_of_previous_late_payments_up_to_59_days\nimputer=SimpleImputer(strategy='median')\nimputer.fit_transform(test_df[['number_of_previous_late_payments_up_to_59_days']])\ntest_df[['number_of_previous_late_payments_up_to_59_days']]=imputer.fit_transform(test_df[['number_of_previous_late_payments_up_to_59_days']])\n\n#Filling number_of_previous_late_payments_up_to_89_days\nimputer=SimpleImputer(strategy='median')\nimputer.fit_transform(test_df[['number_of_previous_late_payments_up_to_89_days']])\ntest_df[['number_of_previous_late_payments_up_to_89_days']]=imputer.fit_transform(test_df[['number_of_previous_late_payments_up_to_89_days']])\n\n#Filling number_of_previous_late_payments_90_days_or_more\nimputer=SimpleImputer(strategy='median')\nimputer.fit_transform(test_df[['number_of_previous_late_payments_90_days_or_more']])\ntest_df[['number_of_previous_late_payments_90_days_or_more']]=imputer.fit_transform(test_df[['number_of_previous_late_payments_90_days_or_more']])","b843fdd0":"test_df.isnull().sum()","c9129ec4":"from sklearn.model_selection import GridSearchCV\n\npredictions=gridsearch.predict_proba(test_df)[:,1]\npredictions","4e740e0d":"ids=test_df['Id']\noutput=pd.DataFrame({'Id':ids,'predicted':predictions})\noutput","8b8c49e4":"output.to_csv('submission.csv',index=False)","a4617381":"After Logisctic Regression we got ~64% It is also not good enough for predicting our data","f3c6206e":"I tried Decision tree model and changed some defaults but it didn't give good result, and even our prediction result decreased. So I will try Random forest now","23ad5744":"After running knn model, we got accuracy of our prediction ~52% and it is not a good result, soo we need to improve our model or change it","91528d1b":"# KNN Classifier","f72f61ed":"We see there are lots of missing values in all dataframes, except ID and defaulted_on_loan, so firstly need to fill all missing values before modeling:","d7198c0d":"I will insert our train data for  modelling","48737c10":"Now let's import our gridsearch model to our code, and strengthen our Random Forest model with the help of it, but before  we need to define parameters and best values of them to  get good prediction result. Let's check!","0cf221cc":"After imputation there is no missing value in our train data","413ce129":"Yes we see some improvements in our percentage already it increased 20% and still we need improvement cuz it is not enough","d96b9d54":"And for getting desirable result I created ids variable to assign all IDs and our predictions is goingg to predictions variable","5dbb522d":"Now time to work on our test data frame, to check our model. Firstly we import data then imputing all missing values, and check our new model gridsearch","0e30c799":"Yeeey! Finally we get somehow good result, it is good news. But we can modify & strengthen our model. Yes it is model which I was searching","018ad514":"Above code you see we splitted our train_data to train test parts for modelling, we will try several modellings and then choose one of it for final result","43029ff1":"# Decision Tree","0e749520":"# Random Forest","203722a5":"# Gaussian Naive Bayes","56419143":"# Logistic Regression","ff875266":"# **Filling missing Values with Imputation method**"}}