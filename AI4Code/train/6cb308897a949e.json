{"cell_type":{"f1ed96ee":"code","65ae96d4":"code","23a24a61":"code","2dd3023a":"code","23036425":"code","230edb8e":"code","4adec6b1":"code","046c6142":"code","2316f833":"code","14559e1f":"code","507ebf7e":"code","af34b0eb":"code","f4854061":"code","8207ad18":"code","43a36888":"code","75868607":"code","6b668518":"code","83d61919":"code","979f2486":"code","f6cc65c6":"code","aafee4c1":"code","d6275920":"code","02147f9f":"code","6aa0daac":"code","1856af94":"code","6dbd97ef":"code","b82d23ec":"code","acf1b66c":"code","3a7cce5c":"code","e3ff2e73":"code","f3b5a641":"code","bff05bed":"code","5fa42481":"code","58f1e127":"code","7f965e2c":"code","fe404ce1":"code","639b3339":"code","3f0f5c9f":"code","61504002":"markdown","2d495321":"markdown","cae61c77":"markdown","35e720ce":"markdown","db667dce":"markdown","789c4466":"markdown","69805c2a":"markdown"},"source":{"f1ed96ee":"import numpy as np \nimport pandas as pd \nfrom glob import glob\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport os\nimport sklearn\nimport tensorflow as tf\nfrom tensorflow import keras","65ae96d4":"import matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.layers import Input\nimport matplotlib\nimport matplotlib.pylab as plt\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Model, Sequential\nfrom keras.layers import Dense, Dropout, BatchNormalization, Flatten, Input\nfrom keras.layers import Conv2D, Activation, GlobalAveragePooling2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing.image import load_img, img_to_array\nfrom keras.applications.resnet50 import preprocess_input, ResNet50\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.model_selection import train_test_split","23a24a61":"data = pd.read_csv('..\/input\/data\/Data_Entry_2017.csv')\nimage_path = {os.path.basename(x): x for x in \n                   glob(os.path.join('..', 'input\/data\/', 'images*', '*', '*.png'))}\ndata['path'] = data['Image Index'].map(image_path.get)\nprint(data.head(5))","2dd3023a":"# Total number of entries \nprint(len(data))\n# Total number of image_path\nprint(len(image_path))","23036425":"# Top 10 labels in the dataset \ndisease_counts = data.groupby('Finding Labels')['Image Index'].count().sort_values(ascending=False).iloc[:10]\nprint(disease_counts)\n\n# plotting top 10 labels' count\nplt.figure(figsize=(12,8))\nplt.bar(np.arange(len(disease_counts))+0.5, disease_counts, tick_label=disease_counts.index)\nplt.xticks(rotation=90)","230edb8e":"# Create a sort of one hot encoding for each instances labels\n# Remember multiclass multilabel classification\ndata['Finding Labels'] = data['Finding Labels'].map(lambda x: x.replace('No Finding','Nothing'))\n\nfrom itertools import chain\nlabels = np.unique(list(chain(*data['Finding Labels'].map(lambda x: x.split('|')).tolist())))\nprint(labels)","4adec6b1":"for lbl in labels: \n    data[lbl] = data['Finding Labels'].map(lambda find: 1 if lbl in find else 0)\ndata['encoding'] = [[1 if l in lbl.split('|') else 0 for l in labels] for lbl in data['Finding Labels']]\nprint(data[['encoding','Finding Labels']])","046c6142":"class_count = {}\nfor lbl in labels:\n    class_count[lbl] = data[lbl].sum()\n\nclassweight = {}\nfor lbl in labels :\n    classweight[lbl] = 1\/class_count[lbl]\n\nclassweight['Nothing'] \/= 2   #Extra penalising the none class \ndef func(row):\n    weight = 0\n    for lbl in labels: \n        if(row[lbl]==1):\n            weight += classweight[lbl]\n    return weight\nnew_weights = data.apply(func, axis=1)\nsampled_data = data.sample(40000, weights = new_weights)\n    ","2316f833":"sampled_data.to_csv('sampled_data.csv')","14559e1f":"sampled_data = pd.read_csv('\/kaggle\/input\/nihmodelset\/sampled_data.csv')","507ebf7e":"# Top 20 labels in the dataset \ndisease_counts = sampled_data.groupby('Finding Labels')['Image Index'].count().sort_values(ascending=False).iloc[:20]\n\n# plotting top 10 labels' count\nplt.figure(figsize=(12,8))\nplt.bar(np.arange(len(disease_counts))+0.5, disease_counts, tick_label=disease_counts.index)\nplt.xticks(rotation=90)","af34b0eb":"# Getting train and test data\nfrom sklearn.model_selection import train_test_split\ntrain_data , test_data = train_test_split(sampled_data, test_size=0.2)\ntrain_data , valid_data = train_test_split(train_data, test_size=0.25)\nprint(len(train_data))\nprint(len(test_data))\nprint(len(valid_data))","f4854061":"from keras.preprocessing.image import ImageDataGenerator \nIMG_SIZE = (299, 299)\n# core imagedatagenerator used to create train and test imageDatagenerators\ncore_idg = ImageDataGenerator(samplewise_center=True, \n                              samplewise_std_normalization=True, \n                              horizontal_flip = True, \n                              vertical_flip = False, \n                              height_shift_range= 0.05, \n                              width_shift_range=0.1, \n                              rotation_range=5, \n                              shear_range = 0.1,\n                              fill_mode = 'reflect',\n                              zoom_range=0.15)","8207ad18":"# Fix for image datagenerator \n\nvalid_data['newLabel'] = valid_data.apply(lambda x: x['Finding Labels'].split('|'), axis=1)\ntrain_data['newLabel'] = train_data.apply(lambda x: x['Finding Labels'].split('|'), axis=1)\ntest_data['newLabel'] = test_data.apply(lambda x: x['Finding Labels'].split('|'), axis=1)\ntrain_gen = core_idg.flow_from_dataframe(\n    dataframe=train_data,\n    directory=None,\n    x_col = 'path',\n    y_col = 'newLabel',\n    class_mode = 'categorical',\n    target_size = IMG_SIZE,\n    color_mode = 'rgb',\n    batch_size = 32)\n\nvalid_gen = core_idg.flow_from_dataframe(\n    dataframe=valid_data,\n    directory=None,\n    x_col = 'path',\n    y_col = 'newLabel',\n    class_mode = 'categorical',\n    target_size = IMG_SIZE,\n    color_mode = 'rgb',\n    batch_size = 256) # we can use much larger batches for evaluation\n\ntest_X, test_Y = next(core_idg.flow_from_dataframe(\n    dataframe=valid_data,\n    directory=None,\n    x_col = 'path',\n    y_col = 'newLabel',\n    class_mode = 'categorical',\n    target_size = IMG_SIZE,\n    color_mode = 'rgb',\n    batch_size = 1024))","43a36888":"t_x, t_y = next(train_gen)\nfig, m_axs = plt.subplots(4, 4, figsize = (16, 16))\nfor (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n    c_ax.imshow(c_x[:,:,0], cmap = 'bone', vmin = -1.5, vmax = 1.5)\n    c_ax.set_title(', '.join([n_class for n_class, n_score in zip(labels, c_y) \n                             if n_score>0.5]))\n    c_ax.axis('off')","75868607":"# transfer learning on ResNet50\nbase_model = keras.applications.xception.Xception(include_top=False, weights='imagenet')","6b668518":"# completing the model\nn_classes = len(labels)\navg = keras.layers.GlobalAveragePooling2D()(base_model.output)\noutput = keras.layers.Dense(n_classes, activation='sigmoid')(avg)\nmodel = keras.Model(inputs=base_model.inputs, outputs = output)","83d61919":"model.summary()","979f2486":"keras.utils.plot_model(model)","f6cc65c6":"met = ['categorical_accuracy', keras.metrics.Precision(), keras.metrics.AUC(), 'binary_accuracy']","aafee4c1":"# focal loss \nfrom keras import backend as K\ndef focal_loss(alpha=0.5,gamma=2.0):\n    def focal_crossentropy(y_true, y_pred):\n        bce = K.binary_crossentropy(y_true, y_pred)\n        \n        y_pred = K.clip(y_pred, K.epsilon(), 1.- K.epsilon())\n        p_t = (y_true*y_pred) + ((1-y_true)*(1-y_pred))\n        \n        alpha_factor = 1\n        modulating_factor = 1\n\n        alpha_factor = y_true*alpha + ((1-alpha)*(1-y_true))\n        modulating_factor = K.pow((1-p_t), gamma)\n\n        # compute the final loss and return\n        return K.mean(alpha_factor*modulating_factor*bce, axis=-1)\n    return focal_crossentropy","d6275920":"for layer in base_model.layers:\n    layer.trainable = False\nmodel.compile(loss='binary_crossentropy', optimizer=keras.optimizers.SGD(lr=0.2, momentum=0.9, decay=0.01), metrics=met)\nhistory = model.fit_generator(train_gen, steps_per_epoch=100, validation_data=(test_X, test_Y), epochs=1,max_queue_size=100, workers=-1, use_multiprocessing=True)","02147f9f":"model.save('Xception.h5')","6aa0daac":"model = keras.models.load_model('\/kaggle\/input\/nihmodelset\/Xception (2).h5')","1856af94":"for layer in base_model.layers:\n    layer.trainable = True\nmodel.compile(loss='binary_crossentropy', optimizer='nadam', metrics=met)\nhistory = model.fit_generator(train_gen, steps_per_epoch=100, validation_data=(test_X, test_Y), epochs=3,max_queue_size=100, workers=-1, use_multiprocessing=True)","6dbd97ef":"# Plotting the ROC curve\ndef plot_roc():\n    pred_Y =  model.predict(test_X, batch_size = 32)\n    from sklearn.metrics import roc_curve, auc\n    fig, c_ax = plt.subplots(1,1, figsize = (9, 9))\n    for (idx, c_label) in enumerate(labels):\n        fpr, tpr, thresholds = roc_curve(test_Y[:,idx].astype(int), pred_Y[:,idx])\n        c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n    c_ax.legend()\n    c_ax.set_xlabel('False Positive Rate')\n    c_ax.set_ylabel('True Positive Rate')\n    fig.savefig('XceptionRoc.png')\n\nplot_roc();","b82d23ec":"model.summary()\nprint(model.layers[-1].name)\nprint(model.layers[-2].name)","acf1b66c":"properties = {\n    \"vgg16\": {\n        \"img_size\": (224, 224),\n        \"last_conv_layer\": \"block5_conv3\",\n        \"last_classifier_layers\": [\n            \"block5_pool\",\n            \"flatten\",\n            \"fc1\",\n            \"fc2\",\n            \"predictions\",\n        ],\n        \"model_builder\": keras.applications.vgg16.VGG16,\n        \"preprocess_input\": keras.applications.vgg16.preprocess_input,\n        \"decode_predictions\": keras.applications.vgg16.decode_predictions,\n    },\n    \"xception\": {\n        \"img_size\": (299, 299),\n        \"last_conv_layer\": \"block14_sepconv2_act\",\n        \"last_classifier_layers\": [\n            \"global_average_pooling2d\",\n            \"dense\",\n        ],\n        \"model_builder\": keras.applications.xception.Xception,\n        \"preprocess_input\": keras.applications.xception.preprocess_input,\n        \"decode_predictions\": keras.applications.xception.decode_predictions,\n        \n    }\n}","3a7cce5c":"NETWORK = \"xception\"\nIMG_PATH = sampled_data['path'][1]\nIMG_SIZE = properties[NETWORK][\"img_size\"]\nLAST_CONV_LAYER = properties[NETWORK][\"last_conv_layer\"]\nCLASSIFIER_LAYER_NAMES = properties[NETWORK][\"last_classifier_layers\"]\nTOP_N = 15","e3ff2e73":"print(IMG_PATH)\nprint(sampled_data['Finding Labels'][1])\nprint(labels)","f3b5a641":"model_builder = properties[NETWORK][\"model_builder\"]\npreprocess_input = properties[NETWORK][\"preprocess_input\"]\ndecode_predictions = properties[NETWORK][\"decode_predictions\"]","bff05bed":"def get_img_array(img_path=IMG_PATH, size=IMG_SIZE):\n    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n    array = keras.preprocessing.image.img_to_array(img)\n    array = np.expand_dims(array, axis=0)\n    return array","5fa42481":"DICT_BY_NAME = {}\nfor i in range(len(labels)):\n    DICT_BY_NAME[labels[i]] = i;\nCLASS_DICT = {}\nfor i in range(len(labels)):\n    CLASS_DICT[i] = labels[i]\nprint(DICT_BY_NAME)\nprint(CLASS_DICT)","58f1e127":"def get_top_predicted_indices(predictions, top_n):\n    return np.argsort(-predictions).squeeze()[:top_n]\n\ndef make_gradcam_heatmap(img_array, model,last_conv_layer_name,\n                         classifier_layer_names,top_n,class_indices):\n#     Create a model that maps the input image to the activations of the last convolution layer \n    img_array = preprocess_input(img_array)\n    last_conv_layer = model.get_layer(last_conv_layer_name)\n    last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)\n#     Create another model that maps from last convolution layer to final class predictions\n    \n    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n    x = classifier_input\n    for layer_name in classifier_layer_names:\n        x = model.get_layer(layer_name)(x)\n    classifier_model = keras.Model(inputs=classifier_input, outputs=x)\n    \n    \n    if(top_n > 0):\n        last_conv_layer_output = last_conv_layer_model(img_array)\n        preds = classifier_model(last_conv_layer_output)\n        class_indices = get_top_predicted_indices(preds, top_n)\n    else:\n        top_n = len(class_indices)\n        \n    heatmaps = []\n    for index in np.arange(top_n):\n        with tf.GradientTape() as tape:\n            last_conv_layer_output = last_conv_layer_model(img_array)\n#             print(last_conv_layer_output)\n            tape.watch(last_conv_layer_output)\n            preds = classifier_model(last_conv_layer_output)\n#             print(preds)\n            class_channel = preds[:, class_indices[index]]\n            \n            \n        grads = tape.gradient(\n            class_channel,\n            last_conv_layer_output\n        )\n#         print(np.sum(grads))\n        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))    \n        last_conv_layer_output = last_conv_layer_output.numpy()[0]\n        pooled_grads = pooled_grads.numpy()\n        for i in range(pooled_grads.shape[-1]):\n            last_conv_layer_output[:, :, i] *= pooled_grads[i]\n        heatmap = np.mean(last_conv_layer_output, axis=-1)\n        heatmap = np.maximum(heatmap, 0) \/ (np.max(heatmap)+float(1e-7))\n        heatmaps.append({\n            \"class_id\": class_indices[index],\n            \"heatmap\": heatmap\n        })\n    return heatmaps\n    ","7f965e2c":"class_indices = np.arange(15)","fe404ce1":"heatmaps = make_gradcam_heatmap(\n    get_img_array(), \n    model, \n    LAST_CONV_LAYER, \n    CLASSIFIER_LAYER_NAMES, \n    0, \n    class_indices\n)","639b3339":"import cv2\ndef superimpose_heatmap(image_path, heatmap):\n    img = keras.preprocessing.image.load_img(image_path)\n    img = keras.preprocessing.image.img_to_array(img)\n    \n    # We rescale heatmap to a range 0-255\n    heatmap = np.uint8(255 * heatmap)\n    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n    heatmap = keras.preprocessing.image.array_to_img(heatmap)\n    heatmap = heatmap.resize((img.shape[1], img.shape[0]))\n    \n    heatmap = keras.preprocessing.image.img_to_array(heatmap)\n    superimposed_img = cv2.addWeighted(heatmap, 0.4, img, 0.6, 0)\n    superimposed_img = np.uint8(superimposed_img)\n    \n    return superimposed_img","3f0f5c9f":"def display_superimposed_heatmaps(heatmaps, image_path, image_id):\n    n = len(heatmaps)\n    n_rows = (n \/\/ 3) + 1 if n % 3 > 0 else n \/\/ 3\n    plt.rcParams['axes.grid'] = False\n    plt.rcParams['xtick.labelsize'] = False\n    plt.rcParams['ytick.labelsize'] = False\n    plt.rcParams['xtick.top'] = False\n    plt.rcParams['xtick.bottom'] = False\n    plt.rcParams['ytick.left'] = False\n    plt.rcParams['ytick.right'] = False\n    plt.rcParams['figure.figsize'] = [30, 15]\n    for index in np.arange(n):\n        heatmap = heatmaps[index][\"heatmap\"]\n        class_id = heatmaps[index][\"class_id\"]\n#         class_name = CLASS_DICT[str(class_id)].split(\",\")[0].capitalize()\n        superimposed_image = superimpose_heatmap(image_path, heatmap)\n        plt.subplot(n_rows, 3, index+1)\n        plt.title(f\"{class_id}\", fontsize= 30)\n        plt.imshow(superimposed_image)\n        \n    plt.show()\ndisplay_superimposed_heatmaps(heatmaps, IMG_PATH, 1)","61504002":"> ### Conclusion the dataset is highly biased towards no finding so if even if we predict every time \"No finding\" then we still have high accuracy\n### We are dealing with multilabel multiclass classification\n\n### Ideas\n1. Can we create multiple instances for multilabel instances ? \n2. Total classes = 15 (14 diseases and one No Finding)  \n3. Is there superimposition of diseases like if we have A disease and B disease can our X ray show both of them, or one can influence or hide the other or their combination lead to a new xray image not similar to either of them.\n4. Two view positions are there AP and PA. Need a biology student to tell the difference\n5. Will we be using features like age or patient gender to predict the diseases ? or just image ?","2d495321":"# Creating ImageDataGenerators","cae61c77":"# Training Begins","35e720ce":"### Significant improvement in the dataset by removing a lot of biasness from the data,","db667dce":"### First some preprocessing of labels and features is required. ","789c4466":"# Transfer learning on ResNet50","69805c2a":"## Strategy is to train the model with freezing the layers for a few epochs "}}