{"cell_type":{"ac7afb1e":"code","f5482338":"code","22713f28":"code","1d0c0aa3":"code","3b241aa3":"code","3527e23c":"code","c2034b2f":"code","346edf06":"code","48f12741":"code","2793a5bf":"code","773adbd1":"code","d47a0cee":"code","83e36201":"code","1007d911":"code","97608dfc":"code","af3138e6":"code","be3e3cde":"code","d09e883f":"code","fc83284b":"code","6c8c3481":"code","199477a7":"code","44300469":"code","4f197cae":"code","02321601":"code","c38af81a":"code","e9698de0":"code","b57b1827":"code","38d564e7":"code","bf718693":"code","11adc865":"code","58e106da":"code","401a4ffd":"code","027bc9dc":"code","d3717d93":"code","4832fde7":"code","98b2b504":"code","4f9e0bd6":"code","f9fb5f23":"code","5421b8cc":"code","2a66df0b":"code","c3a0aee1":"code","1e3a61d3":"code","9f599187":"code","e4d182e9":"code","29911e40":"code","4cfc1f4f":"code","eb4dfcb2":"code","85d47023":"code","503597aa":"code","4bafec4f":"code","a2cc18e9":"code","70e38485":"code","193ce330":"code","e9bb0b28":"markdown","f4b3c622":"markdown"},"source":{"ac7afb1e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f5482338":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")    #reading the train in data\ntrain_data.head()   #see the top 5 data","22713f28":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")   #reading the test data\ntest_data.head()   #viewing first 5 data records","1d0c0aa3":"train_data.info()   #viewing the information of train data attributes","3b241aa3":"test_data.info()   #viewing the information of test data attributes","3527e23c":"train_data.describe()   #checking train data's description(min,mean,etc.)","c2034b2f":"# Target variable statistics\ntrain_data['Survived'].value_counts()","346edf06":"train_data['Survived'].value_counts(normalize=True)","48f12741":"train_data['Sex'].value_counts()","2793a5bf":"# Encoding categorical features\nembrak=pd.get_dummies(train_data['Embarked'])","773adbd1":"gender=pd.get_dummies(train_data['Sex'])","d47a0cee":"# Age gaps are filled with an average of 30\ntrain_data['Age'].fillna(30,inplace=True)\ntrain_data['Age']=train_data['Age'].astype('int')","83e36201":"# Age divided into 6 categories\ndef age_grp(age):\n    if age<13:\n        return '<13'\n    elif (age>=13) &(age<18):\n        return '13-18'\n    elif (age>=18) &(age<=24):\n        return '18-24'\n    elif (age>=25) &(age<=34):\n        return '25-34'\n    elif (age>=35) &(age<=44):\n        return '35-44'\n    else:\n        return '45+'","1007d911":"train_data['Age_grp']=train_data['Age'].apply(lambda x: age_grp(x))","97608dfc":"age=pd.get_dummies(train_data['Age_grp'])","af3138e6":"train_df=pd.concat([train_data,embrak,gender,age],axis=1)\ntrain_df.columns","be3e3cde":"def is_var(val):\n    if val>0:\n        return 1\n    else:\n        return 0","d09e883f":"train_df['Family']=train_df['Parch'] + 1 + train_df['SibSp']\ntrain_df['Parch']=train_df['Parch'].apply(lambda x: is_var(x))\ntrain_df['SibSp']=train_df['SibSp'].apply(lambda x: is_var(x))","fc83284b":"sel_cols=['Fare',\n         'Pclass', 'SibSp',\n            'Parch', 'C', 'Q',\n             'S', 'female', 'male', '18-24', '25-34', '35-44', '45+', '<13', '13-18', 'Family'\n]","6c8c3481":"train_df.fillna(0,inplace=True)","199477a7":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","44300469":"X=train_df[sel_cols]","4f197cae":"y=train_df['Survived']","02321601":"train_X,val_X,train_y,val_y=train_test_split(X,y,test_size=0.3,random_state=1)","c38af81a":"lr=LogisticRegression(max_iter=400)\nlr.fit(train_X,train_y)","e9698de0":"lr.score(train_X,train_y)","b57b1827":"lr.score(val_X,val_y)","38d564e7":"test_data.shape","bf718693":"test_data.columns","11adc865":"# Processing is similar to training sample\nembark=pd.get_dummies(test_data['Embarked'])","58e106da":"gender=pd.get_dummies(test_data['Sex'])","401a4ffd":"test_data['Age'].fillna(30,inplace=True)\ntest_data['Age']=test_data['Age'].astype('int')","027bc9dc":"test_data['Age_grp']=test_data['Age'].apply(lambda x: age_grp(x))","d3717d93":"age=pd.get_dummies(test_data['Age_grp'])","4832fde7":"test_df=pd.concat([test_data,embark,gender,age],axis=1)","98b2b504":"test_df['Family']=test_df['Parch']+ 1 + test_df['SibSp']\ntest_df['Parch']=test_df['Parch'].apply(lambda x: is_var(x))\ntest_df['SibSp']=test_df['SibSp'].apply(lambda x: is_var(x))","4f9e0bd6":"test_df.fillna(0,inplace=True)","f9fb5f23":"test_X=test_df[sel_cols]","5421b8cc":"test_X.columns","2a66df0b":"test_y=lr.predict(test_X)","c3a0aee1":"sub=pd.read_csv(\"\/kaggle\/input\/titanic\/gender_submission.csv\")","1e3a61d3":"sub['Survived']=test_y","9f599187":"sub.head()","e4d182e9":"sub.to_csv('submission.csv', index=False)","29911e40":"women = train_data.loc[train_data.Sex == 'female'][\"Survived\"]   #calculating the precent of women who survived\n\nrate_women = sum(women)\/len(women)\n\nprint(\"% of women who survived:\", rate_women)","4cfc1f4f":"men = train_data.loc[train_data.Sex == 'male'][\"Survived\"]   #calculating the precent of men who survived\n\nrate_men = sum(men)\/len(men)\n\nprint(\"% of men who survived:\", rate_men)","eb4dfcb2":"import seaborn as sns\nsns.barplot(x=\"Sex\", y=\"Survived\", data=train_data)   #using barplot to visualize data","85d47023":"sns.barplot(x=\"Pclass\", y=\"Survived\", data=train_data)   #using barplot to visualize data","503597aa":"sns.barplot(x=\"SibSp\", y=\"Survived\", data=train_data)   #using barplot to visualize data","4bafec4f":"sns.barplot(x=\"Parch\", y=\"Survived\", data=train_data)   #using barplot to visualize data","a2cc18e9":"sns.histplot(x=\"Survived\", y=\"Age\", data=train_data)   #using histplot to visualize data","70e38485":"sns.barplot(x=\"Survived\", y=\"Age\", data=train_data)   #using histplot to visualize data","193ce330":"from sklearn.ensemble import RandomForestClassifier\n\n\ny = train_data[\"Survived\"]\n\ntrain_data[\"Age\"].fillna(value=train_data['Age'].mean(), inplace=True)   #Replacing missing values with mean(contrinution)\ntest_data['Age'].fillna(value=test_data['Age'].mean(), inplace=True)   #Replacing missing values with mean(contrinution)\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]   #changing the features we were considering(contribution)\nX = pd.get_dummies(train_data[features])   #converting catogorical data to indicator values\nX_test = pd.get_dummies(test_data[features])   #converting catogorical data to indicator values\n\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)   #creating the model\nmodel.fit(X, y)   #training the model\npredictions = model.predict(X_test)   #predicting the test data\n\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived' : predictions})\noutput.to_csv('submission.csv', index=False)   # creating output csv file after prediction\n\nprint(\"Your submission was successfully saved!\")","e9bb0b28":"**Test data prediction**","f4b3c622":"**Creating a file to send to Kaggle**"}}