{"cell_type":{"e5598687":"code","4e115849":"code","1f178854":"code","5224fa14":"code","5ad354f4":"code","0369eb0a":"code","283860ea":"code","a1af45aa":"code","378ceb99":"code","cd782c66":"code","062f8007":"code","1cecb3aa":"code","1a48026a":"code","a9ea7fb5":"code","2fe50882":"code","161ea0be":"code","f7e09460":"code","34174718":"code","8b454e9b":"code","b779e0ad":"code","eff5eaa7":"code","12edff7e":"code","e8406ddb":"code","c0e58f4b":"code","20edc3ee":"code","da0962e6":"code","49339719":"code","080fa6cd":"code","b67487bf":"code","f2addc57":"code","b05e1bf1":"code","bf0d2d8f":"code","33656adb":"code","c7577bfa":"code","09e4019c":"code","3771bea9":"code","2a6520da":"code","3b0ad863":"code","249ae131":"code","2fa1ce1c":"code","b5d375f0":"code","fa404741":"code","17855c9b":"code","a7bf9cec":"code","f92507a0":"code","beee254a":"code","3f465a19":"code","28f703fc":"code","31a18373":"code","bb3f4257":"code","df061510":"code","43be6aee":"code","3b1a5971":"code","db3dc6be":"code","6ffeb504":"code","9329d977":"code","3cda7b67":"code","13487feb":"code","156783da":"code","fbbda990":"code","984807eb":"code","3049cc18":"code","1ac0fee5":"code","f97e3b12":"code","55473c8a":"code","832eaf92":"code","e2de9330":"code","b23ecf59":"code","37f1c018":"code","f7abb1c5":"code","85056937":"code","859e3a4e":"markdown","17c345f1":"markdown","49d94a48":"markdown","5994786c":"markdown","047897f7":"markdown","c44c2b5d":"markdown","0e48be32":"markdown","3bf7551b":"markdown"},"source":{"e5598687":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport sklearn\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4e115849":"# Import the packages that we will be using\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport geopandas as gpd\nimport optuna\nimport xgboost as xgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split","1f178854":"# # Set columns to most suitable type to optimize for memory usage\n# traintypes = {'fare_amount': 'float32',\n#               'pickup_datetime': 'str', \n#               'pickup_longitude': 'float32',\n#               'pickup_latitude': 'float32',\n#               'dropoff_longitude': 'float32',\n#               'dropoff_latitude': 'float32',\n#               'passenger_count': 'uint8'}","5224fa14":"train = pd.read_csv(\"\/kaggle\/input\/new-york-city-taxi-fare-prediction\/train.csv\", nrows = 10000000)\ntest = pd.read_csv(\"\/kaggle\/input\/new-york-city-taxi-fare-prediction\/test.csv\")","5ad354f4":"train.shape","0369eb0a":"test.shape","283860ea":"train.head(10)","a1af45aa":"train.describe()","378ceb99":"#check for missing values in train data\ntrain.isnull().sum().sort_values(ascending=False)","cd782c66":"#check for missing values in test data\ntest.isnull().sum().sort_values(ascending=False)","062f8007":"#drop the missing values\ntrain = train.drop(train[train.isnull().any(1)].index, axis = 0)","1cecb3aa":"train.shape","1a48026a":"#check the target column\ntrain['fare_amount'].describe()","a9ea7fb5":"#38 fields have negative fare_amount values.\nfrom collections import Counter\nCounter(train['fare_amount']<0)","2fe50882":"#drop the negative fare_amount values.\ntrain = train.drop(train[train['fare_amount']<0].index, axis=0)\ntrain.shape","161ea0be":"#no more negative values in the fare field\ntrain['fare_amount'].describe()","f7e09460":"train.columns","34174718":"test.columns","8b454e9b":"train.dtypes","b779e0ad":"train['passenger_count'].describe()","eff5eaa7":"# 208\u4eba\u306epassenger_count\u304c\u3042\u308b\u3002drop\u3059\u308b\ntrain[train['passenger_count']>6]","12edff7e":"# If there is more than 6 passengers, also drop the observation\ntrain = train[train[\"passenger_count\"] <= 6]","e8406ddb":"train['passenger_count'].describe()","c0e58f4b":"#Next, let us explore the pickup latitude and longitudes\ntrain['pickup_latitude'].describe()","20edc3ee":"train[train['pickup_latitude']<-90]","da0962e6":"train[train['pickup_latitude']>90]","49339719":"#We need to drop these outliers\ntrain = train.drop(train[train['pickup_latitude']<-90].index, axis=0)\ntrain = train.drop(train[train['pickup_latitude']>90].index, axis=0)","080fa6cd":"train.shape","b67487bf":"#similar operation for pickup longitude\ntrain['pickup_longitude'].describe()","f2addc57":"train[train['pickup_longitude']<-180]","b05e1bf1":"train[train['pickup_longitude']>180]","bf0d2d8f":"train = train.drop(train[train['pickup_longitude']<-180].index, axis=0)\ntrain = train.drop(train[train['pickup_longitude']>180].index, axis=0)","33656adb":"train.shape","c7577bfa":"#similar operation for dropoff latitude and longitude\ntrain[train['dropoff_latitude']<-90]","09e4019c":"train[train['dropoff_latitude']>90]","3771bea9":"train = train.drop(train[train['dropoff_latitude']<-90].index, axis=0)\ntrain = train.drop(train[train['dropoff_latitude']>90].index, axis=0)","2a6520da":"train.shape","3b0ad863":"train[train['dropoff_latitude']<-180]|train[train['dropoff_latitude']>180]","249ae131":"# Drop any records that have zero longitude\/latitude, or long\/lats that are outside bounds. Rembmer our longitude for NYC is always negative.\n# This is going to be a rough chop, there is a significant amount of outliers to discuss\ntrain = train[(train[\"pickup_longitude\"] < -70) & (train[\"pickup_longitude\"] > -83)]\ntrain = train[(train[\"pickup_latitude\"] > 36) & (train[\"pickup_latitude\"] < 46 )]\ntrain = train[(train[\"dropoff_longitude\"] < -70) & (train[\"dropoff_longitude\"] > -83)]\ntrain = train[(train[\"dropoff_latitude\"] > 36) & (train[\"dropoff_latitude\"] < 46 )]","2fa1ce1c":"# Confirm that all our longitude and latitude values now fall within acceptable bounds\ntrain.describe()","b5d375f0":"# See the new shape of our data after dropping the outlier coordinates\nprint(\"Train data shape: \", train.shape)","fa404741":"# key and pickup_datetime seem to be datetime columns which are in object format.\n# Let's convert them to datetime\ntrain['key'] = pd.to_datetime(train['key'])\ntrain['pickup_datetime']  = pd.to_datetime(train['pickup_datetime'])","17855c9b":"#Convert for test data\ntest['key'] = pd.to_datetime(test['key'])\ntest['pickup_datetime']  = pd.to_datetime(test['pickup_datetime'])","a7bf9cec":"data = [train,test]\nfor i in data:\n    i['Year'] = i['pickup_datetime'].dt.year\n    i['Month'] = i['pickup_datetime'].dt.month\n    i['Date'] = i['pickup_datetime'].dt.day\n    i['Day of Week'] = i['pickup_datetime'].dt.dayofweek\n    i['Hour'] = i['pickup_datetime'].dt.hour","f92507a0":"# I don't include the pickup_datetime columns \n# because datetime columns cannot be used directly for modeling.\n# Features need to extracted from the timestamp fields\n# which will later be used as features for modelling.\ntrain = train.drop(['key','pickup_datetime'], axis = 1)\ntest = test.drop(['key','pickup_datetime'], axis = 1)","beee254a":"#check the dtypes after conversion\ntrain.dtypes","3f465a19":"test.dtypes","28f703fc":"#check the data\ntrain.head()","31a18373":"test.head()","bb3f4257":"def haversine_distance(lat1, long1, lat2, long2):\n    data = [train, test]\n    for i in data:\n        R = 6371  #radius of earth in kilometers\n        #R = 3959 #radius of earth in miles\n        phi1 = np.radians(i[lat1])\n        phi2 = np.radians(i[lat2])\n    \n        delta_phi = np.radians(i[lat2]-i[lat1])\n        delta_lambda = np.radians(i[long2]-i[long1])\n    \n        #a = sin\u00b2((\u03c6B - \u03c6A)\/2) + cos \u03c6A . cos \u03c6B . sin\u00b2((\u03bbB - \u03bbA)\/2)\n        a = np.sin(delta_phi \/ 2.0) ** 2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda \/ 2.0) ** 2\n    \n        #c = 2 * atan2( \u221aa, \u221a(1\u2212a) )\n        c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n    \n        #d = R*c\n        d = (R * c) #in kilometers\n        i['H_Distance'] = d\n    return d","df061510":"haversine_distance('pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude')","43be6aee":"train['H_Distance'].head(10)","3b1a5971":"test['H_Distance'].head(10)","db3dc6be":"train.head(10)","6ffeb504":"test.head(10)","9329d977":"# x_train <- train\u306efare_amount(\u76ee\u7684\u5909\u6570)\u4ee5\u5916\u306e\u3059\u3079\u3066\u306e\u884c\n# y_train <- train\u306efare_amount(\u76ee\u7684\u5909\u6570)\u884c\nx_train = train.iloc[:,train.columns!='fare_amount']\ny_train = train['fare_amount'].values\nx_test = test","3cda7b67":"x_train.shape","13487feb":"x_train.columns","156783da":"y_train.shape","fbbda990":"x_test.shape","984807eb":"x_test.columns","3049cc18":"import lightgbm as lgbm","1ac0fee5":"# train\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e3\u5272\u3092\u30e2\u30c7\u30eb\u5b66\u7fd2\u6642\u306e\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u30c7\u30fc\u30bf\u3068\u3057\u3066\u5229\u7528\u3059\u308b\nx_train, x_valid, y_train, y_valid = train_test_split(x_train,\n                                                    y_train,\n                                                    test_size=0.3,\n                                                    random_state=10)\n\n# LightGBM\u3092\u5229\u7528\u3059\u308b\u306e\u306b\u5fc5\u8981\u306a\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u306b\u5909\u63db\nlgb_train = lgbm.Dataset(x_train, y_train)\nlgb_eval = lgbm.Dataset(x_valid, y_valid, reference=lgb_train)","f97e3b12":"params = {\n    'boosting_type': 'gbdt',\n    'objective': 'regression',\n    'nthread': -1,\n    'verbose': 0,\n    'num_leaves': 256,\n    'learning_rate': 0.05,\n    'max_depth': -1,\n    'reg_aplha': 1,\n    'metric': 'rmse',\n    'scale_pos_weight': 1,\n    'min_child_samples': 20\n}","55473c8a":"pred_test_y = np.zeros(x_test.shape[0])\npred_test_y.shape","832eaf92":"train_set = lgbm.Dataset(x_train, y_train, silent=True)\ntrain_set","e2de9330":"model = lgbm.train(params, train_set = train_set, num_boost_round=300)","b23ecf59":"print(model)","37f1c018":"pred_test_y = model.predict(x_test, num_iteration = model.best_iteration)","f7abb1c5":"print(pred_test_y)","85056937":"submission = pd.read_csv('\/kaggle\/input\/new-york-city-taxi-fare-prediction\/sample_submission.csv')\nsubmission['fare_amount'] = pred_test_y\nsubmission.to_csv('submission_LGB.csv', index=False)\nsubmission.head(20)","859e3a4e":"lightgbm\u3092\u5229\u7528\u3057\u3066\u63a8\u5b9a\n","17c345f1":"Next check the passenger_count variable","49d94a48":"create columns for the following -\n* year\n* month\n* date\n* hour\n* day of week","5994786c":"\u7def\u5ea6\u306f-90\u304b\u308990\u307e\u3067\u3002\n\u7d4c\u5ea6\u306f-180\u304b\u3089180\u307e\u3067\u3002\n\u7570\u5e38\u5024\u3092\u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0\u3059\u308b\u3002","047897f7":"\u7def\u5ea6\u3068\u7d4c\u5ea6\u304c\u4e0e\u3048\u3089\u308c\u3066\u3044\u308b\u3068\u304d\u3001\u7403\u9762\u5185\u306e\u8ddd\u96e2\u306fHaversine\u306e\u5f0f\u3067\u8a08\u7b97\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3002\n\nhaversine(\u03b8) = sin\u00b2(\u03b8\/2)\n\n\u7d50\u5c40\u3001\u03c6\u306f\u7def\u5ea6\u3001\u03bb\u306f\u7d4c\u5ea6\u3001R\u306f\u5730\u7403\u306e\u534a\u5f84\uff08\u5e73\u5747\u534a\u5f84\uff1d6,371km\uff09\u3067\u3001\u7def\u5ea6\u3068\u7d4c\u5ea6\u306e\u5ea7\u6a19\uff08\u3053\u3053\u3067\u306fA\u3001B\uff09\u3092\u542b\u3081\u308b\u3068\u3001\u4ee5\u4e0b\u306e\u5f62\u5f0f\u306b\u843d\u3061\u7740\u304f\u3002\n\na = sin\u00b2((\u03c6B - \u03c6A)\/2) + cos \u03c6A . cos \u03c6B . sin\u00b2((\u03bbB - \u03bbA)\/2)\n\nc = 2 * atan2( \u221aa, \u221a(1\u2212a) )\n\nd = R \u22c5 c\n\nd = Haversine distance","c44c2b5d":"key \u3068 pickup_datetime \u3092\u65e5\u4ed8\u578b\u306b\u5909\u63db\u3059\u308b","0e48be32":"herversine distance\u306e\u8a08\u7b97\u3068\u30bb\u30eb\u4f5c\u6210","3bf7551b":"\u30cb\u30e5\u30fc\u30e8\u30fc\u30af\u5e02\u5916\u306e\u7def\u5ea6\u3001\u7d4c\u5ea6\u3067\u306e\u30d4\u30c3\u30af\u30a2\u30c3\u30d7\u3068\u30c9\u30ed\u30c3\u30d7\u30aa\u30d5\u3092\u9664\u5916\u3059\u308b"}}