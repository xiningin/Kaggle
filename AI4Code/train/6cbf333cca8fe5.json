{"cell_type":{"77071ade":"code","2eb940e3":"code","878e9ed3":"code","345ec43b":"code","5ba02e2c":"code","e8611444":"code","a9d227e9":"code","27e2b2a1":"code","0f4b4e1a":"code","569833b9":"code","84cb86b9":"code","9256848b":"code","967dd576":"code","87c2d003":"markdown","b05c28c9":"markdown","105643c7":"markdown","5169fd21":"markdown","2dd5d08f":"markdown","72b4433d":"markdown","38823605":"markdown"},"source":{"77071ade":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2eb940e3":"import matplotlib.pyplot as plt\nimport regex as re\nimport sqlite3","878e9ed3":"df=pd.read_csv(\"..\/input\/email-spam-dataset\/Email spam.csv\")\ndf.head()","345ec43b":"print(df.shape)\n\ndf=df.drop_duplicates()\n\nprint(df.shape)","5ba02e2c":"df = df.reset_index(inplace = False)[['text','spam']]\ndf.head()","e8611444":"clean_desc = []\nfor w in range(len(df.text)):\n    desc = df['text'][w].lower()\n    \n    #remove punctuation\n    desc = re.sub('[^a-zA-Z]', ' ', desc)\n    \n    #remove tags\n    desc=re.sub(\"&lt;\/?.*?&gt;\",\" &lt;&gt; \",desc)\n    \n    #remove digits and special chars\n    desc=re.sub(\"(\\\\d|\\\\W)+\",\" \",desc)\n    \n    clean_desc.append(desc)\n#assign the cleaned descriptions to the data frame\ndf['text'] = clean_desc\ndf = df.reset_index()        \ndf.head(3)","a9d227e9":"from sklearn.feature_extraction.text import CountVectorizer\n\ntext_vec=CountVectorizer().fit_transform(df['text'])\ntext_vec","27e2b2a1":"from sklearn.model_selection import train_test_split\n\nxtrain,xtest,ytrain,ytest=train_test_split(text_vec,df['spam'],test_size=0.4,random_state=44,shuffle=True)","0f4b4e1a":"from sklearn import ensemble\n\nclassifier=ensemble.GradientBoostingClassifier(n_estimators=100,learning_rate=0.5,max_depth=6)","569833b9":"classifier.fit(xtrain,ytrain)","84cb86b9":"from sklearn.metrics import accuracy_score\n\nypred=classifier.predict(xtest)\n\nacc=accuracy_score(ypred,ytest)*100\nacc","9256848b":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\nsns.heatmap(confusion_matrix(ypred,ytest),annot=True)","967dd576":"from textblob import TextBlob\n\n#load the descriptions into textblob\nemail_blob = [TextBlob(text) for text in df['text']]\n#add the sentiment metrics to the dataframe\ndf['tb_Pol'] = [b.sentiment.polarity for b in email_blob]\ndf['tb_Subj'] = [b.sentiment.subjectivity for b in email_blob]\n#show dataframe\ndf.head(3)","87c2d003":"# Gradient Boosting classifier","b05c28c9":"# Creating word embedding","105643c7":"**tb_pol indicatin the polarity,tells it is positive if it is >0**","5169fd21":"# Data cleaning","2dd5d08f":"# Sentiment analysis","72b4433d":"### Here the positive class is spam","38823605":"# Train test split"}}