{"cell_type":{"86bf1aeb":"code","64b45269":"code","090a6971":"code","9509da50":"code","c7d151f9":"code","9adba3d7":"code","3c9e9053":"code","57e8feef":"code","b6cf6faa":"code","98106f1e":"code","3682de25":"code","60c366b5":"code","8cd1dbb5":"code","4b8cb31b":"code","77ae6fce":"code","816cd001":"code","6c658203":"code","bc36a44e":"code","499b8e96":"code","d3946416":"code","3126fe7d":"code","4dbcbc24":"code","a01e730d":"code","532b0219":"code","01937fa0":"code","509810b6":"code","43579161":"code","73f1db6d":"code","62b7b4f0":"code","7117562b":"code","571c2e2f":"code","29acb755":"code","cf9d0a2b":"code","adcecf23":"code","a3b74b7e":"code","c5fcc46e":"code","78552ac8":"code","52eb3fbb":"code","4f3f4cac":"code","5b959e35":"code","956c516f":"code","49f1e92c":"code","7daaf0d6":"code","bcf8978c":"code","789bd2df":"code","9a664b2d":"code","15a20ff9":"code","76489e0f":"code","814ac18d":"code","a834d99e":"code","ac8a94e3":"code","ce332ea2":"code","3892fe40":"code","8596bb86":"code","94ffae13":"code","d65901d8":"code","42f4ed02":"code","9689be9d":"code","a74c8013":"code","868e1624":"code","e683371e":"code","1355cff8":"code","0cb9045c":"code","28cc897d":"code","0e614b98":"code","88599431":"code","53ce0065":"code","92f40101":"code","fa37cce0":"code","fb5aea1a":"code","15672be5":"code","46926104":"code","aab764b3":"code","1b275aa6":"code","8570bf7b":"code","85230c46":"code","959895ad":"code","36a57368":"code","fb5159af":"code","0ff98e48":"code","87e7477e":"code","4a4dafb9":"code","68d0a599":"code","8cff46de":"code","19ced595":"code","b7dc8bec":"code","f6f81187":"code","653714a8":"code","133e67b3":"code","0b6d86f9":"code","a75dbf01":"code","f5dbbc16":"code","74e837cc":"code","eb909c03":"code","9cdaae9b":"code","3387d473":"code","f3347020":"code","e1c0ccea":"code","a4c2b7ee":"markdown","ca4df287":"markdown","f790f5af":"markdown","8a1ec089":"markdown","e9b8ce9a":"markdown","6702eb7d":"markdown","9700148e":"markdown","86dc569d":"markdown","690c0201":"markdown","98e559c4":"markdown","02727606":"markdown","7f032205":"markdown","ce6c95dc":"markdown","3b0336c2":"markdown","1648832c":"markdown","d4416839":"markdown","3ce0be5a":"markdown","e55927b6":"markdown","b483e636":"markdown","038ccf53":"markdown","13b230e9":"markdown","f6e505e9":"markdown","bbcf8e1e":"markdown","d14c847b":"markdown","74520ed4":"markdown","af82f137":"markdown","afd90934":"markdown","a90fd7dc":"markdown","dfa11328":"markdown","63bb3d08":"markdown","0148a6b0":"markdown","3e939c42":"markdown","89c4e6b4":"markdown","ac82961a":"markdown","534cffd5":"markdown","5a26aef7":"markdown","ed21c60f":"markdown","fcd8167b":"markdown","d187bfd9":"markdown","130acfb5":"markdown","91dcf6eb":"markdown","8a7f82b7":"markdown","bb1cab5e":"markdown","1a470c52":"markdown","625b270c":"markdown","0055a27b":"markdown","1334453f":"markdown","104649d5":"markdown","aa2b88c4":"markdown","ed245d25":"markdown","f65da43b":"markdown","eff84f29":"markdown"},"source":{"86bf1aeb":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report  \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler  ","64b45269":"file_path = '..\/input\/fish-market\/Fish.csv'\nfish = pd.read_csv(file_path)","090a6971":"fish.head()","9509da50":"fish.shape","c7d151f9":"fish.info()","9adba3d7":"fish.describe()","3c9e9053":"fig, ax = plt.subplots(ncols=6, figsize=(20, 4))\n\nvariables = fish.columns[1:]\nfor i, var in enumerate(variables):\n    sns.histplot(data=fish, x=var, ax=ax[i])\nplt.show()","57e8feef":"fish['Species'].value_counts()","b6cf6faa":"bream = fish[fish['Species'] == 'Bream']\nnum_bream = len(bream)\nprint(\"# of Breams in datasets are\", num_bream)","98106f1e":"bream_weight = bream['Weight'].values\nbream_length = bream['Length2'].values","3682de25":"bream_weight","60c366b5":"bream_length","8cd1dbb5":"smelt = fish[fish['Species'] == 'Smelt']\nnum_smelt = len(smelt)\nprint(\"# of Smelts in datasets are\",num_smelt)","4b8cb31b":"smelt_weight = smelt['Weight']\nsmelt_length = smelt['Length2']","77ae6fce":"smelt_weight","816cd001":"smelt_length","6c658203":"plt.scatter(bream_length, bream_weight, label='Bream')\nplt.scatter(smelt_length, smelt_weight, label='Smelt')\n\nplt.legend()\nplt.xlabel('Length (cm)')\nplt.ylabel('Weight (g)')\nplt.show()\n","bc36a44e":"bream_data = np.c_[bream_weight, bream_length]\nlen(bream_data)","499b8e96":"bream_data[:5]","d3946416":"bream_data[-5:]","3126fe7d":"smelt_data = np.c_[smelt_weight, smelt_length]\nlen(smelt_data)","4dbcbc24":"smelt_data[:5]","a01e730d":"fish_data = np.r_[bream_data, smelt_data]\nlen(fish_data)","532b0219":"fish_data[:5]","01937fa0":"fish_label = np.array([1] * num_bream + [0] * num_smelt)\nfish_label","509810b6":"knn_clf = KNeighborsClassifier() ","43579161":"knn_clf.fit(X=fish_data, y=fish_label)","73f1db6d":"knn_clf._fit_X[:5]","62b7b4f0":"knn_clf._y","7117562b":"train_predicts = knn_clf.predict(fish_data)\ntrain_predicts","571c2e2f":"np.mean(train_predicts == fish_label)","29acb755":"knn_clf.score(X=fish_data, y=fish_label)","cf9d0a2b":"clf_report = classification_report(y_true=fish_label, y_pred=train_predicts, \n                                   labels=[0, 1],\n                                   target_names=['Smelt', 'Bream'])\nprint(clf_report)","adcecf23":"plt.scatter(bream_length, bream_weight, label='Bream')\nplt.scatter(smelt_length, smelt_weight, label='Smelt')\nplt.scatter([30, 14], [600, 30], marker='v', color='red', label='WhatIf')\n\nplt.legend()\nplt.show()","a3b74b7e":"knn_clf.predict([[600, 30], [50, 14]])","c5fcc46e":"knn_clf.predict([[600, 30]])","78552ac8":"knn_clf.predict([[50, 14]])","52eb3fbb":"knn_clf.get_params()","4f3f4cac":"KNeighborsClassifier()","5b959e35":"knn_clf.n_neighbors","956c516f":"knn_1 = KNeighborsClassifier(n_neighbors=1)\nknn_1.fit(X=fish_data, y=fish_label)\nknn_1.score(X=fish_data, y=fish_label)\n","49f1e92c":"knn_49 = KNeighborsClassifier(n_neighbors=49)\nknn_49.fit(fish_data, fish_label)\nknn_49.score(fish_data, fish_label)","7daaf0d6":"knn = KNeighborsClassifier()\nknn.fit(fish_data, fish_label)\nknn.n_neighbors = 49\nknn.score(fish_data, fish_label)","bcf8978c":"knn = KNeighborsClassifier()\nknn.fit(X=fish_data, y=fish_label)\n\nknn_scores = []\nfor k in range(1, 50):\n    knn.n_neighbors = k\n    score = knn.score(X=fish_data, y=fish_label)\n    knn_scores.append(score)\n    \nprint(knn_scores)","789bd2df":"plt.plot(range(1, 50), knn_scores, 'o-')\nplt.xlabel('# of neighbors(k)')\nplt.ylabel('accuracy')\nplt.grid()\nplt.show()","9a664b2d":"np.argmax(knn_scores)","15a20ff9":"np.argmin(knn_scores)","76489e0f":"num_train = 35","814ac18d":"X_train, X_test = fish_data[:num_train], fish_data[num_train:]","a834d99e":"y_train, y_test = fish_label[:num_train], fish_label[num_train:]","ac8a94e3":"X_train.shape, X_test.shape","ce332ea2":"knn_clf = KNeighborsClassifier()","3892fe40":"knn_clf.fit(X=X_train, y=y_train)","8596bb86":"knn_clf.score(X_train, y_train)","94ffae13":"test_predicts = knn_clf.predict(X_test)","d65901d8":"clf_report = classification_report(y_true=y_test, y_pred=test_predicts, \n                                   labels=[0, 1],\n                                   target_names=['Smelt', 'Bream'])\nprint(clf_report)","42f4ed02":"np.random.seed(1)\nidx = np.arange(49)\nnp.random.shuffle(idx)\nidx","9689be9d":"train_idx, test_idx = idx[:num_train], idx[num_train:]\ntrain_idx","a74c8013":"test_idx","868e1624":"X_train, X_test = fish_data[train_idx], fish_data[test_idx]\nX_train.shape, X_test.shape","e683371e":"y_train, y_test = fish_label[train_idx], fish_label[test_idx]\ny_train.shape, y_test.shape","1355cff8":"np.unique(y_train, return_counts=True)","0cb9045c":"np.unique(y_test, return_counts=True)","28cc897d":"3\/14, 11\/14","0e614b98":"plt.scatter(X_train[:, 1], X_train[:, 0], label='Train')\nplt.scatter(X_test[:, 1], X_test[:, 0], label='Test')\n\nplt.legend()\nplt.xlabel('Length(cm)')\nplt.ylabel('Weight(g')\nplt.show()","88599431":"knn_clf = KNeighborsClassifier()","53ce0065":"knn_clf.fit(X_train, y_train)","92f40101":"knn_clf.score(X_train, y_train)","fa37cce0":"knn_clf.score(X_test, y_test)","fb5aea1a":"X_train, X_test, y_train, y_test = train_test_split(fish_data,       \n                                                    fish_label,      \n                                                    test_size=0.3,  \n                                                    stratify=fish_label, \n                                                    random_state=1) ","15672be5":"X_train.shape, X_test.shape","46926104":"y_train.shape, y_test.shape","aab764b3":"np.unique(y_train, return_counts=True)","1b275aa6":"np.unique(y_test, return_counts=True)","8570bf7b":"4\/15, 11\/15  # Split share between Breams:Smelts","85230c46":"plt.scatter(X_train[:, 1], X_train[:, 0], label='Train')\nplt.scatter(X_test[:, 1], X_test[:, 0], label='Test')\n\nplt.legend()\nplt.xlabel('Length(cm)')\nplt.ylabel('Weight(g')\nplt.show()","959895ad":"# knn Model \nknn_clf = KNeighborsClassifier()","36a57368":"# Model fi\nknn_clf.fit(X=X_train, y=y_train)","fb5159af":"# Model performance evaluation\nknn_clf.score(X=X_train, y=y_train)","0ff98e48":"# Performance evaluation on test set\nknn_clf.score(X_test, y=y_test)","87e7477e":"test_predicts = knn_clf.predict(X=X_test)","4a4dafb9":"confusion_matrix(y_true=y_test, y_pred=test_predicts)","68d0a599":"clf_report = classification_report(y_true=y_test, y_pred=test_predicts, \n                                   labels=[0, 1],\n                                   target_names=['Smelt', 'Bream'])\nprint(clf_report)","8cff46de":"plt.scatter(25, 150, marker='v', color='red')\nplt.scatter(X_train[:, 1], X_train[:, 0])\n\nplt.xlabel('Length')\nplt.ylabel('Weight')\nplt.show()","19ced595":"test_fish = [[150, 25]]\ntest_pred = knn_clf.predict(X=test_fish)\ntest_pred","b7dc8bec":"plt.scatter(25, 150, marker='v', color='red')\nplt.scatter(X_train[:, 1], X_train[:, 0])\nplt.scatter(X_train[0, 1], X_train[0, 0], marker='D', color='orange')\nplt.scatter(X_train[18, 1], X_train[18, 0], marker='D', color='green')\n\nplt.xlim((0, 1_000))\nplt.ylim((0, 1_000))\nplt.gca().set_aspect('equal')\n\nplt.xlabel('Length')\nplt.ylabel('Weight')\nplt.show()","f6f81187":"train_mean = np.mean(X_train, axis=0, keepdims=True)  \ntrain_mean","653714a8":"train_std = np.std(X_train, axis=0, keepdims=True)\ntrain_std","133e67b3":"X_train_scaled = (X_train - train_mean) \/ train_std\nX_train_scaled[:5]","0b6d86f9":"np.mean(X_train_scaled, axis=0), np.std(X_train_scaled, axis=0)","a75dbf01":"X_test_scaled = (X_test - train_mean) \/ train_std\nX_test_scaled[:5]","f5dbbc16":"# Scaling the test fish\ntest_fish_scaled = (test_fish - train_mean) \/ train_std\ntest_fish_scaled","74e837cc":"plt.scatter(X_train_scaled[:, 1], X_train_scaled[:, 0])\nplt.scatter(test_fish_scaled[0, 1], test_fish_scaled[0, 0], marker='v', color='red')\n\nplt.xlabel('Length')\nplt.ylabel('Weight')\nplt.show()","eb909c03":"knn_clf = KNeighborsClassifier()\nknn_clf.fit(X=X_train_scaled, y=y_train)\ntest_pred = knn_clf.predict(X=test_fish_scaled)\ntest_pred  # Bream ","9cdaae9b":"knn_clf.score(X=X_train_scaled, y=y_train)","3387d473":"knn_clf.score(X=X_test_scaled, y=y_test)","f3347020":"test_predicts = knn_clf.predict(X=X_test_scaled)","e1c0ccea":"clf_report = classification_report(y_true=y_test, y_pred=test_predicts, \n                                   labels=[0, 1],\n                                   target_names=['Smelt', 'Bream'])\nprint(clf_report)","a4c2b7ee":"## Stratified Sampling","ca4df287":"As treid by stratified sampling, the Model shows well performance. ","f790f5af":"# Reference\n\n* Wikipedia\n* [Study ML & Deep learning alone with the book](http:\/\/www.yes24.com\/Product\/Goods\/96024871)","8a1ec089":"It looks split well randomly. Let's check out the share to see if they are split in well proportion.","e9b8ce9a":"To fit the model, we need them in array. Since this is begginer tutorial, we will use only weight and length data sets for our convenience. \n\nAs independant variables, weight and length will be used while Species labeled will be used for dependant variable. ","6702eb7d":"## Sequantial Sampling","9700148e":"If we predict this sample, which would the result be? \n\nkNN returns '0' which is 'Smelt'. As Weight unit is much more bigger than Length, kNN tendes to rely more on Weight than Length. ","86dc569d":"# 3. Model Fitting and Training","690c0201":"Do you like fishing? I like fishing. This is one of reasons I chose this dataset.\n\nThis is the notebook for machine learning begginer using Fish market data. In particular, this will deal with KNeighborsClassifier Scikit-Learn class and this is one of classification methodology of ML. \n\nOverall I would like to focus 3 areas. \n\n* kNN Classification class\n* Sampling issue\n* Scaling issue \n\nI will talk about what kNN model is while showing how to deal with datasets.\nAnd then talk about why sampling method is important in kNN which is classification ML. ","98e559c4":"Based on training with train dataset, the accuracy score is 100%. But we will see if it performs well with test set as well. ","02727606":"### **Performance Measure**\n\n<img src='https:\/\/static.packt-cdn.com\/products\/9781838555078\/graphics\/C13314_06_05.jpg' width=500>\n\n\n* Accuracy: Classification accuracy is the total number of correct predictions divided by the total number of predictions made for a dataset\n> `accuracy = (TN + TP) \/ (TN + FP + FN + TP)`\n\n* Precision : Precision quantifies the number of positive class predictions that actually belong to the positive class\n> `precision = TP \/ (FP + TP)`\n\n* Recall: Recall quantifies the number of positive class predictions made out of all positive examples in the dataset.\n> `recall = TP \/ (FN + TP)`\n\n* F1-score: F-Measure provides a single score that balances both the concerns of precision and recall in one number.\n> `f1 = 2 \/ (1\/precision + 1\/recall)`","7f032205":"Now I am going to test the model based on scaled data-sets.","ce6c95dc":"sampling bias is a bias in which a sample is collected in such a way that some members of the intended population have a lower or higher sampling probability than others. Above shows 0 accuracy when fitting the model without considering appropriate sampling. ","3b0336c2":"As trying to plot the accuracy using k from 1 to 50, the performance started to slow from 18 and drastically dropped after k=28.","1648832c":"[**_k-nearest neighbors algorithm_**](https:\/\/en.wikipedia.org\/wiki\/K-nearest_neighbors_algorithm) is used for classification and regression. In both cases, the input consists of the k closest training examples in data set. The output depends on whether k-NN is used for classification or regression.\n\n<img src=\"https:\/\/miro.medium.com\/max\/800\/1*2zYNhLc522h0zftD1zDh2g.png\" width=500 align='left'>\n\n> Since this algorithm relies on distance for classification, **_if the features represent different physical units or come in vastly different scales then normalizing the training data can improve its accuracy dramatically._**\n\n> AS this physical unit is so important, I would like to show step by step how this affects the output.  \n\n> The neighbors are taken from a set of objects for which the class (for k-NN classification) or the object property value (for k-NN regression) is known. This can be thought of as the training set for the algorithm, though no explicit training step is required.\n\n> A peculiarity of the k-NN algorithm is that it is sensitive to the local structure of the data.","d4416839":"Let's assume we have 25cm, 150gram fish on the plot. ","3ce0be5a":"# 1. Introduction","e55927b6":"Draft fitting model is done now. We can test and adjust them. ","b483e636":"# 5. Scaling Issue","038ccf53":"---","13b230e9":"It looks well split between the targets.","f6e505e9":"As for Species, the dataset includes 7 types of fishes. \n\nSince this notebook is aiming for classification, I would like to use only Bream and Smelt only. ","bbcf8e1e":"This is the summary of the notbooek. \n\n* k-nearest neighbors algorithm is used for classification and regression. The output depends on whether k-NN is used for classification or regression.\n* There is a better way of doing it by trying a bunch of different hyperparameter values.Scikit-learn provides a simple way of achieving this using `n_neightbors`.\n* As this replies on the distance, data should be collectively exhaustive and mutually.\n* If the features represent different physical units or come in vastly different scales then normalizing the training data can improve its accuracy dramatically.\n\nHope it helps and kind your UpVote!. Thanks!.","d14c847b":"If you are curious about how these look like, Bream looks like below. They tend to be narrow, deep-bodied species. The name is a derivation of the Middle English word breme, of Old French origin. [Refer to Wikipedia](https:\/\/en.wikipedia.org\/wiki\/Bream)\n<img src=\"https:\/\/www.sydneyfishmarket.com.au\/Portals\/0\/EasyDNNnews\/1256\/img-Yellowfin-Bream.jpg\" width=400>\n\nAnd this is Smelt. Smelts are a family of small fish, the Osmeridae, found in the North Atlantic and North Pacific Oceans, as well as rivers, streams and lakes in Europe, North America and Northeast Asia. [Refer to Wikipedia](https:\/\/en.wikipedia.org\/wiki\/Smelt_(fish))\n<img src=\"https:\/\/images.squarespace-cdn.com\/content\/v1\/5b071ddea2772cebc1662831\/1530230170490-EKRCLOAKTK4639KO4E7M\/ke17ZwdGBToddI8pDm48kInjuZb3CAvjvvi6Jf3mnjlZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpx1viaq3v9Yxb9vhtvLFNwfo7-TXC8LW2F3Zy1D3lO8ahVwA8sicxz2pgFIqMhGFmM\/smelt6.jpg\" width=400>","74520ed4":"If I am tying to set the same scale, this will look like this. \n> Yellow mark below represent the first neighbor of 'Red(25cm, 150g)'\n\n> Green mark below represent the second neighbor of 'Red(25cm, 150g)'","af82f137":"Plot the train set after scaling.","afd90934":"The value of k we selected above was selected by observing the curve of accuracy vs number of neighbors. This is a primitive way of hyperparameter tuning.\n\nThere is a better way of doing it by trying a bunch of different hyperparameter values.\n\nScikit-learn provides a simple way of achieving this using `n_neightbors`.","a90fd7dc":"# 6. Conclusion","dfa11328":"## Bream & Smelt selection","63bb3d08":"We have 6 columns in dataset. First '0' represents for fish species and the rest of columns are size-related data. \n\nAccording to the origin of data set;\n* Weight: weight of fish in Gram g\n* Length1: vertical length in cm\n* Length2: diagonal length in cm\n* Length3: cross length in cm\n* Height: height in cm\n* Width:diagonal width in cm\n\nDont' worry. We won't use all of columns. Instead we will utilize 3 columns only for our conveniences.","0148a6b0":"Among 49 fishes above, 14 smelts are located left bottom and 35 breams are right above. \n\nData is ready now. We can fit the model for the classification with the data.","3e939c42":"## Standardization","89c4e6b4":"\n<img src='https:\/\/www.oreilly.com\/library\/view\/hands-on-machine-learning\/9781788393485\/assets\/7a9d8cb9-10f7-43b5-b52f-865fbbb0b69e.png' width=400 align='left'>","ac82961a":"Having said, they are diffred by its size. Let's plot them by data and check. ","534cffd5":"# 2. Data Exploration","5a26aef7":"# 4. Sampling Issue","ed21c60f":"Now all looks perfect. ","fcd8167b":"In the classification setting, the K-nearest neighbor algorithm essentially boils down to forming a majority vote between the K most similar instances to a given \u201cunseen\u201d observation. Similarity is defined according to a distance metric between two data points. The k-nearest-neighbor classifier is commonly based on the Euclidean distance between a test sample and the specified training samples. Let $x_{i}$ be an input sample with $p$ features $(x_{i1}, x_{i2},..., x_{ip})$, $n$ be the total number of input samples $(i=1,2,...,n)$.  The Euclidean distance between sample $x_{i}$ and $x_{l}$ is is defined as: \n\n\n$$d(x_{i}, x_{l}) = \\sqrt{(x_{i1} - x_{l1})^2 + (x_{i2} - x_{l2})^2 + ... + (x_{ip} - x_{lp})^2}$$\n\nAccording to its formula, weight in gram affects the outcome pretty much more than lenth in cm. \n\nThis is the scaling issue which I will describe further later in this notebook. ","d187bfd9":"## Model selection","130acfb5":"## Table of Contents  \n\n1. [Introduction](#1.-Introduction)\n2. [Data Exploration](#2.-Data-Exploration)\n3. [Model Fitting and Training](#3.-Model-Fitting-Training)\n4. [Sampling Issue](#4.-Sampling-Issue)\n5. [Scaling Issue](#5.-Scaling-Issue)\n6. [Conclusion](#6.-Conclusion) ","91dcf6eb":"## Model Evaluation","8a7f82b7":"Now I would like to cover the scaling issue. As talked above, kNN relies on distance for classification, if the features represent different physical units or come in vastly different scales then normalizing the training data can improve its accuracy dramatically.\n\nHere comes the example. ","bb1cab5e":"---","1a470c52":"In statistics, [**_Stratified Sampling_**](https:\/\/en.wikipedia.org\/wiki\/Stratified_sampling) is a method of sampling from a population which can be partitioned into subpopulations.\n\nIn statistical surveys, when subpopulations within an overall population vary, it could be advantageous to sample each subpopulation (stratum) independently. Stratification is the process of dividing members of the population into homogeneous subgroups before sampling. The strata should define a partition of the population. That is, it should be collectively exhaustive and mutually exclusive: every element in the population must be assigned to one and only one stratum. Then simple random sampling is applied within each stratum. The objective is to improve the precision of the sample by reducing sampling error. It can produce a weighted mean that has less variability than the arithmetic mean of a simple random sample of the population.\n\n<img src='https:\/\/www.netquest.com\/hubfs\/Imported_Blog_Media\/Stratified_sampling.png'>","625b270c":"## Hyperparameter tuning by k(n_neighbors)","0055a27b":"<img src='https:\/\/cdn.images.express.co.uk\/img\/dynamic\/130\/590x\/Fishing-and-lockdown-fishing-exercise-latest-news-coronavirus-1259607.webp?r=1592143825316'>","1334453f":"## Random Sampling ","104649d5":"# <center> kNN Classification on Fish Market","aa2b88c4":"Let's assume that there are 2 fishes in size one bream with 30cm\/600g and one smelt with 14cm\/30g each. We may stick them on the plot as below. ","ed245d25":"According to its model, bream was predicted well, but smelt was wrong. What happened?","f65da43b":"<center>\n<img src=\"https:\/\/previews.123rf.com\/images\/ivanmogilevchik\/ivanmogilevchik1704\/ivanmogilevchik170400258\/75575734-%EC%B2%AD-%EC%96%B4-%EC%86%A1%EC%96%B4%EC%99%80-%EC%8A%A4%EC%BC%80%EC%B9%98-%ED%95%B4%EC%82%B0%EB%AC%BC-%EC%8B%9C%EC%9E%A5%EC%9D%98-%EA%B0%9C%EB%85%90-%EC%9E%89%EC%96%B4-%EC%97%B0%EC%96%B4-%EB%84%99%EC%B9%98-%EC%9E%B0%EB%8D%94-%EB%86%8D%EC%96%B4-%EB%8C%80%EA%B5%AC-%EC%8A%A4%ED%94%BC%EB%A6%BF-%EB%AC%BC%EA%B3%A0%EA%B8%B0-%EC%A0%9C%ED%92%88-%EC%B9%B4%EC%9A%B4%ED%84%B0-%EB%B2%A1%ED%84%B0-%EC%9D%BC%EB%9F%AC%EC%8A%A4%ED%8A%B8-%EB%A0%88%EC%9D%B4%EC%85%98%EC%97%90.jpg\" width=500>","eff84f29":"## Data Import"}}