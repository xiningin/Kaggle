{"cell_type":{"a91e6e84":"code","6eb43534":"code","475461a5":"code","9b63a509":"code","b1ffbf86":"code","7eb5e706":"code","caf9ee19":"code","ec2df6ba":"code","e50dada4":"code","8156118f":"code","c9989b40":"code","0de49b07":"code","aeeea1b4":"code","056556f2":"code","bb0fee5c":"code","008da1ca":"code","636c1fbc":"code","cf1ed6f7":"code","a7b0b219":"code","aa27dac5":"code","b7577d92":"code","99563b4d":"markdown","43a90f59":"markdown","49d9a68e":"markdown","cbbd93d1":"markdown","75ab2cd8":"markdown","780c5071":"markdown","04685c19":"markdown","c30f9478":"markdown","60c7dd18":"markdown","c5bfd7a8":"markdown","eed6d2e9":"markdown"},"source":{"a91e6e84":"# Import helpful libraries\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\npd.set_option('display.max_columns', 8)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)","6eb43534":"# Path of the data files to read\ntrain_data_path = '..\/input\/tabular-playground-series-dec-2021\/train.csv'\ntest_data_path = '..\/input\/tabular-playground-series-dec-2021\/test.csv'","475461a5":"# Read and store train data in DataFrames\ntrain_data = pd.read_csv(train_data_path, index_col='Id')\ntrain_data.head()","9b63a509":"# Read and store test data in DataFrames\ntest_data = pd.read_csv(test_data_path, index_col='Id')\ntest_data.head()","b1ffbf86":"train_data.shape","7eb5e706":"test_data.shape","caf9ee19":"# List all the columns in the data\ntrain_data.columns","ec2df6ba":"# Separate target from features\ny = train_data['Cover_Type']\ntrain_data.drop(['Cover_Type'], axis=1, inplace=True)","e50dada4":"# Create a DataFrame to hold the predictive features\nX = train_data\nX_test = test_data","8156118f":"X.shape","c9989b40":"y.shape","0de49b07":"scaler = StandardScaler()\nx_data = scaler.fit_transform(X)\nx_test = scaler.transform(X_test)","aeeea1b4":"encoder = OneHotEncoder()\ny = encoder.fit_transform(y.values[:, np.newaxis]).toarray()","056556f2":"# Divide data into training and validation subsets\nX_train, X_valid, y_train, y_valid = train_test_split(X, y,\n                                                      test_size=.2,\n                                                      random_state=1)","bb0fee5c":"# Define the model\nmodel = Sequential([\n    Dense(1024, activation='relu', input_shape=(54,)),\n    Dense(256, activation='relu'),\n    Dense(64, activation='relu'),\n    Dense(7, activation='softmax')\n])","008da1ca":"model.compile(\n    loss='categorical_crossentropy',\n    optimizer='adam',\n    metrics=['acc']\n)","636c1fbc":"# Fit the model\nmodel.fit(X_train, y_train, batch_size=1024, epochs=100)","cf1ed6f7":"# Make predictions with validation data\npreds_valid = model.predict(X_valid)","a7b0b219":"# Calculate the Mean Absolute Error in validation data\naccuracy_score(y_valid.argmax(axis=1), preds_valid.argmax(axis=1))","aa27dac5":"# Make predictions which will be submitted\npreds_test = model.predict(X_test)\npreds_test = preds_test.argmax(axis=1).reshape(-1,) + 1","b7577d92":"# Save predictions in the format used for competition scoring\noutput = pd.DataFrame({'Id': X_test.index,\n                       'Cover_Type': preds_test})\noutput.to_csv('submission.csv', index=False)","99563b4d":"# Specify the Prediction Target","43a90f59":"# Data Pre-processing","49d9a68e":"# Generate a Submission","cbbd93d1":"# Make Predictions with Test Data","75ab2cd8":"# Loading the Data","780c5071":"# Specify and Fit the Model","04685c19":"#### Review Data\n\nBefore building a model, take a quick look at `X` and `y`.","c30f9478":"# Make Predictions","60c7dd18":"# Split Your Data","c5bfd7a8":"# Calculate the Error","eed6d2e9":"# Create X"}}