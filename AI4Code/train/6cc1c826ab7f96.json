{"cell_type":{"070932d4":"code","9488da91":"code","d198b0da":"code","2b241584":"code","035a895c":"code","5eb9eac2":"code","bba6021c":"code","65c2098e":"code","1c38b756":"code","c95ba097":"code","416eae49":"code","258e115d":"code","0159b661":"code","e13c4182":"code","ef105786":"code","81822562":"code","30858f05":"code","7cd411a6":"code","f547bdbc":"code","93d81401":"code","55e1f664":"code","09cb38bf":"code","19a1cab8":"code","308bccff":"code","b1a1901f":"code","70ba222e":"code","24093c0c":"code","ac09af0a":"code","ea169545":"code","28fe1466":"code","fa3c4ddb":"markdown","7b9ed77e":"markdown","6a75114f":"markdown","e4831f39":"markdown","83ee73fa":"markdown","8eef29c5":"markdown","2d2d51b8":"markdown","823c2bd3":"markdown","f0b728aa":"markdown","3ba79dcc":"markdown","17738ca0":"markdown","f83e9d3a":"markdown","cbfe390e":"markdown","234b283e":"markdown","562e8254":"markdown","3e1bad9d":"markdown","d4ff6af1":"markdown","dd882db3":"markdown","b1bb325b":"markdown","d275131d":"markdown","b312c296":"markdown"},"source":{"070932d4":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport math\nimport mlxtend\nimport sklearn.cluster as cluster\nimport sklearn.neighbors\nimport sklearn.metrics as metrics\nimport re\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport string\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import classification_report,confusion_matrix, roc_curve, auc, precision_score, recall_score, f1_score, precision_recall_curve\nimport nltk\nnltk.download('wordnet')\nnltk.download('stopwords')\nfrom nltk.tokenize import word_tokenize \nfrom nltk.tokenize import RegexpTokenizer\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9488da91":"train_data = pd.read_csv('..\/input\/emotions-dataset-for-nlp\/train.txt',names=['sentence','emotion'],header=None, sep=';')\ntest_data = pd.read_csv('..\/input\/emotions-dataset-for-nlp\/test.txt',names=['sentence','emotion'],header=None, sep=';')\nval_data= pd.read_csv('..\/input\/emotions-dataset-for-nlp\/val.txt',names=['sentence','emotion'],header=None, sep=';')\ndf = pd.concat([train_data,test_data, val_data])\nprint('Total data:',df.shape)","d198b0da":"# Null Check\ntrain_data.isnull().sum()\ntest_data.isnull().sum()\nval_data.isnull().sum()","2b241584":"df = df.drop_duplicates(keep=\"first\") # Drop duplicated data and reindex the data\ndf_reidx = df.reset_index(drop=True)\ndf_reidx.shape","035a895c":"# convert the emotions to binary labels. love and joy emotions are \"not-stressed ==1\", and sadness, anger, fear, and surprise are \"stressed == 0\".\ndf_reidx['label']=df_reidx['emotion'].replace({'joy': \"not-stressed\" , 'love': \"not-stressed\", \n                                   'sadness': \"stressed\", 'anger': \"stressed\", 'fear': \"stressed\",'surprise': \"stressed\"})","5eb9eac2":"# check if pos and neg sentiments\ndf_reidx.label.value_counts()","bba6021c":"df_reidx['length'] = df_reidx['sentence'].apply(len) # number of characters\ndf_reidx['length'].describe() # info()","65c2098e":"df_reidx.tail()","1c38b756":"from tqdm import tqdm\nimport re\nfrom bs4 import BeautifulSoup\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\n\ndef decontracted(phrase):\n    \"\"\"\n    We first define a function to expand the contracted phrase into normal words\n    \"\"\"\n    # specific\n    phrase = re.sub(r\"wont\", \"will not\", phrase)\n    phrase = re.sub(r\"wouldnt\", \"would not\", phrase)\n    phrase = re.sub(r\"shouldnt\", \"should not\", phrase)\n    phrase = re.sub(r\"couldnt\", \"could not\", phrase)\n    phrase = re.sub(r\"cudnt\", \"could not\", phrase)\n    phrase = re.sub(r\"cant\", \"can not\", phrase)\n    phrase = re.sub(r\"dont\", \"do not\", phrase)\n    phrase = re.sub(r\"doesnt\", \"does not\", phrase)\n    phrase = re.sub(r\"didnt\", \"did not\", phrase)\n    phrase = re.sub(r\"wasnt\", \"was not\", phrase)\n    phrase = re.sub(r\"werent\", \"were not\", phrase)\n    phrase = re.sub(r\"havent\", \"have not\", phrase)\n    phrase = re.sub(r\"hadnt\", \"had not\", phrase)\n\n    # general\n    phrase = re.sub(r\"n\\ t\", \" not\", phrase)\n    #phrase = re.sub(r\"\\re\", \" are\", phrase)\n    phrase = re.sub(r\"\\ s \", \" is \", phrase) # prime \n    phrase = re.sub(r\"\\ d \", \" would \", phrase)\n    phrase = re.sub(r\"\\ ll \", \" will \", phrase)\n    phrase = re.sub(r\"\\dunno\", \"do not \", phrase)\n    phrase = re.sub(r\"ive \", \"i have \", phrase)\n    phrase = re.sub(r\"im \", \"i am \", phrase)\n    phrase = re.sub(r\"i m \", \"i am \", phrase)\n    phrase = re.sub(r\" w \", \" with \", phrase)\n    \n    return phrase\n\n    \ndef clean_text(df):\n    \"\"\"\n    Clean the review texts\n    \"\"\"\n    cleaned_review = []\n\n    for review_text in tqdm(df['sentence']):\n        \n        # expand the contracted words\n        review_text = decontracted(review_text)\n        #remove html tags\n        review_text = BeautifulSoup(review_text, 'lxml').get_text().strip() # re.sub(r'<.*?>', '', text)\n        \n        #remove non-alphabetic characters\n        review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n    \n        #remove url \n        review_text = re.sub(r'https?:\/\/\\S+|www\\.\\S+', '', review_text)\n        \n        #Removing punctutation, string.punctuation in python consists of !\"#$%&\\'()*+,-.\/:;<=>?@[\\\\]^_{|}~`\n        review_text = review_text.translate(str.maketrans('', '', string.punctuation))\n        # ''.join([char for char in movie_text_data if char not in string.punctuation])\n        \n        # remove emails\n        review_text = re.sub(r\"(^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$)\", '', review_text)\n    \n        cleaned_review.append(review_text)\n\n    return cleaned_review  \n\ndf_reidx['cleaned_sentence'] = clean_text(df_reidx)\ndf_reidx.head()  ","c95ba097":"import nltk\nnltk.download('punkt')\ndef remove_stopwords(phrase):\n    remove_sw = []\n    tokenizer = RegexpTokenizer(r'[a-zA-Z0-9]+')\n    stop_words = stopwords.words('english')\n    \n    for review_text in tqdm(phrase):\n        tokens = word_tokenize(review_text)\n        tokens = [word for word in tokens if not word in stop_words]\n        remove_sw.append(tokens)\n    return remove_sw\n\ndf_reidx['cleaned_sentence'] = remove_stopwords(df_reidx['cleaned_sentence'])\ndf_reidx.head()","416eae49":"#stemming for extract the actual meaning of the words\nfrom nltk.stem import PorterStemmer\n\ndef stemming(phrase):\n    stemmer = PorterStemmer()\n    stem_output=[]\n    stemmed=[]\n    for review_text in tqdm(phrase):\n        stemmed = [stemmer.stem(word) for word in review_text]\n        stem_output.append(stemmed)\n    return stem_output\n\ndf_reidx['cleaned_sentence'] = stemming(df_reidx['cleaned_sentence'])\ndf_reidx['cleaned_sentence'].head()","258e115d":"def to_sentence(phrase):\n    sentence=[]\n    for words in tqdm(phrase):\n        sentence.append((\" \").join(words))\n    return sentence\ndf_reidx['cleaned_sentence']=to_sentence(df_reidx['cleaned_sentence'])\ndf_reidx['cleaned_sentence'].head()","0159b661":"# convert the cleaned sentences to vectors\ntoken = RegexpTokenizer(r'[a-zA-Z0-9]+')\n# a built-in stop word list for english is used\n# all values of n such than min_n<=n<= max_n will be used. (1,1): only unigrams, (1,2):uni&bigram, (2,2): only bigrams\n# max_df: when building the vocabulary, ignore terms that have a document frequency strictly higher than the given threshold.\n# min_df: ignore terms that have a document frequency strictly lower than the given threshold.\n\nvectorizer = CountVectorizer(stop_words='english', max_df=0.5, min_df=3, ngram_range=(1,1),tokenizer = token.tokenize)\nx = vectorizer.fit_transform(df_reidx.cleaned_sentence)\ny = df_reidx.label.values\n\nprint(\"X.shape : \",x.shape)\nprint(\"y.shape : \",y.shape)","e13c4182":"# do shuffle to make neg and pos data of data set split equaly in the test and training set\n# do random_sate for making it settle when we run this code repeatedly\ntrain_idx, test_idx = train_test_split(np.arange(df_reidx.shape[0]), test_size=0.3,shuffle=True, random_state=42)\n\nx_train = x[train_idx]\ny_train = y[train_idx]\n\nx_test = x[test_idx]\ny_test = y[test_idx]\nprint(\"Number of training examples:{}\".format(len(train_idx)))\nprint(\"Number of testing examples:{}\\n\".format(len(test_idx)))\nprint(\"Training data: X_train : {}, y_train : {}\".format(x_train.shape, y_train.shape))\nprint(\"Testing data: X_test : {}, y_test : {}\".format(x_test.shape, y_test.shape))\n","ef105786":"x_train.shape","81822562":"# fit a logistic regression classifier on the training data use default settings\nlr_clf = LogisticRegression()\nlr_clf.fit(x_train, y_train)\n\n# make prediction on testing data\ny_pred_test_lr = lr_clf.predict(x_test)\ny_predprob_lr = lr_clf.predict_proba(x_test)\nmatrix_lr = confusion_matrix(y_test,y_pred_test_lr)\nprint(classification_report(y_test, y_pred_test_lr))\nprint(\"\\nAccuracy for Logistic Regression model:\",metrics.accuracy_score(y_test, y_pred_test_lr))\nprint(\"\\n\")\ny_predict = lr_clf.predict(x_test)\nmatrix_display = ConfusionMatrixDisplay(matrix_lr).plot()","30858f05":"from sklearn.naive_bayes import BernoulliNB\nnb_clf = BernoulliNB()\nnb_clf.fit(x_train, y_train)\n# make prediction on testing data\ny_pred_test_nb = nb_clf.predict(x_test)\ny_predprob_nb = nb_clf.predict_proba(x_test)\nmatrix_nb = confusion_matrix(y_test,y_pred_test_nb)\nprint(classification_report(y_test, y_pred_test_nb))\nprint(\"\\nAccuracy for Bernouli Naive Bayes model:\",metrics.accuracy_score(y_test, y_pred_test_nb))\nprint(\"\\n\")\nmatrix_display = ConfusionMatrixDisplay(matrix_nb).plot()","7cd411a6":"mnb = MultinomialNB()\nmnb.fit(x_train, y_train)\n# make prediction on testing data\ny_pred_test_mnb = mnb.predict(x_test)\ny_predprob_mnb = mnb.predict_proba(x_test)\nmatrix = confusion_matrix(y_test,y_pred_test_mnb)\nprint(classification_report(y_test, y_pred_test_mnb))\nprint(\"\\nAccuracy for multinominal Naive Bayes model:\",metrics.accuracy_score(y_test, y_pred_test_mnb))\nprint(\"\\n\")\n\ny_predict = mnb.predict(x_test)\ncm = confusion_matrix(y_test, y_predict)\ncm_display = ConfusionMatrixDisplay(cm).plot()","f547bdbc":"acc_score_lr = metrics.accuracy_score(y_pred_test_lr,y_test)\nprec_score_lr = precision_score(y_test,y_pred_test_lr, average='macro')\nrecall_lr = recall_score(y_test, y_pred_test_lr,average='macro')\nf1_lr = f1_score(y_test,y_pred_test_nb,average='macro')\nmatrix_lr = confusion_matrix(y_test,y_pred_test_lr)\nprint('Logistic Regression Model\\n')\nprint(str('Accuracy: '+'{:04.2f}'.format(acc_score_lr*100))+'%')\nprint(str('Precision: '+'{:04.2f}'.format(prec_score_lr*100))+'%')\nprint(str('Recall: '+'{:04.2f}'.format(recall_lr*100))+'%')\nprint('F1 Score: ',f1_lr)\nprint(matrix_lr)","93d81401":"acc_score_nb = metrics.accuracy_score(y_pred_test_nb,y_test)\nprec_score_nb = precision_score(y_test,y_pred_test_nb, average='macro')\nrecall_nb = recall_score(y_test, y_pred_test_nb,average='macro')\nf1_nb = f1_score(y_test,y_pred_test_nb,average='macro')\nmatrix_nb = confusion_matrix(y_test,y_pred_test_nb)\nprint('Bernouli Naive Bayes Model\\n')\nprint(str('Accuracy: '+'{:04.2f}'.format(acc_score_nb*100))+'%')\nprint(str('Precision: '+'{:04.2f}'.format(prec_score_nb*100))+'%')\nprint(str('Recall: '+'{:04.2f}'.format(recall_nb*100))+'%')\nprint('F1 Score: ',f1_nb)\nprint(matrix_nb)","55e1f664":"acc_score_mnb = metrics.accuracy_score(y_pred_test_mnb,y_test)\nprec_score_mnb = precision_score(y_test,y_pred_test_mnb, average='macro')\nrecall_mnb = recall_score(y_test, y_pred_test_mnb,average='macro')\nf1_mnb = f1_score(y_test,y_pred_test_mnb,average='macro')\nmatrix_mnb = confusion_matrix(y_test,y_pred_test_mnb)\nprint('Multimominal Naive Bayes Model\\n')\nprint(str('Accuracy: '+'{:04.2f}'.format(acc_score_mnb*100))+'%')\nprint(str('Precision: '+'{:04.2f}'.format(prec_score_mnb*100))+'%')\nprint(str('Recall: '+'{:04.2f}'.format(recall_mnb*100))+'%')\nprint('F1 Score: ',f1_mnb)\nprint(matrix_mnb)","09cb38bf":"test_data = df_reidx.iloc[test_idx]\ntest_data['pred_label'] = y_pred_test_lr\ntest_data.head(2)[['sentence','label','pred_label']]\n# shows what the prediction label fit to the real label","19a1cab8":"# shows what the prediction label does not fit to the real label\ntest_data[test_data['label'] != test_data['pred_label']].head()[['sentence','label','pred_label']].head(2)","308bccff":"feature_to_coef = {word: float(\"%.3f\" % coef) for word, coef in zip(vectorizer.get_feature_names(), lr_clf.coef_[0])}\n\nprint(\"Top positive features:\")\nsorted(feature_to_coef.items(), key=lambda x: x[1], reverse=True)[:10]","b1a1901f":"# most of the words are reliable evidence of indicating negative sentiments\nprint(\"Top negative features:\")\nsorted(feature_to_coef.items(), key=lambda x: x[1], reverse=False)[:10]","70ba222e":"feature_to_coef = {word: float(\"%.3f\" % coef) for word, coef in zip(vectorizer.get_feature_names(), nb_clf.coef_[0])}\n\nprint(\"Top positive features:\")\nsorted(feature_to_coef.items(), key=lambda x: x[1], reverse=True)[:10]","24093c0c":"# most of the words are reliable evidence of indicating negative sentiments\nprint(\"Top negative features:\")\nsorted(feature_to_coef.items(), key=lambda x: x[1], reverse=False)[:10]","ac09af0a":"feature_to_coef = {word: float(\"%.3f\" % coef) for word, coef in zip(vectorizer.get_feature_names(), mnb.coef_[0])}\n\nprint(\"Top positive features:\")\nsorted(feature_to_coef.items(), key=lambda x: x[1], reverse=True)[:10]","ea169545":"# most of the words are reliable evidence of indicating negative sentiments\nprint(\"Top negative features:\")\nsorted(feature_to_coef.items(), key=lambda x: x[1], reverse=False)[:10]","28fe1466":"text=['i am not feeling well', 'i want to make this project better', 'i feel aaaaaaah']\ntest_result = lr_clf.predict(vectorizer.transform(text))\nprint(test_result)","fa3c4ddb":"# Load and explore the data\n#### The data is available at this source\nData source: https:\/\/www.kaggle.com\/praveengovi\/emotions-dataset-for-nlp ","7b9ed77e":"# Conclusion","6a75114f":"Multimominal Naive Bayes Model has higher accuracy than Bernouli Naive Bayes Model.","e4831f39":"#### Logistic Regression","83ee73fa":"##### MultinominaliNB","8eef29c5":"##### BernouliNB","2d2d51b8":"##### MultinominaliNB\n\nIt consider a feature vector where a given term represents the number of times it appears or very ofen, such as frequency.","823c2bd3":"###### additional lemmatization","f0b728aa":"# Model Training","3ba79dcc":"# Train Test split","17738ca0":"##### Predicted features of logistic regression model","f83e9d3a":"# Text Preprocessing\n#### To clean the sentences,we do text preprocessing.\n*   Decontracted\n*   Data cleaning\n*   Spell check\n*   Lemmatization\n*   Nomalization","cbfe390e":"##### Predicted features of multinomial NB","234b283e":"##### Predicted features of BernouliNB","562e8254":"# Explain the model prediction","3e1bad9d":"# Feature Engineering","d4ff6af1":"# Cross validataion","dd882db3":"# Data Information","b1bb325b":"\n\n#### Naive Bayes classifier","d275131d":"##### BernouliNB\n\nA binary algorithm used when the feature is present or not.","b312c296":"### CounterVectorize: tokenization: "}}