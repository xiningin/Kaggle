{"cell_type":{"81a210ab":"code","c7500a16":"code","40e0640a":"code","a2fa973f":"code","c9244f32":"code","15f32cb2":"code","be0d584d":"code","8bb862cf":"code","e1f24a5a":"code","84765a29":"code","8290bbc9":"code","3322a8e3":"code","a385111f":"code","6998545c":"code","49953987":"code","10591c54":"code","5d44a9ed":"code","20e42e46":"code","b986ab05":"code","50fa3c6a":"markdown","feac477d":"markdown","c924e5b8":"markdown","1849b251":"markdown","540eaf88":"markdown","bda36e87":"markdown","30fc953e":"markdown","ad057f4a":"markdown","fa926d24":"markdown","eb14bee9":"markdown"},"source":{"81a210ab":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom mlxtend.frequent_patterns import apriori\nfrom mlxtend.frequent_patterns import association_rules\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","c7500a16":"# Load Datasets\ncustomers = pd.read_csv(\"..\/input\/olist_customers_dataset.csv\")\ngeolocation = pd.read_csv(\"..\/input\/olist_geolocation_dataset.csv\")\norder_items = pd.read_csv(\"..\/input\/olist_order_items_dataset.csv\")\norder_payments = pd.read_csv(\"..\/input\/olist_order_payments_dataset.csv\")\nreviews = pd.read_csv(\"..\/input\/olist_order_reviews_dataset.csv\")\norders = pd.read_csv(\"..\/input\/olist_orders_dataset.csv\")\nproducts = pd.read_csv(\"..\/input\/olist_products_dataset.csv\")\nsellers = pd.read_csv(\"..\/input\/olist_sellers_dataset.csv\")\ntranslations = pd.read_csv(\"..\/input\/product_category_name_translation.csv\")","40e0640a":"products.head()","a2fa973f":"# Convert the translations to dictionary format\ntranslations = translations.set_index('product_category_name')['product_category_name_english'].to_dict()\n\n# translate the product category column in the products df to English\nproducts['product_category_name'] = products['product_category_name'].map(translations)","c9244f32":"#total number of unique products and categories\nprint(\"total unique products = \" + str(len(products['product_id'])))\nprint(\"total unique categories = \" + str(len(products['product_category_name'].unique())))","15f32cb2":"# Function to plot bar graphs\ndef plot_bar_graph(x,y,title):\n    fig, axs = plt.subplots(1, 1, figsize=(20, 10), sharey=True)\n    axs.bar(x, y)\n    axs.set_title(title)\n    plt.xticks(rotation =90)\n\n    # data labels\n    for i, v in enumerate(y):\n        axs.text(i-.25, \n                  v+10, \n                  y[i], \n                  fontsize=8, \n                  #color=label_color_list[i]\n                )\n    return plt.show()\n\n# Function to plot line graph\ndef plot_line_graph(x,y,title):\n    fig, axs = plt.subplots(1, 1, figsize=(20, 10), sharey=True)\n    axs.plot(x, y)\n    axs.set_title(title)\n    plt.xticks(rotation =90)\n\n    # data labels\n    for i, v in enumerate(y):\n        axs.text(i-.25, \n                  v+10, \n                  y[i], \n                  fontsize=8, \n                  #color=label_color_list[i]\n                )\n    return plt.show()\n\n# Function to plot bar graphs\ndef plot_scatter_graph(x,y,title):\n    fig, axs = plt.subplots(1, 1, figsize=(20, 10), sharey=True)\n    axs.scatter(x, y)\n    axs.set_title(title)\n    plt.xticks(rotation =90)\n\n    # data labels\n    for i, v in enumerate(y):\n        axs.text(i-.25, \n                  v+10, \n                  y[i], \n                  fontsize=8, \n                  #color=label_color_list[i]\n                )\n    return plt.show()","be0d584d":"# check for missing values\n# since we are only concerned about these two columns we will check only these two:\nprint(\"Missing Values = \" + str(products[[\"product_id\",\"product_category_name\"]].isna().values.sum()))\n\nproducts[[\"product_id\",\"product_category_name\"]].isna().any(axis =1)\n\n# drop the products with missing category names\nproducts = products.dropna(subset=['product_id', 'product_category_name'])\nproducts.head()","8bb862cf":"# distribution of unique products per category\nproduct_category = products[['product_id','product_category_name']] \\\n.groupby('product_category_name')['product_id'] \\\n.count()\\\n.sort_values(ascending=False) \\\n.to_dict()\n\nproduct_category_names = list(product_category.keys())[:20]\nproduct_category_values = list(product_category.values())[:20]\n\nplot_bar_graph(product_category_names,product_category_values,\"Top 20 Unique Products per Category\")","e1f24a5a":"# Orders per Product\n# Join the two datasets\norder_products = pd.merge(order_items, products, left_on = 'product_id', right_on = 'product_id')\n\n# plot the data\norder_products[['product_category_name','order_id']]","84765a29":"# check for missing values\n# since we are only concerned about these two columns we will check only these two:\nprint(\"Missing Values = \" + str(order_products[[\"product_category_name\",\"order_id\"]].isna().values.sum()))\n\norder_products[order_products[[\"product_category_name\",\"order_id\"]].isna().any(axis =1)]\n\n# drop the orders with missing category names\norder_products = order_products.dropna(subset=[\"product_category_name\",\"order_id\"])\n","8290bbc9":"# plot the data\norder_products_dict = order_products[['product_category_name','order_id']] \\\n.groupby('product_category_name')['order_id'] \\\n.count()\\\n.sort_values(ascending=False) \\\n.to_dict()\n\n\norder_product_names = list(order_products_dict.keys())[:20]\norder_product_values = list(order_products_dict.values())[:20]\n\nplot_bar_graph(order_product_names,order_product_values,\"Top 20 Product Categories by Orders\")","3322a8e3":"# Check how many orders have more than one product\nprint(\"Total Orders: \" + str(len(order_items['order_id'].unique())))\nprint(\"Total Orders with 2 or more items: \" + str(len(order_items[order_items['order_item_id'] == 2])))","a385111f":"order_products.head()","6998545c":"# Transforming the data into the correct format\n\nbasket = order_products.groupby(['order_id','product_category_name'])['order_item_id']\\\n                                    .sum() \\\n                                    .unstack() \\\n                                    .reset_index() \\\n                                    .fillna(0) \\\n                                    .set_index('order_id')\n\n# recode all multiple purchases to 1\ndef encode_units(x):\n    if x <= 0:\n        return 0\n    if x >= 1: \n        return 1\nbasket_sets = basket.applymap(encode_units)\nbasket_sets.head()","49953987":"# remove all orders with less than 2 different categories\nbasket_sets = basket_sets[basket_sets.sum(axis = 1) > 1]\nbasket_sets[basket_sets.sum(axis = 1) > 1]","10591c54":"frequent_itemsets = apriori(basket_sets, min_support=0.01, use_colnames = True)\nrules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.1)\n\ndf_results1 = pd.DataFrame(rules)\ndf_results1.sort_values([\"confidence\"],ascending=False)\n\n#remove values with lift < 1\ndf_results1[df_results1[\"lift\"] > 1]","5d44a9ed":"# Transforming the data into the correct format\n\nbasket_product = order_products[(order_products['product_category_name'] == \"home_confort\") | \n                               (order_products['product_category_name'] == \"bed_bath_table\")]\\\n                                    .groupby(['order_id','product_id'])['order_item_id']\\\n                                    .sum() \\\n                                    .unstack() \\\n                                    .reset_index() \\\n                                    .fillna(0) \\\n                                    .set_index('order_id')\n\n\nbasket_product_sets = basket_product.applymap(encode_units)\nbasket_product_sets.head()","20e42e46":"# remove all orders with less than 2 different categories\nbasket_product_sets = basket_product_sets[basket_product_sets.sum(axis = 1) > 1]\nbasket_product_sets.head()","b986ab05":"frequent_itemsets_product = apriori(basket_product_sets, min_support=0.005, use_colnames = True)\nrules_product = association_rules(frequent_itemsets_product, metric='confidence', min_threshold=0.5)\n\npd.DataFrame(rules_product).sort_values([\"confidence\"],ascending = False)","50fa3c6a":"We are going to focus on the two categories that are frequently purchased together.","feac477d":"### Data Preprocessing","c924e5b8":"## Product Association","1849b251":"## Category Association","540eaf88":"### Data Analysis","bda36e87":"We will perform association mining on two levels, category wise and then product wise within those categories. This is because there are too many different products for us to perform association mining across all products.","30fc953e":"### Data Analysis","ad057f4a":"# Association Mining","fa926d24":"# Data Exploration\n\nFirst, lets see how many different products we are working with, how many categories and distribution per category. We will translate the names as a first step.","eb14bee9":"### Data Preprocessing"}}