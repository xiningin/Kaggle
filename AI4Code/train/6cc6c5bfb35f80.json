{"cell_type":{"8b3d92c7":"code","1726136c":"code","5d4da6cc":"code","5fb0d571":"code","0916223c":"code","7cbe660e":"code","a5ac3a8c":"code","a70a539e":"code","09c91043":"code","8e5a935d":"code","88ba77ad":"code","0844ffe0":"code","3ae9a498":"code","b339abd2":"code","3bc71fa4":"code","06bb27cd":"code","65f342a0":"code","6cc11592":"code","1e88b7f1":"code","82b93e51":"code","44591ae8":"code","fb7f5563":"code","d0918dc1":"code","0b177273":"code","e63d2357":"code","8317c2af":"code","c356edff":"code","b54dffe4":"markdown","e8025e06":"markdown","0157312b":"markdown","7ba7725e":"markdown","159c274c":"markdown"},"source":{"8b3d92c7":"#importing the relevant libraries\nimport os\nimport shutil\nimport cv2\nimport random\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Conv2D,AvgPool2D,Flatten,Concatenate,Dense,Input,BatchNormalization\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom sklearn.metrics import confusion_matrix\nfrom tqdm import tqdm","1726136c":"data_path='\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images'\n# Getting the classes in which I have to classify my data\nclasses=os.listdir(data_path)\nprint(classes)","5d4da6cc":"#Deleting cell_images from classes variable\nclasses.pop(-1)\nprint(classes)","5fb0d571":"#Setting up the paths for training,validation and testing data\npath='\/kaggle\/data'\ntrain_path=os.path.join(path,'train')\nvalid_path=os.path.join(path,'valid')\ntest_path=os.path.join(path,'test')","0916223c":"#Making a function that will construct the above directories\ndef make_dir():\n    if not os.path.isdir(path):\n        os.mkdir(path)\n        os.mkdir(train_path)\n        os.mkdir(valid_path)\n        os.mkdir(test_path)\n        # Making folder for each class in the train,valid and test directories\n        for target in classes:\n            os.mkdir(os.path.join(train_path,target))\n            os.mkdir(os.path.join(valid_path,target))\n            os.mkdir(os.path.join(test_path,target))\n# This function checks whether the directories have been successfully created\ndef check_dirs():\n    print(f'{path}: {os.path.isdir(path)}')\n    print(f'{train_path}: {os.path.isdir(train_path)}')\n    print(f'{valid_path}: {os.path.isdir(valid_path)}')\n    print(f'{test_path}: {os.path.isdir(test_path)}')\n    for label in classes:\n        print(f'{os.path.join(train_path,label)}: {os.path.isdir(os.path.join(train_path,label))}')\n        print(f'{os.path.join(valid_path,label)}: {os.path.isdir(os.path.join(valid_path,label))}')\n        print(f'{os.path.join(test_path,label)}: {os.path.isdir(os.path.join(test_path,label))}')","7cbe660e":"make_dir()","a5ac3a8c":"check_dirs()","a70a539e":"# Checking the size of the images \ndef check_input_size():\n    for folder in os.listdir(data_path):\n        folder_path=os.path.join(data_path,folder)\n        for file in os.listdir(folder_path):\n            file_path=os.path.join(folder_path,file)\n            image=cv2.imread(file_path)\n            print(f'Shape: {image.shape}')\n            print(f'Maximum pixel value: {np.max(image)}')\n            break\n        break\ncheck_input_size()","09c91043":"# Making functions to load data from data_path into train_path,valid_path and test_path variables\ndef load_train_images(n=7000):\n    for folder in os.listdir(data_path):\n        if folder=='cell_images':\n            continue\n        folder_path=os.path.join(data_path,folder)\n        dest_path=os.path.join(train_path,folder)\n        image_set=random.sample(os.listdir(folder_path),n)\n        print(f'Loading training images for {folder}')\n        for file in tqdm(image_set):\n            file_path=os.path.join(folder_path,file)\n            shutil.copy(file_path,dest_path)\ndef load_valid_images(n=2000):\n    for folder in os.listdir(data_path):\n        if folder=='cell_images':\n            continue\n        folder_path=os.path.join(data_path,folder)\n        dest_path=os.path.join(valid_path,folder)\n        image_set=random.sample(os.listdir(folder_path),n)\n        print(f'Loading the validation images for {folder}')\n        for file in tqdm(image_set):\n            file_path=os.path.join(folder_path,file)\n            shutil.copy(file_path,dest_path)\ndef load_test_images(n=1000):\n    for folder in os.listdir(data_path):\n        if folder=='cell_images':\n            continue\n        folder_path=os.path.join(data_path,folder)\n        dest_path=os.path.join(test_path,folder)\n        image_set=random.sample(os.listdir(folder_path),n)\n        print(f'Loading the test images for {folder}')\n        for file in tqdm(image_set):\n            file_path=os.path.join(folder_path,file)\n            shutil.copy(file_path,dest_path)","8e5a935d":"load_train_images()","88ba77ad":"load_valid_images()","0844ffe0":"load_test_images()","3ae9a498":"batch_size=100\ntarget_size=(128,128)\nepochs=35","b339abd2":"'''I have used an ImageDataGenerator and provided the relevant paths to make the dataset. \nImageDataGen will apply the transformations specified and will divide the images into batches.\nThey are like DataLoaders from PyTorch\n'''\ndatagen=ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input,rescale=1.\/255)\ntrain_data=ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input,rescale=1.\/255,horizontal_flip=True).flow_from_directory(directory=train_path,target_size=target_size,batch_size=batch_size,classes=classes)\nvalid_data=datagen.flow_from_directory(directory=valid_path,target_size=target_size,batch_size=batch_size,classes=classes)\ntest_data=datagen.flow_from_directory(directory=test_path,target_size=target_size,batch_size=batch_size,shuffle=False,classes=classes)","3bc71fa4":"'''I am making a Residual Network, where there is a shortcut connection between the inputs and \noutputs, this connection facilitates the addition of the input to the output. The advantage of \ndoing this is that the our network can now learn complex as well as simple patterns, complex being \nlearnt from the stack of Conv2D layers and simple patterns being learnt through the shortcut connections.\n\nBelow I have defined my own Residual Unit which I will be using in my model.\n'''\nclass ResidualUnit(tf.keras.models.Model):\n    def __init__(self,filters,n_weights=3,kernel_size=3,strides=1):\n        super().__init__()\n        self.model=[]\n        for i in range(n_weights):\n            self.model.append(Conv2D(filters=filters,kernel_size=kernel_size,strides=strides,padding='same',activation='relu'))\n            self.model.append(BatchNormalization())\n        self.model=Sequential(self.model)\n    def call(self,inputs):\n        out=self.model(inputs)\n        out=Concatenate()([inputs,out])\n        return tf.keras.activations.relu(out)","06bb27cd":"'''Making a function that will build my model'''\ndef build_model(n_res=3,size=target_size[0]):\n    steps=int(np.log2(size))\n    model=[]\n    model.append(Input(shape=(*target_size,3)))\n    filters=16\n    for i in range(steps):\n        model.append(ResidualUnit(filters=filters,n_weights=n_res))\n        model.append(AvgPool2D(pool_size=(2,2),strides=2))\n        filters*=2\n    model+=[\n        Flatten(),\n        Dense(units=4096,activation='relu'),\n        Dense(units=4096,activation='relu'),\n        Dense(units=len(classes),activation='softmax')\n    ]\n    return Sequential(model)","65f342a0":"model=build_model(n_res=4)","6cc11592":"model.summary()","1e88b7f1":"ckpt_path='\/kaggle\/ckpt'\nos.mkdir(ckpt_path)","82b93e51":"'''This callback will save the weights of the model with the highest validation accuracy.'''\nmodel_callback=ModelCheckpoint(filepath=ckpt_path,save_weights_only=True,monitor='val_accuracy',save_best_only=True)","44591ae8":"model.compile(optimizer=Adam(lr=0.0003),loss='categorical_crossentropy',metrics=['accuracy'])","fb7f5563":"history=model.fit(x=train_data,batch_size=batch_size,epochs=epochs,verbose=2,validation_data=valid_data,callbacks=[model_callback])","d0918dc1":"'''Loading the weights of the best model'''\nmodel.load_weights(ckpt_path)","0b177273":"def print_accuracy():\n    p=model.predict(test_data)\n    cm=confusion_matrix(y_true=test_data.classes,y_pred=np.argmax(p,axis=-1))\n    acc=cm.trace()\/cm.sum()\n    print(f'Accuracy: {acc*100}')","e63d2357":"print_accuracy()","8317c2af":"val_loss=history.history['val_loss']\ntrain_loss=history.history['loss']","c356edff":"plt.figure()\nplt.plot(train_loss,'bo--')\nplt.plot(val_loss,'ro--')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(['Train','Valid'])\nplt.show()","b54dffe4":"# Making the train,valid and test data","e8025e06":"# Setting up directories to store training,validation and testing data","0157312b":"Refer the structure of a Residual Network [here](https:\/\/shuzhanfan.github.io\/2018\/11\/ResNet\/)","7ba7725e":"# Making the model","159c274c":"# Training and evaluating the performance of the model"}}