{"cell_type":{"0919362e":"code","72a14398":"code","6b829f94":"code","9ddf8790":"code","47f498c1":"code","14c65d50":"code","614ff4ec":"code","464c7681":"code","1512a851":"code","b1dff2cf":"code","a5d05018":"code","c1b581d2":"code","116a8f16":"code","36b59b3b":"code","695e2e10":"code","6db6cabf":"code","16644841":"code","3653862b":"code","9ba3d452":"code","245cc32b":"code","078b958e":"code","a78f9b12":"code","a9626de9":"code","b4de6bd7":"code","9dabafd4":"code","456e40c4":"code","818eb013":"markdown","1cf4f5d4":"markdown","2ec4f589":"markdown","3ec88e5f":"markdown","13fb378e":"markdown","17443b8d":"markdown","aea36edc":"markdown"},"source":{"0919362e":"# importing packages\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","72a14398":"# display images\nfrom PIL import Image\n\n# computer vision package to read dataset\nimport cv2\n\nnormal_image = Image.open('..\/input\/brain-mri-images-for-brain-tumor-detection\/no\/1 no.jpeg')\ntumor_image = Image.open('..\/input\/brain-mri-images-for-brain-tumor-detection\/yes\/Y1.jpg')\n\n# plot images\n# subplotting image data\nfig = plt.figure(figsize=(12,10))\na1 = fig.add_subplot(1,2,1)\nimg_plot = plt.imshow(normal_image, cmap = plt.cm.bone)\na1.set_title('Normal MRI Scan', fontsize=12)\n\na1 = fig.add_subplot(1,2,2)\nimg_plot = plt.imshow(tumor_image, cmap = plt.cm.bone)\na1.set_title('Tumor MRI Scan', fontsize=12)\n","6b829f94":"import os\nyes = os.listdir(\"..\/input\/brain-mri-images-for-brain-tumor-detection\/yes\")\nno = os.listdir(\"..\/input\/brain-mri-images-for-brain-tumor-detection\/no\")","9ddf8790":"data = np.concatenate([yes,no])","47f498c1":"data","14c65d50":"target_yes = np.full(len(yes),1)\ntarget_no = np.full(len(no),0)","614ff4ec":"data_target = np.concatenate([target_yes, target_no])","464c7681":"data_target","1512a851":"img = cv2.imread('..\/input\/brain-mri-images-for-brain-tumor-detection\/yes\/Y1.jpg')\nmri = cv2.resize(img,(64,64))      # size needs to be same for all images before training\nplt.imshow(mri)","b1dff2cf":"#mri # b, g , r format","a5d05018":"# cv2 - It reads in BGR format by default\nb, g, r = cv2.split(mri)\nimg = cv2.merge([r,g,b])\nplt.imshow(img)","c1b581d2":"#img # in b, g, r","116a8f16":"X_data = []\nyes = os.listdir(\"..\/input\/brain-mri-images-for-brain-tumor-detection\/yes\")\n\nfor file in yes:\n    img = cv2.imread(\"..\/input\/brain-mri-images-for-brain-tumor-detection\/yes\/\"+ file)\n    mri = cv2.resize(img,(32,32)) \n    b, g, r = cv2.split(mri)\n    img = cv2.merge([r,g,b])\n    X_data.append(img)  #this will store list of all image data in array","36b59b3b":"no = os.listdir(\"..\/input\/brain-mri-images-for-brain-tumor-detection\/no\")\n\nfor file in no:\n    img = cv2.imread(\"..\/input\/brain-mri-images-for-brain-tumor-detection\/no\/\"+ file)\n    mri = cv2.resize(img,(32,32)) \n    b, g, r = cv2.split(mri)\n    img = cv2.merge([r,g,b])\n    X_data.append(img)","695e2e10":"X = np.squeeze(X_data) # to prepare the data well","6db6cabf":"# 253 - number of images, each image is of shape (32 X 32 x 3)\nX.shape","16644841":"X = X.astype('float32')\nX \/= 255","3653862b":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X, data_target, test_size =0.1, random_state=3)","9ba3d452":"# validation set\nx_train2, x_val, y_train2, y_val = train_test_split(x_train, y_train, test_size =0.15, random_state=3)","245cc32b":"from keras.models import Sequential\nfrom keras.layers import Flatten, Dense, Conv2D, GlobalAveragePooling2D, Dropout, BatchNormalization \nfrom keras.optimizers import Adam\n\n# Transfer learning model\nfrom keras.applications import VGG16","078b958e":"def build_model():\n    # use imagenet = pre-trained model weights called as knowlegde\n    # default shape is 244x244x3, re-declare to the orignal shape as per the data = 32x32x3\n    vgg16_model = VGG16(weights ='imagenet', include_top = False, input_shape =(32,32,3)) #include_top = False since after the layer of CNN\n    \n    # Input Layer\n    model = Sequential()\n    model.add(Conv2D(filters= 3, kernel_size=(3,3), padding='same', input_shape = (32,32,3)))\n\n    # add tranfer learning layer\n    model.add(vgg16_model)\n\n    # Average Pooling\n    model.add(GlobalAveragePooling2D())\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n\n    # Full Connected Layer\n    model.add(Dense(units = 512, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(units = 1, activation='sigmoid'))\n\n    # Learning Rate - Adam\n    adam_optimizer = Adam(learning_rate= 0.001)\n\n    # loss = binary_crossentropy\n    model.compile(optimizer = adam_optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n    \n    return model","a78f9b12":"model = build_model()","a9626de9":"model.summary()","b4de6bd7":"from keras import callbacks\nfilepath = \".\/best_model_mri.hdf5\"\ncheckpoint = callbacks.ModelCheckpoint(filepath, monitor= 'val_loss', save_best_only=True, mode ='min', verbose=1)\ncheckpoint","9dabafd4":"import datetime\nimport keras\nlogdir = os.path.join(\".\/mri_logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\ntensorboard_callback = keras.callbacks.TensorBoard(logdir)","456e40c4":"history = model.fit(x_train2, y_train2, epochs = 200, batch_size = 32, shuffle=True, \n                              validation_data= (x_val, y_val), \n                              callbacks = [checkpoint, tensorboard_callback], verbose = 1) # more epochs as data is small","818eb013":"### Image Data Preparation","1cf4f5d4":"### Using computer vision to read images","2ec4f589":"### Train and Test Data\n* We dont have train and test dataset, we will split our dataset\n* split 10% into test set\n* split the remaing test and train into 15% for validation","3ec88e5f":"### VGG16 16 Model - Transfer Learning\n\n* Default input (224 X 244)\n* We modified into (32 x 32)","13fb378e":"### Tensorboard - Logs","17443b8d":"Why we chose 'yes' first? we gave preference to yes data as 1 in cell[14]  data_target","aea36edc":"### Image Normalization \/ Image Pixel Scaling\n* Divide every pixel by 255"}}