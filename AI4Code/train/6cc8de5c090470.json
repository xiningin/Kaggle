{"cell_type":{"b07630a1":"code","447dd18b":"code","8b19b2f5":"code","19464d0c":"code","d67364d7":"code","1fffc01c":"code","4bd6989c":"code","5b7e8fbc":"code","8740de30":"code","907329a1":"code","154f3e2b":"code","c64cd298":"code","a2708271":"code","558904ec":"code","83f8f463":"code","f6d2882e":"code","0aea47ce":"code","bd7f7981":"code","25b7fa22":"code","4906c5b1":"code","a478b36e":"code","357f0e03":"code","c5be6a3a":"code","3c550410":"code","0b0ec5cb":"code","4690dd1e":"code","7d37c850":"code","01508684":"code","0170f677":"code","bbac80e5":"code","54dd577f":"code","fa74fd9e":"code","0564e69e":"code","e16b400a":"code","e6478acd":"code","39818156":"code","7906f11f":"markdown","327bc333":"markdown","ab05d17a":"markdown"},"source":{"b07630a1":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import rcParams\nimport seaborn as sb\nfrom collections import Counter\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.preprocessing import LabelEncoder,normalize,MinMaxScaler\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix,roc_auc_score,roc_curve\nimport seaborn as sns\n\n\nimport tensorflow as tf","447dd18b":"# import tensorflow as tf\n\n# # GPU device Check.\n# device_name = tf.test.gpu_device_name()\n# if device_name == '\/device:GPU:0':\n#     print('Found GPU at: {}'.format(device_name))\n# else:\n#     raise SystemError('GPU device not found')\n    \n# import torch\n\n# # If there's a GPU available...\n# if torch.cuda.is_available():    \n\n#     # PyTorch use the GPU.    \n#     device = torch.device(\"cuda\")\n\n#     print('There are %d GPU(s) available.' % torch.cuda.device_count())\n\n#     print('We will use the GPU:', torch.cuda.get_device_name(0))\n\n# # If not...\n# else:\n#     print('No GPU available, using the CPU instead.')\n#     device = torch.device(\"cpu\")","8b19b2f5":"# Reading data\ntrain = pd.read_csv('..\/input\/higgs-boson\/training.zip')\ntest = pd.read_csv('..\/input\/higgs-boson\/test.zip')\n\nprint(train.shape,test.shape)","19464d0c":"train","d67364d7":"print(train.columns.values,'\\n')\nprint(test.columns.values)","1fffc01c":"train = train.drop(['Weight'], axis=1)","4bd6989c":"print(train['Label'].value_counts())\n\nrcParams['figure.figsize'] = 10,5\nsb.barplot(x = train['Label'].value_counts().index, y = train['Label'].value_counts().values)\nplt.title('Label counts')\nplt.show()","5b7e8fbc":"# getting dummy variables column\n\nenc = LabelEncoder()\n\ntrain['Label'] = enc.fit_transform(train['Label'])\ntrain.head()","8740de30":"y = train[\"Label\"]\nX = train\nX_test = test","907329a1":"X.set_index(['EventId'],inplace = True)\nX_test.set_index(['EventId'],inplace = True)\nX = X.drop(['Label'], axis=1)\n\nX.head()","154f3e2b":"X_test.head()","c64cd298":"train.describe()","a2708271":"#Normalizing\n\nfrom sklearn.preprocessing import normalize\n\nX = normalize(X)\nX_test = normalize(X_test)","558904ec":"# from sklearn.model_selection import StratifiedKFold\n# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, GlobalAveragePooling2D,Activation, BatchNormalization\n# from tensorflow.keras.models import Sequential\n\n# BATCH_SIZE = 8\n# n_fold = 5\n\n# kfold = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)\n# cvscores = []  \n# for train, test in kfold.split(X, y): \n#   # create model \n#     model = Sequential() \n#     model.add(Dense(1024, input_dim=30, activation='relu'))\n#     model.add(Dropout(0.8)) \n#     model.add(Dense(1024, activation='relu')) \n#     model.add(Dropout(0.8)) \n#     model.add(Dense(512, activation='relu')) \n#     model.add(Dropout(0.8)) \n#     model.add(Dense(2,activation='softmax'))\n#     # Compile model\n#     opt = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, decay=0.01, amsgrad=False)\n#     model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n#     # Fit the model\n#     model.fit(X[train], y[train],validation_data=(X[train], y[train]), epochs=10, batch_size=BATCH_SIZE, verbose=0)\n#     # evaluate the model\n#     scores = model.evaluate(X[test], y[test], verbose=0)\n#     print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n#     cvscores.append(scores[1] * 100) \n      \n#     #prediction     \n#     prediction = model.predict(X_test, batch_size=BATCH_SIZE, verbose=0)   \n    \n# print(\"%.2f%% (+\/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores))) ","83f8f463":"#K Fold Cross Validation\n\nfrom sklearn.model_selection import KFold\n\n\nkf = KFold(n_splits=5, random_state=2020, shuffle=True)\n\nfor train_index, val_index in kf.split(X):\n    print(\"TRAIN:\", train_index, \"TEST:\", val_index)\n    X_train, X_val = X[train_index], X[val_index]\n    y_train, y_val = y[train_index], y[val_index]","f6d2882e":"# import xgboost as xgb\n\n# dtrain = xgb.DMatrix(X_train, label=y_train)\n# dvalid = xgb.DMatrix(X_val, label=y_val)\n# watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n\n# xgb_pars = {'min_child_weight': 100, 'eta': 0.04, 'colsample_bytree': 0.8, 'max_depth': 100,\n#             'subsample': 0.75, 'lambda': 2, 'nthread': -1, 'booster' : 'gbtree', 'silent': 1, 'gamma' : 0,\n#             'eval_metric': 'rmse', 'objective': 'reg:linear'}    \n\n# model = xgb.train(xgb_pars, dtrain, 500, watchlist, early_stopping_rounds=250,\n#                   maximize=False, verbose_eval=15) ","0aea47ce":"# dtest = xgb.DMatrix(X_test)\n\n# prediction = model.predict(dtest)  ","bd7f7981":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_val.shape)\nprint(y_val.shape)","25b7fa22":"#reshape for rnn\n\nX_train = X_train.reshape(-1, 1, 30)\nX_val  = X_val.reshape(-1, 1, 30)\ny_train = y_train.values #convert pd to array\ny_train = y_train.reshape(-1, 1,)\ny_val = y_val.values #convert pd to array\ny_val = y_val.reshape(-1, 1,)","4906c5b1":"X_train.shape","a478b36e":"from tensorflow.keras.layers import Conv2D,LSTM,LeakyReLU, MaxPooling2D,Concatenate,Input, Dropout, Flatten, Dense, GlobalAveragePooling2D,Activation, BatchNormalization\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.models import Model\n\n\n  # create model\n    \n\n#input \ninput_layer = Input(shape=(1,30))\nmain_rnn_layer = LSTM(64, return_sequences=True, recurrent_dropout=0.2)(input_layer)\n\n    \n#output\nrnn = LSTM(32)(main_rnn_layer)\ndense = Dense(128)(rnn)\ndropout_c = Dropout(0.3)(dense)\nclasses = Dense(1, activation= LeakyReLU(alpha=0.1),name=\"class\")(dropout_c)\n\nmodel = Model(input_layer, classes)\n\n# Compile model\ncallbacks = [ReduceLROnPlateau(monitor='val_loss', patience=4, verbose=1, factor=0.6),\n             EarlyStopping(monitor='val_loss', patience=20),\n             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\nmodel.compile(loss=[tf.keras.losses.MeanSquaredLogarithmicError(),tf.keras.losses.MeanSquaredLogarithmicError()], optimizer=\"adam\")\n\n\nmodel.summary()\n# Fit the model\nhistory = model.fit(X_train, y_train, \n          epochs = 500, \n          batch_size = 16, \n          validation_data=(X_val,  y_val), \n          callbacks=callbacks)\n","357f0e03":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Loss over epochs')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='best')\nplt.show()","c5be6a3a":"X_test.shape","3c550410":"model.load_weights(\"best_model.h5\")\n\ntest = X_test #convert pd to array\ntest = test.reshape(-1, 1,30)\n\n\npredictions = model.predict(test)","0b0ec5cb":"print(predictions.shape)\nprint(predictions)","4690dd1e":"sub = pd.read_csv('..\/input\/higgs-boson\/random_submission.zip')","7d37c850":"sub","01508684":"type(predictions)","0170f677":"pred = np.where(predictions > 0.5, 1, 0)\npred","bbac80e5":"test_predict = pd.Series(pred[:,0])","54dd577f":"test_predict","fa74fd9e":"test_predict = pd.DataFrame({\"EventId\":sub['EventId'],\"RankOrder\":sub['RankOrder'],\"Class\":test_predict})\ntest_predict","0564e69e":"test_predict = test_predict.replace(1,'s')\ntest_predict = test_predict.replace(0,'b')\ntest_predict","e16b400a":"test_predict['RankOrder'] = test_predict['Class'].argsort().argsort() + 1 # +1 to start at 1","e6478acd":"test_predict","39818156":"test_predict.to_csv(\"submission.csv\",index=False)","7906f11f":"2- XGB","327bc333":"3-RNN","ab05d17a":"1-DNN"}}