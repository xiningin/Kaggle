{"cell_type":{"97ec112b":"code","fb48266a":"code","b6920a57":"code","4abddabb":"code","1da0ee56":"code","0baebc59":"code","4f210838":"code","a85f6ec7":"code","ab6ee6ed":"code","ea839d2c":"code","98c828bf":"code","50fecbba":"code","17da6092":"code","a7e0c339":"code","29e0848d":"code","529c5f15":"code","92b569a5":"code","20dda8fc":"code","5c0da6cd":"code","da0ae800":"code","acabd64b":"code","cb56f149":"code","4c9bf272":"code","9e6fbe80":"code","dec03062":"code","75a62085":"code","c14c00c6":"code","b26166b7":"markdown","109abe1f":"markdown","13f3a534":"markdown","7b0a999f":"markdown","58b4583a":"markdown","8cef673f":"markdown","cdd1b173":"markdown","875622e9":"markdown","1ad42faf":"markdown","3474c98a":"markdown","4f746c67":"markdown","fd72f237":"markdown","fe75aad7":"markdown","146299f5":"markdown","fb6cab9d":"markdown","e2139214":"markdown","c2c7b714":"markdown","15d869ba":"markdown"},"source":{"97ec112b":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing import sequence\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","fb48266a":"train_data=pd.read_csv('..\/input\/nlp-getting-started\/train.csv')","b6920a57":"train_data.info()","4abddabb":"train_data","1da0ee56":"word_len=[]\nfor i in range(len(train_data)):\n    word_len.append(len(train_data.text.values[i].split(' ')))    ","0baebc59":"plt.figure(figsize=(12,6))\nsns.countplot(word_len)\nplt.xlabel(\"Word lengths:\")\nplt.ylabel('Counts:')\nplt.title('Train Data \\n Max length='+str(max(word_len)))\nplt.show()","4f210838":"plt.figure(figsize=(10,8))\nsns.countplot(train_data.target)\nplt.title('Count for Zeros:'+str(train_data.target.value_counts()[0])+'\\n'+\n         'Count for Ones:'+str(train_data.target.value_counts()[1]))\nplt.show()","a85f6ec7":"train_data=train_data.drop('keyword',axis=1)\ntrain_data=train_data.drop('location',axis=1)","ab6ee6ed":"Y_train=train_data.target\nX_train=train_data.text","ea839d2c":"Y_train=tf.reshape(Y_train,(-1,1))","98c828bf":"Y_train","50fecbba":"max_words = 100000\nmax_len = 100\n\ntok = Tokenizer(num_words=max_words)\ntok.fit_on_texts(X_train)\nsequences = tok.texts_to_sequences(X_train)\nsequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)","17da6092":"sequences_matrix[1729]","a7e0c339":"model=tf.keras.Sequential()\n\nmodel.add(tf.keras.layers.Input(shape=[max_len]))\nmodel.add(tf.keras.layers.Embedding(max_words,128,input_length=max_len))    \n\nmodel.add(tf.keras.layers.LSTM(200, return_sequences=True))\nmodel.add(tf.keras.layers.Dropout(0.5))\n\nmodel.add(tf.keras.layers.LSTM(200,return_sequences=True))\nmodel.add(tf.keras.layers.Dropout(0.5))\n\nmodel.add(tf.keras.layers.LSTM(200))\nmodel.add(tf.keras.layers.Dropout(0.5))\n          \nmodel.add(tf.keras.layers.Dense(256))\nmodel.add(tf.keras.layers.Dropout(0.5))\n\nmodel.add(tf.keras.layers.Dense(1,activation='sigmoid')) #output layer","29e0848d":"model.summary()","529c5f15":"model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['acc'])","92b569a5":"hist=model.fit(sequences_matrix,Y_train,batch_size=64,epochs=30)","20dda8fc":"model.evaluate(sequences_matrix,Y_train)","5c0da6cd":"plt.plot(hist.history['loss'],'g')\nplt.xlabel('Epochs:')\nplt.ylabel('Loss:')\nplt.show()","da0ae800":"#accuracy\n\nplt.plot(hist.history['acc'],'r')\nplt.xlabel('Epochs:')\nplt.ylabel('Accuracy:')\nplt.show()","acabd64b":"test_data=pd.read_csv('..\/input\/nlp-getting-started\/test.csv')","cb56f149":"X_test=test_data.text","4c9bf272":"tok = Tokenizer(num_words=max_words)\ntok.fit_on_texts(X_test)\nsequences_test = tok.texts_to_sequences(X_test)\nsequences_matrix_test = sequence.pad_sequences(sequences_test,maxlen=max_len)","9e6fbe80":"pred=model.predict(sequences_matrix_test)","dec03062":"pred=(pred>0.5)*1","75a62085":"p=pd.DataFrame()\np['id']=test_data['id']\np['target']=pred","c14c00c6":"p.to_csv('.\/Submission_sachin.csv',index=False)","b26166b7":"# Step 2: Read Train data (Descriptive and Exploratory analysis)","109abe1f":"# Step 5: Training the model","13f3a534":"# Step 4: Creating RNN Model ","7b0a999f":"## Tokenizing the train text data","58b4583a":"# Step 6: Metrics and results","8cef673f":"## Predict","cdd1b173":"## As we can see there are 2 columns that contain null values (keyword and location), we will drop them since anyways we will only use the text and target columns","875622e9":"## This step is required because i have used sigmoid activation function at the output layer. ","1ad42faf":"# Step 1: Import required libraries.","3474c98a":"# Step 3: Pre-processing","4f746c67":"# Step 7: Prediction on test data","fd72f237":"## Visualizing the number of words in sentences\n","fe75aad7":"## Define X_train and Y_train data.","146299f5":"## Visualizing Train loss and accuracy epoch wise","fb6cab9d":"## Submission","e2139214":"## Train Accuracy","c2c7b714":"## Visualizing the number of instances in target field","15d869ba":"## Reshaping Y_train so that it's easier to process it when using LSTM."}}