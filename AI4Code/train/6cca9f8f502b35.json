{"cell_type":{"377a4c25":"code","93421cf6":"code","abec4228":"code","28d75403":"code","840f9986":"code","4aaf45e9":"code","6fe894ca":"code","0974ea90":"code","a0d127d2":"code","42c817df":"code","b34662af":"code","dd55c3e6":"code","cee17529":"code","46b671aa":"code","a23c0e19":"code","7f1b5fc0":"code","7bebe44b":"code","5f92c5a6":"code","e2259760":"code","502c16dd":"code","6a72c575":"code","4905e715":"code","446a1acf":"code","26b6e368":"code","e77d0d05":"code","2091c220":"code","fa47aa82":"code","ce8bd49e":"code","4d239258":"code","44fe24d3":"code","07fbc659":"code","13abf237":"markdown","686896bb":"markdown","87a52440":"markdown","fd668e11":"markdown","37e5fabb":"markdown","f8ba9d60":"markdown","daba5574":"markdown","cb921202":"markdown","e3d8292b":"markdown","7bc680b5":"markdown","c7b7bb33":"markdown","42a6c4f4":"markdown","893d2b1f":"markdown","437064db":"markdown","9c2e3063":"markdown","ce997c7b":"markdown","701de25d":"markdown","dd8cf9f4":"markdown","0789d3fb":"markdown","114b79d0":"markdown","b4ff3c2a":"markdown","679b455a":"markdown","93524903":"markdown"},"source":{"377a4c25":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pylab as plt\nfrom IPython.display import HTML\nimport warnings\npd.set_option('max_columns', 100)\nwarnings.filterwarnings(\"ignore\")\nsns.set_style(\"whitegrid\")\nmy_pal = sns.color_palette(n_colors=10)","93421cf6":"!ls -GFlash ..\/input\/data-science-bowl-2019\/","abec4228":"# Read in the data CSV files\ntrain = pd.read_csv('..\/input\/data-science-bowl-2019\/train.csv')\ntrain_labels = pd.read_csv('..\/input\/data-science-bowl-2019\/train_labels.csv')\ntest = pd.read_csv('..\/input\/data-science-bowl-2019\/test.csv')\nspecs = pd.read_csv('..\/input\/data-science-bowl-2019\/specs.csv')\nss = pd.read_csv('..\/input\/data-science-bowl-2019\/sample_submission.csv')","28d75403":"train_ = train.sample(1000000) #sample 1M observations","840f9986":"train_labels.head()","4aaf45e9":"train_labels.groupby('accuracy_group')['game_session'].count() \\\n    .plot(kind='barh', figsize=(15, 5), title='Target (accuracy group)')\nplt.show()","6fe894ca":"sns.pairplot(train_labels, hue='accuracy_group')\nplt.show()","0974ea90":"train.head()","a0d127d2":"train['event_id_as_int'] = train['event_id'].apply(lambda x: int(x, 16))\ntrain['game_session_as_int'] = train['game_session'].apply(lambda x: int(x, 16))","42c817df":"# Format and make date \/ hour features\ntrain['timestamp'] = pd.to_datetime(train['timestamp'])\ntrain['date'] = train['timestamp'].dt.date\ntrain['hour'] = train['timestamp'].dt.hour\ntrain['weekday_name'] = train['timestamp'].dt.weekday_name\n# Same for test\ntest['timestamp'] = pd.to_datetime(test['timestamp'])\ntest['date'] = test['timestamp'].dt.date\ntest['hour'] = test['timestamp'].dt.hour\ntest['weekday_name'] = test['timestamp'].dt.weekday_name","b34662af":"print(f'Train data has shape: {train.shape}')\nprint(f'Test data has shape: {test.shape}')","dd55c3e6":"train.groupby('date')['event_id'] \\\n    .agg('count') \\\n    .plot(figsize=(15, 3),\n         title='Numer of Event Observations by Date',\n         color=my_pal[2])\nplt.show()\ntrain.groupby('hour')['event_id'] \\\n    .agg('count') \\\n    .plot(figsize=(15, 3),\n         title='Numer of Event Observations by Hour',\n         color=my_pal[1])\nplt.show()\ntrain.groupby('weekday_name')['event_id'] \\\n    .agg('count').T[['Monday','Tuesday','Wednesday',\n                     'Thursday','Friday','Saturday',\n                     'Sunday']].T.plot(figsize=(15, 3),\n                                       title='Numer of Event Observations by Day of Week',\n                                       color=my_pal[3])\nplt.show()","cee17529":"print(train['event_data'][4])\nprint(train['event_data'][5])","46b671aa":"train['installation_id'].nunique()","a23c0e19":"train.groupby('installation_id') \\\n    .count()['event_id'] \\\n    .plot(kind='hist',\n          bins=40,\n          color=my_pal[4],\n          figsize=(15, 5),\n         title='Count of Observations by installation_id')\nplt.show()","7f1b5fc0":"train.groupby('installation_id') \\\n    .count()['event_id'] \\\n    .apply(np.log1p) \\\n    .plot(kind='hist',\n          bins=40,\n          color=my_pal[6],\n         figsize=(15, 5),\n         title='Log(Count) of Observations by installation_id')\nplt.show()","7bebe44b":"train.groupby('installation_id') \\\n    .count()['event_id'].sort_values(ascending=False).head(5)","5f92c5a6":"train.query('installation_id == \"f1c21eda\"') \\\n    .set_index('timestamp')['event_code'] \\\n    .plot(figsize=(15, 5),\n          title='installation_id #f1c21eda event Id - event code vs time',\n         style='.',\n         color=my_pal[8])\nplt.show()","e2259760":"train.groupby('event_code') \\\n    .count()['event_id'] \\\n    .sort_values() \\\n    .plot(kind='bar',\n         figsize=(15, 5),\n         title='Count of different event codes.')\nplt.show()","502c16dd":"train['game_time'].apply(np.log1p) \\\n    .plot(kind='hist',\n          figsize=(15, 5),\n          bins=100,\n          title='Log Transform of game_time',\n          color=my_pal[1])\nplt.show()","6a72c575":"train.groupby('title')['event_id'] \\\n    .count() \\\n    .sort_values() \\\n    .plot(kind='barh',\n          title='Count of Observation by Game\/Video title',\n         figsize=(15, 15))\nplt.show()","4905e715":"# Chow Time Video\nHTML('<iframe width=\"560\" height=\"315\" src=\"https:\/\/www.youtube.com\/embed\/tvRtFqOqa-Y\" frameborder=\"0\" allow=\"accelerometer; \\\n        autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen><\/iframe>')","446a1acf":"# Scrub-a-Dub\nHTML('<iframe width=\"560\" height=\"315\" src=\"https:\/\/www.youtube.com\/embed\/kkNzO2QzWaQ\" frameborder=\"0\" allow=\"accelerometer; \\\n    autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen><\/iframe>')","26b6e368":"train.groupby('type')['event_id'] \\\n    .count() \\\n    .sort_values() \\\n    .plot(kind='bar',\n          figsize=(15, 4),\n          title='Count by Type',\n          color=my_pal[2])\nplt.show()","e77d0d05":"train.groupby('world')['event_id'] \\\n    .count() \\\n    .sort_values() \\\n    .plot(kind='bar',\n          figsize=(15, 4),\n          title='Count by World',\n          color=my_pal[3])\nplt.show()","2091c220":"train['log1p_game_time'] = train['game_time'].apply(np.log1p)","fa47aa82":"fig, ax = plt.subplots(figsize=(15, 5))\nsns.catplot(x=\"type\", y=\"log1p_game_time\",\n            data=train.sample(10000), alpha=0.5, ax=ax);\nax.set_title('Distribution of log1p(game_time) by Type')\nplt.close()\nplt.show()\nfig, ax = plt.subplots(figsize=(15, 5))\nsns.catplot(x=\"world\", y=\"log1p_game_time\",\n            data=train.sample(10000), alpha=0.5, ax=ax);\nax.set_title('Distribution of log1p(game_time) by World')\nplt.close()\nplt.show()","ce8bd49e":"specs.head()","4d239258":"specs.describe()","44fe24d3":"# First Attempt... still working to fully understand the problem\nfrom sklearn.model_selection import train_test_split\n\n# Define cleared or not cleared\n# \ntrain['cleared'] = True\ntrain.loc[train['event_data'].str.contains('false') & train['event_code'].isin([4100, 4110]), 'cleared'] = False\n\ntest['cleared'] = True\ntest.loc[test['event_data'].str.contains('false') & test['event_code'].isin([4100, 4110]), 'cleared'] = False\n\naggs = {'hour': ['max','min','mean'],\n        'cleared': ['mean']}\n\ntrain_aggs = train.groupby('installation_id').agg(aggs)\ntest_aggs = test.groupby('installation_id').agg(aggs)\ntrain_aggs = train_aggs.reset_index()\ntest_aggs = test_aggs.reset_index()\ntrain_aggs.columns = ['_'.join(col).strip() for col in train_aggs.columns.values]\ntest_aggs.columns = ['_'.join(col).strip() for col in test_aggs.columns.values]\ntrain_aggs = train_aggs.rename(columns={'installation_id_' : 'installation_id'})","07fbc659":"# Hmmm... not 1:1\ntrain_aggs.merge(train_labels[['installation_id','accuracy_group']],\n                 how='left')","13abf237":"Lets looks at some of the installation_ids with the highest counts. We see some installation_ids have tens of thousands of observations!","686896bb":"# train.csv \/ test.csv\nThe data provided in these files are as follows:\n- `event_id` - Randomly generated unique identifier for the event type. Maps to event_id column in specs table.\n- `game_session` - Randomly generated unique identifier grouping events within a single game or video play session.\n- `timestamp` - Client-generated datetime\n- `event_data` - Semi-structured JSON formatted string containing the events parameters. Default fields are: event_count, event_code, and game_time; otherwise - fields are determined by the event type.\n- `installation_id` - Randomly generated unique identifier grouping game sessions within a single installed application instance.\n- `event_count` - Incremental counter of events within a game session (offset at 1). Extracted from event_data.\n- `event_code` - Identifier of the event 'class'. Unique per game, but may be duplicated across games. E.g. event code '2000' always identifies the 'Start Game' event for all games. Extracted from event_data.\n- `game_time` - Time in milliseconds since the start of the game session. Extracted from event_data.\n- `title` - Title of the game or video.\n- `type` - Media type of the game or video. Possible values are: 'Game', 'Assessment', 'Activity', 'Clip'.\n- `world` - The section of the application the game or video belongs to. Helpful to identify the educational curriculum goals of the media. Possible values are: 'NONE' (at the app's start screen), TREETOPCITY' (Length\/Height), 'MAGMAPEAK' (Capacity\/Displacement), 'CRYSTALCAVES' (Weight).","87a52440":"First we will see what files we are given to work with. Note the `train.csv` file is quite large at 3.7G.\nFrom the data description we know:\n- `train.csv` & `test.csv` : These are the main data files which contain the gameplay events.\n- `specs.csv` : This file gives the specification of the various event types.\n- `train_labels.csv` : This file demonstrates how to compute the ground truth for the assessments in the training set.\n- `sample_submission.csv` : A sample submission in the correct format.","fd668e11":"Because the training data is so large, we will take a random sample of it for plotting. Since we are doing this at random it will speed up the time it takes to plot, and should still give us a a good view of the data's format.","37e5fabb":"lets take a closer look at the event codes `4070` and `4030`\n- We notice that event 4070 and 4030 always comes with coordinates (x, y) and stage_width.\n- Possibly they could be marking acheivements or something related to position on the screen.\nThese events look like this:\n```\n{\"size\":0,\"coordinates\":{\"x\":782,\"y\":207,\"stage_width\":1015,\"stage_height\":762},\"event_count\":55,\"game_time\":34324,\"event_code\":4030}\n```","f8ba9d60":"## The target.\nFirst we will look at the target we intend to predict.\n\nWe are told: *The intent of the competition is to use the gameplay data to forecast how many attempts a child will take to pass a given assessment (an incorrect answer is counted as an attempt).*\nThe outcomes in this competition are grouped into 4 groups (labeled accuracy_group in the data):\n- 3: the assessment was solved on the first attempt\n- 2: the assessment was solved on the second attempt\n- 1: the assessment was solved after 3 or more attempts\n- 0: the assessment was never solved\n","daba5574":"Wow, 50000+ events for a single `installation_id`. Lets take a closer look at the id with the most observations. Not exactly sure what I'm looking at here. But it looks like this `installation_id` spans a long duration (over one month). Could this be installed by a bot? The use history does not look natural.","cb921202":"## game_time\n- Time in milliseconds since the start of the game session. Extracted from event_data.\n- The `log1p` transform shows a somewhat normal distribution with a peak at zero.","e3d8292b":"## Video Examples of the Gameplay\nIts helpful to see what the games actually look like. Here are a few youtube videos showing gameplay of the more popular titles.","7bc680b5":"# Baseline Model\n\nWe are told in the data description that:\n- The file train_labels.csv has been provided to show how these groups would be computed on the assessments in the training set.\n- Assessment attempts are captured in event_code 4100 for all assessments except for Bird Measurer, which uses event_code 4110. \n- If the attempt was correct, it contains \"correct\":true.\n\nWe also know:\n- The intent of the competition is to **use the gameplay data to forecast how many attempts a child will take to pass a given assessment** (an incorrect answer is counted as an attempt). \n- Each application install is represented by an installation_id. This will typically correspond to one child, but you should expect noise from issues such as shared devices.\n- **In the training set, you are provided the full history of gameplay data.**\n- In the test set, we have truncated the history after the start event of a single assessment, chosen randomly, for which you must predict the number of attempts.\n- Note that the training set contains many installation_ids which never took assessments, whereas every installation_id in the test set made an attempt on at least one assessment.","c7b7bb33":"## log(game_time) vs game\/video categories ","42a6c4f4":"# event_data\nThis looks to have most of the interesting data about the event. It is in JSON format which isn't easy to wrangle in a tabular way. We need to be clever when parsing this data. They have already parsed some of this data for us like `event_count` and `event_code`.","893d2b1f":"# specs.csv\nThe `specs.csv` gives us more information about what the event ids represent.\n- There are 386 unique event_ids\n- 168 unique info\n- 191 unique args\n- info and args columns","437064db":"## Game\/Video type\n- Media type of the game or video. Possible values are: 'Game', 'Assessment', 'Activity', 'Clip'.\n- Most are games, next are activities\n- Clips are the least common","9c2e3063":"## timestamp\nLets see how many observations we have over time. Are they all in the same\/similar time zone?\n- Looks like number of observations rises over time. Steep pickup and dropoff at the start\/end\n- Much less use during the middle of the night hours. Use increases during the day with a slow reduction in use around midnight. We don't know how the timestamp relates to time zones for different users.\n- More users on Thursday and Friday. ","ce997c7b":"Thngs to note about the taget:\n- Accuracy of 100% goes to group 3\n- Accuracy of ~50% goes to group 2\n- Not finishing goes to group 0\n- Group 1 looks to have the most variation","701de25d":"## event_id & game_session\nThey say it's randomly generated, but is that true? Looks to be hex, lets convert it to an integer. Plotting shows nothign really interesting.","dd8cf9f4":"## event_code\n- Identifier of the event 'class'. Unique per game, but may be duplicated across games. E.g. event code '2000' always identifies the 'Start Game' event for all games. Extracted from event_data.","0789d3fb":"## installation_id *important - predictions are grouped by these*\n- Randomly generated unique identifier grouping game sessions within a single installed application instance.\n- We will be predicting based off of these IDs\n- The training set has exactly 17000 unique `installation_ids`","114b79d0":"Lets take a log transform of this count to we can more easily see what the distribution of counts by `insallation_id` looks like","b4ff3c2a":"# 2019 Data Science Bowl\n## A Simple Introduction\n\ntl;dr\n\n*In this challenge, you\u2019ll use anonymous gameplay data, including knowledge of videos watched and games played, from the PBS KIDS Measure Up! app, a game-based learning tool developed as a part of the CPB-PBS Ready To Learn Initiative with funding from the U.S. Department of Education. Competitors will be challenged to predict scores on in-game assessments and create an algorithm that will lead to better-designed games and improved learning outcomes. *\n\n**\nNote that this is a synchronous rerun code competition and the private test set has approximately 8MM rows. You should be mindful of memory in your notebooks to avoid submission errors.** \ud83d\ude05","679b455a":"## World\n- The section of the application the game or video belongs to. Helpful to identify the educational curriculum goals of the media.\n- Possible values are: 'NONE' (at the app's start screen), TREETOPCITY' (Length\/Height), 'MAGMAPEAK' (Capacity\/Displacement), 'CRYSTALCAVES' (Weight).","93524903":"## Game\/Video titles\n- Chow Time is very popular, along with Sandcastle Builder, Scrub-A-Dub, and Bottle Filler\n- After that there is a steep dropoff\n- Assessment's are in the 200000 count range.\n- Games with levels are less frequent\n- Some games or titles (maybe videos?) at the bottom are very infrequently seen.\n\nSome examples of the top games:\nChow Time:\nhttps:\/\/www.youtube.com\/watch?v=tvRtFqOqa-Y\n\n"}}