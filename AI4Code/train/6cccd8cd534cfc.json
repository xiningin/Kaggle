{"cell_type":{"3cb9107e":"code","60532114":"code","4bc7c8cd":"code","d00b97c6":"code","52558acb":"code","1fb2ffdc":"code","118b2376":"code","0778d0a8":"code","33d0ce79":"code","eb089f32":"code","d0ff25cc":"code","912534bd":"code","6edd170a":"code","f110a339":"code","da93eb2b":"code","e428bf91":"code","97484ec4":"code","d869e7dc":"code","9a8ee1e0":"code","122f06b7":"code","fd7d6b06":"code","8f4c3d03":"code","ee236f32":"code","e856d184":"code","1b77177c":"code","beb7b0dc":"markdown","8a7a485b":"markdown","7e2a937b":"markdown","3ef91291":"markdown","47dbec2a":"markdown","6982f820":"markdown","3e83727b":"markdown","a48b7b85":"markdown","d0d6be8d":"markdown"},"source":{"3cb9107e":"import numpy as np\nimport pandas as pd \nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.impute import SimpleImputer\nimport os","60532114":"train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv', index_col=[0])\ntrain.info()","4bc7c8cd":"object_cols = ['MSZoning', 'Street', 'Utilities', 'KitchenQual', 'ExterQual', 'SaleCondition', 'SaleType', 'GarageCond', 'Functional']","d00b97c6":"train[object_cols].isna().sum()","52558acb":"train[object_cols] = train[object_cols].fillna(value = 'NA')\ntrain[object_cols].isna().sum()","1fb2ffdc":"from sklearn.preprocessing import OneHotEncoder\n\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_cols = pd.DataFrame(OH_encoder.fit_transform(train[['MSZoning', 'SaleType']]))\n\nOH_cols.index = train.index\n\nnum_train = train.drop(['MSZoning', 'SaleType'], axis=1)\n\ntrain_encoded = pd.concat([num_train, OH_cols], axis=1)","118b2376":"object_cols_label_encode = ['Street', 'Utilities', 'KitchenQual', 'ExterQual', 'SaleCondition', 'GarageCond', 'Functional']","0778d0a8":"from sklearn.preprocessing import LabelEncoder\n\n# Apply label encoder to each column with categorical data\nlabel_encoder = LabelEncoder()\nfor col in object_cols_label_encode:\n    train_encoded[col] = label_encoder.fit_transform(train_encoded[col])","33d0ce79":"train_encoded[object_cols_label_encode].info()","eb089f32":"train_encoded.select_dtypes(exclude = 'object').info()","d0ff25cc":"imputer = SimpleImputer()\ntrain_dropped = train_encoded.select_dtypes(exclude = 'object')\ntrain_imputed = pd.DataFrame(imputer.fit_transform(train_dropped))\ntrain_imputed.columns = train_dropped.columns\ntrain_imputed.info()","912534bd":"corr = train_imputed.corr()\ncorr.style.background_gradient(cmap='coolwarm', axis = None).set_precision(2)","6edd170a":"train_y = train_imputed.SalePrice\n\nfeatures = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 'OverallQual', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'ExterQual', 'BsmtFinSF1', 'GarageArea', 'GarageCars', 'Fireplaces', 'GarageYrBlt', 'KitchenQual', 'TotRmsAbvGrd', 'TotalBsmtSF', '1stFlrSF', 'FullBath', 'GrLivArea']\ntrain_x = train_imputed[features]\n\ntrain_y.describe()","f110a339":"train_x.info()","da93eb2b":"train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, random_state=1)\nmodel = RandomForestRegressor(random_state=0)\nmodel.fit(train_x, train_y)","e428bf91":"val_predictions = model.predict(val_x)\nval_mae = mean_absolute_error(val_predictions, val_y)\nprint(\"Mean absolute error for Random Forest Regression: {:,.0f}\".format(val_mae))","97484ec4":"test = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\ntest.info()","d869e7dc":"test[object_cols].isna().sum().value_counts","9a8ee1e0":"test[object_cols] = test[object_cols].fillna(value = 'NA')\ntest[object_cols].isna().sum()","122f06b7":"OH_cols = pd.DataFrame(OH_encoder.fit_transform(test[['MSZoning', 'SaleType']]))\n\nOH_cols.index = test.index\n\nnum_test = test.drop(['MSZoning', 'SaleType'], axis=1)\n\ntest_encoded = pd.concat([num_test, OH_cols], axis=1)","fd7d6b06":"test_encoded[object_cols_label_encode].info()","8f4c3d03":"for col in object_cols_label_encode:\n    test_encoded[col] = label_encoder.fit_transform(test_encoded[col].astype(str))","ee236f32":"test_dropped = test_encoded.select_dtypes(exclude = 'object')\ntest_imputed = pd.DataFrame(imputer.fit_transform(test_dropped))\ntest_imputed.columns = test_dropped.columns\ntest_imputed.info()","e856d184":"test_x = test_imputed[features]\ntest_x.info()","1b77177c":"predictions = model.predict(test_x)\n\noutput = pd.DataFrame({'Id': test.Id,\n                       'SalePrice': predictions})\noutput.to_csv('submission.csv', index=False)","beb7b0dc":"Now to the encoding.\n\nFor MSZoning and SaleType we're gonna do use OneHotEncoder","8a7a485b":"Now some imputation.","7e2a937b":"Now to the model. We're gonna do the regression with Random Forest Regressor.\n\nTo select our independent variables we're going to chart a correlation matrix and choose those variables, which correlation with SalePrice is greater than 0,45. ","3ef91291":"Let's check for missing values and deal with them","47dbec2a":"We now can divide our RandomForestRegressor into training and validation subsets and fit the model.","6982f820":"Now we can use the model for prediction of SalePrice in the test dataset. We're gonna load the data, handle the missing values the same way as before, and run the model using the same set of features.","3e83727b":"That's the end of it now. Looks ugly but it's honest work. thanks.","a48b7b85":"I'm going to include some of categorical variables in the model. By looking at the data description I decided to keep:\nMSZoning, \nStreet,\nUtilities,\nKitchenQual,\nExterQual,\nSaleCondition,\nSaleType,\nGarageCond,\nFunctional.","d0d6be8d":"...and for the rest LabelEncoder will do the job"}}