{"cell_type":{"3a23b817":"code","07b57140":"code","fe9082ef":"code","498fa9f0":"code","415eb902":"code","411d83bf":"code","7e06cbcc":"code","1c7b4ce9":"code","968a1085":"code","a7e8bcd5":"code","d26f4c08":"code","a898aa5d":"code","f6e83fd8":"code","66af61c0":"code","19c074a1":"code","842b453e":"code","73bc5b13":"code","18374053":"code","8ba15766":"code","1e4a77fc":"code","1cf54859":"code","eb7076bc":"code","357b2760":"code","218a22f5":"code","2d735a4c":"code","1443e622":"code","7849963d":"code","e8e102c3":"code","d18605e4":"code","54bc2bae":"code","bc0bd583":"code","3ce5eae9":"code","11b253bd":"code","598dd792":"code","75796b90":"code","623fbe96":"code","7c7c3df5":"code","295d3ec6":"code","8db70b63":"code","b37bbdab":"code","f6c3a437":"code","3af657c6":"code","fbc0e450":"code","c1c1f630":"code","c84dd872":"code","7e93cd7f":"markdown","1ef2bd56":"markdown","2bc48d4b":"markdown","7e8fc909":"markdown","96b5e7db":"markdown","475ee722":"markdown","696395bf":"markdown","570c8cf7":"markdown","34b64ae5":"markdown","c75da56a":"markdown","3db4719b":"markdown","8c1d08b1":"markdown","2bd309ad":"markdown","e6940f1a":"markdown","0a017173":"markdown","2f1614ba":"markdown","b3a31606":"markdown","855404be":"markdown","039a9550":"markdown","35658f4f":"markdown","33126350":"markdown","86cdf8b7":"markdown","689d2fb1":"markdown","a0391e43":"markdown","db3740b8":"markdown","fc72a843":"markdown","55549fff":"markdown","2aea3268":"markdown","69d7eed8":"markdown","7b4f0d67":"markdown","d78d5057":"markdown"},"source":{"3a23b817":"%matplotlib inline\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.axes._axes import _log as matplotlib_axes_logger\nmatplotlib_axes_logger.setLevel('ERROR')\nimport seaborn as sns\nfrom scipy import stats\nfrom ast import literal_eval\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel, cosine_similarity\nfrom nltk.stem.snowball import SnowballStemmer\nfrom nltk.stem.wordnet import WordNetLemmatizer\nfrom nltk.corpus import wordnet\nfrom surprise import Reader, Dataset, SVD, evaluate\nimport scipy.sparse as sparse\n\nimport warnings; warnings.simplefilter('ignore')","07b57140":"train = pd. read_csv('..\/input\/movies_metadata.csv')\ntrain.head()","fe9082ef":"print (train[pd.to_numeric(train['popularity'], errors='coerce').isnull()])\nprint (train[pd.to_numeric(train['budget'], errors='coerce').isnull()])","498fa9f0":"train = train.drop([19729, 19730, 29502, 29503, 35586, 35587])","415eb902":"train['popularity'] = train[train['popularity'].notnull()]['popularity'].astype('float')\ntrain['budget'] = train[train['budget'].notnull()]['budget'].astype('float')\ntrain['original_language'] = np.where(train['original_language']==\"en\", 'english', 'other')\ntrain['vote_average'] = train[train['vote_average'].notnull()]['vote_average'].round()","411d83bf":"fig = sns.barplot(x=\"adult\", y=\"id\", data=train, estimator=len)","7e06cbcc":"sns.set(rc={'figure.figsize':(10,8.27)})\nfig = sns.barplot(x=\"status\", y=\"id\", data=train, estimator=len)","1c7b4ce9":"sns.set(rc={'figure.figsize':(9,8.27)})\nfig1 = sns.barplot(x=\"original_language\", y=\"id\", data=train, estimator=len)","968a1085":"data = pd.concat([train['budget'], train['revenue']], axis=1)\ndata.plot.scatter(x='budget', y='revenue');","a7e8bcd5":"data = pd.concat([train['vote_count'], train['popularity']], axis=1)\ndata.plot.scatter(x='vote_count', y='popularity');","d26f4c08":"ax = sns.barplot(x=\"vote_average\", y='id', data=train, estimator=len)","a898aa5d":"md = pd. read_csv('..\/input\/movies_metadata.csv')\nmd.head()","f6e83fd8":"md['genres'] = md['genres'].fillna('[]').apply(literal_eval).apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\nmd['year'] = pd.to_datetime(md['release_date'], errors='coerce').apply(lambda x: str(x).split('-')[0] if x != np.nan else np.nan)","66af61c0":"C = md['vote_average'].mean()\nm= md['vote_count'].quantile(0.95)\nprint(\"C is %f, and m is %d\"%(C,m))","19c074a1":"qualified = md[(md['vote_count'] >= m) & (md['vote_count'].notnull()) & (md['vote_average'].notnull())]\nqualified.shape","842b453e":"def weighted_rating(x):\n    v = x['vote_count']\n    R = x['vote_average']\n    return (v\/(v+m) * R) + (m\/(m+v) * C)\nqualified = qualified[['title', 'year', 'vote_count', 'vote_average', 'popularity', 'genres']]\nqualified['score'] = qualified.apply(weighted_rating, axis=1)\nqualified = qualified.sort_values('score', ascending=False)\nqualified.head(10)","73bc5b13":"links = pd.read_csv('..\/input\/links_small.csv')\nlinks = links[links['tmdbId'].notnull()]['tmdbId'].astype('int')\nprint (md[pd.to_numeric(md['id'], errors='coerce').isnull()])","18374053":"md = md.drop([19730, 29503, 35587])\nmd['id'] = md['id'].astype('int')\n","8ba15766":"def get_recommendations(title, cosine_sim):\n    idx = indices[title]\n    sim_scores = list(enumerate(cosine_sim[idx]))\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    sim_scores = sim_scores[1:31]\n    movie_indices = [i[0] for i in sim_scores]\n    return titles.iloc[movie_indices]","1e4a77fc":"credits = pd.read_csv('..\/input\/credits.csv')\nkeywords = pd.read_csv('..\/input\/keywords.csv')\nkeywords['id'] = keywords['id'].astype('int')\ncredits['id'] = credits['id'].astype('int')\nmd = md.merge(credits, on='id')\nmd = md.merge(keywords, on='id')\nsmd1 = md[md['id'].isin(links)]\n\nfeatures = ['cast', 'crew', 'keywords']\nfor feature in features:\n    smd1[feature] = smd1[feature].apply(literal_eval)","1cf54859":"def get_director(x):\n    for i in x:\n        if i['job'] == 'Director':\n            return i['name']\n    return np.nan\nsmd1['director'] = smd1['crew'].apply(get_director)\nsmd1.head()","eb7076bc":"def get_list(x):\n    if isinstance(x, list):\n        names = [i['name'] for i in x]\n        #Check if more than 3 elements exist. If yes, return only first three. If no, return entire list.\n        if len(names) > 3:\n            names = names[:3]\n        return names\n    return []\nfeatures = ['cast', 'keywords']\nfor feature in features:\n    smd1[feature] = smd1[feature].apply(get_list)\nsmd1[['title', 'cast', 'director', 'keywords', 'genres']].head(3)","357b2760":"def clean_data(x):\n    if isinstance(x, list):\n        return [str.lower(i.replace(\" \", \"\")) for i in x]\n    else:\n        #Check if director exists. If not, return empty string\n        if isinstance(x, str):\n            return str.lower(x.replace(\" \", \"\"))\n        else:\n            return ''\n# Apply clean_data function to your features.\nfeatures = ['cast', 'keywords', 'director', 'genres']\n\nfor feature in features:\n    smd1[feature] = smd1[feature].apply(clean_data)\nsmd1['director'] = smd1['director'].apply(lambda x: [x,x, x])\nsmd1.head(3)","218a22f5":"def create_soup(x):\n    return ' '.join(x['keywords']) + ' ' + ' '.join(x['cast'])  + ' '.join(x['director']) + ' '.join(x['genres'])\nsmd1['soup'] = smd1.apply(create_soup, axis=1)\nsmd1[['title', 'cast', 'director', 'keywords', 'genres', 'soup']].head(3)","2d735a4c":"count = CountVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\ncount_matrix = count.fit_transform(smd1['soup'])\ncosine_sim = cosine_similarity(count_matrix, count_matrix)\n\nsmd1 = smd1.reset_index()\ntitles = smd1['title']\nindices = pd.Series(smd1.index, index=smd1['title'])\n\nindices.head()\n","1443e622":"get_recommendations('Toy Story',cosine_sim)","7849963d":"reader = Reader()\nratings = pd.read_csv('..\/input\/ratings_small.csv')\nratings.head()","e8e102c3":"data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\ndata.split(n_folds=5)\nsvd = SVD()\nevaluate(svd, data, measures=['RMSE', 'MAE'])","d18605e4":"trainset = data.build_full_trainset()\nsvd.train(trainset)\nratings[ratings['userId'] == 1]","54bc2bae":"svd.predict(1, 302)","bc0bd583":"def convert_int(x):\n    try:\n        return int(x)\n    except:\n        return np.nan\n    \nid_map = pd.read_csv('..\/input\/links_small.csv')[['movieId', 'tmdbId']]\nid_map['tmdbId'] = id_map['tmdbId'].apply(convert_int)\nid_map.columns = ['movieId', 'id']\nid_map = id_map.merge(smd1[['title', 'id']], on='id').set_index('title')\nindices_map = id_map.set_index('id')","3ce5eae9":"def hybrid(userId, title):\n    idx = indices[title]\n    tmdbId = id_map.loc[title]['id']\n    #print(idx)\n    movie_id = id_map.loc[title]['movieId']\n    \n    sim_scores = list(enumerate(cosine_sim[int(idx)]))\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    sim_scores = sim_scores[1:26]\n    movie_indices = [i[0] for i in sim_scores]\n    movies = smd1.iloc[movie_indices][['title', 'vote_count', 'vote_average', 'year', 'id']]\n    movies['est'] = movies['id'].apply(lambda x: svd.predict(userId, indices_map.loc[x]['movieId']).est)\n    movies = movies.sort_values('est', ascending=False)\n    return movies.head(10)\n","11b253bd":"movies1= hybrid(1, 'Avatar')\nmovies1","598dd792":"movies2= hybrid(500, 'Avatar')\nmovies2","75796b90":"metadata = pd. read_csv('..\/input\/movies_metadata.csv')\nmetadata = metadata.drop([19729, 19730, 29502, 29503, 35586, 35587])\nmetadata['id'] = metadata[metadata['id'].notnull()]['id'].astype('int')\nmetadata.head()","623fbe96":"image_data = metadata[['imdb_id', 'poster_path']]\nimage_data.head()","7c7c3df5":"links = pd.read_csv(\"..\/input\/links.csv\")\nlinks.head()","295d3ec6":"links = links[['movieId', 'imdbId']]","8db70b63":"image_data = image_data[~ image_data.imdb_id.isnull()]","b37bbdab":"def app(x):\n    try:\n        return int(x[2:])\n    except ValueError:\n        print(x)","f6c3a437":"image_data['imdbId'] = image_data.imdb_id.apply(app)\n\nimage_data = image_data[~ image_data.imdbId.isnull()]\n\nimage_data.imdbId = image_data.imdbId.astype(int)\n\nimage_data = image_data[['imdbId', 'poster_path']]\n\nimage_data.head()","3af657c6":"posters = pd.merge(image_data, links, on='imdbId', how='left')\n\nposters[['id', 'poster_path']] = posters[['movieId', 'poster_path']]\n\nposters = posters[~ posters.movieId.isnull()]\n\nposters.movieId = posters.movieId.astype(int)\n\nposters.head()","fbc0e450":"movies_table = pd.merge(movies1, posters, on='id', how='left')\nmovies_table","c1c1f630":"from IPython.display import HTML\nfrom IPython.display import display\n\ndef display_recommendations(df):\n\n    images = ''\n    for ref in df.poster_path:\n            if '.' in str(ref):\n                link = 'http:\/\/image.tmdb.org\/t\/p\/w185\/' + str(ref)\n                images += \"<img style='width: 120px; margin: 0px; \\\n                  float: left; border: 1px solid black;' src='%s' \/>\" \\\n              % link\n    display(HTML(images))","c84dd872":"display_recommendations(movies_table)","7e93cd7f":"**Good Movies, Movies for your joy!**\n\nWelcome to our Movie recommender System (Good Movies). In this EDA we will explain in details the filtering features that we offer to recommend to you a movie you will most likely adore!\n\n![](https:\/\/lhslance.org\/wp-content\/uploads\/2017\/12\/Top-10-1-900x600.jpg)","1ef2bd56":"There are 2274 movies which qualify to be in this list. Now, we need to calculate our metric for each qualified movie. To do this, we will define a function, weighted_rating() and define a new feature score, of which we'll calculate the value by applying this function to our Data of qualified movies, then display the top 10 movies!","2bc48d4b":"We can use the average ratings of the movie as the score but using this won't be fair enough since a movie with 8.9 average rating and only 3 votes cannot be considered better than the movie with 7.8 as as average rating but 40 votes. So, We'll be using IMDB's weighted rating (wr) which is given as :\n\n![](https:\/\/image.ibb.co\/jYWZp9\/wr.png)","7e8fc909":"**2- Demographic Filtering**","96b5e7db":"**1- EDA (Plotting, Preprocessing and Feature Selection)**","475ee722":"In this notebook, We have built 4 different recommendation engines based on different ideas and algorithms. They are as follows:\n\n* Simple Recommender: This system used overall TMDB Vote Count and Vote Averages to build Top Movies Charts, in general and for a specific genre. The IMDB Weighted Rating System was used to calculate ratings on which the sorting was finally performed.\n* Content Based Recommender: We built two content based engines; one that took movie overview and taglines as input and the other which took metadata such as cast, crew, genre and keywords to come up with predictions. We also deviced a simple filter to give greater preference to movies with more votes and higher ratings.\n* Collaborative Filtering: We used the powerful Surprise Library to build a collaborative filter based on single value decomposition. The RMSE obtained was less than 1 and the engine gave estimated ratings for a given user and movie.\n* Hybrid Engine: We brought together ideas from content and collaborative filterting to build an engine that gave movie suggestions to a particular user based on the estimated ratings that it had internally calculated for that user.\n\nThank You! We hope this project has been helpful to you as much as it was enjoyable for us!","696395bf":"For movie with ID 302, we get the above estimation. One startling feature of this recommender system is that it doesn't care what the movie is (or what it contains). It works purely on the basis of an assigned movie ID and tries to predict ratings based on how the other users have predicted the movie.","570c8cf7":"Interpretation: 98 other languages represent only 1\/4 of the data.","34b64ae5":"**Content**","c75da56a":"So, the mean rating for all the movies is approx 5.6 on a scale of 10\n\nThe minimum number of votes required is 434\n\nNow we will filter out the movies that qualify\n","3db4719b":"Interpretation: Generally, the higher the budget, the higher the revenue.","8c1d08b1":"C: is the mean vote across the data\n\nm: minimum vote required to be listed (must be among the top 5% voted movies)","2bd309ad":"**1- EDA (Plotting, Preprocessing and Feature Selection)**\n\n**2- Demographic Filtering**\n\n**3- Content Based Filtering**\n\n**4- Collaborative Filtering**\n\n**5- Hybrid Recommender**\n\n**6- Displaying**\n\n**7- Conclusion**","e6940f1a":"We get a mean Root Mean Sqaure Error of 0.89 which is more than good enough for our case. Let us now train on our dataset and arrive at predictions.","0a017173":"Interpretation: Status, video, and some other features showed to be not important in the dataset.","2f1614ba":"Interpretation: Movies with low votes have low popularity, but having high vote count_doesnt mean having higher popularity.","b3a31606":"Interpretation: Most movies have a rating between 4.6 and 7.5","855404be":"Collaborative Filtering is based on the idea that users similar to a certain user can be used to predict how much they will like a particular product or service those users have used\/experienced but the others have not.\n\nWe will not be implementing Collaborative Filtering from scratch. Instead, we will use the Surprise library that used extremely powerful algorithms like Singular Value Decomposition (SVD) to minimise RMSE (Root Mean Square Error) and give great recommendations.","039a9550":"**4- Collaborative Filtering**","35658f4f":"----------------------------------------------------------------------------------","33126350":"Define cosine similarity and include more features to improve the score","86cdf8b7":"In this section, we will try to build a simple hybrid recommender that brings together techniques we have implemented in the content based and collaborative filter based engines. This is how it will work:\n* Input: User ID and the Title of a Movie\n* Output: Similar movies sorted on the basis of expected ratings by that particular user.","689d2fb1":"To personalise our recommendations more, weare going to build an engine that computes similarity between movies based on certain metrics and suggests movies that are most similar to a particular movie that a user liked. This is known as Content Based Filtering.\nWe are using a subset of all the movies available to us due to limiting computing power available to us.","a0391e43":"Sources:\n\n* [Kaggle: Getting Started with a movie recommendation](https:\/\/www.kaggle.com\/ibtesama\/getting-started-with-a-movie-recommendation-system\/notebook?fbclid=IwAR03LpAdwODfCMgPWtgWQBlC5dmNqJxMYcvlvEjs8uG_CTUT_PacJVCR9vQ)\n \n* [Kaggle: movie recommender system](https:\/\/www.kaggle.com\/rounakbanik\/movie-recommender-systems?fbclid=IwAR2twbiQA0GToJi7YPqd72eAz1LqmvDEr9pYPcfIQvEyou0UzM73QvCYvO4)\n ","db3740b8":"We see that for our hybrid recommender, we get different recommendations for different users although the movie is the same. Hence, our recommendations are more personalized and tailored towards particular users.","fc72a843":"We can now define our recommendation function. These are the following steps we'll follow :\n\n* Get the index of the movie given its title.\n* Get the list of cosine similarity scores for that particular movie with all movies. Convert it into a list of tuples where the first element is its position and the second is the similarity score.\n* Sort the mentioned list of tuples based on the similarity scores; that is, the second element.\n* Get the top 10 elements of this list. Ignore the first element as it refers to self (the movie most similar to a particular movie is the movie itself).\n* Return the titles corresponding to the indices of the top elements.","55549fff":"**5- Hybrid Recommender**","2aea3268":"Interpretation: Adult feature is not important in the dataset","69d7eed8":"**6- Displaying**","7b4f0d67":"**3- Content Based Filtering**","d78d5057":"**7- Conclusion**"}}