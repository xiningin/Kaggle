{"cell_type":{"2570e6e4":"code","4f1931a4":"code","fd2cc1e0":"code","59fb3a91":"code","3d9eaa98":"code","d3a84c05":"code","b2738e49":"code","3772e050":"code","54f29bcb":"code","f17e7fcf":"code","12cb908a":"code","b5a8e557":"code","d7755868":"code","09e61891":"code","5c55466e":"code","065124af":"code","34fd325d":"code","5bb6eea4":"code","5fe9c129":"code","7882e680":"code","5b2292eb":"markdown","d3e0a6f1":"markdown","d499bb65":"markdown","807c7956":"markdown","8b15acf7":"markdown","8d3c5438":"markdown"},"source":{"2570e6e4":"!pip install rapidfuzz","4f1931a4":"# copy & edit from : https:\/\/www.kaggle.com\/thedrcat\/wiki-image-caption-eda-and-baseline-new-data\nimport pandas as pd\nimport numpy as np\nimport base64\nfrom PIL import Image\nimport io\nfrom rapidfuzz import process, fuzz\nfrom urllib.parse import unquote","fd2cc1e0":"sub = pd.read_csv('..\/input\/wikipedia-image-caption\/sample_submission.csv')\nsub.head(15)","59fb3a91":"test = pd.read_csv('..\/input\/wikipedia-image-caption\/test.tsv',sep='\\t')\ntest.head()","3d9eaa98":"for i in range(5):\n    print(test.image_url.iloc[i])","d3a84c05":"test_caption_list = pd.read_csv('..\/input\/wikipedia-image-caption\/test_caption_list.csv')\ntest_caption_list.head()","b2738e49":"test_image = pd.read_csv('..\/input\/wikipedia-image-caption\/image_data_test\/image_pixels\/test_image_pixels_part-00000.csv',sep='\\t',header=None)\ntest_image.head()","3772e050":"image64_encode = base64.b64decode(test_image[1].iloc[2])\nimg = Image.open(io.BytesIO(image64_encode))\nimg","54f29bcb":"import datatable as dt\ntrain = dt.fread('..\/input\/wikipedia-image-caption\/train-00000-of-00005.tsv')\ntrain.head()","f17e7fcf":"def url_target_process(s):\n    s = s.rsplit('\/',1)[1]\n    s = unquote(s)\n    s = s.replace('_',' ')\n    s = s + '[SEP]'\n    return s","12cb908a":"for i in range(5):\n    print(f'target: {train[i,-1]}')\n    print(f'prediction: {url_target_process(train[i,1])}')\n    print()","b5a8e557":"test['prediction'] = test['image_url'].apply(url_target_process)\ntest.head()","d7755868":"Caption = test_caption_list.caption_title_and_reference_description.values.tolist()","09e61891":"for i in range(5):\n    pp = test.prediction[i]\n    print(pp)\n    res = process.extract(pp, Caption, scorer=fuzz.ratio, processor=None, limit=4)\n    print('closet caption:')\n    for j in res:\n        print(j[0])\n    print('*'*40)","5c55466e":"def predict_caption(m):\n    res = process.extract(m, Caption, scorer=fuzz.ratio, processor=None, limit=5)\n    res = [x[0] for x in res]\n    return res","065124af":"from tqdm.auto import tqdm\ntqdm.pandas()","34fd325d":"test['caption_title_and_reference_description'] = test['prediction'].progress_apply(predict_caption)","5bb6eea4":"del sub","5fe9c129":"\nsub = test[['id','caption_title_and_reference_description']]\nsub = sub.explode('caption_title_and_reference_description')\nsub.head()","7882e680":"sub.to_csv('submission.csv',index=False)","5b2292eb":"## Take a look on submission ","d3e0a6f1":"#### Seems work so apply on test data on make submission","d499bb65":"#### The page_url have contain some information for caption_title_and_reference_description  \n#### test data also have url. Maybe it can do something.","807c7956":"#### from url to target in training data  ","8b15acf7":"#### There are id, caption_title_and_reference_description, in sample submission  \n#### and every id has 5 caption","8d3c5438":"#### test.tsv contain id, image_url"}}