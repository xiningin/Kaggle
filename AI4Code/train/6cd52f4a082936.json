{"cell_type":{"01e58683":"code","31f292b1":"code","ef3fe5cd":"code","dae273a0":"code","44fb2b30":"code","3dd503ae":"code","513a674b":"code","b6e44c20":"code","319b49c4":"code","cf5916d8":"code","8ac2f2d7":"code","a3e874e9":"code","86d74bd4":"code","1770defa":"code","b3efa3ea":"code","bdb6e054":"code","7ebe9b44":"code","0b223a7e":"code","82d632a9":"code","b160bef4":"code","2e340c6b":"code","469d0a92":"markdown","7fd5a47d":"markdown","62d0921e":"markdown","138b0fe2":"markdown","ee5b0f83":"markdown","55e79c3a":"markdown"},"source":{"01e58683":"import os\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport itertools\n\n# librosa l\u00e0 m\u1ed9t th\u01b0 vi\u1ec7n Python \u0111\u1ec3 ph\u00e2n t\u00edch \u00e2m thanh v\u00e0 \u00e2m nh\u1ea1c\nimport librosa\nimport librosa.display\n\n# to play the audio files\nfrom IPython.display import Audio\n\nfrom keras.utils import np_utils","31f292b1":"# Encoding dataset\nravdess_emotions = {\n    '01':'neutral',\n    '02':'neutral',\n    '03':'happy',\n    '04':'sad',\n    '05':'angry',\n    '06':'fear',\n    '07':'disgust',\n    '08':'surprise'}\n\ncrema_emotions = {\n    'NEU':'neutral',\n    'HAP':'happy',\n    'SAD':'sad',\n    'ANG':'angry',\n    'FEA':'fear',\n    'DIS':'disgust'}\n\nsavee_emotions = {\n    'a':'angry',\n    'h':'happy',\n    's':'surprise',\n    'n':'neutral',\n    'f':'fear',\n    'd':'disgust'\n}","ef3fe5cd":"processed_data = []\ndata_path = '..\/input\/speech-emotion-recognition-en'","dae273a0":"# Tr\u00edch xu\u1ea5t t\u00ean c\u1ea3m x\u00fac trong b\u1ed9 d\u1eef li\u1ec7u\nfor root, dirs, files in os.walk(data_path):\n  for file in files:\n    file_path = os.path.join(root, file)\n    \n    dataset = root.split('\/')[3]\n    if dataset == 'Crema':\n      emotion = crema_emotions[file.split('_')[2]]\n      # continue\n    elif dataset == 'Tess':\n      emotion = file.split('_')[-1].split('.')[0]\n      if emotion == 'ps':\n        emotion = 'surprise'\n      # continue\n    elif dataset == 'Ravdess':\n      emotion = ravdess_emotions[file.split('-')[2]]\n    else:\n      emotion_code = file.split('_')[1][:2]\n      if emotion_code.__contains__('sa'):\n        emotion = 'sad'\n      else:\n        emotion = savee_emotions[emotion_code[0]]\n      # continue\n    processed_data.append([file_path, emotion])\n\ndata_df = pd.DataFrame(processed_data, columns = ['File_path', 'Emotion'])","44fb2b30":"data_df.to_csv('data_df.csv')\ndata_df.shape","3dd503ae":"plt.title(\"Count of emotions\")\nsns.countplot(x = data_df[\"Emotion\"])\nsns.despine(top = True, right = True, left = False, bottom = False)","513a674b":"# c\u00e1c h\u00e0m d\u00f9ng \u0111\u1ec3 bi\u1ec3u di\u1ec5n h\u00ecnh \u1ea3nh k\u1ef9 thu\u1eadt s\u1ed1 c\u1ee7a \u00e2m thanh\n\ndef create_waveplot(data, sampling_rate, emotion):\n    plt.figure(figsize=(10, 3))\n    plt.title(f'Waveplot for audio with {emotion} emotion', size=15)\n    librosa.display.waveplot(data, sr = sampling_rate)\n    plt.show()\n\ndef create_spectrogram(data, sampling_rate, emotion):\n    X = librosa.stft(data)\n    Xdb = librosa.amplitude_to_db(abs(X))\n    plt.figure(figsize = (12, 3))\n    plt.title('Spectrogram for audio with {} emotion'.format(emotion), size = 15)\n    librosa.display.specshow(Xdb, sr = sampling_rate, x_axis = 'time', y_axis = 'hz')\n    plt.colorbar()","b6e44c20":"# bi\u1ec3u di\u1ec5n \u00e2m thanh v\u1edbi m\u1ed9t t\u1ec7p \u00e2m thanh v\u1edbi c\u1ea3m x\u00fac l\u00e0 h\u1ea1nh ph\u00fac (happy)\nemotion='happy'\npath = (data_df[data_df.Emotion == emotion].iloc[0])[0]\ndata, sampling_rate = librosa.load(path)\ncreate_waveplot(data, sampling_rate, emotion)\ncreate_spectrogram(data, sampling_rate, emotion)\nAudio(path)","319b49c4":"def noise(data, random = False, rate = 0.035, threshold = 0.075):\n    if random:\n        rate = np.random.random() * threshold\n    noise_amp = rate * np.random.uniform() * np.amax(data)\n    data = data + noise_amp * np.random.normal(size = data.shape[0])\n    return data\n\ndef stretch(data, rate = 0.8):\n    return librosa.effects.time_stretch(data, rate)\n\ndef shift(data, rate = 1000):\n    shift_range = int(np.random.uniform(low = -5, high = 5) * rate)\n    return np.roll(data, shift_range)\n\ndef pitch(data, sampling_rate, pitch_factor=0.7, random = False):\n    if random:\n        pitch_factor = np.random.random() * pitch_factor\n    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)","cf5916d8":"emotion='happy'\npath = (data_df[data_df.Emotion == emotion].iloc[0])[0]\ndata, sampling_rate = librosa.load(path)\ndata_copy = data","8ac2f2d7":"# \u00c2m thanh g\u1ed1c\nplt.figure(figsize = (14,4))\nlibrosa.display.waveplot(data, sampling_rate)\nAudio(path)","a3e874e9":"# \u00c2m thanh th\u00eam nhi\u1ec5u\nnoised_data = noise(data, random = True)\nplt.figure(figsize = (14,4))\n\nlibrosa.display.waveplot(y = noised_data, sr = sampling_rate)\n# librosa.display.waveplot(data_copy, sampling_rate)\n\nAudio(noised_data, rate = sampling_rate)","86d74bd4":"# \u00c2m thanh \u0111\u00e3 thay \u0111\u1ed5i t\u1ed1c \u0111\u1ed9\nstretched_data = stretch(data, rate=0.5)\nplt.figure(figsize = (14,4))\n\nlibrosa.display.waveplot(y = stretched_data, sr = sampling_rate)\n# librosa.display.waveplot(data_copy, sampling_rate)\n\nAudio(stretched_data, rate = sampling_rate)","1770defa":"# \u00c2m thanh \u0111\u01b0\u1ee3c di chuy\u1ec3n\nshifted_data = shift(data)\nplt.figure(figsize = (14,4))\n\nlibrosa.display.waveplot(y = shifted_data, sr = sampling_rate)\n# librosa.display.waveplot(data_copy, sampling_rate)\n\nAudio(shifted_data, rate = sampling_rate)","b3efa3ea":"# \u00c2m thanh \u0111\u01b0\u1ee3c thay \u0111\u1ed5i cao \u0111\u1ed9\npitched_data = pitch(data, sampling_rate, pitch_factor = 0.5, random=True)\nplt.figure(figsize = (14,4))\n\nlibrosa.display.waveplot(y = pitched_data, sr = sampling_rate)\n# librosa.display.waveplot(data_copy, sampling_rate)\n\nAudio(pitched_data, rate = sampling_rate)","bdb6e054":"def zcr(data, frame_length = 2048, hop_length = 512):\n    zcr = librosa.feature.zero_crossing_rate(y = data, \n                                             frame_length = frame_length, \n                                             hop_length = hop_length)\n    librosa.display.specshow(zcr, x_axis='time')\n    plt.colorbar()\n    plt.tight_layout()\n    plt.title('zcr')\n    plt.show()\n    return np.squeeze(zcr)\n\ndef rms(data, frame_length = 2048, hop_length = 512):\n    rms = librosa.feature.rms(y = data, \n                               frame_length = frame_length, \n                               hop_length = hop_length)\n    librosa.display.specshow(rms, x_axis='time')\n    plt.colorbar()\n    plt.tight_layout()\n    plt.title('rms')\n    plt.show()\n    return np.squeeze(rms)\n\ndef mfcc(data, sampling_rate, frame_length = 2048, hop_length = 512, flatten: bool = True):\n    mfcc_feature = librosa.feature.mfcc(y = data, \n                                        sr = sampling_rate)\n    librosa.display.specshow(mfcc_feature, x_axis='time')\n    plt.colorbar()\n    plt.tight_layout()\n    plt.title('mfcc')\n    plt.show()\n    return np.squeeze(mfcc_feature.T) if not flatten else np.ravel(mfcc_feature.T)\n\ndef spc(data, sampling_rate, frame_length = 2048, hop_length = 512):\n    spectral_centroid = librosa.feature.spectral_centroid(y = data, sr = sampling_rate, n_fft = frame_length, hop_length = hop_length)\n    return np.squeeze(spectral_centroid)\n\ndef spc_flux(data):\n    isSpectrum = data.ndim == 1\n    if isSpectrum:\n        data = np.expand_dims(data, axis = 1)\n    X = np.c_[data[:, 0], data]\n    af_Delta_X = np.diff(X, 1, axis = 1)\n    vsf = np.sqrt((np.power(af_Delta_X, 2).sum(axis = 0))) \/ X.shape[0]\n    return np.squeeze(vsf) if isSpectrum else vsf\n\ndef spc_rollof(data, sampling_rate, frame_length = 2048, hop_length = 512):\n    spcrollof = librosa.feature.spectral_rolloff(y = data, sr = sampling_rate, n_fft = frame_length, hop_length = hop_length)\n    return np.squeeze(spcrollof)\n\ndef chroma_stft(data, sampling_rate, frame_length = 2048, hop_length = 512, flatten: bool = True):\n    stft = np.abs(librosa.stft(data))\n    chroma_stft = librosa.feature.chroma_stft(S = stft, sr = sampling_rate)\n    return np.squeeze(chroma_stft.T) if not flatten else np.ravel(chroma_stft.T)\n\ndef mel_spc(data, sampling_rate, frame_length = 2048, hop_length = 512, flatten: bool = True):\n    mel = librosa.feature.melspectrogram(y = data, sr = sampling_rate)\n    return np.squeeze(mel.T) if not flatten else np.ravel(mel.T)\n\ndef energy(data, frame_length = 2048, hop_length = 512):\n    en = np.array([np.sum(np.power(np.abs(data[hop:hop + frame_length]), 2)) for hop in range(0, data.shape[0], hop_length)])\n    return en \/ frame_length","7ebe9b44":"# Ki\u1ec3m tra vi\u1ec7c tr\u00edch xu\u1ea5t \u0111\u1eb7c tr\u01b0ng v\u1edbi m\u1ed9t t\u1ec7p \u00e2m thanh ng\u1eabu nhi\u00ean\npath = np.array(data_df[\"File_path\"])[658]\ndata, sampling_rate = librosa.load(path, duration = 2.5, offset = 0.6)\n\nprint(\"Length of data: \", len(data))\n\nprint(\"Zero-Crossing Rate: \", zcr(data).shape)\nprint(\"Root Mean Square:\", rms(data).shape)\nprint(\"Mel-Frequency Cepstral Coefficients: \", mfcc(data, sampling_rate).shape)\nprint(\"Spectral Centroid :\", spc(data, sampling_rate).shape)\nprint(\"Spectral Flux: \", spc_flux(data).shape)\nprint(\"Spectral Rollof: \", spc_rollof(data, sampling_rate).shape)\nprint(\"Chroma STFT: \", chroma_stft(data, sampling_rate).shape)\nprint(\"MelSpectrogram: \", mel_spc(data, sampling_rate).shape)\nprint(\"Energy: \", energy(data).shape)","0b223a7e":"def extract_features(data, sampling_rate, frame_length = 2048, hop_length = 512):\n  result = np.array([])\n  result = np.hstack((result,\n                      zcr(data, frame_length, hop_length),\n                      # np.mean(energy(data, frame_length, hop_length),axis=0),\n                      # np.mean(entropy_of_energy(data, frame_length, hop_length), axis=0),\n                      rms(data, frame_length, hop_length),\n                      # spc(data, sampling_rate, frame_length, hop_length),\n                      # spc_entropy(data, sampling_rate),\n                      # spc_flux(data),\n                      # spc_rollof(data, sampling_rate, frame_length, hop_length),\n                      # chroma_stft(data, sampling_rate, frame_length, hop_length),\n                      # mel_spc(data, sampling_rate, frame_length, hop_length, flatten=True)\n                      mfcc(data, sampling_rate, frame_length, hop_length)\n                    ))\n  return result\n\ndef get_features(path, duration = 2.5, offset = 0.6):\n  data, sampling_rate = librosa.load(path, \n                                   duration = duration, \n                                   offset = offset)\n\n  # d\u1eef li\u1ec7u kh\u00f4ng t\u0103ng c\u01b0\u1eddng\n  feature = extract_features(data, sampling_rate)\n  result = np.array(feature)\n\n  # d\u1eef li\u1ec7u th\u00eam noise\n  noise_data = noise(data, random = True)\n  feature1 = extract_features(noise_data, sampling_rate)\n  result = np.vstack((result, feature1)) # x\u1ebfp ch\u1ed3ng theo chi\u1ec1u d\u1ecdc\n\n  # d\u1eef li\u1ec7u thay \u0111\u1ed5i t\u1ea7n s\u1ed1 rung\n  pitched_data = pitch(data, sampling_rate, random = True)\n  feature2 = extract_features(pitched_data, sampling_rate)\n  result = np.vstack((result, feature2)) # x\u1ebfp ch\u1ed3ng theo chi\u1ec1u d\u1ecdc\n\n  # d\u1eef li\u1ec7u thay \u0111\u1ed5i t\u1ea7n s\u1ed1 rung v\u00e0 th\u00eam noise\n  new_data = pitch(data, sampling_rate, random = True)\n  data_noise_pitch = noise(new_data, random = True)\n  feature3 = extract_features(data_noise_pitch, sampling_rate)\n  result = np.vstack((result, feature3)) # x\u1ebfp ch\u1ed3ng theo chi\u1ec1u d\u1ecdc\n\n  return result","82d632a9":"X, Y = [], []\nprint('Feature processing...')\nfor path, emotion, index in zip(data_df.File_path, data_df.Emotion, range(data_df.File_path.shape[0])):\n  features = get_features(path)\n  if index % 100 == 0:\n        print(f\"{index} samples has been processed...\")\n  for ele in features:\n    X.append(ele)\n    Y.append(emotion)\nprint('Done.')","b160bef4":"features_path = '.\/features_zcf_rmse_mfcc.csv'","2e340c6b":"extracted_df = pd.DataFrame(X)\nextracted_df['labels'] = Y\nextracted_df.to_csv(features_path, index = False)\nextracted_df.head()","469d0a92":"# **Th\u01b0 vi\u1ec7n**","7fd5a47d":"# **L\u01b0u \u0111\u1eb7c tr\u01b0ng \u0111\u00e3 tr\u00edch xu\u1ea5t \u0111\u1ec3 s\u1eed d\u1ee5ng sau**\n\n\u0110\u1eb7c tr\u01b0ng \u0111\u01b0\u1ee3c tr\u00edch xu\u1ea5t t\u1eeb d\u1eef li\u1ec7u (\u0111\u00e3 \u0111\u01b0\u1ee3c t\u0103ng c\u01b0\u1eddng) l\u01b0u v\u00e0o file features_zcf_rmse_mfcc.csv","62d0921e":"# **D\u1eef li\u1ec7u**","138b0fe2":"# **T\u0103ng c\u01b0\u1eddng d\u1eef li\u1ec7u**","ee5b0f83":"# **Kh\u00e1m ph\u00e1 d\u1eef li\u1ec7u**","55e79c3a":"# **Tr\u00edch xu\u1ea5t \u0111\u1eb7c tr\u01b0ng**"}}