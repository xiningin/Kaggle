{"cell_type":{"75fb83b5":"code","46630d8c":"code","a69d93ff":"code","141ba035":"code","a2ad85de":"code","b9f212b8":"code","8466e5aa":"code","b61b45e7":"code","7a41ac04":"code","c4283419":"code","5bb5a92b":"code","dffcbe13":"code","a220fd03":"code","2cdb0070":"code","f84fd758":"code","bb055909":"code","bd68a355":"code","a569bc1f":"code","69ec5a66":"code","55a906ce":"code","83fbcf35":"code","9f5c2ba6":"code","48e3f246":"code","c6d99271":"code","7d9ea9a6":"code","15260977":"code","e30a0072":"code","50d4de8a":"code","03290eb0":"code","5d61e1a2":"code","05050419":"code","af869ff5":"code","2398737f":"code","5086afdc":"code","101d1aa1":"code","e95934e4":"code","65f287dd":"code","634031dd":"code","d39ef2c6":"code","31728e7f":"code","169f89b1":"code","3d1af207":"code","ba4ec5f5":"code","78cffe9a":"code","30de1a0d":"code","6171aad1":"code","13e020c2":"code","ec766d46":"code","f7899365":"code","e74ef9b6":"code","06225189":"code","5ba9a97f":"code","ef52d318":"code","a43d2308":"code","54ec8973":"code","35345fef":"code","28fc538a":"code","c47303f1":"code","a873a4aa":"markdown","36cab27e":"markdown","d6839444":"markdown","19953cd0":"markdown","2e2b6091":"markdown","8e3140c2":"markdown","d4065413":"markdown","d0840c14":"markdown","358be765":"markdown","3b336a0f":"markdown","71c25ff7":"markdown","0b93620c":"markdown"},"source":{"75fb83b5":"# the following three lines are suggested by the fast.ai course\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","46630d8c":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom fastai.vision import *\nfrom PIL import Image","a69d93ff":"# Train set\ntrain = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","141ba035":"print(train.shape)\nprint(test.shape)","a2ad85de":"train.head(5)","b9f212b8":"test.head(5)","8466e5aa":"img = [np.reshape(train.iloc[idx,1:].values,(28,28)) for idx in range(5)]","b61b45e7":"len(img)","7a41ac04":"for f in img:   \n    plt.imshow(f,cmap='gray')\n    plt.show()","c4283419":"#TRAIN = Path(\"..\/train\")\n#TEST = Path(\"..\/test\")\nPATH = Path('..\/')\nTRAIN = Path('..\/train')\nTRAIN.mkdir(parents=True, exist_ok=True)\nTRAIN\n\n\nTEST = Path('..\/test')\nTEST.mkdir(parents=True, exist_ok=True)\nTEST\n\n","5bb5a92b":"PATH.ls()\n","dffcbe13":"os.listdir('\/kaggle\/working\/')","a220fd03":"train_img = train.iloc[:,1:785]\ntest_img = test.iloc[:,:]","2cdb0070":"#Source: [https:\/\/www.kaggle.com\/christianwallenwein\/beginners-guide-to-mnist-with-fast-ai]\ndef save_img(data,fpath,isTest=False):\n    if isTest == False:\n        for index, row in data.iterrows():\n    \n            label,digit = row[0], row[1:]\n    \n            filepath = fpath\n            filename = \"train_{}.jpg\".format(index)\n            digit = digit.values\n            digit = digit.reshape(28,28)\n            digit = digit.astype(np.uint8)\n    \n            img = Image.fromarray(digit)\n            img.save(filepath\/filename)\n            \n    else:\n        for index, row in data.iterrows():\n    \n            digit = row[:]\n    \n            filepath = fpath\n            filename = \"test_{}.jpg\".format(index)\n            digit = digit.values\n            digit = digit.reshape(28,28)\n            digit = digit.astype(np.uint8)\n    \n            img = Image.fromarray(digit)\n            img.save(filepath\/filename)","f84fd758":"save_img(train,TRAIN,False)","bb055909":"sorted(os.listdir(TRAIN))[0]","bd68a355":"save_img(test,TEST,True)","a569bc1f":"sorted(os.listdir(TEST))[0]","69ec5a66":"train['filename'] = ['train\/train_{}.jpg'.format(x) for x,_ in train.iterrows()]","55a906ce":"train.head()","83fbcf35":"test['filename'] = ['test\/test_{}.jpg'.format(x) for x,_ in test.iterrows()]","9f5c2ba6":"test.head()","48e3f246":"# Sanity check\nimg = open_image(TRAIN\/'train_0.jpg')\nimg","c6d99271":"tfms = ([*rand_pad(padding=3,size=28,mode='reflection'),zoom(scale=1.005),],[])","7d9ea9a6":"src = ImageList.from_df(train,PATH,cols='filename').split_by_rand_pct(0.2).label_from_df(cols='label').add_test_folder(PATH\/'test')","15260977":"src","e30a0072":"data =  src.transform(tfms, size=28).databunch().normalize(imagenet_stats)","50d4de8a":"data.show_batch(2,2)","03290eb0":"data.classes,data.c","5d61e1a2":"data.train_ds[0][0]","05050419":"learn = cnn_learner(data,models.resnet50,metrics=accuracy,model_dir='\/kaggle\/working\/')","af869ff5":"learn.lr_find(num_it=600)","2398737f":"learn.recorder.plot(skip_end=25)","5086afdc":"lr=4e-3","101d1aa1":"learn.fit_one_cycle(10,slice(lr))","e95934e4":"learn.recorder.plot_losses()","65f287dd":"learn.save('stage1-resnet50-mnist')","634031dd":"learn.load('stage1-resnet50-mnist')","d39ef2c6":"learn.unfreeze()","31728e7f":"learn.lr_find(num_it=600)","169f89b1":"\nlearn.recorder.plot()","3d1af207":"learn.fit_one_cycle(10,slice(1e-5,1e-4\/5))","ba4ec5f5":"learn.save('stage2-resnet50-mnist')","78cffe9a":"learn.export()","30de1a0d":"PATH.ls()","6171aad1":"interp = ClassificationInterpretation.from_learner(learn)","13e020c2":"interp.plot_confusion_matrix()","ec766d46":"interp.plot_top_losses(9, figsize=(7, 7))\n# Maybe feed the network with top losses to improve score?\n","f7899365":"test = ImageList.from_folder(TEST)\ntest","e74ef9b6":"learn = load_learner(PATH, test=test)","06225189":"preds, _ = learn.get_preds(ds_type=DatasetType.Test)","5ba9a97f":"probabilities = preds[0].tolist()\n[f\"{index}: {probabilities[index]}\" for index in range(len(probabilities))]","ef52d318":"class_score = np.argmax(preds, axis=1)","a43d2308":"class_score[0].item()","54ec8973":"sample_submission =  pd.read_csv(\"..\/input\/digit-recognizer\/sample_submission.csv\")\nsample_submission.head()\n\n","35345fef":"# remove file extension from filename\nImageId = [os.path.splitext(p)[0].split('test_')[1] for p in os.listdir(TEST)]\n# typecast to int so that file can be sorted by ImageId\nImageId = [int(path) for path in ImageId]\n# +1 because index starts at 1 in the submission file\nImageId = [ID+1 for ID in ImageId]","28fc538a":"sorted(ImageId)[-1]","c47303f1":"submission  = pd.DataFrame({\n    \"ImageId\": ImageId,\n    \"Label\": class_score\n})\n# submission.sort_values(by=[\"ImageId\"], inplace = True)\nsubmission.to_csv(\"nona-submission.csv\", index=False)","a873a4aa":"Let's create a dataframe with image labels and path to a image. For that we are going to save the arrays as images","36cab27e":"# Updates\n* We are going to use ResNet50 instead of Resnet34. On the last version the training loss was a little bit higher than validation loss. It could be a sign of underfitting so let's see if increasing the capacity of the network can solve this. **< Top27% Using ResNet50**\n* This time we are going to check if data augmentation using the transformations from Fast.ai can increase our ranking. We only used max_rotate, flips and no warp. **< flip_lr() and pad(reflection) reduced accuracy to 97% on validation set. Let's remove flip_lr()**. In fact, we will not flip or rotate the image at all because this might change the meaning of it.\n\n* I was applying transformations to the validation and test sets. This can lead to bad predictions since test data should be as close to reality as possible.\n\n* Changed transformations to include a degree of rotation","d6839444":"# Train model","19953cd0":"### Fine tuning","2e2b6091":"# Make predictions","8e3140c2":"# Import data","d4065413":"# Exploratory data analysis","d0840c14":"### Save images","358be765":"# Evaluation","3b336a0f":"### Transformations","71c25ff7":"Let's plot some of the numbers. They are 28x28 images, so we are going to get some and reshape the array.","0b93620c":"# Preprocessing the digit images and create databunch"}}