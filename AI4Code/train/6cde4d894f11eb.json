{"cell_type":{"6d181c1b":"code","e4d07765":"code","a589faca":"code","bd972d47":"code","62926e79":"code","07f29be6":"code","436873d2":"code","6d82fe1c":"code","a0b8682a":"code","913fcf77":"markdown","d5f0baa4":"markdown","eff70a22":"markdown","584a69fa":"markdown","49fd814a":"markdown","27cd8f2e":"markdown","80da3413":"markdown","4c8974ce":"markdown"},"source":{"6d181c1b":"import tensorflow as tf\nfrom kaggle_datasets import KaggleDatasets\nimport numpy as np\n\nprint(\"Tensorflow version \" + tf.__version__)","e4d07765":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","a589faca":"# GCS \u2192 Google Cloud Services\n# TPUs expect data to be as close to them as possible\nGCS_DS_PATH = KaggleDatasets().get_gcs_path() \n# list the bucket with \"!gsutil ls $GCS_DS_PATH\"","bd972d47":"IMAGE_SIZE = [192, 192]\nEPOCHS = 5\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\n\nNUM_TRAINING_IMAGES = 12753\nNUM_TEST_IMAGES = 7382\nSTEPS_PER_EPOCH = NUM_TRAINING_IMAGES \/\/ BATCH_SIZE","62926e79":"def decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    # convert image to floats in [0, 1] range\n    image = tf.cast(image, tf.float32) \/ 255.0\n    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n    return image\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        # [] \u2192 single element\n        # bytestring\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"class\": tf.io.FixedLenFeature([], tf.int64),\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    label = tf.cast(example['class'], tf.int32)\n    return image, label\n\ndef read_unlabeled_tfrecord(example):\n    UNLABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"id\": tf.io.FixedLenFeature([], tf.string),\n    }\n    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    idnum = example['id']\n    return image, idnum","07f29be6":"def load_dataset(filenames, labeled=True, ordered=False):\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False\n    dataset = tf.data.TFRecordDataset(filenames)\n    dataset = dataset.with_options(ignore_order)\n    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord)\n    return dataset","436873d2":"def get_training_dataset():\n    dataset = load_dataset(tf.io.gfile.glob(GCS_DS_PATH + '\/tfrecords-jpeg-192x192\/train\/*.tfrec'), labeled=True)\n    # the training dataset need to repeat for several epochs\n    dataset = dataset.repeat()\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    return dataset\n\ndef get_validation_dataset():\n    dataset = load_dataset(tf.io.gfile.glob(GCS_DS_PATH + '\/tfrecords-jpeg-192x192\/val\/*.tfrec'), labeled=True, ordered=False)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.cache()\n    return dataset\n\ndef get_test_dataset(ordered=False):\n    dataset = load_dataset(tf.io.gfile.glob(GCS_DS_PATH + '\/tfrecords-jpeg-192x192\/test\/*.tfrec'), labeled=False, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    return dataset\n\ntraining_dataset = get_training_dataset()\nvalidation_dataset = get_validation_dataset()","6d82fe1c":"with strategy.scope():    \n    pretrained_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n    pretrained_model.trainable = False # transfer learning\n    \n    model = tf.keras.Sequential([\n        pretrained_model,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(104, activation='softmax')\n    ])\n        \nmodel.compile(\n    optimizer='adam', # an extension to stochastic gradient descent\n    loss = 'sparse_categorical_crossentropy',\n    metrics=['sparse_categorical_accuracy']\n)\n\nhistorical = model.fit(training_dataset, \n                       steps_per_epoch=STEPS_PER_EPOCH, \n                       epochs=EPOCHS, \n                       validation_data=validation_dataset)","a0b8682a":"test_ds = get_test_dataset(ordered=True)\nprint('Computing predictions...')\n# get image\ntest_images_ds = test_ds.map(lambda image, idnum: image)\nprobabilities = model.predict(test_images_ds)\npredictions = np.argmax(probabilities, axis=-1)\nprint(predictions)\n\nprint('Generating submission.csv file...')\n# get id\ntest_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\n# dataset \u2192 numpy array\n# 'U' \u2192 Unicode\ntest_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U')\nnp.savetxt('submission.csv', \n           np.rec.fromarrays([test_ids, predictions]), \n           fmt=['%s', '%d'], \n           delimiter=',', # column separator\n           header='id,label', \n           comments='')\nprint('Done')","913fcf77":"The code below reads from TFRecords. If ordered is set to False, it reads from multiple files at once and disregards data order.","d5f0baa4":"# Set parameters","eff70a22":"# Detect accelerator","584a69fa":"# Build a model on TPU (or GPU, or CPU...) with Tensorflow 2.1","49fd814a":"A single TPU board is made up of 4 TPU chips, and within each of those TPU chips we have two TPU cores. These TPU cores are where all of the matrix multiplication is happening. TPUs were designed to do matrix multiplication incredibly fast on incredibly large amounts of data. This is what makes them such an ideal deep learning tool.","27cd8f2e":"# Get data path","80da3413":"# Load data","4c8974ce":"# Compute predictions on the test set!"}}