{"cell_type":{"dfd57088":"code","2f75a416":"code","f7ccfc65":"code","9df093fb":"code","02a31c27":"code","63d14b82":"code","e38ac8d7":"code","72dcce57":"code","5dd04b5d":"code","bf066c07":"code","e0a15eee":"code","eafb31ee":"code","decd05cd":"code","a3bbb95e":"code","a8a6bda4":"code","9d68259a":"code","c98942a1":"code","cb1e7767":"code","72b92abf":"code","07c8a52a":"code","6d45d1e2":"code","52692d9f":"code","1cdffbbf":"code","d5d2c4a1":"code","08f82d90":"code","066855b3":"code","8bd781d4":"code","2ebdf01e":"code","b77b72ca":"code","f774ac69":"code","2ab24820":"code","ff45ff55":"code","8d2b7ab4":"code","3b5b8ffe":"code","08b12057":"code","7e97774e":"code","c30e1b79":"code","8189d9eb":"code","ba049ea9":"code","94194703":"code","7744d648":"code","0bfd19c1":"code","cacd2b1a":"code","71bdb9e9":"code","fa1b415e":"code","fc06f5a7":"code","a776f020":"code","076e4103":"markdown","042c0315":"markdown","b9f43f54":"markdown","012f8996":"markdown","da2f617d":"markdown","0ab35895":"markdown","f9184847":"markdown","cfacef6a":"markdown","3051af18":"markdown","810e9be9":"markdown","c2e6fa78":"markdown","8f4d9625":"markdown"},"source":{"dfd57088":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns #visualization tools\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","2f75a416":"df=pd.read_csv(\"..\/input\/linearregression\/1.1 linear_regression_dataset.csv.csv\",sep = \";\")","f7ccfc65":"df.columns","9df093fb":"df.info()","02a31c27":"df.head()\n# The first 5 samples of the data set","63d14b82":"df.head(10)","e38ac8d7":"df.tail()\n# The last 5 samples of the data set","72dcce57":"df.dtypes","5dd04b5d":"# plot data\nplt.scatter(df.deneyim,df.maas)\nplt.xlabel(\"deneyim\")\nplt.ylabel(\"maas\")\nplt.show()","bf066c07":"# sklearn library\nfrom sklearn.linear_model import LinearRegression\n\n# linear regression model\nlinear_reg = LinearRegression()\n\nx = df.deneyim.values.reshape(-1,1)\ny = df.maas.values.reshape(-1,1)\n\nlinear_reg.fit(x,y)","e0a15eee":"#%% prediction\nimport numpy as np\n\n#b0 = linear_reg.predict(0)\n#print(\"b0: \",b0)\n\nb0 = linear_reg.intercept_\nprint(\"b0: \",b0)   # y eksenini kestigi nokta intercept\n\nb1 = linear_reg.coef_\nprint(\"b1: \",b1)   # egim slope","eafb31ee":"# maas = 1663 + 1138*deneyim \nmaas_yeni = 1663 + 1138*11\nprint(maas_yeni)","decd05cd":"print(linear_reg.predict([[11]]))","a3bbb95e":"# visualize line\narray = np.array([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]).reshape(-1,1)  # deneyim\n\n\nplt.scatter(x,y)\n\n\ny_head = linear_reg.predict(array)  # maas\n\nplt.plot(array, y_head,color = \"red\")\n\nplt.show()\nlinear_reg.predict([[100]])\n","a8a6bda4":"df=pd.read_csv(\"..\/input\/multiplelinear\/multiple_linear_regression_dataset.csv.csv\",sep = \";\")","9d68259a":"df.head()","c98942a1":"x = df.iloc[:,[0,2]].values\ny = df.maas.values.reshape(-1,1)","cb1e7767":"# %% fitting data\nfrom sklearn.linear_model import LinearRegression\nmultiple_linear_regression = LinearRegression()\nmultiple_linear_regression.fit(x,y)","72b92abf":"print(\"b0: \", multiple_linear_regression.intercept_)\nprint(\"b1,b2: \",multiple_linear_regression.coef_)","07c8a52a":"# predict\nmultiple_linear_regression.predict(np.array([[10,35],[5,35]]))","6d45d1e2":"array=np.array([[1,23],[5,29],[10,34],[12,38],[4,25],[15,40]])\narray","52692d9f":"import matplotlib.pyplot as plt\ny_head=multiple_linear_regression.predict(array)\n\nplt.scatter(x[:,0],y)\nplt.scatter(x[:,1],y,color=\"green\")\n\nplt.plot(array,y_head,color=\"red\")\nplt.show()\n\nmultiple_linear_regression.predict(np.array([[9,35]]))","1cdffbbf":"df=pd.read_csv(\"..\/input\/polynomialregression\/polynomial regression.csv\",sep = \";\")","d5d2c4a1":"df.head()","08f82d90":"df.info()","066855b3":"import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures","8bd781d4":"y = df.araba_max_hiz.values.reshape(-1,1)\nx = df.araba_fiyat.values.reshape(-1,1)","2ebdf01e":"plt.scatter(x,y)\nplt.ylabel(\"araba_max_hiz\")\nplt.xlabel(\"araba_fiyat\")\nplt.show()","b77b72ca":"lr = LinearRegression()\n\nlr.fit(x,y)","f774ac69":"y_head = lr.predict(x)","2ab24820":"plt.plot(x,y_head,color=\"red\",label =\"linear\")\nplt.show()\nprint(\"10 milyon tl lik araba hizi tahmini: \",lr.predict([[10000]]))","ff45ff55":"from sklearn.preprocessing import PolynomialFeatures\npolynomial_regression = PolynomialFeatures(degree = 2)\n\nx_polynomial = polynomial_regression.fit_transform(x)","8d2b7ab4":"x\nx_polynomial","3b5b8ffe":"# %% fit\nlinear_regression2 = LinearRegression()\nlinear_regression2.fit(x_polynomial,y)","08b12057":"y_head2 = linear_regression2.predict(x_polynomial)\n\nplt.plot(x,y_head2,color= \"green\",label = \"poly\")\nplt.legend()\nplt.show()","7e97774e":"print(linear_regression2.predict(polynomial_regression.fit_transform([[1600]])))","c30e1b79":"df = pd.read_csv(\"..\/input\/decisiontreeregression\/decisiontreeregressiondataset.csv\",sep = \";\")","8189d9eb":"x = df.iloc[:,0].values.reshape(-1,1)\ny = df.iloc[:,1].values.reshape(-1,1)","ba049ea9":"#%%  decision tree regression\nfrom sklearn.tree import DecisionTreeRegressor\ntree_reg = DecisionTreeRegressor()   # random sate = 0\ntree_reg.fit(x,y)","94194703":"#tree_reg.predict(5)","7744d648":"x_ = np.arange(min(x),max(x),0.01).reshape(-1,1)\ny_head = tree_reg.predict([[ x_]])","0bfd19c1":"# %% visualize\nplt.scatter(x,y,color=\"red\")\nplt.plot(x_,y_head,color = \"green\")\nplt.xlabel(\"tribun level\")\nplt.ylabel(\"ucret\")\nplt.show()","cacd2b1a":"df = pd.read_csv(\"..\/input\/decisiontreeregression\/decisiontreeregressiondataset.csv\",sep = \";\",header = None)","71bdb9e9":"df.head()","fa1b415e":"x = df.iloc[:,0].values.reshape(-1,1)\ny = df.iloc[:,1].values.reshape(-1,1)","fc06f5a7":"from sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor(n_estimators = 100, random_state = 42)\nrf.fit(x,y)","a776f020":"print(\"7.8 seviyesinde fiyat\u0131n ne kadar oldu\u011fu: \",rf.predict([[7.8]]))","076e4103":"**RANDOM FOREST REGRESS\u0130ON**\n\nRandom Forest is a flexible, easy to use machine learning algorithm that produces, even without hyper-parameter tuning, a great result most of the time. It is also one of the most used algorithms, because it\u2019s simplicity and the fact that it can be used for both classification and regression tasks.flexible, easy to use machine learning algorithm that produces, even without hyper-parameter tuning, a great result most of the time. It is also one of the most used algorithms, because it\u2019s simplicity and the fact that it can be used for both classification and regression tasks.Random Forest is a supervised learning algorithm.\n\n**To say it in simple words: Random forest builds multiple decision trees and merges them together to get a more accurate and stable prediction.**","042c0315":"**DEC\u0130S\u0130ON TREE REGRESS\u0130ON **","b9f43f54":"Polynomial regression is a form of regression analysis in which the relationship between the independent variable x and the dependent variable y is modelled as an nth degree polynomial in x. ","012f8996":"Linear regression is a basic and commonly used type of predictive analysis. These regression estimates are used to explain the relationship between one dependent variable and one or more independent variables.\nThe simplest form of the regression equation with one dependent and one independent variable is defined by the formula y = c + b*x, where y = estimated dependent variable score, c = constant, b = regression coefficient, and x = score on the independent variable.\n","da2f617d":"### POLYNOM\u0130AL L\u0130NEAR REGRESS\u0130ON","0ab35895":"### L\u0130NEAR REGRESS\u0130ON","f9184847":"> ","cfacef6a":"The decision tree is a simple machine learning model for getting started with regression tasks. Decision tree regression observes features of an object and trains a model in the structure of a tree to predict data in the future to produce meaningful continuous output. ","3051af18":" FOOTNOTE:\n- This tutorial will continue.\n- You can write your solution suggestions for the errors :)  ","810e9be9":"### Are you ready to start your path to becoming a Data Scientist ?! \nIn this tutorial, we will enter the world of machine learning with python. We will be your guide to learning how to use the power of Python to analyze data and using the powerful machine learning algorithms! Your only need is to understand basics of machine learning and how to implement it while using python. In python there are some ML libraries like sklearn, keras or tensorflow. We will use sklearn.\n\nYou can check out my previous tutorial :  [https:\/\/www.kaggle.com\/usengecoder\/introduction-to-data-science](http:\/\/)","c2e6fa78":"Multiple linear regression is the most common form of linear regression analysis.  As a predictive analysis, the multiple linear regression is used to explain the relationship between one continuous dependent variable and two or more independent variables. ","8f4d9625":"### MULT\u0130PLE L\u0130NEAR REGRESS\u0130ON"}}