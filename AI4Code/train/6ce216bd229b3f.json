{"cell_type":{"d6293a6f":"code","90dab6db":"code","656311cf":"code","d5961f2c":"code","e901d09b":"code","376b5a10":"code","1e386c37":"code","467db78d":"code","5ed4705a":"code","99253dcd":"code","a55063b1":"code","7b4a678a":"code","c9efcd28":"code","af7b942e":"code","795a8f7e":"code","f0c43ac7":"code","edf3ad80":"code","4ecf35c0":"code","6c291f2d":"code","41be46de":"code","8d133a4b":"code","cb27c9e7":"code","8ea0ec8a":"code","f100c0e4":"code","649eaf4d":"code","3e1f1134":"markdown","da61195f":"markdown","5e3f4630":"markdown","0f49a1ea":"markdown","d7d390ed":"markdown","db5ed96b":"markdown","c14a652c":"markdown"},"source":{"d6293a6f":"train_dir_path = '\/kaggle\/input\/dogcat-classificationcnn\/dataset\/training_set\/'\ntest_dir_path = '\/kaggle\/input\/dogcat-classificationcnn\/dataset\/test_set\/'\nimg_width =  img_height = 299 # width and height of input image (must be 299x299)","90dab6db":"from keras.preprocessing.image import ImageDataGenerator\n\n#Scale these values to a range of 0 to 1 before feeding them to the neural network model. To do so, divide the values by 255.\ntrain_datagen = ImageDataGenerator(rescale=1. \/ 255,\n                                   rotation_range=20,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   shear_range=0.2,\n                                   zoom_range=0.25,\n                                   horizontal_flip=True,\n                                   fill_mode='nearest')\n\n#Scale these values to a range of 0 to 1 before feeding them to the neural network model. To do so, divide the values by 255.\ntest_datagen = ImageDataGenerator(rescale=1. \/ 255)\n\ntrain_set = train_datagen.flow_from_directory(\n    train_dir_path,\n    target_size=(img_width, img_height),\n    batch_size=16,\n    class_mode='categorical',)\n\ntest_set = test_datagen.flow_from_directory(\n    test_dir_path,\n    target_size=(img_width, img_height),\n    batch_size=16,\n    class_mode='categorical',)","656311cf":"class_label = train_set.class_indices\nprint(class_label)","d5961f2c":"import os\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing import image \n\ndogs_image = os.listdir(train_dir_path+'dogs\/')[:12]\ncats_image = os.listdir(train_dir_path+'cats\/')[:12]\nimages = dogs_image + cats_image\nlabels = list(map(lambda x: x.split('.')[0], images))\nplt.figure(figsize=(13,13))\nfor i,name in enumerate(images):\n    plt.subplot(6,4,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    img = image.load_img(train_dir_path+labels[i]+'s\/'+name,target_size=(299,299))\n    plt.xlabel(labels[i])\n    plt.imshow(img)","e901d09b":"from keras.layers import GlobalAveragePooling2D, Dense, BatchNormalization, Dropout\nfrom keras.optimizers import Adam, SGD, RMSprop\nfrom keras.models import Model, Input\nfrom keras.applications import xception\n\n# create the base pre-trained model\nbase_model = xception.Xception(weights='imagenet', include_top=False)\n\n# add a global spatial average pooling layer\nx = base_model.output\nx = BatchNormalization()(x)\nx = GlobalAveragePooling2D()(x)\n# let's add a fully-connected layer\nx = Dropout(0.5)(x)\nx = Dense(1024, activation='relu')(x)\nx = Dropout(0.5)(x)\n# and a logistic layer\npredictions = Dense(2, activation='softmax')(x)\n\n# this is the model we will train\nmodel = Model(inputs=base_model.input, outputs=p-redictions)","376b5a10":"# freeze all convolutional Xception layers\nfor layer in base_model.layers:\n    layer.trainable = False\n\nmodel.summary()","1e386c37":"from keras.callbacks import ModelCheckpoint\n\noptimizer = RMSprop(lr=0.001, rho=0.9)\n\nmodel.compile(optimizer=optimizer,\n              loss='categorical_crossentropy',\n              metrics=[\"accuracy\"])\n\nhist = model.fit_generator(\n    train_set,\n    steps_per_epoch= train_set.samples \/\/ train_set.batch_size,\n    epochs=10,\n    validation_data=test_set,\n    validation_steps=test_set.samples \/\/ test_set.batch_size)","467db78d":"import matplotlib.pyplot as plt\n# summarize history for accuracy\nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","5ed4705a":"# we chose to train the top 2 xception blocks, i.e. we will freeze the first 116 layers and unfreeze the rest:\nfor layer in model.layers[:96]:\n    layer.trainable = False\nfor layer in model.layers[96:]:\n    layer.trainable = True\n    \nmodel.compile(optimizer=SGD(lr=0.0001, momentum=0.9),\n              loss='categorical_crossentropy',\n              metrics=[\"accuracy\"])\n\nhist = model.fit_generator(\n    train_set,\n    steps_per_epoch= train_set.samples \/\/ train_set.batch_size,\n    epochs=10,\n    validation_data=test_set,\n    validation_steps=test_set.samples \/\/ test_set.batch_size)","99253dcd":"import matplotlib.pyplot as plt\n# summarize history for accuracy\nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","a55063b1":"# we chose to train the top 2 xception blocks, i.e. we will freeze the first 116 layers and unfreeze the rest:\nfor layer in model.layers[:16]:\n    layer.trainable = False\nfor layer in model.layers[16:]:\n    layer.trainable = True\n    \nmodel.compile(optimizer=SGD(lr=0.0001, momentum=0.9),\n              loss='categorical_crossentropy',\n              metrics=[\"accuracy\"])\n\nhist = model.fit_generator(\n    train_set,\n    steps_per_epoch= train_set.samples \/\/ train_set.batch_size,\n    epochs=10,\n    validation_data=test_set,\n    validation_steps=test_set.samples \/\/ test_set.batch_size)","7b4a678a":"import matplotlib.pyplot as plt\n# summarize history for accuracy\nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","c9efcd28":"from PIL import Image\nimport requests\nfrom keras.preprocessing.image import img_to_array\nfrom keras.applications.xception import preprocess_input\nimport numpy as np","af7b942e":"def load_img_from_url(url):\n    img = Image.open(requests.get(url, stream=True).raw)\n    img = img.resize((299,299))\n    return img\n\ndef print_predict(img):\n    x = img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    x = preprocess_input(x)\n\n    pred = model.predict(x)\n    class_index = np.argmax(pred)\n    probability = pred[0][class_index]*100\n    print(probability)\n    if probability > 99:\n        if class_index == 0:\n            print('It is a cat')\n        elif class_index == 1:\n            print('It is a dog')\n    else:\n        print('I only detect cat and dog or try another image that have only 1 cat or dog')","795a8f7e":"img = load_img_from_url('https:\/\/vnreview.vn\/image\/19\/87\/64\/1987643.jpg')\nimg","f0c43ac7":"print_predict(img)","edf3ad80":"img = load_img_from_url('https:\/\/i.pinimg.com\/originals\/70\/c6\/46\/70c6461c88417f44ddb9926577eb3fb4.jpg')\nimg","4ecf35c0":"print_predict(img)","6c291f2d":"img = load_img_from_url('https:\/\/petviet.vn\/wp-content\/uploads\/2018\/03\/1803_5-ly-do-khien-ban-muon-nuoi-meo-ngay-lap-tuc-01.jpg')\nimg","41be46de":"print_predict(img)","8d133a4b":"img = load_img_from_url('https:\/\/www.nationalgeographic.com\/content\/dam\/animals\/pictures\/mammals\/a\/african-lion\/african-lion.adapt.1900.1.JPG')\nimg","cb27c9e7":"print_predict(img)","8ea0ec8a":"img = load_img_from_url('https:\/\/ss-images.catscdn.vn\/wpm450\/2020\/05\/22\/7523489\/son-tung-mtp-lo-anh-dung-do-doi-voi-thieu-bao-tram-9-15848102443021860636400.jpg')\nimg","f100c0e4":"print_predict(img)","649eaf4d":"model.save(\"cats_and_dogs.h5\")","3e1f1134":"## Fine-tuning model","da61195f":"## Compile the model\n* Loss function \u2014This measures how accurate the model is during training. You want to minimize this function to \"steer\" the model in the right direction.\n* Optimizer \u2014This is how the model is updated based on the data it sees and its loss function.\n* Metrics \u2014Used to monitor the training and testing steps. The following example uses accuracy, the fraction of the images that are correctly classified.","5e3f4630":"[](http:\/\/)## Explore the data\n* Let's explore the format of the dataset before training the model. The following shows there\nare 10.000 images in the total, 8.000 for training and 2.000 for val","0f49a1ea":"## Set up the layer\n* Use pre-trained model Xception, cut off the last Dense layer and replace with another Dense layer have 2 node logical output (2 classes)","d7d390ed":"# Test v\u1edbi h\u00ecnh \u1ea3nh tr\u00ean m\u1ea1ng","db5ed96b":"## Display the first 24 images from the training set and display the class name below each image.","c14a652c":"## Class labels"}}