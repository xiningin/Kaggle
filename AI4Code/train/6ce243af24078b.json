{"cell_type":{"47a8ad2a":"code","c017e39f":"code","a9da2150":"code","e00959ba":"code","dd2fa8ac":"code","0102d651":"code","8dcb7798":"code","4b14af8e":"code","aad7b167":"code","38d05970":"code","47cb3faa":"code","6c7d204d":"code","4dc393eb":"code","dd3684ee":"code","e43627c4":"code","76d738df":"code","b540f8f6":"code","26df8dd1":"code","4c78a446":"code","d80db505":"code","ea1fdb87":"code","65ac6ae9":"code","217d0a6d":"code","972625b6":"code","d864723d":"code","56f03959":"code","ee2b4394":"code","6674c487":"code","2f81ca89":"code","a87dde24":"code","7b1a7b6d":"code","ba4fa1aa":"code","316325ab":"code","fe104894":"code","19334199":"code","a36cc5f9":"code","6718d76f":"code","ff7ec28b":"code","aa6dc887":"code","54615ac4":"code","4daaa0d3":"code","ac396e8d":"code","115efe55":"code","388994b9":"code","61c87409":"code","40aa4083":"code","f1f132c6":"code","51b3d7f7":"code","5041aa49":"code","867650e4":"code","69520d05":"code","b7e1987e":"code","fa0b37e6":"code","0cf2fb38":"code","f222ff72":"code","54b38bb8":"code","c4a52078":"code","72847854":"code","3fbc94cc":"code","089ba405":"code","3624f1ba":"code","71d24712":"code","d11ff5cd":"code","c5eeb310":"code","c3eb50db":"code","0f3299aa":"code","56d074a5":"code","a439136a":"code","5568591f":"code","b31398eb":"code","62aeb08c":"markdown","e3c9efa9":"markdown","cb695ae7":"markdown","577020ef":"markdown","e58a1710":"markdown","9b1509cb":"markdown","8d637c43":"markdown","e0febdb4":"markdown","2899590e":"markdown","1666a6b4":"markdown","bc3332c1":"markdown","a5f34e29":"markdown","4f60adbe":"markdown","27960ec6":"markdown","48a5ddba":"markdown","28ff6282":"markdown","96a7f8e9":"markdown","f3e672a8":"markdown","caab8a45":"markdown","1c4f2edd":"markdown","18619dcd":"markdown","aeffec95":"markdown","a428f796":"markdown","33a35ed9":"markdown","73e4d45b":"markdown","b8e8cb22":"markdown","9bb71196":"markdown","1495569f":"markdown","2276eec7":"markdown","4d412d22":"markdown","fa11f2b0":"markdown","aa773154":"markdown","0d5f3083":"markdown","9c31bc31":"markdown","132e5fc1":"markdown","6349a79c":"markdown","072f072f":"markdown","ba6a4892":"markdown","4fde53d7":"markdown","fb7271aa":"markdown","3d160f5e":"markdown","3aa4b7ea":"markdown","0e877d53":"markdown","b59b6131":"markdown","005d193d":"markdown"},"source":{"47a8ad2a":"# basic analysis library\nimport sys\nimport numpy as np\nimport pandas as pd\n\n# visual eda library\nfrom pandas_profiling import ProfileReport\nimport webbrowser as web\n\n# visualization libraries\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nsns.set()\n\n# feature engineering library\nfrom sklearn.preprocessing import StandardScaler\n\n# classification modelling libraries\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\n\n# performance measurement library\nfrom sklearn import metrics as m\n\n# enable display of complete array\/dataframe\/series\nnp.set_printoptions(threshold = sys.maxsize)\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.max_colwidth', None)\n\n# ignoring warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint('All Required Libraries Imported')","c017e39f":"data = pd.read_csv('\/kaggle\/input\/machine-learning-for-diabetes-with-python\/diabetes_data.csv')\nprint(data.shape)\ndata.head()","a9da2150":"# classification of features\nnumerical = [var for var in data.columns if data[var].dtype != 'O' and var != 'Outcome']\ncategorical = [var for var in data.columns if data[var].dtype == 'O' and var != 'Outcome']\ntarget = ['Outcome']\nprint('There are', len(numerical), 'numerical variables')\nprint('There are', len(categorical), 'categorical variables')\nprint('There are', len(target), 'target variables')","e00959ba":"# summary statistics of data\ndata.describe()","dd2fa8ac":"# number and percentage of null values in data\nsum_null = data.isnull().sum()\nmean_null = data.isnull().mean()\nnulls = pd.concat([sum_null, mean_null], axis = 1)\nnulls.rename(columns = {0:'count', 1:'percentage'}, inplace = True)\nnulls","0102d651":"# identifying duplicate rows\ndata[data.duplicated()].shape[0]","8dcb7798":"# correlation matrix of the data\nfigure = plt.figure(figsize = (10, 10))\ncorr_matrix = data[numerical].corr().round(2)\nsns.heatmap(data = corr_matrix, annot = True)\n\n# the less correlation, the better. More correlation means presence of duplication of features","4b14af8e":"# distribution of all features\nfig, axes = plt.subplots(ncols = 4, nrows = 2, figsize = (20, 10))\n\nsns.kdeplot(data['Pregnancies'], ax = axes[0,0])\nsns.kdeplot(data['Glucose'], ax = axes[0,1])\nsns.kdeplot(data['BloodPressure'], ax = axes[0,2])\nsns.kdeplot(data['SkinThickness'], ax = axes[0,3])\nsns.kdeplot(data['Insulin'], ax = axes[1,0])\nsns.kdeplot(data['BMI'], ax = axes[1,1])\nsns.kdeplot(data['DiabetesPedigreeFunction'], ax = axes[1,2])\nsns.kdeplot(data['Age'], ax = axes[1,3])","aad7b167":"# pairplot for data\nsns.pairplot(data[numerical])\nplt.show()","38d05970":"# splitting data into train and test datasets\nX = data.drop(['Outcome'], axis = 1)\ny = data['Outcome']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\nX_train.shape, X_test.shape","47cb3faa":"# RandomForestClassifier model\nimodel = RandomForestClassifier()\nimodel.fit(X_train, y_train)","6c7d204d":"# training and testing accuracy\nprint('Training Accuracy:', imodel.score(X_train, y_train))\nprint('Testing Accuracy:', imodel.score(X_test, y_test))","4dc393eb":"# LogisticRegression model\nimodel2 = LogisticRegression()\nimodel2.fit(X_train, y_train)","dd3684ee":"# training and testing accuracy\nprint('Training Accuracy:', imodel2.score(X_train, y_train))\nprint('Testing Accuracy:', imodel2.score(X_test, y_test))","e43627c4":"# copy of orignial data, so that original data does not get overridden\ndata_clean = data.copy()\ndata_clean.head()","76d738df":"# outlier distribution of all features\nfig, axes = plt.subplots(ncols = 4, nrows = 2, figsize = (20, 10))\n\nsns.boxplot(y = data_clean['Pregnancies'], ax = axes[0,0])\nsns.boxplot(y = data_clean['Glucose'], ax = axes[0,1])\nsns.boxplot(y = data_clean['BloodPressure'], ax = axes[0,2])\nsns.boxplot(y = data_clean['SkinThickness'], ax = axes[0,3])\nsns.boxplot(y = data_clean['Insulin'], ax = axes[1,0])\nsns.boxplot(y = data_clean['BMI'], ax = axes[1,1])\nsns.boxplot(y = data_clean['DiabetesPedigreeFunction'], ax = axes[1,2])\nsns.boxplot(y = data_clean['Age'], ax = axes[1,3])","b540f8f6":"# boxplot of Pregnancies to check for outliers\nsns.boxplot(y = data_clean['Pregnancies'])","26df8dd1":"# summary statistics of Pregnancies\nprint(data_clean['Pregnancies'].describe())\niqr_pr = data_clean['Pregnancies'].describe()['75%'] - data_clean['Pregnancies'].describe()['25%']\nprint('Inter Quartile Range ', iqr_pr)\nlower_limit_pr = data_clean['Pregnancies'].describe()['25%'] - (1.5 * iqr_pr)\nupper_limit_pr = data_clean['Pregnancies'].describe()['75%'] + (1.5 * iqr_pr)\nprint('Lower Limit ', lower_limit_pr)\nprint('Upper Limit ', upper_limit_pr)","4c78a446":"# target level summary statistics\npreg_stats = pd.concat([data_clean[data_clean['Outcome'] == 0]['Pregnancies'].describe(), data_clean[data_clean['Outcome'] == 1]['Pregnancies'].describe()], axis = 1)\npreg_stats.columns = ['Outcome 0','Outcome 1']\npreg_stats","d80db505":"# replacing outliers with 2nd Quartile value\n\n# outcome 0\ndata_clean.loc[(data_clean['Pregnancies'] > upper_limit_pr) & (data_clean['Outcome'] == 0), 'Pregnancies'] = data_clean[data_clean['Outcome'] == 0]['Pregnancies'].describe()['50%']\n\n# outcome 1\ndata_clean.loc[(data_clean['Pregnancies'] > upper_limit_pr) & (data_clean['Outcome'] == 1), 'Pregnancies'] = data_clean[data_clean['Outcome'] == 1]['Pregnancies'].describe()['50%']\n\nsns.boxplot(y = data_clean['Pregnancies'])","ea1fdb87":"# boxplot of Glucose to check for outliers\nsns.boxplot(y = data_clean['Glucose'])","65ac6ae9":"# summary statistics of Glucose\nprint(data_clean['Glucose'].describe())\niqr_gl = data_clean['Glucose'].describe()['75%'] - data_clean['Glucose'].describe()['25%']\nprint('Inter Quartile Range ', iqr_gl)\nlower_limit_gl = data_clean['Glucose'].describe()['25%'] - (1.5 * iqr_gl)\nupper_limit_gl = data_clean['Glucose'].describe()['75%'] + (1.5 * iqr_gl)\nprint('Lower Limit ', lower_limit_gl)\nprint('Upper Limit ', upper_limit_gl)","217d0a6d":"# target level summary statistics\nglu_stats = pd.concat([data_clean[data_clean['Outcome'] == 0]['Glucose'].describe(), data_clean[data_clean['Outcome'] == 1]['Glucose'].describe()], axis = 1)\nglu_stats.columns = ['Outcome 0','Outcome 1']\nglu_stats","972625b6":"# replacing outliers with quartile values\n\n# outcome 0\ndata_clean.loc[(data_clean['Glucose'] < data_clean['Glucose'].describe()['25%']) & (data_clean['Outcome'] == 0), 'Glucose'] = data_clean[data_clean['Outcome'] == 0]['Glucose'].describe()['50%']\ndata_clean.loc[(data_clean['Glucose'] > data_clean['Glucose'].describe()['75%']) & (data_clean['Outcome'] == 0), 'Glucose'] = data_clean[data_clean['Outcome'] == 0]['Glucose'].describe()['75%']\n\n# outcome 1\ndata_clean.loc[(data_clean['Glucose'] < data_clean['Glucose'].describe()['25%']) & (data_clean['Outcome'] == 1), 'Glucose'] = data_clean[data_clean['Outcome'] == 1]['Glucose'].describe()['50%']\ndata_clean.loc[(data_clean['Glucose'] > data_clean['Glucose'].describe()['75%']) & (data_clean['Outcome'] == 1), 'Glucose'] = data_clean[data_clean['Outcome'] == 1]['Glucose'].describe()['75%']\n\nsns.boxplot(y = data_clean['Glucose'])","d864723d":"# boxplot of BloodPressure to check for outliers\nsns.boxplot(y = data_clean['BloodPressure'])","56f03959":"# summary statistics of BloodPressure\nprint(data_clean['BloodPressure'].describe())\niqr_bp = data_clean['BloodPressure'].describe()['75%'] - data_clean['BloodPressure'].describe()['25%']\nprint('Inter Quartile Range ', iqr_bp)\nlower_limit_bp = data_clean['BloodPressure'].describe()['25%'] - (1.5 * iqr_bp)\nupper_limit_bp = data_clean['BloodPressure'].describe()['75%'] + (1.5 * iqr_bp)\nprint('Lower Whisker ', lower_limit_bp)\nprint('Upper Whisker ', upper_limit_bp)","ee2b4394":"# target level summary statistics\nbp_stats = pd.concat([data_clean[data_clean['Outcome'] == 0]['BloodPressure'].describe(), data_clean[data_clean['Outcome'] == 1]['BloodPressure'].describe()], axis = 1)\nbp_stats.columns = ['Outcome 0','Outcome 1']\nbp_stats","6674c487":"# replacing outliers with median and 3rd quartile values\n\n# outcome 0\ndata_clean.loc[(data_clean['BloodPressure'] < data_clean['BloodPressure'].describe()['25%']) & (data_clean['Outcome'] == 0), 'BloodPressure'] = data_clean[data_clean['Outcome'] == 0]['BloodPressure'].describe()['50%']\ndata_clean.loc[(data_clean['BloodPressure'] > 95) & (data_clean['Outcome'] == 0), 'BloodPressure'] = data_clean[data_clean['Outcome'] == 0]['BloodPressure'].describe()['75%']\n\n# outcome 1\ndata_clean.loc[(data_clean['BloodPressure'] < data_clean['BloodPressure'].describe()['25%']) & (data_clean['Outcome'] == 1), 'BloodPressure'] = data_clean[data_clean['Outcome'] == 1]['BloodPressure'].describe()['50%']\ndata_clean.loc[(data_clean['BloodPressure'] > 95) & (data_clean['Outcome'] == 1), 'BloodPressure'] = data_clean[data_clean['Outcome'] == 1]['BloodPressure'].describe()['75%']\n\nsns.boxplot(y = data_clean['BloodPressure'])","2f81ca89":"# boxplot of SkinThickness to check for outliers\nsns.boxplot(y = data_clean['SkinThickness'])","a87dde24":"# summary statistics of SkinThickness\nprint(data_clean['SkinThickness'].describe())\niqr_st = data_clean['SkinThickness'].describe()['75%'] - data_clean['SkinThickness'].describe()['25%']\nprint('Inter Quartile Range ', iqr_st)\nlower_limit_st = data_clean['SkinThickness'].describe()['25%'] - (1.5 * iqr_st)\nupper_limit_st = data_clean['SkinThickness'].describe()['75%'] + (1.5 * iqr_st)\nprint('Lower Limit ', lower_limit_st)\nprint('Upper Limit ', upper_limit_st)","7b1a7b6d":"# target level summary statistics\nst_stats = pd.concat([data_clean[data_clean['Outcome'] == 0]['SkinThickness'].describe(), data_clean[data_clean['Outcome'] == 1]['SkinThickness'].describe()], axis = 1)\nst_stats.columns = ['Outcome 0','Outcome 1']\nst_stats","ba4fa1aa":"# replacing outliers with quartile value\n\n# outcome 0\ndata_clean.loc[(data_clean['SkinThickness'] < data_clean['SkinThickness'].describe()['50%']) & (data_clean['Outcome'] == 0), 'SkinThickness'] = data_clean[data_clean['Outcome'] == 0]['SkinThickness'].describe()['50%']\ndata_clean.loc[(data_clean['SkinThickness'] > data_clean['SkinThickness'].describe()['75%']) & (data_clean['Outcome'] == 0), 'SkinThickness'] = data_clean[data_clean['Outcome'] == 0]['SkinThickness'].describe()['75%']\n\n# outcome 1\ndata_clean.loc[(data_clean['SkinThickness'] < data_clean['SkinThickness'].describe()['50%']) & (data_clean['Outcome'] == 1), 'SkinThickness'] = data_clean[data_clean['Outcome'] == 1]['SkinThickness'].describe()['50%']\ndata_clean.loc[(data_clean['SkinThickness'] > data_clean['SkinThickness'].describe()['75%']) & (data_clean['Outcome'] == 1), 'SkinThickness'] = data_clean[data_clean['Outcome'] == 1]['SkinThickness'].describe()['75%']\n\nsns.boxplot(y = data_clean['SkinThickness'])","316325ab":"# boxplot of Insulin to check for outliers\nsns.boxplot(y = data_clean['Insulin'])","fe104894":"# summary statistics of Insulin\nprint(data_clean['Insulin'].describe())\niqr_in = data_clean['Insulin'].describe()['75%'] - data_clean['Insulin'].describe()['25%']\nprint('Inter Quartile Range ', iqr_in)\nlower_limit_in = data_clean['Insulin'].describe()['25%'] - (1.5 * iqr_in)\nupper_limit_in = data_clean['Insulin'].describe()['75%'] + (1.5 * iqr_in)\nprint('Lower Limit ', lower_limit_in)\nprint('Upper Limit ', upper_limit_in)","19334199":"# target level summary statistics\nin_stats = pd.concat([data_clean[data_clean['Outcome'] == 0]['Insulin'].describe(), data_clean[data_clean['Outcome'] == 1]['Insulin'].describe()], axis = 1)\nin_stats.columns = ['Outcome 0','Outcome 1']\nin_stats","a36cc5f9":"# replacing 0s with 2nd quartile value and outliers with 3rd quartile value\n\n# outcome 0\ndata_clean.loc[(data_clean['Insulin'] < data_clean['Insulin'].describe()['50%']) & (data_clean['Outcome'] == 0), 'Insulin'] = data_clean[data_clean['Outcome'] == 0]['Insulin'].describe()['50%']\ndata_clean.loc[(data_clean['Insulin'] > data_clean['Insulin'].describe()['75%']) & (data_clean['Outcome'] == 0), 'Insulin'] = data_clean[data_clean['Outcome'] == 0]['Insulin'].describe()['75%']\n\n# outcome 1\ndata_clean.loc[(data_clean['Insulin'] < data_clean['Insulin'].describe()['50%']) & (data_clean['Outcome'] == 1), 'Insulin'] = data_clean['Insulin'].describe()['50%']\ndata_clean.loc[(data_clean['Insulin'] > data_clean['Insulin'].describe()['75%']) & (data_clean['Outcome'] == 1), 'Insulin'] = data_clean[data_clean['Outcome'] == 1]['Insulin'].describe()['75%']\n\nsns.boxplot(y = data_clean['Insulin'])","6718d76f":"# boxplot of BMI to check for outliers\nsns.boxplot(y = data_clean['BMI'])","ff7ec28b":"# summary statistics of BMI\nprint(data_clean['BMI'].describe())\niqr_bmi = data_clean['BMI'].describe()['75%'] - data_clean['BMI'].describe()['25%']\nprint('Inter Quartile Range ', iqr_bmi)\nlower_limit_bmi = data_clean['BMI'].describe()['25%'] - (1.5 * iqr_bmi)\nupper_limit_bmi = data_clean['BMI'].describe()['75%'] + (1.5 * iqr_bmi)\nprint('Lower Limit ', lower_limit_bmi)\nprint('Upper Limit ', upper_limit_bmi)","aa6dc887":"# target level summary statistics\nbmi_stats = pd.concat([data_clean[data_clean['Outcome'] == 0]['BMI'].describe(), data_clean[data_clean['Outcome'] == 1]['BMI'].describe()], axis = 1)\nbmi_stats.columns = ['Outcome 0','Outcome 1']\nbmi_stats","54615ac4":"# replacing 0s with 1st quartile value and outliers with 3rd quartile value\n\n# outcome 0\ndata_clean.loc[(data_clean['BMI'] < data_clean['BMI'].describe()['25%']) & (data_clean['Outcome'] == 0), 'BMI'] = data_clean[data_clean['Outcome'] == 0]['BMI'].describe()['25%']\ndata_clean.loc[(data_clean['BMI'] > data_clean['BMI'].describe()['75%']) & (data_clean['Outcome'] == 0), 'BMI'] = data_clean[data_clean['Outcome'] == 0]['BMI'].describe()['75%']\n\n# outcome 1\ndata_clean.loc[(data_clean['BMI'] < data_clean['BMI'].describe()['25%']) & (data_clean['Outcome'] == 1), 'BMI'] = data_clean[data_clean['Outcome'] == 1]['BMI'].describe()['25%']\ndata_clean.loc[(data_clean['BMI'] > data_clean['BMI'].describe()['75%']) & (data_clean['Outcome'] == 1), 'BMI'] = data_clean[data_clean['Outcome'] == 1]['BMI'].describe()['75%']\n\nsns.boxplot(y = data_clean['BMI'])","4daaa0d3":"# boxplot of DiabetesPedigreeFunction to check for outliers\nsns.boxplot(y = data_clean['DiabetesPedigreeFunction'])","ac396e8d":"# summary statistics of DiabetesPedigreeFunction\nprint(data_clean['DiabetesPedigreeFunction'].describe())\niqr_dpf = data_clean['DiabetesPedigreeFunction'].describe()['75%'] - data_clean['DiabetesPedigreeFunction'].describe()['25%']\nprint('Inter Quartile Range ', iqr_dpf)\nlower_limit_dpf = data_clean['DiabetesPedigreeFunction'].describe()['25%'] - (1.5 * iqr_dpf)\nupper_limit_dpf = data_clean['DiabetesPedigreeFunction'].describe()['75%'] + (1.5 * iqr_dpf)\nprint('Lower Limit ', lower_limit_dpf)\nprint('Upper Limit ', upper_limit_dpf)","115efe55":"# target level summary statistics\ndpf_stats = pd.concat([data_clean[data_clean['Outcome'] == 0]['DiabetesPedigreeFunction'].describe(), data_clean[data_clean['Outcome'] == 1]['DiabetesPedigreeFunction'].describe()], axis = 1)\ndpf_stats.columns = ['Outcome 0','Outcome 1']\ndpf_stats","388994b9":"# replacing outliers with 3rd quartile value\n\n# outcome 0\ndata_clean.loc[(data_clean['DiabetesPedigreeFunction'] > data_clean['DiabetesPedigreeFunction'].describe()['75%']) & (data_clean['Outcome'] == 0), 'DiabetesPedigreeFunction'] = data_clean[data_clean['Outcome'] == 0]['DiabetesPedigreeFunction'].describe()['75%']\n\n# outcome 1\ndata_clean.loc[(data_clean['DiabetesPedigreeFunction'] > data_clean['DiabetesPedigreeFunction'].describe()['75%']) & (data_clean['Outcome'] == 1), 'DiabetesPedigreeFunction'] = data_clean[data_clean['Outcome'] == 1]['DiabetesPedigreeFunction'].describe()['75%']\n\nsns.boxplot(y = data_clean['DiabetesPedigreeFunction'])","61c87409":"# boxplot of Age to check for outliers\nsns.boxplot(y = data_clean['Age'])","40aa4083":"# summary statistics of Age\nprint('Mean\\t', data_clean['Age'].mean())\nprint('Median\\t', data_clean['Age'].median())\nprint(data_clean['Age'].describe())\niqr_age = data_clean['Age'].describe()['75%'] - data_clean['Age'].describe()['25%']\nprint('Inter Quartile Range ', iqr_age)\nlower_limit_age = data_clean['Age'].describe()['25%'] - (1.5 * iqr_age)\nupper_limit_age = data_clean['Age'].describe()['75%'] + (1.5 * iqr_age)\nprint('Lower Limit ', lower_limit_age)\nprint('Upper Limit ', upper_limit_age)","f1f132c6":"# target level summary statistics\nage_stats = pd.concat([data_clean[data_clean['Outcome'] == 0]['Age'].describe(), data_clean[data_clean['Outcome'] == 1]['Age'].describe()], axis = 1)\nage_stats.columns = ['Outcome 0','Outcome 1']\nage_stats","51b3d7f7":"# replacing outliers with 3rd quartile value\n\n# outcome 0\ndata_clean.loc[(data_clean['Age'] > 60) & (data_clean['Outcome'] == 0), 'Age'] = data_clean[data_clean['Outcome'] == 0]['Age'].describe()['75%']\n\n# outcome 1\ndata_clean.loc[(data_clean['Age'] > 60) & (data_clean['Outcome'] == 1), 'Age'] = data_clean[data_clean['Outcome'] == 1]['Age'].describe()['75%']\n\nsns.boxplot(y = data_clean['Age'])","5041aa49":"# distribution of all features before and after cleaning\nfig, axes = plt.subplots(ncols = 4, nrows = 2, figsize = (20, 10))\n\n# before cleaning\nsns.kdeplot(data['Pregnancies'], ax = axes[0,0])\nsns.kdeplot(data['Glucose'], ax = axes[0,1])\nsns.kdeplot(data['BloodPressure'], ax = axes[0,2])\nsns.kdeplot(data['SkinThickness'], ax = axes[0,3])\nsns.kdeplot(data['Insulin'], ax = axes[1,0])\nsns.kdeplot(data['BMI'], ax = axes[1,1])\nsns.kdeplot(data['DiabetesPedigreeFunction'], ax = axes[1,2])\nsns.kdeplot(data['Age'], ax = axes[1,3])\n\n# after cleaning\nsns.kdeplot(data_clean['Pregnancies'], ax = axes[0,0], color = 'green')\nsns.kdeplot(data_clean['Glucose'], ax = axes[0,1], color = 'green')\nsns.kdeplot(data_clean['BloodPressure'], ax = axes[0,2], color = 'green')\nsns.kdeplot(data_clean['SkinThickness'], ax = axes[0,3], color = 'green')\nsns.kdeplot(data_clean['Insulin'], ax = axes[1,0], color = 'green')\nsns.kdeplot(data_clean['BMI'], ax = axes[1,1], color = 'green')\nsns.kdeplot(data_clean['DiabetesPedigreeFunction'], ax = axes[1,2], color = 'green')\nsns.kdeplot(data_clean['Age'], ax = axes[1,3], color = 'green')","867650e4":"# pairplot for cleaned data\nsns.pairplot(data_clean[numerical])\nplt.show()","69520d05":"data_scal = data_clean.copy()\ndata_scal.head()","b7e1987e":"# splitting into train and test datasets\nX = data_scal.drop(['Outcome'], axis = 1)\ny = data_scal['Outcome']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\nX_train.shape, X_test.shape","fa0b37e6":"# fitting the scaler on the train data\nscaler = StandardScaler()\nscaler.fit(X_train[numerical])","0cf2fb38":"# transforming X_train and X_test\nX_train[numerical] = scaler.transform(X_train[numerical])\nX_test[numerical] = scaler.transform(X_test[numerical])\nX_train.head()","f222ff72":"# Logistic Regression model\nmodel_lr = LogisticRegression()\nmodel_lr.fit(X_train, y_train)","54b38bb8":"# training and testing accuracy\nprint('Logistic Training Accuracy:', model_lr.score(X_train, y_train))\nprint('Logistic Testing Accuracy:', model_lr.score(X_test, y_test))","c4a52078":"# Support Vector model\nmodel_svm = SVC()\nmodel_svm.fit(X_train, y_train)\n\n# training and testing accuracy\nprint('SVM Training Accuracy:', model_svm.score(X_train, y_train))\nprint('SVM Testing Accuracy:', model_svm.score(X_test, y_test))","72847854":"# KNeighborsClassifier model\nmodel_knn = KNeighborsClassifier()\nmodel_knn.fit(X_train, y_train)\n\n# training and testing accuracy\nprint('KNN Training Accuracy:', model_knn.score(X_train, y_train))\nprint('KNN Testing Accuracy:', model_knn.score(X_test, y_test))","3fbc94cc":"# MLPClassifier model\nmodel_mlp = MLPClassifier()\nmodel_mlp.fit(X_train, y_train)\n\n# training and testing accuracy\nprint('MLP Training Accuracy:', model_mlp.score(X_train, y_train))\nprint('MLP Testing Accuracy:', model_mlp.score(X_test, y_test))","089ba405":"# best parameter function\ndef print_results(y_pred, model):\n    print('\\nBest Parameters:',model.best_params_)\n    print('\\nPrediction Metrics:\\n')\n    print('Training Accuracy:', model.score(X_train, y_train))\n    print('Testing Accuracy:', model.score(X_test, y_test))\n    print('Precision:', m.precision_score(y_test, y_pred, average = 'weighted'))\n    print('Recall:', m.recall_score(y_test, y_pred, average = 'weighted'))\n    print('F1-Score:', m.f1_score(y_test, y_pred, average = 'weighted'))","3624f1ba":"# Logistic Regression Model\nmodel_lr = LogisticRegression(random_state = 0)\nparams_lr = {'C':[1,5,10,50], 'solver':['newton-cg','lbfgs','liblinear','sag','saga'], 'max_iter':[50,100,500]}\ngrid_lr = GridSearchCV(model_lr, params_lr, scoring = 'accuracy', cv = 5, verbose = 5, n_jobs = -1, return_train_score = True)\ngrid_lr.fit(X_train, y_train)","71d24712":"# best parameters\ny_pred_lr = grid_lr.predict(X_test)\nprint_results(y_pred_lr, grid_lr)","d11ff5cd":"# Support Vector Model\nmodel_svm = SVC(random_state = 0)\nparams_svm = {'C':[1,5,10,50], 'kernel':['rbf','poly','sigmoid','linear']}\ngrid_svm = GridSearchCV(model_svm, params_svm, scoring = 'accuracy', cv = 5, verbose = 5, n_jobs = -1, return_train_score = True)\ngrid_svm.fit(X_train, y_train)","c5eeb310":"# best parameters\ny_pred_svm = grid_svm.predict(X_test)\nprint_results(y_pred_svm, grid_svm)","c3eb50db":"# K-Nearest Neighbors Model\nmodel_knn = KNeighborsClassifier()\nparams_knn = {'n_neighbors':[5,10,20,50]}\ngrid_knn = GridSearchCV(model_knn, params_knn, scoring = 'accuracy', cv = 5, verbose = 5, n_jobs = -1, return_train_score = True)\ngrid_knn.fit(X_train, y_train)","0f3299aa":"# best parameters\ny_pred_knn = grid_knn.predict(X_test)\nprint_results(y_pred_knn, grid_knn)","56d074a5":"# MLP Classifier\nmodel_nn = MLPClassifier(random_state = 0)\nparams_nn = {'solver':['lbfgs','sgd','adam'], 'hidden_layer_sizes':[(50,50,50),(50,100,50),(100,)], \n             'learning_rate':['constant','invscaling','adaptive'], 'activation':['identity','logistic','tanh','relu']}\ngrid_nn = GridSearchCV(model_nn, params_nn, scoring = 'accuracy', cv = 5, verbose = 5, n_jobs = -1, return_train_score = True)\ngrid_nn.fit(X_train, y_train)","a439136a":"# best parameters\ny_pred_nn = grid_nn.predict(X_test)\nprint_results(y_pred_nn, grid_nn)","5568591f":"# performance metrics dataframe\nperf_mets = pd.DataFrame({'Model':['LR','SVM','KNN','MLP'],\n                          'Training Accuracy':[grid_lr.score(X_train, y_train), grid_svm.score(X_train, y_train), \n                                               grid_knn.score(X_train, y_train), grid_nn.score(X_train, y_train)],\n                          'Testing Accuracy':[grid_lr.score(X_test, y_test), grid_svm.score(X_test, y_test), \n                                               grid_knn.score(X_test, y_test), grid_nn.score(X_test, y_test)],\n                          'Precision':[m.precision_score(y_test, y_pred_lr, average = 'weighted'), \n                                      m.precision_score(y_test, y_pred_svm, average = 'weighted'), \n                                      m.precision_score(y_test, y_pred_knn, average = 'weighted'),\n                                      m.precision_score(y_test, y_pred_nn, average = 'weighted')],\n                          'Recall':[m.recall_score(y_test, y_pred_lr, average = 'weighted'), \n                                   m.recall_score(y_test, y_pred_svm, average = 'weighted'), \n                                   m.recall_score(y_test, y_pred_knn, average = 'weighted'), \n                                   m.recall_score(y_test, y_pred_nn, average = 'weighted')],\n                          'F1-Score':[m.f1_score(y_test, y_pred_lr, average = 'weighted'), \n                                     m.f1_score(y_test, y_pred_svm, average = 'weighted'), \n                                     m.f1_score(y_test, y_pred_knn, average = 'weighted'), \n                                     m.f1_score(y_test, y_pred_nn, average = 'weighted')]\n                         }).set_index('Model')\n\nperf_mets_perc = perf_mets.style.format({'Training Accuracy': '{:,.2%}'.format,\n                                    'Testing Accuracy': '{:,.2%}'.format,\n                                    'Precision': '{:,.2%}'.format,\n                                    'Recall': '{:,.2%}'.format,\n                                    'F1-Score': '{:,.2%}'.format})\nperf_mets_perc","b31398eb":"# comparing the performance metrics\n\nfig, axes = plt.subplots(ncols = 3, nrows = 2, figsize = (15, 10))\n\nsns.barplot(x = perf_mets.index, y = perf_mets['Training Accuracy'], ax = axes[0,0], order = perf_mets.sort_values('Training Accuracy', ascending = False).index)\nsns.barplot(x = perf_mets.index, y = perf_mets['Testing Accuracy'], ax = axes[0,1], order = perf_mets.sort_values('Testing Accuracy', ascending = False).index)\nsns.barplot(x = perf_mets.index, y = perf_mets['Precision'], ax = axes[0,2], order = perf_mets.sort_values('Precision', ascending = False).index)\nsns.barplot(x = perf_mets.index, y = perf_mets['Recall'], ax = axes[1,0], order = perf_mets.sort_values('Recall', ascending = False).index)\nsns.barplot(x = perf_mets.index, y = perf_mets['F1-Score'], ax = axes[1,1], order = perf_mets.sort_values('F1-Score', ascending = False).index)\n\nfig.delaxes(axes[1,2])\n\nfor i in range(2):\n    for j in range(3):\n        for bar in axes[i,j].patches:\n            axes[i,j].annotate(format(bar.get_height(), '.2%'), (bar.get_x() + bar.get_width() \/ 2, bar.get_height()), ha = 'center', va = 'center', size = 15, xytext = (0, 8), textcoords = 'offset points')\n\nfig.tight_layout()\nplt.show()","62aeb08c":"Now that we have trained and tested for the accuracies, let's tune the hyperparameters by using the GridSearchCV function.","e3c9efa9":"## Outliers Analysis","cb695ae7":"The lower values are valid, but we still need to replace the outliers. We will replace these outliers with the 3rd quartile values.","577020ef":"Pregnancies can be 0, but it cannot be as high as the upper whisker value of 13, so it'd be best to replace outliers with the respective median values .","e58a1710":"## Results","9b1509cb":"We have already seen that the data contains only numerical features, let us check whether any of them are stored as text.","8d637c43":"The above pairplot shows a neater correlation of all features with each other compared to the earlier one. Now that all variables are corrected, let's standardize the data.","e0febdb4":"## Initial Model","2899590e":"### Blood Presssure","1666a6b4":"The accuracies have improved very much compared to the initial model we ran at the beginning. So it can be said that our data was cleaned and scaled properly and effectively.","bc3332c1":"## Data Analysis","a5f34e29":"From the above heatmap, it can be seen that there is a high correlation between Pregnancies and Age (about 54%). Since the data size is small, it is obvious and we can ignore this for now.","4f60adbe":"There are outliers above the upper whisker, but insulin level value cannot be 0. So we need to replace these 0s with the median and the outliers with 3rd quartile values. Notice that the median of Insulin where Outcome = 1 is 0, so we replace this value with the overall median value.","27960ec6":"### Body Mass Index (BMI)","48a5ddba":"## Feeding Processed Data to Model","28ff6282":"The Glucose value cannot be 0, and it also cannot be as high as the maximum value (199), so we need to replace 0s with respective median values and upper (considerable) outliers with the respectuve 3rd quartile values.","96a7f8e9":"### Pregnancies","f3e672a8":"The SkinThickness value cannot be 0. So we replace this value with the median, and the outliers with the 3rd Quartile values.","caab8a45":"## Hyperparameter Tuning","1c4f2edd":"From the above table, it is obvious that there are no null values in our data.","18619dcd":"Take a look at the data above. All the features are at different scales. This would definitely affect the performance of the model. So we need to transform the data so that all features are at a common scale. For this purpose, we use Standardization.","aeffec95":"The above plots shows the performance metrics of each model in decreasing order of their magnitudes. As per the plots, we can see that MLP Classifer performs better than the other algorithms.","a428f796":"As we can see, all the features are now at a common scale. This would definitely help in the model performance. Now that our data is ready to be fed to the model, let us run the model.","33a35ed9":"### Insulin","73e4d45b":"### Glucose","b8e8cb22":"As discussed in the beginning, tree-based algorithms (like Decision Tree, Random Forest, Gradient Boost etc.) are not suitable for this data as they overfit on this data. So we start with Logistic Regression.","9bb71196":"BMI value cannot be 0. So we need to replace these outliers with the 1st quartile and 3rd quartile values.","1495569f":"All the other values look valid, so we need to replace the outliers with the 3rd quartile values. Since the upper whisker value (66) itself is an outlier (according to boxlpot), we can reduce it to 60.","2276eec7":"## Standardization","4d412d22":"## Importing the Required Libraries","fa11f2b0":"So there are no features which are stored as text, so we can safely proceed. Let us see the summary statistics of the data.","aa773154":"Now that all the features have been cleaned, let us compare the distributions of the features before and after cleaning.","0d5f3083":"## Loading the Data","9c31bc31":"# DIABETES PREDICTION MODELLING","132e5fc1":"### Skin Thickness","6349a79c":"### Diabetes Pedigree Function","072f072f":"Let us feed the data to few other models as well and check their performance.","ba6a4892":"## Summary","4fde53d7":"The training accuracy is 100%, which indicates that the model is clearly overfitting. The same would be for other tree based models. So tree based algorithms are not suitable for this type of data.","fb7271aa":"In this notebook, \n1. We have analyzed the data, the number of numerical and categorial variables and also the summary statistics of the dataset.\n2. We have run an initial model to check the performance of the model on the data.\n3. We have analyzed the outliers and handled them effectively with suitable techniques.\n4. We have standardized the features so that all features are on a common scale.\n5. We have run the models on the corrected and standardized data and have found out its performance metrics.\n6. We have tuned the hyperparameters of the models to get the model with best set of hyperparameters.","3d160f5e":"The BloodPressure value cannot be zero, and also it cannot be as high as the maximum values (122 and 114). So we will replace these small values with medians and higher values (>95) with 3rd quartile values.","3aa4b7ea":"### Age","0e877d53":"Nor there are any duplicate rows.","b59b6131":"Here the training and testing accuracies are quite low, plus the testing accuracy is greater than the training accuracy. So we need to process and correct the data in order to improve the accuracies.","005d193d":"Since there are no missing values, let's run a sample model to check on the performance of the model on the current data."}}