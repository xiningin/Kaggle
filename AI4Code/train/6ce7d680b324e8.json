{"cell_type":{"b330d151":"code","e7cad0eb":"code","67ff530e":"code","985f7f7f":"code","957ad87d":"code","b740a541":"code","27284639":"code","013db66f":"code","12c72d57":"code","28fb43f6":"code","3c79dcad":"code","879ed096":"code","e829439f":"code","5c71e151":"code","c2338ae2":"code","165387a2":"code","f7b39595":"code","7ad5d82c":"code","1a2d5cb0":"code","79a1f261":"code","6ed1eda7":"code","cff9b5a0":"code","2f368166":"code","77fe89ce":"code","5ddd4723":"code","56ffc900":"code","e3a57bb0":"code","2bda6a87":"code","ea04eb0a":"code","1cf8e943":"code","61b08201":"code","2e655760":"code","10db8858":"code","fa8f3c4e":"code","864775bf":"markdown","8e2138f5":"markdown","1ff45a65":"markdown","1ae177f3":"markdown","5416fc1f":"markdown","8df1f810":"markdown","c94d0978":"markdown","a8b9baf3":"markdown","5e4e2f51":"markdown","49230150":"markdown","4484e3d4":"markdown","817b348d":"markdown","0c003b75":"markdown","6015d60e":"markdown","1543001b":"markdown","b45e562e":"markdown","b7073844":"markdown","4dc00e4a":"markdown","070752d7":"markdown"},"source":{"b330d151":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nfrom scipy.special import boxcox1p, inv_boxcox1p\nfrom scipy.stats import skew, boxcox_normmax","e7cad0eb":"data = pd.read_csv('..\/input\/best-trilogies-book-series-ever\/BestTrilogies_BookSeriesEver.csv')","67ff530e":"data.info()","985f7f7f":"data.head()","957ad87d":"data.describe()","b740a541":"data.describe(include=\"O\")","27284639":"data['peopleVoted'].value_counts()","013db66f":"data['peopleVoted'] = data['peopleVoted'].replace(-1,0)","12c72d57":"data[['totalRating', 'scoreValue']] = data[['totalRating', 'scoreValue']].replace(',','', regex=True)","28fb43f6":"data['avgRating'] = data['avgRating'].replace('[^\\d.]','', regex=True)","3c79dcad":"data['totalRating'] = data['totalRating'].replace('[^\\d]','', regex=True)","879ed096":"data[['totalRating', 'scoreValue']] = data[['totalRating', 'scoreValue']].astype(int)","e829439f":"data['avgRating'] = data['avgRating'].astype(float)","5c71e151":"data.head()","c2338ae2":"data.describe()","165387a2":"\"\"\"\nif you want to extract information in paranthesis for some reason.\nbook = pd.DataFrame()\nbook['Name'] = data['bookTitle'].replace(r'[^(]*\\(|\\)[^)]*','',regex=True)\n\"\"\"","f7b39595":"data = data.drop(['bookTitle', 'authorName'], axis=1)","7ad5d82c":"fig = plt.figure(figsize=(16,14))\nfor index,col in enumerate(data.columns):\n    plt.subplot(2,2,index+1)\n    sns.distplot(data.loc[:,col], kde=False)\nfig.tight_layout(pad=1.0)","1a2d5cb0":"fig = plt.figure(figsize=(10,10))\nfor index,col in enumerate(data.columns):\n    plt.subplot(2,2,index+1)\n    sns.boxplot(y=col, data=data)\nfig.tight_layout(pad=1.0)","79a1f261":"sns.heatmap(data.corr(), annot=True)","6ed1eda7":"data.skew()","cff9b5a0":"highly_skewed = data.drop('avgRating', axis=1).columns","2f368166":"data_unskewed = pd.DataFrame()\nfor col in highly_skewed:\n    data_unskewed[col] = boxcox1p(data[col], boxcox_normmax(data[col]+1))\ndata_unskewed.skew()","77fe89ce":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.svm import SVR\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.model_selection import cross_val_score","5ddd4723":"X = data_unskewed.drop('totalRating', axis=1).join(data['avgRating'])\ny = data_unskewed['totalRating']","56ffc900":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)","e3a57bb0":"scaler = StandardScaler().fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","2bda6a87":"def inv_pred(y_pred):\n    return inv_boxcox1p(y_pred, boxcox_normmax(data['totalRating']+1))","ea04eb0a":"lr = LinearRegression().fit(X_train, y_train)\ny_pred_lr = lr.predict(X_test)\ny_pred_inv = inv_pred(y_pred_lr)\nmean_absolute_error(y_pred_inv, y_test)","1cf8e943":"svr = SVR(C=20, epsilon=0.01, gamma=0.0001, tol=0.0001)\nsvr.fit(X_train, y_train)\ny_pred = svr.predict(X_test)\ny_pred_inv = inv_pred(y_pred)\nmean_absolute_error(y_pred_inv, y_test)","61b08201":"xgb = XGBRegressor(learning_rate=0.001, n_estimators=3000,\n    max_depth=4, min_child_weight=0,\n    subsample=0.8, colsample_bytree=0.4,\n    nthread=-1, scale_pos_weight=2,\n    seed=42)\nxgb.fit(X_train, y_train)\ny_pred = xgb.predict(X_test)\ny_pred_inv = inv_pred(y_pred)\nmean_absolute_error(y_pred_inv, y_test)","2e655760":"lgbm = LGBMRegressor(objective='regression', n_estimators=3000,\n                         num_leaves=5, learning_rate=0.0001,\n                         max_bin=150, bagging_fraction=0.3,\n                         n_jobs=-1, bagging_freq=7,\n                         feature_fraction=0.1, min_data_in_leaf=8)\nlgbm.fit(X_train, y_train)\ny_pred = lgbm.predict(X_test)\ny_pred_inv = inv_pred(y_pred)\nmean_absolute_error(y_pred_inv, y_test)","10db8858":"def blend_model(X, a, b, c):\n    return((a*lgbm.predict(X)) + (b*xgb.predict(X)) + (c*svr.predict(X)))","fa8f3c4e":"y_pred = blend_model(X_test, 0.45, 0.25, 0.30)\ny_pred_inv = inv_pred(y_pred)\nmean_absolute_error(y_pred_inv, y_test)","864775bf":"Removing the skewness will help in dealing with outliers and also reduces the correlation between features.","8e2138f5":"We drop these feature's because I dont think they will be of much use in the prediction of our target variable. We could use the name of Author as a feature because the rating and popularity of a book change's depending on the popularity of its Author. Maybe we will try to use it in a future version.","1ff45a65":"# Preprocessing","1ae177f3":"We can see that except avgRating, other columns are highly skewed and we have to do something to resolve it.","5416fc1f":"Reduced the skewness in our data","8df1f810":"# Visualization","c94d0978":"We replace the negative value with 0 because it was causing problems when we were transforming our data.","a8b9baf3":"There are extreme outliers in every feature except avgRating.\nNote that totalRating is displayed with the help of complex number.","5e4e2f51":"Thanks for reading my Notebook, kindly upvote it will help a lot, feedbacks and suggestions are appreciated.","49230150":"# Data Cleaning","4484e3d4":"**Feature information**\n\n1)bookTitle: Contains the name of the books\n\n2)authorName: Contains name of the Author\n\n3)avgRating: Contains the average rating of the book\n\n4)totalRating: Contains the number of people who have rated the book\n\n5)scoreValue: Contains a score which is calculated using avgRating and peopleVote\n\n6)peopleVoted: Number of people who upvoted the book","817b348d":"function to revert the boxcox transformation of our target variable.","0c003b75":"Now we will convert avgRating, totalRating and scoreValue to numeric datatype.","6015d60e":"Scorevalue and peopleVoted have a correlation value of 1, this means that scorevalue is almost totally based on peopleVoted.","1543001b":"We get a mean absolute error of 11519.34 after blending our models, Although this is greater than what LGBM achieved on its own, we expect it to generalize better to new data.","b45e562e":"We can see the description of our features and understand the data.","b7073844":"In this Notebook I am going to explore the dataset and predict a target feature by blending differrent models.","4dc00e4a":"# Data Exploration","070752d7":"We see that avgRating, totalRating and scoreValue are stored as Object type instead of numerical type's. This is because they contain some strings in between, we will get rid of them and store them as numerical values."}}