{"cell_type":{"3de77ae0":"code","a893204b":"code","3f7571cb":"code","b0842ec5":"code","bbaeb2fa":"code","d4fa1c82":"code","b4a76d7b":"code","28c1cb20":"code","bdb95e5e":"code","d2af28be":"code","d23774ff":"markdown","34f911c2":"markdown","0b859556":"markdown","707c0bf0":"markdown","ed174bb1":"markdown","401855cd":"markdown","a914c512":"markdown","068107f2":"markdown","db1b04c2":"markdown","176ad787":"markdown","a80754f0":"markdown","05b5bbfb":"markdown","83ac99f8":"markdown","1e0875c5":"markdown","b51d5fb9":"markdown","fb22f7a0":"markdown","780ca1b0":"markdown","4d676c0a":"markdown","a0cc37f4":"markdown"},"source":{"3de77ae0":"# Load the numpy and panda package for linear algebra and data processing\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Imports packages to view data\nimport cv2\nfrom glob import glob\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\n# Import keras packages\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.regularizers import l2\n\n# package necessary to load in data\nimport os\n\n# set folders were data is stored\n# To extract all images from kaggle, save the directories for the training, validation and test set\ntrain_data_dir = \"..\/input\/chest-xray-pneumonia\/chest_xray\/train\"\nval_data_dir = \"..\/input\/chest-xray-pneumonia\/chest_xray\/val\"\ntest_data_dir = \"..\/input\/chest-xray-pneumonia\/chest_xray\/test\"","a893204b":"# Set up folders for normal cases and pneumonia cases wihtin our train data\ntrain_n = train_data_dir + '\/NORMAL\/'\ntrain_p = train_data_dir + '\/PNEUMONIA\/'\n\n# Random normal picture from train set\nprint(f\"Normal X-Rays From Validation Set: {len(os.listdir(train_n))} \")\n\n## Select 10 normal pictures\nnorm_pic = os.listdir(train_n)[25:35]\nnorm_pic_address = [train_n + pic for pic in norm_pic]\n\n# Random Pneumonia picture from train set\nprint(f\"Pneumonia X-Rays From Validation Set: {len(os.listdir(train_p))} \")\n\n## Select 10 Pneumonia pictures\npneumonia_pic =  os.listdir(train_p)[40:50]\npneumonia_address = [train_p + pic for pic in pneumonia_pic]\n\nfor i in range(0,10):\n    # Load the images\n    norm_img = Image.open(norm_pic_address[i])\n    pneumonia_img = Image.open(pneumonia_address[i])\n\n    #Let's plt these images\n    ## plot normal picture\n    f = plt.figure(figsize= (10,6))\n    a1 = f.add_subplot(1,2,1)\n    img_plot = plt.imshow(norm_img)\n    a1.set_title(f'Normal {norm_pic[i]}')\n\n    ## plot pneumonia picture\n    a2 = f.add_subplot(1, 2, 2)\n    img_plot = plt.imshow(pneumonia_img)\n    a2.set_title(f'Pneumonia {pneumonia_pic[i]}')","3f7571cb":"#  Create a data augmentor\ndata_augmentor = ImageDataGenerator(samplewise_center=True, rescale=1.\/255, shear_range=0.2,zoom_range = 0.2,samplewise_std_normalization=True,validation_split=0.2) \n\n# Set hyperparameters\ntarget_size = (128,128)   \ntarget_dims = (128, 128, 3) # add channel for RGB\nn_batch_size = 32 \n\n# Create datasets\ntrain_generator = data_augmentor.flow_from_directory(train_data_dir,  target_size=target_size, subset='training',batch_size= n_batch_size,class_mode='binary')\nval_generator = data_augmentor.flow_from_directory(train_data_dir, target_size=target_size,subset='validation',class_mode='binary')\ntest_generator = data_augmentor.flow_from_directory(test_data_dir, target_size=target_size,batch_size= 1,class_mode=None, shuffle=False)","b0842ec5":"def initialize_model(name):    \n    model = Sequential(name=name)\n    model.add(layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=target_dims, padding='same'))\n    model.add(layers.MaxPool2D(pool_size=(2, 2)))\n    model.add(Dropout(0.1))\n    \n    model.add(layers.Conv2D(64, (3, 3), activation=\"relu\", padding='same'))\n    model.add(layers.MaxPool2D(pool_size=(2, 2)))\n    model.add(Dropout(0.1))\n        \n    model.add(layers.Conv2D(128, (3, 3), activation=\"relu\", padding='same'))\n    model.add(layers.MaxPool2D(pool_size=(3, 3)))\n    model.add(Dropout(0.1))\n    \n    model.add(layers.Flatten())    \n    model.add(layers.Dense(64, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(layers.Dense(1, activation='sigmoid'))\n\n    return model","bbaeb2fa":"model = initialize_model(name=\"basemodel\")\nmodel.summary()","d4fa1c82":"def compile_model(model):\n    model.compile(optimizer=\"adam\",loss='binary_crossentropy',metrics=\"binary_accuracy\")\n    return model","b4a76d7b":"model_baseline = initialize_model(name=\"baseline\")\nhistory_baseline = compile_model(model_baseline)\n\ncallback = [EarlyStopping(patience=5, monitor='val_accuracy', restore_best_weights=True),\n            ReduceLROnPlateau(monitor = 'val_loss', patience = 2, factor=0.5, verbose=1),\n            ModelCheckpoint(\"xray_model_v2.h5\",save_best_only=True)]","28c1cb20":"history_baseline = model_baseline.fit(train_generator,\n                                      batch_size=n_batch_size,\n                                      epochs=10,\n                                      validation_data=val_generator,shuffle=True,\n                                      callbacks=callback) #,class_weight=class_weights)","bdb95e5e":"scores = model_baseline.evaluate(val_generator)\nscores","d2af28be":"history_frame = pd.DataFrame(history_baseline.history)\nhistory_frame.loc[:, ['loss', 'val_loss']].plot()\nhistory_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();","d23774ff":"### How do Deep Learning Networks distinguish between healthy and unhealthy lungs?\n\nMost deep neural network applied to the task of pneumonia diagnosis have been adapted from natural image classification. These models have a large number of parameters as well as high hardware requirements, which makes them prone to overfitting and harder to deploy in mobile settings. Some research on medical image classification by CNN has achieved performances rivaling human experts. For example, CheXNet, a CNN with 121 layers trained on a dataset with more than 100,000 frontal-view chest X-rays (ChestX-ray 14), achieved a better performance than the average performance of four radiologists. \n\nConvolutional Neural Networks are a common form of deep networks for classification tasks. The CNNs have extensive learning capacity and can infer the nature of an input image without any prior knowledge, which makes them a suitable method for image classification. CNNs make use of the following three properties:\n\n1. First, units in each layer receive inputs from the previous units which are located in a small neighborhood. This way, elementary features such as edges and corners can be extracted. Then these features will be combined in next layers to detect higher order features. \n2. Second important property is the concept of shared weights, which means similar feature detectors are used for the entire image. \n3. Finally, CNNs usually have several sub-sampling layers. These layers are based on the fact that the precise location of the features are not only beneficial, but also harmful, because this information tends to vary for different instances (Yadav & Jadhav, 2019).\n\nCNN-based methods have various strategies to increase the performance of image classifcation: \n- One method is data augmentation. Where the traditional transform-based data augmentation has better performance than generative adversarial network (GAN) and other neural networkbased methods. \n- Another method is transfer learning An accuracy of 92% accuracy is already achieved on a small pneumonia X-rays image dataset by transfer learning. \n- The third method is the capsule network, which achieves state-of-the-art performance on the Modifed National Institute of Standards and Technology (MNIST) database. Afshar, Mohammadi, and Plataniotis (2018) have utilized a Capsule Neural Network to detect brain tumors and got 86.56% accuracy. \n\n----\nAlthough CNNs have been proved to be useful in many areas,\nthey have several drawbacks specially related to the sub-sampling\nlayers, because these layers give a small amount of translational invariance and they loose the exact location of the most active feature detectors. In addition, CNN's have a hard time with small datasets. \nThe shortcomings of CNNs are mostly related to the pooling layers.\n--> As a result, in Capsule networks, these layers are replaced with a more appropriate criteria called \u201crouting by agreement.\u201d\nCapsule networks can effectively classify even in a limited data set (Toraman, Alakus, Turkoglu, 2020). \n\n----\n\nMost of the experts got high sensitivity but low specificity, while the CNN-based system got high values on both sensitivity and specificity. Moreover, on the average weight error measure, the CNN-based system exceeds two human experts.\n\n\n\n","34f911c2":"## Data Neural Network on Medical Image Classification\nThe dataset contains two kinds of chest X-ray Images: NORMAL and PNEUMONIA, which are stored in two folders.\nIn the PNEUMONIA folder, two types of specifc PNEUMONIA can be recognized by the fle name: BACTERIA and VIRUS.\n\n__Table 1.__ describes the composition of the dataset. The training dataset contains 5232 X-ray images, while the testing dataset contains 624 images. In the training dataset, the image in the NORMAL class only occupies one-fourth of all data. In the testing dataset, the PNEUMONIA consists of 62.5% of all data, which means the accuracy of the testing data should higher 62.5%.\n\n** **\n_Kermany, Daniel; Zhang, Kang; Goldbaum, Michael (2018), \u201cLabeled Optical Coherence Tomography (OCT) and Chest X-Ray Images for Classification\u201d, Mendeley Data, V2, doi: 10.17632\/rscbjbr9sj.2_","0b859556":"### Typification of misclassifications\n\n- What are the types of images where the model performs poorly.\n","707c0bf0":"#### 2.2 Build the model\n\nHere we create the structure of our model, we use the following layers:","ed174bb1":"### How do doctors distinguish between healthy and unhealthy lungs?\n\n__Figure 1.__ shows examples of chest X-rays from the dataset. The normal chest X-ray (left panel) depicts clear lungs without any areas of abnormal opacifcation in the image.\n\nBacterial pneumonia (middle) typically exhibits a focal lobar consolidation, in the right upper lobe (red rectangle), whereas viral pneumonia (right) manifests with a more difuse interstitial pattern in both lungs (Kermany et al., 2018).\n\n** **\n_Kermany, Daniel; Zhang, Kang; Goldbaum, Michael (2018), \u201cLabeled Optical Coherence Tomography (OCT) and Chest X-Ray Images for Classification\u201d, Mendeley Data, V2, doi: 10.17632\/rscbjbr9sj.2_\n\n\n\n**Figure 1**\n\n","401855cd":"## The Challenge\nBuild an algorithm to automatically identify whether a patient is suffering from pneumonia or not by looking at chest X-ray images. \n\n### 0.1 Load in data and all necessary packages","a914c512":"Evaluate the model by looking at a graph","068107f2":"### 2. Prepare the model\n\n#### 2.1 Prepare the data\n\nThere are no files in the validation folder as we have it right now. To generate validation samples we do the following:  \nSplit training data into train and validation (80:20) sets. To perform this specify validation_split parameter in ImageDataGenerator function. Set directory path to training directory so that the Generator can take data from training directory.\nTest generator Shuffle is set to FALSE. This is because, after predictions we want to plot our predictions to a Confusion Matrix and we want to be able to have one-one direct mapping of unshuffled samples.","db1b04c2":"## What is Pneumonia?\n\nPneumonia is a form of acute respiratory infection that affects the lungs. The lungs are made up of small sacs called alveoli, which fill with air when a healthy person breathes. When an individual has pneumonia, the alveoli are filled with pus and fluid, which makes breathing painful and limits oxygen intake.\n\nPneumonia is the single largest infectious cause of death in children worldwide. Pneumonia killed 740 180 children under the age of 5 in 2019, accounting for 14% of all deaths of children under five years old but 22% of all deaths in children aged 1 to 5. Pneumonia affects children and families everywhere, but deaths are highest in South Asia and sub-Saharan Africa.\n\n## The Importance of Diagnosing Pneumonia?\n\nDespite the fact that pneumonia is the most common\ncause of serious illness and death in young children\nworldwide, our ability, as clinicians, to infer an infectious\npathological process in the lung from specific features of\nthe history and examination is poor (Scott et al., 2012).\n\nMisdiagnosis, arbitrary charges, annoying queues, and clinic waiting times among others are long-standing phenomena in the medical industry across the world. These factors can contribute to patient anxiety about misdiagnosis by clinicians. However, with the increasing growth in use of big data in biomedical and health care communities, the performance of artificial intelligence (Al) techniques of diagnosis is improving and can help avoid medical practice errors.\n\nThe development of diverse AI techniques has contributed to early detections, disease diagnoses, and referral management. In addition, A total of 55.8% of the respondents (428 out of 767) opted for AI diagnosis regardless of the description of the clinicians (Liu et al., 2020)\n\n\nThe risk of pneumonia is immense for many, especially in developing nations where billions face energy poverty and rely on polluting forms of energy. Over 150 million people get infected with pneumonia on an annual basis especially children under 5\u2009years old. In such regions, the problem can be further aggravated due to the dearth of medical resources and personnel. For example, in Africa\u2019s 57 nations, a gap of 2.3 million doctors and nurses exists. For these populations, accurate and fast diagnosis means everything. It can guarantee timely access to treatment and save much needed time and money for those already experiencing poverty (Stephen, Sain, Maduh, & Jeong, 2019).\n\n\n****\n_Pneumonia. (2021, 11th of November). World Health Organisation. Consulted on 13th of December 2021, van https:\/\/www.who.int\/news-room\/fact-sheets\/detail\/pneumonia_\n\n_Scott, J. A. G., Wonodi, C., Mo\u00efsi, J. C., Deloria-Knoll, M., DeLuca, A. N., Karron, R. A., Bhat, N., Murdoch, D. R., Crawley, J., Levine, O. S., O\u2019Brien, K. L., & Feikin, D. R. (2012). The Definition of Pneumonia, the Assessment of Severity, and Clinical Standardization in the Pneumonia Etiology Research for Child Health Study. Clinical Infectious Diseases, 54(suppl_2), S109\u2013S116. https:\/\/doi.org\/10.1093\/cid\/cir1065_\n\n_Stephen, O., Sain, M., Maduh, U. J., & Jeong, D. U. (2019). An Efficient Deep Learning Approach to Pneumonia Classification in Healthcare. Journal of Healthcare Engineering, 2019, 1\u20137. https:\/\/doi.org\/10.1155\/2019\/4180949_\n","176ad787":"#### 2.3 Regularization\n\nIn order to prevent our model to overtrain we implement the following regularization measures. ","a80754f0":"![Schermafbeelding 2021-12-13 om 14.00.40.png](attachment:ecb0443e-b3b1-454a-94b6-6b82dcc45e26.png)\n\n","05b5bbfb":"- medicine: we are hired by the hospitle, First EDA with plots. How do docters distinguish between healthy and unhealthy lungs. \n- Then replicate \n- Then original new idea. Can be different architecture, if that makes sense. Can treat them all as hyperparameters to see which are best. \n- Little more consideration of the problem. Can you integrate data from a different place. What can you subtracts as features by hand. Hypotheses test between data augmentation (color flips not, but horizontal flips makes more sense)\n\nSome smart considerations of the problem as part of your notebook. \nI would always link it to medical, or diagnosis based on images papers. Articles newer than the dataset. Typification of misclassifications. What are the types of images where the model performs poorly. What types of images you got mispredictions. Usually you define a range of the hyperparameters (3, 4, 5, layes, this many nodes, max_pooling) list of combinations and will go through them. Only select the best one. You can only be better by thinking more about the problem, and caring about the mispredictions. \"oke Accuracy of 93, but we should look into sensitivity and specificity. Maybe in medical context these are more important. False negative more important, so optimize for sensitivity\"\nYou need to get creative there, and it just has to show that you care about the problem youre analysing. \n\nGrading: not accuracy, 100% on having a nice notebook (understanadble, citations, explanations, comments, graphs, pictures) just super readable. Engaging and readable. \nBAD: if it is copy pasted, problem, hyperparameter training, score. No creative additional original idea or perspective on the problem. Not more text than you need. \nthe less text, the better, the more informative plots, the better, extra points on creativity (make it original)\nJust add a nice original twist. \nPlanning: until next week you should have a skeleton: notebook with EDA, some model, some accuracy score and replicates some better earlier versions, and then start adding your project specific ideas.  \nClear goals until next week.","83ac99f8":"### Who performs better: Doctors or Deep Learning?","1e0875c5":"As we see there is a large bias towards Pneumonia data in the training set, only 25% of the data is normal data. If we built a classifier which would always label our data 1 we still would obtain a 75% accuracy. So we want to think about this, looking at false negatives is probably more informative of the model's performance. One way to deal with this issue is by adding class weights in to the layers.","b51d5fb9":"### 1. Exploratory Data Analysis \n\nThe first step in our project is conducting an exploratory analysis, and look what the data has to offer. We start with loading in the data to check the images to get an idea about the differences in the x-ray imagaes between the 2 classes. All the data is stored online in kaggle.\n\n#### 1.1 Look at Images\n\nWe start with looking at some chest x-rays to get a better idea about the differences between lungs suffering from pneumonia and normal lungs. When interpreting the x-ray, the radiologist will look for white spots in the lungs (called infiltrates) that identify an infection. The edges of the lung especially close to the diaphragm won't be clearly visible when there is an infection present. The same goes for the edges around the hearth and the aorta. In a study where they used chest x-rays to determine Community acquired pneumonia, there was a diagnostic accuracy of 93.1%, this is a benchmark for our model.","fb22f7a0":"### 4. Evaluate the model","780ca1b0":"![Schermafbeelding 2021-12-13 om 14.06.16.png](attachment:414d6d6f-b6c1-47b6-8e53-56434f452415.png)","4d676c0a":"### 3. Train the model\n\nNow it's time to train our model!!","a0cc37f4":"** **\n- Afshar, P., Mohammadi, A., & Plataniotis, K. N. (2018). Brain Tumor Type Classification via Capsule Networks. 2018 25th IEEE International Conference on Image Processing (ICIP). Published. https:\/\/doi.org\/10.1109\/icip.2018.8451379\n- Daniel, P., Bewick, T., Welham, S., Mckeever, T. M., & Lim, W. S. (2017). Adults miscoded and misdiagnosed as having pneumonia: results from the British Thoracic Society pneumonia audit. Thorax, 72(4), 376\u2013379. https:\/\/doi.org\/10.1136\/thoraxjnl-2016-209405\n- Fourcade, A., & Khonsari, R. (2019). Deep learning in medical image analysis: A third eye for doctors. Journal of Stomatology, Oral and Maxillofacial Surgery, 120(4), 279\u2013288. https:\/\/doi.org\/10.1016\/j.jormas.2019.06.002\n- Liu, T., Tsang, W., Huang, F., Lau, O. Y., Chen, Y., Sheng, J., Guo, Y., Akinwunmi, B., Zhang, C. J., & Ming, W. K. (2021). Patients\u2019 Preferences for Artificial Intelligence Applications Versus Clinicians in Disease Diagnosis During the SARS-CoV-2 Pandemic in China: Discrete Choice Experiment. Journal of Medical Internet Research, 23(2), e22841. https:\/\/doi.org\/10.2196\/22841\n- Liu, X., Faes, L., Kale, A. U., Wagner, S. K., Fu, D. J., Bruynseels, A., Mahendiran, T., Moraes, G., Shamdas, M., Kern, C., Ledsam, J. R., Schmid, M. K., Balaskas, K., Topol, E. J., Bachmann, L. M., Keane, P. A., & Denniston, A. K. (2019). A comparison of deep learning performance against health-care professionals in detecting diseases from medical imaging: a systematic review and meta-analysis. The Lancet Digital Health, 1(6), e271\u2013e297. https:\/\/doi.org\/10.1016\/s2589-7500(19)30123-2\n- Nagendran, M., Chen, Y., Lovejoy, C. A., Gordon, A. C., Komorowski, M., Harvey, H., Topol, E. J., Ioannidis, J. P. A., Collins, G. S., & Maruthappu, M. (2020). Artificial intelligence versus clinicians: systematic review of design, reporting standards, and claims of deep learning studies. BMJ, m689. https:\/\/doi.org\/10.1136\/bmj.m689\n- Nagendran, M., Chen, Y., Lovejoy, C. A., Gordon, A. C., Komorowski, M., Harvey, H., Topol, E. J., Ioannidis, J. P. A., Collins, G. S., & Maruthappu, M. (2020b). Artificial intelligence versus clinicians: systematic review of design, reporting standards, and claims of deep learning studies. BMJ, m689. https:\/\/doi.org\/10.1136\/bmj.m689\n- Shen, J., Zhang, C. J. P., Jiang, B., Chen, J., Song, J., Liu, Z., He, Z., Wong, S. Y., Fang, P. H., & Ming, W. K. (2019). Artificial Intelligence Versus Clinicians in Disease Diagnosis: Systematic Review. JMIR Medical Informatics, 7(3), e10010. https:\/\/doi.org\/10.2196\/10010\n- Toraman, S., Alakus, T. B., & Turkoglu, I. (2020). Convolutional capsnet: A novel artificial neural network approach to detect COVID-19 disease from X-ray images using capsule networks. Chaos, Solitons & Fractals, 140, 110122. https:\/\/doi.org\/10.1016\/j.chaos.2020.110122\n- Yadav, S. S., & Jadhav, S. M. (2019). Deep convolutional neural network based medical image classification for disease diagnosis. Journal of Big Data, 6(1). https:\/\/doi.org\/10.1186\/s40537-019-0276-2"}}