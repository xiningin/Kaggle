{"cell_type":{"879bd708":"code","7f71f528":"code","05dc107b":"code","eed47b2a":"code","12b05eda":"code","4af8eb9d":"code","0371540d":"code","3a5591d2":"code","5e34ffc2":"code","dd278b7d":"code","9b86662c":"code","7d7a7ab4":"code","c62b5471":"code","5820ebdb":"code","2fe74f36":"code","87317e9e":"code","7a2988f4":"code","e8f9888e":"code","7310bdd7":"code","7a2bf7b3":"code","c438b0f1":"code","a2a89843":"code","9bece8ca":"code","21f8e398":"code","53c23add":"code","ed9366a4":"code","aa3dcdc0":"code","42527bc2":"code","b8c85dad":"code","c164e650":"code","99a33482":"code","4b1d8f08":"markdown","6e01b01e":"markdown","c7da55cb":"markdown","56746ea9":"markdown","221405cd":"markdown"},"source":{"879bd708":"# old version\n!pip install transformers==3.5.1\n\n!pip install pyspellchecker\n\n!pip install -U joblib textblob\n!python -m textblob.download_corpora","7f71f528":"import pandas as pd\nimport torchtext  # torchtext\u3092\u4f7f\u7528\nfrom transformers import BertTokenizer, BertForMaskedLM, BertConfig\nimport transformers\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import optim\nfrom torch import cuda\nfrom sklearn.model_selection import train_test_split\nimport re\nimport string\n\n# augmentation\nfrom joblib import Parallel, delayed\nfrom textblob import TextBlob\nfrom textblob.translate import NotTranslated\n\n# sleep\nfrom time import sleep ","05dc107b":"train_val_df = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/test.csv\")","eed47b2a":"train_val_df = train_val_df.loc[:,[\"text\",\"target\"]]\ntest_df = test_df.loc[:,[\"text\"]]\ntest_df[\"target\"] = [0]*len(test_df[\"text\"]) ","12b05eda":"print(train_val_df)\nprint(test_df.head())","4af8eb9d":"train_val_df.head()","0371540d":"tokenizer = BertTokenizer.from_pretrained('bert-large-cased')","3a5591d2":"print(torch.__version__)","5e34ffc2":"# URL\u306e\u524a\u9664\ndef remove_URL(text):\n    url = re.compile(r'https?:\/\/\\S+|www\\.\\S+')\n    return url.sub(r'', text)\n\ntrain_val_df['text'] = train_val_df['text'].apply(lambda x : remove_URL(x))\ntest_df['text'] = test_df['text'].apply(lambda x : remove_URL(x))\n\n# html\u30bf\u30b0\u306e\u524a\u9664\ndef remove_html(text):\n    html = re.compile(r'<.*?>')\n    return html.sub(r'',text)\n\ntrain_val_df['text'] = train_val_df['text'].apply(lambda x : remove_html(x))\ntest_df['text'] = test_df['text'].apply(lambda x : remove_html(x))\n\n# \u7d75\u6587\u5b57\u306e\u524a\u9664\ndef remove_emoji(text):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', text)\n\ntrain_val_df['text'] = train_val_df['text'].apply(lambda x: remove_emoji(x))\ntest_df['text'] = test_df['text'].apply(lambda x: remove_emoji(x))\n\n# \u53e5\u8aad\u70b9\u306a\u3069\u306e\u524a\u9664\ndef remove_punct(text):\n    table = str.maketrans('','', string.punctuation)\n    return text.translate(table)\n\ntrain_val_df['text'] = train_val_df['text'].apply(lambda x : remove_punct(x))\ntest_df['text'] = test_df['text'].apply(lambda x : remove_punct(x))\n\n# \u8aa4\u3063\u305f\u30b9\u30da\u30eb\u306e\u82f1\u5358\u8a9e\u3092\u4fee\u6b63\nfrom spellchecker import SpellChecker\nspell = SpellChecker()\ndef correct_spellings(text):\n    corrected_text = []\n    misspelled_words = spell.unknown(text.split())\n    for word in text.split():\n        if word in misspelled_words:\n            corrected_text.append(spell.correction(word))\n        else:\n            corrected_text.append(word)\n    return \" \".join(corrected_text)\n        \ntrain_val_df['text'] = train_val_df['text'].apply(lambda x : correct_spellings(x))\ntest_df['text'] = test_df['text'].apply(lambda x : correct_spellings(x))","dd278b7d":"# \u9806\u756a\u3092\u30b7\u30e3\u30c3\u30d5\u30eb\u3059\u308b\ntrain_val_df = train_val_df.sample(frac=1, random_state=123).reset_index(drop=True)\ntrain_val_df.head()","9b86662c":"# tsv\u30d5\u30a1\u30a4\u30eb\u3067\u4fdd\u5b58\u3059\u308b\n\ntest_df.to_csv(\"test.tsv\", sep='\\t', index=False, header=None)\nprint(test_df.shape)\n\n# \u8a13\u7df4&\u691c\u8a3c\u30c7\u30fc\u30bf\u3068\u3059\u308b\ntrain_val_df.to_csv(\"train_eval.tsv\", sep='\\t', index=False, header=None)\nprint(train_val_df.shape)\n","7d7a7ab4":"max_length = 100\n\n\ndef tokenizer_100(input_text):\n    \"\"\"torchtext\u306etokenizer\u3068\u3057\u3066\u6271\u3048\u308b\u3088\u3046\u306b\u3001100\u5358\u8a9e\u306epytorch\u3067\u306eencode\u3092\u5b9a\u7fa9\u3002\u3053\u3053\u3067[0]\u3092\u6307\u5b9a\u3057\u5fd8\u308c\u306a\u3044\u3088\u3046\u306b\"\"\"\n    return tokenizer.encode(input_text, max_length=100, return_tensors='pt')[0]\n\n\nTEXT = torchtext.data.Field(sequential=True, tokenize=tokenizer_100, use_vocab=False, lower=False,\n                            include_lengths=True, batch_first=True, fix_length=max_length, pad_token=0)\n\nLABEL = torchtext.data.Field(sequential=False, use_vocab=False)","c62b5471":"# \u5404tsv\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u307f\u3001\u5206\u304b\u3061\u66f8\u304d\u3092\u3057\u3066dataset\u306b\u3059\u308b\n# \u5c11\u3057\u6642\u9593\u304c\u304b\u304b\u308b\ndataset_train_eval, dataset_test = torchtext.data.TabularDataset.splits(\n    path='.', train='.\/train_eval.tsv', test='.\/test.tsv', format='tsv', fields=[('Text', TEXT), ('Label', LABEL)])","5820ebdb":"# dataset\u306e\u9577\u3055\u3092\u78ba\u8a8d\nprint(dataset_train_eval.__len__())\nprint(dataset_test.__len__())","2fe74f36":"import random\n# torchtext.data.Dataset\u306esplit\u95a2\u6570\u3067\u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u691c\u8a3c\u30c7\u30fc\u30bf\u3092\u5206\u3051\u308b\n\ndataset_train, dataset_eval = dataset_train_eval.split(\n    split_ratio=1.0 - (1000\/7613), random_state=random.seed(1234))\n\n# dataset\u306e\u9577\u3055\u3092\u78ba\u8a8d\u3057\u3066\u307f\u308b\nprint(dataset_train.__len__())\nprint(dataset_eval.__len__())\nprint(dataset_test.__len__())","87317e9e":"# dataset\u306e\u4e2d\u8eab\u3092\u78ba\u8a8d\u3057\u3066\u307f\u308b\nitem = next(iter(dataset_train))\nprint(item.Text)\nprint(\"\u9577\u3055\uff1a\", len(item.Text))  # \u9577\u3055\u3092\u78ba\u8a8d [CLS]\u304b\u3089\u59cb\u307e\u308a[SEP]\u3067\u7d42\u308f\u308b\u3002512\u3088\u308a\u9577\u3044\u3068\u5f8c\u308d\u304c\u5207\u308c\u308b\nprint(\"\u30e9\u30d9\u30eb\uff1a\", item.Label)","7a2988f4":"# dataset\u306e\u4e2d\u8eab\u3092\u6587\u7ae0\u306b\u623b\u3057\u3001\u78ba\u8a8d\n\nprint(tokenizer.convert_ids_to_tokens(item.Text.tolist()))  # \u6587\u7ae0\nprint(int(item.Label))# id","e8f9888e":"# DataLoader\u3092\u4f5c\u6210\u3057\u307e\u3059\uff08torchtext\u306e\u6587\u8108\u3067\u306f\u5358\u7d14\u306biterater\u3068\u547c\u3070\u308c\u3066\u3044\u307e\u3059\uff09\nbatch_size = 32  # BERT\u3067\u306f16\u300132\u3042\u305f\u308a\u3092\u4f7f\u7528\u3059\u308b\n\ndl_train = torchtext.data.Iterator(\n    dataset_train, batch_size=batch_size, train=True)\n\ndl_eval = torchtext.data.Iterator(\n    dataset_eval, batch_size=batch_size, train=False, sort=False)\n\ndl_test = torchtext.data.Iterator(\n    dataset_test, batch_size=batch_size, train=False, sort=False)\n\n# \u8f9e\u66f8\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306b\u307e\u3068\u3081\u308b\ndataloaders_dict = {\"train\": dl_train, \"val\": dl_eval}","7310bdd7":"# DataLoader\u306e\u52d5\u4f5c\u78ba\u8a8d\n\nbatch = next(iter(dl_eval))\nprint(batch)\nprint(batch.Text[0].shape)\nprint(batch.Label.shape)","7a2bf7b3":"# transformers\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u78ba\u8a8d\nprint(transformers.__version__)","c438b0f1":"from transformers.modeling_bert import BertModel\n\n# BERT\u306e\u5b66\u7fd2\u6e08\u307f\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u30e2\u30c7\u30eb\nmodel = BertModel.from_pretrained('bert-large-cased')","a2a89843":"from torch import nn\n\n\nclass BertForTwitter(nn.Module):\n\n    def __init__(self):\n        super(BertForTwitter, self).__init__()\n\n        # BERT\u30e2\u30b8\u30e5\u30fc\u30eb\n        self.bert = model  # \u65e5\u672c\u8a9e\u5b66\u7fd2\u6e08\u307f\u306eBERT\u30e2\u30c7\u30eb\n\n        # head\u306b\u30af\u30e9\u30b9\u4e88\u6e2c\u3092\u8ffd\u52a0\n        # \u5165\u529b\u306fBERT\u306e\u51fa\u529b\u7279\u5fb4\u91cf\u306e\u6b21\u5143768\u3001\u51fa\u529b\u306f9\u30af\u30e9\u30b9\n        self.cls = nn.Linear(in_features=768, out_features=9)\n\n        # \u91cd\u307f\u521d\u671f\u5316\u51e6\u7406\n        nn.init.normal_(self.cls.weight, std=0.02)\n        nn.init.normal_(self.cls.bias, 0)\n\n    def forward(self, input_ids):\n        '''\n        input_ids\uff1a [batch_size, sequence_length]\u306e\u6587\u7ae0\u306e\u5358\u8a9eID\u306e\u7f85\u5217\n        '''\n\n        # BERT\u306e\u57fa\u672c\u30e2\u30c7\u30eb\u90e8\u5206\u306e\u9806\u4f1d\u642c\n        # \u9806\u4f1d\u642c\u3055\u305b\u308b\n        result = self.bert(input_ids)  # reult \u306f\u3001sequence_output, pooled_output\n\n        # sequence_output\u306e\u5148\u982d\u306e\u5358\u8a9e\u30d9\u30af\u30c8\u30eb\u3092\u629c\u304d\u51fa\u3059\n        vec_0 = result[0]  # \u6700\u521d\u306e0\u304csequence_output\u3092\u793a\u3059\n        vec_0 = vec_0[:, 0, :]  # \u5168\u30d0\u30c3\u30c1\u3002\u5148\u982d0\u756a\u76ee\u306e\u5358\u8a9e\u306e\u5168768\u8981\u7d20\n        vec_0 = vec_0.view(-1, 768)  # size\u3092[batch_size, hidden_size]\u306b\u5909\u63db\n        output = self.cls(vec_0)  # \u5168\u7d50\u5408\u5c64\n\n        return output","9bece8ca":"# \u30e2\u30c7\u30eb\u69cb\u7bc9\nnet = BertForTwitter()\n\n# \u8a13\u7df4\u30e2\u30fc\u30c9\u306b\u8a2d\u5b9a\nnet.train()\n\nprint('\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u8a2d\u5b9a\u5b8c\u4e86')","21f8e398":"# \u52fe\u914d\u8a08\u7b97\u3092\u6700\u5f8c\u306eBertLayer\u30e2\u30b8\u30e5\u30fc\u30eb\u3068\u8ffd\u52a0\u3057\u305f\u5206\u985e\u30a2\u30c0\u30d7\u30bf\u30fc\u306e\u307f\u5b9f\u884c\n\n# 1. \u307e\u305a\u5168\u90e8\u3092\u3001\u52fe\u914d\u8a08\u7b97False\u306b\u3057\u3066\u3057\u307e\u3046\nfor param in net.parameters():\n    param.requires_grad = False\n\n# 2. BertLayer\u30e2\u30b8\u30e5\u30fc\u30eb\u306e\u6700\u5f8c\u3092\u52fe\u914d\u8a08\u7b97\u3042\u308a\u306b\u5909\u66f4\nfor param in net.bert.encoder.layer[-1].parameters():\n    param.requires_grad = True\n\n# 3. \u8b58\u5225\u5668\u3092\u52fe\u914d\u8a08\u7b97\u3042\u308a\u306b\u5909\u66f4\nfor param in net.cls.parameters():\n    param.requires_grad = True","53c23add":"# \u6700\u9069\u5316\u624b\u6cd5\u306e\u8a2d\u5b9a\nimport torch.optim as optim\n\n\n# BERT\u306e\u5143\u306e\u90e8\u5206\u306f\u30d5\u30a1\u30a4\u30f3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\noptimizer = optim.Adam([\n    {'params': net.bert.encoder.layer[-1].parameters(), 'lr': 5e-5},\n    {'params': net.cls.parameters(), 'lr': 1e-4}\n])\n\n# \u640d\u5931\u95a2\u6570\u306e\u8a2d\u5b9a\ncriterion = nn.CrossEntropyLoss()\n# nn.LogSoftmax()\u3092\u8a08\u7b97\u3057\u3066\u304b\u3089nn.NLLLoss(negative log likelihood loss)\u3092\u8a08\u7b97","ed9366a4":"# \u30e2\u30c7\u30eb\u3092\u5b66\u7fd2\u3055\u305b\u308b\u95a2\u6570\u3092\u4f5c\u6210\n\n\ndef train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n    max_acc = 0\n    Stop_flag = False\n\n    # GPU\u304c\u4f7f\u3048\u308b\u304b\u3092\u78ba\u8a8d\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    print(\"\u4f7f\u7528\u30c7\u30d0\u30a4\u30b9\uff1a\", device)\n    print('-----start-------')\n\n    # \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092GPU\u3078\n    net.to(device)\n\n    # \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u304c\u3042\u308b\u7a0b\u5ea6\u56fa\u5b9a\u3067\u3042\u308c\u3070\u3001\u9ad8\u901f\u5316\u3055\u305b\u308b\n    torch.backends.cudnn.benchmark = True\n\n    # \u30df\u30cb\u30d0\u30c3\u30c1\u306e\u30b5\u30a4\u30ba\n    batch_size = dataloaders_dict[\"train\"].batch_size\n\n    # epoch\u306e\u30eb\u30fc\u30d7\n    for epoch in range(num_epochs):\n        # epoch\u3054\u3068\u306e\u8a13\u7df4\u3068\u691c\u8a3c\u306e\u30eb\u30fc\u30d7\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                net.train()  # \u30e2\u30c7\u30eb\u3092\u8a13\u7df4\u30e2\u30fc\u30c9\u306b\n            else:\n                net.eval()   # \u30e2\u30c7\u30eb\u3092\u691c\u8a3c\u30e2\u30fc\u30c9\u306b\n\n            epoch_loss = 0.0  # epoch\u306e\u640d\u5931\u548c\n            epoch_corrects = 0  # epoch\u306e\u6b63\u89e3\u6570\n            iteration = 1\n\n            # \u30c7\u30fc\u30bf\u30ed\u30fc\u30c0\u30fc\u304b\u3089\u30df\u30cb\u30d0\u30c3\u30c1\u3092\u53d6\u308a\u51fa\u3059\u30eb\u30fc\u30d7\n            for batch in (dataloaders_dict[phase]):\n                # batch\u306fText\u3068Lable\u306e\u8f9e\u66f8\u578b\u5909\u6570\n\n                # GPU\u304c\u4f7f\u3048\u308b\u306a\u3089GPU\u306b\u30c7\u30fc\u30bf\u3092\u9001\u308b\n                inputs = batch.Text[0].to(device)  # \u6587\u7ae0\n                labels = batch.Label.to(device)  # \u30e9\u30d9\u30eb\n\n                # optimizer\u3092\u521d\u671f\u5316\n                optimizer.zero_grad()\n\n                # \u9806\u4f1d\u642c\uff08forward\uff09\u8a08\u7b97\n                with torch.set_grad_enabled(phase == 'train'):\n\n                    # BERT\u306b\u5165\u529b\n                    outputs = net(inputs)\n\n                    loss = criterion(outputs, labels)  # \u640d\u5931\u3092\u8a08\u7b97\n\n                    _, preds = torch.max(outputs, 1)  # \u30e9\u30d9\u30eb\u3092\u4e88\u6e2c\n\n                    # \u8a13\u7df4\u6642\u306f\u30d0\u30c3\u30af\u30d7\u30ed\u30d1\u30b2\u30fc\u30b7\u30e7\u30f3\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                        if (iteration % 50 == 0):  # 10iter\u306b1\u5ea6\u3001loss\u3092\u8868\u793a\n                            acc = (torch.sum(preds == labels.data)\n                                   ).double()\/batch_size\n                            print('\u30a4\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3 {} || Loss: {:.4f} || 10iter. || \u672c\u30a4\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3\u306e\u6b63\u89e3\u7387\uff1a{}'.format(\n                                iteration, loss.item(),  acc))\n\n                    iteration += 1\n\n                    # \u640d\u5931\u3068\u6b63\u89e3\u6570\u306e\u5408\u8a08\u3092\u66f4\u65b0\n                    epoch_loss += loss.item() * batch_size\n                    epoch_corrects += torch.sum(preds == labels.data)\n\n            # epoch\u3054\u3068\u306eloss\u3068\u6b63\u89e3\u7387\n            epoch_loss = epoch_loss \/ len(dataloaders_dict[phase].dataset)\n            epoch_acc = epoch_corrects.double(\n            ) \/ len(dataloaders_dict[phase].dataset)\n\n            print('Epoch {}\/{} | {:^5} |  Loss: {:.4f} Acc: {:.4f}'.format(epoch+1, num_epochs,\n                                                                           phase, epoch_loss, epoch_acc))\n            # \u691c\u8a3c\u30d5\u30a7\u30fc\u30ba\u306e\u6642\u306b\u6700\u9ad8\u6b63\u89e3\u7387\u3088\u308a\u9023\u7d9a\u30673\u56de\u6b63\u89e3\u7387\u304c\u4e0b\u56de\u3063\u305f\u3089\u5b66\u7fd2\u3092\u3084\u3081\u308b\n            if phase == \"val\":\n                if epoch_acc < max_acc:\n                    count += 1\n                    if count >= 3:\n                        Stop_flag = True\n                else:\n                    count = 0\n                    max_acc = epoch_acc\n                print(count)\n                \n        if Stop_flag:\n            break\n\n\n    return net","aa3dcdc0":"# \u5b66\u7fd2\u30fb\u691c\u8a3c\u3092\u5b9f\u884c\u3059\u308b\u30021epoch\u306b1\u5206\u307b\u3069\u304b\u304b\u308b\nnum_epochs = 100\nnet_trained = train_model(net, dataloaders_dict,\n                          criterion, optimizer, num_epochs=num_epochs)","42527bc2":"from tqdm import tqdm\nans_list = []\n\n# \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3067\u306e\u6b63\u89e3\u7387\u3092\u6c42\u3081\u308b\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nnet_trained.eval()   # \u30e2\u30c7\u30eb\u3092\u691c\u8a3c\u30e2\u30fc\u30c9\u306b\nnet_trained.to(device)  # GPU\u304c\u4f7f\u3048\u308b\u306a\u3089GPU\u3078\u9001\u308b\n\n# epoch\u306e\u6b63\u89e3\u6570\u3092\u8a18\u9332\u3059\u308b\u5909\u6570\nepoch_corrects = 0\n\nfor batch in tqdm(dl_test):  # test\u30c7\u30fc\u30bf\u306eDataLoader\n    # batch\u306fText\u3068Lable\u306e\u8f9e\u66f8\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\n    # GPU\u304c\u4f7f\u3048\u308b\u306a\u3089GPU\u306b\u30c7\u30fc\u30bf\u3092\u9001\u308b\n    inputs = batch.Text[0].to(device)  # \u6587\u7ae0\n\n    # \u9806\u4f1d\u642c\uff08forward\uff09\u8a08\u7b97\n    with torch.set_grad_enabled(False):\n\n        # BertForTwitter\u306b\u5165\u529b\n        outputs = net_trained(inputs)\n        _, preds = torch.max(outputs, 1)  # \u30e9\u30d9\u30eb\u3092\u4e88\u6e2c\n        for i in preds:\n            ans_list.append(i.tolist())","b8c85dad":"print(ans_list)","c164e650":"sample_submission = pd.read_csv(\"..\/input\/nlp-getting-started\/sample_submission.csv\")\nsample_submission[\"target\"] = ans_list\nsample_submission","99a33482":"sample_submission.to_csv(\"submission_plus.csv\", index=False)","4b1d8f08":"## \u5b66\u7fd2\u306b\u7528\u3044\u308b[\"text\",\"target\"]\u306e\u30c7\u30fc\u30bf\u3060\u3051\u62bd\u51fa","6e01b01e":"## Read data(\u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f)","c7da55cb":"## BERT\u306etokenizer\u3092\u8aad\u307f\u8fbc\u307f","56746ea9":"## Install library(\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb)","221405cd":"## Library import(\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u30a4\u30f3\u30dd\u30fc\u30c8)"}}