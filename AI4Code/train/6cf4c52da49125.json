{"cell_type":{"b5c72ef3":"code","a78891b6":"code","0be77858":"code","efa182b6":"code","66d56c4b":"code","4088bef9":"code","b4d5fff4":"code","1bbc342b":"code","c55cd892":"code","c6f6a978":"code","f4288f6b":"code","4ed6d635":"code","d593c437":"code","0f76779d":"code","1d512c45":"code","94c6dab5":"code","e56493cc":"code","5a6749cf":"code","ca9467fa":"code","df80c449":"code","989042b7":"code","f91a646a":"code","986d4d5f":"code","5fb8da7d":"code","4e775d54":"code","2e86ed9c":"code","9def157e":"code","369ffdae":"code","92953ddd":"code","9310a649":"code","87b809a5":"code","9e431c80":"code","da25c130":"code","ed3a0414":"code","0b403984":"code","f818043e":"code","b863a1b1":"code","92f22caa":"code","29b624d7":"code","8037eabc":"code","6c703edd":"code","3e5f0052":"code","eda67ceb":"code","6bf29fff":"code","d6feb9fb":"code","eb78592e":"code","9594abac":"code","ffbe93df":"code","2d1c7569":"code","1ac0e3a6":"code","25790dd0":"code","f89adc93":"code","c1481457":"code","a9be3991":"code","74ca9278":"code","4a96d4c3":"code","bbc49f76":"code","fac09ab9":"code","baaf2fe0":"code","7ea09cde":"code","550d6be9":"code","7b04f70a":"code","c0cf0f83":"code","51e00ea5":"code","90523c10":"code","8333e050":"code","21ff3ed9":"code","88acfbcf":"code","b491745d":"code","74945dd0":"code","5ced7d06":"code","f8710246":"code","3a668cd4":"markdown","7bb7346f":"markdown"},"source":{"b5c72ef3":"import torch","a78891b6":"a = torch.tensor([1., 0, 4., -5])","0be77858":"a.dtype","efa182b6":"a.view(2,2)","66d56c4b":"m = torch.randn(3, 6,4)","4088bef9":"m","b4d5fff4":"2.1779 + 1.5733 - 2.1569","1bbc342b":"m.sum(dim=0)","c55cd892":"m.sum(dim=1)","c6f6a978":"m.mean(dim=-1)","f4288f6b":"m.device","4ed6d635":"torch.cuda.is_available()","d593c437":"mc = m.to('cuda')","0f76779d":"mc.device","1d512c45":"mc.device","94c6dab5":"a = torch.tensor([1.,2,3,4])","e56493cc":"mc + a.to('cuda')","5a6749cf":"w = torch.randn(4)","ca9467fa":"w.requires_grad_(True)","df80c449":"x = torch.tensor([1., 2., 3., 2.])","989042b7":"y_true = 5\nalpha = 0.001\nfor i in range(100):\n    y_pred = torch.dot(w,x)\n    loss = (y_pred - y_true) ** 2\n    print(y_pred.item(), loss.item())\n    loss.backward()\n    w.data -= alpha * w.grad\n    w.grad.zero_()","f91a646a":"w.data -= alpha * w.grad","986d4d5f":"X = torch.randn(30, 4)","5fb8da7d":"X","4e775d54":"w_true = torch.tensor([2., -1., 0, 0.5])\nb_true = -1","2e86ed9c":"X.size()","9def157e":"X.size(0)","369ffdae":"y = X.matmul(w_true) + b_true + torch.randn(X.size(0)) * 0.5","92953ddd":"y","9310a649":"y - (X.matmul(w_true) + b_true)","87b809a5":"w = torch.randn(4)","9e431c80":"b = torch.tensor(0.)","da25c130":"w.requires_grad_(True)","ed3a0414":"b.requires_grad_(True)","0b403984":"alpha = 0.001\nfor i in range(10000):\n    y_pred = torch.matmul(X, w) + b\n    loss = ((y_pred - y) ** 2).mean()\n    if i % 100 == 0:\n        print('loss:', loss.item())\n    loss.backward()\n    w.data -= alpha * w.grad\n    b.data -= alpha * b.grad\n    w.grad.zero_()\n    b.grad.zero_()\n    ","f818043e":"w.data","b863a1b1":"b.data","92f22caa":"w_true","29b624d7":"b_true","8037eabc":"from torch import nn","6c703edd":"class LinearReg(nn.Module):\n    def __init__(self, input_dim):\n        super().__init__()\n        self.linear = nn.Linear(input_dim, 1)\n        \n    def forward(self, X):\n        return self.linear(X).view(-1)","3e5f0052":"net = LinearReg(4)","eda67ceb":"criterion = nn.MSELoss()","6bf29fff":"optimizer = torch.optim.SGD(net.parameters(), lr=0.001)","d6feb9fb":"for i in range(10_000):\n    optimizer.zero_grad()\n    y_pred = net(X)\n    \n    loss = criterion(y_pred, y)\n    loss.backward()\n    \n    if i % 100 == 0:\n        print(\"loss: \", loss.item())\n    \n    optimizer.step()","eb78592e":"net.linear.weight","9594abac":"net.linear.bias","ffbe93df":"import numpy as np\nimport matplotlib.pyplot as plt","2d1c7569":"xx, yy = np.mgrid[-3:3:100j,-3:3:100j]","1ac0e3a6":"z = np.sqrt(xx**2 + yy**2 + 1)","25790dd0":"from mpl_toolkits.mplot3d import Axes3D","f89adc93":"fig = plt.figure()\nax = fig.add_subplot(projection='3d')\n\nax.plot_wireframe(xx,yy,z)","c1481457":"X_orig = torch.tensor(np.column_stack([xx.ravel(), yy.ravel(), z.ravel()])).type(torch.float32)","a9be3991":"X_orig","74ca9278":"X_orig.shape","4a96d4c3":"from torch.utils.data import TensorDataset, DataLoader","bbc49f76":"class AutoEncoder(nn.Module):\n    def __init__(self, input_dim, bottleneck_dim, hidden_dim):\n        super().__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, bottleneck_dim)\n        )\n        \n        self.decoder = nn.Sequential(\n            nn.Linear(bottleneck_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, input_dim)\n        )\n        \n    def forward(self, X):\n        return self.decoder(self.encoder(X))\n    \n    def encode(self, X):\n        return self.encoder(X)\n    \n    def decode(self, X_small):\n        return self.decoder(X_small)","fac09ab9":"auto_enc = AutoEncoder(input_dim=3,bottleneck_dim=2,hidden_dim=64).cuda()","baaf2fe0":"optimizer = torch.optim.Adam(auto_enc.parameters(), lr=3e-4)","7ea09cde":"dl = DataLoader(X_orig,batch_size=32, shuffle=True)","550d6be9":"from tqdm.notebook import tqdm","7b04f70a":"criteron = nn.MSELoss()","c0cf0f83":"n_epochs = 2\n\nfor epoch in range(n_epochs):\n    tqdm_iterator = tqdm(dl)\n    for X_batch in tqdm_iterator:\n        optimizer.zero_grad()\n        X_batch = X_batch.cuda()\n        X_pred = auto_enc(X_batch)\n        \n        loss = criterion(X_batch, X_pred)\n        loss.backward()\n        \n        tqdm_iterator.set_postfix({'loss': loss.item()})\n        \n        optimizer.step()","51e00ea5":"examples = X_orig[[5,9000,351]]","90523c10":"examples","8333e050":"with torch.no_grad():\n    print(auto_enc(examples.cuda()).cpu())","21ff3ed9":"with torch.no_grad():\n    X_compressed = auto_enc.encode(X_orig.cuda()).cpu().numpy()","88acfbcf":"X_compressed","b491745d":"plt.scatter(X_compressed[:,0],X_compressed[:,1],c=np.arange(X_orig.shape[0]), s=1)","74945dd0":"fig = plt.figure(figsize=(10,10))\n\nax = fig.add_subplot(projection='3d')\n\nax.scatter(X_orig[:,0],X_orig[:,1], X_orig[:,2],s=1,c=np.arange(X_orig.shape[0]))\nplt.show()","5ced7d06":"with torch.no_grad():\n    X_decompressed = auto_enc.decode(torch.tensor(X_compressed).cuda()).cpu().numpy()\n#     X_compressed = auto_enc.encode(X_orig.cuda()).cpu().numpy()","f8710246":"fig = plt.figure(figsize=(10,10))\nax = fig.add_subplot(projection='3d')\n\nax.scatter(X_decompressed[:,0],X_decompressed[:,1], X_decompressed[:,2],s=2,c=np.arange(X_orig.shape[0]))\nplt.show()","3a668cd4":"$${x^{2} \\over a^{2}}+{y^{2} \\over b^{2}}-{z^{2} \\over c^{2}}=1$$","7bb7346f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session"}}