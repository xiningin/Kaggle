{"cell_type":{"9c2da1c3":"code","628fe675":"code","7b3d4099":"code","8fadcc66":"code","887a06b4":"code","453a39bc":"code","6f580c43":"code","0c1b093d":"code","baad9c17":"code","06c84026":"code","d3508669":"code","0e850fd0":"code","5d7bd981":"code","c6f40e13":"code","3ae015b5":"code","9aa12cbf":"code","68d5e0ff":"markdown","99299dc1":"markdown","924651c6":"markdown"},"source":{"9c2da1c3":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.utils.data\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt","628fe675":"train=pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\").values\ntest=pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\").values","7b3d4099":"class dataset(torch.utils.data.Dataset):\n    \n    def __init__(self,data):\n        self.data=data\n        \n    def __getitem__(self,idx):\n        image=self.data[idx,1:].astype(np.float32)\n        label=self.data[idx,0:1].astype(np.float32)\n        \n        return image,label\n    \n    def __len__(self):\n        return len(self.data)","8fadcc66":"trainset=dataset(train)\ntrainloader=DataLoader(trainset,batch_size=64,shuffle=True)","887a06b4":"inp=784\nout=784\nhid=100\n\ndatasize=train.shape[0]\nbatchsize=64\nis_cuda=torch.cuda.is_available()","453a39bc":"class Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.encoder=nn.Linear(inp,hid)\n        self.decoder=nn.Linear(hid,out)\n        \n    def forward(self,x):\n        latent=self.encoder(x)\n        output=self.decoder(latent)\n        \n        return latent,output","6f580c43":"net=Net()\nif(is_cuda):\n    net=net.cuda()\noptim=torch.optim.Adam(net.parameters(),lr=0.001)\n\ndef loss_function(out,real):\n    mse=F.mse_loss(out,real,reduction=\"mean\")  \n    return mse","0c1b093d":"total_loss=[]\nfor epoch in range(10):\n    loss_count=0\n    for x,y in trainloader:\n        if(is_cuda):\n            x,y=x.cuda(),y.cuda()\n\n        _,output=net(x)\n        loss=loss_function(output,x)\n        loss_count+=loss.item()\n\n        net.zero_grad()\n        loss.backward()\n        optim.step()\n        \n    print(f\"epoch : {epoch} - loss : {loss_count}\")\n    total_loss.append(loss_count)","baad9c17":"plt.plot(list(range(len(total_loss))),total_loss)\nplt.show()","06c84026":"x=torch.ones(size=(2,4))","d3508669":"net=Net()\nif(is_cuda):\n    net=net.cuda()\noptim=torch.optim.Adam(net.parameters(),lr=0.001)\n\ndef loss_function(out,real,latent):\n    mse=F.mse_loss(out,real,reduction=\"mean\")  \n    latent=latent.mean(axis=0)\n    kld=F.kl_div(latent,torch.tensor(0.3).cuda(),reduction=\"batchmean\")\n    return mse","0e850fd0":"total_loss=[]\nfor epoch in range(10):\n    loss_count=0\n    for x,y in trainloader:\n        if(is_cuda):\n            x,y=x.cuda(),y.cuda()\n\n        latent,output=net(x)\n        loss=loss_function(output,x,latent)\n        loss_count+=loss.item()\n\n        net.zero_grad()\n        loss.backward()\n        optim.step()\n        \n    print(f\"epoch : {epoch} - loss : {loss_count}\")\n    total_loss.append(loss_count)","5d7bd981":"plt.plot(list(range(len(total_loss))),total_loss)\nplt.show()","c6f40e13":"net=Net()\nif(is_cuda):\n    net=net.cuda()\noptim=torch.optim.Adam(net.parameters(),lr=0.001)\n\ndef loss_function(out,real,latent):\n    mse=F.mse_loss(out,real,reduction=\"mean\")  \n    w=net.state_dict()[\"encoder.weight\"]\n    latent=latent*(1-latent)\n    contractive=torch.mean(0.0004*torch.sum(latent**2 * torch.sum(w**2,axis=1),axis=1))\n    return mse+contractive","3ae015b5":"total_loss=[]\nfor epoch in range(10):\n    loss_count=0\n    for x,y in trainloader:\n        if(is_cuda):\n            x,y=x.cuda(),y.cuda()\n\n        latent,output=net(x)\n        loss=loss_function(output,x,latent)\n        loss_count+=loss.item()\n\n        net.zero_grad()\n        loss.backward()\n        optim.step()\n        \n    print(f\"epoch : {epoch} - loss : {loss_count}\")\n    total_loss.append(loss_count)","9aa12cbf":"plt.plot(list(range(len(total_loss))),total_loss)\nplt.show()","68d5e0ff":"## Sparse Autoencoder","99299dc1":"## Contractive Autoencoder","924651c6":"## Vanilla Autoencoder"}}