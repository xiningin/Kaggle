{"cell_type":{"a16647d7":"code","bc357dc5":"code","9d76f310":"code","ee337661":"code","253512a6":"code","b890a45a":"code","3833a9ec":"code","0deb2fc3":"code","1acb3eab":"code","2f4b9b1e":"code","a92302c5":"markdown","57511354":"markdown","1a6481e2":"markdown","26aa6152":"markdown","f11263b3":"markdown","4fc50252":"markdown","010582a0":"markdown","75db6869":"markdown","1f7ed153":"markdown"},"source":{"a16647d7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bc357dc5":"#=== initial set up\nimport pandas as pd\nimport numpy as np\nimport os\n\npd.set_option(\"display.max_column\", None)\npd.set_option(\"display.max_row\", 50)\n\n#=== reading in of data\nemails = pd.read_csv('\/kaggle\/input\/enron-email-dataset\/emails.csv')\n\n#=== make a copy of the dataframe\nemails_df = emails.copy()\nprint(emails_df.head())\n\n#=== take a small portion of the data for better visualisation results\nemails_df = emails_df.sample(n = 200, random_state = 0)","9d76f310":"#=== create a function to split text\nimport re\ndef split_text(text, match):\t\n    text = re.sub(r\"\\n\\t\", \"\", text)\n    return re.split(match, text)\n\n#=== create a function to extract proper text from the email body\ndef extract_body(text, substr):\t\n    result = re.split(substr, text)[-1]\n    result = re.sub(r\"([\\n-])\", \"\", result)\n    return result\n\n#=== clean up the data fields\n#- function to extract email addresses\ndef extract_emails(text, substr):\n    result = re.findall(\"[^\\s]+@[\\w]+.[\\w]+\", str(text))\n    if substr not in text:\n        result = \"\"\n    return result\n\n#- function to extract subject\ndef extract_subject(text):\n\n    list_of_words = re.split(\"\\s\", text)\n    words_to_drop = [\"Subject:\",\"re:\",\"Re:\",\"RE:\",\"fw:\",\"Fw:\", \"FW:\"]\n\n    desired_words = []\n    for word in list_of_words:\n        if word not in words_to_drop:\n            desired_words.append(word)\n\n    r = re.compile(\"[\\w]{3,}\")\n    final_list = list(filter(r.match, desired_words))\n\n    return final_list \n\n#- function to extract the name of entity\ndef extract_entity(text):\t\n    string = \"\"\n    for i in text:\n        string = string + \" \" + i\n\n    list_of_emails = list(re.findall(r\"@[\\w]+\", string))\t\n    result = []\n    for item in list_of_emails:\t\t\n        result.append(item[1:])\n\n    return set(result)","ee337661":"#=== store output in new column\nemails_df[\"message_tidy\"] = emails_df.message.apply(lambda x : split_text(x, \"\\n\"))\n\n#=== take a look at the output\nprint(emails_df.head())\nprint(emails_df.message.head(1))\nprint(emails_df.message_tidy.head(1))","253512a6":"#=== pull out useful data and post them into columns\nemails_df[\"date\"] = emails_df.message_tidy.apply(lambda x : x[1])\nemails_df[\"sender_email\"] = emails_df.message_tidy.apply(lambda x : x[2])\nemails_df[\"recipient_email\"] = emails_df.message_tidy.apply(lambda x : x[3])\nemails_df[\"subject\"] = emails_df.message_tidy.apply(lambda x : x[4])\nemails_df[\"cc\"] = emails_df.message_tidy.apply(lambda x : x[5])\nemails_df[\"bcc\"] = emails_df.message_tidy.apply(lambda x : x[9])\nemails_df[\"body\"] = emails_df.message.apply(lambda x : extract_body(x, r\"X-FileName: [\\w]*[\\s]*[(Non\\-Privileged).pst]*[\\w-]*[.nsf]*\").strip())","b890a45a":"#- extract date info\nemails_df[\"day_of_week\"] = emails_df.loc[:,\"date\"].apply(lambda x : x[5:9])\nemails_df.loc[:,\"date\"] = emails_df.loc[:,\"date\"].apply(lambda x : x[10:22])\n\n#- extract sender and recipient email\nemails_df.loc[:,\"sender_email\"] = emails_df.loc[:,\"sender_email\"].apply(lambda x : extract_emails(x, \"From: \"))\nemails_df.loc[:,\"recipient_email\"] = emails_df.loc[:,\"recipient_email\"].apply(lambda x : extract_emails(x, \"To: \"))\nemails_df.loc[:,\"cc\"] = emails_df.loc[:,\"cc\"].apply(lambda x : extract_emails(x, \"Cc: \"))\nemails_df.loc[:,\"bcc\"] = emails_df.loc[:,\"bcc\"].apply(lambda x : extract_emails(x, \"Bcc: \"))\nemails_df[\"all_recipient_emails\"] = emails_df.apply(lambda x : list(x[\"recipient_email\"]) + list(x[\"cc\"]) + list(x[\"bcc\"]), axis = 1)\nemails_df[\"num_recipient\"] = emails_df.recipient_email.apply(lambda x : len(x)) + emails_df.cc.apply(lambda x : len(x)) + \\\n                                emails_df.bcc.apply(lambda x : len(x))\n    \n#- extract sender and recipient entity info\nemails_df[\"sender_entity\"]    = emails_df.loc[:,\"sender_email\"].apply(lambda x : extract_entity(x))\nemails_df[\"recipient_entity_to\"] = emails_df.loc[:,\"recipient_email\"].apply(lambda x : extract_entity(x))\nemails_df[\"recipient_entity_cc\"] = emails_df.loc[:,\"cc\" ].apply(lambda x : extract_entity(x))\nemails_df[\"recipient_entity_bcc\"] = emails_df.loc[:,\"bcc\"].apply(lambda x : extract_entity(x))\nemails_df[\"all_recipient_entities\"] = emails_df.apply(lambda x : \\\n                                                 x[\"recipient_entity_to\" ] | \\\n                                                 x[\"recipient_entity_cc\" ] | \\\n                                                 x[\"recipient_entity_bcc\"], axis = 1)\n\nemails_df[\"sender_entity\"] = emails_df.sender_entity.apply(lambda x : list(x))\nemails_df[\"all_recipient_entities\"] = emails_df.all_recipient_entities.apply(lambda x : list(x))\n\n#- extract subject\nemails_df.loc[:,\"subject\"] = emails_df.loc[:,\"subject\"].apply(lambda x : extract_subject(x))\n\n#=== select and reorder the colums\ndf = emails_df.loc[:,[\"date\",\"day_of_week\",\"subject\",\"body\",\"sender_email\",\"all_recipient_emails\",\n                                 \"sender_entity\",\"all_recipient_entities\",\"num_recipient\"]]  \n\nprint(df.head())","3833a9ec":"#=== function to expand list into multiple rows\n#- we examine just the \"sender_email\" and \"all_recipient_emails\"\n#- we try to break up the list (in \"all_recipient_emails\") into multiple rows\nfrom itertools import chain\ndef investigate(df_col1, df_col2):\n    result_df = pd.DataFrame({ \"send\" : np.repeat(df_col1.values, df_col2.str.len()),\"receive\": list(chain.from_iterable(df_col2))})\n    result_df.send = result_df.send.apply(lambda x : x[0])\n    return result_df","0deb2fc3":"df2a = investigate(df.sender_email, df.all_recipient_emails)\ndf2b = investigate(df.sender_entity, df.all_recipient_entities)","1acb3eab":"#=== network analysis\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\n#=== for the sender and recipient emails\n#- define the graph\nG1 = nx.from_pandas_edgelist(df2a.sample(round(0.1*len(df2a)), random_state = 0), \"send\", \"receive\")\n\n#- we define the closeness measure\ncloseness_G1 = nx.closeness_centrality(G1)\ncloseness_G1 = list(closeness_G1.values())\n\n#- plot the network\nplt.figure(figsize = (20,20))\npos1 = nx.spring_layout(G1, k=.1)\nnx.draw(G1, pos1, node_size = 20, node_color = closeness_G1, with_labels = True)\nplt.show()","2f4b9b1e":"#=== for the sender and recipient entities\n#- define the graph\nG2 = nx.from_pandas_edgelist(df2b, \"send\", \"receive\")\n\n#- we define the closeness measure\ncloseness_G2 = nx.closeness_centrality(G2)\ncloseness_G2 = list(closeness_G2.values())\n\n#- plot the network\nplt.figure(figsize = (20,20))\npos2 = nx.spring_layout(G2, k=.1)\nnx.draw(G2, pos2, node_size = 300, node_color = closeness_G2,with_labels = True)\nplt.show()","a92302c5":"We notice that the \"all_recipients_emails\" column contains multiple emails addresses and entities in one chunk. It is ideal, from network analysis standpoint, to split them up into multiple rows. For that purpose, we create the \"investigate\" function to do just that.","57511354":"We applied the \"split_text\" function and stored the results into a new column called \"message_tidy\". Let us take a look at our output for now..","1a6481e2":"We create functions to split the text and to extract the meaningful texts from the email body. Also, we have other functions created to clean up the data fields and to extract email addresses, subjects and the name of the entity (sender\/recipient)","26aa6152":"We do some \"feature engineering\", by extracting useful information that can be used for the analysis such as \"sender email\", \"recipient email\" (because we really want to know who sends\/receives email from who; critical to establish relationships).\n\nWe also extracted the useful information from the body of the emails, leaving out all the \"noises\".","f11263b3":"We extracted the date information and email addresses, as well as to count the number of recipients. Quite a lot of effort for the data cleaning parts","4fc50252":"Let's store the emails and the names of the entities","010582a0":"We see that some of the nodes are unlinked to the rest of the clusters. Be mindful that we are taking a random sample and it is not definite that these \"standalone\" nodes are indeed far from the clusters. To do a more meaningful visual analysis, you will need to do an extraction of the data containing particular entity names or email addresses. What we presented here is just a means to show what Python is capable of showing.","75db6869":"Let's read in the dataset and see how it looks like! However, with such a large number of data, it is very tough to do a proper network visualisation later on. How about, we just take 500 of the data first..","1f7ed153":"We are finally at the network analysis step; this is the easy part of the whole notebook. We do two different network diagrams, one for emails and one for entities"}}