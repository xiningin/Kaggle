{"cell_type":{"479275ed":"code","f4bb3091":"code","0915ff26":"code","fcb50f2b":"code","f258deb1":"code","d7953f30":"code","31808f77":"code","3bdf572d":"code","6509e614":"code","7282ccd6":"code","86e56805":"code","edfc1a25":"code","bf5ab0f1":"code","dde7c113":"code","938bb4ee":"code","d66a5341":"code","a738043e":"code","263c1b35":"code","6e4d6dce":"code","6552b60c":"code","2c435499":"code","909795b5":"code","fdd43836":"code","a3904ac2":"code","47665797":"code","99e98b3f":"code","afaee1fd":"code","6feca588":"code","284c2ac5":"code","75cad198":"code","fba274ae":"code","94a81807":"markdown","ba6e3fe3":"markdown","6d647000":"markdown","8ce36eda":"markdown","a7963a11":"markdown","dbc0f076":"markdown","9a328b4d":"markdown","0f87806c":"markdown","783715a9":"markdown","df31288d":"markdown","edba8c44":"markdown"},"source":{"479275ed":"from sklearn.model_selection import train_test_split\nfrom sklearn.svm import LinearSVC\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import tree\nfrom scipy.spatial.distance import pdist, squareform\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import metrics\n\nfrom pandas import plotting\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n#plotly \nimport plotly.offline as py\nimport plotly.graph_objects as go\nfrom plotly.offline import init_notebook_mode, iplot\nfrom plotly import tools\ninit_notebook_mode(connected=True)\nimport plotly.figure_factory as ff\nimport plotly.express as px\n\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import preprocessing\nfrom sklearn import neighbors\nfrom sklearn.metrics import confusion_matrix,classification_report,precision_score, plot_roc_curve, plot_precision_recall_curve, balanced_accuracy_score\nfrom sklearn.model_selection import train_test_split\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nsns.set(style=\"whitegrid\")\n\nplt.style.use('fivethirtyeight')","f4bb3091":"import warnings #para que no molesten los warnings\nwarnings.filterwarnings('ignore')","0915ff26":"df = pd.read_csv ('..\/input\/water-potability\/water_potability.csv')\ndf","fcb50f2b":"df.isnull().sum()","f258deb1":"df.shape","d7953f30":"df.columns","31808f77":"df.info()","3bdf572d":"df[df['Sulfate'].isnull()]\ndf[df['ph'].isnull()]\ndf[df['Trihalomethanes'].isnull()]","6509e614":"df['ph']=df['ph'].fillna(df.groupby(['Potability'])['ph'].transform('mean'))\ndf['Sulfate']=df['Sulfate'].fillna(df.groupby(['Potability'])['Sulfate'].transform('mean'))\ndf['Trihalomethanes']=df['Trihalomethanes'].fillna(df.groupby(['Potability'])['Trihalomethanes'].transform('mean'))","7282ccd6":"df.isna().sum()","86e56805":"df['Potability'].value_counts()","edfc1a25":"corr = df.corr().round(2)\n\n# Mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set figure size\nf, ax = plt.subplots(figsize=(20, 20))\n\n# Define custom colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap\nsns.heatmap(corr, mask=mask, cmap=cmap, vmin=-1, vmax=1, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True)\n\nplt.tight_layout()","bf5ab0f1":"from statsmodels.stats.outliers_influence import variance_inflation_factor\ncols=['Potability']\nX=df.drop(cols, axis=1)","dde7c113":"vif_data = pd.DataFrame()\nvif_data[\"feature\"] = X.columns\nvif_data[\"VIF\"] = [variance_inflation_factor(X.values, i)\n                          for i in range(len(X.columns))]\nprint(vif_data)","938bb4ee":"x = df.drop(\"Potability\", axis=1)\ny = df.Potability\nX_train , X_test , y_train , y_test = train_test_split(x , y, test_size=0.25, random_state=42)","d66a5341":"from sklearn import metrics\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix,ConfusionMatrixDisplay","a738043e":"import statsmodels.api as sm\nimport statsmodels.formula.api as smf","263c1b35":"lr=LogisticRegression()\nlr.fit(X_train, y_train)","6e4d6dce":"y_pred=lr.predict(X_train)\n","6552b60c":"print(\"Accuracy Score:-\", metrics.accuracy_score(y_train, y_pred))\nprint(\"F1 Score:-\", metrics.f1_score(y_train, y_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_train, y_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_train, y_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_train, y_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_train, y_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_train, y_pred))","2c435499":"y_test_pred=lr.predict(X_test)\n","909795b5":"lr_acc=metrics.accuracy_score(y_test, y_test_pred)\nprint(\"Accuracy Score:-\",lr_acc)\nprint(\"F1 Score:-\", metrics.f1_score(y_test, y_test_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_test, y_test_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_test, y_test_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_test, y_test_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_test, y_test_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_test, y_test_pred))","fdd43836":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import confusion_matrix,classification_report,precision_score, plot_roc_curve, plot_precision_recall_curve, balanced_accuracy_score\n\ndef clf_scores(clf, y_predicted):\n    # Accuracy\n    acc_train = clf.score(X_train, y_train)*100\n    acc_test = clf.score(X_test, y_test)*100\n    \n    roc = roc_auc_score(y_test, y_predicted)*100 \n    tn, fp, fn, tp = confusion_matrix(y_test, y_predicted).ravel()\n    cm = confusion_matrix(y_test, y_predicted)\n    correct = tp + tn\n    incorrect = fp + fn\n    d=[acc_train, acc_test,  roc, correct, incorrect,  cm]\n    index=[\"acc_train\",'Test Accuracy',\"Roc Score\",\"COrrect\",\"Incorrect\",\"Confusion\"  ]\n    output=pd.DataFrame(data=d, index=index)\n    \n    d=sns.heatmap(cm, annot=True)\n    dd=plot_roc_curve(clf, X_train, y_train)\n    ddd=plot_precision_recall_curve(clf, X_train, y_train)\n\n    return output,d, dd, ddd","a3904ac2":"#1. Logistic regression\n\nfrom sklearn.linear_model import LogisticRegression\nclf_lr = LogisticRegression(solver='liblinear')\nclf_lr.fit(X_train, y_train)\n\nY_pred_lr = clf_lr.predict(X_test)\nprint(clf_scores(clf_lr, Y_pred_lr))","47665797":"# 2 Random Forest\n\nfrom sklearn.ensemble import RandomForestClassifier\nclf_rf = RandomForestClassifier()\nclf_rf.fit(X_train, y_train)\n\nY_pred_rf = clf_rf.predict(X_test)\nprint(clf_scores(clf_rf, Y_pred_rf))","99e98b3f":"# 3 XGboost\nfrom sklearn.ensemble import GradientBoostingClassifier\nclf_xg = GradientBoostingClassifier()\nclf_xg.fit(X_train, y_train)\n\nY_pred_xg = clf_xg.predict(X_test)\nprint(clf_scores(clf_xg, Y_pred_xg))","afaee1fd":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n{'n_estimators': [10, 25], 'max_features': [5, 10], \n 'max_depth': [10, 50, None], 'bootstrap': [True, False]}\n]\n\ngrid_search_forest = GridSearchCV(clf_rf, param_grid, cv=10, scoring='neg_mean_squared_error')\ngrid_search_forest.fit(X_train, y_train)","6feca588":"#now let's how the RMSE changes for each parameter configuration\ncvres = grid_search_forest.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(np.sqrt(-mean_score), params)","284c2ac5":"#find the best model of grid search\ngrid_search_forest.best_estimator_","75cad198":"# Performance metrics\ngrid_best= grid_search_forest.best_estimator_.predict(X_train)\nerrors = abs(grid_best - y_train)\n# Calculate mean absolute percentage error (MAPE)\nmape = np.mean(100 * (errors \/ y_train))\n# Calculate and display accuracy\naccuracy = 100 - mape    \n#print result\nprint('The best model from grid-search has an accuracy of', round(accuracy, 2),'%')","fba274ae":"# Tuned Random Forest\n\nfrom sklearn.ensemble import RandomForestClassifier\nclf_rf = RandomForestClassifier(bootstrap=False, max_features=5, n_estimators=25)\nclf_rf.fit(X_train, y_train)                 \nY_pred_rf = clf_rf.predict(X_test)\nprint(clf_scores(clf_rf, Y_pred_rf))","94a81807":"Data preprocessing is complete","ba6e3fe3":"# Logistic Regression","6d647000":"#                                                          THE END","8ce36eda":"# Part 1: Data visualtization","a7963a11":"This dataset gives us information about potability for different waters with respect to their conductivity, PH, etc. With this information we expect to extract conclusions about which components have a bigger impact on the potability of water.","dbc0f076":"### No more null values remain.","9a328b4d":"# Fine-tune Random Forest","0f87806c":"# Part 0: Preprocessing","783715a9":"### There are null values, let's check which:","df31288d":"### We replace them with the mean","edba8c44":"### We check for null values"}}