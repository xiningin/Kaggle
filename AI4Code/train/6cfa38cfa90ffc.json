{"cell_type":{"a8c23cb2":"code","9c041f1b":"code","95856b80":"code","385f32c8":"code","2d2d762e":"code","fbef81a5":"code","5a7ae47b":"code","6a1b6722":"code","109bc037":"code","c3674530":"code","65e38fcd":"code","0f5a4da3":"code","332321e1":"code","a5ec7d59":"code","98d78a91":"code","d52be809":"code","5641f610":"code","abc73cfb":"code","c1b9982b":"code","f0b8e503":"code","16a6de79":"code","41755650":"code","2e20cfd5":"code","205d2fb3":"code","3d4a74c2":"code","99049f77":"code","cac85bd0":"code","fc10e628":"code","712b0216":"code","53a3db0d":"code","027125d6":"code","6c2848f6":"code","5d7ed4c7":"code","8531e150":"code","eef24d55":"code","dcd3aafd":"code","0236b53a":"code","1d15d243":"code","1c2299e2":"code","97c08b50":"code","3f9b0838":"markdown","55700bcc":"markdown","2300f76c":"markdown","83b15e2b":"markdown","fc2db4dd":"markdown","0bf8b0be":"markdown","c95905d5":"markdown","8662c7fd":"markdown","d1f13a01":"markdown","f13a1c2a":"markdown","8f931526":"markdown","2717be6d":"markdown","65ee5ba0":"markdown","ca34bbb2":"markdown","b09adda6":"markdown","262c3c20":"markdown","e2aa50fd":"markdown","f95b2953":"markdown","d557171e":"markdown","42f7eea3":"markdown","7abcb69a":"markdown","6c3b5ef0":"markdown","0d1fc54f":"markdown","7f9a99a0":"markdown","a9083a57":"markdown","2d1590c2":"markdown","c60cb3ac":"markdown","84eaf2a0":"markdown","676d94d3":"markdown","91a41898":"markdown","3f93dec9":"markdown","16f9c278":"markdown","7c18cee5":"markdown","d6b23f27":"markdown","5bd4afa8":"markdown","686043fc":"markdown","94b269f9":"markdown","0dd96d92":"markdown","47c65eaf":"markdown","3e6ceafd":"markdown","59c8297c":"markdown","f92a8551":"markdown","e9f3dc80":"markdown","545e022a":"markdown","323d455e":"markdown","a6040a94":"markdown","16d12e09":"markdown"},"source":{"a8c23cb2":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as  plt\n%matplotlib inline\n\nimport tensorflow as tf  # Importing the TensorFlow Library\nfrom tensorflow import keras  # Import Keras from TensorFlow\nfrom tensorflow.keras import Sequential \nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Dense,Dropout,BatchNormalization,Conv2D,MaxPooling2D,Flatten\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.callbacks import TensorBoard\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport datetime\n\n%load_ext tensorboard\nimport glob\nimport cv2\n","9c041f1b":"training_labels=pd.read_csv(\"https:\/\/raw.githubusercontent.com\/dphi-official\/Datasets\/master\/animal_data\/Training_set_animals.csv\")\ntesting_labels=pd.read_csv(\"https:\/\/raw.githubusercontent.com\/dphi-official\/Datasets\/master\/animal_data\/Testing_set_animals.csv\",header=None)\ntesting_labels.columns=['filename']","95856b80":"training_labels['animal_type'].value_counts()\n","385f32c8":"training_images = []\nfor img in glob.glob(r'..\/input\/animal-classification\/Mucca or Pecora\/train_beg\/train_beg\/*.jpg'):\n    n= cv2.imread(img)\n    training_images.append(n)","2d2d762e":"testing_images = []\nfor img in glob.glob(r'..\/input\/animal-classification\/Mucca or Pecora\/test_beg\/test_beg\/*.jpg'):\n    n= cv2.imread(img)\n    testing_images.append(n)","fbef81a5":"if len(training_labels) == len(training_images):\n    print('Number of labels i.e. ', len(training_labels), 'matches the number of filenames i.e. ', len(training_images))\nelse:\n    print('Number of labels doesnot matches the number of filenames')","5a7ae47b":"if len(testing_labels) == len(testing_images):\n    print('Number of labels i.e. ', len(testing_labels), 'matches the number of filenames i.e. ', len(testing_images))\nelse:\n    print('Number of labels doesnot matches the number of filenames')","6a1b6722":"len(testing_images) ","109bc037":"path1=r\"..\/input\/animal-classification\/Mucca or Pecora\/train_beg\/train_beg\/\"\n\n    \nimages = [[fname, path1+ fname[:-4] + '.jpg'] for fname in training_labels['filename']]\ntrain_df = pd.DataFrame(images)\ntrain_df.columns = ['filename', 'file']\ntrain_df['labels']=training_labels['animal_type']\n\ndef mappp(x):\n    if x==\"mucca\":\n        return 0\n    else: return 1\n    \ntrain_df['labels_num']=train_df['labels'].map(mappp)\ny_train=np.array(train_df['labels_num'])","c3674530":"images_train=[]\nfor img in train_df['file']:\n    img=cv2.imread(img)\n    img = cv2.resize(img, (224,224),interpolation=cv2.INTER_CUBIC)\n    #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    images_train.append(img)","65e38fcd":"images_train=np.array(images_train)\nplt.matshow(images_train[9])\n","0f5a4da3":"num_rows, num_cols = 2,3\nf, ax = plt.subplots(num_rows, num_cols, figsize=(12,5),\n                     gridspec_kw={'wspace':0.15, 'hspace':0.15}, \n                     squeeze=True)\n\nfor r in range(num_rows):\n    for c in range(num_cols):\n      \n        image_index = r*650 + c\n        ax[r,c].axis(\"off\")\n        ax[r,c].imshow(images_train[image_index], cmap='gray')\n        ax[r,c].set_title(train_df['labels'][image_index])\nplt.show()\nplt.close()","332321e1":"\npath2=r\"..\/input\/animal-classification\/Mucca or Pecora\/test_beg\/test_beg\/\"\n\nimages = [[fname, path2+ fname[:-4] + '.jpg'] for fname in testing_labels['filename']]\ntest_df = pd.DataFrame(images)\ntest_df.columns = ['filename', 'file']","a5ec7d59":"images_test=[]\nfor img in test_df['file']:\n    img=cv2.imread(img)\n    #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    img = cv2.resize(img, (224,224),interpolation=cv2.INTER_CUBIC)\n    images_test.append(img)","98d78a91":"images_test=np.array(images_test)\nplt.matshow(images_test[1])\n","d52be809":"num_rows, num_cols = 2,3\nf, ax = plt.subplots(num_rows, num_cols, figsize=(12,5),\n                     gridspec_kw={'wspace':0.15, 'hspace':0.15}, \n                     squeeze=True)\n\nfor r in range(num_rows):\n    for c in range(num_cols):\n      \n        image_index = r*200 + c\n        ax[r,c].axis(\"off\")\n        ax[r,c].imshow(images_test[image_index], cmap='gray')\n        \nplt.show()\nplt.close()","5641f610":"images_train.shape","abc73cfb":"images_test.shape","c1b9982b":"images_train[0]","f0b8e503":"# define input shape\nINPUT_SHAPE = (224,224,3)\n\n# get the densenet169 model\nvgg_layers = tf.keras.applications.densenet.DenseNet169(weights='imagenet', include_top=False, \n                                               input_shape=INPUT_SHAPE)\n# ignore the variable name as vgg_layers as I reused my first code for all the other models by changing the pretrained modelsto check how each pretrained models work\n\n#print the summary and architecture of densenet169 layers\nvgg_layers.summary()","16a6de79":"# Fine-tune all the layers\nfor layer in vgg_layers.layers:\n    layer.trainable = True\n\n# Check the trainable status of the individual layers\nfor layer in vgg_layers.layers:\n    print(layer, layer.trainable)","41755650":"import random\nfrom tensorflow.keras.optimizers import RMSprop\n\nrandom.seed(21)\nprint(random.random())\n# define sequential model\nmodel = tf.keras.models.Sequential()\n\n# Add the vgg convolutional base model\nmodel.add(vgg_layers)\n\n# add flatten layer\nmodel.add(tf.keras.layers.Flatten())\n\n# add dense layers with some dropout\nmodel.add(tf.keras.layers.Dense(1024, activation='relu'))\n#model.add(tf.keras.layers.Dropout(rate=0.1))\nmodel.add(tf.keras.layers.Dense(1024, activation='relu'))\n#model.add(tf.keras.layers.Dropout(rate=0.1))\n\n\n# add output layer\nmodel.add(tf.keras.layers.Dense(2, activation='softmax'))\n\n# compile model\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=2e-5), \n              loss='sparse_categorical_crossentropy', \n              metrics=['accuracy'])\n\n# view model layers\nmodel.summary()","2e20cfd5":"y=np.array(train_df['labels_num'])","205d2fb3":"from sklearn.model_selection import train_test_split\ntrain_df, validate_df = train_test_split(train_df, test_size=0.20, random_state=42)\ntrain_df = train_df.reset_index(drop=True)\nvalidate_df = validate_df.reset_index(drop=True)","3d4a74c2":"total_train = train_df.shape[0]\ntotal_validate = validate_df.shape[0]\nbatch_size=32","99049f77":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(\n    rotation_range=15,\n    rescale=1.\/255,\n    shear_range=0.1,\n    zoom_range=0.3,\n    horizontal_flip=True,\n    width_shift_range=0.2,\n    height_shift_range=0.1\n)\n","cac85bd0":"train_generator = train_datagen.flow_from_dataframe(train_df,r'..\/input\/animal-classification\/Mucca or Pecora\/train_beg\/train_beg\/',\n                                             x_col='filename',y_col='labels',class_mode='binary',\n                                   batch_size=32, target_size=(224,224),shuffle=False)","fc10e628":"validation_datagen = ImageDataGenerator(rescale=1.\/255)\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    validate_df, \n    r'..\/input\/animal-classification\/Mucca or Pecora\/train_beg\/train_beg\/',\n                                             x_col='filename',y_col='labels',class_mode='binary',\n                                   batch_size=32, target_size=(224,224),shuffle=False)\n\n","712b0216":"plt.figure(figsize=(12, 12))\nfor i in range(0, 15):\n    plt.subplot(5, 3, i+1)\n    for X_batch, Y_batch in train_generator:\n        image = X_batch[0]\n        plt.imshow(image)\n        break\nplt.tight_layout()\nplt.show()","53a3db0d":"example_df = train_df.sample(n=2).reset_index(drop=True)\nexample_df.head()\nexample_generator = train_datagen.flow_from_dataframe(\n    example_df, \n    r'..\/input\/animal-classification\/Mucca or Pecora\/train_beg\/train_beg\/', \n    x_col='filename',\n    y_col='labels',\n    target_size=(224,224),\n    class_mode='categorical'\n)\n","027125d6":"plt.figure(figsize=(12, 12))\nfor i in range(0, 15):\n    plt.subplot(5, 3, i+1)\n    for X_batch, Y_batch in example_generator:\n        image = X_batch[0]\n        plt.imshow(image)\n        break\nplt.tight_layout()\nplt.show()","6c2848f6":"EPOCHS = 7\n\nes_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, \n                                               restore_best_weights=True,\n                                               verbose=1)\n\nhistory = model.fit(\n    train_generator, \n    epochs=EPOCHS,\n    validation_data=validation_generator,\n    validation_steps=total_validate\/\/batch_size,\n    steps_per_epoch=total_train\/\/batch_size,\n    callbacks=[es_callback]\n)\n","5d7ed4c7":"fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n\nhistory_df = pd.DataFrame(history.history)\nhistory_df[['loss', 'val_loss']].plot(kind='line', ax=ax[0])\nhistory_df[['accuracy', 'val_accuracy']].plot(kind='line', ax=ax[1]);","8531e150":"test_gen = ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_gen.flow_from_dataframe(\n    test_df, \n    r'..\/input\/animal-classification\/Mucca or Pecora\/test_beg\/test_beg', \n    x_col='filename',\n    y_col=None,\n    class_mode=None,\n    target_size=(224,224),\n    batch_size=batch_size,\n    shuffle=False\n)","eef24d55":"# X_test_flattened=images_test\/255\ny_predict=model.predict(test_generator)\n","dcd3aafd":"final=[]\nfor i in range(0,len(images_test)):\n    final.append(np.argmax(y_predict[i]))\n    ","0236b53a":"g=pd.DataFrame(final)\ng[0]=g[0].replace({1.0:'pecora',0.0:'mucca'})\ng","1d15d243":"res = g \nres.columns = [\"prediction\"]\nres.to_csv(\"highestlatest.csv\")","1c2299e2":"# model.save_weights(\"animal.h5\") ","97c08b50":"# model.save('saved_model\/my_model')\n","3f9b0838":"#### Augumenting the images with ImageData Generator from tf.keras.preprocessing.image with the following trainsformations from rescaling to flipping","55700bcc":"#### Reading the csv files which contain image labels for each image of training & testing dataset and target variable of each image of training dataset","2300f76c":"#### To get the pixel values of the images in images_train list, Converting it into the numpy array and assign it back to the images_train and Displaying one of the images in the images_train","83b15e2b":"#### Augumenting the training images with the different transformations that I created above with the batch size as 32 and class mode as binary since we have two output classes","fc2db4dd":"#### Checking whether the length of the training images read from the path specified is same as the length of the training labels read from csv file","0bf8b0be":"#### Checking whether the length of the testing images read from the path specified is same as the length of the testing labels read from csv file","c95905d5":"#### Displaying some of the images in the images_test using cv2 funtion imshow() ","8662c7fd":"#### Checking the length of the testing images","d1f13a01":"# AIM:  RECOGNIZE AN ANIMAL IN AN IMAGE","f13a1c2a":"### Plotting the loss and accuracy curves of training and validation data","8f931526":"#### 1. Reading each of the testing images in the dataframe using the path specified in the 'file' column in a loop using cv2 function imread and resized the images to (224,224) and appended the images to the images_test list\n#### 2. Also using the interpolation method inter_cubic, because cv2.INTER_CUBIC is slow but more efficient.","2717be6d":"#### Libraries to import ","65ee5ba0":"#### Downloading the densenet169 from tf.keras.applications with weights as imagenet and include_top =false so that we can add our own dense layers at the end and the input shape with the shape mentioned in the INPUT_SHAPE variable","ca34bbb2":"#### To get the pixel values of the images in images_test list, Converting it into the numpy array and assign it back to the images_test and Displaying one of the images in the images_test","b09adda6":"#### Fine tuning all the layers, so that will train the model according to the input images that we feed ","262c3c20":"#### Converting the dataframe to csv for submission. I submitted this model's output and got an accuracy of 97 % in the leaderboard","e2aa50fd":"#### Here comes the major part of the project. It's model selection. \n###  I will first list down all the models that I tried so far:\n##### a) Sequential model - which i will be adding again in the notebook since its considered for an evaluation. It is in another notebook and I m trying to merge all in one notebook\n#### b) Convolution Neural Network - which also i will be adding in the same notebook at the end \n#### c) Transfer Learning - Pretrained model \n#####      1) vgg16 \n#####      2) vgg19\n#####      3) resnet50\n#####      4) resnet152\n#####      5) densenet121\n#####      6) densenet169\n#####      7) inceptionv3\n#####      8) mobilenet\n#####      9) mobilenetv2\n\n","f95b2953":"#### Predicting the unseen data with the model that I trained with the training dataset","d557171e":"### Creating the dataframe with string values by replacing the indices values with mucca and pecora","42f7eea3":"#### Creating a dataframe which contains the image labels, path of the testing dataset","7abcb69a":"#### Displaying some of the images in the images_train using cv2 funtion imshow() along with the labels of an image","6c3b5ef0":"#### Here you can see the final output index values. In my model I mentioned '0' as 'mucca' and '1' as 'pecora' in the train_df labels_num column. ","0d1fc54f":"Since, I m reading all the images using train_df dataframe 'filepath' column - Using flow_from_dataframe method instead of flow_from_directory","7f9a99a0":"##### When I tried with binary_crossentropy as loss funtion, I din get the accuracy at all. It was around zero","a9083a57":"#### Checking the counts of each category","2d1590c2":"#### Checking the shape of the images_train and images_test. Also, printing one of the images in the images_train to see the pixel values distribution","c60cb3ac":"#### Achieved accuracy of around 97 % on testdataset with this model","84eaf2a0":"###  Fitting the model upto 7 epochs with patience = 2. If the val_loss does not have any improvement for more than two epocs, it will automatically save the model with the best_weights \nHere the val_loss increases from 5th epoch. so the model stopped learning in 6th epochs since I mentioned patience = 2\nAs it shows like 97% accuracy on training dataset and 96% accuracy on validation dataset, I got an accuracy of around 97% on testing dataset. So the model is not overfitting\/underfitting ","676d94d3":"#### Reading all the images in test dataset from the path specified in a loop using cv2 function imread() and appended  the images to the list","91a41898":"# INFERENCES:","3f93dec9":"### Here I use \n#### 1) RMSprop as the optimizer with the very less learning rate(2e-5) so that model will be trained very slowly and wont miss the global minima (Also I tried the adam, it also gave the good accuracy with the same learning rate)\n#### 2) Activation function as relu, as we all know the thumb rule that we should relu or leaky relu in the intermediate layers, so i tried with relu activation function\n#### 3) No of neurons is again an trail and error method that I tried. with 512,1024, 2000 neurons in the hidden layers. I got good accuracy with 1024 and also with 2000. I chose 1024, because it is a multiple of 2\n#### 4) Loss as sparse_categorical_crossentropy - it gave the good results. I tried binary_crossentropy with the adam and RMSprop optimizers. It really gave me poor accuracy even in the validated dataset\n I created the sequntial model and added the densenet169 layers to it.  Then, I flattened it so that we can give the inputs to the densely connected layers at the end. Followed by the flatten layers, i added two hidden layers and one output layer with 2 neurons, since we have two output as( 0 or 1) and used softmax as the activation function - it will give the probabilties for each categories in the ouput that we try to classify. I also tried with sigmoid. I dont feel it made much difference to the mdoel","16f9c278":"#### converting the labels_num column in the train_df into the numpy array so that we can use it to fit the model","7c18cee5":"#### Creating a dataframe which contains the image labels, path, target labels of the training dataset","d6b23f27":"### Saving the model","5bd4afa8":"#### Creating the test datagenerator only for rescaling images in the test dataset without augumenting the images","686043fc":"#### Displaying some of the images in the train_generator","94b269f9":"#### Spliting the data into train and validation set  80:20 ratio using sklearn.model_selection","0dd96d92":"1. Transfer Learning model: https:\/\/github.com\/dphi-official\/convolutional_neural_networks_essentials\/blob\/master\/tutorials\/02_Convolutional_Neural_Network_Essentials_CNN_Classifiers.ipynb\n2. Tensorboard : https:\/\/github.com\/dphi-official\/Deep_Learning_Bootcamp\/blob\/master\/Multi_Class_Classification\/FMNIST_classifier_keras.ipynb and dphi materials on tensorboard\n3. Data Augumentation : https:\/\/www.kaggle.com\/uysimty\/keras-cnn-dog-or-cat-classification \n4. Model Building and other topics - dphi materials \n5. Challenge link : https:\/\/dphi.tech\/challenges\/deep-learning-bootcamp-assignment-2-beginners-recognize-an-animal-in-an-image\/31\/leaderboard\/practice\/","47c65eaf":"#### Creating the validation datagenerator only for rescaling images in the Validation dataset without augumenting the images","3e6ceafd":"#### Reading all the images in train dataset from the path specified in a loop using cv2 function imread() and appended the images to the list","59c8297c":"## 1) DENSENET169 (Transfer Learning model)","f92a8551":"#### As softmax produces the probabilities of the ouput classes, I have used numpy.argmax() function to get the maximum probabilities index","e9f3dc80":"### References: \n","545e022a":"\n1) Out of all these models, I got around 85 - 94% accuracy when I used vgg16,vgg19, densenet 121, densenet 169 and mobilenet models without data augumentation. \n\n2) With data augumentation, I got 95-97% with densenet169 and densenet 121\n\n3) Acheived the poor accuracy when I used resnet models - may be due to less input data that I fed into the model\n\n4) With normal MLP network, got an accuracy around 59-62% on test dataset \n\n5) With CNN models, got an accuracy around 69-77 % on test dataset\n\n6) Achieved the highest accracy of around 97% on the test dataset with the pretrained model densenet169 with RMSprop optimizer by training all the layers in the model. It actually took some hours to train. Even Densenet169 and adam combo gave me the same results\n\n7) Image size plays a major role based on the model\n\na) when i tried with normal MLP 28*28 OR 32*32 size images gave me the good accuracy without overfitting\/underfitting. When i tried with the larger sizes, model din't work fine\n    \nb) when it comes to cnn 64*64 size images gave me the good accuracy without overfitting\/underfitting. When i tried with the larger sizes, model din't work fine\n    \nc) With pretrained models, i used the default images size of the model 224*224 and 200*200. But here increasing the image size, increases the accuracy is what i inferred.\n    \n8) Selection of loss, optimizer, activation functions, neurons and number of layers play a vital role when it comes to building any model.\n\n9) More the input to the model, better the accuracy will be. So data augumentation is important.\n\n10) Should save the model whenever get the highest accuracy on test dataset. \n\n","323d455e":"#### 1. Reading each of the training images in the dataframe using the path specified in the 'file' column in a loop using cv2 function imread and resized the images to (224,224) and appended the images to the images_train list\n#### 2. Also using the interpolation method inter_cubic, because cv2.INTER_CUBIC is slow but more efficient.","a6040a94":"#### Checking how images are augumented with the sample data","16d12e09":"# Look what I found in the training dataset :-p\n![image.png](attachment:image.png)\n"}}