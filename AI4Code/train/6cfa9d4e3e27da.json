{"cell_type":{"064269f4":"code","dd9593f8":"code","d921c92a":"code","2a7dd042":"code","007c1c89":"code","f69a018a":"markdown","af036d7a":"markdown","ae283178":"markdown"},"source":{"064269f4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import MultinomialNB,GaussianNB\nfrom sklearn.model_selection import cross_val_score\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import KFold\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","dd9593f8":"data = pd.read_csv('\/kaggle\/input\/sonar-data-set\/sonar.all-data.csv')\n\n## Separate Training & Validation Dataset\nfrom sklearn.model_selection import train_test_split\nX = data.values[:,0:60]\nY = data.values[:,60]\nX_train, X_val, Y_train, Y_val = train_test_split(X,Y, test_size = 0.2, random_state=42)\n","d921c92a":"pipe1 = Pipeline([('LR', LogisticRegression())])\npipe1.fit(X_train ,Y_train)\nprint(accuracy_score(Y_val, pipe1.predict(X_val)))","2a7dd042":"pipe2 = Pipeline([('scaled' , StandardScaler()),\n                 ('LR' ,LogisticRegression())])\npipe2.fit(X_train ,Y_train)\nprint(accuracy_score(Y_val, pipe2.predict(X_val)))","007c1c89":"pipelines = []\npipelines.append(('scaledLR' , (Pipeline([('scaled' , StandardScaler()),('LR' ,LogisticRegression())]))))\npipelines.append(('scaledKNN' , (Pipeline([('scaled' , StandardScaler()),('KNN' ,KNeighborsClassifier())]))))\npipelines.append(('scaledDT' , (Pipeline([('scaled' , StandardScaler()),('DT' ,DecisionTreeClassifier())]))))\npipelines.append(('scaledSVC' , (Pipeline([('scaled' , StandardScaler()),('SVC' ,SVC())]))))\npipelines.append(('scaledMNB' , (Pipeline([('scaled' , StandardScaler()),('MNB' ,GaussianNB())]))))\n\nmodel_name = []\nresults = []\nfor pipe ,model in pipelines:\n    kfold = KFold(n_splits=10, random_state=42)\n    crossv_results = cross_val_score(model , X_train ,Y_train ,cv =kfold , scoring='accuracy')\n    results.append(crossv_results)\n    model_name.append(pipe)\n    msg = \"%s: %f (%f)\" % (model_name, crossv_results.mean(), crossv_results.std())\n    print(msg)\n    \n# Compare different Algorithms\nfig = plt.figure()\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(model_name)\nplt.show()","f69a018a":"# Combining multiple models using Pipelines","af036d7a":"# Logistic Regression using Pipeline","ae283178":"# Implementing scaling using pipeline"}}