{"cell_type":{"0de18be9":"code","61a64a80":"code","b052ba02":"code","70b21cd0":"code","2f80d6b5":"code","57710259":"code","d9a48188":"code","8dce53e5":"code","a8ef7468":"code","4cab91f7":"code","ac843dd5":"code","65e00f17":"code","7a009dce":"code","1360d750":"code","ddf4e3a8":"code","1dc99cf0":"code","9c1a2942":"code","2272837a":"code","214ad76a":"code","39aaafc2":"code","ad9174ea":"code","329c8cba":"markdown","b3de8704":"markdown","bed38568":"markdown","0d1375be":"markdown","8f6aff52":"markdown","8fadc2ae":"markdown","7078f77a":"markdown","1e229db9":"markdown","20db8024":"markdown","9908292f":"markdown","71bd4359":"markdown","cc9e1768":"markdown","268bddca":"markdown","a04b1032":"markdown","5db54291":"markdown","0e5ef4d2":"markdown","9dd883eb":"markdown","d479c05f":"markdown","7c125647":"markdown","b80e51e6":"markdown","13353b89":"markdown"},"source":{"0de18be9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.computer_vision.ex2 import *\nimport matplotlib.pyplot as plt\nimport cv2\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications import InceptionV3\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom keras.optimizers import Adam\nfrom keras import optimizers, losses, activations, models\nfrom keras.applications.vgg16 import VGG16, preprocess_input\n!pip install livelossplot\nfrom livelossplot.inputs.keras import PlotLossesCallback\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n'''for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))'''\n\nprint('Done')\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","61a64a80":"colon_dir='..\/input\/lung-and-colon-cancer-histopathological-images\/lung_colon_image_set\/colon_image_sets\/'\nlung_dir='..\/input\/lung-and-colon-cancer-histopathological-images\/lung_colon_image_set\/lung_image_sets\/'\nlung_aca='..\/input\/lung-and-colon-cancer-histopathological-images\/lung_colon_image_set\/lung_image_sets\/lung_aca\/'\nlung_n='..\/input\/lung-and-colon-cancer-histopathological-images\/lung_colon_image_set\/lung_image_sets\/lung_n\/'\nlung_scc='..\/input\/lung-and-colon-cancer-histopathological-images\/lung_colon_image_set\/lung_image_sets\/lung_scc\/'\nprint('File directory set')","b052ba02":"# Have a general view of how data looks like\nplt.subplot(121)\nimg=cv2.imread(lung_aca+os.listdir(lung_aca)[0])\nplt.title('Lung ACA sample')\nplt.imshow(img)\n\nplt.subplot(122)\nimg = cv2.imread(lung_n + os.listdir(lung_n)[0])\nplt.title('Lung N sample')\nplt.imshow(img)\nplt.show()\n\nplt.subplot(122)\nimg = cv2.imread(lung_scc + os.listdir(lung_scc)[0])\nplt.title('Lung SCC sample')\nplt.imshow(img)\nplt.show()","70b21cd0":"SIZE_X=SIZE_Y=224\ndata=ImageDataGenerator(validation_split = 0.3)\nBATCH_SIZE = 128\n\ntraining=data.flow_from_directory(lung_dir,\n                                  class_mode = \"categorical\",\n                                  target_size = (SIZE_X,SIZE_Y),\n                                  color_mode=\"rgb\",\n                                  batch_size = 128, \n                                  shuffle = False,\n                                  subset='training',\n                                  seed = 42)\n\nvalidation=data.flow_from_directory(lung_dir,\n                                    class_mode = \"categorical\",\n                                    target_size = (SIZE_X,SIZE_Y),\n                                    color_mode=\"rgb\",\n                                    batch_size = 128, \n                                    shuffle = False,\n                                    subset='validation',\n                                    seed = 42)","2f80d6b5":"# VGG 16\n\ndef create_model(input_shape,n_classes,optimizer='adam',fine_tune=0):\n    conv_base = VGG16(include_top=False,\n                     weights='imagenet', \n                     input_shape=input_shape)\n\n    if fine_tune > 0:\n        for layer in conv_base.layers[:-fine_tune]:\n            layer.trainable = False\n    else:\n        for layer in conv_base.layers:\n            layer.trainable = False\n\n    top_model = conv_base.output\n    top_model = Flatten(name=\"flatten\")(top_model)\n    top_model = Dense(256, activation='relu')(top_model)\n    top_model = Dense(128, activation='relu')(top_model)\n    top_model = Dropout(0.2)(top_model) # We add a dropout here to prevent overfitting\n    output_layer = Dense(3, activation='softmax')(top_model)\n    model = Model(inputs=conv_base.input, outputs=output_layer)\n    \n    model.compile(optimizer = 'adam',\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n    \n    return model","57710259":"input_shape=(224,224,3)\noptim_1 = Adam(lr=0.0001)\nn_classes=3\n\nn_steps=training.samples\/\/128\nn_val_steps=validation.samples\/\/128\nn_epochs=5\n\nvggmodel=create_model(input_shape,n_classes,optim_1,fine_tune=2)","d9a48188":"# ModelCheckpoint callback - save best weights\ntl_checkpoint_1 = ModelCheckpoint(filepath='tl_model_v1.weights.best.hdf5',\n                                  save_best_only=True,\n                                  verbose=1)\n\n# EarlyStopping\nearly_stop = EarlyStopping(monitor='val_loss',\n                           patience=10,\n                           restore_best_weights=True,\n                           mode='min')","8dce53e5":"%%time \n\nvgg_history = vggmodel.fit(training,\n                           batch_size=BATCH_SIZE,\n                           epochs=n_epochs,\n                           validation_data=(validation),\n                           steps_per_epoch=n_steps,\n                           validation_steps=n_val_steps,\n                           callbacks=[tl_checkpoint_1, early_stop],\n                           verbose=1)","a8ef7468":"plt.plot(vgg_history.history['loss'],label = 'train_loss')\nplt.plot(vgg_history.history['val_loss'], label = 'testing_loss')\nplt.title('loss')\nplt.legend()\nplt.show()\n\nplt.plot(vgg_history.history['accuracy'], label='training_accuracy')\nplt.plot(vgg_history.history['val_accuracy'], label='validation accuracy')\nplt.title('Accuracy')\nplt.legend()\nplt.show()","4cab91f7":"vggmodel.load_weights('tl_model_v1.weights.best.hdf5') # initialize the best trained weights\n\ntrue_classes = validation.classes\nclass_indices = training.class_indices\nclass_indices = dict((v,k) for k,v in class_indices.items())\n\nvgg_preds = vggmodel.predict(validation)\nvgg_pred_classes = np.argmax(vgg_preds, axis=1)","ac843dd5":"from sklearn.metrics import accuracy_score\n\nvgg_acc = accuracy_score(true_classes, vgg_pred_classes)\nprint(\"VGG16 Model Accuracy with Fine-Tuning: {:.2f}\".format(vgg_acc))","65e00f17":"# InceptionV3\n\ninput_shape=(224,224,3)\n\nn_classes=3\n\nbase_model=InceptionV3(weights='imagenet',\n                      include_top=False,\n                      input_shape=(224,224,3))\n# This is to ensure the base won't be trained again\nbase_model.trainable=False\n\nadd_model=Sequential()\nadd_model.add(base_model)\nadd_model.add(GlobalAveragePooling2D())\nadd_model.add(Dropout(0.2)) # We add a dropout here to prevent overfitting\nadd_model.add(Dense(n_classes,\n                   activation='softmax'))\n\ninceptionmodel=add_model","7a009dce":"inceptionmodel.compile(loss='categorical_crossentropy',\n                      optimizer = 'adam',\n                      metrics=['accuracy'])\ninceptionmodel.summary()","1360d750":"file_path=\"weights.best.hdf5\"\ncheckpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n\nearly = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=10)\n\ncallbacks_list = [checkpoint, early]\n\n# Fit the model with the same configuration as above\ninceptionhistory=inceptionmodel.fit(training,\n                                   epochs=5,\n                                   validation_data=(validation),\n                                   verbose=1,\n                                   callbacks=callbacks_list)","ddf4e3a8":"plt.plot(inceptionhistory.history['loss'],label = 'train_loss')\nplt.plot(inceptionhistory.history['val_loss'], label = 'testing_loss')\nplt.title('loss')\nplt.legend()\nplt.show()\n\nplt.plot(inceptionhistory.history['accuracy'], label='training_accuracy')\nplt.plot(inceptionhistory.history['val_accuracy'], label='validation accuracy')\nplt.title('Accuracy')\nplt.legend()\nplt.show()","1dc99cf0":"inceptionresult=inceptionmodel.evaluate(validation,batch_size=128)\nprint(f'The test loss for InceptionV3 is {\"{:.2f}\".format(inceptionresult[0])} and the test accuracy is {\"{:.2f}\".format(inceptionresult[1])}')","9c1a2942":"# ResNet50\nImage_Size=[224,224]\n\nresnet=Sequential()\n\nresnet.add(ResNet50(input_shape=Image_Size+[3],weights='imagenet',include_top=False,pooling='average'))\n\n# This is to ensure the base won't be trained again\nfor layer in resnet.layers:\n    layer.trainable=False\n    \nflatten=Flatten()(resnet.output)\ndense=Dense(256,activation='relu')(flatten)\ndense=Dense(128,activation='relu')(dense)\ndense=Dropout(0.2)(dense)   # We add a dropout here to prevent overfitting\nprediction=Dense(3,activation='softmax')(dense)\n\nresmodel=Model(inputs=resnet.input,outputs=prediction)\n\nresmodel.summary()","2272837a":"# complile the model\n\nresmodel.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])","214ad76a":"# fit the model to the data with the same configuration\nreshistory=resmodel.fit(training,validation_data=(validation),epochs=5,verbose=1)","39aaafc2":"# plot the performance of this model\n\nplt.plot(reshistory.history['loss'],label = 'train_loss')\nplt.plot(reshistory.history['val_loss'], label = 'testing_loss')\nplt.title('loss')\nplt.legend()\nplt.show()\n\nplt.plot(reshistory.history['accuracy'], label='training_accuracy')\nplt.plot(reshistory.history['val_accuracy'], label='validation accuracy')\nplt.title('Accuracy')\nplt.legend()\nplt.show()","ad9174ea":"# Evaluate the result of the prediction\n\nresult=resmodel.evaluate(validation,batch_size=128)\nprint(f'The test loss for ResNet 50 is {\"{:.2f}\".format(result[0])} and the test accuracy is {\"{:.2f}\".format(result[1])}')","329c8cba":"### We are using the accuracy_score function here from sklearn. This is a function that can help us check the accuracy rate of our predictions made by the model","b3de8704":"# Setting up the environment\n### Import all the libraries that will be used during this investigation","bed38568":"# Choosing the model and training the model\n\n### In this project, I will be using three different pre-trained neural network to train the model and finding out which network fits the prediction best.\n### The three neural networks I will be using are:\n### 1: VGG 16;   2: InceptionV3;  3: ResNet50","0d1375be":"### ResNet 50 is a model that consists of 5 stages each with a convolution and identity block. This model can help tackle the vanishing gradient problem using identity mapping. Less extra paremeters are needed for training a large model compare to other pre-trained models.","8f6aff52":"### Compile the model with the same configuration as above\n### We use the adam optimizer here as it is straightforward to implement; computationally efficient and only requires a little amount of memories","8fadc2ae":"### Set up the file directory","7078f77a":"### After using three differnent pre-trained model and compare the accuracy rate, we can see that the ResNet 50 model has the highest accuracy rate for lung cancer classification, with an accuracy rate of 99%.\n### The final prediction accuracy rate for each model follows:\n### VGG16: 95%\n### InceptionV3: 72%\n### ResNet 50: 99%\n\n### In the process of doing this project and implementing those neural networks that I was not familiar with, I have had some big challenges along the way. One problem that I had was that the neural network configuration is not compatitable with the actual data, which consequently causes the failure of fitting the model. I finally solved this problem by changing the configuration of the model.\n\n### There is still some areas that can be improved, for example, the accuracy rate for InceptionV3. I am not sure what is causing this low accuracy rate, but I believe I will be able to figure it out ultimately.","1e229db9":"### Set up the early stop and checkpoint to record the best weights during the training, and to prevent over-fitting and under-fitting","20db8024":"### Fine Tuning is enabled in the fitting process. This is a process which can take weights of a pre-trained neural network and use it as initialization of a new model being trained on data from the same domain. It can help speed up the training and overcome small dataset size.","9908292f":"### Training model with InceptionV3","71bd4359":"### Load the best weights to the model.\n### Record all the information about the actual classes of each images and check is the model produces the correct predictions\n### Calculate the accuracy rate of this model","cc9e1768":"### Provide a general view of how the images we are going to use to train the model looks like","268bddca":"# The Principle of Transfer Learning\n\n### Transfer learning is a machine learning method where a model developed for a certain task is reused as the starting point for other tasks.\n### In the field of Deep Learning, this technique is usually the method of which pre-trained models are used as the starting point on computer vision and natural language processing tasks.\n### By using the method of Transfer Learning, we can save the total training time for the model, a better performance of neural networks (in most cases), and requires less data.","a04b1032":"### Plot the performance of the model, the loss and the accuracy rate as the model is being trained","5db54291":"# Conclusion","0e5ef4d2":"#### Get the validation and training data ready; make sure the training data and validation data is generated with the same configuration","9dd883eb":"# Introduction of the investigation\n## Purposes:\n### In this project, I will be using the technique of transfer learning to implement a neural network for lung cancer image classfication\n### The data I will mainly be using is an image set with a total of 15000 images.\n### I hope I can achieve the highest possible accuracy rate of classfication\n### I chose to use this image set because lung cancer is currently one of the most vital diseases in society, and patients are more likely to be cured if the disease is spotted earlier.","d479c05f":"### InceptionV3 is a convolutional neural network architecture for assisting in image analysis and object detection. It is the third edition of Google's Inception convolutional neural network","7c125647":"### Training model with ResNet 50","b80e51e6":"### Training model with VGG 16\n\n### VGG 16 is a convolution neural set architecture. It is considered as one of the most excellent computer vision model so far. The unique thing about VGG 16 is that it only focus on having convolution layers of 3\u00d73 filter with a stride 1 and always uses same padding and maxpool layer of 2\u00d72 filter of stride 2. The 16 in VGG 16 refers to it has 16 layes that have weights.","13353b89":"#### Plot the performance of the model as it is being trained"}}