{"cell_type":{"7947dd8c":"code","c295796a":"code","ba4bc625":"code","e3cee042":"code","7b361df7":"code","5c0f8ad8":"code","fddfe865":"code","6e7983ca":"code","99531ae9":"code","d5e3d9db":"code","48c97558":"code","5feb965a":"code","e651f2dd":"code","80e38124":"code","6b5494d2":"code","748f8b0f":"code","fc1e9ac0":"code","c3e244c9":"code","eaf4dbac":"code","c8a621b0":"markdown"},"source":{"7947dd8c":"import time\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom __future__ import absolute_import, division, print_function\ntf.logging.set_verbosity(tf.logging.INFO)\n\nimport os\nprint(os.listdir(\"..\/input\"))","c295796a":"train_img = np.load('..\/input\/kmnist-train-imgs.npz')['arr_0']\ntest_img= np.load('..\/input\/kmnist-test-imgs.npz')['arr_0']\ntrain_label = np.load('..\/input\/kmnist-train-labels.npz')['arr_0']\ntest_label = np.load('..\/input\/kmnist-test-labels.npz')['arr_0']","ba4bc625":"char_df = pd.read_csv(r'..\/input\/kmnist_classmap.csv')\nchar_df","e3cee042":"print('train images shape {}\\ntest images shape {}'.format(train_img.shape , \n                                                            test_img.shape))","7b361df7":"print('train label shape {}\\ntest label shape {}'.format(train_label.shape , \n                                                        test_label.shape))","5c0f8ad8":"train_label[:5]","fddfe865":"plt.figure(1 , figsize = (15 , 9))\nn = 0\nfor i in range(49):\n    n += 1\n    plt.subplot(7 , 7 , n)\n    plt.subplots_adjust(hspace = 0.5 , wspace = 0.5)\n    plt.imshow(train_img[i] , cmap = 'gray')\n    plt.xticks([]) , plt.yticks([])\n    plt.xlabel('class {}'.format(train_label[i]))\n    \nplt.show()","6e7983ca":"plt.figure(1 , figsize = (15 , 9))\nn = 0\nfor i in range(49):\n    n += 1\n    plt.subplot(7 , 7 , n)\n    plt.subplots_adjust(hspace = 0.5 , wspace = 0.5)\n    plt.imshow(test_img[i] , cmap = 'gray')\n    plt.xticks([]) , plt.yticks([])\n    plt.xlabel('class {}'.format(test_label[i]))\n    \nplt.show()","99531ae9":"train_img = train_img.astype(np.float32)\ntest_img = test_img.astype(np.float32)\ntrain_label = train_label.astype(np.int32)\ntest_label = test_label.astype(np.int32)","d5e3d9db":"train_img = train_img\/255\ntest_img = test_img\/255","48c97558":"train_X = train_img.reshape([-1 , 28 , 28 , 1])\ntest_X = test_img.reshape([-1 , 28 , 28 , 1])\ntrain_X      = np.pad(train_X, ((0,0),(2,2),(2,2),(0,0)), 'constant')\ntest_X = np.pad(test_X, ((0,0),(2,2),(2,2),(0,0)), 'constant')","5feb965a":"tf.reset_default_graph()\ndef cnn_model_fn(features , labels , mode ):\n    input_layer = tf.reshape(features['x'] , [ -1 , 32 , 32 , 1])\n    \n    conv1 = tf.layers.conv2d(\n        inputs = input_layer , \n        filters = 6 , \n        kernel_size = [5 , 5],\n        padding = 'valid',\n        activation = tf.nn.tanh\n        )\n    pool1 = tf.layers.average_pooling2d(inputs = conv1 , \n                                        pool_size = [2 , 2] \n                                        , strides = 2 )\n\n    conv2 = tf.layers.conv2d(\n        inputs = pool1,\n        filters = 16 , \n        kernel_size = [5 , 5] ,\n        padding  = 'valid',\n        activation = tf.nn.tanh\n        )\n    \n    pool2 = tf.layers.average_pooling2d(inputs = conv2 , \n                                        pool_size = [2 , 2] \n                                        , strides = 2 )\n\n    conv3 = tf.layers.conv2d(\n        inputs = pool2 , \n        filters = 120 , \n        kernel_size = [5 , 5],\n        padding = 'valid',\n        activation = tf.nn.tanh\n        )\n    conv3_flat = tf.layers.flatten(conv3)\n    dense = tf.layers.dense(\n        inputs = conv3_flat , \n        units = 84 , \n        activation = tf.nn.tanh\n        )\n    logits = tf.layers.dense(\n        inputs = dense,\n        units = 10 \n        ) \n    \n    predictions = {'classes' : tf.argmax(input = logits , axis = 1 ),\n                  'probabilities' : tf.nn.softmax(logits , name = 'softmax_tensor')}\n    \n    if mode == tf.estimator.ModeKeys.PREDICT:\n        return tf.estimator.EstimatorSpec(mode = mode , \n                                          predictions = predictions)\n    \n    #Calculate Loss\n    loss = tf.losses.sparse_softmax_cross_entropy(labels = labels , logits = logits )\n    \n    if mode == tf.estimator.ModeKeys.TRAIN:\n        optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.001)\n        train_op = optimizer.minimize(\n            loss = loss , \n            global_step = tf.train.get_global_step()\n            )\n        return tf.estimator.EstimatorSpec(mode = mode , loss = loss , train_op = train_op)\n    \n    eval_metric_ops = {\n        'accuracy' : tf.metrics.accuracy(labels = labels ,\n                                         predictions =  predictions['classes'])\n    }\n    \n    return tf.estimator.EstimatorSpec(mode = mode , loss = loss , eval_metric_ops = eval_metric_ops)","e651f2dd":"cnn_image_classifier = tf.estimator.Estimator(\n    model_fn = cnn_model_fn , model_dir = '\/tmp\/model_checkpoints' \n    )","80e38124":"tensors_to_log = {'probabilities':'softmax_tensor'}\nlogging_hook = tf.train.LoggingTensorHook(\n    tensors = tensors_to_log , every_n_iter = 50 \n    )","6b5494d2":"train_input_fn = tf.estimator.inputs.numpy_input_fn(\n    x = {'x':train_X},\n    y = train_label , \n    batch_size = 100 ,\n    num_epochs = None , \n    shuffle = True\n    )\n\ncnn_image_classifier.train(input_fn = train_input_fn,\n                          steps = 1, \n                          hooks = [logging_hook])","748f8b0f":"cnn_image_classifier.train(input_fn = train_input_fn , steps = 10000)","fc1e9ac0":"eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n    x = {'x' : test_X},\n    y = test_label , \n    num_epochs = 1,\n    shuffle = False\n    )\n\neval_results = cnn_image_classifier.evaluate(input_fn = eval_input_fn)\nprint(eval_results)","c3e244c9":"pred_input_fn = tf.estimator.inputs.numpy_input_fn(\n    x = {'x' : test_X},\n    y = test_label,\n    num_epochs = 1,\n    shuffle = False\n    )\n\ny_pred = cnn_image_classifier.predict(input_fn = pred_input_fn)\nclasses = [p['classes'] for p in y_pred]","eaf4dbac":"plt.figure(1 , figsize = (15  , 9 ))\nn = 0 \nfor i in range(49):\n    n += 1 \n    plt.subplot(7 , 7 , n)\n    plt.subplots_adjust(hspace = 0.5 , wspace = 0.5)\n    r = np.random.randint(0 , 10000 , 1)[0]\n    plt.imshow(test_img[r] , cmap = 'gray')\n    plt.xticks([]) , plt.yticks([])\n    plt.xlabel('True : {}\\nPred : {} '.format(test_label[r] , classes[r]) )\n    \nplt.show()","c8a621b0":"<center><h1> Handwritten characters in ancient Japanese manuscripts Image classification using CNN  <\/h1><\/center>\n![jm](http:\/\/www.tameshigiri.ca\/wp-content\/uploads\/2014\/07\/yagyu_full.jpg)"}}