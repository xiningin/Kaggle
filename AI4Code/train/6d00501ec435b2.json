{"cell_type":{"8cb90bbd":"code","b8e7adad":"code","ff7a2367":"code","a4257096":"code","b31b1e0d":"code","d09a468c":"code","1aa705cf":"code","d8fa6e98":"code","7c66ac16":"code","38ca6e5b":"code","baecc650":"code","ee2a8dcd":"code","dbe76d5f":"code","32dd82d7":"code","ba063278":"code","ab104062":"code","961a53dc":"code","9a6a5c01":"code","e8332e2b":"code","09fff9c8":"code","33d269b2":"code","876a5048":"code","ab4594f1":"code","ceb051c1":"code","a09e449b":"code","3cd170e1":"code","2e79fb22":"markdown","061375e5":"markdown"},"source":{"8cb90bbd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","b8e7adad":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","ff7a2367":"iris = pd.read_table('..\/input\/IRIS.csv',sep=\",\")","a4257096":"type(iris)","b31b1e0d":"iris.head()","d09a468c":"listItem = []\nfor col in iris.columns :\n    listItem.append([col,iris[col].dtype,\n                     \n                     iris[col].isna().sum(),\n                     \n                     round((iris[col].isna().sum()\/len(iris[col])) * 100,2),\n                     \n                     iris[col].nunique(),\n                     \n                     list(iris[col].sample(5).drop_duplicates().values)]);\n\ndfDesc = pd.DataFrame(columns=['dataFeatures', 'dataType', 'null', 'nullPct', 'unique', 'uniqueSample'],\n                     data=listItem)\ndfDesc","1aa705cf":"iris.groupby([\"species\"]).count()","d8fa6e98":"iris.groupby([\"species\"]).mean()","7c66ac16":"iris.groupby([\"species\"]).mean().sort_values(by=\"petal_length\",ascending =True)[\"petal_length\"]","38ca6e5b":"plt.figure(figsize=(20, 20))\nsns.pairplot(iris,hue=\"species\", markers=\"o\",plot_kws={\"s\": 50,'alpha':0.5})","baecc650":"ciris = iris.copy()","ee2a8dcd":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()","dbe76d5f":"ciris['species'] = le.fit_transform(ciris[\"species\"])","32dd82d7":"plt.figure(figsize=(20, 20))\nsns.pairplot(ciris,hue=\"species\", markers=\"o\",plot_kws={\"s\": 50,'alpha':0.5})","ba063278":"feature=ciris.drop('species',axis=1)\ntarget=ciris['species']\n\nciris_corr = feature.join(target).corr()\n\nmask = np.zeros((5,5))\nmask[:4,:]=1\n\nplt.figure(figsize=(10, 10))\nwith sns.axes_style(\"white\"):\n    sns.heatmap(ciris_corr, annot=True,square=True,mask=mask)","ab104062":"sns.boxplot(x=\"species\",y=\"sepal_length\",data=iris)","961a53dc":"sns.boxplot(x=\"species\",y=\"sepal_width\",data=iris)","9a6a5c01":"sns.boxplot(x=\"species\",y=\"petal_length\",data=iris)","e8332e2b":"sns.boxplot(x=\"species\",y=\"petal_width\",data=iris)","09fff9c8":"iris = pd.read_table('..\/input\/IRIS.csv',sep=\",\")\n\nfeature = iris.drop([\"species\"],axis=1)\ntarget = iris[\"species\"]\nfeature[\"sepalarea\"] = feature[\"sepal_length\"]*feature[\"sepal_width\"]\nfeature[\"petalare\"] = feature[\"petal_length\"]*feature[\"petal_width\"]","33d269b2":"# from sklearn.preprocessing import MinMaxScaler,StandardScaler,robust_scale\n# scaler = StandardScaler();\n\n\n\n# colscal=[\"sepal_length\",\"petal_length\",\"petal_width]\n\n# scaler.fit(feature[colscal])\n# scaled_features = pd.DataFrame(scaler.transform(feature[colscal]),columns=colscal)\n\n# feature =feature.drop(colscal,axis=1)\n# feature = scaled_features.join(feature)","876a5048":"from sklearn.model_selection import train_test_split,cross_val_score\nX_train, X_test, y_train, y_test = train_test_split(feature,target,\n                                                    test_size=0.20,random_state=101)","ab4594f1":"from xgboost import XGBClassifier\n\nmodel = XGBClassifier(random_state=101)\nmodel.fit(X_train, y_train)","ceb051c1":"from sklearn.metrics import classification_report, matthews_corrcoef, roc_auc_score, confusion_matrix, accuracy_score,recall_score\n\npredict = model.predict(X_train)\npredictProb = model.predict_proba(X_train)\n\n\nprint(\"confusion_matrix :\\n\",confusion_matrix(y_train, predict))\nprint(\"\\nclassification_report :\\n\",classification_report(y_train, predict))\nprint('Recall Score',recall_score(y_train, predict,average=None))\nprint('Accuracy :',accuracy_score(y_train, predict))\nprint('Matthews Corr_coef :',matthews_corrcoef(y_train, predict))","a09e449b":"from sklearn.metrics import classification_report, matthews_corrcoef, roc_auc_score, confusion_matrix, accuracy_score,recall_score\n\npredict = model.predict(X_test)\npredictProb = model.predict_proba(X_test)\n\n\nprint(\"confusion_matrix :\\n\",confusion_matrix(y_test, predict))\nprint(\"\\nclassification_report :\\n\",classification_report(y_test, predict))\nprint('Recall Score',recall_score(y_test, predict,average=None))\nprint('Accuracy :',accuracy_score(y_test, predict))\nprint('Matthews Corr_coef :',matthews_corrcoef(y_test, predict))","3cd170e1":"coef1 = pd.Series(model.feature_importances_,feature.columns).sort_values(ascending=False)\n\npd.DataFrame(coef1,columns=[\"Features\"]).transpose().plot(kind=\"bar\",title=\"Feature Importances\") #for the legends\n\ncoef1.plot(kind=\"bar\",title=\"Feature Importances\")","2e79fb22":"### Features Importance","061375e5":"### X_test Evaluation"}}