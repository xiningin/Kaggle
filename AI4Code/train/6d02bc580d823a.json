{"cell_type":{"3c1f7734":"code","1ad55e06":"code","cac27608":"code","49ec5e0d":"code","0c8fd302":"code","5d785257":"code","5cc7b974":"code","2ebbb827":"code","7843a8e3":"code","3b39dba6":"code","550d01ce":"code","5127c67d":"code","f2fdf8ca":"code","76e6c903":"code","f33e502c":"code","57c06eed":"code","3c3963ef":"code","51ddfdba":"code","c52499c7":"code","b44e5d21":"code","08df6019":"code","2b181643":"code","7c1adc90":"code","6fb9c0a9":"code","31a195f6":"code","32fa40cb":"code","9646d3ba":"code","313b1524":"code","b23fcbec":"code","161cfa94":"code","e46d103e":"code","034170e7":"code","9761988d":"code","58cd7ec3":"markdown","4d610186":"markdown","958d447d":"markdown","f9caba22":"markdown","fbcc692f":"markdown","daea825a":"markdown","2f88c22f":"markdown","fded3506":"markdown","e2bbdba1":"markdown","f7a86144":"markdown","6ffd8ec8":"markdown"},"source":{"3c1f7734":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n### Graphic libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns","1ad55e06":"df_train =pd.read_csv(\"..\/input\/tabular-playground-series-jan-2021\/train.csv\")","cac27608":"df_train.head()","49ec5e0d":"df_train.info()","0c8fd302":"df_train.isna().sum()","5d785257":"df_train.describe()","5cc7b974":"df_test=pd.read_csv(\"..\/input\/tabular-playground-series-jan-2021\/test.csv\")","2ebbb827":"df_test.head()","7843a8e3":"df_test.isnull().sum()\n","3b39dba6":"df_train.shape","550d01ce":"df_train.columns","5127c67d":"x = df_train.iloc[:, 1:15].values  \nprint(x) \ny = df_train.iloc[:, -1].values ","f2fdf8ca":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=1)","76e6c903":"# Feature Scaling\n#from sklearn.preprocessing import StandardScaler\n\n#sc = StandardScaler()\n#X_train = sc.fit_transform(X_train)\n#X_test = sc.transform(X_test)","f33e502c":"from sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics\nfrom sklearn import model_selection","57c06eed":"#from xgboost import XGBRegressor\nimport lightgbm as ltb","3c3963ef":"\n#ltb_r = ltb.LGBMRegressor()\n\nlgbm = ltb.LGBMRegressor()","51ddfdba":"#Defining a dictionary containing all the releveant parameters\nparam_grid = {\n    \"boosting_type\": ['gbdt'],\n    \"num_leaves\": [ 19, 31, 37, 47],\n    \"max_depth\": [7, 15, 29, 37, 47, 53], \n    \"learning_rate\": [0.1, 0.15, 0.01],\n    \"n_estimators\": [500, 1000, 2000], \n    \"subsample_for_bin\": [20000, 200000, 2000000], \n    \"objective\": [\"regression\"],\n    \"min_child_weight\": [0.001, 0.01], \n    \"min_child_samples\":[20, 50, 100], \n    \"subsample\":[1.0], \n    \"subsample_freq\":[0], \n    \"colsample_bytree\":[1.0], \n    \"reg_alpha\":[0.0], \n    \"reg_lambda\":[0.0]\n}","c52499c7":"model = model_selection.RandomizedSearchCV(\n    estimator=lgbm,\n    param_distributions=param_grid,\n    n_iter=100,\n    scoring=\"neg_root_mean_squared_error\",\n    verbose=10,\n    n_jobs=-1,\n    cv=5\n)","b44e5d21":"# fit the model and extract best score\nmodel.fit(X_train, y_train)","08df6019":"print(f\"Best score: {model.best_score_}\")\nprint(\"Best parameters from the RandomSearchCV:\")\nbest_parameters = model.best_estimator_.get_params()\nfor param_name in sorted(param_grid.keys()):\n    print(f\"\\t{param_name}: {best_parameters[param_name]}\")","2b181643":"\n#ltb_r = ltb.LGBMRegressor()\n\n'''\nltb_r = ltb.LGBMRegressor(boosting_type= 'gbdt', #'rf', #'goss',#'dart', #\n                         num_leaves=31, \n                         max_depth= 11, #12, #16, #- 1, \n                         learning_rate=0.1, \n                         n_estimators=1000, #500, \n                         subsample_for_bin=200000, \n                         objective=None, \n                         class_weight=None, \n                         min_split_gain=0.0, \n                         min_child_weight=0.001, \n                         min_child_samples=20, \n                         subsample=1.0, \n                         subsample_freq=0, \n                         colsample_bytree=1.0, \n                         reg_alpha=0.0, \n                         reg_lambda=0.0, \n                         random_state=None, \n                         n_jobs=- 1, \n                         silent=True\n                        )\n\nltb_r.fit(X_train,y_train)\n\n'''","7c1adc90":"# Get best model\nbest_model = model.best_estimator_","6fb9c0a9":"y_pred= best_model.predict(X_train)","31a195f6":"from sklearn import metrics\n\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_train, y_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_train, y_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_train, y_pred)))","32fa40cb":"y_pred = best_model.predict(X_test)","9646d3ba":"from sklearn import metrics\n\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","313b1524":"#X_t = sc.transform(df_test[:,1:])","b23fcbec":"# Make prediction for submission using best_estimators from grid search.\npreds = best_model.predict(df_test.iloc[:,1:].values)\n#preds=XGB.predict(df_test.iloc[:,1:].values)","161cfa94":"sub=pd.read_csv(\"..\/input\/tabular-playground-series-jan-2021\/sample_submission.csv\")","e46d103e":"sub.head()","034170e7":"sub.target =preds\nsub.to_csv(\"submission.csv\", index=False)","9761988d":"sub.head()","58cd7ec3":"### RandomizedSearch: Hyperparameters","4d610186":"Some columns have little negative correlation with target variable.\n\nThese can prove to be important features to predict target.","958d447d":"Storing values in numpy array saves memory.","f9caba22":"## EDA\n\n","fbcc692f":"## Prepare predictions for submission.csv","daea825a":"For previous grid_search\n    \n    Mean Absolute Error: 0.590135219891411\n    Mean Squared Error: 0.4941394332980038\n    Root Mean Squared Error: 0.7029505198077627","2f88c22f":"### LGB regressor","fded3506":"## Split data for training & validation","e2bbdba1":"## Loading train and test data sets","f7a86144":"Data is clean with continues target variable. let's make split into 70:20 train and validation data. and drop id column. ","6ffd8ec8":"Now let's check test data."}}