{"cell_type":{"70ba36b7":"code","5baed3a9":"code","50e457be":"code","42a93b65":"code","9eff61bc":"code","081efa69":"code","51407bd7":"code","3ec18e24":"code","b16f4366":"code","8cdee73e":"code","2ba66730":"code","028ce96b":"code","a7f7e26a":"code","d84e77f2":"code","4d6bb590":"code","8c828692":"code","f04c5b83":"code","8da0afae":"code","46fc4eed":"code","1265093d":"code","7c48ca1e":"code","2364f5d5":"code","8b37bf1b":"code","a085c871":"code","ec74b9e9":"code","df8f7551":"code","8fbb2032":"code","98318e36":"code","a8f93c3c":"code","334275a5":"code","254d15d2":"code","163ae2ed":"code","a51a2143":"code","095d1e8f":"code","dc0371f6":"code","2ec4efb4":"code","94bbc9ff":"code","29e229e6":"code","99816edb":"code","66bee9c8":"code","44fe495b":"code","23ffa3ca":"code","a98c5e0e":"code","823e0a92":"code","f9356798":"code","08b6fdd8":"code","fcc8ae4f":"markdown","b5a86ec4":"markdown","1393335e":"markdown","6af264f2":"markdown","78189334":"markdown","04a5e3f5":"markdown","a11e8bac":"markdown","a2e4b23f":"markdown","7a436f44":"markdown"},"source":{"70ba36b7":"import pandas as pd\nimport numpy as np\n\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix, recall_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import precision_score, f1_score\nfrom sklearn.metrics import precision_recall_fscore_support, classification_report\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.model_selection import train_test_split \n\nfrom sklearn import model_selection\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom tqdm.notebook import tqdm\nfrom catboost import Pool, CatBoostClassifier\nfrom sklearn import model_selection\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\n\nimport warnings\nwarnings.filterwarnings('ignore')","5baed3a9":"df = pd.read_csv('..\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv')","50e457be":"df.head()","42a93b65":"df.dtypes","9eff61bc":"colours = ['#000099', '#ffff00'] \nplt.figure(figsize = (15,5))\nsns.heatmap(df.isnull(), cmap = sns.color_palette(colours))\nplt.show()","081efa69":"df = df.fillna(df['bmi'].mean())","51407bd7":"df.shape","3ec18e24":"df[['age', 'avg_glucose_level', 'bmi']].describe()","b16f4366":"df_age = df.pivot_table('age', index='gender', aggfunc=['max', 'min', 'mean', 'median'])","8cdee73e":"df_age","2ba66730":"df_age_count = df['age'].value_counts()","028ce96b":"fig = go.Figure(data=[go.Bar(\n    x=df['age'].value_counts().index,\n    y=df['age'].value_counts().values,\n    width=0.8,\n)])\n\nfig.update_layout(title = 'Count of respondents by age')\nfig.update_layout(title_x = 0.5)\n\n\nfig.show()","a7f7e26a":"df_stroke = df.pivot_table('age', index='stroke', aggfunc=['max', 'min', 'mean', 'median'])\ndf_stroke","d84e77f2":"df_stroke_count = df.loc[df['stroke'] == 1]\ndf_nostroke_count = df.loc[df['stroke'] == 0]","4d6bb590":"fig = go.Figure(data=[go.Bar(\n    x=df_stroke_count['age'].value_counts().index,\n    y=df_stroke_count['age'].value_counts().values,\n    width=0.8\n)])\n\nfig.update_layout(title = 'Count of strokes by age')\nfig.update_layout(title_x = 0.5)\n\n\nfig.show()","8c828692":"fig = go.Figure([go.Bar(\n    x=df['stroke'].value_counts().index, \n    y=df['stroke'].value_counts().values)])\nfig.show()","f04c5b83":"fig = go.Figure([go.Bar(\n    x=df_stroke_count['gender'].value_counts().index, \n    y=df_stroke_count['gender'].value_counts().values)])\nfig.show()","8da0afae":"fig = go.Figure(\n    [go.Bar(\n        name='Stroke',\n        x=df_stroke_count['hypertension'].value_counts().index, \n        y=df_stroke_count['hypertension'].value_counts().values),\n    go.Bar(\n        name='No stroke', \n        x=df_nostroke_count['hypertension'].value_counts().index, \n        y=df_nostroke_count['hypertension'].value_counts().values)]\n    )\n\nfig.update_layout(title = 'Count of people with (1)\/ without (0) hypertension')\nfig.update_layout(title_x = 0.5)\n\nfig.show()","46fc4eed":"fig = go.Figure(\n    [go.Bar(\n        name='Stroke',\n        x=df_stroke_count['heart_disease'].value_counts().index, \n        y=df_stroke_count['heart_disease'].value_counts().values),\n    go.Bar(\n        name='No stroke', \n        x=df_nostroke_count['heart_disease'].value_counts().index, \n        y=df_nostroke_count['heart_disease'].value_counts().values)]\n    )\n\nfig.update_layout(title = 'Count of people with (1)\/ without (0) heart diseases')\nfig.update_layout(title_x = 0.5)\n\nfig.show()","1265093d":"fig = go.Figure(\n    [go.Bar(\n        name='Stroke',\n        x=df_stroke_count['work_type'].value_counts().index, \n        y=df_stroke_count['work_type'].value_counts().values),\n    go.Bar(\n        name='No stroke', \n        x=df_nostroke_count['work_type'].value_counts().index, \n        y=df_nostroke_count['work_type'].value_counts().values)]\n    )\n\nfig.update_layout(title = 'People by work types')\nfig.update_layout(title_x = 0.5)\n\nfig.show()","7c48ca1e":"fig = go.Figure(\n    [go.Bar(\n        name='Stroke',\n        x=df_stroke_count['ever_married'].value_counts().index, \n        y=df_stroke_count['ever_married'].value_counts().values),\n    go.Bar(\n        name='No stroke', \n        x=df_nostroke_count['ever_married'].value_counts().index, \n        y=df_nostroke_count['ever_married'].value_counts().values)]\n    )\n\nfig.update_layout(title = 'Is ever married')\nfig.update_layout(title_x = 0.5)\n\nfig.show()","2364f5d5":"fig = go.Figure(\n    [go.Bar(\n        name='Stroke',\n        x=df_stroke_count['Residence_type'].value_counts().index, \n        y=df_stroke_count['Residence_type'].value_counts().values),\n    go.Bar(\n        name='No stroke', \n        x=df_nostroke_count['Residence_type'].value_counts().index, \n        y=df_nostroke_count['Residence_type'].value_counts().values)]\n    )\n\nfig.update_layout(title = 'Is urban\/rural')\nfig.update_layout(title_x = 0.5)\n\nfig.show()","8b37bf1b":"fig = px.histogram(df_stroke_count, x = df_stroke_count['avg_glucose_level'], nbins=100)\nfig.update_layout(title = 'Glucose level')\nfig.update_layout(title_x = 0.5)\n\nfig.show()\n","a085c871":"fig = px.histogram(df_nostroke_count, x = df_nostroke_count['avg_glucose_level'], nbins=1000)\nfig.update_layout(title = 'Glucose level')\nfig.update_layout(title_x = 0.5)\n\nfig.show()\n\n","ec74b9e9":"fig = px.histogram(df_stroke_count, x = df_stroke_count['bmi'], nbins=70)\nfig.update_layout(title = 'bmi')\nfig.update_layout(title_x = 0.5)\n\nfig.show()","df8f7551":"fig = px.histogram(df_nostroke_count, x = df_nostroke_count['bmi'], nbins=70)\nfig.update_layout(title = 'bmi')\nfig.update_layout(title_x = 0.5)\n\nfig.show()","8fbb2032":"fig = px.scatter(df_stroke_count, x=\"bmi\", y=\"avg_glucose_level\", color = 'gender', size = 'age', height=1000)\nfig.show()","98318e36":"fig = go.Figure(\n    [go.Bar(\n        name='Stroke',\n        x=df_stroke_count['smoking_status'].value_counts().index, \n        y=df_stroke_count['smoking_status'].value_counts().values),\n    go.Bar(\n        name='No stroke', \n        x=df_nostroke_count['smoking_status'].value_counts().index, \n        y=df_nostroke_count['smoking_status'].value_counts().values)]\n    )\n\nfig.update_layout(title = 'Smoking status')\nfig.update_layout(title_x = 0.5)\n\nfig.show()","a8f93c3c":"fig = px.pie(values=df_stroke_count['smoking_status'].value_counts().values, \n                names=df_stroke_count['smoking_status'].value_counts().index)\nfig.show()","334275a5":"from sklearn.preprocessing import LabelEncoder\n\nlabelencoder = LabelEncoder()\ndf['gender'] = labelencoder.fit_transform(df['gender'])\ndf['ever_married'] = labelencoder.fit_transform(df['ever_married'])\ndf['work_type'] = labelencoder.fit_transform(df['work_type'])\ndf['Residence_type'] = labelencoder.fit_transform(df['Residence_type'])\ndf['smoking_status'] = labelencoder.fit_transform(df['smoking_status'])","254d15d2":"from termcolor import colored\nfrom scipy.stats import kendalltau\n    \nfor i in df.columns:\n    coef, p = kendalltau(df[i], df['stroke'])\n    print(colored(f\"{i}\", 'blue'))\n    if coef > 0.6:\n        print(colored('Kendall correlation coef more than 0.6: %.3f' % coef, 'yellow'))\n    else:\n        print('Kendall correlation coef less than 0.6: %.3f' % coef)\n    alpha = 0.05\n    if p > alpha:\n        print(colored('Variables are not correlated p=%.3f' % p, 'red'))\n    else:\n        print(colored('Variables are correlated p=%.3f' % p, 'green'))","163ae2ed":"correlation = df.corr(method=\"kendall\")","a51a2143":"fig = plt.figure(figsize = (12,12))\nsns.heatmap(correlation, annot=True, cmap=\"RdYlGn\", vmin=-1, vmax=+1)\nplt.title('Kendall Correlation')\nplt.show()","095d1e8f":"df.columns","dc0371f6":"train, valid = model_selection.train_test_split(df,\n                                                test_size=0.20, \n                                                stratify=df['stroke'], \n                                                shuffle=True, random_state=10)","2ec4efb4":"feature_names = ['gender', 'age', 'hypertension', 'heart_disease', 'ever_married',\n       'work_type', 'Residence_type', 'avg_glucose_level', 'bmi',\n       'smoking_status']\n\ntarget = 'stroke'","94bbc9ff":"model = CatBoostClassifier(\n    verbose=50,\n    loss_function='Logloss',\n    eval_metric='TotalF1',\n    task_type=\"CPU\",\n    iterations=1000,\n    learning_rate=0.2,            \n)","29e229e6":"model.fit(\n    train[feature_names], train[target],\n    eval_set=(valid[feature_names], valid[target]),\n    plot=True\n)","99816edb":"print(classification_report(valid.stroke.values, model.predict(valid[feature_names])))","66bee9c8":"X = df.loc[:, df.columns != 'stroke']\ny = df.loc[:, df.columns == 'stroke']\n\nfrom imblearn.over_sampling import SMOTE\n\nos = SMOTE(random_state=17)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=17)\ncolumns = X_train.columns\n\nos_data_X,os_data_y=os.fit_resample(X_train, y_train)\nos_data_X = pd.DataFrame(data=os_data_X,columns=columns )\nos_data_y= pd.DataFrame(data=os_data_y,columns=['stroke'])\n\nprint(\"Data shape\",len(os_data_X))\nprint(\"Stroke 0 shape\",len(os_data_y[os_data_y['stroke']==0]))\nprint(\"Stroke 1 shape\",len(os_data_y[os_data_y['stroke']==1]))","44fe495b":"X = os_data_X\ny = os_data_y\n\nX = X.join(y)","23ffa3ca":"train, valid = model_selection.train_test_split(X,\n                                                test_size=0.20, \n                                                stratify=X['stroke'], \n                                                shuffle=True, random_state=10)","a98c5e0e":"feature_names = ['gender', 'age', 'hypertension', 'heart_disease', 'ever_married',\n       'work_type', 'Residence_type', 'avg_glucose_level', 'bmi',\n       'smoking_status']\n\ntarget = 'stroke'","823e0a92":"model.fit(\n    train[feature_names], train[target],\n    eval_set=(valid[feature_names], valid[target]),\n    plot=True\n)","f9356798":"print(classification_report(valid.stroke.values, model.predict(valid[feature_names])))","08b6fdd8":"importance = model.get_feature_importance(prettified=True)\n\nfig = go.Figure([go.Bar(\n    x=importance['Feature Id'], \n    y=importance['Importances'])])\nfig.show()","fcc8ae4f":"Converting text columns to numeric for further work","b5a86ec4":"Let's look at the correlation of features to the target variable","1393335e":"As expected, the model is fairly accurate, but works very poorly for identifying people who have had a stroke. Thus, it does not serve the main purpose of our study. In this case, having no other data, the only method is to artificially increase our sample by the SMOTE method.","6af264f2":"We have some missing values in the bmi index. In order not to delete lines, fill them with the average value.","78189334":"Let's take a quick look at the numeric variables. ","04a5e3f5":"First of all let's look for NaN in data","a11e8bac":"To build the model, I will use CatBoostClassifier. Our task is to obtain the largest metric \"recall\" to minimize \"false negative\" results. Evaluation using F1-Score (given the output class imbalance)","a2e4b23f":"Let's look at the importance of the parameters","7a436f44":"Conclusions on intelligence analysis:\n\n    Although we have a sample of more than 5,000 respondents, the target variable is unevenly distributed. We have very few cases of stroke from the total number of observations. This poses the first problem - even with a reasonably good predictive model, it will almost certainly be good at predicting when a person will not have a stroke, and vice versa.\n    The second problem is not a very clear correlation between signs. There is no clear picture of which of these influences the target variable more. Obviously, it must be age and medical feauters."}}