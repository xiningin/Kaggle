{"cell_type":{"a7d507d3":"code","a7058713":"code","0056fb4e":"code","f7e2ec07":"code","d27fd724":"code","80a0eb74":"code","b5369c95":"code","22690cd7":"code","297f1128":"code","b86116e8":"code","c65c6bd8":"code","2655091f":"code","62fae4f0":"code","37d34034":"code","60bd1746":"code","35775e30":"code","4ecbe348":"code","f3dd99d5":"code","049aad0f":"code","3fcade70":"code","711a2968":"code","d676996b":"markdown","491a89d3":"markdown","ed649c60":"markdown","1a33c5aa":"markdown","e6250e95":"markdown","c2fa75be":"markdown","8fd4c17d":"markdown","46c28ee5":"markdown","970e2ad4":"markdown","620cd25a":"markdown","d67c7080":"markdown","d4e9319f":"markdown","ed4528fa":"markdown"},"source":{"a7d507d3":"import numpy as np # linear algebra\nimport os\nimport tensorflow as tf \nfrom tqdm import tqdm_notebook\nimport skimage.io as io\nimport skimage.transform as trans\nimport numpy as np\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport cv2","a7058713":"id2code = {0:(0,0,0),1:(255,255,255)}\nid2name = {0:'void',1:'vessel'}","0056fb4e":"def rgb_to_onehot(rgb_image, colormap = id2code):\n    '''Function to one hot encode RGB mask labels\n        Inputs: \n            rgb_image - image matrix (eg. 256 x 256 x 3 dimension numpy ndarray)\n            colormap - dictionary of color to label id\n        Output: One hot encoded image of dimensions (height x width x num_classes) where num_classes = len(colormap)\n    '''\n    num_classes = len(colormap)\n    shape = rgb_image.shape[:2]+(num_classes,)\n    encoded_image = np.zeros( shape, dtype=np.int8 )\n    for i, cls in enumerate(colormap):\n        encoded_image[:,:,i] = np.all(rgb_image.reshape( (-1,3) ) == colormap[i], axis=1).reshape(shape[:2])\n    return encoded_image\n\n\ndef onehot_to_rgb(onehot, colormap = id2code):\n    '''Function to decode encoded mask labels\n        Inputs: \n            onehot - one hot encoded image matrix (height x width x num_classes)\n            colormap - dictionary of color to label id\n        Output: Decoded RGB image (height x width x 3) \n    '''\n    single_layer = np.argmax(onehot, axis=-1)\n    output = np.zeros(onehot.shape[:2]+(3,) )\n    for k in colormap.keys():\n        output[single_layer==k] = colormap[k]\n    return np.uint8(output)","f7e2ec07":"def GrayScale(image):\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n    return image","d27fd724":"# define datagenerator\ndata_gen_args = dict(rescale=1.\/255,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    preprocessing_function=GrayScale)\n\n\nmask_gen_args = dict(\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True)\n\ntest_gen_args = dict(rescale=1.\/255)\ntest_mask_gen_args = dict()\n\ntrain_frames_datagen = ImageDataGenerator(**data_gen_args)\ntrain_masks_datagen = ImageDataGenerator(**mask_gen_args)\n\nvalidation_frames_datagen = ImageDataGenerator(**data_gen_args)\nvalidation_masks_datagen = ImageDataGenerator(**mask_gen_args)\n\ntest_frames_datagen = ImageDataGenerator(**test_gen_args)\ntest_masks_datagen = ImageDataGenerator(**test_mask_gen_args)\n","80a0eb74":"def TrainAugmentGenerator(seed=42, batch_size =5):\n    os.chdir('\/kaggle\/input')\n    train_image_generator = train_frames_datagen.flow_from_directory(\n        \".\/eye-vessel\/DRIVE2\/train\/train_frames\/\", batch_size = batch_size, seed = seed, target_size=(256,256))\n    \n    train_mask_generator = train_masks_datagen.flow_from_directory(\n        \".\/eye-vessel\/DRIVE2\/train\/train_labels\/\", batch_size = batch_size, seed = seed, target_size=(256,256))\n    \n    while True:\n        X1i = train_image_generator.next()\n        X2i = train_mask_generator.next()\n        \n        #One hot encoding RGB images\n        mask_encoded = [rgb_to_onehot(X2i[0][x,:,:,:], id2code) for x in range(X2i[0].shape[0])]\n        \n        yield X1i[0], np.asarray(mask_encoded)","b5369c95":"def TestAugmentGenerator(seed=42, batch_size =5):\n    os.chdir('\/kaggle\/input')\n    test_image_generator = test_frames_datagen.flow_from_directory(\n        \".\/eye-vessel\/DRIVE2\/test\/test_frames\/\", batch_size = batch_size, seed = seed, target_size=(256,256))\n    \n    test_mask_generator = test_masks_datagen.flow_from_directory(\n        \".\/eye-vessel\/DRIVE2\/test\/test_labels\/\", batch_size = batch_size, seed = seed, target_size=(256,256))\n    \n    while True:\n        X1i = test_image_generator.next()\n        X2i = test_mask_generator.next()\n        \n        #One hot encoding RGB images\n        mask_encoded = [rgb_to_onehot(X2i[0][x,:,:,:], id2code) for x in range(X2i[0].shape[0])]\n        \n        yield X1i[0], np.asarray(mask_encoded)","22690cd7":"def ValidationAugmentGenerator(seed=42, batch_size =5):\n    os.chdir('\/kaggle\/input')\n    validation_image_generator = train_frames_datagen.flow_from_directory(\n        \".\/eye-vessel\/DRIVE2\/validate\/val_frames\/\", batch_size = batch_size, seed = seed, target_size=(256,256))\n    \n    validation_mask_generator = train_masks_datagen.flow_from_directory(\n        \".\/eye-vessel\/DRIVE2\/validate\/val_labels\/\", batch_size = batch_size, seed = seed, target_size=(256,256))\n    \n \n    while True:\n        X1i =  validation_image_generator.next()\n        X2i =   validation_mask_generator.next()\n        \n        #One hot encoding RGB images\n        mask_encoded = [rgb_to_onehot(X2i[0][x,:,:,:], id2code) for x in range(X2i[0].shape[0])]\n        \n        yield X1i[0], np.asarray(mask_encoded)\n        ","297f1128":"def double_conv(inputs,in_c,out_c,bn=True,dilation_rate=1):\n    conv = Conv2D(in_c,out_c, activation='relu', padding = 'same', dilation_rate = dilation_rate)(inputs)\n    conv = Dropout(0.1)(conv)\n    if bn:\n        conv = BatchNormalization()(conv)\n    conv = Conv2D(in_c,out_c, activation='relu', padding = 'same', dilation_rate = dilation_rate)(conv)\n    conv = Dropout(0.25)(conv)\n    if bn:\n        conv = BatchNormalization()(conv)\n    \n    return conv","b86116e8":"def Unet(n_filters = 16, bn = True, dilation_rate = 1):\n \n    #Define input batch shape\n    batch_shape=(256,256,3)\n    inputs = Input(batch_shape)\n    print(inputs)\n    \n    conv1 = double_conv(inputs,n_filters*1,(3,3),bn=True,dilation_rate=1)\n    \n    pool1 = MaxPooling2D(pool_size=(2, 2), data_format='channels_last')(conv1)\n\n    conv2 = double_conv(pool1,n_filters*2,(3,3),bn=True,dilation_rate=1)\n    \n    pool2 = MaxPooling2D(pool_size=(2, 2), data_format='channels_last')(conv2)\n\n    conv3 = double_conv(pool2,n_filters*4,(3,3),bn=True,dilation_rate=1)\n        \n    pool3 = MaxPooling2D(pool_size=(2, 2), data_format='channels_last')(conv3)\n\n    conv4 = double_conv(pool3,n_filters*8,(3,3),bn=True,dilation_rate=1)\n       \n    pool4 = MaxPooling2D(pool_size=(2, 2), data_format='channels_last')(conv4)\n\n    conv5 = double_conv(pool4,n_filters*16,(3,3),bn=True,dilation_rate=1)\n        \n    up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4], axis=3)\n    \n    conv6 = double_conv(up6,n_filters*8,(3,3),bn=True,dilation_rate=1)\n        \n    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv3], axis=3)\n    \n    conv7 = double_conv(up7,n_filters*4,(3,3),bn=True,dilation_rate=1)\n        \n    up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2], axis=3)\n    \n    conv8 = double_conv(up8,n_filters*2,(3,3),bn=True,dilation_rate=1)\n        \n    up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1], axis=3)\n    \n    conv9 = double_conv(up9,n_filters*1,(3,3),bn=True,dilation_rate=1)\n        \n    conv10 = Conv2D(2, (1, 1), activation='softmax', padding = 'same', dilation_rate = dilation_rate)(conv9)\n\n    model = Model(inputs=inputs, outputs=conv10)\n\n    return model\n\nmodel = Unet(n_filters=32)","c65c6bd8":"def dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)\n\n\ndef tversky(y_true, y_pred, smooth=1, alpha=0.7):\n    y_true_pos = K.flatten(y_true)\n    y_pred_pos = K.flatten(y_pred)\n    true_pos = K.sum(y_true_pos * y_pred_pos)\n    false_neg = K.sum(y_true_pos * (1 - y_pred_pos))\n    false_pos = K.sum((1 - y_true_pos) * y_pred_pos)\n    return (true_pos + smooth) \/ (true_pos + alpha * false_neg + (1 - alpha) * false_pos + smooth)\n\n\ndef tversky_loss(y_true, y_pred):\n    return 1 - tversky(y_true, y_pred)\n\n\ndef focal_tversky_loss(y_true, y_pred, gamma=0.75):\n    tv = tversky(y_true, y_pred)\n    return K.pow((1 - tv), gamma)","2655091f":"import datetime\nmc = ModelCheckpoint(mode='min', filepath='eye_vessel_segment.h5', monitor='val_loss', save_best_only='True', save_weights_only='True', \n                     verbose=1)\nlog_dir = \"\/kaggle\/working\/logs\/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\nes = EarlyStopping(mode='min', monitor='val_loss', patience=10, verbose=1)\ntb = TensorBoard(log_dir=log_dir, write_graph=True, histogram_freq=1)\ncallbacks = [mc, es,tb]","62fae4f0":"opt = Adam(lr=1e-3)\nmodel.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=['accuracy',tversky_loss,dice_coef])\nmodel.summary()","37d34034":"num_epochs = 30\nbatch_size = 10\nresult = model.fit_generator(TrainAugmentGenerator(batch_size=batch_size), steps_per_epoch=234\/\/batch_size,\n                validation_data = ValidationAugmentGenerator(batch_size=batch_size),\n                validation_steps=26\/\/batch_size, epochs=num_epochs, callbacks=callbacks)\n# model.save_weights(\"eye_vessel_segment.h5\", overwrite=True)","60bd1746":"N = len(result.history['loss'])\n\n#Plot the model evaluation history\nplt.style.use(\"ggplot\")\nscale_factor = 5\nfig = plt.figure(figsize=(20,8))\n\nfig.add_subplot(1,2,1)\nplt.title(\"Training Loss\")\nplt.plot(np.arange(0, N), result.history[\"loss\"], label=\"train_loss\",linestyle='dashed')\nplt.plot(np.arange(0, N), result.history[\"val_loss\"], label=\"val_loss\")\nplt.ylim(0, 1)\nplt.xlim(0,N)\n\nfig.add_subplot(1,2,2)\nplt.title(\"Training Accuracy\")\nplt.plot(np.arange(0, N), result.history[\"accuracy\"], label=\"train_accuracy\",linestyle='dashed')\nplt.plot(np.arange(0, N), result.history[\"val_accuracy\"], label=\"val_accuracy\")\nplt.ylim(0, 1)\nplt.xlim(0,N)\n\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss\/Accuracy\")\nplt.legend(loc=\"lower left\")\nplt.show()","35775e30":"\ntesting_gen = TestAugmentGenerator(batch_size=10)\nbatch_img,batch_mask = next(testing_gen)\npred_all= model.predict(batch_img)\npred_all= (pred_all > 0.5).astype(np.uint8)\nnp.shape(pred_all)","4ecbe348":"from skimage.transform import resize\nfrom skimage.morphology import label","f3dd99d5":"preds_test_upsampled = []\nfor i in range(len(pred_all)):\n    preds_test_upsampled.append(resize(np.squeeze(pred_all[i]), \n                                       (256, 256), \n                                       mode='constant', preserve_range=True))","049aad0f":"x = onehot_to_rgb(preds_test_upsampled[1],id2code)","3fcade70":"\n# Run-length encoding stolen from https:\/\/www.kaggle.com\/rakhlin\/fast-run-length-encoding-python\ndef rle_encoding(x):\n    dots = np.where(x.T.flatten() == 1)[0]\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if (b>prev+1): run_lengths.extend((b + 1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return run_lengths\n\ndef prob_to_rles(x, cutoff=0.5):\n    lab_img = label(x > cutoff)\n    for i in range(1, lab_img.max() + 1):\n        yield rle_encoding(lab_img == i)","711a2968":"for i in range(0,np.shape(preds_test_upsampled)[0]):\n    \n    fig = plt.figure(figsize=(20,8))\n    \n    ax1 = fig.add_subplot(1,3,1)\n    ax1.imshow(batch_img[i])\n    ax1.title.set_text('Actual frame')\n    ax1.grid(b=None)\n    \n    \n    ax2 = fig.add_subplot(1,3,2)\n    ax2.set_title('Ground truth labels')\n    ax2.imshow(onehot_to_rgb(batch_mask[i],id2code))\n    ax2.grid(b=None)\n    \n    ax3 = fig.add_subplot(1,3,3)\n    ax3.set_title('Predicted labels')\n    ax3.imshow(onehot_to_rgb(preds_test_upsampled[i],id2code))\n    ax3.grid(b=None)\n    \n    plt.show()","d676996b":"# Function to convert each pixel of labels images to onehot& convert from onehot to probability of pixel","491a89d3":"# Testing","ed649c60":"# Plot Result","1a33c5aa":"# Training and Evaluation Model","e6250e95":"# Define Loss matrics","c2fa75be":"# Import Lirbray","8fd4c17d":"# Callback&Check Points","46c28ee5":"# Function Convert Image to grayscale","970e2ad4":"# Complie Model","620cd25a":"# Create Model","d67c7080":"# Define class and color map","d4e9319f":"# Data Generator and Augmentation","ed4528fa":"# Combine 2xConv to 1 Double Conv"}}