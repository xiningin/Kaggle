{"cell_type":{"0068af9b":"code","3cfc2cd3":"code","0d992d7e":"code","6d4ab8ed":"code","c2b5fa1e":"code","c609c6d0":"code","bb9e6509":"code","a2e6d8a4":"code","00b5e024":"code","390853eb":"code","e57f6369":"code","90031b88":"code","6e1d76b7":"code","6ab059ed":"code","ef2d3716":"code","a50b8603":"code","3de609d9":"code","419883db":"code","6ba11f00":"code","fbbaf342":"code","fc2d627a":"code","d526cc1e":"code","97b2d153":"code","631d5cd5":"code","8b1fa6af":"code","5e8cc05c":"code","4d901d0c":"code","a84ab29a":"code","11d53e46":"code","08b3cdd9":"code","3dd681fb":"code","7c8d6774":"code","c55b9e9b":"code","71440587":"code","5103b9c3":"code","2f857a8a":"code","8dade895":"code","c730b43b":"markdown","a63f01fc":"markdown","aee5ed42":"markdown","1c74589f":"markdown","0e995f5a":"markdown","e127731e":"markdown","b6398421":"markdown","ad81c948":"markdown","74cf68d1":"markdown","e3eafb31":"markdown","5e1b9b39":"markdown","ed5fc37e":"markdown","2875ca48":"markdown","243004bb":"markdown","d97091ac":"markdown","ee95d7e2":"markdown","a77494f6":"markdown","afb8152e":"markdown","8dbfcab9":"markdown","b29f39b6":"markdown","32908202":"markdown","a1a5cf14":"markdown","7ff87a65":"markdown","d2cdc0af":"markdown","ede5d334":"markdown","cd2ed883":"markdown"},"source":{"0068af9b":"import pandas as pd\nimport numpy as np\nimport os\nimport re\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","3cfc2cd3":"df = pd.read_csv('..\/input\/ramen-ratings\/ramen-ratings.csv') # Loading the dataset\ndf.head() # Printing the fist 5 rows to see the available features","0d992d7e":"shape = df.shape\nprint(\"Rows :\",shape[0])\nprint(\"Columns :\",shape[1])","6d4ab8ed":"df.info(verbose=True)","c2b5fa1e":"#Although stars is numberic but it is stored as string in the dataframe\n#Let's convert it into numeric value.\ndf['Stars']=pd.to_numeric(df['Stars'], errors='coerce')","c609c6d0":"df.describe()","bb9e6509":"df.describe(include =\"all\")","a2e6d8a4":"#different types of Ramen styles\ndf['Style'].value_counts()","00b5e024":"#what columns have NaN values\ndf.isna().any()","390853eb":"# Sum of NaNs in each column\ndf.isna().sum()","e57f6369":"# For all the NaNs in \"Top Ten\" column, we have assigned a temporary value 0.\n# we will deal with \"Top Ten\" column later.\ndf['Top Ten'].fillna(0, inplace=True)\n\n#section of dataframe with NaN values\ndf[df.isnull().any(axis=1)]","90031b88":"#Imputing style is not relevant in this case\n#espescially when only two rows have missing style values\n#so dropping the two rows with NaN in style\ndf.drop(2152, axis=0,inplace=True)\ndf.drop(2442, axis=0,inplace=True)","6e1d76b7":"#storing data with NaN in seperate dataframe\ndf_with_Nan = df[df.isnull().any(axis=1)]\ndf_with_Nan","6ab059ed":"for i in df_with_Nan.index:\n    subDf = df.loc[(df['Brand']==df_with_Nan.loc[i,'Brand']) & (df['Country']==df_with_Nan.loc[i,'Country'])]\n    mean = subDf['Stars'].mean()\n    df.loc[i,'Stars'] = round(mean,2)","ef2d3716":"df.isna().sum() # Checking again for NaNs","a50b8603":"df[df['Top Ten'] != 0]","3de609d9":"# we can we still '\\n' in our data\n# considering it as missing value let's fill it with 0 temporarily\ntop_ten_with_n=df[df['Top Ten'] == '\\n']\nfor i in top_ten_with_n.index:\n    df.loc[i,'Top Ten']=0","419883db":"#creating seperate columns for each year\n#and fill with NaN\nyears=['2012','2013','2014','2015','2016']\nfor y in years:\n    df[y+'_rank']=np.nan","6ba11f00":"# for specific year with the help of regex.\n#Stroring the row number for each value.\n#Extracting the rank which is at the end of the string.\n#Storing the rank at the specific year column and specific row index we stored at step2.\n#Dropping the \"Top Ten\" column.\nfor rank in df['Top Ten'].values:\n    for y in years:\n        if re.search('^'+y,str(rank)):\n            index = df[df['Top Ten']==rank].index.values\n            rank_number = str(rank).split()[-1]\n            df.loc[index,y+'_rank'] = int(''.join([i for i in rank_number if i.isdigit()]))\ndf.drop('Top Ten', axis=1, inplace=True)","fbbaf342":"#it very clean that no rank is equal to 0 rank\ndf.fillna(0, inplace=True)\ndf.head()","fc2d627a":"df.isna().sum()","d526cc1e":"df[\"2012_rank\"].value_counts()","97b2d153":"df[\"2013_rank\"].value_counts()","631d5cd5":"df[\"2014_rank\"].value_counts()","8b1fa6af":"df[\"2015_rank\"].value_counts()","5e8cc05c":"df[\"2016_rank\"].value_counts()","4d901d0c":"v = df.Country.value_counts()\nv=v.sort_values(ascending=True)\nfig, ax = plt.subplots(figsize=(12,8))\nv.plot(kind='barh')\nplt.show()","a84ab29a":"brands_name = df.Brand.value_counts()[:10].index\nbrand_size = df.Brand.value_counts()[:10].values\n\nfig,ax=plt.subplots(figsize=(15,4))\nax.bar(brands_name, brand_size, data=df)\nax.set_ylabel('Number of products')\nfor p in ax.patches:\n    an=ax.annotate(str(p.get_height()), xy=(p.get_x(),p.get_height()))\n    an.set_size(12)","11d53e46":"style=df.Style.value_counts()\nstyle","08b3cdd9":"plt.pie(style[0:4],pctdistance=1.5,autopct=\"%2.01f%%\",radius=1.7,labels=['Pack','Bowl','Cup','Tray'],\n        explode=[0,0,0,0.3],\n       textprops={'fontsize': 14})\nplt.show()","3dd681fb":"a4_dims = (4, 10)\nfig, ax = plt.subplots(figsize=a4_dims)\nsns.scatterplot(ax=ax, data=df,y='Country',x='Style')\nplt.show()","7c8d6774":"sns.distplot(df['Stars'],hist=True,kde=True,bins=5)\nplt.show()","c55b9e9b":"v = df.Country.value_counts()\nv=v.sort_values(ascending=True)\nfig, ax = plt.subplots(figsize=(12,8))\nv.plot(kind='barh')\nplt.show()","71440587":"japan=df.loc[(df['Country'] == 'Japan') & (df['Stars'] >= 4.5)]\nusa=df.loc[(df['Country'] == 'USA') & (df['Stars'] >= 4.5)]\nsouth_korea=df.loc[(df['Country'] == 'South Korea') & (df['Stars'] >= 4.5)]\nfig, axes = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n\n# TITLE\nfig.suptitle('TOP RAMEN BRANDS')\naxes[0].set_title('TOP 3 MOST PREFFERED RAMEN BRANDS IN JAPAN',fontsize=10)\naxes[1].set_title('TOP 3 MOST PREFFERED RAMEN BRANDS IN USA',fontsize=10)\naxes[2].set_title('TOP 3 MOST PREFFERED RAMEN BRANDS IN SOUTH KOREA',fontsize=10)\naxes[0].set_ylabel('PREFFERED TIMES', fontsize=10)\naxes[0].set_xlabel('BRANDS', fontsize=10)\naxes[1].set_ylabel('PREFFERED TIMES', fontsize=10)\naxes[1].set_xlabel('BRANDS', fontsize=10)\naxes[2].set_ylabel('PREFFERED TIMES', fontsize=10)\naxes[2].set_xlabel('BRANDS', fontsize=10)\n\n# JAPAN\nx_jp= japan['Brand'].value_counts()\nx_jp= x_jp[:3,]\nsns.barplot(ax=axes[0],x=x_jp.index, y=x_jp.values,palette=\"Paired\")\n\n# USA\nx_usa= usa['Brand'].value_counts()\nx_usa= x_usa[:3,]\nsns.barplot(ax=axes[1],x=x_usa.index,y= x_usa.values,palette=\"hls\")\n\n# SOUTH KOREA\nx_sk= south_korea['Brand'].value_counts()\nx_sk= x_sk[:3,]\nsns.barplot(ax=axes[2],x=x_sk.index,y= x_sk.values,palette=\"Paired\")\nplt.show()","5103b9c3":"# NISSIN\njn1=df.loc[(df['Country'] == 'Japan') & (df['Stars'] >= 4)& (df['Brand']=='Nissin')]\njn2=df.loc[(df['Country'] == 'Japan') & (df['Stars'] < 4)& (df['Brand']=='Nissin')]\ntotjnp=jn1['Review #'].sum()\ntotjnn=jn2['Review #'].sum()\nrev1 = totjnp,totjnn\n\n# MYOJO\njmy1=df.loc[(df['Country'] == 'Japan') & (df['Stars'] >= 4)& (df['Brand']=='Myojo')]\njmy2=df.loc[(df['Country'] == 'Japan') & (df['Stars'] < 4)& (df['Brand']=='Myojo')]\ntotmyp=jmy1['Review #'].sum()\ntotmyn=jmy2['Review #'].sum()\nrev2 = totmyp,totmyn\n\n# MARUCHAN\njma1=df.loc[(df['Country'] == 'Japan') & (df['Stars'] >= 4)& (df['Brand']=='Maruchan')]\njma2=df.loc[(df['Country'] == 'Japan') & (df['Stars'] < 4)& (df['Brand']=='Maruchan')]\ntotmap=jma1['Review #'].sum()\ntotman=jma2['Review #'].sum()\nrev3 = totmap,totman\nlabels = 'Above 4.0','Below 4.0'\ncolors = ['yellowgreen', 'lightskyblue']\nexplode = (0.1, 0) \nfig ,ax=plt.subplots(1,3,figsize=(15,15))\nax[0].pie(rev1, explode=explode, labels=labels, colors=colors,autopct='%1.1f%%')\nax[1].pie(rev2, explode=explode, labels=labels, colors=colors,autopct='%1.1f%%')\nax[2].pie(rev3, explode=explode, labels=labels, colors=colors,autopct='%1.1f%%')\nax[0].set_title('NISSIN',fontsize=10)\nax[1].set_title('MYOJO',fontsize=10)\nax[2].set_title('MARUCHAN',fontsize=10)\nplt.show()\njapan_b1=df.loc[(df['Country'] == 'Japan') & (df['Brand']=='Nissin')]\njapan_b2=df.loc[(df['Country'] == 'Japan') & (df['Brand']=='Myojo')]\njapan_b3=df.loc[(df['Country'] == 'Japan') & (df['Brand']=='Maruchan')]\nfig, axes = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\nfig.suptitle('Ratings Comparision')\naxes[0].set_title('NISSIN',fontsize=10)\naxes[1].set_title('MYOJO',fontsize=10)\naxes[2].set_title('MARUCHAN',fontsize=10)\nsns.countplot(ax=axes[0],x=\"Stars\", data=japan_b1, palette=\"muted\")\nsns.countplot(ax=axes[1],x=\"Stars\", data=japan_b2, palette=\"muted\")\nsns.countplot(ax=axes[2],x=\"Stars\", data=japan_b3, palette=\"muted\")\nplt.show()","2f857a8a":"#Nongshim \nub1=df.loc[(df['Country'] == 'USA') & (df['Stars'] >= 4)& (df['Brand']=='Nongshim')]\nusb1=df.loc[(df['Country'] == 'USA') & (df['Stars'] < 4)& (df['Brand']=='Nongshim')]\ntotub1=ub1['Review #'].sum()\ntotusb1=usb1['Review #'].sum()\nus1 = totub1,totusb1\n\n# NISSIN\nub2=df.loc[(df['Country'] == 'USA') & (df['Stars'] >= 4)& (df['Brand']=='Nissin')]\nusb2=df.loc[(df['Country'] == 'USA') & (df['Stars'] < 4)& (df['Brand']=='Nissin')]\ntotub2=ub2['Review #'].sum()\ntotusb2=usb2['Review #'].sum()\nus2 = totub2,totusb2\n\n#Yamachan\nub3=df.loc[(df['Country'] == 'USA') & (df['Stars'] >= 4.5)& (df['Brand']=='Yamachan')]\nusb3=df.loc[(df['Country'] == 'USA') & (df['Stars'] < 4.5)& (df['Brand']=='Yamachan')]\ntotub3=ub3['Review #'].sum()\ntotusb3=usb3['Review #'].sum()\nus3 = totub3,totusb3\nlabels = 'Above 4.0','Below 4.0'\nlabel1=\"Above 4.5\",\"Below 4.5\"\ncolors = ['yellowgreen', 'lightskyblue']\nexplode = (0.1, 0) \nfig ,ax=plt.subplots(1,3,figsize=(15,15))\nax[0].pie(us1, explode=explode, labels=labels, colors=colors,autopct='%1.1f%%')\nax[1].pie(us2, explode=explode, labels=labels, colors=colors,autopct='%1.1f%%')\nax[2].pie(us3, explode=explode, labels=label1, colors=colors,autopct='%1.1f%%')\nax[0].set_title('Nongshim',fontsize=15)\nax[1].set_title('NISSIN',fontsize=15)\nax[2].set_title('Yamachan',fontsize=15)\nplt.show()\nusa_b1=df.loc[(df['Country'] == 'USA') &  (df['Brand']=='Nongshim')]\nusa_b2=df.loc[(df['Country'] == 'USA') &  (df['Brand']=='Nissin')]\nusa_b3=df.loc[(df['Country'] == 'USA') &  (df['Brand']=='Yamachan')]\nfig, axes = plt.subplots(1, 3, figsize=(20, 5), sharey=True)\nfig.suptitle('Ratings Comparision')\naxes[0].set_title('NONGSHIM',fontsize=10)\naxes[1].set_title('NISSIN',fontsize=10)\naxes[2].set_title('YAMACHAN',fontsize=10)\nsns.countplot(ax=axes[0],x=\"Stars\", data=usa_b1, palette=\"muted\")\nsns.countplot(ax=axes[1],x=\"Stars\", data=usa_b2, palette=\"muted\")\nsns.countplot(ax=axes[2],x=\"Stars\", data=usa_b3, palette=\"muted\")\nplt.show()","8dade895":"# PALDO\nsk1=df.loc[(df['Country'] == 'South Korea') & (df['Stars'] >= 4)& (df['Brand']=='Paldo')]\nskb1=df.loc[(df['Country'] == 'South Korea') & (df['Stars'] < 4)& (df['Brand']=='Paldo')]\ntotsk1=sk1['Review #'].sum()\ntotskb1=skb1['Review #'].sum()\nrev1 = totsk1,totskb1\n\n# NONGSHIM\nsk2=df.loc[(df['Country'] == 'South Korea') & (df['Stars'] >= 4)& (df['Brand']=='Nongshim')]\nskb2=df.loc[(df['Country'] == 'South Korea') & (df['Stars'] < 4)& (df['Brand']=='Nongshim')]\ntotsk2=sk2['Review #'].sum()\ntotskb2=skb2['Review #'].sum()\nrev2 = totsk2,totskb2\n\n# SAMYANG FOODS\nsk3=df.loc[(df['Country'] == 'South Korea') & (df['Stars'] >= 4)& (df['Brand']=='Samyang Foods')]\nskb3=df.loc[(df['Country'] == 'South Korea') & (df['Stars'] < 4)& (df['Brand']=='Samyang Foods')]\ntotsk3=sk3['Review #'].sum()\ntotskb3=skb3['Review #'].sum()\nrev3 = totsk3,totskb3\nlabels = 'Above 4.0','Below 4.0'\ncolors = ['yellowgreen', 'lightskyblue']\nexplode = (0.1, 0) \nfig ,ax=plt.subplots(1,3,figsize=(15,15))\nax[0].pie(rev1, explode=explode, labels=labels, colors=colors,autopct='%1.1f%%')\nax[1].pie(rev2, explode=explode, labels=labels, colors=colors,autopct='%1.1f%%')\nax[2].pie(rev3, explode=explode, labels=labels, colors=colors,autopct='%1.1f%%')\nax[0].set_title('PALDO',fontsize=15)\nax[1].set_title('NONGSHIM',fontsize=15)\nax[2].set_title('SAMYANG FOODS',fontsize=15)\nplt.show()\nsouth_k_b1=df.loc[(df['Country'] == 'South Korea') & (df['Stars'] >= 4)& (df['Brand']=='Paldo')]\nsouth_k_b2=df.loc[(df['Country'] == 'South Korea') & (df['Stars'] >= 4)& (df['Brand']=='Nongshim')]\nsouth_k_b3=df.loc[(df['Country'] == 'South Korea') & (df['Stars'] >= 4)& (df['Brand']=='Samyang Foods')]\nfig, axes = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\nfig.suptitle('Ratings Comparision')\naxes[0].set_title('PALDO',fontsize=10)\naxes[1].set_title('NONGSHIM',fontsize=10)\naxes[2].set_title('SAMYANG FOODS',fontsize=10)\nsns.countplot(ax=axes[0],x=\"Stars\", data=south_k_b1, palette=\"muted\")\nsns.countplot(ax=axes[1],x=\"Stars\", data=south_k_b2, palette=\"muted\")\nsns.countplot(ax=axes[2],x=\"Stars\", data=south_k_b3, palette=\"muted\")\nplt.show()","c730b43b":"#### We see \"Nissin\" brand to be having the highest number of varities followed by \"Nongshim\" and \"Maruchan\" . ","a63f01fc":"This analysis is a team work by.\n1. Sujan Shirol (me)\n2. [Suhas](https:\/\/www.linkedin.com\/in\/suhasvs95\/)\n3. [Subhomoy Chattopadhyay](https:\/\/www.linkedin.com\/in\/subhomoy-chattopadhyay-8664b21b5\/)\n4. Yashovardhan T\n5. [Sonia Tripathi](https:\/\/www.linkedin.com\/in\/sonia-tripathi-400861178)\n6. [Shruthi M](https:\/\/www.linkedin.com\/in\/shruthi-m-989136116\/)","aee5ed42":"### Star Rating Analysis in USA","1c74589f":"#### We have a dataset containing the business statistics of the existing Ramen brands and their perfomance in the countries across the world. We will use this dataset in our analysis and try to arrive at a feasable business model.","0e995f5a":"#### Data Extracted from info() function:\n\n#### 1) Rows are 2580 and Columns are 7\n#### 2) There are 5 categorical columns and 2 numerical columns\n#### 3) Memory consumption: 141.2 KB","e127731e":"### Have you noticed that Japan, USA and South Korea are the top 3 consumers of Ramen?","b6398421":"#### Handling NaNs in Column \"Style\"","ad81c948":"### Star Rating Analysis in South Korea","74cf68d1":"#### Q) Number of varities in each brand?","e3eafb31":"#### \"Pack\" Style is most preferred with 59.6% and followed by \"Bowl\" and \"Cup\"(~18% each)","5e1b9b39":"### Tasks:\n\n\n\n\n\n\n### 1) Understanding the data\n### 2) Cleaning the data\n### 3) Visualising the data\n### 4) Analysing the data","ed5fc37e":"# Understanding the data","2875ca48":"#### Q) Most prefered Ramen style","243004bb":"### Star Rating Analysis in Japan","d97091ac":"#### Ramen is very popular and highly preferred in Asian countries like Japan,China,South korea etc. Exceptions are USA and UK. We can say that migration of people from Asian countries to USA and UK is high and that has resulted in high Ramen Consumption in those 2 countries.","ee95d7e2":"# Visualise and Analyse","a77494f6":"#### Q) What is the density distribution for the \"Stars\" of Ramen?","afb8152e":"Taking mean rating of specific brand from specific country from where it is mssing.\n\nBelow is the logic used which will be generalized with for loop in next cell.\n\nOttogi = df.loc[(df['Brand']=='Ottogi') & (df['Country']=='South Korea')]\n\ndf.loc[32,'Stars'] = round(Ottogi.Stars.mean(),2)\n\n\nSamyang = df.loc[(df['Brand']=='Samyang Foods') & (df['Country']=='South Korea')]\n\ndf.loc[122,'Stars'] = round(Samyang.Stars.mean(),2)\n\n\nMi = df.loc[(df['Brand']=='Mi E-Zee') & (df['Country']=='South Korea')]\n\ndf.loc[993,'Stars'] = Mi(Samyang.Stars.mean(),2)","8dbfcab9":"#### We see that column \"Style\" has <font color='orange'>2<\/font>, \"Stars\" has <font color='orange'>3<\/font>  and \"Top Ten\" has <font color='orange'>2543<\/font> NaNs. It is imperative that we handle these values before we jump in for EDA.","b29f39b6":"#### Handling NaNs in Column \"Stars\"","32908202":"#### Remember we had stored dummy value \"0\" to the NaNs of column \"Top Ten\". Let us see how we can handle it.","a1a5cf14":"# Cleaning the data ","7ff87a65":"### Let's analyse further....","d2cdc0af":"#### Q) What is the popularity of ramens across the countries?","ede5d334":"#### Top 3 most preferred brands in Japan, USA and South Korea?","cd2ed883":"#### The plot of density of \"Stars\" shows that it is \"Left Skewed\"."}}