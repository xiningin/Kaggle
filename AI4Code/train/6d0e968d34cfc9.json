{"cell_type":{"a3b04b33":"code","aad80cb1":"code","c3ecebf5":"code","d786faca":"code","f55a9a65":"code","aeb5bb88":"code","877694fe":"code","c18f2200":"code","2cf18508":"code","c74c8f61":"code","4e127a88":"code","4aeeb47b":"code","49fa374a":"code","329b8a22":"code","26329389":"code","196b2a27":"markdown","dfc121c3":"markdown"},"source":{"a3b04b33":"import re\nimport os\nfrom nltk.corpus import stopwords\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nstop_words = stopwords.words('english')\n\nla_words = ['los','angeles','city','california']\n\nfor word in la_words:\n    stop_words.append(word)\n\nfile_names = os.listdir(\"..\/input\/data-science-for-good-city-of-los-angeles\/cityofla\/CityofLA\/Job Bulletins\/\")\n\nfile_paths = []\n\nfor name in file_names:\n    file_paths.append(\"..\/input\/data-science-for-good-city-of-los-angeles\/cityofla\/CityofLA\/Job Bulletins\/\" + name)\n\nprint(file_paths[0:5])","aad80cb1":"full_text = {}\n\nbag_of_words = {}\n\nno_punct = re.compile(r'[\\?\\.\\,\\>\\<\\[\\]\\{\\(\\)\\'\\\"\\;\\:\\_\\-\\+\\=\\%\\#\\@\\!\\&\\*\\$\\^]')\nno_nums = re.compile(r'[0-9]+')\nfor path in file_paths:\n    with open(path,'r',encoding='ascii',errors='replace') as my_file:\n        temp = my_file.read()\n        full_text[path] = (temp)\n        temp = no_punct.sub(string=temp,repl='')\n        temp = no_nums.sub(string=temp,repl='')\n        for word in temp.lower().split():\n            if not word in stop_words:\n                if not word in bag_of_words.keys():\n                    bag_of_words[word] = 1\n                else:\n                    bag_of_words[word] += 1\n    my_file.close()","c3ecebf5":"bag_of_words_df = pd.DataFrame({'words': list(bag_of_words.keys()), 'count':list(bag_of_words.values())})","d786faca":"print(bag_of_words_df.describe())\nprint('median: '+ str(bag_of_words_df['count'].median()))","f55a9a65":"top_25 = bag_of_words_df.nlargest(25, 'count')\ntop_25","aeb5bb88":"sns.barplot(x='count',y='words',data = top_25)\nplt.title('Top 25 Most Frequent Words in Job Bulletins')\nplt.show()","877694fe":"path_to_remove = re.compile(r'..\/input\/cityofla\/CityofLA\/Job Bulletins\/|[0-9]+|\\.txt')\njob_bullitens = []\n\nfor job in full_text.keys():\n    job_bullitens.append(path_to_remove.sub(string=job,repl='').lower())\n\n\nfull_text_df = pd.DataFrame({'Job Bulletin':job_bullitens,'Job Bulletin Text':list(full_text.values())})","c18f2200":"full_text_df.head()\n","2cf18508":"\nfull_pdf_text = pd.read_csv('..\/input\/datascienceforgoodlapdftextuncleaned\/all_pdf_text.csv')\nprint(full_pdf_text.shape)\nfull_pdf_text = full_pdf_text.dropna()\nprint(full_pdf_text.shape)","c74c8f61":"full_text_pdf = list(full_pdf_text['pdf_text_all'])\nspaces = re.compile(r' {2,}|(\\uf0a7)')\npdf_bag_of_words = {}\nfor text in full_text_pdf:\n    text = spaces.sub(string = text, repl = ' ')\n    text = no_punct.sub(string=text,repl='')\n    text = no_nums.sub(string=text,repl='')\n    for word in text.lower().split():\n        if not word in stop_words:\n            if not word in pdf_bag_of_words.keys():\n                pdf_bag_of_words[word] = 1\n            else:\n                pdf_bag_of_words[word] += 1","4e127a88":"pdf_bag_of_words_df = pd.DataFrame({'words':list(pdf_bag_of_words.keys()), 'count':list(pdf_bag_of_words.values())})\npdf_top_25 = pdf_bag_of_words_df.nlargest(25, 'count')\npdf_top_25","4aeeb47b":"sns.barplot(x='count',y='words',data = pdf_top_25)\nplt.title('Top 25 Most Frequent Words in PDF Job Bulletins')\nplt.show()","49fa374a":"full_text_df.to_csv('job_bulletin_text.csv')\nbag_of_words_df.to_csv('from_txt_job_bulletins_bag_of_words.csv')\npdf_bag_of_words_df.to_csv('from_pdf_job_bulletins_bag_of_words.csv')","329b8a22":"sentences = []\nfor text in full_text.values():\n    temp = text.split('\\n\\n')\n    for line in temp:\n        temp2 = line.split('.')\n        for sent in temp2:\n            sent = sent.strip()\n            sentences.append(sent)\nlen(sentences)","26329389":"sentences = [i for i in sentences if i]\nlen(sentences)","196b2a27":"Thanks for reading... to be continued...","dfc121c3":"In the following you will find:\n\nAn attempt to understand the data as a whole with the bag of words method. \nA start to breaking the files down, by simply reading them in. \nData output from the bag of words (txt and pdf)\nVisualizations of the top 25 words used in all the txt and pdf files. \n\nEnjoy.\n\nAlso, please let me know what I can do better, improve my code, or if you like something you see, in the comments below."}}