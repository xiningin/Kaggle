{"cell_type":{"84335861":"code","af7506e1":"code","7b10eacf":"code","d7f9c682":"code","53161709":"code","824edd11":"code","6bf9d5bd":"code","414dd9d9":"code","17fe4a6a":"code","9fe6dca4":"code","6ca62192":"code","e789577d":"code","b5440703":"code","b8f60cec":"code","1ef220b1":"markdown","feb8e3cb":"markdown","c08b390d":"markdown"},"source":{"84335861":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","af7506e1":"!pip install -q --upgrade efficientnet tensorflow_addons","7b10eacf":"import math # \u6578\u5b78\u5957\u4ef6\nimport re # regular expression\nimport random \nimport os\nimport itertools #\u8fed\u4ee3\u5de5\u5177\nimport numpy as np\nimport pandas as pd\nimport matplotlib\nimport scipy\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport tensorflow.keras.backend as K\nimport efficientnet.tfkeras as efn\nimport efficientnet\nimport sklearn\n\nfrom matplotlib import pyplot as plt\nfrom datetime import datetime\n\n\n#checking the packages version\nprint(f'Numpy version : {np.__version__}')\nprint(f'Tensorflow version : {tf.__version__}')\nprint(f'Tensorflow Addons version : {tfa.__version__}')\nprint(f'EfficientNet (library) version : {efficientnet.__version__}')\nprint(f'Matplotlib version : {matplotlib.__version__}')\nprint(f'Scipy version : {scipy.__version__}')\nprint(f'Pandas version : {pd.__version__}')\nprint(f'Scikit-Learn version : {sklearn.__version__}')","d7f9c682":"PRE_TRaining_TIME_START = datetime.now()\nAUTO = tf.data.experimental.AUTOTUNE\n\nSEED = 42\n\nos.environ['PYTHONHASHSEED'] = str(SEED)\nrandom.seed(SEED)\nnp.random.seed(SEED)\n\nos.environ['TF_DETERMINSTIC_OPS'] = str(SEED)\ntf.random.set_seed(SEED)","53161709":"# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Runnign on TPU', tup.master())\nexcept ValueError:\n    tpu = None\n    \nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strtegy in Tesorflow. Works on CPU and sigle GPU\n    \nprint('REPLICAS: ', strategy.num_replicas_in_sync)","824edd11":"from kaggle_datasets import KaggleDatasets\nGCS_DS_PATH = KaggleDatasets().get_gcs_path()","6bf9d5bd":"!gsutil ls $GCS_DS_PATH","414dd9d9":"IMAGE_SIZE = [224, 224]\nEPOCHS = 12\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync","17fe4a6a":"# GCS_PATCH_SELECT = {\n#     PD: GCS_DS_PATH + '\/_DA_Product_Detection_'\n# }\n# GCS_PATH = GCS_PATH_SELECT[IMAGE_SIZE[0]]\n\nTRAINING_FILENAMES = tf.io.gfile.glob( '\/_DA_Product_Detection_\/train\/*.tfrecords')\n\nprint(len(TRAINING_FILENAMES))","9fe6dca4":"from kaggle_datasets import KaggleDatasets\nIMAGE_SIZE = (512, 512)\n\nGCS_TRAIN_PATHS = [\n    KaggleDatasets().get_gcs_path('..\/input\/kaggle\/shopee-code-league-20\/_DA_Product_Detection_\/train'),\n#     KaggleDatasets().get_gcs_path('tfrecords-2')\n]\nTRAINING_FILENAMES = []\nfor i in GCS_TRAIN_PATHS:\n    TRAINING_FILENAMES.append(tf.io.gfile.glob(i + '\/*.tfrecords'))\nTRAINING_FILENAMES = list(itertools.chain.from_iterable(TRAINING_FILENAMES))\n\nGCS_TEST_PATH = KaggleDatasets().get_gcs_path('tfrecords-3')\nTEST_FILENAMES = tf.io.gfile.glob(GCS_TEST_PATH + '\/*.tfrecords') # predictions on this dataset should be submitted for the competition\n\nprint(len(TRAINING_FILENAMES))\nprint(len(TEST_FILENAMES))","6ca62192":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","e789577d":"from kaggle_datasets import KaggleDatasets\nGCS_PATH = KaggleDatasets().get_gcs_path()","b5440703":"!gsutil ls $GCS_PATH","b8f60cec":"!ls \/kaggle\/input","1ef220b1":"## Detect TPU Availability","feb8e3cb":"## Configuration","c08b390d":"# \u74b0\u5883\u8a2d\u7f6e \n# Set seed and Preconfig"}}