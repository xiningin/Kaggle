{"cell_type":{"93755413":"code","785c5e76":"code","58d23557":"code","27c87015":"code","1a486d7b":"code","c5709da1":"code","cb05d9f3":"code","b9adfee1":"code","2af396d6":"code","e6a74990":"code","80bae0da":"code","b1c36ef4":"code","cc105d1e":"code","1e216df8":"markdown","ecc503a2":"markdown","11fcaeca":"markdown","ba194df9":"markdown","05c13098":"markdown","33e649d1":"markdown","2752b7b5":"markdown","36b7233c":"markdown"},"source":{"93755413":"import numpy as np\nimport pandas as pd\n\nimport os, shutil\nimport json\nfrom pathlib import Path\nimport sys\nfrom datetime import datetime\n\nimport torch.nn.functional as F\nfrom fastai.vision import *\nfrom fastai.utils.mod_display import *\nfrom torchvision import utils\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\nimport numpy as np\nfrom scipy import stats\nfrom sklearn import metrics\n\nfrom fastai.callbacks.hooks import *\nfrom fastai.utils.mem import *\nfrom fastai.utils.mod_display import *\n\nfrom PIL import Image","785c5e76":"kaggle_input_path = '\/kaggle\/input'\n\nkaggle_arc_path = '\/arc\/input'\n\n\nfor dirname, _, filenames in os.walk(kaggle_input_path):\n    print(dirname)","58d23557":"from pathlib import Path\n\ndata_path = Path(kaggle_input_path+'\/abstraction-and-reasoning-challenge\/')\ntraining_path = data_path \/ 'training'\nevaluation_path = data_path \/ 'evaluation'\ntest_path = data_path \/ 'test'","27c87015":"training_tasks = ['ce9e57f2', '868de0fa', 'b6afb2da', \n                  'db3e9e38', '3618c87e', 'bb43febb', \n                  '543a7ed5', '08ed6ac7', '6f8cd79b', \n                  'b1948b0a', '4258a5f9', '00d62c1b',\n                  '1bfc4729',\n                  '25ff71a9', '321b1fc6', '32597951',\n                  '36fdfd69', '3aa6fb7a', '3bdb4ada',\n                  '3befdf3e', '4093f84a', '444801d8',\n                  '4612dd53', '50cb2852', '60b61512',\n                  '67385a82', '6773b310', '694f12f3',\n                  '6c434453', '6cf79266', '6d75e8bb',\n                  '6e82a1ae']","1a486d7b":"cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25' ,'#FFFFFF'])\n\ncnorm = colors.Normalize(vmin=0, vmax=10) #vmax=9\n\ndef plot_task(taskname, train_idx=0, test_index=0, pred_imgs=[], max_train = -1):\n    \"\"\"\n    Plots the first train and test pairs of a specified task,\n    using same color scheme as the ARC app\n    \"\"\"\n    \n    # loading tasks\n    task_file = str(training_path \/ (taskname+'.json'))\n    with open(task_file, 'r') as f:\n        task = json.load(f)\n    \n    \n    if len(pred_imgs) == 0:\n        rows = 2\n    else:\n        rows = 4\n    \n    if max_train == -1:\n        # show all\n        max_train = len(task['train'])  \n    \n    fig, axs = plt.subplots(rows, (max_train+len(task['test']))*2, figsize=(15,2*rows))\n    offset = 0\n    for i in range(max_train):\n        axs[0, i*2].imshow(task['train'][i]['input'], cmap=cmap, norm=cnorm)\n        axs[0, i*2].axis('off')\n        axs[0, i*2].set_title('Train In '+str(i))\n        \n        im = Image.open(f'{kaggle_arc_path}\/temp\/input\/{taskname}\/train_{taskname}_'+str(i)+'.png')\n        axs[1, i*2].imshow(im, cmap=cmap, norm=cnorm)\n        axs[1, i*2].set_title('Train In '+str(i)+' image')\n        axs[1, i*2].axis('off')\n        \n        axs[0, i*2+1].imshow(task['train'][i]['output'], cmap=cmap, norm=cnorm)\n        axs[0, i*2+1].axis('off')\n        axs[0, i*2+1].set_title('Train Out '+str(i))\n        \n        im = Image.open(f'{kaggle_arc_path}\/temp\/output\/{taskname}\/train_{taskname}_'+str(i)+'.png')\n        axs[1, i*2+1].imshow(im, cmap=cmap, norm=cnorm)\n        axs[1, i*2+1].set_title('Train Mask '+str(i)+' image')\n        axs[1, i*2+1].axis('off')\n        \n        offset+=2\n        \n    for i in range(len(task['test'])):\n        j=i*2+offset\n        axs[0, j].imshow(task['test'][i]['input'], cmap=cmap, norm=cnorm)\n        axs[0, j].set_title('Valid In '+str(i))\n        axs[0, j].axis('off')\n        \n        im = Image.open(f'{kaggle_arc_path}\/temp\/input\/{taskname}\/valid_{taskname}_'+str(i)+'.png')\n        axs[1, j].imshow(im, cmap=cmap, norm=cnorm)\n        axs[1, j].set_title('Valid In '+str(i)+' img')\n        axs[1, j].axis('off')\n        \n        axs[0, j+1].imshow(task['test'][i]['output'], cmap=cmap, norm=cnorm)\n        axs[0, j+1].set_title('Valid Out '+str(i))\n        axs[0, j+1].axis('off')\n        \n        im = Image.open(f'{kaggle_arc_path}\/temp\/output\/{taskname}\/valid_{taskname}_'+str(i)+'.png')\n        axs[1, j+1].imshow(im, cmap=cmap, norm=cnorm)\n        axs[1, j+1].set_title('Valid Mask '+str(i)+' image')\n        axs[1, j+1].axis('off')\n    \n    if rows == 4:\n        for p, pred_img in enumerate(pred_imgs):\n            y = -2*(len(pred_imgs))+2*p+1\n            axs[2, y].imshow(pred_img, cmap=cmap, norm=cnorm)\n            axs[2, y].set_title('Pred img')\n            #for i in range(len(task['test'])+max_train*2):\n            #    axs[2, i ].axis('off')\n\n            rs_pred_img = resize_unpad(pred_img,task_info[taskname]['max_xy'],\n                                       np.round(task_info[taskname]['test_in_shapes'][p] * \n                                                task_info[taskname]['avg_train_shape_factor']).astype('uint8')\n                                      )\n            acc = metrics.accuracy_score(np.array(task['test'][p]['output']).reshape(1,-1)[0], rs_pred_img.reshape(1,-1)[0])\n        \n            axs[3, y].imshow(rs_pred_img, cmap=cmap, norm=cnorm)\n            axs[3, y].set_title(f'Pred img croped and rescaled (acc: {acc:.4f})')\n        \n        for i in range((len(task['test'])+max_train)*2):\n            axs[2, i].axis('off')\n            axs[3, i].axis('off')\n        \n        #acc = metrics.accuracy_score(np.array(task['test'][0]['output']).reshape(1,-1)[0], rs_pred_img.reshape(1,-1)[0])\n        #print(f\"Accuracy: {acc}\")\n                \n    plt.tight_layout()\n    plt.show()","c5709da1":"def task_sample_arr(taskname, test_train = 'train', in_out = 'input', idx = 0):\n    task_file = str(training_path \/ (taskname+'.json'))\n    with open(task_file, 'r') as f:\n        task = json.load(f)\n    \n    return np.array(task[test_train][idx][in_out])\n\n\ndef pad_to_xy(a, max_xy, color = 10):\n    \n    ''' Center and 0-pad np.array to max_xy-size '''\n\n    y, x = a.shape\n    (max_x, max_y) = max_xy \n    \n    y0 = (max_y-y)\/\/2 #0\n    y1 = (max_y-y)-(max_y-y)\/\/2 #max_xy[1]-y\n    x0 = (max_x-x)\/\/2 #0\n    x1 = (max_x-x)-(max_x-x)\/\/2 #max_xy[0]-x\n    \n    return np.pad(a, ((y0, y1), (x0, x1)), 'constant', constant_values=(color, color)) #F.pad(t, (0,max_xy[0]-x, 0, max_xy[1]-y), mode='constant')\n\n\ndef unpad_xy(img, max_xy=(16,16), org_xy=(15,15)):\n    x_start = (max_xy[0]-org_xy[1])\/\/2\n    x_end = x_start + org_xy[1]\n\n    y_start = (max_xy[1]-org_xy[0])\/\/2\n    y_end = y_start + org_xy[0]\n    \n    return img[y_start:y_end,x_start:x_end]\n\n\ndef resize_unpad(img, max_xy=(16,16), org_xy=(15,15)):\n    t=Image.fromarray(img.astype('uint8'))\n\n    t = np.asarray(t.resize(max_xy, Image.NEAREST))\n\n    return unpad_xy(t,max_xy,org_xy)","cb05d9f3":"def export_max_padded(task, taskname):\n    \n    ''' Get max x and max y size of all task images. \n        Center and pad task images to max size\n        Save arrays as images to \/temp folder.\n    '''\n    \n    os.makedirs(f'{kaggle_arc_path}\/temp\/input\/{taskname}')\n    os.makedirs(f'{kaggle_arc_path}\/temp\/output\/{taskname}')\n        \n    max_xy=(0,0)\n    max_x=0\n    max_y=0\n    \n    train_in=[]\n    train_out=[]\n    valid_in=[]\n    valid_out=[]\n    all_train_colors=[]\n    \n    num_train = 0\n    num_valid = 0\n    \n    # to array and get max_x, max_y\n    for i, tsk in enumerate(task['train']):\n        t = np.array(tsk['input']).astype('uint8')\n        train_in.append(t)\n        all_train_colors+=t.reshape(1,-1).tolist()\n        max_x = max(t.shape[1], max_x)\n        max_y = max(t.shape[0], max_y)\n        t = np.array(tsk['output']).astype('uint8')\n        train_out.append(t)\n        all_train_colors+=t.reshape(1,-1).tolist()\n        max_x = max(t.shape[1], max_x)\n        max_y = max(t.shape[0], max_y)\n        \n    for i, tsk in enumerate(task['test']):\n        t = np.array(tsk['input']).astype('uint8')\n        valid_in.append(t)\n        max_x = max(t.shape[1], max_x)\n        max_y = max(t.shape[0], max_y)\n        t = np.array(tsk['output']).astype('uint8')\n        valid_out.append(t)\n        max_x = max(t.shape[1], max_x)\n        max_y = max(t.shape[0], max_y)\n        \n        max_xy=(max([int(max_x\/\/0.7),16]), max([int(max_y\/\/0.7),16]))\n        #max_xy=(32,32)\n        #print(f'max_xy: {max_xy}')\n    \n    #flatten\n    all_train_colors = [i for lst in all_train_colors for i in lst]\n    \n    bgcolor = stats.mode(all_train_colors,axis=None)[0]  # 0\n    framecolor = bgcolor\n    \n    # pad and save\n    train_in_shapes = []\n    for i, t in enumerate(train_in):\n        train_in_shapes.append(t.shape)\n        tp = pad_to_xy(t, reversed(tuple(np.add(t.shape,(2,2)))), framecolor) # 0\n        tp = pad_to_xy(tp, max_xy) #t\n        im = Image.fromarray(tp)\n        im.save(f'{kaggle_arc_path}\/temp\/input\/{taskname}\/train_{taskname}_'+str(i)+'.png')\n        num_train += 1\n    train_out_shapes = []\n    for i, t in enumerate(train_out):\n        train_out_shapes.append(t.shape)\n        tp = pad_to_xy(t, reversed(tuple(np.add(t.shape,(2,2)))), framecolor)\n        tp = pad_to_xy(tp, max_xy)\n        im = Image.fromarray(tp)\n        im.save(f'{kaggle_arc_path}\/temp\/output\/{taskname}\/train_{taskname}_'+str(i)+'.png')\n        \n    valid_shapes = []\n    for i, t in enumerate(valid_in):\n        valid_shapes.append(t.shape)\n        tp = pad_to_xy(t, reversed(tuple(np.add(t.shape,(2,2)))), framecolor)\n        tp = pad_to_xy(tp, max_xy)\n        im = Image.fromarray(tp)\n        im.save(f'{kaggle_arc_path}\/temp\/input\/{taskname}\/valid_{taskname}_'+str(i)+'.png')\n        num_valid += 1\n    for i, t in enumerate(valid_out):\n        #print(f'shape of validation output: {t.shape}')\n        tp = pad_to_xy(t, reversed(tuple(np.add(t.shape,(2,2)))), framecolor)\n        tp = pad_to_xy(tp, max_xy)\n        im = Image.fromarray(tp)\n        im.save(f'{kaggle_arc_path}\/temp\/output\/{taskname}\/valid_{taskname}_'+str(i)+'.png')\n\n        \n    return {'num_train': num_train, \n            'num_test': num_valid, \n            'max_xy': max_xy, \n            'test_in_shapes': valid_shapes, # in shapes of test\n            'avg_train_shape_factor': np.mean(np.array(train_out_shapes)\/np.array(train_in_shapes), axis = 0), # avg factor for train in shape to train outshape \n            'bgcolor': bgcolor}\n","b9adfee1":"# create temp folder\nif  os.path.exists(kaggle_arc_path + '\/temp'):\n    shutil.rmtree(kaggle_arc_path + '\/temp');\n\nos.makedirs(kaggle_arc_path + '\/temp\/input')\nos.makedirs(kaggle_arc_path + '\/temp\/output')\n\n# create temp folder\n#if  os.path.exists(kaggle_input_path + '\/temp'):\n#    shutil.rmtree(kaggle_input_path + '\/temp');\n\n#os.makedirs(kaggle_input_path + '\/temp\/input')\n#os.makedirs(kaggle_input_path + '\/temp\/output')\n\ntask_info={}\n\nfor i, taskname in enumerate(training_tasks):\n    # loading tasks\n    task_file = str(training_path \/ (taskname+'.json'))\n    with open(task_file, 'r') as f:\n        task = json.load(f)\n    \n    # save train and validation arrays as images\n    # all images are padded to the max x and y size of the current task arrays\n    num_tt = export_max_padded(task, taskname)\n    task_info[taskname] = num_tt\n    #print(f'Task info: {task_info}')\n    ## show an example\n    if i==0:\n        print(str(i)+'. Example task '+taskname + ':')\n        plot_task(taskname)#, max_train=2)\n\nplt.show() ","2af396d6":"get_y_fn = lambda x: f'{kaggle_arc_path}\/temp\/output\/{x.stem.split(\"_\")[1]}\/{x.stem}{x.suffix}'\n    \ndef data(task = training_tasks[0]):\n    return (SegmentationItemList.from_folder(f'{kaggle_arc_path}\/temp\/input\/{task}')\n        #.split_by_idx(valid_idx=[i for i in range(len(task['train']), len(task['train'])+len(task['test']))])\n        .split_by_files(valid_names = [f'valid_{task}_{i}.png' for i in range(task_info[task]['num_test'])])\n        .label_from_func(get_y_fn, classes = np.array([str(i) for i in range(11)])) #range(10)\n        .transform(get_transforms(), tfm_y=True, size=256, padding_mode = 'border')  #256\n        .databunch(bs=1)\n        .normalize(imagenet_stats)\n       )\n","e6a74990":"# Example\n#data(training_tasks[0]).show_batch(rows=2, figsize=(6, 6), alpha=1) #, cmap=cmap, norm=cnorm)","80bae0da":"\nclass SAI(nn.Module):\n    ''' SelfAttention with Identity '''\n    \n    def __init__(self, nf):\n        super(SAI, self).__init__()\n        \n        self.sa = PooledSelfAttention2d(nf)\n        self.bn = nn.BatchNorm2d(nf)\n        self.do = nn.Dropout(0.4)\n        \n        \n    def forward(self, x):\n        ident = x\n        out = self.sa(x)\n        out = ident + out\n        \n        out = self.do(self.bn(out)) #\n        \n        return out\n","b1c36ef4":"def learn(task = training_tasks[0], epochs = 150, runs = 2, lr = 5e-5):\n    print(f'Task {task} start..')\n    lrn = unet_learner(data(task), models.resnet18, blur = True, bottle = True) #, wd=1e-3 #bottle off\n    \n    lrn.model[0][4].add_module('sai0_4', SAI(64)) \n    lrn.model[0][5].add_module('sai0_5', SAI(128))\n\n    lrn.model[7].shuf.blur.add_module('sai7', SAI(512)) \n    lrn.model[8].blur.add_module('sai8', SAI(384)) \n    \n    lrn.model = lrn.model.cuda()\n        \n    for i in range(runs):\n        # Disable progressbar from https:\/\/forums.fast.ai\/t\/how-to-run-without-progress-bar\/29875\/6\n        with progress_disabled_ctx(lrn) as lrn:\n            lrn.fit_one_cycle(epochs, slice(lr))\n        print(f'run #{i} done')\n  \n    return lrn","cc105d1e":"%%time\nmeasures = []\n\nfor taskname in training_tasks:\n    try:\n        l = learn(taskname, epochs = 150, runs = 2, lr = 5e-5) #e150 r2\n        t = l.TTA(ds_type=DatasetType.Valid, beta=0.7) # l.get_preds(ds_type=DatasetType.Valid) #\n            \n        ## loop over all predictions\n        pred_imgs=[]\n        acc_avg = 0\n        for p in range(t[0].shape[0]):\n            pred_img = t[0][p].numpy().argmax(axis = 0)\n            pred_imgs.append(pred_img)\n            # zoom to expected size\n            rs_pred_img = resize_unpad(pred_img,task_info[taskname]['max_xy'],\n                                       np.round(task_info[taskname]['test_in_shapes'][p] * \n                                                task_info[taskname]['avg_train_shape_factor']).astype('uint8'))\n            \n            # evaluate\n            y_img = task_sample_arr(taskname, test_train = 'test', in_out = 'output', idx = p).reshape(1,-1)[0]\n            y_hat_img = rs_pred_img.reshape(1,-1)[0]\n            \n            acc = metrics.accuracy_score(y_img, y_hat_img)\n            print(f\"Accuracy {taskname}_{p}: {acc}\")\n            \n            acc_avg = (acc_avg * (p) + acc) \/ (p+1)\n        \n        measures += [[taskname , round(acc_avg, 4)]]\n        plot_task(taskname, pred_imgs=pred_imgs, max_train = 2)\n        \n    except:\n        measures += [[taskname , np.nan]]\n        plt.show()\n        print('Exception occured!')\n\npd.DataFrame(measures, columns=['taskname', 'accuracy_unet']).to_csv(f'evaluation_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.csv', index = False)\n\nprint('Done !')","1e216df8":"## Functions to prepare task images\n\nFor convenience the arrays are safed as images, so that the Fastai Dataloader for Segmentation can easily be applied without modification.","ecc503a2":"This notebook is a Fork of https:\/\/www.kaggle.com\/inversion\/abstraction-and-reasoning-starter-notebook.\n# [ARC] Exploring with UNet\nThe assumption in this notebook is that some of the task can be tackled like an Segemntation task, where `output` behaves like a mask with 10 categories. Therefore I try to apply a unet to check this assumption.\n\nThe given tasks in the json files are split into `train` and `test` arrays. My validation set is build upon the `test` arrays, so I'll refere to them as `valid` throughout the notebook.  \n\n## Credits\nElements of this notebooks are taken from:\n\n- Function to plot task, loading tasks: https:\/\/www.kaggle.com\/inversion\/abstraction-and-reasoning-starter-notebook\n\nPlease visit the notebooks and upvote if you like them.","11fcaeca":"## Function to plot task\nModified version of plot_task from https:\/\/www.kaggle.com\/inversion\/abstraction-and-reasoning-starter-notebook.\nAdded white (#FFFFFF) as additional color to fill borders.","ba194df9":"# Prepare images","05c13098":"## Data\nSince there are only view train samples, augmentation is used to generate more samples with increasing sice of epochs.","33e649d1":"# Modeling\nApplying the UNet basicly follows the tutorial (https:\/\/github.com\/fastai\/course-v3\/blob\/master\/nbs\/dl1\/lesson3-camvid.ipynb). ","2752b7b5":"## Model\nThe pretrained model gets extended by a SelfAttention-Block (see Module SAI), which works in this experiment better then the one which could be activated as a learner parameter.","36b7233c":"The `training` folder has 400 JSON tasks. `training_tasks` lists some of them."}}