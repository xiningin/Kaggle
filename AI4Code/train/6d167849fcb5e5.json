{"cell_type":{"0c279d1d":"code","c2ffc555":"code","c70409e5":"code","e15a1b6f":"code","84677ca6":"code","e9e5bd66":"code","2f4e6dfb":"code","d326196e":"code","67f0030a":"code","374c69aa":"code","5b2caa87":"code","6f104a7d":"code","171f1396":"code","06f53c64":"code","4b830b59":"code","6a417d92":"code","611636b4":"code","deae2d9e":"code","95318a74":"code","96da44e8":"code","18713121":"code","cd3d3895":"code","8e7605ae":"code","76ffd40e":"code","d1b47026":"code","2264215f":"code","ab34327d":"code","0d743e85":"code","6d75c06e":"markdown","3eccf3cd":"markdown","1cda6172":"markdown","673af957":"markdown","a94d6501":"markdown","2ceb7820":"markdown","134b7855":"markdown"},"source":{"0c279d1d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\nimport time\n\nimport matplotlib.pyplot as plt\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c2ffc555":"from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\ndata_generator = ImageDataGenerator(rescale=1.\/255.,validation_split=0.2,\n                                   featurewise_center=True,\n        samplewise_center=True,\n        featurewise_std_normalization=True,\n        samplewise_std_normalization=True,\n        rotation_range=20,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.15,\n        zoom_range=0.15,\n        fill_mode=\"nearest\",\n        horizontal_flip=True,\n        vertical_flip=True\n                        )\ntrain_generator = data_generator.flow_from_directory(directory= '..\/input\/cough-detection\/melspectrograms\/training',             \n                                                     target_size=(224, 224),\n                                                     class_mode='binary',\n                                                     subset='training',\n                                                     shuffle=True,\n                                                     seed=2,\n                                                     batch_size=32,\n                                                     color_mode='rgb'\n                                                     )\n\nvalid_generator = data_generator.flow_from_directory(directory= '..\/input\/cough-detection\/melspectrograms\/testing',\n                                                     target_size=(224, 224),\n                                                     class_mode='binary',\n                                                     subset='validation',\n                                                     shuffle=True,\n                                                     batch_size=32,\n                                                     color_mode='rgb'\n                                                    )\n\nclasses = ['cough', 'no_cough']","c70409e5":"plt.figure(figsize=(10,10))\nplt.subplot(2,2,1)\nplt.bar(classes, train_generator.labels.sum(axis = 0)\/train_generator.n * 100)\nplt.title('On training set')\nplt.subplot(2,2,2)\nplt.bar(classes, valid_generator.labels.sum(axis = 0)\/valid_generator.n * 100, color='rgb')\nplt.title('On validation set')","e15a1b6f":"sample_training_images, _ = next(train_generator)","84677ca6":"def plotImages(images_arr):\n    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n    labels = sample_training_images\n    axes = axes.flatten()\n    for img, ax in zip(images_arr, axes):\n        ax.imshow(img)\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()","e9e5bd66":"plotImages(sample_training_images[:5])","2f4e6dfb":"model = tf.keras.models.Sequential()\nmodel.add(MobileNetV2(include_top=False, pooling='avg', weights='imagenet', input_shape=(224, 224, 3), classes=2))\nmodel.add(Dense(2, activation='softmax'))\nmodel.layers[0].trainable = False\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])","d326196e":"callbacks = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy', patience = 2)\nhistory = model.fit_generator(train_generator,\n                              steps_per_epoch = len(train_generator),\n                              epochs=10,\n                              validation_steps = len(valid_generator),\n                              validation_data=valid_generator,\n                              callbacks = [callbacks]\n                              )","67f0030a":"def visualize_training(history, lw = 3):\n    plt.figure(figsize=(10,6))\n    plt.plot(history.history['accuracy'], label = 'training', marker = '*', linewidth = lw)\n    plt.plot(history.history['val_accuracy'], label = 'validation', marker = 'o', linewidth = lw)\n    plt.title('Training Accuracy vs Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend(fontsize = 'x-large')\n    plt.show()\n\n    plt.figure(figsize=(10,6))\n    plt.plot(history.history['loss'], label = 'training', marker = '*', linewidth = lw)\n    plt.plot(history.history['val_loss'], label = 'validation', marker = 'o', linewidth = lw)\n    plt.title('Training Loss vs Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend(fontsize = 'x-large')\n    plt.show()\nvisualize_training(history)","374c69aa":"preds = model.predict_generator(valid_generator,steps=15)","5b2caa87":"label = valid_generator.classes","6f104a7d":"pred= model.predict(valid_generator)\npredicted_class_indices=np.argmax(pred,axis=1)\nlabels = (valid_generator.class_indices)\nlabels2 = dict((v,k) for k,v in labels.items())\npredictions = [labels2[k] for k in predicted_class_indices]\nprint(predicted_class_indices)\nprint (labels)\nprint (predictions)","171f1396":"image_path = '..\/input\/cough-detection\/melspectrograms\/testing\/cough\/1-63679-A-24.png'\nimage = tf.keras.preprocessing.image.load_img(image_path)\ninput_arr = tf.keras.preprocessing.image.img_to_array(image)\ninput_arr = np.array([input_arr])  # Convert single image to a batch.\npredictions = model.predict(input_arr)","06f53c64":"# #Loading CSV file\n# train_csv = pd.read_csv(\"..\/input\/coughclassifier-trial\/cough_trial_extended.csv\")\n# dataset = \"..\/input\/coughclassifier-trial\/cough_trial_extended.csv\"\n\n# cmap = plt.get_cmap('inferno')\n# tot_rows = train_csv.shape[0]\n# for i in range(tot_rows):\n#     source = train_csv['file_properties'][i]\n#     filename = '..\/input\/coughclassifier-trial\/trial_covid\/'+source\n#     y,sr = librosa.load(filename, mono=True, duration=5)\n#     plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n#     plt.axis('off');\n#     plt.savefig(f'.\/{source[:-3].replace(\".\", \"\")}.png')\n#     plt.clf()","4b830b59":"import librosa\nimport librosa.display\nfrom pydub import AudioSegment\nimport matplotlib.pyplot as plt\nfrom scipy.io import wavfile\nfrom tempfile import mktemp\n\ndef plot_mp3_matplot(filename):\n    \"\"\"\n    plot_mp3_matplot -- using matplotlib to simply plot time vs amplitude waveplot\n    \n    Arguments:\n    filename -- filepath to the file that you want to see the waveplot for\n    \n    Returns -- None\n    \"\"\"\n    \n    # sr is for 'sampling rate'\n    # Feel free to adjust it\n    x, sr = librosa.load(filename, sr=44100)\n    plt.figure(figsize=(14, 5))\n    librosa.display.waveplot(x, sr=sr)\n\ndef convert_audio_to_spectogram(filename):\n    \"\"\"\n    convert_audio_to_spectogram -- using librosa to simply plot a spectogram\n    \n    Arguments:\n    filename -- filepath to the file that you want to see the waveplot for\n    \n    Returns -- None\n    \"\"\"\n    \n    # sr == sampling rate \n    x, sr = librosa.load(filename, sr=44100)\n    \n    # stft is short time fourier transform\n    X = librosa.stft(x)\n    \n    # convert the slices to amplitude\n    Xdb = librosa.amplitude_to_db(abs(X))\n    \n    # ... and plot, magic!\n    plt.figure(figsize=(14, 5))\n    librosa.display.specshow(Xdb, sr = sr, x_axis = 'time', y_axis = 'hz')\n    plt.colorbar()\n    \n# same as above, just changed the y_axis from hz to log in the display func    \ndef convert_audio_to_spectogram_log(filename):\n    x, sr = librosa.load(filename, sr=44100)\n    X = librosa.stft(x)\n    Xdb = librosa.amplitude_to_db(abs(X))\n    plt.figure(figsize=(14, 5))\n    librosa.display.specshow(Xdb, sr = sr, x_axis = 'time', y_axis = 'log')\n    plt.colorbar()    ","6a417d92":"convert_audio_to_spectogram_log('..\/input\/covid-cough-wavs\/cleaned_data\/Positive\/1041_Positive_male_39.wav')","611636b4":"# Convert new audio recording to MelSpectogram\n%matplotlib inline\nimport librosa\ncmap = plt.get_cmap('inferno')\nsource = '..\/input\/covid-cough-wavs\/cleaned_data\/Positive\/1066_Positive_male_23.wav'\nfilname = '..\/input\/covid-cough-wavs\/cleaned_data\/Positive'\nfilename = source\ny,sr = librosa.load(filename, mono=True)\nplt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n#plt.axis('off');\n#plt.savefig(f'source1.png')\nplt.savefig('foo1.png')\nplt.clf()","deae2d9e":"predictions","95318a74":"image_path = 'foo1.png'\nimage = tf.keras.preprocessing.image.load_img(image_path)\ninput_arr = tf.keras.preprocessing.image.img_to_array(image)\ninput_arr = np.array([input_arr])  # Convert single image to a batch.\npredictions1 = model.predict(input_arr)","96da44e8":"predictions1","18713121":"image_path = '..\/input\/cough-detection\/melspectrograms\/training\/no_cough\/1-100038-A-14.png'\nimage = tf.keras.preprocessing.image.load_img(image_path)\ninput_arr = tf.keras.preprocessing.image.img_to_array(image)\ninput_arr = np.array([input_arr])  # Convert single image to a batch.\npredictions_nocough = model.predict(input_arr)","cd3d3895":"predictions_nocough","8e7605ae":"from sklearn.metrics import confusion_matrix, classification_report, roc_curve\n\nrc = roc_curve(predicted_class_indices,label)\ncf_matrix = confusion_matrix(predicted_class_indices,label)\ncf_report = classification_report(predicted_class_indices,label)\nprint('Confusion matrix report of the model : \\n{}'.format(cf_matrix))","76ffd40e":"exp_series = pd.Series(label)\npred_series = pd.Series(predicted_class_indices)\npd.crosstab(exp_series, pred_series, rownames=['Actual'], colnames=['Predicted'],margins=True)","d1b47026":"print('Classification report of the model : \\n{}'.format(cf_report))","2264215f":"t = time.time()\nsave_path = '.'\nmodel_json = model.to_json()\nwith open(os.path.join(save_path,\"network.json\"), \"w\") as json_file:\n    json_file.write(model_json)\n\n# save neural network structure to YAML (no weights)\nmodel_yaml = model.to_yaml()\nwith open(os.path.join(save_path,\"network.yaml\"), \"w\") as yaml_file:\n    yaml_file.write(model_yaml)\n\n# save entire network to HDF5 (save everything, suggested)\nmodel.save(os.path.join(save_path,\"network.h5\"))","ab34327d":"!ls","0d743e85":"from tensorflow.keras.models import load_model\nmodel2 = load_model(os.path.join(save_path,\"network.h5\"))\npred = model2.predict(input_arr)\npred","6d75c06e":"# Data Visualization","3eccf3cd":"# Saving Model","1cda6172":"# Data Augmentation","673af957":"# Predictions","a94d6501":"# Loading the Saved Model and Predictions","2ceb7820":"# Predicting Non Cough samples","134b7855":"# Loading Libraries"}}