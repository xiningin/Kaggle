{"cell_type":{"8296539e":"code","a1d02daf":"code","2bff4db5":"code","c22ca49b":"code","1c382e72":"code","3d0ead34":"code","d80b0d69":"code","6dfce4bc":"code","6e2893d1":"code","df6f9765":"code","9da45d47":"code","e53833bb":"markdown","5c16bf5b":"markdown","02056127":"markdown","1410bff4":"markdown","8eb37f09":"markdown","9b88b033":"markdown","484bd931":"markdown","97ec0608":"markdown","721e8a38":"markdown","3710bfaa":"markdown","996a3472":"markdown","b59c7ce7":"markdown","dae036e4":"markdown","3e331967":"markdown"},"source":{"8296539e":"from keras.models import Sequential\nfrom keras.layers.convolutional import Conv3D\nfrom keras.layers.convolutional_recurrent import ConvLSTM2D\nfrom keras.layers.normalization import BatchNormalization\nimport numpy as np\nimport pylab as plt","a1d02daf":"seq = Sequential()\n\nseq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n                   input_shape=(None, 40, 40, 1),\n                   padding='same', return_sequences=True))\nseq.add(BatchNormalization())\n\nseq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n                   padding='same', return_sequences=True))\nseq.add(BatchNormalization())\n\nseq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n                   padding='same', return_sequences=True))\nseq.add(BatchNormalization())\n\nseq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n                   padding='same', return_sequences=True))\nseq.add(BatchNormalization())\n\nseq.add(Conv3D(filters=1, kernel_size=(3, 3, 3),\n               activation='sigmoid',\n               padding='same', data_format='channels_last'))\nseq.compile(loss='binary_crossentropy', optimizer='adadelta')","2bff4db5":"seq.summary()","c22ca49b":"def generate_movies(n_samples=1200, n_frames=15):\n    row = 80\n    col = 80\n    noisy_movies = np.zeros((n_samples, n_frames, row, col, 1), dtype=np.float)\n    shifted_movies = np.zeros((n_samples, n_frames, row, col, 1),\n                              dtype=np.float)\n\n    for i in range(n_samples):\n        # Add 3 to 7 moving squares\n        n = np.random.randint(3, 8)\n\n        for j in range(n):\n            # Initial position\n            xstart = np.random.randint(20, 60)\n            ystart = np.random.randint(20, 60)\n            # Direction of motion\n            directionx = np.random.randint(0, 3) - 1\n            directiony = np.random.randint(0, 3) - 1\n\n            # Size of the square\n            w = np.random.randint(2, 4)\n\n            for t in range(n_frames):\n                x_shift = xstart + directionx * t\n                y_shift = ystart + directiony * t\n                noisy_movies[i, t, x_shift - w: x_shift + w,\n                             y_shift - w: y_shift + w, 0] += 1\n\n                # Make it more robust by adding noise.\n                # The idea is that if during inference,\n                # the value of the pixel is not exactly one,\n                # we need to train the network to be robust and still\n                # consider it as a pixel belonging to a square.\n                if np.random.randint(0, 2):\n                    noise_f = (-1)**np.random.randint(0, 2)\n                    noisy_movies[i, t,\n                                 x_shift - w - 1: x_shift + w + 1,\n                                 y_shift - w - 1: y_shift + w + 1,\n                                 0] += noise_f * 0.1\n\n                # Shift the ground truth by 1\n                x_shift = xstart + directionx * (t + 1)\n                y_shift = ystart + directiony * (t + 1)\n                shifted_movies[i, t, x_shift - w: x_shift + w,\n                               y_shift - w: y_shift + w, 0] += 1\n\n    # Cut to a 40x40 window\n    noisy_movies = noisy_movies[::, ::, 20:60, 20:60, ::]\n    shifted_movies = shifted_movies[::, ::, 20:60, 20:60, ::]\n    noisy_movies[noisy_movies >= 1] = 1\n    shifted_movies[shifted_movies >= 1] = 1\n    return noisy_movies, shifted_movies","1c382e72":"noisy_movies, shifted_movies = generate_movies(n_samples=1200)","3d0ead34":"noisy_movies.shape, shifted_movies.shape","d80b0d69":"%%time\nseq.fit(noisy_movies[:1000], shifted_movies[:1000], batch_size=10,\n        epochs=5, validation_split=0.05)","6dfce4bc":"which = 1004\ntrack = noisy_movies[which][:7, ::, ::, ::]","6e2893d1":"track.shape, track[np.newaxis, ::, ::, ::, ::].shape","df6f9765":"for j in range(16):\n    new_pos = seq.predict(track[np.newaxis, ::, ::, ::, ::]) # (1, 7, 40, 40, 1)\n    new = new_pos[::, -1, ::, ::, ::] # (1, 40, 40, 1)\n    track = np.concatenate((track, new), axis=0) # adds +1 to the first dimension in each loop cycle","9da45d47":"track2 = noisy_movies[which][::, ::, ::, ::]\n\nfor i in range(15):\n    fig = plt.figure(figsize=(10, 5))\n\n    ax = fig.add_subplot(121)\n\n    if i >= 7:\n        ax.text(1, 3, 'Predictions !', fontsize=20, color='w')\n    else:\n        ax.text(1, 3, 'Initial trajectory', fontsize=20)\n\n    toplot = track[i, ::, ::, 0]\n\n    plt.imshow(toplot)\n    ax = fig.add_subplot(122)\n    plt.text(1, 3, 'Ground truth', fontsize=20)\n\n    toplot = track2[i, ::, ::, 0]\n    if i >= 2:\n        toplot = shifted_movies[which][i - 1, ::, ::, 0]\n\n    plt.imshow(toplot)\n    plt.savefig('%i_animate.png' % (i + 1))","e53833bb":"Generate movies with 3 to 7 moving squares inside.\n\nThe squares are of shape 1x1 or 2x2 pixels, which move linearly over time.\n\nFor convenience we first create movies with bigger width and height (80x80) and at the end we select a 40x40 window.","5c16bf5b":"`(batch_size, time_steps, height, width, filters (layers)`","02056127":"Let's check the dimensions of the following array to better understand what's going on here.\n\n`track` has the shape of 7 frames 40\\*40 with one channel. `np.newaxis` adds additional axis so the array can be accepted by the `seq` model.","1410bff4":"## Train the network","8eb37f09":"Feed it with the first 7 positions and then predict the new positions","9b88b033":"# ConvLSTM Expl: Convolutional LSTM Network Tutorial","484bd931":"### This notebook demonstrates the use of a convolutional LSTM network.","97ec0608":"## Model","721e8a38":"## Testing the network on one movie","3710bfaa":"## Artificial data generation","996a3472":"## Compare the predictions to the ground truth","b59c7ce7":"We create a layer which take as input movies of shape `(n_frames, width, height, channels)` and returns a movie of identical shape.","dae036e4":"This network is used to predict the next frame of an artificially\ngenerated movie which contains moving squares.","3e331967":"## Imports"}}