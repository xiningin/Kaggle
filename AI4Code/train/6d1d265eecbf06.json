{"cell_type":{"f0b6bfeb":"code","258fe40f":"code","df411573":"code","f185ec50":"code","70f2f051":"code","3ac2502b":"code","2055499f":"code","2e36d809":"code","45512959":"code","47a30e9a":"code","59f0385e":"code","775c833c":"code","37cf2a3f":"code","49827453":"code","75ec9dd9":"code","d3a30998":"code","1e62a539":"code","ae723372":"code","2bf3a6e6":"code","045253c7":"code","cd1f10f4":"code","ebd67a7a":"code","310b2d6f":"code","6dc98766":"code","226d7a27":"code","9338e31c":"code","734a2c64":"code","aa2e6a02":"code","7fa7b388":"code","5008feb6":"markdown","46209125":"markdown","119c69df":"markdown","749e4d70":"markdown","fe0846b3":"markdown","c601e511":"markdown","37abc4b5":"markdown","23ab2b25":"markdown","edbeb107":"markdown","c185e99c":"markdown","35c3d25d":"markdown","6e8153fb":"markdown","084b96c1":"markdown","b506e012":"markdown","ab9db05a":"markdown","b09d837a":"markdown","ebd59efb":"markdown","ae6e98de":"markdown","e3a5ec6d":"markdown","247369c0":"markdown"},"source":{"f0b6bfeb":"import torch\nfrom torch.autograd import Variable\nimport torch as tch\nimport torch.nn as nn\nimport numpy as np\nfrom sklearn.datasets import make_blobs\nfrom matplotlib import pyplot\n\ndef forward(x):\n    return x * w\n\nw = Variable(torch.Tensor([1.0]), requires_grad=True)\n# . On setting .requires_grad = True they start forming a backward graph\n# that tracks every operation applied on them to calculate the gradients\n# using something called a dynamic computation graph (DCG)\n# When you finish your computation you can call .backward() and have\n# all the gradients computed automatically. The gradient for this tensor\n# will be accumulated into .grad attribute.\n\n# Now create an array of data.\n# By PyTorch\u2019s design, gradients can only be calculated\n# for floating point tensors which is why I\u2019ve created a float type\n# array before making it a gradient enabled PyTorch tensor\nx_data = [11.0, 22.0, 33.0]\ny_data = [21.0, 14.0, 64.0]\n\ndef loss_function(x, y):\n    y_pred = forward(x)\n    return (y_pred - y) * (y_pred - y)\n\n\n# Now running the training loop\nfor epoch in range(10):\n    for x_val, y_val in zip(x_data, y_data):\n        l = loss_function(x_val, y_val)\n        l.backward()\n        print(\"\\tgrad: \", x_val, y_val, w.grad.data[0])\n        w.data = w.data - 0.01 * w.grad\n\n        # Manually set the gradient to zero after updating weights\n        w.grad.data.zero_()\n\n        print('progress: ', epoch, l.data[0])","258fe40f":"torch.bernoulli(torch.Tensor(4, 4).uniform_(0, 1))\n","df411573":"sample_tensor = torch.Tensor([10, 10, 13, 10, 34,45,65,67,87,89,87,34])\ntorch.multinomial(torch.tensor([10., 10., 13., 10., 34., 45., 65., 67., 87., 89., 87., 34.]), 3)","f185ec50":"torch.multinomial(torch.tensor([10., 10., 13., 10., 34., 45., 65., 67., 87., 89., 87., 34.]), 5, replacement=True)","70f2f051":"torch.normal(mean=torch.arange(1., 11), std=torch.arange(1, 0, -0.1))","3ac2502b":"torch.normal(mean=0.5, std=torch.arange(1.,6.))","2055499f":"torch.normal(mean=0.5, std=torch.arange(0.2, 0.6))\n","2e36d809":"from torch.autograd import Variable\nVariable(torch.ones(2,2), requires_grad=True)\n","45512959":"a, b = 12, 23\nx1 = Variable(torch.randn(a, b), requires_grad=True )\nx2 = Variable(torch.randn(a,b), requires_grad=True)\nx3 = Variable(torch.randn(a,b), requires_grad=True)","47a30e9a":"c = x1 * x2\nd = a + x3\ne = torch.sum(d)\n\ne.backward()\n\nprint(e)","59f0385e":"x1.data","775c833c":"x2.data","37cf2a3f":"x3.data","49827453":"torch.__version__","75ec9dd9":"torch.tensor","d3a30998":"#height of people\nt_c = torch.tensor([58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0])\n\n#weight of people\nt_u = torch.tensor([115.0, 117.0, 120.0, 123.0, 126.0, 129.0, 132.0, 135.0, 139.0, 142.0, 146.0, 150.0, 154.0, 159.0,164.0])\n\n","1e62a539":"def model(t_u, w, b):\n    return w * t_u + b\n  \ndef loss_fn(t_p, t_c):\n    squared_diffs = (t_p - t_c)**2\n    return squared_diffs.mean()\n  \nw = torch.ones(1)\nb = torch.zeros(1)\n\nt_p = model(t_u, w, b)\nt_p","ae723372":"loss = loss_fn(t_p, t_c)\nloss","2bf3a6e6":"delta = 0.1\n\nloss_rate_of_change_w = (loss_fn(model(t_u, \n                                       w + delta, b), \n                                 t_c) - loss_fn(model(t_u, w - delta, b), \n                                                t_c)) \/ (2.0 * delta)","045253c7":"learning_rate = 1e-2\n\nw = w - learning_rate * loss_rate_of_change_w","cd1f10f4":"loss_rate_of_change_b = (loss_fn(model(t_u, w, b + delta), t_c) - \n                         loss_fn(model(t_u, w, b - delta), t_c)) \/ (2.0 * delta)\n\nb = b - learning_rate * loss_rate_of_change_b\n\nb","ebd67a7a":"from torch import nn\nloss = nn.MSELoss()\ninput = torch.randn(10, 5, requires_grad=True)\ntarget = torch.randn(10, 5)\noutput = loss(input, target)\noutput.backward()","310b2d6f":"output.grad_fn","6dc98766":"# Make a sample tensor x, for which automatic gradient calculation needs to happen.\nx = Variable(torch.ones(4, 4) * 12.5, requires_grad=True)\nx","226d7a27":"#  Create a linear function fn that is created using the x variable.\nfn = 2 * (x * x) + 5 * x + 6\n\n\n#  Using the backward function, we can perform a backpropagation calculation. \nfn.backward(torch.ones(4,4))\n\n# The .grad() function holds the final output from the tensor differentiation.\nx.grad","9338e31c":"# Creating a toy dataset\n\nsamples = 5000\n\n#Let\u2019s divide the toy dataset into training (80%) and rest for validation.\ntrain_split = int(samples*0.8)\n\n#Create a dummy classification dataset\nX, y = make_blobs(n_samples=samples, centers=2, n_features=64, cluster_std=10, random_state=2020)\ny = y.reshape(-1,1)\n\n#Convert the numpy datasets to Torch Tensors\nX,y = tch.from_numpy(X),tch.from_numpy(y)\nX,y =X.float(),y.float()\n\n#Split the datasets inot train and test(validation)\nX_train, x_test = X[:train_split], X[train_split:]\nY_train, y_test = y[:train_split], y[train_split:]\n\n#Print shapes of each dataset\nprint(\"X_train.shape:\",X_train.shape)\nprint(\"x_test.shape:\",x_test.shape)\nprint(\"Y_train.shape:\",Y_train.shape)\nprint(\"y_test.shape:\",y_test.shape)\nprint(\"X.dtype\",X.dtype)\nprint(\"y.dtype\",y.dtype)\n\n","734a2c64":"#Define a neural network with 3 hidden layers and 1 output layer\n#Hidden Layers will have 64,256 and 1024 neurons\n#Output layers will have 1 neuron\n\nclass NeuralNetwork(nn.Module):\n    \n    def __init__(self):\n        super().__init__()\n        tch.manual_seed(2020)\n        self.fc1 = nn.Linear(64, 256)\n        self.relu1 = nn.ReLU()\n        self.fc2 = nn.Linear(256, 1024)\n        self.relu2 = nn.ReLU()\n        self.out = nn.Linear(1024, 1)\n        self.final = nn.Sigmoid()\n        \n    def forward(self, x):\n        op = self.fc1(x)\n        op = self.relu1(op)        \n        op = self.fc2(op)\n        op = self.relu2(op)\n        op = self.out(op)\n        y = self.final(op)\n        return y\n","aa2e6a02":"#Define function for training a network\ndef train_network(model,optimizer,loss_function, num_epochs,batch_size,X_train,Y_train):\n    #Explicitly start model training\n    model.train()\n\n    loss_across_epochs = []\n    for epoch in range(num_epochs):\n        train_loss= 0.0\n\n\n        for i in range(0,X_train.shape[0],batch_size):\n\n            #Extract train batch from X and Y\n            input_data = X_train[i:min(X_train.shape[0],i+batch_size)]\n            labels = Y_train[i:min(X_train.shape[0],i+batch_size)]\n\n            #set the gradients to zero before starting to do backpropragation \n            optimizer.zero_grad()\n\n            #Forward pass\n            output_data  = model(input_data)\n\n            #Caculate loss\n            loss = loss_function(output_data, labels)\n\n            #Backpropogate\n            loss.backward()\n\n            #Update weights\n            optimizer.step()\n\n            train_loss += loss.item() * batch_size\n\n        print(\"Epoch: {} - Loss:{:.4f}\".format(epoch+1,train_loss ))\n        loss_across_epochs.extend([train_loss])        \n\n    #Predict\n    y_test_pred = model(x_test)\n    a =np.where(y_test_pred>0.5,1,0)\n    return(loss_across_epochs)\n###------------END OF FUNCTION--------------\n\n#Create an object of the Neural Network class\nmodel = NeuralNetwork()\n\n#Define loss function\nloss_function = nn.BCELoss()  #Binary Crosss Entropy Loss\n\n#Define Optimizer\nadam_optimizer = tch.optim.Adam(model.parameters(),lr= 0.001)\n\n#Define epochs and batch size\nnum_epochs = 10\nbatch_size=16\n\n\n#Calling the function for training and pass model, optimizer, loss and related paramters\nadam_loss = train_network(model,adam_optimizer \\\n,loss_function,num_epochs,batch_size,X_train,Y_train)\n\n","7fa7b388":"\n#Define loss function\nloss_function = nn.BCELoss()  #Binary Crosss Entropy Loss\nnum_epochs = 10\nbatch_size=16\n\n#Define a model object from the class defined earlier\nmodel = NeuralNetwork()\n\n#Train network using RMSProp optimizer\nrmsprp_optimizer = tch.optim.RMSprop(model.parameters()\n, lr=0.01, alpha=0.9\n, eps=1e-08, weight_decay=0.1\n, momentum=0.1, centered=True)\nprint(\"RMSProp...\")\n\nrmsprop_loss = train_network(model,rmsprp_optimizer,loss_function\n,num_epochs,batch_size,X_train,Y_train)\n\n\n#Train network using Adam optimizer\n\nmodel = NeuralNetwork()\nadam_optimizer = tch.optim.Adam(model.parameters(),lr= 0.001)\nprint(\"Adam...\")\nadam_loss = train_network(model,adam_optimizer,loss_function\n,num_epochs,batch_size,X_train,Y_train)\n\n#Train network using SGD optimizer\n\nmodel = NeuralNetwork()\nsgd_optimizer = tch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\nprint(\"SGD...\")\nsgd_loss = train_network(model,sgd_optimizer,loss_function\n,num_epochs,batch_size,X_train,Y_train) \n\n#Plot the losses for each optimizer across epochs\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nepochs = range(0,10)\n\nax = plt.subplot(111)\nax.plot(adam_loss,label=\"ADAM\")\nax.plot(sgd_loss,label=\"SGD\")\nax.plot(rmsprop_loss,label=\"RMSProp\")\nax.legend()\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Overall Loss\")\nplt.title(\"Loss across epochs for different optimizers\")\nplt.show()\n\n","5008feb6":"When we look at the gradient calculation that is used for\nbackpropagation, it is shown as MSELoss.\n","46209125":"The initial loss value is 5259.7334, which is too high because of the\ninitial round of weights chosen. The error in the first round of iteration\nis backpropagated to reduce the errors in the second round, for which\nthe initial set of weights needs to be updated. Therefore, the rate of\nchange in the loss function is essential in updating the weights in the\nestimation process.\n","119c69df":"And now, the weight initialization from the normal distribution, which is also a method\nthat is used in fitting a neural network, fitting a deep neural network, and\nCNN and RNN. Let\u2019s have a look at the process of creating a set of random\nweights generated from a normal distribution.\n\nSyntax\n\n```python\ntorch.normal(mean, std, *, generator=None, out=None) \u2192 Tensor\n```\nReturns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.\n\nThe mean is a tensor with the mean of each output element\u2019s normal distribution\n\nThe std is a tensor with the standard deviation of each output element\u2019s normal distribution\n\nThe shapes of mean and std don\u2019t need to match, but the total number of elements in each tensor need to be the same.","749e4d70":"The sample model is just a linear equation to make the calculation\nhappen and the loss function defined if the mean square error (MSE)\nshown next. For now, this is just a simple linear equation\ncomputation.\n","fe0846b3":"The torch.nn module provides the essential means to define and train\nneural networks. It contains all the necessary building blocks for creating\nneural networks of various kinds, sizes, and complexity. We will create\na class for our neural network by inheriting this module and create an\ninitializing method as well as a forward pass method.\n\n\nThe __init__ method creates the different pieces of the network\nand keeps it ready for us every time we create an object with this class.\nEssentially, we used the initialization method to create the hidden layers,\nthe output layer, and the activation for each layer. \n\nThe `nn.Linear(64,256)` function creates a layer with 64 input features and 256 output features.\nThe next layer, naturally, will have 256 input features, and so on. The `nn.ReLU()` and `nn.Sigmoid()` functions add the activation function when\nconnected to a layer. Each of the individual components created within the\ninitialization function is connected in the `forward()` method.\n\n\nIn the forward method, we connect the individual components of\nthe neural network. The first hidden layer, fc1, accepts input data and\nproduces 256 outputs for the next layer. The fc1 layer is passed to the\nrelu1 activation layer, which then passes the activated output to the next\nlayer, fc2, which repeats the same process, to create the final output layer,\nwhich has the sigmoid activation function (since our toy dataset is crafted\nfor binary classification).\n\n\nOn creating an object of the class NeuralNetwork, and calling the\nforward method, we get outputs from the network, which are computed\nby multiplying the input matrix with a randomly initialized weight matrix\npassed through an activation function and repeated for the number of\nhidden layers until the final output layer. At first, the network would\nobviously generate junk outputs\u2014i.e., predictions (which would add no\nvalue to our classification problem, at least not now).\n\n\n# Defining the Loss, Optimizer, and Training Function for the Neural Network\n\nTo get more accurate predictions for our given problem, we would\nneed to train the network\u2014i.e., to backpropagate the loss and update the\nweights with respect to the loss function. Fortunately, PyTorch provides\nthese essential building blocks in an extremely easy to use and intuitive\nway. \n","c601e511":"# Define a feed forward neural network with a toy dataset\n\nThe toy dataset, with 5,000 samples each having 32 features, is divided\ninto 80% train and 20% test. Let\u2019s create a class that defines the neural\nnetwork using PyTorch\u2019s NN module.\n\nFeed-forward neural networks were the earliest implementations within\ndeep learning. These networks are called feed-forward because the\ninformation within them moves only in one direction (forward)\u2014that is,\nfrom the input nodes (units) towards the output units.\n\nWe will now implement a simple network using PyTorch. Defining the creation of a neural network for the purpose of this exercise.","37abc4b5":"Bernoulli Distribution is a random experiment that has only two outcomes (usually called a \u201cSuccess\u201d or a \u201cFailure\u201d). It is best used when we have two outcomes of a given event. Its considered as the discrete\nprobability distribution, which has two possible outcomes. If the event happens, then the value is 1, and if the event does not happen, then the value is 0.\n\nFor discrete probability distribution, we calculate probability mass\nfunction instead of probability density function. The probability mass\nfunction looks like the following formula.\n\n![](https:\/\/i.imgur.com\/bz2dWtc.png)\n\nFrom the Bernoulli distribution, we create sample tensors by considering the uniform distribution of size 4 and 4 in a matrix format, as follows.\n\n Specifically, `torch.bernoulli()` samples from the distribution and returns a binary value (i.e. either 0 or 1). Here, it returns 1 with probability p and return 0 with probability 1-p.\n\n```python\ntorch.bernoulli(input, *, generator=None, out=None)\n```\nIt draws binary random numbers (0 or 1) from a Bernoulli distribution.\n\nSyntax\n\n```python\ntorch.bernoulli(input, *, generator=None, out=None) \u2192 Tensor\n```\n\nParameters :\n\ninput (Tensor) \u2013 the input tensor of probability values for the Bernoulli distribution\n\ngenerator (torch.Generator, optional) \u2013 a pseudorandom number generator for sampling\n\nout (Tensor, optional) \u2013 out tensor only has values 0 or 1 and is of the same shape as input.\n\nThe input tensor should be a tensor containing probabilities to be used for drawing the binary random number. Hence, all values in input have to be in the range:\n\n0 <= input_i <=1\n","23ab2b25":"Weight initialization is an important task in training a neural network,\nwhether its a convolutional neural network\n(CNN), a deep neural network (DNN), and a recurrent neural network\n(RNN). Lets some examples of initializing the weights.\n\n\nWeight initialization can be done by using various methods, including\nrandom weight initialization.\nWeight initialization based on a distribution\nis done using\n- Uniform distribution,\n- Bernoulli distribution,\n- Multinomial distribution, and normal distribution.\n\nTo execute a neural network, a set of initial weights needs to be passed to\nthe backpropagation layer to compute the loss function (and hence, the\naccuracy can be calculated). The selection of a method depends on the\ndata type, the task, and the optimization required for the model.","edbeb107":"Sampling from multinomial distribution with a replacement returns the tensors\u2019 index values.","c185e99c":"# Compute basic gradients from the sample tensors using PyTorch\n\n#### First some basics of Pytorch here\n\n**Autograd**: This class is an engine to calculate derivatives (Jacobian-vector product to be more precise). It records a graph of all the operations performed on a gradient enabled tensor and creates an acyclic graph called the dynamic computational graph. The leaves of this graph are input tensors and the roots are output tensors. Gradients are calculated by tracing the graph from the root to the leaf and multiplying every gradient in the way using the chain rule.\n\nA Variable class wraps a tensor. You can access this tensor by calling `.data` attribute of a Variable.\n\nThe Variable also stores the gradient of a scalar quantity (say, loss) with respect to the parameter it holds. This gradient can be accessed by calling the `.grad` attribute. This is basically the gradient computed up to this particular node, and the gradient of the every subsequent node, can be computed by multiplying the edge weight with the gradient computed at the node just before it.\n\nThe third attribute a Variable holds is a grad_fn, a Function object which created the variable.\n\n**Variable**: The Variable, just like a Tensor is a class that is used to hold data. It differs, however, in the way it\u2019s meant to be used. Variables are specifically tailored to hold values which change during training of a neural network, i.e. the learnable paramaters of our network. Tensors on the other hand are used to store values that are not to be learned. For example, a Tensor maybe used to store the values of the loss generated by each example.\n\nEvery **variable** object has several members one of them is **grad**:\n\n**grad**: grad holds the value of gradient. If requires_grad is False it will hold a None value. Even if requires_grad is True, it will hold a None value unless .backward() function is called from some other node. For example, if you call out.backward() for some variable out that involved x in its calculations then x.grad will hold \u2202out\/\u2202x.\n\n**Backward() function**\nBackward is the function which actually calculates the gradient by passing it\u2019s argument (1x1 unit tensor by default) through the backward graph all the way up to every leaf node traceable from the calling root tensor. The calculated gradients are then stored in .grad of every leaf node. Remember, the backward graph is already made dynamically during the forward pass. Backward function only calculates the gradient using the already made graph and stores them in leaf nodes.","35c3d25d":"Let\u2019s now define the model. The w parameter is the weight tensor,\nwhich is multiplied with the t_u tensor. The result is added with a constant\ntensor, b, and the loss function chosen is a custom-built one; it is also available in PyTorch. \n\nIn the following example, t_u is the tensor used, t_p\nis the tensor predicted, and t_c is the precomputed tensor, with which the\npredicted tensor needs to be compared to calculate the loss function.\n\nThe formula $$w * t_u + b$$ is the linear equation representation of a\ntensor-based computation.\n\n","6e8153fb":"## [Link to original Notebook by @DataStorm](https:\/\/www.kaggle.com\/paulrohan2020\/important-pytorch-snippets-and-techniques\/)","084b96c1":"# Variable in PyTorch and its defined? What is a random variable in PyTorch?\n\nIn PyTorch, the algorithms are represented as a computational graph.\n\nA variable is considered as a representation around the tensor object,\ncorresponding gradients (slope of the function), and a reference to the function from where it was\ncreated. \n\nThe slope of the function can be computed by the derivative of the\nfunction with respect to the parameters that are present in the function.\n\nBasically, a PyTorch variable is a node in a computational graph, which\nstores data and gradients. When training a neural network model, after\neach iteration, we need to compute the gradient of the loss function with\nrespect to the parameters of the model, such as weights and biases. After\nthat, we usually update the weights using the gradient descent algorithm.\n\nBelow Figure explains how the linear regression equation is deployed under\nthe hood using a neural network model in the PyTorch framework.\nIn a computational graph structure, the sequencing and ordering\nof tasks is very important. The one-dimensional tensors are X, Y, W,\nand alpha. The direction of the arrows change when we\nimplement backpropagation to update the weights to match with Y, so that\nthe error or loss function between Y and predicted Y can be minimized.\n\n\n![Imgur](https:\/\/imgur.com\/6JOtOGb.png)\n\n#### Lets see and example\n\nAn example of how a variable is used to create a computational graph is\ndisplayed in the following script. There are three variable objects around\ntensors\u2014 x1, x2, and x3\u2014with random points generated from a = 12 and\nb = 23. The graph computation involves only multiplication and addition,\nand the final result with the gradient is shown.\n\nThe partial derivative of the loss function with respect to the weights\nand biases in a neural network model is achieved in PyTorch using the\nAutograd module. Variables are specifically designed to hold the changed\nvalues while running a backpropagation in a neural network model when\nthe parameters of the model change. The variable type is just a wrapper\naround the tensor. It has three properties: data, grad, and function.\n\n\n\n","b506e012":"# How do we set up a loss function and optimize it ? \n\nChoosing the right loss function increases the chances of model convergence. \n\nwe use another tensor as the update variable, and introduce\nthe tensors to the sample model and compute the error or loss. Then we\ncompute the rate of change in the loss function to measure the choice of\nloss function in model convergence.\n\nIn the following example, t_c and t_u are two tensors. This can be\nconstructed from any NumPy array.\n","ab9db05a":"#### PyTorch has emerged as a major contender in the race to be the king of deep learning frameworks.\n\nIn this notebook I will go over some regular snippets and techniques of it.","b09d837a":"Let\u2019s look at the individual components we defined leveraging PyTorch\u2019s readily provided building\nblocks. We need to define a loss function that will be used to measure\nthe difference between our predictions and actual labels. PyTorch\nprovides a comprehensive list of loss functions for different outcomes.\nThese loss functions are available under torch.nn.*. Examples include\nMSELoss (mean squared error loss), CrossEntropyLoss (for multi-class\nclassification), and BCELoss (binary cross-entropy loss), which is used\nfor binary classification. For our use case, we will leverage binary cross-\nentropy loss.\n\n```py\nThis is defined as loss_function = torch.nn.BCELoss().\n\n```\n\n\n\n# Gradient-Based Optimization Techniques\n\n### Gradient Descent with Momentum\n\nGradient descent with momentum leverages the past\ngradients to calculate an exponentially weighted average of the gradients\nto further smoothen the parameter updates.\n\n![Imgur](https:\/\/imgur.com\/ZNSJbau.png)\n\nThe update process can be simplified using the following equations.\nFirst, we compute an exponentially weighted average of the past gradients\nas \u03bdt, where \n\n$$\u03bdt = \u03b3\u03bdt \u2212 1 + \u03b7\u2207\u0398J(\u0398)$$\n\nand \n\n$$\u0398 = \u0398 - \u03bdt.$$\n\n\nThe \u03b3 here is a hyperparameter that takes values between 0 and 1.\nNext, we use this exponentially weighted average in the updates of weights\ninstead of the gradients directly.\n\nBy leveraging the exponentially weighted averages of the gradients,\ninstead of directly using the gradients, the incremental steps are smoother and\nfaster and thus overcome the problems with oscillating around the minima.\n\n\n\n### RMSprop\n\nAt the core, RMSprop computes the moving\naverage of the squared gradients for each weight and divides the gradient\nby the square root of the mean square. This complex process should help\nin decoding the name root mean square prop. Leveraging exponential\naverage here helps in giving recent updates more preferences than less\nrecent ones.\nThe RMSprop can be represented as follows:\n\n![Imgur](https:\/\/imgur.com\/MaLGGt9.png)\n\n\nwhere \u03b7 \u2013 is a hyperparameter that defines the initial learning rate, and\ngt is the gradient at time t for a parameter\/weight w in \u0398. We add \u2208 to the\ndenominator to avoid divide by zero situations.\n\n\n### Adam\n\nA simplified name for adaptive moment estimation, Adam is the most\npopular choice recently for optimizers in deep learning. In a simple way,\nAdam combines the best of RMSprop and stochastic gradient descent\nwith momentum. From RMSprop, it borrows the idea of using squared\ngradients to scale the learning rate, and it takes the idea of moving\naverages of the gradient instead of directly using the gradient when\ncompared to SGD with momentum.\nHere, for each weight w in \u0398, we have\n\n![Imgur](https:\/\/imgur.com\/7pt6keW.png)\n\nThe preceding three types of optimization algorithms represent just a\nfew from the breadth of available options for different types of use cases\nwithin deep learning. \n\n---\n\n# Training Model with Various Optimizers\n\nNext, we define an optimizer for our network.\n\nPytorch provides a comprehensive list of optimizers that can be used for building various\nkinds of neural networks. All optimizers are organized under torch.\noptim.* (e.g., `torch.optim.SGD`, for SGD optimizer). For our use case,\nwe are using the Adam optimizer (the most recommended optimizer for\nthe majority of use cases). While defining the optimizer, we also need\nto define the parameters for which the gradient needs to be computed\nduring backpropagation. For the neural network, this list would be all\nthe weights in the feed-forward network. We can easily denote the entire\nlist of model weights to the optimizer by using `model.parameters()`\nwithin the definition of the optimizer. We can then additionally define\nhyperparameters for the selected optimizer. By default, PyTorch provides\nfairly good values for all necessary hyperparameters. However, we can\nfurther override them to tailor optimizers for our use case.\n\n```py\nadam_optimizer = tch.optim.Adam(model.parameters(),lr= 0.001)\n```\n\nLastly, we need to define the batch size and the number of epochs\nrequired to train our model. Batch size refers to the number of samples\nwithin a batch in a mini-batch update. One forward and backward pass\nfor all the batches that cover all samples once is called an epoch. Finally,\nwe pass all these constructs to our function to train our model. Let\u2019s take a\ndetailed look at the constructs within the function.\n\n\nIn our training function, we define a structure to train our network with\nthe provided optimizer, loss function, model object, and training data over\nbatches for the defined number of epochs. First, we initiate our model for\ntraining mode with model.train(). Setting the model object to train mode\nexplicitly is essential; the same would be essential while leveraging the\nmodel for evaluation\u2014i.e., explicitly setting the model to evaluate mode\nwith model.eval(). This ensures that the model is aware of the time when\nit is expected to update the parameters and when to not. In the preceding\nexample, we did not add the evaluation loop because it is a tiny toy dataset.\n\n\nWe will train the network over mini-batches. The for loop divides the\ntraining data into batches with our defined size. The training data, along\nwith the corresponding labels, is extracted for a batch using the following\ncode:\n\n\n\n```py\ninput_data = X_train[i:min(X_train.shape[0],i+batch_size)]\nlabels = Y_train[i:min(X_train.shape[0],i+batch_size)]\n\n```\n\nWe then need to set the gradients to zero before starting to do\nbackpropagation using optimizer.zero_grad(). Missing this step will\naccumulate the gradients on subsequent backward passes and lead to\nundesirable effects. This behavior is by design in PyTorch. Then, we\ncalculate the forward pass using output_data = model(input_data).\nThe forward pass is the execution of the forward() function in our class\ndefinition. It connects the different layers we defined for the network,\nwhich finally outputs the prediction for each sample. \n\nOnce we have the predictions, we can calculate its deviation from the actual label using the\nloss function\u2014i.e., \n\n$$loss = loss_function(output_data, labels)$$\n\n\nTo backpropagate our loss, PyTorch provides a built-in module that\ndoes the heavy lifting for computing gradients for the loss with respect to\nthe weights. We simply call the loss.backward() method, and the entire\nbackpropagation is taken care of. \n\nOnce the gradients are computed, it is time to update our model weights. This is done in the step\noptimizer.step(). The optimizer step is aware of the parameters that\nneed to be updated with the gradient, as we provided them while defining\nour optimizer. Calling the optimizer.step() function updates the weights\nfor the network, automatically taking into account the hyperparameters\ndefined within the optimizer\u2014in our case, the learning rate.\nWe repeat this process over batches for the entire training sample. The\ntraining process is repeated for multiple epochs, and with each iteration\nwe expect the losses to reduce and the weights to align in order to achieve\nbetter accuracy for predictions.\n\nBelow code ses different optimizers to illustrate the training process\nfor the preceding neural network. Since the network was trained for a toy\ndataset, we will plot the total losses after each epoch for different optimizers,\ninstead of plotting the validation accuracy. We can study the outputs i.e. loss\nacross epochs for each optimization variant showcased in the plot at the bottom.\n","ebd59efb":"# Generation of sample random values from a multinomial distribution\n\nNote the syntax of multinomial function from official doc\n\n```python\ntorch.multinomial(input, num_samples, replacement=False, *, generator=None, out=None) \u2192 LongTensor\n```\nReturns a tensor where each row contains num_samples indices sampled from the multinomial probability distribution located in the corresponding row of tensor input.\n\n","ae6e98de":"# Tensor differentiation and its relevance in computational graph execution using the PyTorch framework\n\nThe computational graph network is represented by nodes and connected\nthrough functions. There are two different kinds of nodes: dependent and\nindependent. Dependent nodes are waiting for results from other nodes\nto process the input. Independent nodes are connected and are either\nconstants or the results. Tensor differentiation is an efficient method to\nperform computation in a computational graph environment.\n\nIn a computational graph, tensor differentiation is very effective because\nthe tensors can be computed as parallel nodes, multiprocess nodes, or\nmultithreading nodes. The major deep learning and neural computation\nframeworks include this tensor differentiation.\nAutograd is the function that helps perform tensor differentiation,\nwhich means calculating the gradients or slope of the error function,\nand backpropagating errors through the neural network to fine-tune the\nweights and biases. Through the learning rate and iteration, it tries to\nreduce the error value or loss function.\nTo apply tensor differentiation, the nn.backward() method needs to\nbe applied. Let\u2019s take an example and see how the error gradients are\nbackpropagated. To update the curve of the loss function, or to find where\nthe shape of the loss function is minimum and in which direction it is\nmoving, a derivative calculation is required. Tensor differentiation is a way\nto compute the slope of the function in a computational graph.\n","e3a5ec6d":"There are two parameters to update the rate of loss function: the\nlearning rate at the current iteration and the learning rate at the previous\niteration. If the delta between the two iterations exceeds a certain\nthreshold, then the weight tensor needs to be updated, else model\nconvergence could happen. The preceding script shows the delta and\nlearning rate values. Currently, these are static values that the user has the\noption to change.\n","247369c0":"This is how a simple mean square loss function works in a two-\u00ad\ndimensional tensor example, with a tensor size of 10,5.\nLet\u2019s look at the following example. The MSELoss function is within the\nneural network module of PyTorch.\n"}}