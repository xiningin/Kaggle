{"cell_type":{"037dae40":"code","26b0b7e5":"code","e5670f5f":"code","2e99725e":"code","768d6552":"code","e8b8d161":"code","bbfb0510":"code","61830c22":"code","ecba097f":"code","1944f5c5":"code","16f35f41":"code","3566421b":"code","7b3cdea4":"code","cf330638":"code","cb24b408":"code","5f96e58c":"code","5e20036b":"code","7b3c7e5f":"code","d6431300":"code","599ccd07":"markdown","4ee53839":"markdown","982ec494":"markdown","095aec23":"markdown","fe802c0d":"markdown","e5112a27":"markdown","f20b0671":"markdown","e50462d1":"markdown","c556ecd1":"markdown"},"source":{"037dae40":"#Import common packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport string","26b0b7e5":"# import packages for text\nimport nltk\nimport re\nfrom wordcloud import WordCloud\n\n#Set ignore warning for futureWarning\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n#import deep learning packages for text classification\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Embedding\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score","e5670f5f":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nfake_news = pd.read_csv(\"\/kaggle\/input\/fake-and-real-news-dataset\/Fake.csv\")\ntrue_news = pd.read_csv(\"\/kaggle\/input\/fake-and-real-news-dataset\/True.csv\")","2e99725e":"fake_news.head(3)","768d6552":"# See how many fake news are there from different subjects\nfake_news_by_subject = fake_news.groupby(by=\"subject\").count()[\"title\"]\nprint(fake_news_by_subject)\nplt.figure(figsize=(10,3))\nsns.countplot(\"subject\", data=fake_news, palette=\"Blues\")","e8b8d161":"fake_text_data = \"\".join(str(x) for x in fake_news[\"text\"])\nstop_words = set(nltk.corpus.stopwords.words(\"english\"))\nword_cloud_fake = WordCloud(stopwords=stop_words, width=2000, height=1000,\\\n                            max_font_size=160, min_font_size=30).generate(fake_text_data)\nplt.figure(figsize=(12,6), facecolor=\"k\")\nplt.imshow(word_cloud_fake)\nplt.axis(\"off\")\nplt.tight_layout(pad=0)\nplt.show()","bbfb0510":"#Lets do the wordcloud for true news\ntrue_text_data = \"\".join(str(x) for x in true_news[\"text\"])\nword_cloud_fake = WordCloud(stopwords=stop_words, width=2000, height=1000,\\\n                            max_font_size=160, min_font_size=30).generate(true_text_data)\nplt.figure(figsize=(12,6), facecolor=\"k\")\nplt.imshow(word_cloud_fake)\nplt.axis(\"off\")\nplt.tight_layout(pad=0)\nplt.show()","61830c22":"del fake_text_data, true_text_data","ecba097f":"#Label the true_or_not for concat\ntrue_news[\"true\"]=1\nfake_news[\"true\"]=0\ndf = pd.concat([fake_news, true_news])\n# df.shape[0] # 44898 rows\ndf.head()","1944f5c5":"df[\"text\"] = df[\"text\"]+\" \"+df[\"title\"]\n#I am not sure whether giving different weights to these two vars show difference. \ndf = df.filter([\"text\",\"true\"], axis=1)\ndf.head()","16f35f41":"import unicodedata\ndef remove_punct(text):\n    text  = \"\".join([char for char in text if char not in string.punctuation])\n    text = re.sub('[0-9]+', '', text)\n    return text\n\ndef remove_stopwords(text):\n    filtered_text = []\n    for i in text.split():\n        i = i.strip()\n        if i.lower() not in stop_words:\n            filtered_text.append(i)\n    filtered_text = ' '.join(filtered_text)    \n    return filtered_text\n\ndef normalize_accented_characters(text):\n    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf8')\n    return text\n\ndef normalize_text(text):\n    text = remove_punct(text)\n    text = remove_stopwords(text)\n    text = normalize_accented_characters(text)\n    return text    ","3566421b":"df['text']=df['text'].apply(normalize_text)","7b3cdea4":"from nltk.stem import WordNetLemmatizer\nlemmatizer = WordNetLemmatizer()\ndef lemmatize_text(text):\n    lemmas = []\n    for word in text.split():\n        lemmas.append(lemmatizer.lemmatize(word))\n    return \" \".join(lemmas)\ndf['text']=df['text'].apply(lemmatize_text)","cf330638":"x, y = df[\"text\"].values, df[\"true\"].values\ntokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\nX=[]\nfor article in x:\n    sentence_list = []\n    article = nltk.sent_tokenize(article)\n    for sentence in article:\n        sentence = sentence.lower()\n        #The seqence here is very important since they are different data types.\n        #Generally speaking, Word2Vec needs a \"list of list\" for input. \n        tokens = tokenizer.tokenize(sentence)\n        sentence_list.extend([x.strip() for x in tokens])\n    X.append(sentence_list)","cb24b408":"import gensim\nemb_dim = 100 #vector dimension\nword2vec_model = gensim.models.Word2Vec(sentences=X, size=emb_dim, window=10, min_count=1)\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(X)\nX = tokenizer.texts_to_sequences(X)\nX = pad_sequences(X, maxlen=1000)","5f96e58c":"word_index = tokenizer.word_index #A dictionary with index and words\nvocab_size = len(word_index) + 1\n#Get the weight matrix for embedding layer\ndef get_weight(model,word_index):\n    weight_matrix = np.zeros((vocab_size,emb_dim))\n    for word, index in word_index.items():\n        weight_matrix[index]=model[word]\n    return weight_matrix\nemb_vec = get_weight(word2vec_model,word_index)","5e20036b":"x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.20,random_state=42)","7b3c7e5f":"import tensorflow as tf\nnn_model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size, output_dim=emb_dim, weights = [emb_vec], input_length=1000,trainable=False),\n    #REMEMBER TO PUT THE EMBEDDING VECTORS TO A LIST\n    tf.keras.layers.LSTM(128, return_sequences=True),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.LSTM(64),\n    tf.keras.layers.Dense(32,activation=\"relu\"),\n    tf.keras.layers.Dense(1,activation=\"sigmoid\")\n])\nnn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\nnn_model.summary","d6431300":"history = nn_model.fit(x_train,y_train,epochs=3,validation_data=(x_test,y_test),batch_size=128)\nclassification_result = nn_model.evaluate(x_test,y_test)\nclassification_result","599ccd07":"### Train the model","4ee53839":"### EDA for Real News","982ec494":"Now we have two tasks:\nwhich text feature engineering method we should use and which ML\/DL models we should use\n\nFeature Engineering(Vectorization) Methods:\n1. TF-IDF\n2. Word2Vec (YES)\n3. GloVe \n\n#There are two great notebooks illustrating GloVe.So here I am gonna use Word2Vec\n\nThe common methods I learned about text classification:\n1. SVM\n2. Naive Beyes (Normally SVM performs better)\n3. Logistic Regression (Since here it is a binary classification problem)\n4. CNN (Most reasonable since we have enough training set)\n\nWe will try CNN here for general purpose. ","095aec23":"### The However Part","fe802c0d":"Upvoted if you like it! Big Thanks!","e5112a27":"1. When the model trained 7000 out of 35918 in epoch 1, the accuracy already reached 93%. Some of the words like \"Reuters\" \"WASHINGTON\" can ensure the news is true. So this model cannot produce as good results when applying to a new dataset. \n2. I think you can use one less layer for this. The traning time is a little bit too long.","f20b0671":"Worth to mention, we are not supposed to use \"subject\" as a feature for classification since the two datasets have different subjects. It is \"cheating\" to let the ML tell the difference by subjects. So here we only use title and text.","e50462d1":"### Tokenization & Vectorization","c556ecd1":"### Data Cleaning"}}