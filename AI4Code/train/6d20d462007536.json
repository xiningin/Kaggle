{"cell_type":{"c71a4cd3":"code","1db7dfe2":"code","2de5dee1":"code","7a88c1b3":"code","aa3d1654":"code","629efc1c":"code","f02760cb":"code","4c67550b":"code","d0b8f09a":"code","f8efa619":"code","ce980795":"code","fa05a8a7":"code","259d0d58":"code","f113b29b":"markdown"},"source":{"c71a4cd3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.preprocessing import LabelBinarizer\nfrom scipy.sparse import csr_matrix, hstack\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import KFold\nimport string\nimport gc\nimport os\nimport re\n\nimport warnings\nwarnings.filterwarnings('ignore')\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","1db7dfe2":"def rmsle(y, preds):\n    return np.sqrt(np.square(np.log(preds + 1) - np.log(y + 1)).mean())\n\ndef treat_missing(dataset):\n    dataset['name'].fillna(value='unavailable', inplace=True)\n    dataset['category_name'].fillna(value='unavailable', inplace=True)\n    dataset['brand_name'].fillna(value='unavailable', inplace=True)\n    dataset['item_description'].fillna(value='unavailable', inplace=True)\n\ndef treat_brand(dataset):\n    brands = dataset['brand_name'].unique().astype(str)\n    print(pd.isnull(dataset['brand_name']).sum())\n    brands_str = re.compile(r'\\b(?:%s)\\b' % '|'.join(brands))\n    dataset['brand_name'] = dataset.apply(lambda row: row['brand_name'] if pd.notnull(row['brand_name']) or brands_str.match(row['name']) is None else brands_str.match(row['name']).group(0), axis=1)    \n    print(pd.isnull(dataset['brand_name']).sum())\n    del brands\n    del brands_str\n    gc.collect()\n\ndef treat_case(dataset):\n    dataset['category_name'] = dataset['category_name'].str.lower()\n    dataset['brand_name'] = dataset['brand_name'].str.lower()\n    dataset['name'] = dataset['name'].str.lower()\n    dataset['item_description'] = dataset['item_description'].str.lower()\n    \ndef treat_punctuations(dataset):\n    dataset['brand_name'] = dataset['brand_name'].str.replace(\"'\",\"\")\n    dataset['name'] = dataset['name'].str.replace(\"'\",\"\")\n    dataset['item_description'] = dataset['item_description'].str.replace(\"'\",\"\")\n\ndef process_dataset(dataset):\n    treat_case(dataset)\n    treat_punctuations(dataset)\n    treat_brand(dataset)\n    treat_missing(dataset)","2de5dee1":"# Read Datasets\ntrain = pd.read_csv('..\/input\/guess-my-price\/train.tsv',sep='\\t')\ntest = pd.read_csv('..\/input\/guess-my-price\/test.tsv',sep='\\t')\ntrain.drop(columns=['random'],inplace=True,axis=1)\ntest.drop(columns=['random'],inplace=True,axis=1)\ntrain = train.drop(train[train.price <= 1.0].index).reset_index(drop=True)\n\nprint(train.shape)\nprint(test.shape)","7a88c1b3":"# Splitting out category columns\ndef treat_category(cats):\n    cat1 = \"no category 1\"\n    cat2 = \"no category 2\"\n    cat3 = \"no category 3\"\n    if pd.notnull(cats):\n        all_cats = cats.split('\/')\n        if len(all_cats) > 0:\n            cat3 = all_cats[2]\n            cat2 = all_cats[1]\n            cat1 = all_cats[0]\n    return cat1.lower(), cat2.lower(), cat3.lower()\n\ntest_preds_overall = pd.DataFrame(test[['train_id']].reset_index(drop=True))\n\ntrain[['cat1','cat2','cat3']] = pd.DataFrame(train.category_name.apply(treat_category).tolist(), columns = ['cat1','cat2','cat3'])\ntest[['cat1','cat2','cat3']] = pd.DataFrame(test.category_name.apply(treat_category).tolist(), columns = ['cat1','cat2','cat3'])\ntrain.head()","aa3d1654":"# If count of category 3 is less than 100, take category 2. If category 2 is less than 100, take category 1\ncount_cat3 = pd.DataFrame(train['cat3'].value_counts())\nprint('Top 10',count_cat3[0:10])\nprint('\\n')\nprint('Bottom 10',count_cat3[-10:])\nprint('\\n')\n\ncount_cat2 = pd.DataFrame(train['cat2'].value_counts())\nprint('Top 10',count_cat2[0:10])\nprint('\\n')\nprint('Bottom 10',count_cat2[-10:])\nprint('\\n')\n\ncount_cat1 = pd.DataFrame(train['cat1'].value_counts())\nprint('Top 10',count_cat1[0:10])\nprint('\\n')\nprint('Bottom 10',count_cat1[-10:])\nprint('\\n')\n\ncount_cutoff = 100\ncount_cat3 = count_cat3[count_cat3.cat3 >= count_cutoff]\ncount_cat2 = count_cat2[count_cat2.cat2 >= count_cutoff]\n\ntrain['cat3'] = train.apply(lambda row: row['cat3'] if row['cat3'] in count_cat3.index else (row['cat2'] if row['cat2'] in count_cat2.index else row['cat1']), axis=1)\ntest['cat3'] = test.apply(lambda row: row['cat3'] if row['cat3'] in count_cat3.index else (row['cat2'] if row['cat2'] in count_cat2.index else row['cat1']), axis=1)","629efc1c":"# Process Dataframe\nnrow_train = train.shape[0]\ntrain_test_combined = train.append(test,sort=True).reset_index(drop=True)\nprint(train_test_combined.shape)\n\nprocess_dataset(train_test_combined)\ntrain = train_test_combined[:nrow_train]\ntest = train_test_combined[nrow_train:]\ntest.drop(['price'], axis = 1, inplace = True)","f02760cb":"# Combining name + category_name + brand_name. Implementing TF-IDF separately on these columns makes a very large matrix\ntrain_test_combined['name'] = train_test_combined['name'].astype(str) + ' ' + train_test_combined['category_name'].astype(str) + ' ' + train_test_combined['brand_name']\n\ntv = TfidfVectorizer(max_features=None,\n                     ngram_range=(1, 3), min_df=2, token_pattern=r'(?u)\\b\\w+\\b') # Regex source: https:\/\/stackoverflow.com\/questions\/35043085\/what-does-u-do-in-a-regex\nX_name = tv.fit_transform(train_test_combined['name'])\nX_description = tv.fit_transform(train_test_combined['item_description'])\nX_category = tv.fit_transform(train_test_combined['category_name'])\n\nlb = LabelBinarizer(sparse_output=True)\nX_brand = lb.fit_transform(train_test_combined['brand_name'])\nX_dummies = csr_matrix(pd.get_dummies(train_test_combined[['item_condition_id', 'shipping']], sparse=True).values)\nsparse_train_test_combined = hstack((X_dummies, X_description, X_brand, X_name, X_category)).tocsr()\nX = sparse_train_test_combined[:nrow_train]\nX_test = sparse_train_test_combined[nrow_train:]\ny = np.log1p(train['price'])","4c67550b":"X.shape","d0b8f09a":"del train_test_combined\ndel sparse_train_test_combined\ndel X_dummies\ndel X_description\ndel X_brand\ndel X_category\ndel X_name\ngc.collect()","f8efa619":"# Fitting a ridge reggression model at overall level data\nmodel = Ridge(solver=\"sag\", fit_intercept=True, random_state=369)\nmodel.fit(X, y)\ntest_preds_overall['Overall_Price'] = model.predict(X=X_test)\ntest_preds_overall.head()","ce980795":"train.head()","fa05a8a7":"test_preds_cat = pd.DataFrame(columns=['train_id','Category_Price'])\ncats = train['cat3'].unique().astype(str)\ncount_threshold = 100\n\nfor cat in cats:\n    warnings.filterwarnings('ignore')\n    train_cat = train[train.cat3 == cat].reset_index(drop=True)\n    print(cat, train_cat.shape[0])\n    \n    # If count of category 3 is less than threshold, we will not build model\n    if train_cat.shape[0] < count_threshold:\n        continue\n        \n    test_cat = test[test.cat3 == cat].reset_index(drop=True)\n    cat_preds = pd.DataFrame(test_cat[['train_id']].reset_index(drop=True))\n    nrow_cat = train_cat.shape[0]\n    y = np.log1p(train_cat[\"price\"])\n    max_cat = y.max()\n    min_cat = y.min()\n    \n    train_test_combined =  pd.DataFrame(pd.concat([train_cat, test_cat], axis = 0))\n    del train_cat\n    del test_cat\n    \n    # Taking count of category name to add some diversity before ensemble\n    cv = CountVectorizer()\n    X_category = cv.fit_transform(train_test_combined['category_name'])\n    \n    tv = TfidfVectorizer(max_features=None, ngram_range=(1, 3), min_df=2,token_pattern=r'(?u)\\b\\w+\\b') # Regex source: https:\/\/stackoverflow.com\/questions\/35043085\/what-does-u-do-in-a-regex\n    train_test_combined['name'] = train_test_combined['name'] + ' ' + train_test_combined['brand_name']\n    X_name = tv.fit_transform(train_test_combined['name'])\n    X_description = tv.fit_transform(train_test_combined['item_description'])\n    \n    lb = LabelBinarizer(sparse_output=True)\n    X_brand = lb.fit_transform(train_test_combined['brand_name'])\n    X_dummies = csr_matrix(pd.get_dummies(train_test_combined[['item_condition_id', 'shipping']], sparse=True).values)\n    sparse_train_test_combined = hstack((X_dummies, X_description, X_brand, X_name, X_category)).tocsr()\n    X = sparse_train_test_combined[:nrow_cat]\n    X_test = sparse_train_test_combined[nrow_cat:]\n    \n    del train_test_combined\n    del sparse_train_test_combined\n    del X_dummies\n    del X_category\n    del X_description\n    del X_brand\n    del X_name\n    gc.collect()\n\n    model = Ridge(solver=\"saga\", fit_intercept=False, random_state=459)\n    model.fit(X, y)\n    cat_preds['Category_Price'] = model.predict(X=X_test)\n    cat_preds['Category_Price'] = np.clip(cat_preds['Category_Price'], min_cat, max_cat)\n    test_preds_cat = pd.DataFrame(pd.concat([test_preds_cat, cat_preds], axis = 0))","259d0d58":"# Joining overall predictions with category level predictions\npreds_all = test_preds_overall.merge(test_preds_cat,on='train_id',how='left')\n# If category level predictions are null, take the score from overall predictions\npreds_all['Both'] = preds_all.apply(lambda row: row['Overall_Price'] if pd.isnull(row['Category_Price']) else row['Category_Price'], axis=1)\nprint(preds_all['Both'].head(20))\n# Ensemble of overall predictions and category level predictions\npreds_all['price'] = np.expm1((preds_all['Both'] + preds_all['Overall_Price']) \/ 2)\npreds_all[['train_id','price']].to_csv(\"Submission.csv\",index=False)\nprint(preds_all['Overall_Price'].min())\n\nprint(preds_all.head())","f113b29b":"> The idea of building a ridge regression model for the category level in this kernel is sourced from this EDA work by keitashimizu in the Mercari competition: \nhttps:\/\/www.kaggle.com\/keitashimizu\/exploration-of-category-layers"}}