{"cell_type":{"7f60531a":"code","071b2875":"code","b2867a56":"code","359eb1a6":"code","900357e1":"code","9b59ab35":"code","fee326c3":"code","1ab33c73":"code","af2fce18":"code","4fa070a8":"code","ce856b5d":"code","14d9be4e":"code","8d666767":"code","dc1dca26":"code","01c243a3":"code","e79b12a2":"code","4b943dc9":"code","d39e3098":"code","11044b6e":"code","0293eedb":"code","d30f3cbc":"code","dbed4a3c":"code","8e1f6c12":"code","eddf3eeb":"code","e14da2c2":"code","a64e2666":"code","ee0a7dee":"code","a64a7931":"code","60499213":"code","343d77cb":"code","f059549e":"code","185828b7":"code","24ddf527":"code","09023e7f":"code","e9cca439":"code","22dd3427":"code","60bf8a19":"code","18d9e109":"code","104dcf0d":"code","136e9f24":"code","bebbfb67":"code","4d2050f9":"code","4189e757":"code","535ebc58":"code","4bca08c0":"code","b0be4711":"code","8b559f26":"code","9466bd61":"code","22d31c1b":"code","120f7639":"code","e65beb25":"code","5456f6c8":"code","ba354054":"code","0d6c0191":"code","6db776d7":"code","876680c9":"code","a5b2c0e6":"code","1ed198a1":"code","e4c39c3d":"code","bb179083":"markdown","428080fd":"markdown","27317a65":"markdown","97c4f79d":"markdown","810cc649":"markdown","08eaebad":"markdown","d92168d9":"markdown","1bd01ebd":"markdown","0ecc3403":"markdown","5d8a5ca6":"markdown","7c8f150d":"markdown","2907cfac":"markdown","e930a37f":"markdown","4950fcc4":"markdown","020cd64c":"markdown","f3027be0":"markdown","95ba79da":"markdown","d34ba493":"markdown","f2a3630f":"markdown","2af36758":"markdown","bd6e30a8":"markdown","49767ff7":"markdown","e14c2836":"markdown","bd0e4b62":"markdown","9c7b342b":"markdown","ffdcf71d":"markdown","004de9b4":"markdown","6b111c80":"markdown","daf12177":"markdown"},"source":{"7f60531a":"# import libraries for data exploration\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%config InlineBackend.figureFormat='retina'\nimport warnings\nwarnings.filterwarnings('ignore')","071b2875":"# let's load the dataset\nhr = pd.read_csv(r'train_LZdllcl (1).csv')\nbckup = hr.copy()\nhr.head()","b2867a56":"hr.info() # basic descr","359eb1a6":"hr = hr.drop('employee_id', axis=1)","900357e1":"hr['is_promoted'].value_counts()","9b59ab35":"sns.countplot(hr['is_promoted'])","fee326c3":"hr.isnull().sum()","1ab33c73":"hr['education'].value_counts()","af2fce18":"hr['previous_year_rating'].value_counts()","4fa070a8":"labels = hr['is_promoted'].copy()\nhr = hr.drop('is_promoted', axis=1)","ce856b5d":"# let's impute the missing values with mode and median value for now.","14d9be4e":"from sklearn.impute import SimpleImputer","8d666767":"imputer = SimpleImputer(strategy='most_frequent')","dc1dca26":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer","01c243a3":"num_pipline = Pipeline([  # create pipelines for feature transformations\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())\n])","e79b12a2":"cat_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('encoder', OneHotEncoder())\n])","4b943dc9":"num_attribs = list(hr.select_dtypes(include=np.number))\ncat_attribs = list(hr.select_dtypes(exclude=np.number))","d39e3098":"full_pipeline = ColumnTransformer([\n    ('num_attribs', num_pipline, num_attribs),\n    ('cat_attribs', cat_pipeline, cat_attribs)\n])","11044b6e":"hr_prepared = full_pipeline.fit_transform(hr)","0293eedb":"hr_prepared.shape","d30f3cbc":"# hr_prepared = pd.DataFrame(hr_prepared, columns=list(hr))","dbed4a3c":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(hr_prepared, labels, test_size=0.2, random_state=42)","8e1f6c12":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","eddf3eeb":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, classification_report, f1_score # choosing confusion matrix and F1 score","e14da2c2":"log_reg = LogisticRegression()\n\nlog_reg.fit(X_train, y_train)","a64e2666":"predicted = log_reg.predict(X_test)","ee0a7dee":"print(confusion_matrix(y_test, predicted))","a64a7931":"print(classification_report(y_test, predicted))","60499213":"f1_score(y_test, predicted)","343d77cb":"from imblearn.over_sampling import SMOTE","f059549e":"sm = SMOTE()","185828b7":"X, y = sm.fit_resample(hr_prepared, labels)","24ddf527":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","09023e7f":"new_model = LogisticRegression()\nnew_predict = new_model.fit(X_train, y_train).predict(X_test)","e9cca439":"print(confusion_matrix(y_test, new_predict))","22dd3427":"print(classification_report(y_test, new_predict))","60bf8a19":"f1_score(y_test, new_predict)","18d9e109":"hr.isnull().sum()","104dcf0d":"cat_hr = bckup.copy()\n\neducation_mode = cat_hr['education'].mode()[0]\npyr_median = cat_hr['previous_year_rating'].median()\n\ncat_hr['education'].fillna(education_mode, inplace=True)\ncat_hr['previous_year_rating'].fillna(pyr_median, inplace=True)","136e9f24":"# cat_hr = bckup.dropna(how='any')","bebbfb67":"cat_hr.isnull().sum().sum()","4d2050f9":"cat_hr.drop('employee_id', axis=1, inplace=True)\n# cat_hr.head()","4189e757":"from catboost import CatBoostClassifier\nfrom imblearn.over_sampling import SMOTENC","535ebc58":"sm = SMOTENC(categorical_features=[0, 1, 2, 3, 4]) # categorical feature column index are given as input","4bca08c0":"X = cat_hr.drop('is_promoted', axis=1)\ny = cat_hr['is_promoted'].copy()\n\nX, y = sm.fit_resample(X, y)","b0be4711":"cat_hr.columns","8b559f26":"X = pd.DataFrame(X, columns=['department', 'region', 'education', 'gender', 'recruitment_channel',\n       'no_of_trainings', 'age', 'previous_year_rating', 'length_of_service',\n       'KPIs_met >80%', 'awards_won?', 'avg_training_score'])","9466bd61":"np.unique(y, return_counts=True)","22d31c1b":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","120f7639":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","e65beb25":"new_cbr = CatBoostClassifier(verbose=400, eval_metric='F1')","5456f6c8":"new_cbr.fit(X_train, y_train,cat_features=[0,1,2,3,4],eval_set=(X_test, y_test),plot=True) #index of cat. features are mentioned","ba354054":"test_data = pd.read_csv(r'test_2umaH9m.csv') \n# test_data.head()","0d6c0191":"# test_data_prepared = full_pipeline.fit_transform(test_data)","6db776d7":"test_data.isnull().sum()","876680c9":"test_data['education'].fillna(test_data['education'].mode()[0], inplace=True)\ntest_data['previous_year_rating'].fillna(test_data['previous_year_rating'].median(), inplace=True)","a5b2c0e6":"final = test_data.drop('employee_id', axis=1)","1ed198a1":"cbr_predicted = new_cbr.predict(final)\n\ncbr_predicted = pd.DataFrame(cbr_predicted, columns=['is_promoted'])\n\ndf = pd.concat([test_data['employee_id'], cbr_predicted], axis=1)","e4c39c3d":"df.to_csv(r'C:\\Users\\gokul\\Downloads\\results.csv')","bb179083":"we have missing values in 'Region' and 'Previous year rating' column","428080fd":"**Without treating imbalance**","27317a65":"### Data Type      \n**Object**\n\n    - department              \n    - region                  \n    - education               \n    - gender                  \n    - recruitment_channel \n    \n**Numeric**              \n    - employee_id\n    - no_of_trainings\n    - age\n    - previous_year_rating    \n    - length_of_service       \n    - KPIs_met >80%           \n    - awards_won?             \n    - avg_training_score      \n    - is_promoted             ","97c4f79d":"As we can figure out, only few candidates will be considered for promotion, and that makes sense. But, in order to get \naccurate results, we may need to handle this imbalance data.","810cc649":"### Final prediction","08eaebad":"We used one hot encoding to encode the categorical features in the data, let's use Cat boost algorithm, which has in built \nmechanism to handle categorical features.","d92168d9":"**After handling imbalance**","1bd01ebd":"### Prepare test data","0ecc3403":"**Aim**:            \n    Company needs your help in identifying the eligible candidates at a particular checkpoint \n    so that they can expedite the entire","5d8a5ca6":"**Logistic Regression**","7c8f150d":"## Exploratory Data Analysis","2907cfac":"**Imbalance handling**","e930a37f":"To resample data with categorical features, we are using SMOTENC, which is designed to handle both categorical and\nnumerical features.","4950fcc4":"### Model building","020cd64c":"### Let's check the balance of the dataset","f3027be0":"Our dataset contains 54808 entries and 14 features","95ba79da":"**Dependent variables**:       \n\n    Employee id - Unique ID for employee\n    Department - Department of employee\n    Region - Region of employment (unordered)\n    Education - Education Level\n    Gender - Gender of Employee\n    Recruitment Channel - Channel of recruitment for employee\n    No of trainings - no of other trainings completed in previous year on soft skills, technical skills etc.\n    Age - Age of Employee\n    Previous year rating - Employee Rating for the previous year\n    Length of service - Length of service in years\n    KPIs met >80% ? - if Percent of KPIs(Key performance Indicators) >80% then 1 else 0\n    Awards won? - if awards won during previous year then 1 else 0\n    Avg training score - Average score in current training evaluations\n\n**Target variable**:               \n\n    Is promoted ? - (Target) Recommended for promotion","d34ba493":"### Feature category        \n**Categorical**       \n    - department              \n    - region                  \n    - education               \n    - gender                  \n    - recruitment_channel \n    - no_of_trainings\n    - age\n    - previous_year_rating \n    - KPIs_met >80%\n    - awards_won?\n    - is_promoted \n    - \n**Continuous**    \n    - length_of_service\n    - avg_training_score\n    ","f2a3630f":"### Handling missing values","2af36758":"**Cat Boost**","bd6e30a8":"### Attribute information","49767ff7":"Let's drop unnecessary features.","e14c2836":"Our accuracy has greatly increased from 80% to 96%, using Cat boost.","bd0e4b62":"As we can see, the f score has greatly improved after handling imbalance, from 30% to 80%. Let's see we can improve\nthe score with other models.","9c7b342b":"Since under sampling leads to loss of data, let's try first with over sampling method SMOTE.","ffdcf71d":"We could see that, the model couldn't classify more than half of the data is missclassified in true negative region.","004de9b4":"Our classification results are poor for predicting, whether a customer has got promotion.","6b111c80":"Now, our data is balanced.","daf12177":"After one hot encoding, our dimensions has increased from 14 to 58."}}