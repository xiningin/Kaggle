{"cell_type":{"1cf9086f":"code","b93268d9":"code","0fb412b7":"code","352f3a12":"code","fc2586f4":"code","b31e20ea":"code","af658af7":"code","bc3c8902":"code","934a8563":"code","3165bee3":"code","94b50139":"code","fcd4e7ae":"code","10050f74":"code","dcc7e079":"code","a2235154":"code","01e278ce":"code","d9c705dd":"code","912ba9f9":"code","26938364":"code","65fd7891":"code","5618e7e1":"code","823ee6a7":"code","f1631845":"code","6a9e2d48":"code","4921b9ca":"code","95904523":"code","b50b3c02":"code","7a0f1e81":"code","0631c294":"code","bba487fa":"code","e08155ee":"markdown","6441ee05":"markdown","b6f0d524":"markdown","3848d748":"markdown","3a98b0b5":"markdown","2eea3ffd":"markdown","202e271d":"markdown","e05b264b":"markdown","4d491c64":"markdown","383bbd10":"markdown","495357ac":"markdown","2852486b":"markdown","5757f79d":"markdown","51ea16bc":"markdown","7c245a05":"markdown","cf39cf39":"markdown","8cdbf534":"markdown","c0a7fa0c":"markdown","e0a1fd4e":"markdown"},"source":{"1cf9086f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b93268d9":"import matplotlib.pyplot as plt\nimport seaborn as sns","0fb412b7":"train = pd.read_csv('..\/input\/heart-attack-analysis-prediction-dataset\/heart.csv')\nsat = pd.read_csv('..\/input\/heart-attack-analysis-prediction-dataset\/o2Saturation.csv')","352f3a12":"train.head(5)","fc2586f4":"sat.head(5)","b31e20ea":"train","af658af7":"train.isna().sum()","bc3c8902":"train.info()","934a8563":"plt.figure(figsize=[12, 8])\nsns.violinplot(x='output', y='age', data=train, palette='plasma')","3165bee3":"plt.figure(figsize=[20, 10])\nsns.countplot(x='age', data=train, hue='output')","94b50139":"plt.figure(figsize=[20, 10])\nsns.countplot(x='sex', data=train, hue='output')","fcd4e7ae":"plt.figure(figsize=[20, 10])\nsns.countplot(x='sex', data=train, hue='cp')","10050f74":"plt.figure(figsize=[12, 8])\nsns.violinplot(x='sex', y='chol', data=train, hue='output', palette='plasma')","dcc7e079":"plt.figure(figsize=[12, 8])\nsns.violinplot(x='sex', y='fbs', data=train, hue='output', palette='plasma')","a2235154":"plt.figure(figsize=[20, 10])\nsns.countplot(x='sex', data=train, hue='restecg')","01e278ce":"plt.figure(figsize=[20, 10])\nsns.countplot(x='sex', data=train)","d9c705dd":"train","912ba9f9":"mask = np.zeros_like(train.corr())\ntri_ind = np.triu_indices_from(mask)\nmask[tri_ind] = True\nmask","26938364":"plt.figure(figsize=[20, 15])\nsns.heatmap(data=train.corr(), annot=True, mask=mask)","65fd7891":"from sklearn.model_selection import train_test_split","5618e7e1":"from sklearn.metrics import accuracy_score, classification_report","823ee6a7":"x = train.drop(['output', 'chol', 'fbs'], axis=1)\ny = train['output']\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=101)","f1631845":"from sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier","6a9e2d48":"models = []\nmodels.append(('LR', LogisticRegression(solver='liblinear')))\nmodels.append(('XGB', XGBClassifier(eta= 0.3,\n max_depth= 9,\n min_child_weight= 1,\n objective= 'reg:linear',\n subsample= 1)))","4921b9ca":"names = []\nscores = []\n\nfor name, model in models:\n    model.fit(x_train, y_train)\n    pred = model.predict(x_test)\n    scores.append(accuracy_score(y_test, pred))\n    names.append(name)\n    print(classification_report(y_test, pred))\n    \ntr_split = pd.DataFrame({'Name': names, 'Score': scores})\nprint(tr_split)","95904523":"from sklearn.model_selection import GridSearchCV","b50b3c02":"params = {\n    'max_depth':[6, 9],\n    'min_child_weight': [1, 4],\n    'eta':[.3, .6],\n    'subsample': [1, 4],\n    'objective':['reg:linear'],\n}\ngrid_xgb = GridSearchCV(estimator=models[1][1], param_grid=params)","7a0f1e81":"grid_xgb_pred = grid_xgb.fit(x_train, y_train)","0631c294":"grid_xgb_pred.predict(x_test)","bba487fa":"grid_xgb_pred.best_params_","e08155ee":"### We find that:\n* Chest pain type 0 is most common in both the genders.","6441ee05":"## Choosing best params for XGB","b6f0d524":"### We find that:\n\n* Gender 0 has more people having more chances of heart attacks as compared to Gender 1 which has more people in the range of less heart attacks.\n* The contrast between the people of both genders having less chances of heart attacks is very sharp. There is huge gap between the people of Gender 0 and Gender 1 having less chances of heart attacks.\n* But the contrast between the groups having more chances of heart attacks is comparitively less between the two genders as compared to the higher chances of heart attacks.\n\n### Conclusion: \n#### It's a little bit difficult to imagine which two groups are at an advantage just by looking at their ages and outcomes.","3848d748":"# Prediction","3a98b0b5":"## Between age and restecg","2eea3ffd":"### We find out that:\n* Very few people show probable or definite left ventricular hypertrophy in both genders.\n* Gender 1 have same no. of people having normal restecg and people having ST-T wave abnormality.\n","202e271d":"### Through Countplot","e05b264b":"### Now, the question again, which sex is at advantage?\n#### Well, I think each is at some advantage over another. As sex 0 has less no of people in it as compared to sex 1 which have people double than of  sex, the overall result is I think neutral. If one has less no of people with less chances of heart attack other has less no of people with more chances of heart attacks. ","4d491c64":"## Between sex and the chances","383bbd10":"# Visualizing","495357ac":"### As the co-relation between [chol, fbs] and 'output' is very close to 0, I'll neglect them in the training process.","2852486b":"## We find out that the :\n* people who have less chances of heart attack are concentrated around the median age of 58 years;\n* people who have more chances of heart attack are concentrated around the median age of 52 years\n\n#### But the distribution is not uniform i.e.\n* if we look closely at the graph of output 0 & output 1 we find that even though the median age for less chances of heart attack is 58 years, the chances of less heart attack decreases as the age increases which can be interpreted by the output (1).","5757f79d":"## Between sex and cholestrol","51ea16bc":"## Between Age and the chances ","7c245a05":"## How much of each sex?","cf39cf39":"### We find out that:\n* There are few people who have the probability of fasting blood sugar negative meaning that they don't have it as seen from the plot below.\n","8cdbf534":"## Between chest pain and sex","c0a7fa0c":"### So, I choose XGBClassifier with these parameters which gave me 88.5 % accuracy!","e0a1fd4e":"## Between sex and blood sugar"}}