{"cell_type":{"864145f5":"code","195bd206":"code","01f91685":"code","cec6a20c":"code","3fd9a225":"code","9fa7a10b":"code","86bb618e":"code","e962c411":"code","7d8441db":"code","3e1cf04e":"code","66f1b47d":"code","eabcd769":"code","c4919b25":"code","f4bb7b3b":"code","f81df4c6":"code","baf711e9":"code","1a47396e":"code","8c2bb7a4":"code","5b6978f3":"code","0cdaa5b6":"code","514b07f9":"code","497eebfe":"code","8729fd96":"code","df76fc35":"code","c64f6c97":"code","eed54ffc":"code","f6299bd8":"code","b843e65c":"code","2c5a4a68":"code","8db1ecba":"code","2dba9ac0":"code","f7fc3267":"code","9c7f2af4":"code","fe4d6e6f":"code","27328022":"code","1b830f44":"code","d1beef05":"code","bed02d1d":"code","d07ec9fa":"code","91d3391d":"code","062a1549":"code","8dd63f50":"code","165ce571":"code","fba80085":"code","0ad4532c":"code","4bedd1b3":"code","d177348d":"code","dcf13077":"code","648ddf3e":"code","4e440efb":"code","6940f3b7":"code","48730a03":"code","dc17a464":"code","36eb0666":"code","c41767e2":"code","88123bce":"code","3d790286":"markdown","db699c1f":"markdown","e2228109":"markdown","931efdcf":"markdown","86e7e154":"markdown","519b5600":"markdown","c5755ef9":"markdown","86fb022b":"markdown","fddbecec":"markdown","39255aca":"markdown","514a5c8d":"markdown","a207cc6f":"markdown","7d2bae83":"markdown","7279a206":"markdown","5ca45e94":"markdown","c6fb80ed":"markdown","3864895d":"markdown","485db0d6":"markdown","a4668958":"markdown","1682d95f":"markdown","2a960e9c":"markdown","d0feb85a":"markdown","6f52d120":"markdown","a1333937":"markdown","74469250":"markdown","fd8865e0":"markdown","22163cb9":"markdown","96c958c7":"markdown","c696e1d4":"markdown","4a66cb0f":"markdown","3a9f86f6":"markdown","55332d92":"markdown","d0e67dd8":"markdown","7a9c62d4":"markdown","4d10479e":"markdown","b43d1b5a":"markdown","1b4472b1":"markdown","1b9e7afe":"markdown","20031317":"markdown","43a1a82e":"markdown","59dfc400":"markdown","4c1e7894":"markdown","4596f919":"markdown","551a27f0":"markdown","c4865594":"markdown","7ff7ae23":"markdown","98faa68e":"markdown","12acf601":"markdown","fe041920":"markdown","54343105":"markdown","38a523d7":"markdown","49b43de9":"markdown","afb9a8a2":"markdown","7e4b5196":"markdown","673f9708":"markdown","de3690c9":"markdown","f6e649ae":"markdown","6a3d27d4":"markdown","ca902bc5":"markdown","aea5a646":"markdown","d92ff6f3":"markdown","18e6494e":"markdown","55635f12":"markdown","c2d51fbb":"markdown","c5c8532b":"markdown","012a4da8":"markdown","13662660":"markdown","a1e135eb":"markdown","e8fdb9af":"markdown","913e81df":"markdown","10e2d92b":"markdown","3a389f73":"markdown","df483cf8":"markdown","7ef8d0f2":"markdown"},"source":{"864145f5":"!pip install pyngrok","195bd206":"#streamlit ==> to define component of application\n! pip install streamlit","01f91685":"! pyngrok version","cec6a20c":"! streamlit version","3fd9a225":"!pip install writefile","9fa7a10b":"%%writefile app.py \n######### creating python script #########\n\nimport streamlit as st\n\n# Function to define out app\ndef main():\n    #page header\n    st.markdown('Loan Eligibility Checker')\n    \n    ###### 2. loading data ######\n    \n    ## creating boxes where user will provide information => we have 4 features in our data\n    Gender = st.selectbox('Gender',('male','female','other')) # creates a dropdown box\n    Married = st.selectbox('Marital Status',('married','unmarried','other'))\n    ApplicantIncome = st.number_input('monthly income in rupees') #numerical input box\n    LoanAmount = st.number_input('loan amount in rupees')\n    result = ''\n    \n    ## check => if clicked make a prediction and store it\n    if st.button('Check'):\n        result = prediction(Gender,Married,ApplicantIncome,LoanAmount) # calling 'prediction' function\n        st.success(f'Your Loan is: {result}') #display to frontend\n                           \n            \n# defining 'prediction' function => it will predict based on user input data\ndef predict(Gender,Married,ApplicantIncome,LoanAmount):\n    \n    ###### 3. building Rule based model to automate Loan eligibility ######\n    if (ApplicantIncome >=50000): # if loan ApplicantIncome greater or equall to 50k then approve \n        loan_status = 'Approved'\n    elif (LoanAmount < 500000): # elif loan amount less then 50 thou then approve\n        loan_status = 'Approved'\n    else:\n        loan_status = 'Rejected'\n    return loan_status\n\nif __name__ == '__main__':\n    main()","86bb618e":"!ls","e962c411":"# running app\n!streamlit run app.py >\/dev\/null","7d8441db":"# making locally-hosted web application to be publicly accessible\nfrom pyngrok import ngrok\n\npublic_url = ngrok.connect(port=8501)\npublic_url","3e1cf04e":"# disconect server use\n\nngrok.kill()","66f1b47d":"# required libs\nimport pandas as pd\nimport numpy as np\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","eabcd769":"# loading  dataset\npath = '\/kaggle\/input\/loan-data-final\/'\ndata = pd.read_csv(path+'loan_data.csv')\ndata.sample(5)","c4919b25":"data.shape","f4bb7b3b":"# converting categories into numbers\ndata['Gender']= data['Gender'].map({'Male':0, 'Female':1})\ndata['Married']= data['Married'].map({'No':0, 'Yes':1})\ndata['Loan_Status']= data['Loan_Status'].map({'N':0, 'Y':1})","f81df4c6":"# dependent and independent variables\nX = data[['Gender','Married','ApplicantIncome','LoanAmount']]\ny = data.Loan_Status","baf711e9":"# importing ML model\nfrom sklearn.linear_model import LogisticRegression\n\n# training logistic regression model\nmodel = LogisticRegression() \nmodel.fit(X,y)","1a47396e":"# saving model \nimport pickle \n'''\nSaving model as we will use it when neaded \nwe need not to run model again and times\n'''\n\npickle_out = open('classifier_model.pkl',mode ='wb')  # wb => write in binary mode\npickle.dump(model,pickle_out)  \npickle_out.close()","8c2bb7a4":"!ls","5b6978f3":"# installing pyngrok\n!pip install -q pyngrok","0cdaa5b6":"# installing streamlit\n!pip install -q streamlit","514b07f9":"%%writefile app.py\n\n# importing required libraries\nimport pickle\nimport streamlit as st\n\n# loading the trained model\npath_model = '.\/classifier_model.pkl'\npickle_in = open(path_model,'rb')  # rb => read binary file\nclassifier = pickle.load(pickle_in) # loading model in variable\n\n# this is main function in which we define our app  \ndef main():       \n    # header of the page \n    html_temp = \"\"\" \n    <div style =\"background-color:orange;padding:13px\"> \n    <h1 style =\"color:white;text-align:center;\">Check your Loan Eligibility<\/h1> \n    <\/div> \n    \"\"\"\n    st.markdown(html_temp,unsafe_allow_html=True) \n\n    # creating boxes for user input => data required to make prediction \n    Gender = st.selectbox('Gender',('Male','Female','Other'))\n    Married = st.selectbox('Marital Status',('Unmarried','Married','Other')) \n    ApplicantIncome = st.number_input('Monthly Income in INR') \n    LoanAmount = st.number_input('Loan Amount in INR')\n    result =\"\"\n      \n    # when 'Check' will be clicked => make prediction and store it \n    if st.button('Check'): \n        result = prediction(Gender,Married,ApplicantIncome,LoanAmount) \n        st.success(f'Your loan is: {result}') # display output to frontend\n \n# defining function which will make prediction using data which user inputs \ndef prediction(Gender,Married,ApplicantIncome,LoanAmount): \n\n    ########### 2. Loading and Pre-processing data ###########\n    # as input will be in object changing it into numbers\n    if Gender == 'Male':\n        Gender = 0\n    else:\n        Gender = 1\n\n    if Married == 'Married':\n        Married = 1\n    else:\n        Married = 0\n\n    ############ 3. Building ML model to automate Loan Eligibility  ###########\n    # prediction varible will have output as 0 or 1\n    prediction = classifier.predict([[Gender,Married,ApplicantIncome,LoanAmount]]) # use of previously made classifier varaible\n    \n    # if prediction is 0 reject loan else approve loan\n    if prediction == 0:\n        pred = 'Rejected'\n    else:\n        pred = 'Approved'\n    return pred # returning result\n     \nif __name__=='__main__': \n    main()","497eebfe":"# running app\n!streamlit run app.py &>\/dev\/null&","8729fd96":"# making locally-hosted web application to be publicly accessible\nfrom pyngrok import ngrok\n\npublic_url = ngrok.connect('8501')\npublic_url","df76fc35":"# importing required modules\nimport json\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n# importing pytorch related modules\nimport torch\nfrom torchvision import transforms\nfrom torchvision.models import densenet121","c64f6c97":"# defining pretrained densenet121 DL model\nmodel = densenet121(pretrained=True) # 121 => layers # pretrained = true as it is pretrained on imagenet dataset\nmodel.eval()","eed54ffc":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","f6299bd8":"# setting image path\npath = '\/kaggle\/input\/images\/images\/'\nfilename = path + 'dog.jpg'","b843e65c":"# loading image using PIL\ninput_image = Image.open(filename) \n\n# preprocessing image according to pretrained model\npreprocess = transforms.Compose(\n    [transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])]\n)\n\ninput_tensor = preprocess(input_image)\n\n# creating a mini-batch as expected by model\ninput_batch = input_tensor.unsqueeze(0) \n\n# pass input batch to model\nwith torch.no_grad():\n    output = model(input_batch)","2c5a4a68":"# this is original image\ninput_image","8db1ecba":"# above image is converted to tensor\nprint(input_tensor.shape)\ninput_tensor","2dba9ac0":"print(input_batch.shape)\ninput_batch","f7fc3267":"# getting prediction by applying softmax\n\npred = torch.nn.functional.softmax(output[0],dim=0).cpu().numpy()\nnp.argmax(pred)","9c7f2af4":"# downloading classes on which model was trained on \n!wget https:\/\/s3.amazonaws.com\/deep-learning-models\/image-models\/imagenet_class_index.json","fe4d6e6f":"# loading classes\nwith open('imagenet_class_index.json','r') as f:\n    classes = json.load(f) ","27328022":"# showing image and its class\nplt.imshow(input_image)\n\nprint(classes[str(np.argmax(pred))][1], round(max(pred)*100, 2))","1b830f44":"# install if required for you\n!pip install -q streamlit\n!pip install -q pyngrok","d1beef05":"# download imagenet classes\n!wget https:\/\/s3.amazonaws.com\/deep-learning-models\/image-models\/imagenet_class_index.json","bed02d1d":"%%writefile app.py\n\n###### Creating Streamlit APP ######\nimport json \nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom PIL import Image #python imaging library\nfrom torchvision import transforms\nfrom torchvision.models import densenet121\n\nimport streamlit as st\n\n\n# defining prediction function\ndef predict(image):\n    model = densenet121(pretrained=True) # loading Deep Learning pretrained model\n    model.eval()\n\n    # loading classes\n    with open('imagenet_class_index.json','r') as f:\n        classes = json.load(f)\n\n    # preprocessing image\n    preprocess = transforms.Compose(\n        [transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])]\n    )\n    input_tensor = preprocess(input_image)\n    input_batch = input_tensor.unsqueeze(0) # creating a mini-batch as expected by model\n\n    # getting prediction\n    with torch.no_grad():\n        output = model(input_batch) # giving batch to model for prediction\n\n    # using softmax function to convert output into classwise probabilities\n    pred = torch.nn.functional.softmax(output[0],dim=0).cpu().numpy()\n\n    # saving confidence and label to return\n    confidence = round(max(pred)*100, 2)\n    label = classes[str(np.argmax(pred))][1]\n    return confidence,label # returning confidence and label\n\n# defining an image file uploader\nimage = st.file_uploader('Upload image here') #file_uploader is a streamlit component\n\n# defining button for getting prediction\nif image is not None and st.button('See prediction'):\n    input_image = Image.open(image) # loading image using PIL\n    st.image(input_image,use_column_width=True) # showing image using streamlit\n    confidence,label = predict(input_image) # predict() returns confidence and label\n    # printing results\n    print(\"Model is\", confidence, \"% confident that this image is of a\", label)","d07ec9fa":"# running streamlit app\n!streamlit run app.py >\/dev\/null","91d3391d":"# make streamlit app available publicly using ngrok\nfrom pyngrok import ngrok\n\npublic_url = ngrok.connect('8501');\n\npublic_url","062a1549":"!pip install -q pyngrok\n!pip install -q streamlit==0.70\n\n# streamlit component which gives functionality of coding window\n!pip install -q streamlit_ace ","8dd63f50":"%%writefile example_code.py\n\ndef reverse(x: int) -> int:\n    \"\"\"\n    Given a 32-bit signed integer, reverse digits of an integer\n    \"\"\"\n    str_num = str(x)\n    is_negative = False\n    if str_num[0] == '-':\n        is_negative = True\n        str_num = str_num[1:]\n\n    sign = '-' if is_negative else '+'\n    num = int(sign + \"\".join(list(reversed(str_num))))\n\n    if -2**31 < num < 2**31-1:\n        return num\n    else:\n        return 0\n\nprint(reverse(123))","165ce571":"%%writefile SessionState.py\n\nimport streamlit.report_thread as ReportThread\nfrom streamlit.server.server import Server\n\n\n\"\"\"\nHack to add per-session state to Streamlit\nWorks for Streamlit >= v0.65\n\"\"\"\n\n\n\nclass SessionState():\n    \"\"\"\n    SessionState: Add per-session state to Streamlit\n    \"\"\"\n    def __init__(self, **kwargs):\n        for key, val in kwargs.items():\n            setattr(self, key, val)\n\n\ndef get(**kwargs):\n    # Hack to get session object from Streamlit\n    session_id = ReportThread.get_report_ctx().session_id\n    session_info = Server.get_current()._get_session_info(session_id)\n\n    if session_info is None:\n        raise RuntimeError('Could not get Streamlit session object')\n\n    this_session = session_info.session\n\n    # Got session object! Now let's attach some state into it\n    if not hasattr(this_session, '_custom_session_state'):\n        this_session._custom_session_state = SessionState(**kwargs)\n\n    return this_session._custom_session_state","fba80085":"%%writefile app.py\n\n# importing required modules and libraries\nimport time\nimport difflib\nimport textwrap\nimport SessionState\nimport streamlit as st\nfrom streamlit_ace import st_ace\n\n\n\nclass TypingTutor:\n    \"\"\"\n    Class for text generation in streamlit,\n    this class will code for both Back & Front-end of project\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        This function defines what happens when website starts i.e. :-\n        1. Creates session\n        2. Creates frontend\n        \"\"\"\n        ###### STEP-1 ######\n        ####### Defining Session ######\n        \"\"\"\n        utilizing SessionState- Class, defining 5 variable starting from start_time variable\n        will maintain this info for each session\n        Naming this state as ==> session_state\n        \"\"\"\n        self.session_state = SessionState.get(\n            name = \"typingSession\",\n            start_time = 0,\n            end_time = 0,\n            num_chars = 0,\n            text = \"\",\n            content = \"\",\n        )\n\n        ###### STEP-2 ######\n        \"\"\"\n        Creating Front-end Steps:\n            1. inside set_page_config layout='wide'\n        \"\"\"\n        st.set_page_config(page_title=\"Typing Tutor\", layout=\"wide\")\n\n        \"\"\"\n            2. setting title of page\n        \"\"\"\n        st.markdown(\"<h1 style='text-align: center; color: black;'>Typing Tutor<\/h1>\",unsafe_allow_html=True,)\n\n        \"\"\"\n            3. writing hints for new user\n        \"\"\"\n        placeholder = st.empty()\n        with placeholder.beta_container():\n            st.markdown(\"****\")\n            st.subheader(\"Steps to check your Typing speed\")\n            st.write(\n                \"1. When you are ready, click on start button which will generate code for you to write on left hand side.A point to note that timer starts as soon as you click on start button \")\n            st.write(\n                \"2. Start writing same code on code window given on right hand side.When you're done - press 'CTRL + ENTER' to save your code. **Remember to do this as this ensures that code you have written is ready for submission**\")\n            st.write(\n                \"3. Lastly, click on Check Speed button to check you writing accuracy and writing speed. Good luck!\")\n            st.markdown(\"****\")\n\n        \"\"\"\n        Creating two columns\n            * one for code generated\n            * other for code to write\n        Using streamlit beta_columns component as => st.beta_columns(2)\n        \"\"\"\n        self.col1, self.col2 = st.beta_columns(2)\n        \"\"\"\n        Defining start_button for col1\n        Setting subheader as Text to write\n        \"\"\"\n        with self.col1:\n            self.start_button = st.button(\"Start!\",key=\"start_button\")\n            st.subheader(\"Text to write\")\n        \"\"\"\n        Defining eval_button for col2\n        Setting subheader as Text Input\n        \"\"\"\n        with self.col2:\n            self.eval_button = st.button(\"Check Speed\", key=\"eval_button\")\n            st.subheader(\"Text Input\")\n            st.write(\"\")\n\n            \"\"\"\n            defining coding window inside 2nd col\n            Using streamlit ace component as => st_ace() => inside this we will use some arguments to define \n                our coding window\n            auto_update = False because we will use CTRL + Enter to update   \n            \"\"\"\n            self.session_state.content = st_ace(\n                placeholder = \"Start typing here ...\",\n                language = \"python\",\n                theme = \"solarized_light\",\n                keybinding = \"sublime\",\n                font_size = 20,\n                tab_size = 4,\n                show_gutter = True,\n                show_print_margin = True,\n                wrap = True,\n                readonly = False,\n                auto_update = False,\n                key = \"ace-editor\")\n\n    def on_start_click(self):\n        \"\"\"\n        This function defines what happens when start button is clicked,\n            1. Internally calls _code_gen() to generate code\n            2. Modifies session state variables (start_time, text, num_chars)\n            3. Updates front-end accordingly\n            \n        As every update will take place in col1 or left hand side while start click button will be trigered \n        so we are using col1 now\n        \"\"\"\n        with self.col1:\n            ###### STEP-1 ######\n            \"\"\"\n            Saving generated text\n            get prediction\n            \"\"\"\n            self.session_state.text = self._code_gen()\n\n            ###### STEP-2 ######\n            \"\"\"\n            modify session state named as:\n                1. session_state.text\n                2. session_state.num_chars\n                3. session_state.start_time\n            \"\"\"\n            self.session_state.num_chars = len(self.session_state.text)\n            self.session_state.start_time = time.time()\n\n            ######  STEP-3 ######\n            \"\"\"\n            writing code using streamlit on page\n            Using stremlit.code method as st.code => to write code\n            Using textwrap.dedent function => to get proper indentation to generated code\n            \"\"\"\n            st.code(textwrap.dedent(self.session_state.text))\n\n    # defining _code_gen method\n    def _code_gen(self):\n        \"\"\"\n        Function for text generation\n        \n        1. Open example_code.py file in read mode\n        2. Store content of file in variable named as text and return it\n        \"\"\"\n        with open(\"example_code.py\", \"r\") as f:\n            text = \"\".join(f.readlines())\n        return text\n\n    # defining on_eval_click method\n    def on_eval_click(self):\n        \"\"\"\n        This function defines what happens when eval button is clicked\n            1. Internally calls _get_perf() function to calculate performance\n            2. Modifies session state variables (end_time, content)\n            3. Updates front-end accordingly\n        \"\"\"\n\n        ###### STEP-1 ######\n        \"\"\"\n        calculating typing speed and accuracy\n        \n        calling _get_perf() method, it returns peformance named as:\n            1. speed => Typing speed\n            2. accuracy => Typing accuracy\n        \"\"\"\n        speed,accuracy = self._get_perf()\n\n        ###### STEP-3 ######\n        \"\"\"\n        write performance of user using streamlit\n        \n        Setting above Typing speed and accuracy to front-end \n        will calculate Typing speed in WPM=>words per minute\n        \"\"\"\n        with self.col1:\n            st.write(\"Time to write:\",round(speed),\"WPM\")\n            st.write(\"Accuracy:\",round(accuracy * 100, 2), \"%\")\n\n    # _get_perf method will be called internally\n    def _get_perf(self):\n        \"\"\"\n        Function to get accuracy and typing speed\n        \"\"\"\n        ###### STEP-2 ######\n        \"\"\"\n        it modify session state which is (end_time) here itself\n        \"\"\"\n        self.session_state.end_time = time.time() - self.session_state.start_time\n\n        \"\"\"\n        getting typing speed of user \n        based on num_chars typed and end_time\n        Typing speed is being calculated in WPM=>words per minute \n        \"\"\"\n        speed = ((self.session_state.num_chars \/ self.session_state.end_time) \/ 5) * 60\n\n        \"\"\"\n        get typing accuracy of user\n            comparing two things: generated and written code\n        using difflib library's SequenceMatcher method for this as => difflib.SequenceMatcher\n        difflib library => standard library in python\n        according to comarison done we will take ratio()\n        return speed and accuracy of typing speed\n        \"\"\"\n        accuracy = difflib.SequenceMatcher(None,self.session_state.text,self.session_state.content).ratio()\n        return speed,accuracy\n\n# defining main function\nif __name__ == \"__main__\":\n    \"\"\"\n    creating instance of class inside main function as => TypingTutor() class\n    \"\"\"\n    tt = TypingTutor()\n\n    \"\"\"\n    call appropriate method based on button is clicked\n        Down here if start_button is clicked we are calling on_start_click() method \n    \"\"\"\n    if tt.start_button:\n        tt.on_start_click()\n\n    \"\"\"\n    if eval button is clicked calling for on_eval_click() method\n    \"\"\"\n    if tt.eval_button:\n        tt.on_eval_click()","0ad4532c":"# running streamlit app\n!streamlit run app.py >\/dev\/null","4bedd1b3":"# making streamlit app available publicly using pyngrok\nfrom pyngrok import ngrok\n\npublic_url = ngrok.connect('8501')\n\npublic_url","d177348d":"# installing transformers library by Huggingface\n!pip install -q transformers ","dcf13077":"# import required modules\n\"\"\"\nimporting choice method from random library\n\"\"\"\n\nfrom random import choice\n\n\"\"\"\nAutoTokenizer module => to preprocess wrt to AutoModelWithLMHead\nAutoModelWithLMHead module =>  to load pretrained model\n\"\"\"\nfrom transformers import AutoTokenizer, AutoModelWithLMHead","648ddf3e":"# defining pretrained text generation model\n\"\"\"\ncongcongwang\/distilgpt2_fine_tuned_coder => fined tuned GPT-2 model, it is first pretrained on Wikipedia dataset and then finetuned \nwith algorith repos\n    We are loading both tokenizer and model\n\"\"\"\n\ntokenizer = AutoTokenizer.from_pretrained('congcongwang\/distilgpt2_fine_tuned_coder')\nmodel = AutoModelWithLMHead.from_pretrained('congcongwang\/distilgpt2_fine_tuned_coder')","4e440efb":"# setting seed text Why???\n\"\"\"\nAs this is a text generation model it require seed text\nSeed text => text which is given as an input to out text generation model \n            so that it can generate text after this seed text\n\nFor this model we have to give name of function i.e. convert_to_num\n\"\"\"\ncontext = \"def convert_to_num\"\n\n# preprocessing seed text How??\n\"\"\"\nUsing tokenizer which we imported before \n    Specifying language as python as => \"<python> \"\n    Passing in seed text as => context\nSaving preprocessed input into input_ids variable\n\"\"\"\ninput_ids = tokenizer.encode(\"<python> \" + context, return_tensors='pt')\n\n# generate output using model method  => generate\n\"\"\"\nAs our aim is to produce diff code for diff instance so we have to update hyper-parameter \nthat way only\n\"\"\"\noutputs = model.generate(input_ids = input_ids, # passing in input ans after some hyper-parameter\n                         max_length = 512,     # max length of text generated \n                         temperature = 0.7,    # variability of text | ranges: 0 to 1 | 1 for most variability\n                         num_beams = 2,        # ensures diversity of words ranther then char in text\n                         length_penalty = 1.5) # give variability in text length \n\n# decode output to generate text\ndecoded = tokenizer.decode(outputs[0],skip_special_tokens=True)\nprint(decoded)","6940f3b7":"# setting different seed texts Why??\n\"\"\"\nTo add more variability we are convinced to add more seed texts \n\"\"\"\ncontexts = [\"def fib\", \"def fact\", \"def sum_of_int\", \"def sum_of_fact\", \"def sum_of_squares\", \"def get_val\", \"def convert_to_num\", \"def get_date\"]\n\n# choosing seed text\n\"\"\"\nUsing choice() method we can choose only one seed at a time\n\"\"\"\ncontext = choice(contexts)\n\n# preprocessing seed text\ninput_ids = tokenizer.encode(\"<python> \" + context, return_tensors='pt')\n\n# generating output using model\noutputs = model.generate(input_ids = input_ids,\n                         max_length = 512,\n                         temperature = 0.7,\n                         num_return_sequences = 1,\n                         num_beams = 2,\n                         length_penalty = 1.5)\n\n# decoding output to generate text\ndecoded = tokenizer.decode(outputs[0],skip_special_tokens=True)\nprint(decoded)","48730a03":"# for pretrained dl model\n!pip install -q transformers\n\n# for deployment on kaggle or colab\n!pip install -q pyngrok\n!pip install -q streamlit==0.70\n\n# streamlit component for creating coding window for website\n!pip install -q streamlit_ace ","dc17a464":"%%writefile SessionState.py\n\nimport streamlit.report_thread as ReportThread\nfrom streamlit.server.server import Server\n\n\n\"\"\"\nHack to add per-session state to Streamlit\nWorks for Streamlit >= v0.65\n\"\"\"\n\n\n\nclass SessionState():\n    \"\"\"\n    SessionState: Add per-session state to Streamlit\n    \"\"\"\n    def __init__(self, **kwargs):\n        for key, val in kwargs.items():\n            setattr(self, key, val)\n\n\ndef get(**kwargs):\n    # Hack to get session object from Streamlit\n    session_id = ReportThread.get_report_ctx().session_id\n    session_info = Server.get_current()._get_session_info(session_id)\n\n    if session_info is None:\n        raise RuntimeError('Could not get Streamlit session object')\n\n    this_session = session_info.session\n\n    # Got session object! Now let's attach some state into it\n    if not hasattr(this_session, '_custom_session_state'):\n        this_session._custom_session_state = SessionState(**kwargs)\n\n    return this_session._custom_session_state","36eb0666":"%%writefile app.py\n\n# importing required modules and libraries\nimport time\nimport difflib\nimport logging   # to debug website\nimport textwrap\nimport SessionState\nimport streamlit as st\n\nfrom random import choice\nfrom streamlit_ace import st_ace\nfrom tokenizers import AddedToken\nfrom transformers import AutoTokenizer, AutoModelWithLMHead\n\n\n\n# defining seed text\nCONTEXTS = [\n    \"def fib\",\n    \"def fact\",\n    \"def sum_of_int\",\n    \"def sum_of_fact\",\n    \"def sum_of_square_error\",\n    \"def get_val\",\n    \"def convert_to_num\",\n    \"def convolute\",\n    \"def dict_sort\"]\n\n# caching _load_model function so that it called only once\n@st.cache(hash_funcs={st.delta_generator.DeltaGenerator: lambda x: None,AddedToken: lambda x: None,\"_regex.Pattern\": lambda x: None,},allow_output_mutation=True)\n\ndef _load_model():\n    \"\"\"\n    Function to define pretrained text generation model\n    \"\"\"\n    tokenizer = AutoTokenizer.from_pretrained(\"congcongwang\/distilgpt2_fine_tuned_coder\")\n    model = AutoModelWithLMHead.from_pretrained(\"congcongwang\/distilgpt2_fine_tuned_coder\")\n    model.eval()\n    return tokenizer,model\n\n###################################################################################\n\nclass TypingTutor:\n    \"\"\"\n    Class for text generation in streamlit\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        This function defines what happens when website starts :-\n            1. Creates session\n            2. Creates the frontend \n            3. Loads DL model\n        \"\"\"\n\n        ###### Step 1 ######\n        # defining session\n        self.session_state = SessionState.get(\n            name=\"typingSession\",\n            start_time=0,\n            end_time=0,\n            num_chars=0,\n            text=\"\",\n            content=\"\")\n\n        ###### Step 2 ######\n        # creating frontend\n        st.set_page_config(page_title=\"Typing Tutor\", layout=\"wide\")\n\n        # set title of the page\n        st.markdown(\"<h1 style='text-align: center; color: black;'>Typing Tutor<\/h1>\",unsafe_allow_html=True)\n\n        # writing hints for a new user\n        placeholder = st.empty()\n        with placeholder.beta_container():\n            st.markdown(\"****\")\n            st.subheader(\"Steps to check your Typing speed\")\n            st.write(\"1. When you are ready, click on the start button which will generate code for you to write on the left hand side. A point to note that the timer starts as soon as you click on the start button\")\n            st.write(\"2. Start writing the same code on the code window given on the right hand side. When you're done - press 'CTRL + ENTER' to save your code. **Remember to do this as this ensures that the code you have written is ready for submission**\")\n            st.write(\"3. Lastly, click on Check Speed button to check you writing accuracy and the writing speed. Good luck!\")\n            st.markdown(\"****\")\n\n        # creating two columns, one for code generated and other for code to write\n        self.col1,self.col2 = st.beta_columns(2)\n\n        with self.col1:\n            self.start_button = st.button(\"Start!\",key=\"start_button\")\n            st.subheader(\"Text to write\")\n\n        with self.col2:\n            self.eval_button = st.button(\"Check Speed\",key=\"eval_button\")\n            st.subheader(\"Text Input\")\n            st.write(\"\")\n\n            # defining coding window\n            self.session_state.content = st_ace(\n                placeholder = \"Start typing here ...\",\n                language = \"python\",\n                theme = \"solarized_light\",\n                keybinding = \"sublime\",\n                font_size = 20,\n                tab_size = 4,\n                show_gutter = True,\n                show_print_margin = True,\n                wrap = True,\n                readonly = False,\n                auto_update = False,\n                key = \"ace-editor\")\n\n        ###### Step 3 ######\n        # loading model and store it for use\n        self.tokenizer, self.model = _load_model()\n\n    def on_start_click(self):\n        \"\"\"\n        This function defines what happens when start button is clicked,\n            1. Internally calls _code_gen() to generate code\n            2. Modifies session state variables (start_time, text, num_chars)\n            3. Updates the front-end accordingly\n        \"\"\"\n        with self.col1:\n            ###### Step 1 ######\n            # choosing seed text\n            context = choice(CONTEXTS)\n\n            # getting prediction\n            self.session_state.text = self._code_gen(context)\n\n            ###### Step 2 ######\n            # modifying session state\n            self.session_state.num_chars = len(self.session_state.text)\n            self.session_state.start_time = time.time()\n\n            ###### Step 3 ######\n            # writing code using streamlit on page\n            st.code(textwrap.dedent(self.session_state.text))\n\n        # logging\n        logging.info(f\"On start click, start time is {self.session_state.start_time}\")\n        logging.info(f\"On start click, num_chars to type are {self.session_state.num_chars}\")\n\n    def _code_gen(self, context):\n        \"\"\"\n        Function for DeepLearning model inference\n        \"\"\"\n        # preprocessing seed text\n        input_ids = self.tokenizer.encode(\"<python> \" + context, return_tensors=\"pt\")\n        # generating output\n        outputs = self.model.generate(\n            input_ids=input_ids,\n            max_length=256,\n            temperature=0.7,\n            num_beams=2,\n            length_penalty=1.5)\n        # decoding output to generate text\n        text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n        return text\n\n    def on_eval_click(self):\n        \"\"\"\n        This function defines what happens when the eval button is clicked\n            1. Internally calls _get_perf() to calculate performance\n            2. Modifies session state variables (end_time, content)\n            3. Updates the front-end accordingly\n        \"\"\"\n\n        ##### Step 1 #####\n        # calculating typing speed and accuracy\n        speed, accuracy = self._get_perf()\n\n        ##### Step 3 #####\n        # writing performance of user using streamlit\n        with self.col1:\n            st.write(\"Time to write:\", round(speed), \"WPM\")\n            st.write(\"Accuracy:\", round(accuracy * 100, 2), \"%\")\n\n        # logging\n        logging.info(f\"On eval click, current time is {time.time()}\")\n        logging.info(f\"On eval click, start time is {self.session_state.start_time}\")\n        logging.info(f\"On eval click, end time is {self.session_state.end_time}\")\n        logging.info(f\"On eval click, speed is {speed}\")\n\n    def _get_perf(self):\n        \"\"\"\n        Function to get accuracy and typing speed\n        \"\"\"\n        ##### Step 2 #####\n        # modifying session state\n        self.session_state.end_time = time.time() - self.session_state.start_time\n        # getting typing speed of  user\n        speed = ((self.session_state.num_chars \/ self.session_state.end_time) \/ 5) * 60\n        # getting typing accuracy of  user\n        accuracy = difflib.SequenceMatcher(None, self.session_state.text, self.session_state.content).ratio()\n        return speed, accuracy\n\n\nif __name__ == \"__main__\":\n    logging.info(f\"Starting init\")\n    # creating instance of class\n    tt = TypingTutor()\n    logging.info(f\"Done with init\")\n\n    # calling appropriate method if start button is clicked\n    if tt.start_button:\n        logging.info(f\"Start button clicked at {time.time()}\")\n        tt.on_start_click()\n        logging.info(f\"Done with Start button\")\n\n    # calling appropriate method if eval button is clicked\n    if tt.eval_button:\n        logging.info(f\"Eval button clicked at {time.time()}\")\n        tt.on_eval_click()\n        logging.info(f\"Done with Eval button\")","c41767e2":"# running streamlit app\n!streamlit run app.py --logger.level=info >log.txt","88123bce":"# making streamlit app available publicly\nfrom pyngrok import ngrok\n\npublic_url = ngrok.connect('8501');\n\npublic_url","3d790286":"### 3 Deploy Deep Learning model on Colab,kaggle kernel","db699c1f":"**`NOTE:`**<br>\nIf not working here then you can use manual process:\n1. Make a app.py file and copy whole code in that (do all this outside of the notebook)\n2. Run these comands in terminal","e2228109":"#### [argmax basic](https:\/\/www.geeksforgeeks.org\/numpy-argmax-python\/)","931efdcf":"<center><h5>What you can try more with this model<\/h5><\/center><br>\n\nYou can `try and experiment with different settings and see which of combinations work for you and give better results`<br> \nApproaching problem statement<br>\n1. Change `max length` in model generation \n2. Change `temperature` i.e. variability of model generation \n3. Change `num_beams` parameter of model generation \n4. Change `length_penalty` i.e. variability of model generation using  \n\n\n### `Now we have to integrate this Text generation Model to Front-end we have created in past steps`","86e7e154":"NLP Project\n<center> <h2 style=\"background-color:orange; color:white\" ><br>Project-2 (Typing Master)-textGeneration<br><\/h2><\/center>\n\n### Steps\n1. Points on Project\n2. Creating Front-end\n3. Building Text Generation Model\n4. Deploying model using Streamlit and AWS\n5. Setting up an Accesible website","519b5600":"## 3. Building Loan Prediction Model","c5755ef9":"Now it's time to transfer this model to an AWS system as to deploy this DL model ","86fb022b":"### `NOTE`\nIf you are using Google Colab or Kaggle Kernel or Local IDE. It becomes hard to always run them\n* In term of google colab and Kaggle kernel they shut down after a certain time so to deal with it `we will AWS`\n\nGoogle Colab and Kaggle Kernel's are best for experimentation purpose only, for hosting we will migrate our code to AWS","fddbecec":"---\n---\n\nComputer Vision Project\n\n<center> <h2 style=\"background-color:orange; color:white\" ><br>Making and Deploying Image Classification model using AWS & Stremlit (Pytorch)<br><\/h2><\/center>\n\n`Problem Statement`:<br>\nWhat object is in the image say dog or cat...<br>\n\n1. I am using a pretrained Deep Learning model ==> `DenseNet`, `trained on ImageNet Dataset`\n    * ImageNet Dataset have mill of images of thou of objects","39255aca":"### 2. SettingUp Deep Learning Model using `Streamlit`","514a5c8d":"<center> <h4 style=\"background-color:orange; color:white\" ><br>Creating Project Front-end<br><\/h4><\/center>\n\nFocusing on creating Front-end removing deep learning part for now from flow chart<br>\nSteps:\n1. Install required libraries\n2. Setup Typing Tutor using streamlit\n3. Deploy Typing Tutor on Colab or Kaggle Kernel if possible","a207cc6f":"### 1. Installing required libraries","7d2bae83":"### Steps to make this Typing Master Project\n1. Deploying model using `Streamlit` on `AWS` ==> (Front-end)\n    * Insatalling required lib\n    * Setting up Deep Learning model using Streamlit\n    * Deploy Deep Learning model on Kaggle kernel if not possible then Google Colab\n2. Build a `Text Generatin Model` ==> (Back-end)\n    * Installing required lib\n    * Define Deep Learning model \n    * Preprocess data and get prediction\n    * Deploy Deep Learning model on AWS","7279a206":"This is the code produced, there are some problem in this code:\n1. This code will produce Syntex Error, but our aim is only to write the code not execution\n\nSo we are good to go with it","5ca45e94":"Some more points on above code:\n* `class` ==> can be created in Pyton by using keyword `class` \n    * It is used to create object\n* `_code_gen() function` => used to generate text\n* `get_perf() function` => used to calculate speed and accuracy\n* `on_eval_click() function` internally calls `get_perf() function`\n    * `on_start_click function` => calles `_code_gen function` and `modify state variables`\n* `__init__ method` is automatically called when an object\/instance of a class is created\n    * `it allows class to initialize attributes of class`","c6fb80ed":"# 1. Building Frontend of application\n\n1.1. `Install Required Libraries` <br>\n1.2. `Creat Frontend of app using Streamlit`","3864895d":"#### 4. Deploying application","485db0d6":"If these code are not working in Kaggle use Coalb and everything will work so fine.\nIn case of any problem you can msg me","a4668958":"#### 1. Points on Project\n* Front-end => Streamlit\n* Back-end => transformer library from hugging face\n    * This lib gives pretrained deep learning model \n    * we will use `GPT2 Model `=> firstly trained on wikipedia dataset and then finetuned on python code\n* Python code on which model is finetuned on is based on [this](https:\/\/github.com\/TheAlgorithms\/Python) repo\n\n### [openai-gpt2-text-generator-python](https:\/\/www.analyticsvidhya.com\/blog\/2019\/07\/openai-gpt2-text-generator-python\/)","1682d95f":"# 4. Deploying application","2a960e9c":"If not working here you can run it using Terminal\/CMD","d0feb85a":"---\n---","6f52d120":"<center> <h4 style=\"background-color:orange; color:white\" ><br>Integrating Project(Text Generation Model) Front & Back-End with Deployment using Streamlit on AWS<br><\/h4><\/center>\n\n\n### 1. Deploying Text Generation model Steps\n1. Install required libraries\n2. Setup Deep Learning model using streamlit\n3. Deploy Deep Learning model on Kaggle(if possible) and Google Colab","a1333937":"### 2.4 Deploying Project on Kaggle or Google Colab","74469250":"#### 2.2. Defining class SessionState file to maintain single session per login\n\n##### [Hack to add per-session state to Streamlit](https:\/\/gist.github.com\/FranzDiebold\/898396a6be785d9b5ca6f3706ef9b0bc)","fd8865e0":"<center> <h4 style=\"background-color:orange; color:white\" ><br>Deploying ML Model using Streamlit<br><\/h4><\/center>\n\n## Steps to build Loan Eligibility model\n\n1. Loading dataset\n2. Pre-processing dataset\n3. Building Loan Prediction model\n4. Deploying machine learning model using Streamlit","22163cb9":"`PyTorch uses dynamic computaion graphs from tensors and automatically computes gradient`\n\nPy-torch Tensors can also keep track of a computational graph and gradients using `autograd package` which provides automatic differentiation to automate computation of backward passes in neural networks. \n","96c958c7":"### 1. Defining Deep Learning Model\n","c696e1d4":"`ngrok allows you to expose a web server running on your local machine to Internet`\n\nWhen you start ngrok, it will display a UI in your terminal with public URL of your tunnel and other status and metrics information about connections made over your tunnel \n","4a66cb0f":"### 2. Defining Deep Learning Model","3a9f86f6":"### 2. Settingup Typing Tutor using Streamlit\n`We will use example_code.py file instead of text generation model` for now only, to make it simple","55332d92":"Defining class SessionState file to maintain single session per login","d0e67dd8":"Why we need to download `imagenet classes`???<br>\nAs imagenet classes will used to represent Classes in string format(i.e. we can read and understand what class a image belong to) rather then numbers\n\n----\n\nSteps to setup DL or ML model using Streamlit:\n1. Make a app.py file\n2. Put code for front and backhand inside app.py file","7a9c62d4":"<center> <h4 style=\"background-color:orange; color:white\" ><br>Project's to Deploy<br><\/h4>\n\n|Project | Description|\n|-------|-------|\n|Loan Eligibility Application(Finance Industry -Tabular Data) | Building an application to automate Loan Eligibility process for a Bank|\n|Cardiac Arrest Prediction(HealthCare Industry -Tabular Data) | Building an application where users can check their chances of having a cardiac arrest|\n|Image Classification(Computer Vision Domain -Unstructured Data) | Using a Pre-trained model to Classify Images into different categories|\n|Typing Tutor(NLP Domain -Unstructured Data)  |Using a text generation model to generate code and then analyze typing speed|\n|Transcript Generation | Generating Transcript for videos and Deploying that model using `Flask`|\n<\/center>","4d10479e":"<center> <h4 style=\"background-color:orange; color:white\" ><br>Tools Covered-(Model Deployment)<br><\/h4><\/center>\n\n\n1. `Google Colab`\n2. `Streamlit` => opensource app framework\n3. `AWS` => cloude computing service\n4. `Amazone Sagemaker` => ML Service by amazon\n    * Used to Build, Train and Deploy Models\n5. `Flask` => web framework written in Python","b43d1b5a":"## 4. Deploying machine learning model using Streamlit\n\n1. Building Frontend of application\n2. Loading and Pre-processing data\n3. Building Machine Learning model to automate Loan Eligibility\n4. Deploying application","1b4472b1":"#### 1.1. `Install Required Libraries` ","1b9e7afe":"### 1. Installing required libraries","20031317":"<center> <h4 style=\"background-color:orange; color:white\" ><br>Deploying Above Model using Streamlit<br><\/h4><\/center>\n\nSTEPS:\n1. Install required libraries\n2. Setup DL model using streamlit\n3. Deploy DL model on Colab\n","43a1a82e":"<center> <h4 style=\"background-color:orange; color:white\" ><br>Deploying Above Model using Streamlit & AWS<br><\/h4><\/center>\n\n1. Create a AWS instance \n2. Use Public DNS adress to loging into Instance, use command in terminal\/cmd => ssh -i '''path of key''' ubuntu@'''DNS adress''' \n    * You must be loged in now\n3. Create a new folder, use this as to deploy dl model => mkdir model_dl => cd model_dl\n4. Download imagenet classes inside this folder => !wget https:\/\/s3.amazonaws.com\/deep-learning-models\/image-models\/imagenet_class_index.json\n5. create a file name app.py, copy streamlit code into it\n6. deploy this model => stramlit run app.py\n    * Click external url, use to open streamlit deploid model in AWS\n7. Drag dog image it will show class label and %tg for the image","59dfc400":"### Steps to Build Image Classification Using Deep Learning `Pretrained Mode`:\n1. Define DL model \n2. Preprocess data\n3. See for prediction from model","4c1e7894":"<center> <h4 style=\"background-color:orange; color:white\" ><br>Creating Project Back-end<br><\/h4><\/center>\n\nNow Will create Text Generation Model using a pretrained Deep Learning Model using steps:\n1. Install required libraries\n2. Define deep learning model\n3. Preprocess data and get prediction","4596f919":"If you are using Kaggle Kernel or Google Colab then `restart runtime` before running code\n\n1. Go to above `Run`-in kaggle kernel or `Runtime`-in google colab\n2. Restart runtime","551a27f0":"### 1. Installing required libraries\nWill use Huggingface `transfomers` for using pretrained model of text generation","c4865594":"## 1. Loading dataset","7ff7ae23":"<center> <h4 style=\"background-color:orange; color:white\" ><br>6 Stages of ML Lifecycle<br><\/h4><\/center>\n\n1. `Problem Definition`\n2. `Hypothesis Generation`\n3. `Data Collection`\n4. `Data Exploration and  Pre-Processing`\n    * Variable Idenification\n    * Univariate Analysis\n    * Bivariate Anaysis\n    * Missing Value Treatment\n    * Outlier Treatment\n    * Variable Transformation\n5. `Model Building`\n    * Supervised Learning\n    * Un-Supervised Learning\n    * Reinforcement Learning\n6. `Model Deployment and Monitoring`","98faa68e":"|Batch Processing or Ofline Batch Processing | Real Time |\n|----|-----|\n|Working ofline | real time|\n|We have train and test test | speed and feasibility is required|\n|time not a issue | time is crusial|\n\n\n\n### Deploying ML Model using `Streamlit and Google Colab`\n1. Build Loan Eligibility Application\n2. Intro to Streamlit => a web development framework\n3. Deploy ML model using Streamlit and Google Colab\n\n### Deploy ML model using `Streamlit and AWS`\n1. Intro to AWS\n    * setup AWS server\n2. Deploy ML model using Streamlit and AWS\n\n### Deploy Image classification model using Streamlit and AWS\n1. Build Image Classification Model\n2. Deploy model using Streamlit and AWS\n\n### Deploy Text Generation model using `Streamlit and AWS`\n1. Build Text Generation model\n2. Deploy model using Streamlit and AWS\n\n### `Amazon Sagemaker` for model deployment\n1. Intro Amazon Sagemaker\n2. Setting up Amazon Sagemaker\n3. Build a Cardiac Arrest Predictor\n4. Deploy model using Amazon Sagemaker\n\n### `Deploy Models using API's`\n1. Overview of Flask\n2. Understanding API's\n3. Deploy model using `Flask`\n4. Deploy deep learning model using `Flask`\n","12acf601":"Model is predicting image class as `Labrador_retriever` with `89.73%` confidence \n\n---\nI will also try and experiment with different models and techniques and will observe which will give better results\n\nDifferent approaches I am thinking to try\n1. Trying a different pretrained model from `torchvision.models` library like `Inception, Mobilenet` \n2. Taking average prediction from atlest three different Deep Learning models to `Ensemble` them \n---","fe041920":"`1.2. Creating Frontend of app using Streamlit` \n\n[Streamlit Functions](https:\/\/docs.streamlit.io\/library\/api-reference\/data)","54343105":"\n <center> <h2 style=\"background-color:orange; color:white\" ><br> Deploying Machine Learning and Deep Learning Models<br><\/h2>","38a523d7":"### 2. Setup Deep Learning model using streamlit","49b43de9":"Simply click above link's to see deployment.\n* if not working use Google Colab with same code","afb9a8a2":"### Blueprint of Project\n1. `Define two classes named as` \n    * `TypingTutor` => main class used to define both Front & Back End of Project (can say class used for text generation in Streamlit)\n    * `SessionState` => internall used by website to maintian session per user (can say class used for maintaining session per user)\n        * everytime user click start buton, a new session is created for user\n        * untill user will complete all steps, session contin...\n        \n2. `TypingTutor Class have these 5 Main Methods used inside it`: (Remember in OOP's function inside a class is called Method)\n    * `__init__` ==> defines what happens when session starts\n    * `_code_gen()` ==> function for text generation\n    * `_get_perf()` ==> function to get typing speed and accuracy\n    * `on_start_click()` ==> defines what happens when Start button is clicked\n    * `on_eval_click()` ==> defines what happens when Eval button is clicked\n    \n3. `SessionState Class have these 5 variables` (maintained per session)\n    * `start_time` ==> time when user start writing code\n    * `end_time` ==> time when user start written code\n    * `num_chars` ==> number of char to write\n    * `text` ==> overall code to be written\n    * `content` ==> code written by user\n ","7e4b5196":"### 3 Getting Prediction\nTo pass this image as class first convert it by applying `Softmax`\n\nApply Softmax function to an n-dimensional input Tensor rescaling them so that elements of n-dimensional output Tensor lie in range: <br> \n* [0,1] and \n* sum to 1\n\n[Visit this link for activation Fucntion](https:\/\/media.geeksforgeeks.org\/wp-content\/uploads\/20190326164502\/1265.png)","673f9708":"### 2 Preprocessing Data","de3690c9":"#### 1.2. Creating frontend of app using Streamlit","f6e649ae":"<center> <h4 style=\"background-color:orange; color:white\" ><br>Frontend of Loan Eligibility App<br><\/h4><\/center>\n\nWe can use:\n1. HTML with CSS\n2. Javascript\n3. `Streamlit` ==> one of rescent option\n    * Turns data scripts into Shareable web application\n    * All in python\n    * No frontend experience required\n    * Opensource all free\n    \n### Why we are using Streamlit for front-end???\n1. Model Building\n2. Creating Python Scrip\n3. Create frontend in Python\n4. Deploy\n\n### Without Streamlit steps will be\n1. Model Building\n2. Creating Python Scrip\n3. Write Flask or other Application\n4. Create frontend in javascript\n5. Deploy <br>\nWe will require java and flask knowledge","6a3d27d4":"<center> <h4 style=\"background-color:orange; color:white\" ><br>Deploying Rule Based Model using Streamlit<br><\/h4><\/center>\n\n#### [Available Functions in Streamlit](https:\/\/docs.streamlit.io\/library\/api-reference)\n\nSteps:\n1. Build Frontend of application\n2. Load data\n3. Build model to automate Loan Eligibility\n4. Deploy application\n\nAs this is rule based model so no need to preprocess the model","ca902bc5":"#### 1. Building Frontend of application\n\n1.1. Installing Required Libraries<br>\n1.2. Creating Frontend of app using Streamlit","aea5a646":"`cpu()` moves a tensor back to memory accessible to the CPU\n* Some operations on tensors cannot be performed on cuda tensors so you need to move them to cpu first\n\n* Model was trained on GPU and hence tensors are on GPU\n    * Now, to perform some operations, like calculating label, we need to move tensor back to CPU and hence we have used .cpu()","d92ff6f3":"### 1. InstallING required libraries","18e6494e":"<center> <h3 style=\"background-color:orange; color:white\" ><br>Project-1 Loan Eligibility Application<br><\/h3><\/center>\n\nProblem: A bank wants to build an application that can automate Loan Eligibility Process for its customer. In application customer will Fill there details and can chech for the results <br>\nBank want to use 4 attributes:\n* Gender\n* Maritial Status\n* Monthly Income in INR\n* Loan Amount in INR\n\nA check buton to see results based on details filled","55635f12":"### [Why using this `->` notation in Python Code](https:\/\/medium.com\/@thomas_k_r\/whats-this-weird-arrow-notation-in-python-53d9e293113)","c2d51fbb":"Streamlit host application on 8501 port bydefault <br>\nThis model is running locally for now <br>\nTo make it accessible to everyone(public):\n* using `pyngrok lib`","c5c8532b":"### 3. Deploying Deep Learning model on kaggle or Colab","012a4da8":"#### [Meaning-of-a-mini-batch-in-deep-learning](https:\/\/stackoverflow.com\/questions\/58269460\/what-is-the-meaning-of-a-mini-batch-in-deep-learning)","13662660":"**Restart runtime before running code below**","a1e135eb":"<center> <h4 style=\"background-color:orange; color:white\" ><br>Component of Application<br><\/h4><\/center>\n\n1. Frontend\n    * For user interaction\n    * Desplaying Results => Loan is approved or not\n2. Backend => can use Google Colab\n    * Used for Loading data\n    * data Preprocessing\n    * Model Building","e8fdb9af":"[Github Essential Guide](https:\/\/www.analyticsvidhya.com\/blog\/2020\/05\/git-github-essential-guide-beginners\/)<br>\n[Introduction to Linux Commands](https:\/\/www.analyticsvidhya.com\/blog\/2016\/08\/tutorial-data-science-command-line-scikit-learn\/) <br>","913e81df":"### 3. Preprocess data and getting prediction\nLets see how to get prediction from this pretrained model","10e2d92b":"## 2. Pre-processing","3a389f73":"### FlowChart How Website will Work (simplified_v1)\n1. `Website Starting` --> create instance of class TypingTutor --> calls `__init__()` method, when `__init__()` method is called three things happens one after other \n    * unique session is created for user\n    * front-end is create for Website, for user to interact with\n    * deep learning model is `Initialized` & `Loaded`\n2. if User Click's `Start` buton --> `on_start_click()` method is called, which leds to three things\n    * internally call's `_code_gen()` to pick code from example_code.py and generates code for Deep Learning code(example_code.py)\n    * session state variables like => (start_time,text,num_chars) are Modifies atocode generated\n    * Updates front-end accordingly\n    * code generated is shown in leftside of website\n\nCode shown to user will be written by use on the right hand side and saved by pressing `Ctrl + Enter`\n\n3. Click `Check Speed` button --> `on_eval_click()` method we be called, which leds to three things\n    * it internally calls `_get_perf()` method to calculate performance i.e. `Speed and Accuracy of typing`\n    * noe Session state variables specially`(end_time,content)` were modefyied\n    * front-end accordingly updates i.e. Performance shown to user ","df483cf8":"#### 2.3. Front-end Creation\n\n###### [Use of with statement in python](https:\/\/www.geeksforgeeks.org\/with-statement-in-python\/)","7ef8d0f2":"<center> <h4 style=\"background-color:orange; color:white\" ><br>Steps to build Loan Eligibility Application<br><\/h4><\/center>\n\n1. `Build Frontend of Application` => (Frontend component)\n2. `Loading and Pre-processing data` => (Backend component)\n3. `Building model to Automate Loan Eligibility` => (Backend component)\n\n#### First make a Simple Rule Based Model:\n1. If monthly income > 50000, loan approved\n2. If monthly income > 50000, loan approved....Elif loan amount < 500000, loan approved.....Else loan will be rejected\n\n#### ML Model\n"}}