{"cell_type":{"9c2d0678":"code","189d741a":"code","c2085a95":"code","e9eb92f0":"code","7f875439":"code","1c184f12":"code","0963d83a":"code","deffb30f":"code","6158ddcf":"code","edd05775":"code","5990653c":"code","438f4378":"code","4224b683":"code","58ab3875":"code","40ed6343":"code","8bf4c2bc":"code","d0cfef19":"code","1887756f":"code","6970e826":"code","d6009210":"code","ad6d0969":"code","f130f66d":"code","ee71c11d":"code","5d03a853":"code","a4f366b4":"code","81f387a8":"code","28d113d2":"code","4c26aade":"code","ac9388a7":"code","fba9f32c":"code","1fe3eb45":"code","f786145e":"code","1a0de168":"code","03ebd0d4":"code","109417b2":"code","17e80bec":"code","60560f0b":"code","7659a85e":"code","a56e3cbb":"code","e149df4d":"code","63f1b88d":"code","0a4e9961":"code","11f83d1b":"code","bb3a0741":"code","702db634":"code","43631572":"code","1f9db10f":"code","9bfbe1cd":"code","1d30619b":"code","35771fe9":"markdown","670bc26e":"markdown","6c224b51":"markdown","878c6062":"markdown","925e5ef1":"markdown","f649f6a5":"markdown","acc4457b":"markdown","652f6dfa":"markdown","1d5f9a83":"markdown","d364d81c":"markdown","52637fa4":"markdown","cd8e4f25":"markdown","4458c730":"markdown","73cda2e3":"markdown","369202c1":"markdown","80d2655a":"markdown","c6fd9198":"markdown","445e240c":"markdown","c19401c5":"markdown","972e0e5d":"markdown","bb081645":"markdown","b2f2a9ce":"markdown","c9553c93":"markdown","b6220c53":"markdown","a28d8c73":"markdown","e37611dc":"markdown","787f92a8":"markdown","734273da":"markdown","98ddf7bc":"markdown","151895f0":"markdown","310c6df1":"markdown"},"source":{"9c2d0678":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nmultiple_choice = pd.read_csv('..\/input\/multipleChoiceResponses.csv')\nmultiple_choice.head()","189d741a":"questions = []\nfor column in multiple_choice.columns:\n    questions.append((column, multiple_choice.loc[0, column]))\nquestions[:5]\n","c2085a95":"multiple_choice = multiple_choice.iloc[1:]\n\ncolumns_with_other = multiple_choice.filter(regex=\".OTHER.\").columns\n\n\nfor col in columns_with_other:\n    print(multiple_choice[col].unique()[:5], \"...\", multiple_choice[col].unique()[-5:] )\n\nmultiple_choice[columns_with_other] = multiple_choice[columns_with_other].apply(pd.to_numeric)\nmultiple_choice.rename(index=str, columns={'Time from Start to Finish (seconds)': 'TIME'}, inplace=True)\nmultiple_choice['TIME'] = multiple_choice['TIME'].apply(pd.to_numeric)","e9eb92f0":"multiple_choice_replace_minus_one =  multiple_choice[columns_with_other].replace(-1, 0)\ntotal_characters = multiple_choice_replace_minus_one.sum(axis=1)\nmultiple_choice['TOTAL_CHARACTERS'] = total_characters\nmultiple_choice['TYPING_SPEED'] = multiple_choice['TOTAL_CHARACTERS'] \/ multiple_choice['TIME']\n\nour_winner = multiple_choice.sort_values(['TYPING_SPEED'], ascending=False)\nprint(( \"Our winner is user number {} from {}, with a typing speed \"\\\n      +\"of {} characters per second!\\n\").format(our_winner.index[0],\n                                                our_winner.iloc[0].Q3,\n                                                our_winner.iloc[0].loc['TYPING_SPEED']))\n\nnovelist = multiple_choice.sort_values(['TOTAL_CHARACTERS'], ascending=False)\nprint(( \"Wow, this one's a novelist. Here is user number {} from {}, who typed \"\\\n      +\"{} characters to answer their questions.\\n\").format(novelist.index[0],\n                                                            novelist.iloc[0].Q3,\n                                                            novelist.iloc[0].loc['TOTAL_CHARACTERS']))\n\ntaking_it_easy = multiple_choice.sort_values(['TIME'], ascending=False)\nprint((\"Better to take it easy if it's a survey with no benefits whatsoever.\\n\"\\\n       +\"Here is user number {} from {}, who took \"\\\n       +\"{} seconds,\\nAKA {} hours, \"\\\n       +\"or {} days, to answer their questions.\").format(taking_it_easy.index[0],\n                                                         taking_it_easy.iloc[0].Q3,\n                                                         taking_it_easy.iloc[0].loc['TIME'],\n                                                         taking_it_easy.iloc[0].loc['TIME'] \/ 3600,\n                                                         taking_it_easy.iloc[0].loc['TIME'] \/ 86400))\n","7f875439":"aggregate_values = multiple_choice.groupby(['Q3']).agg({'TYPING_SPEED': ['mean', 'max']})\naggregate_values.sort_values([('TYPING_SPEED', 'max')], ascending=False).head(10)","1c184f12":"print(multiple_choice.Q3.unique().tolist()[:10], 'and so on, it\\'s 58 Countries.')","0963d83a":"# Why\ncountry_code_dict = {\n    'United States of America': 'USA', 'Indonesia': 'IDN', 'India': 'IND',\n    'Colombia': 'COL', 'Chile': 'CHL', 'Turkey': 'TUR', 'Hungary': 'HUN',\n    'Ireland': 'IRL', 'France': 'FRA', 'Argentina': 'ARG', 'Japan': 'JAP',\n    'Nigeria': 'NGA', 'Spain': 'ESP', 'Iran, Islamic Republic of...': 'IRN',\n    'United Kingdom of Great Britain and Northern Ireland': 'GBR',\n    'Poland': 'POL', 'Kenya': 'KEN', 'Denmark': 'DNK', \n    'Netherlands': 'NLD', 'China': 'CHN', 'Australia': 'AUS',\n    'Sweden': 'SWE', 'Ukraine': 'UKR', 'Canada': 'CAN',\n    'Russia': 'RUS', 'Austria': 'AUT', 'Italy': 'ITA',\n    'Mexico': 'MEX', 'Germany': 'DEU', 'Singapore': 'SGP',\n    'Brazil': 'BRA', 'Switzerland': 'CHE', 'Tunisia': 'TUN',\n    'South Africa': 'ZAF','South Korea': 'KOR', 'Pakistan': 'PAK',\n    'Malaysia': 'MYS', 'Hong Kong (S.A.R.)': 'HKG', 'Egypt': 'EGY',\n    'Portugal': 'PRT', 'Thailand': 'THA', 'Morocco' : 'MAR',\n    'Czech Republic': 'CZE', 'Romania': 'ROU', 'Israel': 'ISR',\n    'Philippines': 'PHL', 'Bangladesh': 'BGD', 'Belarus': 'BLR',\n    'Viet Nam': 'VNM', 'Belgium': 'BEL', 'New Zealand': 'NZL',\n    'Norway': 'NOR', 'Finland': 'FIN', 'Greece': 'GRC', 'Peru': 'PER',\n    'Republic of Korea': 'ROK'\n}\nmultiple_choice['COUNTRY_CODE'] = multiple_choice['Q3'].replace(country_code_dict).fillna('Unknown')\n\nuseful_entries = multiple_choice[multiple_choice['COUNTRY_CODE'].isin(country_code_dict.values())][['TIME', 'Q3', 'COUNTRY_CODE', 'TYPING_SPEED', 'TOTAL_CHARACTERS']]\nuseful_entries.head()    ","deffb30f":"aggregate_values_clean = useful_entries.groupby(['COUNTRY_CODE']).agg({'TYPING_SPEED': ['mean', 'max']})","6158ddcf":"from plotly.offline import init_notebook_mode, iplot\n\nscl = [[0.0, 'rgb(242,240,247)'],[0.2, 'rgb(218,218,235)'],[0.4, 'rgb(188,189,220)'],\\\n            [0.6, 'rgb(158,154,200)'],[0.8, 'rgb(117,107,177)'],[1.0, 'rgb(84,39,143)']]\n\ninit_notebook_mode(connected=True)\n\nreverse_countries_dict = {country_code: country_name for country_name, country_code in country_code_dict.items()}\n\nlocations = pd.Series(aggregate_values_clean.index)\nprint(aggregate_values_clean.index)\ntext = locations.replace(reverse_countries_dict)\n\ndata = [ dict(\n        type='choropleth',\n        colorscale = scl,\n        autocolorscale = False,\n        locations = locations,\n        z = aggregate_values_clean[('TYPING_SPEED', 'max')].astype(float),\n        #locationmode = 'country names',\n        text = text,\n        marker = dict(\n            line = dict (\n                color = 'rgb(255,255,255)',\n                width = 2\n            ) ),\n        colorbar = dict(\n            title = \"Characters per second\")\n        ) ]\n\nlayout = dict(\n        title = 'Fastest Kaggle Users by Country',\n        geo = dict(\n            scope='world',\n            projection=dict( type='Stereographic'),\n            showlakes = True,\n            lakecolor = 'rgb(255, 255, 255)'),\n             )\n    \nfig = dict( data=data, layout=layout )\niplot(fig,validate=False)","edd05775":"data = [ dict(\n        type='choropleth',\n        colorscale = scl,\n        autocolorscale = False,\n        locations = locations,\n        z = aggregate_values_clean[('TYPING_SPEED', 'mean')].astype(float),\n        #locationmode = 'country names',\n        text = text,\n        marker = dict(\n            line = dict (\n                color = 'rgb(255,255,255)',\n                width = 2\n            ) ),\n        colorbar = dict(\n            title = \"Characters per second\")\n        ) ]\n\nlayout = dict(\n        title = 'Best Typing Mean by Country',\n        geo = dict(\n            scope='world',\n            projection=dict( type='Stereographic'),\n            showlakes = True,\n            lakecolor = 'rgb(255, 255, 255)'),\n             )\n    \nfig = dict( data=data, layout=layout )\niplot(fig,validate=False)","5990653c":"print(multiple_choice.Q4.unique()) # To understand what we're going to replace next, labels-wise","438f4378":"import seaborn as sns\nimport numpy as np\n# nan values could be \"No answer\" ones, but we don't know; let's get rid of them\nno_nan = multiple_choice.dropna(subset=['Q4'])\n\nfontdict = {'fontsize': 20, 'fontweight' : 'bold'}\n\ncatpl = sns.factorplot(x=\"Q4\", kind=\"count\", data=no_nan, orient='h', aspect=1.5)\nlabels=('Doctoral degree', 'Bachelor\u2019s degree', 'Master\u2019s degree',\n        'Professional degree', 'Some college\/university',\n        'No answer', 'High school')\nplt.xticks(np.arange(0, 7, 1), labels, rotation=-80)\nplt.title('Kagglers and Their Education', fontdict=fontdict)\nplt.ylabel('')\n\n# Let's be minimally minimalistic, and maybe write a function instead of copying and pasting\n# This junk\n\ndef minimalistifier(subplot):\n    for key, spine in subplot.spines.items():\n        spine.set_visible(False)\n    for tick in subplot.yaxis.get_major_ticks():\n        tick.label.set_fontweight('bold')\n    for tick in subplot.xaxis.get_major_ticks():\n        tick.label.set_fontweight('bold')\n    subplot.tick_params(bottom=False, left=False)\n\nminimalistifier(catpl.ax)","4224b683":"country_continent_dict = {\n    'United States of America': 'North America', 'Indonesia': 'Asia', 'India': 'Asia',\n    'Colombia': 'South America', 'Chile': 'South America', 'Turkey': 'Asia', 'Hungary': 'Europe',\n    'Ireland': 'Europe', 'France': 'Europe', 'Argentina': 'South America', 'Japan': 'Asia',\n    'Nigeria': 'Africa', 'Spain': 'Europe', 'Iran, Islamic Republic of...': 'Asia',\n    'United Kingdom of Great Britain and Northern Ireland': 'Europe',\n    'Poland': 'Europe', 'Kenya': 'Africa', 'Denmark': 'Europe', \n    'Netherlands': 'Europe', 'China': 'Asia', 'Australia': 'Oceania',\n    'Sweden': 'Europe', 'Ukraine': 'Europe', 'Canada': 'North America',\n    'Russia': 'Europe', 'Austria': 'Europe', 'Italy': 'Europe',\n    'Mexico': 'North America', 'Germany': 'Europe', 'Singapore': 'Asia',\n    'Brazil': 'South America', 'Switzerland': 'Europe', 'Tunisia': 'Africa',\n    'South Africa': 'Africa','South Korea': 'Asia', 'Pakistan': 'Asia',\n    'Malaysia': 'Asia', 'Hong Kong (S.A.R.)': 'Asia', 'Egypt': 'Africa',\n    'Portugal': 'Europe', 'Thailand': 'Asia', 'Morocco' : 'Africa',\n    'Czech Republic': 'Europe', 'Romania': 'Europe', 'Israel': 'Asia',\n    'Philippines': 'Asia', 'Bangladesh': 'Asia', 'Belarus': 'Europe',\n    'Viet Nam': 'Asia', 'Belgium': 'Europe', 'New Zealand': 'Oceania',\n    'Norway': 'Europe', 'Finland': 'Europe', 'Greece': 'Europe', 'Peru': 'South America',\n    'Republic of Korea': 'Asia', 'I do not wish to disclose my location': 'Unknown', 'Other': 'Unknown'\n}\n\nmultiple_choice['CONTINENT'] = multiple_choice['Q3'].replace(country_continent_dict)\nmultiple_choice['CONTINENT'].value_counts()","58ab3875":"catpl = sns.factorplot(x=\"CONTINENT\", kind=\"count\", data=multiple_choice, orient='h', aspect=1.5)\n\nplt.xticks(rotation=-80)\nplt.title('Kagglers and Their Continents', fontdict=fontdict)\nplt.ylabel('')\nplt.xlabel('')\n\n# Let's be minimally minimalistic, again; copy and paste works like a charm\nminimalistifier(catpl.ax)","40ed6343":"values_by_country = multiple_choice['Q3'].value_counts()\ntop_10_countries = values_by_country[:10]\nother_countries = pd.Series([values_by_country[10:].sum()])\nother_countries.index = ['Other Countries']\n#top_10_countries = top_10_countries.append(other_countries)\ntop_10_and_others = pd.concat([top_10_countries, other_countries], axis=0)\ntop_10_and_others","8bf4c2bc":"# Thank you, people who put \"Other\" as their 'country'; let's fix this; oh, apparently\n# Kaggle did it to preserve their privacy\n\nvalues_by_country = multiple_choice['Q3'].value_counts()\ntop_10_countries = pd.concat([values_by_country[:3], values_by_country[4:11]], axis=0)\nother_countries = pd.Series([values_by_country[10:].sum() + values_by_country[3]])\nother_countries.index = ['Other Countries']\n#top_10_countries = top_10_countries.append(other_countries)\ntop_10_and_others = pd.concat([top_10_countries, other_countries], axis=0)\ntop_10_and_others","d0cfef19":"# This will save us some time\ndef its_always_barplots_anyway(x, y, hue=None, xlabel='', ylabel='', title='', rotation=0, bar_text_col='white', bar_text=False, mantissa=1):\n    plt.figure(figsize=(15, 8))\n    barpl = sns.barplot(x=x, y = y, hue=hue)\n    plt.xticks(rotation=rotation)\n    plt.title(title, fontweight='bold', fontsize=20)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    if bar_text:\n        ax = plt.gca()\n        for p in ax.patches:\n            ax.text(p.get_x() + p.get_width()\/2., p.get_height()*2\/5, '%.{}f'.format(mantissa) % float(p.get_height()), \n                    fontsize=14, fontweight='bold', color=bar_text_col, ha='center', va='bottom')\n    minimalistifier(barpl)\n\nlabels=('USA', 'India', 'China', 'Russia', 'Brazil', 'Germany',\n        'UK', 'Canada', 'France', 'Japan', 'Other\\nCountries')\nits_always_barplots_anyway(top_10_and_others.index, top_10_and_others, xlabel='', ylabel='', title='Kagglers by Country', rotation=0, bar_text=False)\nplt.xticks(np.arange(0, 11, 1), labels)","1887756f":"# I wrote this in order to avoid insanity. You can get these values by calling 'unique()'\norder= ['18-21', '22-24', '25-29', '30-34', '35-39',\n        '40-44', '45-49', '50-54', '55-59', '60-69',\n        '70-79', '80+']\n\ncatpl = sns.factorplot(x='Q2', kind='count',\n                       data=multiple_choice, \n                       order=order,\n                       size=5, aspect=1.5)\nplt.xticks(rotation=-80)\nplt.title('Kagglers by Age', fontdict=fontdict)\nplt.ylabel('')\n\n\nminimalistifier(catpl.ax)","6970e826":"# We basically count how many of each 'kind' there are, then we make a pandas Series out\n# of these values and multiply by 100 and divide by the total amount of participants\n# in order to find the percentages\n\nmales = multiple_choice[multiple_choice.Q1 == 'Male']['Q1'].shape[0]\nfemales = multiple_choice[multiple_choice.Q1 == 'Female']['Q1'].shape[0]\nother_1 = multiple_choice[multiple_choice.Q1 == 'Prefer not to say']['Q1'].shape[0]\nother_2 = multiple_choice[multiple_choice.Q1 == 'Prefer to self-describe']['Q1'].shape[0]\nother = other_1 + other_2\n\nmales_females = pd.Series([males, females, other]) * 100 \/ 23859\nmales_females.index = ['Males', 'Females', 'Other']\nprint(males_females.index)\nbarpl = sns.barplot(y=males_females.index,\n                    x=males_females.values,\n                    orient='h')\n\nplt.title('Percentages of Kagglers by Gender', fontdict=fontdict)\nplt.ylabel('')\nplt.xlabel('')\n\nminimalistifier(barpl)","d6009210":"multiple_choice.Q6.value_counts()","ad6d0969":"Q6_dictionary = {'Data Scientist': 'Data Science',\n                 'Data Analyst': 'Data Science',\n                 'Data Engineer': 'Data Science',\n                 'Data Journalist': 'Data Science',\n                 'Marketing Analyst': 'Marketing-Business',\n                 'Business Analyst': 'Marketing-Business',\n                 'Student': 'Students-Researchers',\n                 'Research Scientist': 'Students-Researchers',\n                 'Research Assistant': 'Students-Researchers'}","f130f66d":"multiple_choice.Q1.astype('category', inplace=True)\nmultiple_choice['Q1_SIMPLIFIED'] = multiple_choice[multiple_choice.Q1.isin(['Male', 'Female'])]['Q1']\nmultiple_choice.Q6.astype('category', inplace=True)\nmultiple_choice['Q6_SIMPLIFIED'] = multiple_choice.Q6.replace(Q6_dictionary) \n\ncatpl = sns.factorplot(y='Q6_SIMPLIFIED', hue='Q1_SIMPLIFIED',\n                       data=multiple_choice, kind='count', orient='h',\n                       aspect=0.8, size=7, legend=None)\n\n\nplt.title(' Kagglers by Occupation and Gender (Simplified)', fontdict=fontdict)\nplt.ylabel('')\nplt.xlabel('')\n\nminimalistifier(catpl.ax)","ee71c11d":"multiple_choice_dummies = pd.get_dummies(multiple_choice, columns=['Q1_SIMPLIFIED'])\ngrouped_with_dummies = multiple_choice_dummies.groupby(['Q6_SIMPLIFIED']).agg({'Q1_SIMPLIFIED_Male': 'sum', 'Q1_SIMPLIFIED_Female': 'sum'})\ngrouped_with_dummies['males_females_ratio']= (grouped_with_dummies['Q1_SIMPLIFIED_Male'] \/ \n                       grouped_with_dummies['Q1_SIMPLIFIED_Female'])\ngrouped_with_dummies\nits_always_barplots_anyway(grouped_with_dummies.index, grouped_with_dummies.males_females_ratio, xlabel='', ylabel='',\n                           title='Men-to-Women Ratio for each Occupation (Simplified)', rotation=-65, bar_text=True)\nplt.yticks([])","5d03a853":"dummies_gender_salary = pd.get_dummies(multiple_choice_dummies, columns=['Q9'])\nQ9_columns = dummies_gender_salary.filter(regex=\"Q9_.\").columns.tolist()\nQ9_columns","a4f366b4":"# Let's sort\nQ9_columns = ['Q9_0-10,000', 'Q9_10-20,000', 'Q9_20-30,000', 'Q9_30-40,000',\n              'Q9_40-50,000', 'Q9_50-60,000', 'Q9_60-70,000', 'Q9_70-80,000',\n              'Q9_80-90,000', 'Q9_90-100,000', 'Q9_100-125,000', 'Q9_125-150,000',\n              'Q9_150-200,000', 'Q9_200-250,000', 'Q9_250-300,000', 'Q9_300-400,000',\n              'Q9_400-500,000', 'Q9_I do not wish to disclose my approximate yearly compensation']\ngrouped_dummies_gender_salary = dummies_gender_salary.groupby(['Q3', 'Q1_SIMPLIFIED_Male']).agg({x: 'sum' for x in Q9_columns})\ngrouped_dummies_gender_salary","81f387a8":"grouped_dummies_gender_salary.index\nfor column in Q9_columns:\n    males = grouped_dummies_gender_salary.loc[('United States of America', 0)][column]\n    females = grouped_dummies_gender_salary.loc[('United States of America', 1)][column]\n    print(('For the $ {} bracket the percentage of females is: {:2.2%} ').format(column[3:], males\/ (females + males)))\n\n","28d113d2":"values = {}\nfor column in Q9_columns:\n    males = grouped_dummies_gender_salary.loc[('United States of America', 1)][column]\n    females = grouped_dummies_gender_salary.loc[('United States of America', 0)][column]\n    values[column[3:]] = (females\/(females + males) * 100)\nvalues['Undisclosed'] = values.pop('I do not wish to disclose my approximate yearly compensation')\nvalues_series = pd.Series(values)\n\nits_always_barplots_anyway(values_series.index, values_series.values, xlabel='', ylabel='',\n                           title='Percentage of Women in the USA by Salary Bracket', rotation=-90, bar_text=True, mantissa=1)","4c26aade":"def women_percentage_country(country_name):\n    import math\n    values = {}\n    for column in Q9_columns:\n        males = grouped_dummies_gender_salary.loc[(country_name, 1)][column]\n        females = grouped_dummies_gender_salary.loc[(country_name, 0)][column]\n        ratio = (females\/(females + males) * 100) \n        values[column[3:]] = 0 if math.isnan(ratio) else ratio # Not all Countries have someone in certain brackets, let's divide by zero responsibly\n    values['Undisclosed'] = values.pop('I do not wish to disclose my approximate yearly compensation')\n    values_series = pd.Series(values)\n    \n    its_always_barplots_anyway(values_series.index, values_series.values, xlabel='', ylabel='',\n                           title='Percentage of Women in {} by Salary Bracket'.format(country_name), rotation=-90, bar_text=True)","ac9388a7":"countries = aggregate_values.sort_values([('TYPING_SPEED', 'max')], ascending=False).head(10).index\nfor country in countries:\n    women_percentage_country(country)","fba9f32c":"import math\n# Most of the Countries you'd expect in this list are still in the European Union, but less than 50 people from them answered the survey\n# and they are therefore missing as a distinct Country in the survey answers.\n# The European Union is still going strong, those who claim otherwise are nothing but enemies of the European Union and will be treated accordingly.\neuropean_union = ['Austria', 'Italy', 'Belgium', \n                  'Sweden', 'Netherlands', 'Czech Republic',\n                  'Denmark', 'Poland', 'Portugal','Hungary',\n                  'Finland', 'Romania', 'France', 'Ireland',\n                  'Germany', 'Greece', 'Spain',\n                  'United Kingdom of Great Britain and Northern Ireland']\n\nfor column in Q9_columns:\n    for country in european_union:\n        males = grouped_dummies_gender_salary.loc[(country, 0)][column]\n        females = grouped_dummies_gender_salary.loc[(country, 1)][column]\n\nvalues = {}\nmales_total = 0\nfemales_total = 0\nfor column in Q9_columns:\n    for country in european_union:\n        males = grouped_dummies_gender_salary.loc[(country, 1)][column]\n        females = grouped_dummies_gender_salary.loc[(country, 0)][column]\n        males_total += males\n        females_total += females\n        if column[3:]+'_males' in values:\n            values[column[3:]+'_males'] += males\n\n        else:\n            values[column[3:]+'_males'] = males\n            \n        if column[3:]+'_females' in values:\n            values[column[3:]+'_females'] += females\n        else:\n            values[column[3:]+'_females'] = females\n        \nprint(values)\nfor column in Q9_columns:\n    ratio = values[column[3:]+'_females'] \/ (values.pop(column[3:]+'_females') + values.pop(column[3:]+'_males')) * 100\n    values[column[3:]] = 0 if math.isnan(ratio) else ratio\n\nvalues['Undisclosed'] = values.pop('I do not wish to disclose my approximate yearly compensation')\nvalues_series = pd.Series(values)\n\nits_always_barplots_anyway(values_series.index, values_series.values, xlabel='', ylabel='',\n                           title='Percentage of Women in the European Union by Salary Bracket', rotation=-90, bar_text=True)\nprint(values)\n# Bonus:\nprint('\\n\\n{} European Union people answered the survey.'.format(males_total + females_total))","1fe3eb45":"women_percentage_country('United States of America')\nwomen_percentage_country('India')","f786145e":"questions","1a0de168":" \nQ16_columns = multiple_choice.filter(regex=\"Q16_.*[0-9]\").columns.tolist()\ncolumn_names_for_decent_human_beings = {'Q16_Part_1': 'Python', 'Q16_Part_2': 'R', 'Q16_Part_3': 'SQL',\n                                        'Q16_Part_4': 'Bash', 'Q16_Part_5': 'Java', 'Q16_Part_6': 'Javascript\/Typescript',\n                                        'Q16_Part_7': 'Visual Basic\/VBA', 'Q16_Part_8': 'C\/C++', 'Q16_Part_9': 'MATLAB',\n                                        'Q16_Part_10': 'Scala', 'Q16_Part_11': 'Julia', 'Q16_Part_12': 'Go',\n                                        'Q16_Part_13': 'C#\/.NET', 'Q16_Part_14': 'PHP', 'Q16_Part_15': 'Ruby',\n                                        'Q16_Part_16': 'SAS\/STATA', 'Q16_Part_17': 'None', 'Q16_Part_18': 'Other'}\ncolumn_names_for_decent_human_beings = {key:'Uses ' + value for key, value in column_names_for_decent_human_beings.items()}\nmultiple_choice.rename(column_names_for_decent_human_beings, axis=1, inplace=True)\nmultiple_choice.head()","03ebd0d4":"languages_columns = list(column_names_for_decent_human_beings.values())\nval_dict = {np.nan : 0, 'Python': 1, 'R': 1, 'SQL': 1, 'Bash': 1, 'Java': 1,\n            'Javascript\/Typescript': 1, 'Visual Basic\/VBA': 1, 'C\/C++': 1,\n            'MATLAB': 1, 'Scala': 1, 'Julia': 1, 'Go': 1, 'C#\/.NET': 1, 'PHP': 1,\n            'Ruby': 1, 'SAS\/STATA': 1, 'None': 1, 'Other': 1}\nmultiple_choice[languages_columns] = multiple_choice[languages_columns].replace(val_dict).apply(pd.to_numeric)\nmultiple_choice.head()","109417b2":"groupby_programming_languages = multiple_choice.groupby(['Q2']).agg({col:['sum', 'mean'] for col in languages_columns})\ngroupby_programming_languages","17e80bec":"x = groupby_programming_languages.index\ny = 100 - groupby_programming_languages[('Uses Bash', 'mean')] * 100\nhue = None\nxlabel = ''\nylabel = ''\ntitle = 'Command Line Illiteracy by Age Bracket'\nrotation = 0\nits_always_barplots_anyway(x, y, hue, xlabel, ylabel, title, rotation, 'white', bar_text=True)","60560f0b":"x = groupby_programming_languages.index\ny = groupby_programming_languages[('Uses SQL', 'mean')] * 100\nits_always_barplots_anyway(x,y, title='Usage of SQL by Age Bracket', xlabel='', ylabel='', rotation=0, bar_text=True)","7659a85e":"x = groupby_programming_languages.index\ny = groupby_programming_languages[('Uses Python', 'mean')] * 100\nits_always_barplots_anyway(x,y, None, title='Usage of Python by Age Bracket', xlabel='', ylabel='', rotation=0, bar_text=True)","a56e3cbb":"plt.figure(figsize=(20,20))\nsns.heatmap(multiple_choice[languages_columns].corr())","e149df4d":"multiple_choice[languages_columns].corr()","63f1b88d":"multiple_choice[languages_columns].corr().iloc[0]","0a4e9961":"multiple_choice[languages_columns].corr().iloc[1]","11f83d1b":"groupby_income_programming_languages = multiple_choice.groupby(['Q9']).agg({col:['sum', 'mean'] for col in languages_columns}).iloc[:-1]\ngroupby_income_programming_languages","bb3a0741":"groupby_income_programming_languages.index","702db634":"groupby_income_programming_languages = groupby_income_programming_languages.loc[['0-10,000', '10-20,000', '20-30,000',  '30-40,000', '40-50,000',\n                                                                            '50-60,000', '60-70,000', '70-80,000', '80-90,000', '90-100,000',\n                                                                            '100-125,000', '125-150,000', '150-200,000', '200-250,000',\n                                                                            '250-300,000', '300-400,000', '400-500,000', '500,000+']]\ngroupby_income_programming_languages","43631572":"groupby_income_languages_means = multiple_choice.groupby(['Q9']).agg({col:'mean' for col in languages_columns}).iloc[:-1]\ngroupby_income_languages_means = groupby_income_languages_means.loc[['0-10,000', '10-20,000', '20-30,000',  '30-40,000', '40-50,000',\n                                                                     '50-60,000', '60-70,000', '70-80,000', '80-90,000', '90-100,000',\n                                                                     '100-125,000', '125-150,000', '150-200,000', '200-250,000',\n                                                                     '250-300,000', '300-400,000', '400-500,000', '500,000+']]\ngroupby_income_languages_means","1f9db10f":"dataf = groupby_income_languages_means.iloc[-9:]\ndataf = pd.DataFrame(dataf).T\n\nfor col in dataf.columns:\n    x = dataf.index\n    y = dataf[col] * 100\n    its_always_barplots_anyway(x=x, y=y, title='Usage of Programming Languages in the ${} Bracket'.format(col), xlabel='', ylabel='', rotation=-90, bar_text_col='gold', bar_text=True)","9bfbe1cd":"multiple_choice['TOTAL_LANGUAGES'] = multiple_choice[languages_columns].sum(axis=1, skipna=True)\nmultiple_choice.TOTAL_LANGUAGES.value_counts()","1d30619b":"multiple_choice_salary_dummies = pd.get_dummies(multiple_choice[['Q4', 'Q9']], columns=['Q4', 'Q9'])\nmultiple_choice_salary_dummies.corr().iloc[:7, 7:]  # The indices deal with redundant values we're not interested in","35771fe9":"The way they're sorted is disgusting. Let's fix it.","670bc26e":"Lists are good, but plots are better.  Alright, it's seaborn time. By the way, 'I do not wish to disclose my approximate yearly compensation' is not practical, so we shall rename it to something that doesn't inflate a plot uselessly.","6c224b51":"Great, let's check the unique values of each column containing \"OTHER\". I chose not to make it print as many as\npossible as, believe me, they would have been far too many. By the way, the first column (Time from Start to Finish (seconds)) has a rather long name, maybe we should fix that, and its data type.","878c6062":"So, what have we learned now? Let's check Python users. Python-Bash and Python-C\/C++ correlation is way, way stronger than the R-Bash or R-C\/C++.\nSQL correlation is similar, though. SAS\/STATA is yet another major difference, with R users being more likely to know it and Python users less likely (*I wonder why*). In both scenarios, there is no strong correlation between Python or R and any other column.\nIt looks like lots of Kagglers into Python have a Computer Science\/Engineering background (the MATLAB correlation is weak but noticeably stronger than the R-MATLAB one), while R users are less likely to be into Bash, C\/C++, Java, and so on, so... Statisticians? People into fields such as Psychology or anything else that relies a lot on Statistics?\nNow, let's work on a get-rich-quick scheme. Let's say you want to climb the social ladder through somewhat hard work. What should you learn?\nStuff about paranoid people? Naaah, let's get rid of the 'I do not wish\" people.","925e5ef1":"# Let's join the bandwagon, together\n\nThis stuff is popular, isn't it? Let's try joining the obvious bandwagon with yet another Python kernel.\nIt may also work as a hopefully helpful tutorial, if you've just started this whole Data Science thing.\nLet's import the usual stuff: matplotlib.pyplot in case we want to plot something quickly(ish), pandas to \nread the dataframe, and the IPython magic function `%matplotlib inline`. We shall then display the first five\nrows with multiple_choice.head() in order to understand what we're dealing with.\n\n**By the way, please tell me if there are any issues with this notebook, such as it not being fully rendered\/displayed.**","f649f6a5":"Cool stuff, right? But, what does this mean?\n\nLet's take a look at the younger cohorts:\n1.  57,  64,  and 69% of the under-30 people are pretty focused on Python; way to go, pals.\n2.  They seem to pretty much ignore things like Bash.\n3.  They, however, have some of the highest percentages of C\/C++ and Java usage.\n4.  2 and 3 are not in conflict, they can be considered part and parcel of some software engineering courses (learn C because it's for tough guys, Java because 'standard of the industry', 'What is a command line? I want you to use Eclipse, students.')\n5.  18-21 people still have to understand SQL exists.\n\nEnough with bashing those who don't use Bash. Older Millennials and Gen X, anyone?\n1.  Great Python percentages, too, from 65 to 69%, more or less.\n2.  An example to us all in terms of Bash usage.\n3. They apparently like R, a lot.\n4. Some kind of know C\/C++, lots of them don't care about MATLAB, either. This may support the 'professional converted to Data Science' stereotype about older Data Scientists.\n5.  However, Javascript\/Typescript is more popular among these cohorts than the other ones. Why?\n\nPeople in their 60s and onwards.\n1. They trust the general trend towards using Python.\n2. 60-69 must be old-schol Statisticians or of a similar background, look at the R  percentage.\n\nTo keep it textually simple, Python is no longer the new kid on the block, but the undisputed dominant language, lots of people are allergic to Command Line Interfaces, especially the younger generations, R isn't dead yet, but it's suffering. \nBarplots, again.","acc4457b":"# Would you look at that?\nNeat, right? And absolutely useless. Fear not, for most of those Countries  were actually the most represented ones in the  Kaggle users sample that is the survey participants. How about that whole G8 thing? Too late, disbanded 4 years ago. How about the European Union? No, not kidding, should we do this before other Countries run for their lives ?  We could also compare them with, say, the US and India.","652f6dfa":"The age distribution seems to be right skewed: there must be strong, dominant factors that eclipse random, weaker ones. We can suppose, at least for now, that things like Data Science (and IT in general) being relatively new may make younger people more interested in learning it instead of those who would have to reinvent themselves at the end of (or after) their career. However, there is more than a handful of older Millennials and middle-aged people:\nlots of Data Scientists are in fact people from a somewhat diverse background that try to apply Data Science techniques to their knowledge in their field of expertise (a partial reinventing of their careers).\nThe youngest cohorts are likely made of Computer Science\/Software Engineering\/Mathematics students (and other Mathematics-heavy fields) who find this field to be promising and can compensate their lack of hands-on  experience in whatever business with formal learning of Data Science (several universities offer such degrees nowadays). **WORK IN PROGRESS.** We could ask ourselves something: do businesses prefer veterans of their industry sector who then decided to learn Data Science or would they rather hire someone fresh out of college? And by prefer I mean money, and by money I mean we should group said incomes by age bracket and Country. **WORK IN PROGRESS.**","1d5f9a83":"# What have we learned so far?\nWell, have we learned anything? We've got someone from India who is either quite fast at typing, or copied and pasted the answers in order to \"win\"\n(given Kagglers' background, the former is more likely than the latter, with lots of us being advanced computer users and skilled at typing, and similar results in other countries; also, it is likely that few if any users felt the urge to fill in these answers as fast as possible, this whole _analysis_ is a tongue-in-cheek approach to this dataset, but it should have been obvious by now).\nWe've got someone else who typed a lot and chose not to disclose the location, then an American who took around **10 days and 6 hours** to answer.\nLet's do something \"just for fun\": we shall sort these brave kagglers who typed as fast as they could after grouping them by Country.\nActually, **they won't be values for each person**, for we shall use aggregate functions. By doing so, we're going to get the mean and maximum\nvalue for each Country, and we shall then sort these results by using multiindex values sorting sorcery. As there are far too many Countries\nin the world, maybe we could display a top ten for both cases (maximum speed and greatest mean typing speed).","d364d81c":"# Mildly interesting\nIn order to become an entry-level rich, aka *Middle class*,  Python and SQL seem to be a good pick (that, unless it's just a hobby or something. We're assuming knowing these languages is the cause, not the effect, of belonging to a certain salary bracket).\nAs we move towards better brackets, we notice a curious trend: the plots get flatter. What could the reasons be? A higher proportion of specialists for each language, instead of following each and every fad, resulting in a less Python-centric set of skills? A lack of need for reinventing yourself, once you've made it to the top? To be honest, we can't know that as of now. We've not even counted how many language each person knows, have we? We could also try figuring out what's the relationship between being rich and having an education. Oh yes, it's time to use dummy columns.","52637fa4":"They seem to be ranging from -1 to a value in the hundreds in most cases.\nThat's quite likely to be the number of characters used to answer them.\nCould we analyse this kind of information, too? Sure, why not? How about benchmarking these people?\nWho typed the most? Who's the fastest typist of them all? Who took their sweet time to answer?\n","cd8e4f25":"# U S of A\nWhat's the percentage of females for each salary bracket in the US? Let's find out.","4458c730":"What else could we ask ourselves? Stuff  like: are there any Millennials in the $500,000+ bracket? Ha ha ha. Alright, we could use yet another groupby and even more dummies. I bet that by the end of this notebook you, too, will be using dummies for everything Data Science.  Let's get the dummies for the column stating the salary bracket. We'll get as many dummy columns as there are unique values for said column, with 1 and 0 having a rather Boolean meaning (1 = yes, this row had the value indicated by the dummy column name; 0 = no, it didn't. This is also called one-hot encoding as one and  only one column has a 1 for each row, no more, no less). Regex will help us retrieve the column names, and then a list comprehension inside the aggregate functions dictionary, just because we're cool.\nHaving done that, we could ask the stuff everyone here asks himself because it's cool: do women in country X earn less money? Given how we've got to think in salary brackets: 'Are the higher-ups equally disproportionally made up of men, or is the 80\/20 proportion (of men and women, not what Mr. Pareto said) respected?' But why should we limit ourself to that? How about thinking in terms of G8 and G20? Or continents? Also, is the 'US Data Scientists are wealthier' no-brainer, in fact, a no-brainer?\nHow about the 'I do not wish to disclose' people in our midst? Evil fatcats, as some people think? Ashamed to say they belong  to the 0 to 10,000 bracket? Who are they? Should we even bother?\nAnyway,  to further our agenda, we should sort those pesky Q9 columns, unless you want to deal with 400,000 to 500,000 nearby stuff one order of magnitude smaller.","73cda2e3":"Apparently, women are a bit less than 20% of the survey participants. What happens if we break these values down by occupation? What if we group a few of said occupations in order to avoid insanely huge walls of text?\nLet's see what we're dealing with, first. We're going to ignore the 'Q6_OTHER' answer almost on purpose,\nhoping these brave Kagglers actually did not fit in into any other category and therefore really needed to write something themselves in order to feel special. Read a few of the free form responses and have fun.","369202c1":"Let's do something else. If everyone is into Python (and R, a little bit), it makes sense to focus on this instead of looking at an endless plot\/matrix.","80d2655a":"# It's groupby time\nYes, get used to it. We're going to use it to know how many Kagglers use each of these languages. There is an issue. Summing them up will give us how many kagglers, depending on the age bracket, know a certain language. However, most know more than one. While having a big value for Python and a small one for, say,  Ruby tells us something, we could ask ourselves, **knowing that each value is either a 0 or 1 and therefore if we calculate the mean we're going to get a value between 0 and 1 that we could multiply by 100 to get the percentage of people who know a certain programming language depending on their  age bracket**,  what's indeed the percentage of Python users for each bracket? Are Millennials and Gen Z messing this up by focusing on R or MATLAB? Let's find out.","c6fd9198":"# Boring stuff ahead\nLet's do the usual stuff. How many of these brave kagglers have a Bachelor's degree? Or a Master's? Or a High school education? Let's find out.","445e240c":"So, the Swiss and the Americans seem to sport some of the best means and highest typing speeds. Good job.\nHow about a good, old fashioned, useless map? First and foremost, we need to figure out what Countries we are actually going do deal with, and ignore whoever doesn't come from said Countries (sorry, I do not wish to disclosers and Otherers).","c19401c5":"# Feature engineering, less exciting than it sounds\n\nTechnically, the whole 3 letters code thing was also feature engineering. We're basically going to use our \"domain knowledge\" to create new features (that is, in this case columns) from the data we already have in order to make our analysis process easier. Something pretty basic could be the introduction of continents, and of course, a bar plot with Countries (we should have done that before, shouldn't have we?).","972e0e5d":"# This is messy\n\nThe first row seems to consist of the multiple choice responses questions part of this survey.\nWe could get rid of this row and maybe add its values to a list of tuples, just in case we want to take a look at it.\nWe can also notice how some questions have an \"Other\" option that lets you insert whatever you want in case it is not provided\nas a selected choice. If your choice is \"normal\", the value is -1; if, instead, you need to write something and therefore you\npick \"Other\", then it is going to be equal to 0 (check row 2, column Q6_OTHER_TEXT), unless 0 means the kaggler just selected\n\"Other\" without filling that part in. We shall find that out. Filtering and using regex will come in handy, as there are several\nof these columns. We can then look at their unique values to understand what's really going on. ","bb081645":"So, what's going on? Yes, I included the UK in the European Countries (I shall update it in the future, I guess).\nWell, we can notice something that some people may find odd or counterintuitive: India's percentages of women in the better paid brackets are actually quite high and significantly higher than the EU or US ones, while the least paid ones sport rather small percentages of women. In the US, most higher-ups seem to be men, just like in Europe, whilst in India it seems to be slightly more balanced.","b2f2a9ce":"# One of the greatest classics\n\nIt's great to find out about people's continents and Countries. How about their ages? What does the average Kaggler \"look like\"? What is the share of men and women over here (considering the survey participants to be a reliable sample of the greater Kaggle population)? Is it consistent with data found on other websites that, too, tried to figure this out?","c9553c93":"Okay, that was easy. How about making a whole function that does this for us, as long as we provide the name of the Country? Let's be productively lazy.","b6220c53":"Same for this matrix, unless you have the crappy TV series hacker eyesight and you can scan thousands of popups at a time.","a28d8c73":"With our newfound strength and yet another tool to use, we can now take a look at random Countries, just because we can, and see the percentage of women for each bracket. We could generate plots for each of the most represented Countries. Nah, that would be boring.\nShall we see the percentage of women for each Country in our Typing Speed top 10? ","e37611dc":"We must correct what we have just done, courtesy of whoever chose 'Other'.","787f92a8":"# The horror \nWhy couldn't you just use a simple, easy 1 and 0 encoding? Why that disgusting cluster of 19 columns for all the 18 different choices for that Q16 thing?","734273da":"Like this.","98ddf7bc":"We got a few blue and orange bars, but that's hardly useful to understand what's really going on. What if we, instead, display the men-to-women ratio? How many men for each woman?","151895f0":"A complete disappointment, wasn't it? No reasonable correlation whatsoever. Is the field levelled in Data Science? Can the Bachelor and the Ph.D. compete in the workforce? Perhaps.","310c6df1":"Something you don't want to do when dealing with more than a dozen of columns. Do you understand what's going on?"}}