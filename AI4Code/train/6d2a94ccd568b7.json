{"cell_type":{"0111d978":"code","37fe275e":"code","e626528d":"code","85ae61c3":"code","ead30b45":"code","2eed5563":"code","a43d4095":"code","514e29da":"code","23496fa5":"code","6e2a6d18":"code","6b9cd724":"code","5235e846":"code","2681511a":"code","60bc337e":"code","cac3728d":"code","603a096a":"code","f3b34a91":"markdown","67592cbb":"markdown","674ad2ef":"markdown","67255f61":"markdown","c8f8532b":"markdown","a8efed83":"markdown","abf21c3a":"markdown","b2d0d3ec":"markdown"},"source":{"0111d978":"import numpy as np\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential , Model\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.preprocessing import image","37fe275e":"path = '..\/input\/simpsons-faces\/cropped\/'\nimages_dir = os.listdir(path)\nprint(f\"Length of dataset available: {len(images_dir)}\")","e626528d":"for image in images_dir[:9000:1000]:\n    sample = plt.imread(os.path.join(path , image))\n    plt.imshow(sample)\n    plt.axis('off')\n    plt.title(sample.shape)\n    plt.show() ","85ae61c3":"X_train = []\n\nfor im in images_dir:\n    img = image.load_img(os.path.join(path , im) , target_size=(128,128))\n    \n    # Normalize data in range (-1 , 1)\n    img = image.img_to_array(img)\/255.0\n    img = (img-0.5)\/0.5 \n    X_train.append(img)","ead30b45":"X_train = np.array(X_train)\nprint(X_train.shape)","2eed5563":"np.max(X_train) , np.min(X_train)","a43d4095":"NOISE_DIM = 100        # input noise vector\nTOTAL_EPOCHS = 100\nBATCH_SIZE = 64\nNO_OF_BATCHES = len(X_train)\/\/BATCH_SIZE     # No of batch iterations in one epoch\nHALF_BATCH = BATCH_SIZE\/\/2                   # half fake and half real data to pass through discriminator\n\nadam = Adam(learning_rate=2e-4 , beta_1=0.5)\n\nprint(HALF_BATCH , NO_OF_BATCHES)","514e29da":"generator = Sequential()\n\ngenerator.add(Dense(8*8*1024 , input_shape = (NOISE_DIM,)))\ngenerator.add(Reshape((8, 8, 1024)))\ngenerator.add(LeakyReLU(0.2))\ngenerator.add(BatchNormalization())\n\ngenerator.add(Conv2DTranspose(512, (5,5), strides=(2,2), padding='same'))\ngenerator.add(LeakyReLU(0.2))\ngenerator.add(BatchNormalization())\n\n\ngenerator.add(Conv2DTranspose(256, (5,5), strides=(2,2), padding='same'))\ngenerator.add(LeakyReLU(0.2))\ngenerator.add(BatchNormalization())\n\n\ngenerator.add(Conv2DTranspose(128, (5,5), strides=(2,2), padding='same'))\ngenerator.add(LeakyReLU(0.2))\ngenerator.add(BatchNormalization())\n\ngenerator.add(Conv2DTranspose(64, (5,5), strides=(2,2), padding='same'))\ngenerator.add(LeakyReLU(0.2))\ngenerator.add(BatchNormalization())\n\ngenerator.add(Conv2DTranspose(3, (5,5), strides=(1,1), padding='same' , activation='tanh'))\n\ngenerator.compile(loss = 'binary_crossentropy' , optimizer = adam)\ngenerator.summary()","23496fa5":"plot_model(generator , to_file = 'generator.png' , show_shapes=True)","6e2a6d18":"discriminator = Sequential()\n\ndiscriminator.add(Conv2D(64, (5,5), strides=(2,2), padding='same', input_shape = (128, 128, 3)))\ndiscriminator.add(LeakyReLU(0.2))\n\ndiscriminator.add(Conv2D(128, (5,5), strides=(2,2), padding='same'))\ndiscriminator.add(LeakyReLU(0.2))\n\ndiscriminator.add(Conv2D(256, (5,5), strides=(2,2), padding='same'))\ndiscriminator.add(LeakyReLU(0.2))\n\ndiscriminator.add(Conv2D(512, (5,5), strides=(2,2), padding='same'))\ndiscriminator.add(LeakyReLU(0.2))\n\ndiscriminator.add(Flatten())\ndiscriminator.add(Dense(1 , activation = 'sigmoid'))\n\ndiscriminator.compile(loss = 'binary_crossentropy' , optimizer = adam)\ndiscriminator.summary()","6b9cd724":"plot_model(discriminator , to_file = 'discriminator.png' , show_shapes=True)","5235e846":"discriminator.trainable = False\ngan_input = Input(shape= (NOISE_DIM))\ngen_img = generator(gan_input)\ngan_output = discriminator(gen_img)\n\nmodel = Model(gan_input , gan_output)\nmodel.compile(loss = 'binary_crossentropy' , optimizer = adam)\nmodel.summary()","2681511a":"## Function to display generated images\n\ndef save_imgs(epoch):\n    noise = np.random.normal(0 , 1 , size = (BATCH_SIZE , NOISE_DIM))\n    generated_imgs = generator.predict(noise).reshape(-1, 128, 128, 3)\n    plt.figure(figsize = (12 , 12))\n    \n    for i in range(BATCH_SIZE):\n        plt.subplot(8 , 8 , i+1)\n        plt.imshow(generated_imgs[i] , interpolation='nearest')\n        plt.axis('off')\n\n    plt.tight_layout()\n    plt.show()","60bc337e":"!mkdir images","cac3728d":"d_losses = []\ng_losses = []\n\nfor epoch in range(TOTAL_EPOCHS):\n    d_epoch_loss = 0.0\n    g_epoch_loss = 0.0\n\n    # Mini Batch SGD\n    for step in range(NO_OF_BATCHES): \n        \n        # STEP - 1 : Training Discriminator considering Generator frozen\n        \n        # Fake Data X - generate 50% random images\n        noise = np.random.normal(0 , 1 , size = (HALF_BATCH , NOISE_DIM))\n        fake_imgs = generator.predict(noise)\n        \n        # Real Data X - randomly select 50% real images\n        ids = np.random.randint(0 , len(X_train) , HALF_BATCH)\n        real_imgs = X_train[ids]\n        \n        # Labels\n        fake_y = np.zeros((HALF_BATCH , 1))\n        real_y = np.ones((HALF_BATCH , 1))*0.9  # One Sided Label Smoothing for Discriminator\n        \n        # Train discriminator on both batches of data separately and combine the loss\n        d_loss_real = discriminator.train_on_batch(real_imgs , real_y)\n        d_loss_fake = discriminator.train_on_batch(fake_imgs , fake_y)\n\n        d_loss = 0.5*d_loss_real + 0.5*d_loss_fake\n        d_epoch_loss += d_loss\n        \n        \n        # STEP - 2 : Train Generator (Complete Model Generator + Frozen Discriminator)\n        noise = np.random.normal(0 , 1 , size = (BATCH_SIZE , NOISE_DIM))\n        ground_truth_y = np.ones((BATCH_SIZE , 1))\n\n        g_loss = model.train_on_batch(noise , ground_truth_y)\n        g_epoch_loss += g_loss\n        \n    # Avg loss per batch\n    g_losses.append(g_epoch_loss\/NO_OF_BATCHES)\n    d_losses.append(d_epoch_loss\/NO_OF_BATCHES)\n\n    print('Epoch %d , Discriminator Loss %.4f , Generator Loss %.4f'%(epoch+1 , g_epoch_loss\/NO_OF_BATCHES , d_epoch_loss\/NO_OF_BATCHES))\n  \n    if (epoch+1)%15 == 0:\n        save_imgs(epoch+1)\n        plt.savefig('images\/gan_output_epoch_{}.png'.format(epoch+1))","603a096a":"# The non-trivial loss curves should saturate after certain epochs\n# If discriminator  improves , then generator also improves making image quality better and increases discriminator loss\nplt.plot(d_losses,label=\"Discriminator\")\nplt.plot(g_losses,label=\"Generator\")\nplt.legend()\nplt.show()","f3b34a91":"#### GENERATOR MODEL","67592cbb":"#### IMPORTING REQUIRED LIBRARIES","674ad2ef":"#### COMBINING BOTH NEURAL NETWORKS FOR GENERATOR TRAINING (consider discriminator frozen)","67255f61":"#### HYPERPARAMETERS","c8f8532b":"#### DATA PREPARATION AND NORMALIZATION","a8efed83":"#### DISCRIMINATOR MODEL","abf21c3a":"#### DATA VISUALIZATION","b2d0d3ec":"#### DCGAN MODEL TRAINING"}}