{"cell_type":{"f4d08308":"code","8d381cd2":"code","5deeaab7":"code","66040dcb":"code","9a47e4f3":"code","4485ad5f":"code","030a8ddd":"code","5e5cb58b":"code","31a723a0":"code","e82c87b3":"code","ece2da2f":"code","d7ea045c":"code","4bdc18c4":"code","e735efc5":"code","cb8867d1":"code","bb5850bf":"code","cf8aa1ca":"code","dfa80d59":"code","17f50d31":"code","7d754488":"code","14581e0a":"code","7951e0f4":"code","25bc1af4":"code","4664a777":"code","7f007149":"code","ba916e90":"code","234ca176":"code","2d34c9d0":"code","e0422ad0":"code","193d4b70":"code","131e4674":"code","1b939c00":"code","acd0c582":"code","36df91f4":"code","601eab0f":"code","982f65cf":"code","1f9eebb0":"code","f81afd64":"code","cdf56e5b":"code","41347aa5":"code","087003e1":"code","d64ae162":"code","5aa668b7":"code","7a9ba29d":"code","636e2696":"code","cb6454f4":"code","947cb541":"code","b96db5f2":"code","b9fa7146":"code","dadc99a6":"code","00c11bd4":"code","0185780a":"code","df67256c":"markdown","708ec953":"markdown","08df95b1":"markdown","98f893c0":"markdown","e481ac98":"markdown","d683c88f":"markdown","95870a70":"markdown","23fad4f8":"markdown","229af234":"markdown","81cef603":"markdown","076839b2":"markdown","5cde8896":"markdown","cec4042a":"markdown","0ac3beef":"markdown","dc052728":"markdown","75955c0b":"markdown","da140f0a":"markdown","4091212e":"markdown","d77a7444":"markdown","a9722789":"markdown"},"source":{"f4d08308":"import os\nimport cv2\nimport platform\nimport numpy as np\nimport pandas as pd\nimport random\nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output\n\nos.environ['PYTHONHASHSEED'] = '73'\n\nseed = 73\nrandom.seed(seed)\nnp.random.seed(seed)\n\nprint(platform.platform())\n%matplotlib inline","8d381cd2":"!nvidia-smi","5deeaab7":"!ls \/kaggle\/input\/","66040dcb":"MyDrive = '\/kaggle\/working'\nclear_output()\n\nDataDir = '..\/input\/covidx-cxr2'\nPneumoniaDir = '..\/input\/chest-xray-pneumonia\/chest_xray'\n\nprint('> Covid 19 dir:', os.listdir(DataDir))\nprint('> Pneumonia dir:', os.listdir(PneumoniaDir))","9a47e4f3":"from tqdm import tqdm\n\ntrain_image_dir = PneumoniaDir + '\/train'\ntest_image_dir = PneumoniaDir + '\/test'\nval_image_dir = PneumoniaDir + '\/val'\n\nimg_map = []\n\ndef prepareData(Dir, strat):\n    cats = [\"NORMAL\",\"PNEUMONIA\"]\n    for category in cats:\n        path = os.path.join(Dir,category)\n        class_num = cats.index(category)\n        \n        for img in tqdm(os.listdir(path)):\n            img_path = os.path.join(path,img)\n            img_map.append({'path': img_path, 'label': category})\n\nprepareData(train_image_dir,'train')\nprepareData(test_image_dir,'test')\nprepareData(val_image_dir, 'val')\n\nimg_map = pd.DataFrame(img_map).sample(frac = 1, random_state=seed)","4485ad5f":"#ricord, rsna, cohen, actmed, sirm, \ndef getClass(label):\n    if label == 'negative':\n        return 'NORMAL'\n    if label == 'positive':\n        return 'COVID'\n\ndef get_image_map(txt_path, strat):\n    train_txt = open(txt_path, 'r')\n    Lines = train_txt.readlines()\n    paths = []\n    \n    img_formats = ['jpg', 'jpeg', 'png']\n    \n    for n, line in enumerate(Lines):\n        querywords = line.split()\n\n        if len(querywords) == 4:\n            image_id = querywords[0]\n            image_path = DataDir + '\/' + strat + '\/'+ querywords[1]\n            label = querywords[2]\n\n        if len(querywords) == 5:\n            image_id = querywords[0]\n            image_path = DataDir + '\/' + strat + '\/'+ querywords[2]\n            label = querywords[3]\n            \n        for img_type in img_formats:\n            if img_type in line:\n                obj_ = {'path': image_path, 'label': getClass(label)}\n                if (('positive' in line) | ('negative' in line)):\n                    paths.append(obj_)\n\n    paths_df = pd.DataFrame(paths)\n    return paths_df","030a8ddd":"train_map = get_image_map(DataDir + '\/train.txt', \n                          strat='train').sample(frac = 1, random_state=73)\n\ntest_map = get_image_map(DataDir + '\/test.txt',\n                         strat='test').sample(frac = 1, random_state=73)","5e5cb58b":"img_path_map = pd.concat([img_map, train_map, test_map], axis=0).sample(frac = 1, random_state=73)\nimg_path_map.head()","31a723a0":"import matplotlib.pyplot as plt\n\ndef print_images(samples): \n    images = samples[\"path\"].to_numpy()\n    labels = samples['label'].to_numpy()\n    \n    fig=plt.figure(figsize=(20, 8))\n    columns = 4\n    rows = 1\n    \n    for i, image_path in enumerate(images):\n        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n        \n        fig.add_subplot(rows,columns,i + 1)\n        title = '{}'.format(labels[i])\n        \n        Sample_image = cv2.resize(image, (224, 224), interpolation = cv2.INTER_CUBIC)\n        \n        plt.imshow(Sample_image, cmap='gray')\n        plt.title(title)\n        \n    plt.show()\n        \nprint_images(img_path_map[img_path_map['label']==\"NORMAL\"].iloc[0:4])\nprint_images(img_path_map[img_path_map['label']==\"PNEUMONIA\"].iloc[0:4])\nprint_images(img_path_map[img_path_map['label']==\"COVID\"].iloc[0:4])\n\n%matplotlib inline","e82c87b3":"def getLabelCount(frame):\n    label_count = pd.Series(frame['label'].values.ravel()).value_counts()\n    n_classes = (label_count)\n    return label_count\n\nlabel_count = getLabelCount(img_path_map)\nprint(label_count)","ece2da2f":"from sklearn.model_selection import StratifiedShuffleSplit\n\nfeatures = img_path_map['path'].to_numpy()\nlabels = img_path_map['label'].to_numpy()\n\nstratified_sample = StratifiedShuffleSplit(n_splits=3, test_size=0.2, random_state=73)","d7ea045c":"for train_index, test_index in stratified_sample.split(features, labels):\n    X_train, test_X = features[train_index], features[test_index]\n    y_train, test_y = labels[train_index], labels[test_index]\n    \nhalf_size = np.int(len(test_X) \/ 2)\nX_test, y_test = test_X[0:half_size], test_y[0:half_size]\nX_val, y_val = test_X[half_size:], test_y[half_size:]","4bdc18c4":"train_map = pd.DataFrame()\ntrain_map['path'], train_map['label'] = X_train, y_train","e735efc5":"test_map = pd.DataFrame()\ntest_map['path'], test_map['label'] = X_test, y_test","cb8867d1":"val_map = pd.DataFrame()\nval_map['path'], val_map['label'] = X_val, y_val","bb5850bf":"# data summary\nprint('> {} train size'.format(X_train.shape[0]))\nprint('> {} test size'.format(X_test.shape[0]))\nprint('> {} val size'.format(X_val.shape[0]))","cf8aa1ca":"import cv2\nimport time\nimport imageio\nimport imgaug.augmenters as iaa\nimport imgaug as ia\nia.seed(73)\n\nColorCh = 3\nIMG_SIZE = 224\ninput_shape=(IMG_SIZE, IMG_SIZE, ColorCh)\n\nclasses = (\"COVID\", \"NORMAL\",\"PNEUMONIA\")\nCATEGORIES = sorted(classes)\n\nprint('> Classes:',CATEGORIES)","dfa80d59":"from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n\ndatagen = ImageDataGenerator(rescale = 1.\/255, \n                             horizontal_flip=True,\n                             brightness_range=[1.0,1.3],\n                             rotation_range=15,\n                             #zoom_range=0.2\n                            )","17f50d31":"batch_size = 32\n\ndef get_generator(frame_):\n    generator = datagen.flow_from_dataframe(\n                          dataframe=frame_,\n                          x_col=\"path\",\n                          y_col=\"label\",\n                          batch_size=batch_size,\n                          seed=seed,\n                          shuffle=False,\n                          class_mode=\"sparse\",\n                          color_mode=\"rgb\",\n                          save_format=\"jpeg\",\n                          target_size=(IMG_SIZE,IMG_SIZE)             \n             )\n    \n    return generator","7d754488":"train_df = train_map.sample(frac=1, random_state=seed)\ntrain_generator = get_generator(train_df)\n\nprint('> label count for train set')\ngetLabelCount(train_df)","14581e0a":"test_df = test_map.sample(frac=1, random_state=seed)\ntest_generator = get_generator(test_df)\n\nprint('> label count for test set')\ngetLabelCount(test_df)","7951e0f4":"val_df = val_map.sample(frac=1, random_state=seed)\nval_generator = get_generator(val_df)\n\nprint('> label count for val set')\ngetLabelCount(val_df)","25bc1af4":"print('> input shape:', input_shape)","4664a777":"import keras\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Add, add\nfrom tensorflow.keras.layers import InputLayer, Input, Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, Activation, MaxPool2D, ZeroPadding2D, SeparableConv2D\nfrom keras.layers.normalization import BatchNormalization\nfrom tensorflow.keras.models import Model, Sequential\nfrom keras import regularizers\n\nkernel_regularizer = regularizers.l2(0.0001)\n\nfinal_activation = 'softmax'\nentropy = 'sparse_categorical_crossentropy'\nn_classes = len(CATEGORIES)\nprint('> {} classes'.format(n_classes))","7f007149":"def FCLayers(baseModel):\n    baseModel.trainable = True\n    headModel = baseModel.output\n    headModel = Dropout(0.5, seed=73)(headModel)\n    headModel = Dense(n_classes, activation=final_activation)(headModel)\n    model = Model(inputs = baseModel.input, outputs = headModel)\n    5\n    return model","ba916e90":"from keras.layers.merge import concatenate\n\ndef Inception_block(input_layer, f1, f2, f3, f4):    \n    \n    path1 = Conv2D(filters=f1, kernel_size = (1,1), padding = 'same', activation = 'relu')(input_layer)\n    \n    path2 = Conv2D(filters = f2[0], kernel_size = (1,1), \n                   padding = 'same', activation = 'relu')(input_layer)\n    \n    path2 = Conv2D(filters = f2[1], kernel_size = (3,3), \n                   padding = 'same', activation = 'relu')(path2)\n\n    path3 = Conv2D(filters = f3[0], kernel_size = (1,1), \n                   padding = 'same', activation = 'relu')(input_layer)\n    \n    path3 = Conv2D(filters = f3[1], kernel_size = (5,5), \n                   padding = 'same', activation = 'relu')(path3)\n\n    path4 = MaxPooling2D((3,3), strides= (1,1), \n                         padding = 'same')(input_layer)\n    \n    path4 = Conv2D(filters = f4, kernel_size = (1,1), \n                   padding = 'same', activation = 'relu')(path4)\n    \n    output_layer = concatenate([path1, path2, path3, path4], axis = -1)\n\n    return output_layer","234ca176":"# auxiliary_classifiers\ndef Extra_network_2(X):\n    X2 = AveragePooling2D(pool_size = (5,5), strides = 3)(X)\n    X2 = Conv2D(filters = 128, kernel_size = (1,1), \n                padding = 'same', activation = 'relu')(X2)\n    \n    X2 = Flatten()(X2)\n    X2 = Dense(1024, activation = 'relu')(X2)\n    X2 = Dropout(0.5)(X2)\n    X2 = Dense(n_classes, activation = final_activation, name=\"output2\")(X2)\n    return X2\n\n\ndef Extra_network_1(X):\n    X1 = AveragePooling2D(pool_size = (5,5), strides = 3)(X)\n    X1 = Conv2D(filters = 128, kernel_size = (1,1), \n                padding = 'same', activation = 'relu')(X1)\n    \n    X1 = Flatten()(X1)\n    X1 = Dense(1024, activation = 'relu')(X1)\n    X1 = Dropout(0.5)(X1)\n    X1 = Dense(n_classes, activation = final_activation, name=\"output1\")(X1)\n    return X1","2d34c9d0":"def layer_4(X):\n    X = Inception_block(X, 192, (96, 208) , (16, 48), 64)\n    \n    X1 = Extra_network_1(X)\n    \n    X = Inception_block(X, 160, (112, 224), (24, 64), 64)\n    X = Inception_block(X, 128, (128, 256), (24, 64), 64)\n    X = Inception_block(X, 112, (144, 288), (32, 64), 64)\n    \n    X2 = Extra_network_2(X)\n    \n    X = Inception_block(X, 256, (160, 320), (32, 128), 128)\n    X = MaxPooling2D(pool_size = 3, strides = 2)(X)\n    \n    return X, X1, X2\n\ndef layer_3(X):\n    X = Inception_block(X, 64, (96, 128), (16, 32), 32)\n    X = Inception_block(X, 128, (128, 192), (32, 96), 64)\n    X = MaxPooling2D(pool_size= (3,3), strides = 2)(X)\n    \n    return X\n\ndef layer_2(X):\n    X = Conv2D(filters = 64, \n               kernel_size = 1, \n               strides = 1, \n               padding = 'same', \n               activation = 'relu')(X)\n    \n    X = Conv2D(filters = 192, \n               kernel_size = 3, \n               padding = 'same', \n               activation = 'relu')(X)\n    \n    X = MaxPooling2D(pool_size= 3, strides = 2)(X)\n    \n    return X","e0422ad0":"def load_GoogLeNet():\n    input_layer = Input(shape = input_shape)\n    \n    X = Conv2D(64, kernel_size = 7, strides = 2, \n               padding = 'valid', activation = 'relu')(input_layer)\n    \n    X = MaxPooling2D(pool_size = 3, strides = 2)(X)\n    \n    X = layer_2(X)\n    X = layer_3(X)\n    X, X1, X2 = layer_4(X)\n\n    X = Inception_block(X, 256, (160, 320), (32, 128), 128)\n    X = Inception_block(X, 384, (192, 384), (48, 128), 128)\n\n    X = GlobalAveragePooling2D()(X)\n    X = Dropout(0.6)(X)\n    \n    X = Dense(n_classes, activation = final_activation, name=\"output3\")(X)\n  \n    model = Model(input_layer, [X, X1, X2], name = 'GoogLeNet')\n\n    return model\n\nload_GoogLeNet().summary()","193d4b70":"from keras.applications import DenseNet121\n\ndef load_DenseNet121():\n    input_tensor = Input(shape=input_shape)\n    baseModel = DenseNet121(pooling='avg',\n                            include_top=False, \n                            input_tensor=input_tensor)\n    \n    model = FCLayers(baseModel)\n    return model\n\nload_DenseNet121().summary()","131e4674":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Dropout, Conv2D, LayerNormalization, GlobalAveragePooling1D\n\nCFGS = {\n    'swin_tiny_224': dict(input_size=(224, 224), window_size=7, embed_dim=96, depths=[2, 2, 6, 2], num_heads=[3, 6, 12, 24]),\n    'swin_small_224': dict(input_size=(224, 224), window_size=7, embed_dim=96, depths=[2, 2, 18, 2], num_heads=[3, 6, 12, 24]),\n    'swin_base_224': dict(input_size=(224, 224), window_size=7, embed_dim=128, depths=[2, 2, 18, 2], num_heads=[4, 8, 16, 32]),\n    'swin_base_384': dict(input_size=(384, 384), window_size=12, embed_dim=128, depths=[2, 2, 18, 2], num_heads=[4, 8, 16, 32]),\n    'swin_large_224': dict(input_size=(224, 224), window_size=7, embed_dim=192, depths=[2, 2, 18, 2], num_heads=[6, 12, 24, 48]),\n    'swin_large_384': dict(input_size=(384, 384), window_size=12, embed_dim=192, depths=[2, 2, 18, 2], num_heads=[6, 12, 24, 48])\n}\n\n\nclass Mlp(tf.keras.layers.Layer):\n    def __init__(self, in_features, hidden_features=None, out_features=None, drop=0., prefix=''):\n        super().__init__()\n        out_features = out_features or in_features\n        hidden_features = hidden_features or in_features\n        self.fc1 = Dense(hidden_features, name=f'{prefix}\/mlp\/fc1')\n        self.fc2 = Dense(out_features, name=f'{prefix}\/mlp\/fc2')\n        self.drop = Dropout(drop)\n\n    def call(self, x):\n        x = self.fc1(x)\n        x = tf.keras.activations.gelu(x)\n        x = self.drop(x)\n        x = self.fc2(x)\n        x = self.drop(x)\n        return x\n\n\ndef window_partition(x, window_size):\n    B, H, W, C = x.get_shape().as_list()\n    x = tf.reshape(x, shape=[-1, H \/\/ window_size,\n                   window_size, W \/\/ window_size, window_size, C])\n    x = tf.transpose(x, perm=[0, 1, 3, 2, 4, 5])\n    windows = tf.reshape(x, shape=[-1, window_size, window_size, C])\n    return windows\n\n\ndef window_reverse(windows, window_size, H, W, C):\n    x = tf.reshape(windows, shape=[-1, H \/\/ window_size,\n                   W \/\/ window_size, window_size, window_size, C])\n    x = tf.transpose(x, perm=[0, 1, 3, 2, 4, 5])\n    x = tf.reshape(x, shape=[-1, H, W, C])\n    return x\n\n\nclass WindowAttention(tf.keras.layers.Layer):\n    def __init__(self, dim, window_size, num_heads, qkv_bias=True, qk_scale=None, attn_drop=0., proj_drop=0., prefix=''):\n        super().__init__()\n        self.dim = dim\n        self.window_size = window_size\n        self.num_heads = num_heads\n        head_dim = dim \/\/ num_heads\n        self.scale = qk_scale or head_dim ** -0.5\n        self.prefix = prefix\n\n        self.qkv = Dense(dim * 3, use_bias=qkv_bias,\n                         name=f'{self.prefix}\/attn\/qkv')\n        self.attn_drop = Dropout(attn_drop)\n        self.proj = Dense(dim, name=f'{self.prefix}\/attn\/proj')\n        self.proj_drop = Dropout(proj_drop)\n\n    def build(self, input_shape):\n        self.relative_position_bias_table = self.add_weight(f'{self.prefix}\/attn\/relative_position_bias_table',\n                                                            shape=(\n                                                                (2 * self.window_size[0] - 1) * (2 * self.window_size[1] - 1), self.num_heads),\n                                                            initializer=tf.initializers.Zeros(), trainable=True)\n\n        coords_h = np.arange(self.window_size[0])\n        coords_w = np.arange(self.window_size[1])\n        coords = np.stack(np.meshgrid(coords_h, coords_w, indexing='ij'))\n        coords_flatten = coords.reshape(2, -1)\n        relative_coords = coords_flatten[:, :,\n                                         None] - coords_flatten[:, None, :]\n        relative_coords = relative_coords.transpose([1, 2, 0])\n        relative_coords[:, :, 0] += self.window_size[0] - 1\n        relative_coords[:, :, 1] += self.window_size[1] - 1\n        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n        relative_position_index = relative_coords.sum(-1).astype(np.int64)\n        self.relative_position_index = tf.Variable(initial_value=tf.convert_to_tensor(\n            relative_position_index), trainable=False, name=f'{self.prefix}\/attn\/relative_position_index')\n        self.built = True\n\n    def call(self, x, mask=None):\n        B_, N, C = x.get_shape().as_list()\n        qkv = tf.transpose(tf.reshape(self.qkv(\n            x), shape=[-1, N, 3, self.num_heads, C \/\/ self.num_heads]), perm=[2, 0, 3, 1, 4])\n        q, k, v = qkv[0], qkv[1], qkv[2]\n\n        q = q * self.scale\n        attn = (q @ tf.transpose(k, perm=[0, 1, 3, 2]))\n        relative_position_bias = tf.gather(self.relative_position_bias_table, tf.reshape(\n            self.relative_position_index, shape=[-1]))\n        relative_position_bias = tf.reshape(relative_position_bias, shape=[\n                                            self.window_size[0] * self.window_size[1], self.window_size[0] * self.window_size[1], -1])\n        relative_position_bias = tf.transpose(\n            relative_position_bias, perm=[2, 0, 1])\n        attn = attn + tf.expand_dims(relative_position_bias, axis=0)\n\n        if mask is not None:\n            nW = mask.get_shape()[0]  # tf.shape(mask)[0]\n            attn = tf.reshape(attn, shape=[-1, nW, self.num_heads, N, N]) + tf.cast(\n                tf.expand_dims(tf.expand_dims(mask, axis=1), axis=0), tf.float32)\n            attn = tf.reshape(attn, shape=[-1, self.num_heads, N, N])\n            attn = tf.nn.softmax(attn, axis=-1)\n        else:\n            attn = tf.nn.softmax(attn, axis=-1)\n\n        attn = self.attn_drop(attn)\n\n        x = tf.transpose((attn @ v), perm=[0, 2, 1, 3])\n        x = tf.reshape(x, shape=[-1, N, C])\n        x = self.proj(x)\n        x = self.proj_drop(x)\n        return x\n\n\ndef drop_path(inputs, drop_prob, is_training):\n    if (not is_training) or (drop_prob == 0.):\n        return inputs\n\n    # Compute keep_prob\n    keep_prob = 1.0 - drop_prob\n\n    # Compute drop_connect tensor\n    random_tensor = keep_prob\n    shape = (tf.shape(inputs)[0],) + (1,) * \\\n        (len(tf.shape(inputs)) - 1)\n    random_tensor += tf.random.uniform(shape, dtype=inputs.dtype)\n    binary_tensor = tf.floor(random_tensor)\n    output = tf.math.divide(inputs, keep_prob) * binary_tensor\n    return output\n\n\nclass DropPath(tf.keras.layers.Layer):\n    def __init__(self, drop_prob=None):\n        super().__init__()\n        self.drop_prob = drop_prob\n\n    def call(self, x, training=None):\n        return drop_path(x, self.drop_prob, training)\n\n\nclass SwinTransformerBlock(tf.keras.layers.Layer):\n    def __init__(self, dim, input_resolution, num_heads, window_size=7, shift_size=0, mlp_ratio=4.,\n                 qkv_bias=True, qk_scale=None, drop=0., attn_drop=0., drop_path_prob=0., norm_layer=LayerNormalization, prefix=''):\n        super().__init__()\n        self.dim = dim\n        self.input_resolution = input_resolution\n        self.num_heads = num_heads\n        self.window_size = window_size\n        self.shift_size = shift_size\n        self.mlp_ratio = mlp_ratio\n        if min(self.input_resolution) <= self.window_size:\n            self.shift_size = 0\n            self.window_size = min(self.input_resolution)\n        assert 0 <= self.shift_size < self.window_size, \"shift_size must in 0-window_size\"\n        self.prefix = prefix\n\n        self.norm1 = norm_layer(epsilon=1e-5, name=f'{self.prefix}\/norm1')\n        self.attn = WindowAttention(dim, window_size=(self.window_size, self.window_size), num_heads=num_heads,\n                                    qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop, prefix=self.prefix)\n        self.drop_path = DropPath(\n            drop_path_prob if drop_path_prob > 0. else 0.)\n        self.norm2 = norm_layer(epsilon=1e-5, name=f'{self.prefix}\/norm2')\n        mlp_hidden_dim = int(dim * mlp_ratio)\n        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim,\n                       drop=drop, prefix=self.prefix)\n\n    def build(self, input_shape):\n        if self.shift_size > 0:\n            H, W = self.input_resolution\n            img_mask = np.zeros([1, H, W, 1])\n            h_slices = (slice(0, -self.window_size),\n                        slice(-self.window_size, -self.shift_size),\n                        slice(-self.shift_size, None))\n            w_slices = (slice(0, -self.window_size),\n                        slice(-self.window_size, -self.shift_size),\n                        slice(-self.shift_size, None))\n            cnt = 0\n            for h in h_slices:\n                for w in w_slices:\n                    img_mask[:, h, w, :] = cnt\n                    cnt += 1\n\n            img_mask = tf.convert_to_tensor(img_mask)\n            mask_windows = window_partition(img_mask, self.window_size)\n            mask_windows = tf.reshape(\n                mask_windows, shape=[-1, self.window_size * self.window_size])\n            attn_mask = tf.expand_dims(\n                mask_windows, axis=1) - tf.expand_dims(mask_windows, axis=2)\n            attn_mask = tf.where(attn_mask != 0, -100.0, attn_mask)\n            attn_mask = tf.where(attn_mask == 0, 0.0, attn_mask)\n            self.attn_mask = tf.Variable(\n                initial_value=attn_mask, trainable=False, name=f'{self.prefix}\/attn_mask')\n        else:\n            self.attn_mask = None\n\n        self.built = True\n\n    def call(self, x):\n        H, W = self.input_resolution\n        B, L, C = x.get_shape().as_list()\n        assert L == H * W, \"input feature has wrong size\"\n\n        shortcut = x\n        x = self.norm1(x)\n        x = tf.reshape(x, shape=[-1, H, W, C])\n\n        # cyclic shift\n        if self.shift_size > 0:\n            shifted_x = tf.roll(\n                x, shift=[-self.shift_size, -self.shift_size], axis=[1, 2])\n        else:\n            shifted_x = x\n\n        # partition windows\n        x_windows = window_partition(shifted_x, self.window_size)\n        x_windows = tf.reshape(\n            x_windows, shape=[-1, self.window_size * self.window_size, C])\n\n        # W-MSA\/SW-MSA\n        attn_windows = self.attn(x_windows, mask=self.attn_mask)\n\n        # merge windows\n        attn_windows = tf.reshape(\n            attn_windows, shape=[-1, self.window_size, self.window_size, C])\n        shifted_x = window_reverse(attn_windows, self.window_size, H, W, C)\n\n        # reverse cyclic shift\n        if self.shift_size > 0:\n            x = tf.roll(shifted_x, shift=[\n                        self.shift_size, self.shift_size], axis=[1, 2])\n        else:\n            x = shifted_x\n        x = tf.reshape(x, shape=[-1, H * W, C])\n\n        # FFN\n        x = shortcut + self.drop_path(x)\n        x = x + self.drop_path(self.mlp(self.norm2(x)))\n\n        return x\n\n\nclass PatchMerging(tf.keras.layers.Layer):\n    def __init__(self, input_resolution, dim, norm_layer=LayerNormalization, prefix=''):\n        super().__init__()\n        self.input_resolution = input_resolution\n        self.dim = dim\n        self.reduction = Dense(2 * dim, use_bias=False,\n                               name=f'{prefix}\/downsample\/reduction')\n        self.norm = norm_layer(epsilon=1e-5, name=f'{prefix}\/downsample\/norm')\n\n    def call(self, x):\n        H, W = self.input_resolution\n        B, L, C = x.get_shape().as_list()\n        assert L == H * W, \"input feature has wrong size\"\n        assert H % 2 == 0 and W % 2 == 0, f\"x size ({H}*{W}) are not even.\"\n\n        x = tf.reshape(x, shape=[-1, H, W, C])\n\n        x0 = x[:, 0::2, 0::2, :]  # B H\/2 W\/2 C\n        x1 = x[:, 1::2, 0::2, :]  # B H\/2 W\/2 C\n        x2 = x[:, 0::2, 1::2, :]  # B H\/2 W\/2 C\n        x3 = x[:, 1::2, 1::2, :]  # B H\/2 W\/2 C\n        x = tf.concat([x0, x1, x2, x3], axis=-1)\n        x = tf.reshape(x, shape=[-1, (H \/\/ 2) * (W \/\/ 2), 4 * C])\n\n        x = self.norm(x)\n        x = self.reduction(x)\n\n        return x\n\n\nclass BasicLayer(tf.keras.layers.Layer):\n    def __init__(self, dim, input_resolution, depth, num_heads, window_size,\n                 mlp_ratio=4., qkv_bias=True, qk_scale=None, drop=0., attn_drop=0.,\n                 drop_path_prob=0., norm_layer=LayerNormalization, downsample=None, use_checkpoint=False, prefix=''):\n        super().__init__()\n        self.dim = dim\n        self.input_resolution = input_resolution\n        self.depth = depth\n        self.use_checkpoint = use_checkpoint\n\n        # build blocks\n        self.blocks = tf.keras.Sequential([SwinTransformerBlock(dim=dim, input_resolution=input_resolution,\n                                           num_heads=num_heads, window_size=window_size,\n                                           shift_size=0 if (\n                                               i % 2 == 0) else window_size \/\/ 2,\n                                           mlp_ratio=mlp_ratio,\n                                           qkv_bias=qkv_bias, qk_scale=qk_scale,\n                                           drop=drop, attn_drop=attn_drop,\n                                           drop_path_prob=drop_path_prob[i] if isinstance(\n                                               drop_path_prob, list) else drop_path_prob,\n                                           norm_layer=norm_layer,\n                                           prefix=f'{prefix}\/blocks{i}') for i in range(depth)])\n        if downsample is not None:\n            self.downsample = downsample(\n                input_resolution, dim=dim, norm_layer=norm_layer, prefix=prefix)\n        else:\n            self.downsample = None\n\n    def call(self, x):\n        x = self.blocks(x)\n\n        if self.downsample is not None:\n            x = self.downsample(x)\n        return x\n\n\nclass PatchEmbed(tf.keras.layers.Layer):\n    def __init__(self, img_size=(224, 224), patch_size=(4, 4), in_chans=3, embed_dim=96, norm_layer=None):\n        super().__init__(name='patch_embed')\n        patches_resolution = [img_size[0] \/\/\n                              patch_size[0], img_size[1] \/\/ patch_size[1]]\n        self.img_size = img_size\n        self.patch_size = patch_size\n        self.patches_resolution = patches_resolution\n        self.num_patches = patches_resolution[0] * patches_resolution[1]\n\n        self.in_chans = in_chans\n        self.embed_dim = embed_dim\n\n        self.proj = Conv2D(embed_dim, kernel_size=patch_size,\n                           strides=patch_size, name='proj')\n        if norm_layer is not None:\n            self.norm = norm_layer(epsilon=1e-5, name='norm')\n        else:\n            self.norm = None\n\n    def call(self, x):\n        B, H, W, C = x.get_shape().as_list()\n        assert H == self.img_size[0] and W == self.img_size[1], \\\n            f\"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\"\n        x = self.proj(x)\n        x = tf.reshape(\n            x, shape=[-1, (H \/\/ self.patch_size[0]) * (W \/\/ self.patch_size[0]), self.embed_dim])\n        if self.norm is not None:\n            x = self.norm(x)\n        return x\n\n\nclass SwinTransformerModel(tf.keras.Model):\n    def __init__(self, model_name='swin_tiny_patch4_window7_224', include_top=False,\n                 img_size=(224, 224), patch_size=(4, 4), in_chans=3, num_classes=1000,\n                 embed_dim=96, depths=[2, 2, 6, 2], num_heads=[3, 6, 12, 24],\n                 window_size=7, mlp_ratio=4., qkv_bias=True, qk_scale=None,\n                 drop_rate=0., attn_drop_rate=0., drop_path_rate=0.1,\n                 norm_layer=LayerNormalization, ape=False, patch_norm=True,\n                 use_checkpoint=False, **kwargs):\n        super().__init__(name=model_name)\n\n        self.include_top = include_top\n\n        self.num_classes = num_classes\n        self.num_layers = len(depths)\n        self.embed_dim = embed_dim\n        self.ape = ape\n        self.patch_norm = patch_norm\n        self.num_features = int(embed_dim * 2 ** (self.num_layers - 1))\n        self.mlp_ratio = mlp_ratio\n\n        # split image into non-overlapping patches\n        self.patch_embed = PatchEmbed(\n            img_size=img_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim,\n            norm_layer=norm_layer if self.patch_norm else None)\n        num_patches = self.patch_embed.num_patches\n        patches_resolution = self.patch_embed.patches_resolution\n        self.patches_resolution = patches_resolution\n\n        # absolute postion embedding\n        if self.ape:\n            self.absolute_pos_embed = self.add_weight('absolute_pos_embed',\n                                                      shape=(\n                                                          1, num_patches, embed_dim),\n                                                      initializer=tf.initializers.Zeros())\n\n        self.pos_drop = Dropout(drop_rate)\n\n        # stochastic depth\n        dpr = [x for x in np.linspace(0., drop_path_rate, sum(depths))]\n\n        # build layers\n        self.basic_layers = tf.keras.Sequential([BasicLayer(dim=int(embed_dim * 2 ** i_layer),\n                                                input_resolution=(patches_resolution[0] \/\/ (2 ** i_layer),\n                                                                  patches_resolution[1] \/\/ (2 ** i_layer)),\n                                                depth=depths[i_layer],\n                                                num_heads=num_heads[i_layer],\n                                                window_size=window_size,\n                                                mlp_ratio=self.mlp_ratio,\n                                                qkv_bias=qkv_bias, qk_scale=qk_scale,\n                                                drop=drop_rate, attn_drop=attn_drop_rate,\n                                                drop_path_prob=dpr[sum(depths[:i_layer]):sum(\n                                                    depths[:i_layer + 1])],\n                                                norm_layer=norm_layer,\n                                                downsample=PatchMerging if (\n                                                    i_layer < self.num_layers - 1) else None,\n                                                use_checkpoint=use_checkpoint,\n                                                prefix=f'layers{i_layer}') for i_layer in range(self.num_layers)])\n        self.norm = norm_layer(epsilon=1e-5, name='norm')\n        self.avgpool = GlobalAveragePooling1D()\n        if self.include_top:\n            self.head = Dense(num_classes, name='head')\n        else:\n            self.head = None\n\n    def forward_features(self, x):\n        x = self.patch_embed(x)\n        if self.ape:\n            x = x + self.absolute_pos_embed\n        x = self.pos_drop(x)\n\n        x = self.basic_layers(x)\n        x = self.norm(x)\n        x = self.avgpool(x)\n        return x\n\n    def call(self, x):\n        x = self.forward_features(x)\n        if self.include_top:\n            x = self.head(x)\n        return x\n\n\ndef SwinTransformer(model_name='swin_tiny_224', num_classes=1000, include_top=True, pretrained=True, use_tpu=False, cfgs=CFGS):\n    cfg = cfgs[model_name]\n    net = SwinTransformerModel(\n        model_name=model_name, include_top=include_top, num_classes=num_classes, img_size=cfg['input_size'], window_size=cfg[\n            'window_size'], embed_dim=cfg['embed_dim'], depths=cfg['depths'], num_heads=cfg['num_heads']\n    )\n    net(tf.keras.Input(shape=(cfg['input_size'][0], cfg['input_size'][1], 3)))\n    if pretrained is True:\n        url = f'https:\/\/github.com\/rishigami\/Swin-Transformer-TF\/releases\/download\/v0.1-tf-swin-weights\/{model_name}.tgz'\n        pretrained_ckpt = tf.keras.utils.get_file(\n            model_name, url, untar=True)\n    else:\n        pretrained_ckpt = pretrained\n\n    if pretrained_ckpt:\n        if tf.io.gfile.isdir(pretrained_ckpt):\n            pretrained_ckpt = f'{pretrained_ckpt}\/{model_name}.ckpt'\n\n        if use_tpu:\n            load_locally = tf.saved_model.LoadOptions(\n                experimental_io_device='\/job:localhost')\n            net.load_weights(pretrained_ckpt, options=load_locally)\n        else:\n            net.load_weights(pretrained_ckpt)\n\n    return net","1b939c00":"IMAGE_SIZE=[224, 224]\nCLASSES = ['normal', 'other_pneumonia', 'COVID-19']\n\ndef load_swin_transformer():\n    img_adjust_layer = tf.keras.layers.Lambda(lambda data: tf.keras.applications.imagenet_utils.preprocess_input(tf.cast(data, tf.float32), mode=\"torch\"), input_shape=[*IMAGE_SIZE, 3])\n    pretrained_model = SwinTransformer('swin_tiny_224', num_classes=len(CLASSES), include_top=False, pretrained=True, use_tpu=True)\n    model = tf.keras.Sequential([\n        img_adjust_layer,\n        pretrained_model,\n        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n    ])\n    return model\n\nload_swin_transformer().summary()","acd0c582":"def getMetrics(name, type_):\n    if name == 'GoogLeNet':\n        if type_ == 'accuracy':\n            return 'output3_accuracy'\n        if type_ == 'loss':\n            return 'output3_loss'\n        if type_ == 'val_accuracy':\n            return 'val_output3_accuracy'\n        if type_ == 'val_loss':\n            return 'val_output3_loss'\n        \n    else:\n        if type_ == 'accuracy':\n            return 'accuracy'\n        if type_ == 'loss':\n            return 'loss'\n        if type_ == 'val_accuracy':\n            return 'val_accuracy'\n        if type_ == 'val_loss':\n            return 'val_loss'","36df91f4":"from tensorflow.keras.callbacks import Callback, ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping, ReduceLROnPlateau\n          \nEPOCHS = 120\npatience = 3\n\nstart_lr = 0.00001\nmin_lr = 0.00001\nmax_lr = 0.00005\n\nrampup_epochs = 5\nsustain_epochs = 0\nexp_decay = .8\n        \ndef lrfn(epoch):\n    if epoch < rampup_epochs:\n        return (max_lr - start_lr)\/rampup_epochs * epoch + start_lr\n    elif epoch < rampup_epochs + sustain_epochs:\n        return max_lr\n    else:\n        return (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr\n        \ndef getCallbacks(name):\n    class myCallback(Callback):\n        def on_epoch_end(self, epoch, logs={}):\n            if ((logs.get(getMetrics(name,'accuracy'))>=0.999)):\n                print(\"\\nLimits Reached cancelling training!\")\n                self.model.stop_training = True\n\n            \n    end_callback = myCallback()\n\n    lr_plat = ReduceLROnPlateau(patience = 2, mode = 'min')\n\n    lr_callback = LearningRateScheduler(lambda epoch: lrfn(epoch), verbose=False)\n\n    early_stopping = EarlyStopping(patience = patience, monitor=getMetrics(name, 'val_loss'),\n                                 mode='min', restore_best_weights=True, \n                                 verbose = 1, min_delta = .00075)\n\n\n    checkpoint_filepath = name + '_Weights.h5'\n\n    model_checkpoints = ModelCheckpoint(filepath=checkpoint_filepath,\n                                        save_weights_only=True,\n                                        monitor=getMetrics(name, 'val_loss'),\n                                        mode='min',\n                                        verbose = 1,\n                                        save_best_only=True)\n\n    import datetime\n    log_dir=\"logs\/fit\/\" + '_' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")  \n    tensorboard_callback = TensorBoard(log_dir = log_dir, write_graph=True, histogram_freq=1)\n\n    return [end_callback, \n             lr_callback, \n             model_checkpoints,\n             early_stopping,\n             #tensorboard_callback,\n             lr_plat\n            ]\n\nGoogLeNet_callbacks = getCallbacks('GoogLeNet')\nSwinTransformer_callbacks = getCallbacks('SwinTransformer')\ncallbacks = getCallbacks('DenseNet121')","601eab0f":"def CompileModel(name, model):\n    if name == 'GoogLeNet':\n        model.compile(optimizer='adam', loss=entropy, metrics={\"output1\":\"accuracy\", \"output2\":\"accuracy\", \"output3\":\"accuracy\"})\n    else:\n        model.compile(optimizer='adam', loss=entropy, metrics=[\"accuracy\"])\n    return model\n\ndef FitModel(model, name):\n    callbacks_ = callbacks\n    if name == 'SwinTransformer':\n        callbacks_ = SwinTransformer_callbacks\n    if name == 'GoogLeNet':\n        callbacks_ = GoogLeNet_callbacks\n    history = model.fit(train_generator, \n                        epochs=EPOCHS,\n                        callbacks=callbacks_,\n                        validation_data = val_generator,\n                        steps_per_epoch=(len(train_generator.labels) \/ 80),\n                        validation_steps=(len(val_generator.labels) \/ 80),\n                       )\n    \n    model.load_weights(name + '_Weights.h5')\n\n    final_accuracy_avg = np.mean(history.history[getMetrics(name, \"val_accuracy\")][-5:])\n\n    final_loss = history.history[getMetrics(name, \"val_loss\")][-1]\n  \n    group = {history: 'history', name: 'name', model: 'model', final_accuracy_avg:'acc', final_loss: 'loss'}\n\n    print('\\n')\n    print('---'*15)\n    print(name,' Model')\n    print('Total Epochs :', len(history.history[getMetrics(name, 'loss')]))    \n    print('Restoring best Weights')\n    \n    index = (len(history.history[getMetrics(name, 'loss')]) - (patience + 1))\n    print('---'*15)\n    print('Best Epoch :', index)\n    print('---'*15)\n    \n    train_accuracy = history.history[getMetrics(name, 'accuracy')][index]\n    train_loss = history.history[getMetrics(name, 'loss')][index]\n    \n    val_accuracy = history.history[getMetrics(name, 'val_accuracy')][index]\n    val_loss = history.history[getMetrics(name, 'val_loss')][index]\n\n    print('Accuracy on train:', train_accuracy,\n          '\\tLoss on train:', train_loss)\n    \n    print('Accuracy on val:', val_accuracy ,\n          '\\tLoss on val:', val_loss)\n    print('---'*15)\n\n    return model, history","982f65cf":"def BuildModel(name):\n    if name == 'GoogLeNet':\n        prepared_model = load_GoogLeNet() \n    if name == 'DenseNet121':\n        prepared_model = load_DenseNet121()\n    if name == 'SwinTransformer':\n        prepared_model = load_swin_transformer()\n        \n    compiled_model = CompileModel(name, prepared_model)\n    return compiled_model","1f9eebb0":"s_compiled_model = BuildModel('SwinTransformer')\ns_model, s_history = FitModel(s_compiled_model, 'SwinTransformer')","f81afd64":"g_compiled_model = BuildModel('GoogLeNet')\ng_model, g_history = FitModel(g_compiled_model, 'GoogLeNet')","cdf56e5b":"d_compiled_model = BuildModel('DenseNet121')\nd_model, d_history = FitModel(d_compiled_model, 'DenseNet121')","41347aa5":"%matplotlib inline\ndef print_graph(item, index, history):\n    plt.figure()\n    train_values = history.history[item][0:index]\n    plt.plot(train_values)\n    test_values = history.history['val_' + item][0:index]\n    plt.plot(test_values)\n    plt.legend(['training','validation'])\n    plt.title('Training and validation '+ item)\n    plt.xlabel('epoch')\n    plt.show()\n    plot = '{}.png'.format(item)\n    plt.savefig(plot)","087003e1":"import seaborn as sns\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_curve, roc_auc_score, plot_roc_curve, accuracy_score, classification_report, confusion_matrix\n\ndef test_set_results(pred_value, n=1):    \n    y_test = test_generator.labels\n    X_test, _ = test_generator.next()\n    \n    corr_pred = metrics.confusion_matrix(y_test, pred_value)\n    fig=plt.figure(figsize=(10, 8))\n    ax = plt.axes()\n    \n    sns.heatmap(corr_pred,annot=True, fmt=\"d\",cmap=\"Purples\", xticklabels=CATEGORIES, yticklabels=CATEGORIES)\n    ax.set_title('Dense Output {}'.format(n))\n    plt.show()\n    \n    n_correct = np.int(corr_pred[0][0] + corr_pred[1][1] + corr_pred[2][2])\n    print('...'*15)\n\n    print('> Correct Predictions:', n_correct)\n    \n    n_wrongs = len(y_test) - n_correct\n    print('> Wrong Predictions:', n_wrongs)\n    print('...'*15)\n    \n    print(classification_report(test_generator.labels, pred_value, target_names=CATEGORIES))","d64ae162":"def printResults(name, model):\n    predictions = model.predict(test_generator, verbose=1)\n    preds = np.argmax(predictions, axis=1)\n    test_set_results(preds)","5aa668b7":"def model_summary(model, history, name):\n    index = (len(history.history[getMetrics(name, 'loss')]) - (patience + 1))\n    print('Best Epochs: ', index)\n    \n    if name == 'GoogLeNet':\n        results = model.evaluate(test_generator, verbose=1)\n        loss, output3_loss, output1_loss, output2_loss, output3_accuracy, output1_accuracy, output2_accuracy = results\n        \n        for i in range(3):\n            n = i + 1\n            out_layer = 'Output Layer {}'.format(n)\n            \n            if n == 1:\n                test_accuracy = output1_accuracy\n                test_loss = output1_loss\n\n            if n == 2:\n                test_accuracy = output2_accuracy\n                test_loss = output2_loss\n                \n            if n == 3:\n                test_accuracy = output3_accuracy\n                test_loss = output3_loss\n                \n                \n            output_name = 'output{}_'.format(n)\n            train_accuracy, train_loss = history.history[output_name + 'accuracy'][index], history.history[output_name + 'loss'][index]\n            \n  \n            print_graph(output_name + 'loss', index, history)\n            print_graph(output_name + 'accuracy', index, history)\n        \n            print('---'*15)  \n            print('GoogLeNet Dense output {}:'.format(n))\n            \n            print('> Accuracy on train :'.format(out_layer), train_accuracy, \n                  '\\tLoss on train:',train_loss)\n        \n            print('> Accuracy on test :'.format(out_layer), test_accuracy,\n                  '\\tLoss on test:',test_loss)\n            \n            print('---'*15)\n            print('> predicting test')\n            print('---'*15)\n            \n            predictions = model.predict(test_generator, verbose=1)\n            preds = np.argmax(predictions[i], axis=1)\n            test_set_results(preds, n)\n                \n    else:\n        test_loss, test_accuracy = model.evaluate(test_generator, verbose=1)\n        \n        train_accuracy = history.history['accuracy'][index]\n        train_loss = history.history['loss'][index]\n\n        print_graph('loss', index, history)\n        print_graph('accuracy', index, history)\n        \n        print('---'*15) \n        print(name)\n        print('> Accuracy on train:',train_accuracy, \n              '\\tLoss on train:',train_loss)\n        \n        print('> Accuracy on test:',test_accuracy,\n              '\\tLoss on test:',test_loss)\n        \n        print('---'*15)\n        print('> predicting test')\n        print('---'*15)\n        \n        printResults(name, model)","7a9ba29d":"model_summary(g_model, g_history, 'GoogLeNet')","636e2696":"model_summary(d_model, d_history, 'DenseNet121')","cb6454f4":"model_summary(s_model, s_history, 'SwinTransformer')","947cb541":"from IPython.display import FileLink","b96db5f2":"g_model.save('GoogLeNet_model.h5')\nFileLink(r'.\/GoogLeNet_model.h5')","b9fa7146":"d_model.save('DenseNet121_model.h5')\nFileLink(r'.\/DenseNet121_model.h5')","dadc99a6":"s_model.save('SwinTransformer_model.h5')\nFileLink(r'.\/SwinTransformer_model.h5')","00c11bd4":"a=1\nwhile a=1:\n    b=a","0185780a":"from IPython.display import IFrame\nIFrame(src='https:\/\/model-tester.web.app\/covid_19', width='100%', height=1000)","df67256c":"## Training SwinTransformer","708ec953":"## SwinTransformer Results","08df95b1":"## **GoogLeNet Results**","98f893c0":"## **Model Evaluation on the TestSet**","e481ac98":"### **Visualization**","d683c88f":"## **Training GoogLeNet**","95870a70":"### **Getting image path and labels from *.txt files**","23fad4f8":"## **Training DenseNet121**","229af234":"## **Building Models**","81cef603":"## **Compile** and **Fit Model**","076839b2":"## **Saving Models**","5cde8896":"## Get metrics","cec4042a":"## **GoogLenet**\n\n**Blog Reference**: https:\/\/medium.com\/mlearning-ai\/implementation-of-googlenet-on-keras-d9873aeed83c","0ac3beef":"## **Data Preparation**","dc052728":"## **Virus Classification**\n\n+ **Datasets**: chest-xray-pneumonia + covidx-cxr2\n\n+ **Classes**: Normal, Pneumonia, Covid_19\n\n+ **Models**: GoogLeNet, DenseNet121","75955c0b":"## **DenseNet121**","da140f0a":"## **DenseNet121 Results**","4091212e":"## **Call Backs**","d77a7444":"## **Deployed model**\n\n+ **Models**: DenseNet121\n+ **Size**: 85.9 MB\n+ **Build With**: React Native\n+ **Supported Versions**: ANDROID, IOS, WEB","a9722789":"## Github Tensorflow Swin Transformer Model (rishigami)"}}