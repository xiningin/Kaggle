{"cell_type":{"d67aa637":"code","600d13d7":"code","19422ff7":"code","749303d6":"code","dba653e8":"code","c8cd8715":"code","256cbaf4":"code","699b43de":"code","13c5183c":"code","3a612434":"code","6ab909e9":"code","a7a33599":"code","09d3d719":"code","79732003":"code","8543c3a0":"code","4653d3f5":"code","6aba0aed":"code","52dd74fa":"code","96c9705e":"code","42374164":"code","185139dc":"code","6fb2e18b":"code","47bbeac1":"code","85345694":"code","7b70d0cb":"code","302601c2":"code","88dbf70e":"code","99307fb3":"code","a5f5b340":"code","04f38243":"code","7844d681":"code","95259c77":"code","5843896e":"code","69ea548b":"code","a7fda142":"code","7c30526e":"code","6e3eef42":"code","612a98b1":"code","b9709d28":"code","ed87ce22":"code","1a2881b8":"code","88455829":"code","e246eb53":"code","eba3dec4":"code","e901d4dd":"code","5c8a4d32":"code","532c30f2":"code","f0a8880d":"code","7116e3a8":"code","8d3bca62":"code","c71d3258":"code","606e2dd4":"code","5fe75f26":"code","58d22931":"code","5a4f9bc8":"code","14b27f0a":"code","2be25d14":"code","1e17afcf":"code","369142a0":"code","d5d484e2":"code","4b6a72cd":"code","bb92bf8a":"markdown","600d2f12":"markdown","037ad801":"markdown","a4e5c4f4":"markdown","2a188c19":"markdown","9637049a":"markdown","75933068":"markdown","29cb9895":"markdown","b30d6634":"markdown","28f597a4":"markdown","12d9aa5c":"markdown","8cbf3e0c":"markdown","76661ce2":"markdown","afae7e59":"markdown","3db8d489":"markdown","1f57a7db":"markdown","6b782c08":"markdown","df2ef69c":"markdown","ea6fdb8c":"markdown","ad653df2":"markdown","00ce607f":"markdown","3173884e":"markdown","edf9fc0d":"markdown","76465f22":"markdown","34bbb07f":"markdown","d80bed1e":"markdown","9e4b2e85":"markdown","69ad9b09":"markdown","d8a59e00":"markdown","137bbe38":"markdown","865ed521":"markdown","fa6aaf49":"markdown","252362d6":"markdown","fcdd9b7c":"markdown","d0fccaeb":"markdown"},"source":{"d67aa637":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n#plt.style.use('fivethirtyeight')\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","600d13d7":"data = pd.read_csv('..\/input\/train.csv')","19422ff7":"data.head()\n","749303d6":"data.isnull()","dba653e8":"data.isnull().sum()","c8cd8715":"pd.crosstab(data.Sex,data.Survived,margins=True).style.background_gradient(cmap='summer_r')","256cbaf4":"data.groupby(['Sex','Survived'])['Survived'].count()\n","699b43de":"f,ax=plt.subplots(1,2,figsize=(10,5))\ndata['Survived'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.2f%%',ax=ax[0])\nax[0].set_title('Survived')\nax[0].set_ylabel('')\nsns.countplot('Survived', data=data, ax=ax[1])\nax[1].set_title('Survived')\nplt.show()","13c5183c":"f,ax=plt.subplots(1,2,figsize=(10,5))\ndata[['Sex', 'Survived']].groupby(['Sex']).mean().plot.bar(ax=ax[0])\nax[0].set_title('Survived vs Sex')\nsns.countplot('Sex', hue='Survived', data=data, ax=ax[1])\nax[1].set_title('Survivied vs Dead')\nplt.show()","3a612434":"data.groupby(['Pclass', 'Survived'])['Survived'].count()","6ab909e9":"pd.crosstab(data.Pclass,data.Survived,margins=True).style.background_gradient(cmap='Wistia')","a7a33599":"f,ax=plt.subplots(1,2,figsize=(10,5))\ndata['Pclass'].value_counts().plot.bar(color=['#CD7F32','#FFDF00','#D3D3D3'],ax=ax[0])\nax[0].set_title('Passengers by Pclass')\nax[0].set_ylabel('Count')\nsns.countplot('Pclass',hue='Survived',data=data,ax=ax[1])\nax[1].set_title('Pclass-Survived vs Dead')\nplt.show()","09d3d719":"pd.crosstab([data.Sex,data.Survived],data.Pclass,margins=True).style.background_gradient(cmap='cool')","79732003":"sns.factorplot('Pclass','Survived', hue = 'Sex', data=data)\nplt.show()","8543c3a0":"print('Oldest Passenger was ',data['Age'].max(), 'years old.' )\nprint('Youngest Passenger was ',data['Age'].min(), 'years old')\nprint('Average age for the passengers was ', data['Age'].mean(), 'Years')","4653d3f5":"f,ax=plt.subplots(1,2,figsize=(10,5))\nsns.violinplot('Pclass', 'Age', hue = 'Survived', data=data, split=True, ax=ax[0])\nax[0].set_title('Pclass and Age vs Survived')\nax[0].set_yticks(range(0,110,10))\nsns.violinplot('Sex', 'Age', hue = 'Survived', data=data, split=True, ax=ax[1])\nax[1].set_title('Age and Sex vs Survival')\nax[1].set_yticks(range(0,110,10))\nplt.show()","6aba0aed":"data['Initial']=0\nfor i in data:\n    data['Initial']=data.Name.str.extract('([A-Za-z]+)\\.')    ","52dd74fa":"pd.crosstab(data.Initial,data.Sex).T.style.background_gradient(cmap='hsv')","96c9705e":"data['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don'],['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr'],inplace=True)\n","42374164":"data.groupby('Initial')['Age'].mean()","185139dc":"data.loc[(data.Age.isnull())&(data.Initial=='Mr'),'Age']=33\ndata.loc[(data.Age.isnull())&(data.Initial=='Mrs'),'Age']=36\ndata.loc[(data.Age.isnull())&(data.Initial=='Master'),'Age']=5\ndata.loc[(data.Age.isnull())&(data.Initial=='Miss'),'Age']=22\ndata.loc[(data.Age.isnull())&(data.Initial=='Others'),'Age']=46","6fb2e18b":"data.isnull().sum()","47bbeac1":"f,ax=plt.subplots(1,2,figsize=(15,10))\ndata[data['Survived']==0].Age.plot.hist(ax=ax[0],bins=20,edgecolor='black',color='red')\nax[0].set_title('Survived=0')\nx1=list(range(0,85,5))\nax[0].set_xticks(x1)\ndata[data['Survived']==1].Age.plot.hist(ax=ax[1],bins=20,edgecolor='black',color='green')\nax[1].set_title('Survived=1')\nx2=list(range(0,85,5))\nax[1].set_xticks(x2)\nplt.show()","85345694":"sns.factorplot('Pclass','Survived',col='Initial',data=data)\nplt.show()","7b70d0cb":"pd.crosstab([data.Embarked,data.Pclass],[data.Sex,data.Survived],margins=True).style.background_gradient(cmap='autumn')","302601c2":"sns.factorplot('Embarked', 'Survived', data=data)\nfig=plt.gcf()\nfig.set_size_inches(5,3)\nplt.show()","88dbf70e":"f,ax=plt.subplots(2,2,figsize=(15,10))\nsns.countplot('Embarked',data=data,ax=ax[0,0])\nax[0,0].set_title('Passengers Boarded')\nsns.countplot('Embarked',hue='Sex',data=data,ax=ax[0,1])\nax[0,1].set_title('Gender Embarked')\nsns.countplot('Embarked',hue='Survived',data=data,ax=ax[1,0])\nax[1,0].set_title('Embarked vs Survived')\nsns.countplot('Embarked',hue='Pclass',data=data,ax=ax[1,1])\nax[1,1].set_title('Embarked vs Pclass')\nplt.subplots_adjust(wspace=0.2,hspace=0.5)\nplt.show()","99307fb3":"sns.factorplot('Pclass','Survived', hue='Sex',col='Embarked',data=data)\nplt.show()","a5f5b340":"data['Embarked'].fillna('S', inplace=True)","04f38243":"data.Embarked.isnull().any()","7844d681":"pd.crosstab([data.SibSp],data.Survived,margins=True).style.background_gradient(cmap='summer_r')","95259c77":"f,ax=plt.subplots(1,2,figsize=(15,5))\nsns.barplot('SibSp','Survived',data=data,ax=ax[0])\nax[0].set_title('Siblings vs Survived')\nsns.factorplot('SibSp','Survived',data=data,ax=ax[1])\nax[1].set_title('SibSp vs Survived')\nplt.close(2)\nplt.show()","5843896e":"pd.crosstab(data.SibSp,data.Pclass).style.background_gradient(cmap='summer_r')\n","69ea548b":"pd.crosstab(data.Parch,data.Pclass).style.background_gradient(cmap='summer_r')\n","a7fda142":"f,ax=plt.subplots(1,2,figsize=(15,5))\nsns.barplot('Parch','Survived',data=data,ax=ax[0])\nax[0].set_title('Parch vs Survived')\nsns.factorplot('Parch','Survived',data=data,ax=ax[1])\nax[1].set_title('Parch vs Survived')\nplt.close(2)\nplt.show()","7c30526e":"print('Highest Fare was:',data['Fare'].max())\nprint('Lowest Fare was:',data['Fare'].min())\nprint('Average Fare was:',data['Fare'].mean())","6e3eef42":"f,ax=plt.subplots(1,2,figsize=(15,10))\ndata[data['Survived']==0].Fare.plot.hist(ax=ax[0],bins=30,edgecolor='black',color='red')\nax[0].set_title('Survived= 0')\nx1=list(range(0,550,50))\nax[0].set_xticks(x1)\ndata[data['Survived']==1].Fare.plot.hist(ax=ax[1],color='green',bins=30,edgecolor='black')\nax[1].set_title('Survived= 1')\nx2=list(range(0,550,50))\nax[1].set_xticks(x2)\nplt.show()","612a98b1":"f,ax=plt.subplots(1,2,figsize=(10,5))\nsns.violinplot(\"Pclass\",\"Fare\", hue=\"Survived\", data=data,split=True,ax=ax[0])\nax[0].set_title('Pclass and Fare vs Survived')\nax[0].set_yticks(range(0,550,50))\nsns.violinplot(\"Sex\",\"Fare\", hue=\"Survived\", data=data,split=True,ax=ax[1])\nax[1].set_title('Sex and Fare vs Survived')\nax[1].set_yticks(range(0,550,50))\nplt.show()","b9709d28":"sns.heatmap(data.corr(),annot=True,cmap='PiYG',linewidths=0.2)\nfig=plt.gcf()\nfig.set_size_inches(10,8)\nplt.show()","ed87ce22":"data['Age_band']=0\ndata.loc[data['Age']<=16,'Age_band']=0\ndata.loc[(data['Age']>16)&(data['Age']<=32),'Age_band']=1\ndata.loc[(data['Age']>32)&(data['Age']<=48),'Age_band']=2\ndata.loc[(data['Age']>48)&(data['Age']<=64),'Age_band']=3\ndata.loc[(data['Age']>64)&(data['Age']<=80),'Age_band']=4\ndata.head(2)","1a2881b8":"data['Age_band'].value_counts().to_frame()","88455829":"sns.factorplot('Age_band','Survived',data=data,col='Pclass')\nplt.show()","e246eb53":"sns.barplot('Age_band','Survived',data=data)","eba3dec4":"data['Family']=0\ndata['Family']=data['Parch']+data['SibSp']\ndata['Alone']=0\ndata.loc[data.Family==0,'Alone']=1\ndata.head(3)","e901d4dd":"f,ax=plt.subplots(1,2,figsize=(10,5))\nsns.factorplot('Family','Survived',data=data,ax=ax[0])\nax[0].set_title('Family vs Survived')\nsns.factorplot('Alone','Survived',data=data,ax=ax[1])\nax[1].set_title('Alone vs Survived')\nplt.close(2)\nplt.close(3)\nplt.show()","5c8a4d32":"sns.factorplot('Alone','Survived',data=data,hue='Sex',col='Pclass')","532c30f2":"data['Fare_range']=pd.qcut(data['Fare'],5)\ndata.groupby(['Fare_range'])['Survived'].mean().to_frame().style.background_gradient(cmap='summer_r')","f0a8880d":"data['Fare_cat']=0\ndata.loc[data['Fare']<=0.7854,'Fare_cat']=0\ndata.loc[(data['Fare']>0.7854)&(data['Fare']<=10.5),'Fare_cat']=1\ndata.loc[(data['Fare']>10.5)&(data['Fare']<=21.679),'Fare_cat']=2\ndata.loc[(data['Fare']>21.679)&(data['Fare']<=39.688),'Fare_cat']=3\ndata.loc[(data['Fare']>39.688)&(data['Fare']<=512.329),'Fare_cat']=4","7116e3a8":"sns.factorplot('Fare_cat','Survived',data=data,hue='Sex')\nplt.show()","8d3bca62":"data['Sex'].replace(['male','female'],[0,1],inplace=True)\ndata['Embarked'].replace(['S','C','Q'],[0,1,2],inplace=True)\ndata['Initial'].replace(['Mr','Mrs','Miss','Master','Other'],[0,1,2,3,4],inplace=True)\n","c71d3258":"data.head(2)","606e2dd4":"data.drop(['Name','Age','Ticket','Fare','Cabin','Fare_range','PassengerId'],axis=1,inplace=True)\nsns.heatmap(data.corr(),annot=True,cmap='PiYG',linewidths=0.2,annot_kws={'size':8})\nfig=plt.gcf()\nfig.set_size_inches(8,6)\nplt.show()","5fe75f26":"data.head(2)\n","58d22931":"from sklearn.linear_model import LogisticRegression \nfrom sklearn import svm\nfrom sklearn.ensemble import RandomForestClassifier #Random Forest\nfrom sklearn.neighbors import KNeighborsClassifier #KNN\nfrom sklearn.tree import DecisionTreeClassifier #Decision Tree\nfrom sklearn.cross_validation import train_test_split \nfrom sklearn import metrics #accuracy measure\nfrom sklearn.metrics import confusion_matrix","5a4f9bc8":"train,test=train_test_split(data,test_size=0.3,random_state=0,stratify=data['Survived'])\ntrain_X=train[train.columns[1:]]\ntrain_Y=train[train.columns[:1]]\ntest_X=test[test.columns[1:]]\ntest_Y=test[test.columns[:1]]\nX=data[data.columns[1:]]\nY=data['Survived']","14b27f0a":"model = LogisticRegression()\nmodel.fit(train_X,train_Y)\nprediction1=model.predict(test_X)\nprint('The accuracy is for Logistic Regression is ',metrics.accuracy_score(prediction1,test_Y))","2be25d14":"model=DecisionTreeClassifier()\nmodel.fit(train_X,train_Y)\nprediction2=model.predict(test_X)\nprint('The accuracy of the Decision Tree is',metrics.accuracy_score(prediction2,test_Y))","1e17afcf":"model=RandomForestClassifier()\nmodel.fit(train_X,train_Y)\nprediction3=model.predict(test_X)\nprint('The accuracy of the Random Forests is',metrics.accuracy_score(prediction3,test_Y))","369142a0":"model=KNeighborsClassifier() \nmodel.fit(train_X,train_Y)\nprediction4=model.predict(test_X)\nprint('The accuracy of the KNN is',metrics.accuracy_score(prediction4,test_Y))","d5d484e2":"from sklearn.model_selection import cross_val_predict ","4b6a72cd":"f,ax=plt.subplots(2,2,figsize=(10,8))\ny_pred = cross_val_predict(RandomForestClassifier(n_estimators=100),X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,y_pred),ax=ax[0,0],annot=True,fmt='2.0f')\nax[0,0].set_title('Matrix for Random-Forests')\ny_pred = cross_val_predict(LogisticRegression(),X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,y_pred),ax=ax[0,1],annot=True,fmt='2.0f')\nax[0,1].set_title('Matrix for Logistic Regression')\ny_pred = cross_val_predict(DecisionTreeClassifier(),X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,y_pred),ax=ax[1,0],annot=True,fmt='2.0f')\nax[1,0].set_title('Matrix for Decision Tree')\ny_pred = cross_val_predict(KNeighborsClassifier(n_neighbors=9),X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,y_pred),ax=ax[1,1],annot=True,fmt='2.0f')\nax[1,1].set_title('Matrix for KNN')\nplt.show()\n\n","bb92bf8a":"Dealing with Null values of Embarked:\nUse S as default for null values as max passengers boarded from S.","600d2f12":"Realtion for siblings or spouse","037ad801":"Like age, fare is also a continuous feature. So we have grouped age into 5 sections.\nThe costlier the fare more are chances for surviving. We will give single values to Fare_range.\n","a4e5c4f4":"1=Alone 0=Family. \nTravelling alone has less survival rates than going with family irrespective of Pclass and Gender.","2a188c19":"Feature Engineering & Data Cleaning:\nAll the feautures present in the table are not necessary for prediction of data.\nWe can eliminate unwanted features or even add new features for accurate data prediction.\nWe will analyze all the features:\n\nAGE: It is a continuous feature. Machine learning models dont support continuous features well.\nTo categorize people into different groups is difficult as age is a continuous factor.\nWe can categorize age in sections. Each section has a age gap. The total age varies from 0-80yrs, so we can divide it into 5 sections ie o-16, 17-32 and so on. Hence we can eliminate the Age feature.\n","9637049a":"Most passengers were from the age group 17 to 32. \nVery few passenger were above 65.","75933068":"PREDICTIVE MODELLING:\n","29cb9895":"Inference: Survival rate decreases with age irresective of the class. Class 4 has low survival rate. ","b30d6634":"We have combined siblings\/spouse and parent\/children into a new feature called family, whereas those who dont have any family are put into feature alone. Hence we can eliminate SibSp and Parch.","28f597a4":"Inference from Pclass :\n1.Class 3 has max no of passengers. ie 55% are in class 3.\n2.More no of passenger are saved from class 1 percentage wise (62%).\n3.No other class has survival rate of more than 50%.\n4.The class that is costlier has more survival rate. Money speaks!","12d9aa5c":"Fare_cat is an important feature \nNow lets convert everything into numerical values.\n","8cbf3e0c":"Survival chances based on port of Embarkation for Pclass and Gender.","76661ce2":"Inference for Gender and Pclass Relation:\n1.Almost all females of class-1 survived barring 3 out of 94 and 70 out of 76 survived from the class 2 and 50% survived from class3.\n2.So the maximum priority was given to class-1 and class-2 female passenger their survival rate was 97% and 92% respectively.\n3.Incase of males 37% is the survival rate for class 1. For class 2 and 3 survival rate is pretty low.","afae7e59":"Inference:\n1.Max children were saved ie 0-5yrs.\n2.Very few senior citizens survived the disaster nobody from 65-75 yrs of age survived.\n3.The oldest passengers were saved.\n","3db8d489":"Inference:\n1.More no of people boarded from Southapmton.\n2.Cherbourg had more no of survivors than the victims ie more than 50% of Cherbourg passengers survived.\n3.Cherbourg had more no of class 1 passengers which led to more survivor rate for Cherbourg passengers.\n4.Queensland had least class 1 or class 2 passengers.\n5.Females from all 3 ports class 1 and 2 had a good survival rate and those from class 3 of Queensland also had higher survival rate.\n6.Class 3 of Southampton does'nt have a good survival rate either for men or women.","1f57a7db":"Fare Relation","6b782c08":"Inference:\n1.Most Passengers did not have any sibling.\n2.We can see passengers having 1 or 2 siblings\/spouse had high chances of survival about 50%.\n3.Passengers having 3 or more siblings\/spouse had very less chances of survival.\n4.Anybody having 1 sibling\/spouse had good chances of survival >50%.\n5.Almost all passengers having 3 or more siblings belonged to class 3, while those with 1 siblings were equally distributed in all 3 classes.","df2ef69c":"Confusion Matrix\n","ea6fdb8c":"Inference:\n1.Many passengers who did not have parents or children belonged to class 1.\n2.Passenger with 1-3 parents\/children had a good chance for survival 50-60%.\n3.Passengers with 4-5 children have a poor survival rate.\n4.Children had a good chance for survival with parents on board.","ad653df2":"Family is a good parameter for survival. As the family members increases (>4) survival rate decreases. Alone people have less survival chances than family people. for eg In a grouping charting if a single person is saved in a family, then the probability of survival goes up for family.","00ce607f":"Logistic Regression:","3173884e":"Left diagonal matrix are correct prediction while right diagonal are wrong predictions.\nDecision Tree predicts best for dead predictions.\nK nearest predicts best for survivals.\nK nearest classification has the best predcition overall. ","edf9fc0d":"I did basic EDA of all the features available in the dataset so as to analyze how the features are related with survival rate. Further after EDA some features are removed while some features are also added to the dataset.\nFinally I have done prediction using some machine learning algorithms like Knearest, Decision tree, Random Forest and Logistic Regression.\n","76465f22":"Inference:\n1.From the above figs we note Children and women from class 1 were given the maximum priority for survival followed by thye same from class 2 and then 3.\n2.Men from class 3 were given least priority for survival.\n","34bbb07f":"Now we can clean\/remove unwanted data\nName-We have the initals of the name so we can eliminate name feature.\nAge-As it a continuous feature and we have already split it into Age_band we can eliminate age feature.\nTicket-It consist of random strings.\nFare-It is also a continuous feature and is already split into Fare_cat.\nCabin-It has 90% null values.\nFare range-It is converted into single values Fare_cat.\nPassengerId-It has nothing to do with survival rate.\n","d80bed1e":"Inference from Age Sex and Pclass with Survival:\n1.From class 1 more passengers between 10-50 years of age survived, from class 2 passengers between 20-40 years of age survived more and in class 3 the survival rate was more for age 10-35years.\n2.More priority was given to young passengers. Very few passenger of age 0 to 15 did not survive.\n3.Considering females the survival rate was more for age 10-50.\n4.Many males in the age group 18-45 were unfortunate.\n5.Overall Survival rate for children is good.","9e4b2e85":"Inference Summary:\n\nSex: Females have a greater chances of survival than men.\nPclass: Class 1 passengers have more probability of survival than 2 followed by 3. So the costlier the price more is the chance for survival.\nAge: Children of age group 0-15 have higher chances for survival. Many passengers between 15-35 were unfortunate.\nEmbarked: The passengers who embarked from Cherbourg had a good chance for survival than Southampton and Queensland.\nParch and SibSp: Passengers having 1-3 parents\/children had good chances for survival than others and passengers with 1 or 2 siblings also had more than 50% chances for survival.\n","69ad9b09":"Parent Child Relation:","d8a59e00":"Age Relation for Survival :","137bbe38":"Inference:\n1.Survival rate doenst depend much on fare.\n2.The costliest fare passenger survived.","865ed521":"Passenger Class relation with survival:","fa6aaf49":"Inference:\n1.Survival rate is very much high for class 1 female passenger that embarked from Cherbourg. Only 1 female from this category didnt survive the disaster.\n2.The survival rate for males is also good (>60%) for Cherbourg port.\n3.There were very few people who embarked from Queensland. Nobody survived from class 1 and class 2 men whereas no female died from class 1 and class 2 who embarked from Queensland.\n4.The class 3 passenger of both ports Queensland and Southampton did not have a good survival rate.\n5.Females from class 1 and 2 of Southampton had a good survival rate whereas men did not.\n6.Port Cherbourg has the highest survival chances.\n\n    ","252362d6":"Inference from Gender:\n1.Of the total passengers on the ship 65% were male passengers.\n2.We see that priority to survive is given to females as compared to males. Out of the total females present 75% survived, whereas only about 20% males survived out of total 577 males.","fcdd9b7c":"Pclass and Sex Relation","d0fccaeb":"GENDER : How Gender is related with the survival rate."}}