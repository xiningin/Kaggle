{"cell_type":{"706b1c26":"code","e5267b6a":"code","f3eb339d":"code","c0bfc490":"code","33446d3f":"code","b080422d":"code","aca0c036":"code","d4bab868":"code","9e986570":"code","28b4473b":"code","13883b7c":"code","b5d0bfe1":"code","21fa8f08":"code","3839335b":"code","b5f72557":"code","b7eb545e":"code","82b97d05":"code","906b81a1":"code","ea73bf18":"code","d201b7e1":"code","88c6b2a6":"code","945713c3":"code","7d42cd98":"code","547e9fdb":"code","93226717":"code","a551dcd2":"code","180087d7":"code","27a5f038":"code","f662e999":"code","cb790db9":"code","9ccb203d":"code","f492d84a":"code","eecc32e0":"code","c1db85f9":"code","0ca58609":"code","b45ea267":"code","7f39fa7d":"code","5a4eb024":"code","4ddec84b":"code","ca7cf820":"code","b066d886":"code","87ffe8e2":"code","c899ff86":"code","86d2581f":"code","44c06015":"code","1e581203":"code","ea6e8709":"code","b02643d2":"code","6775b560":"code","0f5cc3d5":"code","be910457":"code","511e55be":"code","8358147b":"code","eb09ef44":"code","75f0d849":"markdown","02052d8b":"markdown","50ab4190":"markdown","5dc2957d":"markdown"},"source":{"706b1c26":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e5267b6a":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport math \n%matplotlib inline\ntitanic_data=pd.read_csv('..\/input\/titanic\/train.csv')\ntest_data=pd.read_csv('..\/input\/titanic\/test.csv')\nimport warnings\nwarnings.filterwarnings('ignore')\nimport sklearn as sklearn","f3eb339d":"titanic_data.head(10)\n","c0bfc490":"test_data.head(10)","33446d3f":"print(\"# of passengers in original data:\" + str(len(titanic_data.index)))","b080422d":"print(\"# of passengers in original data:\" + str(len(test_data.index)))\n\n","aca0c036":"sns.countplot(x=\"Survived\",data=titanic_data)","d4bab868":"sns.countplot(x='Survived',hue='Sex',data=titanic_data)","9e986570":"sns.countplot(x='Survived',hue='Pclass',data=titanic_data)","28b4473b":"titanic_data[\"Age\"].plot.hist()","13883b7c":"titanic_data[\"Fare\"].plot.hist()","b5d0bfe1":"titanic_data[\"Fare\"].plot.hist(figsize=(10,5))\nimport warnings\nwarnings.filterwarnings('ignore')","21fa8f08":"titanic_data.info()","3839335b":"test_data.info()","b5f72557":"sns.countplot(x=\"SibSp\",data=titanic_data)","b7eb545e":"titanic_data.isnull()\n","82b97d05":"test_data.isnull()","906b81a1":"titanic_data.isnull().sum()","ea73bf18":"test_data.isnull().sum()","d201b7e1":"titanic_data.isnull().sum()","88c6b2a6":"sns.heatmap(titanic_data.isnull(),yticklabels=False)","945713c3":"sns.heatmap(titanic_data.isnull(),yticklabels=False,cmap='viridis')","7d42cd98":"sns.boxplot(x=\"Pclass\",y=\"Age\",data=titanic_data)","547e9fdb":"titanic_data.head(5)\n","93226717":"titanic_data = titanic_data.drop([ 'Name', 'Ticket', 'Cabin'], axis=1)\n","a551dcd2":"test_data = test_data.drop(['Name', 'Ticket', 'Cabin'], axis=1)","180087d7":"titanic_data.head()","27a5f038":"test_data.head()","f662e999":"test_data.isnull().sum()","cb790db9":"titanic_data['Embarked'] = titanic_data['Embarked'].fillna(titanic_data['Embarked'].mode())\ntest_data['Embarked'] = test_data['Embarked'].fillna(test_data['Embarked'].mode())","9ccb203d":"data = [titanic_data, test_data]\nfor dataset in data:\n    mean = dataset['Age'].mean()\n    std = dataset['Age'].std()\n    is_null = dataset['Age'].isnull().sum()\n    age_slice = dataset['Age'].copy()\n    rand_age = np.random.randint(mean-std, mean+std, size=is_null)\n    age_slice[np.isnan(age_slice)] = rand_age\n    dataset['Age'] = age_slice\n    dataset['Age'] = titanic_data['Age'].astype(int)","f492d84a":"features = [ 'PassengerId','Sex', 'SibSp', 'Parch', 'Pclass', 'Age']\ny = titanic_data['Survived']\nX = pd.get_dummies(titanic_data[features])\ntest_data = pd.get_dummies(test_data[features])","eecc32e0":"from sklearn.model_selection import train_test_split","c1db85f9":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=1)","0ca58609":"from sklearn.linear_model import LogisticRegression","b45ea267":"# logmodel=LogisticRegression()\nlogmodel = LogisticRegression(solver='liblinear')\n","7f39fa7d":"logmodel.fit(X_train,y_train)","5a4eb024":"predictions=logmodel.predict(X_test)","4ddec84b":"predictions=logmodel.predict(X_test)","ca7cf820":"predictions1=logmodel.predict(test_data)","b066d886":"from sklearn.metrics import classification_report","87ffe8e2":"classification_report(y_test,predictions)","c899ff86":"from sklearn.metrics import confusion_matrix","86d2581f":"confusion_matrix(y_test,predictions)","44c06015":"from sklearn.metrics import accuracy_score","1e581203":"accuracy_score(y_test,predictions)","ea6e8709":"test_data.info()","b02643d2":"predictions1","6775b560":"test_data.head()","0f5cc3d5":"submission = pd.DataFrame({'PassengerId':test_data['PassengerId'],'Survived':predictions1})\n\n#Visualize the first 5 rows\nsubmission.head()","be910457":"submission.head()","511e55be":"submission['Survived'] = predictions1","8358147b":"#Create a  DataFrame with the passengers ids and our prediction regarding whether they survived or not\nsubmission = pd.DataFrame({'PassengerId':test_data['PassengerId'],'Survived':predictions1})\n\n#Visualize the first 5 rows\nsubmission.head()","eb09ef44":"#Convert DataFrame to a csv file that can be uploaded\n#This is saved in the same directory as your notebook\nfilename = 'Titanic Predictions 1.csv'\n\nsubmission.to_csv(filename,index=False)\n\nprint('Saved file: ' + filename)","75f0d849":" ## **Analysing Data**","02052d8b":" ## **Collecting data**","50ab4190":"## Train Data","5dc2957d":"## Data Wrangling"}}