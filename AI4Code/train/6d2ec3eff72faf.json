{"cell_type":{"feb20da6":"code","85cb4c92":"code","242757b9":"code","81afdea2":"code","d849fd9f":"code","413d6154":"code","18e6ce3f":"code","48a11b8d":"code","87180f59":"code","d737057d":"code","104750ac":"code","af94b0f1":"code","1cfd7666":"code","e390da38":"code","512fbd2e":"code","e8a59441":"code","df44b6fe":"code","fe458e3b":"code","281d368d":"code","16e497de":"markdown"},"source":{"feb20da6":"import numpy as np\nimport PIL\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input\nimport math,random\nfrom sklearn.neighbors import NearestNeighbors\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg","85cb4c92":"IMG_SIZE = 224\nBATCH = 64\nroot_dir ='..\/input\/image-cataloguer'","242757b9":"model = ResNet50(weights='imagenet',include_top=False,input_shape=(IMG_SIZE,IMG_SIZE,3),pooling='max')","81afdea2":"model","d849fd9f":"img_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\ndatagen = img_gen.flow_from_directory(root_dir,\n                                        target_size=(IMG_SIZE, IMG_SIZE),\n                                        batch_size=BATCH,\n                                        class_mode=None,\n                                        shuffle=False)\n\nnum_images = len(datagen.filenames)\nnum_epochs = int(math.ceil(num_images \/ BATCH))\n\nfeature_list = model.predict(datagen, num_epochs, verbose=1)\nprint(feature_list)","413d6154":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(feature_list)\nstan_feature_list=scaler.transform(feature_list)","18e6ce3f":"stan_feature_list","48a11b8d":"print(feature_list.shape)","87180f59":"from sklearn.decomposition import PCA\n# Make an instance of the Model\npca = PCA(.95)\npca.fit(stan_feature_list)\nnew_feature_list=pca.transform(stan_feature_list)\nprint(new_feature_list.shape)","d737057d":"print(\"Total images   = \", len(datagen.classes))\nprint(\"Shape of feature_list = \", new_feature_list.shape)","104750ac":"# making a list of all the filenames\nfilenames = [root_dir+'\/'+s for s in datagen.filenames]","af94b0f1":"def extract_features(PATH):\n    img = image.load_img(PATH,target_size=(IMG_SIZE,IMG_SIZE)) #image loaded as 2 dimensional array\n    img_array=image.img_to_array(img) # 3 dimension numpy array\n    expanded_img_array = np.expand_dims(img_array,axis=0) # 4 dimensional numpy array\n    \n    # the pretrained model was trained on a different dataset from the one we use (caltech256)\n    # we use the preprocess_input to make our input image compatible with the model being imported\n    # https:\/\/github.com\/tensorflow\/tensorflow\/blob\/23c218785eac5bfe737eec4f8081fd0ef8e0684d\/tensorflow\/python\/keras\/_impl\/keras\/applications\/imagenet_utils.py#L40\n    # as above, preprocess input uses the caffe method\n    # take the rgb image\n    #  -> convert to bgr\n    #  -> zero center our custom image (normalizing) with respect to the imagenet dataset (no scaling)\n    preprocessed_img = preprocess_input(expanded_img_array)\n    extracted_features=model.predict(preprocessed_img,batch_size=1)\n    #scaler = StandardScaler()\n    #scaler.fit(extracted_features)\n    extracted_features=scaler.transform(extracted_features)\n    \n    #pca = PCA(.95)\n    #pca.fit(stan_feature_list)\n    new_feature_list_n=pca.transform(extracted_features)\n    \n    \n    return new_feature_list_n\n    ","1cfd7666":"#neighbors = NearestNeighbors(n_neighbors=12,\n                             #algorithm='ball_tree')\n#neighbors.fit(new_feature_list)","e390da38":"from sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=10, random_state=0).fit(new_feature_list)\ncluster_labels=kmeans.labels_\nprint(cluster_labels.shape)\nprint(np.unique(cluster_labels))","512fbd2e":"def get_random_image_from_dataset(show_img = False):\n    random_idx_value = random.randint(0,len(filenames)-1)\n    random_img_path = filenames[random_idx_value]\n    #image_features=extract_features(random_img_path)\n    if show_img:\n        plt.imshow(plt.imread(random_img_path))\n    return random_img_path","e8a59441":"def similar_images(indices):\n    plt.figure(figsize=(30,20))\n    plotnumber = 1\n    for index in indices:\n        if plotnumber<=len(indices) :\n            ax = plt.subplot(4,6,plotnumber)\n            print(filenames[index])\n            plt.imshow(mpimg.imread(filenames[index])) \n            plt.xlabel(filenames[index] + 'Similar Image'+str(index)+'\\n')\n            print(\" Cosine Similarity value\")\n            similarity_value(img_features,index)\n            plotnumber+=1\n    plt.tight_layout()","df44b6fe":"from scipy import spatial\ndef similarity_value(img_features,index):\n    \n        similar_img_path = filenames[index]\n        similar_img_features=extract_features(similar_img_path)\n        similarity = 1 - spatial.distance.cosine(img_features,similar_img_features)\n        rounded_similarity = int((similarity * 10000)) \/ 10000.0\n        print(similarity,rounded_similarity) ","fe458e3b":"def reverse_image_search():\n    img_path = get_random_image_from_dataset()\n    global img_features\n    img_features = extract_features(img_path)#features of the random input image \n    #img_features=get_random_image_from_dataset()\n    print(img_features.shape)\n    label= kmeans.predict(img_features)\n    indices = np.where(cluster_labels==label)[0]\n    indices.tolist()\n    # indices of images with similar features\n    \n        \n    print(indices.shape)\n    print(indices[0])\n    plt.imshow(mpimg.imread(img_path))\n    plt.xlabel(img_path)\n    plt.show()\n    similar_images(indices[0])","281d368d":"reverse_image_search()","16e497de":"## Using ResNet for image extraction"}}