{"cell_type":{"4f8b3b05":"code","68aa0a95":"code","349d479a":"code","d88ad204":"code","b725857e":"code","14e973a5":"code","53c9d156":"code","874549a0":"code","6fb08faa":"code","cad7cae2":"code","e9a3c18b":"code","352fadc6":"code","ed983225":"code","baa70e18":"code","8e4f48f0":"code","8c31513f":"code","add689c4":"code","6077af30":"code","b9661a16":"code","ee188139":"code","f4a7bcfb":"markdown","3b73996a":"markdown","1a6b2f4b":"markdown","72287e0a":"markdown"},"source":{"4f8b3b05":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tensorflow as tf\nfrom sklearn.metrics import confusion_matrix\nfrom keras.preprocessing import image\nfrom keras import models\nfrom keras import layers\nfrom keras import optimizers\nfrom keras import applications\nfrom keras.optimizers import Adam\nfrom keras.models import Sequential, Model \nfrom keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D,Conv2D,MaxPooling2D,BatchNormalization\nfrom keras import backend as k \nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n\nimport keras\nfrom keras.optimizers import SGD\nfrom sklearn.model_selection import train_test_split\n\n#print(os.listdir(\"..\/input\/all\/All\"))\n\n# Any results you write to the current directory are saved as output.","68aa0a95":"df=pd.read_csv('..\/input\/all\/All\/GTruth.csv')\ndf.head()","349d479a":"#Number of classes\ndf['Ground_Truth'].value_counts()","d88ad204":"kv_dict= dict(zip(df['Id'].values,df['Ground_Truth'].values))\nkv_dict","b725857e":"#Reading Image data and converting it into pixels and separating class labels\nData=[]\nLabel=[]\ndirectory='..\/input\/all\/All'\n\nfor filename in os.listdir(directory) :\n    if filename.endswith(\".jpeg\") or filename.endswith(\".jpg\"):\n        \n        Label.append(kv_dict.get(int(filename.split('.')[0])))\n        filename=os.path.join(directory, filename)\n        im=image.load_img(filename,target_size=(224, 224))\n        im=np.reshape(im,(224,224,3))\n        im=im.astype('float32') \/ 255\n        Data.append(im)\n    else:\n        continue    ","14e973a5":"#Train Test Split\nX_train, X_1, y_train, y_1 = train_test_split(np.array(Data), np.array(Label), test_size=0.2, random_state=42,stratify=Label)\n\n#Train Test Split\nX_cv, X_test, y_cv, y_test = train_test_split(X_1, y_1, test_size=0.2, random_state=42,stratify=y_1)","53c9d156":"X_train.shape","874549a0":"X_cv.shape","6fb08faa":"X_test.shape","cad7cae2":"img_width=224\nimg_height=224","e9a3c18b":"from keras import backend as K\n\nif K.image_data_format() == 'channels_first':\n    input_shape = (3, img_width, img_height)\n    X_train=X_train.reshape(X_train.shape[0],3,img_width,img_height)\n    X_cv=X_cv.reshape(X_cv.shape[0],3,img_width,img_height)\n    X_test=X_test.reshape(X_test.shape[0],3,img_width,img_height)\n    \nelse:\n    input_shape = (img_width, img_height, 3)\n    X_train=X_train.reshape(X_train.shape[0],img_width,img_height,3)\n    X_cv=X_cv.reshape(X_cv.shape[0],img_width,img_height,3)\n    X_test=X_test.reshape(X_test.shape[0],img_width,img_height,3)\n    ","352fadc6":"del Data","ed983225":"#Function to Plott train and Test loss\n\ndef plt_dynamic(x,vy,ty,ax,colors=['b']):\n  ax.plot(x,vy,'b',label='Validation Loss')\n  ax.plot(x,ty,'r',label='Train Loss')\n  plt.legend()\n  plt.grid()\n  fig.canvas.draw()","baa70e18":"#Variables defined\nepoch=10\nbatch=32\nnum_classes=1","8e4f48f0":"#Model Defining\nmodel=Sequential()\n\nmodel.add(Conv2D(32,kernel_size=(3,3),\n                activation='relu',\n                input_shape=input_shape,\n                kernel_initializer='he_normal'))  \nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Conv2D(64,kernel_size=(3,3),\n                activation='relu',\n                kernel_initializer='he_normal'))\nmodel.add(MaxPooling2D(pool_size=(3,3)))\nmodel.add(Conv2D(64,kernel_size=(3,3),\n                activation='relu',\n                kernel_initializer='he_normal'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Flatten())\nmodel.add(Dense(512,activation='relu',kernel_initializer='he_normal'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(256,activation='relu',kernel_initializer='he_normal'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(128,activation='relu',kernel_initializer='he_normal'))\nmodel.add(Dropout(0.3))\nmodel.add(BatchNormalization())\nmodel.add(Dense(64,activation='relu',kernel_initializer='he_normal'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes,activation='sigmoid',kernel_initializer='glorot_normal'))\nmodel.summary()","8c31513f":"#Model Compile\nmodel.compile(loss='binary_crossentropy',optimizer='Adam',metrics=['accuracy'])\n\n# Train\n#training = model.fit_generator(generator.flow(X_train,y_train, batch_size=batch)\n                              #,epochs=epoch\n                               # ,validation_data=[X_cv, y_cv]\n                                #,steps_per_epoch=10,verbose=1)\nhis=model.fit(X_train,y_train,batch_size=batch,epochs=epoch,verbose=1,validation_data=(X_cv,y_cv))\n\n","add689c4":"#Plotting Train and Validation Loss\nfig,ax=plt.subplots(1,1)\nax.set_xlabel('Epochs')\nax.set_ylabel('Binary Cross Entropy')\n\nx=list(range(1,epoch+1))\n\nvy=his.history['val_loss']\nty=his.history['loss']\nplt_dynamic(x,vy,ty,ax)","6077af30":"#Test Accuracy\nscore=model.evaluate(X_test,y_test,verbose=0)\nprint(\"The test accuracy for the model is %f \"%(score[1]*100))","b9661a16":"y_pred=model.predict(X_test).round()","ee188139":"#Plotting Confusion Matrix\nx=confusion_matrix(y_test,y_pred)\nCm_df=pd.DataFrame(x,index=['Pneumonia',' No Pneumonia'],columns=['Pneumonia','No Pneumonia'])\n\nsns.set(font_scale=1.5,color_codes=True,palette='deep')\nsns.heatmap(Cm_df,annot=True,annot_kws={'size':16},fmt='d',cmap='YlGnBu')\nplt.ylabel(\"True Label\")\nplt.xlabel(\"Predicted Label\")\nplt.title('Confusion Matrix')","f4a7bcfb":"<h2> Conclusion-: <\/h2>","3b73996a":"We were able to build a deep learning model that is able to identify the cases of Pneumonia with an accuracy of around 94.89 %.  The accuracy of the model can be increased by fine tunning the layers.","1a6b2f4b":"<h2> Data Source -: https:\/\/www.kaggle.com\/parthachakraborty\/pneumonia-chest-x-ray <\/h2>","72287e0a":"<h1><center>Pneumonia Detection <\/center><\/h1>"}}