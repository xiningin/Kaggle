{"cell_type":{"5c931965":"code","34240fbf":"code","92306115":"code","0197a616":"code","2bffd5a9":"code","866745a7":"code","3f01cb98":"code","ceda1549":"code","706d1fd5":"code","8f7e65da":"code","1f39e4e4":"code","1af418dd":"code","9ca04f4b":"code","a56d5f6c":"code","264ba1ca":"code","56227c6a":"code","66d7ba44":"code","36122617":"markdown","24877ce8":"markdown","57558b87":"markdown","b32fc528":"markdown","5e9a48d2":"markdown","d75eb739":"markdown","497995a7":"markdown"},"source":{"5c931965":"    # This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","34240fbf":"import tensorflow as tf\nfrom tensorflow import keras \nimport numpy as np \nimport pandas as pd\nfrom keras_tuner import RandomSearch\nfrom keras_tuner.engine.hyperparameters import HyperParameter\n","92306115":"fdata=keras.datasets.fashion_mnist\n(train_imgs,train_labels),(test_imgs ,test_labels)=fdata.load_data()\n","0197a616":"train_imgs=train_imgs\/255.0\ntest_imgs=test_imgs\/255.0","2bffd5a9":"train_imgs=train_imgs.reshape(len(train_imgs),28,28,1)\ntest_imgs=test_imgs.reshape(len(test_imgs),28,28,1)","866745a7":"def build_model(hp):\n    model=keras.Sequential([\n        keras.layers.Conv2D(\n            filters=hp.Int('conv_1_filter',min_value=32,max_value=128,step=16),\n            kernel_size=hp.Choice('conv_1_kernel',values=[3,5]),\n            activation='relu',\n            input_shape= (28,28,1)\n        ),\n        keras.layers.Conv2D(\n            filters=hp.Int('conv_2_filter',min_value=32,max_value=64,step=16),\n            kernel_size=hp.Choice('conv_2_kernel',values=[3,5]),\n            activation='relu',\n        ),\n        keras.layers.Flatten(),\n        keras.layers.Dense(\n            units=hp.Int('dense_1_units',min_value=32,max_value=128,step=16),\n            activation='relu'\n        ),\n        keras.layers.Dense(10,activation='softmax')\n    ]) \n    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate',values=[1e-2,1e-3])),\n                    loss='sparse_categorical_crossentropy',\n                    metrics=['accuracy'])\n    return model\n\n","3f01cb98":"T_search = RandomSearch(build_model,objective='val_accuracy',max_trials=5,directory='preview',project_name ='Mnist fashion')","ceda1549":"T_search.search(train_imgs,train_labels,epochs=5,validation_split=0.1)","706d1fd5":"model=T_search.get_best_models(num_models=1)[0]","8f7e65da":"model.summary()","1f39e4e4":"model.fit(train_imgs,train_labels,epochs=10,validation_split=0.1,initial_epoch=5)","1af418dd":"test_loss, test_acc = model.evaluate(test_imgs,  test_labels, verbose=2)\n","9ca04f4b":"import matplotlib.pyplot as plt\nplt.figure()\nplt.imshow(test_imgs[10])\nplt.colorbar()\nplt.grid(False)\nplt.show()\n","a56d5f6c":"class_names = ['T-shirt\/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n","264ba1ca":"probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])","56227c6a":"predictions = probability_model.predict(test_imgs)\n","66d7ba44":"# predictions[0]\nclass_names[np.argmax(predictions[10])]","36122617":"# Train model","24877ce8":"# Normalize data ","57558b87":"# Creating model","b32fc528":"# Importing the necessary libraries\n ","5e9a48d2":"# Make prediction ","d75eb739":"# Evaluate model","497995a7":"# loading dataset"}}