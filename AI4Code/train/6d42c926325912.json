{"cell_type":{"57cf5199":"code","a8443585":"code","3da15358":"code","07e9ea8f":"code","db30cc88":"code","6329d803":"code","622aaf3a":"code","329c7a1c":"code","39983438":"code","f93292e9":"code","758a4dd2":"code","aea992ad":"code","2957d26e":"code","efb5373b":"code","c5db474c":"code","5668f1cf":"code","ee79974f":"code","f787a7e4":"code","02cdeda1":"code","4ddea7cc":"code","19d195a9":"markdown","57d634dd":"markdown","93843611":"markdown","6af95870":"markdown","4e312170":"markdown","cd20df3a":"markdown","b46c51af":"markdown","8f0a676e":"markdown","7a6cd3b3":"markdown","695ef98c":"markdown","f0e99ac6":"markdown","1d21cece":"markdown","f68f5867":"markdown","b3286d8a":"markdown","03d64e12":"markdown","af7ae3fc":"markdown","121fb32c":"markdown","f639e107":"markdown","d02e20e2":"markdown","6a625d1f":"markdown","8aba20d0":"markdown","d933f276":"markdown","8d2083cb":"markdown"},"source":{"57cf5199":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom imblearn import over_sampling, under_sampling\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a8443585":"SAMPLE_SUBMISSION = pd.read_csv('\/kaggle\/input\/gb-classification-choose-tutors\/sample_submission.csv')\nTRAIN = pd.read_csv('\/kaggle\/input\/gb-classification-choose-tutors\/train.csv')\nTEST = pd.read_csv('\/kaggle\/input\/gb-classification-choose-tutors\/test.csv')","3da15358":"TRAIN.shape","07e9ea8f":"TRAIN.info()","db30cc88":"TRAIN.head(10)","6329d803":"TRAIN.describe()","622aaf3a":"TRAIN.isna().sum()","329c7a1c":"sns.countplot(x=\"choose\", data=TRAIN)\nTRAIN['choose'].value_counts()","39983438":"plt.figure(figsize = (20,15))\n\nsns.set(font_scale=1.4)\nsns.heatmap(TRAIN.corr().round(3), annot=True, linewidths=.5, cmap='GnBu')\n\nplt.title('Correlation matrix')\nplt.show()","f93292e9":"TRAIN.hist(bins=30, figsize=(22,17))\nplt.show()","758a4dd2":"def drop_column(column_list, TRAIN, TEST):\n    for col in column_list:\n        TRAIN = TRAIN.drop([col], axis=1)\n        TEST = TEST.drop([col], axis=1)\n\n\ncolumn_list = ['Id', 'history', 'geography', 'english']   \ndrop_column(column_list, TRAIN, TEST)","aea992ad":"TRAIN['index_qualification'] = (TRAIN['years_of_experience'] + 0.01) \/ (TRAIN['age'] + TRAIN['lesson_price'])\nTEST['index_qualification'] = (TEST['years_of_experience'] + 0.01) \/ (TEST['age'] + TEST['lesson_price'])\n\nTRAIN['index_experience'] = (TRAIN['age'] * (TRAIN['years_of_experience'] + 0.01)) \/ (TRAIN['qualification'])\nTEST['index_experience'] = (TEST['age'] * (TEST['years_of_experience'] + 0.01)) \/ (TEST['qualification'])","2957d26e":"TRAIN.shape, TEST.shape","efb5373b":"X = TRAIN.drop('choose', axis=1).values\ny = TRAIN.choose.values\nTEST = TEST.values","c5db474c":"# \u0411\u0430\u043b\u0430\u043d\u0441\u0438\u0440\u043e\u0432\u043a\u0430 \u043a\u043b\u0430\u0441\u0441\u043e\u0432(\u043d\u0443\u0436\u043d\u0430 \u0431\u043e\u043b\u044c\u0448\u0435 \u0434\u043b\u044f \u043c\u043e\u0434\u0435\u043b\u0438 KNN \u0438 \u043b\u043e\u0433\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u043e\u0439 \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438, \u0442\u0430\u043a \u043a\u0430\u043a \u0438\u043d\u0430\u0447\u0435 \u043c\u043e\u0434\u0435\u043b\u044c \u0431\u0443\u0434\u0435\u0442 \u0432\u0438\u0434\u0435\u0442\u044c \u0440\u044f\u0434\u043e\u043c \u0442\u043e\u043b\u044c\u043a\u043e \u0434\u0430\u043d\u043d\u044b\u0435 \u043e\u0434\u043d\u043e\u0433\u043e \u043a\u043b\u0430\u0441\u0441\u0430, \n# \u0447\u0442\u043e \u043d\u0435\u043a\u043e\u0440\u0440\u0435\u043a\u0442\u043d\u043e \u0441\u043a\u0430\u0436\u0435\u0442\u0441\u044f \u043d\u0430 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0438)\n#from imblearn.over_sampling import SMOTE\n#sm = SMOTE(random_state=0, k_neighbors=11)\n#X_train_res, y_train_res = sm.fit_resample(X, y)\n#print(f\"Before OverSampling, counts of label '1': {sum(y == 1)}\")\n#print(f\"Before OverSampling, counts of label '0': {sum(y == 0)} \\n\")\n\n#print(f'After OverSampling, the shape of train_X: {X_train_res.shape}')\n#print(f'After OverSampling, the shape of train_y: {y_train_res.shape} \\n')\n\n#print(f\"After OverSampling, counts of label '1': {sum(y_train_res == 1)}\")\n#print(f\"After OverSampling, counts of label '0': {sum(y_train_res == 0)}\")","5668f1cf":"class KNN_model:\n    # \u0414\u043b\u044f \u0440\u0430\u0431\u043e\u0442\u044b \u043d\u0430 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0438 \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u0434\u043b\u044f \u0440\u0430\u0431\u043e\u0442\u044b\n    def __init__(self, x, y):\n        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n        self.y_pred = None\n\n    # \u0415\u0432\u043a\u043b\u0438\u0434\u043e\u0432\u0430 \u043c\u0435\u0442\u0440\u0438\u043a\u0430 (\u0435\u0432\u043a\u043b\u0438\u0434\u043e\u0432\u043e \u0440\u0430\u0441\u0441\u0442\u043e\u044f\u043d\u0438\u0435) \u2014 \u043c\u0435\u0442\u0440\u0438\u043a\u0430 \u0432 \u0435\u0432\u043a\u043b\u0438\u0434\u043e\u0432\u043e\u043c \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u0435 \u2014 \u0440\u0430\u0441\u0441\u0442\u043e\u044f\u043d\u0438\u0435 \u043c\u0435\u0436\u0434\u0443 \u0434\u0432\u0443\u043c\u044f \u0442\u043e\u0447\u043a\u0430\u043c\u0438 \u0435\u0432\u043a\u043b\u0438\u0434\u043e\u0432\u0430 \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u0430, \n    # \u0432\u044b\u0447\u0438\u0441\u043b\u044f\u0435\u043c\u043e\u0435 \u043f\u043e \u0442\u0435\u043e\u0440\u0435\u043c\u0435 \u041f\u0438\u0444\u0430\u0433\u043e\u0440\u0430. \n    def e_metrics(self, x1, x2):\n        distance = np.sum(np.square(x1 - x2))\n        return np.sqrt(distance)\n\n    # \u041c\u0435\u0442\u0440\u0438\u043a\u0430 accuracy \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0430\u043d\u0438\u0438 \u043a\u043e\u0442\u043e\u0440\u043e\u0439 \u0431\u0443\u0434\u0435\u043c \u0434\u0435\u043b\u0430\u0442\u044c \u0432\u044b\u0432\u043e\u0434 \u043e \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u043c\u043e\u0434\u0435\u043b\u0438\n    def accuracy(self, pred, y):\n        return sum(pred == y) \/ len(y)\n\n    # \u0414\u043b\u044f \u0440\u0430\u0431\u043e\u0442\u044b \u0443\u0436\u0435 \u043f\u043e \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044e \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u0438 \u043a\u043b\u0430\u0441\u0441\u0430\n    @staticmethod\n    def knn(x_train, y_train, x_test, k, weights=None):\n\n        answers = []\n        for x in x_test:\n\n            # \u0440\u0430\u0441\u0447\u0435\u0442 \u0440\u0430\u0441\u0441\u0442\u043e\u044f\u043d\u0438\u0439 \u043e\u0442 \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u0446\u0438\u0440\u0443\u0435\u043c\u043e\u0433\u043e \u043e\u0431\u044a\u0435\u043a\u0442\u0430 \u0434\u043e\n            # \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0435\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438\n            distances = np.sqrt(np.sum(np.square(x - x_train), axis=1))\n\n            # \u0441\u043e\u0437\u0434\u0430\u0435\u043c \u0441\u043b\u043e\u0432\u0430\u0440\u044c \u0441\u043e \u0432\u0441\u0435\u043c\u0438 \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u044b\u043c\u0438 \u043a\u043b\u0430\u0441\u0441\u0430\u043c\u0438\n            classes = {class_item: 0 for class_item in set(y_train)}\n\n            # \u0431\u043e\u043b\u044c\u0448\u0435 \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0446\u0438\u0438\n            test_distances = np.c_[distances, y_train]\n            for d in sorted(test_distances, key=lambda x: x[0])[0:k]:\n                classes[d[1]] += 1\n\n            # \u0417\u0430\u043f\u0438\u0441\u044b\u0432\u0430\u0435\u043c \u0432 \u0441\u043f\u0438\u0441\u043e\u043a \u043e\u0442\u0432\u0435\u0442\u043e\u0432 \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u044c \u0434\u043b\u044f 1 \u043a\u043b\u0430\u0441\u0441\u0430\n            answers.append(classes[1] \/ (classes[1] + classes[0]))\n\n        return answers\n\n    # \u043c\u0435\u0442\u043e\u0434 \u0434\u043b\u044f \u043f\u043e\u0434\u0441\u0447\u0435\u0442\u0430 \u043e\u043f\u0442\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0433\u043e \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430 k-\u0431\u043b\u0438\u0436\u0430\u0439\u0448\u0438\u0445 \u0441\u043e\u0441\u0435\u0434\u0435\u0439 \u0432 \u0446\u0438\u043a\u043b\u0435\n    def count_best(self):\n        k_list = [9]\n\n        k_result = {}\n        y_pred_dic = {}\n\n        for k in k_list:\n            self.y_pred = self.knn_weight(self.x_train, self.y_train, self.x_test, k)\n            y_pred_dic[k] = self.y_pred\n            k_result[k] = self.accuracy(self.y_pred, self.y_test)\n        print(f\"\u041b\u0443\u0447\u0448\u0438\u0439 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u043f\u0440\u0438 k = {sorted(k_result, key=k_result.get)[-1]}: {k_result[sorted(k_result, key=k_result.get)[-1]]}\")\n        print(k_result)\n\n        return y_pred_dic[sorted(k_result, key=k_result.get)[-1]]","ee79974f":"# \u041c\u0435\u0442\u043e\u0434\u043e\u043c \u043f\u0440\u043e\u0431 \u0438 \u043e\u0448\u0438\u0431\u043e\u043a 9 - \u043b\u0443\u0447\u0448\u0435\u0435 \u0447\u0438\u0441\u043b\u043e k\n# model = KNN_model(X_train_res, y_train_res)\n# y_KNN = KNN_model.knn(X_train_res, y_train_res, X_TEST, 9)","f787a7e4":"# \u0420\u0435\u0430\u043b\u0438\u0437\u0443\u0435\u043c \u0433\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u044e \ud835\udc41 \u0431\u0443\u0442\u0441\u0442\u0440\u0430\u043f-\u0432\u044b\u0431\u043e\u0440\u043e\u043a \u0438 \u043f\u043e\u0434\u043c\u043d\u043e\u0436\u0435\u0441\u0442\u0432\u0430 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 \u0434\u043b\u044f \u043d\u0430\u0445\u043e\u0436\u0434\u0435\u043d\u0438\u044f \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u044f \u0432 \u0443\u0437\u043b\u0435.\nnp.random.seed(42)\n\n\ndef get_bootstrap(data, labels, N):\n    n_samples = data.shape[0]  # \u0440\u0430\u0437\u043c\u0435\u0440 \u0441\u043e\u0432\u043f\u0430\u0434\u0430\u0435\u0442 \u0441 \u0438\u0441\u0445\u043e\u0434\u043d\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u043e\u0439\n    bootstrap = []\n\n    for i in range(N):\n        sample_index = np.random.randint(0, n_samples, size=n_samples)\n        b_data = data[sample_index]\n        b_labels = labels[sample_index]\n\n        bootstrap.append((b_data, b_labels))\n\n    return bootstrap\n\n\ndef get_subsample(len_sample):\n    # \u0431\u0443\u0434\u0435\u043c \u0441\u043e\u0445\u0440\u0430\u043d\u044f\u0442\u044c \u043d\u0435 \u0441\u0430\u043c\u0438 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438, \u0430 \u0438\u0445 \u0438\u043d\u0434\u0435\u043a\u0441\u044b\n    sample_indexes = list(range(len_sample))\n\n    len_subsample = int(np.sqrt(len_sample))\n\n    subsample = np.random.choice(sample_indexes, size=len_subsample, replace=False)\n\n    return subsample\n\n\n# \u0420\u0435\u0430\u043b\u0438\u0437\u0443\u0435\u043c \u043a\u043b\u0430\u0441\u0441 \u0443\u0437\u043b\u0430\nclass Node:\n\n    def __init__(self, index, t, true_branch, false_branch):\n        self.index = index  # \u0438\u043d\u0434\u0435\u043a\u0441 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430, \u043f\u043e \u043a\u043e\u0442\u043e\u0440\u043e\u043c\u0443 \u0432\u0435\u0434\u0435\u0442\u0441\u044f \u0441\u0440\u0430\u0432\u043d\u0435\u043d\u0438\u0435 \u0441 \u043f\u043e\u0440\u043e\u0433\u043e\u043c \u0432 \u044d\u0442\u043e\u043c \u0443\u0437\u043b\u0435\n        self.t = t  # \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u043f\u043e\u0440\u043e\u0433\u0430\n        self.true_branch = true_branch  # \u043f\u043e\u0434\u0434\u0435\u0440\u0435\u0432\u043e, \u0443\u0434\u043e\u0432\u043b\u0435\u0442\u0432\u043e\u0440\u044f\u044e\u0449\u0435\u0435 \u0443\u0441\u043b\u043e\u0432\u0438\u044e \u0432 \u0443\u0437\u043b\u0435\n        self.false_branch = false_branch  # \u043f\u043e\u0434\u0434\u0435\u0440\u0435\u0432\u043e, \u043d\u0435 \u0443\u0434\u043e\u0432\u043b\u0435\u0442\u0432\u043e\u0440\u044f\u044e\u0449\u0435\u0435 \u0443\u0441\u043b\u043e\u0432\u0438\u044e \u0432 \u0443\u0437\u043b\u0435\n\n\n# \u0418 \u043a\u043b\u0430\u0441\u0441 \u0442\u0435\u0440\u043c\u0438\u043d\u0430\u043b\u044c\u043d\u043e\u0433\u043e \u0443\u0437\u043b\u0430 (\u043b\u0438\u0441\u0442\u0430)\nclass Leaf:\n\n    def __init__(self, data, labels):\n        self.data = data\n        self.labels = labels\n        self.prediction = self.predict()\n\n    def predict(self):\n        # \u043f\u043e\u0434\u0441\u0447\u0435\u0442 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430 \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u0440\u0430\u0437\u043d\u044b\u0445 \u043a\u043b\u0430\u0441\u0441\u043e\u0432\n        classes = {}  # \u0441\u0444\u043e\u0440\u043c\u0438\u0440\u0443\u0435\u043c \u0441\u043b\u043e\u0432\u0430\u0440\u044c \"\u043a\u043b\u0430\u0441\u0441: \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432\"\n        for label in self.labels:\n            if label not in classes:\n                classes[label] = 0\n            classes[label] += 1\n\n        # \u043d\u0430\u0439\u0434\u0435\u043c \u043a\u043b\u0430\u0441\u0441, \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u043a\u043e\u0442\u043e\u0440\u043e\u0433\u043e \u0431\u0443\u0434\u0435\u0442 \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u044b\u043c \u0432 \u044d\u0442\u043e\u043c \u043b\u0438\u0441\u0442\u0435 \u0438 \u0432\u0435\u0440\u043d\u0435\u043c \u0435\u0433\u043e\n        prediction = max(classes, key=classes.get)\n        return prediction\n\n\n# \u0420\u0430\u0441\u0447\u0435\u0442 \u043a\u0440\u0438\u0442\u0435\u0440\u0438\u044f \u0414\u0436\u0438\u043d\u0438\ndef gini(labels) -> float:\n    #  \u043f\u043e\u0434\u0441\u0447\u0435\u0442 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430 \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u0440\u0430\u0437\u043d\u044b\u0445 \u043a\u043b\u0430\u0441\u0441\u043e\u0432\n    classes = {}\n    for label in labels:\n        if label not in classes:\n            classes[label] = 0\n        classes[label] += 1\n\n    #  \u0440\u0430\u0441\u0447\u0435\u0442 \u043a\u0440\u0438\u0442\u0435\u0440\u0438\u044f\n    impurity = 1\n    for label in classes:\n        p = classes[label] \/ len(labels)\n        impurity -= p ** 2\n\n    return impurity\n\n\n# \u0420\u0430\u0441\u0447\u0435\u0442 \u043f\u0440\u0438\u0440\u043e\u0441\u0442\u0430\ndef gain(left_labels, right_labels, root_gini):\n    # \u0434\u043e\u043b\u044f \u0432\u044b\u0431\u043e\u0440\u043a\u0438, \u0443\u0448\u0435\u0434\u0448\u0430\u044f \u0432 \u043b\u0435\u0432\u043e\u0435 \u043f\u043e\u0434\u0434\u0435\u0440\u0435\u0432\u043e\n    p = float(left_labels.shape[0]) \/ (left_labels.shape[0] + right_labels.shape[0])\n\n    return root_gini - p * gini(left_labels) - (1 - p) * gini(right_labels)\n\n\n# \u0420\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0435 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430 \u0432 \u0443\u0437\u043b\u0435\ndef split(data, labels, column_index, t):\n    left = np.where(data[:, column_index] <= t)\n    right = np.where(data[:, column_index] > t)\n\n    true_data = data[left]\n    false_data = data[right]\n\n    true_labels = labels[left]\n    false_labels = labels[right]\n\n    return true_data, false_data, true_labels, false_labels\n\n\n# \u041d\u0430\u0445\u043e\u0436\u0434\u0435\u043d\u0438\u0435 \u043d\u0430\u0438\u043b\u0443\u0447\u0448\u0435\u0433\u043e \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u044f\ndef find_best_split(data, labels):\n    #  \u043e\u0431\u043e\u0437\u043d\u0430\u0447\u0438\u043c \u043c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u0432 \u0443\u0437\u043b\u0435\n    min_leaf_samples = 5\n\n    root_gini = gini(labels)\n\n    best_gain = 0\n    best_t = None\n    best_index = None\n\n    n_features = data.shape[1]\n\n    feature_subsample_indices = get_subsample(n_features)  # \u0432\u044b\u0431\u0438\u0440\u0430\u0435\u043c \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438\n\n    for index in feature_subsample_indices:\n        # \u0431\u0443\u0434\u0435\u043c \u043f\u0440\u043e\u0432\u0435\u0440\u044f\u0442\u044c \u0442\u043e\u043b\u044c\u043a\u043e \u0443\u043d\u0438\u043a\u0430\u043b\u044c\u043d\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430, \u0438\u0441\u043a\u043b\u044e\u0447\u0430\u044f \u043f\u043e\u0432\u0442\u043e\u0440\u0435\u043d\u0438\u044f\n        t_values = np.unique(data[:, index])\n\n        for t in t_values:\n            true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n            current_gain = gain(true_labels, false_labels, root_gini)\n\n            #  \u0432\u044b\u0431\u0438\u0440\u0430\u0435\u043c \u043f\u043e\u0440\u043e\u0433, \u043d\u0430 \u043a\u043e\u0442\u043e\u0440\u043e\u043c \u043f\u043e\u043b\u0443\u0447\u0430\u0435\u0442\u0441\u044f \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u044b\u0439 \u043f\u0440\u0438\u0440\u043e\u0441\u0442 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430\n            if current_gain > best_gain:\n                best_gain, best_t, best_index = current_gain, t, index\n\n    return best_gain, best_t, best_index\n\n# \u041f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u0435 \u0434\u0435\u0440\u0435\u0432\u0430 \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u0440\u0435\u043a\u0443\u0440\u0441\u0438\u0432\u043d\u043e\u0439 \u0444\u0443\u043d\u043a\u0446\u0438\u0438\ndef build_tree(data, labels):\n\n    gain, t, index = find_best_split(data, labels)\n\n    #  \u0411\u0430\u0437\u043e\u0432\u044b\u0439 \u0441\u043b\u0443\u0447\u0430\u0439 - \u043f\u0440\u0435\u043a\u0440\u0430\u0449\u0430\u0435\u043c \u0440\u0435\u043a\u0443\u0440\u0441\u0438\u044e, \u043a\u043e\u0433\u0434\u0430 \u043d\u0435\u0442 \u043f\u0440\u0438\u0440\u043e\u0441\u0442\u0430 \u0432 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430\n    if gain == 0:\n        return Leaf(data, labels)\n\n    true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n\n    # \u0420\u0435\u043a\u0443\u0440\u0441\u0438\u0432\u043d\u043e \u0441\u0442\u0440\u043e\u0438\u043c \u0434\u0432\u0430 \u043f\u043e\u0434\u0434\u0435\u0440\u0435\u0432\u0430\n    true_branch = build_tree(true_data, true_labels)\n    false_branch = build_tree(false_data, false_labels)\n\n    # \u0412\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u043c \u043a\u043b\u0430\u0441\u0441 \u0443\u0437\u043b\u0430 \u0441\u043e \u0432\u0441\u0435\u043c\u0438 \u043f\u043e\u0434\u0434\u0435\u0440\u0435\u0432\u044c\u044f\u043c\u0438, \u0442\u043e \u0435\u0441\u0442\u044c \u0446\u0435\u043b\u043e\u0433\u043e \u0434\u0435\u0440\u0435\u0432\u0430\n    return Node(index, t, true_branch, false_branch)\n\n# \u0422\u0435\u043f\u0435\u0440\u044c \u0434\u043e\u0431\u0430\u0432\u0438\u043c \u0444\u0443\u043d\u043a\u0446\u0438\u044e \u0444\u043e\u0440\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u043e\u0433\u043e \u043b\u0435\u0441\u0430.\ndef random_forest(data, labels, n_trees):\n    forest = []\n    bootstrap = get_bootstrap(data, labels, n_trees)\n\n    for b_data, b_labels in bootstrap:\n        forest.append(build_tree(b_data, b_labels))\n\n    return forest\n\n# \u0424\u0443\u043d\u043a\u0446\u0438\u044f \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438 \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u043e\u0433\u043e \u043e\u0431\u044a\u0435\u043a\u0442\u0430\ndef classify_object(obj, node):\n\n    #  \u041e\u0441\u0442\u0430\u043d\u0430\u0432\u043b\u0438\u0432\u0430\u0435\u043c \u0440\u0435\u043a\u0443\u0440\u0441\u0438\u044e, \u0435\u0441\u043b\u0438 \u0434\u043e\u0441\u0442\u0438\u0433\u043b\u0438 \u043b\u0438\u0441\u0442\u0430\n    if isinstance(node, Leaf):\n        answer = node.prediction\n        return answer\n\n    if obj[node.index] <= node.t:\n        return classify_object(obj, node.true_branch)\n    else:\n        return classify_object(obj, node.false_branch)\n\n\n# \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0444\u043e\u0440\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u043f\u043e \u0432\u044b\u0431\u043e\u0440\u043a\u0435 \u043d\u0430 \u043e\u0434\u043d\u043e\u043c \u0434\u0435\u0440\u0435\u0432\u0435\ndef predict(data, tree):\n    classes = []\n    for obj in data:\n        prediction = classify_object(obj, tree)\n        classes.append(prediction)\n    return classes\n\n\n# \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435 \u0433\u043e\u043b\u043e\u0441\u043e\u0432\u0430\u043d\u0438\u0435\u043c \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432\ndef tree_vote(forest, data):\n    # \u0434\u043e\u0431\u0430\u0432\u0438\u043c \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u0432\u0441\u0435\u0445 \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432 \u0432 \u0441\u043f\u0438\u0441\u043e\u043a\n    predictions = []\n    for tree in forest:\n        predictions.append(predict(data, tree))\n        \n    # \u0441\u0444\u043e\u0440\u043c\u0438\u0440\u0443\u0435\u043c \u0441\u043f\u0438\u0441\u043e\u043a \u0441 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f\u043c\u0438 \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u043e\u0431\u044a\u0435\u043a\u0442\u0430\n    predictions_per_object = list(zip(*predictions))\n\n    # \u0432\u044b\u0431\u0435\u0440\u0435\u043c \u0432 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u0438\u0442\u043e\u0433\u043e\u0432\u043e\u0433\u043e \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u0438 \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u043e\u0431\u044a\u0435\u043a\u0442\u0430 \u043e\u0442\u043d\u043e\u0448\u0435\u043d\u0438\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430 \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 1 \u043a\u043b\u0430\u0441\u0441\u0430 \u043a\u043e \u0432\u0441\u0435\u043c \u043e\u0431\u044a\u0435\u043a\u0442\u0430\u043c\n    voted_predictions = []\n    for obj in predictions_per_object:\n        # voted_predictions.append(max(set(obj), key=obj.count))\n        unique = dict(zip(list(obj), [list(obj).count(i) for i in list(obj)]))\n        if unique.get(1) is None:\n            unique[1] = 0\n        if unique.get(0) is None:\n            unique[0] = 0\n        voted_predictions.append(unique[1] \/ (unique[1]+unique[0]))\n\n    return voted_predictions\n\n\n# \u0412\u0432\u0435\u0434\u0435\u043c \u0444\u0443\u043d\u043a\u0446\u0438\u044e \u043f\u043e\u0434\u0441\u0447\u0435\u0442\u0430 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438 \u043a\u0430\u043a \u0434\u043e\u043b\u0438 \u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u044b\u0445 \u043e\u0442\u0432\u0435\u0442\u043e\u0432\ndef accuracy_metric(actual, predicted):\n    correct = 0\n    for i in range(len(actual)):\n        if actual[i] == predicted[i]:\n            correct += 1\n    return correct \/ float(len(actual)) * 100.0","02cdeda1":"# \u0427\u0438\u0441\u043b\u043e \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432 \u0432 \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u043e\u043c \u043b\u0435\u0441\u0443 \u0432\u044b\u0432\u0435\u0434\u0435\u043d\u043e \u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u0430\u043b\u044c\u043d\u044b\u043c \u043f\u0443\u0442\u0435\u043c\n# \u041b\u0443\u0447\u0448\u0438\u0435 \u043c\u0435\u0442\u0440\u0438\u043a\u0438:\n# \u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u043e\u0433\u043e \u043b\u0435\u0441\u0430 \u0438\u0437 9 \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432 \u043d\u0430 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0435\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435: 95.057\n# \u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u043e\u0433\u043e \u043b\u0435\u0441\u0430 \u0438\u0437 9 \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432 \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435: 89.567\n\n# \u0423\u0434\u0430\u043b\u0438\u043b\u0438 Id\n# \u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u043e\u0433\u043e \u043b\u0435\u0441\u0430 \u0438\u0437 7 \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432 \u043d\u0430 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0435\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435: 94.471\n# \u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u043e\u0433\u043e \u043b\u0435\u0441\u0430 \u0438\u0437 7 \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432 \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435: 89.067\n\n# \u0412\u0432\u0435\u0434\u0435\u043c \u0444\u0438\u0447\u0443 index_qualification\n# \u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u043e\u0433\u043e \u043b\u0435\u0441\u0430 \u0438\u0437 9 \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432 \u043d\u0430 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0435\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435: 95.286\n# \u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u043e\u0433\u043e \u043b\u0435\u0441\u0430 \u0438\u0437 9 \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432 \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435: 89.300\n\n# \u0414\u043e\u0431\u0430\u0432\u0438\u043b\u0438 \u0444\u0438\u0447\u0443 index_experience\n# \u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u043e\u0433\u043e \u043b\u0435\u0441\u0430 \u0438\u0437 9 \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432 \u043d\u0430 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0435\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435: 97.843\n# \u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u043e\u0433\u043e \u043b\u0435\u0441\u0430 \u0438\u0437 9 \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432 \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435: 88.700\n\nn_trees = 9\n\nmy_forest = random_forest(X, y, n_trees)\n\n# \u041f\u043e\u043b\u0443\u0447\u0438\u043c \u043e\u0442\u0432\u0435\u0442\u044b \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0435\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438\n# train_answers = tree_vote(my_forest, X)\n\n# \u0418 \u043f\u043e\u043b\u0443\u0447\u0438\u043c \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u0438 \u0434\u043b\u044f \u0444\u0438\u043d\u0430\u043b\u044c\u043d\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438\ny_RandomForest = tree_vote(my_forest, TEST)","4ddea7cc":"SAMPLE_SUBMISSION.choose = y_RandomForest\nSAMPLE_SUBMISSION.to_csv('submit.csv', index=False)","19d195a9":"\u0420\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442: KNN \u0434\u0430\u043b\u0430 \u043d\u0430\u043c \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u0438 - knn 0.90246, \u043d\u043e \u044d\u0442\u0430 \u043c\u043e\u0434\u0435\u043b\u044c \u043e\u043a\u0430\u0437\u0430\u043b\u0430\u0441\u044c \u043d\u0435 \u0441\u0430\u043c\u043e\u0439 \u043b\u0443\u0447\u0448\u0435\u0439.","57d634dd":"\n\u0414\u0430\u0442\u0430\u0441\u0435\u0442 \u0441\u043e\u0441\u0442\u043e\u0438\u0442 \u0438\u0437 10000 \u0437\u0430\u043f\u0438\u0441\u0435\u0439 \u0438 13 \u0444\u0438\u0447\u0435\u0439(\u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432), \u0438\u0437 \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u043e\u0434\u043d\u0430 - \u0446\u0435\u043b\u0435\u0432\u0430\u044f \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u0430\u044f\n\n**id** - \u0438\u0434\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440\n\n**age** - \u0432\u043e\u0437\u0440\u0430\u0441\u0442\n\n**years_of_experience** - \u043e\u043f\u044b\u0442\n\n**lesson_price** - \u0441\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c \u0443\u0440\u043e\u043a\u0430\n\n**qualification** - \u043a\u0432\u0430\u043b\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u044f\n\n**physics** - \u0444\u0438\u0437\u0438\u043a\u0430\n\n**chemistry** - \u0445\u0438\u043c\u0438\u044f\n\n**biology** - \u0431\u0438\u043e\u043b\u043e\u0433\u0438\u044f\n\n**english** - \u0430\u043d\u0433\u043b\u0438\u0439\u0441\u043a\u0438\u0439\n\n**geography** - \u0433\u0435\u043e\u0433\u0440\u0430\u0444\u0438\u044f\n\n**history** - \u0438\u0441\u0442\u043e\u0440\u0438\u044f\n\n**mean_exam_points** - \u0441\u0440\u0435\u0434\u043d\u0438\u0439 \u0431\u0430\u043b\u043b \u0437\u0430 \u044d\u043a\u0437\u0430\u043c\u0435\u043d\n\n**choose** - \u0432\u044b\u0431\u043e\u0440 \u0438 \u043d\u0430\u0448\u0430 \u0446\u0435\u043b\u0435\u0432\u0430\u044f \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u0430\u044f (1 - \u043f\u043e\u0434\u043e\u0439\u0434\u0435\u0442\/0 - \u043d\u0435\u0442)\n\n\u041a\u0430\u043a \u043c\u044b \u0432\u0438\u0434\u0438\u043c, \u0443 \u043d\u0430\u0441 \u0435\u0441\u0442\u044c \u043d\u0435\u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435 \u043e \u0440\u0435\u043f\u0435\u0442\u0438\u0442\u043e\u0440\u0435 \u0438 \u0434\u0430\u043d\u043d\u044b\u0435 \u043e \u0435\u0433\u043e \u043d\u0435\u043a\u0438\u0445 \u043f\u043e\u0437\u043d\u0430\u043d\u0438\u044f\u0445 \u0432 \u0440\u0430\u0437\u043d\u044b\u0445 \u043f\u0440\u0435\u0434\u043c\u0435\u0442\u0430\u0445, \u043d\u043e \u043d\u0435 \u0432 \u043c\u0430\u0442\u0435\u043c\u0430\u0442\u0438\u043a\u0435.\n","93843611":"**\u0412\u0430\u0448\u0430 \u0437\u0430\u0434\u0430\u0447\u0430 \u044d\u0442\u043e\u043c \u0441\u043e\u0440\u0435\u0432\u043d\u043e\u0432\u0430\u043d\u0438\u0438** - \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u0442\u044c \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u044c \u0442\u043e\u0433\u043e, \u043f\u043e\u0434\u043e\u0439\u0434\u0435\u0442 \u043b\u0438 \u0440\u0435\u043f\u0435\u0442\u0438\u0442\u043e\u0440 \u0434\u043b\u044f \u043f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0438 \u043a \u044d\u043a\u0437\u0430\u043c\u0435\u043d\u0443 \u043f\u043e \u043c\u0430\u0442\u0435\u043c\u0430\u0442\u0438\u043a\u0435.\n\u0412\u0430\u043c \u0431\u0443\u0434\u0443\u0442 \u0434\u0430\u043d\u044b \u0434\u0432\u0430 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430: train.csv (\u0441\u043e\u0434\u0435\u0440\u0436\u0438\u0442 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u0438 \u0446\u0435\u043b\u0435\u0432\u0443\u044e \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u0443\u044e) \u0438 test.csv (\u0442\u043e\u043b\u044c\u043a\u043e \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438).\nThe evaluation metric is **ROC AUC**","6af95870":"### 3. Random forest\n**Random forest** (\u0441 \u0430\u043d\u0433\u043b.\u2009\u2014\u2009\u00ab\u0441\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0439 \u043b\u0435\u0441\u00bb) \u2014 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c \u043c\u0430\u0448\u0438\u043d\u043d\u043e\u0433\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f, \u043f\u0440\u0435\u0434\u043b\u043e\u0436\u0435\u043d\u043d\u044b\u0439 \u041b\u0435\u043e \u0411\u0440\u0435\u0439\u043c\u0430\u043d\u043e\u043c \u0438 \u0410\u0434\u0435\u043b\u044c \u041a\u0430\u0442\u043b\u0435\u0440 (\u0430\u043d\u0433\u043b.)\u0440\u0443\u0441\u0441\u043a., \u0437\u0430\u043a\u043b\u044e\u0447\u0430\u044e\u0449\u0438\u0439\u0441\u044f \u0432 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0438 \u043a\u043e\u043c\u0438\u0442\u0435\u0442\u0430 (\u0430\u043d\u0441\u0430\u043c\u0431\u043b\u044f) \u0440\u0435\u0448\u0430\u044e\u0449\u0438\u0445 \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432. \u0410\u043b\u0433\u043e\u0440\u0438\u0442\u043c \u0441\u043e\u0447\u0435\u0442\u0430\u0435\u0442 \u0432 \u0441\u0435\u0431\u0435 \u0434\u0432\u0435 \u043e\u0441\u043d\u043e\u0432\u043d\u044b\u0435 \u0438\u0434\u0435\u0438: \u043c\u0435\u0442\u043e\u0434 \u0431\u044d\u0433\u0433\u0438\u043d\u0433\u0430 \u0411\u0440\u0435\u0439\u043c\u0430\u043d\u0430, \u0438 \u043c\u0435\u0442\u043e\u0434 \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0445 \u043f\u043e\u0434\u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432 (\u0430\u043d\u0433\u043b.)\u0440\u0443\u0441\u0441\u043a., \u043f\u0440\u0435\u0434\u043b\u043e\u0436\u0435\u043d\u043d\u044b\u0439 \u0422\u0438\u043d \u041a\u0430\u043c \u0425\u043e (\u0430\u043d\u0433\u043b.)\u0440\u0443\u0441\u0441\u043a.. \u0410\u043b\u0433\u043e\u0440\u0438\u0442\u043c \u043f\u0440\u0438\u043c\u0435\u043d\u044f\u0435\u0442\u0441\u044f \u0434\u043b\u044f \u0437\u0430\u0434\u0430\u0447 \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438, \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438 \u0438 \u043a\u043b\u0430\u0441\u0442\u0435\u0440\u0438\u0437\u0430\u0446\u0438\u0438. \u041e\u0441\u043d\u043e\u0432\u043d\u0430\u044f \u0438\u0434\u0435\u044f \u0437\u0430\u043a\u043b\u044e\u0447\u0430\u0435\u0442\u0441\u044f \u0432 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0438 \u0431\u043e\u043b\u044c\u0448\u043e\u0433\u043e \u0430\u043d\u0441\u0430\u043c\u0431\u043b\u044f \u0440\u0435\u0448\u0430\u044e\u0449\u0438\u0445 \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432, \u043a\u0430\u0436\u0434\u043e\u0435 \u0438\u0437 \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u0441\u0430\u043c\u043e \u043f\u043e \u0441\u0435\u0431\u0435 \u0434\u0430\u0451\u0442 \u043e\u0447\u0435\u043d\u044c \u043d\u0435\u0432\u044b\u0441\u043e\u043a\u043e\u0435 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438, \u043d\u043e \u0437\u0430 \u0441\u0447\u0451\u0442 \u0438\u0445 \u0431\u043e\u043b\u044c\u0448\u043e\u0433\u043e \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u043f\u043e\u043b\u0443\u0447\u0430\u0435\u0442\u0441\u044f \u0445\u043e\u0440\u043e\u0448\u0438\u043c. ","4e312170":"### 2. KNN Classification\n**\u041c\u0435\u0442\u043e\u0434 \u043a-\u0431\u043b\u0438\u0436\u0430\u0439\u0448\u0438\u0445 \u0441\u043e\u0441\u0435\u0434\u0435\u0439** - \u0417\u0434\u0435\u0441\u044c \u043d\u0430\u043c \u043d\u0443\u0436\u043d\u043e \u043f\u043e\u0434\u043e\u0431\u0440\u0430\u0442\u044c \u0447\u0438\u0441\u043b\u043e K-\u0441\u043e\u0441\u0435\u0434\u0435\u0439, \u0431\u043b\u0438\u0437\u043b\u0435\u0436\u0430\u0449\u0438\u0435 \u043a \u043d\u0430\u0448\u0435\u0439 \u0442\u043e\u0447\u043a\u0435\n\n[\u041c\u0435\u0442\u043e\u0434 k-\u0431\u043b\u0438\u0436\u0430\u0439\u0448\u0438\u0445 \u0441\u043e\u0441\u0435\u0434\u0435\u0439](https:\/\/ru.wikipedia.org\/wiki\/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_k-%D0%B1%D0%BB%D0%B8%D0%B6%D0%B0%D0%B9%D1%88%D0%B8%D1%85_%D1%81%D0%BE%D1%81%D0%B5%D0%B4%D0%B5%D0%B9) (\u0430\u043d\u0433\u043b. k-nearest neighbors algorithm, k-NN) \u2014 \u043c\u0435\u0442\u0440\u0438\u0447\u0435\u0441\u043a\u0438\u0439 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c \u0434\u043b\u044f \u0430\u0432\u0442\u043e\u043c\u0430\u0442\u0438\u0447\u0435\u0441\u043a\u043e\u0439 \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438 \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u0438\u043b\u0438 \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438.\n\n\u0412 \u0441\u043b\u0443\u0447\u0430\u0435 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u043c\u0435\u0442\u043e\u0434\u0430 \u0434\u043b\u044f \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438 \u043e\u0431\u044a\u0435\u043a\u0442 \u043f\u0440\u0438\u0441\u0432\u0430\u0438\u0432\u0430\u0435\u0442\u0441\u044f \u0442\u043e\u043c\u0443 \u043a\u043b\u0430\u0441\u0441\u0443, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u044f\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u043d\u0430\u0438\u0431\u043e\u043b\u0435\u0435 \u0440\u0430\u0441\u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0451\u043d\u043d\u044b\u043c \u0441\u0440\u0435\u0434\u0438 k \u0441\u043e\u0441\u0435\u0434\u0435\u0439 \u0434\u0430\u043d\u043d\u043e\u0433\u043e \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u0430, \u043a\u043b\u0430\u0441\u0441\u044b \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u0443\u0436\u0435 \u0438\u0437\u0432\u0435\u0441\u0442\u043d\u044b. \u0412 \u0441\u043b\u0443\u0447\u0430\u0435 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u043c\u0435\u0442\u043e\u0434\u0430 \u0434\u043b\u044f \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438, \u043e\u0431\u044a\u0435\u043a\u0442\u0443 \u043f\u0440\u0438\u0441\u0432\u0430\u0438\u0432\u0430\u0435\u0442\u0441\u044f \u0441\u0440\u0435\u0434\u043d\u0435\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u043f\u043e k  \u0431\u043b\u0438\u0436\u0430\u0439\u0448\u0438\u043c \u043a \u043d\u0435\u043c\u0443 \u043e\u0431\u044a\u0435\u043a\u0442\u0430\u043c, \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u0443\u0436\u0435 \u0438\u0437\u0432\u0435\u0441\u0442\u043d\u044b.\n\n\u0410\u043b\u0433\u043e\u0440\u0438\u0442\u043c \u043c\u043e\u0436\u0435\u0442 \u0431\u044b\u0442\u044c \u043f\u0440\u0438\u043c\u0435\u043d\u0438\u043c \u043a \u0432\u044b\u0431\u043e\u0440\u043a\u0430\u043c \u0441 \u0431\u043e\u043b\u044c\u0448\u0438\u043c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e\u043c \u0430\u0442\u0440\u0438\u0431\u0443\u0442\u043e\u0432 (\u043c\u043d\u043e\u0433\u043e\u043c\u0435\u0440\u043d\u044b\u043c). \u0414\u043b\u044f \u044d\u0442\u043e\u0433\u043e \u043f\u0435\u0440\u0435\u0434 \u043f\u0440\u0438\u043c\u0435\u043d\u0435\u043d\u0438\u0435\u043c \u043d\u0443\u0436\u043d\u043e \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0438\u0442\u044c \u0444\u0443\u043d\u043a\u0446\u0438\u044e \u0440\u0430\u0441\u0441\u0442\u043e\u044f\u043d\u0438\u044f; \u043a\u043b\u0430\u0441\u0441\u0438\u0447\u0435\u0441\u043a\u0438\u0439 \u0432\u0430\u0440\u0438\u0430\u043d\u0442 \u0442\u0430\u043a\u043e\u0439 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u2014 \u0435\u0432\u043a\u043b\u0438\u0434\u043e\u0432\u0430 \u043c\u0435\u0442\u0440\u0438\u043a\u0430. ","cd20df3a":"#### \u0414\u043e\u0431\u0430\u0432\u0438\u043c \u0432\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u044f \u0435\u0432\u043a\u043b\u0438\u0434\u043e\u0432\u043e\u0439 \u043c\u0435\u0442\u0440\u0438\u043a\u0438 \u0438 \u043c\u0435\u0442\u0440\u0438\u043a\u0438 accuracy","b46c51af":"\u0414\u043e\u0431\u0430\u0432\u0438\u043c \u043d\u043e\u0432\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438","8f0a676e":"\u0423\u0434\u0430\u043b\u0438\u043c \u043d\u0435\u0437\u043d\u0430\u0447\u0438\u043c\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438","7a6cd3b3":"\u0412\u0438\u0434\u0438\u043c \u0447\u0442\u043e \u0443 \u043d\u0430\u0441 \u0437\u043d\u0430\u0447\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0439 \u043f\u0435\u0440\u0435\u0432\u0435\u0441 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u0434\u043b\u044f \u0444\u0438\u0447\u0438 choose: 0 - 8891, 1 - 1109","695ef98c":"\u0417\u0430\u043f\u0438\u0441\u044b\u0432\u0430\u0435\u043c \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442","f0e99ac6":"### 1. EDA(Exploratory Data Analaysis)","1d21cece":"\u041f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432 \u043d\u0435\u0442","f68f5867":"#### \u041e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432","b3286d8a":"#### \u041f\u043e\u0441\u0442\u0440\u043e\u0438\u043c \u043c\u0430\u0442\u0440\u0438\u0446\u0443 \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u0439(\u0442\u043e\u043b\u044c\u043a\u043e \u043b\u0438\u043d\u0435\u0439\u043d\u0430\u044f \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u044c)","03d64e12":"1.6 Seaborn countplot \u0434\u0430\u0435\u0442 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044e \u043e \u0434\u0430\u043d\u043d\u044b\u0445 \u0432 \u043a\u0430\u0436\u0434\u043e\u043c \u043a\u043b\u0430\u0441\u0441\u0435, \u0437\u0434\u0435\u0441\u044c \u0440\u0430\u0441\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430\u0448 target","af7ae3fc":"\u041f\u043e\u043a\u0430\u0436\u0435\u043c \u043f\u0435\u0440\u0432\u044b\u0435 10 \u0437\u0430\u043f\u0438\u0441\u0435\u0439 \u0432 \u0442\u0430\u0431\u043b\u0438\u0446\u0435","121fb32c":"#### \u0415\u0441\u043b\u0438 \u0432 \u0434\u0430\u043d\u043d\u044b\u0445 \u0435\u0441\u0442\u044c \u043d\u0435\u0438\u0437\u0432\u0435\u0441\u0442\u043d\u044b\u0435, \u043f\u0440\u043e\u043f\u0443\u0449\u0435\u043d\u043d\u044b\u0435, \u0438\u043b\u0438 \u043d\u0435\u043a\u043e\u0440\u0440\u0435\u043a\u0442\u043d\u043e \u0437\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u043d\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435, \u0442\u043e \u043c\u044b \u044d\u0442\u043e \u0443\u0432\u0438\u0434\u0438\u043c \u0441 .info()","f639e107":"\u0420\u0435\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0430","d02e20e2":"#### \u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043a\u0430\u0436\u0434\u043e\u0439 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439","6a625d1f":"#### \u041e\u0431\u0437\u043e\u0440 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u044b\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432","8aba20d0":"#### \u0417\u0430\u0434\u0430\u0434\u0438\u043c \u043a\u043b\u0430\u0441\u0441 \u043e\u043f\u0438\u0441\u044b\u0432\u0430\u044e\u0449\u0438\u0439 \u043c\u043e\u0434\u0435\u043b\u044c KNN \u0441 \u0443\u0447\u0435\u0442\u043e\u043c \u0432\u0435\u0441\u043e\u0432 \u0440\u0430\u0441\u0441\u0442\u043e\u044f\u043d\u0438\u0439","d933f276":"\u0421\u0447\u0438\u0442\u044b\u0432\u0430\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435","8d2083cb":"\u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043d\u0430\u0431\u043b\u044e\u0434\u0435\u043d\u0438\u0439 \u0438 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0444\u0438\u0447\u0435\u0439"}}