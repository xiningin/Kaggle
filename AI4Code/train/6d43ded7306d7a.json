{"cell_type":{"3b1ed5db":"code","14e396c6":"code","c5cdbdbe":"code","26320626":"code","1db95dca":"code","3d7d998a":"code","3c2d9864":"code","293548ef":"code","924efa04":"code","ad57a251":"code","119b282e":"code","26ded8bd":"code","ccdcf13c":"code","b7ffa047":"code","7a8803ae":"code","1fb3f2c9":"code","092755d6":"code","84a187bc":"code","484a7943":"code","2c22aae3":"code","7fbe7819":"markdown"},"source":{"3b1ed5db":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","14e396c6":"#import library\nfrom tensorflow import keras\nimport tensorflow as tf\nfrom keras.layers import Dense,Dropout,Activation,Add,MaxPooling2D,Conv2D,Flatten,BatchNormalization\nfrom keras.models import Sequential\nfrom keras import layers\nfrom keras.preprocessing.image import ImageDataGenerator\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing import image\nimport numpy as np","c5cdbdbe":"#import train data\n\ntrain_datagen = ImageDataGenerator(rescale=1\/255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   vertical_flip =  True , \n                                   rotation_range=40,\n                                   brightness_range = (0.5, 1.5),\n                                   horizontal_flip = True)\ntrain_data = train_datagen.flow_from_directory('..\/input\/breakhis-400x\/BreaKHis 400X\/train',\n                                                 target_size = (244, 244),\n                                                 class_mode='sparse',\n                                                 shuffle=True,seed=1)\n\n\n#import test data\ntest_datagen = ImageDataGenerator(rescale = 1\/255)\ntest_data = test_datagen.flow_from_directory(\"..\/input\/breakhis-400x\/BreaKHis 400X\/test\",\n                                                           batch_size=32,\n                                                           target_size=(244,244),\n                                                           class_mode='sparse',\n                                                           shuffle=True,seed=1)","26320626":"#print label name\nlabel =  {0:\"benign\",1:\"malignant\"}\nfor i in label.keys() :\n    print(i,label[i])","1db95dca":"#visualize data\nfig, axis = plt.subplots()\naxis.bar(\"test_data\", 572, color='g', label='Test Data')\naxis.bar(\"train_data\",1148 , color='y', label='Train Data')\nlegend = axis.legend()","3d7d998a":"#visualize data\nfig, axis = plt.subplots()\naxis.bar(\"benign\", 547, color='g', label='Benign')\naxis.bar(\"malignet\",1146 , color='y', label='Malignet')\nlegend = axis.legend()","3c2d9864":"#build cnn\nmodel = Sequential([\nConv2D(32,kernel_size= 3,padding='valid',activation='relu',input_shape=(244,244,3)),\nMaxPooling2D(pool_size=(2,2)),\nConv2D(64,kernel_size= 3,padding='valid',activation='relu'),\nMaxPooling2D(pool_size=(2,2)),\nDropout(0.3),\nConv2D(128,kernel_size= 3,padding='valid',activation='relu'),\nMaxPooling2D(pool_size=(2,2)),\nDropout(0.2),\nFlatten(),\nDense(256,activation='relu'),\nDropout(0.15),\nDense(128,activation='relu'),\nDense(2,activation='softmax')])","293548ef":"\n#compile model\nmodel.compile(optimizer=\"adam\", loss=keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])","924efa04":"#early stop  to avoid overfitting\nearly_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5)","ad57a251":"#fit model\nhistory=model.fit(train_data,\n    validation_data = test_data , \n    callbacks=[early_stop],\n    epochs = 30)","119b282e":"#evaluate model\nmodel.evaluate(test_data)","26ded8bd":"#plotting training values\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\naccuracy = history.history['accuracy']\nval_accuracy = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\n\n#accuracy plot\nplt.plot(epochs, accuracy, color='b', label='Training Accuracy')\nplt.plot(epochs, val_accuracy, color='r', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\n\nplt.figure()\n#loss plot\nplt.plot(epochs, loss, color='g', label='Training Loss')\nplt.plot(epochs, val_loss, color='y', label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","ccdcf13c":"#predict model\ny_predict = model.predict(test_data)\ny_predict = np.argmax(y_predict,axis=1)\n\ny_predict","b7ffa047":"#test model 1 \nimg_ = image.load_img(\"..\/input\/breakhis-400x\/BreaKHis 400X\/train\/benign\/SOB_B_A-14-22549AB-400-002.png\", target_size=(244, 244))\nimag = image.img_to_array(img_)\nimag = np.expand_dims(imag, axis=0)\npred = model.predict(imag)\npred = np.argmax(pred,axis=1)\nprint(pred)\nprint(label[pred[0]])\nplt.imshow(img_)","7a8803ae":"#test model 2\nimg_ = image.load_img(\"..\/input\/breakhis-400x\/BreaKHis 400X\/test\/benign\/SOB_B_A-14-22549AB-400-003.png\", target_size=(244, 244))\nimag = image.img_to_array(img_)\nimag = np.expand_dims(imag, axis=0)\npred = model.predict(imag)\npred = np.argmax(pred,axis=1)\nprint(pred)\nprint(label[pred[0]])\nplt.imshow(img_)","1fb3f2c9":"#test model 3\nimg_ = image.load_img(\"..\/input\/breakhis-400x\/BreaKHis 400X\/train\/malignant\/SOB_M_DC-14-10926-400-006.png\", target_size=(244, 244))\nimag = image.img_to_array(img_)\nimag = np.expand_dims(imag, axis=0)\npred = model.predict(imag)\npred = np.argmax(pred,axis=1)\nprint(pred)\nprint(label[pred[0]])\nplt.imshow(img_)","092755d6":"#test model 4\nimg_ = image.load_img(\"..\/input\/breakhis-400x\/BreaKHis 400X\/test\/malignant\/SOB_M_DC-14-11031-400-003.png\", target_size=(244, 244))\nimag = image.img_to_array(img_)\nimag = np.expand_dims(imag, axis=0)\npred = model.predict(imag)\npred = np.argmax(pred,axis=1)\nprint(pred)\nprint(label[pred[0]])\nplt.imshow(img_)","84a187bc":"#test model 5\nimg_ = image.load_img(\"..\/input\/breakhis-400x\/BreaKHis 400X\/train\/malignant\/SOB_M_DC-14-11031-400-007.png\", target_size=(244, 244))\nimag = image.img_to_array(img_)\nimag = np.expand_dims(imag, axis=0)\npred = model.predict(imag)\npred = np.argmax(pred,axis=1)\nprint(pred)\nprint(label[pred[0]])\nplt.imshow(img_)","484a7943":"#test model 6\nimg_ = image.load_img(\"..\/input\/breakhis-400x\/BreaKHis 400X\/train\/benign\/SOB_B_A-14-22549AB-400-022.png\", target_size=(244, 244))\nimag = image.img_to_array(img_)\nimag = np.expand_dims(imag, axis=0)\npred = model.predict(imag)\npred = np.argmax(pred,axis=1)\nprint(pred)\nprint(label[pred[0]])\nplt.imshow(img_)","2c22aae3":"# serialize weights to HDF5\nmodel.save(\"breast_canser.h5\")","7fbe7819":"# Breast canser \n\n![](http:\/\/s.ndtvimg.com\/\/images\/entities\/300\/breast-cancer_636431504441377790_108485.jpg?q=50)\n\n\n\n\n\n\n\n\n\nBreast cancer is a disease in which cells in the breast grow out of control and more people are suffering from Cancer and a survey says one in every 30 women suffer from this disease in their lifetime and so basically this project lays a foundation in making the detection of the cancer automated so that more and more people can get it diagonised early so as get cured.\n\n"}}