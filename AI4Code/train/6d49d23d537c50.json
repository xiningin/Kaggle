{"cell_type":{"d99d9010":"code","17e48fa3":"code","0128586e":"code","e645cdfe":"code","a843bbae":"code","50d01977":"code","7952ebc5":"code","f79a73f3":"code","36b8ca6d":"code","f8e72b69":"code","aeb4f6e5":"code","79166390":"code","53d55587":"markdown","a9060647":"markdown","6c38d341":"markdown","17ce65d6":"markdown","7b5fa234":"markdown","ceccfe0c":"markdown","272cc25a":"markdown"},"source":{"d99d9010":"!pip install tensorflow\n!pip install tensorflow-hub","17e48fa3":"# %tensorflow_version 2.x\n# # !pip install tensorflow==2.1.0rc0\nimport tensorflow as tf\nprint (tf.__version__)\nimport numpy as np","0128586e":"print (\"Following is simple self explatory code of how dot layer works as cosine similiarity between two vectors, if normalize = True set\")\ntf.keras.backend.set_floatx('float64')\nx=np.asarray([-1.,-1.,-1])\nx=np.reshape(x,(1,3))\ny=np.asarray([1.,1.,1.])\ny=np.reshape(y,(1,3))\ntf.keras.layers.Dot(axes=-1,normalize=True)([x,y]).numpy()[0][0]","e645cdfe":"# %tensorflow_version 2.x\n# !pip install tensorflow==2.1.0rc0\nimport tensorflow as tf\nprint (tf.__version__)\ntf.keras.backend.clear_session()\nimport gc\ntry:\n  del model\nexcept:\n  pass\ngc.collect()\nimport tensorflow_hub as hub\nfrom tensorflow import keras\nimport os\nimport logging\ntf.get_logger().setLevel(logging.ERROR)\n\nhuburl = \"https:\/\/tfhub.dev\/google\/universal-sentence-encoder\/4\" #@param [\"https:\/\/tfhub.dev\/google\/universal-sentence-encoder\/4\", \"https:\/\/tfhub.dev\/google\/universal-sentence-encoder-large\/5\"]\nfine_tuned_module_object = hub.load(huburl)\nshared_embedding_layer = hub.KerasLayer(fine_tuned_module_object,trainable=True)\n\nleft_input = keras.Input(shape=(), dtype=tf.string)\nright_input = keras.Input(shape=(), dtype=tf.string)\n\nembedding_left_output= shared_embedding_layer(left_input)\nembedding_right_output= shared_embedding_layer(right_input)\n\ncosine_similiarity=tf.keras.layers.Dot(axes=-1,normalize=True)([embedding_left_output,embedding_right_output])\n\n#We are using acos so that highly similiar sentences can have well \n#seperation. So we are not using:\n#cos_distance=1-cosine_similiarity\n#https:\/\/math.stackexchange.com\/questions\/2874940\/cosine-similarity-vs-angular-distance?newreg=02fd1e16a9164cbba05197b28d353409\nclip_cosine_similarities = tf.clip_by_value(cosine_similiarity, -1.0, 1.0)\nimport math as m\npi = tf.constant(m.pi,dtype= tf.float64)\ncos_distance = 1.0 - (tf.acos(clip_cosine_similarities)\/pi)\n#Acos Range (0 to Pi (3.14)\/pi radians, with 0 as closest 1 as farthest )\n#cos_distance range=1-0=>1 to 1-1=>0, with 1 being nearest and 0 being farthest\n#http:\/\/mathonweb.com\/help_ebook\/html\/functions_2.htm\n\n\n\nmodel = tf.keras.Model([left_input,right_input], cos_distance)\n#Define Optimizer\n\noptim =tf.compat.v1.train.ProximalAdagradOptimizer(learning_rate=0.0001\n                                                   ,l1_regularization_strength=0.0,\n                                                   l2_regularization_strength=0.01\n                                                   )\nmodel.compile(optimizer=optim, loss='mse')\nmodel.summary()\ntf.keras.utils.plot_model(model, to_file='my_model.png')","a843bbae":"#Inputs\nimport numpy as np\ntext_list=[[\"Man is going to Moon\",\"Education is greatest gift to humanity\"],\n           [\"Man achieved great feat in apollo mission\",\"Literacy is important for civilization\"]]\n\n#Model Input Preperation as Numpy array\nleft_inputs=np.asarray(text_list[0])\nright_inputs=np.asarray(text_list[1])\n#1 if we inputs are semantically similiar, 0 if not. \n#Check the distance function defined as 1-arccos(similiarity)\/pi which has range between 1,0 for domain 0 to 1\nsimiliarity=np.asarray([1,1])\n\nleft_inputs=left_inputs.reshape(left_inputs.shape[0],)\nright_inputs=right_inputs.reshape(right_inputs.shape[0],)\n\nleft_inputs.shape,right_inputs.shape,similiarity.shape","50d01977":"def get_similiarity(target_text_embed,text_to_compare_embed):\n    from sklearn.metrics.pairwise import cosine_similarity\n    similiarity=cosine_similarity(target_text_embed,text_to_compare_embed)\n    similiarity=pd.DataFrame(similiarity)\n    return similiarity","7952ebc5":"#Model Fit\nfrom keras.callbacks import Callback\nclass stopAtLossValue(Callback):\n  import numpy as np\n  def on_batch_end(self, batch, logs={}):\n    THR = 0 #Assign THR with the value at which you want to stop training.\n    if np.around(logs.get('loss'),decimals=1) == THR:\n      self.model.stop_training = True\n\nimport numpy as np\n\nmodel.fit([left_inputs,right_inputs],similiarity,epochs=300,callbacks=[stopAtLossValue()])","f79a73f3":"import tensorflow_hub as hub\nimport tensorflow as tf\nprint (text_list)\ntry:\n  text_list=sum(text_list, [])\nexcept:\n  pass\n\nembeddings = fine_tuned_module_object(text_list)\n\n# print (embeddings.numpy())\n\nembed_target=embeddings.numpy()\nimport pandas as pd\ndoc_embed = pd.DataFrame(data=embed_target)\ndoc_embed.index=text_list\n\n\n\nfinetuned_similiarity=get_similiarity(doc_embed,doc_embed)\n# np.fill_diagonal(sim.values, 0)\nfinetuned_similiarity.index=text_list\nfinetuned_similiarity.columns=text_list\nprint (\"With Fine Tune\")\nfinetuned_similiarity","36b8ca6d":"#Without fine tune: Similiarity\n########################################\nimport tensorflow_hub as hub\nimport tensorflow as tf\nun_tuned_module_object = hub.load(huburl)\ntry:\n  text_list=sum(text_list, [])\nexcept:\n  pass\n\nembeddings = un_tuned_module_object(text_list)\n\nembed_target=embeddings.numpy()\nimport pandas as pd\ndoc_embed_global = pd.DataFrame(data=embed_target)\ndoc_embed_global.index=text_list\n########################################\nglobal_similiarity=get_similiarity(doc_embed_global,doc_embed_global)\n# np.fill_diagonal(sim.values, 0)\nglobal_similiarity.index=text_list\nglobal_similiarity.columns=text_list\n\nprint (\"Without Fine Tune\")\nglobal_similiarity","f8e72b69":"print (\"Following code can be used to export and reuse the fine tuned module from local system.\")\nimport os\n#Set export to true to export fine tuned model to module_export_dir_name\nexport=False\nif (export):\n  module_export_dir_name='finetuned_model_export'\n  #Creating module export directory in current directory. You can change wherever you need.\n  os.makedirs(module_export_dir_name,exist_ok=True)\n  export_module_dir = os.path.join(os.getcwd(), module_export_dir_name)\n  tf.saved_model.save(fine_tuned_module_object, export_module_dir)\n  fine_tuned_module_dir=os.path.join(os.getcwd(),module_export_dir_name)\n\n  loaded_module_obj = hub.load(fine_tuned_module_dir)\n  embeddings = loaded_module_obj(text_list)\n\n  embed_target=embeddings.numpy()\n  import pandas as pd\n  doc_embed = pd.DataFrame(data=embed_target)\n  doc_embed.index=text_list\n\n\n  finetuned_similiarity_loaded=get_similiarity(doc_embed,doc_embed)\n  # np.fill_diagonal(sim.values, 0)\n  finetuned_similiarity_loaded.index=text_list\n  finetuned_similiarity_loaded.columns=text_list\n  print (\"With Fine Tune and Exported\")\n  finetuned_similiarity_loaded\nelse:\n  print (\"No Export Selected\")","aeb4f6e5":"import pandas\nimport scipy\nimport math\nimport csv\n\nsts_dataset = tf.keras.utils.get_file(\n    fname=\"Stsbenchmark.tar.gz\",\n    origin=\"http:\/\/ixa2.si.ehu.es\/stswiki\/images\/4\/48\/Stsbenchmark.tar.gz\",\n    extract=True)\nsts_dev = pandas.read_table(\n    os.path.join(os.path.dirname(sts_dataset), \"stsbenchmark\", \"sts-dev.csv\"),\n    error_bad_lines=False,\n    skip_blank_lines=True,\n    usecols=[4, 5, 6],\n    names=[\"sim\", \"sent_1\", \"sent_2\"])\nsts_test = pandas.read_table(\n    os.path.join(\n        os.path.dirname(sts_dataset), \"stsbenchmark\", \"sts-test.csv\"),\n    error_bad_lines=False,\n    quoting=csv.QUOTE_NONE,\n    skip_blank_lines=True,\n    usecols=[4, 5, 6],\n    names=[\"sim\", \"sent_1\", \"sent_2\"])\n# cleanup some NaN values in sts_dev\nsts_dev = sts_dev[[isinstance(s, str) for s in sts_dev['sent_2']]]\nprint (sts_dev.shape,sts_test.shape)\nsts_dev.head(5)","79166390":"sts_data = sts_test #@param [\"sts_dev\", \"sts_test\"] {type:\"raw\"}\n\ndef run_sts_benchmark(batch,module_object):\n  sts_encode1 = tf.nn.l2_normalize(module_object(tf.constant(batch['sent_1'].tolist())), axis=1)\n  sts_encode2 = tf.nn.l2_normalize(module_object(tf.constant(batch['sent_2'].tolist())), axis=1)\n  cosine_similarities = tf.reduce_sum(tf.multiply(sts_encode1, sts_encode2), axis=1)\n  clip_cosine_similarities = tf.clip_by_value(cosine_similarities, -1.0, 1.0)\n  scores = 1.0 - tf.acos(clip_cosine_similarities)\n  \"\"\"Returns the similarity scores\"\"\"\n  return scores\n\ndev_scores = sts_data['sim'].tolist()\nscores = []\n\nmodule_object=un_tuned_module_object\n\nfor batch in np.array_split(sts_data, 10):\n  scores.extend(run_sts_benchmark(batch,module_object))\n\npearson_correlation = scipy.stats.pearsonr(scores, dev_scores)\nprint('Untuned Pearson correlation coefficient = {0}\\np-value = {1}'.format(\n    pearson_correlation[0], pearson_correlation[1]))\n\n\n##With Fune#\nmodule_object=fine_tuned_module_object\nscores = []\nfor batch in np.array_split(sts_data, 10):\n  scores.extend(run_sts_benchmark(batch,module_object))\n\npearson_correlation = scipy.stats.pearsonr(scores, dev_scores)\nprint('Fine Tuned Pearson correlation coefficient = {0}\\np-value = {1}'.format(\n    pearson_correlation[0], pearson_correlation[1]))","53d55587":"### Arc Cosine Distance Target Value Explanation\n\nWe are using Arc Cosine based distance as it is capable of giving distinct scores even for smaller angles compared to plain cosine distance.\n\nAs you you can see range of arccosine is in 0 to Pi for domain of similiarity between 1 to -1, 1 being highly similiar.\n\nHence 1-arccos distance is 1-0->1 to 1-(pi) (which is negative quantity)\n\nTo make it between 0 to 1, we are dividing 1-arccos by pi as given in paper.\n\nIt means the distance is now between 1 to (1-1)=0, with 1 which corresponds to cosine similiarity 1 and 0 correspongs to -1 (highly dissimiliar).\n\nHence now you can define any sentence similiarity in the range of 1 to 0.","a9060647":"### *Following Sections are reused from Google Universal Sentence Embedding Evaluation. Thanks to TF Hub Authors.*","6c38d341":"### Evaluate Sentence Embeddings for Fine Tuned Module\n\nFine tuning must not too much reduce the OOB Module Corelation Score, indicating we have not much compromised  generalization.\n\n","17ce65d6":"<a href=\"https:\/\/colab.research.google.com\/github\/meethariprasad\/research_works\/blob\/master\/Siamese_TF_Cosine_Distance_Fine_Tune.ipynb\" target=\"_parent\"><img src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\" alt=\"Open In Colab\"\/><\/a>","7b5fa234":"### Download data","ceccfe0c":"###### Author: Hari Prasad, 2019.\n\nTransfer Learning has brought new era in NLP. But also brings challenge of fine tuning. \n\nIn this work of 2019 I have proposed the siamese finetuning of famous Universal Sentence Embedding from google for domain specific embedding. Google document on finetuning guide also updated based on recommendation. https:\/\/github.com\/tensorflow\/hub\/issues\/438\n\nThis notebook is my independent work 2019 & there was also papers published around similiar work from Germany 2020 independently.\n\nPlease go through notebook and have fun. Feel free to quote this work.\n\n##### This work is as part of providing simple examples in the world of complicated examples. Have fun!\n###### Licence: Free to Distribute and Modify. You can quote this github reference for sure. :-)","272cc25a":"## Evaluation: STS (Semantic Textual Similarity) Benchmark\n\nThe [**STS Benchmark**](http:\/\/ixa2.si.ehu.es\/stswiki\/index.php\/STSbenchmark) provides an intristic evaluation of the degree to which similarity scores computed using sentence embeddings align with human judgements. The benchmark requires systems to return similarity scores for a diverse selection of sentence pairs. [Pearson correlation](https:\/\/en.wikipedia.org\/wiki\/Pearson_correlation_coefficient) is then used to evaluate the quality of the machine similarity scores against human judgements.\n"}}