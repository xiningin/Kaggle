{"cell_type":{"e3fbc653":"code","c36bc713":"code","047e79db":"code","085b0fb4":"code","378d45fe":"code","5bb43b08":"code","55cc43f6":"code","622b32d1":"code","be1bdca7":"code","94c7597b":"code","1068a50c":"code","c506ed3b":"code","891d77d4":"code","4ecc6359":"code","989ecb09":"code","5b196815":"code","99cf78e2":"code","68fcd788":"code","316c99a1":"code","2bf99d0b":"code","295656fa":"code","8ffba6ac":"code","4bbc75bb":"code","6c6ebeff":"code","a581afe2":"code","d99fbb15":"markdown","90ab9a10":"markdown","116abe08":"markdown","02e98ac7":"markdown","d83da232":"markdown","7a3042b9":"markdown","255d9ed0":"markdown"},"source":{"e3fbc653":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport pandas as pd \nimport pandas_profiling\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nfrom pandas_profiling import ProfileReport\nfrom sklearn.manifold import TSNE\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import Lasso\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import linear_model\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.model_selection import GridSearchCV\nfrom scipy.stats import zscore\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom xgboost import XGBRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lars\nfrom sklearn.linear_model import TheilSenRegressor\nfrom sklearn.linear_model import HuberRegressor\nfrom sklearn.linear_model import PassiveAggressiveRegressor\nfrom sklearn.linear_model import ARDRegression\nfrom sklearn.linear_model import BayesianRidge\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import OrthogonalMatchingPursuit\nfrom sklearn.svm import SVR\nfrom sklearn.svm import NuSVR\nfrom sklearn.svm import LinearSVR\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.isotonic import IsotonicRegression\nfrom sklearn.ensemble import RandomForestRegressor\n\n\n","c36bc713":"missing_values = [\"n\/a\", \"na\", \"--\",\"NaN\"]\ndf=pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv', na_values = missing_values)\ndf1=pd.read_csv('..\/input\/ameseconomic\/data.csv')\ndf=df.merge(df1,left_on='YrSold',right_on='year')","047e79db":"df.isna().sum().sort_values(ascending=False).head(20)","085b0fb4":"df = df.drop(['PoolQC', 'MiscFeature', 'Alley', 'Fence','FireplaceQu'], axis=1)","378d45fe":"noncategorical_mask = (df.dtypes != object)\nnoncategorical_columns = df.columns[noncategorical_mask].tolist()\ndf2=df[noncategorical_columns]\ndf2.isna().sum().sort_values(ascending=False).head(4)","5bb43b08":"a=df2.columns[df2.isnull().any()].tolist() \nfor w in a:\n    df[w]=df[w].interpolate(method=\"linear\")   ","55cc43f6":"b=df.columns[df.isnull().any()].tolist() \nfor w in b:\n    df[w]=df[w].interpolate(method=\"pad\", limit=2)","622b32d1":"z_scores = zscore(df[noncategorical_columns])\nabs_z_scores = np.abs(z_scores)\nfiltered_entries = (abs_z_scores < 3).all(axis=1)\ndf = df[filtered_entries]","be1bdca7":"df = pd.get_dummies( df, drop_first = True )\ncol=df.columns.tolist()","94c7597b":"scaler = StandardScaler()\ndf = scaler.fit_transform(df)","1068a50c":"df=pd.DataFrame(df,columns=col)","c506ed3b":"sel = VarianceThreshold(threshold=0.001)\nsel.fit(df \/ df.mean())\nmask = sel.get_support()\nreduced_df = df.loc[:, mask]\nprint(\"Dimensionality reduced from {} to {}.\".format(df.shape[1], reduced_df.shape[1]))\n","891d77d4":"X1 = reduced_df.drop(['SalePrice'], axis=1)\ny1 = reduced_df['SalePrice']","4ecc6359":"lasso = Lasso(alpha=0.001,normalize=False)\nlasso.fit(X1,y1)\nlasso_coef = lasso.coef_\nlasso_coef\nX=X1.iloc[:,lasso.coef_!=0]","989ecb09":"X = X.drop(['Exterior2nd_Other', 'GarageQual_Fa', 'Exterior1st_ImStucc'],axis=1)\ny=y1","5b196815":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = False)\nX_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, shuffle = True)","99cf78e2":"classifiers = classifiers = [\n    \n   \n   XGBRegressor(),\n   RandomForestRegressor(),\n   DecisionTreeRegressor(),\n   GaussianProcessRegressor(),\n   SVR(),\n   NuSVR(),\n   LinearSVR(),\n   KernelRidge(),\n   LinearRegression(),\n   Ridge(),\n   Lars(),\n   TheilSenRegressor(),\n   PassiveAggressiveRegressor(),\n   ARDRegression(),\n   BayesianRidge(),\n   ElasticNet(),\n   OrthogonalMatchingPursuit(),\n\n  \n   \n   ]\n\nfor item in classifiers:\n    print(item)\n    clf = item\n    clf.fit(X_train,y_train)\n    y_pred=clf.predict(X_test)\n    print(mean_squared_error(y_test, y_pred))","68fcd788":"model=ARDRegression(alpha_1=1e-10,lambda_1=1e-06,alpha_2=0.0001)\nmodel.get_params()","316c99a1":"params_dt = {      \n             'n_iter':(300,400,500)}\ngm_cv = GridSearchCV(model,param_grid=params_dt,cv=5)\ngm_cv.fit(X_train,y_train)\ny_pred = gm_cv.predict(X_test)\nr2 = gm_cv.score(X_test,y_test)\nmse = mean_squared_error(y_test,y_pred)\nprint(\"Tuned model params: {}\".format(gm_cv.best_params_))\nprint(\"Tuned model R squared: {}\".format(r2))\nprint(\"Tuned model MSE: {}\".format(mse))","2bf99d0b":"col1=X.columns.tolist()","295656fa":"test=pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv',na_values = missing_values)\ntest = pd.get_dummies( test, drop_first = True )\ntest=test.merge(df1,left_on='YrSold',right_on='year')\n\n","8ffba6ac":"nan=test.columns[test.isnull().any()].tolist() \nfor w in nan:\n    test[w]=test[w].interpolate(method=\"linear\") ","4bbc75bb":"predicted_prices = gm_cv.predict(test[col1])\nprint(predicted_prices)","6c6ebeff":"submission = pd.DataFrame({'Id': test[col1].Id, 'SalePrice': predicted_prices})\nsubmission.to_csv('submission.csv', index=False)","a581afe2":"submission","d99fbb15":"\u0130mporting data and adding some economical indicators of Ames","90ab9a10":"Dealing with missing values","116abe08":"Feature Extraction","02e98ac7":"Normalizing non categorical columns","d83da232":"Dealing with outliers","7a3042b9":"Splitting data","255d9ed0":"Dropping columns which have low variance"}}