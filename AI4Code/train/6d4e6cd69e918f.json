{"cell_type":{"a6ac434f":"code","58af8206":"code","92ffa443":"code","8c6299f0":"code","f14dcf93":"code","23886698":"code","45f2bccf":"code","e00acfb3":"code","f9dfa086":"code","81fbe5f7":"code","a51f4194":"code","c509ba21":"code","f3f277a3":"code","b12bb971":"code","a26fb980":"code","90df6949":"code","814deae1":"code","f4953394":"code","6ad1a15a":"code","eef95b4a":"code","3fcae53a":"code","8ff893a1":"code","69569a25":"code","daae21de":"code","ad637750":"code","937383af":"code","f2e238d2":"code","14c461e1":"code","ff9171af":"code","5dce1169":"code","f3250a25":"code","d506a67b":"code","907afd6e":"code","57a1618c":"code","783c4b9c":"code","48f3ed12":"code","9c033d19":"code","be19bc74":"code","6781af02":"code","0c1a90bb":"code","3a44f912":"code","5bceb8f9":"code","ff9979dd":"code","23e18698":"code","28b567dc":"code","ce2bb316":"code","1204215c":"markdown","da678505":"markdown","c41577ff":"markdown"},"source":{"a6ac434f":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nplt.style.use('fivethirtyeight')\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","58af8206":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","92ffa443":"train_df = pd.read_csv('\/kaggle\/input\/cabs-surge\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/cabs-surge\/test.csv')","8c6299f0":"print(train_df.shape)\ntrain_df.head()","f14dcf93":"train_df.isnull().sum()","23886698":"print(\"Surge Pricing type: \",train_df['Surge_Pricing_Type'].unique())\nprint(\"Type_of_Cab: \",train_df['Type_of_Cab'].unique())\nprint(\"Confidence_Life_Style_Index: \",train_df['Confidence_Life_Style_Index'].unique())","45f2bccf":"train_df.describe()","e00acfb3":"#FUNCTION FOR PROVIDING FEATURE SUMMARY\ndef feature_summary(df_fa):\n    print('DataFrame shape')\n    print('rows:',df_fa.shape[0])\n    print('cols:',df_fa.shape[1])\n    col_list=['Null','Unique_Count','Data_type','Max\/Min','Mean','Std','Skewness','Sample_values']\n    df=pd.DataFrame(index=df_fa.columns,columns=col_list)\n    df['Null']=list([len(df_fa[col][df_fa[col].isnull()]) for i,col in enumerate(df_fa.columns)])\n    #df['%_Null']=list([len(df_fa[col][df_fa[col].isnull()])\/df_fa.shape[0]*100 for i,col in enumerate(df_fa.columns)])\n    df['Unique_Count']=list([len(df_fa[col].unique()) for i,col in enumerate(df_fa.columns)])\n    df['Data_type']=list([df_fa[col].dtype for i,col in enumerate(df_fa.columns)])\n    for i,col in enumerate(df_fa.columns):\n        if 'float' in str(df_fa[col].dtype) or 'int' in str(df_fa[col].dtype):\n            df.at[col,'Max\/Min']=str(round(df_fa[col].max(),2))+'\/'+str(round(df_fa[col].min(),2))\n            df.at[col,'Mean']=df_fa[col].mean()\n            df.at[col,'Std']=df_fa[col].std()\n            df.at[col,'Skewness']=df_fa[col].skew()\n        df.at[col,'Sample_values']=list(df_fa[col].unique())\n           \n    return(df.fillna('-'))","f9dfa086":"#train=pd.read_csv(path1+'application_train.csv')\nprint('application_train Feature Summary')\nwith pd.option_context('display.max_rows',train_df.shape[1]):\n    train_fs=feature_summary(train_df) ","81fbe5f7":"train_fs","a51f4194":"nominal_var = list(train_fs[train_fs['Data_type'] == 'object'].index)\nprint(\"Total categorical columns are:\",len(nominal_var))\nprint(nominal_var)","c509ba21":"ord_var = list(train_fs[train_fs['Data_type'] == 'int64'].index)\nprint(\"Total ordinal columns are:\",len(ord_var))\nprint(ord_var)","f3f277a3":"cont_var = train_fs[train_fs['Data_type'] == 'float64'].index\nprint(\"Total categorical columns are:\",len(cont_var))\nprint(cont_var)","b12bb971":"f,ax = plt.subplots(1,2,figsize=(18,8))\ntrain_df['Surge_Pricing_Type'].value_counts().plot.pie(autopct='%1.1f%%',ax = ax[0])\ngraph = sns.countplot('Surge_Pricing_Type',data = train_df,ax = ax[1])\ni=1\nfor p in graph.patches:\n    print(p)\n    height = p.get_height()\n    graph.text(p.get_x()+p.get_width()\/2., height + 0.1,train_df['Surge_Pricing_Type'].value_counts()[i],ha=\"center\")\n    i += 1","a26fb980":"target = 'Surge_Pricing_Type'\nnominal_var.remove('Trip_ID')\nord_var.remove('Surge_Pricing_Type')","90df6949":"\nf,ax = plt.subplots(len(nominal_var),2,figsize = (18,18))\n#data[['Sex','Survived']].groupby(['Sex']).mean().plot.bar(ax=ax[0])\nfor i in range(len(nominal_var)):\n    train_df[[nominal_var[i],target]].groupby([nominal_var[i]]).mean().plot.bar(ax = ax[i][0])\n    sns.countplot(nominal_var[i],data = train_df,ax = ax[i][1],hue=target)","814deae1":"f,ax = plt.subplots(len(ord_var),2,figsize = (18,18))\n#data[['Sex','Survived']].groupby(['Sex']).mean().plot.bar(ax=ax[0])\nfor i in range(len(ord_var)):\n    train_df[ord_var[i]].value_counts().plot.bar(ax = ax[i][0])\n    #data['Pclass'].value_counts().plot.bar(color=['#CD7F32','#FFDF00','#D3D3D3'],ax=ax[0])\n    sns.countplot(ord_var[i],data = train_df,ax = ax[i][1],hue=target)","f4953394":"from sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()","6ad1a15a":"train_fs","eef95b4a":"df1=train_df\n\n#df1.mode()","3fcae53a":"def drop_col(data):\n    data = data.drop(['Trip_ID','Var1','Life_Style_Index'],axis = 1)\n    return data","8ff893a1":"def fill_null(data):\n    data['Type_of_Cab'] = data['Type_of_Cab'].fillna('B')\n    data['Customer_Since_Months'] = data['Customer_Since_Months'].fillna('10')\n    data['Confidence_Life_Style_Index'] = data['Confidence_Life_Style_Index'].fillna('B')\n    #print(data)\n    return data","69569a25":"def lable_encod(le,data,nominal_var):\n    for col in nominal_var:\n        data[col]=le.fit_transform(data[col])\n    return data","daae21de":"#find the mode to fill the null values\ndf1 = drop_col(df1)\n#print(df1.mode())\ndf1 = fill_null(df1)\ndf1 = lable_encod(le,df1,nominal_var)","ad637750":"sns.heatmap(df1.corr(),annot = True,cmap='RdYlGn',linewidths=0.2)\nfig=plt.gcf()\nfig.set_size_inches(10,8)\nplt.show()","937383af":"from sklearn.metrics import confusion_matrix \nfrom sklearn.model_selection import train_test_split \nfrom sklearn.svm import SVC \nfrom sklearn.utils import shuffle\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\nfrom sklearn import preprocessing","f2e238d2":"X = df1.drop([target],axis = 1) \ny = df1[target]","14c461e1":"def Scaling(X):\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X)\n    return X_train_scaled ","ff9171af":"X_train_scaled = Scaling(X)","5dce1169":"# dividing X, y into train and test data \nX_train, X_test, y_train, y_test = train_test_split(X_train_scaled, y, random_state = 0,test_size = 0.3)","f3250a25":"X_train.shape","d506a67b":"#SVM\nsvm_model_linear = SVC(kernel = 'linear', C = 1).fit(X_train, y_train) \n","907afd6e":"svm_predictions = svm_model_linear.predict(X_test) \n  \n# model accuracy for X_test   \naccuracy = svm_model_linear.score(X_test, y_test) \n  \n# creating a confusion matrix \ncm = confusion_matrix(y_test, svm_predictions)","57a1618c":"\nprint(accuracy)\nsns.heatmap(cm,annot=True,fmt = '')","783c4b9c":"from sklearn.neighbors import KNeighborsClassifier \nknn = KNeighborsClassifier(n_neighbors = 7).fit(X_train, y_train) \n  \n# accuracy on X_test \naccuracy = knn.score(X_test, y_test) \nprint(accuracy)\n  \n# creating a confusion matrix \nknn_predictions = knn.predict(X_test)  \ncm = confusion_matrix(y_test, knn_predictions)","48f3ed12":"sns.heatmap(cm,annot=True,fmt = '')","9c033d19":"params_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n                     'C': [1, 10, 100, 1000]},\n                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]","be19bc74":"# Performing CV to tune parameters for best SVM fit \nsvm_model = GridSearchCV(SVC(), params_grid, cv=5)\nsvm_model.fit(X_train, y_train)","6781af02":"# View the accuracy score\nprint('Best score for training data:', svm_model.best_score_,\"\\n\") \n\n# View the best parameters for the model found using grid search\nprint('Best C:',svm_model.best_estimator_.C,\"\\n\") \nprint('Best Kernel:',svm_model.best_estimator_.kernel,\"\\n\")\nprint('Best Gamma:',svm_model.best_estimator_.gamma,\"\\n\")\n\nfinal_model = svm_model.best_estimator_\nY_pred = final_model.predict(X_test_scaled)\nY_pred_label = list(encoder.inverse_transform(Y_pred))","0c1a90bb":"print(test_df.shape)\ntest_df.head()","3a44f912":"test_df.isnull().sum()","5bceb8f9":"test_df1 = test_df\n#find the mode to fill the null values\ntest_df1 = drop_col(test_df1)\n#print(df1.mode())\ntest_df1 = fill_null(test_df1)\ntest_df1 = lable_encod(le,test_df1,nominal_var)","ff9979dd":"X_test_scaled = Scaling(test_df1)","23e18698":"sub = pd.DataFrame(test_df[['Trip_ID']])","28b567dc":"#SVM\nsvm_values = svm_model_linear.predict(X_test_scaled)\nsub['Surge_Pricing_Type'] = svm_values\nsub.to_csv('svmlinear.csv',index = False)","ce2bb316":"#KNN\nknn_values = knn.predict(X_test_scaled)\nsub['Surge_Pricing_Type'] = knn_values\nsub.to_csv('knnlinear.csv',index = False)","1204215c":"EDA for Categorical Features:\n    Nominal features","da678505":"# Test Data","c41577ff":"Continous variable:\n    'Trip_Distance', \n    'Customer_Since_Months', (5920)\n    'Life_Style_Index',(20193)\n    'Customer_Rating', \n    'Var1'(71030)\n    \nCategorical Variables:\n    Nominal:\n        'Trip_ID', \n        'Type_of_Cab', (20210)\n        'Confidence_Life_Style_Index',(20193)\n        'Destination_Type', \n        'Gender'\n    Ordinal:\n        'Cancellation_Last_1Month', \n        'Var2', \n        'Var3', \n        'Surge_Pricing_Type'\n        "}}