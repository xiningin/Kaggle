{"cell_type":{"6fea448d":"code","63b9a378":"code","edc890f9":"code","3bc8ac95":"code","15684989":"code","fb304d1e":"code","e44d7677":"code","683f27b5":"code","1e35e0b6":"code","d7c3e5c6":"code","2f83eb35":"code","9df19389":"code","d32a19b2":"code","7ff6abea":"code","43ed6ef6":"code","a89f80c2":"code","2e7e656f":"code","d4ce26d8":"code","c43a2306":"code","46ff8d33":"code","4a8877d2":"code","716adf83":"code","ac2d7fdc":"code","ee3208c4":"code","b1a54713":"code","e93dd83e":"code","86a28c9d":"markdown","94bb62e0":"markdown","9534fe73":"markdown","11468b0c":"markdown","dfb6c75d":"markdown","8413bcd0":"markdown","f4affc57":"markdown","39596af7":"markdown","2b7fb051":"markdown","7f37822b":"markdown","acb378e8":"markdown","80ff3cde":"markdown","b05ed64e":"markdown","80824fa2":"markdown","9dfc496b":"markdown","382ce269":"markdown","50eb4b15":"markdown","2348680f":"markdown","962fb90e":"markdown","158a48d8":"markdown","af88a745":"markdown","41f9df38":"markdown","0039df91":"markdown","a9e1f308":"markdown","d0ec4e69":"markdown"},"source":{"6fea448d":"import pandas as pd\nimport numpy as np\nimport cv2\nimport os\nimport random\nimport pickle\nfrom matplotlib import image as im\nfrom matplotlib import pyplot as plt\nfrom tqdm import tqdm\nfrom PIL import Image\nrandom.seed(123456789)","63b9a378":"from mc_skin_util import MinecraftSkin, Translator # own utility script\n\nclass Stream:\n  def __init__(self, iterable):\n    self.iterable = iterable\n    self.operations = []\n  \n  def filter(self, fn):\n    return self.of(filter(fn, self.iterable))._stamp(self, \"filter \" + fn.__name__)\n\n  def map(self, fn):\n    return self.of(map(fn, self.iterable))._stamp(self, \"map \" + fn.__name__)\n  \n  def map_key(self, fn):\n    '''\n    fn must return tuple length more than 1\n    '''\n    return self.of(self.__map_key(fn, self.collect()))._stamp(self, \"map \" + fn.__name__)\n\n  def reduce(self, fn):\n    iterable = self.iterable\n    result = None\n    try:\n      result = next(iterable)\n      while(True):\n        result = fn(result, next(iterable))\n    except:\n      return result\n    \n  def collect(self):\n    return list(self.iterable)\n  \n  def enumerate(self):\n    return Stream(enumerate(self.iterable))\n  \n  def next(self):\n    return next(self.iterable)\n\n  def _stamp(self, streamobj, name):\n    self.operations = streamobj.operations\n    self.operations += [name]\n    return self\n\n  def __str__(self):\n    return self.__repr__() + \"\\n  -> \" + \"\\n  -> \".join(self.operations)\n  \n  def __repr__(self):\n    return \"[Stream object]\"\n  \n  @staticmethod\n  def of(iterable):\n    return Stream(iter(iterable))\n  \n  @staticmethod\n  def __map_key(fn, arr):\n    ref = dict()\n    for i in arr:\n      k = fn(i)\n      if (k[0] not in ref.keys()):\n        ref[k[0]] = []\n      ref[k[0]] += k[1:]\n\n    for k in ref.keys():\n      yield [k] + ref[k]","edc890f9":"DIR = \"..\/input\/minecraft-skins\/skins\/\"\n\ndef get_max_bound():\n    return len(os.listdir(DIR))\n\ndef get_image(index):\n    try:\n        return im.imread(os.path.join(DIR, os.listdir(DIR)[index]))\n    except Exception as e:\n        return im.imread(os.path.join(DIR, os.listdir(DIR)[index]), 0)\n\ndef get_file(index):\n    return os.listdir(DIR)[index]\n\ndef get_or_none(index):\n    try:\n        img = get_image(index)\n        assert np.equal(img.shape, (64, 64, 4)).all()\n        return img\n    except:\n        return None\n\ndef get_rgb_histogram(img, channel=0, nbins=np.iinfo(np.uint8).max + 1, clip_low = 0):\n    img = img[:, :, channel].flatten()\n    img = img[img >= clip_low]\n    ratio = (np.iinfo(np.uint8).max + 1) \/ nbins\n    bins = [i * ratio for i in range(nbins)] + [np.iinfo(np.uint8).max + 1]\n    return np.histogram(img, bins=bins, density=True)\n\ndef get_hsv_histogram(img_rgb, channel=0, nbins=np.iinfo(np.uint8).max + 1):\n    img_bgr = cv2.cvtColor(img_rgb[:, :, :3], cv2.COLOR_RGB2BGR)\n    img_hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n    return get_rgb_histogram(img_hsv, channel=channel, nbins=nbins, clip_low=0) # alway unclip low\n\ndef get_merged_histogram(img, histogram_fn, **other_params):\n    chnl1 = histogram_fn(img, channel=0,**other_params)\n    chnl2 = histogram_fn(img, channel=1,**other_params)\n    chnl3 = histogram_fn(img, channel=2,**other_params)\n    return np.hstack((chnl1[0], chnl2[0], chnl3[0]))\n\ndef get_minecraft_histogram(img, hist_fn, **kwargs):\n    mc = MinecraftSkin(img)\n    main_features = [i for i in MinecraftSkin(get_image(0)).get_keys() if 'helm' not in i and 'acc' not in i]\n    comps = [mc.get_component(i) for i in main_features]\n    return np.hstack([hist_fn(i, **kwargs) for i in comps])\n\ndef stack_images(iterable, ncols=8):\n    dim = iterable[0].shape\n    blank = np.zeros(dim, dtype=np.uint8)\n    a = Stream.of(iterable).enumerate().map(lambda x: (x[0] % ncols, x[1])).map_key(lambda x: (x[0], x[1])).collect()\n    a = [i[1:] for i in a]\n    height = max([len(i) for i in a])\n    for i, v in enumerate(a):\n        if (len(v) == height): continue\n        a[i].append(blank)\n    return np.hstack([np.vstack(i) for i in a])","3bc8ac95":"rgb_bins = 20 # rgb bins\nhsv_bins = 10 # hsv bins\n\nrgbhist_fn = lambda x: get_merged_histogram(x, get_rgb_histogram, nbins=rgb_bins, )\nhsvhist_fn = lambda x: get_merged_histogram(x, get_rgb_histogram, nbins=hsv_bins)\n\nmhist_fn = lambda x: np.hstack([get_minecraft_histogram(x, rgbhist_fn), get_minecraft_histogram(x, hsvhist_fn)])","15684989":"keep = 0.5\nimgs_hist = Stream.of(range(get_max_bound()))\\\n.filter(lambda x: random.random() < keep)\\\n.map(get_or_none)\\\n.filter(lambda x: x is not None)\\\n.map(mhist_fn)\\\n.filter(lambda x: not np.isnan(np.max(x)))\\\n.collect()","fb304d1e":"from sklearn.cluster import KMeans\nnclusters = 3\nninit = 30\nkmeans = KMeans(n_clusters=nclusters, n_init=ninit, algorithm='elkan', n_jobs=-2).fit(imgs_hist)","e44d7677":"tst_prob = 0.02\nimg_test = Stream.of(range(get_max_bound()))\\\n.filter(lambda x: random.random() < tst_prob)\\\n.map(get_or_none)\\\n.filter(lambda x: x is not None)\\\n.filter(lambda x: x.shape[2] == 4)\\\n.collect()","683f27b5":"predictions = Stream.of(img_test)\\\n.map(lambda x: (x, mhist_fn(x)))\\\n.filter(lambda x: not np.isnan(np.max(x[1])))\\\n.map_key(lambda x: (kmeans.predict([x[1]])[0], x[0]))\\\n.collect()\n\np_sorted = dict(\n  zip(\n    [i[0] for i in predictions],\n    [i[1:] for i in predictions]\n))","1e35e0b6":"for i, group in enumerate(p_sorted.keys()):\n    print(f\"Group {i + 1} - Cluster Name: {group}\")\n    imgs = Stream.of(p_sorted[group]).map(lambda x: MinecraftSkin(x).get_component('head_front')).collect()\n    stacked = stack_images(imgs)\n    ratio = stacked.shape[0] \/ stacked.shape[1]\n    width = 5\n    plt.figure(figsize = (width, width * (ratio)))\n    plt.imshow(stacked)\n    plt.show()","d7c3e5c6":"labels = Stream.of(range(get_max_bound()))\\\n.map   (lambda x: (x, get_or_none(x)))\\\n.filter(lambda x: x[1] is not None)\\\n.map   (lambda x: (x[0], mhist_fn(x[1])))\\\n.filter(lambda x: not np.isnan(np.max(x[1])))\\\n.map   (lambda x: (x[0], kmeans.predict([x[1]])[0]))\\\n.collect()","2f83eb35":"clusters = pd.DataFrame(data=labels, columns=['imagename', 'cluster'])\nclusters.shape","9df19389":"clusters.groupby('cluster').count()","d32a19b2":"pickle.dump([rgb_bins, hsv_bins], open('hist_bin_params.pickle', 'wb'))","7ff6abea":"def get_hist_fn(rgb_bins, hsv_bins):\n    rgbhist_fn = lambda x: get_merged_histogram(x, get_rgb_histogram, nbins=rgb_bins)\n    hsvhist_fn = lambda x: get_merged_histogram(x, get_rgb_histogram, nbins=hsv_bins)\n\n    return lambda x: np.hstack([get_minecraft_histogram(x, rgbhist_fn), get_minecraft_histogram(x, hsvhist_fn)])  ","43ed6ef6":"rbins, hbins = pickle.load(open('hist_bin_params.pickle', 'rb'))\nmhist_fn = get_hist_fn(rbins, hbins)","a89f80c2":"expanded = Stream.of(range(get_max_bound()))\\\n.map   (lambda x: (x, get_or_none(x)))\\\n.filter(lambda x: x[1] is not None)\\\n.map   (lambda x: (x[0], mhist_fn(x[1])))\\\n.filter(lambda x: not np.isnan(np.max(x[1])))\\\n.map(lambda x: np.hstack(x))\\\n.collect()","2e7e656f":"features = ['imgname'] + [f'f{i}' for i, v in enumerate(np.array(expanded).T[:-1])]\nimg_hists = pd.DataFrame(expanded, columns=features)\nimg_hists.imgname = img_hists.imgname.astype(np.int)\nimg_hists = img_hists.set_index('imgname')","d4ce26d8":"from sklearn.neighbors import NearestNeighbors as KNN\n\nnearest_model = KNN(n_jobs=-1)\nnearest_model.fit(img_hists)\nn_samples = img_hists.shape[0]","c43a2306":"def get_nearest_skins(hist, model, n):\n    return model.kneighbors([hist], n)[1][0]\nknn_fn = lambda x: (\n    Stream.of(get_nearest_skins(mhist_fn(x), nearest_model, n_samples))\n    .map(lambda x: img_hists.index[x])\n)","46ff8d33":"def compute_skin(ms):\n    if not isinstance(ms, MinecraftSkin):\n        ms = MinecraftSkin(ms)\n    head = ms.get_component('head_front')\n    body = ms.get_component('body')\n    larm = ms.get_component('arm_left')\n    rarm = ms.get_component('arm_right')\n    lleg = ms.get_component('leg_left')\n    rleg = ms.get_component('leg_right')\n\n    helm = ms.get_component('helm_front')\n    body_acc = ms.get_component('body_acc')\n    larm_acc = ms.get_component('arm_left_acc')\n    rarm_acc = ms.get_component('arm_right_acc')\n    lleg_acc = ms.get_component('leg_left_acc')\n    rleg_acc = ms.get_component('leg_right_acc')\n\n    head = np.array(Image.alpha_composite(Image.fromarray(head), Image.fromarray(helm)))\n    body = np.array(Image.alpha_composite(Image.fromarray(body), Image.fromarray(body_acc)))\n    larm = np.array(Image.alpha_composite(Image.fromarray(larm), Image.fromarray(larm_acc)))\n    rarm = np.array(Image.alpha_composite(Image.fromarray(rarm), Image.fromarray(rarm_acc)))\n    lleg = np.array(Image.alpha_composite(Image.fromarray(lleg), Image.fromarray(lleg_acc)))\n    rleg = np.array(Image.alpha_composite(Image.fromarray(rleg), Image.fromarray(rleg_acc)))\n\n    chunk = 8\n    semi = 4\n\n    spacing = 0\n    margin = 2\n\n    #                       arm              body              arm\n    total_width = margin + semi + spacing + chunk + spacing + semi + margin\n\n    #                        head                 body                  leg\n    total_height = margin + chunk + spacing + 3 * semi + spacing + 3 * semi + margin\n\n    # translators\n    head_trans = Translator(0, 0, int((total_width - head.shape[1]) \/ 2), margin, head.shape[1], head.shape[0])\n    body_trans = Translator(semi, semi, int((total_width - chunk) \/ 2), margin + head.shape[0] + spacing, chunk, 3 * semi)\n    larm_trans = Translator(semi, semi, margin, margin + head.shape[0] + spacing + 1, semi, 3 * semi)\n    rarm_trans = Translator(semi, semi, total_width - margin - semi, margin + head.shape[0] + spacing + 1, semi, 3 * semi)\n    lleg_trans = Translator(semi, semi, int(total_width \/ 2) - semi, total_height - margin - 3 * semi, semi, 3 * semi)\n    rleg_trans = Translator(semi, semi, int(total_width \/ 2), total_height - margin - 3 * semi, semi, 3 * semi)\n\n    canvas = np.zeros((total_height, total_width, 4), dtype=np.uint8)\n\n    canvas = head_trans.translate(head, canvas)\n    canvas = body_trans.translate(body, canvas)\n    canvas = larm_trans.translate(larm, canvas)\n    canvas = rarm_trans.translate(rarm, canvas)\n    canvas = lleg_trans.translate(lleg, canvas)\n    canvas = rleg_trans.translate(rleg, canvas)\n    return canvas","4a8877d2":"test_img = get_image(200)\n\nsuggested = knn_fn(test_img)\n\nstacked = [compute_skin(get_image(suggested.next())) for _ in range(4 * 4)]\nstacked = stack_images(stacked, 8)\n\nplt.imshow(compute_skin(test_img))\nplt.show()\n\nratio = stacked.shape[0] \/ stacked.shape[1]\nplt.figure(figsize=(8, 8 * ratio))\nplt.imshow(stacked, interpolation='none')\nplt.show()","716adf83":"test_img = get_image(800)\n\nsuggested = knn_fn(test_img)\n\nstacked = [compute_skin(get_image(suggested.next())) for _ in range(4 * 4)]\nstacked = stack_images(stacked, 8)\n\nplt.imshow(compute_skin(test_img))\nplt.show()\n\nratio = stacked.shape[0] \/ stacked.shape[1]\nplt.figure(figsize=(10, 10 * ratio))\nplt.imshow(stacked, interpolation='none')\nplt.show()","ac2d7fdc":"def diff(target_img, test_img):\n    diff_1 = compute_skin(target_img).astype(np.int)\n    diff_2 = compute_skin(test_img).astype(np.int)\n    diff = np.abs(diff_1 - diff_2)\n    return diff.sum() \/ (diff.shape[0] * 255 + 1)","ee3208c4":"similar = {}\nthreshold = 0.01\nerrors = []\nhist_df = img_hists\nwith tqdm(total=hist_df.shape[0]) as progress:\n    progress.set_description(\"Processing...\")\n    for i in hist_df.iterrows():\n        progress.update(1)\n        index, value = i\n        if (index in similar.keys()):\n            progress.set_description(f'Image {index} is already similar with image {similar[index]}.')\n            continue\n        target_img = get_image(index)\n        candidates = nearest_model.kneighbors([mhist_fn(target_img)], n_samples)[1][0]\n        s = Stream.of(candidates)\n\n        sims = 0\n        try:\n            while(True):\n                test = hist_df.index[s.next()]\n                if (test == index): continue\n                test_img = get_image(test)\n                if (diff(target_img, test_img) >= threshold):\n                    break\n                similar[test] = index\n                sims += 1\n                progress.set_description(f'Image {index} has {sims} other similar images.')\n        except Exception as e:\n            errors += [index]\n            print(f'Error! At Image {index}', e)","b1a54713":"target = random.choice(list(similar.keys()))\ntest = similar[target]\n\ntarget_img = get_image(target)\ntest_img = get_image(test)\n\nplt.imshow(compute_skin(target_img))\nplt.show()\nplt.imshow(compute_skin(test_img))\nplt.show()\nassert target != test","e93dd83e":"img_hists[img_hists.index.isin(similar.keys())].shape","86a28c9d":"# Utility Scripts\n\nMinecraftSkin + Stream class\n\nI still have yet to figure out why my stream utility script is not appearing in this notebook, so I am going to put it here manually.","94bb62e0":"### Histogram Features","9534fe73":"Here, I save the histogram parameters so that I can reconstruct the histogram function to be used for KNN algorithm input.","11468b0c":"Here, I expand the csv from the index reference to the image array and then to their histogram feature. The reason I don't save the histogram features into csv is because I want to dynamically regenerate the feature for different histogram parameter (number of bins, etc). This makes it easily tweakable for interface that I am planning to implement on skin suggestion application.","dfb6c75d":"We use a dictionary to put the duplications as the dictionary key and associate it with the similar image index. I am using `tqdm` to see the progress of the image analysis.","8413bcd0":"Now, we can select any of the valid images and grab the nearest 16 images from the dataset. Of course, from the previous, the closest skin will always appear the same with the supplied skin because we are using the skin from the same dataset. This may not happen when supplying skin outside of the data set.","f4affc57":"# Labelling and Analysing Clusters\n\nHere, I re-run the predictions on the whole dataset and then write the output into a `DataFrame` so that we can analyse the clusters.","39596af7":"Here, I initialise the model that can run on multithreading using all available cores.","2b7fb051":"We can also group the dataframe based on their cluster name and then count the number of instances in each group. From the output, we can see that cluster with the least number of skins is for the high-contrast skins. The rest of the clusters have about the same number of instances.","7f37822b":"In this following skin generation, the suggested skins are mostly bright. Skin duplication is still noticable, but we can see that the suggestions are very similar to the supplied image.","acb378e8":"### Training Set \n\nUsing only 50% from the dataset","80ff3cde":"# K-Nearest Skin Suggestions\n\nIn the skin suggestion algorithm, the suggested skin will be among the given dataset only, so the provided output will be local-optima, but because the skin option is huge, I think the user will not ever run out of option. The KNN algorithm will give out the list of skins for the whole dataset ordered by their closest histogram distance, so I will make use of my own `Stream#next` implementation to iterate through the list.","b05ed64e":"Unfortunately, after filtering all duplications, we are only left with about 25% of the original size of dataset. ","80824fa2":"# Conclusion\n\nI have re-run the whole notebook with different value for rgb and hsv bins. Overall, I think HSV should be just enough to help adding more context to the image. When there are too many parameter, the generalisation becomes less effecient to group similar skins. Skin suggestion application can be made possible because the suggested skins are very similar with the supplied skin in terms of the tone of the skin color, but there are many duplications. But this can be easily removed because the duplicated skins usually appear next to each other, so we can introduce distance threshold for two skins to be considered as a duplication. Finally, this is where I found out that the dataset has too many duplicated skins and only about 25% of them is unique.","9dfc496b":"This is an utility function that can show the front view of the skin with the skin accessories. ","382ce269":"### Cluster Sample (Body Skin)","50eb4b15":"### Validation Set\n\nUsing only 2% of the dataset","2348680f":"We can inspect the content in the `similar` dictionary to check if we have successfully register the duplicated entries.","962fb90e":"From the DataFrame shape, we can see that about 25% out of 7830 images in the dataset is excluded, which leaves us 5581 of images. This is majorly due to the image filter for those that does not have an alpha channel as well as those that cannot be parsed into histograms. However, I think 5000 is still a large number and we can still get somem good insights out of this.","158a48d8":"Most of the suggested skins appear the similar with the supplied skin. Black feature is the strongest similarities among all. However, there are a lot of duplication, which has made the suggestions becomes dirty.","af88a745":"### K-Means Clustering\n\nThere will be 3 clusters and 30 trials for finding the best clustering model.","41f9df38":"Minecraft Skin Analysis: Skin Suggestions using KNN\n---\n\nThis is a follow-up to my [minecraft skin clustering notebook](https:\/\/www.kaggle.com\/yedata\/minecraft-skin-analysis) for developing a skin suggestions algorithm using KNN. \n\nThere is a slight improvement on the feature engineering where I merge histograms for both RGB and HSV channels and use lower number bins for better generalisation. Clustering gives us the idea whether or not the features extracted are suitable for generalisation or not. Here, we will revisit clustering for a brief moment to check the clustering quality from the new histogram feature.","0039df91":"# Deduplicate Skin\n\nOne advantage of skin images is that their texture feature are fixed and the same. For example, the head of the skin is always at the same position for all skin. To identify similar skins, we can make a distance function to directly compare the skin images pixel by pixel and use a very low threshold. The following distance function calculates the percentage of absolute difference between two front view of a skin. ","a9e1f308":"The cluster with the second most member shows mostly darker shade of skin color as compared to the cluster with the most member, but both on them has well-defined gradient in their head skin colour. In the last cluster, the head skins are mostly plain, which gives them a high contrast feature. Therefore, we can make three groupings of:\n\n- High contrast skin\n- Dark skins\n- Light skins","d0ec4e69":"# Clustering: Revisited\n\nTo recap, there are two performing clusters while the others are not well-defined in the last clustering notebook. So, I have concluded that I can only make three clusters for this dataset."}}