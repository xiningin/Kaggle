{"cell_type":{"53be026d":"code","80aea215":"code","526fb48a":"code","7273718d":"code","f251d7f3":"code","a6f664d5":"code","2ae3bc34":"code","66edc0ba":"markdown"},"source":{"53be026d":"import os\nimport numpy as np\nimport pandas as pd\nimport csv\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, Dense, Flatten, MaxPooling2D, AveragePooling2D, BatchNormalization\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom sklearn.model_selection import train_test_split\n\nTRAIN_PERC = 0.8\nDATA_LENGHT = 42000\nVAL_LENGHT = DATA_LENGHT*(1-TRAIN_PERC)\nTEST_LENGHT = 28000\nBATCH_SIZE = 600","80aea215":"data = pd.read_csv('..\/input\/digit-recognizer\/train.csv', dtype='float32')\ntest = pd.read_csv('..\/input\/digit-recognizer\/test.csv', dtype='float32')\n\ndata_input = data.drop(columns=['label']).values.reshape(DATA_LENGHT,28,28,1)\/255.0\ndata_labels = data['label'].values\n\ntest_input = test.values.reshape(TEST_LENGHT,28,28,1)\/255.0\n\nx_train, x_val, y_train, y_val = train_test_split(data_input, data_labels, train_size=TRAIN_PERC, \n                                                  random_state=35261) ","526fb48a":"generator = ImageDataGenerator()\ngenerator.fit(x_train)","7273718d":"model = Sequential()\n\nmodel.add(Conv2D(64, (3,3), padding='same', input_shape=(28,28,1)))\nmodel.add(Conv2D(64, (3,3), padding='same', activation='relu'))\nBatchNormalization()\nmodel.add(MaxPooling2D((2,2)))\n\nmodel.add(Conv2D(128, (3,3), padding='same', activation='relu'))\nmodel.add(Conv2D(128, (3,3), padding='same', activation='relu'))\nBatchNormalization()\nmodel.add(MaxPooling2D((2,2)))\n\nmodel.add(Conv2D(256, (3,3), padding='same', activation='relu'))\nmodel.add(Conv2D(256, (3,3), padding='same', activation='relu'))\nmodel.add(Conv2D(256, (3,3), padding='same', activation='relu'))\nBatchNormalization()\nmodel.add(MaxPooling2D((2,2)))\n\nmodel.add(Conv2D(512, (3,3), padding='same', activation='relu'))\nmodel.add(Conv2D(512, (3,3), padding='same', activation='relu'))\nBatchNormalization()\nmodel.add(MaxPooling2D((2,2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(100, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))","f251d7f3":"model.summary()","a6f664d5":"cp = ModelCheckpoint('digit_model_dcti.{epoch:02d}-{accuracy:.2f}.h5', monitor='val_accuracy',\n                     save_best_only=True, verbose=1, mode='max')\n\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\nmodel.fit_generator(generator=generator.flow(x_train, y_train, BATCH_SIZE), epochs=10, \n                    validation_data=(x_val, y_val), validation_steps=int(VAL_LENGHT\/BATCH_SIZE), \n                    callbacks=[cp])","2ae3bc34":"predictions = model.predict_classes(test_input)\nsubmission = np.array([range(1, TEST_LENGHT+1), predictions], np.int16).T\nnp.savetxt('submission.csv', submission, fmt='%d', delimiter=',', header='ImageId,Label', comments='', newline='\\r\\n')","66edc0ba":"Here's a quick implementation of a CNN from [this](https:\/\/www.scitepress.org\/papers\/2018\/67520\/67520.pdf) paper. The authors designed a relatively small DCNN for tiny object recognition. The model has been trained for 10 epochs, reaching a precision of 0.99103 on the test set. I belive the score could be further improved training the model for more epochs. The model is one layer smaller than the original CNN in the paper and the input size is 28x28 grayscale, instead of 32x32 RGB."}}