{"cell_type":{"73345dc2":"code","eaa56131":"code","3483ae80":"code","967a5753":"code","83d540fe":"code","160ba93f":"code","531674d1":"code","74c9c645":"code","3462ddfb":"code","5c20ac11":"code","ce1378bb":"code","a8a641dc":"code","04bc5896":"code","92c7aa07":"code","1f88eacb":"code","acbf00da":"code","3d32a790":"code","3be57aa8":"code","0c2f4d7f":"code","45e5349a":"code","ec1a678a":"code","49d40a63":"code","8e688486":"code","5c07190a":"code","b7e5b0c5":"code","7a6b9245":"code","254fecbf":"code","16094141":"code","e56f2c9d":"code","d32f8076":"code","882f3762":"code","c0c7a3e4":"code","6293089e":"code","8cdff78d":"code","48899e4c":"code","e3e02eb3":"code","22f55d1d":"code","04a3ab60":"code","89c10400":"code","e1316939":"code","a4a24bd7":"code","949bad0f":"code","6576b07a":"code","0136c9a2":"code","b2e532bd":"code","b4089b47":"code","46e44d27":"code","1106098e":"code","1e768765":"markdown","b9a1afa6":"markdown","0fc3a61c":"markdown","24b134a3":"markdown","3ebf2ee3":"markdown","675891f9":"markdown","9b00faa1":"markdown","1b7a7e53":"markdown","601f8b47":"markdown","e32a0084":"markdown","4faee303":"markdown","46b80d4f":"markdown","4b727bd3":"markdown","b0952127":"markdown","cb8fcf29":"markdown","7dc8505c":"markdown","8d6bb33d":"markdown","d50357f4":"markdown","483eeef8":"markdown","e96c0142":"markdown","27917f31":"markdown","76784274":"markdown","17cadb9d":"markdown","6ec900fa":"markdown","2d94c6e2":"markdown","8a2c5514":"markdown","53219d44":"markdown"},"source":{"73345dc2":"import numpy as np \nimport pandas as pd \nimport seaborn as sns\nfrom sklearn import linear_model, metrics\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt","eaa56131":"df = pd.read_csv(\"..\/input\/PoliceKillingsUS.csv\", encoding=\"windows-1252\")\ndf.head()","3483ae80":"df.index[2500:]","967a5753":"df = df.rename(columns={\"city\": \"City\"})\n\ndf.drop([\"id\", \"name\", \"manner_of_death\"], axis=1, inplace=True) # Deleting useless columns\n\ndf.age.fillna(value=df.age.mean(), inplace=True) # Dealing with missing AGE values. Set them to mean of all ages. \ndf.age = df.age.astype(int)\n\ndf.dropna(subset=[\"race\"], inplace=True) # Deleting rows with missing values for race\n\ndf.drop(df.index[2363:], inplace=True) # Deleting deaths after 01\/06\/2017, as more info is missing about these, including vital information such as race","83d540fe":"# Adding total_population column with data corresponding to race\n\nconditions = [df[\"race\"]==\"A\", df[\"race\"]==\"W\", df[\"race\"]==\"H\", df[\"race\"]==\"B\", df[\"race\"]==\"N\", df[\"race\"]==\"O\"]\nnumbers = [14674252, 223553265, 50477594, 38929319, 2932248, 22579629]\n\ndf[\"total_population\"] = np.select(conditions, numbers, default=\"zero\")\n\ndf.head()","160ba93f":"plt.figure(figsize=(15,5))\nsns.countplot(data=df, x=\"race\")\n\nplt.title(\"Total number of people killed, by race\", fontsize=17)","531674d1":"# List of nr of people killed per race\n\nraces = [\"A\", \"W\", \"H\", \"B\", \"N\", \"O\"]\nkilled_per_race = []\n\nfor i in races:\n    i_killings = df.race.loc[(df.race==i)].count()\n    killed_per_race.append(i_killings)\n    \nprint (killed_per_race)","74c9c645":"prop_killed_per_race = []\n\nfor i in races:\n    \n    if i == \"A\":\n        prop_i_killed = killed_per_race[0]\/14674252.0\n        print (prop_i_killed)\n    elif i == \"W\":\n        prop_i_killed = killed_per_race[1]\/223553265.0\n        print (prop_i_killed)\n    elif i == \"H\":\n        prop_i_killed = killed_per_race[2]\/50477594.0\n        print (prop_i_killed)\n    elif i == \"B\":\n        prop_i_killed = killed_per_race[3]\/38929319.0\n        print (prop_i_killed)\n    elif i == \"N\":\n        prop_i_killed = killed_per_race[4]\/2932248.0\n        print (prop_i_killed)\n    else:\n        prop_i_killed = killed_per_race[5]\/22579629.0\n        print (prop_i_killed)\n    \n    prop_killed_per_race.append(prop_i_killed)","3462ddfb":"plt.figure(figsize=(14,6))\nplt.title(\"People killed as a proportion of their respective race\", fontsize=17)\nsns.barplot(x=races, y=prop_killed_per_race)","5c20ac11":"female = df[df[\"gender\"] == \"F\"].gender.count()\nmale = df[df[\"gender\"] == \"M\"].gender.count()\nperc_male = (male*100)\/(male+female) \n\nplt.figure(figsize=(7,5))\nsns.countplot(data=df, x=\"gender\")\n\nplt.title(\"Total number of people killed, by gender\", fontsize=17)\n\nprint (str(perc_male) + \"% \" + \"of the victims are male.\")","ce1378bb":"plt.figure(figsize=(15,7))\nage_dist = sns.distplot(df[\"age\"], bins=40)\nage_dist.set(xlabel=\"Age\", ylabel=\"Count\")\n\nplt.title(\"Age distribution\", fontsize=17)","a8a641dc":"# First, create dataset with only Blacks, Whites, Hispanics\n\nthree_races = df.loc[(df[\"race\"] == \"B\") | (df[\"race\"] == \"W\") | (df[\"race\"] == \"H\")]\n\ng = sns.FacetGrid(data=three_races, hue=\"race\", aspect=3, size=4)\ng.map(sns.kdeplot, \"age\", shade=True)\ng.add_legend(title=\"Race\")\n\n\ng.set_ylabels(\"Count\")\nplt.title(\"Age distribution, by race\", fontsize=17)","04bc5896":"avg_age_w = df.age[(df[\"race\"] == \"W\")].mean() \navg_age_b = df.age[(df[\"race\"] == \"B\")].mean() \navg_age_h = df.age[(df[\"race\"] == \"H\")].mean() \n\nprint (\"Average age of white victims is \" + str(avg_age_w))\nprint (\"Average age of black victims is \" + str(avg_age_b))\nprint (\"Average age of hispanic victims is \" + str(avg_age_h))","92c7aa07":"plt.figure(figsize=(20,10))\nsns.countplot(data=df, x=df.state)\nplt.title(\"Number of police killings, by state\", fontsize=27)","1f88eacb":"city = df.City.value_counts(ascending=False)\n\ndf_city = df.filter([\"City\"], axis=1)\ndf_city[\"count\"] = 1\n\ngrouped_city = df_city.groupby(\"City\", as_index=False,sort=False).sum()\ngrouped_city.sort_index(ascending=False)\n\ngrouped_city = grouped_city.sort_values(\"count\", ascending=False).head(8)                                                       \n\nplt.figure(figsize=(15,8))\nsns.barplot(data=grouped_city, x=\"City\", y=\"count\")\nplt.title(\"Most dangerous cities\", fontsize=17)","acbf00da":"%%HTML\n<div class='tableauPlaceholder' id='viz1504205405904' style='position: relative'><noscript><a href='#'><img alt='Sheet 1 ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;In&#47;InteractivePoliceKillingsMap&#47;Sheet1&#47;1_rss.png' style='border: none' \/><\/a><\/noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' \/> <param name='path' value='views&#47;InteractivePoliceKillingsMap&#47;Sheet1?:embed=y&amp;:display_count=y&amp;publish=yes' \/> <param name='toolbar' value='yes' \/><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;In&#47;InteractivePoliceKillingsMap&#47;Sheet1&#47;1.png' \/> <param name='animate_transition' value='yes' \/><param name='display_static_image' value='yes' \/><param name='display_spinner' value='yes' \/><param name='display_overlay' value='yes' \/><param name='display_count' value='yes' \/><param name='filter' value='publish=yes' \/><\/object><\/div>                <script type='text\/javascript'>                    var divElement = document.getElementById('viz1504205405904');                    var vizElement = divElement.getElementsByTagName('object')[0];                    vizElement.style.width='100%';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';                    var scriptElement = document.createElement('script');                    scriptElement.src = 'https:\/\/public.tableau.com\/javascripts\/api\/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                <\/script>","3d32a790":"armed = df.armed.value_counts(ascending=False)\n\ndf_armed = df.filter([\"armed\"], axis=1)\ndf_armed[\"count\"] = 1\n\ngrouped_armed = df_armed.groupby(\"armed\", as_index=False,sort=False).sum()\ngrouped_armed.sort_index(ascending=False)\n\ngrouped_armed = grouped_armed.sort_values(\"count\", ascending=False).head(8) \n\nplt.figure(figsize=(15,8))\nsns.barplot(data=grouped_armed, x=\"armed\", y=\"count\")\nplt.title(\"Most common ways of being armed\", fontsize=17)","3be57aa8":"income = pd.read_csv(\"..\/input\/MedianHouseholdIncome2015.csv\", encoding=\"windows-1252\")\nincome[\"City\"].replace([\"city\", \"CDP\", \"town\"], \"\", regex=True, inplace=True)\nincome[\"city\"] = income[\"City\"] + \", \" + income[\"Geographic Area\"]\nincome.drop([\"Geographic Area\", \"City\"], axis=1, inplace=True)\n\npoverty = pd.read_csv(\"..\/input\/PercentagePeopleBelowPovertyLevel.csv\", encoding=\"windows-1252\")\npoverty[\"City\"].replace([\"city\", \"CDP\", \"town\"], \"\", regex=True, inplace=True)\npoverty[\"city\"] = poverty[\"City\"] + \", \" + poverty[\"Geographic Area\"]\npoverty.drop([\"Geographic Area\", \"City\"], axis=1, inplace=True)\n\nrace = pd.read_csv(\"..\/input\/ShareRaceByCity.csv\", encoding=\"windows-1252\")\nrace[\"City\"].replace([\"city\", \"CDP\", \"town\"], \"\", regex=True, inplace=True) \nrace[\"city\"] = race[\"City\"] + \", \" + race[\"Geographic area\"]\nrace.drop([\"Geographic area\", \"City\"], axis=1, inplace=True)\n\nhighschool = pd.read_csv(\"..\/input\/PercentOver25CompletedHighSchool.csv\", encoding=\"windows-1252\")\nhighschool[\"City\"].replace([\"city\", \"CDP\", \"town\"], \"\", regex=True, inplace=True)\nhighschool[\"city\"] = highschool[\"City\"] + \", \" + highschool[\"Geographic Area\"]\nhighschool.drop([\"Geographic Area\", \"City\"], axis=1, inplace=True)","0c2f4d7f":"df[\"city\"] = df[\"City\"] + \" , \" + df[\"state\"] # Creating the same \"city\" format\nmerge1 = pd.merge(poverty, race, on=\"city\", how=\"outer\")\nmerge2 = pd.merge(merge1, income, on=\"city\", how=\"outer\")\nmerge3 = pd.merge(merge2, highschool, on=\"city\", how=\"outer\")\ndata = pd.merge(df, merge3, on=\"city\", how=\"outer\")\ndata.dropna(inplace=True)\n\ndata[[\"Median Income\", \"poverty_rate\", \"share_white\", \"share_black\", \"share_native_american\", \"share_asian\", \n      \"share_hispanic\", \"percent_completed_hs\"]] = data[[\"Median Income\", \"poverty_rate\", \"share_white\", \"share_black\", \"share_native_american\", \"share_asian\", \n      \"share_hispanic\", \"percent_completed_hs\"]].replace(\"(X)\", np.NaN)\ndata[[\"Median Income\", \"poverty_rate\", \"share_white\", \"share_black\", \"share_native_american\", \"share_asian\", \n      \"share_hispanic\", \"percent_completed_hs\"]] = data[[\"Median Income\", \"poverty_rate\", \"share_white\", \"share_black\", \"share_native_american\", \"share_asian\", \n      \"share_hispanic\", \"percent_completed_hs\"]].replace(\"-\", np.NaN)\n\ndata[[\"Median Income\", \"poverty_rate\", \"share_white\", \"share_black\", \"share_native_american\", \"share_asian\", \n      \"share_hispanic\", \"percent_completed_hs\"]] = data[[\"Median Income\", \"poverty_rate\", \"share_white\", \"share_black\", \"share_native_american\", \"share_asian\", \n      \"share_hispanic\", \"percent_completed_hs\"]].astype(float)","45e5349a":"data.dropna(inplace=True)","ec1a678a":"# Converting neccesary columns to floats\ndata[\"poverty_rate\"] = data[\"poverty_rate\"].astype(float)\ndata[\"share_white\"] = data[\"share_white\"].astype(float)\ndata[\"share_black\"] = data[\"share_black\"].astype(float)\ndata[\"share_native_american\"] = data[\"share_native_american\"].astype(float)\ndata[\"share_asian\"] = data[\"share_asian\"].astype(float)\ndata[\"share_hispanic\"] = data[\"share_hispanic\"].astype(float)\ndata[\"percent_completed_hs\"] = data[\"percent_completed_hs\"].astype(float)\ndata[\"Median Income\"] = data[\"Median Income\"].astype(int)","49d40a63":"data.head()","8e688486":"from sklearn.cross_validation import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier","5c07190a":"# Mapping True\/False to 1\/0\n\ndata[\"signs_of_mental_illness\"] = data[\"signs_of_mental_illness\"].astype(int)\ndata[\"body_camera\"] = df[\"body_camera\"].astype(int)\n\n# Using LabelEncoder to deal with categorical features\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\nle.fit([\"armed\", \"race\", \"gender\", \"city\", \"state\", \"threat_level\", \"flee\"])","b7e5b0c5":"data_log = data.apply(LabelEncoder().fit_transform)\n\nX = data_log\ny = data_log[\"race\"]\nX.drop([\"race\", \"date\", \"total_population\"], axis=1, inplace=True)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","7a6b9245":"rfc = RandomForestClassifier()\nrfc.fit(X_train, y_train)","254fecbf":"rfc_pred = rfc.predict(X_test)\nrfc.feature_importances_","16094141":"feature_data = pd.DataFrame({\"feature_name\": data_log.columns, \"feature_importance\": rfc.feature_importances_}) \nfeature_data","e56f2c9d":"print(classification_report(y_test, rfc_pred))","d32f8076":"from sklearn.metrics import accuracy_score\n\n# Accuracy score\nrf_accuracy_score = accuracy_score(y_test, rfc_pred)\nrf_accuracy_score","882f3762":"params = {\"max_depth\": [32,44,50],\n         \"n_estimators\": [15,18,26,32],\n          \"min_samples_leaf\": [40,50,60],\n         \"criterion\": [\"gini\", \"entropy\"]}\n\nfrom sklearn import model_selection\n\ngs_rf = model_selection.GridSearchCV(estimator=rfc,\n                                 param_grid=params,\n                                 cv=5,\n                                 scoring=\"accuracy\")\n\ngs_rf.fit(X_train, y_train)","c0c7a3e4":"# Extract the best parameters\ngs_rf.best_params_","6293089e":"# Accuracy score after grid search\ngs_rf_accuracy_score = gs_rf.best_score_ \ngs_rf_accuracy_score","8cdff78d":"# Transforming columns into dummy varaibles\n\ndummies = pd.get_dummies(data[[\"armed\", \"gender\", \"city\", \"City\", \"state\", \"threat_level\", \"flee\",\"signs_of_mental_illness\", \"body_camera\"]], drop_first=True)\ndummies = pd.concat([data, dummies], axis=1)\n\ndummies.drop(data[[\"date\", \"armed\", \"gender\", \"city\", \"City\", \"state\", \"threat_level\", \"flee\", \"total_population\",\"signs_of_mental_illness\", \"body_camera\"]], axis=1, inplace=True)\ndummies.dropna()\ndummies.head()","48899e4c":"X = dummies.drop(\"race\", axis=1)\ny = dummies[\"race\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n\nfrom sklearn.linear_model import LogisticRegression\n\nlogmodel = LogisticRegression()\nlogmodel.fit(X_train, y_train)","e3e02eb3":"predictions = logmodel.predict(X_test)\nprint (classification_report(y_test, predictions))","22f55d1d":"# Accuracy score\nlog_accuracy_score = accuracy_score(y_test, predictions)\nlog_accuracy_score","04a3ab60":"params = {\"max_iter\": [20,30,50],\n         \"C\": [1.0, 2.0, 3.0]}\n\ngs_logmodel = model_selection.GridSearchCV(estimator=logmodel,\n                                 param_grid=params,\n                                 cv=5,\n                                 scoring=\"accuracy\")\n\ngs_logmodel.fit(X_train, y_train)","89c10400":"gs_logmodel.best_params_","e1316939":"# Accuracy score\ngs_logmodel_accuracy_score = gs_logmodel.best_score_\ngs_logmodel_accuracy_score","a4a24bd7":"from sklearn.neighbors import KNeighborsClassifier\n\nX = dummies.drop(\"race\", axis=1)\ny = dummies[\"race\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n\nknn = KNeighborsClassifier(n_neighbors=1) # k=1\nknn.fit(X_train, y_train)","949bad0f":"pred = knn.predict(X_test)\nprint(classification_report(y_test, pred))","6576b07a":"knn_accuracy_score = accuracy_score(y_test, pred)\nknn_accuracy_score","0136c9a2":"error_rate = []\n\nfor i in range(1,30): # Checking every possible k value from 1-30\n\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train, y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test)) ","b2e532bd":"plt.figure(figsize=(10,6))\nplt.plot(range(1,30), error_rate, color=\"grey\", marker=\"o\", markerfacecolor=\"red\")\nplt.title(\"Error rate vs K value\", fontsize=17)\nplt.xlabel(\"K\")\nplt.ylabel(\"Error rate\")","b4089b47":"knn = KNeighborsClassifier(n_neighbors=7)\nknn.fit(X_train, y_train)\npred = knn.predict(X_test)\n\nprint(classification_report(y_test, pred))","46e44d27":"# Accuracy score\nknn_accuracy_score_iter = accuracy_score(y_test, pred)\nknn_accuracy_score_iter","1106098e":"accuracy_pre = {\"Random Forest\": rf_accuracy_score, \n                \"Logistic Regression\": log_accuracy_score, \n                \"KNN\": knn_accuracy_score}\n\naccuracy_post = {\"Random Forest\": gs_rf_accuracy_score, \n                 \"Logistic Regression\": gs_logmodel_accuracy_score, \n                 \"KNN\": knn_accuracy_score_iter}\n\nX = np.arange(len(accuracy_pre))\nax = plt.subplot(111)\nax.bar(X, accuracy_pre.values(), width=0.2, color='b', align='center')\nax.bar(X-0.2, accuracy_post.values(), width=0.2, color='g', align='center')\nax.legend(('Before grid search','After grid search'))\nplt.xticks(X, accuracy_pre.keys())\nplt.title(\"Accuracy score\", fontsize=17)\nplt.show()","1e768765":"<br>\n## FINDINGS - SUMMARY\n\n* Blacks are 3 times more likely to become victims of police shootings than Whites.\n* The average age of Black and Hispanic victims is lower (31 and 33 respectively) than that of White victims (40).\n* California is the state with the most fatal police shootings, and Los Angeles is the most dangerous city.\n* The most common way of being armed is by gun.\n\n**Critical afterthought**\n\nThe data has some obvious shortcomings. For instance, it only goes 2.5 years back in time. It would be interesting to look at data from before this period as well, but as previously mentioned, such data is hard to find. Furthermore, this data doesn't track death from other means than by shooting (such as death in police custody and other means of death).\nJudging by the accuracy score of the three algorithms, the features don't do very well in explaining the target class.","b9a1afa6":"<br>\n## KNN ALGORITHM","0fc3a61c":"## PREPROCESSING THE DATA","24b134a3":"<br>\n## LOGISTIC REGRESSION ALGORITHM TO PREDICT RACE","3ebf2ee3":"#### Total number of people killed, by race","675891f9":"#### Merging the datasets","9b00faa1":"## EXPLORATORY ANALYSIS","1b7a7e53":"This bar chart shows the number of victims per race as a proportion of the total US population of respective race.\nEarlier, when we looked at the total number of people killed, we saw that twice as many Whites were killed as Blacks. However, if you look at the numbers as the proportion of the racial population, Blacks are approximately 3 times as likely to be killed by police than Whites.","601f8b47":"#### Comparing age distributions of Blacks, Whites, and Hispanics","e32a0084":"California, Texas and Florida are the states in which police killings are most frequent. These are also the three most populous states in the US.","4faee303":"#### Number of fatal shootings in each state","46b80d4f":"The dataset divides race into Asian, White, Hispanic, Black, Native American and Other. From the bar chart we can see that the overwhelming majority being killed by police is either White, Hispanic or Black, with White being the race with the largest amount of victims. \nThis makes sense since White is the largest racial group in the US, followed by Black and Hispanic.","4b727bd3":"The most important features in predicting race using the Random Forest algorithm are age and racial demographics.","b0952127":"#### Most dangerous cities","cb8fcf29":"Logistic Regression and the Random Forest algorithms yield the highest accuracy score both before and after running grid search. The KNN algorithm performs better after grid search, whereas Logistic Regression and Random Forest don't.\nKNN doesn't do much better than random choice, meaning there is a risk that there simply is no connection between features and the target class.","7dc8505c":"<br>\nAdding a column to the dataset called \"total population\" with the total US population of the corresponding race. \nSource: https:\/\/en.wikipedia.org\/wiki\/Demography_of_the_United_States\n<br>","8d6bb33d":"The age distribution of Blacks and Hispanics is skewed to the left, whereas the age distribution for Whites is more spread out. On average, Blacks and Hispanics are being killed at a younger age than Whites - which is consistent with the initial hypothesis that black males are subject to police killings at a young age.","d50357f4":"#### Preprocessing the census data","483eeef8":"## Adding features (census data)\n<br>\nUsing US census data, I have compiled datasets on median household income, poverty rate, high school graduation rate, and the racial demographic in each city. This information is then added to the original dataset. Below I merge these datasets, and apply various machine learning algorithms to explore whether it's possible to predict the race of a victim based on the features.","e96c0142":"#### Total number of people killed, by gender","27917f31":"## RANDOM FOREST ALGORITHM TO PREDICT RACE","76784274":"#### Visualizing police shootings using Tableau","17cadb9d":"#### Most common ways of being armed","6ec900fa":"k=7 gives the lowest error rate, so we try fitting the model again, using this information.","2d94c6e2":"#### Number of people killed as a proportion of respective races","8a2c5514":"## Comparing accuracy scores","53219d44":"#### General age distribution"}}