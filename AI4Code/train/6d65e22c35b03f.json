{"cell_type":{"35bb2371":"code","61c46440":"code","31b30c1c":"code","c2cf7ae4":"code","9cc4bdcf":"code","c0470cb8":"code","c88d8c99":"code","ad1d37cc":"code","8c7470c5":"code","9aaba31f":"code","63d006c1":"code","7d6f515d":"code","de4f39a5":"code","b71ff867":"code","82bb0d65":"code","a4639965":"markdown","328cd806":"markdown","f1a65044":"markdown","cbeda771":"markdown","a78a94a0":"markdown","fa3f343b":"markdown","23e3e914":"markdown","a9cfbab5":"markdown","ce38c1f4":"markdown","c86588ab":"markdown","fd8a8161":"markdown","411c4a55":"markdown","9e09d797":"markdown"},"source":{"35bb2371":"import numpy as np \nimport pandas as pd\nimport os\nimport random\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom collections import Counter\nimport cv2\n\n# from tensorflow.python.keras.applications.vgg16 import VGG16, preprocess_input\n# from tensorflow.python.keras.applications.resnet import ResNet50, preprocess_input \nfrom tensorflow.python.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input \nfrom tensorflow.keras.applications.resnet_v2 import ResNet152V2, preprocess_input\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import Adam, SGD\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, Input","61c46440":"base_dir = \"\/kaggle\/input\/knee-osteoarthritis-dataset-with-severity\"\n\ntrain_dir = os.path.join(base_dir,'train')\nval_dir = os.path.join(base_dir,'val')\ntest_dir = os.path.join(base_dir, 'test')","31b30c1c":"fig, ax = plt.subplots(5,5, figsize=(18,18))\n\nfor class_id in range(5):\n    folder = os.path.join(train_dir,str(class_id))\n    os.chdir(folder)\n    samples = random.sample(os.listdir(folder), 5)\n    \n    for col in range(5):\n        image = cv2.imread(samples[col])\n        ax[class_id, col].imshow(image)\n        ax[class_id, col].set_title(\"class_\" + str(class_id))\n        ax[class_id, col].set_axis_off()\n    \nplt.show()","c2cf7ae4":"def show_distribution(folder):\n    \n    datagen = ImageDataGenerator()\n    generator = datagen.flow_from_directory(folder)\n\n    counter = Counter(generator.classes)                          \n    total_images = sum(counter.values())\n    distribution = [(class_id,round(num_images \/ total_images * 100,2)) for class_id, num_images in counter.items()]\n\n    for class_id, percentage in distribution:\n        print(class_id, percentage)\n","9cc4bdcf":"print(\"The distribution for the training data is :\\n\")\nshow_distribution(train_dir)","c0470cb8":"print(\"The distribution for the validation data is :\\n\")\nshow_distribution(val_dir)","c88d8c99":"print(\"The distribution for the test data is :\\n\")\nshow_distribution(test_dir)","ad1d37cc":"# train_datagen = ImageDataGenerator()\n# train_generator = train_datagen.flow_from_directory(train_dir)\n\n# counter = Counter(train_generator.classes)                          \n# max_val = float(max(counter.values()))       \n# class_weights = {class_id : max_val\/num_images for class_id, num_images in counter.items()}   \n# print(\"\\nThe class weights are : \\n\\n\", class_weights)","8c7470c5":"folder = os.path.join(train_dir,'0')\nos.chdir(folder)\nsamples = random.sample(os.listdir(folder), 5)\n\nfor filename in samples:\n    image = cv2.imread(filename)\n    print(image.shape)","9aaba31f":"NUM_CLASSES = 5\nIMAGE_SIZE=[224, 224]\nBATCH_SIZE=32","63d006c1":"# Create the Generators\ntrain_val_generator = ImageDataGenerator(\n                                        preprocessing_function=preprocess_input,    \n                                        rotation_range=10,\n                                        width_shift_range=0.2,\n                                        height_shift_range=0.2,\n                                        shear_range=0.1,\n                                        zoom_range=0.2,\n                                        horizontal_flip=True,\n                                        vertical_flip=False,\n                                        fill_mode='nearest'\n                                        )\n\n\n# Train data generator\ntrain_data = train_val_generator.flow_from_directory(train_dir, \n                                                    target_size=IMAGE_SIZE,\n                                                    batch_size=BATCH_SIZE,\n                                                    class_mode='categorical',\n                                                    color_mode='rgb',\n                                                    shuffle=True\n                                                    )\n\n# Validation data generator\nval_data = train_val_generator.flow_from_directory(val_dir, \n                                                  target_size=IMAGE_SIZE,\n                                                  batch_size=BATCH_SIZE,\n                                                  class_mode='categorical',\n                                                  color_mode='rgb',\n                                                  shuffle=True\n                                                  )\n\n# Test data generator\ntest_generator  = ImageDataGenerator(preprocessing_function=preprocess_input)\ntest_data = test_generator.flow_from_directory(test_dir, \n                                               target_size=IMAGE_SIZE,\n                                               batch_size=1,\n                                               class_mode='categorical',\n                                               color_mode='rgb',\n                                               shuffle=False\n                                               )","7d6f515d":"base_model = ResNet152V2(input_shape=IMAGE_SIZE + [3],\n                            include_top=False,\n                            weights='imagenet',\n                            pooling='avg'\n                           )\n\nfor layer in base_model.layers:\n    layer.trainable = False","de4f39a5":"x_input = base_model.input\n\nx = Dense(128,activation='relu')(base_model.output)\nx = Dropout(0.2)(x)\n\noutput = Dense(NUM_CLASSES, activation='softmax')(x)\n\nmodel = Model(x_input, output)\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","b71ff867":"reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.0001)\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10)\n\nhist = model.fit(train_data,\n                 validation_data=val_data,\n                 epochs=50,\n#                  class_weight=class_weights,\n                 callbacks=[reduce_lr, early_stopping],\n                 verbose=1)","82bb0d65":"model.evaluate(test_data)","a4639965":"### Let us plot some sample images from each of the classes","328cd806":"#### Now add our own layer to classify each image into one of the possible classes","f1a65044":"The training stopped as the Early Stopping callback was triggered. That's ok. This is a very tough dataset and even getting around 52-53% accuracy across 5 classes is decent, if not the best","cbeda771":"### Let us check the distribution of the various classes for train, test and validation datasets","a78a94a0":"We got an accuracy of 52.6% on the test set. The model is not overfitting and is giving a decent results. Please suggest other ways to improve this further. Would be very happy to hear your thoughts.","fa3f343b":"#### Train the model\n\nI have tried providing class_weights but found that the model was quite unstable and was not giving good accuracy. Hence not using the class weights parameter","23e3e914":"## Build the model","a9cfbab5":"We can see that the images are all (224 X 224). We will have to choose the Transfer Model accordingly","ce38c1f4":"### Define the folder paths","c86588ab":"### Evaluate the model","fd8a8161":"### Check the size of the images","411c4a55":"### Dealing with imbalanced classes\n\nWe can see that the distributions are not balanced. Hence we would need to use ways to work with imbalanced data while training the model. One option is to use **\"class_weights\"**\n\nLet us calculate the appropriate class weights","9e09d797":"#### Load the base model"}}