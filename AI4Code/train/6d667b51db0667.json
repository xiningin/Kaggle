{"cell_type":{"8e1da83a":"code","869d7184":"code","3a368d54":"code","99b0fabe":"code","c9408d62":"code","e4245b7b":"code","c6d92ed3":"code","3d40718c":"code","af769f72":"code","e6dc0638":"code","42ac3162":"code","0ecebdc3":"code","08ff3669":"code","48d82019":"code","eaaa8f46":"code","e48e0d63":"code","aa2de867":"code","f6042e81":"code","e1953645":"code","4041457e":"code","22359a8c":"code","ecf02e67":"code","a1386645":"code","8645371d":"code","a54b6463":"code","78554334":"code","693dae17":"code","78c7ac6f":"code","39495b24":"code","4e0db3c1":"markdown","76e49f5c":"markdown","7b934802":"markdown","b4735951":"markdown","f9438364":"markdown","08bebbf0":"markdown","5acb6f42":"markdown","200fd77a":"markdown","34bb4c73":"markdown","358e428d":"markdown","20f39661":"markdown","b9c2b89c":"markdown","e94b3288":"markdown","d9f69e27":"markdown","daee7a8e":"markdown","449eecd4":"markdown","77969e91":"markdown","42fa2687":"markdown","694a82bc":"markdown","1ee9a7b2":"markdown","9aa292da":"markdown","6cd9bc27":"markdown","2b1f0c21":"markdown","67f3c469":"markdown","37242173":"markdown","6c0761c1":"markdown","6d6fa0c4":"markdown","755209f3":"markdown","ed51af83":"markdown","982e6414":"markdown","cdcf7f9e":"markdown","02e6c0d0":"markdown","abb02d91":"markdown","208a8f52":"markdown","11a785b9":"markdown","1d7b59ab":"markdown","deefa2fe":"markdown","e6383c9c":"markdown","f40a1681":"markdown","1b54714a":"markdown","3d23a095":"markdown","694edc07":"markdown","6e11721c":"markdown","52e99ee9":"markdown","7d8d4aef":"markdown","8b8acf44":"markdown","245d942f":"markdown","0c8620fe":"markdown","599b8228":"markdown","76f43ae9":"markdown","b8f8641e":"markdown","32993a6d":"markdown","9afcfd87":"markdown"},"source":{"8e1da83a":"# For managing , processing , cleaning Data:\nimport pandas as pd\nimport numpy as np\n\n# For open Data:\nimport os as os\n\n# For managing data and search for specific informations:\nimport re\n\n# For geographycal visualisation :\nimport folium\nimport geopandas as gpd\nfrom folium.plugins import DualMap\nfrom folium.plugins import TimestampedGeoJson\n\n# For visualisation :\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\n# To generate some gradian colors :\nfrom matplotlib.cm import YlGn, YlOrBr, OrRd\n\n# legend Colormap:\nimport branca.colormap as cm\n\n# For more interactive Visualisation :\nimport plotly.express as px\nimport plotly.graph_objects as go\n\n# For Create features:\nfrom geojson import Feature, Point, FeatureCollection\n\n# To genearte Word Cloud Picture for illustration purpose \nfrom wordcloud import WordCloud, STOPWORDS\n\n# To generate datetime objects:\nimport datetime","869d7184":"# I- converting to continuous data:\n\ndef continuous_data(columns): \n# columns = ['pct_black\/hispanic', 'pct_free\/reduced', 'county_connections_ratio',\n#           'pp_total_raw']     \n\n    d_infos_ = pd.DataFrame(d)\n\n    for column in columns :\n        datas = []\n        if column == 'pp_total_raw':\n            for data in d[column]:\n                data = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", data)\n                data[0] = int(float(data[0]))\n                data[1] = int(float(data[1]))\n                datas.append(sum(data)\/len(data))\n        else :\n            for data in d[column]:\n                data = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", data)\n                data[0] = float(data[0])\n                data[1] = float(data[1])\n                datas.append(sum(data)\/len(data))\n        d_infos_[column] = datas\n    return d_infos_\n\n# II- Top 10 products with higher engagement_index per district:\n\ndef Top_10():\n    # read all engagement data that have data of \"district_infos\" :\n    P_infos_n = P_infos[['LP ID', 'Product Name', 'main_fun']]\n    P_infos_n = P_infos_n.rename(columns={\"LP ID\" : \"lp_id\"}, inplace=False)\n    dfs = {'locale':[], 'state': [], 'ID':[], 'Data':[]}\n    for ID, x in zip(d_infos_.district_id, zip(d_infos_.locale, d_infos_.state)) :\n        dfs['locale'].append(x[0])\n        dfs['state'].append(x[1])\n        dfs['ID'].append(ID)\n\n        tmp_df = pd.DataFrame(pd.read_csv(path+'\/engagement_data\/'+ str(ID)+'.csv')).dropna()\n        tmp_df.time = pd.to_datetime(tmp_df.time)    \n        tmp_df = pd.merge(tmp_df, P_infos_n, on='lp_id')    \n\n        tmp_df = pd.DataFrame(\n        tmp_df[['time', 'lp_id', 'engagement_index', 'Product Name', 'main_fun']].groupby(\n            [pd.Grouper(key='time', freq='1M')]\n            ).apply(\n            lambda x: x.nlargest(1, 'engagement_index'))\n                             )\n        tmp_df.insert(5,\"locale\" , x[0] )\n        tmp_df.insert(6,\"state\" , x[1] )\n\n        dfs['Data'].append(pd.DataFrame(tmp_df).dropna())\n    \n    # concatenate all angagement_data :\n    mlind = [(x, y) for x, y in zip(dfs['locale'], dfs['state']) ]\n    # mlind = [x for x in dfs['locale'] ]\n    DF = pd.concat([pd.DataFrame(df) for df in dfs['Data']], keys= mlind)\n    \n    return DF\n\n# III-  Map a color for each values of 'pp_total_raw' from\n# the districts informations data :\n\ndef color_P_T_R_function(x, locale):\n    if locale == 'City':\n        data_min = All.loc['City']['pp_total_raw'].min()\n        data_max = All.loc['City']['pp_total_raw'].max()\n    elif locale == 'Rural':\n        data_min = All.loc['Rural']['pp_total_raw'].min()\n        data_max = All.loc['Rural']['pp_total_raw'].max()\n    elif locale == 'Town':\n        data_min = All.loc['Town']['pp_total_raw'].min()\n        data_max = All.loc['Town']['pp_total_raw'].max()\n    elif locale == 'Suburb':\n        data_min = All.loc['Suburb']['pp_total_raw'].min()\n        data_max = All.loc['Suburb']['pp_total_raw'].max()\n    y = (x-data_min)\/(data_max-data_min)   \n    color_tuple = YlGn(y, bytes=True)[:3]  \n    return \"#%02x%02x%02x\" % color_tuple         \n\n# IV- Geo-Visualisation of the 'PP_Total_raw' :\n\ndef PP_Total_raw_map(Locales): # Locales = ['City', 'Suburb', 'Town', 'Rural']\n    # Initialization :\n    Map = folium.Map([40, -102], zoom_start = 3)\n    \n    # Create colormap legend :\n    Mx = All.pp_total_raw.max()\n    Mn = All.pp_total_raw.min()\n    scale = np.linspace(Mn,Mx,3)\n    colormap = cm.LinearColormap(colors=['yellow', 'green'],\n                                 index=[Mn, Mx],vmin=Mn, vmax=Mx,\n                                 caption='Per-pupil total expenditure per locale')\n    # add legend to map :\n    Map.add_child(colormap)\n\n    for L in Locales:\n        \n        folium.features.GeoJson(name=\"Click for\"+ L ,\n                                data=All.loc[L],\n                                style_function=lambda feature: {\n        'fillColor': color_P_T_R_function(feature['properties']['pp_total_raw'],L),\n                                'color' : 'black',\n                                'weight' : 1,\n                                'fillOpacity' : .9},\n                                  show=True,\n        tooltip=folium.features.GeoJsonTooltip(\n        fields=['locale','state','district_id','pct_black\/hispanic',\n                'pct_free\/reduced','county_connections_ratio',\n                'pp_total_raw'],\n        aliases=['Locale','State','ID', 'B\/H (%)', 'F\/R (%)', 'C.C.R', \n                 'PP.T.R'],\n        style=(\"background-color: white; color: #333333; font-family: arial; font-size: 12px; padding: 10px;\") \n        )\n                               ).add_to(Map)\n    \n    # Custome the non-information for the missing states : \n    \n    folium.features.GeoJson(\n    name=\"State with no informations.\",\n    data=geoJSON_df[~geoJSON_df['state'].isin(All['state'])],\n    style_function=lambda feature: {\n            'fillColor': '#ffffff',\n            'color' : 'black',\n            'weight' : 1},\n            #'dashArray' : '5, 5'},\n    show=True,\n    tooltip=folium.features.GeoJsonTooltip(\n    fields=['state'],\n    aliases=[\"<b>State <\/b><br><i>No information to display <\/i>.\"],\n    style=(\"background-color: white; color: #333333; font-family: arial; font-size: 12px; padding: 10px;\") \n            )\n        ).add_to(Map)\n    \n    folium.TileLayer('cartodbdark_matter',name=\"dark mode\",control=True).add_to(Map)\n    folium.TileLayer('cartodbpositron',name=\"light mode\",control=True).add_to(Map)\n\n    folium.LayerControl(collapsed=True).add_to(Map)\n    \n    return Map\n\n# V- chart for Top products visualusation:\n\ndef Top_Visual():\n    date = [datetime.datetime(int(str(x).split(' ')[0].split('-')[0]),\n                          int(str(x).split(' ')[0].split('-')[1]),\n                          int(str(x).split(' ')[0].split('-')[2])).strftime(\"%b %Y\")\n                          for x in pd.date_range(start='2020-01-01', end='2020-12-31', freq= \"M\")]\n\n    fig = go.Figure()\n\n    Locale = ['City', 'Town', 'Suburb', 'Rural']   \n    colors = ['firebrick', 'steelblue', 'indianred', 'lightsalmon']\n    for locale, c in zip(Locale, colors) :\n\n        Data = pd.DataFrame(Top_districts.loc[locale].groupby([pd.Grouper(key='time', freq='1M')],\n                                            as_index = False).apply(\n            lambda x: x.nlargest(1, 'engagement_index'))\n                        )    \n        Data['main_fun'] = Data['main_fun'].str.replace('LC','Learning & Curriculum')\n        Data['main_fun'] = Data['main_fun'].str.replace('CM','Classroom Management')\n        Data['main_fun'] = Data['main_fun'].str.replace('SDO','School & District Operations')\n\n        fig.add_trace(go.Bar(\n            x=date,\n            y=Data[\"engagement_index\"],\n            name=locale,\n            marker_color=c,\n            hovertext=\"<b>Product:<\/b><i>\" + Data[\"Product Name\"] +\"<\/i>.<br>\"\n            +\"<b>State:<\/b><i>\"+ Data[\"state\"] + \"<\/i>.<br>\"\n            +\"<b>Essential Function:<\/b><i>\"+ Data[\"main_fun\"] + \"<\/i>.\"\n        ))\n\n    fig.update_layout(\n        title=f'Total page-load events per one thousand students per product',\n        xaxis_tickfont_size=14,\n        xaxis_tickangle=-45,\n        yaxis=dict(\n            title='Engagement Index',\n            titlefont_size=16,\n            tickfont_size=14,\n        ),\n        barmode='group'\n    )\n\n    return fig.show()\n\n# In order to create features:\n\ndef Create_feature(kind):\n    \n    # Beging Creating Features\n    TmpFeature = []\n    for index,row in Group_df.iterrows() :\n        long = Lon_lat[Lon_lat['state'] == index[1]]['long'].values[0]\n        lat = Lon_lat[Lon_lat['state'] == index[1]]['lat'].values[0]\n        radius_data = 'radius\/' + kind\n        fill_color_data = 'fill color\/' + kind\n        TmpFeature.append(\n            Feature(\n                geometry=Point((long,lat)),\n                properties={\n                    'time': pd.to_datetime(index[0]).__str__(),\n                    'style': {'color' : ''},\n                    'icon': 'circle',\n                    'iconstyle':{\n                            'fillColor': row[fill_color_data],\n                            'fillOpacity': 0.8,\n                            'stroke': 'false',\n                            'radius': row[radius_data]\n                                        }\n                            }\n            ))\n\n    return TmpFeature\n\n# VII- Dual map of covud's cases & deaths:\n\ndef Dual_map(cases = 'cases', deaths = 'deaths'):\n    dualmap = DualMap(location = [40,-102],\n                      zoom_start = 3,\n                      layout = 'horizontal'\n                     )\n\n    TimestampedGeoJson({\n                            'type': 'FeatureCollection',\n                            'features': Create_feature(deaths),\n                            },\n                      period = 'P1M',                  \n                      auto_play = True).add_to(dualmap.m1)\n\n    folium.features.GeoJson(\n        name=state_geo,\n        data=state_geo,\n        show=True,\n        tooltip=folium.features.GeoJsonTooltip(\n        fields=['state'],\n        aliases=['State'],    \n        style=(\"background-color: white; color: #333333; font-family: arial; font-size: 12px; padding: 10px;\") \n                )\n            ).add_to(dualmap.m1)\n\n    folium.plugins.Fullscreen(position='topright', \n                              title='Full Screen of Deaths Data', \n                              title_cancel='Exit Full Screen of Deaths Data', \n                              force_separate_button=False).add_to(dualmap.m1)\n\n    TimestampedGeoJson({\n                            'type': 'FeatureCollection',\n                            'features': Create_feature(cases),\n                            },\n                      period = 'P1M',                  \n                      auto_play = True).add_to(dualmap.m2)\n\n    folium.features.GeoJson(\n        name=state_geo,\n        data=state_geo,\n        show=True,\n        tooltip=folium.features.GeoJsonTooltip(\n        fields=['state'],\n        aliases=['State'],    \n        style=(\"background-color: white; color: #333333; font-family: arial; font-size: 12px; padding: 10px;\") \n                )\n            ).add_to(dualmap.m2)\n\n    folium.plugins.Fullscreen(position='topright', \n                              title='Full Screen of Cases Data', \n                              title_cancel='Exit Full Screen of Deaths Data', \n                              force_separate_button=False).add_to(dualmap.m2)\n\n\n    return dualmap\n\n# VIII - Producsts and Engagement  Index \ndef Prod_vs_engagement():\n    fig = go.Figure()\n    for p in Data_prod['Product Name'].unique() :\n\n        Data = pd.DataFrame(Data_prod[Data_prod['Product Name'] == p])\n\n        Date = [datetime.datetime(int(str(x).split(' ')[0].split('-')[0]),\n                              int(str(x).split(' ')[0].split('-')[1]),\n                              int(str(x).split(' ')[0].split('-')[2])).strftime(\"%b %Y\")\n                              for x in Data.time]\n\n        Data['main_fun'] = Data['main_fun'].str.replace('LC','Learning & Curriculum')\n        Data['main_fun'] = Data['main_fun'].str.replace('CM','Classroom Management')\n        Data['main_fun'] = Data['main_fun'].str.replace('SDO','School & District Operations')\n\n        fig.add_trace(go.Bar(\n            x=Date, \n            y=Data['engagement_index'],\n            name = p,\n            hovertext=\n            \"<b>State:<\/b><i>\" + Data['state'] +\"<\/i>.<br>\"\n            + \"<b>Essential Function:<\/b><i>\" + Data['main_fun'] +\"<\/i>.<br>\",\n            width = 0.2\n                            )\n                     )\n    fig.update_layout(\n        title='Total page-load events per one thousand students per product <br> during 2020',\n        xaxis_tickfont_size=14,\n        xaxis_tickangle=-45,\n        yaxis=dict(\n            title='Engagement Index',\n            titlefont_size=16,\n            tickfont_size=14,\n        ),\n        barmode='group',\n        bargap = 0.2\n    )    \n    return fig.show()","3a368d54":"# Data engagement:\n\n# file name == district_id:\n\nf_n = pd.DataFrame({'district_id':[]})\n\npath = \"..\/input\/learnplatform-covid19-impact-on-digital-learning\"\n\nfor root, dirc ,files in os.walk( path + '\/engagement_data'):\n    for name in files:\n        new = {'district_id': int(name.split('.')[0])}\n        f_n = f_n.append(new, ignore_index = True)\n# the amount of engagement data we have:\nprint(len(f_n.index))\nf_n.head()","99b0fabe":"d_infos = pd.read_csv(path + '\/districts_info.csv')\n\nd_infos = d_infos[d_infos['locale'].isin(['Suburb', 'City', 'Rural', 'Town'])]\n\nd_infos.head()","c9408d62":"d = pd.DataFrame({})\nfor iD in f_n['district_id']:\n    d= d.append(d_infos.loc[d_infos['district_id'] == iD], ignore_index = True)\n\nd = d.dropna()\nd = d.reset_index(drop=True)\nd.tail()","e4245b7b":"columns = d.columns[3:]\n\ncontinuous_data(columns).head()","c6d92ed3":"d_infos_ = pd.DataFrame(\n   continuous_data(columns).groupby(by = ['locale','state'],as_index = False\n                        ).agg('max'))\n\nd_infos_.head() # this is the final data we will procceed with","3d40718c":"d_infos_.describe()","af769f72":"P_infos = pd.read_csv( path + '\/products_info.csv')\n\n# droping duplicates URL & \"nan\" values :\n\nP_infos.drop_duplicates(subset=['URL'], keep='first', inplace = True)\nP_infos = P_infos.dropna()\nP_infos = P_infos.reset_index(drop=True)\n\nP_infos.head()","e6dc0638":"# create columns named : \n# \"main_fun\" = which should be: LC, CM or SDO\n# \"sec_fun\" & \"other\" = which should be sub-categories with\n# which the products were labeled.\n\nmain_fun = []\nsec_fun = []\nother = []\n\nfor fun in P_infos['Primary Essential Function'] : \n    fun = fun.split(\"-\")\n    main_fun.append(fun[0])\n    sec_fun.append(fun[1])\n    if (len(fun)>=3) : other.append(fun[-1])\n    else : other.append(\"no other sub func\")\n\nP_infos['main_fun'] = main_fun\nP_infos['sec_fun'] = sec_fun\nP_infos['other'] = other\n\nP_infos.head()","42ac3162":"P_infos_g = pd.DataFrame(\n    P_infos.groupby(by=['main_fun','sec_fun', 'Sector(s)'], \n                    as_index=False)['LP ID'].count()\n            )\nP_infos_g.tail()","0ecebdc3":"Top_districts = Top_10()\nTop_districts.head()","08ff3669":"Data_prod = pd.DataFrame(Top_districts.groupby(['Product Name',\n                                                Top_districts.time]).apply(\n        lambda x: x.nlargest(1, 'engagement_index')))\nData_prod.head()  ","48d82019":"url = \"https:\/\/raw.githubusercontent.com\/nytimes\/covid-19-data\/master\/us-states.csv\"\ncovid_df = pd.read_csv(url, parse_dates = ['date'])\ncovid_df.drop(['fips'], axis = 1, inplace = True)\n\ncovid_df = covid_df[covid_df['state'].isin(d_infos_.state)].reset_index()\ncovid_df.drop(['index'], axis = 1, inplace = True)\ncovid_df = covid_df[covid_df['date'].isin(pd.date_range(start='2020-01-01', end='2020-12-31'))]\n\ncovid_df.tail()","eaaa8f46":"# Data for Longitude and Latitude :\n\nLon_lat = pd.read_csv('..\/input\/longitude-latitude-world-usa\/longitude_latitude_world_usa.csv')\nLon_lat = Lon_lat[['usa_state_code', 'usa_state_longitude', 'usa_state_latitude', 'usa_state']]\nLon_lat.dropna(subset=['usa_state'], inplace =True)\nLon_lat = Lon_lat.reset_index(drop=True)\nLon_lat = Lon_lat.rename(columns={\"usa_state_longitude\":\"long\",\n                                  \"usa_state_latitude\":\"lat\",\n                                  \"usa_state\":\"state\",\n                                  \"usa_state_code\":\"code\"})\nLon_lat = Lon_lat[Lon_lat['state'].isin(d_infos_.state)].reset_index()\nLon_lat.drop(['index'], axis = 1, inplace = True)\nLon_lat.head()    ","e48e0d63":"# We import the geoJSON file. \nurl = (\"https:\/\/raw.githubusercontent.com\/python-visualization\/folium\/master\/examples\/data\")\nstate_geo = f\"{url}\/us-states.json\"\n\n# We read the file and print it.\ngeoJSON_df = gpd.read_file(state_geo)\ngeoJSON_df = geoJSON_df[['name', 'geometry']]\ngeoJSON_df = geoJSON_df.rename(columns={'name':'state'})\ngeoJSON_df.tail()","aa2de867":"# Group Covid data and the geometry of the corresponding staes:\nstate_geo = geoJSON_df[geoJSON_df['state'].isin(d_infos_.state)].reset_index()\nstate_geo.drop(['index'], axis = 1, inplace = True)\n\nMerge = pd.merge(state_geo, covid_df, on = 'state')\n\nGroup_df = Merge.groupby(by=[pd.Grouper(key='date',freq='M'),\n                  'state']).agg({'cases':'sum',\n                                 'deaths':'sum',\n                                 'geometry':'first'})\n# Customize:\ndef color_function(x, kind):\n    if kind == 'cases' :\n        data_min = Group_df['cases'].min()\n        data_max = Group_df['cases'].max()        \n        y = (x-data_min)\/(data_max-data_min)    \n        color_tuple = YlOrBr(y, bytes=True)[:3]   \n    elif kind == 'deaths' :\n        data_min = Group_df['deaths'].min()\n        data_max = Group_df['deaths'].max()\n        y = (x-data_min)\/(data_max-data_min)    \n        color_tuple = OrRd(y, bytes=True)[:3]   \n    return \"#%02x%02x%02x\" % color_tuple\ndef radius_function(x, kind):\n    if kind == 'cases' :\n        data_min = Group_df['cases'].min()\n        data_max = Group_df['cases'].max()\n        y = (x-data_min)\/(data_max-data_min) + 10 \n    elif kind == 'deaths' :\n        data_min = Group_df['deaths'].min()\n        data_max = Group_df['deaths'].max()          \n        y = (x-data_min)\/(data_max-data_min) + 4\n    return y\nGroup_df['fill color\/cases'] = [color_function(X,'cases') for X in Group_df['cases']]\nGroup_df['fill color\/deaths'] = [color_function(X, 'deaths') for X in Group_df['cases']]\nGroup_df['radius\/cases'] = [radius_function(X,'cases') for X in Group_df['cases']]\nGroup_df['radius\/deaths'] = [radius_function(X, 'deaths') for X in Group_df['cases']]\n\nGroup_df.head()","f6042e81":"# Create sub DataFrame by locale:\n# Cities:\ncity_df = d_infos_[d_infos_['locale'] == 'City']\n# Suburb:\nsuburb_df = d_infos_[d_infos_['locale'] == 'Suburb']\n# Rural : \nrural_df = d_infos_[d_infos_['locale'] == 'Rural']\n# Town :\ntown_df = d_infos_[d_infos_['locale'] == 'Town']\n\n# Create sub geoDataFrame by locale:\n# Geo Cities:\ngeo_city = geoJSON_df[geoJSON_df['state'].isin(city_df['state'])] \n# Geo rural:\ngeo_rural = geoJSON_df[geoJSON_df['state'].isin(rural_df['state'])] \n# Geo subrub:\ngeo_suburb = geoJSON_df[geoJSON_df['state'].isin(suburb_df['state'])] \n# Geo town:\ngeo_town = geoJSON_df[geoJSON_df['state'].isin(town_df['state'])] \n\n# Concatenate all sub data with thier geopandas DF : \nAll = pd.concat([pd.merge(geo_rural, rural_df, on= 'state'),\n                pd.merge(geo_city, city_df, on= 'state'),\n                pd.merge(geo_town, town_df, on= 'state'),\n                pd.merge(geo_suburb, suburb_df, on= 'state')],\n                keys=['Rural','City', 'Town', 'Suburb'] )","e1953645":"Locales = ['City', 'Suburb', 'Town', 'Rural']\nPP_Total_raw_map(Locales)","4041457e":"Dual_map()","22359a8c":"sns.set_theme(style=\"darkgrid\")\n\nLocale = ['Town', 'City', 'Rural', 'Suburb']\n\nfig, axes = plt.subplots(ncols=2, nrows=2, sharey=True, figsize=(10, 9))\n\n\nfor ax, locale in zip(axes.flat, Locale):\n    data = d_infos_[d_infos_['locale']== locale]\n\n    sns.barplot(data= data, x= \"state\", y= \"pp_total_raw\", ax=ax)\n    ax.set_title(locale)\n    xlabels = d_infos_['state'][d_infos_['locale']== locale]\n    ax.set_xticklabels(xlabels, rotation =60)\n    ax.set_ylabel(\"\")\n    ax.set_xlabel(\"\")\n# adjustement :\nfig.suptitle(\"Per-pupil total expenditure per locale\")\nfig.subplots_adjust(hspace = 0.4, wspace = 0.2)\nfig.text(0.3, 0.01, 'state', ha='center')\nfig.text(0.75, 0.0, 'state', ha='center')\nfig.text(0.04, 0.25, 'pp_total_raw', va='center', rotation='vertical')\nfig.text(0.04, 0.75, 'pp_total_raw', va='center', rotation='vertical')\nplt.show()","ecf02e67":"Locale = ['Town', 'City', 'Rural', 'Suburb']\n\nfig, axes = plt.subplots(ncols=2, nrows=2, sharey=True, figsize=(10, 9))\n\n\nfor ax, locale in zip(axes.flat, Locale):\n    data = d_infos_[d_infos_['locale']== locale]\n\n    sns.barplot(data= data, x= \"state\", y= \"pct_black\/hispanic\", ax=ax)\n    ax.set_title(locale)\n    xlabels = d_infos_['state'][d_infos_['locale']== locale]\n    ax.set_xticklabels(xlabels, rotation =60)\n    ax.set_ylabel(\"\")\n    ax.set_xlabel(\"\")\n# adjustement :\nfig.suptitle(\"Percentage of students in the districts identified as Black or Hispanic\")\nfig.subplots_adjust(hspace = 0.4, wspace = 0.2)\nfig.text(0.3, 0.01, 'state', ha='center')\nfig.text(0.75, 0.0, 'state', ha='center')\nfig.text(0.04, 0.25, 'Percentage B\/H (0~1)', va='center', rotation='vertical')\nfig.text(0.04, 0.75, 'Percentage B\/H (0~1)', va='center', rotation='vertical')\nplt.show()","a1386645":"Locale = ['Town', 'City', 'Rural', 'Suburb']\n\nfig, axes = plt.subplots(ncols=2, nrows=2, sharey=True, figsize=(10, 9))\n\n\nfor ax, locale in zip(axes.flat, Locale):\n    data = d_infos_[d_infos_['locale']== locale]\n\n    sns.barplot(data= data, x= \"state\", y= \"pct_free\/reduced\", ax=ax)\n    ax.set_title(locale)\n    xlabels = d_infos_['state'][d_infos_['locale']== locale]\n    ax.set_xticklabels(xlabels, rotation =60)\n    ax.set_ylabel(\"\")\n    ax.set_xlabel(\"\")\n# adjustement :\nfig.suptitle(\"Percentage of students in the districts eligible for free or reduced-price Lunch.\")\nfig.subplots_adjust(hspace = 0.4, wspace = 0.2)\nfig.text(0.3, 0.01, 'state', ha='center')\nfig.text(0.75, 0.0, 'state', ha='center')\nfig.text(0.04, 0.25, 'Percentage F\/R (0~1)', va='center', rotation='vertical')\nfig.text(0.04, 0.75, 'Percentage F\/R (0~1)', va='center', rotation='vertical')\nplt.show()","8645371d":"plt.figure(1)\nsns.swarmplot(x=P_infos_g['Sector(s)'], y=P_infos_g['LP ID'])#, hue=P_infos_g['main_fun'], size= 6)\nplt.xticks(rotation = -45)\nplt.ylabel(\"Product's Count\")\nplt.title(\"The Target Sectors of the products.\")\nplt.show()\n\nplt.figure(2)\nsns.countplot(x=P_infos_g['main_fun'], data=P_infos_g)\nplt.xticks(rotation=90)\nplt.title(\"The Dominant Main Function  of the products.\")\nplt.show()\n\n","a54b6463":"Correlations = []\nfor ID in d_infos_[\"district_id\"]:\n    df = pd.read_csv('..\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data\/' + str(ID) + '.csv',\n                      usecols = [\"pct_access\",\"engagement_index\"])\n    Correlations.append(df.pct_access.corr(df.engagement_index))","78554334":"print(\"The Correlation between The Engagement Index and the Access Percentage is:\" ,np.mean(Correlations))    ","693dae17":"Prod_vs_engagement()","78c7ac6f":"Top_Visual()","39495b24":"np.random.choice(covid_df['state'], 4)\nwords = ['Learning', 'Covid', 'Pendamic', 'USA', 'LEarning Platforme',\n         \" \".join(x for x in np.random.choice(covid_df['state'], 4))+\" \", \n         \" \".join(x for x in np.random.choice(Data_prod['Product Name'], 10))+\" \"]\nwords = \" \".join(x for x in words)+\" \"\nwordcloud = WordCloud(width = 800, height = 800,\n                background_color ='black',\n                min_font_size = 9).generate(words)\nplt.figure(figsize = (8, 8), facecolor = None)\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad = 0)\n \nplt.show() ","4e0db3c1":"## II-D. Statistical description:","76e49f5c":"# Districts Data:","7b934802":"# B. Covid-19 evolution of cases and deaths:","b4735951":"## III-D. Grouping by the features 'main_fun','sec_fun' & 'Sector(s)': ","f9438364":"## II-A. Discription of the data:","08bebbf0":"${\\large{ \\underline{\\textbf{I}}n\\ the\\ Map:\\\\ \\textbf{B\/H}\\ : Percentage\\ of\\ students\\ in\\ the\\ districts\\ identified\\ as\\ Black\\ or\\\\ Hispanic.\\\\ \\textbf{F\/R}:\\ Percentage\\ of\\ students\\ in\\ the\\ districts\\ eligible\\ for\\ or\\ reduced-price\\ lunch.\\\\ \\textbf{C.C.R}:Residential\\ fixed\\ hig\\ speed\\ connection\\ over\\ 200\\ kbps\\ in\\ at\\\\ least\\ one\\ direction\/households.\\\\ \\textbf{PP.T.R}:\\ Per-pupil\\ total\\ expenditure.\n} }$","5acb6f42":"${ \\large{ \\underline{\\textbf{W}}e\\ have\\ \\textbf{233}\\ \\texttt{####.csv} \\ file\\ about\\ \\texttt{engagement_data}.\\\\ \\underline{\\textbf{F}}ortunately\\ w'll\\ not\\ use\\ them\\ all\\ \\underline{\\textbf{J}}ust\\ the\\ files\\ with\\ matching\\ \\textbf{ID}\\\\ of\\ the\\ District\\ in\\ the\\ \\texttt{districts_info.csv}.  }}$","200fd77a":"# B. Percentage of students identified as Black or Hispanic:","34bb4c73":"${ \\large{ \\underline{\\textbf{T}}he\\ have\\ \\texttt{districts_info.csv}\\ are\\ not\\ numeric\\ values.\\ \\underline{\\textbf{S}}o\\ w'll\\\\ convert\\ them\\ by\\ taking\\ the\\ middle\\ valuse\\ for\\ each\\ interval.}}$","358e428d":"${ \\large{ \\underline{\\textbf{I}}n\\ this\\ section\\ w'll\\ use\\ the\\ Covid-19\\ data\\ from}}$ [this source](https:\/\/raw.githubusercontent.com\/nytimes\/covid-19-data\/master\/us-states.csv).","20f39661":"# Products Data:","b9c2b89c":"${ \\large{ \\underline{\\textbf{States Coordinates}} }}$","e94b3288":"# I- Extract all the Districts ID with an engagement data:","d9f69e27":"${ \\large{ \\underline{\\textbf{S}}ince\\ the\\ file\\ name\\ of\\ eacth\\ \\texttt{####.csv}\\ in\\ \\texttt{engagement_data}\\ \\\\ stand\\ for\\ the\\ \\textbf{ID}\\ of\\ the\\ District\\ so\\ w'll\\ extract\\ them\\ for future \\\\ purpose\\ (linked\\ \\texttt{districts_info.csv}\\ with\\ the\\ corresponding \\\\ engagement\\_data).  }}$","daee7a8e":"${\\large{ \\underline{\\textbf{A}}bout\\ the \\ data\\ used\\ here, \\ specifically\\ the\\ \\texttt{geojson}\\ one\\ check:\\ }}$[this](http:\/\/raw.githubusercontent.com\/python-visualization\/folium\/master\/examples\/data\/us-states.json).","449eecd4":"# IV- Engagement Data:","77969e91":"| Name | Description |\n| :--- | :----------- |\n| time | date in \"YYYY-MM-DD\" |\n| lp_id | The unique identifier of the product |\n| pct_access | Percentage of students in the district have at least one page-load event of a given product and on a given day |\n| engagement_index | Total page-load events per one thousand students of a given product and on a given day |","42fa2687":"# III- Products informations :","694a82bc":"${ \\large{ \\underline{\\textbf{T}}his\\ last\\ data\\ \\texttt{P_infos_g}\\ is\\ helpful\\ in\\ figuring\\ the\\ sectors\\ targets\\\\ of\\ these\\ \\underline{\\textbf{P}}roducts\\ and\\ thier\\ famous\\  Primary Essential Function.}}$","1ee9a7b2":"# II- Chart Visualization :","9aa292da":"# Libraries","6cd9bc27":"${\\large{ \\underline{\\textbf{Note}}:\\\\ \\hspace{0.5 cm} The\\ right\\ map\\ for\\ Cases\\ Data.\\ And\\ the\\ left\\ one\\ for\\ Deaths\\ Data.}}$","2b1f0c21":"${ \\large{ \\underline{\\textbf{Processing}}\\ Covid\\ data.\\ W'll\\ associate\\ a\\ geometry\\ for\\ each\\ state.\\ And\\ w'll\\ explore\\ the\\ Coordinates\\ of\\ the\\ us states.\\ For\\ the\\ resource\\ check\\ this:\\  }}$ [Geaometry us Data](http:\/\/raw.githubusercontent.com\/python-visualization\/folium\/master\/examples\/data\/us-states.json)\n\n[State Coordinates](https:\/\/www.kaggle.com\/delendaanouarakacha\/longitude-latitude-world-usa?select=longitude_latitude_world_usa.csv).","67f3c469":"# II- Districts informations data:","37242173":"## III-A. Discription of the data:","6c0761c1":"${ \\large{ \\underline{\\textbf{Why}}\\ Engagement\\ index\\ and\\ not\\ Percentage\\ of\\ access?\\\\  \\underline{\\textbf{So}}\\ far\\ the\\ engagement\\ index\\ is\\ little\\ correlated\\ with\\ the\\ access\\ percentage.}}$","6d6fa0c4":"# LearnPlatform COVID-19 Impact on Digital Learning\n${\\large{ In \\ this\\ Notebook\\ You \\ Will \\ go \\ through\\ an\\ analysis\\ of\\ US\\\\ Data \\ about\\ the \\ impact\\ of\\ Covid\\ on \\ Digital\\ Learning.\\\\ Step\\ by\\ step \\ I \\ wish\\ you \\ good\\ time \\ while\\ you\\ scrolling\\ down\\\\ to\\ the\\ end\\ of\\ this \\ notebook. \\\\}}$","755209f3":"## II-B. Districts informations data that have engagement data:","ed51af83":"# Engagement Data (Per Districts and Locales):","982e6414":"## IV-A. Description of the data:","cdcf7f9e":"${ \\large{ \\underline{\\textbf{Grouped Data}}:\\ Customize\\ the\\ color\\ of\\ cases \\ and\\ deaths\\ values\\\\ and\\ add\\ a\\ radius\\ features.}}$","02e6c0d0":"# A. Districts and thiere informations:","abb02d91":"${ \\large{ \\underline{\\textbf{States Geometries}} }}$","208a8f52":"# I- Geographical Visualization:","11a785b9":"| Name | Description |\n| :--- | :----------- |\n| LP ID| The unique identifier of the product |\n| URL | Web Link to the specific product |\n| Product Name | Name of the specific product |\n| Provider\/Company Name | Name of the product provider |\n| Sector(s) | Sector of education where the product is used |\n| Primary Essential Function | The basic function of the product. There are two layers of labels here. Products are first labeled as one of these three categories: LC = Learning & Curriculum, CM = Classroom Management, and SDO = School & District Operations. Each of these categories have multiple sub-categories with which the products were labeled. |","1d7b59ab":"## III-C. Slicing the Primary Essential Function feature of the data to \"main\", \"sec\" & \"others\":","deefa2fe":"${\\large{ In \\ this\\ section\\ we\\ import\\ the\\ necessary\\ libraries. \\\\}}$","e6383c9c":"| Name | Description |\n| :--- | :----------- |\n| district_id | The unique identifier of the school district |\n| state | The state where the district resides in |\n| locale | NCES locale classification that categorizes U.S. territory into four types of areas: City, Suburban, Town, and Rural.|\n| pct_black\/hispanic | Percentage of students in the districts identified as Black or Hispanic based on 2018-19 NCES data |\n| pct_free\/reduced | Percentage of students in the districts eligible for free or reduced-price lunch based on 2018-19 NCES data |\n| county_connections_ratio | `ratio` (residential fixed high-speed connections over 200 kbps in at least one direction\/households) based on the county level data from FCC From 477 (December 2018 version).|\n| pp_total_raw | Per-pupil total expenditure (sum of local and federal expenditure) from Edunomics Lab's National Education Resource Database on Schools (NERD$) project.|","f40a1681":"# Handling the data (District informations, Engagement & Products Data):","1b54714a":"# Visualization :","3d23a095":"# Useful Functions","694edc07":"## II-C. Group by locale and \"max pp_total_raw\" :","6e11721c":"$\\large{ \\underline{\\textbf{Note:}}\\ that\\ not\\ all\\ engagement\\ data\\ are\\ mentioned\\\\ in\\ the\\ file:\\texttt{districts_info.csv} }$","52e99ee9":"# # C. Percentage of students in the districts eligible for free or reduced-price Lunch:","7d8d4aef":"# V- Covid-19 Data:","8b8acf44":"## IV-B. Top districts with a higher engagement index products per month :","245d942f":"# A. Per-pupil total expenditure per locale :","0c8620fe":"## IV-C. Top products with a higher engagement index per month for a districts:","599b8228":"## III-B. Cleaning Data:","76f43ae9":"${\\large{ In \\ this\\ section\\ we\\ write \\ down \\ some Function\\ to\\ reduce \\ the \\ amout\\\\ of\\ coding. \\\\}}$\n","b8f8641e":"# Thank you For Reaching to this Point of the Notebook.","32993a6d":"# A. Sectors as target and The Dominant Main Functionality:","9afcfd87":"# B. Product and Engagement Index:"}}