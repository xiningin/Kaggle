{"cell_type":{"8903928b":"code","9f08b608":"code","920b3b27":"code","736559dc":"code","1f54268f":"code","1baf05e4":"code","27fede65":"code","1170c473":"code","f0f43e4b":"code","3203f6b2":"code","dd05f530":"code","897e632c":"code","896ad427":"code","150c4d14":"code","20bc2f59":"code","deffb43b":"code","b2e3126b":"code","081d6dde":"code","1e5444f1":"code","6bdf7676":"code","a777c983":"code","bfe3e640":"code","60fb91d0":"code","3eeb6988":"code","afaa2e5f":"code","d8a30f43":"code","93ec3d95":"code","4c26254a":"code","3aaa37bb":"code","e295af8d":"code","85ccd13c":"code","3911bc5b":"code","9d8b4461":"code","3700a628":"code","4c0ae5ab":"code","496d90b4":"code","09fb0c70":"code","8b762233":"code","58458d61":"code","62ca35e6":"code","15a99ed9":"code","cad463ac":"code","df342a67":"code","f1369db5":"code","bdc48252":"code","ba4d4ca3":"code","eba61c02":"code","481a7642":"code","0fbe469d":"code","deae5e37":"code","1c968cb2":"code","1fc6fe6d":"code","d694a414":"code","e30b9eb0":"code","e032d776":"code","b9c0c7fb":"code","ad437e34":"code","581fcd0e":"code","7d70ce8d":"code","e0971880":"code","6c81db11":"code","56184492":"code","eed22fea":"code","0e6b345d":"code","9d2a045d":"code","db87a01c":"code","f3355228":"code","6c0f4de2":"code","deeffd75":"code","bb70e616":"code","409cebcf":"code","745b1cc0":"code","b0318ee7":"code","dea67c9b":"code","86411b29":"code","a0603e37":"code","4c37fad5":"code","4497e6bc":"code","1b8ddb8d":"code","9185e03b":"code","21d57c88":"code","85bae409":"code","5476a881":"code","f8d39578":"code","edcf57f1":"code","00ae6a72":"code","ab4b45d3":"code","b2803382":"code","e5430fc9":"code","c33ed67f":"code","c93802bf":"code","2201aa7e":"code","37edbc01":"code","48dc221a":"code","35a46f2d":"code","8e047098":"code","be98d9c3":"code","a0a55fd3":"code","f0081c59":"code","b7ecdefe":"code","6c2ea708":"code","b24f8247":"code","04defbf6":"code","b9b92aa3":"code","d333c8b4":"code","54d0ecb1":"code","b0307cb1":"code","fe4ec0f8":"code","b78bc529":"code","ec48224f":"code","8b13c5e1":"code","989803fe":"code","0a7acf23":"code","be7b48eb":"code","c466efd7":"code","3fafb81e":"code","af62ff76":"code","ad1e1f00":"code","a87f0a89":"code","1eea8be7":"code","274281aa":"code","880faadb":"code","43f47db3":"code","e7ceefa9":"code","cac97ffe":"code","92de6709":"code","3f2ea7c3":"code","11a653e4":"markdown","475cc231":"markdown","a0243ce9":"markdown","173b021c":"markdown","8077b7a1":"markdown","32d32db3":"markdown","feb957ec":"markdown","1bec4576":"markdown","5f099410":"markdown","3574bb6a":"markdown","08911740":"markdown","87ece04c":"markdown","1068dfab":"markdown","39d27dd9":"markdown","231d4798":"markdown","67127d87":"markdown","72979b40":"markdown","b00f350b":"markdown","e4ca7874":"markdown","1ba577fa":"markdown","1b658f78":"markdown","4b6e0fb0":"markdown","fa7f3bf1":"markdown","f3088e7f":"markdown","50b73da9":"markdown","a5a04065":"markdown","4cb926d5":"markdown","1938f56b":"markdown","0375c20f":"markdown","2b7b5ab2":"markdown","092fe6c2":"markdown","c4c4fac4":"markdown","62ed7cb2":"markdown","48da6edb":"markdown","159aa3ed":"markdown","4aa16989":"markdown","7611f185":"markdown","01411570":"markdown","24ef7117":"markdown","88b3e1df":"markdown","a5a67d49":"markdown","a47a03ae":"markdown","23af411d":"markdown","014ceee0":"markdown","278ab93b":"markdown","a7d80590":"markdown","1ee367ef":"markdown","2a4c5968":"markdown","27d3c708":"markdown","6a90bd07":"markdown","f2a38566":"markdown","5a0d0bfb":"markdown","9575db95":"markdown","cd491711":"markdown","1d80a244":"markdown","b25dfce2":"markdown","3c31ec5b":"markdown","922066f4":"markdown","4cdc7420":"markdown","055b2787":"markdown","bb28c054":"markdown","a21a722d":"markdown","e82651ea":"markdown","56df5907":"markdown","7959c01e":"markdown","48065c23":"markdown","73c0ad27":"markdown","ae9b48bf":"markdown","f670ec3c":"markdown","017acb3f":"markdown","b8d14e4d":"markdown","37035c27":"markdown","de13beff":"markdown","2ff717c1":"markdown","6cd6d965":"markdown","597746b7":"markdown","f537ab1c":"markdown","7b469e86":"markdown","483d9160":"markdown","6e0730d6":"markdown","98e2f8b6":"markdown","9ee2c2fd":"markdown","383748b8":"markdown","e3bb1135":"markdown","05a9ec30":"markdown"},"source":{"8903928b":"#Libraries\nimport numpy as np\nimport plotly.express as px\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport pandas as pd\npd.set_option('max_columns', None)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\nimport ast\nfrom wordcloud import WordCloud\nfrom collections import Counter\nfrom PIL import Image\nfrom urllib.request import urlopen\nfrom sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, RandomizedSearchCV\nfrom sklearn.linear_model import LinearRegression,Lasso, Ridge\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport warnings\nwarnings.filterwarnings(\"ignore\")","9f08b608":"train = pd.read_csv('..\/input\/tmdb-box-office-prediction\/train.csv')\ntest = pd.read_csv('..\/input\/tmdb-box-office-prediction\/test.csv')\n\ndict_columns = ['belongs_to_collection','genres','spoken_languages','production_companies',\n                'production_countries','Keywords','cast','crew']\n\ndef text_to_dict(df):\n    for columns in dict_columns:\n        df[columns] = df[columns].apply(lambda x: {} if pd.isna(x) else ast.literal_eval(x))\n    return df\n\ntrain = text_to_dict(train)\ntest = text_to_dict(test)\n\ntest['revenue'] = np.nan\n\n# features from https:\/\/www.kaggle.com\/kamalchhirang\/eda-simple-feature-engineering-external-data\n# Aditional Features\ntrain = pd.merge(train, pd.read_csv('..\/input\/tmdb-competition-additional-features\/TrainAdditionalFeatures.csv'), how='left', on=['imdb_id'])\ntest = pd.merge(test, pd.read_csv('..\/input\/tmdb-competition-additional-features\/TestAdditionalFeatures.csv'), how='left', on=['imdb_id'])\n\ntrain.head(2)","920b3b27":"train.shape , test.shape","736559dc":"# Data Fixes from https:\/\/www.kaggle.com\/somang1418\/happy-valentines-day-and-keep-kaggling-3\n\ntrain.loc[train['id'] == 16,'revenue'] = 192864          # Skinning\ntrain.loc[train['id'] == 90,'budget'] = 30000000         # Sommersby          \ntrain.loc[train['id'] == 118,'budget'] = 60000000        # Wild Hogs\ntrain.loc[train['id'] == 149,'budget'] = 18000000        # Beethoven\ntrain.loc[train['id'] == 313,'revenue'] = 12000000       # The Cookout \ntrain.loc[train['id'] == 451,'revenue'] = 12000000       # Chasing Liberty\ntrain.loc[train['id'] == 464,'budget'] = 20000000        # Parenthood\ntrain.loc[train['id'] == 470,'budget'] = 13000000        # The Karate Kid, Part II\ntrain.loc[train['id'] == 513,'budget'] = 930000          # From Prada to Nada\ntrain.loc[train['id'] == 797,'budget'] = 8000000         # Welcome to Dongmakgol\ntrain.loc[train['id'] == 819,'budget'] = 90000000        # Alvin and the Chipmunks: The Road Chip\ntrain.loc[train['id'] == 850,'budget'] = 90000000        # Modern Times\ntrain.loc[train['id'] == 1007,'budget'] = 2              # Zyzzyx Road \ntrain.loc[train['id'] == 1112,'budget'] = 7500000        # An Officer and a Gentleman\ntrain.loc[train['id'] == 1131,'budget'] = 4300000        # Smokey and the Bandit   \ntrain.loc[train['id'] == 1359,'budget'] = 10000000       # Stir Crazy \ntrain.loc[train['id'] == 1542,'budget'] = 1              # All at Once\ntrain.loc[train['id'] == 1570,'budget'] = 15800000       # Crocodile Dundee II\ntrain.loc[train['id'] == 1571,'budget'] = 4000000        # Lady and the Tramp\ntrain.loc[train['id'] == 1714,'budget'] = 46000000       # The Recruit\ntrain.loc[train['id'] == 1721,'budget'] = 17500000       # Cocoon\ntrain.loc[train['id'] == 1865,'revenue'] = 25000000      # Scooby-Doo 2: Monsters Unleashed\ntrain.loc[train['id'] == 1885,'budget'] = 12             # In the Cut\ntrain.loc[train['id'] == 2091,'budget'] = 10             # Deadfall\ntrain.loc[train['id'] == 2268,'budget'] = 17500000       # Madea Goes to Jail budget\ntrain.loc[train['id'] == 2491,'budget'] = 6              # Never Talk to Strangers\ntrain.loc[train['id'] == 2602,'budget'] = 31000000       # Mr. Holland's Opus\ntrain.loc[train['id'] == 2612,'budget'] = 15000000       # Field of Dreams\ntrain.loc[train['id'] == 2696,'budget'] = 10000000       # Nurse 3-D\ntrain.loc[train['id'] == 2801,'budget'] = 10000000       # Fracture\ntrain.loc[train['id'] == 335,'budget'] = 2 \ntrain.loc[train['id'] == 348,'budget'] = 12\ntrain.loc[train['id'] == 470,'budget'] = 13000000 \ntrain.loc[train['id'] == 513,'budget'] = 1100000\ntrain.loc[train['id'] == 640,'budget'] = 6 \ntrain.loc[train['id'] == 696,'budget'] = 1\ntrain.loc[train['id'] == 797,'budget'] = 8000000 \ntrain.loc[train['id'] == 850,'budget'] = 1500000\ntrain.loc[train['id'] == 1199,'budget'] = 5 \ntrain.loc[train['id'] == 1282,'budget'] = 9               # Death at a Funeral\ntrain.loc[train['id'] == 1347,'budget'] = 1\ntrain.loc[train['id'] == 1755,'budget'] = 2\ntrain.loc[train['id'] == 1801,'budget'] = 5\ntrain.loc[train['id'] == 1918,'budget'] = 592 \ntrain.loc[train['id'] == 2033,'budget'] = 4\ntrain.loc[train['id'] == 2118,'budget'] = 344 \ntrain.loc[train['id'] == 2252,'budget'] = 130\ntrain.loc[train['id'] == 2256,'budget'] = 1 \ntrain.loc[train['id'] == 2696,'budget'] = 10000000\n\n#Clean Data\ntest.loc[test['id'] == 6733,'budget'] = 5000000\ntest.loc[test['id'] == 3889,'budget'] = 15000000\ntest.loc[test['id'] == 6683,'budget'] = 50000000\ntest.loc[test['id'] == 5704,'budget'] = 4300000\ntest.loc[test['id'] == 6109,'budget'] = 281756\ntest.loc[test['id'] == 7242,'budget'] = 10000000\ntest.loc[test['id'] == 7021,'budget'] = 17540562       #  Two Is a Family\ntest.loc[test['id'] == 5591,'budget'] = 4000000        # The Orphanage\ntest.loc[test['id'] == 4282,'budget'] = 20000000       # Big Top Pee-wee\ntest.loc[test['id'] == 3033,'budget'] = 250 \ntest.loc[test['id'] == 3051,'budget'] = 50\ntest.loc[test['id'] == 3084,'budget'] = 337\ntest.loc[test['id'] == 3224,'budget'] = 4  \ntest.loc[test['id'] == 3594,'budget'] = 25  \ntest.loc[test['id'] == 3619,'budget'] = 500  \ntest.loc[test['id'] == 3831,'budget'] = 3  \ntest.loc[test['id'] == 3935,'budget'] = 500  \ntest.loc[test['id'] == 4049,'budget'] = 995946 \ntest.loc[test['id'] == 4424,'budget'] = 3  \ntest.loc[test['id'] == 4460,'budget'] = 8  \ntest.loc[test['id'] == 4555,'budget'] = 1200000 \ntest.loc[test['id'] == 4624,'budget'] = 30 \ntest.loc[test['id'] == 4645,'budget'] = 500 \ntest.loc[test['id'] == 4709,'budget'] = 450 \ntest.loc[test['id'] == 4839,'budget'] = 7\ntest.loc[test['id'] == 3125,'budget'] = 25 \ntest.loc[test['id'] == 3142,'budget'] = 1\ntest.loc[test['id'] == 3201,'budget'] = 450\ntest.loc[test['id'] == 3222,'budget'] = 6\ntest.loc[test['id'] == 3545,'budget'] = 38\ntest.loc[test['id'] == 3670,'budget'] = 18\ntest.loc[test['id'] == 3792,'budget'] = 19\ntest.loc[test['id'] == 3881,'budget'] = 7\ntest.loc[test['id'] == 3969,'budget'] = 400\ntest.loc[test['id'] == 4196,'budget'] = 6\ntest.loc[test['id'] == 4221,'budget'] = 11\ntest.loc[test['id'] == 4222,'budget'] = 500\ntest.loc[test['id'] == 4285,'budget'] = 11\ntest.loc[test['id'] == 4319,'budget'] = 1\ntest.loc[test['id'] == 4639,'budget'] = 10\ntest.loc[test['id'] == 4719,'budget'] = 45\ntest.loc[test['id'] == 4822,'budget'] = 22\ntest.loc[test['id'] == 4829,'budget'] = 20\ntest.loc[test['id'] == 4969,'budget'] = 20\ntest.loc[test['id'] == 5021,'budget'] = 40 \ntest.loc[test['id'] == 5035,'budget'] = 1 \ntest.loc[test['id'] == 5063,'budget'] = 14 \ntest.loc[test['id'] == 5119,'budget'] = 2 \ntest.loc[test['id'] == 5214,'budget'] = 30 \ntest.loc[test['id'] == 5221,'budget'] = 50 \ntest.loc[test['id'] == 4903,'budget'] = 15\ntest.loc[test['id'] == 4983,'budget'] = 3\ntest.loc[test['id'] == 5102,'budget'] = 28\ntest.loc[test['id'] == 5217,'budget'] = 75\ntest.loc[test['id'] == 5224,'budget'] = 3 \ntest.loc[test['id'] == 5469,'budget'] = 20 \ntest.loc[test['id'] == 5840,'budget'] = 1 \ntest.loc[test['id'] == 5960,'budget'] = 30\ntest.loc[test['id'] == 6506,'budget'] = 11 \ntest.loc[test['id'] == 6553,'budget'] = 280\ntest.loc[test['id'] == 6561,'budget'] = 7\ntest.loc[test['id'] == 6582,'budget'] = 218\ntest.loc[test['id'] == 6638,'budget'] = 5\ntest.loc[test['id'] == 6749,'budget'] = 8 \ntest.loc[test['id'] == 6759,'budget'] = 50 \ntest.loc[test['id'] == 6856,'budget'] = 10\ntest.loc[test['id'] == 6858,'budget'] =  100\ntest.loc[test['id'] == 6876,'budget'] =  250\ntest.loc[test['id'] == 6972,'budget'] = 1\ntest.loc[test['id'] == 7079,'budget'] = 8000000\ntest.loc[test['id'] == 7150,'budget'] = 118\ntest.loc[test['id'] == 6506,'budget'] = 118\ntest.loc[test['id'] == 7225,'budget'] = 6\ntest.loc[test['id'] == 7231,'budget'] = 85\ntest.loc[test['id'] == 5222,'budget'] = 5\ntest.loc[test['id'] == 5322,'budget'] = 90\ntest.loc[test['id'] == 5350,'budget'] = 70\ntest.loc[test['id'] == 5378,'budget'] = 10\ntest.loc[test['id'] == 5545,'budget'] = 80\ntest.loc[test['id'] == 5810,'budget'] = 8\ntest.loc[test['id'] == 5926,'budget'] = 300\ntest.loc[test['id'] == 5927,'budget'] = 4\ntest.loc[test['id'] == 5986,'budget'] = 1\ntest.loc[test['id'] == 6053,'budget'] = 20\ntest.loc[test['id'] == 6104,'budget'] = 1\ntest.loc[test['id'] == 6130,'budget'] = 30\ntest.loc[test['id'] == 6301,'budget'] = 150\ntest.loc[test['id'] == 6276,'budget'] = 100\ntest.loc[test['id'] == 6473,'budget'] = 100\ntest.loc[test['id'] == 6842,'budget'] = 30\n","1f54268f":"pd.DataFrame(train.skew().sort_values(ascending=False)).head(10)","1baf05e4":"pd.DataFrame(train.kurtosis().sort_values(ascending=False)).head(10)","27fede65":"train['popularity'] = np.log1p(train['popularity'])   #log(1+x)  #expm1 - inverse\ntrain['revenue'] = np.log1p(train['revenue'])\ntrain['totalVotes'] = np.log1p(train['totalVotes'])\ntrain['budget'] = np.log1p(train['budget'])\ntrain['runtime'] = np.log1p(train['runtime'])\ntrain['popularity2'] = np.log1p(train['popularity2'])\n\ntest['popularity'] = np.log1p(test['popularity'])  \ntest['totalVotes'] = np.log1p(test['totalVotes'])\ntest['budget'] = np.log1p(test['budget'])\ntest['runtime'] = np.log1p(test['runtime'])\ntest['popularity2'] = np.log1p(test['popularity2'])","1170c473":"for i,e in enumerate(train['belongs_to_collection'][:2]):\n    print(i,e)","f0f43e4b":"train['belongs_to_collection'].apply(lambda x: 1 if x!= {} else 0).value_counts()","3203f6b2":"train['has_collection'] = train['belongs_to_collection'].apply(lambda x: len(x) if x!={} else 0)\ntest['has_collection'] = test['belongs_to_collection'].apply(lambda x: len(x) if x!={} else 0)","dd05f530":"train.sample(2)","897e632c":"for i,e in enumerate(train['genres'][:2]):\n    print(i,e)","896ad427":"print('Number of genres in films:')\ntrain['genres'].apply(lambda x: len(x) if x!={} else 0).value_counts()","150c4d14":"list_of_genres = list(train['genres'].apply(lambda x: [i['name'] for i in x] if x!={} else []).values)","20bc2f59":"plt.figure(figsize=(12,8))\ntext = ' '.join(i for j in list_of_genres for i in j)\nwordcloud = WordCloud(max_font_size = None, width = 1200, height = 1000,\n                      collocations =False).generate(text)\nplt.imshow(wordcloud)\nplt.title('Top Genres')\nplt.axis('off')\nplt.show()","deffb43b":"Counter([i for j in list_of_genres for i in j]).most_common(10)","b2e3126b":"top_genres =[m[0] for m in Counter([i for j in list_of_genres for i in j]).most_common(10)]\nprint(top_genres)","081d6dde":"train['num_of_genres'] = train['genres'].apply(lambda x: len(x) if x!={} else 0)\ntrain['all_genres'] = train['genres'].apply(lambda x: ' '.join(sorted([i['name'] for i in x ])) \n                                           if x!= {} else '')\ntest['num_of_genres'] = test['genres'].apply(lambda x: len(x) if x!={} else 0)\ntest['all_genres'] = test['genres'].apply(lambda x: ' '.join(sorted([i['name'] for i in x ])) \n                                           if x!= {} else '')","1e5444f1":"for g in top_genres:\n    train['genre_' + g] = train['all_genres'].apply(lambda x: 1 if g in x else 0)\n    test['genre_' + g] = test['all_genres'].apply(lambda x: 1 if g in x else 0)","6bdf7676":"for i,e in enumerate(train['production_companies'][:2]):\n    print(i,e)","a777c983":"print('Number of Production Companies for a movie:')\ntrain['production_companies'].apply(lambda x: len(x) if x!= {} else 0).value_counts()","bfe3e640":"train[train['production_companies'].apply(lambda x: len(x) if x!= {} else 0) > 10]","60fb91d0":"list_of_companies = list(train['production_companies'].apply(lambda x : [i['name'] for i in x] \n                                                            if x!= {} else []).values)\nCounter(i for j in list_of_companies for i in j).most_common(20)","3eeb6988":"train['num_prod_companies'] = train['production_companies'].apply(lambda x: len(x) if\n                                                                 x!={} else 0)\ntest['num_prod_companies'] = test['production_companies'].apply(lambda x: len(x) if \n                                                               x!={} else 0)\ntrain['all_prod_companies'] = train['production_companies'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x!={} else '' )\ntest['all_prod_companies'] = test['production_companies'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x!={} else '')","afaa2e5f":"top_prod_companies = [m[0] for m in Counter(i for j in list_of_companies for i in j).most_common(10)]\nfor pc in top_prod_companies:\n    train['production_' + pc] = train['all_prod_companies'].apply(lambda x: 1 if pc in x else 0)\n    test['production_'+ pc] = test['all_prod_companies'].apply(lambda x: 1 if pc in x else 0)","d8a30f43":"for i, e in enumerate(train['production_countries'][:2]):\n    print(i,e)","93ec3d95":"print('Number of Production Countries in Movies:')\ntrain['production_countries'].apply(lambda x: len(x) if x!={} else 0).value_counts()","4c26254a":"train[train['production_countries'].apply(lambda x: len(x) if x!= {} else 0) > 5]","3aaa37bb":"List_of_countries = list(train['production_countries'].apply(lambda x: [i['name'] for i in x] \n                                                             if x!= {} else []))\n#Count of production countries in movies\nCounter(i for j in List_of_countries for i in j).most_common(10)","e295af8d":"train['num_prod_countries'] = train['production_countries'].apply(lambda x: len(x) if x!= {} \n                                                                  else 0)\ntest['num_prod_countries'] = test['production_countries'].apply(lambda x: len(x) if x!={}\n                                                               else 0)\ntrain['all_prod_countries'] = train['production_countries'].apply(lambda x: ' '.join(sorted(i['name'] for i in x))\n                                                                 if x!= {} else '')\ntest['all_prod_countries'] = test['production_countries'].apply(lambda x: ' '.join(sorted(i['name'] for i in x))\n                                                               if x!= {} else '')\n","85ccd13c":"top_prod_countries = [m[0] for m in Counter(i for j in List_of_countries for i in j).most_common(6)]\nfor t in top_prod_countries:\n    train['prod_country_' + t] = train['all_prod_countries'].apply(lambda x: 1 if t in x else 0)\n    test['prod_country_'+ t] = test['all_prod_countries'].apply(lambda x: 1 if t in x else 0)","3911bc5b":"for i, e in enumerate(train['spoken_languages'][:2]):\n    print(i,e)","9d8b4461":"print('Number of languages for a movie:')\ntrain['spoken_languages'].apply(lambda x: len(x) if x!={} else 0).value_counts()","3700a628":"list_of_langs = list(train['spoken_languages'].apply(lambda x: [i['name'] for i in x]\n                                                    if x!= {} else []))\ntop_langs = [m[0] for m in Counter(i for j in list_of_langs for i in j).most_common(5)]\nCounter(i for j in list_of_langs for i in j).most_common(5)","4c0ae5ab":"train['num_of_langs'] = train['spoken_languages'].apply(lambda x: len(x) if x!= {} else 0)\ntest['num_of_langs'] = test['spoken_languages'].apply(lambda x: len(x) if x!= {} else 0)\n\ntrain['all_langs'] = train['spoken_languages'].apply(lambda x: ' '.join(sorted([i['name']for i in x]))\n                                                    if x!= {} else '')\ntest['all_langs'] = test['spoken_languages'].apply(lambda x: ' '.join(sorted([i['name'] for i in x]))\n                                                  if x!= {} else '')\n\nfor l in top_langs:\n    train['lang_' + l] = train['all_langs'].apply(lambda x: 1 if l in x else 0)\n    test['lang_'+ l] = test['all_langs'].apply(lambda x: 1 if l in x else 0)","496d90b4":"plt.figure(figsize=(12,8))\ntext2 = ' '.join(i for j in list_of_langs for i in j)\nwordcloud2 = WordCloud(collocations=False).generate(text2)\nplt.imshow(wordcloud2)\nplt.axis('off')\nplt.title('Top Spoken Languages in Movies')\nplt.show()","09fb0c70":"for i, e in enumerate(train['Keywords'][:2]):\n    print(i,e)","8b762233":"list_of_keys = list(train['Keywords'].apply(lambda x: [i['name'] for i in x] if x!= {} else []))\nCounter(i for j in list_of_keys for i in j).most_common(10)","58458d61":"top_keywords = [m[0] for m in Counter(i for j in list_of_keys for i in j).most_common(10)]\ntrain['num_of_keywords'] = train['Keywords'].apply(lambda x: len(x) if x!={} else 0)\ntest['num_of_keywords'] = test['Keywords'].apply(lambda x: len(x) if x!={} else 0)\n\ntrain['all_keywords'] = train['Keywords'].apply(lambda x: ' '.join(sorted([i['name']for i in x]))\n                                               if x!= {} else '')\ntest['all_keywords'] = test['Keywords'].apply(lambda x: ' '.join(sorted([i['name'] for i in x]))\n                                             if x!={} else '')\nfor k in top_keywords:\n    train['keyword_'+ k] = train['all_keywords'].apply(lambda x: 1 if k in x else 0)\n    test['keyword_'+ k] = test['all_keywords'].apply(lambda x: 1 if k in x else 0)\n","62ca35e6":"plt.figure(figsize=(12,10))\ntext3 = ' '.join(['_'.join(i.split(' ')) for j in list_of_keys for i in j])\nwordcloud3 = WordCloud(collocations = False).generate(text3)\nplt.imshow(wordcloud3)\nplt.title('Top Keywords')\nplt.axis('off')\nplt.show()","15a99ed9":"for i, e in enumerate(train['cast'][:1]):\n    print(i,e)","cad463ac":"print('Number of casts used per movie:')\ntrain['cast'].apply(lambda x: len(x) if x!={} else 0).value_counts().head(10)","df342a67":"list_cast_name = list(train['cast'].apply(lambda x: [i['name'] for i in x]if x!= {} else []))\ntop_cast_name = [m[0] for m in Counter(i for j in list_cast_name for i in j).most_common(20)]\nCounter(i for j in list_cast_name for i in j).most_common(20)","f1369db5":"train['num_of_cast']= train['cast'].apply(lambda x: len(x) if x!={} else 0)\ntest['num_of_cast'] = test['cast'].apply(lambda x: len(x) if x!={} else 0)\n\ntrain['all_cast_name'] = train['cast'].apply(lambda x: ' '.join(sorted([i['name']for i in x]))\n                                             if x!={} else '')\ntest['all_cast_name'] = test['cast'].apply(lambda x: ' '.join(sorted([i['name']for i in x]))\n                                          if x!= {} else '')\nfor c in top_cast_name:\n    train['cast_name_'+ c]= train['all_cast_name'].apply(lambda x: 1 if c in x else 0)\n    test['cast_name_'+ c]= test['all_cast_name'].apply(lambda x: 1 if c in x else 0)","bdc48252":"for i,e in enumerate(train['crew'][:1]):\n    print(i,e)","ba4d4ca3":"print('Number of crew members per movie:')\ntrain['crew'].apply(lambda x: len(x) if x!= {} else 0).value_counts().head(10)","eba61c02":"list_crew_names = list(train['crew'].apply(lambda x: [i['name'] for i in x] if x!= {} else []).values)\nCounter(i for j in list_crew_names for i in j).most_common(15)","481a7642":"top_crew_names = [m[0] for m in Counter(i for j in list_crew_names for i in j).most_common(20)]\ntrain['num_of_crew'] = train['crew'].apply(lambda x: len(x) if x!= {} else 0)\ntest['num_of_crew']= test['crew'].apply(lambda x: len(x) if x!= {} else 0)\nfor cn in top_crew_names:\n    train['crew_name_'+ cn]= train['crew'].apply(lambda x: 1 if cn in str(x) else 0)\n    test['crew_name_'+ cn] = test['crew'].apply(lambda x: 1 if cn in str(x) else 0)","0fbe469d":"train['homepage'].isna().sum()","deae5e37":"train['has_homepage'] = 1\ntrain.loc[pd.isnull(train['homepage']) ,\"has_homepage\"] = 0\ntest['has_homepage'] = 1\ntest.loc[pd.isnull(test['homepage']) ,\"has_homepage\"] = 0","1c968cb2":"train['runtime'].isna().sum()","1fc6fe6d":"train['runtime'].fillna(train['runtime'].mean(),inplace= True)","d694a414":"test['runtime'].fillna(test['runtime'].mean(),inplace= True)","e30b9eb0":"fig, ax = plt.subplots(figsize = (12,5))\nsns.set()\nplt.subplot(1,2,1)\nplt.hist(np.expm1(train['revenue']), bins =10)\nplt.title('Distribution of revenue',fontsize=15)\nplt.subplot(1,2,2)\nplt.hist(train['revenue'], bins =10) \nplt.title('Distribution of log revenue', fontsize=15)","e032d776":"fig, ax = plt.subplots(figsize = (14,5))\nsns.set()\nplt.subplot(1,2,1)\nplt.hist(np.expm1(train['budget']), bins =10)\nplt.title('Distribution of budget',fontsize=15)\nplt.subplot(1,2,2)\nplt.hist(train['budget'], bins =10) \nplt.title('Distribution of log budget', fontsize=15)","b9c0c7fb":"px.scatter(data_frame = train, x='budget',y='revenue', title = 'Log Budget vs Log Revenue')","ad437e34":"px.scatter(data_frame = train, x='budget',y='popularity', title = 'Log Budget vs Log Popularity')","581fcd0e":"px.scatter(data_frame = train, x='budget',y='runtime', title = 'Log Budget vs Log Runtime')","7d70ce8d":"fig = px.line(train, x=\"budget\", y=\"revenue\", color=\"original_language\", title = 'Log Budget vs Log Revenue in different languages')\nfig.show()","e0971880":"px.box(train.loc[train['original_language'].isin(train['original_language'].value_counts().head(6).index)], x='original_language', y='revenue', title='Log Revenue Distribution for top languages')\n","6c81db11":"plt.figure(figsize=(12,10))\ntext4 = ' '.join(train['original_title'].sort_values(ascending=False))\nwordcloud = WordCloud(collocations=False).generate(text4)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.title('Most Common words in title', fontsize=15)\nplt.show()","56184492":"plt.figure(figsize=(12,10))\ntext5 = ' '.join(train['overview'].fillna('').values)\nwordcloud = WordCloud(collocations=False).generate(text5)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.title('Top words in Overview', fontsize=15)\nplt.show()","eed22fea":"px.scatter(train.loc[train['original_language'].isin(train['original_language'].value_counts().head(6).index)],\n           x='popularity', y='revenue',color = 'original_language',size='budget', title = 'Log Revenue vs Log Popularity (Buble size=Budget)')","0e6b345d":"train.loc[train['release_date'].isnull() == True, 'release_date'] = '01\/01\/98'\ntest.loc[test['release_date'].isnull() == True, 'release_date'] = '01\/01\/98'\n","9d2a045d":"def fix_date(x):\n    \"\"\"\n    Fixes dates which are in 20xx\n    \"\"\"\n    year = x.split('\/')[2]\n    if int(year) <= 19:\n        return x[:-2] + '20' + year\n    else:\n        return x[:-2] + '19' + year","db87a01c":"train['release_date'] = train['release_date'].apply(lambda x: fix_date(x))\ntest['release_date'] = test['release_date'].apply(lambda x: fix_date(x))\ntrain['release_date'] = pd.to_datetime(train['release_date'])\ntest['release_date'] = pd.to_datetime(test['release_date'])","f3355228":"def process_date(df):\n    date_parts = [\"year\", \"weekday\", \"month\", 'weekofyear', 'day', 'quarter']\n    for part in date_parts:\n        part_col = 'release' + \"_\" + part\n        df[part_col] = getattr(df['release_date'].dt, part).astype(int)\n    \n    return df\n\ntrain = process_date(train)\ntest = process_date(test)","6c0f4de2":"d = train['release_date'].dt.year.value_counts().sort_index()\ng = train.groupby('release_date')['revenue'].sum()","deeffd75":"d1 = train['release_year'].value_counts().sort_index()\nd2 = train.groupby(['release_year'])['revenue'].sum()\nd3 = train.groupby(['release_year'])['budget'].sum()\ndata = [go.Scatter(x=d1.index, y=d1.values, name='film count'), \n        go.Scatter(x=d2.index, y=d2.values, name='total revenue', yaxis='y2'),\n        go.Scatter(x=d3.index, y=d3.values, name='total budget', yaxis='y2')]\nlayout = go.Layout(dict(title = \"Number of films and total revenue per year\",\n                  xaxis = dict(title = 'Year'),\n                  yaxis = dict(title = 'Count'),\n                  yaxis2=dict(title='Capital', overlaying='y', side='right')\n                  ),legend=dict(\n                orientation=\"v\"))\nfig = go.Figure(data, layout)\nfig.update_xaxes(\n    rangeslider_visible=True)\nfig.show()","bb70e616":"plt.figure(figsize=(10,7))\nsns.stripplot(x='release_weekday', y= 'revenue', data=train)\nplt.xlabel('Weekday')\nplt.ylabel('Revenue')\nplt.title('Log Revenue by release day of week', fontsize=17)","409cebcf":"plt.figure(figsize=(10,7))\nsns.stripplot(x='release_quarter', y= 'revenue', data=train)\nplt.xlabel('Quarter')\nplt.ylabel('Revenue')\nplt.title('Log Revenue by release quater of year', fontsize=17)","745b1cc0":"plt.figure(figsize=(10,7))\nsns.stripplot(x='release_month', y= 'revenue', data=train)\nplt.xlabel('Month')\nplt.ylabel('Revenue')\nplt.title('Log Revenue by release month', fontsize=17)","b0318ee7":"fig, ax = plt.subplots(figsize = (14,5))\nplt.subplot(1,2,1)\nsns.regplot(data=train, x='runtime', y='revenue')\nplt.xlabel('Runtime')\nplt.ylabel('Revenue')\nplt.title('Log Revenue by Log Runtime', fontsize=17)\nplt.subplot(1,2,2)\nplt.hist(train['runtime'], bins=10)\nplt.xlabel('Runtime')\nplt.ylabel('Count')\nplt.title('Distribution by Log Runtime', fontsize=17)","dea67c9b":"train['status'].value_counts()","86411b29":"plt.figure(figsize=(12,12))\ntext6 = ' '.join(train['tagline'].fillna('').values)\nwordcloud = WordCloud(collocations = False).generate(text6)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.title('Top words in tagline')\nplt.show()","a0603e37":"fig, ax = plt.subplots(figsize = (14,5))\nplt.subplot(1,2,1)\nsns.stripplot(data=train, x='has_collection', y= 'revenue')\nplt.title('Stripplot of Log Revenue vs Collection', fontsize=17)\nplt.subplot(1,2,2)\nsns.boxplot(data=train, x='has_collection', y= 'revenue')\nplt.title('Boxplot of Log Revenue vs Collection',fontsize=17)\n","4c37fad5":"fig, ax = plt.subplots(figsize = (14,5))\nplt.subplot(1,2,1)\nsns.stripplot(data=train, x='has_homepage', y= 'revenue')\nplt.title('Stripplot of Log Revenue vs Homepage', fontsize=17)\nplt.subplot(1,2,2)\nsns.boxplot(data=train, x='has_homepage', y= 'revenue')\nplt.title('Boxplot of Log Revenue vs Homepage',fontsize=17)\n","4497e6bc":"fig, ax = plt.subplots(figsize = (14,5))\nplt.subplot(1,2,1)\nsns.stripplot(data=train, x='num_of_genres', y= 'revenue')\nplt.title('Stripplot of Log Revenue vs Number of Genres', fontsize=17)\nplt.subplot(1,2,2)\nsns.boxplot(data=train, x='num_of_genres', y= 'revenue')\nplt.title('Boxplot of Log Revenue vs Number of Genres',fontsize=17)\n","1b8ddb8d":"f, axes = plt.subplots(4, 3, figsize=(15, 12))\nfor i,e in enumerate([col for col in train if col.startswith('genre_')]):\n    sns.stripplot(data=train, x=e, y='revenue',  ax=axes[i \/\/ 3][i % 3])\nplt.tight_layout()","9185e03b":"fig = px.box(train, x='num_prod_companies', y= 'revenue',\n             color='has_collection',title='Log Revenue vs Number of Production companys')\nfig.update_traces(quartilemethod=\"exclusive\") # or \"inclusive\", or \"linear\" by default\nfig.show()","21d57c88":"plt.figure(figsize=(10,6))\nsns.set()\nsns.stripplot(x='num_prod_countries', y='revenue', data=train)\nplt.xlabel('Production Countries',fontsize=15)\nplt.ylabel('Revenue',fontsize=15)\nplt.title('Log Revenue vs Number of countries producing the film',fontsize=15);","85bae409":"f, axes = plt.subplots(2, 3, figsize=(12, 10))\nplt.suptitle('Log revenue vs Top Production Countries', fontsize=15)\nfor i,e in enumerate([col for col in train if col.startswith('prod_country_')]):\n    sns.boxplot(data=train, x=e, y='revenue',  ax=axes[i \/\/ 3][i % 3])\nplt.show()","5476a881":"plt.figure(figsize=(10,5))\nsns.set()\nsns.stripplot(x='num_of_langs', y='revenue', data=train)\nplt.xlabel('Number of languages',fontsize=15)\nplt.ylabel('Revenue',fontsize=15)\nplt.title('Log Revenue vs Number of languages movie released in',fontsize=15);","f8d39578":"plt.figure(figsize=(10,6))\nsns.set()\nsns.stripplot(x='num_of_keywords', y='revenue', data=train)\nplt.xlabel('Number of Keywords',fontsize=15)\nplt.ylabel('Revenue',fontsize=15)\nplt.title('Revenue vs Number of keywords',fontsize=15);","edcf57f1":"f, axes = plt.subplots(4, 3, figsize=(15, 15))\nplt.suptitle('Boxplot of Log Revenue vs Top Keywords', fontsize=16)\nfor i,e in enumerate([col for col in train if col.startswith('keyword_')]):\n    sns.boxplot(data=train, x=e, y='revenue',  ax=axes[i \/\/ 3][i % 3])\nplt.show()","00ae6a72":"plt.figure(figsize=(10,6))\nsns.set()\nsns.regplot(x='num_of_cast', y='revenue', data=train)\nplt.xlabel('Number of Cast',fontsize=15)\nplt.ylabel('Revenue',fontsize=15)\nplt.title('Log Revenue vs Number of Cast',fontsize=16);","ab4b45d3":"f, axes = plt.subplots(5, 4, figsize=(15, 13))\nplt.suptitle('Boxplot of Log Revenue vs Top Cast', fontsize=16)\nfor i,e in enumerate([col for col in train if col.startswith('cast_name_')]):\n    sns.boxplot(data=train, x=e, y='revenue',  ax=axes[i \/\/ 4][i % 4])\nplt.show()","b2803382":"px.scatter(data_frame = train, x='num_of_crew',y='revenue', title = 'Crew vs Log Revenue(Bubble size= Number of cast, color= Budget)',\n           size='num_of_cast',color='budget')","e5430fc9":"f, axes = plt.subplots(5, 4, figsize=(15, 20))\nplt.suptitle('Boxplot of Log Revenue vs Top Crew', fontsize=16)\nfor i,e in enumerate([col for col in train if col.startswith('crew_name_')]):\n    sns.boxplot(data=train, x=e, y='revenue',  ax=axes[i \/\/ 4][i % 4])\nplt.show()","c33ed67f":"rating_na = train.groupby([\"release_year\",\"original_language\"])['rating'].mean().reset_index()\ntrain[train.rating.isna()]['rating'] = train.merge(rating_na, how = 'left' ,on = [\"release_year\",\"original_language\"])\nvote_count_na = train.groupby([\"release_year\",\"original_language\"])['totalVotes'].mean().reset_index()\ntrain[train.totalVotes.isna()]['totalVotes'] = train.merge(vote_count_na, how = 'left' ,on = [\"release_year\",\"original_language\"])\ntrain['weightedRating'] = ( train['rating']*train['totalVotes'] + 6.367 * 1000 ) \/ ( train['totalVotes'] + 1000 )\n\ntrain['inflationBudget'] = np.log1p(np.expm1(train['budget']) + np.expm1(train['budget'])*1.8\/100*(2018-train['release_year'])) \n#Inflation simple formula\ntrain['_popularity_mean_year'] = train['popularity'] \/ train.groupby(\"release_year\")[\"popularity\"].transform('mean')\ntrain['_budget_runtime_ratio'] = train['budget']\/train['runtime'] \ntrain['_budget_popularity_ratio'] = train['budget']\/train['popularity']\ntrain['_budget_year_ratio'] = train['budget']\/(train['release_year']*train['release_year'])\ntrain['_releaseYear_popularity_ratio'] = train['release_year']\/train['popularity']\n\ntrain['_popularity_totalVotes_ratio'] = train['totalVotes']\/train['popularity']\ntrain['_rating_popularity_ratio'] = train['rating']\/train['popularity']\ntrain['_rating_totalVotes_ratio'] = train['totalVotes']\/train['rating']\ntrain['_totalVotes_releaseYear_ratio'] = train['totalVotes']\/train['release_year']\ntrain['_budget_rating_ratio'] = train['budget']\/train['rating']\ntrain['_runtime_rating_ratio'] = train['runtime']\/train['rating']\ntrain['_budget_totalVotes_ratio'] = train['budget']\/train['totalVotes']\n    \ntrain['meanruntimeByYear'] = train.groupby(\"release_year\")[\"runtime\"].aggregate('mean')\ntrain['meanPopularityByYear'] = train.groupby(\"release_year\")[\"popularity\"].aggregate('mean')\ntrain['meanBudgetByYear'] = train.groupby(\"release_year\")[\"budget\"].aggregate('mean')\ntrain['meantotalVotesByYear'] = train.groupby(\"release_year\")[\"totalVotes\"].aggregate('mean')\ntrain['meanTotalVotesByRating'] = train.groupby(\"rating\")[\"totalVotes\"].aggregate('mean')\n\ntrain['isTaglineNA'] = 0\ntrain.loc[train['tagline'] == 0 ,\"isTaglineNA\"] = 1 \n    \ntrain['isTitleDifferent'] = 1\ntrain.loc[ train['original_title'] == train['title'] ,\"isTitleDifferent\"] = 0 \n","c93802bf":"rating_na = test.groupby([\"release_year\",\"original_language\"])['rating'].mean().reset_index()\ntest[test.rating.isna()]['rating'] = test.merge(rating_na, how = 'left' ,on = [\"release_year\",\"original_language\"])\nvote_count_na = test.groupby([\"release_year\",\"original_language\"])['totalVotes'].mean().reset_index()\ntest[test.totalVotes.isna()]['totalVotes'] = test.merge(vote_count_na, how = 'left' ,on = [\"release_year\",\"original_language\"])\ntest['weightedRating'] = ( test['rating']*test['totalVotes'] + 6.367 * 1000 ) \/ ( test['totalVotes'] + 1000 )\n\n\ntest['inflationBudget'] = np.log1p(np.expm1(test['budget']) + np.expm1(test['budget'])*1.8\/100*(2018-test['release_year'])) #Inflation simple formula\n \ntest['_popularity_mean_year'] = test['popularity'] \/ test.groupby(\"release_year\")[\"popularity\"].transform('mean')\ntest['_budget_runtime_ratio'] = test['budget']\/test['runtime'] \ntest['_budget_popularity_ratio'] = test['budget']\/test['popularity']\ntest['_budget_year_ratio'] = test['budget']\/(test['release_year']*test['release_year'])\ntest['_releaseYear_popularity_ratio'] = test['release_year']\/train['popularity']\n\ntest['_popularity_totalVotes_ratio'] = test['totalVotes']\/test['popularity']\ntest['_rating_popularity_ratio'] = test['rating']\/test['popularity']\ntest['_rating_totalVotes_ratio'] = test['totalVotes']\/test['rating']\ntest['_totalVotes_releaseYear_ratio'] = test['totalVotes']\/test['release_year']\ntest['_budget_rating_ratio'] = test['budget']\/test['rating']\ntest['_runtime_rating_ratio'] = test['runtime']\/test['rating']\ntest['_budget_totalVotes_ratio'] = test['budget']\/test['totalVotes']\n    \ntest['meanruntimeByYear'] = test.groupby(\"release_year\")[\"runtime\"].aggregate('mean')\ntest['meanPopularityByYear'] = test.groupby(\"release_year\")[\"popularity\"].aggregate('mean')\ntest['meanBudgetByYear'] = test.groupby(\"release_year\")[\"budget\"].aggregate('mean')\ntest['meantotalVotesByYear'] = test.groupby(\"release_year\")[\"totalVotes\"].aggregate('mean')\ntest['meanTotalVotesByRating'] = test.groupby(\"rating\")[\"totalVotes\"].aggregate('mean')\n\ntest['isTaglineNA'] = 0\ntest.loc[test['tagline'] == 0 ,\"isTaglineNA\"] = 1 \n    \ntest['isTitleDifferent'] = 1\ntest.loc[ test['original_title'] == test['title'] ,\"isTitleDifferent\"] = 0 \n","2201aa7e":"train = train.drop(['id','belongs_to_collection','genres','homepage','imdb_id','overview','runtime'\n    ,'poster_path','production_companies','production_countries','release_date','spoken_languages'\n    ,'status','title','Keywords','cast','crew','original_language','original_title','tagline','all_genres',\n                    'all_prod_companies','all_prod_countries','all_langs','all_keywords','all_cast_name'],axis=1)\ntest = test.drop(['id','belongs_to_collection','genres','homepage','imdb_id','overview','runtime'\n    ,'poster_path','production_companies','production_countries','release_date','spoken_languages'\n    ,'status','title','Keywords','cast','crew','original_language','original_title','tagline','all_genres',\n                    'all_prod_companies','all_prod_countries','all_langs','all_keywords','all_cast_name'],axis=1)","37edbc01":"train.fillna(value=0.0, inplace = True) \ntest.fillna(value=0.0, inplace = True) ","48dc221a":"train.sample(3)","35a46f2d":"def clean_dataset(df):\n    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n    df.dropna(inplace=True)\n    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n    return df[indices_to_keep].astype(np.float64)\ntrain = clean_dataset(train)","8e047098":"X = train.drop(['revenue'],axis=1)\ny = train.revenue\n\nX_train, X_valid, y_train, y_valid = train_test_split(X,y,test_size=0.2,random_state=25)","be98d9c3":"lr = LinearRegression()\nlr.fit(X_train, y_train)\npred = lr.predict(X_valid)\naccuracy = r2_score(y_valid,pred)\nprint('Linear Regression R2 Score: ', accuracy)\n\nmse = mean_squared_error(y_valid,pred)\nprint('Mean Squared Error: ', mse)\nprint('Root Mean Square Error',np.sqrt(mse))\n\ncv_pred = cross_val_predict(lr,X,y,n_jobs=-1, cv=10)\ncv_accuracy = r2_score(y,cv_pred)\nprint('Cross-Predicted(KFold) R2 Score: ', cv_accuracy)\n#REsidual Plots","a0a55fd3":"ls = Lasso()\nls.fit(X_train, y_train)\npred = ls.predict(X_valid)\naccuracy = r2_score(y_valid,pred)\nprint('Lasso Regression R2 Score: ', accuracy)\n\nmse = mean_squared_error(y_valid,pred)\nprint('Mean Squared Error: ', mse)\nprint('Root Mean Squared Error', np.sqrt(mse))\n\ncv_pred = cross_val_predict(ls,X,y,n_jobs=-1, cv=10)\ncv_accuracy = r2_score(y,cv_pred)\nprint('Cross-Predicted(KFold) Lasso Regression Accuracy: ', cv_accuracy)","f0081c59":"dt = DecisionTreeRegressor()\ndt.fit(X_train, y_train)\npred = dt.predict(X_valid)\naccuracy = r2_score(y_valid,pred)\nprint('Decision Tree R2 Score: ', accuracy)\n\nmse = mean_squared_error(y_valid,pred)\nprint('Mean Squared Error: ', mse)\nprint('Root Mean Square Error',np.sqrt(mse))\n\ncv_pred = cross_val_predict(dt,X,y,n_jobs=-1, cv=10)\ncv_accuracy = r2_score(y,cv_pred)\nprint('Cross-Predicted(KFold) Decision Tree Accuracy: ', cv_accuracy)","b7ecdefe":"rf = RandomForestRegressor()\nrf.fit(X_train, y_train)\npred = rf.predict(X_valid)\naccuracy = r2_score(y_valid,pred)\nprint('Random Forest Regressor R2: ', accuracy)\n\nmse = mean_squared_error(y_valid,pred)\nprint('Mean Squared Error: ', mse)\nprint('Root Mean Square Error',np.sqrt(mse))\n\ncv_pred = cross_val_predict(rf,X,y,n_jobs=-1, cv=10)\ncv_accuracy = r2_score(y,cv_pred)\nprint('Cross-Predicted(KFold) Random Forest R2: ', cv_accuracy)","6c2ea708":"rfr = RandomForestRegressor()\nn_estimators = [int(x) for x in np.linspace(start = 50 , stop = 300, num = 5)] # returns 10 numbers \nmax_features = [10,20,40,60,80,100,120]\nmax_depth = [int(x) for x in np.linspace(5, 10, num = 2)] \nmax_depth.append(None)\nbootstrap = [True, False]\nr_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'bootstrap': bootstrap}\ncv_random = RandomizedSearchCV(estimator=rfr, param_distributions=r_grid, n_iter = 20,\n                                scoring='neg_mean_squared_error', cv = 3, verbose=2, random_state=42,\n                                n_jobs=-1, return_train_score=True)\n\ncv_random.fit(X_train, y_train);\n\nprint(cv_random.best_params_)\n\npred = cv_random.predict(X_valid)\nmse = mean_squared_error(y_valid,pred)\nprint('Mean Squared Error: ', mse)\nprint('Root Mean Square Error',np.sqrt(mse))\n\ncv_accuracy = r2_score(y_valid,pred)\nprint('Random Forest Predict R2: ', cv_accuracy)","b24f8247":"feature_imp = [col for col in zip(X_train.columns, cv_random.best_estimator_.feature_importances_)]\nfeature_imp.sort(key=lambda x:x[1], reverse=True)\n","04defbf6":"imp = pd.DataFrame(feature_imp[0:40], columns=['feature', 'importance'])\nplt.figure(figsize=(14, 12))\nsns.barplot(y='feature', x='importance', data=imp)\nplt.title('30 Most Important Features', fontsize=16)\nplt.ylabel(\"Feature\", fontsize=15)\nplt.xlabel(\"Importance Param\",fontsize=15)\nplt.show()\n","b9b92aa3":"imp","d333c8b4":"import h2o\nfrom h2o.estimators.gbm import H2OGradientBoostingEstimator\nfrom h2o.automl import H2OAutoML","54d0ecb1":"h2o.init()","b0307cb1":"h2o_df=h2o.H2OFrame(train)\nh2o_df.head()","fe4ec0f8":"splits = h2o_df.split_frame(ratios=[0.8],seed=1)\nh2o_train = splits[0]\nh2o_valid = splits[1]","b78bc529":"y = \"revenue\" \nx = h2o_df.columns \nx.remove(y) ","ec48224f":"aml = H2OAutoML(max_runtime_secs=180, seed=1,stopping_metric='RMSE')","8b13c5e1":"aml.train(x=x,y=y, training_frame=h2o_train)","989803fe":"lb = aml.leaderboard\nlb.head()","0a7acf23":"# Get model ids for all models in the AutoML Leaderboard\nmodel_ids = list(aml.leaderboard['model_id'].as_data_frame().iloc[:,0])\n# Get the \"All Models\" Stacked Ensemble model\nse = h2o.get_model([mid for mid in model_ids if \"StackedEnsemble_AllModels\" in mid][0])\n# Get the Stacked Ensemble metalearner model\nmetalearner = h2o.get_model(se.metalearner()['name'])","be7b48eb":"#This shows us how much each base learner is contributing to the ensemble.\n%matplotlib inline\nmetalearner.std_coef_plot()","c466efd7":"pred = aml.predict(h2o_valid)\npred.head()","3fafb81e":"h2o.save_model(aml.leader, path=\".\/model_bin\")","af62ff76":"import xgboost as xgb\nfrom xgboost.sklearn import XGBRegressor\nparams = {'objective': 'reg:linear', \n          'eta': 0.01, \n          'max_depth': 6, \n          'min_child_weight': 3,\n          'subsample': 0.8,\n          'colsample_bytree': 0.8,\n          'colsample_bylevel': 0.50, \n          'gamma': 1.45, \n          'eval_metric': 'rmse', \n          'seed': 12, \n          'silent': True}\n# create dataset for xgboost\nxgb_data = [(xgb.DMatrix(X_train, y_train), 'train'), (xgb.DMatrix(X_valid, y_valid), 'valid')]\nprint('Starting training...')\n# train\nxgb_model = xgb.train(params, \n                  xgb.DMatrix(X_train, y_train),\n                  10000,  \n                  xgb_data, \n                  verbose_eval=300,\n                  early_stopping_rounds=300)","ad1e1f00":"xgb_pred = xgb_model.predict(xgb.DMatrix(X_valid))","a87f0a89":"fig, ax = plt.subplots(figsize=(20,12))\nxgb.plot_importance(xgb_model, max_num_features=30, height = 0.8, ax = ax)\nplt.title('XGBOOST Features (avg over folds)')\nplt.show()","1eea8be7":"train.shape, test.shape","274281aa":"X_test = test.drop('revenue',axis=1)","880faadb":"X_test[X_test==np.inf]=np.nan\nX_test.fillna(X_test.mean(), inplace=True)","43f47db3":"test_pred_xgb = xgb_model.predict(xgb.DMatrix((X_test)), ntree_limit=xgb_model.best_ntree_limit)","e7ceefa9":"test_pred_xgb[0]","cac97ffe":"from catboost import CatBoostRegressor\nmodel = CatBoostRegressor(iterations=100000,\n                                 learning_rate=0.005,\n                                 depth=5,\n                                 eval_metric='RMSE',\n                                 colsample_bylevel=0.8,\n                                 random_seed = 21,\n                                 bagging_temperature = 0.2,\n                                 metric_period = None,\n                                 early_stopping_rounds=200\n                                )\nmodel.fit(X_train, y_train,eval_set=(X_valid, y_valid),use_best_model=True,verbose=500)\n    \nval_pred = model.predict(X_valid)\nprint('RMSE',np.sqrt(mean_squared_error(val_pred,y_valid)))\ntest_pred_cat = model.predict(X_test)","92de6709":"import lightgbm as lgb\nparams = {'objective':'regression',\n         'num_leaves' : 30,\n         'min_data_in_leaf' : 20,\n         'max_depth' : 9,\n         'learning_rate': 0.004,\n         #'min_child_samples':100,\n         'feature_fraction':0.9,\n         \"bagging_freq\": 1,\n         \"bagging_fraction\": 0.9,\n         'lambda_l1': 0.2,\n         \"bagging_seed\": 11,\n         \"metric\": 'rmse',\n         #'subsample':.8, \n          #'colsample_bytree':.9,\n         \"random_state\" : 11,\n         \"verbosity\": -1}\nrecord = dict()\nmodel = lgb.train(params\n                      , lgb.Dataset(X_train, y_train)\n                      , num_boost_round = 100000\n                      , valid_sets = [lgb.Dataset(X_valid, y_valid)]\n                      , verbose_eval = 500\n                      , early_stopping_rounds = 500\n                      , callbacks = [lgb.record_evaluation(record)]\n                     )\nbest_idx = np.argmin(np.array(record['valid_0']['rmse']))\n\nval_pred = model.predict(X_valid, num_iteration = model.best_iteration)\ntest_pred_gbm = model.predict(X_test, num_iteration = model.best_iteration)","3f2ea7c3":"sub = pd.read_csv('..\/input\/tmdb-box-office-prediction\/sample_submission.csv')\ndf_sub = pd.DataFrame()\ndf_sub['id'] = sub['id']\nfinal_pred = 0.3*test_pred_xgb + 0.7*test_pred_cat\ndf_sub['revenue'] = np.expm1(final_pred)\nprint(df_sub['revenue'])\ndf_sub.to_csv(\"submission.csv\", index=False)","11a653e4":"**Conclusion**\n\nThat's it we reached the end of our exercise.\n\nWe started with data exploration and cleaning, checked skewness,then we jumped straight out to feature creation, we converted all the text features to usable features for our model.\nThen we did Data Visualization and checked correlation between various features and our target variable 'Revenue' and then created additional features.\nFinally we created some models and checked performance based on rmse. Random Forest showed us good result. H2o AutoML gave us an even better performance, but since it is a blackbox model, we rather tried XGBoost model which gave us an equally good performance. \nIt took me many many hours of effort to get this all done.\nDo drop comments where you think I can improve the model or features.\nUpvote if you liked what you saw.\nThanks and much more to come ;)","475cc231":"The film industry has grown significantly over the last few decades as we can see the significant increase in Number of films and Revenue generated by them each year.","a0243ce9":"### Load Libraries","173b021c":"### Budget","8077b7a1":"Some crew definetly produce more revenue.","32d32db3":"Now let's look briefly at production companies.\n#### Production Companies","feb957ec":"#### H2o AutoML\nNow let's try H2o AutoML on our Data to check if it gives better accuracy and less error.","1bec4576":"### Languages\nThe number of languages a movie is released in.","5f099410":"### Tagline","3574bb6a":"Not much different. It hardly matters in which quarter the movie is releasing.","08911740":"This shows that most of the movies have 1-2 languages.","87ece04c":"# TMDB Box Office Prediction","1068dfab":"### Crew","39d27dd9":"### Original Title","231d4798":"#### Linear Regression","67127d87":"**If you use parts of this notebook in your scripts\/notebooks, giving some kind of credit would be very much appreciated :) You can for instance link back to this notebook. Thanks!**","72979b40":"### __Target Variable: Revenue__","b00f350b":"### Introduction","e4ca7874":"### Original Language","1ba577fa":"We converted Revenue to log Revenue earlier and we can see a better distribution of data now.","1b658f78":"We can transform popularity, revenue,totalVotes, budget, runtime and popularity2","4b6e0fb0":"#### Spoken Languages","fa7f3bf1":"#### Cast","f3088e7f":"These are the 30 most important features.","50b73da9":"Let's check the skewness and kurtosis of the columns and make these columns normal for better working of features.","a5a04065":"### Production Countries","4cb926d5":"As the number of Production Countries increases, the revenues is decreasing. The films produced in 1-2 countries have the highest revenue.","1938f56b":"We can see that Adventure and Science Fiction are expected to earn more on average than other genres.","0375c20f":"We will create binary columns for the top 10 production house and later see what we do with this data. We will also create additional features.","2b7b5ab2":"2396 dont have any value. 604 have collection values. We will store collection name separtely as another features, as rest of the values won't be much needed, so we'll drop them.","092fe6c2":"### Cat Boost","c4c4fac4":"### Production Companies","62ed7cb2":"In a world... where movies made an estimated $41.7 billion in 2018, the film industry is more popular than ever. But what movies make the most money at the box office? How much does a director matter? Or the budget? For some movies, it's \"You had me at 'Hello.'\" For others, the trailer falls short of expectations and you think \"What we have here is a failure to communicate.\"\n\nIn this, we're presented with metadata on over 7,000 past films from The Movie Database to try and predict their overall worldwide box office revenue. Data points provided include cast, crew, plot keywords, budget, posters, release dates, languages, production companies, and countries. You can collect other publicly available data to use in your model predictions, but in the spirit of this competition, use only data that would have been available before a movie's release.\n","48da6edb":"For the final submission you can try different combinations of model to predict the target revenue. For me the below model made sense and gave great prediction.","159aa3ed":"### Has Collection","4aa16989":"### Load Data","7611f185":"### Genres","01411570":"Since majority of the movies are released, this variable is useless.","24ef7117":"#### Belongs to collection","88b3e1df":"### Popularity","a5a67d49":"## Data Visualization\nWe'll do Data Visualization for our features and then add additional features .","a47a03ae":"This gives us an indication that the movies that are the part of a collection are expected to earn more on average than the others.","23af411d":"#### Randomized Search CV on Random Forest Regressor","014ceee0":"Now lets see the most common production companies.","278ab93b":"#### Homepage","a7d80590":"Similarly we will check all the dictionaries and clean them.\nNow we will check for Genres.\n### Genres","1ee367ef":"Movies produced in USA generates more revenue on Average as compared to movies produced in other countries.","2a4c5968":"This shows that majority of the films have 2-3 genres. 5-6 are also possible but 0-7 might be outliers. ","27d3c708":"### Status","6a90bd07":"#### XGBoost","f2a38566":"#### Crew","5a0d0bfb":"#### Keywords","9575db95":"RMSE is even better as compared to the best model by H2o AutoML. So we will stick with our XGBoost as our final model.","cd491711":"First we will try simple regressions model like Linear Regression, Lasso Regression, Decision Tree, Random Forest Regressor.","1d80a244":"#### Decision Tree Regressor","b25dfce2":"#### Additional Features","3c31ec5b":"The best rmse is for the Stacked Ensemble Model which is 1.90,which shows that our Random Forest Regressor was a good model as we were able to achieve rmse of 1.92","922066f4":"As we can see, Drama, Comedy, Thriller , Action are the most common genres.","4cdc7420":"There are only 4 movies with more than 5 production countries, all of which look valid. Now let's see which are the most common production countries.","055b2787":"### Release Date","bb28c054":"#### Random Forest Regressor","a21a722d":"Similarly we will check for production countries.\n#### Production Countries","e82651ea":"As you can see, majority of the movie's have 1-3 production companies.\nThere are movie's with more than 10 production companies. We will have a look at these companies to check if the data is valid.","56df5907":"There are only 3000 rows to train the data.\nWe can see that some of columns contain lists with dictionaries. Some lists contain a single dictionary, some have several. Let's extract data from these columns!","7959c01e":"All of the movie's look real, so we will keep the data.","48065c23":"Majority of the movies have 1 or 2 production countries. Some movies have more. Let's check the movie's with more than 5 production countries.","73c0ad27":"### Feature Engineering","ae9b48bf":"### Cast","f670ec3c":"Runtime doesn't look like a strong explanatory variable.","017acb3f":"Random Forest looks like a better predictor than other models, let's tune it and see how much accuracy we can get.","b8d14e4d":"Number of Production companies doesn't matter much in movies with no collection but in movies with collection, average revenue increases with increasing number of production companies, till a certain limit.","37035c27":"### Overview","de13beff":"#### Lasso Regression","2ff717c1":"__Data Description id__ - Integer unique id of each movie\n\n__belongs_to_collection__ - Contains the TMDB Id, Name, Movie Poster and Backdrop URL of a movie in JSON format. You can see the Poster and Backdrop Image like this: https:\/\/image.tmdb.org\/t\/p\/original\/. Example: https:\/\/image.tmdb.org\/t\/p\/original\/\/iEhb00TGPucF0b4joM1ieyY026U.jpg\n\n__budget__:Budget of a movie in dollars. 0 values mean unknown.\n\n__genres__ : Contains all the Genres Name & TMDB Id in JSON Format\n\n__homepage__ - Contains the official homepage URL of a movie. Example: http:\/\/sonyclassics.com\/whiplash\/ , this is the homepage of Whiplash movie.\n\n__imdb_id__ - IMDB id of a movie (string). You can visit the IMDB Page like this: https:\/\/www.imdb.com\/title\/\n\n__original_language__ - Two digit code of the original language, in which the movie was made. Like: en = English, fr = french.\n__original_title__ - The original title of a movie. Title & Original title may differ, if the original title is not in English.\n\n__overview__ - Brief description of the movie.\n\n__popularity__ - Popularity of the movie in float.\n\n__poster_path__ - Poster path of a movie. You can see the full image like this: https:\/\/image.tmdb.org\/t\/p\/original\/\n\n__production_companies__ - All production company name and TMDB id in JSON format of a movie.\n\n__production_countries__ - Two digit code and full name of the production company in JSON format.\n\n__release_date__ - Release date of a movie in mm\/dd\/yy format.\n\n__runtime__ - Total runtime of a movie in minutes (Integer).\n\n__spoken_languages__ - Two digit code and full name of the spoken language.\n\n__status__ - Is the movie released or rumored?\n\n__tagline__ - Tagline of a movie\n\n__title__ - English title of a movie\n\n__Keywords__ - TMDB Id and name of all the keywords in JSON format.\n\n__cast__ - All cast TMDB id, name, character name, gender (1 = Female, 2 = Male) in JSON format\n\n__crew__ - Name, TMDB id, profile path of various kind of crew members job like Director, Writer, Art, Sound etc.\n\n__revenue__ - Total revenue earned by a movie in dollars.","6cd6d965":"Surprisingly movies with 3-4 genres are expected to earn more than the rest.","597746b7":"### Keywords","f537ab1c":"We can clearly see, movies of some actors generate more revenue than others.","7b469e86":"### Runtime","483d9160":"As we can see, Drama and Comedy are the most common genres.\nWe can create separate features. \nOne for num of genres.\nAnother for value of all genres.\nand then for most common genres.","6e0730d6":"### LightGBM Model","98e2f8b6":"![boxoffice.jpg](http:\/\/sanjeevwritings.files.wordpress.com\/2018\/05\/boxoffice.jpg)","9ee2c2fd":"Now let's try if we can get better accuracy and less error from XGBoost.","383748b8":"It looks like Wednesday, Thursday and Friday releases generate more revenue.","e3bb1135":"### Modeling","05a9ec30":"CatBoost gave even less error than the XGB, now let's try LightGBM."}}