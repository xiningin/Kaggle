{"cell_type":{"8d309210":"code","588974eb":"code","f6d6cabb":"code","85b6c040":"code","4d72931e":"code","2e2373ca":"code","df6bb94e":"code","9de07c57":"code","19d7a9f4":"code","daae284a":"code","920e9760":"code","786e61e1":"code","72591757":"code","e7411ad0":"code","839f8f9b":"code","10eb9f13":"code","57295c9f":"code","8b959dc3":"code","30bfb492":"code","93a14034":"code","a38adb02":"code","ba0f963f":"code","f0c699dd":"code","03f409b8":"code","ac24ee26":"code","2dc291ae":"code","4b34433e":"code","cae515bd":"code","dcbef180":"code","01cd53f3":"code","01594804":"code","d563a571":"code","55798464":"code","c1e66c99":"code","f778b333":"code","eec29d6d":"code","613fc131":"markdown","6e862faf":"markdown","ac483a93":"markdown","152d46a9":"markdown","fccc4d55":"markdown","ba05dfd3":"markdown","21684e7f":"markdown","f44d0699":"markdown","27548ef2":"markdown","1275dcbe":"markdown","389a5607":"markdown","4375c79c":"markdown","32173dfa":"markdown","cab4124a":"markdown"},"source":{"8d309210":"# Importing libraries\n\n# overall libraries\nimport pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom collections import OrderedDict\nfrom IPython.core.pylabtools import figsize\nimport re\n\n# plotting libraries\nimport seaborn as sns\nsns.set_style('white')\nimport matplotlib.pyplot as plt\nimport matplotlib.lines as mlines\n%matplotlib inline\n\n# sklearn libraries\nimport sklearn\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import scale\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import make_moons\nfrom sklearn.metrics import log_loss, roc_auc_score, roc_curve, auc, precision_recall_curve, confusion_matrix, average_precision_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.preprocessing import LabelBinarizer","588974eb":"# setting the display so you can see all the columns and all the rows\n\npd.set_option(\"max_columns\", None)\npd.set_option(\"max_rows\", None)","f6d6cabb":"# creating the DataFrame\n\ndf = pd.read_excel('..\/input\/covid19\/dataset.xlsx', encoding='utf8')","85b6c040":"# Checking how the df imported\n\ndf.head()","4d72931e":"# Checking the unique values for the SARS-Cov-2 exam result\n\ndf['SARS-Cov-2 exam result'].unique()","2e2373ca":"# Replacing negative to 0 an positive to 1 and then checking if it worked\n\ndf['SARS-Cov-2 exam result'] = df['SARS-Cov-2 exam result'].replace({'negative': 0, 'positive': 1})\ndf['SARS-Cov-2 exam result'].unique()","df6bb94e":"# checking the categorical variables\n\ndf.select_dtypes(include = ['object']).columns","9de07c57":"# replacing the values to make them numerical, I am doing them by hand to make sure all the exams make sense.\n# This is possible because there aren't many categorical variables.\n# To do this, I checked all the variables unique values and created an unique dictionary\n\ndf.loc[:,'Respiratory Syncytial Virus':'Parainfluenza 2'] = df.loc[:,'Respiratory Syncytial Virus':'Parainfluenza 2'].replace({'not_detected':0, 'detected':1})\ndf.loc[:,'Influenza B, rapid test':'Strepto A'] = df.loc[:,'Influenza B, rapid test':'Strepto A'].replace({'negative':0, 'positive':1})\ndf['Urine - Esterase'] = df['Urine - Esterase'].replace({'absent':0})\ndf['Urine - Aspect'] = df['Urine - Aspect'].replace({'clear':0, 'cloudy':2, 'altered_coloring':3, 'lightly_cloudy':1})\ndf['Urine - pH'] = df['Urine - pH'].replace({'6.5':6.5, '6.0':6.0,'5.0':5.0, '7.0':7.0, '5':5, '5.5':5.5,\n       '7.5':7.5, '6':6, '8.0':8.0})\ndf['Urine - Hemoglobin'] = df['Urine - Hemoglobin'].replace({'absent':0, 'present':1})\ndf.loc[:,'Urine - Bile pigments':'Urine - Nitrite'] = df.loc[:,'Urine - Bile pigments':'Urine - Nitrite'].replace({'absent':0})\ndf.loc[:,'Urine - Urobilinogen':'Urine - Protein'] = df.loc[:,'Urine - Urobilinogen':'Urine - Protein'].replace({'absent':0, 'normal':1})\ndf['Urine - Hemoglobin'] = df['Urine - Hemoglobin'].replace({'absent':0, 'present':1, 'not_done':np.nan})\ndf['Urine - Leukocytes'] = df['Urine - Leukocytes'].replace({'38000':38000, '5942000':5942000, '32000':32000, '22000':22000,'<1000': 900, '3000': 3000,'16000':16000, '7000':7000, '5300':5300, '1000':1000, '4000':4000, '5000':5000, '10600':106000, '6000':6000, '2500':2500, '2600':2600, '23000':23000, '124000':124000, '8000':8000, '29000':29000, '2000':2000,'624000':642000, '40000':40000, '3310000':3310000, '229000':229000, '19000':19000, '28000':28000, '10000':10000,'4600':4600, '77000':77000, '43000':43000})\ndf['Urine - Crystals'] = df['Urine - Crystals'].replace({'Ausentes':0, 'Urato Amorfo --+':1, 'Oxalato de C\u00e1lcio +++':3,'Oxalato de C\u00e1lcio -++':2, 'Urato Amorfo +++':4})\ndf.loc[:,'Urine - Hyaline cylinders':'Urine - Yeasts'] = df.loc[:,'Urine - Hyaline cylinders':'Urine - Yeasts'].replace({'absent':0})\ndf['Urine - Color'] = df['Urine - Color'].replace({'light_yellow':0, 'yellow':1, 'orange':2, 'citrus_yellow':1})\ndf = df.replace('not_done', np.NaN)\ndf = df.replace('N\u00e3o Realizado', np.NaN)","19d7a9f4":"# Dropping the patient ID column\n\ndf = df.drop('Patient ID', axis = 1)","daae284a":"# checking if all of the categorical variables were treated\n\ndf.select_dtypes(include = ['object']).columns","920e9760":"# checking how the data is distribuited in the dataframe\n\ndf.info()","786e61e1":"# let's see what are the two columns that are working with int\n\ndf.select_dtypes(include = ['int64']).columns","72591757":"# let's create a rank of missing values\n\nnull_count = df.isnull().sum().sort_values(ascending=False)\nnull_percentage = null_count \/ len(df)\nnull_rank = pd.DataFrame(data=[null_count, null_percentage],index=['null_count', 'null_ratio']).T\nnull_rank","e7411ad0":"# dropping columns that don't have any content in it\n\ndf = df.drop(['Mycoplasma pneumoniae','Urine - Nitrite', 'Urine - Sugar', 'Partial thromboplastin time\u00a0(PTT)\u00a0', 'Prothrombin time (PT), Activity', 'D-Dimer'], axis = 1)","839f8f9b":"# let's see the min and max values of the variables to fill their missing values\n\ndf.describe().round(2)","10eb9f13":"# filling missing values with 0\n\ndf[['Urine - Leukocytes', 'Urine - pH']] = df[['Urine - Leukocytes', 'Urine - pH']].fillna(0)","57295c9f":"# filling missing values with -1\n\ndf[['Patient age quantile', 'SARS-Cov-2 exam result', 'Respiratory Syncytial Virus', 'Influenza A', 'Influenza B', 'Parainfluenza 1', 'CoronavirusNL63', 'Rhinovirus\/Enterovirus', 'Coronavirus HKU1', 'Parainfluenza 3', 'Chlamydophila pneumoniae', 'Adenovirus', 'Parainfluenza 4', 'Coronavirus229E', 'CoronavirusOC43', 'Inf A H1N1 2009', 'Bordetella pertussis', 'Metapneumovirus', 'Parainfluenza 2', 'Influenza B, rapid test', 'Influenza A, rapid test', 'Strepto A', 'Fio2 (venous blood gas analysis)','Myeloblasts', 'Urine - Esterase', 'Urine - Hemoglobin', 'Urine - Bile pigments', 'Urine - Ketone Bodies', 'Urine - Protein', 'Urine - Crystals', 'Urine - Hyaline cylinders', 'Urine - Granular cylinders', 'Urine - Yeasts', 'Urine - Color']] = df[['Patient age quantile', 'SARS-Cov-2 exam result', 'Respiratory Syncytial Virus', 'Influenza A', 'Influenza B', 'Parainfluenza 1', 'CoronavirusNL63', 'Rhinovirus\/Enterovirus', 'Coronavirus HKU1', 'Parainfluenza 3', 'Chlamydophila pneumoniae', 'Adenovirus', 'Parainfluenza 4', 'Coronavirus229E', 'CoronavirusOC43', 'Inf A H1N1 2009', 'Bordetella pertussis', 'Metapneumovirus', 'Parainfluenza 2', 'Influenza B, rapid test', 'Influenza A, rapid test', 'Strepto A', 'Fio2 (venous blood gas analysis)','Myeloblasts', 'Urine - Esterase', 'Urine - Hemoglobin', 'Urine - Bile pigments', 'Urine - Ketone Bodies', 'Urine - Protein', 'Urine - Crystals', 'Urine - Hyaline cylinders', 'Urine - Granular cylinders', 'Urine - Yeasts', 'Urine - Color']].fillna(-1)","8b959dc3":"# filling all the other missing values with 99\n\ndf = df.fillna(99)","30bfb492":"# let's see if there is still any missing values left\n\nnull_count = df.isnull().sum().sort_values(ascending=False)\nnull_percentage = null_count \/ len(df)\nnull_rank = pd.DataFrame(data=[null_count, null_percentage],index=['null_count', 'null_ratio']).T\nnull_rank","93a14034":"# let's now see the description of the dataframe again, because i am pretty sure we will have to apply some sort of normalization technique on it\n\ndf.describe()","a38adb02":"# creating a scaler and using it, disconsidering the target column\n\nscaler = MinMaxScaler()\naddmits = pd.DataFrame(df[['Patient addmited to regular ward (1=yes, 0=no)','Patient addmited to semi-intensive unit (1=yes, 0=no)', 'Patient addmited to intensive care unit (1=yes, 0=no)']], columns = ['Patient addmited to regular ward (1=yes, 0=no)', 'Patient addmited to semi-intensive unit (1=yes, 0=no)', 'Patient addmited to intensive care unit (1=yes, 0=no)'])\ndf_scaled = pd.DataFrame(scaler.fit_transform(df.drop(['Patient addmited to regular ward (1=yes, 0=no)','Patient addmited to semi-intensive unit (1=yes, 0=no)', 'Patient addmited to intensive care unit (1=yes, 0=no)'], axis = 1)), columns = (df.drop(['Patient addmited to regular ward (1=yes, 0=no)','Patient addmited to semi-intensive unit (1=yes, 0=no)', 'Patient addmited to intensive care unit (1=yes, 0=no)'], axis = 1).columns))","ba0f963f":"# concatenating all the columns again\n\ndf_total = pd.concat([addmits, df_scaled], axis = 1)","f0c699dd":"# checking if the concatening worked\n\ndf_total.head()","03f409b8":"# doing a correlation rank to see how the exams work with the result of the exam\n\ndf_total.corr()[['Patient addmited to regular ward (1=yes, 0=no)', 'Patient addmited to semi-intensive unit (1=yes, 0=no)', 'Patient addmited to intensive care unit (1=yes, 0=no)']].sort_values(by = 'Patient addmited to intensive care unit (1=yes, 0=no)', ascending=False)","ac24ee26":"# renaming the columns with backslash\n\ndf_total = df_total.rename(columns={\"Meancorpuscularhemoglobinconcentration\\xa0MCHC\": \"Meancorpuscularhemoglobinconcentrationxa0MCHC\", \"Gammaglutamyltransferase\\xa0\": \"Gammaglutamyltransferasexa0\", \"Ionizedcalcium\\xa0\": \"Ionizedcalciumxa0\", \"Creatinephosphokinase\\xa0CPK\\xa0\" : \"Creatinephosphokinasexa0CPKxa0\"})","2dc291ae":"# Let's remove all special characters and spaces from the column names\n# We will also make them lowercase\n\ndf_total.columns=df_total.columns.str.replace(r'\\(|\\)|:|,|;|\\.|\u2019|\u201d|\u201c|\\?|%|>|<|(|)','')\ndf_total.columns=df_total.columns.str.replace(r'\/','')\ndf_total.columns=df_total.columns.str.replace(' ','')\ndf_total.columns=df_total.columns.str.replace('\"','')\ndf_total.columns=df_total.columns.str.replace('\\-','')\ndf_total.columns=df_total.columns.str.replace('\\=','')\ndf_total.columns=df_total.columns.str.replace('\\#','')\ndf_total.columns=df_total.columns.str.lower()","4b34433e":"# let's get a list of all the columns so we can start working on our model\n\nlist(df_total.columns)","cae515bd":"# removing all the lines that don't give out a positive result for the sars-cov2 exam\n\ndf_total = df_total[df_total['sarscov2examresult'] != 0]","dcbef180":"# the first column will remain with the 1 value, the other two will be replaced with 2 and 3\n\ndf_total['patientaddmitedtosemiintensiveunit1yes0no'] = df_total['patientaddmitedtosemiintensiveunit1yes0no'].replace({1:2})\ndf_total['patientaddmitedtointensivecareunit1yes0no'] = df_total['patientaddmitedtointensivecareunit1yes0no'].replace({1:3})","01cd53f3":"# creating one single column that sums up all the directions to where the patients where sent\n\ndf_total['patient'] = df_total.apply(lambda row: row.patientaddmitedtoregularward1yes0no + row.patientaddmitedtosemiintensiveunit1yes0no + row.patientaddmitedtointensivecareunit1yes0no, axis=1)\ndf_total.head()","01594804":"# dropping the first three columns\n\ndf_total = df_total.drop(['patientaddmitedtoregularward1yes0no', 'patientaddmitedtosemiintensiveunit1yes0no', 'patientaddmitedtointensivecareunit1yes0no'], axis = 1)","d563a571":"# Creating X and y\n\nX = df_total.drop(['patient'], axis = 1)\ny = df_total['patient']","55798464":"# let's split the X and y into a test and train set\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state = 42)","c1e66c99":"# Creating a Gaussian Naive Bayes Classifier\n\ngnb = GaussianNB().fit(X_train, y_train) \ngnb_predictions = gnb.predict(X_test)","f778b333":"# Calculating the score of the model\n\naccuracy = gnb.score(X_test, y_test) \nprint(accuracy)","eec29d6d":"# Calculating the ROC AUC score of the model\n\ndef multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n    lb = LabelBinarizer()\n    lb.fit(y_test)\n    y_test = lb.transform(y_test)\n    y_pred = lb.transform(y_pred)\n    return roc_auc_score(y_test, y_pred, average=average)\n\nmulticlass_roc_auc_score(y_test, gnb_predictions)","613fc131":"We can exclude the columns that have absolutely no values in it, which are the 'Mycoplasma pneumoniae','Urine - Nitrite', 'Urine - Sugar', 'Partial thromboplastin time (PTT)', 'Prothrombin time (PT), Activity' and 'D-Dimer'.","6e862faf":"# Data Preparation and EDA\nBefore we can start to model anything, we have to treat all the data.","ac483a93":"For some reason I can't remove the backslash, so I will remove those by hand.","152d46a9":"# Naive Bayes Classification Method\nI decided to use the Naive Bayes Classification Method, for this is a multiclassification problem, and the solution is based on Bayes\u2019 theorem. It is termed as \u2018Naive\u2019 because it assumes independence between every pair of feature in the data. Let (x1, x2, \u2026, xn) be a feature vector and y be the class label corresponding to this feature vector.","fccc4d55":"Since there are only negative and positive outcomes, we can exchange those for 0 and 1","ba05dfd3":"Those are ok being int, so let's procceed with our analysis. First let's work with our missing data. Remember that we can't really use a mean, a mode or anything of the sorts, because not having asked for an exam is also an indication of the result of the final exam.","21684e7f":"Let's just check if the values inside the columns that are type int 64 actually make sense being int64 (discrete) and not continuous.","f44d0699":"# Creating the Bayes Classifier\nWe will now work on the bayes classifier.","27548ef2":"Let's scale all the variables to have a more normalized input. We will use the MinMaxScaler because by default it classifies all the inputs between 0-1, and it will scale it close to the target, because the exam results also come into 0-1.","1275dcbe":"Let's create one column to classify the destination of the patients.","389a5607":"Since there is a lot of different values, I will fill the as follows:\n* With 0: 'Urine - Leukocytes', 'Urine - pH'\n* With -1: 'Patient age quantile', 'SARS-Cov-2 exam result', 'Respiratory Syncytial Virus', 'Influenza A', 'Influenza B', 'Parainfluenza 1', 'CoronavirusNL63', 'Rhinovirus\/Enterovirus', 'Coronavirus HKU1', 'Parainfluenza 3', 'Chlamydophila pneumoniae', 'Adenovirus', 'Parainfluenza 4', 'Coronavirus229E', 'CoronavirusOC43', 'Inf A H1N1 2009', 'Bordetella pertussis', 'Metapneumovirus', 'Parainfluenza 2', 'Influenza B, rapid test', 'Influenza A, rapid test', 'Strepto A', 'Fio2 (venous blood gas analysis)','Myeloblasts', 'Urine - Esterase', 'Urine - Hemoglobin', 'Urine - Bile pigments', 'Urine - Ketone Bodies', 'Urine - Protein', 'Urine - Crystals', 'Urine - Hyaline cylinders', 'Urine - Granular cylinders', 'Urine - Yeasts', 'Urine - Color'\n* With 99: everything else","4375c79c":"<h1>Background<\/h1>\nThe World Health Organization (WHO) characterized the COVID-19, caused by the SARS-CoV-2, as a pandemic on March 11, while the exponential increase in the number of cases was risking to overwhelm health systems around the world with a demand for ICU beds far above the existing capacity, with regions of Italy being prominent examples.<br>\n\nBrazil recorded the first case of SARS-CoV-2 on February 26, and the virus transmission evolved from imported cases only, to local and finally community transmission very rapidly, with the federal government declaring nationwide community transmission on March 20.\n<br>\n\nUntil March 27, the state of S\u00e3o Paulo had recorded 1,223 confirmed cases of COVID-19, with 68 related deaths, while the county of S\u00e3o Paulo, with a population of approximately 12 million people and where Hospital Israelita Albert Einstein is located, had 477 confirmed cases and 30 associated death, as of March 23. Both the state and the county of S\u00e3o Paulo decided to establish quarantine and social distancing measures, that will be enforced at least until early April, in an effort to slow the virus spread.\n<br>\n\nOne of the motivations for this challenge is the fact that in the context of an overwhelmed health system with the possible limitation to perform tests for the detection of SARS-CoV-2, testing every case would be impractical and tests results could be delayed even if only a target subpopulation would be tested.\n<br><br>\n<h1>Dataset<\/h1>\nThis dataset contains anonymized data from patients seen at the Hospital Israelita Albert Einstein, at S\u00e3o Paulo, Brazil, and who had samples collected to perform the SARS-CoV-2 RT-PCR and additional laboratory tests during a visit to the hospital.\n<br>\nAll data were anonymized following the best international practices and recommendations. All clinical data were standardized to have a mean of zero and a unit standard deviation.\n<br><br>\n<h1>Task Details<\/h1>\n* <br>\n**TASK 1**<br>\n* Predict confirmed COVID-19 cases among suspected cases.\nBased on the results of laboratory tests commonly collected for a suspected COVID-19 case during a visit to the emergency room, would it be possible to predict the test result for SARS-Cov-2 (positive\/negative)?\n<br>\n**TASK 2**<br>\n* Predict admission to general ward, semi-intensive unit or intensive care unit among confirmed COVID-19 cases.\nBased on the results of laboratory tests commonly collected among confirmed COVID-19 cases during a visit to the emergency room, would it be possible to predict which patients will need to be admitted to a general ward, semi-intensive unit or intensive care unit?\n<br><br>\n<h1>Expected Submission<\/h1>\nSubmit a notebook that implements the full lifecycle of data preparation, model creation and evaluation. Feel free to use this dataset plus any other data you have available. Since this is not a formal competition, you're not submitting a single submission file, but rather your whole approach to building a model.\n<br><br>\n<h1>Evaluation<\/h1>\nThis is not a formal competition, so we won't measure the results strictly against a given validation set using a strict metric. Rather, what we'd like to see is a well-defined process to build a model that can deliver decent results (evaluated by yourself).\n<br>\nOur team will be looking at:\n<br>\n**Model Performance** - How well does the model perform on the real data? Can it be generalized over time? Can it be applied to other scenarios? Was it overfit?\n<br>\n**Data Preparation** - How well was the data analysed prior to feeding it into the model? Are there any useful visualisations? Does the reader learn any new techniques through this submission? A great entry will be informative, thought provoking, and fresh all at the same time.\n<br>\n**Documentation** - Are your code, and notebook, and additional data sources well documented so a reader can understand what you did? Are your sources clearly cited? A high quality analysis should be concise and clear at each step so the rationale is easy to follow and the process is reproducible.","32173dfa":"Let's remove all the lines that have a negative sars-cov2 exam result. Only people with a positive exam result would be directed to any part of the hospital.","cab4124a":"I will replace the values to make them numerical. I will do so by hand, so I can check all the exam results, and if the number transformation makes sense. This is only possbible because there isn't many categorical variables. In order to do that I will check all the unique values and then do an unique replacement dictionary for the columns. I will also drop the patient ID."}}