{"cell_type":{"1ba2e9d9":"code","9701c14c":"code","90c7a8e0":"code","58165f84":"code","ac155183":"code","2d8af766":"code","86f7a010":"code","b10aba38":"code","d9a53edb":"code","0e6f5ed3":"code","15899995":"code","85ef4401":"code","6b7bebcd":"code","47f3e198":"code","3385a417":"code","c1a92673":"code","8bd4415b":"code","a78fc8f0":"code","9e83665c":"code","e596d79a":"code","bceb30dd":"code","bce60611":"code","687b2ba6":"code","6c0137cd":"code","d32497b8":"markdown","e9c2b820":"markdown","1cc82fc7":"markdown","a2abcfbd":"markdown","d3caec03":"markdown","e552a085":"markdown","ec151f05":"markdown","b879c823":"markdown","83bff5e8":"markdown","4e93a326":"markdown","b6ee2664":"markdown","20693bd8":"markdown"},"source":{"1ba2e9d9":"import random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import GridSearchCV , RandomizedSearchCV","9701c14c":"df = pd.read_csv(\"..\/input\/titanic\/train.csv\")","90c7a8e0":"df = df.sample(frac=1)","58165f84":"df.head()","ac155183":"df.Ticket = df.Fare.astype(int)","2d8af766":"X = df.drop([\"Survived\" , \"Name\"] , axis=1)\nY = df[\"Survived\"]","86f7a010":"X.isna().sum()","b10aba38":"Y","d9a53edb":"np.random.seed(0)\n\n\n# Define different features and transformer pipeline\ncategorical_features = [\"Sex\" , \"Pclass\" , \"Cabin\" , \"Ticket\"]\ncategorical_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))])\n\nEmbarked_features = [\"Embarked\"]\nEmbarked_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"S\")),\n    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))])\n\nnumeric_features = [\"Age\"]\nnumeric_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"mean\"))\n])\n\n# Setup preprocessing steps (fill missing values, then convert to numbers)\npreprocessor = ColumnTransformer(\n                    transformers=[\n                        (\"cat\", categorical_transformer, categorical_features),\n                        (\"num\", numeric_transformer, numeric_features),\n                        (\"emb\" , Embarked_transformer , Embarked_features)\n                    ])\n\n# Creating a preprocessing and modelling pipeline\nmodel = Pipeline(steps=[(\"preprocessor\", preprocessor),\n                        (\"model\", RandomForestClassifier())])","0e6f5ed3":"model.fit(X,Y)","15899995":"model.score(X,Y)","85ef4401":"pipe_grid = {\n    \"preprocessor__num__imputer__strategy\": [\"mean\", \"median\"],\n    \"model__criterion\": [\"gini\" , \"entropy\"],\n    \"model__n_estimators\": [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000],\n    \"model__max_depth\": [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n    \"model__max_features\": [\"auto\", \"sqrt\", \"log2\"],\n    \"model__min_samples_split\": np.arange(2,8,2),\n    \"model__min_samples_leaf\": np.arange(1,10,1)\n}","6b7bebcd":"gs_model = RandomizedSearchCV(model, pipe_grid, cv=5, n_iter=200, verbose=2 , n_jobs=-1 , random_state=0)\ngs_model.fit(X,Y)","47f3e198":"gs_model.best_params_","3385a417":"pipe_grid_2 = {\n    \"preprocessor__num__imputer__strategy\": [\"median\"],\n    \"model__criterion\": [\"gini\"],\n    \"model__n_estimators\": [400,500],\n    \"model__max_depth\": [20,25,30],\n    \"model__max_features\": [\"sqrt\"],\n    \"model__min_samples_split\": [2],\n    \"model__min_samples_leaf\": [1,2]\n}","c1a92673":"gs_model = GridSearchCV(model, pipe_grid_2, cv=5, verbose=True , n_jobs=-1 )\ngs_model.fit(X,Y)","8bd4415b":"gs_model.best_params_","a78fc8f0":"df_test = pd.read_csv(\"..\/input\/titanic\/test.csv\")","9e83665c":"x_test = df_test.drop([\"Name\"] , axis=1)\ny_preds = gs_model.predict(x_test)","e596d79a":"survived = y_preds\nsurvived","bceb30dd":"dict = {\"PassengerId\" : x_test[\"PassengerId\"],\n       \"Survived\" : y_preds}","bce60611":"final = pd.DataFrame(dict,\n                    index = None)","687b2ba6":"final","6c0137cd":"final.to_csv(\"results.csv\")","d32497b8":"# GridSearch CV","e9c2b820":"# Randomized Search CV","1cc82fc7":"The \"Name\" and \"Survived\" columns are dropped from the dataset because :\n1. We have to predict \"Survived\" value on the test dataset.\n2. \"Name\" does not play a significant role in modelling.","a2abcfbd":"Checking for missing values in the dataset","d3caec03":"Evaluating model on training data","e552a085":"Shuffling the data","ec151f05":"# Implementing the pipeline<br>\nNotice that we have different pipeline for categorical features , embarked features and numerical features.<br>\nThis is because categorical values require filling \"missing\" value in their NaN cells , while embarked features require filling \"S\" in their NaN cells , which is most common there.<br>\nAlso numeric features do not need one hot encoder.","b879c823":"# Importing test data","83bff5e8":"# Importing the required tools","4e93a326":"In this notebook , sklearn pipeline is implemented to clean the data using simple imputer and one hot encoder and then train a RandomForest classification model.","b6ee2664":"# Importing the data","20693bd8":"Convert data type of \"Fare\" from float to integer"}}