{"cell_type":{"4947ba59":"code","af6c42f4":"code","1512b156":"code","ac5ed8f6":"code","0f1c6acf":"code","9f147243":"code","dbb9e25d":"code","dcf8883b":"code","b6a54120":"code","3558417d":"code","78809db2":"code","3f7a69ce":"code","9d183725":"code","8cea127f":"code","3af1fd86":"code","42f4db34":"code","0838f249":"code","5f7a59ad":"markdown","b1522e4e":"markdown"},"source":{"4947ba59":"!nvidia-smi ## Verificar placa de v\u00eddeo dispon\u00edvel no momento da execu\u00e7\u00e3o\n!mkdir out","af6c42f4":"!pip install -U sentence-transformers # instala requerimentos para execu\u00e7\u00e3o\n!pip install kaggle jsonlines","1512b156":"# imports\nimport pickle\nimport numpy\nimport random\nimport torch\nimport pandas as pd\nfrom torch.utils.data import DataLoader\n\nSEED=42\nrandom.seed(SEED); torch.manual_seed(SEED); numpy.random.seed(seed=SEED) # reproducibily soluction\n\n#hyper-parameters\nfold_id=0 # index fold\ndataset=\"python\"\nbatch_size=32\nmax_length = 256\nmax_epoch=1\nteste_rapido = False\nquantidade_amostra = 5000","ac5ed8f6":"!mkdir -p ~\/.kaggle\/ && echo '{\"username\":\"claudiovaliense\",\"key\":\"470f7d8c6f946fa5805921203bc1eca8\"}' > \/root\/.kaggle\/kaggle.json && chmod 600 ~\/.kaggle\/kaggle.json\n!kaggle datasets download --unzip -d celsofranssa\/xcoformer-datasets -p dataset\/","0f1c6acf":"data_dir=\"dataset\"\nwith open(f\"{data_dir}\/{dataset}\/samples.pkl\", \"rb\") as f:\n    samples=pickle.load(f)\nsamples_df = pd.DataFrame(samples)","9f147243":"def get_ids(path):\n    with open(path, \"rb\") as f:\n        return pickle.load(f)\n\nfolds=[]\nfor fold_idx in range(5):\n    folds.append({\n        \"fold_id\": fold_id,\n        \"splits\": {\n            \"train\": get_ids(f\"{data_dir}\/{dataset}\/fold_{fold_idx}\/train.pkl\"),\n            \"val\": get_ids(f\"{data_dir}\/{dataset}\/fold_{fold_idx}\/val.pkl\"),\n            \"test\": get_ids(f\"{data_dir}\/{dataset}\/fold_{fold_idx}\/test.pkl\")\n            }\n        })","dbb9e25d":"train_df = samples_df[samples_df[\"idx\"].isin(folds[fold_id][\"splits\"][\"train\"])] # filtrando documentos a partir dos ids\nval_df = samples_df[samples_df[\"idx\"].isin(folds[fold_id][\"splits\"][\"val\"])]\ntest_df = samples_df[samples_df[\"idx\"].isin(folds[fold_id][\"splits\"][\"test\"])]\n\nif teste_rapido == True:\n    train_df = train_df.sample(quantidade_amostra)\n    val_df = val_df.sample(quantidade_amostra)\n    #test_df = test_df.sample(quantidade_amostra)\n\n#train_df.to_json(f\"{data_dir}\/{dataset}\/fold_{fold_id}\/train.jsonl\", orient=\"records\", lines=True)\n#val_df.to_json(f\"{data_dir}\/{dataset}\/fold_{fold_id}\/val.jsonl\", orient=\"records\", lines=True)\n#test_df.to_json(f\"{data_dir}\/{dataset}\/fold_{fold_id}\/test.jsonl\", orient=\"records\", lines=True)","dcf8883b":"train_df","b6a54120":"from sentence_transformers import SentenceTransformer,  SentencesDataset, LoggingHandler, losses\nfrom sentence_transformers.readers import InputExample\n\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\n# 1 desc, 2 code\ntrain_examples = []\nfor row in train_df.itertuples(index=False):        \n    train_examples.append( InputExample(texts=[ str(row[0]), str(row[1]) ] ) )\n\ntrain_dataset = SentencesDataset(train_examples, model)\ntrain_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\ntrain_loss = losses.MultipleNegativesRankingLoss(model=model) #apenas o par \u00e9 i,i \u00e9 positivo, os pares  i.j s\u00e3o negativos\n\n#evaluator = evaluation.EmbeddingSimilarityEvaluator(sentences1, sentences2, scores)\n#sentence_transformers.evaluation.InformationRetrievalEvaluator\n\n","3558417d":"#model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=max_epoch)","78809db2":"# Salvar modelo\ntorch.save({'epoch': max_epoch, 'model_state_dict': model.state_dict(), 'loss': train_loss }, f'out\/model_sentence_bert_{dataset}_{fold_id}')","3f7a69ce":"code = model.encode( list( test_df['code'] ), convert_to_tensor=True  )\ndesc = model.encode( list( test_df['desc'] ), convert_to_tensor=True  )\n#temp.shape\n#for row in train_df.itertuples(index=False): \n    ","9d183725":"from sentence_transformers import SentenceTransformer, util\ntop_k=10\n#list_desc = list(test_df['desc'])\n#list_code = list(test_df['code'])\nlist_idx = numpy.array(list(test_df['idx']))\ndesc = torch.split(desc,batch_size) # limita\u00e7\u00e3o de RAM para calcular a matriz de cosseno\n\nindex_query=0\nposicoes = []\nfor desc_temp in  desc:\n    cosine_scores = util.pytorch_cos_sim(desc_temp, code)    #Compute cosine-similarits\n    top_results = torch.topk(cosine_scores, k=top_k)    \n    \n    for score, idx in zip(top_results[0], top_results[1]):              \n        idx_retornado = list_idx[idx.tolist()].tolist()  # encontra os idx retornados\n        \n        if list_idx[index_query] in idx_retornado: # verifica se idx esta no conjunto\n            posicao = idx_retornado.index (list_idx[index_query]) + 1                        \n        else:\n            posicao =  0\n        posicoes.append(posicao)\n        index_query+=1       \n        \n    #print( numpy.where( idx_retornado ==  list_idx[index_query] )[0] )\n    #print(f'idx retornado: {list_idx[idx.tolist()]} ')\n    #print(f'idx retornado: {list_idx[idx[0]]}')\n    #print(f'idx do codigo correto: {list_idx[index_query]}')\n    #print(list_desc[idx], \"(Score: {:.4f})\".format(score))\n    #print(f'query:\\n{list_desc[index_query]}\\ncode:\\n {list_code[idx]}\\n score:\\n {score}')\n","8cea127f":"def mrr_at_k(positions, k, num_samples):\n        \"\"\"\n        Evaluates the MMR considering only the positions up to k.\n        :param positions:\n        :param k:\n        :param num_samples:\n        :return:\n        \"\"\"\n        # positions_at_k = [p for p in positions if p <= k]\n        positions_at_k = [p if p <= k else 0 for p in positions]\n        rrank = 0.0\n        for pos in positions_at_k:\n            if pos != 0:\n                rrank += 1.0 \/ pos\n\n        return rrank \/ num_samples\n    \nmrr_1 = mrr_at_k(posicoes, 1, len(posicoes))\nmrr_5 = mrr_at_k(posicoes, 5, len(posicoes))\nmrr_10 = mrr_at_k(posicoes, 10, len(posicoes))\n\nimport jsonlines\nfrom datetime import datetime\ndata_e_hora_atuais = datetime.now()\ndata_e_hora_em_texto = data_e_hora_atuais.strftime('%d\/%m\/%Y %H:%M')\n\nescreve = jsonlines.open(f'out\/{dataset}_{fold_id}_pred.json', 'w')\nescreve.write( {'data_hora' : data_e_hora_em_texto })\nescreve.write( {'posicoes' : posicoes})\nescreve.write( {'mrr_1' : mrr_1, 'mrr_5' : mrr_5, 'mrr_10' : mrr_10}  )\nescreve.close()\n\nprint({'mrr_1' : mrr_1, 'mrr_5' : mrr_5, 'mrr_10' : mrr_10})","3af1fd86":"#Salvar dados no kaggle de forma permanente\n#!kaggle datasets init -p out\/\n#!echo '{ \"title\": \"sentence-bert\", \"id\": \"claudiovaliense\/data-baseline-sentence-bert\", \"licenses\": [ { \"name\": \"CC0-1.0\"} ]}' > out\/dataset-metadata.json\n#!kaggle datasets create -p out\/ --dir-mode zip # criar dataset ap\u00f3s ter o arquivo de metafile\n\n# atualizar dataset\n#!kaggle datasets download --unzip -d claudiovaliense\/data-baseline-sentence-bert -p out\/ # Download dos dados existente\n!kaggle datasets metadata -p out\/  claudiovaliense\/data-baseline-sentence-bert #download metafile\n!kaggle datasets version -p out\/ --dir-mode zip -m 'update'  # atualizar dataset\n\n","42f4db34":"#!cat out\/dataset-metadata.json\n!ls out\/","0838f249":"cont_patient = 0\nfor epoch in range(max_epoch): # max epoch\n    print(f'Epoch: {epoch}')\n    model.train()\n    for batch in train_dataloader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model(**batch)        \n        loss = outputs.loss\n        loss.backward()\n\n        #optimizer.step()\n        #lr_scheduler.step()\n        #optimizer.zero_grad()\n        \n    ","5f7a59ad":"Backup ------ (n\u00e3o executar)","b1522e4e":"Autentica\u00e7\u00e3o Kaggle"}}