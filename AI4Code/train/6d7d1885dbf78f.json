{"cell_type":{"d7c57cc4":"code","7de027e8":"code","6e9094eb":"code","a3b90d33":"code","a7bc41f7":"code","8532ac17":"code","20432456":"markdown","1a4516a6":"markdown","721e7bb4":"markdown"},"source":{"d7c57cc4":"\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n\ndavis = pd.read_csv(\"..\/input\/davis-data-set\/Davis.csv\")\n\ndavis.columns = ['id','sex', 'weight', 'height', 'repwt', 'repht']\ndavis.sex = pd.get_dummies(davis['sex'])\n\nprint(davis.head())\nprint()\nprint(davis.weight.corr(davis.height),\"correlation of weight by height \")\nprint(davis.weight.corr(davis.sex),\"correlation of weight by sex\")\n\nax = plt.gca()\nax.bar(davis.weight, davis.repwt, align='edge')\nax.set_xlabel('weight')\nax.set_ylabel('repwt')\nplt.show()\nsns.set(style = 'whitegrid', context = 'notebook')\ncols = ['sex','height', 'weight']\nsns.pairplot(davis[cols],height = 2.5)\nplt.show()\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score,mean_squared_error\ndavis.head()\nX = davis.loc[:,['sex','height']].values\nY = davis['weight'].values\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.3, random_state = 0)\n\nslr = LinearRegression()\nslr = slr.fit(X_train, Y_train)\ny_train_pred = slr.predict(X_train)\n\n\ny_test_pred = slr.predict(X_test)\nprint('R2 training: %.3f, test: %.3f' %(r2_score(Y_train, y_train_pred),r2_score(Y_test,y_test_pred)))\n\nx_davis_hght = davis.height.values\nx_davis_hght = np.resize(x_davis_hght, (200,1))\ny_train_pred_graph = np.resize(y_train_pred,(200,1))\ny_test_pred_graph = np.resize(y_test_pred,(200,1))\n\nplt.scatter(x_davis_hght, y_train_pred_graph, c = 'blue',marker ='o', label = 'Train Data')\nplt.scatter(x_davis_hght,y_test_pred_graph, c = 'black', marker = 's', label ='Test Data')\nplt.xlabel('height')\nplt.ylabel('weight')\nplt.legend(loc = 'upper left')\n\nplt.show()\n\nplt.scatter(y_train_pred, y_train_pred - Y_train, c = 'blue',marker ='o', label = 'Train Data')\nplt.scatter(y_test_pred, y_test_pred - Y_test, c = 'black', marker = 's', label ='Test Data')\nplt.xlabel('\u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435')\nplt.ylabel('\u043e\u0441\u0442\u0430\u0442\u043a\u0438')\nplt.legend(loc = 'upper left')\nplt.hlines(y = 0, xmin = 50, xmax = 100 , lw =2, color = 'red')\nplt.xlim([50,100])\nplt.show()","7de027e8":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\ntest = pd.read_csv(\"..\/input\/combined-cycle-power-plant-data-set\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/simple-linear-regression\/powerplant.csv\")\ntrain = train.fillna(train.median(axis=0), axis=0)\ntrain = (train  - train.mean()) \/ train.std()\nprint(train.tail())\nprint()\nprint(train.corr())\n\nsns.set(style = 'whitegrid', context = 'notebook')\ncols = ['AT', 'V', 'AP', 'RH', 'PE']\ncm = np.corrcoef(train[cols].values.T)\nsns.set(font_scale = 1)\nhm = sns.heatmap(cm, cbar = True, annot=True,square = True, fmt ='.2f', annot_kws ={'size':7 },yticklabels = cols, xticklabels = cols)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score,mean_squared_error\n\nX = train.loc[:,['AT', 'V', 'AP', 'RH']].values\nY = train.PE.values\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.3, random_state = 0)\n\nslr = LinearRegression()\nslr = slr.fit(X_train, Y_train)\ny_train_pred = slr.predict(X_train)\ny_test_pred = slr.predict(X_test)\n\nprint()\nprint('R2 training: %.3f, test: %.3f' %(r2_score(Y_train, y_train_pred),r2_score(Y_test,y_test_pred)))\nprint('Mean_squared: %.3f, test: %.3f' %(mean_squared_error(Y_train, y_train_pred),mean_squared_error(Y_test,y_test_pred)))\n\nX = train.iloc[:, :-1]\nY = train.iloc[:, -1]\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.3, random_state = 0)\n\nslr = RandomForestRegressor(n_estimators = 1000,criterion = 'mse',random_state = 1, n_jobs = -1)\nslr = slr.fit(X_train, Y_train)\n\ny_train_pred = slr.predict(X_train)\n\ny_test_pred = slr.predict(X_test)\nprint('R2 training: %.3f, test: %.3f' %(r2_score(Y_train, y_train_pred),r2_score(Y_test,y_test_pred)))\nprint('Mean_squared: %.3f, test: %.3f' %(mean_squared_error(Y_train, y_train_pred),mean_squared_error(Y_test,y_test_pred)))","6e9094eb":"x_train_AT = train.AT.values\nx_train_AT = np.resize(x_train_AT, (9567,1))\ny_train_pred_graph = np.resize(y_train_pred,(9567,1))\ny_test_pred_graph = np.resize(y_test_pred,(9567,1))\nplt.scatter(x_train_AT, y_train_pred_graph, c = 'blue',marker ='o', label = 'Train Data')\nplt.scatter(x_train_AT,y_test_pred_graph, c = 'black', marker = 's', label ='Test Data')\nplt.xlabel('AT')\nplt.ylabel('PE')\nplt.legend(loc = 'upper left')\nplt.xlim(-2,-1)\nplt.ylim(-2,-1)\n\nplt.show()\nprint(y_train_pred - Y_train)\n\nplt.scatter(y_train_pred, y_train_pred - Y_train, c = 'blue',marker ='o', label = 'Train Data')\nplt.scatter(y_test_pred, y_test_pred - Y_test, c = 'black', marker = 's', label ='Test Data')\nplt.xlabel('\u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435')\nplt.ylabel('\u043e\u0441\u0442\u0430\u0442\u043a\u0438')\nplt.legend(loc = 'upper left')\nplt.xlim(-1,1)\nplt.ylim(-0.1,0.1)\nplt.show()","a3b90d33":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nhousing = pd.read_csv(\"..\/input\/california-housing-prices\/housing.csv\")\nhousing.columns = ['longitude','latitude','housing_median_age','total_rooms','total_bedrooms','population','households','median_income','median_house_value','ocean_proximity']\nhousing.ocean_proximity = pd.get_dummies(housing['ocean_proximity'])\n\ndisplay(housing)\n\nhousing = housing.fillna(housing.median(axis=0), axis=0)\n\nhousing = (housing  - housing.mean()) \/ housing.std()\nprint(housing.describe())\nprint(housing.corr())\nsns.set(style = 'whitegrid', context = 'notebook')\ncols = ['longitude','latitude','housing_median_age','total_rooms','total_bedrooms','population','households','median_income','median_house_value','ocean_proximity']\ncm = np.corrcoef(housing[cols].values.T)\nsns.set(font_scale = 1)\nhm = sns.heatmap(cm, cbar = True, annot=True,square = True, fmt ='.2f', annot_kws ={'size':7 },yticklabels = cols, xticklabels = cols)","a7bc41f7":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score\n\nX = housing.loc[:,['longitude','latitude','housing_median_age','total_rooms','ocean_proximity','median_income']].values\nY = housing['median_house_value'].values\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.3, random_state = 0)\n\nslr = RandomForestRegressor(n_estimators = 1000,criterion = 'mse',random_state = 1, n_jobs = -1)\nslr = slr.fit(X_train, Y_train)\n\ny_train_pred = slr.predict(X_train)\n\ny_test_pred = slr.predict(X_test)\nprint('R2 training: %.3f, test: %.3f' %(r2_score(Y_train, y_train_pred),r2_score(Y_test,y_test_pred)))\nprint('Mean_squared: %.3f, test: %.3f' %(mean_squared_error(Y_train, y_train_pred),mean_squared_error(Y_test,y_test_pred)))","8532ac17":"plt.scatter(y_train_pred,y_train_pred - Y_train,c = 'black',marker = 'o', s = 35, alpha = 0.5, label = 'train data')\nplt.scatter(y_test_pred,y_test_pred - Y_test, c = 'blue', marker = 's', s = 35,alpha = 0.5 , label = 'test data')\n\nplt.show()\n\nx_ocean_inc = np.resize(housing.ocean_proximity.values,(100,1))\ny_housing_med_inc = np.resize(housing['median_house_value'].values,(100,1))\n\ny_test_pred_graph = np.resize(y_test_pred,(100,1))\nx = np.resize(np.arange(1,100),(100,1))\nplt.scatter(x,y_test_pred_graph, c = 'black', marker = 's', label ='Test_Data')\nplt.scatter(x,y_housing_med_inc, c = 'red', marker = 'o', label = 'Table_Data')\nplt.xlabel('ocean_proximuty')\nplt.ylabel('median_value')\n\nplt.legend(loc = 'upper left')\n\n\nplt.show()\n\nplt.scatter(y_train_pred, y_train_pred - Y_train, c = 'blue',marker ='o', label = 'Train Data')\nplt.scatter(y_test_pred, y_test_pred - Y_test, c = 'black', marker = 's', label ='Test Data')\nplt.xlabel('\u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435')\nplt.ylabel('\u043e\u0441\u0442\u0430\u0442\u043a\u0438')\nplt.legend(loc = 'upper left')\n\nplt.xlim(-0.1,0.1)\nplt.ylim(-0.5,0.5)\nplt.show()","20432456":"**NUMBER 3**","1a4516a6":"**NUMBER 1**","721e7bb4":"**NUMBER 2**"}}