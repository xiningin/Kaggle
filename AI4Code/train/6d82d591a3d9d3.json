{"cell_type":{"1b5425d8":"code","ff469549":"code","d83cd95b":"code","b8b55ec1":"code","5e3a6344":"code","0abc0211":"code","87a862ff":"code","6ff29fdb":"code","9d182440":"code","8c11f134":"code","92450f99":"code","f9c31501":"code","b80bffdb":"code","032aeeba":"code","486fc9d5":"code","f7ba8aa8":"code","2dad7a44":"code","02fcae8c":"code","19d4043b":"code","92a521c4":"code","682bfb37":"code","692bbc09":"code","2e225b62":"code","e799de0f":"code","7ee7c5e6":"code","740f9cdb":"code","f9580d53":"code","a93dd9fa":"code","9523de3d":"code","1ef7f15b":"code","9855820b":"code","d4c19c58":"code","3723a0d6":"code","37e9b149":"code","06513b9b":"code","98158534":"code","94f3b123":"code","60c4b233":"code","ba28f50d":"code","2dc246fc":"code","215d05c7":"code","8b8d30f9":"markdown","45bea438":"markdown","176302ce":"markdown","a091c9cb":"markdown","80c597d5":"markdown","179c813b":"markdown","c3eb62b1":"markdown","60cdc4e5":"markdown","635428b5":"markdown","4946620d":"markdown","f0ad4ffb":"markdown","289be9a6":"markdown","52adda74":"markdown","4c3d4d97":"markdown","ac46f3c2":"markdown","dc534e69":"markdown","db8d36c1":"markdown","57cd413d":"markdown","09be80df":"markdown","df69fea2":"markdown","b23317eb":"markdown","337eac7d":"markdown","68190121":"markdown","45f82a78":"markdown","d484b700":"markdown","66715e50":"markdown","99f96c7e":"markdown","b94a80ca":"markdown","cf92f691":"markdown","6c3c4fd2":"markdown","fce7358c":"markdown","f5b0b087":"markdown","4acfff77":"markdown"},"source":{"1b5425d8":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ff469549":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve","d83cd95b":"df = pd.read_csv('\/kaggle\/input\/water-potability\/water_potability.csv')\ndf.sample(5)","b8b55ec1":"print('Number of rows:', df.shape[0])","5e3a6344":"print('Number of features:', df.shape[1])","0abc0211":"df.info()","87a862ff":"df.describe()","6ff29fdb":"plt.figure(figsize=(12, 8))\nsns.countplot(data=df, x='Potability')\nplt.show()","9d182440":"df['Potability'].value_counts() \/ df.shape[0] * 100","8c11f134":"plt.figure(figsize=(12, 8))\nsns.barplot(y=df.isna().sum().index, x=df.isna().sum().values \/ len(df) * 100)\nplt.title('Missing data')\nplt.xlabel('Missing values (%)')\nplt.ylabel('Features')\nplt.show()","92450f99":"train, test = train_test_split(\n    df, stratify=df['Potability'],\n    random_state=42\n)","f9c31501":"def plot_hist(col):\n    plt.figure(figsize=(12, 8))\n    sns.histplot(data=train, x=col, hue='Potability')\n    plt.show()","b80bffdb":"features = ['ph', 'Hardness', 'Solids', 'Chloramines', 'Sulfate', 'Conductivity', \n            'Organic_carbon', 'Trihalomethanes', 'Turbidity']","032aeeba":"for col in features:\n    plot_hist(col)","486fc9d5":"plt.figure(figsize=(12, 8))\nmask = np.zeros_like(train[features].corr())\nmask[np.triu_indices_from(mask)] = True\nsns.heatmap(train[features].corr(), annot=True, cmap='viridis', fmt='.2f', mask=mask)\nplt.show()","f7ba8aa8":"X = train.copy()\ny = X.pop('Potability')\n\nX_train, X_valid, y_train, y_valid = train_test_split(\n    X, y, stratify=y,\n    random_state=42\n)","2dad7a44":"# fill in missing value and rescale for training set\n\nbaseline_imputer = SimpleImputer(strategy='median')\nbaseline_scaler = StandardScaler()\n\nX_train = baseline_imputer.fit_transform(X_train)\nX_train = baseline_scaler.fit_transform(X_train)","02fcae8c":"# fill in missing value and rescale for valid set\n\nX_valid = baseline_imputer.transform(X_valid)\nX_valid = baseline_scaler.transform(X_valid)","19d4043b":"# baseline model (Logistic Regression algorithm)\n\nbaseline_model = LogisticRegression()\nbaseline_model.fit(X_train, y_train)","92a521c4":"# Predict\n\ny_pred = baseline_model.predict(X_valid)","682bfb37":"# Evaluate\n\nprint(f'Accuracy: {accuracy_score(y_valid, y_pred) * 100:.2f}%')","692bbc09":"sns.heatmap(confusion_matrix(y_valid, y_pred, normalize='true'), annot=True, fmt='.2f', cmap='viridis')\nplt.xlabel('Predict')\nplt.ylabel('Actual')\nplt.show()","2e225b62":"print(classification_report(y_valid, y_pred))","e799de0f":"yhat = baseline_model.predict_proba(X_valid)\n# keep probabilities for the positive outcome only\nyhat = yhat[:, 1]\n# calculate roc curves\nfpr, tpr, thresholds = roc_curve(y_valid, yhat)\n# plot the roc curve for the model\nplt.figure(figsize=(12, 8))\nplt.plot([0,1], [0,1], linestyle='--', label='No Skill')\nplt.plot(fpr, tpr, marker='.', label='Logistic')\n# axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend()\n# show the plot\nplt.show()","7ee7c5e6":"print(f'Train Accuracy: {accuracy_score(y_train, baseline_model.predict(X_train)) * 100:.2f}%')","740f9cdb":"poly = PolynomialFeatures(3)\nX_train = poly.fit_transform(X_train)\nX_valid = poly.fit_transform(X_valid)","f9580d53":"print(f'Number of features: {X_train.shape[1]}')","a93dd9fa":"inc_features_model = LogisticRegression(solver='liblinear')\ninc_features_model.fit(X_train, y_train)\ny_pred = inc_features_model.predict(X_valid)\nprint(f'Training Set Accuracy: {accuracy_score(y_train, inc_features_model.predict(X_train)) * 100:.2f}%')\nprint(f'Valid Set Accuracy: {accuracy_score(y_valid, y_pred) * 100:.2f}%')","9523de3d":"inc_features_model = LogisticRegression(solver='liblinear', C=0.05)\ninc_features_model.fit(X_train, y_train)\ny_pred = inc_features_model.predict(X_valid)\nprint(f'Training Set Accuracy: {accuracy_score(y_train, inc_features_model.predict(X_train)) * 100:.2f}%')\nprint(f'Valid Set Accuracy: {accuracy_score(y_valid, y_pred) * 100:.2f}%')","1ef7f15b":"import optuna","9855820b":"# Turn off optuna verbose\n# optuna.logging.set_verbosity(optuna.logging.WARNING)","d4c19c58":"def score_dataset(X_train, X_valid, y_train, y_valid, model):\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_valid)\n    score = accuracy_score(y_valid, y_pred)\n    return score","3723a0d6":"def objective(trial):\n    logistic_params = dict(\n        penalty=trial.suggest_categorical('penalty', ['l1', 'l2']),\n        C=trial.suggest_float('C', 1e-6, 1e1),\n        warm_start=trial.suggest_categorical('warm_start', [True, False]),\n    )\n    logistic = LogisticRegression(**logistic_params, solver='liblinear')\n    return score_dataset(X_train, X_valid, y_train, y_valid, logistic)\n\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=100)\nlogistic_params = study.best_params","37e9b149":"print('Best hyperparameters found!')\nprint(logistic_params)","06513b9b":"tuning_model = LogisticRegression(**logistic_params, solver='liblinear')\ntuning_model.fit(X_train, y_train)\ny_pred = tuning_model.predict(X_valid)\nprint(f'Training Set Accuracy: {accuracy_score(y_train, tuning_model.predict(X_train)) * 100:.2f}%')\nprint(f'Valid Set Accuracy: {accuracy_score(y_valid, y_pred) * 100:.2f}%')","98158534":"sns.heatmap(confusion_matrix(y_valid, y_pred, normalize='true'), annot=True, fmt='.2f', cmap='viridis')\nplt.xlabel('Predict')\nplt.ylabel('Actual')\nplt.show()","94f3b123":"print(classification_report(y_valid, y_pred))","60c4b233":"yhat = tuning_model.predict_proba(X_valid)\n# keep probabilities for the positive outcome only\nyhat = yhat[:, 1]\n# calculate roc curves\nfpr, tpr, thresholds = roc_curve(y_valid, yhat)\n# plot the roc curve for the model\nplt.figure(figsize=(12, 8))\nplt.plot([0,1], [0,1], linestyle='--', label='No Skill')\nplt.plot(fpr, tpr, marker='.', label='Logistic')\n# axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend()\n# show the plot\nplt.show()","ba28f50d":"from sklearn.model_selection import ShuffleSplit, learning_curve","2dc246fc":"def plot_learning_curve(estimator, X, y, ylim=None, cv=None,\n                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5), title=None):\n    f, ax = plt.subplots(figsize=(12, 8))\n    if ylim is not None:\n        plt.ylim(*ylim)\n    # First Estimator\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    ax.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color='#ff9124')\n    ax.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color='#2492ff')\n    ax.plot(train_sizes, train_scores_mean, 'o-', color='#ff9124',\n             label='Training score')\n    ax.plot(train_sizes, test_scores_mean, 'o-', color='#2492ff',\n             label='Cross-validation score')\n    ax.set_title(title, fontsize=14)\n    ax.set_xlabel('Training size (m)')\n    ax.set_ylabel('Score')\n    ax.grid(True)\n    ax.legend(loc='best')\n    plt.show()","215d05c7":"cv = ShuffleSplit(n_splits=50, test_size=0.2, random_state=42)\n\nplot_learning_curve(\n    tuning_model, X_train, y_train,\n    (0, 1.01), cv=cv, n_jobs=4,\n    title='XGB Learning Curve'\n)","8b8d30f9":"According to WHO, infectious diseases caused by lack of water and unsanitary living environment cause **01 infant death** every minute. The bad thing is that the world's clean water is gradually running out.\n\nThe reality is that **almost 70%** of the earth's surface is covered with water, but only 2.5% of that water is pure water suitable for consumption. Therefore, water is an important resource that we need to preserve first.\nWith about 2 billion tons of waste entering water sources every day, people still face the challenge of water pollution around the world.\n\nAccording to the United Nations report, up to 2.2 billion people are living without clean water, while those without access to basic sanitation amount to 4.2 billion people.\nIt is forecasted that by 2030, about 60 countries will experience severe water shortage. Annual; 3.6 million people die from diseases caused by polluted water.\nAccording to the World Bank, in the not too distant future, clean water can be a factor causing political instability, armed conflict or reducing economic growth, poverty, and disease.\n\n***Source: City Children\u2019s Hospital, Ho Chi Minh City***","45bea438":"I will use PolynomialFeatures() to increase the number of features by combining them to form new features of higher order. Specifically, here is 3.","176302ce":"**Attention**: before dive deeper dataset, we must split dataset into training-set and test-set. This is to ensure that, after we have created the predictive model, there is a metric against which to evaluate the model objectively.","a091c9cb":"Model can't detect class '1'.","80c597d5":"<hr>","179c813b":"***To be continue...***","c3eb62b1":"<div style=\"background-color: #CDF3A2; color:#ED8E7C;\">\n    <h1><center>Introduction<\/center><\/h1>\n<\/div>","60cdc4e5":"Evaluate model on training-set.","635428b5":"Above we have separated training-set and test-set, testset will be meaningful as future data, so we need one more metric, evaluate the model during training, hyperparameters tuning, It's valid-set! ![image.png](attachment:106aaa75-3f70-4ce7-bada-19dbdcd8b236.png)","4946620d":"In addition to data processing, the choice of hyperparameters is also important. But with a large number of hyperparameters, we need a method that can automatically find them.\n\nI use optuna to tuning hypterparameters. You guy can use RandomizedSearchCV in scikit-learn.","f0ad4ffb":"To solve this problem, we need to:\n\n* Increase samples with class '1'\n* Increase the number of features\n* Adjust hyperparameters\n* Use more complex algorithms or models\n* Increase training time, number of epochs","289be9a6":"It's not possible to collect more data for me, so I'll apply the remaining steps.","52adda74":"Unexpectedly, when the data set is quite difficult, our prediction model is only close to 61% accurate. To improve accuracy, we will need to analyze, do further processing, or use other more powerful algorithms.","4c3d4d97":"Dataset have target with rate **61**:**39** (**Not Potabilty** : **Potability**). Slightly imbalance.","ac46f3c2":"After increasing the number of features with PolynomialFeatures(), from 9 features we will have 220 features.","dc534e69":"With the **Water Quality** data set, I will learn what factors determine the safety of drinking water, as well as a Machine learning application that predicts whether a sample of water is drinkable or not.","db8d36c1":"I will use Logistic Regression algorithm in sciki-learn library. However, to use it, we need to remove, or fill in, missing values.\n\nFurthermore, for easy convergence, we need to rescale the values.\n\nTherefore, there are 2 steps here:\n* **fill in missing value with median of these feature**\n* **rescale to standard distribution**\n\nAlgorithm hyperparameters is be default, we will improve later.","57cd413d":"## 1. Baseline Model","09be80df":"<div style=\"background-color: #CDF3A2\">\n    <center><img src=\"https:\/\/raw.githubusercontent.com\/jaykumar1607\/Water-Quality\/main\/water_sanitation.gif\"><\/center>\n<\/div>","df69fea2":"All features have values in valid range.","b23317eb":"<div style=\"background-color: #CDF3A2; color:#ED8E7C;\">\n    <h1><center>Model<\/center><\/h1>\n<\/div>","337eac7d":"The correlation between the features in the water.","68190121":"We can see that,\n* Training Error = 38.71%\n* Validation Error = 39.19%\nWe have **bias** is **38.71%**, **variance is 0.48%**. So the model is **underfitting**.","45f82a78":"## Increase the number of features","d484b700":"Due to the large number of features, we need to adjust the regularization parameter, here is the \"C\" parameter. By default in sciki-learn library, LogisticRegression has C=1, we will reduce it by 1 to reduce the impact of features, here is 0.05.","66715e50":"<hr>","99f96c7e":"* Feature **ph** has 15% missing values\n* Feature **Sulfate** has 24% missing values\n* Feature **Trihalomethanes** has 5% missing values","b94a80ca":"It can be seen that this dataset is quite difficult, when the features of the target all have the same distribution.","cf92f691":"<div style=\"background-color: #CDF3A2; color:#ED8E7C;\">\n    <h1><center>EDA<\/center><\/h1>\n<\/div>","6c3c4fd2":"* **ph**: PH is an important parameter in evaluating the acid\u2013base balance of water. It is also the indicator of acidic or alkaline condition of water status. WHO has recommended maximum permissible limit of pH from 6.5 to 8.5. The current investigation ranges were 6.52\u20136.83 which are in the range of WHO standards.\n\n* **Hardness**: Hardness is mainly caused by calcium and magnesium salts. These salts are dissolved from geologic deposits through which water travels. The length of time water is in contact with hardness producing material helps determine how much hardness there is in raw water. Hardness was originally defined as the capacity of water to precipitate soap caused by Calcium and Magnesium.\n\n* **Solids**: Water has the ability to dissolve a wide range of inorganic and some organic minerals or salts such as potassium, calcium, sodium, bicarbonates, chlorides, magnesium, sulfates etc. These minerals produced un-wanted taste and diluted color in appearance of water. This is the important parameter for the use of water. The water with high TDS value indicates that water is highly mineralized. Desirable limit for TDS is 500 mg\/l and maximum limit is 1000 mg\/l which prescribed for drinking purpose.\n\n* **Chloramines**: Chlorine and chloramine are the major disinfectants used in public water systems. Chloramines are most commonly formed when ammonia is added to chlorine to treat drinking water. Chlorine levels up to 4 milligrams per liter (mg\/L or 4 parts per million (ppm)) are considered safe in drinking water.\n\n* **Sulfate**: Sulfates are naturally occurring substances that are found in minerals, soil, and rocks. They are present in ambient air, groundwater, plants, and food. The principal commercial use of sulfate is in the chemical industry. Sulfate concentration in seawater is about 2,700 milligrams per liter (mg\/L). It ranges from 3 to 30 mg\/L in most freshwater supplies, although much higher concentrations (1000 mg\/L) are found in some geographic locations.\n\n* **Conductivity**: Pure water is not a good conductor of electric current rather\u2019s a good insulator. Increase in ions concentration enhances the electrical conductivity of water. Generally, the amount of dissolved solids in water determines the electrical conductivity. Electrical conductivity (EC) actually measures the ionic process of a solution that enables it to transmit current. According to WHO standards, EC value should not exceeded 400 \u03bcS\/cm.\n\n* **Trihalomethanes**: THMs are chemicals which may be found in water treated with chlorine. The concentration of THMs in drinking water varies according to the level of organic material in the water, the amount of chlorine required to treat the water, and the temperature of the water that is being treated. THM levels up to 80 ppm is considered safe in drinking water.\n\n* **Organic_carbon**: Total Organic Carbon (TOC) in source waters comes from decaying natural organic matter (NOM) as well as synthetic sources. TOC is a measure of the total amount of carbon in organic compounds in pure water. According to US EPA < 2 mg\/L as TOC in treated \/ drinking water, and < 4 mg\/Lit in source water which is use for treatment.\n\n* **Turbidity**: The turbidity of water depends on the quantity of solid matter present in the suspended state. It is a measure of light emitting properties of water and the test is used to indicate the quality of waste discharge with respect to colloidal matter. The mean turbidity value obtained for Wondo Genet Campus (0.98 NTU) is lower than the WHO recommended value of 5.00 NTU.\n\n* **Potability**: Indicates if water is safe for human consumption where **1** means **Potable** and **0** means **Not potable**.","fce7358c":"**Logistic Regression Tuning Hyperparameters**","f5b0b087":"We have **3276 samples** and **09 features**:","4acfff77":"Compared to baseline, accuracy has **increased by 8.30%**."}}