{"cell_type":{"63ac6b8f":"code","fc30744a":"code","6b555dac":"code","a728bd81":"code","b8e34999":"code","4128c883":"code","05fede49":"code","d180aefc":"code","52dde09a":"code","29f2420c":"code","16175fa6":"code","6b3b16dd":"code","7bf48198":"code","edf8f9e3":"code","245dfba5":"code","a05733fc":"code","dd36e69e":"code","1d52da4f":"code","b234ce34":"code","d2e32063":"code","68463f51":"code","79572c86":"code","aa36c87c":"code","6e75515d":"code","9dfaa4ab":"code","c3b54fc5":"code","a02761a2":"code","0dfd72a0":"code","e950efc4":"code","08b6e8c9":"code","8f3c7de7":"code","f173c029":"code","05b77949":"code","02fb5d71":"code","8137eb29":"code","042ca148":"code","4b31d40a":"code","ed36c2fd":"code","44da9821":"code","a9ee2205":"code","cad04b36":"code","8a4e7a34":"code","f6cba84b":"code","c9b700ec":"code","ac231d90":"code","27194df4":"code","fc0ec2ed":"code","bf7c772b":"code","c4da340b":"markdown","1ae0e652":"markdown","d7d81ac7":"markdown","8df88325":"markdown"},"source":{"63ac6b8f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fc30744a":"!pip install git+https:\/\/github.com\/aleju\/imgaug.git","6b555dac":"!git clone https:\/\/github.com\/ahmadelsallab\/MultiCheXNet.git","a728bd81":"##!rm -r \/kaggle\/working\/MultiCheXNet\/","b8e34999":"# https:\/\/www.kaggle.com\/cpmpml\/fast-iou-metric-in-numpy-and-tensorflow\nimport tensorflow.keras.backend as K\nimport tensorflow as tf\nimport numpy as np\ndef get_iou_vector(A, B):\n    # Numpy version\n    B = K.cast(B, 'float32')\n    batch_size = A.shape[0]\n    if batch_size is None:\n      batch_size = 0\n    metric = 0.0\n    for batch in range(batch_size):\n        t, p = A[batch], B[batch]\n        true = np.sum(t)\n        pred = np.sum(p)\n\n        # deal with empty mask first\n        if true == 0:\n            pred_batch_size = pred \/ ( p.shape[0] * p.shape[1] )\n            if pred_batch_size > 0.03:\n               pred_batch_size = 1 \n            metric +=  1 - pred_batch_size\n            continue\n        \n        # non empty mask case.  Union is never empty \n        # hence it is safe to divide by its number of pixels\n\n        intersection = np.sum(t * p)\n        union = true + pred - intersection\n        iou = intersection \/ union\n        \n        # iou metrric is a stepwise approximation of the real iou over 0.5\n        iou = np.floor(max(0, (iou - 0.45)*20)) \/ 10\n        \n        metric += iou\n        \n    # teake the average over all images in batch\n    metric \/= batch_size\n    return metric\n\n\ndef my_iou_metric(label, pred):\n    # Tensorflow version\n    return tf.py_function(get_iou_vector, [label, pred > 0.5], tf.float64)\n","4128c883":"import tensorflow.keras.backend as K\ndef dice_coef(y_true, y_pred, smooth=1):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    return (2. * intersection + smooth) \/ (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1-dice_coef(y_true, y_pred)\n\ndef dice_loss(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n\n    intersection = y_true_f * y_pred_f\n    score = (200. * K.sum(intersection) + smooth) \/ (100. * K.sum(y_true_f) + 100.* K.sum(y_pred_f) + smooth)\n    return  (1. - score)\n\ndef bce_dice_loss(y_true, y_pred):\n    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n\ndef bce_logdice_loss(y_true, y_pred):\n    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))","05fede49":"\n\n\ndef binary_focal_loss(gamma=2., alpha=.25):\n    \"\"\"\n    Binary form of focal loss.\n      FL(p_t) = -alpha * (1 - p_t)**gamma * log(p_t)\n      where p = sigmoid(x), p_t = p or 1 - p depending on if the label is 1 or 0, respectively.\n    References:\n        https:\/\/arxiv.org\/pdf\/1708.02002.pdf\n    Usage:\n     model.compile(loss=[binary_focal_loss(alpha=.25, gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n    \"\"\"\n    def binary_focal_loss_fixed(y_true, y_pred):\n        \"\"\"\n        :param y_true: A tensor of the same shape as `y_pred`\n        :param y_pred:  A tensor resulting from a sigmoid\n        :return: Output tensor.\n        \"\"\"\n        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n\n        epsilon = K.epsilon()\n        # clip to prevent NaN's and Inf's\n        pt_1 = K.clip(pt_1, epsilon, 1. - epsilon)\n        pt_0 = K.clip(pt_0, epsilon, 1. - epsilon)\n\n        return -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) \\\n               -K.mean((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n\n    return binary_focal_loss_fixed","d180aefc":"def jaccard_distance_loss(y_true, y_pred, smooth=100):\n    \"\"\"\n    Jaccard = (|X & Y|)\/ (|X|+ |Y| - |X & Y|)\n            = sum(|A*B|)\/(sum(|A|)+sum(|B|)-sum(|A*B|))\n    \n    The jaccard distance loss is usefull for unbalanced datasets. This has been\n    shifted so it converges on 0 and is smoothed to avoid exploding or disapearing\n    gradient.\n    \n    Ref: https:\/\/en.wikipedia.org\/wiki\/Jaccard_index\n    \n    @url: https:\/\/gist.github.com\/wassname\/f1452b748efcbeb4cb9b1d059dce6f96\n    @author: wassname\n    \"\"\"\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n    jac = (intersection + smooth) \/ (sum_ - intersection + smooth)\n    return (1 - jac) * smooth","52dde09a":"from MultiCheXNet.data_loader.SIIM_ACR_dataloader import get_train_validation_generator\nfrom MultiCheXNet.MTL_model import MTL_model\nfrom tensorflow.keras.optimizers import Adam","29f2420c":"seg_csv_path = \"\/kaggle\/input\/siim-acr-pneumothorax-segmentation-data\/train-rle.csv\"\nseg_images_path = \"\/kaggle\/input\/siim-acr-pneumothorax-segmentation-data\/dicom-images-train\/\"","16175fa6":"train_gen,val_gen = get_train_validation_generator(seg_csv_path , seg_images_path, only_positive=False, augmentation=True,hist_eq=True,batch_positive_portion=0.5 )","6b3b16dd":"X,Y = next(enumerate(train_gen))[1]","7bf48198":"import matplotlib.pyplot as plt\nimport numpy as np\nfor yy in Y:\n    plt.imshow(np.squeeze(yy))\n    plt.show()","edf8f9e3":"MTL_model_clss = MTL_model(add_class_head=False,add_detector_head=False,add_segmenter_head=True)","245dfba5":"model = MTL_model_clss.MTL_model","a05733fc":"lr=1e-4\nepochs=10\nmodel.compile(loss= binary_focal_loss(), optimizer=Adam(lr) , metrics=[ dice_coef , my_iou_metric])","dd36e69e":"hist= model.fit_generator(train_gen, validation_data=val_gen, epochs=epochs,class_weight={0:1,1:100} )","1d52da4f":"#0.1\n#0.978\n#0.77","b234ce34":"#0.04\n#0.93\n#0.01","d2e32063":"from tensorflow.keras.layers import *\ndef dense_block(x, blocks, name):\n    #REF: keras-team\n    \"\"\"A dense block.\n    # Arguments\n        x: input tensor.\n        blocks: integer, the number of building blocks.\n        name: string, block label.\n    # Returns\n        output tensor for the block.\n    \"\"\"\n    for i in range(blocks):\n        x = conv_block(x, 32, name=name + '_block' + str(i + 1))\n    return x\ndef conv_block(x, growth_rate, name):\n    #REF: keras-team\n    \"\"\"A building block for a dense block.\n    # Arguments\n        x: input tensor.\n        growth_rate: float, growth rate at dense layers.\n        name: string, block label.\n    # Returns\n        Output tensor for the block.\n    \"\"\"\n    bn_axis = 3\n    x1 = BatchNormalization(axis=bn_axis,\n                                   epsilon=1.001e-5,\n                                   name=name + '_0_bn')(x)\n    x1 = Activation('relu', name=name + '_0_relu')(x1)\n    x1 = Conv2D(4 * growth_rate, 1,\n                       use_bias=False,\n                       name=name + '_1_conv')(x1)\n    x1 = BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n                                   name=name + '_1_bn')(x1)\n    x1 = Activation('relu', name=name + '_1_relu')(x1)\n    x1 = Conv2D(growth_rate, 3,\n                       padding='same',\n                       use_bias=False,\n                       name=name + '_2_conv')(x1)\n    x = Concatenate(axis=bn_axis, name=name + '_concat')([x, x1])\n    return x\n\ndef transition_up(x, encoder, skip_connection, out_channels, kernel_size=(3,3), stride=(2,2)):\n    tu = Conv2DTranspose(out_channels, kernel_size, strides = stride, padding = 'same')(x)\n    skip = encoder.layers[skip_connection].output\n    c = concatenate([skip,tu], axis=3)\n    return c","68463f51":"from MultiCheXNet.utils.Encoder import Encoder\nfrom MultiCheXNet.utils.ModelBlock import ModelBlock\nfrom MultiCheXNet.utils.Segmenter import Segmenter ","79572c86":"encoder_class = Encoder(weights=None)\nseg_head= Segmenter(encoder_class)","aa36c87c":"model = ModelBlock.add_heads(encoder_class ,[seg_head] )","6e75515d":"# https:\/\/www.kaggle.com\/cpmpml\/fast-iou-metric-in-numpy-and-tensorflow\nfrom keras import backend as K\ndef get_iou_vector(A, B):\n    # Numpy version\n    B = K.cast(B, 'float32')\n    batch_size = A.shape[0]\n    if batch_size is None:\n      batch_size = 0\n    metric = 0.0\n    for batch in range(batch_size):\n        t, p = A[batch], B[batch]\n        true = np.sum(t)\n        pred = np.sum(p)\n\n        # deal with empty mask first\n        if true == 0:\n            pred_batch_size = pred \/ ( p.shape[0] * p.shape[1] )\n            if pred_batch_size > 0.03:\n               pred_batch_size = 1 \n            metric +=  1 - pred_batch_size\n            continue\n        \n        # non empty mask case.  Union is never empty \n        # hence it is safe to divide by its number of pixels\n\n        intersection = np.sum(t * p)\n        union = true + pred - intersection\n        iou = intersection \/ union\n        \n        # iou metrric is a stepwise approximation of the real iou over 0.5\n        iou = np.floor(max(0, (iou - 0.45)*20)) \/ 10\n        \n        metric += iou\n        \n    # teake the average over all images in batch\n    metric \/= batch_size\n    return metric\n\n\ndef my_iou_metric(label, pred):\n    # Tensorflow version\n    return tf.py_function(get_iou_vector, [label, pred > 0.5], tf.float64)\n","9dfaa4ab":"def dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred = K.cast(y_pred, 'float32')\n    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n    intersection = y_true_f * y_pred_f\n    score = 2. * K.sum(intersection) \/ (K.sum(y_true_f) + K.sum(y_pred_f))\n    return 100 * score\ndef bce_dice_loss(y_true, y_pred):\n    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n","c3b54fc5":"from MultiCheXNet.data_loader.SIIM_ACR_dataloader import get_train_validation_generator\nseg_csv_path = \"\/kaggle\/input\/siim-acr-pneumothorax-segmentation-data\/train-rle.csv\"\nseg_images_path = \"\/kaggle\/input\/siim-acr-pneumothorax-segmentation-data\/dicom-images-train\/\"\n\nseg_train_gen , seg_val_gen = get_train_validation_generator(seg_csv_path,seg_images_path ,augmentation=True,hist_eq=True,normalize=True )","a02761a2":"import tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras.optimizers import Adam\nmodel.compile(loss= \"binary_crossentropy\", optimizer=Adam(1e-4), metrics=[dice_coef,my_iou_metric])","0dfd72a0":"model.fit_generator(seg_train_gen,validation_data=seg_val_gen , epochs=20)","e950efc4":"skip_layers = [308,136,48]\nblocks = [3, 3, 3, 3]\n\ndb5 = encoder.output #(8,8,1024)\ntu5 = transition_up(db5, encoder, skip_layers[0], 3)\n\ndb6 = dense_block(tu5, blocks[-1], name='conv6')\ntu6 = transition_up(db6, encoder, skip_layers[1], 3)\n\ndb7 = dense_block(tu6, blocks[-2], name='conv7')\ntu7 = transition_up(db7, encoder, skip_layers[2], 3)\n\ndb8 = dense_block(tu7, blocks[-3], name='conv8')\ntu8 = Conv2DTranspose(256, (3, 3), strides = (2, 2), padding = 'same')(db8)#(128,128,)\n\nuconv9 = Conv2D(512, (3, 3), activation = 'relu', padding = 'same')(tu8)\ntu9 = Conv2DTranspose(256, (3, 3), strides = (2, 2), padding = 'same')(uconv9)#(256,256,)\noutputs = Conv2D(1, (1, 1), activation = 'sigmoid')(tu9)","08b6e8c9":"def dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred = K.cast(y_pred, 'float32')\n    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n    intersection = y_true_f * y_pred_f\n    score = 2. * K.sum(intersection) \/ (K.sum(y_true_f) + K.sum(y_pred_f))\n    return 100 * score\n\ndef dice_loss(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n\n    intersection = y_true_f * y_pred_f\n    score = (200. * K.sum(intersection) + smooth) \/ (100. * K.sum(y_true_f) + 100.* K.sum(y_pred_f) + smooth)\n    return  (1. - score)\n\ndef bce_dice_loss(y_true, y_pred):\n    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n\ndef bce_logdice_loss(y_true, y_pred):\n    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))","8f3c7de7":"from MultiCheXNet.data_loader.SIIM_ACR_dataloader import get_train_validation_generator\n","f173c029":"seg_csv_path = \"\/kaggle\/input\/siim-acr-pneumothorax-segmentation-data\/train-rle.csv\"\nseg_images_path = \"\/kaggle\/input\/siim-acr-pneumothorax-segmentation-data\/dicom-images-train\/\"\n\nseg_train_gen , seg_val_gen = get_train_validation_generator(seg_csv_path,seg_images_path)","05b77949":"X,y = next(enumerate(seg_val_gen))[1]\nX.shape,y.shape","02fb5d71":"from tensorflow.keras.optimizers import Adam\nmodel.compile(loss= dice_loss, optimizer=Adam(1e-4), metrics=[dice_coef,my_iou_metric ])\n","8137eb29":"import tensorflow as tf\nimport numpy as np\n\nmodel.fit_generator(seg_train_gen , validation_data=seg_val_gen , epochs=10)","042ca148":"seg_csv_path = \"\/kaggle\/input\/siim-acr-pneumothorax-segmentation-data\/train-rle.csv\"\nseg_images_path = \"\/kaggle\/input\/siim-acr-pneumothorax-segmentation-data\/dicom-images-train\/\"\n\nseg_train_gen , seg_val_gen = get_train_validation_generator(seg_csv_path,seg_images_path ,augmentation=True,hist_eq=True,normalize=True )","4b31d40a":"from MultiCheXNet.utils.Encoder import Encoder\nfrom MultiCheXNet.utils.ModelBlock import ModelBlock","ed36c2fd":"encoder_class = Encoder(weights=None)\nencoder = encoder_class.model ","44da9821":"from tensorflow.keras.layers import Conv2DTranspose, Conv2D","a9ee2205":"encoder.summary()","cad04b36":"X = Conv2DTranspose(512, (3, 3), strides = (2, 2), padding = 'same',activation='relu')(encoder.output)#(16,16,)\nX = Conv2D(512 , (1,1), padding='same',activation='relu')(X)\nX = Conv2D(512 , (1,1), padding='same',activation='relu')(X)\n\n\nX = Conv2DTranspose(256, (3, 3), strides = (2, 2), padding = 'same',activation='relu')(X)#(32,32,)\nX = Conv2D(256 , (1,1), padding='same',activation='relu')(X)\nX = Conv2D(256 , (1,1), padding='same',activation='relu')(X)\n\nX = Conv2DTranspose(128, (3, 3), strides = (2, 2), padding = 'same',activation='relu')(X)#(64,64,)\nX = Conv2D(128 , (1,1), padding='same',activation='relu')(X)\nX = Conv2D(128 , (1,1), padding='same',activation='relu')(X)\n\nX = Conv2DTranspose(128, (3, 3), strides = (2, 2), padding = 'same',activation='relu')(X)#(128,128,)\nX = Conv2D(128 , (1,1), padding='same',activation='relu')(X)\nX = Conv2D(128 , (1,1), padding='same',activation='relu')(X)\n\nX = Conv2DTranspose(64, (3, 3), strides = (2, 2), padding = 'same',activation='relu')(X)#(256,256,)\nX = Conv2D(32 , (1,1), padding='same',activation='relu')(X)\nX = Conv2D(32 , (1,1), padding='same',activation='relu')(X)\nX = Conv2D(1 , (1,1), padding='same',activation='sigmoid')(X)\n\n","8a4e7a34":"model= ModelBlock.add_heads(encoder_class, [X] ,is_classes=False )","f6cba84b":"model.summary()","c9b700ec":"from tensorflow.keras.applications.densenet import preprocess_input","ac231d90":"from MultiCheXNet.data_loader.SIIM_ACR_dataloader import get_train_validation_generator\nseg_csv_path = \"\/kaggle\/input\/siim-acr-pneumothorax-segmentation-data\/train-rle.csv\"\nseg_images_path = \"\/kaggle\/input\/siim-acr-pneumothorax-segmentation-data\/dicom-images-train\/\"\n\nseg_train_gen , seg_val_gen = get_train_validation_generator(seg_csv_path,seg_images_path ,augmentation=True,hist_eq=True,normalize=True  )","27194df4":"from tensorflow.keras.optimizers import Adam\nimport tensorflow as tf\nimport numpy as np\n\n","fc0ec2ed":"model.compile(loss= \"binary_crossentropy\", optimizer=Adam(1e-5), metrics=[dice_coef,my_iou_metric ])\n","bf7c772b":"model.fit_generator(seg_train_gen , validation_data=seg_val_gen , epochs=10)","c4da340b":"# loss functions and metrics","1ae0e652":"# segmentation training","d7d81ac7":"# Segmentation Training","8df88325":"# Second try"}}