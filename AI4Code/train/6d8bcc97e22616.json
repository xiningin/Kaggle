{"cell_type":{"21e6bbf2":"code","19fc1fe8":"code","e299e881":"code","d84aeee3":"code","94358c89":"code","69966c82":"code","5b490b64":"code","58a56342":"code","cc25dec7":"code","63d0f01c":"code","ce70109e":"code","eca0ecca":"code","28ff622d":"code","fb9aa960":"code","8b9f9dab":"code","f9e0dd4b":"code","bc25668d":"code","53e2890d":"code","b67f006a":"code","06a8f54d":"code","f4c29254":"code","48494353":"code","82e38b0c":"code","2c7f93d2":"code","0f9dee29":"code","24c629aa":"code","d05f2b4a":"code","a3c33f10":"code","7a828044":"code","e1c56c97":"code","fe53d89b":"code","1cd2fdfa":"code","83454858":"code","a1b07d5b":"code","93cc6c84":"code","6374f0a9":"code","301ca6ee":"code","0e6b5214":"code","715dc761":"code","a064fa06":"markdown","b1cb5dbf":"markdown","0d1e4827":"markdown","79bcc65f":"markdown","dda14381":"markdown","2e4a7fbd":"markdown","61aa6ead":"markdown","ec182d43":"markdown","db81532d":"markdown","719a39e4":"markdown","cfe321d8":"markdown","6f6d152b":"markdown","1f0e005b":"markdown","ee16aeea":"markdown","7578b503":"markdown","bc4cd453":"markdown"},"source":{"21e6bbf2":"import pandas as pd\nimport numpy as np\nimport scipy.stats\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.impute import KNNImputer\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\n\n#Models\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, f1_score, confusion_matrix\n\nimport warnings \nwarnings.filterwarnings('ignore')","19fc1fe8":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\nsubmissioneg = pd.read_csv('..\/input\/titanic\/gender_submission.csv')","e299e881":"train.head()","d84aeee3":"test.head()","94358c89":"test.isna().sum()","69966c82":"print('Train shape:', train.shape)\nprint('Test shape:', test.shape)","5b490b64":"# combine train and test set to infer information for missing values\ntrain1 = train.copy()\ntest1 = test.copy()\n\ntarget = train['Survived']\ntestid = test['PassengerId']","58a56342":"data = pd.concat([train1, test1], axis=0)\ndata = data.drop(['Survived', 'PassengerId'], axis=1)\ndata.head(10)","cc25dec7":"print('Train + Test features combined:', data.shape)","63d0f01c":"data.info()","ce70109e":"#Check for missing values\ndata.isna().sum()","eca0ecca":"data['Cabin'].value_counts()","28ff622d":"# Do not simply want to fill cabin na values with one cabin value, \n# therefore we will pick randomly between the three modes for cabin\nimport random\n\nprint(data['Cabin'].mode())\ncabin_num = [23, 25, 27]\n\ndata['Cabin'] = data['Cabin'].fillna('C' + str(random.choice(cabin_num)))\ndata['Embarked'] = data['Embarked'].fillna(data['Embarked'].mode()[0])","fb9aa960":"data['Fare'] = data['Fare'].fillna(data['Fare'].mean())","8b9f9dab":"def knn_impute(df, imputer):\n    df = df.copy()\n    df['Sex'] = df['Sex'].apply(lambda x: 1 if x == 'male' else 0)\n    \n    num_df = df.select_dtypes(np.number)\n    \n    num_df = pd.DataFrame(imputer.fit_transform(num_df),columns = num_df.columns)\n    \n    \n    return num_df","f9e0dd4b":"imputer = KNNImputer()\ndata2 = knn_impute(data, imputer)","bc25668d":"data3 = data.drop('Age', axis=1)\ndata3['Age'] = data2['Age']\ndata = data3\ndata.head()","53e2890d":"data.isna().sum().sum()","b67f006a":"# Determine number of travel partners, and whether passenger travelled alone\ndata['Travel_partner'] = data[['SibSp', 'Parch']].iloc[:].sum(axis=1)\ndata['Alone'] = data['Travel_partner'].apply(lambda x: 0 if x > 0 else 1)\ndata.head()","06a8f54d":"data['Sex'] = data['Sex'].apply(lambda x: 1 if x == 'male' else 0)","f4c29254":"#One-hot Encoding\ndef onehot_encoder(df, column):\n    df = df.copy()\n    \n    dummies = pd.get_dummies(df[column])\n    df = pd.concat([df, dummies], axis=1)\n    df = df.drop(column, axis=1)\n    \n    return df","48494353":"onehot_features = ['Embarked']","82e38b0c":"data = onehot_encoder(data, onehot_features)\ndata = data.drop(['Name', 'Ticket', 'Cabin'],axis=1)\ndata.head()","2c7f93d2":"corr = data[['Pclass','Sex','SibSp','Parch','Fare',\n             'Age','Travel_partner','Alone', 'Embarked_C','Embarked_Q','Embarked_S']].corr()\nplt.figure(figsize=(10,6))\nsns.heatmap(corr, annot=True, vmin=-1)\nplt.show()","0f9dee29":"train = data.drop(['SibSp','Parch'], axis=1)\ntrain = train.iloc[:891]\ntrain = pd.concat([train, target], axis=1)\ntrain.shape","24c629aa":"test = data.drop(['SibSp', 'Parch'], axis=1)\ntest = test.iloc[891:]\ntest.shape","d05f2b4a":"scaler = StandardScaler()\ndef preprocessing_inputs(df):\n    df = df.copy()\n    \n    #split df into X and y\n    y = df['Survived']\n    X = df.drop(['Survived'], axis=1)\n    \n    #Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n    \n    #Scale X\n    scaler.fit(X_train)\n    \n    X_train = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=X_train.columns)\n    X_test = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=X_test.columns)\n    \n    return X_train, X_test, y_train, y_test","a3c33f10":"X_train, X_test, y_train, y_test = preprocessing_inputs(train)","7a828044":"models = {'         Logistic Regression': LogisticRegression(),\n          '     Support Vector Machines': SVC(),\n          '            Ridge Classifier': RidgeClassifier(),\n          'Gradient Boosting Classifier': GradientBoostingClassifier()}\n\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    print(name + ' trained.')","e1c56c97":"for name, model in models.items():\n    yhat = model.predict(X_test)\n    acc = accuracy_score(y_test, yhat)\n    print(name + ' Accuracy: {:.2%}'.format(acc))","fe53d89b":"for name, model in models.items():\n    yhat = model.predict(X_test)\n    f1 = f1_score(y_test, yhat, pos_label=1)\n    print(name + ' F1-Score: {:.5}'.format(f1))","1cd2fdfa":"def plot_confusion_matrix(y,y_predict):\n    #Function to easily plot confusion matrix\n    cm = confusion_matrix(y, y_predict)\n    ax= plt.subplot()\n    sns.heatmap(cm, annot=True, ax = ax, fmt='g');\n    ax.set_xlabel('Predicted labels')\n    ax.set_ylabel('True labels')\n    ax.set_title('Confusion Matrix'); \n    ax.xaxis.set_ticklabels(['Did not Survive', 'Survived']); ax.yaxis.set_ticklabels(['Did not Survive', 'Survived'])","83454858":"LR = LogisticRegression()\nLR.fit(X_train, y_train)\nyhat = LR.predict(X_test)\nplot_confusion_matrix(y_test, yhat)","a1b07d5b":"parameters = {'C': [0.01, 0.1, 1],\n              'penalty': ['l2', 'l1'],\n              'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}","93cc6c84":"LogReg = LogisticRegression()\nLogReg_cv = GridSearchCV(estimator=LogReg, param_grid=parameters, cv=10)\nLogReg_cv.fit(X_train, y_train)\nyhat = LogReg_cv.predict(X_test)","6374f0a9":"print('Tuned paramters:', LogReg_cv.best_params_)\nprint('       Accuracy:', '{:.2%}'.format(LogReg_cv.best_score_))\nprint('       F1 Score:',f1_score(y_test, yhat, pos_label=1))","301ca6ee":"test = scaler.fit(test).transform(test)\npredictions = LogReg_cv.predict(test)","0e6b5214":"submission = pd.DataFrame({'PassengerId': testid,\n                           'Survived': predictions})\nsubmission.head()","715dc761":"submission.to_csv('Submission.csv',index=False)","a064fa06":"# Model Selection","b1cb5dbf":"# Feature Selection","0d1e4827":"# Getting Started\n## Understanding the Dataset\n| Feature     | Description                                | Key                                            |\n| ----------- | ------------------------------------------ |----------------------------------------------- |\n| survival    | Survival                                   | 0 = no, 1 = yes                                |\n| pclass      | Ticket class                               | 1 = 1st, 2 = 2nd, 3 = 3rd                      |\n| sex         | Sex                                        |                                                |\n| Age         | Age in years                               |                                                |\n| sibsp       | # of siblings \/ spouses aboard the Titanic |                                                |\n| parch       | # of parents \/ children aboard the Titanic |                                                |\n| ticket      | Ticket number                              |                                                |\n| fair        | Passenger fare                             |                                                |\n| cabin       | Cabin Number                               |                                                |\n| embarked    | Port of Embarkation                        | C = Cherbourg, Q = Queenstown, S = Southampton |      ","79bcc65f":"### Fit Model on Test Set","dda14381":"### Numeric Missing Values","2e4a7fbd":"# Preprocessing","61aa6ead":"# Model Evaluation","ec182d43":"# Model Training","db81532d":"# Feature Engineering","719a39e4":"### Categorical Missing Values","cfe321d8":"# Data Cleaning","6f6d152b":"# Titanic Survival Classification: A Machine Learning Disaster\n## Overview:\n* Clean data\n* Feature Engineering\n* Split, scale, and standardize data\n* Test four classifier models: Logistic Regression, Ridge Classifier, SVM, and Gradient Boosting Classifier\n* Find best Hyperparameter for best model\n* Model selection for test data and submit predictions","1f0e005b":"### Improve Logistic Regression Model with GridSearchCV","ee16aeea":"## Load Datasets and Libraries","7578b503":"# Submission","bc4cd453":"# Encoding Features"}}