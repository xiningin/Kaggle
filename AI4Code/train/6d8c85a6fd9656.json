{"cell_type":{"46910f2b":"code","bafd2504":"code","23a62d35":"code","88479479":"code","3c53b71d":"code","30f4da85":"code","ce539104":"code","d904a859":"code","a86b8b72":"code","ed76d8da":"code","8aade79c":"code","3a04555a":"code","ef84d26c":"markdown"},"source":{"46910f2b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bafd2504":"!conda install -y -c rdkit rdkit;\n!pip install git+https:\/\/github.com\/samoturk\/mol2vec;","23a62d35":"import itertools\nimport numpy as np\nimport pandas as pd\n\nfrom rdkit import Chem\nfrom rdkit.Chem import AllChem\nimport rdkit.Chem.Fragments as f\nimport rdkit.Chem.rdMolDescriptors as d\nfrom rdkit.Chem import Lipinski\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import KBinsDiscretizer\n\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport lightgbm as lgb\nimport xgboost as xgb\n\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import MinMaxScaler","88479479":"from gensim.models import word2vec\nfrom mol2vec.features import mol2alt_sentence, mol2sentence, MolSentence, DfVec, sentences2vec\nfrom gensim.models import word2vec","3c53b71d":"def load_data(path):\n    return pd.read_csv(path, index_col=[\"INDEX\"])\n\n\ndef get_smile(dataframe):\n    data = dataframe.copy()\n    data[\"rd_form\"] = data.SMILES.apply(lambda x: Chem.MolFromSmiles(x))\n    data.drop([\"SMILES\"], inplace=True, axis=1)\n    return data\n\n\n\n\ndef cal_auc(prob, labels):\n    f = list(zip(prob, labels))\n    rank = [values2 for values1, values2 in sorted(f, key=lambda x: x[0])]\n    rankList = [i + 1 for i in range(len(rank)) if rank[i] == 1]\n    posNum = 0\n    negNum = 0\n    for i in range(len(labels)):\n        if (labels[i] == 1):\n            posNum += 1\n        else:\n            negNum += 1\n    auc = (sum(rankList) - (posNum * (posNum + 1)) \/ 2) \/ (posNum * negNum)\n    return auc\n\ndef split(train):\n    train = train.drop([\"rd_form\"], axis=1)\n    Y_train = train[\"ACTIVE\"]\n    X_train = train.drop([\"ACTIVE\"], axis=1)\n    x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=1)\n    imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n    scaler = MinMaxScaler()\n    kbd = KBinsDiscretizer(n_bins=10, encode=\"ordinal\")\n    train_index = x_train.index\n    x_train = imp_mean.fit_transform(x_train)\n    x_train[:, [1, 2]] = scaler.fit_transform(x_train[:, [1, 2]])\n    x_train[:, [1, 2]] = kbd.fit_transform(x_train[:, [1, 2]])\n    x_train = pd.DataFrame(x_train, columns=X_train.columns, index=train_index)\n    test_index = x_val.index\n    x_val = imp_mean.fit_transform(x_val)\n    x_val[:, [1, 2]] = scaler.fit_transform(x_val[:, [1, 2]])\n    x_val[:, [1, 2]] = kbd.fit_transform(x_val[:, [1, 2]])\n    x_val = pd.DataFrame(x_val, columns=X_train.columns, index=test_index)\n    return x_train, x_val, y_train, y_val","30f4da85":"train_path = \"\/kaggle\/input\/assignment4\/training_smiles.csv\"\ntest_path = \"\/kaggle\/input\/assignment4\/test_smiles.csv\"\npre_train = load_data(train_path)\npre_test = load_data(test_path)","ce539104":"def get_feature(dataframe):\n    data = dataframe.copy()\n    mol_model = word2vec.Word2Vec.load('\/kaggle\/input\/assignment4\/model_300dim.pkl')\n    data[\"num_atom\"] = data[\"rd_form\"].apply(lambda x:x.GetNumAtoms())\n    data[\"mol_dr\"] = data[\"rd_form\"].apply(lambda x: d.CalcExactMolWt(x))\n    atom_list = ['C','O', 'N', 'Cl']\n    for i in atom_list:\n        data['num_of_{}_atoms'.format(i)] = data[\"rd_form\"].apply(lambda x: len(x.GetSubstructMatches(Chem.MolFromSmiles(i))))\n    data[\"COO\"] = data[\"rd_form\"].apply(lambda x: f.fr_Al_COO(x))\n    data[\"OH\"] = data[\"rd_form\"].apply(lambda x: f.fr_Al_OH(x))\n#     data[\"ArN\"] = data[\"rd_form\"].apply(lambda x: f.fr_ArN(x))\n#     data[\"NH\"] = data[\"rd_form\"].apply(lambda x: f.fr_Ar_NH(x))\n#     data[\"XCCNR\"] = data[\"rd_form\"].apply(lambda x: f.fr_Ndealkylation1(x))\n    data[\"Nhpyrrole\"] = data[\"rd_form\"].apply(lambda x: f.fr_Nhpyrrole(x))\n    data[\"SH\"] = data[\"rd_form\"].apply(lambda x: f.fr_SH(x))\n    data[\"ketones\"] = data[\"rd_form\"].apply(lambda x: f.fr_ketone(x))\n    data[\"halogen\"] = data[\"rd_form\"].apply(lambda x: f.fr_halogen(x))\n    data[\"nhoh_count\"] = data[\"rd_form\"].apply(lambda x: Lipinski.NHOHCount(x))\n    data[\"hacceptor_count\"] = data[\"rd_form\"].apply(lambda x: Lipinski.NumHAcceptors(x))\n    data[\"hdonor_count\"] = data[\"rd_form\"].apply(lambda x: Lipinski.NumHDonors(x))\n    data[\"hetero_count\"] = data[\"rd_form\"].apply(lambda x: Lipinski.NumHeteroatoms(x))\n    data[\"rotatable_bond_count\"] = data[\"rd_form\"].apply(lambda x: Lipinski.NumRotatableBonds(x))\n    data[\"aliphatic_ring_count\"] = data[\"rd_form\"].apply(lambda x: Lipinski.NumAliphaticRings(x))\n    data[\"aromatic_ring_count\"] = data[\"rd_form\"].apply(lambda x: Lipinski.NumAromaticRings(x))\n#     data[\"saturated_ring_count\"] = data[\"rd_form\"].apply(lambda x: Lipinski.NumSaturatedRings(x))\n#     data[\"aliphatic_cycle_count\"] = data[\"rd_form\"].apply(lambda x: Lipinski.NumAliphaticCarbocycles(x))\n#     data[\"aliphaticHetero_cycle_count\"] = data[\"rd_form\"].apply(lambda x: Lipinski.NumAliphaticHeterocycles(x))\n#     data[\"aromatic_cycle_count\"] = data[\"rd_form\"].apply(lambda x: Lipinski.NumAromaticCarbocycles(x))\n#     data[\"aromaticHetero_cycle_count\"] = data[\"rd_form\"].apply(lambda x: Lipinski.NumAromaticHeterocycles(x))\n#     data[\"saturated_cycle_count\"] = data[\"rd_form\"].apply(lambda x: Lipinski.NumSaturatedCarbocycles(x))\n#     data[\"saturatedHetero_cycle_count\"] = data[\"rd_form\"].apply(lambda x: Lipinski.NumSaturatedHeterocycles(x))\n    fcfp_list = []\n    for fcpc in range(124):\n        data[\"fcpc\" + str(fcpc)] = 0\n        fcfp_list.append(\"fcpc\" + str(fcpc))\n    fcpc_x = data[\"rd_form\"].apply(lambda x: np.array(AllChem.GetMorganFingerprintAsBitVect(x,2,nBits=124, useFeatures=True)))\n    fcpc_vector_lists = list(itertools.chain(*fcpc_x))\n    data.loc[:, fcfp_list] = np.array(fcpc_vector_lists).reshape(len(data),124)\n    ecfp_list = []\n    for ecpc in range(124):\n        data[\"ecpc\" + str(ecpc)] = 0\n        ecfp_list.append(\"ecpc\" + str(ecpc))\n    ecpc_x = data[\"rd_form\"].apply(lambda x: np.array(AllChem.GetMorganFingerprintAsBitVect(x,2,nBits=124)))\n    ecpc_vector_lists = list(itertools.chain(*ecpc_x))\n    data.loc[:, ecfp_list] = np.array(ecpc_vector_lists).reshape(len(data),124)\n    min_max_scaler = MinMaxScaler()\n    m2v_idx_list = []\n    data['sentence'] = data['rd_form'].apply(lambda x: mol2alt_sentence(x, radius=2))\n    for m2v_idx in range(100):\n        data[\"m2v\" + str(m2v_idx)] = 0\n        m2v_idx_list.append(\"m2v\" + str(m2v_idx))\n    m2v_x = [DfVec(x) for x in sentences2vec(data['sentence'], mol_model, unseen='UNK')]\n    m2v_list = [x.vec for x in m2v_x]\n    m2v_vector_lists = list(itertools.chain(*m2v_list))\n    m2v_array = np.array(m2v_vector_lists).reshape(len(data),100)\n    m2v_minmax = min_max_scaler.fit_transform(m2v_array)\n    data.loc[:, m2v_idx_list] = m2v_minmax\n    data = data.drop(['sentence'], axis=1)\n    return data, m2v_list","d904a859":"train, m2v_list = get_feature(get_smile(pre_train))","a86b8b72":"def binary_bayes(x_train, x_val,  y_train, y_val):\n    model = BernoulliNB()\n    model.fit(x_train, y_train)\n    prediction = model.predict_proba(x_val)\n    auc = cal_auc(prediction[:, 1], np.array(y_val))\n    return model, auc, prediction\n\n\ndef guassian_bayes(x_train, x_val,  y_train, y_val):\n    model = GaussianNB()\n    model.fit(x_train, y_train)\n    prediction = model.predict_proba(x_val)\n    auc = cal_auc(prediction[:, 1], np.array(y_val))\n    return model, auc, prediction\n\n\ndef multi_bayes(x_train, x_val,  y_train, y_val):\n    model = MultinomialNB()\n    model.fit(x_train, y_train)\n    prediction = model.predict_proba(x_val)\n    auc = cal_auc(prediction[:, 1], np.array(y_val))\n    return model, auc, prediction\n\n\ndef decision_tree(x_train, x_val,  y_train, y_val):\n    model = DecisionTreeClassifier()\n    model.fit(x_train, y_train)\n    prediction = model.predict_proba(x_val)\n    auc = cal_auc(prediction[:, 1], np.array(y_val))\n    return model, auc, prediction\n\n\ndef mlp(x_train, x_val,  y_train, y_val):\n    model = MLPClassifier()\n    model.fit(x_train, y_train)\n    prediction = model.predict_proba(x_val)\n    auc = cal_auc(prediction[:, 1], np.array(y_val))\n    return model, auc, prediction\n\n\ndef random_forest(x_train, x_val,  y_train, y_val):\n    model = RandomForestClassifier(random_state=14, criterion= \"gini\")\n    model.fit(x_train, y_train)\n    prediction = model.predict_proba(x_val)\n    auc = cal_auc(prediction[:, 1], np.array(y_val))\n    return model, auc, prediction\n\n\ndef light_boost(x_train, x_val,  y_train, y_val):\n    model = lgb.LGBMClassifier(boosting_type='gbdt',objective = 'binary',metric = 'auc',verbose=-1,num_boost_round=500,random_state = 2019)\n    model.fit(x_train, y_train)\n    prediction = model.predict_proba(x_val)\n    auc = cal_auc(prediction[:, 1], np.array(y_val))\n    return model, auc, prediction\n\n\ndef extreme_boost(x_train, x_val,  y_train, y_val):\n    model = xgb.XGBClassifier()\n    model.fit(x_train, y_train)\n    prediction = model.predict_proba(x_val)\n    auc = cal_auc(prediction[:, 1], np.array(y_val))\n    return model, auc, prediction","ed76d8da":"x_train, x_val, y_train, y_val = split(train)\n# lb, lb_auc, lb_prediction = light_boost(x_train,x_val,y_train, y_val)\n# eb, eb_auc, en_prediction = extreme_boost(x_train,x_val,y_train, y_val)\n# rf, rf_auc, rf_prediction = random_forest(x_train,x_val,y_train, y_val)\n# print(lb_auc)\n# print(eb_auc)\n# print(rf_auc)","8aade79c":"print(x_train)","3a04555a":"lb, lb_auc, lb_prediction = light_boost(x_train,x_val,y_train, y_val)\nprint(lb_auc)","ef84d26c":"## Data Preprocess"}}