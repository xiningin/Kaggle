{"cell_type":{"456f5b1c":"code","03b72100":"code","fcd4521d":"code","de747406":"code","2ea887af":"code","569341d1":"code","ff6a92db":"code","87301245":"code","892e74c8":"code","5584215e":"code","fd0c9e12":"code","f426388b":"code","16669de6":"code","f1e1cf2c":"code","ac7b9d4f":"code","4464f57b":"code","f0c382aa":"code","e6c61ddc":"code","45f98360":"code","1bc4498b":"code","bdfde57c":"code","3ecb9c94":"code","90c8e602":"code","9bbd6dfd":"code","1b157dc0":"code","8366a523":"code","9e43c46d":"code","4820351f":"code","35445a0b":"code","5184fcd3":"code","3d1aeb3d":"code","eb095948":"code","22efcbcc":"code","e8b7ad94":"code","633627a0":"code","01a10502":"code","2e8c16aa":"code","89774c3d":"code","1c6e6adb":"code","e1ded6a3":"code","5d665573":"code","d1a006d4":"code","4ee12101":"code","71c00c89":"code","7a94317d":"code","a2af2a33":"code","810372e3":"code","f5743196":"code","d4d58e7d":"code","6ae7a2fc":"code","e8b574b8":"code","88d5552f":"code","53e2a40a":"code","8e119bb4":"code","e45e3f91":"code","a1a9890e":"code","954cfa30":"code","458e7102":"markdown","045afaee":"markdown"},"source":{"456f5b1c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","03b72100":"train = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-5\/train.csv\",)\ntest = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-5\/test.csv\")\nsample = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-5\/submission.csv\")","fcd4521d":"train.set_index(\"Id\",inplace=True)\ntrain.head()","de747406":"train.shape","2ea887af":"test.set_index(\"ForecastId\",inplace=True)\ntest.head()","569341d1":"train.isnull().sum()","ff6a92db":"test.isnull().sum()","87301245":"train[\"Province_State\"].replace(np.nan, 'Unknown', inplace= True)","892e74c8":"test[\"Province_State\"].replace(np.nan, 'Unknown', inplace= True)","5584215e":"train[\"County\"].replace(np.nan, 'Unknown', inplace= True)","fd0c9e12":"test[\"County\"].replace(np.nan, 'Unknown', inplace= True)","f426388b":"train.head()","16669de6":"test.head()","f1e1cf2c":"train.dtypes","ac7b9d4f":"train['Date'] = pd.to_datetime(train.Date)","4464f57b":"from datetime import datetime as dt\ntrain['week'] = train['Date'].dt.week\ntrain['month'] = train['Date'].dt.month\ntrain['year'] = train['Date'].dt.year","f0c382aa":"train.drop(\"Date\",axis=1,inplace=True)","e6c61ddc":"test['Date'] = pd.to_datetime(test.Date)\nfrom datetime import datetime as dt\ntest['week'] = test['Date'].dt.week\ntest['month'] = test['Date'].dt.month\ntest['year'] = test['Date'].dt.year\ntest.drop(\"Date\",axis=1,inplace=True)","45f98360":"train.head()","1bc4498b":"test.head()","bdfde57c":"cat_column  = [col for col in train.columns if train[col].dtypes == 'object']","3ecb9c94":"cat_column_other = [col for col in cat_column if not col == 'Target']\ncat_column_other","90c8e602":"cat_column_target = [col for col in cat_column if col == 'Target']\ncat_column_target","9bbd6dfd":"import category_encoders as ce\ntarget_enc = ce.CatBoostEncoder(cols=cat_column_other)\ntrain[cat_column_other] = target_enc.fit_transform(train[cat_column_other],train['TargetValue'])\ntest[cat_column_other] = target_enc.transform(test[cat_column_other])","1b157dc0":"train = pd.get_dummies(train, columns=[\"Target\"], prefix=[\"Type_is\"] )\ntest = pd.get_dummies(test, columns=[\"Target\"], prefix=[\"Type_is\"] )","8366a523":"train.head()","9e43c46d":"import matplotlib.pyplot as plt","4820351f":"for col in train.columns:\n    print('plot of {} is:'.format(col))\n    plt.boxplot(train[col])\n    plt.show()","35445a0b":"Q1 = train.quantile(0.07)\nQ3 = train.quantile(0.93)\nIQR = Q3 - Q1\nprint(IQR)","5184fcd3":"train.shape","3d1aeb3d":"train1 = train[~((train < (Q1 - 1.5 * IQR)) |(train > (Q3 + 1.5 * IQR))).any(axis=1)]\ntrain1.shape","eb095948":"train.head()","22efcbcc":"test.head()","e8b7ad94":"# from sklearn.preprocessing import LabelEncoder\n# labelencoder = LabelEncoder()\n# for col in cat_column:\n#     train[col] = labelencoder.fit_transform(train[col])\n#     test[col] = labelencoder.fit_transform(test[col])","633627a0":"from sklearn.preprocessing import StandardScaler\nstd = StandardScaler()","01a10502":"X = train1.drop('TargetValue', axis=1).copy()\nX = std.fit_transform(X)","2e8c16aa":"y = train1['TargetValue'].copy()","89774c3d":"from sklearn.model_selection import train_test_split\ntrain_X, val_X, train_y, val_y = train_test_split(X, y,train_size=0.80, test_size=0.20,random_state = 0)","1c6e6adb":"# from sklearn.ensemble import RandomForestRegressor\n# from sklearn.preprocessing import StandardScaler\n# from sklearn.pipeline import Pipeline\n# rf =  RandomForestRegressor(n_jobs=-1,verbose=1)\n# rf.fit(train_X , train_y)","e1ded6a3":"# prediction = rf.predict(val_X)","5d665573":"# from sklearn.metrics import mean_absolute_error\n# val_mae = mean_absolute_error(prediction,val_y)\n# print(val_mae)","d1a006d4":"# import xgboost\n# xgb_model = xgboost.XGBRegressor()\n# xgb_model.fit(train_X , train_y)\n# pred_out = xgb_model.predict(val_X)","4ee12101":"# from sklearn.metrics import mean_absolute_error\n# val_mae = mean_absolute_error(pred_out,val_y)\n# print(val_mae)","71c00c89":"# from sklearn.neighbors import KNeighborsRegressor\n# # for i in range(1,10,1):\n# neigh = KNeighborsRegressor()\n# neigh.fit(train_X,train_y)\n# predict_n = neigh.predict(val_X)\n# print('Mean absolute error: %.2f'\n#      % mean_absolute_error(val_y,predict_n))","7a94317d":"import lightgbm as lgb \nlg = lgb.LGBMRegressor()\nlg = lg.fit(train_X,train_y)\npredict_l = lg.predict(val_X)\nprint('Mean absolute error: %.2f'\n     % np.sqrt(mean_absolute_error(val_y,predict_l)))","a2af2a33":"# from catboost import CatBoostRegressor\n\n# model = CatBoostRegressor()\n# #train the model\n# model.fit(train_X,train_y)\n# # make the prediction using the resulting model\n# preds = model.predict(val_X)\n# print('Mean absolute error: %.2f'\n#      % np.sqrt(mean_absolute_error(val_y,preds)))","810372e3":"test1 = std.fit_transform(test)","f5743196":"predict = lg.predict(test1)","d4d58e7d":"prediction_list = [int(x) for x in predict]","6ae7a2fc":"prediction_list","e8b574b8":"sub = pd.DataFrame({'Id': test.index , 'TargetValue': prediction_list})","88d5552f":"sub['TargetValue'].value_counts()","53e2a40a":"p=sub.groupby(['Id'])['TargetValue'].quantile(q=0.05).reset_index()\nq=sub.groupby(['Id'])['TargetValue'].quantile(q=0.5).reset_index()\nr=sub.groupby(['Id'])['TargetValue'].quantile(q=0.95).reset_index()","8e119bb4":"p.columns = ['Id' , 'q0.05']\nq.columns = ['Id' , 'q0.5']\nr.columns = ['Id' , 'q0.95']","e45e3f91":"p = pd.concat([p,q['q0.5'] , r['q0.95']],1)","a1a9890e":"p['q0.05']=p['q0.05'].clip(0,10000)\np['q0.05']=p['q0.5'].clip(0,10000)\np['q0.05']=p['q0.95'].clip(0,10000)\np","954cfa30":"sub=pd.melt(p, id_vars=['Id'], value_vars=['q0.05','q0.5','q0.95'])\nsub['variable']=sub['variable'].str.replace(\"q\",\"\", regex=False)\nsub['ForecastId_Quantile']=sub['Id'].astype(str)+'_'+sub['variable']\nsub['TargetValue']=sub['value']\nsub=sub[['ForecastId_Quantile','TargetValue']]\nsub.reset_index(drop=True,inplace=True)\nsub.to_csv(\"submission.csv\",index=False)\nsub","458e7102":"# Categorical data","045afaee":"# Missing values"}}