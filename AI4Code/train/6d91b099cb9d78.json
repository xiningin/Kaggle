{"cell_type":{"06b69614":"code","08f1ed90":"code","de55bddd":"code","170d6c43":"code","27b61c13":"code","6a783aa1":"code","79f0c249":"code","62cbc975":"code","c95b9965":"code","fd924ae4":"code","aba046b2":"code","027654ac":"code","45ac1f9a":"code","03e08929":"code","a1ea54cb":"code","0c354a64":"code","8be54f05":"markdown","cae72cd4":"markdown","18cf2e7e":"markdown","8e883977":"markdown","6c53bc8e":"markdown","adf4889e":"markdown","4e512ad9":"markdown","b626c309":"markdown","b716e9a0":"markdown","2423fb72":"markdown","fbaa73ff":"markdown","f762ade7":"markdown","dc8f3fb5":"markdown","2d5b9964":"markdown","cfed4fa0":"markdown","168c0c97":"markdown","2043a65b":"markdown","62c3f05c":"markdown","173cc040":"markdown"},"source":{"06b69614":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport warnings\nwarnings.simplefilter(action='ignore', category=Warning)\nfrom sklearn.tree import DecisionTreeClassifier # Our model\n\n#Input data files are available in the read-only \"..\/input\/\" directory\n\n#Lists all files in input directory\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","08f1ed90":"\ntrain_file_path = '..\/input\/heart-attack-analysis-prediction-dataset\/heart.csv'\n# Create a new Pandas DataFrame with our training data\nheart_train_data = pd.read_csv(train_file_path)\n\n\nprint(heart_train_data.columns) #shows all of the columns \n#heart_train_data.describe(include='all')","de55bddd":"train_dataset = pd.read_csv('\/kaggle\/input\/heart-attack-analysis-prediction-dataset\/heart.csv')\nprint(train_dataset.head())\n#print(dataset.shape)\nprint(train_dataset.describe(include = 'all'))\n#print(dataset.info())\ntrain_dataset.isnull().values.any() # checks if there are any zero \"null\" values\n#pd.value_counts(dataset['output'])\n#print(\"--------------------------------------------\")\n#saturation_dataset = pd.read_csv('\/kaggle\/input\/heart-attack-analysis-prediction-dataset\/o2Saturation.csv')\n#print(saturation_dataset.describe(include = 'all'))","170d6c43":"sns.displot(train_dataset[\"thalachh\"], color=\"blue\"); #This graph explores the trend of the feature thalachh \nplt.title(\"DISTRIBUTION OF HEART RATE AMONG PATIENTS\", fontsize=18)\nplt.xlabel(\"HEART RATE\", fontsize=20)\nplt.ylabel(\"COUNT\", fontsize=20)\nplt.show();","27b61c13":"plt.figure(figsize=(13, 10))\nmatrix = np.triu(train_dataset.corr()) #compares the corralation of every variable to each other \nsns.heatmap(train_dataset.corr(), annot=True,\n            linewidth=.8, mask=matrix, cmap=\"rocket\");\n#finds the corralation coefficient inbetween every variable.","6a783aa1":"plt.figure(figsize = (10, 5))\nplt.style.use(\"ggplot\")\nsns.countplot(x = train_dataset[\"age\"]);  # using countplot\nplt.title(\"Age compared to #people with heart failure\", fontsize=20)\nplt.xlabel(\"AGE\", fontsize = 15)\nplt.ylabel(\"#HEART FAILURE CASES \", fontsize=15)\nplt.show()","79f0c249":"plt.figure(figsize = (12, 8))\nplt.style.use(\"ggplot\")\nsns.histplot(data = train_dataset, x = 'age', hue = 'output') #1 = heart failure (blue), 0 = no heart failure (pink)\nplt.title(\"AGE EFFECT ON THE HEART-ATTACK\")\nplt.xlabel(\"Age\")\nplt.ylabel(\"Count\")\nplt.show()","62cbc975":"from sklearn.tree import DecisionTreeRegressor\n\n# Create our new training set containing only the features we want\nfeatures = ['age', 'sex', 'cp', 'trtbps', 'chol', 'fbs', 'restecg', 'thalachh','exng', 'oldpeak', 'slp', 'caa', 'thall', 'output']\nprepared_data = train_dataset[features]\n\n# Drop rows that contain missing values\nprepared_data = prepared_data.dropna(axis = 0)\n\n# Check that I still have a good 'count' value.\nprepared_data.describe(include = 'all')\nprepared_data.head()","c95b9965":"\n#model = DecisionTreeRegressor(random_state=1)\ny = prepared_data.output\n# Drop the Survived column (axis=1 indicates column)\nX = prepared_data.drop('output', axis=1)\nprint(X.head())\nprint(y)\n#print(X.describe(include = 'all'))","fd924ae4":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1) #Splitting the data into training and validation data\n\n#STANDARDISING THE DATA\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train) #Training data\nX_test = sc.transform(X_test) #Validation data\n\nmodel = DecisionTreeRegressor(random_state=1)\n#fit model\nmodel.fit(X_train, y_train)","aba046b2":"print(\"The predictions for validation data:\")\nprint(model.predict(X_test))\nprint(\"The predictions for training data:\")\nprint(model.predict(X_train))\n#test_predictions = model.predict(X_test)\n#print(\"Validation MAE {:,.0f}\".format(test_mae)) doesn't work as MAE has decimal places\n#print(y_train)\n#print(model.predict(X))\n#print(model.predict(X.head()))\n\n\ntest_predictions = model.predict(X_test)\ntest_mae = mean_absolute_error(test_predictions, y_test)\n#This shows the MAE of the X validation  data and the y test data\nprint(\"MAE of testing data: \"  + str(test_mae))\n\ntrain_predictions = model.predict(X_train)\ntrain_mae = mean_absolute_error(y_train, train_predictions)\n##This shows the MAE of the X training data and the y training data, this predicts 0 as we used X and y training data for our model.\nprint(\"MAE of training data: \" + str(train_mae))","027654ac":"reversed_model = DecisionTreeRegressor(random_state=1)\n#fit model\nreversed_model.fit(X_test, y_test) \n\nprint(\"The predictions for old validation data (now training data):\")\nprint(reversed_model.predict(X_test))\nprint(\"The predictions for the old training data (now validation data):\")\nprint(reversed_model.predict(X_train))\n\ntest_predictions_2 = reversed_model.predict(X_test)\ntest_mae_2 = mean_absolute_error(test_predictions_2, y_test)\n#This shows the MAE of the X validation  data and the y test data this predicts 0 as we used X and y validation data for our model.\nprint(\"MAE of old validation new training data: \"  + str(test_mae_2))\n\ntrain_predictions_2 = reversed_model.predict(X_train)\ntrain_mae_2 = mean_absolute_error(y_train, train_predictions_2)\n##This shows the MAE of the X training data and the y training data\nprint(\"MAE of old training new validation data: \" + str(train_mae_2))","45ac1f9a":"#100 max leaf node model \nhundredleaf_model = DecisionTreeRegressor(max_leaf_nodes=100, random_state=1)\nhundredleaf_model.fit(X_train, y_train)\nhundred_leaf_predictions = model.predict(X_test)\nhundred_leaf_mae = mean_absolute_error(hundred_leaf_predictions, y_test)\nprint(\"MAE of a hundred leaf node model validation data: \" + str(hundred_leaf_mae))\n\n#50 max leaf node model \nfiftyleaf_model = DecisionTreeRegressor(max_leaf_nodes=50, random_state=1)\nfiftyleaf_model.fit(X_train, y_train)\nfifty_leaf_predictions = model.predict(X_test)\nfifty_leaf_mae = mean_absolute_error(fifty_leaf_predictions, y_test)\nprint(\"MAE of a fifty leaf node model validation data: \" + str(fifty_leaf_mae))\n\n#20 max leaf node model \ntwentyleaf_model = DecisionTreeRegressor(max_leaf_nodes=20, random_state=1)\ntwentyleaf_model.fit(X_train, y_train)\ntwenty_leaf_predictions = model.predict(X_test)\ntwenty_leaf_mae = mean_absolute_error(twenty_leaf_predictions, y_test)\nprint(\"MAE of a twenty leaf node model validation data: \" + str(twenty_leaf_mae))\n\n#10 max leaf node model \ntenleaf_model = DecisionTreeRegressor(max_leaf_nodes=10, random_state=1)\ntenleaf_model.fit(X_train, y_train)\nten_leaf_predictions = model.predict(X_test)\nten_leaf_mae = mean_absolute_error(ten_leaf_predictions, y_test)\nprint(\"MAE of a ten leaf node model validation data: \" + str(ten_leaf_mae))\n\n","03e08929":"from sklearn.tree import DecisionTreeClassifier ,plot_tree\nheart_predictor = DecisionTreeClassifier(max_depth = 4)\nheart_predictor.fit(X, y)\n\nplt.figure(figsize = (30,20))\nplot_tree(heart_predictor,\n          feature_names = X.columns,\n          class_names =['heart disease', 'no heart disease'],\n          filled=True)\nplt.show()\n","a1ea54cb":"print(\"Making predictions for the first 5 people in the training set.\")\nprint(\"The predictions are:\")\n\nprint(heart_predictor.predict(X.head())) #predictions of who has heart disease\n\nprint(\"Compared to:\")\nprint(y.head()) #data of heart disease \n","0c354a64":"from sklearn.ensemble import RandomForestRegressor\n\n# Define the model. Set random_state to 1\nrf_model = RandomForestRegressor(random_state=1)\nrf_model.fit(X_train, y_train)\nrf_test_predictions = rf_model.predict(X_test)\nrf_test_mae = mean_absolute_error(rf_test_predictions, y_test)\nprint(\"Validation MAE for Random Forest Model: \" + str(rf_test_mae))","8be54f05":"# RANDOM FOREST\nA random forest model is made up of a large number of small decision trees, called estimators, which each produce their own predictions. These small predicitons all add up to make one final prediction at the end. A random forest can be seen as a more accurate descision tree. We can see that i achieved a 0 MAE for my random forest model which i believe can be attributed to the randomness of the random forest and the fact that there is limited datapoints to measure with.","cae72cd4":"This graph shows the correlatioon between age and the number of heart failure cases. You can see in this graph that people who are aged above 40 and below 68 are more likely to get heart attack. People at the age of 58 are highly prone to heart attacks. We also see a signifact dip in the range of  46 - 50 which could be attributed to other external factors suggesting some inconsistencies or outliers in the data. Although it is hard to clarify what can be defined as an outlier for this data as there are only two possible outcomes, heart failure or no heart failure.","18cf2e7e":"# Hyperparamater tuning \nHow does adding differing max numbers of leaf nodes affect our results?","8e883977":"This graph shows the correlation between age and heart failure (0 = heart failure, 1 = no heart failure), we see a significant increase around the age of 60 and then a slow decline.","6c53bc8e":"We can see that out of the first few people in the training set i predicted 4 out of 5 people correctly. This suggests that my descision tree classifier isn't overfit to the data due to me splitting my data, but my predicitons aren't perfect and could probably be improved with a different model.  ","adf4889e":"Spliting and training data + descision tree\n\nI have split the data and then standardised it so that i can test it using my models. I have split the data so that the validation set is much larger then my training data which gives me a broder range to compare my data with. Having less data and therfore less training data will negativily impact my models performance however as it will have a smaller collection of data to compare with which means that its predictions will be less accurate then if i had a wider spread of data. This model is a decision tree regressor which makes reasonably accurate predictions based on what values it gets for its data which will make descisions down a 'tree' to come up with a final answer whether someone has heart disease or not. ","4e512ad9":"# Introduction:\nI am trying to predict whether on not someone will have heart disease based on serveral factors related to their current health and other heart realted issues. The datset that i am i using is the predicting heart failure dataset. I predict that a random forest model will be the best and the most accurate model to use to make accurate predictions. I believe that my strongest feature to affect predictions will be the age of a person. Regarding the age feature i predict people in a higher age bracket will be more prone to heart failure. My goal for the accuracy of my predictions is to achieve moderatly accurate predicitions while ensuring that i do not overift my data which i can avoid by spliting my data into training and testing sets.","b626c309":"PREDICTING HEART FAILURE","b716e9a0":"I am predicting the output variable which is read as 0 or 1 (0 is heart disease, 1 is no heart disease). A suitable prediction target is to be able to use a model that can predict test data with above an accuracy of half of the data.","2423fb72":"# Explore the data\nTo import the data we need to go into the heart database, we have 14 different categories in the heart database, these catergories are 'age', 'sex', 'cp', 'trtbps', 'chol', 'fbs', 'restecg', 'thalachh', 'exng', 'oldpeak', 'slp', 'caa', 'thall', 'output'. \nThese categories represent: age - age, sex - gender, cp - any chest pain and what level of chest pain, trtbps - resting blood pressure (in mg), chol - cholestoral in mg\/dl fetched via BMI sensor, fbs - (fasting blood sugar > 120 mg\/dl) (1 = true; 0 = false), restecg - resting electrocardiographic results, thalachh - maximum heart rate achieved, exng - exercise induced angina (1 = yes; 0 = no), oldpeak - previous peak, slp - slope, caa - number of major vessels in subject (1-3), thall - thal rate, output - If someone had heart disease or not (target variable). For output 0 means that the person has heart failure and 1 means they do not.\n\nIt is also important to note that there are 303 different values per column","fbaa73ff":"This decision tree classifier gives a visual example of what is happening inside of my descision tree when it decides if someone has heart disease or not based on the feature values it is given. We can see the gini impurity in this descision tree classifier.","f762ade7":"# Preparing the Data\nWe want to predict if someone is likely to have a heart attack. To do this it would be logical to choose the most relevent feeatures and model our data of this. However we do not want to get rid of any features as none can be classified as needless or un-neccesary as all data contributes to if the person has a heart attack or not, just at varying levels. \n\nThere is no categorical data and there are no null or missing values in my data so i dont need to drop anything. \n\nAs every feature plays a role in deducing if someone undergoes heart failure, we cannot get rid of a feature. This also applies to data points, this particular data set has limited data (only 303) whcih means that it is hard to clarify what can be defined as an outlier for this data as every piece of data contributes to finding if someone has heart failure or not and the only data that can be deemed an outlier is data that completely contradicts with the majority of the other data. Which in the case of this dataset, there are no such cases.","dc8f3fb5":"# Training a Model and Making Predictions\nWe can see that my MAE for the testing or validation data is 0.276315... and my MAE for the training data is 0. This is because the data that i have used for my training data is exactly the same data that i am making predictions with meaning that the training data is overfit. My MAE for the validation data however is 0.276315 which isn't too high and suggests that the descision tree model is a reasonably good and also efficent way to develop accurate predcitions about heart disease. ","2d5b9964":"# Graphs to visualise and represent data","cfed4fa0":"# CONCLUSION\nThe purpose of the investigation was to deduce if someone had heart disease or not based on certain features of their health. I predicted whether or not someone had heart disease using a descision tree by splitting and standardising the data. The quality of my predictions with the descision tree were reasonable. The descision tree was the best model and it usually made reliable and accurate predictions and showed that it didn't overfit or underfit to the data. I achieved my goal of not wanting to overfit my data and creating semi-accurate predictions,however i hypothesised that a random forest model would be the best model to use to make accurate predictions which was wrong as it had a higher MAE the the descision tree regressor. I believed that my strongest feature that would affect predictions would be the age of a person which proved to be true with the highest corration to the results in the output. My hyperparameter tuning had very little effect on my data and changing the output it gave so it was uneffective. Other models could have been used to a better effect if this dataset was bigger as this dataset has only 300 results to train your model and then also predict with your model which isn't enough to create a reliable large scale model.","168c0c97":"This table shows the correlation inbetween each of the variables, so we can see which variables have high correlation with other variables in order to determine the best 'starting' variables and also use a visual representation of what variables have a high correlation with each other.","2043a65b":"We achieve a MAE of 0.276315 on our validation data with our model. We have achieved this value by modeling our training data and testing it with the validation data. What if I used my validation data to model my training data instead to try to achieve a better MAE.","62c3f05c":"The MAE we get for the validation data in our first model is aprox 0.276, where the MAE for our validation data in our second model is aprox 0.295 which is a greater MAE which means that using our original training data model to predict our original validation data, is better then using the inverted model.","173cc040":"All results appear the same. Tuning this paramater seems to have no visible effect on the data and therefore has no affect on the accuracy."}}