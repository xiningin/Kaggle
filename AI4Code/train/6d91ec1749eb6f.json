{"cell_type":{"78d28b2a":"code","5beb89f0":"code","edd955b1":"code","928e1a8b":"code","61319947":"code","12af38d2":"code","17737b5b":"code","22663b06":"code","2c8c4239":"code","44198736":"code","e4f9f8c6":"code","e956286f":"code","94e9ebe9":"code","630f7bfc":"code","b01e47bd":"code","3a34e3bc":"code","94aad2e8":"code","445613ef":"code","f0fe317f":"code","5196f727":"code","d88c89f7":"code","2176d94f":"code","c65777de":"code","2e15308f":"markdown","2222a8f1":"markdown","cf957dfa":"markdown","5f8b505b":"markdown","d940614e":"markdown","04870326":"markdown","f5db853c":"markdown","ad0d1b8b":"markdown","f86185b5":"markdown"},"source":{"78d28b2a":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.neighbors import KNeighborsClassifier, NeighborhoodComponentsAnalysis, LocalOutlierFactor\nfrom sklearn.decomposition import PCA","5beb89f0":"#warning Library\nimport warnings\nwarnings.filterwarnings(\"ignore\")","edd955b1":"data = pd.read_csv('..\/input\/breast-cancer-wisconsin-data\/data.csv')\ndata.head()","928e1a8b":"data.drop(['Unnamed: 32','id'], inplace = True, axis = 1)\ndata = data.rename(columns = {\"diagnosis\":\"target\"})\n\nsns.countplot(data[\"target\"])\nprint(data.target.value_counts())","61319947":"data[\"target\"] = [1 if i.strip() == \"M\" else 0 for i in data.target]\n\nprint(len(data))\nprint(data.head())\nprint(\"Data shape\", data.shape)\n\ndata.info()","12af38d2":"\"\"\"Standardization\nmissing value:None\"\"\"\ndescribe = data.describe()\ndescribe","17737b5b":"# Correlation\ncorr_matrix = data.corr()\nsns.clustermap(corr_matrix,figsize=(15, 10), annot= True, fmt =  \".2f\")\nplt.title(\"Correlation Between Features\")\nplt.show()","22663b06":"threshold = 0.75\nfiltre = np.abs(corr_matrix[\"target\"]) > threshold\ncorr_features = corr_matrix.columns[filtre].tolist()\nsns.clustermap(corr_matrix,figsize=(15, 10), annot= True, fmt =  \".2f\")\nplt.title(\"Correlation Between Features w Corr Threshold 0.75\")\nplt.show()","2c8c4239":"#box plot\ndata_melted = pd.melt(data, id_vars = \"target\",\n                      var_name = \"features\",\n                      value_name = \"value\")\nplt.figure(figsize=(10,5))\nsns.boxplot(x = \"features\", y = \"value\", hue = \"target\", data = data_melted)\nplt.xticks(rotation = 90)\nplt.show()","44198736":"#pair plot\nsns.pairplot(data[corr_features], diag_kind = \"kde\", markers = \"+\",hue = \"target\")\nplt.show()","e4f9f8c6":"y = data.target\nx = data.drop([\"target\"],axis = 1)\ncolumns = x.columns.tolist()\n\nclf = LocalOutlierFactor()\ny_pred = clf.fit_predict(x)\nX_score = clf.negative_outlier_factor_\n\noutlier_score = pd.DataFrame()\noutlier_score[\"score\"] = X_score\n# threshold\nthreshold = -2.5\nfiltre = outlier_score[\"score\"]< threshold\noutlier_index = outlier_score[filtre].index.tolist()\n\n\n\nplt.figure()\nplt.scatter(x.iloc[outlier_index,0], x.iloc[outlier_index,1],color = \"blue\", s = 50, label = \"Outliers\")\nplt.scatter(x.iloc[:,0], x.iloc[:,1], color=\"k\", s =3, label=\"Data Points\")\n\nradius = (X_score.max() - X_score)\/(X_score.max() - X_score.min())\noutlier_score[\"radius\"] = radius\nplt.scatter(x.iloc[:,0], x.iloc[:,1], s = 1000*radius, edgecolors = \"r\", facecolors = \"none\", label = \"Outlier Scores\")\nplt.legend()\nplt.show()","e956286f":"#drop outliers\nx = x.drop(outlier_index)\ny = y.drop(outlier_index).values","94e9ebe9":"test_size = 0.3\nX_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=test_size, random_state = 42)","630f7bfc":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\nX_train_df = pd.DataFrame(X_train, columns = columns)\nX_train_df_describe = X_train_df.describe()\nX_train_df[\"target\"] = Y_train","b01e47bd":"# box plot\ndata_melted = pd.melt(X_train_df, id_vars = \"target\",\n                      var_name =\"features\",\n                      value_name = \"value\")\nplt.figure(figsize=(10,7))\nsns.boxplot(x = \"features\", y=\"value\", hue= \"target\", data = data_melted)\nplt.xticks(rotation = 90 )\nplt.show()","3a34e3bc":"#pair plot\nsns.pairplot(X_train_df[corr_features], diag_kind = \"kde\", markers = \"+\",hue = \"target\")\nplt.show()","94aad2e8":"knn = KNeighborsClassifier(n_neighbors=2)\nknn.fit(X_train, Y_train)\ny_pred = knn.predict(X_test)\nacc = accuracy_score(Y_test, y_pred)\nscore = knn.score(X_test, Y_test)\nprint(\"KNN Acc:\",acc)\ncm = confusion_matrix(Y_test,knn.predict(X_test))\nsns.heatmap(cm,annot=True,fmt=\"d\")","445613ef":"def KNN_Best_Params(x_train, x_test, y_train, y_test):\n    \n    k_range = list(range(1,31))\n    weight_options = [\"uniform\",\"distance\"]\n    print()\n    param_grid = dict(n_neighbors = k_range, weights=weight_options)\n    knn = KNeighborsClassifier()\n    grid=GridSearchCV(knn, param_grid, cv =10, scoring=\"accuracy\")\n    grid.fit(x_train, y_train)\n    \n    print(\"Best training score: {} with parameters:{}\".format(grid.best_score_, grid.best_params_))\n    print()\n    \n    knn = KNeighborsClassifier(**grid.best_params_)\n    knn.fit(x_train, y_train)\n    \n    y_pred_test = knn.predict(x_test)\n    y_pred_train = knn.predict(x_train)\n    \n    cm_test  = confusion_matrix(y_test, y_pred_test)\n    cm_train = confusion_matrix(y_train, y_pred_train)\n    \n    acc_test = accuracy_score(y_test, y_pred_test)\n    acc_train = accuracy_score(y_train, y_pred_train)\n    print(\"Test Score: {}, Train Score:{}\".format(acc_test, acc_train))\n    print()\n    print(\"CM Test:\",cm_test)\n    print(\"CM Train:\",cm_train)\n    \n    return grid\n\ngrid = KNN_Best_Params(X_train, X_test, Y_train, Y_test )","f0fe317f":"scaler = StandardScaler()\nx_scaled = scaler.fit_transform(x)\n\npca = PCA(n_components=2)\npca.fit(x_scaled)\nX_reduced_pca = pca.transform(x_scaled)\npca_data = pd.DataFrame(X_reduced_pca, columns = [\"p1\",\"p2\"])\npca_data[\"target\"]= y\nsns.scatterplot(x = \"p1\", y= \"p2\",hue=\"target\",data=pca_data)\nplt.title(\"PCA:p1 vs p2\")","5196f727":"X_train_pca, X_test_pca, Y_train_pca, Y_test_pca = train_test_split(X_reduced_pca, y, test_size=test_size, random_state = 42)\n\ngrid_pca = KNN_Best_Params(X_train_pca, X_test_pca, Y_train_pca, Y_test_pca )","d88c89f7":"# visualize\n\ncmap_light = ListedColormap(['orange','cornflowerblue'])\ncmap_bold = ListedColormap(['darkorange','darkblue'])\n\nh = .05\nX = X_reduced_pca\nx_min, x_max = X[:,0].min() - 1, X[:,0].max() + 1\ny_min, y_max = X[:,1].min() - 1, X[:,1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                     np.arange(y_min, y_max, h))\n\nZ = grid_pca.predict(np.c_[xx.ravel(),yy.ravel()])\n#Put the result into a color plot\nZ = Z.reshape(xx.shape)\nplt.figure()\nplt.pcolormesh(xx, yy,Z, cmap=cmap_light)\n#Plot also the training points\nplt.scatter(X[:,0],X[:,1],c=y,cmap=cmap_bold,\n            edgecolor='k', s=20)\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\nplt.title(\"%i-Class classificaation (k = %i, weights = '%s')\"\n          % (len(np.unique(y)),grid_pca.best_estimator_.n_neighbors,grid_pca.best_estimator_.weights))","2176d94f":"nca = NeighborhoodComponentsAnalysis(n_components = 2, random_state= 42)\nnca.fit(x_scaled, y)\nX_reduced_nca = nca.transform(x_scaled)\nnca_data = pd.DataFrame(X_reduced_nca, columns = [\"p1\",\"p2\"])\nnca_data[\"target\"] = y\nsns.scatterplot(x = \"p1\", y = \"p2\",hue=\"target\", data = nca_data)\nplt.title(\"NCA: p1 vs p2\")\n\nX_train_nca, X_test_nca, Y_train_nca, Y_test_nca = train_test_split(X_reduced_nca, y, test_size=test_size, random_state = 42)\n\ngrid_nca = KNN_Best_Params(X_train_nca, X_test_nca, Y_train_nca, Y_test_nca )\n","c65777de":"# visualize\n\ncmap_light = ListedColormap(['orange','cornflowerblue'])\ncmap_bold = ListedColormap(['darkorange','darkblue'])\n\nh = .2 #step size in the mesh\nX = X_reduced_nca\nx_min, x_max = X[:,0].min() - 1, X[:,0].max() + 1\ny_min, y_max = X[:,1].min() - 1, X[:,1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                     np.arange(y_min, y_max, h))\n\nZ = grid_nca.predict(np.c_[xx.ravel(),yy.ravel()])\n#Put the result into a color plot\nZ = Z.reshape(xx.shape)\nplt.figure()\nplt.pcolormesh(xx, yy,Z, cmap=cmap_light)\n\n#Plot also the training points\nplt.scatter(X[:,0],X[:,1],c=y,cmap=cmap_bold,\n            edgecolor='k', s=20)\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\nplt.title(\"%i-Class classificaation (k = %i, weights = '%s')\"\n          % (len(np.unique(y)),grid_nca.best_estimator_.n_neighbors,grid_nca.best_estimator_.weights))","2e15308f":"# **Train-test split**","2222a8f1":"# **Standardization**","cf957dfa":"# **HyperTunning the KNN Model**\n","5f8b505b":"# **KNN MODEL**","d940614e":"# **Outlier**","04870326":"# **Library and dataset**","f5db853c":"# **PCA**","ad0d1b8b":"# **NCA**\n","f86185b5":"# **EDA**"}}