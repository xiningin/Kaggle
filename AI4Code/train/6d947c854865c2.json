{"cell_type":{"29488276":"code","c90bd23a":"code","fc66222a":"code","6c24961a":"code","475fb553":"code","001d05f1":"code","0bfa6b95":"code","363a8ef3":"code","55d3670d":"code","1ec1e634":"code","0ea612f9":"code","27983dbf":"code","e5ff13c3":"code","b4716cfc":"code","1a4e69f4":"markdown","c9c43e83":"markdown","08fbd610":"markdown","0f74fa50":"markdown","db9841a5":"markdown","f3b4ac9a":"markdown","c4261727":"markdown"},"source":{"29488276":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2\nimport matplotlib.pyplot as plt\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import Adam\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n# Any results you write to the current directory are saved as output.","c90bd23a":"path = '..\/input\/ravdessfractals'\n\n# d = {'W':[], 'N':[], 'F':[], 'D':[], 'S':[], 'A':[], 'J':[]}\nd = {'Angry':[], 'Calm':[], 'Disgust':[], 'Fear':[], 'Happy':[], 'Neutral':[], 'Sad':[], 'Suprise':[]}","fc66222a":"for e in os.listdir(path):\n\tfor file in os.listdir(os.path.join(path, e)):\n\t\timg = cv2.imread(os.path.join(path,e,file),cv2.IMREAD_GRAYSCALE)\n\t\ta = np.reshape(img, (480, -1))[58:427, 80:576] # (369,496)\n\t\ta = cv2.resize(a, (int(a.shape[1]\/5), int(a.shape[0]\/5)) )\n\t\tb = a.ravel()\n        \n\t\td[e].append(b)","6c24961a":"for i,key in zip(range(len(d)),d):\n    globals()[key] = pd.DataFrame(np.array(d[key]))\n\n    globals()[key]['label'] = i\n    \n    col_list = list(globals()[key].columns[-1:])+list(globals()[key].columns[:-1])\n    globals()[key] = globals()[key][col_list]","475fb553":"# Concatenate\ndf = pd.concat([globals()[df] for df in d], ignore_index=True)\ndf = df.reset_index(drop=True)\n\n# TTS\nx = df.drop(['label'], axis=1).values\/255\nx = x.reshape(-1, a.shape[0], a.shape[1], 1)\n\ny = to_categorical(df.label, num_classes=df.label.nunique())\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=42)","001d05f1":"#check shapes\n\ntr = np.bincount(np.argmax(y_train, axis=1))\nts = np.bincount(np.argmax(y_test, axis=1))\n\nprint('Number of Samples for Each Label\\n')\n\nsplits = [', '.join(['train='+ str(i), 'test='+ str(j)]) for i,j in zip(tr,ts)]\nfor i,j in zip(range(len(splits)), splits):\n    print('label= {} : {}'.format(i,j))","0bfa6b95":"# FW 1\n\ndef model1():\n    model = Sequential()\n    model.add(Conv2D(32, 5, activation='relu', input_shape=x.shape[1:]))\n    model.add(MaxPool2D(2))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(16, 3, activation='relu'))\n    model.add(MaxPool2D(2))\n    model.add(Dropout(0.25))\n\n\n    model.add(Flatten())\n\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.25))\n    model.add(Dense(df.label.nunique(), activation='softmax'))\n\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    \n    return model","363a8ef3":"# FW 2\ndef model2():\n\n    model = Sequential()\n    model.add(Conv2D(32, 3, activation='relu', input_shape=x.shape[1:]))\n    model.add(MaxPool2D(2))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(16, 3, activation='relu'))\n    model.add(MaxPool2D(2))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(16, 3, activation='relu'))\n    model.add(MaxPool2D(2))\n    model.add(Dropout(0.25))\n\n    model.add(Flatten())\n\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.25))\n    model.add(Dense(df.label.nunique(), activation='softmax'))\n\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    \n    return model","55d3670d":"# FW 3\ndef model3():\n\n    model = Sequential()\n    model.add(Conv2D(32, 3, activation='relu', input_shape=x.shape[1:]))\n    model.add(MaxPool2D(2))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(32, 3, activation='relu'))\n    model.add(MaxPool2D(2))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(64, 3, activation='relu'))\n    model.add(MaxPool2D(2))\n    model.add(Dropout(0.25))\n\n    model.add(Flatten())\n\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.25))\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.25))\n    model.add(Dense(df.label.nunique(), activation='softmax'))\n\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n    return model","1ec1e634":"# FW 4\ndef model4():\n\n    model = Sequential()\n    model.add(Conv2D(32, 5, activation='relu', input_shape=x.shape[1:]))\n    model.add(MaxPool2D(2))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(64, 3, activation='relu'))\n    model.add(MaxPool2D(2))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(128, 3, activation='relu'))\n    model.add(MaxPool2D(2))\n    model.add(Dropout(0.25))\n\n    model.add(Flatten())\n\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.25))\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.25))\n    model.add(Dense(df.label.nunique(), activation='softmax'))\n\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n    return model","0ea612f9":"# FW 5\ndef model5():\n\n    model = Sequential()\n    model.add(Conv2D(60, 8, activation='relu', input_shape=x.shape[1:]))\n    model.add(MaxPool2D(2))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(120, 5, activation='relu'))\n    model.add(MaxPool2D(2))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(240, 5, activation='relu'))\n    model.add(MaxPool2D(2))\n    model.add(Dropout(0.25))\n\n    model.add(Flatten())\n\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.25))\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.25))\n    model.add(Dense(df.label.nunique(), activation='softmax'))\n\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    \n    return model","27983dbf":"# model1()\nmodel2()\n# model3()\n# model4()\n# model5()\n\n\nmodel.fit(x_train, y_train, batch_size=32, epochs=25, verbose=1, validation_split=0.25)","e5ff13c3":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ny_pred = model.predict(x_test)\n\ny_predicted = np.argmax(y_pred, axis = 1) \ny_true = np.argmax(y_test, axis = 1) \n# print(y_predicted.shape)\n# print(y_true.shape)\n\nfrom sklearn.metrics import accuracy_score, f1_score\nprint('test accuracy: ',accuracy_score(y_true, y_predicted))\nprint('f1 score: ',f1_score(y_true, y_predicted, average='macro'))","b4716cfc":"cm = confusion_matrix(y_true, y_predicted)\nplt.figure(figsize=(12,8))\nplt.yticks(rotation=60)\n\ng=sns.heatmap(cm, annot=True, linewidths=0.2, cmap=\"Reds\",linecolor=\"black\",  fmt= '.1f',\n            xticklabels=d.keys())\ng.set_yticklabels(d.keys(), rotation=0)\nplt.title('  -  '.join([':'.join([j,str(i)]) for i,j in zip(np.bincount(y_true), d.keys())]))\nplt.show()\n\n","1a4e69f4":"# Introduction\n\n<font color = blue>\n* This kernel only includes only a sample from the classification part of an academic study called \"Cross-Linguistic Speech Emotion Recognition\nBased on 2D Feature Spaces\". \n* The manuscript has been sent to IEEE already. \n* 4 different feature spaces have been used for this purpose: cochleagrams, spectrograms, mel cepstrograms, and fractal dimension-based space, which are available in my page.\n    \n* The database have the following languages; \n<font color=green>\n    * English\n    * Lithuanian\n    * German\n    * Spanish\n    * Serbian \n    * Polish\n\n\nFeature extraction and other details can be found in [here](https:\/\/github.com\/abyingh\/Speech-Emotion-Recognition)","c9c43e83":"<font color=blue>\n* Sample Topologies","08fbd610":"<font color=blue>\n* Fitting the Chosen Model","0f74fa50":"### Train-Test Split\n","db9841a5":"# Model Evaluation\n\n* F1 Score\n\n* Confusion Matrix","f3b4ac9a":"# Keras Framework","c4261727":"# Preprocessing\n\n### Resize Images\n"}}