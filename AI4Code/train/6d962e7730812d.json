{"cell_type":{"cca1ae59":"code","1f774774":"code","37ff5f0b":"code","1ae5a1de":"code","eea7dcb0":"code","066bceb0":"code","fe417e45":"code","ecd1a553":"code","de2d4778":"code","5e1443a3":"code","a3d83f9a":"code","563bc2f7":"code","be739a6d":"code","a964fa92":"code","c09b20b3":"code","340e9ea4":"code","ed459f76":"code","f9810cff":"code","e9451f6c":"code","931c6bf6":"code","2bac856a":"code","f6ff7f73":"code","0dd0575d":"code","fd839d75":"code","9331bc01":"code","63112efa":"code","eae3618c":"code","4558654e":"code","3ef1d67b":"code","a660d7c4":"code","146fb706":"code","04a8eeb3":"code","d88ad55a":"code","5792d8ac":"code","01599f5e":"code","e61171a8":"code","dadda522":"markdown","6ff6ed17":"markdown","f00baded":"markdown","a3915be9":"markdown","05271bda":"markdown","15bf642a":"markdown","1c70bff3":"markdown","a7333684":"markdown","2b613b6d":"markdown","77bfea3f":"markdown"},"source":{"cca1ae59":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm, skew\nfrom sklearn.preprocessing import LabelEncoder\n\nsns.set_style(\"darkgrid\")","1f774774":"%%time\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\n\nprint(train.shape, test.shape)","37ff5f0b":"train.head()","1ae5a1de":"train.describe(include=['number']).loc[['min','max','mean']].T.sort_values('max')","eea7dcb0":"n = train.select_dtypes(include=object)\nfor c in n.columns:\n    print('{:<14}'.format(c), train[c].unique())","066bceb0":"plt.figure(figsize=(8,3))\nsns.distplot(train['SalePrice'], fit=norm)\nmu, sigma = norm.fit(train['SalePrice'])\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)], loc='best')\nplt.ylabel('Frequency')\nprint('skew={}'.format(skew(np.log1p(train['SalePrice']))))","fe417e45":"cols = ['OverallQual','OverallCond','SaleType','SaleCondition']\nsorted_data = train.sort_values(by='SalePrice')\n\nfig, axes = plt.subplots(ncols=4, nrows=1, figsize=(4 * 4, 3), sharey=True)\nfor i, c in zip(np.arange(len(axes)), cols):\n    sns.boxplot(x=c, y='SalePrice', data=sorted_data, ax=axes[i])\n\nfig, axes = plt.subplots(ncols=4, nrows=1, figsize=(4 * 4, 3), sharey=True)\nfor i, c in zip(np.arange(len(axes)), cols):\n    sns.countplot(x=c, data=sorted_data, ax=axes[i])","ecd1a553":"fig, axes = plt.subplots(ncols=5, nrows=2, figsize=(16, 4), sharey=True)\naxes = np.ravel(axes)\ncol_name = ['GrLivArea','TotalBsmtSF','1stFlrSF','BsmtFinSF1','LotArea']\nfor i, c in zip(range(5), col_name):\n    train.plot.scatter(ax=axes[i], x=c, y='SalePrice', sharey=True, colorbar=False, c='red')\n\n# delete outliers\nprint(train.shape)\ntrain = train[train['GrLivArea'] < 4000]\ntrain = train[train['LotArea'] < 100000]\nprint(train.shape)\n\nfor i, c in zip(range(5,10), col_name):\n    train.plot.scatter(ax=axes[i], x=c, y='SalePrice', sharey=True, colorbar=False, c='navy')","de2d4778":"all_data = train.append(test, sort=False).reset_index(drop=True)\nall_data.shape","5e1443a3":"n = all_data.drop('SalePrice', axis=1).loc[:,all_data.isnull().any()].isnull().sum()\nprint('ALL:', all_data.shape[0])\nprint('-' * 30)\nprint(n.sort_values(ascending=False))","a3d83f9a":"# drop feature\nall_data.drop(['MiscFeature', 'Alley', 'Fence'], axis=1, inplace=True)\n\n# fillna with 0\ncols = ['GarageArea', 'GarageCars', 'GarageFinish', 'MasVnrArea', \n        'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath']\nfor c in cols:\n    all_data[c].fillna(0, inplace=True)\n\n# fillna with 'None'\ncols = ['BsmtQual','BsmtCond','KitchenQual','FireplaceQu','GarageType','GarageQual','GarageCond',\n        'PoolQC','BsmtFinType1','BsmtFinType2','BsmtExposure','MasVnrType']\nfor c in cols:\n    all_data[c].fillna('None', inplace=True)\n\n# fillna with other \nall_data.loc[all_data['GarageYrBlt'].isnull(),'GarageYrBlt'] = all_data.loc[all_data['GarageYrBlt'].isnull(),'YearBuilt']\n\n# fillna with group median\nall_data['LotFrontage'] = all_data.groupby(pd.qcut(all_data['LotArea'], 10))['LotFrontage'].transform(lambda x: x.fillna(x.median()))","563bc2f7":"n = all_data.drop('SalePrice', axis=1).loc[:,all_data.isnull().any()].isnull().sum()\nprint(n.sort_values(ascending=False))","be739a6d":"for i, t in all_data.loc[:, all_data.columns != 'SalePrice'].dtypes.iteritems():\n    if t == object:\n        all_data[i].fillna(all_data[i].mode()[0], inplace=True)\n    else:\n        all_data[i].fillna(all_data[i].median(), inplace=True)","a964fa92":"all_data['_OverallQualCond'] = all_data['OverallQual'] + (all_data['OverallCond'] - 5) * 0.5\nall_data['_TotalSF'] = all_data['TotalBsmtSF'] + all_data['GrLivArea']\nall_data['_PorchArea'] = all_data['OpenPorchSF'] + all_data['EnclosedPorch'] + all_data['3SsnPorch'] + all_data['ScreenPorch']\nall_data['_TotalArea'] = all_data['_TotalSF'] + all_data['GarageArea'] + all_data['_PorchArea']\nall_data['_Rooms'] = all_data['TotRmsAbvGrd'] + all_data['FullBath'] + all_data['HalfBath']\nall_data['_BathRooms'] = all_data['FullBath'] + all_data['BsmtFullBath'] + (all_data['HalfBath'] + all_data['BsmtHalfBath']) * 0.7\nall_data['_GrLAreaAveByRms'] = all_data['GrLivArea'] \/ all_data['_Rooms']","c09b20b3":"grp = train.groupby(['YrSold','MoSold'])\npiv = grp.count()['SalePrice'].reset_index()\npiv.columns = ['YrSold','MoSold','SoldCount']\n\nplt.figure(figsize=(10, 3))\nsns.pointplot(x='MoSold', y='SoldCount', hue='YrSold', data=piv, join=True)\nplt.legend(loc='best', bbox_to_anchor=(1.05, 0.8, 0.2, 0))\n\nall_data['_SaleSeason'] = all_data['MoSold'].replace({1:0, 2:0, 3:0, 4:1, 5:1, 6:2, 7:2, 8:1, 9:0, 10:0, 11:0, 12:0})","340e9ea4":"# year feature\ncols = ['YrSold','YearBuilt','YearRemodAdd','GarageYrBlt']\nprint(all_data[cols].describe())\n\n# correct invalid value\nall_data.loc[all_data['GarageYrBlt'] > 2010, 'GarageYrBlt'] = all_data['YearBuilt']\n\n# relation feature\nall_data['_Remod_Sold'] = 0\nall_data.loc[all_data['YrSold'] <= all_data['YearRemodAdd'], '_Remod_Sold'] = 1\nall_data['_Built_Sold'] = 0\nall_data.loc[all_data['YrSold'] <= all_data['YearBuilt'], '_Built_Sold'] = 1\n\n# year group\n#year_map = pd.concat(pd.Series('YearBin' + str(i+1), index=range(1871+i*10,1881+i*10)) for i in range(0, 14))\n#all_data['_YearBuiltGrp'] = all_data['YearBuilt'].map(year_map)\n\n# diff feature\nall_data['_YrBlt_to_sold'] = all_data['YrSold'] - all_data['YearBuilt']\nall_data['_YrRemod_to_sold'] = all_data['YrSold'] - all_data['YearRemodAdd']\nall_data['_GrgYrBlt_to_sold'] = all_data['YrSold'] - all_data['GarageYrBlt']\nprint('-' * 60)\nprint(all_data[['_YrBlt_to_sold','_YrRemod_to_sold','_GrgYrBlt_to_sold']].describe())\nall_data.drop(cols, axis=1, inplace=True)","ed459f76":"# to categorical feature\ncols = ['MSSubClass']\nfor c in cols:\n    all_data[c] = all_data[c].astype(str)","f9810cff":"#log transform skewed numeric features\n_='''\n'''\nnumeric_feats = all_data.drop('SalePrice', axis=1).dtypes[all_data.dtypes != \"object\"].index\nskewed = all_data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nskewed_feats = skewed[skewed > 1].index\nprint(skewed_feats)\n\nfor c in (skewed_feats):\n    all_data[c] = np.log1p(all_data[c])","e9451f6c":"mssubclass_map = {'180':1, '30':2, '45':2, '190':3, '50':3, '90':3, '85':4, '40':4, '160':4, \n                  '70':5, '20':5, '75':5, '80':5, '150':5, '120':6, '60':6}\nall_data['_MSSubClassBin'] = all_data['MSSubClass'].map(mssubclass_map)\n\nplt.figure(figsize=(9, 3))\nax = sns.boxplot(x='MSSubClass', y='SalePrice', data=all_data[all_data['SalePrice'].notnull()], order=mssubclass_map.keys())","931c6bf6":"neighborhood_map = {\n        \"MeadowV\":0, \"IDOTRR\":0, \"BrDale\":0, \n        \"Blueste\":1, \"NPkVill\":1,\n        \"OldTown\":2, \"BrkSide\":2, \"Edwards\":2, \n        \"SWISU\":3, \"Sawyer\":3, \n        \"Mitchel\":4, \"NAmes\":4, \n        \"SawyerW\":5, \"NWAmes\":5, \n        \"Gilbert\":6, \"Blmngtn\":6, \n        \"CollgCr\":7, \"ClearCr\":7, \"Crawfor\":7, \n        \"Veenker\":8, \"Somerst\":8, \"Timber\":8, \n        \"StoneBr\":9, \"NoRidge\":9, \"NridgHt\":9,\n    }\nall_data[\"_NeighborhoodBin\"] = all_data[\"Neighborhood\"].map(neighborhood_map)\n\nplt.figure(figsize=(12, 3))\nax = sns.boxplot(x='Neighborhood', y='SalePrice', data=all_data[all_data['SalePrice'].notnull()], order=neighborhood_map.keys())\n_=ax.set_xticklabels(ax.get_xticklabels(), rotation='vertical')","2bac856a":"# encode quality - Ex(Excellent), Gd\uff08Good\uff09, TA\uff08Typical\/Average\uff09, Fa\uff08Fair\uff09, Po\uff08Poor\uff09\nall_data.loc[(all_data['PoolArea'] > 0) & (all_data['PoolQC'] == 'None'), 'PoolQC'] = 'TA'\ncols = ['ExterQual','ExterCond','BsmtQual','BsmtCond','HeatingQC','KitchenQual','FireplaceQu','GarageQual','GarageCond','PoolQC']\nfor c in cols:\n    all_data[c].replace({'None':0, 'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5}, inplace=True)\n\n# plot\nfig, axes = plt.subplots(ncols=4, nrows=2, figsize=(4 * 4, 3 * 2), sharey=True)\naxes = np.ravel(axes)\ncols = ['BsmtExposure','CentralAir','GarageFinish','Utilities','LandSlope','Functional','LotShape','SaleCondition']\nfor i, c in zip(np.arange(len(axes)), cols):\n    sns.boxplot(x=c, y='SalePrice', data=train.sort_values(by='SalePrice'), ax=axes[i])\n\n# encode remaining columns\nall_data['BsmtExposure'].replace({'Gd':4,'Av':3,'Mn':2,'No':1,'None':0}, inplace=True)\nall_data['CentralAir'].replace({'Y':1,'N':0}, inplace=True)\nall_data['GarageFinish'].replace({'Fin':3,'RFn':2,'Unf':1,'None':0}, inplace=True)\nall_data['Utilities'].replace({'AllPub':3,'NoSewr':2,'NoSeWa':1,'ELO':0}, inplace=True)\nall_data['LandSlope'].replace({'Gtl':2,'Mod':1,'Sev':0}, inplace=True)\nall_data['Functional'].replace({'Typ':7,'Min1':6,'Min2':5,'Mod':4,'Maj1':3,'Maj2':2,'Sev':1,'Sal':0}, inplace=True)\nall_data['LotShape'].replace({'Reg':3,'IR1':2,'IR2':1,'IR3':0}, inplace=True)\n\n# encode to another \nall_data['_PriceCut'] = all_data['SaleCondition'].replace(\n    {'AdjLand':1,'Abnorml':1,'Family':1,'Alloca':1,'Normal':0,'Partial':0})","f6ff7f73":"# Condition1&2, Exterior1st&2nd --> marged dummies\ndef pair_features_to_dummies(df, col1, col2, prefix):\n    d_1 = pd.get_dummies(df[col1].astype(str), prefix=prefix)\n    d_2 = pd.get_dummies(df[col2].astype(str), prefix=prefix)\n    for c in list(set(list(d_1.columns) + list(d_2.columns))):\n        if not c in d_1.columns: d_1[c] = 0\n        if not c in d_2.columns: d_2[c] = 0\n    return (d_1 + d_2).clip(0, 1)\n\ncond = pair_features_to_dummies(all_data,'Condition1','Condition2','Condition')\nexterior = pair_features_to_dummies(all_data,'Exterior1st','Exterior2nd','Exterior')\n\nall_data = pd.concat([all_data, cond, exterior], axis=1)\nall_data.drop(['Condition1','Condition2','Exterior1st','Exterior2nd'], axis=1, inplace=True)\nall_data.loc[:,cond.columns[0]:].head()","0dd0575d":"# Create new polynomial features about OverallQual\nall_data['_TotalSF_OverallQual'] = all_data['_TotalSF'] * all_data['OverallQual']\nall_data['_Neighborhood_OverallQual'] = all_data['_NeighborhoodBin'] + all_data['OverallQual']\nall_data['_Functional_OverallQual'] = all_data['Functional'] + all_data['OverallQual']","fd839d75":"for i, t in all_data.loc[:, all_data.columns != 'SalePrice'].dtypes.iteritems():\n    if t == object:\n        all_data = pd.concat([all_data, pd.get_dummies(all_data[i].astype(str), prefix=i)], axis=1)\n        all_data.drop(i, axis=1, inplace=True)","9331bc01":"#sns.boxplot(x='GarageCars', y='SalePrice', data=all_data[all_data['SalePrice'].notnull()])\nall_data['GarageCars'] = all_data['GarageCars'].clip(0,3)\n\n# They are either not very helpful or they cause overfitting.\nall_data.drop('MSZoning_C (all)', axis=1, inplace=True)\n\n# adverse effect\n#drop_cols = ['MiscVal', 'MoSold', 'ExterCond', 'BsmtFinSF2', 'BedroomAbvGr']\ndrop_cols = ['MiscVal', 'MoSold']\nall_data.drop(drop_cols, axis=1, inplace=True)\n\n#all_data.loc[(all_data['BsmtFinType2']=='None') & (all_data['BsmtFinSF2']>0), 'BsmtFinType2'] = 'ALQ'\n#all_data.drop('BsmtFinType2', axis=1, inplace=True)","63112efa":"train = all_data[all_data['SalePrice'].notnull()]\ntest = all_data[all_data['SalePrice'].isnull()].drop('SalePrice', axis=1)","eae3618c":"X_train = train.drop(['SalePrice','Id'], axis=1)\nY_train = train['SalePrice']\nX_test  = test.drop(['Id'], axis=1)\n\nprint(X_train.shape, Y_train.shape, X_test.shape)","4558654e":"from sklearn import ensemble, metrics\nfrom sklearn import linear_model, preprocessing\nfrom sklearn.model_selection import cross_val_score, cross_val_predict\nfrom sklearn.model_selection import GridSearchCV, KFold\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.kernel_ridge import KernelRidge\nimport xgboost as xgb","3ef1d67b":"#scaler = preprocessing.RobustScaler();\nscaler = preprocessing.StandardScaler();\nX_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\nX_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)","a660d7c4":"lasso = linear_model.Lasso(alpha=0.001, max_iter=5000, random_state=42)\nlasso.fit(X_train_scaled, np.log1p(Y_train))\nfi = pd.DataFrame({\"Feature Importance\":lasso.coef_}, index=X_train.columns)\nfi = fi[fi[\"Feature Importance\"] != 0].sort_values(\"Feature Importance\")\n\nfi.plot(kind=\"bar\",figsize=(18,4))\nplt.xticks(rotation=-90)\nplt.show()","146fb706":"from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n\nclass AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n    def __init__(self, models, weight):\n        self.models = models\n        self.weight = weight\n        \n    def fit(self, X, y):\n        self.models_ = [clone(x) for x in self.models]\n        for model in self.models_:\n            model.fit(X, y)\n        return self\n    \n    def predict(self, X):\n        predictions = np.column_stack([(model.predict(X) * weight) for model, weight in zip(self.models_, self.weight)])\n        return np.sum(predictions, axis=1)","04a8eeb3":"KRR = KernelRidge(alpha=0.05, kernel='polynomial', degree=1, coef0=2.5)\nlasso = linear_model.Lasso(alpha=0.001, max_iter=5000, random_state=42)\nGBoost = ensemble.GradientBoostingRegressor(n_estimators=1000, learning_rate=0.05, max_depth=3, \n                                            max_features='sqrt', loss='huber', random_state=42)\n\nreg = AveragingModels(models=(KRR, lasso, GBoost), weight=[0.25, 0.35, 0.40])","d88ad55a":"def rmse_cv(model, x, y):\n    rmse = np.sqrt(-cross_val_score(model, x, y, scoring=\"neg_mean_squared_error\", cv=5))\n    return rmse\n\nscore = rmse_cv(reg, X_train_scaled, np.log1p(Y_train))\nprint(round(score.mean(), 5))","5792d8ac":"reg.fit(X_train_scaled, np.log1p(Y_train))\nresult = np.expm1(reg.predict(X_test_scaled))","01599f5e":"submission = pd.DataFrame({\n    \"Id\": test[\"Id\"],\n    \"SalePrice\": result\n})\nsubmission.to_csv(\"submission.csv\", index=False)","e61171a8":"submission.head(10)","dadda522":"# Submit","6ff6ed17":"* feature creation","f00baded":"# Predict","a3915be9":"# Data Analysis","05271bda":"* fillna","15bf642a":"* encode, transform","1c70bff3":"## Preprocessing","a7333684":"# Load data","2b613b6d":"- predict","77bfea3f":"- create model"}}