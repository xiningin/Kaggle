{"cell_type":{"18de11c1":"code","6d583f09":"code","7a47c0e6":"code","37c37fbd":"code","4ada2795":"code","1da2c1d6":"code","f72c67c6":"code","f104e484":"code","4ef4c37a":"code","9e35b267":"code","1531679d":"code","c51e9c84":"code","85adb407":"code","3ddf0606":"code","2c2bf03d":"code","6d7df0c7":"code","bee5c503":"code","016c2b08":"code","dd0e0e94":"code","13bf0eef":"code","5d8afc08":"code","ef52e085":"code","f27a4a18":"code","60b27dbd":"code","afb3e9bb":"code","e0798fb4":"code","387a5d94":"code","387ff398":"code","4739f19d":"code","827e6423":"code","f884d476":"code","0d42f2ac":"code","c0c7b73f":"code","392d2639":"code","96da72bf":"code","ab7b21d1":"code","ca2b6029":"code","f935a031":"code","d099fbbf":"code","c2310dc5":"code","275cc05a":"code","67a55c62":"markdown","ae84c9e7":"markdown","678b34e0":"markdown","7c096440":"markdown","f95e4122":"markdown","59dc6883":"markdown","ac103d15":"markdown","bae99dd4":"markdown"},"source":{"18de11c1":"import numpy as np\nimport pandas as pd\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.ensemble import StackingClassifier\nimport seaborn as sns\nimport matplotlib.pyplot as plt","6d583f09":"df=pd.read_csv('\/kaggle\/input\/weather-dataset-rattle-package\/weatherAUS.csv')","7a47c0e6":"df.shape","37c37fbd":"df.info()","4ada2795":"df.duplicated().sum()","1da2c1d6":"df","f72c67c6":"df['RainTomorrow']=[1 if i=='Yes' else 0 for i in df['RainTomorrow'] ]","f104e484":"df","4ef4c37a":"df['RainTomorrow'].value_counts()","9e35b267":"df_corrs=df.corr()\ndf_corrs","1531679d":"cols_to_drop=['Date']\ndf.drop(columns=cols_to_drop,inplace=True)","c51e9c84":"df.info()","85adb407":"x=df.drop(['RainTomorrow'],axis=1)\ny=df['RainTomorrow']\nprint(x.shape,y.shape)","3ddf0606":"categorical_cols = list(x.select_dtypes(include=['object']).columns)\nx[categorical_cols].isna().sum()","2c2bf03d":"fig, axes = plt.subplots(4,1, figsize=(10, 10), sharey=False)\nfig.suptitle('Distribution')\n\n# Rainfall\nsns.boxplot(x=df[\"Rainfall\"], data = df, palette = 'Set2', ax = axes[0])\naxes[0].set_title(\"\")\n\n# Evaporation\nsns.boxplot(x= 'Evaporation', data = df, palette = 'Set2', ax = axes[1])\naxes[1].set_title(\"\")\n\n# Windspeed (9AM)\nsns.boxplot(x= 'WindSpeed9am', data = df, palette = 'Set2', ax = axes[2])\naxes[2].set_title(\"\")\n\n# Windspeed (3PM)\nsns.boxplot(x= 'WindSpeed3pm', data = df, palette = 'Set2', ax = axes[3])\naxes[3].set_title(\"\")\n\nplt.tight_layout()","6d7df0c7":"for i in categorical_cols:\n    x[i].fillna(x[i].mode()[0], inplace=True)   ","bee5c503":"x[categorical_cols].isna().sum()","016c2b08":"continuous_cols = list(x.select_dtypes(include=['float64']).columns)\nx[continuous_cols].isna().sum()","dd0e0e94":"for column in continuous_cols:\n    x[column].fillna(x[column].median(), inplace = True)\n    #xtest[column].fillna(xtest[column].median(), inplace = True)\n    \n# Checking missing values \nx.isna().sum()","13bf0eef":"transformer = ColumnTransformer(transformers=[('ohe1', OneHotEncoder(sparse='False',drop='first'), ['Location','WindGustDir','WindDir9am','WindDir3pm','RainToday'])],remainder='passthrough')","5d8afc08":"x=transformer.fit_transform(x)","ef52e085":"x.shape","f27a4a18":"transformer.named_transformers_['ohe1'].get_feature_names()","60b27dbd":"x","afb3e9bb":"print(x)","e0798fb4":"smote=SMOTE()\nx,y=smote.fit_resample(x,y)\n\nprint(x.shape,y.shape)","387a5d94":"x=pd.DataFrame(x.toarray())","387ff398":"x","4739f19d":"def check_skewness(x):\n    \n    skew_limit=0.75\n    skew_value=x[x.columns].skew()\n    skew_cols=skew_value[abs(skew_value)>skew_limit]\n    #print(skew_cols)\n    cols=skew_cols.index\n    return cols\n    \nskewed_col=check_skewness(x)\nprint(skewed_col)","827e6423":"x[skewed_col].skew()","f884d476":"from sklearn.preprocessing import PowerTransformer\n\npt=PowerTransformer(standardize=False)\nx[skewed_col]=pt.fit_transform(x[skewed_col])","0d42f2ac":"x[skewed_col].skew()","c0c7b73f":"xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size = 0.2, random_state = 0)","392d2639":"print(xtrain.shape)\nprint(ytrain.shape)\nprint(xtest.shape)\nprint(ytest.shape)","96da72bf":"from sklearn.preprocessing import StandardScaler\n\nsc=StandardScaler()\nxtrain=sc.fit_transform(xtrain)\nxtest=sc.transform(xtest)","ab7b21d1":"def evaluate(model):\n    model.fit(xtrain,ytrain)\n    accuracy=model.score(xtest,ytest)\n    \n    print('model name ',model)\n    print('accuracy ',accuracy)","ca2b6029":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\nlr=LogisticRegression()\nsvm=SVC()\ndt=DecisionTreeClassifier(max_depth=6)\nrf=RandomForestClassifier(max_samples=0.9)\nknn=KNeighborsClassifier(n_neighbors=5)\n\nmodels=[lr,dt,rf,knn]\n\nfor model in models:\n    evaluate(model)","f935a031":"base_models=[('RF',RandomForestClassifier(max_samples=0.9)),('lr',LogisticRegression())]\nmeta_model = LogisticRegression()\nstacking_model = StackingClassifier(estimators=base_models, final_estimator=meta_model, passthrough=True, cv=5)","d099fbbf":"stacking_model.fit(xtrain,ytrain)","c2310dc5":"stacking_model.score(xtest,ytest)","275cc05a":"from sklearn.metrics import classification_report\n\ny_pred = stacking_model.predict(xtest)\nprint(classification_report(ytest, y_pred))","67a55c62":"### How to decide whether to fill NaN values with Mean , Median or Mode ?\n -Always check for the outliers.If our Data is prone to outliers which means it contains good amount of outliers in that case do not choose Mean as it will implicitly contains information of outliers . Always choose Mode or Median in that case \n \n -If the amount of outliers are not significant choose Mean ","ae84c9e7":"### As we can see the data is highly Imbalanced . We will do oversampling latter to balance it because Imbalaned data will lead to bias.Below I have checked for Correaltion between variables to check irrelevent features ","678b34e0":"### As few columns doesnt have relation within them . We will make them ONE-HOT ENCODED ","7c096440":"### Checking the number of NaN values below","f95e4122":"**Upsampling for imbalanced Data**","59dc6883":"### Normality is a pre-requisite for ML algorithms , Hence I am checking the skewness and converting them into more like Normal Distribution","ac103d15":"### As we can see our Data is prone to Outliers .We will use Mode to fill NaN values .","bae99dd4":"### Converting our Matrix X to DataFrame"}}