{"cell_type":{"3a7adb70":"code","a1d81aa7":"code","c0e169ce":"code","0ebbd61a":"code","698c7698":"code","7f8786be":"code","4b265fb7":"code","ce92c4a4":"code","c911eef0":"code","5584d740":"code","ade3a872":"code","864ddcf9":"code","9c4f7aaa":"code","ab3cf11a":"code","56fe0217":"code","80484442":"code","0906f97d":"code","8023b866":"code","f82332d4":"code","2d0df5ee":"code","0e39c3c0":"code","5b1da88a":"code","3160e006":"code","834d312a":"code","58292f00":"code","031e84e2":"markdown","f062ace9":"markdown","d3312ece":"markdown","cea6e7c1":"markdown","5c54661c":"markdown"},"source":{"3a7adb70":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a1d81aa7":"import tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport matplotlib.pyplot as plt","c0e169ce":"df_train = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv')\ndf_test = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_test.csv')","0ebbd61a":"df_train.sample(5)","698c7698":"df_test.sample(5)","7f8786be":"df_train.sample(5)","4b265fb7":"df_train['label'].value_counts()","ce92c4a4":"df_test['label'].value_counts()","c911eef0":"# Shape \/Dimensions of Dataset\n\ndf_train.shape","5584d740":"df_test.shape","ade3a872":"# Let us plot some training images to see how they look\n\n\nrows = 10\ncolumns = 10\nfig,ax = plt.subplots(rows,columns,figsize = (16,16))\nax = ax.ravel()\nn_train = len(df_train)\nfor i in range(0,10*10):\n    index = np.random.randint(0, n_train)\n    img = df_train.iloc[index,1:]\n    img = np.array(img)\n    ax[i].imshow(np.squeeze(img.reshape(28,28,1)),cmap=plt.cm.binary)","864ddcf9":"train_data = np.array(df_train, dtype = 'float32')\ntest_data = np.array(df_test, dtype='float32')","9c4f7aaa":"#Let us normalize these values to a range from 0 to 1\n\nX_train = train_data[:,1:]\/255\n\ny_train = train_data[:,0]   #this is our target, thats why we are not dividing it\n\nX_test= test_data[:,1:]\/255\n\ny_test=test_data[:,0]    #this is our target, thats why we are not dividing it","ab3cf11a":"from sklearn.model_selection import train_test_split","56fe0217":"# test_size means 20 % data will be considered for testing the model\nX_train,X_validate,y_train,y_validate = train_test_split(X_train,y_train,test_size = 0.2,random_state = 12345)","80484442":"#Reshaping training data\n\nimage_shape = (28,28,1)\nX_train = X_train.reshape(X_train.shape[0],*image_shape)\nX_test = X_test.reshape(X_test.shape[0],*image_shape)\nX_validate = X_validate.reshape(X_validate.shape[0],*image_shape)","0906f97d":"from tensorflow.keras import layers, models","8023b866":"conv1 = layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1), padding='same' )\nconv2 = layers.Conv2D(64, (3,3), activation='relu')\nconv3 = layers.Conv2D(128, (3,3), activation='relu')","f82332d4":"#Creating first Max. Pooling Layer\nmax_pool_1 = layers.MaxPooling2D((2,2))\n\n#Creating second Max. Pooling Layer\nmax_pool_2 = layers.MaxPooling2D((2,2))\n\n#Creating third Max. Pooling Layer\nmax_pool_3 = layers.MaxPooling2D((2,2))","2d0df5ee":"flat_layer = layers.Flatten()\nfc = layers.Dense(128, activation='relu')\noutput = layers.Dense(10, 'softmax')","0e39c3c0":"# TensorFlow Keras uses Keras Sequential API\n\nmodel = models.Sequential()\n\nmodel.add(conv1)\nmodel.add(conv2)\nmodel.add(conv3)\nmodel.add(max_pool_1)\nmodel.add(flat_layer)\nmodel.add(fc)\nmodel.add(output)","5b1da88a":"# Let us see what all layers our model has\n\nmodel.summary()","3160e006":"model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","834d312a":"model.fit(X_train, y_train, epochs=15, batch_size=50, shuffle=True, validation_split=0.1) ","58292f00":"#Plotting the Accuracy\n\nplt.plot(model.history.history['accuracy'])\nplt.plot(model.history.history['val_accuracy'])\nplt.title(\"Accuracy\")\nplt.ylabel(\"accuracy\")\nplt.xlabel(\"epoch\")\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","031e84e2":"**Importing Libraries**","f062ace9":"**Building A Model**","d3312ece":"**Reading Data**","cea6e7c1":"**Evaluating Data**","5c54661c":"**Splitting Data**"}}