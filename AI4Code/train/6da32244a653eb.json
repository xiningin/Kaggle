{"cell_type":{"0fc98bd2":"code","5b0c4f47":"code","0f8a490b":"code","d0594178":"code","f82e570c":"code","ef262fee":"code","70d4cde8":"code","9f08e7d8":"code","2b97c328":"code","a86413d7":"code","0db5359f":"code","6c656f56":"code","d4864926":"code","94a486d0":"code","dcf08ed7":"code","dc9872c6":"code","32443ece":"code","5e0543e1":"code","928e3891":"code","ea8dc621":"code","5357db10":"code","d04d8d8f":"code","07d72724":"code","2133a6a4":"code","091532f7":"code","2b425344":"code","b6d16e46":"code","d84c5cf7":"code","704f2173":"code","2dd6af16":"code","690864eb":"code","8573bb78":"code","dd6ff339":"code","5bdae6ad":"code","3e3c9df0":"code","f03ad7c8":"code","7aac1e6d":"code","3480b629":"code","a4d7ea90":"code","00604df3":"code","5e67e7a5":"code","42ed3898":"code","ba1aea64":"code","5a30e361":"code","3812265e":"code","0b9b5bf8":"code","09834648":"code","24bf84ce":"code","f5aaf080":"code","52bfbd40":"code","070ce330":"code","2971ee71":"code","b55a573b":"code","28e2353a":"code","4dbc2e88":"code","54ee9473":"code","aefd6fdb":"code","71972adb":"code","4abdd58a":"code","ef101802":"code","4da8f44c":"code","7cd88068":"code","35a3d860":"code","24bcd5ef":"code","cce02d21":"code","7e3ad729":"code","fc80a28e":"code","9df3d582":"code","dd0c2dfb":"code","4603a4ee":"code","556f6deb":"code","58a8d6ea":"code","d091f43e":"code","3b5068f0":"code","025a820f":"code","3b08abb2":"code","2f351863":"code","3db7043c":"code","8920a0b8":"code","16e4b184":"code","3c4647c0":"code","6e663954":"code","9b3e1675":"code","de38c9b7":"code","67751ded":"markdown","ee61a3d9":"markdown","dac42522":"markdown","406a4e72":"markdown","6d3614ca":"markdown","c93ad7bf":"markdown","b8d1ea98":"markdown","d7163cf4":"markdown"},"source":{"0fc98bd2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5b0c4f47":"A=AA = pd.read_excel('\/kaggle\/input\/bank-loan-modelling\/Bank_Personal_Loan_Modelling.xlsx','Data')","0f8a490b":"AA.shape","d0594178":"# Load libraries\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LogisticRegression,SGDClassifier\nfrom sklearn.preprocessing import StandardScaler,LabelEncoder,PowerTransformer,QuantileTransformer\nfrom sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier,BaggingClassifier,GradientBoostingClassifier,VotingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns \nfrom sklearn.model_selection import train_test_split, cross_val_score,KFold,StratifiedKFold,GridSearchCV,RandomizedSearchCV\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier","f82e570c":"A.describe()\n# O Null Value \n# ID - 1 to 5000  , drop it \n# Age B\/w 23-67, Median at 45\n# Experience :min:-3 not possible , So treat all below Zero as 0, Mean & median is same : 20 ( So somewhat Normal Distributed )\n# ZIp Code:unique number to be count 25% :about 91k, 50% at 93K and 75% at 94 , Where min is just 9307 might be possible one digit forget to mention\n# Family :Family member b\/w 1 to 4\n# CCAvg:0-10, might be some hint of outlier here , as 75 % at 2.5 , max at 10, std is just 1.74\n# Education :1-to 3\n# Mortage : Upto 50% data nothing i.e 0, So highly skewed data... transformation required\n# Personal Loan :Highly skewed data , upto 75% , 0; \n# Securities:Highly negative data \n# CD Account:Highly negative data , Need treatment \n# Oneline and credit card Highly skewed data , Need treatment ","ef262fee":"A.info()\n# Column descriptions\n\n##\tData Description:\n##\n##\tID\tCustomer ID\n##\tAge\tCustomer's age in completed years\n##\tExperience\t#years of professional experience\n##\tIncome\tAnnual income of the customer ($000)\n##\tZIPCode\tHome Address ZIP code.\n##\tFamily\tFamily size of the customer\n##\tCCAvg\tAvg. spending on credit cards per month ($000)\n##\tEducation\tEducation Level. 1: Undergrad; 2: Graduate; 3: Advanced\/Professional\n##\tMortgage\tValue of house mortgage if any. ($000)\n##\tPersonal Loan\tDid this customer accept the personal loan offered in the last campaign?\n##\tSecurities Account\tDoes the customer have a securities account with the bank?\n##\tCD Account\tDoes the customer have a certificate of deposit (CD) account with the bank?\t\n##\tOnline\tDoes the customer use internet banking facilities?\n##\tCreditCard\tDoes the customer use a credit card issued by UniversalBank?","70d4cde8":"A.head()","9f08e7d8":"A.columns","2b97c328":"import missingno \nmissingno.bar(A,figsize=(12, 6), fontsize=12, color='steelblue')","a86413d7":"A.describe(include=[np.number])","0db5359f":"job_unique=A[\"Personal Loan\"].value_counts() # Remember difference between .columns & .columns.values & value_counts()\nprint(\"No. of distinct variables are\",job_unique.shape[0])\nprint(\"-\"*90)\nprint(\"Unique numbers are \\n\",job_unique.head(6))","6c656f56":"total = len(A)\nax=sns.countplot(A[\"Personal Loan\"])\nfor p in ax.patches:\n        ax.annotate('{:.1f}%'.format(100*p.get_height()\/total), (p.get_x()+0.2, p.get_height()+10)) # p has x, height function in patches \n \nax.yaxis.set_ticks(np.linspace(0, total, 21))\n\n#adjust the ticklabel to the desired format, without changing the position of the ticks. \nax.set_yticklabels(map('{:.1f}%'.format, 100*ax.yaxis.get_majorticklocs()\/total)) # Carry ax, then yaxis, then get_majortick locs()\nax.set_xticklabels(ax.get_xticklabels(),rotation=70)\nplt.show()","d4864926":"sns.distplot(job_unique)\nplt.show()","94a486d0":"A_numeric_col=A.select_dtypes(include=np.number)\nA_numeric_col","dcf08ed7":"A=A.drop(\"ID\",1)\nA.shape","dc9872c6":"A[\"Securities Account\"].value_counts()","32443ece":"np.argmin(A[\"ZIP Code\"].values)   ","5e0543e1":"A.loc[384,\"ZIP Code\"] # All other values in 90K + ","928e3891":"A=A.drop(384,0)\nA.shape","ea8dc621":"Experince_in_negative=np.where(A[\"Experience\"].values<0)\nExperince_in_negative\n#A.loc[89,\"Experience\"]","5357db10":"import statsmodels.api as sm\nfrom statsmodels.api import add_constant","d04d8d8f":"sns.pairplot(AA,x_vars=['Age'],y_vars=[ 'Experience', 'ZIP Code', 'Family', 'CCAvg',\n       'Education', 'Mortgage', 'Personal Loan', 'Securities Account',\n       'CD Account', 'Online', 'CreditCard'],kind=\"reg\") \n","07d72724":"# We imputed Wrong values for Exp vs Age , So Improve record as linear regression \nXc=sm.add_constant(A[\"Age\"])\nmodel = sm.OLS(A[\"Experience\"],Xc).fit()\nmodel.summary()\n","2133a6a4":"A[\"Experience\"]=A[\"Experience\"].apply(lambda x:x if x>=0 else np.nan)","091532f7":"A[\"Experience\"]=A.groupby(\"Age\")[\"Experience\"].transform(lambda x: x.fillna(x.mean()))\nA[\"Experience\"].isnull().sum()","2b425344":"df_age=A.groupby(\"Age\")\ndf_age.get_group(23)# here replace Exp with 0\ndf_age.get_group(23).index.tolist()","b6d16e46":"A[\"Experience\"]=A[\"Experience\"].fillna(value=0)","d84c5cf7":"A[\"Experience\"].isnull().sum()","704f2173":"from scipy.stats import ttest_ind,shapiro,mannwhitneyu","2dd6af16":"df_1=A[A[\"Personal Loan\"]==1]\ndf_0=A[A[\"Personal Loan\"]==0]","690864eb":"df_1.shape,A.columns","8573bb78":"ttest_ind(df_1.Age,df_0.Age)","dd6ff339":"type(A.columns.values)","5bdae6ad":"list_of_columns=A.columns.values.tolist() # list \nlist_of_columns.remove('Personal Loan')\nlist_of_columns","3e3c9df0":"list(map(lambda x,y:ttest_ind(df_0[x],df_1[y]),list_of_columns,list_of_columns)) ##list(map(lambda x,y:x+\"\"+y,list_of_columns,list_of_columns))","f03ad7c8":"# No need to perform mannwitney test( Non parametric Model )\nlist(map(lambda x,y:mannwhitneyu(df_0[x],df_1[y]),list_of_columns,list_of_columns))","7aac1e6d":"res=[lis[1] for lis in list(map(lambda x,y:mannwhitneyu(df_0[x],df_1[y]),list_of_columns,list_of_columns))]\nlist(zip(res,A.columns.values.tolist()))\npd.DataFrame(list(zip(res,list_of_columns)),columns=[\"Pvalue_paired_ttest\",\"Variable\"])\n","3480b629":"# just check Distribution of all variable and check skew\npd.DataFrame(list(zip(list(map(lambda x:df_0[x].skew(),list_of_columns)),\n                      list(map(lambda x:df_1[x].skew(),list_of_columns)),\n                      list_of_columns)),columns=[\"Df_0\",\"Df_1\",\"Varible\"])","a4d7ea90":"sns.FacetGrid(data=A,hue=\"Securities Account\",row=\"Personal Loan\").map(sns.countplot,\"Online\").add_legend()","00604df3":"predictor= A.iloc[:,A.columns != 'Personal Loan']\ntarget= A.iloc[:, A.columns == 'Personal Loan']\nprint(\"Target rows \", target.shape[0])\nprint(\"Target columns\", target.shape[1])\nprint(\"Predictor rows \", predictor.shape[0])\nprint(\"Predictor columns\", predictor.shape[1])","5e67e7a5":"A.corr()","42ed3898":"plt.figure(figsize=(12,6))\nsns.heatmap(A.corr(),annot=True,fmt=\".1g\",vmin=-1,vmax=1,center=0,linewidths=3,linecolor=\"black\",cmap=\"coolwarm\",mask=np.triu(A.corr()))","ba1aea64":"\nA.boxplot(column=[\"Age\",\"Income\"],by=\"Personal Loan\",layout=(2,1));","5a30e361":"sc=StandardScaler()\nX_std=sc.fit_transform(predictor)\nX_std\nX_std_df=pd.DataFrame(X_std)\nX_std_df.columns=predictor.columns\nX_std_df\n","3812265e":"\nfrom sklearn.model_selection import train_test_split\nxtrain,xtest,ytrain,ytest=train_test_split(X_std_df,target,test_size=0.4,random_state=0)\nLR=LogisticRegression()\n","0b9b5bf8":"LR.fit(xtrain,ytrain)","09834648":"LR.coef_","24bf84ce":"LR.intercept_","f5aaf080":"y_prob=LR.predict_proba(xtest)\ny_prob[:10]","52bfbd40":"y_class=LR.predict(xtest)\ny_class[:10]","070ce330":"cm=metrics.confusion_matrix(ytest,y_class)\nprint(cm)","2971ee71":"# If PowerTransformer used in place for StandardScaler\npt=PowerTransformer()\nX_std_pt=pt.fit_transform(predictor)\nX_std_pt\nX_std_pt=pd.DataFrame(X_std_pt)\nX_std_pt.columns=predictor.columns\nX_std_pt\n\nqt=QuantileTransformer()\nX_std_qt=qt.fit_transform(predictor)\nX_std_qt\nX_std_qt=pd.DataFrame(X_std_qt)\nX_std_qt.columns=predictor.columns\nX_std_qt","b55a573b":"xtrain1,xtest1,ytrain1,ytest1=train_test_split(X_std_pt,target,test_size=0.4,random_state=0)\nxtrain2,xtest2,ytrain2,ytest2=train_test_split(X_std_qt,target,test_size=0.4,random_state=0)\n","28e2353a":"LR1=LogisticRegression()\nLR1.fit(xtrain1,ytrain1)\ny_class1=LR1.predict(xtest1)\ncm=metrics.confusion_matrix(ytest1,y_class1)\nprint(cm)\n","4dbc2e88":"LR2=LogisticRegression()\nLR2.fit(xtrain2,ytrain2)\ny_class2=LR1.predict(xtest2)\ncm=metrics.confusion_matrix(ytest2,y_class2)\nprint(cm)","54ee9473":"pca1=PCA(n_components=0.99)\npca2=PCA(n_components=0.99)\n\nX_std_pt_PCA=pca1.fit_transform(X_std_pt)\nX_std_pt_PCA\nX_std_pt_PCA=pd.DataFrame(X_std_pt_PCA,columns=[\"PC\"+str(i) for i in range(0,len(pca1.explained_variance_),1)])\nX_std_pt_PCA\n\n","aefd6fdb":"X_std_qt_PCA=pca2.fit_transform(X_std_qt)\nX_std_qt_PCA\nX_std_qt_PCA=pd.DataFrame(X_std_qt_PCA,columns=[\"PC\"+str(i) for i in range(0,len(pca2.explained_variance_),1)])\nX_std_qt_PCA","71972adb":"xtrain3,xtest3,ytrain3,ytest3=train_test_split(X_std_pt_PCA,target,test_size=0.4,random_state=0)\nxtrain4,xtest4,ytrain4,ytest4=train_test_split(X_std_qt_PCA,target,test_size=0.4,random_state=0)\n","4abdd58a":"LR3=LogisticRegression()\nLR3.fit(xtrain3,ytrain3)\ny_class3=LR3.predict(xtest3)\ncm=metrics.confusion_matrix(ytest3,y_class3)\nprint(cm)","ef101802":"LR4=LogisticRegression()\nLR4.fit(xtrain4,ytrain4)\ny_class4=LR4.predict(xtest4)\ncm=metrics.confusion_matrix(ytest4,y_class4)\nprint(cm)","4da8f44c":"\nfrom sklearn.calibration import CalibratedClassifierCV\nsig=CalibratedClassifierCV()\nlr=LogisticRegression(class_weight=\"balanced\")\nlr.fit(xtrain1,ytrain1)\nsig=CalibratedClassifierCV(lr,method=\"sigmoid\")\nsig.fit(xtrain1,ytrain1)\npredicted_y=sig.predict(xtest1)\ncm=metrics.confusion_matrix(ytest1,predicted_y)\nprint(cm)","7cd88068":"import xgboost as xgb","35a3d860":"model2 = xgb.XGBClassifier(n_estimators=150, max_depth=8, learning_rate=0.1, subsample=0.5)\ntrain_model2 = model2.fit(xtrain1,ytrain1)\npredicted_y=train_model2.predict(xtest1)\ncm=metrics.confusion_matrix(ytest1,predicted_y)\nprint(cm)","24bcd5ef":"metrics.accuracy_score(ytest1,predicted_y)","cce02d21":"print(metrics.classification_report(ytest1, predicted_y,\n                            digits = 4,\n                            target_names=[\"Not Loan Customer\",\n                                          \"Loan Customer\"]))","7e3ad729":"dt=DecisionTreeClassifier()\nparamgrid={\"criterion\":[\"gini\",\"entropy\"],\"max_depth\":np.arange(1,15,1)}\nskf=StratifiedKFold(shuffle=True,n_splits=5,random_state=32)\ngd=GridSearchCV(estimator=dt,param_grid=paramgrid,cv=skf)","fc80a28e":"gd.fit(xtrain1,ytrain)\ngd.best_params_","9df3d582":"dt=DecisionTreeClassifier(criterion= \"entropy\", max_depth= 4)\nskf1=StratifiedKFold(shuffle=True,n_splits=5,random_state=32)\ndt.fit(xtrain1,ytrain)\nypredict=dt.predict(xtest1)\ncm=metrics.confusion_matrix(ytest1,ypredict)\ncm","dd0c2dfb":"dt2=DecisionTreeClassifier(criterion= \"entropy\", max_depth= 4)\nScoreDtCv=cross_val_score(dt2,xtrain1,ytrain1,cv=skf1,scoring=\"roc_auc\")\nprint(np.mean(ScoreDtCv))\nprint(np.std(ScoreDtCv))","4603a4ee":"rf=RandomForestClassifier()\nbootstrap = [True, False]\nn_estimators = [int(x) for x in np.linspace(start = 20, stop = 500, num = 50)]\nparam_grid={\"criterion\":['gini',\"entropy\"],\n           \"n_estimators\":n_estimators,\n          \n           \"bootstrap\":bootstrap,\n           \n            \"max_features\" : ['auto', 'sqrt']\n           }\n           \n           \nrs=RandomizedSearchCV(estimator=rf,param_distributions=param_grid,\n                      n_iter = 100, cv = 3,random_state=42,\n                      n_jobs=-1,verbose=2) \nrs.fit(xtrain1,ytrain1)\nrs.best_params_\n\n\n           ","556f6deb":"rf=RandomForestClassifier(n_estimators= 225,max_features= \"auto\",\n criterion= \"entropy\",\n bootstrap= False)\nsk=StratifiedKFold(shuffle=True,random_state=42,n_splits=5)\nscore=cross_val_score(rf,xtrain1,ytrain1,cv=sk,scoring=\"roc_auc\")\nprint(np.mean(score))\nprint(np.std(score))","58a8d6ea":"rf.fit(xtrain1,ytrain1)\nypred=rf.predict(xtest1)\ncm=metrics.confusion_matrix(ytest1,ypred)\ncm","d091f43e":"ascore=metrics.accuracy_score(ytest1,ypred)\nascore","3b5068f0":"AB_be=[]\nfor i in np.arange(1,15):\n  AB=AdaBoostClassifier(base_estimator=rf,n_estimators=i,random_state=0)\n  kfold = KFold(shuffle=True,n_splits=5,random_state=0)\n  mse=cross_val_score(AB,xtrain1,ytrain1.values.ravel(),cv=kfold,scoring='roc_auc')\n  rmse=np.sqrt(np.abs(mse))\n  AB_be.append(np.mean(rmse))","025a820f":"yt=ytest1\nyt.shape\nX_std_pt.shape","3b08abb2":"from keras.layers import Dense, Flatten ,Dropout,BatchNormalization\nfrom keras.models import Sequential","2f351863":"modelz=Sequential()\nmodelz.add(Dense(16,input_dim=12,activation=\"relu\"))\n","3db7043c":"modelz.add(Dense(8,activation=\"relu\"))\nmodelz.add(Dense(1,activation=\"sigmoid\"))","8920a0b8":"modelz.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=['accuracy'])\n#model.fit(X_std_pt,target,epochs=10,batch_size=32)","16e4b184":"modelz.summary()","3c4647c0":"predictor.shape","6e663954":"from keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\n\n \n","9b3e1675":"modelz.fit(predictor,target,epochs=250,batch_size=16)","de38c9b7":"#modelz.fit(X_std_qt,target,epochs=150,batch_size=32)\nmodelz.fit(X_std_qt,target,epochs=250,batch_size=16)","67751ded":"# Data Information\n","ee61a3d9":" ### T-Test: Parametric test\n ### Shapiro: To check Linearity of variable \n ### Mannwhitneyu test Non parametric test used to apply when ttest fails, and we are about to reject any variable on the hypothesis we made on the basis on domain\n \n ","dac42522":"# Get Linear Relationship for Age And Experiance \n\n ","406a4e72":"# Just Draw Bar Garph for Data imbalance","6d3614ca":"Lets Begin With Two copies of Dataset __ Or You may go with DeepCopy","c93ad7bf":"**Download Bank_loan_Dataset ******","b8d1ea98":"# Parametric Test: for Linear Models\n\n# Non Parametric Test for Non Linear Models\n\n","d7163cf4":"# Bar Graph for Non-missing values"}}