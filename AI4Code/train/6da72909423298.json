{"cell_type":{"50a22069":"code","8d0ea12a":"code","94011eeb":"code","2f0d1f6d":"code","42226ac5":"code","3d51c28b":"code","b0dd193e":"code","e8cd5bad":"code","c16c89bf":"code","18274eb4":"code","2ba259c5":"code","27b4e931":"markdown"},"source":{"50a22069":"!pip install kaggle-environments==1.7.2 -q","8d0ea12a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom glob import glob\nimport itertools\nfrom tqdm.notebook import tqdm_notebook as tqdm\n\nimport random","94011eeb":"N_MATCHES = 100","2f0d1f6d":"from kaggle_environments.envs.rps.agents import *\nfrom kaggle_environments import make\n\nenv = make('mab', debug = True)","42226ac5":"agents = sorted(glob('..\/**\/submission.py', recursive=True) + glob('..\/**\/sample_agent.py', recursive=True))\nagents","3d51c28b":"agent_names = [\n    'Default UCB with decay', \n    'Santa 2020: epsilon-greedy with decay', \n    'Santa 2020 Starter', \n    'Santa 2020'\n]","b0dd193e":"agent_dict = {}\nfor a, b in zip(agent_names, agents):\n    agent_dict[a] = b","e8cd5bad":"def match(agent0, agent1):\n        \n    env.reset()\n    \n    env.run([agent_dict[agent0], agent_dict[agent1]])\n    json = env.toJSON()\n    rewards = json['rewards']\n    \n    # cumulative reward\n    result_df.at[agent0, 'cum_reward'] += rewards[0]\n    result_df.at[agent1, 'cum_reward'] += rewards[1]\n    \n    result_df.at[agent0, 'games'] += 1\n    result_df.at[agent1, 'games'] += 1\n    \n    # average reward\n    result_df['score'] = result_df['cum_reward'] \/ result_df['games']\n    \n    scores[agent0].append(rewards[0])\n    scores[agent1].append(rewards[1])","c16c89bf":"result_df = pd.DataFrame(np.zeros((len(agent_names), 3)), columns=['score', 'cum_reward', 'games'], index=agent_names)\nscores = {k:[] for k in agent_names}    ","18274eb4":"for i in range(N_MATCHES):\n    agent0, agent1 = np.random.choice(agent_names, size=2, replace=False)\n    match(agent0, agent1)","2ba259c5":"# which model works better?\n# Let's plot distribution of total rewards.\n\nfig, axes = plt.subplots(figsize = (12, 8))\nmedian_dic = {k: np.median(scores[k]) for k in scores.keys()}\nsorted_models = sorted(median_dic, key=lambda x: median_dic[x])[::-1]\n\nplt.boxplot(tuple(scores[key] for key in sorted_models))\naxes.set_xticklabels(sorted_models)\n\nfor y, i in zip(tuple(scores[key] for key in sorted_models), \n                range(len(sorted_models))):\n    # \"jitter\" to the x-axis \n    x = np.random.normal(i+1, 0.05, size=len(y))\n    plt.plot(x, y, '.', color=\"C{}\".format(i))\n\nplt.xticks(rotation=90)\nplt.show()","27b4e931":"The aim of this notebook is to evaluate which agent works better.\n"}}