{"cell_type":{"3bd8d301":"code","7d850571":"code","57148e3f":"code","719caae1":"code","255c6d4c":"code","030dfc2d":"code","5d883fc6":"code","9b542504":"code","c689e627":"code","878a4a11":"code","62f41073":"code","d37ac284":"code","0d11dcb3":"code","b747d5c7":"code","c2317652":"code","b978799c":"code","044442ed":"code","70d41089":"code","59c6bc1f":"code","e644a083":"code","e8505639":"code","c138c7fd":"code","b5a09910":"code","38a93eaa":"code","2b2019ac":"code","e0b878f0":"code","e3cbc241":"code","cbd3e66d":"code","ecb057e5":"code","e7815dd6":"code","c9b4fd60":"code","b49cf2f9":"markdown","aad75f5f":"markdown","a3b0d944":"markdown","ba453f5c":"markdown","f1460356":"markdown","23dceea9":"markdown","10572d94":"markdown","873ea3d7":"markdown","a88195ef":"markdown","d285bbe1":"markdown","0211ef42":"markdown","18b03644":"markdown"},"source":{"3bd8d301":"import os\nimport pandas as pd\nimport numpy as np\n\nPATH_TO_DATA = '..\/input\/'\n\ndf_train_features = pd.read_csv(os.path.join(PATH_TO_DATA, \n                                             'train_features.csv'), \n                                    index_col='match_id_hash')\ndf_train_targets = pd.read_csv(os.path.join(PATH_TO_DATA, \n                                            'train_targets.csv'), \n                                   index_col='match_id_hash')\ndf_test_features = pd.read_csv(os.path.join(PATH_TO_DATA, 'test_features.csv'), \n                                   index_col='match_id_hash')","7d850571":"df_train_features.head()","57148e3f":"from sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier(n_estimators=100, n_jobs=4, random_state=17)","719caae1":"from sklearn.model_selection import ShuffleSplit, KFold\nfrom sklearn.model_selection import cross_val_score\ncv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=17)","255c6d4c":"from sklearn.model_selection import train_test_split\nimport eli5\nfrom IPython.display import display_html","030dfc2d":"def evaluate_model(train_df, test_df, target_df, model=model, cv=cv):\n\n    X = train_df.values\n    y = target_df['radiant_win'].values\n    \n    cv_scores = cross_val_score(model, X, y, cv=cv, scoring='roc_auc')\n    \n    print (cv_scores, cv_scores.mean())\n    \n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=17)\n    \n    model.fit(X_train, y_train)\n    \n    display_html(eli5.show_weights(estimator=model, \n                  feature_names=train_df.columns.values, top=50))\n    \n    return model, cv_scores","5d883fc6":"model, cv_score_base = evaluate_model(df_train_features, df_test_features, df_train_targets)","9b542504":"def combine_numeric_features (df, feature_suffixes):\n    for feat_suff in feature_suffixes:\n        for team in 'r', 'd':\n            players = [f'{team}{i}' for i in range(1, 6)] # r1, r2...\n            player_col_names = [f'{player}_{feat_suff}' for player in players] # e.g. r1_gold, r2_gold\n            \n            df[f'{team}_{feat_suff}_max'] = df[player_col_names].max(axis=1) # e.g. r_gold_max\n            df[f'{team}_{feat_suff}_mean'] = df[player_col_names].mean(axis=1) # e.g. r_gold_mean\n            df[f'{team}_{feat_suff}_min'] = df[player_col_names].min(axis=1) # e.g. r_gold_min\n            \n            df.drop(columns=player_col_names, inplace=True) # remove raw features from the dataset\n    return df","c689e627":"numeric_features = ['kills', 'deaths', 'assists', 'denies', 'gold', 'xp', 'health', 'max_health', 'max_mana', 'level', 'towers_killed', 'stuns', 'creeps_stacked', 'camps_stacked', 'lh', 'rune_pickups', 'firstblood_claimed', 'teamfight_participation', 'roshans_killed', 'obs_placed', 'sen_placed']","878a4a11":"df_train_features = combine_numeric_features(df_train_features, numeric_features)\ndf_test_features = combine_numeric_features(df_test_features, numeric_features)","62f41073":"df_train_features.head()","d37ac284":"model, cv_score_num = evaluate_model(df_train_features, df_test_features, df_train_targets)","0d11dcb3":"def make_coordinate_features(df):\n    for team in 'r', 'd':\n        players = [f'{team}{i}' for i in range(1, 6)] # r1, r2...\n        for player in players:\n            df[f'{player}_distance'] = np.sqrt(df[f'{player}_x']**2 + df[f'{player}_y']**2)\n            df.drop(columns=[f'{player}_x', f'{player}_y'], inplace=True)\n    return df\n","b747d5c7":"df_train_features = make_coordinate_features(df_train_features)\ndf_test_features = make_coordinate_features(df_test_features)","c2317652":"df_train_features.head()","b978799c":"coord_features = ['distance']","044442ed":"df_train_features = combine_numeric_features(df_train_features, coord_features)\ndf_test_features = combine_numeric_features(df_test_features, coord_features)","70d41089":"df_train_features.head()","59c6bc1f":"model, cv_score_coord = evaluate_model(df_train_features, df_test_features, df_train_targets)","e644a083":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom itertools import combinations","e8505639":"def hero_id_subset_analyzer(text):\n    # it takes a string of hero ids (like '1 2 5 4 3') as input\n    ids = set()\n    for i in range(1, 4): # we need all subset of lenght 1-3. I think longer combinations are not relevant\n        hero_ids = text.split(' ') # '1 2 5 4 3'-> ['1', '2', '5', '4', '3']\n        hero_ids.sort() # sort them as '1 2 5 4 3' and '3 1 4 5 3' should produce the same set of tokens \n        combs = set(combinations(hero_ids, i)) # all combinations of length i e.g for 2 are: (1,2), (1,3)... (2,5)... etc\n        ids = ids.union(combs)\n    ids = { \"_\".join(item) for item in ids} # convert from lists to string e.g. (1,2) -> '1_2'\n    return ids","c138c7fd":"# ngram range is (1,1) as all combinations are created by analyser\n# 1000 features - I think it's enough to cover all heroes + popular combos\nhero_id_vectorizer = TfidfVectorizer(ngram_range = (1, 1), max_features = 1000, tokenizer = lambda s: s.split(), analyzer=hero_id_subset_analyzer)","b5a09910":"def replace_hero_ids (df, train=True, vectorizer=hero_id_vectorizer):\n\n    for team in 'r', 'd':\n        players = [f'{team}{i}' for i in range(1, 6)] # r1, r2,...\n        hero_columns = [f'{player}_hero_id' for player in players] # r1_hero_id,....\n        \n        # combine all hero id columns into one \n        df_hero_id_as_text = df[hero_columns].apply(lambda row: ' '.join([str(i) for i in row]), axis=1).tolist()\n        \n        if train:\n            new_cols = pd.DataFrame(vectorizer.fit_transform(df_hero_id_as_text).todense(), columns = vectorizer.get_feature_names())\n        else:\n            new_cols = pd.DataFrame(vectorizer.transform(df_hero_id_as_text).todense(), columns = vectorizer.get_feature_names())\n        \n        # add index to vectorized dataset - needed for merge?\n        new_cols['match_id_hash'] = df.index.values\n        new_cols = new_cols.set_index('match_id_hash').add_prefix(f'{team}_hero_') # e.g.r_hero_10_21\n        \n        df = pd.merge(df, new_cols, on='match_id_hash')\n        df.drop(columns=hero_columns, inplace=True)\n    return df","38a93eaa":"df_train_features = replace_hero_ids(df_train_features)\ndf_test_features = replace_hero_ids(df_test_features, train=False)","2b2019ac":"df_train_features.head()","e0b878f0":"model, cv_score_hero = evaluate_model(df_train_features, df_test_features, df_train_targets)","e3cbc241":"X = df_train_features.values\ny = df_train_targets['radiant_win'].values","cbd3e66d":"%time\nmodel.fit(X, y)","ecb057e5":"X_test = df_test_features.values\ny_test_pred = model.predict_proba(X_test)[:, 1]\n\ndf_submission = pd.DataFrame({'radiant_win_prob': y_test_pred}, \n                                 index=df_test_features.index)","e7815dd6":"df_submission.head()","c9b4fd60":"import datetime\nsubmission_filename = 'submission_{}.csv'.format(\n    datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\ndf_submission.to_csv(submission_filename)\nprint('Submission saved to {}'.format(submission_filename))","b49cf2f9":"Load datasets","aad75f5f":"Let's train the model on the raw features to get a baseline to compare. This kernel is based on Yury Kashnitskiy's \"How to start\" [kernel](https:\/\/www.kaggle.com\/kashnitsky\/dota2-win-prediction-how-to-start), so the model and cross-validation scheme are simply taken from there.","a3b0d944":"## Numeric features","ba453f5c":"Save the submission file, it's handy to include current datetime in the filename. ","f1460356":"The idea is taken from this [kernel](https:\/\/www.kaggle.com\/utapyngo\/dota-2-how-to-make-use-of-hero-ids). However, I'd like to use not only individual hero ids but possible combinations of them","23dceea9":"As the distance is also a numeric feature convert it into the team features as above","10572d94":"For numeric features such as gold, XP, kills etc just combine them for each team and calculate some basic functions - min, max, average. \n\n*May be sum could be reasonable for some of them? ***","873ea3d7":"## Preparing a submission\n","a88195ef":"## Hero id features","d285bbe1":"# <center> Dota 2 winner prediction\n\n<img src='https:\/\/habrastorage.org\/webt\/ua\/vn\/pq\/uavnpqfoih4zwwznvxubu33ispy.jpeg'>\n\n    \n### General idea\n\nEach team consists of 5 player and they are ordered 1....5. If we switch say 1 and 2 players (and thus their features in dataset) we could assume that the game result should be the same. However, a model built on the dataset will unlikely reflect that. So,theidea is to get rid of the player order somehow. \n\nNote: I've just started learning Pyhton, Pandas and ML, so some things could be implemented not very pitonish, pandish, etc, I'd appreciate if you point such things out in comments.","0211ef42":"## Coordinate-related features","18b03644":"As we see coordinate features (x and y) are quite important. However, I think we need to combine them into one feature.Simplest idea is the distance from the left bottom corner. So, short distances mean near own base, long distances - near the enemy base\n\n*I assume the coordinates a caclualted from the left bottom corner, If it's not correct, need to reevaluate that*"}}