{"cell_type":{"1e7d4c30":"code","ad7b816a":"code","ede07602":"code","cdcceec8":"code","104cb762":"code","2b7a18f6":"code","464b8f70":"code","324c8c84":"code","667e62c3":"code","b5a1cbf0":"code","d2f48dad":"code","0299418d":"code","88c666f6":"code","c89f0111":"code","efa43f72":"code","551a042c":"code","36331cb7":"code","05907db5":"code","13efd689":"code","7f4d4020":"code","15728799":"code","2d3f23c9":"code","40bff313":"code","58b37188":"code","36d7b76d":"code","aa70c160":"code","ca941e9b":"code","5083c82e":"code","d983ba20":"code","27aec3a6":"code","591803c8":"code","dbbf7464":"code","2fd5118c":"code","60d5fa07":"code","9345d503":"code","b38d19bc":"code","41df8081":"code","2a2689cb":"code","40cb67d0":"code","2daff5b6":"code","0967540c":"markdown","e84b3e3e":"markdown","341a9c19":"markdown","ed60c3a1":"markdown","4a73dd83":"markdown","91c052c3":"markdown","3bcb9b30":"markdown","14d6a728":"markdown","99f14e4a":"markdown","ee7c5c39":"markdown","81da3bbf":"markdown","8e315209":"markdown","5bc50076":"markdown","36d6e164":"markdown","99368feb":"markdown","84a5f1b6":"markdown","bb1e0b19":"markdown","1efc6a0d":"markdown","2f33f99c":"markdown","40b9529f":"markdown","eea17410":"markdown","10af5665":"markdown","712360fc":"markdown","3b4e6393":"markdown","d62ebabc":"markdown","aa03fbf8":"markdown"},"source":{"1e7d4c30":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","ad7b816a":"# showing all columns\npd.set_option('display.max_columns', None)","ede07602":"from sklearn.datasets import load_iris","cdcceec8":"iris_data = load_iris()","104cb762":"type(iris_data)","2b7a18f6":"iris_data.keys()","464b8f70":"# feature names (variable names)\niris_data['feature_names']","324c8c84":"# independed variable\niris_data['target_names']","667e62c3":"iris_df = pd.DataFrame(data = iris_data['data'], columns = iris_data['feature_names'])","b5a1cbf0":"iris_df.head()","d2f48dad":"iris_df['Iris type'] = iris_data['target']","0299418d":"iris_df.head()","88c666f6":"iris_df['Iris name'] = iris_df['Iris type'].apply(lambda x: 'sentosa' if x == 0 else ('versicolor' if x == 1 else 'virginica'))","c89f0111":"iris_df.head()","efa43f72":"def f(x):\n    if x == 0:\n        val = 'setosa'\n    elif x == 1:\n        val = 'versicolor'\n    else:\n        val = 'virginica'\n    return val","551a042c":"iris_df['test'] = iris_df['Iris type'].apply(f)","36331cb7":"iris_df.head()","05907db5":"iris_df.drop(['test'], axis =1, inplace = True)","13efd689":"iris_df.info()","7f4d4020":"iris_df.describe()","15728799":"iris_df.groupby(['Iris name']).describe()","2d3f23c9":"iris_df.columns","40bff313":"# im just making a function in order not to repeat the same code\ndef plot_violin(y2,i):\n    plt.subplot(2,2,i)\n    \n    sns.violinplot(x='Iris name',y= y2, data=iris_df)","58b37188":"plt.figure(figsize=(17,12))\ni = 1\nfor measurement in iris_df.columns[:-2]:\n    plot_violin(measurement,i)\n    sns.despine(offset=10, trim=True)\n    i += 1\n    ","36d7b76d":"sns.pairplot(iris_df, hue = 'Iris name', vars = ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], palette = 'Set1' );","aa70c160":"iris_df.iloc[:,:4].corr()","ca941e9b":"fig, axes = plt.subplots(figsize=(7,7))\nsns.heatmap(iris_df.iloc[:,:4].corr(), annot = True, cbar=False)\naxes.tick_params(labelrotation=45)\nplt.title('Correlation heatmap', fontsize = 15);","5083c82e":"from sklearn.model_selection import train_test_split","d983ba20":"X = iris_df[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)','petal width (cm)']]\ny = iris_df['Iris name']","27aec3a6":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)","591803c8":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=3)","dbbf7464":"knn.fit(X_train, y_train)","2fd5118c":"y_pred = knn.predict(X_test)","60d5fa07":"y_pred","9345d503":"print(f'Our model accuracy with k=3 is: {knn.score(X_test, y_test)}')","b38d19bc":"# Source code credit for this function: https:\/\/gist.github.com\/shaypal5\/94c53d765083101efc0240d776a23823\n# also thanks https:\/\/www.youtube.com\/watch?v=2osIZ-dSPGE&ab_channel=codebasics for his video, letting me know for this code\ndef print_confusion_matrix(confusion_matrix, class_names, figsize = (9,7), fontsize=14):\n    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n    \n    Note that due to returning the created figure object, when this funciton is called in a\n    notebook the figure willl be printed twice. To prevent this, either append ; to your\n    function call, or modify the function by commenting out the return expression.\n    \n    Arguments\n    ---------\n    confusion_matrix: numpy.ndarray\n        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n        Similarly constructed ndarrays can also be used.\n    class_names: list\n        An ordered list of class names, in the order they index the given confusion matrix.\n    figsize: tuple\n        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n        the second determining the vertical size. Defaults to (10,7).\n    fontsize: int\n        Font size for axes labels. Defaults to 14.\n        \n    Returns\n    -------\n    matplotlib.figure.Figure\n        The resulting confusion matrix figure\n    \"\"\"\n    df_cm = pd.DataFrame(\n        confusion_matrix, index=class_names, columns=class_names, \n    )\n    fig = plt.figure(figsize=figsize)\n    try:\n        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\", cbar=False)\n    except ValueError:\n        raise ValueError(\"Confusion matrix values must be integers.\")\n    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n    plt.ylabel('True label', fontsize = 12)\n    plt.xlabel('Predicted label', fontsize = 12)\n    plt.title('Confusion Matrix', fontsize = 16)\n    # Note that due to returning the created figure object, when this funciton is called in a notebook\n    # the figure willl be printed twice. To prevent this, either append ; to your function call, or\n    # modify the function by commenting out this return expression.\n    # return fig","41df8081":"from sklearn.metrics import classification_report, confusion_matrix","2a2689cb":"print_confusion_matrix(confusion_matrix(y_test, y_pred), ['sentosa', 'versicolor', 'virginica'])","40cb67d0":"print(classification_report(y_test, y_pred))","2daff5b6":"\nfig = plt.figure(figsize=(15,7))\n\nax1 = fig.add_subplot(1,2,1)\nax1 = sns.scatterplot(x = X_test['petal length (cm)'], y = X_test['petal width (cm)'], hue = y_pred, alpha = 0.5)\nplt.title('Predicted')\nplt.legend(title='Iris name')\n\nax2 = fig.add_subplot(1,2,2)\nax2 = sns.scatterplot(x = X_test['petal length (cm)'], y = X_test['petal width (cm)'], hue = y_test, alpha = 0.5)\nplt.title('Actual');","0967540c":"Lets add the iris type from the irs_data['target']","e84b3e3e":"# Exploring the iris data set","341a9c19":"Lets make a pandas dataframe using the data, and target. Then we will assign its target names to it as column names","ed60c3a1":"The above lambda function might not be that readable, thus lets just make a function and use apply to add the new column.","4a73dd83":"## Training our ML model","91c052c3":"If we groupby them by their type can refine better information","3bcb9b30":"Works fine, however lets get rid of the test column:","14d6a728":"lets use some statistics","99f14e4a":"We are going to use and test the k-Nearest Neighbors model, and since out data does not seem \"noisy\" we can choose a small value of k. We will set the k to 3.\n\nAlthough we noticed that high correlaton between the **petal width** and **length** measurements, we will use all the mesurements available at the moment, \nand later check which gives the better accuracy.\n\nFurthermore keep in mind that KNN is calculating the euclidean distance between the point we want to predict and the nearest(s) training data point(s) (neighbor). To this end \nscaling (normalizing) the data before applying the alogirthm usually is a good approach. However in our case all the data use the same unit of measurement (cm) so this is not necessary. ","ee7c5c39":"Calculating the accuracy with knn.score()","81da3bbf":"Lets import the iris data set (is included within the scikit-learn module)","8e315209":"## Evaluating the Model","5bc50076":"From the above plots we can notice that the three different types can easily been spotted by their petal and sepal measurements. Thus a ML model could learn how to separate them.","36d6e164":"![iris.png](attachment:iris.png)","99368feb":"Also lets assign its iris type name","84a5f1b6":"First we have to import the needed libraries","bb1e0b19":"The **sepal width** and **width** are not correlated while the are highly correlated.\nUsing just the highly correlated measurements might increase our accurasy model.","1efc6a0d":"According to the classification report we can notice very good accuracy, precision and recall.\n\n1.\nPrecision means how many predictions were correct out of the number of the predicted class. Precision = TP\/(TP + FP)\nFor sentosa and versicolor the KNN achieved perfect precision, while for virginica 90%, meaning that out of all the predicted labels assigned as virginica the 90% were correct. More precisely the model predicted 10 flowers as virginica, while the 9 were correct predictions (TP), and 1 was wrong (FP). Precision_virginica 9\/(9+1) = 0.9.\n\n2.\nRecall means how many predictions were correct out of the actual number of the specific class. Recall = TP\/(TP + FN).\nFor versicolor the recalll score was 94%, meaning that the model predicted correct 15 versicolor flowers (TP), while 1 of them was assigned incorrectly as virginica (FN).  Recall_versicolor = 15\/(15 + 1) = 0.94.\n\nIn this case, since we have not greate imbalance in our sample the accuracy scores serves as a good performance measure of the model.","2f33f99c":"We can observe that appears to be a distiction between the sizes of each type of iris. The mean values of sepal length of each flower type are 5, 5.9 and 6.5 (cm) resulting an easy distiction, while all the other measurements follow similar trends. \nAlthough some min values might be close, some max values show differences, for example the the width of a versicolor petal is 3 times the width of the sentosa one and 0.7 mm less then the virginica one.\n\nHowever some graphs will helps us understand and spot better any differences.","40b9529f":"Our iris_df","eea17410":"From the above violin plots we can notice hight density of the length and width of sentosa species, especialy for sepal length, petal length and petal width.\nAlso we can observe that the mean values and the interquartile range for the petal measurements are easily distinguish, althought the values of virginica species are more spreaded. ","10af5665":"Lets make some graphs to help us understand our data","712360fc":"Lets explore our data","3b4e6393":"Lets firstly call the train_test_split to split our data","d62ebabc":"## Data visualization","aa03fbf8":"Lets also produce a heatmap above to find out the correlations between the measurements"}}