{"cell_type":{"63374c0e":"code","fcf3bfba":"code","d4eb8a58":"code","8814def2":"code","24256417":"code","7921f512":"code","d4511ba9":"markdown","6edef24c":"markdown","0f04fe07":"markdown","a7926d66":"markdown"},"source":{"63374c0e":"from gensim.models import KeyedVectors\n\n# As of Gensim 3.7.3 it's using some deprecated function and we don't care about it\nimport warnings\nwarnings.filterwarnings(\"ignore\")","fcf3bfba":"%timeit -n 30 model = KeyedVectors.load(\"..\/input\/glove.twitter.27B.200d.gensim\")","d4eb8a58":"%timeit -n 30 model = KeyedVectors.load(\"..\/input\/glove.twitter.27B.200d.gensim\", mmap=\"r\")","8814def2":"model.most_similar(\"good\")","24256417":"model.most_similar(positive=[\"woman\", \"king\"], negative=[\"man\"])","7921f512":"model[\"good\"]","d4511ba9":"... and that's it. Now you do your NLP from here. Good luck!","6edef24c":"This is tiny `mmap=\"r\"` tells gensim\/numpy to read bytes from the [disk directly to memory](https:\/\/en.wikipedia.org\/wiki\/Mmap). It just can't get faster than that.\n\nAnd now we can play around with vectors:","0f04fe07":"Glove in 4 seconds! But if you think that's impressive, hold my beer:","a7926d66":"# Hello\n\nI put some popular word embeddings into a single Kaggle dataset in unified gensim format. Models are binarized, so they are quick to load (data is stored in numpy arrays).\n\nWhy:\n* Unified format - single handling function for different embeddings\n* gensim mdoels are nice - a lot of helpful methods, take `most_similar` for example\n* Fast loading!"}}