{"cell_type":{"12c093d2":"code","3c5b6abf":"code","a84bde1c":"code","62f0ff91":"code","cbeeddc3":"code","bcab4e49":"code","03e68bdc":"code","a50f9b81":"code","5afb66bc":"code","f800bb00":"code","e5f2a679":"code","bcc31d76":"code","42008ec5":"code","fa2a758b":"code","f0260a1d":"code","18f0a622":"code","5b33bd51":"code","8841c9d1":"code","ab780125":"code","dac4e946":"code","8d425001":"code","5cfbc9ed":"code","7cb7af58":"code","a9045f5d":"code","5781c0d2":"code","59e05af6":"code","547d12fb":"code","af752391":"code","25ff8aaf":"code","0a84eded":"code","c9560213":"code","5157962e":"code","d1b8cb53":"markdown","6dc5a32f":"markdown","295d1c1a":"markdown","f3b80664":"markdown","96e35fdb":"markdown","a8b8e373":"markdown","6ca2eca0":"markdown","a787e587":"markdown","83242df6":"markdown","ccf31b4b":"markdown","d3f7d40f":"markdown"},"source":{"12c093d2":"import pandas as pd\nimport numpy as np\nimport json\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport plotly.graph_objs as go\nfrom plotly.tools import FigureFactory as FF\nfrom wordcloud import WordCloud, STOPWORDS\nfrom plotly import tools\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected = True)","3c5b6abf":"us_df = pd.read_csv('..\/input\/USvideos.csv')","a84bde1c":"us_df.head()","62f0ff91":"us_df['trending_date'] = pd.to_datetime(us_df['trending_date'], format='%y.%d.%m')","cbeeddc3":"us_df['publish_time'] = pd.to_datetime(us_df['publish_time'], format='%Y-%m-%dT%H:%M:%S.%fZ')","bcab4e49":"us_df.head()","03e68bdc":"us_df['publish_date'] = us_df['publish_time'].dt.date\nus_df['publish_tym'] = us_df['publish_time'].dt.time","a50f9b81":"columns = ['views', 'likes' , 'dislikes' , 'comment_count']\nfor col in columns:\n    us_df[col] = us_df[col].astype(int)\nus_df['category_id'] = us_df['category_id'].astype(str)","5afb66bc":"us_df.info()","f800bb00":"id_to_category = {}\n\nwith open('..\/input\/US_category_id.json' , 'r') as f:\n    data = json.load(f)\n    for category in data['items']:\n        id_to_category[category['id']] = category['snippet']['title']\nid_to_category","e5f2a679":"us_df['category'] = us_df['category_id'].map(id_to_category)","bcc31d76":"us_df.head()","42008ec5":"def view_bar(x,y,title):\n    plt.figure(figsize = (13,11))\n    sns.barplot(x = x, y = y)\n    plt.title(title)\n    plt.xticks(rotation = 90)\n    plt.show()","fa2a758b":"x = us_df.category.value_counts().index\ny = us_df.category.value_counts().values\ntitle = \"Categories\"\nview_bar(x,y,title)","f0260a1d":"x = us_df.channel_title.value_counts().head(10).index\ny = us_df.channel_title.value_counts().head(10).values\ntitle = \"Top 10 Channels\"\nview_bar(x,y,title)","18f0a622":"sort_by_views = us_df.sort_values(by =\"views\" , ascending = False).drop_duplicates('title', keep = 'first')","5b33bd51":"x = sort_by_views['title'].head(10)\ny = sort_by_views['views'].head(10)\ntitle = \"Most watched videos\"\nview_bar(x,y,title)","8841c9d1":"sort_by_likes = us_df.sort_values(by =\"likes\" , ascending = False).drop_duplicates('title', keep = 'first')\nx = sort_by_likes['title'].head(10)\ny = sort_by_likes['likes'].head(10)\ntitle = \"Most liked videos\"\nview_bar(x,y,title)","ab780125":"sort_by_dislikes = us_df.sort_values(by =\"dislikes\" , ascending = False).drop_duplicates('title', keep = 'first')\nx = sort_by_dislikes['title'].head(10)\ny = sort_by_dislikes['dislikes'].head(10)\ntitle = \"Most disliked videos\"\nview_bar(x,y,title)","dac4e946":"sort_by_comment = us_df.sort_values(by =\"comment_count\" , ascending = False).drop_duplicates('title', keep = 'first')\nx = sort_by_comment['title'].head(10)\ny = sort_by_comment['comment_count'].head(10)\ntitle = \"Most commented videos\"\nview_bar(x,y,title)","8d425001":"def createwordcloud(data , bgcolor , title):\n    plt.figure(figsize = (13,14))\n    wc = WordCloud(background_color = bgcolor, max_words = 1000, stopwords = STOPWORDS, max_font_size = 50)\n    wc.generate(' '.join(data))\n    plt.imshow(wc)\n    plt.axis('off')","5cfbc9ed":"tags = us_df['tags']\ncreatewordcloud(tags , 'black' , 'commonly used tags' )","7cb7af58":"tags = us_df['tags'].map(lambda x : x.lower().split('|')).values\nall_tags = [tag for t in tags for tag in t]\ntags1 = pd.DataFrame({'tags' : all_tags})\nx = tags1['tags'].value_counts().index[0:10]\ny = tags1['tags'].value_counts().values[0:10]\ntitle = \"Top 10 most frequently used tags\"\nview_bar(x,y,title)\n","a9045f5d":"title = us_df['title']\ncreatewordcloud(title , 'black' , 'commonly used words in titles' )","5781c0d2":"description = us_df['description'].astype('str')\ncreatewordcloud(description , 'black' , 'commonly used words in description' )","59e05af6":"us_df.head()","547d12fb":"us_df['publish_date'] = pd.to_datetime(us_df['publish_date'])\nus_df['diff'] = (us_df['trending_date'] - us_df['publish_date']).dt.days","af752391":"us_df[['trending_date'  ,'views']].set_index('trending_date').plot()","25ff8aaf":"sns.heatmap(us_df[['views' , 'likes' , 'dislikes' , 'comment_count']].corr(), annot = True, fmt = \".2f\")\nplt.show()","0a84eded":"for i , category in us_df.groupby('category'):\n    sns.heatmap(category[['views' , 'likes' , 'dislikes' , 'comment_count']].corr(), annot = True, fmt = \".2f\")\n    plt.title(i)\n    plt.show()","c9560213":"dates_per_id = us_df[['video_id' , 'trending_date']].groupby('video_id', as_index = False).count()\nlong_trending = dates_per_id.loc[dates_per_id['trending_date'] == 13, 'video_id'].tolist()\nlong_trending_videos = us_df.loc[us_df['video_id'].isin(long_trending) , ['title' , 'trending_date' , 'views' , 'likes' , 'dislikes' , 'comment_count']]\nlong_trending_videos['views'] = long_trending_videos['views'].apply(lambda x : x \/ 100000)\nvideo_titles = long_trending_videos['title'].unique().tolist()\n","5157962e":"views = []\nlikes = []\ndislikes = []\ncomments = []\nplots_list = [views, likes, dislikes, comments]\ncolumn_list = ['views' , 'likes' , 'dislikes' , 'comment_count']\nboolen_list = [False , False, False, True]\ncolor_list = []\nfor _ in range(0, len(video_titles)):\n    color = 'rgb('+str(np.random.randint(1,256))+','+str(np.random.randint(1,256))+','+str(np.random.randint(1,256))+')'\n    color_list.append(color)\n    \nfor x in range(0 , len(plots_list)):\n    for i in range(0, len(video_titles)):\n        vt = video_titles[i]\n        trace = go.Scatter(x = long_trending_videos.loc[long_trending_videos['title'] == vt , 'trending_date'],\n                          y = long_trending_videos.loc[long_trending_videos['title'] == vt, column_list[x]],\n                          name = vt,\n                          line = dict(width = 2, color = color_list[i]),\n                          legendgroup = vt,\n                          showlegend = boolen_list[x])\n        plots_list[x].extend([trace])\nfig = tools.make_subplots(rows=4, cols=1, subplot_titles = ('Views', 'Comments', 'Likes', 'Dislikes'), vertical_spacing=0.07)\nfor i in views:\n    fig.append_trace(i, 1, 1)\n        \nfor i in comments:\n    fig.append_trace(i, 2, 1)\n        \nfor i in likes:\n    fig.append_trace(i, 3, 1)\n        \nfor i in dislikes:\n    fig.append_trace(i, 4, 1)\n    \nfig['layout']['xaxis1'].update(title='')\nfig['layout']['xaxis2'].update(title='')\nfig['layout']['xaxis3'].update(title='')\nfig['layout']['xaxis4'].update(title='')\n\nfig['layout']['yaxis1'].update(title='mln. views')\nfig['layout']['yaxis2'].update(title='comments')\nfig['layout']['yaxis3'].update(title='likes')\nfig['layout']['yaxis4'].update(title='dislikes')\n    \nfig['layout'].update(width=800, height=(1000 + len(video_titles)*60))\nfig['layout'].update(title='Different metrics for videos')\nfig['layout'].update(legend = dict(x=0.0,y = -(0.1+len(video_titles)*0.007),tracegroupgap = 1))\n\niplot(fig, filename='customizing-subplot-axes')\n        ","d1b8cb53":"Converting some of flot datatype column to int datatype for memory reduction, also converting category_id column to String datatype. ","6dc5a32f":"Formating trending_date and publish_date columns. pd.to_datetime will convert the  column datatype to datetime ","295d1c1a":"Lets look some of the sample data using pandas head(). By default it will return 1st 5 rows from the dataframe","f3b80664":"Loading Youtube statistics csv file using pandas read_csv(). This function will read the given csv file and save it in pandas DataFrame format","96e35fdb":"### I do analyse the youtube data to undersand the US videos patterns.\n\n**We will find for some informations like:**\n\n* Whats the most frequent type of video?\n* The distribuition of views, likes, comments and engamet is equal for all category's?\n* We have normal distribuition to the values?\n* Whats the most frequent names in title, description, tags?","a8b8e373":"Reading category_id json file which has category name using read mode. This can be mapped with us_dataframe to map category_id with corresponding category","6ca2eca0":"Plotting category name along with count of records available for each category ","a787e587":"****YouTube is an American video-sharing website headquartered in San Bruno, California. The service was created by three former PayPal employees\u2014Chad Hurley, Steve Chen, and Jawed Karim\u2014in February 2005. Google bought the site in November 2006 for US$1.65 billion; YouTube now operates as one of Google\u2019s subsidiaries.****\n\n\n![](https:\/\/www.seoclerk.com\/pics\/443105-1Cdpmj1460287445.png)","83242df6":"Creating a function to display seaborn barplot given values for x axis, y axis and title","ccf31b4b":"pandas info() method can be used to display information about the columns in dataframe","d3f7d40f":"to be continued ..UNDER CONSTRUCTION"}}