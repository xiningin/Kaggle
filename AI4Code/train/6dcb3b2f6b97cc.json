{"cell_type":{"542d3948":"code","8bfc9c3d":"code","af2eac0b":"code","0d5c6234":"code","83841237":"code","8a279e46":"code","2cc0f213":"code","7033718b":"code","a9dc34e0":"code","dd980016":"markdown","04322975":"markdown","4d196f0d":"markdown","bf9c345f":"markdown","87d164db":"markdown","84fdc701":"markdown"},"source":{"542d3948":"import os\nimport cv2\nimport pandas as pd\nfrom tqdm.notebook import tqdm\n\n\nDATA_PATH = '\/kaggle\/input\/cassava-leaf-disease-classification'\n\nJPEG_PATH = os.path.join(DATA_PATH, 'train_images')\nJPEG_SAVE_PATH = '\/kaggle\/train_images_jpeg'\n\nCSV_PATH = os.path.join(DATA_PATH, 'train.csv')\n\nRESIZE = 128\nNUM_TFREDORDS = 1338\nIMG_QUALITY = 95\nDEBUG = False\n\n\nos.makedirs(JPEG_SAVE_PATH, exist_ok=True)\ntrain_df = pd.read_csv(CSV_PATH)","8bfc9c3d":"img_size = {}\nfiles = sorted(os.listdir(JPEG_PATH))\ntargets = train_df['label']\n\n# https:\/\/www.kaggle.com\/nakajima\/duplicate-train-images\n# drop_img_id = ['3551135685.jpg', '911861181.jpg', '1562043567.jpg', '3551135685.jpg']\n# flies = [f for f in files if f not in drop_img_id]\n\nif DEBUG:\n    files = files[:25]\n    targets = targets[:25]\n\nfor img_id in tqdm(files):\n    img = cv2.imread(os.path.join(JPEG_PATH, img_id))\n    if img.shape in img_size:\n        img_size[img.shape] += 1\n    else:\n        img_size[img.shape] = 1\n        \nprint(f'Size of each the image: {img_size}')","af2eac0b":"for img_id in tqdm(files):\n    load_path = os.path.join(JPEG_PATH, img_id)\n    save_path = os.path.join(JPEG_SAVE_PATH, img_id)\n    img = cv2.imread(load_path)\n    img = cv2.resize(img, (RESIZE, RESIZE))\n    cv2.imwrite(save_path, img)\n    \n!tar -czf 'train_images_{RESIZE}x{RESIZE}.tar.gz' \/kaggle\/train_images_jpeg\/*.jpg","0d5c6234":"import matplotlib.pyplot as plt\n\n\ndef jpeg_display(directory_path):\n    fig, axes = plt.subplots(5, 5, figsize=(16, 16))\n    for i in range(25):\n        img = cv2.imread(os.path.join(directory_path, files[i]))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        axes[i\/\/5][i%5].imshow(img)\n        axes[i\/\/5][i%5].set_title(f'{files[i]}: {targets[i]}')\n    plt.show()","83841237":"jpeg_display(JPEG_PATH)","8a279e46":"jpeg_display(JPEG_SAVE_PATH)","2cc0f213":"import math\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\n\nnum_iter = math.ceil(len(files) \/ NUM_TFREDORDS)\n\n\ndef _bytes_feature(value):\n  \"\"\"Returns a bytes_list from a string \/ byte.\"\"\"\n  if isinstance(value, type(tf.constant(0))):\n    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\n\ndef _int64_feature(value):\n  \"\"\"Returns an int64_list from a bool \/ enum \/ int \/ uint.\"\"\"\n  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\n\ndef serialize_example(feature0, feature1, feature2):\n  feature = {\n      'image': _bytes_feature(feature0),\n      'image_name': _bytes_feature(feature1),\n      'target': _int64_feature(feature2)\n  }\n  example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n  return example_proto.SerializeToString()\n\n\n\nfor i in range(num_iter):\n    print(f'Writing TFRecord: {i}')\n    cnt = min(NUM_TFREDORDS, len(files) - i*NUM_TFREDORDS)\n    tf_filename = f'ld_train{str(i).zfill(2)}-{cnt}.tfrec'\n    \n    with tf.io.TFRecordWriter(tf_filename) as wf:\n        for j in range(cnt):\n            img_id = files[NUM_TFREDORDS*i + j]\n            img = cv2.imread(os.path.join(JPEG_PATH, img_id))\n            img = cv2.resize(img, (RESIZE, RESIZE))\n            # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  -> Fix:20201121\n            \n            img = cv2.imencode('.jpg', img, (cv2.IMWRITE_JPEG_QUALITY, IMG_QUALITY))[1].tostring()\n            img_id = str.encode(img_id)\n            target = train_df['label'][NUM_TFREDORDS*i + j]\n            \n            example = serialize_example(img, img_id, target)\n            \n            wf.write(example)","7033718b":"import numpy as np\n\n\ndef decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    return image\n\n\ndef parse_example(example):\n    LABELED_TFREC_FORMAT = {\n        'image': tf.io.FixedLenFeature([], tf.string),\n        'image_name': tf.io.FixedLenFeature([], tf.string),\n        'target': tf.io.FixedLenFeature([], tf.int64)\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    label = example['image_name']\n    target = example['target']\n    return image, label, target\n\n\ndef display_one(image, title, target, subplot, red=False, titlesize=16):\n    plt.subplot(*subplot)\n    plt.axis('off')\n    plt.imshow(image)\n    plt.title(f'{title}: {target}')\n    return (subplot[0], subplot[1], subplot[2]+1)\n\n\ndef display_batch_of_images(databatch):\n    images, labels, targets = databatch\n    images = images.numpy()\n    labels = labels.numpy()\n    targets = targets.numpy()\n    if labels is None:\n        labels = [None for _ in enumerate(images)]\n    if targets is None:\n        targets = [None for _ in enumerate(targets)]\n        \n    # auto-squaring: this will drop data that does not fit into square or square-ish rectangle\n    rows = int(math.sqrt(len(images)))\n    cols = len(images)\/\/rows\n        \n    # size and spacing\n    FIGSIZE = 13.0\n    SPACING = 0.2\n    subplot=(rows, cols, 1)\n    if rows < cols:\n        plt.figure(figsize=(FIGSIZE,FIGSIZE\/cols*rows))\n    else:\n        plt.figure(figsize=(FIGSIZE\/rows*cols,FIGSIZE))\n    \n    # display\n    for i, (image, label, target) in enumerate(zip(images[:rows*cols], labels[:rows*cols], targets[:rows*cols])):\n        title = label\n        title = title.decode('utf-8')\n        correct = True\n        dynamic_titlesize = FIGSIZE*SPACING\/max(rows,cols)*40+3 # magic formula tested to work from 1x1 to 10x10 images\n        subplot = display_one(image, title, target, subplot, not correct, titlesize=dynamic_titlesize)\n    \n    #layout\n    plt.tight_layout()\n    if label is None and predictions is None:\n        plt.subplots_adjust(wspace=0.2, hspace=0.2)\n    else:\n        plt.subplots_adjust(wspace=SPACING, hspace=SPACING)\n    plt.show()","a9dc34e0":"resize_file = f'ld_train00-{min(len(files), NUM_TFREDORDS)}.tfrec'\ndataset = tf.data.TFRecordDataset([resize_file]).map(parse_example).batch(25)\ndata = iter(dataset)\ndisplay_batch_of_images(next(data))","dd980016":"### image checking","04322975":"## JPEG","4d196f0d":"## TFRecords","bf9c345f":"### image checking","87d164db":"- I have prepared both datasets jpeg and tfredords.\n- There is a prepared dataset at the following link.\n- JPEG ([128x128](https:\/\/www.kaggle.com\/spidermandance\/cassava-jpeg-128x128), [196x196](https:\/\/www.kaggle.com\/spidermandance\/cassava-jpeg-196x196), [256x256](https:\/\/www.kaggle.com\/spidermandance\/cassava-jpeg-256x256), [384x384](https:\/\/www.kaggle.com\/spidermandance\/cassava-jpeg-384x384), [512x512](https:\/\/www.kaggle.com\/spidermandance\/cassava-jpeg-512x512))\n- TFRecords ([128x128](https:\/\/www.kaggle.com\/spidermandance\/cassava-tfrecords-128x128), [196x196](https:\/\/www.kaggle.com\/spidermandance\/cassava-tfrecords-196x196), [256x256](https:\/\/www.kaggle.com\/spidermandance\/cassava-tfrecords-256x256), [384x384](https:\/\/www.kaggle.com\/spidermandance\/cassava-tfrecords-384x384), [512x512](https:\/\/www.kaggle.com\/spidermandance\/cassava-tfrecords-512x512))\n\n(11\/21\/2020 ver3)\n- Fix: Removing the `img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)` TFRecords cell.\n- Add: Image check.","84fdc701":"## Size checking"}}