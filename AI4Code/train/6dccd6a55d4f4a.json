{"cell_type":{"4e901be4":"code","8c32b8eb":"code","9ebefc6b":"code","02d007a1":"code","82b638e2":"code","ae18ec95":"code","1d5c1be9":"code","a5f14622":"code","3bcf164d":"code","79667465":"code","a2536650":"code","94127c8e":"code","e77ee9ef":"code","cfb61977":"code","42eaef26":"code","f5f3d34e":"markdown","9adce8c3":"markdown","2024dd74":"markdown","17a3e0cf":"markdown","2f5f4935":"markdown"},"source":{"4e901be4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8c32b8eb":"# Imports\nimport os\nfrom glob import glob\n\nimport cv2\nimport math\nimport skimage\nimport sklearn\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.callbacks import *\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","9ebefc6b":"TARGET_PATH = '\/kaggle\/input\/cat-dataset\/CAT_00'\n\ndef get_original_images(dir_path: str):\n    original_images_paths = []\n    original_images = []\n    [original_images_paths.append(path) for path in glob(f'{TARGET_PATH}\/*.jpg')]\n  \n    for image_path in original_images_paths:\n      original_image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n      casted_original_image = np.array(original_image)\n      original_images.append(casted_original_image)\n    return sorted(original_images_paths), original_images\n\noriginal_images_paths, original_images = get_original_images(TARGET_PATH)","02d007a1":"# Plot original images \n\nplt.figure(figsize=(15, 10))\n\nfor index in range(5):\n  w, h = original_images[index].shape[0], original_images[index].shape[1]\n  plt.subplot(3, 3, index+1)\n  plt.title(f'Original image #{index} with size: {h}*{w}')\n  plt.imshow(original_images[index])\n  plt.axis('off')","82b638e2":"# Util functions\n\ndef resize_img(im, img_size):\n  \"\"\" Resize input image with provided by user input.\n  \n  Notes:\n     source: https:\/\/github.com\/kairess\/cat_hipsterizer\/blob\/master\/preprocess.py \n\n  Returns:\n     new_im, ratio, top, left\n  \"\"\"\n\n  old_size = im.shape[:2] \n  ratio = float(img_size) \/ max(old_size)\n  new_size = tuple([int(x*ratio) for x in old_size])\n  im = cv2.resize(im, (new_size[1], new_size[0]))\n  delta_w = img_size - new_size[1]\n  delta_h = img_size - new_size[0]\n  top, bottom = delta_h \/\/ 2, delta_h - (delta_h \/\/ 2)\n  left, right = delta_w \/\/ 2, delta_w - (delta_w \/\/ 2)\n  new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n  return new_im, ratio, top, left\n\n\ndef apply_gaussian(xL, yL, H, W, sigma=5):\n  channel = [math.exp(-((c - xL) ** 2 + (r - yL) ** 2) \/ (2 * sigma ** 2)) for r in range(H) for c in range(W)]\n  channel = np.array(channel, dtype=np.float32)\n  channel = np.reshape(channel, newshape=(H, W))\n  channel = cv2.GaussianBlur(channel, (5,5), 0)\n  return channel\n\n\ndef get_mask(height, width, landmarks, s=3):\n        \"\"\" Generate a full Heap Map for every landmarks in an array\n\n        Arguments:\n          width: width of target output\n          height: height of target output\n          joints: [(x1,y1),(x2,y2)...] containing landmarks\n          s: denote sigma\n        \"\"\"\n\n        def get_gaussian_kernel(x0, y0, sigma, width, height):\n          \"\"\" Make a square gaussian kernel centered at (x0, y0) with sigma as SD.\n          \"\"\"\n\n          x = np.arange(0, width, 1, float) \n          y = np.arange(0, height, 1, float)[:, np.newaxis]\n          result = np.exp(-((x-x0)**2 + (y-y0)**2) \/ (2*sigma**2))\n          return result\n        \n        landmarks_number = len(landmarks)\n        heatmap = np.zeros((height, width, landmarks_number), dtype = np.float32)\n        for i in range(landmarks_number):\n            if not np.array_equal(landmarks[i], [-1,-1]):\n                heatmap[:,:,i] = get_gaussian_kernel(landmarks[i][0], landmarks[i][1], s, height, width)\n            else:\n                heatmap[:,:,i] = np.zeros((height,width))\n        return heatmap","ae18ec95":"# Form images_dataset && masks_dataset\n\nfiles_list = sorted(os.listdir(TARGET_PATH))\n\nimages_dataset = []\nmasks_dataset = []\n\ndataset = {\n  'images': [],\n  'images_masks': [],\n  'landmarks': [],\n  'bounding_boxes': []\n}\n\nfor file_name in files_list:\n  if '.cat' not in file_name:\n    continue\n\n  pd_frame = pd.read_csv(os.path.join(TARGET_PATH, file_name), sep=' ', header=None)\n  landmarks = (pd_frame.values[0][1:7]).reshape((-1, 2))      \n\n  img_filename, ext = os.path.splitext(file_name)\n  img = cv2.imread(os.path.join(TARGET_PATH, img_filename))\n\n  img, ratio, top, left = resize_img(img, 128)\n  landmarks = ((landmarks * ratio) + np.array([left, top])).astype(np.int)\n  bb = np.array([np.min(landmarks, axis=0), np.max(landmarks, axis=0)])\n\n  heatmaps = []\n  for landmark in landmarks:\n     heatmap = apply_gaussian(landmark[0], landmark[1], 128, 128)\n     heatmaps.append(heatmap)\n  \n  heatmaps = np.array(heatmaps)\n  image_mask = get_mask(128, 128, landmarks, 3)\n\n  x1, y1, x2, y2 = bb.flatten()                     \n  if x1 > 20 and y1 > 20:\n      x1, y1, x2, y2 = x1-20, y1-20, x2+20, y2+20       \n\n  heatmaps = heatmaps.sum(axis=0)\n\n  img = img[y1:y2, x1:x2]                 \n  image_mask = image_mask[y1:y2, x1:x2]\n\n  img, ratio, top, left = resize_img(img, 64)\n  landmarks = ((landmarks * ratio) + np.array([left, top])).astype(np.int)\n  bb = np.array([np.min(landmarks, axis=0), np.max(landmarks, axis=0)])\n  image_mask, ratio, top, left = resize_img(image_mask, 64)\n\n  dataset['landmarks'].append(landmarks.flatten())  \n  dataset['bounding_boxes'].append(bb.flatten())           \n  dataset['images'].append(img)                  \n  dataset['images_masks'].append(image_mask)\n\n  images_dataset.append(img)\n  masks_dataset.append(image_mask)","1d5c1be9":"all_images = np.array(images_dataset)\nall_masks = np.array(masks_dataset)\n\ntrain_data, test_data, train_label, test_label = train_test_split(all_images, all_masks, test_size=.2, shuffle=False)\ntrain_data, valid_data, train_label, valid_label = train_test_split(all_images, all_masks, test_size=.25, shuffle=False)\n\nprint('Training', train_data.shape[0])\nprint('Validation', valid_data.shape[0])\nprint('Test', test_data.shape[0])","a5f14622":"# Plot few of processed images and corresponding masks\n\nselected_images_indexes = np.random.choice(100, 2)\n\nfor _, image_index in enumerate(selected_images_indexes):\n  plt.title(\"Processed Image\")\n  plt.imshow(train_data[image_index]);\n  plt.show()\n\n  plt.title(\"Image Mask\")\n  plt.imshow(train_label[image_index])\n  plt.show()","3bcf164d":"# Normalise dataset and plot few of normalised images and corresponding masks\n\nX_train_norm = (train_data \/ 255)\nX_val_norm = (valid_data \/ 255)\nX_test_norm = (test_data \/ 255)\n\n\nselected_images_indexes = np.random.choice(100, 2)\n\nfor _, image_index in enumerate(selected_images_indexes):\n  plt.title(\"Processed & Normalized Image\")\n  plt.imshow(X_train_norm[image_index]);\n  plt.show()\n\n  plt.title(\"Image Mask\")\n  plt.imshow(train_label[image_index])\n  plt.show()","79667465":"SEED=42  #=1\nBATCH_SIZE=32\n\ndatagen = ImageDataGenerator(featurewise_center=False, \n                             featurewise_std_normalization=False, \n                             width_shift_range=0.1, \n                             height_shift_range=0.1, \n                             zoom_range=0.2\n                             )\n\nimage_generator = datagen.flow(\n        X_train_norm,\n        batch_size=BATCH_SIZE,\n        shuffle=True,\n        seed=SEED)\n\nlabel_generator = datagen.flow(\n        train_label,\n        batch_size=BATCH_SIZE,\n        shuffle=True,\n        seed=SEED)\n\ntrain_generator = zip(image_generator, label_generator)","a2536650":"## Input Layer\ninput = Input(shape=(64, 64, 3))\n\n# Block 1\nx = Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same', name='block1_conv1')(input)\nx = Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same', name='block1_conv2')(x)\nx = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n\n# Block 2\nx = Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same', name='block2_conv1')(x)\nx = Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same', name='block2_conv2')(x)\nx = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n\n## BottleNeck    \nx = (Conv2D(filters=160, kernel_size=(16, 16), activation='relu' , padding='same', name=\"bottleneck_1\"))(x)\nx = (Conv2D(filters=160, kernel_size=(1, 1) , activation='relu' , padding='same', name=\"bottleneck_2\"))(x)\n\n## Output\noutput = Conv2DTranspose(filters=3, kernel_size=(2, 2),  strides=(4,4), use_bias=False, name='upsample_1')(x)\n\nmodel = Model(input, output)\nmodel.compile(optimizer='RMSProp', loss='mse', metrics=['mse']) \nmodel.summary()","94127c8e":"history = model.fit(\n    train_generator,\n    validation_data = (X_val_norm, valid_label), \n    steps_per_epoch = len(X_train_norm) \/\/ BATCH_SIZE, \n    epochs = 30,\n    verbose = True\n    )","e77ee9ef":"def plot_model_performace(history):\n  plt.subplot(1,2,2)\n  plt.plot(history.history['loss'])\n  plt.plot(history.history['val_loss'])\n  plt.title('Model Loss')\n  plt.ylabel('Loss')\n  plt.xlabel('Epoch number')\n  plt.legend(['Train Loss', 'Validation Loss'], loc='upper right')\n  plt.show()\n\nplt.figure(figsize=(15,5))\nplot_model_performace(history)","cfb61977":"predictions = model.predict(X_test_norm, verbose=True)","42eaef26":"def get_image_statistics(channel_1, channel_2, channel_3):\n  r, g, b = channel_1, channel_2, channel_3 \n  x_r, x_g, x_b = range(0, r.shape[0]), range(0, g.shape[0]), range(0, b.shape[0])\n  y_r, x_g, y_b = range(0, r.shape[1]), range(0, g.shape[1]), range(0, b.shape[1])\n    \n  (X_R, Y_R), (X_G, Y_G), (X_B, Y_B) = np.meshgrid(x_r, y_r), np.meshgrid(x_g, x_g), np.meshgrid(x_b, y_b)\n  \n  r_x_coord = (X_R*r).sum() \/ r.sum().astype(\"float\")\n  r_y_coord = (Y_R*r).sum() \/ r.sum().astype(\"float\")\n  \n  g_x_coord = (X_G*g).sum() \/ g.sum().astype(\"float\")\n  g_y_coord = (Y_G*g).sum() \/ g.sum().astype(\"float\")\n\n  b_x_coord = (X_B*b).sum() \/ b.sum().astype(\"float\")\n  b_y_coord = (Y_B*b).sum() \/ b.sum().astype(\"float\")\n\n  r_center = (round(r_x_coord, 0).astype(\"int\"), round(r_y_coord).astype(\"int\"))\n  g_center = (round(g_x_coord, 0).astype(\"int\"), round(g_y_coord).astype(\"int\"))\n  b_center = (round(b_x_coord, 0).astype(\"int\"), round(b_y_coord).astype(\"int\"))\n  return r_center, g_center, b_center\n\nselected_images_indexes = np.random.choice(len(X_test_norm), 5)\n\nfor _, image_index in enumerate(selected_images_indexes):\n  prediction = predictions[image_index]\n  prediction = cv2.cvtColor(prediction, cv2.COLOR_BGR2RGB)\n\n  red, green, blue = cv2.split(prediction)\n  r_center, g_center, b_center =  get_image_statistics(channel_1 = red, channel_2 = green,channel_3 = blue)\n\n\n  cv2.circle(X_test_norm[image_index], center=r_center, radius=1, color=(0, 0, 255), thickness=2)\n  cv2.circle(X_test_norm[image_index], center=g_center, radius=1, color=(0, 255, 0), thickness=2)\n  cv2.circle(X_test_norm[image_index], center=b_center, radius=1, color=(255, 0, 0), thickness=2)\n\n  Image = prediction \/ np.amax(prediction)\n  Image = np.clip(Image, 0, 1)\n\n  plt.title(\"Image\")\n  plt.imshow(X_test_norm[image_index]);\n  plt.show()\n\n  plt.title(\"Prediction Mask\")\n  plt.imshow(Image);\n  plt.show()\n  \n  plt.title(\"Target Mask\")\n  plt.imshow(test_label[image_index])\n  plt.show()","f5f3d34e":"### Establsih Model\n\n#### Another way of defining model:\n```\ninputs = keras.layers.Input((64, 64, 3))\nblock1_conv1 = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\nblock1_conv2 = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(block1_conv1)\nblock1_pool = keras.layers.MaxPool2D(pool_size=(2, 2), padding='same')(block1_conv2)\nblock2_conv1 = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(block1_pool)\nblock2_conv2 = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(block2_conv1)\nbottleneck_1 = keras.layers.Conv2D(160, (16, 16), activation='relu', padding='same')(block2_conv2)\nbottleneck_2 = keras.layers.Conv2D(160, (1, 1), activation='relu', padding='same')(bottleneck_1)\n\nupsample_1 = keras.layers.UpSampling2D()(bottleneck_2)\n\noutput = keras.layers.Conv2DTranspose(3, (2,2), activation='relu', padding='same', use_bias=False)(upsample_1)\n\nmodel = keras.models.Model(inputs=[ inputs ], outputs = [ output] )\nmodel.summary()\n\n    model.compile(\n        optimizer=keras.optimizers.RMSprop(), \n        loss=['mse'],\n        metrics = 'mse'\n    )\n```","9adce8c3":"### Dataset Preparation","2024dd74":"### Split dataset on train & validation & test with ratio 60:20:20","17a3e0cf":"## Intorduction\n\nWithin this notebook we will build and train a cat eyes and nose keypoint detector model using tf.keras. We will use an autoencoder like architecture, which first encodes the data, then decodes it to its original size. To implement such kind of models, you should take a look at the following classes and methods: Funcitonal API, MaxPooling2D, Conv2DTranspose.\n\n#### Agenda\n1. Obtain Dataset.\n2. Plot original images.\n3. Preprocess the data.\n    - we will work just with 3 landmarks ({left & right} eyes, mouth). Each landmark formed as pair of (x, y) coordinate and stored within image_name.jpg.cat file.\n    - You can find some help here: https:\/\/github.com\/kairess\/cat_hipsterizer\/blob\/master\/preprocess.py\n    - Read and resize the images to be 128x128.\n    - Keep only the left eye, right eye and mouth coordinates.\n    - Create a keypoint heatmap from the keypoints. A 128x128x3 channel image, where the first channel corresponds to left eye heatmap, the sencond channel corresponds to the right eye heatmap and the third channel corresponds to the mouth heatmap. To do this:\n      1. At each keypoint, draw a circle with its corresponding color. For this, use the following method: `cv2.circle(<heatmap>, center=<keypoint_coord>, radius=2, color=<keypoint_color>, thickness=2)`\n      2. Then smooth the heatmap with a 5x5 Gauss filter: `<heatmap> = cv2.GaussianBlur(<heatmap>, (5,5), 0)` \n    - Then crop each image and heatmap:\n      1. Define the bounding box, select the min and max keypoint coordinates: `x1, y1, x2, y2`.\n      2. Add a 20x20 border around it: `x1, y1, x2, y2 = x1-20, y1-20, x2+20, y2+20`.\n      3. Then crop the image and the heatmap using the extended bounding box.  \n   - Finally, resize the images and the heatmaps to be 64x64.\n* Split the datasets into train-val-test sets (ratio: 60-20-20), without shuffling.\n* Print the size of each set and plot 5 training images and their corresponding masks.\n* Normalize the datasets. All value should be between 0.0 and 1.0. *Note: you don't have to use standardization, you can just divide them by 255.*","2f5f4935":"### Establish ImageDataGenerator"}}