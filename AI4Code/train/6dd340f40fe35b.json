{"cell_type":{"fa025eb5":"code","6d38e253":"code","6a27e895":"code","1e19fd83":"code","68feb568":"code","2f17ec0f":"code","69dcaafe":"code","cb374d7b":"code","dfa74fd7":"code","c9da8795":"code","7485cdda":"code","8c4215e5":"code","61e017cc":"code","f2c3d7f9":"code","a620a8ae":"code","53b0bf0c":"code","c604bd3f":"code","c150ca42":"code","cd33648c":"code","6b7ec7f3":"code","625dce57":"markdown","24cadad0":"markdown","6e8a9734":"markdown","b20bb5bc":"markdown","562eecb5":"markdown","a3d2b9d1":"markdown","32d7e668":"markdown","a3d94d0e":"markdown","a42687a7":"markdown","93e68827":"markdown","bdfe2e42":"markdown","a2c5d616":"markdown","cd1716d0":"markdown"},"source":{"fa025eb5":"# Import Libraries\nimport pandas as pd \nimport numpy as np\n\n# Load datasets\ntr_df = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\nte_df = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\nprint('Training dataset has {} rows and {} columns.'.format(tr_df.shape[0], tr_df.shape[1]))\n#tr_df.head()\n#te_df.head()","6d38e253":"# Pixel values between 1-255\n# x_tr.iloc[0].unique()\ny_tr = tr_df.label.values\nprint('The unique labels:')\nnp.unique(y_tr)","6a27e895":"x_tr = tr_df.drop('label', axis=1).astype('float32')\n\n# Trun features into numpy.array\nx_tr = x_tr.to_numpy()\nx_te = te_df.to_numpy()\n# Convert train datset to (num_images, img_rows, img_cols, channel) format\n# Expand 1 more dimention as 1 for colour channel gray\nx_tr = x_tr.reshape(x_tr.shape[0], 28, 28, 1)\nx_te = x_te.reshape(x_te.shape[0], 28, 28, 1)","1e19fd83":"IMG_SIZE = [28,28]\nBATCH_SIZE = 128\nSEED = 7\nEPOCHS=300","68feb568":"from keras.utils.np_utils import to_categorical\n\ny_tr = to_categorical(y_tr, dtype='int32')\nnum_classes = y_tr.shape[1]\ny_tr[0]","2f17ec0f":"from sklearn.model_selection import train_test_split\n#from sklearn.metrics import classification_report, confusion_matrix\n\nx_train, x_valid, y_train, y_valid = train_test_split(x_tr, y_tr, test_size=0.15, random_state=SEED)\n# print(x_train.shape)\n# print(y_train.shape)","69dcaafe":"import matplotlib.pyplot as plt\nfor i in range(6, 9):\n    plt.subplot(330 + (i+1))\n    plt.imshow(x_tr[i], )\n    plt.title(y_tr[i])\nplt.show()","cb374d7b":"import tensorflow as tf\n\nkernel = tf.constant([\n    [1,0],\n    [0,1]\n])\n\nimage = x_train[0]\n\n# Reformat for batch compatibility\nkernel = tf.reshape(kernel, [*kernel.shape, 1, 1])\nkernel = tf.cast(kernel, dtype=tf.float32)\n\nimage = tf.expand_dims(x_train[0], axis=0)\nimage = tf.cast(image, dtype=tf.float32)\n\nimage_filter = tf.nn.conv2d(  #common operations performed by neuralnetwork \n    input = image,\n    filters=kernel,\n    strides=1,\n    padding='SAME'\n)\n\nplt.imshow(tf.squeeze(image_filter))\nplt.axis('off')\nplt.show()","dfa74fd7":"img_detect = tf.nn.relu(image_filter)\nplt.imshow(tf.squeeze(img_detect))\nplt.axis('off')\nplt.show()","c9da8795":"img_condense = tf.nn.pool(\n    input=img_detect, \n    window_shape=(2,2),\n    pooling_type='AVG',\n    strides=(2,2),\n    padding='SAME'\n)\n\nplt.imshow(tf.squeeze(img_condense))\nplt.axis('off')\nplt.show()","7485cdda":"img_condense = tf.nn.pool(\n    input=img_detect, \n    window_shape=(2,2),\n    pooling_type='MAX',\n    strides=(2,2),\n    padding='VALID'\n)\n\nplt.imshow(tf.squeeze(img_condense))\nplt.axis('off')\nplt.show()","8c4215e5":"img_condense = tf.nn.pool(\n    input=img_detect, \n    window_shape=(2,2),\n    pooling_type='AVG',\n    strides=(2,2),\n    padding='VALID'\n)\n\nplt.imshow(tf.squeeze(img_condense))\nplt.axis('off')\nplt.show()","61e017cc":"#import tensorflow as tf\ntf.keras.backend.clear_session()","f2c3d7f9":"from tensorflow.keras import Sequential, layers\n\nmodel = Sequential([\n    layers.Conv2D(filters=36, kernel_size=(2,2), activation='relu', input_shape=(28, 28, 1),),\n    layers.MaxPool2D(pool_size=2), # Condense step\n    layers.Conv2D(filters=18, kernel_size=(2,2), activation='relu', padding='VALID',),\n    layers.BatchNormalization(),\n    layers.Dense(units=200, activation='relu'),\n    layers.Flatten(),\n    layers.Dense(units=100, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dense(units=50, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dense(units=num_classes, activation='softmax', name='output')\n])\n\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['acc'],\n)","a620a8ae":"model.summary()","53b0bf0c":"from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n\n# checkpoint\nfilepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n\n\nearly_stopping = EarlyStopping(\n    min_delta=0.001, # minimium amount of change to count as an improvement\n    patience=15, # how many epochs to wait before stopping\n    restore_best_weights=True,\n)\n\nhistory = model.fit(\n    x_train, y_train,\n    #steps_per_epoch=tr_generator.n\/\/BATCH_SIZE,\n    #validation_split=0.1,\n    verbose=1,\n    batch_size=BATCH_SIZE,\n    validation_data=(x_valid, y_valid),#valid_generator,\n    #validation_steps=valid_generator.n,\n    epochs=EPOCHS,  \n    callbacks=[early_stopping, checkpoint, TensorBoard(log_dir='.\/log')]\n)","c604bd3f":"history_df = pd.DataFrame(history.history)\nhistory_df[['loss','acc']].plot()\nhistory_df[['val_loss','val_acc']].plot()\nplt.show()","c150ca42":"predict = model.predict(x_te)\n# predict the class label\ny_classes = predict.argmax(axis=-1)","cd33648c":"submissions=pd.DataFrame({\"ImageId\": list(range(1,len(y_classes)+1)),\n                          \"Label\": y_classes})\nsubmissions.set_index('ImageId', inplace=True)\nsubmissions.head()","6b7ec7f3":"submissions.to_csv(\"third_attempt_model_1.csv\", index=True, header=True)","625dce57":"### Apply Pooling\n","24cadad0":"# Convolutional Neural Networks","6e8a9734":"## Split Training Data","b20bb5bc":"# Preprocessing","562eecb5":"Tensorflow only takes input with dtypes including `float16`, `bfloat16`, `float32`, `float64`, and `int32`.","a3d2b9d1":"### Apply Convolution and ReLU","32d7e668":"## One Hot Encoding for Labels\n\nSince the unique digits are 10 different numbers, my model should fit in multi-ouput model section.","a3d94d0e":"# Setup \n- Import libraries\n- Load dataset\n","a42687a7":"## Configuration","93e68827":"## Submission","bdfe2e42":"## Data Visualisation\n\nEach image is a 28*28 pixel.\n","a2c5d616":"## Architecture\n### Output Activation Function\n\n$$\\sigma(\\vec{z})_i=\\frac{e^{Z_i}}{\\Sigma_{j=1}^K e^{Z_j}}$$\n\nwhere all the $z_i$ values are the elements of the input vector and can take any real values. The term on the bottom of the formula is the normalization term which ensures that all the output values of the function will sum to 1, thus constituting a valid probability distribution\n\nThe **softmax function** is also called the **softargmax function**, or **multi-class logistic regression**.\n\nThe `softmax` function is a function that turns a vector of $K$ real values into a vector of $K$ real values that sum to 1.\n\nThe input values can be positive, negative, zero or greater than one, but the softmax transforms them into values between 0 and 1, so they can be interpreted as probabilities.","cd1716d0":"## Prediction"}}