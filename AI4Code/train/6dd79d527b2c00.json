{"cell_type":{"107e4636":"code","ad4a5236":"code","65296654":"code","57092d6b":"code","969feb86":"code","0c7053e9":"code","afb3a0d9":"code","6551dbef":"code","dcecb7e7":"code","d3f63ffd":"code","7930ff5e":"code","71fb1e8f":"code","dca1d3cd":"code","5e2ebcf2":"markdown","e1481c29":"markdown","617ac46c":"markdown","f10152c8":"markdown","21e64b50":"markdown","8275c01e":"markdown","c27743da":"markdown","6afe5db1":"markdown","e4aa0b87":"markdown","d44d8097":"markdown","1aa6f5a4":"markdown","56ace16f":"markdown","6da5cd87":"markdown","43cabd5e":"markdown","8bae3be6":"markdown","1e056035":"markdown","e9bf7d08":"markdown","88ac3847":"markdown"},"source":{"107e4636":"### Standard imports\nimport pandas as pd\nimport numpy as np\npd.options.display.max_columns = 50\n\n### Time imports\nimport datetime\nimport time\n\n# Counter\nfrom collections import Counter\n\n# Operator\nimport operator\n\n# Regular Expressions\nimport re\n\n# Directory helper\nimport glob\n\n# Language processing import\nimport nltk\n\n# Random\nimport random\n\n# Progress bar\nfrom tqdm import tqdm\n\n### Removes warnings that occassionally show in imports\nimport warnings\nwarnings.filterwarnings('ignore')","ad4a5236":"### Standard imports\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set()\n\n### Altair\nimport altair as alt\nalt.renderers.enable('notebook')\n\n### Plotly\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\nimport plotly.plotly as py\nfrom plotly import tools\ninit_notebook_mode(connected=True)\n\n# WordCloud\nfrom wordcloud import WordCloud\n\n# Folium\nimport folium","65296654":"# A short hand way to plot most bar graphs\ndef pretty_bar(data, ax, xlabel=None, ylabel=None, title=None, int_text=False, x=None, y=None):\n    \n    if x is None:\n        x = data.values\n    if y is None:\n        y = data.index\n    \n    # Plots the data\n    fig = sns.barplot(x, y, ax=ax)\n    \n    # Places text for each value in data\n    for i, v in enumerate(x):\n        \n        # Decides whether the text should be rounded or left as floats\n        if int_text:\n            ax.text(0, i, int(v), color='k', fontsize=14)\n        else:\n            ax.text(0, i, round(v, 3), color='k', fontsize=14)\n     \n    ### Labels plot\n    ylabel != None and fig.set(ylabel=ylabel)\n    xlabel != None and fig.set(xlabel=xlabel)\n    title != None and fig.set(title=title)\n\ndef pretty_transcript(transcript, limit_output=0):\n    for i, speaker in enumerate(transcript):\n        if limit_output and i > limit_output:\n            print(\"  (...)\")\n            break\n        print(color.UNDERLINE, speaker[0] + \":\", color.END)\n        for txt in speaker[1:]:\n            print(\"\\n\\n   \".join(txt))\n        print()\n    \ndef get_trend(series, ROLLING_WINDOW=16):\n    trend = series.rolling(\n        window=ROLLING_WINDOW,\n        center=True, min_periods=1).mean()\n\n    trend = trend.rolling(\n        window=ROLLING_WINDOW \/\/ 2,\n        center=True, min_periods=1).mean()\n\n    trend = trend.rolling(\n        window=ROLLING_WINDOW \/\/ 4,\n        center=True, min_periods=1).mean()\n    return trend\n    \n### Used to style Python print statements\nclass color:\n    BOLD = '\\033[1m'\n    UNDERLINE = '\\033[4m'\n    END = '\\033[0m'","57092d6b":"pbs = pd.read_json(\"..\/input\/PBS-newhour-clean.json\")\npbs = pbs.sort_values(\"Date\")\n\npbs.Story.fillna(\"\", inplace=True)\n\npbs[\"Year\"]  = pbs.Date.map(lambda x: x.year)\npbs[\"Month\"] = pbs.Date.map(lambda x: x.month)\n\nprint(\"Shape of pbs:\", pbs.shape)\npbs.head()","969feb86":"pbs.Timezone.value_counts()","0c7053e9":"temp = pbs.iloc[0]\n\nprint(temp.Title)\nprint(temp.URL)","afb3a0d9":"temp = pbs[pbs.Transcript.map(lambda x: x != [])].iloc[0]\n\nprint(f\"{color.BOLD}{temp.Date}{color.END}\")\nprint(f\"{color.BOLD}{temp.Title}{color.END}\")\nprint()\npretty_transcript(temp.Transcript, limit_output=2)","6551dbef":"for i in range(5):\n    print(pbs.iloc[i].Date)\n    print(pbs.iloc[i].Story)\n    print()","dcecb7e7":"temp = (pbs\n        .assign(n=0)\n        .set_index(\"Date\")\n        .groupby(pd.Grouper(freq=\"M\"))\n        .n\n        .apply(len)\n        .sort_index()\n)\n\ntrace = go.Scatter(\n        x=temp.index,\n        y=temp.values,\n    )\n\nlayout = go.Layout(\n    title = \"Number of transcripts available over time\",\n    yaxis=dict(title=\"Number of transcripts\"),\n    xaxis=dict(title=\"Date\"),\n)\n\n\n\nfig = go.Figure(data=[trace], layout=layout)\niplot(fig)","d3f63ffd":"### These are just examples\npois = {0: \"BERNIE SANDERS\",\n        1: \"VLADIMIR PUTIN\",\n        2: \"DONALD TRUMP\",\n        3: \"JUDY WOODRUFF\",\n        4: \"BEN CARSON\",\n        5: \"STEPHEN COLBERT\",\n        6: \"HILLARY CLINTON\",\n        7: \"JOHN F. KENNEDY\",\n        8: \"ANGELA MERKEL\",\n        9: \"JEFF BEZOS\",\n        10: \"XI JINPING\"\n}\n\npoi = pois[2]\n\nprint(\"Showing results for:\", poi)\npbs[pbs.Speakers.map(lambda x: poi in x)].head(3)","7930ff5e":"pois = [\"BERNIE SANDERS\", \"DONALD TRUMP\", \"HILLARY CLINTON\",\n        \"BARACK OBAMA\", \"MITT ROMNEY\", \"ANGELA MERKEL\",\n        \"JOSEPH BIDEN\", \"MIKE PENCE\"]\n\ndef get_num_articles(df, poi):\n    num_articles = len(df[df.Speakers.map(lambda x: poi in x)])\n    return num_articles\n\ndef get_num_words(df, poi):\n    speaker_text = list()\n    transcripts  = df[df.Speakers.map(lambda x: poi in x)].Transcript.values\n    num_words    = 0\n    \n    for transcript in transcripts:\n        for person in transcript:\n            if person[0] == poi:\n                for txt in person[1]:\n                    num_words += len(txt.split(\" \"))\n    return num_words\n\narticles, words = list(), list()\n\nfor poi in pois:\n    num_articles = get_num_articles(pbs, poi)\n    num_words    = get_num_words(pbs, poi)\n    \n    articles.append(num_articles)\n    words.append(num_words)\n\ntrace1 = go.Bar(\n    x=pois,\n    y=articles,\n    name='Total articles'\n)\ntrace2 = go.Bar(\n    x=pois,\n    y=words,\n    name='Total words'\n)\n\ndata = [trace1, trace2]\nlayout = go.Layout(\n    barmode='group'\n)\n\nfig = go.Figure(data=data, layout=layout)\niplot(fig);","71fb1e8f":"persons = pbs.Speakers.map(list).sum()\n\nfreq = sorted(Counter(persons).items(), key=operator.itemgetter(1), reverse=True)\nx, y = list(zip(*freq[:25]))\n\nfig, ax = plt.subplots(1, 1, figsize=(14, 14))\ntemp = pd.Series(list(y), index=list(x))\npretty_bar(temp, ax, title=\"Top Speakers\", xlabel=\"Number of Transcripts\");","dca1d3cd":"LIMIT_TIME = True\ntopics     = [\"Obama\", \"Trump\", \"Clinton\", \"Bush\", \"Immigration\", \"Congress\", \"Racism\"]\n\ndef topic_popularity(topic):\n    def popularity_helper(transcript):\n        transcript = list(map(lambda x: x[1][0], transcript))\n        transcript = (\" \".join(transcript).lower()).split(\" \")\n        N          = len(transcript)\n        counts     = Counter(transcript)\n        return (counts[topic.lower()] \/ N) * 100\n    return popularity_helper\n\nif LIMIT_TIME:\n    temp = pbs[pbs.Year > 2010]\nelse:\n    temp = pbs\n\ndatas = []\nfor topic in tqdm(topics):\n    temp[\"Temp\"] = (\n                temp[temp.Transcript.map(lambda x: x != [])]\n                    .Transcript\n                    .map(topic_popularity(topic))\n                )\n\n    data = (temp\n         .set_index(\"Date\")\n         .groupby(pd.Grouper(freq=\"M\"))\n         .Temp\n         .apply(np.mean)\n    )\n\n    trend = get_trend(data, ROLLING_WINDOW=12)\n\n    datas.append((topic, data, trend))\n\ntraces = []\n\nfor topic, data, _ in datas:\n    traces.append(go.Scatter(\n                            x=data.index,\n                            y=data.values,\n                            name=f\"{topic} - actual\"\n                        ))\n    \nfor topic, _, trend in datas:\n    traces.append(go.Scatter(\n                            x=trend.index,\n                            y=trend.values, \n                            name=f\"{topic} - trend\"\n                        ))\nbuttons = []\n\nfor i, topic in enumerate(topics):\n    visibility = [i==j for j in range(len(topics))]\n    button = dict(\n                 label =  topic,\n                 method = 'update',\n                 args = [{'visible': visibility},\n                     {'title': f\"'{topic}' usage over time\" }])\n    buttons.append(button)\n\nupdatemenus = list([\n    dict(active=-1,\n         x=-0.15,\n         buttons=buttons\n    )\n])\n\nlayout = dict(title='Topic popularity', \n              updatemenus=updatemenus,\n                xaxis=dict(title='Date'),\n                yaxis=dict(title='Percent of words')\n             )\n\nfig = dict(data=traces, layout=layout)\nfig['layout'].update(height=800, width=800)\n\niplot(fig)","5e2ebcf2":"<a id=\"oldest_transcript\"><\/a>\n\n### [^](#toc) Oldest Transcript\n\nThe oldest complete transcript on PBS's website is an interview with Fidel Castro in February of 1985.","e1481c29":"<a id=\"timezone\"><\/a>\n\n### [^](#toc) Timezone\n\nWe can see the timezone is always EDT.  The program is hosted in Arlington, Virginia and New York City so this makes sense.","617ac46c":"<a id=\"date_spread\"><\/a>\n\n### [^](#toc) Date spread\n\nThe activity starts around March 2011, so we have 7 years of history to analyze","f10152c8":"---\n<a id=\"setup\"><\/a>\n\n# [^](#toc) <u>Setup<\/u>\n\nBelow I import some libraries and create helper functions","21e64b50":"---\n<a id=\"trends\"><\/a>\n\n# [^](#toc) Trends","8275c01e":"<a id=\"topic_popularity\"><\/a>\n\n### [^](#toc) Topic Popularity\n\nThis shows the popularity of a word for a given month.  I measure the fraction of time a word is used for a particular story, then take the average value for a given month.\n\nTo look at the topic of a topic, multiple moving averages are performed to smooth out fluctuations.\n\nThere seems to be an increasing trend talking about immigration and racism.  Interestingly, PBS has no mention of racism until 2013.","c27743da":"<a id=\"imports\"><\/a>\n\n### [^](#toc) Standard imports","6afe5db1":"<a id=\"helpers\"><\/a>\n\n### [^](#toc) Helpers","e4aa0b87":"<a id=\"earliest_interview\"><\/a>\n\n### [^](#toc) Earliest interview by person\n\nIt's only 7 years, but I think it's amazing just looking back 7 years.  So much has changed.  In another sense, not much has changed.\n\nThe earliest mention of Donald Trump is in 2011 when he was demanding Obama for his birth certificate.  During that segment he is considering running for office. ([link](https:\/\/www.pbs.org\/newshour\/show\/with-birth-certificate-release-obama-urges-shift-in-national-dialogue)).  This is tangetial, but this [clip](https:\/\/www.pbs.org\/newshour\/show\/with-birth-certificate-release-obama-urges-shift-in-national-dialogue) also features PBS' Jim Lehrer 40 years earlier.\n\nThe earliest mention of Bernie Sanders is him weighing in on the 2011 Debt Ceiling negotitions ([link](https:\/\/www.pbs.org\/newshour\/show\/debt-deal-stalemate-spills-into-weekend-for-obama-congress)).  He warns that the burden will fall on the working class.","d44d8097":"<a id=\"general\"><\/a>\n\n# [^](#toc) <u>General Overview<\/u>","1aa6f5a4":"---\n<a id=\"background\"><\/a>\n\n# [^](#toc) <u>Background<\/u>\n\nPBS Newshour is an American daily news program founded in 1975.  The program spans 1hr on the weekdays and 30min on the weekends and it covers domestic and international news.\n\nThis notebook is a very basic introduction to PBS Newshour's dataset.  There is more to be done and I hope to do it soon!","56ace16f":"<a id=\"vis_imports\"><\/a>\n\n### [^](#toc) Visualization imports","6da5cd87":"<a id=\"load\"><\/a>\n\n### [^](#toc) Load data\n\nI'm working with PBS Newshour's clean dataset.  I cleaned it myself and the cleaning is up to my standards :)","43cabd5e":"<a id=\"speaker_total_words\"><\/a>\n\n### [^](#toc) Total words spoken\n\nBefore doing any analysis, it's important to check that we have enough data to form meaningful conclusions. We can see from figure 2 the number of words spoken by each famous person. Besides Angela Merkel, it looks like we have plenty of data to work with!","8bae3be6":"<a id=\"toc\"><\/a>\n\n# <u>Table of Contents<\/u>\n\n### Part I: Data Overview  \n1.) [Background](#background)  \n2.) [Setup](#setup)  \n&nbsp;&nbsp;&nbsp;&nbsp; 2.1.) [Standard Imports](#imports)   \n&nbsp;&nbsp;&nbsp;&nbsp; 2.2.) [Visualization Imports](#imports)   \n&nbsp;&nbsp;&nbsp;&nbsp; 2.3.) [Helpers](#helpers)   \n&nbsp;&nbsp;&nbsp;&nbsp; 2.4.) [Load data](#load)   \n3.) [General Overview](#general)  \n&nbsp;&nbsp;&nbsp;&nbsp; 3.1.) [Timezone](#timezone)   \n&nbsp;&nbsp;&nbsp;&nbsp; 3.2.) [Oldest Transcript](#oldest)   \n&nbsp;&nbsp;&nbsp;&nbsp; 3.3.) [5 Oldest Stories](#old_5)   \n&nbsp;&nbsp;&nbsp;&nbsp; 3.4.) [Date spread](#date_spread)   \n&nbsp;&nbsp;&nbsp;&nbsp; 3.5.) [Earliest interview by person](#earliest_interview)   \n&nbsp;&nbsp;&nbsp;&nbsp; 3.6.) [Total words spoken](#speaker_total_words)   \n4.) [Trends](#trends)  \n&nbsp;&nbsp;&nbsp;&nbsp; 4.1.) [Topic Popularity](#topic_popularity)  ","1e056035":"### [^](#toc) Most Popular Speakers\n\nThe plot below counts the number of times a speaker has appeared in an article and plots the top counts.\n\nThe top speakers are mostly employees of PBS Newshour, so it makes sense they'd top the list.  However besides them and the filler names like \"Man\" and \"Woman\", we have Barack Obama, Donald Trump, Hillary Clinton, Mitch McConnell, Mitt Romney, John Boehner, and John Kerry.  All of which are very important politicians","e9bf7d08":"<a id=\"old_5\"><\/a>\n\n### [^](#toc) 5 Oldest Stories\n\nIt looks like PBS Newshour's archive have a lot of gaps early in it's development","88ac3847":"<a id=\"oldest_clip\"><\/a>\n\n### [^](#toc) Oldest Clip\n\nThe oddest news clip is Robert MacNeil's and Jim Lehrer's coverage of Nixon's Watergate scandal.  This story aired back in 1973 and won MacNeil and Lehrer both an Emmy.\n\nThe coverage was so highly praised that it led to the creation of The MacNeil\/Lehrer Report, the predecessor of PBS Newshour."}}