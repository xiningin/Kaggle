{"cell_type":{"7e9b8459":"code","67685030":"code","e892dffa":"code","b2be7549":"code","22e66beb":"code","0158d356":"code","5072274e":"code","a84800e7":"code","7afb9468":"code","3fc31c2f":"code","d20ae7d3":"code","22d89d7d":"code","c184b073":"code","90ba37da":"code","8e33cdc7":"code","79cfa7ed":"code","162b07b8":"code","ff7d75ed":"code","2602ccd1":"code","c6bcfb84":"code","c597db9b":"code","47c643b9":"code","3da41fc8":"code","672955ba":"code","bdbbaf87":"code","a4c26d23":"code","6f276a80":"code","7298dc36":"markdown","cdde8746":"markdown","c6b6b6f7":"markdown","ecc9a407":"markdown","15fa6446":"markdown","97a50936":"markdown","c81b44e0":"markdown","3a614dcd":"markdown","a2f93232":"markdown","eb9366c5":"markdown","19ec3488":"markdown","ac5e55e7":"markdown","e9a578f0":"markdown","b093b158":"markdown","ece38428":"markdown","da48c98e":"markdown","567cce18":"markdown","8963ab2b":"markdown","5f8c03ed":"markdown"},"source":{"7e9b8459":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","67685030":"# Read in the file into a pandas DataFrame\ntrain = pd.read_csv('..\/input\/solar-generation-forecasting-challenge\/train_v3.csv')\n\n# Sneak peek at the actual DataFrame itself\ntrain.head()","e892dffa":"train.info()","b2be7549":"train.describe()","22e66beb":"# Convert the Date Time column to a DateTime64 data type\ntrain['Date.Time'] = pd.to_datetime(train['Date.Time'])\n\n# Then let's create some new features such as hour \/ month \/ year\ntrain['Hour'] = pd.DatetimeIndex(train['Date.Time']).hour\ntrain['Month'] = pd.DatetimeIndex(train['Date.Time']).month\ntrain['Year'] = pd.DatetimeIndex(train['Date.Time']).year","0158d356":"# import some visualisation libraries\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# for DateTime conversion into plots\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters() ","5072274e":"# Let's only take a single PV.Id to visualise and only in the year 2010\nsns.lineplot(x=\"Date.Time\", y=\"Value\", data=train[(train['PV.Id'] == 1) & (train['Year'] == 2010)]).set_title(\"Solar Generated for PV.Id = 1 in Year 2010\")","a84800e7":"# Let's summarise and take the mean Value across all PV.Ids for a specific hour\nmean_value_per_hour = train.groupby(['Hour'])['Value'].mean()\nmean_value_per_hour = mean_value_per_hour.reset_index()\n# Let's visualise this\nsns.lineplot(x=\"Hour\", y=\"Value\", data=mean_value_per_hour).set_title(\"Average Solar Generated across all PV panels on an hourly basis\")","7afb9468":"# Let's summarise and take the mean Value across all PV.Ids by month\nmean_value_month = train.groupby(['Month'])['Value'].mean()\nmean_value_month = mean_value_month.reset_index()\n# Let's visualise this\nsns.lineplot(x=\"Month\", y=\"Value\", data=mean_value_month).set_title(\"Average Solar Generated by Month\")","3fc31c2f":"# Read in the CSV that contains the PV attributes\nsolar_pv_attribute = pd.read_csv(\"..\/input\/solar-generation-forecasting-challenge\/solar_pv_attributes.csv\")","d20ae7d3":"solar_pv_attribute","22d89d7d":"# Now let's join them together with our training dataset\ntrain_df = pd.merge(train, solar_pv_attribute, on = 'PV.Id', how = 'left')\ntrain_df.head()","c184b073":"def process_data(file_name, solar_pv_attr_file_name = None):\n    # read in the file\n    file_path = os.path.join('..\/input\/solar-generation-forecasting-challenge', file_name)\n    data = pd.read_csv(file_path)\n    \n    # Convert the Date Time column to a DateTime64 data type\n    data['Date.Time'] = pd.to_datetime(data['Date.Time'])\n\n    # Then let's create some new features such as hour \/ month \/ year\n    data['Hour'] = pd.DatetimeIndex(data['Date.Time']).hour\n    data['Month'] = pd.DatetimeIndex(data['Date.Time']).month\n    data['Year'] = pd.DatetimeIndex(data['Date.Time']).year\n    \n    # Merge it with the solar PV attribute (if present)\n    if solar_pv_attr_file_name is not None:\n        solar_pv_file_path = os.path.join('..\/input\/solar-generation-forecasting-challenge', solar_pv_attr_file_name)\n        solar_pv_attribute = pd.read_csv(solar_pv_file_path)\n        data = pd.merge(data, solar_pv_attribute, on = 'PV.Id', how = 'left')\n    \n    return data\n\ntrain_df = process_data('train_v3.csv', solar_pv_attr_file_name = 'solar_pv_attributes.csv')\ntest_df = process_data('test_v3.csv', solar_pv_attr_file_name = 'solar_pv_attributes.csv')","90ba37da":"# Check to make sure all is good\ntrain_df.head()","8e33cdc7":"# Note that the test data frame does NOT have the Value column (this is what we are trying to predict)\ntest_df.head()","79cfa7ed":"from sklearn.linear_model import LinearRegression\n\n# Let's split the training data into train \/ validation based on description above\nX_train = train_df[(train_df['Year'] < 2012) | ((train_df['Year'] == 2012) & (train_df['Month'] <= 6))].drop(['Value', 'Date.Time', 'Postcode'], axis = 1)\ny_train = train_df[(train_df['Year'] < 2012) | ((train_df['Year'] == 2012) & (train_df['Month'] <= 6))]['Value']\nX_valid = train_df[(train_df['Year'] == 2012) & (train_df['Month'] > 6)].drop(['Value', 'Date.Time', 'Postcode'], axis = 1)\ny_valid = train_df[(train_df['Year'] == 2012) & (train_df['Month'] > 6)]['Value']","162b07b8":"X_train","ff7d75ed":"y_train","2602ccd1":"lm_model = LinearRegression().fit(X = X_train, y = y_train)","c6bcfb84":"# Let's get a summary on how the model fitted\nfrom statsmodels.api import OLS\n\nOLS(y_train,X_train).fit().summary()","c597db9b":"# Reduce to piecewise linear features\ndef calculate_piecewise_features(data):\n    data['Month_Piecewise_1_6'] = data['Month'].apply(lambda x: x if x >= 1 and x <= 6 else 0)\n    data['Month_Piecewise_7_12'] = data['Month'].apply(lambda x: x if x > 7 else 0)\n    data['Hour_Piecewise_1_12'] = data['Hour'].apply(lambda x: x if x < 13 else 0)\n    data['Hour_Piecewise_13_24'] = data['Hour'].apply(lambda x: x if x >= 13 else 0)\n    return data\n\nX_train = calculate_piecewise_features(X_train)\nX_valid = calculate_piecewise_features(X_valid)\nX_test  = calculate_piecewise_features(test_df)","47c643b9":"# Try again and observe the R^2\nfrom statsmodels.api import OLS\n\nOLS(y_train,X_train.drop(['Hour','Month', 'PV.Id'], axis = 1)).fit().summary()","3da41fc8":"from sklearn.metrics import mean_squared_error\nimport math\n\ndef calculate_rmse(y_true, y_pred):\n    return math.sqrt(mean_squared_error(y_true, y_pred))\n\ncols_excluded = ['PV.Id', 'Hour', 'Month']\ntest_cols_excluded = ['Id', 'PV.Id', 'Hour', 'Month', 'Date.Time', 'Postcode']\n\n# need to re-build our linear model to incorporate the new features\nlm_model = LinearRegression().fit(X = X_train.drop(cols_excluded, axis = 1), y = y_train)\n\n# calculate for the training & validation set\ny_train_pred = lm_model.predict(X_train.drop(cols_excluded, axis = 1))\ny_valid_pred = lm_model.predict(X_valid.drop(cols_excluded, axis = 1))\n\n# calculate for the test set (if required)\ny_test_pred = lm_model.predict(X_test.drop(test_cols_excluded, axis = 1))\n\n# evaluate\nprint('[Linear] Train RMSE: {}'.format(calculate_rmse(y_train, y_train_pred)))\nprint('[Linear] Validation RMSE: {}'.format(calculate_rmse(y_valid, y_valid_pred)))","672955ba":"from sklearn.ensemble import RandomForestRegressor\n\n# build a random forest model\nrf_model = RandomForestRegressor(n_estimators = 10) # can increase the n_estimators to improve the performance, at the expense of increasing training time!\nrf_model.fit(X = X_train.drop(cols_excluded, axis = 1), y = y_train)","bdbbaf87":"# now let's evaluate to see if this is better...\n# calculate for the training & validation set\ny_train_pred = rf_model.predict(X_train.drop(cols_excluded, axis = 1))\ny_valid_pred = rf_model.predict(X_valid.drop(cols_excluded, axis = 1))\n\n# calculate for the test set (if required)\ny_test_pred = rf_model.predict(X_test.drop(test_cols_excluded, axis = 1))\n\n# evaluate\nprint('[RF] Train RMSE: {}'.format(calculate_rmse(y_train, y_train_pred)))\nprint('[RF] Validation RMSE: {}'.format(calculate_rmse(y_valid, y_valid_pred)))","a4c26d23":"def random_forest_varimp(rf_model, features):\n    importances = rf_model.feature_importances_\n    indices = np.argsort(importances)\n    \n    plt.title('Feature Importance')\n    plt.barh(range(len(indices)), importances[indices], color='g', align='center')\n    plt.yticks(range(len(indices)), [features[i] for i in indices])\n    plt.xlabel('Relative Importance')\n    plt.ylabel('Features')\n    plt.show()\n    \nrandom_forest_varimp(rf_model, X_train.drop(cols_excluded, axis = 1).columns.values)","6f276a80":"# Take the sample submission format and replace the Values with the ones we predicted\n# Take care of the ordering (by default both sample submission and the test CSV are ordered the same way, so this shouldn't be an issue unless you change the order of test predictions)\nsubmission = pd.read_csv('..\/input\/solar-generation-forecasting-challenge\/sample_submission_v3.csv')\n\nsubmission['Value'] = y_test_pred\n\nsubmission.to_csv('submission.csv', index=False)","7298dc36":"Our ultimate goal is to predict the power generation specified in the **train_v3.csv** file. We also have a bunch of supplementary files that would prove useful to derive additional features to help us build a model. But first, let's take a look at the training file:","cdde8746":"We can also take a look at the solar generation across all PV panels.","c6b6b6f7":"By logic and reasoning, we would expect that the panels would generate more in summer months as opposed to winter months. If we take a look at a monthly basis:","ecc9a407":"This doesn't seem to be a great score - with so little improvement over the baseline all zero score.\n\nLet's try another popular algorithm that deals with non-linearities better, enter Random Forest. Note that this will take longer to compute!","15fa6446":"Let's start forming a basic model. In addition to the data discovered so far, we could utilise PV attribute data (from **solar_pv_attributes.csv**) to derive a set of *features* for our model including:\n* Generator Capacity\n* Hour\n* Month","97a50936":"# Introduction\nThis notebook does a basic exploration of the dataset and how to complete a reasonable submission to the Kaggle platform.","c81b44e0":"How do we improve our model? We know that the following are true:\n\n* Non-linear relationship between Month and target variable\n* Non-linear relationship between Hour and target variable\n\nThe linear regression model won't be able to capture this. One way around this to improve the performance is to create a piecewise linear feature based on the graphs we have observed earlier. The total solar generation amount decreases until Month 6 (June) where it picks up again. Likewise, for the Hour feature - this peaks around 1pm (13:00).","3a614dcd":"For sklearn Linear Regression documentation: https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.LinearRegression.html\n\nFor a range of different models supported in sklearn: https:\/\/scikit-learn.org\/stable\/modules\/classes.html","a2f93232":"One nice thing about decision tree models is that it can easily compute feature importance.","eb9366c5":"It's probably a good time to make sure we transform the test set the same way as we have had for the training set. Usually, it's best to create a function that transforms the files so this ensures consistency and reuse. I would recommend you to modularise your code to reduce the number of bugs \/ errors you may make.","19ec3488":"Now let's take a single solar PV panel, specified by **PV.Id** 1. And let's visualise the power being generated. Feel free to do your own exploration of this **PV.Id** or other time periods.","ac5e55e7":"Unfortunately the sklearn version doesn't output as great of a summary as the **statsmodels** package. However, we can get the same fit and see the summary:","e9a578f0":"The target variable in which we are trying to predict is the **Value** column. However, they seem to be all zeroes - this will make sense given that the time of day is just past midnight. It'll definitely be weird to see some solar power generation in these wee hours of the night! Let's do some investigation into the data frame.","b093b158":"Take a peek across the training split to ensure it makes sense:","ece38428":"# Next steps\n\nWhat should you do next?\n\n* Incorporate and understand supplemental information (i.e. solar station \/ radiation observations)\n* Delve further into exploratory data to drive new feature engineering \/ insights\n* Hyperparameter Tuning on existing models, i.e. does Random Forest perform better with more estimators? Best to look at relevant documentation on tunable hyperparameters!\n* Test different types of models: Gradient Boosted Trees, Time Series, Deep Learning etc.\n* Test out ensembling techniques to combine different types of models together\n* ???\n","da48c98e":"As the competition is judged based on RMSE (Root Mean Squared Error), it is a good idea to convert your evaluation metric to the same one so it's comparable to the Public Leaderboard (LB).","567cce18":"Now we are ready to build a basic model. There are many options we can experiment here - it is hard to tell what is the best model and feature engineering required. That is the whole point of the competition! For simplicity sakes, we will do a **linear regression** model.\n\nThere are also many ways to *validate* your model. Keep in mind that due to the time series nature of the data - any validation is not split based on time can be highly optimistic. For example, it would be much better if we chose to validate our data on the last 6 months of our training set (from 1st July 2012 to 31st December 2012) and only train on any data prior to 1st July 2012. Rather than just do a random subsample from all rows up to 31st December 2012. You should ask yourself why.","8963ab2b":"It seems like there are some non-zero entries for **Value** (which is a good thing). The Date.Time column is also encoded as an *object* at the moment. We need to convert that to a *datetime64* so we can extract some useful features out of it (such as the hour or month).","5f8c03ed":"What does it mean that Generator Capacity is one of the most important features? In essence, the model *may* be using it to tell the different PV panels apart (as they have different characteristics). It *may* also be using this to determine the valid range of power generation (kWh) for each PV. As Random Forest learns using recursive partitioning of the data space, it can easily divide up using a combination of features - something that a linear regression model can't do out of the box.\n\nSince this looks promising, let's submit using this model. Steps are detailed in the code below:"}}