{"cell_type":{"88668ebf":"code","46cbd5ee":"code","08ba3414":"code","23cb8c19":"code","37c03a51":"code","adfbee31":"code","2fe94961":"code","11a79339":"code","413a17b5":"code","a4e75e09":"code","aaac225f":"code","08eb5eb0":"code","ff98daa4":"code","553e8829":"code","9fd15fee":"code","3df898c6":"code","ba8518b1":"code","c2fb2b78":"code","7cac4137":"code","efccba32":"code","554eecc4":"code","58232de8":"code","cee0a501":"code","0b105221":"code","c0666844":"code","521aa216":"code","f0134c13":"code","07ae4b94":"code","31d461a7":"code","984ca7f8":"code","93e14538":"code","db083b79":"code","54c26ed2":"code","4fc09857":"code","83fe29c4":"code","165e7d31":"code","f0c62765":"code","f3fd7e8e":"code","17962125":"markdown","06e0d04c":"markdown","3ab5a71f":"markdown","89af6377":"markdown","dbec1fdb":"markdown","fd04f035":"markdown","431ea9dd":"markdown","420ffde9":"markdown","f5270757":"markdown","f9fb920b":"markdown","b02f9a37":"markdown","f6278da2":"markdown","71cf2aa6":"markdown","ff1b88fb":"markdown","fc611293":"markdown","8386268d":"markdown","6bec6fbd":"markdown","2e21ef47":"markdown","5db78172":"markdown","59b808b5":"markdown","52c2e74c":"markdown","61cf7ceb":"markdown","263988aa":"markdown","aee8071e":"markdown","7568565b":"markdown","a881080a":"markdown","c9b6ec45":"markdown","54b4d6e2":"markdown","7ffaa219":"markdown"},"source":{"88668ebf":"import os\nimport shutil\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt \n\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.auto import tqdm\n\n#Seed for making reproducible experiments\nseed = 612","46cbd5ee":"train_data = pd.read_csv(\"..\/input\/landmark-recognition-2020\/train.csv\")\ntrain_data.sample(5, random_state=seed)","08ba3414":"print(\"Number of total labels \",  train_data[\"landmark_id\"].nunique())\nprint(\"Number of total images \", train_data.shape[0])","23cb8c19":"n = 201\ntop_200 = train_data['landmark_id'].value_counts()[1:n].index.tolist()\nimages_200 = train_data.loc[train_data[\"landmark_id\"].isin(top_200)]\nprint(\"Number of images of the top \",images_200[\"landmark_id\"].nunique(), \" landmarks: \", images_200.shape[0])","37c03a51":"n = 21\ntop_20 = train_data['landmark_id'].value_counts()[1:n].index.tolist()\nimages_20 = train_data.loc[train_data[\"landmark_id\"].isin(top_20)]\nprint(\"Number of images of the top \",images_20[\"landmark_id\"].nunique(), \" landmarks: \", images_20.shape[0])","adfbee31":"# Calculating the n_images per landmark\ndb1 = images_200.groupby([\"landmark_id\"]).size().reset_index(name='n_images')\ndb2 = images_20.groupby([\"landmark_id\"]).size().reset_index(name='n_images')\n#Plotting a scatterplot of the distribution -> share y axis to compare\nfig, axes = plt.subplots(1, 2, sharey = True, figsize = (20,5))\n\nsns.scatterplot(ax=axes[0], x='landmark_id', y='n_images', data=db1, palette=\"mako\")\naxes[0].set_title(\"Top 200 most frequent landmarks\")\nsns.scatterplot(ax=axes[1], x='landmark_id', y='n_images', data=db2, palette=\"mako\")\naxes[1].set_title(\"Top 20 most frequent landmarks\")","2fe94961":"def downsampling(data_df, counts_df, max_samples):\n    # Get the oustanding classes to downsample\n    outstand = counts_df[counts_df[\"n_images\"]>=max_samples]\n    rest = data_df[data_df[\"landmark_id\"].isin(outstand[\"landmark_id\"]) == False]\n    # Random downsample of these classes to max_samples\n    for row in outstand.itertuples():\n        # Get max_samples for specific landmark_id\n        temp_df = data_df[data_df[\"landmark_id\"] == row.landmark_id].sample(max_samples, random_state = seed)\n        \n        rest = pd.concat([rest, temp_df], axis = 0)\n        \n    return rest","11a79339":"images_200 = downsampling(images_200, db1, db1['n_images'].min()+200) #Get the minimum samples per class and add some more\nimages_20 = downsampling(images_20, db2, db2['n_images'].min()+200)\n\n# Calculating the n_images per landmark\ndb1 = images_200.groupby([\"landmark_id\"]).size().reset_index(name='n_images')\ndb2 = images_20.groupby([\"landmark_id\"]).size().reset_index(name='n_images')\n#Plotting a barplot of the distributions\nfig, axes = plt.subplots(1, 2,sharey = True, figsize = (20,5))\n\nsns.scatterplot(ax=axes[0], x='landmark_id', y='n_images', data=db1, palette=\"mako\")\naxes[0].set_title(\"Top 200 most frequent landmarks\")\n\nsns.scatterplot(ax=axes[1], x='landmark_id', y='n_images', data=db2, palette=\"flare\")\naxes[1].set_title(\"Top 20 most frequent landmarks\")","413a17b5":"print(\"Top 200 landmarks represent {:.2f} % of the entire dataset\".format(images_200.shape[0]\/train_data.shape[0] * 100))\nprint(\"Top 2000 landmarks represent {:.2f} % of the entire dataset\".format(images_20.shape[0]\/train_data.shape[0] * 100))","a4e75e09":"X, y = images_200[\"id\"].to_list(), images_200[\"landmark_id\"].to_list()\nX_train, X_test_200, y_train, y_test_200 = train_test_split(X, y, test_size = 0.1, random_state = seed, stratify = y)","aaac225f":"X_train_200, X_val_200, y_train_200, y_val_200 = train_test_split(X_train, y_train, test_size = 0.22, random_state = seed, stratify = y_train) # 0.22 x 0.9 = 0.2","08eb5eb0":"train = { 'id': X_train_200, 'landmark_id': y_train_200 }  \nval = { 'id': X_val_200, 'landmark_id': y_val_200 }  \ntest = { 'id': X_test_200, 'landmark_id': y_test_200 }  \n\ntrain_200 = pd.DataFrame(train)\nval_200 = pd.DataFrame(val)\ntest_200 = pd.DataFrame(test)","ff98daa4":"train_200.sample(5, random_state=seed)","553e8829":"val_200.sample(5, random_state=seed)","9fd15fee":"test_200.sample(5, random_state=seed)","3df898c6":"X, y = images_20[\"id\"].to_list(), images_20[\"landmark_id\"].to_list()\nX_train, X_test_20, y_train, y_test_20 = train_test_split(X, y, test_size = 0.1, random_state = seed, stratify = y)","ba8518b1":"X_train_20, X_val_20, y_train_20, y_val_20 = train_test_split(X_train, y_train, test_size = 0.22, random_state = seed, stratify = y_train) # 0.22 x 0.9 = 0.2","c2fb2b78":"train = { 'id': X_train_20, 'landmark_id': y_train_20 }  \nval = { 'id': X_val_20, 'landmark_id': y_val_20 }  \ntest = { 'id': X_test_20, 'landmark_id': y_test_20 }  \n\ntrain_20 = pd.DataFrame(train)\nval_20 = pd.DataFrame(val)\ntest_20 = pd.DataFrame(test)","7cac4137":"train_20.sample(5, random_state=seed)","efccba32":"val_20.sample(5, random_state=seed)","554eecc4":"test_20.sample(5, random_state=seed)","58232de8":"def build_paths(df):\n    paths = [\"..\/input\/landmark-recognition-2020\/train\/{}\/{}\/{}\/{}.jpg\".format(row.id[0],row.id[1],row.id[2],row.id) for row in df.itertuples()]\n    df['path'] = paths\n    return df","cee0a501":"train_200 = build_paths(train_200)\nval_200 = build_paths(val_200)\ntest_200 = build_paths(test_200)","0b105221":"train_200.sample(5, random_state=seed)","c0666844":"val_200.sample(5, random_state=seed)","521aa216":"test_200.sample(5, random_state=seed)","f0134c13":"train_200.to_csv('train_200.csv',index=False)\nval_200.to_csv('val_200.csv',index=False)\ntest_200.to_csv('test_200.csv',index=False)","07ae4b94":"train_20 = build_paths(train_20)\nval_20 = build_paths(val_20)\ntest_20 = build_paths(test_20)","31d461a7":"train_20.sample(5, random_state=seed)","984ca7f8":"val_20.sample(5, random_state=seed)","93e14538":"test_20.sample(5, random_state=seed)","db083b79":"train_20.to_csv('train_20.csv',index=False)\nval_20.to_csv('val_20.csv',index=False)\ntest_20.to_csv('test_20.csv',index=False)","54c26ed2":"def making_folders(df, c_col, i_col, path):\n    shutil.os.mkdir(path)\n    classes = df[c_col].unique()\n    for c in tqdm(classes):\n        f_path = f\"{path}{c}\"\n        shutil.os.mkdir(f_path)\n        imgs = df.loc[df[c_col] == c][i_col].to_list()\n        for i in imgs:\n            image_path = \"..\/input\/landmark-recognition-2020\/train\/{}\/{}\/{}\/{}.jpg\".format(i[0],i[1],i[2],i)\n            shutil.copy(image_path, f_path)","4fc09857":"# making_folders(train_200, \"landmark_id\", \"id\", \"..train_200\/\")\n# making_folders(val_200, \"landmark_id\", \"id\", \"..val_200\/\")\n# making_folders(test_200, \"landmark_id\", \"id\", \"..test_200\/\")\nmaking_folders(train_20, \"landmark_id\", \"id\", \"..train_20\/\")\n# making_folders(val_20, \"landmark_id\", \"id\", \"..val_20\/\")\n# making_folders(test_20, \"landmark_id\", \"id\", \"..test_20\/\")","83fe29c4":"! ls -a","165e7d31":"def resize(path, size):\n    subfolders = [f.path for f in os.scandir(path) if f.is_dir()]\n    for s in tqdm(subfolders):\n        for i in os.listdir(s):\n            full_path = os.path.join(s,i)\n            if os.path.isfile(full_path):\n                im = Image.open(full_path)\n                imResize = im.resize(size, Image.ANTIALIAS)\n                imResize.save(full_path)","f0c62765":"# Repeat the same for every folder\ntrain = \"..train_20\/\"\nval = \"..val_20\/\"\ntest = \"..test_20\/\"\n\nresize(train, (128,128))\n# resize(val, (128,128) )\n# resize(test, (128,128)) ","f3fd7e8e":"# Repeat the same for every folder \n! zip -qr train_20.zip \"..train_20\/\"","17962125":"Before carrying on the data cleaning and preparation procees, let's take a look of the already sampled data.","06e0d04c":"Making some calculus we can stablish the proportion of the original dataset that will be used in further project steps.","3ab5a71f":"For an ease of operations later, let's build the data frames for each set.","89af6377":"Checking everything is correct.","dbec1fdb":"Although I am not going to make use of a huge part of the dataset, these percentages represent a big number of images as we have seen previously. The problem is simplified due to time and cost constraints of the development of the project.","fd04f035":"# Image sizes\n\nAfter thinking about the problem with the different image size of the dataset I considered to download the original ones. The main is reason is that I can always go back one step instead of resizing all without already knowing what type of neural network I am going to construct. So, I postpone this task for the next step to make it more suitable and with the aim of a bigger control on the factors of the efficiency of the future models.\n\n----Note **Latest Version**----\n\nOnce I modeled the first neural network I found that resizing the images with ImageDataGenerator class or special Keras layers, the time per epoch was very high due to the sizing task. For each execution, the images were resized what was a waste of time. To make the process faster what I did was resizing all images once and save them, ready to use without waiting too much. \n\nThe other problem that comes with resizing the images is deciding what size to give them. A very big size increase the time to process because there are more features to exctract from an image. On the other hand, a smaller size decrease the execution time, but some features can be overlooked by the neural network.","431ea9dd":"Now, the same process must be applied again in order to get the validation split. For that, the split is applied on the remaining train set.","420ffde9":"The way of making the directory structure comes from how **Keras** works. The idea is to construct the optimal way to feed the models and do not waste time making unnecesary searches while training and evaluating them. It will look something like the following composition:\n\n`--data\n    |--train\n        |--landmark_1\n            |--image_1_landmark_1\n            |--image_2_landmark_1\n            ...\n        |--landmark_2\n        ...\n    |--validation\n    |--test\n  `","f5270757":"# Index of Contents\n\n1. **Importing libraries**\n2. **Approach overview**\n3. **Data preparation**\n4. **Image sizes**","f9fb920b":"As it was mentioned, the images per labels are in some way more balanced than before. However, there are some outstanding classes with a huge difference of images against the others. Also, looking to the 200th classes graph it is very clear that as the range of classes increases, the images per class decreases because the points are highly concentrated on the bottom of the scatter plot.","b02f9a37":"Saving the files.","f6278da2":"Making sure, the process is completed correctly","71cf2aa6":"At this point, some of the limitations of the Kaggle platform appeared. There is a constraint about the space disk one can use, so this task must be done one by one. That is the reason the code above is commented. Moreover, it is impossible to publish the notebook with all the created folders because the **output** or **working directory** only supports `5GB`. What I did is download one by one and just the first part, the dataset with the 200 labels because the other one exceeded all the limits. My intentions is once constructed the models, come back and download the rest to scale down the builded neural networks with less classes and images.","ff1b88fb":"The next step is loading the dataset.","fc611293":"Before making the directories, let's save the `csv` files with the original paths. It is a good idea to keep track of the images we are going to use. By this way further experiments can be reproducible and easily shareable with the community.","8386268d":"# Approach Overview\n\n\nThe [Exploratoty Analysis](http:\/\/www.kaggle.com\/nikoladyulgerov\/labelling-famous-landmarks-eda) gave us clues about the nature of this particular dataset. Let's review some of its characteristics, just to sum up what we should do now to deal with it.\n\n* Huge unbalanced distribution of classes\n* High variance inside classes\n* Different image sizes\n\nDue to the computational limits I am experimenting with this project I am not going to use the entire dataset, it is impossible for me to handle this amount of data. That is why I will divide the process into two parts:\n\n* First, set the model construction with the top `200` classes on Kaggle and Google Colab platform.\n* Secondly, scale down the number of classes and see how models behaviour with the only the top `20` classes.\n\nAlthough these classes do not represent a high percent of the database, they have a great number of images what is the main reason why I have selected them. With that in mind, the balance of labels will be in some way guaranteed, although some variance stills remaining. However, it can be handle with simple techniques.","6bec6fbd":"# Importing libraries\n\nThe modules are the most basic and common one for this kind of work.","2e21ef47":"I am getting rid of the most frequent landmark of the dataset because as it was seen in the exploratory analysis it has a huge difference of images against the rest. My intention with this is to minimize the unbalance on the sample data.","5db78172":"# Data Cleaning\n\nThis notebook is the continuation of my data science project after performing the [Exploratoty Analysis](http:\/\/www.kaggle.com\/nikoladyulgerov\/labelling-famous-landmarks-eda) (**EDA**) on **Google Landmark Recognition 2020** dataset. The aim of this step is to clean and prepare the image data with which I am going to feed later on the constructed models.","59b808b5":"Repeat the same with the sample of 20 classes.","52c2e74c":"# Data Preparation\n\nThis stage consist on the preparation of the directory structure to be downloaded from the Kaggle platform. I will divide each of the two sample datasets obtained before in three main folders: **train**, **validation** and finally **test**. Here comes the other part of simplifying the problem. The test sets with which I am going to work are entirely composed by landmark images which is not the case for the given test folder by the Google competition.\n\nFollowing the standard norms and knowing that the sample datasets are big enough, the holdout of images that corresponds to each partition are going to be: `70%` train, `20%` validation and `10%` test.","61cf7ceb":"To reduce even more the imbalance among classes, I am going to perform a downsample of the outstanding classes. My aim with that is stablishing a more uniform distribution among classes so that the performance of the models will not to be affected by this aspect.","263988aa":"Checking everything is correct.","aee8071e":"With the downsampling function the graphs have changed their shapes. Now all the classes have very similar number of images due to the reduction of the oustanding ones. Moreover, it is more noticeable that as the number of classes increase the number of images per class decrease. The maximum samples per class are setted according to the minimum number of images plus a certain \"variation\" (`200`), just to avoid losing too many images. ","7568565b":"Once we have checked that is correctly loaded, we are ready for work.","a881080a":"Saving the files.","c9b6ec45":"The same operation with the other sample.","54b4d6e2":"Before starting, there is something important to consider, the classes are not perfeclty balanced, so it is a good practice to make a stratified splits. For this task, I am going to use the well known module `sklearn` that has some built-in functions that make it easy.","7ffaa219":"Finally, we are ready for making the directory structure."}}