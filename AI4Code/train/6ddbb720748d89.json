{"cell_type":{"45356862":"code","03446811":"code","b1d14b9f":"code","2dc47dbb":"code","016e787e":"code","223e885f":"code","5890adb4":"code","f744f14a":"code","001c9a80":"code","89197e73":"code","3bc96fcd":"code","84b3dfbb":"code","d5e645b4":"code","78ec5c9c":"code","c25d9e6e":"code","e1121d27":"code","3495e82b":"code","8db156eb":"code","8444d661":"code","806fb762":"code","2c0eb2f8":"code","5678b554":"code","d3b3060b":"code","3056971b":"code","6af92b85":"code","a7899859":"markdown","1f1cef05":"markdown","87f204d0":"markdown","9598dbee":"markdown","4f7224aa":"markdown","89a62477":"markdown","ef72254b":"markdown"},"source":{"45356862":"# Uncomment and run the commands below if imports fail\n# !conda install numpy pytorch torchaudio cpuonly -c pytorch -y\n# !pip install matplotlib --upgrade --quiet\n# !conda install -c conda-forge librosa\n\n# https:\/\/www.kdnuggets.com\/2020\/02\/audio-data-analysis-deep-learning-python-part-1.html?fbclid=IwAR2kJhAloxNo8aJMOvV5XI3pmgWFTEBRKD1tgLlJgg8dYFfXiRTXLjfGeqg","03446811":"!mkdir genres && wget http:\/\/opihi.cs.uvic.ca\/sound\/genres.tar.gz  && tar -xf genres.tar.gz genres\/","b1d14b9f":"!tar -zxvf genres.tar.gz genres\/\n# !tar --help","2dc47dbb":"# !rmdir data\/input\/\n# !rm genres.tar.gz\n# !rm -rf img_data","016e787e":"import torch\nimport torchaudio\nimport jovian\nimport numpy as np\nimport librosa\nimport librosa.display\nimport pandas as pd\nimport os\nfrom PIL import Image\nimport pathlib\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport torch.nn.functional as F\n# from torchvision.datasets import MNIST\n# from torchvision.transforms import ToTensor\n# from torchvision.utils import make_grid\nfrom torch.utils.data.dataloader import DataLoader\nfrom torch.utils.data import random_split\n%matplotlib inline\n","223e885f":"cmap = plt.get_cmap('inferno') # this is for img color\nplt.figure(figsize=(8,8)) # img size\ngenres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split() # all possible  music class\nfor g in genres:\n    pathlib.Path(f'img_data\/{g}').mkdir(parents=True, exist_ok=True)\n    for filename in os.listdir(f'genres\/{g}'):\n        songname = f'genres\/{g}\/{filename}'\n#         print(songname)\n#         break\n        y, sr = librosa.load(songname, mono=True, duration=5)\n        plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n        plt.axis('off');\n        plt.savefig(f'img_data\/{g}\/{filename[:-3].replace(\".\", \"\")}.png')\n        plt.clf()","5890adb4":"audio_data = 'genres\/blues\/blues.00093.wav'\nx , sr = librosa.load(audio_data)\nprint(type(x), type(sr))\n#<class 'numpy.ndarray'> <class 'int'>print(x.shape, sr)#(94316,) 22050","f744f14a":"plt.figure(figsize=(14, 5))\nlibrosa.display.waveplot(x, sr=sr)","001c9a80":"import IPython.display as ipd\nipd.Audio(audio_data)","89197e73":"X = librosa.stft(x)\nXdb = librosa.amplitude_to_db(abs(X))\nplt.figure(figsize=(14, 5))\nlibrosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='log')\nplt.colorbar()","3bc96fcd":"import sklearn\nspectral_centroids = librosa.feature.spectral_centroid(x, sr=sr)[0]\nspectral_centroids.shape","84b3dfbb":"# Computing the time variable for visualization\nplt.figure(figsize=(12, 4))\nframes = range(len(spectral_centroids))\nt = librosa.frames_to_time(frames)\n# Normalising the spectral centroid for visualisation\ndef normalize(x, axis=0):\n    return sklearn.preprocessing.minmax_scale(x, axis=axis)\n#Plotting the Spectral Centroid along the waveform\nlibrosa.display.waveplot(x, sr=sr, alpha=0.4)\nplt.plot(t, normalize(spectral_centroids), color='b')","d5e645b4":"spectral_rolloff = librosa.feature.spectral_rolloff(x+0.01, sr=sr)[0]\nplt.figure(figsize=(12, 4))\nlibrosa.display.waveplot(x, sr=sr, alpha=0.4)\nplt.plot(t, normalize(spectral_rolloff), color='r')","78ec5c9c":"spectral_bandwidth_2 = librosa.feature.spectral_bandwidth(x+0.01, sr=sr)[0]\nspectral_bandwidth_3 = librosa.feature.spectral_bandwidth(x+0.01, sr=sr, p=3)[0]\nspectral_bandwidth_4 = librosa.feature.spectral_bandwidth(x+0.01, sr=sr, p=4)[0]\nplt.figure(figsize=(15, 9))\nlibrosa.display.waveplot(x, sr=sr, alpha=0.4)\nplt.plot(t, normalize(spectral_bandwidth_2), color='r')\nplt.plot(t, normalize(spectral_bandwidth_3), color='g')\nplt.plot(t, normalize(spectral_bandwidth_4), color='y')\nplt.legend(('p = 2', 'p = 3', 'p = 4'))","c25d9e6e":"x, sr = librosa.load('genres\/blues\/blues.00093.wav')\n#Plot the signal:\nplt.figure(figsize=(14, 5))\nlibrosa.display.waveplot(x, sr=sr)\n# Zooming in\nn0 = 9000\nn1 = 9100\nplt.figure(figsize=(14, 5))\nplt.plot(x[n0:n1])\nplt.grid()","e1121d27":"n0 = 9000\nn1 = 9100\nplt.figure(figsize=(14, 5))\nplt.plot(x[n0:n1])\nplt.grid()","3495e82b":"fs = 100\nmfccs = librosa.feature.mfcc(x, sr=fs)\nprint(mfccs.shape)\n#Displaying  the MFCCs:\nplt.figure(figsize=(15, 7))\nlibrosa.display.specshow(mfccs, sr=sr, x_axis='time')","8db156eb":"hop_length =10\nchromagram = librosa.feature.chroma_stft(x, sr=sr, hop_length=hop_length)\nplt.figure(figsize=(15, 5))\nlibrosa.display.specshow(chromagram, x_axis='time', y_axis='chroma', hop_length=hop_length, cmap='coolwarm')\n","8444d661":"import csv","806fb762":"header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\nfor i in range(1, 21):\n    header += f' mfcc{i}'\nheader += ' label'\nheader = header.split()","2c0eb2f8":"file = open('dataset.csv', 'w', newline='')\nwith file:\n    writer = csv.writer(file)\n    writer.writerow(header)\ngenres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\nfor g in genres:\n    for filename in os.listdir(f'genres\/{g}'):\n        songname = f'genres\/{g}\/{filename}'\n        y, sr = librosa.load(songname, mono=True, duration=30)\n        rmse = librosa.feature.rms(y=y)\n        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n        zcr = librosa.feature.zero_crossing_rate(y)\n        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n        to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n        for e in mfcc:\n            to_append += f' {np.mean(e)}'\n        to_append += f' {g}'\n        file = open('dataset.csv', 'a', newline='')\n        with file:\n            writer = csv.writer(file)\n            writer.writerow(to_append.split())","5678b554":"data = pd.read_csv('dataset.csv')\ndata.head()","d3b3060b":"!pip install jovian --upgrade --quiet","3056971b":"import jovian","6af92b85":"jovian.commit(project='music-classification-using-deep-learning-with-pytorch', environment=None)","a7899859":"## Spectral Rolloff","1f1cef05":"## Mel-Frequency Cepstral Coefficients(MFCCs)","87f204d0":"## Create Data","9598dbee":"Spectral Bandwidth","4f7224aa":"## Zero-Crossing Rate","89a62477":"## Download Music Data\nDownload data from data scource and unzip tar file into genres folder \n\n!mkdir: for creating  directoty\n\nwget url : data source url\n\ntar -xvf tag_file_name -d extracted_dir\/  : this command for extract tar zip ","ef72254b":"## Spectrogram"}}