{"cell_type":{"098616ba":"code","5fb53ff0":"code","48df439c":"code","63d68659":"code","22ab4548":"code","a4f9fa4a":"code","83763a3d":"code","3a1f2e57":"code","e566fbfb":"code","56ec37da":"code","bc8db40d":"code","e4f9220b":"code","5b78b9b9":"code","86f7a477":"code","8338036d":"code","9c0745e7":"code","88b29b45":"code","f0f16de8":"code","c6cb3259":"code","fe3658ba":"code","9ae433d9":"code","6aaf6645":"code","c5c29fe9":"code","4d31593b":"code","93c39e60":"code","8c2dd7b5":"code","93f2f0f5":"code","ebeb494a":"code","2f26e884":"code","3f5c4149":"code","5093e8b0":"code","c597633d":"code","67332c73":"code","3f6790a8":"code","8e62b4ea":"code","3c591d51":"code","80f810b4":"code","c46e1f0c":"markdown","df9ac2df":"markdown"},"source":{"098616ba":"import os\nimport random\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import random_split\nfrom torch.utils.data.dataloader import DataLoader\n\nfrom torchvision import datasets, transforms, models \nfrom torchvision.datasets import ImageFolder\nfrom torchvision.transforms import ToTensor\nfrom torchvision.utils import make_grid","5fb53ff0":"data_dir = '..\/input\/chinese-mnist\/data\/data'\nclasses = os.listdir(data_dir)","48df439c":"labels=pd.read_csv('..\/input\/chinese-mnist\/chinese_mnist.csv')\nlabels","63d68659":"suiteids = labels['suite_id'].unique().tolist()\nprint(suiteids)\nprint(len(suiteids))","22ab4548":"sampleids = labels['sample_id'].unique().tolist()\nprint(sampleids)\nprint(len(sampleids))","a4f9fa4a":"characters = labels['character'].unique().tolist()\nprint(characters)\nprint(len(characters))","83763a3d":"values = labels['value'].unique().tolist()\nprint(values)\nprint(len(values))","3a1f2e57":"codes = labels['code'].unique().tolist()\nprint(codes)\nprint(len(codes))","e566fbfb":"labels['file']=labels[['sample_id','code']].apply(lambda x: 'input_100_'+x['sample_id'].astype(str)+'_'+x['code'].astype(str)+'.jpg',axis=1)\nlabels","56ec37da":"dataset=[]\nfor i in tqdm(range(len(labels))):\n    codei=labels.loc[i,'code']\n    filei=labels.loc[i,'file']\n    path=os.path.join(data_dir,filei)\n    image=cv2.imread(path)\n    image = image.astype(np.float32)\n    image2 = torch.from_numpy(image)\n    dataset+=[[image2,codei-1]]","bc8db40d":"dataset[100]","e4f9220b":"# view one image shape of the dataset.\nimg, label = dataset[100]\nprint(img.shape)\nprint(label)","5b78b9b9":"def show_image(img, label):\n    plt.imshow(img.numpy().astype(int))","86f7a477":"show_image(*dataset[20])","8338036d":"torch.manual_seed(20)\nval_size = len(dataset)\/\/10\ntest_size = len(dataset)\/\/5\ntrain_size = len(dataset) - val_size - test_size","9c0745e7":"train_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])\nlen(train_ds), len(val_ds), len(test_ds)   ","88b29b45":"batch_size = 64\ntrain_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\nval_loader = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)\ntest_loader = DataLoader(test_ds, batch_size*2, num_workers=4, pin_memory=True)","f0f16de8":"m=len(dataset)\nM=list(range(m))\nrandom.seed(2021)\nrandom.shuffle(M)","c6cb3259":"fig, axs = plt.subplots(3,3,figsize=(9,9))\nfor i in range(9):\n    r=i\/\/3\n    c=i%3\n    img1,label=dataset[M[i]]\n    ax=axs[r][c].axis(\"off\")\n    ax=axs[r][c].imshow(img1.numpy().astype(int))\nplt.show()","fe3658ba":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))\n\nclass ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_acc']))","9ae433d9":"def evaluate(model, val_loader):\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        for batch in tqdm(train_loader):\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","6aaf6645":"torch.cuda.is_available()","c5c29fe9":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","4d31593b":"device = get_default_device()\ndevice","93c39e60":"train_loader = DeviceDataLoader(train_loader, device)\nval_loader = DeviceDataLoader(val_loader, device)\ntest_loader = DeviceDataLoader(test_loader, device)","8c2dd7b5":"input_size = 3*64*64\noutput_size = 15","93f2f0f5":"class Model(ImageClassificationBase):\n    def __init__(self, input_size, output_size):\n        super().__init__()\n        # hidden layer\n        self.in_layer = nn.Linear(input_size, 8384)\n        self.hidden1 = nn.Linear(8384, 4192)\n        self.hidden2 = nn.Linear(4192, 2096)\n        self.hidden3 = nn.Linear(2096, 1048)\n        self.out_layer = nn.Linear(1048, output_size)\n        \n    def forward(self, xb):\n        # Flatten images into vectors\n        out = xb.view(xb.size(0), -1)\n        out = self.in_layer(out)\n        out = self.hidden1(F.relu(out))\n        out = self.hidden2(F.relu(out))\n        out = self.hidden3(F.relu(out))\n        out = self.out_layer(F.relu(out))\n        return out","ebeb494a":"model = to_device(Model(input_size, output_size), device)","2f26e884":"model","3f5c4149":"history = [evaluate(model, val_loader)]\nhistory","5093e8b0":"history += fit(7, 0.01, model, train_loader, val_loader)","c597633d":"#history += fit(8, 0.001, model, train_loader, val_loader)","67332c73":"#history += fit(3, 0.0001, model, train_loader, val_loader)","3f6790a8":"def plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs')\n    plt.show()\n    \n    \ndef plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs')\n    plt.show()","8e62b4ea":"plot_accuracies(history)","3c591d51":"plot_losses(history)","80f810b4":"evaluate(model, test_loader)","c46e1f0c":"# Linear Model","df9ac2df":"# Chinese MNIST Classify Torch Linear"}}