{"cell_type":{"b20400e6":"code","e1488b28":"code","045d3190":"code","f4e29692":"code","dc4e62b0":"code","028200f9":"code","f21a4da8":"code","00b5c968":"code","de7f0489":"code","328ebf67":"code","c64debfd":"code","86989d20":"code","2a407086":"code","dce56246":"code","f7ece8c9":"markdown","cec2872d":"markdown","f7ed596c":"markdown","15eb6db0":"markdown","d13bc2cc":"markdown","25bc6056":"markdown","f8cce72e":"markdown","37bcbd8d":"markdown","bebd2b0f":"markdown","c76c543d":"markdown","cd3d9e94":"markdown","5ed64477":"markdown","605f9713":"markdown","e5dac0c6":"markdown"},"source":{"b20400e6":"import os\nimport json\nimport datetime\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport wordcloud\n\nDATA_DIR = \"\/kaggle\/input\/youtube-new\/\"\nCOLOR = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple',\n         'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan']","e1488b28":"def load_data(region):\n      videos_path = os.path.join(DATA_DIR, \"%svideos.csv\" %(region, ))\n      category_path = os.path.join(DATA_DIR, \"%s_category_id.json\" %(region, ))\n      df = pd.read_csv(videos_path, sep=',', header=0)\n      with open(category_path, 'r') as f:\n          items = json.load(f)['items']\n          items_id = list(map(lambda x: x['id'], items))\n          items_title = list(map(lambda x: x['snippet']['title'], items))\n          ids_titles = {int(k):v for k, v in zip(items_id, items_title)}\n      return df, ids_titles\n\ndef scale(df):\n    return (df - np.min(df, axis=0, keepdims=True)) \/ np.max(df, axis=0, keepdims=True)","045d3190":"  origin_CA, CA_category = load_data('CA')","f4e29692":"CA = origin_CA.copy()\nfor i in origin_CA.category_id.unique():\n    if i not in CA_category.keys():\n        CA.drop(CA.loc[CA.category_id == i].index, inplace=True)\nCA.set_index(np.arange(0, CA.shape[0]), inplace=True)","dc4e62b0":"CA.publish_time = pd.to_datetime(CA.publish_time, infer_datetime_format=True)\nCA.trending_date = pd.to_datetime('20' + CA.trending_date, format='%Y.%d.%m',\n                                  infer_datetime_format=True, utc=True)","028200f9":"trending_period = {}\nCA_trending_date_begin = {}\nI = pd.Index(CA.video_id)\nfor vid in I.unique():\n    t = I.get_value(CA.trending_date, vid)\n    if isinstance(t, pd.datetime):\n        trending_period[vid] = 1\n        CA_trending_date_begin[vid] = t\n    else:\n        trending_period[vid] = t.shape[0]\n        CA_trending_date_begin[vid] = t.min()\n\nCA['trending_period'] = CA.video_id.map(trending_period)","f21a4da8":"def sample_data(df, train=0.9, val=0.1, test=0.1):\n    df_height = df.shape[0]\n    train_num = int(df_height * 0.9)\n    train_set = df.iloc[:int(train_num*0.9)]\n    val_set = df.iloc[int(train_num*0.9) : train_num]\n    test_set = df.iloc[train_num:]\n    return train_set, val_set, test_set\n\ndef select_label(df, y):\n    Y = df[y]\n    X = df.drop(y, axis=1)\n    return X, Y\n\nCA_train, CA_vali, CA_test = sample_data(CA)\nCA_xtrain, CA_ytrain = select_label(CA_train, 'category_id')\nCA_xvali, CA_yvali = select_label(CA_vali, 'category_id')\nCA_xtest, CA_ytest = select_label(CA_test, 'category_id')","00b5c968":"video_id_unique_idx = CA.video_id.drop_duplicates().index\nCA_category_count = CA.loc[video_id_unique_idx].groupby('category_id').video_id.count()\n\nplt.figure(figsize=(9.0, 6.0), facecolor='white')\nx = list(range(CA_category_count.shape[0]))\nplt.bar(x, CA_category_count, width=0.8)\nxlabel = CA_category_count.index.map(CA_category)\nplt.xticks(x, labels=xlabel, rotation=90)\nplt.xlabel('Category')\nplt.ylabel('Unique count')\nplt.title('Count each category display on YouTube trend')\nplt.show()","de7f0489":"category_trending_period_mean = CA.groupby(['category_id']).trending_period.mean()\n\nplt.figure(figsize=(9.0, 6.0), facecolor='white')\nx = list(range(category_trending_period_mean.shape[0]))\nplt.plot(x, category_trending_period_mean, 'o-')\nxlabel = category_trending_period_mean.index.map(CA_category)\nplt.xticks(x, labels=xlabel, rotation=90)\nplt.ylim(bottom=1)\nplt.grid(True)\nplt.show()\n","328ebf67":"CA_between_time = CA.video_id.map(CA_trending_date_begin) - CA.publish_time\ndays = pd.Series([i.days for i in CA_between_time])\nCA['between_time'] = days\ndays_count = days.value_counts()[:10]\n\nplt.figure(figsize=(9.0, 6.0), facecolor='white')\nplt.bar(days_count.index, days_count)\nplt.xticks(days_count.index)\nplt.grid(True)","c64debfd":"CA_category_between_time_mean = CA.loc[:, ['category_id', 'between_time']].groupby('category_id').mean()\nCA_category_between_time_mean.sort_values(by='between_time', ascending=False, inplace=True)\n\nplt.figure(figsize=(9.0, 6.0), facecolor='white')\nx = list(range(CA_category_between_time_mean.shape[0]))\nplt.plot(x, CA_category_between_time_mean, 'o-')\nplt.xticks(x, labels=list(map(lambda x: CA_category[x], CA_category_between_time_mean.index)), rotation=90)\nplt.grid(True)","86989d20":"corr = CA.corr()\nx = list(range(corr.shape[0]))\n\nplt.style.use('ggplot')\nplt.figure(figsize=(9.0, 6.0))\nplt.imshow(CA.corr(), cmap=plt.cm.Reds, interpolation='nearest')\nplt.colorbar()\nplt.xticks(x, labels=corr.columns, rotation=90)\nplt.yticks(x, labels=corr.columns)\nplt.show()","2a407086":"top_ten_category_id = CA_category_count.sort_values(ascending=False)[:10]\nidx = CA_ytrain.apply(lambda x: x in top_ten_category_id.keys())\nCAv_xtrain = CA_xtrain.loc[idx]\nCAv_ytrain = CA_ytrain.loc[idx]\n\nplt.style.use('ggplot')\nfig, ax = plt.subplots(figsize=(9.0, 6.0))\nfor i, vid in enumerate(top_ten_category_id.keys()):\n    idx = CAv_ytrain == vid\n    x = CAv_xtrain.views[idx]\n    y = CAv_xtrain.likes[idx]\n    ax.scatter(x, y, c=COLOR[i % 10], alpha=0.5, label=CA_category[vid])\nax.legend()\nax.set_xticks([])\nax.set_yticks([])\nax.set_xlabel('views')\nax.set_ylabel('likes')\nfig.tight_layout(pad=0.0)\nplt.show()\n","dce56246":"tags = CA.loc[CA.tags.str.find('none') == -1].tags\nCA_tags = {}\nfor x in tags:\n    words = x.split('|')\n    for w in words:\n        w = w.lower().replace('\\\"', '')\n        CA_tags[w] = CA_tags.get(w, 0) + 1\n\nCA_wordcloud = wordcloud.WordCloud(background_color='white')\nCA_wordcloud.generate_from_frequencies(CA_tags)\n\nplt.figure(figsize=(9.0, 6.0))\nplt.imshow(CA_wordcloud)\nplt.axis('off')\nplt.tight_layout(pad=0.0)\nplt.show()","f7ece8c9":"6. Top 10 category on CA.","cec2872d":"### Describe analysis\n1. explore the count for every category.","f7ed596c":"## Package load","15eb6db0":"5. explore the correlation on every numerical feature.","d13bc2cc":"### from file load data","25bc6056":"3. the time between publish time to first time present on trending list.","f8cce72e":"## Data analysis\n### preprocess\n1. delete the category id on CA data set but not present on the CA_category info list.","37bcbd8d":"## Data load\n### load function\n    On load_data function, I extract category title and category_id generate new dict. \n    And scale function is the $$ X_{scale} = \\frac{X - min(X)}{max(X)} $$","bebd2b0f":"2. convert publish_time to datetime type, and modifyed trending_date to the correct datetime format.","c76c543d":"3. generate new variable trending_period, which represent the video stay days on Youtube trending list. I also records datetime which video first time found stay on trending list.","cd3d9e94":"4. split data set.","5ed64477":"2. explore the average days on trending list for every category.","605f9713":"7. wordcloud for tags.","e5dac0c6":"4. explore every category average time from publish to become trending."}}