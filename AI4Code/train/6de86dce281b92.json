{"cell_type":{"9c814bee":"code","c70b946e":"code","08903611":"code","4ed97f16":"code","430ce87d":"code","9134dbdd":"code","cee1ddfa":"code","089fe91f":"code","1f3962ca":"code","38570339":"code","8d8fc88c":"code","7260fa5f":"code","82870a9e":"code","eeb3a499":"code","061d8ba3":"code","5a11623f":"code","d1ce38eb":"code","38090dcf":"code","75eb36aa":"code","3e7867f8":"code","fb062be5":"code","e6d3d488":"code","caf1417e":"code","f435cb2e":"code","900842da":"code","5f142c17":"code","641c0db9":"code","140dbc83":"code","db8edb40":"code","313a9eeb":"code","c5e76cbd":"code","7cf64dfa":"code","f636b5d5":"code","d19bd26b":"code","8b7dfd67":"code","82a2b7e9":"code","08d2f19d":"code","5aeab8a0":"code","da9ad1b3":"code","f979126a":"code","e5c03bd5":"code","8c8d9384":"code","b22a3f36":"code","6157ef3a":"code","66a26153":"code","825dcf01":"code","d69d26ea":"code","4338da23":"code","7e6e8eb0":"code","3cacbe73":"code","8b10898c":"code","198c4bd9":"code","ff932a71":"code","803c4782":"code","52997dbe":"code","c8ce76b8":"code","fe451f45":"code","6557e241":"code","e4a6f762":"code","49f5a60f":"code","b82b4e4b":"code","fb77ee9e":"code","3665aa75":"code","72bdb68b":"code","c18d59fd":"code","9ebe0f5e":"code","a26059cd":"code","bd4f1ac9":"markdown","e220ce5e":"markdown"},"source":{"9c814bee":"commit = 0\nno_of_timestamps = 16\nbatch_size = 16\nepochs = 100\nlr = 0.01\nshift = 0\nlen_cc = 400","c70b946e":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport lightgbm as lgb\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.metrics import roc_auc_score\nfrom catboost import CatBoostClassifier\nfrom IPython.display import display, clear_output, FileLinks\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\n\nimport altair as alt\nfrom altair.vega import v5\nfrom IPython.display import HTML\nfrom sklearn import preprocessing\nfrom tqdm.notebook import tqdm\nimport lightgbm as lgb\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nimport glob\nimport os\nimport sklearn.datasets\nimport sklearn.metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder \nfrom tqdm.notebook import tqdm\nimport optuna\n\nimport gc, datetime, random\n\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.impute import SimpleImputer\nfrom collections import defaultdict, Counter\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GroupKFold, GridSearchCV, train_test_split, TimeSeriesSplit\nfrom sklearn.model_selection import StratifiedKFold\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\n\n\n\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n","08903611":"!ls","4ed97f16":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport scipy.io        \nimport plotly.graph_objs as go\nfrom PIL import Image\n","430ce87d":"regression = 1\ni_m_g = 1\nchannels = 1\ncycle = 0\nfft_ = 1\nimport cv2\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfrom tqdm import tqdm_notebook as tqdm\nfrom tqdm import tqdm_notebook\nfrom sklearn.preprocessing import LabelEncoder\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport torch\n# Neural networks can be constructed using the torch.nn package.\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data.sampler import SequentialSampler, SubsetRandomSampler\nfrom torch.utils.data import Dataset\nimport torchvision\nimport torchvision.transforms as transforms\nimport torchvision.models as models\nimport torch.optim as optim\nimport pickle \n\n\nimport scipy.io as sio\nfrom scipy.io import loadmat, savemat\nfrom scipy.stats.stats import pearsonr \nfrom scipy.stats import spearmanr\n\n# for dirname, _, filenames in os.walk('\/kaggle\/'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\nimport gc\n\nimport warnings\n\nwarnings.filterwarnings('ignore')\nfrom IPython.display import display, clear_output, FileLinks","9134dbdd":"\n%mkdir Y_train\n%mkdir Y_test\n%mkdir Y\n!ls\n\n","cee1ddfa":"mat_file_path = '\/kaggle\/input\/livenetflixmetadata\/Dataset_Information\/Mat_Files\/Chimera1102347_HuangBufferBasedAdaptor_Trace_3.mat'","089fe91f":"def get_hw(file_name):\n    mat_file_path = '\/kaggle\/input\/livenetflixmetadata\/Dataset_Information\/Mat_Files\/' + file_name\n    import scipy.io\n    mat = scipy.io.loadmat(mat_file_path)\n\n    h = mat['height'][0]\n    w = mat['width'][0]\n    return h, w, mat","1f3962ca":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","38570339":"# ..\/input\/livenetflixtraces\/CosmosLaundromat_VMAFViterbiQualityBasedAdaptor_Trace_0.mp4\nvid_paths = os.listdir('\/kaggle\/input\/livenetflixtraces\/')\n# vid_paths.remove('tr.yuv')\n\nvid_paths","8d8fc88c":"if not commit:\n    vid_paths = vid_paths[:1]\n    print('not comiit')\nelse :\n    print('comiit')","7260fa5f":"def get_len(vid_path):\n    vidcap = cv2.VideoCapture(vid_path)\n    success,image = vidcap.read()\n    count = 0\n    while success:\n#         cv2.imwrite(vid + \"_frame_%d.jpg\" % count, image)   \n        success,image = vidcap.read()\n#         print('Read a new frame: ', success)\n        count += 1\n    return count\n","82870a9e":"!mkdir Y","eeb3a499":"train_datas = []\nvalid_datas = []\n\ntrain_datas_y = []\nvalid_datas_y = []\n\ne=0\n\nmat_files_path = '\/kaggle\/input\/livenetflixmetadata\/Dataset_Information\/Mat_Files\/'","061d8ba3":"def get_df(train_generator):\n    count=0\n    for i in train_generator:\n        count+=1\n    df = pd.DataFrame(index=range(count))\n\n    feats = []\n    labels = []\n    for seq in tqdm(train_generator):\n        feat_1 = []\n        for row in seq[0][0]:\n            for elem in row:\n                feat_1.append(elem)\n\n        feats.append(feat_1)\n        labels.append(seq[1][0])\n    feats = np.array(feats)\n    for i in range(feats.shape[1]):\n        arrr = list(feats[:, i])\n        df[i] = arrr\n#     df = pd.DataFrame(feats)\n#     df['labels'] = labels\n\n    return df\n\n\ndef add_rebuffer(array, is_rebuffered_bool):\n    if len(array) == 1:\n        array = array[0]\n    if len(is_rebuffered_bool) == 1:\n        is_rebuffered_bool = is_rebuffered_bool[0]\n        \n    if len(is_rebuffered_bool) == len(array):\n        return np.array(array).reshape(-1, 1)\n    \n    new_array = np.array(is_rebuffered_bool)*-1\n    j=0\n    for i in range(len(new_array)):\n        new_array[i] = array[j]\n        if is_rebuffered_bool[i]==0:\n            j+=1\n    return np.array(new_array).reshape(-1, 1)\n\n\nusing_features = [\n    'STRRED',\n    'VMAF',\n    'SSIM',\n    'playout_bitrate',\n    'PSNR',\n    'MSSIM',    \n    'is_rebuffered_bool',\n#     'continuous_zscored_mos',\n    # removing 1 from all since to keep same row same label\n]","5a11623f":"using_features","d1ce38eb":"%%time\nimport cv2\nfrom keras.preprocessing.sequence import TimeseriesGenerator\ntrain_names = []\ntrain_frame_no = []\ntrain_labels = []\n\ntest_names = []\ntest_frame_no = []\ntest_labels = []\n\n\ntrain_STRRED = []\ntrain_VMAF = []\ntrain_SSIM = []\ntrain_playout_bitrate = []\ntrain_PSNR = []\ntrain_MSSIM = []\ntrain_is_rebuffered_bool = []\ntrain_interval = []\n\ntest_STRRED = []\ntest_VMAF = []\ntest_SSIM = []\ntest_playout_bitrate = []\ntest_PSNR = []\ntest_MSSIM = []\ntest_is_rebuffered_bool = []\ntest_interval = []\n\n\nfor vid in tqdm(vid_paths):\n    vid_path = os.path.join('\/kaggle\/input\/livenetflixtraces\/', vid)\n    file_name = vid[:-3] + 'mat'\n    h, w, mat = get_hw(file_name)\n    mat_file = scipy.io.loadmat(mat_files_path+file_name)\n    \n    festures = [     ]\n    for feats in using_features:\n        festures.append(add_rebuffer(mat_file[feats], mat_file['is_rebuffered_bool']))\n    festures = np.array(festures)\n    stack = festures[0]\n    for i in range(1,len(using_features)):\n        stack = np.hstack( (stack, festures[i]) )\n    intervals = (np.array(range(len(stack))) \/\/ 20).reshape(-1, 1)\n    stack = np.hstack((stack, intervals))\n    stack = np.vstack((stack, np.array([0]*stack.shape[1])))\n    \n    train_generator = TimeseriesGenerator(stack,stack[:, 0],length=1, batch_size=1)\n    feat_df = get_df(train_generator)\n    feat_df.columns = using_features + ['interval']\n    \n    \n    len_vid = get_len(vid_path)\n    tr_length, val_length = round(len_cc*0.80), len_cc - round(len_vid*0.80)\n    \n    vidcap = cv2.VideoCapture(vid_path)\n    success,image = vidcap.read()\n    count = 0\n    while success:\n        \n        if count < tr_length:\n            train_names.append(vid + \"_frame_%d.jpg\" % count)\n            train_frame_no.append(count)\n            train_labels.append(mat['continuous_zscored_mos'][0][count]+shift)\n            \n            train_STRRED.append(feat_df['STRRED'][count])\n            train_VMAF.append(feat_df['VMAF'][count])\n            train_SSIM.append(feat_df['SSIM'][count])\n            train_playout_bitrate.append(feat_df['playout_bitrate'][count])\n            train_PSNR.append(feat_df['PSNR'][count])\n            train_MSSIM.append(feat_df['MSSIM'][count])\n            train_is_rebuffered_bool.append(feat_df['is_rebuffered_bool'][count])\n            train_interval.append(feat_df['interval'][count])\n\n            \n        else:\n            test_names.append(vid + \"_frame_%d.jpg\" % count)\n            test_frame_no.append(count)\n            test_labels.append(mat['continuous_zscored_mos'][0][count]+shift)\n            \n            test_STRRED.append(feat_df['STRRED'][count])\n            test_VMAF.append(feat_df['VMAF'][count])\n            test_SSIM.append(feat_df['SSIM'][count])\n            test_playout_bitrate.append(feat_df['playout_bitrate'][count])\n            test_PSNR.append(feat_df['PSNR'][count])\n            test_MSSIM.append(feat_df['MSSIM'][count])\n            test_is_rebuffered_bool.append(feat_df['is_rebuffered_bool'][count])\n            test_interval.append(feat_df['interval'][count])\n            \n            \n        cv2.imwrite(\"Y\/\"+vid + \"_frame_%d.jpg\" % count, image)\n        success,image = vidcap.read()\n#         print('Read a new frame: ', success)\n        count += 1\n        if count==len_cc:\n            break\n        ","38090dcf":"mat.keys()","75eb36aa":"data = {'Images':train_names,\n#         'Images_fft':train_names_fft,\n        'labels':train_labels,\n#         'speed' : train_speeds,\n        'frame_no' : train_frame_no,\n#         'encoded_labels' : train_encoded_labels\n        \n        'STRRED': train_STRRED,\n        'VMAF': train_VMAF,\n        'SSIM': train_SSIM,\n        'playout_bitrate': train_playout_bitrate,\n        'PSNR': train_PSNR,\n        'MSSIM': train_MSSIM,\n        'is_rebuffered_bool': train_is_rebuffered_bool,\n        'interval': train_interval,\n       } \ndata = pd.DataFrame(data)\ndata['labels'] = data['labels'].astype(str)\ndata['nu_labels'] = data['labels'].astype(float)\ndata.head()\n\n\ntrain_data = data.copy()\n\ndata = {'Images':test_names,\n#         'Images_fft':test_names_fft,\n        'labels':test_labels,\n#         'speed' : test_speeds,\n        'frame_no' : test_frame_no,\n#         'encoded_labels' : test_encoded_labels\n        'STRRED': test_STRRED,\n        'VMAF': test_VMAF,\n        'SSIM': test_SSIM,\n        'playout_bitrate': test_playout_bitrate,\n        'PSNR': test_PSNR,\n        'MSSIM': test_MSSIM,\n        'is_rebuffered_bool': test_is_rebuffered_bool,\n        'interval': test_interval,\n        \n       } \ndata = pd.DataFrame(data)\ndata['labels'] = data['labels'].astype(str)\ndata['nu_labels'] = data['labels'].astype(float)\ndata.head()\n\n\ntest_data = data.copy()\n\ntrain_data.head()","3e7867f8":"data = pd.concat([train_data, test_data], axis=0)\ndata = data.reset_index(drop=True)\n\n\ntrain_data_rw = train_data.iloc[:-1*no_of_timestamps, :]\ntest_data_rw = test_data.iloc[:-1*no_of_timestamps, :]\ndata_rw = pd.concat([train_data_rw, test_data_rw], axis=0)\ndata_rw = data_rw.reset_index(drop=True)\n\ntrain_indices, val_indices = list(train_data_rw.index), list(len(train_data)+np.array(test_data_rw.index))\ndata.head()","fb062be5":"test_data","e6d3d488":"from sklearn.preprocessing import StandardScaler\nfor i in data.columns[1:]:\n    sc = StandardScaler()\n    data[i] = sc.fit_transform(np.array(data[i]).reshape(-1, 1))\n    sc = StandardScaler()\n    data_rw[i] = sc.fit_transform(np.array(data_rw[i]).reshape(-1, 1))\n    ","caf1417e":"# train_indices = []\n# val_indices = []\n# for i in range(len(data_rw)):\n#     if i%5 == 0:\n#         val_indices += [i]\n#     else:\n#         train_indices += [i]","f435cb2e":"train_indices","900842da":"val_indices","5f142c17":"len_vid","641c0db9":"vidcap = cv2.VideoCapture(vid_path)\nsuccess,image = vidcap.read()\ncount = 0\nwhile success:\n\n    if count < tr_length:\n        train_names.append(vid + \"_frame_%d.jpg\" % count)\n        train_frame_no.append(count)\n        train_labels.append(mat['continuous_zscored_mos'][0][count])\n    else:\n        test_names.append(vid + \"_frame_%d.jpg\" % count)\n        test_frame_no.append(count)\n        test_labels.append(mat['continuous_zscored_mos'][0][count])\n\n    cv2.imwrite(vid + \"_frame_%d.jpg\" % count, image)\n    success,image = vidcap.read()\n#         print('Read a new frame: ', success)\n    count += 1\n    if count == 10:\n        break\n\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\ngray = image\nfig = plt.figure()\nplt.imshow(gray)\ndisplay(fig)","140dbc83":"FileLinks('..\/working\/Y')","db8edb40":"transform = transforms.Compose(\n    [transforms.ToTensor(),\n#      transforms.Resize(325),\n     transforms.Normalize((0.5), (0.5))])\n\nif i_m_g:\n    transform = transforms.Compose(\n        [transforms.ToTensor(),\n#          transforms.Resize(320),\n         transforms.Normalize((0.5), (0.5))])\n","313a9eeb":"from cv2 import imread\nclass Arthopod_Dataset(Dataset):\n    def __init__(self, img_data,img_data_rw,img_path,transform=None):\n        self.img_path = img_path\n        self.transform = transform\n        self.img_data = img_data\n        self.img_data_rw = img_data_rw\n        \n    def __len__(self):\n        return len(self.img_data_rw)\n    \n    def __getitem__(self, index):\n        images = []\n        labels = []\n        frame_nos = []\n        indexs = []\n        \n        \n        STRREDs = []\n        VMAFs = []\n        SSIMs = []\n        playout_bitrates = []\n        PSNRs = []\n        MSSIMs = []\n        is_rebuffered_bools = []\n        intervals = []\n        \n        \n        for ee in range(no_of_timestamps):\n            img_name = os.path.join(self.img_path,self.img_data.loc[index, 'Images'])\n            image = Image.open(img_name)\n            image = image.resize((118,118))\n            if self.transform is not None:\n                image = self.transform(image)\n            image.float()\n            image = image.numpy()\n            \n            label = torch.tensor(self.img_data.loc[index, 'nu_labels']).float() # regression\n            frame_no = torch.tensor(self.img_data.loc[index, 'frame_no']).float()\n            \n            STRRED = torch.tensor(self.img_data.loc[index, 'STRRED']).float()\n            VMAF = torch.tensor(self.img_data.loc[index, 'VMAF']).float()\n            SSIM = torch.tensor(self.img_data.loc[index, 'SSIM']).float()\n            playout_bitrate = torch.tensor(self.img_data.loc[index, 'playout_bitrate']).float()\n            PSNR = torch.tensor(self.img_data.loc[index, 'PSNR']).float()\n            MSSIM = torch.tensor(self.img_data.loc[index, 'MSSIM']).float()\n            is_rebuffered_bool = torch.tensor(self.img_data.loc[index, 'is_rebuffered_bool']).float()\n            interval = torch.tensor(self.img_data.loc[index, 'interval']).float()\n            \n            images.append(image)\n            labels.append(label)\n            \n            frame_nos.append(frame_no)\n            indexs.append(index)\n            \n            STRREDs.append(STRRED)\n            VMAFs.append(VMAF)\n            SSIMs.append(SSIM)\n            playout_bitrates.append(playout_bitrate)\n            PSNRs.append(PSNR)\n            MSSIMs.append(MSSIM)\n            is_rebuffered_bools.append(is_rebuffered_bool)\n            intervals.append(interval)\n            \n\n            index += 1\n        images = torch.tensor(np.array(images))\n        labels = torch.tensor(np.array(labels))\n        frame_nos = torch.tensor(np.array(frame_nos))\n        indexs = torch.tensor(np.array(indexs))\n        \n        STRREDs = torch.tensor(np.array(STRREDs))\n        VMAFs = torch.tensor(np.array(VMAFs))\n        SSIMs = torch.tensor(np.array(SSIMs))\n        playout_bitrates = torch.tensor(np.array(playout_bitrates))\n        PSNRs = torch.tensor(np.array(PSNRs))\n        MSSIMs = torch.tensor(np.array(MSSIMs))\n        is_rebuffered_bools = torch.tensor(np.array(is_rebuffered_bools))\n        intervals = torch.tensor(np.array(intervals))\n        \n        \n        \n        \n        return images, labels, frame_nos, STRREDs,VMAFs,SSIMs,playout_bitrates,PSNRs,MSSIMs,is_rebuffered_bools,intervals,indexs","c5e76cbd":"BASE_PATH = '\/kaggle\/working\/Y\/'\ndataset = Arthopod_Dataset(data,data_rw,BASE_PATH,transform)\n# dataset. __getitem__(5)","7cf64dfa":"data.iloc[:-1*no_of_timestamps, :]","f636b5d5":"dataset.__len__()","d19bd26b":"len(train_indices)+len(val_indices)","8b7dfd67":"for i in dataset:\n    print(i)\n    break","82a2b7e9":"# %%time\n# img_name = BASE_PATH + os.listdir(BASE_PATH)[0]\n# img_name\n# image = Image.open(img_name)\n# (image)","08d2f19d":"def npy_loader(path):\n    sample = torch.from_numpy(np.load(path))\n    return sample","5aeab8a0":"# Creating PT data samplers and loaders:\n\ntrain_sampler = SubsetRandomSampler(train_indices)\nvalid_sampler = SubsetRandomSampler(val_indices)\n\n\n# train_sampler = SequentialSampler(train_indices)\n# valid_sampler = SequentialSampler(val_indices)\n\n\n\ntrain_sampler","da9ad1b3":"train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n                                           sampler=train_sampler)\nvalidation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n                                                sampler=valid_sampler)\n","f979126a":"# image[0, :, :], label, frame_no, index","e5c03bd5":"data.index","8c8d9384":"%%time\nif commit:\n    for i in range(1):\n        for images, labels, frame_nos, STRREDs,VMAFs,SSIMs,playout_bitrates,PSNRs,MSSIMs,is_rebuffered_bools,intervals,indexs in (validation_loader):\n    #         print(target_t.data.cpu().numpy())\n            print(i, len(indexs.data.cpu().numpy() - len(train_indices)))","b22a3f36":"# dataiter = iter(train_loader)\n# images, labels, frame_nos, STRREDs,VMAFs,SSIMs,playout_bitrates,PSNRs,MSSIMs,is_rebuffered_bools,intervals,indexs = dataiter.next()\n# print(np.transpose(images[0][0], (2, 0, 1)).shape)\n# # np.transpose(images[0], (0, 1, 2)).shape\n# images.shape","6157ef3a":"def accuracy(out, labels):\n    _,pred = torch.max(out, dim=1)\n    return torch.sum(pred==labels).item()","66a26153":"def img_display(img):\n    img = img \/ 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    if i_m_g:\n#         npimg = np.transpose(npimg, (2, 0, 1)) # code 3\n        return npimg\n#     return npimg[0, :, :]\n    return npimg","825dcf01":"# %%time\n# # get some random training images\n# dataiter = iter(train_loader)\n# images,labels,frame_nos,STRREDs,VMAFs,SSIMs,playout_bitrates,PSNRs,MSSIMs,is_rebuffered_bools,intervals,indexs = dataiter.next()\n# arthopod_types = {0: 'Coleoptera', 1: 'Diptera', 2: 'Hymenoptera', 3: 'Lepidoptera'}\n# # Viewing data examples used for training\n# fig, axis = plt.subplots(2, 2, figsize=(15, 10))\n# for i, ax in enumerate(axis.flat):\n#     with torch.no_grad():\n#         i=0\n#         image, label, frame_no = images[i], labels[i], frame_nos[i] \n#         image = image[0][0] # code 1\n#         ax.imshow(img_display(image)) # add image\n# #         ax.set(title = f\"{[label.item(), speed.item()]}\") # add label\n#         ax.set(title = f\"{[label[0].item()]}\") # add label\n    \n# display(fig)\n# images.shape","d69d26ea":"class Args:\n    def __init__(self):\n        self.cuda = True\n        self.no_cuda = False\n        self.seed = 1\n        self.batch_size = batch_size\n        self.test_batch_size = batch_size\n        self.epochs = epochs\n        self.lr = lr\n        self.momentum = 0.5\n        self.log_interval = 10\n\n\nargs = Args()\n\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\nargs.no_cuda = not args.cuda\nargs.cuda","4338da23":"\n# class CNN(nn.Module):\n#     def __init__(self):\n#         super(CNN, self).__init__()\n#         self.conv1 = nn.Conv2d(3, 10, kernel_size=5)\n#         self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n#         self.conv2_drop = nn.Dropout2d()\n#         self.fc1 = nn.Linear(320, 50)\n#         self.fc2 = nn.Linear(50, 10)\n\n#     def forward(self, x):\n#         x = F.relu(F.max_pool2d(self.conv1(x), 2))\n#         x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n#         x = x.view(-1, 13520)\n#         #x = F.relu(self.fc1(x))\n#         #x = F.dropout(x, training=self.training)\n#         #x = self.fc2(x)\n#         #return F.log_softmax(x, dim=1)\n#         return x\n\n\n# class Combine(nn.Module):\n#     def __init__(self):\n#         super(Combine, self).__init__()\n#         self.cnn = CNN()\n#         self.rnn = nn.LSTM(\n#             input_size=13520, \n#             hidden_size=64, \n#             num_layers=1,\n#             batch_first=True)\n#         self.linear = nn.Linear(64,1)\n\n#     def forward(self, x):\n# #         print(x.size())\n#         s_a = x.size()\n#         batch_size, timesteps, C, H, W = s_a[0], s_a[1], s_a[2], s_a[3], s_a[4]\n#         c_in = x.view(batch_size * timesteps, C, H, W)\n#         c_out = self.cnn(c_in)\n#         r_in = c_out.view(batch_size, timesteps, -1)\n#         r_out, (h_n, h_c) = self.rnn(r_in)\n#         r_out2 = self.linear(r_out[:, -1, :])\n        \n#         return r_out2\n# #         return F.log_softmax(r_out2, dim=1)    ","7e6e8eb0":"\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 13520)\n        #x = F.relu(self.fc1(x))\n        #x = F.dropout(x, training=self.training)\n        #x = self.fc2(x)\n        #return F.log_softmax(x, dim=1)\n        return x\n\n\nclass Combine(nn.Module):\n    def __init__(self):\n        super(Combine, self).__init__()\n        \n        \n        vgg16 = models.vgg16(pretrained=True)\n        print(vgg16.classifier[6].out_features) # 1000 \n        # Freeze training for all layers\n        for param in vgg16.features.parameters():\n            param.require_grad = False\n\n        # Newly created modules have require_grad=True by default\n        num_features = vgg16.classifier[6].in_features\n        features = list(vgg16.classifier.children())[:-1] # Remove last layer\n        features.extend([nn.Linear(num_features, 1+9)]) # Add our layer with 4 outputs\n        vgg16.classifier = nn.Sequential(*features) # Replace the model classifier\n\n        self.model_ft1 = vgg16\n        \n        \n#         self.cnn = CNN()\n        self.dropout = nn.Dropout2d(0.2)\n        self.lrelu = nn.LeakyReLU()\n        self.relu = nn.ReLU()\n        \n        self.rnn = nn.LSTM(\n            input_size=1+9, \n            hidden_size=24, \n            num_layers=4,\n            batch_first=True)\n        \n        \n        self.rnn1 = nn.LSTM(\n            input_size=8+1, \n            hidden_size=16, \n            num_layers=4,\n            batch_first=True)\n        \n        \n        self.linear = nn.Linear(24,1)\n        self.linear1 = nn.Linear(16,1)\n        \n        self.linear2 = nn.Linear(8+2+1,11)\n        self.linear2_1 = nn.Linear(11,1)\n\n    def forward(self, x, frame_nos,STRREDs,VMAFs,SSIMs,playout_bitrates,PSNRs,MSSIMs,is_rebuffered_bools,intervals):\n        # cnn under lstm\n        s_a = x.size()\n        batch_size, timesteps, C, H, W = s_a[0], s_a[1], s_a[2], s_a[3], s_a[4]\n        c_in = x.view(batch_size * timesteps, C, H, W)\n        c_out = self.dropout(self.lrelu(self.model_ft1(c_in)))\n        r_in_cnn = c_out.view(batch_size, timesteps, -1)\n        \n        r_out_cnn, (h_n, h_c) = self.rnn(r_in_cnn)\n        r_out2_cnn = (self.linear(r_out_cnn[:, -1, :]))\n        \n        # fetaures under lstms\n        r_in = torch.cat([frame_nos, STRREDs], dim=2)\n        r_in = torch.cat([r_in, VMAFs], dim=2)\n        r_in = torch.cat([r_in, SSIMs], dim=2)\n        r_in = torch.cat([r_in, playout_bitrates], dim=2)\n        r_in = torch.cat([r_in, PSNRs], dim=2)\n        r_in = torch.cat([r_in, MSSIMs], dim=2)\n        r_in = torch.cat([r_in, is_rebuffered_bools], dim=2)\n        r_in = torch.cat([r_in, intervals], dim=2)\n        r_out, (h_n, h_c) = self.rnn1(r_in)\n        \n        r_out2 = (self.linear1(r_out[:, -1, :]))\n    \n        # all under linear\n        new_size = STRREDs.size()[0]\n        linear_in = torch.cat([STRREDs[:, -1, 0].view(new_size, -1), frame_nos[:, -1, 0].view(new_size, -1)], dim=1)\n        linear_in = torch.cat([linear_in, VMAFs[:, -1, 0].view(new_size, -1)], dim=1)\n        linear_in = torch.cat([linear_in, SSIMs[:, -1, 0].view(new_size, -1)], dim=1)\n        linear_in = torch.cat([linear_in, playout_bitrates[:, -1, 0].view(new_size, -1)], dim=1)\n        linear_in = torch.cat([linear_in, PSNRs[:, -1, 0].view(new_size, -1)], dim=1)\n        linear_in = torch.cat([linear_in, MSSIMs[:, -1, 0].view(new_size, -1)], dim=1)\n        linear_in = torch.cat([linear_in, is_rebuffered_bools[:, -1, 0].view(new_size, -1)], dim=1)\n        linear_in = torch.cat([linear_in, intervals[:, -1, 0].view(new_size, -1)], dim=1)\n        \n        linear_in = torch.cat([linear_in, r_out2], dim=1)\n        linear_in = torch.cat([linear_in, r_out2_cnn], dim=1)\n        \n        linear_out = (self.linear2(linear_in))\n        linear_out_1 = (self.linear2_1(linear_out))\n        \n        \n        return linear_out_1","3cacbe73":"# dd = np.expand_dims(frame_nos, axis=2)\n# dd.shape","8b10898c":"model = Combine()\nif args.cuda:\n    model.cuda()\n\noptimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n","198c4bd9":"from sklearn.metrics import mean_squared_error as mse","ff932a71":"def ed(a):\n    return np.expand_dims(a, axis=2)\ndef ft(a):\n    return torch.FloatTensor(a)\ndef cu(a):\n    return a.cuda()","803c4782":"from torch.autograd import Variable","52997dbe":"\nfrom torch.autograd import Variable\ndef train(epoch):\n    model.train()\n#     images, labels, frame_nos, indexes\n    for batch_idx, (data, targets, frame_nos ,STRREDs,VMAFs,SSIMs,playout_bitrates,PSNRs,MSSIMs,is_rebuffered_bools,intervals,indexs) in enumerate(train_loader):\n        data, targets, frame_nos,STRREDs,VMAFs,SSIMs,playout_bitrates,PSNRs,MSSIMs,is_rebuffered_bools,intervals,indexs = data.float(),targets.float(),frame_nos.float(),STRREDs.float(),VMAFs.float(),SSIMs.float(),playout_bitrates.float(),PSNRs.float(),MSSIMs.float(),is_rebuffered_bools.float(),intervals.float(),indexs\n        frame_nos = ed(frame_nos)\n        STRREDs,VMAFs,SSIMs,playout_bitrates,PSNRs,MSSIMs,is_rebuffered_bools,intervals = ed(STRREDs),ed(VMAFs),ed(SSIMs),ed(playout_bitrates),ed(PSNRs),ed(MSSIMs),ed(is_rebuffered_bools),ed(intervals)\n        \n        data = torch.FloatTensor(data)\n        frame_nos = torch.FloatTensor(frame_nos)\n        \n        STRREDs,VMAFs,SSIMs,playout_bitrates,PSNRs,MSSIMs,is_rebuffered_bools,intervals = ft(STRREDs),ft(VMAFs),ft(SSIMs),ft(playout_bitrates),ft(PSNRs),ft(MSSIMs),ft(is_rebuffered_bools),ft(intervals)\n        if args.cuda:\n            data, targets, frame_nos = data.cuda(), targets.cuda(),  frame_nos.cuda()\n            STRREDs,VMAFs,SSIMs,playout_bitrates,PSNRs,MSSIMs,is_rebuffered_bools,intervals = cu(STRREDs),cu(VMAFs),cu(SSIMs),cu(playout_bitrates),cu(PSNRs),cu(MSSIMs),cu(is_rebuffered_bools),cu(intervals)\n\n\n        \n        data, targets, frame_nos = Variable(data), Variable(targets), Variable(frame_nos)\n        STRREDs,VMAFs,SSIMs,playout_bitrates,PSNRs,MSSIMs,is_rebuffered_bools,intervals = Variable(STRREDs),Variable(VMAFs),Variable(SSIMs),Variable(playout_bitrates),Variable(PSNRs),Variable(MSSIMs),Variable(is_rebuffered_bools),Variable(intervals)\n\n        optimizer.zero_grad()\n        output = model(data, frame_nos,STRREDs,VMAFs,SSIMs,playout_bitrates,PSNRs,MSSIMs,is_rebuffered_bools,intervals)\n        \n        target = targets[:, -1]\n#         loss = F.mse_loss(output, target)\n        loss = F.l1_loss(output, target)\n#         loss = F.smooth_l1_loss(output, target)\n        loss.backward()\n        optimizer.step()\n        \n        print('\\r', 'Train Epoch: {} [{}\/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n            epoch, batch_idx * len(data), len(train_loader.dataset),\n            100. * batch_idx \/ len(train_loader), loss.data.item()), end='\\t')\n\n\ndef test():\n    \n    model.eval()\n    test_loss = 0\n    correct = 0\n    \n    g_thuths = []\n    preds = []\n    for data, targets, frame_nos ,STRREDs,VMAFs,SSIMs,playout_bitrates,PSNRs,MSSIMs,is_rebuffered_bools,intervals,indexs in validation_loader:\n        data, targets, frame_nos,STRREDs,VMAFs,SSIMs,playout_bitrates,PSNRs,MSSIMs,is_rebuffered_bools,intervals,indexs = data.float(),targets.float(),frame_nos.float(),STRREDs.float(),VMAFs.float(),SSIMs.float(),playout_bitrates.float(),PSNRs.float(),MSSIMs.float(),is_rebuffered_bools.float(),intervals.float(),indexs\n        target = targets[:, -1]\n#         data = np.expand_dims(data, axis=1)\n        frame_nos = np.expand_dims(frame_nos, axis=2)\n        STRREDs,VMAFs,SSIMs,playout_bitrates,PSNRs,MSSIMs,is_rebuffered_bools,intervals = ed(STRREDs),ed(VMAFs),ed(SSIMs),ed(playout_bitrates),ed(PSNRs),ed(MSSIMs),ed(is_rebuffered_bools),ed(intervals)\n        data = torch.FloatTensor(data)\n        frame_nos = torch.FloatTensor(frame_nos)\n        STRREDs,VMAFs,SSIMs,playout_bitrates,PSNRs,MSSIMs,is_rebuffered_bools,intervals = ft(STRREDs),ft(VMAFs),ft(SSIMs),ft(playout_bitrates),ft(PSNRs),ft(MSSIMs),ft(is_rebuffered_bools),ft(intervals)\n\n#         print(target.size)\n        \n        if args.cuda:\n            data, target, frame_nos = data.cuda(), target.cuda(),  frame_nos.cuda()\n            STRREDs,VMAFs,SSIMs,playout_bitrates,PSNRs,MSSIMs,is_rebuffered_bools,intervals = cu(STRREDs),cu(VMAFs),cu(SSIMs),cu(playout_bitrates),cu(PSNRs),cu(MSSIMs),cu(is_rebuffered_bools),cu(intervals)\n\n\n        data, target, frame_nos = Variable(data), Variable(target), Variable(frame_nos)\n        STRREDs,VMAFs,SSIMs,playout_bitrates,PSNRs,MSSIMs,is_rebuffered_bools,intervals = Variable(STRREDs),Variable(VMAFs),Variable(SSIMs),Variable(playout_bitrates),Variable(PSNRs),Variable(MSSIMs),Variable(is_rebuffered_bools),Variable(intervals)\n\n        output = model(data, frame_nos,STRREDs,VMAFs,SSIMs,playout_bitrates,PSNRs,MSSIMs,is_rebuffered_bools,intervals)\n#         test_loss += F.mse_loss(output, target, size_average=False).data.item()\n        test_loss += F.l1_loss(output, target, size_average=False).data.item()\n#         test_loss += F.smooth_l1_loss(output, target, size_average=False).data.item()\n        pred = output\n\n        g_thuths += list(target.cpu())\n        preds += list(pred.detach().cpu().numpy().reshape(1, -1)[0])\n    \n    test_loss \/= len(validation_loader.dataset)\n    print(\n        '\\nTest set: Average loss: {:.4f})\\n'.format(\n            test_loss))\n    \n    return np.array(g_thuths), np.array(preds)","c8ce76b8":"for epoch in tqdm(range(1, 3 + 1)):\n    from scipy import stats;\n    train(epoch)\n    target, pred = test()\n    srocc1 = -2.0\n    factor = 1\n    for i in range(1, 40):\n        new_pred = pred * i\n        if stats.spearmanr(target,new_pred)[0] + stats.pearsonr(target,new_pred)[0] > srocc1:\n            srocc1 = stats.spearmanr(target,new_pred)[0] + stats.pearsonr(target,new_pred)[0]\n            factor = i\n    pred *= factor\n    \n    srocc = stats.spearmanr(target,pred)[0]\n    plcc = stats.pearsonr(target,pred)[0]\n    mse = mean_squared_error(target,pred, squared=False)\n    print(\"epoch : \", epoch, \"factor : \", factor, \"srocc : \", srocc, \"plcc : \", plcc, \"mse : \", mse)\n    fig = plt.figure()\n    fig.suptitle(epoch)\n    plt.plot(pred, 'r')\n    plt.plot(target, 'g')\n    display(fig)\n\n    \nfor epoch in tqdm(range(1, 5 + 1)):\n    from scipy import stats;\n    train(epoch)\n    target, pred = test()\n    srocc1 = -2.0\n    factor = 1\n    for i in range(1, 40):\n        new_pred = pred * i\n        if stats.spearmanr(target,new_pred)[0] + stats.pearsonr(target,new_pred)[0] > srocc1:\n            srocc1 = stats.spearmanr(target,new_pred)[0] + stats.pearsonr(target,new_pred)[0]\n            factor = i\n    pred *= factor\n    \n    srocc = stats.spearmanr(target,pred)[0]\n    plcc = stats.pearsonr(target,pred)[0]\n    mse = mean_squared_error(target,pred, squared=False)\n    print(\"epoch : \", epoch, \"factor : \", factor, \"srocc : \", srocc, \"plcc : \", plcc, \"mse : \", mse)\n    fig = plt.figure()\n    fig.suptitle(epoch)\n    plt.plot(pred, 'r')\n    plt.plot(target, 'g')\n    display(fig)\n    \nfor epoch in tqdm(range(1, 5 + 1)):\n    from scipy import stats;\n    train(epoch)\n    target, pred = test()\n    srocc1 = -2.0\n    factor = 1\n    for i in range(1, 40):\n        new_pred = pred * i\n        if stats.spearmanr(target,new_pred)[0] + stats.pearsonr(target,new_pred)[0] > srocc1:\n            srocc1 = stats.spearmanr(target,new_pred)[0] + stats.pearsonr(target,new_pred)[0]\n            factor = i\n    pred *= factor\n    \n    srocc = stats.spearmanr(target,pred)[0]\n    plcc = stats.pearsonr(target,pred)[0]\n    mse = mean_squared_error(target,pred, squared=False)\n    print(\"epoch : \", epoch, \"factor : \", factor, \"srocc : \", srocc, \"plcc : \", plcc, \"mse : \", mse)\n    fig = plt.figure()\n    fig.suptitle(epoch)\n    plt.plot(pred, 'r')\n    plt.plot(target, 'g')\n    display(fig)\n    ","fe451f45":"target, pred = test()","6557e241":"pred","e4a6f762":"prediction_dataset = {}","49f5a60f":"for epoch in tqdm(range(1, args.epochs + 1)):\n    from scipy import stats;\n    train(epoch)\n    target, pred = test()\n    prediction_dataset[epoch] = pd.DataFrame({\"target\" : target, \"preds\" : pred})\n    srocc1 = -2.0\n    factor = 1\n    for i in range(1, 40):\n        new_pred = pred * i\n        if stats.spearmanr(target,new_pred)[0] + stats.pearsonr(target,new_pred)[0] > srocc1:\n            srocc1 = stats.spearmanr(target,new_pred)[0] + stats.pearsonr(target,new_pred)[0]\n            factor = i\n    pred *= factor\n    \n    srocc = stats.spearmanr(target,pred)[0]\n    plcc = stats.pearsonr(target,pred)[0]\n    mse = mean_squared_error(target,pred, squared=False)\n    print(\"epoch : \", epoch, \"factor : \", factor, \"srocc : \", srocc, \"plcc : \", plcc, \"mse : \", mse)\n    fig = plt.figure()\n    fig.suptitle(epoch)\n    plt.plot(pred, 'r')\n    plt.plot(target, 'g')\n    display(fig)\n    ","b82b4e4b":"import pickle \n\ngeeky_file = open('geekyfile', 'wb') \npickle.dump(prediction_dataset, geeky_file) \ngeeky_file.close() \n","fb77ee9e":"pred = np.array(pred)[:37]\npred.shape","3665aa75":"len(target)","72bdb68b":"    pred = np.array(pred)*5\n    from scipy import stats;\n    srocc = stats.spearmanr(target,pred)[0]\n    plcc = stats.pearsonr(target,pred)[0]\n    mse = mean_squared_error(target,pred, squared=False)\n    print(\"epoch : \", epoch, \"srocc : \", srocc, \"plcc : \", plcc, \"mse : \", mse)\n    fig = plt.figure()\n    fig.suptitle(epoch)\n    plt.plot(pred, 'r')\n    plt.plot(target, 'g')\n    display(fig)","c18d59fd":"for file in os.listdir('Y\/'):\n    os.remove('Y\/'+file)","9ebe0f5e":"torch.save(model.state_dict(), 'model')","a26059cd":"from IPython.display import FileLinks\nFileLinks('.')","bd4f1ac9":"# CNN with LSTM","e220ce5e":"# Model Build"}}