{"cell_type":{"f36a5022":"code","410411d4":"code","c625006e":"code","728a6994":"code","e9ca1dc9":"code","a1a3597f":"code","3e69d9af":"code","abda2733":"code","c4d72dc1":"code","d240b9a3":"code","64cae1e6":"code","a4c86b57":"code","040c8e78":"code","f3824adb":"code","28336087":"code","cd314e02":"code","3cf4228d":"code","79fc5aa9":"code","db52b078":"markdown","d10bf034":"markdown","f33d2b35":"markdown","d577a484":"markdown","16e032ba":"markdown","b002e8f6":"markdown","beb61586":"markdown","e2166e7f":"markdown","486e7ed3":"markdown","369ceebc":"markdown","2198b999":"markdown"},"source":{"f36a5022":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import mean_squared_log_error\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","410411d4":"train = pd.read_csv('..\/input\/bike-sharing-demand\/train.csv')\ntest = pd.read_csv('..\/input\/bike-sharing-demand\/test.csv')\ntest_def=test.copy()\ntrain.head()","c625006e":"train['year'] = [t.year for t in pd.DatetimeIndex(train.datetime)]\ntrain['month'] = [t.month for t in pd.DatetimeIndex(train.datetime)]\ntrain['day'] = [t.day for t in pd.DatetimeIndex(train.datetime)]\ntrain['hour'] = [t.hour for t in pd.DatetimeIndex(train.datetime)]\n\ntest['year'] = [t.year for t in pd.DatetimeIndex(test.datetime)]\ntest['month'] = [t.month for t in pd.DatetimeIndex(test.datetime)]\ntest['day'] = [t.day for t in pd.DatetimeIndex(test.datetime)]\ntest['hour'] = [t.hour for t in pd.DatetimeIndex(test.datetime)]\ntrain.head()","728a6994":"train.drop('datetime',axis=1,inplace=True)\ntest.drop('datetime',axis=1,inplace=True)\ntrain.head()","e9ca1dc9":"sns.set(rc={'figure.figsize':(11.7,8.27)})\nfig, ax = plt.subplots(2,2)\nsns.barplot(train['season'],train['count'],ax=ax[0,0]);\nsns.barplot(train['holiday'],train['count'],ax=ax[0,1]);\nsns.barplot(train['workingday'],train['count'],ax=ax[1,0]);\nsns.barplot(train['weather'],train['count'],ax=ax[1,1]);","a1a3597f":"sns.set(rc={'figure.figsize':(11.7,8.27)})\nfig, ax = plt.subplots(2,2)\nsns.distplot(train['temp'],ax=ax[0,0]);\nsns.distplot(train['atemp'],ax=ax[0,1]);\nsns.distplot(train['humidity'],ax=ax[1,0]);\nsns.distplot(train['windspeed'],ax=ax[1,1]);","3e69d9af":"sns.set(rc={'figure.figsize':(15,10)})\nsns.heatmap(train.corr(),annot=True,linewidths=0.5);","abda2733":"train.drop(['casual','registered'],axis=1,inplace=True)","c4d72dc1":"sns.set(rc={'figure.figsize':(20,5)})\nsns.barplot(x=train['month'],y=train['count']);","d240b9a3":"season = pd.get_dummies(train['season'],prefix='season')\ntrain = pd.concat([train,season],axis=1)\ntrain.drop('season',axis=1,inplace=True)\ntrain.head()","64cae1e6":"weather = pd.get_dummies(train['weather'],prefix='weather')\n\ntrain = pd.concat([train,weather],axis=1)\n\ntrain.drop('weather',axis=1,inplace=True)\ntrain.head()","a4c86b57":"train.columns.to_series().groupby(train.dtypes).groups","040c8e78":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()","f3824adb":"X = train.drop('count',axis=1)\ny = train['count']\nX = sc.fit_transform(X)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n# print(y_test)\n# print(len(y_test))","28336087":"# from sklearn.ensemble import RandomForestRegressor\n# rf = RandomForestRegressor()\n# model_rf = rf.fit(X_train,y_train)\n# # print(y_train)\n# # print(len(y_train))\n# y_pred_rf = model_rf.predict(X_test)\n# np.sqrt(mean_squared_log_error(y_test,y_pred_rf))\n# # print(y_pred_rf)\n# # print(len(y_pred_rf))\n# # print(X_test)\n# # print(len(X_test))\n# # output = pd.read_csv('..\/input\/bike-sharing-demand\/sampleSubmission.csv', header = 0, sep = ',')\n# # datetimecol = output['datetime']\n# # # print(datetimecol)\n# # submission = pd.DataFrame({\n# #         \"datetime\": datetimecol,\n# #         \"count\": [max(0, x) for x in np.exp(y_pred_rf)]\n# #     })\n# # print(submission)\n# # submission.to_csv('..\/output\/sampleSubmissionRandomForest.csv', index=False)\n","cd314e02":"from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestRegressor,BaggingRegressor,GradientBoostingRegressor,AdaBoostRegressor\nfrom sklearn.model_selection import GridSearchCV\nno_of_test=[500]\nparams_dict={'n_estimators':no_of_test,'n_jobs':[-1],'max_features':[\"auto\",'sqrt','log2']}\nrf=GridSearchCV(estimator=RandomForestRegressor(),param_grid=params_dict,scoring='neg_mean_squared_log_error')\nrf.fit(X_train,y_train)\nprint(X_test)\npred = rf.predict(X_test)\nprint(len(pred))\nprint((np.sqrt(mean_squared_log_error(pred,y_test))))","3cf4228d":"rf.best_params_","79fc5aa9":"# print(test_def)\n# test_df = test.drop('datetime',axis=1)\nprint(test)\npred=rf.predict(test)\nd={'datetime':test_def['datetime'],'count':pred}\nans=pd.DataFrame(d)\nans.to_csv('sampleSubmissionRandomForest.csv',index=False)","db52b078":"\u0422\u0435\u043f\u0435\u0440\u044c \u043f\u043e\u043c\u0435\u043d\u044f\u0435\u043c \u043a\u043e\u043b\u043e\u043d\u043a\u0443 \u0441\u0435\u0437\u043e\u043d\u044b. \u0422\u0430\u043a \u043a\u0430\u043a \u0441\u0435\u0437\u043e\u043d\u043e\u0432 \u0432\u0441\u0435\u0433\u043e 4, \u0441\u043e\u0437\u0434\u0430\u0435\u043c \u0447\u0435\u0442\u044b\u0440\u0435 \u0441\u0442\u043e\u043b\u0431\u0446\u0430(season_1 - \u0432\u0435\u0441\u043d\u0430, season_2 - \u043b\u0435\u0442\u043e, season_3 - \u043e\u0441\u0435\u043d\u044c, season_4 - \u0437\u0438\u043c\u0430).","d10bf034":"\u0442\u0435\u043f\u0435\u0440\u044c \u043c\u044b \u043c\u043e\u0436\u0435\u043c \u0443\u043f\u0443\u0441\u0442\u0438\u0442\u044c \u043a\u043e\u043b\u043e\u043d\u043a\u0443 datetime","f33d2b35":"\u0422\u0430\u043a\u0436\u0435 \u043c\u0435\u043d\u044f\u0435\u043c \u0441\u0442\u043e\u043b\u0431\u0435\u0446 \u043f\u043e\u0433\u043e\u0434\u044b.\n1: Clear, Few clouds, Partly cloudy, Partly cloudy\n2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog ","d577a484":"\u041e\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u043c \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u044b \u0434\u043b\u044f \u0438\u0437\u0443\u0447\u0435\u043d\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445. \u041e\u0441\u0442\u0430\u043b\u044c\u043d\u044b\u0435 \u0443\u043f\u0443\u0441\u043a\u0430\u0435\u043c","16e032ba":"\u0412\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435","b002e8f6":"\u0423 \u043d\u0430\u0441 \u0435\u0441\u0442\u044c \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440 datetime, \u0440\u0430\u0437\u0434\u0435\u043b\u0438\u043c \u0435\u0433\u043e \u043d\u0430 \u043c\u0435\u0441\u044f\u0446, \u0447\u0430\u0441, \u0447\u0438\u0441\u043b\u043e, \u0434\u0435\u043d\u044c \u043d\u0435\u0434\u0435\u043b\u0438.","beb61586":"\u041f\u0440\u0438\u0432\u0435\u0434\u0435\u043d\u043d\u044b\u0439 \u0432\u044b\u0448\u0435 \u0433\u0440\u0430\u0444\u0438\u043a \u043e\u0431\u044a\u044f\u043d\u044f\u0435\u0442 \u0441\u043f\u0440\u043e\u0441 \u043d\u0430 \u0432\u0435\u043b\u043e\u0441\u0438\u043f\u0435\u0434 \u0432 \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u0438 \u043e\u0442 \u043c\u0435\u0441\u044f\u0446\u0430.","e2166e7f":"\u0413\u0440\u0430\u0444\u0438\u043a\u0438, \u0440\u0430\u0441\u043f\u043e\u043b\u043e\u0436\u0435\u043d\u043d\u044b\u0435 \u0432\u044b\u0448\u0435, \u043f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u044e\u0442 \u043d\u0430\u043c \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440 count \u0437\u0430\u0432\u0438\u0441\u0438\u0442 \u043e\u0442 \u0440\u0430\u0431\u043e\u0447\u0438\u0445 \u0434\u043d\u0435\u0439, \u043f\u043e\u0433\u043e\u0434\u044b,\u0441\u0435\u0437\u043e\u043d\u0430 \u0438 \u043f\u0440\u0430\u0437\u0434\u043d\u0438\u043a\u043e\u0432.","486e7ed3":"\u042d\u0442\u043e \u0433\u0440\u0430\u0444\u0438\u043a\u0438 \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u044f \u0432\u043b\u0430\u0436\u043d\u043e\u0441\u0442\u0438, \u0441\u043a\u043e\u0440\u043e\u0441\u0442\u0438 \u0432\u0435\u0442\u0440\u0430, \u0442\u0435\u043c\u043f\u0435\u0440\u0430\u0442\u0443\u0440\u044b.","369ceebc":"\u0418\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c Random Forest","2198b999":"\u0420\u0430\u0437\u0434\u0435\u043b\u044f\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0435 \u0438 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u044b\u0435 "}}