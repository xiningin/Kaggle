{"cell_type":{"23723791":"code","ed2c4c2c":"code","22ce9f81":"code","a58f3d86":"code","22a7013a":"code","f5b9b34f":"code","14c9472f":"code","192fd134":"code","b1fa409b":"code","9279b35d":"code","d98439a7":"code","85d83291":"code","97882bcd":"code","a01952d7":"code","fe1a0c1a":"code","f66a84ae":"code","57c65a1e":"code","45233023":"code","515fd53b":"code","49f1eb35":"code","741d891d":"code","d30235d8":"code","c330c154":"code","86c9f4b2":"code","e8c336a6":"code","76e60ac5":"code","ceee02c6":"code","f359edcb":"code","f3ad325b":"code","0a67c3e0":"code","ce455342":"code","16a400bc":"code","3c295804":"code","efa1b2eb":"code","fc857cb3":"code","6841e550":"code","774f5d70":"markdown","28fe50bc":"markdown","458105d3":"markdown","7bd16c24":"markdown","3aedefda":"markdown","75d1cd8a":"markdown","acca6e23":"markdown"},"source":{"23723791":"# Importing the libraries\nimport numpy as np  \nimport matplotlib.pyplot as plt  \nimport pandas as pd  \nfrom sklearn.preprocessing import LabelEncoder, StandardScaler","ed2c4c2c":"# Importing the dataset\nX = pd.read_csv('..\/input\/X_train.csv')\nX_test=pd.read_csv('..\/input\/X_test.csv')\ntarget=pd.read_csv('..\/input\/y_train.csv')\ny=pd.read_csv('..\/input\/sample_submission.csv')\ntarget['surface'].head()","22ce9f81":"# Get a list of unique surface types\nsurfaces_list=target['surface'].unique()","a58f3d86":"seriesID_list=X['series_id'].unique()","22a7013a":"# Define a list of column names to store fft data\nfft_names_list=['offt_X','offt_Y','offt_Z','offt_W','afft_X','afft_Y','afft_Z','lfft_X','lfft_Y','lfft_Z']\n# Prefix offt, afft, and lfft are assgined as the names for fft data of orientation, angular_velocity, and linear_acceleration, respectively","f5b9b34f":"# Scaling train and test sets\npre_scaler = StandardScaler()\nX_prescaled     = pd.DataFrame(pre_scaler.fit_transform(X.loc[:,X.columns[3:]]),columns=X.columns[3:])\nX_test_prescaled= pd.DataFrame(pre_scaler.transform(X_test.loc[:,X_test.columns[3:]]),columns=X_test.columns[3:])","14c9472f":"X_prescaled     =X[X.columns[0:3]].merge(X_prescaled,left_index=True,right_index=True)\nX_test_prescaled=X_test[X_test.columns[0:3]].merge(X_test_prescaled,left_index=True,right_index=True)\nX_test_prescaled.head()","192fd134":"def fft_calculate(X):\n# Calculate FFT data for each series (Each series consists of 128 units of time)\n# Each series has 10 parameters (orientation_X,...,angular_velocity_X,....,linear_acceleration_X,...)\n# Each of the parameters will be fourier transformed using numpy fft function\n    fft_data={}\n    fft_names_list=['offt_X','offt_Y','offt_Z','offt_W','afft_X','afft_Y','afft_Z','lfft_X','lfft_Y','lfft_Z']\n    for seriesID in range(round(len(X)\/128)):\n        fft_data[seriesID]={}\n        i=-1\n        for col in X.columns[3:]:   #stepping through each parameter columns\n            c=np.fft.rfft(X[X['series_id']==seriesID][col])  # Calculate real fft\n            x=np.real(np.abs(c))  # Calculate the amplitude of fft\n            i+=1\n            fft_name=fft_names_list[i]  # Assign names for fft data (orientation_X-->offt_X, etc.)\n            fft_data[seriesID][fft_name]=x\n    return fft_data","b1fa409b":"# Calculate FFT data for train and test sets\n\nfft_data=fft_calculate(X_prescaled)\nfft_test_data=fft_calculate(X_test_prescaled)","9279b35d":"# Group series_id's into their respective surface types\nseriesID_group={}\nfor floor_type in surfaces_list:\n    seriesID_group[floor_type]=target[target['surface']==floor_type].series_id","d98439a7":"#Calculate fft average for each parameter_X,Y,Z for each surface.  \n#These average values are for viewing only, not used for training.\nfft_average={}\nfor floor_type in surfaces_list:\n    count=len(seriesID_group[floor_type])\n    fft_average[floor_type]={}\n    cumsum={}\n    for fft in fft_names_list:\n        cumsum[fft]=np.zeros(65)\n        for seriesID in seriesID_group[floor_type]:\n            cumsum[fft]+=fft_data[seriesID][fft]\n        fft_average[floor_type][fft]=np.zeros(65)\n        fft_average[floor_type][fft]=cumsum[fft]\/count                ","85d83291":"# Preview of fft spectra\nplt.figure(figsize=(26, 26))\ni=0\nfor fft in fft_names_list:\n    i+=1\n    if i==8:\n        i+=1\n    plt.subplot(3,4,i)\n    if fft in ['offt_X','offt_Y','offt_Z','offt_W']:\n        plt.ylim(0,0.4)\n    plt.title(fft, fontsize=20)\n#    plt.yscale('log')\n    for floor_type in surfaces_list:\n        plt.plot(fft_average[floor_type][fft][:])\n    plt.legend(surfaces_list)","97882bcd":"len(fft_data)","a01952d7":"def fft_stats(fft_data):\n# Calculate the mean, sum, and standard deviation of spectra \n    df_fft=pd.DataFrame()\n    for fft in fft_names_list:\n            sum_=fft+'_sum'\n            mean=fft+'_mean'\n            std=fft+'_std'\n            for seriesID in range(len(fft_data)):\n                    df_fft.loc[seriesID,sum_]=np.sum(fft_data[seriesID][fft])\n                    df_fft.loc[seriesID,mean]=np.mean(fft_data[seriesID][fft])\n                    df_fft.loc[seriesID,std]=np.std(fft_data[seriesID][fft])\n    return df_fft","fe1a0c1a":"df_fft=fft_stats(fft_data)\ndf_fft_test=fft_stats(fft_test_data)","f66a84ae":"# Make a copy of fft dataframe\ndf=df_fft.copy()\ndf=df.reset_index(drop=True)\ndf_test=df_fft_test.copy()\ndf_test=df_test.reset_index(drop=True)","57c65a1e":"df=target.merge(df,left_index=True,right_index=True)\ndf.head()","45233023":"le = LabelEncoder()\ndf['surface'] = le.fit_transform(df['surface'])","515fd53b":"#Split train and test sets\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(df.drop(['surface','group_id','series_id'],axis=1), df['surface'], test_size = 0.2, random_state = 10)","49f1eb35":"# List of features\nX_train.columns","741d891d":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nclf=RandomForestClassifier(n_estimators=200,n_jobs=-1,random_state=0)","d30235d8":"scaler = StandardScaler()\nX_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\nX_val_scaled = pd.DataFrame(scaler.transform(X_val),columns=X_val.columns)\nX_test_scaled = pd.DataFrame(scaler.transform(df_test),columns=df_test.columns)","c330c154":"clf.fit(X_train_scaled, y_train)","86c9f4b2":"y_val_predict = clf.predict(X_val_scaled)\ny_test_pred = clf.predict(X_test_scaled)","e8c336a6":"#Result from including full set\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nprint(round(accuracy_score(y_val, y_val_predict),3))","76e60ac5":"feature_importances = pd.DataFrame(clf.feature_importances_,\n                                   index = X_train_scaled.columns,\n                                    columns=['importance']).sort_values('importance',ascending=False)","ceee02c6":"features = X_train_scaled.columns.values\nimportances = clf.feature_importances_\nindices = np.argsort(importances)\nplt.figure(figsize=(15, 10))\nplt.title('Feature Importances', fontsize=24)\nplt.barh(range(len(indices)), importances[indices], color='r', align='center')\nplt.yticks(range(len(indices)), features[indices], fontsize=18)\nplt.xlabel('Importance', fontsize=18)\nplt.show()","f359edcb":"confusion_matrix(y_val,y_val_predict)","f3ad325b":"X_train=df.drop(['surface','group_id','series_id'],axis=1)\ny_train=df['surface']","0a67c3e0":"X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train))","ce455342":"from sklearn.model_selection import cross_val_score\nscore=cross_val_score(clf, X_train_scaled, y_train, cv=10, scoring=\"accuracy\")\nprint(np.around(score,3))\nprint('The average score is: ',round(score.mean(),3))","16a400bc":"y_test_pred=le.inverse_transform(y_test_pred)\ny_test_pred[0:10]","3c295804":"y.head()","efa1b2eb":"y['surface']=y_test_pred","fc857cb3":"y.head(10)","6841e550":"y.to_csv('\/sample_submission.csv',index=False)","774f5d70":"# Plotting for data exploration","28fe50bc":"# Run cross validation for 10 folds","458105d3":"# Feature engineering","7bd16c24":"# Create Submission data ","3aedefda":"# Training and predict","75d1cd8a":"# Construct Dataframe for training","acca6e23":"# Introduction\n\nThis analysis will look at frequency spectra of time series of the 10 outputs by the IMU sensors.  Each time series (128 units of time) will be converted into frequency domain using numpy fft functions.  These frequency spectra will be used as features (instead of the time series).\n\nRandom Rain Forest is the only model used to predict. "}}