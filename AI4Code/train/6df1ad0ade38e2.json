{"cell_type":{"d6c04d31":"code","24695d0c":"code","abf02a2f":"code","4b1ff4d3":"code","4099fc89":"code","f1e08347":"code","5e99c31c":"code","4488b840":"code","665f2f89":"code","e48c55dd":"code","eff76869":"code","5d4bfdd8":"code","49f759af":"code","feb49fb3":"code","8c8ff94e":"code","5286f4e2":"code","ab7f5d50":"code","ccc0b581":"code","29354926":"code","97a8b23f":"code","3d29dd3e":"code","74d48914":"code","35fc7e0f":"markdown","58b2d437":"markdown","0782bd4a":"markdown","6b14c440":"markdown","0dfe6687":"markdown","7fa92bf1":"markdown","f721007f":"markdown","a0abfb50":"markdown","374f61be":"markdown","47390527":"markdown","ed69fc24":"markdown","a72d1142":"markdown","0eca5f5e":"markdown","480eadc3":"markdown"},"source":{"d6c04d31":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\n\n#to data preprocessing\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\n\n#NLP tools\nimport re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n#train split and fit models\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\n#model selection\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","24695d0c":"dataset = pd.read_csv('..\/input\/hate-speech-and-offensive-language-dataset\/labeled_data.csv')\ndataset.head()","abf02a2f":"dataset.info()","4b1ff4d3":"dataset.describe().T","4099fc89":"dt_trasformed = dataset[['class', 'tweet']]\ny = dt_trasformed.iloc[:, :-1].values","f1e08347":"ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\ny = np.array(ct.fit_transform(y))","5e99c31c":"print(y)","4488b840":"y_df = pd.DataFrame(y)\ny_hate = np.array(y_df[0])\ny_offensive = np.array(y_df[1])","665f2f89":"print(y_hate)\nprint(y_offensive)","e48c55dd":"corpus = []\nfor i in range(0, 24783):\n  review = re.sub('[^a-zA-Z]', ' ', dt_trasformed['tweet'][i])\n  review = review.lower()\n  review = review.split()\n  ps = PorterStemmer()\n  all_stopwords = stopwords.words('english')\n  all_stopwords.remove('not')\n  review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n  review = ' '.join(review)\n  corpus.append(review)","eff76869":"cv = CountVectorizer(max_features = 2000)\nX = cv.fit_transform(corpus).toarray()","5d4bfdd8":"X_train, X_test, y_train, y_test = train_test_split(X, y_hate, test_size = 0.20, random_state = 0)","49f759af":"classifier_np = GaussianNB()\nclassifier_np.fit(X_train, y_train)","feb49fb3":"classifier_dt = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\nclassifier_dt.fit(X_train, y_train)","8c8ff94e":"classifier_knn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nclassifier_knn.fit(X_train, y_train)","5286f4e2":"classifier_lr = LogisticRegression(random_state = 0)\nclassifier_lr.fit(X_train, y_train)","ab7f5d50":"classifier_rf = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\nclassifier_rf.fit(X_train, y_train)","ccc0b581":"#Naive Bayes\ny_pred_np = classifier_np.predict(X_test)\ncm = confusion_matrix(y_test, y_pred_np)\nprint(cm)\n","29354926":"#Decision Tree\ny_pred_dt = classifier_dt.predict(X_test)\ncm = confusion_matrix(y_test, y_pred_dt)\nprint(cm)\n","97a8b23f":"#Linear Regression\ny_pred_lr = classifier_lr.predict(X_test)\ncm = confusion_matrix(y_test, y_pred_lr)\nprint(cm)\n","3d29dd3e":"#Random Florest\ny_pred_rf = classifier_rf.predict(X_test)\ncm = confusion_matrix(y_test, y_pred_rf)\nprint(cm)","74d48914":"rf_score = accuracy_score(y_test, y_pred_rf)\nlr_score = accuracy_score(y_test, y_pred_lr)\ndt_score = accuracy_score(y_test, y_pred_dt)\nnp_score = accuracy_score(y_test, y_pred_np)\n\nprint('Random Forest Accuracy: ', str(rf_score))\nprint('Linear Regression Accuracy: ', str(lr_score))\nprint('Decision Tree Accuracy: ', str(dt_score))\nprint('Naive Bayes Accuracy: ', str(np_score))","35fc7e0f":"**Random Forest**","58b2d437":"## Splitting the dataset into the Training set and Test set","0782bd4a":"So, Linear Regression looks better to predict hate speech based on this dataset. It's important to emphasize Random Forest and Decision Tree had great results as well. This Dataset looks like a product of artificial intelligence to classify hate speech and offensive terms. What I think way more technological than these models that I implemented here. It was just a study of the implementation of NLP based on the bag of words method. ","6b14c440":"**Logistic Regression**","0dfe6687":"### Encoding the Dependent Variable","7fa92bf1":"I separated this y in two variables that we will use to fit hate speech models and offensive speech models","f721007f":"# Making the Confusion Matrix for each model","a0abfb50":"# Importing the libraries","374f61be":"**Decision Tree**","47390527":"**KNN**","ed69fc24":"**Naive Bayes**","a72d1142":"## Cleaning the texts","0eca5f5e":"# Importing the dataset","480eadc3":"## Finding the best models to predict hate speech"}}