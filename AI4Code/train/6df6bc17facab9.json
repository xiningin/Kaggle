{"cell_type":{"c652b2fd":"code","273b3aff":"code","762366f1":"code","a7b03caa":"code","c10649ea":"code","5e4f15d9":"code","b36c5aa2":"code","fd592354":"code","1d14e48d":"code","9cf10927":"code","54d2eb49":"code","3d0b9173":"code","bb2723c1":"code","30cdc383":"code","c5200104":"code","1489a242":"code","68d43b32":"code","72bb7f54":"code","5443d552":"code","39ee925e":"code","82ad820f":"code","35b667e7":"code","7409a44b":"code","6402d519":"code","9cbad832":"code","c02be963":"code","52390dd4":"code","6afe6fa2":"code","101dd36c":"code","fd023e56":"code","d7bccc9a":"code","8b1a4509":"code","70d24388":"code","306e7de6":"code","a7983bd0":"code","453318a9":"code","1ecb8454":"code","8b7d41e3":"code","f551cb17":"code","e6de38ce":"code","e6b9fc81":"code","1014eb7e":"code","8c6dec32":"code","56feeedb":"code","c8f40dba":"code","7eec4d95":"code","d6703034":"code","79e0245d":"code","7a08763c":"code","2e46c5a6":"code","8414c5c6":"code","16462181":"code","b1732d92":"code","91735e91":"code","aa04cebe":"code","24d241fe":"code","32becc8f":"code","96a28b3c":"code","a96aa7a4":"code","5f5944f6":"code","b6ec63c9":"code","ae922be6":"code","11be9dfe":"code","8f24a536":"code","6e506139":"code","79af21c3":"code","d678f85d":"code","cacb9bac":"code","bf651570":"code","70a49b8d":"code","396f9068":"code","bf814b09":"code","906b7370":"code","76708e57":"code","b6ac6dfb":"markdown","afbb75d6":"markdown","807d67fd":"markdown","df2061e5":"markdown","ddba291a":"markdown","3fcbc1a4":"markdown","16bea504":"markdown","1564055f":"markdown","4661dd43":"markdown","be8bf740":"markdown","f21327f5":"markdown","787de596":"markdown","d7d3b778":"markdown","fab62bfa":"markdown","091a15a0":"markdown","773004e6":"markdown","8262bd27":"markdown","3c36c6b8":"markdown","a839c200":"markdown","c9b61b42":"markdown","d7913f6f":"markdown","7f39c5c9":"markdown","d81b499a":"markdown","7035f53b":"markdown","0a1894a6":"markdown","cb3381a5":"markdown","70f12283":"markdown","601d901a":"markdown","a6b41f20":"markdown","6c50a53b":"markdown","4bb7b690":"markdown","c46922cf":"markdown","405a0134":"markdown","409c9d9e":"markdown","6b2784c6":"markdown","9f4b6d4b":"markdown","3f9bfd4f":"markdown","ff103d1a":"markdown","e075d3fb":"markdown","8afb7012":"markdown","5bfb143c":"markdown","444e0cb5":"markdown","3d5f2ea4":"markdown","745b27a4":"markdown","9b59f2cf":"markdown","b0cbbd14":"markdown","b1098539":"markdown","bdb37642":"markdown"},"source":{"c652b2fd":"import pandas as pd\nimport numpy as np\n\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score","273b3aff":"train=pd.read_csv(\"..\/input\/titanic\/train.csv\" )\ntit1=train.select_dtypes(include=['float64','int64','object'])\ntrain.info()\n\ntest=pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntit2=test.select_dtypes(include=['float64','int64','object'])\ntest.info()","762366f1":"print(\"train shape:\",train.shape)\nprint(\"test shape :\",test.shape)","a7b03caa":"tit1.head()","c10649ea":"tit2.head()","5e4f15d9":"idtrain=train['PassengerId']\nidtest=test['PassengerId']","b36c5aa2":"tit2['survived']=np.nan\ntit2.head()","fd592354":"plt.figure(figsize=(4,4))\nplt.title('SURVIVED',size=20)\ntit1.Survived.value_counts().plot.bar(color=['red','green'])\n\nplt.figure(figsize=(4,4))\nplt.title('SEX',size=20)\ntit1.Sex.value_counts().plot.bar(color=['skyblue','pink'])\n\n","1d14e48d":"total=train['Survived'].sum()\nprint(\"Total Survivors\",total)\npercent=round(np.mean(train['Survived']),3)*100\nprint(\"Percentage of Survivors:\",percent)","9cf10927":"\nmen=train[train['Sex']=='male']\nwomen=train[train['Sex']=='female']\nm=men['Sex'].count()\nw=women['Sex'].count()\nprint(\"male:\",m)\nprint(\"female:\",w)\nprint(\"percentage of women:\",round(w\/(m+w)*100))\nprint(\"percentage of men:\",round(m\/(m+w)*100))","54d2eb49":"train.isnull().sum()","3d0b9173":"train['Cabin'] = train['Cabin'].fillna('X')\ntest['Cabin']=test['Cabin'].fillna('X')","bb2723c1":"train['Age'].hist(bins=40,color='salmon')\nplt.title(\"AGE\",size=20)\n","30cdc383":"plt.figure(figsize=(5,5))\nplt.title(\"CLASS DIVISION\",size=20)\ntit1.Pclass.value_counts().plot.bar(color=['olive','coral','gold'])","c5200104":"train['Fare'].hist(bins = 80, color = 'orange')\nplt.title(\"FARE\",size=20)","1489a242":"plt.figure(figsize=(5,5))\nplt.title(\"Embarked\",size=20)\ntit1.Embarked.value_counts().plot.bar(color=['olive','coral','gold'])","68d43b32":"sns.heatmap(train.corr(), annot = True)","72bb7f54":"\nplt.figure(figsize=(5,5))\nsns.countplot(x = 'Survived', hue = 'Sex', data = train)\nplt.title(\"SURVIVED AND SEX\",size=20)","5443d552":"plt.figure(figsize=(5,5))\nsns.countplot(x = 'Survived', hue = 'Pclass', data = train)\nplt.title(\"SURVIVED AND PCLASS\",size=20)","39ee925e":"plt.figure(figsize=(5,5))\nsns.countplot(x = 'Survived', hue = 'Embarked', data = train)\nplt.title(\"SURVIVED AND EMBARKED\",size=20)","82ad820f":"age_group = train.groupby(\"Pclass\")[\"Age\"]\nprint(age_group.median())","35b667e7":"age_group = train.groupby(\"Embarked\")[\"Age\"]\nprint(age_group.median())","7409a44b":"train.loc[train.Age.isnull(),'Age']=train.groupby(\"Pclass\").Age.transform('median')\ntest.loc[test.Age.isnull(),'Age']=test.groupby(\"Pclass\").Age.transform('median')\nprint(train['Age'].isnull().sum())","6402d519":"test['Cabin'].unique().tolist()","9cbad832":"cab = test.groupby(\"Cabin\")[\"Age\"]\nprint(cab.median())","c02be963":"\ntrain['Cabin'].unique().tolist()","52390dd4":"\nimport re\n\ntest['Cabin'] = test['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\ntest['Cabin'].unique().tolist()\n","6afe6fa2":"category = {'A':1, 'B':2, 'C':3, 'D':4, 'E':5, 'F':6, 'G':7, 'X':8}\ntest['Cabin'] = test['Cabin'].map(category)\ntest['Cabin'].unique().tolist()","101dd36c":"cab = train.groupby(\"Cabin\")[\"Age\"]\nprint(cab.median())","fd023e56":"\n\ntrain['Cabin'] = train['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\ntrain['Cabin'].unique().tolist()","d7bccc9a":"category = {'A':1, 'B':2, 'C':3, 'D':4, 'E':5, 'F':6, 'G':7, 'X':8, 'T':9}\ntrain['Cabin'] = train['Cabin'].map(category)\ntrain['Cabin'].unique().tolist()","8b1a4509":"print(train.isnull().sum())","70d24388":"from statistics import mode\ntrain[\"Embarked\"] = train[\"Embarked\"].fillna(mode(train[\"Embarked\"]))","306e7de6":"print(train.isnull().sum())","a7983bd0":"train[\"Sex\"][train[\"Sex\"] == \"male\"] = 0\ntrain[\"Sex\"][train[\"Sex\"] == \"female\"] = 1\n\ntest[\"Sex\"][test[\"Sex\"] == \"male\"] = 0\ntest[\"Sex\"][test[\"Sex\"] == \"female\"] = 1\n\ntrain[\"Embarked\"][train[\"Embarked\"] == \"S\"] = 0\ntrain[\"Embarked\"][train[\"Embarked\"] == \"C\"] = 1\ntrain[\"Embarked\"][train[\"Embarked\"] == \"Q\"] = 2\n\ntest[\"Embarked\"][test[\"Embarked\"] == \"S\"] = 0\ntest[\"Embarked\"][test[\"Embarked\"] == \"C\"] = 1\ntest[\"Embarked\"][test[\"Embarked\"] == \"Q\"] = 2\n","453318a9":"train['fam']=train['SibSp']+train['Parch']+1\ntest['fam']=test['SibSp']+test['Parch']+1","1ecb8454":"train['fam'].unique().tolist()","8b7d41e3":"train['Band'] = pd.cut(train['Age'], 5)\ntrain[['Band', 'Survived']].groupby(['Band'], as_index=False).mean().sort_values(by='Band', ascending=True)","f551cb17":"range=[]\nfor i in train.Age:\n    if i<= 16:\n        range.append(0)\n    elif i>16 and i<=32:\n        range.append(1)\n    elif i>32 and i<=48:\n        range.append(2)\n    elif i>48 and i<=64: \n        range.append(3)\n    elif i>64 and i<=80:\n        range.append(4)\n    \n    \ntrain['range']=range    ","e6de38ce":"range=[]\nfor i in test.Age:\n    if i<= 16:\n        range.append(0)\n    elif i>16 and i<=32:\n        range.append(1)\n    elif i>32 and i<=48:\n        range.append(2)\n    elif i>48 and i<=64: \n        range.append(3)\n    elif i>64 and i<=80:\n        range.append(4)\n    else:\n        range.append(5)\n    \ntest['range']=range  ","e6b9fc81":"solo=[]\nfor i in train.fam:\n    \n    if (i==1):  \n        solo.append(1)\n    else:\n        solo.append(0)\ntrain['solo'] =solo  ","1014eb7e":"solo=[]\nfor i in test.fam:\n    \n    if (i==1):  \n        solo.append(1)\n    else:\n        solo.append(0)\ntest['solo'] =solo  ","8c6dec32":"train['Fare'].fillna(train['Fare'].dropna().median(), inplace=True)\ntest['Fare'].fillna(test['Fare'].dropna().median(), inplace=True)\n","56feeedb":"train['newfare']=pd.qcut(train['Fare'],4)\ntrain[['newfare','Survived']].groupby(['newfare'],as_index=False).mean().sort_values(by='newfare', ascending=True)","c8f40dba":"farerange=[]\nfor i in train.Fare:\n    if i<= 8:\n        farerange.append(0)\n    elif i>8 and i<=14:\n        farerange.append(1)\n    elif i>14 and i<=31:\n        farerange.append(2)\n    elif i>31 and i<=513:\n        farerange.append(3)\n \n    \ntrain['farerange']=farerange  ","7eec4d95":"farerange=[]\nfor i in test.Fare:\n    if i<= 8:\n        farerange.append(0)\n    elif i>8 and i<=14:\n        farerange.append(1)\n    elif i>14 and i<=31:\n        farerange.append(2)\n    elif i>31 and i<=513:\n        farerange.append(3)\n    \ntest['farerange']=farerange  ","d6703034":"train['Title'] = train['Name'].map(lambda x: re.compile(\"([A-Za-z]+)\\.\").search(x).group())\ntest['Title'] = test['Name'].map(lambda x: re.compile(\"([A-Za-z]+)\\.\").search(x).group())\nprint(train['Title'].unique())\n    ","79e0245d":"print(test['Title'].unique())","7a08763c":"\n    train['Title'] = train['Title'].replace(['Lady.', 'Capt.', 'Col.',\n    'Don.', 'Dr.', 'Major.', 'Rev.', 'Jonkheer.', 'Dona.'], 'Rare.')\n    \n    train['Title'] = train['Title'].replace(['Countess.', 'Lady.', 'Sir.'], 'Royal.')\n    train['Title'] = train['Title'].replace('Mlle.', 'Miss.')\n    train['Title'] = train['Title'].replace('Ms.', 'Miss.')\n    train['Title'] = train['Title'].replace('Mme.', 'Mrs.')\n\ntrain[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","2e46c5a6":"\n    test['Title'] = test['Title'].replace(['Lady.', 'Capt.', 'Col.',\n    'Don.', 'Dr.', 'Major.', 'Rev.', 'Jonkheer.', 'Dona.'], 'Rare.')\n    \n    test['Title'] = test['Title'].replace(['Countess.', 'Lady.', 'Sir.'], 'Royal.')\n    test['Title'] = test['Title'].replace('Mlle.', 'Miss.')\n    test['Title'] = test['Title'].replace('Ms.', 'Miss.')\n    test['Title'] = test['Title'].replace('Mme.', 'Mrs.')\n\n","8414c5c6":"    title_mapping = {\"Mr.\": 1, \"Miss.\": 2, \"Mrs.\": 3, \"Master.\": 4, \"Royal.\": 5, \"Rare.\": 6}\n\n    train['Title'] = train['Title'].map(title_mapping)\n    train['Title'] = train['Title'].fillna(0)\n\n    train.head()","16462181":"    title_mapping = {\"Mr.\": 1, \"Miss.\": 2, \"Mrs.\": 3, \"Master.\": 4, \"Royal.\": 5, \"Rare.\": 6}\n\n    test['Title'] = test['Title'].map(title_mapping)\n    test['Title'] = test['Title'].fillna(0)\n\n   ","b1732d92":"print(train['Age'])","91735e91":"print(train['Cabin'])","aa04cebe":"print(train['Sex'])","24d241fe":"print(train['Embarked'])","32becc8f":"print(train['fam'])","96a28b3c":"train.select_dtypes(include=['object']).columns","a96aa7a4":"from sklearn.preprocessing import LabelEncoder\nc=('Name', 'Sex', 'Ticket', 'Embarked')\nfor i in c:\n    l=LabelEncoder()\n    l.fit(list(train[i].values))\n    train[i]=l.transform(list(train[i].values))\n ","5f5944f6":"c=('Name', 'Sex', 'Ticket', 'Embarked')\nfor i in c:\n    l=LabelEncoder()\n    l.fit(list(test[i].values))\n    test[i]=l.transform(list(test[i].values))\n ","b6ec63c9":"\ntest = test.drop(['Parch','Age','Name','Cabin','PassengerId'], axis = 1)\ntest = test.drop(['Ticket','SibSp','fam','Fare'], axis = 1)\n\n\ntrain = train.drop(['Parch',\"Band\",'Name','Cabin','newfare','PassengerId'], axis = 1)\ntrain = train.drop(['Ticket','SibSp','Age','fam','Fare'], axis = 1)","ae922be6":"from sklearn.model_selection import train_test_split\n\n\nX_train, X_test, y_train, y_test = train_test_split(train.drop(['Survived'], axis=1), \n                                                    train['Survived'], test_size = 0.2, \n                                                    random_state = 0)","11be9dfe":"from sklearn.linear_model import LogisticRegression\nlogisticRegression = LogisticRegression(max_iter = 30000)\nlogisticRegression.fit(X_train, y_train)\n\n\n","8f24a536":"predictions = logisticRegression.predict(X_test)\nacc_LOG = round(accuracy_score(predictions, y_test) * 100, 2)\nprint(acc_LOG)\nprint(predictions)\n\n\n","6e506139":"round(np.mean(predictions), 3)","79af21c3":"from sklearn.metrics import classification_report, confusion_matrix\n\nprint(confusion_matrix(y_test, predictions))","d678f85d":"accuracy=((84+50)\/(84+50+26+19))\nprint('accuracy is: ', (round(accuracy, 2)*100))","cacb9bac":"from sklearn.ensemble import RandomForestClassifier\n\nrandom_forest = RandomForestClassifier(random_state = 1,\n                                  n_estimators = 750,\n                                  max_depth = 15, \n                                  min_samples_split = 5,  min_samples_leaf = 1)\n\nrandom_forest.fit(X_train, y_train)\n\nY_pred = random_forest.predict(X_test)\n\nacc_rnd = round(accuracy_score(Y_pred, y_test) * 100, 2)\nprint(acc_rnd)\n","bf651570":"from sklearn.ensemble import GradientBoostingClassifier\n\ngbk = GradientBoostingClassifier(learning_rate=0.1, n_estimators=60,max_depth=9,max_features='sqrt', subsample=0.8, random_state=10)\ngbk.fit(X_train, y_train)\npred = gbk.predict(X_test)\nacc_gbk = round(accuracy_score(pred, y_test) * 100, 2)\nprint(acc_gbk)","70a49b8d":"from sklearn.tree import DecisionTreeClassifier\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(accuracy_score(Y_pred, y_test) * 100, 2)\nacc_decision_tree","396f9068":"model=pd.DataFrame({'Model':['Logistic Regression','Random Forest','Gradient Boosting','Decision Tree'],'Score':[acc_LOG,acc_rnd,acc_gbk,acc_decision_tree]})\nmodel","bf814b09":"train.head(10)","906b7370":"test.head()","76708e57":"ids = idtest\npredictions =decision_tree.predict(test)\n\n\noutput = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\noutput.to_csv('submission.csv', index=False)","b6ac6dfb":"**Lets work out with the Cabin numbers**","afbb75d6":"**We should know the size of the data we are working with.**","807d67fd":"![image.png](attachment:image.png)\n","df2061e5":"# **GRADIENT BOOSTING**","ddba291a":"**Now we are assigning values to the initials that we had found in the above step and replace them with integers by mapping them.\nSame step will be repeated for train and test data**","3fcbc1a4":"**Removing NAN values from fare and further converting them into different ranges**","16bea504":"**SUBMISSION FILE**","1564055f":"\n**Lets play a little with Age as well**","4661dd43":"# **CLEANING DATA**","be8bf740":"**So now we have filled the NAN values of embarked too.Lets check the null values again!**","f21327f5":"![](https:\/\/i.pinimg.com\/originals\/af\/bf\/af\/afbfafac1e700ed3ed9b4a4157a7fa98.jpg)\n","787de596":"**Lets try using Random Forest.A Random Forest is an ensemble technique capable of performing both regression and classification tasks with the use of multiple decision trees and a technique called Bootstrap Aggregation, commonly known as bagging. The basic idea behind this is to combine multiple decision trees in determining the final output rather than relying on individual decision trees.**","d7d3b778":"**Mapping new numerical values onto Titles**","fab62bfa":"**Lets create a new column of fam using SibSp which means number of Siblings or Spouse and Parch which means number of Parents or Children,later we will be dropping SibSp and Parch from our data set since these values are alreday being used in Fam**","091a15a0":"**Lets check whether the conversion has worked or not**","773004e6":"**Since we have explored all the features in our dataset,now we shall draw close comparisons with \"SURVIVED\" feature,to help us draw some inference.**","8262bd27":"# **EXPLORING FEATURES**","3c36c6b8":"**Lets find out the Survival Rate**","a839c200":"**First we start by checking the counts of survived(1) and dead(0).\nthus from the below graoh it is clear that there were more deaths than the ratio of survivors.\nWe also plot of graph for the division of genders, to see the ratio between men and women.\nwhen the graph i splotted we see that the range of women seem more equivalent to the range of survivors and the range of deaths seem more closely related to the range of men.\nSo thus that mean that there were more women who survuived?\nWe shall se that further.**","c9b61b42":"**Making and Printing our predictions**","d7913f6f":"**Searching for the titles and extracting them from the names in the given data**","7f39c5c9":"# **RANDOM FOREST**","d81b499a":"**Now we have no missing values for AGE**","7035f53b":"**Mean survival rate according to the Titles assigned**","0a1894a6":"**The Data that we are dropping from the dataset**","cb3381a5":"**Lets find out the percentage of Women and Men**","70f12283":"**Lets play around with Name as well!**","601d901a":"**Replacing to make the categories narrower and accurate**","a6b41f20":"**Lets take help of confusion matrix to find out TP TN FP FN.A confusion matrix is a summary of prediction results on a classification problem. The number of correct and incorrect predictions are summarized with count values and broken down by each class. This is the key to the confusion matrix. The confusion matrix shows the ways in which your classification model is confused when it makes predictions. It gives us insight not only into the errors being made by a classifier but more importantly the types of errors that are being made.\n**\n","6c50a53b":"**Lets assign X value to all the NAN values**","4bb7b690":"**Lets check out the missing values again**","c46922cf":"**Adding a column for Survived which has to be predicted in the test data.**","405a0134":"**Checking out the distribution of Fares**","409c9d9e":"**AGE and CABIN have the higest number of Null Values,so they will not be of major help since most of the values are missing,especially CABIN.\nBut lets see the Maximum age groups present.**","6b2784c6":"**Now only \"Embarked\" has two missing values in it.**","9f4b6d4b":"**This mean is pretty close to the one that we had calculated earlier(0.384)**","3f9bfd4f":"**We will be searching for the initials of the cabin numbers like A,B,C,etc**","ff103d1a":"Lets check out if he is a lone wolf or is travelling in a pack!!","e075d3fb":"**train_test_split :Split arrays or matrices into random train and test subsets**","8afb7012":"**GG!!So no more missing values in our dataset**","5bfb143c":"**Lets check for the number of Null Values in our DATA SET**","444e0cb5":"**Visualizing the data in our dataframe into a correlation heatmap **","3d5f2ea4":"# **LOGISTIC REGRESSION**","745b27a4":"**Calculating median values of \"Age\" by using \"Pclass\" and \"Embarked\" to fill up the missing values.**","9b59f2cf":"**Lets convert our categorical data to numeric form**","b0cbbd14":"**Lets start predicting,we will be using Logistic Regression.Logistic Regression is the appropriate regression analysis to conduct when the dependent variable is dichotomous (binary).  Like all regression analyses, the logistic regression is a predictive analysis.  Logistic regression is used to describe data and to explain the relationship between one dependent binary variable and one or more nominal, ordinal, interval or ratio-level independent variables.**","b1098539":"**Lets examine the types of classes that were present**","bdb37642":"**Checking out Embarked Attribute.\n  It has 3 discrete Divisions,namely S , C ,Q.**"}}