{"cell_type":{"4baba517":"code","fc964721":"code","f9df637a":"code","5be32286":"code","9a0f4599":"code","d58da70d":"code","a1718b13":"code","a29d71f1":"code","030b441e":"code","f4d041ce":"code","ed2640e7":"code","fec8501b":"code","8fb1c3eb":"code","b055c76f":"code","03fc6012":"code","1814454e":"code","bcd5a690":"code","17d5259d":"code","e84c44a9":"code","aee0c560":"code","a5e7e150":"code","552cdacd":"code","ba9d0b61":"code","688de276":"code","d4786c51":"code","421127ba":"code","84ba739b":"code","a006966e":"code","d8155006":"code","2b618cf5":"code","fc8ad9d9":"code","d7c1f616":"code","a6d3bf13":"code","1514df2d":"code","9e30b6eb":"code","f93819cf":"code","3ad709e8":"code","3e5645bb":"code","f10bb70b":"code","af4f7252":"code","2b3e10bb":"code","115819be":"code","470ead1f":"code","dee6cc1c":"code","e17f1b47":"code","48e060ba":"code","a9b7c6f4":"code","b6948e69":"code","fdfc8cb6":"code","a0c7fb87":"code","171a1d0e":"code","81b68cc6":"markdown","940020ff":"markdown"},"source":{"4baba517":"# ignore warnings \nimport warnings\nwarnings.filterwarnings('ignore')\n\n# import general packages\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns \n%matplotlib inline\ncolor = sns.color_palette()\nfrom gplearn.genetic import SymbolicRegressor\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error,make_scorer\n# algorithms\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neural_network import MLPRegressor\n\n\n# modeling helper functions\nfrom sklearn.model_selection import GridSearchCV , KFold , cross_val_score, train_test_split","fc964721":"fnc_df = pd.read_csv(\"C:\/OpenClassRooms\/projet 8\/trends-assessment-prediction\/fnc.csv\")\nloading_df = pd.read_csv(\"C:\/OpenClassRooms\/projet 8\/trends-assessment-prediction\/loading.csv\")\n\nfnc_features, loading_features = list(fnc_df.columns[1:]), list(loading_df.columns[1:])\ndf = fnc_df.merge(loading_df, on=\"Id\")\n\n\nlabels_df = pd.read_csv(\"C:\/OpenClassRooms\/projet 8\/trends-assessment-prediction\/train_scores.csv\")\nlabels_df[\"is_train\"] = True\n\ndf = df.merge(labels_df, on=\"Id\", how=\"left\")\n\ntest_df = df[df[\"is_train\"] != True].copy()\ndf = df[df[\"is_train\"] == True].copy()","f9df637a":"target_cols = ['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']\ndf.drop(['is_train'], axis=1, inplace=True)\ntest_df = test_df.drop(target_cols + ['is_train'], axis=1)\n\n# Giving less importance to FNC features since they are easier to overfit due to high dimensionality.\nFNC_SCALE = 1\/500\n\ndf[fnc_features] *= FNC_SCALE\ntest_df[fnc_features] *= FNC_SCALE","5be32286":"features = loading_features + fnc_features","9a0f4599":"df","d58da70d":"test_df","a1718b13":"#No Missing Values\nx = df['age']\nplt.figure(figsize=(8,6))\nplt.hist(x, bins=25, color='g')\nplt.xlabel('Age')\nplt.ylabel('Number of patients')\nplt.title('Age distribution of patients', fontsize = 16)\nplt.show()","a29d71f1":"x = df['domain1_var1']\nplt.figure(figsize=(8,6))\nplt.hist(x, bins=25, color='c')\nplt.xlabel('domain1_var1')\nplt.ylabel('Number of patients')\nplt.title('domain1_var1 distribution', fontsize = 16)\nplt.show()","030b441e":"#We can see that domain1_var1 distribution is approximately normal. So, we will fill the missing values with mean.\ndf['domain1_var1'].fillna(df['domain1_var1'].mean(), inplace=True)","f4d041ce":"x = df['domain1_var2']\nplt.figure(figsize=(8,6))\nplt.hist(x, bins=25, color='pink')\nplt.xlabel('domain1_var2')\nplt.ylabel('Number of patients')\nplt.title('domain1_var2 distribution', fontsize = 16)\nplt.show()","ed2640e7":"#domain1_var2 is skewed. So, we will fill missing values with median.\ndf['domain1_var2'].fillna(df['domain1_var2'].median(), inplace=True)","fec8501b":"x = df['domain2_var1']\nplt.figure(figsize=(8,6))\nplt.hist(x, bins=25, color='y')\nplt.xlabel('domain2_var1')\nplt.ylabel('Number of patients')\nplt.title('domain2_var1 distribution', fontsize = 16)\nplt.show()","8fb1c3eb":"#domain2_var1 is approximately normal. So, we will fill missing values with mean.\ndf['domain2_var1'].fillna(df['domain2_var1'].mean(), inplace=True)","b055c76f":"x = df['domain2_var2']\nplt.figure(figsize=(8,6))\nplt.hist(x, bins=25, color='r')\nplt.xlabel('domain2_var2')\nplt.ylabel('Number of patients')\nplt.title('domain2_var2 distribution', fontsize = 16)\nplt.show()","03fc6012":"#domain2_var2 is approximately normal. So, we will fill missing values with mean.\ndf['domain2_var2'].fillna(df['domain2_var2'].mean(), inplace=True)","1814454e":"df","bcd5a690":"X_train, X_test, y_train_age, y_test_age = train_test_split(test_df, df['age'],\n                                                    train_size=0.75, test_size=0.25, random_state=42)","17d5259d":"#X_train.reset_index(drop=True,inplace=True)\nX_train","e84c44a9":"X_test","aee0c560":"y_train_age","a5e7e150":"y_test_age","552cdacd":"#symbRegage = SymbolicRegressor(verbose=1, generations=300, population_size=5000,function_set = ('add', 'sub', 'mul', 'div','sqrt','log','inv','max','min','sin','cos','tan'))\nsymbRegage = SymbolicRegressor(population_size=5000,\n                       generations=50,tournament_size=50,stopping_criteria=0.01,function_set=('add', 'sub', 'mul', 'div','sqrt','log','neg','inv','max','min','sin','cos','tan'),\n                       p_crossover=0.7, p_subtree_mutation=0.1,\n                       p_hoist_mutation=0.05, p_point_mutation=0.1,\n                       max_samples=0.9, verbose=1,\n                       parsimony_coefficient=0.01,random_state=42,n_jobs=2)\nsymbRegage.fit(X_train, y_train_age)\ny_pred_age_test = symbRegage.predict(X_test)\ny_pred_age_train = symbRegage.predict(X_train)\nprint('SymbRegage MAE test', mean_absolute_error(y_test_age, y_pred_age_test))\nprint('SymbRegage MAE train', mean_absolute_error(y_train_age, y_pred_age_train))","ba9d0b61":"parameters = {'function_set': [('add', 'sub', 'mul', 'div','sqrt','log','neg','inv','max','min','sin','cos','tan')],\n             'init_depth': [(2, 6),(3,7)],\n             'max_samples': [1.0,0.9],\n             'p_crossover': [1,0.5],\n             'p_hoist_mutation': [0.01,0.05],\n             'p_point_mutation': [0.01,0.02],\n             'random_state': [0],\n             'tournament_size': [20,50],\n             'verbose': [1],\n             'population_size': [5000],\n             'parsimony_coefficient': [\"auto\"],\n             'generations': [50],\n             'warm_start': [False]}","688de276":"#This part sets up the symbolic regressor\nclf = GridSearchCV(symbRegage , parameters, cv=5,n_jobs = -1, verbose = 1)\n#This part runs it on our data\nclf.fit(X_train, y_train_age)","d4786c51":"clf.best_params_","421127ba":"print(clf.best_estimator_._program)\nclf.best_estimator_.score(X_train,y_train_age)","84ba739b":"mae_score = make_scorer(mean_absolute_error)\ncross_val_score(symbRegage, X_train, y_train_age, cv=10, scoring = mae_score)","a006966e":"print(symbRegage._program)","d8155006":"X_train, X_test, y_train_d1v1, y_test_d1v1 = train_test_split(test_df, df['domain1_var1'],\n                                                    train_size=0.75, test_size=0.25, random_state=42)","2b618cf5":"symbRegd1v1 = SymbolicRegressor(verbose=1, generations=300, population_size=5000,function_set = ('add', 'sub', 'mul', 'div','sqrt','log','inv','max','min','sin','cos','tan'))\nsymbRegd1v1.fit(X_train, y_train_d1v1)\ny_pred_d1v1_test = symbRegd1v1.predict(X_test)\ny_pred_d1v1_train = symbRegd1v1.predict(X_train)\nprint('SymbRegd1v1 MAE test', mean_absolute_error(y_test_d1v1, y_pred_d1v1_test))\nprint('SymbRegd1v1 MAE train', mean_absolute_error(y_train_d1v1, y_pred_d1v1_train))","fc8ad9d9":"print(symbRegd1v1._program)","d7c1f616":"X_train, X_test, y_train_d1v2, y_test_d1v2 = train_test_split(test_df, df['domain1_var2'],\n                                                    train_size=0.75, test_size=0.25, random_state=42)","a6d3bf13":"symbRegd1v2 = SymbolicRegressor(verbose=1, generations=300, population_size=5000,function_set = ('add', 'sub', 'mul', 'div','sqrt','log','inv','max','min','sin','cos','tan'))\nsymbRegd1v2.fit(X_train, y_train_d1v2)\ny_pred_d1v2_test = symbRegd1v2.predict(X_test)\ny_pred_d1v2_train = symbRegd1v2.predict(X_train)\nprint('SymbRegd1v2 MAE test', mean_absolute_error(y_test_d1v2, y_pred_d1v2_test))\nprint('SymbRegd1v2 MAE train', mean_absolute_error(y_train_d1v2, y_pred_d1v2_train))","1514df2d":"print(symbRegd1v2._program)","9e30b6eb":"X_train, X_test, y_train_d2v1, y_test_d2v1 = train_test_split(test_df, df['domain2_var1'],\n                                                    train_size=0.75, test_size=0.25, random_state=42)","f93819cf":"symbRegd2v1 = SymbolicRegressor(verbose=1, generations=300, population_size=5000,function_set = ('add', 'sub', 'mul', 'div','sqrt','log','inv','max','min','sin','cos','tan'))\nsymbRegd2v1.fit(X_train, y_train_d2v1)\ny_pred_d2v1_test = symbRegd2v1.predict(X_test)\ny_pred_d2v1_train = symbRegd2v1.predict(X_train)\nprint('SymbRegd2v1 MAE test', mean_absolute_error(y_test_d2v1, y_pred_d2v1_test))\nprint('SymbRegd2v1 MAE test', mean_absolute_error(y_train_d2v1, y_pred_d2v1_train))","3ad709e8":"print(symbRegd2v1._program)","3e5645bb":"X_train, X_test, y_train_d2v2, y_test_d2v2 = train_test_split(test_df, df['domain2_var2'],\n                                                    train_size=0.75, test_size=0.25, random_state=42)","f10bb70b":"symbRegd2v2 = SymbolicRegressor(verbose=1, generations=300, population_size=5000,function_set = ('add', 'sub', 'mul', 'div','sqrt','log','inv','max','min','sin','cos','tan'))\nsymbRegd2v2.fit(X_train, y_train_d2v2)\ny_pred_d2v2_test = symbRegd2v2.predict(X_test)\ny_pred_d2v2_train = symbRegd2v2.predict(X_train)\nprint('SymbRegd2v2 MAE test', mean_absolute_error(y_test_d2v2, y_pred_d2v2_test))\nprint('SymbRegd2v2 MAE train', mean_absolute_error(y_train_d2v2, y_pred_d2v2_train))","af4f7252":"print(symbRegd2v2._program)","2b3e10bb":"X_train","115819be":"test_df","470ead1f":"df","dee6cc1c":"y_pred_age_tot_test = symbRegage.predict(test_df)\ny_pred_age_tot_train = symbRegage.predict(df.drop(columns=['age','domain1_var1','domain1_var2','domain2_var1','domain2_var2']))\nprint('SymbRegage MAE test', mean_absolute_error(df['age'], y_pred_age_tot_test))\nprint('SymbRegage MAE train', mean_absolute_error(df['age'], y_pred_age_tot_train))","e17f1b47":"y_pred_d1v1_tot_test = symbRegd1v1.predict(test_df)\ny_pred_d1v1_tot_train = symbRegd1v1.predict(df.drop(columns=['age','domain1_var1','domain1_var2','domain2_var1','domain2_var2']))\nprint('symbRegd1v1 MAE test', mean_absolute_error(df['domain1_var1'], y_pred_d1v1_tot_test))\nprint('symbRegd1v1 MAE train', mean_absolute_error(df['domain1_var1'], y_pred_d1v1_tot_train))","48e060ba":"y_pred_d1v2_tot_test = symbRegd1v2.predict(test_df)\ny_pred_d1v2_tot_train = symbRegd1v2.predict(df.drop(columns=['age','domain1_var1','domain1_var2','domain2_var1','domain2_var2']))\nprint('symbRegd1v2 MAE test', mean_absolute_error(df['domain1_var2'], y_pred_d1v2_tot_test))\nprint('symbRegd1v2 MAE train', mean_absolute_error(df['domain1_var2'], y_pred_d1v2_tot_train))","a9b7c6f4":"y_pred_d2v1_tot_test = symbRegd2v1.predict(test_df)\ny_pred_d2v1_tot_train = symbRegd2v1.predict(df.drop(columns=['age','domain1_var1','domain1_var2','domain2_var1','domain2_var2']))\nprint('symbRegd2v1 MAE test', mean_absolute_error(df['domain2_var1'], y_pred_d2v1_tot_test))\nprint('symbRegd2v1 MAE train', mean_absolute_error(df['domain2_var1'], y_pred_d2v1_tot_train))","b6948e69":"y_pred_d2v2_tot_test = symbRegd2v2.predict(test_df)\ny_pred_d2v2_tot_train = symbRegd2v2.predict(df.drop(columns=['age','domain1_var1','domain1_var2','domain2_var1','domain2_var2']))\nprint('symbRegd2v2 MAE test', mean_absolute_error(df['domain2_var2'], y_pred_d2v2_tot_test))\nprint('symbRegd2v2 MAE train', mean_absolute_error(df['domain2_var2'], y_pred_d2v2_tot_train))","fdfc8cb6":"d = {'Id' : test_df['Id'],'age': y_pred_age_tot_test , 'domain1_var1' : y_pred_d1v1_tot_test, 'domain1_var2' : y_pred_d1v2_tot_test, 'domain2_var1' : y_pred_d2v1_tot_test, 'domain2_var2' : y_pred_d2v2_tot_test }\npredictions = pd.DataFrame(data=d)\npredictions","a0c7fb87":"test_df","171a1d0e":"sub_df = pd.melt(predictions[[\"Id\", \"age\", \"domain1_var1\", \"domain1_var2\", \"domain2_var1\", \"domain2_var2\"]], id_vars=[\"Id\"], value_name=\"Predicted\")\nsub_df[\"Id\"] = sub_df[\"Id\"].astype(\"str\") + \"_\" +  sub_df[\"variable\"].astype(\"str\")\n\nsub_df = sub_df.drop(\"variable\", axis=1).sort_values(\"Id\")\nassert sub_df.shape[0] == predictions.shape[0]*5\n\nsub_df.to_csv(\"submission2.csv\", index=False)","81b68cc6":"scores = []\n#best_svr = SVR(kernel='rbf')\ncv = KFold(n_splits=10, random_state=42, shuffle=False)\nfor train_index, test_index in cv.split(X_train):\n    print(\"Train Index: \", train_index, \"\\n\")\n    print(\"Test Index: \", test_index)\n    X_train_fold, X_test_fold, y_train_fold, y_test_fold = X_train[train_index], X_train[test_index], y_train_age[train_index], y_test_age[test_index]\n    symbRegage.fit(X_train_fold, y_train_fold)\n    scores.append(mean_absolute_error(X_test_fold, y_test_fold))","940020ff":"<h1>Table of Contents<span class=\"tocSkip\"><\/span><\/h1>\n<div class=\"toc\"><ul class=\"toc-item\"><\/ul><\/div>"}}