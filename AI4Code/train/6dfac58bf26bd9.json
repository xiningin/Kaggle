{"cell_type":{"56c8874a":"code","f6cf2b9e":"code","06a0f092":"code","acb202de":"code","0dacf65c":"code","95bd9fb3":"code","31d85b84":"code","f287fcc5":"code","c7f27db3":"code","ca23c8af":"code","701e06fb":"code","a17251a3":"code","22716472":"code","9429b6a3":"code","182f7266":"code","75a09ac4":"code","e7f7c057":"code","84b0b7bc":"code","175db2cf":"code","56e38b6b":"code","701b00e5":"code","fca3b5ca":"code","eeb17534":"code","79a1ca44":"code","631dfba9":"code","699636b3":"code","8e6b541a":"code","b5654102":"code","d1cd72d4":"code","70433aa8":"code","aece20c2":"code","6b10383f":"code","618388a2":"code","4220425f":"code","59cf43f1":"code","0a8ea1fa":"markdown","b2d555d7":"markdown","8db10ca2":"markdown","463bcd6d":"markdown","c6ea7558":"markdown","23bd345b":"markdown","37c3e8a3":"markdown","b5f2acb4":"markdown","7d7afb56":"markdown","b41a47e0":"markdown","64a65966":"markdown","7a912113":"markdown","471062d9":"markdown","0a224b7a":"markdown"},"source":{"56c8874a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve, recall_score\nfrom sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold, RandomizedSearchCV, cross_val_score\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC \nfrom sklearn.ensemble import RandomForestClassifier,VotingClassifier\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import RandomOverSampler, SMOTE\nfrom collections import Counter\nfrom pprint import pprint\nfrom scipy import stats\nfrom sklearn.preprocessing import StandardScaler","f6cf2b9e":"dataset = pd.read_csv(\"..\/input\/bank-marketing\/bank-additional-full.csv\", sep=';')\ndataset.head()","06a0f092":"dataset.info()","acb202de":"dataset.isnull().sum()","0dacf65c":"dataset.describe()","95bd9fb3":"dataset.hist(bins = 15, figsize = (10,10), xlabelsize = 0.1, ylabelsize = 0.1)\nplt.show()","31d85b84":"dataset.pdays.value_counts(normalize=True)","f287fcc5":"sns.catplot(x='default',hue='y',kind='count',data=dataset)","c7f27db3":"pd.crosstab(dataset['default'], dataset.y)","ca23c8af":"dataset.y.value_counts(normalize=True)","701e06fb":"colors = [\"#0101DF\", \"#DF0101\"]\n\nsns.countplot('y', data=dataset, palette=colors)\nplt.title('Deposit Distributions \\n (0: No || 1: Yes)', fontsize=14)","a17251a3":"plt.figure(figsize=(15,15))\nsns.heatmap(dataset.corr(),square=True,annot=True,cmap= 'twilight_shifted')","22716472":"# make a copy of dataset to scaling\nbank_scale=dataset.copy()\n\n# remove 'pdays' and 'default' columns\nbank_scale= bank_scale.drop(['pdays', 'default'], axis=1)\n\nbank_scale.y.replace(('yes', 'no'), (1, 0), inplace=True)\n\n# standardization for just numerical variables \ncategorical_cols= ['job','marital', 'education',  'housing', 'loan', 'contact', 'month', 'day_of_week','poutcome','y']\nfeature_scale=[feature for feature in bank_scale.columns if feature not in categorical_cols]\n\nscaler=StandardScaler()\nscaler.fit(bank_scale[feature_scale])","9429b6a3":"scaled_data = pd.concat([bank_scale[categorical_cols].reset_index(drop=True),\n                    pd.DataFrame(scaler.transform(bank_scale[feature_scale]), columns=feature_scale)],\n                    axis=1)\n\ncategorical_cols1= ['job','marital', 'education', 'housing', 'loan', 'contact', 'month', 'day_of_week','poutcome']\nscaled_data= pd.get_dummies(scaled_data, columns = categorical_cols1, drop_first=True)\nscaled_data.head()","182f7266":"X = scaled_data.iloc[:,1:]\nY = scaled_data.iloc[:,-0]\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=2)","75a09ac4":"import warnings\nwarnings.filterwarnings(\"ignore\")\n# Tuning parameter for RF ( tuning parameters are choosen based on best parameters of RandomizedSearchCV)\nn_estimators = [int(x) for x in np.linspace(start = 20, stop = 200, num = 5)]\nmax_features = ['auto', 'sqrt']\nmax_depth = [int(x) for x in np.linspace(1, 45, num = 3)]\nmin_samples_split = [5, 10]\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split}\ntuning_rf = RandomizedSearchCV(estimator = RandomForestClassifier(), param_distributions = random_grid, n_iter = 10, cv = 10, verbose=2, random_state=42, n_jobs = -1, scoring='roc_auc')\ntuning_rf.fit(X_train,y_train)\nprint('Best Parameter for Random Forest', tuning_rf.best_params_, tuning_rf.best_score_)\n\n# Tuning parameter for Tree\nparam_dict= {\"criterion\": ['gini', 'entropy'],\n            \"max_depth\": range(1,10),\n            \"min_samples_split\": range(1,10),\n            \"min_samples_leaf\": range(1,5)}\ntuning_tree = GridSearchCV(DecisionTreeClassifier(random_state=12),  param_grid=param_dict, cv=10, verbose=1, n_jobs=-1)\ntuning_tree.fit(X_train,y_train)\nprint('Best Parameter for Tree', tuning_tree.best_params_, tuning_tree.best_score_)\n\n# Xgboost Parameters\nparam_xgb = {\n 'max_depth':[4,5,6],\n 'min_child_weight':[4,5,6],\n 'gamma':[i\/10.0 for i in range(0,5)]\n}\ntuning_xgb = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=4,\n min_child_weight=6, gamma=0, subsample=0.8, colsample_bytree=0.8,\n objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n param_grid = param_xgb, scoring='roc_auc',n_jobs=4, cv=5)\ntuning_xgb.fit(X_train,y_train)\nprint('Best Parameter for XGBoost', tuning_xgb.best_params_, tuning_xgb.best_score_)","e7f7c057":"%%time\n# Voting Classifier\nclf1 = DecisionTreeClassifier()\nclf2 = RandomForestClassifier(random_state=1)\nclf3 = GaussianNB()\nclf4= KNeighborsClassifier()\nclf5= LinearDiscriminantAnalysis()\nclf6= XGBClassifier()\n\n# Instantiate the classfiers and make a list\nclassifiers = [LinearDiscriminantAnalysis(),\n               KNeighborsClassifier(),\n               GaussianNB(), \n               SVC(kernel='linear'),\n               DecisionTreeClassifier(criterion='gini', max_depth=6, min_samples_split=9,min_samples_leaf=2, random_state=12),\n               RandomForestClassifier(n_estimators=155, max_features='auto', max_depth=45, min_samples_split=10, random_state=27),\n               XGBClassifier(learning_rate =0.1, n_estimators=140, max_depth=5, min_child_weight=4, gamma=0.3, subsample=0.8, colsample_bytree=0.8, objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27),\n               VotingClassifier(estimators = [('DTree', clf1), ('rf', clf2), ('gnb', clf3),  ('knn', clf4),('lda', clf5), ('xgb', clf6)], voting ='soft')]\n\n# Define a result table as a DataFrame\nresult_table = pd.DataFrame(columns=['classifiers', 'fpr1','tpr1','fpr','tpr','train_accuracy','test_accuracy', 'train_auc', 'test_auc', 'f1_score', 'precision','recall','confusion matrix','Report'])\n\n# Train the models and record the results\nfor cls in classifiers:\n    model = cls.fit(X_train, y_train)\n    y_train_pred = model.predict(X_train)\n    y_test_pred = model.predict(X_test)\n    \n    train_accuracy= accuracy_score(y_train, y_train_pred)\n    test_accuracy= accuracy_score(y_test, y_test_pred)\n     \n    fpr, tpr, _ = roc_curve(y_test,  y_test_pred)\n    fpr1, tpr1, _ = roc_curve(y_train,  y_train_pred)\n    \n    train_auc = roc_auc_score(y_train, y_train_pred)\n    test_auc = roc_auc_score(y_test, y_test_pred)\n    \n    f1_score= metrics.f1_score(y_test, y_test_pred)\n    precision = metrics.precision_score(y_test, y_test_pred)\n    recall = metrics.recall_score(y_test, y_test_pred)\n    \n    conf_mat= confusion_matrix(y_test,y_test_pred)\n    report=classification_report(y_test,y_test_pred, digits=3, output_dict=True)\n    \n    result_table = result_table.append({'classifiers':cls.__class__.__name__,\n                                        'fpr1':fpr1,\n                                        'tpr1':tpr1,\n                                        'fpr':fpr, \n                                        'tpr':tpr, \n                                        'train_accuracy': train_accuracy,\n                                        'test_accuracy': test_accuracy,\n                                        'train_auc':train_auc,\n                                        'test_auc':test_auc,\n                                        'f1_score': f1_score,\n                                        'precision': precision,\n                                        'recall': recall,\n                                        'confusion matrix':conf_mat,\n                                        'Report':report}, ignore_index=True)\n\n# Set name of the classifiers as index labels\nresult_table.set_index('classifiers', inplace=True)","84b0b7bc":"result_table.rename(index={'VotingClassifier':'Model Ensemble'},inplace=True)\nresult_table","175db2cf":"pd.DataFrame(result_table.iloc[0,12]).transpose()","56e38b6b":"fig = plt.figure(figsize=(15,10))\n\nfor i in range(result_table.shape[0]):\n    plt.plot(result_table.iloc[i,]['fpr'], \n             result_table.iloc[i,]['tpr'], \n             label=\"{}, AUC={:.3f}\".format(result_table.index[i], result_table.iloc[i,]['test_auc']))\n    \nplt.plot([0,1], [0,1], color='orange', linestyle='--')\nplt.xticks(np.arange(0.0, 1.1, step=0.1))\nplt.xlabel(\"False Positive Rate\", fontsize=15)\nplt.yticks(np.arange(0.0, 1.1, step=0.1))\nplt.ylabel(\"True Positive Rate\", fontsize=15)\nplt.title('ROC Curve Analysis', fontweight='bold', fontsize=15)\nplt.legend(prop={'size':13}, loc='lower right')\nplt.show()","701b00e5":"print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1))) \nprint(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train == 0))) \n\nfrom imblearn.over_sampling import RandomOverSampler\n# define oversampling strategy\noversample = RandomOverSampler(sampling_strategy='minority') \nX_train_over, y_train_over = oversample.fit_resample(X_train, y_train)\n  \nprint('After OverSampling, the shape of X_train: {}'.format(X_train_over.shape)) \nprint('After OverSampling, the shape of y_train: {} \\n'.format(y_train_over.shape)) \n  \nprint(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_over == 1))) \nprint(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_over == 0))) ","fca3b5ca":"# Tuning parameter for RF \nn_estimators = [int(x) for x in np.linspace(start = 20, stop = 200, num = 5)]\nmax_features = ['auto', 'sqrt']\nmax_depth = [int(x) for x in np.linspace(1, 45, num = 3)]\nmin_samples_split = [5, 10]\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split}\ntuning_rf = RandomizedSearchCV(estimator = RandomForestClassifier(), param_distributions = random_grid, n_iter = 10, cv = 10, verbose=2, random_state=42, n_jobs = -1, scoring='roc_auc')\ntuning_rf.fit(X_train_over,y_train_over)\nprint('Best Parameter for Random Forest', tuning_rf.best_params_, tuning_rf.best_score_)\n\n# Tuning parameter for Tree\nparam_dict= {\"criterion\": ['gini', 'entropy'],\n            \"max_depth\": range(1,10),\n            \"min_samples_split\": range(1,10),\n            \"min_samples_leaf\": range(1,5)}\ntuning_tree = GridSearchCV(DecisionTreeClassifier(random_state=12),  param_grid=param_dict, cv=10, verbose=1, n_jobs=-1)\ntuning_tree.fit(X_train_over,y_train_over)\nprint('Best Parameter for Tree', tuning_tree.best_params_, tuning_tree.best_score_)\n\n# Xgboost Parameters\nparam_xgb = {\n 'max_depth':[4,5,6],\n 'min_child_weight':[4,5,6],\n 'gamma':[i\/10.0 for i in range(0,5)]}\ntuning_xgb = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=4,\n min_child_weight=6, gamma=0, subsample=0.8, colsample_bytree=0.8,\n objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n param_grid = param_xgb, scoring='roc_auc',n_jobs=4, cv=5)\ntuning_xgb.fit(X_train_over,y_train_over)\nprint('Best Parameter for XGBoost', tuning_xgb.best_params_, tuning_xgb.best_score_)","eeb17534":"%%time\n# Voting Classifier\nclf1 = DecisionTreeClassifier()\nclf2 = RandomForestClassifier(random_state=1)\nclf3 = GaussianNB()\nclf4 = KNeighborsClassifier()\nclf5= LinearDiscriminantAnalysis()\nclf6= XGBClassifier()\n\n# Instantiate the classfiers and make a list\nclassifiers = [LinearDiscriminantAnalysis(),\n               KNeighborsClassifier(),\n               GaussianNB(), \n               SVC(kernel='linear'),\n               DecisionTreeClassifier(criterion='gini', max_depth=9, min_samples_split=5,min_samples_leaf=1, random_state=12),\n               RandomForestClassifier(n_estimators=200, max_features='sqrt', max_depth=45, min_samples_split=5, random_state=27),\n               XGBClassifier(learning_rate =0.1, n_estimators=140, max_depth=4, min_child_weight=6, gamma=0.4, subsample=0.8, colsample_bytree=0.8, objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27),\n               VotingClassifier(estimators = [('DTree', clf1), ('rf', clf2), ('gnb', clf3), ('knn', clf4), ('lda', clf5), ('xgb', clf6)], voting ='soft')]\n\n# Define a result table as a DataFrame\nresult_table1 = pd.DataFrame(columns=['classifiers', 'fpr1','tpr1','fpr','tpr','train_accuracy','test_accuracy', 'train_auc', 'test_auc', 'f1_score', 'precision','recall','confusion matrix','Report'])\n\n# Train the models and record the results\nfor cls in classifiers:\n    model = cls.fit(X_train_over, y_train_over)\n    y_train_pred = model.predict(X_train_over)\n    y_test_pred = model.predict(X_test)\n    \n    train_accuracy= accuracy_score(y_train_over, y_train_pred)\n    test_accuracy= accuracy_score(y_test, y_test_pred)\n     \n    fpr, tpr, _ = roc_curve(y_test,  y_test_pred)\n    fpr1, tpr1, _ = roc_curve(y_train_over,  y_train_pred)\n    \n    train_auc = roc_auc_score(y_train_over, y_train_pred)\n    test_auc = roc_auc_score(y_test, y_test_pred)\n    \n    f1_score= metrics.f1_score(y_test, y_test_pred)\n    precision = metrics.precision_score(y_test, y_test_pred)\n    recall = metrics.recall_score(y_test, y_test_pred)\n    \n    conf_mat= confusion_matrix(y_test,y_test_pred)\n    report=classification_report(y_test,y_test_pred, digits=3, output_dict=True)\n    \n    result_table1 = result_table1.append({'classifiers':cls.__class__.__name__,\n                                        'fpr1':fpr1,\n                                        'tpr1':tpr1,\n                                        'fpr':fpr, \n                                        'tpr':tpr, \n                                        'train_accuracy': train_accuracy,\n                                        'test_accuracy': test_accuracy,\n                                        'train_auc':train_auc,\n                                        'test_auc':test_auc,\n                                        'f1_score': f1_score,\n                                        'precision': precision,\n                                        'recall': recall,\n                                        'confusion matrix':conf_mat,\n                                        'Report':report}, ignore_index=True)\n\n# Set name of the classifiers as index labels\nresult_table1.set_index('classifiers', inplace=True)","79a1ca44":"result_table1.rename(index={'VotingClassifier':'Model Ensemble'},inplace=True)\nresult_table1","631dfba9":"fig = plt.figure(figsize=(15,10))\n\nfor i in range(result_table1.shape[0]):\n    plt.plot(result_table1.iloc[i,]['fpr'], \n             result_table1.iloc[i,]['tpr'], \n             label=\"{}, AUC={:.3f}\".format(result_table1.index[i], result_table1.iloc[i,]['test_auc']))\n    \nplt.plot([0,1], [0,1], color='orange', linestyle='--')\nplt.xticks(np.arange(0.0, 1.1, step=0.1))\nplt.xlabel(\"False Positive Rate\", fontsize=15)\nplt.yticks(np.arange(0.0, 1.1, step=0.1))\nplt.ylabel(\"True Positive Rate\", fontsize=15)\nplt.title('ROC Curve Analysis', fontweight='bold', fontsize=15)\nplt.legend(prop={'size':13}, loc='lower right')\nplt.show()","699636b3":"# Baseline Model\nresult_table.iloc[:,[4,5,6,7,8,9,10]]","8e6b541a":"# Oversampling with RandomOverSampler\nresult_table1.iloc[:,[4,5,6,7,8,9,10]]","b5654102":"xgb = XGBClassifier(learning_rate =0.1, n_estimators=140, max_depth=4, min_child_weight=6, gamma=0.4, subsample=0.8, colsample_bytree=0.8, nthread=4, scale_pos_weight=1,seed=27)\nmodel_xgb = xgb.fit(X_train_over, y_train_over)\ny_train_xgb = model_xgb.predict(X_train_over)\ny_test_xgb = model_xgb.predict(X_test)\n\nprint(confusion_matrix(y_test,y_test_xgb))\nprint(classification_report(y_test,y_test_xgb, digits=3))\n\nprint('Train accuracy: %0.3f' % accuracy_score(y_train_over, y_train_xgb))\nprint('Test accuracy: %0.3f' % accuracy_score(y_test, y_test_xgb))\n\nprint('Train AUC: %0.3f' % roc_auc_score(y_train_over, y_train_xgb))\nprint('Test AUC: %0.3f' % roc_auc_score(y_test, y_test_xgb))","d1cd72d4":"import shap\nexpl_xgb = shap.TreeExplainer(model_xgb)\nshap_xgb = expl_xgb.shap_values(X_train_over)","70433aa8":"shap.summary_plot(shap_xgb, X_train_over, plot_type=\"bar\")","aece20c2":"shap.summary_plot(shap_xgb, X_train_over)","6b10383f":"shap.initjs()\nshap.force_plot(expl_xgb.expected_value, shap_xgb[1050,:], X_train_over.iloc[1050,:], link='logit')","618388a2":"shap.initjs()\nshap.force_plot(expl_xgb.expected_value, shap_xgb[4000,:], X_train_over.iloc[4000,:], link='logit')","4220425f":"# base value\ny_train_over.mean()","59cf43f1":"X_train_over.iloc[4000,]","0a8ea1fa":"# Results","b2d555d7":"# Correlation Matrix","8db10ca2":"Looking at the proportion of the classes we like to predict, we see that the dataset is imbalanced. We will take care of this problem with oversampling method.","463bcd6d":"# Data Cleaning and Preprocessing","c6ea7558":"There are highly correlated variables in the dataset. It would be reasonable to perform feature selection but most of the algorithms I use have their own feature selection, I omit to ddo that.","23bd345b":"## Standardization","37c3e8a3":"# Data Import","b5f2acb4":"# Feature Importance and SHAP Values","7d7afb56":"There are only 3 customers which we know for sure that they have a loan in default. Again, this variable gives no information and it will be dropped in a later stage.","b41a47e0":"## Train\/Test Split","64a65966":"There are no missing values in the dataset.","7a912113":"pdays variable has the value 999 96% of the time. The variable gives no information since its variance is very low. It is better to drop this variable.","471062d9":"# Benchmark Models","0a224b7a":"# Oversampling - RandomOverSampler"}}