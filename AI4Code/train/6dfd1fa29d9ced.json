{"cell_type":{"831d0cde":"code","de404a5c":"code","8c29beab":"code","056c32fa":"code","35e3db41":"code","b148ecbd":"code","39c907a1":"code","89079b86":"code","0bf64021":"code","b3ddcdca":"code","6058791a":"code","f3403e24":"code","e9b5ce75":"code","8879c1d5":"code","3e74fb5e":"code","9a743c28":"code","c9e1af12":"code","7aa4a93c":"code","05298034":"code","35dccd23":"code","da23fd22":"code","b132813c":"code","34206834":"code","1bfc0ba2":"code","77645f5d":"code","0da26a73":"code","4ea541fa":"code","c5d99fda":"code","6b2d2a23":"code","cf95a969":"code","2c282b50":"code","814a14be":"code","24e711bb":"code","cb7ecf27":"code","c1a412a1":"code","00b615f1":"code","6661edec":"code","6c3de3ed":"code","6e307fde":"code","fc5f0af2":"code","a0ddea14":"code","dc81218e":"code","cea4577f":"code","c71226f0":"code","61dbfa96":"code","c5e3d3f1":"code","c834cd0b":"code","66a22d37":"code","f816fcf4":"code","b219bee3":"code","0f4907f1":"code","0c2a2609":"code","85d70816":"code","64ae0dc6":"code","c935f820":"code","d0f75cf0":"code","7ccbd8f1":"code","ca3449c2":"code","5ab3d858":"markdown","8d9fa6c1":"markdown","98c44c34":"markdown","61e8ee6e":"markdown","03e11235":"markdown","8f7fcd51":"markdown","11e73edf":"markdown","26b53500":"markdown","908ffa3b":"markdown","96d24f3f":"markdown","29e13042":"markdown","33d7493d":"markdown","95edf8fa":"markdown","0e4f7e00":"markdown","8641eb1d":"markdown","bc435c5c":"markdown","382304c6":"markdown","ec7cbc59":"markdown","5b8d1eeb":"markdown","08216fba":"markdown","c752d036":"markdown","16db6e2d":"markdown","144a1d47":"markdown","b1b50724":"markdown","4dd81120":"markdown","99757315":"markdown","130e253d":"markdown","86c6f6a1":"markdown","dec1ac0b":"markdown","4a64ca16":"markdown","a6420377":"markdown","c1cefae8":"markdown","19d6d9df":"markdown","27d6b5a2":"markdown","66f26b23":"markdown","d83f7142":"markdown","80a8ff5b":"markdown","4766f48c":"markdown","fe9a02a8":"markdown","b1d1ddbf":"markdown","3dd95e51":"markdown"},"source":{"831d0cde":"# general\nimport pandas as pd\nimport numpy as np\nfrom scipy.stats import scoreatpercentile, percentileofscore\nimport sys\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport datetime\nimport re\nprint(datetime.datetime.now())\n\n# visualization\nfrom IPython.display import display, Image, Markdown\nimport matplotlib.pyplot as plt\npd.set_option('display.max_columns', 500, 'display.max_rows', 100, 'display.min_rows', 20)\nplt.rcParams['figure.figsize'] = [10, 5]\n%matplotlib inline\n%autosave 60","de404a5c":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.metrics import precision_score, recall_score, roc_auc_score, roc_curve, accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.inspection import permutation_importance","8c29beab":"submissions = pd.read_csv('..\/input\/titanicpublicleaderboard\/titanic-publicleaderboard.csv')\nsub_max_scores = submissions.groupby('TeamId')['Score'].agg('max')\nsub_max_scores = sub_max_scores[(sub_max_scores > 0.5) & (sub_max_scores < 1)]\nscore_to_beat = scoreatpercentile(sub_max_scores, 90)\nprint(f'The score to beat is: {score_to_beat:.4f}')\n\nfig, ax = plt.subplots()\nsns.distplot(sub_max_scores, label='scores distribution', ax=ax);\nax.axvline(score_to_beat, label='score to beat', linestyle='--', color='C1')\nax.legend();","056c32fa":"train_df = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('..\/input\/titanic\/test.csv')\nCLASS_LABEL = 'Survived'\nfull_df = pd.concat([train_df, test_df], axis=0, ignore_index=True)","35e3db41":"full_df.head()","b148ecbd":"full_df.isna().sum()","39c907a1":"dummy_columns = []\ndummy_columns.append('Pclass')","89079b86":"def get_title(name):\n    match = re.search('\\w{2,}\\.\\s', name)\n    if match is None:\n        return None\n    else:\n        return match.group()\n\nfull_df['Title'] = full_df['Name'].apply(get_title)\nfull_df[['Name', 'Title']].head(3)","0bf64021":"def get_parenthesis_name(name):\n    match = re.search('\\(.{2,}\\)', name)\n    if match is None:\n        return None\n    else:\n        return match.group()\n\nfull_df['ParenthesisName'] =  full_df['Name'].apply(get_parenthesis_name)\nfull_df[['Name', 'ParenthesisName']].dropna().head(3)","b3ddcdca":"def get_nickname(name):\n    match = re.search('\".{2,}\"', name)\n    if match is None:\n        return None\n    else:\n        return match.group()\n    \nfull_df['Nickname'] = full_df['Name'].apply(get_nickname)\nfull_df[['Name', 'Nickname']].dropna().head(3)","6058791a":"def get_clean_name(name, title, parenthesis_name, nickname):\n    clean_name = name\n    clean_name =  clean_name.replace(title, '')\n    if parenthesis_name:\n        clean_name =  clean_name.replace(parenthesis_name, '')\n    if nickname:\n        clean_name =  clean_name.replace(nickname, '')\n    clean_name = clean_name.strip(' ,()\\\"')\n    \n    return clean_name\n\nfull_df['CleanName'] = full_df.apply(\n    lambda row: get_clean_name(row['Name'], row['Title'], row['ParenthesisName'], row['Nickname']), 1)","f3403e24":"full_df['Title'] = full_df['Title'].str.strip(' .')\nfull_df['Nickname'] = full_df['Nickname'].str.strip(' \\\"()')\nfull_df['ParenthesisName'] = full_df['ParenthesisName'].str.strip(' \\\"()')","e9b5ce75":"full_df[['Name', 'Title', 'CleanName', 'ParenthesisName', 'Nickname']].dropna().head()","8879c1d5":"# full_df['CleanNameShort'] = full_df['CleanName'].apply(lambda x: ' '.join(x.split()[:2]))\n# full_df[['CleanName', 'CleanNameShort']]","3e74fb5e":"UNMARRIED_TITLES = ['Mlle', 'Master', 'Miss']\nfull_df['TitleUnmarried'] = full_df['Title'].apply(lambda x: x in UNMARRIED_TITLES)","9a743c28":"possible_spouses_df = full_df.loc[lambda df: df['TitleUnmarried'] == False].copy()\npossible_spouses_df['OppositeSex'] = possible_spouses_df['Sex'].map({'male': 'female', 'female': 'male'})\n\nfull_df = pd.merge(\n    left=full_df, \n    right=possible_spouses_df, \n    how='left', \n    left_on=['CleanName', 'Sex', 'TitleUnmarried'], \n    right_on=['CleanName', 'OppositeSex', 'TitleUnmarried'], \n    suffixes=['', 'OfSpouse'], \n)[full_df.columns.tolist() + ['PassengerIdOfSpouse', 'NameOfSpouse']]","c9e1af12":"full_df['PassengerIdOfSpouse'] = full_df['PassengerIdOfSpouse'].astype('Int64')\nfull_df['SpouseOnBoard'] = full_df['PassengerIdOfSpouse'].notna().astype('int')\nfull_df['SiblingsOnBoard'] = (full_df['SibSp'] - full_df['SpouseOnBoard']).clip(0, None)\nfull_df[['PassengerId', 'Name', 'SpouseOnBoard', 'PassengerIdOfSpouse', 'NameOfSpouse']].head()","7aa4a93c":"# bad_tickets = (full_df.groupby('Ticket')['Parch'].unique().apply(np.sum, axis=0) != full_df.groupby('Ticket').size()).loc[lambda x: x].index","05298034":"# full_df.loc[\n#     (full_df['Ticket'].isin(bad_tickets))\n#     & (full_df['Parch'] > 1)\n# ].groupby('Ticket').size()","35dccd23":"# full_df.loc[full_df['Ticket'] == '113760']","da23fd22":"MINIMAL_YEARS_FOR_PARENT = 13\n# def group_pa_pos(x):\n#     x_copy = x.copy()\n#     result = x.copy()\n#     for i, y in enumerate(x_copy):\n#         if pd.isna(y):\n#             result.iloc[i] = len(x_copy) - 1\n#         else:\n#             result.iloc[i] = (x_copy.fillna(80) > (y+MINIMAL_YEARS_FOR_PARENT)).sum()\n#     return result\n\n# def group_ch_pos(x):\n#     x_copy = x.copy()\n#     result = x.copy()\n#     for i, y in enumerate(x_copy):\n#         if pd.isna(y):\n#             result.iloc[i] = len(x_copy)-1\n#         else:\n#             result.iloc[i] = (x_copy.fillna(1) < (y-MINIMAL_YEARS_FOR_PARENT)).sum()\n#     return result\n\n# data_p['_ch_pos'] = data_p.groupby(['Ticket'])['Age'].transform(group_ch_pos)\n# data_p['Ch_onboard'] = data_p.apply(lambda x: min(x[['_ch_pos', 'Parch']]), axis=1)\n# data_p['Pa_onboard'] = data_p['Parch'] - data_p['Ch_onboard']\n# data_p['group_size'] = data_p.groupby(['Ticket'])['Ticket'].transform('count')\n# data_p['family_size'] = data_p['SibSp'] + data_p['Parch'] + 1\n# data_p['is_alone'] = (data_p['family_size'] == 1).astype(int)","b132813c":"data_p.loc[data_p['Ticket']=='19950', \n           ['Title', 'Name', 'Age', 'Sex', 'Parch', '_ch_pos', 'Pa_onboard', 'Ch_onboard', 'Sp_onboard', 'family_size']\n          ].sort_values('Age', ascending=False)","34206834":"OVERALL_SURVIVAL_RATE = data['Survived'].mean()\ndef group_survival_rate(x, na_value=OVERALL_SURVIVAL_RATE):\n    x_copy = x.copy().fillna(na_value)\n    result = x_copy.copy()\n    people_in_group = result.count()\n    if people_in_group == 1:\n        return na_value\n    for i, y in enumerate(x_copy):\n        sum_survived_but_me = x_copy.sum() - y\n        result.iloc[i] = sum_survived_but_me \/ (people_in_group-1.0)\n    return result\n\ndata_p['group_survival_rate'] = data_p.groupby(['Ticket'])['Survived'].transform(group_survival_rate)","1bfc0ba2":"data_p['Sex_male'] = (data_p['Sex'] == 'male').astype(int)","77645f5d":"print(data_p['Age'].isna().value_counts(True))","0da26a73":"sns.distplot(data_p['Age']);","4ea541fa":"sns.countplot(data_p['SibSp']);","c5d99fda":"sns.countplot(data_p['Parch']);","6b2d2a23":"# with help from pd_helpers.get_data_formata\nticket_formats = [\n '([A-Z]\\\\.){2,3} \\\\d{4,5}',\n 'A[A-Z]?\/\\\\d\\\\.? \\\\d{3,5}',\n 'A\\\\.[\/ ][25]\\\\. \\\\d{4,5}',\n 'A\\\\.?[45]\\\\. \\\\d{4,5}',\n 'CA\\\\. 23\\\\d{2}',\n 'LINE',\n 'SC\/AH Basle 541',\n 'SC\/A\\\\.3 \\\\d{3,4}',\n 'SC\/Paris 21\\\\d3',\n 'SO?TON\/O[\\\\s\\\\.]?[2Q]\\\\. 3\\\\d{5,6}',\n 'S[A-Z]{1,4}\/[A-Z]\\\\d \\\\d{5,7}',\n 'S\\\\.[CO]\\\\.\/[AP]\\\\.[4P]\\\\. \\\\d{1,5}',\n 'W\\\\.\/C\\\\. \\\\d{4,5}',\n '[A-Z]\\\\.[A-Z]\\\\.\/[A-Z]{2,5} \\\\d{3,5}',\n '[A-Za-z]{1,2} \\\\d{4,6}',\n '[A-Z]{1,5}\/[A-Z]{1,5} \\\\d{3,7}',\n '\\\\d{3,7}']","cf95a969":"def replace_with_format(value, formats):\n    if pd.isna(value):\n        return None\n    import re\n    for f in formats:\n        if re.match('^' + f + '$', value):\n            return f\n    return None\n\ndata_p['Ticket'] = data_p['Ticket'].apply(str)\ndata_p['Ticket_format'] = data_p['Ticket'].apply(lambda v: replace_with_format(v, ticket_formats))\nprint(len(data_p[pd.isna(data_p['Ticket_format'])]['Ticket']),'unrecognized formats')\ndata_p['Ticket_format'].value_counts()","2c282b50":"display(data_p[pd.isna(data['Fare'])])\npassenger_1044_probable_fare = data_p[data_p['Pclass'] == data_p.loc[data_p['PassengerId']==1044, 'Pclass'].iloc[0]]['Fare'].dropna().median()\ndata_p['Fare'] = data_p['Fare'].fillna(passenger_1044_probable_fare)","814a14be":"sns.distplot(data_p['Fare']);","24e711bb":"cabin_formats = [\n '([A-Z]\\\\d{2} ){1,3}[A-Z]\\\\d{2}',\n 'F [A-Z]\\\\d{2}',\n '[A-Z]',\n '[A-Z]\\\\d{1,3}']","cb7ecf27":"data_p['Cabin_format'] = data_p['Cabin'].apply(lambda v: replace_with_format(v,  pd.Series(cabin_formats)))\n\nprint((data_p[pd.isna(data_p['Cabin_format'])]['Cabin']).count(),'unrecognized formats')\ndata_p['Cabin_format'].value_counts(True)","c1a412a1":"sns.countplot(data_p['Embarked'])\ndata_p['Embarked'] = data_p['Embarked'].fillna('S')\ndummy_columns.append('Embarked')","00b615f1":"dummy_columns += ['Cabin_format', 'Ticket_format', 'Title_small']\ndata_features = pd.get_dummies(data_p, columns=list(set(dummy_columns)), drop_first=False)\n\ndata_features.drop(columns=['Sex', 'SibSp', 'Parch', 'Ticket', 'Cabin', '_ch_pos', 'Name', \n                            'CleanName', 'CleanNameShort', 'Title'], inplace=True)\n\ndata_features['has_Pname'] = pd.notna(data_features['Pname']).astype(int)\ndata_features['has_Nickname'] = pd.notna(data_features['Nickname']).astype(int)\ndata_features['Title_Unmarried'] = data_features['Title_Unmarried'].astype(int)\ndata_features.drop(columns=['Pname', 'Nickname'], inplace=True)\n\ndata_features.set_index('PassengerId', inplace=True)","6661edec":"data_features.head()","6c3de3ed":"for col in data_features.columns:\n    if data_features[col].nunique() != 2:\n        continue\n    if data_features[col].value_counts(True)[0] > 0.99:\n        print(f'Dropping column: {col}')\n        data_features.drop(columns=col, inplace=True)","6e307fde":"all_cols_but_nans = [v for v in data_features.columns if v not in ('Age', 'group_survival_rate', 'Survived')]\nage_exists = pd.notna(data_features['Age'])\nrfModel_age = RandomForestRegressor()\nrfModel_age.fit(data_features[age_exists][all_cols_but_nans], data_features[age_exists]['Age'])\n\ngeneratedAgeValues = rfModel_age.predict(X = data_features[~age_exists][all_cols_but_nans])\ndata_features.loc[~age_exists, 'Age'] = generatedAgeValues","fc5f0af2":"sns.distplot(data_features['Age']);","a0ddea14":"# data_features.to_pickle('train_and_test_features.pkl')","dc81218e":"# data_features = pd.read_pickle('train_and_test_features.pkl')\ngender_submission = pd.read_csv('..\/input\/titanic\/gender_submission.csv').set_index('PassengerId')\n\n# dropping columns which were found to have low feature importance (see bellow)\ncols_to_drop = ['Ticket_format_([A-Z]\\\\.){2,3} \\\\d{4,5}',\n 'Ticket_format_A[A-Z]?\/\\\\d\\\\.? \\\\d{3,5}',\n 'Ticket_format_SO?TON\/O[\\\\s\\\\.]?[2Q]\\\\. 3\\\\d{5,6}',\n 'Ticket_format_W\\\\.\/C\\\\. \\\\d{4,5}',\n 'Ticket_format_[A-Z]{1,5}\/[A-Z]{1,5} \\\\d{3,7}',\n 'Ticket_format_[A-Za-z]{1,2} \\\\d{4,6}','Embarked_Q', \n 'Cabin_format_([A-Z]\\\\d{2} ){1,3}[A-Z]\\\\d{2}', 'Pa_onboard', 'Sp_onboard', 'Title_small_Rare', \n 'Ch_onboard',  'Ticket_format_\\\\d{3,7}', 'Embarked_S']\ndata_features.drop(columns = (cols_to_drop), inplace=True)\ndata_features['Pclass'] = data_features['Pclass_3'] * 3 + data_features['Pclass_2'] * 2 + data_features['Pclass_1']\ndata_features.drop(columns = ['Pclass_1', 'Pclass_2', 'Pclass_3'], inplace=True)\ndata_features['age*pclass'] = data_features['Age'] * data_features['Pclass']\n\nCLASS_LABEL = 'Survived'\nRSEED = np.random.randint(100)\n\ndata_features['Age'] = data_features['Age'].fillna(data_features['Age'].mean())\ndata_features.drop(columns=['group_survival_rate'])\ntest_set = data_features[pd.isna(data_features[CLASS_LABEL])].copy()\ntrain_set = data_features[pd.notna(data_features[CLASS_LABEL])].copy()\n\ntrain_set[CLASS_LABEL] = train_set[CLASS_LABEL].astype(int)\nlabels = np.array(train_set.pop(CLASS_LABEL))\ntest_set.drop(columns=CLASS_LABEL, inplace=True)","cea4577f":"# 20% examples in test data\ntrain, cv, train_labels, cv_labels = train_test_split(train_set,\n                                         labels, \n                                         stratify = labels,\n                                         test_size = 0.2, \n                                         random_state = RSEED)","c71226f0":"features = list(train.columns)","61dbfa96":"model = RandomForestClassifier(n_estimators=50, \n                               random_state=RSEED, \n                               max_features = 'sqrt', max_depth=10, bootstrap=True)\n# Fit on training data\nmodel.fit(train, train_labels)","c5e3d3f1":"# Training predictions (to demonstrate overfitting)\ntrain_rf_predictions = model.predict(train)\ntrain_rf_probs = model.predict_proba(train)[:, 1]\n\n# Testing predictions (to determine performance)\nrf_predictions = model.predict(cv)\nrf_probs = model.predict_proba(cv)[:, 1]","c834cd0b":"def plot_model_roc(predictions, probs, train_predictions, train_probs, test_labels):  \n    \n    model_fpr, model_tpr, _ = roc_curve(test_labels, probs)\n    model_auc = np.round(roc_auc_score(test_labels, probs), 3)\n    \n    # Plot\n    plt.figure(figsize = (10, 10))\n    plt.plot([0, 1], [0, 1], 'b', label = 'baseline')\n    plt.plot(model_fpr, model_tpr, 'r', label = 'model (AUC = {})'.format(model_auc))\n    plt.legend();\n    plt.xlabel('False Positive Rate'); \n    plt.ylabel('True Positive Rate'); plt.title('ROC Curves');\n#     print(f'AUC : {model_auc}')\n#     print(confusion_matrix(test_labels, rf_predictions))\n    plt.show();\n\nplot_model_roc(rf_predictions, rf_probs, train_rf_predictions, train_rf_probs, cv_labels)","66a22d37":"print(f'Random Forest CV accuracy : {accuracy_score(cv_labels, rf_predictions)}')\nprint(f'Gender CV accuracy : {accuracy_score(cv_labels, 1-cv.Sex_male)}')","f816fcf4":"feature_names = np.r_[train_set.columns]\ntree_feature_importances = model.feature_importances_\nsorted_idx_rf = tree_feature_importances.argsort()\n\ny_ticks = np.arange(0, len(features))\nfig, ax = plt.subplots(figsize = (10, 10))\n# ax.figure(figsize = (16, 6))\nax.barh(y_ticks, tree_feature_importances[sorted_idx_rf])\nax.set_yticklabels(feature_names[sorted_idx_rf])\nax.set_yticks(y_ticks)\nax.set_title(\"Random Forest Feature Importances (MDI)\")\nfig.tight_layout()\nplt.show()","b219bee3":"permutation_imp_data = permutation_importance(model, cv, cv_labels, n_repeats=10,\n                                random_state=RSEED)\nsorted_idx_pid = permutation_imp_data.importances_mean.argsort()","0f4907f1":"fig, ax = plt.subplots(figsize = (10, 10))\nax.boxplot(permutation_imp_data.importances[sorted_idx_pid].T,\n           vert=False, labels=cv.columns[sorted_idx_pid])\nax.set_title(\"Permutation Importances (test set)\")\nfig.tight_layout()\nplt.show()","0c2a2609":"# Fit on training data\nmodel.fit(train_set, labels)","85d70816":"# Training predictions (to determine overfitting)\ntrain_rf_predictions = model.predict(train_set)\ntrain_rf_probs = model.predict_proba(train_set)[:, 1]\n\n# Testing predictions (to determine performance)\nrf_predictions = model.predict(test_set)\nrf_probs = model.predict_proba(test_set)[:, 1]","64ae0dc6":"prediction_set = test_set.copy()\nprediction_set['Survived'] = rf_predictions\nprediction_set = prediction_set[['Survived']]\nprediction_set.head()","c935f820":"confusion_matrix(prediction_set['Survived'], gender_submission['Survived'])","d0f75cf0":"prediction_set.to_csv('submission.csv')","7ccbd8f1":"MY_BEST_SCORE = 0.81339\nsubmissions = pd.read_csv('..\/input\/titanicpublicleaderboard\/titanic-publicleaderboard.csv')\nsub_max_scores = submissions.groupby('TeamId')['Score'].agg('max')\nsub_max_scores = sub_max_scores[(sub_max_scores>0.4) & (sub_max_scores<1)]\n\nscore_to_beat = scoreatpercentile(sub_max_scores, 90)\nprint('The score to beat is:', score_to_beat)\nprint('You beat the score!' if score_to_beat < MY_BEST_SCORE else 'You didn''t beat the score...')\nprint('Your percentile is:', np.round(percentileofscore(sub_max_scores, MY_BEST_SCORE),2),'%')","ca3449c2":"ax = sns.distplot(sub_max_scores, label='Score distribution');\nax.axvline(MY_BEST_SCORE, color='C1', label='My score')\nax.axvline(score_to_beat, color='grey', linestyle='--', label='Top 10%')\nplt.legend()\nplt.show();","5ab3d858":"An important feature which is 20% empty. Will be filled out later on by some regression method.","8d9fa6c1":"# Pre-assignment","98c44c34":"# Organizing features as numerical","61e8ee6e":"### Age Column:","03e11235":"### SibSp Column:\n#### Extract <ins>spouse onboard <\/ins> and <ins>siblings onboard <\/ins> ","8f7fcd51":"### Define our goal: reach a score in the top 10 percentile. ","11e73edf":"### Column SibSp:","26b53500":"### Cabin Column:","908ffa3b":"Find if a person is unmarried by their title","96d24f3f":"### Fare Column:\n\nThere's just one missing value so it seems fair to fix it with an ad-hoc solution.","29e13042":"Again, there are only two missing values. I'll just fill them up with the most common value. ","33d7493d":"# Submitting result","95edf8fa":"Using permutation importance can be better when there are both numerical and categorical features in the dataset, as the impurity-based feature importance can inflate the importance of numerical features (See [Permutation Importance vs Random Forest Feature Importance (MDI)](https:\/\/scikit-learn.org\/stable\/auto_examples\/inspection\/plot_permutation_importance.html))","0e4f7e00":"# Loading Data","8641eb1d":"# Imports","bc435c5c":"define dummy columns to be converted to numerical later on","382304c6":"We find just 5 cabin formats.","ec7cbc59":"### Survived Column:\n#### Extract <ins>group survival rate","5b8d1eeb":"# Looking at Feature Importance & Permutation Importance","08216fba":"### Column Parch:","c752d036":"Take the Fortune family for example: <br>\nWe can see how we were able to assign 4 children to each parent and 0 children to each of the children. ","16db6e2d":"This is the first feature that is problematic with leakage. \nThe feature is: for each person, look at the other people that came in the group with him (have the same ticket), and compute their average survival rate (not including the data of the person in question). \nIt's fine as far as leakage since this is Kaggle, and I actually don't have the labels of the test set. In a real-world situation it might be unrealistic to use such a feature. ","144a1d47":"### Name column:\n#### Extract the <ins>title<\/ins>, <ins>nickname<\/ins> and <ins>name inside parenthesis<\/ins>.","b1b50724":"### Find missing values","4dd81120":"# Feature Engineering","99757315":"### Fill in <ins>Age<\/ins> missing values with RandomForestRegressor","130e253d":"- First group each party by the ticket. \n- For each passenger count the number of passengers that could've been his\/her child (more than 13 years younger than said passenger).\n- The number of children onboard of a passenger is the minimum between the Parch column and the number of possible children. \n- The number of parents onboard of a passenger is then Parch (parents + children onboard) minus the number of children ob board.","86c6f6a1":"### Sex Column:\nJust transform to binary","dec1ac0b":"# Save dataset for model","4a64ca16":"Comparing our score with the gender submission","a6420377":"The SibSp column specifies the number of spouses\/siblings onboard. The rules for the `join` of husband and wife are:\n- Same name after cleaning title, nickname and parenthesis (e.g. \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\" is the wife of \"Futrelle, Mr. Jacques Heath\")\n- Are of opposite sex to each other. \n- Can't have titles suggesting they are unmarried (e.g. Miss). ","c1cefae8":"We find there are a few formats for the ticket column values. I didn't really dig deeper because the model didn't find the format to be a good feature but it could be interesting to find out how the ticket format is created.","19d6d9df":"### Parch Column:\n#### Extract <ins>children onboard <\/ins> and  <ins>parent onboard<\/ins>","27d6b5a2":"# Loading features, setting up train, test and CV","66f26b23":"Next we remove all columns which are boolean with more than 99% of the same value","d83f7142":"### Embarked Column:","80a8ff5b":"# Modeling - On Complete Train","4766f48c":"# Modeling - On CV","fe9a02a8":"### Column Ticket:\n#### Extract <ins>ticket format<\/ins>","b1d1ddbf":"evaluating our score as a percentile. ","3dd95e51":"Comparing our submission with the gender prediction as a sanity check. We don't expect too much variation."}}