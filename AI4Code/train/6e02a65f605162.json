{"cell_type":{"e0046ee3":"code","45f6a20d":"code","de645a5b":"code","5f888422":"code","658c4f6b":"code","e73e80cd":"code","b41158c3":"code","acf4ffe3":"code","b67abae4":"code","09dcf536":"code","32269ea0":"code","1b1d5a6a":"code","e6998b4f":"code","5a895d7f":"code","ae7c4b93":"code","313d6261":"code","98c45d42":"code","f688d4e2":"code","fd0e5bd8":"code","af90981f":"code","20bd082b":"code","5320f760":"markdown","8bd8b612":"markdown","c68594ff":"markdown","27e4baf9":"markdown","ad43e6c4":"markdown"},"source":{"e0046ee3":"import pandas as pd\n\nimport time\nimport torchvision\nimport torch.nn as nn\nfrom tqdm import tqdm_notebook as tqdm\n\nfrom PIL import Image, ImageFile\nfrom torch.utils.data import Dataset\nimport torch\nimport torch.optim as optim\nfrom torchvision import transforms\nfrom torch.optim import lr_scheduler\nimport os\nfrom torch.autograd import Variable\nfrom PIL import ImageOps \ndevice = torch.device(\"cuda:0\")\n# ImageFile.LOAD_TRUNCATED_IMAGES = True","45f6a20d":"torch.cuda.get_device_name()","de645a5b":"class RetinopathyDataset(Dataset):\n\n    def __init__(self, csv_file, transform, test=False):\n        self.test_ = test\n        self.transform = transform\n        self.data = pd.read_csv(csv_file)\n        self.data_test = pd.read_csv('..\/input\/aptos2019-blindness-detection\/test.csv')\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        if not self.test_:\n            img_name = os.path.join('..\/input\/aptos2019-blindness-detection\/train_images', self.data.loc[idx, 'id_code'] + '.png')\n            image = Image.open(img_name)\n            image = ImageOps.equalize(image)\n            label = torch.tensor(self.data.loc[idx, 'diagnosis'])\n            return {'image': self.transform(image),\n                    'labels': label\n                    }\n        else:\n            img_name = os.path.join('..\/input\/aptos2019-blindness-detection\/test_images', self.data_test.loc[idx, 'id_code'] + '.png')\n            image = Image.open(img_name)\n            image = ImageOps.equalize(image)\n            return  self.transform(image)","5f888422":"model = torchvision.models.resnext101_32x8d(pretrained=False)\nmodel.load_state_dict(torch.load(\"..\/input\/model\/resnext101_32x8d-8ba56ff5.pth\"))","658c4f6b":"num_features = model.fc.in_features\nnum_features","e73e80cd":"num_features = model.fc.in_features\nmodel.fc = nn.Sequential(\n                          nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n                          nn.Dropout(p=0.25),\n                          nn.Linear(in_features=2048, out_features=2048, bias=True),\n                          nn.ReLU(),\n                          nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n                          nn.Dropout(p=0.5),\n                          nn.Linear(in_features=2048, out_features=5, bias=True),\n                         )\n\nmodel = model.to(device)","b41158c3":"model.eval()","acf4ffe3":"for name, param in model.named_parameters():\n    print(name, param.requires_grad)","b67abae4":"train_transform = transforms.Compose([\n    transforms.RandomCrop(250,250),\n    transforms.RandomChoice(\n        [\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomVerticalFlip(),\n        ]\n    ),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\ntest_dataset = RetinopathyDataset(csv_file='..\/input\/aptos2019-blindness-detection\/sample_submission.csv',\n                                      transform=train_transform)","09dcf536":"train_dataset = RetinopathyDataset(csv_file='..\/input\/aptos2019-blindness-detection\/train.csv', transform=train_transform)\ndata_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n\noptimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\nscheduler = lr_scheduler.StepLR(optimizer, step_size=10)","32269ea0":"int(len(data_loader))","1b1d5a6a":"def accuracy_score(output, labels):\n    score = 0\n    for c, cc in zip(output, labels):\n        if c == cc:\n            score += 1\n    return score\/len(output)","e6998b4f":"def train():\n    since = time.time()\n    criterion = nn.criterion = nn.CrossEntropyLoss()\n    num_epochs = 50\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n        scheduler.step()\n        model.train()\n        running_loss = 0.0\n        tk0 = tqdm(data_loader, total=int(len(data_loader)))\n        counter = 0\n        for bi, d in enumerate(tk0):\n            inputs = d[\"image\"]\n            labels = d[\"labels\"].view(-1, 1)\n            inputs = inputs.to(device)\n            labels = labels.to(device, dtype=torch.long)\n            optimizer.zero_grad()\n            with torch.set_grad_enabled(True):\n                outputs = model(inputs)\n                loss = criterion(outputs, labels.squeeze_())\n                loss.backward()\n                optimizer.step()\n            running_loss += loss.item() * inputs.size(0)\n            counter += 1\n            tk0.set_postfix(loss=(running_loss \/ (counter * data_loader.batch_size)))\n        epoch_loss = running_loss \/ len(data_loader)\n        \n        print('Training Loss: {:.4f}'.format(epoch_loss))\n        print('Epoch Accuracy: ', accuracy_score(outputs.argmax(1), labels))\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed \/\/ 60, time_elapsed % 60))\n    torch.save(model.state_dict(), \"model.bin\")","5a895d7f":"train()","ae7c4b93":"torch.save(model.state_dict(), '..\/input\/mode.pth')","313d6261":"test_dataset = RetinopathyDataset(csv_file='..\/input\/aptos2019-blindness-detection\/test.csv', transform=train_transform, test=True)\ntest_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)","98c45d42":"result = []\n\ntk0 = tqdm(test_data_loader, total=int(len(test_data_loader)))\n\nfor a in range(2):\n    result_i = []\n    for d in enumerate(tk0):\n        inputs = Variable(d[1])\n        inputs = inputs.to(device, dtype=torch.float)\n        with torch.set_grad_enabled(False):\n            outputs = model(inputs)\n            for pred in outputs.argmax(1).tolist():\n                result_i.append(pred)\n    result.append(result_i)","f688d4e2":"res = []\nfor i in range(len(result[0])):\n    for ii in range(len(result)):\n        a = []\n        a.append(result[ii][i])\n        res.append(max(set(a), key=a.count))","fd0e5bd8":"sample = pd.read_csv(\"..\/input\/aptos2019-blindness-detection\/sample_submission.csv\")","af90981f":"sample.diagnosis = res","20bd082b":"sample.to_csv(\"submission.csv\", index=False)","5320f760":"**defining dataset**","8bd8b612":"**Defining some transformations**","c68594ff":"**trainining**","27e4baf9":"**Hyperparameters and optimizer**","ad43e6c4":"**Replacing classifier layer**"}}