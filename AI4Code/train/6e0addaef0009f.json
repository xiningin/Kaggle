{"cell_type":{"8252c836":"code","3bbde0cb":"code","bd7972dc":"code","5fd17566":"code","aae658df":"code","1eb31836":"code","efbb0fcb":"code","8a2d219c":"code","b48f92fb":"code","c541d694":"code","1357fb81":"code","89c2af9b":"code","819704ca":"code","8dbc4e61":"code","1e9377c3":"code","b4659167":"code","eb8d95e6":"code","7129b77a":"code","b40a0a39":"code","5f4c035f":"code","6d5820fb":"code","4bb35e9e":"code","6d7fc083":"code","63ba8199":"code","4591a0fd":"code","0f476675":"code","f305816c":"code","d400a9f8":"code","c310c659":"code","8339c55d":"code","4cd76aa5":"code","a319fdea":"code","96355b4c":"code","ab11d75c":"code","c194c666":"code","5932acdd":"code","cf1a9172":"markdown","e74ae0f3":"markdown","87361fc1":"markdown","71ca50ba":"markdown","582e0697":"markdown","f085df39":"markdown","8dc8c6cb":"markdown","5bca28bf":"markdown","5d224aed":"markdown","6e67157e":"markdown","d2188ff5":"markdown","93f3a2f6":"markdown","a10a5c80":"markdown","32a69538":"markdown","4d6fc1ba":"markdown","b95fcaa1":"markdown","a3f4ac79":"markdown","95f23fb4":"markdown","44689579":"markdown","6f5ca974":"markdown","77c7d342":"markdown","1f856eac":"markdown","69f0a83d":"markdown","73c302de":"markdown","17f2f759":"markdown","f03ad6a1":"markdown","66c8bc8a":"markdown","0184b95d":"markdown","9a53641b":"markdown","efa9d95f":"markdown"},"source":{"8252c836":"# Importing filterwarnings to ignore warning messages\nimport warnings\nwarnings.filterwarnings('ignore')","3bbde0cb":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\nfrom matplotlib import style\n#style.use('dark_background')\nplt.style.use('seaborn-dark')\nimport matplotlib.image as mpimg\nfrom matplotlib.offsetbox import AnnotationBbox, OffsetImage\n\n# To perform K-means clustering\nfrom sklearn.cluster import KMeans","bd7972dc":"iris=pd.read_csv(\"..\/input\/iris\/Iris.csv\")\n\niris.head()","5fd17566":"#summary of all the numeric columns in the dataset\niris.describe()","aae658df":"##Determining the number of rows and columns\niris.shape","1eb31836":"#Datatypes of each column\niris.info()","efbb0fcb":"iris.isnull().sum()","8a2d219c":"iris.Species.value_counts()","b48f92fb":"tmp = iris.drop('Id', axis=1)\ng = sns.pairplot(tmp, hue='Species')\nplt.show()","c541d694":"plt.figure(figsize=(20, 6))\n\ncols = ['yellowgreen', 'lightcoral','gold']\nplt.subplot(1,2,1)\nsns.countplot('Species',data=iris, palette='Set1')\nplt.title('Iris Species Count',fontweight=\"bold\", size=20)\nplt.xticks(fontweight=\"bold\")\nplt.subplot(1,2,2)\niris['Species'].value_counts().plot.pie(explode=[0.05,0.05,0.1],autopct='%1.1f%%',shadow=True, colors=cols)\nplt.title('Iris Species Count',fontweight=\"bold\", size=20)\nplt.xticks(fontweight=\"bold\")\nplt.show()","1357fb81":"plt.figure(figsize=(12,10))\nsns.jointplot(x='SepalLengthCm',y='SepalWidthCm',data=iris)\nplt.title('Sepal Length vs Sepal Width',fontweight=\"bold\", size=20)\nplt.show()","89c2af9b":"fig=sns.jointplot(x='SepalLengthCm',y='SepalWidthCm',kind='hex',data=iris)\nplt.title('Sepal Length vs Sepal Width',fontweight=\"bold\", size=20)\nplt.show()","819704ca":"sns.jointplot(\"SepalLengthCm\", \"SepalWidthCm\", data=iris, kind=\"kde\",space=0,color='g')\nplt.title('Sepal Length vs Sepal Width',fontweight=\"bold\", size=20)\nplt.show()","8dbc4e61":"fig = iris[iris.Species=='Iris-setosa'].plot(kind='scatter',x='SepalLengthCm',y='SepalWidthCm',color='orange', label='Setosa')\niris[iris.Species=='Iris-versicolor'].plot(kind='scatter',x='SepalLengthCm',y='SepalWidthCm',color='blue', label='versicolor',ax=fig)\niris[iris.Species=='Iris-virginica'].plot(kind='scatter',x='SepalLengthCm',y='SepalWidthCm',color='green', label='virginica', ax=fig)\nfig.set_xlabel(\"Sepal Length\")\nfig.set_ylabel(\"Sepal Width\")\nfig.set_title(\"Sepal Length VS Width\", fontweight='bold',size=20)\nfig=plt.gcf()\nfig.set_size_inches(10,6)\nplt.show()","1e9377c3":"fig =iris[iris.Species=='Iris-setosa'].plot.scatter(x='PetalLengthCm',y='PetalWidthCm',color='orange', label='Setosa')\niris[iris.Species=='Iris-versicolor'].plot.scatter(x='PetalLengthCm',y='PetalWidthCm',color='blue', label='versicolor',ax=fig)\niris[iris.Species=='Iris-virginica'].plot.scatter(x='PetalLengthCm',y='PetalWidthCm',color='green', label='virginica', ax=fig)\nfig.set_xlabel(\"Petal Length\")\nfig.set_ylabel(\"Petal Width\")\nfig.set_title(\" Petal Length VS Width\")\nfig=plt.gcf()\nfig.set_size_inches(10,6)\nplt.show()","b4659167":"plt.figure(figsize=(15,10))\nplt.subplot(2,2,1)\nsns.violinplot(x='Species',y='PetalLengthCm',data=iris,palette='husl')\nplt.subplot(2,2,2)\nsns.violinplot(x='Species',y='PetalWidthCm',data=iris, palette='Set2')\nplt.subplot(2,2,3)\nsns.violinplot(x='Species',y='SepalLengthCm',data=iris,palette='husl')\nplt.subplot(2,2,4)\nsns.violinplot(x='Species',y='SepalWidthCm',data=iris,palette='Set2')\nplt.show()","eb8d95e6":"plt.figure(figsize=(10,6)) \nsns.heatmap(iris.corr(),annot=True,fmt=\"f\",cmap=\"RdYlGn\")\nplt.show()","7129b77a":"iris.drop('Species', axis =1, inplace = True)\n","b40a0a39":"iris.head()","5f4c035f":"feature = iris.columns[1:]\nfor i in enumerate(feature):\n    print(i)","6d5820fb":"plt.figure(figsize = (15,10))\nfeature = iris.columns[1:]\nfor i in enumerate(feature):\n    plt.subplot(2,2, i[0]+1)\n    sns.distplot(iris[i[1]],color='crimson')","4bb35e9e":"plt.figure(figsize = (10,10))\nfeature = iris.columns[:-1]\nfor i in enumerate(feature):\n    plt.subplot(2,2, i[0]+1)\n    sns.boxplot(iris[i[1]])","6d7fc083":"q1 = iris['SepalWidthCm'].quantile(0.01)\nq4 = iris['SepalWidthCm'].quantile(0.99)\n\niris['SepalWidthCm'][iris['SepalWidthCm']<= q1] = q1\niris['SepalWidthCm'][iris['SepalWidthCm']>= q4] = q4","63ba8199":"# Check the hopkins\n\n#Calculating the Hopkins statistic\nfrom sklearn.neighbors import NearestNeighbors\nfrom random import sample\nfrom numpy.random import uniform\nimport numpy as np\nfrom math import isnan\n \ndef hopkins(X):\n    d = X.shape[1]\n    #d = len(vars) # columns\n    n = len(X) # rows\n    m = int(0.1 * n) \n    nbrs = NearestNeighbors(n_neighbors=1).fit(X.values)\n \n    rand_X = sample(range(0, n, 1), m)\n \n    ujd = []\n    wjd = []\n    for j in range(0, m):\n        u_dist, _ = nbrs.kneighbors(uniform(np.amin(X,axis=0),np.amax(X,axis=0),d).reshape(1, -1), 2, return_distance=True)\n        ujd.append(u_dist[0][1])\n        w_dist, _ = nbrs.kneighbors(X.iloc[rand_X[j]].values.reshape(1, -1), 2, return_distance=True)\n        wjd.append(w_dist[0][1])\n \n    H = sum(ujd) \/ (sum(ujd) + sum(wjd))\n    if isnan(H):\n        print(ujd, wjd)\n        H = 0\n \n    return H","4591a0fd":"hopkins(iris.drop('Id', axis = 1))","0f476675":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ndf1 = scaler.fit_transform(iris.drop('Id', axis = 1))\ndf1","f305816c":"df1 = pd.DataFrame(df1, columns = iris.columns[1:])\ndf1.head()","d400a9f8":"import sklearn\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nssd=[]\nfor k in range(2,11):\n  kmean=KMeans(n_clusters=k).fit(df1)\n  ssd.append([k,kmean.inertia_])\n\nplt.plot(pd.DataFrame(ssd)[0],pd.DataFrame(ssd)[1])\nplt.title('The elbow method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS') # Within cluster sum of squares\nplt.show()","c310c659":"kmeans = KMeans(n_clusters = 3, init = 'k-means++',\n                max_iter = 300, n_init = 10, random_state = 0)\nx = iris.iloc[:, [1, 2, 3 , 4]].values\ny_kmeans = kmeans.fit_predict(x)\ny_kmeans","8339c55d":"df_kmean = iris.copy()","4cd76aa5":"label  = pd.DataFrame(y_kmeans, columns= ['label'])\nlabel.head()","a319fdea":"df_kmean = pd.concat([df_kmean, label], axis =1)\ndf_kmean.head()","96355b4c":"df_kmean.label.value_counts()","ab11d75c":"# Visualising the clusters - On the first two columns\nplt.figure(figsize=(10,6))\nplt.scatter(x[y_kmeans == 0, 0], x[y_kmeans == 0, 1], \n            s = 100, c = 'red', label = 'Iris-setosa')\nplt.scatter(x[y_kmeans == 1, 0], x[y_kmeans == 1, 1], \n            s = 100, c = 'blue', label = 'Iris-versicolour')\nplt.scatter(x[y_kmeans == 2, 0], x[y_kmeans == 2, 1],\n            s = 100, c = 'green', label = 'Iris-virginica')\n\n\n# Plotting the centroids of the clusters\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:,1], \n            s = 100, c = 'yellow', label = 'Centroids')\nplt.legend()\nplt.show()","c194c666":"# Making sense out of the clsuters\n\ndf_kmean.drop('Id', axis = 1).groupby('label').mean().plot(kind = 'bar')\nplt.show()","5932acdd":"df_kmean.drop(['Id', 'SepalLengthCm', 'SepalWidthCm'], axis = 1).groupby('label').mean().plot(kind = 'bar')\nplt.show()","cf1a9172":"## <font color=blue> Clsuter Profiling","e74ae0f3":"Jointplot is seaborn library specific and can be used to quickly visualize and analyze the relationship between two variables and describe their individual distributions on the same plot.","87361fc1":"### <font color=blue> Let's take a look at the Probability Density","71ca50ba":"- We can see that Sepal Length and Sepal Width columns are normally distributed. And Petal Length and Petal Width columns have skewness in the data\n- We will use Petal_length and petal_width for cluster profiling","582e0697":"### <font color=blue>Finding the Optimal Number of Clusters for KMeans Clustering :\u00b6\n### <font color=brown>Elbow Method (SSD - Sum of Squared Distance)","f085df39":"#### <font color=green> This data set has three varities of Iris plant.","8dc8c6cb":"## <font color=blue>K-Mean Clustering","5bca28bf":"## <font color=blue> 1. Loading the necessary libraries\n","5d224aed":"<font color=green>With Petal characteristics we can easily classify the species but there is a little thin line between the virginica and versicolor","6e67157e":"- Cluster 0 is having high sepal length and petal length\n- CLuster 1 is having low petal width and petal length","d2188ff5":"<font color=green>We can clearly see that sepal characteristics differentiate setosa but not versicolor and virginica","93f3a2f6":"The violinplot shows density of the length and width in the species. The thinner part denotes that there is less density whereas the fatter part conveys higher density","a10a5c80":"## <font color=blue>[](http:\/\/) Problem Statement\n ###  From the given \u2018Iris\u2019 dataset, predict the optimum number of clusters and represent it visually","32a69538":"<font color=green>You can clearly see why it is called 'The elbow method' from the above graph, the optimum clusters is where the elbow occurs. This is when the within cluster sum of squares (WCSS) doesn't decrease significantly with every iteration.\n\nFrom this we choose the number of clusters as '3'.","4d6fc1ba":"### <font color=blue>Let's visualize the data with a scatter plots based on Sepal and Petal width and length","b95fcaa1":"## <font color=blue> 3. Data Visualization","a3f4ac79":"#### <font color=green> We can see that there are no missing values in the dataset","95f23fb4":"## <font color=blue>Heatmap","44689579":"![image.png](attachment:image.png)","6f5ca974":"#   K- Means Clustering","77c7d342":"<font color=green>We can see that the value is between {0.8, ..., 0.99}, so the dataset has a high tendency to cluster","1f856eac":"### <font color=blue> Outlier Treatment","69f0a83d":"## <font color=blue> 2. Reading and Inspection","73c302de":"### <font color=blue> Scaling","17f2f759":"## <font color=blue>Clustering","f03ad6a1":"### <font color=blue> Jointplot","66c8bc8a":"- <font color=green> After graphing the features in a pair plot, it is clear that the relationship between pairs of features of a iris-setosa (in blue) is distinctly different from those of the other two species.\n- <font color=green>There is some overlap in the pairwise relationships of the other two species, iris-versicolor (brown) and iris-virginica (green).\n","0184b95d":"### <font color=blue>  2.1 Checking missing values","9a53641b":"- <font color=green>Here the frequency of the observation is plotted.In this case we are plotting the frequency of the three species in the Iris Dataset\n- <font color=green> We can see that there are 50 samples each of all the Iris Species in the data set.","efa9d95f":"- <font color=green> We can see that Cluster 0 is having 38 Data points\n- <font color=green>Cluster 1 is having 50 data points\n- <font color=green>Cluster 2 is having 62 data points\n\n"}}