{"cell_type":{"ce6f247f":"code","3bee93ec":"code","e14f80a0":"code","53cf22e4":"code","0f894ea7":"code","1710a0bb":"code","f194d1e6":"code","5d024faa":"code","0a3e69dd":"code","ae721ea1":"code","cb3df255":"code","9330507e":"code","50547d5b":"code","67ce29db":"code","6bff99ab":"code","922037a3":"code","76bc1606":"code","47461e54":"code","65913f99":"code","baad274d":"markdown"},"source":{"ce6f247f":"import numpy as np\nimport matplotlib.image as mpimg \nimport matplotlib.pyplot as plt \nimport os,sys\nimport tensorflow as tf\nfrom tensorflow.keras.utils import Sequence\nfrom tensorflow.python.tpu import datasets\nfrom tensorflow.python.data.ops import dataset_ops","3bee93ec":"from PIL import Image, ImageFilter, ImageEnhance","e14f80a0":"np.random.seed(16)\ntf.random.set_seed(16)","53cf22e4":"import time \n# code found in https:\/\/www.kaggle.com\/danmoller\/make-best-use-of-a-kernel-s-limited-uptime-keras\n#let's also import the abstract base class for our callback\nfrom keras.callbacks import Callback\n\n#defining the callback\nclass TimerCallback(Callback):\n    \n    def __init__(self, maxExecutionTime, byBatch = False, on_interrupt=None):\n        \n# Arguments:\n#     maxExecutionTime (number): Time in minutes. The model will keep training \n#                                until shortly before this limit\n#                                (If you need safety, provide a time with a certain tolerance)\n\n#     byBatch (boolean)     : If True, will try to interrupt training at the end of each batch\n#                             If False, will try to interrupt the model at the end of each epoch    \n#                            (use `byBatch = True` only if each epoch is going to take hours)          \n\n#     on_interrupt (method)          : called when training is interrupted\n#         signature: func(model,elapsedTime), where...\n#               model: the model being trained\n#               elapsedTime: the time passed since the beginning until interruption   \n\n        \n        self.maxExecutionTime = maxExecutionTime * 60\n        self.on_interrupt = on_interrupt\n        \n        #the same handler is used for checking each batch or each epoch\n        if byBatch == True:\n            #on_batch_end is called by keras every time a batch finishes\n            self.on_batch_end = self.on_end_handler\n        else:\n            #on_epoch_end is called by keras every time an epoch finishes\n            self.on_epoch_end = self.on_end_handler\n    \n    \n    #Keras will call this when training begins\n    def on_train_begin(self, logs):\n        self.startTime = time.time()\n        self.longestTime = 0            #time taken by the longest epoch or batch\n        self.lastTime = self.startTime  #time when the last trained epoch or batch was finished\n    \n    \n    #this is our custom handler that will be used in place of the keras methods:\n        #`on_batch_end(batch,logs)` or `on_epoch_end(epoch,logs)`\n    def on_end_handler(self, index, logs):\n        \n        currentTime      = time.time()                           \n        self.elapsedTime = currentTime - self.startTime    #total time taken until now\n        thisTime         = currentTime - self.lastTime     #time taken for the current epoch\n                                                               #or batch to finish\n        \n        self.lastTime = currentTime\n        \n        #verifications will be made based on the longest epoch or batch\n        if thisTime > self.longestTime:\n            self.longestTime = thisTime\n        \n        \n        #if the (assumed) time taken by the next epoch or batch is greater than the\n            #remaining time, stop training\n        remainingTime = self.maxExecutionTime - self.elapsedTime\n        if remainingTime < self.longestTime:\n            \n            self.model.stop_training = True  #this tells Keras to not continue training\n            print(\"\\n\\nTimerCallback: Finishing model training before it takes too much time. (Elapsed time: \" + str(self.elapsedTime\/60.) + \" minutes )\\n\\n\")\n            \n            #if we have passed the `on_interrupt` callback, call it here\n            if self.on_interrupt is not None:\n                self.on_interrupt(self.model, self.elapsedTime)\n","0f894ea7":"normal = os.listdir('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/train\/NORMAL\/')\ndiseased = os.listdir('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/train\/PNEUMONIA\/')\nnormal = ['\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/train\/NORMAL\/'+i for i in normal]\ndiseased = ['\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/train\/PNEUMONIA\/'+i for i in diseased]\nfile_list_train = np.concatenate([normal,diseased])","1710a0bb":"normal = os.listdir('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/test\/NORMAL\/')\ndiseased = os.listdir('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/test\/PNEUMONIA\/')\nnormal = ['\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/test\/NORMAL\/'+i for i in normal]\ndiseased = ['\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/test\/PNEUMONIA\/'+i for i in diseased]\nfile_list_test = np.concatenate([normal,diseased])","f194d1e6":"from sklearn.preprocessing import scale\nfrom multiprocessing import Pool\nfrom functools import partial\nimport gc\n\nclass Data_generator(Sequence):\n\n    def __init__(self,file_list,batch_size,shuffle=False):\n        self.files = file_list\n        if shuffle:\n            np.random.shuffle(file_list)\n        self.batch_size = batch_size\n        self.files_split = np.array_split(self.files,np.ceil(len(self.files)\/self.batch_size))\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        length = len(self.files_split)\n        return length\n    \n    def __getitem__(self,index):\n        list_IDs_temp = self.files_split[index]\n\n        X, Y = self.__data_generation(list_IDs_temp)\n        \n        return X,Y\n\n\n    def on_epoch_end(self):\n        self.indexes = np.arange(len(self.files_split))\n\n    def __data_generation(self,self_IDs_temp):\n        image1 = []\n        image2 = []\n        image3 = []\n        image4 = []\n        labels = []\n            \n        for i in self_IDs_temp:\n            im = Image.open(i)\n            enh = ImageEnhance.Contrast(im)\n            enh = enh.enhance(1.8)\n            enh = enh.resize((1000,800))\n            enh = enh.convert(mode='L')\n            \n            for k in range(2):\n                for j in range(2):\n                    left = k*1000\/2\n                    top = j*800\/2\n                    right = (k+1) * 1000\/2\n                    bottom = (j+1)*800\/2\n                    new_image = enh.crop((left,top,right,bottom))\n                    if (k==0)&(j==0):\n                        image1.append(np.vstack(np.array_split(scale(list(new_image.getdata())),400)).reshape(500,400))\n                    elif (k==0)&(j==1):\n                        image2.append(np.vstack(np.array_split(scale(list(new_image.getdata())),400)).reshape(500,400))\n                    elif (k==1)&(j==0):\n                        image3.append(np.vstack(np.array_split(scale(list(new_image.getdata())),400)).reshape(500,400))\n                    else:\n                        image4.append(np.vstack(np.array_split(scale(list(new_image.getdata())),400)).reshape(500,400))\n            \n            if ('virus' in i) or ('bacteria' in i):\n                labels.append(0)\n            else:\n                labels.append(1)\n            \n                \n        image1 = np.array(image1)\n        image2 = np.array(image2)\n        image3 = np.array(image3)\n        image4 = np.array(image4)\n        labels = np.array(labels)\n        gc.collect()\n        \n        return [image1,image2,image3,image4],labels\n","5d024faa":"import tensorflow.keras\nfrom tensorflow.keras import initializers\nfrom tensorflow.keras.models import Sequential,load_model, Model\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Input, concatenate, Concatenate, Lambda, ELU,Activation, ZeroPadding2D\nfrom tensorflow.keras.layers import SeparableConv2D, MaxPooling2D, GaussianNoise, Conv2D, GlobalAveragePooling2D\nfrom tensorflow.keras.layers import LeakyReLU, SimpleRNN, GRU, LSTM, Reshape\nfrom tensorflow.keras import regularizers\n","0a3e69dd":"input1 = Input(shape=(500,400))\ninput2 = Input(shape=(500,400))\ninput3 = Input(shape=(500,400))\ninput4 = Input(shape=(500,400))\n\nfilters = 64\n\n\nCNN1 = LSTM(filters)(input1)\nCNN2 = LSTM(filters)(input2)\nCNN3 = LSTM(filters)(input3)\nCNN4 = LSTM(filters)(input4)\n\nmodel = Concatenate(axis=-1)([CNN1,CNN2,CNN3,CNN4])\n\nmodel = Dense(32)(model)\nmodel = LeakyReLU()(model)\n\npredictions = Dense(1, activation='sigmoid',kernel_regularizer = regularizers.l1(0.1))(model)\n\nmodel = Model(inputs = [input1,input2,input3,input4], outputs=[predictions])\n        \nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',tensorflow.keras.metrics.AUC()])","ae721ea1":"best_model = tensorflow.keras.callbacks.ModelCheckpoint('output_model.h5',\n                                             monitor='val_accuracy',\n                                             save_best_only=True,\n                                             save_weights_only=False,\n                                             mode='max')\n\nhistory = model.fit_generator(Data_generator(file_list=file_list_train,batch_size = 5,shuffle=True),\n                              epochs = 5,\n                              validation_data=Data_generator(file_list_test,4),\n                              callbacks = [best_model,TimerCallback(330)],\n                              use_multiprocessing = True,\n                              workers = 5)","cb3df255":"from keras.models import save_model\nsave_model(model,filepath='model.h5')","9330507e":"normal = os.listdir('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/val\/NORMAL\/')\ndiseased = os.listdir('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/val\/PNEUMONIA\/')\nnormal = ['\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/val\/NORMAL\/'+i for i in normal]\ndiseased = ['\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/val\/PNEUMONIA\/'+i for i in diseased]\nfile_list_val = np.concatenate([normal,diseased])","50547d5b":"model1 = load_model('\/kaggle\/working\/output_model.h5',compile=False)\nmodel1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',tensorflow.keras.metrics.AUC()])","67ce29db":"from sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import StratifiedKFold","6bff99ab":"recall0 = []\nrecall1 = []\ncutoff = np.arange(0.1,0.51,0.01)\n\nvalues = []\nfor i in file_list_test:\n    if ('bacteria' in i) or ('virus' in i):\n        values.append(0)\n    else:\n        values.append(1)\n        \nskf = StratifiedKFold(n_splits=5)\n\nfor cut in cutoff:\n    print(cut)\n    r1 = 0\n    r2 = 0\n    for train_index,test_index in skf.split(file_list_test,values):\n        pred = model1.predict_generator(Data_generator(file_list_test[test_index],5))\n        values_pred = []\n   \n        for i in pred:\n            if i < cut:\n                values_pred.append(0)\n            else:\n                values_pred.append(1)\n        cm = confusion_matrix(np.array(values)[test_index],values_pred)\n        tp,fn,fp,tn = cm.flatten()\n        r1 += tp\/(tp+fn)\n        r2 += tn\/(tn+fp)\n    recall0.append(r1\/5)\n    recall1.append(r2\/5)","922037a3":"difference = [abs(i-j) for i,j in zip(recall0,recall1)]\ncutoff_value = cutoff[np.argmin(difference)]","76bc1606":"plt.figure()\nplt.plot(cutoff,recall0,label='Pneumonia')\nplt.plot(cutoff,recall1,label='Normal')\nplt.xlabel('Cutoff')\nplt.ylabel('Recall')\nplt.legend()\nplt.savefig('recall_plot')","47461e54":"pred = model1.predict_generator(Data_generator(file_list_test,5))\n\nvalues = []\nfor i in file_list_test:\n    if ('bacteria' in i) or ('virus' in i):\n        values.append(0)\n    else:\n        values.append(1)\nvalues_pred = []\nfor i in pred:\n    if i < cutoff_value:\n        values_pred.append(0)\n    else:\n        values_pred.append(1)\n        ","65913f99":"tp,fn,fp,tn = confusion_matrix(y_true=values,y_pred=values_pred).flatten()\nsensitivity = tp\/(tp+fn)\nspecificity = tn\/(tn+fp)\nprint('tp:',tp)\nprint('tn:',tn)\nprint('fp:',fp)\nprint('fn:',fn)\nprint('Sensitivity: ', sensitivity)\nprint('Specificity: ', specificity)\nprint('Accuracy: ', (tp+tn)\/len(values))","baad274d":"## Results"}}