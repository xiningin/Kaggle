{"cell_type":{"90491692":"code","4b9d13f6":"code","709efe4a":"code","7f5adcd3":"code","b42d2d04":"code","0b99baeb":"code","f6f04bb3":"code","1bad7a8a":"code","a6fc2227":"code","fee735cf":"code","28f21a6c":"code","b2bab6e1":"code","9f1c9657":"code","73087a6a":"code","dbb36b62":"code","fc3e74b1":"code","63794f3c":"code","56af7560":"code","bd430865":"code","d67a0579":"code","aa9bdfdc":"code","ec671de9":"markdown","b2122b6b":"markdown","7e320a86":"markdown","4a24abf5":"markdown","e2a5537c":"markdown","b1ef79fe":"markdown","b7088e46":"markdown","d6bbff89":"markdown","29f8aab2":"markdown","79c28c43":"markdown","e7c3568f":"markdown","7188f772":"markdown","57d8651f":"markdown","e318295b":"markdown","73c2cbd0":"markdown","1e672613":"markdown"},"source":{"90491692":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import RobustScaler\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.feature_selection import mutual_info_classif, SelectPercentile\nfrom sklearn.model_selection import  cross_val_score,cross_validate, train_test_split, cross_val_predict\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom lightgbm import LGBMClassifier\n\nfrom sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix, accuracy_score, f1_score, recall_score, precision_score, make_scorer\n\nfrom sklearn.compose import ColumnTransformer\n# from imblearn.pipeline import Pipeline\n# from imblearn import FunctionSampler\nfrom sklearn.pipeline import Pipeline\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","4b9d13f6":"!pip install pandas_flavor","709efe4a":"from pandas_flavor import register_dataframe_method,register_series_method\nfrom IPython.core.display import display, HTML\n\n@register_dataframe_method\ndef get_missing(df):        \n    tmp =  sorted(\n                [(col , str(df[col].dtypes) ,df[col].isna().sum(), np.round( df[col].isna().sum() \/ len(df) * 100,2) ) for col in df.columns if df[col].isna().sum() !=0 ],\n                key = lambda x: x[2], reverse=True)\n    \n    return pd.DataFrame(tmp).rename({0:\"Feature\", 1:\"dtype\", 2:\"count\", 3:\"percent\"},axis=1)  \n\n@register_dataframe_method\ndef get_numeric_df(df):\n    return df.select_dtypes(np.number)\n\n@register_dataframe_method\ndef get_numeric_cols(df):\n    return list(df.select_dtypes(np.number).columns)\n\n@register_dataframe_method\ndef get_object_cols(df):\n    return list(df.select_dtypes(exclude = np.number).columns)\n\n@register_dataframe_method\ndef get_object_df(df):\n    return df.select_dtypes(exclude = np.number)\n\n@register_dataframe_method\ndef get_discrete_cols(df,thresold):\n#     thresold in number of unique values\n    return [feature for feature in df.columns if len(df[feature].unique()) < thresold]\n\n@register_dataframe_method\ndef get_discrete_df(df,thresold):\n#     thresold in number of unique values\n    return df[ get_discrete_cols(df=df,thresold=thresold) ]\n\n@register_dataframe_method\ndef describe_discrete_cols(df,thresold, ascending=True):\n    \n    values = pd.DataFrame()\n    \n    for col in df.get_discrete_cols(thresold=thresold):\n        values[col] = [df[col].unique(), df[col].nunique()]\n        \n    return values.transpose().sort_values(by = 1,ascending=ascending).rename({0:\"Values\",1:\"cardinality\"},axis=1)\n\n@register_dataframe_method\ndef get_continuous_cols(df,thresold):\n    #     thresold in number of unique values\n    return [feature for feature in df.columns if len(df[feature].unique()) >= thresold]\n\n@register_dataframe_method\ndef get_continuous_df(df,thresold):\n    #     thresold in number of unique values\n    return df[ get_continuous_cols(df=df,thresold=thresold) ]\n\n\n@register_dataframe_method\ndef describe_continuous_cols(df,thresold, ascending=True):\n    return df[df.get_continuous_cols(thresold=thresold)].describe().T\n\n@register_dataframe_method\ndef dtypes_of_cols(df):\n    return pd.DataFrame(df.dtypes).reset_index().rename(columns={'index':\"Columns\",0: \"dtype\"})\n\n\n@register_series_method\ndef IQR_range(df):\n    if isinstance(df, pd.Series):\n        Q3 = np.quantile(df, 0.75)\n        Q1 = np.quantile(df, 0.25)\n        IQR = Q3 - Q1\n\n        lower_range = Q1 - 1.5 * IQR\n        upper_range = Q3 + 1.5 * IQR\n\n        return (lower_range,upper_range)\n    else:\n        assert False, \"df must be of type pandas.Series\"\n        \n@register_dataframe_method\ndef IQR_range(df):\n    if isinstance(df, pd.DataFrame):\n        cols = df.get_numeric_cols()\n        features = {}\n        for i in cols:\n            Q3 = np.quantile(df[i], 0.75)\n            Q1 = np.quantile(df[i], 0.25)\n            IQR = Q3 - Q1\n\n            lower_range = Q1 - 1.5 * IQR\n            upper_range = Q3 + 1.5 * IQR\n\n\n            features[i] = (lower_range,upper_range)\n            \n        return pd.DataFrame.from_dict(features,orient='index').rename({0: 'IQR_Low',1: 'IQR_High'}, axis=1)\n    else:\n        assert False, \"df must be of type pandas.DataFrame\"\n        \n@register_series_method\ndef IQR_percent(df):\n    if isinstance(df, pd.Series):\n        \n        lower_range, upper_range = df.IQR_range()\n\n        length = len(df)\n        return np.round((length - df.between(lower_range,upper_range).sum())\/length * 100, 2)\n    else:\n        assert False, \"df must be of type pandas.Series\"\n\n@register_dataframe_method\ndef IQR_percent(df):\n    if isinstance(df, pd.DataFrame):\n        cols = df.get_numeric_cols()\n        features = {}\n        for i in cols:\n            lower_range, upper_range = df[i].IQR_range()\n#             length - Number of NON outliers\n            length = len(df[i])\n            outlier_count = length - df[i].between(lower_range,upper_range).sum()\n            \n            percent = np.round( outlier_count \/length * 100, 2)\n            if outlier_count != 0:\n                features[i] = [percent, outlier_count]\n#             features[i] = IQR_percent(df[i])\n            \n        return pd.DataFrame.from_dict(features,orient='index').rename({0: 'Outlier percent', 1:\"Count\"}, axis=1)\n    else:\n        assert False, \"df must be of type pandas.DataFrame\"\n\n@register_dataframe_method\ndef get_outlier_cols(df):\n    return df.IQR_percent().reset_index()[\"index\"].to_list()\n        \n@register_dataframe_method\ndef drop_row_outlier(df, cols, inplace=False):\n#     init empty index\n    indices = pd.Series(np.zeros(len(df), dtype=bool), index=df.index)\n\n    for col in cols:\n        low, top = df[col].IQR_range()\n        indices |= (df[col] > top) | (df[col] < low)\n        \n    \n    return df.drop(df[ indices ].index, inplace=inplace)\n\n@register_series_method\ndef drop_row_outlier(df, inplace=False):\n#     init empty index\n\n    low, top = df.IQR_range()\n    indices = (df > top) | (df < low)\n        \n    \n    return df.drop(df[ indices ].index, inplace=inplace)\n        \n@register_dataframe_method\ndef compare_cols(df,l_feat,r_feat, percent=False, percent_of_total=False):\n    \n#     [L_feat] {R_feat1: agg1, R_feat2: agg2}\n\n    \n    if percent or percent_of_total:\n        \n        comp = []\n        for key, val in zip(r_feat,r_feat.values()):\n            tmp = pd.DataFrame()\n            tmp[key + \" \" + val] =  df.groupby(l_feat,sort=True).agg({key: val})\n            \n            if percent: tmp[key +\" %\"] = tmp.groupby(level=0).apply(lambda x: np.round(100 * x \/ float(x.sum()),2))\n\n            if percent_of_total: tmp[key+\" % of total\"] = np.round(tmp[key + \" \" + val] \/ tmp[key + \" \" + val].sum() * 100 , 2)\n            \n            comp.append(tmp)\n            \n        return comp\n    \n    else:\n        comp = []\n        for key, val in zip(r_feat,r_feat.values()):\n            tmp = pd.DataFrame()\n            tmp[key + \" \" + val] =  df.groupby(l_feat,sort=True).agg({key: val})           \n            comp.append(tmp)\n            \n        return comp  \n    \n    \n\n@register_dataframe_method\ndef count_dtypes(df, ascending=False):\n    return pd.DataFrame(df.dtypes.value_counts(ascending=ascending)).rename({0:\"Count\"},axis=1)\n\n@register_dataframe_method\ndef about(df):\n\n    display(HTML('<h1 style=\"color:green\"> <b> Shape of data <\/b> <\/h1>'))\n    print(df.shape)    \n\n    display(HTML('<h1 style=\"color:green\"> <b> Datatypes in data <\/b> <\/h1> '))\n    display(pd.DataFrame(df.dtypes.value_counts(ascending=False) ).rename({0:\"count\"},axis=1))\n\n    display(HTML('<h1 style=\"color:green\"> <b> dtypes of columns <\/b> <\/h1> '))\n    display(df.dtypes_of_cols())\n\n    display(HTML('<h1 style=\"color:green\"> <b> Percentage of missing values <\/b> <\/h1> '))\n    tmp = get_missing(df)\n    display(tmp) if len(tmp) != 0 else display(HTML(\"<h2> <b> None <b> <\/h2>\"))\n\n    display(HTML('<h1 style=\"color:green\"> <b> Data description <\/b> <\/h1> '))\n    display(df.describe().T)\n    \n    display(HTML('<h1 style=\"color:green\"> <b> Outlier Percentage(IQR) <\/b> <\/h1> '))\n    tmp = df.IQR_percent()\n    display(tmp) if len(tmp) != 0 else display(HTML(\"<h2> <b> None <b> <\/h2>\"))\n\n    display(HTML('<h1 style=\"color:green\"> <b> Example of data <\/b> <\/h1> '))\n    display(df.head())\n    \n    \nimport itertools\ndef display_multiple_tables(table_list):\n    table_list = list(itertools.chain(*table_list) )\n    return HTML(\n        '<table><tr style=\"background-color:white;\">' + \n        ''.join(['<td>' + table._repr_html_() + '<\/td>' for table in table_list]) +\n        '<\/tr><\/table>')\n","7f5adcd3":"df = pd.read_csv(\"..\/input\/creditcardfraud\/creditcard.csv\")\ndf.about()","b42d2d04":"import altair as alt\nalt.data_transformers.enable('json')","0b99baeb":"alt.Chart(df).mark_bar().encode(\n    alt.X(\"Time\",  bin=alt.Bin(maxbins=30)),\n    alt.Y('count()',),\n    tooltip=\"count()\"\n).properties(\n    width=900,\n    height=400\n).interactive()","f6f04bb3":"alt.Chart(df).mark_bar(opacity=0.8).encode(\n    alt.X(\"Time\",  bin=alt.Bin(maxbins=30)),\n    alt.Y('count()', scale=alt.Scale(type='log'), ),\n    column=\"Class\",\n    tooltip=\"count()\"\n).properties(\n    width=700,\n    height=400\n).interactive()","1bad7a8a":"alt.Chart(df).mark_bar().encode(\n    alt.X(\"Amount\",  bin=alt.Bin(maxbins=30), ),\n    alt.Y(\"count()\", scale=alt.Scale(type='log')),\n    tooltip=\"count()\"\n).properties(\n    width=800,\n    height=400\n).interactive()\n\n","a6fc2227":"alt.Chart(df).mark_bar().encode(\n    alt.X(\"Amount\",  bin=alt.Bin(maxbins=30), ),\n    alt.Y(\"count()\", scale=alt.Scale(type='log'),),\n    column=\"Class\",\n    tooltip=\"count()\"\n).properties(\n    width=800,\n    height=400\n).interactive()\n\n","fee735cf":"alt.Chart(df).mark_bar().encode(\n    alt.X(\"Class:O\",  ),\n    alt.Y(\"count()\", scale=alt.Scale(type='log')),\n    tooltip=\"count()\"\n).properties(\n    width=500,\n    height=400\n).interactive()","28f21a6c":"r_scaler = RobustScaler()\n\ndf[\"Amount\"] = r_scaler.fit_transform(df[\"Amount\"].values.reshape(-1,1))\ndf[\"Time\"] = r_scaler.fit_transform(df[\"Time\"].values.reshape(-1,1))","b2bab6e1":"class super_model:\n    def train(self,X,y):\n        return np.zeros((len(y), 1))\n    ","9f1c9657":"model = super_model()\n\nX = df.drop(\"Class\", axis=1)\ny = df[\"Class\"]\n\ny_trained = model.train(X=X,y=y)\n\naccuracy_score(y, y_trained )","73087a6a":"X = df.drop(\"Class\", axis=1)\ny = df[\"Class\"]","dbb36b62":"rus = RandomUnderSampler(random_state=42)\nx_tmp, y_tmp = rus.fit_resample(X, y)\n\nprint(np.round(y_tmp.value_counts()\/len(y_tmp) * 100, 2).to_dict())\nprint(len(y_tmp))\n\nundersampled_df = pd.concat([x_tmp, y_tmp], axis=1)\nundersampled_df[\"Class\"].value_counts()","fc3e74b1":"X = undersampled_df.drop(\"Class\", axis=1)\ny = undersampled_df[\"Class\"]\n\n\n\ncols = X.columns[SelectPercentile(mutual_info_classif, percentile=25).fit(X,y).get_support()]\nprint(f\"columns are {list(cols)}\")\nX_new = X[cols]\nX_new.head()\n\nundersampled_df = pd.concat([X_new, y], axis=1)\n\n\nprint(f\"Treating outliers for {cols}\")\nprint(f\"length of data before {len(undersampled_df)}\")\n\nundersampled_df.drop_row_outlier(cols= cols, inplace=True)\n\nprint(f\"length of data After {len(undersampled_df)}\")","63794f3c":"classifiers = {\n    \"LogisiticRegression\": LogisticRegression(),\n    \"KNearest\": KNeighborsClassifier(),\n#     \"Support Vector Classifier\": SVC(),\n    \"RandomForestClassifier\": RandomForestClassifier(class_weight=dict({0:1,1:100})),\n    \"LGBMClassifier\":LGBMClassifier()\n}\n\nX = undersampled_df.drop(\"Class\",axis=1)\ny = undersampled_df[\"Class\"]\n\n\nscoring = {'accuracy' : make_scorer(accuracy_score), \n           'precision' : make_scorer(precision_score),\n           'recall' : make_scorer(recall_score), \n           'f1_micro' : make_scorer(f1_score, average=\"micro\")}\n\n\nfor key, classifier in classifiers.items():\n\n    training_score = cross_validate(classifier, X, y, cv=10, scoring=scoring, n_jobs=-1 )\n    for score in scoring.keys():\n        print(f'''{classifier.__class__.__name__ :<25} {round(training_score[\"test_\"+score].mean(), 2) * 100} % ({round(training_score[\"test_\"+score].std(), 2) * 100}){score}''')\n\n    print(\"\\n\")\n","56af7560":"# https:\/\/towardsdatascience.com\/the-right-way-of-using-smote-with-cross-validation-92a8d09d00c7\nfrom imblearn.pipeline import Pipeline as imbpipeline\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.combine import SMOTETomek","bd430865":"X = df.drop(\"Class\", axis=1)\ny = df[\"Class\"]\n\n","d67a0579":"# class_weight=dict({0:1,1:100})\n# classifiers = {\n#     \"LogisiticRegression\": LogisticRegression(),\n#     \"KNearest\": KNeighborsClassifier(),\n# #     \"Support Vector Classifier\": SVC(),\n#     \"RandomForestClassifier\": RandomForestClassifier(class_weight=class_weight),\n#     \"LGBMClassifier\":LGBMClassifier()\n# }\n\n# scoring = {'accuracy' : make_scorer(accuracy_score), \n#            'precision' : make_scorer(precision_score),\n#            'recall' : make_scorer(recall_score), \n#            'f1_micro' : make_scorer(f1_score, average=\"micro\")}\n\n# for key, classifier in classifiers.items():\n\n#     feat_select = SelectPercentile(mutual_info_classif, percentile=25)\n#     pipe = imbpipeline(steps=[\n#         (\"select\",feat_select),\n#         (\"smote\",SMOTETomek(random_state=22,sampling_strategy=0.5)),\n#         (key, classifier)\n\n#     ])\n\n#     training_score = cross_validate(pipe, X, y, cv=5, scoring=scoring, n_jobs=-1 )\n#     for score in scoring.keys():\n#         print(f'''{key :<25} {round(training_score[\"test_\"+score].mean(), 2) * 100} % ({round(training_score[\"test_\"+score].std(), 2) * 100}){score}''')\n        \n#     print(\"\\n\")\n    \n    \n","aa9bdfdc":"class_weight=dict({0:1,1:100})\nclassifiers = {\n    \"LogisiticRegression\": LogisticRegression(),\n    \"KNearest\": KNeighborsClassifier(),\n#     \"Support Vector Classifier\": SVC(),\n    \"RandomForestClassifier\": RandomForestClassifier(class_weight=class_weight),\n    \"LGBMClassifier\":LGBMClassifier()\n}\n\nscoring = {'accuracy' : make_scorer(accuracy_score), \n           'precision' : make_scorer(precision_score),\n           'recall' : make_scorer(recall_score), \n           'f1_micro' : make_scorer(f1_score, average=\"micro\")}\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\nprint(f\"len of X {len(y)}\\nlen of train {len(y_train)}\\nlen of test {len(y_test)}\")\n\nfor key, classifier in classifiers.items():\n\n    feat_select = SelectPercentile(mutual_info_classif, percentile=25)\n    pipe = imbpipeline(steps=[\n        (\"select\",feat_select),\n        (\"smote\",SMOTETomek(random_state=22,sampling_strategy=0.5)),\n        (key, classifier)\n\n    ])\n\n    print(f\"-----------{key}-----------------\")\n    pipe.fit(X_train, y_train)\n    y_pred = pipe.predict(X_test)\n    \n    print(classification_report(y_test, y_pred))\n    print(\"\\n\")\n","ec671de9":"#### **Dont unfold the code just yet!!**\n\n**Try to see whats the issue here**","b2122b6b":"# Random Under Sampler","7e320a86":"**Time consuming method with Cross Val**","4a24abf5":"https:\/\/www.youtube.com\/watch?v=DF-rJA-eOUQ","e2a5537c":"# Feature scaling","b1ef79fe":"# Super secret model ","b7088e46":"# SMOTE","d6bbff89":"**Faster method with train test split**","29f8aab2":"# Importing Data","79c28c43":"# Imports","e7c3568f":"# Introduction\n\nIt is important that credit card companies are able to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase.\nContent\n\n\nThe dataset contains transactions made by credit cards in September 2013 by European cardholders.\nThis dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n\n\nIt contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, \u2026 V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-sensitive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n\n\n# About\nIn this notebook we will be doing\n- why accuracy sucks in this case\n- Random Undersampling (Random Forest (Cross Val)  93.0 % (3.0)f1_micro, 87.0 % (5.0)recall)\n- SMOTETomek (Random Forest (train test) 80% recall, 74% F1 FOR CLASS = 1 )\n\n### If you found this helpful please upvote","7188f772":"# Distribution of Features","57d8651f":"# Pandas Helper functions","e318295b":"|                      | Actual  Fraud | Actual  NOT Fraud |     |\n|:--------------------:|---------------|:-----------------:|-----|\n| Predicted  Fraud     | TP            | FP                | PPV |\n| Predicted  NOT Fraud | FN            | TN                | NPV |\n|                      | TPR           | TNR               |     |\n\nTP = True Positive rate\n\nFP = False Positive\n\nFN = False Negative\n\nTN = True Negative\n\n<br>\n\nTPR(Recall) = True Positive rate = $\\dfrac{TP}{TP + FN}$\n\nTNR = True Negative rate = $\\dfrac{TN}{TN + FP}$\n\nPPV(precision) = Positive Predictive value = $\\dfrac{TP}{TP + FP}$\n\nNPV = Negative predictive value = $\\dfrac{TN}{TN + FN}$\n\nF1 = $2 \\cdot \\dfrac{precision \\cdot recall}{precision + recall}$","73c2cbd0":"refer my previous works on pipeline and others [link](https:\/\/www.kaggle.com\/imams2000\/pipelines-clearly-explained-why-you-should-use)","1e672613":"Thats one hell of accuracy!\n\nSeems too good to be true!?\n\nWhat do you think is the issue here?\n\nNow you could unfold the code!\n\nNotice the issue? Comment if you did!"}}