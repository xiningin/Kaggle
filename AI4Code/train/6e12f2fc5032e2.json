{"cell_type":{"8dc19c4f":"code","315f4fdf":"code","ec72fbe3":"code","9dc60529":"code","246f74fd":"code","7181f00b":"code","81777d78":"code","4c8b5f6c":"code","c14f218f":"code","216ca748":"code","126e77bf":"code","51399f19":"code","d05534d6":"code","f0ab21d4":"code","10eb34bf":"code","12ee27e6":"code","f7e19e33":"code","3132f6a1":"code","65abecf2":"code","80804e79":"code","c33554f4":"code","218d76aa":"code","486726a0":"code","4e27a032":"code","eb9aace0":"code","8b6a2a71":"markdown","513f96b8":"markdown","63951dc4":"markdown","49b1582f":"markdown","80e60dc6":"markdown","50aacab0":"markdown","488cd9aa":"markdown","f3492aed":"markdown","a5793c8d":"markdown","43f5eebc":"markdown","58c8c02a":"markdown","df421609":"markdown","2682815f":"markdown","fd5a7e17":"markdown","8b092aa8":"markdown","0a402c76":"markdown"},"source":{"8dc19c4f":"!pip install -U git+https:\/\/github.com\/qubvel\/segmentation_models.pytorch","315f4fdf":"import os\nimport json\nimport nibabel as nib\nimport numpy as np\nfrom tqdm.notebook import tqdm\nimport torchvision\nimport random\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn.utils import clip_grad_norm_\nfrom torch.utils.data import Dataset, DataLoader\nimport albumentations as A # for augmentation\nimport segmentation_models_pytorch as smp","ec72fbe3":"device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\" # Ckeck if GPU is available\n\ndevice = torch.device(device)\nprint(device)","9dc60529":"# from google.colab import drive # Mount GDrive\n# drive.mount('\/content\/drive')","246f74fd":"# core_path = \".\/drive\/MyDrive\/Deep Learning\/CovidKaggleTask\/\" # \u041e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u043c \u043f\u0443\u0442\u0438 \u0434\u043e \u0444\u0430\u0439\u043b\u043e\u0432\n# path = core_path + \"data\/data\/\"","7181f00b":"# for kaggle\ncore_path = \"..\/input\/tgcovid\/\"\npath = core_path + \"data\/data\/\"","81777d78":"from os import listdir\nfrom os.path import isfile, join\nonlyfiles = [f for f in listdir(path + \"images\") if isfile(join(path + \"images\", f))]\nonlyfiles[:5] # gain list of all files","4c8b5f6c":"class CovidDataset(Dataset):\n    def __init__(self, X_data, without_covid_max=9999999):\n        # Load CT scans\n        path_images = os.path.join(path, 'images')\n        path_labels = os.path.join(path, 'labels')\n        \n        # Load json with label info\n        with open(core_path + 'training_data.json', 'r') as f:\n            dict_training = json.load(f)\n\n        self.X = [] \n        self.Y = []\n        without_covid = 0\n        for entry in tqdm(dict_training):\n            image = nib.load(os.path.join(path_images, entry['image'][:-3])) # Load specific CT-scan by name from json\n            label = nib.load(os.path.join(path_labels, entry['label'][:-3])) # Load labels for CT scan\n            image = torch.tensor(image.get_fdata(), dtype=torch.uint8).transpose(1, 2).transpose(0, 1) # Change dimension from [43, 512, 512]\n            label = torch.tensor(label.get_fdata(), dtype=torch.uint8).transpose(1, 2).transpose(0, 1) # to [512, 512, 43] for each image\n            \n            \n            if entry['image'][:-3] in X_data: # If this CT-scan is in a train, load it there\n                for i in range(len(image)): # Run through all the layers in the desired CT scan image\n                    if label[i].sum() != 0:\n                        self.X.append(image[i]) # Add individual images\n                        self.Y.append(label[i])\n                    else:\n                        if without_covid >= without_covid_max:\n                            continue\n                        else:\n                            without_covid += 1\n                            self.X.append(image[i]) # Add individual images\n                            self.Y.append(label[i])\n    \n    \n    def __len__(self):\n        return len(self.X)\n    \n    \n    def __getitem__(self, idx):\n        # Do random augmentation\n        # The method does augmentation both for image - our layer scan and for its labeled image\n        # First, define the rotation by an angle...\n        degrees = [-35, -30, -25, -20, -15, -10, -5, 0, 5, 10, 15, 20, 25, 30, 35]\n        X = self.X[idx]\n        y = self.Y[idx]\n        X = X.type(torch.float)\n        y = y.type(torch.float)\n        X = (torch.Tensor(np.array([X.numpy()]) \/ 255))\n        y = (torch.Tensor(np.array([y.numpy()])))\n        value = random.random()\n        if random.random() > 0.5:\n            value = random.random()\n            if value > 0.5:\n                X = torchvision.transforms.functional.vflip(X)\n                y = torchvision.transforms.functional.vflip(y)\n            else:\n                X = torchvision.transforms.functional.hflip(X)\n                y = torchvision.transforms.functional.hflip(y)\n        value = random.random()\n        if value >= 0.1:\n            degree = random.choice(degrees)\n            X = torchvision.transforms.functional.rotate(X, degree)\n            y = torchvision.transforms.functional.rotate(y, degree)\n        else:\n            pass\n        value = random.random()\n        if value > 0.5:\n            X = torchvision.transforms.RandomPerspective(distortion_scale=0.15, p=0.5, interpolation=2, fill=0)(X)\n            y = torchvision.transforms.RandomPerspective(distortion_scale=0.15, p=0.5, interpolation=2, fill=0)(y)\n        else:\n            pass\n        value = random.random()\n        if value > 0.5:\n            X = torchvision.transforms.GaussianBlur(1)(X)\n            y = torchvision.transforms.GaussianBlur(1)(y)\n        else:\n            pass\n        \n        # Important! It is impossible to transfer just a picture (512, 512), convolution is used in many dimensions\n        # Must be passed in the format [palette, width, height] - [1, 512, 512]\n        return torch.Tensor(X), torch.Tensor(y) \n                                            ","c14f218f":"batch_size = 8\n\n# Shuffle file names randomly (for generation train and validation)\nnp.random.shuffle(onlyfiles) \ntrain_dataset = CovidDataset(onlyfiles[:33], 50)\nvalid_dataset = CovidDataset(onlyfiles[33:], 50)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)","216ca748":"import torch.nn as nn\n\nclass Unet(nn.Module): # Define the structure of the neural network Unet\n    def block_down(self, in_features, out_features):\n        return nn.Sequential(*[nn.Conv2d(in_features, out_features, (3, 3), padding=1),\n                              nn.ReLU(),\n                              nn.BatchNorm2d(out_features)])\n    \n    def block_up(self, in_features, out_features):\n        return nn.Sequential(*[nn.Conv2d(in_features, out_features, (3, 3), padding=1),\n                              nn.ReLU(),\n                              nn.BatchNorm2d(out_features)])\n    \n    \n    def __init__(self):\n        super(Unet, self).__init__()\n        self.block_up11 = self.block_down(1, 32)\n        self.block_up12 = self.block_down(32, 32)\n        self.max_pooling11 = nn.MaxPool2d((2, 2), stride=(2, 2))\n        \n        self.block_up21 = self.block_down(32, 64)\n        self.block_up22 = self.block_down(64, 64)\n        self.max_pooling22 = nn.MaxPool2d((2, 2), stride=(2, 2))\n        \n        self.block_up31 = self.block_down(64, 128)\n        self.block_up32 = self.block_down(128, 128)\n        self.max_pooling33 = nn.MaxPool2d((2, 2), stride=(2, 2))\n        \n        self.block_up41 = self.block_down(128, 256)\n        self.block_up42 = self.block_down(256, 256)\n        self.max_pooling44 = nn.MaxPool2d((2, 2), stride=(2, 2))\n        \n        self.block_up51 = self.block_down(256, 512)\n        self.block_up52 = self.block_down(512, 512)\n        \n        self.block_up61 = nn.Upsample(scale_factor=2)\n        self.block_up62 = self.block_up(512, 256)\n        self.block_up63 = self.block_up(512, 256)\n        self.block_up64 = self.block_up(256, 256)\n        \n        self.block_up71 = nn.Upsample(scale_factor=2)\n        self.block_up72 = self.block_up(256, 128)\n        self.block_up73 = self.block_up(256, 128)\n        self.block_up74 = self.block_up(128, 128)\n        \n        self.block_up81 = nn.Upsample(scale_factor=2)\n        self.block_up82 = self.block_up(128, 64)\n        self.block_up83 = self.block_up(128, 64)\n        self.block_up84 = self.block_up(64, 64)\n        \n        self.block_up91 = nn.Upsample(scale_factor=2)\n        self.block_up92 = self.block_up(64, 32)\n        self.block_up93 = self.block_up(64, 32)\n        self.block_up94 = self.block_up(32, 32)\n        \n        self.block_up100 = self.block_up(32, 1) \n        \n    \n    def forward(self, x):\n        out = self.block_up11(x)\n        out = self.block_up12(out)\n        \n        save1 = out.clone()\n        \n        out = self.max_pooling11(out)\n        \n        out = self.block_up21(out)\n        out = self.block_up22(out)\n        \n        save2 = out.clone()\n        \n        out = self.max_pooling22(out)\n        \n        out = self.block_up31(out)\n        out = self.block_up32(out)\n        \n        save3 = out.clone()\n        \n        out = self.max_pooling33(out)\n        \n        out = self.block_up41(out)\n        out = self.block_up42(out)\n        \n        save4 = out.clone()\n        \n        out = self.max_pooling44(out)\n        \n        out = self.block_up51(out)\n        out = self.block_up52(out)\n        \n        \n        out = self.block_up61(out)\n        out = self.block_up62(out)\n        out = self.block_up63(torch.cat((out, save4), 1))\n        out = self.block_up64(out)\n\n        out = self.block_up71(out)\n        out = self.block_up72(out)\n        out = self.block_up73(torch.cat((out, save3), 1))\n        out = self.block_up74(out)\n\n        out = self.block_up81(out)\n        out = self.block_up82(out)\n        out = self.block_up83(torch.cat((out, save2), 1))\n        out = self.block_up84(out)\n\n        out = self.block_up91(out)\n        out = self.block_up92(out)\n        out = self.block_up93(torch.cat((out, save1), 1))\n        out = self.block_up94(out)\n\n        out = self.block_up100(out)\n        out = nn.Sigmoid()(out)\n        \n        return out","126e77bf":"import torch\nimport torch.nn.functional as F\n\ndef dice_loss(inputs: torch.Tensor, targets: torch.Tensor):\n    inp = inputs.contiguous().view(-1)\n    tar = targets.contiguous().view(-1)\n    noise = random.randint(1, 1000) \/ 10000000000\n    \n    return 1 - ((2 * (inp * tar).sum() + noise) \/ ((inp).sum() + (tar).sum() + noise))","51399f19":"class TverskyLoss(nn.Module):\n    def __init__(self, alpha=0.7):\n        super(TverskyLoss, self).__init__()\n        self.alpha = alpha\n\n    def forward(self, inputs, targets, smooth=1):\n        y_pred = inputs\n        y_true = targets\n        y_true_pos = y_true.view(-1)\n        y_pred_pos = y_pred.view(-1)\n        true_pos = torch.sum(y_true_pos * y_pred_pos)\n        false_neg = torch.sum(y_true_pos * (1 - y_pred_pos))\n        false_pos = torch.sum((1 - y_true_pos) * y_pred_pos)\n        return 1 - (true_pos + smooth) \/ (true_pos + self.alpha * false_neg + (1 - self.alpha) * false_pos + smooth)","d05534d6":"def sigmoid_focal_loss(inputs, targets, alpha=0.25, gamma=2, reduction=\"none\"):\n    p = torch.sigmoid(inputs)\n    ce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\n    p_t = p * targets + (1 - p) * (1 - targets)\n    loss = ce_loss * ((1 - p_t) ** gamma)\n\n    if alpha >= 0:\n        alpha_t = alpha * targets + (1 - alpha) * (1 - targets)\n        loss = alpha_t * loss\n\n    if reduction == \"mean\":\n        loss = loss.mean()\n    elif reduction == \"sum\":\n        loss = loss.sum()\n\n    return loss","f0ab21d4":"import segmentation_models_pytorch as smp\n\nuse_previous_versions = False\nprevious_i = 0\npath_to_model = \"output\/kaggle\/working\/\"\n\n# Check if we can load an already trained model\nif use_previous_versions:\n    models_variation = []\n    for put, papki, files in os.walk(\".\"):\n        for el in files:\n            if \"lungs_ct_model\" in el:\n                models_variation.append(el)\n                \n    # File name - lungs_ct_model_1.h5\n    if len(models_variation) != 0:\n        models_variation = sorted(models_variation, key=lambda x: - int(x.split(\"_\")[-1].split(\".\")[0]))\n        model = torch.load(models_variation[-1])\n        previous_i = int(models_variation[0].split(\"_\")[-1].split(\".\")[0])\n        print(\"Previous model loaded: {}\".format(str(previous_i)))\n    else:\n        model = smp.UnetPlusPlus(encoder_name='resnet18', in_channels=1, classes=1, activation=\"tanh\")\n        print(\"Loaded untrained Unet++\")\nelse:\n    model = smp.UnetPlusPlus(encoder_name='resnet18', in_channels=1, classes=1, activation=\"sigmoid\")\n    print(\"Loaded untrained Unet++\")\n\n\ndevice = torch.device('cuda:0')\nmodel = model.to(device)","10eb34bf":"def recall(output_batch, correct_batch, threshold=0.99):    \n    output_numpy = output_batch.detach().numpy()\n    correct_numpy = correct_batch.detach().numpy()\n    \n    amount_of_correct = np.count_nonzero(np.where(output_numpy > threshold, output_numpy, 0) + correct_numpy == 2)\n    amount_all = np.count_nonzero(correct_numpy == 1)\n    try:\n        return amount_of_correct \/ amount_all\n    except:\n        return np.nan\n\ndef precision(output_batch, correct_batch, threshold=0.99):   \n    output_numpy = output_batch.detach().numpy()\n    correct_numpy = correct_batch.detach().numpy()\n    \n    amount_of_correct = np.count_nonzero(np.where(output_numpy > threshold, output_numpy, 0) + correct_numpy == 2)\n    amount_all = np.count_nonzero(output_numpy == 1)\n    try:\n        return amount_of_correct \/ amount_all\n    except:\n        return np.nan\n    \ndef f1_score(precision, recall):\n    return 2 * (precision * recall) \/ (precision + recall)","12ee27e6":"num_epoch = 125\nlr = 0.0005\n\ndice_loss_criterion = dice_loss\nfocal_loss_criterion = sigmoid_focal_loss\ntverskoy_loss = TverskyLoss(alpha=0.7)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\nscheduler = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, lambda x: 0.9825)","f7e19e33":"losses = []\n\nfor epoch in tqdm(range(num_epoch)):\n    epoch_losses = []\n    \n    # Train model\n    for X, Y in train_loader:\n        X = X.to(device)\n        Y = Y.to(device)\n\n        optimizer.zero_grad()\n        output = model(X)\n        \n        loss = tverskoy_loss(output, Y)\n        loss.backward()\n        clip_grad_norm_(model.parameters(), 99999)\n        \n        optimizer.step()\n\n        del X\n        del Y\n        torch.cuda.empty_cache()\n        epoch_losses.append(loss.item())\n        \n    # Adding loss\n    common_loss = sum(epoch_losses) \/ len(epoch_losses)\n    losses.append(common_loss)\n    \n    # We calculate metrics for validation:\n    valid_precision = []\n    valid_recall = []\n    for X, Y in valid_loader:\n        X = X.to(device)\n        rec = recall(model(X).cpu(), Y)\n        prec = precision(model(X).cpu(), Y)\n        if prec is not np.nan:\n            valid_precision.append(prec)\n        if rec is not np.nan:\n            valid_recall.append(rec)\n        del X\n        del Y\n    \n    # Display information\n    print(\"--\" * 15)\n    print(\"Epoch: {}\".format(str(epoch)))\n    print(\"Loss:\\t\\t {:7.5f}\".format(common_loss))\n    print(\"Learning rate: {:9.8f}\".format(float(optimizer.state_dict()[\"param_groups\"][0][\"lr\"])))\n    \n    try:\n        prec = sum(valid_precision) \/ len(valid_precision)\n        print(\"Precision:\\t {:7.3%}\".format(prec))\n    except:\n        print(\"Precision:\\t No info\")\n        \n    try:\n        rec = sum(valid_recall) \/ len(valid_recall)\n        print(\"Recall:\\t\\t {:7.3%}\".format(rec))\n    except:\n        print(\"Recall:\\t\\t No info\")\n        \n    try:\n        print(\"F1-score: \\t {:7.3f}\".format(f1_score(prec, rec)))\n    except:\n        print(\"F1-score: No info\".format(f1_score(prec, rec)))\n    \n    # Save the model and do the scheduler step\n    torch.save(model, \"lungs_ct_model_\" + str(epoch + previous_i) + \".h5\")\n    scheduler.step()","3132f6a1":"from sklearn.metrics import roc_curve\n\ny_real = []\ny_pred = []\nfor X, Y in valid_loader:\n    X = X.to(device)\n    y_real += Y.view(Y.shape[0] * Y.shape[1] * Y.shape[2] * Y.shape[3]).int().cpu().detach().tolist()\n    y_pred += model(X).view(Y.shape[0] * Y.shape[1] * Y.shape[2] * Y.shape[3]).cpu().detach().tolist()","65abecf2":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(12, 12))\nfpr, tpr, thresholds = roc_curve(np.array(y_real), np.array(y_pred))\nplt.plot(fpr, tpr, 'b', linewidth=3)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot([0, 0], [0, 1], 'k')\nplt.plot([1, 1], [0, 1], 'k')\nplt.plot([0, 1], [0, 0], 'k')\nplt.plot([0, 1], [1, 1], 'k')\nplt.xlabel('FP rate')\nplt.ylabel('TP rate')\nplt.xlim((0, 1))\nplt.ylim((0, 1))\nplt.axis('equal')\nplt.title('ROC curve')\nplt.show()","80804e79":"from sklearn.metrics import roc_auc_score\n\nroc_auc_score(y_real, y_pred)","c33554f4":"#Visualize some of the slices\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\ndef blend(image, mask): # The function returns an image with a mask applied to it - labels, which are a covid thing\n    print(image)\n    image = image.astype(np.float32)\n    min_in = image.min()\n    max_in = image.max()\n    image = (image - min_in) \/ (max_in - min_in + 1e-8) * 255\n    image = np.dstack((image, image, image)).astype(np.uint8)\n    zeros = np.zeros_like(mask)\n    mask = np.dstack((zeros, zeros, mask * 255)).astype(np.uint8)\n    return Image.blend(\n        Image.fromarray(image),\n        Image.fromarray(mask),\n        alpha=.3\n    )\n\nslices_num = (100, )\nslices = []\nfor idx in slices_num:\n    k = valid_dataset[idx]\n    slices.append(blend(\n        k[0][0].numpy(),\n        k[1][0].numpy()\n    ))\n    prediction = model.forward(k[0].view(1, 1, 512, 512).to(device)).cpu().detach().transpose(0, 1).transpose(1, 2).transpose(2, 3)[0]\n    prediction[prediction >= 0.99] = 1\n    prediction[prediction < 0.99] = 0\n    slices.append(\n        torch.cat([prediction, prediction, prediction], 2)\n    )\n\nfigure = plt.figure(figsize=(18, 18))\nfor i, image in enumerate(slices):\n    ax = figure.add_subplot(1, len(slices), i + 1)\n    ax.imshow(slices[i])","218d76aa":"\"\"\"\nLoad testing data into images and labels lists\n\nimages list consists of CT scans -  numpy arrays of shape (512, 512, n_slices)\n\"\"\"\nwith open(core_path + 'testing_data.json', 'r') as f:\n    dict_testing = json.load(f)\n\nimages_testing = []\nlabel_testing = []\nfor entry in tqdm(dict_testing):\n    image = nib.load(os.path.join(path + \"images\/\", entry['image'][:-3]))\n    images_testing.append(image.get_fdata())","486726a0":"def rle_encoding(x):\n    dots = np.where(x.T.flatten() >= 1)[0]\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if (b > prev + 1):\n            run_lengths.extend((b + 1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return [str(item) for item in run_lengths]","4e27a032":"thresh = 0.99\nn_id = len(images_testing)\n\nfor i in range(n_id):\n    n_imgs = images_testing[i][1].shape[-1]\n    name = images_testing[i][0]\n    \n    for j in range(n_imgs):\n        inp = images_testing[i][:, :, j]\n\n        inp = torch.from_numpy(np.array(inp))\n        inp = inp.to(device)\n        inp = inp.type(torch.float)\n        inp = inp.view(-1, 1, 512, 512)\n\n        res = model(inp)\n        res = res.cpu()\n        outp = res.detach().numpy()[0][0]\n\n        outp \/= np.max(outp)\n        outp[outp >= thresh] = 1\n        outp[outp < thresh] = 0\n\n        label_testing.append(outp)","eb9aace0":"import csv\nwith open(f'{core_path}testing_data.json', 'r') as f:\n            dict_testing = json.load(f)\n\nwith open(f'submission.csv', \"wt\") as sb:\n    submission_writer = csv.writer(sb, delimiter=',')\n    submission_writer.writerow([\"Id\", \"Predicted\"])\n    for k_i, patient_i in tqdm(zip(dict_testing, label_testing)):\n        submission_writer.writerow([\n                f\"{k_i['image'][:-7]}\",\n                \" \".join(rle_encoding(patient_i))\n            ])","8b6a2a71":"## Image segmentation\n\nWe are faced with the task of **segmentation** CT images of the lungs and identifying areas of damage from Covid-19.\n\nInitial data: **json** with filenames, **images** - the data, **labels** - labels: 0 - this pixel **does not** belong to the damaged lung, 1 - the pixel **belong** to the damaged lung.\n\nEach scan is numpy arrays of shape (512, 512, n_slices)\n\n","513f96b8":"Having already pretty much tried out various losses, the best solution at the moment is **TverskyLoss**\n\nWe will use it for the final training","63951dc4":"    ## 2. Decide on the structure of the neural network\n\nIn this case, the Unet network was chosen (https:\/\/pytorch.org\/hub\/mateuszbuda_brain-segmentation-pytorch_unet\/)\n\nIt's great for medical image analysis because it has a lot of skip-connections to solve the vanishing gradient problem, as well as increasing information for the next layers that are responsible for feature selection (i.e. decoder)","49b1582f":"### 3. Train model","80e60dc6":"## 0. Prepare Data and Import Libraries","50aacab0":"Project structure:\n1. core_path - the path to the project. In the colab it's \".\/drive\/MyDrive\/DL\/Covid_CT\/\"\n\n2. path = core_path + \"data\/data\/\" - The path to the files. This directory contains the json file itself, the images and labels folders, which contain information about CT scans\n\n3. core_path\/models - path to models for training. Due to the large data volume, it is necessary to save the model every time. Thus, models are saved in this folder after each epoch. lungs_ct_model_1.h5 - correct name for a model that was trained on only one epoch","488cd9aa":"Decide which data augmentation is useful. We are trying to understand which transformations can be useful for this task:\n- **Rotations by a small number of degrees** (rotation does not change the logic of class distribution in any way)\n- **Vertical map(display)**\n- **Horizontal map(display)**\n- **Perspective** (slightly different angle of taking CT will increase the set of initial data)\n- **Blur** (noise will help not to overfit the model)","f3492aed":"#### Metrics\n\nDefining metrics:\n\nWe need to detect covid, which means that the completeness of **recall** is suitable for us (if we detect covid, where there is only suspicion, it will be good)\n\nHowever, detecting everything is not very good, which means that you need to look at **precision**\n\nSo **f-measure** is fine","a5793c8d":"Thus, we trained the model and it achieved an acceptable result.","43f5eebc":"### 5. Inference\n\nBelow code is just to submit solution to **Kaggle**\n","58c8c02a":"### 4. Visualize","df421609":"We have implemented our own **Unet** model. It is quite effective, but in complex tasks it may not be enough, so a good classification model (for example, ResNet) is attached to it.\n\nSo the complex model would be **Unet++**","2682815f":"## 1. Work with dataset","fd5a7e17":"We create a dataset class, in which we write the __init__(self, list of scans for train, list of scans for validation, augmentation) method, dataset length method and getting an element from the dataset","8b092aa8":"#### Model preparation\n\nFirst load the **Unet++** model if we don't have any other **already trained** models","0a402c76":"Consider three losses and choose which one is more **efficient**:\n- Dice Loss\n- TverskyLoss\n- Focal loss"}}