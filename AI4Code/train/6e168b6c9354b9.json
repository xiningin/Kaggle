{"cell_type":{"f3b2e404":"code","68544094":"code","7df5f4dc":"code","0b8ba208":"code","eac58268":"code","bdd63f91":"code","51b20be2":"code","b5778e72":"code","75710df5":"code","42f25c91":"code","05f70a8f":"code","e55de862":"code","b376b00b":"code","420d6bd3":"code","adaae6a9":"code","41380d18":"code","4a365fbb":"code","97606aed":"code","e6452971":"code","5b1dba90":"code","944e0cb9":"code","02cfc597":"code","4327d610":"code","3f388edf":"code","65855270":"markdown","e8640569":"markdown","5f31b46d":"markdown","530fceec":"markdown","139d0c43":"markdown","c4018672":"markdown","23269363":"markdown","43fda9dc":"markdown","36a2befd":"markdown","60e469f5":"markdown","d439ce60":"markdown","09d94df4":"markdown","fc6ef037":"markdown","4d91162d":"markdown","8f4f297c":"markdown","defe2d25":"markdown","3e0190dc":"markdown","90adb3e4":"markdown","c0c97472":"markdown","d591661e":"markdown","fbd42fbf":"markdown","7041b4e3":"markdown","b2d83854":"markdown","50a2b4ba":"markdown","b91f9bb9":"markdown","b2d82473":"markdown","01552367":"markdown"},"source":{"f3b2e404":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np  # linear algebra\nimport pandas as pd  # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    print(dirname)\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\"\n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","68544094":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set parameters for plotting.\n# plt.rc('figure', figsize=(8, 6))\nsns.set(font_scale=1)","7df5f4dc":"df = pd.read_csv('..\/input\/whale-categorization-playground\/train.csv')\ndf","0b8ba208":"# Print the number of missing entries.\ndf.isna().sum()","eac58268":"IMAGES_DIR = '..\/input\/whale-categorization-playground\/train\/train\/'\nNUM_IMAGES_TO_PLOT = 3\nimage_filenames = os.listdir(IMAGES_DIR)\n\nfor i in range(NUM_IMAGES_TO_PLOT):\n    image_filename = image_filenames[i]\n    image_path = os.path.join(IMAGES_DIR, image_filename)\n    image_np = plt.imread(image_path)\n    whale_id = df.query(f\"Image == '{image_filename}'\").Id.item()\n    plt.subplots(figsize=(8, 6))\n    plt.imshow(image_np)\n    plt.title(whale_id)","bdd63f91":"df2 = df.groupby('Id').agg('count').rename({'Image': 'NumImages'}, axis=1)\ndf2.sort_values('NumImages', ascending=False, inplace=True)\ndf2","51b20be2":"plt.figure(figsize=(6, 4))\ndf2.NumImages.hist(bins=list(range(0, 11, 2)))\nplt.title('Number of cases for various numbers of whale images ')\nplt.xlabel('Number of images')\nplt.ylabel('Number of cases')\nplt.show()","b5778e72":"plt.figure(figsize=(6, 4))\ndf2.NumImages.hist(bins=list(range(10, 71, 10)))\nplt.title('Number of cases for various numbers of whale images ')\nplt.xlabel('Number of images')\nplt.ylabel('Number of cases')\nplt.show()","75710df5":"df2.drop('new_whale', inplace=True)\ndf2","42f25c91":"NUM_IMAGES_THRESHOLD = 20\n\ndf3 = df2.query(f'NumImages > {NUM_IMAGES_THRESHOLD}')\n\nprint('shape:', df3.shape)\nprint('total number of images:', df3.NumImages.sum())\ndf3","05f70a8f":"ids_to_leave = list(df3.index)\n\nfiltered_df = df.query(f'Id in {ids_to_leave}')\nfiltered_df","e55de862":"filtered_df.drop(filtered_df.query(\"Image == '496b52ff.jpg'\").index,\n                 axis=0, inplace=True)\n\nfiltered_df","b376b00b":"from sklearn.model_selection import StratifiedShuffleSplit\n\nX, y = filtered_df.Image, filtered_df.Id\nsplitter = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=0)\ntrain_indices, test_indices = list(splitter.split(X, y))[0]\n\nprint('shapes:', train_indices.shape, test_indices.shape)","420d6bd3":"train_df = filtered_df.iloc[train_indices]\ntest_df = filtered_df.iloc[test_indices]\n\ntrain_df.Id.nunique() == test_df.Id.nunique()","adaae6a9":"train_entries_counts = train_df.Id.value_counts().sort_index()\ntest_entries_counts = test_df.Id.value_counts().sort_index()\n\nprint('percentage of entries:')\nprint()\nprint(test_entries_counts \/ train_entries_counts)","41380d18":"from tensorflow import keras\nfrom keras.preprocessing.image import ImageDataGenerator\n\nTRAIN_DIR = '\/kaggle\/input\/whale-categorization-playground\/train\/train'\n\n# Specify image transformations for the data augmentation here. \ndatagen = ImageDataGenerator(\n    rescale=1.\/255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    rotation_range=30,\n    brightness_range=(0.5, 1.5),\n    fill_mode='nearest',\n    horizontal_flip=True\n)\n\nBATCH_SIZE = 32\nTARGET_SIZE = (224, 224)\n\ntrain_set_generator = datagen.flow_from_dataframe(\n    dataframe=train_df,\n    directory=TRAIN_DIR,\n    x_col='Image',\n    y_col='Id',\n    target_size=TARGET_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical'  # ensures one-hot encoding of class labels\n)\n\ntest_set_generator = datagen.flow_from_dataframe(\n    dataframe=test_df,\n    directory=TRAIN_DIR,\n    x_col='Image',\n    y_col='Id',\n    target_size=TARGET_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical'  # ensures one-hot encoding of class labels\n)","4a365fbb":"NUM_IMAGES_TO_PLOT = 5  # must be less than the BATCH_SIZE\n\n# Get one batch of the training data.\nfor X, y in train_set_generator:\n    break\n\n# Get a list of unique whale IDs.\nunique_whale_ids = train_df.Id.unique()\n\nimages_subbatch = X[:NUM_IMAGES_TO_PLOT]\none_hot_class_labels_subbatch = y[:NUM_IMAGES_TO_PLOT]\n\nfor image, one_hot_class_labels in zip(images_subbatch,\n                                       one_hot_class_labels_subbatch):\n    plt.subplots()\n    plt.imshow(image)\n    whale_id = unique_whale_ids[np.argmax(one_hot_class_labels)]\n    plt.title(whale_id)\n    plt.show()","97606aed":"from keras.applications.vgg16 import VGG16\n\n# Form the correct input shape for the model in case the `TARGET_SIZE` \n# is not square (e.g. (224, 224)).\nINPUT_SHAPE = (TARGET_SIZE[0], TARGET_SIZE[1], 3)\n\nbase_model = VGG16(\n    weights='imagenet',  # load weights pretrained on the ImageNet\n    include_top=False,  # do not include the ImageNet classifier at the top\n    input_shape=INPUT_SHAPE,\n    pooling='max'  # add a global max pooling layer after the base model\n)\n\nbase_model.summary()","e6452971":"from keras.layers import Dropout, Dense\n\n# Freeze the base model so that only the new top layers are trained.\nbase_model.trainable = False\n\nnum_classes = len(unique_whale_ids)\n\nmodel = keras.Sequential([\n    base_model,\n    Dropout(0.2),\n    Dense(128, activation='relu'),\n    # Dense(128, activation='relu'),\n    Dropout(0.2),\n    Dense(num_classes, name='predictions')\n])\n\nmodel.summary()","5b1dba90":"from keras.losses import CategoricalCrossentropy\n\nEPOCHS = 30\n\n# As the output of the model is real-numbered, set the `from_logits` \n# parameter of the crossentropy loss to True.\nmodel.compile(\n    optimizer='adam',\n    loss=CategoricalCrossentropy(from_logits=True),  \n    metrics=['accuracy']\n)\n\nhistory = model.fit(train_set_generator, \n                    epochs=EPOCHS,\n                    validation_data=test_set_generator,\n                    verbose=2   # don't display the progress bar\n) ","944e0cb9":"base_model.trainable = True\n\nmodel.summary()","02cfc597":"from keras.optimizers import Adam\n\nFINE_TUNING_EPOCHS = 30\n\nmodel.compile(optimizer=Adam(1e-5),  # set the learning rate to a low value\n              loss=CategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy']\n)\n\nfine_tuning_history = model.fit(train_set_generator, \n                                epochs=FINE_TUNING_EPOCHS,\n                                validation_data=train_set_generator,\n                                verbose=2  # don't display the progress bar\n)","4327d610":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nfine_tuning_acc = fine_tuning_history.history['accuracy']\nfine_tuning_val_acc = fine_tuning_history.history['val_accuracy']\n\ntop_layers_training_epochs = list(range(1, EPOCHS + 1))\nfine_tuning_epochs = list(range(EPOCHS + 1, \n                                EPOCHS + FINE_TUNING_EPOCHS + 1))\n\nax = plt.figure(figsize=(10, 6))\n\nplt.plot(top_layers_training_epochs, acc, label='acc', color='orange')\nplt.plot(top_layers_training_epochs, val_acc, label='val_acc', \n         color='cornflowerblue')\n\nplt.plot(fine_tuning_epochs, fine_tuning_acc, color='orange')\nplt.plot(fine_tuning_epochs, fine_tuning_val_acc, color='cornflowerblue')\nplt.plot([EPOCHS, EPOCHS + 1], [acc[-1], fine_tuning_acc[0]], \n         color='orange')\n\nplt.plot([EPOCHS, EPOCHS + 1], [val_acc[-1], fine_tuning_val_acc[0]], \n         color='cornflowerblue')\n\nplt.vlines(EPOCHS, ymin=0, ymax=1, linestyles='dashed',\n           label='fine-tuning started')\n\nplt.legend(loc='best')\nplt.title('Accuracy during training')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.show()","3f388edf":"loss = history.history['loss']\nval_loss = history.history['val_loss']\n\nfine_tuning_loss = fine_tuning_history.history['loss']\nfine_tuning_val_loss = fine_tuning_history.history['val_loss']\n\ntop_layers_training_epochs = list(range(1, EPOCHS + 1))\n\nax = plt.figure(figsize=(10, 6))\n\nplt.plot(top_layers_training_epochs, loss, label='loss', color='orange')\nplt.plot(top_layers_training_epochs, val_loss, label='val_loss', \n         color='cornflowerblue')\n\nplt.plot(fine_tuning_epochs, fine_tuning_loss, color='orange')\nplt.plot(fine_tuning_epochs, fine_tuning_val_loss, color='cornflowerblue')\nplt.plot([EPOCHS, EPOCHS + 1], [loss[-1], fine_tuning_loss[0]], \n         color='orange')\n\nplt.plot([EPOCHS, EPOCHS + 1], [val_loss[-1], fine_tuning_val_loss[0]], \n         color='cornflowerblue')\n\nmax_loss = max(max(loss), max(val_loss), \n               max(fine_tuning_loss), max(fine_tuning_val_loss))\n\nplt.vlines(EPOCHS, ymin=0, ymax=max_loss, linestyles='dashed', \n           label='fine-tuning started')\n\nplt.legend(loc='best')\nplt.title('Loss during training')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.show()","65855270":"Filter (and leave) only those whale IDs, for which the number of corresponding images is greater than `NUM_IMAGES_THRESHOLD`.","e8640569":"## Plot a few images along with the corresponding whale IDs","5f31b46d":"Plot s histogram describing number of cases for varios numbers of whale images (that is, how frequently a certain number of whale images we have for a single whale ID).","530fceec":"Remove the `new_whale` entry from consideration.","139d0c43":"Articles about transfer learning:\n * https:\/\/machinelearningmastery.com\/how-to-use-transfer-learning-when-developing-convolutional-neural-network-models\/\n * https:\/\/keras.io\/guides\/transfer_learning\/","c4018672":"Obtain a dataframe containing entries only for the filtered whale IDs.","23269363":"## Plot the training history","43fda9dc":"For splitting the data, we could use the `train_test_split` function from `sklearn`. Or, we could specify the `validation_split` parameter for an `ImageDataGenerator` instance and use it to create two augmented image generators: one for the training set, and the other one for the test (validation) set. However, these two approaches do not guarantee a balanced split of the data, i.e. it could happen that not all the whale IDs present in the training set are present in the test set as well. To avoid this problem, we can obtain a stratified split of the data by using a `StratifiedShuffleSplit` object from `sklearn` module.\n\nNote that this splitter can throw exceptions in the following cases:\n* if the `test_size` is too small to include all the whale IDs into the test set (thus, it is not possible to accomplish a truly stratified splitting of the data)\n* if it is not possible to include some whale IDs into the test set because there is only one image for such whale IDs","36a2befd":"## Plot some augmented data","60e469f5":"Check if there is an equal number of unique whale ids in the training and test set.","d439ce60":"## Split the filtered data into the training and test (validation) set","09d94df4":"## Check how many images there are for all whale IDs","fc6ef037":"## Apply fine-tuning, that is, unfreeze the base model and train the whole model with a small learning rate ","4d91162d":"# Data preprocessing","8f4f297c":"# Data augmentation","defe2d25":"Check the list of all possible image transformations in Keras here: https:\/\/keras.io\/api\/preprocessing\/image\/#imagedatagenerator-class\n\nAlso, you can find description of all the parameters of the `flow_from_dataframe` method under the following link: https:\/\/keras.io\/api\/preprocessing\/image\/#flow_from_dataframe-method","3e0190dc":"For each whale id, print the percentage (i.e., proportion) of the corresponding entries in the test dataframe with respect to the training dataframe.","90adb3e4":"## Read in the training set","c0c97472":"## Filter whale IDs","d591661e":"<h1>Table of Contents<span class=\"tocSkip\"><\/span><\/h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Data-preprocessing\" data-toc-modified-id=\"Data-preprocessing-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;<\/span>Data preprocessing<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Read-in-the-training-set\" data-toc-modified-id=\"Read-in-the-training-set-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;<\/span>Read in the training set<\/a><\/span><\/li><li><span><a href=\"#Plot-a-few-images-along-with-the-corresponding-whale-IDs\" data-toc-modified-id=\"Plot-a-few-images-along-with-the-corresponding-whale-IDs-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;<\/span>Plot a few images along with the corresponding whale IDs<\/a><\/span><\/li><li><span><a href=\"#Check-how-many-images-there-are-for-all-whale-IDs\" data-toc-modified-id=\"Check-how-many-images-there-are-for-all-whale-IDs-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;<\/span>Check how many images there are for all whale IDs<\/a><\/span><\/li><li><span><a href=\"#Filter-whale-IDs\" data-toc-modified-id=\"Filter-whale-IDs-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;<\/span>Filter whale IDs<\/a><\/span><\/li><li><span><a href=\"#Split-the-filtered-data-into-the-training-and-test-(validation)-set\" data-toc-modified-id=\"Split-the-filtered-data-into-the-training-and-test-(validation)-set-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;<\/span>Split the filtered data into the training and test (validation) set<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Data-augmentation\" data-toc-modified-id=\"Data-augmentation-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;<\/span>Data augmentation<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Define-a-Keras-data-generator-for-the-data-augmentation-and-apply-this-generator-to-the-splitted-data\" data-toc-modified-id=\"Define-a-Keras-data-generator-for-the-data-augmentation-and-apply-this-generator-to-the-splitted-data-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;<\/span>Define a Keras data generator for the data augmentation and apply this generator to the splitted data<\/a><\/span><\/li><li><span><a href=\"#Plot-some-augmented-data\" data-toc-modified-id=\"Plot-some-augmented-data-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;<\/span>Plot some augmented data<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Model-training\" data-toc-modified-id=\"Model-training-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;<\/span>Model training<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Define-a-model\" data-toc-modified-id=\"Define-a-model-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;<\/span>Define a model<\/a><\/span><\/li><li><span><a href=\"#Train-only-the-new-top-layers-of-the-model\" data-toc-modified-id=\"Train-only-the-new-top-layers-of-the-model-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;<\/span>Train only the new top layers of the model<\/a><\/span><\/li><li><span><a href=\"#Apply-fine-tuning,-that-is,-unfreeze-the-base-model-and-train-the-whole-model-with-a-small-learning-rate\" data-toc-modified-id=\"Apply-fine-tuning,-that-is,-unfreeze-the-base-model-and-train-the-whole-model-with-a-small-learning-rate-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;<\/span>Apply fine-tuning, that is, unfreeze the base model and train the whole model with a small learning rate<\/a><\/span><\/li><li><span><a href=\"#Plot-the-training-history\" data-toc-modified-id=\"Plot-the-training-history-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;<\/span>Plot the training history<\/a><\/span><\/li><\/ul><\/li><\/ul><\/div>","fbd42fbf":"**Kernel description:**\n\nThis kernel demonstrates application of transfer learning with VGG-16 to the given whale multi-class classfication problem. Please note that this is a solution to my university course assignment which differs in the objective from the original stated problem. The difference is that the original training data set is filtered by removing all whale individuals for which the number of images is smaller than the given threshold `NUM_IMAGES_THRESHOLD`. Also, all pictures annotated with 'new whale' label are excluded from the dataset. Last, there is no submission file produced by this kernel.\n\nAnyway, please consider upvoting this kernel if you liked it!\n\nPS. The Table of Contents was generated using ToC2 extension for Jupyter Notebook.","7041b4e3":"## Define a Keras data generator for the data augmentation and apply this generator to the splitted data","b2d83854":"## Train only the new top layers of the model","50a2b4ba":"Note that if the base model contains the batch normalization layers, they will still remain frozen (check the number of non-trainable params in the summary below) so that their learned values (i.e. the mean and stddev) are not \"destroyed\" by the backpropagation process. You can learn more about various nuances related to transfer learning here: https:\/\/keras.io\/guides\/transfer_learning\/","b91f9bb9":"# Model training","b2d82473":"Get rid of the image with the ship.","01552367":"## Define a model"}}