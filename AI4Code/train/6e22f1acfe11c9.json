{"cell_type":{"3e6e0f63":"code","6c23ef09":"code","5ff4e52d":"code","6728449c":"code","b1fb806b":"code","f86f6190":"code","8be4a028":"code","3c950c5f":"code","d3c1f6e6":"code","0fe14684":"code","941eb9e9":"code","3bb7eb74":"code","a2c499f3":"code","5e3b2897":"code","51b12b9d":"code","84c963e3":"code","9cf64c45":"code","3a0cdf87":"code","a9841144":"code","0915ff35":"code","d5fcc005":"code","851d08ad":"code","94d3f363":"code","606d536b":"code","ee413019":"code","e5346600":"code","0256fe4d":"code","3daf763c":"code","d9eb7764":"code","3f98402e":"code","c56550c7":"code","cd28bd1d":"code","34f353eb":"code","6fb782af":"code","d5023991":"code","12377e7b":"code","4f662652":"code","3222d78a":"code","a05a5532":"code","61c747d0":"code","c170cf5e":"code","254d63f8":"code","72b5c3b2":"code","c0c0faca":"code","2d1841bf":"code","6039bd99":"code","8afc7599":"code","b29027a5":"code","ea062b17":"code","e554c833":"code","bd79b34e":"markdown","44ccd596":"markdown","09b4947f":"markdown","210118de":"markdown","9159467d":"markdown","155fa397":"markdown","bf18bcd9":"markdown","4732d30f":"markdown","b1e2e5e4":"markdown","3b09a58c":"markdown","5dda9231":"markdown","f0adb291":"markdown"},"source":{"3e6e0f63":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set(font_scale=1)\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split","6c23ef09":"# Reading the data\nX = pd.read_csv('..\/input\/home-data-for-ml-course\/train.csv', index_col='Id')\nX_test = pd.read_csv('..\/input\/home-data-for-ml-course\/test.csv', index_col='Id')\n\n# Removing rows with missing target, separate target from predictors\nX.dropna(axis=0, subset=['SalePrice'], inplace=True)            \n","5ff4e52d":"X.head()","6728449c":"# Selecting categorical columns with relatively low cardinality\nlow_cardinality_cols = [cname for cname in X.columns if X[cname].nunique() < 10 and \n                        X[cname].dtype == \"object\"]\n\n# Selecting numeric columns\nnumeric_cols = [cname for cname in X.columns if X[cname].dtype in ['int64', 'float64'] and cname!='SalePrice']","b1fb806b":"#combining train and test data\ncombine = [X,X_test]","f86f6190":"# Missng values of numrical columns\nmissing = X[numeric_cols].isnull().sum().sort_values(ascending=False)\nmissing[missing.values>0]","8be4a028":"missing = X_test[numeric_cols].isnull().sum().sort_values(ascending=False)\nmissing[missing.values>0]","3c950c5f":"#LotFrontage: all house have linear connected feet so filling missing data with most mean value\nfor dataset in combine:\n    dataset['LotFrontage']=dataset['LotFrontage'].fillna(dataset['LotFrontage'].dropna().mean())","d3c1f6e6":"#GarageYrBlt and MasVnrArea, can be 0, missing value may represnt that these \n#houses do not have Garage and Masonry Veeener\nfor dataset in combine:\n    dataset['GarageYrBlt']=dataset['GarageYrBlt'].fillna(0)\n    dataset['MasVnrArea']=dataset['MasVnrArea'].fillna(0)","0fe14684":"#Similarly for BsmtHalfBath,BsmtFullBath, GarageArea, BsmtFinSF1, BsmtFinSF2, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF, GarageCars\nfor col in ['BsmtHalfBath','BsmtFullBath','GarageArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','GarageCars']:\n    X_test[col]=X_test[col].fillna(0)","941eb9e9":"#No more missing values for numerical columns\nmissing = X[numeric_cols].isnull().sum().sort_values(ascending=False)\nmissing[missing.values>0]","3bb7eb74":"missing = X_test[numeric_cols].isnull().sum().sort_values(ascending=False)\nmissing[missing.values>0]","a2c499f3":"#Missing values for Categorical columns\nmissing = X[low_cardinality_cols].isnull().sum().sort_values(ascending=False)\nmissing[missing.values>0]","5e3b2897":"missing = X_test[low_cardinality_cols].isnull().sum().sort_values(ascending=False)\nmissing[missing.values>0]","51b12b9d":"#PoolQC, MiscFeature : Since most houses do not have a pool we can fill missing values with NA\nfor dataset in combine:\n    dataset['PoolQC']=dataset['PoolQC'].fillna('NA')\n    dataset['MiscFeature']=dataset['MiscFeature'].fillna('NA')","84c963e3":"# Similarly for Alley, Fence, FireplaceQu, GarageCond, GarageQual, GarageFinish and GarageType filling NA\nfor dataset in combine:\n    for col in ['Alley','Fence','FireplaceQu','GarageCond','GarageQual','GarageFinish','GarageType']:\n        dataset[col]=dataset[col].fillna('NA')","9cf64c45":"# Also for BsmtFinType2, BsmtExposure, BsmtCond, BsmtFinType1, BsmtQual, MasVnrType\nfor dataset in combine:\n    for col in ['BsmtFinType2','BsmtExposure','BsmtCond','BsmtFinType1','BsmtQual','MasVnrType']:\n        dataset[col]=dataset[col].fillna('NA')","3a0cdf87":"# Electrical : There is single missing value for this feature so filling missing value with most occuring value\nX['Electrical']=X['Electrical'].fillna(X['Electrical'].dropna().value_counts().index[0])\nX['Electrical'].unique()","a9841144":"#Similarly for MSZoning, Utilities, Functional, KitchenQual, SaleType in test dataset\nfor col in ['MSZoning', 'Utilities', 'Functional', 'KitchenQual', 'SaleType']:\n    X_test[col]=X_test[col].fillna(X_test[col].dropna().value_counts().index[0])","0915ff35":"#No more missing values for Categorical columns\nmissing = X[low_cardinality_cols].isnull().sum().sort_values(ascending=False)\nmissing[missing.values>0]","d5fcc005":"missing = X_test[low_cardinality_cols].isnull().sum().sort_values(ascending=False)\nmissing[missing.values>0]","851d08ad":"#Creating heatmap to check which numeric features are correlated with SalePrice\nnumeric_cols.append('SalePrice')\ncorrelation=X[numeric_cols].corr().sort_values(by='SalePrice',ascending=False).round(2)\nprint(correlation['SalePrice'])","94d3f363":"#Top correlated features with SalesPrice are OverallQual,GrLivArea,TotalBsmtSF,GarageCars,1stFlrSF,GarageArea \nplt.subplots(figsize=(12, 9))\nsns.heatmap(correlation, vmax=.8, square=True);","606d536b":"#Creating heatmap for top 10 correlated features\ncols =correlation['SalePrice'].head(10).index\ncm = np.corrcoef(X[cols].values.T)\nsns.set(font_scale=1)\nhm = sns.heatmap(cm, annot=True, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","ee413019":"# It is obvious the Overall Qaulity has direct correlation with Sale price\nplt.title(\"House sale price vs Overall Quality\")\nsns.barplot(x=X['OverallQual'], y=X['SalePrice'])","e5346600":"plt.title(\"House sale price vs GrLivArea\")\nsns.scatterplot(x=X['GrLivArea'],y=X['SalePrice'])","0256fe4d":"#Removing the outliers in above graph\nX=X.drop(X.loc[(X['GrLivArea']>4000) & (X['SalePrice']<200000)].index,0)\nX.reset_index(drop=True, inplace=True)\nsns.scatterplot(x=X['GrLivArea'],y=X['SalePrice'])","3daf763c":"sns.barplot(x=X['GarageCars'],y=X['SalePrice'])","d9eb7764":"sns.scatterplot(x=X['GarageArea'], y=X['SalePrice'])","3f98402e":"# Removing outliers from above\nX=X.drop(X.loc[(X['GarageArea']>1200) & (X['SalePrice']<300000)].index,0)\nX.reset_index(drop=True, inplace=True)\nsns.scatterplot(x=X['GarageArea'],y=X['SalePrice'])","c56550c7":"y = X.SalePrice \nX.drop(['SalePrice'], axis=1, inplace=True)","cd28bd1d":"#Creating new features based on highly correlated features, To increase weight of these features in the model\nfor col in ['GrLivArea','GarageCars','GarageArea','TotalBsmtSF','1stFlrSF']:\n    X[col+'_2']=X[col]**2\n    X_test[col+'_2']=X_test[col]**2\n    X[col+'_3']=X[col]**3\n    X_test[col+'_3']=X_test[col]**3\n    X[col+'_4']=X[col]**4\n    X_test[col+'_4']=X_test[col]**4","34f353eb":"#adding 1stFlrSF and 2ndFlrSF and create new feature Totalfloorfeet\nX['Totalfloorfeet']=X['1stFlrSF']+X['2ndFlrSF']\nX_test['Totalfloorfeet']=X_test['1stFlrSF']+X['2ndFlrSF']\nX=X.drop(['1stFlrSF','2ndFlrSF'],1)\nX_test=X_test.drop(['1stFlrSF','2ndFlrSF'],1)","6fb782af":"#adding BsmtFullBath, BsmtHalfBath, FullBath, HalfBath to create new feature TotalBath\nfor dataset in combine:\n    dataset['Bath']=dataset['BsmtFullBath']+dataset['BsmtHalfBath']*.5+dataset['FullBath']+dataset['HalfBath']*.5\n    dataset=dataset.drop(['BsmtFullBath','BsmtHalfBath','FullBath','HalfBath'],1)","d5023991":"#Test dataset has one more outlier in 'GarageYrBlt' feature\nX_test.loc[X_test['GarageYrBlt']==2207.,'GarageYrBlt']=0","12377e7b":"\nobject_cols = [cname for cname in X.columns if X[cname].nunique() < 10 and \n                        X[cname].dtype == \"object\"]\nnumeric_cols = [cname for cname in X.columns if X[cname].dtype in ['int64', 'float64'] and cname!='SalePrice']","4f662652":"my_cols=object_cols+numeric_cols\nX_final=X[my_cols].copy()\nX_test_final=X_test[my_cols].copy()\ncombine=[X_final,X_test_final]\n\n#Creating dummies for Categorical data\nX_final=pd.get_dummies(X_final)\nX_test=pd.get_dummies(X_test)\n\nX_final, X_test_final = X_final.align(X_test_final, join='left', axis=1)","3222d78a":"[cname for cname in X_final.columns if X_final[cname].nunique() < 10 and \n                        X_final[cname].dtype == \"object\"]\n#[cname for cname in X.columns if X[cname].dtype in ['int64', 'float64'] and cname!='SalePrice']","a05a5532":"from sklearn.preprocessing import StandardScaler","61c747d0":"scaler=StandardScaler()\nscaler=scaler.fit(X_final)\nX_scaled=scaler.transform(X_final)\nX_test_scaled=scaler.transform(X_test_final)","c170cf5e":"X_scaled=pd.DataFrame(X_scaled)\nX_test_scaled=pd.DataFrame(X_test_scaled)","254d63f8":"#1.LinearRegression\nfrom sklearn.linear_model import LinearRegression\nLR=LinearRegression()\nLR.fit(X_scaled,y)\nLR.score(X_scaled,y)","72b5c3b2":"#2.LogisticRegression\nfrom sklearn.linear_model import LogisticRegression\nLogR=LogisticRegression()\nLogR.fit(X_scaled,y)\nprint(LogR.score(X_scaled,y))","c0c0faca":"#3.Support Vector Regression\nfrom sklearn import svm\nsvmR=svm.SVC()\nsvmR.fit(X_scaled,y)\nprint(svmR.score(X_scaled,y))","2d1841bf":"#4.Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import MultinomialNB\ngnb=GaussianNB()\nmnb=MultinomialNB()\ngnb.fit(X_scaled,y)\nmnb.fit(X_final,y)\nprint(gnb.score(X_scaled,y))\nprint(mnb.score(X_final,y))","6039bd99":"#4.DecisionTree\nfrom sklearn.tree import DecisionTreeRegressor\nDtree=DecisionTreeRegressor(criterion='mse',max_depth=5)\nDtree.fit(X_scaled,y)\nprint(Dtree.score(X_scaled,y))","8afc7599":"#7.Random Forest\nfrom sklearn.ensemble import RandomForestRegressor\nRandomFR=RandomForestRegressor(n_estimators=500)\nRandomFR.fit(X_scaled,y)\nprint(RandomFR.score(X_scaled,y))","b29027a5":"#8.XGBoost\nfrom xgboost import XGBRegressor\n\nmodel = XGBRegressor(random_state=0, n_estimators=1000, learning_rate=0.05, n_jobs=4)\nmodel.fit(X_scaled, y, \n             early_stopping_rounds=5, \n             eval_set=[(X_scaled, y)], \n             verbose=False)\nprint(model.score(X_scaled,y))","ea062b17":"preds_test = model.predict(X_test_scaled)","e554c833":"output = pd.DataFrame({'Id': X_test_final.index,\n                       'SalePrice': preds_test})\noutput.to_csv('submission.csv', index=False)","bd79b34e":"# Exploring dataset","44ccd596":"# Importing dataset","09b4947f":"**Verifying correlations:**","210118de":"**Missing values for Categorical columns**","9159467d":"# Importing the libraries","155fa397":"**Data visulization**","bf18bcd9":"# Feauture Engineering","4732d30f":"**Missng values of numrical columns**","b1e2e5e4":"# Handling missing values","3b09a58c":"# Feature Scaling ","5dda9231":"# Fitting ML Algorithms","f0adb291":"**Recreating Column lists**"}}