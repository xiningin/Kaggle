{"cell_type":{"9195f7b2":"code","59e1c440":"code","fe4fb711":"code","947f6073":"code","5fa40f6b":"code","bde3538e":"code","5a9674be":"code","f368aa23":"code","e4cc93e9":"code","b7159d1a":"code","cb44cf2d":"code","82c10592":"code","d1419b4a":"code","eb1fc8bf":"code","c4659196":"code","40790352":"code","39e3e1e6":"code","88b187d4":"code","8f2876c4":"code","455e3291":"code","0e94b024":"code","fc76ff98":"code","98d30ccc":"code","9211d4ee":"code","bc2c117e":"code","f1056184":"code","32535846":"markdown","715725f0":"markdown","c6f0b7fe":"markdown","c640ec1b":"markdown","a70c990f":"markdown","c6de190d":"markdown","5de94b73":"markdown"},"source":{"9195f7b2":"import matplotlib.pyplot as plt\n\ndef evaluating_change_point(true, prediction, metric='nab', numenta_time=None):\n    \"\"\"\n    true - both:\n                list of pandas Series with binary int labels\n                pandas Series with binary int labels\n    prediction - both:\n                      list of pandas Series with binary int labels\n                      pandas Series with binary int labels\n    metric: 'nab', 'binary' (FAR, MAR), 'average_delay'\n                \n    \"\"\"\n    \n    def binary(true, prediction):      \n        \"\"\"\n        true - true binary series with 1 as anomalies\n        prediction - trupredicted binary series with 1 as anomalies\n        \"\"\"\n        def single_binary(true,prediction):\n            true_ = true == 1 \n            prediction_ = prediction == 1\n            TP = (true_ & prediction_).sum()\n            TN = (~true_ & ~prediction_).sum()\n            FP = (~true_ & prediction_).sum()\n            FN = (true_ & ~prediction_).sum()\n            return TP,TN,FP,FN\n            \n        if type(true) != type(list()):\n            TP,TN,FP,FN = single_binary(true,prediction)\n        else:\n            TP,TN,FP,FN = 0,0,0,0\n            for i in range(len(true)):\n                TP_,TN_,FP_,FN_ = single_binary(true[i],prediction[i])\n                TP,TN,FP,FN = TP+TP_,TN+TN_,FP+FP_,FN+FN_       \n    \n        f1 = round(TP\/(TP+(FN+FP)\/2), 2)\n        print(f'False Alarm Rate {round(FP\/(FP+TN)*100,2)} %' )\n        print(f'Missing Alarm Rate {round(FN\/(FN+TP)*100,2)} %')\n        print(f'F1 metric {f1}')\n        return f1\n    \n    def average_delay(detecting_boundaries, prediction):\n        \n        def single_average_delay(detecting_boundaries, prediction):\n            missing = 0\n            detectHistory = []\n            for couple in detecting_boundaries:\n                t1 = couple[0]\n                t2 = couple[1]\n                if prediction[t1:t2].sum()==0:\n                    missing+=1\n                else:\n                    detectHistory.append(prediction[prediction ==1][t1:t2].index[0]-t1)\n            return missing, detectHistory\n            \n        \n        if type(prediction) != type(list()):\n            missing, detectHistory = single_average_delay(detecting_boundaries, prediction)\n        else:\n            missing, detectHistory = 0, []\n            for i in range(len(prediction)):\n                missing_, detectHistory_ = single_average_delay(detecting_boundaries[i], prediction[i])\n                missing, detectHistory = missing+missing_, detectHistory+detectHistory_\n\n        add = pd.Series(detectHistory).mean()\n        print('Average delay', add)\n        print(f'A number of missed CPs = {missing}')\n        return add\n    \n    def evaluate_nab(detecting_boundaries, prediction, table_of_coef=None):\n        \"\"\"\n        Scoring labeled time series by means of\n        Numenta Anomaly Benchmark methodics\n        Parameters\n        ----------\n        detecting_boundaries: list of list of two float values\n            The list of lists of left and right boundary indices\n            for scoring results of labeling\n        prediction: pd.Series with timestamp indices, in which 1 \n            is change point, and 0 in other case. \n        table_of_coef: pandas array (3x4) of float values\n            Table of coefficients for NAB score function\n            indeces: 'Standart','LowFP','LowFN'\n            columns:'A_tp','A_fp','A_tn','A_fn'\n        Returns\n        -------\n        Scores: numpy array, shape of 3, float\n            Score for 'Standart','LowFP','LowFN' profile \n        Scores_null: numpy array, shape 3, float\n            Null score for 'Standart','LowFP','LowFN' profile             \n        Scores_perfect: numpy array, shape 3, float\n            Perfect Score for 'Standart','LowFP','LowFN' profile  \n        \"\"\"\n        def single_evaluate_nab(detecting_boundaries, prediction, table_of_coef=None, name_of_dataset=None):\n            if table_of_coef is None:\n                table_of_coef = pd.DataFrame([[1.0,-0.11,1.0,-1.0],\n                                     [1.0,-0.22,1.0,-1.0],\n                                      [1.0,-0.11,1.0,-2.0]])\n                table_of_coef.index = ['Standart','LowFP','LowFN']\n                table_of_coef.index.name = \"Metric\"\n                table_of_coef.columns = ['A_tp','A_fp','A_tn','A_fn']\n\n            alist = detecting_boundaries.copy()\n            prediction = prediction.copy()\n\n            Scores, Scores_perfect, Scores_null=[], [], []\n            for profile in ['Standart', 'LowFP', 'LowFN']:       \n                A_tp = table_of_coef['A_tp'][profile]\n                A_fp = table_of_coef['A_fp'][profile]\n                A_fn = table_of_coef['A_fn'][profile]\n                def sigm_scale(y, A_tp, A_fp, window=1):\n                    return (A_tp-A_fp)*(1\/(1+np.exp(5*y\/window))) + A_fp\n\n                #First part\n                score = 0\n                if len(alist)>0:\n                    score += prediction[:alist[0][0]].sum()*A_fp\n                else:\n                    score += prediction.sum()*A_fp\n                #second part\n                for i in range(len(alist)):\n                    if i<=len(alist)-2:\n                        win_space = prediction[alist[i][0]:alist[i+1][0]].copy()\n                    else:\n                        win_space = prediction[alist[i][0]:].copy()\n                    win_fault = prediction[alist[i][0]:alist[i][1]]\n                    slow_width = int(len(win_fault)\/4)\n\n                    if len(win_fault) + slow_width >= len(win_space):\n                        print(f'Intersection of the windows of too wide widths for dataset {name_of_dataset}')\n                        win_fault_slow = win_fault.copy()\n                    else:\n                        win_fault_slow= win_space[:len(win_fault)  +  slow_width]\n\n                    win_fp = win_space[-len(win_fault_slow):]\n\n                    if win_fault_slow.sum() == 0:\n                        score+=A_fn\n                    else:\n                        #to get the first index\n                        tr = pd.Series(win_fault_slow.values,index = range(-len(win_fault), len(win_fault_slow)-len(win_fault)))\n                        tr_values= tr[tr==1].index[0]\n                        tr_score = sigm_scale(tr_values, A_tp,A_fp,slow_width)\n                        score += tr_score\n                        score += win_fp.sum()*A_fp\n                Scores.append(score)\n                Scores_perfect.append(len(alist)*A_tp)\n                Scores_null.append(len(alist)*A_fn)\n            return np.array([np.array(Scores),np.array(Scores_null), np.array(Scores_perfect)])\n       #======      \n        if type(prediction) != type(list()):\n            matrix = single_evaluate_nab(detecting_boundaries, prediction, table_of_coef=table_of_coef)\n        else:\n            matrix = np.zeros((3,3))\n            for i in range(len(prediction)):\n                matrix_ = single_evaluate_nab(detecting_boundaries[i], prediction[i], table_of_coef=table_of_coef,name_of_dataset=i)\n                matrix = matrix + matrix_      \n                \n        results = {}\n        desc = ['Standart', 'LowFP', 'LowFN'] \n        for t, profile_name in enumerate(desc):\n            results[profile_name] = round(100*(matrix[0,t]-matrix[1,t])\/(matrix[2,t]-matrix[1,t]), 2)\n            print(profile_name,' - ', results[profile_name])\n        \n        return results\n            \n            \n    #=========================================================================\n    if type(true) != type(list()):\n        true_items = true[true==1].index\n    else:\n        true_items = [true[i][true[i]==1].index for i in range(len(true))]\n        \n\n    if not metric=='binary':\n        def single_detecting_boundaries(true, numenta_time, true_items):\n            detecting_boundaries=[]\n            td = pd.Timedelta(numenta_time) if numenta_time is not None else pd.Timedelta((true.index[-1]-true.index[0])\/len(true_items))  \n            for val in true_items:\n                detecting_boundaries.append([val, val + td])\n            return detecting_boundaries\n        \n        if type(true) != type(list()):\n            detecting_boundaries = single_detecting_boundaries(true=true, numenta_time=numenta_time, true_items=true_items)\n        else:\n            detecting_boundaries=[]\n            for i in range(len(true)):\n                detecting_boundaries.append(single_detecting_boundaries(true=true[i], numenta_time=numenta_time, true_items=true_items[i]))\n\n    if metric== 'nab':\n        return evaluate_nab(detecting_boundaries, prediction)\n    elif metric=='average_delay':\n        return average_delay(detecting_boundaries, prediction)\n    elif metric== 'binary':\n        return binary(true, prediction)\ndef Score_data(pred, real):\n    # computing errors\n    errors = np.abs(pred - real).flatten()\n    # estimation\n    mean = sum(errors)\/len(errors)\n    cov = 0\n    for e in errors:\n        cov += (e - mean)**2\n    cov \/= len(errors)\n\n    print('mean : ', mean)\n    print('cov : ', cov)\n    return errors, cov, mean\n\n# calculate Mahalanobis distance\ndef Mahala_distantce(x,mean,cov):\n    return (x - mean)**2 \/ cov\n\ndef scale(A):\n    return (A-np.min(A))\/(np.max(A) - np.min(A))    ","59e1c440":"df_server1 = pd.read_csv('\/kaggle\/input\/benchmark-labeled-anomaly-detection-ts\/server_res_eth1out_curve_61.csv')\ndf_server2 = pd.read_csv('\/kaggle\/input\/benchmark-labeled-anomaly-detection-ts\/rver_res_eth1out_curve_6.csv')\ndf_g = pd.read_csv('\/kaggle\/input\/benchmark-labeled-anomaly-detection-ts\/g.csv')\ndf_cpu = pd.read_csv('\/kaggle\/input\/benchmark-labeled-anomaly-detection-ts\/cpu4.csv')","fe4fb711":"df_server1.head()","947f6073":"df_server1.shape, df_server2.shape, df_g.shape, df_cpu.shape","5fa40f6b":"df_server1.label.value_counts(), df_server2.label.value_counts(), df_g.label.value_counts(), df_cpu.label.value_counts()","bde3538e":"df_server1.label.value_counts()\/df_server1.shape[0]*100, df_server2.label.value_counts()\/df_server2.shape[0]*100, df_g.label.value_counts()\/df_g.shape[0]*100, df_cpu.label.value_counts()\/df_cpu.shape[0]*100,","5a9674be":"import missingno as msno\n\nmsno.matrix(df_cpu[['timestamp', 'value']])","f368aa23":"df_cpu.head(2)","e4cc93e9":"# plotting the labels both for outlier and changepoint detection problems\ndf_cpu.value.plot(figsize=(12,3))\n# df_cpu.scores.plot()\n# df_cpu.scores_norm.plot()\ndf_cpu.outlier.plot()\nplt.legend()\nplt.show()","b7159d1a":"from statsmodels.tsa.arima_model import ARIMA\n\n# follow lag\nmodel_ar = ARIMA(df_cpu['value'], order=(1,1,0))  \nresults_ARIMA_ar = model_ar.fit(disp=-1)","cb44cf2d":"errors, cov, mean = Score_data(results_ARIMA_ar.fittedvalues.values.flatten(), df_cpu['value'].values.flatten()[0:len(results_ARIMA_ar.fittedvalues)])\n","82c10592":"mahala_dist = []\nfor e in errors:\n    mahala_dist.append(Mahala_distantce(e, mean, cov))","d1419b4a":"df_cpu['scores'] = [0]+mahala_dist\n\ndf_cpu['scores_norm'] = scale([0]+mahala_dist)\nplt.figure(figsize=(12, 8))\nplt.hist(df_cpu['scores_norm'], bins=50);","eb1fc8bf":"q1_pc1, q3_pc1 = df_cpu['scores'].quantile([0.25, 0.75])\niqr_pc1 = q3_pc1 - q1_pc1\n\n# Calculate upper and lower bounds for outlier for pc1\nlower_pc1 = q1_pc1 - (1.5*iqr_pc1)\nupper_pc1 = q3_pc1 + (1.5*iqr_pc1)\n    # Filter out the outliers from the pc1\ndf_cpu['outlier'] = ((df_cpu['scores']>upper_pc1) | (df_cpu['scores']<lower_pc1)).astype('int')","c4659196":"true = df_cpu.label\nprediction = df_cpu.outlier\nscore = df_cpu.scores","40790352":"df_cpu.label.value_counts() \/ df_cpu.shape[0]*100","39e3e1e6":"df_cpu.head(2)","88b187d4":"# true outlier indices selection\n\ndf_cpu.outlier.plot(figsize=(12,3), label='predictions', marker='o', markersize=5)\n\ndf_cpu.label.plot(marker='o', markersize=2)\nplt.legend();","8f2876c4":"# binary classification metrics calculation\nbinary = evaluating_change_point(df_cpu.label, df_cpu.outlier, metric='binary', numenta_time='30 sec')","455e3291":"from datetime import datetime\nl_datetime = []\nfor i in range(df_cpu.shape[0]):\n    l_datetime.append(datetime.fromtimestamp(df_cpu.timestamp[i]) )\n\ndf_cpu['datetime'] =l_datetime\ndf_cpu.head(2)","0e94b024":"nab_df = df_cpu[['datetime','label', 'outlier']]\nnab_df.index = df_cpu.datetime\n# average detection delay metric calculation\nadd = evaluating_change_point(nab_df.label, nab_df.outlier, metric='average_delay', numenta_time='30 sec')","fc76ff98":"# nab metric calculation\nnab = evaluating_change_point(nab_df.label, nab_df.outlier, metric='nab', numenta_time='30 sec')","98d30ccc":"def anomaly_plot(df_cpu, target, text):\n    # visualization\n    a = df_cpu.loc[df_cpu[target] == 1] \n    _ = plt.figure(figsize=(18,6))\n    _ = plt.plot(df_cpu['value'], color='blue', label='Inline')\n    _ = plt.plot(a['value'], linestyle='none', marker='X', color='red', markersize=12, label='Anomalies')\n    _ = plt.xlabel('Series')\n    _ = plt.ylabel('Data')\n    _ = plt.title(text)\n    _ = plt.legend(loc='best')\n    plt.show();\n    \nanomaly_plot(df_cpu, 'outlier', \"Predicted Anomalies\")\nanomaly_plot(df_cpu, 'label', \"Truth Anomalies\")","9211d4ee":"#2 -- Distributions of Predicted Probabilities of both classes\nlabels=['Positivo','negativo']\nplt.hist(df_cpu[df_cpu['outlier']==1]['scores_norm'], density=True, bins=25,\n             alpha=.5, color='green',  label=labels[0])\nplt.hist(df_cpu[df_cpu['outlier']==0]['scores_norm'], density=True, bins=25,\n             alpha=.5, color='red', label=labels[1])\nplt.axvline(.5, color='blue', linestyle='--', label='Fronteira de Decis\u00e3o')\n# plt.xlim([0,1])\nplt.title('Distribui\u00e7\u00e3o dos Valores', size=13)\nplt.xlabel('Valores normalizados', size=13)\nplt.ylabel('Amostra (normalizados)', size=13)\nplt.legend(loc=\"upper right\")","bc2c117e":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n\n# Com politica\nprint(classification_report(true, prediction))\nconfusion_matrix(true, prediction)","f1056184":"from sklearn.metrics import roc_auc_score\n\nroc_auc_score(prediction, true)","32535846":"average detection delay metric calculation","715725f0":"nab metric calculation","c6f0b7fe":"### Missing values","c640ec1b":"### Instalation","a70c990f":"% anomalies","c6de190d":"#### Metrics calculation\n\nbinary classification metrics calculation","5de94b73":"# true outlier indices selection"}}