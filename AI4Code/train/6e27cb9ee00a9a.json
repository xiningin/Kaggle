{"cell_type":{"4835b1c0":"code","133d6272":"code","95f76897":"code","f43f2197":"code","da50fbd7":"code","69e32fc8":"code","07ff509d":"code","01d53476":"code","0d945c3a":"code","551fe9fd":"code","cd25ac2d":"markdown","8788f144":"markdown","c3ba001b":"markdown","69f16721":"markdown","9d2e9a5c":"markdown","70968849":"markdown","53ebaf17":"markdown","5778e8c8":"markdown","1dbaf2f2":"markdown"},"source":{"4835b1c0":"import pandas as pd\nimport numpy as np\nimport random\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Dense, Dropout, Activation\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback, ReduceLROnPlateau\nfrom sklearn.preprocessing import StandardScaler  \nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\nseed_everything(2020)    ","133d6272":"df = pd.read_excel('..\/input\/4th-datarobot-ai-academy-deep-learning\/sales_prediction.xlsx')\n# Cleasing\ndf = df[df['Sales']>0].reset_index(drop=True)\ndf['Holiday'] = df['Holiday'].map(lambda x: 0 if x=='No' else 1)\ndf['DestinationEvent'] = df['DestinationEvent'].map(lambda x: 0 if x=='No' else 1)\n# Calendar Feature\ndf['year'] = df['Date'].dt.year\ndf['quarter'] = df['Date'].dt.quarter\ndf['month'] = df['Date'].dt.month\ndf['weekofoyear'] = df['Date'].dt.weekofyear\ndf['dayoyear'] = df['Date'].dt.dayofyear\ndf['dayofweek'] = df['Date'].dt.dayofweek\ndf['weekend'] = (df['Date'].dt.weekday >=5).astype(int)\ndf['dayofmonth'] = df['Date'].dt.day\n# Lag Feature\ndf['Sales_lag7'] = df['Sales'].shift(7)\ndf['Num_Customers_lag7'] = df['Num_Customers'].shift(7)\ndf['Num_Employees_lag7'] = df['Num_Employees'].shift(7)\ndf['Pct_On_Sale_lag7'] = df['Pct_On_Sale'].shift(7)\ndf['Pct_Promotional_lag7'] = df['Pct_Promotional'].shift(7)\ndf['Returns_Pct_lag7'] = df['Returns_Pct'].shift(7)\n\ndisplay(df.head())\ndisplay(df.columns.values)","95f76897":"# \u7279\u5fb4\u91cf\nnum_cols = ['chrismas', 'blackfriday',\n       'Holiday', 'DestinationEvent','year', 'quarter', 'month',\n       'weekofoyear', 'dayoyear', 'dayofweek', 'weekend', 'dayofmonth',\n       'Sales_lag7', 'Num_Customers_lag7', 'Num_Employees_lag7',\n       'Pct_On_Sale_lag7', 'Pct_Promotional_lag7', 'Returns_Pct_lag7']\ntarget = ['Sales']\n\n# \u6b20\u640d\u5024\u88dc\u586b\ndf[num_cols] = df[num_cols].fillna(0)\n\n# \u6b63\u898f\u5316\nscaler = StandardScaler()\ndf[num_cols] = scaler.fit_transform(df[num_cols])","f43f2197":"# \u8a13\u7df4\u3000\u691c\u5b9a\u3000\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3092\u5206\u5272\ntrain = df[df['Date']<='2014-06-07']\nvalid = df[df['Date']>'2014-06-07'] \n\n# \u7279\u5fb4\u91cf\u3068\u30bf\u30fc\u30b2\u30c3\u30c8\ntrain_x_num,train_y = train[num_cols].values,train[target].values\nvalid_x_num,valid_y = valid[num_cols].values,valid[target].values\n\nprint (train_x_num.shape)\nprint (valid_x_num.shape)","da50fbd7":"def mlp(num_cols):\n    \"\"\"\n    \u6f14\u7fd2:Dropout\u3092\u5909\u66f4\u3057\u3066\u307f\u3066\u304f\u3060\u3055\u3044\n    \"\"\"\n    model = Sequential()\n    model.add(Dense(units=512, input_shape = (len(num_cols),), \n                    kernel_initializer='he_normal',activation='relu'))    \n    model.add(Dropout(0.2))\n    model.add(Dense(units=256,  kernel_initializer='he_normal',activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(units=32, kernel_initializer='he_normal', activation='relu'))     \n    model.add(Dropout(0.2))\n    model.add(Dense(1, activation='linear'))\n    model.compile(loss='mape', optimizer='adam', metrics=['mape']) \n    return model","69e32fc8":"filepath = \"mlp_best_model.hdf5\" \n\n\"\"\"\n\u6f14\u7fd2:patience\u3092\u5909\u66f4\u3057\u3066\u307f\u3066\u304f\u3060\u3055\u3044\n\"\"\"\nes = EarlyStopping(patience=2, mode='min', verbose=1) \n\ncheckpoint = ModelCheckpoint(monitor='val_loss',filepath=filepath, save_best_only=True, mode='auto') \n\nreduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', patience=2, factor=0.1, verbose=1, mode='min')\n\nmodel = mlp(num_cols)\n\n\"\"\"\n\u6f14\u7fd2:batch_size,epochs\u3092\u5909\u66f4\u3057\u3066\u307f\u3066\u304f\u3060\u3055\u3044\n\"\"\"\nhistory = model.fit(train_x_num, train_y, batch_size=32, epochs=100, validation_data=(valid_x_num, valid_y), \n                    callbacks=[es, checkpoint, reduce_lr_loss], verbose=1)","07ff509d":"def mean_absolute_percentage_error(y_true, y_pred): \n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return np.mean(np.abs((y_true - y_pred) \/ y_true)) * 100\n\n# load best model weights\nmodel.load_weights(filepath)\n\n# predict valid data\nvalid_pred = model.predict(valid_x_num, batch_size=32).reshape((-1,1))\nvalid_score = mean_absolute_percentage_error(valid_y,  valid_pred)\nprint ('valid mape:',valid_score)\n","01d53476":"model.summary()","0d945c3a":"plot_model(model, to_file='mlp.png')","551fe9fd":"loss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(loss))\nplt.plot(epochs, loss, 'bo' ,label = 'training loss')\nplt.plot(epochs, val_loss, 'b' , label= 'validation loss')\nplt.title('Training and Validation loss')\nplt.legend()\nplt.show()","cd25ac2d":"# \u8a13\u7df4\u3001\u691c\u5b9a\u30c7\u30fc\u30bf\u3092\u4f5c\u6210","8788f144":"# \u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u30a4\u30f3\u30dd\u30fc\u30c8 ","c3ba001b":"# MLP Sequential\u30e2\u30c7\u30eb\u3092\u5b9a\u7fa9\u3059\u308b","69f16721":" # \u6b20\u640d\u5024\u51e6\u7406\u3068\u6b63\u898f\u5316","9d2e9a5c":"# \u30e2\u30c7\u30eb\u53ef\u8996\u5316","70968849":"# \u8a13\u7df4\u5c65\u6b74\u53ef\u8996\u5316","53ebaf17":"# \u30c7\u30fc\u30bf\u524d\u51e6\u7406","5778e8c8":"# \u30e2\u30c7\u30eb\u306e\u8a13\u7df4","1dbaf2f2":"# \u30e2\u30c7\u30eb\u8a55\u4fa1"}}