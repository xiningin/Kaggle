{"cell_type":{"8121121f":"code","843967b7":"code","f5fc4e04":"code","82cf6891":"code","6c574b5c":"code","a606cae1":"code","c8db2ff4":"code","17861116":"code","1ab24404":"code","e3636ff8":"code","1a112358":"code","c51dabbf":"code","ba671cee":"code","5778a827":"code","fae2dad4":"code","e015b1d8":"code","6420f7c8":"code","cd39cea3":"code","03947063":"code","f29c9265":"code","ba9c90bf":"code","72599ebc":"code","05001707":"code","649cc787":"code","ddeb0732":"code","59c5660a":"code","eadbf690":"code","a9f95eb3":"code","3bac62de":"code","d5038dbc":"code","0f82e728":"code","a35cf414":"code","26168bd2":"code","83c857a0":"code","fed4c4b1":"code","6768b044":"markdown","4e7ba7df":"markdown","6e047ced":"markdown","3d72c4be":"markdown","1adc4c93":"markdown","d617f9dd":"markdown","b91a42f0":"markdown"},"source":{"8121121f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","843967b7":"# scintific computing libraries\nimport pandas as pd                                         \nimport numpy as np                                    \nimport scipy.optimize as opt                            \n\n# visualisation libraries\nimport matplotlib.pyplot as plt                                    \nimport seaborn as sns                               \n\n# algorithmic library\nfrom sklearn import svm                                            \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression, LinearRegression, Ridge\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost as xgb\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score\nfrom sklearn.metrics import accuracy_score, jaccard_similarity_score, f1_score, log_loss\n\n%matplotlib inline","f5fc4e04":"df_train = pd.read_csv('\/kaggle\/input\/train.csv')\nprint(df_train.shape)\ndf_train.head()","82cf6891":"df_test = pd.read_csv('\/kaggle\/input\/test.csv')\nprint(df_test.shape)\ndf_test.head()","6c574b5c":"df_train.describe(include='all')","a606cae1":"def data_analysis(df1,  df2):\n    print(df1.shape, df2.shape)\n    train_dtype = []\n    train_isnull = []\n    train_unique = []\n    test_dtype = []\n    test_isnull = []\n    test_unique = []\n    for col in df2.columns:\n        train_dtype.append(df1[col].dtypes)\n        train_isnull.append(df1[col].isnull().sum())\n        train_unique.append(df1[col].unique().shape[0])\n        test_dtype.append(df2[col].dtypes)\n        test_isnull.append(df2[col].isnull().sum())\n        test_unique.append(df2[col].unique().shape[0])\n\n    df = pd.DataFrame({'train_dtype':train_dtype,'test_dtype':test_dtype,'train_isnull':train_isnull,'test_isnull':test_isnull,\n                       'train_unique':train_unique,'test_unique':test_unique}, index=df2.columns)\n    df.sort_values(['train_isnull'], axis=0, ascending=False, inplace=True)\n    return df","c8db2ff4":"data_analysis(df_train, df_test)","17861116":"df_train.drop(['PassengerId','Name','Ticket','Cabin'], axis=1, inplace=True)\ndf_test.drop(['PassengerId','Name','Ticket','Cabin'], axis=1, inplace=True)","1ab24404":"df_train['Age'].fillna(df_train['Age'].median(), inplace=True)\ndf_train['Embarked'].fillna(df_train['Embarked'].mode()[0], inplace=True)\n\ndf_test['Age'].fillna(df_test['Age'].median(), inplace=True)\ndf_test['Fare'].fillna(df_test['Fare'].median(), inplace=True)","e3636ff8":"#df_train[[\"Age\", \"Fare\"]] = df_train[[\"Age\", \"Fare\"]].astype(\"int\")","1a112358":"print(df_train['Survived'].value_counts().to_frame(), '\\n')\nprint(df_train['Sex'].value_counts().to_frame(), '\\n')\nprint(df_train['Pclass'].value_counts().to_frame(), '\\n')\nprint(df_train['Embarked'].value_counts().to_frame())","c51dabbf":"df_train['Sex'] = df_train['Sex'].map(lambda X : 0 if X == 'female' else 1)\ndf_test['Sex'] = df_test['Sex'].map(lambda X : 0 if X == 'female' else 1)","ba671cee":"cols = pd.get_dummies(df_train[['Embarked']])\ndf_train = pd.concat([df_train, cols], axis=1)\ndf_train.drop(['Embarked'], axis = 1, inplace = True)\n\ncols = pd.get_dummies(df_test[['Embarked']])\ndf_test = pd.concat([df_test, cols], axis=1)\ndf_test.drop(['Embarked'], axis = 1, inplace = True)","5778a827":"df_train['SibSp_Parch'] = df_train['SibSp']+df_train['Parch']+1\ndf_train.loc[df_train['SibSp_Parch'] == 1, 'SibSp_Parch'] = 0\ndf_train.loc[df_train['SibSp_Parch'] > 1, 'SibSp_Parch'] = 1\ndf_train.drop(['SibSp','Parch'], axis = 1, inplace = True)\n\ndf_test['SibSp_Parch'] = df_test['SibSp']+df_test['Parch']+1\ndf_test.loc[df_test['SibSp_Parch'] == 1, 'SibSp_Parch'] = 0\ndf_test.loc[df_test['SibSp_Parch'] > 1, 'SibSp_Parch'] = 1\ndf_test.drop(['SibSp','Parch'], axis = 1, inplace = True)","fae2dad4":"df_train.head()","e015b1d8":"df_test.head()","6420f7c8":"df_train.corr()","cd39cea3":"from scipy import stats\ncolumns = df_train.columns\nfor col in columns:\n    pearson_coef, p_value = stats.pearsonr(df_train[col], df_train['Survived'])\n    print(\"The Pearson Correlation Coefficient of  \",col,' is', pearson_coef, \" with a P-value of P =\", p_value)","03947063":"sns.distplot(df_train['Fare'])","f29c9265":"df_train['fare'] = pd.cut(df_train['Fare'], 5)\ndf_train['fare'].value_counts()","ba9c90bf":"df_train.loc[(df_train['Fare'] <= 100), 'Fare'] = 0\ndf_train.loc[(df_train['Fare'] > 100) & (df_train['Fare'] <= 200), 'Fare'] = 1\ndf_train.loc[(df_train['Fare'] > 200) & (df_train['Fare'] <= 300), 'Fare'] = 2\ndf_train.loc[(df_train['Fare'] > 300) & (df_train['Fare'] <= 400), 'Fare'] = 3\ndf_train.loc[(df_train['Fare'] > 400), 'Fare'] = 4\ndf_train.drop('fare', axis = 1, inplace = True)\n\ndf_test.loc[(df_test['Fare'] <= 100), 'Fare'] = 0\ndf_test.loc[(df_test['Fare'] > 100) & (df_test['Fare'] <= 200), 'Fare'] = 1\ndf_test.loc[(df_test['Fare'] > 200) & (df_test['Fare'] <= 300), 'Fare'] = 2\ndf_test.loc[(df_test['Fare'] > 300) & (df_test['Fare'] <= 400), 'Fare'] = 3\ndf_test.loc[(df_test['Fare'] > 400), 'Fare'] = 4","72599ebc":"df_train['age'] = pd.cut(df_train['Age'], 5)\ndf_train['age'].value_counts()","05001707":"df_train.loc[(df_train['Age'] <= 16), 'Age'] = 0\ndf_train.loc[(df_train['Age'] > 16) & (df_train['Age'] <= 32), 'Age'] = 1\ndf_train.loc[(df_train['Age'] > 32) & (df_train['Age'] <= 48), 'Age'] = 2\ndf_train.loc[(df_train['Age'] > 48) & (df_train['Age'] <= 64), 'Age'] = 3\ndf_train.loc[(df_train['Age'] > 64), 'Age'] = 4\ndf_train.drop('age', axis = 1, inplace = True)\n\ndf_test.loc[(df_test['Age'] <= 16), 'Age'] = 0\ndf_test.loc[(df_test['Age'] > 16) & (df_test['Age'] <= 32), 'Age'] = 1\ndf_test.loc[(df_test['Age'] > 32) & (df_test['Age'] <= 48), 'Age'] = 2\ndf_test.loc[(df_test['Age'] > 48) & (df_test['Age'] <= 64), 'Age'] = 3\ndf_test.loc[(df_test['Age'] > 64), 'Age'] = 4","649cc787":"df_train.head()","ddeb0732":"df_test.head()","59c5660a":"Y_train = df_train['Survived'].values\nX_train = df_train.drop(['Survived'], axis = 1)\nX_test= df_test\n\nprint(X_train.shape, Y_train.shape)\nprint(X_test.shape)","eadbf690":"X_train = StandardScaler().fit(X_train).transform(X_train)\nX_test = StandardScaler().fit(X_test).transform(X_test)","a9f95eb3":"x_train, x_test, y_train, y_test = train_test_split( X_train, Y_train, test_size=0.2, random_state=4)\nprint ('Train set:', x_train.shape,  y_train.shape)\nprint ('Test set:', x_test.shape,  y_test.shape)","3bac62de":"SVM = svm.SVC(kernel='rbf', gamma = 'auto')\nSVM.fit(x_train, y_train)\n\nSVM_train_predict = SVM.predict(x_train)\nSVM_test_predict = SVM.predict(x_test)\n\nprint('Train Accuracy', accuracy_score(y_train, SVM_train_predict))\nprint(\"Test set Accuracy: \",accuracy_score(y_test, SVM_test_predict))","d5038dbc":"RFC = RandomForestClassifier(n_estimators = 50)\nRFC.fit(x_train, y_train)\n\nRFC_train_predict = RFC.predict(x_train)\nRFC_test_predict = RFC.predict(x_test)\n\nprint('Train Accuracy', accuracy_score(y_train, RFC_train_predict))\nprint(\"Test set Accuracy: \",accuracy_score(y_test, RFC_test_predict))","0f82e728":"XGB = XGBClassifier(max_depth = 3,\n                     subsample = 0.5,\n                     n_estimators = 50,\n                     learning_rate = 0.10,\n                     min_child_weight = 3,\n                     random_state = 5,\n                     reg_alpha = 0,\n                     reg_lambda = 1)\n\nXGB.fit(x_train, y_train)\nXGB_train_predict = XGB.predict(x_train)\nXGB_test_predict = XGB.predict(x_test)\n\nprint('Train Accuracy', accuracy_score(y_train, XGB_train_predict))\nprint('Test Accuracy', accuracy_score(y_test, XGB_test_predict))","a35cf414":"prediction = XGB.predict(X_test)","26168bd2":"df_submission = pd.read_csv('\/kaggle\/input\/gender_submission.csv')\ndf_submission.head()","83c857a0":"df_submission['Survived'] = prediction\ndf_submission.to_csv('prediction.csv', index=False)\ndf_submission.head()","fed4c4b1":"df_submission['Survived'].value_counts()","6768b044":"## Model Development","4e7ba7df":"Train Test Split","6e047ced":"## Data Wrangling","3d72c4be":"## Submission","1adc4c93":"## Data Exploration","d617f9dd":"## Import Library","b91a42f0":"## Data Acquisition"}}