{"cell_type":{"55e1d4af":"code","f9492d54":"code","459ddbdb":"code","c7218a83":"code","40b28768":"markdown","798dde66":"markdown","f7f9d5da":"markdown","c0c7715e":"markdown","9514d13f":"markdown"},"source":{"55e1d4af":"import os, cv2, skimage\nfrom skimage.transform import resize\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils.np_utils import to_categorical\nfrom keras.layers import Conv2D, Dense, Dropout, Flatten, Input, Add, GlobalAveragePooling2D, DepthwiseConv2D, BatchNormalization, LeakyReLU\nfrom keras.models import Model\nfrom keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau\n\nbatch_size = 64\nimageSize = 64\ntarget_dims = (imageSize, imageSize, 3)\nnum_classes = 29\n\ntrain_len = 87000\ntrain_dir = \"..\/input\/asl_alphabet_train\/asl_alphabet_train\/\"\n\ndef get_data(folder):\n    \"\"\"\n    Load the data and labels from the given folder.\n    \"\"\"\n    X = np.empty((train_len, imageSize, imageSize, 3), dtype=np.float32)\n    y = np.empty((train_len,), dtype=np.int)\n    cnt = 0\n\n    for folderName in os.listdir(folder):\n        if not folderName.startswith('.'):\n            if folderName in ['A']:\n                label = 0\n            elif folderName in ['B']:\n                label = 1\n            elif folderName in ['C']:\n                label = 2\n            elif folderName in ['D']:\n                label = 3\n            elif folderName in ['E']:\n                label = 4\n            elif folderName in ['F']:\n                label = 5\n            elif folderName in ['G']:\n                label = 6\n            elif folderName in ['H']:\n                label = 7\n            elif folderName in ['I']:\n                label = 8\n            elif folderName in ['J']:\n                label = 9\n            elif folderName in ['K']:\n                label = 10\n            elif folderName in ['L']:\n                label = 11\n            elif folderName in ['M']:\n                label = 12\n            elif folderName in ['N']:\n                label = 13\n            elif folderName in ['O']:\n                label = 14\n            elif folderName in ['P']:\n                label = 15\n            elif folderName in ['Q']:\n                label = 16\n            elif folderName in ['R']:\n                label = 17\n            elif folderName in ['S']:\n                label = 18\n            elif folderName in ['T']:\n                label = 19\n            elif folderName in ['U']:\n                label = 20\n            elif folderName in ['V']:\n                label = 21\n            elif folderName in ['W']:\n                label = 22\n            elif folderName in ['X']:\n                label = 23\n            elif folderName in ['Y']:\n                label = 24\n            elif folderName in ['Z']:\n                label = 25\n            elif folderName in ['del']:\n                label = 26\n            elif folderName in ['nothing']:\n                label = 27\n            elif folderName in ['space']:\n                label = 28           \n            else:\n                label = 29\n            for image_filename in os.listdir(folder + folderName):\n                img_file = cv2.imread(folder + folderName + '\/' + image_filename)\n                if img_file is not None:\n                    img_file = skimage.transform.resize(img_file, (imageSize, imageSize, 3))\n                    img_arr = np.asarray(img_file).reshape((-1, imageSize, imageSize, 3))\n                    \n                    X[cnt] = img_arr\n                    y[cnt] = label\n                    cnt += 1\n#                     X.append(img_arr)\n#                     y.append(label)\n#     X = np.asarray(X)\n#     y = np.asarray(y)\n    return X,y\n\nX_train, y_train = get_data(train_dir) \n\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.1) \n\n# Encode labels to hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\ny_trainHot = to_categorical(y_train, num_classes=num_classes)\ny_testHot = to_categorical(y_test, num_classes=num_classes)\n\nX_train.shape, y_trainHot.shape, X_test.shape, y_testHot.shape","f9492d54":"train_image_generator = ImageDataGenerator(\n    samplewise_center=True,\n    samplewise_std_normalization=True,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True\n)\n\nval_image_generator = ImageDataGenerator(\n    samplewise_center=True,\n    samplewise_std_normalization=True,\n)\n\ntrain_generator = train_image_generator.flow(x=X_train, y=y_trainHot, batch_size=batch_size, shuffle=True)\nval_generator = val_image_generator.flow(x=X_test, y=y_testHot, batch_size=batch_size, shuffle=False)","459ddbdb":"inputs = Input(shape=target_dims)\nnet = Conv2D(32, kernel_size=3, strides=1, padding=\"same\")(inputs)\nnet = LeakyReLU()(net)\nnet = Conv2D(32, kernel_size=3, strides=1, padding=\"same\")(net)\nnet = LeakyReLU()(net)\nnet = Conv2D(32, kernel_size=3, strides=2, padding=\"same\")(net)\nnet = LeakyReLU()(net)\n\nnet = Conv2D(32, kernel_size=3, strides=1, padding=\"same\")(net)\nnet = LeakyReLU()(net)\nnet = Conv2D(32, kernel_size=3, strides=1, padding=\"same\")(net)\nnet = LeakyReLU()(net)\nnet = Conv2D(32, kernel_size=3, strides=2, padding=\"same\")(net)\nnet = LeakyReLU()(net)\n\nshortcut = net\n\nnet = DepthwiseConv2D(kernel_size=3, strides=1, padding='same', kernel_initializer='he_normal')(net)\nnet = BatchNormalization(axis=3)(net)\nnet = LeakyReLU()(net)\nnet = Conv2D(filters=32, kernel_size=1, strides=1, padding='same', kernel_initializer='he_normal')(net)\nnet = BatchNormalization(axis=3)(net)\nnet = LeakyReLU()(net)\n\nnet = DepthwiseConv2D(kernel_size=3, strides=1, padding='same', kernel_initializer='he_normal')(net)\nnet = BatchNormalization(axis=3)(net)\nnet = LeakyReLU()(net)\nnet = Conv2D(filters=32, kernel_size=1, strides=1, padding='same', kernel_initializer='he_normal')(net)\nnet = BatchNormalization(axis=3)(net)\nnet = LeakyReLU()(net)\n\nnet = Add()([net, shortcut])\n\nnet = GlobalAveragePooling2D()(net)\nnet = Dropout(0.2)(net)\n\nnet = Dense(128, activation='relu')(net)\noutputs = Dense(num_classes, activation='softmax')(net)\n\nmodel = Model(inputs=inputs, outputs=outputs)\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n\nmodel.summary()","c7218a83":"import datetime\nstart_time = datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n\nmodel.fit_generator(train_generator, epochs=30, validation_data=val_generator,\n    steps_per_epoch=train_generator.__len__(),\n    validation_steps=val_generator.__len__(),\n    callbacks=[\n        # TensorBoard(log_dir='.\/logs\/%s' % (start_time)),\n        # ModelCheckpoint('.\/models\/%s.h5' % (start_time), monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),\n        ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=5, verbose=1, mode='auto')\n])","40b28768":"# Data Augmentation","798dde66":"# Model","f7f9d5da":"I used [\"Interpret Sign Language with Deep Learning\"](https:\/\/www.kaggle.com\/paultimothymooney\/interpret-sign-language-with-deep-learning) code for preprocessing dataset by Paul Mooney, Thanks!","c0c7715e":"# Training","9514d13f":"# Data Preparation"}}