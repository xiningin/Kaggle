{"cell_type":{"e7f8c663":"code","8563ed68":"code","6f3bb56b":"code","180e925c":"code","0d104166":"code","9e3b98a8":"code","0129c393":"code","be9ded34":"code","8e416364":"code","1c91fee3":"code","b220ef0d":"code","a356fcfc":"code","101d9833":"code","cf0be457":"code","d4580c28":"code","49984d6e":"code","b581cb51":"code","9dd601e5":"code","d70ddf06":"code","a94035fa":"code","97eb9db0":"code","840a52ec":"code","0c4243ec":"code","9ce99bea":"code","be0554a3":"code","a10f3c21":"code","6e4c4a51":"code","f6c5b826":"code","f922c71f":"code","8775d4cf":"code","51096a34":"markdown","6dfa1eeb":"markdown","284e9929":"markdown","e2b7d73a":"markdown","8889155e":"markdown","9d10c68b":"markdown","4ad93aef":"markdown","96838edf":"markdown","3e008bbe":"markdown","8da6294e":"markdown","cdfa6ad2":"markdown","1328c662":"markdown","a30e47bd":"markdown","848940d4":"markdown","0d0ec679":"markdown","42035da8":"markdown","7cbbefe9":"markdown","9fd6b61b":"markdown","6c072321":"markdown","d59b1338":"markdown"},"source":{"e7f8c663":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8563ed68":"\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\nfrom sklearn.metrics import roc_auc_score,f1_score,accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split","6f3bb56b":"train=pd.read_csv('..\/input\/train-dataset\/train.csv')\ntest=pd.read_csv('..\/input\/test-dataset\/test.csv')","180e925c":"train.info()","0d104166":"test.info()","9e3b98a8":"train=train.drop('id', axis=1)\ntest=test.drop('id', axis=1)","0129c393":"train['one if net income was negative for the last two year zero otherwise'].value_counts()","be9ded34":"train=train.drop('one if net income was negative for the last two year zero otherwise',axis=1)","8e416364":"test['one if net income was negative for the last two year zero otherwise'].value_counts()","1c91fee3":"test=test.drop('one if net income was negative for the last two year zero otherwise',axis=1)","b220ef0d":"train.isnull().sum().sum()","a356fcfc":"z_scores = stats.zscore(train)\nabs_z_scores = np.abs(z_scores)\nabs_z = (abs_z_scores > 3).all(axis=1)\nprint(len(train[abs_z]))","101d9833":"x=train.drop('Bankrupt',axis=1)","cf0be457":"y=train.loc[:,'Bankrupt']","d4580c28":"y.value_counts()","49984d6e":"xt,x_test,yt,y_test=train_test_split(x,y,stratify=y)","b581cb51":"dtc=DecisionTreeClassifier(class_weight='balanced',criterion='entropy',max_depth=100,min_samples_leaf=5)","9dd601e5":"dtc.fit(xt,yt)","d70ddf06":"ydcp=dtc.predict_proba(x_test)[:,1]","a94035fa":"dcprds=dtc.predict(x_test)","97eb9db0":"roc_auc_score(y_test,ydcp)","840a52ec":"f1_score(y_test,dcprds)","0c4243ec":"accuracy_score(y_test,dcprds)","9ce99bea":"predss=pd.DataFrame(dtc.predict_proba(test)[:,1])\npredss.columns=['Bankrupt']\npredss.to_csv('.\/predictions_decision_tree.csv',index=True, index_label='id')","be0554a3":"rfc=RandomForestClassifier(class_weight='balanced',max_depth=4,criterion='entropy',n_estimators=1200)","a10f3c21":"rfc.fit(xt,yt)\nrfcp=rfc.predict_proba(x_test)[:,1]\nroc_auc_score(y_test,rfcp)","6e4c4a51":"rfcprds=rfc.predict(x_test)","f6c5b826":"f1_score(y_test,rfcprds)","f922c71f":"accuracy_score(y_test,rfcprds)","8775d4cf":"predsp=pd.DataFrame(rfc.predict_proba(test)[:,1])\npredsp.columns=['Bankrupt']\npredsp.to_csv('.\/predictions_random_forest.csv',index=True, index_label='id')","51096a34":"Checking how many unique entries we have ","6dfa1eeb":"Fitting the train dataset and geting auc roc score from the test dataset","284e9929":"Checking for null values","e2b7d73a":"Dropping the id columns from the dataset","8889155e":"Saving and creating a csv file for submission","9d10c68b":"Splitting the dataset into training and testing ","4ad93aef":"#Applying Grid search\ndtc=DecisionTreeClassifier(class_weight='balanced')\n\nparam_dist = {max_depth: [50,100,200,400],max_features: [5,6,7,8,9,10],min_samples_leaf: [5,6,7,8,9,10],criterion: [entropy]}\n\nclf = GridSearchCV(dtc, param_dist)\n\nclf.fit(xt,yt)\n\nclf.best_params_\n\nydcp=clf.predict_proba(x_test)[:,1]\n\nroc_auc_score(y_test,ydcp)\n\nclf.score(x_test,y_test)","96838edf":"Creating an instance of the random forest classifier, tuned variables","3e008bbe":"Fitting to the training dataset","8da6294e":"Dropping column","cdfa6ad2":"Checking the scores","1328c662":"Decision tree classifer, class weight attribute used to counteract imbalanced dataset","a30e47bd":"Prediciting the probabilites","848940d4":"This column contains only 1 value so it may not impact model performance","0d0ec679":"Creating proper column\/row setup","42035da8":"Having a first glance at dataset ","7cbbefe9":"Drop in test set","9fd6b61b":"Saving for submission and predicting the test dataset probabilities","6c072321":"Reading in the csv files both testing and training","d59b1338":"Checking for outliers"}}