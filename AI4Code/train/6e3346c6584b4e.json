{"cell_type":{"87f6b3b0":"code","4881f513":"code","c385c9de":"code","8e386e85":"code","e0289e56":"code","d0397ef8":"code","caab6603":"code","08f919d7":"code","378f7117":"code","e83bb5f6":"code","a1d33eb5":"code","508b298c":"code","5e52fae7":"code","cd053609":"code","9186a0c4":"code","11934065":"code","8326f934":"code","03825312":"code","9c7b46d6":"code","80653e1b":"code","cb46eeea":"code","f6584533":"code","b76cfba9":"code","11c11f7a":"code","21161992":"code","f088d928":"code","06b76f50":"code","8f2eea11":"code","cb5a3705":"code","143f9276":"code","aaed3fef":"code","eac90c0f":"code","44d6d496":"code","cc02f562":"code","cce797ca":"code","c478995a":"code","b1fd0987":"code","f602a178":"code","970446ac":"code","0caab896":"code","4e6ffb53":"code","6852772c":"code","d511b8ca":"code","db58e1ad":"code","80612cb0":"code","eff3a1f9":"code","c27c8bc9":"code","dfda1ac9":"code","dc535e75":"code","718d65ee":"code","97bd1298":"code","2aca3617":"code","410b5a5d":"code","6dad3ee9":"code","414397c9":"code","5ca1b1f1":"code","7a919866":"code","bd608241":"code","c70b4b27":"code","bc7d35ff":"code","7c325346":"code","c05a289c":"code","e9b9c771":"code","0fe97a51":"code","39e8284e":"code","ddc6427a":"code","570c6b74":"code","7a948f3e":"code","fec48bc5":"code","db245e3c":"code","50159026":"code","569df1cc":"code","cd9662f9":"code","205864ca":"code","1a85ef77":"code","aab7777a":"code","b796d606":"code","3a8e15a5":"code","b0451d19":"code","8aace119":"code","07e87549":"markdown","104fd109":"markdown","76eff213":"markdown","e8490f09":"markdown","0edd0de8":"markdown","4d531a8d":"markdown","1a11d926":"markdown","c82afdb8":"markdown","aa0200b5":"markdown","a7260fd4":"markdown","6f1d77b2":"markdown","9d244b74":"markdown","85a47186":"markdown","a2fc88a9":"markdown","7aa29cea":"markdown","9fa3486e":"markdown","314907b5":"markdown","5ae14e05":"markdown","db5c73bc":"markdown","f69a96d6":"markdown","e813e2da":"markdown","b9e0bf6c":"markdown","bbd55050":"markdown","177e545d":"markdown","e0966cb6":"markdown","2c612bf2":"markdown","e6cdd732":"markdown","bfe5f3bd":"markdown","8083f856":"markdown","1be4e6d4":"markdown","d9b7f764":"markdown"},"source":{"87f6b3b0":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn.impute import KNNImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\nfrom sklearn.manifold import LocallyLinearEmbedding\nfrom sklearn.manifold import TSNE\nfrom sklearn.manifold import MDS\nfrom sklearn.manifold import Isomap\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neural_network import MLPClassifier","4881f513":"col_names = ['surgery', 'age', 'hospital_number', 'rectal_temp', 'pulse',\n       'respiratory_rate', 'temp_of_extremities', 'peripheral_pulse',\n       'mucous_membrane', 'capillary_refill_time', 'pain', 'peristalsis',\n       'abdominal_distention', 'nasogastric_tube', 'nasogastric_reflux',\n       'nasogastric_reflux_ph', 'rectal_exam_feces', 'abdomen',\n       'packed_cell_volume', 'total_protein', 'abdomo_appearance',\n       'abdomo_protein', 'outcome', 'surgical_lesion', 'lesion_1', 'lesion_2',\n       'lesion_3', 'cp_data']","c385c9de":"dfTrain = pd.read_csv('..\/input\/horse-colic-dataset\/horse.csv')\ndfTest  = pd.read_csv('..\/input\/horse-colic-dataset\/horseTest.csv')","8e386e85":"dfTrain.columns = col_names\ndfTest.columns = col_names","e0289e56":"dfTrain.describe()","d0397ef8":"dfTrain","caab6603":"dfTest.isna().sum()","08f919d7":"dfTest = dfTest.dropna(subset=['outcome']) #We will drop the test line that has a missing value in the target feature (for obvious reasons)\ndfTest.shape","378f7117":"dfTest['surgery'].isna().sum() #We also deleted the row that had a missing value in surgery","e83bb5f6":"def new_punctuation(df): #This manual ordinal encoder was done looking at the documentation to ensure they follow the correct scale (for ex: more pain -> bigger number)\n    df['surgery'] = df['surgery'].map({'yes':1,'no':0}).astype('float64')\n    df['age'] = df['age'].map({'adult':2,'young':1}).astype('float64')\n    df['temp_of_extremities'] = df['temp_of_extremities'].map({'normal':4,'warm':3,'cool':2,'cold':1}).astype('float64')\n    df['peripheral_pulse'] = df['peripheral_pulse'].map({'increased':4,'normal':3,'reduced':2,'absent':1}).astype('float64')\n    df['mucous_membrane'] = df['mucous_membrane'].map({'dark_cyanotic':6,'bright_red':5,'pale_cyanotic':4,'pale_pink':3,'bright_pink':2,'normal_pink':1}).astype('float64')\n    df['capillary_refill_time'] = df['capillary_refill_time'].map({'more_3_sec':3, '3':2, 'less_3_sec':1}).astype('float64')\n    df['pain'] = df['pain'].map({'extreme_pain':5, 'severe_pain':4, 'mild_pain':3, 'depressed':2, 'alert':1}).astype('float64')\n    df['peristalsis'] = df['peristalsis'].map({'absent':4, 'hypomotile':3, 'normal':2, 'hypermotile':1}).astype('float64')\n    df['abdominal_distention'] = df['abdominal_distention'].map({'severe':4,'moderate':3,'slight':2,'none':1}).astype('float64')\n    df['nasogastric_tube'] = df['nasogastric_tube'].map({'significant':3, 'slight':2, 'none':1}).astype('float64')\n    df['nasogastric_reflux'] = df['nasogastric_reflux'].map({'more_1_liter':3, 'less_1_liter':2, 'none':0}).astype('float64')\n    df['rectal_exam_feces'] = df['rectal_exam_feces'].map({'absent':4, 'decreased':3, 'increased':2, 'normal':1}).astype('float64')\n    df['abdomen'] = df['abdomen'].map({'distend_large':5, 'distend_small':4, 'firm':3, 'other':2, 'normal':1}).astype('float64')\n    df['abdomo_appearance'] = df['abdomo_appearance'].map({'serosanguious':3, 'cloudy':2, 'clear':1}).astype('float64')\n    df['outcome'] = df['outcome'].map({'euthanized':2, 'died':1, 'lived':0}).astype('float64')\n    df['surgical_lesion'] = df['surgical_lesion'].map({'yes':1,'no':0}).astype('float64')\n    return df\ndfTrain = new_punctuation(dfTrain)\ndfTest = new_punctuation(dfTest)","a1d33eb5":"y_test = dfTest['outcome']\ndfTest = dfTest.drop(columns = ['outcome'], axis = 1) #We extract the target feature from the test dataframe and assign it to y_test","508b298c":"dfTrain.dtypes","5e52fae7":"dfTrain = dfTrain.drop(columns = ['cp_data','hospital_number'], axis = 1)\ndfTest = dfTest.drop(columns = ['cp_data', 'hospital_number'], axis = 1)","cd053609":"#The features lesion1, 2 and 3 will give us trouble because the way they are formated doesn't make any sense. \n#Therefore, we will create a new feature that counts the number of lesions the horse has to replace them.\ndfTrain.loc[dfTrain['lesion_1'] > 0, 'lesion_1'] = 1\ndfTrain.loc[dfTrain['lesion_2'] > 0, 'lesion_2'] = 1\ndfTrain.loc[dfTrain['lesion_3'] > 0, 'lesion_3'] = 1\n\ndfTrain['num_lesions'] = dfTrain['lesion_1'] + dfTrain['lesion_2'] + dfTrain['lesion_3']\ndfTrain = dfTrain.drop(columns = ['lesion_1','lesion_2', 'lesion_3'], axis = 1)\ndfTrain['num_lesions'].value_counts()","9186a0c4":"dfTest.loc[dfTest['lesion_1'] > 0, 'lesion_1'] = 1\ndfTest.loc[dfTest['lesion_2'] > 0, 'lesion_2'] = 1\ndfTest.loc[dfTest['lesion_3'] > 0, 'lesion_3'] = 1\n\ndfTest['num_lesions'] = dfTest['lesion_1'] + dfTest['lesion_2'] + dfTest['lesion_3']\ndfTest = dfTest.drop(columns = ['lesion_1','lesion_2', 'lesion_3'], axis = 1)","11934065":"plt.figure(figsize=(24,12))\nsns.heatmap(dfTrain.corr(),cmap='magma_r',annot=True)","8326f934":"fig,ax = plt.subplots(3,1,figsize=(15,15))\nsns.lineplot(x=dfTrain['rectal_temp'],y=dfTrain.outcome,ax=ax[0],color='r') #We visualize 3 features with different levels of correlation with outcome\nsns.lineplot(x=dfTrain['rectal_exam_feces'],y=dfTrain.outcome,ax=ax[1],color='b')\nsns.lineplot(x=dfTrain['peripheral_pulse'],y=dfTrain.outcome,ax=ax[2],color='g')","03825312":"chosen_cols = ['rectal_temp', 'pulse', 'respiratory_rate', 'packed_cell_volume', 'outcome']\nsns.pairplot(dfTrain[chosen_cols], hue='outcome', palette = 'viridis'); #We can see a clear correlation for example with high packed cell volume meaning no survival (the same with pulse not with resprate)","9c7b46d6":"sns.pairplot(dfTrain[chosen_cols], kind=\"kde\"); #This graph helps us show where most values are concentrated in some numerical features","80653e1b":"sns.countplot(data=dfTrain, x='pain', hue = 'outcome') #We can see how the bigger the pain, the less the chance of survival","cb46eeea":"sns.countplot(data=dfTrain, x='mucous_membrane', hue = 'outcome') #We can see how the worse the circulation-> less the chance of survival","f6584533":"sns.countplot(data=dfTrain, x='capillary_refill_time', hue = 'outcome') #We can see how the worse the circulation-> less the chance of survival","b76cfba9":"sns.countplot(data=dfTrain, x='peristalsis', hue = 'outcome') #the lesser the activity on the horses gut the lesser the chance of survival","11c11f7a":"sns.countplot(data=dfTrain, x='abdominal_distention', hue = 'outcome') #the more distended the abdomen the lesser the chance of survival (it means more pain like the documentation says)","21161992":"sns.countplot(data=dfTrain, x='age', hue = 'outcome') #surprisingly, the age of the horse doesn't have a big impact on the outcome of the surgery\n#however younger horses tend to survive less","f088d928":"dfTrain.dtypes","06b76f50":"dfTrain.isna().sum() #There are no columns that have null values in the test dataframe but not in the train dataframe","8f2eea11":"#We start finding which columns to eliminate\nfor col in dfTrain.columns:\n  if dfTrain[col].isna().sum() > 150:\n    print('Column ' + col + ' --> NULL VALUES: ' + str(dfTrain[col].isna().sum()) + ' \/\/ --> CORRELATION WITH TARGET ' + str(dfTrain.corr()['outcome'][col]))","cb5a3705":"#We drop columns nasogastric_reflux_ph and abdomo_protein as they don't hold a significant correlation with the target and they have > 50% of null values in the train dataset\n#Filling their null values would cause more harm than good\ndfTrain = dfTrain.drop(columns = ['abdomo_protein', 'nasogastric_reflux_ph'], axis = 1)\ndfTest = dfTest.drop(columns = ['abdomo_protein', 'nasogastric_reflux_ph'], axis = 1)","143f9276":"dfTrain.shape","aaed3fef":"plt.figure(figsize=(16,8))\nsns.heatmap(dfTrain.isnull(), cbar=False) #There's a row that has a missing value both in the target feature and the surgery feature so we decide to drop it","eac90c0f":"#We will use different approaches to fill the missing values on categorical and numerical variables","44d6d496":"#We create vectors for the categorical and the numerical features that have missing values\ncat_features = ['temp_of_extremities', 'peripheral_pulse',\n       'mucous_membrane', 'capillary_refill_time', 'pain', 'peristalsis',\n       'abdominal_distention', 'nasogastric_tube', 'nasogastric_reflux', \n       'rectal_exam_feces', 'abdomen', 'abdomo_appearance']\n       \nnum_features = ['rectal_temp', 'pulse', 'respiratory_rate', 'packed_cell_volume', 'total_protein']","cc02f562":"dfTrain['total_protein'].hist()","cce797ca":"#We will use a KNNImputer to imput the categorical features\ndfTrainWoTg = dfTrain.drop(columns = ['outcome'], axis = 1) #We extract the target so that the KNN isn't trained using it as a parameter\nKNNimpTR = KNNImputer(n_neighbors=1)\ndfTrainKNN = pd.DataFrame(KNNimpTR.fit_transform(dfTrainWoTg),columns = dfTrainWoTg.columns)\nKNNimpTS = KNNImputer(n_neighbors=1)\ndfTestKNN = pd.DataFrame(KNNimpTS.fit_transform(dfTest),columns = dfTest.columns)","c478995a":"dfTrain[cat_features] = dfTrainKNN[cat_features]  \ndfTest[cat_features] = dfTestKNN[cat_features]  #We only add the categorical variables\ndfTrain['total_protein'] = dfTrainKNN['total_protein']  \ndfTest['total_protein'] = dfTestKNN['total_protein']#We add this variable because the distribution it shows on an histogram is very abnormal and it's better imputed with this method despite being numerical","b1fd0987":"dfTrain.isna().sum()","f602a178":"plt.figure(figsize=(16,8))\nsns.heatmap(dfTrain.isnull(), cbar=False) #The last row has null on all the categorical variables so there's no way to fill it with the KNN imputer","970446ac":"dfTrain.isna().sum() #Only numerical features still have missing values","0caab896":"#According to the documentation hot extremetity temperatures correlate strongly with elevated rectal temperatures\ndfTrain.groupby([\"temp_of_extremities\"])[\"rectal_temp\"].median() #Its false so we will fill with the mean","4e6ffb53":"dfTrain.corr()['temp_of_extremities']['rectal_temp'] #In the heatmap we can see how there's no correlation","6852772c":"x = dfTrain['temp_of_extremities'].values\ny = dfTrain['rectal_temp'].values\nplt.plot(x,y,'o')","d511b8ca":"dfTrain['rectal_temp'] = dfTrain['rectal_temp'].fillna(dfTrain['rectal_temp'].mean())\ndfTest['rectal_temp'] = dfTest['rectal_temp'].fillna(dfTest['rectal_temp'].mean())","db58e1ad":"dfTrain.groupby([\"pain\"])[\"pulse\"].median() #According to the documentation painful lesions correlate strongly with elevated heart rates","80612cb0":"dfTrain[\"pulse\"] = dfTrain.groupby([\"pain\"])[\"pulse\"].transform(lambda x: x.fillna(x.median()))\ndfTest[\"pulse\"] = dfTest.groupby([\"pain\"])[\"pulse\"].transform(lambda x: x.fillna(x.median()))","eff3a1f9":"#According to the heatmap above the respiratory rate has a very strong correlation with the pulse\n#So maybe it also has a strong correlation with the pain feature?\ndfTrain.groupby([\"pain\"])[\"respiratory_rate\"].median() #Yes it does","c27c8bc9":"dfTrain[\"respiratory_rate\"] = dfTrain.groupby([\"pain\"])[\"respiratory_rate\"].transform(lambda x: x.fillna(x.median()))\ndfTest[\"respiratory_rate\"] = dfTest.groupby([\"pain\"])[\"respiratory_rate\"].transform(lambda x: x.fillna(x.median()))","dfda1ac9":"#According to the documentation and the heatmap above the packed cell volume has a very strong correlation with the circulation\n#So we use these 2 features that measure the circulation to groupby and fill with the median\ndfTrain[\"packed_cell_volume\"] = dfTrain.groupby([\"mucous_membrane\", \"capillary_refill_time\"])[\"packed_cell_volume\"].transform(lambda x: x.fillna(x.median()))\ndfTest[\"packed_cell_volume\"] = dfTest.groupby([\"mucous_membrane\", \"capillary_refill_time\"])[\"packed_cell_volume\"].transform(lambda x: x.fillna(x.median()))","dc535e75":"#For this last numerical feature neither the heatmap nor the documentation give us any clue on which features it's correlated with\n#So we will fill with the mean\n#dfTrain['total_protein'] = dfTrain['total_protein'].fillna(dfTrain['total_protein'].median())\n#dfTest['total_protein'] = dfTest['total_protein'].fillna(dfTest['total_protein'].median())","718d65ee":"dfTrain.isna().sum() #No missing values remain!","97bd1298":"dfTrain[num_features].boxplot()","2aca3617":"sns.boxplot(dfTrain['pulse'])","410b5a5d":"sns.boxplot(dfTrain['respiratory_rate'])","6dad3ee9":"sns.boxplot(dfTrain['packed_cell_volume']) #We can ignore these small outliers","414397c9":"Q1 = dfTrain['respiratory_rate'].quantile(0.15)\nQ3 = dfTrain['respiratory_rate'].quantile(0.85)\nIQR = Q3 - Q1\nbig_outliers = dfTrain['respiratory_rate'] > (Q3 + 1.5 * IQR)\ndfTrain[big_outliers] #We will drop these rows with outliers)??????????????????????????????????????????????????????????","5ca1b1f1":"Q1 = dfTrain['pulse'].quantile(0.15)\nQ3 = dfTrain['pulse'].quantile(0.85)\nIQR = Q3 - Q1\nbig_outliers_2 = dfTrain['pulse'] > (Q3 + 1.5 * IQR)\ndfTrain[big_outliers_2] #We will drop these rows with outliers???????????????????????????????????????????????????????????","7a919866":"#We also standardize the categorical variables despite it isn't necessary\ntarget = dfTrain['outcome']\ndfTrain = dfTrain.drop(columns = ['outcome'], axis = 1) #We extract the target to avoid standardizing it\nfeatures = dfTrain.columns\nscaler = StandardScaler()\nscaledTrain = scaler.fit_transform(dfTrain)\nscaledTest = scaler.transform(dfTest) #we transform the test set with the model trained on the train set\ndfTrain = pd.DataFrame(data=scaledTrain, columns=features)\ndfTest = pd.DataFrame(data=scaledTest, columns=features) #We rebuild to a dataframe format\"\"\"","bd608241":"dfTrain.hist(bins=22, figsize=(15, 15))","c70b4b27":"print(dfTrain['pulse'].skew()) #We will fix variables with a skewness > 1\nprint(dfTrain['respiratory_rate'].skew())\nprint(dfTrain['total_protein'].skew())\nprint(dfTrain['packed_cell_volume'].skew())\nprint(dfTrain['rectal_temp'].skew())","bc7d35ff":"sns.distplot(dfTrain[\"pulse\"] , color = \"b\", hist_kws={\"alpha\": 0.4});","7c325346":"sns.distplot(dfTrain[\"respiratory_rate\"] , color = \"b\", hist_kws={\"alpha\": 0.4});","c05a289c":"sns.distplot(dfTrain[\"total_protein\"] , color = \"b\", hist_kws={\"alpha\": 0.4});","e9b9c771":"sns.distplot(dfTrain[\"packed_cell_volume\"] , color = \"b\", hist_kws={\"alpha\": 0.4}); #This distribution looks less skewed (more gaussian)","0fe97a51":"cols_not_normal = ['pulse', 'respiratory_rate', 'total_protein']\n\nPT = PowerTransformer()\n\nPTx_train = PT.fit_transform(dfTrain)\nPTx_test = PT.transform(dfTest)\n\ndfTrain2 = pd.DataFrame(data=PTx_train, columns=features)\ndfTest2 = pd.DataFrame(data=PTx_test, columns=features)\n\ndfTrain[cols_not_normal] = dfTrain2[cols_not_normal]\ndfTest[cols_not_normal] = dfTest2[cols_not_normal]\n\ndfTrain.insert(21,\"outcome\",target.values) #we add the target feature again","39e8284e":"dfTrain.hist(bins=22, figsize=(15, 15))","ddc6427a":"print(dfTrain['pulse'].skew())\nprint(dfTrain['respiratory_rate'].skew())\nprint(dfTrain['total_protein'].skew()) #Skewness fixed!","570c6b74":"dfTrain.corr()['outcome']['total_protein'] #No correlation!","7a948f3e":"dfTrain.drop(columns=['total_protein'], axis = 1, inplace = True)\ndfTest.drop(columns=['total_protein'], axis = 1, inplace = True)","fec48bc5":"featuresVIS = ['temp_of_extremities', 'peripheral_pulse',\n       'mucous_membrane', 'capillary_refill_time', 'pain', 'peristalsis',\n       'abdominal_distention', 'nasogastric_tube', 'nasogastric_reflux', \n       'rectal_exam_feces', 'abdomen', 'abdomo_appearance', 'rectal_temp', \n       'pulse', 'respiratory_rate', 'packed_cell_volume']\n\nx = dfTrain.loc[:,featuresVIS].values\n\ny = dfTrain.loc[:,'outcome'].values\n\nx = StandardScaler().fit_transform(x)\n\ndfaux = dfTrain.copy()\n\ncolors_data = {1: 'y', 2: 'b', 3: 'r'}","db245e3c":"pca = PCA().fit(x)\nplt.plot(np.cumsum(pca.explained_variance_ratio_)) # cumsum computes the cumulative sum\nplt.xlabel('number of components')\nplt.ylabel('cumulative explained variance');","50159026":"pca = PCA(n_components = 10)  # Proyectar 22 dimensiones a 10\npca10 = pca.fit_transform(x)\n#print(dfTrain.shape)\n#print(pca10.shape)\n#print(pca.components_)\n#print(pca.explained_variance_)","569df1cc":"pca = PCA(n_components = 2)  # Proyectar 22 dimensiones a 2\nprojected = pca.fit_transform(x)\n#print(dfTrain.shape)\n#print(pca10.shape)\n#print(pca.components_)\n#print(pca.explained_variance_)","cd9662f9":"plt.scatter(projected[:, 0], projected[:, 1],\n            c = dfTrain['outcome'], edgecolor = 'none', alpha = 0.9,\n            cmap = plt.cm.get_cmap('viridis', 3))\nplt.xlabel('PC1')\nplt.ylabel('PC2')\nplt.colorbar()","205864ca":"y_train = dfTrain['outcome']\nx_train = dfTrain.drop(columns = ['outcome'], axis = 1)\nx_test = dfTest","1a85ef77":"lr = LogisticRegression(random_state=0)\nparam_grid={\"C\":np.logspace(-3,3,10)}\ngrid = GridSearchCV(lr, param_grid, cv=5, verbose=0)\ngrid_search=grid.fit(x_train, y_train)\nprint('The best value found for the hyperparameter C is ' + str(grid_search.best_params_['C']))\nprint('The best result on the training set using 5-Fold CV was ' + str(grid_search.best_score_))\ny_pred = grid_search.predict(x_test)\nprint('The best result predicting the test set was ' + str(accuracy_score(y_test, y_pred)))\nconfusion_matrix(y_test, y_pred)","aab7777a":"gnb = GaussianNB()\nparam_grid = {'var_smoothing': np.logspace(0,-9, num=100)}\ngrid = GridSearchCV(gnb, param_grid, cv=5, verbose=0)\ngrid_search=grid.fit(x_train, y_train)\nprint('The best value found for the hyperparameter var_smoothing is ' + str(grid_search.best_params_['var_smoothing']))\nprint('The best result on the training set using 5-Fold CV was ' + str(grid_search.best_score_))\ny_pred = grid_search.predict(x_test)\nprint('The best result predicting the test set was ' + str(accuracy_score(y_test, y_pred)))\nconfusion_matrix(y_test, y_pred)","b796d606":"knn = KNeighborsClassifier()\nk_range = list(range(1, 16))\nparam_grid = dict(n_neighbors=k_range)\ngrid = GridSearchCV(knn, param_grid, cv=5, verbose=0)\ngrid_search=grid.fit(x_train, y_train)\nprint('The best value found for the hyperparameter number of neighbors is ' + str(grid_search.best_params_['n_neighbors']))\nprint('The best result on the training set using 5-Fold CV was ' + str(grid_search.best_score_))\ny_pred = grid_search.predict(x_test)\nprint('The best result predicting the test set was ' + str(accuracy_score(y_test, y_pred)))\nconfusion_matrix(y_test, y_pred)","3a8e15a5":"rf = RandomForestClassifier(n_jobs=-1, random_state= 0) #nest 200 max depth 8\nparam_grid = { \n    'n_estimators': [100,200,300,400],\n    'max_depth' : [4,6,8,10,12]\n}\ngrid = GridSearchCV(rf, param_grid, cv=5, verbose=0)\ngrid_search=grid.fit(x_train, y_train)\n#print('The best value found for the hyperparameter var_smoothing is ' + str(grid_search.best_params_['var_smoothing']))\nprint('The best result on the training set using 5-Fold CV was ' + str(grid_search.best_score_))\ny_pred = grid_search.predict(x_test)\nprint('The best result predicting the test set was ' + str(accuracy_score(y_test, y_pred)))\nconfusion_matrix(y_test, y_pred)","b0451d19":"grid_search.best_params_","8aace119":"mlpc = MLPClassifier(random_state=0, verbose = 0)\nparam_grid = [\n    {'hidden_layer_sizes': [(100,100),(100,100,100),(100,100,100,100),(100,100,100,100,100),(100,100,100,100,100,100)],\n     'alpha': [0.0001,0.001,0.01,0.1],\n     'early_stopping': [True],\n     'learning_rate_init' : [0.001,0.01,0.1]\n     }\n]\ngrid = GridSearchCV(mlpc, param_grid, cv=5, verbose=0)\ngrid_search=grid.fit(x_train, y_train)\nprint('The best result on the training set using 5-Fold CV was ' + str(grid_search.best_score_))\ny_pred = grid_search.predict(x_test)\nprint('The best result predicting the test set was ' + str(accuracy_score(y_test, y_pred)))\nconfusion_matrix(y_test, y_pred)","07e87549":"BEFORE WE START FILLING MISSING VALUES, LET'S DECIDE WHICH FEATURES ARE REDUNDANT OR HAVE TO BE ELIMINATED","104fd109":"# **LETS START!**","76eff213":"**LINEAR MODELS**","e8490f09":"**Random Forest Classifier**","0edd0de8":"LETS FIRST FILL THE MISSING VALUES OF THE CATEGORICAL FEATURES","4d531a8d":"# **TRANSFORMATION OF VARIABLES**","1a11d926":"**Logistic Regression**","c82afdb8":"# **DATA VISUALIZATION**","aa0200b5":"Now lets take a glance at the correlation between features to decide how we will fill the missing values or nulls.","a7260fd4":"# **FILLING MISSING VALUES**","6f1d77b2":"**PREPROCESSING IS DONE!** \ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34","9d244b74":"We will delete the outliers","85a47186":"PCA DOESN`T REALLY HELP US ON THIS DATASET SINCE WE CAN'T EXPLAIN MOST OF THE VARIANCE WITH A SMALLER NUMBER OF DIMENSIONS NOR OBSERVE CLEAR DIFFERENT GROUPS OF HORSES","a2fc88a9":"\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34\ud83d\udc34","7aa29cea":"# **LOADING THE DATAFRAME**","9fa3486e":"**MLP Classifier**","314907b5":"**KNN Classifier**","5ae14e05":"Thank you for reading this kernel!","db5c73bc":"![caballo.gif](attachment:880fc688-7ec2-44a6-8ad5-587d0088c2cf.gif)","f69a96d6":"# **NORMALIZATION OF THE VARIABLES**","e813e2da":"# **THE END**","b9e0bf6c":"*We will be looking to determine if a horse can survive a surgery!*","bbd55050":"# **MODEL SELECTION**","177e545d":"**PCA**","e0966cb6":"# **PCA?**","2c612bf2":"**NON-LINEAR MODELS**","e6cdd732":"WE WILL NOW TREAT THE MISSING VALUES OF THE NUMERICAL FEATURES","bfe5f3bd":"**Naive Bayes**","8083f856":"# **Treatment of outliers**","1be4e6d4":"# **FEATURE ENGINEERING**","d9b7f764":"Since total_protein doesn't improve its skewness (its distribution is totally abnormal) and its correlation with the target is inexistent, we decide to eliminate it."}}