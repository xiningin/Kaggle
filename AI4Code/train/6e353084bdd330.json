{"cell_type":{"132e5a38":"code","d6dd1dfa":"code","7408f449":"code","ab230075":"code","8a0660e2":"code","d687ad26":"code","a5345c9a":"code","db34351f":"code","c5a9ba67":"code","d08c418b":"code","1fab48de":"code","8ac6e2f7":"code","03434f9d":"code","8833a31b":"code","a8d96ce3":"code","85ce280a":"code","6daf2703":"code","94f06672":"code","947d0dd3":"code","731f5043":"code","78b50d34":"code","7b81a493":"code","6f567799":"code","ef24ec4b":"code","ef7cc154":"code","9e7fee2c":"code","ff591544":"code","69a7c4d5":"code","a1f2a39d":"code","68869059":"code","35da363b":"code","828be138":"markdown","7ac21458":"markdown","5544c87d":"markdown","e8391773":"markdown","63bbce6d":"markdown","a5cd97ae":"markdown","bd7cbc59":"markdown","b18961b7":"markdown","a2ce4e9e":"markdown","53d2b348":"markdown","a16ebd6f":"markdown","7ebbc97a":"markdown"},"source":{"132e5a38":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # data visiualization\nimport seaborn as sns # data visisualization like distribytion chart, matrix plot, heat maps\nimport sklearn # scikit library for machine learning\n\n!pip install altair\n!pip install datapane\nimport altair as alt # declarative statistical visualization library for Python, based on Vega and Vega-Lite.\nimport datapane as dp # open source framework which makes it easy to build and share reports","d6dd1dfa":"\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7408f449":"training_data = pd.read_csv('..\/input\/quora-insincere-questions-classification\/train.csv')\ntest_data = pd.read_csv('..\/input\/quora-insincere-questions-classification\/test.csv')\nsubmission_data=pd.read_csv('..\/input\/quora-insincere-questions-classification\/sample_submission.csv')","ab230075":"print('Training Data',training_data.info()) # find records and attributes\n'\\n'\nprint('Training data column headings:',training_data.columns) # column headings\n'\\n'\nprint('Training data shape:',training_data.shape) # Rows & columns\n'\\n'\nprint('Training Data',training_data.head()) #top 5 records\n'\\n'\nprint('Sample Training data',training_data.sample(10)) # sample 10 records","8a0660e2":"print('Test Data information',test_data.info()) # find records and attributes\n'\\n'\nprint('Test data column headings:',test_data.columns) # column headings\n'\\n'\nprint('Test data shape:',test_data.shape) # Rows & columns\n'\\n'\nprint('Test Data',test_data.head()) #top 5 records\n'\\n'\nprint('Sample Test data',test_data.sample(10)) # sample 10 records","d687ad26":"training_data[training_data.target==1][:5]  # top 5 labeled insincere questions","a5345c9a":"training_data[training_data.target==0][:5] # top 5 labeled sincere questions","db34351f":"#Frequency count of sincere and insincere question texts:\ncount=training_data['target'].value_counts()\nprint('Total Counts of both sets'.format(),count)\n\nplt.figure(figsize=(15,5))\nsns.countplot(y=\"target\",\n              palette =['green','red'],\n              data=training_data)\nplt.suptitle(\"Frequency of Sincere Questions (0) & Insincere Questions (1)\")\nplt.show()","c5a9ba67":"sns.distplot(training_data['target'].value_counts(),\n            kde=True)","d08c418b":"insincere_label=training_data[training_data['target']== 1]['question_text']\nprint(insincere_label.head())  #top insincere questions\n\n\nsincere_label=training_data[training_data['target']== 0]['question_text']\nprint(sincere_label.head())  #top sincere questions","1fab48de":"#Frequency of insincere and sincere questions\n#Function for checking word length\ndef freq_len(data):\n    return len(data)\n\n\nfreq_sincere = sincere_label.str.split().apply(lambda z:freq_len(z))\nprint(\"Sincere Questions Length:\" + str(freq_sincere))\n\nfreq_insincere = insincere_label.str.split().apply(lambda z:freq_len(z))\nprint(\"Insincere Questions Length:\" + str(freq_insincere))","8ac6e2f7":"#Visualizing distributions of length of insincere and sincere questions in the entire training data\n\nfig,axes=plt.subplots(1,2)\n\nsns.distplot(freq_insincere,ax=axes[0],color='red')\n\nsns.distplot(freq_sincere,ax=axes[1],color='green')\n\nplt.show()","03434f9d":"import string","8833a31b":"freq_sincere_punctuations= sincere_label.apply(lambda z: len([c for c in str(z) if c in string.punctuation])) #punctuation in insincere questions\n\nfreq_insincere_punctuations= insincere_label.apply(lambda z:len([c for c in str(z) if c in string.punctuation])) #punctuations in sincere questions\n\n#Distribution plot for length of punctuations in insincere and sincere questions\n\nfig,axes=plt.subplots(1,2)\n\nsns.distplot(freq_insincere_punctuations,ax=axes[0],color='red')\n\nsns.distplot(freq_sincere_punctuations,ax=axes[0],color='green')\n\nplt.show()","a8d96ce3":"import re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords","85ce280a":"stop_words=set(stopwords.words('english')) #designating stopwords\n\nfreq_insincere_stops= insincere_label.apply(lambda z : np.mean([len(z) for w in str(z).split()])) #stopwords in insincere questions\n\nfreq_sincere_stops= sincere_label.apply(lambda z : np.mean([len(z) for w in str(z).split()])) #stopwords in sincere questions\n\n#Distribution plot for stopwords in insincere and sincere questions\n\nfig,axes=plt.subplots(1,2)\n\nsns.distplot(freq_insincere_stops,ax=axes[0],color='red')\n\nsns.distplot(freq_sincere_stops,ax=axes[1],color='green')\n\nplt.show()","6daf2703":"!pip install wordcloud\nimport wordcloud\nfrom wordcloud import WordCloud, STOPWORDS ","94f06672":"def display_cloud(data,color,figsize):\n    plt.subplots(figsize=figsize)\n    wc = WordCloud(stopwords=STOPWORDS,\n                   background_color=\"white\", \n                   contour_width=2, \n                   contour_color=color,\n                   max_words=2000, \n                   max_font_size=256,\n                   random_state=42)\n    wc.generate(' '.join(data))\n    plt.imshow(wc, interpolation=\"bilinear\")\n    plt.axis('off')\n    plt.show()\n    \ndisplay_cloud(training_data['question_text'],color='red',figsize=(15,15)) #WordCloud for the training daata","947d0dd3":"display_cloud(insincere_label,'red',figsize=(15,15))","731f5043":"display_cloud(sincere_label,'green',figsize=(15,15)) #Word cloud for sincere questions","78b50d34":"from collections import Counter","7b81a493":"#Simplified counter function\ndef create_corpus(x=0):\n    corpus=[]\n    for x in training_data[training_data['target']==x]['question_text'].str.split():\n        for i in x:\n            corpus.append(i)\n    return corpus\n\ncorpus=create_corpus(x=0)\ncounter=Counter(corpus)\nmost=counter.most_common()\nx=[]\ny=[]\nfor word,count in most[:100]:\n    if (word not in stop_words) :\n        x.append(word)\n        y.append(count)\n        \nplt.figure(figsize=(15,10))\nsns.barplot(x=y,y=x)\nplt.title(\"Most frequent words in descending order\")\nplt.xlabel(\"frequency\")\nplt.show()","6f567799":"#sincere_wordcloud = display_cloud(sincere_label,'green',figsize=(15,15))\n#insincere_wordcloud = display_cloud(insincere_label,'green',figsize=(15,15))","ef24ec4b":"#Publishing descriptive analysis results\n\n#dp.Report(\n#    dp.Plot(plot), \n#    dp.Table(df)\n#).publish(name='Covid Report', open=True) \n\n#dp.Report(\n#    dp.Plot(sincere_wordcloud),\n#    dp.Plot(insincere_wordcloud)\n#).publish(name='Quora Report', open=True) ","ef7cc154":"from nltk.stem.porter import PorterStemmer\ncorpus = []\nfor i in range(0, 1306122):\n    review = re.sub('[^a-zA-Z]', ' ', training_data['question_text'][i])\n    review = review.lower()\n    review = review.split()\n    ps = PorterStemmer()\n    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n    review = ' '.join(review)\n    corpus.append(review)","9e7fee2c":"# Creating the Bag of Words model\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features = 1500)\nX = cv.fit_transform(corpus).toarray()\ny = training_data.iloc[:, -1].values","ff591544":"# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)","69a7c4d5":"# Fitting Naive Bayes to the Training set\nfrom sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(X_train, y_train)","a1f2a39d":"# Predicting the Test set results\ny_pred = classifier.predict(X_test)\ny_pred","68869059":"# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\ncm","35da363b":"#Publishing output of analysis\n#dp.Report(\n#    dp.Plot(plot), \n#    dp.Table(df)\n#).publish(name='Covid Report', open=True) ","828be138":"# Visualizing occurence of words though word clouds","7ac21458":"# Frequency count of Punctuations","5544c87d":"### Importing nltk library and stopwords","e8391773":"### Checking insincere and sincere message content","63bbce6d":"# 2. Data Preprocessing","a5cd97ae":"# 1. Data set import****","bd7cbc59":"## The Training dataset is unbalanced more towards sincere questions","b18961b7":"# Frequency Count of Stopwords","a2ce4e9e":"# Most frequently occuring words in descending order","53d2b348":"# Predictive analysis","a16ebd6f":"# 3. Exploratory data analysis","7ebbc97a":"### Clearly we see people using more words in insincere questions than in sincere questions"}}