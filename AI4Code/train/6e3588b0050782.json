{"cell_type":{"e40f976c":"code","97c6d5fe":"code","e88bb765":"code","4eda7cf0":"code","1224254f":"code","28e9a00a":"code","386c8dbb":"code","1a6cc3c5":"code","7418c2a3":"code","dbed71e5":"code","c8ce6eba":"code","b37f22f6":"code","42322c21":"code","fdecea41":"code","465d24ee":"code","7d8fff1c":"code","c6b64ea4":"code","e88d505f":"code","3a1c916c":"code","dbf5cf0c":"code","49c0101c":"code","5a9e5bcb":"code","e6181f39":"code","3c67c227":"code","6ac6470a":"code","a05212e1":"code","0129d415":"code","d1af6a1c":"code","b86e38b4":"code","1bb5c79f":"markdown","394abd68":"markdown","27356066":"markdown","25287f1f":"markdown","79cf21ab":"markdown","7e3e84d1":"markdown","1121037b":"markdown","ba14d22e":"markdown"},"source":{"e40f976c":"import pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt\n\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom sklearn.model_selection import GridSearchCV\n\npd.set_option('display.max_rows', 200)","97c6d5fe":"df_init = pd.read_csv('TrainingWiDS2021.csv',index_col=0)\n\n# drop columns which have more than 30% Nan values\ndf = df_init.dropna(thresh = 0.7*len(df_init),axis='columns')","e88bb765":"# columns removed\nremove_cols = list(set(df_init.columns) - set(df.columns))","4eda7cf0":"set(df.columns)","1224254f":"#df","28e9a00a":"print(df.dtypes.unique())","386c8dbb":"# readmission_status columns has all 0\nfor c in df.columns:\n    if df.dtypes[c] == 'int64':\n        print(c, df[c].unique())","1a6cc3c5":"# Number of non-nan values in each column\ndf.count(axis=0)","7418c2a3":"# Exploring categorical columns\nfor c in df.columns:\n    if df.dtypes[c] == 'object':\n        print('Categorical columns: ',c)\n        print('Null values: ',df[c].isna().sum())\n        print(df[c].value_counts())\n        print('--------')\n        #print(df[c].unique())\n        ","dbed71e5":"# one-hot encoding categorical columns\nenc_df = pd.get_dummies(df)","c8ce6eba":"# removing a few hospital_admit_source_ as they are not present in the training data\nX = enc_df.drop(['encounter_id', 'hospital_id','diabetes_mellitus','icu_id','readmission_status',\n                'hospital_admit_source_Acute Care\/Floor',\n 'hospital_admit_source_ICU',\n 'hospital_admit_source_Observation',\n 'hospital_admit_source_Other',\n 'hospital_admit_source_PACU'], axis=1)\nY = enc_df['diabetes_mellitus']\ntrain_X, test_X, train_y, test_y = train_test_split(X, Y, random_state=1, test_size=0.25)","b37f22f6":"X.shape","42322c21":"model = xgb.XGBClassifier(n_estimators=300, max_depth=3, learning_rate=0.1, subsample=0.5)\n# Fit the model to the training set and predict on the test set\ntrain_model = model.fit(train_X, train_y)\npred = train_model.predict(test_X)","fdecea41":"model2 = xgb.XGBClassifier(n_estimators=500, max_depth=3, learning_rate=0.1, subsample=0.5)\n# Fit the model to the training set and predict on the test set\ntrain_model2 = model2.fit(train_X, train_y)\npred2 = train_model2.predict(test_X)","465d24ee":"model3 = xgb.XGBClassifier(n_estimators=500, max_depth=3, learning_rate=0.01, subsample=0.5)\n# Fit the model to the training set and predict on the test set\ntrain_model3 = model3.fit(train_X, train_y)\npred3 = train_model3.predict(test_X)","7d8fff1c":"print(\"Accuracy for model: %.2f\" % (accuracy_score(test_y, pred) * 100))\nprint(\"Accuracy for model: %.2f\" % (accuracy_score(test_y, pred2) * 100))\nprint(\"Accuracy for model: %.2f\" % (accuracy_score(test_y, pred3) * 100))","c6b64ea4":"predprob2 = train_model2.predict_proba(test_X)\npredprob2","e88d505f":"pred2","3a1c916c":"# Plot feature importance\nxgb.plot_importance(model2,max_num_features=100, height=0.2)\nplt.rcParams['figure.figsize'] = [50,20]\n#plt.show()\nplt.tight_layout()\n#plt.savefig('xgboost_model1_featureimp.png',dpi=400)","dbf5cf0c":"testdf = pd.read_csv('UnlabeledWiDS2021.csv',index_col=0)\ntestdf = testdf.drop(['h1_arterial_ph_min', 'h1_glucose_min', 'urineoutput_apache', 'h1_diasbp_invasive_max', \n                      'ph_apache', 'd1_bilirubin_max', 'h1_albumin_min', 'bilirubin_apache', \n                      'd1_pao2fio2ratio_min', 'h1_lactate_max', 'h1_diasbp_invasive_min',\n                      'd1_arterial_pco2_max', 'h1_calcium_min', 'paco2_for_ph_apache', 'd1_albumin_max', \n                      'h1_hematocrit_max', 'h1_sysbp_invasive_max', 'h1_arterial_po2_min', 'h1_hemaglobin_max',\n                      'h1_arterial_pco2_max', 'd1_mbp_invasive_max', 'd1_sysbp_invasive_min', 'h1_inr_max',\n                      'd1_diasbp_invasive_max', 'h1_platelets_min', 'h1_potassium_max', 'h1_wbc_max',\n                      'd1_pao2fio2ratio_max', 'h1_platelets_max', 'h1_hemaglobin_min', 'h1_pao2fio2ratio_max', \n                      'h1_sodium_min', 'albumin_apache', 'h1_lactate_min', 'pao2_apache', 'd1_arterial_ph_min', \n                      'd1_bilirubin_min', 'h1_hco3_max', 'h1_sysbp_invasive_min', 'fio2_apache',\n                      'd1_diasbp_invasive_min', 'h1_mbp_invasive_max', 'h1_bilirubin_min', 'd1_arterial_ph_max',\n                      'd1_albumin_min', 'h1_bun_min', 'h1_bun_max', 'd1_arterial_pco2_min', 'd1_inr_max',\n                      'h1_arterial_po2_max', 'h1_inr_min', 'd1_arterial_po2_max', 'd1_lactate_max', \n                      'd1_arterial_po2_min', 'h1_wbc_min', 'h1_arterial_ph_max', 'h1_mbp_invasive_min', \n                      'h1_pao2fio2ratio_min', 'h1_sodium_max', 'paco2_apache', 'd1_sysbp_invasive_max', \n                      'd1_inr_min', 'h1_hematocrit_min', 'h1_glucose_max', 'h1_bilirubin_max',\n                      'h1_arterial_pco2_min', 'h1_calcium_max', 'h1_creatinine_max', 'h1_creatinine_min',\n                      'h1_albumin_max', 'h1_potassium_min', 'd1_mbp_invasive_min', 'd1_lactate_min', 'h1_hco3_min'], axis=1)","49c0101c":"testdf.shape","5a9e5bcb":"# writing the encounter_id into an array\nenc_id = testdf['encounter_id']","e6181f39":"# one hot encoding\nenc_testdf = pd.get_dummies(testdf)\ntestdf_X = enc_testdf.drop(['encounter_id', 'hospital_id','icu_id','readmission_status'], axis=1)","3c67c227":"print(testdf_X.columns)","6ac6470a":"#df['hospital_admit_source'].unique()\n#set(X.columns) - set(testdf_X.columns)\n#testdf['hospital_admit_source'].unique()","a05212e1":"# Apply model to predict diabetes_mellitus\ntestdf_Y = model2.predict_proba(testdf_X)","0129d415":"# writing encounter_id and diabetes_mellitus prediction into data frame\nfinalx = enc_id.to_numpy()\nfinaly = testdf_Y[:,1]\nfinaldict =  {'encounter_id': finalx, 'diabetes_mellitus': finaly}\nfinaldf = pd.DataFrame(data=finaldict)","d1af6a1c":"finaldf","b86e38b4":"# writing dataframe into csv\nfinaldf.to_csv('Team_Noether_SubmissionWiDS2021.csv',index=False)","1bb5c79f":"# Applying the model to the Unlabeled data","394abd68":"print(\"Accuracy for model: %.2f\" % (accuracy_score(test_y, grid_predictions) * 100))","27356066":"## Classification using XGBoost","25287f1f":"## Predict probability using model 2","79cf21ab":"## Data Exploration","7e3e84d1":"## Feature Importance","1121037b":"## Grid search CV","ba14d22e":"%%time\nparam_grid = {'n_estimators': [100, 300, 500, 700],\n              'max_depth': [3,5,7]}\n\ngrid = GridSearchCV(xgb.XGBClassifier(), param_grid, refit = True, verbose = 3,n_jobs=-1) \n\ngrid.fit(train_X, train_y) \nprint(grid.best_params_) \ngrid_predictions = grid.predict(test_X) "}}