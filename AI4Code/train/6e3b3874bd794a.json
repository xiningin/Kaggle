{"cell_type":{"3d89151a":"code","f366b542":"code","d9f2c931":"code","5f0c50cb":"code","ac49e5b9":"code","0a981ea8":"code","f71c2e11":"code","358d5c29":"code","53b10d92":"code","e0c2d6f8":"code","23e77e10":"code","9318aaa8":"code","e100c9e9":"code","48af4eae":"code","2da33c1f":"code","fbf7909f":"code","9e303ded":"code","a543cc76":"code","68328171":"code","0918c477":"code","4de8e593":"code","483d3144":"code","e477bd3b":"code","c93b5c9a":"code","a7326f81":"markdown","1f4bfecf":"markdown","49a8c194":"markdown","4507882a":"markdown","7bb557c7":"markdown","80271f1f":"markdown","ba3d25c9":"markdown","ef535feb":"markdown","35e0e906":"markdown","4058a43b":"markdown","957e24e6":"markdown","7c57610d":"markdown","77a3f9e6":"markdown"},"source":{"3d89151a":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # data visualization\nimport seaborn as sns # statistical data visualization\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score,classification_report,confusion_matrix\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier","f366b542":"df = pd.read_csv(\"..\/input\/weather-dataset-rattle-package\/weatherAUS.csv\")\ndf.head()","d9f2c931":"categorical = [var for var in df.columns if df[var].dtype=='O']\nprint('There are {} categorical variables\\n'.format(len(categorical)))\nprint('The categorical variables are :', categorical)","5f0c50cb":"cat1 = [var for var in categorical if df[var].isnull().sum()!=0]\nprint(df[cat1].isnull().sum())","ac49e5b9":"for var in categorical:\n    print(var + ' conatins '+str(len(df[var].unique()))+ \" labels \")","0a981ea8":"df['Date'] = pd.to_datetime(df['Date'])\ndf['Year'] = df['Date'].dt.year\ndf['Month'] = df['Date'].dt.month\ndf['Day'] = df['Date'].dt.day\n\ndf.drop('Date',axis=1,inplace=True)","f71c2e11":"categorical = [var for var in df.columns if df[var].dtype=='O']\nprint(\"There are {} categorical variables : \".format(len(categorical)))\nprint(categorical)","358d5c29":"for var in categorical:\n    df[var].fillna(df[var].mode()[0],inplace=True)","53b10d92":"numerical = [var for var in df.columns if df[var].dtype!='O']\nprint(numerical)","e0c2d6f8":"num1 = df[numerical].isnull().sum()\nnum1 = num1[num1!=0]\nnum1","23e77e10":"for col in num1.index:\n    col_mean = df[col].mean()\n    df[col].fillna(col_mean,inplace=True)","9318aaa8":"le = LabelEncoder()\nnew_df = df\nfor col in categorical:\n    new_df[col] = le.fit_transform(df[col])\ncol_names = new_df.columns","e100c9e9":"new_df.head()","48af4eae":"from sklearn.preprocessing import MinMaxScaler\nss = MinMaxScaler()\nnew_df = ss.fit_transform(new_df)\nnew_df = pd.DataFrame(new_df,columns = col_names )","2da33c1f":"new_df.describe()","fbf7909f":"# new_df.to_csv(\"weatherCleaned.csv\")","9e303ded":"correlation = new_df.corr()\nplt.figure(figsize=(16,12))\nplt.title('Correlation Heatmap of Rain in Australia Dataset')\nax = sns.heatmap(correlation, square=True, annot=True, fmt='.2f', linecolor='white',cmap='viridis')\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)\nax.set_yticklabels(ax.get_yticklabels(), rotation=30)           \nplt.show()","a543cc76":"y = new_df.RainTomorrow\nX = new_df.drop('RainTomorrow',axis=1)\nx = df[['Humidity3pm','RISK_MM']]","68328171":"from sklearn.cluster import KMeans\nfrom sklearn import metrics","0918c477":"kmeans = KMeans(n_clusters=2, random_state=100)\nkmeans.fit(x)\nlabels_1 = kmeans.labels_\nnp.unique(kmeans.labels_)\nprint(kmeans.cluster_centers_)\nmetrics.calinski_harabasz_score(X, labels_1)","4de8e593":"plt.scatter(x.iloc[:,0],x.iloc[:,1], c=kmeans.labels_,cmap='rainbow')\nplt.scatter(kmeans.cluster_centers_[:,0] ,kmeans.cluster_centers_[:,1], color='black')\nplt.xlabel('Humidity3pm')\nplt.ylabel(\"RISK_MM\")\nplt.title(\"n_clusters = 2\")","483d3144":"sum_of_squared_distances = []\nK = range(1,15,2)\nfor k in K:\n    k_means = KMeans(n_clusters=k)\n    model = k_means.fit(X)\n    sum_of_squared_distances.append(k_means.inertia_)","e477bd3b":"plt.plot(K, sum_of_squared_distances, 'bx-')\nplt.xlabel('k')\nplt.ylabel('sum_of_squared_distances')\nplt.title('elbow method for optimal k')\nplt.show()","c93b5c9a":"pip install scikit-learn-extra","a7326f81":"## Conclusion\n> ## Hence , KMeans clustering algorithm was applied to WeatherAUS dataset.\n> ## 2 clusters were optimal for the given dataset and Elbow methos was employed to get the optimal K value.","1f4bfecf":"### Replacing the missing categorical values by the most frequent value in respective columns. ","49a8c194":"## Data Cleaning\n\n### Handling Missing Values in Categorical Columns","4507882a":"### Determining the Elbow Point for accurate value of K\n","7bb557c7":"### Fittng the data to KMeans Clustering and calculating CH score\n","80271f1f":"## Data Visualization\n\n### Heatmap of correlation among the columns of data.","ba3d25c9":"### Choosing only the high variance columns for data visualization of clustering for n_clusters = 2\n","ef535feb":"### Splitting the Date column into respective 'Year','Month' & 'Day'.**","35e0e906":"## NAME : JAYNIL GAGLANI\n## ROLL NO : 13\n## BATCH : A\n## DATA WAREHOUSING AND MINING\n## EXPERIMENT NO 7","4058a43b":"## Feature Scaling using MinMaxScaler","957e24e6":"### Replacing the missing numercial values by the mean of their respective columns.","7c57610d":"## Observations KMeans\n> ## The Elbow Method is one of the most popular methods to determine this optimal value of k.\n> ## From the above plot it is clear that for n_clusters = 2 we get the elbow point which means that k = 2 is ideal for clustering","77a3f9e6":"## Applying various clustering algorithms on the training set.\u00b6\n> ## 1. K-Means Clustering"}}