{"cell_type":{"9bbd0d4c":"code","41aa6561":"code","76afb95d":"code","0703c87c":"code","b97430bf":"code","74684a7f":"code","f9f21464":"code","37bdaf55":"code","aef3eb58":"code","8b744393":"code","40b9c541":"code","9e353ac8":"code","d5bb96fb":"code","13a961a5":"code","c66d8ed3":"code","8786d2d5":"code","3623a104":"code","f78562fd":"code","d680d2a8":"code","3dbf1b95":"code","d8d2ecbe":"code","e78818ad":"markdown","6ce4fc81":"markdown"},"source":{"9bbd0d4c":"from IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.base import BaseEstimator, ClassifierMixin\nfrom sklearn.utils.validation import check_X_y, check_is_fitted\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\nfrom scipy import sparse\nimport re\nimport string\nimport lightgbm as lgb","41aa6561":"train_df = pd.read_csv('..\/input\/train.csv')","76afb95d":"annot_idx = train_df[train_df['identity_annotator_count'] > 0].sample(n=48660, random_state=13).index\nnot_annot_idx = train_df[train_df['identity_annotator_count'] == 0].sample(n=48660, random_state=13).index\nx_val_idx = list(set(annot_idx).union(set(not_annot_idx)))\n\nX_val = train_df.loc[x_val_idx]\nX_train = train_df.loc[list(set(train_df.index) - set(x_val_idx))]","0703c87c":"print(X_train.shape)\nprint(X_val.shape)","b97430bf":"text = re.compile(f'([{string.punctuation}\u201c\u201d\u00a8\u00ab\u00bb\u00ae\u00b4\u00b7\u00ba\u00bd\u00be\u00bf\u00a1\u00a7\u00a3\u20a4\u2018\u2019])')\ndef tokenize(s):\n    return text.sub(r' \\1 ', s)","74684a7f":"length = train_df.shape[0]\nword_vectorizer = TfidfVectorizer(ngram_range=(1,2),\n               min_df=5, max_df=0.9, strip_accents='unicode', use_idf=1,\n               smooth_idf=1, sublinear_tf=1, max_features=50000)","f9f21464":"word_vectorizer.fit(X_train['comment_text'])","37bdaf55":"train_tfidf = word_vectorizer.transform(X_train['comment_text'])\nval_tfidf = word_vectorizer.transform(X_val['comment_text'])","aef3eb58":"print(train_tfidf.shape)\nprint(val_tfidf.shape)","8b744393":"import pickle\n\nwith open('word_vectorizer.pickle', 'wb') as handle:\n    pickle.dump(word_vectorizer, handle, protocol=pickle.HIGHEST_PROTOCOL)","40b9c541":"class NbSvmClassifier(BaseEstimator, ClassifierMixin):\n    def __init__(self, C=1.0, dual=False, n_jobs=1):\n        self.C = C\n        self.dual = dual\n        self.n_jobs = n_jobs\n\n    def predict(self, x):\n        # Verify that model has been fit\n        check_is_fitted(self, ['_r', '_clf'])\n        return self._clf.predict(x.multiply(self._r))\n\n    def predict_proba(self, x):\n        # Verify that model has been fit\n        check_is_fitted(self, ['_r', '_clf'])\n        return self._clf.predict_proba(x.multiply(self._r))\n\n    def fit(self, x, y):\n        y = y\n        x, y = check_X_y(x, y, accept_sparse=True)\n\n        def pr(x, y_i, y):\n            p = x[y==y_i].sum(0)\n            return (p+1) \/ ((y==y_i).sum()+1)\n        \n        self._r = sparse.csr_matrix(np.log(pr(x,1,y) \/ pr(x,0,y)))\n        x_nb = x.multiply(self._r)\n        self._clf = LogisticRegression(C=self.C, dual=self.dual, n_jobs=self.n_jobs).fit(x_nb, y)\n        return self","9e353ac8":"y_train = np.where(X_train['target'] >= 0.5, 1, 0)\ny_val = np.where(X_val['target'] >= 0.5, 1, 0)","d5bb96fb":"NbSvm = NbSvmClassifier(C=1.5, dual=True, n_jobs=-1)\nNbSvm.fit(train_tfidf, y_train)","13a961a5":"lr = LogisticRegression(solver='lbfgs', random_state=13)\nlr.fit(train_tfidf, y_train)","c66d8ed3":"with open('lr_model.pickle', 'wb') as handle:\n    pickle.dump(lr, handle, protocol=pickle.HIGHEST_PROTOCOL)","8786d2d5":"lgb_train = lgb.Dataset(train_tfidf, y_train)\nlgb_eval = lgb.Dataset(val_tfidf, y_val, reference=lgb_train)\n\n# specify your configurations as a dict\nparams = {\n    'task': 'train',\n    'boosting_type': 'gbdt',\n    'objective':'binary',\n    'metric': {'auc'},\n    'nthread': -1,\n    'feature_fraction': 0.4,\n    'num_leaves': 50,\n    'verbose': 1,\n    'num_iterations': 500\n}\n\nprint('Start training...')\n# train\ngbm = lgb.train(params,\n                lgb_train,\n                num_boost_round=200,\n                valid_sets=lgb_eval,\n                early_stopping_rounds=20)","3623a104":"with open('gbm_model.pickle', 'wb') as handle:\n    pickle.dump(gbm, handle, protocol=pickle.HIGHEST_PROTOCOL)","f78562fd":"X_val['model_nbsvm'] = NbSvm.predict_proba(val_tfidf)[:, 1]\nX_val['model_lr'] = lr.predict_proba(val_tfidf)[:, 1]\nX_val['model_gbm'] = gbm.predict(val_tfidf)","d680d2a8":"identity_columns = [\n    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n\n# Convert taget and identity columns to booleans\ndef convert_to_bool(df, col_name):\n    df[col_name] = np.where(df[col_name] >= 0.5, True, False)\n    \ndef convert_dataframe_to_bool(df):\n    bool_df = df.copy()\n    for col in ['target'] + identity_columns:\n        convert_to_bool(bool_df, col)\n    return bool_df\n\nval_df = convert_dataframe_to_bool(X_val)","3dbf1b95":"SUBGROUP_AUC = 'subgroup_auc'\nBPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\nBNSP_AUC = 'bnsp_auc'  # stands for background negative, subgroup positive\n\ndef compute_auc(y_true, y_pred):\n    try:\n        return roc_auc_score(y_true, y_pred)\n    except ValueError:\n        return np.nan\n\ndef compute_subgroup_auc(df, subgroup, label, model_name):\n    subgroup_examples = df[df[subgroup]]\n    return compute_auc(subgroup_examples[label], subgroup_examples[model_name])\n\ndef compute_bpsn_auc(df, subgroup, label, model_name):\n    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n    subgroup_negative_examples = df[df[subgroup] & ~df[label]]\n    non_subgroup_positive_examples = df[~df[subgroup] & df[label]]\n    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n    return compute_auc(examples[label], examples[model_name])\n\ndef compute_bnsp_auc(df, subgroup, label, model_name):\n    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n    subgroup_positive_examples = df[df[subgroup] & df[label]]\n    non_subgroup_negative_examples = df[~df[subgroup] & ~df[label]]\n    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n    return compute_auc(examples[label], examples[model_name])\n\ndef compute_bias_metrics_for_model(dataset,\n                                   subgroups,\n                                   model,\n                                   label_col,\n                                   include_asegs=False):\n    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n    records = []\n    for subgroup in subgroups:\n        record = {\n            'subgroup': subgroup,\n            'subgroup_size': len(dataset[dataset[subgroup]])\n        }\n        record[SUBGROUP_AUC] = compute_subgroup_auc(dataset, subgroup, label_col, model)\n        record[BPSN_AUC] = compute_bpsn_auc(dataset, subgroup, label_col, model)\n        record[BNSP_AUC] = compute_bnsp_auc(dataset, subgroup, label_col, model)\n        records.append(record)\n    return pd.DataFrame(records).sort_values('subgroup_auc', ascending=True)\n\n\ndef calculate_overall_auc(df, model_name):\n    true_labels = df['target']\n    predicted_labels = df[model_name]\n    return roc_auc_score(true_labels, predicted_labels)\n\ndef power_mean(series, p):\n    total = sum(np.power(series, p))\n    return np.power(total \/ len(series), 1 \/ p)\n\ndef get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n    bias_score = np.average([\n        power_mean(bias_df[SUBGROUP_AUC], POWER),\n        power_mean(bias_df[BPSN_AUC], POWER),\n        power_mean(bias_df[BNSP_AUC], POWER)\n    ])\n    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)","d8d2ecbe":"model_cols = [col for col in val_df.columns if (col.startswith('model_'))]\nfor m_col in model_cols:\n    bias_metrics_df = compute_bias_metrics_for_model(val_df, identity_columns, m_col, 'target')\n    print(m_col)\n    print(get_final_metric(bias_metrics_df, calculate_overall_auc(val_df, m_col)))","e78818ad":"https:\/\/www.kaggle.com\/coolcoder22\/simple-logisticregression","6ce4fc81":"**VALIDATION PART**"}}