{"cell_type":{"9fb2a9d3":"code","0777d629":"code","a3e9a855":"code","5f8f34f6":"code","e5cd2890":"code","de82472e":"code","108bdaaf":"code","ce93f5d8":"code","5c3dcf19":"code","45a49e1d":"code","6c7f909a":"code","fbaabb8d":"code","549f122c":"code","1d3a7f9e":"code","eb59114e":"code","2dab1711":"code","75a94312":"code","609f88d3":"code","08a4df25":"code","6bcd16f8":"code","7f8e4f1f":"code","4f67cefe":"code","0478eb98":"code","9e2c72f6":"code","2a53bd01":"code","017a8d79":"code","030adab3":"code","08001029":"markdown","6465ea38":"markdown","e3739c7a":"markdown","9ddbc172":"markdown","d54eb387":"markdown","b47956a8":"markdown","086f8e55":"markdown","0e203e1a":"markdown","6a5aa172":"markdown","8ef5ef20":"markdown","98c27518":"markdown","fc22ee90":"markdown"},"source":{"9fb2a9d3":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.impute import KNNImputer, SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import KFold, RepeatedStratifiedKFold, cross_val_score, GridSearchCV\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.metrics import classification_report,confusion_matrix, accuracy_score, precision_recall_curve, auc, roc_curve\nfrom catboost import Pool, CatBoostClassifier, cv, CatBoostRegressor\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier","0777d629":"train_data = pd.read_csv('..\/input\/iba-ml1-mid-project\/train.csv')\ntest_data=pd.read_csv('..\/input\/iba-ml1-mid-project\/test.csv')","a3e9a855":"train_data['credit_line_utilization'].replace(',','.',regex=True, inplace=True)\ntrain_data[\"credit_line_utilization\"] = pd.to_numeric(train_data[\"credit_line_utilization\"])\n\ntest_data['credit_line_utilization'].replace(',','.',regex=True, inplace=True)\ntest_data[\"credit_line_utilization\"] = pd.to_numeric(test_data[\"credit_line_utilization\"])","5f8f34f6":"train_data.head()","e5cd2890":"train_data.info()","de82472e":"train_data.drop(labels='Id', axis=1, inplace=True)","108bdaaf":"train_data.drop(train_data.index[train_data['number_of_previous_late_payments_up_to_59_days'] >7], inplace = True)\ntrain_data.drop(train_data.index[train_data['number_of_previous_late_payments_up_to_89_days'] >4], inplace = True)\ntrain_data.drop(train_data.index[train_data['number_of_previous_late_payments_90_days_or_more'] >4], inplace = True)\ntrain_data.drop(train_data.index[train_data['number_dependent_family_members'] >6], inplace = True)\ntrain_data.drop(train_data.index[train_data['credit_line_utilization'] >2.5], inplace = True)\ntrain_data.drop(train_data.index[train_data['monthly_income'] >30000], inplace = True)\ntrain_data.drop(train_data.index[train_data['real_estate_loans'] >6], inplace = True)\ntrain_data.drop(train_data.index[train_data['ratio_debt_payment_to_income'] >2], inplace = True)","ce93f5d8":"corr_matrix = train_data.corr()\nprint(corr_matrix[\"defaulted_on_loan\"].sort_values(ascending=False))\n(corr_matrix[\"defaulted_on_loan\"]).plot.bar()\nplt.show()","5c3dcf19":"scaler = StandardScaler()\ntrain_data[['number_of_previous_late_payments_up_to_59_days']]= scaler.fit_transform(train_data[['number_of_previous_late_payments_up_to_59_days']])\ntrain_data[['number_of_previous_late_payments_90_days_or_more']]= scaler.fit_transform(train_data[['number_of_previous_late_payments_90_days_or_more']])\ntrain_data[['monthly_income']]= scaler.fit_transform(train_data[['monthly_income']])\ntrain_data[['number_dependent_family_members']]= scaler.fit_transform(train_data[['number_dependent_family_members']])\ntrain_data[['number_of_credit_lines']]= scaler.fit_transform(train_data[['number_of_credit_lines']])\ntrain_data[['real_estate_loans']]= scaler.fit_transform(train_data[['real_estate_loans']])\ntrain_data[['credit_line_utilization']]= scaler.fit_transform(train_data[['credit_line_utilization']])\ntrain_data[['ratio_debt_payment_to_income']]= scaler.fit_transform(train_data[['ratio_debt_payment_to_income']])","45a49e1d":"train_data.isnull().sum()","6c7f909a":"variables = ['credit_line_utilization', 'number_of_previous_late_payments_up_to_59_days','number_of_previous_late_payments_up_to_89_days',\n             'number_of_previous_late_payments_90_days_or_more','age']\ntarget = 'defaulted_on_loan'","fbaabb8d":"train_data[variables] = SimpleImputer(strategy='median').fit_transform(train_data[variables])","549f122c":"train_data.isnull().sum()","1d3a7f9e":"X = train_data[variables]\ny = train_data[target]\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,random_state=1999, train_size=0.6)","eb59114e":"rfc = RandomForestClassifier()\nrfc.fit(X_train, y_train)","2dab1711":"y_pred = rfc.predict(X_test)\ny_pred_proba = rfc.predict_proba(X_test)","75a94312":"fpr, tpr, threshold = roc_curve(y_test, y_pred_proba[:,1])\nroc_auc = auc(fpr, tpr)\n\n#plotting ROC and getting AUC value\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","609f88d3":"precisions, recalls, thresholds = precision_recall_curve(y_test,y_pred_proba[:, 1])\nplt.plot(precisions, recalls)\nplt.xlabel('Precision')\nplt.ylabel('Recall')\nplt.show()","08a4df25":"variables = ['credit_line_utilization', 'number_of_previous_late_payments_up_to_59_days','number_of_previous_late_payments_up_to_89_days',\n             'number_of_previous_late_payments_90_days_or_more','age','number_dependent_family_members', 'monthly_income', 'number_of_credit_lines', 'real_estate_loans',\n             'ratio_debt_payment_to_income']\ntarget = 'defaulted_on_loan'\ntrain_data[variables] = SimpleImputer(strategy='median').fit_transform(train_data[variables])\ntrain_data.isnull().sum()","6bcd16f8":"X = train_data[variables]\ny = train_data[target]\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,random_state=1999, train_size=0.6)\nrfc = RandomForestClassifier()\nrfc.fit(X_train, y_train)\n\ny_pred = rfc.predict(X_test)\ny_pred_proba = rfc.predict_proba(X_test)","7f8e4f1f":"fpr, tpr, threshold = roc_curve(y_test, y_pred_proba[:,1])\nroc_auc = auc(fpr, tpr)\n\n#plotting ROC and getting AUC value\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","4f67cefe":"precisions, recalls, thresholds = precision_recall_curve(y_test,y_pred_proba[:, 1])\nplt.plot(precisions, recalls)\nplt.xlabel('Precision')\nplt.ylabel('Recall')\nplt.show()","0478eb98":"xgb = XGBClassifier()\nxgb.fit(X_train, y_train)\n\ny_pred = xgb.predict(X_test)\ny_pred_proba = xgb.predict_proba(X_test)\n\nfpr, tpr, threshold = roc_curve(y_test, y_pred_proba[:,1])\nroc_auc = auc(fpr, tpr)\n\n#plotting ROC and getting AUC value\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","9e2c72f6":"catb = CatBoostClassifier(silent=True)\ncatb.fit(X_train, y_train)\n\ny_pred = catb.predict(X_test)\ny_pred_proba = catb.predict_proba(X_test)\n\nfpr, tpr, threshold = roc_curve(y_test, y_pred_proba[:,1])\nroc_auc = auc(fpr, tpr)\n\n#plotting ROC and getting AUC value\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","2a53bd01":"# catb = CatBoostClassifier(silent=True,iterations=1500, rsm=0.98, loss_function='Logloss', eval_metric='AUC',random_seed=1999)\n# cate_features_index = np.where(X.dtypes != float)[0]\n# param_grid = {  \n#     'depth': [6, 8],\n#     'learning_rate': [0.01, 0.02],\n#     'l2_leaf_reg':[2, 3, 4]\n#          }\n# gscv= GridSearchCV(estimator=catb, param_grid=param_grid,cv=5, verbose = 1)\n\n# gscv.fit(X_train, y_train,cat_features=cate_features_index,eval_set=(X_test,y_test))\n# gscv.best_params_\n#runs few hours","017a8d79":"catb = CatBoostClassifier(silent=True, iterations=2000, learning_rate=0.01, l2_leaf_reg=3.5, depth=8, rsm=0.98, loss_function='Logloss', eval_metric='AUC',use_best_model=True,random_seed=42)\ncate_features_index = np.where(X.dtypes != float)[0]\ncatb.fit(X_train, y_train,cat_features=cate_features_index,eval_set=(X_test,y_test))\n\ny_pred = catb.predict(X_test)\ny_pred_proba = catb.predict_proba(X_test)\n\nfpr, tpr, threshold = roc_curve(y_test, y_pred_proba[:,1])\nroc_auc = auc(fpr, tpr)\n\n#plotting ROC and getting AUC value\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","030adab3":"\nX = test_data[variables]\n\nX[variables]=SimpleImputer(strategy='median').fit_transform(X[variables])\n\ntrial = catb.predict_proba(X)[:,1:]\ntrial_df=pd.DataFrame(trial)\ntrial_df.index = trial_df.index+1 \ntrial_df.columns=['Predicted']\ntrial_df.to_csv('trial17.csv', index_label='Id')","08001029":"since the columns we will use are filled now we can move on","6465ea38":"so, lets first check the values with most correlation and see what result do we get. We will use credit line utilization, late payments up to 59 and 89 days also 90 days and more. Also age has a relatively bigger correlation compared to the rest so we will use it as well","e3739c7a":"now, since we saw in EDA that our target is imbalanced. And to check how well we did in our predictions, accuracy is not a good metrics to show. Instead we want to see the AUC scores together with Precision-Recall curve.","9ddbc172":"to get rid of the outliers, we will manually remove them as it is stated in EDA","d54eb387":"Generally speaking, for most of the Banking,stock market and e-commerce problems, RandomForest is considered to be one of the best classification methods. So we will first use this technique to see the results.","b47956a8":"after getting AUC score of 0.75, let's try using all the data we have to predict","086f8e55":"as previously mentioned in EDA, Id column is unnecessary in our case, so we drop it. Checking correlation 1 more time to be sure if it is working right.","0e203e1a":"judging from AUC score and precision recall curve we can see that results are better this time. then let us try different methods to get the prediction. According to my research, XGBoost, LightGBM and CatBoost also gives very good results with imbalanced datasets.","6a5aa172":"now we can predict the probabilities and the results.","8ef5ef20":"now comes normalizing the data.","98c27518":"now comparing all these results, CatBoostClassifier gave the best result. Using grid search we can find the best result for it to fit. But also from my observations, removing outliers also have negative effect on the model results. So I will not remove the outliers.","fc22ee90":"also, while checking we see that there are a lot of null values in train dataset. So let us fill them up first. I will use SimpleImputer here because it will give much faster result than KNNImputer (there are more than 70000 data). Even though we removed the outliers, imputing with median would be more clever choice because number of family members, age, number of credit lines and some others cannot be a float number."}}