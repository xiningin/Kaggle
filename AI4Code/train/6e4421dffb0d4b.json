{"cell_type":{"cbf6bad9":"code","d907439c":"code","979e89de":"code","375289b0":"code","1ad1d60c":"code","84d6c25b":"code","c7b36ab1":"code","5c76411c":"code","faa08ffc":"code","508ef347":"code","00762c97":"code","138ce28b":"code","5076f0a8":"code","69f18c28":"code","21b2bd9a":"code","17b40d05":"code","f9364cc7":"code","54ca1866":"code","249fdfc2":"code","07bf922c":"code","ad39badc":"code","1d94fffb":"code","0d835800":"markdown","b441c56f":"markdown","6c040c9a":"markdown","12b5c9ee":"markdown","3d4df957":"markdown","a5439425":"markdown","2caed2c5":"markdown","8737a4a6":"markdown"},"source":{"cbf6bad9":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import KFold,TimeSeriesSplit\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.metrics import mean_squared_error\n\nimport math\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import activations,callbacks\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras import initializers\nfrom tensorflow.keras import regularizers\nfrom keras.models import Model\n","d907439c":"train = pd.read_csv('..\/input\/tabular-playground-series-jul-2021\/train.csv')\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-jul-2021\/test.csv\")\nsample_submission = pd.read_csv(\"..\/input\/tabular-playground-series-jul-2021\/sample_submission.csv\")\nminmax = MinMaxScaler()\ntrain.shape","979e89de":"\"\"\"\nfrom Somayyeh Gholami & Mehran Kazeminia and Alexander Ryzhkov, smart ensembling based upon :\nThanks to: @paddykb https:\/\/www.kaggle.com\/paddykb\/tps-07-gam-baseline\nThanks to: @junhyeok99 https:\/\/www.kaggle.com\/junhyeok99\/automl-pycaret\nThanks to: https:\/\/www.kaggle.com\/hiro5299834\/tps-jul-2021-pycaret-with-pseudo-labels \n\"\"\"\nbench = pd.read_csv(\"..\/input\/benchmark21\/benchmark.csv\")\nbench1 = pd.read_csv(\"..\/input\/benchmark23\/submission_3.csv\")\nname1 = [\"date_time\",\"carbon1\",\"benzene1\",\"nitrogen1\"]\nname2 = [\"date_time\",\"carbon2\",\"benzene2\",\"nitrogen2\"]\nbench.columns = name1\nbench1.columns = name2\ntrain = pd.concat([train,train.iloc[:,-3:]],axis=1)\ntrain.shape","375289b0":"a=[]\na = list([x for x in train.columns])\na = a[:-6]\na.extend(name1[1:])\na.extend(name2[1:])\ntrain.columns = a","1ad1d60c":"train['date_time'] = train['date_time'].astype('datetime64[ns]')\ntrain['hour'] = train['date_time'].dt.hour\ntrain['day'] = train['date_time'].dt.day\ntrain['weekday'] = train['date_time'].dt.dayofweek\ntrain[\"working_hours\"] =  train[\"hour\"].isin(np.arange(8, 21, 1)).astype(\"int\")\ntrain[\"weekend\"] = (train[\"date_time\"].dt.dayofweek >= 5).astype(\"int\")","84d6c25b":"test['date_time'] = test['date_time'].astype('datetime64[ns]')\ntest['hour'] = test['date_time'].dt.hour\ntest['day'] = test['date_time'].dt.day\ntest['weekday'] = test['date_time'].dt.dayofweek\ntest[\"working_hours\"] =  test[\"hour\"].isin(np.arange(8, 21, 1)).astype(\"int\")\ntest[\"weekend\"] = (test[\"date_time\"].dt.dayofweek >= 5).astype(\"int\")","c7b36ab1":"test['date_time'] = test['date_time'].astype(np.int64)\/10**18\ntrain['date_time'] = train['date_time'].astype(np.int64)\/10**18","5c76411c":"test = test[['date_time',\n                'deg_C',\n                'hour',\n                'day',\n                'weekday',\n                'weekend',\n                'working_hours',\n                'relative_humidity',\n                'absolute_humidity',\n                'sensor_1',\n                'sensor_2',\n                'sensor_3',\n                'sensor_4',\n                'sensor_5'\n                 ]]","faa08ffc":"#Double pseudolabelling :\ntest_labels = pd.concat([test,bench.iloc[:,1:], bench1.iloc[:,1:]],axis = 1)\ntest_labels","508ef347":"train = train[['date_time',\n                'deg_C',\n                'hour',\n                'day',\n                'weekday',\n                'weekend',\n                'working_hours',\n                'relative_humidity',\n                'absolute_humidity',\n                'sensor_1',\n                'sensor_2',\n                'sensor_3',\n                'sensor_4',\n                'sensor_5',\n                'carbon1',\n                'benzene1',\n                'nitrogen1',\n                'carbon2',\n                'benzene2',\n                'nitrogen2'\n                 ]]","00762c97":"all_train = pd.concat([train,test_labels],axis = 0,ignore_index=True)\nall_train.shape","138ce28b":"all_train['sensor_6'] = (all_train['sensor_2']-all_train['sensor_5']) \/ all_train['sensor_5']\nall_train['sensor_7'] = (all_train['sensor_3']-all_train['sensor_4']) \/ all_train['sensor_4']\n\nshift = all_train['sensor_1'].shift(periods=1,fill_value=0)\ndif1 = all_train['sensor_1']-shift\nall_train['evolution_sensor_1']= dif1\n\nshift = all_train['sensor_2'].shift(periods=1,fill_value=0)\ndif2 = all_train['sensor_2']-shift\nall_train['evolution_sensor_2']= dif2\n\nshift = all_train['sensor_3'].shift(periods=1,fill_value=0)\ndif3 = all_train['sensor_3']-shift\nall_train['evolution_sensor_3']= dif3\n\nshift = all_train['sensor_4'].shift(periods=1,fill_value=0)\ndif4 = all_train['sensor_4']-shift\nall_train['evolution_sensor_4']= dif4\n\nshift = all_train['sensor_5'].shift(periods=1,fill_value=0)\ndif5 = all_train['sensor_5']-shift\nall_train['evolution_sensor_5']= dif5\n","5076f0a8":"all_train1 = []\nall_train1 = all_train[['date_time',\n                'deg_C',\n                'hour',\n                'day',\n                'weekday',\n                'weekend',\n                'working_hours',\n                'relative_humidity',\n                'absolute_humidity',\n                'sensor_1',\n                'evolution_sensor_1',\n                'sensor_2',\n                'evolution_sensor_2',\n                'sensor_3',\n                'evolution_sensor_3',\n                'sensor_4',\n                'evolution_sensor_4',\n                'sensor_5',\n                'evolution_sensor_5',\n                'sensor_6',\n                'sensor_7',\n                'carbon1',\n                'benzene1',\n                'nitrogen1',\n                'carbon2',\n                'benzene2',\n                'nitrogen2'\n                 ]]\nall_train1.shape","69f18c28":"#---- with double pseudo label ------\nall_train_sc = pd.DataFrame(minmax.fit_transform(all_train1.iloc[:,:-6]))\ntest_sc = all_train_sc.iloc[len(train):,:]\ntrain_sc = all_train_sc.iloc[:len(train),:]\ny_sc = all_train1.iloc[:,-6:]\nall_train.shape, y_sc.shape,test_sc.shape,train_sc.shape","21b2bd9a":"msle = tf.keras.losses.MeanSquaredLogarithmicError()\nmse = tf.keras.losses.MeanSquaredError()\n\nes = tf.keras.callbacks.EarlyStopping(\n    monitor= 'val_loss', min_delta=1e-12, patience=10, verbose=0,\n    mode='auto', baseline=None, restore_best_weights=True)\n\nplateau = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss', factor=0.7, patience=2, verbose=0,\n    mode='auto')","17b40d05":"def reg_model():\n\n    reg_inputs = layers.Input(shape = (21))\n   \n    x = layers.Dense(\n            units = 128, \n            activation ='relu',\n            kernel_initializer ='he_uniform')(reg_inputs)\n    \n    x = layers.Dense(\n            units = 512, \n            activation ='relu',\n            kernel_initializer ='he_uniform')(x)\n    \n    x = layers.Dense(\n            units = 2048, \n            activation ='relu',\n            kernel_initializer ='he_uniform')(x)\n    \n    x = layers.Dense(\n            units = 512, \n            activation ='relu',\n            kernel_initializer ='he_uniform')(x)\n\n    x = layers.Dense(\n            units = 128, \n            activation ='relu',\n            kernel_initializer ='he_uniform')(x)\n        \n    reg_outputs = layers.Dense(\n            units = 6,\n        activation = 'linear',\n        kernel_initializer ='he_uniform',name = 'last')(x)\n\n    #----------- Model instantiation  ---------------\n    model = Model(reg_inputs,reg_outputs)\n\n    return model","f9364cc7":"# ---- Test definition with True label -----\nind_start = train.shape[0]-(24*7*2) #test for the 3 last weeks\nind_stop = train.shape[0]\nX_train = pd.concat([all_train_sc.iloc[:ind_start,:],all_train_sc.iloc[ind_stop:,:]])\nX_test = all_train_sc.iloc[ind_start:ind_stop,:] \ny_train = pd.concat([y_sc.iloc[:ind_start,:],y_sc.iloc[ind_stop:,:]])\ny_test = y_sc.iloc[ind_start:ind_stop,:]\nX_train.shape,X_test.shape,y_train.shape,y_test.shape","54ca1866":"y_train_log = y_train.copy()\ny_test_log = y_test.copy()\ny_train_log.iloc[:,0] = y_train.iloc[:,0].map(lambda x : math.log(x+1))\ny_train_log.iloc[:,1] = y_train.iloc[:,1].map(lambda x : math.log(x+1))\ny_train_log.iloc[:,2] = y_train.iloc[:,2].map(lambda x : math.log(x+1))\ny_train_log.iloc[:,3] = y_train.iloc[:,3].map(lambda x : math.log(x+1))\ny_train_log.iloc[:,4] = y_train.iloc[:,4].map(lambda x : math.log(x+1))\ny_train_log.iloc[:,5] = y_train.iloc[:,5].map(lambda x : math.log(x+1))\ny_test_log.iloc[:,0] = y_test.iloc[:,0].map(lambda x : math.log(x+1))\ny_test_log.iloc[:,1] = y_test.iloc[:,1].map(lambda x : math.log(x+1))\ny_test_log.iloc[:,2] = y_test.iloc[:,2].map(lambda x : math.log(x+1))\ny_test_log.iloc[:,3] = y_test.iloc[:,3].map(lambda x : math.log(x+1))\ny_test_log.iloc[:,4] = y_test.iloc[:,4].map(lambda x : math.log(x+1))\ny_test_log.iloc[:,5] = y_test.iloc[:,5].map(lambda x : math.log(x+1))","249fdfc2":"# We will use this benchmark to evaluate the quality of the training\n#bench = pd.concat([bench.iloc[:,1:],bench1.iloc[:,1:]],axis = 1)\nbench_stat = bench.describe() \nbench_stat","07bf922c":"ROUND =400 # Several iterations because of the stochastic calculation\npred_3 = np.zeros((len(test_sc),3))\npred_final = np.zeros((len(test_sc),3))\nprint('======== TRAINING STARTING ============\\n')\napproved = 0\n\nfor i in range(ROUND):\n    \n    tf.keras.backend.clear_session()\n    model = reg_model()\n    model.compile(loss=msle,optimizer = keras.optimizers.Adam())\n    model.fit(X_train,y_train_log,\n              batch_size = 64, \n              epochs = 100,\n              validation_data=(X_test,y_test_log),\n              callbacks=[es, plateau],\n              verbose =0)\n    pred = model.predict(X_test)\n    pred[:,0] = np.exp(pred[:,0])-1\n    pred[:,1] = np.exp(pred[:,1])-1\n    pred[:,2] = np.exp(pred[:,2])-1\n    pred[:,3] = np.exp(pred[:,3])-1\n    pred[:,4] = np.exp(pred[:,4])-1\n    pred[:,5] = np.exp(pred[:,5])-1\n    \n    \n    pred = np.where(pred>0,pred,0)\n    \n    score = np.round(mean_squared_log_error(y_test, pred),5)\n    print(f\"Score for round {i} on X_test :\", score)\n    \n    # In case of multiple iterations, we can reject anomalous predictions :\n    if (score <= 0.027\n       ) == True:\n        approved += 1\n        print(f\"round {i} approved for benchmarking analysis \")\n        pred_test = model.predict(test_sc)\n        pred_test[:,0] = np.exp(pred_test[:,0])-1\n        pred_test[:,1] = np.exp(pred_test[:,1])-1\n        pred_test[:,2] = np.exp(pred_test[:,2])-1\n        pred_test[:,3] = np.exp(pred_test[:,3])-1\n        pred_test[:,4] = np.exp(pred_test[:,4])-1\n        pred_test[:,5] = np.exp(pred_test[:,5])-1\n        pred_test = np.where(pred_test>0,pred_test,0.05)\n        pred_3[:,0] = (pred_test[:,0]+pred_test[:,3])\/2\n        pred_3[:,1] = (pred_test[:,1]+pred_test[:,4])\/2\n        pred_3[:,2] = (pred_test[:,2]+pred_test[:,5])\/2\n        \n\n        # Run analysis :\n        df = pd.concat([pd.DataFrame(pred_test).describe(),pd.DataFrame(bench_stat)], axis = 1)\n        \n        carbon_75 = np.abs((df.iloc[6,0]-df.iloc[6,6])\/df.iloc[6,6])\n        benzene_75 = np.abs((df.iloc[6,1]-df.iloc[6,7])\/df.iloc[6,7])\n        nitrogen_75 = np.abs((df.iloc[6,2]-df.iloc[6,8])\/df.iloc[6,8])\n        \n        carbon_50 = np.abs((df.iloc[5,0]-df.iloc[5,6])\/df.iloc[5,6])\n        benzene_50 = np.abs((df.iloc[5,1]-df.iloc[5,7])\/df.iloc[5,7])\n        nitrogen_50 = np.abs((df.iloc[5,2]-df.iloc[5,8])\/df.iloc[5,8])\n        \n        carbon_25 = np.abs((df.iloc[4,0]-df.iloc[4,6])\/df.iloc[4,6])\n        benzene_25 = np.abs((df.iloc[4,1]-df.iloc[4,7])\/df.iloc[4,7])\n        nitrogen_25 = np.abs((df.iloc[4,2]-df.iloc[4,8])\/df.iloc[4,8])\n        \n        run_75 =100 *(carbon_75 + benzene_75 + nitrogen_75)\/3\n        run_50 =100 *(carbon_50 + benzene_50 + nitrogen_50)\/3\n        run_25 =100 *(carbon_25 + benzene_25 + nitrogen_25)\/3\n        \n        print(f'Benchmark GAP at 75% :{run_75}% at 50% :{run_50}% at 25% :{run_25}%\\n')\n        if ((run_75 < 1.1) & (run_50 < 1) & (run_25 < 1.1))== True :\n            pred_final += pred_3\n            print(\"PREDICTION RECORDED\")\n            print(f\"Final GAP 75% :{run_75} GAP 50% :{run_50} GAP 25% :{run_25}\")\n            break\n        else :\n            print('PREDICTION REJECTED \\n')\n    else :\n        print(f\"round {i} rejected \\n\")\n\n    \nprint(f\"\\n====== End of the training :{approved} accepted rounds for this training =====\\n\")","ad39badc":"sample_submission['target_carbon_monoxide'] = pred_final[:,-3]\nsample_submission['target_benzene'] = pred_final[:,-2]\nsample_submission['target_nitrogen_oxides'] = pred_final[:,-1]","1d94fffb":"sample_submission.to_csv('sub_NN_double_pseudo_3.csv',index = False)","0d835800":"<h2> Benchmark analysis (no blending)","b441c56f":"<h2> Benchmark preparation before training and submission (no blending)","6c040c9a":"<h2> Features rescaling","12b5c9ee":"<h2> Features augmentation","3d4df957":"![image.png](attachment:56dc995d-66aa-4938-89e8-87f33ce682c9.png)\n\nPseudolabel inpired from TPS LightAutoML baseline (with pseudolabels) made by the famous Alexander Ryzhkov !<h3>\n2 files for pseudolabelling are used. X_test has true labels.\nThe Neural Network prediction is compared with a benchmark file from Somayyeh Gholami & Mehran Kazeminia, smart ensembling.\nThe 75%, 50% and 25% percentiles are evaluated.\nThe best prediction of the Neural Network is recorded if above thresholds on score from the benchmark comparison and the X_test (with true label) MSLE score\n\nThank's to BIZEN :\nhttps:\/\/www.kaggle.com\/hiro5299834\/tps-jul-2021-pycaret-with-pseudo-labels\nand :\n@junhyeok99 https:\/\/www.kaggle.com\/junhyeok99\/automl-pycaret\n","a5439425":"<h2> Model definition","2caed2c5":"<h2> Training and best prediction choice","8737a4a6":"<h2> Loss and metric functions for NN"}}