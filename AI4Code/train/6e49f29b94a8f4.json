{"cell_type":{"8b87516c":"code","cbd2539d":"code","cd1473a1":"code","bf06958e":"code","32d0c640":"code","18f378ce":"code","e0b77766":"code","965c0b84":"code","0a6e9e59":"code","219500a1":"code","a4a97002":"code","495a4bd8":"code","5506f9b7":"code","7073148e":"code","a3def068":"code","63d4bbd2":"code","e483f3d9":"code","2dd606dc":"code","f7515718":"markdown","70732a36":"markdown","1c17075c":"markdown","a2300dd0":"markdown","39a62667":"markdown","4bcb2d0d":"markdown"},"source":{"8b87516c":"import pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import KFold\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nplt.style.use('ggplot')\nimport warnings\nwarnings.filterwarnings('ignore')","cbd2539d":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')","cd1473a1":"print(f\"train data: Rows={train.shape[0]}, Columns={train.shape[1]}\")\nprint(f\"test data : Rows={test.shape[0]}, Columns={test.shape[1]}\")","bf06958e":"train.head()","32d0c640":"print(train.isnull().sum())","18f378ce":"print(test.isnull().sum())","e0b77766":"cfg = {\n    'TARGET' : 'target',\n    'N_FOLDS' : 5,\n    'RANDOM_STATE': 529,\n    'N_ESTIMATORS' : 50_000,\n    'LEARNING_RATE': 0.1\n}\n\ntrain_passes = train['PassengerId'].unique()","965c0b84":"kf = KFold(n_splits=cfg['N_FOLDS'],\n           shuffle=True,\n           random_state=cfg['RANDOM_STATE'])\n\n# Create Folds\nfold = 1\nfor tr_idx, val_idx in kf.split(train_passes):\n    fold_passes = train_passes[val_idx]\n    train.loc[train['PassengerId'].isin(fold_passes), 'fold'] = fold\n    fold += 1\ntrain['fold'] = train['fold'].astype('int')","0a6e9e59":"train['fold'].value_counts()","219500a1":"def prepare_features(df, train=True):\n    #df.dropna(subset=['Age'])\n    df['Pclass'] = df['Pclass'].astype('category')\n    df['SibSp'] = df['SibSp'].astype('category')\n    df['Age'] = df['Age'].fillna(df['Age'].mean())\n    \n    df = pd.get_dummies(df, columns=[\"Sex\", \"Ticket\", \"Cabin\", \"Embarked\"])\n    \n    return df","a4a97002":"train['isTrain'] = True\ntest['isTrain'] = False\nalldata = pd.concat([train, test]).reset_index(drop=True).copy()\nalldata = alldata.drop('Name', axis=1)\n\nalldata = prepare_features(alldata)","495a4bd8":"train_feats = alldata.query('isTrain').reset_index(drop=True).copy()\ntest_feats = alldata.query('isTrain == False').reset_index(drop=True).copy()","5506f9b7":"train_feats.head()","7073148e":"X_test = test_feats.drop('Survived', axis=1)\n\noof = train_feats[['PassengerId','Survived','fold']].reset_index(drop=True).copy()\nsubmission_df = test[['PassengerId']].copy()\n\nFEATURES = X_test.columns.values\nTARGET = ['Survived']","a3def068":"regs = []\nfis = []\n# Example Fold 1\nfor fold in range(1, 6):\n    print(f'===== Running for fold {fold} =====')\n    # Split train \/ val\n    X_tr = train_feats.query('fold != @fold')[FEATURES]\n    y_tr = train_feats.query('fold != @fold')[TARGET]\n    X_val = train_feats.query('fold == @fold')[FEATURES]\n    y_val = train_feats.query('fold == @fold')[TARGET]\n    print(X_tr.shape, y_tr.shape, X_val.shape, y_val.shape)\n\n    # Create our model\n    reg = lgb.LGBMClassifier(n_estimators=cfg['N_ESTIMATORS'],\n                            learning_rate=cfg['LEARNING_RATE'],\n                            objective='binary',\n                            metric=['binary_logloss'],\n                            importance_type='gain'\n                            #importance_type='split'\n                           )\n    # Fit our model\n    reg.fit(X_tr, y_tr,\n            eval_set=(X_val, y_val),\n            early_stopping_rounds=500,\n            verbose=200,\n           )\n\n    # Predicting on validation set\n    fold_preds = reg.predict(X_val,\n                             num_iteration=reg.best_iteration_)\n    oof.loc[oof['fold'] == fold, 'preds'] = fold_preds\n    # Score validation set\n    fold_score = mean_absolute_error(\n        oof.query('fold == 1')['Survived'],\n            oof.query('fold == 1')['preds']\n    )\n\n    # Creating a feature importance dataframe\n    fi = pd.DataFrame(index=reg.feature_name_,\n                 data=reg.feature_importances_,\n                 columns=[f'{fold}_importance'])\n\n    # Predicting on test\n    fold_test_pred = reg.predict(X_test,\n                num_iteration=reg.best_iteration_)\n    submission_df[f'pred_{fold}'] = fold_test_pred.astype(int)\n    print(f'Score of this fold is {fold_score:0.6f}')\n    regs.append(reg)\n    fis.append(fi)","63d4bbd2":"oof_score = mean_absolute_error(oof['Survived'], oof['preds'])\nprint(f'Out of fold score {oof_score:0.6f}')","e483f3d9":"submission_df.set_index('PassengerId')\nsubmission_df","2dd606dc":"pred_cols = [c for c in submission_df.columns if c.startswith('pred_')]\nsubmission_df['Survived'] = submission_df[pred_cols].mode(axis=1)\n\nsubmission_df[['PassengerId','Survived']].to_csv('submission.csv', index=False)","f7515718":"# Preparing Features","70732a36":"# LGBM Classification","1c17075c":"# Checking the data","a2300dd0":"# Simple LGBM Classification and K-Fold model\n\nI create this note for personal study.\nThanks to all the kagglers who shared their helpful wisdom and information.","39a62667":"# Make Submission","4bcb2d0d":"# Create Fold"}}