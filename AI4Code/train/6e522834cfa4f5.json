{"cell_type":{"74bb8f28":"code","53a2c0a4":"code","b91a74f3":"code","9bcb20b9":"code","1be334fe":"code","69725af0":"code","b912d921":"code","f5ba45a0":"code","26a4b1d3":"code","da6c3db4":"code","20718c59":"code","b2742aa8":"code","72176a04":"code","22acb0ea":"markdown","7c545497":"markdown","13001457":"markdown","83e0cad6":"markdown","76b3072d":"markdown","c19b5001":"markdown"},"source":{"74bb8f28":"import numpy as np\nimport pandas as pd\nimport cv2 as cv\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport tensorflow as tf\nimport re\nimport requests\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import LabelBinarizer\n\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D, Dense, BatchNormalization, Dropout \nfrom keras.layers import Flatten, Lambda, Input, MaxPooling2D\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.regularizers import l1, l2\n\n%config InlineBackend.figure_format = 'svg'","53a2c0a4":"# Input shape for ANN and to resize images\ninput_shape = (110, 110, 3)","b91a74f3":"X = [] # Lists for images data\nY_cat = [] # List to store category of image (dress, shirt etc)\nY_col = [] # List to store color of apparel\n\n# Path to datast\ndataset = '..\/input\/apparel-images-dataset'\n\n# Loop through all categories in dataset\nfor folder in os.listdir(dataset):\n    \n    # Path to images in certain category\n    folder_path = os.path.join(dataset, folder)\n    \n    # Loop through all images in category\n    for i in os.listdir(folder_path):\n        \n        # Path to certain image (Example: ..\/input\/apparel-images-dataset\/blue_dress\/11d5fd4203b08f26dac2e7fa2294c6f01babee15.jpg)\n        path_to_image = os.path.join(folder_path, i)\n        \n        # Reading and resizing image to 96x96 pixels size\n        image = cv.imread(path_to_image)\n        image = cv.resize(image, (input_shape[1], input_shape[0]))\n        \n        # using regex to extract labels from path_to_image\n        labels = re.findall(r'\\w+\\_\\w+', path_to_image) # Gives us ['blue_dress']\n        labels = labels[0].split('_') # Gives us ['blue', 'dress']\n        \n        # Adding data and labels to lists\n        X.append(image)\n        Y_cat.append(labels[1])\n        Y_col.append(labels[0])","9bcb20b9":"# Convert X to numpy array\nX = np.array(X) \/ 255.0\n\n# Binarizing labels\nlb_cat = LabelBinarizer()\nY_cat = lb_cat.fit_transform(Y_cat)\n\nlb_col = LabelBinarizer()\nY_col = lb_col.fit_transform(Y_col)","1be334fe":"# Labels\nprint('Category classes:')\n[print(i) for i in zip(lb_cat.classes_, np.unique(np.argmax(Y_cat, axis = 1)))]\n\nprint('\\nColor classes:')\n[print(i) for i in zip(lb_col.classes_, np.unique(np.argmax(Y_col, axis = 1)))]","69725af0":"# test_x, cat_y_test, col_y_test - for final validation\nx, test_x, cat_y, cat_y_test, col_y, col_y_test = train_test_split(X, Y_cat, Y_col, test_size = 0.1, shuffle = True, random_state = 1)\n\n# Train and validation data\ntrain_x, val_x, cat_y_train, cat_y_val, col_y_train, col_y_val = train_test_split(x, cat_y, col_y, test_size = 0.2)","b912d921":"inputs = Input(shape = input_shape)\n\n# Category branch\ncat = Lambda(lambda z: tf.image.rgb_to_grayscale(z))(inputs)\n\ncat = Conv2D(32, 5, padding = 'same', activation = 'relu', kernel_initializer = 'he_normal')(cat)\ncat = BatchNormalization()(cat)\ncat = Conv2D(32, 5, padding = 'same', activation = 'relu', kernel_initializer = 'he_normal')(cat)\ncat = BatchNormalization()(cat)\ncat = MaxPooling2D()(cat)\ncat = Dropout(0.25)(cat)\n\ncat = Conv2D(64, 3, padding = 'same', activation = 'relu', kernel_initializer = 'he_normal')(cat)\ncat = BatchNormalization()(cat)\ncat = Conv2D(64, 3, padding = 'same', activation = 'relu', kernel_initializer = 'he_normal')(cat)\ncat = BatchNormalization()(cat)\ncat = MaxPooling2D()(cat)\ncat = Dropout(0.25)(cat)\n\ncat = Conv2D(128, 3, padding = 'same', activation = 'relu', kernel_initializer = 'he_normal')(cat)\ncat = BatchNormalization()(cat)\ncat = Conv2D(128, 3, padding = 'same', activation = 'relu', kernel_initializer = 'he_normal')(cat)\ncat = BatchNormalization()(cat)\ncat = MaxPooling2D()(cat)\ncat = Dropout(0.25)(cat)\n\ncat = Flatten()(cat)\ncat = Dense(128, activation = 'relu', kernel_initializer = 'he_normal')(cat)\ncat = BatchNormalization()(cat)\ncat = Dropout(0.5)(cat)\ncat = Dense(lb_cat.classes_.shape[0], activation = 'softmax', name = 'cat')(cat)\n\n\n#Color branch\ncol = Conv2D(16, 3, padding = 'same', activation = 'relu', kernel_initializer = 'he_normal')(inputs)\ncol = BatchNormalization(axis = -1)(col)\ncol = MaxPooling2D(3)(col)\ncol = Dropout(0.25)(col)\n\ncol = Conv2D(32, 3, padding = 'same', activation = 'relu', kernel_initializer = 'he_normal')(col)\ncol = BatchNormalization(axis = -1)(col)\ncol = MaxPooling2D()(col)\ncol = Dropout(0.25)(col)\n\ncol = Conv2D(32, 3, padding = 'same', activation = 'relu', kernel_initializer = 'he_normal')(col)\ncol = BatchNormalization(axis = -1)(col)\ncol = MaxPooling2D()(col)\ncol = Dropout(0.25)(col)\n\ncol = Flatten()(col)\ncol = Dense(128, activation = 'relu', kernel_initializer = 'he_normal')(col)\ncol = BatchNormalization()(col)\ncol = Dropout(0.5)(col)\ncol = Dense(lb_col.classes_.shape[0], activation = 'softmax', name = 'col')(col)\n\n\nmodel = Model(inputs = inputs, outputs = [cat, col])\nlosses = {'cat': 'categorical_crossentropy',\n         'col': 'categorical_crossentropy'}\nloss_weights = {'cat': 1.0, 'col': 1.0}\n\ncheckpoint = ModelCheckpoint('..\/working\/best_model.hdf5', save_best_only = True, verbose = 1, monitor = 'val_loss')\n\nmodel.compile(optimizer = 'adam', loss = losses, \n              loss_weights = loss_weights, metrics = ['accuracy'])\n\nhistory = model.fit(train_x, {'cat': cat_y_train, 'col': col_y_train},\n         validation_data = (val_x, {'cat': cat_y_val, 'col': col_y_val}),\n         batch_size = 64, epochs = 30, callbacks = [checkpoint])\n","f5ba45a0":"# Plot learning curves\nH = history.history\nfig = plt.figure(figsize = (13, 5))\n\nfor i, c in enumerate(('cat', 'col')):\n    plt.subplot(f'12{i+1}')\n    plt.plot(H[f'{c}_accuracy'], label = f'{c}_acc')\n    plt.plot(H[f'val_{c}_accuracy'], label = f'val_{c}_acc')\n    plt.plot(H[f'{c}_loss'], label = f'{c}_loss')\n    plt.plot(H[f'val_{c}_loss'], label = f'val_{c}_loss')\n    plt.title(f'{c} learning curves')\n    plt.legend()\n    plt.grid()","26a4b1d3":"# Load best weights\nmodel.load_weights('..\/working\/best_model.hdf5')\n\n# Predicting test images\ncat_preds, col_preds = model.predict(test_x)\ncat_preds = np.argmax(cat_preds, axis = 1)\ncol_preds = np.argmax(col_preds, axis = 1)\n\n# Creating confusion matrices\ncat_confusion = confusion_matrix(np.argmax(cat_y_test, axis = 1), cat_preds)\ncol_confusion = confusion_matrix(np.argmax(col_y_test, axis = 1), col_preds)","da6c3db4":"# Plotting confusion matrices\nfig = plt.figure(figsize = (13, 5))\n\n# Category confusion matrix plot\nplt.subplot(121)\ncat_l = list(lb_cat.classes_)\nsns.heatmap(cat_confusion, square = True, annot = True, fmt = 'd', cbar = False, \n            xticklabels = cat_l, yticklabels = cat_l, cmap = 'coolwarm').set_title('Category confusion matrix')\n\n# Color confusion matrix plot\nplt.subplot(122)\ncol_l = list(lb_col.classes_)\nsns.heatmap(col_confusion, square = True, annot = True, fmt = 'd', cbar = False, \n            xticklabels = col_l, yticklabels = col_l, cmap = 'coolwarm').set_title('Color confusion matrix')\n\nplt.show()","20718c59":"def plot_images(urls, rows, cols):\n    fig = plt.figure(figsize = (13, rows * 5))\n\n    for i, url in enumerate(urls):\n        plt.subplot(f'{rows}{cols}{i+1}')\n\n        # Sending request to the URL\n        r = requests.get(url, stream = True).raw\n\n        # Reading image, convert it to np array and decode\n        image = np.asarray(bytearray(r.read()), dtype=\"uint8\")\n        image = cv.imdecode(image, cv.IMREAD_COLOR)\n\n        # Resize, scale and reshape image before making predictions\n        resized = cv.resize(image, (input_shape[1], input_shape[0]))\n        resized = (resized \/ 255.0).reshape(-1, input_shape[1], input_shape[0], input_shape[2])\n\n        # Predict results\n        preds_cat, preds_col = model.predict(resized)\n        preds_cat = (lb_cat.classes_[np.argmax(preds_cat[0])], round(preds_cat[0].max() * 100, 2))\n        preds_col = (lb_col.classes_[np.argmax(preds_col[0])], round(preds_col[0].max() * 100, 2))\n\n        # Showing image\n        plt.imshow(image[:, :, ::-1])\n        plt.title(f'{preds_cat[0]}: {preds_cat[1]}% \\n {preds_col[0]}: {preds_col[1]}%')\n        plt.axis('off')","b2742aa8":"urls = [\n    'http:\/\/picture-cdn.wheretoget.it\/e07ql5-l-610x610-dress-little+black+dress-skater+dress-nastygal-deep+vneck-short-formal-short+formal+dress-prom-short+prom+dress-black-lbd-short+black+dress-prom+dress-black+dress-blackdress-short+.jpg',\n    'https:\/\/img.simplydresses.com\/_img\/SDPRODUCTS\/2103981\/500\/navy-dress-JU-TI-T0468-a.jpg',\n    'https:\/\/d2euz5hho4dp59.cloudfront.net\/images\/detailed\/40\/main_jean_419.jpg',\n    'https:\/\/sc02.alicdn.com\/kf\/HTB1QbZ_dzgy_uJjSZJnq6zuOXXaq\/Wholesale-scratch-pants-damaged-denim-women-s.jpg_350x350.jpg',\n    'https:\/\/i.ebayimg.com\/00\/s\/NjAwWDYwMA==\/z\/pakAAOSwVtta6SN8\/$_1.JPG?set_id=880000500F',\n    'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcSFA1Q-O44dQWt1lvsnOQyoMcQ3myaxY-GscMHgmPtmyWT14ZJU',\n    'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcTJYyBOAy35RM7m0JzNGHo_-VTSf6bPMh9hACbhhqxsdoMXHQvD',\n    'https:\/\/cdn.shopify.com\/s\/files\/1\/1359\/6121\/products\/7481209_LF0A0919_1024x1024.jpg?v=1511982241',    \n]\n\nplot_images(urls, 2, 4)","72176a04":"urls = [    \n    'https:\/\/lp2.hm.com\/hmgoepprod?set=source[\/3c\/5f\/3c5fa4806ee4a7a9b958041041fd67b1f9a0829b.jpg],origin[dam],category[],type[DESCRIPTIVESTILLLIFE],res[m],hmver[1]&call=url[file:\/product\/main]',\n    'https:\/\/is4.revolveassets.com\/images\/p4\/n\/d\/AXIS-WD346_V1.jpg',\n    'https:\/\/cdn-img.prettylittlething.com\/f\/4\/3\/a\/f43a25de8714d69982b21c107a64f54e16647b08_clz6006_1.jpg',\n    'https:\/\/cdn11.bigcommerce.com\/s-9p1fzopril\/images\/stencil\/500x659\/products\/352\/1416\/Screen_Shot_2019-08-10_at_9.02.38_am__31648.1565392335.png?c=2',\n    'https:\/\/img0.junaroad.com\/uiproducts\/15054911\/zoom_0-1524133662.jpg',\n    'https:\/\/cdn.shopify.com\/s\/files\/1\/0021\/2343\/2045\/products\/Attachment_1550340699_1200x1200.jpeg?v=1550587174',\n    'https:\/\/underarmour.scene7.com\/is\/image\/Underarmour\/V5-1350196-600_FC?template=v65GridSmallRetina&$wid=300&$hei=368',\n    'https:\/\/pa.namshicdn.com\/product\/A8\/13685W\/1-zoom-desktop.jpg'    \n]\n\nplot_images(urls, 2, 4)","22acb0ea":"# Results","7c545497":"# Predicting combinations that are not presented in the dataset","13001457":"# Model creation and training","83e0cad6":"# Goal\n\nThis is experimental kernel. Here I want to get some practice of creating ANN with 2 branches, each of which will classify it's own categories.\n\nAnother kernels on this dataset:\n- [Multi-label classification (Keras)](https:\/\/www.kaggle.com\/trolukovich\/multi-label-classification-keras)\n\n**NOTE**: This kernel was created using 6th version of the dataset. I'm improving this dataset from time to time, so you can get different results if you'll try to follow this kernel.","76b3072d":"# Predicting randoom google search images","c19b5001":"# Creating train and test data"}}