{"cell_type":{"bf6bcbf4":"code","f031033a":"code","ddcdb6be":"code","887ff2d4":"code","4934d789":"code","9b03361d":"code","66832470":"code","b283fe94":"code","f45c93bf":"code","0eea7102":"code","65ca0279":"code","a9567e9f":"code","7ea72dc7":"code","e3f576d9":"code","65934c6d":"code","0bf523ab":"code","450635fd":"code","63746b91":"code","42b08907":"code","928966c3":"code","9ccc6b7f":"code","eefd6b01":"code","85752252":"code","990652c0":"code","131a2317":"code","aa6c6fcb":"code","4614b513":"code","6c52baa2":"code","0651333e":"code","34ea400e":"code","9c1d9aea":"code","ffc951e8":"code","afcfcc4d":"code","62ec076e":"code","43eca2e1":"code","143b0281":"code","1e9eaa2d":"code","ad94b372":"code","38546c16":"code","61790455":"code","472e9582":"code","1105f544":"code","16e7518f":"code","f24f1702":"code","05e7f0cc":"code","f2789e38":"code","55787d6b":"code","1d652c45":"code","950102a3":"code","f6f07f61":"code","c8c37878":"code","9f33ad4e":"code","71544a6a":"code","be6df752":"code","e97656cd":"code","cb5f4494":"code","466b21c9":"markdown","1d600802":"markdown","f16a11e3":"markdown","f1b7ca53":"markdown","99b778c0":"markdown","5d791737":"markdown","80c208ad":"markdown","330143e1":"markdown","8db4513b":"markdown","7cbbdbbb":"markdown","da1e7064":"markdown","b01f3c9b":"markdown","d52b7119":"markdown","f1ca735f":"markdown","3ff579af":"markdown","36245f6d":"markdown","dde74370":"markdown","bf511fcc":"markdown","ef5fa2e9":"markdown","9d976427":"markdown","c86b765e":"markdown","e97163f2":"markdown","a8a3cb65":"markdown","3faeb2a3":"markdown","085a788f":"markdown","6ae7b9a5":"markdown","5c078bb2":"markdown"},"source":{"bf6bcbf4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f031033a":"import matplotlib.pyplot as plt\nimport matplotlib.ticker as mtick\nimport matplotlib.gridspec as grid_spec\nimport seaborn as sns\nfrom imblearn.over_sampling import SMOTE\nimport scikitplot as skplt\n\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler,LabelEncoder\nfrom sklearn.model_selection import train_test_split,cross_val_score\n\n\nfrom sklearn.linear_model import LinearRegression,LogisticRegression\nfrom sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\n\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import accuracy_score, recall_score, roc_auc_score, precision_score, f1_score\nimport warnings\nwarnings.filterwarnings('ignore')\n!pip install pywaffle","ddcdb6be":"data=pd.read_csv('\/kaggle\/input\/pima-indians-diabetes-database\/diabetes.csv')\ndata.head()","887ff2d4":"data.isna().sum()","4934d789":"data.shape","9b03361d":"data.describe()","66832470":"col=data.columns\ncol=list(col)\nfor i in col:\n    print(i)\n    print(data[i].unique())","b283fe94":"col.remove('Outcome')\nfor i in col:\n    fig = px.histogram(data, x=i)\n    fig.show()","f45c93bf":"for i in col:\n    fig = px.box(data, x=i)\n    fig.show()","0eea7102":"for i in col:\n    # Removing Outliers \n    Q3 = data[i].quantile(0.99)\n    data = data[data[i]<= Q3]\n    Q1 = data[i].quantile(0.01)\n    data = data[data[i] >= Q1]\n    print(i)\n    print(\"Q1:-\",Q1)\n    print(\"Q3:-\",Q3)","65ca0279":"data.shape","a9567e9f":"def show(data,i):\n    print(i)\n    print(\"Total : \", data[data[i] == 0].shape[0])\n    print(\"mean by grouping\",data[data[i] == 0].groupby('Outcome')['Age'].count())\n    print(\"overall mean \",data[i].mean())\n    print(\"************************\")","7ea72dc7":"def rep(data,i):\n    res1,res2=data.groupby('Outcome')[i].mean()\n    data.loc[((data[i] == 0 )& (data['Outcome']==0)),i+'new'] = res1\n    data.loc[((data[i] == 0  )& (data['Outcome']==1)),i+'new'] = res2\n    data.loc[(data[i] > 0 ),i+'new'] = data[i]","e3f576d9":"show(data,'Insulin')\nshow(data,'SkinThickness')\nshow(data,'BloodPressure')\nshow(data,'BMI')","65934c6d":"rep(data,'Insulin')\nrep(data,'SkinThickness')\nrep(data,'BloodPressure')\nrep(data,'BMI')","0bf523ab":"data.drop(['SkinThickness','Insulin','BloodPressure','BMI'],inplace=True,axis=1)","450635fd":"data.shape","63746b91":"data[\"SkinThickness\"]=data[\"SkinThicknessnew\"].astype(int)\ndata[\"Insulin\"]=data[\"Insulinnew\"].astype(int)\ndata[\"BloodPressure\"]=data[\"BloodPressurenew\"].astype(int)\ndata[\"BMI\"]=data[\"BMInew\"].astype(int)\ndata[\"outcome\"]=data[\"Outcome\"].astype(int)","42b08907":"data.drop(['SkinThicknessnew','Insulinnew','BloodPressurenew','BMInew','Outcome'],inplace=True,axis=1)\n","928966c3":"corr=data.corr()\ncorr","9ccc6b7f":"plt.figure(figsize=(16, 6))\nmask = np.triu(np.ones_like(corr, dtype=bool))\nsns.heatmap(corr,annot=True, linewidths=1,mask = mask, cmap=\"YlGnBu\")","eefd6b01":"background_color = \"#ffffff\"\nfig = plt.figure(figsize=(15,8), facecolor=background_color)\nsns.pairplot(data,hue='outcome',palette=\"mako_r\")","85752252":"data.describe()","990652c0":"for i in col:\n    fig = px.histogram(data, x=i)\n    fig.show()","131a2317":"\n\nimport scipy.stats as stat\nimport pylab \n\n","aa6c6fcb":"import pylab \n\n#### If you want to check whether feature is guassian or normal distributed\n#### Q-Q plot\ndef plot_data(data,feature):\n    plt.figure(figsize=(10,6))\n    plt.subplot(1,2,1)\n    data[feature].hist()\n    plt.subplot(1,2,2)\n    stat.probplot(data[feature],dist='norm',plot=pylab)\n    plt.show()\n    ","4614b513":"def plot_me(data,i):\n    print('*******************************************')\n    print(i)\n    print('*******************************************')\n    plot_data(data,i)\n    if(i!='Pregnancies'):\n        print('log')\n        data[i+'_log']=np.log(data[i])\n        plot_data(data,i+'_log')\n        print('reciprocal')\n        data[i+'_reciprocal']=1\/data[i]\n        plot_data(data,i+'_reciprocal')\n    print('square')\n    data[i+'_sqaure']=data[i]**(1\/2)\n    plot_data(data,i+'_sqaure')\n    print('expo')\n    data[i+'_exponential']=data[i]**(1\/1.2)\n    plot_data(data,i+'_exponential')\n    if(i!='Pregnancies'):\n        print('boxcox')\n        data[i+'_Boxcox'],parameters=stat.boxcox(data[i])\n        plot_data(data,i+'_Boxcox') \n    print('*******************************************')\n    print('*******************************************')","6c52baa2":"for i in col:\n    plot_me(data,i)","0651333e":"data.columns","34ea400e":"data.drop(['Pregnancies', 'Glucose', 'DiabetesPedigreeFunction', 'Age',\n       'SkinThickness', 'Insulin', 'BMI',\n       'Pregnancies_sqaure',\n       'Glucose_reciprocal', 'Glucose_sqaure', 'Glucose_exponential',\n       'Glucose_Boxcox',\n       'DiabetesPedigreeFunction_reciprocal',\n       'DiabetesPedigreeFunction_sqaure',\n       'DiabetesPedigreeFunction_exponential',\n       'DiabetesPedigreeFunction_Boxcox', 'Age_log', 'Age_reciprocal',\n       'Age_sqaure', 'Age_exponential', 'SkinThickness_log',\n       'SkinThickness_reciprocal',\n       'SkinThickness_exponential', 'SkinThickness_Boxcox', 'Insulin_log',\n       'Insulin_reciprocal', 'Insulin_sqaure', 'Insulin_exponential',\n        'BloodPressure_log', 'BloodPressure_reciprocal',\n       'BloodPressure_sqaure', 'BloodPressure_exponential',\n       'BloodPressure_Boxcox', 'BMI_log', 'BMI_reciprocal', 'BMI_sqaure',\n       'BMI_exponential'],inplace=True,axis=1)","9c1d9aea":"data.columns","ffc951e8":"fig=px.pie(data,values=data['outcome'].value_counts(),\n           names=data['outcome'].value_counts().index,template =\"simple_white\",\n           color_discrete_sequence = px.colors.diverging.Tropic,hole=.6)\nfig.update_layout(title_text=\"<b> Distribution Of The Target Feature-Outcome <\/b>\",\n                  title_x=0.5,\n                  font_size=15)","afcfcc4d":"X  = data[['BloodPressure', 'Pregnancies_exponential', 'Glucose_log',\n       'SkinThickness_sqaure', 'Insulin_Boxcox', 'BMI_Boxcox',\n       'DiabetesPedigreeFunction_log', 'Age_Boxcox']]\ny = data['outcome']","62ec076e":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.3, random_state=42)","43eca2e1":"X_train_resh, y_train_resh = X_train, y_train","143b0281":"#pipelines\nrf_pipeline = Pipeline(steps = [('scale',StandardScaler()),('RF',RandomForestClassifier(random_state=42))])\nsvm_pipeline = Pipeline(steps = [('scale',StandardScaler()),('SVM',SVC(random_state=42))])\nlogreg_pipeline = Pipeline(steps = [('scale',StandardScaler()),('LR',LogisticRegression(random_state=42))])","1e9eaa2d":"#cross validation\nrf_cv = cross_val_score(rf_pipeline,X_train_resh,y_train_resh,cv=10,scoring='f1')\nsvm_cv = cross_val_score(svm_pipeline,X_train_resh,y_train_resh,cv=10,scoring='f1')\nlogreg_cv = cross_val_score(logreg_pipeline,X_train_resh,y_train_resh,cv=10,scoring='f1')","ad94b372":"print('Mean f1 scores:')\nprint('Random Forest mean :',cross_val_score(rf_pipeline,X_train_resh,y_train_resh,cv=10,scoring='f1').mean())\nprint('SVM mean :',cross_val_score(svm_pipeline,X_train_resh,y_train_resh,cv=10,scoring='f1').mean())\nprint('Logistic Regression mean :',cross_val_score(logreg_pipeline,X_train_resh,y_train_resh,cv=10,scoring='f1').mean())","38546c16":"#fitting the model\nrf_pipeline.fit(X_train_resh,y_train_resh)\nsvm_pipeline.fit(X_train_resh,y_train_resh)\nlogreg_pipeline.fit(X_train_resh,y_train_resh)","61790455":"#predicting\nrf_pred   =rf_pipeline.predict(X_test)\nsvm_pred  = svm_pipeline.predict(X_test)\nlogreg_pred   = logreg_pipeline.predict(X_test)","472e9582":"y_pred_final = rf_pred.copy()\nfor i in range(len(rf_pred)):\n    n_ones = rf_pred[i] + svm_pred[i] + logreg_pred[i]\n    if n_ones>1:\n        y_pred_final[i] = 1\n    else:\n        y_pred_final[i] = 0","1105f544":"cl_rep = classification_report(y_test, y_pred_final)\nprint(cl_rep)\n\ncl_rep_f1  = confusion_matrix(y_test,y_pred_final)\ncl_rep_f1","16e7518f":"# Plotting our results\nimport matplotlib\n\ncolors = [\"lightgray\",\"#0f4c81\",\"#0f4c81\",\"#0f4c81\",\"#0f4c81\",\"#0f4c81\",\"#0f4c81\",\"#0f4c81\"]\ncolormap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)\n\n\nbackground_color = \"#fbfbfb\"\n\nfig = plt.figure(figsize=(10,14)) # create figure\ngs = fig.add_gridspec(4, 2)\ngs.update(wspace=0.1, hspace=0.8)\nax0 = fig.add_subplot(gs[0, :])\nax0.set_facecolor(background_color) # axes background color\n\n# Overall\nsns.heatmap(cl_rep_f1, cmap=colormap,annot=True,fmt=\"d\", linewidths=5,cbar=False,ax=ax0,\n            yticklabels=['Actual Non-Stroke','Actual Stroke'],xticklabels=['Predicted Non-Stroke','Predicted Stroke'],annot_kws={\"fontsize\":12})\n\n\n\nax0.tick_params(axis=u'both', which=u'both',length=0)\nbackground_color = \"#fbfbfb\"\nfig.patch.set_facecolor(background_color) # figure background color\nax0.set_facecolor(background_color) \n\n\nax0.text(0,-0.75,'Ensemble Performance',fontsize=18,fontweight='bold',fontfamily='serif')\n\n\nplt.show()","f24f1702":"!pip install pycaret","05e7f0cc":"#checking all models\nfrom pycaret.classification import *\nclf1 = setup(data = data, target = 'outcome')","f2789e38":"compare_models(sort = 'F1') #default is 'Accuracy'","55787d6b":"ada=create_model('ada')","1d652c45":"from imblearn.over_sampling import SMOTE\n\n#3\noversample = SMOTE()\nX_train_resh, y_train_resh = oversample.fit_resample(X_train, y_train.ravel())\n","950102a3":"#pipelines\nrf_pipeline = Pipeline(steps = [('scale',StandardScaler()),('RF',RandomForestClassifier(random_state=42))])\nsvm_pipeline = Pipeline(steps = [('scale',StandardScaler()),('SVM',SVC(random_state=42))])\nlogreg_pipeline = Pipeline(steps = [('scale',StandardScaler()),('LR',LogisticRegression(random_state=42))])","f6f07f61":"\n\n#cross validation\nrf_cv = cross_val_score(rf_pipeline,X_train_resh,y_train_resh,cv=10,scoring='f1')\nsvm_cv = cross_val_score(svm_pipeline,X_train_resh,y_train_resh,cv=10,scoring='f1')\nlogreg_cv = cross_val_score(logreg_pipeline,X_train_resh,y_train_resh,cv=10,scoring='f1')\n\n","c8c37878":"print('Mean f1 scores:')\nprint('Random Forest mean :',cross_val_score(rf_pipeline,X_train_resh,y_train_resh,cv=10,scoring='f1').mean())\nprint('SVM mean :',cross_val_score(svm_pipeline,X_train_resh,y_train_resh,cv=10,scoring='f1').mean())\nprint('Logistic Regression mean :',cross_val_score(logreg_pipeline,X_train_resh,y_train_resh,cv=10,scoring='f1').mean())","9f33ad4e":"\n\n#fitting the model\nrf_pipeline.fit(X_train_resh,y_train_resh)\nsvm_pipeline.fit(X_train_resh,y_train_resh)\nlogreg_pipeline.fit(X_train_resh,y_train_resh)\n\n","71544a6a":"\n\n#predicting\nrf_pred   =rf_pipeline.predict(X_test)\nsvm_pred  = svm_pipeline.predict(X_test)\nlogreg_pred   = logreg_pipeline.predict(X_test)\n\n","be6df752":"y_pred_final = rf_pred.copy()\nfor i in range(len(rf_pred)):\n    n_ones = rf_pred[i] + svm_pred[i] + logreg_pred[i]\n    if n_ones>1:\n        y_pred_final[i] = 1\n    else:\n        y_pred_final[i] = 0","e97656cd":"\n\ncl_rep = classification_report(y_test, y_pred_final)\nprint(cl_rep)\n\ncl_rep_f1  = confusion_matrix(y_test,y_pred_final)\ncl_rep_f1\n\n","cb5f4494":"# Plotting our results\nimport matplotlib\n\ncolors = [\"lightgray\",\"#0f4c81\",\"#0f4c81\",\"#0f4c81\",\"#0f4c81\",\"#0f4c81\",\"#0f4c81\",\"#0f4c81\"]\ncolormap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)\n\n\nbackground_color = \"#fbfbfb\"\n\nfig = plt.figure(figsize=(10,14)) # create figure\ngs = fig.add_gridspec(4, 2)\ngs.update(wspace=0.1, hspace=0.8)\nax0 = fig.add_subplot(gs[0, :])\nax0.set_facecolor(background_color) # axes background color\n\n# Overall\nsns.heatmap(cl_rep_f1, cmap=colormap,annot=True,fmt=\"d\", linewidths=5,cbar=False,ax=ax0,\n            yticklabels=['Actual Non-Stroke','Actual Stroke'],xticklabels=['Predicted Non-Stroke','Predicted Stroke'],annot_kws={\"fontsize\":12})\n\n\n\nax0.tick_params(axis=u'both', which=u'both',length=0)\nbackground_color = \"#fbfbfb\"\nfig.patch.set_facecolor(background_color) # figure background color\nax0.set_facecolor(background_color) \n\n\nax0.text(0,-0.75,'Ensemble Performance',fontsize=18,fontweight='bold',fontfamily='serif')\n\n\nplt.show()","466b21c9":"Generally we can remove feature of less importance ie with correlation less tha 10% or 5% depeding on data.\n\nBut here all features are having importance.","1d600802":"### Correlation","f16a11e3":"Few features seems to be skewed.\nAlso few features tend to have technically incorrect data.\n\nbut main problem with them appears to be outliers\n\nLets see Boxplots to see outliers","f1b7ca53":"All are numeric atribute except outcome attribute","99b778c0":"### Pairplot","5d791737":"#  Data engineering","80c208ad":"### For more info refer Notebook\nhttps:\/\/www.kaggle.com\/msagmj\/pycaret-for-imbalanced-data","330143e1":"## 2)using Pycaret","8db4513b":"There no null Value","7cbbdbbb":"# Transformations\n\nwe will try different transformation and move on with which one best fits.\n\nReference:\nhttps:\/\/github.com\/krishnaik06\/Types-Of-Trnasformation\/blob\/main\/All%20types%20Of%20Feature%20Transformation.ipynb\nhttps:\/\/medium.com\/@sjacks\/feature-transformation-21282d1a3215\n\nfrom the above article the conclusion we can make is:\n\n Data is often scaled implicitly when standardized. ie if we standardize it will get shifted to normal distribution as well as scaled .","da1e7064":"## 3)using SMOTE and building model on balanced data","b01f3c9b":"Observation:\n\nwhich transformation is suitable for which feature and dropping other columns.\n\n1)Pregnancies - Exponential\n\n2)Glucose - Log\n\n3)DiabetesPedigreeFunction - log\n\n4)Age - Boxcox\n\n5)SkinThickness -square\n\n6)Insulin - Boxcox\n\n7)BloodPressure - Its correct no need of transformation\n\n8)BMI - Boxcox\n\nDropping all other columns\n","d52b7119":"Lets view distributions of all features","f1ca735f":"After removing outliers what we observed is there is few records with wrong info might be indication absense of that info.\nie the few columns cannot have 0 as value so replacing them with mean based on outcome\n\n## Correcting Invalid Data","3ff579af":"# Importing nessesary libraries","36245f6d":"The data still seems to be skewed .","dde74370":"# Model Building\n\nwe can use 3 approaches\n\n## 1)Making models with imbalanced data\n## 2)using Pycaret\n## 3)using SMOTE and building model on balanced data\n\nWe must focus more on different scores based on work of model.\n\nIn this model F1 Score is of more importance.","bf511fcc":"All other records seems to be correct .\n\nSo now we have handled invalid data as well as outliers.\n\nNow lets move towards understanding correlation","ef5fa2e9":"## Removing Outliers","9d976427":"## Correlation","c86b765e":"The data is completely imbalance ie the ration is 1:3 for 1:0 outcome classes.\n","e97163f2":"### Heatmap","a8a3cb65":"using the reult from all models ie creating a ensemble","3faeb2a3":"For more info on how to work with imbalanced data do check out:\n\nhttps:\/\/www.kaggle.com\/msagmj\/different-ways-to-handle-imbalanced-data\n\nhttps:\/\/www.kaggle.com\/msagmj\/pycaret-for-imbalanced-data","085a788f":"Now we will try to see if the data is still skewed","6ae7b9a5":"Seeing so many outliers in the features firstly we must remove them\ngeneraly when data set is large the my approach is\n\nincluding data only between 25-75%\n\nBut here the data is too samll so will consider data between 1-99%","5c078bb2":"## 1)Making models with imbalanced data"}}