{"cell_type":{"e38bccbf":"code","6076d913":"code","fa915e3d":"code","20a5f77e":"code","93815418":"code","fb10ffd5":"code","61dfaaba":"code","f4e8e8f7":"code","91ee951a":"code","33ace0fe":"code","2b5c6944":"code","a5a1b76d":"code","1388f8c4":"code","1127113e":"code","bd31843b":"code","8d2df8cb":"markdown","cb0769c7":"markdown"},"source":{"e38bccbf":"#Required Libraries\nimport numpy as np  \nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix","6076d913":"#Read dataset\ndata = pd.read_csv('\/kaggle\/input\/diabetes-dataset\/diabetes2.csv')","fa915e3d":"data.head()","20a5f77e":"data.shape","93815418":"data.Outcome.value_counts()","fb10ffd5":"#Grab features and label from dataframe\nx = data[['Glucose', 'Age']].values\n# x = data[['Glucose', 'Age', 'Pregnancies', 'BloodPressure', 'SkinThickness', 'Insulin','BMI', 'DiabetesPedigreeFunction']].values\ny = data['Outcome'].values\n\nprint(x.shape)\nprint(y.shape)","61dfaaba":"#Visualization\nplt.figure(figsize=(10, 6))\nplt.scatter(x[y == 0][:, 0], x[y == 0][:, 1], color='b', label='0')\nplt.scatter(x[y == 1][:, 0], x[y == 1][:, 1], color='r', label='1')\nplt.xlabel('Glucose')\nplt.ylabel('Age')\nplt.legend()","f4e8e8f7":"class LogisticRegression:\n    \n    def __init__(self, l_rate=0.001, iterations=1000):  #assign values for hyper-parameters\n        self.l_rate = l_rate  #learning rate\n        self.iterations = iterations  #number of iterations\n\n    def fit(self, x, y):  #Fit the training data using Gradient Descent\n        self.losses = []  # An empty list to store the error in each iteration\n        self.theta = np.zeros((1 + x.shape[1]))  #intitalization,,,Array of zeros \n        n = x.shape[0]  #number of training examples 768\n        \n        for i in range(self.iterations):\n            #Step1\n            y_pred = self.theta[0] + np.dot(x, self.theta[1:])  # hypothesis h(x)\n            z = y_pred\n            #Step2\n            g_z =  1 \/ (1 + np.e**(-z))  #map predicted values to probabilities between 0 & 1      \n            \n            #Step3\n            cost = (-y * np.log(g_z) - (1 - y) * np.log(1 - g_z))\/ n #cost function\n            self.losses.append(cost) #Tracking losses\n            \n            #Step4\n            d_theta1 = (1\/n) * np.dot(x.T, (g_z - y)) #Derivatives of theta[1:]\n            d_theta0 = (1\/n) * np.sum(g_z - y)  #Derivatives of theta[0]\n            \n            #Step5\n            self.theta[1:] = self.theta[1:] - self.l_rate * d_theta1  #upadting values of thetas using Gradient descent\n            self.theta[0] = self.theta[0] - self.l_rate * d_theta0  #upadting the value of theta 0 using Gradient descent     \n        return self\n    \n    \n    def predict(self, x):  #Predicts the value after the model has been trained.\n        y_pred = self.theta[0] + np.dot(x, self.theta[1:]) \n        z = y_pred\n        g_z = 1 \/ (1 + np.e**(-z))\n        return [1 if i > 0.5 else 0 for i in g_z] #Threshold  \n   ","91ee951a":"#features scaling using z-score\ndef scale(x):\n    x_scaled = x - np.mean(x, axis=0)\n    x_scaled = x_scaled \/ np.std(x_scaled, axis=0)\n    return x_scaled","33ace0fe":"x_sd= scale(x)  #call the function scale()\nmodel = LogisticRegression()\nmodel.fit(x_sd, y)","2b5c6944":"# print theta 0, 1, 2\nprint(\"theta_0= \", model.theta[0])\nprint(\"theta_1= \", model.theta[1])\nprint(\"theta_2= \", model.theta[2])","a5a1b76d":"y_pred = model.predict(x_sd)","1388f8c4":"#compute confusion matrix\nCM = confusion_matrix(y_pred, y, labels=[1,0])\nprint('Confusion Matrix is : \\n', CM)","1127113e":"TP=CM[0][0]\nFP=CM[0][1]\nFN=CM[1][0]\nTN=CM[1][1]","bd31843b":"ACC = (TP+TN)\/(TP+TN+FP+FN)\nprint('Accuracy is : \\n', ACC)\nprint('--------------------------------')\nRec = TP\/(TP+FN)\nprint('Recall is : \\n', Rec)\nprint('--------------------------------')\nPrec = TP\/(TP+FP)\nprint('Precsion is : \\n', Prec)\nprint('--------------------------------')\nF1 = 2 * ((Prec * Rec)\/(Prec + Rec))\nprint('F1 score is : \\n', F1)\nprint('--------------------------------')","8d2df8cb":"![threshold.png](attachment:threshold.png)","cb0769c7":"![logistic.png](attachment:logistic.png)"}}