{"cell_type":{"16769d0a":"code","9b0a77ad":"code","ff71d437":"code","7c5b8838":"code","4ade365b":"code","d27c8e2b":"code","2b2bd570":"code","92c8f716":"code","80dfb9b1":"code","dda5ff11":"code","f3edc06b":"code","eb478f12":"code","c2a3ebfc":"code","4cabb802":"code","33742b68":"code","05758945":"code","9ac3b367":"code","d7157717":"code","e18b686d":"code","58eb2ae6":"code","ef4482e4":"code","ac42ac5f":"code","e25dd877":"code","435b0027":"code","0744f458":"code","0f02f89f":"code","735a2fc4":"code","2a51a787":"code","1d15a9b3":"code","db53dcd0":"code","a9c36029":"code","33efee9a":"code","08064f03":"code","3549ae6d":"markdown","ef2021de":"markdown","87783f8c":"markdown","f8c99daa":"markdown","4c56eb64":"markdown","c213bcb0":"markdown","d9a6619b":"markdown","e34ac32c":"markdown","99b3975d":"markdown","8cf1cf61":"markdown","c74be5a0":"markdown","bb50a6ed":"markdown","59f2b347":"markdown","55692d35":"markdown","bfaba42e":"markdown","2b822c69":"markdown","a222bfcc":"markdown","89137f74":"markdown","48c1b2d3":"markdown","ad0ea042":"markdown","97c3b93b":"markdown"},"source":{"16769d0a":"# First, we'll import pandas, a data processing and CSV file I\/O library\nimport pandas as pd\n\n# We'll also import seaborn, a Python graphing library\nimport warnings # current version of seaborn generates a bunch of warnings that we'll ignore\nwarnings.filterwarnings(\"ignore\")\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set(style=\"white\", color_codes=True)\n\n# Next, we'll load the Iris flower dataset, which is in the \"..\/input\/\" directory\niris = pd.read_csv(\"..\/input\/iris\/Iris.csv\") # the iris dataset is now a Pandas DataFrame\n\n# Let's see what's in the iris data - Jupyter notebooks print the result of the last thing you do\niris.head()\n\n# Press shift+enter to execute this cell","9b0a77ad":"# Let's see how many examples we have of each species\niris[\"Species\"].value_counts()","ff71d437":"#We use a color gradient to display the data values.\niris.head(10).style.background_gradient(subset=['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm'], cmap='BuGn')","7c5b8838":"#We can also display the data values with bars.\niris.head().style.bar(color='green', subset=['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm'])","4ade365b":"from pandas_profiling import ProfileReport\nprof = ProfileReport(iris)\nprof.to_file(output_file='report.html')","d27c8e2b":"ds = pd.read_csv(\"..\/input\/ds-popularity\/temporal.csv\")\nds.head(10) #View first 10 data rows","2b2bd570":"plt.plot(ds['Mes'], ds['data science'], label='data science')\nplt.plot(ds['Mes'], ds['machine learning'], label='machine learning')\nplt.plot(ds['Mes'], ds['deep learning'], label='deep learning')\nplt.xlabel('Date')\nplt.ylabel('Popularity')\nplt.title('Popularity of AI terms by date')\nplt.grid(True)\nplt.legend()","92c8f716":"#We can draw the graph with different styles for the points of each variable:\nplt.plot(ds['Mes'], ds['data science'], 'r-')\nplt.plot(ds['Mes'], ds['data science']*2, 'bs')\nplt.plot(ds['Mes'], ds['data science']*3, 'g^')","80dfb9b1":"plt.scatter(ds['data science'], ds['machine learning'], ds['deep learning'])","dda5ff11":"plt.bar(ds['Mes'], ds['machine learning'], width=20)","f3edc06b":"plt.hist(ds['deep learning'], bins=15)","eb478f12":"#We can add a text to the graphic, we indicate the position of the text in the same units that we see in the graphic. In the text, we can even add special characters following the TeX language\n#We can also add markers that point to a particular point on the graph.\nplt.plot(ds['Mes'], ds['data science'], label='data science')\nplt.plot(ds['Mes'], ds['machine learning'], label='machine learning')\nplt.plot(ds['Mes'], ds['deep learning'], label='deep learning')\nplt.xlabel('Date')\nplt.ylabel('Popularity')\nplt.title('Popularity of AI terms by date')\nplt.grid(True)\nplt.text(x='2010-01-01', y=80, s=r'$\\lambda=1, r^2=0.8$') #Coordinates use the same units as the graph\nplt.annotate('Notice the change?', xy=('2014-01-01', 30), xytext=('2006-01-01', 50), arrowprops={'facecolor':'red', 'shrink':0.05})","c2a3ebfc":"sns.heatmap(ds.corr(), annot=True, fmt='.2f')","4cabb802":"# We can also use the seaborn library to make a similar plot\n# A seaborn jointplot shows bivariate scatterplots and univariate histograms in the same figure\nsns.jointplot(x=\"SepalLengthCm\", y=\"SepalWidthCm\", data=iris, size=5)","33742b68":"# One piece of information missing in the plots above is what species each plant is\n# We'll use seaborn's FacetGrid to color the scatterplot by species\nsns.FacetGrid(iris, hue=\"Species\", size=5) \\\n   .map(plt.scatter, \"SepalLengthCm\", \"SepalWidthCm\") \\\n   .add_legend()","05758945":"# We can look at an individual feature in Seaborn through a boxplot\nsns.boxplot(x=\"Species\", y=\"PetalLengthCm\", data=iris)","9ac3b367":"# One way we can extend this plot is adding a layer of individual points on top of\n# it through Seaborn's striplot\n# \n# We'll use jitter=True so that all the points don't fall in single vertical lines\n# above the species\n#\n# Saving the resulting axes as ax each time causes the resulting plot to be shown\n# on top of the previous axes\nax = sns.boxplot(x=\"Species\", y=\"PetalLengthCm\", data=iris)\nax = sns.stripplot(x=\"Species\", y=\"PetalLengthCm\", data=iris, jitter=True, edgecolor=\"gray\")","d7157717":"# A violin plot combines the benefits of the previous two plots and simplifies them\n# Denser regions of the data are fatter, and sparser thiner in a violin plot\nsns.violinplot(x=\"Species\", y=\"PetalLengthCm\", data=iris, size=6)","e18b686d":"# A final seaborn plot useful for looking at univariate relations is the kdeplot,\n# which creates and visualizes a kernel density estimate of the underlying feature\nsns.FacetGrid(iris, hue=\"Species\", size=6) \\\n   .map(sns.kdeplot, \"PetalLengthCm\") \\\n   .add_legend()","58eb2ae6":"# Another useful seaborn plot is the pairplot, which shows the bivariate relation\n# between each pair of features\n# \n# From the pairplot, we'll see that the Iris-setosa species is separataed from the other\n# two across all feature combinations\nsns.pairplot(iris.drop(\"Id\", axis=1), hue=\"Species\", size=3)","ef4482e4":"# The diagonal elements in a pairplot show the histogram by default\n# We can update these elements to show other things, such as a kde\nsns.pairplot(iris.drop(\"Id\", axis=1), hue=\"Species\", size=3, diag_kind=\"kde\")","ac42ac5f":"# The first way we can plot things is using the .plot extension from Pandas dataframes\n# We'll use this to make a scatterplot of the Iris features.\niris.plot(kind=\"scatter\", x=\"SepalLengthCm\", y=\"SepalWidthCm\")","e25dd877":"# Now that we've covered seaborn, let's go back to some of the ones we can make with Pandas\n# We can quickly make a boxplot with Pandas on each feature split out by species\niris.drop(\"Id\", axis=1).boxplot(by=\"Species\", figsize=(12, 6))","435b0027":"# One cool more sophisticated technique pandas has available is called Andrews Curves\n# Andrews Curves involve using attributes of samples as coefficients for Fourier series\n# and then plotting these\nfrom pandas.plotting import andrews_curves\nandrews_curves(iris.drop(\"Id\", axis=1), \"Species\")","0744f458":"# Another multivariate visualization technique pandas has is parallel_coordinates\n# Parallel coordinates plots each feature on a separate column & then draws lines\n# connecting the features for each data sample\nfrom pandas.plotting import parallel_coordinates\nparallel_coordinates(iris.drop(\"Id\", axis=1), \"Species\")","0f02f89f":"# A final multivariate visualization technique pandas has is radviz\n# Which puts each feature as a point on a 2D plane, and then simulates\n# having each sample attached to those points through a spring weighted\n# by the relative value for that feature\nfrom pandas.plotting import radviz\nradviz(iris.drop(\"Id\", axis=1), \"Species\")","735a2fc4":"from collections import OrderedDict\nfrom io import StringIO\nfrom math import log, sqrt\n\nimport numpy as np\n\nfrom bokeh.plotting import figure, output_file, show\n\nantibiotics = \"\"\"\nbacteria,                        penicillin, streptomycin, neomycin, gram\nMycobacterium tuberculosis,      800,        5,            2,        negative\nSalmonella schottmuelleri,       10,         0.8,          0.09,     negative\nProteus vulgaris,                3,          0.1,          0.1,      negative\nKlebsiella pneumoniae,           850,        1.2,          1,        negative\nBrucella abortus,                1,          2,            0.02,     negative\nPseudomonas aeruginosa,          850,        2,            0.4,      negative\nEscherichia coli,                100,        0.4,          0.1,      negative\nSalmonella (Eberthella) typhosa, 1,          0.4,          0.008,    negative\nAerobacter aerogenes,            870,        1,            1.6,      negative\nBrucella antracis,               0.001,      0.01,         0.007,    positive\nStreptococcus fecalis,           1,          1,            0.1,      positive\nStaphylococcus aureus,           0.03,       0.03,         0.001,    positive\nStaphylococcus albus,            0.007,      0.1,          0.001,    positive\nStreptococcus hemolyticus,       0.001,      14,           10,       positive\nStreptococcus viridans,          0.005,      10,           40,       positive\nDiplococcus pneumoniae,          0.005,      11,           10,       positive\n\"\"\"\n\ndrug_color = OrderedDict([\n    (\"Penicillin\",   \"#0d3362\"),\n    (\"Streptomycin\", \"#c64737\"),\n    (\"Neomycin\",     \"black\"  ),\n])\n\ngram_color = OrderedDict([\n    (\"negative\", \"#e69584\"),\n    (\"positive\", \"#aeaeb8\"),\n])\n\ndf = pd.read_csv(StringIO(antibiotics),\n                 skiprows=1,\n                 skipinitialspace=True,\n                 engine='python')\n\nwidth = 800\nheight = 800\ninner_radius = 90\nouter_radius = 300 - 10\n\nminr = sqrt(log(.001 * 1E4))\nmaxr = sqrt(log(1000 * 1E4))\na = (outer_radius - inner_radius) \/ (minr - maxr)\nb = inner_radius - a * maxr\n\ndef rad(mic):\n    return a * np.sqrt(np.log(mic * 1E4)) + b\n\nbig_angle = 2.0 * np.pi \/ (len(df) + 1)\nsmall_angle = big_angle \/ 7\n\np = figure(plot_width=width, plot_height=height, title=\"\",\n    x_axis_type=None, y_axis_type=None,\n    x_range=(-420, 420), y_range=(-420, 420),\n    min_border=0, outline_line_color=\"black\",\n    background_fill_color=\"#f0e1d2\")\n\np.xgrid.grid_line_color = None\np.ygrid.grid_line_color = None\n\n# annular wedges\nangles = np.pi\/2 - big_angle\/2 - df.index.to_series()*big_angle\ncolors = [gram_color[gram] for gram in df.gram]\np.annular_wedge(\n    0, 0, inner_radius, outer_radius, -big_angle+angles, angles, color=colors,\n)\n\n# small wedges\np.annular_wedge(0, 0, inner_radius, rad(df.penicillin),\n                -big_angle+angles+5*small_angle, -big_angle+angles+6*small_angle,\n                color=drug_color['Penicillin'])\np.annular_wedge(0, 0, inner_radius, rad(df.streptomycin),\n                -big_angle+angles+3*small_angle, -big_angle+angles+4*small_angle,\n                color=drug_color['Streptomycin'])\np.annular_wedge(0, 0, inner_radius, rad(df.neomycin),\n                -big_angle+angles+1*small_angle, -big_angle+angles+2*small_angle,\n                color=drug_color['Neomycin'])\n\n# circular axes and lables\nlabels = np.power(10.0, np.arange(-3, 4))\nradii = a * np.sqrt(np.log(labels * 1E4)) + b\np.circle(0, 0, radius=radii, fill_color=None, line_color=\"white\")\np.text(0, radii[:-1], [str(r) for r in labels[:-1]],\n       text_font_size=\"11px\", text_align=\"center\", text_baseline=\"middle\")\n\n# radial axes\np.annular_wedge(0, 0, inner_radius-10, outer_radius+10,\n                -big_angle+angles, -big_angle+angles, color=\"black\")\n\n# bacteria labels\nxr = radii[0]*np.cos(np.array(-big_angle\/2 + angles))\nyr = radii[0]*np.sin(np.array(-big_angle\/2 + angles))\nlabel_angle=np.array(-big_angle\/2+angles)\nlabel_angle[label_angle < -np.pi\/2] += np.pi # easier to read labels on the left side\np.text(xr, yr, df.bacteria, angle=label_angle,\n       text_font_size=\"12px\", text_align=\"center\", text_baseline=\"middle\")\n\n# OK, these hand drawn legends are pretty clunky, will be improved in future release\np.circle([-40, -40], [-370, -390], color=list(gram_color.values()), radius=5)\np.text([-30, -30], [-370, -390], text=[\"Gram-\" + gr for gr in gram_color.keys()],\n       text_font_size=\"9px\", text_align=\"left\", text_baseline=\"middle\")\n\np.rect([-40, -40, -40], [18, 0, -18], width=30, height=13,\n       color=list(drug_color.values()))\np.text([-15, -15, -15], [18, 0, -18], text=list(drug_color),\n       text_font_size=\"12px\", text_align=\"left\", text_baseline=\"middle\")\n\noutput_file(\"burtin.html\", title=\"burtin.py example\")\n\nshow(p)","2a51a787":"import colorcet as cc\nfrom numpy import linspace\nfrom scipy.stats.kde import gaussian_kde\n\nfrom bokeh.io import output_file, show\nfrom bokeh.models import ColumnDataSource, FixedTicker, PrintfTickFormatter\nfrom bokeh.plotting import figure\nfrom bokeh.sampledata.perceptions import probly\n\noutput_file(\"ridgeplot.html\")\n\ndef ridge(category, data, scale=20):\n    return list(zip([category]*len(data), scale*data))\n\ncats = list(reversed(probly.keys()))\n\npalette = [cc.rainbow[i*15] for i in range(17)]\n\nx = linspace(-20,110, 500)\n\nsource = ColumnDataSource(data=dict(x=x))\n\np = figure(y_range=cats, plot_width=900, x_range=(-5, 105), toolbar_location=None)\n\nfor i, cat in enumerate(reversed(cats)):\n    pdf = gaussian_kde(probly[cat])\n    y = ridge(cat, pdf(x))\n    source.add(y, cat)\n    p.patch('x', cat, color=palette[i], alpha=0.6, line_color=\"black\", source=source)\n\np.outline_line_color = None\np.background_fill_color = \"#efefef\"\n\np.xaxis.ticker = FixedTicker(ticks=list(range(0, 101, 10)))\np.xaxis.formatter = PrintfTickFormatter(format=\"%d%%\")\n\np.ygrid.grid_line_color = None\np.xgrid.grid_line_color = \"#dddddd\"\np.xgrid.ticker = p.xaxis.ticker\n\np.axis.minor_tick_line_color = None\np.axis.major_tick_line_color = None\np.axis.axis_line_color = None\n\np.y_range.range_padding = 0.12\n\nshow(p)","1d15a9b3":"import folium\nm1 = folium.Map(location=[41.38, 2.17], tiles='openstreetmap', zoom_start=18)\nm1.save('map1.html')","db53dcd0":"#We can add markers to the map:\nm2 = folium.Map(location=[41.38, 2.17], tiles='openstreetmap', zoom_start=16)\nfolium.Marker([41.38, 2.176], popup='<i>You can use whatever HTML code you want<\/i>', tooltip='click here').add_to(m2)\nfolium.Marker([41.38, 2.174], popup='<b>You can use whatever HTML code you want<\/b>', tooltip='dont click here').add_to(m2)\nm2.save('map2.html')","a9c36029":"counties1= pd.read_json(\"..\/input\/fipscounties\/geojson-counties-fips1.json\")\ncounties = counties1.to_json()\nsvi = pd.read_csv(\"..\/input\/svidata\/mod_laucntycur14_feb.csv\",\n                   dtype={\"fips\": str})","33efee9a":"from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly as py\nimport plotly_express as px\nimport plotly.graph_objs as go\ninit_notebook_mode(connected=True)    \n\nfig = px.choropleth(svi, geojson=counties, locations='fips', color='unemp',\n                           color_continuous_scale=\"Inferno\",\n                           range_color=(0, 12),\n                           scope=\"usa\",\n                           hover_data=[\"county_state\"],\n                           labels={'unemp':'Unemployment Rate'}\n                          )\nfig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\npy.offline.iplot(fig)","08064f03":"import networkx as nx\nimport matplotlib.animation as animation\nimport matplotlib.pyplot as plt\nimport random\n# Graph initialization\nG = nx.Graph()\nG.add_nodes_from([1, 2, 3, 4, 5, 6, 7, 8, 9])\nG.add_edges_from([(1,2), (3,4), (2,5), (4,5), (6,7), (8,9), (4,7), (1,7), (3,5), (2,7), (5,8), (2,9), (5,7)])\n#draw network\ncolors = ['r', 'b', 'g', 'y', 'm']\nnx.draw_circular(G, node_color=[random.choice(colors) for j in range(9)])","3549ae6d":"# Resources\n* [How to choose a python plotting library](https:\/\/towardsdatascience.com\/data-visualization-101-how-to-choose-a-python-plotting-library-853460a08a8a) \n* [How to choose right chart](https:\/\/towardsdatascience.com\/data-visualization-how-to-choose-the-right-chart-part-1-d4c550085ea7) \n* [Information is Beautiful](https:\/\/informationisbeautiful.net\/)\n* [Data Visualization Catalogue](https:\/\/datavizcatalogue.com\/)\n* [Matplotlib Cheat Sheet](https:\/\/towardsdatascience.com\/matplotlib-cheat-sheet-f441c43971c4)","ef2021de":"# Bar chart","87783f8c":"# Plotly\n[Plotly](https:\/\/plotly.com\/python\/)'s Python graphing library makes interactive, publication-quality graphs. Examples of how to make line plots, scatter plots, area charts, bar charts, error bars, box plots, histograms, heatmaps, subplots, multiple-axes, polar charts, and bubble charts.\nPlotly.py is free and open source and you can view the source, report issues or contribute on GitHub.\n","f8c99daa":"# Folium\n[Folium](https:\/\/python-visualization.github.io\/folium\/) is a library that allows us to draw maps, markers and we can also draw our data on them. Folium lets us choose the map supplier, this determines the style and quality of the map. In this article, for simplicity, we\u2019re only going to look at OpenStreetMap as a map provider.\nWorking with maps is quite complex and deserves its own article. Here we\u2019re just going to look at the basics and draw a couple of maps with the data we have.\nLet\u2019s begin with the basics, we\u2019ll draw a simple map with nothing on it.","4c56eb64":"# Bokeh\n[Bokeh](https:\/\/bokeh.org\/) is a library that allows you to generate interactive graphics. We can export them to an HTML document that we can share with anyone who has a web browser.\nIt is a very useful library when we are interested in looking for things in the graphics and we want to be able to zoom in and move around the graphic. Or when we want to share them and give the possibility to explore the data to another person.","c213bcb0":"# **Python Data Visualizations**\n\n**Why**\n> Data is just a story told in numbers.\n\n**How to choose a chart type**\n1. What\u2019s the story your data is trying to deliver?\n2. Who will you present your results to?\n3. What is your data looks like? (size, relationships, data types, etc.)","d9a6619b":"# Histogram","e34ac32c":"# Heatmap\nOne of the most popular graphics provided by Seaborn is the heatmap. It is very common to use it to show all the correlations between variables in a dataset","99b3975d":"# Scatterplot","8cf1cf61":"# Gallery of examples\nIn this link https:\/\/docs.bokeh.org\/en\/latest\/docs\/gallery.html you can see examples of everything that can be done with Bokeh.","c74be5a0":"# Matplotlib\n[Matplotlib](http:\/\/matplotlib.org\/) is the most basic library for visualizing data graphically. It includes many of the graphs that we can think of. Just because it is basic does not mean that it is not powerful, many of the other data visualization libraries we are going to talk about are based on it.\nMatplotlib\u2019s charts are made up of two main components, the axes (the lines that delimit the area of the chart) and the figure (where we draw the axes, titles and things that","bb50a6ed":"# Seaborn\nSeaborn is a library based on Matplotlib. Basically what it gives us are nicer graphics and functions to make complex types of graphics with just one line of code.","59f2b347":"# Further Examples\nhttps:\/\/pandas.pydata.org\/pandas-docs\/stable\/user_guide\/visualization.html","55692d35":"## This notebook demos Python Data Visualizations\n\nThis Python 3 environment comes with many helpful analytics libraries installed. It is defined by the [kaggle\/python docker image](https:\/\/github.com\/kaggle\/docker-python)\n\nThis is inspired by https:\/\/www.kaggle.com\/benhamner\/python-data-visualizations\n\n**The Data Visualization Python Libraries**\n\n**Static plotting libraries**\n* [Pandas](http:\/\/pandas.pydata.org\/)\n* [Matplotlib](http:\/\/matplotlib.org\/)\n* [Seaborn](http:\/\/stanford.edu\/~mwaskom\/software\/seaborn\/)\n* [NetworkX](https:\/\/networkx.github.io\/)\n* [Plotnine](https:\/\/plotnine.readthedocs.io\/en\/stable\/) (Not included)\n\n**Dynamic plotting libraries**\n* [Bokeh](https:\/\/docs.bokeh.org\/en\/latest\/index.html)\n* [Plotly](https:\/\/plotly.com\/python\/)\n* [Folium](https:\/\/python-visualization.github.io\/folium\/)\n* [Altair](https:\/\/altair-viz.github.io\/) (Not included)\n* [Gleam](https:\/\/github.com\/dgrtwo\/gleam) (Not included)\n\n\n","bfaba42e":"# Chart selection tips\nWhenever you decide to create some data visualization, use these best practices to make it more straightforward and effective.\n* If you have categorical data, use a bar chart if you have more than 5 categories or a pie chart otherwise.\n* If you have nominal data, use bar charts or histograms if your data is discrete, or line\/ area charts if it is continuous.\n* If you want to show the relationship between values in your dataset, use a scatter plot, bubble chart, or line charts.\n* If you want to compare values, use a pie chart \u2014 for relative comparison \u2014 or bar charts \u2014 for precise comparison.\n* If you want to compare volumes, use an area chart or a bubble chart.\n* If you want to show trends and patterns in your data, use a line chart, bar chart, or scatter plot.\n\n\n**Top 7 used charts type and when to use each of them.**\n\n**Bar Chart**\n\nWhen to use:\n* Comparing parts of a bigger set of data, highlighting different categories, or showing change over time.\n* Have long categories label \u2014 it offers more space.\n* If you want to illustrate both positive and negative values in the dataset.\n\nWhen to avoid:\n* If you\u2019re using multiple data points.\n* If you have many categories, avoid overloading your graph. Your graph shouldn\u2019t have more than 10 bars.\n\n\n**Pie Chart**\n\nWhen to use:\n* When you show relative proportions and percentages of a whole dataset.\n* Best used with small datasets \u2014 also applies to donut charts.\n* When comparing the effect of ONE factor on different categories.\n* If you have up to 6 categories.\n* When your data is nomial and not ordinal.\n\nWhen to avoid:\n* If you have a big dataset.\n* If you want to make a precise or absolute comparison between values.\n\n\n**Line Chart**\n\nWhen to use:\n* If you have a continuous dataset that changes over time.\n* If your dataset is too big for a bar chart.\n* If you want to display multiple series for the same timeline.\n* If you want to visualize trends instead of exact values.\n\nWhen to avoid:\n* Line charts work better with bigger datasets, so, if you have a small one, use a bar chart instead.\n\n\n**Scatter Plot**\n\nWhen to use:\n* To show correlation and clustering in big datasets.\n* If your dataset contains points that have a pair of values.\n* If the order of points in the dataset is not essential.\n\nWhen to avoid:\n* If you have a small dataset.\n* If the values in your dataset are not correlated.\n\n\n**Area Chart**\n\nWhen to use:\n* If you want to show part-to-whole relations.\n* If you want to portray the volume of your data and not just the relation to time.\n\nWhen to avoid:\n* It can\u2019t be used with discrete data.\n\n\n**Bubble Chart**\n\nWhen to use:\n* If you want to compare independent values.\n* If you want to show distribution or relation.\n\nWhen to avoid:\n* If you have a small dataset.\n\n\n**Combined Chart**\n\nWhen to use:\n* If you want to compare values with different measurements.\n* If the values are different in range.\n\nWhen to avoid:\n* If you want to display more than 2~3 types of graphs. In that case, it\u2019s better to have separate graphs to make it easier to read and understand.\n\n\n\n\n# How to choose a python plotting library\n**Static vs. dynamic plotting**\n\nWhen plotting any information, we have options to choose from; we can either generate a static plot or a dynamic one.\n\n* **Static plotting**\n\nStatic plots contain graphs displaying constant relations between two or more variables. That is, once the plot is created, it can\u2019t be changed by the user. In static plots, the users can\u2019t change any aspects of the plot.\n\n* **Dynamic plotting**\n\nDynamic plots \u2014 also known as interactive plots \u2014 are used when the developer\/ designer wants the users to interact with the plot, changing some aspects of it and getting more familiar with the data used to create it.","2b822c69":"# Networkx\n[NetworkX](https:\/\/networkx.org\/) is a Python package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks.","a222bfcc":"# Summary\n\n\nI encourage you to run through these examples yourself, changing them and seeing what happens. You can try applying these plots to a your datasets and incorprating them into your own notebooks!\n\nAlways aim for simple visualization than complex ones. The goal of visualizing data is to make it easier to understand and read. So, avoid overloading and cluttering your graphs. Having multiple simple graphs is always better than one elaborate graph.\n\nBefore you choose what chart type to use, you need to get to know your data better, the story behind it, and your target audience\/media. Whenever you try to create a visualization, chose simple colors and fonts.\nAlways aim for simple visualization than complex ones. The goal of visualizing data is to make it easier to understand and read. So, avoid overloading and cluttering your graphs. Having multiple simple graphs is always better than one elaborate graph.\n\n","89137f74":"# Gallery of examples\nhttps:\/\/seaborn.pydata.org\/examples\/index.html","48c1b2d3":"# Pandas ","ad0ea042":"# Gallery of examples\nIn this link: https:\/\/matplotlib.org\/gallery\/index.html we can see examples of all types of graphics that can be done with Matplotlib.","97c3b93b":"# **Exploratory Data Analysis**\n\n[Exploratory data analysis (EDA)](https:\/\/www.ibm.com\/cloud\/learn\/exploratory-data-analysis) is used by data scientists to analyze and investigate data sets and summarize their main characteristics, often employing data visualization methods. It helps determine how best to manipulate data sources to get the answers you need, making it easier for data scientists to discover patterns, spot anomalies, test a hypothesis, or check assumptions.\n\nEDA is primarily used to see what data can reveal beyond the formal modeling or hypothesis testing task and provides a provides a better understanding of data set variables and the relationships between them. It can also help determine if the statistical techniques you are considering for data analysis are appropriate. Originally developed by American mathematician John Tukey in the 1970s, EDA techniques continue to be a widely used method in the data discovery process today.\n\n# Pandas Profiling"}}