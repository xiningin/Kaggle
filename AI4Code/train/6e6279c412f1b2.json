{"cell_type":{"12974979":"code","51943e03":"code","30bacd78":"code","57a2ac44":"code","fa490135":"code","d9c012a2":"code","fdc7b22d":"code","1f4ca28c":"code","5e64828a":"code","b1e5a9dd":"code","020a0dc6":"markdown","011c5f50":"markdown","78c49ab0":"markdown","ee50b315":"markdown"},"source":{"12974979":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","51943e03":"mel_path = '..\/input\/melbourne-housing-snapshot\/melb_data.csv'\ndataframe = pd.read_csv(mel_path)\n","30bacd78":"df = dataframe\ny = df.Price\nprint(y)\n","57a2ac44":"print(df.columns)","fa490135":"print(df.Rooms)","d9c012a2":"features = ['Rooms', 'Bathroom', 'Landsize', 'Lattitude', 'Longtitude']\nx = df[features]","fdc7b22d":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1)","1f4ca28c":"from sklearn.linear_model import LinearRegression as linear\nreg = linear()\nreg.fit(x_train, y_train)","5e64828a":"x_pred = reg.predict(x_test)","b1e5a9dd":"from sklearn.metrics import mean_absolute_error\nerror = mean_absolute_error(x_pred, y_test)\nprint(error)","020a0dc6":"Below we set df = dataframe so it is easier to call the df object\n<br \/>\nThe dataframe we have created is a pandas object\n<br \/>\nAll you need to know about objects is that we can access certain aspects with df.aspect or df[aspect]\n<br \/>\nBelow we define y as df.Price so basically here we tell the program price is what we want to predict","011c5f50":"You can see that the dataframe contains categories ranging from lattitude to number of rooms\n<br \/>\nCurrently we sadly can only use categories that use int or float values (numbers), later we will learn how to convert Strings (words) into useable data. Right now, as a String, most Categorical (word values) data can not be processed by the model\n<br \/>\nTo find out the value type write the code segment below and look at the end where it writes dtpe: \n<br \/>\nIn this example it says the dtype is int64 which is a type of integer (with 64 bits)","78c49ab0":"When we predict something, we need information to help formulate our prediction\n<br \/>\nWith that said, below we print df.columns to print out the different categories we can choose from","ee50b315":"Summary of Steps:\n1. Load data into dataframe\n2. Pick catagory you want to predict (y)\n3. Pick features you want to use to predict (x)\n4. Split data using imported method into train and test\n5. Import model and train on training data\n6. Predict using x testing data and compare with y test data (validation)"}}