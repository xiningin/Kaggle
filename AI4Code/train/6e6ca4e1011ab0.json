{"cell_type":{"e0569620":"code","d1bf9ab3":"code","b2373ffd":"code","f24bf856":"code","11f07fe6":"code","6da153e3":"code","273caefe":"code","e547fd50":"code","80d94672":"code","d0cc9340":"code","db1ae897":"code","a35d4093":"code","c9f435c9":"markdown","608cb1a9":"markdown","893e946f":"markdown"},"source":{"e0569620":"!ls \/kaggle\/input #\u633a\u597d\u7684\uff0c\u80fd\u5206\u79bb\u6570\u636e\u548c\u4ee3\u7801\n!pip install ..\/input\/mmcvwhl\/addict-2.2.1-py3-none-any.whl\n!pip install ..\/input\/mmdetection20513\/mmcv-0.5.1-cp37-cp37m-linux_x86_64.whl\n!pip install ..\/input\/mmdetection20513\/terminal-0.4.0-py3-none-any.whl\n!pip install ..\/input\/mmdetection20513\/terminaltables-3.1.0-py3-none-any.whl\n\n!cp -r ..\/input\/mmdetection20513\/mmdetection\/mmdetection .\n%cd mmdetection\n!cp -r ..\/..\/input\/mmdetection20513\/cocoapi\/cocoapi .\n%cd cocoapi\/PythonAPI\n!make\n!make install\n!python setup.py install\nimport pycocotools\n%cd ..\/..\n!pip install -v -e .\n%cd ..\/\nimport sys\nsys.path.append('mmdetection') # To find local version","d1bf9ab3":"from mmdet.apis import init_detector, inference_detector, show_result_pyplot\nimport mmcv\nfrom mmcv import Config\nfrom mmdet.models import build_detector\nfrom mmcv.runner import load_checkpoint\nfrom mmcv.parallel import MMDataParallel\nfrom mmdet.apis import single_gpu_test\nfrom mmdet.datasets import build_dataloader, build_dataset\n\nimport pandas as pd\nimport os\nimport json\n\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport torch","b2373ffd":"!ls \n# !python mmdetection\/demo\/image_demo.py \n# \u62a5\u9519image_demo.py: error: the following arguments are required: img, config, checkpoint\n\n\nconfig = 'mmdetection\/configs\/faster_rcnn\/faster_rcnn_r50_fpn_1x_coco.py'\n\n# mm-faster\u4e0d\u6b62\u6709faster rcnn\u7684\u6743\u91cd\uff0c\u8fd8\u6709\u522b\u7684\u6743\u91cd\ncheckpoint = '\/kaggle\/input\/mm-faster\/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\nmodel = init_detector(config, checkpoint, device='cuda:0')\n# model = init_detector(config, checkpoint, device='cpu')","f24bf856":"img = 'mmdetection\/demo\/demo.jpg'\nresult = inference_detector(model, img)\nshow_result_pyplot(model, img, result, score_thr=0.3)\n","11f07fe6":"albu_train_transforms = [\n    dict(\n        type='HorizontalFlip',\n        p=0.5),\n    dict(\n        type='VerticalFlip',\n        p=0.5),\n\n    dict(\n        type='ShiftScaleRotate',\n        shift_limit=0.0625,\n        scale_limit=0.0,\n        rotate_limit=180,\n        interpolation=1,\n        p=0.5),\n        # p='abcde'),#\u6545\u610f\u5199\u9519\uff0c\u770b\u770b\u662f\u5426\u771f\u7684\u8003\u8651\u4e86\u8fd9\u6bb5\u4ee3\u7801 #\u6211\u53bb\uff0c\u771f\u7684\u5b9a\u4f4d\u5230\u4e86albu\u5e93\n    dict(\n        type='RandomBrightnessContrast',\n        brightness_limit=[0.1, 0.3],\n        contrast_limit=[0.1, 0.3],\n        p=0.2),\n    # dict(\n    #     type='OneOf',\n    #     transforms=[\n    #         dict(\n    #             type='RGBShift',\n    #             r_shift_limit=10,\n    #             g_shift_limit=10,\n    #             b_shift_limit=10,\n    #             p=1.0),\n    #         dict(\n    #             type='HueSaturationValue',\n    #             hue_shift_limit=20,\n    #             sat_shift_limit=30,\n    #             val_shift_limit=20,\n    #             p=1.0)\n    #     ],\n    #     p=0.1),\n    # # dict(type='JpegCompression', quality_lower=85, quality_upper=95, p=0.2),\n    #\n    # dict(type='ChannelShuffle', p=0.1),\n    # dict(\n    #     type='OneOf',\n    #     transforms=[\n    #         dict(type='Blur', blur_limit=3, p=1.0),\n    #         dict(type='MedianBlur', blur_limit=3, p=1.0)\n    #     ],\n    #     p=0.1),\n]","6da153e3":"# \u4f7f\u7528py\u6587\u4ef6\u7c7b\u578b\u7684config\uff0c\u63d0\u5347\u914d\u7f6e\u590d\u7528\u6027\n\n##################################cascade_rcnn_r50_fpn.py#######################\n# model settings\nmodel = dict(\n    type='CascadeRCNN',\n    pretrained='\/kaggle\/input\/mm-faster\/resnet50-19c8e357.pth',\n    backbone=dict(\n        type='ResNet',\n        depth=50,\n        num_stages=4,\n        out_indices=(0, 1, 2, 3),\n        frozen_stages=1,\n        norm_cfg=dict(type='BN', requires_grad=True),\n        norm_eval=True,\n        style='pytorch'),\n    neck=dict(\n        type='FPN',\n        in_channels=[256, 512, 1024, 2048],\n        out_channels=256,\n        num_outs=5),\n    rpn_head=dict(\n        type='RPNHead',\n        in_channels=256,\n        feat_channels=256,\n        anchor_generator=dict(\n            type='AnchorGenerator',\n            scales=[8],\n            ratios=[0.5, 1.0, 2.0],\n            strides=[4, 8, 16, 32, 64]),\n        bbox_coder=dict(\n            type='DeltaXYWHBBoxCoder',\n            target_means=[.0, .0, .0, .0],\n            target_stds=[1.0, 1.0, 1.0, 1.0]),\n        loss_cls=dict(\n            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n        loss_bbox=dict(type='SmoothL1Loss', beta=1.0 \/ 9.0, loss_weight=1.0)),\n    roi_head=dict(\n        type='CascadeRoIHead',\n        num_stages=3,\n        stage_loss_weights=[1, 0.5, 0.25],\n        bbox_roi_extractor=dict(\n            type='SingleRoIExtractor',\n            roi_layer=dict(type='RoIAlign', out_size=7, sample_num=0),\n            out_channels=256,\n            featmap_strides=[4, 8, 16, 32]),\n        bbox_head=[\n            dict(\n                type='Shared2FCBBoxHead',\n                in_channels=256,\n                fc_out_channels=1024,\n                roi_feat_size=7,\n                num_classes=1,\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    target_means=[0., 0., 0., 0.],\n                    target_stds=[0.1, 0.1, 0.2, 0.2]),\n                reg_class_agnostic=True,\n                loss_cls=dict(\n                    type='CrossEntropyLoss',\n                    use_sigmoid=False,\n                    loss_weight=1.0),\n                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n                               loss_weight=1.0)),\n            dict(\n                type='Shared2FCBBoxHead',\n                in_channels=256,\n                fc_out_channels=1024,\n                roi_feat_size=7,\n                num_classes=1,\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    target_means=[0., 0., 0., 0.],\n                    target_stds=[0.05, 0.05, 0.1, 0.1]),\n                reg_class_agnostic=True,\n                loss_cls=dict(\n                    type='CrossEntropyLoss',\n                    use_sigmoid=False,\n                    loss_weight=1.0),\n                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n                               loss_weight=1.0)),\n            dict(\n                type='Shared2FCBBoxHead',\n                in_channels=256,\n                fc_out_channels=1024,\n                roi_feat_size=7,\n                num_classes=1,\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    target_means=[0., 0., 0., 0.],\n                    target_stds=[0.033, 0.033, 0.067, 0.067]),\n                reg_class_agnostic=True,\n                loss_cls=dict(\n                    type='CrossEntropyLoss',\n                    use_sigmoid=False,\n                    loss_weight=1.0),\n                loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))\n        ]))\n# model training and testing settings\ntrain_cfg = dict(\n    rpn=dict(\n        assigner=dict(\n            type='MaxIoUAssigner',\n            pos_iou_thr=0.7,\n            neg_iou_thr=0.3,\n            min_pos_iou=0.3,\n            match_low_quality=True,\n            ignore_iof_thr=-1),\n        sampler=dict(\n            type='RandomSampler',\n            num=256,\n            pos_fraction=0.5,\n            neg_pos_ub=-1,\n            add_gt_as_proposals=False),\n        allowed_border=0,\n        pos_weight=-1,\n        debug=False),\n    rpn_proposal=dict(\n        nms_across_levels=False,\n        nms_pre=2000,\n        nms_post=2000,\n        max_num=2000,\n        nms_thr=0.7,\n        min_bbox_size=0),\n    rcnn=[\n        dict(\n            assigner=dict(\n                type='MaxIoUAssigner',\n                pos_iou_thr=0.5,\n                neg_iou_thr=0.5,\n                min_pos_iou=0.5,\n                match_low_quality=False,\n                ignore_iof_thr=-1),\n            sampler=dict(\n                type='RandomSampler',\n                num=512,\n                pos_fraction=0.25,\n                neg_pos_ub=-1,\n                add_gt_as_proposals=True),\n            pos_weight=-1,\n            debug=False),\n        dict(\n            assigner=dict(\n                type='MaxIoUAssigner',\n                pos_iou_thr=0.6,\n                neg_iou_thr=0.6,\n                min_pos_iou=0.6,\n                match_low_quality=False,\n                ignore_iof_thr=-1),\n            sampler=dict(\n                type='RandomSampler',\n                num=512,\n                pos_fraction=0.25,\n                neg_pos_ub=-1,\n                add_gt_as_proposals=True),\n            pos_weight=-1,\n            debug=False),\n        dict(\n            assigner=dict(\n                type='MaxIoUAssigner',\n                pos_iou_thr=0.7,\n                neg_iou_thr=0.7,\n                min_pos_iou=0.7,\n                match_low_quality=False,\n                ignore_iof_thr=-1),\n            sampler=dict(\n                type='RandomSampler',\n                num=512,\n                pos_fraction=0.25,\n                neg_pos_ub=-1,\n                add_gt_as_proposals=True),\n            pos_weight=-1,\n            debug=False)\n    ])\ntest_cfg = dict(\n    rpn=dict(\n        nms_across_levels=False,\n        nms_pre=1000,\n        nms_post=1000,\n        max_num=1000,\n        nms_thr=0.7,\n        min_bbox_size=0),\n    rcnn=dict(\n        score_thr=0.05, nms=dict(type='nms', iou_thr=0.5), max_per_img=100))\n\n\n\n###################################coco_detection.py#############################\ndataset_type = 'CocoDataset'\ndata_root = '\/kaggle\/input\/mmdata\/coco\/' #\u8bb0\u5f97\u52a0\/\n\nclasses = ('wheat',) #\u9700\u8981\u52a0\u9017\u53f7\uff0c\u4e0d\u7136\u597d\u50cf\u4f1a\u62a5\u9519\n\n#\u8fd9\u4e2a\u540e\u7eed\u518d\u6539\u5427\nimg_norm_cfg = dict(mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True),\n    \n    # \u5982\u679c\u662f\u65b0\u624b\u90a3\u5c31\u6309\u7167\u9ed8\u8ba4\u53c2\u6570\u7684\u6bd4\u4f8b\u6269\u5927\u5c31\u884c\u4e86\uff0c\u7136\u540e\u6d4b\u8bd5\u7684\u65f6\u5019\u53d6\u8bad\u7ec3\u96c6\u7684\u4e2d\u95f4\u503c\u3002\u6bd4\u5982cascade50\u9ed8\u8ba4\u5c3a\u5ea6\u662f(1333,800)\n    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),# The largest scale of image\n    # dict(type='Resize',img_scale=[(2000, 300), (2000, 1200)],multiscale_mode='range',keep_ratio=True), #\u522b\u7684\u4ee3\u7801\u770b\u5230\u4e86\u8fd9\u79cd\u7ed3\u6784\n    \n    dict(type='RandomFlip', flip_ratio=0.5),\n    dict(type='Normalize', **img_norm_cfg),\n    dict(type='Pad', size_divisor=32),\n\n    # \u77e5\u4e4e\u8d34\u5b50\u589e\u52a0\u7684\uff0c\u548c\u524d\u9762\u7684\u6bb5\u843d\u914d\u5408\n    dict(\n    type='Albu',\n    transforms=albu_train_transforms,\n    bbox_params=dict(\n        type='BboxParams',\n        format='pascal_voc',\n        label_fields=['gt_labels'],\n        min_visibility=0.0,\n        filter_lost_elements=True),\n    keymap={\n        'img': 'image',\n        'gt_bboxes': 'bboxes'\n    },\n    update_pad_shape=False,\n    skip_img_without_anno=True),\n    \n    dict(type='DefaultFormatBundle'),\n    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels']),\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        \n        #test_pipeline \u4e2dimg_scale\u7684\u5c3a\u5ea6\u53ef\u4ee5\u4e3a\u4efb\u610f\u591a\u4e2a\uff0c\u542b\u4e49\u4e3a\u5bf9\u6d4b\u8bd5\u96c6\u8fdb\u884c\u591a\u5c3a\u5ea6\u6d4b\u8bd5\uff08\u53ef\u4ee5\u7406\u89e3\u4e3aTTA\uff09\n        img_scale=(1333, 800),\n        \n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(type='Normalize', **img_norm_cfg),\n            dict(type='Pad', size_divisor=32),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img']),\n        ])\n]\ndata = dict(\n    samples_per_gpu=2,\n    workers_per_gpu=2,\n    train=dict(\n        type=dataset_type,\n        classes=classes,\n        #ann_file=data_root + 'annotations\/instances_train2017.json',\n        #img_prefix=data_root + 'train2017\/',\n        ann_file='\/kaggle\/input\/wheat-coco-label\/instances_train2017.json',\n        img_prefix='\/kaggle\/input\/global-wheat-detection\/train\/',\n        pipeline=train_pipeline),\n    val=dict(\n        type=dataset_type,\n        classes=classes,\n        #ann_file=data_root + 'annotations\/instances_val2017.json',\n        #img_prefix=data_root + 'val2017\/',\n        ann_file='\/kaggle\/input\/wheat-coco-label\/instances_val2017.json',\n        img_prefix='\/kaggle\/input\/global-wheat-detection\/train\/',\n        pipeline=test_pipeline),\n    test=dict(\n        type=dataset_type,\n        classes=classes,\n        #ann_file=data_root + 'annotations\/instances_val2017.json',\n        #img_prefix=data_root + 'val2017\/',\n        pipeline=test_pipeline))\nevaluation = dict(interval=5, metric='bbox')\n\n\n\n\n#######################################schedule_1x.py#################################\n# optimizer\noptimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\noptimizer_config = dict(grad_clip=None)\n# learning policy\nlr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=500,\n    warmup_ratio=0.001,\n    step=[8, 11])\ntotal_epochs = 50 #epochs\n\n\n\n\n#################################default_runtime.py#############################\ncheckpoint_config = dict(interval=10)\n# yapf:disable\nlog_config = dict(\n    interval=50,\n    hooks=[\n        dict(type='TextLoggerHook'),\n        # dict(type='TensorboardLoggerHook')\n    ])\n# yapf:enable\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = None\nresume_from = None\nworkflow = [('train', 1)]\n\n\n\n\n############################\u751f\u6210\u914d\u7f6e###############################\nconfig_dict=dict(\n    model = model,\n    train_cfg = train_cfg,\n    test_cfg  = test_cfg ,\n    dataset_type =dataset_type,\n    data_root=data_root,\n    classes=classes,\n    img_norm_cfg=img_norm_cfg,\n    train_pipeline=train_pipeline,\n    test_pipeline=test_pipeline,\n    data =data ,\n    evaluation =evaluation ,\n    optimizer=optimizer,\n    optimizer_config=optimizer_config,\n    lr_config=lr_config,\n    total_epochs=total_epochs,\n    checkpoint_config=checkpoint_config,\n    log_config=log_config,\n    dist_params=dist_params,\n    log_level=log_level,\n    load_from =load_from ,\n    resume_from=resume_from,\n    workflow =workflow \n)\n\n\n\ncfg_real_time = Config(config_dict)\n\n# print(config_dict)","273caefe":"# train.py\nimport argparse\nimport copy\nimport os\nimport os.path as osp\nimport time\n\nimport mmcv\nimport torch\nfrom mmcv import Config, DictAction\nfrom mmcv.runner import init_dist\n\nfrom mmdet import __version__\nfrom mmdet.apis import set_random_seed, train_detector\nfrom mmdet.datasets import build_dataset\nfrom mmdet.models import build_detector\nfrom mmdet.utils import collect_env, get_root_logger\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser(description='Train a detector')\n    \n    # \u8fd9\u91cc\u52a0\u77ed\u6a2a\u7ebf\uff0c\u52a0\u9ed8\u8ba4\u8f93\u5165\uff0c\u540e\u7eed\u5904\u7406\u6389\u8fd9\u91cc\n    # parser.add_argument('--config', help='train config file path',default='\/kaggle\/input\/mmconfigs\/cascade_rcnn\/cascade_rcnn_r50_fpn_1x_coco.py')\n    parser.add_argument('--work-dir', help='the dir to save logs and models')\n    parser.add_argument(\n        '--resume-from', help='the checkpoint file to resume from')\n    parser.add_argument(\n        '--no-validate',\n        action='store_true',\n        help='whether not to evaluate the checkpoint during training')\n    group_gpus = parser.add_mutually_exclusive_group()\n    group_gpus.add_argument(\n        '--gpus',\n        type=int,\n        help='number of gpus to use '\n        '(only applicable to non-distributed training)')\n    group_gpus.add_argument(\n        '--gpu-ids',\n        type=int,\n        nargs='+',\n        help='ids of gpus to use '\n        '(only applicable to non-distributed training)')\n    parser.add_argument('--seed', type=int, default=None, help='random seed')\n    parser.add_argument(\n        '--deterministic',\n        action='store_true',\n        help='whether to set deterministic options for CUDNN backend.')\n    parser.add_argument(\n        '--options', nargs='+', action=DictAction, help='arguments in dict')\n    parser.add_argument(\n        '--launcher',\n        choices=['none', 'pytorch', 'slurm', 'mpi'],\n        default='none',\n        help='job launcher')\n    parser.add_argument('--local_rank', type=int, default=0)\n    parser.add_argument(\n        '--autoscale-lr',\n        action='store_true',\n        help='automatically scale lr with the number of gpus')\n\n    # \u7f51\u4e0a\u8bf4\u6539\u6210\u8fd9\u4e2a\u5c31\u80fd\u5728notebook\u91cc\u7528\u54af~\n    # args = parser.parse_args()\n    args, unknown = parser.parse_known_args()\n    \n    if 'LOCAL_RANK' not in os.environ:\n        os.environ['LOCAL_RANK'] = str(args.local_rank)\n\n    return args\n\n\ndef main():\n    args = parse_args()\n    \n\n    #cfg = Config.fromfile(args.config)\n    cfg = cfg_real_time\n    #print(cfg)\n    \n    if args.options is not None:\n        cfg.merge_from_dict(args.options)\n    # set cudnn_benchmark\n    if cfg.get('cudnn_benchmark', False):\n        torch.backends.cudnn.benchmark = True\n\n    # work_dir is determined in this priority: CLI > segment in file > filename\n    if args.work_dir is not None:\n        # update configs according to CLI args if args.work_dir is not None\n        cfg.work_dir = args.work_dir\n    elif cfg.get('work_dir', None) is None:\n        # use config filename as default work_dir if cfg.work_dir is None\n        # \u5220\u9664\u4e86config\u6587\u4ef6\u7684\u8def\u5f84\u540e\u6539\u6210\u4e86\u8fd9\u4e2a\n        cfg.work_dir = '.\/work_dirs'\n    if args.resume_from is not None:\n        cfg.resume_from = args.resume_from\n    if args.gpu_ids is not None:\n        cfg.gpu_ids = args.gpu_ids\n    else:\n        cfg.gpu_ids = range(1) if args.gpus is None else range(args.gpus)\n\n    if args.autoscale_lr:\n        # apply the linear scaling rule (https:\/\/arxiv.org\/abs\/1706.02677)\n        cfg.optimizer['lr'] = cfg.optimizer['lr'] * len(cfg.gpu_ids) \/ 8\n\n    # init distributed env first, since logger depends on the dist info.\n    if args.launcher == 'none':\n        distributed = False\n    else:\n        distributed = True\n        init_dist(args.launcher, **cfg.dist_params)\n\n    # create work_dir\n    mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n    # init the logger before other steps\n    timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())\n    log_file = osp.join(cfg.work_dir, f'{timestamp}.log')\n    logger = get_root_logger(log_file=log_file, log_level=cfg.log_level)\n\n    # init the meta dict to record some important information such as\n    # environment info and seed, which will be logged\n    meta = dict()\n    # log env info\n    env_info_dict = collect_env()\n    env_info = '\\n'.join([(f'{k}: {v}') for k, v in env_info_dict.items()])\n    dash_line = '-' * 60 + '\\n'\n    logger.info('Environment info:\\n' + dash_line + env_info + '\\n' +\n                dash_line)\n    meta['env_info'] = env_info\n\n    # log some basic info\n    logger.info(f'Distributed training: {distributed}')\n    logger.info(f'Config:\\n{cfg.pretty_text}')\n\n    # set random seeds\n    if args.seed is not None:\n        logger.info(f'Set random seed to {args.seed}, '\n                    f'deterministic: {args.deterministic}')\n        set_random_seed(args.seed, deterministic=args.deterministic)\n    cfg.seed = args.seed\n    meta['seed'] = args.seed\n\n    model = build_detector(\n        cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)\n\n    datasets = [build_dataset(cfg.data.train)]\n    if len(cfg.workflow) == 2:\n        val_dataset = copy.deepcopy(cfg.data.val)\n        val_dataset.pipeline = cfg.data.train.pipeline\n        datasets.append(build_dataset(val_dataset))\n    if cfg.checkpoint_config is not None:\n        # save mmdet version, config file content and class names in\n        # checkpoints as meta data\n        cfg.checkpoint_config.meta = dict(\n            mmdet_version=__version__,\n            config=cfg.pretty_text,\n            CLASSES=datasets[0].CLASSES)\n    # add an attribute for visualization convenience\n    model.CLASSES = datasets[0].CLASSES\n    train_detector(\n        model,\n        datasets,\n        cfg,\n        distributed=distributed,\n        validate=(not args.no_validate),\n        timestamp=timestamp,\n        meta=meta)\n\n\n    \n    \nmain()\n","e547fd50":"#\u8fd9\u91cc\u4fee\u6539\u4e0b\u6587\u4ef6\u540d\uff1b\u6709\u65f6\u63d0\u793a\u627e\u4e0d\u5230bbox_mAP\uff0c\u5148\u53bb\u6389\u8fd9\u4e00\u6bb5\n#!python mmdetection\/tools\/analyze_logs.py plot_curve work_dirs\/20200602_051740.log.json --keys bbox_mAP --legend bbox_mAP --out mAP.png\n#import cv2\n\n#mAP_png=cv2.imread('mAP.png')\n#plt.imshow(mAP_png)\n\n","80d94672":"config = 'mmdetection\/configs\/cascade_rcnn\/cascade_rcnn_r50_fpn_1x_coco.py'\ncheckpoint = 'work_dirs\/latest.pth'\nmodel = init_detector(config, checkpoint, device='cuda:0')","d0cc9340":"import numpy as np\ndef show_result(\n                img,\n                result,\n                score_thr=0.3,\n                bbox_color='green',\n                text_color='green',\n                thickness=1,\n                font_scale=0.5,\n                win_name='',\n                show=False,\n                wait_time=0,\n                out_file=None):\n    \"\"\"Draw `result` over `img`.\n    Args:\n        img (str or Tensor): The image to be displayed.\n        result (Tensor or tuple): The results to draw over `img`\n            bbox_result or (bbox_result, segm_result).\n        score_thr (float, optional): Minimum score of bboxes to be shown.\n            Default: 0.3.\n        bbox_color (str or tuple or :obj:`Color`): Color of bbox lines.\n        text_color (str or tuple or :obj:`Color`): Color of texts.\n        thickness (int): Thickness of lines.\n        font_scale (float): Font scales of texts.\n        win_name (str): The window name.\n        wait_time (int): Value of waitKey param.\n            Default: 0.\n        show (bool): Whether to show the image.\n            Default: False.\n        out_file (str or None): The filename to write the image.\n            Default: None.\n    Returns:\n        img (Tensor): Only if not `show` or `out_file`\n    \"\"\"\n    img = mmcv.imread(img)\n    img = img.copy()\n    if isinstance(result, tuple):\n        bbox_result, segm_result = result\n        if isinstance(segm_result, tuple):\n            segm_result = segm_result[0]  # ms rcnn\n    else:\n        bbox_result, segm_result = result, None\n    bboxes = np.vstack(bbox_result)\n    labels = [\n        np.full(bbox.shape[0], i, dtype=np.int32)\n        for i, bbox in enumerate(bbox_result)\n    ]\n    labels = np.concatenate(labels)\n    # draw segmentation masks\n    if segm_result is not None and len(labels) > 0:  # non empty\n        segms = mmcv.concat_list(segm_result)\n        inds = np.where(bboxes[:, -1] > score_thr)[0]\n        np.random.seed(42)\n        color_masks = [\n            np.random.randint(0, 256, (1, 3), dtype=np.uint8)\n            for _ in range(max(labels) + 1)\n        ]\n        for i in inds:\n            i = int(i)\n            color_mask = color_masks[labels[i]]\n            mask = segms[i]\n            img[mask] = img[mask] * 0.5 + color_mask * 0.5\n    # if out_file specified, do not show image in window\n    if out_file is not None:\n        show = False\n    # draw bounding boxes\n    mmcv.imshow_det_bboxes(\n        img,\n        bboxes,\n        labels,\n        class_names=('cancer_cell',),\n        score_thr=score_thr,\n        bbox_color=bbox_color,\n        text_color=text_color,\n        thickness=thickness,\n        font_scale=font_scale,\n        win_name=win_name,\n        show=show,\n        wait_time=wait_time,\n        out_file=out_file)\n\n    if not (show or out_file):\n        return img","db1ae897":"#\u8f93\u5165\u6d4b\u8bd5\u56fe\u7247\u7684\u8def\u5f84\nimg = '..\/input\/global-wheat-detection\/train\/00333207f.jpg'\n# img = 'mmdetection\/demo\/demo.jpg\nresult = inference_detector(model, img)\n#print(result)\n\n#import cv2\n#cv2_img=cv2.imread(img)\n\n#print(result[0])\n#draw_0 = cv2.rectangle(cv2_img, (result[0][0][0], result[0][0][1]), (result[0][0][2], result[0][0][3]), (255, 0, 0), 2)\n\n# \u4fdd\u5b58\u4e0b\u6765\u662f\u5f88\u6b63\u5e38\u7684\u663e\u793a\uff0c\u5b8c\u7f8e\n#cv2.imwrite('temp_out.png',draw_0)\n\n\n#plt.imshow(mmcv.bgr2rgb(draw_0))\n\n# \u8fd9\u4e2a\u672a\u77e5\u539f\u56e0\u62a5\u9519\u4e86\n# show_result_pyplot(model, img, result, score_thr=0.3)\nimg = show_result(img, result, score_thr=0.3)\nplt.imshow(mmcv.bgr2rgb(img))","a35d4093":"#\u8fd9\u4e00\u6bb5\u662f\u4e3a\u4e86\u6700\u540e\u7684\u8f93\u51fa\u4e2d\u627e\u5f97\u5230\u81ea\u5df1\u7684\u8f93\u51fa\u6587\u4ef6\n!rm -rf mmdetection\/","c9f435c9":"# \u5f00\u59cb\u8bad\u7ec3,\u4f7f\u7528cascade rcnn\u7684\u914d\u7f6e\u6587\u4ef6","608cb1a9":"# ###################\u5206\u5272\u7ebf================\n# \u5b89\u88c5\u5b8c\u6bd5\uff0c\u5148\u8bd5\u8bd5demo\u80fd\u4e0d\u80fd\u6b63\u5e38\u4f7f\u7528","893e946f":"# v5\u516c\u5f00\u4e86coco\u6807\u7b7e\uff0c\u5e94\u8be5\u80fd\u6b63\u5e38\u8fd0\u884c\u4e86\u5427\n# kaggle\u8bad\u7ec3mmdet\u793a\u4f8b\uff0c\u53ef\u5728\u7ebf\u66f4\u6539configs\n# \u53c2\u8003\u4e86 https:\/\/www.kaggle.com\/superkevingit\/faster-rcnn-with-mmdetection-without-internet\n\n# \u7b2c\u4e00\u6b65\uff0c\u8fdb\u884c\u5b89\u88c5"}}