{"cell_type":{"ed30668e":"code","9e779211":"code","7cb5610e":"code","01039c3f":"code","00a8a0a1":"code","7336865a":"code","07d29c0e":"code","db9cd901":"code","c6f08e6d":"code","7d145192":"code","707f7308":"code","d74a9755":"code","b5ef3d5b":"code","4b01dbb9":"code","be6f14bb":"code","c7267858":"code","2178c29b":"code","a049a742":"code","9dc82208":"code","700ab574":"code","aa31c318":"markdown","ed5711c9":"markdown","f31be2cf":"markdown","dffefc96":"markdown","4556fda8":"markdown","c73f2f38":"markdown","58e8aabe":"markdown","42233033":"markdown","2dc668d3":"markdown"},"source":{"ed30668e":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","9e779211":"train = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/test.csv')\nsubmission = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/sample_solution.csv')","7cb5610e":"train.head()","01039c3f":"train.info()","00a8a0a1":"train.describe()","7336865a":"train.isnull().sum()","07d29c0e":"test.head()","db9cd901":"test.isnull().sum()","c6f08e6d":"features = [x for x in train.columns.values if x[0]==\"f\"]","7d145192":"train['n_missing'] = train[features].isna().sum(axis=1)\ntest['n_missing'] = test[features].isna().sum(axis=1)\n\ntrain['abs_sum'] = train[features].abs().sum(axis=1)\ntest['abs_sum'] = test[features].abs().sum(axis=1)\n\ntrain['sem'] = train[features].sem(axis=1)\ntest['sem'] = test[features].sem(axis=1)\n\ntrain['std'] = train[features].std(axis=1)\ntest['std'] = test[features].std(axis=1)\n\ntrain['avg'] = train[features].mean(axis=1)\ntest['avg'] = test[features].mean(axis=1)\n\ntrain['max'] = train[features].max(axis=1)\ntest['max'] = test[features].min(axis=1)\n\ntrain['min'] = train[features].min(axis=1)\ntest['min'] = test[features].min(axis=1)","707f7308":"imputer = SimpleImputer(strategy=\"median\")\nfor col in features:\n    train[col] = imputer.fit_transform(np.array(train[col]).reshape(-1,1))\n    test[col] = imputer.transform(np.array(test[col]).reshape(-1,1))","d74a9755":"# s_scaler = StandardScaler()\n# m_scaler = MinMaxScaler()\nr_scaler = RobustScaler()\nfor col in features:\n    # train[col] = s_scaler.fit_transform(np.array(train[col]).reshape(-1,1))\n    # test[col] = s_scaler.transform(np.array(test[col]).reshape(-1,1))\n    # train[col] = m_scaler.fit_transform(np.array(train[col]).reshape(-1,1))\n    # test[col] = m_scaler.transform(np.array(test[col]).reshape(-1,1))\n    train[col] = r_scaler.fit_transform(np.array(train[col]).reshape(-1,1))\n    test[col] = r_scaler.transform(np.array(test[col]).reshape(-1,1))","b5ef3d5b":"X = train.drop(['id', 'claim'], axis = 1)\ny = train['claim']","4b01dbb9":"xgb_params = {\n    'objective': 'binary:logistic',\n    'eval_metric': 'auc',\n    'n_estimators': 2000,\n    'max_depth': 4,\n    'gamma': 0.2465,\n    'subsample': 0.6423,\n    'colsample_bytree': 0.775,\n    'colsample_bylevel': 0.868,\n    'min_child_weight': 366,\n    'reg_lambda': 0.05,\n    'reg_alpha': 10,\n    'verbosity': 0,\n    'random_state': 42\n} ","be6f14bb":"model = XGBClassifier(**xgb_params)\nmodel","c7267858":"X_test = test.drop(['id'], axis = 1)","2178c29b":"splits = 5\nskf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=42)\n\noof_preds = np.zeros((X.shape[0],))\npreds = 0\nmodel_fi = 0\ntotal_mean_auc = 0\n\nfor num, (train_idx, valid_idx) in enumerate(skf.split(X, y)):\n    X_train, X_valid = X.loc[train_idx], X.loc[valid_idx]\n    y_train, y_valid = y.loc[train_idx], y.loc[valid_idx]\n    \n    model.fit(X_train, y_train,\n              verbose=False,\n              eval_set=[(X_train, y_train), (X_valid, y_valid)],\n              eval_metric=\"auc\",\n              early_stopping_rounds=300,\n              )\n    \n    preds += model.predict_proba(X_test)[:, 1] \/ splits\n    model_fi += model.feature_importances_ \/ splits\n    \n    oof_preds[valid_idx] = model.predict_proba(X_valid)[:, 1]\n    \n    fold_auc = roc_auc_score(y_valid, oof_preds[valid_idx])\n    print(f\"Fold {num} ROC AUC: {fold_auc}\")\n\n    total_mean_auc += fold_auc \/ splits\n    \nprint(f\"\\nOverall ROC AUC: {total_mean_auc}\")","a049a742":"importance = pd.DataFrame(model.feature_importances_, index=X.columns, columns=['importance'])\nimportance = importance.sort_values('importance', ascending=False)\nimportance","9dc82208":"submission.claim = preds\nsubmission.head()","700ab574":"submission.to_csv('submission.csv', index=False)","aa31c318":"## Make Submission","ed5711c9":"## Exploratory Data Analysis (EDA)","f31be2cf":"## Feature Importance","dffefc96":"## Feature Engineering","4556fda8":"## References\n- https:\/\/www.kaggle.com\/dlaststark\/tps-sep-single-xgboost-model\n- https:\/\/www.kaggle.com\/maximkazantsev\/tps-09-21-eda-xgboost-with-folds\n- https:\/\/www.kaggle.com\/akihironomura\/tps-lightgbm-optuna-kfold","c73f2f38":"## Import Modules","58e8aabe":"## If you like this kernel, please upvote:)","42233033":"## Model Training","2dc668d3":"## XGBClassifier"}}