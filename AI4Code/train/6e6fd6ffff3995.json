{"cell_type":{"23b79247":"code","5be0fb3a":"code","df6bdab6":"code","7538ac10":"code","ddaf36dd":"code","98dbeeba":"code","49efaad3":"code","8132c1f5":"code","333c82a2":"code","4453218f":"code","c3afe67c":"code","aaa0ebdb":"code","ef1b9571":"code","c9a2c65f":"code","c36be7c5":"code","6b367203":"code","e1c8a96d":"code","81b92cbb":"code","5e18cc06":"code","92ecb3ae":"code","3d3e9611":"code","3487c3e7":"code","8eb597ad":"code","bceb101d":"code","2c703189":"code","2516b6cb":"code","6eed9ae5":"code","4516ea9d":"code","9b359dbc":"code","ae7377b9":"code","8e5965cf":"code","a3078ea0":"code","db27233e":"code","40866c8a":"code","be4b862e":"code","24328483":"code","edd2aca8":"code","c56ca239":"code","e28502ab":"code","9821a49c":"code","b5081b2e":"code","ecace9f8":"code","4941e91a":"code","ddd69b93":"code","b67db8b5":"code","7a3894b5":"code","330ffc5f":"code","22f80f56":"code","f996f587":"code","9ae9232c":"code","0f52da7c":"markdown","391c8e7e":"markdown","7d7ea2a4":"markdown","3940cc91":"markdown","49ba3bc2":"markdown","a779d52f":"markdown","8f93dffe":"markdown","e8354ae4":"markdown","b699140e":"markdown","70dcbc89":"markdown","22475726":"markdown","232051f1":"markdown","8c7cdb6b":"markdown","5089c995":"markdown","9d21fbed":"markdown","22ba546c":"markdown","cf66bdaa":"markdown","b5efa336":"markdown","aa2bbf35":"markdown","e4b72a42":"markdown","e17c9c6c":"markdown","bb794b6f":"markdown","4b39049e":"markdown","bf1791be":"markdown","9c22c381":"markdown","1943df31":"markdown"},"source":{"23b79247":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\n#print(os.listdir(\"..\/input\"))\nimport warnings\nwarnings.filterwarnings(\"ignore\")","5be0fb3a":"hsales = pd.read_csv('..\/input\/nyc-property-sales\/nyc-rolling-sales.csv') ","df6bdab6":"hsales.shape","7538ac10":"# let's check what we have \nhsales.head()","ddaf36dd":"hsales.drop(['Unnamed: 0', 'EASE-MENT'],1, inplace=True)","98dbeeba":"hsales.info()","49efaad3":"#First, let's check which columns should be categorical\nprint('Column name')\nfor col in hsales.columns:\n    if hsales[col].dtype=='object':\n        print(col, hsales[col].nunique())","8132c1f5":"# LAND SQUARE FEET,GROSS SQUARE FEET, SALE PRICE, BOROUGH should be numeric. \n# SALE DATE datetime format.\n# categorical: NEIGHBORHOOD, BUILDING CLASS CATEGORY, TAX CLASS AT PRESENT, BUILDING CLASS AT PRESENT,\n# BUILDING CLASS AT TIME OF SALE, TAX CLASS AT TIME OF SALE,BOROUGH \n\nnumer = ['LAND SQUARE FEET','GROSS SQUARE FEET', 'SALE PRICE', 'BOROUGH']\nfor col in numer: # coerce for missing values\n    hsales[col] = pd.to_numeric(hsales[col], errors='coerce')\n\ncateg = ['NEIGHBORHOOD', 'BUILDING CLASS CATEGORY', 'TAX CLASS AT PRESENT', 'BUILDING CLASS AT PRESENT', 'BUILDING CLASS AT TIME OF SALE', 'TAX CLASS AT TIME OF SALE']\nfor col in categ:\n    hsales[col] = hsales[col].astype('category')\n\nhsales['SALE DATE'] = pd.to_datetime(hsales['SALE DATE'], errors='coerce')","333c82a2":"missing = hsales.isnull().sum()\/len(hsales)*100\n\nprint(pd.DataFrame([missing[missing>0],pd.Series(hsales.isnull().sum()[hsales.isnull().sum()>1000])], index=['percent missing','how many missing']))\n","4453218f":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nplt.figure(figsize=(8,10))\nsns.heatmap(hsales.isnull(),cmap='viridis')","c3afe67c":"# let us check for outliers first\nhsales[['LAND SQUARE FEET','GROSS SQUARE FEET']].describe()","aaa0ebdb":"sns.jointplot(x='LAND SQUARE FEET', y='GROSS SQUARE FEET', data=hsales[(hsales['LAND SQUARE FEET']<=3500)& (hsales['GROSS SQUARE FEET']<=2560)], kind='scatter')","ef1b9571":"hsales[(hsales['LAND SQUARE FEET']<=3500)& (hsales['GROSS SQUARE FEET']<=2560)][['LAND SQUARE FEET','GROSS SQUARE FEET']].corr()","c9a2c65f":"print(hsales[(hsales['LAND SQUARE FEET'].isnull()) & (hsales['GROSS SQUARE FEET'].notnull())].shape)\nprint(hsales[(hsales['LAND SQUARE FEET'].notnull()) & (hsales['GROSS SQUARE FEET'].isnull())].shape)","c36be7c5":"hsales['LAND SQUARE FEET'] = hsales['LAND SQUARE FEET'].mask((hsales['LAND SQUARE FEET'].isnull()) & (hsales['GROSS SQUARE FEET'].notnull()), hsales['GROSS SQUARE FEET'])\nhsales['GROSS SQUARE FEET'] = hsales['GROSS SQUARE FEET'].mask((hsales['LAND SQUARE FEET'].notnull()) & (hsales['GROSS SQUARE FEET'].isnull()), hsales['LAND SQUARE FEET'])","6b367203":"#  Check for duplicates before\nprint(sum(hsales.duplicated()))\nhsales[hsales.duplicated(keep=False)].sort_values(['NEIGHBORHOOD', 'ADDRESS']).head(10)\n# df.duplicated() automatically excludes duplicates, to keep duplicates in df we use keep=False\n# in df.duplicated(df.columns) we can specify column names to look for duplicates only in those mentioned columns.","e1c8a96d":"hsales.drop_duplicates(inplace=True)\nprint(sum(hsales.duplicated()))","81b92cbb":"missing = hsales.isnull().sum()\/len(hsales)*100\nprint(pd.DataFrame([missing[missing>0],pd.Series(hsales.isnull().sum()[hsales.isnull().sum()>1000])], index=['percent missing','how many missing']))","5e18cc06":"print(\"The number of non-null prices for missing square feet observations:\\n\",((hsales['LAND SQUARE FEET'].isnull()) & (hsales['SALE PRICE'].notnull())).sum())","92ecb3ae":"print(\"non-overlapping observations that cannot be imputed:\",((hsales['LAND SQUARE FEET'].isnull()) & (hsales['SALE PRICE'].isnull())).sum())","3d3e9611":"hsales[hsales['COMMERCIAL UNITS']==0].describe()","3487c3e7":"# for visualization purposes, we replace borough numbering with their string names\nhsales['BOROUGH'] = hsales['BOROUGH'].astype(str)\nhsales['BOROUGH'] = hsales['BOROUGH'].str.replace(\"1\", \"Manhattan\")\nhsales['BOROUGH'] = hsales['BOROUGH'].str.replace(\"2\", \"Bronx\")\nhsales['BOROUGH'] = hsales['BOROUGH'].str.replace(\"3\", \"Brooklyn\")\nhsales['BOROUGH'] = hsales['BOROUGH'].str.replace(\"4\", \"Queens\")\nhsales['BOROUGH'] = hsales['BOROUGH'].str.replace(\"5\", \"Staten Island\")\n","8eb597ad":"hsales['BOROUGH'].value_counts()","bceb101d":"# house prices greater than 5 mln probably represents outliers.\nimport matplotlib.ticker as ticker\n\nsns.set_style(\"whitegrid\")\nplt.figure(figsize=(10,5))\nplotd = sns.distplot(hsales[(hsales['SALE PRICE']>100) & (hsales['SALE PRICE'] < 5000000)]['SALE PRICE'], kde=True, bins=100)\n\ntick_spacing=250000 # set spacing for each tick\nplotd.xaxis.set_major_locator(ticker.MultipleLocator(tick_spacing))\nplotd.set_xlim([-100000, 5000000]) # do not show negative values \nplt.xticks(rotation=30) # rotate x ticks by 30 degrees\nplt.axvline(hsales[(hsales['SALE PRICE']>100) & (hsales['SALE PRICE'] < 5000000)]['SALE PRICE'].mean(), c='red')\nplt.axvline(hsales[(hsales['SALE PRICE']>100) & (hsales['SALE PRICE'] < 5000000)]['SALE PRICE'].median(), c='blue')\nplt.text(250000,0.0000012, \"median\")\nplt.text(850000,0.0000010, \"mean\")\nplt.show()","2c703189":"# The dataset seem to have lots of outliers, mainly due to commercial property sales\nsns.boxplot(x='RESIDENTIAL UNITS',data=hsales)\nplt.title('Average units per property')\nplt.show()\n#print('not included:', hsales[hsales['RESIDENTIAL UNITS']>10].shape[0], 'properties')","2516b6cb":"sns.boxplot(x='COMMERCIAL UNITS',data=hsales)\nplt.title('Commercial units at property')\nplt.show()\n#print('not included:', hsales[hsales['COMMERCIAL UNITS']>20].shape[0], 'properties')","6eed9ae5":"sns.boxplot(x='TOTAL UNITS',data=hsales)\nplt.title('total units at property')\nplt.show()\n#print('not included:', hsales[hsales['TOTAL UNITS']>10].shape[0], 'properties')","4516ea9d":"sns.boxplot(x='GROSS SQUARE FEET',data=hsales)\nplt.title('GROSS SQUARE FEET per property')\nplt.show()\n#print('not included:', hsales[hsales['GROSS SQUARE FEET']>20000].shape[0], 'properties')","9b359dbc":"print(\"Uneqaul values for total units:\", (hsales[\"TOTAL UNITS\"] != hsales['COMMERCIAL UNITS'] + hsales['RESIDENTIAL UNITS']).sum())","ae7377b9":"hsales[hsales[\"TOTAL UNITS\"] != hsales['COMMERCIAL UNITS'] + hsales['RESIDENTIAL UNITS']]['TOTAL UNITS'].value_counts()","8e5965cf":"hsales[(hsales[\"TOTAL UNITS\"] != hsales['COMMERCIAL UNITS'] + hsales['RESIDENTIAL UNITS']) & (hsales[\"TOTAL UNITS\"]==1)]['BUILDING CLASS CATEGORY'].value_counts()[:5]","a3078ea0":"dataset = hsales[(hsales['COMMERCIAL UNITS']<20) & (hsales['TOTAL UNITS']<50) & (hsales['SALE PRICE']<5000000) & (hsales['SALE PRICE']>100000) & (hsales['GROSS SQUARE FEET']>0)]","db27233e":"plt.figure(figsize=(10,6))\nsns.boxplot(x='COMMERCIAL UNITS', y=\"SALE PRICE\", data=dataset)\nplt.title('Commercial Units vs Sale Price')","40866c8a":"plt.figure(figsize=(10,6))\nsns.boxplot(x='RESIDENTIAL UNITS', y='SALE PRICE', data=dataset)\nplt.title('Residential Units vs Sale Price')\nplt.show()","be4b862e":"dataset[dataset['YEAR BUILT']<1800]['YEAR BUILT'].value_counts()","24328483":"dataset[dataset['YEAR BUILT']<1800]['BUILDING CLASS CATEGORY'].value_counts()[:15]","edd2aca8":"plt.figure(figsize=(10,6))\nplotd=sns.countplot(x=dataset[dataset['YEAR BUILT']>1900]['YEAR BUILT'])\n#tick_spacing=1 # set spacing for each tick\n#plotd.xaxis.set_major_locator(ticker.MultipleLocator(tick_spacing))\n#plotd.set_xlim([1900, 2020])\nplt.tick_params(labelbottom=False)\nplt.xticks(rotation=30) \nplt.title(\"Quantity of properties sold by year built\")\nplt.show()","c56ca239":"sns.regplot(x='YEAR BUILT', y='SALE PRICE', data=dataset[dataset['YEAR BUILT']>1900][dataset['RESIDENTIAL UNITS']<=5], fit_reg=False, scatter_kws={'alpha':0.1})","e28502ab":"dataset[dataset['YEAR BUILT']>1900][dataset['RESIDENTIAL UNITS']<=5].plot.scatter(x='YEAR BUILT', y='SALE PRICE', c='RESIDENTIAL UNITS', cmap='coolwarm',figsize=(12,8),s=dataset[dataset['YEAR BUILT']>1900][dataset['RESIDENTIAL UNITS']<=5]['RESIDENTIAL UNITS']*10)\nplt.title('Sales Price vs year. bubble size for units')\nplt.show()","9821a49c":"dataset[dataset['YEAR BUILT']>1900][dataset['RESIDENTIAL UNITS']<=5].plot.scatter(x='YEAR BUILT', y='SALE PRICE', c='GROSS SQUARE FEET', cmap='coolwarm',figsize=(12,8),s=dataset[dataset['YEAR BUILT']>1900][dataset['RESIDENTIAL UNITS']<=5]['GROSS SQUARE FEET']*.008)\nplt.title('Sales Price vs year. bubble size for gross square feet')\nplt.show()","b5081b2e":"plt.figure(figsize=(10,6))\norder = sorted(dataset['BUILDING CLASS CATEGORY'].unique())\nsns.boxplot(x='BUILDING CLASS CATEGORY', y='SALE PRICE', data=dataset, order=order)\nplt.xticks(rotation=90)\nplt.title('Sale Price Distribution by Bulding Class Category')\nplt.show()","ecace9f8":"# Sales prices by borough\nplt.figure(figsize=(10,6))\nsns.boxplot(x='BOROUGH', y='SALE PRICE', data=dataset)\nplt.title('Sale Price Distribution by Borough')\nplt.show()","4941e91a":"import folium # library for interactive map drawing","ddd69b93":"# from geopy.geocoders import Nominatim # get longitude and latitude based on the address\n# def get_lonlat(str_):\n#     geolocator = Nominatim()\n#     location = geolocator.geocode(str_, country_codes=\"US\")\n#     try:\n#         return location.latitude, location.longitude\n#     except:\n#         return np.nan, np.nan\n\n# import requests\n# response = requests.get('https:\/\/maps.googleapis.com\/maps\/api\/geocode\/json?address=1600+Amphitheatre+Parkway,+Mountain+View,+CA')\n# resp_json_payload = response.json()\n# print(resp_json_payload)\n\n# too many requests\n# lonlat = []\n# for val in addresses['ADDRESS']:\n#     locatn = get_lonlat(val)\n#     #print(val, locatn)\n#     lonlat.append(locatn)\n# lonlat=pd.DataFrame(lonlat, columns=[\"lon\",\"lat\"])\n# lonlat.to_csv(path_or_buf=\"\/kaggle\/working\/lonlat.csv\",index=False)\n# print(\"saved\")","b67db8b5":"zipcodes = dataset[hsales[\"ZIP CODE\"]>0]\nzipcodes['ZIP']=zipcodes['ZIP CODE'].astype(str) # zipcodes should be str type because geojson file zipcodes are read as str ","7a3894b5":"boroughs = zipcodes[['ZIP','BOROUGH']]\nboroughs.drop_duplicates('ZIP', inplace=True)","330ffc5f":"us_zipcodes = pd.read_csv(\"..\/input\/nyc-zipcode-geodata\/uszipcodes_geodata.txt\", delimiter=',', dtype=str)\nzipcodes_agg=pd.merge(zipcodes.groupby('ZIP').agg(np.mean), us_zipcodes, how='left', on='ZIP')\nzipcodes_agg = pd.merge(zipcodes_agg, boroughs, how='left', on='ZIP')\nzipcodes_agg.loc[116,'LAT']=\"40.6933\"\nzipcodes_agg.loc[116,'LNG']=\"-73.9925\"\n#zipcodes_agg","22f80f56":"from folium.plugins import MarkerCluster # for clustering the markers\nmap = folium.Map(location=[40.693943, -73.985880], default_zoom_start=12)\nmap.choropleth(geo_data=\"..\/input\/nyc-zipcode-geodata\/nyc-zip-code-tabulation-areas-polygons.geojson\", # I found this NYC zipcode boundaries by googling \n             data=zipcodes_agg, # my dataset\n             columns=['ZIP', 'SALE PRICE'], # zip code is here for matching the geojson zipcode, sales price is the column that changes the color of zipcode areas\n             key_on='feature.properties.postalCode', # this path contains zipcodes in str type, this zipcodes should match with our ZIP CODE column\n             fill_color='BuPu', fill_opacity=0.7, line_opacity=0.3,\n             legend_name='SALE PRICE')\n\n# add a marker for every record in the filtered data, use a clustered view\nmarker_cluster = MarkerCluster().add_to(map) # create marker clusters\nfor i in range(zipcodes_agg.shape[0]):\n    location = [zipcodes_agg['LAT'][i],zipcodes_agg['LNG'][i]]\n    tooltip = \"Zipcode:{}<br> Borough: {}<br> Click for more\".format(zipcodes_agg[\"ZIP\"][i], zipcodes_agg['BOROUGH'][i])\n    folium.Marker(location, \n                  popup=\"\"\"<i>Mean sales price: <\/i> <br> <b>${}<\/b> <br>\n                  <i>mean total units: <\/i><b><br>{}<\/b><br>\n                  <i>mean square feet: <\/i><b><br>{}<\/b><br>\"\"\".format(round(zipcodes_agg['SALE PRICE'][i],2), round(zipcodes_agg['TOTAL UNITS'][i],2), round(zipcodes_agg['GROSS SQUARE FEET'][i],2)), \n                  tooltip=tooltip).add_to(marker_cluster)\nmap","f996f587":"map = folium.Map(location=[40.693943, -73.985880], default_zoom_start=12)\nmap.choropleth(geo_data=\"..\/input\/nyc-zipcode-geodata\/nyc-zip-code-tabulation-areas-polygons.geojson\", # I found this NYC zipcode boundaries by googling \n             data=zipcodes, # my dataset\n             columns=['ZIP', 'SALE PRICE'], # zip code is here for matching the geojson zipcode, sales price is the column that changes the color of zipcode areas\n             key_on='feature.properties.postalCode', # this path contains zipcodes in str type, this zipcodes should match with our ZIP CODE column\n             fill_color='BuPu', fill_opacity=0.7, line_opacity=0.2,\n             legend_name='SALE PRICE')\n\n# add a marker for every record in the filtered data, use a clustered view\n# marker_cluster = MarkerCluster().add_to(map) # create marker clusters\n# for i in range(zipcodes_agg.shape[0]):\n#     location = [zipcodes_agg['LAT'][i],zipcodes_agg['LNG'][i]]\n#     tooltip = \"Zipcode:{}<br> Borough: {}<br> Click for more\".format(zipcodes_agg[\"ZIP\"][i], zipcodes_agg['BOROUGH'][i])\n#     folium.Marker(location, \n#                   popup=\"\"\"<i>Mean sales price: <\/i> <br> <b>${}<\/b> <br>\n#                   <i>mean total units: <\/i><b><br>{}<\/b><br>\n#                   <i>mean square feet: <\/i><b><br>{}<\/b><br>\"\"\".format(round(zipcodes_agg['SALE PRICE'][i],2), round(zipcodes_agg['TOTAL UNITS'][i],2), round(zipcodes_agg['GROSS SQUARE FEET'][i],2)), \n#                   tooltip=tooltip).add_to(marker_cluster)\nmap","9ae9232c":"map.save('mymap.html')","0f52da7c":"More map analysis coming soon...","391c8e7e":"These uneqaul values for total unit counts are mostly equal to 1 which might mean they are not residential or commercial units.","7d7ea2a4":"We can further impute the square footage of the missing observations from the existing Sale prices. However, doing so would mean some of the property square footages are being predicted by the SALE PRICE. We do not want this to happen because this might result in multicollinearity problem between square footage and SALE PRICE. Nonetheless, let us check how many missing square feet observations can be imputed from SALE PRICE. ","3940cc91":"The interactive map shows detailed average prices for each zip code. The most expensive zip codes are 10001 and 10016, 10025 which are located in Manhattan.","49ba3bc2":"# Data visualization","a779d52f":"Let us try to understand the columns. Above table shows descriptive statistics for the numeric columns.\n\n* There are zipcodes with 0 value\n* Can block\/lot numbers go up to 16322?\n* Most of the properties have 2 unit and maximum of 1844 units? The latter might mean some company purchased a building. This should be treated as an outlier.\n* Other columns also have outliers which needs further investigation.\n* Year column has a year with 0\n* Most sales prices less than 10000 can be treated as gift or transfer fees.","8f93dffe":"* Properties built before 1940 are higher in price.","e8354ae4":"It looks like empty records are not being treated as NA. We convert columns to their appropriate data types to obtain NAs.","b699140e":"New properties  built after 2000 are sold for relatively cheaper prices compared to houses built in early 1900s.","70dcbc89":"Most expensive properties are located in Manhattan with median sale price of over 2 million USD for a property. \nRelatively cheaper properties are in Bronx with median property prices of 500,000 USD.","22475726":"Above table brings some new insight into why some properties do not have a year or number of units in them. These are vacant lands, elevators, parking and garages. The question is, do they still have addresses?","232051f1":"# Map analysis","8c7cdb6b":"# Data preprocessing","5089c995":"For visualization purposes, we will treat outliers seperately.","9d21fbed":"Around 30% of GROSS SF and LAND SF are missing. Furthermore, around 17% of SALE PRICE is also missing. Below graph indicates which parts of the table are missing values in yellow.","22ba546c":"As we can observe from the distribution plot, prices are skewed to the right. Most of the prices are around 315 and 700 thousands range. The mean is around 750,000 ","cf66bdaa":"Based on the missing values heatmap, we can see that some of the missing values in LAND SQUARE FEET exists in GROSS SQUARE FEET and vice versa. Assuming these two column values are close to each other, we can fill missing value from one another.","b5efa336":"The dataframe has 765 duplicated rows (exluding the original rows). ","aa2bbf35":"There are outliers in the lower and upper bound of the columns. We will set an upper bound of 75% for our dataset as maximum since 75th percentile of the dataset represents a good cutoff for majority of houses' square feet metrics.","e4b72a42":"There are 1372 rows that can be filled in with their approximate values.","e17c9c6c":"It is hard to notice any correlation from the scatter plot. Below is the correlation matrix.","bb794b6f":"Our dataset is ready for checking missing values.","4b39049e":"As we can see from the correlation matrix above, these two columns are positive correlated with r=0.79 (out of 1). We can now fill in the missing value from one column to another, which will help us reduce missing values. ","bf1791be":"As we can observe those properties with 1 total units but with no residential or commercial units are parking, office or storages.","9c22c381":"Most of the properties were built around 1920s.[](http:\/\/)","1943df31":"According to this official [page](https:\/\/www1.nyc.gov\/assets\/finance\/downloads\/pdf\/07pdf\/glossary_rsf071607.pdf), Ease-ment is \"is a right, such as a right of way, which allows an entity to make limited use of another\u2019s real property. For example: MTA railroad tracks that run across a portion of another property\". Also, the Unnamed column is not mentioned and was likely used for iterating through records. So, those two columns are removed for now. "}}