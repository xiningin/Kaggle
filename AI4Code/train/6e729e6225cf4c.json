{"cell_type":{"c0f220e1":"code","46006131":"code","104c5b8b":"code","b5fa3e19":"code","78885c9d":"code","f2905805":"code","9cb1640e":"code","c43a345f":"code","b197863f":"code","1ae0546c":"code","ff311149":"code","059643a3":"code","87694b00":"code","d8f30593":"code","dd2ec1a5":"code","579602df":"code","0b88125b":"code","1b6c88ed":"code","f219ebaa":"code","9e2ec6e9":"code","a83795fe":"code","29746be0":"code","f977a82b":"code","81744ecf":"markdown","5824412d":"markdown","37a794a4":"markdown","c5df5947":"markdown","36d05e01":"markdown","8ec53e89":"markdown","64b57092":"markdown","5e0a0de4":"markdown","9cfd85a0":"markdown","9daeb26f":"markdown","a8c9068a":"markdown","8a2a01e8":"markdown","0adfc5c7":"markdown","6efc06c9":"markdown","1c651c2e":"markdown","485bebcf":"markdown","47b9092f":"markdown","df7b0368":"markdown"},"source":{"c0f220e1":"import numpy as np\nimport pandas as pd\nimport os\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import to_categorical\n\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.optimizers import Adam\n\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.callbacks import EarlyStopping","46006131":"#loading data\ntrain = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv')\ntest = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_test.csv')","104c5b8b":"#looking at the shape of the data\nprint(train.shape)\nprint(test.shape)","b5fa3e19":"#looks very similar to the MNIST Digit task where one column has a label and the other columns are all pixels\ntrain.head(5)","78885c9d":"#no missing values in the dataset, kudos to whoever provided us with such clean data\nprint(\"train missing values:\", train.isnull().any().sum())\nprint(\"test missing values:\", test.isnull().any().sum())","f2905805":"## Setting seed for Reproducibility.\nseed = 3141\nnp.random.seed(seed)","9cb1640e":"X = train.iloc[:,1:] #taking all but the first row\nY = train.iloc[:,0] #taking only the first row as this is the label\n\n#splitting dataframe using train_test_split\nx_train , x_test , y_train , y_test = train_test_split(X, Y , test_size=0.1, random_state=seed)","c43a345f":"class_names = ['T_shirt\/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n\nplt.figure(figsize=(10, 10))\nfor i in range(36):\n    plt.subplot(6, 6, i + 1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(X.loc[i].values.reshape((28,28))) #calling the .values of each row\n    label_index = int(Y[i]) #setting as an int as the number is stored as a string\n    plt.title(class_names[label_index])\nplt.show()","b197863f":"#first param in reshape is number of examples. We pass -1 here as we want numpy to figure this out by itself\n\n#reshape(examples, height, width, channels)\nx_train = x_train.values.reshape(-1, 28, 28, 1)\nx_test = x_test.values.reshape(-1, 28, 28, 1)","1ae0546c":"datagen = ImageDataGenerator(\n            featurewise_center=False,  # set input mean to 0 over the dataset\n            samplewise_center=False,  # set each sample mean to 0\n            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n            samplewise_std_normalization=False,  # divide each input by its std\n            zca_whitening=False,  # apply ZCA whitening\n            rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n            zoom_range = 0.1, # Randomly zoom image \n            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n            horizontal_flip=True,  # randomly flip images\n            vertical_flip=False)  # randomly flip images","ff311149":"#converting values to float because result will be a float. If we dont do this all vals are set to zero\nx_train = x_train.astype(\"float32\")\/255\nx_test = x_test.astype(\"float32\")\/255","059643a3":"#fitting the ImageDataGenerator we defined above\n#datagen.fit(x_train)","87694b00":"#num_classes set to 10 as there are 10 different labels\ny_train = to_categorical(y_train, num_classes=10)\ny_test = to_categorical(y_test, num_classes=10)\n\nprint(y_train[0])\nprint(y_test[0])","d8f30593":"model = Sequential()\n\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same', data_format='channels_last',\n                 input_shape=(28,28,1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same', data_format='channels_last'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid' ))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', strides=1, padding='same', data_format='channels_last'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), strides=1, padding='same', activation='relu', data_format='channels_last'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2), padding='valid', strides=2))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))","dd2ec1a5":"#specifiying the Adam optimizer\noptimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999 )","579602df":"#Compiling the model\nmodel.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","0b88125b":"model.summary()","1b6c88ed":"#specifying learning decay rate which decays every epoch. Aids in fast convergence at local minima\nreduce_lr = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)","f219ebaa":"#by default early stopping is evaluated on 'val_loss'\n\nearly_stopping = EarlyStopping(\n    min_delta=0.001, # minimium amount of change to count as an improvement\n    patience=15, # how many epochs to wait before stopping\n    restore_best_weights=True,\n    monitor='val_loss', #default monitor val, but it helps to visualize model\n)","9e2ec6e9":"#defining these prior to model to increase readability and debugging\nbatch_size = 64\nepochs = 50","a83795fe":"# Fit the Model\nhistory = model.fit_generator(datagen.flow(x_train, y_train, batch_size = batch_size), epochs = epochs, \n                              validation_data = (x_test, y_test), verbose=1, \n                              steps_per_epoch=x_train.shape[0] \/\/ batch_size,\n                              callbacks = [reduce_lr, early_stopping]) #maybe add early_stopping here as well","29746be0":"plt.figure(figsize=(13, 5))\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(['Train','Test'])\nplt.grid()\nplt.show()","f977a82b":"score = model.evaluate(x_test,y_test,verbose=0)\nprint('Test Loss : {:.4f}'.format(score[0]))\nprint('Test Accuracy : {:.4f}'.format(score[1]))","81744ecf":"Data Augmentation is super important here, as we can \"increase the number of images our model sees\"\n\nIe. Rotate the Image, Flip the Image, Zoom on the Image, Change light conditions, Crop the image and more.\n\n- Our data augmentation techniques here will be interesting as the images have some degree of variability. It will be interesting to see how different augmentation techniques will affect the images.\n\n","5824412d":"### Encoding Labels\n\nLike the MNIST Digit recognition task we have labels between 0-9.\n\nWe can onehot encode them to look like the following example.\n>6 looks like this: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]","37a794a4":"# Model Evaluation","c5df5947":"### looking at a few image examples","36d05e01":"As we can see above the images in this dataset are somewhat complex compared to the original MNIST Digit Recognizer task, and fashion items in the same category have some degree of variability. \n\nFor example above, there are multiple pictures of sandals and sneakers. Some of these have higher arches, different straps and a slightly different shade.","8ec53e89":"### Reshaping the Images\n\nLike in MNIST Digit recognition we need to reshape our images before passing them to a CNN. \n\nLucky for us these are this data has the same image size and structure as the MNIST Digit Recognition images (28x28 grayscale).\n\n- Number of channels is set to 1 as the image is greyscale. If this was RGB images we would have past 3 instead.\n- Note that we are passing -1 as the first parameter as we want numpy to figure out the number of examples(images) that we are passing. ","64b57092":"### Data Augmentation","5e0a0de4":"# Data Preprocessing","9cfd85a0":"# Putting together CNN","9daeb26f":"I dont think the following cell makes a difference, I think if we define it in the model that is all we have to do.","a8c9068a":"Evaluating the final model score","8a2a01e8":"### Learning Rate Decay + Early Stopping","0adfc5c7":"### Normalize Data\n\nPixel values are often stored as integers in the range 0 to 255. We can divide by the max value (255 in this case) to set all values between 0-1.","6efc06c9":"# Fitting the Model","1c651c2e":"# Compile Model","485bebcf":"I completed the MNIST digit recognition task, and I wanted to try and apply what I learned with that dataset to another computer vision task.\n\nThe Fashion MNIST dataset provides a more diverse image dataset, but does not get overly complex.\n\nAll  constructive comments and criticisms are welcome!","47b9092f":"From the dataset metadata we are told that the following numbers corresepond to the numerical labels.\n\n- 0 T-shirt\/top\n- 1 Trouser\n- 2 Pullover\n- 3 Dress\n- 4 Coat\n- 5 Sandal\n- 6 Shirt\n- 7 Sneaker\n- 8 Bag\n- 9 Ankle boot","df7b0368":"# Load Data"}}