{"cell_type":{"eb4cb5f3":"code","60433b13":"code","babbcdd7":"code","5d0e4825":"code","327e7a27":"code","5afdb995":"code","34ae907c":"code","04cac7d6":"code","b29fe05b":"code","3e7f95ad":"code","bbc430aa":"code","c0fcb89c":"code","7372d704":"code","163a0f7b":"code","440ed3c4":"code","fa715574":"code","cc6375cb":"code","69591955":"code","8687f0cc":"code","b2d45ee2":"code","4f2b50c4":"code","2435a03a":"code","04707d7c":"code","bbafe620":"code","26d84ab8":"code","10099821":"code","2cd119b6":"code","25379f71":"markdown","a681903d":"markdown","bd434ee3":"markdown","c4b81c60":"markdown","26f3092d":"markdown","02cfd932":"markdown","5f2a4dfb":"markdown","fd79e901":"markdown","81a3d37f":"markdown","5b27f840":"markdown","9699dcb8":"markdown","17b1ba8d":"markdown","e9ac2de7":"markdown","620e4cf6":"markdown","aeb4abec":"markdown","6d18e7d7":"markdown","d14be5e0":"markdown","934e0f7f":"markdown","1338fa25":"markdown"},"source":{"eb4cb5f3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2 # opencv\n#from mtcnn.mtcnn import MTCNN\nfrom matplotlib import pyplot as plt\nfrom keras.models import load_model\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","60433b13":"# extract a single face from a given photograph\ndef extract_face(filename, required_size=(160, 160)):\n    # load image from file\n    image = Image.open(filename)\n    # convert to RGB, if needed\n    image = image.convert('RGB')\n    # convert to array\n    pixels = np.asarray(image)\n# resize pixels to the model size\n    image = Image.fromarray(pixels)\n    image = image.resize(required_size)\n    face_array = np.asarray(image)\n    return face_array","babbcdd7":"img = extract_face('\/kaggle\/input\/masked-unmasked-mixed\/mixed_2_3\/mixed\/train\/chenhe\/1_0_chenhe_0195.jpg')\nplt.imshow(img, cmap = 'gray', interpolation = 'bicubic')\n#plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\nplt.show()\nprint(img.shape)","5d0e4825":"def load_face(dir):\n    faces = list()\n    # enumerate files\n    for filename in os.listdir(dir):\n        path = dir + filename\n        face = extract_face(path)\n        faces.append(face)\n    return faces\n\ndef load_dataset(dir):\n    # list for faces and labels\n    X, y = list(), list()\n    for subdir in os.listdir(dir):\n        path = dir + subdir + '\/'\n        faces = load_face(path)\n        labels = [subdir for i in range(len(faces))]\n        # print(\"loaded %d sample for class: %s\" % (len(faces),subdir) ) # print progress\n        X.extend(faces)\n        y.extend(labels)\n    return np.asarray(X), np.asarray(y)","327e7a27":"# load train dataset\ntrainX, trainy = load_dataset('\/kaggle\/input\/masked-unmasked-mixed\/mixed_2_3\/mixed\/train\/')\nprint(trainX.shape, trainy.shape)","5afdb995":"trainx, valid = train_test_split(trainX, test_size=0.1, random_state=42, shuffle=True)","34ae907c":"\nprint(\"number of image in train dataset : %s\" %(len(trainx)))\n\nprint(\"number of image in validation dataset : %s\" %(len(valid)))","04cac7d6":"y_train, y_valid = train_test_split(trainy, test_size=0.1, random_state=42, shuffle=True)","b29fe05b":"print(\"number of image in train dataset : %s\" %(len(y_train)))\n\nprint(\"number of image in validation dataset : %s\" %(len(y_valid)))","3e7f95ad":"# load train dataset\ntestX, testy = load_dataset('\/kaggle\/input\/masked-unmasked-mixed\/mixed_2_3\/mixed\/test\/')\nprint(testX.shape, testy.shape)","bbc430aa":"# save and compress the dataset for further use\nnp.savez_compressed('extracted_masked_unmasked.npz', trainx, y_train, valid, y_valid,testX, testy)","c0fcb89c":"data = np.load('extracted_masked_unmasked.npz')\ntrainx, y_train, valid, y_valid,testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3'], data['arr_4'], data['arr_5']\nprint('Loaded: ', trainx.shape, y_train.shape, valid.shape, y_valid.shape,testX.shape, testy.shape)","7372d704":"facenet_model = load_model('\/kaggle\/input\/facenet\/keras-facenet\/model\/facenet_keras.h5')\nprint('Loaded Model')","163a0f7b":"print('Loaded: ', trainx.shape, y_train.shape, valid.shape, y_valid.shape,testX.shape, testy.shape)","440ed3c4":"def get_embedding(model, face):\n    # scale pixel values\n    face = face.astype('float32')\n    # standardization\n    mean, std = face.mean(), face.std()\n    face = (face-mean)\/std\n    # transfer face into one sample (3 dimension to 4 dimension)\n    sample = np.expand_dims(face, axis=0)\n    # make prediction to get embedding\n    yhat = model.predict(sample)\n    return yhat[0]","fa715574":"emdTrainX = list()\nfor face in trainx:\n    emd = get_embedding(facenet_model, face)\n    emdTrainX.append(emd)\nemdTrainX = np.asarray(emdTrainX)\nprint(emdTrainX.shape)\nembValid = list()\nfor face in valid:\n    emd = get_embedding(facenet_model,face)\n    embValid.append(emd)\nembValid = np.asarray(embValid)","cc6375cb":"emdTestX = list()\nfor face in testX:\n    emd = get_embedding(facenet_model, face)\n    emdTestX.append(emd)\nemdTestX = np.asarray(emdTestX)\nprint(emdTestX.shape)\n","69591955":"# save arrays to one file in compressed format\nnp.savez_compressed('embeddings_masked.npz', emdTrainX, y_train, embValid, y_valid, emdTestX, testy)","8687f0cc":"data = np.load('embeddings_masked.npz')\nemdTrainX, y_train, embValid, y_valid, emdTestX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3'], data['arr_4'], data['arr_5']","b2d45ee2":"print('Loaded: ', emdTrainX.shape, y_train.shape, embValid.shape, y_valid.shape, emdTestX.shape, testy.shape)","4f2b50c4":"from sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.svm import SVC\nimport pickle\nprint(\"Dataset: train=%d,validation = %d, test=%d\" % (emdTrainX.shape[0],embValid.shape[0] ,emdTestX.shape[0]))\n# normalize input vectors\nin_encoder = Normalizer(norm='l2')\nemdTrainX_norm = in_encoder.transform(emdTrainX)\nembValid_norm = in_encoder.transform(embValid)\nemdTestX_norm = in_encoder.transform(emdTestX)\n# label encode targets\nout_encoder = LabelEncoder()\n#encoder_arr = np.append (y_train, 'chenderong')\nout_encoder.fit(y_train)\n\n","2435a03a":"trainy_enc = out_encoder.transform(y_train)\ny_valid_enc = out_encoder.transform(y_valid)\ntesty_enc = out_encoder.transform(testy)","04707d7c":"# fit model\nmodel = SVC(kernel='linear', probability=True)\n#model = SVC(kernel='poly', probability=True)\n#model = SVC(kernel='rbf', probability=True)\nmodel.fit(emdTrainX_norm, trainy_enc)","bbafe620":"# predict\nyhat_valid = model.predict(embValid_norm)\nyhat_test = model.predict(emdTestX_norm)\n# score\nscore_valid = accuracy_score(y_valid_enc, yhat_valid)\nscore_test = accuracy_score(testy_enc, yhat_test)\n# summarize\nprint('Accuracy: train=%.3f, test=%.3f' % (score_valid*100, score_test*100))","26d84ab8":"filename = 'linear.sav'\npickle.dump(model, open(filename, 'wb'))\n#filename = 'poly.sav'\n#pickle.dump(model, open(filename, 'wb'))\n#filename = 'rbf.sav'\n#pickle.dump(model, open(filename, 'wb'))","10099821":"loaded_model = pickle.load(open('linear.sav', 'rb'))","2cd119b6":"from random import choice\nfor i in range(30):\n    # select a random face from test set\n    selection = choice([i for i in range(testX.shape[0])]) \n    random_face = testX[selection]\n    random_face_emd = emdTestX_norm[selection]\n    random_face_class = testy_enc[selection]\n    random_face_name = out_encoder.inverse_transform([random_face_class])\n    # prediction for the face\n    samples = np.expand_dims(random_face_emd, axis=0)\n    yhat_class = loaded_model.predict(samples)\n    yhat_prob = loaded_model.predict_proba(samples)\n    class_index = yhat_class[0]\n    if class_index <= 75:\n        # get name\n        class_probability = yhat_prob[0,class_index] * 100\n        if class_probability > 10.0:\n            predict_names = out_encoder.inverse_transform(yhat_class)\n            #print('Predicted: %s (%.3f)' % (predict_names[0], class_probability))\n            #if random_face_name[0] == predict_names[0]:\n            print('Predicted: %s (%.3f)' % (predict_names[0], class_probability))\n            print('Expected: %s' % random_face_name[0])\n            # plot face\n            plt.imshow(random_face)\n            title = '%s (%.3f)' % (predict_names[0], class_probability)\n            plt.title(title)\n            plt.show()","25379f71":"### Load Saved Compressed Dataset","a681903d":"## Label Encoding","bd434ee3":"## Result Examples","c4b81c60":"### Load Model","26f3092d":"### Convert Each Face in the Train Set into Embedding","02cfd932":"### Load saved compressed file","5f2a4dfb":"### Convert Each Face in the Test Set into Embedding","fd79e901":"### Compress and Save Train and Test Dataset\n#### > Note: After face extraction process, train and dataset may occupy memory and there might be memorry error. The reason of this process is to deal with this issue . ","81a3d37f":"## Extract Faces","5b27f840":"# Face Recognition with FaceNet Embedding and Support Vector Classification (SVC) Models\n## Pipeline:\n1. Extract Faces\n2. Face Embeddings with FaceNet\n3. Label Encoding \n4. Face Classification with SVC","9699dcb8":"### Load Test Dataset","17b1ba8d":"## Face Classification with SVC\n#### > Note 1: In SVC, different kernels can be used for multiclass classification. These kernels are : linear, polynomial,  radial basis function (rbf). The kernel is a method or function which is used for linear classification for nonlinear problems or classification. As a default rbf are used; however, in the model, linear is used to make classification process faster since rbf works more slowly. \n\n#### > Note 2: If you want you can use other kernels, I write their code to use them as comment.","e9ac2de7":"### Example","620e4cf6":"### Save Model","aeb4abec":"## Load Train and Test Dataset\n### Load Train Dataset","6d18e7d7":"#### > Note: Normally, In this part of the pipeline, MTCNN library are used; however, faces cannot be detected by MTCNN because of weared mask.","d14be5e0":"## Face Embeddings with FaceNet\n### Load Model","934e0f7f":"### Compress and Save Train and Test Embeddings ","1338fa25":"### Encoding Trainy and Testy with Fitted Encoder"}}