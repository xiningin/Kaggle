{"cell_type":{"2d8e3a52":"code","8c0393d8":"code","e041f0ec":"code","66c76e50":"code","d2c1021e":"code","9d3b58b4":"code","9ffb8b30":"code","3f155f5e":"code","cb7a25ce":"markdown","d9e0dcf6":"markdown","6f40c08a":"markdown","82e25696":"markdown","d2d53cc0":"markdown","8f6e22b9":"markdown","ed026873":"markdown"},"source":{"2d8e3a52":"import time\nfrom sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split\nfrom sklearn.metrics import roc_auc_score, average_precision_score, make_scorer\nfrom sklearn import linear_model, tree, ensemble\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.ensemble import BalancedRandomForestClassifier\nfrom imblearn.pipeline import Pipeline","8c0393d8":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\ndf_train = pd.read_csv('\/kaggle\/input\/desafio-falconi-ii\/train.csv')\ndf_test  = pd.read_csv('\/kaggle\/input\/desafio-falconi-ii\/test.csv')\ndf_sample = pd.read_csv('\/kaggle\/input\/desafio-falconi-ii\/sample_submission.csv')\n\ndf_train.head()","e041f0ec":"import category_encoders as ce\n\ndef feature_engineering(df, is_training=False, encoder=None, target=['churn_reason','churn']):\n    \n    df = df.drop(columns='lat_long')\n    \n    df['total_charges'] = df['total_charges'].replace(' ', 0).astype('float64')\n    \n    categorical_features = df.columns[df.dtypes == 'object'].to_list()\n    \n    if is_training:\n    \n        encoder = ce.OrdinalEncoder(cols=categorical_features)\n        encoder.fit(df)\n    \n    df = encoder.transform(df)\n        \n    return df, encoder\n    \nX_train, encoder = feature_engineering(df_train.drop(columns=['churn_reason', 'churn']), is_training=True)\ny_train = df_train['churn']\nX_test, _ = feature_engineering(df_test, encoder=encoder)","66c76e50":"import matplotlib.pyplot as plt\nplt.hist(y_train)\nplt.show()","d2c1021e":"scorer = 'roc_auc' \n\nmin_samples_leaf=5\nn_estimators=100\ncriterion='entropy'\nmax_depth=np.arange(3,45,5)\nmax_depth=[3,4,5,7,10,15,20,30,50]\nn_folds=5\n\n\nestimators = [\n    (\"Logistic Regression\", 'lgst', \n    linear_model.LogisticRegression(solver='liblinear'), \n    {'C':np.logspace(0,3,4),\n     'penalty':['l1','l2'],\n    }),   \n        \n    (\"Decision Tree\", 'cart',\n     tree.DecisionTreeClassifier(min_samples_leaf=min_samples_leaf,\n                                criterion=criterion),\n    {'max_depth':max_depth,\n     'max_features':[3,5,10,None],\n     'splitter':['best','random'],\n     'criterion':['entropy','gini'],\n    }),\n\n    (\"RandomUnderSampling\", 'rus',\n     Pipeline([('res', RandomUnderSampler()),\n               ('tree', tree.DecisionTreeClassifier(\n                       min_samples_leaf=min_samples_leaf, criterion=criterion))\n               ]),\n    {'tree__max_depth':max_depth,\n    }),\n\n    (\"SMOTE\", 'smt',\n     Pipeline([('res', SMOTE()),\n               ('tree', tree.DecisionTreeClassifier(\n                       min_samples_leaf=min_samples_leaf, criterion=criterion))\n               ]),\n    {'tree__max_depth':max_depth,\n    }),\n\n    (\"BalancedRandomForest\", 'brf',\n    BalancedRandomForestClassifier(n_estimators=n_estimators,\n                                   min_samples_leaf=min_samples_leaf,\n                                   criterion=criterion),\n    {'max_depth':max_depth,\n     }),\n    \n    (\"RandomForest\", \"rf\",\n     ensemble.RandomForestClassifier(n_estimators=n_estimators,\n            min_samples_leaf=min_samples_leaf, criterion=criterion),\n    {'max_depth':max_depth,\n    }),\n\n    (\"GradientBoosting\", \"gb\",\n     ensemble.GradientBoostingClassifier(n_estimators=n_estimators,\n            min_samples_leaf=min_samples_leaf),\n    {'max_depth':[10,],\n    }),\n]","9d3b58b4":"n_runs=10\n\nmodels = []\n\nfor est_full_name, est_name, est, params in estimators:\n    print ('\\n%s\\n%s\\n' % ('-'*25, est_full_name))\n    print ('Run\\tEst\\tScore\\tBest parameters')\n    t0 = time.time()\n    for run in range(n_runs):\n        kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=int(run*9))\n        gs = GridSearchCV(est, params, cv=kf, scoring=scorer, verbose=0,n_jobs=-1)  \n \n        gs.fit(X_train, y_train)\n    \n        print (f\"{run}\\t{est_name}\\t{gs.best_score_}\\t{gs.best_params_}\")\n        \n        models.append(gs.best_estimator_)","9ffb8b30":"predictions = []\n\nfor model in models:\n    \n    y_prob = model.predict_proba(X_test)[:,1]\n    predictions.append(y_prob)\n    \nstack_prediction = np.median(np.array(predictions), axis=0)","3f155f5e":"df_submission = pd.DataFrame(stack_prediction, columns=['predict_probability'], index=df_test['client_id'])\ndf_submission.to_csv('submission.csv')\ndf_submission.head()","cb7a25ce":"### Sele\u00e7\u00e3o de modelos\n\nA boa pr\u00e1tica \u00e9 explorar a maior familia de modelos poss\u00edvel quando n\u00e3o conhecemos o problema.\n\nAbaixo deixei apenas os modelos de regress\u00e3o log\u00edstica (linear) e alguns outros baseados em \u00e1rvores de decis\u00e3o e ensembles de \u00e1rvores de decis\u00e3o.\n\nSintam-se a vontade em adicionar\/alterar os modelos abaixo.","d9e0dcf6":"### Stacking (meta-ensemble)\n\n\u00c9 muito comum utilizarmos a predi\u00e7\u00e3o de v\u00e1rios modelos treinados para gerar a predi\u00e7\u00e3o.\n\nPara isso voc\u00ea pode treinar um modelo que escolhe qual modelo de base melhor prev\u00ea uma inst\u00e2ncia, ou simplesmente agrupar as predi\u00e7\u00f5es a partir de alguma agrega\u00e7\u00e3o estat\u00edstica (m\u00e9dia, mediana) de todas as predi\u00e7\u00f5es.\n\n\u00c9 o mesmo conceito do boosting\/bagging, por\u00e9m aplicado entre modelos.\n\nPra exemplificar fiz a mediana de todos os modelos treinados acima.","6f40c08a":"### Ajuste de hiper-par\u00e2metros\n\nAqui iremos avaliar o desempenho dos modelos escolhidos, e salvar todos eles em uma lista para depois conseguirmos resgat\u00e1-los mais facilmente.\n\n\nO **n_runs** define quantos modelos\/simula\u00e7\u00f5es ser\u00e3o treinados.","82e25696":"## Feature engineering\n\nO \u00fanico pr\u00e9-processamento que fiz at\u00e9 agora foi codificar vari\u00e1veis de texto para valores inteiros, para que possa alimentar os algoritmos de classifica\u00e7\u00e3o. Ex.: ['Client A', 'Client B', 'Client C'] -> [1, 2, 3]\n\nS\u00f3 quero mostrar que j\u00e1 \u00e9 poss\u00edvel bons resultados com quase nenhum pr\u00e9-processamento, mas indico que invistam a maior parte do seu tempo nessa etapa, que \u00e9 onde conseguimos melhorar mais nossos modelos.","d2d53cc0":"### A classe que queremos prever \u00e9 realmente desbalanceada?\n\nNesse caso, at\u00e9 que a base n\u00e3o parece t\u00e3o desbalanceada: temos cerca de 4k de casos de incid\u00eancia de n\u00e3o-churn, contra 1,5k de churn. Isso d\u00e1 uma propor\u00e7\u00e3o de +- 2:1.\n\nExistem algumas bases de dados que essa propor\u00e7\u00e3o pode chegar a 10:1, 100:1, at\u00e9 1000:1.","8f6e22b9":"### Aprendizado desabalanceado\n\n\nFiz esse notebook para testar alguns modelos pr\u00f3prios para problemas de aprendizado desbalanceado. Fiz usando uma adapta\u00e7\u00e3o da minha pesquisa de mestrado que foi nesse tema. Adicionei o link do c\u00f3digo original e do artigo, caso tenham interesse em ler mais sobre os modelos testados aqui.\n\nPrincipais conclus\u00f5es:\n\n1. Abordagens de bagging tiveram resultados melhor do que boosting.\n2. Embora o problema de churn n\u00e3o seja t\u00e3o desbalanceado, o balanceamento de classes (BalancedRandomForest) ajudou a melhorar a acur\u00e1cia dos modelos.\n3. A regress\u00e3o log\u00edstica teve um resultado bem pr\u00f3ximo dos modos mais complexos! Talvez abordagens mais simples e explic\u00e1veis (white box) sejam suficiente para esse problema, devido o tamanho da base.\n\nAtualiza\u00e7\u00f5es:\n\n- Rev 5. Atualizado feature engineering para considerar vari\u00e1vel total_charges como num\u00e9rica.\n\n[Reposit\u00f3rio no GitHub](https:\/\/github.com\/rodrigosantis1\/backorder_prediction)\n\n\n[De Santis, Rodrigo Barbosa; De Guiar, Eduardo Pestana; Goliatt, Leonardo. Predicting material backorders in inventory management using machine learning. In: 2017 IEEE Latin American Conference on Computational Intelligence (LA-CCI). IEEE, 2017. p. 1-6.](https:\/\/www.researchgate.net\/publication\/319553365_Predicting_Material_Backorders_in_Inventory_Management_using_Machine_Learning?_sg=jgF4HW0RqOEPEDeiVPlMOJ_JYytazaFkHanlX5r0OvcZFWEd-NV-hYjtsQbq2A3furqfi4ydph9ArVltQDW8zNmmuZZMlG_FD6xEN-yC.Fwm7HcbDnNJ4gWvk36yVOrOXGFkTVUajCh6pX9ERizd9D9RkOyB6CSxrZ80hAfSCjH2f4CTNFA6jV7OcqA3qWg)\n\n\n\n\n","ed026873":"## Leitura das bases"}}