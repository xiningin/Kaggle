{"cell_type":{"04ef0592":"code","77f95d7d":"code","ed168665":"code","b71b399c":"code","1b08009e":"code","125b953a":"code","72bfca93":"code","f118d327":"code","bdc1fe10":"code","ff8348d1":"code","e86a9710":"code","b172fdac":"code","8369c4aa":"code","498be62d":"code","5e2d3ffe":"code","691f18be":"code","535d6cbf":"code","af219cea":"code","b4231e5c":"code","975a5ac5":"code","7710258d":"code","a8fc6676":"code","0ee6ab12":"code","26d7881d":"code","e2d0e970":"code","51c3714b":"code","be64fb46":"code","c848da61":"code","8ec68b5e":"code","61c962bd":"code","f4ef438b":"code","27778690":"code","0b4747c9":"code","85701d27":"markdown","6eae7180":"markdown"},"source":{"04ef0592":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","77f95d7d":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px \n\nimport warnings\n\nwarnings.simplefilter(action='ignore')","ed168665":"df = pd.read_csv(r'..\/input\/travel-insurance-prediction-data\/TravelInsurancePrediction.csv')\ndf.shape","b71b399c":"data = df.copy()","1b08009e":"data.isna().sum()","125b953a":"data.info()","72bfca93":"data.drop('Unnamed: 0', axis=1, inplace=True)","f118d327":"data.head()","bdc1fe10":"def pie_chart(cols):\n    \"\"\" \n    A funtion for plotting a pir chart of all the distinct\n    value present in the dataset wrt to a certain column\n    \n    \"\"\"\n    for i in cols:\n        values = data[i].value_counts()\n        labels = data[i].value_counts().index    \n        \n        fig = px.pie(data, names=labels, values=values, hole=.3, color_discrete_sequence = ['pink', 'red'])\n        fig.update_layout(title=f'Distribution based on {i}', template='plotly_dark', hoverlabel=dict(\n            font_size=18,\n            font_family='Arial',\n        ))\n        fig.update_traces(hovertemplate='Count of %{label}: %{value}')\n        fig.show()","ff8348d1":"pie_list = [i for i in data.columns[:-1] if len(data[i].value_counts()) < 20] # list of columns having less than 20 unique values\npie_list  ","e86a9710":"pie_chart(pie_list)","b172fdac":"data.head()","8369c4aa":"plt.figure(figsize=(8, 6))\nsns.distplot(data['AnnualIncome'])\nplt.show()","498be62d":"from sklearn.preprocessing import LabelEncoder, Normalizer, MinMaxScaler, StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nfrom imblearn.over_sampling import RandomOverSampler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\n\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix","5e2d3ffe":"data['TravelInsurance'].value_counts()","691f18be":"obj_cols = [i for i in data.columns if data[i].dtype == 'O']\nobj_cols","535d6cbf":"label_enc = LabelEncoder()","af219cea":"for i in obj_cols:\n    data[i] = label_enc.fit_transform(data[i])","b4231e5c":"data.head()","975a5ac5":"X = data.iloc[:, :-1]\ny = data['TravelInsurance']","7710258d":"ros = RandomOverSampler(random_state=42)","a8fc6676":"x_ros, y_ros = ros.fit_resample(X, y)\ny_ros.value_counts()","0ee6ab12":"x_ros.head()","26d7881d":"x_ros.shape","e2d0e970":"def normalizer(x_train, x_test):\n    scaler = Normalizer()\n    x_train = scaler.fit_transform(x_train)\n    x_test = scaler.transform(x_test)\n    return x_train, x_test","51c3714b":"def standardscaler(x_train, x_test):\n    scaler = StandardScaler()\n    x_train = scaler.fit_transform(x_train)\n    x_test = scaler.transform(x_test)\n    \n    return x_train, x_test","be64fb46":"def minmax(x_train, x_test):\n    scaler = MinMaxScaler()\n    x_train = scaler.fit_transform(x_train)\n    x_test = scaler.transform(x_test)\n    return x_train, x_test","c848da61":"def best_model(X, y, scaler, algo):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=True)\n    \n    X_train = np.asarray(X_train)\n    X_test = np.asarray(X_test)\n        \n    X_train, X_test = scaler(X_train, X_test)\n    \n    y_train = np.asarray(y_train)\n    y_test = np.asarray(y_test)\n    \n    model = algo()\n    model.fit(X_train, y_train)\n    predictions = model.predict(X_test)\n    \n    training_score = model.score(X_train, y_train)\n    acc = accuracy_score(y_test, predictions)\n    con = confusion_matrix(y_test, predictions)\n    report = classification_report(y_test, predictions)\n    print(f'Training Score: {training_score}')\n    print(f'Accuracy Score: {acc}')\n    print(f'Confusion Matrix: {con}')\n    print(f'Classification Report: {report}')\n    return acc, training_score","8ec68b5e":"list_algo = [LogisticRegression, KNeighborsClassifier, DecisionTreeClassifier, RandomForestClassifier, XGBClassifier]\n\nlist_of_accuracy = []\nlist_of_score = []\n\nfor i in list_algo:\n    accuracyscore, trainingscore = best_model(x_ros, y_ros, normalizer, i)\n    list_of_accuracy.append(accuracyscore)\n    list_of_score.append(trainingscore) ","61c962bd":"list_of_accuracy1 = []\nlist_of_score1 = []\nfor i in list_algo:\n    accuracyscore, trainingscore = best_model(x_ros, y_ros, standardscaler, i)\n    list_of_accuracy1.append(accuracyscore)\n    list_of_score1.append(trainingscore)    ","f4ef438b":"list_of_accuracy2 = []\nlist_of_score2 = []\nfor i in list_algo:\n    accuracyscore, trainingscore = best_model(x_ros, y_ros, minmax, i)\n    list_of_accuracy2.append(accuracyscore)\n    list_of_score2.append(trainingscore)  ","27778690":"acc_df = pd.DataFrame()\nacc_df['Algo'] = ['LogisticRegression', 'KNeighborsClassifier', 'DecisionTreeClassifier', 'RandomForestClassifier', 'XGBClassifier']\nacc_df['normazlier_acc'] = list_of_accuracy\nacc_df['normazlier_training'] = list_of_score\nacc_df['standard_acc'] = list_of_accuracy1\nacc_df['standard_training'] = list_of_score1\nacc_df['minmax_acc'] = list_of_accuracy2\nacc_df['minmax_training'] = list_of_score2\nacc_df","0b4747c9":"fig = px.line(acc_df, x='Algo', y = ['normazlier_acc', 'standard_acc', 'minmax_acc'])\nfig.update_layout(template='plotly_dark')\nfig.show()","85701d27":"Checking for outliers in the Annual Income column","6eae7180":"## EDA"}}