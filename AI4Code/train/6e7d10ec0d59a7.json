{"cell_type":{"5abaca6a":"code","4609ca31":"code","e289b482":"code","6e520259":"code","d93a70c0":"code","d69769fc":"code","8e7f4f31":"code","a494a39f":"code","646ba46b":"code","853cf82d":"code","5cb87c9a":"code","9d6dbe11":"code","7ba71bbe":"code","7faa676c":"code","a886e512":"code","986b59b3":"code","5c838eaf":"code","f43f1068":"code","cd6d0be9":"markdown","33e50c2b":"markdown","2ba056ed":"markdown","06736103":"markdown","e4e98890":"markdown","ed8a119f":"markdown","59319be2":"markdown"},"source":{"5abaca6a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4609ca31":"!python","e289b482":"import numpy as np\nimport cv2\nimport os","6e520259":"def readfile(path,label):\n    img_dir = sorted(os.listdir(path))\n    x = np.zeros((len(img_dir),128,128,3),dtype = np.uint8) # \u56fe\u7247\u5b58\u5728\u8fd9\u4e2a\u7ef4\u5ea6\n    y = np.zeros(len(img_dir),dtype = np.uint8) # \u6807\u7b7e\n    for i , file in enumerate(img_dir):\n        x [i,:,:] = cv2.resize(cv2.imread(os.path.join(path,file)),(128,128))\n        if label:\n            y[i] = int(file.split('_')[0])\n    if label:\n        return x, y\n    else:\n        return y","d93a70c0":"workspace_dir ='\/kaggle\/input\/ml2020spring-hw3\/food-11\/'\nprint(\"Reading data\")\ntrain_x , train_y = readfile(os.path.join(workspace_dir,\"training\"),True)\nprint(\"Size of training data = {}\".format(len(train_x)))\nval_x , val_y = readfile(os.path.join(workspace_dir,\"validation\"),True)\nprint(\"Size of validation data = {}\".format(len(val_x)))\ntest_x = readfile(os.path.join(workspace_dir,'testing'),False)\nprint(\"Size of Testing data = {}\".format(len(test_x)))","d69769fc":"import torchvision.transforms as transforms","8e7f4f31":"train_transform = transforms.Compose([\n    transforms.ToPILImage(),# \n    transforms.RandomHorizontalFlip(), #\u6c34\u5e73\u7ffb\u8f6c\n    transforms.RandomRotation(15), # \u968f\u673a\u65cb\u8f6c\n    transforms.ToTensor(),\n])\n\ntest_transform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.ToTensor(),\n])","a494a39f":"from torch.utils.data import DataLoader,Dataset","646ba46b":"class ImgDataset(Dataset):\n    def __init__(self,x,y=None,transform=None):\n        self.x = x\n        self.y = y\n        if y is not None:\n            self.y = torch.LongTensor(y)\n        self.transform = transform\n    def __len__(self):\n        return len(self.x)\n    def __getitem__(self,index):\n        X = self.x[index]\n        if self.transform is not None:\n            X = self.transform(X)\n        if not self.y:\n            Y = self.y[index]\n            return X,Y\n        else:\n            return X","853cf82d":"import torch","5cb87c9a":"dir(torch.nn)","9d6dbe11":"batch_size = 128\ntrain_set = ImgDataset(train_x,train_y,train_transform) # \u5b9e\u4f8b\u5316train_set\nval_set = ImgDataset(val_x,val_y,test_transform)\ntrain_loader = DataLoader(train_set,batch_size = batch_size,shuffle = True)\nval_loader = DataLoader(val_set,batch_size = batch_size,shuffle=False)\n","7ba71bbe":"import torch.nn as nn","7faa676c":"class Classifier(nn.Module):\n    def __init__(self):\n        super(Classifier,self).__init__()\n        self.cnn = nn.Sequential(\n            nn.Conv2d(3,64,3,1,1), #[64,128,128]\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(2,2,0), #[64,64,64]\n            \n            nn.Conv2d(64,128,3,1,1), # [128,64,64]\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(2,2,0),\n            \n            nn.Conv2d(128, 256, 3, 1, 1), # [256, 32, 32]\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2, 0),      # [256, 16, 16]\n\n            nn.Conv2d(256, 512, 3, 1, 1), # [512, 16, 16]\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2, 0),       # [512, 8, 8]\n            \n            nn.Conv2d(512, 512, 3, 1, 1), # [512, 8, 8]\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2, 0),       # [512, 4, 4]\n        )\n        self.fc = nn.Sequential(\n            nn.Linear(512*4*4,1024),\n            nn.ReLU(),\n            nn.Linear(1024,512),\n            nn.ReLU(),\n            nn.Linear(512,11)\n        )\n    def forward(self,x):\n        out = self.cnn(x)\n        out = out.view(out.size()[0],-1)\n        return self.fc(out)","a886e512":"torch.cuda.is_available()","986b59b3":"model  = Classifier().cuda()  # \u6a21\u578b\u4e5f\u8981\u8f6c\u6210cuda\nloss = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(),lr = 0.001)\nnum_epoch = 30\nfor epoch in range(num_epoch):\n    epoch_stat_time = time.time()\n    train_acc = 0.0\n    train_loss = 0.0\n    val_acc = 0.0\n    val_loss = 0.0\n    model.train()\n    for i , data in enumerate(train_loader):\n        optimizer.zero_grad()\n        train_pred = model(data[0].cuda())\n        batch_loss = loss(train_pred , cuda[1].cuda() )\n        batch_loss.backward()\n        optimizer.step()\n        # \u6700\u5927\u503c\u7684\u7d22\u5f15\uff1a\n        train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(),axis = 1) == data[1].numpy())\n        train_loss += batch_loss.item()\n        \n    model.eval()\n    with torch.no_grad():\n        for i,data in enuemrate(val_loader):\n            val_pred = model(data[0].cuda()) # \u9a8c\u8bc1\u96c6\u7684pred\n            batch_loss = loss(val_pred,data[1].cuda())\n            val_acc += np.sum(np.argmax(val_pred.cpu().data.numpy(),axis = 1) == data[1].numpy())\n            val_loss += batch_loss.item()\n            print('[%03d\/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f' % \\\n            (epoch + 1, num_epoch, time.time()-epoch_start_time, \\\n             train_acc\/train_set.__len__(), train_loss\/train_set.__len__(), val_acc\/val_set.__len__(), val_loss\/val_set.__len__()))\n    ","5c838eaf":"test_set = ImgDataset(test_x,transform = test_transform)\ntest_loader = DataLoader(test_set , batch_size = batch_size ,shuffle=False)","f43f1068":"model_best.eval()\npredicition = []\nwith torch.no_grad():\n    for i,data in enumerate(test_loader):\n        test_pred = model_best(data.cuda())\n        test_label = np.argmax(test_pred.cpu().data.numpy(),axis = 1)\n        for y in test_label:\n            predicition.append(y)","cd6d0be9":"# \u5199\u4e2a\u51fd\u6570\u628a\u56fe\u8bfb\u8fdb\u5927\u6570\u7ec4\u91cc\u9762","33e50c2b":"# mode","2ba056ed":"# \u91cd\u5199Dataset\u7684__len__\u548c__getitem__\u65b9\u6cd5\n","06736103":"## \u7ee7\u627fDataset\uff0c\u5e76\u4e14\u91cd\u51992\u4e2a\u65b9\u6cd5","e4e98890":"## \u5148import \u4e00\u4e0btransform","ed8a119f":"# Training","59319be2":"## \u5b9e\u4f8b\u5316Dataset\u7684\u7c7b\uff0c\u5e76\u4e14\u4e22\u8fdbDataLoader\u4e2d"}}