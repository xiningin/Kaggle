{"cell_type":{"3b901e1b":"code","e0c56fed":"code","23888751":"markdown"},"source":{"3b901e1b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport os\nimport datetime\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom IPython.display import display, HTML\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n#         break\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\nKAGGLE_WORKING_DIR = \"\/kaggle\/working\/\"","e0c56fed":"class HurstExponentAnalysis(object):\n    def __init__(self, file_path: str, n_weeks: list, trending_market_limit: float, mean_reverting_limit: float):\n        self.file_path = file_path\n        self.n_weeks = n_weeks\n        self.trending_market_limit = trending_market_limit\n        self.mean_reverting_limit = mean_reverting_limit\n    \n    def readFileAsDataFrame(self, file_path: str):\n        df = pd.read_csv(file_path)\n        if len(df) < 1:\n            return None\n        df[\"time\"] = [self.unixTimeToDatetime(dt) for dt in df[\"time\"]]\n        df[\"week\"] = [dt.isocalendar()[1] for dt in df[\"time\"]]\n        return df\n    \n    @staticmethod\n    def averageOHLC(record):\n        return (record[\"open\"] + record[\"close\"] + record[\"high\"] + record[\"low\"]) \/ 4\n    \n    def getWeeklySplitTimeseriesDataSplit(self, df: pd.DataFrame):\n        treated_data = list()\n        week_data = list()\n        current_week = None\n        for record in df.to_dict(\"records\"):\n            if current_week is None:\n                current_week = record[\"week\"]\n                week_data.append(self.averageOHLC(record))\n            elif current_week != record[\"week\"]:\n                treated_data.append(week_data)\n                current_week = record[\"week\"]\n                week_data = list()\n                week_data.append(self.averageOHLC(record))\n            else:\n                week_data.append(self.averageOHLC(record))\n        if len(week_data) > 0:\n            treated_data.append(week_data)\n        return treated_data\n\n    @staticmethod\n    def unixTimeToDatetime(unix_time: int):\n        return datetime.datetime.utcfromtimestamp(unix_time \/ 1000)\n    \n    @staticmethod\n    def hurst_exponent(time_series):\n        if time_series is None or len(time_series) < 1:\n            return\n        if type(time_series[0]) == list:\n            # flatten 2d list\n            time_series = [data for week in time_series for data in week]\n        lags = range(2, 100)\n        tau = [np.sqrt(np.std(np.subtract(time_series[lag:], time_series[:-lag]))) for lag in lags]\n        poly = np.polyfit(np.log(lags), np.log(tau), 1)\n        return poly[0]*2.0\n    \n    def getRollingHurstExponentResult(self, weekly_splited_data, week_period):\n        weekly_hurst_exp = list()\n        for i in range(len(weekly_splited_data)):\n            if i < week_period - 1:\n                weekly_hurst_exp.append(np.nan)\n            else:\n                start = i - week_period + 1\n                end = i + 1\n                weekly_hurst_exp.append(self.hurst_exponent(weekly_splited_data[start:end]))\n        return weekly_hurst_exp\n\n    def run(self):\n        self.df = self.readFileAsDataFrame(self.file_path)\n        weekly_splited_data = self.getWeeklySplitTimeseriesDataSplit(self.df)\n        records = dict()\n        colnames = list()\n        for n_week in self.n_weeks:\n            colname = \"%s_week\" % n_week\n            records[colname] = self.getRollingHurstExponentResult(weekly_splited_data, n_week)\n            colnames.append(colname)\n        df = pd.DataFrame.from_dict(records)[colnames]\n        return df\n\n\nN_WEEKS = [1, 2, 5, 8, 13, 26, 52]\nTRENDING_MARKET_LIMIT = 0.6\nMEAN_REVERTING_MARKET_LIMIT = 0.4\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        file_path = os.path.join(dirname, filename)\n        target_file_path = os.path.join(KAGGLE_WORKING_DIR, filename.replace(\".csv\", \"_hurst.csv\"))\n        if not os.path.isfile(target_file_path):\n            he_analysis = HurstExponentAnalysis(\n                file_path, N_WEEKS, TRENDING_MARKET_LIMIT, MEAN_REVERTING_MARKET_LIMIT\n            )\n            resultTable = he_analysis.run()\n            resultTable.to_csv(target_file_path, index=False)\n        else:\n            resultTable = pd.read_csv(target_file_path)\n        with pd.option_context('display.max_rows', 1000, 'display.max_columns', 20):\n            display(resultTable)\n        resultTable.plot()\n        break","23888751":"# What is Hurst Exponent ?\nThe Hurst exponent is used as a measure of long-term memory of time series. It relates to the autocorrelations of the time series and the rate at which these decrease as the lag between pairs of values increases.\n\n### Hurst Value is more than 0.5\n\nIf the Hurst value is more than 0.5 then it would indicate a persistent time series (roughly translates to a trending market).\n\n### Hurst Value is less than 0.5\n\nIf the Hurst Value is less than 0.5 then it can be considered as an anti-persistent time series (roughly translates to sideways market).\n\n### Hurst Value is 0.5\n\nIf the Hurst value is 0.5 then it would indicate a random walk or a market where prediction of future based on past data is not possible.\n\nReference: https:\/\/blog.quantinsti.com\/hurst-exponent\/"}}