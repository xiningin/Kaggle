{"cell_type":{"2673e0f3":"code","507ef772":"code","03f3f50d":"code","457aaa83":"code","31d5d06a":"code","c466f231":"code","3a06aeee":"code","3b676dda":"code","69bb1514":"code","660c2dff":"code","9b337e71":"code","e68fb91f":"code","2055e650":"code","0142176a":"code","53875ff6":"code","a4af46bf":"code","6220b5d6":"code","810a09c5":"code","c7e9b984":"code","902759a7":"code","8fa3034f":"code","0cb48a3f":"code","071594cf":"code","cfd9b9d9":"code","f47cfaa6":"code","fc02be22":"code","89efac87":"code","38902fff":"code","5b9a3839":"code","0f0ac472":"code","8003930d":"code","72b50f45":"code","4180be04":"code","7c3a1a17":"code","c126c75e":"code","630c9289":"code","40232fa7":"code","e9953598":"code","9855f0f2":"code","18ffc202":"code","a045b032":"code","82d6cf23":"code","dc735f3e":"code","5f180bbe":"code","d76cd80b":"code","830c84dc":"code","5977cd22":"code","bd0da6a2":"code","d38976d9":"code","1d165781":"code","23b0e363":"code","087c2880":"code","ec7217eb":"code","0ea5ff79":"code","da8610b8":"code","1b619572":"code","0298d8b8":"code","a5245e2a":"code","9021fdf4":"code","5b4f3d62":"code","db2d1161":"code","f029d2a4":"code","a1e6b907":"code","0e307182":"code","8a4b3bad":"code","36965e67":"code","3869c595":"code","5d232a9b":"code","67600c3d":"code","33ee9bc4":"code","43267d92":"code","cf90c312":"code","6d4afe2f":"code","3af69439":"code","7910238d":"markdown","91c8d57d":"markdown","09e4035c":"markdown","4d63997f":"markdown","6b32b7f1":"markdown","23ba94cb":"markdown","8dfb192e":"markdown","2a24cdcf":"markdown","84e99441":"markdown","6c6920ae":"markdown","602f9071":"markdown","bdc7e20d":"markdown","73213b7e":"markdown","399feb30":"markdown","de449c02":"markdown","f0f1cb83":"markdown","4f2f3ef9":"markdown","80bdc320":"markdown","a2c0b9a0":"markdown","55e3d360":"markdown","50fa7eb0":"markdown","c59d2a2b":"markdown","adabf9e7":"markdown","60433796":"markdown","61047273":"markdown","8c32d364":"markdown","d13fd781":"markdown","d3bc4d8b":"markdown"},"source":{"2673e0f3":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt #visualization\n%matplotlib inline\nimport matplotlib\nmatplotlib.rcParams[\"figure.figsize\"] = (20,15)","507ef772":"# additional imports:\nimport seaborn as sns\nimport re\nimport sys\nfrom time import sleep\nfrom tqdm.notebook import tqdm\nimport warnings;\nwarnings.filterwarnings('ignore');","03f3f50d":"df = pd.read_csv(\"..\/input\/bengaluru-house-price-data\/Bengaluru_House_Data.csv\")","457aaa83":"df.head()","31d5d06a":"df.shape","c466f231":"df.info()","3a06aeee":"df.head()","3b676dda":"df.isnull().sum()","69bb1514":"#Remove unnecessary columns \ndf1 = df.drop(['area_type','society','balcony','availability'],axis='columns')\ndf1.head()","660c2dff":"df1.shape","9b337e71":"df1.isnull().sum()","e68fb91f":"df1 = df1.dropna()\ndf1.isnull().sum()","2055e650":"# lets check 'size' column\ndf1['size'].unique()","0142176a":"# FUNCTION to remove string from row values.\n# Nan values will be replaced by 0\ndef remove_string(x):\n    x = str(x)\n    if x == 'nan':\n        x = np.NaN\n    else:\n        x = int(x.split(\" \")[0])\n    return x","53875ff6":"# We create new column for the cleaned values of size column:\ndf1['BHK'] = df1['size'].apply(lambda x: remove_string(x))","a4af46bf":"df1['BHK'].unique()","6220b5d6":"df1[df1.BHK > 20]","810a09c5":"df1.isnull().sum()","c7e9b984":"df1.total_sqft.unique()","902759a7":"# Function to catch all non numeric and abnormal values:\ndef catch_abnormal_val(series):\n    err_val = []\n    for x in series:\n        try:\n            float(x)\n        except:\n            err_val.append(x)\n    return err_val","8fa3034f":"catch_abnormal_val(df1['total_sqft'])","0cb48a3f":"# Lets modify the range format values first:\n# function that will identfy range format values and convert them to single float value:\ndef convert_rng_val(x):\n    values = x.split('-')\n    if len(values) == 2:\n        return (float(values[0])+float(values[1]))\/2 #return float mean value of range\n    try:\n        return float(x) #return remaining values in float.\n    except:\n        return x #return other abnormal value as it is.","071594cf":"print(convert_rng_val('1200'))\nprint(convert_rng_val('1200-2349'))\nprint(convert_rng_val('1200sqft. Meter'))","cfd9b9d9":"def sqmt_to_sqft(x):\n    \"\"\"convert sq.meters to sqft\"\"\"\n    return x * 10.764\n\ndef sqyards_to_sqft(x):\n    \"\"\"convert sq.yards to sqft\"\"\"\n    return x * 9\n\ndef gunta_to_sqft(x):\n    \"\"\"convert gunta to sqft\"\"\"\n    return x * 1089\n\ndef acres_to_sqft(x):\n    \"\"\"convert acres to sqft\"\"\"\n    return x * 43560\n\ndef perch_to_sqft(x):\n    \"\"\"convert perch to sqft\"\"\"\n    return x * 272.25\n\ndef grounds_to_sqft(x):\n    \"\"\"convert grounds to sqft\"\"\"\n    return x * 2400\n\ndef cents_to_sqft(x):\n    \"\"\"convert cents to sqft\"\"\"\n    return x * 435.6","f47cfaa6":"def clean_total_sqft(y):\n    try:\n        y = float(y)\n    except:\n        if \"-\" in y:\n            y = round(convert_rng_val(y),1)\n        elif \"Sq. Meter\" in y:\n            y = round(sqmt_to_sqft(float(re.findall('\\d+',y)[0])),1)\n        elif \"Sq. Yards\" in y:\n            y = sqyards_to_sqft(float(re.findall('\\d+',y)[0]))\n        elif \"Guntha\" in y:\n            y = gunta_to_sqft(float(re.findall('\\d+',y)[0]))\n        elif \"Acres\" in y:\n            y = acres_to_sqft(float(re.findall('\\d+',y)[0]))\n        elif \"Perch\" in y:\n            y = perch_to_sqft(float(re.findall('\\d+',y)[0]))\n        elif \"Grounds\" in y:\n            y = grounds_to_sqft(float(re.findall('\\d+',y)[0])) \n        elif \"Cents\" in y:\n            y = round(cents_to_sqft(float(re.findall('\\d+',y)[0])),1)\n        return y\n    return y","fc02be22":"clean_total_sqft(\"13Sq. Yards\")","89efac87":"# Lets clean our column and create a cleaned version of it:\ndf1['total_sqft_cleaned'] = df1['total_sqft'].apply(lambda x : clean_total_sqft(x))\n# lets check for abnormal values now :\ncatch_abnormal_val(df1['total_sqft_cleaned'])","38902fff":"# Remove unecessary columns:\ndf2 = df1.drop(['size','total_sqft'], axis=1)","5b9a3839":"df2.head()","0f0ac472":"df3 = df2.copy()","8003930d":"df3['location'].unique()","72b50f45":"len(df3['location'].unique())","4180be04":"#Lets check number of classes in each categorical columns:\ncategorical_cols = df3.select_dtypes(include='object').columns\nfor col in categorical_cols:\n    print(f'Number of classes in {col} : {df2[col].nunique()}')","7c3a1a17":"# Creating new feature for detecting outliers:\ndf3['price_per_sqft'] = df3['price']*100000\/df3['total_sqft_cleaned']\ndf3.head()","c126c75e":"# Checking location statistics:\ndf3['location'] = df3['location'].apply(lambda x: x.strip())\nlocation_stats = df3.groupby('location')['location'].agg('count').sort_values(ascending=False)\nlocation_stats","630c9289":"# Locations with less than 10 count:\nlocations_stats_less_than_10 = location_stats[location_stats<=10]\nlocations_stats_less_than_10","40232fa7":"df3['location'] = df3['location'].apply(lambda x : \"other\" if x in locations_stats_less_than_10 else x)","e9953598":"df3['location'].nunique()","9855f0f2":"# Per room sqft threshold be 300sqft: \ndf3 = df3[~(df3.total_sqft_cleaned\/df3.BHK < 300)]\ndf3.shape","18ffc202":"df3['price_per_sqft'].describe()","a045b032":"# Function to remove outliers from price_per_sqft based on locations.\n# As every location will have different price range.\ndef remove_price_outlier(df_in):\n    df_out = pd.DataFrame()\n    for key, subdf in df_in.groupby('location'):\n        avg_price = np.mean(subdf.price_per_sqft)\n        std_price = np.std(subdf.price_per_sqft)\n        # data without outliers: \n        reduced_df = subdf[(subdf.price_per_sqft>(avg_price-std_price)) & (subdf.price_per_sqft<=(avg_price+std_price))]\n        df_out =pd.concat([df_out, reduced_df], ignore_index=True)\n    return df_out\ndf4 = remove_price_outlier(df3)\ndf4.shape","82d6cf23":"# Function to remove BHK outliers:\ndef remove_bhk_outliers(df_in):\n    exclude_indices = np.array([])\n    for location, location_subdf in df_in.groupby('location'):\n        bhk_stats = {}\n        for bhk, bhk_subdf in df_in.groupby('BHK'):\n            bhk_stats[bhk] = {\n                'mean':np.mean(bhk_subdf.price_per_sqft),\n                'std':np.std(bhk_subdf.price_per_sqft),\n                'count':bhk_subdf.shape[0]\n            }\n        for bhk, bhk_subdf in location_subdf.groupby('BHK'):\n            stats = bhk_stats.get(bhk-1) #statistics of n-1 BHK\n            if stats and stats['count'] > 5:\n                exclude_indices = np.append(exclude_indices, bhk_subdf[bhk_subdf.price_per_sqft<(stats['mean'])].index.values)\n    return df_in.drop(exclude_indices, axis='index')\n        \ndf5 = remove_bhk_outliers(df4)\ndf5.shape","dc735f3e":"# Visualize to see number of data points for price_per_sqft\nplt.hist(df5.price_per_sqft, rwidth=0.8)\nplt.xlabel(\"Price Per Sqft.\")\nplt.ylabel(\"Count\")","5f180bbe":"df5[df5.bath>10]","d76cd80b":"# Visualize to see data points based on number of bathrooms:\nplt.hist(df5.bath, rwidth=0.8)\nplt.xlabel(\"Number of Bathrooms\")\nplt.ylabel(\"Count\")","830c84dc":"df5[df5.bath > df5.BHK+2]","5977cd22":"# Remove bathroom outliers:\ndf6 = df5[df5.bath<df5.BHK+2]\ndf6.shape","bd0da6a2":"df6.head()","d38976d9":"df7 = df6.drop(['price_per_sqft'], axis=1)\ndf7.head()","1d165781":"location_dummies = pd.get_dummies(df7.location)\nlocation_dummies.head()","23b0e363":"df8 = pd.concat([df7, location_dummies.drop('other', axis='columns')], axis='columns')\ndf8.head()","087c2880":"# Remove Location Column:\ndf9 = df8.drop(['location'], axis='columns')\ndf9.head()","ec7217eb":"df9.shape","0ea5ff79":"# Independent variables:\nX = df9.drop('price', axis='columns')\nX.head()","da8610b8":"# Dependent Variable:\ny = df9['price']\ny.head()","1b619572":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)","0298d8b8":"# Linear Regression: \nfrom  sklearn.linear_model import LinearRegression\nlin_reg = LinearRegression()\nlin_reg.fit(X_train, y_train)\nprint(f'Score: {lin_reg.score(X_test, y_test)}')","a5245e2a":"# K-fold validation for Linear Regression:\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import cross_val_score\ncv1 = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\ncross_val_score(LinearRegression(), X, y, cv=cv1)","9021fdf4":"from sklearn.linear_model import Lasso\nfrom sklearn.linear_model import Ridge\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import ElasticNet","5b4f3d62":"def find_best_model_grid_search(X, Y, tqdm=tqdm):\n    algos = {\n        'Linear_regression' : {\n            'model' : LinearRegression(),\n            'params': {\n                'normalize':[True, False]\n             }\n          },  \n         'Lasso' : {\n             'model': Lasso(),\n             'params': {\n                  \"max_iter\": [1, 5, 10],\n                 'alpha': [0.02, 0.024, 0.025, 0.026, 0.03, 0.05, 0.5, 1,2],\n                 'selection':['random', 'cyclic'],\n                  'normalize':[True, False]\n             }\n          },\n         'Ridge' : {\n             'model' : Ridge(),\n             'params': {\n                  \"max_iter\": [1, 5, 10],\n                 'alpha': [0.05, 0.1, 0.5, 1, 5, 10, 200, 230, 250,265, 270, 275, 290, 300, 500],\n                  'normalize':[True, False]\n             }\n         },\n        'ElasticNet' : {\n             'model' : ElasticNet(),\n             'params' : {\n                 \"max_iter\": [1, 5, 10],\n                 'alpha': [0, 0.01, 0.02, 0.03, 0.05, 0.5, 1, 0.05, 0.1, 0.5, 1, 5, 10, 100],\n                 'l1_ratio': np.arange(0.0, 1.0, 0.1),\n                 'normalize':[True, False]\n             } \n         },\n          'Decision_tree': {\n              'model': DecisionTreeRegressor(),\n              'params': {\n                  'criterion' : ['mse', 'friedman_mse'],\n                  'splitter': ['best', 'random']\n              }\n          }\n    }\n    values = (algos.items())\n    scores = []\n    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n    print(f'Grid Search CV Initiated..' )    \n    with tqdm(total=len(values), file=sys.stdout) as pbar:\n        for algo_name, config in algos.items():\n            pbar.set_description('Processed')\n            gs =  GridSearchCV(config['model'], config['params'], cv=cv, return_train_score=False)\n            gs.fit(X,Y)\n            scores.append({\n                'model': algo_name,\n                'best_score': gs.best_score_,\n                'best_params': gs.best_params_\n            })\n            pbar.update(1)\n            print(f'Grid search CV for {algo_name} done')\n        print(\"Grid Search CV completed!\")\n    return pd.DataFrame(scores,columns=['model','best_score','best_params'])","db2d1161":"models = find_best_model_grid_search(X, y)\nmodels","f029d2a4":"# Ridge best parameters:\nmodels.loc[3]['best_params']","a1e6b907":"# Re-train using best parameter:\nmodel = Ridge(alpha=0.1, max_iter=1)\nmodel.fit(X_train, y_train)","0e307182":"# Prediction:\nypred = model.predict(X_test)","8a4b3bad":"# Visualising the test vs predicted data:\nplt.scatter(ypred, y_test)\nplt.title('Actual Price vs Predicted Price (in Lacs)')\nplt.xlabel('Predicted Price')\nplt.ylabel('Actual Price')","36965e67":"# Calculate the absolute errors\nerrors = abs(ypred - y_test)\n# Print out the mean absolute error (mae)\nprint('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')","3869c595":"# Calculate mean absolute percentage error (MAPE)\nmape = 100 * (errors \/ y_test)\n# Calculate and display accuracy\naccuracy = 100 - np.mean(mape)\nprint('Accuracy:', round(accuracy, 2), '%.')","5d232a9b":"X.columns","67600c3d":"pd.DataFrame(model.coef_,X.columns,columns=['Coefficient'])","33ee9bc4":"# Prediction Function\ndef predict_price(location, sqft, bath, bhk, data=X):\n    loc_index = np.where(data.columns==location)[0][0]\n    x = np.zeros(len(data.columns)) #init a new array with zero values.\n    x[0] = bath\n    x[1] = bhk\n    x[2] = sqft\n    if loc_index >= 0:\n        x[loc_index] = 1\n    return model.predict([x])[0]","43267d92":"predict_price('1st Phase JP Nagar',1000,2,2)","cf90c312":"# Indira Nagar is most expensive in Bengaluru. Lets predict\npredict_price('Indira Nagar',1000,2,2)","6d4afe2f":"# saving ml model as pickle file:\nimport pickle\nwith open('bengaluru_home_price_model.pickle','wb') as f:\n    pickle.dump(model,f)","3af69439":"# saving column names as a json file:\nimport json\ncolumns = {\n    'data_columns' : [col.lower() for col in X.columns]\n}\nwith open('columns.json', 'w') as f:\n    f.write(json.dumps(columns))","7910238d":"The unique values have been reduced.\n\nNow we will detect and remove outliers first. Suppose we have a threshold value for per room sqft given by realestate expert. \nUsing this we can find out anomalies in our data and remove them.","91c8d57d":"## Saving Model","09e4035c":"* sq Meters to sqft: 10.764 * sq.meters\n* sqYards to sqft: 9 * sqYards\n* gunta to sqft: 1089 * gunta\n* acres to sqft: 43560 * acres\n* perch to sqft: 272.25 * perch\n* Grounds to sqft: 2400 * ground\n* Cents to sqft: 435.6 * cent","4d63997f":"For normal distribution of data, we will keep price values which are near to mean and std.\nOutliers are all above mean+standard_deviation and below mean+standard_deviation.","6b32b7f1":"We will tag the locations which are having very less counts as others.","23ba94cb":"Done!!","8dfb192e":"### Data Spliting: (train and test)\n(X_train, y_train, X_test, y_test)\n\nWe will keep 20% of sample data for test and rest for training.","2a24cdcf":"Outliers removal is done. Now we can remove the extra column \"price_per_sqft\"","84e99441":"## Data Cleaning:","6c6920ae":"## Model Selection and Parameter Tuning","602f9071":"As this generated binary columns of locations, it is obvious that if any one the row value is 1 then rest are 0. So we will remove one column.\nWhenever there are N classes in a feature, we keep N-1 dummies for it. Here we will drop 'other' column","bdc7e20d":"Lets check the null or nan values","73213b7e":"It was found that in some rows price of 2BHK is very less than 1 BHK. So we  will remove outliers based on BHK for each location. That is we can remove those n BHK apartments whose price_per_sqft is less than mean price_per_sqft of n-1 BHK.","399feb30":"Clearly, we can see Ridge is performing well. Lasso and Ridge are actually any other regression model. They are regularization methods of linear regressions.\nTo know more about Lasso and Ridge:https:\/\/www.analyticsvidhya.com\/blog\/2017\/06\/a-comprehensive-guide-for-linear-ridge-and-lasso-regression\/ .\nLets collect its best parameters and proceed to re-train our model using these parameters.","de449c02":"Using GridSearch lets find out best model among Linear reg, Lasso reg, DecisionTree reg","f0f1cb83":"All columns are cleaned and no nan values remaining.\nNow we can proceed to feature engineering.","4f2f3ef9":"All functions are ready now will make one parent function to clean our 'total_sqft' column","80bdc320":"In Data Cleaning section, we encountered that there exist number of bathrooms more than 10.\nLets tackle that in this section.","a2c0b9a0":"## Model Building\n### Data Spliting: (Independent: X, Dependent:y) ","55e3d360":"There are some values in range format. like 1133-1384","50fa7eb0":"We can consider the following for bathroom outlier, that **we cannot have (number of bathrooms) more than  (number of bedrooms)+2**","c59d2a2b":"As location variable is an categorical feature, we will create dummy columns for location feature using get dummies function.","adabf9e7":"Feature engineering is done. We are now at 9th pipe stage and can proceed further for Prediction model building.","60433796":"Here we need numeric values, so we will remove bedroom and BHK strings from all values.","61047273":"## Feature Engineering","8c32d364":"These rows are our outliers for bathrooms.","d13fd781":"Not just range values, we can see there are some numeric values written in sqft, perch, acres, yards, cents and ground formats.","d3bc4d8b":"Our Model is ready!! \n\n## Predictions"}}