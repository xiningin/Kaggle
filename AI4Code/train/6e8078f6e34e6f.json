{"cell_type":{"52907c9c":"code","834110b2":"code","14573504":"code","d8db2952":"code","68f7c574":"code","0762bb50":"code","b57e2d9e":"code","c00f5326":"code","71248bac":"code","08a880cf":"code","8dafa5f1":"code","c2c9ffed":"code","c30cdcc6":"code","89b3f1d6":"code","d5e4d87d":"code","2df95266":"code","eaface6e":"code","082dfd30":"code","412a6747":"code","52ae0e36":"code","4a42a7a5":"code","50720698":"code","ffd2e6b5":"code","c1894b67":"code","ed501470":"code","365983f6":"code","e82e8dff":"code","6fb78d3a":"code","52addb04":"code","fd9745df":"code","5a9b7834":"code","c7646d36":"code","3c25a69c":"code","4dfc7419":"code","306583ea":"code","e56f442a":"code","9232634d":"code","91967353":"code","69e2e373":"code","c13d7872":"code","f3ececc1":"code","f238169a":"markdown","a8203ea2":"markdown","4e7c364b":"markdown","2ed49890":"markdown","e9589f73":"markdown","99db5540":"markdown","abca1dce":"markdown","efdce1b5":"markdown","0c78e30d":"markdown","ccab2aaa":"markdown","4a5bd570":"markdown","9d83e7c0":"markdown","cbca0c25":"markdown","c61c5503":"markdown","381ea64c":"markdown","259a5799":"markdown","1feccd47":"markdown","4022c851":"markdown","5e2bd831":"markdown","81ffc6ab":"markdown","6469ea3d":"markdown","caf60579":"markdown","d09e15a5":"markdown","12bbce18":"markdown","696afd4a":"markdown","000325d8":"markdown","315145fc":"markdown","b4989717":"markdown","2a13eb52":"markdown","cc71d069":"markdown"},"source":{"52907c9c":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom numpy import unique\nfrom sklearn.cluster import KMeans\nfrom sklearn.cluster import AffinityPropagation\nfrom sklearn.cluster import Birch\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.cluster import MiniBatchKMeans\nfrom sklearn.cluster import MeanShift\nfrom sklearn.cluster import OPTICS\nfrom sklearn.cluster import SpectralClustering\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.cluster import AgglomerativeClustering\nfrom sklearn import metrics\n#                                 \nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname,filename))","834110b2":"data = pd.read_csv('\/kaggle\/input\/mall-customers\/Mall_Customers.csv', index_col=0)\ndata.head()","14573504":"data.drop(['Genre'], axis=1, inplace=True)\ndata.drop(['Age'], axis=1, inplace=True)\n\ndata.head()","d8db2952":"data = data.sample(frac=1)","68f7c574":"data.head()","0762bb50":"k_means = KMeans(n_clusters=2)\nk_means.fit(data)","b57e2d9e":"k_means.labels_","c00f5326":"np.unique(k_means.labels_)","71248bac":"centers = k_means.cluster_centers_\n\ncenters","08a880cf":"plt.figure(figsize=(10, 8))\n\nplt.scatter(data['Annual Income (k$)'], \n            data['Spending Score (1-100)'], \n            c=k_means.labels_, s=100)\n\nplt.scatter(centers[:,0], centers[:,1], color='blue', marker='s', s=200) \n\nplt.xlabel('Annual Income')\nplt.ylabel('Spending Score')\nplt.title('K-Means with 2 clusters')\n\nplt.show()","8dafa5f1":"from sklearn.metrics import silhouette_score\n\nscore = silhouette_score (data, k_means.labels_)\n\nprint(\"Score = \", score)","c2c9ffed":"wscc = []\nfor i in range(1,15): \n    kmeans = KMeans(n_clusters=i, init=\"k-means++\",random_state=0)\n    kmeans.fit(data)\n    wscc.append(kmeans.inertia_)  \n\nplt.plot(range(1,15),wscc,marker=\"*\",c=\"black\")\nplt.title(\"Elbow plot for optimal number of clusters\")","c30cdcc6":"k_means = KMeans(n_clusters=5)\nk_means.fit(data)","89b3f1d6":"np.unique(k_means.labels_)","d5e4d87d":"centers = k_means.cluster_centers_\n\ncenters","2df95266":"plt.figure(figsize=(10, 8))\n\nplt.scatter(data['Annual Income (k$)'], \n            data['Spending Score (1-100)'], \n            c=k_means.labels_, s=100)\n\nplt.scatter(centers[:,0], centers[:,1], color='blue', marker='s', s=200) \n\nplt.xlabel('Annual Income')\nplt.ylabel('Spending Score')\nplt.title('5 Cluster K-Means')\n\nplt.show()","eaface6e":"score = metrics.silhouette_score(data, k_means.labels_)\n\nprint(\"Score = \", score)","082dfd30":"score1 = metrics.silhouette_samples(data, k_means.labels_, metric='euclidean')\nprint(\"Score = \", score1)","412a6747":"model_aff = AffinityPropagation(damping=0.9)\nmodel_aff.fit(data)\n#\nyhat_aff = model_aff.predict(data)\nclusters_aff = unique(yhat_aff)\nprint(\"Clusters of Affinity Prop.\",clusters_aff)\nlabels_aff = model_aff.labels_\ncentroids_aff = model_aff.cluster_centers_","52ae0e36":"plt.figure(figsize=(10, 8))\n\nplt.scatter(data['Annual Income (k$)'], \n            data['Spending Score (1-100)'], \n            c=labels_aff, s=100)\n\nplt.scatter(centroids_aff[:,0], centroids_aff[:,1], color='red', marker='*', s=200) \n\nplt.xlabel('Annual Income')\nplt.ylabel('Spending Score')\nplt.title('Affinity Propagation')\nplt.grid()\nplt.show()","4a42a7a5":"score_aff = metrics.silhouette_score(data,labels_aff)\n\nprint(\"Score of Affinity Propagation = \", score_aff)","50720698":"model_br = Birch(threshold=0.01, n_clusters=5)\nmodel_br.fit(data)\n#\nyhat_br = model_br.predict(data)\nclusters_br = unique(yhat_br)\nprint(\"Clusters of Birch\",clusters_br)\nlabels_br = model_br.labels_","ffd2e6b5":"score_br = metrics.silhouette_score(data,labels_br)\n\nprint(\"Score of Birch = \", score_br)","c1894b67":"# dbscan clustering\nfrom numpy import unique\nfrom numpy import where\ndata_X = data.iloc[:,[0,1]].values","ed501470":"# define the model\nmodel = DBSCAN(eps=0.7, min_samples=90)\n# fit model and predict clusters\nyhat = model.fit_predict(data_X)\n# retrieve unique clusters\nclusters = unique(yhat)\n# create scatter plot for samples from each cluster\nfor cluster in clusters:\n\t# get row indexes for samples with this cluster\n\trow_ix = where(yhat == cluster)\n\t# create scatter of these samples\n\tplt.scatter(data_X[row_ix, 0], data_X[row_ix, 1])\n# show the plot\nplt.show()","365983f6":"model_mini = MiniBatchKMeans(n_clusters=2)\nmodel_mini.fit(data)\n#\nyhat_mini = model_mini.predict(data)\nclusters_mini = unique(yhat_mini)\nprint(\"Clusters of Mini Batch KMeans.\",clusters_mini)\nlabels_mini = model_mini.labels_\ncentroids_mini = model_mini.cluster_centers_","e82e8dff":"wscc = []\nfor i in range(1,15): \n    mkmeans = MiniBatchKMeans(n_clusters=i, init=\"k-means++\",random_state=0)\n    mkmeans.fit(data)\n    wscc.append(mkmeans.inertia_)  \n\nplt.plot(range(1,15),wscc,marker=\"*\",c=\"black\")\nplt.title(\"Elbow plot for Mini Batch KMeans\")","6fb78d3a":"model_mini = MiniBatchKMeans(n_clusters=5)\nmodel_mini.fit(data)\n#\nyhat_mini = model_mini.predict(data)\nclusters_mini = unique(yhat_mini)\nprint(\"Clusters of Mini Batch KMeans.\",clusters_mini)\nlabels_mini = model_mini.labels_\ncentroids_mini = model_mini.cluster_centers_","52addb04":"plt.figure(figsize=(10, 8))\n\nplt.scatter(data['Annual Income (k$)'], \n            data['Spending Score (1-100)'], \n            c=labels_mini, s=100)\n\nplt.scatter(centroids_mini[:,0], centroids_mini[:,1], color='red', marker='*', s=200) \n\nplt.xlabel('Annual Income')\nplt.ylabel('Spending Score')\nplt.title('Mini Batch KMeans')\nplt.grid()\nplt.show()","fd9745df":"score_mini = metrics.silhouette_score(data,labels_mini)\n\nprint(\"Score of Birch = \", score_mini)","5a9b7834":"model_ms = MeanShift(bandwidth=25)\nmodel_ms.fit(data)\n#\nyhat_ms = model_ms.predict(data)\nclusters_ms = unique(yhat_ms)\nprint(\"Clusters of Mean Shift.\",clusters_ms)\nlabels_ms = model_ms.labels_\ncentroids_ms = model_ms.cluster_centers_","c7646d36":"plt.figure(figsize=(10, 8))\n\nplt.scatter(data['Annual Income (k$)'], \n            data['Spending Score (1-100)'], \n            c=labels_ms, s=100)\n\nplt.scatter(centroids_ms[:,0], centroids_ms[:,1], color='red', marker='*', s=200) \n\nplt.xlabel('Annual Income')\nplt.ylabel('Spending Score')\nplt.title('Mean Shift')\nplt.grid()\nplt.show()","3c25a69c":"score_ms = metrics.silhouette_score(data,labels_ms)\n\nprint(\"Score of Mean Shift = \", score_ms)","4dfc7419":"model_op = OPTICS(eps=0.8, min_samples=10)\n#\nyhat_op = model_op.fit_predict(data)\nclusters_op = unique(yhat_op)\nprint(\"Clusters of Mean Shift.\",clusters_op)\nlabels_op = model_op.labels_","306583ea":"score_op = metrics.silhouette_score(data,labels_op)\n\nprint(\"Score of Mean Shift = \", score_op)","e56f442a":"model_sc = SpectralClustering(n_clusters=5)\n#\nyhat_sc = model_sc.fit_predict(data)\nclusters_sc = unique(yhat_sc)\nprint(\"Clusters of Mean Shift.\",clusters_sc)\nlabels_sc = model_sc.labels_","9232634d":"score_sc = metrics.silhouette_score(data,labels_sc)\n\nprint(\"Score of Mean Shift = \", score_sc)","91967353":"from numpy import unique\nfrom numpy import where\ndata_X = data.iloc[:,[0,1]].values","69e2e373":"model_gb = GaussianMixture(n_components=5)\nmodel_gb.fit(data_X)\n#\nyhat_gb = model_gb.predict(data_X)\nclusters_gb = unique(yhat_gb)\n# create scatter plot for samples from each cluster\nfor cluster in clusters_gb:\n\t# get row indexes for samples with this cluster\n\trow_ix = where(yhat_gb == cluster)\n\t# create scatter of these samples\n\tplt.scatter(data_X[row_ix, 0], data_X[row_ix, 1])\n# show the plot\nplt.show()","c13d7872":"model_agg = AgglomerativeClustering(n_clusters=5)\n#\nyhat_agg = model_agg.fit_predict(data)\nclusters_agg = unique(yhat_agg)\nprint(\"Clusters of Mini Batch KMeans.\",clusters_agg)\nlabels_agg = model_agg.labels_","f3ececc1":"score_agg = metrics.silhouette_score(data,labels_agg)\n\nprint(\"Score of Mean Shift = \", score_agg)","f238169a":" * DBSCAN Clustering (where DBSCAN is short for Density-Based Spatial Clustering of Applications with Noise) involves finding high-density areas in the domain and expanding those areas of the feature space around them as clusters.\n * For this data, could not get a good result.","a8203ea2":"Silhouette Score: This is a better measure to decide the number of clusters to be formulated from the data. ","4e7c364b":"<a id = \"5\"><\/a><br>\n## 2 - Affinity Propagation\nAffinity Propagation involves finding a set of exemplars that best summarize the data.","2ed49890":"<a id = \"7\"><\/a><br>\n## 4- DBSCAN","e9589f73":"### Taking full fraction of data\nIt shuffles the data","99db5540":"# Introduction\n Involve 10 Models Clustering\n \n<br>\n<br>\n<font color = 'blue'>\n<b>Content: <\/b>\n\n1. [Prepare Problems]\n    * [Load Libraries](#2)\n    * [Load Dataset](#3)    \n1. [Models]\n    * [K-Means](#4)\n    * [Affinity Propagation](#5)\n    * [BIRCH](#6)\n    * [DBSCAN](#7)\n    * [Mini Batch K-Means](#8)\n    * [Mean Shift](#9)\n    * [OPTICS](#10)\n    * [Spectral Clustering](#11)\n    * [Gaussian Mixture Model](#12)\n    * [Agglomerative Clustering](#13)\n1. [References](#14)","abca1dce":"<a id = \"11\"><\/a><br>\n## 8 - Spectral Clustering","efdce1b5":"* https:\/\/machinelearningmastery.com\/clustering-algorithms-with-python\/","0c78e30d":"<a id = \"12\"><\/a><br>\n## 9 - Gaussian Mixture Model","ccab2aaa":"<a id = \"9\"><\/a><br>\n## 6 - Mean Shift","4a5bd570":"<a id = \"3\"><\/a><br>\n## Load Dataset","9d83e7c0":"<a id = \"13\"><\/a><br>\n## 10 - Agglomerative Clustering","cbca0c25":"<a id = \"10\"><\/a><br>\n## 7 - OPTICS","c61c5503":"### KMeans clustering with 5 clusters","381ea64c":"* Mean shift clustering involves finding and adapting centroids based on the density of examples in the feature space.","259a5799":"<a id = \"2\"><\/a><br>\n## Load Libraries","1feccd47":"#  If you like my kernel, please upvote","4022c851":"<a id = \"4\"><\/a><br>\n## 1 - K-Means ","5e2bd831":"### Labels","81ffc6ab":"This function returns the Silhouette Coefficient for each sample.\n\nThe best value is 1 and the worst value is -1. Values near 0 indicate overlapping clusters.","6469ea3d":"### Displaying Data in 5 cluster form \nwith 5 centroids","caf60579":"* OPTICS clustering (where OPTICS is short for Ordering Points To Identify the Clustering Structure) is a modified version of DBSCAN described above.\n* In this case, I could not achieve a reasonable result on this dataset.","d09e15a5":"<a id = \"14\"><\/a><br>\n## References","12bbce18":"* Spectral Clustering is a general class of clustering methods, drawn from linear algebra.","696afd4a":"* A measure of how similar a point is to other points in its own cluster and how different it is from points in other clusters.","000325d8":"* Mini-Batch K-Means is a modified version of k-means that makes updates to the cluster centroids using mini-batches of samples rather than the entire dataset, which can make it faster for large datasets, and perhaps more robust to statistical noise.","315145fc":"* Agglomerative clustering involves merging examples until the desired number of clusters is achieved.","b4989717":"<a id = \"8\"><\/a><br>\n## 5 - Mini Batch K-Means","2a13eb52":"<a id = \"6\"><\/a><br>\n## 3 - BIRCH\nBIRCH Clustering (BIRCH is short for Balanced Iterative Reducing and Clustering using\nHierarchies) involves constructing a tree structure from which cluster centroids are extracted.","cc71d069":"* A Gaussian mixture model summarizes a multivariate probability density function with a mixture of Gaussian probability distributions as its name suggests."}}