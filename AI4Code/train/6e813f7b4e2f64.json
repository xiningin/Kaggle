{"cell_type":{"1286ddfa":"code","82dfc1cd":"code","15183216":"code","df4b6c6e":"code","e145f2c8":"code","c600ec5a":"code","873c10a3":"code","658938d5":"code","f22fc340":"code","96b19537":"code","8577a9b0":"code","359256a0":"code","8ba11d92":"code","78ded835":"code","e8a5fdf9":"code","9d3c121b":"code","091d5b2b":"code","f4e885ae":"code","add7c9a0":"code","adec25da":"code","dc00ea42":"code","e247d760":"code","49cc0b8c":"code","bf651246":"code","bbab6893":"code","8e98527f":"markdown","8633e41f":"markdown","01b37e77":"markdown","0719aebf":"markdown","7aabb25c":"markdown","647d5d1e":"markdown","1b1f0cf0":"markdown","f8211cd2":"markdown","5c22ef49":"markdown"},"source":{"1286ddfa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","82dfc1cd":"#Reading the Train file \nX_train=pd.read_csv(\"\/kaggle\/input\/cat-in-the-dat-ii\/train.csv\")\nX_train.info()","15183216":"# Reading Test file\nX_test=pd.read_csv(\"\/kaggle\/input\/cat-in-the-dat-ii\/test.csv\")\nX_test.head()","df4b6c6e":"# Identifying Missing Values perecntage of train data set\nround((X_train.isnull().sum()\/len(X_train)*100),2)","e145f2c8":"# Identifying Missing Values perecntage of test data set\nround((X_test.isnull().sum()\/len(X_test)*100),2)","c600ec5a":"# Get list of categorical variables\ns = X_train.select_dtypes(include=['object'])\nCat_cols=s.columns.to_list()\n","873c10a3":"#Imputing Missg Values with Mode() for categorical columns\nfor c in Cat_cols:\n    X_train[c].fillna(X_train[c].mode()[0], inplace = True)  \nround((X_train.isnull().sum()\/len(X_train)*100),2)    ","658938d5":"#Imputing Missg Values with Mode() for categorical columns-Test data set\nfor c in Cat_cols:\n    X_test[c].fillna(X_test[c].mode()[0], inplace = True)  \nround((X_test.isnull().sum()\/len(X_test)*100),2)  ","f22fc340":"Num_cols =X_train.select_dtypes(include=['int64','float']).columns.to_list()\nNum_cols.pop(Num_cols.index('id'))  #Removing ID as it not requried\nNum_cols\n\n\nfor c in Num_cols:\n    X_train[c].fillna(np.mean(X_train[c]), inplace = True)  \nround((X_train.isnull().sum()\/len(X_train)*100),2)","96b19537":"# Test Dataset\nNum_cols =X_test.select_dtypes(include=['int64','float']).columns.to_list()\nNum_cols.pop(Num_cols.index('id'))  #Removing ID as it not requried\nNum_cols\n\n\nfor c in Num_cols:\n    X_test[c].fillna(np.mean(X_test[c]), inplace = True)  \nround((X_test.isnull().sum()\/len(X_test)*100),2)","8577a9b0":"\nbin_cols = [col for col in X_train if col.startswith('bin')]\n\nfor i in bin_cols:\n    print([i],X_train[i].unique())","359256a0":"bin_cols = [col for col in X_test if col.startswith('bin')]\n\nfor i in bin_cols:\n    print([i],X_test[i].unique())","8ba11d92":"# Converting into Binary values\nfor i in bin_cols[:3]:\n    X_train[i]=X_train[i].apply(lambda x : 1 if x>0.5 else 0)\n    \nfor i in bin_cols[:3]:\n    X_test[i]=X_test[i].apply(lambda x : 1 if x>0.5 else 0)    \n     ","78ded835":"X_train['bin_0'].unique()","e8a5fdf9":"import seaborn as sns\nimport matplotlib.pyplot as plt ","9d3c121b":"# Binary variable visualisation\n\nfor i in bin_cols:\n    sns.countplot(x=i, hue=\"target\", data=X_train)\n    plt.title(i)\n    plt.show()","091d5b2b":"# Bin_3 and Bin_4- We convert categorical into Binary values\nX_train['bin_3']=X_train['bin_3'].apply(lambda x : 1 if 'F' else 'T')\nX_train['bin_4']=X_train['bin_2'].apply(lambda x : 1 if 'N' else 'Y')\n\n# Test set\nX_test['bin_3']=X_test['bin_3'].apply(lambda x : 1 if 'F' else 'T')\nX_test['bin_4']=X_test['bin_2'].apply(lambda x : 1 if 'N' else 'Y')\n\n","f4e885ae":"X_train[bin_cols].head()","add7c9a0":"ord_cols = [col for col in X_train if col.startswith('ord')]\n\nfor i in ord_cols:\n    print([i],X_train[i].unique())","adec25da":"nominal_cols = [col for col in X_train if col.startswith('nom')]\n\nfor i in nominal_cols:\n    print([i],X_train[i].unique())","dc00ea42":"X_train.info()","e247d760":"cat_cols_encoding= X_train.select_dtypes(include=['object']).columns.to_list()\nX_test[cat_cols_encoding].head()\n","49cc0b8c":"# X_train[cat_cols_encoding].head()\nX_test.columns","bf651246":"# we will do Random Forest Method to Identify the target. for that we will do Label encoding.\n\n\ncat_cols_encoding= X_train.select_dtypes(include=['object']).columns.to_list()\n\nfrom sklearn.preprocessing import LabelEncoder\n\n# Apply label encoder to each column with categorical data\nlabel_encoder = LabelEncoder()\n\nfor col in cat_cols_encoding:\n    X_train[c]= label_encoder.fit_transform(X_train[c])\n \n\n","bbab6893":"for c in cat_cols_encoding:\n    X_test[c] = label_encoder.transform(X_test[c])","8e98527f":"Now Binary columns are ready for Modelling. Next is to encoding nominal and ordinary variables","8633e41f":"binary variables bin_0,bin_1,bin_2 contains decimal as well. we will convert it into either 0 or 1 based on threshold","01b37e77":"**Categorical Encoding**","0719aebf":"Next is to impute Numerical columns with Mean value","7aabb25c":"Now data set contain no NULL values and  is ready for EDA","647d5d1e":"As above columns contins around ~3% of NULL values, It is good to impute with Mean for Numerical columns and Mode for Categorical Columns.","1b1f0cf0":"We will impute above categorical columns with Mode.","f8211cd2":"**Data Understanding and Cleansing**","5c22ef49":"We have to do encoding for Categorical variables. For Nominal , it is better to do by One Hot Encoding"}}