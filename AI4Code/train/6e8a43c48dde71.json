{"cell_type":{"a09f8928":"code","3829486c":"code","a23fffa9":"code","9941a9e0":"code","da73054c":"code","3c22b40a":"code","2259f3c1":"code","b0a1e07f":"code","8d991578":"code","06485442":"code","cb3a0b04":"code","0a879966":"code","c49462b5":"code","11a9f653":"code","575b2b51":"code","81e98396":"code","60ce5368":"code","9dd9161e":"code","63769e15":"code","540df304":"code","218cb563":"code","510246c0":"code","36b3b7b3":"code","8cab85fd":"code","eef5dbc2":"code","4ff23762":"code","6718248e":"code","2a661977":"code","0925cbd2":"code","3ee24235":"code","4ef67a43":"code","f1ac6c83":"markdown","a49212b0":"markdown","d5597dd3":"markdown","8ee31637":"markdown","ad6e06bc":"markdown","852bd1cb":"markdown","72688564":"markdown"},"source":{"a09f8928":"import os\nimport warnings\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\nfrom IPython.display import display\nfrom pandas.api.types import CategoricalDtype\n\nfrom category_encoders import MEstimateEncoder\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.feature_selection import mutual_info_regression\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom xgboost import XGBRegressor\n\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n\n%matplotlib inline\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)","3829486c":"def load_data():\n    \n    # Read data\n    #data_dir = Path(\"..\/input\/house-prices-advanced-regression-techniques\/\")\n    \n    df_train_org = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\", index_col=\"Id\") \n    \n    df_submission_org = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\", index_col=\"Id\")\n    \n    # Merge the splits so we can process them together\n    df = pd.concat([df_train_org, df_submission_org])\n    \n    # Preprocessing\n    df = clean(df)                              # run the clean function with the dataframe\n    df = encode(df)                             # run the encode function with the dataframe\n    df = impute(df)                             # run the impute function with the dataframe\n    df = apply_dummies(df)                      # run the apply_dummies function with the dataframe    \n\n    \n    # Reform splits\n    df_train = df.loc[df_train_org.index, :]\n    df_submission = df.loc[df_submission_org.index, :]\n    \n    return df_train, df_submission","a23fffa9":"def clean(df):\n    \n    # Clean up the space between letters\n    df[\"Exterior2nd\"] = df[\"Exterior2nd\"].replace({\"Brk Cmn\": \"BrkComm\"})\n    \n    # Some values of GarageYrBlt are corrupt, so we'll replace them with the year the house was built\n    df[\"GarageYrBlt\"] = df[\"GarageYrBlt\"].where(df.GarageYrBlt <= 2010, df.YearBuilt)\n    \n    # Names beginning with numbers are awkward to work with\n    df.rename(columns={\n        \"1stFlrSF\": \"FirstFlrSF\",\n        \"2ndFlrSF\": \"SecondFlrSF\",\n        \"3SsnPorch\": \"Threeseasonporch\",\n    }, inplace=True,\n    )\n    return df","9941a9e0":"# The nominative (unordered) categorical features\nfeatures_nom = [\"MSSubClass\", \"MSZoning\", \"Street\", \"Alley\", \"LandContour\", \n                \"LotConfig\", \"Neighborhood\", \"Condition1\", \"Condition2\", \n                \"BldgType\", \"HouseStyle\", \"RoofStyle\", \"RoofMatl\", \"Exterior1st\", \n                \"Exterior2nd\", \"MasVnrType\", \"Foundation\", \"Heating\", \"CentralAir\", \n                \"GarageType\", \"MiscFeature\", \"SaleType\", \"SaleCondition\"]\n\n# The ordinal (ordered) categorical features \n\n# Pandas calls the categories \"levels\"\nfive_levels = [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]       # \"Po\": Poor, \"Fa\": Fail, \"TA\": The Average, \"Gd\": Good, \"Ex\": Excellent\n\nten_levels = list(range(10))\n\nordered_levels = {\n    \"OverallQual\": ten_levels,\n    \"OverallCond\": ten_levels,\n    \"ExterQual\": five_levels,\n    \"ExterCond\": five_levels,\n    \"BsmtQual\": five_levels,\n    \"BsmtCond\": five_levels,\n    \"HeatingQC\": five_levels,\n    \"KitchenQual\": five_levels,\n    \"FireplaceQu\": five_levels,\n    \"GarageQual\": five_levels,\n    \"GarageCond\": five_levels,\n    \"PoolQC\": five_levels,\n    \"LotShape\": [\"Reg\", \"IR1\", \"IR2\", \"IR3\"],\n    \"LandSlope\": [\"Sev\", \"Mod\", \"Gtl\"],\n    \"BsmtExposure\": [\"No\", \"Mn\", \"Av\", \"Gd\"],\n    \"BsmtFinType1\": [\"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n    \"BsmtFinType2\": [\"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n    \"Functional\": [\"Sal\", \"Sev\", \"Maj1\", \"Maj2\", \"Mod\", \"Min2\", \"Min1\", \"Typ\"],\n    \"GarageFinish\": [\"Unf\", \"RFn\", \"Fin\"],\n    \"PavedDrive\": [\"N\", \"P\", \"Y\"],\n    \"Utilities\": [\"NoSeWa\", \"NoSewr\", \"AllPub\"],\n    \"CentralAir\": [\"N\", \"Y\"],\n    \"Electrical\": [\"Mix\", \"FuseP\", \"FuseF\", \"FuseA\", \"SBrkr\"],\n    \"Fence\": [\"MnWw\", \"GdWo\", \"MnPrv\", \"GdPrv\"],\n}\n\n# Add a None level for missing values\nordered_levels = {key: [\"None\"] + value for key, value in\n                  ordered_levels.items()}\n\ndef encode(df):\n    \n    # Nominal categories\n    for name in features_nom:\n        \n        df[name] = df[name].astype(\"category\")\n        \n        # Add a None category for missing values\n        if \"None\" not in df[name].cat.categories:\n            \n            df[name].cat.add_categories(\"None\", inplace=True)\n            \n    # Ordinal categories\n    for name, levels in ordered_levels.items():\n        \n        df[name] = df[name].astype(CategoricalDtype(levels, ordered=True))\n        \n    return df","da73054c":"def impute(df):                                    # Function for Handle Missing Values\n    \n    for name in df.select_dtypes(\"number\"):        # if data type is Numeric Values\n        \n        df[name] = df[name].fillna(0)              # fill in \"0\" when missing \n        \n    for name in df.select_dtypes(\"category\"):      # if data type is Category Values\n        \n        df[name] = df[name].fillna(\"None\")         # fill in \"None\" when missing\n        \n    return df","3c22b40a":"def apply_dummies(df):                             # Function to convert categorical column to numbers\n    \n    df = pd.get_dummies(df)\n    \n    return df","2259f3c1":"# Call the data loader and get the processed data splits\ndf_train, df_submission = load_data()","b0a1e07f":"def apply_normalize(df):\n\n    df_n = df.iloc[:, :]                      # iloc: selecting data. All rows, except first serial column\n\n    df_norm = (df_n - df_n.mean()) \/ df_n.std()\n\n    return df_norm","8d991578":"df_train_normalize = apply_normalize(df_train)\ndf_submission_normalize = apply_normalize(df_submission)","06485442":"impute(df_train_normalize)\nimpute(df_submission_normalize)","cb3a0b04":"df_train_normalize","0a879966":"df_mean = df_train['SalePrice'].mean()            # Caluclate the mean before normalize\ndf_std = df_train['SalePrice'].std()              # Caluclate the Std before normalize\n\ndef convert_label_value(pred):                    # Create the function\n\n    return int(pred * df_std + df_mean)","c49462b5":"print(convert_label_value(df_train_normalize.iloc[3,33]))         # Test the function. SalePrice at Column 34","11a9f653":"y_train = df_train_normalize['SalePrice']        # set training set target \"SalePrice\" as target y","575b2b51":"x_train = df_train_normalize.drop(['SalePrice'], axis=1, inplace=True)              # Remove target feature \"SalePrice\" from training set\nx_submission = df_submission_normalize.drop(['SalePrice'], axis=1, inplace=True)    # Remove target feature \"SalePrice\" from submission set","81e98396":"x_train = df_train_normalize\nx_submission = df_submission_normalize","60ce5368":"x_train.shape","9dd9161e":"x_submission.shape","63769e15":"x_train_arr = x_train.values        # convert dataframe into array\ny_train_arr = y_train.values        ","540df304":"from sklearn.model_selection import train_test_split\nx_train, x_valid, y_train, y_valid = train_test_split(x_train_arr, y_train_arr, test_size=0.15)","218cb563":"def get_model():\n    \n    model = Sequential([\n        Dense(256, input_shape = (374, ), activation = 'relu'),     # input_shape = 374: We have 374 features\n        Dense(128, activation = 'relu'),\n        Dense(64, activation = 'relu'),\n        Dense(32, activation = 'relu'),\n        Dense(16, activation = 'relu'),\n        Dense(8, activation = 'relu'),\n        Dense(4, activation = 'relu'),\n        Dense(2, activation = 'relu'),\n        Dense(1)                                                 # Regression Model with only 1 output   \n    ])\n    \n            \n    model.compile(\n        loss = 'mse',                                            # MSE: Mean Squre Error for regression model\n        optimizer = 'adam'                                       # Use Stochastic Gradient Descent (SGD) or Adam\n        )\n        \n    return model","510246c0":"get_model().summary()","36b3b7b3":"Early_Stopping = EarlyStopping(monitor='val_loss', patience=20)\n\ncheckpointer = ModelCheckpoint(filepath=\"Model_Save.hdf5\", verbose=1, save_best_only=True)\n\nmodel = get_model()\n\nprdes_on_untrained = model.predict(x_valid)\n\nhistory = model.fit(\n    x_train, y_train,                           # use converted array\n    validation_data = (x_valid, y_valid),\n    epochs = 300,\n    callbacks = [checkpointer, Early_Stopping]\n)","8cab85fd":"def plot_loss(history):\n    h = history.history\n    x_lim = len(h['loss'])\n    plt.figure(figsize=(8, 8))\n    plt.plot(range(x_lim), h['val_loss'], label = 'Validation Loss')\n    plt.plot(range(x_lim), h['loss'], label = 'Training Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.show()\n    return","eef5dbc2":"plot_loss(history)","4ff23762":"x_submission_arr = x_submission.values          # convert the dataframe into array","6718248e":"preds_submission = model.predict(x_submission_arr)","2a661977":"id_num = []\n\nfor i in range(1461, 2920):\n    \n    id_num.append(i)\n    \nsubmission_df = pd.DataFrame(id_num, columns=list('I'))\n\nsubmission_df = submission_df.rename(columns={'I':'Id'}, inplace=False)","0925cbd2":"submission_SalePrice = []\n\nfor i in range(0, preds_submission.shape[0]):\n\n    submission_SalePrice.append(convert_label_value(preds_submission[i]))        # Convert Predicted Price from normalized value\n    \nsubmission_df['SalePrice'] = submission_SalePrice","3ee24235":"submission_df","4ef67a43":"submission_df.to_csv('my_Neural_Networks_model_submission.csv', index=False)","f1ac6c83":"## Create Model","a49212b0":"## Predict The Submission","d5597dd3":"## Prepare array to train the Neural Network ","8ee31637":"## Visualize the Training Loss and Validation Loss","ad6e06bc":"## Define Convert Label Value function to convert normalized Sale Price back to dollar amount","852bd1cb":"## Data Preprocessing\n\n1. **Load** the data from CSV files\n2. **Clean** the data to fix any errors or inconsistencies\n3. **Encode** the statistical data type (numeric, categorical)\n4. **Impute** any missing values\n5. **Apply Dummies** convert categorical column to numbers\n6. **Apply Normalize** apply data normalization ","72688564":"## Split Training Set into Training and Validation Set"}}