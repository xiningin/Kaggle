{"cell_type":{"ebd7027b":"code","ebd478f2":"code","d74aeab3":"code","4ab158cd":"code","869cafd9":"code","019b006d":"code","ea8ef3b4":"code","b2e00f58":"code","bf8c97a0":"code","914f6b7f":"code","b2c7497e":"code","a1bd2d1f":"code","eeb05df6":"code","c2f4c3da":"code","7840cc7f":"code","149cb0fd":"code","cff531fd":"code","70b241d7":"code","b8dc96ad":"code","29106e59":"code","ec1fb0f9":"code","ed4a7c88":"code","8bdd3e9a":"code","883d3fc1":"code","61f8725d":"code","4124e746":"code","ca21b594":"code","5e8d344a":"code","9ef1b78b":"code","780e22c1":"code","2b82114c":"code","1af64451":"code","84b7fd9a":"code","875cf507":"code","865cbc7b":"code","e14c812c":"code","7888fc32":"code","35fb60c5":"code","8023a4ed":"code","796db30a":"code","3898109c":"code","3b7c4396":"code","e6ce900a":"markdown","0a968849":"markdown","ef6f213b":"markdown","0bb0775f":"markdown","5d99bc36":"markdown","c12a2433":"markdown","d0cbb69a":"markdown","e8869986":"markdown","04e9eebd":"markdown","b85b0867":"markdown","a9cc33a5":"markdown","3ce0bedb":"markdown","0b870f6c":"markdown","4a41a944":"markdown","075dfe6f":"markdown","e7cf200d":"markdown","545a0cc1":"markdown","04f68f0d":"markdown"},"source":{"ebd7027b":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib.gridspec import  GridSpec\nimport plotly.graph_objs as go \nfrom plotly.offline import init_notebook_mode, iplot, plot\ninit_notebook_mode(connected=True) \nimport warnings\nwarnings.filterwarnings('ignore')\nimport pandas_profiling as pp\n#import DataScienceHelper as dsh\n\n%matplotlib inline\n\nfrom sklearn.utils import resample\nfrom sklearn.linear_model import LogisticRegression, Perceptron, RidgeClassifier, SGDClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier \nfrom sklearn.ensemble import BaggingClassifier, VotingClassifier \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.preprocessing import normalize, StandardScaler\nfrom sklearn import metrics \n\n\n\n","ebd478f2":"## We look at the data using the head and tail functions\nHF = pd.read_csv('\/kaggle\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')\n\nHF.head(5)","d74aeab3":"HF.tail(5)","4ab158cd":"HF.shape","869cafd9":"HF.info()","019b006d":"HF.describe()","ea8ef3b4":"HF.isnull().sum()","b2e00f58":"## Change the data type of the variables with Binary values to the appropriate data type\nHF[\"anaemia\"] = HF[\"anaemia\"].astype(str)\nHF[\"diabetes\"] = HF[\"diabetes\"].astype(str)\nHF[\"high_blood_pressure\"] = HF[\"high_blood_pressure\"].astype(str)\nHF[\"sex\"] = HF[\"sex\"].astype(str)\nHF[\"smoking\"] = HF[\"smoking\"].astype(str)\nHF[\"DEATH_EVENT\"] = HF[\"DEATH_EVENT\"].astype(str)\n","bf8c97a0":"print(HF.describe())\nprint(HF.describe(include = np.object))","914f6b7f":"columns = list(HF._get_numeric_data().keys())\n\ncolumns","b2c7497e":"pp.ProfileReport(HF) ## Another way of generating descriptive statistics using Pandas Profiling package","a1bd2d1f":"dsh.show_kdeplot(HF, columns)","eeb05df6":"dsh.show_boxplot(HF, columns)","c2f4c3da":"## First reconvert the categorical binary variables to intergers\ncat_columns = list(HF.select_dtypes(include = 'object').keys())\n\nfor column in cat_columns:\n    HF[column] = HF[column].astype(int)\n\nprint(cat_columns)","7840cc7f":"## Then we proceed with the correlation matrix\nHF_matrix = HF.corr()\n\nf, ax = plt.subplots(figsize = (12,10))\nk = 13 ## Number of columns in the matrix\n## Use the DEATH EVENT variable as index as it will be compared against other variables\ncols = HF_matrix.nlargest(k, 'DEATH_EVENT')['DEATH_EVENT'].index \nhfm = np.corrcoef(HF[cols].values.T)\nsns.set(font_scale = 1.5)\n\nsns.heatmap(hfm, cbar = True, annot = True, square = True, fmt = '.2f', annot_kws = {'size': 12},\n           cmap = 'BrBG', yticklabels = cols.values, xticklabels = cols.values)\n\nplt.show()\n","149cb0fd":"HF['DEATH_EVENT'].value_counts()","cff531fd":"Death_major = HF[HF['DEATH_EVENT'] == 0]\nDeath_minor = HF[HF['DEATH_EVENT'] == 1]\n\nUP_min = resample(Death_minor, replace = True, n_samples = 203, random_state = 320)\n\n## Combine the majority class with the upsampled minority class\nHFN = pd.concat([Death_major, UP_min])\n\nHFN['DEATH_EVENT'].value_counts()","70b241d7":"## get the target variable and the independent variables\ntarget = HFN['DEATH_EVENT']\nindependent = HFN.drop(['DEATH_EVENT'], axis = 1)","b8dc96ad":"## Normalize the independent variable values\nindependent = normalize(independent)\nindependent = StandardScaler().fit_transform(independent)\n\n\n\n## OR\n# independent = StandardScaler().fit_transform(normalize(independent))","29106e59":"scores_lr = []\ntrain_list = []\nfor i in range(1,10):\n    x_train, x_test, y_train, y_test = train_test_split(independent, target,test_size = i\/10, random_state = 123)\n    \n    \n    lr = LogisticRegression()\n    lr.fit(x_train,y_train) \n    print(\"Test accuracy: {}\/Test Size: {}\".format(np.round(lr.score(x_test,y_test),3),i))\n    scores_lr.append(lr.score(x_test,y_test))\n    train_list.append(lr.score(x_train,y_train))\n     \n    \n\nfig, ax = plt.subplots(1,2, figsize = (17,6))\ngs = fig.add_gridspec(1, 4)\n\ngrid = GridSpec(1, 4, left=0.1, bottom=0.05, right=1.2, top=0.94, wspace=0.3, hspace=0.3)\n\nax1 = fig.add_subplot(grid[0:3])\nax2 = fig.add_subplot(grid[3:4])\n\nax1.plot(range(1,10),scores_lr,label = \"Test Accuracy\")\nax1.plot(range(1,10),train_list, label = \"Train Accuracy\")\nax1.legend(fontsize = 15)\nax1.set_xlabel(\"Test Sizes\")\nax1.set_ylabel(\"Accuracy\")\nax1.set_title(\"Scores For Each Test Size\",fontsize = 17)\nax1.grid(True, alpha = 0.4)\n\n\nx_train, x_test, y_train, y_test = train_test_split(independent, \n                                                    target,test_size = (1 + scores_lr.index(np.max(scores_lr)))\/10, \n                                                    random_state = 123)\n\nlr_best = LogisticRegression(random_state = 123)\nlr_best = lr_best.fit(x_train, y_train)\ny_pred = lr_best.predict(x_test)\ny_true = y_test\n\n\ncm = confusion_matrix(y_true,y_pred)\n\nsns.heatmap(cm, annot=True, annot_kws = {\"size\": 25}, linewidths=0.5, fmt = '.0f',\n            ax = ax2,cmap = \"Blues\",linecolor = \"black\")\nplt.title(\"Logistic Regression Confusion Matrix\",fontsize = 17)\nplt.show()\n\nprint(\"Best Accuracy(test): {}\/Test Size: {}\".format(np.max(scores_lr), 1 + scores_lr.index(np.max(scores_lr))))\n\n       ","ec1fb0f9":"print(classification_report(y_pred, y_true))","ed4a7c88":"pred_prob = lr_best.predict_proba(x_test)\n\ny_preds = pred_prob[:, 1]\nfpr, tpr, _ = metrics.roc_curve(y_true, y_preds)\nauc_score = metrics.auc(fpr, tpr)\n\nplt.figure(figsize = (10,10))\nplt.title('ROC Curve: Logistic')\nplt.plot(fpr, tpr, label = 'AUC = {:.2f}'.format(auc_score))\nplt.plot([0, 1], [0, 1], 'r--')\n\nplt.xlim(-0.1, 1.1)\nplt.ylim(-0.1, 1.1)\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.legend(loc = 'lower right')\nplt.show()","8bdd3e9a":"x_train, x_test, y_train, y_test = train_test_split(independent, target, test_size = 0.2, random_state = 123)\n\nscores_knn = []\ntrain_list = []\nfor i in range(1,25):\n    knn = KNeighborsClassifier(n_neighbors = i)\n    knn.fit(x_train,y_train)\n    print(\"test accuracy: {}\/Neighbors: {}\".format(np.round(knn.score(x_test,y_test), 3),i))\n    scores_knn.append(knn.score(x_test,y_test))\n    train_list.append(knn.score(x_train,y_train))\n    \n\nfig, ax = plt.subplots(1,2, figsize = (17,6))\ngs = fig.add_gridspec(1, 4)\n\ngrid = GridSpec(1,4,left=0.1, bottom=0.05, right=1.2, top=0.94, wspace=0.3, hspace=0.3)\n\nax1 = fig.add_subplot(grid[0:3])\nax2 = fig.add_subplot(grid[3:4])    \n\nax1.plot(range(1,25),scores_knn, label = \"Test Accuracy\")\nax1.plot(range(1,25),train_list,c = \"orange\", label = \"Train Accuracy\")\nax1.legend(fontsize = 15)\nax1.set_xlabel(\"K Values\")\nax1.set_ylabel(\"Accuracy\")\nax1.set_title(\"Scores For Each K Value\",fontsize = 17)\nax1.grid(True , alpha = 0.4)\n\n\n\nBest_knn = KNeighborsClassifier(n_neighbors = 1 + scores_knn.index(np.max(scores_knn)))\nBest_knn = Best_knn.fit(x_train, y_train)\ny_pred = Best_knn.predict(x_test)\ny_true = y_test\n\ncm = confusion_matrix(y_true,y_pred)\n\n\nsns.heatmap(cm, annot=True,annot_kws = {\"size\": 25}, linewidths=0.5, fmt = '.0f', ax=ax2,cmap = \"Blues\",linecolor = \"black\")\nplt.title(\"KNN Confusion Matrix\",fontsize = 17)\nplt.show()\n\nprint(\"Best Accuracy(test): {}\/Neighbors: {}\".format(np.max(scores_knn),1 + scores_knn.index(np.max(scores_knn))))\n","883d3fc1":"print(classification_report(y_pred, y_true))","61f8725d":"knn_prob = Best_knn.predict_proba(x_test)\n\ny_preds = knn_prob[:, 1]\nfpr, tpr, _ = metrics.roc_curve(y_true, y_preds)\nauc_score = metrics.auc(fpr, tpr)\n\nplt.figure(figsize = (10,10))\nplt.title('ROC Curve: KNN')\nplt.plot(fpr, tpr, label = 'AUC = {:.2f}'.format(auc_score))\nplt.plot([0, 1], [0, 1], 'r--')\n\nplt.xlim(-0.1, 1.1)\nplt.ylim(-0.1, 1.1)\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.legend(loc = 'lower right')\nplt.show()","4124e746":"scores_svm = []\ntrain_list = []\nfor i in range(100,500,50):\n    svm = SVC(cache_size = i)\n    svm.fit(x_train,y_train)\n    print(\"test accuracy: {}\/Cache Size: {}\".format(np.round(svm.score(x_test,y_test),3),i))\n    scores_svm.append(svm.score(x_test,y_test))\n    train_list.append(svm.score(x_train,y_train))\n\n\n\nfig, ax = plt.subplots(1,2, figsize = (17,6))\ngs = fig.add_gridspec(1, 4)\n\ngrid = GridSpec(1,4,left=0.1, bottom=0.05, right=1.2, top=0.94, wspace=0.3, hspace=0.3)\n\nax1 = fig.add_subplot(grid[0:3])\nax2 = fig.add_subplot(grid[3:4])  \n    \nax1.plot(range(100,500,50), scores_svm, label = \"Test Accuracy\")\nax1.plot(range(100,500,50), train_list,c = \"orange\", label = \"Train Accuracy\")\nax1.legend(fontsize = 15)\nax1.set_xlabel(\"Cache Sizes\")\nax1.set_ylabel(\"Accuracy\")\nax1.set_title(\"Scores For Each Cache Size\",fontsize = 17)\nax1.grid(True , alpha = 0.4)\n\nBest_SVM = SVC(cache_size = 50*(1+scores_svm.index(np.max(scores_svm))))\nBest_SVM = Best_SVM.fit(x_train, y_train)\ny_pred = Best_SVM.predict(x_test)\ny_true = y_test\n\ncm = confusion_matrix(y_true,y_pred)\n\nsns.heatmap(cm, annot=True,annot_kws = {\"size\": 25}, linewidths=0.5, fmt = '.0f', ax=ax2,cmap = \"Blues\",linecolor = \"black\")\nplt.title(\"Confusion Matrix\",fontsize = 17)\nplt.show()\n\nprint(\"Best Accuracy(test): {}\/Cache Size: {}\".format(np.max(scores_svm), \n                                                      50 + 50 * (1 + scores_svm.index(np.max(scores_svm)))))","ca21b594":"print(classification_report(y_pred, y_true))","5e8d344a":"scores_dt = []\ntrain_list = []\nfor d in range(1,10):\n    clf = DecisionTreeClassifier(max_depth = d,random_state = 123)\n    clf = clf.fit(x_train, y_train)\n    print(\"Test accuracy: {}\/Max Depth: {}\".format(np.round(clf.score(x_test,y_test),3),d))\n    scores_dt.append(clf.score(x_test,y_test))\n    train_list.append(clf.score(x_train,y_train))\n    \nfig, ax = plt.subplots(1,2, figsize = (17,6))\ngs = fig.add_gridspec(1, 4)\n\ngrid = GridSpec(1,4,left=0.1, bottom=0.05, right=1.2, top=0.94, wspace=0.3, hspace=0.3)\n\nax1 = fig.add_subplot(grid[0:3])\nax2 = fig.add_subplot(grid[3:4])  \n    \nax1.plot(range(1,10),scores_dt,label = \"Test Score\")\nax1.plot(range(1,10),train_list,label = \"Train Score\")\nax1.legend(fontsize = 15)\nax1.set_xlabel(\"Max Depth\")\nax1.set_ylabel(\"Accuracy\")\nax1.grid(True, alpha = 0.5)\nax1.set_title(\"Accuricies for each Max Depth Value\",fontsize = 17)\n\nBest_DT = DecisionTreeClassifier(max_depth = 1 + scores_dt.index(np.max(scores_dt)))\nBest_DT = Best_DT.fit(x_train, y_train)\ny_pred = Best_DT.predict(x_test)\ny_true = y_test\n\ncm = confusion_matrix(y_true,y_pred)\n\nsns.heatmap(cm, annot=True,annot_kws = {\"size\": 25}, linewidths=0.5, fmt = '.0f', ax=ax2,cmap = \"Blues\",linecolor = \"black\")\nplt.title(\"Confusion Matrix\",fontsize = 17)\nplt.show()\n\nprint(\"Best Accuracy: {}\/Max Depth: {}\".format(np.max(scores_dt), 1 + scores_dt.index(np.max(scores_dt))))","9ef1b78b":"print(classification_report(y_pred, y_true))","780e22c1":"DT_prob = Best_DT.predict_proba(x_test)\n\ny_preds = DT_prob[:, 1]\nfpr, tpr, _ = metrics.roc_curve(y_true, y_preds)\nauc_score = metrics.auc(fpr, tpr)\n\nplt.figure(figsize = (10,10))\nplt.title('ROC Curve: Decision Tree')\nplt.plot(fpr, tpr, label = 'AUC = {:.2f}'.format(auc_score))\nplt.plot([0, 1], [0, 1], 'r--')\n\nplt.xlim(-0.1, 1.1)\nplt.ylim(-0.1, 1.1)\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.legend(loc = 'lower right')\nplt.show()","2b82114c":"scores_rf = []\ntrain_list = []\n\nfor i in range(20,160,20):\n    rf = RandomForestClassifier(n_estimators = i, random_state = 123) #100\n    rf.fit(x_train,y_train)\n    print(\"Test Score: {}\/Number of Estimators: {} \".format(np.round(rf.score(x_test,y_test),3),i))\n    scores_rf.append(rf.score(x_test,y_test))\n    train_list.append(rf.score(x_train,y_train))\n\nfig, ax = plt.subplots(1,2, figsize = (17,6))\ngs = fig.add_gridspec(1, 4)\n\ngrid = GridSpec(1,4,left=0.1, bottom=0.05, right=1.2, top=0.94, wspace=0.3, hspace=0.3)\n\nax1 = fig.add_subplot(grid[0:3])\nax2 = fig.add_subplot(grid[3:4])  \n\nax1.plot(range(20,160,20),scores_rf,label = \"Test Accuracy\")\nax1.plot(range(20,160,20),train_list,label = \"Train Accuracy\")\nax1.legend(fontsize = 15)\nax1.set_xlabel(\"N Estimators\")\nax1.set_ylabel(\"Accuracy\")\nax1.set_title(\"Scores for each N Estimator\",fontsize = 17)\nax1.grid(True, alpha=0.5)\n\nBest_rf = RandomForestClassifier(n_estimators = 20*(1+scores_rf.index(np.max(scores_rf))))\nBest_rf = Best_rf.fit(x_train, y_train)\ny_pred = Best_rf.predict(x_test)\ny_true = y_test\n\ncm = confusion_matrix(y_true,y_pred)\n\nsns.heatmap(cm, annot=True,annot_kws = {\"size\": 25}, linewidths=0.5, fmt = '.0f', ax=ax2,cmap = \"Blues\",linecolor = \"black\")\nplt.title(\"Confusion Matrix\",fontsize = 17)\nplt.show()\n\n\nprint(\"Best Accuracy: {}\/Max Depth: {}\".format(np.max(scores_rf),\n                                               20*(1+scores_rf.index(np.max(scores_rf)))))","1af64451":"print(classification_report(y_pred, y_true))","84b7fd9a":"rf_prob = Best_rf.predict_proba(x_test)\n\ny_preds = rf_prob[:, 1]\nfpr, tpr, _ = metrics.roc_curve(y_true, y_preds)\nauc_score = metrics.auc(fpr, tpr)\n\nplt.figure(figsize = (10,10))\nplt.title('ROC Curve: Random Forest')\nplt.plot(fpr, tpr, label = 'AUC = {:.2f}'.format(auc_score))\nplt.plot([0, 1], [0, 1], 'r--')\n\nplt.xlim(-0.1, 1.1)\nplt.ylim(-0.1, 1.1)\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.legend(loc = 'lower right')\nplt.show()","875cf507":"scores_per = []\ntrain_list = []\nfor i in np.arange(0.0001, 0.001, 0.0001):\n    perceptron = Perceptron(alpha = i, random_state = 123) \n    perceptron.fit(x_train,y_train)\n    print(\"Test Score: {}\/Alpha: {} \".format(np.round(perceptron.score(x_test,y_test),3),np.round(i,5)))\n    scores_per.append(perceptron.score(x_test,y_test))\n    train_list.append(perceptron.score(x_train,y_train))\n\nfig, ax = plt.subplots(1,2, figsize = (17,6))\ngs = fig.add_gridspec(1, 4)\n\ngrid = GridSpec(1,4,left=0.1, bottom=0.05, right=1.2, top=0.94, wspace=0.3, hspace=0.3)\n\nax1 = fig.add_subplot(grid[0:3])\nax2 = fig.add_subplot(grid[3:4])      \n\nax1.plot(np.arange(0.0001,0.001, 0.0001),scores_per,label = \"Test Accuracy\")\nax1.plot(np.arange(0.0001,0.001, 0.0001),train_list,label = \"Train Accuracy\")\nax1.legend(fontsize = 15)\nax1.set_xlabel(\"Alpha\")\nax1.set_ylabel(\"Accuracy\")\nax1.set_title(\"Scores for each Alpha\",fontsize = 17)\nax1.grid(True, alpha=0.5)    \n\nBest_per = Perceptron(alpha = 0.0001+0.0001*(1+scores_per.index(np.max(scores_per))))\nBest_per = Best_per.fit(x_train, y_train)\ny_pred = Best_per.predict(x_test)\ny_true = y_test\n\ncm = confusion_matrix(y_true,y_pred)\n\nsns.heatmap(cm, annot=True,annot_kws = {\"size\": 25}, linewidths=0.5, fmt = '.0f', ax=ax2,cmap = \"Blues\",linecolor = \"black\")\nplt.title(\"Confusion Matrix\",fontsize = 17)\nplt.show()\n\nprint(\"Best Accuracy: {}\/Alpha: {}\".format(np.max(scores_per),0.0001*(1+scores_per.index(np.max(scores_per)))))","865cbc7b":"print(classification_report(y_pred, y_true))","e14c812c":"scores_SGD = []\ntrain_list = []\nfor i in np.arange(0.05, 0.3, 0.02):\n    sgd = SGDClassifier(epsilon = i, random_state = 123) \n    sgd.fit(x_train,y_train)\n    print(\"Test Score: {}\/Epsilon: {} \".format(np.round(sgd.score(x_test,y_test),3),np.round(i,4)))\n    scores_SGD.append(sgd.score(x_test,y_test))\n    train_list.append(sgd.score(x_train,y_train))\n\nfig, ax = plt.subplots(1,2, figsize = (17,6))\ngs = fig.add_gridspec(1, 4)\n\ngrid = GridSpec(1,4,left=0.1, bottom=0.05, right=1.2, top=0.94, wspace=0.3, hspace=0.3)\n\nax1 = fig.add_subplot(grid[0:3])\nax2 = fig.add_subplot(grid[3:4])    \n\nax1.plot(np.arange(0.05, 0.3, 0.02),scores_SGD,label = \"Test Accuracy\")\nax1.plot(np.arange(0.05, 0.3, 0.02),train_list,label = \"Train Accuracy\")\nax1.legend(fontsize = 15)\nax1.set_xlabel(\"Epsilons\")\nax1.set_ylabel(\"Accuracy\")\nax1.set_title(\"Scores for each Epsilon\", fontsize = 17)\nax1.grid(True, alpha=0.5)\n\nBest_SGD = SGDClassifier(epsilon = 0.03+0.02*(1 + scores_SGD.index(np.max(scores_SGD))))\nBest_SGD = Best_SGD.fit(x_train, y_train)\ny_pred = Best_SGD.predict(x_test)\ny_true = y_test\n\ncm = confusion_matrix(y_true,y_pred)\n\nsns.heatmap(cm, annot=True,annot_kws = {\"size\": 25}, linewidths=0.5, fmt = '.0f', ax=ax2,cmap = \"Blues\",linecolor = \"black\")\nplt.title(\"Confusion Matrix\",fontsize = 17)\nplt.show()\n\nprint(\"Best Accuracy: {}\/Epsilon: {}\".format(np.max(scores_SGD),\n                                             0.03+0.02*(1+scores_SGD.index(np.max(scores_SGD)))))","7888fc32":"print(classification_report(y_pred, y_true))","35fb60c5":"scores_ridge = []\ntrain_list = []\nfor i in np.arange(0.0005, 0.003, 0.0005):\n    ridge = RidgeClassifier(tol = i, random_state = 123) \n    ridge.fit(x_train,y_train)\n    print(\"Test Score: {}\/Tol: {} \".format(np.round(ridge.score(x_test,y_test),3),np.round(i,4)))\n    scores_ridge.append(ridge.score(x_test,y_test))\n    train_list.append(ridge.score(x_train,y_train))\n\nfig, ax = plt.subplots(1,2, figsize = (17,6))\ngs = fig.add_gridspec(1, 4)\n\ngrid = GridSpec(1,4,left=0.1, bottom=0.05, right=1.2, top=0.94, wspace=0.3, hspace=0.3)\n\nax1 = fig.add_subplot(grid[0:3])\nax2 = fig.add_subplot(grid[3:4])  \n\nax1.plot(np.arange(0.0005, 0.003, 0.0005),scores_ridge,label = \"Test Accuracy\")\nax1.plot(np.arange(0.0005, 0.003, 0.0005),train_list,label = \"Train Accuracy\")\nax1.legend(fontsize = 15)\nax1.set_xlabel(\"Tols\")\nax1.set_ylabel(\"Accuracy\")\nax1.set_title(\"Scores for each Tol\",fontsize = 17)\nax1.grid(True, alpha=0.5)\n\nBest_Ridge = RidgeClassifier(tol = 0.0005*(1+scores_ridge.index(np.max(scores_ridge))))\nBest_Ridge = Best_Ridge.fit(x_train, y_train)\ny_pred = Best_Ridge.predict(x_test)\ny_true = y_test\n\ncm = confusion_matrix(y_true,y_pred)\n\nsns.heatmap(cm, annot=True,annot_kws = {\"size\": 25}, linewidths=0.5, fmt = '.0f', ax=ax2,cmap = \"Blues\",linecolor = \"black\")\nplt.title(\"Confusion Matrix\",fontsize = 17)\nplt.show()\n\nprint(\"Best Accuracy: {}\/Tol: {}\".format(np.max(scores_ridge),0.0005*(1+scores_ridge.index(np.max(scores_ridge)))))","8023a4ed":"print(classification_report(y_true, y_pred))","796db30a":"nb = GaussianNB()\nnb.fit(x_train,y_train)\n\nprint(\"Test Accuracy: \",nb.score(x_test,y_test))\n\ny_pred = nb.predict(x_test)\ny_true = y_test\n\ncm = confusion_matrix(y_true,y_pred)\n\nplt.figure(figsize = (6,6))\nsns.heatmap(cm, annot=True,annot_kws = {\"size\": 25}, linewidths=0.5, fmt = '.0f',cmap = \"Blues\",linecolor = \"black\")\nplt.title(\"NB Confusion Matrix\",fontsize = 17)\nplt.show()","3898109c":"models = {\"Models\":[\"Logistic Regression\",\n                       \"KNN\",\n                       \"SVC\",\n                       \"Decision Tree\",\n                       \"Random Forest\",\n                       \"Perceptron\",\n                       \"Sthocastic Gradient Descent\",\n                       \"Ridge\", \"Naive Bayes\"],\n             \"Scores\":[np.max(scores_lr).round(3),\n                       np.max(scores_knn).round(3),\n                       np.max(scores_svm).round(3),\n                       np.max(scores_dt).round(3),\n                       np.max(scores_rf).round(3),\n                       np.max(scores_per).round(3),\n                       np.max(scores_SGD).round(3),\n                       np.max(scores_ridge).round(3),\n                       nb.score(x_test,y_test).round(3)]}\n\n\nmodelsDF = pd.DataFrame(models)\nmodelsDF = modelsDF.sort_values(by = [\"Scores\"])\nmodelsDF.head(len(modelsDF)) \n","3b7c4396":"trace = go.Bar(\n    x = modelsDF[\"Models\"],\n    y = modelsDF[\"Scores\"],\n    text = modelsDF[\"Scores\"],\n    textposition = \"auto\",\n    marker=dict(color = modelsDF[\"Scores\"],colorbar=dict(\n            title=\"ColorScale\"\n        ),colorscale=\"Viridis\",))\n\ndata = [trace]\nlayout = go.Layout(title = \"Comparison of Models\",template = \"plotly_white\")\n\nfig = go.Figure(data = data, layout = layout)\nfig.update_xaxes(title_text = \"Models\")\nfig.update_yaxes(title_text = \"Scores\")\nfig.show()","e6ce900a":"### Decision Trees","0a968849":"### Random Forests","ef6f213b":"#### We can see from the above that there are no missing values in any of the columns, which makes our job relatively much easier","0bb0775f":"### Perceptron","5d99bc36":"### Naive Bayes","c12a2433":"### Boxplots of Quatitative Variables","d0cbb69a":"#### The above shows that all variables of the integer and float type. However looking at summary statistics of the data we can see that some variables are of the binary format and as such cannot be analysed as either integer or floating variables. We have to rectify accordingly","e8869986":"### Support Vector Machine(SVM)","04e9eebd":"### Compile the results","b85b0867":"### K-Nearest Neighbours","a9cc33a5":"### KDE plots of Quantitative Variables","3ce0bedb":"#### From the above we can see that this is clearly an imbalanced data. Therefore, we will employ resampling techniques(Over Sampling)","0b870f6c":"# Visualizations","4a41a944":"# Modelling ","075dfe6f":"### Ridge Regression","e7cf200d":"### Stochastic Gradient Descent","545a0cc1":"### Logistic Regression","04f68f0d":"### Correlation Matrix"}}