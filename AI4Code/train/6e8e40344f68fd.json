{"cell_type":{"28a22378":"code","fdb29bd2":"code","07a7301d":"code","df642de7":"code","d3f1240b":"code","980b84fe":"code","115048cb":"code","f778e12e":"code","a3abdc76":"code","02bb5e33":"code","ad175e3e":"code","06da88a5":"code","5882eb96":"code","ee034ab9":"code","26283dac":"code","3a48faec":"code","85e8bc77":"code","9db16f8a":"code","01e66e01":"code","3c4f2e63":"code","660e6522":"code","0032fd81":"code","36e1448b":"code","68f17909":"code","05f1630b":"code","c27b02bf":"code","3a2a7539":"code","56abd461":"code","fe5a68f9":"code","f996f7cc":"code","276f44f9":"code","29ce0a0d":"code","ae9db1e9":"code","9c149c3c":"code","d05be73f":"code","1334af91":"code","4bfbbe24":"code","36214f07":"code","7eac1eed":"code","e77c268d":"code","046479d2":"code","b2353442":"code","f47d2f9a":"code","171d5d78":"code","4c8ff612":"code","f15a4ed2":"code","fd6319aa":"code","b816e61e":"code","b5386519":"code","326bfee4":"code","a66ca7e7":"code","46236c85":"code","5b5b00cd":"code","3bbb82de":"code","d09c6b49":"code","2d55b112":"code","f28baac3":"code","7686cd6a":"code","bf9f9e18":"code","0b18757b":"code","0044ac73":"code","39e3fc25":"code","aee3d329":"code","a58ebaab":"code","c0c1504d":"code","16bc317c":"code","251a890e":"code","8c33669a":"code","a6852a3e":"code","01caf6e6":"code","b8e02a6a":"code","0f210d0d":"code","b05b6b46":"code","06ff0592":"code","f3dee0c2":"code","5f7f8785":"code","225ae268":"code","e3d1bfb5":"code","f838f2d8":"code","0e59ca4f":"code","da1de7c4":"code","d8fb9f76":"code","330e79d2":"code","e59d5022":"code","26bca6ad":"code","0f8b7e81":"code","d39b833f":"code","e088b462":"code","4de5666a":"code","8b3406cf":"code","a2d0705f":"code","b53622e4":"code","608410b6":"code","bd602c6a":"code","52619271":"markdown","83ad84d7":"markdown","4779a938":"markdown","f2969284":"markdown","39ad5770":"markdown","5aea2af2":"markdown","7debcd71":"markdown","d44cba76":"markdown","e61724bf":"markdown","dd64aa2c":"markdown","07e98ac9":"markdown","4983959f":"markdown","e6f8f96e":"markdown","11597e51":"markdown","e04e1240":"markdown","77e54fbf":"markdown","f45c64cd":"markdown","5c539fdc":"markdown","bb7883c8":"markdown","2a2dafac":"markdown","cae6fa58":"markdown","7d02a933":"markdown","f1eb4f4a":"markdown","76c89298":"markdown","346493b0":"markdown","3afb25cc":"markdown","169fee67":"markdown","29fdf30e":"markdown","9c4fdc27":"markdown","ed18d8d0":"markdown","b9fd8b89":"markdown","120ccdcf":"markdown","0311557d":"markdown","a0a3c843":"markdown","b742cb14":"markdown","65c85263":"markdown","816168b4":"markdown","fb029a55":"markdown","52332842":"markdown","41006067":"markdown","447569c9":"markdown","f3895374":"markdown","e8abd74a":"markdown","cac8ac29":"markdown","962038db":"markdown","1b337769":"markdown","ebd5cc46":"markdown","6ec67929":"markdown","3151bb69":"markdown","c9501683":"markdown","9364c936":"markdown","6c43eb30":"markdown","4dae7072":"markdown","6136af60":"markdown"},"source":{"28a22378":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tabulate import tabulate\nimport missingno as msno\nimport tabulate as tb\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\nimport scipy.stats as stats\nimport statsmodels.stats.multicomp as multi\nfrom sklearn import preprocessing\nimport matplotlib.pyplot as plt \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns","fdb29bd2":"data = pd.DataFrame(pd.read_csv('..\/input\/heart-disease-prediction-using-logistic-regression\/framingham.csv'))\ndisplay(data)\ndata.shape","07a7301d":"data.dtypes","df642de7":"np.sum(data.isnull())","d3f1240b":"msno.matrix(data)","980b84fe":"#Descriptive statistics of numeric variables\ndata[['age','cigsPerDay','totChol','sysBP','diaBP','BMI','heartRate','glucose']].dropna().describe()","115048cb":"#Imputed data\ndata_wo_na=data.copy()\ndata_wo_na['cigsPerDay'] = data_wo_na['cigsPerDay'].fillna(data_wo_na['cigsPerDay'].mode().iloc[0])\ndata_wo_na['totChol'] = data_wo_na['totChol'].fillna(data_wo_na['totChol'].median())\ndata_wo_na['BMI'] = data_wo_na['BMI'].fillna(data_wo_na['BMI'].median())\ndata_wo_na['heartRate'] = data_wo_na['heartRate'].fillna(data_wo_na['heartRate'].median())\ndata_wo_na['glucose'] = data_wo_na['glucose'].fillna(data_wo_na['glucose'].median())\ndata_wo_na['education'] = data_wo_na['education'].fillna(data_wo_na['education'].mode().iloc[0])\ndata_wo_na['BPMeds'] = data_wo_na['BPMeds'].fillna(0)","f778e12e":"bins = [29, 39, 49, 59, 69, 79]\nlabels = ['30-39', '40-49', '50-59', '60-69', '70-79']\ndata['agerange'] = pd.cut(data.age, bins, labels = labels,include_lowest = True)\nbins = [29, 39, 49, 59, 69, 79]\nlabels = ['30-39', '40-49', '50-59', '60-69', '70-79']\ndata_wo_na['agerange'] = pd.cut(data.age, bins, labels = labels,include_lowest = True)","a3abdc76":"data[['male','education','currentSmoker','BPMeds','prevalentStroke','prevalentHyp','diabetes','TenYearCHD','education']]=data[['male','education','currentSmoker','BPMeds','prevalentStroke','prevalentHyp','diabetes','TenYearCHD','education']].astype('category')\nprint(data.dtypes)\ndata_wo_na[['male','education','currentSmoker','BPMeds','prevalentStroke','prevalentHyp','diabetes','TenYearCHD','education']]=data_wo_na[['male','education','currentSmoker','BPMeds','prevalentStroke','prevalentHyp','diabetes','TenYearCHD','education']].astype('category')\nprint(data_wo_na.dtypes)","02bb5e33":"data.groupby('TenYearCHD').mean()","ad175e3e":"#Descriptive statistics after imputation\ndata_wo_na[['age','cigsPerDay','totChol','sysBP','diaBP','BMI','heartRate','glucose']].describe()","06da88a5":"palette = sns.color_palette(\"mako_r\", 6)\nsns.catplot(x=\"TenYearCHD\", kind=\"count\",palette=palette, data=data)","5882eb96":"TenYearCHD_table=pd.crosstab(index=data['TenYearCHD'],columns='count')\nsns.heatmap(TenYearCHD_table, cmap=palette, annot=True, fmt='g');","ee034ab9":"#GENDER\nx, y, hue = \"TenYearCHD\", \"proportion\", \"male\"\nhue_order = [\"Female\", \"Male\"]\n\n(data[x]\n .groupby(data[hue])\n .value_counts(normalize=True)\n .rename(y)\n .reset_index()\n .pipe((sns.barplot, \"data\"), x=x, y=y, hue=hue,palette=palette))","26283dac":"from scipy.stats import chi2_contingency\nc=pd.crosstab(index=data['male'], columns=data['TenYearCHD'])\nsns.heatmap(c, cmap=palette, annot=True, fmt='g');","3a48faec":"stat, p, dof, expected = chi2_contingency(c)\n  \n# interpret p-value\nalpha = 0.05\nprint(\"Chi-Square Test Result\")\nprint(\"p value is \" + str(p))\nif p <= alpha:\n    print('Dependent (reject H0)')\nelse:\n    print('Independent (H0 holds true)')","85e8bc77":"#AGE\nage_CHD_table=pd.crosstab(index=data['agerange'],columns=data['TenYearCHD'])\nsns.heatmap(age_CHD_table, cmap=palette, annot=True, fmt='g');","9db16f8a":"x, y, hue = \"TenYearCHD\", \"proportion\", \"agerange\"\nhue_order = [\"30-39\", \"40-49\",\"50-59\",\"60-69\",\"70-79\"]\n\n(data[x]\n .groupby(data[hue])\n .value_counts(normalize=True)\n .rename(y)\n .reset_index()\n .pipe((sns.barplot, \"data\"), x=x, y=y, hue=hue,palette=palette))","01e66e01":"#EDUCATION\nx, y, hue = \"TenYearCHD\", \"proportion\", \"education\"\nhue_order = [1, 2,3,4]\n\n(data[x]\n .groupby(data[hue])\n .value_counts(normalize=True)\n .rename(y)\n .reset_index()\n .pipe((sns.barplot, \"data\"), x=x, y=y, hue=hue,palette=palette))","3c4f2e63":"c=pd.crosstab(index=data['education'], columns=data['TenYearCHD'])\nsns.heatmap(c, cmap=palette, annot=True, fmt='g');\nstat, p, dof, expected = chi2_contingency(c)\n  \n# interpret p-value\nalpha = 0.05\nprint(\"Chi-Square Test Result\")\nprint(\"p value is \" + str(p))\nif p <= alpha:\n    print('Dependent (reject H0)')\nelse:\n    print('Independent (H0 holds true)')","660e6522":"#PREVALENT STROKE\nc=pd.crosstab(index=data['prevalentStroke'], columns=data['TenYearCHD'])\nsns.heatmap(c, cmap=palette, annot=True, fmt='g');","0032fd81":"stat, p, dof, expected = chi2_contingency(c)\n  \n# interpret p-value\nalpha = 0.05\nprint(\"Chi-Square Test Result\")\nprint(\"p value is \" + str(p))\nif p <= alpha:\n    print('Dependent (reject H0)')\nelse:\n    print('Independent (H0 holds true)')","36e1448b":"#PREVALENT HYPERTENSION\nc=pd.crosstab(index=data['prevalentHyp'], columns=data['TenYearCHD'])\nsns.heatmap(c, cmap=palette, annot=True, fmt='g');","68f17909":"stat, p, dof, expected = chi2_contingency(c)\n  \n# interpret p-value\nalpha = 0.05\nprint(\"Chi-Square Test Result\")\nprint(\"p value is \" + str(p))\nif p <= alpha:\n    print('Dependent (reject H0)')\nelse:\n    print('Independent (H0 holds true)')","05f1630b":"#DIABETES\nc=pd.crosstab(index=data['diabetes'], columns=data['TenYearCHD'])\nsns.heatmap(c, cmap=palette, annot=True, fmt='g');","c27b02bf":"stat, p, dof, expected = chi2_contingency(c)\n  \n# interpret p-value\nalpha = 0.05\nprint(\"Chi-Square Test Result\")\nprint(\"p value is \" + str(p))\nif p <= alpha:\n    print('Dependent (reject H0)')\nelse:\n    print('Independent (H0 holds true)')","3a2a7539":"#SMOKING STATUS\nsns.catplot(x=\"currentSmoker\",hue=\"TenYearCHD\", kind=\"count\",palette=palette, data=data)","56abd461":"c=pd.crosstab(index=data['currentSmoker'], columns=data['TenYearCHD'])\nsns.heatmap(c, cmap=palette, annot=True, fmt='g');\n\nstat, p, dof, expected = chi2_contingency(c)\n  \n# interpret p-value\nalpha = 0.05\nprint(\"Chi-Square Test Result\")\nprint(\"p value is \" + str(p))\nif p <= alpha:\n    print('Dependent (reject H0)')\nelse:\n    print('Independent (H0 holds true)')","fe5a68f9":"#BODY MASS INDEX\nager_10ychd = pd.crosstab(index=data['agerange'],columns=data['TenYearCHD'],\n                    values=data['BMI'],\n                    aggfunc=np.mean).round(0)\nsns.heatmap(ager_10ychd, cmap=palette, annot=True, fmt='g');","f996f7cc":"sns.catplot(x=\"TenYearCHD\", y=\"BMI\",hue=\"agerange\", kind=\"box\", data=data,palette=palette)","276f44f9":"#GLUCOSE, TOTAL CHOLESTEROL, SYSTOLIC BLOOD PRESSURE, DIASTOLIC BLOOD PRESSURE, HEART RATE\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfig, axes = plt.subplots(2, 3, figsize=(18, 10))\n\nsns.boxplot(ax=axes[0, 0],data=data_wo_na, y=\"glucose\", x='TenYearCHD', palette=palette)\nsns.boxplot(ax=axes[0, 1],data=data_wo_na, y=\"totChol\", x='TenYearCHD', palette=palette)\nsns.boxplot(ax=axes[1, 0],data=data_wo_na, y=\"sysBP\", x='TenYearCHD', palette=palette)\nsns.boxplot(ax=axes[1, 1],data=data_wo_na, y=\"diaBP\", x='TenYearCHD', palette=palette)\nsns.boxplot(ax=axes[0, 2],data=data_wo_na, y=\"heartRate\", x='TenYearCHD', palette=palette)","29ce0a0d":"data['cigsPerDay'].value_counts()\nbins = [0,1,3,7,11,15,19,23,27,30,39,49,80]\nlabels = ['0','1-3', '4-7', '8-11', '12-15', '16-19','20-23','24-27','27-30','31-39','40-49','50+']\ndata['cigrange'] = pd.cut(data.cigsPerDay, bins, labels = labels,include_lowest = True)\ndata[['cigrange','cigsPerDay']]\ndata_wo_na['cigsPerDay'].value_counts()\nbins = [0,1,3,7,11,15,19,23,27,30,39,49,80]\nlabels = ['0','1-3', '4-7', '8-11', '12-15', '16-19','20-23','24-27','27-30','31-39','40-49','50+']\ndata_wo_na['cigrange1'] = pd.cut(data_wo_na.cigsPerDay, bins, labels = labels,include_lowest = True)\ndata_wo_na[['cigrange1','cigsPerDay']]\n#Groups that have the range of cigarettes smoked in a day were created to see the results in graphs without a mess.","ae9db1e9":"#HEART RATE\ncgr_10ychd = pd.crosstab(index=data_wo_na['cigrange1'],columns=data_wo_na['agerange'],\n                    values=data_wo_na['heartRate'],\n                    aggfunc=np.mean).round(0)\nsns.heatmap(cgr_10ychd, cmap=palette, annot=True, fmt='g');\nsns.catplot(x=\"cigrange1\", y=\"heartRate\",aspect=1.5, kind=\"box\", data=data_wo_na,palette=\"viridis\")","9c149c3c":"plt.hist(data_wo_na['heartRate'])\nstats.shapiro(data_wo_na['heartRate'])","d05be73f":"data_wo_na['cigrange1'].value_counts()","1334af91":"data_wo_na['cigrange1'].value_counts()\ncr0=data_wo_na['heartRate'][data_wo_na['cigrange1']=='0']\ncr1=data_wo_na['heartRate'][data_wo_na['cigrange1']=='1-3']\ncr2=data_wo_na['heartRate'][data_wo_na['cigrange1']=='4-7']\ncr3=data_wo_na['heartRate'][data_wo_na['cigrange1']=='8-11']\ncr4=data_wo_na['heartRate'][data_wo_na['cigrange1']=='12-15']\ncr5=data_wo_na['heartRate'][data_wo_na['cigrange1']=='16-19']\ncr6=data_wo_na['heartRate'][data_wo_na['cigrange1']=='20-23']\ncr7=data_wo_na['heartRate'][data_wo_na['cigrange1']=='24-27']\ncr8=data_wo_na['heartRate'][data_wo_na['cigrange1']=='28-31']\ncr9=data_wo_na['heartRate'][data_wo_na['cigrange1']=='31-39']\ncr10=data_wo_na['heartRate'][data_wo_na['cigrange1']=='40-49']\ncr11=data_wo_na['heartRate'][data_wo_na['cigrange1']=='50+']\ncr0=cr0.append(cr1)\ncr2=cr2.append(cr3)\ncr4=cr4.append(cr5)\ncr6=cr6.append(cr8)\ncr8=cr8.append(cr10)\ncr10=cr10.append(cr11)\n#perform Kruskal-Wallis Test \n\nstats.kruskal(cr0,cr2,cr4,cr6,cr8,cr10)","4bfbbe24":"#SYSTOLIC BLOOD PRESSURE\ncgr_10ychdsys = pd.crosstab(index=data_wo_na['cigrange1'],columns=data_wo_na['agerange'],\n                    values=data_wo_na['sysBP'],\n                    aggfunc=np.mean).round(0)\nsns.heatmap(cgr_10ychdsys, cmap=palette, annot=True, fmt='g');\nsns.catplot(x=\"cigrange\", y=\"sysBP\",aspect=1.5, kind=\"box\", data=data,palette=\"viridis\")","36214f07":"plt.hist(data_wo_na['sysBP'])\nstats.shapiro(data_wo_na['sysBP'])","7eac1eed":"data_wo_na['cigrange1'].value_counts()\ncr0=data_wo_na['sysBP'][data_wo_na['cigrange1']=='0']\ncr1=data_wo_na['sysBP'][data_wo_na['cigrange1']=='1-3']\ncr2=data_wo_na['sysBP'][data_wo_na['cigrange1']=='4-7']\ncr3=data_wo_na['sysBP'][data_wo_na['cigrange1']=='8-11']\ncr4=data_wo_na['sysBP'][data_wo_na['cigrange1']=='12-15']\ncr5=data_wo_na['sysBP'][data_wo_na['cigrange1']=='16-19']\ncr6=data_wo_na['sysBP'][data_wo_na['cigrange1']=='20-23']\ncr7=data_wo_na['sysBP'][data_wo_na['cigrange1']=='24-27']\ncr8=data_wo_na['sysBP'][data_wo_na['cigrange1']=='28-31']\ncr9=data_wo_na['sysBP'][data_wo_na['cigrange1']=='31-39']\ncr10=data_wo_na['sysBP'][data_wo_na['cigrange1']=='40-49']\ncr11=data_wo_na['sysBP'][data_wo_na['cigrange1']=='50+']\ncr0=cr0.append(cr1)\ncr2=cr2.append(cr3)\ncr4=cr4.append(cr5)\ncr6=cr6.append(cr8)\ncr8=cr8.append(cr10)\ncr10=cr10.append(cr11)\n#perform Kruskal-Wallis Test \nstats.kruskal(cr0,cr2,cr4,cr6,cr8,cr10)","e77c268d":"x, y, hue = \"currentSmoker\", \"proportion\", \"male\"\nhue_order = [\"Male\", \"Female\"]\n\n(data[x]\n .groupby(data[hue])\n .value_counts(normalize=True)\n .rename(y)\n .reset_index()\n .pipe((sns.barplot, \"data\"), x=x, y=y, hue=hue,palette=palette))","046479d2":"x, y, hue = \"currentSmoker\", \"proportion\", \"agerange\"\nhue_order = [\"30-39\",\"40-49\",\"50-59\",\"60-69\",\"70-79\"]\n\n(data[x]\n .groupby(data[hue])\n .value_counts(normalize=True)\n .rename(y)\n .reset_index()\n .pipe((sns.barplot, \"data\"), x=x, y=y, hue=hue,palette=palette))","b2353442":"sns.catplot(x=\"cigrange\", kind=\"count\",hue='male', aspect=1.5, data=data,palette=palette)","f47d2f9a":"#EDUCATION\nfrom matplotlib import cm\n# Prepare Data\ndf = data.groupby('education').size()\n\n# Make the plot with pandas\ndf.plot(kind='pie', subplots=True, figsize=(8, 8),cmap=\"crest\", autopct='%1.1f%%')\nplt.title(\"Pie Chart of Education\")\nplt.ylabel(\"\")\nplt.show()","171d5d78":"sns.catplot(x=\"education\",y='cigsPerDay' ,kind=\"bar\", aspect=1.5, data=data,palette=palette)","4c8ff612":"sns.catplot(x='education' ,hue=\"currentSmoker\",kind=\"count\", aspect=1.5, data=data,palette=palette)","f15a4ed2":"#HEART RATE\nsns.catplot(x=\"agerange\", y=\"heartRate\",aspect=1.5, kind=\"box\", data=data_wo_na,palette=\"viridis\")","fd6319aa":"data_wo_na['agerange'].value_counts()\nar3=data_wo_na['heartRate'][data_wo_na['agerange']=='30-39']\nar4=data_wo_na['heartRate'][data_wo_na['agerange']=='40-49']\nar5=data_wo_na['heartRate'][data_wo_na['agerange']=='50-59']\nar6=data_wo_na['heartRate'][data_wo_na['agerange']=='60-69']\nar7=data_wo_na['heartRate'][data_wo_na['agerange']=='70-79']\n#perform Kruskal-Wallis Test \nstats.kruskal(ar3, ar4 ,ar5, ar6, ar7)","b816e61e":"#SYSTOLIC BLOOD PRESSURE\nsns.catplot(x=\"agerange\", y=\"sysBP\",aspect=1.5, kind=\"box\", data=data_wo_na,palette=\"viridis\")","b5386519":"data_wo_na['agerange'].value_counts()\nar3=data_wo_na['sysBP'][data_wo_na['agerange']=='30-39']\nar4=data_wo_na['sysBP'][data_wo_na['agerange']=='40-49']\nar5=data_wo_na['sysBP'][data_wo_na['agerange']=='50-59']\nar6=data_wo_na['sysBP'][data_wo_na['agerange']=='60-69']\nar7=data_wo_na['sysBP'][data_wo_na['agerange']=='70-79']\n#perform Kruskal-Wallis Test \nstats.kruskal(ar3, ar4 ,ar5, ar6, ar7)","326bfee4":"sns.catplot(x=\"agerange\", y=\"glucose\",aspect=1.5, kind=\"box\", data=data_wo_na,palette=\"viridis\")","a66ca7e7":"plt.hist(data_wo_na['glucose'])","46236c85":"data_wo_na['agerange'].value_counts()\nar3=data_wo_na['glucose'][data_wo_na['agerange']=='30-39']\nar4=data_wo_na['glucose'][data_wo_na['agerange']=='40-49']\nar5=data_wo_na['glucose'][data_wo_na['agerange']=='50-59']\nar6=data_wo_na['glucose'][data_wo_na['agerange']=='60-69']\nar7=data_wo_na['glucose'][data_wo_na['agerange']=='70-79']\n#perform Kruskal-Wallis Test \nstats.kruskal(ar3, ar4 ,ar5, ar6, ar7)","5b5b00cd":"plt.rc(\"font\", size=14)\nsns.set(style=\"white\")\nsns.set(style=\"whitegrid\", color_codes=True)\ndata_wo_na = data_wo_na.rename(columns={'TenYearCHD': 'y'})\ndata_wo_na=data_wo_na.drop(columns=['agerange','cigrange1'])\neducation=pd.get_dummies(data_wo_na['education'])\neducation.columns=['education_1','education_2','education_3','education_4']\neducation","3bbb82de":"data_wo_na=pd.concat([data_wo_na,education],axis=1)\ndata_wo_na=data_wo_na.drop(columns='education')\ndata_wo_na","d09c6b49":"#OUTLIER DETECTION\ndatanum=data_wo_na[['cigsPerDay','totChol','sysBP','diaBP','BMI','heartRate','glucose']].copy()\ndatacat=data_wo_na.drop(columns=['cigsPerDay','totChol','sysBP','diaBP','BMI','heartRate','glucose']).copy()\nQ1 = datanum.quantile(0.25)\nQ3 = datanum.quantile(0.75)\nIQR = Q3 - Q1\nprint(IQR)\ndatanum = datanum[~((datanum < (Q1 - 1.5 * IQR)) |(datanum > (Q3 + 1.5 * IQR))).any(axis=1)]\ndatanum.shape","2d55b112":"datanumcat=pd.concat([datacat, datanum], axis=1)\ndatanumcat=datanumcat.dropna()\ndatanumcat[['age','cigsPerDay','totChol','sysBP','diaBP','BMI','heartRate','glucose']].describe()\n#Descriptive statistics after deleting outliers","f28baac3":"#MULTICOLLINEARITY CHECK\n# Correlation\nplt.figure(figsize=(6,5), dpi= 80)\nsns.heatmap(datanumcat[['totChol',\t'sysBP',\t'diaBP'\t,'BMI'\t,'heartRate',\t'glucose']].corr(), xticklabels=datanumcat[['totChol',\t'sysBP',\t'diaBP'\t,'BMI'\t,'heartRate',\t'glucose']].corr().columns, yticklabels=datanumcat[['totChol',\t'sysBP',\t'diaBP'\t,'BMI'\t,'heartRate',\t'glucose']].corr().columns, cmap=\"viridis\", center=0, annot=True)\n\n# Decorations\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\nplt.show()","7686cd6a":"# Import library for VIF\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\ndef calc_vif(X):\n\n    # Calculating VIF\n    vif = pd.DataFrame()\n    vif[\"variables\"] = X.columns\n    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n\n    return(vif)\nvif_data=datanumcat[['totChol',\t'sysBP',\t'diaBP'\t,'BMI'\t,'heartRate',\t'glucose']].copy() #Burada standardized etmeden \u00f6nceki VIF valuelar\u0131 da g\u00f6stermek laz\u0131m\ncalc_vif(vif_data)","bf9f9e18":"#SCALING\nfrom numpy import asarray\nfrom sklearn.preprocessing import MinMaxScaler\n# define min max scaler\nscaler = MinMaxScaler()\n# transform data\ndatanum2=datanumcat[['totChol','sysBP','diaBP','BMI','heartRate','glucose']].copy()\ndatanum2=pd.DataFrame(scaler.fit_transform(datanum2))\nprint(datanum2)\ndatanum2.columns=['totChol','sysBP','diaBP','BMI','heartRate','glucose']\ndatacat2=datanumcat.drop(columns=['totChol','sysBP','diaBP','BMI','heartRate','glucose']).copy()\ndata_log= pd.concat([datanum2, datacat2], axis=1)","0b18757b":"data_log=data_log.dropna()\nvif_data=data_log[['totChol',\t'sysBP',\t'diaBP'\t,'BMI'\t,'heartRate',\t'glucose']].copy() #Burada standardized etmeden \u00f6nceki VIF valuelar\u0131 da g\u00f6stermek laz\u0131m\ncalc_vif(vif_data)","0044ac73":"#After deleting diaBP\nvif_data=data_log[['totChol',\t'sysBP'\t,'BMI'\t,'heartRate',\t'glucose']].copy() #Burada standardized etmeden \u00f6nceki VIF valuelar\u0131 da g\u00f6stermek laz\u0131m\ncalc_vif(vif_data)","39e3fc25":"#After scaling and elimination, VIF values became less than 10. So, there is no multicollinearity between variables now.\ndata_log=data_log.drop(columns='diaBP',axis=1)","aee3d329":"data_log\ndata_final=data_log.copy()\ndata_final.columns.values\nX = data_final.loc[:, data_final.columns != 'y']\ny = data_final.loc[:, data_final.columns == 'y']","a58ebaab":"#OVERSAMPLING FOR IMBALANCED DATA\nfrom collections import Counter\nfrom imblearn.over_sampling import RandomOverSampler \n\nros = RandomOverSampler(sampling_strategy=1, random_state=42)\nX, y = ros.fit_resample(X, y)\n\nprint('Resampled dataset shape %s' % Counter(y))","c0c1504d":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score\nmodel = GaussianNB()\nmodel.fit(X, y);\nX = data_log.drop('y', axis=1).copy()\ny = data_log['y'].copy()\n\nX, y = ros.fit_resample(X, y)\nX=pd.DataFrame(X)\nX.columns=['totChol', 'sysBP', 'BMI', 'heartRate', 'glucose', 'male', 'age',\n       'currentSmoker', 'BPMeds', 'prevalentStroke', 'prevalentHyp',\n       'diabetes', 'education_1', 'education_2', 'education_3', 'education_4',\n       'cigsPerDay']\nX[['totChol', 'sysBP', 'BMI', 'heartRate', 'glucose', 'male', 'age',\n       'currentSmoker', 'BPMeds', 'prevalentStroke', 'prevalentHyp',\n       'diabetes', 'education_1', 'education_2', 'education_3', 'education_4',\n       'cigsPerDay']]=X[['totChol', 'sysBP', 'BMI', 'heartRate', 'glucose', 'male', 'age',\n       'currentSmoker', 'BPMeds', 'prevalentStroke', 'prevalentHyp',\n       'diabetes', 'education_1', 'education_2', 'education_3', 'education_4',\n       'cigsPerDay']].astype('category')\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42,stratify=y)\n#param_grid_nb = {\n#    'var_smoothing': np.logspace(0,-9, num=100)\n#}\n#grid_search= GridSearchCV(GaussianNB(), param_grid_nb,cv=7)\n#grid_search.fit(X_train,y_train)\n#grid_search.best_params_\nmodelnb=GaussianNB(var_smoothing=0.0005336699231206307)\nmodelnb.fit(X_train,y_train)\ny2_modelnb = modelnb.predict(X_test)\naccuracy_score(y_test, y2_modelnb)","16bc317c":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\ncf=confusion_matrix(y_test, y2_modelnb)\nprint(classification_report(y_test, y2_modelnb))\n\ngroup_names = [\"True Negative\",\"False Positive\",\"False Negative\",\"True Positive\"]\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                cf.flatten()]\ngroup_percentages = [\"{0:.2%}\".format(value) for value in\n                     cf.flatten()\/np.sum(cf)]\nlabels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n          zip(group_names,group_counts,group_percentages)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(cf, annot=labels, fmt=\"\", cmap=palette)","251a890e":"perf_nb=pd.DataFrame({'Train_Score':modelnb.score(X_train,y_train),\"Test_Score\":modelnb.score(X_test,y_test),\"Precision_Score\":precision_score(y_test,y2_modelnb),\"Recall_Score\":recall_score(y_test,y2_modelnb),\"F1_Score\":f1_score(y_test,y2_modelnb)},index=[\"Naives Bayes\"])","8c33669a":"from sklearn.neighbors import KNeighborsClassifier\nX = data_log.drop('y', axis=1).copy()\ny = data_log['y'].copy()\n\nX, y = ros.fit_resample(X, y)\nX=pd.DataFrame(X)\nX.columns=['totChol', 'sysBP', 'BMI', 'heartRate', 'glucose', 'male', 'age',\n       'currentSmoker', 'BPMeds', 'prevalentStroke', 'prevalentHyp',\n       'diabetes', 'education_1', 'education_2', 'education_3', 'education_4',\n       'cigsPerDay']\nX[['totChol', 'sysBP', 'BMI', 'heartRate', 'glucose', 'male', 'age',\n       'currentSmoker', 'BPMeds', 'prevalentStroke', 'prevalentHyp',\n       'diabetes', 'education_1', 'education_2', 'education_3', 'education_4',\n       'cigsPerDay']]=X[['totChol', 'sysBP', 'BMI', 'heartRate', 'glucose', 'male', 'age',\n       'currentSmoker', 'BPMeds', 'prevalentStroke', 'prevalentHyp',\n       'diabetes', 'education_1', 'education_2', 'education_3', 'education_4',\n       'cigsPerDay']].astype('category')\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42,stratify=y)\n#from sklearn.model_selection import GridSearchCV\n\n#gridSearchParameters = {'n_neighbors' : [i for i in range(3,10,2)],\n#                        'weights' : ['uniform', 'distance'],\n#                        'metric' : ['euclidean','manhattan','minkowski','hamming']\n#                        }\n\n#grid = GridSearchCV(KNeighborsClassifier(), gridSearchParameters, cv=7)\n#grid.fit(X_train,y_train)\n#grid.best_params_\n\nmodelknn=KNeighborsClassifier(metric= 'hamming', n_neighbors= 3, weights= 'distance')\nmodelknn.fit(X_train,y_train)\ny2_modelknn = modelknn.predict(X_test)\naccuracy_score(y_test, y2_modelknn)","a6852a3e":"cf=confusion_matrix(y_test, y2_modelknn)\nprint(classification_report(y_test, y2_modelknn))\ngroup_names = [\"True Negative\",\"False Positive\",\"False Negative\",\"True Positive\"]\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                cf.flatten()]\ngroup_percentages = [\"{0:.2%}\".format(value) for value in\n                     cf.flatten()\/np.sum(cf)]\nlabels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n          zip(group_names,group_counts,group_percentages)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(cf, annot=labels, fmt=\"\", cmap=palette)\nperf_knn=pd.DataFrame({'Train_Score':modelknn.score(X_train,y_train),\"Test_Score\":modelknn.score(X_test,y_test),\"Precision_Score\":precision_score(y_test,y2_modelknn),\"Recall_Score\":recall_score(y_test,y2_modelknn),\"F1_Score\":f1_score(y_test,y2_modelknn)},index=[\"KNN\"])","01caf6e6":"data_log['y'].value_counts()","b8e02a6a":"count_no_risk = len(data_log[data_log['y']==0])\ncount_risk = len(data_log[data_log['y']==1])\npct_of_no_risk = count_no_risk\/(count_no_risk+count_risk)\nprint(\"percentage of no risk\", pct_of_no_risk*100)\npct_of_risk = count_risk\/(count_no_risk+count_risk)\nprint(\"percentage of risk\", pct_of_risk*100)","0f210d0d":"data_log\ndata_final=data_log.copy()\ndata_final.columns.values\nX = data_final.loc[:, data_final.columns != 'y']\ny = data_final.loc[:, data_final.columns == 'y']","b05b6b46":"#OVERSAMPLING FOR IMBALANCED DATA\nfrom collections import Counter\nfrom imblearn.over_sampling import RandomOverSampler \n\nros = RandomOverSampler(sampling_strategy=1, random_state=42)\nX, y = ros.fit_resample(X, y)\n\nprint('Resampled dataset shape %s' % Counter(y))","06ff0592":"X=pd.DataFrame(X,columns=['totChol', 'sysBP', 'BMI', 'heartRate', 'glucose', 'male', 'age',\n       'currentSmoker', 'BPMeds', 'prevalentStroke', 'prevalentHyp',\n       'diabetes', 'education_1', 'education_2', 'education_3', 'education_4',\n       'cigsPerDay'])\nX[['totChol', 'sysBP', 'BMI', 'heartRate', 'glucose', 'male', 'age',\n       'currentSmoker', 'BPMeds', 'prevalentStroke', 'prevalentHyp',\n       'diabetes', 'education_1', 'education_2', 'education_3', 'education_4',\n       'cigsPerDay']]=X[['totChol', 'sysBP', 'BMI', 'heartRate', 'glucose', 'male', 'age',\n       'currentSmoker', 'BPMeds', 'prevalentStroke', 'prevalentHyp',\n       'diabetes', 'education_1', 'education_2', 'education_3', 'education_4',\n       'cigsPerDay']].astype('category')\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42,stratify=y)\npd.DataFrame(y).value_counts()","f3dee0c2":"X_for_logistic = data_final.loc[:, data_final.columns != 'y']\ny_for_logistic = data_final.loc[:, data_final.columns == 'y']\n\nX_for_logistic, y_for_logistic = ros.fit_resample(X_for_logistic, y_for_logistic)\nX_for_logistic=pd.DataFrame(X_for_logistic)\nX_for_logistic.columns=['totChol', 'sysBP', 'BMI', 'heartRate', 'glucose', 'male', 'age',\n       'currentSmoker', 'BPMeds', 'prevalentStroke', 'prevalentHyp',\n       'diabetes', 'education_1', 'education_2', 'education_3', 'education_4',\n       'cigsPerDay']\nX_for_logistic[['totChol', 'sysBP', 'BMI', 'heartRate', 'glucose', 'male', 'age',\n       'currentSmoker', 'BPMeds', 'prevalentStroke', 'prevalentHyp',\n       'diabetes', 'education_1', 'education_2', 'education_3', 'education_4',\n       'cigsPerDay']]=X_for_logistic[['totChol', 'sysBP', 'BMI', 'heartRate', 'glucose', 'male', 'age',\n       'currentSmoker', 'BPMeds', 'prevalentStroke', 'prevalentHyp',\n       'diabetes', 'education_1', 'education_2', 'education_3', 'education_4',\n       'cigsPerDay']].astype('category')\nX_train_lg, X_test_lg, y_train_lg, y_test_lg = train_test_split(X_for_logistic, y_for_logistic, test_size=0.25, random_state=42,stratify=y_for_logistic)","5f7f8785":"columns = X_train.columns\nos_data_X = pd.DataFrame(X_train,columns=columns )\nos_data_y= pd.DataFrame(y_train)\nos_data_y.columns=['y']\nos_data_y.value_counts()","225ae268":"print(\"length of oversampled data is \",len(os_data_X))\nprint(\"Number of no subscription in oversampled data\",len(os_data_y[os_data_y['y']==0]))\nprint(\"Number of subscription\",len(os_data_y[os_data_y['y']==1]))\nprint(\"Proportion of no subscription data in oversampled data is \",len(os_data_y[os_data_y['y']==0])\/len(os_data_X))\nprint(\"Proportion of subscription data in oversampled data is \",len(os_data_y[os_data_y['y']==1])\/len(os_data_X))","e3d1bfb5":"#from sklearn.model_selection import GridSearchCV\n#grid= dict(solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n#                      C= [0.001,0.01,0.1,1,10,100,1000],\n#                      penalty= ['none', 'l1', 'l2', 'elasticnet'])# l1 lasso l2 ridge\n#logreg=LogisticRegression()\n#logreg_cv=GridSearchCV(logreg,grid,cv=10)\n#logreg_cv.fit(X_train_lg,y_train_lg)\n#print(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)\n#print(\"accuracy :\",logreg_cv.best_score_)\n\n#By the GridSearchCV method, the best hyperparameters were found and they were used in the logistic model.\ndata_final_vars=data_final.columns.values.tolist()\ny=['y']\nX=[i for i in data_final_vars if i not in y]\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression(C= 0.1, penalty= 'l1', solver= 'saga')\nrfe = RFE(logreg, 20)\nrfe = rfe.fit(os_data_X, os_data_y.values.ravel())\nprint(rfe.support_)\nprint(rfe.ranking_)","f838f2d8":"X=os_data_X\ny=os_data_y['y']\nimport statsmodels.api as sm\nlogit_model=sm.Logit(np.asarray(y),X.astype(float))\nresult=logit_model.fit()\nprint(result.summary2())","0e59ca4f":"#Since there are variables that have p-values greater than 0.05, there should be an elimination among independent variables.\nX=os_data_X.drop(columns=['BPMeds','diabetes','sysBP','totChol','currentSmoker','prevalentStroke','heartRate','glucose'],axis=1).copy()\ny=os_data_y['y']\n\nlogit_model=sm.Logit(np.asarray(y),X.astype(float))\nresult=logit_model.fit()\nprint(result.summary2())","da1de7c4":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\n\nX_train, X_test, y_train, y_test = train_test_split(X_for_logistic, y_for_logistic, test_size=0.25, random_state=42,stratify=y_for_logistic)\nlogreg = LogisticRegression(C= 0.1, penalty= 'l1', solver= 'saga')\nlogreg.fit(X_train, y_train)\ny_pred = logreg.predict(X_test)\nfrom sklearn.metrics import confusion_matrix\ncf = confusion_matrix(y_test, y_pred)\nprint(cf)","d8fb9f76":"from sklearn.metrics import classification_report\nl_cr=classification_report(y_test, y_pred,output_dict=True)\nprint(classification_report(y_test, y_pred))","330e79d2":"perf_lr=pd.DataFrame({'Train_Score':logreg.score(X_train,y_train),\"Test_Score\":logreg.score(X_test,y_test),\"Precision_Score\":precision_score(y_test,y_pred),\"Recall_Score\":recall_score(y_test,y_pred),\"F1_Score\":f1_score(y_test,y_pred)},index=[\"Logistic Regression\"])","e59d5022":"# Load libraries\nimport pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\nfrom sklearn.model_selection import train_test_split # Import train_test_split function\nfrom sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\nX = data_log.drop(columns='y') # Features\ny = data_log['y'] # Target variable\n\nX, y = ros.fit_resample(X, y)\nX=pd.DataFrame(X)\nX.columns=['totChol', 'sysBP', 'BMI', 'heartRate', 'glucose', 'male', 'age',\n       'currentSmoker', 'BPMeds', 'prevalentStroke', 'prevalentHyp',\n       'diabetes', 'education_1', 'education_2', 'education_3', 'education_4',\n       'cigsPerDay']\nX[['totChol', 'sysBP', 'BMI', 'heartRate', 'glucose', 'male', 'age',\n       'currentSmoker', 'BPMeds', 'prevalentStroke', 'prevalentHyp',\n       'diabetes', 'education_1', 'education_2', 'education_3', 'education_4',\n       'cigsPerDay']]=X[['totChol', 'sysBP', 'BMI', 'heartRate', 'glucose', 'male', 'age',\n       'currentSmoker', 'BPMeds', 'prevalentStroke', 'prevalentHyp',\n       'diabetes', 'education_1', 'education_2', 'education_3', 'education_4',\n       'cigsPerDay']].astype('category')\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42,stratify=y)","26bca6ad":"#param_dict={\"criterion\" : ['gini', 'entropy'], \"max_depth\":range(1,10),\"min_samples_split\":range(1,10),\"min_samples_leaf\":range(1,5)   }\n#clf_GS = GridSearchCV( DecisionTreeClassifier(),param_grid= param_dict,cv=10,verbose=1,n_jobs=-1)\n#clf_GS.fit(X_train, y_train)\n#clf_GS.best_params_\n#clf_GS.best_estimator_\n\n# Create Decision Tree classifer object\nclf = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n                       max_depth=9, max_features=None, max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=3,\n                       min_weight_fraction_leaf=0.0, presort='deprecated',\n                       random_state=None, splitter='best')\n\n# Train Decision Tree Classifer\nclf = clf.fit(X_train,y_train)\n\n#Predict the response for test dataset\ny_pred = clf.predict(X_test)\n\n# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n\ndt_cr=classification_report(y_test, y_pred,output_dict=True)","0f8b7e81":"perf_dt=pd.DataFrame({'Train_Score':clf.score(X_train,y_train),\"Test_Score\":clf.score(X_test,y_test),\"Precision_Score\":precision_score(y_test,y_pred),\"Recall_Score\":recall_score(y_test,y_pred),\"F1_Score\":f1_score(y_test,y_pred)},index=[\"Decision Tree\"])\ncf=confusion_matrix(y_test, y_pred)\ngroup_names = [\"True Negative\",\"False Positive\",\"False Negative\",\"True Positive\"]\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                cf.flatten()]\ngroup_percentages = [\"{0:.2%}\".format(value) for value in\n                     cf.flatten()\/np.sum(cf)]\nlabels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n          zip(group_names,group_counts,group_percentages)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(cf, annot=labels, fmt=\"\", cmap=palette)\nprint(classification_report(y_test, y_pred))","d39b833f":"X = data_log.drop('y', axis=1)\ny = data_log['y'].copy()\n\nX, y = ros.fit_resample(X, y)\nX=pd.DataFrame(X)\nX.columns=['totChol', 'sysBP', 'BMI', 'heartRate', 'glucose', 'male', 'age',\n       'currentSmoker', 'BPMeds', 'prevalentStroke', 'prevalentHyp',\n       'diabetes', 'education_1', 'education_2', 'education_3', 'education_4',\n       'cigsPerDay']\nX[['totChol', 'sysBP', 'BMI', 'heartRate', 'glucose', 'male', 'age',\n       'currentSmoker', 'BPMeds', 'prevalentStroke', 'prevalentHyp',\n       'diabetes', 'education_1', 'education_2', 'education_3', 'education_4',\n       'cigsPerDay']]=X[['totChol', 'sysBP', 'BMI', 'heartRate', 'glucose', 'male', 'age',\n       'currentSmoker', 'BPMeds', 'prevalentStroke', 'prevalentHyp',\n       'diabetes', 'education_1', 'education_2', 'education_3', 'education_4',\n       'cigsPerDay']].astype('category')\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42,stratify=y)","e088b462":"#from sklearn.model_selection import RandomizedSearchCV\n\n#number of trees in random forest\n#n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n\n#number of features at every split\n#max_features = ['auto', 'sqrt']\n\n#max depth\n#max_depth = [int(x) for x in np.linspace(100, 500, num = 11)] max_depth.append(None)\n\n#create random grid\n#random_grid = { 'n_estimators': n_estimators, 'max_features': max_features, 'max_depth': max_depth }\n\n#Random search of parameters\n#rfc_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n\n#Fit the model\n#rfc_random.fit(X_train, y_train)\n\n#print results\n#print(rfc_random.best_params_)","4de5666a":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nrfc = RandomForestClassifier(n_estimators= 200, max_features= 'sqrt', max_depth= None)\nrfc.fit(X_train,y_train)\nrfc_predict = rfc.predict(X_test)\nrfc_cv_score = cross_val_score(rfc, X, y, cv=10, scoring='roc_auc')\nprint(\"=== Confusion Matrix ===\")\nprint(confusion_matrix(y_test, rfc_predict))\nprint('\\n')\nprint(\"=== Classification Report ===\")\nprint(classification_report(y_test, rfc_predict))\nprint('\\n')\nprint(\"=== All AUC Scores ===\")\nprint(rfc_cv_score)\nprint('\\n')\nprint(\"=== Mean AUC Score ===\")\nprint(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())","8b3406cf":"sorted_idx = rfc.feature_importances_.argsort()\nplt.barh(data_log.columns[sorted_idx], rfc.feature_importances_[sorted_idx])\nplt.xlabel(\"Random Forest Feature Importance\")","a2d0705f":"cf=confusion_matrix(y_test, rfc_predict)\ngroup_names = [\"True Negative\",\"False Positive\",\"False Negative\",\"True Positive\"]\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                cf.flatten()]\ngroup_percentages = [\"{0:.2%}\".format(value) for value in\n                     cf.flatten()\/np.sum(cf)]\nlabels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n          zip(group_names,group_counts,group_percentages)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(cf, annot=labels, fmt=\"\", cmap=palette)\nperf_rf=pd.DataFrame({'Train_Score':rfc.score(X_train,y_train),\"Test_Score\":rfc.score(X_test,y_test),\"Precision_Score\":precision_score(y_test,rfc_predict),\"Recall_Score\":recall_score(y_test,rfc_predict),\"F1_Score\":f1_score(y_test,rfc_predict)},index=[\"Random Forest\"])","b53622e4":"X = data_log.drop('y', axis=1).copy()\ny = data_log['y'].copy()\n\nX, y = ros.fit_resample(X, y)\nX=pd.DataFrame(X)\nX.columns=['totChol', 'sysBP', 'BMI', 'heartRate', 'glucose', 'male', 'age',\n       'currentSmoker', 'BPMeds', 'prevalentStroke', 'prevalentHyp',\n       'diabetes', 'education_1', 'education_2', 'education_3', 'education_4',\n       'cigsPerDay']\nX[['totChol', 'sysBP', 'BMI', 'heartRate', 'glucose', 'male', 'age',\n       'currentSmoker', 'BPMeds', 'prevalentStroke', 'prevalentHyp',\n       'diabetes', 'education_1', 'education_2', 'education_3', 'education_4',\n       'cigsPerDay']]=X[['totChol', 'sysBP', 'BMI', 'heartRate', 'glucose', 'male', 'age',\n       'currentSmoker', 'BPMeds', 'prevalentStroke', 'prevalentHyp',\n       'diabetes', 'education_1', 'education_2', 'education_3', 'education_4',\n       'cigsPerDay']].astype('category')\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42,stratify=y)\nfrom sklearn.svm import SVC\n# defining parameter range\n#param_grid = {'C': [0.1, 1, 10, 100, 1000], \n#              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n#              'kernel': ['rbf']} \n  \n#grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n  \n# fitting the model for grid search\n#grid.fit(X_train, y_train)\n\nfrom sklearn.svm import SVC\nsvclassifier = SVC(kernel='rbf',C=100,gamma=1)\nsvclassifier.fit(X_train, y_train)","608410b6":"y_pred = svclassifier.predict(X_test)\nfrom sklearn.metrics import classification_report, confusion_matrix\ncf=confusion_matrix(y_test, y_pred)\nprint(classification_report(y_test, y_pred))\nperf_svm=pd.DataFrame({'Train_Score':svclassifier.score(X_train,y_train),\"Test_Score\":svclassifier.score(X_test,y_test),\"Precision_Score\":precision_score(y_test,y_pred),\"Recall_Score\":recall_score(y_test,y_pred),\"F1_Score\":f1_score(y_test,y_pred)},index=[\"SVM\"])\ngroup_names = [\"True Negative\",\"False Positive\",\"False Negative\",\"True Positive\"]\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                cf.flatten()]\ngroup_percentages = [\"{0:.2%}\".format(value) for value in\n                     cf.flatten()\/np.sum(cf)]\nlabels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n          zip(group_names,group_counts,group_percentages)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(cf, annot=labels, fmt=\"\", cmap=palette)","bd602c6a":"A=pd.concat([perf_nb,perf_lr,perf_dt,perf_rf,perf_knn,perf_svm])\nA","52619271":"Since the p-value of the Kruskal Wallis H Test is smaller than 0.05, the null hypothesis can be rejected. This means the median heart rate differ by the number of cigarettes smoked in a day.","83ad84d7":"The table of 10-year risk of coronary heart disease and gender shows the number of people in each group. By that, we can conclude that men in the data who have a 10-year risk of coronary heart disease are greater than women while for the other group that has no risk it is the opposite.","4779a938":"The above box plots show the distributions in each variable by the 10-year risk of coronary heart disease.\n\n**Glucose-10 Year Risk of Coronary Heart Disease:** The distributions for both the risk group and the group of people who don't have the risk are almost the same except the third quartile which is greater and the maximum value which is slightly greater for the risk group. Both groups have so many outliers.\n\n**Total Cholesterol-10 Year Risk of Coronary Heart Disease:** The distributions for both the risk group and the group of people who don't have the risk are almost the same. Both groups have so many outliers.\n\n**Heart Rate-10 Year Risk of Coronary Heart Disease:** The distributions for both the risk group and the group of people who don't have the risk are almost the same except for the third quartile, minimum and maximum values which are slightly greater for the risk group. Both groups have so many outliers especially the group of people who don't have the risk.\n\n**Systolic Blood Pressure-10 Year Risk of Coronary Heart Disease:** In the group that doesn't have a 10-year risk of coronary heart disease, the median is about 130 while in the other group that has a 10-year risk of coronary heart disease it is almost 150. The minimum systolic blood pressure value for both two groups are the same while the maximum value is much higher in the risk group. Also, the first and third quartiles are so much higher in the risk group.\n\n**Diastolic Blood Pressure-10 Year Risk of Coronary Heart Disease:** Like systolic blood pressure, diastolic blood pressure's median, max, first quartile, and third quartile values are higher for the risk group.","f2969284":"By the above histogram, it can be seen that glucose is not normal. So the assumption of ANOVA, normality was not provided. Because of this, ANOVA can not be performed. Instead of ANOVA, Non-parametric Kruskal was used to see the differences between median glucose in each age group.","39ad5770":"**LOGISTIC REGRESSION**","5aea2af2":"Therefore, H0 was rejected, that is, the 10-year risk of coronary heart disease and prevalent hypertension have a significant relation.","7debcd71":"The most important 5 features are respectively age, body mass index, total cholesterol, systolic blood pressure, and glucose.","d44cba76":"The above graph shows the proportion of people in the status smokers and non-smokers while the colors show the gender in each group. In this data, almost 60 percent of people who are smokers are female while more than 60 percent of people who are not smokers are male.","e61724bf":"It is known that the heart rate is not normal. So the assumption of ANOVA, normality was not provided. Because of this, ANOVA can not be performed. Instead of ANOVA, Non-parametric Kruskal was used to see the differences between median heart rates in each age group.","dd64aa2c":"In the above graph, white lines represent missing values and their location. As can be seen above, the variable with the most missing values is glucose while 9 other variables don't have any such as gender, age, smoking status. In this project, missing values will be imputed by the appropriate method.","07e98ac9":"In order to see the multicollinearity between variables, their VIF values were checked. They should be less than 5 or 10. In this analysis, the threshold of VIF values was decided as 10. Since VIF values are much higher in the above table, scaling or another method has to be applied.","4983959f":"Therefore, H0 was rejected, that is, the 10-year risk of coronary heart disease and education have a significant relation.","e6f8f96e":"**EDA-RESEARCH QUESTIONS**","11597e51":"All numeric variables are higher in the group who have a 10-year risk of coronary heart disease.","e04e1240":"The body mass index box plot shows the distributions for the 10-year risk of coronary heart disease by age group.\n\nIn the age group 30-39; There is not much difference in the median but for the risk group, it is slightly higher. Minimum, maximum values, and the first quartile are lower in the risk group but the third quartile is higher.\n\nIn the age group 40-49; The distribution for the risk group is almost the same as the group of people who don't have the risk.\n\nIn the age group 50-59; The distribution for the risk group is almost the same as the group of people who don't have the risk but the first and third quartile is slightly higher in the risk group.\n\nIn the age group 60-69; There is not much difference in the median and minimum value. Maximum values and the first quartile are lower in the risk group but the third quartile is higher.","77e54fbf":"**DECISION TREE**","f45c64cd":"Therefore, H0 was rejected, that is, the 10-year risk of coronary heart disease and gender have a significant relation.","5c539fdc":"Therefore, H0 was rejected, that is, the 10-year risk of coronary heart disease and diabetes have a significant relation.","bb7883c8":"Most of the people who don't have a 10-year risk of coronary heart disease are female while the ones who have the risk are generally male.","2a2dafac":"Median of systolic blood pressure, interquartile ranges, minimum and maximum values are getting higher until the group 70-79 except for the 50-59's min value. The distributions of all groups look symmetric.","cae6fa58":"*1) How does the 10-year risk of coronary heart disease change by other variables in the data?*","7d02a933":"Since the p-value of the Kruskal Wallis H Test is greater than 0.05, the null hypothesis cannot be rejected. This means heart rates don't change by age groups.","f1eb4f4a":"The above plot shows the frequencies of smoking status in each education level. The highest percentage of smokers are in the education level 2 while the second one is in the level 4 and the least one is in the level 3.","76c89298":"The proportion of the 10-year risk of coronary heart disease by education graph shows the percentages of 10-year risk of coronary heart disease in each education group. There is no huge difference between those percentages but the greatest risk is in education group 1 while the lowest is in group 2.","346493b0":"The medians of heart rate are almost the same for all age groups except 70-79. In each group, the distribution looks symmetric. The range for the group 70-79 is the smallest but since there are only 2 people in that group, it doesn't mean anything concrete.","3afb25cc":"There is a strong correlation between systolic and diastolic blood pressures. But all other variables have weak correlations between each other.","169fee67":"Therefore, H0 was rejected, that is, the 10-year risk of coronary heart disease and prevalent stroke have a significant relation.","29fdf30e":"Almost all desciptives are equal for each group.","9c4fdc27":"Since the p-value of the Kruskal Wallis H Test is smaller than 0.05, the null hypothesis can be rejected. This means systolic blood pressure differ by age groups.","ed18d8d0":"**SUPPORT VECTOR MACHINE**","b9fd8b89":"The table above shows the frequencies of people who have diabetes or not by the 10-year risk of coronary heart disease. And by that, it can be concluded that there is a huge difference in percentages for people who have diabetes. For people who don't have diabetes, the risk is 14.6 percent while for the other group the risk is 63.3 percent.","120ccdcf":"The above box plot shows the distribution of heart rate and the range of cigarettes smoked in a day. Except for the 31-39 and 50+ groups, every group has almost the same median heart rate. The comments for each group were written as a comparison with the previous one.\n\n* For the group who are non-smokers, the box plot shows a symmetric distribution. Also, this group has many outliers and this can be because of other variables such as age. Without outliers, the minimum value for this group is almost 45 which is very low even in resting. The maximum value is near 105 and the median is near 75.\n* For the group 1-3, while the minimum heart rate increased, the maximum heart rate decreased. There is a left-skewed distribution in this group and this means that there is an agglomeration in between the median and the third quartile. So, we can say that in this group there are more people who have heartrate above the median than who have heartrate below the median.\n* For the group 4-7, minimum and maximum values for heart rate are almost the same as the 1-3 group but the first and third quartiles are higher. This group also has an almost symmetric distribution.\n* For the group 8-11, while the minimum value is lower the maximum value is higher than the previous group. The first and third quartiles are almost the same except the third quartile is a little lower in the 8-11. This group also looks symmetric.\n* For the group 12-15 there is an increase in the minimum value but the maximum value remains the same as the previous group. The first and third quartiles are higher and there is a right-skewed distribution in this group. This means there is an agglomeration between the first quartile and the median.\n* For the groups 16-19 the range of the minimum and maximum is getting the smallest. Also, the interquartile range is the smallest too. The distribution looks symmetric and there are only 2 outliers that are lower than the minimum value and very higher than the maximum. This can be a cause of other factors such as age.\n* For the group 20-23 the distribution and descriptive statistics are almost equal to the group 12-15. But there are so many outliers in this case that are higher than the maximum value.\n* For the group 24-27 the minimum value is much higher while the maximum is much lower than the previous one. The first quartile is almost the same but the third quartile is a little higher. There is a right-skewed distribution in this group which means there is an agglomeration in between the first quartile and the median.\n* For the group 27-30 the minimum value is much lower while the maximum is much higher than the previous one. While the third quartile is almost the same, the first quartile is a little lower. There is also right-skewed distribution but not so obvious like the previous group.\n* For the group 31-39 the median is lower than previous ones and there is a really obvious decrease in the maximum value which is confusing because it is expected that the number of cigarettes smoked and the heart rate are directly proportional. It can be because of other variables. The minimum value remains the same. There is a right-skewed distribution as well.\n* For the group 40-49 there is almost the same distribution as the 27-30 except the first quartile and the minimum value which are a little higher.\n* For the 50+ group the median and ranges between maximum and minimum values getting smaller. There is an obvious right-skewed distribution which means there is an agglomeration in between the first quartile and the median.","0311557d":"The above box plot shows the distribution of systolic blood pressure and the range of cigarettes smoked in a day. The comments for each group were written as a comparison with the previous one.\n\n* For the group who are non-smokers, the box plot shows a symmetric distribution. This group has many outliers and this can be because of other variables such as age. Without outliers, the minimum value for this group is almost 75. The maximum value is near 185 and the median is near 130.\n* For the group 1-3, while the minimum systolic blood pressure(near 100) increased, the maximum systolic blood pressure(near 180) and the median(near 130) decreased. The distribution looks symmetric.\n* For the group 4-7, minimum, maximum, first quartile, and third quartile are all lower than the previous group. This group also has an almost symmetric distribution.\n* For the group 8-11, the minimum value and the maximum values are lower than the previous group. The first and third quartiles are almost the same. There is a right-skewed distribution which means there is an agglomeration between the first quartile and the median.\n* For the group 12-15 there is a decrease in the minimum and the maximum values. The first and third quartiles are almost the same and there is an almost symmetric distribution in this group.\n* For the groups 16-19 the minimum, maximum, first, and third quartiles and also median are higher. There is a right-skewed distribution.\n* For the group 20-23 all descriptive statistics are lower than the previous group.\n* For the group 24-27 the minimum value is much higher while the maximum is much lower than the previous one. The first quartile is almost the same but the third quartile is a little lower. There is a right-skewed distribution in this group which means there is an agglomeration in between the first quartile and the median.\n* For the group 27-30 the minimum value is much lower while the maximum is much higher than the previous one. While the first quartile is almost the same, the first quartile is a little higher. There is an almost symmetric distribution.\n* For the group 31-39 all descriptive statistics are higher except the first quartile and the distribution looks symmetric.\n* For the group 40-49 all descriptive statistics are lower except the first quartile and the distribution looks symmetric.\n* For the 50+ group the median and ranges between maximum and minimum values getting smaller. There is an obvious right-skewed distribution which means there is an agglomeration in between the first quartile and the median.","a0a3c843":"Actually, it is expected that while education levels go higher the number of cigarettes smoked per day will decrease. But above bar plot shows that there is not a relationship like that in this data. The education level that has the most cigarettes in a day is level 2 while the second one is level 4 and the least is level 3.","b742cb14":"Therefore, H0 was accepted, that is, the 10-year risk of coronary heart disease and smoking status does not have a significant relation.","65c85263":"In the above bar plots, the first one represents the frequency of 10-year risk of CHD in each age group while the second one shows the proportions.\n\nBy age frequency table and the first graph, it can be said that 40-49 age group is the most crowded one while age group 70-79 have only 2 people.\nThe age group and CHD table and the second graph show that age and the 10-year risk of coronary heart disease are directly proportional. In the age group 70-79, the risk increases to 50 percent while in the age group 30-39 it is less than 5 percent.","816168b4":"**KNN**","fb029a55":"The above table shows the change in 10-year risk of coronary heart disease by smoking status. It can be said that smoking status has an inconsiderable effect on the risk in the data.","52332842":"**RANDOM FOREST**","41006067":"Similar to the previous graph, the above graph shows the proportion for smoking status. But in this case, it shows the proportion of age groups instead of gender. In the x axis, 0 represents non-smokers while 1 represents smokers.\n\nAll people in the age group 70-79 are smokers by this graph. But it is not correct to conclude with this result since there are only 2 people in that group in the data.\n\nIn the age groups 60-69 and 50-59, the majority of people are smokers while for the age groups 40-49 and 30-39 it is the opposite. But generally, the highest percentage of people who are smokers are in the 60-69 age group if 70-79 will not be included.","447569c9":"As can be seen in the above table the most accurate algorithm used is Random Forest while the most inaccurate one is Na\u00efve Bayes.\n\nAt first, Random Forest can give an idea of overfitting in classification report and confusion matrix but by looking at the train and test score in the above table it can be seen that there is not an overfitting problem.\n","f3895374":"**NAIVE BAYES**","e8abd74a":"3) Does smoking status and the number of cigarettes smoked change by gender, age and education?","cac8ac29":"4) Does age affect other variables?","962038db":"The range of cigarettes smoked in a day and gender graph shows the following conclusions;\n\n* Women in the data who don't smoke are more than 2 times of men who are non-smokers. Also, it can be said that the people who don't smoke are the majority.\n* In the range of 1-15 cigarettes smoked in a day, the majority are women.\n* In the range of 16-19 and 31-39 cigarettes smoked in a day, there is not any female.\n* In the range of 20-40+ cigarettes smoked in a day, the majority are men.\nA simple conclusion can be made by looking at these results. And this is that men tend to smoke more cigarettes than women in this data.","1b337769":"Since the p-value of the Kruskal Wallis H Test is smaller than 0.05, the null hypothesis can be rejected. This means the median systolic blood pressure differs by the number of cigarettes smoked in a day.","ebd5cc46":"### ","6ec67929":"2) Does smoking status and the number of cigarettes smoked in a day affect heart rate and systolic blood pressure?","3151bb69":"Since the p-value of the Kruskal Wallis H Test is smaller than 0.05, the null hypothesis can be rejected. This means glucose differ by age groups.","c9501683":"**PRE-PROCESSING**","9364c936":"By the above histogram, it can be seen that systolic blood pressure is not normal. So the assumption of ANOVA, normality was not provided. Because of this, ANOVA can not be performed. Instead of ANOVA, Non-parametric Kruskal was used to see the differences between median systolic blood pressure in each age group.","6c43eb30":"By the above histogram, it can be seen that heart rate is not normal. So the assumption of ANOVA, normality was not provided. Because of this, ANOVA can not be performed. Instead of ANOVA, Non-parametric Kruskal was used to see the differences between median systolic blood pressure in each age group.","4dae7072":"The data consist of only 25 people who had a stroke before and 44 percent of them have a 10-year risk of coronary heart disease. This seems like a big percentage but since the sample is very small, it did not give a considerable meaning apart from this data.","6136af60":"As it can be seen in the above graph and the frequency table, data consist of 3594 people who don't have a 10-year risk of coronary heart disease and 644 people who have the risk."}}