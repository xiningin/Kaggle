{"cell_type":{"e7fa0f68":"code","fac3ed4e":"code","54849acf":"code","40c7a1a1":"code","0e581b96":"code","abc41e41":"code","e9218c83":"code","8e318f42":"code","f4e3b31b":"code","810f9566":"code","62b78f2a":"code","c2ae51ae":"code","0939718f":"code","96a5f5c5":"code","d537ef4a":"code","cbfbc261":"code","64b518e8":"code","6b2e93e7":"code","11f351e5":"markdown","5d3aa527":"markdown","5c66adbb":"markdown","05d9322e":"markdown","c51f53e6":"markdown"},"source":{"e7fa0f68":"# linear algebra\nimport numpy as np \n\n# data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pandas as pd \n\n#For Data Visualization \nimport matplotlib.pyplot as plt \nimport seaborn as sns \n\n#For Warnings \nimport warnings \nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","fac3ed4e":"df_2015 = pd.read_csv('\/kaggle\/input\/world-happiness\/2015.csv')\ndf_2016 = pd.read_csv('\/kaggle\/input\/world-happiness\/2016.csv')\ndf_2017 = pd.read_csv('\/kaggle\/input\/world-happiness\/2017.csv')\ndf_2018 = pd.read_csv('\/kaggle\/input\/world-happiness\/2018.csv')\ndf_2019 = pd.read_csv('\/kaggle\/input\/world-happiness\/2019.csv')","54849acf":"df_2015.head()","40c7a1a1":"# Accessing the information about the '2015' dataset.\n\ndf_2015.info()","0e581b96":"# Finding the missing \/ NaN values ,if any.\ndf_2015.isnull().sum()","abc41e41":"corr_matrix_2015 = df_2015.corrwith(df_2015['Happiness Score'])\n\nprint(f'Correlation Matrix with respect to \"Happiness Score\" : ')\ncorr_matrix_2015","e9218c83":"# Seperating 'Features' and 'Label'. \n\nX_2015 = df_2015.drop('Happiness Score' , axis = 1)\ny_2015 = df_2015['Happiness Score']","8e318f42":"# Splitting Train-Test Split.\n\nfrom sklearn.model_selection import train_test_split\nX_train_2015 , X_valid_2015 ,y_train_2015 , y_valid_2015 = train_test_split(X_2015,y_2015,test_size = 0.2 ,random_state = 42)\n\nprint(f'X_train_2015 shape: {X_train_2015.shape}')\nprint(f'y_valid_2015 shape : {y_train_2015.shape}')\nprint(f'X_Valid_2015 shape :{X_valid_2015.shape}')\nprint(f'y_valid_2015 shape : {y_valid_2015.shape}')","f4e3b31b":"# Selecting categorical columns with relatively low cardinality. \n\nlow_cardinality_cols = [cname for cname in X_train_2015.columns if  X_train_2015[cname].dtype == 'object']","810f9566":"# Selecting Numerical Columns.\n\nnumerical_cols_2015 = [cname for cname in X_train_2015.columns if X_train_2015[cname].dtype in ['int64','float64']]","62b78f2a":"# Selected Columns will be Converted to 'X_train' and 'X_valid'\n\ncols_2015 = low_cardinality_cols + numerical_cols_2015 \n\nX_train = X_train_2015[cols_2015].copy()\nX_valid = X_valid_2015[cols_2015].copy()","c2ae51ae":"X_train.head()","0939718f":"# Getting Categorical Variables of 'X_train'\n\no = (X_train.dtypes == 'object')\nobject_cols = o[o].index \n\n\nprint(f'Categorical Variables : {object_cols}')","96a5f5c5":"# Creating a Function for calculating Mean_Squarred_Error. \n\nfrom sklearn.linear_model import LinearRegression \nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error \n\ndef score_dataset(X_train,X_valid,y_train_2015,y_valid_2015) : \n    global y_pred_2015\n    model = LinearRegression()\n    model.fit(X_train,y_train_2015)\n    y_pred_2015 = model.predict(X_valid)\n    \n    return mean_squared_error(y_valid_2015 , y_pred_2015)","d537ef4a":"# Approach 1 (Drop Categorical Variables.)\n\ndrop_X_train = X_train.select_dtypes(exclude = ['object'])\ndrop_X_valid = X_valid.select_dtypes(exclude = ['object'])\n\nprint('MAE from Approach 1 (Drop Categorical Variables) : ')\nprint(score_dataset(drop_X_train,drop_X_valid,y_train_2015,y_valid_2015))","cbfbc261":"# Approach 2 (Ordinal Encoder)\n\nfrom sklearn.preprocessing import OrdinalEncoder\n\nlabel_X_train = X_train.copy()\nlabel_X_valid = X_valid.copy()\n\nordinal_encoder = OrdinalEncoder()\n\nlabel_X_train[object_cols] = ordinal_encoder.fit_transform(label_X_train[object_cols])\nlabel_X_valid[object_cols] = ordinal_encoder.fit_transform(label_X_valid[object_cols])\n\n\nprint('MAE from Approach 1 (Ordinal Encoding): ')\nprint(score_dataset(label_X_train,label_X_valid,y_train_2015,y_valid_2015))","64b518e8":"label_X_train1 = label_X_train.drop(['Happiness Rank','Standard Error'] , axis = 1 )\nlabel_X_valid1 = label_X_valid.drop(['Happiness Rank','Standard Error'] , axis = 1 )\n\nlabel_X_train1[object_cols] = ordinal_encoder.fit_transform(label_X_train1[object_cols])\nlabel_X_valid[object_cols] = ordinal_encoder.fit_transform(label_X_valid1[object_cols])\n\nprint(score_dataset(label_X_train1 ,label_X_valid1, y_train_2015 ,y_valid_2015))","6b2e93e7":"# Approach 3 (One Hot Encoding\n\nfrom sklearn.preprocessing import OneHotEncoder\n\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\nOH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[object_cols]))\n\nOH_cols_train.index = X_train.index\nOH_cols_valid.index = X_valid.index\n\nnum_X_train = X_train.drop(object_cols, axis=1)\nnum_X_valid = X_valid.drop(object_cols, axis=1)\n\nOH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\nOH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n\nprint(\"MAE from Approach 3 (One-Hot Encoding):\") \nprint(score_dataset(OH_X_train, OH_X_valid, y_train_2015, y_valid_2015))","11f351e5":"## 2015 Dataset !","5d3aa527":"## Import Required Libraries","5c66adbb":"<b style = 'font-size:20px'>Context<\/b>\n<br>\n<br>\n<i>The World Happiness Report is a landmark survey of the state of global happiness. The first report was published in 2012, the second in 2013, the third in 2015, and the fourth in the 2016 Update. The World Happiness 2017, which ranks 155 countries by their happiness levels, was released at the United Nations at an event celebrating International Day of Happiness on March 20th. The report continues to gain global recognition as governments, organizations and civil society increasingly use happiness indicators to inform their policy-making decisions. Leading experts across fields \u2013 economics, psychology, survey analysis, national statistics, health, public policy and more \u2013 describe how measurements of well-being can be used effectively to assess the progress of nations. The reports review the state of happiness in the world today and show how the new science of happiness explains personal and national variations in happiness.<\/i>\n\n\n<b style = 'font-size:20px'>Inspiration <\/b>\n<br>\n<br>\n<i>What countries or regions rank the highest in overall happiness and each of the six factors contributing to happiness? How did country ranks or scores change between the 2015 and 2016 as well as the 2016 and 2017 reports? Did any country experience a significant increase or decrease in happiness\n\nWhat is Dystopia?\n\nDystopia is an imaginary country that has the world\u2019s least-happy people. The purpose in establishing Dystopia is to have a benchmark against which all countries can be favorably compared (no country performs more poorly than Dystopia) in terms of each of the six key variables, thus allowing each sub-bar to be of positive width. The lowest scores observed for the six key variables, therefore, characterize Dystopia. Since life would be very unpleasant in a country with the world\u2019s lowest incomes, lowest life expectancy, lowest generosity, most corruption, least freedom and least social support, it is referred to as \u201cDystopia,\u201d in contrast to Utopia.\n\nWhat are the residuals?\n\nThe residuals, or unexplained components, differ for each country, reflecting the extent to which the six variables either over- or under-explain average 2014-2016 life evaluations. These residuals have an average value of approximately zero over the whole set of countries. Figure 2.2 shows the average residual for each country when the equation in Table 2.1 is applied to average 2014- 2016 data for the six variables in that country. We combine these residuals with the estimate for life evaluations in Dystopia so that the combined bar will always have positive values. As can be seen in Figure 2.2, although some life evaluation residuals are quite large, occasionally exceeding one point on the scale from 0 to 10, they are always much smaller than the calculated value in Dystopia, where the average life is rated at 1.85 on the 0 to 10 scale.\n\nWhat do the columns succeeding the Happiness Score(like Family, Generosity, etc.) describe?\n\nThe following columns: GDP per Capita, Family, Life Expectancy, Freedom, Generosity, Trust Government Corruption describe the extent to which these factors contribute in evaluating the happiness in each country.\nThe Dystopia Residual metric actually is the Dystopia Happiness Score(1.85) + the Residual value or the unexplained value for each country as stated in the previous answer.\n\nIf you add all these factors up, you get the happiness score so it might be un-reliable to model them to predict Happiness Scores.<\/i>","05d9322e":"## Reading and Understanding the datasets.","c51f53e6":"Approach 3 'ONE HOT ENCODING' performed better than other two approaches."}}