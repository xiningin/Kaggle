{"cell_type":{"b2091d92":"code","c9004215":"code","752b4034":"code","2d814742":"code","2fe62ff8":"code","175be55f":"code","9257f266":"code","252717ed":"code","224f62bf":"code","983528ad":"code","394f3519":"code","f7b73d64":"code","65794878":"code","e808cdb1":"code","24700cd1":"code","76c79a2f":"code","f84aab3c":"code","2f584350":"code","3ce15e23":"code","56264094":"code","cba3213e":"code","0638b7fd":"code","527b57ac":"code","adbc41b4":"code","06ea63c5":"code","5a2616ba":"code","c9d005ae":"code","0868fd59":"code","551a4145":"code","34776501":"code","2d98945b":"code","47a9c6bf":"code","9f746a8c":"code","70612056":"code","c2f14974":"code","08233182":"code","723b5e66":"code","8252a63e":"code","5dfa868f":"code","46f00aa0":"code","6ba8a387":"code","1dff5e10":"code","4fe7fc26":"code","e45f064a":"code","0571d2c8":"code","299fa0d6":"code","110f9b07":"code","66d36b3e":"markdown","9d75a651":"markdown","6fd52e9c":"markdown","040180e9":"markdown","12026785":"markdown","f65876b6":"markdown","bd2b06cd":"markdown","2433c1f1":"markdown","1c0fa6c7":"markdown","d5bf7772":"markdown","d1718a0c":"markdown","efd82279":"markdown","bd506116":"markdown","f2e4ccff":"markdown","262621c3":"markdown"},"source":{"b2091d92":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nfrom numpy import mean, std, absolute\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier,Ridge,Lasso,ElasticNet,LinearRegression\nfrom sklearn import linear_model\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split,cross_val_score, RepeatedKFold, GridSearchCV, TimeSeriesSplit\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import mean_squared_error\nimport math\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c9004215":"train_data = pd.read_csv('..\/input\/cap-4611-2021-fall-assignment-1\/train.csv')\ntest_data = pd.read_csv('..\/input\/cap-4611-2021-fall-assignment-1\/test.csv')\nsample_submission = pd.read_csv('..\/input\/cap-4611-2021-fall-assignment-1\/sample_submission.csv')\ndatasets = [train_data, test_data]","752b4034":"train_data.head()","2d814742":"test_data.head()","2fe62ff8":"train_data.shape","175be55f":"print(\"Check for Null values: \")\ntrain_data.isnull().sum()\ntest_data.isnull().sum()","9257f266":"test_id = test_data['id']\ntrain_data = train_data.drop(['id','Data As Of', 'End Date', 'Year', 'Month','Week-Ending Date', 'Total Deaths', 'Footnote'], axis=1)\ntest_data = test_data.drop(['id','Data As Of','End Date', 'Year', 'Month','Week-Ending Date'], axis = 1)\n# test = train_data.drop([train_data['Group'] == 'By year',],axis=0)\nprint('\\nshape after deletion for train data: ' + str(train_data.shape))\nprint('\\nshape after deletion for train data: ' + str(test_data.shape))","252717ed":"train_data = train_data.loc[(train_data['Group'] == \"By Week\") & (train_data['HHS Region'] == \"United States\")]\ntest_data = test_data.loc[(train_data['Group'] == \"By Week\") & (train_data['HHS Region'] == \"United States\")]\ntrain_data.head\ntest_data.head","224f62bf":"train_data.info()","983528ad":"train_data['MMWR Week'].describe()","394f3519":"train_data['Age Group'].describe()","f7b73d64":"ax = sns.barplot(data= train_data, y= 'COVID-19 Deaths', x='Age Group')\nplt.title('COVID Deaths & Age Group')\nplt.xticks(rotation=45)\nplt.show()","65794878":"ax = sns.lineplot(data= train_data, y= 'COVID-19 Deaths', x='Start Date')\nplt.title('COVID deaths & Start Date')\nplt.xticks(rotation=90)\nplt.show()","e808cdb1":"ax = sns.lineplot(data= train_data, y= 'COVID-19 Deaths', x='MMWR Week')\nplt.title('COVID Deaths & MMWR Week')\nplt.xticks(rotation=90)\nplt.show()","24700cd1":"# train_data[\"Start Date\"] = pd.to_datetime(train_data[\"Start Date\"])\ntrain_data[\"Start Date\"] = pd.to_datetime(train_data[\"Start Date\"])\ntest_data[\"Start Date\"] = pd.to_datetime(test_data[\"Start Date\"])\ntrain_data['Start Date'].head\ntest_data['Start Date'].head","76c79a2f":"train_data['Start Date'] = pd.to_numeric(train_data['Start Date'], errors = 'coerce')\ntest_data['Start Date'] = pd.to_numeric(test_data['Start Date'], errors = 'coerce')\nprint(train_data['Start Date'])\nprint(test_data['Start Date'])\ntrain_data.head()\ntest_data.head()","f84aab3c":"groupMap = {'By Week':1}\nhhsMap = {'United States':1}\nraceMap = {'Hispanic':1,'Non-Hispanic American Indian or Alaska Native':2,'Non-Hispanic Asian':3,'Non-Hispanic Black':4, 'Non-Hispanic More than one race':5,'Non-Hispanic Native Hawaiian or Other Pacific Islander':6,'Non-Hispanic White':7,'Unknown':8}\nageMap = {'0-4 years':0,'5-17 years':1,'18-29 years':2,'30-39 years':3,'40-49 years':4,'50-64 years':5,'65-74 years':6,'75-84 years':7,'85 years and over':8}\n\n","2f584350":"train_data['Group'] = train_data['Group'].map(groupMap)\ntrain_data['HHS Region'] = train_data['HHS Region'].map(hhsMap)\ntrain_data['Race and Hispanic Origin Group'] = train_data['Race and Hispanic Origin Group'].map(raceMap)\ntrain_data['Age Group'] = train_data['Age Group'].map(ageMap)\n\ntest_data['Group'] = test_data['Group'].map(groupMap)\ntest_data['HHS Region'] = test_data['HHS Region'].map(hhsMap)\ntest_data['Race and Hispanic Origin Group'] = test_data['Race and Hispanic Origin Group'].map(raceMap)\ntest_data['Age Group'] = test_data['Age Group'].map(ageMap)","3ce15e23":"# train_data = train_data.replace(np.nan,0,regex=True)","56264094":"train_data.head()","cba3213e":"print(train_data)","0638b7fd":"train_data.info()","527b57ac":"# g = sns.FacetGrid(train_data, col='Race and Hispanic Origin Group', row='Age Group')\n# g.map(sns.regplot, 'Start Date', 'COVID-19 Deaths')","adbc41b4":"# dateIterator=[]\n# iterator = 0\n# for i in (train_data['Start Date'].unique()):\n#     dateIterator += [iterator]\n# #     train_data['Start Date'] = train_data['Start Date'].index(dtype = 'int64')\n#     print(iterator)\n#     iterator = iterator+1\n# print(dateIterator)","06ea63c5":"# for i in (train_data['Start Date'].unique()):\n#     train_data = train_data['Start Date'].unique()","5a2616ba":"us_df = train_data.loc[(train_data['HHS Region'] == \"United States\")]","c9d005ae":"X_raw = us_df.drop(columns=['COVID-19 Deaths'])\nY_raw = us_df.loc[:, 'COVID-19 Deaths']","0868fd59":"epoch_date = X_raw['Start Date']","551a4145":"class FrameCleaner(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    def fit(self,X,y=None):\n        return self\n    def Transform(self, X, y=None):\n        X = X.drop(columns=['id',\n                            'Data As Of',\n                            'End Date',\n                            'Group',\n                            'Year',\n                            'Month',\n                            'MMWR Week',\n                            'Week-Ending Date',\n                            'HHS Region',\n                            'Total Deaths'])\n        return X","34776501":"class MonthInserter(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    def fit(self,X,y=None):\n        return self\n    def Transform(self,X,y=None):\n        X.loc[:,'Month'] = X.loc[:,'Start Date'].dt.month\n        return X","2d98945b":"class DateIndexer(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    def fit(self,X,y=None):\n        return self\n    def Transform(self,X,y=None):\n        X.loc[:,'t'] = (X['Start Date'] - epoch_date).dt.total_seconds() \/ (60*60*24)+1\n        X = X.drop(columns='Start Date')\n        return X","47a9c6bf":"def rmse(predictions,y):\n    mse= mean_squared_error(y,predictions)\n    return math.sqrt(mse)","9f746a8c":"X = train_data.drop(['COVID-19 Deaths'], axis=1)\ny = train_data['COVID-19 Deaths']\ntssplit = TimeSeriesSplit(20)","70612056":"X_train, X_test, y_train,y_test = train_test_split(X,y,test_size =0.2,shuffle=False)","c2f14974":"lg_model = LogisticRegression()\nlg_model.fit(X_train, y_train)\nlg_model_score =(lg_model.score(X, y)) *100\n","08233182":"# ols_pipe = make_pipeline(FrameCleaner(),\n#                          MonthInserter(),\n#                          DateIndexer,\n#                          make_column_transformer(\n#                          (OneHotEncoder(), ['Race and Hispanic Orgin Group']),\n#                          (OneHotEncoder(),['Age Group']),\n#                          remainder = 'passthrough'\n#                          ),\n#                          LinearRegression()\n#                         )\n                            ","723b5e66":"# n_components = list(range(1,X.shape[1]+1,1))\n# normalize = [True, False]\n# selection = [\"cyclic\", \"random\"]","8252a63e":"# ols_pipe = Pipeline(steps=[('std_scl', StandardScaler()),\n#                            ('pca', PCA()),\n#                            ('linear', LinearRegression())])\n# parameters = dict(pca__n_components=n_components,\n#                       linear__normalize=normalize)\n# ols_reg = GridSearchCV(pipe, parameters)\n# ols_reg.fit(X, y)","5dfa868f":"ols= linear_model.LinearRegression()\nols_results=[]\n\nfor train_i, test_i in tssplit.split(X):\n    ols.fit(X_train,y_train)\n    prediction = ols.predict(X_test)\n    ols_results.append(rmse(prediction,y_test))\nsns.histplot(ols_results,bins=10)\nplt.show()\nols_df=pd.Series(ols_results)\nprint(ols_df.describe())","46f00aa0":"rrmodel = Ridge(alpha=1.0)\nrr_results = []\nrrcv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\nrrscores = cross_val_score(rrmodel, X, y, scoring='neg_mean_absolute_error', cv=rrcv, n_jobs=-1)\nrrscores = absolute(rrscores)\nrrmodel.fit(X_train,y_train)\nrrprediction = rrmodel.predict(X_test)\nrr_results.append(rmse(rrprediction,y_test))\n\nsns.histplot(rrscores, bins=10)\nplt.show()\nridge_df=pd.Series(ols_results)\nprint(ols_df.describe())\n# RRscores = df = pd.DataFrame(RRscores, columns = [\"MSE\"])\n# RRscores[\"RMSE\"] = RRscores['MSE']**(1\/2)\n# RRscores[\"RMSE\"].describe()","6ba8a387":"lr_results= []\nlrmodel = Lasso(alpha=1.0)\nlrcv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\nlrscores = cross_val_score(LRmodel, X, y, scoring='neg_mean_absolute_error', cv=lrcv, n_jobs=-1)\nlrscores = absolute(LRscores)\nlrmodel.fit(X, y)\nlrprediction = lrmodel.predict(X_test)\nlr_results.append(rmse(lrprediction,y_test))\n\nsns.histplot(lrscores, bins=10)\nplt.show()\nlasso_df=pd.Series(lr_results)\nprint(lasso_df.describe())\n# LRscores = df = pd.DataFrame(LRscores, columns = [\"MSE\"])\n# LRscores[\"RMSE\"] = RRscores['MSE']**(1\/2)\n# LRscores[\"RMSE\"].describe()","1dff5e10":"enr_results=[]\nenrmodel = ElasticNet(alpha=1.0, l1_ratio=0.5)\nenrcv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\nenrscores = cross_val_score(enrmodel, X, y, scoring='neg_mean_absolute_error', cv=enrcv, n_jobs=-1)\nenrscores = absolute(enrscores)\nenrmodel.fit(X_train, y_train)\nenrprediction = enrmodel.predict(X_test)\nenr_results.append(rmse(enrprediction,y_test))\n\nsns.histplot(enrscores, bins=10)\nplt.show()\nenr_df=pd.Series(enr_results)\nprint(enr_df.describe())","4fe7fc26":"print('Logistic Regression: %' + str(lg_model_score))\nprint('Ridge Mean RMAE: %.3f (%.3f)' % (mean(rrscores), std(rrscores)))\nprint('Lasso Mean RMAE: %.3f (%.3f)' % (mean(lrscores), std(lrscores)))\nprint('Elastic Mean RMAE: %.3f (%.3f)' % (mean(enrscores), std(enrscores)))","e45f064a":"# ourPred = enrmodel.predict(train_data)\n# submission = pd.DataFrame({'id': test_id, 'COVID-19 Deaths': mean(lassoscores)})\n# submission.to_csv(\"submission.csv\", index=False)\n# print(\"Your submission was successfully saved!\")","0571d2c8":"test_data.shape","299fa0d6":"train_data.shape","110f9b07":"lrmodel.fit(X,y)\nfinal_pred= lrmodel.predict(test_data)\nprediction_df=pd.DataFrame()\nprediction_df['id']=test_id\nprediction_df['COVID-19 Deaths']=final_pred\nprediction_df.to_csv(\"submission.csv\",index=False)\nprint(prediction_df.to_string())","66d36b3e":"### Elastic Net Regression","9d75a651":"### As we can see, month has missing data, and MMWR week and week - ending date has missing data. covid-19 deaths and total deaths and foot note also have missing data","6fd52e9c":"regression problem, Root mean square ","040180e9":"### Ridge Regression","12026785":"### Logistic Regression","f65876b6":"-----------\n## check for missing data","bd2b06cd":"the time data needs to change from time to int. ","2433c1f1":"### There are no outliers that stand out after I fixed the Data. ","1c0fa6c7":"month has 59400 null values, drop the column?\n\nfootnote has 38371 null values, drop the colmun?\n\nMMWR week, week-ending, covid 19 deaths, and total deaths - fill in null data","d5bf7772":"# data Analysis","d1718a0c":"### Oridnary Least Squares","efd82279":"# Christopher Gray\n# Assignment 1\n# CAP 4611","bd506116":"### Lasso Regression","f2e4ccff":"## Check for outliers","262621c3":"# load Data"}}