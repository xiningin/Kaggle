{"cell_type":{"23877b56":"code","7c16d114":"code","1438051c":"code","0e2bc04f":"code","32cae55c":"code","1b268bca":"code","23c26656":"code","aeeea491":"code","e1be24de":"code","c2084753":"code","39f03414":"code","fde37807":"code","6af10d25":"code","701c583b":"code","a5e68fa6":"code","2ce7a80b":"code","7fca5cfb":"code","af8435f8":"code","7f86f067":"code","08b400f9":"markdown","5f0cac35":"markdown","496b71cf":"markdown"},"source":{"23877b56":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7c16d114":"# import libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as py\nimport seaborn as sns\n\n\n#warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\npd.set_option(\"display.max_rows\",None)\npd.set_option(\"display.max_columns\",None)","1438051c":"# load data into the dataframe\ndf_raw = pd.read_csv(\"..\/input\/healthcare-providers-data\/Healthcare Providers.csv\")\ndf_raw.head()","0e2bc04f":"# shape of data\ndf_raw.shape","32cae55c":"df_raw.columns","1b268bca":"DropCols = ['index', 'National Provider Identifier','Last Name\/Organization Name of the Provider',\n       'First Name of the Provider', 'Middle Initial of the Provider','Street Address 1 of the Provider',\n       'Street Address 2 of the Provider','Zip Code of the Provider',\"HCPCS Code\"]\ndf_cur1 = df_raw.drop(DropCols, axis = 1)\ndf_cur1.info()","23c26656":"100*df_cur1.isnull().sum()\/len(df_cur1)","aeeea491":"print('Frequenty appearing value in \"Credentials of the Provider\" feature is  ',df_cur1[\"Credentials of the Provider\"].mode()[0])\nprint('Frequenty appearing value in \"Gender of the Provider\" feature is  ' ,df_cur1['Gender of the Provider'].mode()[0])","e1be24de":"df_cur1[\"Credentials of the Provider\"] = df_cur1[\"Credentials of the Provider\"].fillna(df_cur1[\"Credentials of the Provider\"].mode()[0])\ndf_cur1[\"Gender of the Provider\"] = df_cur1[\"Gender of the Provider\"].fillna(df_cur1[\"Gender of the Provider\"].mode()[0])","c2084753":"# % of null values in dataset\n100*df_cur1.isnull().sum()\/len(df_cur1)","39f03414":"df_cur1.describe()","fde37807":"int_cols = ['Number of Services','Number of Medicare Beneficiaries',\n            \"Number of Distinct Medicare Beneficiary\/Per Day Services\",\n            'Average Medicare Allowed Amount','Average Submitted Charge Amount',\n            'Average Medicare Payment Amount','Average Medicare Standardized Amount']","6af10d25":"\ndf_cur1[int_cols].describe()","701c583b":"#ValueError: Unable to parse string \"1,529.4\" at position 122\n# In the above error we can see that comma in number, function is created to remove , from that number\n# cleanse all the numeric data and convert that table into numeric\n\ndef remove_comma(x):\n    return x.replace(\",\",\"\")\n\nfor col in int_cols:\n    df_cur1[col] = pd.to_numeric(df_cur1[col].apply(lambda x: remove_comma(x)),errors= \"ignore\")","a5e68fa6":"df_cur1[int_cols].describe()","2ce7a80b":"### Lets get categorical columns and there categories\n\nfor col in df_cur1.columns:\n    if col not in int_cols:\n        print(col)\n        print(df_cur1[col].value_counts())","7fca5cfb":"print(int_cols)","af8435f8":"import category_encoders as ce\nfrom sklearn.preprocessing import StandardScaler\n#2.Binary Encoding.\n\ndata =   df_cur1  \nBEcols = [var for var in data.columns if data[var].dtype == \"O\"]\n\nfor col in BEcols:\n    encoder = ce.BinaryEncoder(cols = [col])\n    dfbin = encoder.fit_transform(data[col])\n    data = pd.concat([data,dfbin], axis = 1)\n    del data[col]","7f86f067":"data.head()","08b400f9":"#### We can see that feature 'Credentials of the Provider'  and 'Gender of the Provider' is having less than 10% null values , we can remove these entries or else we can replace them by frequenty appearing values","5f0cac35":"# Anomaly Detection ","496b71cf":"#### by seeing STD from the above table , we can say that the data is widley spreaded"}}