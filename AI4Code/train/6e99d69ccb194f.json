{"cell_type":{"fe7421de":"code","f1bbe759":"code","74062bb2":"code","4f8ff76d":"code","a6838b58":"code","1eb52b15":"code","7836351c":"code","c949b380":"code","8e2b1a2a":"code","6d0cc705":"code","9d483eb4":"code","6dea51bf":"code","ff452ad6":"code","38013241":"markdown","660fe332":"markdown","51fb1344":"markdown","373236dd":"markdown","5f619b29":"markdown","e138b3e6":"markdown","7be6d2f7":"markdown","0172967d":"markdown","8970e617":"markdown","2864b003":"markdown","1e0a4638":"markdown","ed2c97f1":"markdown"},"source":{"fe7421de":"INPUT_DIR = '\/kaggle\/input\/anime-recommendation-database-2020'\n#!ls {INPUT_DIR}\n\nimport pandas as pd\nimport warnings; warnings.filterwarnings(\"always\"); warnings.filterwarnings(action='ignore')\n\n\"\"\" 1) anime \ub370\uc774\ud130\uc14b \"\"\"\n\nanime = pd.read_csv(INPUT_DIR + '\/anime.csv')\nanime_with_synopsis = pd.read_csv(INPUT_DIR + '\/anime_with_synopsis.csv', usecols=[\"MAL_ID\", \"sypnopsis\"])\nanimes = pd.merge(anime, anime_with_synopsis, on='MAL_ID') # anime + synopsis \ud569\uce68\nprint('number of animes: ', len(animes.MAL_ID.unique()))\n\n\"\"\" 2) user rating \ub370\uc774\ud130\uc14b \"\"\" # 0 if the user didn't assign a score\n\nanimelist = pd.read_csv(INPUT_DIR + '\/animelist.csv', usecols=[\"user_id\", \"anime_id\", \"rating\"])\n# Users who rated more than 5000 animies\nn_ratings = animelist['user_id'].value_counts()\nrating_df = animelist[animelist['user_id'].isin(n_ratings[n_ratings >= 5000].index)]\nprint('number of users: ', len(rating_df.user_id.unique()))\n\n\"\"\" \uacb0\uce21\uce58 \ucc98\ub9ac \"\"\"\n\nanimes = animes.dropna()\nrating_df = rating_df.dropna()\n\n\"\"\" \uc911\ubcf5\uac12 \ucc98\ub9ac \"\"\"\n\ndef remove_duplicated_rows(df):\n    print('dataframe')\n    duplicates = df.duplicated()\n    if duplicates.sum() > 0:\n        print('> {} duplicates'.format(duplicates.sum()))\n        df = df[~duplicates]\n    print('> {} duplicates'.format(df.duplicated().sum()))\n\nremove_duplicated_rows(animes)\nremove_duplicated_rows(rating_df)","f1bbe759":"\"\"\"import pandas as pd\nimport warnings; warnings.filterwarnings(\"always\"); warnings.filterwarnings(action='ignore')\n\nanimes = pd.read_feather('..\/input\/anime-data-save-as-feather\/animes.feather')\nanimes = animes.rename({'anime_id': 'MAL_ID'}, axis='columns')\nprint(animes.shape)\n\nrating_df = pd.read_feather('..\/input\/anime-data-save-as-feather\/rating_df.feather')\nprint(rating_df.shape)\n\nanimes.sample()\"\"\"","74062bb2":"\"\"\" \uc0ac\uc6a9\ud560 feature \uc120\ud0dd \"\"\"\n\nani_df = animes[['MAL_ID', 'Name', 'Genders', 'Type','Episodes', 'Aired','Source', 'Duration', 'Rating', 'Ranked', 'sypnopsis']]\nprint(ani_df.shape)\nani_df.sample(3)","4f8ff76d":"\"\"\" \uacb0\uce21\uce58 \uac2f\uc218 \"\"\"\nani_df[ani_df == 'Unknown'].count()","a6838b58":"\"\"\"\n1) sypnopsis \n\"\"\"     \nani_df[~ani_df['sypnopsis'].str.contains(\"No synopsis\")]\n\n\"\"\"\n2) Source\n\"\"\"\nani_df['Source'] = ani_df['Source'].replace(\"Unknown\", 'Original') # Original 5000\uac1c\uc778\ub370 \uc880 \uc624\ubc14\uc778\ub4ef \n\n\"\"\"\n3) \ub098\uba38\uc9c0\n\"\"\"\nani_df = ani_df[ani_df['Genders'] != 'Unknown']\nani_df = ani_df[ani_df['Type'] != 'Unknown']\nani_df = ani_df[ani_df['Episodes'] != 'Unknown']\nani_df = ani_df[ani_df['Aired'] != 'Unknown']\nani_df = ani_df[ani_df['Source'] != 'Unknown']\nani_df = ani_df[ani_df['Duration'] != 'Unknown']\nani_df = ani_df[ani_df['Rating'] != 'Unknown']\nani_df = ani_df[ani_df['Ranked'] != 'Unknown']\nprint('remaining: ', ani_df.shape)\n\n\"\"\"\nreset index\n\"\"\"\nani_df = ani_df.reset_index() ","1eb52b15":"\"\"\" \uacb0\uce21\uce58 \uac2f\uc218 \"\"\"\nani_df[ani_df == 'Unknown'].count()","7836351c":"\"\"\" \n1) Aired: \ub0a0\uc9dc \ud615\uc2dd \ud1b5\uc77c (e.g., Spe 1, 2001 => 2001) \n\"\"\"\n\nyears  = []\nmonths = []\nfor val in ani_df['Aired']:\n    vr = val.split()\n    y = 'Unknown'\n    m = 'Unknown'\n    for v in vr:\n        if v.isdigit() and len(v) == 4 :\n            y = v\n            break\n    for v in vr:\n        if not v.isdigit() and len(v) >= 3 and v[0].isupper() and v != 'Unknown' :\n            m = v[:3]\n            break\n        \n    years += [ y ]\n    months += [ m ]\n\nani_df['Year'] = years\nani_df['Month'] = months\n\nmonth_to_number = {\n'Jan' : 1,         \n'Feb' : 2,         \n'Mar' : 3,           \n'Apr' : 4,              \n'May' : 5, \n'Jun' : 6,\n'Jul' : 7, \n'Aug' : 8, \n'Sep' : 9, \n'Oct' : 10, \n'Nov' : 11, \n'Dec' : 12}\n\nani_df['Month'] = ani_df['Month'].replace(month_to_number)\n\nani_df['Year'] = ani_df['Year'].replace(\"Unknown\", 0).astype(float)\nani_df['Month'] = ani_df['Month'].replace(\"Unknown\", 0).astype(float)\n\nani_df['date'] = ani_df['Year']\n\n\"\"\" \n2) Duration: \ub2e8\uc704 \ud1b5\uc77c (e.g., 1 hr. 55 min. => 115) \n\"\"\"\n\nhrs  = []\nmins = []\nfor val in ani_df['Duration']:\n    split_list = val.split() # ['24', 'min.', 'per', 'ep.']\n    h = 'Unknown'\n    m = 'Unknown'\n    for i in split_list:\n        if i == 'hr.':\n            h = split_list[split_list.index(i)-1]\n        elif i == 'min.':\n            m = split_list[split_list.index(i)-1]\n        \n    hrs += [ h ]\n    mins += [ m ]\n\nani_df['hours'] = hrs\nani_df['mins'] = mins\n\nani_df['hours'] = ani_df['hours'].replace(\"Unknown\", 0).astype(float)\nani_df['mins'] = ani_df['mins'].replace(\"Unknown\", 0).astype(float)\n\nani_df['duration'] = (ani_df['hours']*60) + ani_df['mins']\n\n\"\"\" \n3) Ranked: str -> int \ud0c0\uc785 \ubcc0\ud658 \n\"\"\"\n\ntry:\n    ani_df['Ranked'] = ani_df['Ranked'].replace(\"Unknown\", 0).astype(float)\nexcept:\n    pass\nani_df[\"Ranked\"] = pd.to_numeric(ani_df[\"Ranked\"])\n\n\n\"\"\" \n\ucd9c\ub825 \n\"\"\"\n\nani_df = ani_df.drop(['Aired', 'Duration','Year', 'Month','hours', 'mins' ], axis = 1)\nprint(ani_df.shape)\nani_df.head()","c949b380":"\"\"\" \n1) BoW: Genders \n\"\"\"\n\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ncount_vector = CountVectorizer()\ncount_vector.fit(ani_df['Genders'])\n#print('number of genres: ', len(count_vector.get_feature_names())) # action, comedy, ...\n\ndoc_array = count_vector.transform(ani_df['Genders']).toarray()\nfrequency_matrix = pd.DataFrame(doc_array, \n                                columns = count_vector.get_feature_names())\nprint('BoW of Genders shape: ', frequency_matrix.shape)\n\n\"\"\" \n2) tf-idf: sypnopsis \n\"\"\"\n\n#ani_df['sypnopsis'] = ani_df['sypnopsis'].map(lambda x: ','.join(x))\n\ndef process_multilabel(series):\n    series = series.split(\" \")\n    if \"Unknown\" in series:\n        series.remove(\"Unknown\")\n    return series\nani_df[\"sypnopsis\"] = ani_df[\"sypnopsis\"].map(process_multilabel)\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\ntfv = TfidfVectorizer(min_df=3,  max_features=100, \n            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n            ngram_range=(1, 3),\n            stop_words = 'english')\nsypnopsis_original = ani_df['sypnopsis'].fillna('').astype(str) # Filling NaNs with empty string\nsypnopsis_vector_tf_idf = tfv.fit_transform(sypnopsis_original)\nsypnopsis_matrix = pd.DataFrame(sypnopsis_vector_tf_idf.toarray())\nprint(\"tf-idf of sypnopsis shape:\", sypnopsis_vector_tf_idf.shape)\n\n\"\"\" \n3) OneHotEncoding: Type, Source, Rating \n\"\"\"\n\nfrom sklearn.preprocessing import OneHotEncoder\n\nType = ani_df['Type'].values.reshape(-1, 1)\nenc = OneHotEncoder()\nenc.fit(Type)\ntype_ohe = enc.transform(Type).toarray()\ntype_ohe = pd.DataFrame(type_ohe, columns = enc.get_feature_names())\n\nSource = ani_df['Source'].values.reshape(-1, 1)\nenc = OneHotEncoder()\nenc.fit(Source)\nsource_ohe = enc.transform(Source).toarray()\nsource_ohe = pd.DataFrame(source_ohe, columns = enc.get_feature_names())\n\nRating = ani_df['Rating'].values.reshape(-1, 1)\nenc = OneHotEncoder()\nenc.fit(Rating)\nrating_ohe = enc.transform(Rating).toarray()\nrating_ohe = pd.DataFrame(rating_ohe, columns = enc.get_feature_names())\n","8e2b1a2a":"a = len(rating_df.anime_id.unique())\nb = len(rating_df.user_id.unique())\n\nprint('animes: ',a)\nprint('users: ', b)\nprint('\\n', '{0}\uba85\uc758 \uc720\uc800\uac00 {1}\uac1c\uc758 \uc601\ud654\ub97c \ud3c9\uac00\ud55c matrix \uc0dd\uc131'.format(b,a), '\\n')\n\nimport numpy as np\n\ntop_users = rating_df.groupby('user_id')['rating'].count()\ntop_r = rating_df.join(top_users, rsuffix='_r', how='inner', on='user_id')\n\ntop_animes = rating_df.groupby('anime_id')['rating'].count()\ntop_r = top_r.join(top_animes, rsuffix='_r', how='inner', on='anime_id')\n\nscore_df = pd.crosstab(top_r.user_id, top_r.anime_id, top_r.rating, aggfunc=np.sum)\nscore_df","6d0cc705":"all_users_df = []\n\nuser_id_list = list(score_df.index)\n\nfor user_id in user_id_list:\n    \"\"\" \uc720\uc800 \ubcc4 score vector \"\"\"\n    score_vector = score_df.loc[user_id] \n    score_vector = score_vector.dropna() \n    score_vector = score_vector[score_vector != 0] # 0\uc810\uc740 \ud3c9\uac00 \uc548\ud55c\uac83 (\uc5ec\uae30\uc11c \ub9ce\uc774 \ub0a0\ub77c\uac00\ub294\ub4ef)\n\n    anime_id_list = list(score_vector.index)\n    user_score_list = list(score_vector.values)\n\n    \"\"\" \uc720\uc800\uac00 \ubcf8 \uc601\ud654\ub9cc \ucd94\ucd9c \"\"\"\n    ani_df_user = ani_df.loc[ani_df['MAL_ID'].isin(anime_id_list)] \n\n    \"\"\" \uc720\uc800 \ubcc4 \ub9e4\ud2b8\ub9ad\uc2a4 \uc0dd\uc131 \"\"\"\n    score_vector_df = pd.DataFrame(score_vector)\n    score_vector_df['MAL_ID'] = score_vector_df.index\n    score_vector_df.columns = ['score_by_user_{}'.format(user_id), 'MAL_ID']\n\n    user_df = pd.merge(ani_df_user,score_vector_df, how='inner',on='MAL_ID')\n    \n    \"\"\" append user_df \"\"\"\n    all_users_df.append(user_df)\n\na = len(all_users_df)\nprint('users: ', a)\nprint('\\n', '{0}\uba85\uc758 \uc720\uc800\uc5d0 \ub300\ud574 \uc544\ub798 matrix\ub97c \uac01\uac01 \uc0dd\uc131'.format(a), '\\n')\nall_users_df[0]","9d483eb4":"\"\"\" \ucd5c\uc885 \uc0ac\uc6a9\ud560 \ub370\uc774\ud130 \uc218 \"\"\"\n\nprint('\uc720\uc800 \uc218: ', len(all_users_df))\n\nnum = 0\nfor i in all_users_df:\n    num += len(i)\n    \nprint('\uc720\uc800 1\uba85 \ub2f9 \ud3c9\uade0 \ud3c9\uac00 \uac2f\uc218: ', round(num\/len(all_users_df),1))","6dea51bf":"combined_matrix = frequency_matrix.join(sypnopsis_matrix, how='left')\ndata = ani_df.join(combined_matrix, how='left')\ndata = data.drop(data.loc[:, 'Name':'duration'].columns, axis = 1)\ndata = data.drop(columns=['index'])\ndata","ff452ad6":"data = ani_df[['MAL_ID', 'Episodes', 'Ranked', 'date', 'duration']] # numeric\n\nfrom sklearn.preprocessing import MinMaxScaler\ndata[[\"Episodes\"]] = MinMaxScaler().fit_transform(data[[\"Episodes\"]])\ndata[[\"Ranked\"]] = MinMaxScaler().fit_transform(data[[\"Ranked\"]])\ndata[[\"date\"]] = MinMaxScaler().fit_transform(data[[\"date\"]])\ndata[[\"duration\"]] = MinMaxScaler().fit_transform(data[[\"duration\"]])\n\ntry:\n    type_ohe.rename(columns = {'x0_Music' : 'x0_Music_'}, inplace = True)\nexcept:\n    pass\n\ndata = data.join(type_ohe, how='left')\ndata = data.join(source_ohe, how='left')\ndata = data.join(rating_ohe, how='left')\ndata","38013241":"## 2-2. prediction model\n- \uc0ac\uc6a9 feature: Episodes, Ranked, date, duration, Type, Source, Rating,","660fe332":"## 1-1. feature matrix (ani_df)","51fb1344":"## 1-3. user matrix (user_df)\n- ani_df + score_df","373236dd":"# 0. \uc601\ud638\ud615 \ub370\uc774\ud130 \ubd88\ub7ec\uc624\uae30","5f619b29":"# 2. \ub370\uc774\ud130\uc14b \uc800\uc7a5","e138b3e6":"### 1-1-3. \uc804\ucc98\ub9ac (text) \n- \uc0ac\uc6a9 feature: Genders, Sypnopsis, Type, Source, Rating\n    - BoW: Genders\n    - TF-IDF: sypnopsis\n    - OneHotEncoding: Type, Source, Rating","7be6d2f7":"# 0. \ub370\uc774\ud130 \ubd88\ub7ec\uc624\uae30\n- \ucee8\ud150\uce20\n    - \ub370\uc774\ud130: animes (16214\uac1c) = anime.csv (17562\uac1c) + anime_with_synopsis.csv (16214\uac1c) \n- \uc720\uc800\n    - \ub370\uc774\ud130: animelist.csv (\uc720\uc800 325770\uba85, \uc601\ud654 17562\uac1c, \ud3c9\uac00 62M\uac1c)","0172967d":"# 1. \ub370\uc774\ud130\uc14b \uc0dd\uc131","8970e617":"### 1-1-1. \uacb0\uce21\uce58('Unknown') \ucc98\ub9ac\n- \uc0ac\uc6a9 feature: \ubaa8\ub450\n    - sypnopsis: \"No synopsis information ...\" & \"No synopsis has ...\" \uc0ad\uc81c\n    - Source: \ucd5c\ube48\uac12 \ub300\uce58\n    - \ub098\uba38\uc9c0: \uc0ad\uc81c","2864b003":"## 1-2. score matrix (score_df)","1e0a4638":"## 2-1. vector space model\n- \uc0ac\uc6a9 feature: Genders, sypnopsis","ed2c97f1":"### 1-1-2. \uc804\ucc98\ub9ac (numeric)\n- \uc0ac\uc6a9 feature: Aired, Duration, Ranked"}}