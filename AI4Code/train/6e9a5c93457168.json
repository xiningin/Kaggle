{"cell_type":{"24799d66":"code","3a2b2316":"code","7a92066e":"code","a83e3c64":"code","cfcf0a68":"code","7c7a5d4a":"code","59f4461d":"code","2820d94a":"code","95eba3b4":"code","7bc629b9":"code","4845b86f":"code","26e41a84":"code","99ef45fa":"code","06c04ad6":"code","5951620a":"code","253edc51":"code","209199d6":"code","53e3c181":"code","3437236d":"code","64d3180f":"code","a7991cb1":"code","c6cdd450":"code","6cafbb41":"code","7d7624f4":"code","40ec6a93":"code","3301e3d3":"code","e68114d7":"code","9607ab8a":"code","d198f180":"code","d91c5542":"code","aa765e7c":"code","f43b78f5":"code","a9d6340f":"code","6b6fc58b":"code","b45cf981":"code","14efe8e1":"code","2d105d09":"code","fb5cc701":"code","c835d0a5":"code","2a802fb6":"code","d7dbbb47":"code","ec1614e8":"code","09a21ab5":"code","ca537e5c":"markdown","59bdc2fd":"markdown","5e0d30cb":"markdown","afc114bb":"markdown","4c493ef8":"markdown","0b3d56e1":"markdown","e8f88714":"markdown","c2411608":"markdown","bb0197a4":"markdown","23f5a06c":"markdown"},"source":{"24799d66":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n","3a2b2316":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport cv2\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Flatten, Dense, Activation, Dropout\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\nfrom keras.applications.imagenet_utils import preprocess_input\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input, decode_predictions\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.utils import *\nfrom tensorflow.keras.callbacks import *\nfrom tensorflow.keras.initializers import *","7a92066e":"!pip install -U efficientnet\nimport efficientnet.keras as efn","a83e3c64":"train_txt = pd.read_csv('\/kaggle\/input\/covidx-cxr2\/train.txt', sep=\" \", header=None)\ntrain_txt.columns= [\"Sl.no\",\"File_Name\",\"Status\",\"Source\"]\ntrain_txt.head()","cfcf0a68":"train_txt.drop([\"Sl.no\",\"Source\"], axis=1, inplace=True)","7c7a5d4a":"test_txt= pd.read_csv('\/kaggle\/input\/covidx-cxr2\/test.txt', sep=\" \", header=None)\ntest_txt.columns= [\"Sl.no\",\"File_Name\",\"Status\",\"Source\"]\ntest_txt.head()","59f4461d":"test_txt.drop([\"Sl.no\",\"Source\"], axis=1, inplace=True)","2820d94a":"test_dest_pth= '\/kaggle\/input\/covidx-cxr2\/test\/'\ntest_txt['File_Name'] = test_dest_pth + test_txt['File_Name']","95eba3b4":"test_txt","7bc629b9":"dest_pth= '\/kaggle\/input\/covidx-cxr2\/train\/'\ntrain_txt['File_Name'] = dest_pth+train_txt['File_Name']","4845b86f":"train_txt['Status'].value_counts()","26e41a84":"neg = train_txt.Status[train_txt.Status.eq(\"negative\")].sample(2158).index\npos = train_txt.Status[train_txt.Status.eq(\"positive\")].sample(2158).index \n\ntrain_txt = train_txt.loc[neg.union(pos)]","99ef45fa":"train_txt.shape","06c04ad6":"train_df, valid_df=train_test_split(train_txt, test_size=0.2, stratify=train_txt[\"Status\"], random_state=123)","5951620a":"datagen=ImageDataGenerator(rescale=1.\/255.,validation_split=0.25)","253edc51":"train_df","209199d6":"valid_df","53e3c181":"import os\nprint( os.path.abspath(\"valid_df\"))","3437236d":"train_generator=datagen.flow_from_dataframe(\ndataframe=train_df,\ndirectory=\"\/kaggle\/working\/\",\nx_col=\"File_Name\",\ny_col=\"Status\",\nsubset=\"training\",\nbatch_size=32,\nseed=42,\nshuffle=True,\nclass_mode=\"binary\",\ntarget_size=(256,256))\n\nvalid_generator=datagen.flow_from_dataframe(\ndataframe=valid_df,\ndirectory=\"\/kaggle\/working\/\",\nx_col=\"File_Name\",\ny_col=\"Status\",\nsubset=\"validation\",\nbatch_size=10,\nseed=42,\nshuffle=True,\nclass_mode=\"binary\",\ntarget_size=(256,256))\n\ntest_datagen=ImageDataGenerator(rescale=1.\/255.)\ntest_generator=test_datagen.flow_from_dataframe(\ndataframe=test_txt,\ndirectory=\"\/kaggle\/working\/\",\nx_col=\"File_Name\",\ny_col=\"Status\",\nbatch_size=32,\nseed=42,\nshuffle=False,\nclass_mode=\"binary\",\ntarget_size=(256,256))","64d3180f":"base_model = efn.EfficientNetB0(input_shape = (256, 256, 3), include_top = False, weights = 'imagenet')","a7991cb1":"for layer in base_model.layers:\n    layer.trainable = False","c6cdd450":"x = base_model.output\nx = Flatten()(x)\nx = Dense(1024, activation=\"relu\")(x)\nx = Dropout(0.5)(x)\npredictions = Dense(1, activation=\"sigmoid\")(x)\nmodel_final = Model(base_model.input,predictions)","6cafbb41":"model_final.compile('rmsprop',loss='binary_crossentropy',metrics=['accuracy'])","7d7624f4":"eff_history = model_final.fit_generator(train_generator, validation_data = valid_generator, steps_per_epoch = 50, epochs = 4)","40ec6a93":"model_final.evaluate_generator(generator=valid_generator,steps=10)","3301e3d3":"valid_df","e68114d7":"model_final.evaluate_generator(generator=test_generator,steps=10)","9607ab8a":"pred=model_final.predict_generator(test_generator)","d198f180":"len(pred)","d91c5542":"# Prediction for Test Data\npreds=pred.round(decimals=0)\nfor p in preds:\n    print (p)","aa765e7c":"test_txt['Status'].value_counts()","f43b78f5":"from matplotlib import pyplot\npyplot.subplot(211)\npyplot.title('Loss')\npyplot.plot(eff_history.history['loss'], label='train')\npyplot.plot(eff_history.history['val_loss'], label='test')\npyplot.legend()\n# plot accuracy during training\npyplot.subplot(212)\npyplot.title('Accuracy')\npyplot.plot(eff_history.history['accuracy'], label='train')\npyplot.plot(eff_history.history['val_accuracy'], label='test')\npyplot.legend()\npyplot.tight_layout()\npyplot.show()","a9d6340f":"test_generator.class_indices","6b6fc58b":"test_txt['Status'][test_txt['Status']=='positive']=1.0\ntest_txt['Status'][test_txt['Status']=='negative']=0.0","b45cf981":"test_txt['Status'].astype('float')","14efe8e1":"from sklearn.metrics import classification_report, confusion_matrix\nprint('Confusion Matrix')\nprint(confusion_matrix(test_generator.classes, preds))\nmat = confusion_matrix(test_generator.classes, preds)\nprint('Classification Report')\ntarget_names = ['Negative', 'Positive']\nprint(classification_report(test_generator.classes, preds, target_names=target_names))","2d105d09":"ax= plt.subplot()\nsns.heatmap(mat, annot=True, fmt='g', ax=ax);  \n\n# labels, title and ticks\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix'); \nax.xaxis.set_ticklabels(['Negative', 'Positive']); ax.yaxis.set_ticklabels(['Negative', 'Positive']);","fb5cc701":"# Picking out a Positive Test Sample\ntest_txt['File_Name'][112]","c835d0a5":"import numpy as np\nfrom keras.preprocessing import image\ntest_image= image.load_img('\/kaggle\/input\/covidx-cxr2\/test\/MIDRC-RICORD-1C-419639-000025-39552-1.png'\n                           ,target_size =(256,256))\ntest_image","2a802fb6":"preds[112]","d7dbbb47":"# We are taking a sample of 4 Positive & Negative Images\n# We will look at the predictions generated for the above images\n\npos_imgs=[]\nneg_imgs=[]\npos_imgs.append(test_txt['File_Name'][60])\npos_imgs.append(test_txt['File_Name'][79])\npos_imgs.append(test_txt['File_Name'][138])\npos_imgs.append(test_txt['File_Name'][141])\nneg_imgs.append(test_txt['File_Name'][287])\nneg_imgs.append(test_txt['File_Name'][252])\nneg_imgs.append(test_txt['File_Name'][253])\nneg_imgs.append(test_txt['File_Name'][243])\nimgs =[]\nfor i in pos_imgs:\n    imgs.append(i)\nfor i in neg_imgs:\n    imgs.append(i)","ec1614e8":"# Model generated predictions for above Images\npreds[[60,79,138,141,287,252,253,243]]","09a21ab5":"# Visualization of the above selected Images\nplt.figure()\nimages=[]\n\n#subplot(r,c) provide the no. of rows and columns\n\nfor i in range(len(imgs)):\n    it_image = plt.imread(imgs[i]) \n    images.append(it_image)\nf, axarr = plt.subplots(2,4,figsize=(19,10)) \naxarr[0,0].imshow(images[0],cmap='gray')\naxarr[0,1].imshow(images[1],cmap='gray')\naxarr[0,2].imshow(images[2],cmap='gray')\naxarr[0,3].imshow(images[3],cmap='gray')\naxarr[1,0].imshow(images[4],cmap='gray')\naxarr[1,1].imshow(images[5],cmap='gray')\naxarr[1,2].imshow(images[6],cmap='gray')\naxarr[1,3].imshow(images[7],cmap='gray')\naxarr[0,0].title.set_text('Positive')\naxarr[0,1].title.set_text('Positive')\naxarr[0,2].title.set_text('Positive')\naxarr[0,3].title.set_text('Positive')\naxarr[1,0].title.set_text('Negative')\naxarr[1,1].title.set_text('Negative')\naxarr[1,2].title.set_text('Negative')\naxarr[1,3].title.set_text('Negative')\nplt.show()","ca537e5c":"#### The Test Image is a Positive Sample & Model Result also indicates that the sample is Positive","59bdc2fd":"### Model Training","5e0d30cb":"### Validation of Predictions","afc114bb":"#### It is found that for randomly picked 4 Positive & 4 Negative Images. Model Prediction Output has classified the samples correctly","4c493ef8":"### Model Performance Analysis","0b3d56e1":"## COVID X-ray Image Classification with EfficientNet","e8f88714":"### Model Validation & Prediction","c2411608":"### Plotting Model Loss & Accuracy","bb0197a4":"### Importing Required Libraries & Data","23f5a06c":"### Checking Model Predictions"}}