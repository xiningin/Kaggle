{"cell_type":{"ef2f610c":"code","56b4dd19":"code","0a06f783":"code","a707bf7f":"code","6059aa63":"code","2dfbbb46":"code","4ef8d54d":"code","b8be7c80":"code","c5e83ad7":"code","7e686eac":"code","500f9294":"code","a455171a":"code","77431c1a":"code","acdcead9":"code","e3ee9d94":"code","310c9bb2":"code","10c1d247":"code","d75c4942":"code","e2caae4b":"code","0fa1d668":"code","9cb03aed":"code","36365389":"code","f684a3f9":"code","c6158113":"code","aaf00dd6":"code","d4062dff":"code","3c276c66":"code","0772a6ed":"code","4c372adb":"code","a472ed78":"code","fea213d2":"code","9ad87a29":"code","53f92b43":"code","8e64d0b6":"code","aed0b6fa":"code","125dadef":"markdown","d132bd3f":"markdown","a8359440":"markdown","7c1d2b1a":"markdown","babf8779":"markdown","3132fae5":"markdown","c6c96137":"markdown","0ea93e87":"markdown","e52c3646":"markdown","7cbb4ed5":"markdown","c8dd1824":"markdown","05950d55":"markdown","39a809cd":"markdown","a12a3f16":"markdown","3a1f804b":"markdown"},"source":{"ef2f610c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","56b4dd19":"# course title will be come and encoded after all process\n\ndata = pd.read_csv('..\/input\/udemy-courses\/udemy_courses.csv').drop(['course_id', 'course_title', 'url'], axis=1)\nX = data.drop('is_paid', axis=1)\ny = pd.DataFrame(data.is_paid).astype(np.int)","0a06f783":"data.info()","a707bf7f":"object_based_columns = X.loc[:, ['level', 'published_timestamp', 'subject']]","6059aa63":"object_based_columns['level'].drop_duplicates()","2dfbbb46":"object_based_columns['level'][object_based_columns['level'] == 'All Levels'] = 0\nobject_based_columns['level'][object_based_columns['level'] == 'Beginner Level'] = 1\nobject_based_columns['level'][object_based_columns['level'] == 'Intermediate Level'] = 2\nobject_based_columns['level'][object_based_columns['level'] == 'Expert Level'] = 3\nobject_based_columns['level'].describe()","4ef8d54d":"object_based_columns['subject'].drop_duplicates()","b8be7c80":"onehotencode_arrays = np.zeros([object_based_columns['subject'].shape[0], 4])\n\nonehotencode_arrays[object_based_columns['subject'] == 'Business Finance', 0] = 1\nonehotencode_arrays[object_based_columns['subject'] == 'Graphic Design', 1] = 1\nonehotencode_arrays[object_based_columns['subject'] == 'Musical Instruments', 2] = 1\nonehotencode_arrays[object_based_columns['subject'] == 'Web Development', 3] = 1\nprint(onehotencode_arrays)\n\nobject_based_columns = pd.concat([object_based_columns.drop('subject', axis=1), pd.DataFrame(onehotencode_arrays)], axis=1)","c5e83ad7":"min_year = [2017, -1]\nfor rowi in range(len(object_based_columns['published_timestamp'])):\n    yr = int(object_based_columns.loc[rowi, 'published_timestamp'][:4])\n    if min_year[0] >= yr:\n        min_year[0] = yr\n        min_year[1] = rowi\nmin_year","7e686eac":"for rowi in range(len(object_based_columns['published_timestamp'])):\n    yr = int(object_based_columns.loc[rowi, 'published_timestamp'][:4]) - 2011;\n    m = int(object_based_columns.loc[rowi, 'published_timestamp'][5:7])\n    d = int(object_based_columns.loc[rowi, 'published_timestamp'][8:10])\n    h = int(object_based_columns.loc[rowi, 'published_timestamp'][11:13])\n    mi = int(object_based_columns.loc[rowi, 'published_timestamp'][14:16])\n    s = int(object_based_columns.loc[rowi, 'published_timestamp'][17:-1])\n\n    yrc = 60 * 60 * 24 * 30 * 12\n    mc = 60 * 60 * 24 * 30\n    dc = 60 * 60 * 24\n    hc = 60 * 60\n    mic = 60\n    sc = 1\n\n    res = [ yrc * yr\n         + mc * m\n         + dc * d\n         + hc * h\n         + mic * mi\n         + sc * s ][0]\n\n    object_based_columns.loc[rowi, 'published_timestamp'] = res\nobject_based_columns['published_timestamp'].describe()    ","500f9294":"# end of encoding object type columns\nX = pd.concat([X.drop(['level', 'published_timestamp', 'subject'], axis=1), object_based_columns], axis=1)","a455171a":"# num_subcribers, num_reviews, num_lectures, content_duration seem have much extremely upper values\n\nfig, axs = plt.subplots(1, 7, figsize=(30, 4))\ncolumns = X.columns\nk = 0\nfor j in range(7):\n    axs[j].scatter(X[columns[k]], range(X.shape[0]), label=columns[k])\n    axs[j].legend()\n    k += 1\nplt.show()","77431c1a":"# left after that column: num_reviews, num_lectures, content_duration\n\nplt.figure(figsize=(8, 6))\nplt.scatter(X['num_subscribers'], range(data.shape[0]))\nplt.show()","acdcead9":"(X['num_subscribers'].value_counts().index > 30000).sum(), X['num_subscribers'].median()","e3ee9d94":"X.loc[X['num_subscribers'] > 30000, 'num_subscribers'] = X['num_subscribers'].median()","310c9bb2":"# left after that column: num_lectures, content_duration\n\nplt.figure(figsize=(8, 6))\nplt.scatter(X['num_reviews'], range(X.shape[0]))\nplt.show()","10c1d247":"(X['num_reviews'].value_counts().index > 3000).sum(), X['num_reviews'].median()","d75c4942":"X.loc[data['num_reviews'] > 3000, 'num_reviews'] = X['num_reviews'].median()","e2caae4b":"# left after that column: content_duration\n\nplt.figure(figsize=(8, 6))\nplt.scatter(X['num_lectures'], range(X.shape[0]))\nplt.show()","0fa1d668":"(X['num_lectures'].value_counts().index > 280).sum(), X['num_lectures'].median()","9cb03aed":"X.loc[X['num_lectures'] > 280, 'num_lectures'] = X['num_lectures'].median()","36365389":"plt.figure(figsize=(8, 6))\nplt.scatter(X['content_duration'], range(X.shape[0]))\nplt.show()","f684a3f9":"(X['content_duration'].value_counts().index > 28).sum(), X['content_duration'].median()","c6158113":"X.loc[X['content_duration'] > 28, 'content_duration'] = X['content_duration'].median()","aaf00dd6":"pd.concat([X, y], axis=1).corr()['is_paid'].drop('is_paid', axis=0).sort_values(ascending=False)","d4062dff":"def scaler(X):\n    X = (X - X.mean()) \/ X.max()\n    return X\ncolumns = X.columns\nfor column in columns:\n    X.loc[:, column] = scaler(X[column].values)\nX","3c276c66":"new_columns = [\n    X.price * X.num_lectures, # pos\n    X.price * X.content_duration, # pos\n    X.num_lectures * X.content_duration, # pos\n    \n    X.num_subscribers * X.num_reviews, # neg\n    \n    X.price \/ X.num_subscribers,\n    X.num_subscribers \/ X.price,\n    X.num_lectures \/ X.num_subscribers,\n    X.num_subscribers \/ X.num_lectures,\n    X.content_duration \/ X.num_subscribers,\n    X.num_subscribers \/ X.content_duration,\n\n    X.price \/ X.num_reviews,\n    X.num_reviews \/ X.price,\n    X.num_lectures \/ X.num_reviews,\n    X.num_reviews \/ X.num_lectures,\n    X.content_duration \/ X.num_reviews,\n    X.num_reviews \/ X.content_duration\n]\nfor new_column in new_columns:\n    X = pd.DataFrame(np.concatenate([X, new_column.values.reshape(-1, 1)], axis=1)).astype(np.float)\nX","0772a6ed":"X.describe().iloc[:,15:]","4c372adb":"def scaler(X):\n    X = (X - X.mean()) \/ X.max()\n    return X\nindexes = list(range(15, 27))\nfor index in indexes:\n    X.iloc[:, index] = scaler(X.iloc[:, index].values)\nX","a472ed78":"fig, axs = plt.subplots(14, 2, figsize=(8, 45))\nk = 0\nfor i in range(13):\n    for j in range(2):\n        axs[i, j].scatter(X.iloc[:, i], range(X.shape[0]), label=k)\n        axs[i, j].legend()\n        k += 1\naxs[13, 0].scatter(X.iloc[:, 26], range(X.shape[0]), label=26)\naxs[i, j].legend()\nplt.show()","fea213d2":"from sklearn.decomposition import KernelPCA\npca = KernelPCA(n_components=round(X.shape[1]\/5), kernel='rbf')\npca.fit(X)\nX = np.concatenate([X, pca.transform(X)], axis=1)\nX","9ad87a29":"from sklearn.model_selection import train_test_split\nXtrain, Xvalid, ytrain, yvalid = train_test_split(X, y, test_size=.2, random_state=777)","53f92b43":"from xgboost import XGBClassifier\nmodel = XGBClassifier(n_estimators=1000)\nmodel.fit(Xtrain, ytrain.values.reshape(-1,))\nypred = model.predict(Xvalid)","8e64d0b6":"from sklearn.metrics import accuracy_score, confusion_matrix\naccuracy_score(ypred, yvalid), confusion_matrix(ypred, yvalid)","aed0b6fa":"from sklearn.model_selection import cross_val_score\ncross_val_score(estimator=XGBClassifier(n_estimators=1000), X=X, y=y, scoring='accuracy', cv=3, n_jobs=-1)","125dadef":"---","d132bd3f":"---","a8359440":"---","7c1d2b1a":"---","babf8779":"---","3132fae5":"---","c6c96137":"---","0ea93e87":"---","e52c3646":"---","7cbb4ed5":"---","c8dd1824":"---","05950d55":"---","39a809cd":"---","a12a3f16":"---","3a1f804b":"---"}}