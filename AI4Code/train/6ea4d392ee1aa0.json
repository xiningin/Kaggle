{"cell_type":{"c10a176d":"code","eab225ae":"code","eecee012":"code","d3ce105e":"code","346ea1f6":"code","6b267ea3":"code","e5c61ff9":"code","9c9282d3":"code","a9c8b81c":"code","6f4ce163":"code","0e0b741f":"code","c32af760":"code","e28ea60b":"code","f6880131":"code","d45dee75":"code","46af53ef":"code","3df149e3":"code","ae181b26":"code","5d8c2d1d":"code","ef7a5afc":"code","46011f03":"code","3c468739":"code","1aeeffa7":"code","d525f948":"code","9f08c572":"code","fcb738e8":"code","cfad0777":"code","db269e83":"code","0a98ed83":"code","ed41e34e":"code","6e3f317b":"code","e0b0072f":"code","217be833":"code","b9a7e940":"code","32b86e89":"code","b62a5896":"code","a1e4ae29":"markdown","33b9922f":"markdown","e82eb83e":"markdown","e9c3fee9":"markdown"},"source":{"c10a176d":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport string\nimport re","eab225ae":"%matplotlib inline","eecee012":"import nltk\nfrom nltk.corpus import stopwords","d3ce105e":"# nltk.download_shell()","346ea1f6":"train =pd.read_csv('..\/input\/nlp-getting-started\/train.csv')\ntest =pd.read_csv('..\/input\/nlp-getting-started\/test.csv')\nsample =pd.read_csv('..\/input\/nlp-getting-started\/sample_submission.csv')","6b267ea3":"sample.head()","e5c61ff9":"train.info()\ntest.info()\n# some locations and keywords are unknown","9c9282d3":"len(train['location'].unique())","a9c8b81c":"train['target'].unique()","6f4ce163":"sns.countplot(data=train,x='target') \n# labels are quite balanced","0e0b741f":"train['text'].head()","c32af760":"train['text'].describe()","e28ea60b":"train.groupby('target').describe()","f6880131":"httdata = train[train['text'].str.contains('http')]\nsns.countplot(httdata['target'])\n\n# no significant differences between tweets truth of tweets containing 'http'","d45dee75":"len(train['location'].unique())","46af53ef":"train['length'] = train['text'].apply(len)\ntrain.head()","3df149e3":"target_1 = train[train['target'] == 1.0]\ntarget_0 = train[train['target'] == 0.0]\n\nplt.figure(figsize=(10,6))\ntarget_0['length'].plot(kind='hist',title='False')\ntarget_1['length'].plot(kind='hist',title='True')\nplt.legend()\n\n# no significant difference in the distribution between length of false \n# and true tweets but there are more false tweets than true tweets","ae181b26":"# Text processing logic\nline = ' '.join(train['text'][0])\nno_punc = [char for char in line if char not in string.punctuation]\nno_punc = ''.join(no_punc)\nclean_mess = [word.lower() for word in no_punc.split() if word.lower() not in stopwords.words('english')]","5d8c2d1d":"def text_processing(df):\n    line = ''.join(df)\n    no_punc = [char for char in line if char not in string.punctuation]\n    no_punc = ''.join(no_punc)\n    clean_mess = [word.lower() for word in no_punc.split() if word.lower() not in stopwords.words('english')]\n    return clean_mess","ef7a5afc":"train['text_list'] = train['text'].apply(text_processing)","46011f03":"from sklearn.model_selection import train_test_split","3c468739":"X = train['text']\ny = train['target']","1aeeffa7":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)","d525f948":"from sklearn.naive_bayes import MultinomialNB","9f08c572":"from sklearn.pipeline import Pipeline","fcb738e8":"from sklearn.feature_extraction.text import CountVectorizer","cfad0777":"from sklearn.feature_extraction.text import TfidfTransformer","db269e83":"# ATTEMPT 1\n\npipeline = Pipeline([\n    ('bow',CountVectorizer(analyzer=text_processing)),\n    ('tfidf',TfidfTransformer()),\n    ('model',MultinomialNB())    \n]\n)","0a98ed83":"pipeline.fit(X_train,y_train)","ed41e34e":"pred = pipeline.predict(X_test)","6e3f317b":"from sklearn.metrics import confusion_matrix,classification_report","e0b0072f":"print(confusion_matrix(y_test,pred))","217be833":"print(classification_report(y_test,pred))","b9a7e940":"pred = pipeline.predict(test['text'])","32b86e89":"sample_submission = pd.DataFrame()\nsample_submission['id'] = test['id']\nsample_submission['target'] = pred","b62a5896":"sample_submission.to_csv(\"submission.csv\", index=False)","a1e4ae29":"# Preprocessing","33b9922f":"# Train Test Split","e82eb83e":"# Classification and Pipeline","e9c3fee9":"# Data Exploratory"}}