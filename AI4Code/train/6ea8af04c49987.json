{"cell_type":{"bb702fd0":"code","d6c91d1e":"code","de0e3d5b":"code","507dca9c":"code","1eeedbc4":"code","8f1e6511":"code","fda4bb8a":"code","92983299":"code","f1cd0f38":"code","13a46616":"code","6d4fcd8e":"code","65d0e718":"code","8d124841":"code","33c51e3a":"code","3af5ee86":"code","26e7eed9":"code","16c17e8a":"code","f1b3126e":"code","b8970a9f":"markdown","9132468a":"markdown","5d2328ff":"markdown","56d421e3":"markdown","d73b77c1":"markdown","5e1c1844":"markdown","5bb81c88":"markdown","34c0b95f":"markdown","e47afaf1":"markdown","c391a718":"markdown","33f83ff4":"markdown","d2406a79":"markdown","5a181bc8":"markdown","0a7543f1":"markdown","51afe41f":"markdown","7420e913":"markdown","205416da":"markdown"},"source":{"bb702fd0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom matplotlib import image as mp_image\n\n# Required magic to display matplotlib plots in notebooks\n%matplotlib inline\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","d6c91d1e":"# Set up the folder where the images are\nsrc_folder = '..\/input\/natural-images\/data\/natural_images'\n\n# Set up a figure of an appropriate size\nfig = plt.figure(figsize=(15, 30))\n\n# loop through the subfolders\nfor root, folders, filenames in os.walk(src_folder):\n    image_num = 0\n    num_folders = len(folders)\n    for folder in sorted(folders):\n        # Keep an incrementing count of each image\n        image_num +=1\n        # Find the first image file in the folder\n        file_name = os.listdir(os.path.join(root,folder))[0]\n        # Get the full path from the root folder\n        file_path = os.path.join(root,folder, file_name)\n        # Open the file using the matplotlib.image library\n        image = mp_image.imread(file_path)\n        # Add the image to the figure (which will have a row for each folder, each containing one column for the image)\n        a = fig.add_subplot(num_folders, 1, image_num)\n        # Add the image to the plot\n        image_plot = plt.imshow(image)\n        # Add a caption with the folder name\n        a.set_title(folder)\n        \n# Adjust vertical space\nfig.subplots_adjust(hspace=0.6)\n        \n# Show the plot\nplt.show()","de0e3d5b":"from PIL import Image\nimport skimage as sk\nfrom skimage import io as sk_io\nimport cv2\n\nimages = [] \n\n# We open the first image using PIL module PIL.Image.open()\npil_image = Image.open(os.path.join(src_folder, \"cat\", \"cat_0711.jpg\")) \nimages.append(pil_image)\n\n# We opend the second image using skimage module skimage_io() called as sk_io\nsk_image = sk_io.imread(os.path.join(src_folder, \"car\", \"car_0200.jpg\"))\nimages.append(sk_image)\n\n# We open the third image using OpenCV module cv2.imread()\ncv_image = cv2.imread(os.path.join(src_folder, \"dog\", \"dog_0673.jpg\"))\nimages.append(cv_image)\n\n# Set up a figure of an appropriate size\nfig = plt.figure(figsize=(12, 12))\n\nimage_num = 0\nnum_images = len(images)\n# loop through the images\nfor image_idx in range(num_images):\n    # Keep an incrementing count of each image\n    a=fig.add_subplot(1, num_images, image_idx+1)\n    # Add the image to the plot\n    image_plot = plt.imshow(images[image_idx])\n    # Add a caption with the folder name\n    a.set_title(\"Image \" + str(image_idx+1))\n        \n# Show the plot\nplt.show()\n\n\nprint('Notice that the three formats are different: ')\nprint(' Type PIL images: ', type(pil_image))\nprint(' Type skimage images: ', type(sk_image))\nprint(' Type OpenCV images: ', type(cv_image))\nprint('\\n')\n\nprint('Now we apply the np.array() module to the PIL image: ')\nprint('Type np.array(PIL) images: ', type(np.array(pil_image)))\nprint('\\n')\n\n\nprint('Now we apply the Image.fromarray() module to a cv ord sk image: ')\nprint('Type Image.fromarray(cv_image) images: ', type(Image.fromarray(cv_image)))\nprint('\\n')\n\nprint('Shape of a sk_image: ', sk_image.shape)\nprint('It is a RGB image. ')\nprint('\\n')\n\nprint('CV images looks funny? it is because has a different range color! change it to standard RGB: ')\ncv_image_rgb = cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB)\nplt.imshow(cv_image_rgb)\nplt.show()\n\nprint('We tranform a RGB image into a grey scale one: ')\nsk_gray_image = sk.color.rgb2gray(sk_image) # from rgb TO grey_scale\nplt.imshow(sk_gray_image, 'gray')\nplt.show()\nprint('The grey scale image shape is: ', sk_gray_image.shape)","507dca9c":"print('ROTATING IMAGES \\n')\n\nprint('Rotating image using PIL: ')\nrotated_pil_image = pil_image.rotate(90, expand=1) #rotate; the expand=1 is important to have the rotated image! look below\nplt.imshow(rotated_pil_image)\nplt.show()\n\nprint('Notice what happens without specifying the expand parameter: ')\nfrom skimage import transform as sk_transform\n\nrotated_pil_image = pil_image.rotate(90)\nplt.imshow(rotated_pil_image)\nplt.show()\n\nprint('Rotating image using skimage.transform.rotate: ')\nrotated_sk_image = sk_transform.rotate(sk_image, 90, resize=True) # gives the same as PIL Image .rotate(\u00b0, expand=1)\nplt.imshow(rotated_sk_image)\nplt.show()\n\n\nprint('FLIPPING IMAGES \\n')\n\nprint('We simply have to use numpy')\n\nimport numpy as np #we use the np.flip() method \n\nupended_cv_image_rgb = np.flip(cv_image_rgb, axis=0) #w.r.t. x axis\n    # recall that \n    # cv_image_rgb = cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB) \n    # so it is a cv2 object whose type is a multidimensional np array!\nmirrored_cv_image_rgb = np.flip(cv_image_rgb, axis=1) #w.r.t. y axis\n\nfig = plt.figure(figsize=(12, 12))\n\n# Plot original image\na=fig.add_subplot(1, 3, 1)\nimage_plot_1 = plt.imshow(cv_image_rgb)\na.set_title(\"Original\")\n\n# Plot upended image\na=fig.add_subplot(1, 3, 2)\nimage_plot_2 = plt.imshow(upended_cv_image_rgb)\na.set_title(\"Flipped Vertically\")\n\n# Plot mirrored image\na=fig.add_subplot(1, 3, 3)\nimage_plot_3 = plt.imshow(mirrored_cv_image_rgb)\na.set_title(\"Flipped Horizontally\")\n\nplt.show()","1eeedbc4":"print('THUMBNAIL \\n')\nfrom PIL import Image, ImageOps\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\n# Get the PIL image size\no_h, o_w = pil_image.size #gives the Height and the Width\nprint('Original size:', o_h, 'x', o_w)\n\n# We'll resize this so it's 150 pixels on its widest dimensions\ntarget_size = (150,150)\nresized_img = pil_image.copy() # We create a copy because the .thumbnail() method is INPLACE = TRUE ALWAYS!\nresized_img.thumbnail(target_size, Image.ANTIALIAS) #we call the thumbnail method with the resample = Image.ANTIALIAS \nn_h, n_w = resized_img.size\nprint('New size:', n_h, 'x', n_w)\n\n# Show the original and resized images\n# Create a figure\nfig = plt.figure(figsize=(12, 12))\n\n# Subplot for original image\na=fig.add_subplot(1,2,1)\nimgplot = plt.imshow(pil_image)\na.set_title('Before')\n\n# Subplot for resized image\na=fig.add_subplot(1,2,2)\nimgplot = plt.imshow(resized_img)\na.set_title('After')\n\nplt.show()\n\nprint('RESIZE \\n')\n# Get the image size\no_h, o_w = pil_image.size\nprint('Original size:', o_h, 'x', o_w)\n\n# We'll resize this so it's 150 x 150\n    # We'll change the SHAPE\ntarget_size = (150,150)\nnew_img = pil_image.resize(target_size) # here we call the .resize() method!!!\nn_h, n_w = new_img.size\nprint('New size:', n_h, 'x', n_w)\n\n# Show the original and resized images\n# Create a figure\nfig = plt.figure(figsize=(12, 12))\n\n# Subplot for original image\na=fig.add_subplot(1,2,1)\nimgplot = plt.imshow(pil_image)\na.set_title('Before')\n\n# Subplot for resized image\na=fig.add_subplot(1,2,2)\nimgplot = plt.imshow(new_img)\na.set_title('After')\n\nplt.show()\n\n","8f1e6511":"print('DEFINING THE resize_image FUNCTION \\n')\n\ndef resize_image(src_image, size=(200,200), bg_color=\"white\"): # the 2\u00b0 and 3\u00b0 entries are setted by default, so they can be either called or not.\n    ;\n    from PIL import Image, ImageOps \n    \n    # resize the image so the longest dimension matches our target size\n    src_image.thumbnail(size, Image.ANTIALIAS)\n    \n    # Create a new square background image\n    new_image = Image.new(\"RGB\", size, bg_color)\n    \n    # Paste the resized image into the center of the square background\n    new_image.paste(src_image, (int((size[0] - src_image.size[0]) \/ 2), int((size[1] - src_image.size[1]) \/ 2)))\n  \n    # return the resized image\n    return new_image","fda4bb8a":"print('USING THE resize_image FUNCTION \\n')\n\n# Get the image size\no_h, o_w = pil_image.size\nprint('Original size:', o_h, 'x', o_w)\n\n# We'll resize this so it's 150 x 150 with black padding\ntarget_size = (150,150)\npad_color = \"black\"\nresized_img = resize_image(pil_image.copy(), target_size, pad_color)\nn_h, n_w = resized_img.size\nprint('New size:', n_h, 'x', n_w)\n\n# Show the original and resized images\n# Create a figure\nfig = plt.figure(figsize=(12, 12))\n\n# Subplot for original image\na=fig.add_subplot(1,2,1)\nimgplot = plt.imshow(pil_image)\na.set_title('Before')\n\n# Subplot for resized image\na=fig.add_subplot(1,2,2)\nimgplot = plt.imshow(resized_img)\na.set_title('After')\n\nplt.show()","92983299":"print('Create a folder into which save the images: ')\n\nimport os, shutil\n\nimage_folder = \"my_images\"\n\n# Delete the folder if it already exists\nif os.path.exists(image_folder):\n    shutil.rmtree(image_folder)\n\n# Create the folder\nos.makedirs(image_folder)\nprint(\"Ready to save images in\", image_folder)\n\n\nprint('Saving with PIL')\nfile_name = \"resized_PIL_img.jpg\"\nfile_path = os.path.join(image_folder, file_name)\n\n# Save the image\nresized_img.save(file_path, format=\"JPEG\") # PIL has the .save() method\nprint(\"Image saved as\", file_path)\n\n\nprint('Saving with Scikit-learn.Image')\nfile_name = \"sk_image.jpg\"\nfile_path = os.path.join(image_folder, file_name)\n\n# Save the image\nsk_io.imsave(fname=file_path, arr=rotated_sk_image)\nprint(\"Image saved as\", file_path) \n\n\nprint('Saving with OpenCV')\nfile_name = \"cv_image.jpg\"\nfile_path = os.path.join(image_folder, file_name)\n\n# Save the image\ncv2.imwrite(filename=file_path, img=mirrored_cv_image_rgb)\nprint(\"Image saved as\", file_path)","f1cd0f38":"print('Importing a test image')\n\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import image as mp_image\n\n# Required magic to display matplotlib plots in notebooks\n%matplotlib inline\n\n# Load the image from the source file\n#image_file = \"..\/input\/natural-images\/data\/natural_images\/airplane\/airplane_0404.jpg\"\nimage_file = \"..\/input\/natural-images\/data\/natural_images\/airplane\/airplane_0019.jpg\"\n\nimage = mp_image.imread(image_file)\n\n# Display it\nplt.imshow(image)\nplt.show()\n\nprint('The histrogram distribution of the image: ')\n# Plot a histogram - we need to use ravel to \"flatten\" the 3 dimensions\nplt.hist(image.ravel()) # .ravel() : Return a flattened array.\nplt.show()\n\nprint('The cdf of the image: ')\nplt.hist(image.ravel(), bins=255, cumulative=True) # Cumulants\nplt.show()\n\n\n\nprint('Using skimage to Normalize the image')\nfrom skimage import exposure # exposure has .rescale_intensity() and .equalize_hist()\nimport numpy as np\n\n# Contrast stretching\np2 = np.percentile(image, 2) #np.percentile() : Compute the q-th percentile of the data along the specified axis.\np98 = np.percentile(image, 98)\nimage_ct = exposure.rescale_intensity(image, in_range=(p2, p98)) \n    # exposure.rescale_intensity() : Return image after stretching or shrinking its intensity levels. \n\n# Histogram Equalization\nimage_eq = exposure.equalize_hist(image) \n    #exposure.equalize_hist() : Return image after histogram equalization.\n\n\n# Show the images\nfig = plt.figure(figsize=(20, 12))\n\n# Subplot for original image\na=fig.add_subplot(3,3,1)\nimgplot = plt.imshow(image)\na.set_title('Original')\n\n# Subplot for contrast stretched image\na=fig.add_subplot(3,3,2)\nimgplot = plt.imshow(image_ct)\na.set_title('Contrast Stretched')\n\n# Subplot for equalized image\na=fig.add_subplot(3,3,3)\nimgplot = plt.imshow(image_eq)\na.set_title('Histogram Equalized')\n\n# Subplots for histograms\na=fig.add_subplot(3,3,4)\nimgplot = plt.hist(image.ravel())\n\na=fig.add_subplot(3,3,5)\nimgplot = plt.hist(image_ct.ravel())\n\na=fig.add_subplot(3,3,6)\nimgplot = plt.hist(image_eq.ravel())\n\n# Subplots for CDFs\n\na=fig.add_subplot(3,3,7)\nimgplot = plt.hist(image.ravel(), bins=255, cumulative=True)\n\na=fig.add_subplot(3,3,8)\nimgplot = plt.hist(image_ct.ravel(), bins=255, cumulative=True)\n\na=fig.add_subplot(3,3,9)\nimgplot = plt.hist(image_eq.ravel(), bins=255, cumulative=True)\n\nplt.show()","13a46616":"import os\nimport matplotlib.pyplot as plt\nfrom PIL import Image, ImageFilter # PIL.ImageFilter for filters\n\n# Required magic to display matplotlib plots in notebooks\n%matplotlib inline\n\n# Load the image from the source file\n#image_file = \"..\/input\/natural-images\/data\/natural_images\/airplane\/airplane_0404.jpg\"\nimage_file = \"..\/input\/natural-images\/data\/natural_images\/airplane\/airplane_0019.jpg\"\n\nimage = Image.open(image_file)\n\nblurred_image = image.filter(ImageFilter.BLUR) \n    # image.filter(ImageFilter.BLUR)  : Filters this image using the given filter:\n        # BLUR, CONTOUR, DETAIL, EDGE_ENHANCE, EDGE_ENHANCE_MORE, EMBOSS, FIND_EDGES, SHARPEN, SMOOTH, SMOOTH_MORE\nsharpened_image = image.filter(ImageFilter.SHARPEN)\n\n# I add it\nedged_image = image.filter(ImageFilter.FIND_EDGES)\n\n# Display it\nfig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(nrows=2, ncols=2, figsize=(16, 12))\n#fig = plt.figure(figsize=(16, 12))\nfig.tight_layout()\n\n                                          \n# Plot original image\nax1.imshow(image)\nax1.set_title(\"Original\")\n\n# Plot blurred image\nax2.imshow(blurred_image)\nax2.set_title(\"Blurred\")\n\n# Plot sharpened image\nax3.imshow(sharpened_image)\nax3.set_title(\"Sharpened\")\n\n# Plot FIND_EDGES image\nedged_image = image.filter(ImageFilter.FIND_EDGES)\nax4.imshow(edged_image)\nax4.set_title(\"FIND_EDGES\")\n\n\nplt.show()","6d4fcd8e":"#recall that\n# Load the image from the source file\n#image_file = \"..\/data\/voc\/plane\/002279.jpg\"\n#image = Image.open(image_file)\n\n\n            \n# Let me define it!\nale_kernel = (-200, 50, +100,\n             -50, 0, -50,\n            +100, 50, -200)\n\nfiltered_image_ale = image.filter(ImageFilter.Kernel((3,3), ale_kernel)) \n    # image.filter(filter) ; we set our kernel via ImageFilter.Kernel\n        # ImageFilter.Kernel(size, kernel, scale=None, offset=0) \n            # the size of the Kernel is a 3x3 matrix, that is my_kernel.             \n            \n# Display it\nfig = plt.figure(figsize=(16, 12))\n\n# Plot original image\na=fig.add_subplot(1, 2, 1)\nimage_plot_1 = plt.imshow(image)\na.set_title(\"Original\")\n\n# Plot Custom image\na=fig.add_subplot(1, 2, 2)\nimage_plot_2 = plt.imshow(filtered_image_ale)\na.set_title(\"Custom Filter\")\n\nplt.show()","65d0e718":"# I now try to do my sobel\ndef ale_sobel(img, threshold = 70):\n    import skimage.color as sc\n    import numpy as np\n    \n    image = 255*sc.rgb2gray(img) # Convert color image to gray scale\n    len_x = image.shape[0]\n    len_y = image.shape[1]\n    \n    Gx = np.array([[+1, +2, +1], [0,0,0], [-1,-2,-1]])\n    Gy = np.array([[-1,0,+1],[-2,0,+2],[-1,0,+1]])\n    \n    mag = np.zeros((len_x, len_y))\n    ano=0\n    \n    for i in np.arange(1, len_x-1):\n        for j in np.arange(1, len_y-1):\n            S1=0;\n            S2=0;\n            for n in np.arange(-1,2):\n                for m in np.arange(-1,2):\n                    S1+= Gx[n,m]*image[i+n,j+m]\n                    S2+= Gy[n,m]*image[i+n,j+m]\n                    #print(np.sqrt(S1**2 + S2**2))\n\n            ano=max(np.around(np.sqrt(S1**2 + S2**2), 0), threshold)\n            \n            if (ano>255):\n                mag[i,j] = 255\n            elif (ano<0):\n                mag[i,j] = 0\n            else :\n                mag[i,j] = ano\n    \n    # Normalize the image\n    mag = mag.astype(np.uint8)\n    return mag\n\n# importing the image\nimage_file = \"..\/input\/natural-images\/data\/natural_images\/airplane\/airplane_0019.jpg\"\nimage = Image.open(image_file)\n\nale_sobel_img=ale_sobel(np.array(image))\n\n# Display it\nfig = plt.figure(figsize=(16, 12))\n\n# Plot original image\na=fig.add_subplot(1, 2, 1)\nimage_plot_1 = plt.imshow(image)\na.set_title(\"Original\")\n\n# Plot image after Sobel algorithm\na=fig.add_subplot(1, 2, 2)\nimage_plot_2 = plt.imshow(ale_sobel_img, cmap=\"gray\")\na.set_title(\"Sobel Edge Detection\")\nplt.show()","8d124841":"def edge_sobel(image):\n    from scipy import ndimage # it has .sobel() method;\n        # ndimage.sobel(image, index) where index = 0 or 1, i.e. Horizontal or Vertical!\n    import skimage.color as sc\n    import numpy as np\n    image = sc.rgb2gray(image) # Convert color image to gray scale\n    dx = ndimage.sobel(image, 1)  # horizontal derivative\n    dy = ndimage.sobel(image, 0)  # vertical derivative\n    mag = np.hypot(dx, dy)  # magnitude\n    mag *= 255.0 \/ np.amax(mag)  # normalize (Q&D)\n    mag = mag.astype(np.uint8)\n    return mag\n\n\n\n# importing the image\nimage_file = \"..\/input\/natural-images\/data\/natural_images\/airplane\/airplane_0019.jpg\"\nimage = Image.open(image_file)\n\n# Apply the sobel function\nsobel_image = edge_sobel(np.array(image))\n\n# Display it\nfig = plt.figure(figsize=(16, 12))\n\n# Plot original image\na=fig.add_subplot(1, 2, 1)\nimage_plot_1 = plt.imshow(image)\na.set_title(\"Original\")\n\n# Plot Sobel image\na=fig.add_subplot(1, 2, 2)\nimage_plot_2 = plt.imshow(sobel_image, cmap=\"gray\") # Need to use a gray color map as we converted this to a grayscale image\na.set_title(\"Sobel\")\n\nplt.show()","33c51e3a":"import os\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom skimage import io as sk_io, color as sk_col, morphology as sk_mm\nfrom skimage.filters import threshold_mean #needed for thresholding\n\n%matplotlib inline\n\n# Load the image from the source file\nimage_file = \"..\/input\/natural-images\/data\/natural_images\/airplane\/airplane_0019.jpg\"\nimage = sk_io.imread(image_file)\n\n# Convert to grayscale so we only have one channel\nbw_image = sk_col.rgb2gray(image)\n\n# Find the mean threshold value\nmean_val = threshold_mean(bw_image)\n\n# Threshold the image\nbinary_image = bw_image > mean_val # easy-peasy lemon squeezy\n\n# Plot the thresholded image\nfig = plt.figure(figsize=(5,5))\nplt.imshow(binary_image, cmap=\"gray\")\nplt.title(\"Mean Threshold: \" + str(mean_val))\nplt.show()","3af5ee86":"from skimage.filters import try_all_threshold\n\n# Load the image  \n#image_file = \"..\/input\/natural-images\/data\/natural_images\/airplane\/airplane_0404.jpg\"\nimage_file = \"..\/input\/natural-images\/data\/natural_images\/fruit\/fruit_0686.jpg\"\nimage = sk_io.imread(image_file)\n\n# Convert to grayscale so we only have one channel\nbw_image = sk_col.rgb2gray(image)\n\nfig, ax = try_all_threshold(bw_image, figsize=(10, 10), verbose=False)\nplt.show()","26e7eed9":"print('Basic Image')\n\nimport numpy as np\nfrom skimage import morphology as sk_mm\nfrom matplotlib import pyplot as plt\n\n# Required magic to display matplotlib plots in notebooks\n%matplotlib inline\n\n\nsquare = np.array([[0, 0, 0, 0, 0],\n                   [0, 1, 1, 1, 0],\n                   [0, 1, 1, 1, 0],\n                   [0, 1, 1, 1, 0],\n                   [0, 0, 0, 0, 0]], dtype=np.uint8)\n\n\n# Display it\nfig = plt.figure(figsize=(3,3))\nplt.imshow(square, cmap=\"binary\")\nplt.show()\n\nprint('Structuring Element')\nstruct_element = sk_mm.selem.diamond(1) #from skimage import morphology as sk_mm <---\n    #sk_mm.selem.diamond(radius, dtype=<class 'numpy.uint8'>) : Generates a flat, diamond-shaped structuring element.\n\nprint(struct_element)\n\n# Display it\nfig = plt.figure(figsize=(1,1))\nplt.imshow(struct_element, cmap=\"binary\")\nplt.show()\n\n\nprint('Applying EROSION')\n# Apply erosion\neroded_square = sk_mm.erosion(square, struct_element)\n    #sk_mm.erosion(image, selem=None, out=None, shift_x=False, shift_y=False) : Return greyscale morphological erosion of an image.\n\n\nfig = plt.figure(figsize=(6, 6))\n# Plot original image\na=fig.add_subplot(1, 3, 1)\nplt.imshow(square, cmap=\"binary\")\na.set_title(\"Original\")\n\n# Plot structuring Element\na=fig.add_subplot(1, 3, 2)\nimage_plot_1 = plt.imshow(struct_element, cmap=\"binary\")\na.set_title(\"Structuring element\")\n\n# Plot eroded image\na=fig.add_subplot(1, 3, 3)\nplt.imshow(eroded_square, cmap=\"binary\")\na.set_title(\"Eroded\")\n\nplt.show()\n\n\nprint('Applying DILATION')\n#Apply dilation\ndilated_square = sk_mm.dilation(square, struct_element)\n    #sk_mm.dilation(image, selem=None, out=None, shift_x=False, shift_y=False) : Return greyscale morphological dilation of an image.\n\n\n# Display it\nfig = plt.figure(figsize=(6, 6))\n\n# Plot original image\na=fig.add_subplot(1, 3, 1)\nplt.imshow(square, cmap=\"binary\")\na.set_title(\"Original\")\n\n# Plot structuring Element\na=fig.add_subplot(1, 3, 2)\nimage_plot_1 = plt.imshow(struct_element, cmap=\"binary\")\na.set_title(\"Structuring element\")\n\n# Plot dilated image\na=fig.add_subplot(1, 3, 3)\nplt.imshow(dilated_square, cmap=\"binary\")\na.set_title(\"Dilated\")\n\nplt.show()\n\n\n\nprint('Applying OPENING')\n\n#\neroded_square = sk_mm.erosion(square, struct_element)\nopened_square = sk_mm.dilation(eroded_square, struct_element)\n\n# Display it\nfig = plt.figure(figsize=(6, 6))\n\n# Plot original image\na=fig.add_subplot(1, 3, 1)\nimage_plot_1 = plt.imshow(square, cmap=\"binary\")\na.set_title(\"Original\")\n\n# Plot structuring Element\na=fig.add_subplot(1, 3, 2)\nimage_plot_1 = plt.imshow(struct_element, cmap=\"binary\")\na.set_title(\"Structuring element\")\n\n# Plot opened image\na=fig.add_subplot(1, 3, 3)\nimage_plot_2 = plt.imshow(opened_square, cmap=\"binary\")\na.set_title(\"Opened\")\n\nplt.show()\n\n\nprint('Applying CLOSING')\ndilated_square = sk_mm.dilation(square, struct_element)\nclosed_square = sk_mm.erosion(dilated_square, struct_element)\n\nfig = plt.figure(figsize=(6, 6))\n\n# Plot original image\na=fig.add_subplot(1, 3, 1)\nimage_plot_1 = plt.imshow(square, cmap=\"binary\")\na.set_title(\"Original\")\n\n# Plot structuring Element\na=fig.add_subplot(1, 3, 2)\nimage_plot_1 = plt.imshow(struct_element, cmap=\"binary\")\na.set_title(\"Structuring element\")\n\n# Plot closed image\na=fig.add_subplot(1, 3, 3)\nimage_plot_2 = plt.imshow(closed_square, cmap=\"binary\")\na.set_title(\"Closed\")\n\nplt.show()","16c17e8a":"import os\nfrom skimage import io as sk_io\nimport skimage.color as sk_col\n\n# Load the image  \n#image_file = \"..\/input\/natural-images\/data\/natural_images\/airplane\/airplane_0404.jpg\"\nimage_file = \"..\/input\/natural-images\/data\/natural_images\/fruit\/fruit_0686.jpg\"\n\n\nimage = sk_io.imread(image_file)\n\n\n\n# Convert to grayscale so we only have one channel\nbw_image = sk_col.rgb2gray(image)\n\n# Apply operations\neroded_image = sk_mm.erosion(bw_image)\ndilated_image = sk_mm.dilation(bw_image)\nclosed_image = sk_mm.closing(bw_image)\nopened_image = sk_mm.opening(bw_image)\n\n# Display it\nfig = plt.figure(figsize=(20,20))\n\n# Plot original image\na=fig.add_subplot(5, 1, 1)\nplt.imshow(bw_image, cmap=\"gray\")\na.set_title(\"Original\")\n\n# Plot eroded image\na=fig.add_subplot(5, 1, 2)\nplt.imshow(eroded_image, cmap=\"gray\")\na.set_title(\"Eroded\")\n\n# Plot dilated image\na=fig.add_subplot(5, 1, 3)\nplt.imshow(dilated_image, cmap=\"gray\")\na.set_title(\"Dilated\")\n\n# Plot closed image\na=fig.add_subplot(5, 1, 4)\nplt.imshow(closed_image, cmap=\"gray\")\na.set_title(\"Closed\")\n\n# Plot opened image\na=fig.add_subplot(5, 1, 5)\nplt.imshow(opened_image, cmap=\"gray\")\na.set_title(\"Opened\")\n\nplt.show()","f1b3126e":"from skimage import io as sk_io\nfrom skimage.filters import threshold_otsu\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\n# Load the image from the source file\n#planes_image_file = \"..\/input\/natural-images\/data\/natural_images\/airplane\/airplane_0596.jpg\"\n#image_file = \"..\/input\/two-cars\/two_cars.jpg\" #fruit_0984 # fruit_0686\nimage_file = \"..\/input\/two-airplanes1\/two_airplanes1.jpg\"\n\ncars_image = sk_io.imread(image_file)\n\nprint('Original Image')\nfig = plt.figure(figsize=(6,6))\nplt.imshow(cars_image)\nplt.show()\n\n# Convert to grayscale so we only have one channel\nfrom skimage import color as sk_col\nprint('Grey scale image')\nbw_planes = sk_col.rgb2gray(cars_image)\n\nfig = plt.figure(figsize=(6,6))\nplt.imshow(bw_planes, cmap=\"gray\")\nplt.show()\n\nprint('Step 1: thresholding')\nfrom skimage.filters import threshold_otsu\n\n\n\n\nplanes_otsu = threshold_otsu(bw_planes) # Otsu thresholding\nthresh_planes = bw_planes > planes_otsu\n\n# Convert the thresholded image to its inverse\ninverse_thresh = np.invert(thresh_planes)\n\nfig = plt.figure(figsize=(6,6))\nplt.imshow(inverse_thresh, \"gray\")\nplt.show()\n\nprint('Step 2: Use opening and dilation to find the background')\nfrom skimage import morphology as sk_mm\n\n# Use opening and dilation to find the background\nkernel = sk_mm.selem.square(3)\nopened_thresh = sk_mm.opening(inverse_thresh, kernel)\nbackground = sk_mm.dilation(opened_thresh, kernel)\n\nfig = plt.figure(figsize=(6,6))\nplt.imshow(background,cmap=\"gray\", interpolation='nearest')\nplt.show()\n\n\nprint('Step 3: finding foreground')\nfrom scipy import ndimage as ndi\nfrom skimage.filters import threshold_minimum\n\ndistance = ndi.distance_transform_edt(opened_thresh)\n    #ndi.distance_transform_edt(input, sampling=None, return_distances=True, return_indices=False, distances=None, indices=None):\n        # Exact euclidean distance transform.\n\n\nforeground_threshold = threshold_otsu(distance) # Return threshold value based on Otsu's method.\nforeground = distance > foreground_threshold\nforeground = np.uint8(foreground)\n\nunknown = background - foreground\n\nfig = plt.figure(figsize=(16,16))\n\na=fig.add_subplot(1, 3, 1)\nplt.imshow(distance, cmap=\"gray\")\na.set_title(\"Distances\")\n\n# Plot eroded image\na=fig.add_subplot(1, 3, 2)\nplt.imshow(foreground, cmap=\"gray\")\na.set_title(\"Foreground\")\n\n# Plot eroded image\na=fig.add_subplot(1, 3, 3)\nplt.imshow(unknown, cmap=\"gray\")\na.set_title(\"Unknown\")\n\nplt.show()\n\n\nprint('Step 4: defining markers')\nfrom skimage.feature import peak_local_max\n\nlocal_maxi = peak_local_max(foreground, indices=False, footprint=np.ones((3, 3)), labels=inverse_thresh)\n    # Find peaks in an image as coordinate list or boolean mask.\nmarkers = ndi.label(local_maxi)[0]\n    #Label features in an array.\n\nfig = plt.figure(figsize=(6,6))\nplt.imshow(markers, \"gray\")\nplt.show()\n\nprint('Step 5: watersheding')\nfrom skimage.morphology import watershed\n\n# Apply watershed\nlabels = watershed(inverse_thresh, markers) \n    # Find watershed basins in `image` flooded from given `markers`.\n\n# Invert the image back so the background is white\ninverted_labels = np.invert(labels)\n\nfig = plt.figure(figsize=(6,6))\nplt.imshow(inverted_labels, \"gray\")\nplt.show()","b8970a9f":"It is possible to use **scipy.ndimag.sobel()** method to apply the Sobel algorithm to images:","9132468a":"# Thresholding\n\nThe simplest thresholding methods replace each pixel in an image with a black pixel if the image intensity $I_{i,j}$ is less than some fixed constant $T$ (that is, $I_{{i,j}}<T$), or a white pixel if the image intensity is greater than that constant [1].\n\n### Implementing Threshiolding in Python\n\nWe will implement thresholding using the **skimage.filters** module of Scikit-learn [2]. \n\n-------\n[1] https:\/\/en.wikipedia.org\/wiki\/Thresholding_(image_processing)\n\n[2] https:\/\/scikit-image.org\/docs\/dev\/auto_examples\/segmentation\/plot_thresholding.html","5d2328ff":"# Normalization and Filters\n\n## Normalization\n\nFrom wikipedia [1]: \n> In image processing, normalization is a process that changes the range of pixel intensity values. Applications include photographs with poor contrast due to glare, for example. Normalization is sometimes called contrast stretching or histogram stretching. In more general fields of data processing, such as digital signal processing, it is referred to as dynamic range expansion. \nThe purpose of dynamic range expansion in the various applications is usually to bring the image, or other type of signal, into a range that is more familiar or normal to the senses, hence the term normalization. Often, the motivation is to achieve consistency in dynamic range for a set of data, signals, or images to avoid mental distraction or fatigue. For example, a newspaper will strive to make all of the images in an issue share a similar range of grayscale.\n\n* A particular used normalization function is called **Histogram normalization** [2]. While the standard normalization stretches the [cumulative distribution function](https:\/\/en.wikipedia.org\/wiki\/Cumulative_distribution_function) **cdf**, the Histrogram normalization makes it (almost) an exact line, since the goal of Histogram normalization is to make the histogram of the distribution of pixel values *flat*.  \n\n--------\n[1] https:\/\/en.wikipedia.org\/wiki\/Normalization_(image_processing)\n\n[2] https:\/\/en.wikipedia.org\/wiki\/Histogram_equalization","56d421e3":"# Image pre-treatment\n\nWe show here how to deal with images in Python, how to import\/read them, how to manipulate them using **normalization and filters** or **morphology and segmentation**. \n\nWe will employ techniques as \n1. **Manipulation**:\n    * Rotation\n    * Flip\n    * Resizing\n    * Exporting images\n2. **Image Normalization**:\n    * Contrast stretching\n    * Histogram Equalization\n3. **Filters**:\n    * Blurring\n    * Sharpening\n    * Edge detection: **Sobel algorithm**\n4. **Mathematical Morphology**:\n    * Erosion\n    * Dilation\n    * Closing\n    * Opening\n    * Thresholding\n    * Watershed segmentation\n    \n## About the dataset\n\nWe will use the dataset **Natural Images - A compiled dataset of 6899 images from 8 distinct classes** by *[Prasun Roy](https:\/\/www.kaggle.com\/prasunroy)*, available on kaggle at:\nhttps:\/\/www.kaggle.com\/prasunroy\/natural-images\n","d73b77c1":"# Importing Images","5e1c1844":"In addition to the Matplotlib library, there are other common libraries for working with images:\n- [**PIL**](https:\/\/pillow.readthedocs.io\/en\/stable\/) (based on the **Pillow** fork)\n- [**OpenCV**](https:\/\/opencv.org\/)\n- [**Scikit-Image**](https:\/\/scikit-image.org\/)\n\nWe now import the three modules and open an image with each of the three in order to see the differences.\n\nThe main difference are:\n1. Both OpenCV, Scikit-Image and Matplotlib imports images as Numpy array of the form *(Height, Width, Number of colors)*, i.e. a RGB 500x300 images is a np.array with shape (300, 500, 3).\n2. The PIL package has is own type: 'PIL.JpegImagePlugin.JpegImageFile'. To change it to  a np.array() matrix simpy apply np.array() to the PIL image; the viceversa may be extremy useful and it is done via the **Image.fromarray()** PIL module\n3. OpenCV import [images in a different defualt format (the BGR format)](https:\/\/www.learnopencv.com\/why-does-opencv-use-bgr-color-format\/), so you usually want to change it to a standard RGB via the module **cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB)**\n\nWe may convert a RGB image (H,W, 3) into a grey-scale (H, W) image via the **sk.color.rgb2gray** module of scikit-learn.","5bb81c88":"### Matematical Morphology on real images","34c0b95f":"## Filters\n\nFilters are implemented by defining numeric grids, called *kernels* [1] that are *convolved* across an image to change the value of the pixel in the middle of the grid by calculating a weighted sum of the surrounding pixels, using the values in the kernel as weights. Recall that [1]\n> In image processing, a kernel, convolution matrix, or mask is a small matrix. It is used for blurring, sharpening, embossing, edge detection, and more. This is accomplished by doing a convolution between a kernel and an image.\n\nand \n\n> Convolution is the process of adding each element of the image to its local neighbors, weighted by the kernel. This is related to a form of mathematical convolution. The matrix operation being performed\u2014convolution\u2014is not traditional matrix multiplication, despite being similarly denoted by \"*\".\n\nIn practice they are used to apply visual enhancement effects to the image; such as *sharpening*, *blurring*, and so on. This can often be used to remove \"noise\" from an image, such as is common in photgraphs taken in low-light conditions.\n\nThe particular Kernels required for the various operations such as *edge detection*, *blurring*, etc. can be found in [1].\n\n-------\n[1] https:\/\/en.wikipedia.org\/wiki\/Kernel_(image_processing)\n","e47afaf1":"# Manipulating Images: basics\n\nWe now see how to easily flip, rotate, resize images. ","c391a718":"## Saving Images\n\n#### PIL\nTo save a PIL image, use the **save** method of the PIL image object;\n\n#### Scikit-learn\nThe **io** namespace in the **Scikit-image** library has an **imsave** method;\n\n#### OpenCV\nThe OpenCV library has an **imwrite** method;\n\n#### Matplotlib\nThe **matplotlib.pyplot** library has an **imsave** method;","33f83ff4":"Actually, PIL.Image let you custom your kernel: let us see an example below:","d2406a79":"# Mathematical Morphology\n\nThe **Mathematical Morphology (MM)** is a technique for the analysis and processing of geometrical structures. The basic morphological operators are **erosion, dilation, opening and closing**.\n\nThe basic idea in binary morphology is to probe an image with a simple, pre-defined shape, drawing conclusions on how this shape fits or misses the shapes in the image. This simple \"probe\" is called the **structuring element**, and is itself a binary image (i.e., a subset of the space or grid).\n\n\n\n1. **Erosion**: \n\nErosion has the effect of removing pixels at the edges of shapes in the image. The structuring element only retains center pixels where *all* of the values in the area of the image beneath the structuring element match the corresponding pixels in the structuring element itself (in other words, it performs a logical AND operation) to set the target pixel.\n\nLet $E$ be an euclidean space and $A$ a binary image in $E$. Mathematically speaking, the **erosion** of the binary image $A$ by the structuring element $B$ is defined by\n$$A\\ominus B = \\{ z\\in E \\,|\\, B_z \\subseteq A\\}$$\nwhere $B_z$ is the translation of $B$ by the vector $z$, i.e.\n$$B_z = \\{ b+z \\,|\\, b\\in B\\}, \\quad \\forall z \\in E.$$\n\nWhen the structuring element $B$ has a center (e.g., $B$ is a disk or a square), and this center is located on the origin of $E$, then the erosion of $A$ by $B$ can be understood as the locus of points reached by the center of $B$ when $B$ moves inside $A$.\n\nThe erosion of $A$ by $B$ is also given by\n$$A\\ominus B = \\bigcap_{b\\in B} A_{-b} \\, .$$\n\n\n2. **Dilation**\n\nDilation has the effect of adding pixels at the edges of shapes in the image. The structuring element only retains center pixels where *any* of the values in the area of the image beneath the structuring element match the corresponding pixels in the structuring element itself (in other words, it performs a logical OR operation) to set the target pixel.\n\nMathematically, the **dilation** of $A$ by the structuring element $B$ is defined by\n$$A \\oplus B = \\bigcup_{b\\in B} A_b \\,. $$\n\n3. **Opening**\n\nThe **opening** of $A$ by $B$ is obtained by the Erosion of $A$ by $B$, followed by a Dilation of the resulting image again by $B$:\n$$A \\circ B = (A \\ominus B) \\oplus B\\,.$$\nEquivalently, \n$$A \\circ B = \\bigcup_{B_x \\subseteq A} B_x \\,,$$\nthat is the locus of translations of the structuring element $B$ inside the image $A$. \n\n\n4. **Closing**\n\nThe **closing** of $A$ by $B$ is obtained by the Dilation of $A$ by $B$, followed by a Erosion of the resulting image again by $B$:\n$$A \\bullet B = (A \\oplus B)\\ominus B \\,.$$\n\n\n\n\n\n### Implementing the code in Python\n\nTo implement the code in Python, we will use the module **skimage.morphology** [2].\n\n------\n[1] https:\/\/en.wikipedia.org\/wiki\/Mathematical_morphology\n\n[2] https:\/\/scikit-image.org\/docs\/dev\/api\/skimage.morphology.html","5a181bc8":"## Rotating and Flipping images\n\nTo rotate image we may use\n1. The **.rotate** module of a PIL image; \n      * The **expand** parameter tells PIL to change the image dimenions to fit the rotated orientation. Without this, we'd get an image with the original dimensions with a resized, rotated version of the image and the space that was created filled in, like this:\n2. The **sklearn.transform.rotate** module\n\nTo flip the image we can use directly the fact that an image is a np.array() so we may easily use the **np.flip(, axis=)** to flip along the indicated axis.  ","0a7543f1":"# Watersheding\n\nIn the study of image processing, a **watershed** is a transformation defined on a grayscale image. The name refers metaphorically to a geological watershed, or drainage divide, which separates adjacent drainage basins. The watershed transformation treats the image it operates upon like a topographic map, with the brightness of each point representing its height, and finds the lines that run along the tops of ridges [1].\n\n\n\n\n--------\n[1] https:\/\/en.wikipedia.org\/wiki\/Watershed_(image_processing)\n\n[2] https:\/\/scikit-image.org\/docs\/dev\/api\/skimage.morphology.html?highlight=watershed","51afe41f":"## Resizing images\n\nTo resize an image we may use \n1. The PIL **.thumbnail** module; this actually *rescale* the image; \n2. The PIL **.resize** module, that really resize the image but do *not* scale image. \n\nSo the best option is to *combine* the two operations, using the **thumbnail** method to rescale the image so that it's longest dimension fits the desired size, and then create a new \"background\" image of the right dimensions, and then *paste* the rescaled thumbnail into the middle of the background. \n\nSince there are a few steps to this, we'll encapsulate all of them in a function **resize_image**.","7420e913":"## Edge Detection and Sobel Filter\n\n### Edge Detection\n\n\n### Sobel Filter\n\nIf the built-in FIND-EDGES filter doesn't provide what you need, you could use a Sobel edge-detection algorithm; which involves convolving two filters across an image to find the horizontal and vertical vector gradients for each pixel, and then calculating the magnitude (length) of each vector gradient. \n\nThe Sobel filter apply two filers $G_x$ and $G_y$ to the images; those are\n$$G_x = \\left[\\begin{matrix} +1 & +2 & +1 \\\\ 0 & 0 & 0 \\\\ -1 & -2 & -1  \\end{matrix}\\right]$$\n$$G_y = \\left[\\begin{matrix} -1 & 0 & +1 \\\\ -2 & 0 & +2 \\\\ -1 & 0 & +1  \\end{matrix}\\right]$$\nAnd then the filtered images has gradient magnitude\n$$G = \\sqrt{G_x^2 + G_y^2}$$\nthe gradient direction is\n$$\\Theta = \\arctan \\frac{G_y}{G_x}$$\n\n\nThe pseudocode implementation is [1]\n\nfunction sobel(A : as two dimensional image array)\n\t\n    Gx=[-1 0 1; -2 0 2; -1 0 1]\n\tGy=[-1 -2 -1; 0 0 0; 1 2 1]\n\t\n\trows = size(A,1)\n\tcolumns = size(A,2)\n\tmag=zeros(A)\n\n\tfor i=1:rows-2\n\t\tfor j=1:columns-2\n\t\t\tS1=sum(sum(Gx.*A(i:i+2,j:j+2)))\n\t\t\tS2=sum(sum(Gy.*A(i:i+2,j:j+2)))\n\n\t\t\tmag(i+1,j+1)=sqrt(S1.^2+S2.^2)\n\t\tend for\n\tend for\n\t\n\tthreshold = 70 %varies for application [0 255]\n\toutput_image = max(mag,threshold)\n\toutput_image(output_image==round(threshold))=0;\n\treturn output_image\nend function\n\n----------------\n[1] https:\/\/en.wikipedia.org\/wiki\/Sobel_operator","205416da":"From [1]:\n> If you are not familiar with the details of the different algorithms and the underlying assumptions, it is often difficult to know which algorithm will give the best results. Therefore, Scikit-image includes a function to evaluate thresholding algorithms provided by the library. At a glance, you can select the best algorithm for your data without a deep understanding of their mechanisms.\n\n"}}