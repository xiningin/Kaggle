{"cell_type":{"86df2b4d":"code","958d4609":"code","467a7057":"code","8760a5e1":"code","7a7d80bf":"code","796b089b":"code","475f1f5e":"code","c803fde5":"code","4ee11905":"code","866553c8":"code","312edd19":"code","0dad844c":"code","6a7a8600":"code","dd477a48":"markdown","d767716f":"markdown","63b95b61":"markdown","5e2159c5":"markdown","b70ced7b":"markdown","90e7c697":"markdown"},"source":{"86df2b4d":"import pandas as pd\nimport numpy as np\nfrom sklearn.datasets import load_iris\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier,export_graphviz\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nplt.style.use('seaborn')","958d4609":"df = pd.read_csv(\"..\/input\/iris\/Iris.csv\")","467a7057":"df.head()","8760a5e1":"# drop Id Column\ndf = df.drop(\"Id\", axis = 1)","7a7d80bf":"df.head()","796b089b":"# split the data\nX = df.drop(\"Species\", axis = 1)\ny = df[\"Species\"]\nX_train, X_test, Y_train, Y_test = train_test_split(X, y, random_state = 42,test_size=0.30)","475f1f5e":"# Decision Tree\nclf = DecisionTreeClassifier (max_depth = 2, random_state = 0)\nclf.fit(X_train, Y_train)\nscore = clf.score(X_test, Y_test)\nprint(score)","c803fde5":"from sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(clf, X, y, cv=10) #CV = k partition = 10\nscores.mean()","4ee11905":"max_depth_range = list(range(1, 6))\n\naccuracy = []\ndepths = []\nfor depth in max_depth_range:\n    \n    clf = DecisionTreeClassifier(max_depth = depth, \n                             random_state = 0)\n    clf.fit(X_train, Y_train)\n    score = clf.score(X_test, Y_test)\n    accuracy.append(score)\n    depths.append(depth)","866553c8":"max_depth_range = list(range(1, 50))\n\naccuracy = []\ndepths = []\nfor depth in max_depth_range:\n        \n    clf = DecisionTreeClassifier(max_depth = depth, \n                             random_state = 0)\n    scores = cross_val_score(clf, X, y, cv=10)\n    score = scores.mean()\n\n    accuracy.append(score)\n    depths.append(depth)","312edd19":"pd.DataFrame.from_dict({\"max_depth\":depths, \"accuracy\" : accuracy}).sort_values(\"accuracy\",ascending=False)","0dad844c":"plt.plot(depths, accuracy, linestyle='--', marker='o', color=\"red\")\nplt.xlabel(\"Max Depth\")\nplt.ylabel(\"Accuracy\")\nplt.show()","6a7a8600":"from ipywidgets import interactive\nfrom IPython.display import SVG,display\nfrom graphviz import Source\n\n\n#features\nfeatures_label = X_train.columns\n\n# Labels\nY_train_decode = Y_train.replace({0: 'Setosa', 1:'Versicolor', 2:'Virginica'})\n\nclass_label = list(set(Y_train_decode))\n\n\ndef plot_tree(crit, split, depth):\n    estimator = DecisionTreeClassifier(\n           random_state = 0 \n          ,criterion = crit\n          ,splitter = split\n          ,max_depth = depth\n    )\n    estimator.fit(X_train, Y_train_decode)\n    graph = Source(export_graphviz(estimator\n      , out_file=None\n      , feature_names=features_label\n      , class_names=class_label\n      , impurity=True\n      , filled = True))\n    display(SVG(graph.pipe(format='svg')))\n    return estimator\n\ninter=interactive(plot_tree \n   , crit = [\"gini\", \"entropy\"]\n   , split = [\"best\", \"random\"]\n   , depth=[1,2,3,4,5,10,20,30])\n\ndisplay(inter)","dd477a48":"Assessing Tree Behavior","d767716f":"reading the data","63b95b61":"Loading the libraries","5e2159c5":"Now, using crossvalidation","b70ced7b":"## Modeling\n### Decision Tree","90e7c697":"### Tuning the decision tree"}}