{"cell_type":{"a7d36e75":"code","f8a1c04a":"code","d34e8a5b":"code","2d578624":"code","27950235":"code","177a8ae1":"code","4fb1f648":"code","696e1c06":"code","4a37ae2d":"code","3224b5b0":"code","bb57910b":"code","f56fb77f":"code","86fb016f":"code","a6b0d6aa":"code","d9c94647":"code","84a6746b":"code","bf9bfdcc":"code","a42ca470":"code","2e2c67e4":"code","8980ae54":"code","1d80df38":"code","558355d9":"code","b246edc4":"code","8d03a5d9":"code","5df4d521":"code","5b4c6e4a":"code","e0d13067":"code","ad116cad":"code","12c8bac8":"code","3de91561":"code","9e0ccc6a":"code","9b47a453":"code","88012f65":"code","c09efba7":"code","57e6b471":"code","25258d77":"code","ec36c5b0":"code","3c6f77b1":"code","dd68dd2a":"code","14fa28eb":"code","3d0812c2":"code","09a52e09":"code","9e11cfd4":"code","69398f69":"code","18d27be7":"code","5f3e4095":"code","0d75819d":"code","72dc05db":"code","acca0fd2":"code","f4acdf7d":"code","54c15ba1":"code","db7d92fc":"code","f0903d4f":"code","f9fb9cfc":"code","0e4b9b93":"code","dcb4c000":"code","a68c45b9":"code","0eef3202":"code","35a41959":"code","f3b78e22":"code","a745e7d0":"code","d38dc826":"code","ecc296a8":"code","12555c95":"code","0a13e23e":"code","e9880795":"code","4deb4a42":"code","801992a0":"code","c53a73d2":"code","e69b1137":"code","4339679c":"code","48645b95":"code","a3965f90":"code","ddb5fca7":"code","f7ee9fe7":"code","7588adc0":"code","1a5c4373":"code","bd9b4815":"code","7ea1e68d":"code","2a4afb9c":"code","0ba4c37c":"code","ecd0c28e":"code","4acb9084":"code","c4c54d66":"code","57d435bb":"code","760ce20a":"code","43f9a3fd":"code","137dbffc":"code","9292a6d7":"code","dcc5f86d":"code","083feab8":"code","eccb9ebd":"code","79f6ce27":"code","d27309ff":"code","1c733241":"code","bbfd51b2":"code","9a7de7e8":"code","37d46f4e":"code","c8d1f6f1":"code","bdb629bf":"code","d7eaf0ba":"code","173400fd":"code","3742cbe5":"code","b3f5e075":"code","da609a20":"code","5df91e30":"code","5a06e8da":"code","3562294b":"code","78f225e8":"code","2c1c0631":"code","d7e1edba":"code","8f933bf6":"code","735425f2":"code","a0f2ec38":"code","85fee574":"code","6900e328":"code","f18d364f":"code","97398851":"code","28d8ef82":"code","3dfbd6f1":"code","d2f74a1d":"code","9ed8e145":"code","416b1763":"code","69d5c366":"code","abf6cbea":"code","028ce6e0":"code","fc65d7f2":"code","c7ebc902":"code","01fd2692":"code","96900abe":"markdown","3e903dc8":"markdown","2bf40d6e":"markdown","8b59f66d":"markdown","fc527962":"markdown","29c1262d":"markdown","bb1bde43":"markdown","8dc6dffb":"markdown","6df294f0":"markdown","f2caf704":"markdown","a60d6d6c":"markdown","5d054cbd":"markdown","0062bd9a":"markdown","1357a8cc":"markdown","45dc137d":"markdown","3717cbd1":"markdown","857f521c":"markdown","09d91803":"markdown","19920688":"markdown","e1569698":"markdown","b3e9ab15":"markdown","fc39dee0":"markdown","3fc0e80a":"markdown","769d8ba3":"markdown","a9ce8820":"markdown","94cd7caa":"markdown","e9fc83aa":"markdown","20d1c214":"markdown","07cd5b81":"markdown","db375193":"markdown","b9b69539":"markdown","7afe25c7":"markdown","d42eef9f":"markdown","a7919b3e":"markdown","6a31e8b5":"markdown","c921c3e8":"markdown","f6388b0d":"markdown","c92311ee":"markdown","73c6654e":"markdown","f00df0d9":"markdown","52157a4c":"markdown","1ca4d931":"markdown","824c7d80":"markdown","e334d639":"markdown","9ccab66f":"markdown","10d0b13c":"markdown"},"source":{"a7d36e75":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f8a1c04a":"df=pd.read_csv('\/kaggle\/input\/delhi-house-price-prediction\/MagicBricks.csv')","d34e8a5b":"df","2d578624":"df.info()","27950235":"df.isnull().sum()","177a8ae1":"import seaborn as sns\nimport matplotlib.pyplot as plt","4fb1f648":"df['Area'].value_counts()","696e1c06":"sns.regplot(y='Area',x='Price',data=df)","4a37ae2d":"sns.boxplot(df[\"Area\"])\nplt.show()","3224b5b0":"sns.barplot(df[\"Price\"],df['Area'])\nplt.show()","bb57910b":"sns.scatterplot(df[\"Area\"],df['Price'])\nplt.show()","f56fb77f":"df['BHK'].value_counts()","86fb016f":"sns.regplot(y='BHK',x='Price',data=df)","a6b0d6aa":"sns.countplot(df[\"BHK\"])\nplt.show()","d9c94647":"sns.boxplot(df[\"BHK\"])\nplt.show()","84a6746b":"df['Bathroom'].value_counts()","bf9bfdcc":"sns.regplot(y='Bathroom',x='Price',data=df)","a42ca470":"sns.countplot(df[\"Bathroom\"])\nplt.show()","2e2c67e4":"df['Parking'].value_counts()","8980ae54":"sns.boxplot(df[\"Parking\"])\nplt.show()","1d80df38":"df['Transaction'].value_counts()","558355d9":"sns.catplot(x=\"Transaction\", y=\"Area\", data=df)\n","b246edc4":"sns.catplot(x=\"Transaction\", y=\"Area\", kind=\"box\", data=df)","8d03a5d9":"sns.catplot(x=\"Transaction\", y=\"Area\", kind=\"bar\", data=df)","5df4d521":"df['Status'].value_counts()","5b4c6e4a":"sns.catplot(x=\"Status\", y=\"Area\", kind=\"box\", data=df)","e0d13067":"df['Furnishing'].value_counts()","ad116cad":"sns.catplot(x=\"Furnishing\", y=\"Area\", kind=\"box\", data=df)","12c8bac8":"df['Type'].value_counts()","3de91561":"sns.catplot(x=\"Type\", y=\"Area\", kind=\"box\", data=df)","9e0ccc6a":"df['Locality'].value_counts()","9b47a453":"sns.catplot(x=\"Area\", y=\"Locality\", kind=\"bar\", data=df)","88012f65":"area_df=df['Area'].value_counts().head(40)\n# Areas that occured atleast 10 times are taken:--\n\narea_df\n# among top 36 most occured(atleast 10 times) Area values, MAX is 2700.","c09efba7":"sns.distplot(df['Area'])","57e6b471":"plt.hist(df[\"Area\"],color='green')\nplt.show()","25258d77":"df=df[df['Area']<=3000]","ec36c5b0":"sns.regplot(y='Area',x='Price',data=df)","3c6f77b1":"df=df[df['BHK']<6]","dd68dd2a":"df=df[~(df['Bathroom']==6)]","14fa28eb":"df\n","3d0812c2":"correlation=df.corr()","09a52e09":"correlation","9e11cfd4":"df.shape","69398f69":"new=df.drop_duplicates()","18d27be7":"new.shape","5f3e4095":"new.isnull().sum()","0d75819d":"plt.hist(new[\"Per_Sqft\"],color='brown')\nplt.show()","72dc05db":"compare=(new['Price']\/new['Area'])-new['Per_Sqft']","acca0fd2":"compare","f4acdf7d":"compare.median()","54c15ba1":"new['Per_Sqft']=new['Per_Sqft'].fillna(value=new['Price']\/new['Area'] )","db7d92fc":"new.head(50)","f0903d4f":"new.isnull().sum()","f9fb9cfc":"new[new['Bathroom'].isnull()]","0e4b9b93":"new['Bathroom']=new['Bathroom'].fillna(value=new['Bathroom'].median())","dcb4c000":"# Not needed to go with Float value to Bathroom.\nnew = new.astype({\"Bathroom\":'int64'}) ","a68c45b9":"new","0eef3202":"new.isnull().sum()","35a41959":"new['Furnishing'].value_counts()","f3b78e22":"new['Type'].value_counts()","a745e7d0":"new[new['Furnishing'].isnull()]","d38dc826":"new[new['Type'].isnull()]","ecc296a8":"new=new.sort_values(by='Locality',axis=0)\n#This will arrange the localities sequentially...","12555c95":"new","0a13e23e":"new.isnull().sum()","e9880795":"new['Type']=new['Type'].fillna(method='bfill')","4deb4a42":"new['Furnishing']=new['Furnishing'].fillna(method='bfill')","801992a0":"new.isnull().sum()","c53a73d2":"from sklearn.preprocessing import LabelEncoder","e69b1137":"furnishing_encoder=LabelEncoder()\nstatus_encoder=LabelEncoder()\ntransaction_encoder=LabelEncoder()\ntype_encoder=LabelEncoder()","4339679c":"new['Furnishing']=furnishing_encoder.fit_transform(new['Furnishing'].astype('str'))\nnew['Status']=status_encoder.fit_transform(new['Status'])\nnew['Transaction']=transaction_encoder.fit_transform(new['Transaction'])\nnew['Type']=type_encoder.fit_transform(new['Type'].astype('str'))","48645b95":"new.head(30)","a3965f90":"new.corr()['Price']","ddb5fca7":"sns.heatmap(new.corr(),annot=True)","f7ee9fe7":"sns.regplot(x=\"Parking\", y=\"Price\", data=new)\n","7588adc0":"sns.catplot(x=\"Furnishing\", y=\"Price\", kind=\"box\", data=new)","1a5c4373":"sns.regplot(x=\"Furnishing\", y=\"Price\", data=new)","bd9b4815":"final= new.drop(columns=['Furnishing','Parking','Locality'])","7ea1e68d":"final","2a4afb9c":"final['Bathroom'].value_counts()","0ba4c37c":"from sklearn.preprocessing import OneHotEncoder\nohe=OneHotEncoder(drop='first')","ecd0c28e":"final2=ohe.fit_transform(final[['BHK','Bathroom']])","4acb9084":"final2.toarray()","c4c54d66":"final2=pd.DataFrame(final2.toarray())","57d435bb":"final2","760ce20a":"final1=final.drop(columns=['BHK','Bathroom'])","43f9a3fd":"final1=final1.reset_index()","137dbffc":"final1=final1.drop(columns=['index'])","9292a6d7":"final1","dcc5f86d":"final= pd.concat([final1, final2], axis=1, ignore_index=False)","083feab8":"final","eccb9ebd":"y=final['Price'].values","79f6ce27":"y","d27309ff":"from sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()","1c733241":"X=final.drop(columns=['Price'])\nX","bbfd51b2":"X=scaler.fit_transform(X)\nX","9a7de7e8":"print(X.shape)\nprint(y.shape)","37d46f4e":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,train_size=0.9,random_state=2)","c8d1f6f1":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","bdb629bf":"from sklearn.linear_model import LinearRegression\nlr=LinearRegression()","d7eaf0ba":"lr.fit(X_train,y_train)","173400fd":"y_pred=lr.predict(X_test)","3742cbe5":"y_pred","b3f5e075":"from sklearn.metrics import r2_score\nr2_score(y_test,y_pred)","da609a20":"plt.scatter(x=y_test, y=y_pred)\nplt.show()","5df91e30":"print(lr.coef_)\nprint(lr.intercept_)","5a06e8da":"from sklearn.ensemble import RandomForestRegressor\nrf= RandomForestRegressor(n_estimators=100,random_state=0)","3562294b":"rf.fit(X_train, y_train)","78f225e8":"y_pred1=rf.predict(X_test)","2c1c0631":"y_pred1","d7e1edba":"r2_score(y_test,y_pred1)","8f933bf6":"plt.scatter(x=y_test, y=y_pred1)\nplt.show()","735425f2":"# Try different numbers of n_estimators - this will take a minute or so\nestimators = np.arange(10, 200,10)\nscores = []\nfor n in estimators:\n    rf.set_params(n_estimators=n)\n    rf.fit(X_train, y_train)\n    scores.append(rf.score(X_test, y_test))\nplt.title(\"Effect of n_estimators\")\nplt.xlabel(\"n_estimator\")\nplt.ylabel(\"score\")\nplt.plot(estimators, scores)","a0f2ec38":"estimators","85fee574":"scores","6900e328":"from sklearn.neighbors import KNeighborsRegressor\nknr=KNeighborsRegressor()","f18d364f":"knr.fit(X_train, y_train)","97398851":"y_pred2=knr.predict(X_test)","28d8ef82":"y_pred2","3dfbd6f1":"r2_score(y_test,y_pred2)","d2f74a1d":"from sklearn.ensemble import GradientBoostingRegressor\nGB = GradientBoostingRegressor(loss='ls',n_estimators=800,subsample=0.1,criterion='mse',max_features='auto',min_samples_leaf=5, min_samples_split=4, max_leaf_nodes=40, learning_rate=0.05, max_depth=20, random_state=2, n_iter_no_change=5)","9ed8e145":"GB.fit(X_train, y_train)\ny_pred3 = GB.predict(X_test)\nr2_score(y_test,y_pred3)","416b1763":"y_pred3","69d5c366":"from xgboost import XGBRegressor\nXGB = XGBRegressor(eta=0.05, gamma=1,tree_method='auto',objective ='reg:squarederror',max_depth=4, max_leaves=15, subsample=0.1, reg_lambda=9, reg_alpha=50, n_estimators=900, random_state=30)","abf6cbea":"XGB.fit(X_train, y_train)\ny_pred4 = XGB.predict(X_test)\nr2_score(y_test,y_pred4)","028ce6e0":"import pickle","fc65d7f2":"pickle.dump(lr, open('model.pkl','wb'), protocol=2)","c7ebc902":"pickle.dump(status_encoder, open('status_encoder.pkl','wb'), protocol=2)\npickle.dump(transaction_encoder, open('transaction_encoder.pkl','wb'), protocol=2)\npickle.dump(type_encoder, open('type_encoder.pkl','wb'), protocol=2)\npickle.dump(ohe, open('ohe.pkl','wb'), protocol=2)","01fd2692":"final.to_csv('House_Price.csv',header=False)","96900abe":"### ***Area is the biggest factor to predict price, as we all know. And seemingly Box Plot is a better way to understand the distribution of these Catagorical Data over Area. These plots as well say that MAX of Area is around 2500 sqft.*** \n\n### **Lets see what the other data are signifying--**","3e903dc8":"### **Locality Column is a mess actually, 365 different localities are there. Though its evident. So we actually have nothing to do with this column.**","2bf40d6e":"## 3. Filtering out Bathroom Column-->","8b59f66d":"## 1. Filtering out Area Column-->","fc527962":"### Parking still have some NaNs. Lets first find if it has any significant role to play to predict price or not. ","29c1262d":"> ## **We have done the Analysis. So now we will filter out the Dataframe. And we will workout the above plans.**","bb1bde43":"# >>  Filtering","8dc6dffb":"## 2. Filtering out BHK Column-->","6df294f0":"> ## **Well we can understand from both Correlation Chart and the above plot that Parking Column is Good for Nothing for Price-Prediction. \"A correlation of 0.02 is nothing\". So is with Furnishing.**\n### So these are dropped off along with Locality....","f2caf704":"* ## Predictions are more than 81% correct(with the Gradient Boosting Model), which is quite good. XGBoost is unlikely loosing the race to GB, which is kind of weird, as it generally is better. But, we can do further upgradation and make the predictions more accurate possibly with some other Models. \n ### **But for now the Boosting Algorithms are GOOD to GO.**","a60d6d6c":"## For that correlation of various columns with Price(i.e the Output Column) is to be examined.\n### But some columns are NOT Numerical.","5d054cbd":"## **(1). Linear Regression:--**","0062bd9a":"### There are still some NULL values in our Dataset. Lets find out ways to deal with them. \n#### *First concern is for Per_Sqft.*","1357a8cc":"# ---> There you go. We have successfully generated a model that is capable of predicting the Price of a house if the following data are given by the user.\n### 1.Total Area, \n### 2.BHK,\n### 3.Bathroom,\n### 4.Status,\n### 5.Transaction,\n### 6.Type and \n### 7.Per_Sqft value. \n","45dc137d":"### \"And we are left with a pure numerical dataset.\"","3717cbd1":"### **There are 200 odd NULL values in Per_Sqft. I think the best way to fill them will be to fill them by the ratio of corresponding Price and Area.**\n\n## \"And it has a Reason\"","857f521c":"### Some more codes to get the correct Area range ;)","09d91803":" ## ***I hope this Notebook was helpful for you, and may be you learned something from it. I'm eagerly waiting for your suggestions, so that the results can be further improved. So, comment below your sayings.*** \n ###  **THANK YOU, Be Safe.....**","19920688":"### **No. of Parking is mainly distributed about 1 and 2. This will be discussed later**","e1569698":"## **(2). Random Forest:--**","b3e9ab15":"### **Now this analysis implies that No. of Bathrooms above 5 really don't have any significant effect on Price Prediction**","fc39dee0":"**To CSV**","3fc0e80a":"## To get a clear view about Area, we can see these plots below.\n   ###     ----Which clearly says that Area values below 3000 sqft are more frequent.","769d8ba3":"### **Actully there are some Duplicate rows in our df. So I'm dropping them.","a9ce8820":"# >>DATA Spliting:","94cd7caa":"## ***For now let us analyse the Catagorical Data:-***","e9fc83aa":"# >>SCALING: \n### --- a step of Data Pre-processing which is applied to independent variables or features of data. \n### *~It basically helps to normalise the data within a particular range. Sometimes, it also helps in speeding up the calculations in an algorithm*.\n> ## The formula used in the following object is often used in Statistic, where each value is replaced first substracting the mean of that column and then divided by the Standard Deviation of the same.\nhttps:\/\/www.google.com\/url?sa=i&url=https%3A%2F%2F365datascience.com%2Fstandardization%2F&psig=AOvVaw3pa_eeGRJHaJSfXrYJCCbF&ust=1606203348694000&source=images&cd=vfe&ved=0CAIQjRxqFwoTCJCbpvOTmO0CFQAAAAAdAAAAABAD","20d1c214":"# >> NULL value Removing","07cd5b81":"# >> Pickling","db375193":"## **(5). XGBoost:--**","b9b69539":"## Columns to be OHEd:~ BHK and Bathroom, as they are like catagorical data. Status, Transaction and Type are not reqd to do so as they have only two columns each. ","7afe25c7":"### **These are also making us to take Area values below 3000 sqft. Lets see what the Area itself says**","d42eef9f":" ## **~Yup. We did well. Lets keep AREA<=3000 sqft**","a7919b3e":"### **From these three plots above we can understand that BHK above 5 are not significant to predict Price. Lets do the same for Bathrooms**","6a31e8b5":"### Type Column is well distributed between Builder_Floor and Apartment. What should we do?","c921c3e8":"# >>LABEL ENCODING:\n##### >----to convert Furnishing, Status, Transaction and Type into Numerical Data----<","f6388b0d":"### Here's our BRAND-NEW Dataframe....","c92311ee":"### You can see Per_Sqft value is quite close to that ratio. So we will stick to this plan.","73c6654e":" # >> **Exploratory Data Analysis**","f00df0d9":"### So lets start the Data Analysis:","52157a4c":"> ### And you can clearly see that with this above plot.","1ca4d931":"### Ok. We are filling it with that value of a room at the same locality. Any other Suggestion is always welcomed.","824c7d80":"# >>ONE HOT ENCODING:\n\n### **As Label Encoding is generally followed by OHE","e334d639":"## **(3). KNeighbours:--**","9ccab66f":"## **(4). Gradient Boosting:--**","10d0b13c":"# >> MODEL Building:"}}