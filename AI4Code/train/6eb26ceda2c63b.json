{"cell_type":{"8830955b":"code","5d0efe17":"code","58a666c0":"code","765efda3":"code","441e2084":"code","ed82c327":"code","019418c9":"code","9dd2dd93":"code","7232a5bd":"code","635962aa":"code","9b1e8cae":"code","9040414f":"code","03aab3fa":"code","b8bbdc94":"code","9549c865":"code","e20fc05a":"code","cde2d3cb":"code","6e9a2976":"code","8e14470d":"code","c26568fa":"code","fd6b3578":"markdown","a487a5fe":"markdown","c56434b5":"markdown","ed5ec4fa":"markdown","bbc76e09":"markdown","a4367c78":"markdown","5612f4ab":"markdown","2473eb0e":"markdown","35c93f08":"markdown","16724138":"markdown"},"source":{"8830955b":"# EDA\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n\n# Modeling and Prediction \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score","5d0efe17":"df = pd.read_csv(\"\/kaggle\/input\/heart-attack-analysis-prediction-dataset\/heart.csv\")","58a666c0":"df.head()","765efda3":"df.shape","441e2084":"df.info()","ed82c327":"df.describe()","019418c9":"df.isnull().sum()","9dd2dd93":"sns.set_style(\"darkgrid\")\nsns.countplot(x='output',data=df, palette = 'Pastel1')","7232a5bd":"df['output'].value_counts()","635962aa":"sns.set_style(\"darkgrid\")\nsns.countplot(x='output',hue='sex',data=df, palette = 'Pastel1')","9b1e8cae":"sns.boxplot(x='output',y='age',data=df,palette='Pastel1')","9040414f":"sns.pairplot(df, hue = 'output')","03aab3fa":"df.corr()","b8bbdc94":"plt.figure(figsize=(14,10))\nsns.heatmap(df.corr(), annot=True)","9549c865":"X = df.drop(['output'], axis = 1)\nY = df['output']","e20fc05a":"# Train-test split 30-70\nX_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.3, \n                                                    random_state=101)","cde2d3cb":"#Scaling the data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.fit_transform(X_test)","6e9a2976":"def models(X_train,y_train):\n    \n    #Logistic Regression\n    log = LogisticRegression(random_state=0)\n    log.fit(X_train, y_train)\n    \n    #Decision Tree\n    decision_tree = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n    decision_tree.fit(X_train, y_train)\n    \n    #Random Forest\n    random_forest = RandomForestClassifier(n_estimators=10,criterion = 'entropy', random_state=0)\n    random_forest.fit(X_train, y_train)\n    \n    #KNN\n    knn = KNeighborsClassifier(n_neighbors = 3)\n    knn.fit(X_train, y_train)\n    \n    #SVM\n    svm = SVC(kernel='linear', C=1, random_state=101).fit(X_train,y_train)\n    \n    #Model Accuracy on Training Data\n    print('[0]Logistic Regression Training Acc:', log.score(X_train,y_train))\n    print('[1]Decision Tree Training Acc:', decision_tree.score(X_train,y_train))\n    print('[2]Random Forest Training Acc:', random_forest.score(X_train,y_train))\n    print('[3]KNN Training Acc:', knn.score(X_train,y_train))\n    print('[4]SVM Training Acc:', svm.score(X_train,y_train))\n    \n    return log, decision_tree, random_forest, knn, svm","8e14470d":"model = models(X_train,y_train)","c26568fa":"# Accuracy on Testing Data\n\nfor i in range(len(model)):\n    print('Model ', i)\n    cm = confusion_matrix(y_test, model[i].predict(X_test))\n\n    tp = cm[0][0]\n    tn = cm[1][1]\n    fp = cm[1][0]\n    fn = cm[0][1]\n\n    print(cm)\n    print('Testing Acc = ', (tp + tn)\/(tp +tn +fn + fp))\n    print()","fd6b3578":"**Models and Accuracy**","a487a5fe":"We can see that there are 165 people who are prone to heart attacks and 138 people who are not prone to heart attacks. ","c56434b5":"**The testing accuracies are:**\n* Logistic Regression: 0.86\n* Decision Tree: 0.86\n* Random Forest: 0.78\n* KNN: 0.86\n* SVM: 0.87\n\nSVM has the best accuracy score.","ed5ec4fa":"We will be using:\n* Logistic Regression\n* Decision Tree\n* Random Forest \n* KNN\n* SVM","bbc76e09":"**Exploratory Data Analysis**","a4367c78":"In this project, we will be predicting if a person is prone to heart attack or not. We will also be doing some EDA.","5612f4ab":"From the plot above, we can conclude that:\n* People whose sex = 1 is more prone to getting a heart attack as compared to those whose sex = 0","2473eb0e":"**Splitting and Scaling the Data**","35c93f08":"# Heart Attack Prediction","16724138":"**Importing Libraries**"}}