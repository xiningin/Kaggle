{"cell_type":{"deb95d6a":"code","6a772407":"code","190db32f":"code","c9b53479":"code","7602dd5f":"code","f65ffb6f":"code","529c8d97":"code","acb468f9":"code","8c9d3ab6":"code","44beb7f9":"code","70819fd5":"code","c729b762":"code","16050af9":"code","143fd99e":"code","a63e999f":"code","f0582219":"code","4b2d8264":"code","5c4e1040":"code","a1999852":"markdown","93b97d5c":"markdown","1822cddc":"markdown","4c0c1e82":"markdown","6d042407":"markdown","1192cf3f":"markdown","198456a3":"markdown","5f8e0c71":"markdown","fb249e13":"markdown","3c2806e9":"markdown","d4804b93":"markdown","e426bf2f":"markdown","e642ca29":"markdown","e6a5a4c1":"markdown","01fea872":"markdown","f91e965a":"markdown","908e6ebb":"markdown","475ad280":"markdown","d6496af1":"markdown"},"source":{"deb95d6a":"! pip install pyfolio\n! pip install PyPortfolioOpt","6a772407":"import numpy as np \nimport pandas as pd \nimport pyfolio as pf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import display, HTML\n\nfrom pypfopt.efficient_frontier import EfficientFrontier\nfrom pypfopt import risk_models\nfrom pypfopt import expected_returns\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        path = os.path.join(dirname, filename)","190db32f":"def join_df_list(df_list, tolerance):\n    \"\"\"\n    Performs the merge_asof in a list of dfs\n    using 'tolerance' as tolerance.\n\n    :param df_list: list of data frames\n    :type df_list: [pd.DataFrame]\n    :param tolerance: difference of days between\n                      data frames that can be\n                      tolerated\n    :type tolerance: pd.Timestamp\n    :return: merged dataframe\n    :rtype: pd.DataFrame\n    \"\"\"\n    size = len(df_list)\n    df = pd.merge_asof(df_list[0], df_list[1],\n                       left_index=True,\n                       right_index=True,\n                       tolerance=tolerance)\n    for i in range(2, size):\n        df = pd.merge_asof(df, df_list[i],\n                           left_index=True,\n                           right_index=True,\n                           tolerance=tolerance)\n    return df\n\n\ndef show_clean_p(p):\n    p_show = p.transpose()[p.transpose() > 0.001].dropna()\n    p_show = p_show.transpose()\n    p_show = (p_show.transpose()[0]).map(lambda x: \"{:.1%}\".format(x)).to_frame().transpose()\n    display(HTML(p_show.to_html()))","c9b53479":"ibov = [\"ABEV3\", \"AZUL4\", \"B3SA3\", \"BBAS3\", \"BBDC3\", \"BBDC4\", \"BBSE3\", \"BPAC11\", \"BRAP4\",\n        \"BRDT3\", \"BRFS3\", \"BRKM5\", \"BRML3\", \"BTOW3\", \"CCRO3\", \"CIEL3\", \"CMIG4\", \"COGN3\", \"CRFB3\",\n        \"CSAN3\", \"CSNA3\", \"CVCB3\", \"CYRE3\", \"ECOR3\", \"EGIE3\", \"ELET3\", \"ELET6\", \"EMBR3\", \"ENBR3\",\n        \"EQTL3\", \"FLRY3\", \"GGBR4\", \"GNDI3\", \"GOAU4\", \"GOLL4\", \"HAPV3\", \"HGTX3\", \"HYPE3\", \"IGTA3\",\n        \"IRBR3\", \"ITSA4\", \"ITUB4\", \"JBSS3\", \"KLBN11\", \"LAME4\", \"LREN3\", \"MGLU3\", \"MRFG3\", \"MRVE3\", \"MULT3\",\n        \"NTCO3\", \"PCAR4\", \"PETR3\", \"PETR4\", \"QUAL3\", \"RADL3\", \"RAIL3\", \"RENT3\", \"SANB11\", \"SBSP3\", \"SMLS3\",\n        \"SULA11\", \"SUZB3\", \"TAEE11\", \"TIMP3\", \"TOTS3\", \"UGPA3\", \"USIM5\", \"VALE3\", \"VIVT4\", \"VVAR3\", \"WEGE3\", \"YDUQ3\"]\n","7602dd5f":"df = pd.read_csv(path)\ndf.loc[:, \"datetime\"] = df.datetime.map(pd.Timestamp)","f65ffb6f":"df_sort = df.set_index([\"ticker\", \"datetime\"]).sort_index()\nstart_date = \"2016-02-02\"\n\n\nibov_mini = []\nfor ticker in ibov:\n    ts = df_sort.xs(ticker)\n    if ts.index.min() <= pd.Timestamp(start_date):\n        ibov_mini.append(ticker)\n\ndel df_sort\n\nratio = len(ibov_mini)\/len(ibov)\nprint(\"percentage of ibov's tickers that will be used in the analysis = {:.1%}\".format(ratio))","529c8d97":"df_sort = df.set_index([\"datetime\"]).sort_index()\ndf_sort = df_sort[df_sort.index >= start_date]\ndf_sort = df_sort[df_sort.ticker.isin(ibov_mini)]\ndf_train = df_sort[df_sort.index < \"2019-01-01\"]\ndf_test = df_sort[df_sort.index >= \"2019-01-01\"]\n\ndel df_sort\n\ndf_train = df_train.reset_index().set_index([\"ticker\", \"datetime\"]).sort_index()\ndf_test = df_test.reset_index().set_index([\"ticker\", \"datetime\"]).sort_index()\n","acb468f9":"all_prices = []\n\nfor ticker in ibov_mini:\n    series = df_train.xs(ticker).close\n    series.name = ticker\n    all_prices.append(series.to_frame())\n    \nall_prices = join_df_list(all_prices, tolerance=pd.Timedelta(\"10days\"))\n\n# dealing with missing data\nall_prices = all_prices.dropna(1)\n\n\n","8c9d3ab6":"ibov_mini = list(all_prices.columns)\n\nn_ibov = len(ibov_mini)\n\n\nuniform_weigths = np.ones((n_ibov)) \/ n_ibov\nbanks_weigths = np.ones((n_ibov))\/ n_ibov\np1 = pd.DataFrame([uniform_weigths], columns=ibov_mini)\np2 = pd.DataFrame([banks_weigths], columns=ibov_mini)\n\np2.loc[:, \"ITSA4\"] = 0.2\np2.loc[:, \"ITUB4\"] = 0.2\np2.loc[:, \"BBDC3\"] = 0.2\np2.loc[:, \"BBDC4\"] = 0.2\n\np2 = p2 \/ p2.sum(1)[0]\n\nuniform_weigths = p1.values.flatten()\nbanks_weigths = p2.values.flatten()\n\n\n\n\nprint(\"\\nportfolio 1:\\n\")\np1_show = (p1.transpose()[0]).map(lambda x: \"{:.1%}\".format(x)).to_frame().transpose()\ndisplay(HTML(p1_show.to_html()))\n\nprint(\"\\nportfolio 2:\\n\")\np2_show = (p2.transpose()[0]).map(lambda x: \"{:.1%}\".format(x)).to_frame().transpose()\ndisplay(HTML(p2_show.to_html()))","44beb7f9":"ticker = \"BBDC4\"\nprices = all_prices[ticker]\nwindow = 250\n\ndef get_daily_max_drawdown(prices, window):\n    max_rolling = prices.rolling(min_periods=1, window=window).max()\n    daily_drawdown = (prices \/ max_rolling) - 1\n    max_daily_drawdown = daily_drawdown.rolling(min_periods=1, window=window).min()\n    return daily_drawdown,max_daily_drawdown\n\nmax_rolling = prices.rolling(min_periods=1, window=window).max()\n\ndaily_drawdown, max_daily_drawdown = get_daily_max_drawdown(prices, window)\ndaily_drawdown.name = \"{} daily drawdown\".format(ticker)  \n\nfig, ax = plt.subplots(figsize=(10,5))\ndaily_drawdown.plot();\nplt.legend(loc=\"best\");\nplt.show()","70819fd5":"returns = all_prices.pct_change()\nmean_daily_returns = returns.mean().values\n\np1_return = np.dot(mean_daily_returns, uniform_weigths)\np2_return = np.dot(mean_daily_returns, banks_weigths)\n\nprint(\"portfolio 1 average daily return = {:.4%}\".format(p1_return))\nprint(\"portfolio 2 average daily return = {:.4%}\".format(p2_return))","c729b762":"def get_annualized_return(prices, weigths):\n    months = (prices.index[-1] - prices.index[0]) \/ np.timedelta64(1, 'M')\n    months = np.floor(months)\n    total_return = (prices.iloc[-1].dot(weigths) - prices.iloc[0].dot(weigths)) \/ prices.iloc[0].dot(weigths)\n    annualized_return = ((1 + total_return) ** (12 \/ months)) - 1\n    return annualized_return\n\n\np1_annual_return = get_annualized_return(all_prices, uniform_weigths)\np2_annual_return = get_annualized_return(all_prices, banks_weigths)\n\ndef get_portfolio_variance(returns, weigths):\n    covariance_returns = returns.cov() * 250\n    return np.dot(weigths.T, np.dot(covariance_returns, weigths))\n\nuni_var = get_portfolio_variance(returns, uniform_weigths)\nbanks_var = get_portfolio_variance(returns, banks_weigths)\n\nprint(\"portfolio 1 annualized return = {:.4%}\".format(p1_annual_return))\nprint(\"portfolio 1 annualized variance = {:.1%}\".format(uni_var))\nprint(\"portfolio 1 annualized std = {:.1%}\".format(np.sqrt(uni_var)))\nprint()\nprint(\"portfolio 2 annualized return = {:.4%}\".format(p2_annual_return))\nprint(\"portfolio 2 annualized variance = {:.1%}\".format(banks_var))\nprint(\"portfolio 2 annualized std = {:.1%}\".format(np.sqrt(banks_var)))","16050af9":"uniform_returns = returns.dot(uniform_weigths)\nbanks_returns = returns.dot(banks_weigths)\n\nrfr = 0.0425\n\np1_vol = uniform_returns.std() * np.sqrt(250)\np2_vol = banks_returns.std() * np.sqrt(250)\n\np1_sharpe_ratio = ((p1_annual_return  - rfr) \/ p1_vol)\np2_sharpe_ratio = ((p2_annual_return  - rfr) \/ p2_vol)\n\ndef get_sortino(return_, target_return, rfr):\n    negative_return_ = return_.loc[return_ < target_return]\n    expected_return = return_.mean()\n    down_std = negative_return_.std()\n    sortino_ratio = (expected_return - rfr) \/ down_std\n    return sortino_ratio\n\n\np1_sortino_ratio = get_sortino(uniform_returns, target_return=0, rfr=rfr)\np2_sortino_ratio = get_sortino(banks_returns, target_return=0, rfr=rfr)\n\nprint(\"portfolio 1 sharpe ratio = {:.2f}\".format(p1_sharpe_ratio))\nprint(\"portfolio 1 sortino ratio = {:.2f}\".format(p1_sortino_ratio))\nprint()\nprint(\"portfolio 2 sharpe ratio = {:.2f}\".format(p2_sharpe_ratio))\nprint(\"portfolio 2 sortino ratio = {:.2f}\".format(p2_sortino_ratio))","143fd99e":"uniform_cum_returns = (1 + uniform_returns).cumprod()\nuniform_cum_returns.name = \"portifolio 1: uniform weights\"\n\nbanks_cum_returns = (1 + banks_returns).cumprod()\nbanks_cum_returns.name = \"portifolio 2: concentrated on banks\"\n\nfig, ax = plt.subplots(figsize=(16,8))\nbanks_cum_returns.plot(ax=ax, color=\"mediumorchid\");\nuniform_cum_returns.plot(ax=ax, color=\"red\");\n\nplt.legend(loc=\"best\");\nax.set_ylabel(\"cummulative return\");","a63e999f":"mu = expected_returns.mean_historical_return(all_prices)\nSigma = risk_models.sample_cov(all_prices)\nef = EfficientFrontier(mu,Sigma)\nbest_sharpe_p = pd.DataFrame(ef.max_sharpe(), index=[0])\n\nprint(\"max sharpe portfolio:\")\nshow_clean_p(best_sharpe_p)\n\n_ = ef.portfolio_performance(verbose=True, risk_free_rate=rfr)\n\nprint()\n\nmin_vol_p = pd.DataFrame(ef.min_volatility(), index=[0])\n\nprint(\"min vol portfolio:\")\nshow_clean_p(min_vol_p)\n\n_ = ef.portfolio_performance(verbose=True, risk_free_rate=rfr)\n\nmu_ema = expected_returns.ema_historical_return(all_prices, span=252, frequency=252)\nSigma_ew = risk_models.exp_cov(all_prices, span=180, frequency=252)\nef_ew = EfficientFrontier(mu_ema, Sigma_ew)\n\n\nmax_sharpe_ew_p = pd.DataFrame(ef_ew.max_sharpe(), index=[0])\n\nprint()\n\nprint(\"max sharpe portfolio with exponetially weighted returns:\")\nshow_clean_p(max_sharpe_ew_p)\n\n_ = ef_ew.portfolio_performance(verbose=True, risk_free_rate=rfr)","f0582219":"best_sharpe_weights = best_sharpe_p.values.flatten()\nbest_sharpe_returns = returns.dot(best_sharpe_weights)\nbest_sharpe_cum_returns = (1 + best_sharpe_returns).cumprod()\nbest_sharpe_cum_returns.name = \"best sharpe portfolio\"\n\n\nbest_sharpe_ew_weights = max_sharpe_ew_p.values.flatten()\nbest_sharpe_ew_returns = returns.dot(best_sharpe_ew_weights)\nbest_sharpe_ew_cum_returns = (1 + best_sharpe_ew_returns).cumprod()\nbest_sharpe_ew_cum_returns.name = \"best sharpe portfolio by ew opt\"\n\n\n\n\nmin_vol_weights = min_vol_p.values.flatten()\nmin_vol_returns = returns.dot(min_vol_weights)\nmin_vol_cum_returns = (1 + min_vol_returns).cumprod()\nmin_vol_cum_returns.name = \"minimum volatility portfolio\"\n\n\nfig, ax = plt.subplots(figsize=(16,8))\nbest_sharpe_cum_returns.plot(ax=ax, color=\"darkorange\");\nmin_vol_cum_returns.plot(ax=ax, color=\"dodgerblue\")\nbest_sharpe_ew_cum_returns.plot(ax=ax, color=\"seagreen\")\nuniform_cum_returns.plot(ax=ax, color=\"red\");\nplt.legend(loc=\"best\");\nax.set_ylabel(\"cummulative return\");\nax.set_title(\"Backtest based on the data from 2016 to 2018\", fontsize=20);","4b2d8264":"all_prices_test = []\n\nfor ticker in ibov_mini:\n    series = df_test.xs(ticker).close\n    series.name = ticker\n    all_prices_test.append(series)\n    \nreturns_test = pd.DataFrame(all_prices_test).transpose().pct_change()\n\nest_sharpe_weights = best_sharpe_p.values.flatten()\nbest_sharpe_returns = returns_test.dot(best_sharpe_weights)\nbest_sharpe_cum_returns = (1 + best_sharpe_returns).cumprod()\nbest_sharpe_cum_returns.name = \"best sharpe portfolio\"\n\nbest_sharpe_ew_weights = max_sharpe_ew_p.values.flatten()\nbest_sharpe_ew_returns = returns_test.dot(best_sharpe_ew_weights)\nbest_sharpe_ew_cum_returns = (1 + best_sharpe_ew_returns).cumprod()\nbest_sharpe_ew_cum_returns.name = \"best sharpe portfolio by ew opt\"\n\nmin_vol_weights = min_vol_p.values.flatten()\nmin_vol_returns = returns_test.dot(min_vol_weights)\nmin_vol_cum_returns = (1 + min_vol_returns).cumprod()\nmin_vol_cum_returns.name = \"minimum volatility portfolio\"\n\n\nuniform_returns = returns_test.dot(uniform_weigths)\nuniform_cum_returns = (1 + uniform_returns).cumprod()\nuniform_cum_returns.name = \"portifolio 1: uniform weights\"\n\n\nfig, ax = plt.subplots(figsize=(16,8))\nbest_sharpe_cum_returns.plot(ax=ax, color=\"darkorange\");\nmin_vol_cum_returns.plot(ax=ax, color=\"dodgerblue\")\nbest_sharpe_ew_cum_returns.plot(ax=ax, color=\"seagreen\")\nuniform_cum_returns.plot(ax=ax, color=\"red\");\nplt.legend(loc=\"best\");\nax.set_ylabel(\"cummulative return\");\nax.set_title(\"Evaluating the optimized portfolios using the data from 2019 to 2020\", fontsize=20);\n\nps_cum = [best_sharpe_cum_returns, min_vol_cum_returns, best_sharpe_ew_cum_returns]\nps = [best_sharpe_returns, min_vol_returns, best_sharpe_ew_returns]\n\nfinal_return = []\nfor p in ps_cum:\n    final_return.append(p.iloc[-1])\n    \nid_ = np.argmax(final_return)\nbest_p = ps[id_]\nbest_p.name = (ps_cum[id_]).name \n\nprint(\"Best portfolio: \",  best_p.name)\nprint(\"Final cumulative return: {:.2f} \".format(final_return[id_]))","5c4e1040":"uniform_returns.name = \"Benchmark: uniform weights\"\npf.create_returns_tear_sheet(best_p.dropna(), benchmark_rets=uniform_returns.dropna())\n","a1999852":"## Splitting the dataset","93b97d5c":"### Plotting the cummulative return","1822cddc":"### Annualized return, variance and standart deviation","4c0c1e82":"### Using the average daily return to calculate portfolio return","6d042407":"## Loading Market Data","1192cf3f":"## Using PyportfolioOpt for portfolio optimization\n\n\n### Three types of optimized portfolios:\n\n   - Maximun Sharpe portfolios\n   - Minimum volatility portfolio\n   - Maximun Sharpe portfolios obtained by exponentially weighted returns","198456a3":"### Plotting Prices Drawdown","5f8e0c71":"### Backtesting (2016-2018)","fb249e13":"## Using Pyfolio to analyse the best portfolio for 2019-2020","3c2806e9":"## First example, two naive types of portfolios:\n - **Portfolio 1**: Uniform weights\n - **Portfolio 2**: Concentrated on Banks ","d4804b93":"### Sharpe and Sortino ratio","e426bf2f":"### All Imports","e642ca29":"# Basic Notions of Portfolio Analysis","e6a5a4c1":"\n## Getting all close prices ","01fea872":"### Installing Pyfolio and PyPortfolioOpt","f91e965a":"## Selecting the tickers using a start date","908e6ebb":"## All Ibovespa Tickers","475ad280":"### Eval (2019-2020)","d6496af1":"### Useful Functions"}}