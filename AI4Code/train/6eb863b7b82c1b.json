{"cell_type":{"cb92585c":"code","09fdd0ce":"code","8c956d7f":"code","e1e48ed5":"code","93a1e22b":"code","087859e8":"code","d67efb60":"code","b4dd55fd":"code","b05a7262":"code","29a77253":"code","95b535d7":"code","25a9be50":"code","a355fff3":"code","1757178f":"code","0afe243c":"code","5ca236d9":"code","bfd74ea9":"code","bd8ac6d6":"code","f376ffd7":"code","6ca59f44":"code","4acf7150":"code","d3bc2ab9":"code","3077f7ba":"code","3b1e39ad":"code","aa0fa380":"code","a629ca31":"code","d7ff427f":"code","e9c183b7":"markdown"},"source":{"cb92585c":"#I deleted some things by mistake in the previous commit\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\ndf = pd.read_csv('\/kaggle\/input\/CORD-19-research-challenge\/2020-03-13\/all_sources_metadata_2020-03-13.csv')\ndf.head(10)\n\n","09fdd0ce":"df.info()","8c956d7f":"df.describe(include='all').T","e1e48ed5":"df.sha.head(10)","93a1e22b":"df.isnull().sum()","087859e8":"df.source_x.head(5)","d67efb60":"df.source_x.value_counts()","b4dd55fd":"pd.get_dummies(df.source_x)","b05a7262":"pd.get_dummies(df.has_full_text).iloc[:,1:]","29a77253":"df.columns","95b535d7":"short = df[['title','publish_time','abstract','authors','journal','Microsoft Academic Paper ID', 'has_full_text']]","25a9be50":"short.head()","a355fff3":"short.publish_time.value_counts()","1757178f":"short.dropna(inplace = True)","0afe243c":"short.isnull().sum()","5ca236d9":"from collections import Counter\nfrom functools import reduce\n\n#short1.apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis = 0)\n#short1.str.split().str.len()\n#short['title'].str.count(' ') + 1\ntitle_counter = Counter(\" \".join(short.title).split(\" \")).items()\nabstract_counter = Counter(\" \".join(short.abstract).split(\" \")).items()\njournal_counter = Counter(\" \".join(short.journal).split(\" \")).items()","bfd74ea9":"import nltk\nfrom nltk.corpus import stopwords\nstop_words = stopwords.words('english')\nprint(stop_words)","bd8ac6d6":"import re\ntitle_counter = re.sub(\"[^a-zA-Z]\",\" \",str(title_counter))\nabstract_counter = re.sub(\"[^a-zA-Z]\",\" \",str(abstract_counter))\njournal_counter = re.sub(\"[^a-zA-Z]\",\" \",str(journal_counter))","f376ffd7":"from nltk.tokenize import word_tokenize\ntokens0 = word_tokenize(title_counter)\ntokens0 = [w.lower() for w in tokens0]\ntokens1 = word_tokenize(abstract_counter)\ntokens1 = [w.lower() for w in tokens1]\ntokens2 = word_tokenize(journal_counter)\ntokens2 = [w.lower() for w in tokens2]\n# remove punctuation from each word\nimport string\ntable = str.maketrans('', '', string.punctuation)\nstripped0 = [w.translate(table) for w in tokens0]\nstripped1 = [w.translate(table) for w in tokens1]\nstripped2 = [w.translate(table) for w in tokens2]\n\n# remove remaining tokens that are not alphabetic\nwords0 = [word for word in stripped0 if word.isalpha()]\nwords1 = [word for word in stripped1 if word.isalpha()]\nwords2 = [word for word in stripped2 if word.isalpha()]\n\n\n# filter out stop words\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))\nwords0 = [w for w in words0 if not w in stop_words]\nwords1 = [w for w in words1 if not w in stop_words]\nwords2 = [w for w in words2 if not w in stop_words]","6ca59f44":"title_counter = Counter(\" \".join(words0).split(\" \")).items()\nabstract_counter = Counter(\" \".join(words1).split(\" \")).items()\njournal_counter = Counter(\" \".join(words2).split(\" \")).items()","4acf7150":"tc = pd.DataFrame(title_counter)\ntc.columns=[\"Word\",\"Frequency\"]\nac = pd.DataFrame(abstract_counter)\nac.columns=[\"Word\",\"Frequency\"]\njc = pd.DataFrame(journal_counter)\njc.columns=[\"Word\",\"Frequency\"]","d3bc2ab9":"tc20 = tc.head(20)","3077f7ba":"tc20.plot.bar(x='Word',y='Frequency')\nplt.show()","3b1e39ad":"ac20 = ac.head(20)","aa0fa380":"ac20.plot.bar(x='Word',y='Frequency')\nplt.show()","a629ca31":"jc20 = jc.head(20)","d7ff427f":"jc20.plot.bar(x='Word',y='Frequency')\nplt.show()","e9c183b7":"## Daniel Cruz"}}