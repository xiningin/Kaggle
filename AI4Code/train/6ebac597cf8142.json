{"cell_type":{"cbad72ee":"code","b7c65d04":"code","e3e5ae21":"code","076c252e":"code","5c09a94d":"code","7101b7be":"code","3a088cb8":"code","a33771f7":"code","edf2aae8":"code","340601f9":"code","076cc713":"code","fe357d3c":"code","15152511":"code","1ab35f0c":"code","9b3b7593":"code","805c40fc":"code","5ac5109f":"code","40993d33":"code","e1a5fab1":"code","6d57ee54":"code","c16ecc9b":"code","51e46bb6":"code","a843ebba":"code","40fb6169":"code","4318ed28":"code","26f388cb":"code","9c0859c7":"code","8e3f433e":"code","041b1a41":"code","434a941a":"code","b8bcb980":"code","76d6a3c0":"code","23d5ab37":"code","da521d73":"code","8f0ec654":"code","285bc97d":"markdown","31cc62df":"markdown","f61541ee":"markdown","7a24c3f7":"markdown","cb6406ca":"markdown","229ed1f6":"markdown","4b8cf8e6":"markdown","1aabd2e0":"markdown","508dadf9":"markdown","5dc011e6":"markdown","95146b59":"markdown"},"source":{"cbad72ee":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter(\"ignore\")","b7c65d04":"df = pd.read_csv(\"..\/input\/insurance\/insurance.csv\")\ndf.head()","e3e5ae21":"df.shape","076c252e":"df.isna().sum()","5c09a94d":"df.describe()","7101b7be":"# male : 0, female : 1\ndf[\"sex\"] = df[\"sex\"].map({\"male\":0, \"female\":1})\n\n# yes : 0, no : 1\ndf[\"smoker\"] = df[\"smoker\"].map({\"yes\":0, \"no\":1})","3a088cb8":"df.head()","a33771f7":"# Having a look at the correlation matrix\n\nfig, ax = plt.subplots(figsize=(8,6))\nsns.heatmap(df.corr(), annot=True, fmt='.1g', cmap=\"viridis\", cbar=False);","edf2aae8":"plt.style.use(\"seaborn\")\nfig, ax = plt.subplots(figsize=(7,7))\nplt.pie(x=df[\"sex\"].value_counts(), \n        colors=[\"skyblue\",\"pink\"], \n        labels=[\"Male\",\"Female\"], \n        shadow = True, \n        autopct=\"%1.2f%%\", \n        explode = (0, 0.1)\n        )\nplt.show()","340601f9":"plt.style.use(\"seaborn\")\nfig, ax = plt.subplots(figsize=(8,6))\nsns.countplot(df[\"children\"], palette=\"hls\");","076cc713":"plt.style.use(\"seaborn\")\nfig, ax = plt.subplots(figsize=(20,6))\nsns.countplot(df[\"age\"]);","fe357d3c":"plt.style.use(\"seaborn\")\nfig, ax = plt.subplots(figsize=(8,6))\nsns.histplot(x = df[\"bmi\"], color=\"purple\", kde=True);","15152511":"plt.style.use(\"seaborn\")\nfig, ax = plt.subplots(figsize=(7,7))\nplt.pie(x=df[\"smoker\"].value_counts(), \n        colors=[\"royalblue\",\"orangered\"], \n        labels=[\"Non-Smoker\",\"Smoker\"], \n        shadow = True, \n        autopct=\"%1.2f%%\", \n        explode = (0, 0.1)\n        )\nplt.show()","1ab35f0c":"plt.style.use(\"seaborn\")\nfig, ax = plt.subplots(figsize=(8,6))\nsns.countplot(df[\"region\"]);","9b3b7593":"plt.style.use(\"seaborn\")\nfig, ax = plt.subplots(figsize=(8,6))\nsns.histplot(x = df[\"charges\"], color=\"darkgreen\", kde=True);","805c40fc":"df.drop(\"region\", axis=1, inplace=True)","5ac5109f":"plt.style.use(\"seaborn\")\nfig, ax =plt.subplots(1,2, figsize=(15,5)) \n\nsns.scatterplot(x = df['age'], y = df['charges'], ax=ax[0]);\n\nsns.scatterplot(x = df['bmi'], y = df['charges'], ax=ax[1]);","40993d33":"# X data\nX = df.drop(\"charges\",axis=1)\nX.head()","e1a5fab1":"# y data\ny = df[\"charges\"]\ny.head()","6d57ee54":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","c16ecc9b":"len(X_train), len(X_test)","51e46bb6":"# Scaling the data \n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","a843ebba":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(X_train, y_train)","40fb6169":"LinearRegressionScore = lr.score(X_test, y_test)\nprint(\"Accuracy obtained by Linear Regression model:\",LinearRegressionScore*100)","4318ed28":"from sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor(n_estimators = 100)\nrf.fit(X_train,y_train)","26f388cb":"RandomForestRegressorScore = rf.score(X_test, y_test)\nprint(\"Accuracy obtained by Random Forest Regressor model:\",RandomForestRegressorScore*100)","9c0859c7":"from sklearn.tree import DecisionTreeRegressor\ntree = DecisionTreeRegressor()\ntree.fit(X_train,y_train)","8e3f433e":"DecisionTreeRegressorScore = tree.score(X_test, y_test)\nprint(\"Accuracy obtained by Decision Tree Regressor model:\",DecisionTreeRegressorScore*100)","041b1a41":"from sklearn.neighbors import KNeighborsRegressor\nknn = KNeighborsRegressor()\nknn.fit(X_train, y_train)","434a941a":"KNeighborsRegressorScore = knn.score(X_test, y_test)\nprint(\"Accuracy obtained by K Neighbors Regressor model:\",KNeighborsRegressorScore*100)","b8bcb980":"from sklearn.ensemble import AdaBoostRegressor\nada = AdaBoostRegressor()\nada.fit(X_train, y_train)","76d6a3c0":"AdaBoostRegressorScore = ada.score(X_test, y_test)\nprint(\"Accuracy obtained by AdaBoost Regressor model:\",AdaBoostRegressorScore*100)","23d5ab37":"from sklearn.ensemble import GradientBoostingRegressor\ngbr = GradientBoostingRegressor()\ngbr.fit(X_train, y_train)","da521d73":"GradientBoostingRegressorScore = gbr.score(X_test, y_test)\nprint(\"Accuracy obtained by Gradient Boosting Regressor model:\",GradientBoostingRegressorScore*100)","8f0ec654":"plt.style.use(\"seaborn\")\n\nx = [\"DecisionTreeRegressor\",\n     \"LinearRegression\", \n     \"AdaBoostRegressor\",\n     \"KNeighborsRegressor\", \n     \"RandomForestRegressor\", \n     \"GradientBoostingRegressor\"]\n\ny = [DecisionTreeRegressorScore,\n     LinearRegressionScore, \n     AdaBoostRegressorScore, \n     KNeighborsRegressorScore, \n     RandomForestRegressorScore, \n     GradientBoostingRegressorScore]\n\nfig, ax = plt.subplots(figsize=(8,6))\nsns.barplot(x=x,y=y, palette=\"crest\");\nplt.ylabel(\"Model Accuracy\")\nplt.xticks(rotation=40)\nplt.title(\"Model Comparison - Model Accuracy\", fontsize=14, fontname=\"Helvetica\", y=1.03);","285bc97d":"#### If you like my work, It will be really great of you to upvote this notebook!\n#### If not then you leaving a comment on what do I need to work on and improve will be really helpful!","31cc62df":"## KNeighborsRegressor","f61541ee":"## Random Forest Regressor","7a24c3f7":"## Loading up the data","cb6406ca":"## AdaBoost Regressor","229ed1f6":"## Importing Libraries","4b8cf8e6":"# Predicting Medical Cost \ud83d\udcdc","1aabd2e0":"## Splitting the data into training and test datasets\nHere, we are trying to predict the Insurance Charges has diabetes or not using the given data. Hence, the `charges` will be the y label and rest of the data will be the X or the input data.","508dadf9":"## Gradient Boosting Regressor","5dc011e6":"## Decision Tree Regressor","95146b59":"## Linear Regression"}}