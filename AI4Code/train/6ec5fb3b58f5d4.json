{"cell_type":{"cb4813ed":"code","d5316d48":"code","0313a6e5":"code","898d6bbc":"code","bc48c2c8":"code","83cf8de0":"code","5d65a85b":"code","ad66ad8e":"code","8d3bc3a0":"code","8afa8393":"code","4016ee29":"code","92ace292":"code","f4938887":"code","f144f74b":"code","89d185d6":"code","ca9c9f00":"code","997f9be3":"code","baf88617":"code","b6bb7670":"code","1e652409":"code","5151ab7f":"code","e8961104":"code","cf17a6c8":"code","f7ee508a":"code","e7db9d38":"code","e5576080":"code","6fd4460f":"code","9f6849de":"code","22d8ec6c":"code","303276bf":"code","84701363":"code","d6c0367a":"code","4a62d994":"code","82d932ce":"markdown","f8efb3e4":"markdown","5aaedc73":"markdown","1d28cdab":"markdown","36a1c4e6":"markdown","29ec621b":"markdown","39d09cb7":"markdown","fedb0daf":"markdown","c2de969d":"markdown","65aff002":"markdown","1fb68cb1":"markdown","4fc4feb9":"markdown","d2be6cba":"markdown","566a7910":"markdown","5d60d3ea":"markdown","4e0c85cb":"markdown","1e2a823d":"markdown"},"source":{"cb4813ed":"import json\nimport os\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport glob\nimport matplotlib.pyplot as plt\nfrom nltk.corpus import stopwords\nimport re\nimport string\nfrom wordcloud import WordCloud, STOPWORDS\nimport seaborn as sns\nwarnings.filterwarnings(\"ignore\")","d5316d48":"all_dir = os.listdir(\"..\/input\/coleridgeinitiative-show-us-the-data\")\nprint(all_dir)\ntrain_path = \"..\/input\/coleridgeinitiative-show-us-the-data\/train\"\ntest_path = \"..\/input\/coleridgeinitiative-show-us-the-data\/train\"\nsub_path = \"..\/input\/coleridgeinitiative-show-us-the-data\/sample_submission.csv\"\ntrain_path = \"..\/input\/coleridgeinitiative-show-us-the-data\/train.csv\"","0313a6e5":"train_df = pd.read_csv(train_path)  # reading csv file\ntrain_df.head(5) # get the first 5 rows","898d6bbc":"with open(\"..\/input\/coleridgeinitiative-show-us-the-data\/train\/0007f880-0a9b-492d-9a58-76eb0b0e0bd7.json\") as f:\n    sample = json.load(f)\nsample[:2]","bc48c2c8":"duplicate_df = train_df[train_df['Id'] == \"170113f9-399c-489e-ab53-2faf5c64c5bc\"].drop_duplicates(\"dataset_title\")\nduplicate_df","83cf8de0":"train_df.describe()  #get detail information about id, publication title, dataset title, dataset label.","5d65a85b":"dataset_title = train_df.groupby('Id').count()[['dataset_title']].sort_values(by = \"dataset_title\", ascending = False)\nid_pub_title = dataset_title[dataset_title['dataset_title'] >1][['dataset_title']].reset_index()","ad66ad8e":"plt.figure(figsize = (13,13))\nsns.barplot(id_pub_title['dataset_title'].iloc[:20], id_pub_title['Id'].iloc[:20])\nplt.title(\"dataset titles vs publication\")\nplt.xticks(fontsize=13)\nplt.yticks(fontsize=13)\nplt.ylabel(\"\")\nplt.xlabel(\"Count\", fontsize=14)","8d3bc3a0":"pub_title = train_df.groupby('pub_title').count()[['dataset_title']].sort_values(by = ['dataset_title'], ascending = False)\nid_title = pub_title.reset_index()\nid_title","8afa8393":"\nplt.figure(figsize = (13,13))\nsns.barplot(id_title['dataset_title'].iloc[:20], id_pub_title['Id'].iloc[:20])\nplt.title(\"dataset titles vs publication titles\")\nplt.xticks(fontsize=13)\nplt.yticks(fontsize=13)\nplt.ylabel(\"\")\nplt.xlabel(\"Count\", fontsize=14)","4016ee29":"data_title = train_df.groupby('dataset_title').count()[['dataset_label']].sort_values(by = ['dataset_title'], ascending = False)\nid_title = pub_title.reset_index()\nid_title","92ace292":"\nplt.figure(figsize = (13,13))\nsns.barplot(id_title['dataset_title'].iloc[:20], id_pub_title['Id'].iloc[:20])\nplt.title(\"dataset titles vs dataset label\")\nplt.xticks(fontsize=13)\nplt.yticks(fontsize=13)\nplt.ylabel(\"\")\nplt.xlabel(\"Count\", fontsize=14)","f4938887":"train_df.sample(5) # some  of the random samples","f144f74b":"stopwords = set(STOPWORDS)\nwordcloud = WordCloud(background_color='white',\n                      stopwords=stopwords,\n                      max_words=100,\n                      max_font_size=30,\n                      scale=3,\n                      random_state=1)\n   \nwordcloud=wordcloud.generate(str(train_df['dataset_title'].unique()))\nfig = plt.figure(1, figsize=(12, 12))\nplt.axis('off')\nplt.imshow(wordcloud)\nplt.show()","89d185d6":"def get_text(filename, test=False):\n    if test:\n        df = pd.read_json('..\/input\/coleridgeinitiative-show-us-the-data\/test\/{}.json'.format(filename))\n    else:\n        df = pd.read_json('..\/input\/coleridgeinitiative-show-us-the-data\/train\/{}.json'.format(filename))\n    text = \" \".join(list(df['text']))\n    return text","ca9c9f00":"train_df['text'] = train_df['Id'].apply(get_text)\ntrain_df.sample(5)","997f9be3":"train_df['lower'] = train_df['text'].str.lower()","baf88617":"train_df","b6bb7670":"PUNCT_TO_REMOVE = '!\"#$%&\\'()*+,-.\/:;<=>?@[\\\\]^_`{|}~\\n'\ndef remove_punctuation(text):\n    \"\"\"custom function to remove the punctuation\"\"\"\n    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n\ntrain_df[\"text_wo_punct\"] = train_df[\"lower\"].apply(lambda text: remove_punctuation(text))\ntrain_df","1e652409":"train_df.to_csv('train_df.csv', index = False)","5151ab7f":"#Stopwords = list(stopwords.words('english'))\nfrom nltk.corpus import stopwords\nStopwords = list(stopwords.words('english'))\n","e8961104":"Stopwords = list(stopwords.words('english'))\ndef remove_stopwords(text):\n    return \" \".join([word for word in str(text).split() if word not in Stopwords])\n\ntrain_df[\"text_wo_stop\"] = train_df[\"text_wo_punct\"].apply(lambda text: remove_stopwords(text))\ntrain_df.head()","cf17a6c8":"str1 = train_df['text_wo_stop'][0]\nstr2 = train_df['text'][0]\n#results\nprint(str1[:250])\nprint(str2[:250])","f7ee508a":"test_files = os.listdir('..\/input\/coleridgeinitiative-show-us-the-data\/test')\ntest = pd.DataFrame({'Id':test_files})\ntest['Id'] = test['Id'].apply(lambda x : x.split('.')[0])\ntest['text'] = test['Id'].apply(get_text, test=True)","e7db9d38":"test","e5576080":"titles = [x.lower() for x in set(train_df['dataset_title'].unique()).union(set(train_df['dataset_label'].unique()))]\n","6fd4460f":"#to clean the text data\ndef clean_text(txt):\n    return re.sub('[^A-Za-z0-9]+', ' ', str(txt).lower()).strip()","9f6849de":"submission_df = pd.read_csv(\"..\/input\/coleridgeinitiative-show-us-the-data\/sample_submission.csv\")","22d8ec6c":"#matching the string\nlabels = []\nfor index in submission_df['Id']:\n    pub_text = test[test['Id'] == index].text.str.cat(sep = '\\n').lower()\n    #print(pub_text)\n    label = []\n    for data_title in titles:\n        if data_title in pub_text:\n            label.append(clean_text(data_title))\n            \n            \n    labels.append(\"|\".join(label))","303276bf":"labels","84701363":"submission_df['PredictionString'] = labels","d6c0367a":"submission_df","4a62d994":"submission_df.to_csv('submission.csv', index = False)","82d932ce":"**Now lets concat the text in json file with our train csv file**","f8efb3e4":"**word with larger size are repeated the most in the dataset title\nsimilary you can plot the sane wordcloud for the text data**","5aaedc73":"**from above it is clear that each id has more than one dataset labels which may also belong to different Id**","1d28cdab":"# Lets understand the data #\n\n1. The objective of the competition is to identify the mention of datasets within scientific publications.\n2. The predictions will be short excerpts from the publications that appear to note a dataset.\n\n**Files present in our dataset**\n\n* train - the full text of the training set's publications in JSON format, broken into sections with section titles\n* test - the full text of the test set's publications in JSON format, broken into sections with section titles\n* train.csv - labels and metadata for the training set\n* sample_submission.csv - a sample submission file in the correct format\n","36a1c4e6":"# Text Preprocessing(optional)","29ec621b":"# String Matching\n\nNow we have to get all the dataset titles from the csv file and use the same dataset titles for getting predictions over test files","39d09cb7":"***removing stopwords***","fedb0daf":"**columns in csv files**\n\n* id - publication id - note that there are multiple rows for some training documents, indicating multiple mentioned datasets\n* pub_title - title of the publication (a small number of publications have the same title)\n* dataset_title - the title of the dataset that is mentioned within the publication\n* dataset_label - a portion of the text that indicates the dataset\n* cleaned_label - the dataset_label, as passed through the clean_text function from the Evaluation page\n","c2de969d":"**All necessary libraries**","65aff002":"# Word cloud representation","1fb68cb1":"**Now check how many different dataset title are present with different label**","4fc4feb9":"**Similarly we can get for the publication title vs dataset title**","d2be6cba":"***removing punctuation***\n\n\nwe also need to remove the punctuation symbols from the text.\n\npunctuation in python contains the following punctuation symbols\n\n!\"#$%&\\'()*+,-.\/:;<=>?@[\\\\]^_{|}~`\n\nWe can add or remove more punctuations as per our need.","566a7910":" **let us check the Id having different dataset labels**","5d60d3ea":"**Thankyou for having patience and reading my notebook\nplease upvote if you understood**\n\n**Credits:**\nhttps:\/\/www.kaggle.com\/anthokalel\/coleridge-complete-eda","4e0c85cb":"**** main aim of the competition is to get the dataset label for the particular publication which is provied in json format and use the same dataset labels to get prediction for the test dataset ****","1e2a823d":"***lower casing the text***"}}