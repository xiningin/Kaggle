{"cell_type":{"d6a1c9c2":"code","1eb8b91a":"code","a82d0058":"code","e7fc4191":"code","e738b70c":"code","2b361758":"code","48cbf80c":"code","fca76f7a":"code","f9883d4f":"code","e77fb958":"code","e81cceac":"code","767aaa75":"code","696c729c":"code","df72b7f5":"code","3c303a78":"code","d8634ed0":"code","1b17d7e2":"code","ca307d26":"markdown","dd4a068e":"markdown","f06fe6f0":"markdown","5f41b961":"markdown","5bc47f71":"markdown","5aaf369e":"markdown","b4a2536e":"markdown","d22bc632":"markdown","91822420":"markdown","7320a7a0":"markdown"},"source":{"d6a1c9c2":"# for TPU\n!curl https:\/\/raw.githubusercontent.com\/pytorch\/xla\/master\/contrib\/scripts\/env-setup.py -o pytorch-xla-env-setup.py\n!python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev","1eb8b91a":"!pip install efficientnet_pytorch > \/dev\/null\n!pip install albumentations > \/dev\/null","a82d0058":"import warnings\nimport torch_xla\nimport torch_xla.debug.metrics as met\nimport torch_xla.distributed.data_parallel as dp\nimport torch_xla.distributed.parallel_loader as pl\nimport torch_xla.utils.utils as xu\nimport torch_xla.core.xla_model as xm\nimport torch_xla.distributed.xla_multiprocessing as xmp\nimport torch_xla.test.test_utils as test_utils\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")","e7fc4191":"import torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nimport operator\nfrom PIL import Image \nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom torchvision.transforms import ToTensor, RandomHorizontalFlip, Resize\nfrom efficientnet_pytorch import EfficientNet\nfrom transformers import AdamW, get_cosine_schedule_with_warmup\nfrom albumentations import *\nfrom albumentations.pytorch import ToTensor\nfrom tqdm import tqdm\nimport json\nimport time","e738b70c":"BASE_DIR = '..\/input\/plant-pathology-2020-fgvc7\/'","2b361758":"train_df = pd.read_csv(BASE_DIR +'train.csv')","48cbf80c":"train_df.head()","fca76f7a":"train_df['image_id'] = BASE_DIR + 'images\/' + train_df['image_id'] + '.jpg'","f9883d4f":"train_df['label'] = [np.argmax(label) for label in train_df[['healthy','multiple_diseases','rust','scab']].values]","e77fb958":"train_df.head()","e81cceac":"class SimpleDataset(Dataset):\n    def __init__(self, image_ids_df, labels_df, transform=None):\n        self.image_ids = image_ids_df\n        self.labels = labels_df\n        self.transform = transform\n        \n    def __getitem__(self, idx):\n        image = cv2.imread(self.image_ids.values[idx])\n        label = self.labels.values[idx]\n        \n        sample = {\n            'image': image,\n            'label': label\n        }\n        \n        if self.transform:\n            sample = self.transform(**sample)\n        \n        image, label = sample['image'], sample['label']\n        \n        return image, label\n    \n    def __len__(self):\n        return len(self.image_ids)\n    \n\n        ","767aaa75":"image_ids = train_df['image_id']\nlabels = train_df['label']","696c729c":"X_train, X_test, y_train, y_test = train_test_split(image_ids, labels, test_size=0.25, random_state=42)","df72b7f5":"train_transform = Compose(\n    [\n        Resize(224, 224),\n        HorizontalFlip(p=0.5),\n        VerticalFlip(p=0.5),\n#         ShiftScaleRotate(rotate_limit=25.0, p=0.7),\n#         OneOf(\n#             [\n#                 IAAEmboss(p=1),\n#                 IAASharpen(p=1),\n#                 Blur(p=1)\n#             ], \n#             p=0.5\n#         ),\n#         IAAPiecewiseAffine(p=0.5),\n        Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225), always_apply=True),\n        ToTensor()\n    ]\n)","3c303a78":"model = EfficientNet.from_pretrained('efficientnet-b5', num_classes=4)","d8634ed0":"def _run(model):\n     \n    def train_fn(epoch, train_dataloader, optimizer, criterion, scheduler, device):\n\n        running_loss = 0\n        total = 0\n        model.train()\n\n        for batch_idx, (images, labels) in enumerate(train_dataloader, 1):\n\n            optimizer.zero_grad()\n            images = images.to(device)\n            labels = labels.to(device)\n\n            outputs = model(images)\n\n            loss = criterion(outputs, labels)\n\n            xm.master_print(f'Batch: {batch_idx}, loss: {loss.item()}')\n\n            loss.backward()\n            xm.optimizer_step(optimizer)\n\n            lr_scheduler.step()\n\n    def valid_fn(epoch, valid_dataloader, criterion, device):\n\n        running_loss = 0\n        total = 0\n        preds_acc = []\n        labels_acc = []\n\n        model.eval()\n\n        for batch_idx, (images, labels) in enumerate(valid_dataloader, 1):\n\n            images = images.to(device)\n            labels = labels.to(device)\n\n            outputs = model(images)\n\n            loss = criterion(outputs, labels)\n            \n            xm.master_print(f'Batch: {batch_idx}, loss: {loss.item()}')\n\n            running_loss += loss.item()\n    \n    \n    EPOCHS = 20\n    BATCH_SIZE = 64\n    \n    train_dataset = SimpleDataset(X_train, y_train, transform=train_transform)\n    valid_dataset = SimpleDataset(X_test, y_test, transform=train_transform)\n    \n    train_sampler = torch.utils.data.distributed.DistributedSampler(\n          train_dataset,\n          num_replicas=xm.xrt_world_size(),\n          rank=xm.get_ordinal(),\n          shuffle=True)\n    valid_sampler = torch.utils.data.distributed.DistributedSampler(\n          valid_dataset,\n          num_replicas=xm.xrt_world_size(),\n          rank=xm.get_ordinal(),\n          shuffle=False)\n\n    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, num_workers=1)\n    valid_dataloader = DataLoader(valid_dataset, batch_size=32, sampler=valid_sampler, num_workers=1)\n    \n    device = xm.xla_device()\n    model = model.to(device)\n    \n    lr = 0.4 * 1e-5 * xm.xrt_world_size()\n    criterion = nn.CrossEntropyLoss()\n    \n    optimizer = AdamW(model.parameters(), lr=lr)\n    num_train_steps = int(len(train_dataset) \/ BATCH_SIZE \/ xm.xrt_world_size() * EPOCHS)\n    xm.master_print(f'num_train_steps = {num_train_steps}, world_size={xm.xrt_world_size()}')\n    num_train_steps = int(len(train_dataset) \/ BATCH_SIZE * EPOCHS)\n    lr_scheduler = get_cosine_schedule_with_warmup(\n        optimizer,\n        num_warmup_steps=0,\n        num_training_steps=num_train_steps\n    )\n    \n    train_loss = []\n    valid_loss = []\n    best_loss = 1\n    \n    train_begin = time.time()\n    for epoch in range(EPOCHS):\n        \n        para_loader = pl.ParallelLoader(train_dataloader, [device])\n\n        start = time.time()\n        print('*'*15)\n        print(f'EPOCH: {epoch+1}')\n        print('*'*15)\n\n        print('Training.....')\n        train_fn(epoch=epoch+1, \n                                  train_dataloader=para_loader.per_device_loader(device), \n                                  optimizer=optimizer, \n                                  criterion=criterion,\n                                  scheduler=lr_scheduler,\n                                  device=device)\n\n\n        \n        with torch.no_grad():\n            \n            para_loader = pl.ParallelLoader(valid_dataloader, [device])\n            \n            print('Validating....')\n            valid_fn(epoch=epoch+1, \n                                      valid_dataloader=para_loader.per_device_loader(device), \n                                      criterion=criterion, \n                                      device=device)\n            xm.save(\n                model.state_dict(),\n                f'efficientnet-b0-bs-8.pt'\n            )\n    \n        print(f'Epoch completed in {(time.time() - start)\/60} minutes')\n    print(f'Training completed in {(time.time() - train_begin)\/60} minutes')","1b17d7e2":"# Start training processes\ndef _mp_fn(rank, flags):\n    torch.set_default_tensor_type('torch.FloatTensor')\n    a = _run(model)\n\nFLAGS={}\nxmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')","ca307d26":"# My observations:\n1. torch.xla has it's own specific requirements. U can't simply make a device using `xm.xla_device()` and pass the model to it. \n<br\/><br\/>\nWith that:\n    1. Optimizer has to stepped with `xm.optimizer_step(optimizer)`.\n    2. You have to save the model with `xm.save(model.state_dict(), '<your-model-name>)`\n    3. You have to use `xm.master_print(...)` to print. This you can try for yourself below. Try to change \n       the `xm.master_print(f'Batch: {batch_idx}, loss: {loss.item()}')` in the training function(`train_fn()`) to simple \n       `print(f'Batch: {batch_idx}, loss: {loss.item()}')`. You will see it deos not get printed.\n    4. For parellel training we first define the distributed train & valid sampler, then we wrap the dataloaders in `torch_xla.distributed.parallel_loader(<your-data-loader>)` and create a `torch_xla.distributed.parallel_loader` object \n    5. While passing it to training and validation function we specify this `para_loader.per_device_loader(device)`. This is what you will iterate over in the training function, i.e. we pass a parelleloader and not a dataloader (for parellel training only).","dd4a068e":"### Torch XLA setup","f06fe6f0":"## Splitting the dataset:\nI split the datset simply using sklearn's train_test_split()","5f41b961":"## Below cell is what makes the model train on all 8 cores! Run yourself to see the magic","5bc47f71":"# Simple PyTorch Training\n\n1. In this part let's try simple pytorch model and train it for 20 epochs straight without CV.\n2. The model of my choice is: 'EfficientNet-b5'.\n3. Parellely training on all 8 cores","5aaf369e":"# Prolouge:\n### Welcome to my kaggle adventures of learning how to use a tpu in kaggle. Let's learn together.\nHey there, This is a kernel to teach you how to train on a tpu in kaggle on all cores parellely. This a work in progress kernel as I will keep it updating as I learn new things!  ","b4a2536e":"## Code taken from [https:\/\/www.kaggle.com\/abhishek\/bert-multi-lingual-tpu-training-8-cores-w-valid](http:\/\/) and modified for this comeptetion. Thank you [Abhishek](http:\/\/www.kaggle.com\/abhishek) :)","d22bc632":"# Epilouge: \n\n1. With parellely running on all 8 cores, my training time was 15 minutes (20 epochs) with a batch size of 64 for training and 32 for validation, as opposed to 1 hr on my local device (which has a gtx 1050 with 4 gb memory) with a batch size of 8 for both training and validation. Okay I get it, it's not a fair comparison as we have a more powerful gpu on kaggle, but I am guessing you get what I am trying to say. :P  \n2. This kernel was for me to keep as a future reference, but I want to share it with all of you. You are the ones from whom I learn so much.\n3. About the accuracy and inference that I haven't done and I am currently working on. I just ran it once to see how long it takes. :P\n\nYou're free to correct me, make suggestions and tell me on what I can improve on. :) \nLastly if u found it any useful please consider to upvote :)\n\nAlso for more information: [Torch XLA documentation](https:\/\/pytorch.org\/xla\/release\/1.5\/index.html#)","91822420":"### make training labels by taking argmax\n","7320a7a0":"### Imports required for TPU"}}