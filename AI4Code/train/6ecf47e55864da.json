{"cell_type":{"05e5b2ad":"code","8bbbbaf1":"code","b09de69c":"code","4892041a":"code","b3fdb4fb":"code","d4f4a1a7":"code","5e536e4f":"code","4c1b9149":"code","44662f9c":"code","6eafe36f":"code","6b3b4fb3":"code","3b3d3ddb":"code","52d687ee":"code","4061ff97":"code","9a4e2bc5":"code","a0cba4ff":"code","3765d478":"code","66715213":"code","eb53ed12":"code","e7d2314b":"code","39fca02e":"code","56c65ef6":"code","6b7c7df4":"code","45a0d913":"code","5af363e9":"code","0d69e39a":"code","52940ec0":"code","3a8b7e19":"code","2a1ea753":"code","7b77d80c":"code","3b3f6a84":"code","72959576":"code","b9e25836":"code","30d6153c":"code","57656b1d":"code","2b66b18c":"markdown","e620eace":"markdown","acd87cdc":"markdown","eb553331":"markdown","5ef2c9c2":"markdown","5e6a483c":"markdown","0d5e65ca":"markdown","86f73c0c":"markdown","b5e32756":"markdown","12293c25":"markdown","bb3af710":"markdown","bb8e40a9":"markdown","0a822774":"markdown","23bec658":"markdown","6f51f076":"markdown","40ec397d":"markdown","9ecb257d":"markdown","7fe55e44":"markdown","6e61dd8c":"markdown","bee5c38c":"markdown","ab110c41":"markdown","cdaeaea6":"markdown","63d26a3b":"markdown","d88e8265":"markdown","6c4de961":"markdown","416e1672":"markdown"},"source":{"05e5b2ad":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold, KFold\nimport matplotlib.pyplot as plt \nfrom sklearn.metrics import roc_auc_score\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 500)\n\nimport lightgbm\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\n\n# Any results you write to the current directory are saved as output.","8bbbbaf1":"drop_cols = ['encounter_id','patient_id','icu_id', 'hospital_id', 'readmission_status']\ndrop_cols_test = ['encounter_id','patient_id','icu_id','hospital_death','hospital_id', 'readmission_status']\n\ntrain = pd.read_csv(\"\/kaggle\/input\/widsdatathon2020\/training_v2.csv\").drop(drop_cols, axis=1)\n# sample_submission = pd.read_csv(\"\/kaggle\/input\/widsdatathon2020\/samplesubmission.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/widsdatathon2020\/unlabeled.csv\").drop(drop_cols_test, axis=1)\ndata_dictionary = pd.read_csv(\"\/kaggle\/input\/widsdatathon2020\/WiDS Datathon 2020 Dictionary.csv\")\nsolution_template = pd.read_csv(\"\/kaggle\/input\/widsdatathon2020\/solution_template.csv\")\n\ntarget = 'hospital_death'","b09de69c":"print(f'Rows in train data : {train.shape[0]} and columns in train data: {train.shape[1]}')\nprint(f'Rows in test data  : {test.shape[0]} and columns in train data: {test.shape[1]}')","4892041a":"np.round(train[target].value_counts()*100\/len(train[target]),2)","b3fdb4fb":"ax = sns.countplot(train[target])\nfor p in ax.patches:\n    ax.annotate('{}'.format(p.get_height()), (p.get_x()+0.15, p.get_height()+1))\nplt.show()","d4f4a1a7":"train.info()","5e536e4f":"train.head()","4c1b9149":"np.round(train.isna().mean()*100,2)","44662f9c":"np.round(test.isna().mean()*100,2)","6eafe36f":"train.dtypes","6b3b4fb3":"train.select_dtypes(include='O').columns.values.tolist()","3b3d3ddb":"test.select_dtypes(include='O').columns.values.tolist()","52d687ee":"def explore_variable(col_name):\n    \"\"\"\n    Helper function for categorical variable\n    \"\"\"\n    print(f\"Unique values in train: {train[col_name].unique()}\")\n    print(f\"Unique values in test:  {test[col_name].unique()}\")\n    print(f\"Number of unique values in train : {train[col_name].nunique()}\") \n    print(f\"Number of unique values in test: {test[col_name].nunique()}\")\n\ndef count_plot(col_name, fig_size=(10,10)):\n    \"\"\"\n    Helper function for count plot. \n    Here in count plot I have ordered by train[col].value_counts so it is easy compare distribution between train and test\n    \"\"\"\n    fig = plt.figure(figsize=fig_size)\n    fig.add_subplot(2,1,1)            \n    ax1 = sns.countplot(x=col_name, data=train, order = train[col_name].value_counts().index)\n    for p in ax1.patches:\n        ax1.annotate('{}'.format(p.get_height()), (p.get_x()+0.15, p.get_height()+1))\n    ax1.set_title(\"Train distribution\", fontsize='large')\n    ax1.set_ylabel(col_name)\n    fig.add_subplot(2,1,2)            \n    ax2 = sns.countplot(x=col_name, data=test, order = train[col_name].value_counts().index)\n    ax2.set_title(\"Test distribution\", fontsize='large')\n    ax2.set_ylabel(col_name)\n    for p in ax2.patches:\n        ax2.annotate('{}'.format(p.get_height()), (p.get_x()+0.15, p.get_height()+1))\n    \n    plt.show()                        ","4061ff97":"explore_variable('ethnicity')","9a4e2bc5":"count_plot(col_name ='ethnicity', fig_size=(20,10))","a0cba4ff":"explore_variable('age')","3765d478":"count_plot(col_name ='age', fig_size=(40,15))","66715213":"explore_variable('hospital_admit_source')","eb53ed12":"count_plot(col_name ='hospital_admit_source', fig_size=(30,12))","e7d2314b":"explore_variable('icu_admit_source')","39fca02e":"count_plot(col_name ='icu_admit_source', fig_size=(30,12))","56c65ef6":"explore_variable('icu_stay_type')","6b7c7df4":"count_plot(col_name ='icu_stay_type', fig_size=(30,10))","45a0d913":"explore_variable('icu_type')","5af363e9":"count_plot(col_name ='icu_type', fig_size=(20,10))","0d69e39a":"explore_variable('apache_3j_bodysystem')","52940ec0":"count_plot(col_name ='apache_3j_bodysystem', fig_size=(25,12))","3a8b7e19":"explore_variable('apache_2_bodysystem')","2a1ea753":"count_plot(col_name ='apache_2_bodysystem', fig_size=(25,12))","7b77d80c":"cat_cols =  train.select_dtypes(include='O').columns.values.tolist()\nfor col in cat_cols: \n    if col in train.columns: \n        le = LabelEncoder() \n        le.fit(list(train[col].astype(str).values) + list(test[col].astype(str).values)) \n        train[col] = le.transform(list(train[col].astype(str).values)) \n        test[col] = le.transform(list(test[col].astype(str).values)) ","3b3f6a84":"y=train[target]\ntrain=train.drop(target, axis=1)","72959576":"# Parameters\nparams = {\"objective\": \"binary\", \n          \"boosting\": \"gbdt\",\n          \"metric\": \"auc\",\n          \"n_jobs\":-1,\n          \"verbose\":-1}\n\nnum_folds = 10\nroc_auc = list()\nfeature_importances = pd.DataFrame()\nfeature_importances['feature'] = train.columns\npred_on_test = np.zeros(test.shape[0])\n\n\nkf = StratifiedKFold(n_splits=num_folds,shuffle=True, random_state=2020)\nfor index, (train_index, valid_index) in enumerate(kf.split(X=train,y=y)):\n    print(f\"FOLD {index+1}\")\n\n    X_train_fold, y_train_fold = train.iloc[train_index], y.iloc[train_index]\n    X_valid_fold, y_valid_fold = train.iloc[valid_index], y.iloc[valid_index]\n\n    dtrain = lightgbm.Dataset(X_train_fold, label=y_train_fold)\n    dvalid = lightgbm.Dataset(X_valid_fold, label=y_valid_fold)\n\n    lgb = lightgbm.train(params=params, train_set=dtrain, num_boost_round=2000, \n                         valid_sets=[dtrain, dvalid], verbose_eval=250, early_stopping_rounds=500)\n\n    feature_importances[f'fold_{index + 1}'] = lgb.feature_importance()\n\n    y_valid_pred = (lgb.predict(X_valid_fold,num_iteration=lgb.best_iteration))\n    pred_on_test += (lgb.predict(test,num_iteration=lgb.best_iteration)) \/ num_folds\n\n    # winsorization\n    y_valid_pred = np.clip(a=y_valid_pred, a_min=0, a_max=1)\n    pred_on_test = np.clip(a=pred_on_test, a_min=0, a_max=1)\n\n    print(f\"FOLD {index+1}: ROC_AUC  => {np.round(roc_auc_score(y_true=y_valid_fold, y_score=y_valid_pred),5)}\")\n    roc_auc.append(roc_auc_score(y_true=y_valid_fold, y_score=y_valid_pred)\/num_folds)\n    \nprint(f\"Mean roc_auc for {num_folds} folds: {np.round(sum(roc_auc),5)}\")","b9e25836":"def plot_feature_importance(df, k_fold_object):\n    df['average_feature_imp'] = df[['fold_{}'.format(fold + 1) for fold in range(k_fold_object.n_splits)]].mean(axis=1)\n    plt.figure(figsize=(10, 40))\n    sns.barplot(data=df.sort_values(by='average_feature_imp', ascending=False), x='average_feature_imp', y='feature');\n    plt.title('Feature importance over {} folds average'.format(k_fold_object.n_splits))\n    plt.show()","30d6153c":"plot_feature_importance(df=feature_importances, k_fold_object=kf)","57656b1d":"solution_template.hospital_death = pred_on_test\nsolution_template.to_csv(\"Version_1.csv\", index=0)","2b66b18c":"#### 91.37% of data belong to class 0 and 8.63% of data belong to class 1. Clear imbalance, so it's necessary to setup proper validation scheme. That's why I'll use Stratified K Fold cross validation. ","e620eace":"# In this kernel I'll explore data with no cleaning and FE and see areas of improvement.","acd87cdc":"### Data types in our data","eb553331":"## Columns dropped: encounter_id, patient_id, hospital_id and icu_id and readmission status:\n1. ID columns seem to be noise here.\n2. Readmission status has only value in both train and test. Not carrying useful information.\n ","5ef2c9c2":"### One extra column in train data is hospital_death ","5e6a483c":"# Feature Importance","0d5e65ca":"### We can see there are lots of missing values in our data. **Proper filling of missing values can definitely boost up score.**","86f73c0c":"## 6. icu_type","b5e32756":"## Percentage of missing values in each column","12293c25":"## 5. icu_stay_type","bb3af710":"# Key Points \n1. Here Undefined diagnoses and Undefined Diagnoses can be combined to one category \n2. Some categories can be grouped to create one category to avoid low sample count.","bb8e40a9":"# EDA ","0a822774":"## 2. Age","23bec658":"# Label Encoding ","6f51f076":"## 3. hospital_admit_source","40ec397d":"# Model building","9ecb257d":"### Object columns in our data ","7fe55e44":"# Helper functions","6e61dd8c":"## 7. apache_3j_bodysystem","bee5c38c":"## 8. apache_2_bodysystem","ab110c41":"## Imports","cdaeaea6":"## Test data","63d26a3b":"## 1. Ethnicity","d88e8265":"## 4. icu_admit_source","6c4de961":"## Train data","416e1672":"# Check target distribution"}}