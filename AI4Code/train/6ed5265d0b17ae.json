{"cell_type":{"ddcdc562":"code","a0564b90":"code","c0d731f3":"code","21f2fe1c":"code","f166de88":"code","4462a7bc":"code","337e79a6":"code","a9564cf7":"code","ee8d0e38":"code","139b9dd4":"code","96e2afe2":"code","2ea684dd":"code","d55c450c":"code","17e10eea":"code","4edcc97f":"code","0181bad6":"code","ffd3ac54":"code","724603ca":"code","6f1d8c01":"code","110a6d68":"markdown","84a280dc":"markdown","0d1d53e0":"markdown","442b3910":"markdown","8810c9fe":"markdown"},"source":{"ddcdc562":"import numpy as np\nimport pandas as pd\nimport cv2\nimport re\nfrom tqdm.notebook import tqdm\nfrom PIL import Image\nimport hashlib\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set()\n\nDIR_INPUT = '\/kaggle\/input\/global-wheat-detection'\nDIR_TRAIN_IMAGES = f'{DIR_INPUT}\/train'","a0564b90":"train_df = pd.read_csv(f'{DIR_INPUT}\/train.csv')\ntrain_df.shape","c0d731f3":"train_df.head()","21f2fe1c":"train_df['image_id'].nunique()","f166de88":"train_df['height'].value_counts(), train_df['width'].value_counts()","4462a7bc":"def calculate_hash(im):\n    md5 = hashlib.md5()\n    md5.update(np.array(im).tostring())\n    \n    return md5.hexdigest()\n    \ndef get_image_meta(image_id, image_src, dataset='train'):\n    im = Image.open(image_src)\n    extrema = im.getextrema()\n\n    meta = {\n        'image_id': image_id,\n        'dataset': dataset,\n        'hash': calculate_hash(im),\n        'r_min': extrema[0][0],\n        'r_max': extrema[0][1],\n        'g_min': extrema[1][0],\n        'g_max': extrema[1][1],\n        'b_min': extrema[2][0],\n        'b_max': extrema[2][1],\n        'height': im.size[0],\n        'width': im.size[1],\n        'format': im.format,\n        'mode': im.mode\n    }\n    return meta","337e79a6":"data = []\n\nfor i, image_id in enumerate(tqdm(train_df['image_id'].unique(), total=train_df['image_id'].unique().shape[0])):\n    data.append(get_image_meta(image_id, DIR_TRAIN_IMAGES + '\/{}.jpg'.format(image_id)))","a9564cf7":"meta_df = pd.DataFrame(data)\nmeta_df.head()","ee8d0e38":"duplicates = meta_df.groupby(by='hash')[['image_id']].count().reset_index()\nduplicates = duplicates[duplicates['image_id'] > 1]\nduplicates.reset_index(drop=True, inplace=True)\n\nduplicates = duplicates.merge(meta_df[['image_id', 'hash']], on='hash')\n\nduplicates.head(20)","139b9dd4":"train_df['x'] = -1\ntrain_df['y'] = -1\ntrain_df['w'] = -1\ntrain_df['h'] = -1\n\ndef expand_bbox(x):\n    r = np.array(re.findall(\"([0-9]+[.]?[0-9]*)\", x))\n    if len(r) == 0:\n        r = [-1, -1, -1, -1]\n    return r\n\ntrain_df[['x', 'y', 'w', 'h']] = np.stack(train_df['bbox'].apply(lambda x: expand_bbox(x)))\ntrain_df.drop(columns=['bbox'], inplace=True)\ntrain_df['x'] = train_df['x'].astype(np.float)\ntrain_df['y'] = train_df['y'].astype(np.float)\ntrain_df['w'] = train_df['w'].astype(np.float)\ntrain_df['h'] = train_df['h'].astype(np.float)","96e2afe2":"train_df","2ea684dd":"train_df.groupby(by='image_id')['source'].count().agg(['min', 'max', 'mean'])","d55c450c":"source = train_df['source'].value_counts()\nsource","17e10eea":"fig = go.Figure(data=[\n    go.Pie(labels=source.index, values=source.values)\n])\n\nfig.update_layout(title='Source distribution')\nfig.show()","4edcc97f":"def show_images(image_ids):\n    \n    col = 5\n    row = min(len(image_ids) \/\/ col, 5)\n    \n    fig, ax = plt.subplots(row, col, figsize=(16, 8))\n    ax = ax.flatten()\n\n    for i, image_id in enumerate(image_ids):\n        image = cv2.imread(DIR_TRAIN_IMAGES + '\/{}.jpg'.format(image_id))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        ax[i].set_axis_off()\n        ax[i].imshow(image)\n        ax[i].set_title(image_id)\n        \ndef show_image_bb(image_data):\n    \n    fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n    \n    image = cv2.imread(DIR_TRAIN_IMAGES + '\/{}.jpg'.format(image_data.iloc[0]['image_id']))\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n    for i, row in image_data.iterrows():\n        \n        cv2.rectangle(image,\n                      (int(row['x']), int(row['y'])),\n                      (int(row['x']) + int(row['w']), int(row['y']) + int(row['h'])),\n                      (220, 0, 0), 3)\n\n    ax.set_axis_off()\n    ax.imshow(image)\n    ax.set_title(image_id)","0181bad6":"show_images(train_df.sample(n=15)['image_id'].values)","ffd3ac54":"show_image_bb(train_df[train_df['image_id'] == '5e0747034'])","724603ca":"show_image_bb(train_df[train_df['image_id'] == '5b13b8160'])","6f1d8c01":"show_image_bb(train_df[train_df['image_id'] == '1f2b1a759'])","110a6d68":"# Gloabl Wheat Detection - EDA\n\n![GWD](https:\/\/albumizr.com\/ia\/68bce2e2687097c61faee360dc1dce79.jpg)\n\n> In this competition, you\u2019ll detect wheat heads from outdoor images of wheat plants, including wheat datasets from around the globe. Using worldwide data, you will focus on a generalized solution to estimate the number and size of wheat heads. To better gauge the performance for unseen genotypes, environments, and observational conditions, the training dataset covers multiple regions. You will use more than 3,000 images from Europe (France, UK, Switzerland) and North America (Canada). The test data includes about 1,000 images from Australia, Japan, and China.\n","84a280dc":"Great! No duplications!","0d1d53e0":"## Image meta\n- We have 3373 unique images in the train dataset\n- It seems all of the images hav the same size (1024x1024)\n- Minimum number of bbox per image: 0\n- Maximum number of bbox per image: 116\n- Average number of bbox per image: 43.82\n- No duplicated images (in train)","442b3910":"### Duplications","8810c9fe":"## Extract bounding box data"}}