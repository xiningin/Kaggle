{"cell_type":{"9482fc92":"code","e94f399a":"code","dcf1d6b4":"code","f711eb9d":"code","bd79b8af":"code","e8061347":"code","680959ad":"code","8a8a5a6d":"code","b2942504":"code","eddcdba0":"code","8e73a332":"code","7004e491":"code","95597341":"code","e4c53445":"code","9a9e7fa5":"code","b0135e20":"code","d45ebc4d":"code","7b0f29bd":"code","36f85f69":"code","e1228ff7":"code","33a2d6a7":"code","5abb8686":"code","e1dfa6f5":"code","20e089d5":"code","e8c40dbb":"code","24f18257":"code","0c1d2f0f":"code","167830f2":"code","aa7f8546":"code","61bdc300":"code","7d9a37cf":"code","6fab0b07":"code","fec03f36":"code","00d1f027":"code","2ba93a4e":"code","80ee5122":"code","2c17aaac":"code","ea8b4a7e":"code","b3d5cbb1":"code","5e51c542":"code","9f49666c":"code","bbddb2ae":"code","37f105f7":"code","56edfd54":"code","faafe031":"code","0ca5dff6":"markdown","defe474e":"markdown","fa1d1eb3":"markdown","626bed78":"markdown","12a98d8c":"markdown","1a8d0dbe":"markdown","faad6eba":"markdown","b3276e47":"markdown","9a0c4837":"markdown","bfd03707":"markdown","0a4ba3dd":"markdown","7f20434e":"markdown","c82cccc6":"markdown","84baee3a":"markdown","6a4dd34b":"markdown","00a7cb0f":"markdown","f0ca648d":"markdown","fab1944a":"markdown"},"source":{"9482fc92":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e94f399a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics","dcf1d6b4":"# read the raw data\ndf_original = pd.read_csv('\/kaggle\/input\/cardiovascular-disease-dataset\/cardio_train.csv', sep = ';')\ndf_original.sample(7)","f711eb9d":"df = df_original.copy()\ndf.info()","bd79b8af":"# there is no missing values in this dataset, checking for duplicated rows\ndf.duplicated().any()","e8061347":"# changing the age column into year\ndf['age'] = df['age'].map(lambda x: round(x\/365))","680959ad":"df.describe().T[1:]    #excluding the id column","8a8a5a6d":"# plotting histogram for quick view\nfigure = plt.figure(figsize=(12,10))\n\nax1 = plt.subplot(221)\nax1 = plt.hist(df['height'], bins=50)\nax1 = plt.title('height')\n\nax2 = plt.subplot(222)\nax2 = plt.hist(df['weight'], bins=50)\nax2 = plt.title('weight')\n\nax3 = plt.subplot(223)\nax3 = plt.hist(df['ap_hi'], bins=30)\nax3 = plt.title('ap_hi')\n\nax4 = plt.subplot(224)\nax4 = plt.hist(df['ap_lo'], bins=30)\nax4 = plt.title('ap_lo')\n\nplt.show()\n\n# the extreme values in column ap_hi and ap_lo affected the range of x in historgrams","b2942504":"# to remove values more than 1.5 times the Inter Quartile Range (IQR) variable values\ndef outliers_iqr(ys):\n    quartile1, quartile3 = np.percentile(ys, [25,75])\n    iqr = quartile3 - quartile1\n    lower_bound = quartile1 - (iqr*3)\n    upper_bound = quartile3 + (iqr*3)\n    \n    print(f'Q1:{quartile1}, Q3:{quartile3}, IQR:{iqr}')\n    print(f'Lower Bound:{lower_bound}, Upper Bound:{upper_bound}')\n    \n    result = np.where((ys > upper_bound) | (ys < lower_bound))\n    boundary = (lower_bound, upper_bound)\n    \n    print(f'Number of outliers: {len(result[0])}')\n    \n    return result, boundary","eddcdba0":"height_outlier_index = list(outliers_iqr(df['height'])[0][0])\ndf_height_outlier = df.iloc[height_outlier_index,:]\ndf_height_outlier","8e73a332":"weight_outlier_index = list(outliers_iqr(df['weight'])[0][0])\ndf_weight_outlier = df.iloc[weight_outlier_index,:]\ndf_weight_outlier","7004e491":"ap_hi_outlier_index = list(outliers_iqr(df['ap_hi'])[0][0])\ndf_aphi_outlier = df.iloc[ap_hi_outlier_index,:]\ndf_aphi_outlier","95597341":"ap_lo_outlier_index = list(outliers_iqr(df['ap_lo'])[0][0])\ndf_aplo_outlier = df.iloc[ap_lo_outlier_index,:]\ndf_aplo_outlier","e4c53445":"def replace_outliers_boundary(dataframe, column):\n    lower_bound = outliers_iqr(dataframe[column])[1][0]\n    upper_bound = outliers_iqr(dataframe[column])[1][1]\n    \n    dataframe.loc[(dataframe[column] < lower_bound), column] = lower_bound\n    dataframe.loc[(dataframe[column] > upper_bound), column] = upper_bound","9a9e7fa5":"replace_outliers_boundary(df, 'height')\nreplace_outliers_boundary(df, 'weight')\nreplace_outliers_boundary(df, 'ap_hi')\nreplace_outliers_boundary(df, 'ap_lo')","b0135e20":"df1 = df.drop(columns = ['id'])\ndf1","d45ebc4d":"all_outlier_index = height_outlier_index + weight_outlier_index + ap_hi_outlier_index + ap_lo_outlier_index\nall_outlier_index = list(set(all_outlier_index))\nprint(len(all_outlier_index))","7b0f29bd":"df2 = df.drop(index = all_outlier_index).reset_index()\ndf2.drop(columns=['index','id'], inplace=True)\ndf2","36f85f69":"# checking on the proportion of our target\n\nx = range(2)\n\nplt.subplot(1,2,1)\nbar1 = plt.bar(x, df1['cardio'].value_counts(normalize=True))\nplt.xticks(x, df1['cardio'].unique())\nplt.title('df1 target\\'s proportion')\n\nplt.subplot(1,2,2)\nbar1 = plt.bar(x, df2['cardio'].value_counts(normalize=True))\nplt.xticks(x, df2['cardio'].unique())\nplt.title('df2 target\\'s proportion')\n\nplt.tight_layout()\n\nplt.show()","e1228ff7":"def get_cat_value_count(dataframe,column_list):\n    for i in column_list:\n        print(f'{i}')\n        print('*'*len(i))\n        print(dataframe[i].value_counts(normalize=True))\n        print()\n\ncolumn_cat_list = ['gender', 'cholesterol', 'gluc', 'smoke', 'alco', 'active', 'cardio']","33a2d6a7":"# for df1\nget_cat_value_count(df1, column_cat_list)","5abb8686":"# for df2\nget_cat_value_count(df2, column_cat_list)","e1dfa6f5":"# understand continous variable distribution\n# for df1\n\nfigure3 = plt.figure(figsize = (12,8))\n\n\nplt.subplot(2,3,1)\nsns.distplot(df1['age'], bins=15, kde=False, color=\"red\")\n\nplt.subplot(2,3,2)\nsns.distplot(df1['height'], bins=25, kde=False, color=\"red\")\n\nplt.subplot(2,3,3)\nsns.distplot(df1['weight'], bins=25, kde=False, color=\"red\")\n\nplt.subplot(2,3,4)\nsns.distplot(df1['ap_lo'], bins=15, kde=False, color=\"red\")\n\nplt.subplot(2,3,5)\nsns.distplot(df1['ap_hi'], bins=15, kde=False, color=\"red\")\n\nplt.tight_layout()\n\nplt.show()","20e089d5":"# for df2\nfigure4 = plt.figure(figsize = (12,8))\n\nplt.subplot(2,3,1)\nsns.distplot(df2['age'], bins=15, kde=False, color=\"red\")\n\nplt.subplot(2,3,2)\nsns.distplot(df2['height'], bins=25, kde=False, color=\"red\")\n\nplt.subplot(2,3,3)\nsns.distplot(df2['weight'], bins=25, kde=False, color=\"red\")\n\nplt.subplot(2,3,4)\nsns.distplot(df2['ap_lo'], bins=15, kde=False, color=\"red\")\n\nplt.subplot(2,3,5)\nsns.distplot(df2['ap_hi'], bins=15, kde=False, color=\"red\")\n\nplt.tight_layout()\n\nplt.show()","e8c40dbb":"sns.heatmap(df.drop(columns=['id']).corr(), annot=True, cmap='YlOrBr')\nfig = plt.gcf()\nfig.set_size_inches(10,8)","24f18257":"# to combine weight and height into 1 feature\ndf1['bmi'] = round(df1['weight']\/ (df1['height']\/100)**2, 2)\ndf1","0c1d2f0f":"# binning the bmi feature\ndf1.loc[(df1['bmi'] < 18.5), 'bmi_cat'] = 1\ndf1.loc[(df1['bmi'] >= 18.5) & (df1['bmi'] < 25), 'bmi_cat'] = 2\ndf1.loc[(df1['bmi'] >= 25) & (df1['bmi'] < 30), 'bmi_cat'] = 3\ndf1.loc[(df1['bmi'] >= 30), 'bmi_cat'] = 4","167830f2":"df1['bmi_cat'] = df1['bmi_cat'].astype('int')\ndf1['bmi_cat'].value_counts()","aa7f8546":"# binning the bp (ap_hi & ap_lo) features\ndf1.loc[(df1['ap_hi'] < 130) | (df1['ap_lo'] < 90), 'blood_pressure_cat'] = 1\ndf1.loc[(df1['ap_hi'] >= 130) | (df1['ap_lo'] >= 90), 'blood_pressure_cat'] = 2","61bdc300":"df1['blood_pressure_cat'] = df1['blood_pressure_cat'].astype('int')\ndf1['blood_pressure_cat'].value_counts()","7d9a37cf":"# doing the same for 'age' column\ndf1['age'].hist()","6fab0b07":"# binning the age feature\ndf1.loc[(df1['age'] >= 30) & (df1['age'] < 40), 'age'] = 1\ndf1.loc[(df1['age'] >= 40) & (df1['age'] < 50), 'age'] = 2\ndf1.loc[(df1['age'] >= 50) & (df1['age'] < 60), 'age'] = 3\ndf1.loc[df1['age'] >= 60, 'age'] = 4","fec03f36":"# dropping the columns we do not need\ncolumns_remove = ['height','weight','ap_hi','ap_lo','bmi']\ndf1_new = df1.drop(columns=columns_remove)\ndf1_new","00d1f027":"df2['bmi'] = round(df2['weight']\/ (df2['height']\/100)**2, 2)\n# binning the bmi feature\ndf2.loc[(df2['bmi'] < 18.5), 'bmi_cat'] = 1\ndf2.loc[(df2['bmi'] >= 18.5) & (df2['bmi'] < 25), 'bmi_cat'] = 2\ndf2.loc[(df2['bmi'] >= 25) & (df2['bmi'] < 30), 'bmi_cat'] = 3\ndf2.loc[(df2['bmi'] >= 30), 'bmi_cat'] = 4\n\ndf2['bmi_cat'] = df2['bmi_cat'].astype('int')\ndf2['bmi_cat'].value_counts()","2ba93a4e":"# binning the bp (ap_hi & ap_lo) features\ndf2.loc[(df2['ap_hi'] < 130) | (df2['ap_lo'] < 90), 'blood_pressure_cat'] = 1\ndf2.loc[(df2['ap_hi'] >= 130) | (df2['ap_lo'] >= 90), 'blood_pressure_cat'] = 2\n\ndf2['blood_pressure_cat'] = df2['blood_pressure_cat'].astype('int')\ndf2['blood_pressure_cat'].value_counts()","80ee5122":"# binning the age feature\ndf2.loc[(df2['age'] >= 30) & (df2['age'] < 40), 'age'] = 1\ndf2.loc[(df2['age'] >= 40) & (df2['age'] < 50), 'age'] = 2\ndf2.loc[(df2['age'] >= 50) & (df2['age'] < 60), 'age'] = 3\ndf2.loc[df2['age'] >= 60, 'age'] = 4","2c17aaac":"columns_remove = ['height','weight','ap_hi','ap_lo','bmi']\ndf2_new = df2.drop(columns=columns_remove)\ndf2_new","ea8b4a7e":"X1_data = df1_new.drop(columns=['cardio']).values\ny1_data = df1_new['cardio']\n\n# splitting the data into training and testing sets\nX1_train, X1_test, y1_train, y1_test = train_test_split(X1_data, y1_data, test_size = 0.25, random_state = 2)\nprint(X1_train.shape)\nprint(y1_train.shape)\nprint(X1_test.shape)\nprint(y1_test.shape)","b3d5cbb1":"# fitting df1 data to the model\nlogreg1 = LogisticRegression()\nlogreg1.fit(X1_train, y1_train)\n\nprint(logreg1.intercept_)\nprint(logreg1.coef_)\n\ny1_pred = logreg1.predict(X1_test)","5e51c542":"# creating a confusion matrix\npd.crosstab(y1_test, \n            y1_pred, \n            rownames=['Actual'], \n            colnames=['Predicted'])","9f49666c":"print(\"Accuracy:\", metrics.accuracy_score(y1_test, y1_pred))","bbddb2ae":"X2_data = df2_new.drop(columns=['cardio']).values\ny2_data = df2_new['cardio']\n\n# splitting the data into training and testing sets\nX2_train, X2_test, y2_train, y2_test = train_test_split(X2_data, y2_data, test_size = 0.25, random_state = 2)\nprint(X2_train.shape)\nprint(y2_train.shape)\nprint(X2_test.shape)\nprint(y2_test.shape)","37f105f7":"# fitting df2 data to the model\nlogreg2 = LogisticRegression()\nlogreg2.fit(X2_train, y2_train)\n\nprint(logreg2.intercept_)\nprint(logreg2.coef_)\n\ny2_pred = logreg2.predict(X2_test)","56edfd54":"# creating a confusion matrix\npd.crosstab(y2_test, \n            y2_pred, \n            rownames=['Actual'], \n            colnames=['Predicted'])","faafe031":"print(\"Accuracy:\", metrics.accuracy_score(y2_test, y2_pred))","0ca5dff6":"We will also group the blood pressure range accordingly:\n\nSystolic Blood Pressure (ap_hi), Diastolic Blood Pressure (ap_lo)\n- ap_hi < 130 mmHg and ap_lo < 80 mmHg: Normal --> 1\n- ap_hi >= 130 mmHg and ap_lo >= 80 mmHg: Hypertension--> 2","defe474e":"Viewing the raw dataset and its information:","fa1d1eb3":"### understand continous variable distribution\n\nfor df1:","626bed78":"## Data Description\n\n**There are 3 types of input features:**\n\n- Objective: factual information;\n- Examination: results of medical examination;\n- Subjective: information given by the patient.\n\n\n1. Age | Objective Feature | age | int (days)\n2. Height | Objective Feature | height | int (cm) |\n3. Weight | Objective Feature | weight | float (kg) |\n4. Gender | Objective Feature | gender | categorical code |\n5. Systolic blood pressure | Examination Feature | ap_hi | int |\n6. Diastolic blood pressure | Examination Feature | ap_lo | int |\n7. Cholesterol | Examination Feature | cholesterol | 1: normal, 2: above normal, 3: well above normal |\n8. Glucose | Examination Feature | gluc | 1: normal, 2: above normal, 3: well above normal |\n9. Smoking | Subjective Feature | smoke | binary |\n10. Alcohol intake | Subjective Feature | alco | binary |\n11. Physical activity | Subjective Feature | active | binary |\n12. Presence or absence of cardiovascular disease | Target Variable | cardio | binary |","12a98d8c":"### **Observations from the statistics description:**\n- minumum age recorded is 30 years old\n- height(cm) and weight(kg) are objective features\n    - height - min: 55cm\n    - weight - min: 10kg\n- ap_hi and ap_lo are examination features and both recorded extremes values\n    - ap_hi - min:-150 and max:16020\n    - ap_low - min:-70 and max:11000\n    \n## Checking for outliers:\n\nplotting histograms for quick view","1a8d0dbe":"## Logistic Regression model\n\n### based on df1 -- outliers are replaced with boundary values","faad6eba":"Looking into the correlation heatmap, and it seems like our target has higher correlation with age, weight, ap_hi, ap_lo, cholestrol.","b3276e47":"The outliers of the datasets are processed differently:\n - df1: outliers are replaced with boundary values, based on 1.5*Q1 and 1.5*Q3\n - df2: outliers are removed\n \nThe model accuracy for both datasets are similar, df1's model at 71.7% whereare df2's model at 72.1%.\n\n**Actionables:**\n - to explore different type of classification models\n - to explore other methods in processing features with extreme values, as I realised that the lower boundary values for weight is 14kg, which is quiet impossible as the recorded minumum age of the dataset is 30 years old.\n - to identify both ap_hi and ap_lo columns with negative values -- is there a pattern to this error, or we could simply replace it to a positive sign of the same value","9a0c4837":"## Data Preprocessing\n### for df1","bfd03707":"taking the bmi range as according to cdc.gov\n\n- Below 18.5: Underweight --> 1\n- 18.5 - 24.9: Normal --> 2\n- 25.0 - 29.9: Overweight --> 3\n- 30 and above: Obese --> 4","0a4ba3dd":"### based on df2 -- outliers are removed","7f20434e":"## Data Understanding\n\nFirst, checking on the proportion of our target:","c82cccc6":"for df2:","84baee3a":"## 2 different ways in handling outliers\n\n1. replace with nearest boundary values\n2. remove outliers\n\n### 1.  replace with nearest boundary values -- creating df1","6a4dd34b":"### 2. remove outliers -- creating df2","00a7cb0f":"### for df2","f0ca648d":"<img src=https:\/\/img.webmd.com\/dtmcms\/live\/webmd\/consumer_assets\/site_images\/article_thumbnails\/other\/blood_pressure_charts\/basic_blood_pressure_chart.png width=\"650\">","fab1944a":"### understand categorical variable, each category proportion"}}