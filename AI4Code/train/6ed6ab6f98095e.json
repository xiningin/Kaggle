{"cell_type":{"b42a7ca7":"code","b2eed600":"code","cdaed715":"code","fc06b2a6":"code","b1209826":"code","fd82b6dc":"code","e27d926d":"code","9adec188":"code","496f688d":"code","aa4831c8":"code","2636a65d":"code","1299468a":"code","470e5d19":"code","e333b5b5":"code","4e73abee":"code","328f6c32":"code","91afea1c":"code","dbfd98d3":"code","416c9949":"code","c3879307":"code","d6174a04":"code","c1f99799":"code","93cdffbf":"code","da49772c":"code","ce71f9d1":"markdown","1cb8fcf1":"markdown","382f10e3":"markdown","310bd3aa":"markdown","fe4ac830":"markdown","d20b7cfd":"markdown","0e3ce481":"markdown","98f43a7f":"markdown","28709f38":"markdown","01e25951":"markdown","16f6ab7f":"markdown","5b089d5f":"markdown","e87cb7a6":"markdown","a65bb332":"markdown","fbd42b3a":"markdown","96155000":"markdown","9b5d6b4c":"markdown","bcf7641b":"markdown","05d98481":"markdown","16435e39":"markdown","90a14f0a":"markdown"},"source":{"b42a7ca7":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport missingno\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nimport os\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.optimizers import SGD\n\nimport os\nimport tempfile\n\nimport matplotlib as mpl\nimport seaborn as sns\n\nimport sklearn\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nseed_value= 0\n\n# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\nimport os\nos.environ['PYTHONHASHSEED']=str(seed_value)\n\n# 2. Set the `python` built-in pseudo-random generator at a fixed value\nimport random\nrandom.seed(seed_value)\n\n# 3. Set the `numpy` pseudo-random generator at a fixed value\nimport numpy as np\nnp.random.seed(seed_value)\n\n# 4. Set the `tensorflow` pseudo-random generator at a fixed value\nimport tensorflow as tf\ntf.random.set_seed(seed_value)\n# for later versions: \n# tf.compat.v1.set_random_seed(seed_value)\n\n# 5. Configure a new global `tensorflow` session\nfrom tensorflow.compat.v1.keras import backend as K\nsession_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\nsess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\nK.set_session(sess)\n# for later versions:\n# session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n# sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n# tf.compat.v1.keras.backend.set_session(sess)\n\n%matplotlib inline","b2eed600":"df= pd.read_csv('..\/input\/heart-attack-analysis-prediction-dataset\/heart.csv')","cdaed715":"df.shape","fc06b2a6":"df.head()","b1209826":"missingno.matrix(df,sparkline=False, figsize=(10,5), fontsize=12);","fd82b6dc":"df.info()","e27d926d":"neg, pos = np.bincount(df['output'])\ntotal = neg + pos\nprint('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n    total, pos, 100 * pos \/ total))","9adec188":"val = df.output.value_counts().to_frame().reset_index()\n\nx = val.index\ny = val.output\n\ncolors = ['lightblue',] * 2\ncolors[1] = 'crimson'\n\n# Use the hovertext kw argument for hover text\nfig = go.Figure(data=[go.Bar(x=x, y=y,\n            hovertext=['Count of 0s', 'Count of 1s'], marker_color=colors )])\n\nfig.update_layout(title_text='Count of Classes', height = 400, width = 500)\nfig.show()","496f688d":"data = df[['age', 'sex', 'cp', 'chol', 'fbs', 'restecg', 'thalachh',\n       'exng', 'oldpeak', 'slp', 'caa', 'thall']]\n\ndef graph1(name, u, title):\n    \n    ax = sns.kdeplot(x=data[name],hue=df['output'], ax=u, shade=True, palette = 'Blues')\n    ax.set_title(title, fontsize=13)\n    \n    ax. spines[\"right\"]. set_visible(False)\n    ax. spines[\"left\"]. set_visible(False)\n    ax. spines[\"top\"]. set_visible(False)\n    ax. spines[\"bottom\"]. set_visible(False)\n    \n    plt.legend(loc = 'best')\n    \n\nfig2, ax2 = plt.subplots(4, 3, figsize=(15, 18), gridspec_kw={\"wspace\" : 0.4, \"hspace\" : 0.3, \"top\": 0.95})\n\ngraph1(\"age\", ax2[0,0], 'Age')\ngraph1(\"sex\", ax2[0,1], 'Gender')\ngraph1(\"cp\", ax2[0,2], 'Chest Pain type')\n\ngraph1('chol', ax2[1,0], 'Cholestoral in mg\/dl')\ngraph1('fbs', ax2[1,1], 'Fasting blood sugar')\ngraph1(\"restecg\", ax2[1,2], 'Resting blood sugar')\n\ngraph1('thalachh', ax2[2,0], 'Maximum heart rate')\ngraph1('exng', ax2[2,1], 'Exercise induced angina')\ngraph1(\"oldpeak\", ax2[2,2], 'Previous Peak')\n\ngraph1('slp', ax2[3,0], 'Slope')\ngraph1('caa', ax2[3,1], 'Number of major vessels')\ngraph1('thall', ax2[3,2], 'Thal Rate')\n\nplt.rcParams['axes.axisbelow'] = True","aa4831c8":"# Use a utility from sklearn to split and shuffle your dataset.\ntrain_df, test_df = train_test_split(df, test_size=0.2)\ntrain_df, val_df = train_test_split(df, test_size=0.2)\n\n# Form np arrays of labels and features.\ntrain_labels = np.array(train_df.pop('output'))\nbool_train_labels = train_labels != 0\nval_labels = np.array(val_df.pop('output'))\ntest_labels = np.array(test_df.pop('output'))\n\ntrain_features = np.array(train_df)\nval_features = np.array(val_df)\ntest_features = np.array(test_df)","2636a65d":"scaler = StandardScaler()\ntrain_features = scaler.fit_transform(train_features)\n\nval_features = scaler.transform(val_features)\ntest_features = scaler.transform(test_features)\n\ntrain_features = np.clip(train_features, -5, 5)\nval_features = np.clip(val_features, -5, 5)\ntest_features = np.clip(test_features, -5, 5)\n\nprint('Training labels shape:', train_labels.shape)\nprint('Validation labels shape:', val_labels.shape)\nprint('Test labels shape:', test_labels.shape)\n\nprint('Training features shape:', train_features.shape)\nprint('Validation features shape:', val_features.shape)\nprint('Test features shape:', test_features.shape)","1299468a":"METRICS = [\n          keras.metrics.TruePositives(name='tp'),\n          keras.metrics.FalsePositives(name='fp'),\n          keras.metrics.TrueNegatives(name='tn'),\n          keras.metrics.FalseNegatives(name='fn'), \n          keras.metrics.BinaryAccuracy(name='accuracy'),\n          keras.metrics.Precision(name='precision'),\n          keras.metrics.Recall(name='recall'),\n          keras.metrics.AUC(name='auc'),\n          keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n]\n\ndef make_model(metrics= METRICS, output_bias=None):\n        \n        if output_bias is not None:\n                \n                output_bias = tf.keras.initializers.Constant(output_bias)\n            \n        model = keras.Sequential([\n                  keras.layers.Dense(\n                              100, activation='relu',\n                              input_shape=(train_features.shape[-1],)),\n                  keras.layers.Dropout(0.5),\n                  keras.layers.Dense(1, activation='sigmoid',\n                                 bias_initializer=output_bias),\n        ])\n\n        model.compile(\n              optimizer=keras.optimizers.Adam(lr=1e-3),\n              #optimizer = SGD(lr=1e-3, momentum = 1),\n              loss=keras.losses.BinaryCrossentropy(),\n              metrics=metrics)\n\n        return model","470e5d19":"EPOCHS = 10\nBATCH_SIZE = 1\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_acc', \n    verbose=1,\n    patience=10,\n    mode='max',\n    restore_best_weights=True)\n\nmodel = make_model()\nmodel.summary()","e333b5b5":"%%time\n\nmodel = make_model()\nbaseline_history = model.fit(\n    train_features,\n    train_labels,\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n    callbacks=[early_stopping],\n    validation_data=(val_features, val_labels))","4e73abee":"def plot_metrics(history):\n    \n    mpl.rcParams['figure.figsize'] = (18, 10)\n    metrics = ['loss', 'accuracy', 'precision', 'recall']\n    for n, metric in enumerate(metrics):\n        \n            name = metric.replace(\"_\",\" \").capitalize()\n            plt.subplot(2,2,n+1)\n            ax = plt.plot(history.epoch, history.history[metric], label='Train', linewidth = 2, color = 'skyblue')\n            ax = plt.plot(history.epoch, history.history['val_'+ metric], linestyle= \"--\", label= 'Validation', linewidth = 2, color = 'gray')\n            \n            plt.xlabel('Epoch')\n            plt.ylabel(name)\n            \n            \n            plt.legend(fontsize ='large')","328f6c32":"plot_metrics(baseline_history)","91afea1c":"train_predictions_baseline = model.predict(train_features, batch_size=BATCH_SIZE)\ntest_predictions_baseline = model.predict(test_features, batch_size=BATCH_SIZE)","dbfd98d3":"train_results = model.evaluate(train_features, train_labels, batch_size=BATCH_SIZE, verbose=0)\n\nfor name, value in zip(model.metrics_names, train_results):\n          print(name, ': ', value)","416c9949":"val_results = model.evaluate(val_features, val_labels, batch_size=BATCH_SIZE, verbose=0)\n\nfor name, value in zip(model.metrics_names, val_results):\n          print(name, ': ', value)","c3879307":"test_results = model.evaluate(test_features, test_labels, batch_size=BATCH_SIZE, verbose=0)\n\nfor name, value in zip(model.metrics_names, test_results):\n          print(name, ': ', value)","d6174a04":"def plot_cm(labels, predictions, p=0.5):\n    \n      cm = confusion_matrix(labels, predictions > p)\n      plt.figure(figsize=(6,5))\n      sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n      plt.title('Confusion matrix')\n      plt.ylabel('Actual label')\n      plt.xlabel('Predicted label')\n\n      print('True Negatives (no heart-attack as no heart-attack): ', cm[0][0])\n      print('False Positives (no heart as heart-attack): ', cm[0][1])\n      print('False Negatives (heart-attack as no heart-attack): ', cm[1][0])\n      print('True Positives (heart-attack as heart-attack): ', cm[1][1])\n    \nplot_cm(test_labels, test_predictions_baseline)","c1f99799":"def plot_roc(name, labels, predictions, **kwargs):\n    \n    mpl.rcParams['figure.figsize'] = (8, 8)\n    fp, tp, _ = sklearn.metrics.roc_curve(labels, predictions)\n    ax = plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)\n    plt.xlabel('False positives [%]', fontsize = 16)\n    plt.ylabel('True positives [%]', fontsize = 16)\n    \nplot_roc(\"Train Baseline\", train_labels, train_predictions_baseline, color='gray')\nplot_roc(\"Test Baseline\", test_labels, test_predictions_baseline, color='black', linestyle='--')\nplt.legend(loc='lower right', fontsize = 'large')\nplt.show()","93cdffbf":"def plot_prc(name, labels, predictions, **kwargs):\n    \n    mpl.rcParams['figure.figsize'] = (8, 8)\n    precision, recall, _ = sklearn.metrics.precision_recall_curve(labels, predictions)\n    plt.plot(precision, recall, label=name, linewidth=2, **kwargs)\n    plt.xlabel('Recall', fontsize = 16)\n    plt.ylabel('Precision', fontsize = 16)\n\nplot_prc(\"Train Baseline\", train_labels, train_predictions_baseline,  color='gray')\nplot_prc(\"Test Baseline\", test_labels, test_predictions_baseline, color='black', linestyle='--')\nplt.legend(loc='lower left', fontsize = 'large')\nplt.show()","da49772c":"test_df['Predicted_output'] = list(np.where(np.array(test_predictions_baseline) > 0.5, 1, 0 )[:, 0])\ntest_df.to_csv('submission.csv', index = False)","ce71f9d1":"## Check training history\n\nLet's produce plots of the model's accuracy and loss on the training and validation set.","1cb8fcf1":"## Missing Values","382f10e3":"## Define the model and metrics\n\nDefine a function that creates a simple neural network with a densly connected hidden layer, a dropout layer to reduce overfitting, and an output sigmoid layer that returns the probability of output being 1:","310bd3aa":"## Let's look at the number of False positivis and False negatives","fe4ac830":"## About this dataset\n\n**Age : Age of the patient****\n\n**Sex : Sex of the patient****\n\n**exang: exercise induced angina (1 = yes; 0 = no)****\n\n**ca: number of major vessels (0-3)****\n\n**cp : Chest Pain type chest pain type****\n\n    * Value 1: typical angina\n    * Value 2: atypical angina\n    * Value 3: non-anginal pain\n    * Value 4: asymptomatic\n\n**trtbps : resting blood pressure (in mm Hg)****\n\n**chol : cholestoral in mg\/dl fetched via BMI sensor****\n\n**fbs : (fasting blood sugar > 120 mg\/dl) (1 = true; 0 = false)****\n\n**rest_ecg : resting electrocardiographic results****\n\n    * Value 0: normal\n    * Value 1: having ST-T wave abnormality (T wave inversions and\/or ST elevation or depression of > 0.05 mV)\n    * Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n\n**thalach : maximum heart rate achieved**\n\n**target : 0= less chance of heart attack 1= more chance of heart attack**","d20b7cfd":"Split the dataset into train, validation, and test sets. The validation set is used during the model fitting to evaluate the loss and any metrics, however the model is not fit with this data. The test set is completely unused during the training phase and is only used at the end to evaluate how well the model generalizes to new data.","0e3ce481":"## Little bit of EDA","98f43a7f":"## Train the model","28709f38":"#### Will work on improving the Accuracy and Recall score in the next notebook soon! Let me know what you think about this one :)","01e25951":"## Split and normalize the data","16f6ab7f":"## References\n\n*  [True vs. False and Positive vs. Negative](https:\/\/developers.google.com\/machine-learning\/crash-course\/classification\/true-false-positive-negative)\n*  [Accuracy](https:\/\/developers.google.com\/machine-learning\/crash-course\/classification\/accuracy)\n*  [Precision and Recall](https:\/\/developers.google.com\/machine-learning\/crash-course\/classification\/precision-and-recall)\n*  [ROC-AUC](https:\/\/developers.google.com\/machine-learning\/crash-course\/classification\/roc-and-auc)\n*  [Relationship between Precision-Recall and ROC Curves](https:\/\/www.biostat.wisc.edu\/~page\/rocpr.pdf)","5b089d5f":"## Baseline model","e87cb7a6":"## Dataset","a65bb332":"## Test Accuracy: 0.9016","fbd42b3a":"### AUPRC\n\nArea under the interpolated precision-recall curve, obtained by plotting (recall, precision) points for different values of the classification threshold. Depending on how it's calculated, PR AUC may be equivalent to the average precision of the model.","96155000":"<img src= \"https:\/\/i.pinimg.com\/originals\/67\/fb\/22\/67fb22aa0142b62effc23870f80cf39d.jpg\" alt =\"Titanic\" style='width: 250px;'>","9b5d6b4c":"## Training Accuracy: 0.8967","bcf7641b":"### ROC","05d98481":"Normalize the input features using the sklearn StandardScaler. This will set the mean to 0 and standard deviation to 1.\n\nNote: The StandardScaler is only fit using the train_features to be sure the model is not peeking at the validation or test sets.","16435e39":"## Validation Accuracy: 0.8361","90a14f0a":"## Binary Classification using Simple NN"}}