{"cell_type":{"300fceef":"code","dfd904f5":"code","dc498135":"code","d3216125":"code","ae0e5fce":"code","666be1bc":"code","440b3d41":"code","16406abf":"code","fdf0454e":"code","4bc2cf8d":"code","2d400639":"code","7fc36a54":"code","b3af644c":"code","267a3106":"code","54ac0dac":"code","860b0e33":"code","61b7cc3c":"code","5f86b5a2":"code","8f137783":"code","04cf1041":"markdown","22ef7f3e":"markdown","bff24fe2":"markdown","a114a826":"markdown","a99c5e47":"markdown","63e5f290":"markdown"},"source":{"300fceef":"#\u914d\u7f6eTPU\u8fd0\u884c\u6a21\u5f0f\nimport tensorflow as tf\nfrom kaggle_datasets import KaggleDatasets\n# \u63a2\u6d4bTPU\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nGCS_DS_PATH = KaggleDatasets().get_gcs_path()\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","dfd904f5":"\"\"\"\n\u7a0b\u5e8f\uff1ahandle_data.py\n\u529f\u80fd\uff1a\u6570\u636e\u9884\u5904\u7406\n\u8bbe\u8ba1\uff1a\u8463\u76f8\u5fd7\uff0cupsunny2008@163.com\n\u65e5\u671f\uff1a2021.3.12\n\"\"\"\nimport os\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\n\ntqdm.pandas()\n\n# \u6570\u636e\u96c6\u89c2\u5bdf\ndef data_observation(csv_file_path: str, image_path: str, index: int):\n    data = pd.read_csv(csv_file_path)\n    print(data.head())  # \u663e\u793a\u6570\u636e\u96c6\n    image = cv2.imread(image_path + data['image_id'][index] + '.jpg')\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    fig = px.imshow(cv2.resize(image, (205, 136)))\n    fig.show()\n\n\n# \u5206\u7c7b\u89c2\u5bdf\ndef category_observation(csv_file_path: str, image_path: str, cond=[0, 0, 0, 0], cond_cols=[\"healthy\"]):\n    data = pd.read_csv(csv_file_path)\n    train_images = []\n    SAMPLE_LEN = 40\n    for i in range(SAMPLE_LEN):\n        image = cv2.imread(image_path + data['image_id'][i] + '.jpg')\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        train_images.append(image)\n    cond_0 = \"healthy == {}\".format(cond[0])\n    cond_1 = \"scab == {}\".format(cond[1])\n    cond_2 = \"rust == {}\".format(cond[2])\n    cond_3 = \"multiple_diseases == {}\".format(cond[3])\n    cond_list = []\n    for col in cond_cols:\n        if col == \"healthy\":\n            cond_list.append(cond_0)\n        if col == \"scab\":\n            cond_list.append(cond_1)\n        if col == \"rust\":\n            cond_list.append(cond_2)\n        if col == \"multiple_diseases\":\n            cond_list.append(cond_3)\n    data = data[:SAMPLE_LEN]\n    for cond in cond_list:\n        data = data.query(cond)\n    print(data)\n    images = []\n    for index in data.index:\n        images.append(train_images[index])\n    cols, rows = 2, min([2, len(images) \/\/ 2])\n    fig, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(8, rows * 6 \/ 2))\n    for col in range(cols):\n        for row in range(rows):\n            ax[row, col].imshow(images[row * 2 + col])\n            ax[row, col].set_title(data['image_id'][data.index[row * 2 + col]])\n    plt.show()\n\n\n# \u7c7b\u522b\u5206\u5e03\ndef category_distribution(csv_file_path: str):\n    train_data = pd.read_csv(csv_file_path)\n    fig = px.parallel_categories(train_data[[\"healthy\", \"scab\", \"rust\", \"multiple_diseases\"]],\n                                 color=\"healthy\", color_continuous_scale=\"sunset\",\n                                 title=\"Parallel categories plot of targets\",\n                                 width=500, height=300)\n    fig.show()\n\n    fig = go.Figure([go.Pie(labels=train_data.columns[1:],\n                            values=train_data.iloc[:, 1:].sum().values)])\n    fig.update_layout(title_text=\"Pie chart of targets\", template=\"simple_white\")\n    fig.data[0].marker.line.color = 'rgb(0, 0, 0)'\n    fig.data[0].marker.line.width = 0.5\n    fig.show()\n\n\n# \u6570\u636e\u968f\u673a\u589e\u5f3a\ndef data_augmentation(image, label=None):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    if label is None:\n        return image\n    else:\n        return image, label\n\n\n# \u751f\u6210\u56fe\u50cf\u8def\u5f84\ndef format_path(image_id):\n    return GCS_DS_PATH + '\/images\/' + image_id + '.jpg'\n\n\n# \u56fe\u50cf\u6570\u636e\u52a0\u8f7d\u4e0e\u89e3\u7801\u51fd\u6570\ndef decode_image(filename, label=None, image_size=(512, 512)):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.image.resize(image, image_size)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    if label is None:\n        return image\n    else:\n        return image, label\n\n\n# \u6570\u636e\u96c6\u5212\u5206\ndef data_split(train_file_path: str, test_file_path: str):\n    train_data = pd.read_csv(train_file_path)  # \u8bad\u7ec3\u96c6\n    test_data = pd.read_csv(test_file_path)  # \u6d4b\u8bd5\u96c6\n    train_paths = train_data.image_id.apply(format_path).values\n    train_labels = np.float32(train_data.loc[:, 'healthy':'scab'].values)\n    test_paths = test_data.image_id.apply(format_path).values\n    train_paths, valid_paths, train_labels, valid_labels = train_test_split(train_paths, train_labels, test_size=0.15,\n                                                                            random_state=2021)\n\n    AUTO = tf.data.experimental.AUTOTUNE\n    # \u6784\u5efa\u8bad\u7ec3\u96c6\n    train_dataset = (\n        tf.data.Dataset\n            .from_tensor_slices((train_paths, train_labels))\n            .map(decode_image, num_parallel_calls=AUTO)\n            .map(data_augmentation, num_parallel_calls=AUTO)\n            .repeat()\n            .shuffle(512)\n            .batch(BATCH_SIZE)\n            .prefetch(AUTO)\n    )\n    # \u6784\u5efa\u9a8c\u8bc1\u96c6\n    valid_dataset = (\n        tf.data.Dataset\n            .from_tensor_slices((valid_paths, valid_labels))\n            .map(decode_image, num_parallel_calls=AUTO)\n            .batch(BATCH_SIZE)\n            .cache()\n            .prefetch(AUTO)\n    )\n    # \u6784\u5efa\u6d4b\u8bd5\u96c6\n    test_dataset = (\n        tf.data.Dataset\n            .from_tensor_slices(test_paths)\n            .map(decode_image, num_parallel_calls=AUTO)\n            .batch(BATCH_SIZE)\n    )\n    return train_dataset, valid_dataset, test_dataset\n","dc498135":"\"\"\"\n\u7a0b\u5e8f\uff1ahandle_model.py\n\u529f\u80fd\uff1a\u5efa\u6a21\u8fc7\u7a0b\n\u8bbe\u8ba1\uff1a\u8463\u76f8\u5fd7\uff0cupsunny2008@163.com\n\u65e5\u671f\uff1a2021.3.12\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport cv2\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D,Dropout,GlobalAveragePooling2D\nfrom tensorflow.keras.applications import DenseNet121\nfrom tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import load_model\n\n# \u6a21\u578b\u5b9a\u4e49\ndef model_define(train_labels, batch_size: int=BATCH_SIZE):\n    steps_per_epoch = train_labels.shape[0] \/\/ batch_size\n    model = Sequential(name='MyDenseNet121')\n    dense_net = DenseNet121(include_top=False, weights='imagenet', input_shape=(512, 512, 3))\n    model.add(dense_net)\n    model.add(GlobalAveragePooling2D())\n    model.add(Dense(train_labels.shape[1], activation='softmax'))\n    model.compile(optimizer=Adam(learning_rate=0.001),\n                  loss='categorical_crossentropy',\n                  metrics=['categorical_accuracy'])\n    model.summary()\n    return model\n\n#\u5b66\u4e60\u7387\u8c03\u5ea6\u51fd\u6570\ndef build_lrfn(lr_start=0.00001, lr_max=0.00005, \n               lr_min=0.00001, lr_rampup_epochs=5, \n               lr_sustain_epochs=0, lr_exp_decay=.8):\n    lr_max = lr_max * strategy.num_replicas_in_sync\n\n    def lrfn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) \/ lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) *\\\n                 lr_exp_decay**(epoch - lr_rampup_epochs\\\n                                - lr_sustain_epochs) + lr_min\n        return lr\n    return lrfn\n\n\n# \u6a21\u578b\u8bad\u7ec3\ndef model_train(model, train_dataset, valid_dataset, epochs, steps_per_epoch, saved_path):\n    # \u5b9a\u4e49\u56de\u8c03\u51fd\u6570\uff1a\u5b66\u4e60\u7387\u8c03\u5ea6\n    lrfn = build_lrfn(lr_sustain_epochs=2,lr_exp_decay=.9)\n    lr_schedule = LearningRateScheduler(lrfn, verbose=1)\n    # \u5b9a\u4e49\u56de\u8c03\u51fd\u6570\uff1a\u63d0\u524d\u7ec8\u6b62\u8bad\u7ec3\n    early_stop = EarlyStopping(monitor='val_categorical_accuracy', min_delta=0, \n                               patience=10, verbose=1, restore_best_weights=True)\n    # \u5b9a\u4e49\u56de\u8c03\u51fd\u6570\uff1a\u4fdd\u5b58\u6700\u4f18\u6a21\u578b\n    best_model = ModelCheckpoint(saved_path, monitor='val_categorical_accuracy', \n                                 verbose=1, save_best_only=True,\n                                 save_weights_only=False, mode='max')\n    history = model.fit(train_dataset,epochs=epochs,\n                        callbacks=[lr_schedule, best_model,early_stop],\n                        steps_per_epoch=steps_per_epoch,\n                        validation_data=valid_dataset)\n    return history\n\n\n# \u6a21\u578b\u8bc4\u4f30\ndef model_estimate(history, epochs):\n    training = history.history['categorical_accuracy']\n    validation = history.history['val_categorical_accuracy']\n    ylabel = \"Accuracy\"\n    title = \"Accuracy vs. Epochs\"\n    fig = go.Figure()\n    fig.add_trace(\n        go.Scatter(x=np.arange(1, epochs + 1), mode='lines+markers', \n                   y=training, marker=dict(color=\"dodgerblue\"),\n                   name=\"Train\"))\n    fig.add_trace(\n        go.Scatter(x=np.arange(1, epochs + 1), mode='lines+markers', \n                   y=validation, marker=dict(color=\"darkorange\"),\n                   name=\"Val\"))\n    fig.update_layout(title_text=title, yaxis_title=ylabel, \n                      xaxis_title=\"Epochs\", width=500, height=300)\n    fig.show()\n\n\ndef load_image(image_id):\n    file_path = '\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/' + image_id + \".jpg\"\n    image = cv2.imread(file_path)\n    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n\ndef process(img):\n    return cv2.resize(img \/ 255.0, (512, 512)).reshape(-1, 512, 512, 3)\n\n\n# \u6a21\u578b\u9884\u6d4b\ndef model_predict(saved_model, img):\n    model = load_model(saved_model)\n    preds = model.layers[2](model.layers[1](model.layers[0](process(img)))).numpy()[0]\n    return preds\n\n# \u663e\u793a\u9884\u6d4b\u7ed3\u679c\ndef displayResult(img, preds):\n    fig = make_subplots(rows=1, cols=2)\n    colors = {\"Healthy\": px.colors.qualitative.Plotly[0], \"Scab\": px.colors.qualitative.Plotly[0],\n              \"Rust\": px.colors.qualitative.Plotly[0], \"Multiple diseases\": px.colors.qualitative.Plotly[0]}\n    pred = ''\n    if list.index(preds.tolist(), max(preds)) == 0:\n        pred = \"Healthy\"\n    if list.index(preds.tolist(), max(preds)) == 1:\n        pred = \"Scab\"\n    if list.index(preds.tolist(), max(preds)) == 2:\n        pred = \"Rust\"\n    if list.index(preds.tolist(), max(preds)) == 3:\n        pred = \"Multiple diseases\"\n    colors[pred] = px.colors.qualitative.Plotly[1]\n    colors[\"Healthy\"] = \"seagreen\"\n    colors = [colors[val] for val in colors.keys()]\n    fig.add_trace(go.Image(z=cv2.resize(img, (205, 136))), row=1, col=1)\n    fig.add_trace(go.Bar(x=[\"Healthy\", \"Multiple diseases\", \"Rust\", \"Scab\"],\n                         y=preds, marker=dict(color=colors)), row=1, col=2)\n\n    fig.update_layout(height=400, width=800, title_text=\"DenseNet Predictions\",\n                      showlegend=False)\n    fig.show()\n\n\n# \u663e\u793a\u524d\u56db\u5e45\u56fe\u50cf\u9884\u6d4b\u7ed3\u679c\ndef display_four_examples(saved_model,train_data):\n    train_images = train_data[\"image_id\"][:4].progress_apply(load_image)\n    preds = model_predict(saved_model,train_images[2])\n    displayResult(train_images[2], preds)\n    preds = model_predict(saved_model,train_images[0])\n    displayResult(train_images[0], preds)\n    preds = model_predict(saved_model,train_images[3])\n    displayResult(train_images[3], preds)\n    preds = model_predict(saved_model,train_images[1])\n    displayResult(train_images[1], preds)\n\n\n# \u5bf9\u6d4b\u8bd5\u96c6\u505a\u9884\u6d4b\uff0c\u4fdd\u5b58\u9884\u6d4b\u7ed3\u679c\ndef test_dataset_predict(saved_model, test_dataset):\n    model = load_model(saved_model)\n    sub_path = \"\/kaggle\/input\/plant-pathology-2020-fgvc7\/sample_submission.csv\"\n    sub = pd.read_csv(sub_path)\n    probs_densenet = model.predict(test_dataset, verbose=1)\n    sub.loc[:, 'healthy':] = probs_densenet\n    sub.to_csv('submission_densenet.csv', index=False)\n    print(sub.head())\n","d3216125":"# \u6570\u636e\u96c6\u89c2\u5bdf\ntrain_path = '\/kaggle\/input\/plant-pathology-2020-fgvc7\/train.csv'\ntest_path ='\/kaggle\/input\/plant-pathology-2020-fgvc7\/test.csv'\nimage_path = '\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/'\nprint('\u89c2\u5bdf\u8bad\u7ec3\u96c6\uff1a')\ndata_observation(train_path, image_path, 3)\nprint('\u89c2\u5bdf\u6d4b\u8bd5\u96c6\uff1a')\ndata_observation(test_path, image_path, 80)","ae0e5fce":"# \u5206\u7c7b\u89c2\u5bdf\nprint('=========healthy\u53f6\u7247\u89c2\u5bdf===========')\ncategory_observation(train_path,image_path,cond=[1, 0, 0, 0], cond_cols=[\"healthy\"])\nprint('=========scab\u53f6\u7247\u89c2\u5bdf=========')\ncategory_observation(train_path,image_path,cond=[0, 1, 0, 0], cond_cols=[\"scab\"])\nprint('=========rust\u53f6\u7247\u89c2\u5bdf=========')\ncategory_observation(train_path,image_path,cond=[0, 0, 1, 0], cond_cols=[\"rust\"])\nprint('========= multiple_diseases\u53f6\u7247\u89c2\u5bdf=========')\ncategory_observation(train_path,image_path,cond=[0, 0, 0, 1], cond_cols=[\"multiple_diseases\"])","666be1bc":"# \u7c7b\u522b\u5206\u5e03\ncategory_distribution(train_path)","440b3d41":"# \u6570\u636e\u968f\u673a\u589e\u5f3a\ndata = pd.read_csv(train_path)\nimage = cv2.imread(image_path + data['image_id'][0] + '.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nimage_new = data_augmentation(image)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(8, 6))\nax[0].imshow(image)\nax[0].set_title('Original Image', fontsize=14)\nax[1].imshow(image_new)\nax[1].set_title('New Image', fontsize=14)\nplt.show()","16406abf":"# \u5212\u5206\u6570\u636e\u96c6\ntrain_dataset, valid_dataset, test_dataset=data_split(train_path,test_path)\nprint('\u5b8c\u6210\u6570\u636e\u96c6\u5212\u5206\uff01')\nprint(valid_dataset)\n","fdf0454e":"with strategy.scope():\n    # \u6a21\u578b\u5b9a\u4e49\n    train_data = pd.read_csv(train_path)\n    train_labels = np.float32(train_data.loc[:, 'healthy':'scab'].values)\n    batch_size=BATCH_SIZE\n    model = model_define(train_labels=train_labels,batch_size=batch_size)","4bc2cf8d":"# \u6a21\u578b\u8bad\u7ec3\nmodel_save_dir = 'models'\nif not os.path.exists(model_save_dir):\n    os.makedirs(model_save_dir)\nsaved_path = os.path.join(os.getcwd(), model_save_dir) + '\/densenet121.h5' # \u56fe\u7247\u5b58\u653e\u8def\u5f84\nprint(saved_path)\nepochs = 20\nsteps_per_epoch =train_labels.shape[0] \/\/ BATCH_SIZE\n\nhistory = model_train(model,train_dataset,valid_dataset,epochs,steps_per_epoch,saved_path)\n","2d400639":"# \u6a21\u578b\u8bc4\u4f30\nmodel_estimate(history,epochs)","7fc36a54":"# \u6a21\u578b\u9884\u6d4b\uff0c\u663e\u793a\u524d\u56db\u5e45\u56fe\u50cf\u9884\u6d4b\u7ed3\u679c\ndisplay_four_examples(saved_path,train_data)\n","b3af644c":"%%time\n# \u5bf9\u6d4b\u8bd5\u96c6\u505a\u9884\u6d4b\uff0c\u4fdd\u5b58\u9884\u6d4b\u7ed3\u679c\ntest_dataset_predict(saved_model=saved_path,test_dataset=test_dataset)","267a3106":"\"\"\"\n\u7a0b\u5e8f\uff1ahandle_model.py\n\u529f\u80fd\uff1a\u5efa\u6a21\u8fc7\u7a0b\n\u8bbe\u8ba1\uff1a\u8463\u76f8\u5fd7\uff0cupsunny2008@163.com\n\u65e5\u671f\uff1a2021.3.12\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport cv2\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, GlobalAveragePooling2D,Dropout\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler,ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import load_model\n\n# \u6a21\u578b\u5b9a\u4e49\ndef mobile_model_define(train_labels, batch_size: int=BATCH_SIZE):\n    steps_per_epoch = train_labels.shape[0] \/\/ batch_size\n    model = Sequential(name='MyMobileNetV2')\n    mobile_net = MobileNetV2(include_top=False, weights='imagenet', input_shape=(512, 512, 3))   \n#     mobile_net.trainable = False\n    model.add(mobile_net)\n#     model.add(Conv2D(64,3,activation='relu'))\n#     model.add(Dropout(0.2))\n    model.add(GlobalAveragePooling2D())\n    model.add(Dense(train_labels.shape[1], activation='softmax'))\n    model.compile(optimizer=Adam(learning_rate=0.001),\n                  loss='categorical_crossentropy',\n                  metrics=['categorical_accuracy'])\n    model.summary()\n    return model\n\n#\u5b66\u4e60\u7387\u8c03\u5ea6\u51fd\u6570\ndef mobile_build_lrfn(lr_start=0.00001, lr_max=0.00005, \n               lr_min=0.00001, lr_rampup_epochs=5, \n               lr_sustain_epochs=0, lr_exp_decay=.8):\n    lr_max = lr_max * strategy.num_replicas_in_sync\n\n    def lrfn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) \/ lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) *\\\n                 lr_exp_decay**(epoch - lr_rampup_epochs\\\n                                - lr_sustain_epochs) + lr_min\n        return lr\n    return lrfn\n\n\n# \u6a21\u578b\u8bad\u7ec3\ndef mobile_model_train(model, train_dataset, valid_dataset, epochs, steps_per_epoch, saved_path):\n    # \u5b9a\u4e49\u56de\u8c03\u51fd\u6570\uff1a\u5b66\u4e60\u7387\u8c03\u5ea6\n    lrfn = build_lrfn(lr_sustain_epochs=2,lr_exp_decay=.9)\n    lr_schedule = LearningRateScheduler(lrfn, verbose=1)\n    # \u5b9a\u4e49\u56de\u8c03\u51fd\u6570\uff1a\u63d0\u524d\u7ec8\u6b62\u8bad\u7ec3\n    early_stop = EarlyStopping(monitor='val_categorical_accuracy', min_delta=0, \n                               patience=10, verbose=1, restore_best_weights=True)\n    # \u5b9a\u4e49\u56de\u8c03\u51fd\u6570\uff1a\u4fdd\u5b58\u6700\u4f18\u6a21\u578b\n    best_model = ModelCheckpoint(saved_path, monitor='val_categorical_accuracy', \n                                 verbose=1, save_best_only=True,\n                                 save_weights_only=False, mode='max')\n    history = model.fit(train_dataset,epochs=epochs,\n                        callbacks=[lr_schedule,best_model,early_stop],\n                        steps_per_epoch=steps_per_epoch,\n                        validation_data=valid_dataset)\n    return history\n\n\n# \u6a21\u578b\u8bc4\u4f30\ndef mobile_model_estimate(history, epochs):\n    training = history.history['categorical_accuracy']\n    validation = history.history['val_categorical_accuracy']\n    ylabel = \"Accuracy\"\n    title = \"Accuracy vs. Epochs\"\n    fig = go.Figure()\n    fig.add_trace(\n        go.Scatter(x=np.arange(1, epochs + 1), mode='lines+markers', \n                   y=training, marker=dict(color=\"dodgerblue\"),\n                   name=\"Train\"))\n    fig.add_trace(\n        go.Scatter(x=np.arange(1, epochs + 1), mode='lines+markers', \n                   y=validation, marker=dict(color=\"darkorange\"),\n                   name=\"Val\"))\n    fig.update_layout(title_text=title, yaxis_title=ylabel, \n                      xaxis_title=\"Epochs\", width=500, height=300)\n    fig.show()\n\n\ndef mobile_load_image(image_id):\n    file_path = '\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/' + image_id + \".jpg\"\n    image = cv2.imread(file_path)\n    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n\ndef mobile_process(img):\n    return cv2.resize(img \/ 255.0, (512, 512)).reshape(-1, 512, 512, 3)\n\n\n# \u6a21\u578b\u9884\u6d4b\ndef mobile_model_predict(saved_model, img):\n    model = load_model(saved_model)\n    preds = model.layers[2](model.layers[1](model.layers[0](mobile_process(img)))).numpy()[0]\n    return preds\n\n\n# \u663e\u793a\u9884\u6d4b\u7ed3\u679c\ndef mobile_displayResult(img, preds):\n    fig = make_subplots(rows=1, cols=2)\n    colors = {\"Healthy\": px.colors.qualitative.Plotly[0], \"Scab\": px.colors.qualitative.Plotly[0],\n              \"Rust\": px.colors.qualitative.Plotly[0], \"Multiple diseases\": px.colors.qualitative.Plotly[0]}\n    pred = ''\n    if list.index(preds.tolist(), max(preds)) == 0:\n        pred = \"Healthy\"\n    if list.index(preds.tolist(), max(preds)) == 1:\n        pred = \"Scab\"\n    if list.index(preds.tolist(), max(preds)) == 2:\n        pred = \"Rust\"\n    if list.index(preds.tolist(), max(preds)) == 3:\n        pred = \"Multiple diseases\"\n    colors[pred] = px.colors.qualitative.Plotly[1]\n    colors[\"Healthy\"] = \"seagreen\"\n    colors = [colors[val] for val in colors.keys()]\n    fig.add_trace(go.Image(z=cv2.resize(img, (205, 136))), row=1, col=1)\n    fig.add_trace(go.Bar(x=[\"Healthy\", \"Multiple diseases\", \"Rust\", \"Scab\"],\n                         y=preds, marker=dict(color=colors)), row=1, col=2)\n\n    fig.update_layout(height=400, width=800, title_text=\"MobileNetV2 Predictions\",\n                      showlegend=False)\n    fig.show()\n\n\n# \u663e\u793a\u524d\u56db\u5e45\u56fe\u50cf\u9884\u6d4b\u7ed3\u679c\ndef mobile_display_four_examples(saved_model,train_data):\n    train_images = train_data[\"image_id\"][:4].progress_apply(mobile_load_image)\n    preds = mobile_model_predict(saved_model,train_images[2])\n    mobile_displayResult(train_images[2], preds)\n    preds = mobile_model_predict(saved_model,train_images[0])\n    mobile_displayResult(train_images[0], preds)\n    preds = mobile_model_predict(saved_model,train_images[3])\n    mobile_displayResult(train_images[3], preds)\n    preds = mobile_model_predict(saved_model,train_images[1])\n    mobile_displayResult(train_images[1], preds)\n\n\n# \u5bf9\u6d4b\u8bd5\u96c6\u505a\u9884\u6d4b\uff0c\u4fdd\u5b58\u9884\u6d4b\u7ed3\u679c\ndef mobile_test_dataset_predict(saved_model, test_dataset):\n    model = load_model(saved_model)\n    sub_path = \"\/kaggle\/input\/plant-pathology-2020-fgvc7\/sample_submission.csv\"\n    sub = pd.read_csv(sub_path)\n    probs_mobilenet = model.predict(test_dataset, verbose=1)\n    sub.loc[:, 'healthy':] = probs_mobilenet\n    sub.to_csv('submission_mobilenet.csv', index=False)\n    print(sub.head())\n","54ac0dac":"with strategy.scope():\n    # \u6a21\u578b\u5b9a\u4e49\n    train_data = pd.read_csv(train_path)\n    train_labels = np.float32(train_data.loc[:, 'healthy':'scab'].values)\n    batch_size=BATCH_SIZE\n    model = mobile_model_define(train_labels=train_labels,batch_size=batch_size)","860b0e33":"# \u6a21\u578b\u8bad\u7ec3\nmodel_save_dir = 'models'\nif not os.path.exists(model_save_dir):\n    os.makedirs(model_save_dir)\nsaved_path = os.path.join(os.getcwd(), model_save_dir) + '\/mobilenetv2.h5' # \u56fe\u7247\u5b58\u653e\u8def\u5f84\nprint(saved_path)\nepochs = 20\nsteps_per_epoch =train_labels.shape[0] \/\/ BATCH_SIZE\n\nhistory = mobile_model_train(model,train_dataset,valid_dataset,epochs,steps_per_epoch,saved_path)\n","61b7cc3c":"# \u6a21\u578b\u8bc4\u4f30\nmobile_model_estimate(history,epochs)","5f86b5a2":"# \u6a21\u578b\u9884\u6d4b\uff0c\u663e\u793a\u524d\u56db\u5e45\u56fe\u50cf\u9884\u6d4b\u7ed3\u679c\nmobile_display_four_examples(saved_path,train_data)","8f137783":"%%time\n# \u5bf9\u6d4b\u8bd5\u96c6\u505a\u9884\u6d4b\uff0c\u4fdd\u5b58\u9884\u6d4b\u7ed3\u679c\nmobile_test_dataset_predict(saved_model=saved_path,test_dataset=test_dataset)","04cf1041":"# 1 DenseNet121 Model****","22ef7f3e":"# 2 MobileNetV2","bff24fe2":"### Acknowledgements\n### \u53c2\u8003\uff1a<a href = 'https:\/\/www.kaggle.com\/tarunpaparaju\/plant-pathology-2020-eda-models'>Plant Pathology 2020 : EDA + Models <\/a>","a114a826":"\u70df\u53f0\u82f9\u679c\u7532\u5929\u4e0b\uff0c\u9a70\u540d\u6d77\u5916\uff0c\u70df\u53f0\u82f9\u679c\u65e2\u597d\u770b\u53c8\u597d\u5403\u3002\u751f\u6d3b\u5728\u76db\u4ea7\u82f9\u679c\u7684\u6545\u4e61\uff0c\u4ece\u5c0f\u5543\u7740\u82f9\u679c\u957f\u5927\uff0c\u4e0e\u679c\u56ed\u548c\u679c\u6811\u6253\u4ea4\u9053\uff0c\u53c2\u52a0\u679c\u56ed\u7ba1\u7406\uff0c\u65bd\u80a5\u3001\u6d47\u6c34\u3001\u53bb\u75c5\u866b\u5bb3\u548c\u6536\u83b7\uff0c\u5404\u7c7b\u82f9\u679c\u7684\u5473\u9053\u3001\u679c\u6811\u7684\u5473\u9053\u3001\u519c\u836f\u7684\u5473\u9053\u3001\u6811\u679d\u6811\u53f6\u6811\u76ae\u7684\u5473\u9053\uff0c\u5bf9\u679c\u56ed\u719f\u6089\u5f97\u4e0d\u80fd\u518d\u719f\u6089\u3002<br\/>\n\u8fc7\u5f80\u5728\u679c\u56ed\u52b3\u52a8\u7684\u573a\u666f\u5386\u5386\u5728\u76ee\uff0c\u6240\u4ee5\u770b\u5230\u6709\u8fd9\u6837\u4e00\u4e2a\u6570\u636e\u96c6\uff0c\u7acb\u5373\u88ab\u5438\u5f15\u4e86\u3002\u672c\u6848\u4f8b\u662f\u5bf9DenseNet121\u4e0eMobileNetV2\u7684\u6a21\u578b\u6027\u80fd\u505a\u6bd4\u8f83\u3002<br\/>\n\u5199\u5f97\u5f88\u6d45\uff0c\u4ee5\u540e\u6709\u65f6\u95f4\u518d\u56de\u6765\u8865\u5145\u5b8c\u5584\u3002<br\/>\n\u4e3b\u8981\u53c2\u7167\u4e86\u4f5c\u8005\uff1a<a href='https:\/\/www.kaggle.com\/tarunpaparaju'>Tarun Paparaju<\/a> \u7684\u4f5c\u54c1\uff0c\u6709\u4e00\u5b9a\u7684\u53c2\u6570\u6539\u826f\uff0c\u91cd\u65b0\u8fdb\u884c\u4e86\u6a21\u5757\u5316\u8bbe\u8ba1\uff0c\u4fbf\u4e8e\u8fc1\u79fb\u5230Pycharm\u7b49IDE\u73af\u5883\u4e0b\u8fd0\u884c\u3002","a99c5e47":"## 1.2 \u5efa\u6a21\u4e0e\u8bc4\u4f30","63e5f290":"## 1.1 \u6570\u636e\u9884\u5904\u7406"}}