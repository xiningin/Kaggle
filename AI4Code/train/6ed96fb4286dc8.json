{"cell_type":{"c77a5be9":"code","d34e94af":"code","b0fa6852":"code","5f55f745":"code","63ee4242":"code","1ce0eca8":"code","12e033de":"code","28cd910e":"code","1b2c83c3":"code","27d350fa":"code","f733cc5b":"code","73b8def6":"code","bb9966b2":"code","d72470d9":"code","b9c45321":"code","f070fafe":"code","c6e30295":"markdown","8490b338":"markdown"},"source":{"c77a5be9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","d34e94af":"# Dimentionality Reduction Using PCA\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","b0fa6852":"from sklearn.datasets import load_breast_cancer","5f55f745":"lbc = load_breast_cancer()\nlbc.keys()","63ee4242":"lbc['DESCR']","1ce0eca8":"df = pd.DataFrame(lbc['data'], columns = lbc['feature_names'])\ndf.head()","12e033de":"from sklearn.preprocessing import StandardScaler","28cd910e":"scaler = StandardScaler()\n\n#return type of fit_transform is array\nscaled_data = scaler.fit_transform(df)","1b2c83c3":"scaled_data","27d350fa":"from sklearn.decomposition import PCA\npca = PCA(n_components=2)\n\n#return type array\nx_pca = pca.fit_transform(scaled_data)","f733cc5b":"x_pca","73b8def6":"# Compare shape\nprint(\"Scaled Data Shape:\")\nprint(scaled_data.shape)\nprint(\"PCA Data Shape:\")\nprint(x_pca.shape)","bb9966b2":"plt.figure(figsize=(8,6))\nplt.scatter(x_pca[:,0], x_pca[:,1], c=lbc['target'], cmap='plasma')\nplt.xlabel(\"First Principal Component\")\nplt.ylabel(\"Second Principal Component\")","d72470d9":"pca.components_\n# Shape of 2x30","b9c45321":"df_comp = pd.DataFrame(pca.components_, columns=lbc['feature_names'])\ndf_comp.head()","f070fafe":"plt.figure(figsize=(12,6))\nsns.heatmap(df_comp, cmap='plasma')","c6e30295":"This heatmap and the color bar basically represent the correlation between the various feature and the principal component itself.\n## Conclusion\nHopefully this information is useful to you when dealing with high dimensional data!","8490b338":"## Interpreting the components\n\nUnfortunately, with this great power of dimensionality reduction, comes the cost of being able to easily understand what these components represent.  \nThe components correspond to combinations of the original features, the components themselves are stored as an attribute of the fitted PCA object:"}}