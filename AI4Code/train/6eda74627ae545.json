{"cell_type":{"39403616":"code","5fcfcc3f":"code","c0633141":"code","55c7b29d":"code","d1ec34f4":"code","065443c2":"code","069bb259":"code","59398bf0":"code","027c67f9":"code","a13d1e5c":"code","d5e4b4ff":"code","944d9753":"code","0a921f96":"code","177f1fde":"code","62fc3b99":"code","0352abde":"code","f04cfb34":"code","6152bef2":"code","ed500fce":"code","7bd93632":"code","a08a74ee":"code","76d09395":"code","bd8a5d90":"code","48657ed8":"code","6aaf7593":"code","a50e7315":"code","cdb43741":"code","35182258":"code","031e111f":"code","6b93ed7b":"code","28e8aaa5":"markdown","18eb7489":"markdown","084bb8f7":"markdown","fbb03963":"markdown","c9999c3a":"markdown","d375ee4a":"markdown","326dcefe":"markdown","f6ee155b":"markdown","8b4cf6af":"markdown","f0df49ce":"markdown","cae92ba6":"markdown","c55c1c89":"markdown","d472c08a":"markdown","a99dc938":"markdown","950a747e":"markdown","76f93f4c":"markdown","5aac876f":"markdown","398c0ffd":"markdown","796863a7":"markdown","fe9102c3":"markdown","3a8b2e33":"markdown","131445f0":"markdown","c5d90da7":"markdown","65fd7361":"markdown","af20d84f":"markdown","f0859cce":"markdown","da318606":"markdown","3a85746a":"markdown","7890666e":"markdown"},"source":{"39403616":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5fcfcc3f":"#basics\nimport numpy as np\nimport pandas as pd\n\n#interactive graph\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.io as pio\npio.templates.default = \"ggplot2\"\n\n#graph\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","c0633141":"offense = pd.read_csv(r'..\/input\/nba-stats\/off.csv')\ndefense = pd.read_csv(r'..\/input\/nba-stats\/defen.csv')\noverall = pd.read_csv(r'..\/input\/nba-stats\/ovr.csv')\n#oringinal data\ndf = pd.read_csv(r'..\/input\/nba-stats\/NBA_all.csv')","55c7b29d":"#Check data\n\n#function for checking missing value\ndef miss_val(data):\n    m=0\n    if sum(data.isnull().sum())==0:\n        m = 'No Missing value'\n    else:\n        m = 'There is at least one missing value in the data'\n    return str(m) ","d1ec34f4":"print('Data Checking:')\nprint(\"\\n========================================\")\nprint('1.Offensive data:'+ miss_val(offense)+\"\\n\")\noffense.info()\nprint(\"\\n========================================\")\nprint('2.Defensive data:'+ miss_val(defense)+\"n\")\ndefense.info()\nprint(\"\\n========================================\")\nprint('3.Overall data:'+ miss_val(overall)+\"\\n\")\noverall.info()\nprint(\"\\n========================================\")\nprint('4.All data:'+ miss_val(df)+\"\\n\")\ndf.info()","065443c2":"from sklearn.preprocessing import StandardScaler\n#offensive data\nscaler1 = StandardScaler().fit(offense)\noff_norm = scaler1.transform(offense)\n#defensive data\nscaler2 = StandardScaler().fit(defense)\ndef_norm = scaler2.transform(defense)\n#overall data\nscaler3 = StandardScaler().fit(overall)\novr_norm = scaler3.transform(overall)","069bb259":"from sklearn.decomposition import PCA","59398bf0":"#Line chart help us observate the chnaging of total explained ratio\n#while different dimension\n\n#input\n#norm_data : Normalized data, name:data name(such as \"Offensive Data\")\ndef sumratio(norm_data, name): \n    max_dim = norm_data.shape[1]\n    sum_ratio = {}\n    if(max_dim>10):\n        M = 10\n    else:\n        M = max_dim\n    for i in range(1,M):\n        pca = PCA(n_components = i)\n        pca.fit(norm_data)\n        off_pca = pca.transform(norm_data)\n        sum_ratio[i] = pca.explained_variance_ratio_.sum()\n\n    sum_ratio = pd.DataFrame(sum_ratio.items(),\n                             columns=['no. of dimension','Total_explain_ratio'])\n\n    fig = px.line(sum_ratio, x=\"no. of dimension\",\n                  y=\"Total_explain_ratio\", title='Total Variance Explaind ratio of '+ name)\n    fig.show() \n\n#3D scatter plot: visualized the result of ruducing dimensions to 3.\n#input\n#data:normalized data that be reduced to 3 dimensions\ndef triD_scatter(data):\n    fig = px.scatter_3d(\n        data, x=0, y=1, z=2,\n        labels={'0': 'PC 1', '1': 'PC 2', '2': 'PC 3'},\n        size_max=1,\n        opacity=0.3\n    )\n    fig.show()","027c67f9":"sumratio(off_norm,'Offensive Data')","a13d1e5c":"pca = PCA(n_components = 3)\npca.fit(off_norm)\noff_pca = pca.transform(off_norm)\nprint(pca.explained_variance_ratio_.sum())\ntriD_scatter(off_pca)","d5e4b4ff":"sumratio(def_norm, 'defensive Data')","944d9753":"pca2 = PCA(n_components = 3)\npca2.fit(def_norm)\ndef_pca = pca2.transform(def_norm)\nprint(pca2.explained_variance_ratio_.sum())\ntriD_scatter(def_pca)","0a921f96":"sumratio(ovr_norm, 'Overall Data')","177f1fde":"pca3 = PCA(n_components = 3)\npca3.fit(ovr_norm)\novr_pca = pca3.transform(ovr_norm)\nprint(pca3.explained_variance_ratio_.sum())\ntriD_scatter(ovr_pca)","62fc3b99":"from sklearn.cluster import KMeans\n\n#silhouette\nfrom sklearn.metrics import silhouette_score\n#yellow brick\nfrom yellowbrick.cluster import silhouette_visualizer\nfrom yellowbrick.datasets import load_credit","0352abde":"#inertia plot\ndef iner_plot(pca_data,name):\n    inertia={}\n    for i in range(1,10):\n        kmeans=KMeans(n_clusters=i)\n        kmeans.fit(pca_data)\n        inertia[i] = kmeans.inertia_\n\n    inertiadf = pd.DataFrame(inertia.items(), columns=['num of cluster','inertia'])\n\n    fig = px.line(inertiadf, x=\"num of cluster\", y=\"inertia\", title='Inertia of ' + name)\n    fig.show()\n    \n#sihouette1\ndef sil_1(data):\n    for i in range(2,11):\n        silhouette_visualizer(KMeans(i, random_state=42), data, colors='RdBu')\n        \n#silhouette2 (Calculate silhouette based on normalized data)\ndef sil_2(pca_data,norm_data, name):\n    sil2 = {}\n    #print('Silhouette score of normalized' + name + 'data while n_cluster=2~10:')\n    for i in range(2,11):\n        km = KMeans(n_clusters = i, random_state= 42)\n        km.fit(pca_data)\n        sil2[i] = silhouette_score(norm_data, km.labels_)\n        #print(\"Silhouette Score (n_cluster=\"+ str(i) + \"):\", silhouette_score(norm_data, km.labels_))\n    sil2_df = pd.DataFrame(sil2.items(), columns = ['no. of clusters','silhouette'])\n    max_index = sil2_df['silhouette'].idxmax()\n    colors = ['lightslategray',] * 10\n    colors[max_index] = 'crimson'\n    fig = go.Figure(data=[go.Bar(\n        x=sil2_df['no. of clusters'],\n        y=sil2_df['silhouette'],\n        marker_color=colors # marker color can be a single color value or an iterable\n    )])\n    fig.update_layout(title_text='Silhouette score of normalized ' + name,\n                      xaxis=dict(\n                                  title = 'n_clusters'\n                                ),\n                      yaxis=dict(title = 'Silhouette')\n                     )\n    fig.show()","f04cfb34":"#Inertia\niner_plot(off_pca, 'Offensive Data')","6152bef2":"sil_1(off_pca)","ed500fce":"sil_2(off_pca, off_norm, 'Offensive Data')","7bd93632":"iner_plot(def_pca, 'Defensive Data')","a08a74ee":"sil_1(def_pca)","76d09395":"sil_2(def_pca, def_norm, 'Defensive Data')","bd8a5d90":"iner_plot(ovr_pca, 'overall data')","48657ed8":"sil_1(ovr_pca)","6aaf7593":"sil_2(ovr_pca, ovr_norm, 'Overall Data')","a50e7315":"#offensive data\noffensive = KMeans(n_clusters = 4, random_state= 42)\noffensive.fit(off_pca)\noffense['Off_kmean'] = offensive.labels_\ndf['Off_kmean'] = offensive.labels_\n\n#def\ndefensive = KMeans(n_clusters = 3, random_state= 42)\ndefensive.fit(off_pca)\ndefense['Def_kmean'] = defensive.labels_\ndf['Def_kmean'] = defensive.labels_\n\n#off\novr = KMeans(n_clusters = 3, random_state= 42)\novr.fit(off_pca)\noverall['Ovr_kmean'] = ovr.labels_\ndf['Ovr_kmean'] = ovr.labels_","cdb43741":"#Off\nfig = px.scatter_3d(\n    off_pca, x=0, y=1, z=2,\n    labels={'0': 'PC 1', '1': 'PC 2', '2': 'PC 3'},\n    size_max=1,\n    color = df['Off_kmean'],\n\n    opacity=0.3\n)\nfig.show()","35182258":"#def\nfig = px.scatter_3d(\n    def_pca, x=0, y=1, z=2,\n    labels={'0': 'PC 1', '1': 'PC 2', '2': 'PC 3'},\n    size_max=1,\n    color = df['Def_kmean'],\n\n    opacity=0.3\n)\nfig.show()","031e111f":"fig = px.scatter_3d(\n    ovr_pca, x=0, y=1, z=2,\n    labels={'0': 'PC 1', '1': 'PC 2', '2': 'PC 3'},\n    size_max=1,\n    color = df['Ovr_kmean'],\n\n    opacity=0.3\n)\nfig.show()","6b93ed7b":"df.to_csv(r'.\/\/Combined_data.csv', index=False)\noffense.to_csv(r'.\/\/Combined_offensive.csv', index=False)\ndefense.to_csv(r'.\/\/Combined_defensive.csv', index=False)\noverall.to_csv(r'.\/\/Combined_overall.csv', index=False)","28e8aaa5":"### Defensive","18eb7489":"<a id=00><\/a>\n# Table of Content\n\n1. [Data Checking](#01)\n2. [Z-score Normalization](#02)\n3. [PCA](#03)\n> 3.1. [PCA-Offensive Data](#04)\n    \n > 3.2. [PCA-Defensive Data](#05)\n  \n > 3.3. [PCA-Overall Data](#06)\n  \n4. [KMeans-Evaluation](#07)\n> 4.1. [Kmeans-Offensive Data](#08)\n \n > 4.2. [Kmeans-Defensive Data](#09)\n  \n > 4.3. [Kmeans-Overall Data](#10)\n\n5. [Kmeans-Inplementation\/Results\/Data Output](#11)\n\n  ","084bb8f7":"<a id=11><\/a>\n# 5. [Kmeans-Inplementation\/Results\/Data Output](#00)","fbb03963":"### Evaluation:","c9999c3a":"n_clusters = 3 has best perfromance.","d375ee4a":"<a id=07><\/a>\n# 4. [KMeans-Evaluation](#00)","326dcefe":"<a id=10><\/a>\n## 4.3. [KMeans-Overall Data](#00)","f6ee155b":"<a id=03><\/a>\n# 3.[ PCA](#00)","8b4cf6af":"<a id=06><\/a>\n## 3.3. [PCA-Overall Data](#00)","f0df49ce":"<a id=09><\/a>\n## 4.2. [KMeans-Defensive Data](#00)","cae92ba6":"### Functions for PCA ","c55c1c89":"<a id=08><\/a>\n## 4.1. [KMeans-Offensive Data](#00)","d472c08a":"<a id=04><\/a>\n## 3.1.[ PCA - Offensive Data](#00)","a99dc938":"# Cluster NBA player implementing PCA and Kmeans\n\n1. Data Source:NBA.stats\n2. Samples: 6734 instances from NBA player data between season 2005-06 and season 2019-2020.\n   (Reckon that same player in different season as different player, since NBA players usually change their playing style by years)\n3. Datasets was saperated to three sub-topic:(1) offensive data, (2) defensive data (3) overall data","950a747e":"<a id=05><\/a>\n## 3.2. [PCA-Defensive Data](#00)","76f93f4c":"### Essential Functions","5aac876f":"import files","398c0ffd":"### Conclusion\n* 4 clusters for Offfensive data\n* n_cluster = 2 has the best performance; However, classify player into just 2 groups seems not that reasonable, I decided to try n_clusters=3.\n* 3 clusters for overall data.","796863a7":"There's no any missing value in the datasets.","fe9102c3":"### Import libraries ","3a8b2e33":"### Offensive","131445f0":"### Data Output","c5d90da7":"### import PCA library from Scikit learn","65fd7361":"<a id=01><\/a>\n# 1. [Data Checking](#00)","af20d84f":"n_cluster=2 has better performance than any other.","f0859cce":"According to results of these three cluster performance evaluation approaches, 4 is the second optimal number of n_clusters.","da318606":"# Why cluster NBA players?\nRecently, NBA games are completly different than before. Players on court usaully do what their position roles were not supposed to do. It is hard to imaging that a center or a power forward frequently shoots 3 pointer in 90s or in early 2000; however, this senareo has become more and more common nowadays, and as a result defining player by his performance might be better than defining a player by his position. ","3a85746a":"<a id=02><\/a>\n# 2.[ Z-score Normalization](#00)","7890666e":"### Overall"}}