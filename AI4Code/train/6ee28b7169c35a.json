{"cell_type":{"553d2c46":"code","b8e7e5dc":"code","a1024b99":"code","2710ec6e":"code","b14b37ee":"code","2bffb3f6":"code","0300fe27":"code","6a946a4b":"code","7c2dd678":"code","a4cb3b29":"code","9983241d":"code","541e44e9":"code","a3b0f946":"code","660d5ca0":"code","1c174e9a":"code","b93a0a86":"code","bf9f0449":"code","1c1b4500":"code","5d073155":"code","8ccddab5":"code","0066a8c4":"code","d5ec2932":"code","387fb2af":"code","efaf3c68":"code","f83cdc19":"code","562de898":"code","bf7a276f":"code","b380f224":"code","f286fe4a":"code","e4f1a953":"code","7a34a35f":"code","7a148e2d":"code","b2d88645":"code","74aa7acd":"code","7e2fedc2":"code","7d77bfb1":"markdown","170e286e":"markdown","d1a3ecff":"markdown","47c5b7dd":"markdown","df675f38":"markdown"},"source":{"553d2c46":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nfrom warnings import filterwarnings\nfilterwarnings('ignore')","b8e7e5dc":"hit = pd.read_csv(\"\/kaggle\/input\/hitters\/Hitters.csv\")\ndf = hit.copy()\ndf = df.dropna()\ndf.head()","a1024b99":"df.info()","2710ec6e":"def check_df(dataframe, head=5):\n    print(\"##################### Shape #####################\")\n    print(dataframe.shape)\n    print(\"##################### Types #####################\")\n    print(dataframe.dtypes)\n    print(\"##################### Head #####################\")\n    print(dataframe.head(head))\n    print(\"##################### Tail #####################\")\n    print(dataframe.tail(head))\n    print(\"##################### NA #####################\")\n    print(dataframe.isnull().sum())\n    print(\"##################### Quantiles #####################\")\n    print(dataframe.quantile([0, 0.05, 0.50, 0.95, 0.99, 1]).T)","b14b37ee":"check_df(df)","2bffb3f6":"one_hot_encoding = pd.get_dummies(df[['League', 'Division', 'NewLeague']],drop_first=True)\none_hot_encoding .head() ","0300fe27":"sns.distplot(df.Salary);","6a946a4b":"df.groupby([\"League\", \"Division\"]).agg({\"Salary\":[\"mean\", \"median\"],\n                            \"Hits\":[\"mean\",\"median\"],\n                            \"Years\":[\"mean\", \"median\"],\n                            \"CHits\":[\"mean\", \"median\"],\n                            \"CAtBat\":[\"mean\", \"median\"],\n                            \"Assists\":[\"mean\", \"median\"],\n                            \"Errors\":[\"mean\", \"median\"],})","7c2dd678":"#Analysis of Categorical Variables\n\ndef grab_col_names(dataframe, cat_th=10, car_th=20):\n    \"\"\"\n\n    Veri setindeki kategorik, numerik ve kategorik fakat kardinal de\u011fi\u015fkenlerin isimlerini verir.\n    Not: Kategorik de\u011fi\u015fkenlerin i\u00e7erisine numerik g\u00f6r\u00fcn\u00fcml\u00fc kategorik de\u011fi\u015fkenler de dahildir.\n\n    Parameters\n    ------\n        dataframe: dataframe\n                De\u011fi\u015fken isimleri al\u0131nmak istenilen dataframe\n        cat_th: int, optional\n                numerik fakat kategorik olan de\u011fi\u015fkenler i\u00e7in s\u0131n\u0131f e\u015fik de\u011feri\n        car_th: int, optional\n                kategorik fakat kardinal de\u011fi\u015fkenler i\u00e7in s\u0131n\u0131f e\u015fik de\u011feri\n\n    Returns\n    ------\n        cat_cols: list\n                Kategorik de\u011fi\u015fken listesi\n        num_cols: list\n                Numerik de\u011fi\u015fken listesi\n        cat_but_car: list\n                Kategorik g\u00f6r\u00fcn\u00fcml\u00fc kardinal de\u011fi\u015fken listesi\n\n    Examples\n    ------\n        import seaborn as sns\n        df = sns.load_dataset(\"iris\")\n        print(grab_col_names(df))\n\n\n    Notes\n    ------\n        cat_cols + num_cols + cat_but_car = toplam de\u011fi\u015fken say\u0131s\u0131\n        num_but_cat cat_cols'un i\u00e7erisinde.\n\n    \"\"\"\n\n    # cat_cols, cat_but_car\n    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n\n    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n                   dataframe[col].dtypes != \"O\"]\n\n    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n                   dataframe[col].dtypes == \"O\"]\n\n    cat_cols = cat_cols + num_but_cat\n\n    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n\n    # num_cols\n    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n\n    num_cols = [col for col in num_cols if col not in num_but_cat]\n\n    print(f\"Observations: {dataframe.shape[0]}\")\n    print(f\"Variables: {dataframe.shape[1]}\")\n    print(f'cat_cols: {len(cat_cols)}')\n    print(f'num_cols: {len(num_cols)}')\n    print(f'cat_but_car: {len(cat_but_car)}')\n    print(f'num_but_cat: {len(num_but_cat)}')\n\n    return cat_cols, num_cols, cat_but_car\n\n\ncat_cols, num_cols, cat_but_car = grab_col_names(df)\n","a4cb3b29":"def cat_summary(dataframe, col_name, plot=False):\n\n    print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),\n                        \"Ratio\": 100 * dataframe[col_name].value_counts() \/ len(dataframe)}))\n\nfor col in cat_cols:\n    cat_summary(df, col, plot=True)","9983241d":"df.isnull().values.any()","541e44e9":"def missing_values_table(dataframe, na_name=False):\n    na_columns = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]\n    n_miss = dataframe[na_columns].isnull().sum().sort_values(ascending=False)\n    ratio = (dataframe[na_columns].isnull().sum() \/ dataframe.shape[0] * 100).sort_values(ascending=False)\n    missing_df = pd.concat([n_miss, np.round(ratio, 2)], axis=1, keys=['n_miss', 'ratio'])\n    print(missing_df, end=\"\\n\")\n    if na_name:\n        return na_columns\nmissing_values_table(df, True)","a3b0f946":"df.dropna(inplace=True)","660d5ca0":"def outlier_thresholds(dataframe, col_name, q1=0.05, q3=0.95):\n    quartile1 = dataframe[col_name].quantile(q1)\n    quartile3 = dataframe[col_name].quantile(q3)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit","1c174e9a":"for col in num_cols:\n    print(outlier_thresholds(df, col))","b93a0a86":"def check_outlier(dataframe, col_name):\n    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n        return True\n    else:\n        return False","bf9f0449":"for col in num_cols:\n    print(col, check_outlier(df, col))","1c1b4500":"def grab_outliers(dataframe, col_name, index=False):\n    low, up = outlier_thresholds(dataframe, col_name)\n    if dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].shape[0] > 10:\n        print(dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].head())\n    else:\n        print(dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))])\n\n    if index:\n        outlier_index = dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].index\n        return outlier_index","5d073155":"for col in num_cols:\n    grab_outliers(df, col)","8ccddab5":"def replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit","0066a8c4":"for col in num_cols:\n    replace_with_thresholds(df,col)","d5ec2932":"y = df[\"Salary\"]","387fb2af":"X_ = df.drop([\"Salary\",\"League\",\"Division\",\"NewLeague\"], axis = 1).astype(\"float64\")\n\n#Ba\u011f\u0131ml\u0131 de\u011fi\u015fkeni ve kategorik de\u011fi\u015fkenlerin  initial states'lerini veri k\u00fcmesinden \u00e7\u0131kard\u0131k.","efaf3c68":"X_.head()","f83cdc19":"X = pd.concat([X_, one_hot_encoding[[\"League_N\", \"Division_W\",\"NewLeague_N\"]]], axis = 1)\nX.head()\n#Elimizdeki de\u011fi\u015fkenleri modellemeye haz\u0131r hale getirdik.","562de898":"from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict","bf7a276f":"X_train, X_test, y_train, y_test = train_test_split(X,\n                                                    y,\n                                                    test_size=0.20, random_state=1)","b380f224":"print(\"X_train\", X_train.shape)\n\nprint(\"y_train\",y_train.shape)\n\nprint(\"X_test\",X_test.shape)\n\nprint(\"y_test\",y_test.shape)","f286fe4a":"training = df.copy()\n\nprint(\"training\", training.shape)","e4f1a953":"lm = LinearRegression()\npcr_model = lm.fit(X_train, y_train)\npcr_model.intercept_","7a34a35f":"pcr_model.coef_","7a148e2d":"from sklearn.metrics import mean_squared_error, r2_score\ny_pred = pcr_model.predict(X_train)\ny_pred[0:5]","b2d88645":"np.sqrt(mean_squared_error(y_train, y_pred))","74aa7acd":"df[\"Salary\"].mean()","7e2fedc2":"r2_score(y_train, y_pred)","7d77bfb1":"<a id = \"1\"><\/a><h1 id=\"\u0130\u015f Problemi\"><span class=\"label label-default\" style=\"background-color:#f5c0c0; font-size:30px; color: Black; \">\u0130\u015f Problemi<\/span><\/h1>\n\n\u27a4 Maa\u015f bilgileri ve 1986 y\u0131l\u0131na ait kariyer istatistikleri payla\u015f\u0131lan beyzbol oyuncular\u0131n\u0131n maa\u015f tahminleri i\u00e7in bir makine \u00f6\u011frenmesi projesi ger\u00e7ekle\u015ftirilebilir mi?","170e286e":"<a id = \"1\"><\/a><h1 id=\"G\u00f6rev\"><span class=\"label label-default\" style=\"background-color:#f5c0c0; font-size:30px; color: Black; \">G\u00f6rev<\/span><\/h1>\nVeri \u00f6n i\u015fleme ve \u00f6zellik m\u00fchendisli\u011fi tekniklerini kullanarak maa\u015f tahmin modeli geli\u015ftiriniz.","d1a3ecff":"![photo-718952.jpeg](attachment:ef485a46-20d7-443d-bb64-17b68b362561.jpeg)","47c5b7dd":"<a id = \"1\"><\/a><h1 id=\"De\u011fi\u015fkenler\"><span class=\"label label-default\" style=\"background-color:#f5c0c0; font-size:30px; color: Black; \">De\u011fi\u015fkenler<\/span><\/h1>\n\nAtBat: 1986-1987 sezonunda bir beyzbol sopas\u0131 ile topa yap\u0131lan vuru\u015f say\u0131s\u0131\n\nHits: 1986-1987 sezonundaki isabet say\u0131s\u0131\n\nHmRun: 1986-1987 sezonundaki en de\u011ferli vuru\u015f say\u0131s\u0131\n\nRuns: 1986-1987 sezonunda tak\u0131m\u0131na kazand\u0131rd\u0131\u011f\u0131 say\u0131\n\nRBI: Bir vurucunun vuru\u015f yapt\u0131g\u0131nda ko\u015fu yapt\u0131rd\u0131\u011f\u0131 oyuncu say\u0131s\u0131\n\nWalks: Kar\u015f\u0131 oyuncuya yapt\u0131r\u0131lan hata say\u0131s\u0131\n\nYears: Oyuncunun major liginde oynama s\u00fcresi (sene)\n\nCAtBat: Oyuncunun kariyeri boyunca topa vurma say\u0131s\u0131\n\nCHits: Oyuncunun kariyeri boyunca yapt\u0131\u011f\u0131 isabetli vuru\u015f say\u0131s\u0131\n\nCHmRun: Oyucunun kariyeri boyunca yapt\u0131\u011f\u0131 en de\u011ferli say\u0131s\u0131\n\nCRuns: Oyuncunun kariyeri boyunca tak\u0131m\u0131na kazand\u0131rd\u0131\u011f\u0131 say\u0131\n\nCRBI: Oyuncunun kariyeri boyunca ko\u015fu yapt\u0131rd\u0131rd\u0131\u011f\u0131 oyuncu say\u0131s\u0131\n\nCWalks: Oyuncun kariyeri boyunca kar\u015f\u0131 oyuncuya yapt\u0131rd\u0131\u011f\u0131 hata say\u0131s\u0131\n\nLeague: Oyuncunun sezon sonuna kadar oynad\u0131\u011f\u0131 ligi g\u00f6steren A ve N seviyelerine sahip bir fakt\u00f6r\n\nDivision: 1986 sonunda oyuncunun oynad\u0131\u011f\u0131 pozisyonu g\u00f6steren E ve W seviyelerine sahip bir fakt\u00f6r\n\nPutOuts: Oyun icinde tak\u0131m arkada\u015f\u0131nla yard\u0131mla\u015fma\n\nAssits: 1986-1987 sezonunda oyuncunun yapt\u0131\u011f\u0131 asist say\u0131s\u0131\n\nErrors: 1986-1987 sezonundaki oyuncunun hata say\u0131s\u0131\n\nSalary: Oyuncunun 1986-1987 sezonunda ald\u0131\u011f\u0131 maa\u015f(bin uzerinden)\n\nNewLeague: 1987 sezonunun ba\u015f\u0131nda oyuncunun ligini g\u00f6steren A ve N seviyelerine sahip bir fakt\u00f6r","df675f38":"<a id = \"1\"><\/a><h1 id=\"Veri Seti Hikayesi\"><span class=\"label label-default\" style=\"background-color:#f5c0c0; font-size:30px; \ncolor: Black; \">Veri Seti Hikayesi<\/span><\/h1>\n\nBu veri seti orijinal olarak Carnegie Mellon \u00dcniversitesi'nde bulunan StatLib k\u00fct\u00fcphanesinden al\u0131nm\u0131\u015ft\u0131r. Veri seti 1988 ASA Grafik B\u00f6l\u00fcm\u00fc Poster Oturumu'nda kullan\u0131lan verilerin bir par\u00e7as\u0131d\u0131r. Maa\u015f verileri orijinal olarak Sports Illustrated, 20 Nisan 1987'den al\u0131nm\u0131\u015ft\u0131r.1986 ve kariyer istatistikleri, Collier Books, Macmillan Publishing Company, New York taraf\u0131ndan yay\u0131nlanan 1987 Beyzbol Ansiklopedisi G\u00fcncellemesinden elde edilmi\u015ftir.\n\n\nKullan\u0131c\u0131n\u0131n performanslar\u0131na ili\u015fkin bir veri setimiz bulunmaktad\u0131r. Veri seti Amerika'da bulunan bir beyzbol liginin 1986 - 1987 sezonunundaki verileri ve bu ligde oynayan oyuncular\u0131n verilerini i\u00e7eren bir veri setidir."}}