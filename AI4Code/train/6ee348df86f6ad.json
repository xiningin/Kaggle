{"cell_type":{"1a36e48f":"code","71ed1457":"code","336a8f4d":"code","8125d294":"code","e5341706":"code","95758a0a":"code","4361f0aa":"code","19ce771b":"code","24e17e92":"code","3e25377c":"code","4ca79dc2":"code","b3c23ff5":"code","c77b6612":"code","195165b0":"code","4edec315":"code","b55be30d":"code","898105f6":"code","83507d7b":"code","37cae4f8":"code","0a0e3421":"code","e94fcdaf":"code","d264c0c0":"code","5bf8c5e0":"code","79f99a9f":"code","7b20431c":"code","e6b8b87a":"code","1dcce2ba":"code","c86329c5":"code","fa95ab66":"code","2edc5ed7":"code","4ccf54bc":"code","6bf0ffa9":"code","671794fd":"code","1ecb1156":"code","c4700564":"code","053b89cc":"code","277954f7":"code","51315984":"code","944f0d8d":"code","af9b9d3d":"markdown","9050a0e6":"markdown","faa41d66":"markdown","f713b4e0":"markdown","0f3ed585":"markdown","256e52ba":"markdown","5be9c802":"markdown","fd016d52":"markdown","f0da98f5":"markdown","55544a93":"markdown","6d7b939f":"markdown","193ec090":"markdown","7ec11f35":"markdown","aa7baad6":"markdown","6acacdaa":"markdown","66759dd2":"markdown","61b2cadc":"markdown"},"source":{"1a36e48f":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix","71ed1457":"df = pd.read_csv('..\/input\/heart-disease-uci\/heart.csv')","336a8f4d":"df.isna().sum()","8125d294":"df['thal'].unique()","e5341706":"df.loc[df['thal'] == 0]","95758a0a":"df.columns","4361f0aa":"df.columns = ['age', 'sex', 'chest_pain_type', 'resting_blood_pressure', 'cholesterol', 'fasting_blood_sugar', 'rest_ecg', 'max_heart_rate_achieved',\n       'exercise_induced_angina', 'st_depression', 'st_slope', 'num_major_vessels', 'thalassemia', 'target']","19ce771b":"df['sex'] = df['sex'].map({0: 'F',\n                           1: 'M'})\n\ndf['chest_pain_type'] = df['chest_pain_type'].map({0: 'typical angina',\n                                                   1: 'atypical angina',\n                                                   2: 'non-anginal pain',\n                                                   3: 'asymptomatic'})\n\ndf['fasting_blood_sugar'] = df['fasting_blood_sugar'].map({0: 'lower than 120mg\/ml',\n                                                           1: 'greater than 120mg\/ml'})\n\ndf['rest_ecg'] = df['rest_ecg'].map({0: 'normal',\n                                     1: 'ST-T wave abnormality',\n                                     2: 'left ventricular hypertrophy'})\n\ndf['exercise_induced_angina'] = df['exercise_induced_angina'].map({0: 'no',\n                                                                   1: 'yes'})\n\ndf['st_slope'] = df['st_slope'].map({0: 'upsloping',\n                                     1: 'flat',\n                                     2: 'downsloping'})\n\ndf['thalassemia'] = df['thalassemia'].map({1: 'normal',\n                                           2: 'fixed defect',\n                                           3: 'reversable defect'})","24e17e92":"df.head()","3e25377c":"df.dtypes","4ca79dc2":"sns.displot(data=df, x='age', col='sex', hue='target', kind='kde')","b3c23ff5":"sns.displot(data=df, x='age', col='chest_pain_type', hue='target')","c77b6612":"sns.displot(df['resting_blood_pressure'], kde=True)","195165b0":"sns.displot(df['cholesterol'], kde=True)","4edec315":"df.loc[df['cholesterol'] > 500]","b55be30d":"sns.displot(df['max_heart_rate_achieved'], kde=True)","898105f6":"sns.displot(df['st_depression'], kde=True)","83507d7b":"sns.countplot(x='num_major_vessels', data=df)","37cae4f8":"sns.boxplot(x='chest_pain_type', y='age', data=df)","0a0e3421":"sns.pairplot(df, hue='target')","e94fcdaf":"colormap = plt.cm.RdBu\nplt.figure(figsize=(12,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(df.corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)","d264c0c0":"onehot_df = pd.get_dummies(df)","5bf8c5e0":"onehot_df.head()","79f99a9f":"y = onehot_df.target.values\nx = onehot_df.drop('target', axis=1).values","7b20431c":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=5)","e6b8b87a":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import KFold, cross_val_score","1dcce2ba":"# Evaluate Models\n\nn_folds = 10\nmodels = []\n\n\n# Scaling features\nscaler = StandardScaler()\nscaler.fit(x_train)\n\nscaled_x_train = scaler.transform(x_train)\nscaled_x_test = scaler.transform(x_test)\n\n\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('Tree', DecisionTreeClassifier()))\nmodels.append(('Forest', RandomForestClassifier()))\nmodels.append(('XGB', XGBClassifier(use_label_encoder=False, eval_metric='logloss')))\nmodels.append(('NB', GaussianNB()))\n\nfor name, model in models:\n    kfold = KFold(n_splits=n_folds)\n    cv_results = cross_val_score(model, scaled_x_train, y_train, cv=kfold, scoring='accuracy')\n    print(\"%6s %.3f %.3f \" % (name, cv_results.mean(), cv_results.std()))","c86329c5":"rf = RandomForestClassifier(max_depth=5, n_estimators=100)\n\n# Train the model on training data\nrf.fit(x_train, y_train)","fa95ab66":"pred = rf.predict(x_test).round()\nprint('Random Forest')\nprint(\"Test Accuracy: %.2f\" % ((pred == y_test).mean()))","2edc5ed7":"cm = confusion_matrix(y_test, pred)\nsns.heatmap(cm, square=True, annot=True)\nplt.title('Confusion Matrix')\nplt.ylabel('True label')\nplt.xlabel('Predicted label')","4ccf54bc":"print(classification_report(y_test, pred))","6bf0ffa9":"feature_importance = rf.feature_importances_\nonehot_df_x = onehot_df.drop('target', axis=1)\nnames = [col for col in onehot_df_x.columns[feature_importance.argsort()[::-1]]]\n\nplt.figure(figsize=(10,10))\nsns.barplot(y=names, x=np.sort(feature_importance)[::-1], orient='h').set_title('Feature Importance')","671794fd":"from sklearn.decomposition import PCA\n\npca = PCA(n_components=0.9)\npc = pca.fit_transform(scaled_x_train)","1ecb1156":"plt.figure(figsize=(8,4))\nsns.barplot(x=np.array(range(pca.n_components_)), y=pca.explained_variance_ratio_)\nplt.xlabel(\"Components\")\nplt.ylabel(\"Variance\")","c4700564":"plt.scatter(pc[:, 0], pc[:, 1], c=y_train, label=y_train)\nplt.title(\"PCA\")\nplt.xlabel(\"1st Component\")\nplt.ylabel(\"2nd Component\")\nplt.show()","053b89cc":"from mpl_toolkits.mplot3d import Axes3D\n\nfig = plt.figure(figsize=(8,8))\nax = Axes3D(fig)\nax.scatter(pc[:, 0], pc[:, 1], pc[:, 2], c=y_train)\nax.set_xlabel('1st Component')\nax.set_ylabel('2nd Component')\nax.set_zlabel('3rd Component')\nax.set_title('PCA')","277954f7":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import mean_squared_error\n# K-Nearest-Neighbors\n\nprint('  k     Accuracy      MSE_In        MSE_Out')\nprint('--------------------------------------------')\nfor k in range(1, 30, 2):\n    knn = KNeighborsClassifier(n_neighbors=k, weights='uniform')\n    knn = knn.fit(scaled_x_train, y_train)\n\n    y_train_predict = knn.predict(scaled_x_train)\n    y_test_predict  = knn.predict(scaled_x_test)\n\n    acc = (y_test_predict == y_test).mean()\n    mse_in  = mean_squared_error(y_train, y_train_predict)\n    mse_out = mean_squared_error(y_test, y_test_predict)\n    \n    \n    print(\"%3d %10.2f %13.4f  %12.4f\" % (k , acc, mse_in , mse_out))","51315984":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import mean_squared_error\n# K-Nearest-Neighbors\n\nprint('  k     Accuracy      MSE_In        MSE_Out')\nprint('--------------------------------------------')\nfor k in range(1, 30, 2):\n    knn = KNeighborsClassifier(n_neighbors=k, weights='uniform')\n    knn = knn.fit(pc, y_train)\n\n    y_train_predict = knn.predict(pc)\n    y_test_predict  = knn.predict(pca.transform(scaled_x_test))\n\n    acc = (y_test_predict == y_test).mean()\n    mse_in  = mean_squared_error(y_train, y_train_predict)\n    mse_out = mean_squared_error(y_test, y_test_predict)\n    \n    \n    print(\"%3d %10.2f %13.4f  %12.4f\" % (k , acc, mse_in , mse_out))","944f0d8d":"from sklearn.cluster import KMeans\n\nkm = KMeans(n_clusters=2)\nkm.fit(pc)\n\nscaled_x_test = scaler.transform(x_test)\ntest_pcs = pca.transform(scaled_x_test)\n\npredicts = km.predict(test_pcs)\n\nacc1 = (predicts == y_test).mean()\nacc2 = (predicts == np.logical_not(y_test)).mean()\n\nprint('K-Means')\nprint('Test Accuracy: %.2f' % max(acc1, acc2))","af9b9d3d":"# K-Nearest Neighbours\n\nNow we're going to test the performance of the KNN algorithm using our PCA decomposition, since we could see clusters and some clear distinguish between our target label.","9050a0e6":"For comparison, let's train our KNN with the original dataset, and then use the PCA decompositions to see if we can get any better.","faa41d66":"Renaming DataFrame columns to a more comprehensible feature description","f713b4e0":"# Testing Classifiers\n\n10 Fold Cross Validation to evaluate the performance of some algorithms","0f3ed585":"# Abstract\n\nKaggle Dasatet Link: https:\/\/www.kaggle.com\/ronitf\/heart-disease-uci\n\n* In this notebook I've been through some classification algorithms to predict the presence of heart disease in a patient using previous patient's data.\n\n* Even though we have a labeled dataset, I've tried to use K-Means Clustering (Unsupervised), since I didn't use it before, to predict using Principal Component Analysis decomposition and achieved a similar result.\n\n* Target variable represented by the column 'target' maps: {0: 'Healthy', 1: 'Abnormality'}","256e52ba":"# Conclusion\n\nAll models we've tested presented good results, and we could get a nice view of our data with the PCA decomposition.","5be9c802":"And now with PCA","fd016d52":"# Dimensionality Reduction (PCA)\n\nLet's try to find some clusters in our data so we can try others approaches. We will decompose our data in components so we retain 90% of variance.","f0da98f5":"# Imports","55544a93":"**Note:** There is no register of the 0 value for 'thal' in https:\/\/archive.ics.uci.edu\/ml\/datasets\/Heart+Disease. I've tried to remove the only 2 entries for some simplicity, but I've got much worse results. So I'm leaving as it is.","6d7b939f":"# K-Means Clustering\n\nNow, let's see the performance of a basic KMeans with our PCA components.","193ec090":"With only 2 components we have some noise in the center but it's already looking pretty distinguishable! Let's see with 3 components...","7ec11f35":"An increase of 2% in Test Accuracy when using the PCA components!","aa7baad6":"Testing Random Forest. We could do a randomized search with [sklearn's randomized search](http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.RandomizedSearchCV.html) and try to find the optimal hyperparameters for our case, but I won't cover this in this notebook.","6acacdaa":"One Hot Enconding our dataset","66759dd2":"Outlier!","61b2cadc":"# Data Visualization"}}