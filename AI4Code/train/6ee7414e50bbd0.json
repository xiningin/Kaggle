{"cell_type":{"097817c3":"code","0d2b2f2e":"code","1b574281":"code","7074edc8":"code","fe9d2c11":"code","3203bc00":"code","beb58873":"code","c3d6b2ba":"code","39133381":"code","4b2cd5ba":"code","872c7625":"code","60367b3d":"code","64b0eac6":"code","b9ad113b":"code","5f4ef6ee":"code","963b2846":"code","3d28c2a9":"code","575012be":"code","f86b6b99":"code","3d2c3a52":"markdown","d39ca2ca":"markdown","bcc41494":"markdown","897eb0c8":"markdown"},"source":{"097817c3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0d2b2f2e":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\n\n","1b574281":"data = pd.read_csv('..\/input\/mall-customer-market-segmentation\/Mall_Customers.csv')\n","7074edc8":"data","fe9d2c11":"data.drop('CustomerID', axis=1, inplace=True)","3203bc00":"encoder = LabelEncoder()\ndata['Gender'] = encoder.fit_transform(data['Gender'])\n\ngender_mappings = {index: label for index, label in enumerate(encoder.classes_)}\ngender_mappings","beb58873":"scaler = StandardScaler()\nscaled_data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n","c3d6b2ba":"max_clusters=50","39133381":"kmeans_tests = [KMeans(n_clusters=i, n_init=10) for i in range(1, max_clusters)]\ninertias = [kmeans_tests[i].fit(scaled_data).inertia_ for i in range(len(kmeans_tests))]","4b2cd5ba":"plt.figure(figsize=(7, 5))\nplt.plot(range(1, max_clusters), inertias)\nplt.xlabel(\"Number of Clusters\")\nplt.ylabel(\"Inertia\")\nplt.title(\"Choosing the Number of Clusters\")\nplt.show()","872c7625":"kmeans = KMeans(n_clusters=10, n_init=10)\nkmeans.fit(scaled_data)","60367b3d":"clusters = kmeans.predict(scaled_data)\nclusters","64b0eac6":"pca = PCA(n_components=2)\n\nreduced_data = pd.DataFrame(pca.fit_transform(scaled_data), columns=['PC1', 'PC2'])","b9ad113b":"reduced_data","5f4ef6ee":"kmeans.cluster_centers_","963b2846":"reduced_centers = pca.transform(kmeans.cluster_centers_)\nreduced_centers","3d28c2a9":"reduced_data['cluster'] = clusters","575012be":"reduced_data","f86b6b99":"plt.figure(figsize=(14, 10))\n\nplt.scatter(reduced_data[reduced_data['cluster'] == 0].loc[:, 'PC1'], reduced_data[reduced_data['cluster'] == 0].loc[:, 'PC2'], color='red')\nplt.scatter(reduced_data[reduced_data['cluster'] == 1].loc[:, 'PC1'], reduced_data[reduced_data['cluster'] == 1].loc[:, 'PC2'], color='blue')\nplt.scatter(reduced_data[reduced_data['cluster'] == 2].loc[:, 'PC1'], reduced_data[reduced_data['cluster'] == 2].loc[:, 'PC2'], color='yellow')\nplt.scatter(reduced_data[reduced_data['cluster'] == 3].loc[:, 'PC1'], reduced_data[reduced_data['cluster'] == 3].loc[:, 'PC2'], color='orange')\nplt.scatter(reduced_data[reduced_data['cluster'] == 4].loc[:, 'PC1'], reduced_data[reduced_data['cluster'] == 4].loc[:, 'PC2'], color='cyan')\nplt.scatter(reduced_data[reduced_data['cluster'] == 5].loc[:, 'PC1'], reduced_data[reduced_data['cluster'] == 5].loc[:, 'PC2'], color='magenta')\nplt.scatter(reduced_data[reduced_data['cluster'] == 6].loc[:, 'PC1'], reduced_data[reduced_data['cluster'] == 6].loc[:, 'PC2'], color='brown')\nplt.scatter(reduced_data[reduced_data['cluster'] == 7].loc[:, 'PC1'], reduced_data[reduced_data['cluster'] == 7].loc[:, 'PC2'], color='pink')\nplt.scatter(reduced_data[reduced_data['cluster'] == 8].loc[:, 'PC1'], reduced_data[reduced_data['cluster'] == 8].loc[:, 'PC2'], color='green')\nplt.scatter(reduced_data[reduced_data['cluster'] == 9].loc[:, 'PC1'], reduced_data[reduced_data['cluster'] == 9].loc[:, 'PC2'], color='purple')\n\nplt.scatter(reduced_centers[:, 0], reduced_centers[:, 1], color='black', marker='x', s=300)\n\nplt.xlabel(\"PC1\")\nplt.ylabel(\"PC2\")\n\nplt.show()","3d2c3a52":"# Preprocessing","d39ca2ca":"import pandas as np\nimport numpy as np\nimport matplotlip.pyplot as plt\nfrom sklearn.preprocessing import LableEncoder\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\n\n","bcc41494":"# Getting Started","897eb0c8":"scaled_data\n"}}