{"cell_type":{"ca358969":"code","7e5a6418":"code","4ede8ff9":"code","c745dd5f":"code","a198a59f":"code","ec134a64":"code","313d5445":"code","f1d54812":"code","45392c09":"code","6458d556":"code","5dcd276c":"code","6bac2fc5":"code","d72499df":"code","7eeed673":"code","95d65b8a":"code","041fbbf8":"code","a1faeeb8":"markdown"},"source":{"ca358969":"!pip uninstall kaggle\n!pip install --upgrade pip\n!pip install kaggle==1.5.6\n\n!mkdir -p ~\/.kaggle\n!cp kaggle.json ~\/.kaggle\n!ls -lha kaggle.json\n!chmod 600 ~\/.kaggle\/kaggle.json","7e5a6418":"!unzip 18011854kbopredicton.zip","4ede8ff9":"import pandas as pd\nimport numpy as np\nimport torch\nimport torchvision.datasets as data\nimport torchvision.transforms as transforms\nimport random\nfrom sklearn import preprocessing","c745dd5f":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nrandom.seed(777)\ntorch.manual_seed(777)\nif device=='cuda':\n  torch.cuda.manual_seed_all(777)","a198a59f":"learning_rate=0.0001\ntraining_epochs=2000\nbatch_size=100\nScaler = preprocessing.StandardScaler()","ec134a64":"train_data=pd.read_csv('kbo_train.csv',header=None,skiprows=1,usecols=range(0,9))\ntest_data=pd.read_csv('kbo_test.csv',header=None,skiprows=1,usecols=range(0,8))","313d5445":"x_train_data=train_data.loc[:,0:7]\ny_train_data=train_data.loc[:,[8]]\n\nx_train_data=np.array(x_train_data)\ny_train_data=np.array(y_train_data)\nx_train_data=Scaler.fit_transform(x_train_data)\n\nx_train_data=torch.FloatTensor(x_train_data)\ny_train_data=torch.FloatTensor(y_train_data)","f1d54812":"train_dataset=torch.utils.data.TensorDataset(x_train_data,y_train_data)\ndata_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True,drop_last=True)","45392c09":"linear1 = torch.nn.Linear(8, 8,bias=True)\nlinear2 = torch.nn.Linear(8, 16,bias=True)\nlinear3 = torch.nn.Linear(16, 32,bias=True)\nlinear4 = torch.nn.Linear(32, 32,bias=True)\nlinear5 = torch.nn.Linear(32, 16,bias=True)\nlinear6 = torch.nn.Linear(16, 8,bias=True)\nlinear7 = torch.nn.Linear(8, 1,bias=True)\nrelu = torch.nn.ReLU()\n\ntorch.nn.init.xavier_uniform_(linear1.weight)\ntorch.nn.init.xavier_uniform_(linear2.weight)\ntorch.nn.init.xavier_uniform_(linear3.weight)\ntorch.nn.init.xavier_uniform_(linear4.weight)\ntorch.nn.init.xavier_uniform_(linear5.weight)\ntorch.nn.init.xavier_uniform_(linear6.weight)\ntorch.nn.init.xavier_uniform_(linear7.weight)\n\nmodel = torch.nn.Sequential(linear1,relu,\n                            linear2,relu,\n                            linear3,relu,\n                            linear4,relu,\n                            linear5,relu,\n                            linear6,relu,\n                            linear7).to(device)","6458d556":"loss=torch.nn.MSELoss().to(device)\noptimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)\n","5dcd276c":"total_batch=len(data_loader)\nfor epoch in range(training_epochs):\n  avg_cost=0\n\n  for x, y in data_loader:\n    x=x.to(device)\n    y=y.to(device)\n\n    optimizer.zero_grad()\n    hypo=model(x)\n    cost=loss(hypo,y)\n    cost.backward()\n    optimizer.step()\n    avg_cost+=cost\/total_batch\n  if(epoch%50==0):\n    print('epoch:','%04d'%(epoch),'cost=','{:.9f}'.format(avg_cost))\nprint('Learning finished')","6bac2fc5":"with torch.no_grad():\n  x_test_data=test_data.loc[:,:]\n  x_test_data=np.array(x_test_data)\n  x_test_data=Scaler.transform(x_test_data)\n  x_test_data=torch.from_numpy(x_test_data).float().to(device)\n\n  prediction=model(x_test_data)","d72499df":"correct=prediction.cpu().numpy().reshape(-1,1)","7eeed673":"submit=pd.read_csv('submit_sample.csv')","95d65b8a":"for i in range(len(correct)):\n  submit['Expected'][i]=correct[i].item()\nsubmit","041fbbf8":"submit.to_csv('defense_baseline.csv',index=False,header=True)\nfrom google.colab import files\n\nfiles.download('defense_baseline.csv') ","a1faeeb8":"# \uacf5\uaca9\ucf54\ub4dc\uc640\uc758 \ucc28\uc774\uc810\n\n1. \ub808\uc774\uc5b4\uc218 5\uac1c\uc5d0\uc11c 7\uac1c\ub85c \uc99d\uac00\n2. xavier normal \uc5d0\uc11c  xavier uniform\uc73c\ub85c \ubcc0\uacbd\n3. input, output \uc744 8->16->32->16->8->1 \ub85c \uc124\uc815"}}