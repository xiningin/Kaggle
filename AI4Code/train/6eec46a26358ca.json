{"cell_type":{"707a40e2":"code","219f7648":"code","5f1b7589":"code","cc0e6131":"code","c17a99dc":"code","d0e191b3":"code","37dd1f04":"code","18be6373":"code","c9fab1d8":"code","cc5d25c2":"code","c70f0b12":"code","18fe334f":"code","1f379599":"code","a4ee1ea5":"code","21359d41":"code","5b0efcae":"code","63a8e1b6":"code","b98eafd9":"code","afa4fe8f":"code","b17f4756":"code","fd377ded":"code","79acb13f":"code","96a7fbde":"code","008503b9":"code","8c9740ad":"code","9d948f54":"code","7f431d9d":"code","7b2d0df9":"code","23b7f5dd":"code","381ebe05":"code","9eb2df29":"code","af352f00":"code","c7b05f37":"code","176895d7":"code","60915ada":"code","21d9c77f":"code","3ffb0035":"code","b0cf3b94":"code","dcebc9ac":"code","a41ab790":"code","1b4058b5":"code","8b284254":"code","499813aa":"code","4db28eba":"code","2f70c708":"code","8f41443d":"code","8da193e3":"code","c9ee3bb2":"markdown","5181c0c9":"markdown","bae707b0":"markdown","cdaf6690":"markdown","c4ec1c1b":"markdown","a3b17955":"markdown","b8c07f48":"markdown","4e54ce45":"markdown"},"source":{"707a40e2":"import matplotlib.pyplot as plt # plotting\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom glob import glob\nfrom PIL import Image\n\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPool2D , Flatten\nfrom tensorflow.keras.optimizers import Adam\n\n\nfrom keras.utils import to_categorical\n\nimport tensorflow.keras.backend as K","219f7648":"class_names = glob('..\/input\/*\/train\/*')\nfor i in range (len(class_names)):\n    class_names[i] = class_names[i][len('..\/input\/logos3\/train\/'):]\nclass_names\n\nclass_ind = {class_names[i]:i for i in range(6)}\nprint(class_names)\nprint(class_ind)","5f1b7589":"image_names = {}\ncount_list = {}\nfor class_name in class_names:\n    image_names[class_name] = glob('..\/input\/*\/*\/' + class_name +  '\/*' )\n    count_list[class_name] = len(glob('..\/input\/*\/*\/' + class_name +  '\/*' ))\n#     print(class_name,'-' , len(image_names[class_name]),'images')\ncount_list","cc0e6131":"dataset = pd.DataFrame(list(count_list.items()),columns=['name','number'])\ndataset","c17a99dc":"import random\nr = lambda: random.randint(0,255)\ncol = lambda : ('#%02X%02X%02X' % (r(),r(),r()))","d0e191b3":"import seaborn as sns\nsns.set(style=\"darkgrid\")\nax = plt.bar(dataset['name'],dataset['number'] , color = [col() for i in range(6)])\nplt.show()","37dd1f04":"sns.set_style(\"whitegrid\", {'axes.grid' : False})","18be6373":"j = 0\nfig, axs = plt.subplots(6, 5, figsize=(20, 30))\nfor class_name in class_names:\n    class_wise_names = image_names[class_name]\n    i = 0\n    for img_name in class_wise_names[:5]:\n        img = Image.open(img_name)\n        img = np.array(img)\n        axs[j][i].imshow(img)\n        axs[j][i].set_title(class_name)\n        i+=1\n    j+=1","c9fab1d8":"# def generate_image_arr(cur_dir,image_size = (224,224)):\n#     image_names = {}\n#     count_list = {}\n#     m = 0\n#     for class_name in class_names:\n#         image_names[class_name] = glob(cur_dir + class_name +  '\/*' )\n#         count_list[class_name] = len(image_names[class_name])\n#         m += len(image_names[class_name])\n#     print(count_list)\n#     print('Total image count =', m)\n    \n#     X, Y = np.zeros((m,*image_size,3),dtype=np.uint8),np.zeros((m,1),dtype=np.uint8)\n    \n#     ind = 0 \n#     for class_name in class_names:\n#         class_wise_names = image_names[class_name]\n#         for i in range(len(class_wise_names)):\n#             img = Image.open(class_wise_names[i])\n#             img = img.resize(image_size)\n#             img = np.array(img)\n#             X[ind]= img\n#             Y[ind] = class_ind[class_name]\n#             assert(class_name == class_names[class_ind[class_name]])\n#             ind+=1\n#     Y_ = to_categorical(Y)\n# #     print(Y_.shape)\n# #     print(Y.shape)\n# #     print(.shape)\n# #     assert(np.argmax(Y_,axis=1).reshape(-1,1) == Y)\n# #     assert(np.argmax(Y_,axis=1) == Y.flatten())\n#     assert(np.argmax(Y_,axis = 1).reshape(-1,1).shape == Y.shape)\n    \n    \n#     return X,Y_,m","cc5d25c2":"# cur_dir = '..\/input\/*\/train\/'\n# X_, Y_, m_tr = generate_image_arr(cur_dir)\n# Xtr, Xval, Ytr, Yval = train_test_split(X_,Y_,test_size=0.25)\n# print(Xtr.shape)\n# print(Xval.shape)\n# print(Ytr.shape)\n# print(Yval.shape)","c70f0b12":"# fig, axs = plt.subplots(5, 5, figsize=(20, 30))\n# for i in range(25):\n#     ax = axs[i\/\/5][i % 5]\n#     ax.imshow(Xtr[i])\n#     ax.set_title(class_names[np.argmax(Ytr[i])] +\" \" +str(Ytr[i]))","18fe334f":"# cur_dir = '..\/input\/*\/test\/'\n# Xts, Yts, m_ts  = generate_image_arr(cur_dir)","1f379599":"# fig, axs = plt.subplots(5, 5, figsize=(20, 30))\n# for i in range(25):\n#     ax = axs[i\/\/5][i % 5]\n#     i = random.randint(0,560)\n#     ax.imshow(Xts[i])\n#     ax.set_title(class_names[np.argmax(Yts[i])] +\" \" +str(Yts[i]))","a4ee1ea5":"# def get_images_of_class(class_name):\n# #     print(Xts[(np.argmax(Yts,axis=-1).reshape(-1,1) == [class_ind[class_name]]).flatten()].shape)\n#     return Xts[(np.argmax(Yts,axis=-1).reshape(-1,1) == [class_ind[class_name]]).flatten()]\n    \n# fig, axs = plt.subplots(2, 3, figsize=(20, 15))\n# axs = axs.flatten()\n# for i in range(len(class_names)):\n#     mean_img = np.array(get_images_of_class(class_names[i])[0:5].mean(axis=0),dtype=np.uint8)\n#     ax = axs[i]\n#     ax.imshow(mean_img)\n#     ax.set_title(class_names[i])\n# #     print(mean_img.shape)\n# #     plt.imshow(mean_img)\n# #     print(ax)\n# # plt.imshow(mean_img)","21359d41":"# model = Sequential()\n# model.add(Conv2D(input_shape=(224,224,3),filters=32,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n# model.add(Conv2D(filters=32,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n\n# model.add(Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n# model.add(Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n\n# model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n# model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n# model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n\n# model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n# model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n# model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n\n\n# model.add(Flatten())\n# model.add(Dense(units=1024,activation=\"relu\"))\n# model.add(Dense(units=1024,activation=\"relu\"))\n# model.add(Dense(units=6, activation=\"softmax\"))","5b0efcae":"# model.summary()","63a8e1b6":"\n# opt = Adam(lr=0.001)\n# model.compile(optimizer=opt, loss=tf.keras.losses.categorical_crossentropy, metrics=['accuracy', 'acc'])","b98eafd9":"# # del X_,Y_\n# import gc\n# gc.collect()","afa4fe8f":"# datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n#     featurewise_center=True,\n#     featurewise_std_normalization=True,\n#     rotation_range=20,\n#     width_shift_range=0.2,\n#     height_shift_range=0.2,\n#     horizontal_flip=True\n# )\n\n\n# # train_generator = datagen.flow_from_directory(\n# #     directory=r\"..\/input\/logos3\/train\/\",\n# #     target_size=(224, 224),\n# #     color_mode=\"rgb\",\n# #     batch_size=32,\n# #     class_mode=\"categorical\",\n# #     shuffle=True,\n# #     seed=42\n# # )","b17f4756":"# datagen.fit(Xtr[:1],seed=7)","fd377ded":"# hist = model.fit(datagen.flow(Xtr, Ytr, batch_size=32),\n#           steps_per_epoch=len(Xtr) \/ 32,validation_data = datagen.flow(Xval,Yval), validation_steps=10, epochs=40,seed=7)","79acb13f":"# ","96a7fbde":"# import ctypes\n# # a = \"hello world\"\n# myid = int('0x7efe6ba1ff60',16)\n# print(ctypes.cast(myid, ctypes.py_object).value)\n","008503b9":"# import matplotlib.pyplot as plt\n\n# plt.plot(hist.history[\"acc\"])\n# plt.plot(hist.history['val_acc'])\n# plt.title(\"model accuracy\")\n# plt.ylabel(\"Accuracy\")\n# plt.xlabel(\"Epoch\")\n# plt.legend([\"Accuracy\",\"Validation Accuracy\"])\n# plt.show()","8c9740ad":"# # pred = np.argmax(model.predict(Xtr),axis=1)\n\n# test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n# test_datagen.fit(Xts[:1])\n\n# pred = model.predict(test_datagen.flow(Xts,shuffle=0,batch_size=1),steps = Xts.shape[0])\n# ypr = np.argmax(pred,axis=1)\n# y = np.argmax(Yts,axis=1)\n# acc = sum(ypr == y)\/Xts.shape[0]\n# acc\n\n\n# predictions = model.predict(x=testX.astype(\"float32\"), batch_size=BS)\n# print(classification_report(testY.argmax(axis=1),\n# \tpredictions.argmax(axis=1), target_names=le.classes_))","9d948f54":"# model.save('my_model.h5')","7f431d9d":"train_dir = glob('..\/input\/*\/train')[0]\ntest_dir = glob('..\/input\/*\/test')[0]","7b2d0df9":"datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.2\n)\n\ndatagen.fit(img.reshape(1,300,300,3)[:,0:224,0:224,:])\n\n# train_flowed = train_gen.flow_from_directory(\n#     train_dir, target_size=(224, 224), color_mode='rgb', classes=None,\n#     class_mode='categorical', batch_size=32, shuffle=True, seed=724\n# )\n\ntrain_gen = datagen.flow_from_directory(\n    train_dir,\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical',\n    subset='training') # set as training data\n\nval_gen = datagen.flow_from_directory(\n    train_dir,\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical',\n    subset='validation') # set as validation data\n\ntest_gen = datagen.flow_from_directory(\n    test_dir,\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical')","23b7f5dd":"def f1_score(y_true, y_pred): #taken from old keras source code\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives \/ (predicted_positives + K.epsilon())\n    recall = true_positives \/ (possible_positives + K.epsilon())\n    f1_val = 2*(precision*recall)\/(precision+recall+K.epsilon())\n    return f1_val","381ebe05":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import BatchNormalization\nimport numpy as np\nnp.random.seed(1000)\n#Instantiate an empty model\nmodel = Sequential()\n\n# 1st Convolutional Layer\nmodel.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='valid',activation=\"relu\"))\nmodel.add(Activation('relu'))\n# Max Pooling\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n\n# 2nd Convolutional Layer\nmodel.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\nmodel.add(Activation('relu'))\n# Max Pooling\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n\n# 3rd Convolutional Layer\nmodel.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\nmodel.add(Activation('relu'))\n\n# 4th Convolutional Layer\nmodel.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\nmodel.add(Activation('relu'))\n\n# 5th Convolutional Layer\nmodel.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\nmodel.add(Activation('relu'))\n# Max Pooling\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n\n# Passing it to a Fully Connected layer\nmodel.add(Flatten())\n# 1st Fully Connected Layer\nmodel.add(Dense(4096, input_shape=(224*224*3,)))\nmodel.add(Activation('relu'))\n# Add Dropout to prevent overfitting\nmodel.add(Dropout(0.4))\n\n# 2nd Fully Connected Layer\nmodel.add(Dense(4096))\nmodel.add(Activation('relu'))\n# Add Dropout\nmodel.add(Dropout(0.4))\n\n# 3rd Fully Connected Layer\nmodel.add(Dense(1000))\nmodel.add(Activation('relu'))\n# Add Dropout\nmodel.add(Dropout(0.4))\n\n# Output Layer\nmodel.add(Dense(6))\nmodel.add(Activation('softmax'))\n\nmodel.summary()\n\n# Compile the model\n\n","9eb2df29":"opt = Adam(lr=0.001)\nmodel.compile(optimizer=opt, loss=tf.keras.losses.categorical_crossentropy, metrics=['accuracy', 'acc', f1_score])","af352f00":"hist = model.fit_generator(train_gen,\n          steps_per_epoch= train_gen.samples \/\/ 32, validation_data = val_gen, validation_steps=val_gen.samples \/\/ 32, epochs= 40 )","c7b05f37":"import matplotlib.pyplot as plt\n\nplt.plot(hist.history[\"acc\"])\nplt.plot(hist.history['val_acc'])\nplt.title(\"model accuracy\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"Accuracy\",\"Validation Accuracy\"])\nplt.show()","176895d7":"\n# filenames = test_gen.filenames\n# nb_samples = len(filenames)","60915ada":"_, acc, f1_score_val = model.evaluate(test_gen)","21d9c77f":"acc, f1_score_val","3ffb0035":"model1 = Sequential()\nmodel1.add(Conv2D(input_shape=(224,224,3),filters=32,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\nmodel1.add(Conv2D(filters=32,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\nmodel1.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel1.add(Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel1.add(Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel1.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel1.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel1.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel1.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel1.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel1.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel1.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel1.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel1.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel1.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel1.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel1.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel1.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel1.add(Flatten())\n\nmodel1.add(Dense(units=1024,activation=\"relu\"))\nmodel1.add(Dense(units=1024,activation=\"relu\"))\nmodel1.add(Dense(units=6, activation=\"softmax\"))","b0cf3b94":"model1.summary()","dcebc9ac":"opt = Adam()\nmodel1.compile(loss = tf.keras.losses.categorical_crossentropy, optimizer='adam', metrics=[\"accuracy\", f1_score])","a41ab790":"hist = model1.fit_generator(train_gen,\n          steps_per_epoch= train_gen.samples \/\/ 32, validation_data = val_gen, validation_steps=val_gen.samples \/\/ 32, epochs=40 )","1b4058b5":"import matplotlib.pyplot as plt\n\nplt.plot(hist.history[\"acc\"])\nplt.plot(hist.history['val_acc'])\nplt.title(\"model accuracy\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"Accuracy\",\"Validation Accuracy\"])\nplt.show()","8b284254":"_, acc, f1_score_val = model1.evaluate(test_gen)","499813aa":"acc, f1_score_val","4db28eba":"from sklearn.metrics import accuracy_score, classification_report, f1_score, confusion_matrix\n\ndef evaluate_from_gen(test_data_gen, model1, model2 , n = 560, batch_size = 32 ):\n    acc = []\n    n_batches = (n  \/\/ batch_size) + 1\n    X = np.zeros((n , 224, 224, 3))\n    Y = np.zeros((n , 6))\n    \n    index = 0\n    for i in range(n_batches):\n        x,y = next(test_data_gen)\n        X[index:index + x.shape[0]] = x\n        Y[index:index + x.shape[0]] = y\n        index += x.shape[0]\n    \n    y_true = np.argmax(Y,axis=-1)\n    \n    Y_pred1 = model1.predict(X)\n    Y_pred2 = model2.predict(X)\n    \n    pred = Y_pred1 + Y_pred2\n    \n    \n    y_pred = np.argmax(pred,axis=-1)\n    \n    print(classification_report(y_true, y_pred))\n    print(confusion_matrix(y_true, y_pred))\n#     print(f1_score(y_true, y_pred))\n    print(\"Accuracy = \",accuracy_score(y_true, y_pred))","2f70c708":"evaluate_from_gen(train_gen, model,model1 ,  1393)","8f41443d":"evaluate_from_gen(val_gen, model,model1 ,  345)","8da193e3":"evaluate_from_gen(test_gen, model,model1 ,  560)","c9ee3bb2":"# Alexnet","5181c0c9":"# Importing Data and Libraries","bae707b0":"# VGG16 ","cdaf6690":"# Sample Class-wise Plot","c4ec1c1b":"# From Numpy Arrays","a3b17955":"# Training set Validation Plot ","b8c07f48":"## Introduction\nGreetings from the Kaggle bot! This is an automatically-generated kernel with starter code demonstrating how to read in the data and begin exploring. If you're inspired to dig deeper, click the blue \"Fork Notebook\" button at the top of this kernel to begin editing.","4e54ce45":"# Using Flow from Dir"}}