{"cell_type":{"2917c011":"code","8568d6b7":"code","f46654f3":"code","1280290c":"code","b1d56b97":"code","e3d5554e":"code","b19ebfc8":"code","c90d8fac":"code","3196fa51":"code","15f1923d":"code","bd7479f6":"code","b1bee498":"code","3c44ee27":"code","058d1cbe":"code","b8686a4e":"code","cbee4854":"code","88d7bcde":"code","f107ef10":"code","0c524c48":"code","f92ef781":"code","16eafd2b":"markdown","0149b0d8":"markdown","fb0fc7b4":"markdown","9f8d49b9":"markdown","0c2544ca":"markdown","119a3d77":"markdown","b857bb75":"markdown","48ac186d":"markdown","6d413144":"markdown","833dec89":"markdown","5436b6ab":"markdown","74cd666a":"markdown","dc0ed623":"markdown","e8349bee":"markdown"},"source":{"2917c011":"# Essentials\nimport pandas as pd  \nimport numpy as np\nimport math\n\n\n# Visuals\nimport seaborn as sns\n\n# Data Preprocessing\nfrom sklearn.preprocessing import KBinsDiscretizer, OneHotEncoder, MinMaxScaler\n\n# Model Selection Tools\nfrom sklearn.model_selection import KFold, train_test_split, GridSearchCV\n\n# Models\nfrom sklearn.svm import SVR, SVC\nfrom sklearn.dummy import DummyClassifier\n\n","8568d6b7":"df = pd.read_csv('..\/input\/train.csv')\nRawX = df.iloc[:, 2:].values  # for train, use 2: \/\/  for test, use 1:\ny = df.iloc[:, 1].values","f46654f3":"sns.countplot(x = df.SibSp, hue = df.Survived)","1280290c":"sns.countplot(x = df.Pclass, hue = df.Survived)","b1d56b97":"df = df.drop(['Ticket'], axis = 1)","e3d5554e":"df['NameLen'] = df.Name.apply(lambda x : len(x)) \n","b19ebfc8":"for i in range(np.shape(RawX)[0]): RawX[i,1] = RawX[i,1][RawX[i,1].find(', ')+2:RawX[i,1].find('. ')]\nnp.unique(RawX[:,1])  # How many unique values? Let's plot these to see how many of each title\n\n# Clean it up a bit. No need for all these fancy titles, let's break it down\ndef replace_titles(x):\n        title=RawX[x,1]\n        if title in ['Don', 'Major', 'Capt', 'Jonkheer', 'Rev', 'Col', 'Sir', 'Master',]:\n            return 'Mr'\n        elif title in ['Countess', 'Mme','Dona']:\n            return 'Mrs'\n        elif title in ['Mlle', 'Ms', 'Lady']:\n            return 'Miss'\n        elif title in ['Dr','Master','Col','Rev','Capt','the Countess']:\n            return 'Special'\n        else:\n            return title\n\nfor i in range(np.shape(RawX)[0]):\n    RawX[i,1] = replace_titles(i)\n\n# Let's look at the data.\nplot = sns.countplot(RawX[:,1])\n\ndf['Name'] = RawX[:,1] # Insert back into our df","c90d8fac":"# Average age of Mr\nmravg = RawX[np.where(RawX[:,1] == 'Mr')][:,3]\nmravg = round(np.nanmean(mravg, dtype = np.dtype(np.float)))\n# Average age of Mrs\nmrsavg = RawX[np.where(RawX[:,1] == 'Mrs')][:,3]\nmrsavg = round(np.nanmean(mrsavg, dtype = np.dtype(np.float))) \n# Average age of Miss\nmsavg = RawX[np.where(RawX[:,1] == 'Miss')][:,3]\nmsavg = round(np.nanmean(msavg, dtype = np.dtype(np.float)))\n# Average of every person (for special category)\navg = RawX[np.where(RawX[:,1] == 'Special')][:,3]\navg = round(np.nanmean(avg, dtype = np.dtype(np.float)))\n\n# Below, we will define a function that iterates through the entire age set, looking for nan and replacing\ndef replace_age(x):\n    for i in range(np.shape(x)[0]):\n        if math.isnan(x[i,3]) == True:\n            if x[i,1] == 'Mr':\n                x[i,3] = mravg\n            if x[i,1] == 'Mrs':\n                x[i,3] = mrsavg\n            if x[i,1] == 'Miss':\n                x[i,3] = msavg\n            if x[i,1] == 'Special':\n                x[i,3] = avg\n                \n            \nreplace_age(RawX)\ndf['Age'] = RawX[:,3] # Insert back into our df\ndf['Age'] = df.Age.astype(int)","3196fa51":"# Now let's clean up NA's in Embarked\ndf['Embarked'] = df['Embarked'].fillna(list(df['Embarked'].value_counts().index)[0]) ","15f1923d":"df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n\ndf['Alone']=0\ndf.loc[(df.FamilySize==1),'Alone'] = 1","bd7479f6":"sns.countplot(df.Age, hue = df.Survived)","b1bee498":"est = KBinsDiscretizer(n_bins = 5, encode = 'ordinal', strategy = 'quantile')\nest.fit(df[['Age']])  # use me for train data\nnew = est.transform(df[['Age']]) # Use me for train data\ndf['AgeBin'] = new\n\nsns.countplot(df.AgeBin, hue = df.Survived)\n\ndf = df.drop('AgeBin', axis = 1)","3c44ee27":"ohe = OneHotEncoder()\n\n# For the Name\/Title column:\nX = ohe.fit_transform(df.Name.values.reshape(-1,1)).toarray()\ndfOneHot = pd.DataFrame(X, columns = [\"Title_\"+str(int(i)) for i in range(X.shape[1])])\ndf = pd.concat([df, dfOneHot], axis=1)\n\n# For embarked column\nX = ohe.fit_transform(df.Embarked.values.reshape(-1,1)).toarray()\ndfOneHot = pd.DataFrame(X, columns = [\"Embarked_\"+str(int(i)) for i in range(X.shape[1])])\ndf = pd.concat([df, dfOneHot], axis=1)","058d1cbe":"df = df.drop('Cabin', axis = 1)\ndf = df.drop('Embarked', axis = 1)\ndf = df.drop('Name', axis = 1)\ndf = df.drop('Sex', axis = 1)\ndf = df.drop('Age', axis = 1)\n\nRawX = df.iloc[:, 2:].values","b8686a4e":"scaler = MinMaxScaler()\nScaled_X = scaler.fit_transform(RawX)","cbee4854":"#%% Dummy with cross validation\nscores_dummy = []\nclf = DummyClassifier()\ncv = KFold(n_splits = 10, random_state = 42, shuffle = False)\n\nfor train_index, test_index in cv.split(Scaled_X):\n    X_train, X_test, y_train, y_test = Scaled_X[train_index], Scaled_X[test_index], y[train_index], y[test_index]\n    clf.fit(X_train, y_train)\n    scores_dummy.append(clf.score(X_test, y_test))\nprint(scores_dummy)","88d7bcde":"\"\"\"\n# Grid search to determine parameters\nX_train, X_test, y_train, y_test = train_test_split(Scaled_X, y, test_size = 0.2, random_state = 0)\n\ndef svc_param_selection(X, y, nfolds):\n    Cs = [0.001, 0.01, 0.1, 1, 10, 100]\n    gammas = [0.001, 0.01, 0.1, 1, 10]\n    degrees = list(range(1,9))\n    param_grid = { 'kernel' : ('linear', 'rbf'), \n                  'C': Cs, \n                  'gamma' : gammas, \n                  'degree' : degrees}\n    grid_search = GridSearchCV(SVC(), param_grid, cv=nfolds)\n    grid_search.fit(X, y)\n    grid_search.best_params_\n    return grid_search.best_params_\n\n# Find best parameters\nsvc_param_selection(X_train, y_train, 5)\n\"\"\"","f107ef10":"#%% SVC w\/ CV\nscores_SVC = []\ncv = KFold(n_splits = 10, random_state = 42, shuffle = False)\nclf = SVC(kernel = 'rbf', C = 0.1, degree = 1, gamma = 1)\n\nfor train_index, test_index in cv.split(Scaled_X):\n    X_train, X_test, y_train, y_test = Scaled_X[train_index], Scaled_X[test_index], y[train_index], y[test_index]\n    clf.fit(X_train, y_train)\n    scores_SVC.append(clf.score(X_test, y_test))\nprint(scores_SVC)","0c524c48":"df = pd.read_csv('..\/input\/test.csv')\nRawX = df.iloc[:, 1:].values\n\ndf = df.drop(['Ticket'], axis = 1)\n\n\ndf['NameLen'] = df.Name.apply(lambda x : len(x)) \n    \n    \nfor i in range(np.shape(RawX)[0]): RawX[i,1] = RawX[i,1][RawX[i,1].find(', ')+2:RawX[i,1].find('. ')]\nnp.unique(RawX[:,1])  # How many unique values? Let's plot these to see how many of each title\n\n# Clean it up a bit. No need for all these fancy titles, let's break it down\ndef replace_titles(x):\n        title=RawX[x,1]\n        if title in ['Don', 'Major', 'Capt', 'Jonkheer', 'Rev', 'Col', 'Sir', 'Master',]:\n            return 'Mr'\n        elif title in ['Countess', 'Mme','Dona']:\n            return 'Mrs'\n        elif title in ['Mlle', 'Ms', 'Lady']:\n            return 'Miss'\n        elif title in ['Dr','Master','Col','Rev','Capt','the Countess']:\n            return 'Special'\n        else:\n            return title\n\nfor i in range(np.shape(RawX)[0]):\n    RawX[i,1] = replace_titles(i)\n\n# Let's look at the data.\nplot = sns.countplot(RawX[:,1])\n\ndf['Name'] = RawX[:,1] # Insert back into our df\n\n\n# Average age of Mr\nmravg = RawX[np.where(RawX[:,1] == 'Mr')][:,3]\nmravg = round(np.nanmean(mravg, dtype = np.dtype(np.float)))\n# Average age of Mrs\nmrsavg = RawX[np.where(RawX[:,1] == 'Mrs')][:,3]\nmrsavg = round(np.nanmean(mrsavg, dtype = np.dtype(np.float))) \n# Average age of Miss\nmsavg = RawX[np.where(RawX[:,1] == 'Miss')][:,3]\nmsavg = round(np.nanmean(msavg, dtype = np.dtype(np.float)))\n# Average of every person (for special category)\navg = RawX[np.where(RawX[:,1] == 'Special')][:,3]\navg = round(np.nanmean(avg, dtype = np.dtype(np.float)))\n\n# Below, we will define a function that iterates through the entire age set, looking for nan and replacing\ndef replace_age(x):\n    for i in range(np.shape(x)[0]):\n        if math.isnan(x[i,3]) == True:\n            if x[i,1] == 'Mr':\n                x[i,3] = mravg\n            if x[i,1] == 'Mrs':\n                x[i,3] = mrsavg\n            if x[i,1] == 'Miss':\n                x[i,3] = msavg\n            if x[i,1] == 'Special':\n                x[i,3] = avg\n                \n            \nreplace_age(RawX)\ndf['Age'] = RawX[:,3] # Insert back into our df\ndf['Age'] = df.Age.astype(int)\n\n\n# Now let's clean up NA's in Embarked\ndf['Embarked'] = df['Embarked'].fillna(list(df['Embarked'].value_counts().index)[0])\n\n\ndf['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n\ndf['Alone']=0\ndf.loc[(df.FamilySize==1),'Alone'] = 1\n\n\nohe = OneHotEncoder()\n\n# For the Name\/Title column:\nX = ohe.fit_transform(df.Name.values.reshape(-1,1)).toarray()\ndfOneHot = pd.DataFrame(X, columns = [\"Title_\"+str(int(i)) for i in range(X.shape[1])])\ndf = pd.concat([df, dfOneHot], axis=1)\n\n# For embarked column\nX = ohe.fit_transform(df.Embarked.values.reshape(-1,1)).toarray()\ndfOneHot = pd.DataFrame(X, columns = [\"Embarked_\"+str(int(i)) for i in range(X.shape[1])])\ndf = pd.concat([df, dfOneHot], axis=1)\n\n\ndf = df.drop('Cabin', axis = 1)\ndf = df.drop('Embarked', axis = 1)\ndf = df.drop('Name', axis = 1)\ndf = df.drop('Sex', axis = 1)\ndf = df.drop('Age', axis = 1)\ndf = df.fillna(0)\nRawX = df.iloc[:, 1:].values\n\n# Scale based on train data\nScaled_X = scaler.transform(RawX)\n\n\n\ny_pred = clf.predict(Scaled_X)","f92ef781":"new = pd.DataFrame({'Survived':y_pred[:]})\noutput = pd.concat([df['PassengerId'],new], axis=1)\n\noutput.to_csv('SVC_Unbinned_HW.csv',index = False)","16eafd2b":"2] Let's try SVC with grid search AND cross validation now\n","0149b0d8":"And now the data!","fb0fc7b4":"One last thing.... scale everything!","9f8d49b9":"1] First classifier is a dummy to give us a baseline","0c2544ca":"Now, we want to distinguish between people travelling alone and with families.  ","119a3d77":"Let's take a peek at what is to come. Looks like we can see a couple of relationships between suvived and some of our features...","b857bb75":"Let's start by importing libraries! We need those before we can do anything.","48ac186d":"It may be useful to bin the age data, so let's go for it:\nNote: Quantile Binning\nAnother Note: Not useful https:\/\/medium.com\/@peterflom\/why-binning-continuous-data-is-almost-always-a-mistake-ad0b3a1d141f","6d413144":"Now we need to transform our SUBMISSION data based on what we just used:","833dec89":"Let's get rid of the most blaringly irrelevant column. As much as I would love to run some NLP on this, probably not worth the time...","5436b6ab":"Instead of filling in missing age values with NA, let's be smart and take the average of the title category to fill it in:","74cd666a":"Drop any remaining irrelevant columns and create our Raw attributes to feed to algorithims","dc0ed623":"Fellow Kagglers have made the observation that name length has quite an effect on survival. Coincidence? Correlation without casusation?","e8349bee":"Now we need to encode titles so our algorithims can do something with it"}}