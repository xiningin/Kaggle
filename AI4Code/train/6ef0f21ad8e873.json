{"cell_type":{"4ac29b2f":"code","0fa9bd87":"code","8e834b01":"code","67026ab4":"code","7ef92f7f":"code","65d13850":"code","423b140e":"code","9d207f2f":"code","0256344d":"code","ec390d25":"code","c0dba7c2":"code","88180419":"code","4979dbdf":"code","2083b79a":"code","624afacc":"code","99d928a4":"code","eecc516e":"code","53e1dfdc":"code","a8c8cf46":"code","e2cecc39":"markdown","11fb6f31":"markdown","ccb0e154":"markdown","21b6e1e8":"markdown","b4d5f5ae":"markdown","6a68e709":"markdown","691a27ec":"markdown","6f6309d6":"markdown","012d8c57":"markdown","1217308b":"markdown","c138d437":"markdown","acb14b7d":"markdown","704d51de":"markdown","f84e2dc3":"markdown","705826d2":"markdown","f6d39663":"markdown","c0222139":"markdown","24d9177d":"markdown","d0289fd4":"markdown","093c9d30":"markdown","2fdb48b9":"markdown","06e0fc4e":"markdown","c0213f15":"markdown","912bfe04":"markdown","5f1a1665":"markdown","29787d21":"markdown"},"source":{"4ac29b2f":"class KaggleMember(): #line1\n    #class member\n    kaggle_member_count=0  #line2\n        \n    def __init__(self, name, surname, level=None): #line3\n        \n        #object members\n        self.name=name.capitalize() #line4\n        self.surname=surname.upper() #line5\n        self._set_level(level) #6\n        \n        KaggleMember.kaggle_member_count+=1 #line7\n        self.kaggle_id=KaggleMember.kaggle_member_count #line8\n        \n        \n    \n    def display_number_of_member(self): #line11\n        print(\"There are {} members in Kaggle community\".format(KaggleMember.kaggle_member_count)) #line12\n    \n    def display_member_info(self): #line13\n        print(\"Kaggle Member Full Name:{} {}\".format(self.name, self.surname)) #line14\n        print(\"Level:{:15}\".format(self.level)) #line15\n        print(\"Kaggle ID:\",self.kaggle_id)\n    \n    def _set_level(self, level):\n        if level is None: #line6\n            self.level='Novice' #line7\n        else: #line8\n            self.level=level.title() #line9\n        \n    \n    myclass_name='Kaggle Member' #line16\n    ","0fa9bd87":"kaggler1=KaggleMember('SERkan','peldek','expert')\nkaggler1.display_member_info()\nkaggler1.display_number_of_member()\nprint()\nkaggler2=KaggleMember('kaan','can', 'grand master')\nkaggler2.display_member_info()\nkaggler1.display_number_of_member()\nprint()\nkaggler3=KaggleMember('Kral','Adam', \"expert\")\nkaggler3.display_member_info()\nkaggler1.display_number_of_member()\n\nprint()\nprint('Following codes check other class variable value ')\nprint(kaggler1.myclass_name)\nprint(kaggler2.myclass_name)\nprint(kaggler3.myclass_name)","8e834b01":"class MyDefinedClass:#Implicitly inheritance  \n    pass\n\nclass YourDefinedClass(object):#Explicityl inheritance\n    pass\n\nprint(\"The methods in MyDefinedClass:\\n\",dir(MyDefinedClass))\nprint()\nprint(\"The methods in YourDefinedClass:\\n\",dir(MyDefinedClass))\nprint()\nprint(\"The methods in 'object':\\n\",dir(object))","67026ab4":"print(\"The methods in KaggleMember:\\n\",dir(KaggleMember))","7ef92f7f":"import numpy as np # linear algebra\nimport pandas as pd # data processing\n\n#Visualization\nimport matplotlib.pyplot as plt\n\n#Systems\nimport os\nimport warnings\nprint(os.listdir(\"..\/input\"))","65d13850":"warnings.filterwarnings('ignore')\nprint(\"Warnings were ignored\")","423b140e":"class Information():\n\n    def __init__(self):\n        \"\"\"\n        This class give some brief information about the datasets.\n        Information introduced in R language style\n        \"\"\"\n        print(\"Information object created\")\n\n    def _get_missing_values(self,data):\n        \"\"\"\n        Find missing values of given datad\n        :param data: checked its missing value\n        :return: Pandas Series object\n        \"\"\"\n        #Getting sum of missing values for each feature\n        missing_values = data.isnull().sum()\n        #Feature missing values are sorted from few to many\n        missing_values.sort_values(ascending=False, inplace=True)\n        \n        #Returning missing values\n        return missing_values\n\n    def info(self,data):\n        \"\"\"\n        print feature name, data type, number of missing values and ten samples of \n        each feature\n        :param data: dataset information will be gathered from\n        :return: no return value\n        \"\"\"\n        feature_dtypes=data.dtypes\n        self.missing_values=self._get_missing_values(data)\n\n        print(\"=\" * 50)\n\n        print(\"{:16} {:16} {:25} {:16}\".format(\"Feature Name\".upper(),\n                                            \"Data Format\".upper(),\n                                            \"# of Missing Values\".upper(),\n                                            \"Samples\".upper()))\n        for feature_name, dtype, missing_value in zip(self.missing_values.index.values,\n                                                      feature_dtypes[self.missing_values.index.values],\n                                                      self.missing_values.values):\n            print(\"{:18} {:19} {:19} \".format(feature_name, str(dtype), str(missing_value)), end=\"\")\n            for v in data[feature_name].values[:10]:\n                print(v, end=\",\")\n            print()\n\n        print(\"=\"*50)\n","9d207f2f":"import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nclass Preprocess():\n\n    def __init__(self):\n        print(\"Preprocess object created\")\n\n    def fillna(self, data, fill_strategies):\n        for column, strategy in fill_strategies.items():\n            if strategy == 'None':\n                data[column] = data[column].fillna('None')\n            elif strategy == 'Zero':\n                data[column] = data[column].fillna(0)\n            elif strategy == 'Mode':\n                data[column] = data[column].fillna(data[column].mode()[0])\n            elif strategy == 'Mean':\n                data[column] = data[column].fillna(data[column].mean())\n            elif strategy == 'Median':\n                data[column] = data[column].fillna(data[column].median())\n            else:\n                print(\"{}: There is no such thing as preprocess strategy\".format(strategy))\n\n        return data\n\n    def drop(self, data, drop_strategies):\n        for column, strategy in drop_strategies.items():\n            data=data.drop(labels=[column], axis=strategy)\n\n        return data\n\n    def feature_engineering(self, data, engineering_strategies=1):\n        if engineering_strategies==1:\n            return self._feature_engineering1(data)\n\n        return data\n\n    def _feature_engineering1(self,data):\n\n        data=self._base_feature_engineering(data)\n\n\n        data['FareBin'] = pd.qcut(data['Fare'], 4)\n\n        data['AgeBin'] = pd.cut(data['Age'].astype(int), 5)\n\n        drop_strategy = {'Age': 1,  # 1 indicate axis 1(column)\n                         'Name': 1,\n                         'Fare': 1}\n        data = self.drop(data, drop_strategy)\n\n        return data\n\n    def _base_feature_engineering(self,data):\n        data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n\n        data['IsAlone'] = 1\n        data.loc[(data['FamilySize'] > 1), 'IsAlone'] = 0\n\n        data['Title'] = data['Name'].str.split(\", \", expand=True)[1].str.split('.', expand=True)[0]\n        min_lengtht = 10\n        title_names = (data['Title'].value_counts() < min_lengtht)\n        data['Title'] = data['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)\n\n        return data\n\n    def _label_encoder(self,data):\n        labelEncoder=LabelEncoder()\n        for column in data.columns.values:\n            if 'int64'==data[column].dtype or 'float64'==data[column].dtype or 'int64'==data[column].dtype:\n                continue\n            labelEncoder.fit(data[column])\n            data[column]=labelEncoder.transform(data[column])\n        return data\n\n    def _get_dummies(self, data, prefered_columns=None):\n\n        if prefered_columns is None:\n            columns=data.columns.values\n            non_dummies=None\n        else:\n            non_dummies=[col for col in data.columns.values if col not in prefered_columns ]\n\n            columns=prefered_columns\n\n\n        dummies_data=[pd.get_dummies(data[col],prefix=col) for col in columns]\n\n        if non_dummies is not None:\n            for non_dummy in non_dummies:\n                dummies_data.append(data[non_dummy])\n\n        return pd.concat(dummies_data, axis=1)","0256344d":"class PreprocessStrategy():\n    \"\"\"\n    Preprocess strategies defined and exected in this class\n    \"\"\"\n    def __init__(self):\n        self.data=None\n        self._preprocessor=Preprocess()\n\n    def strategy(self, data, strategy_type=\"strategy1\"):\n        self.data=data\n        if strategy_type=='strategy1':\n            self._strategy1()\n        elif strategy_type=='strategy2':\n            self._strategy2()\n\n        return self.data\n\n    def _base_strategy(self):\n        drop_strategy = {'PassengerId': 1,  # 1 indicate axis 1(column)\n                         'Cabin': 1,\n                         'Ticket': 1}\n        self.data = self._preprocessor.drop(self.data, drop_strategy)\n\n        fill_strategy = {'Age': 'Median',\n                         'Fare': 'Median',\n                         'Embarked': 'Mode'}\n        self.data = self._preprocessor.fillna(self.data, fill_strategy)\n\n        self.data = self._preprocessor.feature_engineering(self.data, 1)\n\n\n        self.data = self._preprocessor._label_encoder(self.data)\n\n    def _strategy1(self):\n        self._base_strategy()\n\n        self.data=self._preprocessor._get_dummies(self.data,\n                                        prefered_columns=['Pclass', 'Sex', 'Parch', 'Embarked', 'Title', 'IsAlone'])\n\n    def _strategy2(self):\n        self._base_strategy()\n\n        self.data=self._preprocessor._get_dummies(self.data,\n                                        prefered_columns=None)#None mean that all feature will be dummied","ec390d25":"import numpy as np\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.ensemble import VotingClassifier\nimport pandas as pd\nclass GridSearchHelper():\n    def __init__(self):\n        print(\"GridSearchHelper Created\")\n\n        self.gridSearchCV=None\n        self.clf_and_params=list()\n\n        self._initialize_clf_and_params()\n\n    def _initialize_clf_and_params(self):\n\n        clf= KNeighborsClassifier()\n        params={'n_neighbors':[5,7,9,11,13,15],\n          'leaf_size':[1,2,3,5],\n          'weights':['uniform', 'distance']\n          }\n        self.clf_and_params.append((clf, params))\n\n        clf=LogisticRegression()\n        params={'penalty':['l1', 'l2'],\n                'C':np.logspace(0, 4, 10)\n                }\n        self.clf_and_params.append((clf, params))\n\n        clf = SVC()\n        params = [ {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n                   {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']}]\n        self.clf_and_params.append((clf, params))\n\n        clf=DecisionTreeClassifier()\n        params={'max_features': ['auto', 'sqrt', 'log2'],\n          'min_samples_split': [2,3,4,5,6,7,8,9,10,11,12,13,14,15],\n          'min_samples_leaf':[1],\n          'random_state':[123]}\n        #Because of depricating warning for Decision Tree which is not appended.\n        #But it give high competion accuracy score. You can append when you run the kernel\n        self.clf_and_params.append((clf,params))\n\n        clf = RandomForestClassifier()\n        params = {'n_estimators': [4, 6, 9],\n              'max_features': ['log2', 'sqrt','auto'],\n              'criterion': ['entropy', 'gini'],\n              'max_depth': [2, 3, 5, 10],\n              'min_samples_split': [2, 3, 5],\n              'min_samples_leaf': [1,5,8]\n             }\n        #Because of depricating warning for RandomForestClassifier which is not appended.\n        #But it give high competion accuracy score. You can append when you run the kernel\n        self.clf_and_params.append((clf, params))\n\n    def fit_predict_save(self, X_train, X_test, y_train, submission_id, strategy_type):\n        self.X_train=X_train\n        self.X_test=X_test\n        self.y_train=y_train\n        self.submission_id=submission_id\n        self.strategy_type=strategy_type\n\n        clf_and_params = self.get_clf_and_params()\n        models=[]\n        self.results={}\n        for clf, params in clf_and_params:\n            self.current_clf_name = clf.__class__.__name__\n            grid_search_clf = GridSearchCV(clf, params, cv=5)\n            grid_search_clf.fit(self.X_train, self.y_train)\n            self.Y_pred = grid_search_clf.predict(self.X_test)\n            clf_train_acc = round(grid_search_clf.score(self.X_train, self.y_train) * 100, 2)\n            print(self.current_clf_name, \" trained and used for prediction on test data...\")\n            self.results[self.current_clf_name]=clf_train_acc\n            # for ensemble\n            models.append(clf)\n\n            self.save_result()\n            print()\n        \n        \"\"\"\n        voting_clf=VotingClassifier(models)\n        voting_clf.fit(self.X_train, self.y_train)\n        self.Y_pred=voting_clf.predict(self.X_test)\n        self.current_clf_name = clf.__class__.__name__\n        clf_train_acc = round(voting_clf.score(self.X_train, self.y_train) * 100, 2)\n        print(self.current_clf_name, \" train accuracy:\", clf_train_acc)\n        self.save_result()\n        \"\"\"\n    \n    def show_result(self):\n        for clf_name, train_acc in self.results.items():\n                  print(\"{} train accuracy is {:.3f}\".format(clf_name, train_acc))\n        \n    def save_result(self):\n        Submission = pd.DataFrame({'PassengerId': self.submission_id,\n                                           'Survived': self.Y_pred})\n        file_name=\"{}_{}.csv\".format(self.strategy_type,self.current_clf_name.lower())\n        Submission.to_csv(file_name, index=False)\n\n        print(\"Submission saved file name: \",file_name)\n\n    def get_clf_and_params(self):\n\n        return self.clf_and_params\n\n    def add(self,clf, params):\n        self.clf_and_params.append((clf, params))","c0dba7c2":"from yellowbrick.features import RadViz\nclass Visualizer:\n    \n    def __init__(self):\n        print(\"Visualizer object created!\")\n    \n    def RandianViz(self, X, y, number_of_features):\n        if number_of_features is None:\n            features=X.columns.values\n        else:\n            features=X.columns.values[:number_of_features]\n        \n        fig, ax=plt.subplots(1, figsize=(15,12))\n        radViz=RadViz(classes=['survived', 'not survived'], features=features)\n        \n        radViz.fit(X, y)\n        radViz.transform(X)\n        radViz.poof()\n        ","88180419":"class ObjectOrientedTitanic():\n\n    def __init__(self, train, test):\n        \"\"\"\n\n        :param train: train data will be used for modelling\n        :param test:  test data will be used for model evaluation\n        \"\"\"\n        print(\"ObjectOrientedTitanic object created\")\n        #properties\n        self.testPassengerID=test['PassengerId']\n        self.number_of_train=train.shape[0]\n\n        self.y_train=train['Survived']\n        self.train=train.drop('Survived', axis=1)\n        self.test=test\n\n        #concat train and test data\n        self.all_data=self._get_all_data()\n\n        #Create instance of objects\n        self._info=Information()\n        self.preprocessStrategy = PreprocessStrategy()\n        self.visualizer=Visualizer()\n        self.gridSearchHelper = GridSearchHelper()\n        \n\n\n    def _get_all_data(self):\n        return pd.concat([self.train, self.test])\n\n    def information(self):\n        \"\"\"\n        using _info object gives summary about dataset\n        :return:\n        \"\"\"\n        self._info.info(self.all_data)\n\n\n\n    def preprocessing(self, strategy_type):\n        \"\"\"\n        Process data depend upon strategy type\n        :param strategy_type: Preprocessing strategy type\n        :return:\n        \"\"\"\n        self.strategy_type=strategy_type\n\n        self.all_data = self.preprocessStrategy.strategy(self._get_all_data(), strategy_type)\n\n    def visualize(self, visualizer_type, number_of_features=None):\n        \n        self._get_train_and_test()\n        \n        if visualizer_type==\"RadViz\":\n            self.visualizer.RandianViz(X=self.X_train, \n                                    y=self.y_train, \n                                    number_of_features=number_of_features)\n\n    def machine_learning(self):\n        \"\"\"\n        Get self.X_train, self.X_test and self.y_train\n        Find best parameters for classifiers registered in gridSearchHelper\n        :return:\n        \"\"\"\n        self._get_train_and_test()\n\n        self.gridSearchHelper.fit_predict_save(self.X_train,\n                                          self.X_test,\n                                          self.y_train,\n                                          self.testPassengerID,\n                                          self.strategy_type)\n    def show_result(self):\n        self.gridSearchHelper.show_result()\n\n\n\n    def _get_train_and_test(self):\n        \"\"\"\n        Split data into train and test datasets\n        :return:\n        \"\"\"\n        self.X_train=self.all_data[:self.number_of_train]\n        self.X_test=self.all_data[self.number_of_train:]\n","4979dbdf":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\n\nobjectOrientedTitanic=ObjectOrientedTitanic(train, test)\n","2083b79a":"objectOrientedTitanic.information()","624afacc":"#There are currently two strategy type: strategy1, strategy2.\n#We can select any of two\nobjectOrientedTitanic.preprocessing(strategy_type='strategy1')","99d928a4":"objectOrientedTitanic.information()","eecc516e":"#Radian Viz figure\nobjectOrientedTitanic.visualize(visualizer_type=\"RadViz\", number_of_features=None)","53e1dfdc":"#Run all machine learning algorithms defined in object\nobjectOrientedTitanic.machine_learning()","a8c8cf46":"objectOrientedTitanic.show_result()","e2cecc39":"[Go to Contents Menu](#0.)\n\n# <a class=\"anchor\" id=\"1.2.\"><\/a>**Design Prencible** \n\nDesign princeble of object oriented programming is **modularity, abstraction, encapsulation.**\n\n**Modularity** is organizing principle of code into various functional units\n\n**Abstraction** is to simplisfication  a complex inner machanism to fundemantel parts\n\n**Encapsulation** mean that class inner details have not to be known by outer users","11fb6f31":"[Go to Contents Menu](#0.)\n\n# <a class=\"achor\" id=\"1.5.\"><\/a>**First Example: KaggleMember class**  \n\nLet's have some code to understand above definitions","ccb0e154":"Let's explain the code above. Numbers are given at the end of each line to make the descriptions easier (eg, # line1)\n\nFirst, we create a class named KaggleMember using the 'class' key word. The bracket symbols '()' are added at the end of the class name. Python allows class definition without adding parentheses (eg, KaggleMember). However, since most programming languages require the addition of parentheses symbols after the class name, the use of parentheses  has been preferred in this class definition\n\nIn the second line, the class variable named kaggle_member_count is defined. Class variables are defined outside of class functions. However, it is a good programming practice to write class variables just below the class name. At the bottom of the KaggleMember class, a class variable defined for learning purposes\n\nConstructor function is defined in line 3. In Python, the constructor function has a special name: __init __ (). Constructor functions are invoked on every instance of the class, and are generally used to assign initial values. In the above example, the constructor function has four different parameters: self, name, surname, level.\n* The first argument of every class method, including init, is always a reference to the current instance of the class. The word 'self' should be written as the first parameter of each function created in the Python class definition. It is important to note that; The word 'self' can be replaced with another word based on user preference. By convention, this argument is always named self.\n* There are three parameters that come after 'self'. The second and third parameters have no default value. For this reason, these parameters must be sent when the function is called. The fourth parameter has a default value. For this reason, if the fourth parameter is not sent when the function is called, it will get its default value. For the example above, it will take the value None.\n\nIn lines 4, 5, 6 and 8, the initial assignments of instance variables were made with values from the constructor function. Note that when values are assigned to variables, different inputs are transformed into the desired form. This input control is a small example for ** Robustness ** mentioned above.\n\nIn the sixth line, another instance variable is assigned a value. A function has been used for value assignment. The function assigns the value of the 'self.level' variable according to the value of the 'level' parameter.\n\nThe remaining lines contain the functions used.\n\nLet's create object using KaggleMember class\n","21b6e1e8":"**Notes:**\n\nPlease note, this kernel is currently in progress, but open to feedback and upvotes  (o____o)  ! Thanks!","b4d5f5ae":"[Go to Contents Menu](#0.)\n\n# <a class=\"anchor\" id=\"2.2.\"><\/a>**'Preprocess' class**","6a68e709":"[Go to Contents Menu](#0.)\n\n# <a  class=\"anchor\" id=\"1.6.\"><\/a>**Inheritance**  \n\nOne of the most important aspects of OOP is the ability to use previously written code. Inheritance is a perfect way to go. In fact, every object we created in Python inherits methods from \"**object**\" which is **super** class of all Python class. Let's understand how it is by examining the following code.\n","691a27ec":"[Go to Contents Menu](#0.)\n\n# <a class=\"anchor\" id=\"2.e1.\"><\/a>**Visualizer class** ","6f6309d6":"[Go to Contents Menu](#0.)\n\n# <a class=\"anchor\" id=\"1.3.\"><\/a>**Convention for Coding Style **  \n\n[The official Style Guide for Python Code](http:\/\/www.python.org\/dev\/peps\/pep-0008\/)\n\nPython code blocks are typically indented by 4 spaces. It is strongly recommended that tabs be avoided\n\nUse meaningful names for variables, funcitons, classes etc.\n\n**Classes**: should be singular and capitalized (e.g., 'Book' rather than 'book' or 'Books'\n\n**Functions**: sould be a lowercase verb and separeted by underscore for multple words (e.g., preprocess_data).\n\n**Variables**: sould be lowercase noun and separeted by underscore for multiple words (e.g., product_id)\n\n**Constant**: sould be uppercase noun and separeted by underscore for multiple words (e.g., MAX_SIZE)","012d8c57":"[Go to Contents Menu](#0.)\n\n# <a class=\"anchor\" id=\"2.\"><\/a>**WORKING ON TITANIC DATASET** \n\nNow let's work on the Titanic dataset using classes\n\n\nDifferent classes have been created for the operations on the Titanic dataset; Information, Preprocess, PreprocessStrategy, GridSearchHelper, ObjectOrientedTitanic\n\n'**Information**': This class prints summary information about the data set on the screen.\n\n'**Preprocess**': The preprocessing on the data set is done using this class.\n\n'**PreprocessStrategy**': Preprocessing is important in the Titanic data set. The PreprocessStrategy class was created to develop different pre-processing strategies.\n\n'**GridSearchHelper**': Class for parameter optimization for machine learning algorithms.\n\n'**ObjectOrientedTitanic**': The class for which all classes are managed.\n\n","1217308b":"[Go to Contents Menu](#0.)\n\n# <a class=\"anchor\" id=\"2.6.4.\"><\/a>**Visualize**  ","c138d437":"<a class=\"anchor\" id=\"0.\"><\/a>\n# **Contents**\n\n1. [OBJECT ORIENTED PROGRAMMING](#1.)\n* * [Design Goals](#1.1.)\n* *  [Design Prenciples](#1.2.)\n* * [Convention for Coding Style](#1.3.)\n* * [Starting Point of Object Oriented Programming: Class](#1.4.)\n* * [First Example: KaggleMember class](#1.5.)\n* * [Inheritance](#1.6.)\n1. [WORKING ON TITANIC DATASET](#2.)\n* * ['Information' class](#2.1.)\n* *  ['Preprocess' class](#2.2.)\n* * ['PreprocessStrategy' class](#2.3.)\n* * ['GridSearchHelper' class](#2.4.)\n* * [Visualizer class](#2.e1.)\n* * ['ObjectOrientedTitanic' class](#2.5.)\n* * [Testing](#2.6.)\n* * * [Create ObjectOrientedTitanic object](#2.6.1.)\n* * * [Display R Type Information](#2.6.2.)\n* * * [Define preprocess strategy](#2.6.3.)\n* * * [Visualize](#2.6.4.)\n* * * [Get GridSearchCV Results](#2.6.5.)","acb14b7d":"[Go to Contents Menu](#0.)\n<a class=\"anchor\" id=\"1.\"><\/a>\n\n# **OBJECT ORIENTED PROGRAMMING**  \n\nThe key point in the object oriented paradigma is **object**.  Each **object** is an instance of **class**. Each class consists of a description that contains the properties and functions of the objects.\n\nTypically a class includes:\n\n**Instance variables**, also known as **data members**\n\n**Methods**, also known as **member functions**","704d51de":"[Go to Contents Menu](#0.)\n\n# <a class=\"anchor\" id=\"1.4.\"><\/a>**Starting Point of Object Oriented Programming: Class** \n\nA class play as fundemental role for abstraction in OOP. \n\n**Mebmer functions** (also known as methods) perform set of actions ,with implementations that are common to all instances of that class. \n\n**Attributes** (also known as fields, instance variables, or data members) determine the information for each instance.\n\n**Instance**:  An individual object of a certain class. An object obj that belongs to a class Circle, for example, is an instance of the class Circle.\n\n**Class variable**: A variable that is shared by all instances of a class. Class variables are attributes which are owned by the class itself. They will be shared by all the instances of the class. Therefore they have the same value for every instance. \n\n**Instance variable: **A variable that is defined inside a method and belongs only to the current instance of a class. Instance variables are owned by the specific instances of a class. This means for two different instances the instance variables are usually\ndifferent.\n\n**Constructor: **A special funciton which is called when a new instance of class created. \n\n\n","f84e2dc3":"[Go to Contents Menu](#0.)\n\n<a class=\"anchor\" id=\"1.1.\"><\/a>**Design Goals** \n\nThe key point in the object oriented paradigma is designing code structure. \n\nDesign goals of object oriented paradigms are **robustness**, **adaptability** and **reusability**\n\n**Robustness** is capablity of handling unexpexted input.\n\n**Adaptability**(or evolvability or portability) is ability to run on different hadware and operating systems.\n\n**Reusability** is opportunity of using same code as a component of different systems. ","705826d2":"[Go to Contents Menu](#0.)\n\n# <a class=\"anchor\" id=\"2.6.5.\"><\/a>**Get GridSearchCV Results** ","f6d39663":"[Go to Contents Menu](#0.)\n\n# <a class=\"anchor\" id=\"2.4.\"><\/a>**'GridSearchHelper' class** ","c0222139":"[Go to Contents Menu](#0.)\n\n# <a class=\"anchor\" id=\"2.3.\"><\/a>**'PreprocessStrategy' class** ","24d9177d":"[Go to Contents Menu](#0.)\n\n# <a class=\"anchor\" id=\"2.6.2.\"><\/a>**Display  Information in 'R Style'**   ","d0289fd4":"Two different classes are defined in the above code. One is implicitly inherited while the other is explicitly  inherited. Using the predefined '**dir**' function, the methods belong to MyDefinedClass, YourDefinedClass and  '**object**'  is predefined class in Python, are printed on the screen. The methods of the three classes are the same.\n\nIf there are user-defined methods in the class, the dir function will show them too. The **methods** and **attributes** of the KaggleMember class are shown below. The **methods** and **attributes** we have described are at the end of the list.","093c9d30":"* **The aim of this kernel is to provide a solution for data science projects by using an Object Oriented Programming(OOP) approach. Object oriented programming is largely based on personal experience and is open to development. For this reason, code design can be improved according to the comments to be made for the kernel. Comments and criticisms will provide a better code design.**\n\n\n**Many thanks for upvotes and feedbacks ^ ____^ ! **","2fdb48b9":"[Go to Contents Menu](#0.)\n\n# <a class=\"anchor\" id=\"2.6.\"><\/a>**'Testing**  ","06e0fc4e":"[Go to Contents Menu](#0.)\n\n# <a class=\"anchor\" id=\"2.6.1.\"><\/a>**Create  ObjectOrientedTitanic object** ","c0213f15":"[Go to Contents Menu](#0.)\n\n# <a class=\"anchor\" id=\"2.5.\"><\/a>**'ObjectOrientedTitanic' class**  ","912bfe04":"[Go to Contents Menu](#0.)\n\n# <a class=\"anchor\" id=\"2.6.3.\"><\/a>**Define preprocess strategy**","5f1a1665":"[Go to Contents Menu](#0.)\n\n# <a class=\"anchor\" id=\"2.1.\"><\/a>**'Information' class**  ","29787d21":"Let's examine the codes above.\nThree different KaggleMember objects were created. The same process is performed for each object:\n\nWhen creatin Kaggler1 object, three parameters were sent to constructor function; 'SeRKaN', 'peldek', 'expert'. Then the display_member_info () function of the kaggler1 object is called. The function prints the information of the object kaggler1. The function kaggler1.display_number_of_member () prints the number of members.\n\nWhen creating kaggler2 object, three parameters were sent to constructor function; 'kaan', 'can', 'grand master'.\n\nWhen creating kaggler3 object, three parameters were sent to constructor function; 'King man'. Note that, after each object is created, the number of objects created is correctly given even though the function **kaggler1.display_number_of_member () **is called."}}