{"cell_type":{"2d494f73":"code","fab4c79e":"code","7cbc30b8":"code","8994051e":"code","90a5cbdd":"code","6339b071":"code","ff2482e1":"code","12f4df18":"code","01f51cb7":"code","aecabdcb":"code","e6e864f1":"code","2363bb9f":"code","2d41918b":"code","8816b6e9":"markdown","aafb28f5":"markdown","851e2730":"markdown","0f3adfc7":"markdown","e737bca6":"markdown","5b8d5e1a":"markdown","7f852571":"markdown","42136837":"markdown","9ed71bde":"markdown","9ee6b4f2":"markdown","bc4fd9b2":"markdown","4404340b":"markdown","55c191f2":"markdown","05e159f6":"markdown","62de3def":"markdown","89860450":"markdown","095eeff1":"markdown"},"source":{"2d494f73":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\nimport torch\n\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nfrom torch import nn \nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        path, folder = os.path.split(dirname)\n","fab4c79e":"train_on_gpu = torch.cuda.is_available()\ndata_transform1 = transforms.Compose([transforms.RandomRotation(45),\n                                     transforms.RandomRotation(30),\n                                     transforms.RandomResizedCrop(1080),\n                                     transforms.Resize(512),\n                                     transforms.Resize(224),\n                                     transforms.RandomRotation(45),\n                                      transforms.ToTensor()])\n\ndata_transform2 = transforms.Compose([transforms.RandomHorizontalFlip(),\n                                     transforms.RandomResizedCrop(1080),\n                                     transforms.Resize(224),\n                                     transforms.RandomRotation(45),\n                                      transforms.RandomRotation(35),\n                                      transforms.ToTensor()])","7cbc30b8":"from torch.utils.data import Subset, ConcatDataset , DataLoader\ndataset1 = datasets.ImageFolder(path,transform=data_transform1)\ndataset2 = datasets.ImageFolder(path,transform=data_transform2)\nprint(type(dataset1))\n#master=datasets.ImageFolder(path,transform=data_transform1)\nmaxlen=850\nfor l, cls in enumerate(dataset1.classes):\n    if l == 0 :\n        idx = [i for i in range(len(dataset1) ) if dataset1.imgs[i][1] == dataset1.class_to_idx[dataset1.classes[l]]]\n        subset = Subset(dataset1, idx)\n        master= Subset(subset,idx [:maxlen])\n        subset = Subset(dataset2, idx[:maxlen])\n        master= ConcatDataset((master, subset))\n        \n        print(len(master))\n    else : \n        idx = [i for i in range(len(dataset1) ) if dataset1.imgs[i][1] == dataset1.class_to_idx[dataset1.classes[l]]]\n        \n        subset = Subset(dataset1, idx[:maxlen])\n        master= ConcatDataset((master, subset))\n        subset = Subset(dataset2, idx[:maxlen])\n        master= ConcatDataset((master, subset))\n        print(len(master))\n        #print(len(master))\n","8994051e":"valid_size = 0.1\ntest_size = 0.1\nnum_train = len(master)\nindices = list(range(num_train))\nnp.random.shuffle(indices)\nvalid_split = int(np.floor((valid_size) * num_train))\ntest_split = int(np.floor((valid_size+test_size) * num_train))\nvalid_idx, test_idx, train_idx = indices[:valid_split], indices[valid_split:test_split], indices[test_split:]\n\nnum_workers = 9\nbatch_size= 60\ndisimage = 20\n#data = torch.utils.data.DataLoader(master, batch_size=batch_size, num_workers=num_workers)\n\ntrain_loader = Subset(master, train_idx)\nvalid_loader = Subset(master,valid_idx )\ntest_loader = Subset(master,test_idx )\n\n\ntrain_loader =torch.utils.data.DataLoader(train_loader, batch_size=batch_size, num_workers=num_workers)\nvalid_loader =torch.utils.data.DataLoader(valid_loader, batch_size=batch_size, num_workers=num_workers)\ntest_loader =torch.utils.data.DataLoader(test_loader, batch_size=batch_size, num_workers=num_workers)\n\n#print(train_loader[0])\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","90a5cbdd":"classes = [\"cane\", \"cavallo\", \"elefante\", \"farfalla\", \"gallina\", \"gatto\", \"mucca\", \"pecora\",\"ragno\", \"scoiattolo\" ]\n\ntranslate = {\"cane\": \"dog\", \"cavallo\": \"horse\", \"elefante\": \"elephant\", \"farfalla\": \"butterfly\",\n             \"gallina\": \"chicken\", \"gatto\": \"cat\", \"mucca\": \"cow\", \"pecora\": \"sheep\", \n             \"ragno\": \"spider\", \"scoiattolo\": \"squirrel\" }\n\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\nimages = images.numpy() # convert images to numpy for display\n# plot the images in the batch, along with the corresponding labels\nfig = plt.figure(figsize=(25, 4))\nfor idx in np.arange(disimage):\n    ax = fig.add_subplot(2, disimage\/2, idx+1, xticks=[], yticks=[])\n    plt.imshow(np.transpose(images[idx], (1, 2, 0)))\n    ax.set_title(translate[classes[labels[idx]]])","6339b071":"from collections import OrderedDict\nmodel = models.vgg19(pretrained=True)\n\nclassifier = nn.Sequential(OrderedDict([('fc1', nn.Linear(25088, 6000)),\n                                         ('relu', nn.LeakyReLU()),\n                                         ('dropout', nn.Dropout(.5)), \n                                         ('fc2', nn.Linear(6000, 10)), \n                                         ('output', nn.Softmax(dim=1) )]))                                  \n\nmodel.classifier = classifier\n\nprint(model)","ff2482e1":"import torch.optim as optim\n\n# specify loss function (categorical cross-entropy)\ncriterion = nn.CrossEntropyLoss()\n\n# specify optimizer (stochastic gradient descent) and learning rate = 0.001\noptimizer = optim.SGD(model.parameters(), lr=0.001)","12f4df18":"def seq (model, df, name ): \n    train_loss = 0.0\n    class_correct = list(0. for i in range(10))\n    class_total = list(0. for i in range(10))\n    for batch_i, (data, target) in enumerate(df):\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n            model.cuda()\n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # backward pass: compute gradient of the loss with respect to model parameters\n        if name == 'train': \n            loss.backward()\n        # perform a single optimization step (parameter update)\n        optimizer.step()\n        # update training loss \n        train_loss += loss.item()\n        _, pred = torch.max(output, 1) \n        # compare predictions to true label\n        correct_tensor = pred.eq(target.data.view_as(pred))\n        correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n        for i in range(len(target.data)):\n            label = target.data[i]\n            class_correct[label] += correct[i].item()\n            class_total[label] += 1\n        \n    return class_correct, class_total, train_loss","01f51cb7":"def printdata(class_correct, class_total, train_loss, epoch, name, df ): \n    print(f'Epoch %d, loss: %.8f \\t{name} Accuracy (Overall): %2d%% (%2d\/%2d)' %(epoch,\n        train_loss \/ len(df), 100. * np.sum(class_correct) \/ np.sum(class_total),\n        np.sum(class_correct), np.sum(class_total)))\n    if ((epoch+1) % 5 == 0 or epoch == 1):\n        for i in range(10):\n            if class_total[i] > 0:\n                print(f'{name} Accuracy of %5s: %2d%% (%2d\/%2d)' % (\n                translate[classes[i]], 100 * class_correct[i] \/ class_total[i],\n                np.sum(class_correct[i]), np.sum(class_total[i])))","aecabdcb":"def trainModel (model, train_loader,valid_loader, num_epochs=20): \n    # number of epochs to train the model\n    n_epochs = num_epochs\n    for epoch in range(1, n_epochs+1):\n        train_loss = 0.0\n        class_correct = list(0. for i in range(10))\n        class_total = list(0. for i in range(10))\n        ###################\n        # train the model #\n        ###################\n       # Repeat for each batch in the training set\n        model.train()\n        class_correct, class_total, train_loss= seq(model,  train_loader, 'train')\n        printdata(class_correct, class_total, train_loss, epoch, 'train', train_loader)\n        # Repeat for each validation batch \n        ###################\n        # validate the model #\n        ###################\n        model.eval()\n        class_correct, class_total, train_loss= seq(model, valid_loader, 'validation')\n        printdata(class_correct, class_total, train_loss, epoch, 'validation', valid_loader)\n    torch.save(model.state_dict(), 'model.pt')        \n    print(f'model saved ')","e6e864f1":"print(len(train_loader), len(valid_loader))\ntrainModel (model, train_loader,valid_loader,80)","2363bb9f":" # track test loss \n# over 10 animals classes\ntest_loss = 0.0\nclass_correct = list(0. for i in range(10))\nclass_total = list(0. for i in range(10))\nmodel.eval()\nclass_correct, class_total, train_loss= seq(model, test_loader, 'test')\nprintdata(class_correct, class_total, train_loss, 1, 'test', test_loader)","2d41918b":"# obtain one batch of test images\ndataiter = iter(test_loader)\nimages, labels = dataiter.next()\nimages.numpy()\n\n# move model inputs to cuda, if GPU available\nif train_on_gpu:\n    images, labels = images.cuda(), labels.cuda()\n    print('train on gpu' , train_on_gpu)\n\n# get sample outputs\noutput = model(images)\nimages = images.cpu()\n# convert output probabilities to predicted class\n_, preds_tensor = torch.max(output, 1)\npreds = np.squeeze(preds_tensor.numpy()) if not train_on_gpu else np.squeeze(preds_tensor.cpu().numpy())\n\n# plot the images in the batch, along with predicted and true labels\nfig = plt.figure(figsize=(25, 4))\nfor idx in np.arange(disimage):\n    ax = fig.add_subplot(2, disimage\/2, idx+1, xticks=[], yticks=[])\n    plt.imshow(np.transpose(images[idx], (1, 2, 0)))\n    ax.set_title(\"{} ({})\".format(translate[classes[preds[idx]]], translate[classes[labels[idx]]]),\n                 color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))","8816b6e9":"# testing the model ","aafb28f5":"we are going to apply some transformation on the data like random rotation and resize the images then convert it into torch tensor to feed it into the model using pytorch ","851e2730":"## create sequantical function \nThis function go on the train processes one by one ","0f3adfc7":"## reading the data ","e737bca6":"#### calling the train function ","5b8d5e1a":"## animal classifier \nHere we'll be using VGG19  model to classify images of animals. We'll start, as usual, by importing our usual resources. And checking if we can train our model on GPU.\n![VGG-19.png](attachment:9649d06f-b18d-4e30-8365-b819dd6c61dc.png)","7f852571":"### model train function \nThis function call all the function in the note book to make the training and evaluating  to the model ","42136837":"then we are going to check for a sampel of the data in the train data to make sure the data had been splited right. ","9ed71bde":"first of all we need to identical in size of images that in the so we are going to pickup the fist few images from eache class.   \nbefor loading the data into torch loader we need to spit it into train , validation, and test.   \nwe are going to use numpy to create arrays for the validation, train, and test data  \nby using the rondom shuffle to get random images from the image folders   \nthen we are going to save this number in a lists   ","9ee6b4f2":"after we save the lists that contain the images number we are going to use the data subset to split the imagefolder data into sub torchs to be used in Dataloader to be loaded ","bc4fd9b2":"### creating transforms to edit the data ,and transform it into torch tensor ","4404340b":"###  **Please upvote if you like my approach or if you learned something from this notebook. Your support gives me motivation to create interesting stuff. Thank you.** ","55c191f2":"## divid the data into train, validate, and test ","05e159f6":"### print data funcion \nThis function get the data from sequantical  function then print it ","62de3def":"## loade VGG19 then change it's classifier to fit our data ","89860450":"---\n# Training\n\nHere, we'll train the network.","095eeff1":"# image classification \nIn this notebook, we'll be using CNN model on animals  dataset as a feature extractor. "}}