{"cell_type":{"76122011":"code","0006d581":"code","1d27b273":"code","75065425":"code","3657230b":"code","85ab03c5":"code","c3c25671":"code","b0e322f6":"code","915246b4":"code","b9e87c4b":"code","a803f938":"code","d27145f6":"code","d05227ac":"code","246ba651":"code","8666b694":"code","e844d547":"code","f2a122b6":"code","e1224b3f":"code","e4eb7269":"code","03dac8d0":"code","5b0c909d":"code","939be25d":"code","a1c02c08":"code","98c0674f":"code","ec769c97":"code","01ec3a7e":"code","69900b57":"markdown","00114b7a":"markdown","a5416fa5":"markdown","ec9048e7":"markdown","01edf1c9":"markdown","2ba9b8b8":"markdown","6e793dd0":"markdown","2074d233":"markdown","f7bb9bd5":"markdown","cd339fbb":"markdown","a08ce3b7":"markdown","b1b9663a":"markdown"},"source":{"76122011":"import warnings\nwarnings.filterwarnings('ignore')","0006d581":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport json\nfrom pandas.io.json import json_normalize\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1d27b273":"import datetime\n\nimport IPython\nimport IPython.display\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\n\nmpl.rcParams['figure.figsize'] = (8, 6)\nmpl.rcParams['axes.grid'] = False","75065425":"train_full = pd.read_json('..\/input\/stanford-covid-vaccine\/train.json', lines=True)\ntrain_full.shape","3657230b":"test_full = pd.read_json('..\/input\/stanford-covid-vaccine\/test.json', lines=True)\ntest_full.shape","85ab03c5":"train_full.head().T","c3c25671":"test_full.head().T","b0e322f6":"train_json = [json.loads(line) for line in open('..\/input\/stanford-covid-vaccine\/train.json', 'r')]\ntest_json = [json.loads(line) for line in open('..\/input\/stanford-covid-vaccine\/test.json', 'r')]","915246b4":"def preprocess_json(input_json, is_train):\n    \n    for index,json_ in enumerate(input_json):\n        json_['step'] = list(range(json_['seq_length']))\n        json_['sequence'] = list(json_['sequence'])\n        json_['structure'] = list(json_['structure'])\n        json_['predicted_loop_type'] = list(json_['predicted_loop_type'])\n        if os.path.exists('..\/input\/stanford-covid-vaccine\/bpps\/'+json_['id']+'.npy'):\n            np_array = np.load('..\/input\/stanford-covid-vaccine\/bpps\/'+json_['id']+'.npy')\n            json_['unpaired_probability'] = list(1-sum(np_array))\n        else:\n            print('bpps not found')\n        if is_train:\n            append_list = [np.nan for i in range(39)]\n            json_['reactivity'].extend(append_list)\n            json_['reactivity_error'].extend(append_list)\n            json_['deg_Mg_pH10'].extend(append_list)\n            json_['deg_error_Mg_pH10'].extend(append_list)\n            json_['deg_pH10'].extend(append_list)\n            json_['deg_error_pH10'].extend(append_list)\n            json_['deg_Mg_50C'].extend(append_list)\n            json_['deg_error_Mg_50C'].extend(append_list)\n            json_['deg_50C'].extend(append_list)\n            json_['deg_error_50C'].extend(append_list)\n                \npreprocess_json(train_json, True)\npreprocess_json(test_json, False)","b9e87c4b":"def process_json(input_json, is_train):\n    if is_train:\n        train = pd.json_normalize(data = input_json, \n                                record_path ='step',  \n                                meta =['id','seq_length','seq_scored','SN_filter','signal_to_noise']) \n    else:\n        train = pd.json_normalize(data = input_json, \n                                record_path ='step',  \n                                meta =['id','seq_length','seq_scored']) \n    train.rename(columns={0:'step'}, inplace=True)\n    train['unpaired_probability'] = pd.json_normalize(data = input_json, \n                                record_path ='unpaired_probability'\n                                            )\n    train['sequence'] = pd.json_normalize(data = input_json, \n                                record_path ='sequence'\n                                            )\n    train['structure'] = pd.json_normalize(data = input_json, \n                                record_path ='structure'\n                                            )\n    train['predicted_loop_type'] = pd.json_normalize(data = input_json, \n                                record_path ='predicted_loop_type'\n                                            )\n    if is_train:\n        train['reactivity'] = pd.json_normalize(data = input_json, \n                                        record_path ='reactivity'\n                                                    )\n        train['reactivity_error'] = pd.json_normalize(data = input_json, \n                                        record_path ='reactivity_error'\n                                                    )\n        train['deg_Mg_pH10'] = pd.json_normalize(data = input_json, \n                                        record_path ='deg_Mg_pH10'\n                                                    )\n        train['deg_error_Mg_pH10'] = pd.json_normalize(data = input_json, \n                                        record_path ='deg_error_Mg_pH10'\n                                                    )\n        train['deg_pH10'] = pd.json_normalize(data = input_json, \n                                        record_path ='deg_pH10',\n                                                    )\n        train['deg_error_pH10'] = pd.json_normalize(data = input_json, \n                                        record_path ='deg_error_pH10',\n                                                    )\n        train['deg_Mg_50C'] = pd.json_normalize(data = input_json, \n                                        record_path ='deg_Mg_50C',\n                                                    )\n        train['deg_error_Mg_50C'] = pd.json_normalize(data = input_json, \n                                        record_path ='deg_error_Mg_50C',\n                                                    )\n        train['deg_50C'] = pd.json_normalize(data = input_json, \n                                        record_path ='deg_50C',\n                                                    )\n        train['deg_error_50C'] = pd.json_normalize(data = input_json, \n                                        record_path ='deg_error_50C',\n                                                    )\n    \n    train.set_index(['id','step'], inplace=True)\n    return train\n\nX_train = process_json(train_json, True)\nX_test = process_json(test_json, False)\nprint(X_train.shape, X_test.shape)","a803f938":"X_train.isnull().any()","d27145f6":"X_train.isnull().sum()","d05227ac":"X_train.head()","246ba651":"print(X_test[X_test.seq_length==107].shape, X_test[X_test.seq_length==130].shape)","8666b694":"print(X_test.isnull().any())","e844d547":"X_test.head()","f2a122b6":"X_train.to_csv('train.csv')\nX_test.to_csv('test.csv')","e1224b3f":"!cp ..\/input\/stanford-covid-vaccine\/sample_submission.csv sample_submission.csv ","e4eb7269":"test_train = pd.read_csv('train.csv', index_col=[0,1])\nprint(X_train.dtypes)\nprint(test_train.dtypes)","03dac8d0":"cols = ['sequence','structure','predicted_loop_type']\nprint(X_train.shape, test_train.shape, test_train[cols].equals(X_train[cols]))","5b0c909d":"X_train.head()","939be25d":"test_train.head()","a1c02c08":"test_test = pd.read_csv('test.csv', index_col=[0,1])\nprint(X_test.dtypes)\nprint(test_test.dtypes)","98c0674f":"cols = ['sequence','structure','predicted_loop_type']\nprint(X_test.shape, test_test.shape, test_test[cols].equals(X_test[cols]))","ec769c97":"X_test.head()","01ec3a7e":"test_test.head()","69900b57":"There are no NaN entries as expected.","00114b7a":"# OpenVaccine: COVID-19 mRNA Vaccine Degradation Prediction JSON Dataset to CSV Dataset Conversion","a5416fa5":"### Write to CSV file","ec9048e7":"# EOF","01edf1c9":"Not so intuitive, right. Lets see if we can flatten it.","2ba9b8b8":"## UPDATE: There was a bug in previous version, in train set all measurement values were flattened to the first 2400\\*68 entries followed by 2400\\*39 nan. This is updated to flatten correctly with 68 entries and 39 nan for each id.","6e793dd0":"### Read back and verify shape and contents","2074d233":"Test set has 629\\*107 = 67303 + 3005\\*130 = 390650 entries corresponding to 3634 rows in test set.","f7bb9bd5":"## Read train and test json","cd339fbb":"Lets compare the columns of same type (float64 not compared as floating point numbers will not match due to precision)","a08ce3b7":"I think that for EDA, a flat file based representation would be good. Hence I am converting the json hierarchical dataset of the competition to CSV format popular among Kagglers.\n\n## References: My public notebooks for OpenVaccine\n\n* [Flatten JSON Data](https:\/\/www.kaggle.com\/arunprathap\/openvaccine-flatten-json-data)\n\n* [Feature Correlation, Importance](https:\/\/www.kaggle.com\/arunprathap\/openvaccine-feature-correlation-importance)","b1b9663a":"So we got 256800 = 2400\\*107 rows. But since the measured values are there only for first 68 pairs, we will have NaN on the remaining columns for these entries. This is not cleaned here since the user can easily remove those with dropna if he wants only 68 entries or can fill with dummy values if he wants to use all 107. So we will have 2400\\*39 = 96300 NaN values in these columns."}}