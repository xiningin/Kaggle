{"cell_type":{"26d14849":"code","d8d39db6":"code","79da9aaa":"code","cd0cee5f":"code","7abe7b4b":"code","0320de08":"code","58d807e3":"code","5f778bc8":"code","bef871c7":"code","686767b0":"code","dd5f2d3f":"code","6610b735":"code","c48173d0":"code","5490296f":"code","fd5b788c":"code","48cb8cb8":"code","f718d94a":"code","a153253c":"code","6e85b6fd":"code","d9261cf9":"code","74b06fe9":"code","b44472ac":"code","ab2cb253":"code","baf60f11":"code","8e4aacdf":"code","674a87f1":"code","0c952af5":"code","e61dfc06":"code","b4280f8a":"code","99e2c713":"code","ca6d9952":"code","c6af7334":"code","e1b99d48":"code","cb972a51":"code","582fc9dd":"code","8f8bb994":"code","872b8252":"code","ec0b7ad0":"code","d605e1ed":"code","fe76575b":"code","b66e7ee1":"code","f14f40ff":"code","c703ec76":"code","5c9f3d74":"code","8f8b2f87":"code","a652866c":"code","dd3aff90":"code","22f0b7cb":"code","9cbcd949":"code","2a83f477":"code","565259bb":"code","971eb10c":"code","18b0d88f":"code","9712f3d6":"code","5c3dee9b":"code","796a77cf":"code","1e0fb995":"code","01cd06e3":"markdown","4b9a34b2":"markdown","21ef34df":"markdown","0acf5de9":"markdown","216e4d3e":"markdown","cf4842b7":"markdown","9fca1560":"markdown"},"source":{"26d14849":"!pip install nodevectors","d8d39db6":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import KFold, GridSearchCV\nfrom sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n\nimport itertools\nimport xgboost \nimport lightgbm\nimport networkx\nimport nodevectors\nimport os,gc\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","79da9aaa":"train = pd.read_csv('..\/input\/liverpool-ion-switching\/train.csv')\ntest = pd.read_csv('..\/input\/liverpool-ion-switching\/test.csv')\nprint(train.shape, test.shape)","cd0cee5f":"train.head()","7abe7b4b":"train.info()","0320de08":"test.head()","58d807e3":"print(train.isna().any().sum(), test.isna().any().sum())","5f778bc8":"fig, ax = plt.subplots(1,2,figsize=(20,8))\nsns.countplot(train.open_channels, ax=ax[0])\nsns.distplot(train.open_channels, ax=ax[1])","bef871c7":"# plt.figure(figsize=(20,8))\n# sns.scatterplot(x='time', y='open_channels', data=train)","686767b0":"# plt.figure(figsize=(20,8))\n# sns.lineplot(x='time', y='signal', hue='open_channels', data=train[train['time'] < 100])","dd5f2d3f":"# plt.figure(figsize=(20,8))\n# sns.lineplot(x='time', y='signal', hue='open_channels', data=train[(train['time'] > 100) & (train['time'] < 200)])","6610b735":"# plt.figure(figsize=(20,8))\n# sns.lineplot(x='time', y='signal', hue='open_channels', data=train[(train['time'] > 200) & (train['time'] < 300)])","c48173d0":"# plt.figure(figsize=(20,8))\n# sns.lineplot(x='time', y='signal', hue='open_channels', data=train[(train['time'] > 300) & (train['time'] < 400)])","5490296f":"# plt.figure(figsize=(20,8))\n# sns.lineplot(x='time', y='signal', hue='open_channels', data=train[train['time'] > 400])","fd5b788c":"train.describe()","48cb8cb8":"G = networkx.Graph()\nG","f718d94a":"temp = train[['signal', 'open_channels']]\ntemp","a153253c":"temp['signal'] = temp['signal'].round(2)\ntemp['signal'].nunique()","6e85b6fd":"temp['signal'] = temp['signal'].astype(str)\ntemp","d9261cf9":"G.add_nodes_from(temp['signal'].values, signal=True)\nprint(len(G.nodes()))","74b06fe9":"temp['open_channels'] = temp['open_channels'].apply(lambda x : -99 if x ==0 else x * -999)\ntemp","b44472ac":"G.add_nodes_from(temp['open_channels'].values, channel=True)\nprint(len(G.nodes()))","ab2cb253":"G.add_edges_from(temp.values)\nprint(len(G.nodes()), len(G.edges()))","baf60f11":"def createEdgesBetweenSignalsWithSameOpenChannel(G):\n    channel_nodes = networkx.get_node_attributes(G, 'channel')\n    channel_nodes = list(channel_nodes.keys())\n    edges_to_be_created = []\n\n    for i in channel_nodes:\n        if(len([x for x in G.neighbors(i)]) > 1):\n            edges_to_be_created.append([x for x in G.neighbors(i)])\n            \n    for i in edges_to_be_created:\n        for j in itertools.combinations(i,2):\n            G.add_edge(*j)\n            \n    return G ","8e4aacdf":"G = createEdgesBetweenSignalsWithSameOpenChannel(G)\nprint(len(G.edges()))","674a87f1":"channel_nodes = networkx.get_node_attributes(G, 'channel')\nchannel_nodes = list(channel_nodes.keys())\nG.remove_nodes_from(channel_nodes)","0c952af5":"n2v = nodevectors.Node2Vec(\n    walklen=32,\n    epochs=10,\n    return_weight=1,\n    neighbor_weight=1.0,\n    n_components=32,\n    w2vparams={'window': 10,\n               'min_count':1\n              }\n)\nn2v.fit(G, verbose=True)","e61dfc06":"%%time\nnodes = [i for i in n2v.model.wv.vocab]\nembeddings = np.array([n2v.model.wv[x] for x in nodes])","b4280f8a":"embedding_df = pd.DataFrame()\nembedding_df['signal'] = nodes\nembedding_df['embed'] = list(embeddings)\nembedding_df","99e2c713":"del G, temp\ngc.collect()","ca6d9952":"embed_cols = [f\"embed{i}\" for i in range(32)]\nembed_cols\n\ndf3 = pd.DataFrame(embedding_df['embed'].values.tolist(), columns=embed_cols)\ndf3","c6af7334":"embedding_df = embedding_df.join(df3)\nembedding_df = embedding_df.drop(['embed'], axis=1)\nembedding_df","e1b99d48":"del df3, embed_cols\ngc.collect()","cb972a51":"embedding_df = embedding_df.drop_duplicates(subset=['signal'])\nembedding_df","582fc9dd":"embedding_df['signal'] = embedding_df['signal'].astype(float)\nembedding_df","8f8bb994":"train['train'] = 1\ntest['train'] = 0","872b8252":"all_data = pd.concat([train,test]).drop(['open_channels'], axis=1).reset_index(drop=True)\nall_data","ec0b7ad0":"all_data = all_data.sort_values(by=['time']).reset_index(drop=True)\nall_data","d605e1ed":"all_data.index = ((all_data.time * 10_000) - 1).values\nall_data","fe76575b":"all_data['batch'] = all_data.index \/\/ 50_000\nall_data","b66e7ee1":"all_data['signal_batch_min'] = all_data.groupby('batch')['signal'].transform('min')\nall_data['signal_batch_max'] = all_data.groupby('batch')['signal'].transform('max')\nall_data['signal_batch_std'] = all_data.groupby('batch')['signal'].transform('std')\nall_data['signal_batch_mean'] = all_data.groupby('batch')['signal'].transform('mean')\nall_data['signal_batch_median'] = all_data.groupby('batch')['signal'].transform('median')","f14f40ff":"all_data['signal_batch_skew'] = all_data.groupby('batch')['signal'].transform('skew')\nall_data['mean_abs_chg_batch'] = all_data.groupby(['batch'])['signal'].transform(lambda x: np.mean(np.abs(np.diff(x))))\nall_data['median_abs_chg_batch'] = all_data.groupby(['batch'])['signal'].transform(lambda x: np.median(np.abs(np.diff(x))))\nall_data['abs_max_batch'] = all_data.groupby(['batch'])['signal'].transform(lambda x: np.max(np.abs(x)))\nall_data['abs_min_batch'] = all_data.groupby(['batch'])['signal'].transform(lambda x: np.min(np.abs(x)))\nall_data['abs_mean_batch'] = all_data.groupby(['batch'])['signal'].transform(lambda x: np.mean(np.abs(x)))\nall_data['abs_median_batch'] = all_data.groupby(['batch'])['signal'].transform(lambda x: np.median(np.abs(x)))\nall_data['moving_average_batch_1000_mean'] = all_data.groupby(['batch'])['signal'].rolling(window=1000).mean().mean(skipna=True)","c703ec76":"all_data['signal_round'] = all_data['signal'].round(2)\nall_data","5c9f3d74":"all_data = all_data.merge(embedding_df, left_on='signal_round', right_on='signal', how='left')\nall_data","8f8b2f87":"all_data = all_data.drop_duplicates(subset=['time'])\nall_data","a652866c":"del test, embedding_df\ngc.collect()","dd3aff90":"KFOLDS = 5\ncv = KFold(n_splits=KFOLDS, shuffle=True, random_state=108)","22f0b7cb":"# xgb = xgboost.XGBClassifier(tree_method='hist', objective='multi:softmax')\nparam_grid ={\n    'learning_rate': [0.01],\n    'n_estimators':[100],\n    }","9cbcd949":"lgb = lightgbm.LGBMClassifier(objective='multiclass')","2a83f477":"clf = GridSearchCV(\n        estimator=lgb,\n        param_grid=param_grid,\n        cv=cv,\n        iid=True,\n        return_train_score=True,\n        scoring='f1_macro',\n        verbose=0\n    )","565259bb":"clf.fit(all_data[all_data['train']==1].drop(['train', 'time', 'signal_y'],axis=1),train['open_channels'])","971eb10c":"plt.figure(figsize=(20,6))\nsns.barplot(x=clf.best_estimator_.feature_importances_, y=all_data[all_data['train']==1].drop(['train', 'time', 'signal_y'],axis=1).columns)","18b0d88f":"X_test = all_data[all_data['train'] == 0]\nX_test","9712f3d6":"predictions = clf.predict(X_test.drop(['train', 'time', 'signal_y'], axis=1))\npredictions","5c3dee9b":"plt.figure(figsize=(8,6))\nsns.countplot(predictions)","796a77cf":"X_test['open_channels'] = predictions\nX_test","1e0fb995":"X_test = X_test[['time', 'open_channels']]\nX_test.to_csv('submission.csv', index=False, float_format='%.4f')","01cd06e3":"## Modeling","4b9a34b2":"Classification. Higher number of open channels are less frequent. Let's check how open_channels vary with time. ","21ef34df":"Cool. So, we can say that a single channel is opened only when the value of signal > -2.","0acf5de9":"Insights:\n1. Values 0 and 1 for open_channels is very frequent as compared to other values.\n2. Values >= 6 occur between 200s and 250s and then between 450s and 500s. Seasonality? Maybe\n3. Values 2 and 3 occur between 150s and 300s and then between 350s and 500s. ","216e4d3e":"## Feature Engineering","cf4842b7":"Clearly, the number of open channels increases with increase in signal. This graph is in tune with our time vs open_channels graph.","9fca1560":"Cool, we have no missing values and all columns are numeric type."}}