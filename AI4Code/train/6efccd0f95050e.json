{"cell_type":{"0d6d2c8a":"code","f6e09613":"code","79033296":"code","59e188ec":"code","713f6492":"code","cd7a3472":"code","2a6be56f":"code","b92307e5":"code","a8dfd7e4":"code","6b098af6":"code","68e91212":"code","24f15110":"code","afedb42b":"code","4e256b66":"code","6655b148":"code","c6fe62ab":"code","6bee39ef":"code","6cff226d":"code","7566fc9f":"code","b80a4023":"code","faf2cfa6":"code","149af58d":"code","e0ef65a4":"code","d3125663":"code","f969b189":"code","58e0999b":"code","21191fce":"code","dfca89c9":"code","05f00a24":"code","6041dcce":"code","6d8cd8a8":"code","b1f547b6":"code","86a7f455":"code","97f10c11":"code","aa630612":"code","48306561":"code","dfcd7abc":"code","332b369a":"markdown","d23dbf14":"markdown","d808ed22":"markdown","e7cfde70":"markdown","4feef41d":"markdown","b001d713":"markdown","eb79841f":"markdown","5eb46735":"markdown","7f6e5ffa":"markdown","e6c3345d":"markdown","fd2ada21":"markdown","585d4274":"markdown","edbe30ea":"markdown","e0816b64":"markdown"},"source":{"0d6d2c8a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport glob\nimport json\nimport re\nimport nltk\nnltk.download('stopwords')\nnltk.download(\"wordnet\")\nfrom nltk.corpus import stopwords\nimport seaborn as sns\nfrom wordcloud import WordCloud, ImageColorGenerator\nstop_words = set(stopwords.words(\"english\"))\nfrom nltk.corpus import wordnet\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn import svm","f6e09613":"df = pd.read_json('..\/input\/news-headlines-dataset-for-sarcasm-detection\/Sarcasm_Headlines_Dataset.json', lines=True)\npd.set_option('display.max_colwidth', -1)","79033296":"df['source'] = df.article_link.apply(lambda x: x.split('.')[1])\ndf = df.drop('article_link', axis=1)\ndf.shape","59e188ec":"df.is_sarcastic.value_counts()","713f6492":"print(df.shape)\ndf.head()","cd7a3472":"df.source.value_counts()","2a6be56f":"df.headline.isna().sum()","b92307e5":"df.describe()","a8dfd7e4":"cur_stops = [ 'what','which','who','whom','this','that','these','those','been','being','have','has','had','having','do','does','did',\n                    'doing','and','but','if','or','because','as','until','while','of','at','by','for','with','about','against','between',\n                    'into','through','during','before','after','above','below','to','from','up','down','in','out','on','off','over','under',\n                    'again''further','then','once','here','there','when','where','why','how','all','any','both','each','few','more','most',\n                    'other','some','such','no','nor','not','only','own','same','so','than','too','very','can','will','just','don','should',\n                    'now','n\\t' ]","6b098af6":"df_gen = df[df['is_sarcastic'] == 0]['headline']\ndf_sarc = df[df['is_sarcastic'] == 1]['headline']","68e91212":"gen_tokens = df_gen.apply(lambda x: nltk.word_tokenize(x))\nsarc_tokens = df_sarc.apply(lambda x: nltk.word_tokenize(x))","24f15110":"gen_dict = {}\nsarc_dict = {}\ndef create_dict(tokens, toks_dict):\n    for row in tokens:\n        for w in row:\n            if w in cur_stops:\n                if w in toks_dict:\n                    toks_dict[w] += 1\n                else:\n                    toks_dict[w] = 1\n    return toks_dict\n\ngen_count = create_dict(gen_tokens, gen_dict)\nsarc_count = create_dict(sarc_tokens, sarc_dict)","afedb42b":"df_gen_stops = pd.DataFrame({'Non-sarcasm Stops': list(gen_count.keys()), \n                        'count': list(gen_count.values()) }).sort_values('count', ascending=False).reset_index()\ndf_sarc_stops = pd.DataFrame({'Sarcasm Stops': list(sarc_count.keys()), \n                        'count': list(sarc_count.values()) }).sort_values('count', ascending=False).reset_index()","4e256b66":"sns.set(rc={'figure.figsize':(20,14)})\na = sns.barplot(x=\"Non-sarcasm Stops\", y='count', data=df_gen_stops, palette=\"Blues_d\")\nplt.xticks(rotation=80)\nplt.show()","6655b148":"a = sns.barplot(x=\"Sarcasm Stops\", y='count', data=df_sarc_stops, palette=\"OrRd_d\")\nplt.xticks(rotation=80)\nplt.show()","c6fe62ab":"plt.figure(figsize = (10,10))\nwc = WordCloud(width = 2000 , height = 1000 , max_words = 500).generate(\" \".join(df_gen))\nplt.imshow(wc , interpolation = 'bilinear')","6bee39ef":"plt.figure(figsize = (10,10))\nwc = WordCloud(width = 2000 , height = 1000 , max_words = 1000).generate(\" \".join(df_sarc))\nplt.imshow(wc , interpolation = 'bilinear')","6cff226d":"df['text_len'] = df['headline'].apply(lambda x: len(x.split(' ')))","7566fc9f":"sns.set(rc={'figure.figsize':(8 ,7)})\nsns.boxplot(y='text_len', x=\"is_sarcastic\", data=df)","b80a4023":"from nltk.sentiment.vader import SentimentIntensityAnalyzer\n\nsia = SentimentIntensityAnalyzer()","faf2cfa6":"def get_scores(row):\n    scores = list()\n    h = row.split(' ')\n    for word in h:\n        score = sia.polarity_scores(word)\n        scores.append(score['compound'])\n    res = sum(scores) \/ len(scores)\n    return res\n\ndf['sentiment_rating'] = df['headline'].apply(lambda x: get_scores(x))","149af58d":"sns.boxplot(y='sentiment_rating', x='is_sarcastic', hue=\"is_sarcastic\", palette=\"GnBu_d\", data=df)","e0ef65a4":"def parser(x):\n    x = re.sub('[^a-z\\s]', '', x.lower())      \n    x = [w for w in x.split() if w not in set(stop_words)]\n    x = [w for w in x if wordnet.synsets(w)]\n    return ' '.join(x)\n\ndf['headline'] = df.headline.apply(lambda x: parser(x))","d3125663":"X = df.drop('is_sarcastic', axis=1)\ny = df.is_sarcastic\nX_train, X_test, y_train, y_test = train_test_split(X, y)","f969b189":"X_train = X_train['headline']\nX_test = X_test['headline']","58e0999b":"cv = CountVectorizer(ngram_range=(1,3))\ncv_train = cv.fit_transform(X_train)\ncv_test = cv.transform(X_test)\n\nprint(cv_train.shape)\nprint(cv_test.shape)","21191fce":"tv = TfidfVectorizer(ngram_range=(1,3))\ntv_train = tv.fit_transform(X_train)\ntv_test = tv.transform(X_test)\n\nprint(tv_train.shape)\nprint(tv_test.shape)","dfca89c9":"nb = MultinomialNB()\n\nnb_bow_cv = nb.fit(cv_train, y_train)\nnb_bow_tv = nb.fit(tv_train, y_train)","05f00a24":"nb_cv_predict = nb_bow_cv.predict(cv_test)\nnb_tv_predict = nb_bow_tv.predict(tv_test)","6041dcce":"nb_cv_score = accuracy_score(y_test, nb_cv_predict)\nnb_tv_score = accuracy_score(y_test, nb_tv_predict)\nprint(nb_cv_score, nb_tv_score)","6d8cd8a8":"cm_cv = confusion_matrix(y_test,nb_cv_predict)\ncm_tv = confusion_matrix(y_test, nb_tv_predict)","b1f547b6":"df_cv = pd.DataFrame(cm_cv)\ndf_tv = pd.DataFrame(cm_tv)\n\nsns.heatmap(cm_cv, cmap='Blues',annot = True, fmt='')","86a7f455":"sns.heatmap(cm_tv, cmap='Blues',annot = True, fmt='')","97f10c11":"df_samp = df.sample(n=2000)\nX_train_samp, X_test_samp, y_train_samp, y_test_samp = train_test_split(df_samp.drop('is_sarcastic', axis=1), df_samp.is_sarcastic)\n\ncv = CountVectorizer(ngram_range=(1,3))\ncv_train_samp = cv.fit_transform(X_train_samp.headline)\ncv_test_samp = cv.transform(X_test_samp.headline)\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import SGDClassifier\n\nparameters = { 'loss': ('hinge', 'log', 'modified_huber'), 'penalty': ('l1', 'l2', 'elasticnet',), 'alpha': [0.0001, 0.001, 0.01, 0.1, 1]}\n\nsgd = SGDClassifier()\nclf = GridSearchCV(sgd, parameters)\nclf.fit(cv_train_samp, y_train_samp)","aa630612":"print(clf.best_estimator_, clf.best_score_, clf.best_params_)","48306561":"from gensim.models import Doc2Vec\nimport gensim\nfrom gensim.models.doc2vec import TaggedDocument","dfcd7abc":"model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\nmodel_dbow.build_vocab([x for x in tqdm(all_data)])\n\nfor epoch in range(30):\n    model_dbow.train(utils.shuffle([x for x in tqdm(all_data)]), total_examples=len(all_data), epochs=1)\n    model_dbow.alpha -= 0.002\n    model_dbow.min_alpha = model_dbow.alpha","332b369a":"## Overview\n\n**This data set is a collection of headlines from 2 sources - The Onion and The Huffington Post - the former being an exclusively satirical publication and the latter being a mixture of both satire and serious pieces.\nEach headline contains headlines as strings of between 10 and 15 words of which there are just shy of 27000 data points. The aim is to classify each of these headlines as either sarcastic or serious.**","d23dbf14":"Unfortunately, not a lot of information can be gleaned from this comparison. Both sarcastic and serious headlines seem to use basically the same stopwords to convey meaning, be it 'straight-up' or satirised.","d808ed22":"## Doc To Vec","e7cfde70":"We see that the topics of Donald Trump and to a lesser extent Obama feature heavily in the satirical class, which makes sense given how popular political figures as targets of satire in the US. This is contrasted by the more neutral language, like 'new' and 'men' of the non-sarcastic class. Note that the noun 'women' and the name 'Obama' (but not Trump) also features notably in serious headlines.","4feef41d":"## The Model\nWe will try both Multinomial Bayes and and SVM to classify our cleaned text data. ","b001d713":"## Getting Started\nLet's begin by getting a general overview of the data set. Luckily, the classes are pretty well balanced and NANs nowhere to be found. ","eb79841f":"There appears to be some albeit mild discrepancy between the classes regarding length of headlines, with serious headlines tending to be more of similar length, whereas the longest and shortest headlines tending to be satirical.","5eb46735":"## Stopwords\nStopwords are common grammatical words that provide structure to a phrase or sentence but are considered, against there ubiquitousness, to contribute relatively little to the overall meaning of the sentence, when compared to, say, proper nouns or verbs.","7f6e5ffa":"## What is this Sarcasm?\nCambridge defines sarcasm as \"the use of remarks that clearly mean the opposite of what they say, made in order to hurt someone's feelings or to criticize something in a humorous way\". \n\nWith this in mind and considering that sarcasm and irony often hinge on flipped or unexpected meanings. This in turn can sometimes hinge on the use of auxiliary or modal verbs (should, can, would etc.) and untypical negations, using \"not\" or a negated auxiliary \/ modal with \"-n't\". \n\nThus, rather than overzealously ejecting all stopwords words from the set, we will first take a look at whether certain selected stopwords are more common in sarcastic sentences as opposed to serious or genuine ones, allowing us potentially to pass a modified list to the count vectorizer.\n\nThe following list is curated a set of stopwords from NLTK.","e6c3345d":"## Vectorize the headlines\nWe will use 2 different vectorizers - CountVectorizer and tf-idf - and see how they perform on the headlines texts.","fd2ada21":"<img src=\"https:\/\/i.pinimg.com\/originals\/58\/dc\/13\/58dc13f9a1f54fea6427171ef3fff423.jpg\"\n     alt=\"bla\"\n     style=\"width: 400px\" \/>","585d4274":"## Parsing the text data before tokenisation\nLet's now parse our data removing stopwords and non-alpha-numeric characters and wordss congtaining them from the headlines.","edbe30ea":"## Topics\nGiven that stopwords provided little joy, let's take a look at the kinds of NON-stopwords that appear in both sarcastic and non-sarcastic headlines which should help us to answer the question as to whether certain topics are more ripe for satire than others, as such, whether our classifier should be on the lookout if certain word combinations (and hence topic combinations) appear. \n\nThis list should include nouns, proper nouns and verbs among lesser ocurring words types, which will represent using a word cloud.","e0816b64":"## \"The Highest form of Wit\"\nOr so claimed by Oscar Wild. However, was he right? Let's compare the length of sarcastic and serious headlines. "}}