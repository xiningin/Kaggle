{"cell_type":{"eeb159d8":"code","c4c8423d":"code","936b8c81":"code","010898cf":"code","1619c4ae":"code","15cacdd9":"code","6916d83a":"code","ad4651f9":"code","b1aba5dd":"code","72e705cf":"code","655db3e7":"code","80e5ec23":"code","d579b0fe":"code","01a514d3":"code","c9f82de9":"code","3db68c69":"code","86de3afe":"code","664c10d6":"code","105b2615":"code","83250d46":"code","ef5094cf":"code","529b371a":"code","e4f790e1":"code","a87156d8":"code","6f29d514":"code","6f6574c0":"code","1b6cf908":"code","c13d15bb":"code","4fd68e03":"code","8fe570a1":"code","6c0c61d8":"code","a8da5ae6":"code","a7716b61":"code","b6ff0500":"code","47152c81":"code","163056f5":"code","5fd02a37":"code","884e6e6d":"code","b3942797":"code","aeb3e685":"code","9c19f4cf":"code","4f458549":"code","ca9f43fc":"code","a2a98b44":"code","dc819e5a":"code","e3322ab2":"code","01683e0a":"code","ef11ae52":"code","f9660927":"code","c74a5823":"code","22e8c9a1":"code","5f485e98":"code","f9513205":"code","5b4af8ee":"markdown","92e178a0":"markdown","27f53705":"markdown","baa8e3ab":"markdown","399fd8d9":"markdown","d68ea757":"markdown","e1a97fea":"markdown","9186348c":"markdown","a95706df":"markdown","bcf265a7":"markdown","5a63b57b":"markdown","8c2e9e98":"markdown","53c8870d":"markdown","56781b8a":"markdown","07f2e44d":"markdown","d8b82781":"markdown","b5b8c784":"markdown","15b98233":"markdown","c18dde33":"markdown","a65f2822":"markdown","7b1c18c0":"markdown","c90aa04d":"markdown","5960315a":"markdown","dc435008":"markdown","435db9f4":"markdown","811ccf30":"markdown"},"source":{"eeb159d8":"import plotly.express as px\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\nimport pandas as pd\nimport numpy as np\n\ncnf, dth, rec, act = '#393e46', '#ff2e63', '#21bf73', '#fe9801' \n\n\nfull_grouped = pd.read_csv('..\/input\/corona-virus-report\/full_grouped.csv')\nfull_grouped['Date'] = pd.to_datetime(full_grouped['Date'])\n\n\nday_wise = pd.read_csv('..\/input\/corona-virus-report\/day_wise.csv')\nday_wise['Date'] = pd.to_datetime(day_wise['Date'])\n\n\ncountry_wise = pd.read_csv('..\/input\/corona-virus-report\/country_wise_latest.csv')\ncountry_wise = country_wise.replace('', np.nan).fillna(0)\n# country_wise.head()","c4c8423d":"worldometer_data = pd.read_csv('..\/input\/worldometer-stats\/wworldometer.csv')\nworldometer_data = worldometer_data.replace('', np.nan).fillna(0)","936b8c81":"temp = day_wise[['Date','Deaths', 'Recovered', 'Active']].tail(1)\ntemp = temp.melt(id_vars=\"Date\", value_vars=['Active', 'Deaths', 'Recovered'])\nfig = px.treemap(temp, path=[\"variable\"], values=\"value\", height=225, \n                 color_discrete_sequence=[act, rec, dth])\nfig.data[0].textinfo = 'label+text+value'","010898cf":"def plot_map(df, col, pal):\n    df = df[df[col]>0]\n    fig = px.choropleth(df, locations=\"Country\/Region\", locationmode='country names', \n                  color=col, hover_name=\"Country\/Region\", \n                  title=col, hover_data=[col], color_continuous_scale=pal)\n    fig.show()\nplot_map(country_wise, 'Confirmed', 'matter')","1619c4ae":"from IPython.display import YouTubeVideo\nYouTubeVideo('i0ZabxXmH4Y', width=700, height=450)","15cacdd9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set()\nimport numpy as np # linear algebra\n # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import  Input, Conv2D, MaxPooling2D,GlobalMaxPooling2D, Flatten, Dense, GlobalAveragePooling2D, Activation, MaxPool2D, AvgPool2D, Dropout, Conv1D, MaxPooling1D\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop\nfrom tensorflow.keras.applications import DenseNet121, VGG19, ResNet50\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom IPython.display import display, Image\nimport matplotlib.pyplot as mpimg\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.utils import shuffle\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6916d83a":"train_df = pd.read_csv('..\/input\/coronahack-chest-xraydataset\/Chest_xray_Corona_Metadata.csv')\nvalid_df = pd.read_csv('..\/input\/coronahack-chest-xraydataset\/Chest_xray_Corona_dataset_Summary.csv')\n\nprint('The training dataset has rows : ', format(train_df.shape[0]))\nprint('The training dataset has cols : ', format(train_df.shape[1]))","ad4651f9":"train_df.head(5)","b1aba5dd":"missing_vals = train_df.isnull().sum()\nmissing_vals.plot(kind = 'bar')","72e705cf":"train_df.dropna(how = 'all')\ntrain_df.isnull().sum()","655db3e7":"train_data = train_df[train_df['Dataset_type'] == 'TRAIN']\ntest_data = train_df[train_df['Dataset_type'] == 'TEST']\nassert train_data.shape[0] + test_data.shape[0] == train_df.shape[0]\nprint(f\"Shape of train data : {train_data.shape}\")\nprint(f\"Shape of test data : {test_data.shape}\")\ntest_data.sample(10)","80e5ec23":"train_fill = train_data.fillna('unknown')\ntest_fill = test_data.fillna('unknown')\ndisplay(train_fill.head(5))","d579b0fe":"# Count plot for 3 attributes with unknown variable addition\ntargets = ['Label', 'Label_2_Virus_category', 'Label_1_Virus_category']\nfig, ax = plt.subplots(2, 2, figsize=(20, 10))\nsns.countplot(x=targets[0], data=train_fill, ax=ax[0, 0])\nsns.countplot(x=targets[1], data=train_fill, ax=ax[0, 1])\nsns.countplot(x=targets[2], data=train_fill, ax=ax[1, 0])\nplt.show()","01a514d3":"test_img_dir = '\/kaggle\/input\/coronahack-chest-xraydataset\/Coronahack-Chest-XRay-Dataset\/Coronahack-Chest-XRay-Dataset\/test'\ntrain_img_dir = '\/kaggle\/input\/coronahack-chest-xraydataset\/Coronahack-Chest-XRay-Dataset\/Coronahack-Chest-XRay-Dataset\/train'\n\nassert os.path.isdir(test_img_dir) == True\nassert os.path.isdir(train_img_dir) == True\n\nsample_train_images = list(os.walk(train_img_dir))[0][2][:8]\nsample_train_images = list(map(lambda x: os.path.join(train_img_dir, x), sample_train_images))\n\nsample_test_images = list(os.walk(test_img_dir))[0][2][:8]\nsample_test_images = list(map(lambda x: os.path.join(test_img_dir, x), sample_test_images))","c9f82de9":"from PIL import Image\nplt.figure(figsize = (17,17))\nfor iterator, filename in enumerate(sample_train_images):\n    image = Image.open(filename)\n    plt.subplot(4,2,iterator+1)\n    plt.imshow(image)\n\nplt.tight_layout()","3db68c69":"plt.figure(figsize = (17,17))\nfor iterator, filename in enumerate(sample_test_images):\n    image = Image.open(filename)\n    plt.subplot(4,2,iterator+1)\n    plt.imshow(image)\n\nplt.tight_layout()","86de3afe":"fig, ax = plt.subplots(4, 2, figsize=(17, 17))\n\n\ncovid_path = train_data[train_data['Label_2_Virus_category']=='COVID-19']['X_ray_image_name'].values\n\nsample_covid_path = covid_path[:4]\nsample_covid_path = list(map(lambda x: os.path.join(train_img_dir, x), sample_covid_path))\n\nfor row, file in enumerate(sample_covid_path):\n    image = plt.imread(file)\n    ax[row, 0].imshow(image)\n    ax[row, 1].hist(image.ravel(), 256, [0,256])\n    ax[row, 0].axis('off')\n    if row == 0:\n        ax[row, 0].set_title('Images')\n        ax[row, 1].set_title('Histograms')\nfig.suptitle('Label 2 Virus Category = COVID-19', size=16)\nplt.show()","664c10d6":"fig, ax = plt.subplots(4, 2, figsize=(17, 17))\n\n\nnormal_path = train_data[train_data['Label']=='Normal']['X_ray_image_name'].values\n\nsample_normal_path = normal_path[:4]\nsample_normal_path = list(map(lambda x: os.path.join(train_img_dir, x), sample_normal_path))\n\nfor row, file in enumerate(sample_normal_path):\n    image = plt.imread(file)\n    ax[row, 0].imshow(image)\n    ax[row, 1].hist(image.ravel(), 256, [0,256])\n    ax[row, 0].axis('off')\n    if row == 0:\n        ax[row, 0].set_title('Images')\n        ax[row, 1].set_title('Histograms')\nfig.suptitle('Label = NORMAL', size=16)\nplt.show()","105b2615":"final_train_data = train_data[(train_data['Label'] == 'Normal') | \n                              ((train_data['Label'] == 'Pnemonia') & (train_data['Label_2_Virus_category'] == 'COVID-19'))]\n\n\n# Create a target attribute where value = positive if 'Pnemonia + COVID-19' or value = negative if 'Normal'\nfinal_train_data['target'] = ['negative' if holder == 'Normal' else 'positive' for holder in final_train_data['Label']]\n\nfinal_train_data = shuffle(final_train_data, random_state=1)\n\nfinal_validation_data = final_train_data.iloc[1000:, :]\nfinal_train_data = final_train_data.iloc[:1000, :]\n\nprint(f\"Final train data shape : {final_train_data.shape}\")\nfinal_train_data.sample(10)","83250d46":"train_image_generator = ImageDataGenerator(\n    rescale=1.\/255,\n    rotation_range=90,\n    width_shift_range=0.15,\n    height_shift_range=0.15,\n    horizontal_flip=True,\n    zoom_range=0.5,\n)\n\ntest_image_generator = ImageDataGenerator(\n    rescale=1.\/255\n)\n\ntrain_generator = train_image_generator.flow_from_dataframe(\n    dataframe=final_train_data,\n    directory=train_img_dir,\n    x_col='X_ray_image_name',\n    y_col='target',\n    target_size=(224, 224),\n    batch_size=16,\n    seed=2020,\n    shuffle=True,\n    class_mode='binary'\n)\n\nvalidation_generator = train_image_generator.flow_from_dataframe(\n    dataframe=final_validation_data,\n    directory=train_img_dir,\n    x_col='X_ray_image_name',\n    y_col='target',\n    target_size=(224, 224),\n    batch_size=16,\n    seed=2020,\n    shuffle=True,\n    class_mode='binary'\n)\n\ntest_generator = test_image_generator.flow_from_dataframe(\n    dataframe=test_data,\n    directory=test_img_dir,\n    x_col='X_ray_image_name',\n    target_size=(224, 224),\n    shuffle=False,\n    batch_size=16,\n    class_mode=None)","ef5094cf":"IMG_W = 224\nIMG_H = 224\nCHANNELS = 3\n\nINPUT_SHAPE = (IMG_W, IMG_H, CHANNELS)\nNB_CLASSES = 2\nEPOCHS = 30\nBATCH_SIZE = 6","529b371a":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), input_shape=INPUT_SHAPE))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n\nmodel.add(Conv2D(64,(3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(Conv2D(250,(3,3)))\nmodel.add(Activation(\"relu\"))\n  \nmodel.add(Conv2D(128,(3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(AvgPool2D(2,2))\nmodel.add(Conv2D(64,(3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(AvgPool2D(2,2))\n\nmodel.add(Conv2D(256,(2,2)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPool2D(2,2))\n    \nmodel.add(Flatten())\nmodel.add(Dense(32))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(1))\nmodel.add(Activation(\"sigmoid\"))","e4f790e1":"model.summary()","a87156d8":"class myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('accuracy')>0.9325):\n            print(\"\\nReached 94.25% accuracy so cancelling training!\")\n            self.model.stop_training = True\ncallbacks = myCallback()","6f29d514":"#callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)","6f6574c0":"model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\nhistory = model.fit(train_generator,\n                              steps_per_epoch = len(train_generator),\n                              validation_data=validation_generator,\n                              epochs=20,\n                              validation_steps=len(validation_generator),\n                              callbacks = [callbacks]\n                                     )","1b6cf908":"plt.figure(figsize=(17,17))\nplt.subplot(2, 2, 1)\nplt.plot(history.history['loss'], label='Loss')\nplt.legend()\nplt.title('Training - Loss Function')\n\nplt.subplot(2, 2, 2)\nplt.plot(history.history['accuracy'], label='Accuracy')\nplt.legend()\nplt.title('Train - Accuracy')\n\nplt.legend()\nplt.title('Metrics estimations')\n","c13d15bb":"dense_model = Sequential()\ndense_model.add(DenseNet121(include_top=False, pooling = 'avg', weights='imagenet',input_shape=(224, 224, 3), classes=2))\ndense_model.add(Dense(512, activation='relu'))\ndense_model.add(Dense(128, activation='relu'))\ndense_model.add(Dense(64, activation='relu'))\ndense_model.add(Dense(1, activation='sigmoid'))\ndense_model.layers[0].trainable = False\ndense_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","4fd68e03":"callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2)","8fe570a1":"dense_history = dense_model.fit_generator(train_generator,\n                                          steps_per_epoch = len(train_generator),\n                                          validation_data=validation_generator,\n                                          epochs=20,\n                                          validation_steps=len(validation_generator),\n                                          callbacks = [callbacks]\n                                             )","6c0c61d8":"plt.figure(figsize=(17,17))\n\nplt.subplot(2, 2, 1)\nplt.plot(dense_history.history['loss'], label='Loss')\nplt.plot(dense_history.history['val_loss'], label='Validation Loss')\nplt.legend()\nplt.title('Training - Loss Function')\n\nplt.subplot(2, 2, 2)\nplt.plot(dense_history.history['accuracy'], label='Accuracy')\nplt.plot(dense_history.history['val_accuracy'], label='Validation Accuracy')\n\nplt.legend()\nplt.title('Train - Accuracy')","a8da5ae6":"mob_model = Sequential()\nmob_model.add(tf.keras.applications.MobileNetV2(include_top=False, pooling = 'avg', weights='imagenet',input_shape=(224, 224, 3), classes=2))\nmob_model.add(Dense(32, activation='relu'))\nmob_model.add(Dense(1, activation='sigmoid'))\nmob_model.layers[0].trainable = False\nmob_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","a7716b61":"mob_history = mob_model.fit_generator(train_generator,\n                              steps_per_epoch = len(train_generator),\n                              validation_data=validation_generator,\n                              epochs=20,\n                              validation_steps=len(validation_generator),\n                              callbacks = [callbacks]\n                                     )","b6ff0500":"plt.figure(figsize=(17,17))\n\nplt.subplot(2, 2, 1)\nplt.plot(mob_history.history['loss'], label='Loss')\nplt.plot(mob_history.history['loss'], label='Validation Loss')\n\nplt.legend()\nplt.title('Training - Loss Function')\n\nplt.subplot(2, 2, 2)\nplt.plot(mob_history.history['accuracy'], label='Accuracy')\nplt.plot(mob_history.history['val_accuracy'], label='Validation Accuracy')\n\n\nplt.legend()\nplt.title('Train - Accuracy')","47152c81":"model.predict(validation_generator)","163056f5":"dense_model.predict(validation_generator)","5fd02a37":"mob_model.predict(validation_generator)","884e6e6d":"label = validation_generator.classes\nprint('Cases summary of the models : \\n{}'.format(label))","b3942797":"pred= model.predict(validation_generator)\npredicted_class_indices=np.argmax(pred,axis=1)\nlabels = (validation_generator.class_indices)\nlabels2 = dict((v,k) for k,v in labels.items())\npredictions = [labels2[k] for k in predicted_class_indices]","aeb3e685":"print('CNN Model Predictions : \\n{}'.format(predictions))","9c19f4cf":"from sklearn.metrics import confusion_matrix, classification_report\n\ncf_matrix = confusion_matrix(predicted_class_indices,label)\ncf_matrix","4f458549":"exp_series = pd.Series(label)\npred_series = pd.Series(predicted_class_indices)\npd.crosstab(exp_series, pred_series, rownames=['Actual'], colnames=['Predicted'],margins=True)","ca9f43fc":"import seaborn as sns\n\nmatrix_index = [\"Normal\", \"Covid\"]\n\npreds = model.predict(validation_generator)\nclasspreds = np.argmax(preds, axis=1) # predicted classes \n#y_testclass = np.argmax(valida, axis=1) # true classes\n\ncm = confusion_matrix(predicted_class_indices,label)\nprint(classification_report(predicted_class_indices,label, target_names=matrix_index))\n\n# Get percentage value for each element of the matrix\ncm_sum = np.sum(cm, axis=1, keepdims=True)\ncm_perc = cm \/ cm_sum.astype(float) * 100\nannot = np.empty_like(cm).astype(str)\nnrows, ncols = cm.shape\nfor i in range(nrows):\n    for j in range(ncols):\n        c = cm[i, j]\n        p = cm_perc[i, j]\n        if i == j:\n            s = cm_sum[i]\n            annot[i, j] = '%.1f%%\\n%d\/%d' % (p, c, s)\n        elif c == 0:\n            annot[i, j] = ''\n        else:\n            annot[i, j] = '%.1f%%\\n%d' % (p, c)\n\n\n# Display confusion matrix \ndf_cm = pd.DataFrame(cm, index = matrix_index, columns = matrix_index)\ndf_cm.index.name = 'Actual'\ndf_cm.columns.name = 'Predicted'\nfig, ax = plt.subplots(figsize=(10,7))\nsns.heatmap(df_cm, annot=annot, fmt='')","a2a98b44":"pred= dense_model.predict(validation_generator)\npredicted_class_indices=np.argmax(pred,axis=1)\nlabels = (validation_generator.class_indices)\nlabels2 = dict((v,k) for k,v in labels.items())\npredictions = [labels2[k] for k in predicted_class_indices]","dc819e5a":"print('DenseNet Model Predictions : \\n{}'.format(predictions))","e3322ab2":"cf_matrix = confusion_matrix(predicted_class_indices,label)\ncf_matrix","01683e0a":"exp_series = pd.Series(label)\npred_series = pd.Series(predicted_class_indices)\npd.crosstab(exp_series, pred_series, rownames=['Actual'], colnames=['Predicted'],margins=True)","ef11ae52":"matrix_index = [\"Normal\", \"Covid\"]\n\npreds = dense_model.predict(validation_generator)\nclasspreds = np.argmax(preds, axis=1) # predicted classes \n#y_testclass = np.argmax(valida, axis=1) # true classes\n\ncm = confusion_matrix(predicted_class_indices,label)\nprint(classification_report(predicted_class_indices,label, target_names=matrix_index))\n\n# Get percentage value for each element of the matrix\ncm_sum = np.sum(cm, axis=1, keepdims=True)\ncm_perc = cm \/ cm_sum.astype(float) * 100\nannot = np.empty_like(cm).astype(str)\nnrows, ncols = cm.shape\nfor i in range(nrows):\n    for j in range(ncols):\n        c = cm[i, j]\n        p = cm_perc[i, j]\n        if i == j:\n            s = cm_sum[i]\n            annot[i, j] = '%.1f%%\\n%d\/%d' % (p, c, s)\n        elif c == 0:\n            annot[i, j] = ''\n        else:\n            annot[i, j] = '%.1f%%\\n%d' % (p, c)\n\n\n# Display confusion matrix \ndf_cm = pd.DataFrame(cm, index = matrix_index, columns = matrix_index)\ndf_cm.index.name = 'Actual'\ndf_cm.columns.name = 'Predicted'\nfig, ax = plt.subplots(figsize=(10,7))\nsns.heatmap(df_cm, annot=annot, fmt='')","f9660927":"pred= mob_model.predict(validation_generator)\npredicted_class_indices=np.argmax(pred,axis=1)\nlabels = (validation_generator.class_indices)\nlabels2 = dict((v,k) for k,v in labels.items())\npredictions = [labels2[k] for k in predicted_class_indices]","c74a5823":"print('MobileNet Model Predictions : \\n{}'.format(predictions))","22e8c9a1":"cf_matrix = confusion_matrix(predicted_class_indices,label)\ncf_matrix","5f485e98":"exp_series = pd.Series(label)\npred_series = pd.Series(predicted_class_indices)\npd.crosstab(exp_series, pred_series, rownames=['Actual'], colnames=['Predicted'],margins=True)","f9513205":"matrix_index = [\"Normal\", \"Covid\" ]\n\npreds = mob_model.predict(validation_generator)\nclasspreds = np.argmax(preds, axis=1) # predicted classes \n#y_testclass = np.argmax(valida, axis=1) # true classes\n\ncm = confusion_matrix(predicted_class_indices,label)\nprint(classification_report(predicted_class_indices,label, target_names=matrix_index))\n\n# Get percentage value for each element of the matrix\ncm_sum = np.sum(cm, axis=1, keepdims=True)\ncm_perc = cm \/ cm_sum.astype(float) * 100\nannot = np.empty_like(cm).astype(str)\nnrows, ncols = cm.shape\nfor i in range(nrows):\n    for j in range(ncols):\n        c = cm[i, j]\n        p = cm_perc[i, j]\n        if i == j:\n            s = cm_sum[i]\n            annot[i, j] = '%.1f%%\\n%d\/%d' % (p, c, s)\n        elif c == 0:\n            annot[i, j] = ''\n        else:\n            annot[i, j] = '%.1f%%\\n%d' % (p, c)\n\n\n# Display confusion matrix \ndf_cm = pd.DataFrame(cm, index = matrix_index, columns = matrix_index)\ndf_cm.index.name = 'Actual'\ndf_cm.columns.name = 'Predicted'\nfig, ax = plt.subplots(figsize=(10,7))\nsns.heatmap(df_cm, annot=annot, fmt='')","5b4af8ee":"# 8. References\nThanks to some amazing notebooks I was able to learn how to display images in an orderly fashion and was able to apply transfer learning CNN in COVID related applications.\n1. https:\/\/www.kaggle.com\/adityam1311\/covid-19-x-ray-images-eda-models\/notebook\n2. https:\/\/www.kaggle.com\/eswarchandt\/covid-19-detection-from-lung-x-rays","92e178a0":"**For COVID-19 cases**","27f53705":"# MobileNetV2","baa8e3ab":"# COVID-19 Pandemic\n\n![](https:\/\/www.statnews.com\/wp-content\/uploads\/2020\/02\/Coronavirus-CDC-645x645.jpg)\n\nSource = https:\/\/www.statnews.com\/wp-content\/uploads\/2020\/02\/Coronavirus-CDC-645x645.jpg\n","399fd8d9":"# 1. Loading Datasets","d68ea757":"# 6.2 Transfer Learning","e1a97fea":"# Load the libraries","9186348c":"***Normal:- 0, COVID:- 1***","a95706df":"# 4.1 Histogram analysis of Images","bcf265a7":"# DenseNet121","5a63b57b":"# 3. Visualization of Unknown Data","8c2e9e98":"# MobileNet predictions","53c8870d":"# 6.1 Convolutional Neural Network","56781b8a":"# COVID-19 Pandemic World Map\n\nref : https:\/\/www.kaggle.com\/imdevskp\/covid-19-analysis-visualization-comparisons","07f2e44d":"# CNN predictions","d8b82781":"# 4. Display Images","b5b8c784":"# DenseNet predictions","15b98233":"# Updates\nVERSION-16\n1. Images displayed with labels and Histogram plots\n2. CNN model developed with accuracy and loss plot\n3. initiation of callbacks for the above models\n4. DenseNet121 simplified \n5. Mobilenet_V2\n6. Predictions ","c18dde33":"Let's fill the missing values with 'unknown'","a65f2822":"**Normal Histogram images**","7b1c18c0":"# 5. Image Augmentation","c90aa04d":"# 6. Model Development","5960315a":"Displaying test images","dc435008":"**Plots to estimate loss and accuracy**","435db9f4":"# 2. Missing Values","811ccf30":"# Beginners Intro to Coronavirus"}}