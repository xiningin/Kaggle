{"cell_type":{"54f7869f":"code","d743c6cd":"code","747537ad":"code","139b5c4f":"code","96b0b5be":"code","0550b017":"code","87610b19":"code","4b8b6489":"code","bfef651d":"code","0f953a63":"code","242f55b6":"code","372c2054":"code","3f1da68a":"code","b93c643a":"code","dbdfd461":"code","d050a07e":"code","e00583f5":"code","c9d7b1f9":"code","1490c217":"code","41e2f111":"code","b6187c74":"code","147a699c":"code","88372aae":"code","e29f3f20":"code","95e4581e":"code","8c658b5f":"markdown","15e97b02":"markdown","2fd2b9c5":"markdown","988ed17e":"markdown","c1856881":"markdown","5827837f":"markdown","fe3f04a8":"markdown","0c7bf8a1":"markdown","152e137d":"markdown","cf7300e7":"markdown","eba75e76":"markdown","161329fa":"markdown","dbdaeadb":"markdown","b0e2389e":"markdown","efcba9a7":"markdown","e44c6878":"markdown","6d010b34":"markdown","6e42d9ff":"markdown","2f28e59a":"markdown","95155ff6":"markdown"},"source":{"54f7869f":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d743c6cd":"#load training data\ntraindf=pd.read_csv('..\/input\/tweets-mec-task-e-c-preprocessing\/cleaned_training_tweets.csv',encoding='utf-8',sep=\",\")\ndevdf=pd.read_csv('..\/input\/tweets-mec-task-e-c-preprocessing\/cleaned_develop_tweets.csv',encoding='utf-8',sep=\",\")\ntestdf=pd.read_csv('..\/input\/tweets-mec-task-e-c-preprocessing\/cleaned_testing_tweets.csv',encoding='utf-8',sep=\",\")\ntraindf.head(10)","747537ad":"#import libraries\nimport re\nimport nltk\nfrom nltk import FreqDist\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud","139b5c4f":"#initiate lists of emotions and frequency distribution\nem=[\"anger\",\"anticipation\",\"disgust\",\"fear\",\"joy\",\"love\",\"optimism\",\"pessimism\",\"sadness\",\"surprise\",\"trust\"]\nuni_lst,bi_lst=[],[]","96b0b5be":"#compute unigram frequency distribution\ndef uni_freq(x):\n    tmp=' '.join(traindf[traindf[x]==1][\"clean\"])\n    tmp=re.sub('\\n','',tmp)\n    return FreqDist(nltk.word_tokenize(tmp))\n\n#compute bigram frequency distribution\ndef bi_freq(x):\n    tmp=' '.join(traindf[traindf[x]==1][\"clean\"])\n    tmp=re.sub('\\n','',tmp)\n    tmp_bi=nltk.bigrams(nltk.word_tokenize(tmp))\n    return FreqDist(tmp_bi)","0550b017":"#iterate over emotions \nfor x in em:\n    uni_lst.append(uni_freq(x))\n    bi_lst.append(bi_freq(x))","87610b19":"#function of display word cloud\ndef display_wrd_cloud(lst,i):\n    wc = WordCloud(width=800, height=400, max_words=100).generate_from_frequencies(lst)\n    plt.subplot(6,2,i)\n    plt.imshow(wc, interpolation=\"bilinear\")\n    plt.title(em[i-1])\n    plt.axis(\"off\")\n    ","4b8b6489":"plt.subplots(6, 2,figsize=(15,25))\n\n#WordCloud of emotions\nfor i,x in enumerate(em):\n    display_wrd_cloud(uni_lst[i],i+1)\n\nplt.subplot(6,2,12)\nplt.axis(\"off\")\n\nplt.show()","bfef651d":"#define fuction to plot maximum 20 tokens\ndef plt_freq(rows,cols,lst,i):\n    plt.subplot(rows,cols,i)\n    wrd,lbl=zip(*lst)\n    try:\n        wrd=[x+\",\"+y for (x,y) in wrd]\n        plt.barh(wrd,lbl)\n    except:\n        plt.barh(wrd,lbl)\n    plt.title(em[i-1])","0f953a63":"#plot highest common 20 tokens in each emotion\nrows=6\ncols=2\nplt.subplots(rows, cols,figsize=(15,25))\nfor i,x in enumerate(em):\n    plt_freq(rows,cols,uni_lst[i].most_common(20),i+1)\n\nplt.subplot(rows,cols,12)\nplt.axis(\"off\")\nplt.show()\n","242f55b6":"#plot highest common 10 bi-grams in each emotion\nrows,cols=11,1\nplt.subplots(rows, cols,figsize=(15,30))\nfor i,x in enumerate(em):\n    plt_freq(rows,cols,bi_lst[i].most_common(10),i+1)\n\nplt.show()\n","372c2054":"#intersections between each unigram frequency two emotions\nintersections=dict({})\nfor i,val1 in enumerate(uni_lst):\n    for j,val2 in enumerate(uni_lst):\n        if (j>i):\n            lbl=em[i]+\" & \"+em[j]\n            intersect=len(set(val1.keys()).intersection(set(val2.keys())))\n            print (lbl,\":\",intersect)\n            intersections[lbl]=intersect","3f1da68a":"#plot bar graph to visualize intersections between each two emotions\nplt.figure(figsize=(15,15))\nplt.barh(list(intersections.keys()),list(intersections.values()))","b93c643a":"#intersections between each bigram frequency two emotions\nbi_intersections=dict({})\nfor i,val1 in enumerate(bi_lst):\n    for j,val2 in enumerate(bi_lst):\n        if (j>i):\n            lbl=em[i]+\" & \"+em[j]\n            intersect=len(set(val1.keys()).intersection(set(val2.keys())))\n            print (lbl,\":\",intersect)\n            bi_intersections[lbl]=intersect","dbdfd461":"#plot bar graph to visualize intersections between each two emotions\nplt.figure(figsize=(15,15))\nplt.barh(list(bi_intersections.keys()),list(bi_intersections.values()))","d050a07e":"#compute average frequency distribution of tweet to each emotion for both unigram and bigram (Training)\nfor i,e in enumerate(em):\n    traindf[\"freq_\"+e]=traindf[\"clean\"].apply(lambda x: sum([uni_lst[i].get(wrd)\/len(uni_lst[i].keys()) if uni_lst[i].get(wrd)!=None else 0 for wrd in nltk.word_tokenize(x)]))\n    traindf[\"bi_\"+e]=traindf[\"clean\"].apply(lambda x: sum([bi_lst[i].get(tpl)\/len(bi_lst[i].keys()) if bi_lst[i].get(tpl)!=None else 0 for tpl in nltk.bigrams(nltk.word_tokenize(x))]))\n\n#compute average frequency distribution of tweet to each emotion for both unigram and bigram (develop)\nfor i,e in enumerate(em):\n    devdf[\"freq_\"+e]=devdf[\"clean\"].apply(lambda x: sum([uni_lst[i].get(wrd)\/len(uni_lst[i].keys()) if uni_lst[i].get(wrd)!=None else 0 for wrd in nltk.word_tokenize(x)]))\n    devdf[\"bi_\"+e]=devdf[\"clean\"].apply(lambda x: sum([bi_lst[i].get(tpl)\/len(bi_lst[i].keys()) if bi_lst[i].get(tpl)!=None else 0 for tpl in nltk.bigrams(nltk.word_tokenize(x))]))\n    \n#compute average frequency distribution of tweet to each emotion for both unigram and bigram (testing)\nfor i,e in enumerate(em):\n    testdf[\"freq_\"+e]=testdf[\"clean\"].apply(lambda x: sum([uni_lst[i].get(wrd)\/len(uni_lst[i].keys()) if uni_lst[i].get(wrd)!=None else 0 for wrd in nltk.word_tokenize(x)]))\n    testdf[\"bi_\"+e]=testdf[\"clean\"].apply(lambda x: sum([bi_lst[i].get(tpl)\/len(bi_lst[i].keys()) if bi_lst[i].get(tpl)!=None else 0 for tpl in nltk.bigrams(nltk.word_tokenize(x))]))\n","e00583f5":"#visualize unigram frequency distribution of tweets classified into two emotions\n#blue displays common tweets\ndef display_related_freq(em1,em2,rows,cols,i):\n    plt.subplot(rows,cols,i)\n    \n    plt.scatter(traindf[(traindf[em1]==1) & (traindf[em2]==0)][\"freq_\"+em1],traindf[(traindf[em1]==1) & (traindf[em2]==0)][\"freq_\"+em2],color='g')\n    plt.scatter(traindf[(traindf[em1]==0) & (traindf[em2]==1)][\"freq_\"+em1],traindf[(traindf[em1]==0) & (traindf[em2]==1)][\"freq_\"+em2],color='r')\n    plt.scatter(traindf[(traindf[em1]==1) & (traindf[em2]==1)][\"freq_\"+em1],traindf[(traindf[em1]==1) & (traindf[em2]==1)][\"freq_\"+em2],color='b')\n    plt.legend([ em1, em2, em1+\" & \"+em2 ])\n    plt.ylim([0,0.1])\n","c9d7b1f9":"rows,cols=28,2\nplt.subplots(rows, cols,figsize=(15,45))\nz=1\nfor i,e1 in enumerate(em):\n    for j,e2 in enumerate(em):\n        if(j>i):\n            display_related_freq(e1,e2,rows,cols,z)\n            z=z+1\nplt.subplot(rows,cols,56)\nplt.axis(\"off\")\nplt.show()","1490c217":"#visualize bigram frequency distribution of tweets classified into two emotions\n#blue displays common tweets\ndef display_related_bi(em1,em2,rows,cols,i):\n    plt.subplot(rows,cols,i)\n    plt.scatter(traindf[(traindf[em1]==1) & (traindf[em2]==0)][\"bi_\"+em1],traindf[(traindf[em1]==1) & (traindf[em2]==0)][\"bi_\"+em2],color='g')\n    plt.scatter(traindf[(traindf[em1]==0) & (traindf[em2]==1)][\"bi_\"+em1],traindf[(traindf[em1]==0) & (traindf[em2]==1)][\"bi_\"+em2],color='r')\n    plt.scatter(traindf[(traindf[em1]==1) & (traindf[em2]==1)][\"bi_\"+em1],traindf[(traindf[em1]==1) & (traindf[em2]==1)][\"bi_\"+em2],color='b')\n    plt.legend([em1, em2, em1+\" & \"+em2 ])\n    plt.ylim([0,0.02])\n","41e2f111":"rows,cols=28,2\nplt.subplots(rows, cols,figsize=(15,45))\nz=1\nfor i,e1 in enumerate(em):\n    for j,e2 in enumerate(em):\n        if(j>i):\n            display_related_bi(e1,e2,rows,cols,z)\n            z=z+1\nplt.subplot(rows,cols,56)\nplt.axis(\"off\")\nplt.show()","b6187c74":"#### Quick data exploration\n#distribution plot for frequency distribution for unigrams\nimport seaborn as sns\ndef display_distplot_freq(e,i):\n    ax=sns.distplot(traindf[\"freq_\"+str(e)].values,ax=i)\n    ax.set_title(str(e))\n    \n#repeat to plot frequency distribution \nfig,axes=plt.subplots(6, 2,figsize=(15,20))\nz=0\nfor row in range(0,6):\n    for col in range(0,2):\n        if (z != 11):\n            display_distplot_freq(em[z],axes[row][col])\n            z=z+1\nplt.subplot(6,2,12)\nplt.axis(\"off\")\nplt.show()","147a699c":"#### Quick data exploration\n#box plot for unigram distribution\ndef display_boxplot_freq(e,i):\n    ax=sns.boxplot(traindf[\"freq_\"+str(e)].values,ax=i)\n    ax.set_title(str(e))\n\nfig,axes=plt.subplots(6, 2,figsize=(15,20))\nz=0\nfor row in range(0,6):\n    for col in range(0,2):\n        if (z != 11):\n            display_boxplot_freq(em[z],axes[row][col])\n            z=z+1\nplt.subplot(6,2,12)\nplt.axis(\"off\")\nplt.show()","88372aae":"#### Quick data exploration\n#box plot for bigram distribution\ndef display_boxplot_bigram(e,i):\n    ax=sns.boxplot(traindf[\"bi_\"+str(e)].values,ax=i)\n    ax.set_title(str(e))\n\nfig,axes=plt.subplots(6, 2,figsize=(15,20))\nz=0\nfor row in range(0,6):\n    for col in range(0,2):\n        if (z != 11):\n            display_boxplot_bigram(em[z],axes[row][col])\n            z=z+1\nplt.subplot(6,2,12)\nplt.axis(\"off\")\nplt.show()","e29f3f20":"traindf.head(10)","95e4581e":"#save feature values to csv\ntraindf.to_csv(\"freq_bi_tweets_train.csv\",index=False,encoding=\"utf-8\")\ndevdf.to_csv(\"freq_bi_tweets_dev.csv\",index=False,encoding=\"utf-8\")\ntestdf.to_csv(\"freq_bi_tweets_test.csv\",index=False,encoding=\"utf-8\")","8c658b5f":"Tweets are multi label classified into eleven emotions:\n(anger,anticipation, disgust, fear, joy, love, optimism, pessimism, sadness, surprise, trust)","15e97b02":"# Loading Data","2fd2b9c5":"Analysis:\nFeature extraction is applied to tweets for each emotion space\n* frequency distribution of unigram.\n* frequency distribution of bigrams.\n\nExplanatory analysis applied to feature values to show different relatedness between same vocabularies and tweets to different emotions using word cloud, bar graph, and scatter plot.\nThe most common noticed vocabularies between two emotion spaces \n* anger and disgust\n* anger and sad\n* disgust and sad\n* joy and optimism","988ed17e":"# Word Cloud Explanatory Analysis","c1856881":"# Saving Features in csv","5827837f":"# Intersection between unigrams of each two emotions spaces","fe3f04a8":"# **Feature Extraction**","0c7bf8a1":"# # Data Exploration using distribution & box plot for unigram","152e137d":"This notebook targets converting cleaned tweets into feature vectors, it outlines unigram and bigrams from cleaned tweets in the following steps:\n* Apply unigram for tweets to each emotion class\n* Apply bigram for tweets to each emotion class\n* Use Word cloud for visual explanatory for unigram output to each emotion class\n* Use Bar graph for visual exlanatory for Bigram output to each emotion class\n* Visualize interesection between unigram output for each two emotions\n* Visualize interesection between bigram output for each two emotions\n* Transform Tweets into Unigram and Bigram feature vector\n    * Compute probability of frequency distribution of unigram tokens foreach tweet corresponds each emotion class\n    * Compute probability of frequency distriution of bigram tokens foreach tweet corresponds each emotion class\n* Visualize common tweets labelled between each two emotion classes using computed probability of Unigram using scatter plot\n* Visualize common tweets labelled between each two emotion classes using computed probability of Bigram using scatter plot\n* Visualize computed probability of unigram boxplot and distribution plot for emotion class\n* Visualize computed probability of bigram boxplot and distribution plot for emotion class","cf7300e7":"# Unigram frequency distribution explanatory analysis","eba75e76":"# # Data Exploration using box plot for bigram","161329fa":"* Compute average unigram frequency distribution for each tweet to target each emotion space\n* Compute average bigram frequency distribution for each tweet to target each emotion space","dbdaeadb":"# Final Analysis","b0e2389e":"# Intersection between bigrams between each two emotion spaces","efcba9a7":"# Convert Tweet into Unigram and Bigram Feature Vector","e44c6878":"# Bigram frequency distribution explanatory analysis","6d010b34":"These tweets were previously preprocessed in \nhttps:\/\/www.kaggle.com\/sohaelshafey\/multi-label-classification-tweets-preprocessing","6e42d9ff":"# Visualize relation ship between each two emotion classes for each tweet","2f28e59a":"# Unigram & Bigram Frequency Distribution","95155ff6":"# SemEval2018 TaskE-c Multi emotion tweets."}}