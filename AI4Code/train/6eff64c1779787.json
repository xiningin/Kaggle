{"cell_type":{"9bc07626":"code","d60fae54":"code","e1b9c844":"code","63b61fd4":"code","eab3d1e2":"code","e6ab2152":"code","41417db4":"code","479cb3aa":"code","9565b94e":"code","43fb95d6":"code","a981e094":"code","fde0f35e":"code","e1c9ee17":"code","26fa5010":"code","a1b66c96":"code","5d301729":"code","59496580":"code","807d15c6":"code","1ce6874e":"code","d0ca840a":"code","13213ee5":"markdown","a4d20fed":"markdown","25caf8ab":"markdown","226a8941":"markdown","2732adb0":"markdown","2c691ae2":"markdown","88cd49e2":"markdown","c800f428":"markdown","4697d4ae":"markdown","4d063a86":"markdown","9c776ff9":"markdown","5692ad38":"markdown","94879607":"markdown","3a8b15d8":"markdown","55ad8222":"markdown","023cb310":"markdown"},"source":{"9bc07626":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d60fae54":"#function to create artificial dataset\nfrom sklearn.datasets import make_classification\n# define dataset\nX, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5,n_classes=2, random_state=1)\n# summarize the dataset\nprint(X.shape, y.shape)","e1b9c844":"def get_models():\n    models = dict()\n    models['lr'] = LogisticRegression()\n    models['knn'] = KNeighborsClassifier()\n    models['cart'] = DecisionTreeClassifier()\n    models['svm'] = SVC()\n    models['boost'] = GradientBoostingClassifier()\n    models['forest'] =RandomForestClassifier()\n    return models","63b61fd4":"def evaluate_model(model, X, y):\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n    return scores","eab3d1e2":"from numpy import mean\nfrom numpy import std\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom matplotlib import pyplot","e6ab2152":"# get the dataset\ndef get_dataset():\n    X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n    return X, y","41417db4":"# get a list of models to evaluate\ndef get_models():\n    models = dict()\n    models['lr'] = LogisticRegression()\n    models['knn'] = KNeighborsClassifier()\n    models['cart'] = DecisionTreeClassifier()\n    models['svm'] = SVC()\n    models['boosting'] = GradientBoostingClassifier()\n    models['forest'] = RandomForestClassifier()\n    return models","479cb3aa":"# evaluate a given model using cross-validation\ndef evaluate_model(model, X, y):\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n    return scores","9565b94e":"# define dataset\nX, y = get_dataset()\n# get the models to evaluate\nmodels = get_models()\n# evaluate the models and store results\nresults, names = list(), list()\nfor name, model in models.items():\n    scores = evaluate_model(model, X, y)\n    results.append(scores)\n    names.append(name)\n    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n# plot model performance for comparison\npyplot.boxplot(results, labels=names, showmeans=True)\npyplot.show()","43fb95d6":"def get_stacking():\n    # define the base models\n    leve0 = list()\n    leve0.append(('lr', LogisticRegression()))\n    leve0.append(('knn', KNeighborsClassifier()))\n    leve0.append(('cart', DecisionTreeClassifier()))\n    leve0.append(('svm', SVC()))\n    leve0.append(('boosting', GradientBoostingClassifier()))\n    leve0.append(('forest',RandomForestClassifier()))\n                 \n    # define meta learner model\n    level1 = LogisticRegression()\n    # define the stacking ensemble\n    model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n    return model","a981e094":"def get_models():\n    models = dict()\n    models['lr'] = LogisticRegression()\n    models['knn'] = KNeighborsClassifier()\n    models['cart'] = DecisionTreeClassifier()\n    models['svm'] = SVC()\n    models['boosting'] = GradientBoostingClassifier()\n    models['forest'] = RandomForestClassifier()\n    models['Stacking'] = get_stacking()\n    return models","fde0f35e":"from numpy import mean\nfrom numpy import std\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import StackingClassifier\nfrom matplotlib import pyplot\n\n\n# get the dataset\ndef get_dataset():\n    X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n    return X, y\n\n\ndef get_stacking():\n    # define the base models\n    level0 = list()\n    level0.append(('lr', LogisticRegression()))\n    level0.append(('knn', KNeighborsClassifier()))\n    level0.append(('cart', DecisionTreeClassifier()))\n    level0.append(('svm', SVC()))\n    level0.append(('boosting', GradientBoostingClassifier()))\n    level0.append(('forest',RandomForestClassifier()))\n                 \n    # define meta learner model\n    level1 = LogisticRegression()\n    # define the stacking ensemble\n    model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n    return model\n\ndef get_models():\n    models = dict()\n    models['lr'] = LogisticRegression()\n    models['knn'] = KNeighborsClassifier()\n    models['cart'] = DecisionTreeClassifier()\n    models['svm'] = SVC()\n    models['boosting'] = GradientBoostingClassifier()\n    models['forest'] = RandomForestClassifier()\n    models['Stacking'] = get_stacking()\n    return models\n\n# evaluate a give model using cross-validation\ndef evaluate_model(model, X, y):\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n    return scores\n\n# define dataset\nX, y = get_dataset()\n# get the models to evaluate\nmodels = get_models()\n# evaluate the models and store results\nresults, names = list(), list()\nfor name, model in models.items():\n    scores = evaluate_model(model, X, y)\n    results.append(scores)\n    names.append(name)\n    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n# plot model performance for comparison\npyplot.boxplot(results, labels=names, showmeans=True)\npyplot.show()","e1c9ee17":"from sklearn import datasets\ndata = datasets.load_breast_cancer()\n# Import pandas\nimport pandas as pd\n# Read the DataFrame, first using the feature data\ndf = pd.DataFrame(data.data, columns=data.feature_names)\n# Add a target column, and fill it with the target data\ndf['target'] = data.target\n# Show the first five rows\ndf.head()","26fa5010":"# Store the feature data\nx = data.data\n# store the target data\ny = data.target\n","a1b66c96":"# define the base models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nlevel0 = list()\nlevel0.append(('lr', LogisticRegression()))\nlevel0.append(('knn', KNeighborsClassifier()))\nlevel0.append(('cart', DecisionTreeClassifier()))\nlevel0.append(('svm', SVC()))\nlevel0.append(('forest',RandomForestClassifier()))\n","5d301729":"#define meta model\nfrom sklearn.ensemble import StackingClassifier\n# define meta learner model\nlevel1 = LogisticRegression()\n# define the stacking ensemble\nmodel = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)","59496580":"#splitting data \nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=101,stratify=y)","807d15c6":"#running model\nmodel.fit(x_train,y_train)","1ce6874e":"#Checking Accuracy\nmodel.score(x_test,y_test)","d0ca840a":"#Running Classification Report And Confusion Matrix\nfrom sklearn.metrics import classification_report,confusion_matrix\nimport seaborn as sns\nimport numpy as np\ny_pred = model.predict(x_test)\ncf_matrix = confusion_matrix(y_test,y_pred)\nsns.heatmap(cf_matrix\/np.sum(cf_matrix), annot=True, \n            fmt='.2%', cmap='Blues')","13213ee5":"Each model will be evaluated using repeated k-fold cross-validation.\n\n> The evaluate_model() function below takes a model instance and returns a list of scores from three repeats of stratified 10-fold cross-validation.","a4d20fed":"> We can include the stacking ensemble in the list of models to evaluate, along with the standalone models.","25caf8ab":"Next, we can try to combine these five models into a single ensemble model using stacking.","226a8941":"Stacked Generalization or \u201cStacking\u201d for short is an ensemble machine learning algorithm.\n> The architecture of a stacking model involves two or more base models, often referred to as level-0 models, and a meta-model that combines the predictions of the base models, referred to as a level-1 model.","2732adb0":"# Making Final Model For Stacking ","2c691ae2":"Next, we can evaluate a suite of different machine learning models on the dataset.\nSpecifically, we will evaluate the following five algorithms:\n\nLogistic Regression.\n\nk-Nearest Neighbors.\n\nDecision Tree.\n\nSupport Vector Machine.\n\nGradeint Boost\n\nRandom Forest\n","88cd49e2":"The level-1 model ( meta model) is provided by 'final_estimator' argument and by deafault is set to Linear Regression in Regression Models and Logistic Regression and Classification Models","c800f428":"Stacking is provided via the StackingRegressor and StackingClassifier classes.","4697d4ae":"> The get_stacking() function below defines the StackingClassifier model by first defining a list of tuples for the five base models, then defining the logistic regression meta-model to combine the predictions from the base models using 5-fold cross-validation.","4d063a86":"The dataset for meta model is prepared using cross validation","9c776ff9":"  models = [('lr',LogisticRegression()),('svm',SVC())\n\n\n\n stacking = StackingClassifier(estimators=models)","5692ad38":"Both models operate the same way and take the same arguments. Using the model requires that you specify a list of estimators (level-0 models), and a final estimator (level-1 or meta-model).\n\nA list of level-0 models or base models is provided via the \u201cestimators\u201d argument. This is a Python list where each element in the list is a tuple with the name of the model and the configured model instance.\n> \nFor example, below defines two level-0 models:","94879607":"# Combing All This For A Complete Code","3a8b15d8":"# COMPLETE CODE TO SHOW STACKING","55ad8222":"# STACKING FOR CLASSIFICATION","023cb310":"The scikit-learn Python machine learning library provides an implementation of stacking for machine learning."}}