{"cell_type":{"328bda29":"code","7a1b9b33":"code","c6cc2b1d":"code","5d403fbc":"code","edc0fbbe":"code","a664383b":"code","1e02ca47":"code","4da3fba8":"code","c65fb210":"code","5adaf747":"code","cc2f5445":"code","46bbd3e3":"code","28c21fb4":"code","5ba26b37":"code","65608a87":"code","4732fe83":"code","b179f534":"code","b90533f3":"code","3bd27bfe":"code","2f59b778":"code","91790419":"code","04fd19e0":"code","eca08257":"code","76dbb0c7":"code","28352e3e":"code","6644d02d":"code","07956f00":"code","4a55ec30":"code","bfe93755":"code","952891e9":"code","7cab46c5":"code","238fe0d9":"code","3f979892":"code","2e553f41":"code","b020ccf3":"code","98f44a48":"code","9104145e":"code","5df4430a":"code","c7c2af6a":"code","bac6102a":"code","30d0796b":"code","258b4396":"code","10f7ea8a":"code","2b5e4173":"code","53fc796f":"code","d855e573":"code","5b29a89f":"code","4420b9b7":"code","10a72238":"markdown","daae4bc3":"markdown","03040798":"markdown","4d32ff8a":"markdown","8a1449a6":"markdown","ba790616":"markdown","62f21de0":"markdown","75941493":"markdown","85f9628f":"markdown","3fe29674":"markdown","d6769da9":"markdown"},"source":{"328bda29":"import pandas as pd\nimport numpy as np\nimport time\nfrom datetime import datetime\n#import lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","7a1b9b33":"import os\nimport json\nimport numpy as np\nimport pandas as pd\nfrom pandas.io.json import json_normalize\n\ndef load_df(csv_path='..\/input\/train.csv', nrows=None):\n    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n    \n    df = pd.read_csv(csv_path, \n                     converters={column: json.loads for column in JSON_COLUMNS}, \n                     dtype={'fullVisitorId': 'str'}, # Important!!\n                     nrows=nrows)\n    \n    for column in JSON_COLUMNS:\n        column_as_df = json_normalize(df[column])\n        column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n    print(f\"Loaded {os.path.basename(csv_path)}. Shape: {df.shape}\")\n    return df\n\n#print(os.listdir(\"input\"))","c6cc2b1d":"%%time\ntrain_df = load_df()","5d403fbc":"train_df.columns","edc0fbbe":"# Let's check quickly how the data looks like after the conversion\n\ntrain_df.head()","a664383b":"#Temporarily take the dataframe into another variable and this sd variable is the one we will use it throughout the notebook \n\nsd = train_df","1e02ca47":"#let's check the info on all columns, how many null and not null values are and their associated data types\nsd.info()","4da3fba8":"sd.sessionId.nunique()","c65fb210":"#removing duploicate session Id from the dataframe\ndf = sd[sd.duplicated(subset='sessionId')]","5adaf747":"sd.drop_duplicates(subset='sessionId', keep=\"first\", inplace=True)","cc2f5445":"#new session id count after removing all duplicates\nsd.sessionId.count()","46bbd3e3":"# Let's see how first record looks like\nsd.loc[0]","28c21fb4":"cols =     ['device.browserSize', 'device.browserVersion', 'device.language', 'device.mobileDeviceBranding',  'device.mobileDeviceInfo', \n            'device.mobileDeviceMarketingName', 'device.mobileDeviceModel', 'device.mobileInputSelector', 'device.operatingSystemVersion',\n            'device.screenColors', 'device.screenResolution', 'device.flashVersion','geoNetwork.cityId', 'geoNetwork.latitude', 'geoNetwork.longitude','geoNetwork.networkLocation',\n           'trafficSource.campaignCode']","5ba26b37":"# Drop unwanted columns from dataframe which does not have useful information (null values etc)\nsd.drop(columns=cols, axis=1, inplace=True)","65608a87":"#Also there are many columns which have numeric values and currently they are Object, so let's convert them into numberic values\nsd[[ \n       'trafficSource.adwordsClickInfo.page',\n         'totals.bounces', 'totals.hits',\n       'totals.newVisits', 'totals.pageviews', 'totals.transactionRevenue', 'totals.visits']] = sd[[ \n       'trafficSource.adwordsClickInfo.page',\n         'totals.bounces', 'totals.hits',\n       'totals.newVisits', 'totals.pageviews', 'totals.transactionRevenue', 'totals.visits']].apply(pd.to_numeric)","4732fe83":"# If you see the transaction amount, they are too high value\nsd['totals.transactionRevenue'].max()","b179f534":"#fixing the transactionRevenue column data in dataframe\nsd['totals.transactionRevenue'] = sd['totals.transactionRevenue']\/1000000","b90533f3":"# Some useful stats around transactionRevenue count and transactionRevenue amount data\n\nprint(\"Total transactions count over 0 dollars \" +  sd[sd['totals.transactionRevenue'] > 0]['totals.transactionRevenue'].count().astype(str))\nprint(\"Total transactions amount over 0 dollars \" +  sd[sd['totals.transactionRevenue'] > 0]['totals.transactionRevenue'].sum().astype(str))\nprint(\"Minimum transactions amount over 0 dollars \" +  sd[sd['totals.transactionRevenue'] > 0]['totals.transactionRevenue'].min().astype(str))\nprint(\"Maximum transactions amount over 0 dollars \" +  sd[sd['totals.transactionRevenue'] > 0]['totals.transactionRevenue'].max().astype(str))\nprint(\"Total transactions count over 1000 dollars \" +  sd[sd['totals.transactionRevenue'] > 1000]['totals.transactionRevenue'].count().astype(str))\nprint(\"Total transactions amoount over 1000 dollars \" +  sd[sd['totals.transactionRevenue'] > 1000]['totals.transactionRevenue'].sum().astype(str))","3bd27bfe":"sd[(sd['totals.transactionRevenue'] > 0) & (sd['totals.transactionRevenue'] < 1000)]['totals.transactionRevenue'].plot(kind='hist', bins=120, sort_columns=False, figsize=[14,7])","2f59b778":"sd['date'] = pd.to_datetime(sd['date'].astype(str), format='%Y%m%d')","91790419":"# Showing a line graph with transaction revenue generated per day for the entire dataset between August 2017 - August 2018\n# It's clear that during the month of Oct-Nov-Dec 2017 the overall mean level of the transactions were higher than other months\n\nsd.groupby(['date'])['totals.transactionRevenue'].sum().plot(kind='line', sort_columns=False, figsize=[14,7], title='Daily Revenue (USD)', label='Transaction Revenue $ Amount', markevery=500, legend=True)","04fd19e0":"# Below graph shows # of transactions done by customers. It's visible that during Christmas time there were most number of transactions\n# and again during May 2018... could be because schools are off and people do shopping a lot before summer vacations ?? :) \nsd.groupby(['date'])['totals.transactionRevenue'].count().plot(kind='line', sort_columns=False, figsize=[14,7], title='Daily number of session', label='Session count', markevery=100, legend=True)","eca08257":"# Let's add a weekday name like sunday, monday, tuesday....saturday for further analysis\nsd['day_of_week'] = sd['date'].dt.weekday_name","76dbb0c7":"# Let's add day number for sorting purpose\nsd['day_number'] = sd['date'].dt.weekday","28352e3e":"# Let's see which day of the week store get's most revenue in a year. It seems Tuesday is the winner. Saturday\/Sunday people dont shop much online it seems \n\nax = sd.groupby(['day_number'])['totals.transactionRevenue'].sum().plot(kind='bar', sort_columns=False, figsize=[14,7], title='Revenue per weekday (USD)', label='Transaction Revenue $ Amount',legend=True)\nax.set_xticklabels(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])    \nax.set_ylabel('Revenue(USD)')\nax.set_xlabel('Day of the week')","6644d02d":"# Most number of transactions are done on Monday and very low transaction rate is found on Saturday and Sunday\n\nax = sd.groupby(['day_number'])['totals.transactionRevenue'].count().plot(kind='bar', sort_columns=False, figsize=[14,7], title='Number of Session on weekday', label='Number of sessions',legend=True)\nax.set_xticklabels(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])    \nax.set_ylabel('Number of Sessions')\nax.set_xlabel('Day of the week')","07956f00":"# Now which month of the year get's most revenue... it turns out that April, August and December are the months\n# April = Summer vacation\n# August = School about to start\n# December = Christmas Vacations\nax = sd.groupby([sd['date'].dt.month])['totals.transactionRevenue'].sum().plot(kind='bar', width=.9, sort_columns=False, figsize=[14,7], title='Revenue per month', label='Revenue',legend=True)\nax.set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])    \nax.set_ylabel('Revenue per month (USD)')\nax.set_xlabel('Months')","4a55ec30":"# most number of transactions are done in December\n\nax = sd.groupby([sd['date'].dt.month])['totals.transactionRevenue'].count().plot(kind='bar', width=.9, sort_columns=False, figsize=[14,7], title='Number of Session per month', label='Number of sessions',legend=True)\nax.set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])    \nax.set_ylabel('Number of Sessions per month')\nax.set_xlabel('Months')","bfe93755":"# Transaction revenue per channel grouping\n\nax = sd.groupby([sd['channelGrouping']])['totals.transactionRevenue'].sum().plot(kind='bar', width=.9, sort_columns=True, figsize=[14,7], title='Revenue per Channel', label='Revenue',legend=True)\nax.set_ylabel('Revenue (USD)')\nax.set_xlabel('Channel Name')","952891e9":"# Most number of sessions per channel grouping\n\nax = sd['channelGrouping'].value_counts().plot(kind='bar', width=.9, sort_columns=True, figsize=[14,7], title='Number of Sessions per Channel', label='Number of sessions',legend=True)\nax.set_ylabel('Number of Sessions')\nax.set_xlabel('Channel Name')","7cab46c5":"# revenue generated by source\nsd.groupby([sd['trafficSource.source']])['totals.transactionRevenue'].sum().sort_values(ascending=False)[:20]","238fe0d9":"#Similarly plot for the revenue generated by source\n\nax = sd.groupby([sd['trafficSource.source']])['totals.transactionRevenue'].sum().sort_values(ascending=False)[:20].sort_values().plot(kind='barh', width=.9, sort_columns=True, figsize=[14,7], title='Revenue per Source', label='Revenue',legend=True)\nax.set_ylabel('Source Name')\nax.set_xlabel('Revenue (USD)')","3f979892":"ax = sd['trafficSource.source'].value_counts()[:20].sort_values().plot(kind='barh', width=.9, sort_columns=False, figsize=[14,7], title='Number of Sessions per Source', label='Number of sessions',legend=True)\nax.set_ylabel('Source Name')\nax.set_xlabel('Number of Sessions')","2e553f41":"ax = sd.groupby([sd['device.deviceCategory']])['totals.transactionRevenue'].sum().sort_values(ascending=False)[:20].plot(kind='bar', width=.9, sort_columns=True, figsize=[14,7], title='Revenue per Device Category', label='Revenue',legend=True)\nax.set_xlabel('Device Category')\nax.set_ylabel('Revenue (USD)')","b020ccf3":"ax = sd['device.deviceCategory'].value_counts()[:20].plot(kind='bar', width=.9, sort_columns=False, figsize=[14,7], title='Number of Sessions per Device Category', label='Number of sessions',legend=True)\nax.set_xlabel('Device Category')\nax.set_ylabel('Number of Sessions')","98f44a48":"ax = sd.groupby([sd['device.operatingSystem']])['totals.transactionRevenue'].sum().sort_values(ascending=False)[:7].plot(kind='bar', width=.9, sort_columns=True, figsize=[14,7], title='Revenue per Operating System', label='Revenue',legend=True)\nax.set_xlabel('Operating System')\nax.set_ylabel('Revenue (USD)')","9104145e":"ax = sd['device.operatingSystem'].value_counts()[:7].plot(kind='bar', width=.9, sort_columns=False, figsize=[14,7], title='Number of Sessions per Operating System', label='Number of sessions',legend=True)\nax.set_xlabel('Operating System')\nax.set_ylabel('Number of Sessions')","5df4430a":"ax = sd.groupby([sd['device.browser']])['totals.transactionRevenue'].sum().sort_values(ascending=False)[:9].plot(kind='bar', width=.9, sort_columns=True, figsize=[14,7], title='Revenue per Browser', label='Revenue',legend=True)\nax.set_xlabel('Browser')\nax.set_ylabel('Revenue (USD)')","c7c2af6a":"ax = sd['device.browser'].value_counts()[:9].plot(kind='bar', width=.9, sort_columns=False, figsize=[14,7], title='Number of Sessions per Browser', label='Number of sessions',legend=True)\nax.set_xlabel('Browser')\nax.set_ylabel('Number of Sessions')","bac6102a":"ax = sd.groupby([sd['totals.pageviews']])['totals.transactionRevenue'].sum()[:75].plot(kind='bar', width=.9, sort_columns=True, figsize=[14,7], title='Revenue Pageviews', label='Revenue',legend=True)\nax.set_xlabel('Pageviews')\nax.set_ylabel('Revenue (USD)')","30d0796b":"ax = sd['totals.pageviews'].value_counts()[:30].plot(kind='bar', width=.9, sort_columns=False, figsize=[14,7], title='Number of Sessions per pageviews', label='Number of sessions',legend=True)\nax.set_xlabel('Pageviews')\nax.set_ylabel('Number of Sessions')","258b4396":"ax = sd[(sd['totals.pageviews'] <= 100) & (sd['totals.transactionRevenue'] > 0)]['totals.pageviews'].value_counts().sort_values(ascending=False)[:50].plot(kind='bar', width=.9, sort_columns=True, figsize=[14,7], title='Number of Sessions per pageviews', label='Number of sessions',legend=True)\nax.set_xlabel('Pageviews')\nax.set_ylabel('Number of Sessions with transaction revenue')","10f7ea8a":"print('Total number of bounces ' + sd[(sd['totals.bounces'] == 1)].count().iloc[1].astype(str))\nprint('Total revenue (USD) generated from bounces ' + sd[(sd['totals.bounces'] == 1) & (sd['totals.transactionRevenue'] > 0)]['totals.transactionRevenue'].sum().astype(str))","2b5e4173":"print('Total number of single pageviews ' + sd[(sd['totals.pageviews'] == 1)].count().iloc[1].astype(str))\nprint('Total revenue (USD) generated from single pageviews ' + sd[(sd['totals.pageviews'] == 1) & (sd['totals.transactionRevenue'] > 0)]['totals.transactionRevenue'].sum().astype(str))","53fc796f":"ax = sd.groupby([sd[(sd['totals.hits'] <200 )]['totals.hits']])['totals.transactionRevenue'].sum()[:100].plot(kind='bar', width=.9, sort_columns=True, figsize=[14,7], title='Revenue page hits', label='Revenue',legend=True)\nax.set_xlabel('Pagehits')\nax.set_ylabel('Revenue (USD)')\nax.set_xmargin(.5)","d855e573":"print(sd.groupby([sd[(sd['totals.transactionRevenue'] > 1 )]['geoNetwork.country']])['totals.transactionRevenue'].sum().sort_values(ascending=False)[:10])\nax = sd.groupby([sd[(sd['totals.transactionRevenue'] > 1 )]['geoNetwork.country']])['totals.transactionRevenue'].sum().sort_values(ascending=False)[:10].plot(kind='bar', width=.9, sort_columns=True, figsize=[14,7], title='Revenue per country', label='Revenue',legend=True)\nax.set_xlabel('Country')\nax.set_ylabel('Revenue (USD)')\nax.set_xmargin(.5)","5b29a89f":"print('All visits by Country  - top 10')\nprint(sd.groupby(['geoNetwork.country'])['totals.visits'].sum().sort_values(ascending=False)[:10])\nprint('\\nAll Revenue making visits by Country - top 10')\nprint(sd.groupby([sd[(sd['totals.transactionRevenue'] > 1 )]['geoNetwork.country']])['totals.visits'].sum().sort_values(ascending=False)[:10])\n\nsd.groupby(['geoNetwork.country'])['totals.visits'].sum().sort_values(ascending=False)[:10].plot(kind='line', sort_columns=True, figsize=[14,7], label='Total Visits (right)',legend=True, subplots=True, sharey=False, secondary_y=True, colormap='rainbow')\nax = sd.groupby([sd[(sd['totals.transactionRevenue'] > 1 )]['geoNetwork.country']])['totals.visits'].sum().sort_values(ascending=False)[:10].plot(kind='bar', width=.9, sort_columns=True, figsize=[14,7], title='Revenue per country', label='Revenue making visits (left)',legend=True)\nax.set_xlabel('Country')\nax.set_ylabel('Revenue (USD)')\nax.set_xmargin(.5)","4420b9b7":"print('\\nMean Transaction Revenue by Country where Transaction Revenue is > $0 - top 10')\nprint(sd.groupby([sd[(sd['totals.transactionRevenue'] > 0 )]['geoNetwork.country']])['totals.transactionRevenue'].mean().sort_values(ascending=False)[:10])\n\nax = sd.groupby([sd[(sd['totals.transactionRevenue'] > 0 )]['geoNetwork.country']])['totals.transactionRevenue'].mean().sort_values(ascending=False)[:10].plot(kind='bar', width=.9, sort_columns=True, figsize=[14,7], title='Mean Revenue per country with transaction amount > $0', label='Mean Revenue',legend=True)\nax.set_xlabel('Country')\nax.set_ylabel('Revenue (USD)')\nax.set_xmargin(.5)","10a72238":"#correcting transaction revenues (see https:\/\/www.kaggle.com\/c\/google-analytics-customer-revenue-prediction\/discussion\/65775). This is for EDA purposes only. In the competition, we need to predict the log of the tranaction values as they are stored in the dataset (so not divided by 1,000,000).\n","daae4bc3":"## 1. Loading Libraries and Data","03040798":"Display the list of columns in the dataset, and verify that all the JSON related columns have been properly added to the dataframe","4d32ff8a":"Converting date column from int64 to date data type","8a1449a6":"Thanks ML for providing this load_df function and json code ","ba790616":"There are many columns which either have NULL values all over OR \"not available in demo dataset\". Which is not very useful to drive data analysis. Let;s convert the column to a list. and then use it for dropping those columns from dataframe","62f21de0":"loading the data file into train_df ","75941493":"SessionId should be the unique identifier for each observation as it is a combination of fullVisitorId and visitId. The number of unique sessionId's comes close to the total number of observations (903,653), but is 898 short.","85f9628f":"Let's see how many total columns are in the dataset and how many of them are null and not-null","3fe29674":"As the distribution of revenues is very right skewed, with the tail reaching 23,000 USD, I am below only displaying the histogram of the transaction with revenues below 1,000 USD.","d6769da9":"Drop duplicates for sessionId fields"}}