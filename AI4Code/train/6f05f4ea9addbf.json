{"cell_type":{"196a39e8":"code","8c521f56":"code","54a0f24c":"code","23123857":"code","e5f63c31":"code","c755b744":"code","124638b1":"code","e3ee6dd4":"code","bd06710e":"code","f62416a8":"code","c58eb53c":"code","567564cc":"code","eddc9dcd":"code","b9e35b7f":"code","48207f0c":"code","51d75e5f":"code","d11fd8db":"code","63e9e26d":"code","b8db1700":"code","7050df60":"code","2c957b1c":"code","940c8311":"code","3e8a8470":"code","7b85467e":"markdown","08dde406":"markdown","52b1fcfe":"markdown","aced6639":"markdown","6273e034":"markdown","a5c956e3":"markdown","485a60be":"markdown","fac2f209":"markdown","36f342fc":"markdown"},"source":{"196a39e8":"#essential libraries\nimport pandas as pd                   #pandas does things with matrixes\nimport numpy as np                    #used for sorting a matrix\nimport matplotlib.pyplot as plt       #matplotlib is used for plotting data\nimport matplotlib.ticker as ticker    #used for changing tick spacing\nimport datetime as dt                 #used for dates\nimport matplotlib.dates as mdates     #used for dates, in a different way\n\nfrom sklearn import preprocessing;\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import linear_model;","8c521f56":"#importing dataset\ndf = pd.read_csv('..\/input\/sandp500\/all_stocks_5yr.csv')\ndf.head()","54a0f24c":"df.columns                     #prints just the columns of the matrix","23123857":"df.info()                            #get information of each column","e5f63c31":"df.describe()                        #describe the dataset","c755b744":"total = df.isnull().sum().sort_values()                                              #counts all null cells in a row\npercent = ((df.isnull().sum()\/df.isnull().count()).sort_values()*100)                #sees what percent of the data is null\nmissing_data = pd.concat([total,percent],axis=1,keys=['Total','Percent'])            #combines the two matrixies\nmissing_data                                                                         #this displays the matrix","124638b1":"df = df.ffill(axis=1)                                   #forward filling rows with a null cell\n","e3ee6dd4":"total = df.isnull().sum().sort_values()                                              #counts all null cells in a row\npercent = ((df.isnull().sum()\/df.isnull().count()).sort_values()*100)                #sees what percent of the data is null\nmissing_data = pd.concat([total,percent],axis=1,keys=['Total','Percent'])            #combines the two matrixies\nmissing_data  ","bd06710e":"df = df.drop(df.loc[df['open'].isnull()].index)                                   #drops rows with a null cell in the open column\ntotal = df.isnull().sum().sort_values()                                              #counts all null cells in a row\npercent = ((df.isnull().sum()\/df.isnull().count()).sort_values()*100)                #sees what percent of the data is null\nmissing_data = pd.concat([total,percent],axis=1,keys=['Total','Percent'])            #combines the two matrixies\nmissing_data  ","f62416a8":"len(df.Name.unique())                  #calculating total number of companies listed in the dataset","c58eb53c":"# For the sake of visualization, Let's create extract year from the date column\ndf['year'] = pd.DatetimeIndex(df[\"date\"]).year\ndf['month'] = pd.DatetimeIndex(df[\"date\"]).month\ndf['date'] = pd.DatetimeIndex(df[\"date\"]).date","567564cc":"df.tail()","eddc9dcd":"#Since the year 2017 is the most recent year with dataset of over 4 months, let's explore that\n# Creating a ColumnDataSource instance to act as a reusable data source for ploting\n","b9e35b7f":"df[\"Name\"].unique()","48207f0c":"#We'll focus on one\nwalmart = df.loc[df['Name'] == 'WMT']\nwalmart.head()","51d75e5f":"walmart.info()","d11fd8db":"#Create a copy to avoid the SettingWarning .loc issue \nwalmart_df = walmart.copy()\n\n# Change to datetime datatype.\nwalmart_df.loc[:, 'date'] = pd.to_datetime(walmart.loc[:,'date'], format=\"%Y\/%m\/%d\")","63e9e26d":"walmart_df.info()","b8db1700":"# Let us plot Walmart Stock Price\n# First Subplot\n\nf, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\nax1.plot(walmart_df[\"date\"], walmart_df[\"close\"], color=\"yellow\")\nax1.set_xlabel(\"Date\", fontsize=12)\nax1.set_ylabel(\"Stock Price\")\nax1.set_title(\"Walmart Close Price History\")\n\n# Second Subplot\nax1.plot(walmart_df[\"date\"], walmart_df[\"high\"], color=\"green\")\nax1.set_xlabel(\"Date\", fontsize=12)\nax1.set_ylabel(\"Stock Price\")\nax1.set_title(\"Walmart High Price History\")\n\n# Third Subplot\nax1.plot(walmart_df[\"date\"], walmart_df[\"low\"], color=\"red\")\nax1.set_xlabel(\"Date\", fontsize=12)\nax1.set_ylabel(\"Stock Price\")\nax1.set_title(\"Walmart Low Price History\")\n\n# Fourth Subplot\nax2.plot(walmart_df[\"date\"], walmart_df[\"volume\"], color=\"blue\")\nax2.set_xlabel(\"Date\", fontsize=12)\nax2.set_ylabel(\"Stock Price\")\nax2.set_title(\"Walmart's Volume History\")\n\nplt.show()","7050df60":"# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\ndef prepare_data(df,forecast_col,forecast_out,test_size):\n    label = df[forecast_col].shift(-forecast_out);#creating new column called label with the last 5 rows are nan\n    X = np.array(df[[forecast_col]]); #creating the feature array\n    X = preprocessing.scale(X) #processing the feature array\n    X_lately = X[-forecast_out:] #creating the column i want to use later in the predicting method\n    X = X[:-forecast_out] # X that will contain the training and testing\n    label.dropna(inplace=True); #dropping na values\n    y = np.array(label)  # assigning Y\n    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=test_size) #cross validation \n\n    response = [X_train,X_test , Y_train, Y_test , X_lately];\n    return response;","2c957b1c":"forecast_col = 'close'#choosing which column to forecast\nforecast_out = 50 #how far to forecast \ntest_size = 0.2; #the size of my test set\n\nX_train, X_test, Y_train, Y_test , X_lately =prepare_data(walmart_df,forecast_col,forecast_out,test_size); #calling the method were the cross validation and data preperation is in\n\nlearner = linear_model.LinearRegression(); #initializing linear regression model\nlearner.fit(X_train,Y_train); #training the linear regression model\n\nscore=learner.score(X_test,Y_test);#testing the linear regression model\nforecast= learner.predict(X_lately); #set that will contain the forecasted data\n\nresponse={};#creting json object\nresponse['test_score']=score; \nresponse['forecast_set']=forecast;\n\nprint(response);","940c8311":"f, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\nax1.plot(X_lately, forecast, color=\"yellow\")\nax1.set_xlabel(\"Date\", fontsize=12)\nax1.set_ylabel(\"Stock Price\")\nax1.set_title(\"Walmart Close Price Predicted\")\n\nax2.scatter(X_test, Y_test, color=\"green\")\nax2.set_xlabel(\"day\", fontsize=12)\nax2.set_ylabel(\"Stock Price\")\nax2.set_title(\"Walmart actual Close Price\")\n\n","3e8a8470":"score","7b85467e":"Let's check the missing data again","08dde406":"We need to make sure if the date column is either a categorical type or a datetype. In our case date is a categorical datatype so we need to change it to datetime.","52b1fcfe":"We observe that the total number of missing rows to be 11, making the total number of rows being deleted less than 0.002% of the dataset.","aced6639":"We observe that the total number of column with missing values is 8-27 which is less that 0.005% of the dataset.\nIt is convinient to get rid of the rows with missing value since the affect on the dataset will be very insignificant, but to avoid any issues since it is a time series analysis, we will forward fill the null values instead of dropping them.","6273e034":"# understanding our dataset\n\nThe first step towards data analysis is to understand the data in hand. Its columns, max, min, count, null values, etc...","a5c956e3":"we have ***successfully*** cleared all missing data from our dataset","485a60be":"# Missing values\nIn this section we will handle all the missing data in the dataset","fac2f209":"# Feature Extraction","36f342fc":"# Exploratory Data Analysis\n\nLet's analyse, plot and work on different aspects of the project"}}