{"cell_type":{"f79e90c7":"code","bdeb176d":"code","ad1675b0":"code","7906a4d6":"code","e1a104cb":"code","38a2668a":"code","ee375b56":"code","9aaf3d72":"code","74559ce9":"code","526a9054":"code","340be367":"code","a3326a82":"code","60655235":"code","ca7ff6e7":"code","b2e97ebd":"code","b71b7a4a":"code","c25275d8":"code","e0331337":"code","db41ad46":"code","845086f7":"code","043e349d":"code","35121642":"code","9a4f268c":"code","23dc719f":"code","b347129d":"code","05e25243":"code","60e115a2":"code","9080d52b":"code","68333333":"code","0763690d":"code","5990abfa":"code","8819cef3":"code","97d488d3":"code","71333b00":"code","605a9bbc":"code","0000ab45":"code","f8a21788":"code","4e762b6c":"code","9084a8ff":"code","0dfdebaa":"code","cc83749f":"code","661b13ba":"code","4b9a5079":"code","a3ee29c1":"code","987be2b2":"code","d899aafa":"code","acc254f8":"code","8a69ba2b":"code","8b5d2814":"code","84d31c82":"code","cc3b6938":"code","48dd0d9f":"code","696e6b10":"code","b7d74416":"code","807d82a2":"code","4d4a4b3b":"code","8bd88e30":"code","b6e289a1":"code","b99f7c57":"code","7f8fcfca":"code","9f98aade":"code","7cc1a983":"code","51dd14e0":"code","49f81060":"code","c4c66754":"code","161cc74c":"code","29846e6d":"code","f958a3af":"code","f37469e7":"code","b1eab675":"code","df7993be":"code","cbfe3857":"code","6df9af09":"code","edc7c1e6":"code","e362c683":"code","bfa1f123":"code","4d1ef87c":"code","a233dffb":"code","9a473cc5":"code","c1487fd7":"code","438c5ff7":"code","d37ed10a":"code","96023fa8":"code","ef888b06":"code","7ef46623":"code","746bc934":"code","04f045d2":"code","ea7bd5ed":"code","1ee3d3c5":"code","6fc82e63":"code","f4067fcf":"code","394ce92a":"code","c6edb2cc":"code","2f07bd0f":"markdown","8c783e51":"markdown","b8dcd994":"markdown","6a499fea":"markdown","be78ef44":"markdown","e39f4b4c":"markdown","16e90916":"markdown","a94c4ef7":"markdown","fdf88cc5":"markdown","c83b4b9d":"markdown","4c91174c":"markdown","9932fc00":"markdown","1c1ae005":"markdown","24ad289a":"markdown","f5cd878a":"markdown","00854328":"markdown","55f6ff83":"markdown","30281d21":"markdown","2de2d66a":"markdown","28d4662e":"markdown","0064fd62":"markdown","c090e819":"markdown","e3aaf9a5":"markdown","72e674bd":"markdown","c7941261":"markdown","888bdc9c":"markdown","a09dca10":"markdown","f2e64d43":"markdown","2caf141d":"markdown","1ea4d8fa":"markdown"},"source":{"f79e90c7":"# 1.Introduction\n# 2.Data Understanding\n#   2.1 \u0130mporting Libraries and Loading Data\n#   2.2 Feature Analysis\n#   2.3 Visualization\n# 3.Data Preparation\n#   3.1 Deleting Unnecessary Variables\n#   3.2 Outlier Treatment\n#   3.3 Missing Value Treatment\n#      3.3.1 Age\n#      3.3.2 Embarked\n#      3.3.3 Fare\n#      3.3.4 Cabin\n#   3.4 Variables Transformation\n#      3.4.1 Embarked\n#      3.4.2 Sex\n#      3.4.3 Name-Title\n#      3.4.4 AgeGroup\n#      3.4.5 Fare\n#   3.5 Feature Engineering\n#      3.5.1 Family Size\n#      3.5.2 Embarked-Title\n#      3.5.3 Pclass\n# 4.Modelling\n#   4.1 Spliting The Train Data\n#   4.2 Model Tuning\n#   4.3 Deployment\n ","bdeb176d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ad1675b0":"    import numpy as np\n    import pandas as pd\n\n    # data visualization libraries:\n    import matplotlib.pyplot as plt\n    import seaborn as sns\n\n    # to ignore warnings:\n    import warnings\n    warnings.filterwarnings('ignore')\n\n    # to display all columns:\n    pd.set_option('display.max_columns', None)\n\n    from sklearn.model_selection import train_test_split, GridSearchCV\n","7906a4d6":"# Read train and test data with pd.read_csv():\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","e1a104cb":"train = train_data.copy()\ntest = test_data.copy()","38a2668a":"# I want to combine test and train to make operations easier\n\ndf=pd.concat([train,test],ignore_index=True)","ee375b56":"df","9aaf3d72":"df.info()","74559ce9":"df.describe().T","526a9054":"df[\"Pclass\"].value_counts()","340be367":"df[\"Sex\"].value_counts()","a3326a82":"df[\"SibSp\"].value_counts()","60655235":"df[\"Parch\"].value_counts()","ca7ff6e7":"df[\"Ticket\"].value_counts()","b2e97ebd":"df[\"Cabin\"].value_counts()","b71b7a4a":"df[\"Embarked\"].value_counts()","c25275d8":"age = pd.cut(train[\"Age\"], [0, 18,35,50,90])\nage.head(10)","e0331337":"train.pivot_table(\"Survived\", [\"Sex\", age], \"Pclass\")","db41ad46":"sns.barplot(x=\"Pclass\",y=\"Survived\",data=df);","845086f7":"df.groupby(\"Pclass\")[[\"Survived\"]].mean()","043e349d":"sns.barplot(x=\"Sex\",y=\"Survived\",data=df);","35121642":"df.groupby(\"Sex\")[[\"Survived\"]].mean()","9a4f268c":"sns.factorplot('Pclass','Survived',hue='Sex',data=df)\nplt.show()","23dc719f":"sns.barplot(x=\"SibSp\",y=\"Survived\",data=df);","b347129d":"df.groupby(\"SibSp\")[[\"Survived\"]].mean()","05e25243":"sns.barplot(x=\"Parch\",y=\"Survived\",data=df);","60e115a2":"df.groupby(\"SibSp\")[[\"Survived\"]].mean()","9080d52b":"sns.barplot(x=age ,y=\"Survived\", data=train);","68333333":"train.groupby(age)[[\"Survived\"]].count()","0763690d":"sns.kdeplot(df.Age, shade = True);","5990abfa":"# We can drop the Ticket feature since it is unlikely to have useful information\n\ndf = df.drop(['Ticket'], axis = 1)\n\ndf.head()","8819cef3":"df.describe().T","97d488d3":"# It looks like there is a problem in Fare max data. Visualize with boxplot.\nsns.boxplot(x = df['Fare']);","71333b00":"Q1 = df['Fare'].quantile(0.25)\nQ3 = df['Fare'].quantile(0.75)\nIQR = Q3 - Q1\n\nlower_limit = Q1- 1.5*IQR\nlower_limit\n\nupper_limit = Q3 + 1.5*IQR\nupper_limit","605a9bbc":"# observations with Fare data higher than the upper limit:\n\ndf['Fare'] > (upper_limit)","0000ab45":"df.sort_values(\"Fare\", ascending=False).head()","f8a21788":"# In boxplot, there are too many data higher than upper limit; we can not change all. Just repress the highest value -512- \n\ndf['Fare'] = df['Fare'].replace(512.3292, 300)\n","4e762b6c":"df.sort_values(\"Fare\", ascending=False).head()\n","9084a8ff":"df.isnull().sum()","0dfdebaa":"# Missing value of \"Survived\" is in test data.So it is not important.","cc83749f":"# We can fill the age variable with median.\n\ndf[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].median())","661b13ba":"df.isnull().sum()","4b9a5079":"df[\"Embarked\"].value_counts()","a3ee29c1":"# Fill NA with the most frequent value:\n\ndf[\"Embarked\"] = df[\"Embarked\"].fillna(\"S\")","987be2b2":"df.isnull().sum()","d899aafa":"df[df[\"Fare\"].isnull()]","acc254f8":"df[[\"Pclass\",\"Fare\"]].groupby(\"Pclass\").mean()","8a69ba2b":"# We fill the missing value in fare with the mean of class where Pclass is 3.\n\ndf[\"Fare\"] = df[\"Fare\"].fillna(13)","8b5d2814":"df[\"Fare\"].isnull().sum()","84d31c82":"# Create CabinBool variable which states if someone has a Cabin data or not:\n\ndf[\"CabinBool\"] = (df[\"Cabin\"].notnull().astype('int'))\n\ndf = df.drop(['Cabin'], axis = 1)\n\ndf.head()","cc3b6938":"df.isnull().sum()","48dd0d9f":"# Map each Embarked value to a numerical value:\n\nembarked_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\n\ndf[\"Embarked\"] = df[\"Embarked\"].map(embarked_mapping)\n","696e6b10":"df.head()","b7d74416":"# Convert Sex values into 1-0:\n\ndf[\"Sex\"]=df[\"Sex\"].map(lambda x:1 if x== \"male\" else 0)","807d82a2":"df.head()","4d4a4b3b":"df[\"Title\"] = df[\"Name\"].str.extract(' ([A-Za-z]+)\\.', expand=False)","8bd88e30":"df.head()","b6e289a1":"df = df.drop(['Name'], axis = 1)","b99f7c57":"df['Title'] = df['Title'].replace(['Lady', 'Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\ndf['Title'] = df['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\ndf['Title'] = df['Title'].replace('Mlle', 'Miss')\ndf['Title'] = df['Title'].replace('Ms', 'Miss')\ndf['Title'] = df['Title'].replace('Mme', 'Mrs')","7f8fcfca":"df.head()","9f98aade":"df[[\"Title\",\"PassengerId\"]].groupby(\"Title\").count()","7cc1a983":"df[['Title', 'Survived']].groupby(['Title'], as_index=False).agg({\"count\",\"mean\"})","51dd14e0":"# Map each of the title groups to a numerical value\n\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royal\": 5, \"Rare\": 5}\n\ndf['Title'] = df['Title'].map(title_mapping)\n","49f81060":"df.head()","c4c66754":"# Map Age values into groups of numerical values:\nbins = [0, 5, 12, 18, 24, 35, 60, np.inf]\nmylabels = [1, 2, 3, 4, 5, 6, 7]\ndf['AgeGroup'] = pd.cut(df[\"Age\"], bins, labels = mylabels)\ndf[\"AgeGroup\"] = df[\"AgeGroup\"].astype(\"int\")","161cc74c":"df.head()","29846e6d":"#dropping the Age feature for now, might change:\ndf = df.drop(['Age'], axis = 1)","f958a3af":"df.head()","f37469e7":"# Map Fare values into groups of numerical values:\ndf[\"FareBand\"]=pd.qcut(df[\"Fare\"],4,labels=[1,2,3,4])\ndf[\"FareBand\"] = df[\"FareBand\"].astype(\"int\")","b1eab675":"df=df.drop([\"Fare\"],axis=1)","df7993be":"df.head()","cbfe3857":"df[\"FamilySize\"]=df[\"SibSp\"]+df[\"Parch\"]+1\n","6df9af09":"df.head()","edc7c1e6":"# Create new feature of family size:\n\ndf['Single'] = df['FamilySize'].map(lambda s: 1 if s == 1 else 0)\ndf['SmallFam'] = df['FamilySize'].map(lambda s: 1 if  s == 2  else 0)\ndf['MedFam'] = df['FamilySize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\ndf['LargeFam'] = df['FamilySize'].map(lambda s: 1 if s >= 5 else 0)","e362c683":"df.head()","bfa1f123":"# Convert Title and Embarked into dummy variables:\n\ndf = pd.get_dummies(df, columns = [\"Title\"])\ndf = pd.get_dummies(df, columns = [\"Embarked\"], prefix=\"Em\")","4d1ef87c":"df.head()","a233dffb":"# Create categorical values for Pclass:\ndf[\"Pclass\"] = df[\"Pclass\"].astype(\"category\")\ndf= pd.get_dummies(df, columns = [\"Pclass\"],prefix=\"Pc\")","9a473cc5":"df.head()","c1487fd7":"train=df[(df.PassengerId <892 )].astype(int)\ntest=df[(df.PassengerId >891 )]\n","438c5ff7":"train","d37ed10a":"test","96023fa8":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier","ef888b06":"def base_models(df):\n    \n    \n    from sklearn.model_selection import train_test_split\n    from sklearn.metrics import accuracy_score\n    \n    Y = df[\"Survived\"]\n    X = df.drop([\"Survived\",\"PassengerId\"], axis=1)\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, Y, \n                                                    test_size = 0.20, \n                                                    random_state = 42)\n    \n    #results = []\n    \n    names = [\"LogisticRegression\",\"GaussianNB\",\"KNN\",\"LinearSVC\",\"SVC\",\n             \"CART\",\"RF\",\"GBM\",\"XGBoost\",\"LightGBM\",\"CatBoost\"]\n    \n    \n    classifiers = [LogisticRegression(),GaussianNB(), KNeighborsClassifier(),LinearSVC(),SVC(),\n                  DecisionTreeClassifier(),RandomForestClassifier(), GradientBoostingClassifier(),\n                  XGBClassifier(), LGBMClassifier(), CatBoostClassifier(verbose = False)]\n    \n    \n    for name, clf in zip(names, classifiers):\n\n        model = clf.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        acc = accuracy_score(y_test, y_pred)\n        msg = \"%s: %f\" % (name, acc)\n        print(msg)","7ef46623":"base_models(train)","746bc934":"#As showed, xgboost gives the best results.therefore \u0131 want to choise xgboost as a model.","04f045d2":"Y = train[\"Survived\"]\nX = train.drop([\"Survived\",\"PassengerId\"], axis=1)\n    \nX_train, X_test, y_train, y_test = train_test_split(X, Y, \n                                                    test_size = 0.20, \n                                                    random_state = 42)\n    \nxgb_params = {\n        'n_estimators': [100, 500, 1000],\n        'subsample': [0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5,6],\n        'learning_rate': [0.1,0.01,0.02,0.05],\n        \"min_samples_split\": [2,5,10]}\nxgb = XGBClassifier()\n\nxgb_cv_model = GridSearchCV(xgb, xgb_params, cv = 10, n_jobs = -1, verbose = 2)\nxgb_cv_model.fit(X_train, y_train)","ea7bd5ed":"xgb_cv_model.best_params_","1ee3d3c5":"from sklearn.metrics import accuracy_score\nxgb = XGBClassifier(learning_rate = 0.05, \n                    max_depth = 3,\n                    min_samples_split = 2,\n                    n_estimators = 100,\n                    subsample = 0.6)\nxgb_tuned =  xgb.fit(X_train,y_train)\ny_pred = xgb_tuned.predict(X_test)\naccuracy_score(y_test, y_pred)","6fc82e63":"feature_imp = pd.Series(xgb_tuned.feature_importances_,\n                        index=X_train.columns).sort_values(ascending=False)\n\nsns.barplot(x=feature_imp, y=feature_imp.index)\nplt.xlabel('Variable \u0130mportance Scores')\nplt.ylabel('Variables')\nplt.title(\"Variable Significance Levels\")\nplt.show()","f4067fcf":"test=test.drop(\"Survived\", axis=1)\ntest=test.astype(int)","394ce92a":"#set ids as PassengerId and predict survival \nids = test['PassengerId']\npredictions = xgb_tuned.predict(test.drop('PassengerId', axis=1))\n\n#set the output as a dataframe and convert to csv file named submission.csv\noutput = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\noutput.to_csv('submission.csv', index=False)","c6edb2cc":"output.head()","2f07bd0f":"## Deleting Unnecessary Variables","8c783e51":"## Outlier Treatment","b8dcd994":"### Age","6a499fea":"## Feature Engineering","be78ef44":" **Variables**\n\n\n        Survival: Survival -> 0 = No, 1 = Yes\n\n        Pclass: Ticket class -> 1 = 1st, 2 = 2nd, 3 = 3rd\n\n        Sex: Sex\n\n        Age: Age in years\n\n        SibSp: # of siblings \/ spouses aboard the Titanic\n\n        Parch: # of parents \/ children aboard the Titanic\n\n        Ticket: Ticket number\n\n        Fare: Passenger fare\n\n        Cabin: Cabin number\n\n        Embarked: Port of Embarkation -> C = Cherbourg, Q = Queenstown, S = Southampton\n\n\n\n    ","e39f4b4c":"### Fare","16e90916":"# **Data Preparation**","a94c4ef7":"### AgeGroup","fdf88cc5":"## Variable Transformation","c83b4b9d":"## Visualization","4c91174c":"In this challenge, we ask you to build a predictive model that answers the question: \u201cwhat sorts of people were more likely to survive?\u201d using passenger data (ie name, age, gender, socio-economic class, etc).\n","9932fc00":"### Embarked & Title","1c1ae005":"## Modeling","24ad289a":"### Name - Title","f5cd878a":"## Spliting the train data","00854328":"### Sex","55f6ff83":"### Fare","30281d21":"### Family Size","2de2d66a":"## Model tuning","28d4662e":"# Machine Learning","0064fd62":"# Data Understanding ","c090e819":"## Missing Value Treatment","e3aaf9a5":"### Pclass","72e674bd":"# \u0130ntroduction","c7941261":"### Cabin","888bdc9c":"## **Importing Librarires and Loading Data**","a09dca10":"## deployment","f2e64d43":"### Embarked","2caf141d":"### Embarked","1ea4d8fa":"## Feature Analysis"}}