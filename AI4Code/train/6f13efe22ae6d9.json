{"cell_type":{"bc272043":"code","62d03cd7":"code","18ec7aeb":"code","f867f536":"code","4af74cc5":"code","86208319":"code","d7bda187":"code","69bb5729":"code","52df75cc":"code","820177e0":"code","89607f47":"code","b6884347":"code","86ccfcfe":"code","582ab552":"code","7a6a1e0d":"code","a8b001d1":"code","a46f60ee":"code","24065943":"code","fcd5f50d":"code","0c69c710":"code","d8ada9ba":"code","a62c21c6":"code","32951c6c":"markdown","75003295":"markdown","19ea710f":"markdown","2d25f3e5":"markdown","a5176b03":"markdown","563fc913":"markdown","40fa7ffa":"markdown","b3030369":"markdown","41560cc9":"markdown","a8f542df":"markdown","51dd760f":"markdown","38c80dec":"markdown","f8956818":"markdown","59e7fc24":"markdown","86f84ea5":"markdown","4cbd874c":"markdown","fc3b4123":"markdown","2de084c3":"markdown","93651b03":"markdown","bd110c9b":"markdown"},"source":{"bc272043":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\n\nimport os\nimport random\nimport keras\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau","62d03cd7":"import zipfile\nwith zipfile.ZipFile(\"..\/input\/dogs-vs-cats\/train.zip\",'r') as z:\n    z.extractall(\".\")\nwith zipfile.ZipFile(\"..\/input\/dogs-vs-cats\/test1.zip\",'r') as z:\n    z.extractall(\".\")","18ec7aeb":"filenames = os.listdir('\/kaggle\/working\/train')\ncategories = []\nfor filename in filenames:\n    category = filename.split('.')[0]\n    if category == 'dog':\n        categories.append(str(1))\n    else:\n        categories.append(str(0))\n\ndf = pd.DataFrame({\n    'filename': filenames,\n    'category': categories\n})","f867f536":"df['category'] = df[\"category\"].replace({0: 'cat', 1: 'dog'}) ","4af74cc5":"df.head() , df.tail()","86208319":"sns.countplot(df['category'], palette='cool')","d7bda187":"sample = filenames[473]\nimage = load_img(\"\/kaggle\/working\/train\/\"+sample)\nplt.imshow(image)","69bb5729":"train_data, valid_data = train_test_split(df, test_size=0.2, random_state = 42)\ntrain_data = train_data.reset_index(drop=True)\nvalid_data = valid_data.reset_index(drop=True)","52df75cc":"train_data_gen = ImageDataGenerator(\n    rotation_range=15,\n    rescale=1.\/255,\n    shear_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    width_shift_range=0.1,\n    height_shift_range=0.1\n)","820177e0":"train_generator = train_data_gen.flow_from_dataframe(\n    train_data, \n    \"\/kaggle\/working\/train\/\", \n    x_col='filename',\n    y_col='category',\n    target_size=(128,128),\n    class_mode='categorical',\n    batch_size=15\n)","89607f47":"valid_data_gen = ImageDataGenerator(rescale=1.\/255)\n\nvalid_generator = valid_data_gen.flow_from_dataframe(\n    valid_data, \n    \"\/kaggle\/working\/train\/\", \n    x_col='filename',\n    y_col='category',\n    target_size=(128,128),\n    class_mode='categorical',\n    batch_size=15\n)","b6884347":"model = keras.models.Sequential([\n                         keras.layers.Conv2D(filters=64, kernel_size=3, strides=(1,1), padding='valid',activation= 'relu', input_shape=(128,128,3)),\n                         keras.layers.MaxPooling2D(pool_size=(2,2)),\n                         keras.layers.Conv2D(filters=128, kernel_size=3, strides=(2,2), padding='same', activation='relu'),\n                         keras.layers.MaxPooling2D(pool_size=(2,2)),\n                         keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2,2), padding='same', activation='relu'),\n                         keras.layers.MaxPooling2D(pool_size=(2,2)),\n                         keras.layers.Flatten(),\n                         keras.layers.Dense(units=128, activation='relu'),\n                         keras.layers.Dropout(0.25),\n                         keras.layers.Dense(units=256, activation='relu'),\n                         keras.layers.Dropout(0.5),\n                         keras.layers.Dense(units=256, activation='relu'),\n                         keras.layers.Dropout(0.25),                        \n                         keras.layers.Dense(units=128, activation='relu'),\n                         keras.layers.Dropout(0.10),                         \n                         keras.layers.Dense(units=2, activation='softmax')\n])\nmodel.summary()","86ccfcfe":"keras.utils.plot_model(model, 'model.png')","582ab552":"model.compile(optimizer='adam', loss= 'categorical_crossentropy', metrics=['accuracy'])","7a6a1e0d":"earlystop = EarlyStopping(patience = 10)\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=2, verbose=1, factor=0.5, min_lr=0.00001)\ncallbacks = [earlystop, learning_rate_reduction]","a8b001d1":"total_train = train_data.shape[0]\ntotal_validate = valid_data.shape[0]\nbatch_size=15\nepochs=30","a46f60ee":"history = model.fit(train_generator, epochs=epochs, verbose=1, validation_data=valid_generator,\n                   validation_steps=total_validate\/\/batch_size,\n                   steps_per_epoch=total_train\/\/batch_size,\n                   callbacks=callbacks) ","24065943":"model.save('cat-vs-dog-model.h5')","fcd5f50d":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\nax1.plot(history.history['loss'], color='b', label=\"Training loss\")\nax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\nax1.set_xticks(np.arange(1, epochs, 1))\nax1.set_yticks(np.arange(0, 1, 0.1))\n\nax2.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax2.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nax2.set_xticks(np.arange(1, epochs, 1))\n\nlegend = plt.legend(loc='best', shadow=True)\nplt.tight_layout()\nplt.show()","0c69c710":"nb_samples = valid_data.shape[0]\npredict = model.predict(valid_generator, steps=np.ceil(nb_samples\/batch_size))","d8ada9ba":"valid_data['category'] = np.argmax(predict, axis=-1)\nlabel_map = dict((v,k) for k,v in train_generator.class_indices.items())\nvalid_data['category'] = valid_data['category'].replace(label_map)\nvalid_data['category'] = valid_data['category'].replace({ 'dog': 1, 'cat': 0 })","a62c21c6":"# make a prediction for a new image.\n\nsample = filenames[60]\nimage = load_img(\"\/kaggle\/working\/train\/\"+sample, target_size=(128,128))\n\nimg = img_to_array(image)\nimg = img.reshape(1, 128, 128, 3)\nimg = img.astype('float32')\n\nresult = model.predict(img)\nresult = np.argmax(result, axis=-1)\n\nif result == 0:\n    print(\"It's a Cat.\")\nelse:\n    print(\"It's a Dog.\")\n    \nplt.imshow(image)","32951c6c":"![download.png](attachment:520a7d7b-77a4-4fef-9558-c0ecdda8eb45.png)","75003295":"## Callbacks","19ea710f":"## Splitting of Dataset","2d25f3e5":"![download.png](attachment:de574804-1f50-4b1f-8661-9f19a253dfb9.png)","a5176b03":"## Extracting Files","563fc913":"![download.png](attachment:0be8ceb3-0daf-499f-a809-bf539b5669c6.png)","40fa7ffa":"## Saving Model","b3030369":"## Model Training","41560cc9":"## Exploratory Data Analysis","a8f542df":"## *Deep CNN Model*","51dd760f":"![Sample Image](attachment:300429cd-73da-49c1-9126-e8f4381b5f7e.png)","38c80dec":"## Generating Training Data","f8956818":"## Model Plotting","59e7fc24":"##### This will show how our model architecture looks like in the form of an image.","86f84ea5":"## Generating Validation Data","4cbd874c":"## Visualizing Data\n##### Run this cell again and again, it will randomly show image from our dataset.","fc3b4123":"## Cat vs Dog\n![](https:\/\/storage.googleapis.com\/petbacker\/images\/blog\/2017\/dog-and-cat-cover.jpg)","2de084c3":"## Model Testing","93651b03":"## Importing Required libraries","bd110c9b":"![](https:\/\/www.kaggleusercontent.com\/kf\/83339988\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..OoD3pShREofW9RIKSxkxqQ.ib5uZ1oEnBQ84_IFiN2dhTnWsu3dg3sgq9B8nC038eKD80EctLNsJT6FmBzAENC-4y1xpEO_sttfF9X3In7U13KhpWOg0Tew-RV5VG8X_IEpPfGHeBl759zgTL91WraUpnbEFEiyUDOd-re1ayrfoYiSsi6-OFHdC6osNCMFUiXriZsfkjYMod2uYpldQAzhtCNIIjVgVkdUP5db3KBozW-LAxsOSRmbfrZtdqnOIe-ypjXLVyKrBwugIMUVcya3CT-dym0ztY1vu60Pl3ENMAI1TdaORnx690PvFE7VgLCfAsf8BhUljSdmTnifBMVb8LIsG0i__35Rgt3aHaHaZ5xgrOPKI4RUFpXyY39ET3qE3q_U0S2xvH46CId0TD_CWZuVx17-KyhYwHUBKcFzOTrB7zunf7jTHbUWDi0rMlRCq7LWSq_OweR-4OP_fRrGc9Rf64dXhjStmtGCbdjXAO2Bj_Q5BcUFCzzS3xS5sqzYs0NsenrlFFJeZ1IG7lD2NJX2KiuJBsXZGpU74HgtPUk1NGYREWZSKtSkkoPjwoIO78MJq0WJ5eepgeHX1koTgob0wdFuFvbP0X0OOrDGb70x0WKjhVPg-_f2be_XwfKUW4jG4S472ZzkFsSVhh0OMkVEr3xBi03zP8FiYKhS8AAO4slPb0oOaA6NiBSG6iMrnmdBAw1VxxsvIFvHnFceqw6AAAIlphNbAdILuPKLmw.mvOImk3jGmNo3HEtkjau6A\/__results___files\/__results___32_0.png)"}}