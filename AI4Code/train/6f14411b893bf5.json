{"cell_type":{"8bfde1b9":"code","b989d792":"code","d46151ca":"code","3efc6b0c":"code","bab54761":"code","4442124b":"code","3c91c032":"code","7177a246":"code","03b1676e":"code","6b0c627f":"code","c9b8cdc0":"code","e67be265":"code","127fea7f":"code","b5afa238":"code","8df961c3":"code","aecaf5c5":"code","fe75f530":"code","32007bc7":"code","e2b1e267":"code","f1291c97":"code","92b3692e":"code","6966f10d":"code","a5926537":"code","ddd42eec":"code","6ecb6b47":"code","dc35189c":"code","378544ce":"code","a333db1a":"code","ca101f6a":"code","ecdfaf1f":"code","542a9710":"code","68446417":"code","cf00a61f":"code","e92b78da":"code","1d29bd7b":"code","f55808e4":"code","a7ab0644":"code","89d7f995":"code","e35cf000":"code","207d6784":"code","44741981":"code","7ee6497e":"code","a0b47d33":"code","b8c3e240":"code","62312b6d":"code","100bcc95":"code","13c404fa":"code","53dabce6":"code","77e184bf":"code","2b0e6e8c":"code","ea24b400":"code","22fc85fe":"code","8661fe15":"code","af200b4e":"code","9b9116f3":"code","938b94b6":"code","321457f4":"code","b3aa1a03":"code","bef42aea":"code","4f7e8ed4":"code","93437a44":"code","f5fdb93d":"code","669786fd":"code","40fb1f09":"code","4d0faafe":"code","6a7e89b6":"code","56d13875":"code","8ea42c26":"code","48c3b900":"code","d3b2c46f":"code","35f0a600":"code","67ae7556":"code","bedd9323":"code","14d8c297":"code","dbe53997":"code","d5488f60":"code","1a68fbb1":"code","b04e9aab":"code","94e25032":"code","b0e04b29":"code","3f2ba2e9":"code","c454b2c5":"code","81761c29":"code","7126d89d":"code","ba8fe617":"code","13a4ac6f":"code","035fb3aa":"code","cc2b7b5a":"code","43e2194f":"code","179c1cb9":"code","b083dbdd":"code","a4cfc7f0":"code","374877fe":"markdown","3b808ee0":"markdown","30cde00b":"markdown","ef88d1cc":"markdown","65c1f1f4":"markdown","65f55cb3":"markdown","2003356c":"markdown","67e49da0":"markdown","6dc03330":"markdown","a5e37d3f":"markdown","bc11984f":"markdown","3b13b3ec":"markdown","c7a5120f":"markdown","5007a8a9":"markdown","a0e1e886":"markdown","b2536cfd":"markdown","6a1c8f5c":"markdown","475c4361":"markdown","d852bea4":"markdown","1eb57aaf":"markdown","ee3f4f34":"markdown","c8df3672":"markdown","cd4aa4dd":"markdown","d2bc13d0":"markdown","e49f3d74":"markdown","de5e17fd":"markdown","cf90fbde":"markdown","9f365d8e":"markdown","86f046e1":"markdown","b4482a65":"markdown","2a500a3b":"markdown","24ddf8b7":"markdown","75b8fb5a":"markdown","e3cdb8b6":"markdown","c101091f":"markdown","d6c5f8f4":"markdown","dc48735c":"markdown","cae5bdd9":"markdown","dbbd2b92":"markdown","674a550d":"markdown","6921941e":"markdown","a66a9d95":"markdown","08af2cb3":"markdown","82c176b9":"markdown","8a66e131":"markdown","7eb9fd5a":"markdown","8526b26d":"markdown","1fddc8ef":"markdown","1556863a":"markdown","2bcded5b":"markdown","adad9bb9":"markdown","a40b990c":"markdown","00e3778f":"markdown","698b0384":"markdown","64771e24":"markdown","a0308efc":"markdown","3d84f77c":"markdown","0099f519":"markdown","ebe77a39":"markdown","155c0475":"markdown","30e154ec":"markdown","2cb79a70":"markdown","ea9941fc":"markdown","de3cf905":"markdown","0b51db75":"markdown","74c4c3d7":"markdown"},"source":{"8bfde1b9":"import numpy as np\nimport pandas as pd\n\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")","b989d792":"train.head()","d46151ca":"train.tail()","3efc6b0c":"train.shape","bab54761":"train.info()","4442124b":"train.describe().T","3c91c032":"test.shape","7177a246":"train.corr()","03b1676e":"train.isna().any()","6b0c627f":"train.isnull().sum()","c9b8cdc0":"train_size = train.shape[0]\ndf = pd.concat([train, test], axis=0)","e67be265":"df","127fea7f":"df.info()","b5afa238":"df.isnull().sum()","8df961c3":"df.groupby('Sex').nunique()","aecaf5c5":"df['Female'] = (df['Sex'] == 'female').astype(int)","fe75f530":"df.info()","32007bc7":"train = df[0:train_size]","e2b1e267":"train[['Female','Survived']].groupby(['Female']).mean()","f1291c97":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","92b3692e":"g =sns.catplot(x=\"Female\", y=\"Survived\", data=train, kind=\"bar\", ci=None)\ng.set(ylim=(0, 1))\nplt.title(\"Survival Rate for Men and Women\");","6966f10d":"train[['Pclass','Survived']].groupby(['Pclass']).mean()","a5926537":"g = sns.catplot(x=\"Pclass\", y=\"Survived\", data=train, kind=\"bar\", ci=None)\ng.set_axis_labels(\"Pclass\", \"Survival Rate\").set(ylim=(0, 1))\nplt.title(\"Survival Rate for First, Second, and Third Class Passengers\");","ddd42eec":"g = sns.catplot(x=\"Sex\", y=\"Survived\", col=\"Pclass\",\n                    data=train, saturation=.5,\n                    kind=\"bar\", ci=None, aspect=.6)\n(g.set_axis_labels(\"\", \"Survival Rate\")\n    .set_xticklabels([\"Men\", \"Women\"])\n    .set_titles(\"{col_name} {col_var}\")\n    .set(ylim=(0, 1))\n    .despine(left=True))  \nplt.subplots_adjust(top=0.8)","6ecb6b47":"df['Age'].describe()","dc35189c":"plt.hist([df['Age']], bins=81, range=(0,81))\nplt.title(\"Age histogram\")\nplt.xlabel(\"Age\")\nplt.ylabel(\"Count\");","378544ce":"g = sns.FacetGrid(train, col=\"Female\", row=\"Survived\", margin_titles=True)\ng = g.map(plt.hist, \"Age\")\ng.set_axis_labels(\"\", \"Count\");","a333db1a":"train.Embarked.value_counts().plot(kind='bar', alpha=0.55)\nplt.title(\"Passengers per boarding location\")\nplt.ylabel(\"Count\")\n\ng = sns.catplot(x = 'Embarked',y=\"Survived\", data = train,kind='point')\n\ng.set(ylim=(0, 1))\ng.set_axis_labels(\"\", \"Survival Rate\");","ca101f6a":"# Start on getting info from people's names\n# Strip quotes out of people's names\ndf['NameFixed'] = df['Name'].str.replace('\\\"','').str.strip()","ecdfaf1f":"df.iloc[875].Name","542a9710":"df.iloc[875].NameFixed","68446417":"titlemap = {'Mr': 1, 'Don': 2, 'Dona': 2, 'Jonkheer': 2, 'Capt' :2, 'Col': 2, 'Major': 2, 'Countess': 2,  \n            'Rev': 2, 'Sir': 2, 'Lady': 2, 'Dr': 3,  'Master': 4, 'Mme': 5, 'Miss': 5,'Mrs': 6, 'Mlle': 7, 'Ms': 8 }\n\n#titleLabels = {1: 'Mr', 2: 'Special', 3: 'Dr', 4: 'Master', 5: 'Mme\/Miss', 6: 'Mrs', 7: 'Mlle', 8:'Ms' }\ntitleLabels = ['Mr', 'Special', 'Dr', 'Master', 'Mme\/Miss', 'Mrs', 'Mlle', 'Ms']\ndf['Title'] = df['NameFixed'].str.extract('([A-Za-z]+)\\.', expand=False)\ndf['TitleCat'] = df['Title'].map(titlemap)","cf00a61f":"g = sns.catplot(x=\"TitleCat\",data=df, kind=\"count\", ci=None)\ng.set_xticklabels(titleLabels, rotation=45, horizontalalignment='right')\nplt.title(\"Passengers per Title Category\");","e92b78da":"for atitle in ['Miss','Mr', 'Mrs', 'Master', 'Dr', 'Ms']:    \n    df.loc[ (df['Age'].isnull()) & (df['Title'] == atitle), 'Age'] = df[ (df['Title'] == atitle) ]['Age'].median()","1d29bd7b":"df.isnull().sum()","f55808e4":"df.loc[df.Fare.isnull()]","a7ab0644":"df.loc[df.Fare.isnull(), 'Fare'] = df[ df.Pclass==3].Fare.median()","89d7f995":"df.loc[df.PassengerId==1044]","e35cf000":"df[\"Deck\"]=df.Cabin.str[0]","207d6784":"df[\"Deck\"].unique()","44741981":"g = sns.catplot(x=\"Survived\", col=\"Deck\", col_wrap=4,\n                    data=df[df.Deck.notnull() & df.Survived.notnull()],\n                    kind=\"count\", height=2.5, aspect=.8)\ng.fig.subplots_adjust(top=0.87)\ng.fig.suptitle(\"Number of Passengers that survived per Deck\");","7ee6497e":"df.Deck.fillna('Z', inplace=True)","a0b47d33":"df[df['Embarked'].isnull()]","b8c3e240":"df[\"Embarked\"] = df[\"Embarked\"].fillna('C')","62312b6d":"embarkedmap = {'S':0, 'Q':1, 'C': 2}\ndf['EmbarkedCat'] = df['Embarked'].map(embarkedmap)","100bcc95":"df.info()","13c404fa":"g = sns.catplot(x=\"TitleCat\", y=\"Survived\", data=df[df.Survived.notnull()], kind=\"bar\")\ng.set(ylim=(0, 1))\ng.set_xticklabels(titleLabels, rotation=45, horizontalalignment='right')\ng.fig.subplots_adjust(top=0.87)\ng.fig.suptitle(\"Survival Rate for each Title Category\");","53dabce6":"deckmap = {'T': 0, 'Z': 1, 'A': 2, 'G': 3, 'C': 4, 'F': 5, 'B' :6, 'E': 7, 'D': 8}\ndf['DeckCat'] = df['Deck'].map(deckmap)\n\ng = sns.catplot(x=\"DeckCat\", y=\"Survived\", data=df[df.Survived.notnull()], kind=\"bar\")\ng.set(ylim=(0, 1))\ng.fig.subplots_adjust(top=0.87)\ng.fig.suptitle(\"Survival Rate for each Deck Category\");","77e184bf":"df['NameLength'] = df.Name.fillna('').str.len()","2b0e6e8c":"df['NameLength'].describe()","ea24b400":"plt.hist([df['NameLength']], bins=15, range=(0,83))\nplt.title('Name Length Histogram');","22fc85fe":"grouped = df.groupby(['Survived'])\ngroup0 = grouped.get_group(0)\ngroup1 = grouped.get_group(1)\nplt.hist([group0.NameLength, group1.NameLength], bins=16, range=(0,83), stacked=False, \n        label=['Not Survived', 'Survived'], alpha=0.6)\nplt.legend(loc='best', fontsize='small')\nplt.title('Survival distribution by NameLength');","8661fe15":"df['FamilySize'] = df['SibSp'] + df['Parch']","af200b4e":"g = sns.catplot(x=\"FamilySize\", y=\"Survived\", data=df[df.Survived.notnull()], kind=\"bar\")\ng.set_axis_labels(\"Additional Family Members\", \"Survival Rate\").set(ylim=(0, 1));","9b9116f3":"df['FamilySize'].describe()","938b94b6":"familysizemap = {0: 1, 1: 2, 2: 2, 3: 2, 4: 0, 5: 0, 6:0, 7:0, 8:0, 9:0, 10:0}\nfamilysizeLabels = {'Large Family', 'Alone', 'Small Family'}\ndf['FamilySizeCat'] = df['FamilySize'].map(familysizemap)","321457f4":"g = sns.catplot(x=\"FamilySizeCat\", y=\"Survived\", data=df[df.Survived.notnull()], kind=\"bar\")\ng.set_axis_labels(\"FamilySizeCat\", \"Survival Rate\").set(ylim=(0, 1))\ng.set_xticklabels(familysizeLabels, rotation=45, horizontalalignment='right');","b3aa1a03":"from sklearn.preprocessing import StandardScaler\n\ndrop_columns = ['PassengerId', 'Name', 'Sex', 'Ticket', 'Cabin', 'Embarked', 'NameFixed', 'Title', 'Deck', 'FamilySize']\nX_trainFull = df.drop(drop_columns, axis=1).iloc[:train_size]\nX_trainx = df.drop(drop_columns + ['Survived'], axis=1).iloc[:train_size]\nX_train = StandardScaler().fit_transform(X_trainx)\ny_train = df['Survived'].iloc[:train_size]\nX_testx  = df.drop(drop_columns + ['Survived'], axis=1).iloc[train_size:]\nX_test = StandardScaler().fit_transform(X_testx)","bef42aea":"X_trainx.info()","4f7e8ed4":"X_trainx.describe()","93437a44":"X_trainx.head()","f5fdb93d":"f, ax = plt.subplots(figsize = [25,16])\nsns.heatmap(X_trainFull.corr(),linewidths = .5, annot = True, cmap = 'YlGnBu', square = True);","669786fd":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier, plot_importance ","40fb1f09":"clf_rf = RandomForestClassifier()\nclf_et = ExtraTreesClassifier()\nclf_bc = BaggingClassifier()\nclf_ada = AdaBoostClassifier()\nclf_dt = DecisionTreeClassifier()\nclf_xg = XGBClassifier()\nclf_lr = LogisticRegression()\nclf_svm = SVC()","4d0faafe":"Classifiers = ['RandomForest','ExtraTrees','Bagging','AdaBoost','DecisionTree','XGBoost','LogisticRegression','SVM']\nscores = []\nmodels = [clf_rf, clf_et, clf_bc, clf_ada, clf_dt, clf_xg, clf_lr, clf_svm]\nfor model in models:\n    score = cross_val_score(model, X_train, y_train, scoring = 'accuracy', cv = 10, n_jobs = -1).mean()\n    scores.append(score)","6a7e89b6":"mode = pd.DataFrame(scores, index = Classifiers, columns = ['score']).sort_values(by = 'score',\n             ascending = False)","56d13875":"mode","8ea42c26":"parameters_xg = {'objective':['binary:logistic'], 'max_depth':[3,6,7], 'learning_rate': [0.1,0.2], 'n_estimators': [300,200], \n                 'min_child_weight': [4], 'reg_alpha': [6,0], 'reg_lambda': [1,8],'max_delta_step':[2],\n                 'gamma':[0],'seed':[1],'use_label_encoder':[False],'eval_metric':['logloss']}\n\nparameters_svm = {'C':[0.9,0.01],'kernel':['rbf','linear'], 'gamma':[0,0.1,'auto'], 'probability':[True,False],\n                  'random_state':[0,7,16],'decision_function_shape':['ovo','ovr'],'degree':[3,4,10]}\n\nparameters_rf = {'n_estimators': [100,50], 'max_features': [7,'auto',None],\n                 'n_jobs': [-1], 'min_samples_leaf': [2,4,], 'random_state':[1,7,], \n                 'min_samples_split':[2,6,], 'oob_score': [True,False],\n                 'criterion': ['gini'], 'warm_start': [False]}","48c3b900":"def grid(model,parameters):\n    grid = GridSearchCV(estimator = model, param_grid = parameters, cv = 10, \n                        scoring = 'accuracy')\n    grid.fit(X_train,y_train)\n    return grid.best_score_, grid.best_estimator_.get_params()","d3b2c46f":"def imp_features(model, model_name, params):\n    Model = model(**params)\n    Model.fit(X_train,y_train)\n    names = X_trainx.columns\n    feature = Model.feature_importances_\n    important_features = pd.Series(data = feature, index = names,)\n    important_features = important_features.sort_values(ascending = True)\n    return important_features.plot(kind = 'barh', grid = False,title = model_name)","35f0a600":"best_score_xg, best_params_xg = grid(clf_xg,parameters_xg)\nimp_features(XGBClassifier, 'XGBoostClassifier', best_params_xg);","67ae7556":"print(f\"The best score for XGBoost is: {best_score_xg:.4f}\")","bedd9323":"best_score_rf, best_params_rf = grid(clf_rf, parameters_rf)\nprint(f\"The best score for Random Forest is: {best_score_rf:.4f}\")\nimp_features(RandomForestClassifier,'Random Forest', best_params_rf);","14d8c297":"best_score_svm, best_params_svm = grid(clf_svm, parameters_svm)\nprint(f\"The best score for SVM is: {best_score_svm:.4f}\")","dbe53997":"clf_rf_best = RandomForestClassifier(**best_params_rf)\nclf_xg_best = XGBClassifier(**best_params_xg)\nclf_svm_best = SVC(**best_params_svm)","d5488f60":"from sklearn.ensemble import VotingClassifier\n\nclf_e = VotingClassifier(estimators=[('xg', clf_xg_best), ('rf', clf_rf_best), ('svm', clf_svm_best)], voting='hard')","1a68fbb1":"best_scores = []\nbest_models = [clf_rf_best, clf_et, clf_bc, clf_ada, clf_dt, clf_xg_best, clf_lr, clf_svm_best, clf_e]\nfor model in best_models:\n    score = cross_val_score(model, X_train, y_train, scoring = 'accuracy', cv = 10, n_jobs = -1).mean()\n    best_scores.append(score)","b04e9aab":"NewClassifiers = ['RandomForest','ExtraTrees','Bagging','AdaBoost','DecisionTree','XGBoost','LogisticRegression','SVM','Ensemble']\nmode = pd.DataFrame(best_scores, index = NewClassifiers, columns = ['score']).sort_values(by = 'score',\n             ascending = False)","94e25032":"mode\n","b0e04b29":"best_scores = []\nbest_models = [clf_rf_best, clf_et, clf_bc, clf_ada, clf_dt, clf_xg_best, clf_lr, clf_svm_best]\nfor model in best_models:\n    score = cross_val_score(model, X_train, y_train, scoring = 'roc_auc', cv = 10, n_jobs = -1).mean()\n    best_scores.append(score)\nmode = pd.DataFrame(best_scores, index = Classifiers, columns = ['score']).sort_values(by = 'score',\n             ascending = False)\nmode","3f2ba2e9":"#clf_e.fit(X_train, y_train)\n#clf_xg_best.fit(X_train, y_train)\n#clf_rf_best.fit(X_train, y_train)\n#clf_svm_best.fit(X_train, y_train)\nclf_lr.fit(X_train, y_train)\n\n\n#preds = clf_e.predict(X_test).astype(int) # 0.78468\n#preds = clf_xg_best.predict(X_test).astype(int) #0.77033\n#preds = clf_rf_best.predict(X_test).astype(int) # 0.79186\n#preds = clf_svm_best.predict(X_test).astype(int) #0.77272\npreds = clf_lr.predict(X_test).astype(int) # 0.77511\n\npredictions = pd.DataFrame()\npredictions['PassengerId'] = test['PassengerId']\npredictions['Survived'] = preds\npredictions.set_index('PassengerId', inplace=True, drop=True)\npredictions.to_csv('lr_jup2.csv')\nprint(\"Done\")","c454b2c5":"from sklearn.metrics import roc_curve, auc\nfrom sklearn.model_selection import train_test_split\n\n# Set up new training set and test set for ROC curve analysis\nroc_X_train, roc_X_test, roc_y_train, roc_y_test = train_test_split(X_train, y_train, test_size=.25, random_state=42)\n\n# Re-train models on the new training set\nclf_rf_roc = RandomForestClassifier(**best_params_rf)\nclf_rf_roc.fit(roc_X_train, roc_y_train)\nclf_xg_roc = XGBClassifier(**best_params_xg)\nclf_xg_roc.fit(roc_X_train, roc_y_train)\nclf_svm_roc = SVC(**best_params_svm)\nclf_svm_roc.fit(roc_X_train, roc_y_train)\nclf_lr_roc = LogisticRegression()\nclf_lr_roc.fit(roc_X_train, roc_y_train)","81761c29":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\n\nbest_models = [clf_rf_roc, clf_svm_roc, clf_lr_roc, clf_xg_roc]\nmodel_names = ['Random Forest', 'SVM', 'Linear Regression', 'XGBoost']\n\nconf = []\nfor model in best_models:\n    conf.append(confusion_matrix(roc_y_test, model.predict(roc_X_test)))","7126d89d":"fig = plt.figure(figsize=(16,4))\nfor i, model in enumerate(best_models):\n    plt.subplot(1, len(best_models), i+1)\n    sns.heatmap(conf[i], annot = True, fmt='d')\n    plt.title(model_names[i])\n    plt.xlabel(\"Prediction: (0 = Perished. 1 = Survived)\")\n    if i==0:\n        plt.ylabel('True Value')    ","ba8fe617":"conf_scores = []\nfor c in conf:\n    precision   = c[1,1] \/ sum(c[:,1])\n    recall      = c[1,1] \/ sum(c[1,:])\n    specificity = c[0,0] \/ sum(c[0,:])\n    f1_score    = 2*precision*recall \/ (precision + recall)\n    conf_scores.append([precision, recall, specificity, f1_score])\n\nconf_score_names = [\"Precision\", \"Sensitivity\", \"Specificity\", \"F1\"]  \npd.options.display.precision = 3\nprint(pd.DataFrame(conf_scores, model_names, conf_score_names))","13a4ac6f":"fig = plt.figure(figsize=(16,4))\nfor i, model in enumerate(best_models):\n    plt.subplot(1, len(best_models), i+1)\n    # Determine the false positive and true positive rates\n    fpr, tpr, thresholds = roc_curve(roc_y_test, model.predict_proba(roc_X_test)[:,1])\n    # Calculate the AUC\n    roc_auc = auc(fpr, tpr)\n    plt.plot(fpr, tpr, label='ROC curve (AUC = %0.3f)' % roc_auc)\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    if i==0:\n        plt.ylabel('True Positive Rate')\n    plt.legend(loc=\"lower right\")\n    plt.title(model_names[i])","035fb3aa":"def model_pred(model, s):\n    model.fit(roc_X_train[0:s], roc_y_train[0:s])\n    modelpredtest = model.predict(roc_X_test)\n    modelpredtraining = model.predict(roc_X_train[0:s])\n    return accuracy_score(roc_y_test, modelpredtest), accuracy_score(roc_y_train[0:s], modelpredtraining)","cc2b7b5a":"max_restricted_training_size = len(roc_X_train)\ntraining_sizes = np.arange(2,max_restricted_training_size, 20)\naccuracy_training = []\naccuracy_test = []\nbest_models = [clf_rf_roc, clf_svm_roc, clf_lr_roc, clf_xg_roc]\nmodel_names = ['Random Forest', 'SVM', 'Linear Regression', 'XGBoost']\n\nfor model in best_models:\n    y1 = np.zeros(training_sizes.shape)\n    y2 = np.zeros(training_sizes.shape)\n    for key, m in enumerate(training_sizes):\n        y1[key], y2[key] = model_pred(model, m)\n    accuracy_test.append(y1)\n    accuracy_training.append(y2)","43e2194f":"fig = plt.figure(figsize=(16,4))\nfor i, model in enumerate(best_models):\n    plt.subplot(1, len(best_models), i+1)\n    plt.plot(training_sizes, accuracy_training[i])\n    plt.plot(training_sizes, accuracy_test[i])\n    plt.plot(training_sizes, np.array([0.85 for j in range(len(training_sizes))]), 'k--')\n    plt.ylim([0.0, 1.0])\n    plt.xlabel('Size of training set')\n    if i==0:\n        plt.ylabel('Accuracy')\n    plt.title(model_names[i])\n    plt.legend(['Training Accuracy', 'Test Accuracy', 'Desired Performance'], loc=\"lower right\")","179c1cb9":"imp_features(RandomForestClassifier,'Random Forest', best_params_rf);","b083dbdd":"drop_order = ['Parch', 'EmbarkedCat', 'SibSp', 'FamilySizeCat', 'DeckCat', 'Age', 'Pclass', 'NameLength', 'Fare', 'Female']\n\naccuracies = []\n\ndef dropandreport(i):\n    X_trainx_reduced = X_trainx.drop(drop_order[0:i], axis=1)\n    X_train_reduced = StandardScaler().fit_transform(X_trainx_reduced)\n    roc_X_train_reduced, roc_X_test_reduced, roc_y_train_reduced, roc_y_test_reduced = train_test_split(X_train_reduced, y_train, test_size=.25, random_state=42)\n    clf_rf_roc_reduced = RandomForestClassifier(**best_params_rf)\n    clf_rf_roc_reduced.fit(roc_X_train_reduced, roc_y_train_reduced)\n    roc_pred_reduced = clf_rf_roc_reduced.predict(roc_X_test_reduced)\n    accuracy_score_reduced = accuracy_score(roc_y_test_reduced, roc_pred_reduced)\n    accuracies.append(accuracy_score_reduced)\n\n# Accuracy with all features\ndropandreport(0)\n# Drop features iteratively and see how accuracy changes\nfor i in range(len(drop_order)):\n    dropandreport(i+1)","a4cfc7f0":"x_pos = [i for i, _ in enumerate([\"Full Data\"] + drop_order)]\nplt.bar([\"Full Data\"] + drop_order, accuracies)\nplt.ylim([0.7, 1.0])\nplt.xticks(x_pos, [\"Full Data\"] + drop_order)\nplt.setp(plt.gca().get_xticklabels(), rotation=45, horizontalalignment='right')\nplt.ylabel('Accuracy')\nplt.title(\"Error Analysis: Accuracy as we remove features one by one in a Random Forest model\");","374877fe":"We now have filled in non-null values everywhere (other than the test set which doesn't have the `Survived` value, and the `Cabin` field which we will drop, since we put information from the `Cabin` into the `Deck` feature):","3b808ee0":"In the graph below, the first bar is the accuracy with all features (Full Data). Subsequent bars show the accuracy of the Random Forest model after the feature in the bar has been removed.","30cde00b":"Check our data has the columns we want, and the data is not null and in numeric fields:","ef88d1cc":"Let's check out if deck shows any information on whether people survived or not:","65c1f1f4":"This shows first and second class women were very likely to survive. Men in first class were much more likely to survive than men in second and third class.\n\nNext look at age:","65f55cb3":"##### 3.5: Submitting predictions to Kaggle to obtain test set results\n\nSubmitting predictions from our top models to [Kaggle](https:\/\/www.kaggle.com\/c\/titanic\/submit) for the test set yielded Random Forest giving our top score at 79.186% accuracy when first run:","2003356c":"Now let's investigate `Pclass`. What did a person's class indicate in terms of survival in the training set?","67e49da0":"So ages ranged from 0 to 80.","6dc03330":"Let's look at the ages of men and women who survived and those that didn't in the training set:","a5e37d3f":"For XGBoost, we can see what it considers the most important classifiers, which are `TitleCat` and `Pclass`:","bc11984f":"Since they are first class women who survived, we'll just say they embarked at Cherbourg, which had the highest probability of survival.","3b13b3ec":"So we'll want to fill in the missing null values in four fields: `Age`, `Fare`, `Cabin`, and `Embarked`. The null values in the `Survived` field are from the test set.\n\nNow let's analyse the columns to gain insight from them. We'll start with the \"Sex\" Column, as it likely has good predictive information on whether the passenger survived. We'll make the new feature: `Female` as binary 1 and 0 to make it easier for classitication models.","c7a5120f":"#### Step 5: Error Analysis\nAnother diagnostic to perform is error analysis. Let's take the important features in the Random Forest model and iteratively remove the least important feature to see how this affects prediction accuracy.","5007a8a9":"There's data missing in the `Age`, `Cabin`, and `Embarked` fields, so we'll have to do data cleaning. Let's see how much data is missing for each field:\n","a0e1e886":"We can check that the feature was added correctly with 1309 non-null entries:","b2536cfd":"Here is the number of people in each title category:","6a1c8f5c":"Looks like Pclass and Fare are most correlated with survival in this preliminary analysis. This makes sense, as Pclass is a proxy of socio-econic status (1 = Upper; 2 = Middle; 3 = Lower). Fare also would be linked to class, as we'd assume first class tickets would cost more.\n\nThis matrix includes only numeric fields, and thus leaves out important information like the gender of the passenger.\n\nNow, let's check if there is any data missing in the fields:","475c4361":"From this, class is an excellent predictor of survival as well. A first class passenger was 2.6x as likely to survive in the training set.\n\nPut Together, graphing survival for men and women in the three classes:\n    ","d852bea4":"##### 3.3: Ensemble Classifier built upon previous classifiers\n\nWe'll also make an ensemble classifier, that does majority voting based on our tuned XGBoost, Random Forest, and SVM models:","1eb57aaf":"Data Types:","ee3f4f34":"There's a mixture of numeric and non-numeric types. Let's get stats on the numeric fields:","c8df3672":"Indeed, women had a 74% chance of surviving, vs. 19% for men, in the training set. So gender looks definitely to be an excellent predictor of survival. Let's start graphing these insights.","cd4aa4dd":"##### 3.4: ROC AUC scoring\n\nWe'll now look at ROC AUC scoring for all our models:","d2bc13d0":"Now that all the fields are numeric, check which fields are most correlated with survival:","e49f3d74":"'Mr.' is by far the most common title.\n\nFor now, we'll just fill in missing `Age` values with the median age of the `Title` that person is in. A more refined way to do this would be fill in the age as a model prediction, for example from a random forest based on other columns.","de5e17fd":"Let's check that all the `Age` values are now filled in (not null):","cf90fbde":"Check the ranges of the data:","9f365d8e":"Here's the confusion matrices for our classifiers. The True value is found on the y-axis, and the Predicted value is found on the x-axis.","86f046e1":"Fill in this fare with the median fare of their class (Third class)","b4482a65":"Here's the accuracy scores now for our models:","2a500a3b":"People on decks: B, C, E, and D seem to have done much better than others. We'll make deck `Z` for those without deck information (ie. `Cabin` was null in the data):","24ddf8b7":"This shows names with longer lengths tended to survive. This information might be encoded in their class, so it's questionable if this feature will give any added information.\n\nLet's look at family size, which is the sum of siblings, spouses, parents, and children of a person:","75b8fb5a":"We make a `DeckCat` feature that is numeric, in order of survival probability:","e3cdb8b6":"Next, let's fill in the rest of the null values. Inspect the one record with a missing fare:","c101091f":"We've sorted people's title value in ascending order of survival probability.","d6c5f8f4":"This shows:\n* True positives in bottom right\n* True negatives in top left\n* False positives in top right\n* False negatives in bottom left\n\nWe see all models performed quite similarly, with Random Forest having the most true positives.\n\nHere are scores for precision, sensitivity, specificity, as well as the F1 score.","dc48735c":"##### 2.2: Exploration of Data\n\nHere we'll look at the data given to us on each passenger. We'll look at the first 5 and last 5 entries in the training set.","cae5bdd9":"There's two people with `Embarked` not filled in. Let's see if we can guess the values:","dbbd2b92":"`Age` and `Cabin` have a lot of missing data, while `Embarked` only has a few missing entries.\nTo fix the data, we'll want to fix both the training set and the test set at the same time. So we'll merge the data into one DataFrame: `df`.","674a550d":"So `Sex` is made up entirely of 'male' and 'female' entries, so let's make our first new feature, `Female`:","6921941e":"One idea is that the length of a person's name might be indicative of survival:","a66a9d95":"##### 3.2: Hyperparameter optimization\n\nTuning hyperparameters is an extensive topic. In this notebook, we want to focus on diagnostics after the model has been set up, so here we won't dive into optimizing each classifier's hyperparameters. Instead, we'll use a grid search to test several hyperparameters for XGBoost, SVM, and Random Forest models:","08af2cb3":"Let's inspect `df` and check for missing data:","82c176b9":"Here are the ROC Curves and AUC scores for the top 4 models:","8a66e131":"S = Southampton, C = Cherbourg, Q = Queenstown. \nThere isn't too much info here it appears. People from Cherbourg seemed to survive the most. How this relates to class could be explored more, to see if there is additional survival information from this feature. \n\nNow we'll process people's names, which are in a format for each person that gives their title. Title's are, for example, \"Mr.\", \"Mrs\", \"Miss\", etc.\n\nWe'll put titles in categories, as there are a lot of special titles that only a few people have, like \"Capt\" and \"Countess\". The \"Special\" title category includes all these special titles.","7eb9fd5a":"There's not a lot that stands out here on the surface for age indicating survival probability.\n\nNow let's look at the location where passengers embarked as it relates to those who survived (bars in lower graph are standard deviation). S = Southampton, C = Cherbourg, Q = Queenstown. ","8526b26d":"The above exploration gives an overview of the data. To get a complete picture of the data, the type of information should be inspected for all the 891 passengers in the training set and 418 passengers in the test set. The full description of the fields is found on the [Kaggle Titanic Data page](https:\/\/www.kaggle.com\/c\/titanic\/data).\n\nIn terms of getting a better idea of which fields are most useful, we'll inspect the correlation matrix to see what's correlated with `Survived` in the training set.","1fddc8ef":"We're finally done cleaning the data and doing our initial data exploration.\n\n#### Step 3. Model setup\n\n##### 3.1: Initial model creation\n\nWe'll drop the columns we don't need anymore, and make our training and test sets with the data that's been cleaned.","1556863a":"For the Random Forest and XGBoost classifiers, there is a large gap in the training error and test error, which is indicative of high variance. This makes sense as these algorithms are prone to overfitting, and we haven't done much work on the hyperparameters of these classifiers to combat this. So for the Random Forest and XGBoost classifiers, working on the hyperparameters to reduce variance is indicated.\n\nFor SVM and Linear Regression, we see the training and test accuracy relatively flat after 200 training examples, and lower than our desired test accuracy. This is indicative of high bias. That is, even with more data, it doesn't seem like the models will improve. In general, more training data does not seem to be helping these algorithms after 200-300 data points, so focusing on reducing bias looks to be indicated. This would look to add more features, and get more information out of the data.\n\nFor example, we could do more feature engineering to add features such as:\n* Mother - Female with a child on board\n* Child - Under 18 with a mother on board\n\nWe could also have a separate model to predict age, as many passengers had missing age information, and we initially just based a person's age on their title. This is not very accurate and led many people to have the same assumed age (especially men with title \"Mr.\" which all received the same estimate of their age if it was missing).\n\nOne other approach is to add features that rely on knowledge of the survival of people in the training set. For example, if we know from the training set that a mother survives, then it is likely the mother's children survived. If we know someone in a family survives, then it's more likely other family members survived.\n\nAnother approach to reduce bias is to manually inspect the false positives and false negatives of a model to see if there is some piece of information that isn't accurately given in our features that could help the model predict the correct outcome. Better features could arise from such an analysis.\n","2bcded5b":"Inspect the data:","adad9bb9":"Accuracy rose after the following were dropped:\n    <ul>\n    <li>SibSp<\/li>\n    <li>DeckCat<\/li>\n    <li>NameLength<\/li>\n    <\/ul>\nThis suggests these features may not be so important.\n\nAccuracy fell the most when `Pclass` was dropped, suggesting it has a lot of predictive value, which in our exploration of data was indeed the case. The most used feature was `TitleCat` which takes into account gender. Combined, gender and class seem to be the most useful.\n\n#### Conclusions\n\nThe above notebook describes how to perform an analysis on models using a confusion matrix and ROC curves, in the event that the True Positive Rate and False Positive Rate are of interest.\n\nWe also covered performing diagnostics on models to see if the model suffers from high bias or high variance, by varying the number of training examples used and quantifying training set and test set accuracy. As well, we performed ablative analysis on our features to understand which features are important for our models and which may be just leading to overfitting.\n\nIn this challenge, gender and class look to be the primary sources of information that differentiate those that survived and those that perished on the Titanic. Extracting useful information from the other fields in the data set, without overfitting the data looks to be the primary challenge in improving predictions.\n\nThis notebook did not cover extensive work on optimizing hyperparameters of our models, nor did it cover all models which could be used as binary classifiers, such as neural networks. However, with the diagnostics explained in this tutorial, it points the way into how to improve models to gain optimal accuracy of predictions.","a40b990c":"Names have lengths between 12 and 82 characters. Plot a histogram of these lengths:","00e3778f":"# Diagnostics to Improve Models in the Titanic Kaggle Competition\n\n[Douglas Friesen, PhD](https:\/\/www.linkedin.com\/in\/douglas-friesen-phd\/), April 2021\n\nThe sinking of the Titanic, which happened on April 15, 1912, is one of the most famous shipwrecks in history. It forms the basis of the introductory [machine learning competition](https:\/\/www.kaggle.com\/c\/titanic) on Kaggle. The basis of this competition is the binary classification problem: Given features of the passengers on the Titanic, predict whether or not they survived when the Titanic sunk.\n\nIn this notebook, I go through the process of designing an optimal model to predict survival:\n* Understanding of Problem\n* Exploration of Data\n* Cleaning of Data\n* Feature Engineering\n* Model Selection\n* Hyperparameter optimization for models\n* Model Testing\n\nI supplement these common elements of machine learning problems in Kaggle competitions with a focus on the following:\n1. Evaluating the model predictions using Confusion Matrices, ROC curves, and Area under the curve (AUC) scores. This allows insight into modifying the threshold of a binary classifier in order to reduce false positives or false negatives (Type I and Type II error), which is applicable to many binary classification problems, such as those in healthcare.\n2. Diagnostics to point to the most efficient way to improve predictions, based on evidence of bias or variability in the models. Having models overfit and underfit data are common problems, and being able to diagnose which problem a model has can lead to pursuing efforts that improve a model.\n\nThe motivation of this guide is to explore the suggestions made by Andrew Ng in his Stanford class CS229 lecture entitled: [Lecture 13 - Debugging ML Models and Error Analysis | Stanford CS229: Machine Learning (Autumn 2018)](https:\/\/www.youtube.com\/watch?v=ORrStCArmP4). The main question explored in this lecture is that after a model has been created, what is the most efficient use of time to improve the model? There are many ways to improve an algorithm, and figuring out the best way involves diagnostics to understand what the main problem the model is encountering. Common problems are:\n* High bias\n* High variance\n* Problem with the optimization algorithm\n* Problem with the optimization objective\n\nProfessor Ng indicates a strong understanding of these elements can save months in a tough data science problem by targeting what will actually improve performance in an underperforming model.\n\nAs well, the lecture explores error analysis and ablative analysis when multiple learning components form a pipeline, to understand which part of the pipeline is key to the algorithm's success, and which parts have the most potential to improve the algorithm. We will perform ablative analysis on our features in classifying survival in this project as a step to identifying ways to improve the model developed.\n\nThis notebook takes elements from other Kaggle notebooks in the setup of the features and the models.\n\n### Titanic Kaggle Competition\n\n#### Step 1. Undestanding of Problem\n\nThe problem is a straight-forward [binary classification challenge](https:\/\/www.kaggle.com\/c\/titanic), to predict who survives the Titanic shipwreck. Passenger information is given on all passengers. Further understanding of the problem will be developed as we explore the data.\n\n#### Step 2. Exploration of Data\n\n##### 2.1: Acquire Data and store in Pandas DataFrame\n\nThe training set and test set are given to us in separate csv files.\n","698b0384":"The above plot shows having 1-3 additional family members was best for one's chance of survival.\n\nWe'll make a feature, `FamilySizeCat`, that encodes this.","64771e24":"As expected, `TitleCat` and `Female` are most correlated with survival, and they are also very correlated to each other.\n\nNow we'll make several classifiers using different models:","a0308efc":"Let's tune the Random Forest model hyperparameters:","3d84f77c":"There are 891 passengers, with 12 fields per passenger:","0099f519":"Also, let's see how many passengers are in the test set:","ebe77a39":"All have similar areas under the curve. The Random Forest classifier is smoother than XGBoost and SVM in the area when the False Positive Rate is around 10%. The Linear Regression model by the slimmest of margins has the highest area under the curve (AUC). If True Positive Rate or False Positive Rate need to be at certain levels, these graphs can help select the model and the threshold of the classifier to use.\n\n#### Step 4. Diagnostics on Bias and Variance\n\nIn order to check whether our classifiers are suffering from high bias or variance, we'll see how increasing the number of training examples changes the accuracy of the models. This is the diagnostic taught by Professor Ng in CS 229 [Lecture 13](https:\/\/www.youtube.com\/watch?v=ORrStCArmP4). The theory is that if the gap between training accuracy and test accuracy remains high as we add more training examples, then the problem with the model is likely overfitting (high variance). If the gap between training and test accuracy is small, and the accuracies plateau at a certain number of training examples, and these accuracies aren't at the desired performance, then the problem is likely high bias.","155c0475":"This makes sense, as TitleCat is basically a more refined feature of gender, and combined with class make an excellent predictor of survival.\n\nNow XGBoost is doing much better in terms of accuracy:","30e154ec":"##### 3.6: Confusion Matrices and ROC Curves\n\nLet's evaluate the confusion matrix and ROC Curve of these models.\nIn a typical machine learning problem where we don't want to evaluate the test set while improving our model, one approach is to create a development test set out of the training set. From the 891 passengers in the training set, where we have their survival data, we'll split this 75% into a reduced training set, and 25% into a development test set. In this development test set, we have the survival data. It is noted that we have trained our hyperparameters for our models on the development test set data already.\n\nSet up development test set and train our top four models:","2cb79a70":"Of the training set, let's see what percentage of women survived. We recall that in the Titanic sinking, \"women and children\" should have had the highest chance of survival.","ea9941fc":"With only their default hyperparameters, here are their accuracy scores using 10-fold cross-validation on the training set:","de3cf905":"We'll make `EmbarkedCat` to be a numeric field, for easier processing for models.","0b51db75":"The most important parameters for our Random Forest is `TitleCat` (same as XGBoost), and `Female`. Its accuracy \nscore is now better as well at over 84%.\n\nLet's also tune the Support Vector Machine:","74c4c3d7":"There's a lot of missing fields for the `Cabin` field. Let's make a new feature called `Deck` that extracts the deck from the cabin, and we'll make a new \"deck\" for all the people that we don't have the cabin they were in."}}