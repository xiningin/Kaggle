{"cell_type":{"86f11b44":"code","ca91256f":"code","e2456d47":"code","0ba68858":"code","ee119e2b":"code","8ba8e874":"code","e6305639":"code","a3b9e75d":"code","223b7fe3":"code","03ac1639":"code","d14d68b6":"code","857bfd18":"code","94a44443":"code","e6902294":"code","29773ead":"code","6077fe2a":"code","8943c91c":"code","dbb5ecf8":"code","10b3019f":"code","cc33690f":"code","ba72f461":"code","0bd96177":"code","5400120b":"markdown","38e9d3f0":"markdown","92308dfd":"markdown","3c6b6d6c":"markdown","a4d7170c":"markdown","1d4751fd":"markdown","4ccc0a2e":"markdown","3c3c1257":"markdown","d06a0275":"markdown","dc6a4ab4":"markdown"},"source":{"86f11b44":"# Import all libraries we need\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # Visualization\n# sklearn library\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n# Evaluation Metric\nfrom sklearn.metrics import r2_score\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ca91256f":"df = pd.read_csv(\"\/kaggle\/input\/world-happiness\/2019.csv\")\ndf.head()","e2456d47":"df.info()","0ba68858":"# plot data\nplt.scatter(df[\"Social support\"],df[\"Score\"])\nplt.xlabel(\"Social Support\")\nplt.ylabel(\"Score\")\nplt.show()\n","ee119e2b":"# linear regression model\nlinear_reg = LinearRegression()\n\nx = df[\"Social support\"].values.reshape(-1,1)\ny = df[\"Score\"].values.reshape(-1,1)\n\nlinear_reg.fit(x,y)","8ba8e874":"Predicted_Score1 = linear_reg.predict([[1.5]])\nprint(\"Predicted Score 1: \",Predicted_Score1)\n\nPredicted_Score2 = linear_reg.predict([[0.5]])\nprint(\"Predicted Score 2: \",Predicted_Score2)\n\nPredicted_Score3 = linear_reg.predict([[1.8]])\nprint(\"Predicted Score 3: \",Predicted_Score3)\n\nintercept = linear_reg.intercept_\nprint(\"intercept: \",intercept)   # y eksenini kestigi nokta intercept\n\nslope = linear_reg.coef_\nprint(\"slope: \",slope)   # egim slope\n\n# Score = 1.91243024 + 2.89098704*Social Support \n\n","e6305639":"y_predicted = linear_reg.predict(x)\nplt.scatter(x,y)\nplt.plot(x, y_predicted,color = \"red\")\nplt.xlabel(\"Social Support\")\nplt.ylabel(\"Score\")\nplt.title(\"Linear Regression\")\nplt.show()\nprint(\"r_score: \", r2_score(y,y_predicted))","a3b9e75d":"# Multiple Linear Regression Model\nx = df.iloc[:,3:].values\ny = df[\"Score\"].values.reshape(-1,1)\nmultiple_linear_regression = LinearRegression()\nmultiple_linear_regression.fit(x,y)","223b7fe3":"print(\"Intercept: \", multiple_linear_regression.intercept_)\nprint(\"b1,b2,b3,b4,b5,b6: \",multiple_linear_regression.coef_)","03ac1639":"# prediction\nmultiple_linear_regression.predict(np.array([[1.340,1.587,0.986,0.596,0.153,0.393]]))","d14d68b6":"df.head()","857bfd18":"# plot data\nplt.scatter(df[\"Social support\"],df[\"Score\"])\nplt.xlabel(\"Social support\")\nplt.ylabel(\"Score\")\nplt.show()","94a44443":"x = df[\"Healthy life expectancy\"].values.reshape(-1,1)\ny = df[\"Score\"].values.reshape(-1,1)","e6902294":"lr = LinearRegression()\nlr.fit(x,y)\ny_head = lr.predict(x)\nplt.scatter(df[\"Healthy life expectancy\"],df[\"Score\"])\nplt.xlabel(\"Healthy life expectancy\")\nplt.ylabel(\"Score\")\nplt.plot(x,y_head,color=\"red\",label =\"linear\")\nplt.show()","29773ead":"polynomial_regression = PolynomialFeatures(degree = 2)\nx_polynomial = polynomial_regression.fit_transform(x)\nlinear_regression2 = LinearRegression()\nlinear_regression2.fit(x_polynomial,y)","6077fe2a":"y_head2 = linear_regression2.predict(x_polynomial)\nplt.scatter(df[\"Healthy life expectancy\"],df[\"Score\"])\nplt.xlabel(\"Healthy life expectancy\")\nplt.ylabel(\"Score\")\nplt.plot(x,y_head2,color= \"green\",label = \"poly\")\nplt.title(\"Polynomial Regression\")\nplt.legend()\nplt.show()\nprint(\"r_square score: \", r2_score(y,y_head2))","8943c91c":"x = df[\"GDP per capita\"].values.reshape(-1,1)\ny = df[\"Score\"].values.reshape(-1,1)","dbb5ecf8":"tree_reg = DecisionTreeRegressor()\ntree_reg.fit(x,y)\ntree_reg.predict([[1.2]])\nx_ = np.arange(min(x),max(x),0.1).reshape(-1,1)\ny_head = tree_reg.predict(x_)","10b3019f":"# visualize\nplt.scatter(x,y,color=\"red\")\nplt.plot(x_,y_head,color = \"green\")\nplt.xlabel(\"GDP per capita\")\nplt.ylabel(\"Score\")\nplt.title(\"Decision Tree\")\nplt.show()","cc33690f":"x = df[\"Freedom to make life choices\"].values.reshape(-1,1)\ny = df[\"Score\"].values.reshape(-1,1)","ba72f461":"rf = RandomForestRegressor(n_estimators = 100, random_state = 42)\nrf.fit(x,y)\nprint(\"Predicted Value = : \",rf.predict([[0.5]]))\nx_ = np.arange(min(x),max(x),0.01).reshape(-1,1)\ny_head = rf.predict(x_)","0bd96177":"# visualize\nplt.scatter(x,y,color=\"red\")\nplt.plot(x_,y_head,color=\"green\")\nplt.xlabel(\"Freedom to make life choices\")\nplt.ylabel(\"Score\")\nplt.show()","5400120b":"## Random Forest","38e9d3f0":"### Prediction","92308dfd":"## Polynomial Regression","3c6b6d6c":"### Visualization","a4d7170c":"## Decision Tree","1d4751fd":"### Prediction","4ccc0a2e":"## Linear Regression","3c3c1257":"### Visualization","d06a0275":"## Happiness 2019\n\nIn the dataset we will observe happiness 2019 dataset. This dataset gives the happiness rank and happiness score of 156 countries around the world based on six factors including GDP per capita, Social support, Healthy life expectancy, Freedom to make life choices, Generosity, Perceptions of corruption. Sum of the value of these six factors gives us the happiness score and the higher the happiness score, the lower the happiness rank. So, it is evident that the higher value of each of these six factors means the level of happiness is higher. We can define the meaning of these factors as the extent to which these factors lead to happiness.","dc6a4ab4":"## Multiple Linear Regression"}}