{"cell_type":{"8b0927fe":"code","b871e1b2":"code","92464e1d":"code","aed00f92":"code","f8cbf39f":"code","aa3dfd75":"code","11f92137":"code","f0a2fec6":"code","ae1ec6c2":"code","713c43bc":"code","3fd9c9fe":"code","7e67c173":"code","c61df743":"code","5068e47b":"code","1c29ffb6":"code","ee51b651":"markdown"},"source":{"8b0927fe":"import os\nimport pickle\nimport random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\n\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom sklearn.preprocessing import RobustScaler, normalize\nfrom sklearn.model_selection import train_test_split, GroupKFold, KFold\n\nfrom IPython.display import display","b871e1b2":"from tqdm import tqdm","92464e1d":"def seed_everything(seed=0):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\nseed_everything(0)","aed00f92":"path_folder_out = \"\/kaggle\/working\"\nprint(f\"output folder is {path_folder_out}\")\n# os.makedirs(path_folder_out, exist_ok=True)","f8cbf39f":"DEBUG = False\n\n# In kaggle\npath_folder = \"..\/input\/ventilator-pressure-prediction\"\n\ntrain_ori = pd.read_csv(f'{path_folder}\/train.csv')\ntest_ori = pd.read_csv(f'{path_folder}\/test.csv')\nsubmission = pd.read_csv(f'{path_folder}\/sample_submission.csv')\n\nif DEBUG:\n    train_ori = train_ori[:80*1000]","aa3dfd75":"def add_features(df):\n    df['cross'] = df['u_in']*df['u_out']\n    df['cross2'] = df['time_step']*df['u_out']\n    \n    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n    df['one'] = 1\n    df['count'] = (df['one']).groupby(df['breath_id']).cumsum()\n    df['u_in_cummean'] = df['u_in_cumsum'] \/ df['count']\n    \n    # LagFeatures\n    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n    df = df.fillna(0)\n    \n    # diff values\n    df['u_in_max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n    df['u_in_diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['u_in_diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n\n    # AUC\n    df['breath_time_lag1'] = df.groupby(\"breath_id\")[\"time_step\"].shift(1).fillna(0)\n    df['breath_time_lag2'] = df.groupby(\"breath_id\")[\"time_step\"].shift(2).fillna(0)\n    df[\"area\"] = df[\"breath_time_lag1\"] * (df[\"u_in\"] + df[\"u_in_lag1\"]) \/ 2.0\n    df[\"AUC\"] = df.groupby(\"breath_id\")[\"area\"].cumsum()\n\n    # R,C\n    df['R'] = df['R'].astype(str)\n    df['C'] = df['C'].astype(str)\n    df['RC'] = df['R']+df['C']\n    df = pd.get_dummies(df)\n\n    return df\n\ntrain = add_features(train_ori)\ntest = add_features(test_ori)","11f92137":"def simple_check_df(df):\n    print(\"np.inf\", df.isin([np.inf, -np.inf]).any().any())\n    print(\"np.nan\", df.isnull().any().any())\nsimple_check_df(train)\nsimple_check_df(test)","f0a2fec6":"d1 = {}\nd2 = {}\nfor i, v in enumerate(sorted(set(train[\"pressure\"]))):\n    d1[v] = i\n    d2[i] = v","ae1ec6c2":"targets = train[['pressure']].replace(d1).astype(int).to_numpy().reshape(-1, 80)\ndropcols = [\n  'id',\n  'breath_id',\n  'one',\n  'count',\n]\n\ntrain.drop(dropcols, axis=1, inplace=True)\ntest.drop(dropcols, axis=1, inplace=True)\ntrain.drop(\"pressure\", axis=1, inplace=True)","713c43bc":"test2 = test.head(1600)","3fd9c9fe":"RS = RobustScaler()\ntrain = RS.fit_transform(train)\ntest = RS.transform(test)\ntest2 = RS.transform(test2)\n\ntrain = train.reshape(-1, 80, train.shape[-1])\ntest = test.reshape(-1, 80, train.shape[-1])\ntest2 = test2.reshape(-1, 80, train.shape[-1])","7e67c173":"EPOCH = 3 # only for debug\nBATCH_SIZE = 256\n\nkf = KFold(n_splits=5, shuffle=True, random_state=2021)\ntest_preds = []\nfor fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n    if fold != 0: # only for debug\n        continue\n    \n    print('-'*15, '>', f'Fold {fold+1}', '<', '-'*15)\n    X_train, X_valid = train[train_idx], train[test_idx]\n    y_train, y_valid = targets[train_idx], targets[test_idx]\n    model = keras.models.Sequential([\n        keras.layers.Input(shape=train.shape[-2:]),\n        keras.layers.Bidirectional(keras.layers.LSTM(300, return_sequences=True)),\n        keras.layers.Bidirectional(keras.layers.LSTM(250, return_sequences=True)),\n        keras.layers.Bidirectional(keras.layers.LSTM(150, return_sequences=True)),\n        keras.layers.Bidirectional(keras.layers.LSTM(100, return_sequences=True)),\n        keras.layers.Dense(50, activation='selu'),\n        keras.layers.Dense(950, activation='softmax'),\n    ])\n    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics='accuracy')\n\n    # \u5b66\u7fd2\n    cp = ModelCheckpoint(f\"model.keras_{fold}.best_weight.h5\", monitor=\"val_loss\", verbose=1, save_best_only=True, save_weights_only=False)\n    scheduler = ExponentialDecay(1e-3, 400*((len(train)*0.8)\/BATCH_SIZE), 1e-5)\n    lr = LearningRateScheduler(scheduler, verbose=1)\n    es = EarlyStopping(monitor=\"val_loss\", patience=100, verbose=1, mode=\"min\", restore_best_weights=True)\n    csv_logger = CSVLogger(f'training.{fold}.log', append=True)\n    model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=EPOCH, batch_size=BATCH_SIZE, callbacks=[lr, csv_logger, es, cp])","c61df743":"def model_split_predict(num_split=500):\n    # global var => model, test\n    preds_flatten = np.array([])\n    tests_splitted = np.array_split(test, 500)\n    for test_splitted in tqdm(tests_splitted):\n        test_preds = model.predict(test_splitted)\n        for i in range(len(test_splitted)):\n            preds_flatten = np.append(preds_flatten, np.argmax(test_preds[i], axis=1))\n    return preds_flatten","5068e47b":"test_preds_index = model_split_predict()","1c29ffb6":"test_preds = [d2[ind] for ind in test_preds_index]","ee51b651":"@takamichitoda is already doing something similar approach with pytorch.\nhttps:\/\/www.kaggle.com\/takamichitoda\/ventilator-train-classification\n\nIn my latest version (Larger Epoch size and add some features), LB score was 0.186.."}}