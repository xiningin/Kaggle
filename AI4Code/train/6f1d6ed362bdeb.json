{"cell_type":{"064dd2fc":"code","1f228392":"code","5e8a38c0":"code","ef502dfc":"code","bca378a6":"code","f0eb0e9d":"code","8700bd53":"code","e12d5afc":"code","2e507263":"code","3a4787b8":"code","ba8f6e50":"code","0c91c2da":"code","ad8eaa3f":"code","9d1fc722":"code","990ed180":"markdown","9943aee2":"markdown","4bdb53f2":"markdown","e0d035f9":"markdown","c690b5c0":"markdown","1925bcbc":"markdown","a4af8e86":"markdown","0618dbda":"markdown","b183f8ae":"markdown","730c984c":"markdown","36af583b":"markdown","afaa09be":"markdown","d4d40c9c":"markdown","2cb77dff":"markdown","f0d89897":"markdown","7d77def8":"markdown","0acf2407":"markdown","6fbe449f":"markdown","f29b6751":"markdown","2df52008":"markdown","0ca72678":"markdown"},"source":{"064dd2fc":"import pandas as pd \nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import train_test_split #useful to divide the dataset\nfrom sklearn.ensemble import RandomForestRegressor \nfrom sklearn.metrics import mean_absolute_error #for measurement of performance","1f228392":"iowa_file_path = '..\/input\/home-data-for-ml-course\/train.csv'\n\nhome_data = pd.read_csv(iowa_file_path)\n\n# Print summary statistics\nhome_data.describe()","5e8a38c0":"y = home_data.SalePrice\nfeatures = [\"LotArea\", \"YearBuilt\", \"1stFlrSF\", \"2ndFlrSF\", \"FullBath\", \"BedroomAbvGr\", \"TotRmsAbvGrd\"]\nX = home_data[features]","ef502dfc":"#For model reproducibility, set a numeric value for random_state when specifying the model\niowa_model = DecisionTreeRegressor(random_state=1)\n\n# Fit the model\niowa_model.fit(X, y)\n\npredictions = iowa_model.predict(X)\nprint(predictions)","bca378a6":"train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\niowa_model_2 = DecisionTreeRegressor(random_state=1)\n\n# Fit iowa_model with the training data.\niowa_model_2.fit(train_X, train_y)\nval_predictions = iowa_model_2.predict(val_X)\n\nval_mae = mean_absolute_error(val_predictions, val_y)\n\nprint(val_mae)","f0eb0e9d":"def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n    model.fit(train_X, train_y)\n    preds_val = model.predict(val_X)\n    mae = mean_absolute_error(val_y, preds_val)\n    return(mae)","8700bd53":"candidate_max_leaf_nodes = [5, 25, 50, 100, 250, 500]\n# Write loop to find the ideal tree size from candidate_max_leaf_nodes\nscores = {leaf_size: get_mae(leaf_size, train_X, val_X, train_y, val_y) for leaf_size in candidate_max_leaf_nodes}\nbest_tree_size = min(scores, key=scores.get)\nprint(best_tree_size)","e12d5afc":"# Fit the model with best_tree_size.\nfinal_model = DecisionTreeRegressor(max_leaf_nodes=best_tree_size, random_state=1)\n\n# fit the final model\nfinal_model.fit(X, y)","2e507263":"# Split into validation and training data\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n\n# Define a random forest model\nrf_model = RandomForestRegressor(random_state=1)\nrf_model.fit(train_X, train_y)\nrf_val_predictions = rf_model.predict(val_X)\nrf_val_mae = mean_absolute_error(rf_val_predictions, val_y)\n\nprint(\"Validation MAE for Random Forest Model: {:,.0f}\".format(rf_val_mae))","3a4787b8":"# To improve accuracy, create a new Random Forest model which you will train on all training data\nrf_model_on_full_data = RandomForestRegressor(random_state=1)\n\n# fit rf_model_on_full_data on all data from the training data\nrf_model_on_full_data.fit(X, y)\nrf_model_on_full_data_predictions = rf_model_on_full_data.predict(X)","ba8f6e50":"# path to file you will use for predictions\ntest_data_path = '..\/input\/home-data-for-ml-course\/test.csv'\n\n# read test data file using pandas\ntest_data = pd.read_csv(test_data_path)\n\n# create test_X which comes from test_data but includes only the columns you used for prediction.\n# The list of columns is stored in a variable called features\ntest_X = test_data[features]\n\n# make predictions which we will submit. \ntest_preds = rf_model_on_full_data.predict(test_X)\ntest_preds","0c91c2da":"X_full = pd.read_csv('..\/input\/home-data-for-ml-course\/train.csv', index_col='Id')\nX_test_full = pd.read_csv('..\/input\/home-data-for-ml-course\/test.csv', index_col='Id')\n\n# Obtain target and predictors\ny = X_full.SalePrice\nfeatures = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\nX = X_full[features].copy()\nX_test = X_test_full[features].copy()\n\n# Break off validation set from training data\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n                                                      random_state=0)","ad8eaa3f":"# Define the models\nmodel_1 = RandomForestRegressor(n_estimators=50, random_state=0)\nmodel_2 = RandomForestRegressor(n_estimators=100, random_state=0)\nmodel_3 = RandomForestRegressor(n_estimators=100, criterion='mae', random_state=0)\nmodel_4 = RandomForestRegressor(n_estimators=200, min_samples_split=20, random_state=0)\nmodel_5 = RandomForestRegressor(n_estimators=100, max_depth=7, random_state=0)\n\nmodels = [model_1, model_2, model_3, model_4, model_5]","9d1fc722":"# Function for comparing different models\ndef score_model(model, X_t=X_train, X_v=X_valid, y_t=y_train, y_v=y_valid):\n    model.fit(X_t, y_t)\n    preds = model.predict(X_v)\n    return mean_absolute_error(y_v, preds)\n\nfor i in range(0, len(models)):\n    mae = score_model(models[i])\n    print(\"Model %d MAE: %d\" % (i+1, mae))","990ed180":"You know the best tree size. If you were going to deploy this model in practice, you would make it even more accurate by using all of the data and keeping that tree size. That is, you don't need to hold out the validation data now that you've made all your modeling decisions.","9943aee2":"The \"exercise: introduction\" notebook in the intermediate ML micro-course shows a way to compare different models:","4bdb53f2":"### Loading data\n\nThe Iowa data file is stored into a Pandas DataFrame called home_data.\n\nThe data doesn't have missing values in the columns used as features. \n\nThere is no need for a detailed treatment at this time.","e0d035f9":"![housesbanner.png](attachment:1adf8d1d-6a02-4ba0-890d-5119cd93a8c0.png)","c690b5c0":"# Random Forest","1925bcbc":"Now, read the file of \"test\" data, and apply your model to make predictions.","a4af8e86":"The micro-course's first model is a decision tree, created with the scikit-learn library, written as sklearn. Scikit-learn is easily the most popular library for modeling the types of data typically stored in DataFrames.\n\nThe steps to building and using a model are:\n\n**Define:** What type of model will it be? A decision tree? Some other type of model? Some other parameters of the model type are specified too.\n\n**Fit:** Capture patterns from provided data. This is the heart of modeling.\n\n**Predict:** Just what it sounds like.\n\n**Evaluate:** Determine how accurate the model's predictions are.\n","0618dbda":"The measure we just computed can be called an \"in-sample\" score. We used a single \"sample\" of houses for both building the model and evaluating it. Here's why this is bad.\n\nImagine that, in the large real estate market, door color is unrelated to home price.\n\nHowever, in the sample of data you used to build the model, all homes with green doors were very expensive. The model's job is to find patterns that predict home prices, so it will see this pattern, and it will always predict high prices for homes with green doors.\n\nSince this pattern was derived from the training data, the model will appear accurate in the training data.\n\nBut if this pattern doesn't hold when the model sees new data, the model would be very inaccurate when used in practice.\n\nSince models' practical value come from making predictions on new data, we measure performance on data that wasn't used to build the model. The most straightforward way to do this is to exclude some data from the model-building process, and then use those to test the model's accuracy on data it hasn't seen before. This data is called validation data.","b183f8ae":"### Model validation\n\nSo we've built a model, but how good is it? In the model validation lesson, we are introduced to Mean Absolute Error (MAE), imported from the sklearn module.\n\nSince models' practical value come from making predictions on new data, we measure performance on data that wasn't used to build the model. The scikit-learn library has a function train_test_split to break up the data into two pieces. We'll use some of that data as training data to fit the model, and we'll use the other data as validation data to calculate mean_absolute_error.","730c984c":"This notebook compiles the exercises of the \"Intro to ML\" micro-course, based on the [Ames House Dataset](https:\/\/www.kaggle.com\/c\/home-data-for-ml-course\/overview). The exercises' main goal is to predict the sales price for each house in the dataset.","36af583b":"# The first model: Decision Tree","afaa09be":"We build a random forest model similarly to how we built a decision tree in scikit-learn - this time using the RandomForestRegressor class instead of DecisionTreeRegressor.\n\nThe random forest uses many trees, and it makes a prediction by averaging the predictions of each component tree. It generally has much better predictive accuracy than a single decision tree and it works well with default parameters. If you keep modeling, you can learn more models with even better performance, but many of those are sensitive to getting the right parameters.","d4d40c9c":"In this case, the best model is the model 3 (lowest MAE).\n","2cb77dff":"The predictions can be submitted to a competition in a csv file. ","f0d89897":"# Intro to Machine Learning micro-course: exercises summary","7d77def8":"Since the competition dataset is divided in test and train, we can create a new Random Forest model which we will train on all training data.","0acf2407":"### Importing useful modules\n\nThese are the modules used throughout the micro-course:","6fbe449f":"When we divide the houses amongst many leaves, we also have fewer houses in each leaf. Leaves with very few houses will make predictions that are quite close to those homes' actual values, but they may make very unreliable predictions for new data (because each prediction is based on only a few houses).\n\nThis is a phenomenon called overfitting, where a model matches the training data almost perfectly, but does poorly in validation and other new data. On the flip side, if we make our tree very shallow, it doesn't divide up the houses into very distinct groups.\n\nAt an extreme, if a tree divides houses into only 2 or 4, each group still has a wide variety of houses. Resulting predictions may be far off for most houses, even in the training data (and it will be bad in validation too for the same reason). When a model fails to capture important distinctions and patterns in the data, so it performs poorly even in training data, that is called underfitting.\n\nSince we care about accuracy on new data, which we estimate from our validation data, we want to find the sweet spot between underfitting and overfitting.","f29b6751":"To select the best model out of the five, we define a function score_model() below. This function returns the mean absolute error (MAE) from the validation set. Recall that the best model will obtain the lowest MAE. ","2df52008":"### Defining features and prediction target\n\nThe target variable is the sales price, saved in a variable called y.\n\nThe predictive features are stored in a DataFrame called X.","0ca72678":"# Machine Learning Competitions"}}