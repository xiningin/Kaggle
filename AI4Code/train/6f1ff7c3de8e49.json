{"cell_type":{"bfd8e7ac":"code","32719af2":"code","2ec37266":"code","48d256f1":"code","db608613":"code","9c05ff07":"code","a6b1f8f8":"code","e7516935":"code","2a24244d":"code","30a8bece":"code","d74cce02":"code","8506e86b":"code","daa2174b":"code","77fe0cfb":"code","434a987c":"code","93c7ca05":"code","c72bce9c":"code","dd294441":"code","290a8515":"code","5a7eb586":"code","d97165da":"code","5c7705a5":"code","e52f4015":"code","123510a8":"code","9d9305ac":"code","6abaa190":"code","b8e95ac7":"code","a358952e":"code","b0c465a3":"code","447e4306":"code","b5ba8818":"code","947a3c04":"code","5eec385e":"code","3edac575":"code","abe60437":"code","39b1a116":"markdown","e4223ecb":"markdown","d6eb0bff":"markdown","4e11e6df":"markdown","53bae67d":"markdown","fd6df997":"markdown","5b90f959":"markdown","5e0bb6ea":"markdown","3748ee3f":"markdown","36be6a85":"markdown","5c3edeea":"markdown","d8efff1b":"markdown","de3e6161":"markdown","dddab39a":"markdown","0967a6b9":"markdown","c559371b":"markdown","e775d9de":"markdown","86866ba6":"markdown","22ca6df2":"markdown","1f8e2987":"markdown","52cf31c9":"markdown"},"source":{"bfd8e7ac":"import pandas as pd\nimport numpy as np\nfrom string import punctuation\nimport re\nimport nltk\nfrom nltk.corpus import twitter_samples\nimport random\nnltk.download('stopwords')\nimport string   \nfrom tensorflow.keras.preprocessing.text import Tokenizer                        \nfrom nltk.corpus import stopwords \nfrom nltk.stem import PorterStemmer\nfrom nltk.tokenize import TweetTokenizer\nfrom sklearn.preprocessing import LabelEncoder\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Embedding, LSTM, Dense,Dropout\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n","32719af2":"tweets=pd.read_csv(\"..\/input\/twitter-sentiment-dataset\/Twitter_Data.csv\")","2ec37266":"tweets.head(10)\ntweets['clean_text']=tweets['clean_text'].astype('str')","48d256f1":"tweets=tweets.dropna()\n","db608613":"all_positive_tweets=tweets[tweets['category']==1]['clean_text']\nall_neutral_tweets=tweets[tweets['category']==0]['clean_text']\nall_negative_tweets=tweets[tweets['category']==-1]['clean_text']","9c05ff07":"total_positive_words = []\nfor sentence in all_positive_tweets:\n    total_positive_words.append(sentence.count(' '))\n    \ntotal_negative_words = []\nfor sentence in all_negative_tweets:\n    total_negative_words.append(sentence.count(' '))\n\ntotal_neutral_words = []\nfor sentence in all_neutral_tweets:\n    total_neutral_words.append(sentence.count(' '))\n    \nimport plotly.graph_objects as go\nimport numpy as np\n\nx0 = np.array(total_positive_words)\nx1 = np.array(total_negative_words)\nx2 = np.array(total_neutral_words)\n\nfig = go.Figure()\nfig.add_trace(go.Histogram(x=x0, name = 'Positive'))\nfig.add_trace(go.Histogram(x=x2, name = 'Neutral'))\n\n# Overlay both histograms\nfig.update_layout(barmode='overlay')\n# Reduce opacity to see both histograms\nfig.update_traces(opacity=0.75)\nfig.show()","a6b1f8f8":"total_negative_words = []\nfor sentence in all_negative_tweets:\n    total_negative_words.append(sentence.count(' '))\n\ntotal_neutral_words = []\nfor sentence in all_neutral_tweets:\n    total_neutral_words.append(sentence.count(' '))\n    \nimport plotly.graph_objects as go\nimport numpy as np\n\nx0 = np.array(total_positive_words)\nx1 = np.array(total_negative_words)\nx2 = np.array(total_neutral_words)\n\nfig = go.Figure()\nfig.add_trace(go.Histogram(x=x1, name = 'Negative'))\nfig.add_trace(go.Histogram(x=x2, name = 'Neutral'))\n\n# Overlay both histograms\nfig.update_layout(barmode='overlay')\n# Reduce opacity to see both histograms\nfig.update_traces(opacity=0.75)\nfig.show()\n","e7516935":"total_positive_words = []\nfor sentence in all_positive_tweets:\n    total_positive_words.append(sentence.count(' '))\n    \ntotal_negative_words = []\nfor sentence in all_negative_tweets:\n    total_negative_words.append(sentence.count(' '))\n\ntotal_neutral_words = []\nfor sentence in all_neutral_tweets:\n    total_neutral_words.append(sentence.count(' '))\n    \nimport plotly.graph_objects as go\nimport numpy as np\n\nx0 = np.array(total_positive_words)\nx1 = np.array(total_negative_words)\nx2 = np.array(total_neutral_words)\n\nfig = go.Figure()\nfig.add_trace(go.Histogram(x=x0, name = 'Positive'))\nfig.add_trace(go.Histogram(x=x1, name = 'Negative'))\n\n# Overlay both histograms\nfig.update_layout(barmode='overlay')\n# Reduce opacity to see both histograms\nfig.update_traces(opacity=0.75)\nfig.show()","2a24244d":"plt.figure(figsize=(8,10))\nsns.countplot(x=tweets['category'])","30a8bece":"from wordcloud import WordCloud\nwc = WordCloud(width = 500, height = 500, min_font_size = 10, background_color = 'white')\npositive_wc = wc.generate(tweets[tweets['category'] == 1.0]['clean_text'].str.cat(sep = \" \"))\nneutral_wc = wc.generate(tweets[tweets['category'] == 0.0]['clean_text'].str.cat(sep = \" \"))\nnegative_wc = wc.generate(tweets[tweets['category'] == -1.0]['clean_text'].str.cat(sep = \" \"))\nplt.figure(figsize = (12, 12))\nplt.imshow(positive_wc)","d74cce02":"plt.figure(figsize = (12, 12))\nplt.imshow(neutral_wc)","8506e86b":"plt.figure(figsize = (12, 12))\nplt.imshow(negative_wc)","daa2174b":"tweets.isnull().sum()","77fe0cfb":"#Import the english stop words list from NLTK\nstopwords_english = stopwords.words('english') \n\nprint('Stop words\\n')\nprint(stopwords_english)\n\nprint('\\nPunctuation\\n')\nprint(string.punctuation)","434a987c":"tweets=tweets.dropna(axis=0)","93c7ca05":"tweets.isnull().sum()","c72bce9c":"# Removing Stopwords\ntweets['clean_text'] = tweets['clean_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords_english)]))","dd294441":"tweets['clean_text'][0]","290a8515":"# removing punctuations\ntweets['clean_text'] = tweets['clean_text'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))","5a7eb586":"tweets['clean_text'][0]","d97165da":"stemmer = PorterStemmer() \ndef stemming(word):\n    list1=[]\n    for i in word.split():\n        list1.append(stemmer.stem(i))\n    return ' '.join(list1)\n    \ntweets['clean_text'] = tweets['clean_text'].apply(lambda x:stemming(x))","5c7705a5":"tweets['category'] = [2 if x == -1 else x for x in tweets['category']]","e52f4015":"tweets_2=tweets.copy()","123510a8":"tokenizer = Tokenizer()\ntokenizer.fit_on_texts(tweets.clean_text)\nword_index = tokenizer.word_index","9d9305ac":"vocab_size = len(word_index)+1","6abaa190":"# padding the tokenized sequences to same length\nmax_length = 200\nlines = pad_sequences(tokenizer.texts_to_sequences(tweets.clean_text),\n                        maxlen = max_length)","b8e95ac7":"tweets.clean_text = lines.tolist()\n","a358952e":"tweets.category.value_counts()","b0c465a3":"tweets.head()","447e4306":"tweets.isnull().sum()","b5ba8818":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(tweets['clean_text'],tweets['category'],test_size=0.2,random_state=101)\nX_train = np.vstack(X_train.values)\ny_train = np.vstack(y_train.values)\n\nX_val = np.vstack(X_test.values)\ny_val = np.vstack(y_test.values)\n\n","947a3c04":"\n\nmodel = tf.keras.Sequential()\n\n# Input layer\nmodel.add(Input(shape=(None,)))\n\n# Embedding layer\nmodel.add(Embedding(input_dim=vocab_size,output_dim=200,trainable=True))\n\n# LSTM layer\nmodel.add(LSTM(64, activation='relu'))\n\n# Fully connected layer\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.2))\n\n# Output layer\nmodel.add(Dense(3, activation='sigmoid'))\n\nmodel.summary()","5eec385e":"model.compile(optimizer='adam', loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\nhistory = model.fit(X_train, y_train,\n                    epochs=2, batch_size=512,\n                    verbose=1,shuffle=True,validation_data=(X_val,y_val))","3edac575":"predictions = model.predict(X_val)\nprint(history.history)","abe60437":"print(\"Evaluate on test data\")\nresults = model.evaluate(X_val, y_val, batch_size=128)\nprint(\"test loss, test acc:\", results)","39b1a116":"<Center><img src=\"https:\/\/miro.medium.com\/max\/875\/1*SICYykT7ybua1gVJDNlajw.png\" width=\"700\" \/><\/Center>","e4223ecb":"<div style=\"background-color:#F5F5F5;height:70px\">\n    <Center><h3 style=\"padding-top:20px ;color:blue;font-size:26px\">Data Modelling<\/h3><\/Center>\n    <\/div>","d6eb0bff":"<div style=\"background-color:#F5F5F5;height:70px\">\n    <Center><h3 style=\"padding-top:20px ;color:blue;font-size:26px\">Sequential Modelling<\/h3><\/Center>\n    <\/div>","4e11e6df":"<div style=\"background-color:#F5F5F5;height:70px\">\n    <Center><h3 style=\"padding-top:20px ;color:blue;font-size:26px\">Data Visualization<\/h3><\/Center>\n    <\/div>","53bae67d":"<div style=\"background-color:#F5F5F5;height:70px\">\n    <Center><h3 style=\"padding-top:20px ;color:blue;font-size:26px\">Importing the packages<\/h3><\/Center>\n    <\/div>","fd6df997":"<p style=\"font-size:20px\">Sentiment analysis is contextual mining of text which identifies and extracts subjective information in source material, and helping a business to understand the social sentiment of their brand, product or service while monitoring online conversations.<\/p>","5b90f959":"<div style=\"background-color:#F5F5F5;height:70px\">\n    <Center><h3 style=\"padding-top:20px ;color:blue;font-size:26px\">Accuracy and Loss of Test data<\/h3><\/Center>\n    <\/div>","5e0bb6ea":"<div style=\"background-color:#F5F5F5;height:70px\">\n    <Center><h3 style=\"padding-top:20px ;color:blue;font-size:26px\">Removing StopWords and Punctuations<\/h3><\/Center>\n    <\/div>","3748ee3f":"<p style=\"font-size:20px\">Data preprocessing is one of the critical steps in any machine learning project. It includes cleaning and formatting the data before feeding into a machine learning algorithm. For NLP, the preprocessing steps are comprised of the following tasks :<\/p>\n\n<ul>\n    <li><p style=\"font-size:14px\">Tokenizing the string<\/p><\/li>\n    <li><p style=\"font-size:14px\">Lowercasing<\/p><\/li>\n    <li><p style=\"font-size:14px\">Removing stop words and punctuation<\/p><\/li>\n    <li><p style=\"font-size:14px\">Stemming<\/p><\/li>\n    <li><p style=\"font-size:14px\">Sequential modelling<\/p><\/li>\n <\/ul>\n","36be6a85":"<div style=\"background-color:#F5F5F5;height:70px\">\n    <Center><h3 style=\"padding-top:20px ;color:blue;font-size:26px\">Interpreting nature of tweet with length of the tweet<\/h3><\/Center>\n    <\/div>","5c3edeea":"\n<div style=\"background-color:#F5F5F5;height:90px\">\n<Center><h2 style=\"color:blue;font-size:40px;background-color:#F5F5F5;padding-top:20px\" >Sentement analysis<\/h2><Center>\n<\/div>","d8efff1b":"<div style=\"background-color:#F5F5F5;height:70px\">\n    <Center><h3 style=\"padding-top:20px ;color:blue;font-size:26px\">Model Evaluvation<\/h3><\/Center>\n    <\/div>","de3e6161":"<div style=\"background-color:#F5F5F5;height:70px\">\n    <Center><h3 style=\"padding-top:20px ;color:blue;font-size:26px\">Stemming The Words<\/h3><\/Center>\n    <\/div>","dddab39a":"<div style=\"background-color:#F5F5F5;height:70px\">\n    <Center><h3 style=\"padding-top:20px ;color:blue;font-size:26px\">Padding the tweets <\/h3><\/Center>\n    <\/div>","0967a6b9":"<div style=\"background-color:#F5F5F5;height:70px\">\n    <Center><h3 style=\"padding-top:20px ;color:blue;font-size:26px\">Dropping Nan Values<\/h3><\/Center>\n    <\/div>","c559371b":"<div style=\"background-color:#F5F5F5;height:70px\">\n    <Center><h3 style=\"padding-top:20px ;color:blue;font-size:26px\">Splitting the data<\/h3><\/Center>\n    <\/div>","e775d9de":"<div style=\"background-color:#F5F5F5;height:70px\">\n    <Center><h3 style=\"padding-top:20px ;color:blue;font-size:26px\">Adding Optimizer,loss function and Training the Model<\/h3><\/Center>\n    <\/div>","86866ba6":"<div style=\"background-color:#F5F5F5;height:70px\">\n    <Center><h3 style=\"padding-top:20px ;color:blue;font-size:26px\">Tokenizing the words<\/h3><\/Center>\n    <\/div>","22ca6df2":"<div style=\"background-color:#F5F5F5;height:70px\">\n    <Center><h3 style=\"padding-top:20px ;color:blue;font-size:26px\">Accuracy is 85%!!\ud83d\ude0e<\/h3><\/Center>\n    <\/div>","1f8e2987":"<div style=\"background-color:#F5F5F5;height:70px\">\n    <Center><h3 style=\"padding-top:20px ;color:blue;font-size:26px\">Loading the data<\/h3><\/Center>\n    <\/div>","52cf31c9":"<Center><img src=\"https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcS_z8nWP316NWiUfkQJrF-Qoiydp1oN3JnTqJcVAFz4GLZqAYz_&s\" width=\"390\" \/><\/Center>"}}