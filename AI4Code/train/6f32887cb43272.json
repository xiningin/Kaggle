{"cell_type":{"ca387e30":"code","841b905a":"code","0876ed82":"code","c3bd7942":"code","66aa5afe":"code","8e0fde11":"code","8cf9b38b":"code","7b9c950b":"code","8acbd92e":"code","b59797f4":"code","0466ab3c":"code","9686829b":"code","e3795cb1":"code","b0f1fff4":"code","b7333af2":"code","35a07d3f":"code","d6f732cb":"code","0db0fc5b":"code","2c3037d3":"code","4564aeb5":"code","5e59b328":"code","48d74bc3":"code","9548004a":"code","0d20fb68":"code","c449f53b":"markdown","bc79c145":"markdown","f8e8c8ab":"markdown","1ac6dbfa":"markdown","d78a5d33":"markdown","d80457bf":"markdown","55418ea6":"markdown","ad069723":"markdown","393af620":"markdown","88ea0536":"markdown","df6ab114":"markdown","9292126d":"markdown","e3ef505b":"markdown","6db9cd13":"markdown","74928667":"markdown"},"source":{"ca387e30":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport random\nfrom zipfile import ZipFile\nfrom PIL import Image\nimport os\n\nimport tensorflow as tf\nprint(\"TensorFlow version:\", tf.__version__)\n","841b905a":"!unzip -q '..\/input\/train.zip'\n!unzip -q '..\/input\/test1.zip'","0876ed82":"filenames = os.listdir(\".\/train\")\ncategories = []\nfor filename in filenames:\n    category = filename.split('.')[0]\n    if category == 'dog':\n        categories.append(1)\n    else:\n        categories.append(0)\n\ndf = pd.DataFrame({\n    'filename': filenames,\n    'category': categories\n})\ndf.tail()","c3bd7942":"df['category'].value_counts().plot.bar()","66aa5afe":"sample = random.choice(filenames)\nimage = load_img(\".\/train\/\"+sample)\nplt.imshow(image);","8e0fde11":"from keras import layers, applications, optimizers, callbacks\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation,GlobalMaxPooling2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications import VGG16\nfrom keras.models import Model\n\nimage_size = 224\ninput_shape = (image_size, image_size, 3)\n\nepochs = 8\nbatch_size = 16\n\npre_trained_model = VGG16(input_shape=input_shape, include_top=False, weights=\"imagenet\")\n    \nfor layer in pre_trained_model.layers[:15]:\n    layer.trainable = False\n\nfor layer in pre_trained_model.layers[15:]:\n    layer.trainable = True\n    \nlast_layer = pre_trained_model.get_layer('block5_pool')\nlast_output = last_layer.output\n    \n# Flatten the output layer to 1 dimension\nx = GlobalMaxPooling2D()(last_output)\n# Add a fully connected layer with 512 hidden units and ReLU activation\nx = Dense(512, activation='relu')(x)\n# Add a dropout rate of 0.5\nx = Dropout(0.3)(x)\n# Add a final sigmoid layer for classification\nx = layers.Dense(1, activation='sigmoid')(x)\n\nmodel = Model(pre_trained_model.input, x)\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=optimizers.Adam(lr=1e-4),\n              metrics=['accuracy'])\n\nmodel.summary()","8cf9b38b":"train_df, validate_df = train_test_split(df, test_size=0.1)\ntrain_df = train_df.reset_index()\nvalidate_df = validate_df.reset_index()\n\n# validate_df = validate_df.sample(n=100).reset_index() # use for fast testing code purpose\n# train_df = train_df.sample(n=1800).reset_index() # use for fast testing code purpose\n\ntotal_train = train_df.shape[0]\ntotal_validate = validate_df.shape[0]","7b9c950b":"train_datagen = ImageDataGenerator(\n    rotation_range=16,\n    rescale=1.\/255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest',\n    width_shift_range=0.1,\n    height_shift_range=0.1\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df, \n    \".\/train\/\", \n    x_col='filename',\n    y_col='category',\n    class_mode='binary',\n    target_size=(image_size, image_size),\n    batch_size=batch_size\n)","8acbd92e":"validation_datagen = ImageDataGenerator(rescale=1.\/255)\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    validate_df, \n    \".\/train\/\",  \n    x_col='filename',\n    y_col='category',\n    class_mode='binary',\n    target_size=(image_size, image_size),\n    batch_size=batch_size\n)","b59797f4":"example_df = train_df.sample(n=1).reset_index(drop=True)\nexample_generator = train_datagen.flow_from_dataframe(\n    example_df, \n    \".\/train\/\", \n    x_col='filename',\n    y_col='category',\n    class_mode='binary'\n)\n\nimage = load_img(\".\/train\/\"+example_df['filename'].values[0])\nplt.imshow(image);\n\nplt.figure(figsize=(15, 15))\nfor i in range(16):\n    plt.subplot(4, 4, i+1)\n    for X_batch, Y_batch in example_generator:\n        image = X_batch[0]\n        plt.imshow(image)\n        break\nplt.tight_layout()\nplt.show()","0466ab3c":"# fine-tune the model\ncheckpoint_path = 'model_0_vgg16.h5'\n\ncp_callback = callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                            save_weights_only=False,\n                                            monitor='val_loss',\n                                            save_best_only=True)\n\n\nhistory = model.fit_generator(\n    train_generator,\n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=total_validate\/\/batch_size,\n    steps_per_epoch=total_train\/\/batch_size,\n    callbacks=[cp_callback])","9686829b":"loss, accuracy = model.evaluate_generator(validation_generator, total_validate\/\/batch_size, workers=12)\nprint(\"Test: accuracy = %f  ;  loss = %f \" % (accuracy, loss))","e3795cb1":"def plot_model_history(model_history, acc='acc', val_acc='val_acc'):\n    fig, axs = plt.subplots(1,2,figsize=(15,5))\n    axs[0].plot(range(1,len(model_history.history[acc])+1),model_history.history[acc])\n    axs[0].plot(range(1,len(model_history.history[val_acc])+1),model_history.history[val_acc])\n    axs[0].set_title('Model Accuracy')\n    axs[0].set_ylabel('Accuracy')\n    axs[0].set_xlabel('Epoch')\n    axs[0].set_xticks(np.arange(1,len(model_history.history[acc])+1),len(model_history.history[acc])\/10)\n    axs[0].legend(['train', 'val'], loc='best')\n    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n    axs[1].set_title('Model Loss')\n    axs[1].set_ylabel('Loss')\n    axs[1].set_xlabel('Epoch')\n    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])\/10)\n    axs[1].legend(['train', 'val'], loc='best')\n    plt.show()\n    \nplot_model_history(history)","b0f1fff4":"Y_val = validate_df['category']\ny_pred =  model.predict_generator(validation_generator)","b7333af2":"threshold = 0.5\ny_final = np.where(y_pred > threshold, 1,0)","35a07d3f":"y_final.size","d6f732cb":"import seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n# Predict the values from the validation dataset\n\n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_val, y_final) \n# plot the confusion matrix\nf,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","0db0fc5b":"from sklearn.metrics import classification_report\n\n# Generate a classification report\nreport = classification_report(Y_val, y_final, target_names=['0','1'])\n\nprint(report)","2c3037d3":"test_filenames = os.listdir(\".\/test1\/\")\ntest_df = pd.DataFrame({\n    'filename': test_filenames\n})\nnb_samples = test_df.shape[0]","4564aeb5":"test_gen = ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_gen.flow_from_dataframe(\n    test_df, \n    \".\/test1\/\", \n    x_col='filename',\n    y_col=None,\n    class_mode=None,\n    batch_size=batch_size,\n    target_size=(image_size, image_size),\n    shuffle=False\n)","5e59b328":"predict = model.predict_generator(test_generator, steps=np.ceil(nb_samples\/batch_size))\nthreshold = 0.5\ntest_df['category'] = np.where(predict > threshold, 1,0)","48d74bc3":"sample_test = test_df.sample(n=9).reset_index()\nsample_test.head()\nplt.figure(figsize=(12, 12))\nfor index, row in sample_test.iterrows():\n    filename = row['filename']\n    category = row['category']\n    img = load_img(\".\/test1\/\"+filename, target_size=(256, 256))\n    plt.subplot(3, 3, index+1)\n    plt.imshow(img)\n    plt.xlabel(filename + '(' + \"{}\".format(category) + ')')\nplt.tight_layout()\nplt.show()","9548004a":"submission_df = test_df.copy()\nsubmission_df['id'] = submission_df['filename'].str.split('.').str[0]\nsubmission_df['label'] = submission_df['category']\nsubmission_df.drop(['filename', 'category'], axis=1, inplace=True)\nsubmission_df.to_csv('submission.csv', index=False)\n\nplt.figure(figsize=(10,5))\nsns.countplot(submission_df['label'])\nplt.title(\"(Test data)\")","0d20fb68":"!rm -r '.\/train'\n!rm -r '.\/test1'","c449f53b":"# Traning Generator","bc79c145":"# Submission","f8e8c8ab":"# Build Model","1ac6dbfa":"# Create Testing Generator","d78a5d33":"# Predict","d80457bf":"# Prepare Traning Data","55418ea6":"# Validation Generator","ad069723":"# See predicted result","393af620":"# Import Library","88ea0536":"# Prepare Test and Train Data","df6ab114":"# See sample image","9292126d":"# Fit Model","e3ef505b":"# See sample generated images","6db9cd13":"# Prepare Testing Data","74928667":"### See Total In count"}}