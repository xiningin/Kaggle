{"cell_type":{"061aa953":"code","b29cc19f":"code","dbe7e0f6":"code","3d98acb9":"code","e2013978":"code","d1051c5e":"code","0979b30d":"code","05c199a7":"code","78367a10":"code","e484b1ef":"code","985358e6":"code","9cc36548":"code","ecc80bb1":"code","efbdcea4":"code","2ae4148c":"code","7901e437":"code","9e47eeb7":"code","c360580d":"code","fb38c9b8":"code","02749234":"code","42dde12a":"code","a4a5a97a":"code","69353d5f":"code","1c389fcd":"code","71f8118c":"code","0f92d719":"code","ce70bc73":"code","f500b510":"code","9d4d5ca2":"code","5f962d28":"code","4fa7eefb":"code","6f4e6e90":"code","05294b21":"code","3615b4d3":"code","a0e603bd":"code","0b23e6bb":"code","8a2a335e":"code","8a024a54":"code","73a1a1b2":"code","f2b7d7c3":"code","dea20962":"code","83780be1":"code","b8d6629c":"code","a266d70c":"code","d3ae96e5":"code","924cbb6c":"code","2026df88":"code","1779176b":"code","ef91283e":"code","648c7465":"code","193c8c47":"code","0b7d1d74":"code","dbd1993b":"code","fc3471b5":"code","bae86858":"code","ca48b1e5":"code","41c8640b":"code","38a1f353":"code","d34d6fc0":"code","36eda493":"code","508dad43":"code","fdd0c792":"markdown","b6ec2aa6":"markdown","f3841de0":"markdown","7f7e3c26":"markdown","a3685894":"markdown","8bf6d6bd":"markdown","18e407bb":"markdown","e23b8d12":"markdown","f3befb91":"markdown","82ce21a7":"markdown","55cd5f9e":"markdown","132ff82d":"markdown","f3439b97":"markdown","2cd61363":"markdown","bba56afd":"markdown","9b457773":"markdown","fda40efe":"markdown","66a7284f":"markdown","e715a0f4":"markdown","51223e0f":"markdown","e3b1d31f":"markdown"},"source":{"061aa953":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b29cc19f":"import warnings\n\nwarnings.filterwarnings('ignore')","dbe7e0f6":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport plotly.express as px\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","3d98acb9":"df_raw = pd.read_csv('\/kaggle\/input\/weather-dataset-rattle-package\/weatherAUS.csv')\ndf = df_raw","e2013978":"df_raw","d1051c5e":"df_raw.info()","0979b30d":"df_raw.describe()","05c199a7":"#size of data... there are 3.345.580 of elements\ndf_raw.size","78367a10":"# Identification all column listed\ndf_raw.columns","e484b1ef":"# Checking data categorical\nprint(\"location :\", df_raw['Location'].unique())\nprint(\"WindGustDir :\", df_raw['WindGustDir'].unique())\nprint(\"WindDir9am :\", df_raw['WindDir9am'].unique())\nprint(\"WindDir3pm :\", df_raw['WindDir3pm'].unique())\nprint(\"RainToday :\", df_raw['RainToday'].unique())\nprint(\"RainTomorrow :\", df_raw['RainTomorrow'].unique())","985358e6":"# Checking the label counts data categorical\nprint(\"location :\", df_raw['Location'].value_counts())\nprint(\"WindGustDir :\", df_raw['WindGustDir'].value_counts())\nprint(\"WindDir9am :\", df_raw['WindDir9am'].value_counts())\nprint(\"WindDir3pm :\", df_raw['WindDir3pm'].value_counts())\nprint(\"RainToday :\", df_raw['RainToday'].value_counts())\nprint(\"RainTomorrow :\", df_raw['RainTomorrow'].value_counts())","9cc36548":"# Having a look at the correlation matrix\n\nfig, ax = plt.subplots(figsize=(15,10))\nplt.title('Correlation')\nsns.heatmap(df_raw.corr(), annot=True, fmt='.1g', cmap=\"coolwarm\");","ecc80bb1":"df_seeplotrain = df_raw","efbdcea4":"df_seeplotrain.dropna(subset=['RainToday', 'RainTomorrow'], inplace=True)","2ae4148c":"px.histogram(df_seeplotrain, x='Location', title='Location vs. Rainy Days', color='RainToday')","7901e437":"px.histogram(df_seeplotrain, \n             x='RainTomorrow', \n             color='RainToday', \n             title='Rain Tomorrow vs. Rain Today')","9e47eeb7":"df_seeplotrain.isnull().sum()","c360580d":"df_raw.isnull().sum()","fb38c9b8":"# ploting distribution data each column numerics\nfig, axes = plt.subplots(4, 4, figsize=(25, 15))\nsns.distplot(df_raw['MinTemp'], bins=20, kde=True, ax=axes[0, 0])\nsns.distplot(df_raw['MaxTemp'], bins=20, kde=True, ax=axes[0, 1])\nsns.distplot(df_raw['Rainfall'], bins=20, kde=True, ax=axes[0, 2])\nsns.distplot(df_raw['Evaporation'], bins=20, kde=True, ax=axes[0, 3])\n\nsns.distplot(df_raw['Sunshine'], bins=20, kde=True, ax=axes[1, 0])\nsns.distplot(df_raw['WindGustSpeed'], bins=20, kde=True, ax=axes[1, 1])\nsns.distplot(df_raw['WindSpeed9am'], bins=20, kde=True, ax=axes[1, 2])\nsns.distplot(df_raw['WindSpeed3pm'], bins=20, kde=True, ax=axes[1, 3])\n\nsns.distplot(df_raw['Humidity9am'], bins=20, kde=True, ax=axes[2, 0])\nsns.distplot(df_raw['Humidity3pm'], bins=20, kde=True, ax=axes[2, 1])\nsns.distplot(df_raw['Pressure9am'], bins=20, kde=True, ax=axes[2, 2])\nsns.distplot(df_raw['Pressure3pm'], bins=20, kde=True, ax=axes[2, 3])\n\nsns.distplot(df_raw['Cloud9am'], bins=20, kde=True, ax=axes[3, 0])\nsns.distplot(df_raw['Cloud3pm'], bins=20, kde=True, ax=axes[3, 1])\nsns.distplot(df_raw['Temp9am'], bins=20, kde=True, ax=axes[3, 2])\nsns.distplot(df_raw['Temp3pm'], bins=20, kde=True, ax=axes[3, 3])","02749234":"# Identification outliers data from all features\n\nfig = plt.figure(figsize=(30,15))\nsns.boxplot(data =df_raw)","42dde12a":"# variable percentage of na\nna_values = df_raw.isnull().sum()\/len(df_raw)*100\n\n#intiate plot\nplt.figure(figsize = (30,12))\nax = sns.barplot(na_values.index, na_values)\n\n# iterate over every x and y and annotate the value inside of the barchart\nfor i in range(len(na_values)):\n  ax.text(i, na_values[i]\/2, str(round(na_values[i],2)),\n  fontdict = dict(color = 'black', fontsize = 12, fontweight = 'bold'),\n  horizontalalignment = 'center')\n\n# set x & y label\nax.tick_params(axis='x', labelrotation=18, labelsize=15)\nax.tick_params(axis='y', labelsize=12)\n\n# set a title for the plot\nax.set_title('Percentage of Nan Values each features', fontsize=15, fontweight='bold')","a4a5a97a":"# Distribution of the Target variable\nfig, ax = plt.subplots(1,2)\ndf_raw['RainTomorrow'].value_counts().plot(kind='bar', ax=ax[0], cmap='Accent_r')\ndf_raw['RainTomorrow'].value_counts().plot(kind='pie', ax=ax[1], cmap='Accent_r', autopct='%.1f%%', explode=[0, 0.1])\n\nfig, ax = plt.subplots(1,2)\ndf_raw['RainToday'].value_counts().plot(kind='bar', ax=ax[0], cmap='Accent')\ndf_raw['RainToday'].value_counts().plot(kind='pie', ax=ax[1], cmap='Accent', autopct='%.1f%%', explode=[0, 0.1])","69353d5f":"# grouping column features categorics type\ncategorics = [x for x in df.columns if df[x].dtype=='object']\nprint(categorics)\n\n# grouping column features numerics type\nnumerics = [x for x in df.columns if df[x].dtype=='float64']\nprint(numerics)","1c389fcd":"df.isnull().sum()","71f8118c":"# fill na for numerics variables\ndf['MinTemp'] = df['MinTemp'].fillna(df['MinTemp'].mean())\ndf['MaxTemp'] = df['MaxTemp'].fillna(df['MaxTemp'].median())\ndf['Rainfall'] = df['Rainfall'].fillna(df['Rainfall'].median())\ndf['Sunshine'] = df['Sunshine'].fillna(df['Sunshine'].mean())\ndf['Cloud9am'] = df['Cloud9am'].fillna(df['Cloud9am'].mean())\ndf['Cloud3pm'] = df['Cloud3pm'].fillna(df['Cloud3pm'].mean())\ndf['Humidity3pm'] = df['Humidity3pm'].fillna(df['Humidity3pm'].mean())\n\ndf['Evaporation'] = df['Evaporation'].fillna(df['Evaporation'].median())\ndf['WindGustSpeed'] = df['WindGustSpeed'].fillna(df['WindGustSpeed'].median())\ndf['WindSpeed3pm'] = df['WindSpeed3pm'].fillna(df['WindSpeed3pm'].median())\ndf['Humidity9am'] = df['Humidity9am'].fillna(df['Humidity9am'].median())\ndf['WindSpeed9am'] = df['WindSpeed9am'].fillna(df['WindSpeed9am'].median())\ndf['Pressure9am'] = df['Pressure9am'].fillna(df['Pressure9am'].median())\ndf['Pressure3pm'] = df['Pressure3pm'].fillna(df['Pressure3pm'].median())\ndf['Temp9am'] = df['Temp9am'].fillna(df['Temp9am'].median())\ndf['Temp3pm'] = df['Temp3pm'].fillna(df['Temp3pm'].median())","0f92d719":"# fill na for categorics variables\ndf['WindGustDir'] = df['WindGustDir'].fillna(df[\"WindGustDir\"].mode()[0])\ndf['WindDir9am'] = df['WindDir9am'].fillna(df[\"WindDir9am\"].mode()[0])\ndf['WindDir3pm'] = df['WindDir3pm'].fillna(df[\"WindDir3pm\"].mode()[0])\ndf['RainToday'] = df['RainToday'].fillna(df[\"RainToday\"].mode()[0])\ndf['RainTomorrow'] = df['RainTomorrow'].fillna(df[\"RainTomorrow\"].mode()[0])","ce70bc73":"# Checking any missing values\ndf[df.isnull().any(axis = 1)]","f500b510":"# Mapping value for some categorical features\n\ndf['RainTomorrow'] = df['RainTomorrow'].map({'Yes': 1, 'No': 0})\ndf['RainToday'] = df['RainToday'].map({'Yes': 1, 'No': 0})","9d4d5ca2":"#feature engineering\ndf['IsHeavyRain'] = (df.RainToday == 1 ) & (df.Rainfall >= 100) \ndf['IsHeavyRain'] = df['IsHeavyRain'].map({True: 1, False: 0})\ndf['CloudyAllDay'] = (df.RainToday == 0 ) & (df.Cloud3pm == df.Cloud9am)\ndf['CloudyAllDay'] = df['CloudyAllDay'].map({True: 1, False: 0})","5f962d28":"df.head()","4fa7eefb":"#spliting dataset\nX = df.drop(['Date', 'RainTomorrow', 'Location'], axis = 1)\ny = df['RainTomorrow']\n\nprint(X)\n","6f4e6e90":"# One hot encoding\nX = pd.get_dummies(X)\ndisplay(X)","05294b21":"# Encoding the target variable\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ny = le.fit_transform(y)","3615b4d3":"print(y)","a0e603bd":"y","0b23e6bb":"# Split dataset \nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3,random_state = 123)","8a2a335e":"X","8a024a54":"# Decision Tree\nfrom sklearn.tree import DecisionTreeClassifier\ndectree = DecisionTreeClassifier(criterion = 'entropy', random_state = 0, max_depth=5)\ndectree.fit(X_train, y_train)","73a1a1b2":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\ny_test_pred = dectree.predict(X_test)\nprint('Accuracy score :', accuracy_score(y_test, y_test_pred))\nprint(classification_report(y_test, y_test_pred))","f2b7d7c3":"y_train_pred = dectree.predict(X_train)\naccuracy_score(y_train, y_train_pred)\nprint('Accuracy score :', accuracy_score(y_train, y_train_pred))\nprint(classification_report(y_train, y_train_pred))","dea20962":"def search_tree(X_train, X_test, y_train, y_test, max_depths):\n    acc_train = []\n    acc_test = []\n    for depth in max_depths:\n        # Train based on tree's depth\n        classifier = DecisionTreeClassifier(criterion='entropy', random_state=0,\n                                            max_depth=depth)\n        classifier.fit(X_train, y_train)\n        \n        # Predict the result\n        y_train_pred = classifier.predict(X_train)\n        y_test_pred = classifier.predict(X_test)\n        \n        # Training Performance\n        score_train = accuracy_score(y_train, y_train_pred)\n        acc_train.append(score_train)\n\n        # Test Performance\n        score_test = accuracy_score(y_test, y_test_pred)\n        acc_test.append(score_test)\n\n    result = pd.DataFrame({'depths': max_depths, 'acc_train': acc_train, 'acc_test': acc_test})\n\n    plt.figure(figsize=(12, 8))\n    plt.title('Decision Tree Performance')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Max Depths')\n    sns.lineplot(data=result, x='depths', y='acc_train')\n    sns.lineplot(data=result, x='depths', y='acc_test')\n    plt.grid()\n    plt.xticks(result['depths'])\n    plt.show()","83780be1":"# Visualize Decision Tree\nfrom sklearn import tree\n\nplt.figure(figsize=(25,12))\ntree.plot_tree(dectree, feature_names=X.columns,\n               class_names=['Rain', 'Not Rain'],\n               filled=True)\nplt.show()","b8d6629c":"df_feature_imp = pd.DataFrame([X_train.columns,dectree.feature_importances_]).transpose()\ndf_feature_imp.columns = ['feature','feature_score']","a266d70c":"params ={'max_depth':[1,3,5,8,10,20,'max']}","d3ae96e5":"from sklearn.model_selection import GridSearchCV\ngrid = GridSearchCV(\n             estimator=dectree, # model yang akan digunakan\n             param_grid=params, # hyperparameter yang dipilih\n             scoring = 'accuracy', # metrics evaluation\n             n_jobs = 10, # core cpu yang digunakan\n             cv = 3 # 3-fold cross validation (artinya kita melakukan iterasi model sebanyak 3 kali)\n            )","924cbb6c":"# harus dilakukan standardization\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_scaler = scaler.fit_transform(X_train)\nX_scaler = pd.DataFrame(X_scaler,columns = X_train.columns)","2026df88":"grid.fit(X_scaler,y_train)","1779176b":"grid.best_params_","ef91283e":"def evaluasi(model,X_test,y_test):\n    from sklearn.metrics import accuracy_score\n\n    X_scaler_test = scaler.transform(X_test)\n    y_pred = model.predict(X_scaler_test)\n    \n    return accuracy_score(y_test,y_pred)*100","648c7465":"evaluasi(dectree,X_test,y_test)","193c8c47":"accuracy = evaluasi(grid,X_test,y_test)","0b7d1d74":"print('accuracy : {0:.5f}%'.format(accuracy))","dbd1993b":"# harus dilakukan standardization\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_scaler = scaler.fit_transform(X_train)\nX_scaler = pd.DataFrame(X_scaler,columns = X_train.columns)","fc3471b5":"def prediksi(model,X_test):\n    X_scaler = scaler.transform(X_test)\n    return model.predict(X_scaler)\n     ","bae86858":"def evaluasi(model,X_test,y_test):\n    from sklearn.metrics import accuracy_score\n\n    X_scaler_test = scaler.transform(X_test)\n    y_pred = model.predict(X_scaler_test)\n    \n    return accuracy_score(y_test,y_pred)*100","ca48b1e5":"# harus dilakukan standardization\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_scaler = scaler.fit_transform(X_train)\nX_scaler = pd.DataFrame(X_scaler,columns = X_train.columns)","41c8640b":"grid.fit(X_scaler,y_train)","38a1f353":"list_feature_imp = ['Humidity3pm','WindGustSpeed', 'Sunshine',\n                     'Rainfall', 'Pressure3pm', 'Pressure9am',\n                    'Cloud3pm', 'MinTemp']","d34d6fc0":"scaler = MinMaxScaler()\nX_scaler = scaler.fit_transform(X_train[list_feature_imp])\nX_scaler = pd.DataFrame(X_scaler,columns = X_train[list_feature_imp].columns)","36eda493":"from sklearn.tree import DecisionTreeClassifier\ndectree = DecisionTreeClassifier()\ndectree.fit(X_scaler[list_feature_imp],y_train)","508dad43":"evaluasi(dectree,X_test[list_feature_imp],y_test)","fdd0c792":"# 4. Exploratory Data Analysis with Visualisation\nIn this step, we would analyze the data set, learn the statistics and correlation between different features","b6ec2aa6":"There are significatn amount of missing values in the dataset especially in columns like \"sunshine\". \"Evaporation\",\"Cloud3pm\", \"cloud9pm\". It is also observed that there are different types of data type like object, float64, int64.\n\nLets look at the basic statistics of the data","f3841de0":"**Correlation plot**","7f7e3c26":"## 7. Split Train Test Validation & Creating Modelling","a3685894":"# 6. Spliting Dataset","8bf6d6bd":"**Show Distributtion Plot using seaborn**","18e407bb":"# 2. Problem Statement\n\nIn this notebook we will learn how to implement how to apply logistic regression in a real world data. We are using open kaglle data set named, \"Rain in Australia\". It is a 10 year historical rainfall data that comes in csv file format. After doing primary data exploration, we will try to predict next day rainfall for different regions in australia.\n\n","e23b8d12":"**Identify Data Categorical values**","f3befb91":"# 3. Loading Dataset\nWe will first load and import the dataset to work with","82ce21a7":"# 5. Data Pre-Processing","55cd5f9e":"for fill missing value on dataset we using approch median & mean value for fill the null value.","132ff82d":"# 8. Min Max Scaller","f3439b97":"**## Maaping Value Rain Today and Rain Tomorrow**","2cd61363":"**Identify Outliers Data******","bba56afd":"# 1. Import Necessary Libraries","9b457773":"**## Feature Engineering**","fda40efe":"We can see that this dataset contains over 145,000 rows and 23 columns including date, numeric and categorical columns. We will create a model which will predict the RainTomorrow by using other features.","66a7284f":"**Counting in percentage missing values**","e715a0f4":"# 9. Logistic Regression & Decision Tree with Feature Important","51223e0f":"![](http:\/\/)","e3b1d31f":"**## Encoder data features**"}}