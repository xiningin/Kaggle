{"cell_type":{"5da727bb":"code","90f27c9c":"code","3f0bcab7":"code","59895737":"code","1fb0c804":"code","d9c5a928":"code","50935b25":"code","b30925cd":"code","76f0ba25":"code","abd236d8":"code","be20b22f":"code","c03acf5f":"code","9c4275a4":"code","42c739f4":"code","1334915a":"code","40046992":"code","0a6ba15a":"code","706b240d":"code","8a6199d1":"code","58e4e698":"code","1a4bf82c":"code","01e7d3af":"code","6b775ae8":"code","c60555d3":"code","7226a1d1":"code","b0ec5f31":"code","9872d594":"code","b279ce8e":"code","7aa5eb1e":"code","bf080158":"code","81a20225":"markdown","bba39e31":"markdown","b2bc8b0f":"markdown","f2b27b50":"markdown","aa87c31d":"markdown","6ed0996f":"markdown","9558069d":"markdown","0d99f9fd":"markdown","88cc0be0":"markdown"},"source":{"5da727bb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","90f27c9c":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","3f0bcab7":"test = pd.read_csv('..\/input\/titanic\/test.csv')\ntest = test.drop(['Name', 'Ticket', 'Cabin'], axis = 1)\n      \nfor i in range(len(test)):\n    if(test.loc[i,'Sex'] == 'male'):\n        test.loc[i,'Sex'] = 1;\n    else:\n        test.loc[i,'Sex'] = 0\n        \nnew_embark = pd.get_dummies(test['Embarked'],drop_first=True)\ntest.drop(['Embarked'],axis=1,inplace=True)\ntest = pd.concat([test,new_embark],axis=1)\ntest['Fare'] = test['Fare'].fillna(test['Fare'].median())\n\ntest['Age'] = test[\"Age\"].fillna(test['Age'].median())\n\ntest2 = test\n\ntest.head()","59895737":"df = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ndf.info()","1fb0c804":"df.head(10)","d9c5a928":"df.describe()","50935b25":"print(df['Survived'].value_counts())\nsns.countplot(data = df, x = df['Survived'],palette='RdBu_r')","b30925cd":"sns.countplot(data = df, x = df['SibSp'], palette='RdBu_r')","76f0ba25":"sns.boxplot(x='Pclass',y='Fare',data=df)","abd236d8":"sns.boxplot(x='Embarked',y='Age',data=df, palette='RdBu_r')","be20b22f":"sns.countplot(x='Survived',data=df,hue='Pclass', palette='RdYlBu_r')","c03acf5f":"df = df.drop(['Name', 'Ticket', 'Cabin'],axis = 1)","9c4275a4":"sns.pairplot(df,hue='Survived')","42c739f4":"for i in range(len(df)):\n    if(df.loc[i,'Sex'] == 'male'):\n        df.loc[i,'Sex'] = 1;\n    else:\n        df.loc[i,'Sex'] = 0\n        \ndf.head()","1334915a":"df.isnull().sum()","40046992":"df['Age'] = df[\"Age\"].fillna(df['Age'].median())\ndf[df['Embarked'].isnull()]","0a6ba15a":"df = df.drop([61,829], axis = 0)","706b240d":"df.isnull().sum()","8a6199d1":"df['Embarked'].value_counts()","58e4e698":"New_Embark = pd.get_dummies(df['Embarked'], drop_first=True)\ndf.drop(['Embarked'], axis=1, inplace =True)\ndf = pd.concat([df,New_Embark], axis=1)\ndf.head(10)","1a4bf82c":"sns.heatmap(df.corr(), annot=True)","01e7d3af":"from sklearn.model_selection import train_test_split as tts\ny = df['Survived']\nX = df.drop('Survived', axis=1)\ntrain_X, val_X, train_y, val_y= tts(X, y, test_size=0.3, random_state=42)","6b775ae8":"from sklearn.preprocessing import StandardScaler as ss\ns = ss()\ns.fit(train_X)\ntrain_X = s.transform(train_X)\nval_x = s.transform(val_X)\nval = s.transform(test)","c60555d3":"from sklearn.linear_model import LogisticRegression as lr\n\nl_model = lr()\nl_model.fit(train_X, train_y)\ny_pred = l_model.predict(val_X)","7226a1d1":"param = l_model.get_params()\npd.DataFrame(data=param, index=[0])","b0ec5f31":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, plot_confusion_matrix\naccuracy_score(val_y, y_pred)","9872d594":"from sklearn.metrics import plot_confusion_matrix\nplot_confusion_matrix(l_model, train_X, train_y)","b279ce8e":"print(classification_report(val_y, y_pred))","7aa5eb1e":"y_test_pred= l_model.predict(test)\ntest","bf080158":"my_submission = pd.DataFrame({'PassengerId': test2.PassengerId, 'Survived': y_test_pred})\nmy_submission.to_csv('TitanicSubmission.csv', index=False)","81a20225":"## Training and Testing Models","bba39e31":"# **Import Libraries**","b2bc8b0f":"## As you can see, about 5% of Age is missing. Along with 2 missing datas from Embarked Column. Most of then wrong predictions happens due to missing data. Now our job is to drop these rows which have null values.","f2b27b50":"# **Dummy Data**","aa87c31d":"# **Logistic Regression**","6ed0996f":"# **EDA**","9558069d":"## First find the missing datas in each columns","0d99f9fd":"# **Model Evaluation**","88cc0be0":"# **Missing Data**"}}