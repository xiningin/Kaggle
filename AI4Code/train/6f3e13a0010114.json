{"cell_type":{"b0992218":"code","dfe689ad":"code","3577bd09":"code","d47478b5":"code","f42acc8f":"code","8dd6390c":"code","766975f3":"code","e9fe5f62":"code","6803287b":"code","2b3b540f":"code","c5b208c5":"code","edc16351":"code","cb42344d":"code","a77c0791":"code","434cfdf7":"code","76eaffc6":"code","908f128c":"code","5cb9087a":"code","655347bf":"code","046332ad":"code","ee7f27bd":"code","967a9791":"code","a6919992":"code","79586da4":"code","b75d0dee":"code","2d2b0f2b":"code","98afded6":"code","68309e23":"code","a68c9945":"code","0857af73":"code","5cfb6e6a":"code","361626f4":"code","58ed62d9":"code","1a1efbce":"code","b9240891":"code","da02ca1b":"code","0288e90d":"code","6f8def7b":"code","51c85fec":"code","f21202e3":"code","d9417839":"code","4d34ec4f":"code","248d8ec7":"code","09f731fc":"code","cb530832":"code","104f1de3":"code","e135dbd0":"code","a7a40401":"code","3a891990":"code","0bc3a23f":"code","ee65f9f1":"code","dca465e2":"code","1b6aeb86":"code","5488380f":"code","721b6186":"code","5343b7c6":"code","711a8a2f":"code","eff46cb5":"code","513b251f":"code","fe0a6424":"code","e7ffb90e":"code","4617400d":"code","bf78a276":"code","9a769a4f":"code","69895f51":"code","e744f85c":"code","c4827d1f":"code","77ccd80f":"code","d527b56e":"code","0810e112":"code","f53ce3bf":"code","57897fe4":"code","db880c33":"code","d4a5843a":"code","1996fa80":"code","08c6eb43":"code","ccb4c02a":"code","86c9a597":"code","f6ac87b8":"code","9b8ea935":"code","a2d59e87":"code","5bd72af7":"code","60defb1b":"code","5792347c":"code","bab58433":"code","29ffc69d":"code","ef7e116c":"code","f4578860":"code","6ade1ab6":"code","bce46f6b":"code","e5fb1447":"code","2c7f22dd":"code","162a08ed":"code","4d027cb8":"code","81277263":"code","2efcf5cb":"code","db4b83ee":"code","e2f53bdf":"code","fe210b16":"code","8cafb4cc":"code","55213941":"code","4227a60a":"code","e64e5575":"code","702ec4a3":"code","4381d9ab":"code","3b195dd1":"code","e7e78c32":"code","62ea2f6f":"code","8034d47b":"code","0318907f":"code","4eaacbab":"code","88871943":"code","125d7800":"code","e940781f":"code","df397871":"code","36d60064":"code","2030ec7b":"code","5b56f5f9":"code","929cc442":"code","00e3e0aa":"code","9c91bb61":"code","b8286ad0":"code","4d6eee2d":"code","b264a5e4":"code","84f0e3d8":"markdown","c87201c5":"markdown","38d4b85b":"markdown","56ebe37a":"markdown","9c66762a":"markdown","e9712f82":"markdown","015e13f6":"markdown","f92f3acf":"markdown","c342f287":"markdown","9da41f5d":"markdown","ba87f796":"markdown","4e75d5d3":"markdown","00e30824":"markdown","30e664e0":"markdown","3cab1c4b":"markdown","290c77c1":"markdown","e672e74f":"markdown","cb9b222c":"markdown","5b5ff6e9":"markdown","9bb05b9d":"markdown","65b3ea21":"markdown","fbb26212":"markdown","33af8c00":"markdown","fb401a17":"markdown","9f9161b7":"markdown","0d4430ee":"markdown","2d7800dd":"markdown","66c258db":"markdown","89db71bd":"markdown","a755a5c4":"markdown","db88bc1f":"markdown","3245f75d":"markdown","4d309f3b":"markdown","314c35e2":"markdown","e6c6c702":"markdown","5dd51dc2":"markdown","d7380cb1":"markdown","a2fcc15e":"markdown","e805481a":"markdown","4dda5e8b":"markdown","8f21e76f":"markdown","8afd8836":"markdown","b671a7d5":"markdown","710bb76f":"markdown","66b45231":"markdown","3de1b57f":"markdown","4b02bfd8":"markdown","d23cfb42":"markdown","1346d77a":"markdown","28d7a24e":"markdown","6688f662":"markdown","cae71109":"markdown","678a8595":"markdown","01c31756":"markdown","f72d32a3":"markdown","a0690dd6":"markdown","9ea8b6ba":"markdown","2f51a175":"markdown","47dec716":"markdown","604b8fda":"markdown","d4b94e37":"markdown","834a2276":"markdown","f83acccc":"markdown","d8f4175e":"markdown","be3471fe":"markdown","d39ab301":"markdown","3566f0ac":"markdown","9a5fd2af":"markdown","acbdff99":"markdown","e3f312a9":"markdown","489ed1fe":"markdown","f964bb71":"markdown","f3204c77":"markdown","93f32cb9":"markdown","841b92e7":"markdown","936c6c4e":"markdown","2cf79e67":"markdown","b43bfd4b":"markdown"},"source":{"b0992218":"import numpy as np # linear algebra\nimport pandas as pd # import in pandas\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport os\nprint(os.listdir(\"..\/input\"))","dfe689ad":"mySeries = pd.Series([3,-5,7,4], index=['a','b','c','d'])\ntype(mySeries)","3577bd09":"pd.Series([1, 2, 3])","d47478b5":"series=pd.Series([1,2,3])\nser=pd.Series(pd.Categorical([1,2,3,4,4,3]))\nprint(type(ser))","f42acc8f":"data = {'Country' : ['Belgium', 'India', 'Brazil' ],\n        'Capital': ['Brussels', 'New Delhi', 'Brassilia'],\n        'Population': [1234,1234,1234]}\ndatas = pd.DataFrame(data, columns=['Country','Capital','Population'])\nprint(type(data))\nprint(type(datas))","8dd6390c":"dictionary={\"Name\":[\"John\",\"James\",\"Awi\",\"Kewi\"],\n           \"Age\":[15,16,17,18]}\nprint(dictionary)\ndata_dict=pd.DataFrame(data=dictionary,index=range(4),columns=[\"Name\",\"Age\"])\nprint(data_dict)\nprint(\"*\"*50)\ndict_new={\"Name\":[\"King\",\"Arthur\",\"Jurdi\",\"Hirdi\"],\n           \"Age\":[25,35,45,55]}\ndict_new=pd.DataFrame(data=dict_new,index=range(4),columns=[\"Name\",\"Age\"])\ndata_dict=pd.concat([data_dict,dict_new],axis=0,ignore_index=True)\nprint(data_dict)","766975f3":"df = pd.read_csv('..\/input\/DJIA_table.csv')\ntype(df)\n# If your Python file is not in the same folder as your CSV file, you should do this as follows.\n# df = pd.read_csv('\/home\/desktop\/Iris.csv')","e9fe5f62":"# pd.read_excel('filename')\n# pd.to_excel('dir\/dataFrame.xlsx', sheet_name='Sheet1')","6803287b":"# pd.read_sql(query,connection_object) -> Reads from a SQL table\/database\n# pd.read_table(filename) -> From a delimited text file(like TSV)\n# pd.read_json(json_string) -> Reads from a json formatted string, URL or file\n# pd.read_html(url) -> Parses an html URL, string or file and extracts tables to a list of dataframes\n# pd.read_clipboard() -> Takes the contentes of your clipboard and passes it to read_table()\n# pd.DataFrame(dict) -> From a dict, keys for columns names, values for data as lists","2b3b540f":"# df.to_csv(filename) -> Writes to a CSV file\n# df.to_excel(filename) -> Writes on an Excel file\n# df.to_sql(table_name, connection_object) -> Writes to a SQL table\n# df.to_json(filename) -> Writes to a file in JSON format\n# df.to_html(filename) -> Saves as an HTML table\n# df.to_clipboard() -> Writes to the clipboard","c5b208c5":"pd.DataFrame(np.random.rand(20,5)) # 5 columns and 20 rows of random floats","edc16351":"df.info()","cb42344d":"df.dtypes","a77c0791":"df.shape","434cfdf7":"df.index","76eaffc6":"df.columns","908f128c":"for col in df.columns:\n    print(col)","5cb9087a":"for i,col in enumerate(df.columns):\n    print((i+1),'-',col)","655347bf":"df=df.rename(columns=({'Date':'Date','Open':'Open','High':'High','Low':'Low','Close':'Close','Volume':'Volume','Adj Close':'Adj Close','Difference':'Difference'}))","046332ad":"df.count()","ee7f27bd":"df.sum()","967a9791":"df.dtypes","a6919992":"df.sample(3)","79586da4":"np.sum(df.iloc[:,2]) #High","b75d0dee":"np.sum(df.iloc[:,1:]) #High","2d2b0f2b":"df.cumsum().head()","98afded6":"df.cumsum().tail()","68309e23":"df.cumsum().sample(5)","a68c9945":"df.cumsum().sample(frac=0.001)","0857af73":"df.min()","5cfb6e6a":"min(df.High)","361626f4":"min(df.Close)","58ed62d9":"df.max()","1a1efbce":"df.min()","b9240891":"max(df.High)","da02ca1b":"print(\"df: \",df['Open'].idxmin())\nprint(\"series\", mySeries.idxmin())","0288e90d":"print(\"df: \",df['Open'].idxmax())\nprint(\"series: \",mySeries.idxmax())","6f8def7b":"df.describe()","51c85fec":"df[['Open','High','Low']].describe()","f21202e3":"df.mean()","d9417839":"df.median()","4d34ec4f":"df.quantile([0.25,0.75])","248d8ec7":"df.quantile([0.5])","09f731fc":"df.var()","cb530832":"df.std()","104f1de3":"df.cummax()","e135dbd0":"df.cummin()","a7a40401":"df['Open'].cumprod().head()","3a891990":"len(df)","0bc3a23f":"df.isnull().head()","ee65f9f1":"df.isnull().values","dca465e2":"df.isnull().values.any()","1b6aeb86":"np.arange(10) #ordinary numbers","5488380f":"type(np.arange(10))","721b6186":"range(10) #list number","5343b7c6":"type(range(10))","711a8a2f":"type(list(range(10)))","eff46cb5":"list(range(10))","513b251f":"df.isna().count()","fe0a6424":"df.isnull().values.any()","e7ffb90e":"df.isnull().sum()","4617400d":"df.corr()","bf78a276":"import seaborn as sns\nsns.heatmap(df.corr(),annot=True)\nplt.show()","9a769a4f":"df[['Open','High','Low','Close']].corr()","69895f51":"sns.heatmap(df.corr(), vmax=.3, square=True)\nplt.show()","e744f85c":"import numpy as np; np.random.seed(0)\nimport seaborn as sns; sns.set()\nuniform_data = np.random.rand(10, 12)\nax = sns.heatmap(uniform_data)","c4827d1f":"df[['Open','High','Low','Close','Volume']].corr()","77ccd80f":"import seaborn as sns\nimport matplotlib.pyplot as plt\nsns.heatmap(df.corr(),annot=True,fmt='.1f')\nplt.show()","d527b56e":"mySeries['b']","0810e112":"df[1982:]\n#Or\n#df[5:7]","f53ce3bf":"print(len(df))\nprint(len(df.columns))\ndf[:-1982]","57897fe4":"df.iloc[[0],[3]]","db880c33":"#df.loc[n:]\n# OR\ndf.loc[5:7]","d4a5843a":"df.loc[:7]","1996fa80":"df['Open'].head()\n# OR\n# df.Open","08c6eb43":"df['Open'][0]\n# OR\n# df.Open[0]\n# df[\"Open\"][1]\ndf.loc[1,[\"Open\"]]","ccb4c02a":"df['Open'].nunique()","86c9a597":"df['Open'].unique()\n# We can write the above code as follows:: df.Open.unique()","f6ac87b8":"df.Open.head()","9b8ea935":"print(df.Open.value_counts(dropna =True).head())\n# OR\n# print(df['Item'].value_counts(dropna =False))","a2d59e87":"df.head()\n# OR\n# df.head(15)","5bd72af7":"df.tail()\n# OR\n# df.tail(20)","60defb1b":"df.sample(frac=.3).tail()","5792347c":"df.sample(5)","bab58433":"df.sample(frac=0.5).head()","29ffc69d":"df.nlargest(5,'Open')","ef7e116c":"df.nsmallest(3,'Open')","f4578860":"df[df.Open > 18281.949219]","6ade1ab6":"df[['High','Low']].head()\n# df.loc[:,[\"High\",\"Low\"]]","bce46f6b":"df.loc[:,\"Date\":\"Close\"].head()\n# OR\n# data.loc[:3,\"Date\":\"Close\"]","e5fb1447":"df.iloc[:,:].head()","2c7f22dd":"filters = df.Date > '2016-06-27'\ndf[filters]","162a08ed":"df.filter(regex='^L').head()","4d027cb8":"df[np.logical_and(df['Open']>18281.949219, df['Date']>'2015-05-20' )]","81277263":"df[(df['Open']>18281.949219) & (df['Date']>'2015-05-20')]","2efcf5cb":"df.sort_values('Open').head()","db4b83ee":"df.sort_values('Close').tail()","e2f53bdf":"df.sort_values(by='Date', ascending=True).head()","fe210b16":"df.sort_values(by='Date', ascending=True).tail()","8cafb4cc":"df.sort_values(by='Date',ascending=False).sample(frac=0.01)","55213941":"df.sort_values('Date', ascending=False).head()","4227a60a":"df.sort_index().head()","e64e5575":"df.rename(columns= {'Adj Close' : 'Adjclose'}).head()\n# df = df.rename(columns= {'Id' : 'Identif'}, inplace=True) -> True way\n# inplace= True or False; This meaning, overwrite the data set.\n# Other Way\n# df.columns = ['date', 'open', 'high', 'low', 'close', 'volume', 'adjclose']","702ec4a3":"df[\"Difference\"] = df.High - df.Low\ndf.head()","4381d9ab":"print(df.index.name)\ndf.index.name = \"index_name\"\ndf.head()","3b195dd1":"#df.columns = map(str.lower(), df.columns)","e7e78c32":"#df.columns = map(str.upper(), df.columns)","62ea2f6f":"df.drop(columns=['Adj Close']).head()\n# df = df.drop(columns=['Id']) -> True way\n# OR\n# df = df.drop('col', axis=1)\n# axis = 1 is meaning delete columns\n# axis = 0 is meaning delete rows","8034d47b":"mySeries.drop(['a'])","0318907f":"# df.drop(['2016-07-01', '2016-06-27'])","4eaacbab":"# df.drop('Volume', axis=1)","88871943":"df.dtypes","125d7800":"df.Date.astype('category').dtypes\n# OR Convert Datetime\n# df.Date= pd.to_datetime(df.Date)","e940781f":"df_new = df.head()\nmelted = pd.melt(frame=df_new,id_vars = 'Date', value_vars= ['Low'])\nmelted","df397871":"df_new_1 = df.tail()\nmelted = pd.melt(frame=df_new_1,id_vars = 'Date', value_vars= ['Low','Close','High'])\nmelted","36d60064":"df.tail()","2030ec7b":"def examples(x):   #create a function\n    return x*2\n\ndf.Open.apply(examples).head()  #use the function with apply() ","5b56f5f9":"df.Open.apply(lambda x: x*2).head()","929cc442":"df.Open.apply(lambda x: x**2).head()","00e3e0aa":"df.corr()","9c91bb61":"sns.heatmap(df.corr(),annot=True,fmt='.1f')\nplt.show()","b8286ad0":"df.head()","4d6eee2d":"  df.dtypes","b264a5e4":"max(df.Close)","84f0e3d8":"### **len(df)** <a id=\"34\"><\/a>\nThis code gives you how many data there is.\n\n<mark>[Return Contents](#0)\n<hr>","c87201c5":"# **Selection & Filtering** <a id=\"36\"><\/a>\n<mark>[Return Contents](#0)\n<hr>\n\nThis is how we can choose the data we want with pandas, how we can bring unique data.","38d4b85b":"# **Exporting Data** <a id=\"11\"><\/a>\n<mark>[Return Contents](#0)\n<hr>","56ebe37a":"### **Filtering with &** <a id=\"59\"><\/a>\n<mark>[Return Contents](#0)\n<hr>","9c66762a":"# **Summarize Data** <a id=\"13\"><\/a>\n<mark>[Return Contents](#0)\n<hr>\n\nIt's easy to get information about data with pandas. It makes it easier for us. Let's examine the existing functions one by one","e9712f82":"### **mySeries.drop(['a'])** <a id=\"72\"><\/a>\nThis code allows us to delete the value specified in the series.\n\n<mark>[Return Contents](#0)\n<hr>","015e13f6":"### **idxmin()**  <a id=\"23\"><\/a>\nThis code fetches the smallest value in the data. The use on series and dataframe is different.\n\n<mark>[Return Contents](#0)\n<hr>","f92f3acf":"### **df['columnName'].unique()** <a id=\"44\"><\/a>\nThis code shows which of the data in the selected column repeats.\n\n<mark>[Return Contents](#0)\n<hr>","c342f287":"### **df.min()** <a id=\"21\"><\/a>\nThis code brings us the smallest of the data.\n\n<mark>[Return Contents](#0)\n<hr>","9da41f5d":"### **df['columnName'].value_counts(dropna =False)** <a id=\"46\"><\/a>\nThis code counts all of the data in the column we have specified, but does not count the null\/none values.\n\n<mark>[Return Contents](#0)\n<hr>","ba87f796":"### **df.filter(regex = 'code')** <a id=\"57\"><\/a>\nThis code allows regex to filter any data we want.\n\n<mark>[Return Contents](#0)\n<hr>","4e75d5d3":"# **Pandas Tutorial** <a id=\"0\"><\/a>\n<hr>\n1. [Overview](#1)\n2. [Pandas Library About](#2)\n3. [Import Library](#3)\n4. [Pandas Data Structure](#4)\n    * [Series](#5)\n    * [DataFrame](#6)\n5. [Import Data](#7)\n    * [CSV](#8)\n    * [Excel](#9)\n    * [Others(json, SQL, html)](#10)\n6. [Exporting Data](#11)\n7. [Create Test Objects](#12)\n8. [Summariza Data](#13)\n    * [df.info()](#14)\n    * [df.shape()](#15)\n    * [df.index](#16)\n    * [df.columns](#17)\n    * [df.count()](#18)\n    * [df.sum()](#19)\n    * [df.cumsum()](#20)\n    * [df.min()](#21)\n    * [df.max()](#22)\n    * [idxmin()](#23)\n    * [idxmax()](#24)\n    * [df.describe()](#25)\n    * [df.mean()](#26)\n    * [df.median()](#27)\n    * [df.quantile([0.25,0.75])](#28)\n    * [df.var()](#29)\n    * [df.std()](#30)\n    * [df.cummax()](#31)\n    * [df.cummin()](#32)\n    * [df['columnName'].cumproad()](#33)\n    * [len(df)](#34)\n    * [df.isnull()](#35)\n    * [df.corr()](#81)\n9. [Pandas with Selection & Filtering](#36)\n    * [series['index']](#37)\n    * [df[n:n]](#38)\n    * [df.iloc[[0],[5]]](#39)\n    * [df.loc[n:n]](#40)\n    * [df['columnName']](#41)\n    * [df['columnName][n]](#42)\n    * [df['columnName'].nunique()](#43)\n    * [df['columnName'].unique()](#44)\n    * [df.columnName](#45)\n    * [df['columnName'].value_counts(dropna =False)](#46)\n    * [df.head(n)](#47)\n    * [df.tail(n)](#48)\n    * [df.sample(n)](#49)\n    * [df.sample(frac=0.5)](#50)\n    * [df.nlargest(n,'columnName')](#51)\n    * [df.nsmallest(n,'columnName')](#52)\n    * [df[df.columnName < n]](#53)\n    * [df[['columnName','columnName']] ](#54)\n    * [df.loc[:,\"columnName1\":\"columnName2\"]](#55)\n    * [Create Filter](#56)\n    * [df.filter(regex = 'code')](#57)\n    * [np.logical_and](#58)\n    * [Filtering with &](#59)\n10. [Sort Data](#60)\n    * [df.sort_values('columnName')](#61)\n    * [df.sort_values('columnName', ascending=False)](#62)\n    * [df.sort_index()](#63)\n11. [Rename & Defining New & Change Columns](#64)\n    * [df.rename(columns= {'columnName' : 'newColumnName'})](#65)\n    * [Defining New Column](#66)\n    * [Change Index Name](#67)\n    * [Make all columns lowercase](#68)\n    * [Make all columns uppercase](#69)\n12. [Drop Data](#70)\n    * [df.drop(columns=['columnName'])](#71)\n    * [Series.drop(['index'])](#72)\n    * [Drop an observation (row)](#82)\n    * [Drop a variable (column)](#83)\n13. [Convert Data Types](#73)\n    * [df.dtypes](#74)\n    * [df['columnName'] = df['columnName'].astype('dataType')](#75)\n    * [pd.melt(frame=dataFrameName,id_vars = 'columnName', value_vars= ['columnName'])](#76)\n14. [Apply Function](#77)\n    * [Method 1](#78)\n    * [Method 2](#79)\n15. [Utilities Code](#80)","00e30824":"### **df[n:n]** <a id=\"38\"><\/a>\nThis code fetches data from N to N.\n\n<mark>[Return Contents](#0)\n<hr>","30e664e0":"### **Drop an observation (row)** <a id=\"82\"><\/a>\n\n<mark>[Return Contents](#0)\n<hr>","3cab1c4b":"# **Sort Data** <a id=\"60\"><\/a>\n\n<mark>[Return Contents](#0)\n<hr>\n\n### **df.sort_values('columnName')** <a id=\"61\"><\/a>\nThis code sorts the column we specify in the form of low to high.","290c77c1":"###  **Defining New Column** <a id=\"66\"><\/a>\nCreate a new column\n\n<mark>[Return Contents](#0)\n<hr>","e672e74f":"### **np.logical_and** <a id=\"58\"><\/a>\nFiltering with logical_and. Lets look at the example.\n\n<mark>[Return Contents](#0)\n<hr>","cb9b222c":"### **df.nsmallest(n,'columnName')** <a id=\"52\"><\/a>\nThis code brings N from the column where we have specified the smallest data.\n\n<mark>[Return Contents](#0)\n<hr>","5b5ff6e9":"### **df.sample(frac=0.5)** <a id=\"50\"><\/a>\nThis code selects the fractions of random rows and fetches the data to that extent.\n\n<mark>[Return Contents](#0)\n<hr>","9bb05b9d":"### **Drop a variable (column)** <a id=\"83\"><\/a>\n\n<mark>[Return Contents](#0)\n<hr>\nNote: axis=1 denotes that we are referring to a column, not a row","65b3ea21":"### **mySeries['b']** <a id=\"37\"><\/a>\nThis code returns data with a value of B in series.\n\n<mark>[Return Contents](#0)\n<hr>","fbb26212":"### **df.cumsum()** <a id=\"20\"><\/a>\nThis code gives us cumulative sum of the data.\n\n<mark>[Return Contents](#0)\n<hr>","33af8c00":"### **Others(json, SQL, table, html)** <a id=\"10\"><\/a>","fb401a17":"### **Method 2** <a id=\"79\"><\/a>","9f9161b7":"### **df.corr()** <a id=\"81\"><\/a>\nit gives information about the correlation between the data.\n\n<mark>[Return Contents](#0)\n<hr>","0d4430ee":"# **Rename & Defining New & Change Columns** <a id=\"64\"><\/a>\n<mark>[Return Contents](#0)\n<hr>","2d7800dd":"### **Make all columns lowercase** <a id=\"68\"><\/a>\n<mark>[Return Contents](#0)\n<hr>","66c258db":"### **df.std()** <a id=\"30\"><\/a>\nThis code calculates the standard deviation value for each column with numeric value.\n\n<mark>[Return Contents](#0)\n<hr>","89db71bd":"### **df.var()**  <a id=\"29\"><\/a>\nThis code calculates the variance value for each column with a numeric value.\n\n<mark>[Return Contents](#0)\n<hr>","a755a5c4":"### **df['columnName'].cumproad()** <a id=\"33\"><\/a>\nThis code returns the cumulative production of the data.\n\n<mark>[Return Contents](#0)\n<hr>","db88bc1f":"# **Convert Data Types** <a id=\"73\"><\/a>\n\n<mark>[Return Contents](#0)\n<hr>\n\n### **df.dtypes** <a id=\"74\"><\/a>\nThis code shows what data type of columns are. Boolean, int, float, object(String), date and categorical.","3245f75d":"### **df.columnName** <a id=\"45\"><\/a>\nThis code is another way to select the column we want.\n\n<mark>[Return Contents](#0)\n<hr>","4d309f3b":"### **df['columnName']** <a id=\"41\"><\/a>\nWith this code, we can select and bring any column we want.\n\n<mark>[Return Contents](#0)\n<hr>","314c35e2":"### **df[['columnName','columnName']]** <a id=\"54\"><\/a>\nThis code helps us pick and bring any columns we want.\n\n<mark>[Return Contents](#0)\n<hr>","e6c6c702":"### **df.columns** <a id=\"17\"><\/a>\nThis code shows all the columns contained in the data we have examined.\n\n<mark>[Return Contents](#0)\n<hr>","5dd51dc2":"### **df['columnName'][n]** <a id=\"42\"><\/a>\nWith this code, we can select and return any value of the column we want.\n\n<mark>[Return Contents](#0)\n<hr>","d7380cb1":"### **df.cummin()** <a id=\"32\"><\/a>\nThis code returns the cumulative min value of the data.\n\n<mark>[Return Contents](#0)\n<hr>","a2fcc15e":"### **df['columnName'].nunique()** <a id=\"43\"><\/a>\nThis code shows how many of the data that is in the selected column and does not repeat.\n\n<mark>[Return Contents](#0)\n<hr>","e805481a":"### **df.loc[n:n]** <a id=\"40\"><\/a>\nThis code allows us to fetch the data in the range we specify.\n\n<mark>[Return Contents](#0)\n<hr>","4dda5e8b":"### **df.cummax()** <a id=\"31\"><\/a>\nThis code calculates the cumulative max value between the data.\n\n<mark>[Return Contents](#0)\n<hr>","8f21e76f":"# **Drop Data** <a id=\"70\"><\/a>\n\n<mark>[Return Contents](#0)\n<hr>","8afd8836":"### **df.isnull()** <a id=\"35\"><\/a>\nChecks for null values, returns boolean.\n\n<mark>[Return Contents](#0)\n<hr>","b671a7d5":"# **Import Library** <a id=\"3\"><\/a>\n<mark>[Return Contents](#0)\n<hr>","710bb76f":"### **pd.melt(frame=dataFrameName,id_vars = 'columnName', value_vars= ['columnName'])** <a id=\"76\"><\/a>\nThis code is confusing, so lets look at the example.\n\n<mark>[Return Contents](#0)\n<hr>","66b45231":"### **df.drop(columns=['columnName'])** <a id=\"71\"><\/a>\nThis code deletes the column we have specified. But as above, I have to reset the delete to the df variable again.","3de1b57f":"### **DataFrame** <a id=\"6\"><\/a>\n\nThe dataframe is a two-dimensional data structure. It contains columns.","4b02bfd8":"### **df.tail(n)** <a id=\"48\"><\/a>\nThis code optionally brings 5 data at the end. returns the number of data that you type instead of N.\n\n<mark>[Return Contents](#0)\n<hr>","d23cfb42":"### **df.shape()** <a id=\"15\"><\/a>\nThis code shows us the number of rows and columns.\n\n<mark>[Return Contents](#0)\n<hr>","1346d77a":"### **df[df.columnName < 5]** <a id=\"53\"><\/a>\nThis code returns the column name we have specified, which is less than 5.\n\n<mark>[Return Contents](#0)\n<hr>","28d7a24e":"### **df.sort_values('columnName', ascending=False)** <a id=\"62\"><\/a>\nThis code is the column we specify in the form of high to low.\n\n<mark>[Return Contents](#0)\n<hr>","6688f662":"### **df.rename(columns= {'columnName' : 'newColumnName'})** <a id=\"65\"><\/a>\nThis code helps us change the column name. The code I wrote below changes the ID value, but as we did not assign the change to the variable DF, it seems to be unchanged as you see below.","cae71109":"### **df.sample(n)** <a id=\"49\"><\/a>\nThis code fetches random n data from the data.\n\n<mark>[Return Contents](#0)\n<hr>","678a8595":"**# **Overview** <a id=\"1\"><\/a>\n<mark>[Return Contents](#0)\n<hr>\n\nWelcome to my Kernel! In this kernel, I show you Pandas functions and how to use pandas. Why do I this? Because everyone who's just starting out or who's a professional is using the pandas.\n\nIf you have a question or feedback, do not hesitate to write and if you **like** this kernel, please do not forget to **UPVOTE**.\n\n<p><h2>Last Updated :<b> 30.06.2019<\/b><\/h2><\/p>","01c31756":"### **idxmax()**  <a id=\"24\"><\/a>\nThis code returns the largest value in the data.\n\n<mark>[Return Contents](#0)\n<hr>","f72d32a3":"# **What is the pandas?** <a id=\"2\"><\/a>\n<mark>[Return Contents](#0)\n<hr>\n\npandas is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.\n\npandas is a NumFOCUS sponsored project. This will help ensure the success of development of pandas as a world-class open-source project, and makes it possible to donate to the project.","a0690dd6":"### **df.head(n)** <a id=\"47\"><\/a>\nThis code optionally brings in the first 5 data. returns the number of data that you type instead of N.\n\n<mark>[Return Contents](#0)\n<hr>","9ea8b6ba":"### **Change Index Name** <a id=\"67\"><\/a>\nChange index name to new index name\n\n<mark>[Return Contents](#0)\n<hr>","2f51a175":"### **df.loc[:,\"columnName1\":\"columnName2\"]** <a id=\"55\"><\/a>\nThis code returns columns from columnname1 to columnname2.\n\n<mark>[Return Contents](#0)\n<hr>","47dec716":"### **df.describe()**  <a id=\"25\"><\/a>\nThis Code provides basic statistical information about the data. The numerical column is based.\n\n* **count:** vnumber of entries\n* **mean: **average of entries\n* **std:** standart deviation\n* **min:** minimum entry\n* **25%:** first quantile\n* **50%:** median or second quantile\n* **75%:** third quantile\n* **max:** maximum entry\n\n<mark>[Return Contents](#0)\n<hr>","604b8fda":"### **df['columnName'] = df['columnName'].astype('dataType')** <a id=\"75\"><\/a>\nThis code convert the column we specify into the data type we specify.\n\n<mark>[Return Contents](#0)\n<hr>","d4b94e37":"### **Create Filter** <a id=\"56\"><\/a>\n<mark>[Return Contents](#0)\n<hr>","834a2276":"# **Pandas Data Structure** <a id=\"4\"><\/a>\n<mark>[Return Contents](#0)\n<hr>\n\nPandas has two types of data structures. These are series and dataframe.\n\n### **Series** <a id=\"5\"><\/a>\n\nThe series is a one-dimensional labeled array. It can accommodate any type of data in it.","f83acccc":"### **df.sort_index()** <a id=\"63\"><\/a>\nThis code sorts from small to large according to the DataFrame index.\n\n<mark>[Return Contents](#0)\n<hr>","d8f4175e":"### **df.index** <a id=\"16\"><\/a>\nThis code shows the total number of index found.\n\n<mark>[Return Contents](#0)\n<hr>","be3471fe":"### **df.count()** <a id=\"18\"><\/a>\nThis code shows us how many pieces of data are in each column.\n\n<mark>[Return Contents](#0)\n<hr>","d39ab301":"# **Apply Function** <a id=\"77\"><\/a>\n\n<mark>[Return Contents](#0)\n<hr>\n\n### **Method 1** <a id=\"78\"><\/a>","3566f0ac":"### **df.info()** <a id=\"14\"><\/a>\nThis Code provides detailed information about our data.\n\n* **RangeIndex:** Specifies how many data there is.\n* **Data Columns:** Specifies how many columns are found.\n* **Columns:** Gives information about Columns.\n* **dtypes:** It says what kind of data you have and how many of these data you have.\n* **Memory Usage:** It says how much memory usage is.\n\n<mark>[Return Contents](#0)\n<hr>","9a5fd2af":"### **df.median()**  <a id=\"27\"><\/a>\nThis code returns median for columns with numeric values.\n\n<mark>[Return Contents](#0)\n<hr>","acbdff99":"### **df.max()** <a id=\"22\"><\/a>\nThis code brings up the largest among the data.\n\n<mark>[Return Contents](#0)\n<hr>","e3f312a9":"### **df.mean()**  <a id=\"26\"><\/a>\nThis code returns the mean value for the numeric column.\n\n<mark>[Return Contents](#0)\n<hr>","489ed1fe":"### **df.iloc[[n],[n]]** <a id=\"39\"><\/a>\nThis code brings the data in the N row and N column in the DataFrame.\n\n<mark>[Return Contents](#0)\n<hr>","f964bb71":"### **Make all columns uppercase** <a id=\"69\"><\/a>\n<mark>[Return Contents](#0)\n<hr>","f3204c77":"### **Excel** <a id=\"9\"><\/a>\n\nWhen we want to work with Excel files, we need to type the following code.","93f32cb9":"### **df.quantile([0.25,0.75])**  <a id=\"28\"><\/a>\nThis code calculates the values 0.25 and 0.75 of the columns for each column.\n\n<mark>[Return Contents](#0)\n<hr>","841b92e7":"# **Create Test Objects** <a id=\"12\"><\/a>\n<mark>[Return Contents](#0)\n<hr>","936c6c4e":"# **Import Library** <a id=\"7\"><\/a>\n<mark>[Return Contents](#0)\n<hr>\n\nWith pandas, we can open CSV, Excel and SQL databases. I will show you how to use this method for CSV and Excel files only.\n\n### **CSV(comma - separated values)** <a id=\"8\"><\/a>\n\nIt is very easy to open and read CSV files and to overwrite the CSV file.","2cf79e67":"### **df.sum()** <a id=\"19\"><\/a>\nThis code shows us the sum of the data in each column.\n\n<mark>[Return Contents](#0)\n<hr>","b43bfd4b":"### **df.nlargest(n,'columnName')** <a id=\"51\"><\/a>\nThis code brings N from the column where we have specified the largest data.\n\n<mark>[Return Contents](#0)\n<hr>"}}