{"cell_type":{"07e3fc9c":"code","5bf9da12":"code","ad0711bc":"code","988f7e6e":"code","b822263c":"code","19b36634":"code","97252763":"code","c57e14e0":"code","9971280c":"code","3c22430b":"code","1da40832":"code","20441d66":"code","c64f22b4":"code","80c00f95":"code","2781a64a":"code","cee1de51":"code","139755a1":"markdown","21312914":"markdown","e186285d":"markdown"},"source":{"07e3fc9c":"import time\nimport numpy as np\nimport pandas as pd\nimport pickle as pkl","5bf9da12":"from sklearn.metrics import plot_confusion_matrix\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nimport xgboost as xgb","ad0711bc":"from sklearn.model_selection import KFold\nfrom tensorflow import random\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom keras.layers import LeakyReLU","988f7e6e":"random_seed = 8789\nnp.random.seed(random_seed)\nrandom.set_seed(random_seed)","b822263c":"def pkl_load(name):\n    pkl_file = open(\"\/kaggle\/input\/\"+name, 'rb')\n    X = pkl.load(pkl_file)\n    pkl_file.close()\n    return X","19b36634":"def func_xgbc(name, data, labels):\n    xgbc = xgb.XGBClassifier(n_estimators=150, scale_pos_weight=6, max_depth=7, objective=\"binary:logistic\", eval_metric=\"auc\", use_label_encoder=False)\n    rskf = RepeatedStratifiedKFold(n_splits=11, n_repeats=3, random_state=random_seed)\n    \n    scoring = ('roc_auc', 'f1', 'recall')\n    scores = cross_validate(xgbc, data, labels, scoring=scoring, cv=rskf)\n\n    for key in scores:\n        print(\"Mean \"+key+\": %.3f\" % np.mean(scores[key]))\n    \n    X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.3, stratify=labels)\n    xgbc.fit(X_train, y_train)\n    plot_confusion_matrix(xgbc, X_test, y_test, display_labels=['NoDlqin2yrs', 'SeriousDlqin2yrs'], cmap='viridis')\n    \n    return xgbc, scores","97252763":"df_train = pd.read_csv(\"\/kaggle\/input\/GiveMeSomeCredit\/cs-training.csv\")\ndf_test = pkl_load(\"gmsc-data-overview-eda\/x_test.pkl\")\ndf_pca = pkl_load(\"gmsc-data-overview-eda\/pca.pkl\")","c57e14e0":"print(df_train.loc[df_train.SeriousDlqin2yrs == 0].shape)\nprint(df_train.loc[df_train.SeriousDlqin2yrs == 1].shape)","9971280c":"y_train = df_train.SeriousDlqin2yrs.astype('int32')\nX_train = df_train.drop(columns=[\"SeriousDlqin2yrs\"])\nname = \"legacy\"\nstart_time = time.time()\n# classifier, scores = func_xgbc(name, X_train, y_train)\nprint(\"--- %s minutes ---\" % ((time.time() - start_time)\/60))","3c22430b":"df_train_curated = pkl_load(\"gmsc-data-overview-eda\/x_train.pkl\")\ny_train_curated = df_train.SeriousDlqin2yrs.astype('int32')\nX_train_curated = df_train.drop(columns=[\"SeriousDlqin2yrs\"])\nname = \"curated\"\n\nstart_time = time.time()\n# classifier, scores = func_xgbc(name, X_train_curated, y_train_curated)\nprint(\"--- %s minutes ---\" % ((time.time() - start_time)\/60))","1da40832":"df_pca = pkl_load(\"gmsc-data-overview-eda\/pca.pkl\")\ny_pca = df_pca.label\nX_pca = df_pca.drop(columns=[\"label\"])\nname = \"pca\"\n\nstart_time = time.time()\nclassifier, scores = func_xgbc(name, X_pca, y_pca)\nprint(\"--- %s minutes ---\" % ((time.time() - start_time)\/60))","20441d66":"def get_model(feature_count, hidden_layer_size=1024, drop_out=0.2):\n    model = Sequential()\n    model.add(Dense(hiddenLayerSize, input_dim=feature_count))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(dropOut))\n    model.add(Dense(hiddenLayerSize, input_dim=feature_count))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(dropOut))\n    model.add(Dense(hiddenLayerSize))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dense(1, activation=\"sigmoid\"))\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"AUC\"])\n    return model","c64f22b4":"nSplits = 7\nbatchSize = 5000\nepochCount = 32\nfeature_count = X_pca.shape[1]\nhiddenLayerSize = 1024\ndropOut = 0.1","80c00f95":"models = []\nhistory = {}\nverbosity = 1\n\nkfold = KFold(n_splits=nSplits, shuffle=True)\nstart_time = time.time()\nfor j, (train_idx, val_idx) in enumerate(kfold.split(X_pca)):\n    model = get_model(feature_count=feature_count, hidden_layer_size=hiddenLayerSize, drop_out=dropOut)\n    history[j] = model.fit(X_pca.iloc[train_idx], y_pca.iloc[train_idx], validation_data=(X_pca.iloc[val_idx], y_pca.iloc[val_idx]), batch_size=batchSize, epochs=epochCount, verbose=verbosity)\n    scores = model.evaluate(X_pca.iloc[val_idx], y_pca.iloc[val_idx], verbose=verbosity)\n    print('Fold %d: %s of %f' % (j,model.metrics_names[0],scores[0]))\n    print('Fold %d: %s of %f' % (j,model.metrics_names[1],scores[1]))\n    models.append(model)\nprint(\"--- %s minutes ---\" % ((time.time() - start_time)\/60))","2781a64a":"X_test = pkl_load(\"gmsc-data-overview-eda\/x_test.pkl\")\nxgbc = xgb.XGBClassifier(n_estimators=150, scale_pos_weight=6, max_depth=7,objective=\"binary:logistic\", eval_metric=\"auc\", use_label_encoder=False)\nxgbc.fit(X_train, y_train)\ny_hat = xgbc.predict_proba(X_test)\nsubmission = pd.read_csv(\"\/kaggle\/input\/GiveMeSomeCredit\/sampleEntry.csv\")\nsubmission['Probability'] = y_hat[:,1]\nsubmission.to_csv(\"submission-xgboost.csv\", index=False)","cee1de51":"X_test = pkl_load(\"gmsc-data-overview-eda\/pca_test.pkl\")\ndl_model = get_model(feature_count=feature_count, hidden_layer_size=hiddenLayerSize, drop_out=dropOut)\ndl_model.fit(X_pca, y_pca)\ny_hat = dl_model.predict_proba(X_test)\nsubmission = pd.read_csv(\"\/kaggle\/input\/GiveMeSomeCredit\/sampleEntry.csv\")\nsubmission['Probability'] = y_hat\nsubmission.to_csv(\"submission-deeplearning.csv\", index=False)","139755a1":"# Deep Learning","21312914":"# Predictions","e186285d":"# xgBoost"}}