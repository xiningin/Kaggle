{"cell_type":{"9dc1991f":"code","1c22d4fe":"code","a6668618":"code","49e8bf03":"code","aa083c9e":"code","cca7af5f":"code","0bee47c3":"code","6b59f402":"code","d79e9c3a":"code","d7258069":"code","a5ea9e88":"code","44b3294e":"code","f8304416":"code","404703a7":"code","b2b88432":"code","110dc0d7":"code","563ea12e":"code","83295af0":"code","f3213fff":"code","8a8c3b2b":"code","576e808c":"code","41371575":"code","097c58d5":"code","fb127544":"code","a97ab016":"code","5d59493f":"markdown","f7dc91ac":"markdown","4ca07a29":"markdown","1a815060":"markdown","420bfc14":"markdown","7f6a7d64":"markdown","e0fcfef3":"markdown","4767ed18":"markdown","8a130e34":"markdown","26d4054b":"markdown"},"source":{"9dc1991f":"import numpy as np\n\nimport matplotlib.pyplot as plt\n\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n","1c22d4fe":"# Load data method loads the dataset into 2 tuples\n(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()","a6668618":"# Count of the X_train and X_test\nprint(\"X train {} and Test size {}\".format(X_train.shape[0], X_test.shape[0]))","49e8bf03":"plt.figure(figsize=(10,10))\n\nfor i in range(5):\n    plt.subplot(1, 5, i+1)\n    plt.imshow(X_test[i])\n    plt.axis('off')\nplt.show()\n\nprint('Label %s' % (y_test[0:5]))\n","aa083c9e":"X_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\n\nX_train \/= 255\nX_test \/= 255\n\nX_train.shape","cca7af5f":"# Convert to the tensor shape\nX_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\nX_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n","0bee47c3":"print(\"X_Train shape {}\".format(X_train.shape))\nprint(\"X_Test shape {}\".format(X_test.shape))","6b59f402":"y_train = keras.utils.to_categorical(y_train, 10)\ny_test = keras.utils.to_categorical(y_test, 10)","d79e9c3a":"def build_model():\n    \"\"\"\n        Method constructs the CNN architecture with 2D-Convolution\n    \"\"\"\n    model = keras.models.Sequential()\n    \n    model.add(keras.layers.Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n    model.add(keras.layers.Activation('relu'))\n    model.add(keras.layers.Dropout(0.25))\n    \n    model.add(keras.layers.Convolution2D(32, 3, 3))\n    model.add(keras.layers.Activation('relu'))\n    \n    model.add(keras.layers.Convolution2D(32, 3, 3))\n    model.add(keras.layers.Activation('relu'))\n    model.add(keras.layers.Dropout(0.25))\n    \n    model.add(keras.layers.Flatten())\n    \n    model.add(keras.layers.Dense(128))\n    model.add(keras.layers.Dense(128))\n    model.add(keras.layers.Activation('relu'))\n    \n    model.add(keras.layers.Dense(10))\n    model.add(keras.layers.Activation('softmax'))\n    \n    return model\n    \n    ","d7258069":"cnn_model = build_model()\n\ncnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\ncnn_model.summary()","a5ea9e88":"history = cnn_model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))","44b3294e":"cnn_model.evaluate(X_test, y_test)","f8304416":"history_dict = history.history\n\nprint(history_dict.keys())","404703a7":"def plot_train_instrumentation(epochs, data, train_param, val_param):\n    \n    plt.figure(figsize=(10,7))\n    \n    plt.plot(epochs, data[train_param], 'g', label=f'Training ({train_param})')\n    plt.plot(epochs, data[val_param], 'red', label=f'Validation ({val_param})')\n    \n    plt.title(\"Training performance\")\n    plt.xlabel('Epochs')\n    plt.ylabel(train_param)\n    \n    plt.legend()\n    plt.show()","b2b88432":"epochs = range(1, len(history_dict['accuracy'])+1)\n\nplot_train_instrumentation(epochs, history_dict, 'accuracy', 'val_accuracy')\nplot_train_instrumentation(epochs, history_dict, 'loss', 'val_loss')","110dc0d7":"# Create data augmentation object\ndata_augmentor = ImageDataGenerator(rotation_range=50, \n                                    width_shift_range=0.01, \n                                    height_shift_range=0.01)\n\n# fit the training data\ndata_augmentor.fit(X_train)\n\naugment = data_augmentor.flow(X_train[1:2], batch_size=1)\n\nfor i in range(1, 6):\n    plt.subplot(1,5,i)\n    plt.imshow(augment.next().squeeze())\n    plt.axis('off')\nplt.show()","563ea12e":"history_data_aug = cnn_model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))","83295af0":"cnn_model.evaluate(X_test, y_test)","f3213fff":"history_dict = history_data_aug.history","8a8c3b2b":"plot_train_instrumentation(epochs, history_dict, 'accuracy', 'val_accuracy')\nplot_train_instrumentation(epochs, history_dict, 'loss', 'val_loss')","576e808c":"def construct_model(input_shape=(28,28,1)):\n    \n    model = keras.models.Sequential()\n    \n    model.add(keras.layers.Conv2D(32, kernel_size=3, activation='relu', input_shape= input_shape))\n    model.add(keras.layers.BatchNormalization())\n    \n    model.add(keras.layers.Conv2D(32, kernel_size=3, activation='relu'))\n    model.add(keras.layers.BatchNormalization())\n    model.add(keras.layers.Conv2D(32, kernel_size=5, strides=2, padding='same',  activation='relu'))\n    model.add(keras.layers.BatchNormalization())\n    model.add(keras.layers.Dropout(0.4))\n    ## Dropout Regularization of 0.4 in order to avoid overfitting\n    model.add(keras.layers.Conv2D(64, kernel_size=3,  activation='relu'))\n    model.add(keras.layers.BatchNormalization())\n    model.add(keras.layers.Conv2D(64, kernel_size=3,  activation='relu'))\n    model.add(keras.layers.BatchNormalization())\n    model.add(keras.layers.Conv2D(64, kernel_size=5, strides=2, padding='same',  activation='relu'))\n    model.add(keras.layers.BatchNormalization())\n    model.add(keras.layers.Dropout(0.4))\n    \n    model.add(keras.layers.Conv2D(64, kernel_size=4,  activation='relu'))\n    model.add(keras.layers.BatchNormalization())\n    model.add(keras.layers.Flatten())\n    model.add(keras.layers.Dropout(0.4))\n    model.add(keras.layers.Dense(10, activation='softmax'))\n    \n    return model\n    ","41371575":"conv_model = construct_model((28,28,1))\n\nconv_model.summary()","097c58d5":"# Compile the model\nconv_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# fit the model with training set\nhistory = conv_model.fit(X_train, y_train, batch_size=32, epochs=10, validation_split=0.2)","fb127544":"def plot_model_performance(model_history, metric, val_metric):\n    plt.figure(figsize=(10,8))\n    plt.plot(model_history.history[metric], label=str('Training '+ metric))\n    plt.plot(model_history.history[val_metric], label=str('Validation '+ val_metric))\n    plt.title(metric+\" vs \"+val_metric)\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(metric)\n    plt.legend()\n    plt.show()","a97ab016":"plot_model_performance(history, 'accuracy', 'val_accuracy')\nplot_model_performance(history, 'loss', 'val_loss')","5d59493f":"Fitting the model with the dataset.","f7dc91ac":"## Data Augmentation ","4ca07a29":"**ImageDataGenerator-Class**\n\n<pre>\ntf.keras.preprocessing.image.ImageDataGenerator(\n    featurewise_center=False, samplewise_center=False,\n    featurewise_std_normalization=False, samplewise_std_normalization=False,\n    zca_whitening=False, zca_epsilon=1e-06, rotation_range=0, width_shift_range=0.0,\n    height_shift_range=0.0, brightness_range=None, shear_range=0.0, zoom_range=0.0,\n    channel_shift_range=0.0, fill_mode='nearest', cval=0.0, horizontal_flip=False,\n    vertical_flip=False, rescale=None, preprocessing_function=None,\n    data_format=None, validation_split=0.0, dtype=None\n)\n<\/pre>\n\n**.flow() Method**\n<pre>\nflow(\n    x, y=None, batch_size=32, shuffle=True, sample_weight=None, seed=None,\n    save_to_dir=None, save_prefix='', save_format='png', subset=None\n)\n<\/pre>","1a815060":"**Converting Target variable to Categorical**\n\nWe need to convert the target variable to categorical variable. ","420bfc14":"If we observe the plot we can see that there are lot of variation in the accuracy and validation accuracy. The model is overfitting(high variance), we need to regularize the model by doing normalize the data and optimize the parameter. We can do this by adding layers `BatchNormalization` and `Dropout`.","7f6a7d64":"## BatchNormalization\n\n<pre style='background-color:#EBECE4;'>\ntf.keras.layers.BatchNormalization(\n    axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True,\n    beta_initializer='zeros', gamma_initializer='ones',\n    moving_mean_initializer='zeros', moving_variance_initializer='ones',\n    beta_regularizer=None, gamma_regularizer=None, beta_constraint=None,\n    gamma_constraint=None, renorm=False, renorm_clipping=None, renorm_momentum=0.99,\n    fused=None, trainable=True, virtual_batch_size=None, adjustment=None, name=None,\n    **kwargs\n)\n<\/pre>","e0fcfef3":"## Loading data from keras dataset","4767ed18":"## Exploring the dataset","8a130e34":"# Deep Learning and Data Augmentation\n\n## Overview\n\nLet's build a CNN model with MNIST fashion dataset without any data augmentation and then we will do data augmentation on the images, the finally compare the performance of the two model accuracies. ","26d4054b":"## Feature Scaling\n\nNormalize both training and testing images and convert them into dimensions that are accepted by keras. \nConvert the labels to categorical values. "}}