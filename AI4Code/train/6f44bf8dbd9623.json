{"cell_type":{"83fb35c8":"code","bbe1ee54":"code","cda9aa7e":"code","7dc76194":"code","d349017f":"code","49297131":"code","26cfa8fc":"code","69c2789a":"code","ead5c921":"code","3e68e686":"code","3d8d2fe3":"code","e772fada":"code","8fa82d70":"code","8b638fee":"code","d158ef51":"code","07755044":"code","67159010":"code","64a0ccfa":"code","3f31f9c6":"code","f5c8b62e":"code","409b1ee9":"code","9734156d":"code","ca7cf5a6":"code","31506969":"code","729796d1":"code","555edd0d":"code","e184202c":"code","ab23a0ba":"code","e14a5e95":"code","8c9fda13":"code","6eafb6a4":"code","3b2c25f3":"code","2295ee9f":"code","85575e07":"code","349fe34b":"code","6659946f":"code","a241fbd1":"code","c8aedb7f":"code","2fad878d":"code","6a6fdbb3":"code","9089e666":"markdown","a629935d":"markdown","c19ef73e":"markdown","aaf54772":"markdown","c4a6ab3d":"markdown"},"source":{"83fb35c8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bbe1ee54":"# Initializing train and test dataframe in the variables. \ntrain = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ngen_submission = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')","cda9aa7e":"train.head()","7dc76194":"test.head()","d349017f":"gen_submission.head()","49297131":"# We are dropping the columns that is not required \ntrain.drop(columns=['PassengerId', 'Name','Ticket','Embarked','Cabin' ], axis=1, inplace=True)","26cfa8fc":"train.head()","69c2789a":"# We find nan values in the Age column which we will remove now\ntrain.isnull().sum()","ead5c921":"train = train.fillna(train.Age.mean())\n","3e68e686":"# here is the result, we got none nan.\ntrain.isnull().sum()","3d8d2fe3":"# Now, using matplotlib and quantile(), we will check the outliers\n# simultaneously also import other libraries we may need\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n%matplotlib inline","e772fada":"# So, here we find that 'Fare' column has outliers, we will remove that.\n# 'Sex' column is not added in the boxplot as it is a numerical variable, boxplot works with only integers\ntrain.boxplot(column =['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare'], grid = False)\ntrain.columns","8fa82d70":"# this is an extra information that will show you the outliers clearly, and gives information \n# about the price that the passengers paid along with their age\ntrain.boxplot(column = 'Fare', by = 'Age',figsize=(25,8))","8b638fee":"train.quantile(1)","d158ef51":"outliers_fare = train['Fare'].quantile(1)\ntrain = train[train.Fare < outliers_fare]","07755044":"# from the above and the below we see the change in the Fare column, we removed the outliers \n# using an arithematic and quantile function\ntrain.quantile(1)","67159010":"# Out train dataset is cleaned, we can visualise now to see the data using graphs and hists\nplt.figure(figsize=(15,8))\nplt.title('No of people travelling on the titanic along with thier age')\nplt.grid()\nsns.histplot(data=train, x='Age', color='green', binwidth=5)","64a0ccfa":"plt.figure(figsize=(15,8))\nplt.title('Passengers age who did not survive')\nplt.grid()\nsns.histplot(x=train.loc[train['Survived'] == 0 ,'Age'],color='red',binwidth=5)","3f31f9c6":"plt.figure(figsize=(15,8))\nplt.title('Passengers age who survived')\nplt.grid()\nsns.histplot(x=train.loc[train['Survived'] == 1 ,'Age'],color='red',binwidth=5)","f5c8b62e":"# lets drop the index and column so that you pass just the data from the dataframe\ntrain.head()","409b1ee9":"x = train.iloc[:,1:7].values\nx","9734156d":"# In the above values you see Sex data which is in categorical format, lets convert it into integers \n# LabelEncoder can be used to normalize labels\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nx[:,1] = le.fit_transform(x[:,1])\nx","ca7cf5a6":"## The idea behind StandardScaler is that it will transform your data such \n## that its distribution will have a mean value 0 and standard deviation of 1 (Standard Normal Distribution)\nfrom sklearn.preprocessing import StandardScaler\nss = StandardScaler()\nx = ss.fit_transform(x)\nx","31506969":"# Lets assign our dependent data which is the 'Survived' column to 'y' variable \n## as we are choosing 'survived' column from train data set to predict values \n## thats on the test data. \n\n# The test data set has no column 'Survived'. We are using the 'Survived' column from the train\n# dataset as a dependent value to generate our model which will give us the column in the test data set\ny = train.iloc[:,0]\ny","729796d1":"from sklearn.tree import DecisionTreeClassifier\nclassifier = DecisionTreeClassifier(random_state=0)\nclassifier.fit(x,y)\ny_test = classifier.predict(x)","555edd0d":"#we going to use 'accuracy score' to find out accuracy of our model\nfrom sklearn.metrics import accuracy_score,confusion_matrix\n# This accuracy percentage will tell us how similar the data is ('y' vs our model), the higher the better\nprint(accuracy_score(y,y_test))","e184202c":"# let me show you the accuracy in a different way\ndata = train.copy()\ndata['y-test'] = y_test","ab23a0ba":"# Numpy will help us here in making the comparison between two features\n# Define conditions\nconditions = [data['Survived'] == data['y-test'], \n              data['Survived'] != data['y-test']]\n\n#define choices\nchoices = ['yes', 'no']\n\n#create new column in DataFrame that displays results of comparisons\ndata['results'] = np.select(conditions, choices, default='Tie')     ","e14a5e95":"# Here we see that 16 values that are not matching, in other words - 0.9819819819819819 accuracy\ndata.results.value_counts()","8c9fda13":"# We can get this data quickly using a function that we have in scikit - confusion_matrix\n# We already imported the library above\n# y is from the train set & y_test is from the model that we created\n# 547 + 325 = 872 are yes & 14+2 = 16 No\nprint(confusion_matrix(y,y_test))","6eafb6a4":"# we need to clean the test data before running the prediction on it\ntest.head()","3b2c25f3":"test.isnull().sum()","2295ee9f":"# from the above data we see there are nan values and features that we dont need \ntest.drop(columns=['PassengerId', 'Name','Ticket','Embarked','Cabin' ], axis=1, inplace=True)\n","85575e07":"test = test.fillna(train.Age.mean())\ntest.info()","349fe34b":"test = test.fillna(train.Age.mean())\ntest.info()","6659946f":"# We extract values from the dataframe and convert 'Sex' column to integers\nx_test = test.values\nx_test[:,1] = le.fit_transform(x_test[:,1])\nx_test","a241fbd1":"# we scale now\nx_test = ss.fit_transform(x_test)\nx_test","c8aedb7f":"# last step - lets predict\nx_predict = classifier.predict(x_test)\n# here we get out 'Survived' feature from the test data\nx_predict","2fad878d":"#Lets save the file as per the requirements of competion, we look at the submission dataframe \n# and then we create a similar style using our prediction on 'Survived'\ngen_submission.head()\nsubmission = pd.DataFrame(columns = ['PassengerId','Survived'])\nsubmission['PassengerId'] = gen_submission['PassengerId']\n# below we add our prediction\nsubmission['Survived'] = x_predict\nsubmission","6a6fdbb3":"#save our submission in a csv\nsubmission.to_csv(\"submission.csv\",header=True,index=False)","9089e666":"## We have the training data\n## Now we initialize DecisionTreeClassifier to predict our 'Survived' column in test dataset","a629935d":"Lets train out model to convert the values into standard scalar \nso that individual values are scaled into common metric which will help our model to predict\ntest data with accuracy\n","c19ef73e":"1. * # We look at the above data and understand the datasets we have and understand the question which is asking us to build a model using train.csv. \n1. * # We perform feature engineering, feature selection then use ML models to convert values in standard scalar\n1. * # Once we have the model which you will find it below, we predict values on the test.csv. \n1. * # Before predicting you should also make sure the test.csv data is cleaned.\n1. * # lets go ahead and do this ...","aaf54772":"Upload the file in the kaggle submission section. Thank you so much for going through my code and analysis, I thank my tutors and people from kaggle community too. I hope my notes help you understand how the modelling, data analysis, selection and engineering work. I understand there was no much EDA above, as this dataset is reasonable and easy, I will make a details EDA on other datasets. Thank you.","c4a6ab3d":"## Now we have a very good understanding, lets use the model on the test data set and submit on kaggle"}}