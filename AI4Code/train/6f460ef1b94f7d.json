{"cell_type":{"bcd630f7":"code","7ca4936c":"code","20d434a4":"code","c46d03ea":"code","ddda3f4b":"code","55130607":"code","a6e2df2c":"code","dbad4c3f":"code","7c6c6d35":"code","8ffc657c":"code","2485b7d6":"code","885a7115":"code","65039cb6":"code","8027c860":"code","bf5bd88f":"code","90dd9796":"code","5e368372":"code","dff80b6e":"code","8168991c":"markdown","e8ab26ea":"markdown","54c1ce86":"markdown","bc3c1100":"markdown"},"source":{"bcd630f7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7ca4936c":"import nltk\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n#import contractions\nimport sys  \n!{sys.executable} -m pip install contractions\nimport contractions\n\n#from pycontractions import Contractions\n\n%matplotlib inline\n\nplt.rcParams['figure.figsize'] = [14,7]\nplt.rcParams['figure.dpi'] = 70","20d434a4":"df = pd.read_csv(\"..\/input\/the-office-lines\/the-office_lines.csv\")\ndf.head()","c46d03ea":"print(df['Character'].unique())","ddda3f4b":"df['Count'] = df.groupby('Line')['Line'].transform('count')\ndf.sort_values(by='Count', ascending=False, inplace = True)\ndf.head()","55130607":"Line = df.drop_duplicates(subset=['Line'])\nLine100 = Line.head(100)\nplt.figure(figsize=(30,15))\nLines = sns.barplot(data=Line100, x = 'Line', y = 'Count', palette = 'Blues_r')\nLines.set_xticklabels(Lines.get_xticklabels(), rotation=90)\nLines.set_title('Most Common Lines',fontsize=16);","a6e2df2c":"Jimdf = df.loc[df['Character'] == \"Jim\"]\nMichaeldf = df.loc[df['Character'] == \"Michael\"]\nPamdf = df.loc[df['Character'] == \"Pam\"]\nDwightdf = df.loc[df['Character'] == \"Dwight\"]\nJandf = df.loc[df['Character'] == \"Jan\"]\nPhyllisdf = df.loc[df['Character'] == \"Phyllis\"]\nStanleydf = df.loc[df['Character'] == \"Stanley\"]\nAngeladf = df.loc[df['Character'] == \"Angela\"]\nKevindf = df.loc[df['Character'] == \"Kevin\"]\nJimDwightdf = df.loc[df['Character'] == \"Jim And Dwight\"]\nJimdf.head()","dbad4c3f":"text = df['Line']\ntext = text.to_string()\ntext = contractions.fix(text)\ntokens = [t for t in text.split()]\n\nsw= stopwords.words('english')\n#swJimDwight = ['7842','It','know','want','need','think','a..','t.','If','No,','Yeah.','cannot','know,','But','He','Do','I', ';','You','it','it\\'s', 'I\\'m', 'Oh,', ':', 'And','Okay', 'So', 'like', 'going', 'r', 'would', 'got', 'let', 'get', 'We', 'that.', 't.', 'it.', 'Okay,','That', 't,', 'It','What', 'This','The','one','Yeah','Oh','us','No.','t..','no,','you.','Hey,','Well,']\nclean_tokens = tokens[:]\nfor token in tokens:\n    if token in sw:\n        \n        clean_tokens.remove(token)\nfreq = nltk.FreqDist(clean_tokens)\nfreq.plot(30, cumulative=False)","7c6c6d35":"text = JimDwightdf['Line']\ntext = text.to_string()\ntext = contractions.fix(text)\ntokens = [t for t in text.split()]\n\nsw= stopwords.words('english')\nswJimDwight = ['7842','It','know','want','need','think','a..','t.','If','No,','Yeah.','cannot','know,','But','He','Do','I', ';','You','it','it\\'s', 'I\\'m', 'Oh,', ':', 'And','Okay', 'So', 'like', 'going', 'r', 'would', 'got', 'let', 'get', 'We', 'that.', 't.', 'it.', 'Okay,','That', 't,', 'It','What', 'This','The','one','Yeah','Oh','us','No.','t..','no,','you.','Hey,','Well,']\nclean_tokens = tokens[:]\nfor token in tokens:\n    if token in sw or token in swJimDwight:\n        \n        clean_tokens.remove(token)\nfreq = nltk.FreqDist(clean_tokens)\nfreq.plot(30, cumulative=False)","8ffc657c":"text = Kevindf['Line']\ntext = text.to_string()\ntext = contractions.fix(text)\ntokens = [t for t in text.split()]\n\nsw= stopwords.words('english')\nswKevin = ['I', 'You', 'Oh', 'going', 'know', 'What', 'No', 'think', 'like', 'Well', 'it', 'get', 'would', 'Yeah', 'want', 'you.', 'And', 'Yeah', 'Hey,', 'Okay', 'No', 'got', 'us', 'We', 'Oh', 'This', 'Okay.', 'let', 'really', 't.','[to','th...','w.','t..','go','It','know','want','need','think','a..','t.','If','No,','Yeah.','cannot','know,','But','He','Do','I', ';','You','it','it\\'s', 'I\\'m', 'Oh,', ':', 'And','Okay', 'So', 'like', 'going', 'r', 'would', 'got', 'let', 'get', 'We', 'that.', 't.', 'it.', 'Okay,','That', 't,', 'It','What', 'This','The','one','Yeah','Oh','us','No.','t..','no,','you.','Hey,','Well,']\nclean_tokens = tokens[:]\nfor token in tokens:\n    if token in sw or token in swKevin:\n        \n        clean_tokens.remove(token)\nfreq = nltk.FreqDist(clean_tokens)\nfreq.plot(30, cumulative=False)","2485b7d6":"text = Angeladf['Line']\ntext = text.to_string()\ntext = contractions.fix(text)\ntokens = [t for t in text.split()]\n\nsw= stopwords.words('english')\nswAngela = ['I', 'You', 'Oh', 'going', 'know', 'What', 'No', 'think', 'like', 'Well', 'it', 'get', 'would', 'Yeah', 'want', 'you.', 'And', 'Yeah', 'Hey,', 'Okay', 'No', 'got', 'us', 'We', 'Oh', 'This', 'Okay.', 'let', 'really','t..','It','know','want','need','think','a..','t.','If','No,','Yeah.','cannot','know,','But','He','Do','I', ';','You','it','it\\'s', 'I\\'m', 'Oh,', ':', 'And','Okay', 'So', 'like', 'going', 'r', 'would', 'got', 'let', 'get', 'We', 'that.', 't.', 'it.', 'Okay,','That', 't,', 'It','What', 'This','The','one','Yeah','Oh','us','No.','t..','no,','you.','Hey,','Well,']\nclean_tokens = tokens[:]\nfor token in tokens:\n    if token in sw or token in swAngela:\n        \n        clean_tokens.remove(token)\nfreq = nltk.FreqDist(clean_tokens)\nfreq.plot(30, cumulative=False)","885a7115":"text = Stanleydf['Line']\ntext = text.to_string()\ntext = contractions.fix(text)\ntokens = [t for t in text.split()]\n\nsw= stopwords.words('english')\nswStanley = ['I', 'You', 'Oh', 'going', 'know', 'What', 'No', 'think', 'like', 'Well', 'it', 'get', 'would', 'Yeah', 'want', 'you.', 'And', 'Yeah', 'Hey,', 'Okay', 'No', 'got', 'us', 'We', 'Oh', 'This', 'Okay.', 'let', 'really','It','know','want','need','think','a..','t.','If','No,','Yeah.','cannot','know,','But','He','Do','I', ';','You','it','it\\'s', 'I\\'m', 'Oh,', ':', 'And','Okay', 'So', 'like', 'going', 'r', 'would', 'got', 'let', 'get', 'We', 'that.', 't.', 'it.', 'Okay,','That', 't,', 'It','What', 'This','The','one','Yeah','Oh','us','No.','t..','no,','you.','Hey,','Well,']\nclean_tokens = tokens[:]\nfor token in tokens:\n    if token in sw or token in swStanley:\n        \n        clean_tokens.remove(token)\nfreq = nltk.FreqDist(clean_tokens)\nfreq.plot(30, cumulative=False)","65039cb6":"text = Phyllisdf['Line']\ntext = text.to_string()\ntext = contractions.fix(text)\ntokens = [t for t in text.split()]\n\nsw= stopwords.words('english')\nswPhyllis = ['I', 'You', 'Oh', 'going', 'know', 'What', 'No', 'think', 'like', 'Well', 'it', 'get', 'would', 'Yeah', 'want', 'you.', 'And', 'Yeah', 'Hey,', 'Okay', 'No', 'got', 'us', 'We', 'Oh', 'This', 'Okay.', 'let', 'really','It','know','want','need','think','a..','t.','If','No,','Yeah.','cannot','know,','But','He','Do','I', ';','You','it','it\\'s', 'I\\'m', 'Oh,', ':', 'And','Okay', 'So', 'like', 'going', 'r', 'would', 'got', 'let', 'get', 'We', 'that.', 't.', 'it.', 'Okay,','That', 't,', 'It','What', 'This','The','one','Yeah','Oh','us','No.','t..','no,','you.','Hey,','Well,']\nclean_tokens = tokens[:]\nfor token in tokens:\n    if token in sw or token in swPhyllis:\n        \n        clean_tokens.remove(token)\nfreq = nltk.FreqDist(clean_tokens)\nfreq.plot(30, cumulative=False)","8027c860":"text = Jandf['Line']\ntext = text.to_string()\ntext = contractions.fix(text)\ntokens = [t for t in text.split()]\n\nsw= stopwords.words('english')\nswJan = ['I', 'You', 'Oh', 'going', 'know', 'What', 'No', 'think', 'like', 'Well', 'it', 'get', 'would', 'Yeah', 'want', 'you.', 'And', 'Yeah', 'Hey,', 'Okay', 'No', 'got', 'us', 'We', 'Oh', 'This', 'Okay.', 'let', 'really','It','know','want','need','think','a..','t.','If','No,','Yeah.','cannot','know,','But','He','Do','I', ';','You','it','it\\'s', 'I\\'m', 'Oh,', ':', 'And','Okay', 'So', 'like', 'going', 'r', 'would', 'got', 'let', 'get', 'We', 'that.', 't.', 'it.', 'Okay,','That', 't,', 'It','What', 'This','The','one','Yeah','Oh','us','No.','t..','no,','you.','Hey,','Well,']\nclean_tokens = tokens[:]\nfor token in tokens:\n    if token in sw or token in swJan:\n        \n        clean_tokens.remove(token)\nfreq = nltk.FreqDist(clean_tokens)\nfreq.plot(30, cumulative=False)","bf5bd88f":"text = Dwightdf['Line']\ntext = text.to_string()\ntext = contractions.fix(text)\ntokens = [t for t in text.split()]\n\nsw= stopwords.words('english')\nswDwight = ['I', 'You', 'Oh', 'going', 'know', 'What', 'No', 'think', 'like', 'Well', 'it', 'get', 'would', 'Yeah,', 'want', 'you.', 'And', 'Yeah', 'Hey,', 'Okay', 'No', 'got', 'us', 'We', 'Oh', 'This', 'Okay.', 'let', 'really','It','know','want','need','think','a..','t.','If','No,','Yeah.','cannot','know,','But','He','Do','I', ';','You','it','it\\'s', 'I\\'m', 'Oh,', ':', 'And','Okay', 'So', 'like', 'going', 'r', 'would', 'got', 'let', 'get', 'We', 'that.', 't.', 'it.', 'Okay,','That', 't,', 'It','What', 'This','The','one','Yeah','Oh','us','No.','t..','no,','you.','Hey,','Well,']\nclean_tokens = tokens[:]\nfor token in tokens:\n    if token in sw or token in swDwight:\n        \n        clean_tokens.remove(token)\nfreq = nltk.FreqDist(clean_tokens)\nfreq.plot(30, cumulative=False)","90dd9796":"text = Pamdf['Line']\ntext = text.to_string()\ntext = contractions.fix(text)\ntokens = [t for t in text.split()]\n\nsw= stopwords.words('english')\nswPam = ['I', 'You', 'Oh', 'going', 'know', 'What', 'No', 'think', 'like', 'Well', 'it', 'get', 'would', 'Yeah', 'want', 'you.', 'And', 'Yeah', 'Hey,', 'Okay', 'No', 'got', 'us', 'We', 'Oh', 'This', 'Okay.', 'let', 'really','know','want','need','think','a..','t.','a.','[to','t..','No,','Yeah.','cannot','know,','But','He','Do','I', ';','You','it','it\\'s', 'I\\'m', 'Oh,', ':', 'And','Okay', 'So', 'like', 'going', 'r', 'would', 'got', 'let', 'get', 'We', 'that.', 't.', 'it.', 'Okay,','That', 't,', 'It','What', 'This','The','one','Yeah','Oh','us','No.','t..','no,','you.','Hey,','Well,']\nclean_tokens = tokens[:]\nfor token in tokens:\n    if token in sw or token in swPam:\n        \n        clean_tokens.remove(token)\nfreq = nltk.FreqDist(clean_tokens)\nfreq.plot(30, cumulative=False)","5e368372":"text = Jimdf['Line']\ntext = text.to_string()\ntext = contractions.fix(text)\ntokens = [t for t in text.split()]\n\nsw= stopwords.words('english')\nswJim = ['t..','I', 'You', 'Oh', 'going', 'know', 'What', 'No', 'think', 'like', 'Well', 'it', 'get', 'would', 'Yeah', 'want', 'you.', 'And', 'Yeah', 'Hey,', 'Okay', 'No', 'got', 'us', 'We', 'Oh', 'This', 'Okay.', 'let', 'really','really','Is','a.','.','..','t..','But','come','no,','you.','could','one','Do','Come','cannot','no.','The','know','want','need','think','I', ';','You','it','it\\'s', 'I\\'m', 'Oh,', ':', 'And','Okay', 'So', 'like', 'going', 'r', 'would', 'got', 'let', 'get', 'We', 'that.', 't.', 'it.', 'Okay,','That', 't,', 'It','What', 'This']\nclean_tokens = tokens[:]\nfor token in tokens:\n    if token in sw or token in swJim:\n        \n        clean_tokens.remove(token)\nfreq = nltk.FreqDist(clean_tokens)\nfreq.plot(30, cumulative=False)","dff80b6e":"text = Michaeldf['Line']\ntext = text.to_string()\ntext = contractions.fix(text)\ntokens = [t for t in text.split()]\n\nsw= stopwords.words('english')\nswM = ['a..','know.','just','There','t..','No,','Oh,','I', 'You', 'Oh', 'going', 'know', 'What', 'No', 'think', 'like', 'Well', 'it', 'get', 'would', 'Yeah', 'want', 'you.', 'And', 'Yeah', 'Hey,', 'Okay', 'No', 'got', 'us', 'We', 'Oh', 'This', 'Okay.', 'let', 'really','We','cannot','one','No','think','Come','know','I','it', 'And', 'you', 'like', 'That', 'This', 'It', 'You', 'would', 'Okay.', 'get', 't.', 'r', 'Yeah,', 'So', 'no.', 'you.', 'us','Oh', 'got', 'The','let','it','no,','know,','Do','that.','it.','t..']\nclean_tokens = tokens[:]\nfor token in tokens:\n    if token in sw or token in swM:\n        \n        clean_tokens.remove(token)\nfreq = nltk.FreqDist(clean_tokens)\nfreq.plot(30, cumulative=False)","8168991c":"**NLP Analysis on scripts from The Office**\n* What are the most common phrases for each character?\n* Which phrases are most common overall?","e8ab26ea":"Separating the scripts into separate dataframes based on speakers","54c1ce86":"Identifying the most commonly spoken words. These will be stopwords for individual speakers.","bc3c1100":"The most common words in The Office are:\nI, You, Oh, going, know, What, No, think, like, Well, it, get, would, Yeah, want, you. And, Yeah, Hey, Okay, No, got, us, We, Oh, This, Okay. let, really"}}