{"cell_type":{"ec0d1c5b":"code","b9583be7":"code","16074863":"code","5b574b9d":"code","2d1cedbb":"code","32ed0d88":"code","6550c6ec":"code","7ed8eddd":"code","c3ef08af":"code","807980ae":"code","a7b3dbd5":"code","20d76ea4":"code","de199edf":"code","58e2332b":"code","0b121742":"code","5b94e690":"code","2e24dc36":"code","0ff4cd64":"code","0cc6b926":"code","980560b5":"code","3b97bc71":"code","d9909fb7":"code","a577db53":"code","abd84c11":"markdown","a5042d8b":"markdown","cb30a5e4":"markdown","640359c2":"markdown","9d418e7e":"markdown","c9a2d6c9":"markdown","d9f3026a":"markdown","18f1dceb":"markdown","03df044a":"markdown","7796e967":"markdown"},"source":{"ec0d1c5b":"# data analysis and wrangling\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n\n#grafs\nimport pandas as pd\npd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Import Dependencies\n%matplotlib inline\n\n# Start Python Imports\nimport math, time, random, datetime\n\n# Data Manipulation\nimport numpy as np\nimport pandas as pd\n\n# Visualization \nimport matplotlib.pyplot as plt\nimport missingno\nimport seaborn as sns\nplt.style.use('seaborn-whitegrid')\n\n# Preprocessing\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, label_binarize\n\n# Machine learning\nimport catboost\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import model_selection, tree, preprocessing, metrics, linear_model\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom catboost import CatBoostClassifier, Pool, cv\nimport lightgbm as lgb\n# Let's be rebels and ignore warnings for now\nimport warnings\nwarnings.filterwarnings('ignore')\n\n","b9583be7":"tourney_result = pd.read_csv('..\/input\/google-cloud-ncaa-march-madness-2020-division-1-mens-tournament\/MDataFiles_Stage1\/MNCAATourneyCompactResults.csv')\ntourney_seed = pd.read_csv('..\/input\/google-cloud-ncaa-march-madness-2020-division-1-mens-tournament\/MDataFiles_Stage1\/MNCAATourneySeeds.csv')","16074863":"tourney_result = tourney_result.drop(['DayNum', 'WScore', 'LScore', 'WLoc', 'NumOT'], axis=1)\ntourney_result\ntourney_result = pd.merge(tourney_result, tourney_seed, left_on=['Season', 'WTeamID'], right_on=['Season', 'TeamID'], how='left')\ntourney_result.rename(columns={'Seed':'WSeed'}, inplace=True)\ntourney_result = tourney_result.drop('TeamID', axis=1)\ntourney_result = pd.merge(tourney_result, tourney_seed, left_on=['Season', 'LTeamID'], right_on=['Season', 'TeamID'], how='left')\ntourney_result.rename(columns={'Seed':'LSeed'}, inplace=True)\ntourney_result = tourney_result.drop('TeamID', axis=1)\ntourney_result","5b574b9d":"# Get String\ndef get_seed(x):\n    return int(x[1:3])\n\ntourney_result['WSeed'] = tourney_result['WSeed'].map(lambda x: get_seed(x))\ntourney_result['LSeed'] = tourney_result['LSeed'].map(lambda x: get_seed(x))\ntourney_result","2d1cedbb":"season_result = pd.read_csv('..\/input\/google-cloud-ncaa-march-madness-2020-division-1-mens-tournament\/MDataFiles_Stage1\/MRegularSeasonCompactResults.csv')","32ed0d88":"season_win_result = season_result[['Season', 'WTeamID', 'WScore']]\nseason_lose_result = season_result[['Season', 'LTeamID', 'LScore']]\nseason_win_result.rename(columns={'WTeamID':'TeamID', 'WScore':'Score'}, inplace=True)\nseason_lose_result.rename(columns={'LTeamID':'TeamID', 'LScore':'Score'}, inplace=True)\nseason_result = pd.concat((season_win_result, season_lose_result)).reset_index(drop=True)\nseason_result","6550c6ec":"season_score = season_result.groupby(['Season', 'TeamID'])['Score'].sum().reset_index()\nseason_score","7ed8eddd":"tourney_result = pd.merge(tourney_result, season_score, left_on=['Season', 'WTeamID'], right_on=['Season', 'TeamID'], how='left')\ntourney_result.rename(columns={'Score':'WScoreT'}, inplace=True)\ntourney_result = tourney_result.drop('TeamID', axis=1)\ntourney_result = pd.merge(tourney_result, season_score, left_on=['Season', 'LTeamID'], right_on=['Season', 'TeamID'], how='left')\ntourney_result.rename(columns={'Score':'LScoreT'}, inplace=True)\ntourney_result = tourney_result.drop('TeamID', axis=1)\ntourney_result\n#WScoreT is Score in this year","c3ef08af":"tourney_win_result = tourney_result.drop(['Season', 'WTeamID', 'LTeamID'], axis=1)\ntourney_win_result.rename(columns={'WSeed':'Seed1', 'LSeed':'Seed2', 'WScoreT':'ScoreT1', 'LScoreT':'ScoreT2'}, inplace=True)\ntourney_win_result","807980ae":"tourney_lose_result = tourney_win_result.copy()\ntourney_lose_result['Seed1'] = tourney_win_result['Seed2']\ntourney_lose_result['Seed2'] = tourney_win_result['Seed1']\ntourney_lose_result['ScoreT1'] = tourney_win_result['ScoreT2']\ntourney_lose_result['ScoreT2'] = tourney_win_result['ScoreT1']\ntourney_lose_result","a7b3dbd5":"tourney_win_result['Seed_diff'] = tourney_win_result['Seed1'] - tourney_win_result['Seed2']\ntourney_win_result['ScoreT_diff'] = tourney_win_result['ScoreT1'] - tourney_win_result['ScoreT2']\ntourney_lose_result['Seed_diff'] = tourney_lose_result['Seed1'] - tourney_lose_result['Seed2']\ntourney_lose_result['ScoreT_diff'] = tourney_lose_result['ScoreT1'] - tourney_lose_result['ScoreT2']","20d76ea4":"tourney_win_result['result'] = 1\ntourney_lose_result['result'] = 0\ntourney_result = pd.concat((tourney_win_result, tourney_lose_result)).reset_index(drop=True)\ntourney_result","de199edf":"test_df = pd.read_csv('..\/input\/google-cloud-ncaa-march-madness-2020-division-1-mens-tournament\/MSampleSubmissionStage1_2020.csv')\ntest_df['Season'] = test_df['ID'].map(lambda x: int(x[:4]))\ntest_df['WTeamID'] = test_df['ID'].map(lambda x: int(x[5:9]))\ntest_df['LTeamID'] = test_df['ID'].map(lambda x: int(x[10:14]))\ntest_df\n","58e2332b":"test_df = pd.merge(test_df, tourney_seed, left_on=['Season', 'WTeamID'], right_on=['Season', 'TeamID'], how='left')\ntest_df.rename(columns={'Seed':'Seed1'}, inplace=True)\ntest_df = test_df.drop('TeamID', axis=1)\ntest_df = pd.merge(test_df, tourney_seed, left_on=['Season', 'LTeamID'], right_on=['Season', 'TeamID'], how='left')\ntest_df.rename(columns={'Seed':'Seed2'}, inplace=True)\ntest_df = test_df.drop('TeamID', axis=1)\ntest_df = pd.merge(test_df, season_score, left_on=['Season', 'WTeamID'], right_on=['Season', 'TeamID'], how='left')\ntest_df.rename(columns={'Score':'ScoreT1'}, inplace=True)\ntest_df = test_df.drop('TeamID', axis=1)\ntest_df = pd.merge(test_df, season_score, left_on=['Season', 'LTeamID'], right_on=['Season', 'TeamID'], how='left')\ntest_df.rename(columns={'Score':'ScoreT2'}, inplace=True)\ntest_df = test_df.drop('TeamID', axis=1)\ntest_df","0b121742":"test_df['Seed1'] = test_df['Seed1'].map(lambda x: get_seed(x))\ntest_df['Seed2'] = test_df['Seed2'].map(lambda x: get_seed(x))\ntest_df['Seed_diff'] = test_df['Seed1'] - test_df['Seed2']\ntest_df['ScoreT_diff'] = test_df['ScoreT1'] - test_df['ScoreT2']\ntest_df = test_df.drop(['ID', 'Pred', 'Season', 'WTeamID', 'LTeamID'], axis=1)\ntest_df","5b94e690":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Read the data\nX = tourney_result.copy()\nX_test_full = test_df.copy()\n\n# Remove rows with missing target, separate target from predictors\nX.dropna(axis=0, subset=['result'], inplace=True)\ny = X.result              \nX.drop(['result'], axis=1, inplace=True)\n   \n    \n    # Break off validation set from training data\nX_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n                                                                random_state=0)\n\n# \"Cardinality\" means the number of unique values in a column\n# Select categorical columns with relatively low cardinality (convenient but arbitrary)\nlow_cardinality_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and \n                        X_train_full[cname].dtype == \"object\"]\n# Low cardinality means that the column contains a lot of \u201crepeats\u201d in its data range.\n# Examples of categorical variables are race, sex, age group, and educational level. \n# While the latter two variables may also be considered in a numerical manner by using exact values for age \n# and highest grade completed\n# nunique() function to find the number of unique values over the column axis. So when it finds over 10 uniqe \n# values and the cname is a \n# dtype 'object' which means Data type objects are useful for creating structured arrays. \n# A structured array is the one which contains different types of data.\n\n### one line meaning of above####\n## for cname in a dataframes column shall return a value to 'low_cardinality_cols' if there are more then 10 uniqe values\n## and the dtype shall be a object which is a structured array that can have different types of data (lik; int, float string ect.)\n\n\n# Select numeric columns\nnumeric_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n### for cname (every value, one at the time) in dataframe for columns return a value to 'numeric_cols' if the \n### dtype= int64 or float64. \n\n\n\n# Keep selected columns only\nmy_cols = low_cardinality_cols + numeric_cols\nX_train = X_train_full[my_cols].copy()\nX_valid = X_valid_full[my_cols].copy()\nX_test = X_test_full[my_cols].copy()\n\n# One-hot encode the data (to shorten the code, we use pandas)\nX_train = pd.get_dummies(X_train)\nX_valid = pd.get_dummies(X_valid)\nX_test = pd.get_dummies(X_test)\nX_train, X_valid = X_train.align(X_valid, join='left', axis=1)\nX_train, X_test = X_train.align(X_test, join='left', axis=1)","2e24dc36":"X_train.head()","0ff4cd64":"y.head()","0cc6b926":"from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\nfrom xgboost import XGBRegressor\n\n\nmodel2 = RandomForestClassifier(n_estimators=150, max_depth=4, random_state=1)\nmodel_0 = GradientBoostingClassifier(random_state=1)\nmodel3 = DecisionTreeClassifier(max_depth=3, random_state=1)\n#model=SGDClassifier(random_state=1)\n#model=ExtraTreesClassifier(random_state=1)\nmodel = XGBRegressor()\n# Define the models\nmodel_1 = RandomForestClassifier(n_estimators=50, random_state=0)\nmodel_2 = RandomForestClassifier(n_estimators=100, random_state=0)\nmodel_3 = RandomForestClassifier(n_estimators=200, min_samples_split=20, random_state=0)\nmodel_4 = RandomForestClassifier(n_estimators=300, max_depth=6, random_state=1)\n\n\n\nmodel.fit(X_train,y_train)\n\n\nprint(f'Model test accuracy: {model.score(X_valid, y_valid)*100:.3f}%')","980560b5":"model2.fit(X_train,y_train)\nprint(f'Model test accuracy: {model2.score(X_valid, y_valid)*100:.3f}%')\nmodel3.fit(X_train,y_train)\nprint(f'Model test accuracy: {model3.score(X_valid, y_valid)*100:.3f}%')","3b97bc71":"model_1.fit(X_train,y_train)\nprint(f'Model test accuracy: {model_1.score(X_valid, y_valid)*100:.3f}%')\nmodel_2.fit(X_train,y_train)\nprint(f'Model test accuracy: {model_2.score(X_valid, y_valid)*100:.3f}%')\nmodel_3.fit(X_train,y_train)\nprint(f'Model test accuracy: {model_3.score(X_valid, y_valid)*100:.3f}%')\nmodel_4.fit(X_train,y_train)\nprint(f'Model test accuracy: {model_4.score(X_valid, y_valid)*100:.3f}%')","d9909fb7":"Pred = model.predict(X_test)\n\n# to submit\nsubmission_df = pd.read_csv('..\/input\/google-cloud-ncaa-march-madness-2020-division-1-mens-tournament\/MSampleSubmissionStage1_2020.csv')\nsubmission_df['Pred'] = Pred\n\noutput = pd.DataFrame({'ID': submission_df.ID, 'Pred': Pred})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","a577db53":"if len(output) == len(submission_df):\n    print(\"Submission dataframe is the same length as test ({} rows).\".format(len(output)))\nelse:\n    print(\"Dataframes mismatched, won't be able to submit to Kaggle.\")","abd84c11":"# Submission","a5042d8b":"Thank you for reading my kernal, if there are any mistakes or improvement you want to point out, feel free to do so in the comments, and thank you in advance if you do! ","cb30a5e4":"# Model \/ predictions","640359c2":"# Importing data","9d418e7e":"# Disclaimer! This kernel is only for educational purposes and made for fun therefor the content of the kernel should not be taken to seriously!\n\nAll the data preprocessing is based on [This Kernel.](https:\/\/www.kaggle.com\/ratan123\/march-madness-2020-ncaam-simple-lightgbm-on-kfold)\nThank you for that!!\nThe main purpose of this kernel is to build a simple ML model. \n","c9a2d6c9":"# more predictions","d9f3026a":"# model prep","18f1dceb":"![image.png](attachment:image.png)","03df044a":"# test data cleaning","7796e967":"# tourney_result cleaning"}}