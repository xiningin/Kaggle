{"cell_type":{"f746c07e":"code","3ff090ac":"code","a30d4db2":"code","66ef872a":"code","7b89d016":"code","2c2fdbca":"code","6034a555":"code","331b5ed3":"code","afed528a":"code","745d0c58":"code","909b62fd":"code","78cfb73a":"code","b22cc3ce":"code","e9ffee26":"code","eabc7c30":"code","ca73585e":"code","9bc2d64f":"code","631f5ef5":"code","e2796ccb":"code","a37fa135":"code","0d884728":"code","b4c97dcf":"markdown","c8fe3c3f":"markdown","929fa835":"markdown","cc08fd19":"markdown","43d38a76":"markdown"},"source":{"f746c07e":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","3ff090ac":"from fastai.imports import *","a30d4db2":"from fastai.transforms import *\nfrom fastai.conv_learner import *\nfrom fastai.model import *\nfrom fastai.dataset import *\nfrom fastai.sgdr import *\nfrom fastai.plots import *","66ef872a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os","7b89d016":"torch.cuda.is_available()","2c2fdbca":"torch.backends.cudnn.enabled","6034a555":"print(os.listdir('..\/input\/'))\nPATH = \"..\/input\/\"\nTMP_PATH = \"\/tmp\/tmp\"\nMODEL_PATH = \"\/tmp\/model\/\"\narch = resnet34\nsz = 14","331b5ed3":"train_df = pd.read_csv('..\/input\/fashion-mnist_train.csv')\ntest_df  = pd.read_csv('..\/input\/fashion-mnist_test.csv')\n\nprint(f'train_df shape : {train_df.shape}')\nprint(f'test_df shape  : {test_df.shape}')","afed528a":"test_df.head(10)","745d0c58":"valid_df = train_df.sample(frac=0.2)\ntrain_df = train_df.drop(valid_df.index)","909b62fd":"print(f'Train_df shape : {train_df.shape}')\nprint(f'Valid_df shape : {valid_df.shape}')\nprint(f'Test_df shape  : {test_df.shape}')","78cfb73a":"def split_df(df):\n    '''return a tuple (X, y) \n    \n        X : the training inputs which is in (samples, height, width, channel) shape\n        y : the label which is flatten\n    '''\n    y = df['label'].values.flatten()\n    X = df.drop('label', axis=1).values\n    X = X.reshape(X.shape[0], 28, 28)\n    return (X,y)","b22cc3ce":"X_train, y_train = split_df(train_df)\nX_valid, y_valid = split_df(valid_df)\nX_test, y_test   = split_df(test_df)","e9ffee26":"print(f'Train set shape : {X_train.shape, y_train.shape}')\nprint(f'Valid set shape : {X_valid.shape, y_valid.shape}')\nprint(f'Test  set shape  : {X_test.shape, y_test.shape}')","eabc7c30":"# normalizing data \nX_train = X_train.astype('float64') \/ 255\nX_valid = X_valid.astype('float64') \/ 255\nX_test = X_test.astype('float64') \/ 255","ca73585e":"# adding missing color channels \nX_train = np.stack((X_train,) * 3, axis=-1)\nX_valid = np.stack((X_valid,) * 3, axis=-1)\nX_test  = np.stack((X_test,) * 3, axis=-1)","9bc2d64f":"print(f'Train set shape : {X_train.shape, y_train.shape}')\nprint(f'Valid set shape : {X_valid.shape, y_valid.shape}')\nprint(f'Test  set shape  : {X_test.shape, y_test.shape}')","631f5ef5":"labels = ['T-shirt\/top',\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",'Sneaker',\"Bag\",\"Ankle boot\"]","e2796ccb":"index = 3\nplt.imshow(X_train[index,], cmap='gray')\nplt.title(labels[y_train[index]])","a37fa135":"data = ImageClassifierData.from_arrays(PATH, trn=(X_train,y_train), classes=[0,1,2,3,4,5,6,7,8,9],val=(X_valid, y_valid), tfms=tfms_from_model(arch, 28), test=X_test)\nlearn = ConvLearner.pretrained(arch, data, precompute=True, tmp_name=TMP_PATH, models_name=MODEL_PATH)\nlearn.fit(7e-3, 3, cycle_len=1, cycle_mult=2)","0d884728":"log_preds, _ = learn.TTA(is_test=True)\nprods = np.exp(log_preds)\nprods = np.mean(prods, 0)\naccuracy_np(prods, y_test)","b4c97dcf":"We loaded the csv files containing the training and test images into train and test.\nLet's take a look at the dataset by using `df.head()`","c8fe3c3f":"We are now going to split each dataset into label y and img sample X. ","929fa835":"## Visualizing Data","cc08fd19":"As we can see in above dataframe, the first column contains the labels and the rest are pixels of each image.\nWe are now going to split the train data set into train and validation sets.  We will use 0.2 fraction of the train data as validation data.","43d38a76":"## Loading dataset into train and test set"}}