{"cell_type":{"929934b1":"code","fbefd1df":"code","bd75326e":"code","fe7c6665":"code","797e7428":"code","b5023d59":"code","6a8159f2":"code","c0197b34":"code","98188bb6":"code","b6f7593b":"code","7835eebc":"code","e3c54882":"code","9fb40e8f":"code","7e8d0994":"code","ff57fff0":"code","dee0ca69":"code","fe5d6c55":"code","bb69b688":"code","65c98a52":"code","998c1028":"code","d51e1d0e":"code","d4c009f0":"code","d0782e1a":"markdown","1fca76e8":"markdown","6578db05":"markdown","058cf9f2":"markdown","20598654":"markdown","a7c438f2":"markdown","b83a4850":"markdown","4a53c971":"markdown","8da56c8f":"markdown","29e0b492":"markdown","1be784ba":"markdown","a345ff73":"markdown","bcd3df67":"markdown","480f26d4":"markdown","db6da0df":"markdown","ea8e2324":"markdown","2b776526":"markdown","e61a8e50":"markdown","9a7b94de":"markdown","6b15ca13":"markdown","b4ecd4f5":"markdown","074d289e":"markdown","098f1b2b":"markdown","a3f1cb7f":"markdown","30b58469":"markdown","ba016128":"markdown","d31b4a61":"markdown","77f0115a":"markdown","37cbaea2":"markdown","6f8afaa1":"markdown","a6ca37c1":"markdown","f4124ed9":"markdown","216d6211":"markdown"},"source":{"929934b1":"import pandas as pd\n\ndata = pd.read_csv('..\/input\/used-car-dataset-ford-and-mercedes\/focus.csv')\nprint('Raw Data')\nprint(data.head())","fbefd1df":"transmission = pd.get_dummies(data['transmission'], drop_first=True)\nfuelType = pd.get_dummies(data['fuelType'], drop_first=True)","bd75326e":"data = data.drop(columns=['model', 'transmission', 'fuelType'])\ndata = data.join(transmission)\ndata = data.join(fuelType)\ndata.rename(columns={'year': 'year', 'price': 'price', 'mileage': 'mileage', 'engineSize': 'engine_size', 'Manual': 'manual', 'Semi-Auto': 'semi_auto', 'Petrol': 'petrol'}, inplace=True)\ndata = data[['year', 'mileage', 'engine_size', 'manual', 'semi_auto', 'petrol', 'price']]\nprint('Organized Data')\nprint(data.head())","fe7c6665":"import numpy as np\nfrom sklearn.model_selection import train_test_split\n\nX = data[['year', 'mileage', 'engine_size', 'manual', 'semi_auto', 'petrol']]\ny = data['price']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\nX_train = X_train.to_numpy()\nX_test = X_test.to_numpy()\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\n\nprint('X_train\\n' + str(X_train[:4,:]) + '\\n')\nprint('y_train\\n' + str(y_train[:4]) + '\\n')\nprint('X_test\\n' + str(X_test[:4,:]) + '\\n')\nprint('y_test\\n' + str(y_test[:4]))","797e7428":"# Select all rows from the second (mileage) column of the numpy arrays\nX_train_mileage = X_train[:,1]\nX_test_mileage = X_test[:,1]\n\nprint('X_train_mileage: ' + str(X_train_mileage))\nprint('y_train: ' + str(y_train))\n\nfrom bokeh.plotting import figure, show\nfrom bokeh.io import output_notebook\noutput_notebook()\n\ntrain_plot = figure(title='Training Data', x_axis_label='Mileage', y_axis_label='Price')\ntrain_plot.circle(x=X_train_mileage, y=y_train, color='blue')\nshow(train_plot)","b5023d59":"from sklearn.preprocessing import PolynomialFeatures\n\ncubic = PolynomialFeatures(degree=3)\nX_train_mileage_cubic = cubic.fit_transform(X_train_mileage[:,None])\nX_test_mileage_cubic = cubic.fit_transform(X_test_mileage[:,None])\n\nprint('X_train_mileage_cubic \\n' + str(X_train_mileage_cubic[:4,:]))","6a8159f2":"from sklearn import linear_model\n\ncubic_model = linear_model.LinearRegression()\ncubic_model.fit(X_train_mileage_cubic, y_train)\n\ntrain_predictions_cubic = cubic_model.predict(X_train_mileage_cubic)\ntest_predictions_cubic = cubic_model.predict(X_test_mileage_cubic)","c0197b34":"from bokeh.layouts import row\n\ntrain_plot_cubic = figure(title='Train Data', x_axis_label='Mileage', y_axis_label='Price')\ntest_plot_cubic = figure(title='Test Data', x_axis_label='Mileage', y_axis_label='Price')\n\ntrain_plot_cubic.circle(x=X_train_mileage, y=y_train, color='blue', legend_label='Actual')\ntrain_plot_cubic.circle(x=X_train_mileage, y=train_predictions_cubic, color='red', legend_label='Predicted')\n\ntest_plot_cubic.circle(x=X_test_mileage, y=y_test, color='blue', legend_label='Actual')\ntest_plot_cubic.circle(x=X_test_mileage, y=test_predictions_cubic, color='red', legend_label='Predicted')\n\nshow(row(train_plot_cubic,test_plot_cubic))\n\nprint('Train Data R-squared: ' + str(cubic_model.score(X_train_mileage_cubic,y_train)))\nprint('Test Data R-squred: ' + str(cubic_model.score(X_test_mileage_cubic,y_test)))","98188bb6":"X_train_mileage_rl = X_train_mileage[:,None]\nX_test_mileage_rl = X_test_mileage[:,None]\n\ndef addInvLogFeatures(numeric):\n    log_feats = numeric.copy()\n    valid = (log_feats != 1) & (log_feats > 0)\n    log_feats[valid] = np.log(log_feats[valid]) \/ np.log(10)\n    log_feats[log_feats <= 0] = 1e-10\n    inv_log_feats = 1 \/ log_feats\n    return np.hstack([numeric, inv_log_feats, numeric * inv_log_feats])\n\nX_train_mileage_rl = addInvLogFeatures(X_train_mileage_rl)\nX_test_mileage_rl = addInvLogFeatures(X_test_mileage_rl)\n\nprint('X_train_mileage_rl \\n' + str(X_train_mileage_rl[:4,:]))","b6f7593b":"rl_model = linear_model.LinearRegression()\nrl_model.fit(X_train_mileage_rl, y_train)\n\ntrain_predictions_rl = rl_model.predict(X_train_mileage_rl)\ntest_predictions_rl = rl_model.predict(X_test_mileage_rl)","7835eebc":"train_plot_rl = figure(title='Train Data', x_axis_label='Mileage', y_axis_label='Price')\ntest_plot_rl = figure(title='Test Data', x_axis_label='Mileage', y_axis_label='Price')\n\ntrain_plot_rl.circle(x=X_train_mileage, y=y_train, color='blue', legend_label='Actual')\ntrain_plot_rl.circle(x=X_train_mileage, y=train_predictions_rl, color='red', legend_label='Predicted')\n\ntest_plot_rl.circle(x=X_test_mileage, y=y_test, color='blue', legend_label='Actual')\ntest_plot_rl.circle(x=X_test_mileage, y=test_predictions_rl, color='red', legend_label='Predicted')\n\nshow(row(train_plot_rl,test_plot_rl))\n\nprint('Train Data R-squared: ' + str(rl_model.score(X_train_mileage_rl,y_train)))\nprint('Test Data R-squred: ' + str(rl_model.score(X_test_mileage_rl,y_test)))","e3c54882":"from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\nX_train_numeric = X_train[:,:3]\nX_test_numeric = X_test[:,:3]\n\nscaler = StandardScaler()\nX_train_numeric_scaled = scaler.fit_transform(X_train_numeric)\nX_test_numeric_scaled = scaler.fit_transform(X_test_numeric)\n\npca = PCA(n_components=1)\nX_train_pca = pca.fit_transform(X_train_numeric_scaled)\n\ntrain_plot_pca = figure(title='Principal Component Analysis', x_axis_label='Principal Component', y_axis_label='price')\ntrain_plot_pca.circle(x=X_train_pca[:,0], y=y_train, color='blue')\nshow(train_plot_pca)","9fb40e8f":"X_train_cubic = cubic.fit_transform(X_train_numeric)\nX_test_cubic = cubic.fit_transform(X_test_numeric)\n# print(\"X_train_cubic \\n\" + str(X_train_cubic[:4,:]))","7e8d0994":"X_train_cubic_scaled = scaler.fit_transform(X_train_cubic)\nX_test_cubic_scaled = scaler.fit_transform(X_test_cubic)\n\nX_train_nominal = X_train[:,3:]\nX_test_nominal = X_test[:,3:]\n\nX_train_cubic_full = np.hstack([X_train_cubic_scaled, X_train_nominal])\nX_test_cubic_full = np.hstack([X_test_cubic_scaled, X_test_nominal])\n\n# print(\"X_train_cubic_full \\n\" + str(X_train_cubic_full[:4,:]))","ff57fff0":"cubic_model = linear_model.RidgeCV()\ncubic_model.fit(X_train_cubic_full, y_train)\n\ntrain_predictions_cubic = cubic_model.predict(X_train_cubic_full)\ntest_predictions_cubic = cubic_model.predict(X_test_cubic_full)","dee0ca69":"print('Train Data R-squared: ' + str(cubic_model.score(X_train_cubic_full,y_train)))\nprint('Test Data R-squred: ' + str(cubic_model.score(X_test_cubic_full,y_test)))","fe5d6c55":"df = pd.DataFrame({\"Predicted\": test_predictions_cubic, \"Actual\": y_test})\ndf['% Difference'] = (abs(df['Predicted']-df['Actual'])\/df['Actual'])*100\n\nprint(\"Percentage Difference between Predicted and Actual Values (Cubic Model)\")\nprint(df.head())\nprint(\"\\nMean % Difference between Predicted and Actual Values: \" + str(df['% Difference'].mean()) +\"%\")","bb69b688":"X_train_rl = addInvLogFeatures(X_train_numeric)\nX_test_rl = addInvLogFeatures(X_test_numeric)\n# print('X_train_rl \\n' + str(X_train_rl[:4,:]))","65c98a52":"X_train_rl_scaled = scaler.fit_transform(X_train_rl)\nX_test_rl_scaled = scaler.fit_transform(X_test_rl)\n\nX_train_rl_full = np.hstack([X_train_rl_scaled, X_train_nominal])\nX_test_rl_full = np.hstack([X_test_rl_scaled, X_test_nominal])\n\n# print(\"X_train_rl_full \\n\" + str(X_train_rl_full[:4,:]))","998c1028":"rl_model = linear_model.RidgeCV()\nrl_model.fit(X_train_rl_full, y_train)\n\ntrain_predictions_rl = rl_model.predict(X_train_rl_full)\ntest_predictions_rl = rl_model.predict(X_test_rl_full)","d51e1d0e":"print('Train Data R-squared: ' + str(rl_model.score(X_train_rl_full,y_train)))\nprint('Test Data R-squred: ' + str(rl_model.score(X_test_rl_full,y_test)))","d4c009f0":"df = pd.DataFrame({\"Predicted\": test_predictions_rl, \"Actual\": y_test})\ndf['% Difference'] = (abs(df['Predicted']-df['Actual'])\/df['Actual'])*100\n\nprint(\"Percentage Difference between Predicted and Actual Values (Reciprocal Log Model)\")\nprint(df.head())\nprint(\"\\nMean % Difference between Predicted and Actual Values: \" + str(df['% Difference'].mean()) +\"%\")","d0782e1a":"### Import and Read Data\n\nThe first step is to import necessary libraries and read the raw data into a Pandas DataFrame.","1fca76e8":"\nFirst, the single feature $x$, is transformed into multiple featuers $x^0, x^1, x^2, x^3$.","6578db05":"First, the data is transformed to match the reciprocal $\\log$ function $\\frac{1}{\\log(x)}$.","058cf9f2":"### Convert Categorical Data to Dummy Values\n\nBefore running regression, the *categorical (nominal) data* must first be converted to *dummy values*. Dummy values indicate the absence or presence of a feature with a `0` or `1` value. For nominal data with $k$ possible values, we create $k-1$ dummy variables. The `drop_first=True` parameter drops the first of the $k$ possible values, leading to $k-1$ features. The two nominal features that must be converted are `transmission` and `fuelType`.","20598654":"Closeness of fit is assessed using $R^2$ once again.","a7c438f2":"# \ud83d\ude98 Used Car Pricing Model\n\n**Goal:** The goal of this project is to estimate the resale price of a used Ford Focus using regression.","b83a4850":"Instead of plotting the predictions, the following code compares the predicted price to the actual price, and calculates, on average, how far off the prediction was (for the test data).","4a53c971":"## Preprocessing","8da56c8f":"Before running regression to fit the model, the features are scaled to make the orders of magnitude roughly the same. They are then combined with the ordinal features from before.","29e0b492":"### Cubic Model\n\nThe first model is a cubic one. That means it takes the form $y = ax^3 + bx^2 + cx + d$ for constants $a, b, c, d$, where $x$ is the `mileage` variable and $y$ is the predicted price.","1be784ba":"Then, linear regression is run to fit the model and generate predictions for the train and test set.","a345ff73":"First, the numeric features are transformed to match the reciprocal $\\log$ function $\\frac{1}{\\log(x)}$.","bcd3df67":"## Principle Component Analysis (PCA)\n\n*Principal Component Analysis* flattens multiple numeric features into fewer features (known as components) that preserve the most important information from the original data. This allows for easy visualization of the data to get an intuition of which function would be best applied.","480f26d4":"Before running regression to fit the model, the features are scaled to make the orders of magnitude roughly the same. They are then combined with the ordinal features from before.","db6da0df":"### Visualize the Shape of the Data\n\nIn order to develop an intuition around which function will fit the data best, it is helpful to visualize the relationship between $x$ (`mileage`) and $y$ (`price`) in the training data.","ea8e2324":"Finally, the cubic model is fit using `RidgeCV` - an advanced form of linear regression that *regularizes* data to prevent overfitting.","2b776526":"Again, the reciprocal $\\log$ model is fit using `RidgeCV` - a *regularized* version of regression.","e61a8e50":"### Cubic Model\nThe first model is a cubic one. That means it takes the form $y = ax^3 + bx^2 + cx + d$ for constants $a, b, c, d$. This time however, every variable is used as input, and not just `mileage`.","9a7b94de":"### Reciprocal Logarithmic Model\n\nAnother approach is a model similar in shape to $\\frac{1}{\\log(x)}$, with all the features.","6b15ca13":"Finally, predicted results are plotted against the train and test data and assigned an $R^2$ value (measure of how close the data fit the model).","b4ecd4f5":"First, each numeric feature is transformed into polynomial features of degree 3.","074d289e":"Once again, linear regression is run to fit the model and generate predictions for the train and test set.","098f1b2b":"### Reciprocal Logarithmic Model\n\nThe second approach is a model similar in shape to $\\frac{1}{\\log(x)}$.","a3f1cb7f":"### Organize the DataFrame\n\nThe following step joins dummy variables, drops unnecessary features, and rearranges features in the DataFrame.","30b58469":"The above plot suggests that both cubic and reciprocal logarithmic functions might be good fits for the data.","ba016128":"The data is either cubic or close to the function $\\frac{1}{\\log(x)}$. Each curve is then plotted to determine the optimal model.","d31b4a61":"There are 6 input features: `year`, `transmission`, `mileage`, `fuelType`, and `engineSize`. The `model` column can be dropped because it is constant across each row. The `price` column is the output ($y$) variable.","77f0115a":"Instead of plotting the predictions, the following code compares the predicted price to the actual price, and calculates, on average, how far off the prediction was (for the test data).","37cbaea2":"### Split into Train\/Test Data\n\nThe data must be split into a *training set* to build the model and a *test set* to evaluate its effectiveness. Here, 75% of the data is used to train and 25% is used to test.","6f8afaa1":"And again, predicted results are plotted against the train and test data and assigned an $R^2$ value (measure of how close the data fit the model).","a6ca37c1":"## Model 2: Multiple Polynomial Regression\n\nThe final model will use all numeric variables: `year`, `mileage`, `engine_size`, and dummy variables `manual`, `semi_auto`, `petrol`, to predict the output variable: `price`.","f4124ed9":"Once again, closeness of fit is measured with $R^2$.","216d6211":"## Model 1: Simple Polynomial Regression\n\nThe first model will use just one numeric variable: `mileage`, to predict the output variable: `price`."}}