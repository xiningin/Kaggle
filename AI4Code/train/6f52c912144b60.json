{"cell_type":{"6d8ae8a8":"code","0551eff4":"code","4810e245":"code","d0ee7c59":"code","ca81f046":"code","9a279eb9":"code","c39b9c2f":"code","bc4d116b":"code","0cedee3d":"code","8cb8c9f2":"code","3c28159d":"code","d00a5a9e":"code","646913a2":"code","93462e2d":"code","3bc38f91":"code","1bb412f6":"code","850e4ebd":"code","1a7821f0":"code","5339aa0d":"code","98dc347a":"code","9cb5c769":"code","e9ff6def":"code","cccf19d1":"code","a082eacd":"code","c0427b2e":"code","8a8db548":"code","e246b511":"code","ea51920c":"code","7e0f013d":"code","9c32f4a5":"code","448f0d52":"code","08d96239":"code","39c9f8cf":"code","76faacf1":"code","764ba23b":"code","3938eb3a":"code","73e93d42":"code","4831c553":"code","f2e62b1a":"code","2c795804":"code","51eda916":"code","fe0f99a7":"code","97f75a38":"code","4858d064":"code","eb98bbec":"code","592ceab2":"code","2b6de459":"code","65ba5ec4":"code","daf2b901":"code","535cdfef":"code","7560e2bb":"code","4f38538a":"code","72ae7a96":"code","4e9a50d9":"code","80240afe":"code","c5a12c9c":"code","0b43cc6c":"code","b54756f8":"code","41081868":"code","9cb4661d":"code","8f1845fb":"code","737d1252":"code","431f8993":"code","053d9390":"code","bfc45cae":"code","5d2cf46a":"code","85f5b042":"code","abdfb2b9":"code","100da92d":"code","f160c49e":"code","3a34a38a":"code","44cc0f34":"code","9e0d9b14":"code","cbb599ea":"code","6ca23e07":"code","76b755d0":"markdown","c144d13f":"markdown","83b1854a":"markdown","d10f93dd":"markdown","8548ef9e":"markdown","3bda2b22":"markdown","019ccb4c":"markdown","815672d1":"markdown","b63bde5a":"markdown","407e3773":"markdown","c92acf80":"markdown","8bf04ef7":"markdown","88ce4909":"markdown","b5f52023":"markdown","785cbba3":"markdown","eb42072e":"markdown","8dc8ecc8":"markdown","e37c61ec":"markdown","a7fa1df8":"markdown","40675dec":"markdown","27a69a6e":"markdown","f3c88e50":"markdown","14767f80":"markdown","cc09523f":"markdown","2eb81bd8":"markdown","ea85e047":"markdown","8158013e":"markdown","39ba9258":"markdown","2adcf672":"markdown","41a76c68":"markdown","559db6f4":"markdown","204262d8":"markdown","89610da6":"markdown","bdae9ec8":"markdown","2ff2c1f2":"markdown","d8273326":"markdown","4ccff8be":"markdown","22872cdd":"markdown","2d12df05":"markdown","b53993e9":"markdown","a111a71b":"markdown","542af269":"markdown","9536b6ef":"markdown","66d0454a":"markdown","a3368d4a":"markdown","1d706a7d":"markdown","91e3d235":"markdown","9ad35859":"markdown","6c52ce4d":"markdown","4d2fb67a":"markdown","6c7a4243":"markdown","0e65313f":"markdown"},"source":{"6d8ae8a8":"pip install contractions","0551eff4":"pip install unidecode","4810e245":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom wordcloud import WordCloud, STOPWORDS\nstopwords=set(STOPWORDS)\nimport re\nimport random\nimport nltk\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.corpus import stopwords\nimport matplotlib\nfrom matplotlib import pyplot as plt\nfrom matplotlib import gridspec\nfrom sklearn.feature_extraction.text import CountVectorizer\n%matplotlib inline\nimport warnings\nimport contractions\nimport unidecode\nfrom collections import Counter\nimport spacy\nfrom nltk.stem import PorterStemmer\nporter = PorterStemmer()\nfrom nltk.stem import WordNetLemmatizer\nlemmatizer = WordNetLemmatizer()\nwarnings.filterwarnings('ignore')\nstopwords = nltk.corpus.stopwords.words('english')\n","d0ee7c59":"nltk.download('punkt')\nnltk.download('stopwords')\nnlp = spacy.load(\"en_core_web_sm\")\nnltk.download('averaged_perceptron_tagger')\nnltk.download('words')\nnltk.download('wordnet')","ca81f046":"train=pd.read_csv(\"..\/input\/uhack-sentiments-20-decode-code-words\/Participants_Data_DCW\/train.csv\")\ntest=pd.read_csv(\"..\/input\/uhack-sentiments-20-decode-code-words\/Participants_Data_DCW\/test.csv\")","9a279eb9":"train.info()","c39b9c2f":"test.info()","bc4d116b":"train.isnull().sum()","0cedee3d":"test.isnull().sum()","8cb8c9f2":"train.head()","3c28159d":"test.head()","d00a5a9e":"fig=plt.subplots(figsize=(15, 15))\nfor i,col  in enumerate(train.iloc[:,2:14].columns.values):    \n       _=plt.subplot(6,2,i+1)\n       _=sns.countplot(x=train[col],hue=train[col])\n       _=plt.title(col+' Topic Distribution',fontsize=15)\n       _=plt.xlabel(col,fontsize=10)\n       _=plt.xticks(fontsize=15)\n       _=plt.tight_layout()  \nplt.show()  ","646913a2":"for col in train.iloc[:,2:14].columns.values:    \n  print(\"=\"*100)\n  print(train[col].value_counts())\n  print(\"-\"*100)","93462e2d":"fig = plt.figure(figsize=(30, 30),constrained_layout=True)\nouter = gridspec.GridSpec(6, 2, wspace=0.2, hspace=0.2)\n\nfor i,col  in enumerate(train.iloc[:,2:8].columns.values):\n    inner = gridspec.GridSpecFromSubplotSpec(1, 2,\n                    subplot_spec=outer[i], wspace=0.1, hspace=0.1\n                    )\n    for x in train[col].unique():    \n        ax = plt.Subplot(fig, inner[x])\n        wc = WordCloud(background_color=\"white\", max_words=100, stopwords=stopwords,\n                    max_font_size=40, random_state=42).generate(train[train[col]==x]['Review'].to_string())\n        fig.add_subplot(ax)\n        plt.imshow(wc)\n        ax.set_title(f\"{col}_{x}\")\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.set_frame_on(False)\nfig.tight_layout()\n  \n         ","3bc38f91":"fig = plt.figure(figsize=(30, 30),constrained_layout=True)\nouter = gridspec.GridSpec(6, 2, wspace=0.2, hspace=0.2)\n\nfor i,col  in enumerate(train.iloc[:,8:14].columns.values):\n    inner = gridspec.GridSpecFromSubplotSpec(1, 2,\n                    subplot_spec=outer[i], wspace=0.1, hspace=0.1\n                    )\n    for x in train[col].unique():    \n        ax = plt.Subplot(fig, inner[x])\n        wc = WordCloud(background_color=\"white\", max_words=100, stopwords=stopwords,\n                    max_font_size=40, random_state=42).generate(train[train[col]==x]['Review'].to_string())\n        fig.add_subplot(ax)\n        plt.imshow(wc)\n        ax.set_title(f\"{col}_{x}\")\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.set_frame_on(False)\nfig.tight_layout()\n  \n         ","1bb412f6":"_=plt.figure(figsize=(8, 5))\n_=sns.histplot(train['Review'].str.len(),kde=True)\n_=plt.title( 'Number of characters in Reviews',fontsize=15)","850e4ebd":"sns.boxplot(y=train['Review'].str.len());","1a7821f0":"train['Review'].str.len().describe()","5339aa0d":"_=plt.figure(figsize=(8, 5))\n_=sns.histplot(train['Review'].str.split().map(lambda x: len(x)),kde=True,color='Green')\n_=plt.title( 'Number of Words in Reviews',fontsize=15)","98dc347a":"sns.boxplot(y=train['Review'].str.split().map(lambda x: len(x)),color='Green');","9cb5c769":"train['Review'].str.split().map(lambda x: len(x)).describe()","e9ff6def":"_=plt.figure(figsize=(8, 5))\n_=sns.histplot(train['Review'].str.split().apply(lambda x: [len(i) for i in x]).map(lambda x:np.mean(x))\n,kde=True,color='Orange')\n_=plt.title( 'Average Number of Words in Each Reviews',fontsize=15)\n","cccf19d1":"sns.boxplot(y=train['Review'].str.split().apply(lambda x: [len(i) for i in x]).map(lambda x:np.mean(x)),\n            color='Orange');","a082eacd":"train['Review'].str.split().apply(lambda x: [len(i) for i in x]).map(lambda x:np.mean(x)).describe()","c0427b2e":"txt_info=train.iloc[:,2:14]\nfor i in range(3):\n   txt_info['characters']=train['Review'].str.len()\n   txt_info['words']=train['Review'].str.split().map(lambda x: len(x))\n   txt_info['avg_words']=train['Review'].str.split().apply(lambda x: [len(i) for i in x]).map(lambda x:np.mean(x))\n   \n","8a8db548":"def target_grp_hist(df,valcol,title=''):\n  fig=plt.subplots(figsize=(15, 15))\n  for i,col in enumerate(df.iloc[:,0:12].columns.values): \n    _=plt.subplot(6,2,i+1)\n    _=sns.histplot(x=df[valcol],hue=txt_info[col])\n    _=plt.title(col+title,fontsize=15)\n    _=plt.xlabel(col,fontsize=10)\n    _=plt.xticks(fontsize=15)\n    _=plt.tight_layout()  \n  plt.show()","e246b511":"target_grp_hist(txt_info,'characters','-Number of Characters')","ea51920c":"def target_grp_box(df,valcol,title=''):\n  fig=plt.subplots(figsize=(15, 15))\n  for i,col in enumerate(df.iloc[:,0:12].columns.values): \n    _=plt.subplot(6,2,i+1)\n    _=sns.boxplot(x=txt_info[col],y=df[valcol])\n    _=plt.title(col+title,fontsize=15)\n    _=plt.xlabel(col,fontsize=10)\n    _=plt.xticks(fontsize=15)\n    _=plt.tight_layout()  \n  plt.show()","7e0f013d":"target_grp_box(txt_info,'characters','-Number of Characters')","9c32f4a5":"def target_grp_summary(df,valcol):\n  for col in df.iloc[:,0:12].columns.values:\n    print(\"=\"*100)\n    print(f\"{df.groupby([col])[valcol].describe()}\")\n    print(\"-\"*100)","448f0d52":"target_grp_summary(txt_info,'characters')    ","08d96239":"target_grp_hist(txt_info,'words','-Number of Words')","39c9f8cf":"target_grp_box(txt_info,'words','-Number of Words')","76faacf1":"target_grp_summary(txt_info,'words')","764ba23b":"target_grp_hist(txt_info,'avg_words','-Number of Average Words')","3938eb3a":"target_grp_box(txt_info,'avg_words','-Number of Average Words')","73e93d42":"target_grp_summary(txt_info,'avg_words')","4831c553":"from collections import defaultdict","f2e62b1a":"\nwords = word_tokenize(train['Review'].to_string().lower())\n","2c795804":"dic=defaultdict(int)\nfor word in words:\n    if word in stopwords:\n        dic[word]+=1","51eda916":"list(dict(Counter(dic).most_common(20)).items())","fe0f99a7":"_=plt.figure(figsize=(8,8))\nsns.barplot(x=list(dict(Counter(dic).most_common(20)).values()),\n            y=list(dict(Counter(dic).most_common(20)).keys())\n            );","97f75a38":"dic1=defaultdict(int)\nfor word in words:\n    if word not in stopwords:\n        dic1[word]+=1","4858d064":"list(dict(Counter(dic1).most_common(20)).items())","eb98bbec":"_=plt.figure(figsize=(8,8))\nsns.barplot(x=list(dict(Counter(dic1).most_common(20)).values()),\n            y=list(dict(Counter(dic1).most_common(20)).keys())\n            );","592ceab2":"def top_ngram(txt=None,n=0):\n  n_gram=(pd.Series(nltk.ngrams(txt, n)).value_counts().sort_values(ascending=False))[:10]\n  return n_gram, sns.barplot(x=n_gram.values,\n                            y=n_gram.index);","2b6de459":"top_ngram(words,2)","65ba5ec4":"top_ngram(words,3)","daf2b901":"doc=nlp(\" \".join([j for i in train['Review'].str.split() for j in i]))","535cdfef":"all_ent=[(x.text,x.label_) for x in doc.ents]","7560e2bb":"cat_ents=pd.DataFrame()\ncat_ents['cat_ent']=[j for i ,j in all_ent]\ncat_ents['txt']=[i for i ,j in all_ent]","4f38538a":"plt.figure(figsize=(8,8))\nsns.countplot(y=cat_ents['cat_ent'],order=cat_ents['cat_ent'].value_counts().index);","72ae7a96":"clr=[]\nfor name, hex in matplotlib.colors.cnames.items():\n  if 'dark' in name:\n    clr.append(name)","4e9a50d9":"fig=plt.subplots(figsize=(15, 15))\nfor i,(col,clrs)  in enumerate(zip(cat_ents['cat_ent'].value_counts().nlargest(10).index.values\n                                   ,clr[9:19])):    \n       _=plt.subplot(5,2,i+1)\n       df=(cat_ents[cat_ents['cat_ent']==col].groupby(['txt'])['txt'].agg({'count'}).\n           reset_index().sort_values('count',ascending=False)[:10])\n       df=df.sort_values('count')\n       _=plt.barh(df['txt'],df['count'],color=clrs)\n       _=plt.title(f\"Top '{col}' Named-Entity\",fontsize=15)\n       _=plt.ylabel(\"\")\n       _=plt.yticks(fontsize=12)\n       _=plt.tight_layout()  \nplt.show()  ","80240afe":"pos=nltk.pos_tag(word_tokenize(\" \".join([j for i in train['Review'].str.split() for j in i])))","c5a12c9c":"pos_tag=pd.DataFrame()\npos_tag['tag']=[j for i ,j in pos]\npos_tag['txt']=[i for i ,j in pos]","0b43cc6c":"plt.figure(figsize=(12,12))\nsns.countplot(y=pos_tag['tag'],order=pos_tag['tag'].value_counts().index);","b54756f8":"fig=plt.subplots(figsize=(15, 15))\nfor i,(col,clrs)  in enumerate(zip(pos_tag['tag'].value_counts().nlargest(10).index.values\n                                   ,clr[6:16])):    \n       _=plt.subplot(5,2,i+1)\n       df=(pos_tag[pos_tag['tag']==col].groupby(['txt'])['txt'].agg({'count'}).\n           reset_index().sort_values('count',ascending=False)[:10])\n       df=df.sort_values('count')\n       _=plt.barh(df['txt'],df['count'],color=clrs)\n       _=plt.title(f\"Most Common '{col}'\",fontsize=15)\n       _=plt.ylabel(\"\")\n       _=plt.yticks(fontsize=12)\n       _=plt.tight_layout()  \nplt.show()  ","41081868":"train[train['Review'].str.lower().str.contains(\"(https:?\\\/\\\/[www]?.+)\")]['Review']","9cb4661d":"train[train['Review'].str.contains(\"(\\d+)\")]['Review'][6123]","8f1845fb":"def digits(text):\n    res=text.str.lower().str.extract(\"(\\d+|\\d+\\.\\d+)\")\n    return res.dropna().value_counts().nlargest(10), res.dropna().value_counts().nlargest(10).sort_values(ascending=True).plot(kind='barh',figsize=(15,10))","737d1252":"digits(train['Review'])","431f8993":"def mixed_contraction(text):\n    res=text.str.lower().str.extract(\"([a-zA-Z]+'[a-zA-Z]+)\")\n    return res.dropna().value_counts().nlargest(10), res.dropna().value_counts().nlargest(10).sort_values(ascending=True).plot(kind='barh',figsize=(15,10))","053d9390":"mixed_contraction(train['Review'])","bfc45cae":"def non_ascii(text):\n    res=text.str.lower().str.extract(\"([^\\x00-\\x7F]+)\")\n    return res.dropna().value_counts().nlargest(20), res.dropna().value_counts().nlargest(10).sort_values(ascending=True).plot(kind='barh',figsize=(15,10))\n","5d2cf46a":"non_ascii(train['Review'])","85f5b042":"def currency(text):\n    res=text.str.lower().str.extract(\"([$\u00a2\u00a3\u00a4\u00a5\u058f\u060b\u09f2\u09f3\u09fb\u0af1\u0bf9\u0e3f\u17db\\u20a0-\\u20bd\\ua838\\ufdfc\\ufe69\\uff04\\uffe0\\uffe1\\uffe5\\uffe6])\")\n    return res.dropna().value_counts().nlargest(10), res.dropna().value_counts().nlargest(10).sort_values(ascending=True).plot(kind='barh',figsize=(8,5))\n","abdfb2b9":"currency(train['Review'])","100da92d":"def remove_stopwords(x:str):\n    lst = [i for i in x.split(\" \") if i not in stopwords]\n    final = ' '.join(lst)\n    return final","f160c49e":"def lemmati(x:str):\n    lst = [lemmatizer.lemmatize(i) for i in x.split(\" \")]\n    final=\" \".join(lst)\n    return final\n","3a34a38a":"def stem(x:str):\n    lst = [porter.stem(i) for i in x.split(\" \")]\n    final=\" \".join(lst)\n    return final","44cc0f34":"train['Review'][100]","9e0d9b14":"stem(\"\"\"Cushions holding up well after a month of use. Color and size is accurate.\n Seller provides great customer service with quick communication and follow up.\"\"\")","cbb599ea":"lemmati(\"\"\"Cushions holding up well after a month of use. Color and size is accurate.\n Seller provides great customer service with quick communication and follow up.\"\"\")","6ca23e07":"def text_pre_process(strings):\n    txt=strings.lower()  # convert text to lowercse\n    txt=re.sub('(https:?\\\/\\\/[www]?.+)','',txt) # remove url\n    txt=unidecode.unidecode(txt) # diacritics remove\n    txt=contractions.fix(txt) # contraction fix\n    txt=re.sub('(\\d+)',' ',txt) # remove numbers\n    txt=re.sub('[^\\w\\s]',' ',txt) # remove punctuations\n    txt=remove_stopwords(txt)\n    txt=lemmati(txt)\n    return txt\n","76b755d0":"#### The above inforamtion shows that cardinal, date, org are top named enity information category.","c144d13f":"### Most used mixed (Formal,Informal) Contractions.","83b1854a":"### Let's see most used words other than stopwrods.","d10f93dd":"#### Build a machine learning model to bucket the customer's future reviews under the respective topic category.","8548ef9e":"### Let's view the sample data from train and test dataset","3bda2b22":"#### The above histogram explains that the average length of the character in review is 161.\n\n#### The review character's length range from 16 to 1987.","019ccb4c":"### The dataset have more than one target label.So basically a  multioutput classification problem.Let's see how review's are claasified under each topics. ","815672d1":"### About","b63bde5a":"### Let's see how average number of words in each review differed across the different target label groups.","407e3773":"#### The above histogram explains that the average words used in each review is 4.\n\n#### The average word in review are ranging from 2 to 11.","c92acf80":"#### The above histogram explains that the average number of words used in the review is 30.\n\n#### The number of words in reviews are ranging from 2 to 374.","8bf04ef7":"### Import Necessary Libraries","88ce4909":"### Let's check if there is any missing value in train and test dataset.","b5f52023":"### Let's see the structure of train and test dataset.","785cbba3":"#### Let's see what are the words classified under the top pos tag category. ","eb42072e":"### Let's extract the named entity informations in review and classify them in pre-defined categories.","8dc8ecc8":"### Let's see is there numbers used in review.","e37c61ec":"### Let's see is there any currency symbol in review.","a7fa1df8":"### Load train and test dataset","40675dec":"#### The above chart explains that **(easy,to)** is most used bi-gram word in reviews.","27a69a6e":"#### Let's create a wordcloud and see most frequent words in three classes.","f3c88e50":"#### Let'see most used stopwords in review.","14767f80":"#### For better visualization let's first 6 target label reviews.","cc09523f":"#### The above chart explains that the mean of the number of average words in each review is almost the same in all target groups.","2eb81bd8":"### Let's classify the words into parts of speech.  ","ea85e047":"### Let's perform exploratory data analysis.First, let see the target columns distribution.","8158013e":"### Let's see the number of characters in reviews.","39ba9258":"### Let's see top Tri-gram in review.","2adcf672":"### Let's see is there any url link used in reviews.","41a76c68":"### Let's see is there any diacritics in review.","559db6f4":"### Let's use nltk pos_tagger function and classify the words.","204262d8":"#### The above chart shows that most words in the review are tagged under nouns, determiners, prepositions, or conjunctions.","89610da6":"#### The train dataset contains 6136 data entries and 14 columns.\n#### The target column is **Sentiment**.","bdae9ec8":"### Let's see how number of words in each review  differed across the different target label groups.","2ff2c1f2":"### Let's see top used POS tag.","d8273326":"### Let's see average words in each review.","4ccff8be":"### Let's create a dataframe to collect target label group level number of characters, number of words, number of average words in the review. ","22872cdd":"#### There are two reviews that contains url link.","2d12df05":"#### The above chart explains that **(easy to use)** is most used tri-gram in reviews.","b53993e9":"#### The above summary shows that there is no missing in any column.","a111a71b":"### Let's see top Bi-gram in review.","542af269":"### Tokenize the review and then use the english pipe line to extract the named entity informations. ","9536b6ef":"### Let's see how character length in each review differed across the different target label groups.","66d0454a":"#### The above barplot explains that **...** symbol is most used in the reviews.\n\n#### **Note:The result based on raw text**","a3368d4a":"### Let's see how reviews are classified under each topics ","1d706a7d":"#### The above plot explains that there is an imbalance in all target class distributions.","91e3d235":"#### The test dataset contains 2631 entries and 14 columns.","9ad35859":"### Let's see top named entity information category.","6c52ce4d":"### Store entities and text in dataframe.","4d2fb67a":"#### The above barplot explains that **the** is most used stopword in review.","6c7a4243":"### Let's see what are the tokens classified under top 10 named entity category.","0e65313f":"### Let's see the number of words in review."}}