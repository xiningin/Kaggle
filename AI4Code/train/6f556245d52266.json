{"cell_type":{"e4ef2b16":"code","e59aee02":"code","f006f39d":"code","1a310332":"code","de260987":"code","e08ee343":"code","37b9f2a1":"code","8be9a50c":"code","79ec6d81":"code","584330ca":"code","2bc4d764":"code","a2f4ad0a":"code","c703f6b4":"code","0f74ceb1":"code","12df306e":"code","af111dee":"code","b6ce4945":"code","0ff1a44a":"code","07f4d832":"code","6c48ce12":"code","123dabee":"code","ebc46293":"code","4c60a67a":"code","1cccfc5f":"code","68adf940":"code","afe5de01":"code","1a90c381":"code","351f324b":"code","860aecf4":"code","83766852":"code","1113fd5a":"code","c86f82a2":"code","86831ca4":"code","7db8e382":"code","384e3aae":"markdown","0d8518d4":"markdown","c69888ea":"markdown","379b9f51":"markdown","19df38c0":"markdown","3c4211f4":"markdown","cbb5fc66":"markdown","bd85bbdb":"markdown","d27f20e2":"markdown","28ddd38f":"markdown","28597076":"markdown"},"source":{"e4ef2b16":"import datetime\nimport tensorflow as tf\nimport keras\nimport itertools\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import class_weight\nimport tensorflow_addons as tfa\nfrom sklearn.model_selection import StratifiedKFold\nfrom imblearn.combine import SMOTEENN\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.pipeline import Pipeline\nfrom sklearn.metrics import mean_absolute_error as mae\nimport random\nimport math\nfrom sklearn.metrics import accuracy_score\nfrom hyperopt import STATUS_OK, Trials, fmin, hp, tpe\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport seaborn as sns\nfrom sklearn import preprocessing\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\nfrom sklearn import linear_model, tree, ensemble\nfrom xgboost import plot_importance\nimport optuna\n\ndef sigmoid(x):\n    return 1 \/ (1 + math.exp(-x))","e59aee02":"df=pd.read_csv('..\/input\/home-data-for-ml-course\/train.csv')\ntest=pd.read_csv('..\/input\/home-data-for-ml-course\/test.csv')\nx=test.drop('Id', axis=1)\ndf=df.drop('Id', axis=1)\ndf=df.sample(frac=1)\nX=df.drop('SalePrice', axis=1)\ny=df.SalePrice\nobject_columns = X.select_dtypes(include=['object']).columns\nnumeric_columns = X.select_dtypes(exclude=['object']).columns\ntotal_X=pd.concat([X,x], ignore_index=True)\ntotal_X.reset_index()\ndf.info()","f006f39d":"object_columns","1a310332":"numeric_columns","de260987":"import missingno as msno\n\nmsno.bar(df[numeric_columns])\nplt.show()","e08ee343":"total_X[object_columns].isnull().sum()","37b9f2a1":"total_X[numeric_columns].isnull().sum()","8be9a50c":"for i in object_columns:\n    if(total_X[i].isnull().sum()<=50 & total_X[i].isnull().sum()>0):\n        total_X[i]=total_X[i].fillna(total_X[i].mode()[0], inplace = True)\ntotal_X[object_columns]=total_X[object_columns].fillna('NA')","79ec6d81":"for i in numeric_columns:\n    if(total_X[i].isnull().sum()<50 & total_X[i].isnull().sum()>0):\n        total_X[i]=total_X[i].fillna(total_X[i].mean())\ntotal_X['LotFrontage']=total_X['LotFrontage'].fillna(0)     \n#missing values for garage yr built indicates that garage is not made yet","584330ca":"fig=px.scatter(df,\n                 x=\"GarageYrBlt\", y=\"SalePrice\",\n                 log_x=True, size_max=20,\n                 template='plotly', title=\"How saleprice varies with year garage was built?\",opacity=1)\nfig.show()  ","2bc4d764":"total_X['GarageYrBlt']=total_X['GarageYrBlt'].fillna(total_X['GarageYrBlt'].min())","a2f4ad0a":"X=total_X.iloc[:len(y),:]\nX['SalePrice']=y","c703f6b4":"fig, ax=plt.subplots(figsize=(15,5))\nsns.histplot(df['SalePrice'],kde=True)\nax.set_title('How is SalePrice distributed')\nplt.show()","0f74ceb1":"sns.catplot(x = 'HouseStyle', y = 'SalePrice', data = df, kind = 'bar', hue='RoofStyle', height=10, aspect=2)","12df306e":"fig=px.scatter(df,\n                 x=\"LotArea\", y=\"SalePrice\",\n                 log_x=True, size_max=20,\n                 template='plotly', title=\"How saleprice varies with LotArea?\",opacity=0.7, color='YrSold')\nfig.show()  ","af111dee":"sns.catplot(x = 'YrSold', y = 'SalePrice', data = df, kind = 'bar', hue='SaleType', height=10, aspect=2)","b6ce4945":"sns.barplot(x='CentralAir', y='SalePrice', data=df);","0ff1a44a":"sns.kdeplot(x=X['YrSold'], shade=True)","07f4d832":"corrmatrix=df.corr()\nfig, ax=plt.subplots(figsize=(30,30))\nsns.heatmap(corrmatrix, vmax=8, square=True, annot=True, fmt='.2f')\nplt.show()","6c48ce12":"plt.figure(figsize=(28,50))\nc=1\nfor i in numeric_columns:\n    plt.subplot(7, 6, c)\n    #sns.scatterplot(data=X, x=i, y=\"SalePrice\", hue=\"CentralAir\", fit_reg=True)\n    sns.regplot(x=i, y=\"SalePrice\", data=df)\n    plt.title(str(i)+\" Vs SalePrice\")\n    c+=1\nplt.subplots_adjust(wspace=0.3, hspace=-0.1)\nplt.show()    ","123dabee":"#how much is the age of house can be a good feature\ntotal_X['---**---Age']=total_X['YrSold']-total_X['YearBuilt']\ntotal_X['---**---Garage_Age']=total_X['YrSold']-total_X['GarageYrBlt']\ntotal_X['---**---Age_se']=total_X['YrSold']-total_X['YearRemodAdd']\ntotal_X['---**---full_bath_per_bedroom']=total_X['FullBath']\/(total_X['BedroomAbvGr'])\ntotal_X['---**---half_bath_per_bedroom']=total_X['HalfBath']\/(total_X['BedroomAbvGr'])\ntotal_X['---**---garage_per_bedroom']=total_X['GarageCars']\/(total_X['BedroomAbvGr'])\ntotal_X['---**---kitchen_per_bedroom']=total_X['KitchenAbvGr']\/(total_X['BedroomAbvGr'])\ntotal_X['---**---full_bath_per_bedroom']= total_X['---**---full_bath_per_bedroom'].apply(lambda x: sigmoid(x))\ntotal_X['---**---half_bath_per_bedroom']=total_X['---**---half_bath_per_bedroom'].apply(lambda x: sigmoid(x))\ntotal_X['---**---garage_per_bedroom']=total_X['---**---garage_per_bedroom'].apply(lambda x: sigmoid(x))\ntotal_X['---**---kitchen_per_bedroom']=total_X['---**---kitchen_per_bedroom'].apply(lambda x: sigmoid(x))","ebc46293":"%%capture\ndummies = pd.get_dummies(total_X[object_columns])\ntotal_X=total_X.drop(object_columns, axis=1)\ntotal_X = pd.concat([total_X, dummies], axis=1, join='inner')\nfor col in numeric_columns:\n    percentiles = total_X[col].quantile([0.05, 0.95]).values\n    total_X[col][total_X[col] <= percentiles[0]] = percentiles[0]\n    total_X[col][total_X[col] >= percentiles[1]] = percentiles[1]\ntotal_X=total_X.drop('MoSold', axis=1)","4c60a67a":"X=total_X.iloc[:len(y),:]\nx=total_X.iloc[len(y):,:]","1cccfc5f":"kf =KFold(n_splits=5, shuffle=True, random_state=42)\ncnt = 1\nfor train_index, test_index in kf.split(X, y):\n    print(f'Fold:{cnt}, Train set: {len(train_index)}, Test set:{len(test_index)}')\n    cnt += 1","68adf940":"X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.1)\nimport xgboost as xgb\nfrom xgboost import XGBRegressor, XGBClassifier","afe5de01":"xgb_m = XGBRegressor(n_estimators=1000, random_state=0, tree_method='gpu_hist', gpu_id=0)\nxgb_m.fit(X_train,y_train)\npreds=xgb_m.predict(X_validation)\nr=mae(y_validation, preds)\nprint(r)","1a90c381":"fig, ax=plt.subplots(figsize=(20,60))\nplot_importance(xgb_m,ax=ax)\nplt.show()","351f324b":"def objective(trial,data=X,target=y):\n    \n    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.1,random_state=42)\n    param = {\n        'tree_method':'gpu_hist',  # this parameter means using the GPU when training our model to speedup the training process\n        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n        'learning_rate': trial.suggest_categorical('learning_rate', [0.008,0.009,0.01,0.012,0.014,0.016,0.018, 0.02]),\n        'max_depth': trial.suggest_categorical('max_depth', [5,7,9,11,13,15,17,20]),\n        'random_state': trial.suggest_categorical('random_state', [24, 48,2020]),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n        'n_estimators': trial.suggest_categorical('n_estimators',[3200,3400,3500,3600,3800,3900])\n    }\n    model = XGBRegressor(**param)  \n    \n    model.fit(train_x,train_y,eval_set=[(test_x,test_y)],early_stopping_rounds=100,verbose=False)\n    \n    preds = model.predict(test_x)\n    \n    rmse = mae(test_y, preds)\n    \n    return rmse","860aecf4":"study = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=100)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)","83766852":"def checking(X,y,params_fi):\n    xgb_m = XGBRegressor(**params_fi, tree_method='gpu_hist', gpu_id=0)\n    r = -1*cross_val_score(xgb_m, X, y, cv= kf, scoring=\"neg_mean_absolute_error\")\n    r=r.mean()\n    print(\"The model gives Mae loss of \"+str(r))          \n    return xgb_m  ","1113fd5a":"params_fi=study.best_trial.params\nxt=checking(X,y,params_fi)","c86f82a2":"xt.fit(X,y)","86831ca4":"fig, ax=plt.subplots(figsize=(20,60))\nplot_importance(xt,ax=ax)\nplt.show()","7db8e382":"t_df=pd.read_csv('..\/input\/home-data-for-ml-course\/sample_submission.csv')\npreds=xt.predict(x)\nt_df['SalePrice']=preds\nimport gzip\nt_df.to_csv('sub.gz', index=False, compression='gzip')\nt_df.head(10)","384e3aae":"# Importing of Dataset","0d8518d4":"# IF you like this notebook then please give an upvote \ud83d\udc4d\n**and also give suggestions in comment \ud83d\ude4c**","c69888ea":"# encoding categorical features","379b9f51":"# Lets visualize relations in details","19df38c0":"# Feature Generation","3c4211f4":"# Handling of Missing Values for Categorical Features","cbb5fc66":"**we can see garage yr built has some missing values and in object features there are missing of garage details which means garage is not built yet**","bd85bbdb":"# Handling of Missing values of numerical Features","d27f20e2":"**It is clear that SalePrice is dependent on GarageYrBlt so we take min yr as it is not built so...**","28ddd38f":"# Tuning hyperparams","28597076":"# IF you like this notebook then please give an upvote \ud83d\udc4d\n**and also give suggestions in comment \ud83d\ude4c**"}}