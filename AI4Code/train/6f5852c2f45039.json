{"cell_type":{"a54b14ec":"code","d2e3d7bc":"code","55f0740c":"code","6a7846df":"code","f98613f6":"code","63e84798":"code","7f495d6f":"code","5c614ed1":"code","9a4db3ba":"code","81639027":"code","df6dc0a7":"code","5b0bcf80":"code","b30b01eb":"code","8fdb1dd6":"code","6e1dd403":"code","239d786c":"code","ef962566":"code","ebeafe89":"code","e9f0d403":"code","b058a9b4":"code","d973073b":"code","de2e27df":"code","fc60673f":"code","ca778549":"code","f481153f":"code","6a75cc1d":"code","ba3df256":"code","c45a8e5d":"code","99aac89d":"code","534b4e8a":"markdown","186a6ccd":"markdown","9ed18202":"markdown","076681b8":"markdown","546fb6c9":"markdown"},"source":{"a54b14ec":"!pip install ..\/input\/pretrainedmodels\/pretrainedmodels-0.7.4\/pretrainedmodels-0.7.4\/ > \/dev\/null # no output\npackage_path = '..\/input\/unetmodelscript' # add unet script dataset\nimport sys\nsys.path.append(package_path)\nfrom model import Unet # import Unet model from the script","d2e3d7bc":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport cv2\nfrom tqdm.notebook import tqdm_notebook as tqdm\nimport seaborn as sns\nimport albumentations  as albu\nfrom albumentations.pytorch import ToTensor\nimport random\n\nimport torch\nimport torch.backends.cudnn as cudnn\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import optim\nimport torchvision\nfrom torchvision import models\nfrom torch.autograd import Function","55f0740c":"# \u4e71\u6570\u306e\u30b7\u30fc\u30c9\u3092\u8a2d\u5b9a\nseed = 1234\nrandom.seed(seed)\ntorch.manual_seed(seed)\nnp.random.seed(seed)","6a7846df":"input_dir = \"..\/input\/severstal-steel-defect-detection\/\"\ninput_dir_Train  = os.path.join(input_dir, 'train_images')\ninput_dir_Test  = os.path.join(input_dir, 'test_images')\nfilelist_Train = os.listdir(input_dir_Train)\nfilelist_Test = os.listdir(input_dir_Test)","f98613f6":"image = cv2.imread(os.path.join(input_dir_Test, filelist_Test[0]))\nplt.imshow(image)\nplt.xticks([])\nplt.yticks([])\nplt.savefig('image.jpg')\nplt.show()","63e84798":"df_path = os.path.join(input_dir, 'train.csv')\ndf = pd.read_csv(df_path)\ndf.head()","7f495d6f":"def make_df(df):\n    df = df.pivot(index='ImageId',columns='ClassId',values='EncodedPixels')\n    df['defects'] = df.count(axis=1)\n    train_df, val_df = train_test_split(df, test_size=0.2, stratify=df[\"defects\"], random_state=seed)\n    return train_df, val_df","5c614ed1":"train_df, val_df = make_df(df)","9a4db3ba":"test_df_path = os.path.join(input_dir, 'sample_submission.csv')\ntest_df = pd.read_csv(test_df_path)\ntest_df.head()","81639027":"mean = (0.485, 0.456, 0.406)\nstd = (0.229, 0.224, 0.225)\ndef get_augmentation(mean, std, phase):\n    \n    if phase == 'train':\n        transform = [\n            albu.HorizontalFlip(p=0.5),\n            albu.VerticalFlip(p=0.5),\n            albu.Resize(256, 256, interpolation=cv2.INTER_NEAREST, p=1),\n            albu.Normalize(mean=mean, std=std, p=1),\n            ToTensor(),\n        ]\n    else:\n        transform = [\n            albu.Resize(256, 256, interpolation=cv2.INTER_NEAREST, p=1),\n            albu.Normalize(mean=mean, std=std, p=1),\n            ToTensor(),\n        ]\n    \n    return albu.Compose(transform)","df6dc0a7":"def make_mask(index, df):\n    filename = df.iloc[index].name\n    labels = df.iloc[index, :4]\n    masks = np.zeros((256, 1600, 4), dtype=np.float32)\n    for idx, label in enumerate(labels):\n        if label is not np.nan:\n            mask = np.zeros((256*1600), dtype=np.uint8)\n            pixels = label.split(' ')\n            pixels = [pixels[i:i+2] for i in range(0, len(pixels), 2)]\n            for pixel in pixels:\n                pos, le = pixel\n                pos, le = int(pos), int(le)\n                mask[pos-1:pos+le-1] = 1\n            masks[:,:,idx] = mask.reshape(256, 1600, order = 'F')\n    return filename, masks","5b0bcf80":"class ValDataset(torch.utils.data.Dataset):\n    def __init__(self, df, input_dir, phase):\n        self.df = df\n        self.input_dir = input_dir\n        self.transforms = get_augmentation(mean, std, phase) \n        self.phase = phase\n    def __getitem__(self, idx):\n        filename, mask = make_mask(idx, self.df)\n        image = cv2.imread(os.path.join(self.input_dir, filename))\n        augmented = self.transforms(image=image, mask=mask)\n        image, mask = augmented['image'], augmented['mask']\n        mask = mask[0].permute(2, 0, 1)\n        return image, mask\n    def __len__(self):\n        return len(self.df)","b30b01eb":"class TestDataset(torch.utils.data.Dataset):\n    def __init__(self, input_dir, df, phase):\n        self.input_dir = input_dir\n        self.fnames = df['ImageId'].unique().tolist()\n        self.transforms = get_augmentation(mean, std, phase)\n        self.phase = phase\n    def __getitem__(self, idx):\n        fname = self.fnames[idx]\n        image = cv2.imread(os.path.join(self.input_dir, fname))\n        augmented = self.transforms(image=image)\n        image = augmented['image']\n        return fname, image\n    def __len__(self):\n        return len(self.fnames)","8fdb1dd6":"val_dataset = ValDataset(val_df, input_dir_Train, phase = 'val')\n\n# \u52d5\u4f5c\u78ba\u8a8d\nindex = 0\nimage, mask = val_dataset.__getitem__(index) \nprint(image.size())\nplt.imshow(image.to('cpu').detach().numpy().copy()[0])\nplt.show()\nprint(mask.size())\nplt.imshow(mask.to('cpu').detach().numpy().copy()[2])\nplt.show()","6e1dd403":"test_dataset = TestDataset(input_dir_Test, test_df, phase = 'test')\n\n# \u52d5\u4f5c\u78ba\u8a8d\nindex = 0\nfname, image = test_dataset.__getitem__(index) \nprint('filename : {}'.format(fname))\nprint(image.size())\nplt.imshow(image.to('cpu').detach().numpy().copy()[0])\nplt.show()","239d786c":"batch_size = 4\n\nval_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=6)\ntest_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=6, pin_memory=True)\n\n# \u52d5\u4f5c\u78ba\u8a8d\nbatch_iterator = iter(test_dataloader)  # \u30a4\u30c6\u30ec\u30fc\u30bf\u306b\u5909\u63db\nfname, inputs = next(\n    batch_iterator)  # 1\u756a\u76ee\u306e\u8981\u7d20\u3092\u53d6\u308a\u51fa\u3059\nprint(inputs.size())","ef962566":"resnet18 = Unet(\"resnet18\", encoder_weights=\"imagenet\", classes=4, activation=None)\nresnet34 = Unet(\"resnet34\", encoder_weights=\"imagenet\", classes=4, activation=None)\nresnet50 = Unet(\"resnet50\", encoder_weights=\"imagenet\", classes=4, activation=None)\n\nresnet18.load_state_dict(torch.load(\"..\/input\/resnet-weights\/resnet18_CP18.pth\"))\nresnet34.load_state_dict(torch.load(\"..\/input\/resnet-weights\/resnet34_CP19.pth\"))\nresnet50.load_state_dict(torch.load(\"..\/input\/resnet-weights\/resnet50_CP16.pth\"))\n\nprint('\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u8a2d\u5b9a\u5b8c\u4e86\uff1a\u5b66\u7fd2\u6e08\u307f\u306e\u91cd\u307f\u3092\u30ed\u30fc\u30c9\u3057\u307e\u3057\u305f')","ebeafe89":"def dice_coeff(pred, mask):\n    with torch.no_grad():\n        batch_size = len(pred)\n        pred = pred.view(batch_size, -1) # Flatten\n        mask = mask.view(batch_size, -1)  # Flatten\n        pred = (pred>0.5).float()\n        mask = (mask>0.5).float()\n        smooth = 0.0001\n        intersection = (pred * mask).sum()\n        dice_pos = (2. * intersection + smooth) \/ (pred.sum() + mask.sum() + smooth) \n        intersection = ((pred + mask) == 0).sum()\n        dice_neg = (2. * intersection + smooth) \/ ((pred == 0).sum() + (mask == 0).sum() + smooth)\n        dice = (dice_pos + dice_neg) \/ 2.0\n        return dice.item()","e9f0d403":"# Validate one model\ndef validate(model, dataloader):\n    # \u521d\u671f\u8a2d\u5b9a\n    # GPU\u304c\u4f7f\u3048\u308b\u304b\u3092\u78ba\u8a8d\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    print(\"\u4f7f\u7528\u30c7\u30d0\u30a4\u30b9\uff1a\", device)\n\n    # \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092GPU\u3078\n    model = model.to(device)\n\n    # \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u304c\u3042\u308b\u7a0b\u5ea6\u56fa\u5b9a\u3067\u3042\u308c\u3070\u3001\u9ad8\u901f\u5316\u3055\u305b\u308b\n    torch.backends.cudnn.benchmark = True\n    \n    num_val_imgs = len(val_dataloader.dataset)\n    batch_size = val_dataloader.batch_size\n    \n    epoch_acc = 0.0\n    with torch.no_grad():\n        for img, mask in tqdm(val_dataloader):\n            \n            model.eval()\n            \n            # GPU\u304c\u4f7f\u3048\u308b\u306a\u3089GPU\u306b\u30c7\u30fc\u30bf\u3092\u9001\u308b\n            img = img.to(device)\n            mask = mask.to(device)\n\n            output = model(img)\n                \n            prob = torch.sigmoid(output)\n            prob = prob.to('cpu').detach()\n            mask = mask.to('cpu').detach()\n            \n            # \u30c0\u30a4\u30b9\u4fc2\u6570\u306e\u5408\u8a08\u3092\u66f4\u65b0\n            epoch_acc += dice_coeff(prob, mask)\n    print('Accuracy : {}'.format(epoch_acc \/ num_val_imgs * batch_size))\n        ","b058a9b4":"# Validate ensumble model\ndef validate_ensumble(model1, model2, model3, val_dataloader):\n    # \u521d\u671f\u8a2d\u5b9a\n    # GPU\u304c\u4f7f\u3048\u308b\u304b\u3092\u78ba\u8a8d\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    print(\"\u4f7f\u7528\u30c7\u30d0\u30a4\u30b9\uff1a\", device)\n\n    # \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092GPU\u3078\n    model1 = model1.to(device)\n    model2 = model2.to(device)\n    model3 = model3.to(device)\n\n    # \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u304c\u3042\u308b\u7a0b\u5ea6\u56fa\u5b9a\u3067\u3042\u308c\u3070\u3001\u9ad8\u901f\u5316\u3055\u305b\u308b\n    torch.backends.cudnn.benchmark = True\n    \n    num_val_imgs = len(val_dataloader.dataset)\n    batch_size = val_dataloader.batch_size\n    \n    epoch_acc = 0.0\n    with torch.no_grad():\n        for img, mask in tqdm(val_dataloader):\n            \n            model1.eval()\n            model2.eval()\n            model3.eval()\n            \n            # GPU\u304c\u4f7f\u3048\u308b\u306a\u3089GPU\u306b\u30c7\u30fc\u30bf\u3092\u9001\u308b\n            img = img.to(device)\n            mask = mask.to(device)\n\n            output1 = model1(img)\n            output2 = model2(img)\n            output3 = model3(img)\n            \n            prob1 = torch.sigmoid(output1)\n            prob2 = torch.sigmoid(output2)\n            prob3 = torch.sigmoid(output3)\n            \n            prob = (prob1 + prob2 + prob3) \/ 3.0\n            \n            prob = prob.to('cpu').detach()\n            mask = mask.to('cpu').detach()\n            \n            # \u30c0\u30a4\u30b9\u4fc2\u6570\u306e\u5408\u8a08\u3092\u66f4\u65b0\n            epoch_acc += dice_coeff(prob, mask)\n    print('Accuracy : {}'.format(epoch_acc \/ num_val_imgs * batch_size))\n        ","d973073b":"# Resnet18 Validation\nvalidate(resnet18, val_dataloader)","de2e27df":"# Resnet34 Validation\nvalidate(resnet34, val_dataloader)","fc60673f":"# Resnet50 Validation\nvalidate(resnet50, val_dataloader)","ca778549":"# Resnet Ensumble Validation\nvalidate_ensumble(resnet18, resnet34, resnet50, val_dataloader)","f481153f":"# Show and Save predicted image\ndef predict_show(index, test_dataloader, model, spath=None):\n    \n    # \u521d\u671f\u8a2d\u5b9a\n    # GPU\u304c\u4f7f\u3048\u308b\u304b\u3092\u78ba\u8a8d\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    print(\"\u4f7f\u7528\u30c7\u30d0\u30a4\u30b9\uff1a\", device)\n\n    # \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092GPU\u3078\n    model = model.to(device)\n\n    # \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u304c\u3042\u308b\u7a0b\u5ea6\u56fa\u5b9a\u3067\u3042\u308c\u3070\u3001\u9ad8\u901f\u5316\u3055\u305b\u308b\n    torch.backends.cudnn.benchmark = True\n    \n    with torch.no_grad():\n        \n        model.eval()\n        \n        fname, img = test_dataloader.dataset.__getitem__(index)\n        \n        img = img.unsqueeze(0)\n        \n        # GPU\u304c\u4f7f\u3048\u308b\u306a\u3089GPU\u306b\u30c7\u30fc\u30bf\u3092\u9001\u308b\n        img = img.to(device)\n            \n        output = model(img)\n            \n        prob = torch.sigmoid(output)\n        prob = (prob>0.5).float()\n            \n        img = img.to('cpu').detach().numpy().copy()[0,0]\n        prob = prob.to('cpu').detach().numpy().copy()[0,2]\n            \n        print(\"\u5143\u753b\u50cf\")\n        print(\"filename : {}\".format(fname))\n        plt.imshow(cv2.resize(img, (1600, 256), interpolation=cv2.INTER_NEAREST))\n        plt.xticks([])\n        plt.yticks([])\n        plt.show()\n        print(\"\u4e88\u6e2c\u753b\u50cf\")\n        plt.imshow(cv2.resize(prob, (1600, 256), interpolation=cv2.INTER_NEAREST))\n        plt.xticks([])\n        plt.yticks([])\n        if spath is not None:\n            save_path = os.path.join(spath, '{}_pred.jpg'.format(fname[:-4]))\n            plt.savefig(save_path)\n        plt.show()","6a75cc1d":"save_path  = \".\/predicts\"\n\nif os.path.exists(save_path) == False:\n    os.makedirs(save_path)\n\nindex = 0\npredict_show(index, test_dataloader, resnet34, save_path)","ba3df256":"def mask2rle(img):\n    \n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    \n    return ' '.join(str(x) for x in runs)","c45a8e5d":"def post_process(pred, min_size):\n    \n    mask = cv2.resize(pred, (1600, 256), interpolation=cv2.INTER_NEAREST)\n    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n    predictions = np.zeros((256, 1600), np.float32)\n    num = 0\n    for c in range(1, num_component):\n        p = (component == c)\n        if p.sum() > min_size:\n            predictions[p] = 1\n            num += 1\n    return predictions, num","99aac89d":"# \u521d\u671f\u8a2d\u5b9a\n# GPU\u304c\u4f7f\u3048\u308b\u304b\u3092\u78ba\u8a8d\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(\"\u4f7f\u7528\u30c7\u30d0\u30a4\u30b9\uff1a\", device)\n\n# \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092GPU\u3078\nmodel = resnet34.to(device)\n\n# \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u304c\u3042\u308b\u7a0b\u5ea6\u56fa\u5b9a\u3067\u3042\u308c\u3070\u3001\u9ad8\u901f\u5316\u3055\u305b\u308b\ntorch.backends.cudnn.benchmark = True    \n\nmin_size = 3500\n\npredictions = []\nfor i, batch in enumerate(tqdm(test_dataloader)):\n    fnames, images = batch\n    batch_preds = torch.sigmoid(model(images.to(device)))\n    batch_preds = (batch_preds>0.5).float()\n    batch_preds = batch_preds.detach().cpu().numpy()\n    for fname, preds in zip(fnames, batch_preds):\n        for cls, pred in enumerate(preds):\n            pred, num = post_process(pred, min_size)\n            rle = mask2rle(pred)\n            if rle != '':\n                predictions.append([fname, rle, cls+1])\n\n# save predictions to submission.csv\ndf = pd.DataFrame(predictions, columns=['ImageId', 'EncodedPixels', 'ClassId'])\ndf.to_csv(\"submission.csv\", index=False)","534b4e8a":"# \u63a8\u8ad6\u3092\u5b9f\u884c","186a6ccd":"# Data Augmentation","9ed18202":"# \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u7528\u610f","076681b8":"# Dataloader\u4f5c\u6210","546fb6c9":"# \u30c7\u30fc\u30bf\u8aad\u307f\u8fbc\u307f"}}