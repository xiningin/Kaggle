{"cell_type":{"f151919e":"code","2b1cce28":"code","b7714c20":"code","10bd8b56":"code","6f97e701":"code","16bb6c55":"code","ad04b352":"code","d41b1f9d":"code","d7a9051a":"code","8f9b1bcf":"code","3c7c338a":"code","f59782ff":"code","d946de5f":"code","31977180":"code","8e8ee953":"code","985fb628":"code","4ae487fe":"code","ffe5f104":"code","e6020f50":"code","3ef877d5":"code","733e49e9":"code","c8e506a6":"code","ccf3cf9a":"code","3844e0ad":"code","714fd96a":"code","d8bb2cb5":"code","fc2a9ae4":"code","99f6d68b":"code","de9dac84":"code","cdf342e6":"code","f7053c9f":"code","3cc89b32":"code","71d4681d":"code","186f9157":"code","9efccd13":"code","d2e30fbc":"code","10289994":"code","3fc6244c":"code","835376d2":"code","9f324de6":"code","9c4912dc":"code","b8bd09b8":"code","d919f0ab":"code","6ee51c30":"code","f2b209ce":"code","e90f17e9":"code","f5312920":"markdown","553e4077":"markdown","03efa5f9":"markdown","07483a53":"markdown","d158972d":"markdown","bcf3242c":"markdown","78ae077d":"markdown","d4c71b07":"markdown","e521d138":"markdown"},"source":{"f151919e":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport cv2\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nimport tensorflow as tf\nfrom keras.applications.densenet import DenseNet121, preprocess_input\nfrom keras.layers import Dense, Flatten, Input, Lambda\nfrom tensorflow import keras","2b1cce28":"data=pd.read_csv(\"\/content\/drive\/MyDrive\/Colab Notebooks\/MIAS-Classification\/Info.txt\",sep=\" \")\ndata","b7714c20":"data.SEVERITY.fillna(\"H\", inplace=True)\ndata.SEVERITY = data.SEVERITY.map({'H':0, 'B':1, 'M':2})","10bd8b56":"data.SEVERITY.unique()","6f97e701":"_ = [ 'BG', 'CLASS', 'X', 'Y', 'RADIUS', 'Unnamed: 7']\ndata = data.drop(_, axis = 1)\ndata.info()","16bb6c55":"data = data.drop([5], axis=0)\ndata.reset_index(inplace = True)\ndata = data.drop(\"index\",axis=1)\ndata","ad04b352":"ohe = OneHotEncoder()\nimg_labels = ohe.fit_transform(data.SEVERITY.values.reshape(-1, 1)).toarray()","d41b1f9d":"path = \"\/content\/drive\/MyDrive\/Colab Notebooks\/MIAS-Classification\/all-mias\/\"\nimg_paths = []\n# img_labels = []\n\nfor i in range(len(data)):\n  abs_path = path + data.REFNUM[i] + '.pgm'\n  img_paths.append(abs_path)\n  # img_labels.append(data.SEVERITY[i])","d7a9051a":"img_paths[0], img_labels[0]","8f9b1bcf":"image_numeric = []\nfor img in img_paths:\n  image = cv2.imread(img)\n  image = cv2.resize(image, (224,224)) # put `\/255` to normalize the colour scores\n  image_numeric.append(image)","3c7c338a":"image_numeric = np.array(image_numeric)\/255.0\nimg_labels = np.array(img_labels)","f59782ff":"image_numeric[0].shape","d946de5f":"img_labels.shape","31977180":"x_train, x_test, y_train, y_test = train_test_split(image_numeric, img_labels, test_size = 0.3, random_state = 42)","8e8ee953":"# y_train=y_train.reshape(-1,1)","985fb628":"print(x_train.shape) #, y_train.shape, x_test.shape, y_test.shape\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)","4ae487fe":"# x_train = x_train[..., np.newaxis]","ffe5f104":"x_train.shape","e6020f50":"%%time\nbase_model = DenseNet121(\n    weights='imagenet',\n    input_shape=(224, 224, 3),\n    include_top=False\n)\n\nbase_model.trainable = False\n\n# Create inputs with correct shape\ninputs = Input(shape = (224,224,3))\n\nx = base_model(inputs, training=False)\n# Add pooling layer or flatten layer\nx = keras.layers.GlobalAveragePooling2D()(x)\n\n\n# Add final dense layer\noutputs = Dense(3, activation = 'softmax')(x)\n\n# Combine inputs and outputs to create model\nmodel = keras.Model(inputs, outputs)\n\nmodel.compile(loss = keras.losses.CategoricalCrossentropy() , metrics = ['accuracy']) # compiles the model with the given parameters\n\nmodel.summary() # prints a summary of the model","3ef877d5":"%%time\nEPOCH = 25\nd_model = model.fit(x_train, y_train, epochs = EPOCH, validation_data = (x_test, y_test) )","733e49e9":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report","c8e506a6":"# loss\nfig, ax = plt.subplots()\nax.plot(d_model.history['loss'], label='loss')\nax.plot(d_model.history['val_loss'], label='val_loss')\nax.legend()\nplt.title('DenseNet121')\nplt.show()\nfig.savefig('\/content\/drive\/MyDrive\/Colab Notebooks\/MIAS-Classification\/DenseNet121Loss.png')","ccf3cf9a":"# accuracies\nfig, ax = plt.subplots()\nax.plot(d_model.history['accuracy'], label='acc')\nax.plot(d_model.history['val_accuracy'], label='val acc')\nax.legend()\nplt.title('DenseNet121')\nplt.show()\nfig.savefig('\/content\/drive\/MyDrive\/Colab Notebooks\/MIAS-Classification\/DenseNet121Accuracy.png')","3844e0ad":"model.save(\"\/content\/drive\/MyDrive\/Colab Notebooks\/MIAS-Classification\/Densenet121.h5\")","714fd96a":"y_preds =  model.predict(x_test)\ny_preds","d8bb2cb5":"y_preds_ind = np.argmax(y_preds,axis=1)\ny_preds_ind","fc2a9ae4":"qwe=np.argmax(y_test, axis=1)","99f6d68b":"confusion_matrix(qwe,y_preds_ind)","de9dac84":"print(classification_report(qwe,y_preds_ind))","cdf342e6":"model.evaluate(x_test,y_test)","f7053c9f":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc\n\nfpr, tpr, thresholds = roc_curve(qwe, y_preds_ind, pos_label=2)\n\nauc = auc(fpr, tpr)\n\nimport matplotlib.pyplot as plt\nplt.figure(1)\nplt.plot([0, 1], [0, 1],\"--\")\n\nplt.plot(fpr, tpr, label='RF (area = {:.3f})'.format(auc), color='orange')\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve')\nplt.legend(loc='best')\nplt.show()","3cc89b32":"def Visualize_Result(acc,val_acc,loss, val_loss):\n    fig, (ax1, ax2) = plt.subplots(nrows = 1,\n                                   ncols = 2,\n                                   figsize = (15,6))\n\n    plot1 = ax1.plot(range(0, len(acc)),\n                     acc,\n                     label = 'accuracy')\n\n    plot2 = ax1.plot(range(0, len(val_acc)),\n                     val_acc,\n                     label = 'val_accuracy')\n\n    ax1.set(title = 'Accuracy And Val Accuracy progress',\n            xlabel = 'epoch',\n            ylabel = 'accuracy\/ validation accuracy')\n\n    ax1.legend()\n\n    plot3 = ax2.plot(range(0, len(loss)),\n                     loss,\n                     label = 'loss')\n    \n    plot4 = ax2.plot(range(0, len(val_loss)),\n                     val_loss,\n                     label = 'val_loss')\n    \n    ax2.set(title = 'Loss And Val loss progress',\n            xlabel = 'epoch',\n            ylabel = 'loss\/ validation loss')\n\n    ax2.legend()\n\n    fig.suptitle('Result Of Model', fontsize = 20, fontweight = 'bold')\n    fig.savefig('\/content\/drive\/MyDrive\/Colab Notebooks\/MIAS-Classification\/Accuracy_Loss_figure.png')\n    plt.tight_layout()\n    plt.show()\n\nvisualize_result = Visualize_Result(d_model.history['accuracy'],d_model.history['val_accuracy'], d_model.history['loss'], d_model.history['val_loss'])\n","71d4681d":"from sklearn.metrics import classification_report, confusion_matrix\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping","186f9157":"#set early stopping criteria\npat = 5 #this is the number of epochs with no improvment after which the training will stop\nearly_stopping = EarlyStopping(monitor='val_loss', patience=pat, verbose=1)\n\n#define the model checkpoint callback -> this will keep on saving the model as a physical file\nmodel_checkpoint = ModelCheckpoint('\/content\/drive\/MyDrive\/Colab Notebooks\/MIAS-Classification\/Models\/h_mias.h5', verbose=1, save_best_only=True)\n\n#define a function to fit the model\ndef fit_and_evaluate(x_train, x_test, y_train, y_test, EPOCHS=20, BATCH_SIZE=32,model=model):\n    results = model.fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[early_stopping, model_checkpoint], \n                        verbose=1, validation_split=0.3)  \n    print(\"Val Score: \", model.evaluate(x_test,y_test))\n    return results","9efccd13":"n_folds=10\nepochs=20\nbatch_size=32\n\n#save the model history after fitting so that we can plot later\nmodel_history = [] \n\nfor i in range(n_folds):\n    print(\"Training on Fold: \",i+1)\n    x_train, x_test, y_train, y_test = train_test_split(image_numeric, img_labels, test_size = 0.3, \n                                               random_state = np.random.randint(1,1000, 1)[0])\n    model_history.append(fit_and_evaluate(x_train, x_test, y_train, y_test, epochs, batch_size))\n    print(\"=======\"*12, end=\"\\n\\n\\n\")","d2e30fbc":"plt.title('Accuracies vs Epochs')\nfor i in range(len(model_history)):\n  plt.plot(model_history[i].history['accuracy'], label=f\"Training Fold {i+1}\")\n\nplt.legend()\nplt.show()","10289994":"plt.figure(figsize=(8,6))\nplt.title('Train Accuracy vs Val Accuracy')\nplt.plot(model_history[0].history['accuracy'], label='Train Accuracy Fold 1', color='black')\nplt.plot(model_history[0].history['val_accuracy'], label='Val Accuracy Fold 1', color='black', linestyle = \"dashdot\")\nplt.plot(model_history[1].history['accuracy'], label='Train Accuracy Fold 2', color='red', )\nplt.plot(model_history[1].history['val_accuracy'], label='Val Accuracy Fold 2', color='red', linestyle = \"dashdot\")\nplt.plot(model_history[2].history['accuracy'], label='Train Accuracy Fold 3', color='green', )\nplt.plot(model_history[2].history['val_accuracy'], label='Val Accuracy Fold 3', color='green', linestyle = \"dashdot\")\nplt.legend()\nplt.show()","3fc6244c":"# plt.figure(figsize=(15,10))\n# plt.title('Train Accuracy vs Val Accuracy')\n# for i in range(len(model_history)):\n#   plt.plot(model_history[i].history['accuracy'], label=f\"Trai Accuracy Fold {i+1}\")\n#   plt.plot(model_history[i].history['val_accuracy'], label=f'Val Accuracy Fold {i+1}', linestyle = \"dashdot\")\n\n# plt.legend()\n# plt.show()","835376d2":"#Load the model that was saved by ModelCheckpoint\nfrom tensorflow import keras\n\nmodel = keras.models.load_model('\/content\/drive\/MyDrive\/Colab Notebooks\/MIAS-Classification\/Models\/h_mias.h5')\n\nmodel.evaluate(x_test,y_test)","9f324de6":"y_preds =  model.predict(x_test)\ny_preds","9c4912dc":"y_preds_arg = np.argmax(y_preds,axis=1)\ny_preds_arg","b8bd09b8":"asd = np.argmax(y_test, axis=1)\nasd","d919f0ab":"confusion_matrix(asd,y_preds_arg)","6ee51c30":"print(classification_report(asd,y_preds_arg))","f2b209ce":"#function to draw confusion matrix\nimport seaborn as sns\n\ndef draw_confusion_matrix(true,preds):\n    conf_matx = confusion_matrix(true, preds)\n    sns.heatmap(conf_matx, annot=True,fmt='g', cmap=\"viridis\")\n    plt.show()","e90f17e9":"draw_confusion_matrix(asd,y_preds_arg)","f5312920":"## **Read Data**","553e4077":"## **Train-Test-Split**","03efa5f9":"## **Make Dataset of ```imagepath``` and ```labels```**\n\n\n\n\n","07483a53":"## **ROC Curve**","d158972d":"## **Cross-Validation**","bcf3242c":"## **Confusion Matrix and Classification Report**","78ae077d":"* Read Data\n* Make Dataset of `imagepath` and `labels`\n* Convert images into tensors\n* Test-Train-Split\n* Train a DenseNet121 model\n* Test the model\n* Get Metrics\n* ROC Curve","d4c71b07":"### **Visualization**","e521d138":"## **Train a DenseNet121 Model**"}}