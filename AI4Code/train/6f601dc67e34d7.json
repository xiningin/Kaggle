{"cell_type":{"757d15ce":"code","bbe4b06f":"code","2835014c":"code","bb3b2637":"code","cec5859d":"code","b8c8da0e":"code","4005a96e":"code","e8ec6d34":"code","412903a7":"code","ccb7705c":"code","77157b8c":"code","87cca054":"code","401bf481":"code","76895bab":"code","9f06afa4":"code","6e9eb2e4":"markdown","61e5acfd":"markdown","770829a8":"markdown","e5bcaf1c":"markdown","fcc56fe4":"markdown","1de752e8":"markdown","47e75e6d":"markdown","93fe9e62":"markdown"},"source":{"757d15ce":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bbe4b06f":"titanic=pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntitanic_test=pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntitanic.head()","2835014c":"titanic.info()","bb3b2637":"\nx=titanic.drop(['Name','Survived'],axis=1)\ny=pd.DataFrame(titanic['Survived'])","cec5859d":"\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y , test_size = 0.25, random_state=10)","b8c8da0e":"from sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n\n#Modify the numeric features\nnumeric_features=['PassengerId','SibSp','Parch','Age','Fare']\nnumeric_features_pipeline=Pipeline(steps=[('imputer',SimpleImputer(strategy='median')),\n                                          ('scaler',StandardScaler())])","4005a96e":"#Modify the Categorical features\ncategorical_features=['Sex','Ticket','Cabin','Embarked']\ncategorical_features_pipeline=Pipeline(steps=[('imputer',SimpleImputer(strategy='constant',fill_value='missing')),\n                                              ('ohe',OneHotEncoder(handle_unknown='ignore'))])","e8ec6d34":"#Modify the Ordinal Features\nordinal_features=['Pclass']\nordinal_features_pipeline=Pipeline(steps=[('ordinal',OrdinalEncoder(categories=[[1,2,3]]))])","412903a7":"from sklearn.compose import ColumnTransformer\n#create a transformer to handle all columns\npreprocessor = ColumnTransformer(transformers= [\n    ('num', numeric_features_pipeline, numeric_features),        # transformer with name 'num' that will apply 'numeric_features_pipeline' to numeric_features\n    ('cat', categorical_features_pipeline, categorical_features), # transformer with name 'cat' that will apply 'categorical_features_pipeline' to categorical_features\n    ('ord', ordinal_features_pipeline, ordinal_features)\n])","ccb7705c":"from sklearn.linear_model import LogisticRegression\n# Now, we will create a full prediction pipeline\nclf = Pipeline(steps=[('preprocessor', preprocessor),\n                     ('classifier', LogisticRegression(solver = 'lbfgs'))])","77157b8c":"#Fitting The Model\nclf.fit(x_train,y_train)","87cca054":"from sklearn.metrics import accuracy_score\n#Calculating The accuracy of the model\npred=clf.predict(x_test)\naccuracy_score(pred,y_test)","401bf481":"titanic_test.fillna(titanic_test.median(),inplace=True)\ntitanic_test.isnull().sum()\ntitanic_test.fillna('missing',inplace=True)\ntitanic_test.isnull().sum()\ntitanic_test","76895bab":"#Applying Model to Test Data\npredictions=clf.predict(titanic_test)\nprint(predictions)","9f06afa4":"#submitting\ndf=pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\npassid=df['PassengerId']\n\nto_submit=pd.DataFrame(list(zip(passid,predictions)),columns=['PassengerId','Survived'])\nto_submit.to_csv(\"Submission_Data\",header=True,index=False)","6e9eb2e4":"# Splitting titanic Data","61e5acfd":"# PreProcessing Data","770829a8":"# Finishing and Submitting The output","e5bcaf1c":"# Building Model (Logistic Regression)","fcc56fe4":"# Preprocessing Test file","1de752e8":"# Split the data into train and test","47e75e6d":"# Loading Data (train and test files )","93fe9e62":"# Getting titanic info"}}