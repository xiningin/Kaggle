{"cell_type":{"495f6835":"code","73bf3254":"code","aa7c4365":"code","2245bf5b":"code","ccdfebbb":"code","f0d1428a":"code","5b792525":"code","bda9b3a1":"code","afd5f862":"code","699e2537":"code","ca7251b7":"code","0ba5afab":"code","b83f806e":"code","16898656":"code","d6a9b3cd":"code","20b4c9c7":"code","fae5b0fe":"code","5d6a99bf":"code","aaaba08b":"code","794f4108":"code","93284206":"code","f6ae14fa":"code","a7c24cb6":"code","8f1cd077":"code","7037cbc9":"code","4cd5ea75":"code","c2aff713":"code","f0b3b2e3":"code","ba4b42a6":"code","66e09fb7":"code","b46e0572":"code","d63a2216":"code","3e88a5b9":"code","b05712c6":"code","dd938ae8":"code","d60e2a2a":"code","1cb71d2b":"code","f904ec63":"code","6ff509df":"code","9a7d34f4":"code","6e5ed007":"code","79e161df":"code","c1ff2844":"code","1c08290f":"code","5f50e38a":"code","91638ddf":"code","4b6851f7":"code","cb020b42":"code","d9ac0e61":"code","0aa04a18":"code","987398ea":"code","a99bce53":"code","b76255cf":"code","ea81b1b0":"code","c0a104d9":"code","5dfc2651":"code","90b16645":"code","5f4c2be5":"code","f0d3ccde":"code","d5a4b470":"code","8cf4282b":"code","02734f98":"code","8f81ca8e":"code","8a541362":"code","395b39e1":"code","8f4d2fc5":"code","d299cf46":"code","f3e0102e":"code","613dcb42":"code","69bbb532":"code","7fbb2371":"code","bfb1de7f":"code","ced860a9":"code","0c80e04a":"code","5e8b4cc6":"code","f94e03c7":"code","6205c121":"code","1c2b9856":"code","c5a67be8":"code","14846bec":"code","57a2975a":"code","c899d122":"code","f873429c":"markdown","7ffe2385":"markdown","bc868b88":"markdown","6bb1b178":"markdown","bb96984d":"markdown","a8253868":"markdown","3f72abee":"markdown","846c5e20":"markdown","263a880c":"markdown","700dc9d4":"markdown","c311b14f":"markdown","5103a0da":"markdown","b013a12e":"markdown","bcac8839":"markdown","4c4826a0":"markdown","06046618":"markdown","94ef5369":"markdown","11a0e492":"markdown","9268d2b5":"markdown","a1d9a1e3":"markdown","61245bd5":"markdown","cbf00267":"markdown","9b3ffb1a":"markdown","9c81fef1":"markdown","9d6ed7a3":"markdown","f204ddbb":"markdown","3e250f37":"markdown","40edac4c":"markdown","35a3cdfa":"markdown","11bbe53b":"markdown","4f9c4bb1":"markdown","c20ffaec":"markdown","b4412b82":"markdown","dc6b4869":"markdown","067fe9d4":"markdown","a4e26cdc":"markdown","d5b5eb12":"markdown","2e0f4513":"markdown","ff6e7924":"markdown","03a574f1":"markdown","3bba5e06":"markdown","cceed719":"markdown","cebffa4b":"markdown","aca83e29":"markdown","9c00032a":"markdown","292bdd39":"markdown","76e6dd30":"markdown","e7eeeffb":"markdown","40ad0fb3":"markdown","3a16ce8a":"markdown","6baabc4e":"markdown","8a7f69e9":"markdown","16111d5e":"markdown","700a344a":"markdown","7df224e6":"markdown","a2dec866":"markdown","67ff4226":"markdown","8dc172e8":"markdown","0101333a":"markdown","4d6362a5":"markdown","9b474a35":"markdown","3aeda71b":"markdown","f7787fea":"markdown","a2751363":"markdown","5dc74708":"markdown","0488c1ae":"markdown","af049464":"markdown"},"source":{"495f6835":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport re\nimport string\nimport numpy as np \nimport random\nimport pandas as pd \n\n%matplotlib inline\nfrom plotly import graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom collections import Counter\n\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\n\nimport nltk\nfrom nltk.corpus import stopwords\nimport nltk as nlp\n\nfrom tqdm import tqdm\nimport os\n\n\n\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\nimport matplotlib.pyplot as plt\nplt.style.use(\"seaborn-whitegrid\")\n\nimport seaborn as sns\n\nfrom collections import Counter\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","73bf3254":"train_df = pd.read_csv(\"\/kaggle\/input\/tweet-sentiment-extraction\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/tweet-sentiment-extraction\/test.csv\")\n\ntrain_df.columns","aa7c4365":"train_df.head()","2245bf5b":"train_df.describe()","ccdfebbb":"print(train_df.shape)\nprint(test_df.shape)","f0d1428a":"train_df.info()","5b792525":"train_df.dropna(inplace=True)","bda9b3a1":"temp = train_df.groupby('sentiment').count()['text'].reset_index().sort_values(by='text',ascending=False)\ntemp.style.background_gradient(cmap='Reds')","afd5f862":"def bar_plot(variable):\n   \n    # get feature\n    var = train_df[variable]\n    # count number of categorical variable(value\/sample)\n    varValue = var.value_counts()\n    \n    # visualize\n    plt.figure(figsize = (9,3))\n    plt.bar(varValue.index, varValue)\n    plt.xticks(varValue.index, varValue.index.values)\n    plt.ylabel(\"Frequency\")\n    plt.title(variable)\n    plt.show()\n    print(\"{}: \\n {}\".format(variable,varValue))","699e2537":"plt.figure(figsize=(10,8))\nsns.countplot(x='sentiment',data=train_df)","ca7251b7":"fig = go.Figure(go.Funnelarea(\n    text =temp.sentiment,\n    values = temp.text,\n    title = {\"position\": \"top center\", \"text\": \"Funnel-Chart of Sentiment Distribution\"}\n    ))\nfig.show()","0ba5afab":"lens = [len(x) for x in train_df.text]\nplt.figure(figsize=(12, 5));\n\nprint (\"Max length:\", max(lens))\nprint (\"Min length:\", min(lens))\nprint (\"Mean length:\", np.mean(lens))\n\nsns.distplot(lens);\nplt.title('Text length distribution')","b83f806e":"lens = [len(x) for x in train_df.selected_text]\nplt.figure(figsize=(12, 5));\nprint (\"Max length:\", max(lens))\nprint (\"Min length:\", min(lens))\nprint (\"Mean length:\", np.mean(lens))\nsns.distplot(lens);\nplt.title('Text length distribution')","16898656":"def jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) \/ (len(a) + len(b) - len(c))","d6a9b3cd":"results_jaccard=[]\n\nfor ind,row in train_df.iterrows():\n    sentence1 = row.text\n    sentence2 = row.selected_text\n\n    jaccard_score = jaccard(sentence1,sentence2)\n    results_jaccard.append([sentence1,sentence2,jaccard_score])","20b4c9c7":"jaccard = pd.DataFrame(results_jaccard,columns=[\"text\",\"selected_text\",\"jaccard_score\"])\ntrain_df = train_df.merge(jaccard,how='outer')","fae5b0fe":"train_df['Num_words_ST'] = train_df['selected_text'].apply(lambda x:len(str(x).split())) #Number Of words in Selected Text\ntrain_df['Num_word_text'] = train_df['text'].apply(lambda x:len(str(x).split())) #Number Of words in main text\ntrain_df['difference_in_words'] = train_df['Num_word_text'] - train_df['Num_words_ST'] #Difference in Number of words text and Selected Text","5d6a99bf":"train_df.head() ","aaaba08b":"#Duygulara gore Jaccard scrore ortalama degerleri","794f4108":"train_df.groupby('sentiment').mean()['jaccard_score']","93284206":"def clean_text(text):\n    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n    text = str(text).lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?:\/\/\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text","f6ae14fa":"train_df['text'] = train_df['text'].apply(lambda x:clean_text(x))\ntrain_df['selected_text'] = train_df['selected_text'].apply(lambda x:clean_text(x))","a7c24cb6":"train_df['sentiment'] = train_df['sentiment'].map({'positive': 1, 'negative': 2, 'neutral':0})\n","8f1cd077":"train_df.head()","7037cbc9":"def remove_stopword(x):\n    return [y for y in x if y not in stopwords.words('english')]\n","4cd5ea75":"#remove stopwords - selected text\n\ntrain_df['selected_text_clear'] = train_df['selected_text'].apply(lambda x:str(x).split())\n\ntrain_df['selected_text_clear'] = train_df['selected_text_clear'].apply(lambda x:remove_stopword(x))","c2aff713":"#remove stopwords - text\n\ntrain_df['text_clear'] = train_df['text'].apply(lambda x:str(x).split())\n\ntrain_df['text_clear'] = train_df['text_clear'].apply(lambda x:remove_stopword(x))","f0b3b2e3":"lemma = nlp.WordNetLemmatizer()\n\ndef lemmatizate_word(x):\n    return [lemma.lemmatize(word) for word in x]\n\ntrain_df['selected_text_clear'] = train_df['selected_text_clear'].apply(lambda x:lemmatizate_word(x)) #selected text\ntrain_df['text_clear'] = train_df['text_clear'].apply(lambda x:lemmatizate_word(x)) #text","ba4b42a6":"def ngram(text):    \n    return [(text[i],text[i+1]) for i in range(0,len(text)-1)]\n\ntrain_df['ngram_text'] = train_df['text_clear'].apply(lambda x:str(x).split())\nngram_list = []\n\n    \ntrain_df['ngram_text'] = train_df['ngram_text'].apply(lambda ngram_list:ngram(ngram_list))\n","66e09fb7":"train_df.ngram_text","b46e0572":"train_df.head()","d63a2216":"top = Counter([item for sublist in train_df['selected_text_clear'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(25))\ntemp = temp.iloc[1:,:]\ntemp.columns = ['Common_words','count']\ntemp.style.background_gradient(cmap='Blues')\n","3e88a5b9":"fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Commmon Words in Selected Text', orientation='h', \n             width=700, height=700,color='Common_words')\nfig.show()","b05712c6":"top = Counter([item for sublist in train_df['text_clear'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(25))\ntemp = temp.iloc[1:,:]\ntemp.columns = ['Common_words','count']\ntemp.style.background_gradient(cmap='Blues')","dd938ae8":"fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Commmon Words in Text', orientation='h', \n             width=700, height=700,color='Common_words')\nfig.show()","d60e2a2a":"Positive_sent = train_df[(train_df['sentiment']== 1) ]\n\ntop = Counter([item for sublist in Positive_sent['text_clear'] for item in sublist])\ntemp_positive = pd.DataFrame(top.most_common(25))\ntemp_positive.columns = ['Common_words','count']\ntemp_positive.style.background_gradient(cmap='Greens')","1cb71d2b":"Negative_sent = train_df[(train_df['sentiment']== 2) ]\n\ntop = Counter([item for sublist in Negative_sent['text_clear'] for item in sublist])\ntemp_negative = pd.DataFrame(top.most_common(25))\ntemp_negative = temp_negative.iloc[1:,:] #except 'im'\ntemp_negative.columns = ['Common_words','count']\ntemp_negative.style.background_gradient(cmap='Reds')","f904ec63":"Neutral_sent = train_df[(train_df['sentiment']== 0) ]\n\ntop = Counter([item for sublist in Neutral_sent['text_clear'] for item in sublist])\ntemp_neutral = pd.DataFrame(top.most_common(25))\ntemp_neutral = temp_neutral.loc[1:,:] #except 'im'\ntemp_neutral.columns = ['Common_words','count']\ntemp_neutral.style.background_gradient(cmap='Greys')","6ff509df":"raw_text = [word for word_list in train_df['selected_text_clear'] for word in word_list]\n","9a7d34f4":"def words_unique(sentiment,numwords,raw_words):\n    '''\n    Input:\n        segment - Segment category (ex. 'Neutral');\n        numwords - how many specific words do you want to see in the final result; \n        raw_words - list  for item in train_data[train_data.segments == segments]['temp_list1']:\n    Output: \n        dataframe giving information about the name of the specific ingredient and how many times it occurs in the chosen cuisine (in descending order based on their counts)..\n    '''\n    allother = []\n    for item in train_df[(train_df.sentiment != sentiment)]['selected_text_clear']:\n        for word in item:\n            allother.append(word)\n    allother = list(set(allother ))\n    \n    specificnonly = [x for x in raw_text if x not in allother]\n    \n    mycounter = Counter()\n    \n    for item in train_df[(train_df.sentiment == sentiment) ]['selected_text_clear']:\n        for word in item:\n            mycounter[word] += 1\n    keep = list(specificnonly)\n    \n    for word in list(mycounter):\n        if word not in keep:\n            del mycounter[word]\n    \n    Unique_words = pd.DataFrame(mycounter.most_common(numwords), columns = ['words','count'])\n    \n    return Unique_words","6e5ed007":"Unique_Positive= words_unique(1, 10, raw_text)\nprint(\"The top 10 unique words in Positive Tweets are:\")\nUnique_Positive.style.background_gradient(cmap='Greens')","79e161df":"Unique_Negative= words_unique(2, 10, raw_text)\nprint(\"The top 10 unique words in Negative Tweets are:\")\nUnique_Negative.style.background_gradient(cmap='Reds')","c1ff2844":"Unique_Neutral= words_unique(0, 10, raw_text)\nprint(\"The top 10 unique words in Neutral Tweets are:\")\nUnique_Neutral.style.background_gradient(cmap='Greys')\n","1c08290f":"train_df2 = train_df[train_df['jaccard_score'] > 0.2]\ntrain_df2.head()","5f50e38a":"temp = train_df2.groupby('sentiment').count()['text'].reset_index().sort_values(by='text',ascending=False)\ntemp.style.background_gradient(cmap='Reds')","91638ddf":"selected_text_listt = []\nfor i in train_df2['selected_text_clear']:\n    i = ' '.join(i)\n    selected_text_listt.append(i)\n    \nfrom sklearn.feature_extraction.text import CountVectorizer \nmax_features =500\n\ncount_vectorizer = CountVectorizer(max_features=max_features,stop_words = \"english\")\n\nsparce_matrix = count_vectorizer.fit_transform(selected_text_listt).toarray()  \n","4b6851f7":"y = train_df2.iloc[:,3:4].values     # sentiment\nx = sparce_matrix\n# train test split\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, random_state = 42)","cb020b42":"# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","d9ac0e61":"# %% naive bayes\nfrom sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(x_train,y_train)\n\nfrom sklearn.metrics import *\n# Predicting the Test set results\ny_pred = nb.predict(x_test)\n\n\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\nprint(accuracy_score(y_test, y_pred))\n\nnb_02_accuracy = accuracy_score(y_test, y_pred)","0aa04a18":"from sklearn.metrics import confusion_matrix\nmat = confusion_matrix(y_test, y_pred)\nsns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False,\n            xticklabels='', yticklabels='')\nplt.xlabel('true label')\nplt.ylabel('predicted label');","987398ea":"# from sklearn.naive_bayes import MultinomialNB\n# nb = MultinomialNB()\n# nb.fit(x_train,y_train)\n\n# from sklearn.metrics import *\n# # Predicting the Test set results\n# y_pred = nb.predict(x_test)\n\n\n# print(classification_report(y_test, y_pred))\n# print(confusion_matrix(y_test, y_pred))\n# print(accuracy_score(y_test, y_pred))","a99bce53":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\n\n# %% Grid search CV with logistic regression\ngrid = {\"C\":np.logspace(-3,3,7),\"penalty\":[\"l1\",\"l2\"]}  # l1 = lasso ve l2 = ridge\n\nlogreg = LogisticRegression()\nlogreg_cv = GridSearchCV(logreg,grid,cv = 10)\nlogreg_cv.fit(x_train,y_train)\n\n# Predicting the Test set results\ny_pred = logreg_cv.predict(x_test)\n\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\nprint(accuracy_score(y_test, y_pred))\n\nprint(\"tuned hyperparameters: (best parameters): \",logreg_cv.best_params_)\nprint(\"accuracy: \",logreg_cv.best_score_)\n\nlr_02_accuracy = logreg_cv.best_score_","b76255cf":"from sklearn.metrics import confusion_matrix\nmat = confusion_matrix(y_test, y_pred)\nsns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False,\n            xticklabels='', yticklabels='')\nplt.xlabel('true label')\nplt.ylabel('predicted label');","ea81b1b0":"# Fitting Decision Tree Classification to the Training set\nfrom sklearn.tree import DecisionTreeClassifier\nclassifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\nclassifier.fit(x_train, y_train)\n\n# Predicting the Test set results\ny_pred = classifier.predict(x_test)\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\nprint(accuracy_score(y_test, y_pred))\n\ndt_02_accuracy = accuracy_score(y_test, y_pred)","c0a104d9":"from sklearn.metrics import confusion_matrix\nmat = confusion_matrix(y_test, y_pred)\nsns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False,\n            xticklabels='', yticklabels='')\nplt.xlabel('true label')\nplt.ylabel('predicted label');","5dfc2651":"from sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators=100, criterion = 'entropy', random_state = 0)\nclassifier.fit(x_train, y_train)\n\ny_pred = classifier.predict(x_test)\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\nprint(accuracy_score(y_test, y_pred))\n\nrf_02_accuracy = accuracy_score(y_test, y_pred)","90b16645":"from sklearn.metrics import confusion_matrix\nmat = confusion_matrix(y_test, y_pred)\nsns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False,\n            xticklabels='', yticklabels='')\nplt.xlabel('true label')\nplt.ylabel('predicted label');","5f4c2be5":"from sklearn.neighbors import KNeighborsClassifier\n# classifier = KNeighborsClassifier(n_neighbors = 3, metric = 'minkowski', p = 2)\n# classifier.fit(x_train, y_train)\n\n\nknn = KNeighborsClassifier(n_neighbors=3)  # k = n_neighbors\n\n# %% K fold CV K = 10\nfrom sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = knn, X = x_train, y= y_train, cv = 10)\nprint(\"average accuracy: \",np.mean(accuracies))\nprint(\"average std: \",np.std(accuracies))\n\n#%% \nknn.fit(x_train,y_train)\nprint(\"test accuracy: \",knn.score(x_test,y_test))\n\n\n# Predicting the Test set results\ny_pred = knn.predict(x_test)\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\nprint(accuracy_score(y_test, y_pred))\n\nknn_02_accuracy = accuracy_score(y_test, y_pred)","f0d3ccde":"from sklearn.metrics import confusion_matrix\nmat = confusion_matrix(y_test, y_pred)\nsns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False,\n            xticklabels='', yticklabels='')\nplt.xlabel('true label')\nplt.ylabel('predicted label');","d5a4b470":"# # LOAD LIBRARIES\n# from sklearn.svm import SVC\n# clf = SVC(probability=True,kernel='poly',degree=3,gamma='auto')\n# clf.fit(x_train, y_train)\n\n# y_pred = clf.predict(x_test)\n# print(classification_report(y_test, y_pred))\n# print(confusion_matrix(y_test, y_pred))\n# print(accuracy_score(y_test, y_pred))\n\n# svm_02_accuracy = accuracy_score(y_test, y_pred)","8cf4282b":"# from sklearn.metrics import confusion_matrix\n# mat = confusion_matrix(y_test, y_pred)\n# sns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False,\n#             xticklabels='', yticklabels='')\n# plt.xlabel('true label')\n# plt.ylabel('predicted label');","02734f98":"from lightgbm import LGBMClassifier\nlgbm_model = LGBMClassifier().fit(x_train, y_train)\n\n# Predicting the Test set results\ny_pred = lgbm_model.predict(x_test)\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\nprint(accuracy_score(y_test, y_pred))\n\nlgbm_02_accuracy = accuracy_score(y_test, y_pred)","8f81ca8e":"train_df8 = train_df[train_df['jaccard_score'] > 0.8]","8a541362":"selected_text_listt = []\nfor i in train_df8['selected_text_clear']:\n    i = ' '.join(i)\n    selected_text_listt.append(i)\n    \nfrom sklearn.feature_extraction.text import CountVectorizer \nmax_features = 500\n\ncount_vectorizer = CountVectorizer(max_features=max_features,stop_words = \"english\")\n\nsparce_matrix = count_vectorizer.fit_transform(selected_text_listt).toarray()  \n","395b39e1":"y = train_df8.iloc[:,3:4].values     # sentiment\nx = sparce_matrix\n# train test split\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, random_state = 42)\n\n\n# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","8f4d2fc5":"# %% naive bayes\nfrom sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(x_train,y_train)\n\nfrom sklearn.metrics import *\n# Predicting the Test set results\ny_pred = nb.predict(x_test)\n\n\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\nprint(accuracy_score(y_test, y_pred))\n\nnb_08_accuracy = accuracy_score(y_test, y_pred)","d299cf46":"from sklearn.metrics import confusion_matrix\nmat = confusion_matrix(y_test, y_pred)\nsns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False,\n            xticklabels='', yticklabels='')\nplt.xlabel('true label')\nplt.ylabel('predicted label');","f3e0102e":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 42)\nclassifier.fit(x_train, y_train)\n\n# Predicting the Test set results\ny_pred = classifier.predict(x_test)\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\nprint(accuracy_score(y_test, y_pred))\n\nlr_08_accuracy = accuracy_score(y_test, y_pred)","613dcb42":"from sklearn.metrics import confusion_matrix\nmat = confusion_matrix(y_test, y_pred)\nsns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False,\n            xticklabels='', yticklabels='')\nplt.xlabel('true label')\nplt.ylabel('predicted label');","69bbb532":"# Fitting Decision Tree Classification to the Training set\nfrom sklearn.tree import DecisionTreeClassifier\nclassifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\nclassifier.fit(x_train, y_train)\n\n# Predicting the Test set results\ny_pred = classifier.predict(x_test)\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\nprint(accuracy_score(y_test, y_pred))\n\ndt_08_accuracy = accuracy_score(y_test, y_pred)","7fbb2371":"from sklearn.metrics import confusion_matrix\nmat = confusion_matrix(y_test, y_pred)\nsns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False,\n            xticklabels='', yticklabels='')\nplt.xlabel('true label')\nplt.ylabel('predicted label');","bfb1de7f":"from sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators=100, criterion = 'entropy', random_state = 0)\nclassifier.fit(x_train, y_train)\n\ny_pred = classifier.predict(x_test)\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\nprint(accuracy_score(y_test, y_pred))\n\nrf_08_accuracy = accuracy_score(y_test, y_pred)","ced860a9":"from sklearn.metrics import confusion_matrix\nmat = confusion_matrix(y_test, y_pred)\nsns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False,\n            xticklabels='', yticklabels='')\nplt.xlabel('true label')\nplt.ylabel('predicted label');","0c80e04a":"from sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors = 3, metric = 'minkowski', p = 2)\nclassifier.fit(x_train, y_train)\n\n# Predicting the Test set results\ny_pred = classifier.predict(x_test)\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\nprint(accuracy_score(y_test, y_pred))\n\nknn_08_accuracy = accuracy_score(y_test, y_pred)","5e8b4cc6":"from sklearn.metrics import confusion_matrix\nmat = confusion_matrix(y_test, y_pred)\nsns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False,\n            xticklabels='', yticklabels='')\nplt.xlabel('true label')\nplt.ylabel('predicted label');","f94e03c7":"# # LOAD LIBRARIES\n# from sklearn.svm import SVC\n# clf = SVC(probability=True,kernel='poly',degree=4,gamma='auto')\n# clf.fit(x_train, y_train)\n\n# y_pred = clf.predict(x_test)\n# print(classification_report(y_test, y_pred))\n# print(confusion_matrix(y_test, y_pred))\n# print(accuracy_score(y_test, y_pred))\n\n# svm_08_accuracy = accuracy_score(y_test, y_pred)","6205c121":"# from sklearn.metrics import confusion_matrix\n# mat = confusion_matrix(y_test, y_pred)\n# sns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False,\n#             xticklabels='', yticklabels='')\n# plt.xlabel('true label')\n# plt.ylabel('predicted label');","1c2b9856":"from lightgbm import LGBMClassifier\nlgbm_model = LGBMClassifier().fit(x_train, y_train)\n\n# Predicting the Test set results\ny_pred = lgbm_model.predict(x_test)\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\nprint(accuracy_score(y_test, y_pred))\n\nlgbm_08_accuracy = accuracy_score(y_test, y_pred)","c5a67be8":"df_accuracies = [lr_02_accuracy,nb_02_accuracy,dt_02_accuracy,rf_02_accuracy,knn_02_accuracy,lgbm_02_accuracy,lr_08_accuracy,nb_08_accuracy,dt_08_accuracy,rf_08_accuracy,knn_08_accuracy,lgbm_08_accuracy]\n","14846bec":"df_accuracies = pd.DataFrame(data = df_accuracies, index=range(len(df_accuracies)),columns=['accuracy'])\ndf_accuracies['model_name'] = ['logistic regression 02','naive bayes 02','desicion tree 02','random forest 02','knn 02','lightgbm 02','logistic regression 08','naive bayes 08','desicion tree 08','random forest 08','knn 08','lightgbm 08']","57a2975a":"df_accuracies.head(12)\n","c899d122":"df_accuracies.plot(kind='bar',x='model_name',y='accuracy',figsize=(15,10))\n","f873429c":"# Let's Look at Unique Words in each Segment\nWe will look at unique words in each segment in the Following Order:","7ffe2385":"# Support Vector Machine","bc868b88":"There are three important terms that need to be known well in order to understand machine learning models. These terms are:\n* Classification report\n* Accuracy score\n* Confusion matrix\n\nA general overview of these terms can be found below","6bb1b178":"# Modeling with jaccard scores over 0.2","bb96984d":"# Content:\n\n1. Load and Check Data\n2. Variable Description\n3. Univariate Variable Analysis\n4. Text Length Distribution\n5. Basic Data Analysis\n6. Cleaning the Data\n    *     Removing the stopwords\n    *     Lemmatization\n7. N-Gram Modelling\n8. Most Common Words Analysis\n    *     In \"Selected Text\"\n    *     In \"Text\"\n9. Most common words Sentiments Wise\n    *     Most 25 common positive words\n    *     Most 25 common negative words\n    *     Most 25 common neutral words\n10. Unique Words in each Segment\n    *     Unique 10 Positive words\n    *     Unique 10 Negative words\n    *     Unique 10 Neutral words\n11. Modeling With Jaccard Scores Over 0.2\n    *     Naive Bayes\n    *     Logistic Regression\n    *     Decision Tree\n    *     Random Forest\n    *     K-Nearest Neighbour\n    *     Support Vector Machine\n    *     LightGBM\n12. Modeling With Jaccard Scores Over 0.8\n    *     Naive Bayes\n    *     Logistic Regression\n    *     Decision Tree\n    *     Random Forest\n    *     K-Nearest Neighbour\n    *     Support Vector Machine\n    *     LightGBM","a8253868":"> Naive Bayes is a classification algorithm for binary (two-class) and multiclass classification problems. It is called Naive Bayes or idiot Bayes because the calculations of the probabilities for each class are simplified to make their calculations tractable.\n> \n> Rather than attempting to calculate the probabilities of each attribute value, they are assumed to be conditionally independent given the class value.\n> \n> This is a very strong assumption that is most unlikely in real data, i.e. that the attributes do not interact. Nevertheless, the approach performs surprisingly well on data where this assumption does not hold.","3f72abee":"Up to now, we have analyzed the dataset.\nFrom now on we will focus on modeling and handle 7 different machine learning methods:\n\n* Naive Bayes\n* Logistic Regression\n* Decision Tree\n* Random Forest\n* K-Nearest Neighbour\n* Support Vector Machine\n* LightGBM\n\nThese methods are preferred taking into account the opinions and tips of leading professionals.\nIn order to achieve better results we have focused on Jaccard score and we have implemented 7 different machine learning methods taking into account 2 different jaccard scores: 0.2 and 0.8","846c5e20":"# Basic Data Analysis\n","263a880c":"\"My ridiculous dog is amazing.\" [sentiment: positive]\n\nWith all of the tweets circulating every second it is hard to tell whether the sentiment behind a specific tweet will impact a company, or a person's, brand for being viral (positive), or devastate profit because it strikes a negative tone. Capturing sentiment in language is important in these times where decisions and reactions are created and updated in seconds. But, which words actually lead to the sentiment description? In this competition you will need to pick out the part of the tweet (word or phrase) that reflects the sentiment.","700dc9d4":"# Lemmatization","c311b14f":"> Decision tree is the most powerful and popular tool for classification and prediction. A Decision tree is a flowchart like tree structure, where each internal node denotes a test on an attribute, each branch represents an outcome of the test, and each leaf node (terminal node) holds a class label.","5103a0da":"> SVM model is a representation of the examples as points in space, mapped so that the examples of the separate categories are divided by a clear gap that is as wide as possible.\nIn addition to performing linear classification, SVMs can efficiently perform a non-linear classification, implicitly mapping their inputs into high-dimensional feature spaces.","b013a12e":"# Univariate Variable Analysis\nCategorical Variable: textID, text, selected_text  , sentiment","bcac8839":"Bag of Words","4c4826a0":"# Selected Text Length Distribution","06046618":"The top 100 unique words in Neutral Tweets are:","94ef5369":"Most 25 common ***positive*** words in Selected Texts","11a0e492":"**Categorical Variable**\n\nLets look at the distribution of tweets in the train set","9268d2b5":"![](https:\/\/www.kdnuggets.com\/images\/sentiment-fig-1-689.jpg)","a1d9a1e3":"> Sentiment names converted to numeric","61245bd5":"It\u2019s estimated that 80% of the world\u2019s data is unstructured, in other words it\u2019s unorganized. Huge volumes of text data (emails, support tickets, chats, social media conversations, surveys, articles, documents, etc), is created every day but it\u2019s hard to analyze, understand, and sort through, not to mention time-consuming and expensive.\n\nSentiment analysis, however, helps businesses make sense of all this unstructured text by automatically tagging it.","cbf00267":"StandardScaler standardizes a feature by subtracting the mean and then scaling to unit variance. Unit variance means dividing all the values by the standard deviation.","9b3ffb1a":"Most 25 common ***negative*** words in Selected Texts","9c81fef1":"> A bag-of-words model, or BoW for short, is a way of extracting features from text for use in modeling, such as with machine learning algorithms. The approach is very simple and flexible. In this model, a text (such as a sentence or a document) is represented as the bag (multiset) of its words, disregarding grammar and even word order but keeping multiplicity.","9d6ed7a3":"# Text Length Distribution","f204ddbb":"Sentiment analysis is the interpretation and classification of emotions (positive, negative and neutral) within text data using text analysis techniques. Sentiment analysis allows businesses to identify customer sentiment toward products, brands or services in online conversations and feedback.","3e250f37":"**Confusion matrix**, also known as an error matrix, is a specific table layout that allows visualization of the performance of an algorithm, typically a supervised learning one (in unsupervised learning it is usually called a matching matrix). Each row of the matrix represents the instances in a predicted class while each column represents the instances in an actual class (or vice versa). The name stems from the fact that it makes it easy to see if the system is confusing two classes (i.e. commonly mislabeling one as another).","40edac4c":"> Logistic regression is a classification algorithm used to assign observations to a discrete set of classes. Unlike linear regression which outputs continuous number values, logistic regression transforms its output using the logistic sigmoid function to return a probability value which can then be mapped to two or more discrete classes.","35a3cdfa":"# **Removing the stopwords**","11bbe53b":"Types of Naive Bayes Classifier:\nMultinomial Naive Bayes:\n\nThis is mostly used for document classification problem, i.e whether a document belongs to the category of sports, politics, technology etc. The features\/predictors used by the classifier are the frequency of the words present in the document.\nBernoulli Naive Bayes:\n\nThis is similar to the multinomial naive bayes but the predictors are boolean variables. The parameters that we use to predict the class variable take up only values yes or no, for example if a word occurs in the text or not.\nGaussian Naive Bayes:\n\nWhen the predictors take up a continuous value and are not discrete, we assume that these values are sampled from a gaussian distribution.","4f9c4bb1":"#  Most Common words in \"Text\"","c20ffaec":"Confusion Matrix ","b4412b82":"# Variable Description\n1. textID: unique ID for each piece of text\n2. text: the text of the tweet\n3. selected_text: the general sentiment of the tweet\n4. sentiment: [train only] the text that supports the tweet's sentiment; Positive, Negative, Neutral\n","dc6b4869":"# LightGBM","067fe9d4":"# Most common words Sentiments Wise\nLet's look at the most common words in different sentiments","a4e26cdc":"# RandomForest","d5b5eb12":"# Decission Tree","2e0f4513":"> Scikit-learn\u2019s CountVectorizer is used to convert a collection of text documents to a vector of term\/token counts. It also enables the \u200bpre-processing of text data prior to generating the vector representation. This functionality makes it a highly flexible feature representation module for text.","ff6e7924":"# Cleaning the Data\nNow Before We Dive into extracting information out of words in text and selected text,let's first clean the data","03a574f1":"> Random forests is a supervised learning algorithm. It can be used both for classification and regression. It is also the most flexible and easy to use algorithm. A forest is comprised of trees. It is said that the more trees it has, the more robust a forest is. Random forests creates decision trees on randomly selected data samples, gets prediction from each tree and selects the best solution by means of voting. It also provides a pretty good indicator of the feature importance.","3bba5e06":"* positive sonucunu veren tweetler ortalama olarak %31 oraninda selected text olarak kaydedilmis. yani textlerin ortalama %69u elenmis.\n* negative sonucunu veren tweetler ortalama olarak %33u oraninda selected text olarak kaydedilmis. yani textlerin ortalama %67si elenmis.\n* neutral sonucunu veren tweetler ortalama olarak %97si oraninda selected text olarak kaydedilmis. yani textlerin ortalama %3u elenmis.\n","cceed719":"# Logistic Regression","cebffa4b":"We have one null Value in the train , as the test field for value is NAN we will just remove it\n\n","aca83e29":"# Random Forest","9c00032a":"> K Nearest Neighbor(KNN) is a very simple, easy to understand, versatile and one of the topmost machine learning algorithms. KNN used in the variety of applications such as finance, healthcare, political science, handwriting detection, image recognition and video recognition. In Credit ratings, financial institutes will predict the credit rating of customers. In loan disbursement, banking institutes will predict whether the loan is safe or risky. In political science, classifying potential voters in two classes will vote or won\u2019t vote. KNN algorithm used for both classification and regression problems. ","292bdd39":"**Accuracy score:** In multilabel classification, this function computes subset accuracy: the set of labels predicted for a sample must exactly match the corresponding set of labels in y_true.","76e6dd30":"Bag of Words","e7eeeffb":"The top 100 unique words in Negative Tweets are:","40ad0fb3":"Most 25 common ***neutral*** words in Selected Texts","3a16ce8a":"# Why Perform Sentiment Analysis?","6baabc4e":"# Naive Bayes","8a7f69e9":"# Modeling with jaccard scores over 0.8","16111d5e":"# K-Nearest Neighbour","700a344a":"# Naive Bayes","7df224e6":"# Load and Check Data\n","a2dec866":"# Support Vector Machine","67ff4226":"Classification report is used to measure the quality of predictions from a classification algorithm. How many predictions are True and how many are False. More specifically, True Positives, False Positives, True negatives and False Negatives are used to predict the metrics of a classification report. \n\nThe report shows the main classification metrics precision, recall and f1-score on a per-class basis.\n\nThe metrics are calculated by using true and false positives, true and false negatives. Positive and negative in this case are generic names for the predicted classes. There are four ways to check if the predictions are right or wrong:\n\n    TN \/ True Negative: when a case was negative and predicted negative\n    TP \/ True Positive: when a case was positive and predicted positive\n    FN \/ False Negative: when a case was positive but predicted negative\n    FP \/ False Positive: when a case was negative but predicted positive\n\n**Precision** \u2013 What percent of your predictions were correct?\n\nPrecision is the ability of a classifier not to label an instance positive that is actually negative. For each class it is defined as the ratio of true positives to the sum of true and false positives.\n\nTP \u2013 True Positives\nFP \u2013 False Positives\n\nPrecision \u2013 Accuracy of positive predictions.\nPrecision = TP\/(TP + FP)\n\n\n**Recall** \u2013 What percent of the positive cases did you catch? \n\nRecall is the ability of a classifier to find all positive instances. For each class it is defined as the ratio of true positives to the sum of true positives and false negatives.\n\nFN \u2013 False Negatives\n\nRecall: Fraction of positives that were correctly identified.\nRecall = TP\/(TP+FN)\n\n\n**F1 score** \u2013 What percent of positive predictions were correct? \n\nThe F1 score is a weighted harmonic mean of precision and recall such that the best score is 1.0 and the worst is 0.0. Generally speaking, F1 scores are lower than accuracy measures as they embed precision and recall into their computation. As a rule of thumb, the weighted average of F1 should be used to compare classifier models, not global accuracy.\n\nF1 Score = 2*(Recall * Precision) \/ (Recall + Precision)","8dc172e8":"# Tweet Sentiment Analysis","0101333a":"**The top 10 unique words in Positive Tweets are:**","4d6362a5":"# LightGBM ","9b474a35":"# Most Common words \"Selected Text\"","3aeda71b":"# K-Nearest Neighbour","f7787fea":"# Logistic Regression","a2751363":"# N-Gram Modelling","5dc74708":"# Decision Tree","0488c1ae":"> LightGBM is a gradient boosting framework that uses tree based learning algorithms. It is designed to be distributed and efficient with the following advantages:\n> \n> * Faster training speed and higher efficiency.\n>  \n> * Lower memory usage.\n>  \n> * Better accuracy.\n>  \n> * Support of parallel and GPU learning.\n>  \n> * Capable of handling large-scale data.","af049464":"Confusion Matrix"}}