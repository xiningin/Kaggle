{"cell_type":{"40961413":"code","b3173019":"code","b2fa642f":"code","87538a18":"code","f25a60e8":"code","4510b6dd":"code","8203374a":"code","e223df31":"code","dcfcf870":"code","bb09e5bf":"code","6c3d6f90":"code","19b24870":"code","e9c856db":"code","2feaa2ed":"code","deb74f6f":"code","5fb6e359":"code","727af101":"code","4a3c2d59":"code","07f827f7":"code","a28896e5":"code","30e2911e":"code","60f3b9f8":"code","771219f6":"code","cd0bbbf9":"code","11bd97ed":"code","1066479d":"code","8fb323e5":"code","d6c1017d":"code","3c50322c":"code","5ac96b6d":"code","f8fbbc75":"code","9b2cac22":"code","d96e22a1":"code","77fa13fc":"code","01095841":"code","d6335864":"code","e54104fd":"code","89417a4d":"code","54ed411a":"code","39fdd72b":"code","c5a849df":"code","a56f45da":"code","d6605ee9":"code","40a40e92":"code","9b72adc3":"code","89ce5980":"markdown","8d09fde6":"markdown","144d0d4e":"markdown","f4eb5c40":"markdown","b0d641b3":"markdown","06b47599":"markdown","cfad09fa":"markdown","32ccac1a":"markdown","4a1451d5":"markdown","32868bfe":"markdown","54db9d69":"markdown","d0b8bd68":"markdown","c078fd8f":"markdown","9e274a33":"markdown","70063f78":"markdown","d8b1d29b":"markdown","9ddc8929":"markdown","bbb5d8d1":"markdown","9ed9f7fd":"markdown","ab204b11":"markdown","233f2ecc":"markdown"},"source":{"40961413":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport math\nfrom math import *\n\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objects as go\nfrom ipywidgets import widgets\nfrom ipywidgets import *\n# Ce code fonctionne dans un notebook jupyter.\ninit_notebook_mode(connected=True)","b3173019":"%matplotlib inline","b2fa642f":"df_train = pd.read_csv('..\/input\/titanic\/train.csv')\ndf_test = pd.read_csv('..\/input\/titanic\/test.csv')\ndf_sub = pd.read_csv('..\/input\/titanic\/gender_submission.csv')","87538a18":"df_train.dtypes.value_counts()","f25a60e8":"df_test.dtypes.value_counts()","4510b6dd":"df_train[\"Survived\"].value_counts()","8203374a":"labels=df_train[\"Survived\"].value_counts().index\nvalues=df_train[\"Survived\"].value_counts().values\nfig = go.Figure(data=[go.Pie(labels=labels, values=values, textinfo='label+percent',\n                             insidetextorientation='radial'\n                            )])\nfig.show()","e223df31":"w_variable = widgets.Dropdown(\n    options=[\"Age\",\"Fare\"],\n    value=\"Age\",\n    description='Variable:',\n    disabled=False,\n)\n\ndef plot_histo(variable):\n    fig, ax = plt.subplots(ncols=1, figsize=(12, 8))\n    sns.distplot(df_train[df_train[\"Survived\"]==1][variable].dropna(), color=\"skyblue\",bins=30, label=\"Survived\")\n    sns.distplot(df_train[df_train[\"Survived\"]==0][variable].dropna(), color=\"red\",bins=30, label=\"Not Survived\")\n    plt.legend()        \nwidget=interactive(plot_histo,variable=w_variable)\nwidget","dcfcf870":"fig, ax = plt.subplots(ncols=2,nrows=5,figsize=(15, 20))\n\ndf_train['Sex'].value_counts().plot.pie(ax=ax[0,0])\nsns.countplot(x='Sex', hue=\"Survived\", data=df_train,ax=ax[0,1])\n\ndf_train['Embarked'].value_counts().plot.pie(ax=ax[1,0])\nsns.countplot(x='Embarked', hue=\"Survived\", data=df_train,ax=ax[1,1])\n\ndf_train['Pclass'].value_counts().plot.pie(ax=ax[2,0])\nsns.countplot(x='Pclass', hue=\"Survived\", data=df_train,ax=ax[2,1])\n\ndf_train['SibSp'].value_counts().plot.pie(ax=ax[3,0])\nsns.countplot(x='SibSp', hue=\"Survived\", data=df_train,ax=ax[3,1])\n\ndf_train['Parch'].value_counts().plot.pie(ax=ax[4,0])\nsns.countplot(x='Parch', hue=\"Survived\", data=df_train,ax=ax[4,1])\n\nplt.legend()","bb09e5bf":"fig, ax = plt.subplots(ncols=2, figsize=(20, 8))\nsns.heatmap(df_train.isnull(),yticklabels=False,cbar=False,cmap='BuPu',ax=ax[0])\nsns.heatmap(df_test.isnull(), yticklabels=False,cbar=False, cmap='BuPu',ax=ax[1])\nax[0].set_title('Train Set Missing Values')\nax[1].set_title('Test Set Missing Values')\nplt.xticks(rotation=90)\nplt.show()","6c3d6f90":"missing_rate_train = (df_train.isna().sum()\/df_train.shape[0]).sort_values()\nnb_missing = df_train.isna().sum().sort_values()\nprint(f'{\"Variable\" :-<40} {\"missing_rate_train\":-<30} {\"Number of missing values\":-<30}')\nfor n in range(len(missing_rate_train)):\n    print(f'{missing_rate_train.index[n] :-<30} {missing_rate_train[n]:-<30} {nb_missing[n]:-<30}')","19b24870":"missing_rate_test = (df_test.isna().sum()\/df_test.shape[0]).sort_values()\nnb_missing = df_test.isna().sum().sort_values()\nprint(f'{\"Variable\" :-<30} {\"missing_rate_train\":-<30} {\"Number of missing values\":-<30}')\nfor n in range(len(missing_rate_test)):\n    print(f'{missing_rate_test.index[n] :-<30} {missing_rate_test[n]:-<30} {nb_missing[n]:-<30}')","e9c856db":"def TransfromTitle(df_aux):\n    \n    title = []\n    for name in df_aux['Name'] :\n        p1 = name.find(',') # position of coma\n        p2 = name.find('.') # position of point\n        if p1 != -1 or p2!= -1:\n            title.append(name[p1+2:p2])\n        else :\n            title.append(np.nan) \n    df_aux['title'] = pd.DataFrame(title, index=df_aux.index)\n    \n    title2 = []\n    for t in df_aux['title'] :\n        if t in [\"Mr\",\"Miss\",\"Mrs\",\"Master\"]:\n            title2.append(t)\n        elif t in ['Don', 'Mme', 'Ms', 'Lady', 'Sir', 'Mlle', 'the Countess','Jonkheer', 'Dona']: \n            title2.append(\"royale\")\n        elif t in ['Major','Col', 'Capt','Rev','Dr']:\n            title2.append(\"officier\/capitaine\")\n    df_aux['title'] = pd.DataFrame(title2, index=df_aux.index) \n    \n    return df_aux.drop(columns=[\"PassengerId\",\"Name\"])","2feaa2ed":"df1 = TransfromTitle(df_train)\ndf1.head(5)","deb74f6f":"fig, ax = plt.subplots(ncols=2, figsize=(20, 7))\nsns.countplot(x='title', hue=\"Survived\", data=df1,ax=ax[0])\nsns.countplot(x='Pclass', hue=\"Survived\", data=df1,ax=ax[1])\nax[0].set_title('Histogram')\nax[1].set_title('Histogram')","5fb6e359":"fig, ax = plt.subplots(ncols=1, figsize=(15, 5))\nsns.distplot(df1[df1[\"title\"]=='Mr'][\"Age\"].dropna(), color=\"red\",bins=30, label='Mr')\nsns.distplot(df1[df1[\"title\"]=='Mrs'][\"Age\"].dropna(), color=\"green\",bins=30, label='Mrs')\nsns.distplot(df1[df1[\"title\"]=='Miss'][\"Age\"].dropna(), color=\"blue\",bins=30, label='Miss')\nsns.distplot(df1[df1[\"title\"]=='Master'][\"Age\"].dropna(), color=\"skyblue\",bins=2, label='Master')\nsns.distplot(df1[df1[\"title\"]=='officier\/capitaine'][\"Age\"].dropna(), color=\"yellow\",bins=2, label='officier\/capitaine')\nplt.legend()","727af101":"fig, ax = plt.subplots(ncols=1, figsize=(15, 5))\nsns.distplot(df1[df1[\"Pclass\"]==3][\"Age\"].dropna(), color=\"red\",bins=30, label=\"Class 3\")\nsns.distplot(df1[df1[\"Pclass\"]==2][\"Age\"].dropna(), color=\"green\",bins=30, label=\"Class 2\")\nsns.distplot(df1[df1[\"Pclass\"]==1][\"Age\"].dropna(), color=\"blue\",bins=30, label=\"Class 1\")\nplt.legend()","4a3c2d59":"def TransfromAge(df_aux):\n    GroupAge = ['inf-10', '10-18', '18-35', '35-65', 'sup-65']\n    cond1 = (df_aux[\"Age\"].isnull())&(df_aux[\"title\"]==\"Master\")\n    df_aux.loc[cond1, 'Age'] = calcul_median(df_aux,\"Master\")\n\n    cond2 = (df_aux[\"Age\"].isnull())&(df_aux[\"title\"]==\"Miss\")\n    df_aux.loc[cond2, 'Age'] = calcul_median(df_aux,\"Miss\")\n\n    cond3 = (df_aux[\"Age\"].isnull())&(df_aux[\"title\"]==\"Mrs\")\n    df_aux.loc[cond3, 'Age'] = calcul_median(df_aux,\"Mrs\")\n\n    cond4 = (df_aux[\"Age\"].isnull())&(df_aux[\"title\"]==\"Mr\")\n    df_aux.loc[cond4, 'Age'] = calcul_median(df_aux,\"Mr\")\n\n    cond5 = (df_aux[\"Age\"].isnull())&(df_aux[\"title\"]==\"officier\/capitaine\")\n    df_aux.loc[cond5, 'Age'] = calcul_median(df_aux,\"officier\/capitaine\")\n\n    cond6 = (df_aux[\"Age\"].isnull())&(df_aux[\"title\"]==\"royale\")\n    df_aux.loc[cond6, 'Age'] = calcul_median(df_aux,\"royale\")\n    # Age group\n    bins = [0, 10, 18, 35, 65, np.inf]\n    GroupAge = ['inf-10', '10-18', '18-35', '35-65', 'sup-65']\n    df_aux['GroupAge'] = pd.cut(df_aux['Age'], bins, labels=GroupAge)\n    return df_aux\n\ndef calcul_median(df_aux,ch):\n    return df_aux[df_aux[\"title\"]==ch].Age.dropna().median()","07f827f7":"df_test[df_test[\"Fare\"].isnull()]","a28896e5":"fig, ax = plt.subplots(ncols=1, figsize=(15, 5))\nsns.distplot(df1[df1[\"Pclass\"]==3][\"Fare\"].dropna(), color=\"blue\",bins=50, label='Pclass 3')\nplt.legend()","30e2911e":"def TransfromFare(df_aux):\n    df_aux.loc[(df_aux[\"Fare\"].isnull())&(df_aux[\"Pclass\"]==3), 'Fare'] = df_aux[df_aux[\"Pclass\"]==3].Fare.dropna().median()\n    # Fare group\n    bins = [-1,8,14,20,60,100,600]\n    GroupFare = ['0-8\u00a3','8-14\u00a3','14-20\u00a3','20-60\u00a3','60-100\u00a3','100-515\u00a3']\n    df_aux['GroupFare'] = pd.cut(df_aux['Fare'], bins, labels=GroupFare)\n    return df_aux","60f3b9f8":"def TransfromCabin(df_aux):\n    df_aux.loc[(df_aux[\"Cabin\"].isnull()), 'HasOrNotCabinNumber'] = \"Has Not Cabin Number\"\n    df_aux.loc[(df_aux[\"Cabin\"].notnull()), 'HasOrNotCabinNumber'] = \"Has Cabin Number\"\n    return df_aux.drop(columns=[\"Cabin\",\"Ticket\"])","771219f6":"df_train[df_train[\"Embarked\"].isnull()]","cd0bbbf9":"fig, ax = plt.subplots(ncols=2, figsize=(20, 5))\nsns.countplot(x='Embarked', hue=\"Survived\", data=df_train[(df_train[\"Pclass\"]==1)],ax=ax[0])\ndf_train['Embarked'].value_counts().plot.pie(ax=ax[1])\nax[0].set_title('Embarked\/Survived for first class')\nax[1].set_title('value count of Embarked')\nplt.show()","11bd97ed":"def TransfromEmbarked(df_aux):\n    df_aux.loc[(df_aux[\"Embarked\"].isnull())&(df_aux[\"Pclass\"]==1), 'Embarked'] = \"S\"\n    return df_aux","1066479d":"def TransfromFamiliy(df_aux):\n    df_aux[\"familiySize\"] = df_aux[\"SibSp\"] + df_aux[\"Parch\"] + 1\n    \n    AloneTravel = (df_aux['SibSp'] == 0) & (df_aux['Parch'] == 0)\n    CoupleTravel = (df_aux['SibSp'] == 0) & (df_aux['Parch'] == 1)\n    siblingsTravel = (df_aux['SibSp'] == 1) & (df_aux['Parch'] == 0)\n    SmallFamilly = (df_aux['familiySize'] <= 3) & (df_aux['familiySize'] >= 2)\n    BigFamilly =(df_aux['familiySize'] >3)\n    \n    df_aux.loc[AloneTravel, 'familiy'] = \"Alone Travel\"\n    df_aux.loc[CoupleTravel, 'familiy'] = \"Couple Travel\"\n    df_aux.loc[siblingsTravel, 'familiy'] = \"siblings Travel\"\n    df_aux.loc[SmallFamilly, 'familiy'] = \"Small Familly\"\n    df_aux.loc[BigFamilly, 'familiy'] = \"Big Familly\"\n    \n    return df_aux","8fb323e5":"dfTrain = TransfromTitle(df_train)\ndfTrain = TransfromAge(dfTrain)\ndfTrain = TransfromFare(dfTrain)\ndfTrain = TransfromCabin(dfTrain)\ndfTrain = TransfromEmbarked(dfTrain)\ndfTrain = TransfromFamiliy(dfTrain)","d6c1017d":"dfTrain = dfTrain[['familiySize','SibSp','Parch','title','GroupAge','GroupFare','HasOrNotCabinNumber',\n         'Sex','Embarked','Pclass','familiy','Survived']]","3c50322c":"dfTrain.head(10)","5ac96b6d":"dfTest = TransfromTitle(df_test)\ndfTest = TransfromAge(dfTest)\ndfTest = TransfromFare(dfTest)\ndfTest = TransfromCabin(dfTest)\ndfTest = TransfromEmbarked(dfTest)\ndfTest = TransfromFamiliy(dfTest)","f8fbbc75":"dfTest = dfTest[['familiySize','SibSp','Parch','title','GroupAge','GroupFare','HasOrNotCabinNumber',\n         'Sex','Embarked','Pclass','familiy']]","9b2cac22":"dfTest.head(10)","d96e22a1":"from sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.impute import KNNImputer\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler","77fa13fc":"X_train = dfTrain.drop(columns = ['Survived']).values\ny = dfTrain.Survived.values\nX_test = dfTest.values","01095841":"for i in range(len(X_train)):\n    X_train[i,9] = str(X_train[i,9])\n\nX_train[:,0:3] = StandardScaler().fit_transform(X_train[:,0:3])\n\n\nonehotencoder_1 = OneHotEncoder()\nu1 = onehotencoder_1.fit_transform(X_train[:,3:]).toarray()\n\nX_train2 = np.concatenate((X_train[:,0:3], u1), axis=1)\nX_train2.shape","d6335864":"StandardScaler().fit_transform(X_test[:,0:3]).shape\nX_test[:,0:3].shape","e54104fd":"for i in range(len(X_test)):\n    X_test[i,9] = str(X_test[i,9])\n\nX_test[:,0:3] = StandardScaler().fit_transform(X_test[:,0:3])\n\nonehotencoder_2 = OneHotEncoder()\nu2 = onehotencoder_2.fit_transform(X_test[:,3:]).toarray()\n\nX_test2 = np.concatenate((X_test[:,0:3], u2), axis=1)\nX_test2.shape","89417a4d":"from sklearn.pipeline import make_pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\nimport xgboost as xgb","54ed411a":"import xgboost as xgb\nlogreg = LogisticRegression()\nGauss = GaussianNB()\nrf = RandomForestClassifier()\ngboost = GradientBoostingClassifier()\nDTC =  DecisionTreeClassifier()\nRF = RandomForestClassifier(n_estimators=200)\nSVectorMachine = SVC()\nxgb = xgb.XGBClassifier(max_depth=3, n_estimators=10, learning_rate=0.01)\nmodels = [logreg,Gauss, gboost,DTC,RF,SVectorMachine,xgb]","39fdd72b":"def compute_score(clf, X, y, scoring='accuracy'):\n    xval = cross_val_score(clf, X, y, cv = 10, scoring=scoring)\n    return np.mean(xval)","c5a849df":"for model in models:\n    print('Cross-validation of : {0}'.format(model.__class__))\n    score = compute_score(clf=model, X=X_train2, y=y, scoring='accuracy')\n    print('CV score = {0}'.format(score))\n    print('----->>>>>>')","a56f45da":"\nX = np.asarray(X_train2).astype(np.float32)\nY = np.asarray(y).astype(np.float32)","d6605ee9":"from keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\n\nclassifier = Sequential() \nclassifier.add(Dense(units = 35,activation = \"relu\",kernel_initializer=\"uniform\",input_dim=33))\nclassifier.add(Dropout(rate=0.1))\nclassifier.add(Dense(units = 20,activation = \"relu\",kernel_initializer=\"uniform\"))\nclassifier.add(Dense(units = 15,activation = \"relu\",kernel_initializer=\"uniform\"))\nclassifier.add(Dense(units = 1,activation = \"sigmoid\",kernel_initializer=\"uniform\"))\nclassifier.compile(optimizer=\"rmsprop\",loss=\"binary_crossentropy\",metrics=['acc'])\nclassifier.fit(X,Y,batch_size=50,epochs=110)","40a40e92":"result = []\nY_pred = classifier.predict(np.asarray(X_test2).astype(np.float32))\nY_pred = (Y_pred>0.55)\n\nfor i in range(len(Y_pred)):\n    if Y_pred[i][0] == True :\n        result.append(1)\n    else :\n        result.append(0)\nPassengerId = df_test[\"PassengerId\"] # PassengerId,Survived\nSurvivedResult = pd.DataFrame({'Survived': result})\nresults = pd.concat([PassengerId,SurvivedResult],axis=1)\nresults.to_csv(\"gender_submission.csv\",sep = ',',index=False)","9b72adc3":"results","89ce5980":"<div class=\"alert alert-block alert-warning\">  \n<b> Observation 1 :<\/b> We can see that the women survived the sinking of the titanic more than the men. We can also note that the passengers of the first class were more lucky than the other passengers of the third and second class.\n<\/div>","8d09fde6":"<div class=\"alert alert-block alert-danger\">  \nNote : As can be seen, several values are missing in the Age columns. Replacing missing values with the average is not the best solution.   \n<\/div>","144d0d4e":"## Simple Neural network","f4eb5c40":"#### Training set ","b0d641b3":"### Age processing : ","06b47599":"##### Encode Train Set","cfad09fa":"### Embarked processing :","32ccac1a":"<div class=\"alert alert-block alert-warning\">  \n<b> Observation 2 :<\/b> We replace the missing values of the age variable according to the title variable. For this we use the median\n<\/div>","4a1451d5":"#### Testing set ","32868bfe":"## First visualization","54db9d69":"##### Encode Train Test","d0b8bd68":"<div class=\"alert alert-block alert-warning\">  \n<b> <\/b> Please upvote if you enjoy .Thanks\n<\/div>","c078fd8f":"<img src=\"https:\/\/www.disneyphile.fr\/wp-content\/uploads\/2019\/03\/titanic-2-possible-to-sail-by-2022-the-exact-replica-of-original-following-same-route-1540364496.jpg\" alt=\"Meatball Sub\" width=\"500\"\/>","9e274a33":"#### Transforming ....","70063f78":"## Part 1 : Data analysis\n\n#### Variable Notes\n\n- pclass: A proxy for socio-economic status (1st = Upper, 2nd = Middle, 3rd = Lower)\n- age: Passenger Age\n- sibsp:  siblings \/ spouses aboard the Titani\n- parch:  of parents \/ children aboard the Titanic\n- fare:\tPassenger fare\n- sex :\tmale\/female\n- Embarked : Port of Embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)\n\n#### Variable analysis (Train Set)\n\n- **Target variable** : Survived. 549 not survived ,342 survived\n- **Nombre of columns\/rows** : 12 columns and 891 rows \n- **Variable type :** We have 5 variables of type float64, 5 variables of type int64 and 5 variables of type object.\n\n#### Variable analysis (Test Set)\n\n- **Nombre of columns\/rows** : 12 columns and 891 rows \n- **Variable type :** We have 5 variables of type float64, 4 variables of type int64 and 5 variables of type object.","d8b1d29b":"### SibSp and Parch processing : ","9ddc8929":"### Cabin processing : ","bbb5d8d1":"### Fare processing : ","9ed9f7fd":"# Titanic: Machine Learning from Disaster","ab204b11":"## Missing Value","233f2ecc":"<div class=\"alert alert-block alert-warning\">  \n<b> Observation 3 :<\/b> We have one missing value for Fare variable.\n<\/div>"}}