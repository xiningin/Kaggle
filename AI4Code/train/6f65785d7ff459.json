{"cell_type":{"0e0b2f75":"code","ba8c268f":"code","b59afb06":"code","e3629453":"code","a141cb41":"code","edeac3ed":"code","57e35fe4":"code","df6c887a":"code","8e6a06ea":"code","6964e411":"code","728d5088":"code","b0597a8d":"code","2111f963":"code","e4c41725":"code","d4f76706":"code","b7d8eb7d":"code","f3931a85":"markdown","009f2079":"markdown","a98a73c9":"markdown","91e4d379":"markdown","b9adf0e9":"markdown","2aa42607":"markdown","486f2466":"markdown","69fbe392":"markdown","cf461975":"markdown","8ed89394":"markdown","ba702539":"markdown","31b93756":"markdown","39229658":"markdown"},"source":{"0e0b2f75":"!pip install timm","ba8c268f":"import os\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\nfrom pytorch_lightning.metrics.functional import accuracy\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport albumentations as albu\nfrom albumentations.pytorch.transforms import ToTensorV2\nfrom sklearn.model_selection import StratifiedKFold\nimport timm","b59afb06":"import random\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nseed_everything()","e3629453":"FOLDS = 10\nBATCH_SIZE =16\nLR = 0.0001\nEPOCHS=4\nSMOOTHING = 0.1\n\nLOSS_FUNCTION = F.mse_loss\n\nIMG_SIZE = 240\nIMG_SIZE = 400\n\nEARLY_STOPPING = True\n\nMODEL_ARCH = 'resnet50'\nMODEL_ARCH = 'tf_efficientnet_b1_ns'\nMODEL_ARCH = 'efficientnet_b3'\nMODEL_ARCH = 'tf_efficientnet_b4_ns'\n\nIMAGE_FOLDER = '..\/input\/banana-count-and-weight-in-a-bunch\/Images\/Images'","a141cb41":"banana_df = pd.read_csv('..\/input\/banana-count-and-weight-in-a-bunch\/Estu.csv')\nbanana_df.shape","edeac3ed":"banana_df.sample(9)","57e35fe4":"samples = banana_df.sample(9)\nfig, ax = plt.subplots(nrows=3, ncols=3, figsize=(16, 16))\ncount=0\nfor row in ax:\n    for col in row:\n        col.imshow(plt.imread('..\/input\/banana-count-and-weight-in-a-bunch\/Images\/Images\/'+samples.iloc[count]['File Name']))\n        col.set_title(f'Count:{samples.iloc[count][\"Banana Count\"]}, Weight:{samples.iloc[count][\"Weight\"]}kg')\n        count += 1\nplt.show()","df6c887a":"banana_df.describe()","8e6a06ea":"unique_branch_ids = banana_df['Bunch ID'].unique()\nnp.random.shuffle(unique_branch_ids)\nbanana_df.loc[banana_df['Bunch ID'].isin(unique_branch_ids[0:4]),'kfold'] = 0\nbanana_df.loc[banana_df['Bunch ID'].isin(unique_branch_ids[4:8]),'kfold'] = 1\nbanana_df.loc[banana_df['Bunch ID'].isin(unique_branch_ids[8:12]),'kfold'] = 2\nbanana_df.loc[banana_df['Bunch ID'].isin(unique_branch_ids[12:16]),'kfold'] = 3\nbanana_df.loc[banana_df['Bunch ID'].isin(unique_branch_ids[16:22]),'kfold'] = 4\nbanana_df.to_csv(\"train_folds.csv\", index=False)","6964e411":"def get_augmentations():\n    \n    mean = (0.485, 0.456, 0.406)\n    std = (0.229, 0.224, 0.225) \n    \n    train_augmentations = albu.Compose([\n        albu.RandomResizedCrop(IMG_SIZE, IMG_SIZE, p=1.0),\n        albu.Transpose(p=0.5),\n        albu.HorizontalFlip(p=0.5),\n#         albu.VerticalFlip(0.5),\n        albu.CoarseDropout (p=0.5),\n        albu.Normalize(always_apply=True),        \n        ToTensorV2(p=1.0)\n    ], p=1.0)\n    \n    valid_augmentations = albu.Compose([\n        albu.Resize(IMG_SIZE, IMG_SIZE),\n        albu.Normalize(always_apply=True),        \n        ToTensorV2(p=1.0)\n    ], p=1.0)   \n    \n    return train_augmentations, valid_augmentations\n\ntrain_augs, val_augs = get_augmentations()","728d5088":"class BananaDataset(Dataset):\n    def __init__(self, data, is_testing=False, transforms=None):\n        self.data = data\n        self.is_testing = is_testing\n        self.transforms = transforms\n        \n    def __len__(self):\n        return self.data.shape[0]\n    \n    def __getitem__(self, index):        \n        image_path = f\"{IMAGE_FOLDER}\/{self.data.iloc[index]['File Name']}\"\n        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.transforms:\n            transformed = self.transforms(image = image)\n            image = transformed['image']  # this is of type tensor\n            \n        if self.is_testing:\n            item = {\n                \"image_name\": self.data.iloc[index]['File Name'],\n                \"image\": image \n            }\n        else:\n            y_count = self.data.iloc[index]['Banana Count']\n            y_weight = self.data.iloc[index]['Weight']\n            item = {\n                \"image_name\": self.data.iloc[index]['File Name'],\n                \"image\": image,\n                \"weight\": torch.tensor(y_weight, dtype = torch.float32),\n                \"count\": torch.tensor(y_count, dtype = torch.float32)\n            }\n        return item","b0597a8d":"class BananaNNModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = timm.create_model(MODEL_ARCH, pretrained=False)        \n        n_features = 1792\n        self.model.pooling = nn.AdaptiveAvgPool2d(1)\n        self.model.weightRegressor = nn.Linear(n_features, 1)\n        self.model.countRegressor = nn.Linear(n_features, 1)\n    \n    def forward(self, x):\n        x = self.model.forward_features(x)\n        x = self.model.pooling(x)\n        x = x.flatten(1)\n        pr_weight = self.model.weightRegressor(x)\n        pr_count = self.model.countRegressor(x)\n        return pr_weight.squeeze(), pr_count.squeeze()","2111f963":"class BananaDataModule(pl.LightningDataModule):\n    def __init__(self, fold):\n        super().__init__()\n        self.train_aug, self.val_aug = get_augmentations()\n        self.fold = fold\n        \n    def setup(self, stage=None):\n        train_fold = banana_df.loc[banana_df['kfold'] != self.fold]\n        val_fold = train_fold = banana_df.loc[banana_df['kfold'] == self.fold]\n        self.train_ds = BananaDataset(train_fold, transforms = self.train_aug)\n        self.val_ds = BananaDataset(val_fold, transforms = self.val_aug)\n        \n    def train_dataloader(self):\n        return DataLoader(self.train_ds, BATCH_SIZE, num_workers=4, shuffle=True)\n        \n    def val_dataloader(self):\n        return DataLoader(self.val_ds, BATCH_SIZE, num_workers=4, shuffle=False)                ","e4c41725":"class BananaModule(pl.LightningModule):\n    def __init__(self, hparams, model):\n        super(BananaModule, self).__init__()\n        self.hparams = hparams\n        self.loss_function = LOSS_FUNCTION\n        self.model = model\n        self.accuracy = pl.metrics.Accuracy\n        \n    def forward(self, x):\n        return self.model(x)\n    \n    def training_step(self, batch, batch_index):\n        weight_prediction, count_prediction = self(batch['image'])\n#         import pdb; pdb.set_trace()\n        weight_loss = self.loss_function(weight_prediction, batch['weight'])\n        count_loss = self.loss_function(count_prediction, batch['count'])\n        loss = weight_loss + count_loss\n        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True,logger=True)\n        return loss\n    \n    def validation_step(self, batch, batch_index): \n        weight_prediction, count_prediction = self(batch['image'])\n        weight_loss = self.loss_function(weight_prediction, batch['weight'])\n        count_loss = self.loss_function(count_prediction, batch['count'])\n        loss = weight_loss + count_loss\n        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True,logger=True)    \n    \n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams['lr'])\n        scheduler = {\n            'scheduler': \n                torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n                    optimizer, \n                    15,\n                    verbose=False\n                ),\n            'interval': 'step',\n            'monitor' : 'train_loss'\n        }\n        return [optimizer], [scheduler]          ","d4f76706":"def train(fold):\n    callbacks = []\n    \n    checkpoint_cb = ModelCheckpoint(\n        dirpath='checkpoints\/',\n        filename='model_{val_loss:.2f}',\n        monitor='val_loss', verbose=True,\n        save_last=False, save_top_k=1, save_weights_only=False,\n        mode='min', period=1\n    )\n    callbacks.append(checkpoint_cb)\n    \n    early_stopping_cb = EarlyStopping('val_loss', patience=3, verbose=True, mode='min')\n    callbacks.append(early_stopping_cb)\n    \n    trainer = pl.Trainer(\n        gpus=-1,\n        precision=16,\n        max_epochs=EPOCHS,\n        accumulate_grad_batches=1, # NEW NEW NEW NEW NEW NEW NEW NEW NEW\n        callbacks=callbacks        \n    )\n    \n    model = BananaNNModel()\n    pl_dm = BananaDataModule(fold)\n    pl_module = BananaModule(hparams={'lr':LR, 'batch_size':BATCH_SIZE}, model=model)\n    trainer.fit(pl_module, pl_dm)","b7d8eb7d":"for fold in range(FOLDS):\n    train(fold)","f3931a85":"### Sample images\nYou can note that some images are in landscape mode. You may have to rotate them in your dataset","009f2079":"### Augmentations","a98a73c9":"### Dataset","91e4d379":"### NN Model - Multi output regressor","b9adf0e9":"### Import Libraries","2aa42607":"### Simple EDA","486f2466":"### Load Data","69fbe392":"### What is a banana bunch?  \nAs you can see in above images, each bunch is nothing but a complete fruit-set from the banana tree.","cf461975":"### KFold\nEvery fold will have 4 bunches and the last fold will have 6 bunches.","8ed89394":"### Pytorch Lightning Data Module\nPrepares data and prepares dataloaders","ba702539":"### Hyperparameters","31b93756":"There are 22 unique branches in the dataset. However there are 713 images to train on. While creating cross validation (CV) we have to ensure that images of the same bunch are not in training and validation set, so as to prevent a validation leak.","39229658":"### Train"}}