{"cell_type":{"39d6d7b1":"code","e70e5f0a":"code","46ab88d9":"code","2e39f66a":"code","43b2cff6":"code","628521c9":"code","c9facb92":"code","ce423add":"code","c706b1f0":"code","289f1f19":"code","9ea0525c":"code","6341240f":"code","71e1a157":"code","b5956362":"code","866cf81b":"code","b41b1091":"code","29a3f1f5":"code","ab6db1d4":"code","2eb0476a":"code","9ad33eea":"code","7f3fae53":"code","4f56f32c":"code","fba7a676":"code","df548e15":"code","8f2069cd":"code","611d9ce1":"code","cd8b42b5":"code","14c54c24":"code","1fc660f9":"code","e17cf8f7":"code","5a5912a6":"code","7303bf70":"code","287f27f3":"code","adab1e01":"code","55dd7eb5":"code","1f8b6e7f":"markdown","b321cbdc":"markdown","4f7acefe":"markdown","e0ac1b66":"markdown","d357bdff":"markdown","5b1c7d45":"markdown","8cf8af8f":"markdown","4b3695a2":"markdown","75094761":"markdown","936223eb":"markdown","3facaf6c":"markdown","eb4bd3c6":"markdown","e5f9f360":"markdown","ea7e80c0":"markdown","7dc368b3":"markdown","0c90d503":"markdown"},"source":{"39d6d7b1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e70e5f0a":"t1 = pd.read_csv('\/kaggle\/input\/usage-of-parking-lots-in-lisbon-portugal\/1t2020.csv',delimiter=';')\nt2 = pd.read_csv('\/kaggle\/input\/usage-of-parking-lots-in-lisbon-portugal\/2t2020.csv',delimiter=';')\nt4 = pd.read_csv('\/kaggle\/input\/usage-of-parking-lots-in-lisbon-portugal\/4t2020.csv',delimiter=';')","46ab88d9":"t1.datetime = pd.to_datetime(t1.datetime)\nt1.entity_ts = pd.to_datetime(t1.entity_ts)","2e39f66a":"t2.datetime = pd.to_datetime(t2.datetime)\nt2.entity_ts = pd.to_datetime(t2.entity_ts)","43b2cff6":"t4.datetime = pd.to_datetime(t4.datetime)\nt4.entity_ts = pd.to_datetime(t4.entity_ts)","628521c9":"df = t1.append(t2).append(t4)","c9facb92":"df.describe()","ce423add":"df.info()","c706b1f0":"df.id_park.unique()","289f1f19":"print(f'unique ids:'+str(df.id_park.nunique()))\nprint(f'unique names:'+str(df.name.nunique()))\nprint(f'unique positions:'+str(df.position.nunique()))","9ea0525c":"df.groupby('position').agg({'id_park':'nunique','name':'nunique'})","6341240f":"df[df.position == \"{'coordinates': [-9.128867, 38.716819], 'type': 'Point'}\"]['name'].unique()","71e1a157":"df[df.position == \"{'coordinates': [-9.128867, 38.716819], 'type': 'Point'}\"]['id_park'].unique()","b5956362":"df.name.replace(to_replace='Olivais',value='Parque da Gra\u00e7a',inplace=True)\ndf.id_park.replace(to_replace='P064',value='P062',inplace=True)","866cf81b":"df.groupby('position').agg({'id_park':'nunique','name':'nunique'})","b41b1091":"df[df.occupancy<0]","29a3f1f5":"df = df[df.occupancy>0]","ab6db1d4":"df.describe()","2eb0476a":"import json as j","9ad33eea":"parks = df.groupby('id_park').agg({'name':'unique','position':'unique'})","7f3fae53":"parks.position","4f56f32c":"def transform(x):\n    \n    s = x[0].replace(\"'\",'\"') #since json needes double quotes to keys\n    obj = j.loads(s) #use the loads function to create the obj\n    return obj #return obj\n\ns = parks.position[0][0].replace(\"'\",'\"')","fba7a676":"parks.position = parks.position.apply(transform)","df548e15":"parks.position[0]['coordinates'][0]","8f2069cd":"pd.json_normalize(parks['position'])","611d9ce1":"parks_temp = pd.concat([parks.reset_index(),pd.json_normalize(parks['position'])],ignore_index=True,axis=1)","cd8b42b5":"parks_temp.head()","14c54c24":"parks_temp.columns=['id','name','position','coordinates','type']","1fc660f9":"parks_temp.head()","e17cf8f7":"parks_temp['long'] = parks_temp.coordinates.apply(lambda x: x[0])\nparks_temp['lat'] = parks_temp.coordinates.apply(lambda x: x[1])\nparks_temp.name = parks_temp.name.apply(lambda x: x[0])","5a5912a6":"parks = parks_temp.drop(['position','coordinates'],axis=1)","7303bf70":"parking_lots = parks","287f27f3":"parking_lots.to_csv('parking_lots.csv',index=False)","adab1e01":"occupancy_data = df.drop(['position'],axis=1)","55dd7eb5":"occupancy_data.to_csv('occupancy_data.csv',index=False)","1f8b6e7f":"drop these rows","b321cbdc":"# Export data","4f7acefe":"## Infer datetime","e0ac1b66":"It is curious that occupancy has negative values, Investigate it!","d357bdff":"# Data exploring\n\nVerify if data is consistent","5b1c7d45":"Inconsistency found! Investigate","8cf8af8f":"# Data spliting","4b3695a2":"## Verify unique values for park id name and position","75094761":"## Verify negative occupancy","936223eb":"## Positions\n\nTransform every input to a json to facilitate manipulation","3facaf6c":"{'coordinates': [-9.128867, 38.716819], 'type': 'Point'} has 2 ids and names","eb4bd3c6":"### Create 3 new columns: lat,long type","e5f9f360":"# Data Import","ea7e80c0":"After researching, I've concluded that they are the same parking place.  \nSolution: rename Olivais to parque da gra\u00e7a, since it is the only one with information in the EMEL's website","7dc368b3":"# Setup\n\n## Library Import","0c90d503":"# Raw data ETL\n\n## Purpose\n\nThis notebook loads the files and proceed to cleaning and transforming data to ease the utilization for further data analysis\n\n## TODO'S\n\n- [x] Join the 3 csv's files into a single one\n- [x] create a a separate file containing unique parks names, ids and position\n\n## Results\n\nasdsdsdfdsd"}}