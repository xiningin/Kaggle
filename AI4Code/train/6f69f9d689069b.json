{"cell_type":{"59a102d3":"code","c690b6cf":"code","fdbd6178":"code","654d7945":"code","3d22637d":"code","df286720":"code","5119ce86":"code","29d2f8b9":"code","332c8bc6":"code","d5ad2110":"code","2265d372":"code","03d22260":"code","2dd35098":"markdown"},"source":{"59a102d3":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nprint(os.listdir(\"..\/input\"))","c690b6cf":"# Read the data file\ndata = pd.read_csv('..\/input\/data.csv')\ndata.head()","fdbd6178":"# Import libraries\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n%matplotlib inline","654d7945":"# Check for missing values\n#data.isnull().sum()\ndata.info()","3d22637d":"# Preprocessing data set\n\n# Drop unnecessary columns\ncols_drop = ['id', 'Unnamed: 32']\ndata = data.drop(cols_drop, axis=1)\n# Encode diagnosis label\ndata['diagnonis'] = data['diagnosis'].map({'M':1,'B':0})\n# Featureset creation\nX = data.drop('diagnosis', axis=1).values\nX = StandardScaler().fit_transform(X)","df286720":"#1 KMeans Clustering >> k=2 i.e. either Malignant or Benign\n\nfrom sklearn.cluster import KMeans\nkm = KMeans(n_clusters=2, init=\"k-means++\", n_init=10)\nkm_pred = km.fit_predict(X)\n#labels = km.labels_\n\n# Scatter plots\nf, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n\nax1.scatter(X[:,0], X[:,1], c=data[\"diagnosis\"], cmap=\"jet\", edgecolor=\"None\", alpha=0.35)\nax1.set_title(\"Actual clusters\")\n\nax2.scatter(X[:,0], X[:,1], c=km_pred, cmap=\"jet\", edgecolor=\"None\", alpha=0.35)\nax2.set_title(\"KMeans clustering plot\")","5119ce86":"#2 Hierarchical Agglomerative Clustering \n\nfrom sklearn.cluster import AgglomerativeClustering\nac = AgglomerativeClustering(n_clusters=2, linkage=\"ward\")\nac_pred = ac.fit_predict(X)\n\n# Scatter plots\nf, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n\nax1.scatter(X[:,0], X[:,1], c=data[\"diagnosis\"], cmap=\"jet\", edgecolor=\"None\", alpha=0.35)\nax1.set_title(\"Actual clusters\")\n\nax2.scatter(X[:,0], X[:,1], c=ac_pred, cmap=\"jet\", edgecolor=\"None\", alpha=0.35)\nax2.set_title(\"Agglomeratve clustering plot\")","29d2f8b9":"#3 DBSCAN (Density-Based Clustering of Applications with Noise)\n\nfrom sklearn.cluster import DBSCAN\ndbs = DBSCAN(eps=0.2, min_samples=6)\ndbs_pred = dbs.fit_predict(X)\n\n# Scatter plots\nf, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n\nax1.scatter(X[:,0], X[:,1], c=data[\"diagnosis\"], cmap=\"jet\", edgecolor=\"None\", alpha=0.35)\nax1.set_title(\"Actual clusters\")\n\nax2.scatter(X[:,0], X[:,1], c=dbs_pred, cmap=\"jet\", edgecolor=\"None\", alpha=0.35)\nax2.set_title(\"DBSCAN clustering plot\")","332c8bc6":"#4 MeanShift Clustering\n\nfrom sklearn.cluster import MeanShift, estimate_bandwidth\nbandwidth = estimate_bandwidth(X, quantile=0.2, n_samples=500)\nms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\nms_pred = ms.fit_predict(X)\n\n# Scatter plots\nf, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n\nax1.scatter(X[:,0], X[:,1], c=data[\"diagnosis\"], cmap=\"jet\", edgecolor=\"None\", alpha=0.35)\nax1.set_title(\"Actual clusters\")\n\nax2.scatter(X[:,0], X[:,1], c=ms_pred, cmap=\"jet\", edgecolor=\"None\", alpha=0.35)\nax2.set_title(\"MeanShift clustering plot\")","d5ad2110":"#5 Spectral Clustering\n\nfrom sklearn.cluster import SpectralClustering\nsc = SpectralClustering(n_clusters=2, gamma=0.5, affinity=\"rbf\", assign_labels=\"discretize\")\nsc_pred = sc.fit_predict(X)\n\n# Scatter plots\nf, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n\nax1.scatter(X[:,0], X[:,1], c=data[\"diagnosis\"], cmap=\"jet\", edgecolor=\"None\", alpha=0.35)\nax1.set_title(\"Actual clusters\")\n\nax2.scatter(X[:,0], X[:,1], c=sc_pred, cmap=\"jet\", edgecolor=\"None\", alpha=0.35)\nax2.set_title(\"Spectral clustering plot\")","2265d372":"#6 Gaussian Mixture with Expectation Maximization (EM) Clustering\n# Uses all specified components to fit.\n\nfrom sklearn.mixture import GaussianMixture\ngm = GaussianMixture(n_components=2, covariance_type=\"full\")\ngm_pred = gm.fit_predict(X)\n\n# Scatter plots\nf, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n\nax1.scatter(X[:,0], X[:,1], c=data[\"diagnosis\"], cmap=\"jet\", edgecolor=\"None\", alpha=0.35)\nax1.set_title(\"Actual clusters\")\n\nax2.scatter(X[:,0], X[:,1], c=gm_pred, cmap=\"jet\", edgecolor=\"None\", alpha=0.35)\nax2.set_title(\"Gaussian Mix-EM clustering plot\")","03d22260":"#7 Gaussian Mixture with Variation Inference (VI) Clustering >> Dirichlet process.\n# Uses only as much as needed components for a good fit.\n\nfrom sklearn.mixture import BayesianGaussianMixture\nbgm = BayesianGaussianMixture(n_components=2, covariance_type=\"full\")\nbgm_pred = bgm.fit_predict(X)\n\n# Scatter plots\nf, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n\nax1.scatter(X[:,0], X[:,1], c=data[\"diagnosis\"], cmap=\"jet\", edgecolor=\"None\", alpha=0.35)\nax1.set_title(\"Actual clusters\")\n\nax2.scatter(X[:,0], X[:,1], c=bgm_pred, cmap=\"jet\", edgecolor=\"None\", alpha=0.35)\nax2.set_title(\"Gaussian Mix-VI clustering plot\")","2dd35098":"**Breast Cancer Wisconsin (Diagonistic) Data Set Cluster Analysis Using Different Techniques...**\n> Two major clusters expected === Malignant(M) and Benign(B) ===\n\n> **Techniques Implemented**\n\n>> KMeans Clustering\n\n>> Hierarchical Agglomerative Clustering  \n\n>> DBSCAN (Density-Based Clustering of Applications with Noise) \n\n>> MeanShift Clustering\n\n>> Spectral Clustering\n\n>> Gaussian Mixture with Expectation Maximization (EM) Clustering\n\n>> Gaussian Mixture with Variation Inference (VI) Clustering a.k.a Dirichlet Process\n"}}