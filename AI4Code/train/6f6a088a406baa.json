{"cell_type":{"b04562ea":"code","0fe8b6f7":"code","b69d56d4":"markdown"},"source":{"b04562ea":"import pandas as pd\nimport numpy as np\n\nimport torch\nimport random\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nrandom.seed(777)\ntorch.manual_seed(777)\nif device == 'cuda' :\n    torch.cuda.manual_seed_all(777)\n","0fe8b6f7":"# \ud559\uc2b5 \ud30c\ub77c\ubbf8\ud130 \uc124\uc815\nlearning_rate = 0.0001\ntraining_epochs = 2500\nbatch_size = 15\n\n# Data load\ntrain_data = pd.read_csv('..\/input\/crime-types\/train_data.csv', header=None, skiprows=1, usecols=range(0, 13))\ntest_data = pd.read_csv('..\/input\/crime-types\/test_data.csv', header=None, skiprows=1, usecols=range(0, 12))\n\n# Data \ud30c\uc2f1\nx_train_data = train_data.loc[:, 1:13]\ny_train_data = train_data.loc[:, 0]\n\n# \ud30c\uc2f1\ud55c Data\ub97c numpy\uc758 array\ub85c \ubcc0\ud658\nx_train_data = np.array(x_train_data)\ny_train_data = np.array(y_train_data)\n\ntest_data = np.array(test_data)\n\n# \ubcc0\ud658\ud55c numpy\uc758 array\ub97c Tensor\ub85c \ubcc0\ud658\nx_train_data = torch.FloatTensor(x_train_data)\ny_train_data = torch.LongTensor(y_train_data)\n\ntest_data = torch.FloatTensor(test_data)\n\n# data_loader\uc5d0 \uc774\uc6a9\ud560 \ud558\ub098\uc758 train Dataset\uc73c\ub85c \ubcc0\ud658\ntrain_dataset = torch.utils.data.TensorDataset(x_train_data, y_train_data)\n\n# data_loader \uc124\uc815\ndata_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                          batch_size=batch_size,\n                                          shuffle=True,\n                                          drop_last=True)\n\n# \ubaa8\ub378 \uc124\uacc4\nlinear1 = torch.nn.Linear(12, 256, bias=True)\nlinear2 = torch.nn.Linear(256, 256, bias=True)\nlinear3 = torch.nn.Linear(256, 256, bias=True)\nlinear4 = torch.nn.Linear(256, 512, bias=True)\nlinear5 = torch.nn.Linear(512, 1024, bias=True)\nlinear6 = torch.nn.Linear(1024, 1024, bias=True)\nlinear7 = torch.nn.Linear(1024, 512, bias=True)\nlinear8 = torch.nn.Linear(512, 512, bias=True)\nlinear9 = torch.nn.Linear(512, 256, bias=True)\nlinear10 = torch.nn.Linear(256, 7, bias=True)\nleakyrelu = torch.nn.LeakyReLU()\n\ntorch.nn.init.xavier_normal_(linear1.weight)\ntorch.nn.init.xavier_normal_(linear2.weight)\ntorch.nn.init.xavier_uniform_(linear3.weight)\ntorch.nn.init.xavier_normal_(linear4.weight)\ntorch.nn.init.xavier_uniform_(linear5.weight)\ntorch.nn.init.xavier_normal_(linear6.weight)\ntorch.nn.init.xavier_normal_(linear7.weight)\ntorch.nn.init.xavier_normal_(linear8.weight)\ntorch.nn.init.xavier_uniform_(linear9.weight)\ntorch.nn.init.xavier_normal_(linear10.weight)\n\nmodel = torch.nn.Sequential(linear1, leakyrelu,\n                            linear2, leakyrelu,\n                            linear3, leakyrelu,\n                            linear4, leakyrelu,\n                            linear5, leakyrelu,\n                            linear6, leakyrelu,\n                            linear7, leakyrelu,\n                            linear8, leakyrelu,\n                            linear9, leakyrelu,\n                            linear10).to(device)\n\nloss = torch.nn.CrossEntropyLoss().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\n# \ubaa8\ub378 \ud559\uc2b5\ntotal_batch = len(data_loader)\n\nfor epoch in range(training_epochs) :\n    avg_cost = 0\n\n    for X, Y in data_loader :\n\n        X = X.to(device)\n        Y = Y.to(device)\n\n        optimizer.zero_grad()\n        hypothesis = model(X)\n        cost = loss(hypothesis, Y)\n        cost.backward()\n        optimizer.step()\n\n        avg_cost += cost \/ total_batch\n\n    print('Epoch : {:4d}'.format(epoch+1), 'Cost : {:.9f}'.format(avg_cost))\n\nprint('Learning Finishied')\n\n# \ubaa8\ub378 \ud3c9\uac00\nwith torch.no_grad() :\n    test_data = test_data.to(device)\n\n    prediction = model(test_data)\n    prediction = torch.argmax(prediction, 1)\n    prediction = prediction.cpu().numpy().reshape(-1, 1)\n\nsubmit = pd.read_csv('submission_format.csv')\n\nfor i in range(len(prediction)) :\n    submit['Lable'][i] = prediction[i].item()\n\nsubmit.to_csv('result.csv', index=False, header=True)\n ","b69d56d4":"## \ucc28\ubcc4\uc810\n- \ub7ec\ub2dd\ub808\uc774\ud2b8 0.01->0.0001\n- \uc5d0\ud3ec\ud06c 2000->2500\n- \uad6c\uc870\ub97c 13\uce35\uc5d0\uc11c 10\uce35\uc73c\ub85c\n- \ud65c\uc131\ud568\uc218 ELU -> leakyReLU\n- optimizer : Adagrad->Adam"}}