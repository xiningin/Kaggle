{"cell_type":{"50719a95":"code","4cbe81a9":"code","5df90446":"code","8a9b8c0f":"code","8a2be7ce":"code","2f67123c":"code","e3394589":"code","f2026c57":"code","052824e2":"code","8797a734":"code","ff99b17c":"code","c23e0273":"code","124f101a":"code","7742b95a":"code","b4f1c861":"code","28c34427":"code","95fd8b0c":"code","7bc83039":"code","ba435745":"code","173526cc":"code","63cb9221":"code","a48211a0":"code","555d7bd9":"code","bdfd0b7d":"code","dac1e429":"code","c5d03d6a":"code","3654133f":"code","b93e986d":"code","97bda169":"code","36c145d9":"markdown","4d3fca92":"markdown","b9b5c260":"markdown","370c8b56":"markdown","52845285":"markdown"},"source":{"50719a95":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport bz2\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","4cbe81a9":"trainfile = bz2.BZ2File('..\/input\/train.ft.txt.bz2','r')\nlines = trainfile.readlines()","5df90446":"lines[1]","8a9b8c0f":"docSentimentList=[]\ndef getDocumentSentimentList(docs,splitStr='__label__'):\n    for i in range(len(docs)):\n        #print('Processing doc ',i,' of ',len(docs))\n        text=str(lines[i])\n        #print(text)\n        splitText=text.split(splitStr)\n        secHalf=splitText[1]\n        text=secHalf[2:len(secHalf)-1]\n        sentiment=secHalf[0]\n        #print('First half:',secHalf[0],'\\nsecond half:',secHalf[2:len(secHalf)-1])\n        docSentimentList.append([text,sentiment])\n    print('Done!!')\n    return docSentimentList","8a2be7ce":"docSentimentList=getDocumentSentimentList(lines[:1000000],splitStr='__label__')","2f67123c":"train_df = pd.DataFrame(docSentimentList,columns=['Text','Sentiment'])\ntrain_df.head()","e3394589":"train_df['Sentiment'][train_df['Sentiment']=='1'] = 0\ntrain_df['Sentiment'][train_df['Sentiment']=='2'] = 1","f2026c57":"train_df['Sentiment'].value_counts()","052824e2":"train_df['word_count'] = train_df['Text'].str.lower().str.split().apply(len)\ntrain_df.head()","8797a734":"import string \ndef remove_punc(s):\n    table = str.maketrans({key: None for key in string.punctuation})\n    return s.translate(table)","ff99b17c":"train_df['Text'] = train_df['Text'].apply(remove_punc)\ntrain_df.shape","c23e0273":"train_df.head()","124f101a":"len(train_df['word_count'][train_df['word_count']<=25])","7742b95a":"train_df1 = train_df[:][train_df['word_count']<=25]\ntrain_df1.head()","b4f1c861":"train_df1['Sentiment'].value_counts()","28c34427":"from sklearn.feature_extraction import text\nfrom sklearn.feature_extraction.text import CountVectorizer\nst_wd = text.ENGLISH_STOP_WORDS\nc_vector = CountVectorizer(stop_words = st_wd,min_df=.0001,lowercase=1)\nX_counts = c_vector.fit_transform(train_df1['Text'].values)","95fd8b0c":"X_counts","7bc83039":"from sklearn.model_selection import train_test_split\ny = train_df1['Sentiment'].values\nX_train, X_test, y_train, y_test = train_test_split(X_counts, y, test_size=0.1, random_state=42)","ba435745":"X_train = X_train.todense()\nX_test = X_test.todense()","173526cc":"X_train.shape","63cb9221":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\n\nmodel1=  Sequential()\nmodel1.add(Dense(1000,input_shape=(8915,),activation='relu'))\nmodel1.add(Dense(1,activation='sigmoid'))\n\nmodel1.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\nhist = model1.fit(X_train,y_train,epochs=6,batch_size=128,verbose=1)","a48211a0":"model1.evaluate(X_test, y_test, batch_size=128)","555d7bd9":"model1.evaluate(X_train, y_train, batch_size=128)","bdfd0b7d":"model2=  Sequential()\nmodel2.add(Dense(1000,input_shape=(8915,),activation='relu'))\nmodel2.add(Dense(500,activation='relu'))\nmodel2.add(Dense(1,activation='sigmoid'))\n\nmodel2.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\nhist2 = model2.fit(X_train,y_train,epochs=6,batch_size=128,verbose=1)\n","dac1e429":"model3=  Sequential()\nmodel3.add(Dense(2000,input_shape=(8915,),activation='relu'))\nmodel3.add(Dense(1000,activation='relu'))\nmodel3.add(Dense(500,activation='relu'))\nmodel3.add(Dense(1,activation='sigmoid'))\n\nmodel3.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\nhist3 = model3.fit(X_train,y_train,epochs=6,batch_size=128,verbose=1)\n","c5d03d6a":"model2.evaluate(X_test, y_test, batch_size=128)","3654133f":"model3.evaluate(X_test, y_test, batch_size=128)","b93e986d":"import matplotlib.pyplot as plt\nloss_curve = hist.history['loss']\nepoch_c = list(range(len(loss_curve)))\nloss_curve2 = hist2.history['loss']\nepoch_c = list(range(len(loss_curve)))\nloss_curve3 = hist3.history['loss']\nepoch_c = list(range(len(loss_curve)))\nplt.xlabel('Epochs')\nplt.ylabel('Loss value')\nplt.plot(epoch_c,loss_curve,label='1 Hidden layer')\nplt.plot(epoch_c,loss_curve2,label='2 Hidden layers')\nplt.plot(epoch_c,loss_curve3,label='3 Hidden layers')\nplt.legend()\nplt.show()","97bda169":"acc_curve = hist.history['acc']\nepoch_c = list(range(len(loss_curve)))\nacc_curve2 = hist2.history['acc']\nepoch_c = list(range(len(loss_curve)))\nacc_curve3 = hist3.history['acc']\nepoch_c = list(range(len(loss_curve)))\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy value')\nplt.plot(epoch_c,acc_curve,label='1 Hidden layer')\nplt.plot(epoch_c,acc_curve2,label='2 Hidden layers')\nplt.plot(epoch_c,acc_curve3,label='3 Hidden layers')\nplt.legend()\nplt.show()","36c145d9":"## **FastText File Reading** ##","4d3fca92":" ## **Keras NN Model** ##","b9b5c260":"## ** Loss Curve and Accuracy Plot ** ## ","370c8b56":"## **Text Preprocessing**##","52845285":"## **CountVectorized Representation** ##"}}