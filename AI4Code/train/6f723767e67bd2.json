{"cell_type":{"3108fccb":"code","4f8038d7":"code","20498857":"code","90130ab1":"code","17fca517":"code","5a12f964":"code","bbb5c68e":"code","eb329dd0":"code","172bd1a7":"code","d5394ebb":"code","9470ac54":"code","f5a2ae8c":"code","4f84143e":"code","6aa77ce0":"code","f5c76ea2":"code","06017683":"code","0db1c651":"code","6eb6df2c":"code","269e21c6":"code","e4cbca9e":"code","3cf8012e":"code","7dceca71":"code","f77b0274":"code","5bfefab0":"code","6fa2ef0b":"code","e98c254c":"code","9ac46dec":"code","53dd18f7":"code","7771e7a9":"code","64332562":"code","4f1eaac5":"code","791670ff":"code","d05d1485":"code","2e9a05e5":"code","f432980b":"code","0ac17fac":"code","1d0cb117":"code","719fe0e4":"code","a8964ff7":"code","2779a8b6":"code","f69d56ec":"code","cb159539":"code","4b24bcb0":"code","8d8ae707":"code","f0e590ab":"code","c6234aef":"code","38ab2b49":"code","e8936701":"code","639c6d42":"code","dc52d823":"code","9974640c":"code","f2caa2eb":"code","6801384b":"code","2a8fe429":"code","e7a17194":"code","08333cec":"code","2fd64db0":"code","59dbedf7":"code","21576f4f":"code","a93eb5d5":"code","a98e10d5":"code","d020eb1a":"code","035235c0":"code","95fe7ba2":"code","f022d10c":"code","981f667f":"code","9f7be424":"code","059cffcd":"code","40ce3265":"code","3c6fe38d":"code","9c2ae82c":"code","f76b0dda":"code","4a51d414":"code","5a4b0755":"code","49a9e782":"code","578d4532":"code","06be0c2d":"code","aa29d614":"code","09304465":"code","99a2707b":"code","82340b37":"code","a0d8b050":"code","73c0f53e":"code","fdb661a9":"code","cb00b75f":"code","4f48c404":"code","cf91a383":"code","f972ea1e":"code","38266f09":"code","6486a6f9":"code","dc843567":"code","3b8998f8":"code","d8624073":"code","aa21226d":"code","5ecb93b7":"code","bd2b1e7c":"code","ebf0c5d8":"code","caa5a9e0":"code","50542fe0":"code","07102b49":"code","d37def27":"code","2d62f480":"code","0c75d821":"code","1bf1417e":"code","cd9214ea":"code","256c90a8":"code","a9b2eb05":"code","efa27ae9":"code","298eb243":"code","96611d13":"code","fa0264b2":"code","d5058c48":"code","dc8cda3c":"code","c4274925":"code","54500ef1":"code","8e1837cd":"code","5e587c80":"code","1833174d":"code","042aa345":"code","42ce82ea":"code","c307f484":"code","6236c4b8":"code","79e04c3f":"code","4dfe804c":"code","58de9929":"code","40177e04":"code","783f4e36":"code","539a3f47":"code","22e5030e":"code","52ec5961":"code","1b4e8e87":"code","4454b8bd":"code","f986c11f":"code","d5f01f14":"code","fc5d9e31":"code","d54148cc":"code","d91a3506":"code","408aa57c":"code","7fa1b13f":"code","846e297c":"code","8fa19b9a":"code","7b06a623":"code","b2a27467":"code","7ccc88da":"code","ec9228ec":"code","c553ab36":"code","1fffb29d":"code","7fbe880b":"code","1620c969":"code","53f52859":"code","838b93d0":"code","2e02f43b":"code","ae04ecbc":"code","17f53b2b":"code","f59e617a":"code","7176699b":"code","e47e9fd4":"code","4786ca44":"code","fd869890":"code","981d7e1c":"code","40b1acb4":"code","e028b95c":"code","2acbe079":"code","12f01eb8":"code","357d5080":"code","608b20b4":"code","738b1d4d":"code","91fdcbec":"code","e06a3aba":"code","0d541799":"code","f38b01dd":"code","e1a81311":"code","b9eb66b7":"code","9342df86":"code","d8526be5":"code","3eca5d5d":"code","354d7e4f":"code","6bbaabfa":"code","3a479dea":"code","0d281cf7":"code","68605d0c":"code","c9947b12":"code","112039b7":"code","abba8a7e":"code","9e2319a7":"code","202eb300":"code","51896a26":"code","9f4fd106":"code","6fcb92b4":"code","cf431d53":"code","d7df7aa0":"code","3e301a14":"code","67e710d9":"code","32c82dd6":"code","a5630cfd":"code","66a2bebb":"code","2cccfcbe":"code","0d3fb2cd":"code","b554b398":"code","66a28e86":"code","13dae3e2":"code","95858078":"code","2f58a5d3":"code","a26dadcd":"code","9be58248":"code","6302e56a":"code","0435833b":"code","fcd189f1":"code","13f4797a":"code","6c352147":"code","c265494e":"code","4784eadc":"code","6ad9395e":"code","b5b6283a":"code","8ce1c417":"code","6cfe3430":"code","0e2935c8":"code","6aeb6613":"code","92a80edc":"code","5edccc9a":"code","17f9dd27":"code","604ee443":"code","c54663e2":"code","608170e5":"code","c3364147":"code","937ca6e8":"code","873296ea":"code","1fa7a728":"code","26cf3ea1":"code","1c275057":"code","647c84e9":"code","e06cceb4":"code","b7c754d8":"code","914adae3":"code","c0a03e11":"code","6281a693":"code","86d759a5":"code","3b65c106":"code","8412f49f":"code","94718818":"code","86cacd26":"code","7bfeac07":"code","33b4dcb5":"code","36ba4484":"code","37f03ed4":"code","442f8eef":"code","8a2fbe65":"code","250f2c51":"markdown","f927c562":"markdown","01b7d920":"markdown","9bf07255":"markdown","b460adbc":"markdown","1a7349ec":"markdown","284418c6":"markdown","fbf19411":"markdown","50c930f0":"markdown","804ce33f":"markdown","c5c2cbbe":"markdown","c62f6388":"markdown","dae0cb5c":"markdown","b600980d":"markdown","c2999921":"markdown","8969885e":"markdown","8897a29a":"markdown","c2fa4ed5":"markdown","fcf54a6f":"markdown","a05e8dc1":"markdown","ca6dfa9f":"markdown","eaa8d82e":"markdown","bd639fa1":"markdown","3bd42205":"markdown","fabb026f":"markdown","20fdf797":"markdown","bb9b26b5":"markdown","4476d9a7":"markdown","68ce42f0":"markdown","01d181d7":"markdown","9da0a01c":"markdown","b4868bf4":"markdown","8d50928d":"markdown","95abc688":"markdown","454a8744":"markdown","4509565e":"markdown","81c49a1b":"markdown","af1fd590":"markdown","91babf91":"markdown","20ad55a1":"markdown","b75a83c4":"markdown","9473eb5a":"markdown","c3e917d4":"markdown","c9201bbb":"markdown","5e4cbd23":"markdown","9a510115":"markdown","2aa1563c":"markdown","846cd841":"markdown","241477c7":"markdown","d962bff4":"markdown","a96f075f":"markdown","09b4b948":"markdown","9a17f6d7":"markdown","91bc9b1d":"markdown","cf002b56":"markdown","2db81323":"markdown","74751865":"markdown","e2b7354f":"markdown","00ebeb22":"markdown","04e7a33c":"markdown","a14f9e41":"markdown","bebc3f97":"markdown","e45fa267":"markdown","9869b7e9":"markdown","0a46864c":"markdown","a1ffda9e":"markdown","b6295cba":"markdown","5069d7e5":"markdown","ae7680ae":"markdown","bfc2d3e4":"markdown","82c082f8":"markdown","91aeca3d":"markdown","089befa2":"markdown","31ed3041":"markdown","fd6cae00":"markdown","4d702951":"markdown","78208ebf":"markdown","3173e4bb":"markdown","c8ce8428":"markdown","9717a155":"markdown","96b626a6":"markdown","cb7d4b5e":"markdown","e5262641":"markdown","13ff7a95":"markdown","460136ba":"markdown","80996c96":"markdown","6dedc2d2":"markdown","846e3580":"markdown","a36683e7":"markdown","b947e176":"markdown","fce6b4c3":"markdown","6d620226":"markdown","4f814437":"markdown","ee58ca57":"markdown","4294074e":"markdown","9cea760f":"markdown","d1136c2f":"markdown","04717b1b":"markdown","b52c0aa7":"markdown","69c432d0":"markdown","52f1b00b":"markdown","6655f08f":"markdown","e4b0b34d":"markdown","f377cbf5":"markdown","ada10672":"markdown","17f38e8f":"markdown","118a4924":"markdown","73b58aba":"markdown","76479710":"markdown","ded899c7":"markdown","9aa13d08":"markdown","687d6480":"markdown","e5db6cf0":"markdown","b5b715ed":"markdown","0bec55a2":"markdown","a884afad":"markdown","80576096":"markdown","b7b9994f":"markdown","a8c210a2":"markdown","5c225377":"markdown","464525cd":"markdown","e981f163":"markdown","fa5a8e3a":"markdown","e59f4a29":"markdown","74817476":"markdown","8162dc7c":"markdown","cafb4c6f":"markdown","cdfe466b":"markdown","12b2c5d1":"markdown","283308e3":"markdown","b4114813":"markdown","adbc7393":"markdown","dddeef29":"markdown","a981907c":"markdown","e6bca307":"markdown","3283a306":"markdown","a23c50dc":"markdown","d83133de":"markdown","b680df4f":"markdown","f69fa626":"markdown","0e2be616":"markdown","aaf6eb8f":"markdown","2ffcca38":"markdown","3ae8307e":"markdown","ac4abe54":"markdown","6a3154de":"markdown","54ade8fa":"markdown","2e28fc80":"markdown","f99e3d05":"markdown","079e7993":"markdown","40534f92":"markdown","27099d79":"markdown","7f8538d8":"markdown","2cc89b04":"markdown","541e6c4f":"markdown","596a9b71":"markdown","582010a0":"markdown","30d76b34":"markdown","a2d22682":"markdown","d14bc407":"markdown","e4779655":"markdown","f7c35336":"markdown","d25f0cb3":"markdown","2fb721b7":"markdown","1645c3fe":"markdown","459af38d":"markdown","8993e286":"markdown","8101ea6a":"markdown","5edf874e":"markdown","1f0cda55":"markdown","c36917eb":"markdown","ff0e4b18":"markdown","66246da3":"markdown","d1b4a4b0":"markdown","9476b0ba":"markdown","09c79333":"markdown","2581d31a":"markdown","4afed1e8":"markdown","140f3a29":"markdown","fc057f50":"markdown","e02ba710":"markdown","09f4fea2":"markdown","b61004cf":"markdown","60796ad6":"markdown","5411d0c3":"markdown","727b2aaf":"markdown","2cbbb859":"markdown","908f2288":"markdown","2b196d0e":"markdown","2c87a920":"markdown","0dd36398":"markdown","4ec99425":"markdown","9f18e33c":"markdown","18dc3ec8":"markdown","e64d49ba":"markdown","16ed35f6":"markdown","5eb15eab":"markdown","82941742":"markdown","37e70555":"markdown","813d89d4":"markdown","9fcc0013":"markdown","75ec3861":"markdown","c3a9e02e":"markdown","7fbace7e":"markdown","3a1d6533":"markdown","4f9ab4bf":"markdown","1c30c631":"markdown","f6c10af9":"markdown","3f20ffec":"markdown","c68f7aed":"markdown","fc25b400":"markdown","395b9c9f":"markdown","5fc32895":"markdown","7bba0a77":"markdown","772c2c36":"markdown","6f0c70f7":"markdown","0f9082b6":"markdown","ecc8cb88":"markdown","bd59ceeb":"markdown","f883659e":"markdown","caa3a3cd":"markdown","933b093b":"markdown","a7ddf7d9":"markdown","d93218b9":"markdown","5f9877e6":"markdown","ce9adad3":"markdown","4dc7ebe1":"markdown","d4e305eb":"markdown","0a5d45f1":"markdown","af70642a":"markdown","ee4985fa":"markdown","3052efc9":"markdown","62300c3b":"markdown","d649053d":"markdown","a4be7760":"markdown","92f4f642":"markdown","a06f1073":"markdown","a0a8445b":"markdown","3206dd30":"markdown","b192c625":"markdown","ec918943":"markdown","ad0c97e5":"markdown","0df2b9b4":"markdown","8bc01b57":"markdown","5866adf0":"markdown","630d2a6d":"markdown","4fe56a61":"markdown","da7fa15b":"markdown","aecd608b":"markdown","07149d46":"markdown","a922d332":"markdown","50411825":"markdown","47d26cdb":"markdown","8bde2add":"markdown","a1457567":"markdown","1afa359f":"markdown","2b601b25":"markdown","58c827bd":"markdown","6f0791b4":"markdown","d66a225a":"markdown","e03a1379":"markdown","d904ebc3":"markdown","049ee3c4":"markdown","4dd73d89":"markdown","85d9e6b0":"markdown","9de1ceca":"markdown","35fe4f4f":"markdown","f5dd89ee":"markdown","61bffed5":"markdown","46501a5f":"markdown","f5192a05":"markdown","fffd0971":"markdown","e817e54c":"markdown","eeeeb837":"markdown","402f15aa":"markdown","48acc393":"markdown","a216fdf2":"markdown","6c9bc5b1":"markdown","94c4aff5":"markdown","067d9517":"markdown","290269af":"markdown","e561d308":"markdown","903a6289":"markdown","7ea6f259":"markdown","50938591":"markdown","3f8ad5d0":"markdown","5ae0715a":"markdown","470aadc1":"markdown","6ab075cd":"markdown","44ea74cf":"markdown","f129ac1f":"markdown","c3eb8dc7":"markdown","78dcfb16":"markdown","050baf21":"markdown","ae8ec2f7":"markdown","101acf8c":"markdown","a456a754":"markdown","1f5a1de0":"markdown","57fba2ae":"markdown","7d52b3b8":"markdown","2e47130c":"markdown","06d080b6":"markdown","f007b8a9":"markdown","c7b97cf5":"markdown","5220c657":"markdown","53866f10":"markdown","27f86d46":"markdown","b6a7acdd":"markdown","0d6414b4":"markdown","73efb35c":"markdown","07488ce5":"markdown","b68f8cb8":"markdown","a11b9e57":"markdown","c9d2f60d":"markdown","cbcc165b":"markdown","e9d50a36":"markdown","98656dd2":"markdown","a9acee3a":"markdown","65fa18bc":"markdown","2a1fbedd":"markdown","dfeccefc":"markdown","578ff6c8":"markdown","1d3387ab":"markdown","66c2cdf7":"markdown","05b66fce":"markdown","f961fd68":"markdown","3b32fd96":"markdown","b723733d":"markdown","515a7984":"markdown","82153e1e":"markdown","a2df5c54":"markdown","092d2b5a":"markdown","5324dde8":"markdown","c6ed11c6":"markdown","fb3bc027":"markdown","ef78fb70":"markdown","18af9da2":"markdown","3c4ac987":"markdown","60b8a754":"markdown","bf10b97c":"markdown","fe6f051e":"markdown","cafd1e58":"markdown","ee80a04a":"markdown","629d0fae":"markdown","6afa2219":"markdown","8fd6128d":"markdown","4cd10c6f":"markdown","cf91d580":"markdown","7dee7417":"markdown","c4bf9dc0":"markdown","f930c691":"markdown","244deacb":"markdown","cd0705d9":"markdown","077227ee":"markdown","9c27c64a":"markdown","de9345dd":"markdown","93d4c226":"markdown","d10213c7":"markdown","c1ad950b":"markdown","d9cc68f7":"markdown","bd587230":"markdown","0519140a":"markdown","e3680ceb":"markdown","2a051551":"markdown","5f7c65b6":"markdown","7b7aeef2":"markdown","9f7ae35b":"markdown","50da26d1":"markdown","4e927eab":"markdown","28b321c1":"markdown","b87e0f05":"markdown","2a28ab47":"markdown","a089627a":"markdown","fd2f66e2":"markdown","a1619a55":"markdown","cec2823b":"markdown","9cfb1d9d":"markdown"},"source":{"3108fccb":"import os\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport random\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport plotly.graph_objs as go\nimport plotly.offline as pyo\nimport plotly.figure_factory as ff\nimport plotly.express as px\nfrom plotly import tools\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import iplot\nfrom IPython import display ","4f8038d7":"from IPython.core.display import HTML\ndef multi_table(table_list):\n    ''' Acceps a list of IpyTable objects and returns a table which contains each IpyTable in a cell\n    '''\n    return HTML(\n        '<table><tr style=\"background-color:white;\">' + \n        ''.join(['<td>' + table._repr_html_() + '<\/td>' for table in table_list]) +\n        '<\/tr><\/table>')","20498857":"df_2018 = pd.read_csv('..\/input\/kaggle-survey-2018\/multipleChoiceResponses.csv')\ndf_2018 = df_2018[1:]\ndf_2019 = pd.read_csv('..\/input\/kaggle-survey-2019\/multiple_choice_responses.csv')\ndf_2019 = df_2019[1:]\ndf_2020 = pd.read_csv('..\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv')\ndf_2020 = df_2020[1:]","90130ab1":"df1 = pd.read_csv('..\/input\/kaggle-survey-2021\/kaggle_survey_2021_responses.csv')\ndf1","17fca517":"df = df1[1:]","5a12f964":"print('Number of responses given to survey\/rows in dataframe:', df.shape[0])\nprint('Number of columns of dataframe',df.shape[1])","bbb5c68e":"fig = make_subplots(rows=1,cols=2,\n                    subplot_titles=('Countplot',\n                                    'Percentages'),\n                    specs=[[{\"type\": \"xy\"},\n                            {'type':'domain'}]])\nfig.add_trace(go.Bar(y = df['Q1'].value_counts().values.tolist(), \n                      x = df['Q1'].value_counts().index, \n                      text=df['Q1'].value_counts().values.tolist(),\n              textfont=dict(size=15),\n                      name = 'Age of People',\n                      textposition = 'outside',\n                      showlegend=False,\n              marker = dict(color = 'cornflowerblue',\n                            line_color = 'black',\n                            line_width=3)),row = 1,col = 1)\nfig.add_trace((go.Pie(labels=df['Q1'].value_counts().keys(),\n                             values=df['Q1'].value_counts().values,textfont = dict(size = 16),\n                     textposition='auto',\n                     showlegend = True,\n                     name = 'Age of People')), row = 1, col = 2)\nfig.update_layout(title={'text': 'Age of People',\n                         'y':0.9,\n                         'x':0.5,\n                         'xanchor': 'center',\n                         'yanchor': 'top'},\n                  template='plotly_white')\nfig.update_yaxes(range=[0,6000])\niplot(fig)","eb329dd0":"fig = make_subplots(rows=1,cols=2,\n                    subplot_titles=('Countplot',\n                                    'Percentages'),\n                    specs=[[{\"type\": \"xy\"},\n                            {'type':'domain'}]])\nfig.add_trace(go.Bar(y = df['Q2'].value_counts().values.tolist(), \n                      x = df['Q2'].value_counts().index, \n                      text=df['Q2'].value_counts().values.tolist(),\n              textfont=dict(size=15),\n                      textposition = 'outside',\n                      showlegend=False,\n              marker = dict(color = 'deeppink',\n                            line_color = 'black',\n                            line_width=3)),row = 1,col = 1)\nfig.add_trace((go.Pie(labels=df['Q2'].value_counts().keys(),\n                             values=df['Q2'].value_counts().values,textfont = dict(size = 16),\n                     textposition='auto',\n                     showlegend = True,\n                     )), row = 1, col = 2)\nfig.update_layout(title={'text': 'Gender of People',\n                         'y':0.9,\n                         'x':0.5,\n                         'xanchor': 'center',\n                         'yanchor': 'top'},\n                  template='plotly_white')\nfig.update_yaxes(range=[0,22000])\niplot(fig)","172bd1a7":"import plotly.offline as py\npy.offline.init_notebook_mode()\n\ndef plot_in_map(locations,counts,title):\n    data = [ dict(\n            type = 'choropleth',\n            locations = locations,\n            z = counts,\n            locationmode = 'country names',\n            autocolorscale = True,\n            marker = dict(\n                line = dict(color = 'rgb(58,100,69)', width = 0.6)),\n                colorbar = dict(autotick = True, tickprefix = '', title = '# of Kagglers')\n                )\n           ]\n    layout = dict(\n        title = title,\n        geo = dict(\n            showframe = True,\n            showcoastlines = True,\n            projection = dict(\n            type = 'equirectangular'\n            ),\n        margin = dict(b = 0, t = 0, l = 0, r = 0)\n                ),\n        )\n\n    fig = dict(data=data, layout=layout)\n    \n    py.iplot(fig, validate=False, filename='world-map')\nz = df['Q3'].value_counts()\nplot_in_map(locations=z.index,\n            counts=z.values,\n            title='Participants by Country')","d5394ebb":"fig = make_subplots(rows=1,cols=2,\n                    subplot_titles=('Countplot',\n                                    'Percentages'),\n                    specs=[[{\"type\": \"xy\"},\n                            {'type':'domain'}]])\nfig.add_trace(go.Bar(y = df['Q4'].value_counts().values.tolist(), \n                      x = df['Q4'].value_counts().index, \n                      text=df['Q4'].value_counts().values.tolist(),\n              textfont=dict(size=15),\n                      textposition = 'outside',\n                      showlegend=False,\n              marker = dict(color = 'yellow',\n                            line_color = 'black',\n                            line_width=3)),row = 1,col = 1)\nfig.add_trace((go.Pie(labels=df['Q4'].value_counts().keys(),\n                             values=df['Q4'].value_counts().values,textfont = dict(size = 16),\n                     textposition='auto',\n                     showlegend = True,)), row = 1, col = 2)\nfig.update_layout(title={'text': 'Degree of People',\n                         'y':1.0,\n                         'x':0.5,\n                         'xanchor': 'center',\n                         'yanchor': 'top'},width=1000,\n    height=1000,\n                  template='plotly_white')\nfig.update_yaxes(range=[0,22000])\niplot(fig)","9470ac54":"fig = make_subplots(rows=1,cols=2,\n                    subplot_titles=('Countplot',\n                                    'Percentages'),\n                    specs=[[{\"type\": \"xy\"},\n                            {'type':'domain'}]])\nfig.add_trace(go.Bar(y = df['Q5'].value_counts().values.tolist(), \n                      x = df['Q5'].value_counts().index, \n                      text=df['Q5'].value_counts().values.tolist(),\n              textfont=dict(size=15),\n                      textposition = 'outside',\n                      showlegend=False,\n              marker = dict(color = '#FFE399',\n                            line_color = 'black',\n                            line_width=3)),row = 1,col = 1)\nfig.add_trace((go.Pie(labels=df['Q5'].value_counts().keys(),\n                             values=df['Q5'].value_counts().values,textfont = dict(size = 16),\n                     textposition='auto',\n                     showlegend = True,)), row = 1, col = 2)\nfig.update_layout(title={'text': 'Profession of People',\n                         'y':0.9,\n                         'x':0.5,\n                         'xanchor': 'center',\n                         'yanchor': 'top'},width = 1300,height = 600,\n                  template='plotly_white')\nfig.update_yaxes(range=[0,7200])\niplot(fig)","f5a2ae8c":"fig = make_subplots(rows=1,cols=2,\n                    subplot_titles=('Countplot',\n                                    'Percentages'),\n                    specs=[[{\"type\": \"xy\"},\n                            {'type':'domain'}]])\nfig.add_trace(go.Bar(y = df['Q6'].value_counts().values.tolist(), \n                      x = df['Q6'].value_counts().index, \n                      text=df['Q6'].value_counts().values.tolist(),\n              textfont=dict(size=15),\n                      name = 'Coding Experience of People',\n                      textposition = 'outside',\n                      showlegend=False,\n              marker = dict(color = '#0891EF',\n                            line_color = 'black',\n                            line_width=3)),row = 1,col = 1)\nfig.add_trace((go.Pie(labels=df['Q6'].value_counts().keys(),\n                             values=df['Q6'].value_counts().values,textfont = dict(size = 16),\n                     textposition='auto',\n                     showlegend = True,\n                     name = 'Coding Experience of People')), row = 1, col = 2)\nfig.update_layout(title={'text': 'Coding Experience of People',\n                         'y':1,\n                         'x':0.5,\n                         'xanchor': 'center',\n                         'yanchor': 'top'},width = 1000,height = 600,\n                  template='plotly_white')\nfig.update_yaxes(range=[0,8200])\niplot(fig)","4f84143e":"col = ['Q7_Part_1', 'Q7_Part_2', 'Q7_Part_3','Q7_Part_4',\n                       'Q7_Part_5', 'Q7_Part_6', 'Q7_Part_7', 'Q7_Part_8', 'Q7_Part_9',\n                       'Q7_Part_10', 'Q7_Part_11', 'Q7_Part_12', 'Q7_OTHER']\na = []\nfor i in col:\n    a.append(df[i].value_counts().keys()[0])\nb = []\nfor i in col:\n    b.append(df[i].value_counts().iloc[0])","6aa77ce0":"fig = make_subplots(rows=1,cols=2,\n                    subplot_titles=('Countplot',\n                                    'Percentages'),\n                    specs=[[{\"type\": \"xy\"},\n                            {'type':'domain'}]])\nfig.add_trace(go.Bar(y = b, \n                      x = a, \n                      text=b,\n              textfont=dict(size=15),\n                      name = 'Programming Language used on Regular Basis',\n                      textposition = 'outside',\n                      showlegend=False,\n              marker = dict(color = '#FF00E0',\n                            line_color = 'black',\n                            line_width=3)),row = 1,col = 1)\nfig.add_trace((go.Pie(labels=a,\n                             values=b,textfont = dict(size = 16),\n                     textposition='auto',\n                     showlegend = True,\n                     name = 'Programming Language used on Regular Basis')), row = 1, col = 2)\nfig.update_layout(title={'text': 'Programming Language used on Regular Basis',\n                         'y':1,\n                         'x':0.5,\n                         'xanchor': 'center',\n                         'yanchor': 'top'},width = 1200,height = 600,\n                  template='plotly_white')\nfig.update_yaxes(range=[0,22500])\niplot(fig)","f5c76ea2":"fig = make_subplots(rows=1,cols=2,\n                    subplot_titles=('Countplot',\n                                    'Percentages'),\n                    specs=[[{\"type\": \"xy\"},\n                            {'type':'domain'}]])\nfig.add_trace(go.Bar(y = df['Q8'].value_counts().values.tolist(), \n                      x = df['Q8'].value_counts().index, \n                      text=df['Q8'].value_counts().values.tolist(),\n              textfont=dict(size=15),\n                      textposition = 'outside',\n                      showlegend=False,\n              marker = dict(color = 'yellowgreen',\n                            line_color = 'black',\n                            line_width=3)),row = 1,col = 1)\nfig.add_trace((go.Pie(labels=df['Q8'].value_counts().keys(),\n                             values=df['Q8'].value_counts().values,textfont = dict(size = 16),\n                     textposition='auto',\n                     showlegend = True,)), row = 1, col = 2)\nfig.update_layout(title={'text': 'Mostly Recommended Language For Aspiring Data Scientist',\n                         'y':0.9,\n                         'x':0.5,\n                         'xanchor': 'center',\n                         'yanchor': 'top'},width = 1000,height = 600,\n                  template='plotly_white')\nfig.update_yaxes(range=[0,21000])\niplot(fig)","06017683":"col = ['Q9_Part_1', 'Q9_Part_2', 'Q9_Part_3', 'Q9_Part_4', 'Q9_Part_5',\n       'Q9_Part_6', 'Q9_Part_7', 'Q9_Part_8', 'Q9_Part_9', 'Q9_Part_10',\n       'Q9_Part_11', 'Q9_Part_12', 'Q9_OTHER']\na = []\nfor i in col:\n    a.append(df[i].value_counts().keys()[0])\nb = []\nfor i in col:\n    b.append(df[i].value_counts().iloc[0])","0db1c651":"data = [go.Bar(x=a,y= b,text = b,\n              textposition= 'outside',\n              width=[0.7, 0.7],\n              marker = dict(color = 'orange',\n                            line_color = 'black',\n                            line_width=3))]\n\nlayout = go.Layout(title='IDEs used on regular basis',\n                   xaxis = dict(title='IDEs name'),\n                   width=800,\n                   height=600,\n                   template = 'plotly_white')\n\nfig=go.Figure(data=data, layout=layout)\nfig.update_yaxes(range=[0,17200])\niplot(fig)","6eb6df2c":"col = ['Q10_Part_1', 'Q10_Part_2',\n       'Q10_Part_3', 'Q10_Part_4', 'Q10_Part_5', 'Q10_Part_6',\n       'Q10_Part_7', 'Q10_Part_8', 'Q10_Part_9', 'Q10_Part_10',\n       'Q10_Part_11', 'Q10_Part_12', 'Q10_Part_13', 'Q10_Part_14',\n       'Q10_Part_15', 'Q10_Part_16', 'Q10_OTHER']\na = []\nfor i in col:\n    a.append(df[i].value_counts().keys()[0])\nb = []\nfor i in col:\n    b.append(df[i].value_counts().iloc[0])","269e21c6":"data = [go.Bar(x=a,y= b,text = b,\n              textposition= 'outside',\n              width=[0.7, 0.7],\n              marker = dict(color = 'red',\n                            line_color = 'black',\n                            line_width=3))]\n\nlayout = go.Layout(title='Notebooks used on regular basis',\n                   xaxis = dict(title='Notebbok name'),\n                   width=800,\n                   height=600,\n                   template = 'plotly_white')\n\nfig=go.Figure(data=data, layout=layout)\nfig.update_yaxes(range=[0,11000])\niplot(fig)","e4cbca9e":"fig = make_subplots(rows=1,cols=2,\n                    subplot_titles=('Countplot',\n                                    'Percentages'),\n                    specs=[[{\"type\": \"xy\"},\n                            {'type':'domain'}]])\nfig.add_trace(go.Bar(y = df['Q11'].value_counts().values.tolist(), \n                      x = df['Q11'].value_counts().index, \n                      text=df['Q11'].value_counts().values.tolist(),\n              textfont=dict(size=15),\n                      textposition = 'outside',\n                      showlegend=False,\n              marker = dict(color = '#0891EF',\n                            line_color = 'black',\n                            line_width=3)),row = 1,col = 1)\nfig.add_trace((go.Pie(labels=df['Q11'].value_counts().keys(),\n                             values=df['Q11'].value_counts().values,textfont = dict(size = 16),\n                     textposition='auto',\n                     showlegend = True,)), row = 1, col = 2)\nfig.update_layout(title={'text': 'Most used Computing Platform',\n                         'y':0.9,\n                         'x':0.5,\n                         'xanchor': 'center',\n                         'yanchor': 'top'},width = 1000,height = 600,\n                  template='plotly_white')\nfig.update_yaxes(range=[0,17000])\niplot(fig)","3cf8012e":"col = ['Q12_Part_1',\n       'Q12_Part_2', 'Q12_Part_3', 'Q12_Part_4', 'Q12_Part_5',\n       'Q12_OTHER']\na = []\nfor i in col:\n    a.append(df[i].value_counts().keys()[0])\nb = []\nfor i in col:\n    b.append(df[i].value_counts().iloc[0])","7dceca71":"fig = make_subplots(rows=1,cols=2,\n                    subplot_titles=('Countplot',\n                                    'Percentages'),\n                    specs=[[{\"type\": \"xy\"},\n                            {'type':'domain'}]])\nfig.add_trace(go.Bar(y = b, \n                      x = a, \n                      text=b,\n              textfont=dict(size=15),\n                      textposition = 'outside',\n                      showlegend=False,\n              marker = dict(color = 'gold',\n                            line_color = 'black',\n                            line_width=3)),row = 1,col = 1)\nfig.add_trace((go.Pie(labels=a,\n                             values=b,textfont = dict(size = 16),\n                     textposition='auto',\n                     showlegend = True)), row = 1, col = 2)\nfig.update_layout(title={'text': 'Specialized Hardware used on Regular Basis',\n                         'y':1,\n                         'x':0.5,\n                         'xanchor': 'center',\n                         'yanchor': 'top'},width = 1000,height = 600,\n                  template='plotly_white')\nfig.update_yaxes(range=[0,15000])\niplot(fig)","f77b0274":"fig = make_subplots(rows=1,cols=2,\n                    subplot_titles=('Countplot',\n                                    'Percentages'),\n                    specs=[[{\"type\": \"xy\"},\n                            {'type':'domain'}]])\nfig.add_trace(go.Bar(y = df['Q13'].value_counts().values.tolist(), \n                      x = df['Q13'].value_counts().index, \n                      text=df['Q13'].value_counts().values.tolist(),\n              textfont=dict(size=15),\n                      textposition = 'outside',\n                      showlegend=False,\n              marker = dict(color = 'darkcyan',\n                            line_color = 'black',\n                            line_width=3)),row = 1,col = 1)\nfig.add_trace((go.Pie(labels=df['Q13'].value_counts().keys(),\n                             values=df['Q13'].value_counts().values,textfont = dict(size = 16),\n                     textposition='auto',\n                     showlegend = True,)), row = 1, col = 2)\nfig.update_layout(title={'text': 'TPU Usage Count',\n                         'y':0.9,\n                         'x':0.5,\n                         'xanchor': 'center',\n                         'yanchor': 'top'},width = 1000,height = 600,\n                  template='plotly_white')\nfig.update_yaxes(range=[0,17500])\niplot(fig)","5bfefab0":"col = ['Q14_Part_1', 'Q14_Part_2', 'Q14_Part_3',\n       'Q14_Part_4', 'Q14_Part_5', 'Q14_Part_6', 'Q14_Part_7',\n       'Q14_Part_8', 'Q14_Part_9', 'Q14_Part_10', 'Q14_Part_11',\n       'Q14_OTHER']\na = []\nfor i in col:\n    a.append(df[i].value_counts().keys()[0])\nb = []\nfor i in col:\n    b.append(df[i].value_counts().iloc[0])","6fa2ef0b":"data = [go.Bar(x=a,y= b,text = b,\n              textposition= 'outside',\n              width=[0.7, 0.7],\n              marker = dict(color = 'lavender',\n                            line_color = 'black',\n                            line_width=3))]\n\nlayout = go.Layout(title='Data Visulaisation Libraries used on regular basis',\n                   xaxis = dict(title='Libraries Name'),\n                   width=800,\n                   height=600,\n                   template = 'plotly_white')\n\nfig=go.Figure(data=data, layout=layout)\nfig.update_yaxes(range=[0,19000])\niplot(fig)","e98c254c":"fig = make_subplots(rows=1,cols=2,\n                    subplot_titles=('Countplot',\n                                    'Percentages'),\n                    specs=[[{\"type\": \"xy\"},\n                            {'type':'domain'}]])\nfig.add_trace(go.Bar(y = df['Q15'].value_counts().values.tolist(), \n                      x = df['Q15'].value_counts().index, \n                      text=df['Q15'].value_counts().values.tolist(),\n              textfont=dict(size=15),\n                      textposition = 'outside',\n                      showlegend=False,\n              marker = dict(color = 'cyan',\n                            line_color = 'black',\n                            line_width=3)),row = 1,col = 1)\nfig.add_trace((go.Pie(labels=df['Q15'].value_counts().keys(),\n                             values=df['Q15'].value_counts().values,textfont = dict(size = 16),\n                     textposition='auto',\n                     showlegend = True,)), row = 1, col = 2)\nfig.update_layout(title={'text': 'Machine Learning Methods',\n                         'y':0.9,\n                         'x':0.5,\n                         'xanchor': 'center',\n                         'yanchor': 'top'},width = 1000,height = 600,\n                  template='plotly_white')\nfig.update_yaxes(range=[0,10000])\niplot(fig)","9ac46dec":"col = ['Q16_Part_1', 'Q16_Part_2', 'Q16_Part_3',\n       'Q16_Part_4', 'Q16_Part_5', 'Q16_Part_6', 'Q16_Part_7',\n       'Q16_Part_8', 'Q16_Part_9', 'Q16_Part_10', 'Q16_Part_11',\n       'Q16_Part_12', 'Q16_Part_13', 'Q16_Part_14', 'Q16_Part_15',\n       'Q16_Part_16', 'Q16_Part_17', 'Q16_OTHER']\na = []\nfor i in col:\n    a.append(df[i].value_counts().keys()[0])\nb = []\nfor i in col:\n    b.append(df[i].value_counts().iloc[0])","53dd18f7":"data = [go.Bar(x=a,y= b,text = b,\n              textposition= 'outside',\n              width=[0.7, 0.7],\n              marker = dict(color = 'coral',\n                            line_color = 'black',\n                            line_width=3))]\n\nlayout = go.Layout(title='Machine Learning Frameworks used on regular basis',\n                   xaxis = dict(title='Machine Learning Frameworks'),\n                   width=800,\n                   height=600,\n                   template = 'plotly_white')\n\nfig=go.Figure(data=data, layout=layout)\nfig.update_yaxes(range=[0,15000])\niplot(fig)","7771e7a9":"col = ['Q17_Part_1',\n       'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5',\n       'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9',\n       'Q17_Part_10', 'Q17_Part_11', 'Q17_OTHER']\na = []\nfor i in col:\n    a.append(df[i].value_counts().keys()[0])\nb = []\nfor i in col:\n    b.append(df[i].value_counts().iloc[0])","64332562":"data = [go.Bar(x=a,y= b,text = b,\n              textposition= 'outside',\n              width=[0.7, 0.7],\n              marker = dict(color = 'darksalmon',\n                            line_color = 'black',\n                            line_width=3))]\n\nlayout = go.Layout(title='Machine Learning Algorithms used on regular basis',\n                   xaxis = dict(title='Machine Learning Algorithms'),\n                   width=800,\n                   height=600,\n                   template = 'plotly_white')\n\nfig=go.Figure(data=data, layout=layout)\nfig.update_yaxes(range=[0,15000])\niplot(fig)","4f1eaac5":"col = ['Q18_Part_1',\n       'Q18_Part_2', 'Q18_Part_3', 'Q18_Part_4', 'Q18_Part_5',\n       'Q18_Part_6', 'Q18_OTHER']\na = []\nfor i in col:\n    a.append(df[i].value_counts().keys()[0])\nb = []\nfor i in col:\n    b.append(df[i].value_counts().iloc[0])","791670ff":"data = [go.Bar(x=a,y= b,text = b,\n              textposition= 'outside',\n              width=[0.7, 0.7],\n              marker = dict(color = 'cornsilk',\n                            line_color = 'black',\n                            line_width=3))]\n\nlayout = go.Layout(title='Computer Vision Methods used on regular basis',\n                   xaxis = dict(title='Computer Vision Methods'),\n                   width=800,\n                   height=600,\n                   template = 'plotly_white')\n\nfig=go.Figure(data=data, layout=layout)\nfig.update_yaxes(range=[0,6000])\niplot(fig)","d05d1485":"col = ['Q19_Part_1', 'Q19_Part_2',\n       'Q19_Part_3', 'Q19_Part_4', 'Q19_Part_5', 'Q19_OTHER']\na = []\nfor i in col:\n    a.append(df[i].value_counts().keys()[0])\nb = []\nfor i in col:\n    b.append(df[i].value_counts().iloc[0])","2e9a05e5":"fig = make_subplots(rows=1,cols=2,\n                    subplot_titles=('Countplot',\n                                    'Percentages'),\n                    specs=[[{\"type\": \"xy\"},\n                            {'type':'domain'}]])\nfig.add_trace(go.Bar(y = b, \n                      x = a, \n                      text=b,\n              textfont=dict(size=15),\n                      textposition = 'outside',\n                      showlegend=False,\n              marker = dict(color = 'burlywood',\n                            line_color = 'black',\n                            line_width=3)),row = 1,col = 1)\nfig.add_trace((go.Pie(labels=a,\n                             values=b,textfont = dict(size = 16),\n                     textposition='auto',\n                     showlegend = True)), row = 1, col = 2)\nfig.update_layout(title={'text': 'NLP Methods used on Regular Basis',\n                         'y':1,\n                         'x':0.5,\n                         'xanchor': 'center',\n                         'yanchor': 'top'},width = 1000,height = 600,\n                  template='plotly_white')\nfig.update_yaxes(range=[0,3500])\niplot(fig)","f432980b":"fig = make_subplots(rows=1,cols=2,\n                    subplot_titles=('Countplot',\n                                    'Percentages'),\n                    specs=[[{\"type\": \"xy\"},\n                            {'type':'domain'}]])\nfig.add_trace(go.Bar(y = df['Q20'].value_counts().values.tolist(), \n                      x = df['Q20'].value_counts().index, \n                      text=df['Q20'].value_counts().values.tolist(),\n              textfont=dict(size=15),\n                      textposition = 'outside',\n                      showlegend=False,\n              marker = dict(color = 'grey',\n                            line_color = 'black',\n                            line_width=3)),row = 1,col = 1)\nfig.add_trace((go.Pie(labels=df['Q20'].value_counts().keys(),\n                             values=df['Q20'].value_counts().values,textfont = dict(size = 16),\n                     textposition='auto',\n                     showlegend = True,)), row = 1, col = 2)\nfig.update_layout(title={'text': 'Current Employement',\n                         'y':1,\n                         'x':0.4,\n                         'xanchor': 'center',\n                         'yanchor': 'top'},width = 1400,height = 600,\n                  template='plotly_white')\nfig.update_yaxes(range=[0,4600])\niplot(fig)","0ac17fac":"fig = make_subplots(rows=1,cols=2,\n                    subplot_titles=('Countplot',\n                                    'Percentages'),\n                    specs=[[{\"type\": \"xy\"},\n                            {'type':'domain'}]])\nfig.add_trace(go.Bar(y = df['Q21'].value_counts().values.tolist(), \n                      x = df['Q21'].value_counts().index, \n                      text=df['Q21'].value_counts().values.tolist(),\n              textfont=dict(size=15),\n                      textposition = 'outside',\n                      showlegend=False,\n              marker = dict(color = 'lime',\n                            line_color = 'black',\n                            line_width=3)),row = 1,col = 1)\nfig.add_trace((go.Pie(labels=df['Q21'].value_counts().keys(),\n                             values=df['Q21'].value_counts().values,textfont = dict(size = 16),\n                     textposition='auto',\n                     showlegend = True,)), row = 1, col = 2)\nfig.update_layout(title={'text': 'Number of People',\n                         'y':1,\n                         'x':0.5,\n                         'xanchor': 'center',\n                         'yanchor': 'top'},width = 1000,height = 600,\n                  template='plotly_white')\nfig.update_yaxes(range=[0,5500])\niplot(fig)","1d0cb117":"fig = make_subplots(rows=1,cols=2,\n                    subplot_titles=('Countplot',\n                                    'Percentages'),\n                    specs=[[{\"type\": \"xy\"},\n                            {'type':'domain'}]])\nfig.add_trace(go.Bar(y = df['Q22'].value_counts().values.tolist(), \n                      x = df['Q22'].value_counts().index, \n                      text=df['Q22'].value_counts().values.tolist(),\n              textfont=dict(size=15),\n                      textposition = 'outside',\n                      showlegend=False,\n              marker = dict(color = 'mediumpurple',\n                            line_color = 'black',\n                            line_width=3)),row = 1,col = 1)\nfig.add_trace((go.Pie(labels=df['Q22'].value_counts().keys(),\n                             values=df['Q22'].value_counts().values,textfont = dict(size = 16),\n                     textposition='auto',\n                     showlegend = True,)), row = 1, col = 2)\nfig.update_layout(title={'text': 'Employees Responsible for Data Science Role',\n                         'y':1,\n                         'x':0.5,\n                         'xanchor': 'center',\n                         'yanchor': 'top'},width = 1000,height = 600,\n                  template='plotly_white')\nfig.update_yaxes(range=[0,4000])\niplot(fig)","719fe0e4":"fig = make_subplots(rows=1,cols=2,\n                    subplot_titles=('Countplot',\n                                    'Percentages'),\n                    specs=[[{\"type\": \"xy\"},\n                            {'type':'domain'}]])\nfig.add_trace(go.Bar(y = df['Q23'].value_counts().values.tolist(), \n                      x = df['Q23'].value_counts().index, \n                      text=df['Q23'].value_counts().values.tolist(),\n              textfont=dict(size=15),\n                      textposition = 'outside',\n                      showlegend=False,\n              marker = dict(color = 'navy',\n                            line_color = 'black',\n                            line_width=3)),row = 1,col = 1)\nfig.add_trace((go.Pie(labels=df['Q23'].value_counts().keys(),\n                             values=df['Q23'].value_counts().values,textfont = dict(size = 16),\n                     textposition='auto',\n                     showlegend = True,)), row = 1, col = 2)\nfig.update_layout(title={'text': 'Machine Learning Methods into their Business',\n                         'y':1,\n                         'x':0.4,\n                         'xanchor': 'center',\n                         'yanchor': 'top'},width = 1200,height = 600,\n                  template='plotly_white')\nfig.update_yaxes(range=[0,4000])\niplot(fig)","a8964ff7":"col = ['Q24_Part_1', 'Q24_Part_2', 'Q24_Part_3',\n       'Q24_Part_4', 'Q24_Part_5', 'Q24_Part_6', 'Q24_Part_7',\n       'Q24_OTHER']\na = []\nfor i in col:\n    a.append(df[i].value_counts().keys()[0])\nb = []\nfor i in col:\n    b.append(df[i].value_counts().iloc[0])","2779a8b6":"data = [go.Bar(x=a,y= b,text = b,\n              textposition= 'outside',\n              width=[0.7, 0.7],\n              marker = dict(color = 'chocolate',\n                            line_color = 'black',\n                            line_width=3))]\n\nlayout = go.Layout(title='Activities that make important role at work',\n                   xaxis = dict(title='Activities'),\n                   width=800,\n                   height=600,\n                   template = 'plotly_white')\n\nfig=go.Figure(data=data, layout=layout)\nfig.update_yaxes(range=[0,11000])\niplot(fig)","f69d56ec":"fig = make_subplots(rows=1,cols=2,\n                    subplot_titles=('Countplot',\n                                    'Percentages'),\n                    specs=[[{\"type\": \"xy\"},\n                            {'type':'domain'}]])\nfig.add_trace(go.Bar(y = df['Q25'].value_counts().values.tolist(), \n                      x = df['Q25'].value_counts().index, \n                      text=df['Q25'].value_counts().values.tolist(),\n              textfont=dict(size=15),\n                      textposition = 'outside',\n                      showlegend=False,\n              marker = dict(color = 'mediumpurple',\n                            line_color = 'black',\n                            line_width=3)),row = 1,col = 1)\nfig.add_trace((go.Pie(labels=df['Q25'].value_counts().keys(),\n                             values=df['Q25'].value_counts().values,textfont = dict(size = 16),\n                     textposition='auto',\n                     showlegend = True,)), row = 1, col = 2)\nfig.update_layout(title={'text': 'Yearly Compensation of Employees',\n                         'y':1,\n                         'x':0.5,\n                         'xanchor': 'center',\n                         'yanchor': 'top'},width = 1600,height = 600,\n                  template='plotly_white')\nfig.update_yaxes(range=[0,3800])\niplot(fig)","cb159539":"fig = make_subplots(rows=1,cols=2,\n                    subplot_titles=('Countplot',\n                                    'Percentages'),\n                    specs=[[{\"type\": \"xy\"},\n                            {'type':'domain'}]])\nfig.add_trace(go.Bar(y = df['Q26'].value_counts().values.tolist(), \n                      x = df['Q26'].value_counts().index, \n                      text=df['Q26'].value_counts().values.tolist(),\n              textfont=dict(size=15),\n                      textposition = 'outside',\n                      showlegend=False,\n              marker = dict(color = 'wheat',\n                            line_color = 'black',\n                            line_width=3)),row = 1,col = 1)\nfig.add_trace((go.Pie(labels=df['Q26'].value_counts().keys(),\n                             values=df['Q26'].value_counts().values,textfont = dict(size = 16),\n                     textposition='auto',\n                     showlegend = True,)), row = 1, col = 2)\nfig.update_layout(title={'text': 'Money Spent on ML or Cloud Computing Services',\n                         'y':1,\n                         'x':0.5,\n                         'xanchor': 'center',\n                         'yanchor': 'top'},width = 1000,height = 600,\n                  template='plotly_white')\nfig.update_yaxes(range=[0,6600])\niplot(fig)","4b24bcb0":"col = ['Q27_A_Part_1', 'Q27_A_Part_2',\n       'Q27_A_Part_3', 'Q27_A_Part_4', 'Q27_A_Part_5', 'Q27_A_Part_6',\n       'Q27_A_Part_7', 'Q27_A_Part_8', 'Q27_A_Part_9', 'Q27_A_Part_10',\n       'Q27_A_Part_11', 'Q27_A_OTHER']\na = []\nfor i in col:\n    a.append(df[i].value_counts().keys()[0])\nb = []\nfor i in col:\n    b.append(df[i].value_counts().iloc[0])","8d8ae707":"data = [go.Bar(x=a,y= b,text = b,\n              textposition= 'outside',\n              width=[0.7, 0.7],\n              marker = dict(color = 'cyan',\n                            line_color = 'black',\n                            line_width=3))]\n\nlayout = go.Layout(title='Cloud Computing Platforms used on regular basis',\n                   xaxis = dict(title='Cloud Computing Platforms'),\n                   width=800,\n                   height=600,\n                   template = 'plotly_white')\n\nfig=go.Figure(data=data, layout=layout)\nfig.update_yaxes(range=[0,5000])\niplot(fig)","f0e590ab":"col = ['Q27_B_Part_1', 'Q27_B_Part_2',\n       'Q27_B_Part_3', 'Q27_B_Part_4', 'Q27_B_Part_5', 'Q27_B_Part_6',\n       'Q27_B_Part_7', 'Q27_B_Part_8', 'Q27_B_Part_9', 'Q27_B_Part_10',\n       'Q27_B_Part_11', 'Q27_B_OTHER']\na = []\nfor i in col:\n    a.append(df[i].value_counts().keys()[0])\nb = []\nfor i in col:\n    b.append(df[i].value_counts().iloc[0])","c6234aef":"data = [go.Bar(x=a,y= b,text = b,\n              textposition= 'outside',\n              width=[0.7, 0.7],\n              marker = dict(color = 'khaki',\n                            line_color = 'black',\n                            line_width=3))]\n\nlayout = go.Layout(title='Cloud Computing Platforms do you hope to familiar within next two years',\n                   xaxis = dict(title='Cloud Computing Platforms'),\n                   width=800,\n                   height=600,\n                   template = 'plotly_white')\n\nfig=go.Figure(data=data, layout=layout)\nfig.update_yaxes(range=[0,8500])\niplot(fig)","38ab2b49":"fig = make_subplots(rows=1,cols=2,\n                    subplot_titles=('Countplot',\n                                    'Percentages'),\n                    specs=[[{\"type\": \"xy\"},\n                            {'type':'domain'}]])\nfig.add_trace(go.Bar(y = df['Q28'].value_counts().values.tolist(), \n                      x = df['Q28'].value_counts().index, \n                      text=df['Q28'].value_counts().values.tolist(),\n              textfont=dict(size=15),\n                      textposition = 'outside',\n                      showlegend=False,\n              marker = dict(color = 'snow',\n                            line_color = 'black',\n                            line_width=3)),row = 1,col = 1)\nfig.add_trace((go.Pie(labels=df['Q28'].value_counts().keys(),\n                             values=df['Q28'].value_counts().values,textfont = dict(size = 16),\n                     textposition='auto',\n                     showlegend = True,)), row = 1, col = 2)\nfig.update_layout(title={'text': 'Cloud Platforms With Best Developer Experience',\n                         'y':1,\n                         'x':0.5,\n                         'xanchor': 'center',\n                         'yanchor': 'top'},width = 1400,height = 600,\n                  template='plotly_white')\nfig.update_yaxes(range=[0,1000])\niplot(fig)","e8936701":"col = ['Q29_A_Part_1',\n       'Q29_A_Part_2', 'Q29_A_Part_3', 'Q29_A_Part_4', 'Q29_A_OTHER']\na = []\nfor i in col:\n    a.append(df[i].value_counts().keys()[0])\nb = []\nfor i in col:\n    b.append(df[i].value_counts().iloc[0])","639c6d42":"fig = make_subplots(rows=1,cols=2,\n                    subplot_titles=('Countplot',\n                                    'Percentages'),\n                    specs=[[{\"type\": \"xy\"},\n                            {'type':'domain'}]])\nfig.add_trace(go.Bar(y = b, \n                      x = a, \n                      text=b,\n              textfont=dict(size=15),\n                      textposition = 'outside',\n                      showlegend=False,\n              marker = dict(color = 'lightblue',\n                            line_color = 'black',\n                            line_width=3)),row = 1,col = 1)\nfig.add_trace((go.Pie(labels=a,\n                             values=b,textfont = dict(size = 16),\n                     textposition='auto',\n                     showlegend = True)), row = 1, col = 2)\nfig.update_layout(title={'text': 'Cloud Computing Products used on Regular Basis',\n                         'y':1,\n                         'x':0.5,\n                         'xanchor': 'center',\n                         'yanchor': 'top'},width = 1000,height = 600,\n                  template='plotly_white')\nfig.update_yaxes(range=[0,2700])\niplot(fig)","dc52d823":"col = ['Q29_B_Part_1',\n       'Q29_B_Part_2', 'Q29_B_Part_3', 'Q29_B_Part_4', 'Q29_B_OTHER']\na = []\nfor i in col:\n    a.append(df[i].value_counts().keys()[0])\nb = []\nfor i in col:\n    b.append(df[i].value_counts().iloc[0])","9974640c":"fig = make_subplots(rows=1,cols=2,\n                    subplot_titles=('Countplot',\n                                    'Percentages'),\n                    specs=[[{\"type\": \"xy\"},\n                            {'type':'domain'}]])\nfig.add_trace(go.Bar(y = b, \n                      x = a, \n                      text=b,\n              textfont=dict(size=15),\n                      textposition = 'outside',\n                      showlegend=False,\n              marker = dict(color = 'mintcream',\n                            line_color = 'black',\n                            line_width=3)),row = 1,col = 1)\nfig.add_trace((go.Pie(labels=a,\n                             values=b,textfont = dict(size = 16),\n                     textposition='auto',\n                     showlegend = True)), row = 1, col = 2)\nfig.update_layout(title={'text': 'Cloud Computing Products used on Regular Basis',\n                         'y':1,\n                         'x':0.5,\n                         'xanchor': 'center',\n                         'yanchor': 'top'},width = 1000,height = 600,\n                  template='plotly_white')\nfig.update_yaxes(range=[0,8000])\niplot(fig)","f2caa2eb":"col = ['Q30_A_Part_1', 'Q30_A_Part_2', 'Q30_A_Part_3', 'Q30_A_Part_4',\n       'Q30_A_Part_5', 'Q30_A_Part_6', 'Q30_A_Part_7', 'Q30_A_OTHER',]\na = []\nfor i in col:\n    a.append(df[i].value_counts().keys()[0])\nb = []\nfor i in col:\n    b.append(df[i].value_counts().iloc[0])","6801384b":"data = [go.Bar(x=a,y= b,text = b,\n              textposition= 'outside',\n              width=[0.7, 0.7],\n              marker = dict(color = 'red',\n                            line_color = 'black',\n                            line_width=3))]\n\nlayout = go.Layout(title='Storage Products used on regular basis',\n                   xaxis = dict(title='Storage Products'),\n                   width=800,\n                   height=600,\n                   template = 'plotly_white')\n\nfig=go.Figure(data=data, layout=layout)\nfig.update_yaxes(range=[0,3000])\niplot(fig)","2a8fe429":"col = ['Q31_A_Part_1', 'Q31_A_Part_2', 'Q31_A_Part_3', 'Q31_A_Part_4',\n       'Q31_A_Part_5', 'Q31_A_Part_6', 'Q31_A_Part_7', 'Q31_A_Part_8',\n       'Q31_A_Part_9', 'Q31_A_OTHER']\na = []\nfor i in col:\n    a.append(df[i].value_counts().keys()[0])\nb = []\nfor i in col:\n    b.append(df[i].value_counts().iloc[0])","e7a17194":"data = [go.Bar(x=a,y= b,text = b,\n              textposition= 'outside',\n              width=[0.7, 0.7],\n              marker = dict(color = 'green',\n                            line_color = 'black',\n                            line_width=3))]\n\nlayout = go.Layout(title='Machine Learning Products used on regular basis',\n                   xaxis = dict(title='Machine Learning Products'),\n                   width=800,\n                   height=600,\n                   template = 'plotly_white')\n\nfig=go.Figure(data=data, layout=layout)\nfig.update_yaxes(range=[0,7000])\niplot(fig)","08333cec":"col = ['Q31_B_Part_1', 'Q31_B_Part_2', 'Q31_B_Part_3', 'Q31_B_Part_4',\n       'Q31_B_Part_5', 'Q31_B_Part_6', 'Q31_B_Part_7', 'Q31_B_Part_8',\n       'Q31_B_Part_9', 'Q31_B_OTHER']\na = []\nfor i in col:\n    a.append(df[i].value_counts().keys()[0])\nb = []\nfor i in col:\n    b.append(df[i].value_counts().iloc[0])","2fd64db0":"data = [go.Bar(x=a,y= b,text = b,\n              textposition= 'outside',\n              width=[0.7, 0.7],\n              marker = dict(color = 'lightcyan',\n                            line_color = 'black',\n                            line_width=3))]\n\nlayout = go.Layout(title='Machine Learning Products hope to familiar with them in next 2 years',\n                   xaxis = dict(title='Machine Learning Products'),\n                   width=800,\n                   height=600,\n                   template = 'plotly_white')\n\nfig=go.Figure(data=data, layout=layout)\nfig.update_yaxes(range=[0,6800])\niplot(fig)","59dbedf7":"col = ['Q32_A_Part_1', 'Q32_A_Part_2',\n       'Q32_A_Part_3', 'Q32_A_Part_4', 'Q32_A_Part_5', 'Q32_A_Part_6',\n       'Q32_A_Part_7', 'Q32_A_Part_8', 'Q32_A_Part_9', 'Q32_A_Part_10',\n       'Q32_A_Part_11', 'Q32_A_Part_12', 'Q32_A_Part_13', 'Q32_A_Part_14',\n       'Q32_A_Part_15', 'Q32_A_Part_16', 'Q32_A_Part_17', 'Q32_A_Part_18',\n       'Q32_A_Part_19', 'Q32_A_Part_20', 'Q32_A_OTHER']\na = []\nfor i in col:\n    a.append(df[i].value_counts().keys()[0])\nb = []\nfor i in col:\n    b.append(df[i].value_counts().iloc[0])","21576f4f":"data = [go.Bar(x=a,y= b,text = b,\n              textposition= 'outside',\n              width=[0.7, 0.7],\n              marker = dict(color = 'gold',\n                            line_color = 'black',\n                            line_width=3))]\n\nlayout = go.Layout(title='Big data Products used on regular basis',\n                   xaxis = dict(title='Big data Products'),\n                   width=800,\n                   height=600,\n                   template = 'plotly_white')\n\nfig=go.Figure(data=data, layout=layout)\nfig.update_yaxes(range=[0,4000])\niplot(fig)","a93eb5d5":"col = ['Q32_B_Part_1', 'Q32_B_Part_2',\n       'Q32_B_Part_3', 'Q32_B_Part_4', 'Q32_B_Part_5', 'Q32_B_Part_6',\n       'Q32_B_Part_7', 'Q32_B_Part_8', 'Q32_B_Part_9', 'Q32_B_Part_10',\n       'Q32_B_Part_11', 'Q32_B_Part_12', 'Q32_B_Part_13', 'Q32_B_Part_14',\n       'Q32_B_Part_15', 'Q32_B_Part_16', 'Q32_B_Part_17', 'Q32_B_Part_18',\n       'Q32_B_Part_19', 'Q32_B_Part_20', 'Q32_B_OTHER']\na = []\nfor i in col:\n    a.append(df[i].value_counts().keys()[0])\nb = []\nfor i in col:\n    b.append(df[i].value_counts().iloc[0])","a98e10d5":"data = [go.Bar(x=a,y= b,text = b,\n              textposition= 'outside',\n              width=[0.7, 0.7],\n              marker = dict(color = 'violet',\n                            line_color = 'black',\n                            line_width=3))]\n\nlayout = go.Layout(title='Big data Products hope to familiar with them in next 2 years',\n                   xaxis = dict(title='Big data Products'),\n                   width=800,\n                   height=600,\n                   template = 'plotly_white')\n\nfig=go.Figure(data=data, layout=layout)\nfig.update_yaxes(range=[0,6700])\niplot(fig)","d020eb1a":"data = [go.Bar(x=df['Q33'].value_counts().keys(),\n               y=df['Q33'].value_counts(),\n               text =round(df['Q33'].value_counts(),2),\n              textposition= 'outside',\n              width=[0.7, 0.7],\n              marker = dict(color = 'tan',\n                            line_color = 'black',\n                            line_width=3))]\n\nlayout = go.Layout(title='Data Products Used most Often',\n                   xaxis = dict(title='Data Products Name'),\n                   width=800,\n                   height=600,\n                   template = 'plotly_white')\n\nfig=go.Figure(data=data, layout=layout)\nfig.update_yaxes(range=[0,1500])\niplot(fig)","035235c0":"col = ['Q34_A_Part_1', 'Q34_A_Part_2', 'Q34_A_Part_3', 'Q34_A_Part_4',\n       'Q34_A_Part_5', 'Q34_A_Part_6', 'Q34_A_Part_7', 'Q34_A_Part_8',\n       'Q34_A_Part_9', 'Q34_A_Part_10', 'Q34_A_Part_11', 'Q34_A_Part_12',\n       'Q34_A_Part_13', 'Q34_A_Part_14', 'Q34_A_Part_15', 'Q34_A_Part_16',\n       'Q34_A_OTHER']\na = []\nfor i in col:\n    a.append(df[i].value_counts().keys()[0])\nb = []\nfor i in col:\n    b.append(df[i].value_counts().iloc[0])","95fe7ba2":"data = [go.Bar(x=a,y= b,text = b,\n              textposition= 'outside',\n              width=[0.7, 0.7],\n              marker = dict(color = 'moccasin',\n                            line_color = 'black',\n                            line_width=3))]\n\nlayout = go.Layout(title='Business Intelligence tools used on regular basis',\n                   xaxis = dict(title='Businees Intelligence Tools'),\n                   width=800,\n                   height=600,\n                   template = 'plotly_white')\n\nfig=go.Figure(data=data, layout=layout)\nfig.update_yaxes(range=[0,4500])\niplot(fig)","f022d10c":"col = ['Q34_B_Part_1', 'Q34_B_Part_2', 'Q34_B_Part_3', 'Q34_B_Part_4',\n       'Q34_B_Part_5', 'Q34_B_Part_6', 'Q34_B_Part_7', 'Q34_B_Part_8',\n       'Q34_B_Part_9', 'Q34_B_Part_10', 'Q34_B_Part_11', 'Q34_B_Part_12',\n       'Q34_B_Part_13', 'Q34_B_Part_14', 'Q34_B_Part_15', 'Q34_B_Part_16',\n       'Q34_B_OTHER']\na = []\nfor i in col:\n    a.append(df[i].value_counts().keys()[0])\nb = []\nfor i in col:\n    b.append(df[i].value_counts().iloc[0])","981f667f":"data = [go.Bar(x=a,y= b,text = b,\n              textposition= 'outside',\n              width=[0.7, 0.7],\n              marker = dict(color = 'firebrick',\n                            line_color = 'black',\n                            line_width=3))]\n\nlayout = go.Layout(title='Business Intelligence tools hope to familiar within next 2 years',\n                   xaxis = dict(title='Businees Intelligence Tools'),\n                   width=800,\n                   height=600,\n                   template = 'plotly_white')\n\nfig=go.Figure(data=data, layout=layout)\nfig.update_yaxes(range=[0,6000])\niplot(fig)","9f7be424":"data = [go.Bar(x=df['Q35'].value_counts().keys(),\n               y=df['Q35'].value_counts(),\n               text =round(df['Q35'].value_counts(),2),\n              textposition= 'outside',\n              width=[0.7, 0.7],\n              marker = dict(color = 'teal',\n                            line_color = 'black',\n                            line_width=3))]\n\nlayout = go.Layout(title='Business Intelligent Tools used Most',\n                   xaxis = dict(title='Businees Tools Names'),\n                   width=800,\n                   height=600,\n                   template = 'plotly_white')\n\nfig=go.Figure(data=data, layout=layout)\nfig.update_yaxes(range=[0,1000])\niplot(fig)","059cffcd":"col = ['Q36_A_Part_1', 'Q36_A_Part_2',\n       'Q36_A_Part_3', 'Q36_A_Part_4', 'Q36_A_Part_5', 'Q36_A_Part_6',\n       'Q36_A_Part_7', 'Q36_A_OTHER']\na = []\nfor i in col:\n    a.append(df[i].value_counts().keys()[0])\nb = []\nfor i in col:\n    b.append(df[i].value_counts().iloc[0])","40ce3265":"data = [go.Bar(x=a,y= b,text = b,\n              textposition= 'outside',\n              width=[0.7, 0.7],\n              marker = dict(color = 'yellow',\n                            line_color = 'black',\n                            line_width=3))]\n\nlayout = go.Layout(title='Machine Learning tools used on regular basis',\n                   xaxis = dict(title='Machine Learning Tools'),\n                   width=800,\n                   height=600,\n                   template = 'plotly_white')\n\nfig=go.Figure(data=data, layout=layout)\nfig.update_yaxes(range=[0,7000])\niplot(fig)","3c6fe38d":"col = ['Q36_B_Part_1', 'Q36_B_Part_2',\n       'Q36_B_Part_3', 'Q36_B_Part_4', 'Q36_B_Part_5', 'Q36_B_Part_6',\n       'Q36_B_Part_7', 'Q36_B_OTHER']\na = []\nfor i in col:\n    a.append(df[i].value_counts().keys()[0])\nb = []\nfor i in col:\n    b.append(df[i].value_counts().iloc[0])","9c2ae82c":"data = [go.Bar(x=a,y= b,text = b,\n              textposition= 'outside',\n              width=[0.7, 0.7],\n              marker = dict(color = 'indianred',\n                            line_color = 'black',\n                            line_width=3))]\n\nlayout = go.Layout(title='Machine Learning tools hope to familiar with them within next 2 years',\n                   xaxis = dict(title='Machine Learning Tools'),\n                   width=800,\n                   height=600,\n                   template = 'plotly_white')\n\nfig=go.Figure(data=data, layout=layout)\nfig.update_yaxes(range=[0,7000])\niplot(fig)","f76b0dda":"col = ['Q37_A_Part_1', 'Q37_A_Part_2',\n       'Q37_A_Part_3', 'Q37_A_Part_4', 'Q37_A_Part_5', 'Q37_A_Part_6',\n       'Q37_A_Part_7', 'Q37_A_OTHER']\na = []\nfor i in col:\n    a.append(df[i].value_counts().keys()[0])\nb = []\nfor i in col:\n    b.append(df[i].value_counts().iloc[0])","4a51d414":"data = [go.Bar(x=a,y= b,text = b,\n              textposition= 'outside',\n              width=[0.7, 0.7],\n              marker = dict(color = 'darkcyan',\n                            line_color = 'black',\n                            line_width=3))]\n\nlayout = go.Layout(title='Auto Machine Learning tools used on regular basis',\n                   xaxis = dict(title='Auto Machine Learning Tools'),\n                   width=800,\n                   height=600,\n                   template = 'plotly_white')\n\nfig=go.Figure(data=data, layout=layout)\nfig.update_yaxes(range=[0,1500])\niplot(fig)","5a4b0755":"col = ['Q37_B_Part_1', 'Q37_B_Part_2',\n       'Q37_B_Part_3', 'Q37_B_Part_4', 'Q37_B_Part_5', 'Q37_B_Part_6',\n       'Q37_B_Part_7', 'Q37_B_OTHER']\na = []\nfor i in col:\n    a.append(df[i].value_counts().keys()[0])\nb = []\nfor i in col:\n    b.append(df[i].value_counts().iloc[0])","49a9e782":"data = [go.Bar(x=a,y= b,text = b,\n              textposition= 'outside',\n              width=[0.7, 0.7],\n              marker = dict(color = 'indianred',\n                            line_color = 'black',\n                            line_width=3))]\n\nlayout = go.Layout(title='Auto Machine Learning tools hope to familiar with them within next 2 years',\n                   xaxis = dict(title='Auto Machine Learning Tools'),\n                   width=800,\n                   height=600,\n                   template = 'plotly_white')\n\nfig=go.Figure(data=data, layout=layout)\nfig.update_yaxes(range=[0,5500])\niplot(fig)","578d4532":"col = ['Q38_A_Part_1', 'Q38_A_Part_2',\n       'Q38_A_Part_3', 'Q38_A_Part_4', 'Q38_A_Part_5', 'Q38_A_Part_6',\n       'Q38_A_Part_7', 'Q38_A_Part_8', 'Q38_A_Part_9', 'Q38_A_Part_10',\n       'Q38_A_Part_11', 'Q38_A_OTHER']\na = []\nfor i in col:\n    a.append(df[i].value_counts().keys()[0])\nb = []\nfor i in col:\n    b.append(df[i].value_counts().iloc[0])","06be0c2d":"data = [go.Bar(x=a,y= b,text = b,\n              textposition= 'outside',\n              width=[0.7, 0.7],\n              marker = dict(color = 'darkseagreen',\n                            line_color = 'black',\n                            line_width=3))]\n\nlayout = go.Layout(title='Machine Learning Experimrnt tools used to manage work',\n                   xaxis = dict(title='Machine Learning Experiment Tools'),\n                   width=800,\n                   height=600,\n                   template = 'plotly_white')\n\nfig=go.Figure(data=data, layout=layout)\nfig.update_yaxes(range=[0,6500])\niplot(fig)","aa29d614":"col = ['Q38_B_Part_1', 'Q38_B_Part_2',\n       'Q38_B_Part_3', 'Q38_B_Part_4', 'Q38_B_Part_5', 'Q38_B_Part_6',\n       'Q38_B_Part_7', 'Q38_B_Part_8', 'Q38_B_Part_9', 'Q38_B_Part_10',\n       'Q38_B_Part_11', 'Q38_B_OTHER']\na = []\nfor i in col:\n    a.append(df[i].value_counts().keys()[0])\nb = []\nfor i in col:\n    b.append(df[i].value_counts().iloc[0])","09304465":"data = [go.Bar(x=a,y= b,text = b,\n              textposition= 'outside',\n              width=[0.7, 0.7],\n              marker = dict(color = 'indianred',\n                            line_color = 'black',\n                            line_width=3))]\n\nlayout = go.Layout(title='Machine Learning Experiment tools hope to familiar with them within next 2 years',\n                   xaxis = dict(title='Machine Learning Experimeny Tools'),\n                   width=800,\n                   height=600,\n                   template = 'plotly_white')\n\nfig=go.Figure(data=data, layout=layout)\nfig.update_yaxes(range=[0,5000])\niplot(fig)","99a2707b":"col = ['Q39_Part_1', 'Q39_Part_2',\n       'Q39_Part_3', 'Q39_Part_4', 'Q39_Part_5', 'Q39_Part_6',\n       'Q39_Part_7', 'Q39_Part_8', 'Q39_Part_9', 'Q39_OTHER']\na = []\nfor i in col:\n    a.append(df[i].value_counts().keys()[0])\nb = []\nfor i in col:\n    b.append(df[i].value_counts().iloc[0])\n\ndata = [go.Bar(x=a,y= b,text = b,\n              textposition= 'outside',\n              width=[0.7, 0.7],\n              marker = dict(color = 'bisque',\n                            line_color = 'black',\n                            line_width=3))]\n\nlayout = go.Layout(title='Publicly share your data analysis or machine learning applications',\n                   xaxis = dict(title='Public Aplications'),\n                   width=800,\n                   height=600,\n                   template = 'plotly_white')\n\nfig=go.Figure(data=data, layout=layout)\nfig.update_yaxes(range=[0,5000])\niplot(fig)","82340b37":"col = ['Q40_Part_1', 'Q40_Part_2', 'Q40_Part_3', 'Q40_Part_4',\n       'Q40_Part_5', 'Q40_Part_6', 'Q40_Part_7', 'Q40_Part_8',\n       'Q40_Part_9', 'Q40_Part_10', 'Q40_Part_11', 'Q40_OTHER']\na = []\nfor i in col:\n    a.append(df[i].value_counts().keys()[0])\nb = []\nfor i in col:\n    b.append(df[i].value_counts().iloc[0])\n    \ndata = [go.Bar(x=a,y= b,text = b,\n              textposition= 'outside',\n              width=[0.7, 0.7],\n              marker = dict(color = 'indigo',\n                            line_color = 'black',\n                            line_width=3))]\n\nlayout = go.Layout(title='Platform name where you begun or completed data science course',\n                   xaxis = dict(title='Platform Name'),\n                   width=800,\n                   height=600,\n                   template = 'plotly_white')\n\nfig=go.Figure(data=data, layout=layout)\nfig.update_yaxes(range=[0,12000])\niplot(fig)","a0d8b050":"fig = make_subplots(rows=1,cols=2,\n                    subplot_titles=('Countplot',\n                                    'Percentages'),\n                    specs=[[{\"type\": \"xy\"},\n                            {'type':'domain'}]])\nfig.add_trace(go.Bar(y = df['Q41'].value_counts().values.tolist(), \n                      x = df['Q41'].value_counts().index, \n                      text=df['Q41'].value_counts().values.tolist(),\n              textfont=dict(size=15),\n                      textposition = 'outside',\n                      showlegend=False,\n              marker = dict(color = 'gainsboro',\n                            line_color = 'black',\n                            line_width=3)),row = 1,col = 1)\nfig.add_trace((go.Pie(labels=df['Q41'].value_counts().keys(),\n                             values=df['Q41'].value_counts().values,textfont = dict(size = 16),\n                     textposition='auto',\n                     showlegend = True,)), row = 1, col = 2)\nfig.update_layout(title={'text': 'Primary Tool used most to work at school\/home',\n                         'y':1,\n                         'x':0.5,\n                         'xanchor': 'center',\n                         'yanchor': 'top'},width = 1000,height = 600,\n                  template='plotly_white')\nfig.update_yaxes(range=[0,8000])\niplot(fig)","73c0f53e":"col = ['Q42_Part_1', 'Q42_Part_2', 'Q42_Part_3', 'Q42_Part_4',\n       'Q42_Part_5', 'Q42_Part_6', 'Q42_Part_7', 'Q42_Part_8',\n       'Q42_Part_9', 'Q42_Part_10', 'Q42_Part_11', 'Q42_OTHER']\na = []\nfor i in col:\n    a.append(df[i].value_counts().keys()[0])\nb = []\nfor i in col:\n    b.append(df[i].value_counts().iloc[0])\n    \ndata = [go.Bar(x=a,y= b,text = b,\n              textposition= 'outside',\n              width=[0.7, 0.7],\n              marker = dict(color = 'dimgrey',\n                            line_color = 'black',\n                            line_width=3))]\n\nlayout = go.Layout(title='Favourite Sociaal Media to report a data science topics',\n                   xaxis = dict(title='Social media'),\n                   width=800,\n                   height=600,\n                   template = 'plotly_white')\n\nfig=go.Figure(data=data, layout=layout)\nfig.update_yaxes(range=[0,13000])\niplot(fig)","fdb661a9":"df_2018['Q1'].replace(['Male'],'Man',inplace = True)\ndf_2018['Q1'].replace(['Female'],'Woman',inplace = True)\ndf_2019['Q2'].replace(['Male'],'Man',inplace = True)\ndf_2019['Q2'].replace(['Female'],'Woman',inplace = True)\ndf_2020['Q2'].replace(['Male'],'Man',inplace = True)\ndf_2020['Q2'].replace(['Female'],'Woman',inplace = True)","cb00b75f":"df_2018['Q4'].replace(['Master\u00e2\u0080\u0099s degree'],\"Master\u2019s degree\",inplace = True)\ndf_2019['Q4'].replace(['Master\u00e2\u0080\u0099s degree'],\"Master\u2019s degree\",inplace = True)\ndf_2020['Q4'].replace(['Master\u00e2\u0080\u0099s degree'],\"Master\u2019s degree\",inplace = True)\n\ndf_2018['Q4'].replace(['Bachelor\u00e2\u0080\u0099s degree'],\"Bachelor\u2019s degree\",inplace = True)\ndf_2019['Q4'].replace(['Bachelor\u00e2\u0080\u0099s degree'],\"Bachelor\u2019s degree\",inplace = True)\ndf_2020['Q4'].replace(['Bachelor\u00e2\u0080\u0099s degree'],\"Bachelor\u2019s degree\",inplace = True)\n\ndf_2018['Q4'].replace(['Some college\/university study without earning a bachelor\u00e2\u0080\u0099s degree'],\"Some college\/university study without earning a bachelor\u2019s degree\",inplace = True)\ndf_2019['Q4'].replace(['Some college\/university study without earning a bachelor\u00e2\u0080\u0099s degree'],\"Some college\/university study without earning a bachelor\u2019s degree\",inplace = True)\ndf_2020['Q4'].replace(['Some college\/university study without earning a bachelor\u00e2\u0080\u0099s degree'],\"Some college\/university study without earning a bachelor\u2019s degree\",inplace = True)\n\ndf_2018['Q4'].replace(['Professional degree'],\"Professional doctorate\",inplace = True)\ndf_2019['Q4'].replace(['Professional degree'],\"Professional doctorate\",inplace = True)\ndf_2020['Q4'].replace(['Professional degree'],\"Professional doctorate\",inplace = True)","4f48c404":"x = ['2018','2019','2020','2021']\ny = [len(df_2018[df_2018['Q1'] == 'Woman']['Q1'].tolist()),len(df_2019[df_2019['Q2'] == 'Woman']['Q2'].tolist()),len(df_2020[df_2020['Q2'] == 'Woman']['Q2'].tolist()),len(df[df['Q2'] == 'Woman']['Q2'].tolist())]\nfig = plt.figure(figsize=(10, 6))\nsns.set(style=\"dark\", color_codes=True)\npal = sns.color_palette(\"YlGnBu\", len(x))\nax = sns.barplot(x=x,y=y,palette=pal)\nfor p in ax.patches:\n        ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.3, p.get_height()),\n                    ha='center', va='bottom',\n                    color= 'black')\nplt.suptitle ('Woman Involved In survey',weight = 'bold')\nplt.xticks(rotation=90,weight = 'bold')\nplt.show()","cf91a383":"x = ['2018','2019','2020','2021']\ny = [len(df_2018[(df_2018['Q1'] == 'Woman') & (df_2018['Q6'] != 'Not employed')]['Q1']),len(df_2019[(df_2019['Q2'] == 'Woman') & (df_2019['Q5'] != 'Not employed')]['Q5']),len(df_2020[(df_2020['Q2'] == 'Woman') & (df_2020['Q5'] != 'Currently not employed')]['Q5']),len(df[(df['Q2'] == 'Woman') & (df['Q5'] != 'Currently not employed')]['Q5'])]\nfig = plt.figure(figsize=(10, 6))\nsns.set(style=\"dark\", color_codes=True)\npal = sns.color_palette(\"YlGnBu\", len(x))\nax = sns.barplot(x=x,y=y,palette=pal)\nfor p in ax.patches:\n        ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.3, p.get_height()),\n                    ha='center', va='bottom',\n                    color= 'black')\nplt.suptitle ('Employed Woman In survey',weight = 'bold')\nplt.xticks(rotation=90,weight = 'bold')\nplt.show()","f972ea1e":"x = ['2018','2019','2020','2021']\ny = [len(df_2018[(df_2018['Q1'] == 'Woman') & (df_2018['Q6'] == 'Not employed')]['Q1']),len(df_2019[(df_2019['Q2'] == 'Woman') & (df_2019['Q5'] == 'Not employed')]['Q5']),len(df_2020[(df_2020['Q2'] == 'Woman') & (df_2020['Q5'] == 'Currently not employed')]['Q5']),len(df[(df['Q2'] == 'Woman') & (df['Q5'] == 'Currently not employed')]['Q5'])]\nfig = plt.figure(figsize=(10, 6))\nsns.set(style=\"dark\", color_codes=True)\npal = sns.color_palette(\"YlGnBu\", len(x))\nax = sns.barplot(x=x,y=y,palette=pal)\nfor p in ax.patches:\n        ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.3, p.get_height()),\n                    ha='center', va='bottom',\n                    color= 'black')\nplt.suptitle ('Unemployed Woman In survey',weight = 'bold')\nplt.xticks(rotation=90,weight = 'bold')\nplt.show()","38266f09":"x = ['2018','2019','2020','2021']\ny = [len(df_2018[(df_2018['Q1'] == 'Woman') & (df_2018['Q6'] != 'Student')]['Q1']),len(df_2019[(df_2019['Q2'] == 'Woman') & (df_2019['Q5'] != 'Student')]['Q5']),len(df_2020[(df_2020['Q2'] == 'Woman') & (df_2020['Q5'] != 'Student')]['Q5']),len(df[(df['Q2'] == 'Woman') & (df['Q5'] != 'Student')]['Q5'])]\nfig = plt.figure(figsize=(10, 6))\nsns.set(style=\"dark\", color_codes=True)\npal = sns.color_palette(\"YlGnBu\", len(x))\nax = sns.barplot(x=x,y=y,palette=pal)\nfor p in ax.patches:\n        ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.3, p.get_height()),\n                    ha='center', va='bottom',\n                    color= 'black')\nplt.suptitle ('Woman Students In survey',weight = 'bold')\nplt.xticks(rotation=90,weight = 'bold')\nplt.show()","6486a6f9":"a = ['Data Scientist','Data Analyst','Machine Learning Engineer',\n     'Business Analyst','Data Engineer','Statistician',\n     'DBA\/Database Engineer','Marketing Analyst','Data Journalist']\nc = 0\nn = []\nfor i in df_2018[df_2018['Q1'] == 'Woman']['Q6']:\n    if i in a:\n        c += 1\nn.append(c)\nc = 0\nfor i in df_2019[df_2019['Q2'] == 'Woman']['Q5']:\n    if i in a:\n        c += 1\nn.append(c)\nc = 0\nfor i in df_2020[df_2020['Q2'] == 'Woman']['Q5']:\n    if i in a:\n        c += 1\nn.append(c)\nc = 0\nfor i in df[df['Q2'] == 'Woman']['Q5']:\n    if i in a:\n        c += 1\nn.append(c)\nx = ['2018','2019','2020','2021']\ny = n\nfig = plt.figure(figsize=(10, 6))\nsns.set(style=\"dark\", color_codes=True)\npal = sns.color_palette(\"YlGnBu\", len(x))\nax = sns.barplot(x=x,y=y,palette=pal)\nfor p in ax.patches:\n        ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.3, p.get_height()),\n                    ha='center', va='bottom',\n                    color= 'black')\nplt.suptitle ('Woman in Jobs related to Data Science',weight = 'bold')\nplt.xticks(rotation=90,weight = 'bold')\nplt.show()","dc843567":"# Displaying values at the top of the Grouped Bar Chart using plt.text()\nplt.figure(figsize=(10,6))\n\n# set width of bar\nbarWidth = 0.2\na = ['Data Scientist','Data Analyst','Machine Learning Engineer',\n     'Business Analyst','Data Engineer','Statistician',\n     'DBA\/Database Engineer','Marketing Analyst','Data Journalist']\nc = 0\nn = []\nfor i in df_2018[df_2018['Q1'] == 'Woman']['Q6']:\n    if i in a:\n        c += 1\nn.append(c)\nc = 0\nfor i in df_2019[df_2019['Q2'] == 'Woman']['Q5']:\n    if i in a:\n        c += 1\nn.append(c)\nc = 0\nfor i in df_2020[df_2020['Q2'] == 'Woman']['Q5']:\n    if i in a:\n        c += 1\nn.append(c)\nc = 0\nfor i in df[df['Q2'] == 'Woman']['Q5']:\n    if i in a:\n        c += 1\nn.append(c)\n\nn1 = []\nc = 0\nfor i in df_2018[df_2018['Q1'] == 'Woman']['Q6']:\n    if i not in a:\n        c += 1\nn1.append(c)\nc = 0\nfor i in df_2019[df_2019['Q2'] == 'Woman']['Q5']:\n    if i not in a:\n        c += 1\nn1.append(c)\nc = 0\nfor i in df_2020[df_2020['Q2'] == 'Woman']['Q5']:\n    if i not in a:\n        c += 1\nn1.append(c)\nc = 0\nfor i in df[df['Q2'] == 'Woman']['Q5']:\n    if i not in a:\n        c += 1\nn1.append(c)\nx = ['2018','2019','2020','2021']\ny1 = n\ny2 = n1\n\npos1 = np.arange(len(y1))\npos2 = [x + barWidth for x in pos1]\n\n# Make the plot\nplt.bar(pos1, y1, color='#FBC02D', width=barWidth, label='data science field')\nplt.bar(pos2, y2, color='#F57F17', width=barWidth, label='Other fields')\n\n# Add xticks on the middle of the group bars\nplt.xticks([i + barWidth for i in range(len(y1))], x,rotation=90,weight = 'bold')\n\nfor x,y in zip(pos1,y1):\n    plt.text(x, y, '%d' % y, ha='center' , va= 'bottom')\n    \nfor x,y in zip(pos2,y2):\n    plt.text(x, y, '%d' % y, ha='center' , va= 'bottom')\n    \nplt.suptitle ('Woman in Jobs related to Data Science vs Other Fields',weight = 'bold')\n\n# Create legend & Show graphic\nplt.legend()\nplt.show()","3b8998f8":"n = []\nn.append(len(df_2018[(df_2018['Q1'] == 'Woman') & (df_2018['Q4'] == \"Bachelor\u2019s degree\") & (df_2018['Q6'] == 'Data Analyst')]))\nn.append(len(df_2019[(df_2019['Q2'] == 'Woman') & (df_2019['Q4'] == \"Bachelor\u2019s degree\") & (df_2019['Q5'] == 'Data Analyst')]))\nn.append(len(df_2020[(df_2020['Q2'] == 'Woman') & (df_2020['Q4'] == \"Bachelor\u2019s degree\") & (df_2020['Q5'] == 'Data Analyst')]))\nn.append(len(df[(df['Q2'] == 'Woman') & (df['Q4'] == \"Bachelor\u2019s degree\") & (df['Q5'] == 'Data Analyst')]))\n\nx = ['2018','2019','2020','2021']\ny = n\nfig = plt.figure(figsize=(10, 6))\nsns.set(style=\"dark\", color_codes=True)\npal = sns.color_palette(\"YlGnBu\", len(x))\nax = sns.barplot(x=x,y=y,palette=pal)\nfor p in ax.patches:\n        ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.3, p.get_height()),\n                    ha='center', va='bottom',\n                    color= 'black')\nplt.suptitle (\"Woman with Bachelor's degree and working as a Data Analyst\",weight = 'bold')\nplt.xticks(rotation=90,weight = 'bold')\nplt.show()","d8624073":"# Displaying values at the top of the Grouped Bar Chart using plt.text()\nplt.figure(figsize=(10,6))\n\n# set width of bar\nbarWidth = 0.2\n\nn = []\nn.append(len(df_2018[(df_2018['Q1'] == 'Woman') & (df_2018['Q4'] == \"Bachelor\u2019s degree\") & (df_2018['Q6'] != 'Not employed')]))\nn.append(len(df_2019[(df_2019['Q2'] == 'Woman') & (df_2019['Q4'] == \"Bachelor\u2019s degree\") & (df_2019['Q5'] != 'Not employed')]))\nn.append(len(df_2020[(df_2020['Q2'] == 'Woman') & (df_2020['Q4'] == \"Bachelor\u2019s degree\") & (df_2020['Q5'] != 'Currently not employed')]))\nn.append(len(df[(df['Q2'] == 'Woman') & (df['Q4'] == \"Bachelor\u2019s degree\") & (df['Q5'] != 'Currently not employed')]))\n\nn1 = []\n\nn1.append(len(df_2018[(df_2018['Q1'] == 'Woman') & (df_2018['Q4'] == \"Bachelor\u2019s degree\") & (df_2018['Q6'] == 'Not employed')]))\nn1.append(len(df_2019[(df_2019['Q2'] == 'Woman') & (df_2019['Q4'] == \"Bachelor\u2019s degree\") & (df_2019['Q5'] == 'Not employed')]))\nn1.append(len(df_2020[(df_2020['Q2'] == 'Woman') & (df_2020['Q4'] == \"Bachelor\u2019s degree\") & (df_2020['Q5'] == 'Currently not employed')]))\nn1.append(len(df[(df['Q2'] == 'Woman') & (df['Q4'] == \"Bachelor\u2019s degree\") & (df['Q5'] == 'Currently not employed')]))\n\n\nx = ['2018','2019','2020','2021']\ny1 = n\ny2 = n1\n\npos1 = np.arange(len(y1))\npos2 = [x + barWidth for x in pos1]\n\n# Make the plot\nplt.bar(pos1, y1, color='#FBC02D', width=barWidth, label='Employed')\nplt.bar(pos2, y2, color='#F57F17', width=barWidth, label='Unemployed')\n\n# Add xticks on the middle of the group bars\nplt.xticks([i + barWidth for i in range(len(y1))], x,rotation=90,weight = 'bold')\n\nfor x,y in zip(pos1,y1):\n    plt.text(x, y, '%d' % y, ha='center' , va= 'bottom')\n    \nfor x,y in zip(pos2,y2):\n    plt.text(x, y, '%d' % y, ha='center' , va= 'bottom')\n    \nplt.suptitle (\"Woman with Bachelor's degree and Employed vs Not employed\",weight = 'bold')\n\n# Create legend & Show graphic\nplt.legend()\nplt.show()","aa21226d":"a = ['Data Scientist','Data Analyst','Machine Learning Engineer',\n     'Business Analyst','Data Engineer','Statistician',\n     'DBA\/Database Engineer','Marketing Analyst','Data Journalist']\nc = 0\nn = []\nfor i in df_2018[((df_2018['Q1'] == 'Woman') & (df_2018['Q24'] == 'I have never written code and I do not want to learn')) | ((df_2018['Q1'] == 'Woman') &(df_2018['Q24'] == 'I have never written code but I want to learn'))]['Q6']:\n    if i in a:\n        c += 1\nn.append(c)\nc = 0\nfor i in df_2019[(df_2019['Q2'] == 'Woman') & (df_2019['Q15'] == 'I have never written code')]['Q5']:\n    if i in a:\n        c += 1\nn.append(c)\nc = 0\nfor i in df_2020[(df_2020['Q2'] == 'Woman') & (df_2020['Q6'] == 'I have never written code')]['Q5']:\n    if i in a:\n        c += 1\nn.append(c)\nc = 0\nfor i in df[(df['Q2'] == 'Woman') & (df['Q6'] == 'I have never written code')]['Q5']:\n    if i in a:\n        c += 1\nn.append(c)\nx = ['2018','2019','2020','2021']\ny = n\nfig = plt.figure(figsize=(10, 6))\nsns.set(style=\"dark\", color_codes=True)\npal = sns.color_palette(\"YlGnBu\", len(x))\nax = sns.barplot(x=x,y=y,palette=pal)\nfor p in ax.patches:\n        ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.3, p.get_height()),\n                    ha='center', va='bottom',\n                    color= 'black')\nplt.suptitle ('Woman with No coding experience getting a job in Data Science Field',weight = 'bold')\nplt.xticks(rotation=90,weight = 'bold')\nplt.show()","5ecb93b7":"a = ['Data Scientist','Data Analyst','Machine Learning Engineer',\n     'Business Analyst','Data Engineer','Statistician',\n     'DBA\/Database Engineer','Marketing Analyst','Data Journalist']\nc = 0\nn = []\nfor i in df_2018[(df_2018['Q1'] == 'Woman') & (df_2018['Q16_Part_2'] == 'R')]['Q6']:\n    if i in a:\n        c += 1\nn.append(c)\nc = 0\nfor i in df_2019[(df_2019['Q2'] == 'Woman') & (df_2019['Q18_Part_2'] == 'R')]['Q5']:\n    if i in a:\n        c += 1\nn.append(c)\nc = 0\nfor i in df_2020[(df_2020['Q2'] == 'Woman') & (df_2020['Q7_Part_2'] == 'R')]['Q5']:\n    if i in a:\n        c += 1\nn.append(c)\nc = 0\nfor i in df[(df['Q2'] == 'Woman') & (df['Q7_Part_2'] == 'R')]['Q5']:\n    if i in a:\n        c += 1\nn.append(c)\nx = ['2018','2019','2020','2021']\ny = n\nfig = plt.figure(figsize=(10, 6))\nsns.set(style=\"dark\", color_codes=True)\npal = sns.color_palette(\"YlGnBu\", len(x))\nax = sns.barplot(x=x,y=y,palette=pal)\nfor p in ax.patches:\n        ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.3, p.get_height()),\n                    ha='center', va='bottom',\n                    color= 'black')\nplt.suptitle ('Woman who knows only R and having a job in Data Science Field',weight = 'bold')\nplt.xticks(rotation=90,weight = 'bold')\nplt.show()","bd2b1e7c":"# Displaying values at the top of the Grouped Bar Chart using plt.text()\nplt.figure(figsize=(10,6))\n\n# set width of bar\nbarWidth = 0.2\n\na = ['Data Scientist','Data Analyst','Machine Learning Engineer',\n     'Business Analyst','Data Engineer','Statistician',\n     'DBA\/Database Engineer','Marketing Analyst','Data Journalist']\nc = 0\nn = []\nfor i in df_2018[(df_2018['Q1'] == 'Woman') & (df_2018['Q16_Part_2'] == 'R')]['Q6']:\n    if i in a:\n        c += 1\nn.append(c)\nc = 0\nfor i in df_2019[(df_2019['Q2'] == 'Woman') & (df_2019['Q18_Part_2'] == 'R')]['Q5']:\n    if i in a:\n        c += 1\nn.append(c)\nc = 0\nfor i in df_2020[(df_2020['Q2'] == 'Woman') & (df_2020['Q7_Part_2'] == 'R')]['Q5']:\n    if i in a:\n        c += 1\nn.append(c)\nc = 0\nfor i in df[(df['Q2'] == 'Woman') & (df['Q7_Part_2'] == 'R')]['Q5']:\n    if i in a:\n        c += 1\nn.append(c)\n\nc = 0\nn1 = []\nfor i in df_2018[(df_2018['Q1'] == 'Woman') & (df_2018['Q16_Part_2'] == 'R')]['Q6']:\n    if i == 'Not employed':\n        c += 1\nn1.append(c)\nc = 0\nfor i in df_2019[(df_2019['Q2'] == 'Woman') & (df_2019['Q18_Part_2'] == 'R')]['Q5']:\n    if i == 'Not employed':\n        c += 1\nn1.append(c)\nc = 0\nfor i in df_2020[(df_2020['Q2'] == 'Woman') & (df_2020['Q7_Part_2'] == 'R')]['Q5']:\n    if i == 'Currently not employed':\n        c += 1\nn1.append(c)\nc = 0\nfor i in df[(df['Q2'] == 'Woman') & (df['Q7_Part_2'] == 'R')]['Q5']:\n    if i == 'Currently not employed':\n        c += 1\nn1.append(c)\n\nx = ['2018','2019','2020','2021']\ny1 = n\ny2 = n1\n\npos1 = np.arange(len(y1))\npos2 = [x + barWidth for x in pos1]\n\n# Make the plot\nplt.bar(pos1, y1, color='#FBC02D', width=barWidth, label='Employed')\nplt.bar(pos2, y2, color='#F57F17', width=barWidth, label='unemployed')\n\n# Add xticks on the middle of the group bars\nplt.xticks([i + barWidth for i in range(len(y1))], x,rotation=90,weight = 'bold')\n\nfor x,y in zip(pos1,y1):\n    plt.text(x, y, '%d' % y, ha='center' , va= 'bottom')\n    \nfor x,y in zip(pos2,y2):\n    plt.text(x, y, '%d' % y, ha='center' , va= 'bottom')\n    \nplt.suptitle (\"Woman who only knows R language Employed vs Not employed(Data Science Field)\",weight = 'bold')\n\n# Create legend & Show graphic\nplt.legend()\nplt.show()","ebf0c5d8":"a = ['Data Scientist','Data Analyst','Machine Learning Engineer',\n     'Business Analyst','Data Engineer','Statistician',\n     'DBA\/Database Engineer','Marketing Analyst','Data Journalist']\nc = 0\nn = []\nfor i in df_2018[(df_2018['Q1'] == 'Woman') & (df_2018['Q4'] == 'Master\u2019s degree') & (df_2018['Q3'] == 'United States of America')]['Q6']:\n    if i in a:\n        c += 1\nn.append(c)\nc = 0\nfor i in df_2019[(df_2019['Q2'] == 'Woman') & (df_2019['Q4'] == 'Master\u2019s degree') & (df_2019['Q3'] == 'United States of America')]['Q5']:\n    if i in a:\n        c += 1\nn.append(c)\nc = 0\nfor i in df_2020[(df_2020['Q2'] == 'Woman') & (df_2020['Q4'] == 'Master\u2019s degree') & (df_2020['Q3'] == 'United States of America')]['Q5']:\n    if i in a:\n        c += 1\nn.append(c)\nc = 0\nfor i in df[(df['Q2'] == 'Woman') & (df['Q4'] == 'Master\u2019s degree') & (df['Q3'] == 'United States of America')]['Q5']:\n    if i in a:\n        c += 1\nn.append(c)\nx = ['2018','2019','2020','2021']\ny = n\nfig = plt.figure(figsize=(10, 6))\nsns.set(style=\"dark\", color_codes=True)\npal = sns.color_palette(\"YlGnBu\", len(x))\nax = sns.barplot(x=x,y=y,palette=pal)\nfor p in ax.patches:\n        ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.3, p.get_height()),\n                    ha='center', va='bottom',\n                    color= 'black')\nplt.suptitle ('Woman with master degree and any job related to data science in United States of America',weight = 'bold')\nplt.xticks(rotation=90,weight = 'bold')\nplt.show()","caa5a9e0":"a = ['Data Scientist','Data Analyst','Machine Learning Engineer',\n     'Business Analyst','Data Engineer','Statistician',\n     'DBA\/Database Engineer','Marketing Analyst','Data Journalist']\nc = 0\nn = []\nfor i in df_2018[(df_2018['Q1'] == 'Woman') & (df_2018['Q4'] == 'Doctoral degree')]['Q6']:\n    if i in a:\n        c += 1\nn.append(c)\nc = 0\nfor i in df_2019[(df_2019['Q2'] == 'Woman') & (df_2019['Q4'] == 'Doctoral degree')]['Q5']:\n    if i in a:\n        c += 1\nn.append(c)\nc = 0\nfor i in df_2020[(df_2020['Q2'] == 'Woman') & (df_2020['Q4'] == 'Doctoral degree')]['Q5']:\n    if i in a:\n        c += 1\nn.append(c)\nc = 0\nfor i in df[(df['Q2'] == 'Woman') & (df['Q4'] == 'Doctoral degree')]['Q5']:\n    if i in a:\n        c += 1\nn.append(c)\nx = ['2018','2019','2020','2021']\ny = n\nfig = plt.figure(figsize=(10, 6))\nsns.set(style=\"dark\", color_codes=True)\npal = sns.color_palette(\"YlGnBu\", len(x))\nax = sns.barplot(x=x,y=y,palette=pal)\nfor p in ax.patches:\n        ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.3, p.get_height()),\n                    ha='center', va='bottom',\n                    color= 'black')\nplt.suptitle ('Woman with doctoral degree and having a job in Data Science Field',weight = 'bold')\nplt.xticks(rotation=90,weight = 'bold')\nplt.show()","50542fe0":"n = []\nn.append(len(df_2018[(df_2018['Q1'] == 'Woman') & (df_2018['Q4'] == 'Master\u2019s degree') & (df_2018['Q6'] == 'Data Scientist') & (df_2018['Q3'] == 'Australia')]))\nn.append(len(df_2019[(df_2019['Q2'] == 'Woman') & (df_2019['Q4'] == 'Master\u2019s degree') & (df_2019['Q5'] == 'Data Scientist') & (df_2019['Q3'] == 'Australia')]))\nn.append(len(df_2020[(df_2020['Q2'] == 'Woman') & (df_2020['Q4'] == 'Master\u2019s degree') & (df_2020['Q5'] == 'Data Scientist') & (df_2020['Q3'] == 'Australia')]))\nn.append(len(df[(df['Q2'] == 'Woman') & (df['Q4'] == 'Master\u2019s degree') & (df['Q5'] == 'Data Scientist') & (df['Q3'] == 'Australia')]))\n\nx = ['2018','2019','2020','2021']\ny = n\nfig = plt.figure(figsize=(10, 6))\nsns.set(style=\"dark\", color_codes=True)\npal = sns.color_palette(\"YlGnBu\", len(x))\nax = sns.barplot(x=x,y=y,palette=pal)\nfor p in ax.patches:\n        ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.3, p.get_height()),\n                    ha='center', va='bottom',\n                    color= 'black')\nplt.suptitle (\"Woman with Maters degree and working as a Data Scientist in Australia\",weight = 'bold')\nplt.xticks(rotation=90,weight = 'bold')\nplt.show()","07102b49":"df[(df['Q2'] == 'Woman') & (df['Q3'] == 'Australia')]['Q5'].value_counts()","d37def27":"a = ['Data Scientist','Data Analyst','Machine Learning Engineer',\n     'Business Analyst','Data Engineer','Statistician',\n     'DBA\/Database Engineer','Marketing Analyst','Data Journalist']\nc = 0\nn = []\nfor i in df_2018[(df_2018['Q1'] == 'Woman') & (df_2018['Q4'] == 'Master\u2019s degree') & (df_2018['Q3'] == 'Australia')]['Q6']:\n    if i in a:\n        c += 1\nn.append(c)\nc = 0\nfor i in df_2019[(df_2019['Q2'] == 'Woman') & (df_2019['Q4'] == 'Master\u2019s degree') & (df_2019['Q3'] == 'Australia')]['Q5']:\n    if i in a:\n        c += 1\nn.append(c)\nc = 0\nfor i in df_2020[(df_2020['Q2'] == 'Woman') & (df_2020['Q4'] == 'Master\u2019s degree') & (df_2020['Q3'] == 'Australia')]['Q5']:\n    if i in a:\n        c += 1\nn.append(c)\nc = 0\nfor i in df[(df['Q2'] == 'Woman') & (df['Q4'] == 'Master\u2019s degree') & (df['Q3'] == 'Australia')]['Q5']:\n    if i in a:\n        c += 1\nn.append(c)\nx = ['2018','2019','2020','2021']\ny = n\nfig = plt.figure(figsize=(10, 6))\nsns.set(style=\"dark\", color_codes=True)\npal = sns.color_palette(\"YlGnBu\", len(x))\nax = sns.barplot(x=x,y=y,palette=pal)\nfor p in ax.patches:\n        ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.3, p.get_height()),\n                    ha='center', va='bottom',\n                    color= 'black')\nplt.suptitle ('Woman with master degree and any job related to data science in Australia',weight = 'bold')\nplt.xticks(rotation=90,weight = 'bold')\nplt.show()","2d62f480":"# Displaying values at the top of the Grouped Bar Chart using plt.text()\nplt.figure(figsize=(10,6))\n\n# set width of bar\nbarWidth = 0.2\nn = []\nc = 0\nfor i in df_2018[(df_2018['Q1'] == 'Woman') & (df_2018['Q6'] != 'Not employed')]['Q2']:\n    if i in ['50-54','55-59','60-69','70-79','70+','80+']:\n        c+=1\nn.append(c)\nc = 0\nfor i in df_2019[(df_2019['Q2'] == 'Woman') & (df_2019['Q5'] != 'Not employed')]['Q1']:\n    if i in ['50-54','55-59','60-69','70-79','70+','80+']:\n        c+=1\nn.append(c)\nc = 0\nfor i in df_2020[(df_2020['Q2'] == 'Woman') & (df_2020['Q5'] != 'Currently not employed')]['Q1']:\n    if i in ['50-54','55-59','60-69','70-79','70+','80+']:\n        c+=1\nn.append(c)\nc = 0\nfor i in df[(df['Q2'] == 'Woman') & (df['Q5'] != 'Currently not employed')]['Q1']:\n    if i in ['50-54','55-59','60-69','70-79','70+','80+']:\n        c+=1\nn.append(c)\n\n\nn1 = []\nc = 0\nfor i in df_2018[(df_2018['Q1'] == 'Woman') & (df_2018['Q6'] == 'Not employed')]['Q2']:\n    if i in ['50-54','55-59','60-69','70-79','70+','80+']:\n        c+=1\nn1.append(c)\nc = 0\nfor i in df_2019[(df_2019['Q2'] == 'Woman') & (df_2019['Q5'] == 'Not employed')]['Q1']:\n    if i in ['50-54','55-59','60-69','70-79','70+','80+']:\n        c+=1\nn1.append(c)\nc = 0\nfor i in df_2020[(df_2020['Q2'] == 'Woman') & (df_2020['Q5'] == 'Currently not employed')]['Q1']:\n    if i in ['50-54','55-59','60-69','70-79','70+','80+']:\n        c+=1\nn1.append(c)\nc = 0\nfor i in df[(df['Q2'] == 'Woman') & (df['Q5'] == 'Currently not employed')]['Q1']:\n    if i in ['50-54','55-59','60-69','70-79','70+','80+']:\n        c+=1\nn1.append(c)\n\n\nx = ['2018','2019','2020','2021']\ny1 = n\ny2 = n1\n\npos1 = np.arange(len(y1))\npos2 = [x + barWidth for x in pos1]\n\n# Make the plot\nplt.bar(pos1, y1, color='#FBC02D', width=barWidth, label='Employed')\nplt.bar(pos2, y2, color='#F57F17', width=barWidth, label='unemployed')\n\n# Add xticks on the middle of the group bars\nplt.xticks([i + barWidth for i in range(len(y1))], x,rotation=90,weight = 'bold')\n\nfor x,y in zip(pos1,y1):\n    plt.text(x, y, '%d' % y, ha='center' , va= 'bottom')\n    \nfor x,y in zip(pos2,y2):\n    plt.text(x, y, '%d' % y, ha='center' , va= 'bottom')\n    \nplt.suptitle (\"Woman above age 50 employement vs unemployement\",weight = 'bold')\n\n# Create legend & Show graphic\nplt.legend()\nplt.show()","0c75d821":"x = df[df['Q2'] == 'Woman']['Q1'].value_counts().keys().tolist()\ny = df[df['Q2'] == 'Woman']['Q1'].value_counts().values.tolist()\nfig = plt.figure(figsize=(10, 6))\nsns.set(style=\"dark\", color_codes=True)\npal = sns.color_palette(\"YlGnBu\", len(x))\nax = sns.barplot(x=x,y=y,palette=pal)\nfor p in ax.patches:\n        ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.3, p.get_height()),\n                    ha='center', va='bottom',\n                    color= 'black')\nplt.suptitle (\"Women in all age groups\",weight = 'bold')\nplt.xticks(rotation=90,weight = 'bold')\nplt.show()","1bf1417e":"# Displaying values at the top of the Grouped Bar Chart using plt.text()\nplt.figure(figsize=(14,8))\n\n# set width of bar\nbarWidth = 0.2\nn = []\nn.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] != 'Currently not employed') & (df['Q1'] == '18-21')]['Q1']))\nn.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] != 'Currently not employed') & (df['Q1'] == '25-29')]['Q1']))\nn.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] != 'Currently not employed') & (df['Q1'] == '22-24')]['Q1']))\nn.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] != 'Currently not employed') & (df['Q1'] == '30-34')]['Q1']))\nn.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] != 'Currently not employed') & (df['Q1'] == '35-39')]['Q1']))\nn.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] != 'Currently not employed') & (df['Q1'] == '40-44')]['Q1']))\nn.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] != 'Currently not employed') & (df['Q1'] == '45-49')]['Q1']))\nn.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] != 'Currently not employed') & (df['Q1'] == '50-54')]['Q1']))\nn.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] != 'Currently not employed') & (df['Q1'] == '55-59')]['Q1']))\nn.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] != 'Currently not employed') & (df['Q1'] == '60-69')]['Q1']))\nn.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] != 'Currently not employed') & (df['Q1'] == '70+')]['Q1']))\n\nn1 = []\nn1.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] == 'Currently not employed') & (df['Q1'] == '18-21')]['Q1']))\nn1.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] == 'Currently not employed') & (df['Q1'] == '25-29')]['Q1']))\nn1.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] == 'Currently not employed') & (df['Q1'] == '22-24')]['Q1']))\nn1.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] == 'Currently not employed') & (df['Q1'] == '30-34')]['Q1']))\nn1.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] == 'Currently not employed') & (df['Q1'] == '35-39')]['Q1']))\nn1.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] == 'Currently not employed') & (df['Q1'] == '40-44')]['Q1']))\nn1.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] == 'Currently not employed') & (df['Q1'] == '45-49')]['Q1']))\nn1.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] == 'Currently not employed') & (df['Q1'] == '50-54')]['Q1']))\nn1.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] == 'Currently not employed') & (df['Q1'] == '55-59')]['Q1']))\nn1.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] == 'Currently not employed') & (df['Q1'] == '60-69')]['Q1']))\nn1.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] == 'Currently not employed') & (df['Q1'] == '70+')]['Q1']))\n\nx = df[df['Q2'] == 'Woman']['Q1'].value_counts().keys().tolist()\ny1 = n\ny2 = n1\n\npos1 = np.arange(len(y1))\npos2 = [x + barWidth for x in pos1]\n\n# Make the plot\nplt.bar(pos1, y1, color='#FBC02D', width=barWidth, label='Employed')\nplt.bar(pos2, y2, color='#F57F17', width=barWidth, label='unemployed')\n\n# Add xticks on the middle of the group bars\nplt.xticks([i + barWidth for i in range(len(y1))], x,rotation=90,weight = 'bold')\n\nfor x,y in zip(pos1,y1):\n    plt.text(x, y, '%d' % y, ha='center' , va= 'bottom')\n    \nfor x,y in zip(pos2,y2):\n    plt.text(x, y, '%d' % y, ha='center' , va= 'bottom')\n    \nplt.suptitle (\"Employed vs Unemployed women in all age groups\",weight = 'bold')\n\n# Create legend & Show graphic\nplt.legend()\nplt.show()","cd9214ea":"from matplotlib.patches import Rectangle\nz=df[df['Q2']=='Woman'].groupby(['Q3','Q1']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 24))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap=\"pink\", annot=True, linewidths=0.005, linecolor='black',annot_kws={\"fontsize\":12}, fmt='.3f', cbar=False)\nplt.ylabel('Country', weight = 'bold', fontsize = 20)\nplt.xlabel('Age groups of women',weight = 'bold', fontsize = 20)\nplt.title('Age Distribution of women by country',weight='bold', fontsize = 20)\n\ncolumns_text = z.columns\n\ncolumn_max = z.apply(lambda x: x, axis=1).idxmax(axis=0)\n\nfor col, variable in enumerate(columns_text):\n    position = z.apply(lambda x: x, axis=1).index.get_loc(column_max[variable])\n    ax.add_patch(Rectangle((col, position),1,1, fill=False, edgecolor='red', lw=3))\nplt.yticks(fontsize=14,weight = 'bold')\nplt.xticks(fontsize=14,weight = 'bold')\nplt.show()","256c90a8":"z=df[df['Q2']=='Woman'].groupby(['Q4','Q1']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap=\"pink\", annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Age groups of women', weight = 'bold', fontsize = 20)\ncolumns_text = z.columns\ncolumn_max = z.apply(lambda x: x, axis=1).idxmax(axis=0)\nfor col, variable in enumerate(columns_text):\n    position = z.apply(lambda x: x, axis=1).index.get_loc(column_max[variable])\n    ax.add_patch(Rectangle((col, position),1,1, fill=False, edgecolor='red', lw=3))\nplt.ylabel('Degree',weight = 'bold', fontsize = 20)\nplt.title('Age Distribution of women by degree',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14,weight = 'bold')\nplt.xticks(fontsize=14,weight = 'bold')\nplt.show()","a9b2eb05":"z=df[df['Q2']=='Woman'].groupby(['Q4','Q1']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap=\"pink\", annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Age groups of women', weight = 'bold', fontsize = 20)\nindex_text = z.index    \nrow_max = z.apply(lambda x: x, axis=1).idxmax(axis=1)\nfor row, index in enumerate(index_text):\n    position = z.apply(lambda x: x, axis=1).columns.get_loc(row_max[index])\n    ax.add_patch(Rectangle((position, row),1,1, fill=False, edgecolor='blue', lw=3))   \nplt.ylabel('Degree',weight = 'bold', fontsize = 20)\nplt.title('Age Distribution of women by degree',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14,weight = 'bold')\nplt.xticks(fontsize=14,weight = 'bold')\nplt.show()","efa27ae9":"z=df[df['Q2']=='Woman'].groupby(['Q5','Q1']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap=\"pink\", annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":12}, fmt='.3f', cbar=False)\nplt.xlabel('Age groups of women', weight = 'bold', fontsize = 20)\ncolumns_text = z.columns\ncolumn_max = z.apply(lambda x: x, axis=1).idxmax(axis=0)\nfor col, variable in enumerate(columns_text):\n    position = z.apply(lambda x: x, axis=1).index.get_loc(column_max[variable])\n    ax.add_patch(Rectangle((col, position),1,1, fill=False, edgecolor='red', lw=3))\nplt.ylabel('Current Job',weight = 'bold', fontsize = 20)\nplt.title('Age Distribution of women by Current Job',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","298eb243":"z=df[df['Q2']=='Woman'].groupby(['Q6','Q1']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap=\"pink\", annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Age groups of women', weight = 'bold', fontsize = 20)\ncolumns_text = z.columns\ncolumn_max = z.apply(lambda x: x, axis=1).idxmax(axis=0)\nfor col, variable in enumerate(columns_text):\n    position = z.apply(lambda x: x, axis=1).index.get_loc(column_max[variable])\n    ax.add_patch(Rectangle((col, position),1,1, fill=False, edgecolor='red', lw=3))\nplt.ylabel('Coding Experience',weight = 'bold', fontsize = 20)\nplt.title('Age Distribution of women by Coding Experience',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold',rotation = 45)\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","96611d13":"z=df[df['Q2']=='Woman'].groupby(['Q6','Q1']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap=\"pink\", annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Age groups of women', weight = 'bold', fontsize = 20)\nindex_text = z.index\nrow_max = z.apply(lambda x: x, axis=1).idxmax(axis=1)\nfor row, index in enumerate(index_text):\n    position = z.apply(lambda x: x, axis=1).columns.get_loc(row_max[index])\n    ax.add_patch(Rectangle((position, row),1,1, fill=False, edgecolor='blue', lw=3))   \nplt.ylabel('Coding Experience',weight = 'bold', fontsize = 20)\nplt.title('Age Distribution of women by Coding Experience',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold',rotation = 45)\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","fa0264b2":"df_groupby = {var: pd.DataFrame(df[df['Q2'] == 'Woman'].groupby([var, 'Q1']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","d5058c48":"z=df[df['Q2']=='Woman'].groupby(['Q8','Q1']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap=\"pink\", annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Age groups of women', weight = 'bold', fontsize = 14)\ncolumns_text = z.columns\ncolumn_max = z.apply(lambda x: x, axis=1).idxmax(axis=0)\nfor col, variable in enumerate(columns_text):\n    position = z.apply(lambda x: x, axis=1).index.get_loc(column_max[variable])\n    ax.add_patch(Rectangle((col, position),1,1, fill=False, edgecolor='red', lw=3))\nplt.ylabel('Programming Language',weight = 'bold', fontsize = 14)\nplt.title('Age distribution of women by Programming Language recommended for aspiring Data Scientist',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","dc8cda3c":"z=df[df['Q2']=='Woman'].groupby(['Q8','Q1']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap=\"pink\", annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Age groups of women', weight = 'bold', fontsize = 14)\nindex_text = z.index    \nrow_max = z.apply(lambda x: x, axis=1).idxmax(axis=1)\nfor row, index in enumerate(index_text):\n    position = z.apply(lambda x: x, axis=1).columns.get_loc(row_max[index])\n    ax.add_patch(Rectangle((position, row),1,1, fill=False, edgecolor='blue', lw=3))\nplt.ylabel('Programming Language',weight = 'bold', fontsize = 14)\nplt.title('Age distribution of women by Programming Language recommended for aspiring Data Scientist',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","c4274925":"df_groupby = {var: pd.DataFrame(df[df['Q2'] == 'Woman'].groupby([var, 'Q1']).size()) \n              for var in {'Q9_Part_4','Q9_Part_5','Q9_Part_11'}}\nmulti_table([df_groupby['Q9_Part_4'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q9_Part_5'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q9_Part_11'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","54500ef1":"df_groupby = {var: pd.DataFrame(df[df['Q2'] == 'Woman'].groupby([var, 'Q1']).size()) \n              for var in {'Q10_Part_1','Q10_Part_2','Q10_Part_11'}}\nmulti_table([df_groupby['Q10_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q10_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q10_Part_11'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","8e1837cd":"z=df[df['Q2']=='Woman'].groupby(['Q11','Q1']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap='pink', annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Specialized Software', weight = 'bold', fontsize = 20)\ncolumns_text = z.columns\ncolumn_max = z.apply(lambda x: x, axis=1).idxmax(axis=0)\nfor col, variable in enumerate(columns_text):\n    position = z.apply(lambda x: x, axis=1).index.get_loc(column_max[variable])\n    ax.add_patch(Rectangle((col, position),1,1, fill=False, edgecolor='red', lw=3))\nplt.ylabel('Age groups of women',weight = 'bold', fontsize = 20)\nplt.title('Age Distribution of women by Specialized Software used on regular basis',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","5e587c80":"z=df[df['Q2']=='Woman'].groupby(['Q11','Q1']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap='pink', annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Specialized Software', weight = 'bold', fontsize = 20)\nindex_text = z.index    \nrow_max = z.apply(lambda x: x, axis=1).idxmax(axis=1)\nfor row, index in enumerate(index_text):\n    position = z.apply(lambda x: x, axis=1).columns.get_loc(row_max[index])\n    ax.add_patch(Rectangle((position, row),1,1, fill=False, edgecolor='blue', lw=3))\nplt.ylabel('Age groups of women',weight = 'bold', fontsize = 20)\nplt.title('Age Distribution of women by Specialized Software used on regular basis',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","1833174d":"df_groupby = {var: pd.DataFrame(df[df['Q2'] == 'Woman'].groupby([var, 'Q1']).size()) \n              for var in {'Q14_Part_1','Q14_Part_2','Q14_Part_3','Q14_Part_4'}}\nmulti_table([df_groupby['Q14_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q14_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q14_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'),df_groupby['Q14_Part_4'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","042aa345":"z=df[df['Q2']=='Woman'].groupby(['Q15','Q1']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap='pink', annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Age groups of women', weight = 'bold', fontsize = 20)\ncolumns_text = z.columns\ncolumn_max = z.apply(lambda x: x, axis=1).idxmax(axis=0)\nfor col, variable in enumerate(columns_text):\n    position = z.apply(lambda x: x, axis=1).index.get_loc(column_max[variable])\n    ax.add_patch(Rectangle((col, position),1,1, fill=False, edgecolor='red', lw=3))\nplt.ylabel('No. of Years',weight = 'bold', fontsize = 20)\nplt.title('Age distribution of women by No. of years Machine Learning Methods used',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","42ce82ea":"z=df[df['Q2']=='Woman'].groupby(['Q15','Q1']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap='pink', annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Age groups of women', weight = 'bold', fontsize = 20)\nindex_text = z.index    \nrow_max = z.apply(lambda x: x, axis=1).idxmax(axis=1)\nfor row, index in enumerate(index_text):\n    position = z.apply(lambda x: x, axis=1).columns.get_loc(row_max[index])\n    ax.add_patch(Rectangle((position, row),1,1, fill=False, edgecolor='blue', lw=3))\nplt.ylabel('No. of Years',weight = 'bold', fontsize = 20)\nplt.title('Age distribution of women by No. of years Machine Learning Methods used',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","c307f484":"df_groupby = {var: pd.DataFrame(df[df['Q2'] == 'Woman'].groupby([var, 'Q1']).size()) \n              for var in {'Q16_Part_1','Q16_Part_2','Q16_Part_3','Q16_Part_4','Q16_Part_7'}}\nmulti_table([df_groupby['Q16_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q16_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q16_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'),df_groupby['Q16_Part_4'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'),df_groupby['Q16_Part_7'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","6236c4b8":"df_groupby = {var: pd.DataFrame(df[df['Q2'] == 'Woman'].groupby([var, 'Q1']).size()) \n              for var in {'Q17_Part_1','Q17_Part_2','Q17_Part_3','Q17_Part_7'}}\nmulti_table([df_groupby['Q17_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q17_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q17_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'),df_groupby['Q17_Part_7'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","79e04c3f":"z=df[df['Q2']=='Woman'].groupby(['Q20','Q1']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap='pink', annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Age groups of women', weight = 'bold', fontsize = 14)\ncolumns_text = z.columns\ncolumn_max = z.apply(lambda x: x, axis=1).idxmax(axis=0)\nfor col, variable in enumerate(columns_text):\n    position = z.apply(lambda x: x, axis=1).index.get_loc(column_max[variable])\n    ax.add_patch(Rectangle((col, position),1,1, fill=False, edgecolor='red', lw=3))\nplt.ylabel('Current Employer\/ contract',weight = 'bold', fontsize = 14)\nplt.title('Age distribution of women by Current Employer\/ Contract',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","4dfe804c":"z=df[df['Q2']=='Woman'].groupby(['Q20','Q1']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap='pink', annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Age groups of women', weight = 'bold', fontsize = 14)\nindex_text = z.index    \nrow_max = z.apply(lambda x: x, axis=1).idxmax(axis=1)\nfor row, index in enumerate(index_text):\n    position = z.apply(lambda x: x, axis=1).columns.get_loc(row_max[index])\n    ax.add_patch(Rectangle((position, row),1,1, fill=False, edgecolor='blue', lw=3))\nplt.ylabel('Current Employer\/ contract',weight = 'bold', fontsize = 14)\nplt.title('Age distribution of women by Current Employer\/ Contract',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","58de9929":"z=df[df['Q2']=='Woman'].groupby(['Q25','Q1']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(20, 13))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap='pink', annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Age groups of women', weight = 'bold', fontsize = 20)\ncolumns_text = z.columns\ncolumn_max = z.apply(lambda x: x, axis=1).idxmax(axis=0)\nfor col, variable in enumerate(columns_text):\n    position = z.apply(lambda x: x, axis=1).index.get_loc(column_max[variable])\n    ax.add_patch(Rectangle((col, position),1,1, fill=False, edgecolor='red', lw=3))\nplt.ylabel('Compensation in USD',weight = 'bold', fontsize = 20)\nplt.title('Age distribution of women by Current Yearly Compensation',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","40177e04":"z=df[df['Q2']=='Woman'].groupby(['Q25','Q1']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(20, 13))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap='pink', annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Age groups of women', weight = 'bold', fontsize = 20)\nindex_text = z.index    \nrow_max = z.apply(lambda x: x, axis=1).idxmax(axis=1)\nfor row, index in enumerate(index_text):\n    position = z.apply(lambda x: x, axis=1).columns.get_loc(row_max[index])\n    ax.add_patch(Rectangle((position, row),1,1, fill=False, edgecolor='blue', lw=3))\nplt.ylabel('Compensation in USD',weight = 'bold', fontsize = 20)\nplt.title('Age distribution of women by Current Yearly Compensation',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","783f4e36":"z=df[df['Q2']=='Woman'].groupby(['Q26','Q1']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap='pink', annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Age groups of women', weight = 'bold', fontsize = 14)\ncolumns_text = z.columns\ncolumn_max = z.apply(lambda x: x, axis=1).idxmax(axis=0)\nfor col, variable in enumerate(columns_text):\n    position = z.apply(lambda x: x, axis=1).index.get_loc(column_max[variable])\n    ax.add_patch(Rectangle((col, position),1,1, fill=False, edgecolor='red', lw=3))\nplt.ylabel('Compensation in USD',weight = 'bold', fontsize = 14)\nplt.title('Age distribution of women by Money spent on learning Machine Learning\/ Cloud Computing services in the past 5 years',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14,weight = 'bold')\nplt.xticks(fontsize=14,weight = 'bold')\nplt.show()","539a3f47":"z=df[df['Q2']=='Woman'].groupby(['Q26','Q1']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap='pink', annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Age groups of women', weight = 'bold', fontsize = 14)\nindex_text = z.index    \nrow_max = z.apply(lambda x: x, axis=1).idxmax(axis=1)\nfor row, index in enumerate(index_text):\n    position = z.apply(lambda x: x, axis=1).columns.get_loc(row_max[index])\n    ax.add_patch(Rectangle((position, row),1,1, fill=False, edgecolor='blue', lw=3))\nplt.ylabel('Compensation in USD',weight = 'bold', fontsize = 14)\nplt.title('Age distribution of women by Money spent on learning Machine Learning\/ Cloud Computing services in the past 5 years',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14,weight = 'bold')\nplt.xticks(fontsize=14,weight = 'bold')\nplt.show()","22e5030e":"df_groupby = {var: pd.DataFrame(df[df['Q2'] == 'Woman'].groupby([var, 'Q1']).size()) \n              for var in {'Q39_Part_4','Q39_Part_6','Q39_Part_7','Q39_Part_9'}}\nmulti_table([df_groupby['Q39_Part_4'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q39_Part_6'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q39_Part_7'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'),df_groupby['Q39_Part_9'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","52ec5961":"df_groupby = {var: pd.DataFrame(df[df['Q2'] == 'Woman'].groupby([var, 'Q1']).size()) \n              for var in {'Q40_Part_1','Q40_Part_3','Q40_Part_7','Q40_Part_10'}}\nmulti_table([df_groupby['Q40_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q40_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q40_Part_7'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'),df_groupby['Q40_Part_10'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","1b4e8e87":"df_groupby = {var: pd.DataFrame(df[df['Q2'] == 'Woman'].groupby([var, 'Q1']).size()) \n              for var in {'Q42_Part_4','Q42_Part_6','Q42_Part_8'}}\nmulti_table([df_groupby['Q42_Part_4'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q42_Part_6'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q42_Part_8'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","4454b8bd":"x = df[df['Q2'] == 'Woman']['Q4'].value_counts().keys().tolist()\ny = df[df['Q2'] == 'Woman']['Q4'].value_counts().values.tolist()\nfig = plt.figure(figsize=(10, 6))\nsns.set(style=\"dark\", color_codes=True)\npal = sns.color_palette(\"YlGnBu\", len(x))\nax = sns.barplot(x=x,y=y,palette=pal)\nfor p in ax.patches:\n        ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.3, p.get_height()),\n                    ha='center', va='bottom',\n                    color= 'black')\nplt.suptitle (\"Women in all Degrees\",weight = 'bold')\nplt.xticks(rotation=90,weight = 'bold')\nplt.show()","f986c11f":"# Displaying values at the top of the Grouped Bar Chart using plt.text()\nplt.figure(figsize=(14,8))\n\n# set width of bar\nbarWidth = 0.2\nn = []\nn.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] != 'Currently not employed') & (df['Q4'] == \"Master\u2019s degree\")]))\nn.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] != 'Currently not employed') & (df['Q4'] == \"Bachelor\u2019s degree\")]))\nn.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] != 'Currently not employed') & (df['Q4'] == \"Doctoral degree\")]))\nn.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] != 'Currently not employed') & (df['Q4'] == \"Some college\/university study without earning a bachelor\u2019s degree\")]))\nn.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] != 'Currently not employed') & (df['Q4'] == \"I prefer not to answer\")]))\nn.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] != 'Currently not employed') & (df['Q4'] == \"No formal education past high school\")]))\nn.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] != 'Currently not employed') & (df['Q4'] == \"Professional doctorate\")]))\n\nn1 = []\nn1.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] == 'Currently not employed') & (df['Q4'] == \"Master\u2019s degree\")]))\nn1.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] == 'Currently not employed') & (df['Q4'] == \"Bachelor\u2019s degree\")]))\nn1.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] == 'Currently not employed') & (df['Q4'] == \"Doctoral degree\")]))\nn1.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] == 'Currently not employed') & (df['Q4'] == \"Some college\/university study without earning a bachelor\u2019s degree\")]))\nn1.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] == 'Currently not employed') & (df['Q4'] == \"I prefer not to answer\")]))\nn1.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] == 'Currently not employed') & (df['Q4'] == \"No formal education past high school\")]))\nn1.append(len(df[(df['Q2'] == 'Woman') & (df['Q5'] == 'Currently not employed') & (df['Q4'] == 'Professional doctorate')]))\n\nx = df[df['Q2'] == 'Woman']['Q4'].value_counts().keys().tolist()\ny1 = n\ny2 = n1\n\npos1 = np.arange(len(y1))\npos2 = [x + barWidth for x in pos1]\n\n# Make the plot\nplt.bar(pos1, y1, color='#FBC02D', width=barWidth, label='Employed')\nplt.bar(pos2, y2, color='#F57F17', width=barWidth, label='unemployed')\n\n# Add xticks on the middle of the group bars\nplt.xticks([i + barWidth for i in range(len(y1))], x,rotation=90,weight = 'bold')\n\nfor x,y in zip(pos1,y1):\n    plt.text(x, y, '%d' % y, ha='center' , va= 'bottom')\n    \nfor x,y in zip(pos2,y2):\n    plt.text(x, y, '%d' % y, ha='center' , va= 'bottom')\n    \nplt.suptitle (\"Employed vs Unemployed women in all Degrees\",weight = 'bold')\n\n# Create legend & Show graphic\nplt.legend()\nplt.show()","d5f01f14":"from matplotlib.patches import Rectangle\nz=df[df['Q2']=='Woman'].groupby(['Q1','Q4']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap=\"pink\", annot=True, linewidths=0.005, linecolor='black',annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.ylabel('Age Groups', weight = 'bold', fontsize = 14)\nplt.xlabel('Degrees of women',weight = 'bold', fontsize = 14)\nplt.title('Degree Distribution of women by Age Groups',weight='bold', fontsize = 20)\n\ncolumns_text = z.columns\n\ncolumn_max = z.apply(lambda x: x, axis=1).idxmax(axis=0)\n\nfor col, variable in enumerate(columns_text):\n    position = z.apply(lambda x: x, axis=1).index.get_loc(column_max[variable])\n    ax.add_patch(Rectangle((col, position),1,1, fill=False, edgecolor='red', lw=3))\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","fc5d9e31":"from matplotlib.patches import Rectangle\nz=df[df['Q2']=='Woman'].groupby(['Q1','Q4']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap=\"pink\", annot=True, linewidths=0.005, linecolor='black',annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.ylabel('Age Groups', weight = 'bold', fontsize = 14)\nplt.xlabel('Degrees of women',weight = 'bold', fontsize = 14)\nplt.title('Degree Distribution of women by Age Groups',weight='bold', fontsize = 20)\nindex_text = z.index    \nrow_max = z.apply(lambda x: x, axis=1).idxmax(axis=1)\nfor row, index in enumerate(index_text):\n    position = z.apply(lambda x: x, axis=1).columns.get_loc(row_max[index])\n    ax.add_patch(Rectangle((position, row),1,1, fill=False, edgecolor='blue', lw=3))\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","d54148cc":"from matplotlib.patches import Rectangle\nz=df[df['Q2']=='Woman'].groupby(['Q3','Q4']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 24))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap=\"pink\", annot=True, linewidths=0.005, linecolor='black',annot_kws={\"fontsize\":12}, fmt='.3f', cbar=False)\nplt.ylabel('Country', weight = 'bold', fontsize = 14)\nplt.xlabel('Degrees of women',weight = 'bold', fontsize = 14)\nplt.title('Degree Distribution of women by country',weight='bold', fontsize = 20)\n\ncolumns_text = z.columns\n\ncolumn_max = z.apply(lambda x: x, axis=1).idxmax(axis=0)\n\nfor col, variable in enumerate(columns_text):\n    position = z.apply(lambda x: x, axis=1).index.get_loc(column_max[variable])\n    ax.add_patch(Rectangle((col, position),1,1, fill=False, edgecolor='red', lw=3))\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","d91a3506":"z=df[df['Q2']=='Woman'].groupby(['Q5','Q4']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap=\"pink\", annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Degrees of women', weight = 'bold', fontsize = 20)\ncolumns_text = z.columns\ncolumn_max = z.apply(lambda x: x, axis=1).idxmax(axis=0)\nfor col, variable in enumerate(columns_text):\n    position = z.apply(lambda x: x, axis=1).index.get_loc(column_max[variable])\n    ax.add_patch(Rectangle((col, position),1,1, fill=False, edgecolor='red', lw=3))\nplt.ylabel('Current Job',weight = 'bold', fontsize = 14)\nplt.title('Degree Distribution of women by Current Job',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","408aa57c":"z=df[df['Q2']=='Woman'].groupby(['Q5','Q4']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap=\"pink\", annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Degrees of women', weight = 'bold', fontsize = 20)\nindex_text = z.index    \nrow_max = z.apply(lambda x: x, axis=1).idxmax(axis=1)\nfor row, index in enumerate(index_text):\n    position = z.apply(lambda x: x, axis=1).columns.get_loc(row_max[index])\n    ax.add_patch(Rectangle((position, row),1,1, fill=False, edgecolor='blue', lw=3))\nplt.ylabel('Current Job',weight = 'bold', fontsize = 14)\nplt.title('Degree Distribution of women by Current Job',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","7fa1b13f":"z=df[df['Q2']=='Woman'].groupby(['Q6','Q4']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap=\"pink\", annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Degrees of women', weight = 'bold', fontsize = 20)\ncolumns_text = z.columns\ncolumn_max = z.apply(lambda x: x, axis=1).idxmax(axis=0)\nfor col, variable in enumerate(columns_text):\n    position = z.apply(lambda x: x, axis=1).index.get_loc(column_max[variable])\n    ax.add_patch(Rectangle((col, position),1,1, fill=False, edgecolor='red', lw=3))\nplt.ylabel('Coding Experience',weight = 'bold', fontsize = 14)\nplt.title('Degree Distribution of women by Coding Experience',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold',rotation = 45)\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","846e297c":"z=df[df['Q2']=='Woman'].groupby(['Q6','Q4']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap=\"pink\", annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Degrees of women', weight = 'bold', fontsize = 20)\nindex_text = z.index    \nrow_max = z.apply(lambda x: x, axis=1).idxmax(axis=1)\nfor row, index in enumerate(index_text):\n    position = z.apply(lambda x: x, axis=1).columns.get_loc(row_max[index])\n    ax.add_patch(Rectangle((position, row),1,1, fill=False, edgecolor='blue', lw=3))\nplt.ylabel('Coding Experience',weight = 'bold', fontsize = 14)\nplt.title('Degree Distribution of women by Coding Experience',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold',rotation = 45)\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","8fa19b9a":"df_groupby = {var: pd.DataFrame(df[df['Q2'] == 'Woman'].groupby([var, 'Q4']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","7b06a623":"z=df[df['Q2']=='Woman'].groupby(['Q8','Q4']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap=\"pink\", annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Degrees of women', weight = 'bold', fontsize = 20)\ncolumns_text = z.columns\ncolumn_max = z.apply(lambda x: x, axis=1).idxmax(axis=0)\nfor col, variable in enumerate(columns_text):\n    position = z.apply(lambda x: x, axis=1).index.get_loc(column_max[variable])\n    ax.add_patch(Rectangle((col, position),1,1, fill=False, edgecolor='red', lw=3))\nplt.ylabel('Programming Language',weight = 'bold', fontsize = 20)\nplt.title('Degree distribution of women by Programming Language recommended for aspiring Data Scientist',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","b2a27467":"z=df[df['Q2']=='Woman'].groupby(['Q8','Q4']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap=\"pink\", annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Degrees of women', weight = 'bold', fontsize = 20)\nindex_text = z.index    \nrow_max = z.apply(lambda x: x, axis=1).idxmax(axis=1)\nfor row, index in enumerate(index_text):\n    position = z.apply(lambda x: x, axis=1).columns.get_loc(row_max[index])\n    ax.add_patch(Rectangle((position, row),1,1, fill=False, edgecolor='blue', lw=3))\nplt.ylabel('Programming Language',weight = 'bold', fontsize = 20)\nplt.title('Degree distribution of women by Programming Language recommended for aspiring Data Scientist',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","7ccc88da":"df_groupby = {var: pd.DataFrame(df[df['Q2'] == 'Woman'].groupby([var, 'Q4']).size()) \n              for var in {'Q9_Part_4','Q9_Part_5','Q9_Part_11'}}\nmulti_table([df_groupby['Q9_Part_4'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q9_Part_5'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q9_Part_11'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","ec9228ec":"df_groupby = {var: pd.DataFrame(df[df['Q2'] == 'Woman'].groupby([var, 'Q4']).size()) \n              for var in {'Q10_Part_1','Q10_Part_2','Q10_Part_11'}}\nmulti_table([df_groupby['Q10_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q10_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q10_Part_11'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","c553ab36":"z=df[df['Q2']=='Woman'].groupby(['Q11','Q4']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap='pink', annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Degrees of women', weight = 'bold', fontsize = 20)\ncolumns_text = z.columns\ncolumn_max = z.apply(lambda x: x, axis=1).idxmax(axis=0)\nfor col, variable in enumerate(columns_text):\n    position = z.apply(lambda x: x, axis=1).index.get_loc(column_max[variable])\n    ax.add_patch(Rectangle((col, position),1,1, fill=False, edgecolor='red', lw=3))\nplt.ylabel('Specialized Software',weight = 'bold', fontsize = 20)\nplt.title('Degree Distribution of women by Specialized Software used on regular basis',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","1fffb29d":"z=df[df['Q2']=='Woman'].groupby(['Q11','Q4']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap='pink', annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Degrees of women', weight = 'bold', fontsize = 20)\nindex_text = z.index    \nrow_max = z.apply(lambda x: x, axis=1).idxmax(axis=1)\nfor row, index in enumerate(index_text):\n    position = z.apply(lambda x: x, axis=1).columns.get_loc(row_max[index])\n    ax.add_patch(Rectangle((position, row),1,1, fill=False, edgecolor='blue', lw=3))\nplt.ylabel('Specialized Software',weight = 'bold', fontsize = 20)\nplt.title('Degree Distribution of women by Specialized Software used on regular basis',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","7fbe880b":"df_groupby = {var: pd.DataFrame(df[df['Q2'] == 'Woman'].groupby([var, 'Q4']).size()) \n              for var in {'Q14_Part_1','Q14_Part_2','Q14_Part_3','Q14_Part_4'}}\nmulti_table([df_groupby['Q14_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q14_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q14_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'),df_groupby['Q14_Part_4'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","1620c969":"z=df[df['Q2']=='Woman'].groupby(['Q15','Q4']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap='pink', annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Degrees of women', weight = 'bold', fontsize = 20)\ncolumns_text = z.columns\ncolumn_max = z.apply(lambda x: x, axis=1).idxmax(axis=0)\nfor col, variable in enumerate(columns_text):\n    position = z.apply(lambda x: x, axis=1).index.get_loc(column_max[variable])\n    ax.add_patch(Rectangle((col, position),1,1, fill=False, edgecolor='red', lw=3))\nplt.ylabel('No. of Years',weight = 'bold', fontsize = 20)\nplt.title('Degree distribution of women by No. of years Machine Learning Methods used',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","53f52859":"z=df[df['Q2']=='Woman'].groupby(['Q15','Q4']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap='pink', annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Degrees of women', weight = 'bold', fontsize = 20)\nindex_text = z.index    \nrow_max = z.apply(lambda x: x, axis=1).idxmax(axis=1)\nfor row, index in enumerate(index_text):\n    position = z.apply(lambda x: x, axis=1).columns.get_loc(row_max[index])\n    ax.add_patch(Rectangle((position, row),1,1, fill=False, edgecolor='blue', lw=3))\nplt.ylabel('No. of Years',weight = 'bold', fontsize = 20)\nplt.title('Degree distribution of women by No. of years Machine Learning Methods used',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","838b93d0":"df_groupby = {var: pd.DataFrame(df[df['Q2'] == 'Woman'].groupby([var, 'Q4']).size()) \n              for var in {'Q16_Part_1','Q16_Part_2','Q16_Part_3','Q16_Part_4','Q16_Part_7'}}\nmulti_table([df_groupby['Q16_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q16_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q16_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'),df_groupby['Q16_Part_4'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'),df_groupby['Q16_Part_7'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","2e02f43b":"df_groupby = {var: pd.DataFrame(df[df['Q2'] == 'Woman'].groupby([var, 'Q4']).size()) \n              for var in {'Q17_Part_1','Q17_Part_2','Q17_Part_3','Q17_Part_7'}}\nmulti_table([df_groupby['Q17_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q17_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q17_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'),df_groupby['Q17_Part_7'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","ae04ecbc":"z=df[df['Q2']=='Woman'].groupby(['Q20','Q4']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(18, 12))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap='pink', annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Degrees of women', weight = 'bold', fontsize = 20)\ncolumns_text = z.columns\ncolumn_max = z.apply(lambda x: x, axis=1).idxmax(axis=0)\nfor col, variable in enumerate(columns_text):\n    position = z.apply(lambda x: x, axis=1).index.get_loc(column_max[variable])\n    ax.add_patch(Rectangle((col, position),1,1, fill=False, edgecolor='red', lw=3))\nplt.ylabel('Current Employer\/ contract',weight = 'bold', fontsize = 20)\nplt.title('Degree distribution of women by Current Employer\/ Contract',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","17f53b2b":"z=df[df['Q2']=='Woman'].groupby(['Q20','Q4']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(18, 12))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap='pink', annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Degrees of women', weight = 'bold', fontsize = 20)\nindex_text = z.index    \nrow_max = z.apply(lambda x: x, axis=1).idxmax(axis=1)\nfor row, index in enumerate(index_text):\n    position = z.apply(lambda x: x, axis=1).columns.get_loc(row_max[index])\n    ax.add_patch(Rectangle((position, row),1,1, fill=False, edgecolor='blue', lw=3))\nplt.ylabel('Current Employer\/ contract',weight = 'bold', fontsize = 20)\nplt.title('Degree distribution of women by Current Employer\/ Contract',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","f59e617a":"z=df[df['Q2']=='Woman'].groupby(['Q25','Q4']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(20, 16))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap='pink', annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Compensation in USD', weight = 'bold', fontsize = 20)\ncolumns_text = z.columns\ncolumn_max = z.apply(lambda x: x, axis=1).idxmax(axis=0)\nfor col, variable in enumerate(columns_text):\n    position = z.apply(lambda x: x, axis=1).index.get_loc(column_max[variable])\n    ax.add_patch(Rectangle((col, position),1,1, fill=False, edgecolor='red', lw=3))\nplt.ylabel('Degrees of women',weight = 'bold', fontsize = 20)\nplt.title('Degree distribution of women by Current Yearly Compensation',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","7176699b":"z=df[df['Q2']=='Woman'].groupby(['Q25','Q4']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(20, 16))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap='pink', annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Compensation in USD', weight = 'bold', fontsize = 20)\nindex_text = z.index    \nrow_max = z.apply(lambda x: x, axis=1).idxmax(axis=1)\nfor row, index in enumerate(index_text):\n    position = z.apply(lambda x: x, axis=1).columns.get_loc(row_max[index])\n    ax.add_patch(Rectangle((position, row),1,1, fill=False, edgecolor='blue', lw=3))\nplt.ylabel('Degrees of women',weight = 'bold', fontsize = 20)\nplt.title('Degree distribution of women by Current Yearly Compensation',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","e47e9fd4":"z=df[df['Q2']=='Woman'].groupby(['Q26','Q4']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap='pink', annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Degrees of women', weight = 'bold', fontsize = 20)\ncolumns_text = z.columns\ncolumn_max = z.apply(lambda x: x, axis=1).idxmax(axis=0)\nfor col, variable in enumerate(columns_text):\n    position = z.apply(lambda x: x, axis=1).index.get_loc(column_max[variable])\n    ax.add_patch(Rectangle((col, position),1,1, fill=False, edgecolor='red', lw=3))\nplt.ylabel('Compensation in USD',weight = 'bold', fontsize = 20)\nplt.title('Degree distribution of women by Money spent on learning Machine Learning\/ Cloud Computing services in the past 5 years',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","4786ca44":"z=df[df['Q2']=='Woman'].groupby(['Q26','Q4']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap='pink', annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Degrees of women', weight = 'bold', fontsize = 20)\nindex_text = z.index    \nrow_max = z.apply(lambda x: x, axis=1).idxmax(axis=1)\nfor row, index in enumerate(index_text):\n    position = z.apply(lambda x: x, axis=1).columns.get_loc(row_max[index])\n    ax.add_patch(Rectangle((position, row),1,1, fill=False, edgecolor='blue', lw=3))\nplt.ylabel('Compensation in USD',weight = 'bold', fontsize = 20)\nplt.title('Degree distribution of women by Money spent on learning Machine Learning\/ Cloud Computing services in the past 5 years',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","fd869890":"df_groupby = {var: pd.DataFrame(df[df['Q2'] == 'Woman'].groupby([var, 'Q4']).size()) \n              for var in {'Q39_Part_4','Q39_Part_6','Q39_Part_7','Q39_Part_9'}}\nmulti_table([df_groupby['Q39_Part_4'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q39_Part_6'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q39_Part_7'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'),df_groupby['Q39_Part_9'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","981d7e1c":"df_groupby = {var: pd.DataFrame(df[df['Q2'] == 'Woman'].groupby([var, 'Q4']).size()) \n              for var in {'Q40_Part_1','Q40_Part_3','Q40_Part_7','Q40_Part_10'}}\nmulti_table([df_groupby['Q40_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q40_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q40_Part_7'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'),df_groupby['Q40_Part_10'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","40b1acb4":"df_groupby = {var: pd.DataFrame(df[df['Q2'] == 'Woman'].groupby([var, 'Q4']).size()) \n              for var in {'Q42_Part_4','Q42_Part_6','Q42_Part_8'}}\nmulti_table([df_groupby['Q42_Part_4'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q42_Part_6'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q42_Part_8'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","e028b95c":"x = df[df['Q2'] == 'Woman']['Q5'].value_counts().keys().tolist()\ny = df[df['Q2'] == 'Woman']['Q5'].value_counts().values.tolist()\nfig = plt.figure(figsize=(10, 6))\nsns.set(style=\"dark\", color_codes=True)\npal = sns.color_palette(\"YlGnBu\", len(x))\nax = sns.barplot(x=x,y=y,palette=pal)\nfor p in ax.patches:\n        ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.3, p.get_height()),\n                    ha='center', va='bottom',\n                    color= 'black')\nplt.suptitle (\"Women in Current Role\",weight = 'bold')\nplt.xticks(rotation=90,weight = 'bold')\nplt.show()","2acbe079":"from matplotlib.patches import Rectangle\nz=df[df['Q2']=='Woman'].groupby(['Q1','Q5']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap=\"pink\", annot=True, linewidths=0.005, linecolor='black',annot_kws={\"fontsize\":12}, fmt='.3f', cbar=False)\nplt.ylabel('Age Groups', weight = 'bold', fontsize = 20)\nplt.xlabel('Current Roles of women',weight = 'bold', fontsize = 20)\nplt.title('Current Role Distribution of women by country',weight='bold', fontsize = 20)\n\ncolumns_text = z.columns\n\ncolumn_max = z.apply(lambda x: x, axis=1).idxmax(axis=0)\n\nfor col, variable in enumerate(columns_text):\n    position = z.apply(lambda x: x, axis=1).index.get_loc(column_max[variable])\n    ax.add_patch(Rectangle((col, position),1,1, fill=False, edgecolor='red', lw=3))\nplt.yticks(fontsize=14,weight = 'bold',rotation = 45)\nplt.xticks(fontsize=14,weight = 'bold')\nplt.show()","12f01eb8":"from matplotlib.patches import Rectangle\nz=df[df['Q2']=='Woman'].groupby(['Q1','Q5']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap=\"pink\", annot=True, linewidths=0.005, linecolor='black',annot_kws={\"fontsize\":12}, fmt='.3f', cbar=False)\nplt.ylabel('Age Groups', weight = 'bold', fontsize = 20)\nplt.xlabel('Current Roles of women',weight = 'bold', fontsize = 20)\nplt.title('Current Role Distribution of women by country',weight='bold', fontsize = 20)\nindex_text = z.index    \nrow_max = z.apply(lambda x: x, axis=1).idxmax(axis=1)\nfor row, index in enumerate(index_text):\n    position = z.apply(lambda x: x, axis=1).columns.get_loc(row_max[index])\n    ax.add_patch(Rectangle((position, row),1,1, fill=False, edgecolor='blue', lw=3))\nplt.yticks(fontsize=14,weight = 'bold',rotation = 45)\nplt.xticks(fontsize=14,weight = 'bold')\nplt.show()","357d5080":"from matplotlib.patches import Rectangle\nz=df[df['Q2']=='Woman'].groupby(['Q3','Q5']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 24))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap=\"pink\", annot=True, linewidths=0.005, linecolor='black',annot_kws={\"fontsize\":12}, fmt='.3f', cbar=False)\nplt.ylabel('Country', weight = 'bold', fontsize = 20)\nplt.xlabel('Current Roles of women',weight = 'bold', fontsize = 20)\nplt.title('Current Role Distribution of women by country',weight='bold', fontsize = 20)\n\ncolumns_text = z.columns\n\ncolumn_max = z.apply(lambda x: x, axis=1).idxmax(axis=0)\n\nfor col, variable in enumerate(columns_text):\n    position = z.apply(lambda x: x, axis=1).index.get_loc(column_max[variable])\n    ax.add_patch(Rectangle((col, position),1,1, fill=False, edgecolor='red', lw=3))\nplt.yticks(fontsize=14,weight = 'bold')\nplt.xticks(fontsize=14,weight = 'bold')\nplt.show()","608b20b4":"z=df[df['Q2']=='Woman'].groupby(['Q6','Q5']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(18, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap=\"pink\", annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Current Roles of women', weight = 'bold', fontsize = 20)\ncolumns_text = z.columns\ncolumn_max = z.apply(lambda x: x, axis=1).idxmax(axis=0)\nfor col, variable in enumerate(columns_text):\n    position = z.apply(lambda x: x, axis=1).index.get_loc(column_max[variable])\n    ax.add_patch(Rectangle((col, position),1,1, fill=False, edgecolor='red', lw=3))\nplt.ylabel('Coding Experience',weight = 'bold', fontsize = 14)\nplt.title('Current Role Distribution of women by Coding Experience',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold',rotation = 45)\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","738b1d4d":"z=df[df['Q2']=='Woman'].groupby(['Q6','Q5']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(18, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap=\"pink\", annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Current Roles of women', weight = 'bold', fontsize = 20)\nindex_text = z.index    \nrow_max = z.apply(lambda x: x, axis=1).idxmax(axis=1)\nfor row, index in enumerate(index_text):\n    position = z.apply(lambda x: x, axis=1).columns.get_loc(row_max[index])\n    ax.add_patch(Rectangle((position, row),1,1, fill=False, edgecolor='blue', lw=3))\nplt.ylabel('Coding Experience',weight = 'bold', fontsize = 14)\nplt.title('Current Role Distribution of women by Coding Experience',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold',rotation = 45)\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","91fdcbec":"df_groupby = {var: pd.DataFrame(df[df['Q2'] == 'Woman'].groupby([var, 'Q5']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","e06a3aba":"z=df[df['Q2']=='Woman'].groupby(['Q8','Q5']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap=\"pink\", annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Current Roles of women', weight = 'bold', fontsize = 20)\ncolumns_text = z.columns\ncolumn_max = z.apply(lambda x: x, axis=1).idxmax(axis=0)\nfor col, variable in enumerate(columns_text):\n    position = z.apply(lambda x: x, axis=1).index.get_loc(column_max[variable])\n    ax.add_patch(Rectangle((col, position),1,1, fill=False, edgecolor='red', lw=3))\nplt.ylabel('Programming Language',weight = 'bold', fontsize = 20)\nplt.title('Current Roles distribution of women by Programming Language recommended for aspiring Data Scientist',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","0d541799":"z=df[df['Q2']=='Woman'].groupby(['Q8','Q5']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap=\"pink\", annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Current Roles of women', weight = 'bold', fontsize = 20)\nindex_text = z.index    \nrow_max = z.apply(lambda x: x, axis=1).idxmax(axis=1)\nfor row, index in enumerate(index_text):\n    position = z.apply(lambda x: x, axis=1).columns.get_loc(row_max[index])\n    ax.add_patch(Rectangle((position, row),1,1, fill=False, edgecolor='blue', lw=3))\nplt.ylabel('Programming Language',weight = 'bold', fontsize = 20)\nplt.title('Current Roles distribution of women by Programming Language recommended for aspiring Data Scientist',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","f38b01dd":"df_groupby = {var: pd.DataFrame(df[df['Q2'] == 'Woman'].groupby([var, 'Q5']).size()) \n              for var in {'Q9_Part_4','Q9_Part_5','Q9_Part_11'}}\nmulti_table([df_groupby['Q9_Part_4'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q9_Part_5'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q9_Part_11'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","e1a81311":"df_groupby = {var: pd.DataFrame(df[df['Q2'] == 'Woman'].groupby([var, 'Q5']).size()) \n              for var in {'Q10_Part_1','Q10_Part_2','Q10_Part_11'}}\nmulti_table([df_groupby['Q10_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q10_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q10_Part_11'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","b9eb66b7":"z=df[df['Q2']=='Woman'].groupby(['Q11','Q5']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(18, 12))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap='pink', annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Current Roles of women', weight = 'bold', fontsize = 20)\ncolumns_text = z.columns\ncolumn_max = z.apply(lambda x: x, axis=1).idxmax(axis=0)\nfor col, variable in enumerate(columns_text):\n    position = z.apply(lambda x: x, axis=1).index.get_loc(column_max[variable])\n    ax.add_patch(Rectangle((col, position),1,1, fill=False, edgecolor='red', lw=3))\nplt.ylabel('Specialized Software',weight = 'bold', fontsize = 20)\nplt.title('Current Roles Distribution of women by Specialized Software used on regular basis',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","9342df86":"z=df[df['Q2']=='Woman'].groupby(['Q11','Q5']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(18, 12))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap='pink', annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Current Roles of women', weight = 'bold', fontsize = 20)\nindex_text = z.index    \nrow_max = z.apply(lambda x: x, axis=1).idxmax(axis=1)\nfor row, index in enumerate(index_text):\n    position = z.apply(lambda x: x, axis=1).columns.get_loc(row_max[index])\n    ax.add_patch(Rectangle((position, row),1,1, fill=False, edgecolor='blue', lw=3))\nplt.ylabel('Specialized Software',weight = 'bold', fontsize = 20)\nplt.title('Current Roles Distribution of women by Specialized Software used on regular basis',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","d8526be5":"df_groupby = {var: pd.DataFrame(df[df['Q2'] == 'Woman'].groupby([var, 'Q5']).size()) \n              for var in {'Q14_Part_1','Q14_Part_2','Q14_Part_3','Q14_Part_4'}}\nmulti_table([df_groupby['Q14_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q14_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q14_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'),df_groupby['Q14_Part_4'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","3eca5d5d":"z=df[df['Q2']=='Woman'].groupby(['Q15','Q5']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap='pink', annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Current Roles of women', weight = 'bold', fontsize = 20)\ncolumns_text = z.columns\ncolumn_max = z.apply(lambda x: x, axis=1).idxmax(axis=0)\nfor col, variable in enumerate(columns_text):\n    position = z.apply(lambda x: x, axis=1).index.get_loc(column_max[variable])\n    ax.add_patch(Rectangle((col, position),1,1, fill=False, edgecolor='red', lw=3))\nplt.ylabel('No. of Years',weight = 'bold', fontsize = 20)\nplt.title('Current Role distribution of women by No. of years Machine Learning Methods used',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","354d7e4f":"z=df[df['Q2']=='Woman'].groupby(['Q15','Q5']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap='pink', annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Current Roles of women', weight = 'bold', fontsize = 20)\nindex_text = z.index    \nrow_max = z.apply(lambda x: x, axis=1).idxmax(axis=1)\nfor row, index in enumerate(index_text):\n    position = z.apply(lambda x: x, axis=1).columns.get_loc(row_max[index])\n    ax.add_patch(Rectangle((position, row),1,1, fill=False, edgecolor='blue', lw=3))\nplt.ylabel('No. of Years',weight = 'bold', fontsize = 20)\nplt.title('Current Role distribution of women by No. of years Machine Learning Methods used',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","6bbaabfa":"df_groupby = {var: pd.DataFrame(df[df['Q2'] == 'Woman'].groupby([var, 'Q5']).size()) \n              for var in {'Q16_Part_1','Q16_Part_2','Q16_Part_3','Q16_Part_4','Q16_Part_7'}}\nmulti_table([df_groupby['Q16_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q16_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q16_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'),df_groupby['Q16_Part_4'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'),df_groupby['Q16_Part_7'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","3a479dea":"df_groupby = {var: pd.DataFrame(df[df['Q2'] == 'Woman'].groupby([var, 'Q5']).size()) \n              for var in {'Q17_Part_1','Q17_Part_2','Q17_Part_3','Q17_Part_7'}}\nmulti_table([df_groupby['Q17_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q17_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q17_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'),df_groupby['Q17_Part_7'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","0d281cf7":"z=df[df['Q2']=='Woman'].groupby(['Q20','Q5']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap='pink', annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Current Roles of women', weight = 'bold', fontsize = 20)\ncolumns_text = z.columns\ncolumn_max = z.apply(lambda x: x, axis=1).idxmax(axis=0)\nfor col, variable in enumerate(columns_text):\n    position = z.apply(lambda x: x, axis=1).index.get_loc(column_max[variable])\n    ax.add_patch(Rectangle((col, position),1,1, fill=False, edgecolor='red', lw=3))\nplt.ylabel('Current Employer\/ contract',weight = 'bold', fontsize = 20)\nplt.title('Current Roles distribution of women by Current Employer\/ Contract',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","68605d0c":"z=df[df['Q2']=='Woman'].groupby(['Q20','Q5']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap='pink', annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Current Roles of women', weight = 'bold', fontsize = 20)\nindex_text = z.index    \nrow_max = z.apply(lambda x: x, axis=1).idxmax(axis=1)\nfor row, index in enumerate(index_text):\n    position = z.apply(lambda x: x, axis=1).columns.get_loc(row_max[index])\n    ax.add_patch(Rectangle((position, row),1,1, fill=False, edgecolor='blue', lw=3))\nplt.ylabel('Current Employer\/ contract',weight = 'bold', fontsize = 20)\nplt.title('Current Roles distribution of women by Current Employer\/ Contract',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","c9947b12":"z=df[df['Q2']=='Woman'].groupby(['Q25','Q5']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(20, 16))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap='pink', annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Current Roles of women', weight = 'bold', fontsize = 20)\ncolumns_text = z.columns\ncolumn_max = z.apply(lambda x: x, axis=1).idxmax(axis=0)\nfor col, variable in enumerate(columns_text):\n    position = z.apply(lambda x: x, axis=1).index.get_loc(column_max[variable])\n    ax.add_patch(Rectangle((col, position),1,1, fill=False, edgecolor='red', lw=3))\nplt.ylabel('Compensation in USD',weight = 'bold', fontsize = 20)\nplt.title('Current Roles distribution of women by Current Yearly Compensation',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","112039b7":"z=df[df['Q2']=='Woman'].groupby(['Q25','Q5']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(20, 16))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap='pink', annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Current Roles of women', weight = 'bold', fontsize = 20)\nindex_text = z.index    \nrow_max = z.apply(lambda x: x, axis=1).idxmax(axis=1)\nfor row, index in enumerate(index_text):\n    position = z.apply(lambda x: x, axis=1).columns.get_loc(row_max[index])\n    ax.add_patch(Rectangle((position, row),1,1, fill=False, edgecolor='blue', lw=3))\nplt.ylabel('Compensation in USD',weight = 'bold', fontsize = 20)\nplt.title('Current Roles distribution of women by Current Yearly Compensation',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","abba8a7e":"z=df[df['Q2']=='Woman'].groupby(['Q26','Q5']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap='pink', annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Current Roles of women', weight = 'bold', fontsize = 20)\ncolumns_text = z.columns\ncolumn_max = z.apply(lambda x: x, axis=1).idxmax(axis=0)\nfor col, variable in enumerate(columns_text):\n    position = z.apply(lambda x: x, axis=1).index.get_loc(column_max[variable])\n    ax.add_patch(Rectangle((col, position),1,1, fill=False, edgecolor='red', lw=3))\nplt.ylabel('Compensation in USD',weight = 'bold', fontsize = 20)\nplt.title('Current Roles distribution of women by Money spent on learning Machine Learning\/ Cloud Computing services in the past 5 years',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","9e2319a7":"z=df[df['Q2']=='Woman'].groupby(['Q26','Q5']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(16, 10))\nsns.heatmap(z.apply(lambda x: x, axis=1), xticklabels=True, yticklabels=True, cmap='pink', annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":14}, fmt='.3f', cbar=False)\nplt.xlabel('Current Roles of women', weight = 'bold', fontsize = 20)\nindex_text = z.index    \nrow_max = z.apply(lambda x: x, axis=1).idxmax(axis=1)\nfor row, index in enumerate(index_text):\n    position = z.apply(lambda x: x, axis=1).columns.get_loc(row_max[index])\n    ax.add_patch(Rectangle((position, row),1,1, fill=False, edgecolor='blue', lw=3))\nplt.ylabel('Compensation in USD',weight = 'bold', fontsize = 20)\nplt.title('Current Roles distribution of women by Money spent on learning Machine Learning\/ Cloud Computing services in the past 5 years',weight='bold', fontsize = 20)\nplt.yticks(fontsize=14, weight = 'bold')\nplt.xticks(fontsize=14, weight = 'bold')\nplt.show()","202eb300":"df_groupby = {var: pd.DataFrame(df[df['Q2'] == 'Woman'].groupby([var, 'Q5']).size()) \n              for var in {'Q39_Part_4','Q39_Part_6','Q39_Part_7','Q39_Part_9'}}\nmulti_table([df_groupby['Q39_Part_4'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q39_Part_6'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q39_Part_7'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'),df_groupby['Q39_Part_9'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","51896a26":"df_groupby = {var: pd.DataFrame(df[df['Q2'] == 'Woman'].groupby([var, 'Q5']).size()) \n              for var in {'Q40_Part_1','Q40_Part_3','Q40_Part_7','Q40_Part_10'}}\nmulti_table([df_groupby['Q40_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q40_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q40_Part_7'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'),df_groupby['Q40_Part_10'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","9f4fd106":"df_groupby = {var: pd.DataFrame(df[df['Q2'] == 'Woman'].groupby([var, 'Q5']).size()) \n              for var in {'Q42_Part_4','Q42_Part_6','Q42_Part_8'}}\nmulti_table([df_groupby['Q42_Part_4'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q42_Part_6'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q42_Part_8'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","6fcb92b4":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q1'] == '18-21')].groupby([var,'Q1','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","cf431d53":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q1'] == '22-24')].groupby([var,'Q1','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","d7df7aa0":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q1'] == '25-29')].groupby([var,'Q1','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","3e301a14":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q1'] == '30-34')].groupby([var,'Q1','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","67e710d9":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q1'] == '35-39')].groupby([var,'Q1','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","32c82dd6":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q1'] == '40-44')].groupby([var,'Q1','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","a5630cfd":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q1'] == '45-49')].groupby([var,'Q1','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","66a2bebb":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q1'] == '50-54')].groupby([var,'Q1','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","2cccfcbe":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q1'] == '55-59')].groupby([var,'Q1','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","0d3fb2cd":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q1'] == '60-69')].groupby([var,'Q1','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","b554b398":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q1'] == '70+')].groupby([var,'Q1','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","66a28e86":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q4'] == 'Bachelor\u2019s degree')].groupby([var,'Q4','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","13dae3e2":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q4'] == 'Master\u2019s degree')].groupby([var,'Q4','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","95858078":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q4'] == 'Doctoral degree')].groupby([var,'Q4','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","2f58a5d3":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q4'] == 'Some college\/university study without earning a bachelor\u2019s degree')].groupby([var,'Q4','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","a26dadcd":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q4'] == 'No formal education past high school')].groupby([var,'Q4','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","9be58248":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q4'] == 'Professional doctorate')].groupby([var,'Q4','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","6302e56a":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q5'] == 'Student')].groupby([var,'Q5','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","0435833b":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q5'] == 'Data Scientist')].groupby([var,'Q5','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","fcd189f1":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q5'] == 'Software Engineer')].groupby([var,'Q5','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","13f4797a":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q5'] == 'Data Analyst')].groupby([var,'Q5','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","6c352147":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q5'] == 'Currently not employed')].groupby([var,'Q5','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","c265494e":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q5'] == 'Research Scientist')].groupby([var,'Q5','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","4784eadc":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q5'] == 'Machine Learning Engineer')].groupby([var,'Q5','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","6ad9395e":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q5'] == 'Business Analyst')].groupby([var,'Q5','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","b5b6283a":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q5'] == 'Program\/Project Manager')].groupby([var,'Q5','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","8ce1c417":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q5'] == 'Data Engineer')].groupby([var,'Q5','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","6cfe3430":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q5'] == 'Product Manager')].groupby([var,'Q5','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","0e2935c8":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q5'] == 'Statistician')].groupby([var,'Q5','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","6aeb6613":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q5'] == 'DBA\/Database Engineer')].groupby([var,'Q5','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","92a80edc":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q5'] == 'Developer Relations\/Advocacy')].groupby([var,'Q5','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","5edccc9a":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q6'] == '1-3 years')].groupby([var,'Q6','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","17f9dd27":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q6'] == '< 1 years')].groupby([var,'Q6','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","604ee443":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q6'] == '3-5 years')].groupby([var,'Q6','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","c54663e2":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q6'] == '5-10 years')].groupby([var,'Q6','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","608170e5":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q6'] == '10-20 years')].groupby([var,'Q6','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","c3364147":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q6'] == '20+ years')].groupby([var,'Q6','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","937ca6e8":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q20'] == 'Computers\/Technology')].groupby([var,'Q20','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","873296ea":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q20'] == 'Academics\/Education')].groupby([var,'Q20','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","1fa7a728":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q20'] == 'Accounting\/Finance')].groupby([var,'Q20','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","26cf3ea1":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q20'] == 'Manufacturing\/Fabrication')].groupby([var,'Q20','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","1c275057":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q20'] == 'Medical\/Pharmaceutical')].groupby([var,'Q20','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","647c84e9":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q20'] == 'Government\/Public Service')].groupby([var,'Q20','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","e06cceb4":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q20'] == 'Online Service\/Internet-based Services')].groupby([var,'Q20','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","b7c754d8":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q20'] == 'Energy\/Mining')].groupby([var,'Q20','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","914adae3":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q20'] == 'Retail\/Sales')].groupby([var,'Q20','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","c0a03e11":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q20'] == 'Insurance\/Risk Assessment')].groupby([var,'Q20','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","6281a693":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q20'] == 'Marketing\/CRM')].groupby([var,'Q20','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","86d759a5":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q20'] == 'Broadcasting\/Communications')].groupby([var,'Q20','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","3b65c106":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q20'] == 'Shipping\/Transportation')].groupby([var,'Q20','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","8412f49f":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q20'] == 'Non-profit\/Service')].groupby([var,'Q20','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","94718818":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q20'] == 'Online Business\/Internet-based Sales')].groupby([var,'Q20','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","86cacd26":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman') & (df['Q20'] == 'Hospitality\/Entertainment\/Sports')].groupby([var,'Q20','Q25']).size()) \n              for var in {'Q7_Part_1','Q7_Part_2','Q7_Part_3'}}\nmulti_table([df_groupby['Q7_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q7_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","7bfeac07":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman')].groupby([var,'Q25']).size()) \n              for var in {'Q27_A_Part_1', 'Q27_A_Part_2',\n       'Q27_A_Part_3', 'Q27_A_Part_4', 'Q27_A_Part_5', 'Q27_A_Part_6',\n       'Q27_A_Part_7', 'Q27_A_Part_8', 'Q27_A_Part_9', 'Q27_A_Part_10',\n       'Q27_A_Part_11', 'Q27_A_OTHER'}}\nmulti_table([df_groupby['Q27_A_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q27_A_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q27_A_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q27_A_Part_4'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q27_A_Part_5'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q27_A_Part_6'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q27_A_Part_7'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q27_A_Part_8'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q27_A_Part_9'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q27_A_Part_10'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q27_A_Part_11'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q27_A_OTHER'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","33b4dcb5":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman')].groupby([var,'Q25']).size()) \n              for var in {'Q29_A_Part_1', 'Q29_A_Part_2',\n       'Q29_A_Part_3', 'Q29_A_Part_4', 'Q29_A_OTHER'}}\nmulti_table([df_groupby['Q29_A_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q29_A_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q29_A_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q29_A_Part_4'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q29_A_OTHER'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","36ba4484":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman')].groupby([var,'Q25']).size()) \n              for var in {'Q31_A_Part_1', 'Q31_A_Part_2', 'Q31_A_Part_3', 'Q31_A_Part_4',\n       'Q31_A_Part_5', 'Q31_A_Part_6', 'Q31_A_Part_7', 'Q31_A_Part_8',\n       'Q31_A_Part_9', 'Q31_A_OTHER'}}\nmulti_table([df_groupby['Q31_A_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q31_A_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q31_A_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q31_A_Part_4'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q31_A_Part_5'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q31_A_Part_6'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q31_A_Part_7'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q31_A_Part_8'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q31_A_Part_9'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q31_A_OTHER'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","37f03ed4":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman')].groupby([var,'Q25']).size()) \n              for var in {'Q32_A_Part_1', 'Q32_A_Part_2',\n       'Q32_A_Part_3', 'Q32_A_Part_4', 'Q32_A_Part_5', 'Q32_A_Part_6',\n       'Q32_A_Part_7', 'Q32_A_Part_8', 'Q32_A_Part_9', 'Q32_A_Part_10',\n       'Q32_A_Part_11', 'Q32_A_Part_12', 'Q32_A_Part_13', 'Q32_A_Part_14',\n       'Q32_A_Part_15', 'Q32_A_Part_16', 'Q32_A_Part_17', 'Q32_A_Part_18',\n       'Q32_A_Part_19', 'Q32_A_Part_20', 'Q32_A_OTHER'}}\nmulti_table([df_groupby['Q32_A_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q32_A_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q32_A_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q32_A_Part_4'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q32_A_Part_5'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q32_A_Part_6'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q32_A_Part_7'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q32_A_Part_8'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q32_A_Part_9'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q32_A_Part_10'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q32_A_Part_11'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q32_A_Part_12'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q32_A_Part_13'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q32_A_Part_14'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q32_A_Part_15'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q32_A_Part_16'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q32_A_Part_17'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q32_A_Part_18'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q32_A_Part_19'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q32_A_Part_20'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q32_A_OTHER'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","442f8eef":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman')].groupby([var,'Q25']).size()) \n              for var in {'Q34_A_Part_1', 'Q34_A_Part_2', 'Q34_A_Part_3', 'Q34_A_Part_4',\n       'Q34_A_Part_5', 'Q34_A_Part_6', 'Q34_A_Part_7', 'Q34_A_Part_8',\n       'Q34_A_Part_9', 'Q34_A_Part_10', 'Q34_A_Part_11', 'Q34_A_Part_12',\n       'Q34_A_Part_13', 'Q34_A_Part_14', 'Q34_A_Part_15', 'Q34_A_Part_16',\n       'Q34_A_OTHER'}}\nmulti_table([df_groupby['Q34_A_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q34_A_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q34_A_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q34_A_Part_4'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q34_A_Part_5'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q34_A_Part_6'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q34_A_Part_7'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q34_A_Part_8'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q34_A_Part_9'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q34_A_Part_10'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q34_A_Part_11'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q34_A_Part_12'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q34_A_Part_13'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q34_A_Part_14'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q34_A_Part_15'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q34_A_Part_16'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q34_A_OTHER'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","8a2fbe65":"df_groupby = {var: pd.DataFrame(df[(df['Q2'] == 'Woman')].groupby([var,'Q25']).size()) \n              for var in {'Q36_A_Part_1', 'Q36_A_Part_2',\n       'Q36_A_Part_3', 'Q36_A_Part_4', 'Q36_A_Part_5', 'Q36_A_Part_6',\n       'Q36_A_Part_7', 'Q36_A_OTHER'}}\nmulti_table([df_groupby['Q36_A_Part_1'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q36_A_Part_2'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q36_A_Part_3'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q36_A_Part_4'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q36_A_Part_5'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q36_A_Part_6'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q36_A_Part_7'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow'), df_groupby['Q36_A_OTHER'].style\\\n      .format('{:.2f}')\\\n      .highlight_max(color = 'lightgreen')\\\n      .highlight_min(color = 'coral')\\\n      .highlight_null(null_color='yellow')])","250f2c51":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 7: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">What programming languages do you use on a regular basis?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","f927c562":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women with coding experience less than 1 years by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","01b7d920":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Current Roles distribution of women by public application to share your data analysis or machine learning <strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","9bf07255":"<h1 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Analysis with respect to Degree Distribution of women<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h1>","b460adbc":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Age distribution of women by platforms they begun or completed data science courses<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","1a7349ec":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women Students by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","284418c6":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women with Accounting\/Finance contract by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","fbf19411":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 42: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">Who\/what are your favorite media sources that report on data science topics?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","50c930f0":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Employed Woman Across Years<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","804ce33f":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Current Roles distribution of women by platforms they begun or completed data science courses<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","c5c2cbbe":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women with Academics\/Education contract by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","c62f6388":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Employed vs Unemployed women in all Degrees<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","dae0cb5c":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 10: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">Which of the following hosted notebook products do you use on a regular basis?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","b600980d":"#### Observation:\n\n1. In all years survey, women with jobs not related to data science are more when compared to women with jobs related to data science","c2999921":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women with Current Employer\/Contract as <strong> Academics\/Education <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(208) <\/strong> as yearly compensation.\n2. Most of the women with Current Employer\/Contract as <strong> Academics\/Education <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(59) <\/strong> as yearly compensation.\n3. Most of the womenwith Current Employer\/Contract as <strong> Academics\/Education <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(99) <\/strong> as yearly compensation.\n4. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> 300,000-499,999 USD <\/strong>\n5. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 250,000-299,999 USD <\/strong>\n6. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 300,000-499,999 USD <\/strong>","8969885e":"#### Observation:\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n\n1. Most of the women with Current Job <strong> Data Engineer,Data Scientist, Machine Learning Engineer,Research Scientist,Statistician,Software Engineer,Student <\/strong> have coding experience <strong> 1-3 years <\/strong>\n2. Most of the women with Current Job <strong> Developer Relations\/Advocacy <\/strong> have coding experience <strong> 10-20 years <\/strong>\n3. Most of the women with Current Job <strong> DBA\/Database Engineer <\/strong> have coding experience <strong> 3-5 years <\/strong>\n4. Most of the women with Current Job <strong> Business Analyst,Currently not employed,Data Analyst,Other, Product Manager,Program\/Project Manager <\/strong> have coding experience <strong> lessthan 1 year <\/strong>\n5. Most of the women who has coding experience <strong> 5-20+ years <\/strong> are working as <strong> Data Scientist <\/strong>\n6. Most of the women who has coding experience <strong> 0-5 years <\/strong> are <strong> Students <\/strong>","8897a29a":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Age distribution of woman by degree<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","c2fa4ed5":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women of age group 35-39 by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","fcf54a6f":"## Note: In all heatmaps red patches indicates HIGHEST VALUE IN EVERY COLUMN and blue patches indicates HIGHEST VALUE IN EVERY ROW","a05e8dc1":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women of Masters degree by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","ca6dfa9f":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Degree distribution of women by Machine Learning Algorithms used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","eaa8d82e":"#### Observation:\n\n1. 31.1% of people are working in company of size 0-50 employees which is highest among all\n2. 21% of the people are working in company of size 10,000+ employees\n3. 18.8% of the people are working in company of size 1000-9999 employees\n4. 15.8% of the people are working in company of size 50-249 employees\n5. 13.3% of thr people are working in company of size 250-999 employees which is least among all","bd639fa1":"#### Observation:\n\n1. OHHH..!!! Most of the people are doing their projects in their laptop and a good number of people are using personal computer\/ Desktop\n2. Very less number of people are using A deep learning workstation\n3. One thing I got here is that many people are beginners or started their learning recently. So, a laptop is enough to finish their work and since it was a kaggale survey every one who does work on kaggle at most use laptop..!!","3bd42205":"<strong> In the survey a total of 42 questions have been asked lets look into them <\/strong>","fabb026f":"<h6 style=\"color:#fce444;font-size:26px;font-family:Georgia;text-align:center;\"><strong> <strong style=\"color:black;font-size:21px;font-family:Georgia;\">This is the story for today thanks for listening and if you also want be successful in life start working from today.........Signing off.... <strong style=\"color:#fce444;font-size:21px;font-family:Georgia;\"> <strong style=\"color:black;font-size:26px;font-family:Georgia;\"> <\/strong><\/strong><\/strong><\/strong><\/h6>","20fdf797":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Employed Woman vs Unemployed Woman with Bachelor's degree<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","bb9b26b5":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n\n1. Most of the women of age group <strong> 18-49 <\/strong> and <strong> 55-69 <\/strong> are earning <strong> 0-999 USD <\/strong> yearly.\n2. Most of the women of age group <strong> 50-54 <\/strong> and <strong> 70+ <\/strong> are earning <strong> 100,000 - 124,999 USD <\/strong> yearly.\n3. Most of the women who earn <strong> 0-999 USD,$4,000 - 4,999,$300,000 - 499,999 <\/strong> are of age group <strong> 22-24 <\/strong>.\n4. Most of the women who earn <strong> 1,000-1,999 USD, $10,000-14,999, $15,000-19,999, $2,000-2,999, $20,000-24,999,$200,000-249,999, $25,000-29,999, $3,000-3,999, $30,000-39,999, $40,000-49,999,$5,000-7,499,$50,000-59,999,$7,500-9,999 <\/strong> are of age group <strong> 25-29 <\/strong>.\n5. Most of the women who earn <strong> $125,000-149,999, $80,000-89,999 <\/strong> are of age group <strong> 30-34 <\/strong>.\n6. Most of the women who earn <strong> 500,000-999,999 USD, $150,000-199,999,$60,000-69,999,$70,000-79,999,$90,000-99,999 <\/strong> are of age group <strong> 35-39 <\/strong>.\n7. Most of the women who earn <strong> 100,000-124,999 USD, $>$1,000,000 <\/strong> are of age group <strong> 40-44 <\/strong>.\n8. Most of the women who earn <strong> 250,000-299,999 <\/strong> are of age group <strong> 55-59 <\/strong>.","4476d9a7":"### References:\n1. Headings HTML style is suggested by : Sonali Singh \n2. Heatmaps are inspiration from https:\/\/www.kaggle.com\/datafan07\/what-takes-to-be-a-data-scientist-story-of-robert\n3. All images are taken from google.","68ce42f0":"#### Observation:\n\n1. 21.3% of employees stated that they are exploring to use ML methods and may put into production in their business which is highest among all\n2. 20.5% of employees stated that they are not using any ML methods in their business.\n3. 17% of employees stated that they don't know whether they use or not\n4. 10.7% of employees stated that they only used ML methods to generate insights but not put working models into production which is lowest among all\n5. Combinely 30.6% of employees stated that they are using ML methods frrom 0-4 years in their business production","01d181d7":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women of age group 25-29 by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","9da0a01c":"<h1 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Analysis with respect to Income Distribution<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h1>","b4868bf4":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women with Current Employer\/Contract as <strong> Computers\/Technology <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(151) <\/strong> as yearly compensation.\n2. Most of the women with Current Employer\/Contract as <strong> Computers\/Technology <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(23) <\/strong> as yearly compensation.\n3. Most of the womenwith Current Employer\/Contract as <strong> Computers\/Technology <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(83) <\/strong> as yearly compensation.\n4. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> morethan 1,000,000 USD <\/strong>\n5. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 300,000-499,999 USD <\/strong>\n6. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 300,000-499,999 USD <\/strong>","8d50928d":"#### Observation:\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n\n1. Most of the women who attained\/wanted to do <strong>  Bachelor's degree, Prefer not to answer, Master's degree <\/strong> have coding experience in between <strong> 1-3 years <\/strong>.\n2. Most of the women who attained\/wanted to do <strong>  No formal education past high school, Professional Doctorate,Some college\/university study without earning a bachelor's degree <\/strong> have coding experience <strong> lessthan 1 year <\/strong>.\n3. Most of the women who attained\/wanted to do <strong>  Doctoral degree <\/strong> have coding experience in between <strong> 3-5 years <\/strong>.\n4. Most of the women with coding experience <strong> 3-20+ years <\/strong> have attained\/want to do <strong> Master's Degree <\/strong>\n5. Most of the women with no coding experience or <strong> 0-3 years <\/strong> of coding experience have attained\/want to do <strong> Bachelor's Degree <\/strong>.","95abc688":"#### Observation:\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n\n1. Most of the women of all degrees are using <strong> Laptop <\/strong> as specialized software used on regular basis\n2. Most of the women who are using <strong> A cloud computing platform (AWS, Azure, GCP, hosted notebooks, etc),A deep learning workstation (NVIDIA GTX, LambdaLabs, etc),A personal computer \/ desktop,None,Other <\/strong> as specialized software used on regular basis have attained\/want to do <strong> Master's Degree <\/strong>","454a8744":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 22: <strong style=\"color:black;font-size:25px;font-family:Georgia;\"> Approximately how many individuals are responsible for data science workloads at your place of business?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","4509565e":"<img src=\"https:\/\/d.newsweek.com\/en\/full\/1868100\/what-if-watcher.png\" width=\"800px\">","81c49a1b":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 30 Part A: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">In the next 2 years, do you hope to become more familiar with any of these specific cloud computing products?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","af1fd590":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women with by big data products used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","91babf91":"#### Observation:\n\n1. 21.9% of people are earning 0-999 USD per year highest among all\n2. 6.3% people are earning 1,000-1999 USD per year\n3. Only 0.208% people are earning 500,000-999,999 USD per year which is lowest among all","20ad55a1":"<h1 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women of all Degrees by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h1>","b75a83c4":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women of age group <strong> 35-39 <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(49) <\/strong> as yearly compensation and less number of women are earning <strong> 200,000-249,999 USD (1), 300,000-499,999 USD (1), 500,000-999,999 USD(1) <\/strong> as yearly compensation.\n2. Most of the women of age group <strong> 35-39 <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(9) <\/strong> as yearly compensation and less number of women are earning <strong> 100,000-124,999 USD (1), 300,000-499,999 USD (1), 40,000-49,999 USD (1)<\/strong> as yearly compensation.\n3. Most of the women of age group <strong> 35-39 <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(27) <\/strong> as yearly compensation and less number of women are earning <strong> 200,000-249,999 USD (1), 300,000-499,999 USD (1), 4,000-4,999 USD (1) <\/strong> as yearly compensation.\n4. Here we can see three woman are earning <strong> 300,000-499,999 USD <\/strong> one use <strong> R <\/strong>,one use <strong> SQL <\/strong> and another one use <strong> Python <\/strong> programming language on regular basis.\n5. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> 300,000-499,999 USD <\/strong>\n6. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 300,000-499,999 USD <\/strong>\n7. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 300,000-499,999 USD <\/strong>\n\n\n\nIf we compare women of age group <strong> 35-39 <\/strong> on programming language used on regular basis, we can see that women who use python on regular basis are earning morethan women who use R and SQL and we can also see that women who use python are also more than women who use R,SQl.\n\nIf we arrange Python,R and SQL with respect to number of women using the languages on regular basis and how much they are earning, it would look like:<strong> python > SQL> R <\/strong>","9473eb5a":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women of age group 55-59 by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","c3e917d4":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Python vs R vs SQL(Programming Language used on regular basis) in all Current Roles of Women<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","c9201bbb":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women with coding experience <strong> 5-10 years <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(49) <\/strong> as yearly compensation and less number of women are earning <strong> 250,000-299,999 USD(1)<\/strong> as yearly compensation.\n2. Most of the women with coding experience <strong> 5-10 years <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 30,000-39,999\t USD(9) <\/strong> as yearly compensation and less number of women are earning <strong> 500,000-999,999 USD(1),150,000-199,999 USD(1),200,000-249,999 USD(1),40,000-49,999 USD(1)<\/strong> as yearly compensation.\n3. Most of the womenwith coding experience <strong> 5-10 years <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(26) <\/strong> as yearly compensation and less number of women are earning <strong> 250,000-299,999 USD(1)<\/strong> as yearly compensation.\n4. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> 250,000-299,999 USD <\/strong>\n5. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 500,000-999,999 USD<\/strong>\n6. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 250,000-299,999 USD <\/strong>","5e4cbd23":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Scikit-learn, TensorFlow, Keras, PyTorch and Xgboost only these 5 because these are the most choosed option.\n\n\n1. Scikit-learn is most choosed by the women of age group <strong> 25-29(521) <\/strong> and less choosed by the women of age group <strong> 70+(5) <\/strong>. \n2. TensorFlow is most choosed by the women of age group <strong> 25-29(316) <\/strong> and less choosed by the women of age group <strong> 70+ (1) <\/strong>.\n3. Keras is most choosed by the women of age group <strong> 25-29(267) <\/strong> and less choosed by the women of age group \n<strong> 70+(1) <\/strong>.\n4. PyTorch is most choosed by the women of age group <strong> 25-29(197) <\/strong> and less choosed by the women of age group <strong> 60-69(4) <\/strong>.Intresting fact is no women of age group <strong> 70+ <\/strong> choosed <strong> PyTorch <\/strong>.\n5. Xgboost is most choosed by the women of age group <strong> 25-29(194) <\/strong> and less choosed by the women of age group <strong> 70+(1) <\/strong>.","9a510115":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n\n1. Most of the women of all Current roles are using <strong> Laptop <\/strong> as their specialized software.\n2. Most of the women who use <strong> A deep learning workstation (NVIDIA GTX, LambdaLabs, etc),A laptop,A personal computer \/ desktop <\/strong> as their specialized software are <strong> Students <\/strong>.\n3. Most of the women who use <strong> A cloud computing platform (AWS, Azure, GCP, hosted notebooks, etc) <\/strong> as their specialized software are of Current Role <strong> Data Scientist <\/strong>.","2aa1563c":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women of age group <strong> 25-29 <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(140) <\/strong> as yearly compensation and less number of women are earning <strong> 250,000 - 299,999 USD(1) <\/strong> as yearly compensation.\n2. Most of the women of age group <strong> 25-29 <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(39) <\/strong> as yearly compensation and less number of women are earning <strong> 125,000-149,999 USD(1),150,000-199,999 USD(1)<\/strong> as yearly compensation.\n3. Most of the women of age group <strong> 25-29 <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(77) <\/strong> as yearly compensation and less number of women are earning <strong> > 1,000,000 USD(1) <\/strong> as yearly compensation.\\\n4. Here we can see one woman is earning <strong> morethan 1,000,000 USD <\/strong> she uses <strong> SQL <\/strong> programming language on regular basis.\n5. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> 250,000-299,999 USD <\/strong>\n6. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 150,000-199,999 USD <\/strong>\n7. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> morethan 1,000,000 USD <\/strong>\n\n\nIf we compare women of age group <strong> 25-29 <\/strong> on programming language used on regular basis, we can see that women who use python on regular basis are earning morethan women who use R and SQL and we can also see that women who use python are also more than women who use R,SQl.\n\nIf we arrange Python,R and SQL with respect to number of women using the languages on regular basis and how much they are earning, it would look like:<strong> python > SQL> R <\/strong>","846cd841":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 25: <strong style=\"color:black;font-size:25px;font-family:Georgia;\"> What is your current yearly compensation (approximate USD)?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","241477c7":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Age distribution of women by Current Employer\/ Contract<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","d962bff4":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women of Current Role as <strong> Research Scientist <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(60) <\/strong> as yearly compensation.\n2. Most of the women of Current Role as <strong> Research Scientist<\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(4) <\/strong> as yearly compensation.\n3. Most of the women of Current Role as <strong> Research Scientist <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(16) <\/strong> as yearly compensation.\n4. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong>500,000-999,999 USD <\/strong>\n5. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 100,000-124,999 USD <\/strong>\n6. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 150,000-199,999 USD <\/strong>","a96f075f":"#### Observation:\n\n1. Most of the people are using Word embeddings\/vectors (GLoVe, fastText, word2vec) NLP method on regular basis..!! and if you want to know word embeddings library\/method used to find which categorical value repeated most in that particular column..!!!\n2. Transformer language models (GPT-3, BERT, XLnet, etc) NLP model stands in second place\n3. Least number of people are using Contextualized embeddings (ELMo, CoVe) NLP method..!!","09b4b948":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women Business Analysts by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","9a17f6d7":"#### Observation:\n\n1. It seems that this question is a multiple option choosable question..!!\n2. Matplotlib library is using by many people. It is pretty obivous that for plotting matplotlib is very necessary and it is the first visualisation library that is introduced to everyone..!!\n3. The next 3 popular libraries used are Seaborn,plotly\/plotly express and Ggplot\/ ggplot2\n4. Among the options less opted option\/library is Altair..!","91bc9b1d":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women with Medical\/Pharmaceutical contract by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","cf002b56":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Python vs R vs SQL(Programming Language used on regular basis) in all Age Groups of Women<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","2db81323":"#### Observation:\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n1. Most of the women of all degrees are currently earning <strong> 0-999 USD <\/strong> every year.\n2. Most of the women who are earning <strong> 0-999 USD,1,000-1,999 USD,10,000-14,999 USD, 100,000-124,999USD,125,000-149,999 USD, 15,000-19,999 USD,150,000-199,999 USD, 2,000-2,999 USD, 20,000-24,999 USD, 200,000-249,999 USD, 25,000-29,999 USD, 250,000-299,999 USD, 3,000-3,999 USD, 30,000-39,999 USD <\/strong> have attained\/want to do <strong> Master's Degree <\/strong>.\n3. Most of the women who are earning <strong> 5,000 - 7,499 USD, > 1,000,000 USD <\/strong> have attained\/want to do <strong> Bachelor's Degree <\/strong>.\n4. 3. Most of the women who are earning <strong> 500,000-999,999 USD, 300,000-499,999 USD <\/strong> have attained\/want to do <strong> Doctoral Degree <\/strong>.","74751865":"#### Observation:\n\n1. OHHHHH..!!! there are only 3 Notebooks above 2000 votes and their votes are greather than 9500.\n2. Most of the people are using Colab Notebooks on regular basis.\n3. Kaggle Notebook stands is second place but not much difference\n4. Suprisingly the 3rd most opted option is None may be they are using jupyter notebook I think since it is not mentioned in the options\n5. Observable Notebooks stands in last place","e2b7354f":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n1. Most of the women with Current Role <strong> Business Analyst, Currently not employed, DBA\/Database Engineer,Data Analyst, Data Engineer,Data Scientist,Developer Relations\/Advocacy, Machine Learning Engineer, Other,Product Manager <\/strong> are of age group <strong> 25-29 <\/strong>.\n2. Most of the women with Current Role <strong> Program\/Project Manager,Research Scientist <\/strong> are of age group <strong> 30-34 <\/strong>.\n3. Most of the women with Current Role <strong> Software Engineer, Statistician <\/strong> are of age group <strong> 22-24 <\/strong>.\n4. Most of the women <strong> Students <\/strong> are of age group <strong> 18-21 <\/strong>.\n5. In age group <strong> 18-29 <\/strong> most of the women are <strong> Students(837) <\/strong>, but women in age groups 22-29 are pretty much invloved in jobs.\n6. In age group <strong> 30-44 <\/strong> most of the women are working as <strong> Data Scientist(383) <\/strong>.\n7. In age group <strong> 45-69 <\/strong> most of the women are working in <strong> Other fields(189) <\/strong> which are not mentioned in survey options.\n8. In age group <strong> 70+ <\/strong> most of the women are <strong> Currently not Employed <\/strong>\n9. In age group <strong> 25-29 <\/strong> most of them are students but number is not much domiant like in case of age group 18-21, many women of age group <strong> 25-29 <\/strong> are working in <strong> Data Science related fields <\/strong>.","00ebeb22":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Linear or Coursera, Kaggle Learn Courses, Udemy and University Courses (resulting in a university degree) only these 4 because these are the most choosed option.\n\n\n1. Coursera is most choosed by the women of age group <strong> 25-29(358) <\/strong> and less choosed by the women of age group <strong> 70+(5) <\/strong>. \n2. Kaggle Learn Courses is most choosed by the women of age group <strong> 18-21(303) <\/strong> and less choosed by the women of age group <strong> 70+ (5) <\/strong>.\n3. Udemy is most choosed by the women of age group <strong> 25-29(252) <\/strong> and less choosed by the women of age group  <strong> 70+(3) <\/strong>.\n4. University Courses (resulting in a university degree is most choosed by the women of age group <strong> 25-29(238) <\/strong> and less choosed by the women of age group <strong> 70+(3) <\/strong>.","04e7a33c":"<h6 style=\"color:#fce444;font-size:26px;font-family:Georgia;text-align:center;\"><strong>\"I am The Watcher. I am your guide through these vast new realities. <strong style=\"color:black;font-size:21px;font-family:Georgia;\">Follow me and dare to face the unknown,and ponder the question... What if? <strong style=\"color:#fce444;font-size:21px;font-family:Georgia;\">\"I observe all that transpires here. And I do not, can not, will not interfere.\" <strong style=\"color:black;font-size:26px;font-family:Georgia;\"> <\/strong><\/strong><\/strong><\/strong><\/h6>","a14f9e41":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Degree Distribution of women by age<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","bebc3f97":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n1. Most of the women involved in <strong> 2021 <\/strong> survey attained\/wanted to do <strong> Master's degree(1950) <\/strong>\n2. Women attained\/wanted to do <strong> Bachelor's degree(1843) <\/strong> stands in 2nd place in <strong> 2021 <\/strong>.\n3. Very less women invloved in <strong> 2021 <\/strong> survey had <strong> No formal education past high school <\/strong>.","e45fa267":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Kaggle (notebooks, forums, etc), YouTube (Kaggle YouTube, Cloud AI Adventures, etc), Blogs (Towards Data Science, Analytics Vidhya, etc) only these 3 because these are the most choosed option.\n\n\n1. Kaggle (notebooks, forums, etc) is most choosed by the women <strong> Students (504) <\/strong> and less choosed by the women with Current Role <strong>Developer Relations\/Advocacy(6) <\/strong>.\n2. YouTube (Kaggle YouTube, Cloud AI Adventures, etc) is most choosed by the women <strong> Students (500) <\/strong> and less choosed by the women with Current Role <strong> Developer Relations\/Advocacy(6)<\/strong>.\n3. Blogs (Towards Data Science, Analytics Vidhya, etc) is most choosed by the women <strong> Students (374) <\/strong> and less choosed by the women with Current Role <strong> Developer Relations\/Advocacy(2) <\/strong>.","9869b7e9":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed  Kaggle (notebooks, forums, etc), YouTube (Kaggle YouTube, Cloud AI Adventures, etc) and Blogs (Towards Data Science, Analytics Vidhya, etc) only these 3 because these are the most choosed option.\n\n\n1. Kaggle (notebooks, forums, etc) is most choosed by the women who attained\/want to do <strong> Master's degree(795) <\/strong> and less choosed by the women who attained\/want to do <strong> No formal education past high school(5) <\/strong>.\n2. YouTube (Kaggle YouTube, Cloud AI Adventures, etc) is most choosed by the women who attained\/want to do <strong> Master's degree(674) <\/strong> and less choosed by the women who attained\/want to do <strong> No formal education past high school(9) <\/strong>.\n3. Blogs (Towards Data Science, Analytics Vidhya, etc) is most choosed by the women who attained\/want to do <strong> Master's degree(645) <\/strong> and less choosed by the women who attained\/want to do <strong> No formal education past high school(6) <\/strong>.","0a46864c":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed VSCode, PyCharm and Jupyter Notebook only these 3 because these are the most choosed option.\n\n1. VSCode is most choosed by the women of age group <strong> 18-21(505) <\/strong> and less choosed by the women of age group <strong> 60-69(7) <\/strong>. Intresting fact is no women of age group <strong> 70+ <\/strong> choosed <strong> VSCode <\/strong>.\n2. PyCharm is most choosed by the women of age group <strong> 18-21(367) <\/strong> and less choosed by the women of age group <strong> 60-69(6) <\/strong>. Intresting fact is no women of age group <strong> 70+ <\/strong> choosed <strong> PyCharm <\/strong>.\n3. Jupyter Notebook is most choosed by the women of age group <strong> 18-21(690) <\/strong> and less choosed by the women of age group <strong> 70+(5) <\/strong>.","a1ffda9e":"#### Observation:\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n1. Most of the women who attained\/want to do <strong> Bachelor's Degree, Master's Degree, Some college\/University study without earning a abachelor's degree <\/strong> have Current Employer\/Contract as <strong> Computers\/Technology <\/strong>.\n2. Most of the women who attained\/want to do <strong> Doctoral Degree,I prefer not to answer, No formal education past high school, professional doctorate <\/strong> have Current Employer\/Contract as<strong> Academics\/Education <\/strong>.\n3. Most of the people who have Current Employer\/Contract as <strong> Accounting\/Finance,Broadcasting\/Communications,Computers\/Technology,Energy\/Mining,Government\/Public Service,Hospitality\/Entertainment\/Sports,Insurance\/Risk Assessment,Manufacturing\/Fabrication,Marketing\/CRM,Medical\/Pharmaceutical,Military\/Security\/Defense, Non-profit\/Service,Online Business\/Internet-based Sales,Online Service\/Internet-based Services,Retail\/Sales,Shipping\/Transportation <\/strong> have attained\/want to do <strong> Master's degree <\/strong>\n4. Most of the people who have Current Employer\/Contract as <strong> Academics\/Education <\/strong> have attained\/want to do <strong> Doctoral degree <\/strong>","b6295cba":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women of age group <strong> 50-54 <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 100,000-124,999 USD(9),150,000-199,999 USD(9) <\/strong> as yearly compensation and less number of women are earning <strong> 200,000-249,999 USD(1), 30,000-39,999 USD (1), 5,000-7,499 USD(1), 70,000-79,999 USD(1)   <\/strong> as yearly compensation.\n2. Most of the women of age group <strong> 50-54 <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 150,000-199,999 USD(6) <\/strong> as yearly compensation and less number of women are earning <strong> 0-999 USD(1), 1,000-1,999 USD(1),15,000-19,999 USD(1),15,000-19,999 USD(1),20,000-24,999 USD(1),200,000-249,999 USD(1),3,000-3,999 USD(1),70,000-79,999 USD(1), 80,000-89,999 USD (1), 90,000-99,999 USD(1)  <\/strong> as yearly compensation.\n3. Most of the women of age group <strong> 50-54 <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 100,000-124,999 USD(10) <\/strong> as yearly compensation and less number of women are earning <strong> 1,000-1,999\tUSD(1), 20,000-24,999 USD (1), 3,000-3,999 USD(1), 30,000-39,999 USD (1), 40,000-49,999 USD(1), 7,500-9,999 USD(1),70,000-79,999 USD(1), 80,000-89,999 USD (1) <\/strong> as yearly compensation.\n4. Here we can see two woman are earning <strong> 200,000-249,999 USD <\/strong> one use <strong> R <\/strong> and another one use <strong> Python <\/strong> programming language on regular basis.\n5. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> 200,000-249,999 USD <\/strong>\n6. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 200,000-249,999\t USD <\/strong>\n7. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 150,000-199,999 USD <\/strong>\n\n\nIf we compare women of age group <strong> 50-54 <\/strong> on programming language used on regular basis, we can see that women who use python on regular basis are earning morethan women who use R and SQL and we can also see that women who use python are also more than women who use R,SQl.\n\nIf we arrange Python,R and SQL with respect to number of women using the languages on regular basis and how much they are earning it would look like:<strong> python >SQL> R <\/strong>","5069d7e5":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 35: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">Which of the following business intelligence tools do you use most often?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","ae7680ae":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women Data Scientist by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","bfc2d3e4":"#### Observation:\n\n1. Most of the people did masters's degree or willing to do masters's degree in next two years and also many students did bachelor's degree.\n\n2. We already know the fact that people between age <strong> 18-29 <\/strong> are more, so it is very often that maximum people in that age will do bachelor's or master's degree and there are people without bachelor's degree but less in number.\n\n3. One intresting thing is that some people with no formal education are on Kaggle.. Thats pretty good..!!!!","82c082f8":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women of age group 50-54 by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","91aeca3d":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed  Coursera, Kaggle Learn Courses, Udemy and University Courses (resulting in a university degree) only these 4 because these are the most choosed option.\n\n\n1. Coursera is most choosed by the women who attained\/want to do <strong> Master's degree(718) <\/strong> and less choosed by the women who attained\/want to do <strong> No formal education past high school(9) <\/strong>.\n2. Kaggle Learn Courses is most choosed by the women who attained\/want to do <strong> Master's degree(601) <\/strong> and less choosed by the women who attained\/want to do <strong> No formal education past high school(7) <\/strong>.\n3. Udemy is most choosed by the women who attained\/want to do <strong> Master's degree(465) <\/strong> and less choosed by the women who attained\/want to do <strong> No formal education past high school(7) <\/strong>.\n4. University Courses (resulting in a university degree) is most choosed by the women who attained\/want to do <strong> Master's degree(470) <\/strong> and less choosed by the women who attained\/want to do <strong> No formal education past high school(4) <\/strong>.","089befa2":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 20: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">In what industry is your current employer\/contract (or your most recent employer if retired)?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","31ed3041":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women with Current Employer\/Contract as <strong> Accounting\/Finance <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(29) <\/strong> as yearly compensation.\n2. Most of the women with Current Employer\/Contract as <strong> Accounting\/Finance <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(11) <\/strong> as yearly compensation.\n3. Most of the womenwith Current Employer\/Contract as <strong> Accounting\/Finance <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(21) <\/strong> as yearly compensation.\n4. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> 200,000-249,999\t USD <\/strong>\n5. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 250,000-299,999 USD <\/strong>\n6. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 200,000-249,999 USD <\/strong>","fd6cae00":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women with Current Employer\/Contract as <strong> Manufacturing\/Fabrication <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(14) <\/strong> as yearly compensation.\n2. Most of the women with Current Employer\/Contract as <strong> Manufacturing\/Fabrication <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(4),40,000-49,999 USD(4) <\/strong> as yearly compensation.\n3. Most of the womenwith Current Employer\/Contract as <strong> Manufacturing\/Fabrication <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(7) <\/strong> as yearly compensation.\n4. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> 200,000-249,999\t USD <\/strong>\n5. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 150,000-199,999 USD <\/strong>\n6. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 200,000-249,999 USD <\/strong>","4d702951":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women of Doctoral degree by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","78208ebf":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Current Role distribution of women by Data Visualization Libraries used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","3173e4bb":"#### Observation:\n\n1. In every year employed women with Bachelor's degree are morethan unemployed women with Bachelor's degree","c8ce8428":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Degree distribution of women by Current Yearly Compensation <strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","9717a155":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women with Current Employer\/Contract as <strong> Government\/Public Service <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(12) <\/strong> as yearly compensation.\n2. Most of the women with Current Employer\/Contract as <strong> Government\/Public Service <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 100,000-124,99 USD(5) <\/strong> as yearly compensation.\n3. Most of the womenwith Current Employer\/Contract as <strong> Government\/Public Service <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(7) <\/strong> as yearly compensation.\n4. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> 150,000-199,999\t\t USD <\/strong>\n5. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 150,000-199,999 USD <\/strong>\n6. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 150,000-199,999 USD <\/strong>","96b626a6":"#### Observation:\n1. WAAAHH...!!! Most of the People in kaggle are Students(includig me). It is pretty obvious that students have more time to do this stuff.\n\n2. Data scientists stood at 2nd place\n\n3. One intresting fact is that Software Engineers are more than Data analysts, machine learning engineers, data engineers\n\n4. Developers are very less as we know both the domains are quite different but some are doing Kaggle as their daily hobby..!! That's good..!!","cb7d4b5e":"#### Observation:\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n\n1. Most of the women in all degrees recommended <strong> Python <\/strong> programming language for aspiring Data Scientists\n2. Most of the women who recommended <strong> C,C++,Java,MATLAB <\/strong> programming languages for aspiring Data Scientists have attined\/want to do <strong> Bachelor's degree <\/strong>.\n3. Most of the women who recommended <strong> Java Script,Julia,None,Other,Python,R,SQL <\/strong> programming languages for aspiring Data Scientists have attined\/want to do <strong> Master's degree <\/strong>.\n4. In total survey only one women recommended <strong> Swift <\/strong> programming language for aspiring Data Scientists and she attained\/want to do <strong> Doctoral Degree <\/strong>.\n5. In total survey only 5 women recommended <strong> Bash <\/strong> programming language for aspiring Data Scientists, in that majority of women have attained\/want to do <strong> Some college\/University study without earning a Bachelor's degree <\/strong>.","e5262641":"<h2 style=\"color:red;font-size:16px;font-family:Georgia;text-align:center;\"><strong><p><\/p> <strong style=\"color:black;font-size:20px;font-family:Georgia;\"> Students submitted all these observations to NICK FURY. See what he is quite impressive and appreciated all the students,given some compensation as well. He also told each and every student to work hard to achieve their goals. All the students were happy and they went to their hostels\/home at the end of the day.<\/strong><\/strong><\/h2>","13ff7a95":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women with Current Employer\/Contract as <strong>Shipping\/Transportation <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(4) <\/strong> as yearly compensation.\n2. Most of the women with Current Employer\/Contract as <strong> Shipping\/Transportation <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 100,000-124,999 USD(2),60,000-69,999 USD(2) <\/strong> as yearly compensation.\n3. Most of the womenwith Current Employer\/Contract as <strong> Shipping\/Transportation <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(2), 20,000-24,999 USD(2) <\/strong> as yearly compensation.\n4. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> 125,000-149,999 USD <\/strong>\n5. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 100,000-124,999 USD <\/strong>\n6. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 125,000-149,999 USD <\/strong>","460136ba":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 3: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">In which country do you currently reside? <strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","80996c96":"#### Observation\n##### All these observations are with respect to the women in the survey not entire women in the world \n \n \n1. In age group <strong> 18-21 <\/strong> most of the women<strong> (763) <\/strong> attained\/wanted to do <strong> Bachelor's degree <\/strong>.\n2. In age group <strong> 22-24 <\/strong> most of the women<strong> (435) <\/strong> attained\/wanted to do <strong> Bachelor's degree <\/strong>, followed by women with\/wanted to do <strong> Master's Degree(423) <\/strong> are more.\n3. In age group <strong> 22-24 <\/strong> women with\/wanted to do <strong> Bachelor's degree <\/strong> and women with\/wanted to do <strong> Master's degree <\/strong> are almost equal.\n4. In age group <strong>  25-70+ <\/strong> most of the women attained\/wanted to do <strong> Master's degree.<\/strong>\n5. In age group <strong> 60-69 <\/strong> most of thr women attained\/wanted to do both <strong> Bachelor's and Master's degree <\/strong>.\n6. There are only <strong> 8 women <\/strong> of age group <strong> 70+ <\/strong> invloved in the survey in which 4 women attained\/wanted to do <strong> Master's degree <\/strong>, 2 women each attained\/wanted to <strong> Bachelor's degree and professional doctorate <\/strong>.\n7. Most of the Women attained\/wanted to do <strong> Bachelor's degree <\/strong> are from age group <strong> 18-21 (763) <\/strong>.\n8. Most of the Women attained\/wanted to do <strong> Doctoral degree <\/strong> are from age group <strong> 35-39 (129) <\/strong>.\n9. Most of the Women who <strong> donot prefer to answer <\/strong> are from age group <strong> 18-21(31) <\/strong>.\n10. Most of the Women attained\/wanted to do <strong> Master's degree <\/strong> are from age group <strong> 25-29 (538) <\/strong>.\n11. Most of the Women who <strong> had no formal education past high school <\/strong> are from age group <strong> 18-21 (15) <\/strong>.\n12. Most of the Women attained\/wanted to do <strong> Professional doctorate <\/strong> are from age group <strong> 30-34 (18) <\/strong>.","6dedc2d2":"#### Answers for questions asked by girls:\n1. Yes, it is possible for women to get job related to data science.Because, we already saw that in 2021 there are 1632 women having jobs related to data science invloved in the survey which is highest till now from 2018. So, getting job related data science is possible with hardwork and commitment since there are good opportunities for women to get jobs. \n2. Yes, it is possible for <strong> Nebula <\/strong> to get Data Analyst job with Bachelor's degree.Because, we already saw that in 2021 there are 171 women having Data Analyst job with Bachelor's degree invloved in the survey which is highest till now from 2018 and it is gradually increasing from 2018. So, in future there will be more opportunities for no only nebula but for women with Bachelor's degree and getting Data Analyst job.\n3. Yes, it is possible for <strong> Wanda <\/strong> to get job related to data science with no coding experience.Because, we already saw that in 2021 there are 102 women having job related to data science with no coding experience invloved in the survey which is highest till now from 2018 and it is gradually increasing from 2018. So, in future there will be more opportunities for no only wanda but for women who have no coding experience and getting job retaled to data science .\n4. It will be a little difficult for <strong> Wanda <\/strong> but not impossible to get job related to data science who knows only R programming language, because from 2018 there is significant decrease of women having job related to data science who knows only R programming language but in 2021 it is increased when compared to 2019,2020 and one more thing is in every year employed women who knows are morethan unemployed women who knows R with huge difference. So, she need to be perfect in R to get job.\n5. It will be difficult for <strong> Pepper Potts <\/strong> but not impossible to get job related to data science in USA, because from 2018 there is significant decrease of women having job related to data science in USA but in 2021 it is increased when compared to 2020.\n6. Yes, it possible for <strong> Gamora <\/strong> to get job related to data science with doctoral degree. In every year there are morethan 150 women invloved in the survey have jobs related to data science with doctoral degree.\n7. Out of 38 women invloved in 2021 survey from Australia 5 are unemployed. Reality is we can't say <strong> Peggy Carter <\/strong>will get job or not by simply this but out of those 24(actually 33 but 9 are students) employed women 20 have jobs related to data science.\n8. Yes, it is possible for women of age above 50 to get job .Because, we already saw that in 2021 there are 219 women having jobs invloved in the survey which is highest till now from 2018. So, getting job is possible with hardwork and commitment since there are good opportunities for women to get jobs. ","846e3580":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women of age group 70+ by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","a36683e7":"### observation:\n\n1. UFFFFFF...!!! Morethan <strong> 79%(20598)<\/strong> people invloved in the survey are <strong> Man <\/strong>. It is very baised because it is like unbalanced data and it will not help the community if the same trend is followed in the long run, next most populated gender is <strong> woman(4890) <\/strong> but they are only <strong> 18.8% <\/strong>.","b947e176":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n\n1. Most of the women with Current Role <strong> DBA\/Database Engineer, Developer Relations\/Advocacy <\/strong> have\/are not used\/using Machine learning Methods.\n2. Most of the women with Current Role <strong> Business Analyst,Currently not employed,Data Analyst,Data Engineer,Data Scientist,Other,Machine Learning Engineer, Product Manager,Program\/Project Manager,Research Scientist, Software Engineer,Statistician,Students <\/strong> have\/are used\/using Machine learning Methods <strong> lessthan 1 year <\/strong>.\n3. Most of the women who has coding experience <strong> 2-20+ years <\/strong> are working as a <strong> Data Scientist <\/strong>.\n4.  Most of the women who has coding experience <strong> 0-2 years <\/strong> are <strong> Students <\/strong>.","fce6b4c3":"<h1 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">How all age groups of woman doing in year 2021<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h1>","6d620226":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women of age group 60-69 by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","4f814437":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n1. In age group <strong> 18-69 <\/strong> most of the women choosed <strong> Laptop <\/strong> as their specialized software used on regular basis.\n2. Only women of age group <strong> 70+ <\/strong> choosed <strong> A personal computer\/ desktop <\/strong> as their specialized software used on regular basis.","ee58ca57":"#### Observation:\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n1. In age group <strong> 18-29 <\/strong> most of the women are <strong> Students(837) <\/strong>, but women in age groups 22-29 are pretty much invloved in jobs.\n2. In age group <strong> 30-44 <\/strong> most of the women are working as <strong> Data Scientist(383) <\/strong>.\n3. In age group <strong> 45-69 <\/strong> most of the women are working in <strong> Other fields(189) <\/strong> which are not mentioned in survey options.\n4. In age group <strong> 70+ <\/strong> most of the women are <strong> Currently not Employed <\/strong>\n5. In age group <strong> 25-29 <\/strong> most of them are students but number is not much domiant like in case of age group 18-21, many women of age group <strong> 25-29 <\/strong> are working in <strong> Data Science related fields <\/strong>.\n\n\nI have some doubts here may be I am wrong but I want to confess, The question is given to choose the option related to your current role many of the women of age group 18-21 have choosed student but I can see one women of this age group choosed Product manager. I think it is not possible because at this age almost all people will do bachelor's degree may be other degree as well but surely all people of age group 18-21 are invloved in study. If we need a job degree is compulsory, how can someone get job without degree??? and that too a job related to product manager which requires experience. May be the one who choosed that she is a product manager is given false information or may be I am wrong but my point is that it is not possible to become a product manager at that age even if she has degree. ","4294074e":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women who have<strong> No formal education past high school <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(2) <\/strong> as yearly compensation.\n2. Most of the women who have<strong> No formal education past high school <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 30,000-39,999 USD(1) <\/strong> as yearly compensation.\n3. Most of the women who have<strong> No formal education past high school <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(2) <\/strong> as yearly compensation.\n4. Here we can see one woman is earning <strong> 150,000-199,999 USD <\/strong>and she use <strong> Python <\/strong> programming language on regular basis.\n5. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> 150,000-199,999 USD <\/strong>\n6. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 30,000-39,999 USD <\/strong>\n7. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 60,000-69,999 USD <\/strong>","9cea760f":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Degree distribution of women by Data Visualization Libraries used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","d1136c2f":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n\n1. Most of the women of all Current Roles didn't spent any money on learning Machine Learning\/ Cloud Computing services in the past 5 years\n2. Most of the women who spent <strong> 1-100,000 or more USD <\/strong> have Current Role <strong> Data Scientist <\/strong>","04717b1b":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women of Current Role as <strong> Developer Relations\/Advocacy <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(3)<\/strong> as yearly compensation.\n2. Most of the women of Current Role as <strong> Developer Relations\/Advocacy <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 250,000-299,999 USD(1) <\/strong> as yearly compensation.\n3. Most of the women of Current Role as <strong> Developer Relations\/Advocacy <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 250,000-299,999 USD(1) <\/strong> as yearly compensation.\n4. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong>250,000-299,999 USD <\/strong>\n5. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 250,000-299,999 USD <\/strong>\n6. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 250,000-299,999 USD <\/strong>","b52c0aa7":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women Product Managers by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","69c432d0":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Kaggle Notebooks,Colab Notebooks and Google Cloud Datalab only these 3 because these are the most choosed option.\n\n\n1. Kaggle Notebooks is most choosed by the women who attained\/want to do <strong> Master's degree(677) <\/strong> and less choosed by the women who attained\/want to do <strong> No formal education past high school(5) <\/strong>.\n2. PyCharm is most choosed by the women who attained\/want to do <strong> Bachelor's degree(663) <\/strong> and less choosed by the women who attained\/want to do <strong> No formal education past high school(8) <\/strong>.\n3. Jupyter Notebook is most choosed by the women who attained\/want to do <strong> Bachelor's degree(133) <\/strong> and less choosed by the women who attained\/want to do <strong> No formal education past high school(3) <\/strong>.","52f1b00b":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women with Online Service\/Internet-based Services contract by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","6655f08f":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n1. In every degree employed women are morethan the unemployed women with good margin.\n2. Women with <strong> Master's Degree(1763) <\/strong> have more employed when compared to women with other degree.\n3. Women with <strong> Master's Degree(187) <\/strong> have more unemployed when compared to women with other degree, but it is not a problem because when compared to 1763 employed women 187 is negligible this also states that employement rate is very high for women.","e4b0b34d":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n\n1. Most of the women of age group <strong> 18-70+ <\/strong> have not spent money to learn Machine Learning\/ Cloud Computing services in the past 5 years.\n2. Most of the women who spend <strong> 0-99,999 USD <\/strong> to learn Machine Learning\/ Cloud Computing services in the past 5 years are of age group <strong> 25-29 <\/strong>.\n3. Most of the women who spend <strong> more than 100,000 USD <\/strong> to learn Machine Learning\/ Cloud Computing services in the past 5 years are of age group <strong> 40-44 <\/strong>.","f377cbf5":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 36 Part A: <strong style=\"color:black;font-size:25px;font-family:Georgia;\"> Do you use any automated machine learning tools (or partial AutoML tools) on a regular basis?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","ada10672":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women with coding experience 3-5 years by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","17f38e8f":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women of age group <strong> 22-24 <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(147) <\/strong> as yearly compensation and less number of women are earning <strong> > 1,000,000 USD(1) <\/strong> as yearly compensation.\n2. Most of the women of age group <strong> 22-24 <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(41) <\/strong> as yearly compensation and less number of women are earning <strong> 100,000-124,999 USD (1), 20,000 - 24,999 USD(1), 300,000-499,999 USD (1),50,000-59,999(1),80,000-89,999(1)<\/strong> as yearly compensation.\n3. Most of the women of age group <strong> 22-24 <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(85) <\/strong> as yearly compensation and less number of women are earning <strong> 60,000-69,999 USD(1), 80,000-89,999 USD (1) <\/strong> as yearly compensation.\\\n4. Here we can see one woman is earning <strong> morethan 1,000,000 USD <\/strong> she uses <strong> python <\/strong> programming language on regular basis.\n5. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> morethan 1,000,000 USD <\/strong>\n6. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 300,000-499,999 USD <\/strong>\n7. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 300,000-499,999 USD <\/strong>\n\n\nIf we compare women of age group <strong> 22-24 <\/strong> on programming language used on regular basis, we can see that women who use python on regular basis are earning morethan women who use R and SQL and we can also see that women who use python are also more than women who use R,SQl.\n\nIf we arrange Python,R and SQL with respect to number of women using the languages on regular basis and how much they are earning, it would look like:<strong> python > SQL> R <\/strong>","118a4924":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Current Role Distribution of women by country<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","73b58aba":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Scikit-learn,TensorFlow,keras,PyTorch and Xgboost only these 5 because these are the most choosed option.\n\n\n1. Scikit-learn is most choosed by the women <strong> Students (643) <\/strong> and less choosed by the women with Current Role <strong>Developer Relations\/Advocacy(4) <\/strong>.\n2. TensorFlow is most choosed by the women <strong> Students (416) <\/strong> and less choosed by the women with Current Role <strong> Developer Relations\/Advocacy(4),DBA\/Database Engineer(4)<\/strong>.\n3. keras is most choosed by the women <strong> Students (363) <\/strong> and less choosed by the women with Current Role <strong> Developer Relations\/Advocacy(3), DBA\/Database Engineer(3) <\/strong>.\n4. PyTorch is most choosed by the women <strong> Students (246) <\/strong> and less choosed by the women with Current Role <strong> DBA\/Database Engineer(2) <\/strong>.\n5. Xgboost is most choosed by the women of Current Role<strong> Data Scientist (643) <\/strong> and less choosed by the women with Current Role <strong>Developer Relations\/Advocacy(2) <\/strong>.","76479710":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Woman in Survey across years<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","ded899c7":"<h1 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Conclusion<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h1>","9aa13d08":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Woman with master degree and working as data scientist in Australia<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","687d6480":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed VSCode,PyCharm and Jupyter Notebook only these 3 because these are the most choosed option.\n\n\n1. VsCode is most choosed by the women <strong> Students (608) <\/strong> and less choosed by the women with Current Role <strong>DBA\/Database Engineer(3) <\/strong>.\n2. PyCharm is most choosed by the women <strong> Students (471) <\/strong> and less choosed by the women with Current Role <strong> Developer Relations\/Advocacy(2) <\/strong>.\n3. Jupyter Notebook is most choosed by the women <strong> Students (1010) <\/strong> and less choosed by the women with Current Role <strong> Developer Relations\/Advocacy(9) <\/strong>.","e5db6cf0":"<h1 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women of all age groups by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h1>","b5b715ed":"<h1 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Analysis of women in 2021 with respect to Current Role<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h1>","0bec55a2":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 2: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">What is your gender? <strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","a884afad":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women of age group 18-21 by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","80576096":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women with Hospitality\/Entertainment\/Sports contract by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","b7b9994f":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women of Professional doctorate by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","a8c210a2":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women with coding experience 20+ years by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","5c225377":"#### Observation:\n1. Many people are using ML methods since less than a year, this means many are new to this subject and interest of people towards this subject is increasing these days(from less than a year)\n2. Only 2% people are using these methods from 10-20 or morethan 20+ years..\n3. Pretty surprisingly 3rd most opted option\/choicee is \"I do not use machine learning methods\". May be they are intrested only in reading the notebooks..!!","464525cd":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Kaggle Notebooks, Colab Notebooks and Google Cloud Datalab only these 3 because these are the most choosed option.\n\n1. Kaggle Notebooks is most choosed by the women of age group <strong> 18-21(415) <\/strong> and less choosed by the women of age group <strong> 70+(1) <\/strong>. \n2. Colab Notebooks is most choosed by the women of age group <strong> 18-21(432) <\/strong> and less choosed by the women of age group <strong> 60-69(10) <\/strong>. Intresting fact is no women of age group <strong> 70+ <\/strong> choosed <strong> Colab Notebooks <\/strong>.\n3. Google Cloud Datalab is most choosed by the women of age group <strong> 18-21(92) <\/strong> and less choosed by the women of age group <strong> 60-69(2) <\/strong>.Intresting fact is no women of age group <strong> 70+ <\/strong> choosed <strong> Google Cloud Datalab <\/strong>.","e981f163":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n1. Not quite suprised here, women from age 18 to 70+ all recommended python programming language for aspiring data scientists","fa5a8e3a":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n1. Most of the women of age group <strong> 18-59 <\/strong>used\/using machine learning methods <strong> lessthan 1 year <\/strong>.\n2. Most of the women of age group <strong> 60-69 <\/strong> have <strong> not used <\/strong>any machine learning methods.\n3. Most of the women of age group <strong> 70+ <\/strong> used\/using machine learning methods in between <strong> 1-2 years<\/strong>.\n4. Most of the women who don't use any machine learning methods or used\/using machine learning methods <strong> lessthan 1 year <\/strong> are of age group <strong> 18-21 <\/strong>.\n5. Most of the women who used\/using machine learning methods in between <strong> 1-2 years <\/strong> are of age group <strong> 22-24 <\/strong>.\n6. Most of the women who used\/using machine learning methods in between <strong> 2-4 years <\/strong> are of age group <strong> 25-29 <\/strong>.\n7. Most of the women who used\/using machine learning methods in between <strong> 4-20 years <\/strong> are of age group <strong> 35-39 <\/strong>.\n8. Most of the women who used\/using machine learning methods from <strong> morethan 20 years <\/strong> are of age group <strong> 50-54 <\/strong>.\n\n\nHere also couple of women given false information, How can women of age groups 22-24 have used\/using Machine learning methods from morethan 20 years??? It is false information because practically from the age of 2 or 3, it is not possible to learn ML methods....!!!!","e59f4a29":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n1. In age group <strong> 18-29 <\/strong> most of the women have coding experience in between <strong> 1-3 years <\/strong>\n2. In age group <strong> 30-39 <\/strong> most of the women have coding experience <strong> lessthan 1 year <\/strong>\n3. In age group <strong> 40-44 <\/strong> most of the women have coding experience in between <strong> 10-20 years <\/strong>\n4. In age group <strong> 45-49 <\/strong> most of the women have coding experience <strong> lessthan 1 year <\/strong>\n5. In age group <strong> 50-69 <\/strong> most of the women have coding experience <strong> morethan than 20 years <\/strong>\n6. In age group <strong> 70+ <\/strong> most of the women have coding experience <strong> morethan than 10 years <\/strong>\n\n\nHere also I have got some questions....\n\nHow can women of age group 18-21 have coding experience morethan 20 years??????? Like if we think they are of age 21, do they start coding when their age is 1???? It is absolutley false data given by them. So how can we prevent people from giving false data?? Just need to disable some options according to their age group so that they cannot select them.\n\nSame in case of woman of age group 22-24 who has coding experience morethan 20 years","74817476":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Age distribution of women by favorite media sources that report on data science topics<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","8162dc7c":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Unemployed Woman Across Years<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","cafb4c6f":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women of Current Role as <strong> Research Scientist <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(51) <\/strong> as yearly compensation.\n2. Most of the women of Current Role as <strong> Research Scientist<\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(11) <\/strong> as yearly compensation.\n3. Most of the women of Current Role as <strong> Research Scientist <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(18) <\/strong> as yearly compensation.\n4. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong>300,000-499,999 USD <\/strong>\n5. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 300,000-499,999 USD <\/strong>\n6. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 150,000-199,999 USD <\/strong>","cdfe466b":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women with coding experience <strong> lessthan 1 year <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(204) <\/strong> as yearly compensation and less number of women are earning <strong> 300,000-499,999 USD(1), 90,000-99,999 USD(1)<\/strong> as yearly compensation.\n2. Most of the women with coding experience <strong> lessthan 1 year <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(45) <\/strong> as yearly compensation and less number of women are earning <strong> 125,000-149,999 USD(1), 150,000-199,999 USD(1), 200,000-249,999 USD(1), 60,000-69,999 USD(1)<\/strong> as yearly compensation.\n3. Most of the womenwith coding experience <strong> lessthan 1 year <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(110) <\/strong> as yearly compensation and less number of women are earning <strong> 125,000-149,999 USD(1), 150,000-199,999 USD(1), 300,000-499,999 USD(1), morethan 1,000,000 USD(1)<\/strong> as yearly compensation.\n4. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> 300,000-499,999 USD <\/strong>\n5. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 250,000-299,999 USD <\/strong>\n6. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> morethan 1,000,000 USD <\/strong>\n","12b2c5d1":"<h2 style=\"color:red;font-size:16px;font-family:Georgia;text-align:center;\"><strong><p>Students started to think so that they may get any question to analyze. Meanwhile, black widow observed there is a huge difference in invlovement of Men and women in the survey, only 19% are women, whereas 80% were man. Some of the questions raised by girl students are:<\/p> <strong style=\"color:black;font-size:13px;font-family:Georgia;\"> <p> 1. Getting a job related to data science is possible for woman??<\/p> <p> 2. Nebula want to become a data Analyst with Bachelor's degree is it possible.??<\/p><p> 3. Wanda has no coding experience will she be able to get a job related to data science.??<\/p><p> 4. Black widow knows only R language will she be able to get a job related to data science?<\/p><p> 5. Pepper potts wants to have a doctoral degree and then want to get a job related to data science is it possible?<\/p><p> 6. Gamora want to do Masters and then get a job related to data science in USA is it possible?<\/p><p> 7. Peggy Carter knows only Python will she be able to get a job as data scientist in Austraila?<\/p><p>8. Does Woman above age 50 able to get a job in data science field?<\/p><p><p> Some additional Analysis they want to do on 2021 survey data:<\/p><p> 1. Employement and unemployement rate of woman<\/p><p> 2. Analysis of all age groups of womem<\/p><p> 3. Analysis of all degree groups of woman<\/p><p> 4. Analysis of women with respect to coding experience <\/p><p> 5. Analysis of women with respect to programming language used on regular basis<\/p><p> 6. Analysis of women with respect to income<\/p><p>7. Analysis of women with respect to Current Role<strong style=\"color:red;font-size:16px;font-family:Georgia;\"> <strong style=\"color:red;font-size:16px;font-family:Georgia;\"> <\/strong><p>Captain America instructed to take previous years survey data and analyze the questions asked by girls. Everyone started their analysis....<\/p><\/strong><\/strong><\/strong><\/h2>","283308e3":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Current Role distribution of women by No. of years Machine Learning Methods used<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","b4114813":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Kaggle vs Colab vs Google Cloud Datalab(hosted notebooks used on Regular Basis) in all Degrees of Women<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","adbc7393":"#### Observation:\n1. Wowwww..!! more than people from 60 different countries are the part of kaggle community, It shows how big is this platform and we can also say this is a data ocean where different rivers(people from different countries) comes inside it. It will also increase the communication of people from different countries.\n\n2. Indians involved most in this survey with <strong> 7434 <\/strong> people and they are very actively giving their contribution to the kaggle community.\n\n3. People from USA are more next to Indians with 2650 in number.\n\n4. In top 5 countries there are 3 countries from asia: <strong> India, china, Japan.<\/strong> This shows asians are contributing more to the kaggle.","dddeef29":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">VSCode vs PyCharm vs Jupyter Notebook(IDE's used on Regular Basis) in all Age Groups of Women<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","a981907c":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n\n1. Most of the women of all Current Roles recommended <strong> Python <\/strong> programming language for aspiring Data Scientists.\n2. Most of the women who recommended <strong> C,C++,Java,Java script,MATLAB,Python,R,SQL,Julia,Bash <\/strong> programming languages for aspiring Data Scientists are <strong> Students <\/strong>.\n3. Most of the women who recommended <strong> Julia <\/strong> programming language for aspiring Data Scientists are of with Current Role<strong> Data Analyst <\/strong>","e6bca307":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women Research Scientists by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","3283a306":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women with Current Employer\/Contract as <strong>Energy\/Mining <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(12) <\/strong> as yearly compensation.\n2. Most of the women with Current Employer\/Contract as <strong> Energy\/Mining <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 30,000-39,999(3) <\/strong> as yearly compensation.\n3. Most of the womenwith Current Employer\/Contract as <strong> Energy\/Mining <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(4) <\/strong> as yearly compensation.\n4. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> 125,000-149,999 USD <\/strong>\n5. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 100,000-124,999 USD <\/strong>\n6. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 100,000-124,999 USD <\/strong>","a23c50dc":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women who attained\/want to do  <strong> Doctoral Degree <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(69) <\/strong> as yearly compensation and less number of women are earning <strong> 500,000-999,999 USD(1)<\/strong> as yearly compensation.\n2. Most of the women who attained\/want to do  <strong> Doctoral Degree <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(20) <\/strong> as yearly compensation and less number of women are earning <strong>125,000-149,999 USD (1),200,000-249,999 USD (1),250,000-299,999 USD(1)<\/strong> as yearly compensation.\n3. Most of the women who attained\/want to do  <strong> Doctoral Degree <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(27) <\/strong> as yearly compensation and less number of women are earning <strong>,250,000-299,999 USD(1),80,000-89,999 USD(1), 15,000-19,999 USD (1)<\/strong> as yearly compensation.\n4. Here we can see one woman is earning <strong> 500,000-999,999 USD <\/strong> and she use <strong> Python <\/strong> programming language on regular basis.\n5. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> 500,000-999,999 USD <\/strong>\n6. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 250,000-299,999 USD <\/strong>\n7. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 250,000-299,999 USD <\/strong>\n\n\nIf we compare women who attained\/want to do  <strong> Doctoral Degree <\/strong> on programming language used on regular basis, we can see that women who use python on regular basis are earning morethan women who use R and SQL and we can also see that women who use python are also more than women who use R,SQl.\n\nIf we arrange Python,R and SQL with respect to number of women using the languages on regular basis and how much they are earning it would look like:<strong> python >SQL> R <\/strong>","d83133de":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women of Current Role as <strong> Data Engineers <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(20) <\/strong> as yearly compensation.\n2. Most of the women of Current Role as <strong> Data Engineers <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(6) <\/strong> as yearly compensation.\n3. Most of the women of Current Role as <strong> Data Engineers <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(18) <\/strong> as yearly compensation.\n4. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong>125,000-149,999\t USD <\/strong>\n5. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 100,000-124,999 USD <\/strong>\n6. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 125,000-149,999 USD <\/strong>","b680df4f":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n1. Most of the women who use <strong> Amazon QuickSight <\/strong> are earning <strong> 0-999 USD (9) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Amazon QuickSight <\/strong> is <strong> 500,000-999,999 USD <\/strong>\n2. Most of the women who use <strong> Microsoft Power BI <\/strong> are earning <strong> 0-999 USD (66) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Microsoft Power BI <\/strong> is <strong> 500,000-999,999 USD <\/strong>\n3. Most of the women who use <strong> Google Data Studio <\/strong> are earning <strong> 0-999 USD (31) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Google Data Studio <\/strong> is <strong> 500,000-999,999 USD <\/strong>\n4. Most of the women who use <strong> Looker <\/strong> are earning <strong> 0-999 USD (3), 100,000-124,999 USD(3), 150,000-199,999 USD (3) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Looker <\/strong> is <strong> 500,000-999,999 USD <\/strong>\n5. Most of the women who use <strong> Tableau <\/strong> are earning <strong> 0-999 USD (81) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Tableau <\/strong> is <strong> morethan 1,000,000 USD <\/strong>\n6. Most of the women who use <strong> Salesforce <\/strong> are earning <strong> 0-999 USD(16) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Salesforce <\/strong> is <strong> morethan 1,000,000 USD <\/strong>\n7. Most of the women who use <strong> Tableau CRM <\/strong> are earning <strong> 0-999 USD (13) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Tableau CRM <\/strong> is <strong> 500,000-999,999 USD <\/strong>\n8. Most of the women who use <strong>Qlik <\/strong> are earning <strong> 0-999 USD (6), 1,000-1,999 USD(6) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Qlik <\/strong> is <strong> 500,000-999,999 USD <\/strong>\n9. Most of the women who use <strong> Domo <\/strong> are earning <strong> 0-999 USD (2) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Domo <\/strong> is <strong> 500,000-999,999 USD <\/strong>\n10. Most of the women who use <strong> TIBCO Spotfire <\/strong> are earning <strong> 0-999 USD (4) <\/strong> as yearly Compensation. Highest salary of women who use <strong> TIBCO Spotfire <\/strong> is <strong> 500,000-999,999 USD <\/strong>\n11. Most of the women who use <strong> Alteryx <\/strong> are earning <strong> 100,000-124,999 USD (5) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Alteryx <\/strong> is <strong> morethan 1,000,000 USD<\/strong>\n12. Most of the women who use <strong> Sisense <\/strong> are earning <strong> 0-999 USD (3) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Sisense <\/strong> is <strong> 500,000-999,999 USD <\/strong>\n13. Most of the women who use <strong> SAP Analytics Cloud <\/strong> are earning <strong> 0-999 USD (7) <\/strong> as yearly Compensation. Highest salary of women who use <strong> SAP Analytics Cloud <\/strong> is <strong> 500,000-999,999 USD <\/strong>\n14. Most of the women who use <strong> Microsoft Azure Synapse <\/strong> are earning <strong> 0-999 USD (9) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Microsoft Azure Synapse <\/strong> is <strong> 500,000-999,999 USD <\/strong>\n15. Most of the women who use <strong> Thoughtspot <\/strong> are earning <strong> 0-999 USD (3) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Thoughtspot <\/strong> is <strong> morethan 1,000,000 USD <\/strong>\n16. Most of the women who <strong>doesnot use business intelligence tools <\/strong> are earning <strong> 0-999 USD (148) <\/strong> as yearly Compensation. Highest salary of women who use <strong> doesnot use Machine Learning Products <\/strong> is <strong> 300,000-499,999 USD <\/strong>\n17. Most of the women who use <strong> Other business intelligence tools <\/strong> are earning <strong> 0-999 USD (10) <\/strong> as yearly Compensation. Highest salary of women who use <strong>Other Machine Learning Products <\/strong> is <strong> 150,000-199,999 USD<\/strong>","f69fa626":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Age distribution of women by public application to share your data analysis or machine learning <strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","0e2be616":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Woman with No coding experience having a job in Data Science Field<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","aaf6eb8f":"> Welcome to Kaggle's annual Machine Learning and Data Science Survey competition!\n\n>The challenge objective: tell a data story about a subset of the data science community represented in this survey, through a combination of both narrative text and data exploration. A \u201cstory\u201d could be defined any number of ways, and that\u2019s deliberate. The challenge is to deeply explore (through data) the impact, priorities, or concerns of a specific group of data science and machine learning practitioners. That group can be defined in the macro (for example: anyone who does most of their coding in Python) or the micro (for example: female data science students studying machine learning in masters programs). This is an opportunity to be creative and tell the story of a community you identify with or are passionate about!","2ffcca38":"#### Observation\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n1. <strong> Indian women <\/strong> are more when compared to all other women across world in attained\/want to do any degree followed by <strong> USA women <\/strong> in second place","3ae8307e":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Age Distribution of women by country<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","ac4abe54":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 6: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">For how many years have you been writing code and\/or programming? <strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","6a3154de":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women who attained\/want to do  <strong> Master's Degree <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(233) <\/strong> as yearly compensation and less number of women are earning <strong> 300,000-499,999 USD(1), morethan 1,000,000 USD(1)<\/strong> as yearly compensation.\n2. Most of the women who attained\/want to do  <strong> Master's Degree <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(73) <\/strong> as yearly compensation and less number of women are earning <strong>250,000-299,999 USD(1)<\/strong> as yearly compensation.\n3. Most of the women who attained\/want to do  <strong> Master's Degree <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(127) <\/strong> as yearly compensation and less number of women are earning <strong>300,000-499,999 USD(1)<\/strong> as yearly compensation.\n4. Here we can see one woman is earning <strong> morethan 1,000,000 USD <\/strong> and she use <strong> Python <\/strong> programming language on regular basis.\n5. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> morethan 1,000,000 USD <\/strong>\n6. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 250,000-299,999 USD <\/strong>\n7. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 300,000-499,999 USD <\/strong>\n\n\nIf we compare women who attained\/want to do  <strong> Master's Degree <\/strong> on programming language used on regular basis, we can see that women who use python on regular basis are earning morethan women who use R and SQL and we can also see that women who use python are also more than women who use R,SQl.\n\nIf we arrange Python,R and SQL with respect to number of women using the languages on regular basis and how much they are earning it would look like:<strong> python >SQL> R <\/strong>","54ade8fa":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women with Online Business\/Internet-based Sales contract by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","2e28fc80":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women with coding experience 1-3 years by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","f99e3d05":"#### Observation:\n\nEmployed women are significantly very high in very year when compared to unemployed women.","079e7993":"#### Observation:\n\n1. In <strong> 2019,2021(5) <\/strong> more Woman with Maters degree and working as a Data Scientist in Australia when compared to years <strong> 2018,2020 <\/strong>.\n2. In <strong> 2018(3) <\/strong>more Woman with Maters degree and working as a Data Scientist in Australia when compared to the years <strong>2020(2)<\/strong>.","40534f92":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Current Roles distribution of women by Specialized Software used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","27099d79":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women Data Analysts by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","7f8538d8":"#### Observation:\n\n1. Many of them suggested to learn python first and yes it was a very good opinion by most of them.\n2. In my opnion python and sql are most important languages to learn first for an aspiring data scientist.\n3. After python R is choosed mostly next and yes it is a powerful language.\n4. Swift is recommended by less number of people","2cc89b04":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Degree distribution of women by Current Employer\/ Contract<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","541e6c4f":"#### Observation:\n\n1. <strong> 30.3% (7874) <\/strong> of people have coding experience <strong> 1-3 years <\/strong> followed by <strong> 22.6% (5881) <\/strong> having coding experience <strong> less than 1 year <\/strong> while there are <strong> 15.6% (4061) <\/strong> of people have coding experience <strong> 3-5 years <\/strong>.\n\n2. There are good number of people who has coding experience <strong> greather than 5 years <\/strong>\n    \n3. OHHHH..!!! There are few people who are never been into coding, It signifies that people who have no experience can also survive in this field.","596a9b71":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed GitHub,Kaggle,Colab,PyTorch and Xgboost only these 4 because these are the most choosed option.\n\n\n1. GitHub is most choosed is most choosed by the women of Current Role<strong> Data Scientist (172) <\/strong> and less choosed by the women with Current Role <strong>DBA\/Database Engineer(2) <\/strong>.\n2. Kaggle is most choosed by the women of Current Role<strong> Data Scientist (91) <\/strong> and less choosed by the women with Current Role <strong>Developer Relations\/Advocacy(2), Product Manager(2) <\/strong>.\n3. Colab is most choosed by the women of Current Role<strong> Data Scientist (61) <\/strong> and less choosed by the women with Current Role <strong>Developer Relations\/Advocacy(1), Product Manager(1) <\/strong>.\n4. I do not share my work publicly is most choosed by the women of Current Role<strong> Data Scientist (94) <\/strong> and less choosed by the women with Current Role <strong>Developer Relations\/Advocacy(1) <\/strong>.","582010a0":"<h6 style=\"color:#fce444;font-size:26px;font-family:Georgia;text-align:center;\"><strong> <strong style=\"color:black;font-size:21px;font-family:Georgia;\">NICK FURY was ok with observation made by the students and he had enough confidence and trust on the students that they will complete the task. So, he left all the students alone in the room, insisted them to proceed on the survey analysis...!!<strong style=\"color:#fce444;font-size:21px;font-family:Georgia;\"> <strong style=\"color:black;font-size:26px;font-family:Georgia;\"> <\/strong><\/strong><\/strong><\/strong><\/h6>","30d76b34":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Woman In Data Science related Jobs<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","a2d22682":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women of Current Role as <strong> Business Analyst <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(21) <\/strong> as yearly compensation.\n2. Most of the women of Current Role as <strong> Business Analyst<\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(5),10,000-14,999 USD(5) <\/strong> as yearly compensation.\n3. Most of the women of Current Role as <strong> Business Analyst <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(17) <\/strong> as yearly compensation.\n4. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong>125,000-149,999 USD <\/strong>\n5. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 125,000-149,999 USD <\/strong>\n6. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 125,000-149,999USD <\/strong>","d14bc407":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women of age group <strong> 60-69 <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(3) <\/strong> as yearly compensation \n2. Most of the women of age group <strong> 60-69 <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(3) <\/strong> as yearly compensation \n3. Most of the women of age group <strong> 60-69 <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(4) <\/strong> as yearly compensation \n4. Here we can see three woman are earning <strong> 250,000-299,999 USD <\/strong> one use <strong> R <\/strong>, one use <strong> Python <\/strong> and another one use <strong> SQL <\/strong> programming language on regular basis.\n5. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> 250,000-299,999 USD <\/strong>\n6. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 250,000-299,999\t USD <\/strong>\n7. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 250,000-299,999 USD <\/strong>","e4779655":"<h6 style=\"color:#fce444;font-size:26px;font-family:Georgia;text-align:center;\"><strong> <strong style=\"color:black;font-size:21px;font-family:Georgia;\">I am the Watcher. I can see all situations and the lives of all people in every universe. Today I will share with you the story of the students who are pursuing their Senior Secondary education in AVENGERS high school in India. The headmaster of the school  NICK FURY, gave a task to his students to analyze Kaggle survey 2021, most of the students are new to all these data analysis, data exploration, etc. So, NICK FURY decided to help them out in this task, he decided to give them a start by explaining all 42 questions asked in the survey <strong style=\"color:#fce444;font-size:21px;font-family:Georgia;\"> <strong style=\"color:black;font-size:26px;font-family:Georgia;\"> <\/strong><\/strong><\/strong><\/strong><\/h6>","f7c35336":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 4: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">What is the highest level of formal education that you have attained or plan to attain within the next 2 years? <strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","d25f0cb3":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Age distribution of women by Machine Learning Frameworks used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","2fb721b7":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women who attained\/want to do  <strong> Bachelor's Degree <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(218) <\/strong> as yearly compensation and less number of women are earning <strong> 250,000-299,999 USD(1), 300,000-499,999 USD(1)   <\/strong> as yearly compensation.\n2. Most of the women who attained\/want to do  <strong> Bachelor's Degree <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(37) <\/strong> as yearly compensation and less number of women are earning <strong>125,000-149,999 USD (1), 200,000-249,999 USD(1),250,000-299,999 USD(1), 300,000-499,999 USD(1)  <\/strong> as yearly compensation.\n3. Most of the women who attained\/want to do  <strong> Bachelor's Degree <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(120) <\/strong> as yearly compensation and less number of women are earning <strong>250,000-299,999 USD(1), 300,000-499,999 USD(1), morethan 1,000,000 USD(1)  <\/strong> as yearly compensation.\n4. Here we can see one woman is earning <strong> morethan 1,000,000 USD <\/strong> and she use <strong> SQL <\/strong> programming language on regular basis.\n5. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> 300,000-499,999 USD <\/strong>\n6. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 300,000-499,999\t USD <\/strong>\n7. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> morethan 1,000,000 USD <\/strong>\n\n\nIf we compare women who attained\/want to do  <strong> Bachelor's Degree <\/strong> on programming language used on regular basis, we can see that women who use python on regular basis are earning morethan women who use R and SQL and we can also see that women who use python are also more than women who use R,SQl.\n\nIf we arrange Python,R and SQL with respect to number of women using the languages on regular basis and how much they are earning it would look like:<strong> python >SQL> R <\/strong>","1645c3fe":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women of age group <strong> 30-34 <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(72) <\/strong> as yearly compensation and less number of women are earning <strong> 250,000 - 299,999 USD(1), 300,000-499,999 USD (1) <\/strong> as yearly compensation.\n2. Most of the women of age group <strong> 30-34 <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(20) <\/strong> as yearly compensation and less number of women are earning <strong> 200,000-249,999 USD (1)<\/strong> as yearly compensation.\n3. Most of the women of age group <strong> 30-34 <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(27) <\/strong> as yearly compensation and less number of women are earning <strong> 250,000 - 299,999 USD(1), 300,000-499,999 USD (1) <\/strong> as yearly compensation.\n4. Here we can see two woman are earning <strong> 300,000-499,999 USD <\/strong> one use <strong> SQL <\/strong> and another one use <strong> Python <\/strong> programming language on regular basis.\n5. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> 300,000-499,999 USD <\/strong>\n6. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 200,000-249,999 USD <\/strong>\n7. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 300,000-499,999 USD <\/strong>\n\n\n\nIf we compare women of age group <strong> 30-34 <\/strong> on programming language used on regular basis, we can see that women who use python on regular basis are earning morethan women who use R and SQL and we can also see that women who use python are also more than women who use R,SQl.\n\nIf we arrange Python,R and SQL with respect to number of women using the languages on regular basis and how much they are earning, it would look like:<strong> python > SQL> R <\/strong>","459af38d":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women of age group 45-49 by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","8993e286":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 34 Part B: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">Which of the following business intelligence tools do you hope to become more familiar with in the next 2 years?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","8101ea6a":"#### Observation:\n\n1. Count of unemployed women in the survey increased gradually from 2018 to 2021. This doesnot mean that unemployed women are increasing every year so it is a negative sign. This is actually a positive sign, I will explain why. This is the data of the survey, most of the people involved in the kaggle survey will also invlove in kaggle competitions, solving datasets, uploading notebooks or learning from others notebooks. The count of unemployed women increasing in the survey shows that people with\/without knowledge are wanted to learn data science and get a job in this field or people with some knowledge in this field are willing to increase their knowledge through kaggle(Since it is the best platform to show case your skills and I feel personally we can learn a lot by seeing others work as well). So, unemployement is not a negative sign here as it helps in improvement in every individual and it also shows the willingness of the people to get the job.\n\n\n\n2. One more thing is only around 50-150 unemployed women are increasing every year but around 500-1000 employed women are increasing every year and my prediction is more unemployed people invloving in the survey but there be also vast increasing in number of employed people invloving in the survey.","5edf874e":"#### Observation\n\n1. In the year <strong> 2021 <\/strong> highest number of <strong> employed women(4427) <\/strong> involved when compared to all other years\n2. In <strong> 2018 <\/strong>there are many <strong> employed women(3829) <\/strong> involved in survey than in year <strong>2019,2020 <\/strong>.\n3. In <strong> 2020 <\/strong> there are many <strong> employed women (3502) <\/strong> invloved in survey than in year <strong> 2019 (2998) <\/strong>.\n4. Since there are many woman invloved in the survey during 2018 when compared 2019 and 2020. It is pretty obvious that the employed women count in 2018 will be greather than employed women count in 2019,2020 and same applies between 2018 and 2021.\n5. There are almost 1000 employed women more invloved in 2021 when compared to 2020.\n6. If we look at last 3 years there is almost a <strong> 1500 employed women were increased between 2018 and 2021<\/strong> and employed women are gradually increasing. So, may be in upcoming years we can see more employed woman invloving in both survey and job industry.","1f0cda55":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women with Computers\/Technology contract by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","c36917eb":"<h1 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women of all current employer\/contract by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h1>","ff0e4b18":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n1. Most of the women who use <strong> MySQL <\/strong> are earning <strong> 0-999 USD (148) <\/strong> as yearly Compensation. Highest salary of women who use <strong> MySQL <\/strong> is <strong> morethan 1,000,000 USD <\/strong>\n2. Most of the women who use <strong> Postgre SQL <\/strong> are earning <strong> 0-999 USD (54) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Postgre SQL <\/strong> is <strong> morethan 1,000,000 USD <\/strong>\n3. Most of the women who use <strong> SQLite <\/strong> are earning <strong> 0-999 USD (53) <\/strong> as yearly Compensation. Highest salary of women who use <strong> SQLite <\/strong> is <strong> morethan 1,000,000 USD <\/strong>\n4. Most of the women who use <strong> Oracle Databases <\/strong> are earning <strong> 0-999 USD (44) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Oracle Databases <\/strong> is <strong> morethan 1,000,000 USD <\/strong>\n5. Most of the women who use <strong> MongoDB <\/strong> are earning <strong> 0-999 USD (49) <\/strong> as yearly Compensation. Highest salary of women who use <strong> MongoDB <\/strong> is <strong> morethan 1,000,000 USD <\/strong>\n6. Most of the women who use <strong> Snowflake <\/strong> are earning <strong> 150,000-199,999 USD(8) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Snowflake <\/strong> is <strong> morethan 1,000,000 USD <\/strong>\n7. Most of the women who use <strong> IBMdb2 <\/strong> are earning <strong> 0-999 USD (12) <\/strong> as yearly Compensation. Highest salary of women who use <strong> IBMdb2 <\/strong> is <strong> morethan 1,000,000 USD <\/strong>\n8. Most of the women who use <strong> Microsoft SQL Server <\/strong> are earning <strong> 0-999 USD (55) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Microsoft SQL Server <\/strong> is <strong> morethan 1,000,000 USD <\/strong>\n9. Most of the women who use <strong> Microsoft Azure SQL Database <\/strong> are earning <strong> 0-999 USD (19) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Microsoft Azure SQL Database <\/strong> is <strong> 500,000-999,999 USD <\/strong>\n10. Most of the women who use <strong> Microsoft Azure Cosmos DB <\/strong> are earning <strong> 0-999 USD (11) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Microsoft Azure Cosmos DB <\/strong> is <strong> morethan 1,000,000 USD <\/strong>\n11. Most of the women who use <strong> Amazon Redshift <\/strong> are earning <strong> 0-999 USD (11) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Amazon Redshift <\/strong> is <strong> 500,000-999,999 USD <\/strong>\n12. Most of the women who use <strong> Amazon Aurora <\/strong> are earning <strong> 0-999 USD (6) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Amazon Aurora <\/strong> is <strong> morethan 1,000,000 USD <\/strong>\n13. Most of the women who use <strong> Amazon RDS <\/strong> are earning <strong> 0-999 USD (14) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Amazon RDS <\/strong> is <strong> 500,000-999,999 USD <\/strong>\n14. Most of the women who use <strong> Amazon DynamoDB <\/strong> are earning <strong> 0-999 USD (11) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Amazon DynamoDB <\/strong> is <strong> 500,000-999,999 USD <\/strong>\n15. Most of the women who use <strong> Google Cloud BigQuery <\/strong> are earning <strong> 0-999 USD (20) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Google Cloud BigQuery <\/strong> is <strong> 500,000-999,999 USD <\/strong>\n16. Most of the women who use <strong> Google Cloud SQL <\/strong> are earning <strong> 0-999 USD (22) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Google Cloud SQL <\/strong> is <strong> morethan 1,000,000 USD <\/strong>\n17. Most of the women who use <strong> Google Cloud Firestore <\/strong> are earning <strong> 0-999 USD (13) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Google Cloud FireStore <\/strong> is <strong> morethan 1,000,000 USD <\/strong>\n18. Most of the women who use <strong> Google Cloud BigTable <\/strong> are earning <strong> 0-999 USD (12) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Google Cloud BigTable <\/strong> is <strong> 500,000-999,999 USD <\/strong>\n19. Most of the women who use <strong> Google Cloud Spanner <\/strong> are earning <strong> 0-999 USD (7) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Google Cloud Spanner <\/strong> is <strong> 500,000-999,999 USD <\/strong>\n20. Most of the women who <strong>doesnot use Big Data Products <\/strong> are earning <strong> 0-999 USD (77) <\/strong> as yearly Compensation. Highest salary of women who use <strong> doesnot use Machine Learning Products <\/strong> is <strong> 300,000-499,999 USD <\/strong>\n21. Most of the women who use <strong> Other Big Data Products<\/strong> are earning <strong> 0-999 USD (10) <\/strong> as yearly Compensation. Highest salary of women who use <strong>Other Machine Learning Products <\/strong> is <strong> 150,000-199,999 USD<\/strong>","66246da3":"#### Observation:\n\n1. 25% of the people are from computers\/Technology contract\n2. 19.7% of people are from Academics\/Education, so all the students comes into this category\n3. 9% of people are from Accounting\/Finance\n4. Very less number of people are from Hospitality\/Entertainment\/Sports, Military\/Security\/Defense only 1%","d1b4a4b0":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women of Current Role as <strong> Data Scientist <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(149) <\/strong> as yearly compensation and less number of women are earning <strong> 250,000-299,999 USD(1),300,000-499,999 USD(1)<\/strong> as yearly compensation.\n2. Most of the women of Current Role as <strong> Data Scientist <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(42) <\/strong> as yearly compensation and less number of women are earning <strong>125,000-149,999 USD (2),50,000-59,999 USD(2)<\/strong> as yearly compensation.\n3. Most of the women of Current Role as <strong> Data Scientist <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(71) <\/strong> as yearly compensation and less number of women are earning <strong>250,000-299,999 USD(1),300,000-499,999 USD(1)<\/strong> as yearly compensation.\n4. Here we can see two woman are earning <strong> 300,000-499,999 USD <\/strong>,one of them use <strong> Python <\/strong> and another uses <strong> SQL <\/strong> programming language on regular basis.\n5. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> 300,000-499,999 USD <\/strong>\n6. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 150,000-199,999 USD <\/strong>\n7. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 300,000-499,999 USD <\/strong>\n\n\nIf we compare women of Current Role as <strong> Data Scientist <\/strong> on programming language used on regular basis, we can see that women who use python on regular basis are earning morethan women who use R and SQL and we can also see that women who use python are also more than women who use R,SQl.\n\nIf we arrange Python,R and SQL with respect to number of women using the languages on regular basis and how much they are earning it would look like:<strong> python >SQL> R <\/strong>","9476b0ba":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women Program\/Project Manager by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","09c79333":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Degree distribution of women by public application to share your data analysis or machine learning <strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","2581d31a":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women with coding experience <strong> 3-5 years <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(93) <\/strong> as yearly compensation and less number of women are earning <strong> 200,000-249,999 USD(1), morethan 1,000,000 USD(1)<\/strong> as yearly compensation.\n2. Most of the women with coding experience <strong> 3-5 years <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(27) <\/strong> as yearly compensation and less number of women are earning <strong> 250,000-299,999 USD(1)<\/strong> as yearly compensation.\n3. Most of the womenwith coding experience <strong> 3-5 years <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(51) <\/strong> as yearly compensation and less number of women are earning <strong> 200,000-249,999 USD(1)<\/strong> as yearly compensation.\n4. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> morethan 1,000,000 USD <\/strong>\n5. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 250,000-299,999 USD <\/strong>\n6. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 200,000-249,999 USD <\/strong>","4afed1e8":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Degree distribution of women by No. of years Machine Learning Methods used<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","140f3a29":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Woman in Jobs related to Data Science vs Other Fields<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","fc057f50":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n1. Most of the women who use <strong> Automated data augmentation (e.g. imgaug, albumentations) <\/strong> are earning <strong> 0-999 USD (38) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Automated data augmentation (e.g. imgaug, albumentations) <\/strong> is <strong> 500,000-999,999 USD <\/strong>\n2. Most of the women who use <strong> Automated feature engineering\/selection (e.g. tpot, boruta_py) <\/strong> are earning <strong> 0-999 USD (22) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Automated feature engineering\/selection (e.g. tpot, boruta_py) <\/strong> is <strong> 500,000-999,999 USD <\/strong>\n3. Most of the women who use <strong> Automated model selection (e.g. auto-sklearn, xcessiv) <\/strong> are earning <strong> 0-999 USD (38) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Automated model selection (e.g. auto-sklearn, xcessiv) <\/strong> is <strong> 500,000-999,999 USD <\/strong>\n4. Most of the women who use <strong> Automated model architecture searches (e.g. darts, enas) <\/strong> are earning <strong> 0-999 USD (11) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Automated model architecture searches (e.g. darts, enas) <\/strong> is <strong> 500,000-999,999 USD <\/strong>\n5. Most of the women who use <strong> Automated hyperparameter tuning (e.g. hyperopt, ray.tune, Vizier) <\/strong> are earning <strong> 0-999 USD (17) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Automated hyperparameter tuning (e.g. hyperopt, ray.tune, Vizier) <\/strong> is <strong> 500,000-999,999 USD<\/strong>\n6. Most of the women who use <strong> Automation of full ML pipelines (e.g. Google AutoML, H2O Driverless AI) <\/strong> are earning <strong> 0-999 USD(24) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Automation of full ML pipelines (e.g. Google AutoML, H2O Driverless AI) <\/strong> is <strong> morethan 1,000,000 USD <\/strong>\n7. Most of the women who <strong>doesnot use automated machine learning tools (or partial AutoML tools) <\/strong> are earning <strong> 0-999 USD (213) <\/strong> as yearly Compensation. Highest salary of women who use <strong> doesnot use Machine Learning Products <\/strong> is <strong> 500,000-999,999 USD <\/strong>\n8. Most of the women who use <strong> Other automated machine learning tools (or partial AutoML tools) <\/strong> are earning <strong> 0-999 USD (10) <\/strong> as yearly Compensation. Highest salary of women who use <strong>Other Machine Learning Products <\/strong> is <strong> 250,000-299,999 USD<\/strong>","e02ba710":"#### Observation:\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n1. Most of the women of all degrees doesnot spend any money for learning Machine Learning\/ Cloud Computing services in the past 5 years\n2. Most of women who spend <strong> 0-100,000 or more USD<\/strong> or learning Machine Learning\/ Cloud Computing services in the past 5 years have attained\/want to do <strong> Master's Degree <\/strong>","09f4fea2":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women with Current Employer\/Contract as <strong> Online Service\/Internet-based Services <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(16) <\/strong> as yearly compensation.\n2. Most of the women with Current Employer\/Contract as <strong> Online Service\/Internet-based Services <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(7) <\/strong> as yearly compensation.\n3. Most of the womenwith Current Employer\/Contract as <strong> Online Service\/Internet-based Services <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(8) <\/strong> as yearly compensation.\n4. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> 250,000-299,999 USD <\/strong>\n5. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 90,000-99,999 USD <\/strong>\n6. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 250,000-299,999 USD <\/strong>","b61004cf":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Age distribution of women by Current Job<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","60796ad6":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Degree distribution of women by favorite media sources that report on data science topics<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","5411d0c3":"#### Observation:\n1. We can see that many have never used TPU till now, It seems that many of them not aware of this and dont know what a TPU does..\n2. There are only 612 people out of 23k people who have used TPU morethan 25 times","727b2aaf":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">VSCode vs PyCharm vs Jupyter Notebook(IDE's used on Regular Basis) in all Current Roles of Women<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","2cbbb859":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 33: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you hope to become more familiar with in the next 2 years?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","908f2288":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women with Shipping\/Transportation contract by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","2b196d0e":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 26: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">  Approximately how much money have you (or your team) spent on machine learning and\/or cloud computing services at home (or at work) in the past 5 years (approximate USD)..?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","2c87a920":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 27 Part B: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">Which of the following cloud computing platforms do you hope to become more familiar with in the next 2 years?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","0dd36398":"#### Observation:\n1. Good thing here is there is vast increase of number of women invloved in survey over the years. If this trend follows then, in upcoming years Man and Woman count in survey will be equal..!!!","4ec99425":"#### Observation:\n\n1. In <strong> 2018(672) <\/strong> more women knows only R and working having job related to data science when compared to years <strong> 2019,2020 and 2021 <\/strong>.\n2. In <strong> 2021(495) <\/strong>more women knows only R and working having job related to data science when compared to the years <strong>2019,2020 <\/strong>.\n3. In <strong> 2019(420) <\/strong> more women knows only R and working having job related to data science when compared to <strong>2020 (395)<\/strong>.\n\n\nThere is a significant decrease of women knows only R and working having job related to data science from 2018 to 2020 and increased in the 2021 but still lessthan 2018.","9f18e33c":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women of Current Role as <strong> Program\/Project Manager <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(8) <\/strong> as yearly compensation.\n2. Most of the women of Current Role as <strong> Program\/Project Manager<\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 100,000-124,999 USD(3) <\/strong> as yearly compensation.\n3. Most of the women of Current Role as <strong> Program\/Project Manager <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(5) <\/strong> as yearly compensation.\n4. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong>200,000-249,999 USD <\/strong>\n5. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 150,000-199,999 USD <\/strong>\n6. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 200,000-249,999 USD <\/strong>","18dc3ec8":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women of Current Role as <strong> Software Engineer <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(80) <\/strong> as yearly compensation and less number of women are earning <strong> 300,000-499,999 USD(1), morethan 1,000,000 USD(1)<\/strong> as yearly compensation.\n2. Most of the women of Current Role as <strong> Software Engineer<\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(5) <\/strong> as yearly compensation.\n3. Most of the women of Current Role as <strong> Software Engineer <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(53) <\/strong> as yearly compensation and less number of women are earning <strong>80,000-89,999 USD(1),90,000-99,999 USD(1),300,000-499,999 USD(1)<\/strong> as yearly compensation.\n4. Here we can see one woman is earning <strong> morethan 1,000,000 USD <\/strong>and she use <strong> Python <\/strong> programming language on regular basis.\n5. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> morethan 1,000,000 USD <\/strong>\n6. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 200,000-249,999 USD <\/strong>\n7. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 300,000-499,999 USD <\/strong>\n\n\nIf we compare women of Current Role as  <strong> Software Engineer <\/strong> on programming language used on regular basis, we can see that women who use python on regular basis are earning morethan women who use R and SQL and we can also see that women who use python are also more than women who use R,SQl.\n\nIf we arrange Python,R and SQL with respect to number of women using the languages on regular basis and how much they are earning it would look like:<strong> python >SQL> R <\/strong>","e64d49ba":"<h1 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women with coding experience by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h1>","16ed35f6":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Degree distribution of women by Programming Language recommended for aspiring Data Scientist<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","5eb15eab":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women of Current Role as <strong> DBA\/Database Engineer <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(4)<\/strong> as yearly compensation.\n2. Only one of Current Role as <strong> DBA\/Database Engineer <\/strong> who use <strong> R <\/strong> Programming Language on regular basis and earning <strong> 3,000-3,999 USD <\/strong> as yearly compensation.\n3. Most of the women of Current Role as <strong> DBA\/Database Engineer <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(4) <\/strong> as yearly compensation.\n4. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong>150,000-199,999 USD <\/strong>\n5. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 150,000-199,999 USD <\/strong>","82941742":"#### Observation:\n\n1. In <strong> 2021(171) <\/strong> more women are with Bachelor's degree working as a Data Analyst when compared to years <strong> 2018,2019 and 2020 <\/strong>.\n2. In <strong> 2018(124) <\/strong>more women are with Bachelor's degree working as a Data Analyst when compared to the years <strong>2019,2020 <\/strong>.\n3. In <strong> 2020(110) <\/strong> more women are with Bachelor's degree working as a Data Analyst when compared to <strong>2019 (104)<\/strong>.\n\n\nThere is a significant increase of women working as a Data Analyst from 2018 to 2021. It will be a good choice if women with bachelor's degree choose their career as data analyst.","37e70555":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Current Roles distribution of women by Machine Learning Algorithms used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","813d89d4":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed  Kaggle (notebooks, forums, etc), YouTube (Kaggle YouTube, Cloud AI Adventures, etc), Blogs (Towards Data Science, Analytics Vidhya, etc) only these 3 because these are the most choosed option.\n\n\n1. Kaggle (notebooks, forums, etc) is most choosed by the women of age group <strong> 25-29(405) <\/strong> and less choosed by the women of age group <strong> 70+(6) <\/strong>. \n2. YouTube (Kaggle YouTube, Cloud AI Adventures, etc) is most choosed by the women of age group <strong> 18-21(369) <\/strong> and less choosed by the women of age group <strong> 70+ (4) <\/strong>.\n3. Blogs (Towards Data Science, Analytics Vidhya, etc) is most choosed by the women of age group <strong> 25-29(315) <\/strong> and less choosed by the women of age group  <strong> 70+(4) <\/strong>.","9fcc0013":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 31 Part B: <strong style=\"color:black;font-size:25px;font-family:Georgia;\"> In the next 2 years, do you hope to become more familiar with any of these managed machine learning products?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","75ec3861":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Age distribution of women by Specialized Software used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","c3a9e02e":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Current Roles distribution of women by Current Yearly Compensation <strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","7fbace7e":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Woman above age 50 employement vs unemployement<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","3a1d6533":"#### Observation:\n\n1. 22.6% of people are working in a company where 1-2 people are responsible for data science workloads which is highest\n2. 22.3% of people are working in a company where 20+ people are responsible for data science workloads\n3. 2.61% of people are working in a company where 15-19 people are responsible for data science workloads which is lowest\n4. 19% of people are working in a company where no employee is responsible for data science workload this is intresting as many companies are not using data science\n5. Another Interesting fact is, If we observe top 2 percentages of employees having data science workloads we can see that either the company has only 1 or 2 employees responsible for data science workload oe they are having morethan 20+ employees responsible for data science workload","4f9ab4bf":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n1. Most of the women who use <strong> Amazon Elastic Compute Cloud (EC2) <\/strong> are earning <strong> 0-999 USD (31) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Amazon Elastic Compute Cloud (EC2) <\/strong> is <strong> morethan 1,000,000 USD <\/strong>\n2. Most of the women who use <strong> Microsoft Azure Virtual Machines <\/strong> are earning <strong> 0-999 USD (45) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Microsoft Azure Virtual Machines <\/strong> is <strong> morethan 1,000,000 USD <\/strong>\n3. Most of the women who use <strong> Google Cloud Compute Engine <\/strong> are earning <strong> 0-999 USD (63) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Google Cloud Compute Engine <\/strong> is <strong> morethan 1,000,000 USD <\/strong>\n4. Most of the women who <strong>doesnot use Cloud Products <\/strong> are earning <strong> 0-999 USD (69) <\/strong> as yearly Compensation. Highest salary of women who use <strong> doesnot use Cloud Products <\/strong> is <strong> 250,000-299,999 USD <\/strong>\n5. Most of the women who use <strong> Other Cloud Products<\/strong> are earning <strong> 150,000-199,999 USD (3) <\/strong> as yearly Compensation. Highest salary of women who use <strong>Other Cloud Products <\/strong> is <strong> 150,000-199,999 USD<\/strong>","1c30c631":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 14: <strong style=\"color:black;font-size:25px;font-family:Georgia;\"> What data visualization libraries or tools do you use on a regular basis?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","f6c10af9":"<h1 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women of all Current Roles by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h1>","3f20ffec":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 1: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">What is your age (# years)? <strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","c68f7aed":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 38 Part A: <strong style=\"color:black;font-size:25px;font-family:Georgia;\"> Do you use any tools to help manage machine learning experiments?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","fc25b400":"<h3 style=\"color:red;font-size:13px;font-family:Georgia;text-align:center;\"><strong> Final Observation of the students after NICK FURY completed explaining them all the 42 questions in the survey is(Top 2 options picked from all the questions):<strong style=\"color:black;font-size:13px;font-family:Georgia;\"><p>1. What is your age?: 25-29(4931), 18-21(4901)<\/p><p> 2. What is your gender?: Man(20598), Woman (4890)<\/p><p> 3. In which country do you currently reside?: India(7434), USA(2650)<\/p><p> 4. What is the highest level of formal education that you have attained or plan to attain within the next 2 years?: Master's degree(10132), Bachelor's degree(9907)<\/p><p> 5. Select the title most similar to your current role (or most recent title if retired)?: Student(6804), Data Scientist(3616)<\/p><p> 6. For how many years have you been writing code and\/or programming?: 1-3 years (7874), lessthan 1 year (5881)<\/p><p> 7.What programming languages do you use on a regular basis?: Python(21860), SQL(10756)<\/p><p> 8. What programming language would you recommend an aspiring data scientist to learn first?:Python (20213), R (1445), SQL (1338)<\/p><p> 9. Which of the following integrated development environments (IDE's) do you use on a regular basis?: Jupyter Notebook (16233), VS Code (10040)<\/p><p> 10. Which of the following hosted notebook products do you use on a regular basis?: Colab Notebooks (9792), Kaggle Notebooks (9507),None(7174)<\/p><p> 11. What type of computing platform do you use most often for your data science projects?: A laptop (16231), A personal Computer\/Desktop (4916)<\/p><p> 12. Which types of specialized hardware do you use on a regular basis?: None(13234), NIVIDIA GPUs (8036)<\/p><p> 13. Approximately how many times have you used a TPU (tensor processing unit)?: Never (16457), 2-5 times (3405)<\/p><p> 14.What data visualization libraries or tools do you use on a regular basis?: Matplotlib (17595), Seaborn (12586)<\/p><p> 15. For how many years have you used machine learning methods?: Under 1 year (9163), 1-2 years (4675)<\/p><p> 16. Which of the following machine learning frameworks do you use on a regular basis?: Scikit-learn (13987), Tensor-Flow (9371)<\/p><p> 17. Which of the following ML algorithms do you use on a regular basis?: Linear or Logistic Regression (13852), Decision Trees or Random Forests (11863)<\/p><p> 18. Which categories of computer vision methods do you use on a regular basis?: Image classification and other general purpose networks (VGG, Inception, ResNet, ResNeXt, NASNet, EfficientNet, etc)(4373), Image segmentation methods (U-Net, Mask R-CNN, etc) (2740)<\/p><p> 19. Which of the following natural language processing (NLP) methods do you use on a regular basis?:\n    Word embeddings\/vectors (GLoVe, fastText, word2vec) (2643), Transformer language models (GPT-3, BERT, XLnet, etc) (2351)<\/p><p> 20. In what industry is your current employer\/contract (or your most recent employer if retired)?: Computers\/ Technology (4079), Acadeemics\/Education (3214)<\/p><p> 21. What is the size of the company where you are employed?: 0-49 employees (5055), 10,000 or more employees (3416)<\/p><p> 22. Approximately how many individuals are responsible for data science workloads at your place of business?: 1-2 (3642), 20+ (3595)<\/p><p> 23. Does your current employer incorporate machine learning methods into their business?: We are exploring ML methods (and may one day put a model into production) (3390), No (we do not use ML methods)(3263)<\/p><p> 24. Select any activities that make up an important part of your role at work?: Analyze and understand data to influence product or business decisions(9108) , Build prototypes to explore applying machine learning to new areas (5150)<\/p><p> 25. What is your current yearly compensation (approximate USD)?: 0-999 USD (3369), 1,000-1999 USD (969)<\/p><p> 26. Approximately how much money have you (or your team) spent on machine learning and\/or cloud computing services at home (or at work) in the past 5 years (approximate USD)..?: 0 USD (5903), 100-999 (2534)<\/p><p> 27 Part A. Which of the following cloud computing platforms do you use on a regular basis?: Amazon Web Services(AWS) (3721), Google Cloud Platform (GCP) (3142)<\/p><p> 27 Part B. Which of the following cloud computing platforms do you hope to become more familiar with in the next 2 years?: Amazon Web Services(AWS) (7494), Google Cloud Platform (GCP) (7484)<\/p><p> 28. Of the cloud platforms that you are familiar with, which has the best developer experience (most enjoyable to use)?: Amazon Web Services(AWS) (836), Google Cloud Platform (GCP) (738)<\/p><p> 29 Part A. Do you use any of the following cloud computing products on a regular basis?: Amazon Elastic Compute Cloud (EC2)(2270), Google Cloud Compute Engine (1960)<\/p><p> 29 Part B. In the next 2 years, do you hope to become more familiar with any of these specific cloud computing products?: Google Cloud Compute Engine(7497), Microsoft Azure Virtual Machines(5973)<\/p><p> 30 Part A. Do you use any of the following data storage products on a regular basis?: Amazon Simple Storage Service (S3)(2308), Google Cloud Storage (GCS) (1950)<\/p><p> 31 Part A. In the next 2 years, do you hope to become more familiar with any of these specific data storage products?: No\/None (6381), Amazon SageMaker (991)<\/p><p> 31 Part B: In the next 2 years, do you hope to become more familiar with any of these managed machine learning products?: Google Cloud Vetex AI (5304), Azure Machine Learning Studio (5029)<\/p><p> 32 Part A. Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you use on a regular basis?: My Sql (3576), None (2297)<\/p><p> 32 Part B. Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you hope to become more familiar with in the next 2 years?: MySql (6135), MongoDB (4288)<\/p><p> 33. Which of the following big data products (relational database, data warehouse, data lake, or similar) do you use most often?: MySql (1110), Postgre SQL (694)<\/p><p> 34 Part A. Which of the following business intelligence tools do you use on a regular basis?: None (4123), Tableau (2464) <\/p><p> 34 Part B. Which of the following business intelligence tools do you hope to become more familiar with in the next 2 years?: Tableau (5421), Microsoft PowerBI (4923)<\/p><p> 35. Which of the following business intelligence tools do you use most often?: Microsoft PowerBi (790), Tableau (740)<\/p><p> 36 Part A. Do you use any automated machine learning tools (or partial AutoML tools) on a regular basis?: No\/None 6338, Automated model selection (e.g. auto-sklearn, xcessiv) (1186)<\/p><p> 36 Part B. Which categories of automated machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years?: Automated model selection (e.g. auto-sklearn, xcessiv) (4761), Automation of full ML pipelines (e.g. Google Cloud AutoML, H2O Driverless AI) (4752) <\/p><p> 37 Part A. Which of the following automated machine learning tools (or partial AutoML tools) do you use on a regular basis?: No\/None (1196), Google Cloud AutoML (751)<\/p><p> 37 Part B. Which specific automated machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years?: Google Cloud AutoML (4817), Azure Automated Machine Learning (3152) <\/p><p> 38 Part A. Do you use any tools to help manage machine learning experiments?: No\/None (6239), TensorBoard (1726) <\/p><p> 38 Part B: In the next 2 years, do you hope to become more familiar with any of these tools for managing ML experiments?: None (4542), TensorBoard (4249) <\/p> <p> 39. Where do you publicly share your data analysis or machine learning applications?: GitHub (4586), I do not share my work publicly (3167) <\/p> <p> 40. On which platforms have you begun or completed data science courses?: Coursera (9649), Kaggle Learn Courses (8670)<\/p><p> 41. What is the primary tool that you use at work or school to analyze data?: Basic statistical software (Microsoft Excel, Google Sheets, etc.) (7246), Local development environments (RStudio, JupyterLab, etc.) (7170)<\/p><p> 42. Who\/what are your favorite media sources that report on data science topics?: Kaggle (notebooks, forums, etc)(11373), YouTube (Kaggle YouTube, Cloud AI Adventures, etc) (10401)<\/p>  <strong style=\"color:#fce444;font-size:13px;font-family:Georgia;\"> <strong style=\"color:black;font-size:26px;font-family:Georgia;\"> <\/strong><\/strong><\/strong><\/strong><\/h3>","395b9c9f":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Current Roles distribution of women by Current Employer\/ Contract<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","5fc32895":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women with Current Employer\/Contract as <strong>Online Business\/Internet-based Sales <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(14) <\/strong> as yearly compensation.\n2. Most of the women with Current Employer\/Contract as <strong> Online Business\/Internet-based Sales <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(2), 30,000-39,999 USD(2) <\/strong> as yearly compensation.\n3. Most of the womenwith Current Employer\/Contract as <strong> Online Business\/Internet-based Sales <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD (10) <\/strong> as yearly compensation.\n4. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> 125,000-149,999 USD <\/strong>\n5. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 125,000-149,999 USD <\/strong>\n6. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 100,000-124,999 USD <\/strong>","7bba0a77":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Matplotlib,Seaborn,Plotly\/Plotly Express and Ggplot\/ggplot2 only these 4 because these are the most choosed option.\n\n\n1. Matplotlib is most choosed by the women <strong> Students (953) <\/strong> and less choosed by the women with Current Role <strong>Developer Relations\/Advocacy(6) <\/strong>.\n2. Seaborn is most choosed by the women <strong> Students (620) <\/strong> and less choosed by the women with Current Role <strong> Developer Relations\/Advocacy(4)<\/strong>.\n3. Plotly\/Plotly Express is most choosed by the women <strong> Students (246) <\/strong> and less choosed by the women with Current Role <strong> Developer Relations\/Advocacy(3), DBA\/Database Engineer(3) <\/strong>.\n4. Ggplot\/ggplot2 is most choosed by the women <strong> Students (280) <\/strong> and less choosed by the women with Current Role <strong> DBA\/Database Engineer(3) <\/strong>.","772c2c36":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 29 Part A: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">Do you use any of the following cloud computing products on a regular basis?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","6f0c70f7":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women with coding experience 10-20 years by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","0f9082b6":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Current Role Distribution of women by Age<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","ecc8cb88":"<img src=\"https:\/\/static01.nyt.com\/images\/2019\/05\/05\/arts\/05avengers-writers7\/merlin_153837675_4394eb10-a2eb-43c4-9734-c8aefa79901e-articleLarge.jpg\" width=\"800px\">","bd59ceeb":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women of age group 22-24 by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","f883659e":"#### Observation:\n\n1. It is pretty known that people will use python more and followed by SQL(since we can do queries with sql which is very important..!!!)\n2. C++ and R is also used by many people\n3. R can explain statistics of the data deeper than python...!!\n4. Swift is used by less people..!!\n5. I'm pretty confused that some people not using any language may be they have a habit of reading the notebooks and learn..!!!","caa3a3cd":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 17: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">Which of the following machine learning Algorithms do you use on a regular basis?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","933b093b":"#### Observation:\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n\n1. Most of the women who attained\/wanted to do <strong>  Bachelor's degree, Prefer not to answer, Master's degree,No formal education past high school, some college\/university study without earning a bachelor's degree <\/strong> are <strong> Students <\/strong>.\n2. Most of the women who attained\/wanted to do <strong>  Doctoral degree, Professional doctorate <\/strong> are <strong> Research Scientist <\/strong>.\n3. Most of the women with current job as <strong> Business Analyst,Currently not employed,DBA\/Database Engineer,Data Analyst, Data Engineer,Data Scientist,Developer Relations\/Advocacy, Machine Learning Engineer,Other,Product Manager,Program\/Project Manager <\/strong> have attained <strong> Master's Degree <\/strong>.\n4. Most of the women with current job as <strong> Software Engineer <\/strong> have attained <strong> Bachelor's Degree <\/strong>\n5. Most of the <strong> Student <\/strong> women attained\/want to do <strong> Bachelor's Degree <\/strong>\n6. Most of the women with current job as <strong> Research Scientist <\/strong> have attained <strong> Doctoral Degree <\/strong>","a7ddf7d9":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women Developer Relations\/Advocacy by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","d93218b9":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women with coding experience <strong> 10-20 years <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(27) <\/strong> as yearly compensation and less number of women are earning <strong> 500,000-999,999 USD(1)<\/strong> as yearly compensation.\n2. Most of the women with coding experience <strong> 10-20 years <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 150,000-199,999 USD(9) <\/strong> as yearly compensation and less number of women are earning <strong> 250,000-299,999 USD(1),25,000-29,999 USD(1),200,000-249,999 USD(1),4,000-4,999 USD(1)<\/strong> as yearly compensation.\n3. Most of the womenwith coding experience <strong> 10-20 years <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(25) <\/strong> as yearly compensation and less number of women are earning <strong> 300,000-499,999 USD(1)<\/strong> as yearly compensation.\n4. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> 500,000-999,999 USD <\/strong>\n5. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 300,000-499,999 USD<\/strong>\n6. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 300,000-499,999 USD <\/strong>","5f9877e6":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 37 Part A: <strong style=\"color:black;font-size:25px;font-family:Georgia;\"> Which of the following automated machine learning tools (or partial AutoML tools) do you use on a regular basis?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","ce9adad3":"#### Observation:\n1. OHHH..!!!! we can see that many people are not using any specialized hardwares, as above we saw that many people are having a laptop and many laptops wont have any GPUs.\n2. NIVIDIA GPUs is used most among all GPUs.\n3. Out Of all Hardwares mentioned above,AWS Trainium Chips and AWS Inferentia Chips are used by less people","4dc7ebe1":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women with Insurance\/Risk Assessment contract by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","d4e305eb":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women of Current Role as <strong> Data Analyst <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(109) <\/strong> as yearly compensation and less number of women are earning <strong> 200,000-249,999 USD(1)<\/strong> as yearly compensation.\n2. Most of the women of Current Role as <strong> Data Analyst<\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(47) <\/strong> as yearly compensation and less number of women are earning <strong> 250,000-299,999 USD(1), 300,000-499,999 USD(1), 500,000-999,999 USD(1)<\/strong> as yearly compensation.\n3. Most of the women of Current Role as <strong> Data Analyst <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(66) <\/strong> as yearly compensation and less number of women are earning <strong>150,000-199,999 USD(1), 200,000-249,999 USD(1)<\/strong> as yearly compensation.\n4. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong>300,000-499,999 USD <\/strong>\n5. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 500,000-999,999 USD <\/strong>\n6. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 300,000-499,999 USD <\/strong>","0a5d45f1":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women with Non-profit\/Service contract by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","af70642a":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Current Role distribution of women by Programming Language recommended for aspiring Data Scientist<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","ee4985fa":"#### Observation:\n\nEmployed women are significantly very high in very year when compared to unemployed women.","3052efc9":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Current Roles distribution of women by Money spent on learning Machine Learning\/ Cloud Computing services in the past 5 years <strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","62300c3b":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 12: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">Which types of specialized hardware do you use on a regular basis?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","d649053d":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\nObvious that unemployed women have no earning(with respect to the jobs given survey)","a4be7760":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women who attained\/want to do  <strong> Some college\/university study without earning a bachelor\u2019s degree <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(27) <\/strong> as yearly compensation.\n2. Most of the women who attained\/want to do  <strong> Some college\/university study without earning a bachelor\u2019s degree <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(5) <\/strong> as yearly compensation.\n3. Most of the women who attained\/want to do  <strong> Some college\/university study without earning a bachelor\u2019s degree <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(9) <\/strong> as yearly compensation.\n4. Here we can see two woman are earning <strong> morethan 1,000,000 USD <\/strong>, one of them use <strong> Python <\/strong> and another uses <strong> R <\/strong> programming language on regular basis.\n5. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> morethan 1,000,000 USD <\/strong>\n6. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> morethan 1,000,000 USD <\/strong>\n7. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 200,000-249,999 USD <\/strong>","92f4f642":"#### Observation:\n\n1. we can see from 2018 to 2021 every year number of women getting jobs related to data science field is increasing rapidly.","a06f1073":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">VSCode vs PyCharm vs Jupyter Notebook(IDE's used on Regular Basis) in all Degrees of Women<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","a0a8445b":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women with Manufacturing\/Fabrication contract by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","3206dd30":"<h6 style=\"color:#fce444;font-size:13px;font-family:Georgia;text-align:center;\"><strong> <strong style=\"color:black;font-size:13px;font-family:Georgia;\">Names of students in the class are: Captain America, Iron Man, Thor, Black Panther, Loki, Hulk,Spider Man, Hawk Eye, Ant Man, Doctor Strange,Star-Lord, Sam, Bucky, Black widow, Wanda, Pepper Potts, Gamora, Peggy Carter, Nebula,All the students are from different countries<strong style=\"color:#fce444;font-size:13px;font-family:Georgia;\"> <strong style=\"color:black;font-size:13px;font-family:Georgia;\"> <\/strong><\/strong><\/strong><\/strong><\/h6>","b192c625":"<img src=\"https:\/\/d.newsweek.com\/en\/full\/1868100\/what-if-watcher.png\" width=\"800px\">","ec918943":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 34 Part A: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">Which of the following business intelligence tools do you use on a regular basis?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","ad0c97e5":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 24: <strong style=\"color:black;font-size:25px;font-family:Georgia;\"> Select any activities that make up an important part of your role at work<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","0df2b9b4":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women with Government\/Public Service contract by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","8bc01b57":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women with Retail\/Sales contract by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","5866adf0":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women of age group 30-34 by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","630d2a6d":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women of age group 40-44 by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","4fe56a61":"<img src=\"https:\/\/static0.srcdn.com\/wordpress\/wp-content\/uploads\/2019\/07\/Spider-Man-Far-From-Home-Nick-Fury-Maria-Hill.jpg\" width=\"800px\">","da7fa15b":"#### Observation:\n\n1. This question is multi option choosing one.\n2. Most of the people opted Scikit-learn and it is pretty obivious that we saw above most of them are beginners, beginners mainly work on ML alogorithms and all basic ML algos will available in Sikit-learn, not only beginners even experts use atleast once in their projects.\n3. TensorFlow, Keras and PyTorch stands in 2,3,4 places respectively..!!!\n4. Least used Framework is Caret","aecd608b":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women with Current Employer\/Contract as <strong>Hospitality\/Entertainment\/Sports <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(6) <\/strong> as yearly compensation.\n2. Most of the women with Current Employer\/Contract as <strong> Hospitality\/Entertainment\/Sports <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(2) <\/strong> as yearly compensation.\n3. Most of the womenwith Current Employer\/Contract as <strong> Hospitality\/Entertainment\/Sports <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD (3) <\/strong> as yearly compensation.\n4. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> 300,000-499,999 USD <\/strong>\n5. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 300,000-499,999 USD <\/strong>\n6. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 300,000-499,999 USD <\/strong>","07149d46":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Degree distribution of women by Coding Experience<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","a922d332":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women with Energy\/Mining contract by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","50411825":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 40: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">On which platforms have you begun or completed data science courses?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","47d26cdb":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 5: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">Select the title most similar to your current role (or most recent title if retired)? <strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","8bde2add":"<h1 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fDescription of <strong style=\"color:black;font-size:25px;font-family:Georgia;\">The <strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\">\"Challenge\" <strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h1>","a1457567":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n1. Most of the women who use <strong> Amazon Web Services (AWS) <\/strong> are earning <strong> 0-999 USD (82) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Amazon Web Services (AWS) <\/strong> is <strong> morethan 1,000,000 USD <\/strong>\n2. Most of the women who use <strong> Microsoft Azure <\/strong> are earning <strong> 0-999 USD (75) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Microsoft Azure <\/strong> is <strong> morethan 1,000,000 USD <\/strong>\n3. Most of the women who use <strong> Google Cloud Platform (GCP) <\/strong> are earning <strong> 0-999 USD (98) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Google Cloud Platform (GCP) <\/strong> is <strong> 500,000-999,999 USD <\/strong>\n4. Most of the women who use <strong> IBM Cloud \/ Red Hat <\/strong> are earning <strong> 0-999 USD (34) <\/strong> as yearly Compensation. Highest salary of women who use <strong> IBM Cloud \/ Red Hat <\/strong> is <strong> morethan 1,000,000 USD <\/strong>\n5. Most of the women who use <strong> Oracle Cloud <\/strong> are earning <strong> 0-999 USD (28) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Oracle Cloud (GCP) <\/strong> is <strong> 500,000-999,999 USD <\/strong>\n6. Most of the women who use <strong>SAP Cloud <\/strong> are earning <strong> 0-999 USD (14) <\/strong> as yearly Compensation. Highest salary of women who use <strong> SAP Cloud <\/strong> is <strong> morethan 1,000,000 USD <\/strong>\n7. Most of the women who use <strong>Sales force Cloud <\/strong> are earning <strong> 0-999 USD (14) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Sales force Cloud <\/strong> is <strong> morethan 1,000,000 USD <\/strong>\n8. Most of the women who use <strong>VM Ware Cloud <\/strong> are earning <strong> 0-999 USD (29) <\/strong> as yearly Compensation. Highest salary of women who use <strong> VM Ware Cloud <\/strong> is <strong> morethan 1,000,000 USD <\/strong>\\\n9. Most of the women who use <strong>Alibaba Cloud <\/strong> are earning <strong> 0-999 USD (5) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Alibaba Cloud <\/strong> is <strong> morethan 1,000,000 USD <\/strong>\n10. Most of the women who use <strong>Tenset Cloud <\/strong> are earning <strong> 0-999 USD (6) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Tenset Cloud <\/strong> is <strong> morethan 1,000,000 USD <\/strong>\n11. Most of the women who <strong>doesnot use Cloud Platform <\/strong> are earning <strong> 0-999 USD (119) <\/strong> as yearly Compensation. Highest salary of women who use <strong> doesnot use Cloud Platform <\/strong> is <strong> 300,000-499,999 <\/strong>\n12. Most of the women who use <strong> Other Cloud Platforms<\/strong> are earning <strong> 0-999 USD (7), 1,000-1,999 USD (7) <\/strong> as yearly Compensation. Highest salary of women who use <strong>Other Cloud Platforms <\/strong> is <strong> 250,000-299,999\t <\/strong>","1afa359f":"#### Observation:\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n\n1. Most of the women with current job as <strong> Business Analyst,Currently not employed,DBA\/Database Engineer,Data Analyst, Data Engineer,Data Scientist,Developer Relations\/Advocacy, Machine Learning Engineer,Other,Research Scientist,Statistician,Software Engineer,Student <\/strong> are <strong> Indians <\/strong>.\n2. Most of the women with current job as <strong> Product Manager,Program\/Project Manager <\/strong> are from <strong> USA <\/strong>.","2b601b25":"#### Observation:\n\n1. In <strong> 2018(203) <\/strong> more Woman with doctoral degree and having a job in Data Science Field when compared to years <strong> 2019,2020 and 2021 <\/strong>.\n2. In <strong> 2021(193) <\/strong>more Woman with doctoral degree and having a job in Data Science Field when compared to the years <strong>2019,2020 <\/strong>.\n3. In <strong> 2019(186) <\/strong> more Woman with doctoral degree and having a job in Data Science Field when compared to <strong>2020(159)<\/strong>.\n\n\nThere is a significant decrease of Woman with doctoral degree and having a job in Data Science Field from 2018 to 2020 and increased in the 2021 but still lessthan 2018(not with much difference).","58c827bd":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women with Current Employer\/Contract as <strong>Retail\/Sales <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 20,000-24,999 USD(5) <\/strong> as yearly compensation.\n2. Most of the women with Current Employer\/Contract as <strong> Retail\/Sales <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999(3) <\/strong> as yearly compensation.\n3. Most of the womenwith Current Employer\/Contract as <strong> Retail\/Sales <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 1,000-1,999 USD(3),20,000-24,999 USD(3), 20,000-24,999 USD(3), 30,000-39,999 USD(3), 70,000-79,999 USD(3), 80,000-89,999 USD(3) <\/strong> as yearly compensation.\n4. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> 150,000-199,999 USD <\/strong>\n5. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 150,000-199,999 USD <\/strong>\n6. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 150,000-199,999 USD <\/strong>","6f0791b4":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Degree distribution of women by Current Job<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","d66a225a":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Woman count in Current Role<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","e03a1379":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women of No formal education past high school by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","d904ebc3":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Current Roles distribution of women by favorite media sources that report on data science topics<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","049ee3c4":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women with by Cloud Computing Platforms used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","4dd73d89":"#### Observation:\n\n1. This is a multi option choosable question\n2. Most of the people are using Linear or Logistic Regression on regular basis, yes everyone of us will try linear regression algorithm first if the problem is regression one.\n3. Decision Trees or Random Forests stands in second place\n4. Option choosed my least number of people is \"other\".\n5. In the given options least number of people choosed Evolutionary Approaches Algorithms(only 963 people)","85d9e6b0":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 18: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">Which of the following computer vision methods do you use on a regular basis?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","9de1ceca":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Age distribution of women by Money spent on learning Machine Learning\/ Cloud Computing services in the past 5 years <strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","35fe4f4f":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Woman with Bachelor's degree and working as a Data Analyst<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","f5dd89ee":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 38 Part B: <strong style=\"color:black;font-size:25px;font-family:Georgia;\"> In the next 2 years, do you hope to become more familiar with any of these tools for managing ML experiments?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","61bffed5":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Matplotlib,Seaborn,Plotly\/Plotly Express and Ggplot\/ggplot2 only these 4 because these are the most choosed option.\n\n\n1. Matplotlib is most choosed by the women who attained\/want to do <strong> Master's degree(1242) <\/strong> and less choosed by the women who attained\/want to do <strong> No formal education past high school(16) <\/strong>.\n2. Seaborn is most choosed by the women who attained\/want to do <strong> Master's degree(921) <\/strong> and less choosed by the women who attained\/want to do <strong> No formal education past high school(9) <\/strong>.\n3. Plotly\/Plotly Express is most choosed by the women who attained\/want to do <strong> Master's degree(446) <\/strong> and less choosed by the women who attained\/want to do <strong> No formal education past high school(3) <\/strong>.\n4. Ggplot\/ggplot2 is most choosed by the women who attained\/want to do <strong> Master's degree(539) <\/strong> and less choosed by the women who attained\/want to do <strong> No formal education past high school(3) <\/strong>.","46501a5f":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed GitHub, Kaggle, Colab, I do not share my work publicly only these 4 because these are the most choosed option.\n\n\n1. GitHub is most choosed by the women of age group <strong> 25-29(157) <\/strong> and less choosed by the women of age group <strong> 70+(2) <\/strong>. \n2.  Kaggle is most choosed by the women of age group <strong> 25-29(91) <\/strong> and less choosed by the women of age group <strong> 70+ (1) <\/strong>.\n3. Colab is most choosed by the women of age group <strong> 25-29(64) <\/strong> and less choosed by the women of age group  <strong> 55-69(2) <\/strong>.Intresting fact is no women of age group <strong> 70+ <\/strong> choosed <strong> Colab <\/strong>.\n4.  I do not share my work publicly is most choosed by the women of age group <strong> 25-29(111) <\/strong> and less choosed by the women of age group <strong> 60-69(4) <\/strong>.Intresting fact is no women of age group <strong> 70+ <\/strong> choosed <strong>  I do not share my work publicly <\/strong>.","f5192a05":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women of Current Role as <strong> Statisticians <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(8)<\/strong> as yearly compensation.\n2. Most of the women of Current Role as <strong> Statisticians <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(14) <\/strong> as yearly compensation.\n3. Most of the women of Current Role as <strong> Statisticians <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(3) <\/strong> as yearly compensation.\n4. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong>125,000-149,999 USD <\/strong>\n5. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 200,000-249,999 USD <\/strong>\n6. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 30,000-39,999 USD <\/strong>","fffd0971":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n<strong> Students <\/strong> are not earning.","e817e54c":"#### Observation:\n\n1. In <strong> 2018(288) <\/strong> more Woman with doctoral degree and having a job in Data Science Field when compared to years <strong> 2019,2020 and 2021 <\/strong>.\n2. In <strong> 2019(171) <\/strong>more Woman with doctoral degree and having a job in Data Science Field when compared to the years <strong>2021,2020 <\/strong>.\n3. In <strong> 2021(129) <\/strong> more Woman with doctoral degree and having a job in Data Science Field when compared to <strong>2020(114)<\/strong>.","eeeeb837":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Degree distribution of women by Specialized Software used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","402f15aa":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women with Current Employer\/Contract as <strong>Marketing\/CRM Assessment <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 10,000-14,999 USD(5) <\/strong> as yearly compensation.\n2. Most of the womenwith Current Employer\/Contract as <strong> Marketing\/CRM Assessment <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 10,000-14,999 USD(5) <\/strong> as yearly compensation.\n3. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> 200,000-249,999 USD <\/strong>\n4. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 100,000-124,999 USD <\/strong>\n5. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 200,000-249,999 USD <\/strong>","48acc393":"#### Observation:\n\n1. In <strong> 2019,2021(13) <\/strong> more Woman with Maters degree and working as a Data Scientist in Australia when compared to years <strong> 2018,2020 <\/strong>.\n2. In <strong> 2020(9) <\/strong>more Woman with Maters degree and working as a Data Scientist in Australia when compared to the years <strong>2018(7)<\/strong>.","a216fdf2":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Degree distribution of women by Money spent on learning Machine Learning\/ Cloud Computing services in the past 5 years <strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","6c9bc5b1":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women with by business intelligence tools used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","94c4aff5":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 21: <strong style=\"color:black;font-size:25px;font-family:Georgia;\"> What is the size of the company where you are employed?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","067d9517":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women with by automated machine learning tools (or partial AutoML tools) used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","290269af":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed  GitHub, Kaggle, Colab and I do not share my work publicly only these 4 because these are the most choosed option.\n\n\n1. GitHub is most choosed by the women who attained\/want to do <strong> Master's degree(322) <\/strong> and less choosed by the women who attained\/want to do <strong> No formal education past high school(4) <\/strong>.\n2. Kaggle is most choosed by the women who attained\/want to do <strong> Master's degree(197) <\/strong> and less choosed by the women who attained\/want to do <strong> No formal education past high school(2) <\/strong>.\n3. Colab is most choosed by the women who attained\/want to do <strong> Master's degree(112) <\/strong> and less choosed by the women who attained\/want to do <strong> No formal education past high school(2) <\/strong>.\n4. I do not share my work publicly is most choosed by the women who attained\/want to do <strong> Master's degree(221) <\/strong> and less choosed by the women who attained\/want to do <strong> No formal education past high school(2) <\/strong>.","e561d308":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 39: <strong style=\"color:black;font-size:25px;font-family:Georgia;\"> Where do you publicly share your data analysis or machine learning applications?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","903a6289":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women with coding experience 5-10 years by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","7ea6f259":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women Students by Software Engineer used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","50938591":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Age distribution of women by Data Visualization Libraries used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","3f8ad5d0":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed  Linear or Logistic Regression,Decision Trees or Random Forests,Gradient Boosting Machines (xgboost, lightgbm, etc) and Convolutional Neural Networks only these 4 because these are the most choosed option.\n\n\n1. Linear or Logistic Regression is most choosed by the women who attained\/want to do <strong> Master's degree(1031) <\/strong> and less choosed by the women who attained\/want to do <strong> No formal education past high school(9) <\/strong>.\n2. Decision Trees or Random Forests is most choosed by the women who attained\/want to do <strong> Master's degree(909) <\/strong> and less choosed by the women who attained\/want to do <strong> No formal education past high school(10) <\/strong>.\n3. Gradient Boosting Machines (xgboost, lightgbm, etc) is most choosed by the women who attained\/want to do <strong> Master's degree(479) <\/strong> and less choosed by the women who attained\/want to do <strong> No formal education past high school(5) <\/strong>.\n4. Convolutional Neural Networks is most choosed by the women who attained\/want to do <strong> Master's degree(436) <\/strong> and less choosed by the women who attained\/want to do <strong> No formal education past high school(7) <\/strong>.","5ae0715a":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n\n1. Most of the women of all Current Roles are earning <strong> 0-999 USD <\/strong> as their yearly compensation.\n2. Most of the womem who earn <strong> 500,000-999,999 USD, 1,000-1,999 USD, 10,000-14,999 USD, 15,000 - 19,999 USD, 25,000 - 29,999 USD, 3,000 - 3,999 USD,300,000-499,999 USD, 4,000-4,999 USD, 40,000-49,999 USD, 7,500-9,999 USD, 70,000-79,999 USD <\/strong> have current role <strong> Data Analyst <\/strong>.\n3. Most of the womem who earn <strong> 0-999 USD, 100,000-124,999 USD, 125,000-149,999 USD, 150,000-199,999 USD, 2,000-2,999 USD, 20,000-24,999 USD, 200,000-249,999 USD, 30,000-39,999 USD, 60,000-69,999 USD, 80,000-89,999 USD, 90,000-99,999 USD<\/strong> have current role <strong> Data Scientist <\/strong>.","470aadc1":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Kaggle Notebooks,Colab Notebooks and Goggle Cloud Datalab only these 3 because these are the most choosed option.\n\n\n1. Kaggle Notebooks is most choosed by the women <strong> Students (549) <\/strong> and less choosed by the women with Current Role <strong>DBA\/Database Engineer(3) <\/strong>.\n2. Colab Notebooks is most choosed by the women <strong> Students (598) <\/strong> and less choosed by the women with Current Role <strong> Developer Relations\/Advocacy(3), DBA\/Database Engineer(3)<\/strong>.\n3. Google Cloud Datalab is most choosed by the women <strong> Students (109) <\/strong> and less choosed by the women with Current Role <strong> Developer Relations\/Advocacy(1) <\/strong>.","6ab075cd":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women with by Machine Learning Products used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","44ea74cf":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 29 Part B: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">In the next 2 years, do you hope to become more familiar with any of these specific cloud computing products?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","f129ac1f":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women with Current Employer\/Contract as <strong> Medical\/Pharmaceutical <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(21) <\/strong> as yearly compensation.\n2. Most of the women with Current Employer\/Contract as <strong> Medical\/Pharmaceutical <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 30,000-39,999 USD(5) <\/strong> as yearly compensation.\n3. Most of the womenwith Current Employer\/Contract as <strong> Medical\/Pharmaceutical <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(8),30,000-39,999 USD(8) <\/strong> as yearly compensation.\n4. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> 250,000-299,999\t USD <\/strong>\n5. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 250,000-299,999 USD <\/strong>\n6. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 250,000-299,999 USD <\/strong>","c3eb8dc7":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women of age group <strong> 45-49 <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(17) <\/strong> as yearly compensation and less number of women are earning <strong> 5,000-7,499 USD (1), 7,500-9,999 USD (1), 90,000-99,999 USD(1) <\/strong> as yearly compensation.\n2. Most of the women of age group <strong> 45-49 <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(7) <\/strong> as yearly compensation and less number of women are earning <strong> 1,000-1,999 USD(1),100,000-124,999 USD(1),15,000-19,999 USD(1),200,000-249,999 USD(1),4,000-4,999 USD(1),40,000-49,999 USD(1), 50,000-59,999 USD (1)  <\/strong> as yearly compensation.\n3. Most of the women of age group <strong> 45-49 <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(9) <\/strong> as yearly compensation and less number of women are earning <strong> 100,000-124,999 USD(1),15,000-19,999 USD(1),250,000-299,999 USD(1),60,000-69,999 USD(1),7,500-9,999 USD(1) <\/strong> as yearly compensation.\n4. Here we can see two woman are earning <strong> >1,000,000 USD <\/strong> one use <strong> R <\/strong> and another one use <strong> Python <\/strong> programming language on regular basis.\n5. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> 150,000-199,999 USD <\/strong>\n6. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 200,000-249,999\t USD <\/strong>\n7. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 250,000-299,999 USD <\/strong>\n\n\nIf we compare women of age group <strong> 45-49 <\/strong> on programming language used on regular basis, we can see that women who use python on regular basis are earning morethan women who use R and SQL and we can also see that women who use python are also more than women who use R,SQl.\n\nIf we arrange Python,R and SQL with respect to number of women using the languages on regular basis and how much they are earning it would look like:<strong> SQL>python > R <\/strong>","78dcfb16":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women of age group <strong> 40-44 <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(30) <\/strong> as yearly compensation and less number of women are earning <strong> 125,000-149,999 USD (1), 300,000-499,999 USD (1), >1,000,000 USD(1) <\/strong> as yearly compensation.\n2. Most of the women of age group <strong> 40-44 <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 100,000-124,999 USD(10) <\/strong> as yearly compensation and less number of women are earning <strong> 20,000-24,999 USD (1),60,000-69,999 USD (1),250,000-299,999 USD (1),300,000-499,999 USD (1), 500,000-999,999 USD (1),>1,000,000 USD(1)<\/strong> as yearly compensation.\n3. Most of the women of age group <strong> 40-44 <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(13) <\/strong> as yearly compensation and less number of women are earning <strong> 125,000-149,999 USD (1) <\/strong> as yearly compensation.\n4. Here we can see two woman are earning <strong> >1,000,000 USD <\/strong> one use <strong> R <\/strong> and another one use <strong> Python <\/strong> programming language on regular basis.\n5. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> >1,000,000 USD <\/strong>\n6. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> >1,000,000 USD <\/strong>\n7. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 150,000-199,999 USD <\/strong>\n\n\nIf we compare women of age group <strong> 40-44 <\/strong> on programming language used on regular basis, we can see that women who use python on regular basis are earning morethan women who use R and SQL and we can also see that women who use python are also more than women who use R,SQl.\n\nIf we arrange Python,R and SQL with respect to number of women using the languages on regular basis and how much they are earning it would look like:<strong> python > R> SQL <\/strong>","050baf21":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women with coding experience <strong> 20+ years <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(16) <\/strong> as yearly compensation.\n2. Most of the women with coding experience <strong> 20+ years <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(10) <\/strong> as yearly compensation.\n3. Most of the womenwith coding experience <strong> 20+ years <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(15) <\/strong> as yearly compensation.\n4. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> morethan 1,000,000 USD <\/strong>\n5. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> morethan 1,000,000 USD<\/strong>\n6. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 250,000-299,999 USD <\/strong>","ae8ec2f7":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 16: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">Which of the following machine learning frameworks do you use on a regular basis?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","101acf8c":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Age distribution of women by Machine Learning Algorithms used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","a456a754":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Woman with master degree and working as data science related jobs in USA<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","1f5a1de0":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 31 Part A: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">Do you use any of the following managed machine learning products on a regular basis?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","57fba2ae":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women with Current Employer\/Contract as <strong>Retail\/Sales <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(11) <\/strong> as yearly compensation.\n2. Most of the women with Current Employer\/Contract as <strong> Retail\/Sales <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 7,500-9,999(3) <\/strong> as yearly compensation.\n3. Most of the womenwith Current Employer\/Contract as <strong> Retail\/Sales <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 10,000-14,999(6) <\/strong> as yearly compensation.\n4. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> 150,000-199,999 USD <\/strong>\n5. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 150,000-199,999 USD <\/strong>\n6. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 150,000-199,999 USD <\/strong>","7d52b3b8":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 36 Part B: <strong style=\"color:black;font-size:25px;font-family:Georgia;\"> Which categories of automated machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","2e47130c":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women Machine Learning Engineers by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","06d080b6":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 8: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">What programming language would you recommend an aspiring data scientist to learn first?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","f007b8a9":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Woman Students Across Years<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","c7b97cf5":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Woman who knows only R and having a job in Data Science Field<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","5220c657":"#### Observation:\n\nEmployed women are significantly very high in very year when compared to unemployed women.","53866f10":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of Currently Not employed woman by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","27f86d46":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Degree distribution of women by platforms they begun or completed data science courses<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","b6a7acdd":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Degree distribution of women by Machine Learning Frameworks used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","0d6414b4":"#### Observation\n##### All these observations are with respect to the women in the survey not entire women in the world \n \n \n1. In age group <strong> 18-21 <\/strong> most of the women<strong> (763) <\/strong> attained\/wanted to do <strong> Bachelor's degree <\/strong>.\n2. In age group <strong> 22-24 <\/strong> most of the women<strong> (435) <\/strong> attained\/wanted to do <strong> Bachelor's degree <\/strong>, followed by women with\/wanted to do <strong> Master's Degree(423) <\/strong> are more.\n3. In age group <strong> 22-24 <\/strong> women with\/wanted to do <strong> Bachelor's degree <\/strong> and women with\/wanted to do <strong> Master's degree <\/strong> are almost equal.\n4. In age group <strong>  25-70+ <\/strong> most of the women attained\/wanted to do <strong> Master's degree.<\/strong>\n5. In age group <strong> 60-69 <\/strong> most of thr women attained\/wanted to do both <strong> Bachelor's and Master's degree <\/strong>.\n6. There are only <strong> 8 women <\/strong> of age group <strong> 70+ <\/strong> invloved in the survey in which 4 women attained\/wanted to do <strong> Master's degree <\/strong>, 2 women each attained\/wanted to <strong> Bachelor's degree and professional doctorate <\/strong>.\n7. Most of the Women attained\/wanted to do <strong> Bachelor's degree <\/strong> are from age group <strong> 18-21 (763) <\/strong>.\n8. Most of the Women attained\/wanted to do <strong> Doctoral degree <\/strong> are from age group <strong> 35-39 (129) <\/strong>.\n9. Most of the Women who <strong> donot prefer to answer <\/strong> are from age group <strong> 18-21(31) <\/strong>.\n10. Most of the Women attained\/wanted to do <strong> Master's degree <\/strong> are from age group <strong> 25-29 (538) <\/strong>.\n11. Most of the Women who <strong> had no formal education past high school <\/strong> are from age group <strong> 18-21 (15) <\/strong>.\n12. Most of the Women attained\/wanted to do <strong> Professional doctorate <\/strong> are from age group <strong> 30-34 (18) <\/strong>.\n13. Most of the Women studing in <strong> Some college\/university study without earning a bachelor's degree <\/strong> are from age group <strong> 18-21 (147) <\/strong>.","73efb35c":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Linear or Logistic Regression, Desision Trees or Random Forests, Gradient Boosting Machines (xgboost, lightgbm, etc) and Convolutional Neural Networks only these 4 because these are the most choosed option.\n\n\n1. Linear or Logistic Regression is most choosed by the women of age group <strong> 25-29(502) <\/strong> and less choosed by the women of age group <strong> 70+(5) <\/strong>. \n2.  Desision Trees or Random Forests is most choosed by the women of age group <strong> 25-29(428) <\/strong> and less choosed by the women of age group <strong> 70+ (5) <\/strong>.\n3. Gradient Boosting Machines (xgboost, lightgbm, etc) is most choosed by the women of age group <strong> 25-29(232) <\/strong> and less choosed by the women of age group  <strong> 70+(2) <\/strong>.\n4. Convolutional Neural Networks is most choosed by the women of age group <strong> 25-29(225) <\/strong> and less choosed by the women of age group <strong> 70+(1) <\/strong>.","07488ce5":"#### Observation:\n\n1. Most of the people in age groups <strong> 18-21,22-24,25-29,30-34 <\/strong>are from <strong> India <\/strong>. This states that age group <strong> 18-34 (young to middle aged women) <\/strong> are more invloved in the survey from India.\n2. From India there are <strong> 701 women from age group 18-21 <\/strong> which is highest among all, whereas <strong> Indonesia <\/strong> stands in second place with only <strong> 40 women <\/strong> invloved in survey, followed by <strong> USA <\/strong> with <strong> 30 women <\/strong> involved. We can expect this because we already saw that Indian women are more in the survey.\n3. Age groups <strong> 35-39, 40-44 <\/strong> are also actively invloved from India when compared to other countries, actually in <strong> second place <\/strong> after women from USA.\n4. Most of the people in age groups <strong> 35-39,40-44,45-49,50-54,55-59,60-69,70+ <\/strong>are from <strong> USA <\/strong>. This states, that age group <strong> 35-70+ (middle to old aged women) <\/strong> are more invloved in the survey from <strong> USA <\/strong>.\n5. Women from <strong> USA and India <\/strong> are more invloved in survey when compared to all other countries.","b68f8cb8":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Woman with master degree and any job related to data science in Australia<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","a11b9e57":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 41: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">What is the primary tool that you use at work or school to analyze data?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","c9d2f60d":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Age distribution of women by Current Yearly Compensation <strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","cbcc165b":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 32 Part B: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you hope to become more familiar with in the next 2 years?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","e9d50a36":"#### Observation:\n\n1. In <strong> 2021(3316) <\/strong> more women invloved in the survey when compared to years <strong> 2018,2019 and 2020 <\/strong>.\n2. When compared to <strong> 2018(2999) <\/strong>involvement of women in survey decreased in the years <strong>2019,2020 <\/strong>.\n3. When compared to <strong> 2019(2448) <\/strong> involvement of women in survey increased in <strong> 2020(2633) <\/strong>.\n4. From <strong> 2019 <\/strong>there is constant increase in women involvement in the survey","98656dd2":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Age distribution of women by Coding Experience<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","a9acee3a":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Woman count in all Degrees<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","65fa18bc":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women of age group <strong> 18-21 <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(109) <\/strong> as yearly compensation and less number of women are earning <strong> 10,000 -14,999 USD(1), 60,000-69,999 USD(1), 200,000-249,999 USD(1) <\/strong> as yearly compensation.\n2. Most of the women of age group <strong> 18-21 <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(17) <\/strong> as yearly compensation and less number of women are earning <strong> 10,000 - 14,999 USD(1), 60,000-69,999 USD(1), 200,000-249,999 USD(1) <\/strong> as yearly compensation.\n3. Most of the women of age group <strong> 18-21 <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(53) <\/strong> as yearly compensation and less number of women are earning <strong> 200,000-249,999 USD(1) <\/strong> as yearly compensation.\n4. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> 200,000-249,999 USD <\/strong>\n5. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 200,000-249,999 USD <\/strong>\n6. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 200,000-249,999 USD <\/strong>\n\n\nIf we compare women of age group <strong> 18-21 <\/strong> on programming language used on regular basis, we can see that women who use python on regular basis are earning morethan women who use R and SQL and we can also see that women who use python are also more than women who use R,SQl.\n\nIf we arrange Python,R and SQL with respect to number of women using the them on regular basis and how much they are earning,it would look like:\n\n\n<strong> python > SQL> R <\/strong>","2a1fbedd":"<h1 style=\"color:#fce444;font-size:45px;font-family:Georgia;text-align:center;\"><strong>Analysis <strong style=\"color:black;font-size:40px;font-family:Georgia;\">Of <strong style=\"color:#fce444;font-size:40px;font-family:Georgia;\">\"Kaggle Survey 2021\" <strong style=\"color:black;font-size:45px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h1>","dfeccefc":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Age distribution of women by No. of years Machine Learning Methods used<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","578ff6c8":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed only Linear or Logistic Regression,Decision Trees or Random Forests,Gradient Boosting Machines (xgboost, lightgbm, etc) and Convolutional Neural Networks these 4 because these are the most choosed option.\n\n\n1. Linear or Logistic Regression is most choosed by the women <strong> Students (677) <\/strong> and less choosed by the women with Current Role <strong>Developer Relations\/Advocacy(5) <\/strong>.\n2. Decision Trees or Random Forests is most choosed by the women <strong> Students (577) <\/strong> and less choosed by the women with Current Role <strong> Developer Relations\/Advocacy(5)<\/strong>.\n3. Gradient Boosting Machines (xgboost, lightgbm, etc) is most choosed by the women of Current Role<strong> Data Scientist (266) <\/strong> and less choosed by the women with Current Role <strong>Developer Relations\/Advocacy(3),DBA\/Database Engineer(3) <\/strong>.\n4. Convolutional Neural Networks is most choosed by the women <strong> Students (320) <\/strong> and less choosed by the women with Current Role <strong> DBA\/Database Engineer(1) <\/strong>.","1d3387ab":"#### Observation:\n\n1. Most of the people are using Jupyter Notebook mainly because it is has cells so we can execute our codes line by line.\n2. Visual Studio code is at second, Pycharm at third\n3. People who use R language are pretty good in number so they are using RStudio.","66c2cdf7":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Age distribution of women by Programming Language recommended for aspiring Data Scientist<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","05b66fce":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Kaggle vs Colab vs Google Cloud Datalab(hosted notebooks used on Regular Basis) in all Current Roles of Women<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","f961fd68":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 13: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">Approximately how many times have you used a TPU (tensor processing unit)?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","3b32fd96":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women with Current Employer\/Contract as <strong>Non-profit\/Service <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(14) <\/strong> as yearly compensation.\n2. Most of the women with Current Employer\/Contract as <strong> Non-profit\/Service <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(5) <\/strong> as yearly compensation.\n3. Most of the womenwith Current Employer\/Contract as <strong> Non-profit\/Service <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 1,000-1,999 USD (6) <\/strong> as yearly compensation.\n4. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> 150,000-199,999 USD <\/strong>\n5. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 150,000-199,999 USD <\/strong>\n6. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 150,000-199,999 USD <\/strong>","b723733d":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 11: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">What type of computing platform do you use most often for your data science projects?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","515a7984":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Python vs R vs SQL(Programming Language used on regular basis) in all Degrees of Women<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","82153e1e":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 27 Part A: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">Which of the following cloud computing platforms do you use on a regular basis?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","a2df5c54":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women of age group <strong> 55-59 <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(8) <\/strong> as yearly compensation \n2. Most of the women of age group <strong> 55-59 <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(3) <\/strong> as yearly compensation \n3. Most of the women of age group <strong> 55-59 <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(5) <\/strong> as yearly compensation \n4. Here we can see four woman are earning <strong> 250,000-299,999 USD <\/strong> one use <strong> R <\/strong>, two of them use <strong> Python <\/strong> and another one use <strong> SQL <\/strong> programming language on regular basis.\n5. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> 250,000-299,999 USD <\/strong>\n6. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 250,000-299,999\t USD <\/strong>\n7. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 250,000-299,999 USD <\/strong>","092d2b5a":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Scikit-learn,TensorFlow,Keras,PyTorch and Xgboost only these 5 because these are the most choosed option.\n\n\n1. Scikit-learn is most choosed by the women who attained\/want to do <strong> Master's degree(1002) <\/strong> and less choosed by the women who attained\/want to do <strong> No formal education past high school(9) <\/strong>.\n2. TensorFlow is most choosed by the women who attained\/want to do <strong> Master's degree(566) <\/strong> and less choosed by the women who attained\/want to do <strong> No formal education past high school(8) <\/strong>.\n3. Keras is most choosed by the women who attained\/want to do <strong> Master's degree(484) <\/strong> and less choosed by the women who attained\/want to do <strong> No formal education past high school(6) <\/strong>.\n4. PyTorch is most choosed by the women who attained\/want to do <strong> Master's degree(339) <\/strong> and less choosed by the women who attained\/want to do <strong> No formal education past high school(5) <\/strong>.\n5. Xgboost is most choosed by the women who attained\/want to do <strong> Master's degree(383) <\/strong> and less choosed by the women who attained\/want to do <strong> No formal education past high school(3) <\/strong>.","5324dde8":"#### observation:\n1. Well..!!! I can see <strong> 14526 <\/strong> people out of <strong> 25973 <\/strong> people are in <strong> age group 18-29 <\/strong>, This shows that more younge are involved in this kaggle survey. Most of the people involved in the survey are of age group <strong> 25-29(4931) <\/strong>, followed by age group <strong> 18-21(4901) only 30 lessthan people of age group 25-29<\/strong>,followed by age group <strong> 22-24(4901) <\/strong>.\n\n2. Except for top 3 age groups, as age increasing number of people decreasing.\n\n3. There are a total of <strong> 2237 <\/strong> of age group 50-70+. This shows that a good number of old people are also invloved in the survey.","c6ed11c6":"#### Observation:\n\n1. In <strong> 2021(1632) <\/strong> more women are in jobs related to data science when compared to years <strong> 2018,2019 and 2020 <\/strong>.\n2. In <strong> 2018(1464) <\/strong>more women are in jobs related to data science when compared to the years <strong>2019,2020 <\/strong>.\n3. In <strong> 2019(1241) <\/strong> more women are in jobs related to data science when compared to <strong>2020 (1223)<\/strong>.","fb3bc027":"<h1 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Analysis of Women in survey<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h1>","ef78fb70":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 9: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">Which of the following integrated development environments (IDE's) do you use on a regular basis?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","18af9da2":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n1. There are only 2 women of age group <strong> 70+ <\/strong> who use <strong> python <\/strong>programming language on regular basis and one of them earning <strong> 100,000-124,999\tUSD <\/strong> and another one earning <strong> 7,500-9,999 <\/strong> as their yearly compensation.\n2. No women of age group <strong> 70+ <\/strong> who use <strong> R <\/strong> programming language on regular basis.\n3. There are only 2 women of age group <strong> 70+ <\/strong> who use <strong> SQL <\/strong>programming language on regular basis and both of them are earning <strong> 100,000-124,999\tUSD <\/strong> as their yearly compensation.","3c4ac987":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 19: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">Which of the following natural language processing (NLP) methods do you use on a regular basis?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","60b8a754":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women of Current Role as <strong> Product Managers <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(3), 150,000-199,999 USD(3) <\/strong> as yearly compensation.\n2. Most of the women of Current Role as <strong> Product Managers <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 250,000-299,999 USD(1) <\/strong> as yearly compensation.\n3. Most of the women of Current Role as <strong> Product Managers <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(2),50,000-59,999 USD(2),150,000-199,999 USD(2) <\/strong> as yearly compensation.\n4. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong>250,000-299,999 USD <\/strong>\n5. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 250,000-299,999 USD <\/strong>\n6. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 200,000-249,999 USD <\/strong>","bf10b97c":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Woman with doctoral degree and having a job in Data Science Field<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","fe6f051e":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Coursera, Kaggle Learn Courses,Udemy and University Courses (resulting in a university degree) only these 4 because these are the most choosed option.\n\n\n1. Coursera is most choosed by the women <strong> Students (460) <\/strong> and less choosed by the women with Current Role <strong>Developer Relations\/Advocacy(4),DBA\/Database Engineer(4) <\/strong>.\n2. Kaggle Learn Courses is most choosed by the women <strong> Students (423) <\/strong> and less choosed by the women with Current Role <strong> Developer Relations\/Advocacy(4)<\/strong>.\n3. Udemy is most choosed by the women <strong> Students (287) <\/strong> and less choosed by the women with Current Role <strong> Developer Relations\/Advocacy(4) <\/strong>.\n4. University Courses (resulting in a university degree) is most choosed by the women <strong> Students (357) <\/strong> and less choosed by the women with Current Role <strong> Developer Relations\/Advocacy(4),DBA\/Database Engineer(4) <\/strong>.","cafd1e58":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of Data Engineers by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","ee80a04a":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women with Current Employer\/Contract as <strong>Marketing\/CRM Assessment <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(11) <\/strong> as yearly compensation.\n2. Most of the women with Current Employer\/Contract as <strong> Marketing\/CRM Assessment <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999(3) <\/strong> as yearly compensation.\n3. Most of the womenwith Current Employer\/Contract as <strong> Marketing\/CRM Assessment <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(10) <\/strong> as yearly compensation.\n4. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> 125,000-149,999 USD <\/strong>\n5. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 100,000-124,999 USD <\/strong>\n6. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 150,000-199,999 USD <\/strong>","629d0fae":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women of Bachelors degree by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","6afa2219":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Current Role distribution of women by Coding Experience<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","8fd6128d":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women who attained\/want to do  <strong> Professional Doctorate <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(10) <\/strong> as yearly compensation.\n2. Most of the women who attained\/want to do  <strong> Professional Doctorate <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(4) <\/strong> as yearly compensation.\n3. Most of the women who attained\/want to do  <strong> Professional Doctorate <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(6) <\/strong> as yearly compensation.\n4. Here we can see one woman is earning <strong> 500,000-999,999 USD <\/strong>and she use <strong> R <\/strong> programming language on regular basis.\n5. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> 250,000-299,999 USD <\/strong>\n6. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 500,000-999,999 USD <\/strong>\n7. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 90,000-99,999 USD <\/strong>","4cd10c6f":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women with by Cloud Computing Products used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","cf91d580":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 37 Part B: <strong style=\"color:black;font-size:25px;font-family:Georgia;\"> Which specific automated machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","7dee7417":"# Observation:\n\n1. Most of the people are using Image classification and other general purpose networks (VGG, Inception, ResNet, ResNeXt, NASNet, EfficientNet, etc this computer vision method on regular basis.\n2. Good thing is every option is almost balanced here no bias that means all methods which are available in computer methods are using regularly by people who want to use..!!!","c4bf9dc0":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Python is most choosed by the women <strong> Students (1363) <\/strong> and less choosed by the women with Current Role <strong> Developer Relations\/Advocacy(10) <\/strong>.\n2. R is most choosed by the women <strong> Students (359) <\/strong> and less choosed by the women with Current Role <strong> DBA\/Database Engineer(1) <\/strong>.\n3. SQL is most choosed by the women <strong> Students (1363) <\/strong> and less choosed by the women with Current Role <strong> Developer Relations\/Advocacy(10) <\/strong>.","f930c691":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n\n1. Most of the women of Current Role <strong> Business Analyst,DBA\/Database Engineer,Data Engineer,Data Scientist,DBA\/Database Engineer,Machine Learning Engineering, Product Manager,Program\/Project Manager, Software Engineer,Students <\/strong> have Current Employer\/Contract as <strong> Computers\/Technology <\/strong>\n2. Most of the women of Current Role <strong> Data Analyst, Research Scientist, Statistician <\/strong> have Current Employer\/Contract as <strong> Academics\/Education <\/strong>\n3. Most of the women of Current Employer\/Contract <strong> Accounting\/Finance,Broadcasting\/Communications,Government\/Public Service,Hospitality\/Entertainment\/Sports,Marketing\/CRM,Online Business\/Internet-based Sales,Online Service\/Internet-based Services,Retail\/Sales,Shipping\/Transportation <\/strong> have Current Role as <strong> Data Analyst <\/strong>\n4. Most of the women of Current Employer\/Contract <strong> Energy\/Mining,Insurance\/Risk Assessment,Manufacturing\/Fabrication,Medical\/Pharmaceutical,Military\/Security\/Defense<\/strong> have Current Role as <strong> Data Scientist <\/strong>\n5. Most of the women of Current Employer\/Contract <strong> Academics\/Education <\/strong> have Current Role as <strong> Research Scientist <\/strong>\n6. Most of the women of Current Employer\/Contract <strong> Computers\/Technology <\/strong> have Current Role as <strong> Software Engineer <\/strong>","244deacb":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Woman count in all age groups<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","cd0705d9":"#### Observation:\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n\n1. Most of the women of all degrees are used\/using Machine learning methods <strong> lessthan 1 year <\/strong>\n2. Most of the women who are using\/used Machine learning methods <strong> 1-10 years<\/strong> have attained\/want to do <strong> Master's Degree <\/strong>\n3. Most of the women who are using\/used Machine learning methods <strong> 10-20+ years<\/strong> have attained\/want to do <strong> Doctoral Degree <\/strong>\n4. Most of the women who not used\/using Machine learning Methods or using\/used Machine learning methods <strong> lessthan 1 year<\/strong> have attained\/want to do <strong> Bachelo's Degree <\/strong>","077227ee":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Degree Distribution of women by country<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","9c27c64a":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Employed vs Unemployed women in all age groups<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","de9345dd":"<h1 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fLoading <strong style=\"color:black;font-size:25px;font-family:Georgia;\">Dataset <strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h1>","93d4c226":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women Statisticians by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","d10213c7":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Most of the women with coding experience <strong> 1-3 years <\/strong> who use <strong> Python <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(204) <\/strong> as yearly compensation and less number of women are earning <strong> 125,000-149,999 USD(1), 150,000-199,999 USD(1)<\/strong> as yearly compensation.\n2. Most of the women with coding experience <strong> 1-3 years <\/strong> who use <strong> R <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(45) <\/strong> as yearly compensation and less number of women are earning <strong> 300,000-499,999 USD(1)<\/strong> as yearly compensation.\n3. Most of the womenwith coding experience <strong> 1-3 years <\/strong> who use <strong> SQL <\/strong> Programming Language on regular basis are earning <strong> 0-999 USD(110) <\/strong> as yearly compensation and less number of women are earning <strong> 125,000-149,999 USD(1), 150,000-199,999 USD(1)<\/strong> as yearly compensation.\n4. Highest Salary of women who use <strong> Python <\/strong> programming language on regular basis is <strong> 300,000-499,999 USD <\/strong>\n5. Highest Salary of women who use <strong> R <\/strong> programming language on regular basis is <strong> 300,000-499,999 USD <\/strong>\n6. Highest Salary of women who use <strong> SQL <\/strong> programming language on regular basis is <strong> 300,000-499,999 USD <\/strong>","c1ad950b":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n1. Most of the women involved in <strong> 2021 <\/strong>survey are <strong> Students(1574) <\/strong>\n2. Women with Current Role  <strong> Data Scientist(584) <\/strong> stands in 2nd place.\n3. Very less women with Current Role <strong> Developer Relations\/Advocacy(16) <\/strong>.","d9cc68f7":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed VSCode,PyCharm and Jupyter Notebook only these 3 because these are the most choosed option.\n\n\n1. VSCode is most choosed by the women who attained\/want to do <strong> Bachelor's degree(705) <\/strong> and less choosed by the women who attained\/want to do <strong> Professional Doctorate(12) <\/strong>.\n2. PyCharm is most choosed by the women who attained\/want to do <strong> Bachelor's degree(507) <\/strong> and less choosed by the women who attained\/want to do <strong> No formal education past high school(7) <\/strong>.\n3. Jupyter Notebook is most choosed by the women who attained\/want to do <strong> Master's degree(1264) <\/strong> and less choosed by the women who attained\/want to do <strong> No formal education past high school(18) <\/strong>.","bd587230":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Matplotlib, Seaborn, Plotly\/ Plotly Express and Ggplot\/ggplot2 only these 4 because these are the most choosed option.\n\n1. Matplotlib is most choosed by the women of age group <strong> 25-29(659) <\/strong> and less choosed by the women of age group <strong> 70+(6) <\/strong>. \n2. Seaborn is most choosed by the women of age group <strong> 25-29(484) <\/strong> and less choosed by the women of age group <strong> 70+ (5) <\/strong>.\n3. Plotly\/Plotly Express is most choosed by the women of age group <strong> 25-29(216) <\/strong> and less choosed by the women of age group <strong> 70+(2) <\/strong>.\n4. Ggplot\/ ggplot2 is most choosed by the women of age group <strong> 25-29(237) <\/strong> and less choosed by the women of age group <strong> 70+(1) <\/strong>.","0519140a":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Kaggle vs Colab vs Google Cloud Datalab(hosted notebooks used on Regular Basis) in all Age Groups of Women<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","e3680ceb":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 15: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">  For how many years have you used machine learning methods?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","2a051551":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n1. Most of the women who use <strong> Amazon SageMaker <\/strong> are earning <strong> 0-999 USD (24) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Amazon SageMaker <\/strong> is <strong> morethan 1,000,000 USD <\/strong>\n2. Most of the women who use <strong> Azure Machine Learning Studio <\/strong> are earning <strong> 0-999 USD (34) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Azure Machine Learning Studio <\/strong> is <strong> morethan 1,000,000 USD <\/strong>\n3. Most of the women who use <strong> Google Cloud Vertex AI <\/strong> are earning <strong> 0-999 USD (34) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Google Cloud Vertex AI <\/strong> is <strong> morethan 1,000,000 USD <\/strong>\n4. Most of the women who use <strong> Data Robot <\/strong> are earning <strong> 0-999 USD (16) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Data Robot <\/strong> is <strong> morethan 1,000,000 USD <\/strong>\n5. Most of the women who use <strong> Databricks <\/strong> are earning <strong> 0-999 USD (15) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Databricks <\/strong> is <strong> morethan 1,000,000 USD <\/strong>\n6. Most of the women who use <strong> Dataiku <\/strong> are earning <strong> 0-999 USD (6) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Dataiku <\/strong> is <strong> morethan 1,000,000 USD <\/strong>\n7. Most of the women who use <strong> Alteryx <\/strong> are earning <strong> 0-999 USD (8) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Alteryx <\/strong> is <strong> morethan 1,000,000 USD <\/strong>\n8. Most of the women who use <strong> Rapidminer <\/strong> are earning <strong> 0-999 USD (10) <\/strong> as yearly Compensation. Highest salary of women who use <strong> Rapidminer <\/strong> is <strong> 250,000-299,999 USD <\/strong>\n9. Most of the women who <strong>doesnot use Machine Learning Products <\/strong> are earning <strong> 0-999 USD (220) <\/strong> as yearly Compensation. Highest salary of women who use <strong> doesnot use Machine Learning Products <\/strong> is <strong> 300,000-499,999 USD <\/strong>\n10. Most of the women who use <strong> Other Machine Learning Products<\/strong> are earning <strong> 0-999 USD (14) <\/strong> as yearly Compensation. Highest salary of women who use <strong>Other Machine Learning Products <\/strong> is <strong> 250,000-299,999 USD<\/strong>","5f7c65b6":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Python is most choosed by the women who attained\/want to do <strong> Master's degree(1574) <\/strong> and less choosed by the women who attained\/want to do <strong> No formal education past high school(30) <\/strong>.\n2. R is most choosed by the women who attained\/want to do <strong> Master's degree(540) <\/strong> and less choosed by the women who attained\/want to do <strong> No formal education past high school(5) <\/strong>.\n3. SQL is most choosed by the women who attained\/want to do <strong> Master's degree(954) <\/strong> and less choosed by the women who attained\/want to do <strong> No formal education past high school(15) <\/strong>.","7b7aeef2":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 23: <strong style=\"color:black;font-size:25px;font-family:Georgia;\"> Does your current employer incorporate machine learning methods into their business?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","9f7ae35b":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women of Some college\/university study without earning a bachelor\u2019s degree by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","50da26d1":"<h6 style=\"color:#fce444;font-size:26px;font-family:Georgia;text-align:center;\"><strong> <strong style=\"color:black;font-size:21px;font-family:Georgia;\">NICK FURY started explaining all questions asked in the survey and students started to write their observation from his explanation<strong style=\"color:#fce444;font-size:21px;font-family:Georgia;\"> <strong style=\"color:black;font-size:26px;font-family:Georgia;\"> <\/strong><\/strong><\/strong><\/strong><\/h6>","4e927eab":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women with Marketing\/CRM Assessment contract by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","28b321c1":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women with Broadcasting\/Communications contract by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","b87e0f05":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Current Roles distribution of women by Machine Learning Frameworks used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","2a28ab47":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 32 Part A: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you use on a regular basis?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","a089627a":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong>\u270f\ufe0fQuestion 28: <strong style=\"color:black;font-size:25px;font-family:Georgia;\">Of the cloud platforms that you are familiar with, which has the best developer experience (most enjoyable to use)?<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","fd2f66e2":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n\n\n1. Most of the women of age group <strong> 18-21 <\/strong> have current Employer\/contract as <strong> Academics\/Education <\/strong>\n2. Most of the women of age group <strong> 22-29 <\/strong> have current Employer\/contract as <strong> Computers\/Technology <\/strong>\n3. Most of the women of age group <strong> 30-70+ <\/strong> have current Employer\/contract as <strong> Academics\/Education <\/strong>\n4. Most of the women with Current Employer\/Contract as <strong> Academics\/Education, Accounting\/Finance,\nBroadcasting\/Communications, Computers\/Technology, Hospitality\/Entertainment\/Sports,Manufacturing\/Fabrication,Marketing\/CRM, Medical\/Pharmaceutical, Non-profit\/Service, Online Business\/Internet-based Sales,Online Service\/Internet-based Services, Other, Retail\/Sales <\/strong> are of age group <strong> 25-29 <\/strong>\n5. Most of the women with Current Employert\/Contract as <strong> Energy\/Mining,Government\/Public Service,Insurance\/Risk Assessment,Shipping\/Transportation <\/strong> are of age group <strong> 30-34 <\/strong>.\n6. Most of the women with Current Employer\/Contract as <strong> Military\/Security\/Defense <\/strong> are of age group <strong> 22-24 <\/strong>.","a1619a55":"<h2 style=\"color:#fce444;font-size:30px;font-family:Georgia;text-align:center;\"><strong><strong style=\"color:black;font-size:25px;font-family:Georgia;\">Income Distribution of women DBA\/Database Engineer by programming language used on regular basis<strong style=\"color:#fce444;font-size:25px;font-family:Georgia;\"><strong style=\"color:black;font-size:30px;font-family:Georgia;\">:- <\/strong><\/strong><\/strong><\/strong><\/h2>","cec2823b":"<h6 style=\"color:#fce444;font-size:26px;font-family:Georgia;text-align:center;\"><strong> <strong style=\"color:black;font-size:21px;font-family:Georgia;\"> <strong style=\"color:#fce444;font-size:21px;font-family:Georgia;\"> <strong style=\"color:black;font-size:26px;font-family:Georgia;\"> THE END<\/strong><\/strong><\/strong><\/strong><\/h6>","9cfb1d9d":"#### Observation:\n\n\n##### All these observations are with respect to the women in the survey not entire women in the world \n##### Here I choosed Python,R and SQL only these 3 because these are the most choosed option.\n\n\n1. Python is most choosed by the women of age group <strong> 18-21(959) <\/strong> and less choosed by the women of age group <strong> 70+(4) <\/strong>.\n2. R is most choosed by the women of age group <strong> 25-29(243) <\/strong> and less choosed by the women of age group <strong> 60-69(15) <\/strong>. Intresting fact is no women of age group <strong> 70+ <\/strong> choosed <strong> R <\/strong>.\n3. SQL is most choosed by the women of age group <strong> 25-29 (456) <\/strong> and less choosed by the women of age group <strong> 70+(3) <\/strong> "}}