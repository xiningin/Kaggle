{"cell_type":{"0824f372":"code","dbc3a830":"code","003930e0":"code","1bfff594":"code","e839fc9c":"code","037159e6":"code","4aa3cb7d":"code","e37247b8":"code","79c0964b":"code","6f8b9b55":"code","da9c1a64":"code","daa79d11":"code","b276ec2f":"code","6543ff6b":"code","64569e19":"code","fbd39872":"code","614bc341":"code","d300dddd":"code","c8383f25":"code","24e2a96e":"code","83888635":"code","2c18f1d8":"code","47cb9b8b":"code","8ca5d0d4":"code","5682949d":"code","948d0b14":"code","07c22d1d":"code","269e8944":"code","955f2fe9":"code","b8b9fbb6":"code","e89ac560":"code","896fc0f6":"code","b8f365f1":"code","2eca7cc6":"code","34aaf6ad":"code","61c33b98":"code","e34cc769":"code","8be6a5cb":"code","93541f40":"code","0389f486":"code","045e9ae6":"code","4bf6509d":"code","8e61389e":"code","367b0b39":"code","4342011a":"code","937864cc":"code","02aae094":"code","2ca4f701":"code","e6003098":"code","48f4abfb":"code","3bd99b23":"code","02e6da04":"code","d15ed5ca":"markdown","52a25cd9":"markdown","6a65cb3c":"markdown","7b7e7a43":"markdown","b980cdad":"markdown","caab3861":"markdown","90b38eae":"markdown","2f9121b5":"markdown","bf7f0de8":"markdown","492680da":"markdown","76515538":"markdown","226f6f7e":"markdown","8ea99bfb":"markdown","da001402":"markdown"},"source":{"0824f372":"import numpy as np \nimport pandas as pd\nimport matplotlib.pylab as plt\nimport os\nfrom os import listdir\nfrom os.path import isfile, join","dbc3a830":"# Resized images directory\ndir_2019_images = \"\/kaggle\/input\/resizedsiimisic\/train_resized\/\"\nimages_2019 = [f for f in listdir(dir_2019_images) if isfile(join(dir_2019_images, f))]\n\n# CSV file\ntrain_df = pd.read_csv('\/kaggle\/input\/resizedsiimisic\/train.csv')","003930e0":"train_df.head()","1bfff594":"print(\"Train shape:\", train_df.shape)","e839fc9c":"from sklearn.utils import class_weight as cw\n\ny_train = train_df['target'].to_numpy()\nclass_weight_ = cw.compute_class_weight('balanced',\n                                        np.unique(y_train),\n                                        y_train)\nprint(class_weight_)","037159e6":"class_weight_ = {0:class_weight_[0], 1:class_weight_[1]}","4aa3cb7d":"from collections import Counter\nfrom sklearn.model_selection import train_test_split\n\nX = train_df\ny = train_df['target']","e37247b8":"# Split into train, validation test and calibration sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.2, \n                                                    stratify=y,\n                                                    random_state=42)\n\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n                                                  test_size=0.2,\n                                                  stratify=y_train,\n                                                  random_state=42)\n\nX_test, X_calib, y_test, y_calib = train_test_split(X_test, y_test, \n                                                    test_size=0.4,\n                                                    stratify=y_test,\n                                                    random_state=42)\n\n\nprint(\"Conjunto de train:\", X_train.shape)\nprint(\"Conjunto de validacion:\", X_val.shape)\nprint(\"Conjunto de prueba:\", X_test.shape)\nprint(\"Conjunto de calibracion:\", X_calib.shape)\nprint(\"-----------------------\")\nprint('Distribucion de train ->', Counter(y_train))\nprint('Distribucion de validacion ->', Counter(y_val))\nprint(\"Distribucion de prueba ->\", Counter(y_test))\nprint(\"Distribucion de calibracion ->\", Counter(y_calib))","79c0964b":"X_train.to_csv('\/kaggle\/working\/train.csv', index=False)\nX_val.to_csv('\/kaggle\/working\/val.csv', index=False)\nX_calib.to_csv('\/kaggle\/working\/calib.csv', index=False)\nX_test.to_csv('\/kaggle\/working\/test.csv', index=False)","6f8b9b55":"X_train[\"target\"] = X_train['target'].astype(str)\nX_val[\"target\"] = X_val['target'].astype(str)\nX_calib[\"target\"] = X_calib['target'].astype(str)\nX_test[\"target\"] = X_test['target'].astype(str)","da9c1a64":"import tensorflow as tf\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import DenseNet121\nfrom tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.metrics import TruePositives, FalsePositives, TrueNegatives, FalseNegatives, AUC\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.models import Model","daa79d11":"datagen = ImageDataGenerator(rescale=1.\/255.)\n\ntrain_generator = datagen.flow_from_dataframe(\n    dataframe=X_train,\n    directory=dir_2019_images,\n    x_col=\"image_name\",\n    y_col=\"target\",\n    batch_size=32,\n    seed=42,\n    shuffle=True,\n    class_mode=\"binary\"\n)\n\nvalid_generator = datagen.flow_from_dataframe(\n    dataframe=X_val,\n    directory=dir_2019_images,\n    x_col=\"image_name\",\n    y_col=\"target\",\n    batch_size=32,\n    seed=42,\n    shuffle=True,\n    class_mode=\"binary\"\n)\n\ncalib_generator=datagen.flow_from_dataframe(\n    dataframe=X_calib,\n    directory=dir_2019_images,\n    x_col=\"image_name\",\n    y_col=\"target\",\n    batch_size=32,\n    seed=42,\n    shuffle=True,\n    class_mode=\"binary\"\n)\n\ntest_generator = datagen.flow_from_dataframe(\n    dataframe=X_test,\n    directory=dir_2019_images,\n    x_col=\"image_name\",\n    y_col=\"target\",\n    batch_size=32,\n    seed=42,\n    shuffle=False,\n    class_mode=\"binary\"\n)\n\nSTEP_SIZE_TRAIN = train_generator.n\/\/train_generator.batch_size\nSTEP_SIZE_VALID = valid_generator.n\/\/valid_generator.batch_size\nSTEP_SIZE_CALIB=calib_generator.n\/\/calib_generator.batch_size\nSTEP_SIZE_TEST = test_generator.n\/\/test_generator.batch_size","b276ec2f":"encoder = DenseNet121(input_shape=(None,None,3), \n                      include_top=False, \n                      weights='imagenet')","6543ff6b":"inputs = Input(shape=(None, None, 3))\nx = encoder(inputs, training=False)\nx = GlobalAveragePooling2D()(x)\npredictions = Dense(1, activation='sigmoid')(x)\nmodel_weighted_loss = Model(inputs=inputs, outputs=predictions)","64569e19":"model_weighted_loss.summary()","fbd39872":"METRICS = [\n      TruePositives(name='tp'),\n      FalsePositives(name='fp'),\n      TrueNegatives(name='tn'),\n      FalseNegatives(name='fn'),\n      AUC(name='auc')\n]","614bc341":"checkpoint_filepath = '\/kaggle\/working\/weighted_model.h5'\nmodel_checkpoint_callback = ModelCheckpoint(filepath=checkpoint_filepath,\n                                            monitor='val_auc',\n                                            mode='max',\n                                            verbose=1,\n                                            save_best_only=True)","d300dddd":"model_weighted_loss.compile(\n    optimizer=Adam(),\n    loss=BinaryCrossentropy(),\n    metrics=METRICS\n)","c8383f25":"history = model_weighted_loss.fit(train_generator,  \n                                  validation_data=valid_generator,\n                                  steps_per_epoch=STEP_SIZE_TRAIN, \n                                  validation_steps=STEP_SIZE_VALID,\n                                  class_weight=class_weight_,\n                                  callbacks=[model_checkpoint_callback],\n                                  epochs = 100)","24e2a96e":"plt.plot(history.history['auc'], \n         label='Training AUC (area = {:.3f})'.format(history.history['auc'][-1]))\nplt.plot(history.history['val_auc'], \n         label='Validation AUC ( area = {:.3f})'.format(history.history['val_auc'][-1]))\nplt.title('Model weighted loss')\nplt.ylabel('AUC')\nplt.xlabel('epoch')\nplt.grid()\nplt.legend(loc='best')\n\nplt.show()","83888635":"plt.plot(history.history['loss'], label='Training loss (loss = {:.3f})'.format(history.history['loss'][-1]))\nplt.plot(history.history['val_loss'], label='Validation loss (loss = {:.3f})'.format(history.history['val_loss'][-1]))\nplt.title('Model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.grid()\nplt.legend(loc='best')\n\nplt.show()","2c18f1d8":"eval_metrics = model_weighted_loss.evaluate(test_generator, \n                                            steps=STEP_SIZE_TEST,\n                                            return_dict=True,\n                                            # use_multiprocessing=False,\n                                            verbose=1)","47cb9b8b":"true_labels = test_generator.classes\npredict = model_weighted_loss.predict(test_generator, \n                                      verbose=1)","8ca5d0d4":"from sklearn import metrics\nimport scikitplot as skplt\n\nfpr, tpr, tr = metrics.roc_curve(true_labels,predict)\nauc = metrics.roc_auc_score(true_labels, predict)\nplt.plot(fpr,tpr,'b',label=\"AUC=\"+str(auc))\nplt.plot([0,1],[0,1],'k--')\nplt.title('Test evaluation')\nplt.grid()\nplt.legend(loc='best')\nplt.show()","5682949d":"import seaborn as sns\n\ncm = [eval_metrics['tn'],eval_metrics['fp'],eval_metrics['fn'],eval_metrics['tp']]\n\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in cm]\ngroup_percentages = [\"{0:.2%}\".format(value) for value in cm\/np.sum(cm)]\nlabels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\nlabels = np.asarray(labels).reshape(2,2)\n\nsns.heatmap([[cm[0], cm[1]], [cm[2], cm[3]]], annot=labels, fmt='', cmap='Greens')","948d0b14":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.isotonic import IsotonicRegression\nfrom sklearn.metrics import brier_score_loss, log_loss\n!pip install ml_insights\nimport ml_insights as mli\n!pip install betacal\nfrom betacal import BetaCalibration","07c22d1d":"true_labels_test = y_test\npredict_weighted_test = model_weighted_loss.predict(test_generator, verbose=1)\n\ntrue_labels_calib = y_calib\npredict_weighted_calib = model_weighted_loss.predict(calib_generator, verbose=1)","269e8944":"print('Calibracion Brier Score:', brier_score_loss(true_labels_calib, predict_weighted_calib))\nprint(\"-----------------------\")\nprint('Test Brier Score:', brier_score_loss(true_labels_test, predict_weighted_test))","955f2fe9":"def plot_reliability_diagram(true_labels, predict_labels):\n    plt.figure(figsize=(15,5))\n    rd = mli.plot_reliability_diagram(true_labels, predict_labels, show_histogram=True)\n    return rd","b8b9fbb6":"rd = plot_reliability_diagram(np.array(true_labels_calib), predict_weighted_calib.ravel())\nplt.title('Reliability Diagram on Calibration Data')","e89ac560":"rd = plot_reliability_diagram(np.array(true_labels_test),predict_weighted_test.ravel())\nplt.title('Reliability Diagram on Test Data')","896fc0f6":"# Fit Platt scaling (logistic calibration)\nlr = LogisticRegression(C=99999999999, solver='lbfgs')\nlr.fit(predict_weighted_calib.reshape(-1,1), np.array(true_labels_calib))","b8f365f1":"calibset_platt_probs = lr.predict_proba(predict_weighted_calib.reshape(-1,1))[:,1]\ntestset_platt_probs = lr.predict_proba(predict_weighted_test.reshape(-1,1))[:,1]","2eca7cc6":"iso = IsotonicRegression(out_of_bounds = 'clip')\niso.fit(predict_weighted_calib.ravel(), np.array(true_labels_calib))","34aaf6ad":"calibset_iso_probs = iso.predict(predict_weighted_calib.ravel())\ntestset_iso_probs = iso.predict(predict_weighted_test.ravel())","61c33b98":"# Fit three-parameter beta calibration\nbc = BetaCalibration()\nbc.fit(predict_weighted_calib.ravel(), np.array(true_labels_calib))","e34cc769":"calibset_bc_probs = bc.predict(predict_weighted_calib.ravel())\ntestset_bc_probs = bc.predict(predict_weighted_test.ravel())","8be6a5cb":"# Define SplineCalib object\nsplinecalib = mli.SplineCalib()\nsplinecalib.fit(predict_weighted_calib.ravel(), np.array(true_labels_calib))","93541f40":"calibset_splinecalib_probs = splinecalib.predict(predict_weighted_calib.ravel())\ntestset_splinecalib_probs = splinecalib.predict(predict_weighted_test.ravel())","0389f486":"mli.plot_reliability_diagram(np.array(true_labels_test), predict_weighted_test.ravel())\nplt.title('Reliability Diagram on Test Data\\n before Platt Calibration')","045e9ae6":"mli.plot_reliability_diagram(np.array(true_labels_test), testset_platt_probs)\nplt.title('Reliability Diagram on Test Data\\n after Platt Calibration')","4bf6509d":"mli.plot_reliability_diagram(np.array(true_labels_calib), predict_weighted_calib.ravel())\n#tvec = np.linspace(.01, .99, 99)\n#plt.plot(tvec, iso.predict(tvec), label='Isotonic')\nplt.title('Isotonic Calibration Curve on Calibration Data')","8e61389e":"mli.plot_reliability_diagram(np.array(true_labels_test), predict_weighted_test.ravel())\n#tvec = np.linspace(.01, .99, 99)\n#plt.plot(tvec, iso.predict(tvec), label='Isotonic')\nplt.title('Isotonic Calibration Curve on Test Data')","367b0b39":"mli.plot_reliability_diagram(np.array(true_labels_test), testset_iso_probs)\nplt.title('Reliability Diagram on Test Data\\n after Isotonic Calibration')","4342011a":"mli.plot_reliability_diagram(np.array(true_labels_calib), predict_weighted_calib.ravel())\n#tvec = np.linspace(.01, .99, 99)\n#plt.plot(tvec, bc.predict(tvec))\nplt.title('Beta Calibration Curve on Calibration Set')","937864cc":"mli.plot_reliability_diagram(np.array(true_labels_test), predict_weighted_test.ravel())\n#tvec = np.linspace(.01, .99, 99)\n#plt.plot(tvec, bc.predict(tvec))\nplt.title('Beta Calibration Curve on Test Set')","02aae094":"mli.plot_reliability_diagram(np.array(true_labels_test), testset_bc_probs)\nplt.title('Reliability Diagram on Test Data\\n after Beta Calibration')","2ca4f701":"mli.plot_reliability_diagram(np.array(true_labels_calib), predict_weighted_calib.ravel())\n#tvec = np.linspace(.01, .99, 99)\n#plt.plot(tvec, splinecalib.predict(tvec))\nplt.title('SplineCalib Calibration Curve on Calibration Set')","e6003098":"mli.plot_reliability_diagram(np.array(true_labels_test), predict_weighted_test.ravel())\n#tvec = np.linspace(.01, .99, 99)\n#plt.plot(tvec, splinecalib.predict(tvec))\nplt.title('SplineCalib Calibration Curve on Test Set')","48f4abfb":"mli.plot_reliability_diagram(np.array(true_labels_test), testset_splinecalib_probs)\nplt.title('Reliability Diagram on Test Data\\n after SplineCalib Calibration')","3bd99b23":"print('Uncalibrated log_loss = {}'.format(log_loss(true_labels_test, predict_weighted_test.ravel())))\nprint('Platt calibrated log_loss = {}'.format(log_loss(true_labels_test, testset_platt_probs)))\nprint('Isotonic calibrated log_loss = {}'.format(log_loss(true_labels_test, testset_iso_probs)))\nprint('Beta calibrated log_loss = {}'.format(log_loss(true_labels_test, testset_bc_probs)))\nprint('Spline calibrated log_loss = {}'.format(log_loss(true_labels_test, testset_splinecalib_probs)))","02e6da04":"print('Uncalibrated Brier Score = {}'.format(brier_score_loss(true_labels_test, predict_weighted_test.ravel())))\nprint('Platt calibrated Brier Score = {}'.format(brier_score_loss(true_labels_test, testset_platt_probs)))\nprint('Isotonic calibrated Brier Score = {}'.format(brier_score_loss(true_labels_test, testset_iso_probs)))\nprint('Beta calibrated Brier Score = {}'.format(brier_score_loss(true_labels_test, testset_bc_probs)))\nprint('Spline calibrated Brier Score = {}'.format(brier_score_loss(true_labels_test, testset_splinecalib_probs)))","d15ed5ca":"## <font color=red>5. <\/font>Calibraci\u00f3n del modelo","52a25cd9":"# Modelo con funci\u00f3n de p\u00e9rdida ponderada","6a65cb3c":"#### Finalmente, se observa la curva ROC-AUC y la matriz de confusi\u00f3n.","7b7e7a43":"#### Comparaci\u00f3n de los m\u00e9todos de calibraci\u00f3n","b980cdad":"#### M\u00e9todo 2: Isotonic Regression","caab3861":"#### M\u00e9todo 4: SplineCalib","90b38eae":"#### M\u00e9todo 3: Beta Calibration","2f9121b5":"## <font color=red>2. <\/font> Funci\u00f3n de p\u00e9rdida ponderada","bf7f0de8":"#### M\u00e9todo 1: Platt Scaling","492680da":"## <font color=red>3. <\/font>Crear y entrenar el modelo","76515538":"## <font color=red>1. <\/font>Cargar las im\u00e1genes y los datos tabulares","226f6f7e":"#### Se obtiene las predicciones y las etiquetas del conjunto de prueba.","8ea99bfb":"## <font color=red>4. <\/font>Evaluar el modelo","da001402":"#### M\u00e9tricas"}}