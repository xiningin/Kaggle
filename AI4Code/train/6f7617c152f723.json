{"cell_type":{"5464540f":"code","f0944091":"code","b2f51156":"code","fdd62b6e":"code","4edbd1c9":"code","e047d756":"code","aa090915":"code","8ddcb3e0":"code","c8db285a":"code","ffcfed09":"code","55f60d18":"code","447c90ef":"code","aa295d81":"code","98f0117c":"code","0a8df46c":"code","c8f90768":"code","04eb0bf1":"code","5dfa3987":"code","31b33c33":"code","a0648fc3":"code","c0d667bd":"code","0a1ac31d":"code","eab2a8fd":"code","cb83f4a3":"code","ada00d04":"code","f66dc9fc":"code","2ea8e25f":"code","c791f91c":"code","844ede5a":"code","6e260afd":"code","396582d5":"code","3a61ba79":"code","ab0878d8":"code","a7161443":"code","8ce3dfce":"code","5fcdceec":"code","98211c76":"code","7de44a03":"code","17f43954":"code","119c80ad":"code","eea47d8c":"code","214f5306":"code","33782275":"code","c1dfee20":"markdown","30b9e0e8":"markdown"},"source":{"5464540f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f0944091":"import numpy as np \nimport pandas as pd \n%matplotlib inline\nimport matplotlib.pyplot as plt\n# plt.style.use('ggplot')\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\n","b2f51156":"# Reading Data from CSV file\n\nx = pd.read_csv('..\/input\/neolen-house-price-prediction\/train.csv') \ny = pd.read_csv('..\/input\/neolen-house-price-prediction\/test.csv')\n\n# z = pd.read_csv(\"C:\\\\Users\\\\hp\\\\Desktop\\\\House price prediction\\\\sample_submission.csv\")\n","fdd62b6e":"x.info()\nx.head()\n","4edbd1c9":"display(x.describe())\nprint('shape : ',x.shape)","e047d756":"display(y.describe())\nprint('shape : ',x.shape)","aa090915":"x.SalePrice.hist(bins=50, rwidth=0.6, figsize=(20,10))\nplt.title('Price of the Houses')\nplt.show()\n","8ddcb3e0":"plt.hist(x['SalePrice'], color = 'green')","c8db285a":"sns.distplot(x['SalePrice'], color = 'red')","ffcfed09":"sns.pairplot(x[[\"SalePrice\", \"LotArea\", \"YearBuilt\", \"1stFlrSF\", \"2ndFlrSF\", \"FullBath\", \"BedroomAbvGr\", \"TotRmsAbvGrd\"]], diag_kind=\"kde\")\n# sns.heatmap(x.corr(), annot = True)","55f60d18":"#checking if there is null values exist\nx.isnull().any()","447c90ef":"x.isnull().sum()\nnulls = x.isnull().sum().sort_values(ascending=False)\nnulls","aa295d81":"mis_val_percent = 100 * x.isnull().sum() \/ len(x)\nmis_val_percent","98f0117c":"mis_val_percent = 100 * y.isnull().sum() \/ len(y)\nmis_val_percent","0a8df46c":"Y = x[['SalePrice']]\nx = x.drop(['SalePrice','Alley','PoolQC','Fence','MiscFeature','FireplaceQu'],axis = 1)\n","c8f90768":"y.isnull().sum()","04eb0bf1":"y = y.drop(['Alley','PoolQC','Fence','MiscFeature','FireplaceQu'],axis = 1)","5dfa3987":"#Looking Into the Data\nprint('Our training dataset has {} rows and {} columns'.format(x.shape[0],x.shape[1]))\nprint('Our Test data has {} rows and {} columns'.format(y.shape[0],y.shape[1]))","31b33c33":"#get a list of columns with null values\n# x.columns[x.isnull().any()].tolist()\n","a0648fc3":"x_num = x.select_dtypes(exclude=['object'])\n\nfrom sklearn.impute import SimpleImputer\n# initiate an Imputer\nimputer = SimpleImputer(missing_values=np.nan, strategy='median')\n# start imputing\nx_imputed = imputer.fit_transform(x_num)\n# convert to dataframe again\nx_numerical = pd.DataFrame(x_imputed, columns=x_num.columns)\nx_numerical","c0d667bd":"y_num = y.select_dtypes(exclude=['object'])\n\nfrom sklearn.impute import SimpleImputer\n# initiate an Imputer\nimputer = SimpleImputer(missing_values=np.nan, strategy='median')\n# start imputing\ny_imputed = imputer.fit_transform(y_num)\n# convert to dataframe again\ny_numerical = pd.DataFrame(y_imputed, columns=y_num.columns)\ny_numerical","0a1ac31d":"x_object = x.select_dtypes('object')\n# initiate an Imputer\nimputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n# start imputing\nx_imputed = imputer.fit_transform(x_object)\n# convert to dataframe again\nx_categorical = pd.DataFrame(x_imputed, columns=x_object.columns)","eab2a8fd":"y_object = y.select_dtypes('object')\n# initiate an Imputer\nimputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n# start imputing\ny_imputed = imputer.fit_transform(y_object)\n# convert to dataframe again\ny_categorical = pd.DataFrame(y_imputed, columns=y_object.columns)\ny_categorical.info()","cb83f4a3":"# # x_object = pd.get_dummies(x_object)\n# # x_object.head()\n# x_enc = pd.get_dummies(x)\n# x_enc\n# x_enc.columns","ada00d04":"# y_enc = pd.get_dummies(y)\n# y_enc\n# y_enc.columns","f66dc9fc":"# using LabelEncoder to handle Categorical features\nfrom sklearn.preprocessing import LabelEncoder\ncols = ['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities',\n       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n       'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n       'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n       'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n       'Functional', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n       'PavedDrive', 'SaleType', 'SaleCondition']\nx_categorical[cols] = x_categorical[cols].apply(LabelEncoder().fit_transform)\nx_categorical.dtypes","2ea8e25f":"from sklearn.preprocessing import LabelEncoder\ncols = ['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities',\n       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n       'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n       'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n       'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n       'Functional', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n       'PavedDrive', 'SaleType', 'SaleCondition']\ny_categorical[cols] = y_categorical[cols].apply(LabelEncoder().fit_transform)\ny_categorical","c791f91c":"x = pd.concat([x_numerical, x_categorical], axis=1)\ny = pd.concat([y_numerical, y_categorical], axis=1)\n\ny.isnull().any()","844ede5a":"#using sklearn \"simpleimputer\" to get rid of the null values using most_frequent strategy\nfrom sklearn.impute import SimpleImputer\n# initiate an Imputer\nimputer = SimpleImputer(missing_values=np.nan, strategy='median')\n# start imputing\nx_imputed = imputer.fit_transform(x)\n# convert to dataframe again\nx_imputed = pd.DataFrame(x_imputed, columns=x.columns)\nx_imputed","6e260afd":"#using sklearn \"simpleimputer\" to get rid of the null values using most_frequent strategy\nfrom sklearn.impute import SimpleImputer\n# initiate an Imputer\nimputer = SimpleImputer(missing_values=np.nan, strategy='median')\n# start imputing\ny_imputed = imputer.fit_transform(y)\n# convert to dataframe again\ny_imputed = pd.DataFrame(y_imputed, columns=y.columns)\ny_imputed","396582d5":"#check if there is null values\n# x_imputed.isnull().sum()\n","3a61ba79":"#check if there is null values\n# y_imputed.isnull().sum()","ab0878d8":"# # Splitting data\n\nXx = x_imputed[[\"LotArea\", \"YearBuilt\", \"1stFlrSF\", \"2ndFlrSF\", \"FullBath\", \"BedroomAbvGr\", \"TotRmsAbvGrd\"]].astype(float)\nfrom sklearn.preprocessing import StandardScaler\n# Create the scaler\ns = StandardScaler()\n# Scaled data \nX_imputed = s.fit_transform(Xx)\n# #create a dataframe\nx_col=list(Xx.columns.values)\nX_imputedd = pd.DataFrame(X_imputed , columns = x_col).astype(float)\nX_imputedd","a7161443":"# Splitting data\nYy = y_imputed[[\"LotArea\", \"YearBuilt\", \"1stFlrSF\", \"2ndFlrSF\", \"FullBath\", \"BedroomAbvGr\", \"TotRmsAbvGrd\"]].astype(float)# from sklearn.preprocessing import StandardScaler\n# Create the scaler\ns = StandardScaler()\n# Scaled data \nY_imputed = s.fit_transform(Yy)\n# #create a dataframe\ny_col=list(Yy.columns.values)\nY_imputedd = pd.DataFrame(Y_imputed , columns = y_col).astype(float)\n# Y_imputedd = pd.DataFrame(Y_imputed, columns = [\"LotArea\", \"YearBuilt\", \"1stFlrSF\", \"2ndFlrSF\", \"FullBath\", \"BedroomAbvGr\", \"TotRmsAbvGrd\"])\nY_imputedd","8ce3dfce":"X_imputedd.head()","5fcdceec":"Y_imputedd.head()","98211c76":"# corr_matrix = X_imputedd.corr().abs()\n# upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape),k=1).astype(np.bool))\n# to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.95)]\n# X_imputedd = X_imputedd.drop(X_imputedd.columns[to_drop], axis=1)\n# Y.info()\n# Y_imputedd = Y_imputedd.drop(['Id'],axis = 1)\n# X_imputedd = X_imputedd.drop(['Id'],axis = 1)\n","7de44a03":"# using test_train_split from sklearn to split data to \"train\" and \"test\"\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X_imputedd, Y,  train_size=0.7, test_size=0.3, random_state =0)\nx_train.head()","17f43954":"from sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nmodel.fit(x_train, y_train)\n\nr_sq = model.score(x_train, y_train)\nprint(r_sq*100, \"%\")\nprint('intercept:', model.intercept_)\nprint('slope:', model.coef_)\nprint('='*50)\n# How to use your model for pridection\ny_pred = model.predict(x_test)\ny_pred","119c80ad":"from sklearn.metrics import mean_squared_error \n# from sklearn import mean_squared_log_error\n\nfrom math import sqrt\n\nRMSE = sqrt(mean_squared_error(y_test, y_pred))\nRMSE","eea47d8c":"plt.scatter(y_test, y_pred)","214f5306":"# model.fit(X_imputedd, Y)\ny_pred = model.predict(Y_imputedd)\ny_pred","33782275":"y_pred = np.squeeze(y_pred)\ny_pred.shape\n# # Save test predictions to file\noutput = pd.DataFrame({'Id': y.Id,\n                     'SalePrice': y_pred})\noutput.to_csv('submissionsfinalll.csv', index=False)","c1dfee20":"# **Reading Data From csv file**","30b9e0e8":"# **Importing libraries**"}}