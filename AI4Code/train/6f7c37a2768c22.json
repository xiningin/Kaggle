{"cell_type":{"fb076ca5":"code","2025c911":"code","7b4d0e5e":"code","10a14474":"code","724b190a":"code","a71d77b3":"code","db73cc0b":"code","ee4f3508":"code","8059b8b7":"code","39e33e8f":"code","2717d066":"code","28e675cb":"code","0b4a088a":"code","621767b6":"code","d9f5800d":"code","88e49723":"code","4ff077cd":"code","a15b6ad8":"code","d43f76c0":"code","105510f9":"code","4167770f":"code","2f4b6483":"code","0b475789":"code","9c9eb5e4":"code","4991ef72":"code","a5c936f7":"code","e140f8d6":"code","e17860e7":"code","04499fb0":"code","0ff29f60":"code","93695901":"code","1a88fa2f":"code","7003adaa":"code","33e735fc":"code","ad87a9c9":"code","615cba15":"code","840991f8":"code","b033416b":"code","a985e9a2":"code","5e5a46f4":"code","a7cc3ab3":"code","96400f49":"code","7bb207c4":"code","e12f4f48":"code","5b55b59e":"code","c932f739":"code","89d3c6e4":"code","3f61f461":"code","6395f4c9":"code","3b468b30":"code","271b00c9":"code","434d3c9a":"code","8f19ca86":"code","7b4456ac":"code","a02202f3":"code","1c3d545d":"markdown","1cc1b240":"markdown","09786ad8":"markdown","8efe80bb":"markdown","6bd63f21":"markdown","ff6ea7cf":"markdown","8dab7351":"markdown","11e41f09":"markdown","5a9b7d40":"markdown","2845e1e7":"markdown","4545b262":"markdown","86e10b62":"markdown","f517b30c":"markdown"},"source":{"fb076ca5":"# NumPy\u306e\u8aad\u307f\u8fbc\u307f\nimport numpy as np\n# Pandas\u306e\u8aad\u307f\u8fbc\u307f\nimport pandas as pd \n# OS\u30e2\u30b8\u30e5\u30fc\u30eb:\u30d7\u30ed\u30b0\u30e9\u30e0\u306e\u4e2d\u3067OS\u306e\u6642\u9593\u3092\u5229\u7528\u3057\u305f\u308a\u3001\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u30a2\u30af\u30bb\u30b9\u3057\u3066\u30d5\u30a1\u30a4\u30eb\u306e\u4f5c\u6210\/\u7de8\u96c6\/\u524a\u9664\u306a\u3069\u304c\u3067\u304d\u308b\nimport os\n# OpenCV:\u753b\u50cf\u3092\u51e6\u7406\u3059\u308b\u306e\u306b\u5fc5\u8981\u306a\u69d8\u3005\u306a\u6a5f\u80fd\u3092\u63d0\u4f9b\u3059\u308b\u30e9\u30a4\u30d6\u30e9\u30ea\nimport cv2\n# matplotlib:NumPy\u306e\u305f\u3081\u306e\u30b0\u30e9\u30d5\u63cf\u753b\u30d1\u30c3\u30b1\u30fc\u30b8\n# pyplot:\u307b\u3057\u3044\u30d7\u30ed\u30c3\u30c8\u3092\u4f5c\u308b\u305f\u3081\u306b\u6697\u9ed9\u7684\u304b\u3064\u81ea\u52d5\u7684\u306b\u56f3\u5f62\u3084\u8ef8\u3092\u4f5c\u6210\u3059\u308b\u30e2\u30b8\u30e5\u30fc\u30eb\nfrom matplotlib import pyplot as plt\n# TPU\u306e\u5834\u5408\u3001\u30c7\u30fc\u30bf\u306fGoogle Cloud Storage\u306e\u307f\u30a2\u30af\u30bb\u30b9\u3067\u304d\u308b\u305f\u3081\u3001\u4f7f\u7528\nfrom kaggle_datasets import KaggleDatasets\n\n# tensorflow:\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u4e3b\u306a\u30e9\u30a4\u30d6\u30e9\u30ea\n# keras:\u5358\u4f53\u3067\u306f\u4f7f\u3046\u3053\u3068\u306e\u3067\u304d\u306a\u3044\u30e9\u30a4\u30d6\u30e9\u30ea\u3002tensorflow\u304c\u5fc5\u8981\nimport tensorflow as tf\n# Sequential:\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u3092\u7c21\u7565\u5316\u3059\u308b\u30e2\u30c7\u30eb\u306e\u4e00\u3064\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers as L\nfrom tensorflow.keras.utils import to_categorical\n\n# train_test_split:train\u30c7\u30fc\u30bf\u3068test\u30c7\u30fc\u30bf\u306b\u5206\u3051\u308b\u30e2\u30b8\u30e5\u30fc\u30eb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn import metrics\n\n%matplotlib inline","2025c911":"# \n# TPU\u306e\u521d\u671f\u5316\n# \n# \u4f8b\u5916\u51e6\u7406\u306etry\ntry:\n#     TPU\u306e\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u60c5\u5831\u3092\u7372\u5f97\u3002TPU\u304c\u5229\u7528\u3067\u304d\u306a\u3044\u74b0\u5883\u3067\u306f\u30a8\u30e9\u30fc\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n#     TPU\u5229\u7528\u53ef\u80fd\u5316\u306e\u78ba\u8a8d\n    print('Running on TPU:', tpu.master())\n# \u4e0a\u8a18\u3067\u30a8\u30e9\u30fc\uff08\u4f8b\u5916\uff09\u304c\u51fa\u305f\u5834\u5408\u306e\u51e6\u7406\nexcept ValueError:\n    tpu = None\n\n# tpu\u304c\u5229\u7528\u3067\u304d\u308b\u5834\u5408\uff08Accelerator TPU\uff09\n# \u4e0a\u8a18\u3067None\u3067\u306a\u3044\u3068\u304d\nif tpu:\n#   \u30ea\u30e2\u30fc\u30c8\u30af\u30e9\u30b9\u30bf\u306b\u63a5\u7d9a\u3057\u3066TPU\u3092\u521d\u671f\u5316\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n#   \u30c7\u30fc\u30bf\u306e\u4e26\u5217\u51e6\u7406\u3092\u4f7f\u7528\u3057\u3066\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3092\u5206\u6563\u3059\u308b\n#   TPU\u3067\u4e26\u5217\u51e6\u7406\u306e\u65b9\u6cd5\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n# TPU\u306a\u3057\u306e\u3068\u304d\uff08Accelerator None\uff09\nelse:\n    strategy = tf.distribute.get_strategy()\n\n# \u4e26\u5217\u51e6\u7406\u306e\u30ec\u30d9\u30eb\u306b\u95a2\u3059\u308b\u6c7a\u5b9a\u3092AUTO\u3067\u884c\u3046\nAUTO = tf.data.experimental.AUTOTUNE\n# TPU\u306fGCS(Google Cloud Storage)\u306b\u306e\u307f\u30a2\u30af\u30bb\u30b9\u3067\u304d\u308b\u3002\nGCS_DS_PATH = KaggleDatasets().get_gcs_path()\n\n# \u30df\u30cb\u30d0\u30c3\u30c1\u52fe\u914d\u964d\u4e0b\u6cd5\u3092\u884c\u3046\u969b\u3001\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u5e7e\u3064\u304b\u306e\u30b5\u30d6\u30bb\u30c3\u30c8\u306b\u5206\u3051\u308b\n# \u30b5\u30d6\u30bb\u30c3\u30c8\u306e\u52fe\u914d\u306e\u5e73\u5747\u3067\u91cd\u307f\u3092\u66f4\u65b0\u3059\u308b\n# \u305d\u306e\u30b5\u30d6\u30bb\u30c3\u30c8\u306e\u5927\u304d\u3055\u3092Batch Size\u3068\u547c\u3076\n# strategy.num_replicas_in_sync\u306fstrategy\u306e\u5206\u5272\u3057\u305fTPU\u30ec\u30d7\u30ea\u30ab\u306e\u6570\u3092\u8868\u3059\u3002\n# TPU\u304c\u4f7f\u7528\u53ef\u80fd\u306a\u5834\u5408\u3001\u30ec\u30d7\u30ea\u30ab\u6570\u306f8\u3067\u3042\u308b\u304b\u30898\u500d\u3057\u305f\u6570\u3092\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u3068\u3059\u308b\u3002\n# TPU\u4f7f\u7528\u4e0d\u53ef\u306e\u6642\u3001\u30ec\u30d7\u30ea\u30ab\u6570\u306f1\u3068\u306a\u308a\u3001\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u306f8\nBATCH_SIZE = 8 * strategy.num_replicas_in_sync\nIMG_SIZE = 768\n\nprint('Batch size:', BATCH_SIZE)","7b4d0e5e":"train = pd.read_csv('\/kaggle\/input\/plant-pathology-2020-fgvc7\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/plant-pathology-2020-fgvc7\/test.csv')\nsub = pd.read_csv('\/kaggle\/input\/plant-pathology-2020-fgvc7\/sample_submission.csv')\n\nprint(train.head())\n\n# GCS\u3067image\u306e\u30d1\u30b9\u6307\u5b9a\ntrain_path = train.image_id.apply(lambda x: f'{GCS_DS_PATH}\/images\/{x}.jpg').values\ntest_path = test.image_id.apply(lambda x: f'{GCS_DS_PATH}\/images\/{x}.jpg').values\n# train\u306eimage_id\u3092\u524a\u9664\u3057\u3001array\u306b\ntrain_label = train.loc[:, 'healthy':].values\n\n# train_path, valid_path, train_label, valid_label = train_test_split(train_path, train_label,\n#                                                                     test_size=0.1, stratify=train_label)","10a14474":"# weight\u3092\u304b\u3051\u308b\u3068\u5168\u30c7\u30fc\u30bf\u6570\u306e1\/4\u306b\u306a\u308b\n# n_samples[1821] \/ (n_classes[4] * np.bincount(y)[healthy:516\/multi:91\/rust:622\/scab:592])\nclass_weight = compute_class_weight('balanced', np.unique(np.argmax(train_label, axis=1)), np.argmax(train_label, axis=1))\n# barplot\u306e\u4f5c\u6210\nplt.bar(range(4), class_weight)","724b190a":"# 2\u00d72\u3067\u8868\u793a\nfig, ax = plt.subplots(2, 2)\n# \u30b5\u30f3\u30d7\u30eb\u8aad\u307f\u8fbc\u307f\nimg = cv2.imread('\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/Train_0.jpg')\nimg1 = cv2.imread('\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/Train_1.jpg')\nimg2 = cv2.imread('\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/Train_2.jpg')\nimg3 = cv2.imread('\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/Train_3.jpg')\n# \u5834\u6240\u6307\u5b9a\u3057\u305f\u66f8\u304d\u51fa\u3057\nax[0, 0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\nax[0, 1].imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\nax[1, 0].imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\nax[1, 1].imshow(cv2.cvtColor(img3, cv2.COLOR_BGR2RGB))","a71d77b3":"# \u30c7\u30b3\u30fc\u30c9\u306e\u5b9a\u7fa9\ndef decode_image(filename, label=None, image_size=(IMG_SIZE, IMG_SIZE)):\n#     \u751f\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u307f\n    bits = tf.io.read_file(filename)\n#     \u753b\u50cf\u306e\u30c6\u30f3\u30bd\u30eb\u306b\u30c7\u30b3\u30fc\u30c9\n    image = tf.image.decode_jpeg(bits, channels=3)\n#     0-255\u306eRGB\u30920-1\u306b\u3059\u308bnormalize\n    image = tf.cast(image, tf.float32) \/ 255.0\n#     1365\u00d72048\u306e\u753b\u50cf\u3092\u3001768\u00d7768\u306b\u3059\u308b\n    image = tf.image.resize(image, image_size)\n    \n#     \u6761\u4ef6\u5f0f\u306e\u610f\u5473\u306f\u308f\u304b\u308a\u307e\u305b\u3093\u304c\u5909\u63db\u3057\u305fimage\u3092return\n    if label is None:\n        return image\n    else:\n        return image, label\n\n# augment\u306e\u5b9a\u7fa9\ndef data_augment(image, label=None):\n#     \u30e9\u30f3\u30c0\u30e0\u306b\u6c34\u5e73\u65b9\u5411\u306b\u53cd\u8ee2\n    image = tf.image.random_flip_left_right(image)\n#     \u30e9\u30f3\u30c0\u30e0\u306b\u5782\u76f4\u65b9\u5411\u306b\u53cd\u8ee2\n    image = tf.image.random_flip_up_down(image)\n    \n#     image\u3092return\n    if label is None:\n        return image\n    else:\n        return image, label","db73cc0b":"# \u6559\u5e2b\u30c7\u30fc\u30bf\u3092\u30c7\u30b3\u30fc\u30c9\ntrain_dataset = (\n#     TFR\u5f62\u5f0f\u3067\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u66f8\u304d\u3059\u308b\n    tf.data.TFRecordDataset\n#     \u914d\u5217\u3092\u30b9\u30e9\u30a4\u30b9\u3057\u3066\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u69cb\u7bc9\u3059\u308b\n    .from_tensor_slices((train_path, train_label))\n#     \u30c7\u30fc\u30bf\u5909\u63db\uff08\u30c7\u30b3\u30fc\u30c9\uff09\u3092\u4e26\u5217\u5316\u3057\u3066\u884c\u3046\n    .map(decode_image, num_parallel_calls=AUTO)\n#     \u30c7\u30fc\u30bf\u5909\u63db\uff08\u5897\u5e45\uff09\u3092\u4e26\u5217\u5316\u3059\u308b\n    .map(data_augment, num_parallel_calls=AUTO)\n#     \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u30e1\u30e2\u30ea\u304b\u30ed\u30fc\u30ab\u30b9\u30b9\u30c8\u30ec\u30fc\u30b8\u306b\u30ad\u30e3\u30c3\u30b7\u30e5\u3067\u304d\u308b\n    .cache()\n#     \u7e70\u308a\u8fd4\u3057\u3002shuffle\u306e\u524d\u306b\u3042\u308c\u3070EPOCH\u306e\u5883\u754c\u3092\u8d8a\u3048\u3066\u8981\u7d20\u304c\u30b7\u30e3\u30c3\u30d5\u30eb\u3055\u308c\u306a\u3044\n    .repeat()\n#     \u30b7\u30e3\u30c3\u30d5\u30eb\u30d0\u30c3\u30d5\u30a1\u306e\u30b5\u30a4\u30ba\u306f\u5927\u304d\u3044\u307b\u3069\u5b8c\u5168\u306b\u30b7\u30e3\u30c3\u30d5\u30eb\u3055\u308c\u308b\u3002\u203b\u30e9\u30f3\u30c0\u30e0\u8981\u7d20\n    .shuffle(1024)\n#     \u30d0\u30c3\u30c1\u5316\n    .batch(BATCH_SIZE)\n#     CPU\u3068TPU\u3067\u305d\u308c\u305e\u308c\u4e26\u5217\u306b\u51e6\u7406\u3092\u5b9f\u884c\n    .prefetch(AUTO)\n)\n\n# valid_dataset = (\n#     tf.data.TFRecordDataset\n#     .from_tensor_slices((valid_path, valid_label))\n#     .map(decode_image, num_parallel_calls=AUTO)\n#     .map(data_augment, num_parallel_calls=AUTO)\n#     .cache()\n#     .batch(BATCH_SIZE)\n#     .prefetch(AUTO)\n# )\n\n# \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u30c7\u30b3\u30fc\u30c9\ntest_dataset = (\n    tf.data.TFRecordDataset\n    .from_tensor_slices(test_path)\n    .map(decode_image, num_parallel_calls=AUTO)\n    .map(data_augment, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n)","ee4f3508":"EPOCHS = 40\nLR_START = 0.0001\nLR_MAX = 0.00005 * strategy.num_replicas_in_sync\nLR_MIN = 0.0001\nLR_RAMPUP_EPOCHS = 10\nLR_SUSTAIN_EPOCHS = 4\nLR_EXP_DECAY = .8\n\ndef lrfn(epoch):\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) \/ LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n    return lr\n\nlr = tf.keras.callbacks.LearningRateScheduler(lrfn)\n\ny = [lrfn(x) for x in range(EPOCHS)]\nplt.plot(y)","8059b8b7":"# # EfficientNet\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n# !pip install -q efficientnet","39e33e8f":"# # EfficientNetB7\u306e\u8aad\u307f\u8fbc\u307f\n# from efficientnet.tfkeras import EfficientNetB7\n\n# # model\u306e\u4f5c\u6210\u306fstrategy.scope\u4e0b\u3067\u884c\u3046\n# with strategy.scope():\n# #     \u5168\u7d50\u5408\u5c64\u3092\u542b\u3081\u306a\u3044\/noisy-student\u3067self training\/average pooling\/\u753b\u50cf\u30b5\u30a4\u30ba\u3068RGB\n#     efn7 = EfficientNetB7(include_top=False, weights='noisy-student', pooling='avg', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n# #     Sequential\u30e2\u30c7\u30eb\u3092\u4f5c\u6210\u3001\u5f8c\u308d\u306b\u5c64\u3092\u8ffd\u52a0\n#     model_efn7 = Sequential()\n# #     EfficientNet\u5c64\u3092Model\u306b\u8ffd\u52a0\n#     model_efn7.add(efn7)\n# #     \u3053\u3061\u3089\u3067\u5168\u7d50\u5408\u5c64\u3092\u8ffd\u52a0\u30014\u5024\u5206\u985e\u3001\u5206\u985e\u554f\u984c\u306e\u305f\u3081\u6d3b\u6027\u5316\u95a2\u6570\u306fsoftmax\n#     model_efn7.add(L.Dense(4, activation='softmax'))\n# #     model\u304c\u3069\u306e\u3088\u3046\u306b\u5b66\u7fd2\u3059\u308b\u304b\u3092\u6c7a\u3081\u308b\n# #     \u6700\u9069\u5316\u95a2\u6570adam\/\u640d\u5931\u95a2\u6570\u306f\u591a\u30af\u30e9\u30b9\u5206\u985e\u306e\u305f\u3081\u30af\u30ed\u30b9\u30a8\u30f3\u30c8\u30ed\u30d4\u30fc\/\u8a55\u4fa1\u95a2\u6570\u306f\u6b63\u89e3\u7387\uff08\u5b66\u7fd2\u306b\u306f\u5f71\u97ff\u3057\u306a\u3044\uff09\n#     model_efn7.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_efn7.summary())","2717d066":"# from efficientnet.tfkeras import EfficientNetB6\n\n# with strategy.scope():\n#     efn6 = EfficientNetB6(include_top=False, weights='noisy-student', pooling='avg', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_efn6 = Sequential()\n#     model_efn6.add(efn6)\n#     model_efn6.add(L.Dense(4, activation='softmax'))\n#     model_efn6.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_efn6.summary())","28e675cb":"# from efficientnet.tfkeras import EfficientNetB5\n\n# with strategy.scope():\n#     efn5 = EfficientNetB5(include_top=False, weights='noisy-student', pooling='avg', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_efn5 = Sequential()\n#     model_efn5.add(efn5)\n#     model_efn5.add(L.Dense(4, activation='softmax'))\n#     model_efn5.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_efn5.summary())","0b4a088a":"# from efficientnet.tfkeras import EfficientNetB4\n\n# with strategy.scope():\n#     efn4 = EfficientNetB4(include_top=False, weights='noisy-student', pooling='avg', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_efn4 = Sequential()\n#     model_efn4.add(efn4)\n#     model_efn4.add(L.Dense(4, activation='softmax'))\n#     model_efn4.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_efn4.summary())","621767b6":"# from efficientnet.tfkeras import EfficientNetB3\n\n# with strategy.scope():\n#     efn3 = EfficientNetB3(include_top=False, weights='noisy-student', pooling='avg', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_efn3 = Sequential()\n#     model_efn3.add(efn3)\n#     model_efn3.add(L.Dense(4, activation='softmax'))\n#     model_efn3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_efn3.summary())","d9f5800d":"# from efficientnet.tfkeras import EfficientNetB2\n\n# with strategy.scope():\n#     efn2 = EfficientNetB2(include_top=False, weights='noisy-student', pooling='avg', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_efn2 = Sequential()\n#     model_efn2.add(efn2)\n#     model_efn2.add(L.Dense(4, activation='softmax'))\n#     model_efn2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_efn2.summary())","88e49723":"# from efficientnet.tfkeras import EfficientNetB1\n\n# with strategy.scope():\n#     efn1 = EfficientNetB1(include_top=False, weights='noisy-student', pooling='avg', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_efn1 = Sequential()\n#     model_efn1.add(efn1)\n#     model_efn1.add(L.Dense(4, activation='softmax'))\n#     model_efn1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_efn1.summary())","4ff077cd":"# from tensorflow.keras.applications import DenseNet121\n\n# with strategy.scope():\n#     dnn121 = DenseNet121(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_dnn121 = Sequential()\n#     model_dnn121.add(dnn121)\n#     model_dnn121.add(L.GlobalAveragePooling2D())\n#     model_dnn121.add(L.Dense(4, activation='softmax'))\n#     model_dnn121.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_dnn121.summary())","a15b6ad8":"# from tensorflow.keras.applications import DenseNet169\n\n# with strategy.scope():\n#     dnn169 = DenseNet169(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_dnn169 = Sequential()\n#     model_dnn169.add(dnn169)\n#     model_dnn169.add(L.GlobalAveragePooling2D())\n#     model_dnn169.add(L.Dense(4, activation='softmax'))\n#     model_dnn169.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_dnn169.summary())","d43f76c0":"# from tensorflow.keras.applications import DenseNet201\n\n# with strategy.scope():\n#     dnn201 = DenseNet201(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_dnn201 = Sequential()\n#     model_dnn201.add(dnn201)\n#     model_dnn201.add(L.GlobalAveragePooling2D())\n#     model_dnn201.add(L.Dense(4, activation='softmax'))\n#     model_dnn201.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_dnn201.summary())","105510f9":"# from tensorflow.keras.applications import ResNet50\n\n# with strategy.scope():\n#     rsn50 = ResNet50(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_rsn50 = Sequential()\n#     model_rsn50.add(rsn50)\n#     model_rsn50.add(L.GlobalAveragePooling2D())\n#     model_rsn50.add(L.Dense(4, activation='softmax'))\n#     model_rsn50.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_rsn50.summary())","4167770f":"# from tensorflow.keras.applications import ResNet101\n\n# with strategy.scope():\n#     rsn101 = ResNet101(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_rsn101 = Sequential()\n#     model_rsn101.add(rsn101)\n#     model_rsn101.add(L.GlobalAveragePooling2D())\n#     model_rsn101.add(L.Dense(4, activation='softmax'))\n#     model_rsn101.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_rsn101.summary())","2f4b6483":"# from tensorflow.keras.applications import ResNet152\n\n# with strategy.scope():\n#     rsn152 = ResNet152(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_rsn152 = Sequential()\n#     model_rsn152.add(rsn152)\n#     model_rsn152.add(L.GlobalAveragePooling2D())\n#     model_rsn152.add(L.Dense(4, activation='softmax'))\n#     model_rsn152.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_rsn152.summary())","0b475789":"from tensorflow.keras.applications import VGG16\n\nwith strategy.scope():\n    vgg16 = VGG16(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n    model_vgg16 = Sequential()\n    model_vgg16.add(vgg16)\n    model_vgg16.add(L.GlobalAveragePooling2D())\n    model_vgg16.add(L.Dense(4, activation='softmax'))\n    model_vgg16.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    print(model_vgg16.summary())","9c9eb5e4":"from tensorflow.keras.applications import VGG19\n\nwith strategy.scope():\n    vgg19 = VGG19(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n    model_vgg19 = Sequential()\n    model_vgg19.add(vgg19)\n    model_vgg19.add(L.GlobalAveragePooling2D())\n    model_vgg19.add(L.Dense(4, activation='softmax'))\n    model_vgg19.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    print(model_vgg19.summary())","4991ef72":"# # Epoch\u7d42\u4e86\u5f8c\u306e\u5404\u6570\u5024\u3092\u76e3\u8996\u3057\u3066\u6761\u4ef6\u304c\u63c3\u3063\u305f\u5834\u5408\u30e2\u30c7\u30eb\u3092\u4fdd\u5b58\u3059\u308b\n# # \u91cd\u307f\u306e\u30d5\u30a1\u30a4\u30eb\u540d\/\u76e3\u8996\u3059\u308b\u5024\/\u5224\u5b9a\u7d50\u679c\u304b\u3089\u4fdd\u5b58\u3092\u6c7a\u5b9a\/\u30e2\u30c7\u30eb\u306e\u91cd\u307f\u3092\u4fdd\u5b58\n# mc_efn7 = tf.keras.callbacks.ModelCheckpoint('weights_efn7.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# # \u8a13\u7df4\u306e\u5c65\u6b74\u306e\u53ef\u8996\u5316\n# history = model_efn7.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_efn7], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","a5c936f7":"# mc_efn6 = tf.keras.callbacks.ModelCheckpoint('weights_efn6.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_efn6.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_efn6], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","e140f8d6":"# mc_efn5 = tf.keras.callbacks.ModelCheckpoint('weights_efn5.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_efn5.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_efn5], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","e17860e7":"# mc_efn4 = tf.keras.callbacks.ModelCheckpoint('weights_efn4.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_efn4.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_efn4], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","04499fb0":"# mc_efn3 = tf.keras.callbacks.ModelCheckpoint('weights_efn3.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_efn3.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_efn3], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","0ff29f60":"# mc_efn2 = tf.keras.callbacks.ModelCheckpoint('weights_efn2.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_efn2.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_efn2], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","93695901":"# mc_efn1 = tf.keras.callbacks.ModelCheckpoint('weights_efn1.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_efn1.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_efn1], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","1a88fa2f":"# mc_dnn121 = tf.keras.callbacks.ModelCheckpoint('weights_dnn121.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_dnn121.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_dnn121], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","7003adaa":"# mc_dnn169 = tf.keras.callbacks.ModelCheckpoint('weights_dnn169.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_dnn169.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_dnn169], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","33e735fc":"# mc_dnn201 = tf.keras.callbacks.ModelCheckpoint('weights_dnn201.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_dnn201.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_dnn201], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","ad87a9c9":"# mc_rsn50 = tf.keras.callbacks.ModelCheckpoint('weights_rsn50.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_rsn50.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_rsn50], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","615cba15":"# mc_rsn101 = tf.keras.callbacks.ModelCheckpoint('weights_rsn101.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_rsn101.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_rsn101], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","840991f8":"# mc_rsn152 = tf.keras.callbacks.ModelCheckpoint('weights_rsn152.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_rsn152.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_rsn152], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","b033416b":"mc_vgg16 = tf.keras.callbacks.ModelCheckpoint('weights_vgg16.h5', monitor='loss', save_best_only=True, save_weights_only=True)\nhistory = model_vgg16.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_vgg16], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","a985e9a2":"mc_vgg19 = tf.keras.callbacks.ModelCheckpoint('weights_vgg19.h5', monitor='loss', save_best_only=True, save_weights_only=True)\nhistory = model_vgg19.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_vgg19], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","5e5a46f4":"with strategy.scope():\n#     \u3042\u3089\u304b\u3058\u3081\u4fdd\u5b58\u3057\u3066\u304a\u3044\u305fweight\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u30ed\u30fc\u30c9\n#     model_efn7.load_weights('weights_efn7.h5')\n#     model_efn6.load_weights('weights_efn6.h5')\n#     model_efn5.load_weights('weights_efn5.h5')\n#     model_efn4.load_weights('weights_efn4.h5')\n#     model_efn3.load_weights('weights_efn3.h5')\n#     model_efn2.load_weights('weights_efn2.h5')\n#     model_efn1.load_weights('weights_efn1.h5')\n#     model_dnn121.load_weights('weights_dnn121.h5')\n#     model_dnn169.load_weights('weights_dnn169.h5')\n#     model_dnn201.load_weights('weights_dnn201.h5')\n#     model_rsn50.load_weights('weights_rsn50.h5')\n#     model_rsn101.load_weights('weights_rsn101.h5')\n#     model_rsn152.load_weights('weights_rsn152.h5')\n    model_vgg16.load_weights('weights_vgg16.h5')\n    model_vgg19.load_weights('weights_vgg19.h5')\n# valid_prob = model.predict(valid_dataset, verbose=1)\n# print(metrics.classification_report(np.argmax(valid_label, axis=1), np.argmax(valid_prob, axis=1)))\n# print(metrics.confusion_matrix(np.argmax(valid_label, axis=1), np.argmax(valid_prob, axis=1)))","a7cc3ab3":"# # test\u30c7\u30fc\u30bf\u3067\u306e\u4e88\u6e2c\/log\u306e\u51fa\u529bverbose\n# probs_efn7 = model_efn7.predict(test_dataset, verbose=1)\n# # probs\u306e\u5024\u3092sumple_submission\u306e\u5217healthy,multiple_diseases,rust,scab\u306b\u3042\u3066\u306f\u3081\n# sub_efn7 = sub\n# sub_efn7.loc[:, 'healthy':] = probs_efn7\n# # CSV\u30d5\u30a1\u30a4\u30eb\u306b\u66f8\u304d\u51fa\u3057\n# sub_efn7.to_csv('submission_efn7.csv', index=False)\n# # \u8868\u793a\n# sub_efn7.head()","96400f49":"# probs_efn6 = model_efn6.predict(test_dataset, verbose=1)\n# sub_efn6 = sub\n# sub_efn6.loc[:, 'healthy':] = probs_efn6\n# sub_efn6.to_csv('submission_efn6.csv', index=False)\n# sub_efn6.head()","7bb207c4":"# probs_efn5 = model_efn5.predict(test_dataset, verbose=1)\n# sub_efn5 = sub\n# sub_efn5.loc[:, 'healthy':] = probs_efn5\n# sub_efn5.to_csv('submission_efn5.csv', index=False)\n# sub_efn5.head()","e12f4f48":"# probs_efn4 = model_efn4.predict(test_dataset, verbose=1)\n# sub_efn4 = sub\n# sub_efn4.loc[:, 'healthy':] = probs_efn4\n# sub_efn4.to_csv('submission_efn4.csv', index=False)\n# sub_efn4.head()","5b55b59e":"# probs_efn3 = model_efn3.predict(test_dataset, verbose=1)\n# sub_efn3 = sub\n# sub_efn3.loc[:, 'healthy':] = probs_efn3\n# sub_efn3.to_csv('submission_efn3.csv', index=False)\n# sub_efn3.head()","c932f739":"# probs_efn2 = model_efn2.predict(test_dataset, verbose=1)\n# sub_efn2 = sub\n# sub_efn2.loc[:, 'healthy':] = probs_efn2\n# sub_efn2.to_csv('submission_efn2.csv', index=False)\n# sub_efn2.head()","89d3c6e4":"# probs_efn1 = model_efn1.predict(test_dataset, verbose=1)\n# sub_efn1 = sub\n# sub_efn1.loc[:, 'healthy':] = probs_efn1\n# sub_efn1.to_csv('submission_efn1.csv', index=False)\n# sub_efn1.head()","3f61f461":"# probs_dnn121 = model_dnn121.predict(test_dataset, verbose=1)\n# sub_dnn121 = sub\n# sub_dnn121.loc[:, 'healthy':] = probs_dnn121\n# sub_dnn121.to_csv('submission_dnn121.csv', index=False)\n# sub_dnn121.head()","6395f4c9":"# probs_dnn169 = model_dnn169.predict(test_dataset, verbose=1)\n# sub_dnn169 = sub\n# sub_dnn169.loc[:, 'healthy':] = probs_dnn169\n# sub_dnn169.to_csv('submission_dnn169.csv', index=False)\n# sub_dnn169.head()","3b468b30":"# probs_dnn201 = model_dnn201.predict(test_dataset, verbose=1)\n# sub_dnn201 = sub\n# sub_dnn201.loc[:, 'healthy':] = probs_dnn201\n# sub_dnn201.to_csv('submission_dnn201.csv', index=False)\n# sub_dnn201.head()","271b00c9":"# probs_rsn50 = model_rsn50.predict(test_dataset, verbose=1)\n# sub_rsn50 = sub\n# sub_rsn50.loc[:, 'healthy':] = probs_rsn50\n# sub_rsn50.to_csv('submission_rsn50.csv', index=False)\n# sub_rsn50.head()","434d3c9a":"# probs_rsn101 = model_rsn101.predict(test_dataset, verbose=1)\n# sub_rsn101 = sub\n# sub_rsn101.loc[:, 'healthy':] = probs_rsn101\n# sub_rsn101.to_csv('submission_rsn101.csv', index=False)\n# sub_rsn101.head()","8f19ca86":"# probs_rsn152 = model_rsn152.predict(test_dataset, verbose=1)\n# sub_rsn152 = sub\n# sub_rsn152.loc[:, 'healthy':] = probs_rsn152\n# sub_rsn152.to_csv('submission_rsn152.csv', index=False)\n# sub_rsn152.head()","7b4456ac":"probs_vgg16 = model_vgg16.predict(test_dataset, verbose=1)\nsub_vgg16 = sub\nsub_vgg16.loc[:, 'healthy':] = probs_vgg16\nsub_vgg16.to_csv('submission_vgg16.csv', index=False)\nsub_vgg16.head()","a02202f3":"probs_vgg19 = model_vgg19.predict(test_dataset, verbose=1)\nsub_vgg19 = sub\nsub_vgg19.loc[:, 'healthy':] = probs_vgg19\nsub_vgg19.to_csv('submission_vgg19.csv', index=False)\nsub_vgg19.head()","1c3d545d":"# Model","1cc1b240":"# TPU setup","09786ad8":"# Get class weights","8efe80bb":"# Lets see some images","6bd63f21":"# Get train and test data","ff6ea7cf":"# Decode images","8dab7351":"# ResNet 50\/101\/152","11e41f09":"# DenseNet 121\/169\/201","5a9b7d40":"# Define the parameters","2845e1e7":"# Predict","4545b262":"# EfficientNet B7-B1","86e10b62":"# Import Libraries","f517b30c":"# VGG 16\/19"}}