{"cell_type":{"856db00b":"code","1a930a39":"code","0f07d5d9":"code","325e62d0":"code","ab5b1a9e":"code","d8d9b04a":"code","8f4773bb":"code","dca8e1ee":"markdown","952dd793":"markdown","1a44f0d1":"markdown","6287ac96":"markdown","256beaa5":"markdown"},"source":{"856db00b":"import os\n\nimport numpy as np\nimport pandas as pd\nimport xgboost as xgb\nfrom tqdm import tqdm\n\nos.listdir('..\/input\/')","1a930a39":"def remove_outliers(df):\n    df = df.dropna()\n    mask = df['fare_amount'].between(0, 500)\n    mask &= df['passenger_count'].between(0, 6)\n\n    # to select coordinates: https:\/\/www.openstreetmap.org\/export\n    mask &= df['pickup_longitude'].between(-75, -73)\n    mask &= df['dropoff_longitude'].between(-75, -73)\n    mask &= df['pickup_latitude'].between(40, 42)\n    mask &= df['dropoff_latitude'].between(40, 42)\n\n    return df[mask]\n\ndef manhattan(pickup, dropoff):\n    pickup_long, pickup_lat = pickup\n    dropoff_long, dropoff_lat = dropoff\n    return np.abs(dropoff_long - pickup_long) + np.abs(dropoff_lat - pickup_lat)\n\ndef extract_distance_features(df):\n    df['abs_diff_longitude'] = (df['dropoff_longitude'] - df['pickup_longitude']).abs()\n    df['abs_diff_latitude'] = (df['dropoff_latitude'] - df['pickup_latitude']).abs()\n\n    pickup = (df['pickup_longitude'], df['pickup_latitude'])\n    dropoff = (df['dropoff_longitude'], df['dropoff_latitude'])\n    df['distance'] = manhattan(pickup, dropoff)\n\n    # Distances to nearby airports, and city center\n    # https:\/\/www.kaggle.com\/btyuhas\/bayesian-optimization-with-xgboost\n    coordinates = {\n        'nyc': (-74.0063889, 40.7141667),\n        'jfk': (-73.7822222222, 40.6441666667),\n        'ewr': (-74.175, 40.69),\n        'lgr': (-73.87, 40.77)\n    }\n\n    for name, coord in coordinates.items():\n        df[f'pickup_distance_to_{name}'] = manhattan(coord, pickup)\n        df[f'dropoff_distance_to_{name}'] = manhattan(coord, dropoff)\n\n    return df\n\ndef extract_datetime_features(df):\n    # Removing unecessary information from the datetime string\n    # https:\/\/www.kaggle.com\/btyuhas\/bayesian-optimization-with-xgboost\n    pickup_datetime = df['pickup_datetime'].str.slice(0, 16)\n    pickup_datetime = pd.to_datetime(pickup_datetime, utc=True, format='%Y-%m-%d %H:%M')\n\n    df['year'] = pickup_datetime.dt.year\n    df['month'] = pickup_datetime.dt.month\n    df['day'] = pickup_datetime.dt.day\n    df['dayofweek'] = pickup_datetime.dt.dayofweek\n    df['hour'] = pickup_datetime.dt.hour\n\n    return df.drop(columns='pickup_datetime')\n\ndef extract_features(df):\n    df = extract_distance_features(df)\n    df = extract_datetime_features(df)\n    return df","0f07d5d9":"# save some space from the defaults float64 and int64\ndtypes = {'fare_amount': 'float32',\n          'pickup_datetime': 'str',\n          'pickup_longitude': 'float32',\n          'pickup_latitude': 'float32',\n          'dropoff_longitude': 'float32',\n          'dropoff_latitude': 'float32',\n          'passenger_count': 'uint8'}\n\nval_size = 10_000\ninput_path = '..\/input\/train.csv'\n\nval_df = pd.read_csv(input_path, usecols=dtypes.keys(), dtype=dtypes, nrows=val_size)\nval_df = remove_outliers(val_df)\nval_df = extract_features(val_df)\n\nX_val = val_df.drop(columns='fare_amount')\ny_val = val_df[['fare_amount']]\ndval = xgb.DMatrix(X_val, y_val, feature_names=X_val.columns)\n\nbatch_size = 10_000_000\ncolumns = pd.read_csv(input_path, nrows=0).columns\ntrain_df = pd.read_csv(input_path, usecols=dtypes.keys(), dtype=dtypes,\n                       names=columns, skiprows=val_size + 1,\n                       chunksize=batch_size)\nval_df.dtypes","325e62d0":"params = {'learning_rate': 0.05,\n          'max_depth': 7,\n          'objective': 'reg:linear',\n          'eval_metric': 'rmse',\n          'subsample': 0.8,\n          'gamma': 1,\n          'silent': True,\n          'verbose_eval': True}\n\nnum_rounds = 100\nmodel = None\nfor batch_df in tqdm(train_df):\n    batch_df = remove_outliers(batch_df)\n    batch_df = extract_features(batch_df)\n\n    X_train = batch_df.drop(columns='fare_amount')\n    y_train = batch_df[['fare_amount']]\n    dtrain = xgb.DMatrix(X_train, y_train, feature_names=X_train.columns)\n\n    model = xgb.train(params, dtrain, num_rounds, early_stopping_rounds=5,\n                      evals=[(dtrain, 'train'), (dval, 'eval')],\n                      xgb_model=model)","ab5b1a9e":"xgb.plot_importance(model)","d8d9b04a":"test_df = pd.read_csv('..\/input\/test.csv')\ntest_df = extract_features(test_df)\ntest_df.dtypes","8f4773bb":"X_test = test_df.drop(columns='key')\ndtest = xgb.DMatrix(X_test, feature_names=X_test.columns)\ny_pred = model.predict(dtest)\n\nsubmission = pd.DataFrame({'key': test_df['key'], 'fare_amount': y_pred})\nsubmission.to_csv('submission.csv', index = False)\n\n!head submission.csv","dca8e1ee":"## Predictions","952dd793":"## Training","1a44f0d1":"## Setup data","6287ac96":"## Data cleaning & Feature engineering","256beaa5":"# New York City Taxi Fare Prediction Playground Competition "}}