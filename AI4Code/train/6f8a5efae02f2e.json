{"cell_type":{"1947e583":"code","d9b4a343":"code","051bbb46":"code","10cd817d":"code","7580d989":"code","9c49e760":"code","76ffc11e":"code","6e17caa0":"code","7c27e0e2":"code","18af9886":"code","1533ccd0":"code","a1c6446d":"code","c4e00e91":"code","7c92681e":"code","2360a96a":"code","ced11cc3":"code","7a7373f0":"code","c37459b2":"code","df0cc0f4":"code","7c1d03ea":"code","cfe3597c":"code","f00c0578":"code","1c326e2b":"code","c7c0b9d0":"code","5b2d773c":"code","62d16ba2":"code","b4de0447":"code","22efb3cd":"code","bc7175fb":"code","be810d0b":"code","c14e872e":"code","044cf7a5":"code","55f256fb":"code","1daf2f0c":"code","fba1bf6f":"code","d71e2c5d":"code","94f4efea":"code","7c72b852":"code","ff211671":"code","a1855348":"code","40201876":"code","b465b24f":"code","b4580d9e":"code","8d2e1274":"code","bd290e41":"code","4e5145a1":"code","7d754dab":"code","af07657f":"code","de690a57":"code","44dfe71a":"code","ecd0ca0a":"code","7a9a01df":"code","e89c4b36":"code","fdb53679":"code","3a090725":"code","0b8307e9":"markdown","d9941ad1":"markdown","9f259392":"markdown","702d4cc4":"markdown","f2af7603":"markdown","2c5e8fa8":"markdown","13d8dd97":"markdown","73865cf1":"markdown","0e312b7d":"markdown","256de740":"markdown","7812e7f6":"markdown","1cd467ff":"markdown","10aba408":"markdown","297a602a":"markdown","ced337f5":"markdown","cd7f2c35":"markdown","76488589":"markdown","1fbd9c02":"markdown","e5908cd8":"markdown","e9837375":"markdown","d9b60ad0":"markdown","12446f79":"markdown","16652723":"markdown","bfe43abc":"markdown","3253e65c":"markdown","9473b1ba":"markdown","e0a21e53":"markdown"},"source":{"1947e583":"# Pandas and Visualization\n%matplotlib inline\nimport pandas as pd\nimport numpy as np\nfrom pandas.plotting import scatter_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()\nimport os\nimport warnings\n# Sklearn\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import GridSearchCV","d9b4a343":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","051bbb46":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n\nprint(\"The shape of the training dataset is {}.\\n\".format(train_data.shape))\nprint(\"The shape of the testing dataset is {}.\\n\".format(test_data.shape))","10cd817d":"warnings.filterwarnings(\"ignore\")","7580d989":"train_data.head()","9c49e760":"train_data.drop(columns='PassengerId', axis=1, inplace=True)","76ffc11e":"train_data.describe().T","6e17caa0":"train_data.info()","7c27e0e2":"train_data.isnull().sum()","18af9886":"round((train_data.isnull().sum() \/ len(train_data)) * 100, 2)","1533ccd0":"# Select numerical columns\nnum_cols = [cname for cname in train_data.columns \n            if train_data[cname].dtype in ['int64', 'float64']]\nnum_cols.remove('Pclass')\n\ncat_cols = list(set(train_data.columns) - set(num_cols) - {'Ticket', 'Name', 'Cabin'})\nnum_cols.remove('Survived')\n\nprint(\"Numerical Columns:\", num_cols, '', sep='\\n')\nprint(\"Categorical Columns:\", cat_cols, '', sep='\\n')","a1c6446d":"train_data['Survived'].value_counts()","c4e00e91":"train_data['Survived'].value_counts().plot(kind='bar')","7c92681e":"train_data['Sex'].value_counts()","2360a96a":"train_data['Sex'].value_counts().plot(kind='bar')","ced11cc3":"train_data['Embarked'].value_counts()","7a7373f0":"train_data['Embarked'].value_counts().plot(kind='bar')","c37459b2":"train_data['Pclass'].value_counts()","df0cc0f4":"train_data['Pclass'].value_counts().plot(kind='bar')","7c1d03ea":"train_data['SibSp'].value_counts()","cfe3597c":"train_data['SibSp'].value_counts().plot(kind='bar')","f00c0578":"train_data['Parch'].value_counts()","1c326e2b":"train_data['Parch'].value_counts().plot(kind='bar')","c7c0b9d0":"train_data[['Age', 'Fare']].hist(bins=50, figsize=(12,5))","5b2d773c":"train_data['Age'].plot(kind='box')","62d16ba2":"corr_matrix = train_data.corr()","b4de0447":"corr_matrix[\"Survived\"].sort_values(ascending=False)","22efb3cd":"women = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)\/len(women)\n\nprint(\"% of women who survived:\", rate_women)","bc7175fb":"train_data.loc[train_data.Sex == 'female'][\"Survived\"].value_counts().plot(kind='bar')","be810d0b":"men = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)\/len(men)\n\nprint(\"% of men who survived:\", rate_men)","c14e872e":"train_data.loc[train_data.Sex == 'male'][\"Survived\"].value_counts().plot(kind='bar')","044cf7a5":"class MostFrequentImputer(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X], index = X.columns)\n        return self\n    def transform(self, X, y=None):\n        return X.fillna(self.most_frequent_)","55f256fb":"class AddColumns(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self  \n    def transform(self, X):\n        # print(X.shape)\n        AgeBucket = X[:, Age_index] \/\/ 15 * 15\n        FamilySize = X[:, SibSp_index] + X[:, Parch_index]\n        FarePerPerson = X[:, Fare_index] \/ (FamilySize + 1)\n        \n        return np.c_[AgeBucket, FamilySize, FarePerPerson]","1daf2f0c":"# num_cols = ['Age', 'SibSp', 'Parch', 'Fare']\nAge_index, SibSp_index, Parch_index, Fare_index = 0, 1, 2, 3  ","fba1bf6f":"num_pipeline = Pipeline([('num_imputer', SimpleImputer(strategy=\"median\")),\n                         ('add_cols', AddColumns()),\n                         ('std_scaler', StandardScaler())])\n\ncat_pipeline = Pipeline([('cat_imputer', MostFrequentImputer()),\n                         ('one_hot', OneHotEncoder())])","d71e2c5d":"preprocessor_pipeline = ColumnTransformer([(\"num_transformer\", num_pipeline, num_cols),\n                                         (\"cat_transformer\", cat_pipeline, cat_cols)])","94f4efea":"X_train = preprocessor_pipeline.fit_transform(train_data)","7c72b852":"y_train = train_data[\"Survived\"]","ff211671":"svm_clf = SVC(gamma=\"scale\")","a1855348":"full_pipeline =  Pipeline([('preprocessor', preprocessor_pipeline),\n                           ('model', svm_clf)])","40201876":"svm_scores = cross_val_score(full_pipeline, train_data, y_train, cv=10)\nprint('SVC score:', svm_scores.mean())","b465b24f":"forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)","b4580d9e":"full_pipeline = Pipeline([('preprocessor', preprocessor_pipeline),\n                           ('model', forest_clf)])","8d2e1274":"forest_scores = cross_val_score(full_pipeline, train_data, y_train, cv=10)\nprint('RandomForest score:', forest_scores.mean())","bd290e41":"plt.figure(figsize=(8, 4))\nplt.plot([1]*10, svm_scores, \".\")\nplt.plot([2]*10, forest_scores, \".\")\nplt.boxplot([svm_scores, forest_scores], labels=(\"SVM\",\"Random Forest\"))\nplt.ylabel(\"Accuracy\", fontsize=14)\nplt.show()","4e5145a1":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.base import clone\nrf_scores = []\n\nskfolds = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\nfor train_index, test_index in skfolds.split(X_train, y_train):\n    clone_clf = clone(forest_clf)\n\n    X_train_folds = X_train[train_index]\n    y_train_folds = y_train[train_index]\n    \n    X_valid_fold = X_train[test_index]\n    y_valid_fold = y_train[test_index]\n\n    clone_clf.fit(X_train_folds, y_train_folds)\n    y_pred = clone_clf.predict(X_valid_fold)\n    \n    n_correct = sum(y_pred == y_valid_fold)\n    rf_scores.append((n_correct \/ len(y_pred)))","7d754dab":"print('RandomForest score:', np.mean(rf_scores))","af07657f":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.base import clone\nsv_scores = []\n\nskfolds = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\nfor train_index, test_index in skfolds.split(X_train, y_train):\n    clone_clf = clone(svm_clf)\n\n    X_train_folds = X_train[train_index]\n    y_train_folds = y_train[train_index]\n    \n    X_valid_fold = X_train[test_index]\n    y_valid_fold = y_train[test_index]\n\n    clone_clf.fit(X_train_folds, y_train_folds)\n    y_pred = clone_clf.predict(X_valid_fold)\n    \n    n_correct = sum(y_pred == y_valid_fold)\n    sv_scores.append((n_correct \/ len(y_pred)))","de690a57":"print('SVC score:', np.mean(sv_scores))","44dfe71a":"plt.figure(figsize=(8, 4))\nplt.plot([1]*10, sv_scores, \".\")\nplt.plot([2]*10, rf_scores, \".\")\nplt.boxplot([svm_scores, forest_scores], labels=(\"SVM\",\"Random Forest\"))\nplt.ylabel(\"Accuracy\", fontsize=14)\nplt.show()","ecd0ca0a":"param_grid = [{'n_estimators': [50, 80, 100, 120, 150], 'max_depth': [2, 4, 6, 8, 10]}]\nforest_clf = RandomForestClassifier(random_state=42)\n\ngrid_search = GridSearchCV(forest_clf, param_grid, cv=10, return_train_score=True)\ngrid_search.fit(X_train, y_train)","7a9a01df":"grid_search.best_params_","e89c4b36":"cvres = grid_search.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(mean_score, params)","fdb53679":"X_test = preprocessor_pipeline.fit_transform(test_data)","3a090725":"predictions = grid_search.best_estimator_.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","0b8307e9":"**Numerical and Categorical Columns**","d9941ad1":"**RandomForest Classifier VS. SVM Classifier**","9f259392":"## hyperparameters Tuning using cross validation and grid search\n","702d4cc4":"# Import Libraries","f2af7603":"## Model Selection\n","2c5e8fa8":"**Percentage of survived Women**","13d8dd97":"## Split Data using StratifiedKFold","73865cf1":"## Apply model on Test dataset\n**RandomForestClassifier is better than SVC on test dataset**","0e312b7d":"**Linear Correlation**","256de740":"## Feature Engineering \n**1-Handle missing values (Age, Embarked) columns**\n\n**2-Convert categorical columns (Sex, Embarked, Pclass) to one_hot_encoder**\n\n**3-Add new features**\n\n**4- Use StandardScaler**","7812e7f6":"**Percentage of survived Men**","1cd467ff":"**What about descriptive statistics?**","10aba408":"**Analysis other columns**","297a602a":"**RandomForest Classifier**","ced337f5":"## More EDA","cd7f2c35":"# EDA","76488589":"**Analysis of categorical columns**","1fbd9c02":"**SVM Classifier**","e5908cd8":"**RandomForest Classifier**","e9837375":"**What about info?**","d9b60ad0":"**Drop PassengerId column**","12446f79":"**SVM Classifier**","16652723":"**Outliers Detection**","bfe43abc":"**What about Nulls?**","3253e65c":"**First few row of training dataset**","9473b1ba":"**RandomForest Classifier**","e0a21e53":"# Load Train and Test Datasets"}}