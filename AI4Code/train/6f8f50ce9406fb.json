{"cell_type":{"67e25190":"code","3cbf21f0":"code","2a426ab6":"code","4b23bf1f":"code","6ca39a92":"code","83611e69":"code","0b53c50b":"code","eebcbb79":"code","77d15bcf":"code","216759fd":"code","55034496":"code","8e8335b5":"code","350ebb88":"code","5ca31ca8":"code","260ebf4c":"code","e6a427c7":"code","53899291":"code","abbaea34":"code","a53d04fb":"code","b04b8d9c":"code","b6529496":"code","b4a68dea":"code","df0345c1":"markdown","4ac196f8":"markdown","9beb6a75":"markdown","301bfed9":"markdown","10029660":"markdown","6cf841ca":"markdown","db1c137e":"markdown"},"source":{"67e25190":"#import libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.style.use(\"fivethirtyeight\")","3cbf21f0":"df = pd.read_csv(\"..\/input\/income-classification\/income_evaluation.csv\")\ndf.head()\n\n#fnlwgt referst to final weight (this is the number of people the census believes the entry represents)","2a426ab6":"#check out the data set\ndf.shape","4b23bf1f":"df.info()","6ca39a92":"#Fixing the columns\n\nfor x in df.columns:\n    x_new = x.strip()\n    df=df.rename(columns={x:x_new})\n\ndf.columns","83611e69":"data = df.drop([\"fnlwgt\",\"capital-gain\",\"capital-loss\",\"native-country\"],axis=1)\ndata","0b53c50b":"#Remove Whitespace from dataframe\n\nfor column in data[[\"workclass\",\"education\",\"marital-status\",\"occupation\",\"race\",\"sex\"]]:\n    data[column] = data[column].str.strip()","eebcbb79":"data.head(6)","77d15bcf":"from sklearn import preprocessing","216759fd":"#categorical values of workclass\nprint(\"Unique values of workclass: \", data[\"workclass\"].unique())\nprint(\"Unique values of education: \", data[\"education\"].unique())\nprint(\"Unique values of marital status: \", data[\"marital-status\"].unique())\nprint(\"Unique values of occupation: \", data[\"occupation\"].unique())\nprint(\"Unique values of relationship: \", data[\"relationship\"].unique())\nprint(\"Unique values of race: \", data[\"race\"].unique())\nprint(\"Unique values of sex: \", data[\"sex\"].unique())","55034496":"#workclass labels\nlb_workclass = preprocessing.LabelEncoder()\nlb_workclass.fit([\"Private\",\"Self-emp-not-inc\",\"Local-gov\",\"?\",\n                  \"State-gov\",\"Self-emp-inc\",\n                 \"Federal-gov\",\"Without-pay\",\"Never-worked\"])\ndata.iloc[:,1] = lb_workclass.transform(data.iloc[:,1])\n\n#education labels\nlb_educ = preprocessing.LabelEncoder()\nlb_educ.fit([\"HS-grad\",\"Some-college\",\"Bachelors\",\"Masters\",\n             \"Assoc-voc\",\"11th\",\"Assoc-acdm\",\"10th\",\"7th-8th\",\"Prof-school\",\n             \"9th\",\"12th\",\"Doctorate\",\"5th-6th\",\"1st-4th\",\"Preschool\"])\ndata.iloc[:,2] = lb_educ.transform(data.iloc[:,2])\n\n#marriage labels\nlb_marry = preprocessing.LabelEncoder()\nlb_marry.fit([\"Married-civ-spouse\",\"Never-married\",\"Divorced\",\"Separated\",\n              \"Widowed\",\"Married-spouse-absent\",\"Married-AF-spouse\"])\ndata.iloc[:,4] = lb_marry.transform(data.iloc[:,4])\n\n#occupation labels\nlb_occ = preprocessing.LabelEncoder()\nlb_occ.fit(['Adm-clerical', 'Exec-managerial', 'Handlers-cleaners',\n       'Prof-specialty', 'Other-service', 'Sales', 'Craft-repair',\n       'Transport-moving', 'Farming-fishing', 'Machine-op-inspct',\n       'Tech-support', '?', 'Protective-serv', 'Armed-Forces',\n       'Priv-house-serv'])\ndata.iloc[:,5] = lb_occ.transform(data.iloc[:,5])\n\n#relationship labels\nlb_rel = preprocessing.LabelEncoder()\nlb_rel.fit([' Not-in-family', ' Husband', ' Wife', ' Own-child', ' Unmarried',\n       ' Other-relative'])\ndata.iloc[:,6] = lb_rel.transform(data.iloc[:,6])\n\n#race labels\nlb_race = preprocessing.LabelEncoder()\nlb_race.fit(['White', 'Black', 'Asian-Pac-Islander', 'Amer-Indian-Eskimo',\n       'Other'])\ndata.iloc[:,7] = lb_race.transform(data.iloc[:,7])\n\n#gender labels\nlb_sex = preprocessing.LabelEncoder()\nlb_sex.fit(['Male', 'Female'])\ndata.iloc[:,8] = lb_sex.transform(data.iloc[:,8])","8e8335b5":"data.head(8)","350ebb88":"X=data.iloc[:,:-1]\ny=data[[\"income\"]]","5ca31ca8":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=4)\n\nprint(\"Size of train set:\", X_train.shape, y_train.shape)\nprint(\"Size of test set: \", X_test.shape, y_test.shape)","260ebf4c":"from sklearn.tree import DecisionTreeClassifier\n\nincomeGuess = DecisionTreeClassifier(criterion=\"entropy\",max_depth=4)\nincomeGuess","e6a427c7":"incomeGuess.fit(X_train,y_train)","53899291":"predict_income = incomeGuess.predict(X_test)","abbaea34":"## Evaluation\nfrom sklearn import metrics\nprint(\"Accuracy of decision tree model regarding to income prediction: \", metrics.accuracy_score(y_test,predict_income))","a53d04fb":"from sklearn.neighbors import KNeighborsClassifier\n\nfor i in range(1,11):\n    #Train the model\n    neigh=KNeighborsClassifier(n_neighbors=i).fit(X_train,np.ravel(y_train))\n    y_pred=neigh.predict(X_test)\n    acc=metrics.accuracy_score(y_test,y_pred)\n    print(i,acc)\n","b04b8d9c":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nlog_r = LogisticRegression(C=0.01,solver=\"liblinear\").fit(X_train,np.ravel(y_train))","b6529496":"y_hat = log_r.predict(X_test)\ny_hat","b4a68dea":"#Evaluation\nimport math\ncon_mat = confusion_matrix(y_test,y_hat)\ntotal_accuracy = (con_mat[0, 0] + con_mat[1, 1]) \/ float(np.sum(con_mat))\nclass1_accuracy = (con_mat[0, 0] \/ float(np.sum(con_mat[0, :])))\nclass2_accuracy = (con_mat[1, 1] \/ float(np.sum(con_mat[1, :])))\nprint(con_mat)\nprint('Total accuracy of income model: %.2f' % total_accuracy)\nprint('Accuracy \"Income more than 50K\": %.2f' % class1_accuracy)\nprint('Accuracy \"Income less than 50K\": %.2f' % class2_accuracy)\nprint('Geometric mean accuracy: %.5f' % math.sqrt((class1_accuracy * class2_accuracy)))","df0345c1":"The columns **\"fnlwgt\",\"capital-gain\" and \"capital-loss\"** have a broad variety of values so I will base my predictions on a model with other variables such as age, years of education and hours per week.","4ac196f8":"## Modeling 1 - Decision Tree","9beb6a75":"### Modeling 3: Logistic Regression","301bfed9":"There are plenty of categorical values in our data set. Therefore, our first task is to convert them into numbers by **LabelEncoder**:","10029660":"## Modeling 2 - KNN","6cf841ca":"### Pre-processing","db1c137e":"## Train\/Test Split"}}