{"cell_type":{"08a08220":"code","bd55f6a1":"code","f0ee617b":"code","d9bf583b":"code","ce1b2b73":"code","81e0c545":"code","b0964090":"code","38284b81":"code","8843181f":"code","81a7dd16":"code","f5bb8ad6":"code","14fbd011":"code","bcb87f1a":"code","8640af7e":"code","20d7ff82":"code","f4d56ecd":"code","08f41796":"code","6b5eb74c":"code","237f7fb8":"code","a27a98bc":"code","9ecab5d6":"code","0579cc1d":"code","21562b06":"code","2cb4a8c9":"code","6fb1a8b8":"code","f93a02c8":"code","a2761492":"code","89a71f03":"code","d5911ef1":"code","f4151373":"markdown","194d23c9":"markdown","51019129":"markdown","5c7b9875":"markdown","f5e0ce09":"markdown","6b8bde0f":"markdown","9043009f":"markdown","89afbb83":"markdown","23ec3b82":"markdown","c5b92f13":"markdown","0949300f":"markdown","c98a3508":"markdown","0612cf53":"markdown","f309322e":"markdown","1a2b4357":"markdown","7c92af08":"markdown","e4f1adca":"markdown","c8653ab8":"markdown","ffe2a362":"markdown","55e84aed":"markdown","ef86e406":"markdown","1d77be5d":"markdown","522d344a":"markdown","84297458":"markdown","95659bde":"markdown","702cc1cd":"markdown","a95cfe53":"markdown","bb5eb694":"markdown","f5ff0d63":"markdown","2b966064":"markdown","6874929f":"markdown","1861b47d":"markdown","7daebb89":"markdown"},"source":{"08a08220":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \nimport tensorflow as tf \nimport seaborn as sns \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n# from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,LeakyReLU\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model\n\nimport plotly.graph_objs as go\nfrom plotly import tools\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\n\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","bd55f6a1":"test = pd.read_csv(\"..\/input\/test.csv\")   \ntrain = pd.read_csv(\"..\/input\/train.csv\")","f0ee617b":"train.head()","d9bf583b":"x_train = train.drop([\"label\"],axis=1)\ny_train = train[\"label\"]","ce1b2b73":"x_train.isnull().any().describe()","81e0c545":"test.isnull().any().describe()","b0964090":"# Normalization [-1,1]\nm_train = np.mean(x_train)\nX_train = (x_train - m_train) \/ 255.0\nm_test = np.mean(test)\nttest = (test - m_test) \/ 255.0","38284b81":"# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\nX_train = X_train.values.reshape(-1,28,28,1)\nttest = test.values.reshape(-1,28,28,1)","8843181f":"# one-hot encoding \ny_train = tf.keras.utils.to_categorical(y_train , num_classes = 10)","81a7dd16":"#fix a seed for the random number generator\nrandom_seed = 7 \nX_train , X_val , y_train , y_val = train_test_split (X_train,y_train, test_size = 0.2, random_state = random_seed)\n","f5bb8ad6":"# Some example\nplt.imshow(X_train[147][:,:,0])","14fbd011":"# I followed the 2X filter + pooling scheme but went a little experimental on kernel and filter sizes  \nmodel = Sequential() \n\n# 1.filter & 2.filter + Maxpooling + dropout\n\nmodel.add(Conv2D(filters = 16, kernel_size = (3,3),padding = 'Same', \n                 activation = lambda x: tf.keras.activations.relu(x, alpha=0.1), input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n                 activation = lambda x: tf.keras.activations.relu(x, alpha=0.1)))\n\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n# 3.filter + 4.filer + Maxpooling + Dropout + strides\n\nmodel.add(Conv2D(filters = 32, kernel_size = (2,2),padding = 'Same', \n                 activation = lambda x: tf.keras.activations.relu(x, alpha=0.1)))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (2,2),padding = 'Same', \n                 activation = lambda x: tf.keras.activations.relu(x, alpha=0.1)))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(Dropout(0.5))\n\n\nmodel.add(Dense(10, activation = \"softmax\"))","bcb87f1a":"model.summary()","8640af7e":"plot_model(model, to_file='model.png')\nSVG(model_to_dot(model).create(prog='dot',format='svg'))","20d7ff82":"# adam or RMSprop\noptimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)","f4d56ecd":"# Compile the model\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","08f41796":"lr_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","6b5eb74c":"epochs = 35\nbatch_size = 64","237f7fb8":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(X_train)","a27a98bc":"# Fit the model\nhistory = model.fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_val,y_val),\n                              verbose = 2, steps_per_epoch=X_train.shape[0] \/\/ batch_size,\n                              callbacks=[lr_reduction])","9ecab5d6":"def create_trace(x,y,ylabel,color):\n        trace = go.Scatter(\n            x = x,y = y,\n            name=ylabel,\n            marker=dict(color=color),\n            mode = \"markers+lines\",\n            text=x\n        )\n        return trace\n    \ndef plot_accuracy_and_loss(history):\n    hist = history.history\n    acc = hist['acc']\n    val_acc = hist['val_acc']\n    loss = hist['loss']\n    val_loss = hist['val_loss']\n    epochs = list(range(1,len(acc)+1))\n    \n    trace_ta = create_trace(epochs,acc,\"Training accuracy\", \"Green\")\n    trace_va = create_trace(epochs,val_acc,\"Validation accuracy\", \"Red\")\n    trace_tl = create_trace(epochs,loss,\"Training loss\", \"Blue\")\n    trace_vl = create_trace(epochs,val_loss,\"Validation loss\", \"Magenta\")\n   \n    fig = tools.make_subplots(rows=1,cols=2, subplot_titles=('Training and validation accuracy',\n                                                             'Training and validation loss'))\n    fig.append_trace(trace_ta,1,1)\n    fig.append_trace(trace_va,1,1)\n    fig.append_trace(trace_tl,1,2)\n    fig.append_trace(trace_vl,1,2)\n    fig['layout']['xaxis'].update(title = 'Epoch')\n    fig['layout']['xaxis2'].update(title = 'Epoch')\n    fig['layout']['yaxis'].update(title = 'Accuracy', range=[0,1])\n    fig['layout']['yaxis2'].update(title = 'Loss', range=[0,1])\n\n    \n    iplot(fig, filename='accuracy-loss')\n\nplot_accuracy_and_loss(history)","0579cc1d":"# Plot the loss curve for training and validation \nplt.plot(history.history['val_loss'], color='r', label=\"validation loss\")\nplt.title(\"Validation Loss\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","21562b06":"# Plot the accuracy curves for training and validation \nplt.plot(history.history['val_acc'], color='g', label=\"validation accuracy\")\nplt.title(\"Validation Accuracy\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.show()","2cb4a8c9":"# Look at confusion matrix \n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(10)) ","6fb1a8b8":"print('-'*80)\nprint('train accuracy of the model: ', history.history['acc'][-1])\nprint('-'*80)","f93a02c8":"print('-'*80)\nprint('validation accuracy of the model: ', history.history['val_acc'][-1])\nprint('-'*80)","a2761492":"# Display some error results \n\n# Errors are difference between predicted labels and true labels\nerrors = (Y_pred_classes - Y_true != 0)\n\nY_pred_classes_errors = Y_pred_classes[errors]\nY_pred_errors = Y_pred[errors]\nY_true_errors = Y_true[errors]\nX_val_errors = X_val[errors]\n\ndef display_errors(errors_index,img_errors,pred_errors, obs_errors):\n    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n    n = 0\n    nrows = 2\n    ncols = 3\n    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n    for row in range(nrows):\n        for col in range(ncols):\n            error = errors_index[n]\n            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n            n += 1\n\n# Probabilities of the wrong predicted numbers\nY_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n\n# Predicted probabilities of the true values in the error set\ntrue_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n\n# Difference between the probability of the predicted label and the true label\ndelta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n\n# Sorted list of the delta prob errors\nsorted_dela_errors = np.argsort(delta_pred_true_errors)\n\n# Top 6 errors \nmost_important_errors = sorted_dela_errors[-6:]\n\n# Show the top 6 errors\ndisplay_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)","89a71f03":"# predict results\nresults = model.predict(ttest)\n\n# select the indix with the maximum probability\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")\n","d5911ef1":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"Digit_Recognizer_Suad_Emre_Umar.csv\",index=False)","f4151373":"<a id=\"4\"><\/a> \n### Check the data for isnull","194d23c9":"<a id=\"12\"><\/a> \n## CNN Graphs","51019129":"<a id=\"1\"><\/a> \n# Introduction\nIn this kernel, I create a CNN model with as much explanation as possible .","5c7b9875":"<a id=\"6\"><\/a> \n## Reshape\n* Train and test images (28 x 28)\n* We reshape all data to 28x28x1 3D matrices. Last index is normally RGB index but we dont have it in this dataset.\n* Keras needs an extra dimension in the end which correspond to channels. Our images are gray scaled so it use only one channel.","f5e0ce09":"#### ReduceLROnPlateau\n* Reduce learning rate when a metric has stopped improving.\n\n* Models often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates. This callback monitors a quantity and if no improvement is seen for a 'patience' number of epochs, the learning rate is reduced.","6b8bde0f":"<a id=\"13\"><\/a> \n## Optimizer \n","9043009f":"#### Dropout\n    * Dropout: Dropout is a technique where randomly selected neurons are ignored during training\n    * Helps lower the calculation load while acting as a regularization method\n    \n <a href=\"https:\/\/imgbb.com\/\"><img src=\"https:\/\/i.ibb.co\/sgsm7pt\/30.png\" alt=\"30\" border=\"0\"><\/a>","89afbb83":"<a id=\"16\"><\/a> \n## Data Augmentation\n","23ec3b82":"<a id=\"2\"><\/a> \n# Loading data set","c5b92f13":"<a href=\"https:\/\/ibb.co\/tZhhFxz\"><img src=\"https:\/\/i.ibb.co\/GsJJNt9\/21.png\" alt=\"21\" border=\"0\"><\/a>\n\n* One of the best ways to improve the performance of a Deep Learning model is to add more data to the training set. Aside from gathering more instances from the wild that are representative of the distinction task, we want to develop a set of methods that enhance the data we already have. There are many ways to augment existing datasets and produce more robust models. In the image domain, these are done to utilize the full power of the convolutional neural network, which is able to capture translational invariance. This translational invariance is what makes image recognition such a difficult task in the first place. You want the dataset to be representative of the many different positions, angles, lightings, and miscellaneous distortions that are of interest to the vision task.\n\n* For example, if every image in your training set is perfectly centered within the frame, traditional feed forward models would be confused when the image is slightly shifted to the right relative to the background. If every picture of a cat is taken in portrait made, the model will not recognize the cat when it\u2019s face is turned to the right.\n\n* To improve the model\u2019s ability to generalize and correctly label images with some sort of distortion, we apply several translations to our dataset. This can be done in many ways, in this article we will focus primarily on horizontal and vertical flips, translations, color distortions, and adding random noise.","0949300f":" #### Same Padding\n\n   * As we keep applying conv layers, the size of the volume will decrease faster than we would like. In the early layers of our network, we want to preserve as much information about the original input volume so that we can extract those low level features.\n   * input size and output size are same.\n   \n   <a href=\"https:\/\/imgbb.com\/\"><img src=\"https:\/\/i.ibb.co\/ccCDTcq\/90.png\" alt=\"90\" border=\"0\"><\/a><br \/><a target='_blank' href='https:\/\/aluminumsulfate.net\/aluminum-bromide'>what is the name for albr3<\/a><br \/>","c98a3508":"#### Define the optimizer\n* Change learning rate and relevant parameters used in optimizer","0612cf53":"<a id=\"11\"><\/a> \n#### Summery of model","f309322e":"#### Flattening\n \n <a href=\"https:\/\/imgbb.com\/\"><img src=\"https:\/\/i.ibb.co\/48bwCv5\/16.png\" alt=\"16\" border=\"0\"><\/a>","1a2b4357":"#### MaxPoolingis a Max pooling operation for spatial data. \n    * It makes down-sampling or sub-sampling (Reduces the number of parameters)\n    * It makes the detection of features invariant to scale or orientation changes.\n    * It reduce the amount of parameters and computation in the network, and hence to also control overfitting.\n    \n <a href=\"https:\/\/ibb.co\/YjvRV55\"><img src=\"https:\/\/i.ibb.co\/JkXBSYY\/12.png\" alt=\"12\" border=\"0\"><\/a>","7c92af08":" #### Activation Functions \n Lets talk about some activation functions \n \n * Sigmoid or Logistic Activation Function : \n The main reason why we use sigmoid function is because it exists between (0 to 1). Therefore, it is especially used for models where we have to predict the probability as an output.Since probability of anything exists only between the range of 0 and 1, sigmoid is the right choice.\n\n *  Tanh or hyperbolic tangent Activation Function :\ntanh is very similar to logistic sigmoid. The range of the tanh function is from (-1 to 1).\n * ReLU (Rectified Linear Unit) Activation Function :\n The ReLU is the most used activation function in the world right now.Since it is used in almost all the convolutional neural networks or deep learning.\n \n * Leaky ReLU\nIt is an attempt to solve the dying ReLU problem.The leak helps to increase the range of the ReLU function. Usually, the value of a is chosen to be small, like 0.01. For example a=0.3 is the standard in keras. Therefore the range of the Leaky ReLU is (-infinity to infinity).LeakyRelu is monotonic in nature. Moreover, its derivatives are also monotonic in nature.\n\n* Softmax :\nThe Softmax regression is a form of logistic regression that normalizes an input value into a vector of values that follows a probability distribution whose total sums up to 1. The output values are between the range [0,1] which is nice because we are able to avoid binary classification and accommodate as many classes or dimensions in our neural network model. This is why softmax is sometimes referred to as a multinomial logistic regression.\n  \n  <a href=\"https:\/\/ibb.co\/brm1wCB\"><img src=\"https:\/\/i.ibb.co\/0f2q46M\/20.png\" alt=\"20\" border=\"0\"><\/a>","e4f1adca":"<a id=\"3\"><\/a> \n### Determined the x,y columns","c8653ab8":"<a id=\"15\"><\/a> \n## Epochs and Batch Size\n* Say you have a dataset of 10 examples (or samples). You have a batch size of 2, and you've specified you want the algorithm to run for 3 epochs. Therefore, in each epoch, you have 5 batches (10\/2 = 5). Each batch gets passed through the algorithm, therefore you have 5 iterations per epoch.\n* reference: https:\/\/stackoverflow.com\/questions\/4752626\/epoch-vs-iteration-when-training-neural-networks","ffe2a362":"#### Full Connection\n   * Neurons in a fully connected layer have connections to all activations in the previous layer\n   * Artificial Neural Network\n   \n   <a href=\"https:\/\/ibb.co\/C6jJRFP\"><img src=\"https:\/\/i.ibb.co\/HCcN5Qh\/18.png\" alt=\"18\" border=\"0\"><\/a>","55e84aed":"<a id=\"10\"><\/a> \n## Define CNN model ","ef86e406":"#### Optimizer Functions\nSome of the commonly used optimizers are: Adadelta, Adagrad, Adam, Adamax, Nadam, RMSprop and standard SGD","1d77be5d":"<a id=\"18\"><\/a> \n## Confusing Matrix","522d344a":"<a id=\"17\"><\/a> \n## Graphs of Training and Validation Accuracy","84297458":"<a id=\"14\"><\/a> \n## Compile Model\n* Choose a loss function: Categorical crossentropy since we have a multi class classification problem\n* Choose a metric: Other than accuracy, recall, precision or f1-score can be chosen","95659bde":"#### Fit the model","702cc1cd":"<a id=\"9\"><\/a> \n# How does CNN Algorithm work\n\n<a href=\"https:\/\/ibb.co\/QCTShny\"><img src=\"https:\/\/i.ibb.co\/X3K06pc\/cnn.png\" alt=\"cnn\" border=\"0\"><\/a>\n\nBuild the model: \nWe will use a Sequential model.\n\n* The Sequential model is a linear stack of layers. It can be first initialized and then we add layers using add method or we can add all layers at init stage. The layers added are as follows:\n\n* Convolution Operation\n   * We have some image and feature detector(3*3)\n   * Feature detector does not need to be 3 by 3 matrix. It can be a square matrix of our own choosing(usually 5x5 and 7x7 are chosen).\n   * Feature detector = kernel = filter\n   * Feauture detector detects features like edges or convex shapes. Example, if out input is dog, feature detector can detect features like ear or tail of the dog.\n   * feature map = conv(input image, feature detector). Element wise multiplication of matrices.\n   * feature map = convolved feature\n   * Stride = navigating in input image.\n   * We reduce the size of image. This is important bc code runs faster. However, we lost information.\n   * We create multiple feature maps bc we use multiple feature detectors(filters).\n   * Lets look at gimp. Edge detect: [0,10,0],[10,-4,10],[0,10,0]\n   \n   <a href=\"https:\/\/imgbb.com\/\"><img src=\"https:\/\/i.ibb.co\/G2dr903\/5.jpg\" alt=\"5\" border=\"0\"><\/a>\n   \n \n","a95cfe53":"<a id=\"20\"><\/a>\n# Conclusion\nHyperparameters that affect accuracy\n\n* Epoch size\n* The values chosen in data augmentation part\n* Batch size\n* Dense\n* Filter size\n* Kernel size","bb5eb694":"<a id=\"8\"><\/a> \n## Train & Validation Split\n* We split the data into train and test sets.\n* validation size is 20%.\n* train size is 80%.","f5ff0d63":"Reference : \n* https:\/\/www.kaggle.com\/yassineghouzam\/introduction-to-cnn-keras-0-997-top-6\n* https:\/\/www.kaggle.com\/kanncaa1\/convolutional-neural-network-cnn-tutorial\n* https:\/\/towardsdatascience.com\/data-augmentation-and-images-7aca9bd0dbe8\n* https:\/\/medium.com\/@tuncerergin\/convolutional-neural-network-convnet-yada-cnn-nedir-nasil-calisir-97a0f5d34cad","2b966064":"<a id=\"5\"><\/a> \n## Normalization\n* We perform a grayscale normalization to reduce the effect of illumination's differences.\n* If we perform normalization, CNN works faster.\n* I prefer LeakyRelu over Relu since in more general datasets Relu may cause gradients to 'collapse',\n     so I normalized the features into [-1,1]","6874929f":"1. [Introduction)](#1)\n1. [Loading Data Set](#2)\n      1. [Define x,y columns](#3)\n      1. [Check Data Set](#4)\n   1. [Normalization](#5)\n   1. [Reshape](#6)\n   1. [Label Encoding](#7)\n   1. [Train & Validation Split](#8)\n1. [How is CNN algorithm work](#9)\n1. [Define CNN Algorithm](#10) \n    1. [Summary model](#11)\n    1. [CNN Graph](#12)\n    1. [Optimizer](#13)  \n    1. [Compile Model](#14)\n    1. [Epoch & Batch size](#15) \n    1. [Data Augementation](#16)\n    1. [Graphs of Training and Validation Accuracy](#17)\n1. [Confusing Matrix](#18)\n    1. [Check error labels](#19)\n1. [Conclusion](#20)\n","1861b47d":"<a id=\"7\"><\/a> \n## Label Encoding\n* Encode labels to one-hot vectors\n* 2 => [0,0,1,0,0,0,0,0,0,0]\n* 4 => [0,0,0,0,1,0,0,0,0,0]","7daebb89":"<a id=\"19\"><\/a> \n## Check error labels"}}