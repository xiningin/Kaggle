{"cell_type":{"4a46757c":"code","f720709f":"code","cc009c59":"code","f4530ac6":"code","99d2e1f9":"code","c26468fb":"code","7a11824f":"code","a193f60e":"code","8646ef33":"code","9e3f74ab":"code","3c59fce7":"code","9dbd5d55":"code","a2d29506":"code","0ebc3bec":"code","1d32cec8":"code","d5ebc586":"code","83381a26":"code","65e2f0c7":"code","556b8ca4":"code","40e84e68":"code","b74fec27":"code","1d48d93e":"code","2e236c43":"code","4c5a0c86":"code","b9428520":"code","9a236ff0":"code","849a1676":"code","f2757eee":"code","f63930ed":"code","eb138cc8":"code","7f78e1f9":"code","f1f21e63":"code","bbba5150":"code","9cbaad23":"code","1f3da443":"code","0bd1f988":"code","8098b46d":"code","2e6692f8":"code","6eaaa814":"code","ff99bd3c":"code","70cb115f":"code","9b25e8f4":"code","62b70b80":"code","9c6c5c00":"code","dac6f97c":"code","c178e91c":"code","5d27f33a":"code","12611f69":"code","67abf73a":"code","4dc06892":"code","584cee0c":"code","64b5d945":"code","f24c3485":"code","74fe1f64":"code","feb6097d":"code","df16b105":"code","fcb51807":"code","403750c1":"code","ef42c580":"code","643728e2":"code","a0f61573":"code","f67d24ea":"code","e2fe8ab1":"code","cb1e8c0a":"code","f50da1db":"markdown","581bcdd6":"markdown","600e792b":"markdown","39c90fb2":"markdown","0910685e":"markdown","c561b1f7":"markdown","c411e852":"markdown","4bbbf6a0":"markdown","8ded5000":"markdown","7e0a78e2":"markdown","d5552245":"markdown","bc4bb36f":"markdown","37f8bb00":"markdown","6037e374":"markdown","7382bbdc":"markdown","6a156331":"markdown","72a26e46":"markdown","052435f3":"markdown","0043a39e":"markdown","89607a63":"markdown","58e74fef":"markdown","5314d6bb":"markdown","30833a35":"markdown","01640c10":"markdown","139e02dc":"markdown","2c921d4d":"markdown","5f50862f":"markdown","b80ed658":"markdown","f93de683":"markdown","a26a7a0e":"markdown","4c1d5077":"markdown","9ae77e6a":"markdown","e1c79f0e":"markdown","0afc9efd":"markdown","b214c002":"markdown","bc76a804":"markdown","104973bc":"markdown","9a8e6d66":"markdown","e39e0a1c":"markdown","7b8b0cdb":"markdown","58a6b912":"markdown","9debc1c5":"markdown","e48543a4":"markdown","575d05a3":"markdown","843b1df7":"markdown","0cefa568":"markdown","6ef1b2c5":"markdown","ee256d34":"markdown","7bb88eb1":"markdown","bc077cdd":"markdown","7f88f59e":"markdown","3f7af6c8":"markdown","129894ca":"markdown","c6ddd2f2":"markdown","fd5a8761":"markdown","e067e1e4":"markdown","8cd6747d":"markdown","dda49970":"markdown","ed7cf37d":"markdown","6d3bf5f3":"markdown","26c6a0b3":"markdown","41a971cc":"markdown","aab6e8fd":"markdown","11a855f7":"markdown","c53e9231":"markdown","2724402a":"markdown","a33047bb":"markdown","477cd559":"markdown","2030334a":"markdown","7aa5215c":"markdown","a0197eb5":"markdown","21415b82":"markdown","67b07485":"markdown","33df06ad":"markdown","168b1702":"markdown","2036ad39":"markdown","4d9ee6d2":"markdown","febe2d1b":"markdown","443767b1":"markdown","82bc3aaa":"markdown","207f6818":"markdown","8f595984":"markdown","6d7734cc":"markdown","a20e7871":"markdown","52533f8b":"markdown","254564c2":"markdown","735a40cd":"markdown","1915b082":"markdown","0378e295":"markdown","bcdf1f1e":"markdown","7ff34a82":"markdown","b3178102":"markdown","75c07171":"markdown","e3b90f20":"markdown","502ec14a":"markdown","63908493":"markdown"},"source":{"4a46757c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","f720709f":"print('--------------------------------------------------------')\nprint('------+--+--------------+------+++--+++-+-+++-----------')\nprint('------+-+---------------+--------+--+-+-+-+-+-----------')\nprint('------++---+++--+++-+++-+-+++----+--+-+-+-+++-----------')\nprint('------+-+--+-+--+-+-+-+-+-+-+----+--+-+-+---+-----------')\nprint('------+--+-++++-+++-+++-+-+++---+++++++-+-+++-----------')\nprint('------------------+---+---------------------------------')\nprint('------------------+---+---------------------------------')\nprint('------------------+---+---------------------------------')\nprint('--------------------------------------------------------')","cc009c59":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.gridspec import GridSpec\nimport plotly.graph_objects as go\nimport numpy as np\n\n\n%matplotlib inline","f4530ac6":"multiple_choice_responses_2019 = pd.read_csv('\/kaggle\/input\/kaggle-survey-2019\/multiple_choice_responses.csv')","99d2e1f9":"multiple_choice_responses_2018 = pd.read_csv('\/kaggle\/input\/kaggle-survey-2018\/multipleChoiceResponses.csv')","c26468fb":"multiple_choice_responses_2017 = pd.read_csv('\/kaggle\/input\/kaggle-survey-2017\/multipleChoiceResponses.csv', encoding='ISO-8859-1')","7a11824f":"# Building a dictionary for age of paricipants in 2017 survey. \n\nage_dic = {}\n\nfor age_range in multiple_choice_responses_2018.Q2.value_counts().index[:-2]:\n\n    \n    age_range_list = list(range(int(age_range.split('-')[0]),int(age_range.split('-')[1]) +1))\n    \n    age_count_list = []\n    \n   \n    for age in age_range_list:\n        \n        age_count = sum(multiple_choice_responses_2017.Age == age)\n        \n        age_count_list.append(age_count)\n        \n    age_dic[age_range] = sum(age_count_list)\nage_dic['80+'] = sum(multiple_choice_responses_2017.Age >= 80)\nage_df_2017 = pd.DataFrame(age_dic.values(),age_dic.keys()) # Corrected df for age of respondens.","a193f60e":"\nage_order_2017 = ['18-21','22-24','25-29','30-34','35-39','40-44','45-49','50-54','55-59','60-69','70-79','80+']\nage_values_2017 = age_df_2017.T[age_order_2017].values[0]\n\nage_order_2018 = ['18-21','22-24','25-29','30-34','35-39','40-44','45-49','50-54','55-59','60-69','70-79','80+']\nage_values_2018 = multiple_choice_responses_2018.Q2.value_counts()[age_order_2018].values\n\nage_order_2019 = ['18-21','22-24','25-29','30-34','35-39','40-44','45-49','50-54','55-59','60-69','70+']\nage_values_2019 = multiple_choice_responses_2019.Q1.value_counts()[age_order_2019].values\n\nage_order_2019_SQL = ['18-21','22-24','25-29','30-34','35-39','40-44','45-49','50-54','55-59','60-69','70+']\nage_values_2019_SQL = multiple_choice_responses_2019.Q1[multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts()[age_order_2019].values\n\nage_vals_2017_prc = age_values_2017\/sum(age_values_2017)\nage_vals_2018_prc = age_values_2018\/sum(age_values_2018)\nage_vals_2019_prc = age_values_2019\/sum(age_values_2019)\nage_vals_2019_prc_SQL = age_values_2019_SQL\/sum(age_values_2019_SQL)\n\nfig = go.Figure(data=[\n    go.Bar(name='2017 data', x=age_order_2017, y=age_vals_2017_prc,),\n    go.Bar(name='2018 data', x=age_order_2018, y=age_vals_2018_prc),\n    go.Bar(name='2019 data', x=age_order_2019, y=age_vals_2019_prc),\n    go.Bar(name='2019 data SQL', x=age_order_2019_SQL, y=age_vals_2019_prc_SQL),\n    \n])\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.update_layout(title_text='Respodents age',yaxis=dict(\n        title='Percent',\n        titlefont_size=16,\n        tickfont_size=14,))\nfig.show()","8646ef33":"# Respondents gender.\n\nplt.figure(3, figsize=(20,15))\nthe_grid = GridSpec(1, 3)\n\n# Q GennderSelect.\n# Year 2017.\n\ngender_values_2017 = multiple_choice_responses_2017.GenderSelect.value_counts().values\ngender_2017 = multiple_choice_responses_2017.GenderSelect.value_counts().index\n\nplt.subplot(the_grid[0, 0])\n\nmy_circle=plt.Circle((0,0), 0.9, color='white')\nplt.pie(gender_values_2017,  autopct='%1.1f%%', labels=gender_2017, colors=['skyblue','pink','green','brown'])\np=plt.gcf()\nplt.title(\"Gender distribution in 2017.\")\np.gca().add_artist(my_circle)\n\n# Q1.\n# Year 2018.\n\ngender_values_2018 = multiple_choice_responses_2018.Q1.value_counts().values[:4]\ngender_2018 = multiple_choice_responses_2018.Q1.value_counts().index[:4]\n\nplt.subplot(the_grid[0, 1])\n\nmy_circle=plt.Circle((0,0), 0.9, color='white')\nplt.pie(gender_values_2018, autopct='%1.1f%%', labels=gender_2018, colors=['skyblue','pink','green','brown'])\np=plt.gcf()\nplt.title(\"Gender distribution in 2018.\")\np.gca().add_artist(my_circle)\n\n# Q2.\n# Year 2019.\n\nplt.subplot(the_grid[0, 2])\n\ngender_values_2019 = multiple_choice_responses_2019.Q2.value_counts().values[:4]\ngender_2019 = multiple_choice_responses_2019.Q2.value_counts().index[:4]\n\n\nmy_circle=plt.Circle((0,0), 0.9, color='white')\nplt.pie(gender_values_2019,  autopct='%1.1f%%',labels=gender_2019, colors=['skyblue','pink','green','brown'])\np=plt.gcf()\nplt.title(\"Gender distribution in 2019.\")\np.gca().add_artist(my_circle)\n\nplt.show()","9e3f74ab":"gender_values_2019 = multiple_choice_responses_2019.Q2[multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts().values[:4]\ngender_2019 = multiple_choice_responses_2019.Q2[multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts().index[:4]\n\n\nmy_circle=plt.Circle((0,0), 0.9, color='white')\nplt.pie(gender_values_2019,  autopct='%1.1f%%',labels=gender_2019, colors=['skyblue','pink','green','brown'])\np=plt.gcf()\nplt.title(\"Gender distribution in 2019.\")\np.gca().add_artist(my_circle)\n\nplt.show()","3c59fce7":"import pycountry\n\ncountry = multiple_choice_responses_2019.Q3[1:].value_counts().index\ncountry = pd.Series(country)\ncountry = country.replace('United Kingdom of Great Britain and Northern Ireland','United Kingdom')\ncountry = country.replace('United States of America','United States')\ncountry = country.replace('Iran, Islamic Republic of...','Iran')\ncountry = country.replace('Republic of Korea','Other')\ncountry = country.replace('Hong Kong (S.A.R.)','Hong Kong')\ncountry = country.replace('South Korea', 'Korea')\n\ncountry_values = multiple_choice_responses_2019.Q3[1:].value_counts().values\n\n\ncountries_2019 = []\niso_alpha_2019 = []\ncountries_vals_2019 = []\n\nfor c,v in zip(country,multiple_choice_responses_2019.Q3[1:].value_counts().values):\n    \n    iso = pycountry.countries.search_fuzzy(c)[0].alpha_3\n    pop = v*232009\n \n    if c !=\"Other\":\n        countries_2019.append(c)\n        iso_alpha_2019.append(iso)\n        countries_vals_2019.append(pop)","9dbd5d55":"df_countries_2019 = pd.DataFrame()\ndf_countries_2019['country'] = countries_2019\ndf_countries_2019['iso_alpha'] = iso_alpha_2019\ndf_countries_2019['pop'] = countries_vals_2019\ndf_countries_2019['year'] = '2019'","a2d29506":"country_2017 = multiple_choice_responses_2017.Country.value_counts().index\ncountry_2017 = pd.DataFrame(country_2017, columns=['Country'])\ncountry_2017 = country_2017.replace('People \\'s Republic of China', 'China')\ncountry_2017 = country_2017.replace('Republic of China', 'China')\ncountry_2017 = country_2017.replace('South Korea', 'Korea')\n\ncountry_2017_values = multiple_choice_responses_2017.Country.value_counts().values\n\ncountries_2017 = []\niso_alpha_2017 = []\ncountries_vals_2017 = []\n\nfor c,v in zip(country_2017['Country'].values,country_2017_values):\n\n    iso = pycountry.countries.search_fuzzy(c)[0].alpha_3\n    pop = v*232009\n\n    if c !=\"Other\":\n        countries_2017.append(c)\n        iso_alpha_2017.append(iso)\n        countries_vals_2017.append(pop)\n\n    \ndf_countries_2017 = pd.DataFrame()\ndf_countries_2017['country'] = countries_2017\ndf_countries_2017['iso_alpha'] = iso_alpha_2017\ndf_countries_2017['pop'] = countries_vals_2017\ndf_countries_2017['year'] = '2017'","0ebc3bec":"country_2018 = multiple_choice_responses_2018.Q3.value_counts().index\ncountry_2018 = pd.DataFrame(country_2018, columns=['Country'])\ncountry_2018 = country_2018.replace('United Kingdom of Great Britain and Northern Ireland','United Kingdom')\ncountry_2018 = country_2018.replace('I do not wish to disclose my location', 'Other')\ncountry_2018 = country_2018.replace('South Korea', 'Korea')\ncountry_2018 = country_2018.replace('United States of America','United States')\ncountry_2018 = country_2018.replace('Iran, Islamic Republic of...','Iran')\ncountry_2018 = country_2018.replace('Hong Kong (S.A.R.)','Hong Kong')\ncountry_2018 = country_2018.replace('Republic of Korea','Other')\n\n\ncountry_2018_values = multiple_choice_responses_2018.Q3.value_counts().values\n\ncountries_2018 = []\niso_alpha_2018 = []\ncountries_vals_2018 = []\n\nfor c,v in zip(country_2018['Country'][:-1].values,country_2018_values):\n    \n    iso = pycountry.countries.search_fuzzy(c)[0].alpha_3\n    pop = v*232009\n    \n    if c !=\"Other\":\n        countries_2018.append(c)\n        iso_alpha_2018.append(iso)\n        countries_vals_2018.append(pop)\n\n    \ndf_countries_2018 = pd.DataFrame()\ndf_countries_2018['country'] = countries_2018\ndf_countries_2018['iso_alpha'] = iso_alpha_2018\ndf_countries_2018['pop'] = countries_vals_2018\ndf_countries_2018['year'] = '2018'\n","1d32cec8":"# Combining 2017, 2018, 2019 years in one dataframe.\n\nframes = [df_countries_2017, df_countries_2018, df_countries_2019]\n\ndf_countries_2017_2018_2019 = pd.concat(frames)","d5ebc586":"import plotly.express as px\nfig = px.scatter_geo(df_countries_2017_2018_2019, locations=\"iso_alpha\",\n                     hover_name=\"country\", size=\"pop\",\n                     animation_frame=\"year\",\n                     projection=\"natural earth\")\nfig.show()","83381a26":"# Q3.\n# Country do you currently reside.\n\ncountry = multiple_choice_responses_2019.Q3[1:].value_counts().index\ncountry = pd.Series(country)\ncountry = country.replace('United Kingdom of Great Britain and Northern Ireland','UK')\ncountry = country.replace('United States of America','USA')\ncountry_values = multiple_choice_responses_2019.Q3[1:].value_counts().values\n\nplt.figure(figsize=(16, 6))\ng = sns.barplot(x=country, y=country_values)\ng.set_xticklabels(g.get_xticklabels(), rotation=90)\ng.set_ylabel(\"Number of respondens.\")\n\nfor ix, x in zip(range(len(country_values)+1),country_values):\n    g.text(ix,x,x, horizontalalignment='center')\n    \nplt.title(\"Country distribution in 2019 survey.\")\nplt.show()","65e2f0c7":"# Q3.\n# Country do you currently reside.\n\ncountry =  multiple_choice_responses_2019.Q3[multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts().index\ncountry = pd.Series(country)\ncountry = country.replace('United Kingdom of Great Britain and Northern Ireland','UK')\ncountry = country.replace('United States of America','USA')\ncountry_values = multiple_choice_responses_2019.Q3[multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts().values\n\n\n\nplt.figure(figsize=(16, 6))\ng = sns.barplot(x=country, y=country_values)\ng.set_xticklabels(g.get_xticklabels(), rotation=90)\ng.set_ylabel(\"Number of respondens.\")\n\nfor ix, x in zip(range(len(country_values)+1),country_values):\n    g.text(ix,x,x, horizontalalignment='center')\n    \nplt.title(\"Country distribution in 2019 survey.\")\nplt.show()","556b8ca4":"education = multiple_choice_responses_2019.Q4.value_counts()[:-1].index\neducation_values = multiple_choice_responses_2019.Q4.value_counts()[:-1].values\n\nsns.set({'figure.figsize':(6,6)})\nmy_circle=plt.Circle( (0,0), 0.9, color='white')\nplt.pie(education_values, autopct='%1.1f%%', labels=education)\np=plt.gcf()\nplt.title(\"Education distribution in 2019.\")\np.gca().add_artist(my_circle)\nplt.show()","40e84e68":"education = multiple_choice_responses_2019.Q4[multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts()[:-1].index\neducation_values = multiple_choice_responses_2019.Q4[multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts()[:-1].values\n\nsns.set({'figure.figsize':(6,6)})\nmy_circle=plt.Circle( (0,0), 0.9, color='white')\nplt.pie(education_values, autopct='%1.1f%%', labels=education)\np=plt.gcf()\nplt.title(\"Education distribution in 2019.\")\np.gca().add_artist(my_circle)\nplt.show()","b74fec27":"degree = multiple_choice_responses_2019.Q5.value_counts()[:-1].index\ndegree_values = multiple_choice_responses_2019.Q5.value_counts()[:-1].values\n\nsns.set({'figure.figsize':(6,6)})\nmy_circle=plt.Circle( (0,0), 0.9, color='white')\nplt.pie(degree_values, autopct='%1.1f%%', labels=degree)\np=plt.gcf()\nplt.title(\"Degree distribution in 2019.\")\np.gca().add_artist(my_circle)\nplt.show()","1d48d93e":"degree = multiple_choice_responses_2019.Q5[multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts()[:-1].index\ndegree_values = multiple_choice_responses_2019.Q5[multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts()[:-1].values\n\nsns.set({'figure.figsize':(6,6)})\nmy_circle=plt.Circle( (0,0), 0.9, color='white')\nplt.pie(degree_values, autopct='%1.1f%%', labels=degree)\np=plt.gcf()\nplt.title(\"Degree distribution in 2019.\")\np.gca().add_artist(my_circle)\nplt.show()","2e236c43":"company_order = ['0-49 employees','50-249 employees','250-999 employees','1000-9,999 employees','> 10,000 employees']\ncompany_index = multiple_choice_responses_2019.Q6.value_counts()[company_order].index\ncompany_values = multiple_choice_responses_2019.Q6.value_counts()[company_order].values\ncompany_values_SQL = multiple_choice_responses_2019.Q6[multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts()[company_order].values\n\ncompany_vals_prc = company_values\/sum(company_values)\ncompany_vals_SQL_prc = company_values_SQL\/sum(company_values_SQL)\n\nfig = go.Figure(data=[\n    go.Bar(name='2019 data', x=company_order, y=company_vals_prc),\n    go.Bar(name='2019 data SQL', x=company_order, y=company_vals_SQL_prc),\n    \n])\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.update_layout(title_text='The size of the company where you work',yaxis=dict(\n        title='Percent',\n        titlefont_size=16,\n        tickfont_size=14,))\nfig.show()","4c5a0c86":"numb_of_people_order = ['0','1-2','3-4','5-9','10-14','15-19','20+']\nnumb_of_people_index = multiple_choice_responses_2019.Q7.value_counts()[numb_of_people_order].index\nnumb_of_people_values = multiple_choice_responses_2019.Q7.value_counts()[numb_of_people_order].values\nnumb_of_people_values_SQL = multiple_choice_responses_2019.Q7[multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts()[numb_of_people_order].values\n\nnumb_of_people_vals_prc = numb_of_people_values\/sum(numb_of_people_values)\nnumb_of_people_vals_SQL_prc = numb_of_people_values_SQL\/sum(numb_of_people_values_SQL)\n\nfig = go.Figure(data=[\n    go.Bar(name='2019 data', x=numb_of_people_order, y=numb_of_people_vals_prc),\n    go.Bar(name='2019 data SQL', x=numb_of_people_order, y=numb_of_people_vals_SQL_prc),\n    \n])\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.update_layout(title_text='Aproximate number of individuals are responsible for data science workloads',yaxis=dict(\n        title='Percent',\n        titlefont_size=16,\n        tickfont_size=14,))\nfig.show()","b9428520":"labeling_current_ML_incorporation = multiple_choice_responses_2019.Q8.value_counts()[:-1].index\nvalues_current_ML_incorporation = multiple_choice_responses_2019.Q8.value_counts().values\nvalues_current_ML_incorporation_SQL =  multiple_choice_responses_2019.Q8[multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts().values\nvalues_current_ML_incorporation_prc = values_current_ML_incorporation\/sum(values_current_ML_incorporation)\nvalues_current_ML_incorporation_SQL_prc = values_current_ML_incorporation_SQL\/sum(values_current_ML_incorporation_SQL)\n\nfig = go.Figure(data=[\n    go.Bar(name='2019 data', x=labeling_current_ML_incorporation, y=values_current_ML_incorporation_prc),\n    go.Bar(name='2019 data SQL', x=labeling_current_ML_incorporation, y=values_current_ML_incorporation_SQL_prc),\n    \n])\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.update_layout(title_text='Employer incorporate machine learning methods into their business',yaxis=dict(\n        title='Percent',\n        titlefont_size=16,\n        tickfont_size=14,))\nfig.show()","9a236ff0":"Q9cols = ['Q9_Part_1','Q9_Part_2','Q9_Part_3','Q9_Part_4','Q9_Part_5','Q9_Part_6','Q9_Part_7','Q9_Part_8']\n\nlist_number_important_activities = []\nlist_important_activities = []\n\nfor col in Q9cols:\n    important_activities = multiple_choice_responses_2019[col].value_counts().index[0] \n    number_important_activities = multiple_choice_responses_2019[col].value_counts()[0] \n    list_number_important_activities.append(number_important_activities)\n    list_important_activities.append(important_activities)\n\ndf = pd.DataFrame(list_number_important_activities)\ndf = df.T\ndf.columns = list_important_activities\n\nlabels = list_important_activities\nsizes = list_number_important_activities\nfig1, ax1 = plt.subplots()\nax1.pie(sizes, labels=labels, autopct='%1.1f%%',shadow=False, startangle=140)\nax1.axis('equal')\nplt.title(\"Your role at work in 2019 survey.\")\nplt.show()","849a1676":"Q9cols = ['Q9_Part_1','Q9_Part_2','Q9_Part_3','Q9_Part_4','Q9_Part_5','Q9_Part_6','Q9_Part_7','Q9_Part_8']\n\nlist_number_important_activities_SQL = []\nlist_important_activities = []\n\nfor col in Q9cols:\n    important_activities = multiple_choice_responses_2019[col].value_counts().index[0] \n    number_important_activities_SQL = multiple_choice_responses_2019[col][multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts()[0] \n    list_number_important_activities_SQL.append(number_important_activities_SQL)\n    list_important_activities.append(important_activities)\n\ndf = pd.DataFrame(list_number_important_activities_SQL)\ndf = df.T\ndf.columns = list_important_activities\n\nlabels = list_important_activities\nsizes = list_number_important_activities_SQL\nfig1, ax1 = plt.subplots()\nax1.pie(sizes, labels=labels, autopct='%1.1f%%',shadow=False, startangle=140)\nax1.axis('equal')\nplt.title(\"Your role at for SQL user\")\nplt.show()","f2757eee":"\nmultiple_choice_responses_2019.Q10.value_counts().index\n\ncompensation_order = ['$0-999', '1,000-1,999', '2,000-2,999', '3,000-3,999','4,000-4,999',\n                      '5,000-7,499', '7,500-9,999','10,000-14,999','15,000-19,999',  \n                      '20,000-24,999','25,000-29,999','30,000-39,999','40,000-49,999', \n                      '50,000-59,999','60,000-69,999','70,000-79,999','80,000-89,999',\n                      '90,000-99,999','100,000-124,999','125,000-149,999', \n                      '150,000-199,999','200,000-249,999','250,000-299,999', '300,000-500,000', '> $500,000']\n\nvalues_compensation = multiple_choice_responses_2019.Q10.value_counts()[compensation_order].values\nvalues_compensation_SQL = multiple_choice_responses_2019.Q10[multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts()[compensation_order].values\n\n\nvalues_compensation_prc = values_compensation\/sum(values_compensation)\nvalues_compensation_SQL_prc = values_compensation_SQL\/sum(values_compensation_SQL)\n\nfig = go.Figure(data=[\n    go.Bar(name='2019 data', x=compensation_order, y=values_compensation_prc),\n    go.Bar(name='2019 data SQL', x=compensation_order, y=values_compensation_SQL_prc),\n    \n])\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.update_layout(title_text=\"Yearly compensation (approximate $USD) in 2019\",yaxis=dict(\n        title='Percent',\n        titlefont_size=16,\n        tickfont_size=14,))\nfig.show()\n","f63930ed":"\nmoney_spent_order = ['$0 (USD)', '$1-$99', '$100-$999', '$1000-$9,999', '$10,000-$99,999','> $100,000 ($USD)']\nmoney_spent_order_formated_x = ['$0 (USD)', '$1-99', '$100-999', '$1000-9,999', '$10,000-99,999','> $100,000']\nvalues_money_spent = multiple_choice_responses_2019.Q11.value_counts()[money_spent_order].values\nvalues_money_spent_SQL = multiple_choice_responses_2019.Q11[multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts()[money_spent_order].values\n\nvalues_money_spent_prc = values_money_spent\/sum(values_money_spent)\nvalues_money_spent_SQL_prc = values_money_spent_SQL\/sum(values_money_spent_SQL)\n\nfig = go.Figure(data=[\n    go.Bar(name='2019 data', x=money_spent_order_formated_x, y=values_money_spent_prc),\n    go.Bar(name='2019 data SQL', x=money_spent_order_formated_x, y=values_money_spent_SQL_prc),\n    \n])\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.update_layout(title_text=\" Approximately money have you spent on machine learning and\/or cloud computing products at your work\",yaxis=dict(\n        title='Percent',\n        titlefont_size=16,\n        tickfont_size=14,))\nfig.show()\n","eb138cc8":"Q12cols = ['Q12_Part_1','Q12_Part_2','Q12_Part_3','Q12_Part_4','Q12_Part_5','Q12_Part_6','Q12_Part_7','Q12_Part_8','Q12_Part_9','Q12_Part_10','Q12_Part_11','Q12_Part_12']\n\nlist_number_of_media_sources = []\nlist_of_media_sources = []\nlist_number_of_media_sources_SQL = []\n\nfor col in Q12cols:\n    media_source = multiple_choice_responses_2019[col].value_counts().index[0] \n    number_media_sources = multiple_choice_responses_2019[col].value_counts()[0]\n    number_media_sources_SQL = multiple_choice_responses_2019[col][multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts()[0]\n    \n    list_number_of_media_sources.append(number_media_sources)\n    list_of_media_sources.append(media_source)\n    list_number_of_media_sources_SQL.append(number_media_sources_SQL)\n    \n    \nlist_number_of_media_sources_prc = list_number_of_media_sources\/sum(list_number_of_media_sources)\nlist_number_of_media_sources_SQL_prc =list_number_of_media_sources_SQL\/sum(list_number_of_media_sources_SQL)\n\nfig = go.Figure(data=[\n    go.Bar(name='2019 data', x=list_of_media_sources, y=list_number_of_media_sources_prc),\n    go.Bar(name='2019 data SQL', x=list_of_media_sources, y=list_number_of_media_sources_SQL_prc),\n])\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.update_layout(title_text=\"Your favorite media sources that report on data science topics\",yaxis=dict(\n        title='Percent',\n        titlefont_size=16,\n        tickfont_size=14,)), \nfig.show()\n","7f78e1f9":"Q13cols = ['Q13_Part_1','Q13_Part_2','Q13_Part_3','Q13_Part_4','Q13_Part_5','Q13_Part_6','Q13_Part_7','Q13_Part_8','Q13_Part_9','Q13_Part_10','Q13_Part_11','Q13_Part_12']\n\nlist_science_courses = []\nlist_number_science_courses = []\nlist_number_science_courses_SQL = []\n\nfor col in Q13cols:\n    science_course = multiple_choice_responses_2019[col].value_counts().index[0] \n    number_science_courses = multiple_choice_responses_2019[col].value_counts()[0] \n    number_science_courses_SQL = multiple_choice_responses_2019[col][multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts()[0]\n    list_number_science_courses.append(number_science_courses)\n    list_science_courses.append(science_course)\n    list_number_science_courses_SQL.append(number_science_courses_SQL)\n    \n    \nlist_number_science_courses_prc = list_number_science_courses\/sum(list_number_science_courses)\nlist_number_science_courses_SQL_prc = list_number_science_courses_SQL\/sum(list_number_science_courses_SQL)\n\nfig = go.Figure(data=[\n    go.Bar(name='2019 data', x=list_science_courses, y=list_number_science_courses_prc),\n    go.Bar(name='2019 data SQL', x=list_science_courses, y=list_number_science_courses_SQL_prc),\n])\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.update_layout(title_text=\"Platforms that you have begun or completed data science courses\",yaxis=dict(\n        title='Percent',\n        titlefont_size=16,\n        tickfont_size=14,)), \nfig.show()\n","f1f21e63":"tools = multiple_choice_responses_2019.Q14.value_counts().index[:-1]\ntools_number = multiple_choice_responses_2019.Q14.value_counts()[tools].values\ntools_number_sql = multiple_choice_responses_2019.Q14[multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts()[tools].values\n\ntools_number_prc = tools_number\/sum(tools_number)\ntools_number_SQL_prc = tools_number_sql\/sum(tools_number_sql)\n\nfig = go.Figure(data=[\n    go.Bar(name='2019 data', x=tools, y=tools_number_prc),\n    go.Bar(name='2019 data SQL', x=tools, y=tools_number_SQL_prc),\n])\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.update_layout(title_text=\"The primary tool that you use at work or school to analyze data\",yaxis=dict(\n        title='Percent',\n        titlefont_size=16,\n        tickfont_size=14,)), \nfig.show()\n","bbba5150":"code_writing_time = ['I have never written code','< 1 years', '1-2 years', '3-5 years', '5-10 years', '10-20 years', '20+ years']\nnumb_code_writing_time = multiple_choice_responses_2019.Q15.value_counts()[code_writing_time].values\nnumb_code_writing_time_SQL = multiple_choice_responses_2019.Q15[multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts()[code_writing_time].values\n\n#print(numb_code_writing_time_SQL[1:])\ncode_writing_number_prc = numb_code_writing_time\/sum(numb_code_writing_time)\ncode_writing_number_SQL_prc = numb_code_writing_time_SQL[1:]\/sum(numb_code_writing_time_SQL[1:])\n\ncode_corrected_number_SQL = np.insert(code_writing_number_SQL_prc,0,0)\n\nfig = go.Figure(data=[\n    go.Bar(name='2019 data', x=code_writing_time, y=code_writing_number_prc),\n    go.Bar(name='2019 data SQL', x=code_writing_time, y=code_corrected_number_SQL),\n])\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.update_layout(title_text=\"Time spent writing code to analyze data\",yaxis=dict(\n        title='Percent',\n        titlefont_size=16,\n        tickfont_size=14,)), \nfig.show()","9cbaad23":"Q16cols = ['Q16_Part_1','Q16_Part_2','Q16_Part_3','Q16_Part_4','Q16_Part_5','Q16_Part_6','Q16_Part_7','Q16_Part_8','Q16_Part_9','Q16_Part_10','Q16_Part_11','Q16_Part_12']\n\nlist_of_IDE_numbers = []\nlist_of_IDE = []\nlist_of_IDE_numbers_SQL = []\n\n\nfor col in Q16cols:\n    IDE = multiple_choice_responses_2019[col].value_counts().index[0]\n    number_of_IDE = multiple_choice_responses_2019[col].value_counts()[0]\n    number_of_IDE_SQL = multiple_choice_responses_2019[col][multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts()[0]\n  \n    \n    list_of_IDE_numbers.append(number_of_IDE)\n    list_of_IDE.append(IDE)\n    list_of_IDE_numbers_SQL.append(number_of_IDE_SQL)\n    \nlist_of_IDE_numbers_prc = list_of_IDE_numbers\/sum(list_of_IDE_numbers)\nlist_of_IDE_numbers_SQL_prc = list_of_IDE_numbers_SQL \/ sum(list_of_IDE_numbers_SQL)\n\nfig = go.Figure(data=[\n    go.Bar(name='2019 data', x=list_of_IDE, y=list_of_IDE_numbers_prc),\n    go.Bar(name='2019 data SQL', x=list_of_IDE, y=list_of_IDE_numbers_SQL_prc),\n])\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.update_layout(title_text=\"IDE you are using for regural basis\",yaxis=dict(\n        title='Percent',\n        titlefont_size=16,\n        tickfont_size=14,)), \nfig.show()","1f3da443":"Q17cols = ['Q17_Part_1','Q17_Part_2','Q17_Part_3','Q17_Part_4','Q17_Part_5','Q17_Part_6','Q17_Part_7','Q17_Part_8','Q17_Part_9','Q17_Part_10','Q17_Part_11','Q17_Part_12']\n\nlist_of_hnotebooks_numbers = []\nlist_of_hnotebooks = []\nlist_of_hnotebooks_numbers_SQL = []\n\nfor col in Q17cols:\n    hnotebooks = multiple_choice_responses_2019[col].value_counts().index[0] \n    number_hnotebooks = multiple_choice_responses_2019[col].value_counts()[0] \n    number_hnotebooks_SQL = multiple_choice_responses_2019[col][multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts()[0] \n    \n    list_of_hnotebooks_numbers.append(number_hnotebooks)\n    list_of_hnotebooks.append(hnotebooks)\n    list_of_hnotebooks_numbers_SQL.append(number_hnotebooks_SQL)\n    \nlist_of_hnotebooks_numbers_prc = list_of_hnotebooks_numbers\/sum(list_of_hnotebooks_numbers)\nlist_of_hnotebooks_numbers_SQL_prc = list_of_hnotebooks_numbers_SQL \/ sum(list_of_hnotebooks_numbers_SQL)\n\nfig = go.Figure(data=[\n    go.Bar(name='2019 data', x=list_of_hnotebooks, y=list_of_hnotebooks_numbers_prc),\n    go.Bar(name='2019 data SQL', x=list_of_hnotebooks, y=list_of_hnotebooks_numbers_SQL_prc),\n])\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.update_layout(title_text=\"Following hosted notebook products do you use on a regular basis \",yaxis=dict(\n        title='Percent',\n        titlefont_size=16,\n        tickfont_size=14,)), \nfig.show()","0bd1f988":"Q18cols = ['Q18_Part_1','Q18_Part_2','Q18_Part_3','Q18_Part_4','Q18_Part_5','Q18_Part_6','Q18_Part_7','Q18_Part_8','Q18_Part_9','Q18_Part_10','Q18_Part_11','Q18_Part_12']\n\nlist_number_of_users = []\nlist_of_programming_languages = []\nfor col in Q18cols:\n    programming_language = multiple_choice_responses_2019[col].value_counts().index[0] \n    number_of_users = multiple_choice_responses_2019[col].value_counts()[0] \n    list_number_of_users.append(number_of_users)\n    list_of_programming_languages.append(programming_language)\n    \ng = sns.barplot(x=list_of_programming_languages, y=list_number_of_users)\ng.set_xticklabels(g.get_xticklabels(), rotation=90)\nplt.title(\"Popularity of programming languages in 2019 survey\")\ng.set_ylabel(\"Number of respondents.\")\n\nfor ix, x in zip(range(len(list_number_of_users)+1),list_number_of_users):\n    g.text(ix,x,x, horizontalalignment='center')\n\nplt.show()","8098b46d":"languages = multiple_choice_responses_2019.Q19.value_counts().index[:-1]\nlanguages_numbers = multiple_choice_responses_2019.Q19.value_counts().values[:-1]\n\ng = sns.barplot(x=languages, y=languages_numbers)\ng.set_xticklabels(g.get_xticklabels(), rotation=45)\nplt.title(\"Programming language would you recommend an aspiring data scientist to learn first in 2019.\")\ng.set_ylabel(\"Number of respondents.\")\n\n\n\nfor ix, x in zip(range(len(languages_numbers)+1),languages_numbers):\n    g.text(ix,x,x, horizontalalignment='center')\n\nplt.show()","2e6692f8":"Q20cols = ['Q20_Part_1','Q20_Part_2','Q20_Part_3','Q20_Part_4','Q20_Part_5','Q20_Part_6','Q20_Part_7','Q20_Part_8','Q20_Part_9','Q20_Part_10','Q20_Part_11','Q20_Part_12']\n\nlist_viz_tools = []\nlist_viz_tools_numbers = []\nlist_viz_tools_numbers_SQL = []\n\nfor col in Q20cols:\n    viz_tools = multiple_choice_responses_2019[col].value_counts().index[0] \n    viz_tools_numbers = multiple_choice_responses_2019[col].value_counts()[0] \n    viz_tools_numbers_SQL = multiple_choice_responses_2019[col][multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts()[0] \n    list_viz_tools.append(viz_tools)\n    list_viz_tools_numbers.append(viz_tools_numbers)\n    list_viz_tools_numbers_SQL.append(viz_tools_numbers_SQL)\n    \n    \nlist_of_viz_tools_numbers_prc = list_viz_tools_numbers\/sum(list_viz_tools_numbers)\nlist_of_viz_tools_numbers_SQL_prc = list_viz_tools_numbers_SQL \/ sum(list_viz_tools_numbers_SQL)\n\nfig = go.Figure(data=[\n    go.Bar(name='2019 data', x=list_viz_tools, y=list_of_viz_tools_numbers_prc),\n    go.Bar(name='2019 data SQL', x=list_viz_tools, y=list_of_viz_tools_numbers_SQL_prc),\n])\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.update_layout(title_text=\"Visualization libraries or tools do you use on a regular basis \",yaxis=dict(\n        title='Percent',\n        titlefont_size=16,\n        tickfont_size=14,)), \nfig.show()\n    \n","6eaaa814":"Q20cols = ['Q20_Part_1','Q20_Part_2','Q20_Part_3','Q20_Part_4','Q20_Part_5','Q20_Part_6','Q20_Part_7','Q20_Part_8','Q20_Part_9','Q20_Part_10','Q20_Part_11','Q20_Part_12']\n\nlist_viz_tools = []\nlist_viz_tools_numbers = []\nlist_viz_tools_numbers_SQL = []\n\nfor col in Q20cols:\n    viz_tools = multiple_choice_responses_2019[col].value_counts().index[0] \n    viz_tools_numbers = multiple_choice_responses_2019[col].value_counts()[0] \n    viz_tools_numbers_SQL = multiple_choice_responses_2019[col][(multiple_choice_responses_2019.Q18_Part_3 == \"SQL\") & (multiple_choice_responses_2019.Q18_Part_1 != \"Python\")].value_counts()[0] \n    list_viz_tools.append(viz_tools)\n    list_viz_tools_numbers.append(viz_tools_numbers)\n    list_viz_tools_numbers_SQL.append(viz_tools_numbers_SQL)\n    \n    \nlist_of_viz_tools_numbers_prc = list_viz_tools_numbers\/sum(list_viz_tools_numbers)\nlist_of_viz_tools_numbers_SQL_prc = list_viz_tools_numbers_SQL \/ sum(list_viz_tools_numbers_SQL)\n\nfig = go.Figure(data=[\n    go.Bar(name='2019 data', x=list_viz_tools, y=list_of_viz_tools_numbers_prc),\n    go.Bar(name='2019 data SQL', x=list_viz_tools, y=list_of_viz_tools_numbers_SQL_prc),\n])\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.update_layout(title_text=\"Visualization libraries or tools do you use on a regular basis \",yaxis=dict(\n        title='Percent',\n        titlefont_size=16,\n        tickfont_size=14,)), \nfig.show()","ff99bd3c":"Q21cols = ['Q21_Part_1','Q21_Part_2','Q21_Part_3','Q21_Part_4','Q21_Part_5']\n\nlist_hardware_tools = []\nlist_hardware_tools_numbers = []\nlist_hardware_tools_numbers_SQL = []\n\n\nfor col in Q21cols:\n    \n    hardware_tools = multiple_choice_responses_2019[col].value_counts().index[0] \n    hardware_tools_numbers = multiple_choice_responses_2019[col].value_counts()[0] \n    hardware_tools_numbers_SQL = multiple_choice_responses_2019[col][multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts()[0] \n    \n    list_hardware_tools.append(hardware_tools)\n    list_hardware_tools_numbers.append(hardware_tools_numbers)\n    list_hardware_tools_numbers_SQL.append(hardware_tools_numbers_SQL)\n\nlist_hardware_tools_numbers_prc = list_hardware_tools_numbers\/sum(list_hardware_tools_numbers)\nlist_hardware_tools_numbers_SQL_prc = list_hardware_tools_numbers_SQL \/ sum(list_hardware_tools_numbers_SQL)\n\nfig = go.Figure(data=[\n    go.Bar(name='2019 data', x=list_hardware_tools, y=list_hardware_tools_numbers_prc),\n    go.Bar(name='2019 data SQL', x=list_hardware_tools, y=list_hardware_tools_numbers_SQL_prc),\n])\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.update_layout(title_text=\"Types of specialized hardware do you use on a regular basis\",yaxis=dict(\n        title='Percent',\n        titlefont_size=16,\n        tickfont_size=14,)), \nfig.show()\n\n","70cb115f":"TPU_usage =  ['Never', 'Once', '2-5 times', '6-24 times', '> 25 times']\nTPU_usage_numbers = multiple_choice_responses_2019.Q22.value_counts()[TPU_usage].values\nTPU_usage_numbers_SQL = multiple_choice_responses_2019.Q22[multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts()[TPU_usage].values\n\n\nTPU_usage_numbers_prc = TPU_usage_numbers \/ sum(TPU_usage_numbers)\nTPU_usage_numbers_SQL_prc = TPU_usage_numbers_SQL \/ sum(TPU_usage_numbers_SQL)\n\nfig = go.Figure(data=[\n    go.Bar(name='2019 data', x=TPU_usage, y=TPU_usage_numbers_prc),\n    go.Bar(name='2019 data SQL', x=TPU_usage, y=TPU_usage_numbers_SQL_prc),\n])\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.update_layout(title_text=\"Use of a TPU (tensor processing unit)\",yaxis=dict(\n        title='Percent',\n        titlefont_size=16,\n        tickfont_size=14,)), \nfig.show()\n","9b25e8f4":"Users_years =  ['< 1 years', '1-2 years', '2-3 years', '3-4 years', '4-5 years', '5-10 years', '10-15 years', '20+ years']\nUsers_years_counts = multiple_choice_responses_2019.Q23.value_counts()[Users_years].values\nUsers_years_counts_SQL = multiple_choice_responses_2019.Q23[multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts()[Users_years].values\n\nUsers_years_counts_prc = Users_years_counts \/ sum(Users_years_counts)\nUsers_years_counts_SQL_prc = Users_years_counts_SQL \/ sum(Users_years_counts_SQL)\n\nfig = go.Figure(data=[\n    go.Bar(name='2019 data', x=Users_years, y=Users_years_counts_prc),\n    go.Bar(name='2019 data SQL', x=Users_years, y=Users_years_counts_SQL_prc),\n])\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.update_layout(title_text=\"Use of machine learning methods\",yaxis=dict(\n        title='Percent',\n        titlefont_size=16,\n        tickfont_size=14,)), \nfig.show()","62b70b80":"Q24cols = ['Q24_Part_1','Q24_Part_2','Q24_Part_3','Q24_Part_4','Q24_Part_5','Q24_Part_6','Q24_Part_7','Q24_Part_8','Q24_Part_9','Q24_Part_10','Q24_Part_11','Q24_Part_12']\n\nlist_ml_tools = []\nlist_ml_tools_numbers = []\nlist_ml_tools_numbers_SQL = []\n\nfor col in Q24cols:\n    \n    ml_tools = multiple_choice_responses_2019[col].value_counts().index[0] \n    ml_tools_numbers = multiple_choice_responses_2019[col].value_counts()[0] \n    ml_tools_numbers_SQL = multiple_choice_responses_2019[col][multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts()[0]\n    \n    list_ml_tools.append(ml_tools)\n    list_ml_tools_numbers.append(ml_tools_numbers)\n    list_ml_tools_numbers_SQL.append(ml_tools_numbers_SQL)\n\nlist_ml_tools_prc = list_ml_tools_numbers \/ sum(list_ml_tools_numbers)\nlist_ml_tools_SQL_prc = list_ml_tools_numbers_SQL \/ sum(list_ml_tools_numbers_SQL)\n\nfig = go.Figure(data=[\n    go.Bar(name='2019 data', x=list_ml_tools, y=list_ml_tools_prc),\n    go.Bar(name='2019 data SQL', x=list_ml_tools, y=list_ml_tools_SQL_prc),\n])\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.update_layout(title_text=\"ML algorithms do you use on a regular basis\",yaxis=dict(\n        title='Percent',\n        titlefont_size=16,\n        tickfont_size=14,)), \nfig.show()\n","9c6c5c00":"Q25cols = ['Q25_Part_1','Q25_Part_2','Q25_Part_3','Q25_Part_4','Q25_Part_5','Q25_Part_6','Q25_Part_7','Q25_Part_8']\n\nlist_ml_tools_reg = []\nlist_ml_tools_numbers_reg = []\nlist_ml_tools_numbers_reg_SQL = []\n\nfor col in Q25cols:\n    \n    ml_tools_reg = multiple_choice_responses_2019[col].value_counts().index[0] \n    ml_tools_numbers_reg = multiple_choice_responses_2019[col].value_counts()[0] \n    ml_tools_numbers_reg_SQL = multiple_choice_responses_2019[col][multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts()[0] \n    \n    \n    list_ml_tools_reg.append(ml_tools_reg)\n    list_ml_tools_numbers_reg.append(ml_tools_numbers_reg)\n    list_ml_tools_numbers_reg_SQL.append(ml_tools_numbers_reg_SQL)\n    \n\nlist_ml_tools_prc = list_ml_tools_numbers_reg \/ sum(list_ml_tools_numbers_reg)\nlist_ml_tools_SQL_prc = list_ml_tools_numbers_reg_SQL \/ sum(list_ml_tools_numbers_reg_SQL)\n\nfig = go.Figure(data=[\n    go.Bar(name='2019 data', x=list_ml_tools_reg, y=list_ml_tools_prc),\n    go.Bar(name='2019 data SQL', x=list_ml_tools_reg, y=list_ml_tools_SQL_prc),\n])\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.update_layout(title_text=\"ML algorithms do you use on a regular basis\",yaxis=dict(\n        title='Percent',\n        titlefont_size=16,\n        tickfont_size=14,)), \nfig.show()","dac6f97c":"Q26cols = ['Q26_Part_1','Q26_Part_2','Q26_Part_3','Q26_Part_4','Q26_Part_5','Q26_Part_6','Q26_Part_7']\n\nlist_cv_tools = []\nlist_cv_tools_numbers = []\nlist_cv_tools_numbers_SQL = []\n\nfor col in Q26cols:\n    cv_tools= multiple_choice_responses_2019[col].value_counts().index[0] \n    cv_tools_numbers = multiple_choice_responses_2019[col].value_counts()[0] \n    cv_tools_numbers_SQL = multiple_choice_responses_2019[col][multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts()[0] \n    \n    list_cv_tools.append(cv_tools)\n    list_cv_tools_numbers.append(cv_tools_numbers)\n    list_cv_tools_numbers_SQL.append(cv_tools_numbers_SQL)\n\nlist_cv_tools_prc = list_cv_tools_numbers \/ sum(list_cv_tools_numbers)\nlist_cv_tools_SQL_prc = list_cv_tools_numbers_SQL \/ sum(list_cv_tools_numbers_SQL)\n\nfig = go.Figure(data=[\n    go.Bar(name='2019 data', x=list_cv_tools, y=list_cv_tools_prc),\n    go.Bar(name='2019 data SQL', x=list_cv_tools, y=list_cv_tools_SQL_prc),\n])\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.update_layout(title_text=\"Categories of computer vision methods do you use on a regular basis\",\n        yaxis=dict(\n        title='Percent',\n        titlefont_size=16,\n        tickfont_size=14,)), \nfig.show()\n","c178e91c":"Q27cols = ['Q27_Part_1','Q27_Part_2','Q27_Part_3','Q27_Part_4','Q27_Part_5','Q27_Part_6']\n\nlist_nlp_tools = []\nlist_nlp_tools_numbers = []\nlist_nlp_tools_numbers_SQL = []\n\nfor col in Q27cols:\n    \n    nlp_tools= multiple_choice_responses_2019[col].value_counts().index[0] \n    nlp_tools_numbers = multiple_choice_responses_2019[col].value_counts()[0] \n    nlp_tools_numbers_SQL = multiple_choice_responses_2019[col][multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts()[0] \n    \n    list_nlp_tools.append(nlp_tools)\n    list_nlp_tools_numbers.append(nlp_tools_numbers)\n    list_nlp_tools_numbers_SQL.append(nlp_tools_numbers_SQL)\n\n\nlist_nlp_tools_prc = list_nlp_tools_numbers \/ sum(list_nlp_tools_numbers)\nlist_nlp_tools_SQL_prc = list_nlp_tools_numbers_SQL \/ sum(list_nlp_tools_numbers_SQL)\n\nfig = go.Figure(data=[\n    go.Bar(name='2019 data', x=list_nlp_tools, y=list_nlp_tools_prc),\n    go.Bar(name='2019 data SQL', x=list_nlp_tools, y=list_nlp_tools_SQL_prc),\n])\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.update_layout(title_text=\"The following natural language processing (NLP) methods do you use on a regular basis\",\n        yaxis=dict(\n        title='Percent',\n        titlefont_size=16,\n        tickfont_size=14,)), \nfig.show()","5d27f33a":"Q28cols = ['Q28_Part_1','Q28_Part_2','Q28_Part_3','Q28_Part_4','Q28_Part_5','Q28_Part_6','Q28_Part_7','Q28_Part_8','Q28_Part_9','Q28_Part_10','Q28_Part_11','Q28_Part_12']\n\nlist_ml_frs = []\nlist_ml_frs_numbers = []\nlist_ml_frs_numbers_SQL = []\n\n\nfor col in Q28cols:\n    \n    ml_frs = multiple_choice_responses_2019[col].value_counts().index[0] \n    ml_frs_numbers = multiple_choice_responses_2019[col].value_counts()[0] \n    ml_frs_numbers_SQL = multiple_choice_responses_2019[col][multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts()[0]\n    \n    list_ml_frs.append(ml_frs)\n    list_ml_frs_numbers.append(ml_frs_numbers)\n    list_ml_frs_numbers_SQL.append(ml_frs_numbers_SQL)\n    \nlist_frs_numbers_prc = list_ml_frs_numbers \/ sum(list_ml_frs_numbers)\nlist_frs_numbers_SQL_prc = list_ml_frs_numbers_SQL \/ sum(list_ml_frs_numbers_SQL)\n\nfig = go.Figure(data=[\n    go.Bar(name='2019 data', x=list_ml_frs, y=list_frs_numbers_prc),\n    go.Bar(name='2019 data SQL', x=list_ml_frs, y=list_frs_numbers_SQL_prc),\n])\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.update_layout(title_text=\"Machine learning frameworks do you use on a regular basis\",\n        yaxis=dict(\n        title='Percent',\n        titlefont_size=16,\n        tickfont_size=14,)), \nfig.show()\n","12611f69":"Q29cols = ['Q29_Part_1','Q29_Part_2','Q29_Part_3','Q29_Part_4','Q29_Part_5','Q29_Part_6','Q29_Part_7','Q29_Part_8','Q29_Part_9','Q29_Part_10','Q29_Part_11','Q29_Part_12']\n\nlist_cps = []\nlist_cps_numbers = []\nlist_cps_numbers_SQL = []\n\nfor col in Q29cols:\n    \n    cps = multiple_choice_responses_2019[col].value_counts().index[0] \n    cps_numbers = multiple_choice_responses_2019[col].value_counts()[0] \n    cps_numbers_SQL = multiple_choice_responses_2019[col][multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts()[0] \n    \n    list_cps.append(cps)\n    list_cps_numbers.append(cps_numbers)\n    list_cps_numbers_SQL.append(cps_numbers_SQL)\n    \nlist_cps_numbers_prc = list_cps_numbers \/ sum(list_cps_numbers)\nlist_cps_numbers_SQL_prc = list_cps_numbers_SQL \/ sum(list_cps_numbers_SQL)\n\nfig = go.Figure(data=[\n    go.Bar(name='2019 data', x=list_cps, y=list_cps_numbers_prc),\n    go.Bar(name='2019 data SQL', x=list_cps, y=list_cps_numbers_SQL_prc),\n])\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.update_layout(title_text=\"Computer platforms you use on regular basis \",\n        yaxis=dict(\n        title='Percent',\n        titlefont_size=16,\n        tickfont_size=14,)), \nfig.show()\n    \n","67abf73a":"Q30cols = ['Q30_Part_1','Q30_Part_2','Q30_Part_3','Q30_Part_4','Q30_Part_5','Q30_Part_6','Q30_Part_7','Q30_Part_8','Q30_Part_9','Q30_Part_10','Q30_Part_11','Q30_Part_12']\n\nlist_ccps = []\nlist_ccps_numbers = []\nlist_ccps_numbers_SQL = []\n\n\nfor col in Q30cols:\n    \n    ccps = multiple_choice_responses_2019[col].value_counts().index[0] \n    ccps_numbers = multiple_choice_responses_2019[col].value_counts()[0] \n    ccps_numbers_SQL = multiple_choice_responses_2019[col][multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts()[0] \n\n    \n    list_ccps.append(ccps)\n    list_ccps_numbers.append(ccps_numbers)\n    list_ccps_numbers_SQL.append(ccps_numbers_SQL)\n    \nlist_ccps_numbers_prc = list_ccps_numbers \/ sum(list_ccps_numbers)\nlist_ccps_numbers_SQL_prc = list_ccps_numbers_SQL \/ sum(list_ccps_numbers_SQL)\n\nfig = go.Figure(data=[\n    go.Bar(name='2019 data', x=list_ccps, y=list_ccps_numbers_prc),\n    go.Bar(name='2019 data SQL', x=list_ccps, y=list_ccps_numbers_SQL_prc),\n])\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.update_layout(title_text=\"Specific cloud computing products do you use on a regular basis\",\n        yaxis=dict(\n        title='Percent',\n        titlefont_size=16,\n        tickfont_size=14,)), \nfig.show()    ","4dc06892":"\nQ31cols = ['Q31_Part_1','Q31_Part_2','Q31_Part_3','Q31_Part_4','Q31_Part_5','Q31_Part_6','Q31_Part_7','Q31_Part_8','Q31_Part_9','Q31_Part_10','Q31_Part_11','Q31_Part_12']\n\nlist_bds = []\nlist_bds_numbers = []\nlist_bds_numbers_SQL = []\n\n\nfor col in Q31cols:\n    \n    bds = multiple_choice_responses_2019[col].value_counts().index[0] \n    bds_numbers = multiple_choice_responses_2019[col].value_counts()[0] \n    bds_numbers_SQL = multiple_choice_responses_2019[col][multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts()[0] \n    \n    \n    list_bds.append(bds)\n    list_bds_numbers.append(bds_numbers)\n    list_bds_numbers_SQL.append(bds_numbers_SQL)\n    \nlist_bds_numbers_prc = list_bds_numbers \/ sum(list_bds_numbers)\nlist_bds_numbers_SQL_prc = list_bds_numbers_SQL \/ sum(list_bds_numbers_SQL)\n\nfig = go.Figure(data=[\n    go.Bar(name='2019 data', x=list_bds, y=list_bds_numbers_prc),\n    go.Bar(name='2019 data SQL', x=list_bds, y=list_bds_numbers_SQL_prc),\n])\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.update_layout(title_text=\"Specific big data \/ analytics products do you use on a regular basis\",\n        yaxis=dict(\n        title='Percent',\n        titlefont_size=16,\n        tickfont_size=14,)), \nfig.show()    \n","584cee0c":"Q32cols = ['Q32_Part_1','Q32_Part_2','Q32_Part_3','Q32_Part_4','Q32_Part_5','Q32_Part_6','Q32_Part_7','Q32_Part_8','Q32_Part_9','Q32_Part_10','Q32_Part_11','Q32_Part_12']\n\nlist_mlps = []\nlist_mlps_numbers = []\nlist_mlps_numbers_SQL = []\n\nfor col in Q32cols:\n    mlps = multiple_choice_responses_2019[col].value_counts().index[0] \n    mlps_numbers = multiple_choice_responses_2019[col].value_counts()[0] \n    mlps_numbers_SQL = multiple_choice_responses_2019[col][multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts()[0] \n    \n    list_mlps.append(mlps)\n    list_mlps_numbers.append(mlps_numbers)\n    list_mlps_numbers_SQL.append(mlps_numbers_SQL)\n\nlist_mlps_numbers_prc = list_mlps_numbers \/ sum(list_mlps_numbers)\nlist_mlps_numbers_SQL_prc = list_mlps_numbers_SQL \/ sum(list_mlps_numbers_SQL)\n\nfig = go.Figure(data=[\n    go.Bar(name='2019 data', x=list_mlps, y=list_mlps_numbers_prc),\n    go.Bar(name='2019 data SQL', x=list_mlps, y=list_mlps_numbers_SQL_prc),\n])\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.update_layout(title_text=\"Following machine learning products do you use on a regular basis \",\n        yaxis=dict(\n        title='Percent',\n        titlefont_size=16,\n        tickfont_size=14,)), \nfig.show() \n    \n","64b5d945":"Q33cols = ['Q33_Part_1','Q33_Part_2','Q33_Part_3','Q33_Part_4','Q33_Part_5','Q33_Part_6','Q33_Part_7','Q33_Part_8','Q33_Part_9','Q33_Part_10','Q33_Part_11','Q33_Part_12']\n\nlist_amlts = []\nlist_amlts_numbers = []\nlist_amlts_numbers_SQL = []\n\n\nfor col in Q33cols:\n    \n    amlts = multiple_choice_responses_2019[col].value_counts().index[0] \n    amlts_numbers = multiple_choice_responses_2019[col].value_counts()[0] \n    amlts_numbers_SQL = multiple_choice_responses_2019[col][multiple_choice_responses_2019.Q18_Part_3 == \"SQL\"].value_counts()[0] \n    \n    list_amlts.append(amlts)\n    list_amlts_numbers.append(amlts_numbers)\n    list_amlts_numbers_SQL.append(amlts_numbers_SQL)\n\nlist_amlts_numbers_prc = list_amlts_numbers \/ sum(list_amlts_numbers)\nlist_amlts_numbers_SQL_prc = list_amlts_numbers_SQL \/ sum(list_amlts_numbers_SQL)\n\nfig = go.Figure(data=[\n    go.Bar(name='2019 data', x=list_amlts, y=list_amlts_numbers_prc),\n    go.Bar(name='2019 data SQL', x=list_amlts, y=list_amlts_numbers_SQL_prc),\n])\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.update_layout(title_text=\"Automated machine learning tools (or partial AutoML tools) do you use on a regular basis\",\n        yaxis=dict(\n        title='Percent',\n        titlefont_size=16,\n        tickfont_size=14,)), \nfig.show() \n","f24c3485":"multiple_choice_responses_2019.Q34_Part_1.value_counts()\n\nQ34cols = ['Q34_Part_1','Q34_Part_2','Q34_Part_3','Q34_Part_4','Q34_Part_5','Q34_Part_6','Q34_Part_7','Q34_Part_8','Q34_Part_9','Q34_Part_10','Q34_Part_11','Q34_Part_12']\n\nlist_dbs = []\nlist_dbs_numbers = []\n\nfor col in Q34cols:\n    \n    dbs = multiple_choice_responses_2019[col].value_counts().index[0] \n    dbs_numbers = multiple_choice_responses_2019[col].value_counts()[0] \n    \n    list_dbs.append(dbs)\n    list_dbs_numbers.append(dbs_numbers)\n    \ng = sns.barplot(x=list_dbs, y=list_dbs_numbers)\ng.set_xticklabels(g.get_xticklabels(), rotation=80)\nplt.title(\"The following relational database products do you use on a regular basis in 2019\")\ng.set_ylabel('Number of respondents.')\n\nfor ix, x in zip(range(len(list_dbs_numbers)+1),list_dbs_numbers):\n    g.text(ix,x,x, horizontalalignment='center')\n\nplt.show()","74fe1f64":"junior_ml_devs = multiple_choice_responses_2019.Q3[(multiple_choice_responses_2019.Q23 == '< 1 years') | (multiple_choice_responses_2019.Q23 == '1-2 years')| (multiple_choice_responses_2019.Q23 ==  '2-3 years')].value_counts()[:5]\nmid_ml_devs = multiple_choice_responses_2019.Q3[(multiple_choice_responses_2019.Q23 == '3-4 years') | (multiple_choice_responses_2019.Q23 == '4-5 years')].value_counts()[:5]\nsenior_ml_devs = multiple_choice_responses_2019.Q3[(multiple_choice_responses_2019.Q23 == '5-10 years') | (multiple_choice_responses_2019.Q23 == '10-15 years') | (multiple_choice_responses_2019.Q23 == '20+ years') ].value_counts()[:5]\n\nplt.figure(3, figsize=(20,5))\nthe_grid = GridSpec(1, 3)\n\n# Junior Developers are from these top 5 countries.\n\nplt.subplot(the_grid[0, 0])\ng = sns.barplot(x=junior_ml_devs.index, y=junior_ml_devs.values)\ng.set_xticklabels(junior_ml_devs.index, rotation=80)\ng.set_ylabel(\"Number of respondents\")\nplt.title(\"Countries where junior ML developers come from in 2019 survey.\")\n\n\n# Middle developers are from these top 5 countries.\n\nplt.subplot(the_grid[0, 1])\ng = sns.barplot(x=mid_ml_devs.index, y=mid_ml_devs.values)\ng.set_xticklabels(mid_ml_devs.index, rotation=80)\ng.set_ylabel(\"Number of respondents\")\nplt.title(\"Countries where middle-level ML developers come from in 2019 survey.\")\n\n\n# Senior developers are from these top 5 countries.\n\nplt.subplot(the_grid[0, 2])\n\ng = sns.barplot(x=senior_ml_devs.index, y=senior_ml_devs.values)\ng.set_xticklabels(senior_ml_devs.index, rotation=80)\ng.set_ylabel(\"Number of respondents\")\nplt.title(\"Countries where senior ML developer come from in 2019 survey.\")\n\nplt.show()","feb6097d":"Q18cols = ['Q18_Part_1','Q18_Part_2','Q18_Part_3','Q18_Part_4','Q18_Part_5','Q18_Part_6','Q18_Part_7','Q18_Part_8','Q18_Part_9','Q18_Part_10','Q18_Part_11','Q18_Part_12']\n\nl_junior_ml_dev_lang = []\nl_junior_ml_dev_lang_num = [] \n\nfor col in Q18cols:\n \n    junior_ml_devs = multiple_choice_responses_2019[col][(multiple_choice_responses_2019.Q23 == '< 1 years') | (multiple_choice_responses_2019.Q23 == '1-2 years')| (multiple_choice_responses_2019.Q23 ==  '2-3 years')].value_counts()\n    junior_ml_dev_lang = junior_ml_devs.index[0]\n    junior_ml_dev_lang_num = junior_ml_devs.values[0]\n    \n    l_junior_ml_dev_lang.append(junior_ml_dev_lang)\n    l_junior_ml_dev_lang_num.append(junior_ml_dev_lang_num)\n\n    \nl_mid_ml_dev_lang = []\nl_mid_ml_dev_lang_num = [] \n\nfor col in Q18cols:\n    \n    mid_ml_devs = multiple_choice_responses_2019[col][(multiple_choice_responses_2019.Q23 == '3-4 years') | (multiple_choice_responses_2019.Q23 == '4-5 years')].value_counts()\n\n    mid_ml_dev_lang = mid_ml_devs.index[0]  \n    mid_ml_dev_lang_num = mid_ml_devs.values[0]\n    \n    l_mid_ml_dev_lang.append(mid_ml_dev_lang)\n    l_mid_ml_dev_lang_num.append(mid_ml_dev_lang_num)\n\nl_senior_ml_dev_lang = []\nl_senior_ml_dev_lang_num = [] \n\n\nfor col in Q18cols:\n\n    senior_ml_devs = multiple_choice_responses_2019[col][(multiple_choice_responses_2019.Q23 == '5-10 years') | (multiple_choice_responses_2019.Q23 == '10-15 years') | (multiple_choice_responses_2019.Q23 == '20+ years') ].value_counts()\n\n    senior_ml_dev_lang = senior_ml_devs.index[0]  \n    senior_ml_dev_lang_num = senior_ml_devs.values[0]\n    \n    l_senior_ml_dev_lang.append(senior_ml_dev_lang)\n    l_senior_ml_dev_lang_num.append(senior_ml_dev_lang_num)\n\n    \nplt.figure(3, figsize=(20,5))\nthe_grid = GridSpec(1, 3)\n\n# Junior Developers.\n\nplt.subplot(the_grid[0, 0])\ng = sns.barplot(x=l_junior_ml_dev_lang, y=l_junior_ml_dev_lang_num)\ng.set_xticklabels(l_junior_ml_dev_lang, rotation=80)\ng.set_ylabel(\"Number of respondents\")\nplt.title(\"Programming languages junior ML developers use in 2019 survey.\")\n\n\n# Middle-level developers.\n\nplt.subplot(the_grid[0, 1])\ng = sns.barplot(x=l_mid_ml_dev_lang, y=l_mid_ml_dev_lang_num)\ng.set_xticklabels(l_mid_ml_dev_lang, rotation=80)\ng.set_ylabel(\"Number of respondents\")\nplt.title(\"Programming languages middle-level ML developers use in 2019 survey\")\n\n\n# Senior developers.\n\nplt.subplot(the_grid[0, 2])\n\ng = sns.barplot(x=l_senior_ml_dev_lang, y=l_senior_ml_dev_lang_num)\ng.set_xticklabels(l_senior_ml_dev_lang, rotation=80)\ng.set_ylabel(\"Number of respondents\")\nplt.title(\"Programming languages senior ML developers use in 2019 survey\")\n\nplt.show()","df16b105":"Q16cols = ['Q16_Part_1','Q16_Part_2','Q16_Part_3','Q16_Part_4','Q16_Part_5','Q16_Part_6','Q16_Part_7','Q16_Part_8','Q16_Part_9','Q16_Part_10','Q16_Part_11','Q16_Part_12']\n\nl_junior_ml_dev_ide = []\nl_junior_ml_dev_ide_num = [] \n\nfor col in Q16cols:\n \n    junior_ml_devs = multiple_choice_responses_2019[col][(multiple_choice_responses_2019.Q23 == '< 1 years') | (multiple_choice_responses_2019.Q23 == '1-2 years')| (multiple_choice_responses_2019.Q23 ==  '2-3 years')].value_counts()\n    junior_ml_dev_ide = junior_ml_devs.index[0]\n    junior_ml_dev_ide_num = junior_ml_devs.values[0]\n    \n    l_junior_ml_dev_ide.append(junior_ml_dev_ide)\n    l_junior_ml_dev_ide_num.append(junior_ml_dev_ide_num)\n\n    \nl_mid_ml_dev_ide = []\nl_mid_ml_dev_ide_num = [] \n\nfor col in Q16cols:\n    \n    mid_ml_devs = multiple_choice_responses_2019[col][(multiple_choice_responses_2019.Q23 == '3-4 years') | (multiple_choice_responses_2019.Q23 == '4-5 years')].value_counts()\n\n    mid_ml_dev_ide = mid_ml_devs.index[0]  \n    mid_ml_dev_ide_num = mid_ml_devs.values[0]\n    \n    l_mid_ml_dev_ide.append(mid_ml_dev_ide)\n    l_mid_ml_dev_ide_num.append(mid_ml_dev_ide_num)\n\nl_senior_ml_dev_ide = []\nl_senior_ml_dev_ide_num = [] \n\n\nfor col in Q16cols:\n\n    senior_ml_devs = multiple_choice_responses_2019[col][(multiple_choice_responses_2019.Q23 == '5-10 years') | (multiple_choice_responses_2019.Q23 == '10-15 years') | (multiple_choice_responses_2019.Q23 == '20+ years') ].value_counts()\n\n    senior_ml_dev_ide = senior_ml_devs.index[0]  \n    senior_ml_dev_ide_num = senior_ml_devs.values[0]\n    \n    l_senior_ml_dev_ide.append(senior_ml_dev_ide)\n    l_senior_ml_dev_ide_num.append(senior_ml_dev_ide_num)\n\n    \nplt.figure(3, figsize=(20,5))\nthe_grid = GridSpec(1, 3)\n\n# Junior Developers.\n\nplt.subplot(the_grid[0, 0])\ng = sns.barplot(x=l_junior_ml_dev_ide, y=l_junior_ml_dev_ide_num)\ng.set_xticklabels(l_junior_ml_dev_ide, rotation=80)\ng.set_ylabel(\"Number of respondents\")\nplt.title(\"IDEs junior ML developers use in 2019 survey.\")\n\n\n# Middle-level developers.\n\nplt.subplot(the_grid[0, 1])\ng = sns.barplot(x=l_mid_ml_dev_ide, y=l_mid_ml_dev_ide_num)\ng.set_xticklabels(l_mid_ml_dev_ide, rotation=80)\ng.set_ylabel(\"Number of respondents\")\nplt.title(\"IDEs middle-level ML developers use in 2019 survey\")\n\n\n# Senior developers.\n\nplt.subplot(the_grid[0, 2])\n\ng = sns.barplot(x=l_senior_ml_dev_ide, y=l_senior_ml_dev_ide_num)\ng.set_xticklabels(l_senior_ml_dev_ide, rotation=80)\ng.set_ylabel(\"Number of respondents\")\nplt.title(\"IDEs senior ML developers use in 2019 survey\")\n\nplt.show()\n","fcb51807":"Q34cols = ['Q34_Part_1','Q34_Part_2','Q34_Part_3','Q34_Part_4','Q34_Part_5','Q34_Part_6','Q34_Part_7','Q34_Part_8','Q34_Part_9','Q34_Part_10','Q34_Part_11','Q34_Part_12']\n\nl_junior_ml_dev_db = []\nl_junior_ml_dev_db_num = [] \n\nfor col in Q34cols:\n \n    junior_ml_devs = multiple_choice_responses_2019[col][(multiple_choice_responses_2019.Q23 == '< 1 years') | (multiple_choice_responses_2019.Q23 == '1-2 years')| (multiple_choice_responses_2019.Q23 ==  '2-3 years')].value_counts()\n    junior_ml_dev_db = junior_ml_devs.index[0]\n    junior_ml_dev_db_num = junior_ml_devs.values[0]\n    \n    l_junior_ml_dev_db.append(junior_ml_dev_db)\n    l_junior_ml_dev_db_num.append(junior_ml_dev_db_num)\n\n    \nl_mid_ml_dev_db = []\nl_mid_ml_dev_db_num = [] \n\nfor col in Q34cols:\n    \n    mid_ml_devs = multiple_choice_responses_2019[col][(multiple_choice_responses_2019.Q23 == '3-4 years') | (multiple_choice_responses_2019.Q23 == '4-5 years')].value_counts()\n\n    mid_ml_dev_db = mid_ml_devs.index[0]  \n    mid_ml_dev_db_num = mid_ml_devs.values[0]\n    \n    l_mid_ml_dev_db.append(mid_ml_dev_db)\n    l_mid_ml_dev_db_num.append(mid_ml_dev_db_num)\n\nl_senior_ml_dev_db = []\nl_senior_ml_dev_db_num = [] \n\n\nfor col in Q34cols:\n\n    senior_ml_devs = multiple_choice_responses_2019[col][(multiple_choice_responses_2019.Q23 == '5-10 years') | (multiple_choice_responses_2019.Q23 == '10-15 years') | (multiple_choice_responses_2019.Q23 == '20+ years') ].value_counts()\n\n    senior_ml_dev_db = senior_ml_devs.index[0]  \n    senior_ml_dev_db_num = senior_ml_devs.values[0]\n    \n    l_senior_ml_dev_db.append(senior_ml_dev_db)\n    l_senior_ml_dev_db_num.append(senior_ml_dev_db_num)\n\n    \nplt.figure(3, figsize=(20,5))\nthe_grid = GridSpec(1, 3)\n\n# Junior Developers.\n\nplt.subplot(the_grid[0, 0])\ng = sns.barplot(x=l_junior_ml_dev_db, y=l_junior_ml_dev_db_num)\ng.set_xticklabels(l_junior_ml_dev_db, rotation=80)\ng.set_ylabel(\"Number of respondents\")\nplt.title(\"Relational database popular among junior ML developers\")\n\n\n# Middle-level developers.\n\nplt.subplot(the_grid[0, 1])\ng = sns.barplot(x=l_mid_ml_dev_db, y=l_mid_ml_dev_db_num)\ng.set_xticklabels(l_mid_ml_dev_db, rotation=80)\ng.set_ylabel(\"Number of respondents\")\nplt.title(\"Relational database popular among middle-level ML developers\")\n\n\n# Senior developers.\n\nplt.subplot(the_grid[0, 2])\n\ng = sns.barplot(x=l_senior_ml_dev_db, y=l_senior_ml_dev_db_num)\ng.set_xticklabels(l_senior_ml_dev_db, rotation=80)\ng.set_ylabel(\"Number of respondents\")\nplt.title(\"Relational database popular among senior ML developers\")\n\nplt.show()\n","403750c1":"compensation_order = ['$0-999', '1,000-1,999', '2,000-2,999', '3,000-3,999','4,000-4,999',\n                      '5,000-7,499', '7,500-9,999','10,000-14,999','15,000-19,999',  \n                      '20,000-24,999','25,000-29,999','30,000-39,999','40,000-49,999', \n                      '50,000-59,999','60,000-69,999','70,000-79,999','80,000-89,999',\n                      '90,000-99,999','100,000-124,999','125,000-149,999', \n                      '150,000-199,999','200,000-249,999','250,000-299,999', '300,000-500,000', '> $500,000']\nvalues_compensation = multiple_choice_responses_2019.Q10.value_counts()[compensation_order].values\n\n \njunior_ml_devs = multiple_choice_responses_2019.Q10[(multiple_choice_responses_2019.Q23 == '< 1 years') | (multiple_choice_responses_2019.Q23 == '1-2 years')| (multiple_choice_responses_2019.Q23 ==  '2-3 years')].value_counts()[compensation_order].values\nmid_ml_devs = multiple_choice_responses_2019.Q10[(multiple_choice_responses_2019.Q23 == '3-4 years') | (multiple_choice_responses_2019.Q23 == '4-5 years')].value_counts()[compensation_order].values\nsenior_ml_devs = multiple_choice_responses_2019.Q10[(multiple_choice_responses_2019.Q23 == '5-10 years') | (multiple_choice_responses_2019.Q23 == '10-15 years') | (multiple_choice_responses_2019.Q23 == '20+ years') ].value_counts()[compensation_order].values\n\n    \nplt.figure(3, figsize=(20,5))\nthe_grid = GridSpec(1, 3)\n\n# Junior Developers.\n\nplt.subplot(the_grid[0, 0])\ng = sns.barplot(x=compensation_order, y=junior_ml_devs)\ng.set_xticklabels(compensation_order, rotation=80)\ng.set_ylabel(\"Number of respondents\")\nplt.title(\"Yearly compensation for junior developers in 2019 survey.\")\n\n\n# Middle-level developers.\n\nplt.subplot(the_grid[0, 1])\ng = sns.barplot(x=compensation_order, y=mid_ml_devs)\ng.set_xticklabels(compensation_order, rotation=80)\ng.set_ylabel(\"Number of respondents\")\nplt.title(\"Yearly compensation for middle-level developers in 2019 survey\")\n\n\n# Senior developers.\n\nplt.subplot(the_grid[0, 2])\n\ng = sns.barplot(x=compensation_order, y=senior_ml_devs)\ng.set_xticklabels(compensation_order, rotation=80)\ng.set_ylabel(\"Number of respondents\")\nplt.title(\"Yearly compensation for senior developers in 2019 survey\")\n\nplt.show()\n","ef42c580":"compensation_order = ['$0-999', '1,000-1,999', '2,000-2,999', '3,000-3,999','4,000-4,999',\n                      '5,000-7,499', '7,500-9,999','10,000-14,999','15,000-19,999',  \n                      '20,000-24,999','25,000-29,999','30,000-39,999','40,000-49,999', \n                      '50,000-59,999','60,000-69,999','70,000-79,999','80,000-89,999',\n                      '90,000-99,999','100,000-124,999','125,000-149,999', \n                      '150,000-199,999','200,000-249,999','250,000-299,999', '300,000-500,000', '> $500,000']\n\npython_devs = multiple_choice_responses_2019.Q10[multiple_choice_responses_2019.Q18_Part_1 == 'Python'].value_counts()[compensation_order].values\nSQL_devs = multiple_choice_responses_2019.Q10[multiple_choice_responses_2019.Q18_Part_3 == 'SQL'].value_counts()[compensation_order].values\nR_devs = multiple_choice_responses_2019.Q10[multiple_choice_responses_2019.Q18_Part_2 == 'R' ].value_counts()[compensation_order].values\nJava_devs = multiple_choice_responses_2019.Q10[multiple_choice_responses_2019.Q18_Part_6 == 'Java' ].value_counts()[compensation_order].values\nCpp_devs = multiple_choice_responses_2019.Q10[multiple_choice_responses_2019.Q18_Part_5 == 'C++' ].value_counts()[compensation_order].values\n\nplt.figure(2, figsize=(12,20))\nthe_grid = GridSpec(3, 2, hspace=0.5)\n\n# Python Developers.\n\nplt.subplot(the_grid[0, 0])\ng = sns.barplot(x=compensation_order, y=python_devs)\ng.set_xticklabels(compensation_order, rotation=80)\ng.set_ylabel(\"Number of respondents\")\nplt.title(\"Yearly compensation for Python developers in 2019 survey.\")\n\n\n# SQL developers.\n\nplt.subplot(the_grid[0, 1])\ng = sns.barplot(x=compensation_order, y=SQL_devs)\ng.set_xticklabels(compensation_order, rotation=80)\ng.set_ylabel(\"Number of respondents\")\nplt.title(\"Yearly compensation for SQL developers in 2019 survey\")\n\n\n# R developers.\n\nplt.subplot(the_grid[1, 0])\n\ng = sns.barplot(x=compensation_order, y=R_devs)\ng.set_xticklabels(compensation_order, rotation=80)\ng.set_ylabel(\"Number of respondents\")\nplt.title(\"Yearly compensation for R developers in 2019 survey\")\n\n# Java developers.\n\nplt.subplot(the_grid[1, 1])\ng = sns.barplot(x=compensation_order, y=Java_devs)\ng.set_xticklabels(compensation_order, rotation=80)\ng.set_ylabel(\"Number of respondents\")\nplt.title(\"Yearly compensation for Java developers in 2019 survey\")\n\n\n# C++ developers.\n\nplt.subplot(the_grid[2, 0])\n\ng = sns.barplot(x=compensation_order, y=Cpp_devs)\ng.set_xticklabels(compensation_order, rotation=80)\ng.set_ylabel(\"Number of respondents\")\nplt.title(\"Yearly compensation for C++ developers in 2019 survey\")\n\n\nplt.show()\n","643728e2":"low_python_devs = multiple_choice_responses_2019.Q3[(multiple_choice_responses_2019.Q18_Part_1 == 'Python') &\n                                                   (multiple_choice_responses_2019.Q10 == '$0-999') | (multiple_choice_responses_2019.Q10 == '1000-1999')].value_counts()\n\nhigh_python_devs = multiple_choice_responses_2019.Q3[(multiple_choice_responses_2019.Q18_Part_1 == 'Python') &\n                                                   (multiple_choice_responses_2019.Q10 == '100,000-124,999') | (multiple_choice_responses_2019.Q10 == '125,000-149,999')].value_counts()\n \n\ncountry = low_python_devs.index\ncountry = pd.Series(country)\ncountry = country.replace('United Kingdom of Great Britain and Northern Ireland','UK')\ncountry = country.replace('United States of America','USA')\ncountry_values = low_python_devs.values\n\nplt.figure(figsize=(16, 6))\ng = sns.barplot(x=country, y=country_values)\ng.set_xticklabels(g.get_xticklabels(), rotation=90)\ng.set_ylabel(\"Number of respondens.\")\n\nfor ix, x in zip(range(len(country_values)+1),country_values):\n    g.text(ix,x,x, horizontalalignment='center')\n    \nplt.title(\"Low pay '$0-999' or '1000-1999' country distribution in 2019 survey.\")\nplt.show()","a0f61573":"country = high_python_devs.index\ncountry = pd.Series(country)\ncountry = country.replace('United Kingdom of Great Britain and Northern Ireland','UK')\ncountry = country.replace('United States of America','USA')\ncountry_values = high_python_devs.values\n\nplt.figure(figsize=(16, 6))\ng = sns.barplot(x=country, y=country_values)\ng.set_xticklabels(g.get_xticklabels(), rotation=90)\ng.set_ylabel(\"Number of respondens.\")\n\nfor ix, x in zip(range(len(country_values)+1),country_values):\n    g.text(ix,x,x, horizontalalignment='center')\n    \nplt.title(\"High pay '100,000-124,999' or '125,000-149,999' country distribution in 2019 survey.\")\nplt.show()","f67d24ea":"Q12cols = ['Q12_Part_1','Q12_Part_2','Q12_Part_3','Q12_Part_4','Q12_Part_5','Q12_Part_6','Q12_Part_7','Q12_Part_8','Q12_Part_9','Q12_Part_10','Q12_Part_11','Q12_Part_12']\n\nlist_number_of_media_sources = []\nlist_of_media_sources = []\n\nfor col in Q12cols:\n    media_source = multiple_choice_responses_2019[col][(multiple_choice_responses_2019.Q18_Part_1 == 'Python')].value_counts().index[0] \n    number_media_sources = multiple_choice_responses_2019[col][(multiple_choice_responses_2019.Q18_Part_1 == 'Python')].value_counts()[0] \n    list_number_of_media_sources.append(number_media_sources)\n    list_of_media_sources.append(media_source)\n\nfig, ax = plt.subplots() \n    \nax.barh(list_of_media_sources, list_number_of_media_sources, align='center', color=(0.6, 0.4, 0.6, 0.6))\nax.set_yticklabels(list_of_media_sources)\nax.invert_yaxis()  # labels read top-to-bottom\nax.set_xlabel('Number of respondents.')\nax.set_title('Pythonistas favorite media sources that report on data science topics.')\nfor i, v in enumerate(list_number_of_media_sources):\n    ax.text(v + 3, i + .25, str(v), color='black', fontweight='bold')\n\nplt.show()","e2fe8ab1":"Q24cols = ['Q24_Part_1','Q24_Part_2','Q24_Part_3','Q24_Part_4','Q24_Part_5','Q24_Part_6','Q24_Part_7','Q24_Part_8','Q24_Part_9','Q24_Part_10','Q24_Part_11','Q24_Part_12']\n\nlist_ml_tools = []\nlist_ml_tools_numbers = []\n\nfor col in Q24cols:\n    ml_tools = multiple_choice_responses_2019[col][(multiple_choice_responses_2019.Q18_Part_1 == 'Python')].value_counts().index[0] \n    ml_tools_numbers = multiple_choice_responses_2019[col][(multiple_choice_responses_2019.Q18_Part_1 == 'Python')].value_counts()[0] \n    list_ml_tools.append(ml_tools)\n    list_ml_tools_numbers.append(ml_tools_numbers)\n\nfig, ax = plt.subplots()\n\nax.barh(list_ml_tools, list_ml_tools_numbers, align='center', color=(0.6, 0.4, 0.6, 0.6))\nax.set_yticklabels(list_ml_tools)\nax.invert_yaxis()  # labels read top-to-bottom\nax.set_xlabel('Number of respondents.')\nax.set_title('ML algorithms Pythonistas use on a regular basis in 2019.')\nfor i, v in enumerate(list_ml_tools_numbers):\n    ax.text(v + 3, i + .25, str(v), color='black', fontweight='bold')\n\nplt.show()","cb1e8c0a":"Q13cols = ['Q13_Part_1','Q13_Part_2','Q13_Part_3','Q13_Part_4','Q13_Part_5','Q13_Part_6','Q13_Part_7','Q13_Part_8','Q13_Part_9','Q13_Part_10','Q13_Part_11','Q13_Part_12']\n\nlist_science_courses = []\nlist_number_science_courses = []\n\nfor col in Q13cols:\n    science_course = multiple_choice_responses_2019[col][(multiple_choice_responses_2019.Q18_Part_1 == 'Python')].value_counts().index[0] \n    number_science_courses = multiple_choice_responses_2019[col][(multiple_choice_responses_2019.Q18_Part_1 == 'Python')].value_counts()[0] \n    list_number_science_courses.append(number_science_courses)\n    list_science_courses.append(science_course)\n\nfig, ax = plt.subplots()\n\nax.barh(list_science_courses, list_number_science_courses, align='center', color=(0.6, 0.4, 0.6, 0.6))\nax.set_yticklabels(list_science_courses)\nax.invert_yaxis()  # labels read top-to-bottom\nax.set_xlabel('Number of respondents.')\nax.set_title('Platforms that Pythonistas have begun or completed data science courses in 2019 survey.')\nfor i, v in enumerate(list_number_science_courses):\n    ax.text(v + 3, i + .25, str(v), color='black', fontweight='bold')\n\nplt.show()","f50da1db":"### Pythonistas favorite ML algorithms <a class=\"anchor\" id=\"Q43\"><\/a>","581bcdd6":"### Yearly compensation among junior, middle-level and senior developers <a class=\"anchor\" id=\"Q39\"><\/a>","600e792b":"It seems that relatively there are more respondents that earn more that use Python, SQL, R languages rather than C++ or Java. But that might be different in other surveys where Java and C++ are more popular languages.","39c90fb2":"We can se that SQL user more often user Linear or Logistic regression models, Decision tree models, Gradient boosting and Bayesian aproachees. While general users more often use Neural network models.\n","0910685e":"## Q28\n### Machine learning frameworks do you use on a regular basis <a class=\"anchor\" id=\"Q28\"><\/a>","c561b1f7":"As you can see Python is the most used language. R, SQL and C++ are slightly more popular among senior level ML developer than a junior level.","c411e852":"Let's find out which relational database product is popular among junior, middle-level, senior ML developers.","4bbbf6a0":"### Yearly compensation depending of which progamming language you use <a class=\"anchor\" id=\"Q40\"><\/a>","8ded5000":"As we can see from the graph the main tools for developent for respondents and SQL users are local development environment 54%. There are slight increases of SQL users in Cloud-based software and Business intelligence software. ","7e0a78e2":"As we can see from the chart most popular IDE is Jupyter notebook. There is not much difference between general programmers and once that use SQL programming languages. Their preference for IDEs are almost identical. Just slight increase in RStudio and Notepad++.","d5552245":"## Q21\n### Types of specialized hardware do you use on a regular basis <a class=\"anchor\" id=\"Q21\"><\/a>","bc4bb36f":"From diagrams we can see that most popular relational database is MySQL. It seems that PostgresSQL, SQLite and Microsoft SQL Server are more popular among mid and senior level developers than of junior level.","37f8bb00":"## Q25\n### Categories of ML tools do you use on a regular basis <a class=\"anchor\" id=\"Q25\"><\/a>","6037e374":"## Q10\n### Yearly compensation (approximate $USD) <a class=\"anchor\" id=\"Q10\"><\/a>","7382bbdc":"The NLP tools are almost the same for both groups general and SQL user group.","6a156331":"## Q33\n### Automated machine learning tools (or partial AutoML tools) do you use on a regular basis <a class=\"anchor\" id=\"Q33\"><\/a>","72a26e46":"All positive answers to question of employer incorporating ML methods in their current acitivities where higher in respondents using SQL. Consequently negative aswerst to the question where in general respondents group.","052435f3":"## Q27\n### The following natural language processing (NLP) methods do you use on a regular basis <a class=\"anchor\" id=\"Q27\"><\/a>","0043a39e":"We see that the most popular IDE is a Jupyter notebook. However for senior ML developers RStudio and Vim is reletively more popular than for junior ML developers.","89607a63":"We can see from the graph that SQL users use more of almost all specific cloud computer products compared to general respondents. This also confirms that we see lower percentage of column None for SQL users.","58e74fef":"As you can see from the pie chart there are not that many differences in roles at work for SQL users and general respondents. ","5314d6bb":"## Q1-Q2\n### Gender of respondents<a class=\"anchor\" id=\"Q2\"><\/a>","30833a35":"## Q8\n### Employer incorporate machine learning methods into their business  <a class=\"anchor\" id=\"Q8\"><\/a>","01640c10":"Lets separate our ML developer in 3 groups according to experience in ML. And look at top 5 countries where these developers come from: junior developer: <1-3, middle-level developer: 3-5, senior developer: 5-20+","139e02dc":"From the graphs you can see that main respondents about half of respondents have a Master degree and about one third of respondents have a Bachelor's degree. About 14% of respondents have a doctoral degree. There are some minor differences in respondents that are SQL users but trends are the same.","2c921d4d":"As you see from the chart most respondents are with 1-2 year experience. From the chart you also see that most of the respondents that use SQL programming language have more experience in programming. ","5f50862f":" Which programming language is paying more.","b80ed658":"## Q9\n### Important part of your role at work  <a class=\"anchor\" id=\"Q9\"><\/a>","f93de683":"## Q15\n### Time span you have been writing code to analyze data. <a class=\"anchor\" id=\"Q14\"><\/a>","a26a7a0e":"### IDE popular among junior, middle-level and senior developers <a class=\"anchor\" id=\"Q37\"><\/a>","4c1d5077":"# Introduction\n\nI am very excited to analyze Kaggle's annual survey data. Not just because there it is plenty of graphs to make. But it is my own curiosity to know which programming languages are most popular among other developers, which tools do they use for data analysis and more... You can divide my analysis in two main parts. [First](#first) plot all the questions and for a sake of my own curiosity compare them with SQL users data. [Second](#second) part is just questions that I was interested to ask after analyzing all general questions. After every graph I leave a short comment. If you find something interesting leave a comment below. I would be happy to start a discussion ! Or may be make further inquiries! I hope you get some new information about other developers from my data or atleast something new about SQL users. Have fun!","9ae77e6a":"## Q12\n### Your favorite media sources that report on data science topics <a class=\"anchor\" id=\"Q12\"><\/a>","e1c79f0e":"### Pythonistas favorite media sources that report on data science topics <a class=\"anchor\" id=\"Q42\"><\/a>","0afc9efd":"## Q1-Q2\n### Gender of respondents of SQL users<a class=\"anchor\" id=\"Q2-SQL\"><\/a>","b214c002":"We can see from the graph that SQL users use more of automated machine learning tools compared to general respondents. This also confirms that we see lower percentage of column None for SQL users.","bc76a804":"You can see from the chart that SQL user have more experience using machine learning methods compared with general respondents.","104973bc":"## Q34\n### The following relational database products do you use on a regular basis <a class=\"anchor\" id=\"Q34\"><\/a>","9a8e6d66":"As you can see Image classification tool is the most used among both groups of respondents. There is slight increase in None category of SQL users. It might make sense since SQL users are less likely to use computer vision tools.","e39e0a1c":"## Q4\n### The highest level of formal education of SQL users <a class=\"anchor\" id=\"Q4-SQL\"><\/a>","7b8b0cdb":"## Q23\n### Use of machine learning methods <a class=\"anchor\" id=\"Q23\"><\/a>","58a6b912":"## Q14\n### The primary tool that you use at work or school to analyze data <a class=\"anchor\" id=\"Q14\"><\/a>","9debc1c5":"## Q7\n###  Approximate number of individuals are responsible for data science workloads at your place of business <a class=\"anchor\" id=\"Q7\"><\/a>","e48543a4":"It would also be interesting to investigate from which country low and high paid Pythonistas come from.  ","575d05a3":"## Q4\n### The highest level of formal education <a class=\"anchor\" id=\"Q4\"><\/a>","843b1df7":"### Countries where highly paid Pythonistas come from <a class=\"anchor\" id=\"Q41\"><\/a>","0cefa568":"From the graph we can see that the highest number of respondents obtain the lowest yearly compensation(0-999 USD). It is also interesting to notice that SQL users obtain slightly higher compensation in a salary range from 50,000 USD to 150,000 USD. ","6ef1b2c5":"We can see from the graph that SQL users use more of big data \/ analytics products compared to general respondents. This also confirms that we see lower percentage of column None for SQL users.","ee256d34":"As you can see from the chart the most used hardware tool in DS is CPU in the second place GPU.","7bb88eb1":"## Q24\n### ML algorithms do you use on a regular basis <a class=\"anchor\" id=\"Q24\"><\/a>","bc077cdd":"Let's find our which programming language is popular among junior, middle-level, senior ML developers.","7f88f59e":"## Q19\n### Programming language would you recommend an aspiring data scientist to learn first <a class=\"anchor\" id=\"Q19\"><\/a>","3f7af6c8":"### Programming language popular among junior, middle-level and senior developers <a class=\"anchor\" id=\"Q36\"><\/a>","129894ca":"### Relational database popular among junior, middle-level and senior developers <a class=\"anchor\" id=\"Q38\"><\/a>","c6ddd2f2":"### Countries of junior, middle-level and senior developers <a class=\"anchor\" id=\"Q35\"><\/a>","fd5a8761":"## Q17\n### Following hosted notebook products do you use on a regular basis <a class=\"anchor\" id=\"Q17\"><\/a>","e067e1e4":"#########################################################\n# Second part. Question and answers. <a class=\"anchor\" id=\"second\"><\/a>#########\n#########################################################","8cd6747d":"To make a bar graph comparable with SQL users data I converted counts of age to percent. You can clearly see that most of the population up to 25% percent is 25-29 years age group. You can also see that the SQL population is increased in older groups 30-59. The cause of such distribution might be that the SQL is not the first language you learn for a programming.","dda49970":"#########################################################\n# First part <a class=\"anchor\" id=\"first\"><\/a>#########\n#########################################################","ed7cf37d":"### Platforms that Pythonistas have begun or completed data science courses <a class=\"anchor\" id=\"Q44\"><\/a>","6d3bf5f3":"More than 25% of respondents work in companies where employee numbers are low 0-49. There are no dramatic differences between general respondents values and SQL users values. But we see slight increase of numbers of SQL users in larger companies.","26c6a0b3":"## Q18\n### Language popularity <a class=\"anchor\" id=\"Q18\"><\/a>","41a971cc":"As you can see the most of the respondents are male ~82%. The same tendency is also for SQL users.","aab6e8fd":"We can see from the graph that SQL users use more of machine learning products compared to general respondents. This also confirms that we see lower percentage of column None for SQL users.","11a855f7":"We can see that approximately money spent on machine learning and\/or cloud computing products at your work in the past 5 years highest percentage (about 33%) is 0$(USD). We can also see the trend that SQL users spend more on machine learning and\/or cloud computing products.   ","c53e9231":"From the graph you can see that SQL users tend to use AWS, Microsoft Azure, Oracle Cloud and WMware Cloud computer platforms more than general respondents.","2724402a":"## Q26\n### Categories of computer vision methods do you use on a regular basis <a class=\"anchor\" id=\"Q26\"><\/a>","a33047bb":"We can see that a lot of junior and middle developers come from India. Whereas senior developers come from USA, UK and Germany. ","477cd559":"## Q30\n### Specific cloud computing products do you use on a regular basis <a class=\"anchor\" id=\"Q30\"><\/a>","2030334a":"Some of the most used hosted notebooks are Kaggle Notebooks and Google Colab.","7aa5215c":"## Q20\n### Visualization libraries or tools do you use on a regular basis <a class=\"anchor\" id=\"Q20\"><\/a>","a0197eb5":"## Q9\n### Important part of your role at work for SQL users  <a class=\"anchor\" id=\"Q9-SQL\"><\/a>","21415b82":"## Q16\n### IDE you are using for regural basis <a class=\"anchor\" id=\"Q16\"><\/a>","67b07485":"Let's find out what yearly compensation junior, middle-level, senior ML developers get.","33df06ad":"As you can see usage of TPU for general and SQL users are almost the same. Most of the time respondends do not use TPU.","168b1702":"## Q5\n### The title most similar to your current <a class=\"anchor\" id=\"Q5\"><\/a>","2036ad39":"In the companies where more people(>2) are responsible for data science workloads SQL users tend to get this responsibilities more often than general population.","4d9ee6d2":"As you can see from the chart the most popular media sources for respondents are Kaggle, Blogs and YouTube.","febe2d1b":"You can clearly see how increasing in experience increases your annual compensation. Keep in mind that number of low paid compensation 0-999 decreases and you see exaggeration of highly paid ML developer but still you see an increase in highly paid positions coresponds to their experience in the field.","443767b1":"As in graph Q24 we can see icreased usage of RandomForest and Xgboost ML platforms in SQL users compared to general users.","82bc3aaa":"## Q6\n### The size of the company where you work <a class=\"anchor\" id=\"Q6\"><\/a>","207f6818":"## Q11\n### Approximately money have you spent on machine learning and\/or cloud computing products at your work in the past 5 years <a class=\"anchor\" id=\"Q11\"><\/a>","8f595984":"## Q5\n### The title most similar to your current of SQL users <a class=\"anchor\" id=\"Q5-SQL\"><\/a>","6d7734cc":"## Q29\n### Computer platforms you use on regular basis <a class=\"anchor\" id=\"Q29\"><\/a>","a20e7871":"## Q32\n### Following machine learning products do you use on a regular basis <a class=\"anchor\" id=\"Q32\"><\/a>","52533f8b":"The graph show that python library Matplotlib is the most popular among developers that use SQL lanuguage and ones that do not use it. Seaborn is second among the most popular vizualization libraries. This shows that most of the SQL developers also use an python programming language. We can test that using following code.","254564c2":"## Q3\n### The country of residence for SQL users <a class=\"anchor\" id=\"Q3-SQL\"><\/a>","735a40cd":"## Q3\n### The country of residence <a class=\"anchor\" id=\"Q3\"><\/a>","1915b082":"## Q1-Q2\n### Respondents age<a class=\"anchor\" id=\"Q1\"><\/a>\n","0378e295":"Let's find our which IDE is popular among junior, middle-level, senior ML developers.","bcdf1f1e":"As you can see in the map that highest respondents rate changes from USA to India. And we also see big incease of users from Nigeria. For SQL users is similar story we see higest respondent rate from USA and India almost equal in count. So we can conclude that nowdays the main players in the data science field are USA and India(If we counting on numbers:)). ","7ff34a82":"About 21% of the respondents in 2019 survey identify themselves as a data scientist. This number is higher in SQL user population where about 30% of the respondents identify themselves as a data scientist. About the same amount(21%) of respondents identify themselves as a Students. This number is lower in SQL users 13%. There could be explanation that would suggest that SQL is used by more experienced users. So in this case these experienced users are data scientists and Data analysts.","b3178102":"# Content \n\n   [First Part.](#first)<br>\n1. [Respondents age](#Q1)<br>\n2. [Gender of respondents](#Q2)<br>\n    2.1. [The gender of SQL users](#Q2-SQL)<br>\n3. [The country of residence](#Q3)<br>\n    3.1. [The country of residence for SQL users](#Q3-SQL)<br>\n4. [The highest level of formal education](#Q4)<br>\n    4.1. [The highest level of formal education of SQL users](#Q4-SQL)<br>\n5. [The title most similar to your current](#Q5)<br>\n    5.1. [The title most similar to your current of SQL users](#Q5-SQL)<br>\n6. [The size of the company where you work](#Q6)<br>\n7. [ Approximate number of individuals are responsible for data science workloads at your place of business](#Q7)<br>\n8. [Employer incorporate machine learning methods into their business](#Q8)<br>\n9. [Important part of your role at work](#Q9)<br>\n    9.1. [Important part of your role at work for SQL users](#Q9-SQL)<br>\n10. [Yearly compensation](#Q10)<br>\n11. [Approximately money have you spent on machine learning and\/or cloud computing products at your work in the past 5 years](#Q11)<br>\n12. [Your favorite media sources that report on data science topics](#Q12)<br>\n13. [Platforms that you have begun or completed data science courses](#Q13)<br>\n14. [The primary tool that you use at work or school to analyze data](#Q14)<br>\n15. [Time span you have been writing code to analyze data](#Q15)<br>\n16. [IDE you are using for regural basis](#Q16)<br>\n17. [Following hosted notebook products do you use on a regular basis](#Q17)<br>\n18. [Language popularity](#Q18)<br>\n19. [Programming language would you recommend an aspiring data scientist to learn first](#Q19)<br>\n20. [Visualization libraries or tools do you use on a regular basis](#Q20)<br>\n21. [Types of specialized hardware do you use on a regular basis](#Q21)<br>\n22. [Use of a TPU (tensor processing unit)](#Q22)<br>\n23. [Use of machine learning methods](#Q23)<br>\n24. [ML algorithms do you use on a regular basis](#Q24)<br>\n25. [Categories of ML tools do you use on a regular basis](#Q25)<br>\n26. [Categories of computer vision methods do you use on a regular basis](#Q26)<br>\n27. [The following natural language processing (NLP) methods do you use on a regular basis](#Q27)<br>\n28. [Machine learning frameworks do you use on a regular basis](#Q28)<br>\n29. [Computer platforms you use on regular basis](#Q29)<br>\n30. [Specific cloud computing products do you use on a regular basis](#Q30)<br>\n31. [Specific big data \/ analytics products do you use on a regular basis](#Q31)<br>\n32. [Following machine learning products do you use on a regular basis](#Q32)<br>\n33. [Automated machine learning tools (or partial AutoML tools) do you use on a regular basis](#Q33)<br>\n34. [The following relational database products do you use on a regular basis](#Q34)<br>\n[Second part. Questions and answers.](#second)<br>\n35. [Countries of junior, middle-level and senior developers](#Q35)<br>\n36. [Programming language popular among junior, middle-level and senior developers](#Q36)<br>\n37. [IDE popular among junior, middle-level and senior developers](#Q37)<br>\n38. [Relational database popular among junior, middle-level and senior developers](#Q38)<br>\n39. [Yearly compensation among junior, middle-level and senior developers](#Q39)<br>\n40. [Yearly compensation depending of which progamming language you use](#Q40)<br>\n41. [Countries where highly paid Pythonistas come from](#Q41)<br>\n42. [Pythonistas favorite media sources that report on data science topics](#Q42)<br>\n43. [Pythonistas favorite ML algorithms](#Q43)<br>\n44. [Platforms that Pythonistas have begun or completed data science courses](#Q44)<br>","75c07171":"## Q13\n### Platforms that you have begun or completed data science courses <a class=\"anchor\" id=\"Q13\"><\/a>","e3b90f20":"## Q22\n### Use of a TPU (tensor processing unit) <a class=\"anchor\" id=\"Q22\"><\/a>","502ec14a":"## Q31\n### Specific big data \/ analytics products do you use on a regular basis <a class=\"anchor\" id=\"Q31\"><\/a>","63908493":"Now we see huge increase of Ggplot \/ ggplot2 , Shiny libraries and None values. Meaning that that users who use SQL and do not use Python mostly use R or only use SQL."}}