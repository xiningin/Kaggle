{"cell_type":{"211d76dd":"code","3d3fe596":"code","e13c13f5":"code","b803657a":"code","9247d733":"code","c86e6131":"code","4855d9cc":"code","b35a47f3":"code","0d37ad75":"code","d3f8e15e":"code","24020a24":"code","a89192d4":"markdown","7ac2ef53":"markdown","4bfc9dd6":"markdown","bba45999":"markdown","4c50de3e":"markdown","5df745b7":"markdown","fdf1292e":"markdown"},"source":{"211d76dd":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn import preprocessing\nfrom sklearn import utils\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\n","3d3fe596":"df = pd.read_csv(\"..\/input\/graduate-admissions\/Admission_Predict_Ver1.1.csv\",sep=',')\n#df = pd.read_csv(\"..\/input\/graduate-admissions\/Admission_Predict.csv\",sep=',')\n\nprint(\"Row: \",df.shape[0])\nprint(\"Column: \",df.shape[1])\ndf.head(10)","e13c13f5":"df.describe()","b803657a":"df=df.dropna()","9247d733":"y=df.iloc[:,-1]\n#y=df[['Chance of Admit']]\n","c86e6131":"df=df[['GRE Score','TOEFL Score','University Rating','SOP','LOR ','CGPA','Research']]\n\ndf.head(2)","4855d9cc":"\nxtrain, xtest, ytrain, ytest = train_test_split( \n        df, y, test_size = 0.25, random_state = 0)\n\nscaler = StandardScaler()\nxtrain = scaler.fit_transform(xtrain)\nxtest = scaler.fit_transform(xtest)\n\nytrain_binary=(ytrain>0.7).astype(int)\nytest_binary=(ytest>0.7).astype(int)\n","b35a47f3":"reg = LogisticRegression() \n   \n# train the model using the training sets \nreg.fit(xtrain, ytrain_binary) \n  ","0d37ad75":"ynew = reg.predict(xtest)\nModel_accuracy = (reg.score(xtest, ytest_binary))*100\nModel_accuracy","d3f8e15e":"from sklearn.metrics import classification_report,confusion_matrix\n\nprint(confusion_matrix(ytest_binary,ynew))","24020a24":"print(classification_report(ynew,ytest_binary))\n","a89192d4":"# <font color=blue>5. Logistic Regression Model<\/font>   ","7ac2ef53":"# <font color=blue>6. Prediction and Accuracy<\/font>  ","4bfc9dd6":"# <font color=blue>2. Data Cleaning<\/font>   \n","bba45999":"# <font color=blue>4. Train and Test Dataset<\/font>  ","4c50de3e":"# <font color=blue>3. Features Selection<\/font>   ","5df745b7":"# <font color=blue>1. Data Load<\/font>   \n","fdf1292e":"## Accuracy\nAccuracy= (TP+TN)\/(TP+FP+TN+FN)=(49+61)\/(49+9+6+61)=0.88=88% \nAccuracy alone doesn't tell the full story when we are working with a class-imbalanced data set, like this one, where there is a significant disparity between the number of positive and negative labels.\n<!--\nImbalanced data typically refers to a problem with classification problems where the classes are not represented equally. For example, the above dataset has a 2-class (binary) classification problem with 100 instances (rows). A total of 96 instances are labeled with N and the remaining 4 instances are labeled with Y.This is an imbalanced dataset( idealy ratio of Class-1 to Class-2 instances is 80:20 or more concisely 4:1 is considered as imbalance dataset).\n -->\n## Precision\nPrecision= TP\/(TP+FP)=49\/(49+9)=0.84=84% \nOur model has a precision of 0.84\u2014in other words, when it predicts a admission possibilty is Yes, it is correct 84% of the time.\n\n## Recall\nRecall=TP\/(TP+FN)=49\/(49+6)=0.89=89% \nOur model has a recall of 0.89\u2014in other words, it correctly predicts 89% of all admission possibility.\n\n## F score \nCompute the F1 score, also known as balanced F-score or F-measure\n\nThe F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal. The formula for the F1 score is:\n            F1 = 2 * (precision * recall) \/ (precision + recall)=2*(84*89)\/(84+89)=87% \n\n\n\n\n\n\n\n\n\n\n\n"}}