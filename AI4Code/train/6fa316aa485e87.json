{"cell_type":{"a1568516":"code","a056f14c":"code","02e6d11b":"code","4938c29d":"code","d42d9605":"code","af3ffcb6":"code","e0e7651e":"code","fc353855":"code","eda1f1ee":"code","ee06cb98":"code","b9a19873":"code","00cd4aca":"code","915d9850":"code","b15dfc83":"code","23e8b9aa":"code","991d67f8":"code","85587d92":"code","54014eea":"code","e1590b5a":"code","4f6e4e94":"markdown","b3c2e548":"markdown","322e781c":"markdown","12ebf4be":"markdown","d341e884":"markdown","c7072a0d":"markdown","db6fca91":"markdown"},"source":{"a1568516":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a056f14c":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","02e6d11b":"df = pd.read_csv(\"..\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv\")","4938c29d":"df.head(3)","d42d9605":"df.info()\ndf.describe()","af3ffcb6":"#no missing value yah, but lets check it\ndf.isnull().sum()","e0e7651e":"#Distribution of Gender\nlabels=['Female','Male']\nsize=df['Gender'].value_counts()\ncolors=['pink','blue']\nexplode=[0,0.1]\n\nplt.rcParams['figure.figsize']=(6,6)\nplt.pie(size,colors=colors, explode=explode, labels=labels, shadow=True, autopct='%.2f%%')\nplt.title('Distribution of Gender', fontsize=20)\nplt.axis('off')\nplt.legend()\nplt.show()","fc353855":"#Distribution of Age, Annual Income, Spending Score\nplt.figure(1,figsize=(19,7))\nn=0\nfor x in ['Age','Annual Income (k$)','Spending Score (1-100)']:\n  n+=1\n  plt.subplot(1,3,n)\n  plt.subplots_adjust(hspace=0.5,wspace=0.5)\n  sns.distplot(df[x],bins=20)\n  plt.title('Distribution of {}'.format(x))\nplt.show()","eda1f1ee":"# Making  the independent variables matrix, Annual and Spending score\nX = df.iloc[:, [3, 4]].values","ee06cb98":"# Convert gender to categorical variabel\ndf = pd.get_dummies(df, columns = ['Gender'], prefix = ['Gender'])\ndf.head(3)","b9a19873":"#Using KMeans for clustering Annual Income and Spending Score\nfrom sklearn.cluster import KMeans\nwcss = []\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', max_iter = 300, n_init = 10)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)","00cd4aca":"font_title = {'family' : 'normal',\n        'weight' : 'bold',\n        'size'   : 35}\n\nfont_axes = {'family' : 'normal',\n        'weight' : 'normal',\n        'size'   : 28}","915d9850":"#Plotting Number of Clusters Vs wcss - The Elbow Method Annual Income\nplt.plot(range(1, 11), wcss)\nplt.title('The Elbow Method', fontsize=20)\nplt.xlabel('Number of clusters')\nplt.ylabel('wcss')\nplt.show()","b15dfc83":"#Taking number of clusters = 5\nkmeans = KMeans(n_clusters = 5, init = 'k-means++', max_iter = 300, n_init = 10)\ny_kmeans = kmeans.fit_predict(X)","23e8b9aa":"# PLotting the clusters\nplt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Cluster1')\nplt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Cluster2')\nplt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 100, c = 'green', label = 'Cluster3')\nplt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s = 100, c = 'yellow', label = 'Cluster4')\nplt.scatter(X[y_kmeans == 4, 0], X[y_kmeans == 4, 1], s = 100, c = 'pink', label = 'Cluster5')\nplt.title('Clusters of Customers', **font_title)\nplt.xlabel('Annual income(k$)', **font_axes)\nplt.ylabel('spending score', **font_axes)\nplt.legend()\nplt.show()","991d67f8":"# Making  the independent variables matrix (Age)\nX2 = df.iloc[:, [1, 3]].values","85587d92":"#Using KMeans for clustering (Age)\nfrom sklearn.cluster import KMeans\nwcss = []\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', max_iter = 300, n_init = 10)\n    kmeans.fit(X2)\n    wcss.append(kmeans.inertia_)","54014eea":"#Plotting Number of Clusters Vs wcss - The Elbow Method (Age)\nplt.plot(range(1, 11), wcss)\nplt.title('The Elbow Method', fontsize=20)\nplt.xlabel('Number of clusters')\nplt.ylabel('wcss')\nplt.show()","e1590b5a":"#Taking number of clusters = 4\nkmeans = KMeans(n_clusters = 4, init = 'k-means++', max_iter = 300, n_init = 10)\ny_kmeans = kmeans.fit_predict(X2)\n\n# PLotting the clusters\nplt.scatter(X2[y_kmeans == 0, 0], X2[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Cluster1')\nplt.scatter(X2[y_kmeans == 1, 0], X2[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Cluster2')\nplt.scatter(X2[y_kmeans == 2, 0], X2[y_kmeans == 2, 1], s = 100, c = 'green', label = 'Cluster3')\nplt.scatter(X2[y_kmeans == 3, 0], X2[y_kmeans == 3, 1], s = 100, c = 'yellow', label = 'Cluster4')\n\nplt.title('Clusters of Age', **font_title)\nplt.xlabel('Age', **font_axes)\nplt.ylabel('spending score', **font_axes)\nplt.legend()\nplt.show()","4f6e4e94":"**Result:**\n1. Cluster 1 (red color), is called the young customer cluster\n\nIn cluster 1, customers with an age range of 20\u201340 years have a spending score of 30\u201370. In this cluster, mall owners need to improve their services.\n\n2. Cluster 2 (blue), called priority customer cluster\n\nIn cluster 2, customers with an age range of 20\u201340 years have a spending score of 70\u201399. In this cluster, mall owners need to maintain good relations while maintaining mall services.\n\n3. Cluster 3 (green color), called old customer cluster cluster\n\nIn cluster 3, customers with an age range of 40\u201370 years have a spending score of 35\u201360. In this cluster, mall owners need to improve related facilities to make it easier for adults and even the elderly to shop at the mall to feel comfortable so that they can increase their shopping activities.\n\n4. Cluster 4 (yellow color), is called the target customer cluster\n\nIn cluster 4, customers with an age range of 20\u201370 years have a spending score of 0\u201330. In this cluster, mall owners need to pay more attention to improving mall services and facilities.","b3c2e548":"The best number of clusters is 4. So it will be analyzed how the clustering between Age and Spending Score with 4 clusters using the K-Means algorithm.","322e781c":"> KMEANS","12ebf4be":"**Result:**\n1. Cluster 1 (red color), is called the waster cluster\n\nIn cluster 1 it can be seen that people with low income but have a higher spending score, they are people who for some reason prefer to buy products even though they have low income. Maybe because these people are more than satisfied with the mall's services. Shops\/malls may not target these people effectively but still won't miss them.\n2. Cluster 2 (blue color), is called the common cluster\n\nIn cluster 2, it can be seen that mall customers who have moderate income have moderate expenses, adjusted to their economic situation.\n\n3. Cluster 3 (green), called the stingy cluster\n\nIn cluster 3 it can be seen that high-income mall customers have low spending, this is interesting. Maybe these are people who are dissatisfied or unhappy with the mall's services. This can be a prime target for malls, as it has the potential to cost money. Therefore, the mall manager will try to add new facilities in order to attract the interest of the community and meet their needs.\n\n4. Cluster 4 (yellow color), is called a conglomerate cluster\n\nIn cluster 4 it can be seen that people have high income and high expenses, this is an ideal case for malls or shops because these people are the main source of profit. These people may be regulars of the mall and are confident in the mall's amenities.\n\n5.  Cluster 5 (pink color), is called the caution cluster\n\nIn cluster 5 it can be seen that people have low annual income and low spending scores, this is quite reasonable because people who have low salaries prefer to buy less, in fact, these are wise people who know how spend and save money. Shops\/malls will be least interested in people belonging to this cluster.","d341e884":"> Distribution of Age, Annual Income, and Spending Score","c7072a0d":"> Distribution of Gender","db6fca91":"Based on the Elbow Method graph above, the best number of clusters is 5. So it will be analyzed how the clustering between Annual Income and Spending Score with 5 clusters uses the K-Means algorithm."}}