{"cell_type":{"39682dcc":"code","9fbed5b9":"code","b91f1c1c":"code","88f7f9f8":"code","5dd0a2c5":"code","4cdaa570":"code","22634f99":"code","9ebcbc37":"code","7e838ed2":"code","799a3abc":"code","9179e96d":"code","c0ad43e7":"code","1289233b":"code","77bce486":"code","eca432c6":"code","468ab54c":"code","43d1f31f":"code","2d0c36e1":"code","4e04b660":"code","05e2f2ec":"code","893b7955":"code","1cb7c8a4":"code","6101442e":"code","ccb60a8a":"code","7749767c":"code","c011f7cd":"markdown","e0842d2e":"markdown","8e39eb6b":"markdown","4e60bb57":"markdown","ef0c0948":"markdown","64ce9e28":"markdown"},"source":{"39682dcc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","9fbed5b9":"import matplotlib.pyplot as plt\nfrom sklearn.datasets import make_classification\n\nX, y = make_classification(n_samples = 100, n_features=2, n_informative=2,n_redundant=0, n_clusters_per_class=1, class_sep=2, random_state=101)\nplt.scatter(X[:,0], X[:,1], marker='o', c=y, linewidths=0, edgecolors=None)\nplt.show()","b91f1c1c":"y_orig=[0,0,0,0,0,0,1,1,1,1]\ny_pred=[0,0,0,0,1,1,1,1,1,0]","88f7f9f8":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_orig,y_pred)","5dd0a2c5":"import seaborn as sns\nsns.heatmap(confusion_matrix(y_orig,y_pred), linecolor='white', linewidths=3, annot=True)\nplt.title('Confusion Matrix', fontsize=20)\nplt.show()","4cdaa570":"from mlxtend.plotting import plot_confusion_matrix\nplot_confusion_matrix(confusion_matrix(y_orig,y_pred))\nplt.show()","22634f99":"from sklearn.metrics import accuracy_score\n#ACC = (TP\/(P+N))  TP = 3, TN = 4, P = 4, N = 6, \nacc=accuracy_score(y_orig, y_pred)\nacc","9ebcbc37":"from sklearn.metrics import precision_score\nprecision_score (y_orig, y_pred)","7e838ed2":"from sklearn.metrics import recall_score\n# recall score or hit rate\nrecall_score(y_orig, y_pred)","799a3abc":"from sklearn.metrics import f1_score\nf1_score (y_orig, y_pred)","9179e96d":"from sklearn.metrics import classification_report\nprint(classification_report (y_orig, y_pred))","c0ad43e7":"X.shape","1289233b":"y.shape","77bce486":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y.astype(float), test_size=0.33, random_state = 101)","eca432c6":"from sklearn.linear_model import LinearRegression\nregr=LinearRegression()\nregr.fit(X_train, y_train)\nregr.predict(X_train)","468ab54c":"import numpy as np\n\ndef model(x):\n    return 1\/(1+np.exp(-x))","43d1f31f":"plt.style.use('seaborn')\nX_vals = np.linspace(-10,10, 1000)\nplt.plot(X_vals, model(X_vals), color='red', linewidth=4)\nplt.ylabel('sigmoid(t)')\nplt.xlabel(\"t\")\nplt.show()","2d0c36e1":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\n\nclf=LogisticRegression()\nclf.fit(X_train, y_train.astype(int))\ny_clf=clf.predict(X_test)\n\nprint(classification_report(y_test, y_clf))","4e04b660":"y_clf","05e2f2ec":"h=0.02\nplt.style.use('ggplot')\nx_min, x_max=X[:,0].min()- 0.5, X[:,0].max() + 0.5\ny_min, y_max=X[:,1].min()- 0.5, X[:,1].max() + 0.5\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min,y_max,h))\nZ=clf.predict(np.c_[xx.ravel(),yy.ravel()])\n\nZ=Z.reshape(xx.shape)\nplt.pcolormesh(xx, yy, Z, cmap=plt.cm.autumn)\nplt.contour(xx,yy,Z)\n\n\nplt.scatter(X[:,0], X[:,1], c=y, edgecolor='k', linewidth = 0, cmap=plt.cm.Paired)\nplt.xticks(())\nplt.yticks(())\nplt.show()","893b7955":"import matplotlib.pyplot as plt\nfrom sklearn.datasets import make_classification\n\nX, y = make_classification(n_samples=200, n_features=2, \n                          n_classes=3, n_informative=2, \n                          n_redundant=0, n_clusters_per_class= 1,\n                          class_sep=2.0, random_state=101)","1cb7c8a4":"plt.style.use('default')\nplt.scatter(X[:,0],X[:,1], marker='o', c=y)\nplt.show()","6101442e":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y.astype(float), test_size=0.33, random_state = 101)\n\n\nfrom sklearn.linear_model import LinearRegression\nclf=LogisticRegression()\nclf.fit(X_train, y_train.astype(int))\ny_clf=clf.predict(X_test)","ccb60a8a":"print(classification_report(y_test, y_clf))","7749767c":"h=0.01\nplt.style.use('default')\nx_min, x_max=X[:,0].min()- 0.5, X[:,0].max() + 0.5\ny_min, y_max=X[:,1].min()- 0.5, X[:,1].max() + 0.5\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min,y_max,h))\nZ=clf.predict(np.c_[xx.ravel(),yy.ravel()])\n\nZ=Z.reshape(xx.shape)\nplt.pcolormesh(xx, yy, Z, cmap=plt.cm.autumn)\n\n\nplt.scatter(X[:,0], X[:,1], c=y, edgecolor='k', linewidth = 1, cmap=plt.cm.Paired)\nplt.xticks(())\nplt.yticks(())\nplt.show()","c011f7cd":"![image.png](attachment:image.png)","e0842d2e":"## Multiclass Logistic Regression","8e39eb6b":"## Classification and decision boundary","4e60bb57":"## Measuring the Classifier's performance","ef0c0948":"## Fitting the Classifier","64ce9e28":"### The sigmoid (logit) function"}}