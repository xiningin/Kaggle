{"cell_type":{"421caf4d":"code","94a764fc":"code","52b1fb9b":"code","2594b7a2":"code","762c64f5":"code","83beeee5":"code","a7216482":"code","52b42547":"code","207f0539":"code","280c8b34":"code","182cdc74":"code","c23a3eae":"code","dbf852b7":"code","682b989d":"code","e64cd26a":"code","277d5789":"code","bf4bba28":"markdown","b6d495ee":"markdown","02479309":"markdown","be786c2b":"markdown","5eaa7294":"markdown"},"source":{"421caf4d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","94a764fc":"df = pd.read_csv(\"\/kaggle\/input\/brent-oil-prices\/BrentOilPrices.csv\")\ndf.head()","52b1fb9b":"df.Date = pd.to_datetime(df.Date)\ndf.head()","2594b7a2":"def univariate_data(dataset, start_index, end_index, history_size, target_size):\n  data = []\n  labels = []\n\n  start_index = start_index + history_size\n  if end_index is None:\n    end_index = len(dataset) - target_size\n\n  for i in range(start_index, end_index):\n    indices = range(i-history_size, i)\n    # Reshape data from (history_size,) to (history_size, 1)\n    data.append(np.reshape(dataset[indices], (history_size, 1)))\n    labels.append(dataset[i+target_size])\n  return np.array(data), np.array(labels)","762c64f5":"TRAIN_SPLIT = int(0.8 * df.shape[0]) # selecting 80% as our training data \nuni_data = df.Price\nuni_data\nuni_data.plot()","83beeee5":"uni_data = uni_data.values\nuni_data","a7216482":"uni_train_mean = uni_data[:TRAIN_SPLIT].mean()\nuni_train_std = uni_data[:TRAIN_SPLIT].std()","52b42547":"uni_data = (uni_data-uni_train_mean)\/uni_train_std\nuni_data","207f0539":"univariate_past_history = 100\nunivariate_future_target = 0\n\nx_train_uni, y_train_uni = univariate_data(uni_data, 0, TRAIN_SPLIT,\n                                           univariate_past_history,\n                                           univariate_future_target)\nx_val_uni, y_val_uni = univariate_data(uni_data, TRAIN_SPLIT, None,\n                                       univariate_past_history,\n                                       univariate_future_target)","280c8b34":"def create_time_steps(length):\n  time_steps = []\n  for i in range(-length, 0, 1):\n    time_steps.append(i)\n  return time_steps","182cdc74":"def show_plot(plot_data, delta, title):\n  labels = ['History', 'True Future', 'Model Prediction']\n  marker = ['.-', 'rx', 'go']\n  time_steps = create_time_steps(plot_data[0].shape[0])\n  if delta:\n    future = delta\n  else:\n    future = 0\n\n  plt.title(title)\n  for i, x in enumerate(plot_data):\n    if i:\n      plt.plot(future, plot_data[i], marker[i], markersize=10,\n               label=labels[i])\n    else:\n      plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n  plt.legend()\n  plt.xlim([time_steps[0], (future+5)*2])\n  plt.xlabel('Time-Step')\n  return plt","c23a3eae":"show_plot([x_train_uni[0], y_train_uni[0]], 0, 'Sample Example')","dbf852b7":"BATCH_SIZE = 256\nBUFFER_SIZE = 10000\n\ntrain_univariate = tf.data.Dataset.from_tensor_slices((x_train_uni, y_train_uni))\ntrain_univariate = train_univariate.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n\nval_univariate = tf.data.Dataset.from_tensor_slices((x_val_uni, y_val_uni))\nval_univariate = val_univariate.batch(BATCH_SIZE).repeat()","682b989d":"simple_lstm_model = tf.keras.models.Sequential([\n    tf.keras.layers.LSTM(8, input_shape=x_train_uni.shape[-2:]),\n    tf.keras.layers.Dense(1)\n])\n\nsimple_lstm_model.compile(optimizer='adam', loss='mae')","e64cd26a":"EVALUATION_INTERVAL = 100\nEPOCHS = 10\n\nsimple_lstm_model.fit(train_univariate, epochs=EPOCHS,\n                      steps_per_epoch=EVALUATION_INTERVAL,\n                      validation_data=val_univariate, validation_steps=50)","277d5789":"for x, y in val_univariate.take(10):\n  plot = show_plot([x[0].numpy(), y[0].numpy(),\n                    simple_lstm_model.predict(x)[0]], 0, 'Simple LSTM model')\n  plot.show()","bf4bba28":"Coverting first column to datetime format","b6d495ee":"We normalise our data. Keep in mind that we do this only for the traning set.","02479309":"For this project we are going to make an LSTM model, which needs a window of past historical prices to be trained on, along with a target_size of the number of data points we want to predict in the future. The function below prepares our our training and test data","be786c2b":"We are going to use 10 epochs to train our LSTM model along with 100 evaluation steps (instead of the whole training set which is the usual).","5eaa7294":"We start by importing the libraries we are going to use\n"}}