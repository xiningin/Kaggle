{"cell_type":{"cb228778":"code","ce19251d":"code","d6871942":"code","c56a9e7b":"code","c7163b88":"code","6df18348":"code","e589d9d3":"code","b281324c":"code","a1836d14":"code","72cbde0d":"code","17ea0017":"code","f36199d4":"code","4778b6dd":"code","a552bc25":"code","2aaeb2d5":"code","7988008c":"code","0189c4ee":"code","5cc7bdec":"code","f709a804":"code","b061ad0f":"code","f196b8a8":"code","e40b2739":"code","fcf520b5":"code","6fc501f3":"code","5428c545":"code","71e0fca4":"code","d829245e":"code","8501ce03":"code","34256731":"code","8730e597":"code","24abd55f":"code","259923a9":"code","67135da2":"code","37b0a3d4":"code","b555a304":"code","a83ee2fb":"code","ed0077ad":"code","ffc7102d":"code","087125cc":"code","9ff2da6c":"code","203ac2f1":"code","317ce044":"code","b9a17d11":"code","e414a2b0":"code","3d9a0246":"code","c14ec6bf":"code","87f437e4":"code","df86c1f4":"code","6c29a511":"code","848b6a10":"code","6b1f1fb9":"code","0ec34dab":"code","9b639e97":"code","57a64a93":"code","91fec38c":"code","b8ce2432":"code","85d7023f":"code","158dda79":"code","7f393e41":"code","6cee6f2f":"code","e5522c7f":"code","654ac42b":"code","088e011e":"code","ff02f773":"code","8c4dade1":"code","f11cff8e":"code","31ac2d94":"code","21f8bba3":"code","c647d0b0":"code","d5112b91":"code","4abfe637":"code","13c6ac6f":"code","b20549ce":"code","1a4ef30a":"code","a6cc6201":"code","dd55583f":"code","dfe27d7b":"code","49a1de5c":"code","ae433dd1":"markdown","0eed2991":"markdown","00174d5e":"markdown","44ee2a97":"markdown","93477cb8":"markdown","1402c1fc":"markdown","7d6b68ed":"markdown","c9ba6325":"markdown","324b8e60":"markdown","cf31f2f1":"markdown","77dc40ff":"markdown","b199e099":"markdown","867aeee0":"markdown","f3cb2739":"markdown","9bcd1da3":"markdown","c34befe2":"markdown","2fd44870":"markdown","a587d150":"markdown","db5c6e05":"markdown"},"source":{"cb228778":"import numpy as np\nimport pandas as pd\nfrom pandas.plotting import scatter_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom catboost import CatBoostRegressor, CatBoostClassifier, Pool\nimport xgboost as xgb\nimport lightgbm as lgbm\nfrom sklearn.linear_model import SGDClassifier, LogisticRegression, LogisticRegressionCV\nfrom sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier, RandomForestClassifier\nfrom sklearn.svm import SVC\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_predict, cross_val_score\nfrom sklearn.metrics import f1_score as f1,\\\n                            r2_score as r2,\\\n                            mean_squared_error as mse,\\\n                            roc_auc_score as ras,\\\n                            roc_curve,\\\n                            confusion_matrix,\\\n                            precision_score as pres,\\\n                            recall_score as recall,\\\n                            precision_recall_curve,\\\n                            classification_report,\\\n                            precision_score,\\\n                            recall_score\n\nfrom sklearn.model_selection import KFold, StratifiedKFold\n\nfrom scipy.stats import shapiro\nfrom scipy.stats import probplot\nfrom scipy.stats import mannwhitneyu\nfrom scipy.stats import chi2_contingency\n\nimport os\nimport sys\nimport warnings\nimport time, datetime\nimport itertools\nimport pickle\nfrom collections.abc import Iterable\nwarnings.filterwarnings('ignore')\n\n\npd.options.display.min_rows = 50\npd.options.display.max_columns = 50\n# pd.options.display.max_rows = 1000\n%matplotlib inline\n\nstart = time.time()","ce19251d":"#\u0424\u0443\u043d\u043a\u0446\u0438\u044f, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u043f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u0442 \u0441\u0440\u0435\u0434\u043d\u0435\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u043f\u043e \u0446\u0435\u043b\u0435\u0432\u043e\u043c\u0443 \u043f\u0440\u0438\u043d\u0430\u043a\u0443 \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0439 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0438 \u0443\u043a\u0430\u0437\u0430\u043d\u043d\u043e\u0433\u043e \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430\ndef mean_for_category(data, target, feature):\n    df = data.copy()\n    df[feature].fillna('MISSING', inplace=True)\n    result = pd.DataFrame()\n    values = list(set(df[feature].values))\n    result['Category'] = values\n    for val in values:\n        qty = len(df.loc[(df[feature]==val)])\n        if qty == 0:\n            continue\n        else:\n            dens = df.loc[df[feature]==val, target].mean()\n            \n        result.loc[result['Category']==val, 'Mean'] = dens\n        result.loc[result['Category']==val, 'Quantity'] = qty\n\n    return result.sort_values(by='Mean', ascending=False)","d6871942":"def evaluate_preds(true_values, pred_values, max_x = 10000000, max_y = 10000000, save=False):\n    \"\"\"\u041e\u0446\u0435\u043d\u043a\u0430 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u043c\u043e\u0434\u0435\u043b\u0438 \u0438 \u0433\u0440\u0430\u0444\u0438\u043a preds vs true\"\"\"\n    \n    print(\"R2:\\t\" + str(round(r2(true_values, pred_values), 3)) + \"\\n\" +\n          \"RMSE:\\t\" + str(round(np.sqrt(mse(true_values, pred_values)), 3)) + \"\\n\" +\n          \"MSE:\\t\" + str(round(mse(true_values, pred_values), 3))\n         )\n    \n    plt.figure(figsize=(8,8))\n    \n    sns.scatterplot(x=pred_values, y=true_values)\n    plt.plot([0, max_x], [0, max_y], linestyle='--', color='black')\n    \n    plt.xlabel('Predicted values')\n    plt.ylabel('True values')\n    plt.title('True vs Predicted values')\n    \n    plt.show()","c56a9e7b":"#\u0424\u0443\u043d\u043a\u0446\u0438\u044f, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u0443\u0441\u0440\u0435\u0434\u043d\u044f\u0435\u0442 \u0432\u044b\u0447\u0438\u0441\u043b\u044f\u0435\u0442 \u0441\u0440\u0435\u0434\u043d\u0438\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u043f\u043e \u0446\u0435\u043b\u0435\u0432\u043e\u0433\u043e \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430 \u043f\u043e \u043a\u0430\u0436\u0434\u043e\u0439 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0438 \u0437\u0430\u0434\u0430\u043d\u043d\u043e\u0433\u043e\n#\u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430\ndef make_mean_encoding_smooth2(train, test, target_col_name, feature_col_name, alpha=2, for_test=True):\n    column_name = feature_col_name + ' MEAN '+ target_col_name\n    train_new = train.copy()\n    global_mean = train.loc[~train[target_col_name].isna(), target_col_name].mean()\n    encod_type = train.loc[~train[target_col_name].isna()].groupby(by=[feature_col_name],\\\n                           as_index=False)[target_col_name].aggregate(np.mean)\n    nrows_train = train.loc[~train[target_col_name].isna()].groupby(by=[feature_col_name],\\\n                                                            as_index=False)[target_col_name].aggregate(len)\n    mean_table = encod_type.merge(nrows_train, on=feature_col_name)\n    mean_table.columns=[feature_col_name, 'encod_type', 'nrows_train']\n    mean_table[column_name] = (mean_table['encod_type'] + global_mean * alpha)\\\n                                                                \/ (mean_table['nrows_train'] + alpha)\n    mean_table = mean_table[[feature_col_name, column_name]]\n    train_new = train_new.merge(mean_table, how='left', on=feature_col_name)\n    \n    if for_test:\n        test_new = test.copy()\n        test_new = test_new.merge(mean_table, how='left', on=feature_col_name)\n        return train_new, test_new\n    \n    return train_new","c7163b88":"def get_classification_report(y_train_true, y_train_pred, y_test_true, y_test_pred):\n    print('TRAIN\\n\\n' + classification_report(y_train_true, y_train_pred))\n    print('TEST\\n\\n' + classification_report(y_test_true, y_test_pred))\n    print('CONFUSION MATRIX\\n')\n    print(pd.crosstab(y_test_true, y_test_pred))","6df18348":"def balance_df_by_target(df, target_name, method='over'):\n\n    assert method in ['over', 'under', 'tomek', 'smote'], '\u041d\u0435\u0432\u0435\u0440\u043d\u044b\u0439 \u043c\u0435\u0442\u043e\u0434 \u0441\u044d\u043c\u043f\u043b\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f'\n    \n    target_counts = df[target_name].value_counts()\n\n    major_class_name = target_counts.argmax()\n    minor_class_name = target_counts.argmin()\n\n    disbalance_coeff = int(target_counts[major_class_name] \/ target_counts[minor_class_name]) - 1\n    if method == 'over':\n        for i in range(disbalance_coeff):\n            sample = df[df[target_name] == minor_class_name].sample(target_counts[minor_class_name])\n            df = df.append(sample, ignore_index=True)\n            \n    elif method == 'under':\n        df_ = df.copy()\n        df = df_[df_[target_name] == minor_class_name]\n        tmp = df_[df_[target_name] == major_class_name]\n        df = df.append(tmp.iloc[\n            np.random.randint(0, tmp.shape[0], target_counts[minor_class_name])\n        ], ignore_index=True)\n\n    elif method == 'tomek':\n        from imblearn.under_sampling import TomekLinks\n        tl = TomekLinks()\n        X_tomek, y_tomek = tl.fit_sample(df.drop(columns=target_name), df[target_name])\n        df = pd.concat([X_tomek, y_tomek], axis=1)\n    \n    elif method == 'smote':\n        from imblearn.over_sampling import SMOTE\n        smote = SMOTE(random_state=42)\n        X_smote, y_smote = smote.fit_sample(df.drop(columns=target_name), df[target_name])\n        df = pd.concat([X_smote, y_smote], axis=1)\n\n    return df.sample(frac=1)","e589d9d3":"def show_proba_calibration_plots(y_predicted_probs, y_true_labels):\n    preds_with_true_labels = np.array(list(zip(y_predicted_probs, y_true_labels)))\n\n    thresholds = []\n    precisions = []\n    recalls = []\n    f1_scores = []\n\n    for threshold in np.linspace(0.1, 0.9, 20):\n        thresholds.append(threshold)\n        precisions.append(precision_score(y_true_labels, list(map(int, y_predicted_probs > threshold))))\n        recalls.append(recall_score(y_true_labels, list(map(int, y_predicted_probs > threshold))))\n        f1_scores.append(f1(y_true_labels, list(map(int, y_predicted_probs > threshold)), average='binary'))\n\n    scores_table = pd.DataFrame({'f1':f1_scores,\n                                 'precision':precisions,\n                                 'recall':recalls,\n                                 'probability':thresholds}).sort_values('f1', ascending=False).round(3)\n  \n    figure = plt.figure(figsize = (20, 5))\n\n    plt1 = figure.add_subplot(121)\n    plt1.plot(thresholds, precisions, label='Precision', linewidth=4)\n    plt1.plot(thresholds, recalls, label='Recall', linewidth=4)\n    plt1.plot(thresholds, f1_scores, label='F1', linewidth=4)\n    plt1.set_ylabel('Scores')\n    plt1.set_xlabel('Probability threshold')\n    plt1.set_title('Probabilities threshold calibration')\n    plt1.legend(bbox_to_anchor=(0.25, 0.25))   \n    plt1.table(cellText = scores_table.values,\n               colLabels = scores_table.columns, \n               colLoc = 'center', cellLoc = 'center', loc = 'bottom', bbox = [0, -1.3, 1, 1])\n\n    plt2 = figure.add_subplot(122)\n    plt2.hist(preds_with_true_labels[preds_with_true_labels[:, 1] == 0][:, 0], \n              label='Another class', color='royalblue', alpha=1)\n    plt2.hist(preds_with_true_labels[preds_with_true_labels[:, 1] == 1][:, 0], \n              label='Main class', color='darkcyan', alpha=0.8)\n    plt2.set_ylabel('Number of examples')\n    plt2.set_xlabel('Probabilities')\n    plt2.set_title('Probability histogram')\n    plt2.legend(bbox_to_anchor=(1, 1))\n\n    plt.show()","b281324c":"#\u0424\u0443\u043d\u043a\u0446\u0438\u044f \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u0442 \u043b\u0443\u0448\u0447\u0443\u044e \u043e\u0442\u0441\u0435\u0447\u043a\u0443\ndef best_threshold(y_predicted_probs, y_true_labels):\n    preds_with_true_labels = np.array(list(zip(y_predicted_probs, y_true_labels)))\n\n    thresholds = []\n    f1_scores = []\n\n    for threshold in np.linspace(0.05, 0.95, 18):\n        thresholds.append(threshold)\n        f1_scores.append(f1(y_true_labels, list(map(int, y_predicted_probs > threshold)), average='binary'))\n\n    scores_table = pd.DataFrame({'f1':f1_scores,\n                                 'probability':thresholds}).sort_values('f1', ascending=False).round(3)\n    return scores_table.iloc[0, 1]","a1836d14":"def show_feature_importances(feature_names, feature_importances, get_top=None):\n    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importances})\n    feature_importances = feature_importances.sort_values('importance', ascending=False)\n       \n    plt.figure(figsize = (20, len(feature_importances) * 0.355))\n    \n    sns.barplot(feature_importances['importance'], feature_importances['feature'])\n    \n    plt.xlabel('Importance')\n    plt.title('Importance of features')\n    plt.show()\n    \n    if get_top is not None:\n        return feature_importances['feature'][:get_top].tolist()","72cbde0d":"#\u0424\u0443\u043d\u043a\u0446\u0438\u0438 \u043f\u0435\u0440\u0435\u0434\u0430\u0435\u0442\u0441\u044f \u0441\u043f\u0438\u0441\u043e\u043a \u0441\u043f\u0438\u0441\u043a\u043e\u0432 \u0441 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430\u043c\u0438 \u0438 \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u043d\u0430\u0445\u043e\u0434\u0438\u0442 \u043d\u0430\u0438\u043b\u0443\u0447\u0448\u0435\u0435 \u0441\u043e\u0447\u0435\u0442\u0430\u043d\u0438\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432.\n#\u041f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u043d\u0443\u0436\u043d\u043e \u0433\u0440\u0443\u043f\u043f\u0438\u0440\u043e\u0432\u0430\u0442\u044c, \u0442\u0430\u043a \u043a\u0430\u043a \u0432 \u043f\u0440\u043e\u0442\u0438\u0432\u043d\u043e\u043c \u0441\u043b\u0443\u0447\u0430\u0435 \u0440\u0430\u0441\u0447\u0435\u0442\u044b \u0431\u0443\u0434\u0443\u0442 \u043e\u0447\u0435\u043d\u044c \u0438 \u043e\u0447\u0435\u043d\u044c \u0434\u043e\u043b\u0433\u0438\u043c\u0438.\ndef best_features(features, model, X_train, y_train, X_test, y_test, must=[]):\n    result = pd.DataFrame(columns=['F1 train', 'F1 test', 'Overfitting', 'Features'])\n    result.loc[0] = 0\n    \n    \n    options = []\n    for L in range(0, len(features)+1):\n        for subset in itertools.combinations(features, L):\n            if len(subset)>0:\n                options.append(list(itertools.chain(*subset))+must)\n    \n    iterations = len(options)\n    i = 0\n    for opt in options:\n        model.fit(X_train[opt], y_train)\n        i += 1\n        print(f'Iteration {i} of {iterations}, '+  '{:.1%}'.format(i\/iterations), end=\"\\r\")\n        y_train_pred = model.predict(X_train[opt])\n        y_test_pred = model.predict(X_test[opt])\n        result.loc[result.index.max()+1] = [f1(y_train, y_train_pred, average='binary'),\n                                                  f1(y_test, y_test_pred, average='binary'),\n                                                  f1(y_train, y_train_pred, average='binary') -\\\n                                                  f1(y_test, y_test_pred, average='binary'),\n                                                  opt]\n    \n    result = result.drop([0])\n    result['Sorting'] = result['F1 test'] - result['Overfitting']\n    \n    \n    return result.sort_values(by='F1 test', ascending=False)","17ea0017":"#\u0424\u0443\u043d\u043a\u0446\u0438\u044f \u043f\u043e\u043f\u0430\u0440\u043d\u043e \u043f\u0435\u0440\u0435\u0431\u0438\u0440\u0430\u0435\u0442 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0438 \u0437\u0430\u0434\u0430\u043d\u043d\u043e\u0433\u043e \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430 \u0438 \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0439 \u043f\u0430\u0440\u044b \u043f\u0440\u043e\u0432\u0435\u0440\u044f\u0435\u0442\u0441\u044f \u0441\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u0430\u044f\n#\u0437\u043d\u0430\u0447\u0438\u043c\u043e\u0441\u0442\u044c \u0440\u0430\u0437\u043b\u0438\u0447\u0438\u0439. \u0415\u0441\u043b\u0438 \u0440\u0430\u0437\u043b\u0438\u0447\u0438\u044f \u043d\u0435\u0437\u043d\u0430\u0447\u0438\u0442\u0435\u043b\u044c\u043d\u044b, \u0442\u043e \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0438 \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u044f\u044e\u0442\u0441\u044f \u0438 \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0437\u0430\u043d\u043e\u0432\u043e \u043f\u0435\u0440\u0435\u0431\u0438\u0440\u0430\u0435\u0442\n#\u043f\u0430\u0440\u044b \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0439 \u0441 \u0443\u0447\u0435\u0442\u043e\u043c \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u0435\u043d\u043d\u043e\u0439 \u043f\u0430\u0440\u044b. \u0418 \u0442\u0430\u043a \u043f\u043e\u043a\u0430 \u043d\u0438\u043a\u0430\u043a\u0438\u0435 \u0438\u0437 \u043f\u0430\u0440 \u043d\u0435\u043b\u044c\u0437\u044f \u0431\u0443\u0434\u0435\u0442 \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u0438\u0442\u044c.\ndef categories_reducing(df, test, feature, target, func, p=0.05):\n    data = df.copy()\n    cats = list(set(data[feature].values))\n    data['Id'] = data.index    \n    for i in itertools.combinations(cats, r=2):\n        feature_and_target = data.loc[data[feature].isin([i[0], i[1]]), ['Id', feature, target]]\n        table = feature_and_target.pivot_table(values='Id', index=feature, columns=target,\n                                               aggfunc=func)\n        chi2, p, _, _ = chi2_contingency(table)\n        if p>0.05:\n            data[feature].replace({i[0]: i[1]}, inplace=True)\n            test[feature].replace({i[0]: i[1]}, inplace=True)\n            data, test = categories_reducing(data, test, feature, target, func)\n            return data, test\n    return data, test","f36199d4":"train = pd.read_csv('..\/input\/creditdefaultdf\/train.csv')\ntest = pd.read_csv('..\/input\/creditdefaultdf\/test.csv')","4778b6dd":"train.describe()","a552bc25":"train.info()","2aaeb2d5":"TARGET = ['Credit Default']\n\nCAT_COLS = ['Home Ownership', 'Years in current job', 'Purpose', 'Term']\nNUM_COLS = ['Annual Income', 'Tax Liens', 'Number of Open Accounts', 'Years of Credit History',\n           'Maximum Open Credit', 'Number of Credit Problems', 'Months since last delinquent',\n           'Bankruptcies', 'Current Loan Amount', 'Current Credit Balance', 'Monthly Debt', 'Credit Score']","7988008c":"class Preprocessing:\n    #Number of open accounts \u043d\u0438\u043a\u0430\u043a \u043d\u0435 \u043e\u0431\u0440\u0430\u0431\u0430\u0442\u044b\u0432\u0430\u043b. \u041c\u043e\u0436\u043d\u043e \u0434\u0438\u0441\u043a\u0440\u0435\u0442\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0438 \u0441\u0434\u0435\u043b\u0430\u0442\u044c \u0434\u0430\u043c\u043c\u0438\u0441.\n    def __init__(self):\n        self.ICLcondition = None\n        self.dummis_dict = {}\n#         self.purposes_dict = {'renewable energy': 1,\n#                              'small business': 1,\n#                             'business loan': 1,\n#                             'medical bills': 2,\n#                             'other': 2,\n#                             'debt consolidation': 2,\n#                             'take a trip': 2,\n#                             'home improvements': 3,\n#                             'wedding': 3,\n#                             'buy house': 3,\n#                             'buy a car': 3,\n#                             'vacation': 3,\n#                             'major purchase': 3,\n#                             'moving': 3,\n#                             'educational expenses': 3}\n        self.terms_dict = {'Long Term': 0, 'Short Term': 1}\n        self.CAT_cols = []\n        self.CAT_cols_AI = []\n    \n    def fit(self, df):\n        self.ICLcondition = (df['Current Loan Amount']!=99999999)&(~df['Annual Income'].isna())\n        self.IncomeCurrentLoanRatio = sum(df.loc[self.ICLcondition, 'Annual Income']) \/\\\n                                                (sum(df.loc[self.ICLcondition, 'Current Loan Amount'])*0.5)\n        \n        self.max_max_open_credit = df['Maximum Open Credit'].quantile(0.995)\n        self.min_max_open_credit = df.loc[df['Maximum Open Credit']>0, 'Maximum Open Credit'].min()\n        self.CCBtoMOC = df.loc[df['Maximum Open Credit']<self.max_max_open_credit, 'Current Credit Balance']\\\n        .sum()\/ df.loc[df['Maximum Open Credit']<self.max_max_open_credit, 'Maximum Open Credit'].sum()\n        \n        self.CLA_bins = [-1, 0,\n                         df['Current Loan Amount'].quantile(.10),\n                         df['Current Loan Amount'].quantile(.20),\n                         df['Current Loan Amount'].quantile(.30),\n                         df['Current Loan Amount'].quantile(.40),\n                         df['Current Loan Amount'].quantile(.50),\n                         df['Current Loan Amount'].quantile(.60),\n                         df['Current Loan Amount'].quantile(.70),\n                         df['Current Loan Amount'].quantile(.80),\n                         df['Current Loan Amount'].max(),\n                         df['Current Loan Amount'].max()*10]\n        \n        self.MOC_bins = [-1, 0,\n                         df['Maximum Open Credit'].quantile(.10),\n                         df['Maximum Open Credit'].quantile(.20),\n                         df['Maximum Open Credit'].quantile(.30),\n                         df['Maximum Open Credit'].quantile(.40),\n                         df['Maximum Open Credit'].quantile(.50),\n                         df['Maximum Open Credit'].quantile(.60),\n                         df['Maximum Open Credit'].quantile(.70),\n                         df['Maximum Open Credit'].quantile(.80),\n                         df['Maximum Open Credit'].quantile(.90),\n                         df['Maximum Open Credit'].max(),\n                         df['Maximum Open Credit'].max()*10]\n        \n        self.MSLD_bins = [-1, 0,\n                         df['Months since last delinquent'].quantile(.10), \n                         df['Months since last delinquent'].quantile(.20),\n                         df['Months since last delinquent'].quantile(.30),\n                         df['Months since last delinquent'].quantile(.40),\n                         df['Months since last delinquent'].quantile(.50),\n                         df['Months since last delinquent'].quantile(.60),\n                         df['Months since last delinquent'].quantile(.70),\n                         df['Months since last delinquent'].quantile(.80),\n                         df['Months since last delinquent'].quantile(.90),\n                         df['Months since last delinquent'].max(),\n                         df['Months since last delinquent'].max()*10]\n        \n        self.MD_bins = [-1, 0,\n                         df['Monthly Debt'].quantile(.10),\n                         df['Monthly Debt'].quantile(.20),\n                         df['Monthly Debt'].quantile(.30),\n                         df['Monthly Debt'].quantile(.40),\n                         df['Monthly Debt'].quantile(.50),\n                         df['Monthly Debt'].quantile(.60),\n                         df['Monthly Debt'].quantile(.70),\n                         df['Monthly Debt'].quantile(.80),\n                         df['Monthly Debt'].quantile(.90),\n                         df['Monthly Debt'].max(),\n                         df['Monthly Debt'].max()*10,]\n        \n        self.YOCH_bins = [-1, 0,\n                         df['Years of Credit History'].quantile(.10),\n                         df['Years of Credit History'].quantile(.20),\n                         df['Years of Credit History'].quantile(.30),\n                         df['Years of Credit History'].quantile(.40),\n                         df['Years of Credit History'].quantile(.50),\n                         df['Years of Credit History'].quantile(.60),\n                         df['Years of Credit History'].quantile(.70),\n                         df['Years of Credit History'].quantile(.80),\n                         df['Years of Credit History'].quantile(.90),\n                         df['Years of Credit History'].max(),\n                         df['Years of Credit History'].max()*10]\n        \n        self.monthly_debt_median = df['Monthly Debt'].median()\n        \n        self.NOAC_bins = [-1, 0,\n                         df['Number of Open Accounts'].quantile(.10),\n                         df['Number of Open Accounts'].quantile(.20),\n                         df['Number of Open Accounts'].quantile(.30),\n                         df['Number of Open Accounts'].quantile(.40),\n                         df['Number of Open Accounts'].quantile(.50),\n                         df['Number of Open Accounts'].quantile(.60),\n                         df['Number of Open Accounts'].quantile(.70),\n                         df['Number of Open Accounts'].quantile(.80),\n                         df['Number of Open Accounts'].quantile(.90),\n                         df['Number of Open Accounts'].max(),\n                         df['Number of Open Accounts'].max()*10]\n        self.TL_bins = [-1, 0,\n                         df['Tax Liens'].quantile(.10),\n                         df['Tax Liens'].quantile(.20),\n                         df['Tax Liens'].quantile(.30),\n                         df['Tax Liens'].quantile(.40),\n                         df['Tax Liens'].quantile(.50),\n                         df['Tax Liens'].quantile(.60),\n                         df['Tax Liens'].quantile(.70),\n                         df['Tax Liens'].quantile(.80),\n                         df['Tax Liens'].quantile(.90),\n                         df['Tax Liens'].max(),\n                         df['Tax Liens'].max()*10]\n        \n    def transform(self, data):\n        df = data.copy()\n        df['Years in current job'].fillna('MISSING', inplace=True)\n        \n        df['Current Loan Amount SUBS'] = 0\n        df.loc[df['Current Loan Amount']>90000000, 'Current Loan Amount SUBS'] = 1\n        df.loc[df['Current Loan Amount']>90000000, 'Current Loan Amount']= \\\n        df.loc[df['Current Loan Amount']>90000000, 'Annual Income'] \/ self.IncomeCurrentLoanRatio\n        \n        df['Maximum Open Credit MAXSUBS'] = 0\n        df.loc[df['Maximum Open Credit']>self.max_max_open_credit, 'Maximum Open Credit MAXSUBS'] = 1\n        df.loc[df['Maximum Open Credit']>self.max_max_open_credit, 'Maximum Open Credit'] =\\\n        df.loc[df['Maximum Open Credit']>self.max_max_open_credit,'Current Credit Balance'] \/ self.CCBtoMOC\n       \n        df['Maximum Open Credit MINSUBS'] = 0\n        df.loc[df['Maximum Open Credit']==0, 'Maximum Open Credit MINSUBS'] = 1\n        df.loc[df['Maximum Open Credit']==0, 'Maximum Open Credit'] = self.min_max_open_credit\n        \n        df['Number of Credit Problems'].fillna(0, inplace=True) #\u041c\u043e\u0436\u043d\u043e \u043f\u043e\u043f\u0440\u043e\u0431\u043e\u0432\u0430\u0442\u044c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u0431\u043e\u043b\u044c\u0448\u0435 0\n                                                                #\u0437\u0430\u043c\u0435\u043d\u0438\u0442\u044c \u0435\u0434\u0438\u043d\u0438\u0446\u0435\u0439\n        df['Months since last delinquent SUBS'] = 0\n        df.loc[df['Months since last delinquent'].isna(), 'Months since last delinquent SUBS'] = 1\n        df['Months since last delinquent'].fillna(0, inplace=True)\n        \n        df['Bankruptcies'].fillna(0, inplace=True)\n#         df['Purpose'].replace(self.purposes_dict, inplace=True)\n        df['Term'].replace(self.terms_dict, inplace=True)\n        df['Credit Score'].fillna(0, inplace=True)\n        \n        #\u0421\u043e\u0437\u0434\u0430\u044e \u043a\u043e\u043f\u0438\u044e \u043f\u0440\u0438\u0437\u0430\u043a\u0430 Credit Score, \u0447\u0442\u043e\u0431\u044b \u0437\u0430\u0442\u0435\u043c \u0437\u0430\u043c\u0435\u043d\u0438\u0442\u044c \u0432 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0438 0 \u043d\u0430 1, \u0442\u0430\u043c \u0433\u0434\u0435\n        #Credit Score \u0431\u043e\u043b\u044c\u0448\u0435 3000.\n        df['CS2'] = df['Credit Score']\n        df.loc[df['Credit Score']>3000, 'CS2'] = df.loc[df['Credit Score']>3000, 'Credit Score']\/10\n        \n#         df.loc[df['Credit Score']<=3000, 'Credit Score'] = 0\n#         df.loc[df['Credit Score']>3000, 'Credit Score'] = 1\n        \n        df['Monthly Debt'].fillna(self.monthly_debt_median, inplace=True)\n        \n        return df\n\n    \n    def create_categories(self, df, features):\n        if 'Number of Open Accounts' in features:\n            df['Number of Open Accounts CAT'] = pd.cut(df['Number of Open Accounts'],\n                                                       bins=self.NOAC_bins, labels=False)\n            self.CAT_cols.append('Number of Open Accounts CAT')\n            \n        if 'Years of Credit History' in features:\n            df['Years of Credit History CAT'] = pd.cut(df['Years of Credit History'],\n                                                       bins=self.YOCH_bins, labels=False)\n            self.CAT_cols.append('Years of Credit History CAT')\n            \n        if 'Current Loan Amount' in features:\n            df['Current Loan Amount CAT'] = pd.cut(df['Current Loan Amount'], bins=self.CLA_bins,\n                                                   labels=False)\n            self.CAT_cols.append('Current Loan Amount CAT')\n            \n        if 'Maximum Open Credit' in features:\n            df['Maximum Open Credit CAT'] = pd.cut(df['Maximum Open Credit'], bins=self.MOC_bins,\n                                                   labels=False)\n            self.CAT_cols.append('Maximum Open Credit CAT')\n            \n        if 'Months since last delinquent' in features:\n            df['Months since last delinquent CAT'] = pd.cut(df['Months since last delinquent'],\n                                                   bins=self.MSLD_bins, labels=False)\n            self.CAT_cols.append('Months since last delinquent CAT')\n            \n        if 'Monthly Debt' in features:\n            df['Monthly Debt CAT'] = pd.cut(df['Monthly Debt'], bins=self.MD_bins, labels=False)    \n            self.CAT_cols.append('Monthly Debt CAT')\n        \n        if 'Tax Liens' in features:\n            df['Tax Liens CAT'] = pd.cut(df['Tax Liens'], bins=self.MD_bins, labels=False)    \n            self.CAT_cols.append('Tax LiensCAT')\n            \n        return df","0189c4ee":"prep = Preprocessing()\nprep.fit(train)","5cc7bdec":"train = prep.transform(train)\ntest = prep.transform(test)","f709a804":"train = prep.create_categories(train, ['Number of Open Accounts', 'Years of Credit History',\n                                       'Current Loan Amount', 'Maximum Open Credit',\n                                       'Months since last delinquent', 'Monthly Debt'])\ntest = prep.create_categories(test, ['Number of Open Accounts', 'Years of Credit History',\n                                     'Current Loan Amount', 'Maximum Open Credit',\n                                     'Months since last delinquent', 'Monthly Debt'])","b061ad0f":"CAT_COLS = CAT_COLS + ['Number of Open Accounts CAT', 'Years of Credit History CAT',\n                       'Current Loan Amount CAT', 'Maximum Open Credit CAT',\n                       'Months since last delinquent CAT', 'Monthly Debt CAT']","f196b8a8":"#\u0423\u043c\u0435\u043d\u044c\u0448\u0435\u043d\u0438\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0439 \u0432 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430\u0445 \u043f\u043e \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0443 Credit Default.\nfor feature in CAT_COLS:\n    train, test = categories_reducing(train, test, feature, 'Credit Default', 'count')","e40b2739":"#\u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u044b\u0445 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0439, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0431\u0443\u0434\u0443\u0442 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u044b \u043f\u0440\u0438 \u0440\u0430\u0441\u0441\u0447\u0435\u0442\u0435 Annual Income. \nCAT_COLS_AI = []\nfor feature in CAT_COLS:\n    train[feature+' AI'] = train[feature]\n    test[feature+' AI'] = test[feature]\n    CAT_COLS_AI.append(feature+' AI')","fcf520b5":"#\u041f\u0440\u043e\u0432\u0435\u0440\u043a\u0430 \u043d\u0430 \u043d\u0430\u043b\u0438\u0447\u0438\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432, \u0433\u0434\u0435 \u0432\u0441\u0435 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0438 \u0441\u0432\u0435\u0440\u043d\u0443\u043b\u0438\u0441\u044c \u0432 \u043e\u0434\u043d\u0443.\nuseless_features = []\nfor feature in [CAT_COLS+CAT_COLS_AI]:\n    if len(train[feature].value_counts())==1:\n        useless_features.append(feature)\nuseless_features","6fc501f3":"DUMMIES_COLS_AI = []\ndef create_dummies_AI(df):\n    df = pd.concat([df, pd.get_dummies(df['Home Ownership AI'], prefix='HO AI')], axis=1)\n    DUMMIES_COLS_AI.append(pd.get_dummies(df['Home Ownership AI'], prefix='HO AI').columns[0])\n    \n    df = pd.concat([df, pd.get_dummies(df['Years in current job AI'], prefix='YCJ AI')], axis=1)\n    DUMMIES_COLS_AI.append(pd.get_dummies(df['Years in current job AI'], prefix='YCJ AI').columns[0])\n    \n    df = pd.concat([df, pd.get_dummies(df['Current Loan Amount CAT AI'], prefix='CLA AI')], axis=1)\n    DUMMIES_COLS_AI.append(pd.get_dummies(df['Current Loan Amount CAT AI'], prefix='CLA AI').columns[0])\n    \n    df = pd.concat([df, pd.get_dummies(df['Number of Open Accounts CAT AI'], prefix='NOOA AI')], axis=1)\n    DUMMIES_COLS_AI.append(pd.get_dummies(df['Number of Open Accounts CAT AI'], prefix='NOOA AI').columns[0])\n    \n    df = pd.concat([df, pd.get_dummies(df['Years of Credit History CAT AI'], prefix='YCH AI')], axis=1)\n    DUMMIES_COLS_AI.append(pd.get_dummies(df['Years of Credit History CAT AI'], prefix='YCH AI').columns[0])\n    \n    df = pd.concat([df, pd.get_dummies(df['Maximum Open Credit CAT AI'], prefix='MOC AI')], axis=1)\n    DUMMIES_COLS_AI.append(pd.get_dummies(df['Maximum Open Credit CAT AI'], prefix='MOC AI').columns[0])\n    \n    df = pd.concat([df, pd.get_dummies(df['Months since last delinquent CAT AI'], prefix='MSLD AI')], axis=1)  \n    DUMMIES_COLS_AI.append(pd.get_dummies(df['Months since last delinquent CAT AI'], prefix='MSLD AI').\\\n                           columns[0])\n    \n    df = pd.concat([df, pd.get_dummies(df['Purpose AI'], prefix='PRPS AI')], axis=1)\n    DUMMIES_COLS_AI.append(pd.get_dummies(df['Purpose AI'], prefix='PRPS AI').columns[0])\n    \n    df = pd.concat([df, pd.get_dummies(df['Monthly Debt CAT AI'], prefix='MD AI')], axis=1)   \n    DUMMIES_COLS_AI.append(pd.get_dummies(df['Monthly Debt CAT AI'], prefix='MD AI').columns[0])\n    \n    return df","5428c545":"train = create_dummies_AI(train)\ntest = create_dummies_AI(test)","71e0fca4":"TARGET_ENCODING_FEATURES = ['Term', 'Home Ownership', 'Years in current job',\n                            'Months since last delinquent CAT', 'Years of Credit History CAT',\n                            'Current Loan Amount CAT', 'Number of Credit Problems']","d829245e":"#\u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432, \u0432 \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u043a\u043e\u0434\u0438\u0440\u0443\u0435\u043c Annual Income \u0434\u043b\u044f \u043f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0438\nfor feature in TARGET_ENCODING_FEATURES:\n    train, test = make_mean_encoding_smooth2(train, test, 'Annual Income', feature, alpha=2, for_test=True)","8501ce03":"plt.figure(figsize = (10, 5))\nsns.distplot(train['Annual Income'], bins=50)\nplt.suptitle('Distribution of Annual Income')\nplt.show()","34256731":"ai_cols = [\n 'Annual Income',\n 'Credit Score',\n 'CS2',\n 'Tax Liens',\n 'Number of Open Accounts',\n 'Maximum Open Credit',\n 'Number of Credit Problems',\n 'Months since last delinquent',\n 'Bankruptcies',\n 'Term',\n 'Current Loan Amount',\n 'Current Credit Balance',\n 'Monthly Debt',\n 'Current Loan Amount SUBS',\n 'Maximum Open Credit MAXSUBS',\n 'Maximum Open Credit MINSUBS',\n 'Months since last delinquent SUBS',\n 'Term MEAN Annual Income',\n 'Home Ownership MEAN Annual Income',\n 'Years in current job MEAN Annual Income',\n 'Months since last delinquent CAT MEAN Annual Income',\n 'Current Loan Amount CAT MEAN Annual Income',\n 'Number of Credit Problems MEAN Annual Income'] + list(set(DUMMIES_COLS_AI))","8730e597":"#\u0423\u0434\u0430\u043b\u0435\u043c \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043c\u044b \u043f\u0435\u0440\u0435\u0432\u0435\u043b\u0438 \u0432 \u0434\u0430\u043c\u043c\u043c\u0438\u0441.\nfor col in CAT_COLS_AI:\n    if col in ai_cols:\n        ai_cols.remove(col)","24abd55f":"X_ai = train[ai_cols].loc[~train['Annual Income'].isna()]\ny_ai = train.loc[~train['Annual Income'].isna(), 'Annual Income']","259923a9":"X_ai = X_ai.drop(columns=['Annual Income'])\nai_cols.remove('Annual Income')","67135da2":"X_train_income, X_test_income, y_train_income, y_test_income = \\\ntrain_test_split(X_ai, y_ai, test_size=0.3, shuffle=True, random_state=42)","37b0a3d4":"income_model = CatBoostRegressor(random_state=42)","b555a304":"params = {'n_estimators':[100, 110, 120, 130],\n          'max_depth':[3, 4, 5]}","a83ee2fb":"cv=KFold(n_splits=3, random_state=42, shuffle=True)","ed0077ad":"gs_ai = GridSearchCV(income_model, params, scoring='r2', cv=cv, n_jobs=-2)","ffc7102d":"%%time\ngs_ai.fit(X_train_income, y_train_income, verbose=0)","087125cc":"gs_ai.best_params_","9ff2da6c":"income_model = CatBoostRegressor(max_depth=gs_ai.best_params_['max_depth'],\n                                 n_estimators=gs_ai.best_params_['n_estimators'],\n                                 random_state=42)","203ac2f1":"income_model.fit(X_train_income, y_train_income, verbose=0)","317ce044":"y_train_income_preds = income_model.predict(X_train_income)\nevaluate_preds(y_train_income, y_train_income_preds)","b9a17d11":"y_test_income_preds = income_model.predict(X_test_income)\nevaluate_preds(y_test_income, y_test_income_preds)","e414a2b0":"income_importances = pd.DataFrame(zip(ai_cols, income_model.feature_importances_)).\\\nrename(columns={0: \"Feature\", 1: 'Importance'}).sort_values(by='Importance', ascending=False)\nincome_importances","3d9a0246":"#\u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0435\u0449\u0435 \u043e\u0434\u043d\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u0438 \u0441 \u043c\u0435\u043d\u044c\u0448\u0438\u043c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e\u043c \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u043c, \u0434\u043b\u044f \u0443\u043c\u0435\u043d\u044c\u0448\u0435\u043d\u0438\u044f \u043f\u0435\u0440\u0435\u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f\nincome_columns = income_importances['Feature'][income_importances['Importance']>1].tolist()","c14ec6bf":"income_short_model = CatBoostRegressor(max_depth=3,\n                                       n_estimators=120,\n                                       random_state=42)","87f437e4":"income_short_model.fit(X_train_income[income_columns], y_train_income, verbose=0)","df86c1f4":"y_train_income_preds = income_short_model.predict(X_train_income[income_columns])\nevaluate_preds(y_train_income, y_train_income_preds)","6c29a511":"y_test_income_preds = income_short_model.predict(X_test_income[income_columns])\nevaluate_preds(y_test_income, y_test_income_preds)","848b6a10":"#\u0417\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432 \u043f\u0440\u043e\u0433\u043d\u043e\u0437\u043d\u044b\u043c\u0438 \u0434\u0430\u043d\u043d\u044b\u043c\u0438\ntrain.loc[train['Annual Income'].isna(), 'Annual Income'] =\\\n                        income_short_model.predict(train.loc[train['Annual Income'].isna(), income_columns])\ntest.loc[test['Annual Income'].isna(), 'Annual Income'] =\\\n                        income_short_model.predict(test.loc[test['Annual Income'].isna(), income_columns])","6b1f1fb9":"atributes = ['Annual Income',\n             'Maximum Open Credit',\n             'Current Loan Amount',\n             'Current Credit Balance',\n             'Monthly Debt',\n             'Credit Score']","0ec34dab":"scatter_matrix(train[atributes], figsize=(16,16))\n# plt.show()","9b639e97":"cols = [\n 'Annual Income',\n 'Credit Score',\n 'CS2',\n 'Tax Liens',\n 'Number of Open Accounts',\n 'Maximum Open Credit',\n 'Number of Credit Problems',\n 'Months since last delinquent',\n 'Bankruptcies',\n 'Term',\n 'Current Loan Amount',\n 'Current Credit Balance',\n 'Monthly Debt',\n 'Current Loan Amount SUBS',\n 'Maximum Open Credit MAXSUBS',\n 'Maximum Open Credit MINSUBS',\n 'Months since last delinquent SUBS',\n 'Term MEAN Annual Income',\n 'Home Ownership MEAN Annual Income',\n 'Years in current job MEAN Annual Income',\n 'Months since last delinquent CAT MEAN Annual Income',\n 'Current Loan Amount CAT MEAN Annual Income',\n 'Number of Credit Problems MEAN Annual Income']","57a64a93":"plt.figure(figsize = (30,25))\n\nsns.set(font_scale=1.4)\n\ncorr_matrix = train[cols].corr()\ncorr_matrix = np.round(corr_matrix, 2)\ncorr_matrix[np.abs(corr_matrix) < 0.3] = 0\n\nsns.heatmap(corr_matrix, annot=True, linewidths=.5, cmap='GnBu')\n\nplt.title('Correlation matrix')\nplt.show()","91fec38c":"#\u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432, \u0432 \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u043a\u043e\u0434\u0438\u0440\u0443\u0435\u043c Credit Score \u0434\u043b\u044f \u043f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0438\nfor feature in TARGET_ENCODING_FEATURES:\n    train, test = make_mean_encoding_smooth2(train, test, 'Credit Default', feature, alpha=2)","b8ce2432":"DUMMIES_COLS_CD = []\ndef create_dummies_CD(df):\n    df = pd.concat([df, pd.get_dummies(df['Home Ownership'], prefix='HO')], axis=1)\n    DUMMIES_COLS_AI.append(pd.get_dummies(df['Home Ownership'], prefix='HO').columns[0])\n    \n    df = pd.concat([df, pd.get_dummies(df['Years in current job'], prefix='YCJ')], axis=1)\n    DUMMIES_COLS_AI.append(pd.get_dummies(df['Years in current job'], prefix='YCJ').columns[0])\n    \n    df = pd.concat([df, pd.get_dummies(df['Current Loan Amount CAT'], prefix='CLA')], axis=1)\n    DUMMIES_COLS_AI.append(pd.get_dummies(df['Current Loan Amount CAT'], prefix='CLA').columns[0])\n    \n    df = pd.concat([df, pd.get_dummies(df['Number of Open Accounts CAT'], prefix='NOOA')], axis=1)\n    DUMMIES_COLS_AI.append(pd.get_dummies(df['Number of Open Accounts CAT'], prefix='NOOA').columns[0])\n    \n    df = pd.concat([df, pd.get_dummies(df['Years of Credit History CAT'], prefix='YCH')], axis=1)\n    DUMMIES_COLS_AI.append(pd.get_dummies(df['Years of Credit History CAT'], prefix='YCH').columns[0])\n    \n    df = pd.concat([df, pd.get_dummies(df['Maximum Open Credit CAT'], prefix='MOC')], axis=1)\n    DUMMIES_COLS_AI.append(pd.get_dummies(df['Maximum Open Credit CAT'], prefix='MOC').columns[0])\n    \n    df = pd.concat([df, pd.get_dummies(df['Months since last delinquent CAT'], prefix='MSLD')], axis=1) \n    DUMMIES_COLS_AI.append(pd.get_dummies(df['Months since last delinquent CAT'], prefix='MSLD').columns[0])\n    \n    df = pd.concat([df, pd.get_dummies(df['Purpose'], prefix='PRPS')], axis=1)\n    DUMMIES_COLS_AI.append(pd.get_dummies(df['Purpose'], prefix='PRPS').columns[0])\n    \n    df = pd.concat([df, pd.get_dummies(df['Monthly Debt CAT'], prefix='MD')], axis=1)\n    DUMMIES_COLS_AI.append(pd.get_dummies(df['Monthly Debt CAT'], prefix='MD').columns[0])\n    \n    return df","85d7023f":"train = create_dummies_CD(train)\ntest = create_dummies_CD(test)","158dda79":"final_cols = train.columns.tolist()\nfinal_cols.remove('Credit Default')\nfinal_cols.remove('Id')\nlen(final_cols)","7f393e41":"#\u0423\u0434\u0430\u043b\u044f\u0435\u043c \u0432\u0441\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043d\u0435 \u0441\u043e\u0433\u043b\u0430\u0441\u043e\u0432\u044b\u0432\u0430\u044e\u0442\u0441\u044f \u043d\u0430 \u0442\u0440\u0435\u0439\u043d\u0435 \u0438 \u0442\u0435\u0441\u0442\u0435 \u043f\u043e \u043a\u0440\u0438\u0442\u0435\u0440\u0438\u044e \u041c\u0430\u043d\u043d\u0430\u0423\u0438\u0442\u043d\u0438\nfinal_cols_for_check = final_cols.copy()\nfor col in final_cols_for_check:\n    if col in test:\n        if mannwhitneyu(train[col], test[col]).pvalue<0.05:\n            final_cols.remove(col)\n    else:\n        final_cols.remove(col)","6cee6f2f":"#\u0423\u0434\u0430\u043b\u044f\u0435\u043c \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f\u0430\u043b\u044c\u043d\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438, \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0430\u043d\u0438\u0438 \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u0431\u044b\u043b\u0438 \u0441\u043e\u0437\u0434\u0430\u043d\u043d\u044b \u0434\u0430\u043c\u043c\u0438\u0441.\nfor col in CAT_COLS_AI+CAT_COLS:\n    if col in final_cols:\n        final_cols.remove(col)","e5522c7f":"len(final_cols)","654ac42b":"final_cols","088e011e":"#\u041f\u0440\u043e\u0432\u0440\u043a\u0430 \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0439 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 \u043d\u0430 \u0442\u0440\u0435\u0439\u043d\u0435 \u0438 \u0442\u0435\u0441\u0442\u0435\nnum_feature = 'Current Credit Balance'\nfor col in list(set(DUMMIES_COLS_CD))+list(set(DUMMIES_COLS_AI)):\n    plt.figure(figsize=figsize)\n    sns.pointplot(x=col, y=num_feature, data=train, capsize=.1, label='train', color='red')\n    sns.pointplot(x=col, y=num_feature, data=test, capsize=.1, label='test', color='blue')\n    plt.title(col) \n    plt.show()","ff02f773":"num_feature = 'Annual Income'\nfor col in list(set(DUMMIES_COLS_CD))+list(set(DUMMIES_COLS_AI)):\n    plt.figure(figsize=figsize)\n    sns.pointplot(x=col, y=num_feature, data=train, capsize=.1, label='train', color='red')\n    sns.pointplot(x=col, y=num_feature, data=test, capsize=.1, label='test', color='blue')\n    plt.title(col) \n    plt.show()","8c4dade1":"COLS_FOR_EXCLUSION = ['Years in current job', 'Years in current job AI', 'MSLD_7']\nMAYBE_COLS_FOR_EXCLUSION = ['MSLD AI_7']","f11cff8e":"for col in COLS_FOR_EXCLUSION + MAYBE_COLS_FOR_EXCLUSION:\n    if col in final_cols:\n        final_cols.remove(col)","31ac2d94":"final_cols","21f8bba3":"corr_with_target = train[final_cols + TARGET].corr().iloc[:-1, -1].sort_values(ascending=False)\n\nplt.figure(figsize=(10, 8))\n\nsns.barplot(x=corr_with_target.values, y=corr_with_target.index)\n\nplt.title('Correlation with target variable')\nplt.show()","c647d0b0":"#\u041d\u0443\u0436\u043d\u043e \u043f\u0440\u043e\u0441\u043b\u0435\u0434\u0438\u0442\u044c, \u0447\u0442\u043e params \u0440\u0430\u0431\u043e\u0442\u0430\u0435\u0442 \u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u043e, \u0435\u0441\u043b\u0438 \u043c\u044b \u043d\u0435 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c gridsearch.\n\"\"\"\n\u041f\u043e\u0440\u044f\u0434\u043e\u043a \u0440\u0430\u0431\u043e\u0442\u044b \u0441 \u043a\u043b\u0430\u0441\u0441\u043e\u043c:\n1. \u0421 \u0438\u043b\u0438 \u0431\u0435\u0437 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430 Credit Score.\n\u0412\u043d\u0430\u0447\u0430\u043b\u0435 \u0444\u043e\u0440\u043c\u0438\u0440\u0443\u0435\u0442\u0441\u044f \u043c\u043e\u0434\u0435\u043b\u044c \u043d\u0430 \u0432\u0441\u0435\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430\u0445 \u0438 \u043d\u0430 \u0432\u0441\u0435\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430\u0445 \u043a\u0440\u043e\u043c\u0435 Credit Score c \u043f\u043e\u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0435\u0439 \u043f\u0440\u044f\u043c\u043e\u0439\n\u043f\u043e\u0434\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u043e\u0439 \u0435\u0434\u0438\u043d\u0438\u0446 \u0432 \u0438\u0442\u043e\u0433\u043e\u0432\u043e\u0435 \u0440\u0435\u0448\u0435\u043d\u0438\u0435 \u0434\u043b\u044f \u0442\u0435\u0445 \u043d\u0430\u0431\u043b\u044e\u0434\u0435\u043d\u0438\u0439, \u0433\u0434\u0435 Credit Score \u0440\u0430\u0432\u0435\u043d 1 (\u0438\u043b\u0438 \u0431\u043e\u043b\u044c\u0448\u0435 3000, \u0435\u0441\u043b\u0438 \u043d\u0435\n\u043e\u0431\u0440\u0430\u0431\u0430\u0442\u044b\u0432\u0430\u0442\u044c \u043a\u043b\u0430\u0441\u0441). \u041f\u043e\u0434\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0443 \u0434\u0435\u043b\u0430\u0435\u043c \u0432 \u043e\u0431\u043e\u0438\u0445 \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u0430\u0445.\n\nModelSearch: balance_mode=None, CS_data_sep=False.\ncreate_model: best_feat=False, gr_features=None, must=[], gs=True, params=None, cv=None,\n              threshold_fit=False, topN=5, CS_subs=True\n\u041c\u043e\u0434\u0435\u043b\u0438 \u0444\u043e\u0440\u043c\u0438\u0440\u0443\u0435\u043c \u0434\u0432\u0430 \u0440\u0430\u0437\u0430 - threshold_fit==False \u0438 ==True (\u043f\u043e\u0434\u0431\u043e\u0440 \u043e\u043f\u0442\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0439 \u043e\u0442\u0441\u0435\u0447\u043a\u0438).\n\n2. \u0421 \u0438\u043b\u0438 \u0431\u0435\u0437 \u043d\u0430\u0431\u043b\u044e\u0434\u0435\u043d\u0438\u0439, \u0443 \u043a\u043e\u0442\u043e\u0440\u044b\u0445 Credit Score == 1 (\u0431\u043e\u043b\u044c\u0448\u0435 3000 \u043f\u0440\u0438 \u043d\u0435\u043e\u0431\u0440\u0430\u0431\u043e\u0442\u0430\u043d\u043d\u043e\u043c \u043a\u043b\u0430\u0441\u0441\u0435)\n\u041f\u0440\u043e\u0432\u0435\u0440\u044f\u0435\u043c \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u0440\u0438 \u0440\u0430\u0437\u043d\u044b\u0445 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f\u0445 CS_data_sep (\u0443\u0447\u0438\u0442\u044b\u0432\u0430\u0435\u043c \u0438\u043b\u0438 \u043d\u0435 \u0443\u0447\u0438\u0442\u044b\u0432\u0430\u0435\u043c \u043d\u0430\u0431\u043b\u044e\u0434\u0435\u043d\u0438\u044f, \u0432\n\u043a\u043e\u0442\u043e\u0440\u044b\u0445 Credit Score \u0440\u0430\u0432\u0435\u043d 1 (\u0431\u043e\u043b\u044c\u0448\u0435 3000 \u043f\u0440\u0438 \u043d\u0435\u043e\u0431\u0440\u0430\u0431\u043e\u0442\u0430\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445) \u043f\u0440\u0438 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0438 \u043c\u043e\u0434\u0435\u043b\u0438).\n\n3. \u041f\u043e\u0434\u0431\u043e\u0440 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432.\n\u041e\u0442 \u043f\u0440\u0435\u0434\u044b\u0434\u0443\u0449\u0438\u0435\u0439 \u043b\u0443\u0447\u0448\u0435 \u043c\u043e\u0434\u0435\u043b\u0438 \u0431\u0435\u0440\u0435\u043c \u0432\u0441\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u0441\u043e \u0437\u043d\u0430\u0447\u0438\u043c\u043e\u0441\u0442\u044c\u044e \u0431\u043e\u043b\u0435\u0435 1%.\n\u0411\u0435\u0440\u0435\u043c \u0442\u043e\u043f-7 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 \u0438 \u0432\u0441\u0435 \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u044b\u0435 \u0438\u0445 \u043a\u043e\u043c\u0431\u0438\u043d\u0430\u0446\u0438\u0438. \u041f\u0440\u043e\u0432\u0435\u0440\u044f\u0435\u043c \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043a\u043e\u043c\u0431\u0438\u043d\u0430\u0446\u0438\u0438 \u043c\u043e\u0434\u0435\u043b\u044c \u0431\u0443\u0434\u0435\u0442 \u043b\u0443\u0447\u0448\u0435 \u0432\u0441\u0435\u0433\u043e\n\u0440\u0430\u0431\u043e\u0442\u0430\u0442\u044c. \u0414\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u043b\u0443\u0447\u0448\u0443\u044e \u043a\u043e\u043c\u0431\u0438\u043d\u0430\u0446\u0438\u044e \u0432 must (\u044d\u0442\u0438 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u0442\u043e\u0447\u043d\u043e \u0431\u0443\u0434\u0443\u0442 \u0443\u0447\u0430\u0432\u0441\u0442\u0432\u043e\u0432\u0430\u0442\u044c). \u041e\u0441\u0442\u0430\u0432\u0448\u0438\u0435\u0441\u044f \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438\n\u0440\u0430\u0437\u0431\u0438\u0432\u0430\u0435\u043c \u043c\u0430\u043a\u0441\u0438\u043c\u0443\u043c \u043d\u0430 7 \u0433\u0440\u0443\u043f\u043f \u0438 \u0432\u043c\u0435\u0441\u0442\u0435 \u0441 must \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u043c \u043b\u0443\u0447\u0448\u0443\u044e \u043c\u043e\u0434\u0435\u043b\u044c.\n\u0424\u0438\u043a\u0441\u0438\u0440\u0443\u0435\u043c \u043f\u043e\u043b\u0443\u0447\u0430\u0435\u043d\u043d\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u0432 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0435 final_cols.\n\n4. \u0411\u0430\u043b\u0430\u043d\u0441\u0438\u0440\u043e\u0432\u043a\u0430.\n\u041f\u0440\u043e\u0432\u0435\u0440\u044f\u0435\u043c \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u0440\u0438 \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0438\u0445 \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u0430\u0445 \u0431\u0430\u043b\u0430\u043d\u0441\u0438\u0440\u043e\u0432\u043e\u043a:\n- tomek\n- smote\n- \u0432\u043d\u0430\u0447\u0430\u043b\u0435 tomek, \u0430 \u043f\u043e\u0442\u043e\u043c smote\n\u0412\u044b\u0431\u0438\u0440\u0430\u0435\u043c \u043b\u0443\u0447\u0448\u0443\u044e \u043c\u043e\u0434\u0435\u043b\u044c.\n\n5. \u041f\u043e\u0438\u0441\u043a \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u043c\u043e\u0434\u0435\u043b\u0438.\n\u0418\u0437\u043d\u0430\u0447\u0430\u043b\u044c\u043d\u043e \u0443\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u043c \u043f\u043e \u0442\u0440\u0438 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430 \u043c\u043e\u0434\u0435\u043b\u0438. \u0417\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u0434\u043e\u043b\u0436\u043d\u044b \u0437\u043d\u0430\u0447\u0438\u0442\u0435\u043b\u044c\u043d\u043e\n\u043e\u0442\u043b\u0438\u0447\u0430\u0442\u044c\u0441\u044f \u0434\u0440\u0443\u0433 \u043e\u0442 \u0434\u0440\u0443\u0433\u0430. \u041d\u0430\u0445\u043e\u0434\u0438\u043c \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u0441 \u043d\u0430\u0438\u043b\u0443\u0447\u0448\u0438\u043c\u0438 \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u044f\u043c\u0438, \u043e\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u043c \u0438\u0445. \u041f\u0440\u0438\u0434\u0432\u0438\u0433\u0430\u0435\u043c \u043e\u0441\u0442\u0430\u0432\u0448\u0438\u0435\u0441\u044f\n\u0432\u0430\u0440\u0438\u0430\u043d\u0442\u044b \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u043a \u0443\u0436\u0435 \u043d\u0430\u0439\u0434\u0435\u043d\u043d\u044b\u043c. \u0414\u0435\u043b\u0430\u0435\u043c \u0442\u0430\u043a, \u043f\u043e\u043a\u0430 \u0440\u0430\u0437\u043d\u0438\u0446\u0430 \u043c\u0435\u0436\u0434\u0443 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430\u043c\u0438 \u043d\u0435 \u0431\u0443\u0434\u0435\u0442 \u043c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0439.\n\"\"\"\n\nclass ModelSearch:\n    def __init__(self, model_name, df, cols, target, balance_mode=None, CS_data_sep=False):\n        self.best_features = None\n        \n        self.model_name = model_name\n        self.df = df\n        self.cols = cols\n        self.target = target\n        self.balance_mode=balance_mode\n        self.CS_data_sep = CS_data_sep\n        \n        self.best_feat = None\n        self.gr_features = None\n        self.must = None\n        self.gs=None\n        self.params = None\n        self.cv = None\n        self.threshold_fit = None\n        self.topN = None\n        self.CS_subs = None\n        self.best_params = pd.DataFrame(columns=['Model', 'Features', 'Best params'])\n        self.i_for_bp = 0\n        self.model = None\n        self.threshold = None\n        self.total = pd.DataFrame(columns=['Name',\n                                           'Params',\n                                           'Features',\n                                           'F1 train',\n                                           'F1 test',\n                                           'Overfitting'])\n        self.total.loc[0] = 0\n        \n        self.X_train = None\n        self.y_train = None\n        self.X_train_balanced = None\n        self.y_train_balanced = None\n        self.X_test = None\n        self.y_test = None\n        self.y_test_pred = None\n        self.y_train_pred = None\n          \n        if 'Credit Score' in cols:\n            self.X_train = df[self.cols]\n            self.y_train = df[self.target]\n        else:\n            self.X_train = df[self.cols+['Credit Score']]\n            self.y_train = df[self.target]\n      \n        \n        self.X_train_full, self.X_test, self.y_train_full, self.y_test = train_test_split(self.X_train,\n                                                                                          self.y_train,\n                                                       shuffle=True, test_size=0.25, random_state=42,\n                                                    stratify=self.y_train)\n        \n        #\u0415\u0441\u043b\u0438 CS_data_sep \u0440\u0430\u0432\u043d\u0430 True, \u0442\u043e \u0432 \u043f\u043e\u0441\u0442\u043e\u0440\u043e\u0435\u043d\u0438\u0438 \u043c\u043e\u0434\u0435\u043b\u0438 \u043d\u0435 \u0443\u0447\u0438\u0442\u044b\u0432\u0430\u0435\u043c \u043d\u0430\u0431\u043b\u044e\u0434\u0435\u043d\u0438\u044f, \u0433\u0434\u0435 'Credit Score'==1\n        if CS_data_sep:\n            self.X_train = pd.DataFrame(self.X_train_full)\n            self.y_train = pd.DataFrame(self.y_train_full)\n            self.X_train = self.X_train.loc[self.X_train_full['Credit Score']==0, self.cols]\n            self.y_train = self.y_train.loc[self.X_train_full['Credit Score']==0]\n        else:\n            self.X_train = pd.DataFrame(self.X_train_full)\n            self.y_train = pd.DataFrame(self.y_train_full)\n            \n        if balance_mode!=None:\n            self.df_for_balancing = pd.concat([self.X_train, self.y_train], axis=1)\n            self.df_balanced = balance_df_by_target(self.df_for_balancing, self.target, method=balance_mode)\n            #\u041c\u043e\u0436\u043d\u043e \u0435\u0449\u0435 \u0441\u0434\u0435\u043b\u0430\u0442\u044c \u0434\u0432\u043e\u0439\u043d\u043d\u0443\u044e \u0431\u0430\u043b\u0430\u043d\u0441\u0438\u0440\u043e\u0432\u043a\u0443 \u043a\u043b\u0430\u0441\u0441\u043e\u0432\n            self.X_train_balanced = self.df_balanced.drop(columns=target)\n            self.y_train_balanced = self.df_balanced[target]\n        else:\n            self.X_train_balanced = self.X_train\n            self.y_train_balanced = self.y_train\n    \n\n    def determine_best_features(self, features, X_train, y_train, X_test, y_test, must=[]):\n        model = self.model\n        result = pd.DataFrame(columns=['F1 train', 'F1 test', 'Overfitting', 'Features'])\n        result.loc[0] = 0\n\n\n        options = []\n        for L in range(0, len(features)+1):\n            for subset in itertools.combinations(features, L):\n                if len(subset)>0:\n                    options.append(list(itertools.chain(*subset))+must)\n    \n        iterations = len(options)\n        i = 0\n        for opt in options:\n            if self.model_name!='GB':\n                model.fit(X_train[opt], y_train, verbose=0)\n            else:\n                model.fit(X_train[opt], y_train)\n            i += 1\n            print(f'Iteration {i} of {iterations}, '+  '{:.1%}'.format(i\/iterations), end=\"\\r\")\n            y_train_pred = model.predict(X_train[opt])\n            y_test_pred = model.predict(X_test[opt])\n            result.loc[result.index.max()+1] = [f1(y_train, y_train_pred, average='binary'),\n                                                      f1(y_test, y_test_pred, average='binary'),\n                                                      f1(y_train, y_train_pred, average='binary') -\\\n                                                      f1(y_test, y_test_pred, average='binary'),\n                                                      opt]\n\n        result = result.drop([0])\n        result['Sorting'] = result['F1 test'] - result['Overfitting']\n\n\n        return result.sort_values(by='F1 test', ascending=False)\n   \n\n\n    def best_threshold(self, y_predicted_probs, y_true_labels):\n        preds_with_true_labels = np.array(list(zip(y_predicted_probs, y_true_labels)))\n\n        thresholds = []\n        f1_scores = []\n\n        for threshold in np.linspace(0.05, 0.95, 18):\n            thresholds.append(threshold)\n            f1_scores.append(f1(y_true_labels, list(map(int, y_predicted_probs > threshold)),\n                                average='binary'))\n\n        scores_table = pd.DataFrame({'f1':f1_scores,\n                                     'probability':thresholds}).sort_values('f1', ascending=False).round(3)\n        return scores_table.iloc[0, 1]\n    \n\n    \n    def create_model(self, best_feat=True, gr_features=None, must=[], gs=True, params=None, cv=None,\n              threshold_fit=True, topN=3, CS_subs=True):\n        \n        self.best_feat = best_feat\n        self.gr_features = gr_features\n        self.must = must\n        self.gs = gs\n        self.threshold_fit = threshold_fit\n        self.topN = topN\n        self.CS_subs = CS_subs\n        \n        if cv == None:\n            self.cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n        else:\n            self.cv = cv\n        \n        if self.model_name == 'CB':\n            self.model = CatBoostClassifier(max_depth=3, n_estimators=50, random_state=42)\n            if params!=None:\n                self.params = params\n            else:\n                self.params = {'n_estimators':[30, 100, 200], 'max_depth':[3, 5, 7]}\n        \n        elif self.model_name =='XGB':\n            self.model = xgb.XGBClassifier(max_depth=3, n_estimators=50, gamma=0.5, random_state=42)\n            if params!=None:\n                self.params = params\n            else:\n                self.params = {'n_estimators':[50, 100, 150, 300, 600], 'max_depth':[3, 7, 10, 15]}\n        \n        elif self.model_name== 'LGBM':\n            self.model = lgbm.LGBMClassifier(max_depth=3, n_estimators=50, reg_lambda=0.5, random_state=42)\n            if params!=None:\n                self.params = params\n            else:\n                self.params = {'n_estimators':[20, 30, 50], 'max_depth':[3], 'reg_lambda': [0.5, 0.9]}\n        \n        elif self.model_name == 'GB':\n            self.model = GradientBoostingClassifier(max_depth=3, n_estimators=400)\n            if params!=None:\n                self.params = params\n            else:\n                self.params = {'n_estimators':[100, 200, 400], 'max_depth':[3, 7, 15]}\n            \n\n        if best_feat:\n            self.best_features = self.determine_best_features(\n                                                     gr_features,\n                                                     self.X_train_balanced,\n                                                     self.y_train_balanced, self.X_test, self.y_test,\n                                                     must=must).head(topN)['Features'].tolist()\n        else:\n            self.best_features = self.cols\n   \n    \n        if gs:\n            for feats in self.best_features:\n                grid_search = GridSearchCV(self.model, self.params, cv=self.cv, scoring='f1',\n                                           n_jobs=-1, verbose=0)\n                if self.model_name!='GB':\n                    grid_search.fit(self.X_train_balanced[feats], self.y_train_balanced, verbose=0)\n                else:\n                    grid_search.fit(self.X_train_balanced[feats], self.y_train_balanced)\n                \n                self.best_params.loc[self.i_for_bp + 1] = [self.model_name, feats, grid_search.best_params_]\n                self.i_for_bp += 1\n                if self.model_name == 'CB':\n                    self.model = CatBoostClassifier(max_depth=grid_search.best_params_['max_depth'],\n                                                   n_estimators=grid_search.best_params_['n_estimators'],\n                                                    random_state=42)\n                elif self.model_name =='XGB':\n                    self.model = xgb.XGBClassifier(max_depth=grid_search.best_params_['max_depth'],\n                                                   n_estimators=grid_search.best_params_['n_estimators'],\n                                                   gamma=0.5,\n                                                   random_state=42)\n                elif self.model_name == 'LGBM':\n                    self.model = lgbm.LGBMClassifier(max_depth=grid_search.best_params_['max_depth'],\n                                                     n_estimators=grid_search.best_params_['n_estimators'],\n                                                     reg_lambda=grid_search.best_params_['reg_lambda'],\n                                                     random_state=42)\n                elif self.model_name == 'GB':\n                    self.model = GradientBoostingClassifier(max_depth=grid_search.best_params_['max_depth'],\n                                                            n_estimators=\\\n                                                            grid_search.best_params_['n_estimators'],\n                                                            random_state=42)\n#                 if self.model_name == 'CB':\n#                     train_data = np.array(pd.concat([self.X_train_balanced[feats], self.y_train_balanced],\n#                                                     axis=0))\n#                     eval_data = np.array(pd.concat([self.X_test[feats], self.y_test], axis=0))\n                    \n#                     train_label = np.ones(len(pd.concat([self.X_train_balanced[feats], self.y_train_balanced],\n#                                                     axis=0)))\n#                     train_labels[-1] = 0\n#                     eval_label = np.zeros(len(pd.concat([self.X_test[feats], self.y_test], axis=0)))\n#                     eval_label[-1] = 1\n#                     train_dataset = Pool(data=train_data, label=train_label)\n#                     eval_dataset = Pool(data=eval_data, label=eval_label)\n                                                         \n#                     self.model.fit(train_dataset,\n#                                    use_best_model=True,\n#                                    eval_set=eval_dataset)\n                if self.model_name!='GB':\n                    self.model.fit(self.X_train_balanced[feats], self.y_train_balanced, verbose=0)\n                else:\n                    self.model.fit(self.X_train_balanced[feats], self.y_train_balanced)\n                \n                if threshold_fit:\n                    #\u041d\u0430\u0445\u043e\u0434\u0438\u043c \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u0438 \u0434\u043b\u044f \u0433\u043b\u0430\u0432\u043d\u043e\u0433\u043e \u043a\u043b\u0430\u0441\u0441\u0430\n                    y_train_pred_probs = self.model.predict_proba(self.X_train_full[feats])\n                    y_test_pred_probs = self.model.predict_proba(self.X_test[feats])\n\n                    #\u041e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u043c \u043b\u0443\u0447\u0448\u0443\u044e \u043e\u0442\u0441\u0435\u0447\u043a\u0443\n                    threshold_model_train = self.best_threshold(y_train_pred_probs[:, 1], self.y_train_full)\n                    threshold_model_test = self.best_threshold(y_test_pred_probs[:, 1], self.y_test)\n                    self.threshold = threshold_model_train\n\n                    #\u041a\u043e\u0440\u0440\u0435\u043a\u0442\u0438\u0440\u0443\u0435\u043c \u0438\u0442\u043e\u0433\u043e\u0432\u044b\u0439 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u0441 \u0443\u0447\u0435\u0442\u043e\u043c \u043b\u0443\u0447\u0448\u0435\u0439 \u043e\u0442\u0441\u0435\u0447\u043a\u0438\n                    y_train_pred = (y_train_pred_probs[:,1] > self.threshold)\n                    y_test_pred = (y_test_pred_probs[:,1] > self.threshold)\n                else:\n                    y_train_pred = self.model.predict(self.X_train_full[feats])\n                    y_test_pred = self.model.predict(self.X_test[feats])\n                    y_train_pred = np.where(y_train_pred==0, False, True)\n                    y_test_pred = np.where(y_test_pred==0, False, True)\n                    \n                              \n                if CS_subs:\n                    y_train_pred = pd.DataFrame(y_train_pred)\n                    y_train_pred.iloc[self.X_train_full['Credit Score']>3000] = True\n                    y_train_pred = np.array(y_train_pred[0])\n\n                    y_test_pred = pd.DataFrame(y_test_pred)\n                    y_test_pred.iloc[self.X_test['Credit Score']>3000] = True\n                    y_test_pred = np.array(y_test_pred[0])\n                    self.y_test_pred = y_test_pred\n                    self.y_train_pred = y_train_pred \n                else:\n                    y_train_pred = self.model.predict(self.X_train_full[feats])\n                    y_test_pred = self.model.predict(self.X_test[feats])\n                    self.y_test_pred = y_test_pred\n                    self.y_train_pred = y_train_pred \n    \n                self.total.loc[self.total.index.max()+1] = [self.model_name,\n                                                       grid_search.best_params_,\n                                                       feats,\n                                                       f1(self.y_train_full, y_train_pred, average='binary'),\n                                                       f1(self.y_test, y_test_pred, average='binary'),\n                                                       f1(self.y_train_full, y_train_pred, average='binary')-\\\n                                                       f1(self.y_test, y_test_pred, average='binary')]\n        else:\n#             if self.model_name == 'CB':\n#                 train_data = np.array(pd.concat([self.X_train_balanced[self.best_features],\n#                                                  self.y_train_balanced], axis=0))\n#                 eval_data = np.array(pd.concat([self.X_test[self.best_features], self.y_test], axis=0))\n\n#                 train_label = np.ones(len(pd.concat([self.X_train_balanced[self.best_features],\n#                                                      self.y_train_balanced], axis=0)))\n#                 train_label[-1] = 0\n#                 eval_label = np.zeros(len(pd.concat([self.X_test[self.best_features], self.y_test], axis=0)))\n#                 eval_label[-1] = 1\n#                 train_dataset = Pool(data=train_data, label=train_label)\n#                 eval_dataset = Pool(data=eval_data, label=eval_label)\n\n#                 self.model.fit(train_dataset,\n#                                use_best_model=True,\n#                                eval_set=eval_dataset)\n# \n            if self.model_name!='GB':\n                self.model.fit(self.X_train_balanced[self.best_features], self.y_train_balanced, verbose=0)\n            else:\n                self.model.fit(self.X_train_balanced[self.best_features], self.y_train_balanced)\n                \n            if threshold_fit:\n                #\u041d\u0430\u0445\u043e\u0434\u0438\u043c \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u0438 \u0434\u043b\u044f \u0433\u043b\u0430\u0432\u043d\u043e\u0433\u043e \u043a\u043b\u0430\u0441\u0441\u0430\n                y_train_pred_probs = self.model.predict_proba(self.X_train_full[self.cols])\n                y_test_pred_probs = self.model.predict_proba(self.X_test[self.cols])\n               \n                #\u041e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u043c \u043b\u0443\u0447\u0448\u0443\u044e \u043e\u0442\u0441\u0435\u0447\u043a\u0443\n                threshold_model_train = self.best_threshold(y_train_pred_probs[:, 1], self.y_train_full)\n                threshold_model_test = self.best_threshold(y_test_pred_probs[:, 1], self.y_test)\n                self.threshold = threshold_model_train\n\n                #\u041a\u043e\u0440\u0440\u0435\u043a\u0442\u0438\u0440\u0443\u0435\u043c \u0438\u0442\u043e\u0433\u043e\u0432\u044b\u0439 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u0441 \u0443\u0447\u0435\u0442\u043e\u043c \u043b\u0443\u0447\u0448\u0435\u0439 \u043e\u0442\u0441\u0435\u0447\u043a\u0438\n                y_test_pred = (y_test_pred_probs[:,1] > self.threshold)\n                y_train_pred = (y_train_pred_probs[:,1] > self.threshold)\n                self.y_test_pred = y_test_pred\n                self.y_train_pred = y_train_pred\n            else:\n                y_train_pred = self.model.predict(self.X_train_full[self.cols])\n                y_test_pred = self.model.predict(self.X_test[self.cols])\n                y_train_pred = np.where(y_train_pred==0, False, True)\n                y_test_pred = np.where(y_test_pred==0, False, True)\n                \n            if CS_subs:\n                y_train_pred = pd.DataFrame(y_train_pred)\n                y_train_pred.iloc[self.X_train_full['Credit Score']>3000] = True\n                y_train_pred = np.array(y_train_pred[0])\n\n                y_test_pred = pd.DataFrame(y_test_pred)\n                y_test_pred.iloc[self.X_test['Credit Score']>3000] = True\n                y_test_pred = np.array(y_test_pred[0])\n                self.y_test_pred = y_test_pred\n                self.y_train_pred = y_train_pred \n            else:\n                y_train_pred = self.model.predict(self.X_train_full[self.cols])\n                y_test_pred = self.model.predict(self.X_test[self.cols])\n                self.y_test_pred = y_test_pred\n                self.y_train_pred = y_train_pred \n\n            self.total.loc[self.total.index.max()+1] = [self.model_name,\n                                                       'Default',\n                                                       self.cols,\n                                                       f1(self.y_train_full, y_train_pred, average='binary'),\n                                                       f1(self.y_test, y_test_pred, average='binary'),\n                                                       f1(self.y_train_full, y_train_pred, average='binary')-\\\n                                                       f1(self.y_test, y_test_pred, average='binary')]\n\n    def get_total(self):\n        if 0 in self.total.index:\n            self.total = self.total.drop([0])\n        return self.total.sort_values('F1 test', ascending=False)","d5112b91":"cb_cols = final_cols.copy()\n# cb_cols.remove('Current Loan Amount SUBS')\n# cb_cols.remove('Credit Score')\n# cb_cols.remove('CS2')","4abfe637":"cb_cols = ['Annual Income',\n 'Tax Liens',\n 'Number of Open Accounts',\n 'Years of Credit History',\n 'Maximum Open Credit',\n 'Number of Credit Problems',\n 'Months since last delinquent',\n 'Current Loan Amount',\n 'Current Credit Balance',\n 'Credit Score',\n 'Monthly Debt',\n 'Term MEAN Credit Default',\n 'Home Ownership MEAN Credit Default',\n 'Months since last delinquent CAT MEAN Credit Default',\n 'Years of Credit History CAT MEAN Credit Default',\n 'Current Loan Amount CAT MEAN Credit Default',\n 'Number of Credit Problems MEAN Credit Default'] + DUMMIES_COLS_CD","13c6ac6f":"cb_model = ModelSearch('CB', train, cb_cols, *TARGET, balance_mode=None, CS_data_sep=False)\ncb_model.create_model(best_feat=False, gr_features=None, gs=False, threshold_fit=True, topN=7, CS_subs=True)\ncb_model.get_total()","b20549ce":"importances = pd.DataFrame(zip(cb_cols, cb_model.model.feature_importances_)).\\\nrename(columns={0: \"Feature\", 1: 'Importance'}).sort_values(by='Importance', ascending=False)\nimportances","1a4ef30a":"short_columns = importances['Feature'][importances['Importance']>0].tolist()","a6cc6201":"#\u041f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438 \u0441 \u043c\u0435\u043d\u044c\u0448\u0438\u043c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e\u043c \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432\ncb_model = ModelSearch('CB', train, short_columns, *TARGET, balance_mode='smote', CS_data_sep=False)\ncb_model.create_model(best_feat=False, gr_features=None, gs=False, threshold_fit=True, topN=7, CS_subs=True)\ncb_model.get_total()","dd55583f":"#\u041f\u043e\u0434\u0431\u043e\u0440 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432\ncb_model = ModelSearch('CB', train, short_columns, *TARGET, balance_mode='smote', CS_data_sep=False)\ncb_model.create_model(best_feat=True, gr_features=[short_columns], gs=True, threshold_fit=True, topN=7,\n                      CS_subs=True, params = {'n_estimators':[30,31,32], 'max_depth':[2, 3]})\ncb_model.get_total()","dfe27d7b":"y_train_pred_probs = cb_model.model.predict_proba(cb_model.X_train_full[short_columns])\ny_test_pred_probs = cb_model.model.predict_proba(cb_model.X_test[short_columns])\nshow_proba_calibration_plots(y_train_pred_probs[:, 1], cb_model.y_train_full)\nshow_proba_calibration_plots(y_test_pred_probs[:, 1], cb_model.y_test)","49a1de5c":"get_classification_report(cb_model.y_train_full, cb_model.y_train_pred, cb_model.y_test, cb_model.y_test_pred)","ae433dd1":"#\u0423\u043c\u0435\u043d\u044c\u0448\u0435\u043d\u0438\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0439 \u0432 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430\u0445 \u043f\u043e \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0443 Annual Income.\nfor feature in CAT_COLS_AI:\n    train, test = categories_reducing(train, test, feature, 'Annual Income', 'mean')","0eed2991":"## \u0424\u0443\u043d\u043a\u0446\u0438\u0438 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c\u044b\u0435 \u0432 \u043d\u043e\u0443\u0442\u0431\u0443\u043a\u0435","00174d5e":"predictions = pd.DataFrame(predictions)\npredictions = predictions.astype(int)\npredictions.iloc[test['Credit Score']==1] = 1\npredictions = np.array(predictions[0])","44ee2a97":"\u041d\u0435 \u0443\u0432\u0438\u0434\u0435\u043b, \u0447\u0442\u043e \u0431\u044b\u043b\u0438 \u0432\u043e\u043f\u0440\u043e\u0441\u044b \u043a \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u043c\u0443 \u0432\u0435\u0431\u0438\u043d\u0430\u0440\u0443. \u0412\u044b\u043a\u043b\u0430\u0434\u044b\u0432\u0430\u044e \u043e\u0442\u0432\u0435\u0442\u044b \u0442\u0443\u0442.\n1. \u0412 \u0440\u0435\u0448\u0430\u044e\u0449\u0438\u0445 \u0434\u0435\u0440\u0435\u0432\u044c\u044f\u0445 \u043c\u044b \u043c\u043e\u0436\u0435\u043c \u0440\u0435\u0433\u0443\u043b\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0438\u043c\u0438 \u0441\u043f\u043e\u0441\u043e\u0431\u0430\u043c\u0438:\n - \u041e\u0433\u0440\u0430\u043d\u0438\u0447\u0438\u0442\u044c \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u0443\u044e \u0433\u043b\u0443\u0431\u0438\u043d\u0443 \u0434\u0435\u0440\u0435\u0432\u0430\n - \u0423\u0432\u0435\u043b\u0438\u0447\u0438\u0442\u044c \u043c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043b\u0438\u0441\u0442\u044c\u0435\u0432\n2. \u0412\u0430\u0436\u043d\u043e\u0441\u0442\u044c \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430 \u0432 \u0440\u0435\u0448\u0430\u044e\u0449\u0438\u0445 \u0434\u0435\u0440\u0435\u0432\u044c\u044f\u0445 \u043f\u043e \u0441\u0443\u0442\u0438 \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u0442 \u0441\u043e\u0431\u043e\u0439 \u0440\u0430\u0437\u043d\u0438\u0446\u0443 \u0432 \u043e\u0448\u0438\u0431\u043a\u0435 \u043f\u0440\u0438 \u043f\u043e\u0434\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0435 \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0445 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 \u0432 \u043c\u043e\u0434\u0435\u043b\u044c. \u0427\u0435\u043c \u0431\u043e\u043b\u044c\u0448\u0435 \u0440\u0430\u0437\u043d\u0438\u0446\u0430, \u0442\u0435\u043c \u0431\u043e\u043b\u044c\u0448\u0435 \u0437\u043d\u0430\u0447\u0438\u043c \u043f\u0440\u0438\u0437\u043d\u0430\u043a. \u041d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, \u0435\u0441\u043b\u0438 \u043c\u044b \u043f\u043e\u0434\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u043c \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430 \u0432 \u043c\u043e\u0434\u0435\u043b\u044c \u0438 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u043e\u0448\u0438\u0431\u043a\u0438 \u043c\u043e\u0434\u0435\u043b\u0438 \u0443\u0432\u0435\u043b\u0438\u0447\u0438\u0432\u0430\u0435\u0442\u0441\u044f - \u0437\u043d\u0430\u0447\u0438\u0442 \u043f\u0440\u0438\u0437\u043d\u0430\u043a \u0432\u0430\u0436\u043d\u044b\u0439. \u0415\u0441\u043b\u0438 \u043f\u043e\u0434\u0441\u0442\u0430\u0432\u044f\u0435\u043c \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u044b \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0438 \u043e\u0448\u0438\u0431\u043a\u0430 \u0438\u0437\u043c\u0435\u043d\u044f\u0435\u0442\u0441\u044f \u043d\u0435\u0437\u043d\u0430\u0447\u0438\u0442\u0435\u043b\u044c\u043d\u043e, \u0442\u043e \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0435\u043d\u043d\u043e \u0438 \u043f\u0440\u0438\u0437\u043d\u0430\u043a \u043d\u0435 \u0442\u0430\u043a \u0432\u0430\u0436\u0435\u043d.","93477cb8":"## EDA","1402c1fc":"## \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043d\u043e\u0432\u044b\u0445 \u0438 \u0443\u0434\u0430\u043b\u0435\u043d\u0438\u0435 \u043d\u0435\u043d\u0443\u0436\u043d\u044b\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432","7d6b68ed":"figsize = (6, 3)\nfor col in final_cols:\n    plt.figure(figsize=figsize)\n    sns.set(font_scale=0.8)\n    sns.kdeplot(train[col], shade=True, label='train[final_cols]', color='black')\n    sns.kdeplot(test[col], shade=True, label='test', color='white')\n    print(col)\n    print(mannwhitneyu(train[col], test[col]))\n    plt.legend()\n    plt.title(col)\n    plt.show()","c9ba6325":"## \u041f\u043e\u0438\u0441\u043a \u043d\u0430\u0438\u043b\u0443\u0447\u0448\u0435\u0439 \u043c\u043e\u0434\u0435\u043b\u0438","324b8e60":"end = time.time()\nduration = (end - start)\/60\nduration","cf31f2f1":"submit = pd.read_csv('sample_submission.csv')","77dc40ff":"### \u041f\u0440\u043e\u0433\u043d\u043e\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u043c \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0435","b199e099":"## Import","867aeee0":"## EDA","f3cb2739":"## \u0417\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432 \u0432 Annual Income c \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u043c\u043e\u0434\u0435\u043b\u0438","9bcd1da3":"## \u041e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430","c34befe2":"Home Ownership - \u0434\u043e\u043c\u043e\u0432\u043b\u0430\u0434\u0435\u043d\u0438\u0435\nAnnual Income - \u0433\u043e\u0434\u043e\u0432\u043e\u0439 \u0434\u043e\u0445\u043e\u0434\nYears in current job - \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043b\u0435\u0442 \u043d\u0430 \u0442\u0435\u043a\u0443\u0449\u0435\u043c \u043c\u0435\u0441\u0442\u0435 \u0440\u0430\u0431\u043e\u0442\u044b\nTax Liens - \u043d\u0430\u043b\u043e\u0433\u043e\u0432\u044b\u0435 \u043e\u0431\u0440\u0435\u043c\u0435\u043d\u0435\u043d\u0438\u044f\nNumber of Open Accounts - \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043e\u0442\u043a\u0440\u044b\u0442\u044b\u0445 \u0441\u0447\u0435\u0442\u043e\u0432\nYears of Credit History - \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043b\u0435\u0442 \u043a\u0440\u0435\u0434\u0438\u0442\u043d\u043e\u0439 \u0438\u0441\u0442\u043e\u0440\u0438\u0438\nMaximum Open Credit - \u043d\u0430\u0438\u0431\u043e\u043b\u044c\u0448\u0438\u0439 \u043e\u0442\u043a\u0440\u044b\u0442\u044b\u0439 \u043a\u0440\u0435\u0434\u0438\u0442\nNumber of Credit Problems - \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u0440\u043e\u0431\u043b\u0435\u043c \u0441 \u043a\u0440\u0435\u0434\u0438\u0442\u043e\u043c\nMonths since last delinquent - \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043c\u0435\u0441\u044f\u0446\u0435\u0432 \u0441 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0439 \u043f\u0440\u043e\u0441\u0440\u043e\u0447\u043a\u0438 \u043f\u043b\u0430\u0442\u0435\u0436\u0430\nBankruptcies - \u0431\u0430\u043d\u043a\u0440\u043e\u0442\u0441\u0442\u0432\u0430\nPurpose - \u0446\u0435\u043b\u044c \u043a\u0440\u0435\u0434\u0438\u0442\u0430\nTerm - \u0441\u0440\u043e\u043a \u043a\u0440\u0435\u0434\u0438\u0442\u0430\nCurrent Loan Amount - \u0442\u0435\u043a\u0443\u0449\u0430\u044f \u0441\u0443\u043c\u043c\u0430 \u043a\u0440\u0435\u0434\u0438\u0442\u0430\nCurrent Credit Balance - \u0442\u0435\u043a\u0443\u0449\u0438\u0439 \u043a\u0440\u0435\u0434\u0438\u0442\u043d\u044b\u0439 \u0431\u0430\u043b\u0430\u043d\u0441\nMonthly Debt - \u0435\u0436\u0435\u043c\u0435\u0441\u044f\u0447\u043d\u044b\u0439 \u0434\u043e\u043b\u0433\nCredit Score - \u0447\u0438\u0441\u043b\u043e \u043e\u0431\u043e\u0437\u043d\u0430\u0447\u0430\u044e\u0449\u0435\u0435 \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u044c \u0432\u044b\u043f\u043b\u0430\u0442\u044b \u043a\u0440\u0435\u0434\u0438\u0442\u043e\u0440\u043e\u043c \u0434\u043e\u043b\u0433\u0430\nCredit Default - \u0444\u0430\u043a\u0442 \u043d\u0435\u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u043a\u0440\u0435\u0434\u0438\u0442\u043d\u044b\u0445 \u043e\u0431\u044f\u0437\u0430\u0442\u0435\u043b\u044c\u0441\u0442\u0432 (0 - \u043f\u043e\u0433\u0430\u0448\u0435\u043d \u0432\u043e\u0432\u0440\u0435\u043c\u044f, 1 - \u043f\u0440\u043e\u0441\u0440\u043e\u0447\u043a\u0430)\n","2fd44870":"submit['Credit Default'] = predictions\nsubmit.to_csv('submit_rc40.csv', index=False)","a587d150":"datetime.datetime.now()","db5c6e05":"predictions = cb_model.model.predict_proba(test[short_columns])\npredictions = (predictions[:,1] > cb_model.threshold)"}}