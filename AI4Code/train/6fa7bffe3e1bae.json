{"cell_type":{"351e0672":"code","fcba3104":"code","a6f15028":"code","7471b81e":"code","1c841296":"code","bebbab27":"code","488573e3":"code","0d5e99ec":"code","79ce7a99":"code","35803e5a":"code","9b098de2":"code","ae9f98e2":"code","0c0f2a65":"code","ca4f300a":"code","68bdbb42":"code","c8750157":"code","dac41333":"code","967055d1":"code","df6e32d4":"code","ec0cac0e":"code","894ac1ac":"code","63d18e98":"code","92664674":"code","d25e6618":"code","594bc686":"code","0bb69416":"code","3d1afdc1":"code","964b033c":"code","0af62746":"code","1c2056cc":"code","960c707c":"code","5c9f5ba4":"code","3bd18837":"code","92c9f9cd":"code","1f8e239e":"code","5b0ea9b8":"markdown","b10f4dec":"markdown","70b5a315":"markdown","471f7daa":"markdown","6e53a5eb":"markdown","2855a704":"markdown","c951d3c3":"markdown","1db9d696":"markdown","14f496c2":"markdown","174ef8d1":"markdown","79a6c47e":"markdown","fd23539a":"markdown","b42b5c35":"markdown","c9525b02":"markdown","165bf02a":"markdown","cb46bd07":"markdown","6e048ffa":"markdown","7ca28108":"markdown","7ded6157":"markdown","94f3ac17":"markdown","79dddbb1":"markdown","a980832a":"markdown","3cb69115":"markdown","598074ee":"markdown","413f7e52":"markdown","0e4b0644":"markdown"},"source":{"351e0672":"#!pip install pygal_maps_world\n#import pygal\n#from pygal_maps_world.maps import World\n\n\nimport numpy as np # linear algebra\nfrom numpy import zeros\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBRegressor\nfrom sklearn.linear_model import LogisticRegression\n\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nfrom plotly import tools\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot","fcba3104":"data_ks = pd.read_csv(\"..\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv\")\ncountry_Code = pd.read_csv(\"..\/input\/countrycode\/country.csv\")","a6f15028":"data_ks.head()","7471b81e":"data_ks = data_ks.drop(0)","1c841296":"data_ks1 = data_ks.groupby(['Q3','Q1'])['Q1'].count()\ndata_ks1 = data_ks1.unstack()\ndata_ks1 = data_ks1.fillna(0)\ndata_ks1[\"sum\"] = data_ks1.sum(axis=1)\ndata_ks1 = data_ks1.sort_values(by=['sum'], ascending=False)","bebbab27":"data_ks1.columns","488573e3":"data_ks2 = data_ks1[['18-21', '22-24', '25-29', '30-34', '35-39', '40-44', '45-49', '50-54',\n       '55-59', '60-69', '70+']]\n\ndata_ks2 = data_ks2[:10]\ndata_ks2.plot(figsize=(20,20), kind='bar', stacked=True, title = 'Top 10 countries with Age Distribution')\nplt.show()","0d5e99ec":"data_ks1.head()","79ce7a99":"data_ks3 = data_ks1[['18-21', '22-24', '25-29', '30-34', '35-39', '40-44', '45-49', '50-54',\n       '55-59', '60-69', '70+']].div(data_ks1['sum'].values,axis=0)","35803e5a":"data_ks3.head()","9b098de2":"data_ks4 = data_ks3\nplt.figure(figsize = (16,16))\nax = sns.heatmap(data_ks4,annot=True)\nax.set_title('Age Percentage Distribution across multiple countries')","ae9f98e2":"data_ks4 = data_ks3[:15]\nplt.figure(figsize = (16,16))\nax = sns.heatmap(data_ks4,annot=True)\nax.set_title('Age Percentage Distribution across top 10 countries')","0c0f2a65":"print(data_ks1.index)","ca4f300a":"from numpy import array\n\ndata_ks5 = pd.DataFrame(data_ks1['sum'])\ndata5 = np.zeros(country_Code.shape[0])\n\nfor index, row in country_Code.iterrows():\n    for index1, row1 in data_ks5.iterrows():\n        if (index1 == row['Country']):\n            data5[index] = row1['sum']       \n            \ncountry_Code['Count'] = pd.Series(data5, index=country_Code.index)","68bdbb42":"#worldmap = World()\n\n#data_dict = country_Code[['Symbol','Count']].set_index('Symbol').to_dict()\n    \n# set the title of the map \n#worldmap.title = 'Countries'\n\n# adding the countries \n#worldmap.add('Engineer Count',data_dict['Count']) \n  \n# save into the file \n#worldmap.render_to_file('abc.svg')","c8750157":"country_Code","dac41333":"trace = go.Choropleth(\n            locations = country_Code['Country'],\n            locationmode='country names',\n            z = country_Code['Count'],\n            text = country_Code['Country'],\n            autocolorscale =False,\n            reversescale = True,\n            colorscale = 'rainbow',\n            marker = dict(\n                line = dict(\n                    color = 'rgb(0,0,0)',\n                    width = 0.5)\n            ),\n            colorbar = dict(\n                title = 'Responses from each country',\n                tickprefix = '')\n        )\n\ndata = [trace]\nlayout = go.Layout(\n    title = 'Repesenttaion of respondents in each country',\n    autosize=True,\n    width=1000,\n    height=1000,\n    geo = dict(\n        showframe = True,\n        showlakes = False,\n        showcoastlines = True,\n        projection = dict(\n            type = 'natural earth'\n        )\n    )\n)\n\nfig = dict( data=data, layout=layout )\niplot(fig)","967055d1":"data_ks1 = data_ks.groupby(['Q3','Q2'])['Q2'].count()\ndata_ks1 = data_ks1.unstack()\ndata_ks1 = data_ks1.fillna(0)\ndata_ks1[\"sum\"] = data_ks1.sum(axis=1)\ndata_ks1 = data_ks1.sort_values(by=['sum'], ascending=False)\ndata_ks1 = data_ks1[:15]","df6e32d4":"data_ks1.columns","ec0cac0e":"data_ks3 = data_ks1[['Man', 'Woman']].div(data_ks1['sum'].values,axis=0)","894ac1ac":"data_ks4 = data_ks3\ndata_ks4 = data_ks4.sort_values(by=['Woman'], ascending=False)\nplt.figure(figsize = (16,16))\nax = sns.heatmap(data_ks4,annot=True)\nax.set_title('Gender Percentage Distribution across multiple countries')","63d18e98":"data_ks1 = data_ks.groupby(['Q3','Q5'])['Q5'].count()\ndata_ks1 = data_ks1.unstack()\ndata_ks1 = data_ks1.fillna(0)\ncolumn_names = data_ks1.columns\ndata_ks1[\"sum\"] = data_ks1.sum(axis=1)\ndata_ks1 = data_ks1.sort_values(by=['sum'], ascending=False)\ndata_ks1 = data_ks1[:15]\ndata_ks3 = data_ks1[column_names].div(data_ks1['sum'].values,axis=0)","92664674":"plt.figure(figsize = (16,16))\nax = sns.heatmap(data_ks3,annot=True)\nax.set_title('Highest Education Percentage Distribution across top 10 countries')","d25e6618":"data_ks5 = data_ks\ndata_ks5['Q6'] = data_ks5['Q6'].replace(['5-10 years', '10-20 years', '3-5 years', '< 1 years', '1-2 years',\n       '20+ years'],['10','20','05','01','02','20+'])\ndata_ks5['Q15'] = data_ks5['Q15'].replace(['1-2 years', 'I do not use machine learning methods', '3-4 years',\n       'Under 1 year', '2-3 years', '4-5 years', '5-10 years',\n       '20 or more years', '10-20 years'],['02','00','04','01','03','05','10','20+','20'])\n\ndetails_World = data_ks5[(data_ks['Q5'] != 'Currently not employed')][['Q3','Q5','Q6','Q15']].dropna()\ndetails_US = data_ks5[((data_ks['Q5'] != 'Currently not employed') & (data_ks['Q3'] == 'United States of America'))][['Q3','Q5','Q6','Q15']].dropna()\ndetails_Ind = data_ks5[((data_ks['Q5'] != 'Currently not employed') & (data_ks['Q3'] == 'India'))][['Q3','Q5','Q6','Q15']].dropna()\n\nprofession = details_World.groupby('Q5').sum().index.values\ncode_exp = details_World.groupby('Q6').sum().index.values\nmachine_exp = details_World.groupby('Q15').sum().index.values","594bc686":"data_ks['Q15'].unique()","0bb69416":"details_Ind","3d1afdc1":"details_i = details_Ind[(details_Ind['Q5'] == 'Student')]\n\ndetails_i=details_i.sort_values(by=['Q6','Q15']).groupby(['Q6','Q15']).count()\ndetails_i=details_i.reset_index().pivot('Q6','Q15','Q5').fillna(0).astype('int')\ndetails_i.head()\nsns.color_palette(\"cubehelix\")\nax = sns.heatmap(details_i)\n","964b033c":"details_i = details_US[(details_US['Q5'] == 'Student')]\n\ndetails_i=details_i.sort_values(by=['Q6','Q15']).groupby(['Q6','Q15']).count()\ndetails_i=details_i.reset_index().pivot('Q6','Q15','Q5').fillna(0).astype('int')\ndetails_i.head()\nsns.color_palette(\"cubehelix\")\nax = sns.heatmap(details_i)","0af62746":"fig, ax = plt.subplots(len(profession),3, figsize=(18,20), dpi=100)\ni = 0\n\ndetails_type = details_World[(details_World['Q5'] == 'Business Analyst')]\ndetails_type = details_type.sort_values(by=['Q6','Q15']).groupby(['Q6','Q15']).count()\ndetails_type = details_type.reset_index().pivot('Q6','Q15','Q5').fillna(0).astype('int')\n\nfig.suptitle('World                                               US                                               India', fontsize=20)\n\n#ax[0][0].set_title(str(\"World\"), rotation=0)\n#ax[0][1].set_title(str(\"US\"), rotation=0)\n#ax[0][2].set_title(str(\"India\"), rotation=0)\n        \nfor prof in profession:\n    details_iWorld = details_World[(details_World['Q5'] == prof)]\n    details_iWorld=details_iWorld.sort_values(by=['Q6','Q15']).groupby(['Q6','Q15']).count()\n    details_iWorld=details_iWorld.reset_index().pivot('Q6','Q15','Q5').fillna(0).astype('int')\n    \n    details_iUS = details_US[(details_US['Q5'] == prof)]\n    details_iUS=details_iUS.sort_values(by=['Q6','Q15']).groupby(['Q6','Q15']).count()\n    details_iUS=details_iUS.reset_index().pivot('Q6','Q15','Q5').fillna(0).astype('int')\n\n    details_iInd = details_Ind[(details_Ind['Q5'] == prof)]\n    details_iInd=details_iInd.sort_values(by=['Q6','Q15']).groupby(['Q6','Q15']).count()\n    details_iInd=details_iInd.reset_index().pivot('Q6','Q15','Q5').fillna(0).astype('int')\n\n    \n    ax[i][0].matshow(details_iWorld, cmap='GnBu')\n    ax[i][0].set_xticks(np.arange(len(details_type.columns)))\n    ax[i][0].set_yticks(np.arange(len(details_type.index)))\n    ax[i][0].grid(False)\n    ax[i][0].set_title(prof, y=-0.1, rotation=0)\n\n\n    ax[i][1].matshow(details_iUS, cmap='GnBu')\n    ax[i][1].set_xticks(np.arange(len(details_type.columns)))\n    ax[i][1].set_yticks(np.arange(len(details_type.index)))\n    ax[i][1].grid(False)\n    \n   \n    ax[i][2].matshow(details_iInd, cmap='GnBu')\n    ax[i][2].set_xticks(np.arange(len(details_type.columns)))\n    ax[i][2].set_yticks(np.arange(len(details_type.index)))\n    ax[i][2].grid(False)\n    \n    ax[i][0].set_xticklabels([])\n    ax[i][0].set_yticklabels(details_type.index)\n\n    if i == 0:\n        ax[i][0].set_xticklabels(details_type.columns, rotation=90)\n        ax[i][1].set_xticklabels(details_type.columns, rotation=90)\n        ax[i][1].set_yticklabels([])\n        ax[i][2].set_xticklabels(details_type.columns, rotation=90)\n        ax[i][2].set_yticklabels([])\n\n    else:\n        ax[i][1].set_xticklabels([])\n        ax[i][1].set_yticklabels([])\n        ax[i][2].set_xticklabels([])\n        ax[i][2].set_yticklabels([])\n\n    i= i + 1\n    \nplt.savefig('ProfileCompare.png')\nplt.show()  \n    \n","1c2056cc":"data_ks6 = data_ks\n\n\ndata_ks6['Q20'] = data_ks6['Q20'].replace(['10,000 or more employees', '1000-9,999 employees',\n       '250-999 employees', '0-49 employees', '50-249 employees'],['10K+','10K','01K','00050','00250'])\ndata_ks5['Q21'] = data_ks5['Q21'].replace(['20+', '0', '5-9', '1-2', '3-4', '10-14', '15-19'],['20+','00','09','02','04','14','19'])\n\ndetails_World = data_ks5[(data_ks['Q5'] != 'Currently not employed')][['Q3','Q5','Q20','Q21']].dropna()\ndetails_US = data_ks5[((data_ks['Q5'] != 'Currently not employed') & (data_ks['Q3'] == 'United States of America'))][['Q3','Q5','Q20','Q21']].dropna()\ndetails_Ind = data_ks5[((data_ks['Q5'] != 'Currently not employed') & (data_ks['Q3'] == 'India'))][['Q3','Q5','Q20','Q21']].dropna()\n\nprofession = details_World.groupby('Q5').sum().index.values","960c707c":"fig, ax = plt.subplots(len(profession),3, figsize=(18,20), dpi=100)\ni = 0\n\ndetails_type = details_World[(details_World['Q5'] == 'Business Analyst')]\ndetails_type = details_type.sort_values(by=['Q20','Q21']).groupby(['Q20','Q21']).count()\ndetails_type = details_type.reset_index().pivot('Q20','Q21','Q5').fillna(0).astype('int')\n\nfig.suptitle('World                                               US                                               India', fontsize=20)\n\n#ax[0][0].set_title(str(\"World\"), rotation=0)\n#ax[0][1].set_title(str(\"US\"), rotation=0)\n#ax[0][2].set_title(str(\"India\"), rotation=0)\n        \nfor prof in profession:\n    details_iWorld = details_World[(details_World['Q5'] == prof)]\n    details_iWorld=details_iWorld.sort_values(by=['Q20','Q21']).groupby(['Q20','Q21']).count()\n    details_iWorld=details_iWorld.reset_index().pivot('Q20','Q21','Q5').fillna(0).astype('int')\n    \n    details_iUS = details_US[(details_US['Q5'] == prof)]\n    details_iUS=details_iUS.sort_values(by=['Q20','Q21']).groupby(['Q20','Q21']).count()\n    details_iUS=details_iUS.reset_index().pivot('Q20','Q21','Q5').fillna(0).astype('int')\n\n    details_iInd = details_Ind[(details_Ind['Q5'] == prof)]\n    details_iInd=details_iInd.sort_values(by=['Q20','Q21']).groupby(['Q20','Q21']).count()\n    details_iInd=details_iInd.reset_index().pivot('Q20','Q21','Q5').fillna(0).astype('int')\n\n    \n    ax[i][0].matshow(details_iWorld, cmap='GnBu')\n    ax[i][0].set_xticks(np.arange(len(details_type.columns)))\n    ax[i][0].set_yticks(np.arange(len(details_type.index)))\n    ax[i][0].grid(False)\n    ax[i][0].set_title(prof, y=-0.1, rotation=0)\n\n\n    ax[i][1].matshow(details_iUS, cmap='GnBu')\n    ax[i][1].set_xticks(np.arange(len(details_type.columns)))\n    ax[i][1].set_yticks(np.arange(len(details_type.index)))\n    ax[i][1].grid(False)\n    \n   \n    ax[i][2].matshow(details_iInd, cmap='GnBu')\n    ax[i][2].set_xticks(np.arange(len(details_type.columns)))\n    ax[i][2].set_yticks(np.arange(len(details_type.index)))\n    ax[i][2].grid(False)\n    \n    ax[i][0].set_xticklabels([])\n    ax[i][0].set_yticklabels(details_type.index)\n\n    if i == 0:\n        ax[i][0].set_xticklabels(details_type.columns, rotation=90)\n        ax[i][1].set_xticklabels(details_type.columns, rotation=90)\n        ax[i][1].set_yticklabels([])\n        ax[i][2].set_xticklabels(details_type.columns, rotation=90)\n        ax[i][2].set_yticklabels([])\n\n    else:\n        ax[i][1].set_xticklabels([])\n        ax[i][1].set_yticklabels([])\n        ax[i][2].set_xticklabels([])\n        ax[i][2].set_yticklabels([])\n\n    i= i + 1\n    \nplt.savefig('CompanyCompare.png')\nplt.show()  \n    ","5c9f5ba4":"details_World.head()","3bd18837":"import pandas as pd\nimport plotly.express as px\n\ndata_ks6 = data_ks4.reset_index()\n\nxmin, xmax = min(data_ks6.Man), max(data_ks6.Man)\nymin, ymax = min(data_ks6.Woman), max(data_ks6.Woman)\n\nfig = px.scatter(data_ks6, x=\"Man\", y=\"Woman\", color=\"Q3\", hover_name=\"Q3\",facet_col=\"Q3\", width=3000, height=400, log_x=True, size_max=45,range_x=[xmin,xmax], range_y=[ymin,ymax])\n\nfig.show()","92c9f9cd":"data_ks3 = data_ks1.reset_index()\n\ndata_ks3['sum_niche'] =  data_ks3['Data Scientist'] + data_ks3['Research Scientist'] + data_ks3['Statistician']","1f8e239e":"xmin, xmax = min(data_ks3[\"sum\"]), max(data_ks3[\"sum\"])\n\nymin, ymax = min(data_ks3[\"sum_niche\"]), max(data_ks3[\"sum_niche\"])\n\nfig = px.scatter(data_ks3, x=\"sum\", y=\"sum_niche\", color=\"Q3\", hover_name=\"Q3\",facet_col=\"Q3\", width=3000, height=400, log_x=True, size_max=45,range_x=[xmin,xmax], range_y=[ymin,ymax])\n\nfig.show()","5b0ea9b8":"# Import Libraries","b10f4dec":"References:\n\nhttps:\/\/www.kaggle.com\/uyangas\/becoming-a-data-scientist\n\nhttps:\/\/www.kaggle.com\/gpreda\/data-scientists-in-2020-kaggle-survey\n","70b5a315":"# Grouping data by age and country","471f7daa":"# Grouping by Highest education and country","6e53a5eb":"# US Student Profile","2855a704":"This method of representation I got from Gabriel Preda (gpreda)\n\nLink to his notebook:\nhttps:\/\/www.kaggle.com\/gpreda\/data-scientists-in-2020-kaggle-survey\n","c951d3c3":"# Age Distribution across multiple countries","1db9d696":"It is clear that in US in each designation the engineers carry higher experience in both Coding experience and Machine Learning experience","14f496c2":"# Y axis is Size of Company and X axis is Size of Team","174ef8d1":"# India Student Profile","79a6c47e":"India clearly has taken the lead. Both in the number of engineers as well as the number of engineers at lower age band. This would help ensure that in the future there are more experience ML engineers in India ","fd23539a":"Data screened for US and India and ignoring 'currently not employed' people","b42b5c35":"# Drop first row which is just the questions","c9525b02":"# Comparing Engineer profile between World, US and India","165bf02a":"# Countries having higher percetage of Woman Data Experts ","cb46bd07":"# Load Data and review","6e048ffa":"# Age Percentage Distribution across multiple countries","7ca28108":"In US the student population has higher programming knowledge. \nThey have on an average 5-10 years of programming knowledge and 3 years of machine learning knowledge\n\n* This shows that profiles of people vary from country to country.\n* More advanaced countries will have people in each profile with higher experience","7ded6157":"# Analysing India and US data based on Companies","94f3ac17":"# Grouping by gender and country","79dddbb1":"# Countries with Higher percentage of Niche profiles","a980832a":"If you look Datat Scientist, ML engineers and Statiticians in US work for large companies but in India such people work for smaller startup companies. In India large IT companies are primarily IT outsourcing companies which work with US clients and help deploy ML solutions with lesser experienced Data Science engineers who do more depolyment and customization and less work on developing new algorithm. The Datat Scientist, ML engineers and Statiticians in India are primarily work in startups where they are trying to build breakthrough products.","3cb69115":"In India the student population is new to programming. \nThey have on an average 2 - 5 years of programming knowledge and 1-2 years of machine learning knowledge","598074ee":"# Analysing India and US data for Years of Experience","413f7e52":"# Distribution representation Country wise","0e4b0644":"# Y axis is Coding experience and X axis is Machine Learning Experience"}}