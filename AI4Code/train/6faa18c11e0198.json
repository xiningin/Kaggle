{"cell_type":{"863d6129":"code","20a3a634":"code","15e35134":"code","dce05a47":"code","afa542ec":"code","c1addfa0":"code","3449fbe3":"code","361ee0bd":"code","0fafeb0c":"code","076d2306":"code","2352e56b":"code","764645cc":"code","39ad30f8":"code","0381d712":"code","5d0bcb36":"code","69b5c05e":"code","ee6e5921":"code","196ce061":"code","07db6ace":"code","24a3b1a9":"code","0a6cfe5d":"markdown"},"source":{"863d6129":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport copy","20a3a634":"#load dataset\nx = np.load(\"..\/input\/digit-signs\/X.npy\")\ny = np.load(\"..\/input\/digit-signs\/Y.npy\")\n\n\n","15e35134":"print(x.shape)\nprint(y.shape)","dce05a47":"#show sample image\nplt.subplot(1,2,1)\nplt.imshow(x[260])\nplt.axis(\"off\")\nplt.subplot(1,2,2)\nplt.imshow(x[900])\n\nplt.axis(\"off\")\nplt.show()","afa542ec":"#we need train for one and zero sign \n# zero sign starts from index 204 : 409 so total is 205\n# one sign starts from 822 : 1027 so total is 205\n\nX = np.concatenate((x[204:409] , x[822:1027]) , axis = 0)\n\nz = np.zeros(205)\no = np.ones(205)\nY = np.concatenate((z,o) , axis = 0).reshape(X.shape[0] , 1)\n\nprint(X.shape)\nprint(Y.shape)","c1addfa0":"#lets create x_train , y_train , x_test,y_test\nfrom sklearn.model_selection import train_test_split\n#test_size means 85% for training and 15% for testing\n#random_state keep same training and testing data \nx_train , x_test ,y_train,y_test = train_test_split(X,Y,test_size = 0.15 , random_state = 42)\nn_train = x_train.shape[0]\nn_test =  x_test.shape[0]","3449fbe3":"print(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","361ee0bd":"#we need shape of x to be 2d array so we reshape it to (number of examples , number of pixles for one pic).T\nx_train = x_train.reshape(n_train , x_train.shape[1]*x_train.shape[2]).T\nx_test = x_test.reshape(n_test , x_test.shape[1]*x_test.shape[2]).T\ny_train = y_train.T\ny_test = y_test.T\n","0fafeb0c":"print(\"x_train :\" , x_train.shape)\nprint( \"y_train : \",y_train.shape)\nprint( \"x_test : \", x_test.shape)\nprint(\"y_test : \",y_test.shape)","076d2306":"def initialize_parameters(n_x):\n    w = np.full((n_x , 1) , 0.01)\n    b = 0.0\n    return w , b","2352e56b":"def sigmoid(z):\n    return 1 \/ (1+np.exp(-z))","764645cc":"#test sigmoid\nsigmoid(0)","39ad30f8":"def forward_propagation(x,y , w , b):\n    z = np.dot(w.T , x)+b\n    y_hat = sigmoid(z)\n    loss = y*np.log(y_hat)+(1-y)*np.log(1-y_hat)\n    cost = -np.sum(loss)\/x.shape[1]\n    return y_hat,cost","0381d712":"def backward_propagation(x , y, y_hat):\n    \n    error = y_hat - y\n    dw =np.dot(x , error.T)\/x.shape[1]\n    db = np.sum(error , axis = 1)\/x.shape[1]\n    \n    return dw , db\n    ","5d0bcb36":"def update(x , y , num_iters = 3000 , learning_rate = 0.001 , print_cost = False):\n    \n    w,b = initialize_parameters(x.shape[0])\n    costs = []\n    \n    for i in range(num_iters):\n        \n        y_hat , cost = forward_propagation(x,y,w,b)\n        dw , db = backward_propagation(x , y,y_hat)\n        \n        w = w - learning_rate * dw\n        b = b - learning_rate*db\n        \n        \n        if print_cost and i%100 == 0 or i == num_iters-1:\n            print(\"cost of iters %d equal %f\" %(i , cost) )\n        \n        if i%10 == 0:\n            costs.append(cost)\n    \n    parameters = {\"w\" : w , \"b\" : b}\n    grads = {\"dw\":dw , \"db\":db}\n    \n    return parameters , grads , costs\n","69b5c05e":"def predict(x,w,b):\n    \n    y_prediction = sigmoid(np.dot(w.T , x) + b)\n    \n    y_prediction[y_prediction > 0.5] = 1\n    y_prediction[y_prediction <= 0.5] = 0\n    \n    return y_prediction\n    \n    ","ee6e5921":"def logestic_regression(x_train , y_train , x_test , y_test , num_iters = 300 , learning_rate = 0.01 , print_cost = False):\n    \n    pars , grads , costs = update(x_train , y_train , num_iters ,learning_rate , print_cost)\n    \n    plt.plot(costs)\n    \n    y_prediction_test = predict(x_test , pars[\"w\"],pars[\"b\"])\n    y_prediction_train = predict(x_train , pars[\"w\"],pars[\"b\"])\n    \n    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_train - y_train)) * 100))\n    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_test - y_test)) * 100))\n    \n    return pars\n    ","196ce061":"pars = logestic_regression(x_train , y_train , x_test , y_test , num_iters = 3000 , learning_rate = 0.01 , print_cost = True)","07db6ace":"plt.imshow(X[250])\n","24a3b1a9":"k = X[250]\nprint(\"image is : \" , np.squeeze(predict(k.reshape(64*64 , 1) ,pars[\"w\"] , pars[\"b\"])))","0a6cfe5d":"# first using simple logestic regression"}}