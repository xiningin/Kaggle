{"cell_type":{"d7454f9e":"code","5e7a175a":"code","9dde76c2":"code","5b74ec6c":"code","84257988":"code","be928d90":"code","688944e2":"code","7ca352b5":"code","9cc97e43":"code","aeac3ab1":"code","434ffc72":"code","d33ee7a5":"markdown","05de896a":"markdown","986d1fc1":"markdown","c513637d":"markdown","8cdc5043":"markdown","63a1ae93":"markdown"},"source":{"d7454f9e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5e7a175a":"!pip install praw\nimport praw","9dde76c2":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"my_client_id\")\nsecret_value_1 = user_secrets.get_secret(\"my_client_secret\")\nsecret_value_2 = user_secrets.get_secret(\"my_user_agent\")","5b74ec6c":"reddit = praw.Reddit(client_id= secret_value_0, client_secret= secret_value_1, user_agent= secret_value_2)","84257988":"hot_posts = reddit.subreddit('olympics').hot(limit=10)\nfor post in hot_posts:\n    print(post.title)","be928d90":"hot_posts = reddit.subreddit('all').hot(limit=10)\nfor post in hot_posts:\n    print(post.title)","688944e2":"import pandas as pd\nposts = []\nml_subreddit = reddit.subreddit('olympics')\nfor post in ml_subreddit.hot(limit=10):\n    posts.append([post.title, post.score, post.id, post.subreddit, post.url, post.num_comments, post.selftext, post.created])\nposts = pd.DataFrame(posts,columns=['title', 'score', 'id', 'subreddit', 'url', 'num_comments', 'body', 'created'])\nprint(posts)","7ca352b5":"# get CryptoCurrency subreddit data\nCC_subreddit = reddit.subreddit('olympics')\n\nprint(CC_subreddit.description)","9cc97e43":"submission = reddit.submission(url=\"https:\/\/www.reddit.com\/r\/olympics\/comments\/p4fdmn\/australian_swimmer_emma_mckeon_became_the_second\/?utm_source=share&utm_medium=web2x&context=3\")","aeac3ab1":"from praw.models import MoreComments\nfor top_level_comment in submission.comments:\n    if isinstance(top_level_comment, MoreComments):\n        continue\n    print(top_level_comment.body)","434ffc72":"posts.to_csv('mycsvfile.csv',index=False)","d33ee7a5":"install and import PRAW to scrape a subreddit","05de896a":"i have saved my credentials using secrets, please refer to the following link to get your own credentials","986d1fc1":"## To get the hottest posts on reddit","c513637d":"You can get your client_id, client_secret, and, user_agent by referring to: https:\/\/praw.readthedocs.io\/en\/latest\/getting_started\/quick_start.html","8cdc5043":"The following code gets the top 10 hottest posts, you get more posts by increasing the limit","63a1ae93":"### I have used the example of the subreddit \"olympics\""}}