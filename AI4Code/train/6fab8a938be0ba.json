{"cell_type":{"56b44a93":"code","67b0257e":"code","f0f3b735":"code","d4ccc709":"code","f41f32be":"code","45e203d9":"code","707abe16":"code","26216f9a":"code","f50957b6":"code","574372ae":"code","279e4e51":"code","9ce2cd80":"code","b64ece7a":"code","e9fec6e5":"code","e9fc5410":"code","e3e59c84":"code","a7ba2586":"markdown","fc262f8a":"markdown","2a1bc8e7":"markdown","23a3cbc4":"markdown","55d5b7ed":"markdown"},"source":{"56b44a93":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten, BatchNormalization, MaxPool2D, Dropout\nfrom keras.callbacks import ModelCheckpoint\n\nfrom sklearn.model_selection import cross_val_score, train_test_split, cross_validate","67b0257e":"trainData = pd.read_csv(\"..\/input\/images\/train.csv\")\nevalData = pd.read_csv(\"..\/input\/images\/eval.csv\")\n\nprint(trainData.head())\nprint(evalData.head())","f0f3b735":"# Labels\nlabels = {0: \"T-shirt\/top\", 1: \"Trouser\", 2: \"Pullover\", 3: \"Dress\", 4: \"Coat\", 5: \"Sandal\", 6: \"Shirt\", 7: \"Sneaker\", 8: \"Bag\", 9: \"Ankle boot\"}","d4ccc709":"for col in trainData.columns:\n    if (col in [\"id\", \"label\"]):\n        continue\n    trainData[col] = trainData[col] \/ 255.0\nfor col in evalData.columns:\n    if (col in [\"id\", \"label\"]):\n        continue\n    evalData[col] = evalData[col] \/ 255.0\nprint(trainData[:3])","f41f32be":"# Show the images\nnum = 20\ndef getImageArray(imageNumber, data = trainData):\n    image = data.iloc[imageNumber]\n    imgArr = []\n    \n    for i in range(28):\n        temp = []\n        for j in range(28):\n            pix = i * 28 + j + 1\n            temp.append(image[\"pixel\" + str(pix)])\n        imgArr.append(temp)\n    return(imgArr)\n\ns = 4\nfig, axs = plt.subplots(s, s)\nfor i in range(s):\n    for j in range(s):\n        index = i * s + j\n        axs[i][j].imshow(getImageArray(index))\n        axs[i][j].set_title(labels[trainData.iloc[index][\"label\"]])\nplt.subplots_adjust(hspace = 1)\nplt.show()","45e203d9":"categories = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\nohe_labels = np.zeros((len(trainData['label']), 10))\nprint(ohe_labels.shape)\nfor ii in range(len(ohe_labels)):\n    jj = np.where(categories == trainData['label'][ii])\n    ohe_labels[ii, jj] = 1","707abe16":"X = []\nfor i in range(len(trainData)):\n    X.append(np.array(getImageArray(i)).reshape(28, 28, 1))\n    if (i != 0 and len(trainData) % i == 6000):\n        print(\"-\", end = \"\")\nprint()\ny = ohe_labels\nX = np.array(X)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 8)","26216f9a":"checkpoint = ModelCheckpoint(\"weights.hdf5\", monitor = \"val_loss\", save_best_only = True)\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","f50957b6":"model = Sequential()\nmodel.add(Conv2D(15, kernel_size = 3, activation = \"relu\", input_shape = (28, 28, 1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(12, kernel_size = 2, activation = \"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(10, kernel_size = 2, activation = \"relu\"))\nmodel.add(Flatten())\nmodel.add(Dense(10, activation = \"softmax\"))\n","574372ae":"model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\ntraining = model.fit(X_train, y_train, validation_split = 0.2, epochs = 25, callbacks = [checkpoint])\nplt.show()","279e4e51":"plt.plot(training.history[\"loss\"], c = \"r\", label = \"loss\")\nplt.plot(training.history[\"val_loss\"], c = \"b\", label = \"val_loss\")\nplt.plot(training.history[\"accuracy\"], c = \"g\", label = \"accuracy\")\nplt.plot(training.history[\"val_accuracy\"], c = \"y\", label = \"val_accuracy\")\nplt.legend()\nplt.show()","9ce2cd80":"bestModel = Sequential()\nbestModel.add(Conv2D(15, kernel_size = 3, activation = \"relu\", input_shape = (28, 28, 1)))\nbestModel.add(BatchNormalization())\nbestModel.add(Conv2D(12, kernel_size = 2, activation = \"relu\"))\nbestModel.add(BatchNormalization())\nbestModel.add(Conv2D(10, kernel_size = 2, activation = \"relu\"))\nbestModel.add(Flatten())\nbestModel.add(Dense(10, activation = \"softmax\"))\nbestModel.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\nbestModel.load_weights(\"weights.hdf5\")","b64ece7a":"print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)","e9fec6e5":"model.evaluate(X_train, y_train)\nmodel.evaluate(X_test, y_test)\nprint()\nbestModel.evaluate(X_train, y_train)\nbestModel.evaluate(X_test, y_test)","e9fc5410":"testData = []\nfor i in range(len(evalData)):\n    testData.append(np.array(getImageArray(i, evalData)).reshape(28, 28, 1))\nprint()","e3e59c84":"pred = bestModel.predict(np.array(testData)).round(2)\nfixedPred = np.argmax(pred, axis = 1)\n\noutput = pd.DataFrame({'id': evalData[\"id\"], \"label\": fixedPred})\noutput.to_csv('submission.csv', index = False)\nprint(\"Your submission was successfully saved!\")\nprint(output.to_string())","a7ba2586":"### Submission creation","fc262f8a":"# Assignment 4\n## Dalton Kajander","2a1bc8e7":"### Evaluating and cleaning data","23a3cbc4":"### Importing modules and data","55d5b7ed":"### Model creation"}}