{"cell_type":{"4707045b":"code","72af02d8":"code","b09d1ce8":"code","b8b88991":"code","a081ba71":"code","d0f0dbf5":"code","5b757f1a":"code","ad435794":"code","30d99875":"code","232549d7":"code","e55bffdd":"code","1376cca8":"code","3dbdd508":"code","9be76f77":"code","aa6cb804":"code","1c52e8f4":"code","36ebac75":"code","0efb3bad":"code","111582ae":"code","a64263af":"code","0c09c08d":"code","4059c0de":"code","8e9fa342":"code","4e6568cf":"code","c507956d":"code","3a4f84eb":"code","af09a8bc":"code","998288ec":"code","74a595a2":"code","9441169a":"code","b8ec7c92":"code","b9ed9201":"code","3e1da028":"code","7c64369c":"markdown","5b4a118c":"markdown","460847ab":"markdown","6890010a":"markdown","8e044620":"markdown","8600ccbc":"markdown","8d3dc656":"markdown","0a5d023c":"markdown","d94ae791":"markdown","8bb1debb":"markdown","9708cd01":"markdown","88707540":"markdown","c58ed168":"markdown","b1c061e4":"markdown","c8c30448":"markdown","bbcbc42b":"markdown"},"source":{"4707045b":"#Librerias\nimport numpy as np\nfrom pathlib import Path\nfrom PIL import Image\nimport util_func as fc\nimport time\n\n#Librer\u00edas de PyTorch\nimport torch  #PyTorch library\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn #Neural networks library\nimport torch.nn.functional as F\n\n#Librerias utiles para plotear\nimport matplotlib.pyplot as plt\n%matplotlib inline \n#plots in the line below the code, inside the notebook \n\n#Nombre del proyecto\nproject_name = 'Deteccion de nubes'","72af02d8":"total_list = fc.data_split('..\/input\/95cloud-cloud-segmentation-on-satellite-images\/95-cloud_training_only_additional_to38-cloud\/train_red_additional_to38cloud', 15000, 5000)\nlen(total_list)","b09d1ce8":"#Cargo la direccion de la carpeta que contiene todos los canales en una variable, como objeto 'Path'\npath_ppal = Path('..\/input\/95cloud-cloud-segmentation-on-satellite-images\/95-cloud_training_only_additional_to38-cloud')","b8b88991":"#Cargo el dataset de entrenamiento, es el primer objeto de la lista total_lista\ntrain_dataset = fc.CloudDataset(path_ppal\/'train_red_additional_to38cloud', \n                    path_ppal\/'train_green_additional_to38cloud', \n                    path_ppal\/'train_blue_additional_to38cloud', \n                    path_ppal\/'train_nir_additional_to38cloud',\n                    path_ppal\/'train_gt_additional_to38cloud',\n                    total_list[0])\nlen(train_dataset)","a081ba71":"#Cargo el dataset de validaci\u00f3n, es el segundo objeto de la lista total_list\nval_dataset = fc.CloudDataset(path_ppal\/'train_red_additional_to38cloud', \n                    path_ppal\/'train_green_additional_to38cloud', \n                    path_ppal\/'train_blue_additional_to38cloud', \n                    path_ppal\/'train_nir_additional_to38cloud',\n                    path_ppal\/'train_gt_additional_to38cloud',\n                    total_list[1])\nlen(val_dataset)","d0f0dbf5":"#Cargo el dataset de validaci\u00f3n, es el tercer objeto de la lista total_list\ntest_dataset = fc.CloudDataset(path_ppal\/'train_red_additional_to38cloud', \n                    path_ppal\/'train_green_additional_to38cloud', \n                    path_ppal\/'train_blue_additional_to38cloud', \n                    path_ppal\/'train_nir_additional_to38cloud',\n                    path_ppal\/'train_gt_additional_to38cloud',\n                    total_list[2])\nlen(test_dataset)","5b757f1a":"batch_size = 6","ad435794":"train_dl = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=4, pin_memory=True)\nval_dl = DataLoader(val_dataset, batch_size*2, shuffle=True, num_workers=4, pin_memory=True)","30d99875":"torch.cuda.is_available() #Detecta si hay un GPU disponible","232549d7":"#Elige un GPU si hay uno disponible. Si no, elige un CPU.\ndevice = fc.get_default_device()\ndevice","e55bffdd":"def to_device(data, device):\n    \"\"\"Mueve tensor(es) al dispositivo (CPU O GPU) elegido\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Cantidad de batches o lotes\"\"\"\n        return len(self.dl)","1376cca8":"#Cargo los datos con un Dataloader en el dispositivo correspondiente\ntrain_loader = DeviceDataLoader(train_dl, device)\nval_loader = DeviceDataLoader(val_dl, device)","3dbdd508":"#The accuracy we will define our own, that will be basically \n#the number of matched pixels (mask == prediction) divided by the total number of pixels in a batch\ndef accuracy(predb, yb):\n    return (predb.argmax(dim=1) == yb).float().mean()\n\nclass ImageClassificationBase(nn.Module):\n    \n    def training_step(self, batch):\n        loss_fn = nn.CrossEntropyLoss()\n        images, masks = batch \n        #input, targets Carga un lote de datos, cada imagen con su respectiva m\u00e1scara de nubes\n        out = self(images)     # output Genera las predicciones\n        loss = loss_fn(out, masks) # Calcula las perdidas para cada prediccion (diferencia entre predicci\u00f3n y mascara)        \n        return loss\n    \n    def validation_step(self, batch):\n        loss_fn = nn.CrossEntropyLoss()\n        images, masks = batch      # Carga un lote de datos, cada imagen con su respectiva m\u00e1scara\n        out = self(images)          # Generate predictions\n        loss = loss_fn(out, masks.long()) # Calculate loss\n        acc = accuracy(out, masks) # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs] # Lista de las perdidas de cada batch\n        epoch_loss = torch.stack(batch_losses).mean()   # Junta las losses de todos los lotes\n        batch_accs = [x['val_acc'] for x in outputs]    # Lista de las exctitudes de cada batch\n        epoch_acc = torch.stack(batch_accs).mean()      # Junta las accuracies de todos los lotes\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result): #Imprime los resultados al terminar de correr cada epoch\n        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))","9be76f77":"class SimpleCNN(ImageClassificationBase):\n    \n    def __init__(self):\n        super().__init__() \n        \n        self.encod = nn.Sequential(\n            nn.Conv2d(4,32, kernel_size=5, stride=1, padding=2), #out = 32x384x384 cambie 16 por 32\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2), #out = 32x192x192, acum = 1\/2\n\n            nn.Conv2d(32,64, kernel_size=5, stride=1, padding=2), #out = 64x192x192\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2), #out = 64x96x96, acum = 1\/4\n        \n        \n            nn.Conv2d(64,128, kernel_size=5, stride=1, padding=2), #out=128x96x96\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2), #out = 128x48x48, acum = 1\/8\n        \n            nn.Conv2d(128, 256, kernel_size=5, stride=1, padding=2), #out = 256x48x48\n            nn.BatchNorm2d(256),\n            nn.ReLU(),    \n            nn.MaxPool2d(kernel_size=2, stride=2), #out = 256x24x24, acum = 1\/16\n        \n            nn.Conv2d(256, 512, kernel_size=5, stride=1, padding=2), #out = 256x24x24\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2), #out = 512x12x12, acum = 1\/32\n            \n            nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1), #out = 1024x24x24\n            nn.BatchNorm2d(1024),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2), #out = 1024x6x6, acum = 1\/64\n            \n            nn.Conv2d(1024, 1024, kernel_size=5, stride=1, padding=2), #out = 2048x12x12\n            nn.BatchNorm2d(1024),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2) #out = 1024x3x3, acum = 1\/128\n            \n        )\n        \n        self.decod = nn.Sequential(\n            nn.ConvTranspose2d(in_channels=1024,out_channels=512,kernel_size=3,stride=1, padding=2), #out = 512x3x3\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.UpsamplingNearest2d([6,6], scale_factor=None), #out=128x6x6 \n            \n            nn.ConvTranspose2d(in_channels=512,out_channels=256,kernel_size=3,stride=1, padding=2), #out = 256x6x6\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.UpsamplingNearest2d([12,12], scale_factor=None), #out=128x6x6 \n            \n            nn.ConvTranspose2d(in_channels=256,out_channels=128,kernel_size=5,stride=1, padding=2), #out=128x12x12\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.UpsamplingNearest2d([24,24], scale_factor=None), #out=128x24x24\n        \n            nn.ConvTranspose2d(in_channels=128,out_channels=64,kernel_size=5,stride=1, padding=2),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.UpsamplingNearest2d([48,48], scale_factor=None), #out=64x48x48\n           \n            nn.ConvTranspose2d(in_channels=64,out_channels=32,kernel_size=5,stride=1, padding=2),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.UpsamplingNearest2d([96,96], scale_factor=None), #out=32x96x96\n        \n            nn.ConvTranspose2d(in_channels=32,out_channels=16,kernel_size=5,stride=1, padding=2),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.UpsamplingNearest2d([192,192], scale_factor=None),#out=16x192x192\n        \n            nn.ConvTranspose2d(in_channels=16,out_channels=2,kernel_size=5,stride=1, padding=2),\n            nn.BatchNorm2d(2),\n            nn.Sigmoid(), \n            nn.UpsamplingNearest2d([384,384], scale_factor=None),#out=4x384x384\n        )\n            \n    \n    def forward(self, xb):\n        out = self.encod(xb) #out = 512x12x12\n        out = self.decod(out)\n        return out","aa6cb804":"class VanillaCNN(ImageClassificationBase):\n    def __init__(self):\n        super().__init__() #pad = k-1\/2\n        \n        self.convnet = nn.Sequential(\n            nn.Conv2d(4,16, kernel_size=5, stride=1, padding=2), #out = 16x384x384\n            nn.BatchNorm2d(16),\n            nn.GELU(),\n            nn.MaxPool2d(kernel_size=2, stride=2), #out = 16x192x192\n\n            nn.Conv2d(16,32, kernel_size=5, stride=1, padding=2), #out = 32x96x96\n            nn.BatchNorm2d(32),\n            nn.GELU(),\n            nn.MaxPool2d(kernel_size=2, stride=2), #out = 32x96x96\n        \n        \n            nn.Conv2d(32,64, kernel_size=5, stride=1, padding=2), #out=64x96x96\n            nn.BatchNorm2d(64),\n            nn.GELU(),\n            nn.MaxPool2d(kernel_size=2, stride=2), #out = 64x48x48\n        \n            nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2), #out = 128x48x48\n            nn.BatchNorm2d(128),\n            nn.GELU(),     \n            nn.MaxPool2d(kernel_size=2, stride=2), #out = 128x24x24\n        \n        \n            nn.Conv2d(128, 256, kernel_size=5, stride=1, padding=2), #out = 256x24x24\n            nn.BatchNorm2d(256),\n            nn.GELU(),\n            nn.MaxPool2d(kernel_size=2, stride=2), #out = 256x12x12\n        \n            nn.Conv2d(256, 512, kernel_size=5, stride=1, padding=2), #out = 512x12x12\n            nn.BatchNorm2d(512),\n            nn.GELU(),\n            nn.MaxPool2d(kernel_size=2, stride=2), #out = 512x6x6\n        \n            nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1), #out = 1024x6x6\n            nn.BatchNorm2d(1024),\n            nn.Sigmoid(),\n            nn.MaxPool2d(kernel_size=2, stride=1) #out = 1024x3x3\n        )\n        \n            #Deconvolution layers\n        self.deconvnet = nn.Sequential(\n            nn.ConvTranspose2d(in_channels=1024,out_channels=512,kernel_size=5, stride=1, padding=2), #1024x3x3\n            nn.GELU(),\n            nn.UpsamplingNearest2d([6,6], scale_factor=None), #out=512x6x6\n        \n            nn.ConvTranspose2d(in_channels=512,out_channels=256,kernel_size=5, stride=1, padding=2),\n            nn.GELU(),\n            nn.UpsamplingNearest2d([12,12], scale_factor=None), #out=256x12x12\n        \n            nn.ConvTranspose2d(in_channels=256,out_channels=128,kernel_size=5,stride=1, padding=2),\n            nn.GELU(),\n            nn.UpsamplingNearest2d([24,24], scale_factor=None), #out=128x24x24\n        \n            nn.ConvTranspose2d(in_channels=128,out_channels=64,kernel_size=5,stride=1, padding=2),\n            nn.GELU(),\n            nn.UpsamplingNearest2d([48,48], scale_factor=None), #out=64x48x48\n           \n            nn.ConvTranspose2d(in_channels=64,out_channels=32,kernel_size=5,stride=1, padding=2),\n            nn.GELU(),\n            nn.UpsamplingNearest2d([96,96], scale_factor=None), #out=32x96x96\n        \n            nn.ConvTranspose2d(in_channels=32,out_channels=16,kernel_size=5,stride=1, padding=2),\n            nn.GELU(),\n            nn.UpsamplingNearest2d([192,192], scale_factor=None),#out=16x192x192\n        \n            nn.ConvTranspose2d(in_channels=16,out_channels=2,kernel_size=3,stride=1, padding=2),\n            nn.Sigmoid(), #out=4x384x384\n            nn.UpsamplingNearest2d([384,384], scale_factor=None),#out=4x384x384\n            \n            #nn.ConvTranspose2d(in_channels=4, out_channels=2, kernel_size=3, stride=2, padding=1)\n        )\n          \n    def forward(self, x):\n        \n        out = self.convnet(x) #out = 16x384x384\n        out = self.deconvnet(out) #out=4x384x384\n        return out","1c52e8f4":"class UNET(ImageClassificationBase):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n\n        self.conv1 = self.contract_block(in_channels, 32, 7, 3)\n        self.conv2 = self.contract_block(32, 64, 3, 1)\n        self.conv3 = self.contract_block(64, 128, 3, 1)\n\n        self.upconv3 = self.expand_block(128, 64, 3, 1)\n        self.upconv2 = self.expand_block(64*2, 32, 3, 1)\n        self.upconv1 = self.expand_block(32*2, out_channels, 3, 1)\n\n    def __call__(self, x):\n\n        # downsampling part\n        conv1 = self.conv1(x)\n        conv2 = self.conv2(conv1)\n        conv3 = self.conv3(conv2)\n\n        upconv3 = self.upconv3(conv3)\n        upconv2 = self.upconv2(torch.cat([upconv3, conv2], 1))\n        upconv1 = self.upconv1(torch.cat([upconv2, conv1], 1))\n\n        return upconv1\n\n    def contract_block(self, in_channels, out_channels, kernel_size, padding):\n\n        contract = nn.Sequential(\n            torch.nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n            torch.nn.BatchNorm2d(out_channels),\n            nn.ReLU(),\n            torch.nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n            torch.nn.BatchNorm2d(out_channels),\n            nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n                                 )\n        return contract\n\n    def expand_block(self, in_channels, out_channels, kernel_size, padding):\n\n        expand = nn.Sequential(torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=padding),\n                            torch.nn.BatchNorm2d(out_channels),\n                            nn.ReLU(),\n                            torch.nn.Conv2d(out_channels, out_channels, kernel_size, stride=1, padding=padding),\n                            torch.nn.BatchNorm2d(out_channels),\n                            nn.ReLU(),\n                            torch.nn.ConvTranspose2d(out_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1) \n                            )\n        return expand","36ebac75":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n\ndef fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, weight_decay=0, grad_clip=None, opt_func=torch.optim.ASGD): #Averege SGD\n    '''Funci\u00f3n que entrena el modelo para un dado numero de epochs con la pol\u00edtica de un ciclo de learning rates'''\n    \n    torch.cuda.empty_cache()\n    history = [] \n    \n    # Seteo una funcion de optimizacion con weight decay\n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n    # Set up one-cycle learning rate scheduler\n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n                                                steps_per_epoch=len(train_loader))\n    torch.optim.lr_scheduler.OneCycleLR(optimizer, \n                                        max_lr, \n                                        total_steps=None, \n                                        epochs=epochs, \n                                        steps_per_epoch=len(train_loader), \n                                        pct_start=0.3,\n                                        anneal_strategy='cos', \n                                        cycle_momentum=True, \n                                        base_momentum=0.85,\n                                        max_momentum=0.95)\n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = [] #Lista donde guardo las losses del train dataset\n        lrs = [] #Lista donde guardo los learning rates\n        \n        for batch in train_loader: #para cada lote de datos \n            loss = model.training_step(batch) #calculo la loss para el batch\n            train_losses.append(loss) #agrego a la lista de train_losses\n            loss.backward() #calulo el gradiente respecto a los pesos y biasses\n            \n            # Gradient clipping\n            if grad_clip: \n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n            \n            optimizer.step()\n            optimizer.zero_grad() #Reset gradient to 0 ?\n            \n            # Record & update learning rate\n            lrs.append(get_lr(optimizer))\n            sched.step()\n        \n        # Validation phase\n        result = evaluate(model, val_loader) #Genera predicciones\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = lrs\n        model.epoch_end(epoch, result) #imprime los resultados\n        history.append(result) #Agrega a lista history\n        \n    return history","0efb3bad":" def init_all(model, init_func, *params, **kwargs):\n    for p in model.parameters():\n        init_func(p, *params, **kwargs)","111582ae":"#ModelCNN\n#model = to_device(VanillaCNN(), device)\n\n#model = to_device(VanillaFCN32(4,2), device)\n\n#model = to_device(SimpleCNN(), device)\n \n\n#Modelo U-Net\nmodel = to_device(UNET(4,2), device)\n\n#init_all(model, torch.nn.init.normal_, mean=0., std=1) #inicializo los pesos\nmodel","a64263af":"history = [evaluate(model, val_loader)]\nhistory","0c09c08d":"epochs = 10 #cantidad de iteraciones\nmax_lr = 0.001 #learning rate maximo para el ciclo\ngrad_clip = 0.1 \nweight_decay = 1e-4\nopt_func = torch.optim.Adam #funci\u00f3n de optimizaci\u00f3n\n\nstart = time.time()\nhistory += fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n                             grad_clip=grad_clip, \n                             weight_decay=weight_decay, \n                             opt_func=opt_func) #entreno y agrego a la historia","4059c0de":"#Tiempo de entrenamiento en horas en sistema decimal\ntime = ((time.time() - start)\/60)\/60\ntime","8e9fa342":"def plot_lrs(history):\n    lrs = np.concatenate([x.get('lrs', []) for x in history])\n    plt.plot(lrs)\n    plt.xlabel('Batch no.')\n    plt.ylabel('Learning rate')\n    plt.title('Learning Rate vs. Batch no.');\n    \nplot_lrs(history)","4e6568cf":"def plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs');\n    \nplot_accuracies(history)","c507956d":"def plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');\n    \nplot_losses(history)","3a4f84eb":"test_dl = DataLoader(test_dataset, batch_size*2, num_workers=4, pin_memory=True)\n#Muevo los datos al GPU.\ntest_loader = DeviceDataLoader(test_dl, device)","af09a8bc":"#Test\ndef predict_image(img, model):\n    xb = to_device(img.unsqueeze(0), device)  # Convert to a batch of 1\n    yb = model(xb) # Get predictions from model\n    return yb","998288ec":"img, label = test_dataset[1209]\npred = predict_image(img, model).cpu().detach().numpy()\nprint(pred.shape)\nmask_pred = np.zeros([384,384,2])\nmask_pred[:,:,0] = pred[:,1,:,:] #rojo = 1 = nubes\nmask_pred[:,:,1] = pred[:,0,:,:] #verde = 0 = no nubes\nprint(mask_pred.shape)\n","74a595a2":"from skimage import data\nfrom skimage.filters import threshold_otsu\n\n# Load image\nimage = mask_pred\n\n# Threshold image to binary\nthresh = threshold_otsu(image)\nbinary = image > thresh\n\n# Make 3 channel RGB image same dimensions\nRGB = np.zeros((binary.shape[0],binary.shape[1],3), dtype=np.uint8)\n\n# Make True pixels red\nRGB[binary]  = [255,0,0]\n# Make False pixels blue\nRGB[~binary] = [0,0,255]\n\n# Display result\nImage.fromarray(RGB).show()","9441169a":"\ndef test_plot(num, test_dataset):\n    \n    img, label = test_dataset[num]\n    pred = predict_image(img, model).cpu().detach().numpy()\n    mask_pred = np.zeros([384,384,3])\n    mask_pred[:,:,0] = pred[:,0,:,:]*255 #no nubes = 0 = rojo\n    mask_pred[:,:,1] = pred[:,1,:,:]*255 #nubes = 1 = verde\n    \n    plt.figure(num, figsize=(15,15))\n    \n    plt.subplot(131)\n    plt.title('Imagen RGB')\n    plt.imshow(test_dataset.open_as_array(num))\n\n    plt.subplot(132)\n    plt.title('M\u00e1scara predicha')\n    plt.imshow(mask_pred)\n#plt.cm.binary_\n    plt.subplot(133)\n    plt.title('M\u00e1scara real')\n    plt.imshow(test_dataset.open_mask(num))\n\n    plt.show()","b8ec7c92":"test_plot(296,test_dataset)","b9ed9201":"test_loader = DeviceDataLoader(DataLoader(test_dataset, batch_size*2), device)\nresult = evaluate(model, test_loader)\nresult","3e1da028":"#Plataforma para guardar los resultados \n!pip install jovian --upgrade -q\nimport jovian \n\ntorch.save(model.state_dict(), 'Deteccion de nubes')\n\njovian.reset()\n\njovian.log_hyperparams(Modelo='UNET',\n                       Loss_fn = 'nn.CrossEntropyLoss',\n                       batch_size = batch_size,\n                       epochs = epochs, \n                       lr = max_lr, \n                       scheduler='one-cycle', \n                       weight_decay = weight_decay, \n                       grad_clip = grad_clip,\n                       opt = opt_func.__name__, \n                       time = time)\n\njovian.log_metrics(best_acc=0.9133, test_loss=result.get('val_loss'), test_acc=result.get('val_acc') )\n\njovian.commit(project=project_name, outputs=['Deteccion de nubes.pth'], environment=None)","7c64369c":"## Preparando los datos\n\nPara empezar, cargo en la lista a la que denomino *'total_list'* los nombres de todos los archivos. Esta lista contiene tres sub-listas, cada una de ellas contiene los nombres de los archivos que van a pertenecer al conjunto de datos de entrenamiento(*training*), validacion y prueba(*test*) respectivamente. ","5b4a118c":"## Entrenamiento\n\nLo voy a hacer con pol\u00edtica de un ciclo del learning rate, weight decay y gradient clipping\n\nProceso para implementar gradient descent:\n\n1. Generar predicciones a trav\u00e9s del modelo.\n\n2. Calcular las perdidas (*loss*), es decir la diferencia entre la prediccion y la m\u00e1scara.\n\n3. Calcular los gradientes respecto a los pesos y biases.\n\n4. Adjust los pesos by subtracting a small quantity proportional to the gradient.\n\n5. Resetear los gradientes a 0 y repetir el proceso.","460847ab":"### U-Net\n![Esquema](https:\/\/miro.medium.com\/max\/700\/1*XvJffq5FAdDS4FoCqUb76g.png)","6890010a":"Finalmente, podemos ver la perdida y la exactitud del modelo sobre todo el conjunto de datos de testeo. Se espera que estos valores sean similares para este conjunto de datos y para el de validaci\u00f3n. Si no lo son, puede ser un indicador de que es necesario un mejor conjunto de datos de validaci\u00f3n, que contenga im\u00e1genes similares y con la misma distribuci\u00f3n que el conjunto de datos de testeo.","8e044620":"Creo los *dataloaders* donde cargo los *datasets* y defino el tama\u00f1o del lote (*batch*) para cargar el conjunto de datos en lotes al entrenarlo. ","8600ccbc":"### CNN","8d3dc656":"Este c\u00f3digo puede encontrarse en Kaggle y Github.","0a5d023c":"## Evaluaci\u00f3n de los resultados","d94ae791":"## Fuentes y bibliograf\u00eda\n* C\u00f3digo para la creacion del dataset original no ampliado, 38Cloud: https:\/\/github.com\/SorourMo\/38-Cloud-A-Cloud-Segmentation-Dataset\n* Clase CloudDataset: https:\/\/medium.com\/analytics-vidhya\/how-to-create-a-custom-dataset-loader-in-pytorch-from-scratch-for-multi-band-satellite-images-c5924e908edf\n* S. Mohajerani and P. Saeedi. \"Cloud-Net: An End-to-end Cloud Detection Algorithm for Landsat 8 Imagery\". (forthcoming) 2019. to appear at IEEE International Geoscience and Remote Sensing Symposium (IGARSS). URL: https:\/\/arxiv.org\/pdf\/1901.10077.pdf\n* Modelo U-Net: https:\/\/medium.com\/analytics-vidhya\/creating-a-very-simple-u-net-model-with-pytorch-for-semantic-segmentation-of-satellite-images-223aa216e705\n* Funciones varias: curso de Deep Learnig https:\/\/jovian.ml\/forum\/c\/pytorch-zero-to-gans\/18\n* Explicaci\u00f3n detallada sobre las redes neuronales convolucionales: https:\/\/cs231n.github.io\/convolutional-networks\/\n* Explicaci\u00f3n detallada sobre el modelo U-Net: https:\/\/towardsdatascience.com\/understanding-semantic-segmentation-with-unet-6be4f42d4b47\n* Explicaci\u00f3n detallada de las funciones de optimizaci\u00f3n\n* Dive into Deep Learning (libro): https:\/\/d2l.ai\/index.html\n* Towards Data Science (post explicativos, tom\u00e9 varias im\u00e1genes de esta cuenta): \nhttp:\/\/deeplearning.net\/tutorial\/fcn_2D_segm.html\n\nSemantic segmentation\nhttps:\/\/la.mathworks.com\/help\/vision\/ug\/semantic-segmentation-with-deep-learning.html#mw_6ab02754-d2fa-4330-8bea-3eeec77279da\n\nhttps:\/\/www.kite.com\/blog\/python\/image-segmentation-tutorial\/#confusion-matrix","8bb1debb":"## Mover los datos al GPU\nA continuaci\u00f3n defino una serie de funciones cuyo objetivo es mover los datos al GPU para poder utilizarlo y entrenar la red con este dispositivo. Si utilizara s\u00f3lo el CPU tardaria mucho tiempo, incluso es probable que no sea posible. \n[Fuente](https:\/\/jovian.ml\/forum\/c\/pytorch-zero-to-gans\/18)","9708cd01":"Como ultimo paso, grabo las mediciones en Jovian. Esto me permite tener un registro de los valores que obtuve y con qu\u00e9 hiperpar\u00e1metros y modelos lo logre. De esta forma puedo entender cual fue el 'mejor modelo' y por qu\u00e9.","88707540":"Ahora voy a utilizar el dataset 'test' para ver qu\u00e9 tan bien est\u00e1 etiquetando el modelo. Siguiendo el mismo procedimiento, cargo el dataset, muevo los datos al GPU y luego con la funci\u00f3n *predict_image* puedo pasarle una imagen y el modelo que elegi y obtener la prediccion. Luego la comparo con la m\u00e1scara correpondiente. ","c58ed168":"Elijo los par\u00e1metros y entreno. Adem\u00e1s, voy a registrar el tiempo que lleva cada entrenamiento.","b1c061e4":"Defino una lista denominada 'history' donde voy a guardar los par\u00e1metros de los entrenamientos y los resultados. Ademas, con la funci\u00f3n evaluate() voy a elegir los parametros iniciales.","c8c30448":"## Modelo","bbcbc42b":"Elijo el modelo y lo imprimo"}}