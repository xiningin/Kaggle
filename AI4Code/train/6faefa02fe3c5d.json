{"cell_type":{"80a695f0":"code","0966668a":"code","ba81029b":"code","2eb4a0b3":"code","578377a0":"code","062b1f79":"code","dd6243fd":"code","259e7b39":"code","ce0c44d6":"code","42d12974":"code","928c8835":"code","f0d0c155":"code","e7ae0f1d":"code","fb1d022d":"code","08ee7533":"code","e123e96f":"code","3a78d2a3":"code","46413f17":"code","48a0dc53":"code","ea7be8b7":"code","10deed33":"code","1c0d48c7":"code","a16f705e":"code","169964d8":"code","5c21d892":"code","ad2f6ea9":"code","ac33e316":"code","01ca5ddf":"code","c4ed615d":"code","09cbd60f":"code","46a92599":"code","1c231ada":"code","6d82ebc2":"code","bb5a9fd0":"code","7c41139e":"code","a80942a8":"code","a24d8cc3":"code","c4091e50":"code","3fa7eb4e":"code","2893650b":"code","17bbb8f5":"markdown","d14b51c6":"markdown","c9a0423c":"markdown","cf8fcae3":"markdown","6eb6f656":"markdown","7bb8bc93":"markdown","0e9815f5":"markdown","6a63c0ce":"markdown","d44e3399":"markdown","16d614ff":"markdown","6123de4d":"markdown","7d76c2e4":"markdown","6ca37b7a":"markdown","83647531":"markdown","795d378e":"markdown","f78561a7":"markdown","cadddf3b":"markdown","c999d484":"markdown","c47d2b49":"markdown","097f59b7":"markdown","336382ef":"markdown","6af08a25":"markdown","0634b73f":"markdown","7309777d":"markdown","524301bc":"markdown","5eb84600":"markdown","77017516":"markdown","71ba3a24":"markdown","fb7fe319":"markdown"},"source":{"80a695f0":"# Install Pycaret\n!pip install pycaret -q","0966668a":"# importing dataset\nimport pandas as pd\ndf = pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv')\ndf","ba81029b":"# Importing dataset from PyCaret\nfrom pycaret.datasets import get_data\ndiabetes = get_data('diabetes')","2eb4a0b3":"# import a classification module of PyCaret\nfrom pycaret.classification import *","578377a0":"clf = setup(data = df, target = 'Outcome', silent = True, session_id = 123)","062b1f79":"# run compare_models and save top 5 models based on 'Accuracy'\ntop_five = compare_models(n_select = 5)","dd6243fd":"catboost = create_model('catboost')   ","259e7b39":"# tune the best performance model\ntuned_catboost = tune_model(catboost)","ce0c44d6":"# tune multiple models dynamically (tuning top 5 model)\ntuned_top5 = [tune_model(i) for i in top_five]","42d12974":"tuned_top5","928c8835":"tuned_model_1 = tuned_top5[0] \ntuned_model_2 = tuned_top5[1]\ntuned_model_3 = tuned_top5[2] \ntuned_model_4 = tuned_top5[3]\ntuned_model_5 = tuned_top5[4]","f0d0c155":"evaluate_model(tuned_catboost)","e7ae0f1d":"evaluate_model(tuned_model_2)","fb1d022d":"evaluate_model(tuned_model_3)","08ee7533":"evaluate_model(tuned_model_4)","e123e96f":"evaluate_model(tuned_model_5)","3a78d2a3":"interpret_model(tuned_catboost)","46413f17":"# using recall \nautoml_model = automl(optimize = 'f1')\nautoml_model","48a0dc53":"prediction = predict_model(automl_model)","ea7be8b7":"prediction.head()","10deed33":"# specify the model in \"estimator_list\" parameter\nblended_top5 = blend_models(estimator_list = tuned_top5) \nblended_top5","1c0d48c7":"# ensemble top 5 tuned models\nbagged_top5 = [ensemble_model(i) for i in tuned_top5]","a16f705e":"# specify which model you want to save in the first parameter, name in the second\nsave_model(automl_model, model_name='automl-model')","169964d8":"# load model\nloaded_model = load_model('automl-model')\nprint(loaded_model)","5c21d892":"# Data preprocessing\ndef replace_missing(data):\n    data[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = data[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0, np.NaN)\n    return data\n\ndef median_target(data,var):   \n    temp = data[data[var].notnull()]\n    temp = temp[[var, 'Outcome']].groupby(['Outcome'])[[var]].median().reset_index()\n    return temp\n\ndef replace_median(data):\n    null_columns = ['BloodPressure', 'BMI', 'SkinThickness', 'Glucose', 'Insulin']\n    for i in null_columns:\n        f = median_target(data, i)\n        data.loc[(data['Outcome'] == 0 ) & (data[i].isnull()), i] = f[[i]].values[0][0]\n        data.loc[(data['Outcome'] == 1 ) & (data[i].isnull()), i] = f[[i]].values[1][0]\n    return data\n\ndef feature_engineering(data):\n    data.loc[:,'N1']=0\n    data.loc[(data['Age']<=30) & (data['Glucose']<=120),'N1']=1\n\n    data.loc[:,'N2']=0\n    data.loc[(data['BMI']<=30),'N2']=1\n\n    data.loc[:,'N3']=0\n    data.loc[(data['Age']<=30) & (data['Pregnancies']<=6),'N3']=1\n\n    data.loc[:,'N3_1']=0\n    data.loc[(data['Glucose']<=110) & (data['Pregnancies']<=5),'N3_1']=1\n\n    data.loc[:,'N4']=0\n    data.loc[(data['Glucose']<=105) & (data['BloodPressure']<=80),'N4']=1\n\n    data.loc[:,'N4_1']=0\n    data.loc[(data['Age']<=30) & (data['Pregnancies']<=6),'N4_1']=1\n\n    data.loc[:,'N5']=0\n    data.loc[(data['SkinThickness']<=20) ,'N5']=1\n\n    data.loc[:,'N6']=0\n    data.loc[(data['BMI']<30) & (data['SkinThickness']<=20),'N6']=1\n\n    data.loc[:,'N7']=0\n    data.loc[(data['Glucose']<=105) & (data['BMI']<=30),'N7']=1\n\n    data.loc[:,'N7_1']=0\n    data.loc[(data['BMI']<30) & (data['SkinThickness']<=20),'N7_1']=1\n\n    data.loc[:,'N9']=0\n    data.loc[(data['Insulin']<200),'N9']=1\n\n    data.loc[:,'N10']=0\n    data.loc[(data['BloodPressure']<80),'N10']=1\n\n    data.loc[:,'N11']=0\n    data.loc[(data['Pregnancies']<4) & (data['Pregnancies']!=0) ,'N11']=1\n\n    # highly correlate data\n\n    data['N0'] = data['BMI'] * data['SkinThickness']\n\n    data['N8'] =  data['Pregnancies'] \/ data['Age']\n\n    data['N13'] = data['Glucose'] \/ data['DiabetesPedigreeFunction']\n\n    data['N12'] = data['Age'] * data['DiabetesPedigreeFunction']\n\n    data['N14'] = data['Age'] \/ data['Insulin']\n\n    data['N15'] = data['BMI'] \/ data['Insulin']\n    return data\n\ndef prepare_data(data):\n    cat_cols   = data.nunique()[data.nunique() < 12].keys().tolist()\n    cat_cols   = [x for x in cat_cols]\n    #numerical columns\n    num_cols   = [x for x in data.columns if x not in cat_cols]\n    #Binary columns with 2 values\n    bin_cols   = data.nunique()[data.nunique() == 2].keys().tolist()\n    #Columns more than 2 values\n    multi_cols = [i for i in cat_cols if i not in bin_cols]\n\n    #Label encoding Binary columns\n    le = LabelEncoder()\n    for i in bin_cols :\n        data[i] = le.fit_transform(data[i])\n        \n    #Duplicating columns for multi value columns\n    data = pd.get_dummies(data = data,columns = multi_cols )\n\n    #Scaling Numerical columns\n    std = StandardScaler()\n    scaled = std.fit_transform(data[num_cols])\n    scaled = pd.DataFrame(scaled,columns=num_cols)\n\n    #dropping original values merging scaled values for numerical columns\n    df_data_og = data.copy()\n    data = data.drop(columns = num_cols,axis = 1)\n    data = data.merge(scaled,left_index=True,right_index=True,how = \"left\")\n    return data","ad2f6ea9":"from sklearn.preprocessing import StandardScaler, LabelEncoder\ndf_rms = replace_missing(df)\ndf_rm = replace_median(df_rms)\ndf_fe = feature_engineering(df_rm)\nprepared_data = prepare_data(df_fe)","ac33e316":"prepared_data","01ca5ddf":"clf_new = setup(data = prepared_data, target = 'Outcome', silent = True, session_id = 125)","c4ed615d":"# run compare_models and save top 5 models\ntop_five = compare_models(n_select = 5)","09cbd60f":"car_data = pd.read_csv('..\/input\/car-price-prediction\/CarPrice_Assignment.csv')\ncar_data","46a92599":"from pycaret.regression import *","1c231ada":"rgs = setup(data = car_data,  target = 'price', silent = True, session_id = 124)","6d82ebc2":"# run compare_models and save top 5 models \ntop_five_r = compare_models(n_select = 5)","bb5a9fd0":"catboost = create_model('catboost')   ","7c41139e":"# tune the best performance model\ntuned_catboost = tune_model(catboost)","a80942a8":"evaluate_model(tuned_catboost)","a24d8cc3":"interpret_model(tuned_catboost)","c4091e50":"# using recall \nautoml_model = automl(optimize = 'MAE')\nautoml_model","3fa7eb4e":"pred_holdouts = predict_model(automl_model)\npred_holdouts.head()","2893650b":"new_data = car_data.copy()\nnew_data.drop(['price'], axis=1, inplace=True)\npredictions = predict_model(automl_model, data=new_data)\npredictions.head()","17bbb8f5":"<h1 style=\"font-size:210%; font-family:monospace; background:#3CB371; color:white; text-align:center; border:10px solid ; padding:25px;\"> Thank you for reading and there are more to come! If you found this helpful, please upvote \ud83d\ude0a <\/h1> \n","d14b51c6":"The predict_model function below produces predictions for the holdout datasets used for validating the model during cross-validation. The code also gives us a dataframe with performance statistics for the predictions generated by the AutoML model.","c9a0423c":"# Intro to Pycaret","cf8fcae3":"# Bonus section on Classification (applying feature engineering) \nYou can check how to do a feature engineering here https:\/\/www.kaggle.com\/vincentlugat\/pima-indians-diabetes-eda-prediction-0-906\n\n","6eb6f656":"\n<li style=\"font-size:100%; font-family:monospace\"><b><\/b>you can put the whole dataframe in the \"data\" parameter and put the target variable in \"target\"\n<\/li>\n<li style=\"font-size:100%; font-family:monospace\"><b><\/b>parameter silent = True will ignore pops up message<\/li>","7bb8bc93":"<h1 style=\"font-size:210%; font-family:monospace; background:#3CB371; color:white; text-align:center; border:10px solid ; padding:25px;\">Create the Best Model Performance (result can be different in each run)<\/h1>","0e9815f5":"# Saving and loading the Model\nThe following function save any model you want. After running it, you can check the file in the output folder on your right","6a63c0ce":"# Blending Model\nThis function automatically create voting classifer based on the model we passed into the \"estimator list\" parameter","d44e3399":"<h1 style=\"font-size:210%; font-family:monospace; background:#3CB371; color:white; text-align:center; border:10px solid ; padding:25px;\"> Pycaret Installation \u2728<\/h1>","16d614ff":"The predict_model function allows us to predict data from the experiment or new unseen data. ","6123de4d":"# Interpret the model \nThis function supports tree based models for binary classification: lightgbm, catboost, et, xgboost, rf, dt.)","7d76c2e4":"<h1 style=\"font-size:210%; font-family:monospace; background:#3CB371; color:white; text-align:center; border:10px solid ; padding:25px;\"> Let's turn on Accelerator in Kaggle kernel and begin with PyCaret! \ud83c\udfa2 <\/h1>","6ca37b7a":"# Emsemble Model","83647531":"# Classification","795d378e":"# Tuning the model","f78561a7":"#### Isn't that amazing? It's just one line of code!","cadddf3b":"<div class=\"alert alert-block alert-info\">  \ud83d\udccc First, we will be using PyCaret on the diabetes dataset for classification<\/div>","c999d484":"# Visualize model performance\n<div class=\"alert alert-block alert-info\">  PyCaret uses high-level library Yellowbrick for creating these visualizations.<\/div>","c47d2b49":"# AutoML\nThe following function returns the best model out of all models created in the current active environment based on metric defined in optimize parameter. Run this code at the end of  your script.","097f59b7":"After we applied feature engineering, we can see a big improvement of each model","336382ef":"<div class=\"alert alert-block alert-info\">  \ud83d\udccc Running the below command and the module will automatically preprocesses the data and then creates a dataframe<\/div>","6af08a25":"# Hyperparameter of each of tuned_top5 model","0634b73f":"We can also produce predictions on the entire dataset","7309777d":"<h1 style=\"font-size:210%; font-family:monospace; background:#3CB371; color:white; text-align:center; border:10px solid ; padding:25px;\"> importing classification module and initializing setup \ud83d\udc31\u200d\ud83d\udc64<\/h1>","524301bc":"# Prediction","5eb84600":"<div class=\"alert alert-block alert-info\">  You can see that the setup process preprocess the data and create a train\/test set automatically for us<\/div>","77017516":"# Regression","71ba3a24":"<h1 style=\"font-size:300%; font-family:monospace; background:#3CB371; color:white; text-align:center; border:10px solid ; padding:25px;\"> Introduction to Pycaret<\/h1>\n\n<img src=\"https:\/\/pycaret.org\/wp-content\/uploads\/2021\/02\/pycaret2.3.png\" width=\"450px\"> <img src=\"https:\/\/i1.wp.com\/pycaret.org\/wp-content\/uploads\/2020\/04\/thumbnail.png?fit=1166%2C656&ssl=1\" width=\"500px\">\n\n\n\n<img align=center src=\"https:\/\/cdn.dribbble.com\/users\/18013\/screenshots\/12600021\/media\/3cb1d96666688e41589a638d48cd4674.png\" width=\"500px\">\n\n<cite>Image from www.dribbble.com by Vitaliy Sokovikov<\/cite>\n\n<li style=\"font-size:120%; font-family:monospace\"> PyCaret is a low-code machine learning library in Python that allows you to go from preparing your data to deploying your model in less time, so you can spend time doing something else while waiting for your model training \ud83d\ude0e\n<\/li>\n\n\n<li style=\"font-size:120%; font-family:monospace\"> You can read the documentation of PyCaret at https:\/\/pycaret.org or https:\/\/pycaret.readthedocs.io\/en\/latest\/\n<\/li>\n\n<li style=\"font-size:120%; font-family:monospace\">and a similar low-code ML library called LazyPredict at https:\/\/lazypredict.readthedocs.io\/en\/latest\/\n<\/li>","fb7fe319":"<div class=\"alert alert-block alert-info\">  \ud83d\udccc We have two choice which are importing dataset from Kaggle or from Pycaret dataset itself (two of them are the same except for the column name)<\/div>"}}