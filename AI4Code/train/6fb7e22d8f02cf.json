{"cell_type":{"e8d969ac":"code","821a4e2c":"code","cf6ed9dc":"code","95faa18a":"code","8510cb51":"code","6a2b23ee":"code","55be6c9b":"code","232ca60a":"code","34f5748b":"code","d918583d":"code","6d9f0561":"code","6a1ae90d":"code","3017cafe":"code","44c23cf7":"code","85625855":"code","e14f1e29":"code","a9cde66a":"code","0e17ebd8":"code","3c84d05b":"code","244f7b7c":"code","b7113942":"code","3c7d8c0c":"code","bc75862d":"code","3cb412e9":"code","6bd3cae2":"code","70fb6167":"code","1bdc2455":"code","5a75ed31":"code","aab3a7e3":"markdown","b500151f":"markdown","088153d3":"markdown","d32c8ba1":"markdown","1d26c2f6":"markdown","7c280313":"markdown","05eb36db":"markdown","ed4d9ac7":"markdown","f087605e":"markdown","2086ccd5":"markdown","73a4cdb6":"markdown","87328877":"markdown","97e06f60":"markdown","7ab57497":"markdown","b77f08c6":"markdown","7e2e3621":"markdown"},"source":{"e8d969ac":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as  sns\n\nfrom sklearn.model_selection import train_test_split\n\nimport xgboost\n\nsns.set(style=\"white\")","821a4e2c":"train_set = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntest_set = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")","cf6ed9dc":"train_set.tail()","95faa18a":"train_set.shape","8510cb51":"## Segregation of feature matrix and target variable\ny     = train_set[['Id','SalePrice']]\ntrain_set = train_set.drop('SalePrice',axis=1)","6a2b23ee":"final_set = pd.concat([train_set,test_set],axis=0)","55be6c9b":"# Generate a large random dataset\nrs = np.random.RandomState(33)\nd = pd.DataFrame(data=rs.normal(size=(100, final_set.shape[1])),\n                 columns=final_set.columns)\n\n# Compute the correlation matrix\ncorr = d.corr()\n\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(30, 20))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.5, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","232ca60a":"final_set.tail()","34f5748b":"print(\"Total Features :: \", len(final_set.columns.tolist()))\nprint(\"Total Categorical variables::\", len(final_set.select_dtypes(exclude=[\"number\",\"bool_\"]).columns.tolist()))\nprint(\"Total Continuous variables :: \",len(final_set.select_dtypes(exclude=[\"object_\"]).columns.tolist()))","d918583d":"fig, ax = plt.subplots(figsize=(30,15))\nsns.heatmap(final_set.isnull(),yticklabels=False,cbar=False,ax=ax)","6d9f0561":"# WE are chosing nan percentage threshold upto 40.\nfinal_set = final_set.loc[:, final_set.isnull().mean() < .4]","6a1ae90d":"fig, ax = plt.subplots(figsize=(30,15))\nsns.heatmap(final_set.isnull(),yticklabels=False,cbar=False,ax=ax)","3017cafe":"categorical_features = final_set.select_dtypes(exclude=[\"number\",\"bool_\"]).columns.tolist()\nlen(categorical_features)","44c23cf7":"def fill_nan_categorical(categorical_features,final_set):\n    for i in categorical_features:\n        final_set[i] =  final_set[i].fillna(final_set[i].mode()[0])\n    \n    return final_set","85625855":"final_set = fill_nan_categorical(categorical_features,final_set)","e14f1e29":"fig, ax = plt.subplots(figsize=(40,20))\nsns.heatmap(final_set.isnull(),yticklabels=False,cbar=False,ax=ax)","a9cde66a":"continuous_features =  final_set.select_dtypes(exclude=[\"object_\"]).columns.tolist()","0e17ebd8":"def fill_nan_continuous(continuous_features,final_set):\n    for i in continuous_features:\n        final_set[i] =  final_set[i].fillna(final_set[i].mean())\n    return final_set","3c84d05b":"final_set = fill_nan_continuous(continuous_features,final_set)\nfig, ax = plt.subplots(figsize=(40,20))\nsns.heatmap(final_set.isnull(),yticklabels=False,cbar=False)","244f7b7c":"def one_hot_encoder(final_set):\n    df  = final_set.copy(deep= True)\n    dummies = pd.get_dummies(df,prefix=\"column_\",drop_first=True)\n    return dummies","b7113942":"final_set = one_hot_encoder(final_set)\nfinal_set = final_set.loc[:,~final_set.columns.duplicated()]","3c7d8c0c":"final_set.head()","bc75862d":"train_data = pd.DataFrame(final_set[:1460])\ntest_data = pd.DataFrame(final_set[1460:2920])","3cb412e9":"print(train_data.shape)\nprint(test_data.shape)","6bd3cae2":"X = final_set[:1460]\nX_train, X_test, y_train, y_test = train_test_split(X,\n                                                    y[\"SalePrice\"],\n                                                    test_size=0.1,\n                                                    random_state=42)","70fb6167":"xgb_classifier = xgboost.XGBRFRegressor(n_estimators=20,\n                                        learning_rate=1,\n                                        reg_lambda=0.1,\n                                        gamma=0.6,\n                                        max_depth=10)\nxgb_classifier.fit(X_train, y_train)\ny_pred = xgb_classifier.predict(test_data).tolist()","1bdc2455":"xgb_classifier.score(X_test,y_test)","5a75ed31":"predictions = pd.DataFrame(y_pred)\ndatasets = pd.concat([test_set[\"Id\"],predictions],axis=1)\ndatasets.columns = [\"Id\",\"SalePrice\"]\ndatasets.to_csv(\"submission.csv\",index=False)","aab3a7e3":"### Finding all the categorical features","b500151f":"### Initial lookup after filling Nan of categorical features","088153d3":"### Filling NaNs For Continuous variable","d32c8ba1":"### Still some of them are holding NaNs so time to fill the Nan with mean, median,mode accordingly\n","1d26c2f6":"### Dataset Import","7c280313":"### OneHot Encoding Of Features","05eb36db":"### Data lookup after feature reductions","ed4d9ac7":"### Drop features which are below certain percentage","f087605e":"#### Ok, as of now we got rid of features which were not compliant with our percentage measures(<40% nan got removed)","2086ccd5":"Here goes the clean black slate, we have good reduction and filling policy and awe succeeded to remove\/fill them","73a4cdb6":"### Filling NaNs for Categorical Features","87328877":"### Heat map to show the feature  wise nan distribution.","97e06f60":"### Libraries","7ab57497":"**Let's Pinch this data little bit to know about it**","b77f08c6":"### Finding all the continuous features","7e2e3621":"As it's obvious we have enormous missing values so better to club them and pre-process and later we will divide them separately according to our to need."}}