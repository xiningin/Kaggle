{"cell_type":{"23883844":"code","d201941a":"code","aa3cdf67":"code","20c9ba10":"code","6e722e3c":"code","f78bb571":"code","7b4a3842":"code","02c217e1":"code","53317cf4":"code","8d0acd17":"code","1ae7267c":"code","e4693ede":"code","9c4ceae2":"code","2d1709a0":"code","da021917":"code","9afb946c":"code","e37d26b1":"code","0eb9d0f3":"code","347be709":"code","6b1132d1":"code","9004f02b":"code","eec01bc1":"code","9ac0d1d7":"code","5446dc5b":"code","07eb4a06":"code","8cdfa08f":"code","473c31c5":"code","15a8f79f":"code","a3ce8f13":"code","f5b9897f":"code","a24dc6c8":"code","c7ba55a7":"code","f903736b":"code","30100da5":"code","6d136bd8":"code","35387d21":"code","c068254e":"code","7485792f":"code","ec70f6ae":"code","18d27782":"code","79eb8ee6":"code","2d70a9cf":"code","44ff7c3a":"code","244770fe":"code","0de1383c":"code","577bf92e":"code","eb278128":"code","92520352":"code","3ae895f8":"code","57b586d3":"code","e04a9842":"code","b6e172c7":"code","c0d490b5":"code","9b0fc2f1":"code","18faf459":"code","9a0bd811":"code","e18eb266":"code","3999353d":"code","79e6d418":"code","7063660a":"code","1040fa22":"code","68117efd":"code","34bf3eb8":"code","18038daa":"code","ecebc53f":"code","af2164b5":"code","db5597c1":"code","b640ec23":"code","53d821d8":"code","ba6ad679":"code","cc7aa2f5":"markdown","363e8f5f":"markdown","c7727c9e":"markdown","7da5a8f3":"markdown"},"source":{"23883844":"# \u57fa\u672c\u30bb\u30c3\u30c8\u306e\u8aad\u8fbc\nimport numpy as np\nimport scipy as sp\nimport pandas as pd\npd.set_option('display.max_columns', 100)\npd.set_option('display.max_rows', 100)\nfrom pandas import Series, DataFrame\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom IPython.core.display import display, HTML\ndisplay(HTML(\"<style>.container{width: 100% !important; }<\/style>\"))# Jupyter notebook\u306e\u6a2a\u5e45\u3092\u30d6\u30e9\u30a6\u30b6\u3068\u63c3\u3048\u308b\u30b3\u30de\u30f3\u30c9\n\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n%matplotlib inline\n\n# \u6a5f\u68b0\u5b66\u7fd2\u30e9\u30a4\u30d6\u30e9\u30ea\u8aad\u307f\u8fbc\u307f\nimport sklearn\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nimport category_encoders as ce\nfrom category_encoders import OrdinalEncoder, OneHotEncoder, TargetEncoder\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import HistGradientBoostingRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\n\n\nfrom sklearn.model_selection import GroupKFold, train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_squared_log_error\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import r2_score\n\n#\u5c0f\u6570\u70b9\u4ee5\u4e0b\u7b2c\uff13\u4f4d\u307e\u3067\u8868\u793a\n%precision 3","d201941a":"# \u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u3080\ndf_train = pd.read_csv('..\/input\/machine-learning-homework\/train.csv', index_col=0) # machine-learning-homework\ndf_test = pd.read_csv('..\/input\/machine-learning-homework\/test.csv', index_col=0)\nprint('size of train data:' + str(df_train.shape))\nprint('size of test data:' + str(df_test.shape))","aa3cdf67":"# \u6e7e\u5cb8\u5730\u57df\u306a\u3069\u5468\u8fba\u9996\u90fd\u570f\u306e\u4fa1\u683c\u5e2f\u3068\u9055\u3046\u4e16\u754c\u306e\u7269\u4ef6\u3092\u524a\u9664\ndf_train = df_train[df_train.TradePrice <= 100000000]","20c9ba10":"# \u90fd\u9053\u5e9c\u770c\u5225\u306e\u51fa\u73fe\u983b\u5ea6\u3092\u78ba\u8a8d\u3057\u3066\u307f\u3088\u3046\u3002\ndf_train.Prefecture.value_counts()","6e722e3c":"# train\u30c7\u30fc\u30bf\u3092X,y\u306b\u5206\u96e2\ny_train = df_train.TradePrice\nX_train = df_train.drop(['TradePrice'], axis=1)\nX_test = df_test.copy()","f78bb571":"# DataFrame\u306eshape\u3067\u884c\u6570\u3068\u5217\u6570\u3092\u78ba\u8a8d\nX_test.shape, X_train.shape","7b4a3842":"# \u524d\u51e6\u7406\u7528df\u4f5c\u6210\ndf_all = pd.concat([X_train,X_test], sort=False)\ndf_all.head() #\u30c7\u30fc\u30bf\u306e\u982d5\u884c\u3092\u8868\u793a","02c217e1":"X_train.dtypes","53317cf4":"# \u6b20\u640d\u5024\u78ba\u8a8d\nX_train.isnull().sum()","8d0acd17":"# \u6570\u5024\u3068\u3057\u3066\u53d6\u308a\u6271\u3048\u305d\u3046\u306a\u3082\u306e\u3092\u6570\u5024\u5316\nTimeToNearestStation_dict = {'30-60minutes': 45, '1H-1H30': 75,\n                              '1H30-2H': 120, '2H-': 150, 'NaN': 60}\n\nX_train.TimeToNearestStation.replace(TimeToNearestStation_dict, inplace=True)\nX_test.TimeToNearestStation.replace(TimeToNearestStation_dict, inplace=True)\n\nX_train.TimeToNearestStation = X_train.TimeToNearestStation.astype(float).fillna(-99999)\nX_test.TimeToNearestStation = X_test.TimeToNearestStation.astype(float).fillna(-99999)","1ae7267c":"X_train.Frontage = X_train.Frontage.fillna(-99999)\nX_test.Frontage = X_test.Frontage.fillna(-99999)","e4693ede":"X_train.TotalFloorArea = X_train.TotalFloorArea.fillna(-99999)\nX_test.TotalFloorArea = X_test.TotalFloorArea.fillna(-99999)","9c4ceae2":"X_train.BuildingYear = X_train.BuildingYear.fillna(-99999)\nX_test.BuildingYear = X_test.BuildingYear.fillna(-99999)","2d1709a0":"X_train.Breadth = X_train.Breadth.fillna(-99999)\nX_test.Breadth = X_test.Breadth.fillna(-99999)","da021917":"X_train.MinTimeToNearestStation = X_train.MinTimeToNearestStation.fillna(-99999)\nX_test.MinTimeToNearestStation = X_test.MinTimeToNearestStation.fillna(-99999)","9afb946c":"X_train.MaxTimeToNearestStation = X_train.MaxTimeToNearestStation.fillna(-99999)\nX_test.MaxTimeToNearestStation = X_test.MaxTimeToNearestStation.fillna(-99999)","e37d26b1":"X_train.CoverageRatio = X_train.CoverageRatio.fillna(-99999)\nX_test.CoverageRatio = X_test.CoverageRatio.fillna(-99999)","0eb9d0f3":"X_train.FloorAreaRatio = X_train.FloorAreaRatio.fillna(-99999)\nX_test.FloorAreaRatio = X_test.FloorAreaRatio.fillna(-99999)","347be709":"# \u4f3c\u305f\u3088\u3046\u306a\u9805\u76ee\u306e\u639b\u3051\u5408\u308f\u305b\nX_train['MinTimeSt_\/_MaxTimeSt'] = X_train['MinTimeToNearestStation'] \/ X_train['MaxTimeToNearestStation']\nX_test['MinTimeSt_\/_MaxTimeSt'] = X_test['MinTimeToNearestStation'] \/ X_test['MaxTimeToNearestStation']","6b1132d1":"from geopy.distance import great_circle\n# csv\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u307f\u307e\u3059\u3002\n\ndf_station = pd.read_csv('..\/input\/machine-learning-homework\/station_info.csv')","9004f02b":"df_station.head()","eec01bc1":"# \u99c5\u306e\u7def\u5ea6\u7d4c\u5ea6\u3092merge.\n\nX_train = X_train.merge(df_station, left_on='NearestStation', right_on='Station', how='left')\nX_test = X_test.merge(df_station, left_on='NearestStation', right_on='Station', how='left')","9ac0d1d7":"X_train.head()","5446dc5b":"# \u8ddd\u96e2\u8a08\u7b97\u3092\u884c\u3046\u95a2\u6570\u3092\u5b9a\u7fa9\u3002\ndef calc_distance(df, dist):\n    return great_circle((df.Latitude, df.Longitude), dist).meters","07eb4a06":"%%time\n# \u6700\u5bc4\u99c5\u304b\u3089\u5404\u4e3b\u8981\u99c5\u307e\u3067\u306e\u8ddd\u96e2\u3092\u8a08\u7b97\u3002\n\nstations = ['Tokyo', 'Chiba', 'Yokohama', 'Oarai', 'Utsunomiya',\n            'Maebashi', 'Hakoneyumoto','Awakamogawa','Kawagoe']\n\nfor station in stations:\n    lat_dist = df_station[df_station.Station==station].Latitude.values[0]\n    lon_dist = df_station[df_station.Station==station].Longitude.values[0]\n    \n    X_train.loc[X_train.Latitude.isnull()==False, 'distance_%s'%station] = \\\n    X_train[X_train.Latitude.isnull()==False].apply(calc_distance, dist=(lat_dist, lon_dist), axis=1)\n\n    X_test.loc[X_test.Latitude.isnull()==False, 'distance_%s'%station] = \\\n    X_test[X_test.Latitude.isnull()==False].apply(calc_distance, dist=(lat_dist, lon_dist), axis=1)","8cdfa08f":"%%time\n# \u6700\u5bc4\u99c5\u304b\u3089\u5404\u4e3b\u8981\u99c5\u307e\u3067\u306e\u8ddd\u96e2\u3092\u8a08\u7b97\u3002\n\nstations = ['Akihabara', 'Nikko', 'Oarai', 'Takasaki (JR)', 'Maihama',\n            'Yugawara', 'Shinbashi', 'Shinagawa', 'Odawara','Mito']\n\nfor station in stations:\n    lat_dist = df_station[df_station.Station==station].Latitude.values[0]\n    lon_dist = df_station[df_station.Station==station].Longitude.values[0]\n    \n    X_train.loc[X_train.Latitude.isnull()==False, 'distance_%s'%station] = \\\n    X_train[X_train.Latitude.isnull()==False].apply(calc_distance, dist=(lat_dist, lon_dist), axis=1)\n\n    X_test.loc[X_test.Latitude.isnull()==False, 'distance_%s'%station] = \\\n    X_test[X_test.Latitude.isnull()==False].apply(calc_distance, dist=(lat_dist, lon_dist), axis=1)","473c31c5":"%%time\n# \u6700\u5bc4\u99c5\u304b\u3089\u5404\u4e3b\u8981\u99c5\u307e\u3067\u306e\u8ddd\u96e2\u3092\u8a08\u7b97\u3002\n\nstations = ['Ueno', 'Omiya (Saitama)', 'Oyama', 'Nasushiobara', 'Kumagaya']\n\nfor station in stations:\n    lat_dist = df_station[df_station.Station==station].Latitude.values[0]\n    lon_dist = df_station[df_station.Station==station].Longitude.values[0]\n    \n    X_train.loc[X_train.Latitude.isnull()==False, 'distance_%s'%station] = \\\n    X_train[X_train.Latitude.isnull()==False].apply(calc_distance, dist=(lat_dist, lon_dist), axis=1)\n\n    X_test.loc[X_test.Latitude.isnull()==False, 'distance_%s'%station] = \\\n    X_test[X_test.Latitude.isnull()==False].apply(calc_distance, dist=(lat_dist, lon_dist), axis=1)","15a8f79f":"# \u5217\u5185\u5bb9\u304c\u88ab\u308b\u305f\u3081'NearestStation'\u884c\u3092\u524a\u9664\nX_train = X_train.drop(['NearestStation'], axis=1)\nX_test = X_test.drop(['NearestStation'], axis=1)","a3ce8f13":"df_city = pd.read_csv('..\/input\/machine-learning-homework\/city_info.csv')","f5b9897f":"df_city.head()","a24dc6c8":"# \u90fd\u5e02\u306e\u7def\u5ea6\u7d4c\u5ea6\u3092merge.\n\nX_train = X_train.merge(df_city, left_on='Municipality', right_on='Municipality', how='left')\nX_test = X_test.merge(df_city, left_on='Municipality', right_on='Municipality', how='left')","c7ba55a7":"# \u8ddd\u96e2\u8a08\u7b97\u3092\u884c\u3046\u95a2\u6570\u3092\u5b9a\u7fa9\u3002\ndef calc_distance(df, dist):\n    return great_circle((df.Latitude_y, df.Longitude_y), dist).meters","f903736b":"%%time\n# \u4f4f\u5c45\u5730\u304b\u3089\u5404\u4e3b\u8981\u90fd\u5e02\u307e\u3067\u306e\u8ddd\u96e2\u3092\u8a08\u7b97\u3002\n\nmunucipalitys = ['Chiyoda Ward', 'Shibuya Ward', 'Minato Ward', 'Toshima Ward',\n                 'Naka Ward,Yokohama City', 'Nishi Ward,Yokohama City', 'Kanagawa Ward,Yokohama City',\n                 'Takatsu Ward,Kawasaki City','Chigasaki City', 'Kamakura City']\n\nfor munucipality in munucipalitys:\n    lat_dist = df_city[df_city.Municipality==munucipality].Latitude.values[0]\n    lon_dist = df_city[df_city.Municipality==munucipality].Longitude.values[0]\n\n    X_train.loc[X_train.Latitude_y.isnull()==False, 'distance_%s'%munucipality] = \\\n    X_train[X_train.Latitude_y.isnull()==False].apply(calc_distance, dist=(lat_dist, lon_dist), axis=1)\n\n    X_test.loc[X_test.Latitude_y.isnull()==False, 'distance_%s'%munucipality] = \\\n    X_test[X_test.Latitude_y.isnull()==False].apply(calc_distance, dist=(lat_dist, lon_dist), axis=1)","30100da5":"%%time\n# \u4f4f\u5c45\u5730\u304b\u3089\u5404\u4e3b\u8981\u90fd\u5e02\u307e\u3067\u306e\u8ddd\u96e2\u3092\u8a08\u7b97\u3002\n\nmunucipalitys = ['Omiya Ward,Saitama City', 'Urawa Ward,Saitama City',\n                 'Minami Ward,Saitama City', 'Sakura Ward,Saitama City', 'Kawaguchi City',\n                 'Kumagaya City', 'Urayasu City', 'Funabashi City', 'Utsunomiya City'] \n\nfor munucipality in munucipalitys:\n    lat_dist = df_city[df_city.Municipality==munucipality].Latitude.values[0]\n    lon_dist = df_city[df_city.Municipality==munucipality].Longitude.values[0]\n\n    X_train.loc[X_train.Latitude_y.isnull()==False, 'distance_%s'%munucipality] = \\\n    X_train[X_train.Latitude_y.isnull()==False].apply(calc_distance, dist=(lat_dist, lon_dist), axis=1)\n\n    X_test.loc[X_test.Latitude_y.isnull()==False, 'distance_%s'%munucipality] = \\\n    X_test[X_test.Latitude_y.isnull()==False].apply(calc_distance, dist=(lat_dist, lon_dist), axis=1)","6d136bd8":"%%time\n# \u4f4f\u5c45\u5730\u304b\u3089\u5404\u4e3b\u8981\u90fd\u5e02\u307e\u3067\u306e\u8ddd\u96e2\u3092\u8a08\u7b97\u3002\n\nmunucipalitys = ['Chuo Ward,Saitama City', 'Odawara City', 'Chuo Ward,Chiba City',\n                 'Mihama Ward,Chiba City', 'Takasaki City', 'Kashiwa City', 'Tsukuba City',\n                 'Hitachi City', 'Tsuchiura City', 'Kashima City', 'Tochigi City', 'Nikko City']\n\nfor munucipality in munucipalitys:\n    lat_dist = df_city[df_city.Municipality==munucipality].Latitude.values[0]\n    lon_dist = df_city[df_city.Municipality==munucipality].Longitude.values[0]\n\n    X_train.loc[X_train.Latitude_y.isnull()==False, 'distance_%s'%munucipality] = \\\n    X_train[X_train.Latitude_y.isnull()==False].apply(calc_distance, dist=(lat_dist, lon_dist), axis=1)\n\n    X_test.loc[X_test.Latitude_y.isnull()==False, 'distance_%s'%munucipality] = \\\n    X_test[X_test.Latitude_y.isnull()==False].apply(calc_distance, dist=(lat_dist, lon_dist), axis=1)","35387d21":"%%time\n# \u4f4f\u5c45\u5730\u304b\u3089\u5404\u4e3b\u8981\u90fd\u5e02\u307e\u3067\u306e\u8ddd\u96e2\u3092\u8a08\u7b97\u3002\n\nmunucipalitys = ['Mito City', 'Matsudo City','Kawagoe City', 'Kisarazu City', 'Kimitsu City',\n                 'Hachioji City','Ogano Town,Chichibu County','Kasukabe City']\n\n\nfor munucipality in munucipalitys:\n    lat_dist = df_city[df_city.Municipality==munucipality].Latitude.values[0]\n    lon_dist = df_city[df_city.Municipality==munucipality].Longitude.values[0]\n\n    X_train.loc[X_train.Latitude_y.isnull()==False, 'distance_%s'%munucipality] = \\\n    X_train[X_train.Latitude_y.isnull()==False].apply(calc_distance, dist=(lat_dist, lon_dist), axis=1)\n\n    X_test.loc[X_test.Latitude_y.isnull()==False, 'distance_%s'%munucipality] = \\\n    X_test[X_test.Latitude_y.isnull()==False].apply(calc_distance, dist=(lat_dist, lon_dist), axis=1)","c068254e":"# \u5217\u5185\u5bb9\u304c\u88ab\u308b\u305f\u3081'NearestStation'\u884c\u3092\u524a\u9664\n#df_all = df_all.drop(['Prefecture_y'], axis=1)\nX_train = X_train.drop(['Prefecture_y'], axis=1)\nX_test = X_test.drop(['Prefecture_y'], axis=1)","7485792f":"X_train.shape, X_test.shape","ec70f6ae":"X_test.head()","18d27782":"X_train.dtypes","79eb8ee6":"# index\u632f\u76f4\u3057\nX_train.index = X_train.index\nX_test.index = X_test.index + 251487","2d70a9cf":"# \u6b8b\u3063\u305fobject\u5217\u3092Eoncode\u3002\u5217\u3092\u30ea\u30b9\u30c8\u6307\u5b9a\n# dtype\u304cobject\u306e\u3082\u306e\u3092LabelEncoding\u3057\u3066\u304a\u304f\u3002\u540c\u6642\u306b\u6b20\u640d\u3092\u57cb\u3081\u3066\u304a\u304f\u3002\nX_concat = pd.concat([X_train, X_test])\n\nfor col in X_concat.columns:\n    if (X_concat[col].dtype == 'object'):\n        le = LabelEncoder()\n        X_concat[col] = le.fit_transform(X_concat[col].fillna('NaN')) # \u30ab\u30c6\u30b4\u30ea\u306e\u6b20\u640d\u3092NaN\u3068\u3044\u3046\u5024\u3067\u57cb\u3081\u3066\u304a\u304f\n        \nX_train = X_concat[X_concat.index.isin(X_train.index)].fillna(-11) # \u6570\u5024\u306e\u6b20\u640d\u3092-99999\u3067\u57cb\u3081\u3066\u304a\u304f\nX_test = X_concat[~X_concat.index.isin(X_train.index)].fillna(-11)","44ff7c3a":"X_train.head()","244770fe":"X_test.head()","0de1383c":"# \u6b20\u640d\u5024\u78ba\u8a8d\nX_train.isnull().sum()","577bf92e":"X_train.dtypes","eb278128":"#\u7d71\u8a08\u91cf\u78ba\u8a8d\nX_train.describe()","92520352":"# 'Prefecture'\u5024\u3067groups\u4f5c\u6210\ngroups = X_train.Prefecture_x.values\n\nX_train.drop(['Prefecture_x'], axis=1, inplace=True)\nX_test.drop(['Prefecture_x'], axis=1, inplace=True)","3ae895f8":"X_train.shape, X_test.shape","57b586d3":"X_train.head()","e04a9842":"%%time\n# \u90fd\u9053\u5e9c\u770c\u3067\u533a\u5207\u3063\u3066\u4ea4\u5dee\u691c\u5b9a\u3092\u884c\u3044\u3001\u4e88\u6e2c\u7cbe\u5ea6\u3092\u898b\u7a4d\u3082\u308b\u3002\n# \u540c\u6642\u306b\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066cv averaging\u3092\u884c\u3044\u3001\u4e88\u6e2c\u5024\u3092\u5f97\u308b\u3002\n\nn_fold = 5\ncv = GroupKFold(n_splits=n_fold)\n\ny_pred_train = np.zeros(len(X_train))\ny_pred_test = np.zeros(len(X_test))\nscores = []\n\nfor i, (train_index, val_index) in enumerate(cv.split(X_train, y_train, groups)):\n    X_train_, y_train_ = X_train.iloc[train_index], y_train.iloc[train_index]\n    X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]\n    \n    hgb = HistGradientBoostingRegressor(learning_rate=0.05, random_state=71, max_iter=500)\n    hgb.fit(X_train_, np.log1p(y_train_))\n    y_pred_val = np.expm1(hgb.predict(X_val))\n    y_pred_test += np.expm1(hgb.predict(X_test))\/n_fold\n    \n    y_pred_train[val_index] = y_pred_val\n    score = mean_squared_log_error(y_val, y_pred_val)**0.5\n    scores.append(score)\n    \n    print(\"Fold%d RMSLE: %f\"%(i, score))\n    \nprint(\"Overall RMSLE: %f\u00b1%f\"%(np.mean(scores), np.std(scores)))","b6e172c7":"submission_hgb = pd.read_csv('..\/input\/machine-learning-homework\/sample_submission.csv', index_col=0)\n\nsubmission_hgb.TradePrice = y_pred_test\nsubmission_hgb.to_csv('hgb_submission.csv')","c0d490b5":"submission_hgb.head()","9b0fc2f1":"%%time\n# \u90fd\u9053\u5e9c\u770c\u3067\u533a\u5207\u3063\u3066\u4ea4\u5dee\u691c\u5b9a\u3092\u884c\u3044\u3001\u4e88\u6e2c\u7cbe\u5ea6\u3092\u898b\u7a4d\u3082\u308b\u3002\n# \u540c\u6642\u306b\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066cv averaging\u3092\u884c\u3044\u3001\u4e88\u6e2c\u5024\u3092\u5f97\u308b\u3002\n\nn_fold = 5\ncv = GroupKFold(n_splits=n_fold)\n\ny_pred_train = np.zeros(len(X_train))\ny_pred_test = np.zeros(len(X_test))\nscores = []\n\nfor i, (train_index, val_index) in enumerate(cv.split(X_train, y_train, groups)):\n    X_train_, y_train_ = X_train.iloc[train_index], y_train.iloc[train_index]\n    X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]\n    \n    xgb1 = XGBRegressor(colsample_bylevel=1.0, colsample_bytree=0.5,\n                                learning_rate=0.02, loss='gamma', max_depth=8,\n                                max_bin=256, min_child_weight=1.0, min_split_loss=0.01,\n                                n_estimators=12500, subsample=1.0, tree_method='gpu_hist')   \n\n    xgb1.fit(X_train_, np.log1p(y_train_), early_stopping_rounds=50,\n                                eval_metric='rmsle', eval_set=[(X_val, np.log1p(y_val))])\n    \n    y_pred_val = np.expm1(xgb1.predict(X_val))\n    y_pred_test += np.expm1(xgb1.predict(X_test))\/n_fold\n    \n    y_pred_train[val_index] = y_pred_val\n    score = mean_squared_log_error(y_val, y_pred_val)**0.5\n    scores.append(score)\n    \n    print(\"Fold%d RMSLE: %f\"%(i, score))\n    \nprint(\"Overall RMSLE: %f\u00b1%f\"%(np.mean(scores), np.std(scores)))","18faf459":"# sample submission\u3092\u8aad\u307f\u8fbc\u3093\u3067\u3001\u4e88\u6e2c\u5024\u3092\u4ee3\u5165\u306e\u5f8c\u3001\u4fdd\u5b58\u3059\u308b\nsubmission_xgb1 = pd.read_csv('..\/input\/machine-learning-homework\/sample_submission.csv', index_col=0)\n\nsubmission_xgb1.TradePrice = y_pred_test\nsubmission_xgb1.to_csv('xgb1_submission.csv')","9a0bd811":"submission_xgb1.head()","e18eb266":"%%time\n# \u90fd\u9053\u5e9c\u770c\u3067\u533a\u5207\u3063\u3066\u4ea4\u5dee\u691c\u5b9a\u3092\u884c\u3044\u3001\u4e88\u6e2c\u7cbe\u5ea6\u3092\u898b\u7a4d\u3082\u308b\u3002\n# \u540c\u6642\u306b\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066cv averaging\u3092\u884c\u3044\u3001\u4e88\u6e2c\u5024\u3092\u5f97\u308b\u3002\n\nn_fold = 5\ncv = GroupKFold(n_splits=n_fold)\n\ny_pred_train = np.zeros(len(X_train))\ny_pred_test = np.zeros(len(X_test))\nscores = []\n\nfor i, (train_index, val_index) in enumerate(cv.split(X_train, y_train, groups)):\n    X_train_, y_train_ = X_train.iloc[train_index], y_train.iloc[train_index]\n    X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]\n    \n    xgb2 =  XGBRegressor(colsample_bylevel=1.0, colsample_bytree=0.5,\n                                learning_rate=0.02, loss='poisson', max_depth=None,\n                                max_bin=256, min_child_weight=1.0, min_split_loss=0.01,\n                                n_estimators=12500, subsample=1.0, tree_method='gpu_hist')  \n    \n    xgb2.fit(X_train_, np.log1p(y_train_), early_stopping_rounds=50,\n                                eval_metric='rmsle', eval_set=[(X_val, np.log1p(y_val))])\n    y_pred_val = np.expm1(xgb2.predict(X_val))\n    y_pred_test += np.expm1(xgb2.predict(X_test))\/n_fold\n    \n    y_pred_train[val_index] = y_pred_val\n    score = mean_squared_log_error(y_val, y_pred_val)**0.5\n    scores.append(score)\n    \n    print(\"Fold%d RMSLE: %f\"%(i, score))\n    \nprint(\"Overall RMSLE: %f\u00b1%f\"%(np.mean(scores), np.std(scores))) # True","3999353d":"# sample submission\u3092\u8aad\u307f\u8fbc\u3093\u3067\u3001\u4e88\u6e2c\u5024\u3092\u4ee3\u5165\u306e\u5f8c\u3001\u4fdd\u5b58\u3059\u308b\nsubmission_xgb2 = pd.read_csv('..\/input\/machine-learning-homework\/sample_submission.csv', index_col=0)\n\nsubmission_xgb2.TradePrice = y_pred_test\nsubmission_xgb2.to_csv('xgb2_submission.csv')","79e6d418":"submission_xgb2.head()","7063660a":"%%time\n# \u90fd\u9053\u5e9c\u770c\u3067\u533a\u5207\u3063\u3066\u4ea4\u5dee\u691c\u5b9a\u3092\u884c\u3044\u3001\u4e88\u6e2c\u7cbe\u5ea6\u3092\u898b\u7a4d\u3082\u308b\u3002\n# \u540c\u6642\u306b\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066cv averaging\u3092\u884c\u3044\u3001\u4e88\u6e2c\u5024\u3092\u5f97\u308b\u3002\n\nn_fold = 5\ncv = GroupKFold(n_splits=n_fold)\n\ny_pred_train = np.zeros(len(X_train))\ny_pred_test = np.zeros(len(X_test))\nscores = []\n\nfor i, (train_index, val_index) in enumerate(cv.split(X_train, y_train, groups)):\n    X_train_, y_train_ = X_train.iloc[train_index], y_train.iloc[train_index]\n    X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]\n    \n    xgb3 =  XGBRegressor(colsample_bylevel=1.0, colsample_bytree=0.5,\n                                learning_rate=0.05, loss='gamma', max_depth=12,\n                                max_bin=256, min_child_weight=1.0, min_split_loss=0.01,\n                                n_estimators=12500, subsample=1.0, tree_method='gpu_hist')    \n    \n    xgb3.fit(X_train_, np.log1p(y_train_), early_stopping_rounds=50,\n                                eval_metric='rmse', eval_set=[(X_val, np.log1p(y_val))])\n    y_pred_val = np.expm1(xgb3.predict(X_val))\n    y_pred_test += np.expm1(xgb3.predict(X_test))\/n_fold\n    \n    y_pred_train[val_index] = y_pred_val\n    score = mean_squared_log_error(y_val, y_pred_val)**0.5\n    scores.append(score)\n    \n    print(\"Fold%d RMSLE: %f\"%(i, score))\n    \nprint(\"Overall RMSLE: %f\u00b1%f\"%(np.mean(scores), np.std(scores))) # True","1040fa22":"# sample submission\u3092\u8aad\u307f\u8fbc\u3093\u3067\u3001\u4e88\u6e2c\u5024\u3092\u4ee3\u5165\u306e\u5f8c\u3001\u4fdd\u5b58\u3059\u308b\nsubmission_xgb3 = pd.read_csv('..\/input\/machine-learning-homework\/sample_submission.csv', index_col=0)\n\nsubmission_xgb3.TradePrice = y_pred_test\nsubmission_xgb3.to_csv('xgb3_submission.csv')","68117efd":"submission_xgb3.head()","34bf3eb8":"%%time\n# \u90fd\u9053\u5e9c\u770c\u3067\u533a\u5207\u3063\u3066\u4ea4\u5dee\u691c\u5b9a\u3092\u884c\u3044\u3001\u4e88\u6e2c\u7cbe\u5ea6\u3092\u898b\u7a4d\u3082\u308b\u3002\n# \u540c\u6642\u306b\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066cv averaging\u3092\u884c\u3044\u3001\u4e88\u6e2c\u5024\u3092\u5f97\u308b\u3002\n\nn_fold = 5\ncv = GroupKFold(n_splits=n_fold)\n\ny_pred_train = np.zeros(len(X_train))\ny_pred_test = np.zeros(len(X_test))\nscores = []\n\nfor i, (train_index, val_index) in enumerate(cv.split(X_train, y_train, groups)):\n    X_train_, y_train_ = X_train.iloc[train_index], y_train.iloc[train_index]\n    X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]\n    \n    xgb4 =  XGBRegressor(colsample_bylevel=1.0, colsample_bytree=0.5,\n                                learning_rate=0.01, loss='gamma', max_depth=5,\n                                max_bin=256, min_child_weight=1.0, min_split_loss=0.01,\n                                n_estimators=12500, subsample=1.0, tree_method='gpu_hist')     \n\n    xgb4.fit(X_train_, np.log1p(y_train_), early_stopping_rounds=50,\n                                eval_metric='rmsle', eval_set=[(X_val, np.log1p(y_val))])\n    \n    y_pred_val = np.expm1(xgb4.predict(X_val))\n    y_pred_test += np.expm1(xgb4.predict(X_test))\/n_fold\n    \n    y_pred_train[val_index] = y_pred_val\n    score = mean_squared_log_error(y_val, y_pred_val)**0.5\n    scores.append(score)\n    \n    print(\"Fold%d RMSLE: %f\"%(i, score))\n    \nprint(\"Overall RMSLE: %f\u00b1%f\"%(np.mean(scores), np.std(scores)))","18038daa":"# sample submission\u3092\u8aad\u307f\u8fbc\u3093\u3067\u3001\u4e88\u6e2c\u5024\u3092\u4ee3\u5165\u306e\u5f8c\u3001\u4fdd\u5b58\u3059\u308b\nsubmission_xgb4 = pd.read_csv('..\/input\/machine-learning-homework\/sample_submission.csv', index_col=0)\n\nsubmission_xgb4.TradePrice = y_pred_test\nsubmission_xgb4.to_csv('xgb4_submission.csv')","ecebc53f":"submission_xgb4.head()","af2164b5":"%%time\n# \u90fd\u9053\u5e9c\u770c\u3067\u533a\u5207\u3063\u3066\u4ea4\u5dee\u691c\u5b9a\u3092\u884c\u3044\u3001\u4e88\u6e2c\u7cbe\u5ea6\u3092\u898b\u7a4d\u3082\u308b\u3002\n# \u540c\u6642\u306b\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066cv averaging\u3092\u884c\u3044\u3001\u4e88\u6e2c\u5024\u3092\u5f97\u308b\u3002\n\nn_fold = 5\ncv = GroupKFold(n_splits=n_fold)\n\ny_pred_train = np.zeros(len(X_train))\ny_pred_test = np.zeros(len(X_test))\nscores = []\n\nfor i, (train_index, val_index) in enumerate(cv.split(X_train, y_train, groups)):\n    X_train_, y_train_ = X_train.iloc[train_index], y_train.iloc[train_index]\n    X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]\n    \n    xgb5 =  XGBRegressor(colsample_bylevel=1.0, colsample_bytree=0.5,\n                                learning_rate=0.01, max_depth=15,\n                                max_bin=256, min_child_weight=1.0, min_split_loss=0.01,\n                                n_estimators=12500, subsample=1.0, tree_method='gpu_hist')  \n\n    xgb5.fit(X_train_, np.log1p(y_train_), early_stopping_rounds=200,\n                                eval_metric='rmsle', eval_set=[(X_val, np.log1p(y_val))])\n    \n    y_pred_val = np.expm1(xgb5.predict(X_val))\n    y_pred_test += np.expm1(xgb5.predict(X_test))\/n_fold\n    \n    y_pred_train[val_index] = y_pred_val\n    score = mean_squared_log_error(y_val, y_pred_val)**0.5\n    scores.append(score)\n    \n    print(\"Fold%d RMSLE: %f\"%(i, score))\n    \nprint(\"Overall RMSLE: %f\u00b1%f\"%(np.mean(scores), np.std(scores)))","db5597c1":"# sample submission\u3092\u8aad\u307f\u8fbc\u3093\u3067\u3001\u4e88\u6e2c\u5024\u3092\u4ee3\u5165\u306e\u5f8c\u3001\u4fdd\u5b58\u3059\u308b\nsubmission_xgb5 = pd.read_csv('..\/input\/machine-learning-homework\/sample_submission.csv', index_col=0)\n\nsubmission_xgb5.TradePrice = y_pred_test\nsubmission_xgb5.to_csv('xgb5_submission.csv')","b640ec23":"submission_xgb5.head()","53d821d8":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import r2_score\nfrom sklearn.linear_model import LogisticRegression\n\n#Stack base oredicts for training meta model\n\ndf_sub_concat = pd.concat([submission_xgb1, submission_xgb2,\n                           submission_xgb3, submission_xgb4,\n                           submission_xgb5],axis=1)\ndf_Ave_pred = df_sub_concat.mean(axis=1)\n\n# sample submission\u3092\u8aad\u307f\u8fbc\u3093\u3067\u3001\u4e88\u6e2c\u5024\u3092\u4ee3\u5165\u306e\u5f8c\u3001\u4fdd\u5b58\u3059\u308b\nsubmission_ave = pd.read_csv('..\/input\/machine-learning-homework\/sample_submission.csv', index_col=0)\n\nsubmission_ave.TradePrice = df_Ave_pred\nsubmission_ave.to_csv('ave_submission.csv')","ba6ad679":"submission_ave.head()","cc7aa2f5":"# \u4ee5\u4e0b\u3001XGB\uff08Gamma_Loss\u3001Poisson_Loss)","363e8f5f":"\u6570\u5024\u578b\u306e\u5217\u306e\u6b20\u640d\u5024\u3092\u57cb\u3081\u308b","c7727c9e":"# \u56de\u5e30\u958b\u59cb\uff08\u30d9\u30fc\u30b9\u306fHGB\uff09","7da5a8f3":"# \u4e88\u6e2c\u306e\u5e73\u5747"}}