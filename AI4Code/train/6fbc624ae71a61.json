{"cell_type":{"5123798c":"code","9a2af05f":"code","2647da51":"code","d9a1e411":"code","33ebc270":"code","6ba05f21":"code","42a0740f":"code","6bf44b4d":"code","23b42c99":"code","51b3f01d":"code","c0cfe6bd":"code","6191c5c4":"code","ba02ec8c":"code","af7e4bd1":"code","5778df9e":"code","8f088d45":"code","9341df28":"code","00bfd747":"code","edd1d896":"code","be5a431d":"code","fefa859a":"code","8652cc5a":"code","7b90ed77":"code","1276585d":"code","166cec29":"code","b46b3f92":"code","017489e1":"code","829b4a69":"code","84e13073":"code","5ca922f1":"code","7e3dd1d0":"code","27f840ca":"code","243809a4":"code","173eb4a0":"code","ca9b604b":"code","3d591baa":"code","084ae605":"code","8de388d9":"code","63d8e35f":"code","7334369f":"code","cbb2ea2f":"code","eee89097":"code","4a2356a7":"code","97764d53":"code","f8880f00":"code","4a7ac88a":"code","0919f98a":"code","254b2c77":"code","65382bde":"code","9c150f3b":"code","f07e6e24":"code","ef14d1db":"code","0362c093":"code","1f6ae630":"code","1099bc98":"code","55a8da49":"code","c9790f7b":"code","322906c8":"code","86f8aa19":"code","b4abaf42":"code","07c771e7":"code","fa2827c5":"code","ae8a254f":"code","c9c6bd5b":"code","5de3c678":"code","70274494":"code","9b88c0b5":"code","c1afd8c4":"code","6fd1f5be":"code","522499b7":"code","a6af27f4":"code","9e50dd65":"code","e99bdb26":"code","8571ca00":"code","dfe5be22":"code","5016bd6f":"code","1b673557":"code","8bc14896":"code","20e51f3e":"code","c65a5d4f":"code","4f873f02":"code","8d3c4c25":"code","c0067aec":"code","464e5e8e":"code","65d01ebe":"code","c866bac5":"code","4d371e21":"code","d6f5a28c":"code","f934ed54":"code","22565853":"code","4e3bffc9":"code","fb13533f":"code","99c14451":"code","1c32e540":"code","b3895103":"code","f1060de3":"code","154abbac":"code","5473fe8a":"code","6ded1cd7":"code","f69b6cf7":"code","d573899c":"code","0b5c8b68":"code","52034ec3":"code","984b17cd":"code","7deb9027":"code","5d2d5495":"markdown","4f822afd":"markdown","735a22ec":"markdown","60b2054f":"markdown","4955b0bb":"markdown","7ad390f9":"markdown","9c7d5d7f":"markdown","3630b3d9":"markdown","e8801a4b":"markdown","26cf5024":"markdown","a637e074":"markdown","47065cb6":"markdown","7d8c7cf5":"markdown","ae498025":"markdown","f0d3c951":"markdown","4ab6a079":"markdown","ea0a270b":"markdown","c146eca4":"markdown","ee2a24d6":"markdown","aa33eec8":"markdown","8e22a45b":"markdown","e996d672":"markdown","1efdf35a":"markdown","bb568f04":"markdown","3930c39f":"markdown","e1f01dbe":"markdown","ac6841c6":"markdown","a90fa5b5":"markdown","6ffcfe69":"markdown","66325e3c":"markdown","752752bf":"markdown","5400c80a":"markdown","40e37431":"markdown","ead89bb1":"markdown","f47b835b":"markdown","fb885b7e":"markdown","c611b14b":"markdown","5a978688":"markdown","376c38c2":"markdown","08ae1fca":"markdown","0e9c51af":"markdown","b1173052":"markdown","84a631e4":"markdown","b230c67a":"markdown","ea10ffb6":"markdown","93e58922":"markdown","0ecf9a1e":"markdown","aeb55e72":"markdown","d10c5f1a":"markdown","25b9d005":"markdown","9e7045c2":"markdown","79f0727e":"markdown","c387dce6":"markdown","8a130c7e":"markdown","26d63fed":"markdown","d5be4feb":"markdown","8402d296":"markdown","f1d7acfe":"markdown","35b10e3b":"markdown","7d379b50":"markdown","57d7d436":"markdown","730c0a25":"markdown","9c050434":"markdown","71fab730":"markdown","232685fb":"markdown"},"source":{"5123798c":"import pandas as pd\nimport numpy as np\nimport copy\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\nimport pylab\nimport math\n%matplotlib inline\nimport os","9a2af05f":"print(os.listdir(\"..\/input\"))","2647da51":"wholesale_customer_df = pd.read_csv('..\/input\/WholesaleCustomersData.csv')","d9a1e411":"wholesale_customer_df.head()","33ebc270":"wholesale_customer_df.info()","6ba05f21":"msno.matrix(wholesale_customer_df, figsize = (30,4))","42a0740f":"wholesale_customer_drop_df = copy.deepcopy(wholesale_customer_df)\nwholesale_customer_drop_df","6bf44b4d":"del wholesale_customer_drop_df['Buyer\/Spender']","23b42c99":"wholesale_customer_drop_df","51b3f01d":"wholesale_customer_drop_df['Region'].value_counts()","c0cfe6bd":"wholesale_customer_drop_df['Channel'].value_counts()","6191c5c4":"def categorical_multi(i,j):\n    pd.crosstab(wholesale_customer_drop_df[i],wholesale_customer_drop_df[j]).plot(kind='bar')\n    plt.show()\n    print(pd.crosstab(wholesale_customer_drop_df[i],wholesale_customer_drop_df[j]))\n\ncategorical_multi(i='Channel',j='Region')    ","ba02ec8c":"print('Descriptive Statastics of our Data:')\nwholesale_customer_drop_df.describe().T","af7e4bd1":"print('Descriptive Statastics of our Data including Channel & Retail:')\nwholesale_customer_drop_df.describe(include='all').T","5778df9e":"def plot_distribution(df, cols=5, width=20, height=15, hspace=0.2, wspace=0.5):\n    plt.style.use('seaborn-whitegrid')\n    fig = plt.figure(figsize=(width,height))\n    fig.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=wspace, hspace=hspace)\n    rows = math.ceil(float(df.shape[1]) \/ cols)\n    for i, column in enumerate(df.columns):\n        ax = fig.add_subplot(rows, cols, i + 1)\n        ax.set_title(column)\n        if df.dtypes[column] == np.object:\n            g = sns.countplot(y=column, data=df)\n            substrings = [s.get_text()[:18] for s in g.get_yticklabels()]\n            g.set(yticklabels=substrings)\n            plt.xticks(rotation=25)\n        else:\n            g = sns.distplot(df[column])\n            plt.xticks(rotation=25)\n    \nplot_distribution(wholesale_customer_drop_df, cols=3, width=20, height=20, hspace=0.45, wspace=0.5)","8f088d45":"# Let\u2019s remove the categorical columns:\nproducts = wholesale_customer_drop_df[wholesale_customer_drop_df.columns[+2:wholesale_customer_drop_df.columns.size]]\n\n#Let\u2019s plot the distribution of each feature\ndef plot_distribution(df2, cols=5, width=20, height=15, hspace=0.2, wspace=0.5):\n    plt.style.use('seaborn-whitegrid')\n    fig = plt.figure(figsize=(width,height))\n    fig.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=wspace, hspace=hspace)\n    rows = math.ceil(float(df2.shape[1]) \/ cols)\n    for i, column in enumerate(df2.columns):\n        ax = fig.add_subplot(rows, cols, i + 1)\n        ax.set_title(column)\n        g = sns.boxplot(df2[column])\n        plt.xticks(rotation=25)\n    \nplot_distribution(products, cols=3, width=20, height=10, hspace=0.45, wspace=0.5)","9341df28":"sns.set(style=\"ticks\")\ng = sns.pairplot(products,corner=True,kind='reg')\ng.fig.set_size_inches(15,15)","00bfd747":"# Compute the correlation matrix\ncorr = products.corr()\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, center=0.5,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .6},annot=True)\n\nplt.title(\"Pearson correlation\", fontsize =20)","edd1d896":"print('Descriptive Statastics of our Data:')\nwholesale_customer_drop_df.describe().T","be5a431d":"print('Descriptive Statastics of our Data including Channel & Retail:')\nwholesale_customer_drop_df.describe(include='all').T","fefa859a":"#created Summation of all the products into a new column - Spending\n# there are many ways to create a new column, I have selected the below approach\nwholesale_customer_spending_df = copy.deepcopy(wholesale_customer_drop_df)\nwholesale_customer_spending_df['Spending'] =wholesale_customer_drop_df['Fresh']+wholesale_customer_drop_df['Milk']+wholesale_customer_drop_df['Grocery']+wholesale_customer_drop_df['Frozen']+wholesale_customer_drop_df['Detergents_Paper']+wholesale_customer_drop_df['Delicatessen']\nwholesale_customer_spending_df","8652cc5a":"regiondf = wholesale_customer_spending_df.groupby('Region')['Spending'].sum()\nprint(regiondf)\nprint()\nchanneldf = wholesale_customer_spending_df.groupby('Channel')['Spending'].sum()\nprint(channeldf)","7b90ed77":"region_channel_df = wholesale_customer_spending_df.groupby(['Region','Channel'])['Spending'].sum()\nprint(region_channel_df)\n#different way\n#region_channel_df_1 = wholesale_customer_spending_df.groupby(['Region','Channel']).agg({'Spending' : 'sum'})\n#print(region_channel_df_1)","1276585d":"wholesale_customer_drop_df_1 = copy.deepcopy(wholesale_customer_df)\ndel wholesale_customer_drop_df_1['Buyer\/Spender']","166cec29":"data1 = wholesale_customer_drop_df_1.drop(columns=['Region'])\nmean1 = data1.groupby('Channel').mean()\nmean1.round(2)","b46b3f92":"data2 = wholesale_customer_drop_df_1.drop(columns=['Channel'])\nmean2 = data2.groupby('Region').mean()\nmean2.round(2)","017489e1":"sns.set(style=\"ticks\", color_codes=True)\nsns.catplot(x=\"Channel\", y=\"Fresh\", hue =\"Region\", kind=\"bar\", ci=None, data=wholesale_customer_drop_df)\nplt.title('Item - Fresh')","829b4a69":"sns.catplot(x=\"Channel\", y=\"Fresh\", kind=\"bar\", ci=None, data=wholesale_customer_drop_df)\nplt.title('Item - Fresh')","84e13073":"sns.catplot(x=\"Region\", y=\"Fresh\", kind=\"bar\", ci=None, data=wholesale_customer_drop_df)\nplt.title('Item - Fresh')","5ca922f1":"sns.set(style=\"ticks\", color_codes=True)\nsns.catplot(x=\"Channel\", y=\"Milk\", hue =\"Region\", kind=\"bar\", ci=None, data=wholesale_customer_drop_df)\nplt.title('Item - Milk')","7e3dd1d0":"sns.catplot(x=\"Channel\", y=\"Milk\", kind=\"bar\", ci=None, data=wholesale_customer_drop_df)\nplt.title('Item - Milk')","27f840ca":"sns.catplot(x=\"Region\", y=\"Milk\", kind=\"bar\", ci=None, data=wholesale_customer_drop_df)\nplt.title('Item - Milk')","243809a4":"sns.set(style=\"ticks\", color_codes=True)\nsns.catplot(x=\"Channel\", y=\"Grocery\", hue =\"Region\", kind=\"bar\", ci=None, data=wholesale_customer_drop_df)\nplt.title('Item - Grocery')","173eb4a0":"sns.catplot(x=\"Channel\", y=\"Grocery\", kind=\"bar\", ci=None, data=wholesale_customer_drop_df)\nplt.title('Item - Grocery')","ca9b604b":"sns.catplot(x=\"Region\", y=\"Grocery\", kind=\"bar\", ci=None, data=wholesale_customer_drop_df)\nplt.title('Item - Grocery')","3d591baa":"sns.set(style=\"ticks\", color_codes=True)\nsns.catplot(x=\"Channel\", y=\"Frozen\", hue =\"Region\", kind=\"bar\", ci=None, data=wholesale_customer_drop_df)\nplt.title('Item - Frozen')","084ae605":"sns.catplot(x=\"Channel\", y=\"Frozen\", kind=\"bar\", ci=None, data=wholesale_customer_drop_df)\nplt.title('Item - Frozen')","8de388d9":"sns.catplot(x=\"Region\", y=\"Frozen\", kind=\"bar\", ci=None, data=wholesale_customer_drop_df)\nplt.title('Item - Frozen')","63d8e35f":"sns.set(style=\"ticks\", color_codes=True)\nsns.catplot(x=\"Channel\", y=\"Detergents_Paper\", hue =\"Region\", kind=\"bar\", ci=None, data=wholesale_customer_drop_df)\nplt.title('Item - Detergents_Paper')","7334369f":"sns.catplot(x=\"Channel\", y=\"Detergents_Paper\", kind=\"bar\", ci=None, data=wholesale_customer_drop_df)\nplt.title('Item - Detergents_Paper')","cbb2ea2f":"sns.catplot(x=\"Region\", y=\"Detergents_Paper\", kind=\"bar\", ci=None, data=wholesale_customer_drop_df)\nplt.title('Item - Detergents_Paper')","eee89097":"sns.set(style=\"ticks\", color_codes=True)\nsns.catplot(x=\"Channel\", y=\"Delicatessen\", hue =\"Region\", kind=\"bar\", ci=None, data=wholesale_customer_drop_df)\nplt.title('Delicatessen')","4a2356a7":"sns.catplot(x=\"Channel\", y=\"Delicatessen\", kind=\"bar\", ci=None, data=wholesale_customer_drop_df)\nplt.title('Item - Delicatessen')","97764d53":"sns.catplot(x=\"Region\", y=\"Delicatessen\", kind=\"bar\", ci=None, data=wholesale_customer_drop_df)\nplt.title('Item - Delicatessen')","f8880f00":"standard_deviation_items = products.std() #use standard deviation to check the measure of variabilty\nstandard_deviation_items.round(2)","4a7ac88a":"cv_fresh = np.std(products['Fresh']) \/ np.mean(products['Fresh'])\ncv_fresh","0919f98a":"cv_milk = np.std(products['Milk']) \/ np.mean(products['Milk'])\ncv_milk","254b2c77":"cv_grocery = np.std(products['Grocery']) \/ np.mean(products['Grocery'])\ncv_grocery","65382bde":"cv_frozen = np.std(products['Frozen']) \/ np.mean(products['Frozen'])\ncv_frozen","9c150f3b":"cv_detergents_paper = np.std(products['Detergents_Paper']) \/ np.mean(products['Detergents_Paper'])\ncv_detergents_paper","f07e6e24":"cv_delicatessen = np.std(products['Delicatessen']) \/ np.mean(products['Delicatessen'])\ncv_delicatessen","ef14d1db":"from scipy.stats import variation\nprint(variation(products, axis = 0))","0362c093":"variance_items = products.var()\nvariance_items","1f6ae630":"products.describe().T","1099bc98":"pylab.style.use('seaborn-pastel')\nproducts.plot.area(stacked=False,figsize=(11,5))\npylab.grid(); pylab.show()","55a8da49":"plt.figure(figsize=(15,8))\nsns.boxplot(data=products, orient=\"h\", palette=\"Set2\")","c9790f7b":"def plot_distribution(items, cols=5, width=20, height=15, hspace=0.2, wspace=0.5):\n    plt.style.use('seaborn-whitegrid')\n    fig = plt.figure(figsize=(width,height))\n    fig.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=wspace, hspace=hspace)\n    rows = math.ceil(float(items.shape[1]) \/ cols)\n    for i, column in enumerate(items.columns):\n        ax = fig.add_subplot(rows, cols, i + 1)\n        ax.set_title(column)\n        g = sns.boxplot(items[column])\n        plt.xticks(rotation=25)\n    \nplot_distribution(products, cols=3, width=20, height=10, hspace=0.45, wspace=0.5)","322906c8":"# visual analysis via histogram\nproducts.hist(figsize=(6,6));","86f8aa19":"def out_std(s, nstd=3.0, return_thresholds=False):\n    data_mean, data_std = s.mean(), s.std()\n    cut_off = data_std * nstd\n    lower, upper = data_mean - cut_off, data_mean + cut_off\n    if return_thresholds:\n        return lower, upper\n    else:\n        return [True if x < lower or x > upper else False for x in s]\n\ndef out_iqr(s, k=1.5, return_thresholds=False):\n    # calculate interquartile range\n    q25, q75 = np.percentile(s, 25), np.percentile(s, 75)\n    iqr = q75 - q25\n    # calculate the outlier cutoff\n    cut_off = iqr * k\n    lower, upper = q25 - cut_off, q75 + cut_off\n    if return_thresholds:\n        return lower, upper\n    else: # identify outliers\n        return [True if x < lower or x > upper else False for x in s]","b4abaf42":"# outlier_mask is a boolean list identifies the indices of the outliers\noutlier_mask = out_std(products['Fresh'], nstd=3.0)\n# first 10 elements\noutlier_mask[:10]","07c771e7":"products['Fresh'][outlier_mask]","fa2827c5":"plt.figure(figsize=(8,6))\nsns.distplot(products['Fresh'], kde=False);\nplt.vlines(products['Fresh'][outlier_mask], ymin=0, ymax=110, linestyles='dashed');","ae8a254f":"# outlier_mask is a boolean list identifies the indices of the outliers\noutlier_mask_Milk = out_std(products['Milk'], nstd=3.0)\n# first 10 elements\noutlier_mask_Milk[:10]","c9c6bd5b":"products['Milk'][outlier_mask_Milk]","5de3c678":"plt.figure(figsize=(8,6))\nsns.distplot(products['Milk'], kde=False);\nplt.vlines(products['Milk'][outlier_mask_Milk], ymin=0, ymax=110, linestyles='dashed');","70274494":"# outlier_mask is a boolean list identifies the indices of the outliers\noutlier_mask_Frozen = out_std(products['Frozen'], nstd=3.0)\n# first 10 elements\noutlier_mask_Frozen[:10]","9b88c0b5":"products['Frozen'][outlier_mask_Frozen]","c1afd8c4":"plt.figure(figsize=(8,6))\nsns.distplot(products['Frozen'], kde=False);\nplt.vlines(products['Frozen'][outlier_mask_Frozen], ymin=0, ymax=110, linestyles='dashed');","6fd1f5be":"# outlier_mask is a boolean list identifies the indices of the outliers\noutlier_mask_Grocery= out_std(products['Grocery'], nstd=3.0)\n# first 10 elements\noutlier_mask_Grocery[:10]","522499b7":"products['Grocery'][outlier_mask_Grocery]","a6af27f4":"plt.figure(figsize=(8,6))\nsns.distplot(products['Grocery'], kde=False);\nplt.vlines(products['Grocery'][outlier_mask_Grocery], ymin=0, ymax=110, linestyles='dashed');","9e50dd65":"# outlier_mask is a boolean list identifies the indices of the outliers\noutlier_mask_Detergents_Paper= out_std(products['Detergents_Paper'], nstd=3.0)\n# first 10 elements\noutlier_mask_Detergents_Paper[:10]","e99bdb26":"products['Detergents_Paper'][outlier_mask_Detergents_Paper]","8571ca00":"plt.figure(figsize=(8,6))\nsns.distplot(products['Detergents_Paper'], kde=False);\nplt.vlines(products['Detergents_Paper'][outlier_mask_Detergents_Paper], ymin=0, ymax=110, linestyles='dashed');","dfe5be22":"# outlier_mask is a boolean list identifies the indices of the outliers\noutlier_mask_Delicatessen = out_std(products['Delicatessen'], nstd=3.0)\n# first 10 elements\noutlier_mask_Delicatessen[:10]","5016bd6f":"products['Delicatessen'][outlier_mask_Delicatessen]","1b673557":"plt.figure(figsize=(8,6))\nsns.distplot(products['Delicatessen'], kde=False);\nplt.vlines(products['Delicatessen'][outlier_mask_Delicatessen], ymin=0, ymax=110, linestyles='dashed');","8bc14896":"# For comparison, make one array each using standard deviations of 2.0, 3.0 and 4.0.\nstd2 = products.apply(out_std, nstd=2.0)\nstd3 = products.apply(out_std, nstd=3.0)\nstd4 = products.apply(out_std, nstd=4.0)\n\n# For comparison, make one array each at varying values of k.\niqr1 = products.apply(out_iqr, k=1.5)\niqr2 = products.apply(out_iqr, k=2.0)\niqr3 = products.apply(out_iqr, k=3.0)","20e51f3e":"f, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(ncols=3, nrows=2, figsize=(22, 12));\nax1.set_title('Outliers using 2 standard deviations');\nax2.set_title('Outliers using 3 standard deviations');\nax3.set_title('Outliers using 4 standard deviations');\nax4.set_title('Outliers using a 1.5 IQR cutoff');\nax5.set_title('Outliers using a 2.5 IQR cutoff');\nax6.set_title('Outliers using a 3.0 IQR cutoff');\n\nsns.heatmap(std2, cmap='YlGn', ax=ax1);\nsns.heatmap(std3, cmap='YlGn', ax=ax2);\nsns.heatmap(std4, cmap='YlGn', ax=ax3);\nsns.heatmap(iqr1, cmap='YlGn', ax=ax4);\nsns.heatmap(iqr2, cmap='YlGn', ax=ax5);\nsns.heatmap(iqr3, cmap='YlGn', ax=ax6);\n\nplt.savefig('outliers.png')\nplt.show()","c65a5d4f":"def plot_cutoff(dataframe, col, nstd=2.0, color='red'):\n    lower, upper = out_std(dataframe[col], nstd=nstd, return_thresholds=True)\n    plt.axvspan(min(dataframe[col][dataframe[col] < lower], default=dataframe[col].min()), lower, alpha=0.2, color=color);\n    plt.axvspan(upper, max(dataframe[col][dataframe[col] > upper], default=dataframe[col].max()), alpha=0.2, color=color);","4f873f02":"column = 'Fresh'\nsns.distplot(products[column], kde=False)\nplot_cutoff(products, column, nstd=2.0, color='red');\nplot_cutoff(products, column, nstd=3.0, color='green');\nplot_cutoff(products, column, nstd=4.0, color='yellow');","8d3c4c25":"column = 'Milk'\nsns.distplot(products[column], kde=False)\nplot_cutoff(products, column, nstd=2.0, color='red');\nplot_cutoff(products, column, nstd=3.0, color='green');\nplot_cutoff(products, column, nstd=4.0, color='yellow');","c0067aec":"column = 'Grocery'\nsns.distplot(products[column], kde=False)\nplot_cutoff(products, column, nstd=2.0, color='red');\nplot_cutoff(products, column, nstd=3.0, color='green');\nplot_cutoff(products, column, nstd=4.0, color='yellow');","464e5e8e":"column = 'Frozen'\nsns.distplot(products[column], kde=False)\nplot_cutoff(products, column, nstd=2.0, color='red');\nplot_cutoff(products, column, nstd=3.0, color='green');\nplot_cutoff(products, column, nstd=4.0, color='yellow');","65d01ebe":"column = 'Detergents_Paper'\nsns.distplot(products[column], kde=False)\nplot_cutoff(products, column, nstd=2.0, color='red');\nplot_cutoff(products, column, nstd=3.0, color='green');\nplot_cutoff(products, column, nstd=4.0, color='yellow');","c866bac5":"column = 'Delicatessen'\nsns.distplot(products[column], kde=False)\nplot_cutoff(products, column, nstd=2.0, color='red');\nplot_cutoff(products, column, nstd=3.0, color='green');\nplot_cutoff(products, column, nstd=4.0, color='yellow');","4d371e21":"cols_prd = ['Fresh', 'Milk', 'Grocery', 'Frozen', 'Detergents_Paper', 'Delicatessen']","d6f5a28c":"from sklearn.ensemble import IsolationForest\nfig, axs = plt.subplots(2, 3, figsize=(22, 12), facecolor='w', edgecolor='k')\naxs = axs.ravel()\n\nfor i, column in enumerate(cols_prd):\n    isolation_forest = IsolationForest(contamination='auto')\n    isolation_forest.fit(products[column].values.reshape(-1,1))\n\n    xx = np.linspace(products[column].min(), products[column].max(), len(products)).reshape(-1,1)\n    anomaly_score = isolation_forest.decision_function(xx)\n    outlier_iso_forest = isolation_forest.predict(xx)\n    \n    axs[i].plot(xx, anomaly_score, label='anomaly score')\n    axs[i].fill_between(xx.T[0], np.min(anomaly_score), np.max(anomaly_score), \n                     where=outlier_iso_forest==-1, color='r', \n                     alpha=.4, label='outlier region')\n    axs[i].legend()\n    axs[i].set_title(column)","f934ed54":"wholesale_customer_drop_df.groupby(['Channel', 'Region']).agg(['mean', 'std']).round(1)","22565853":"def hist_plot(column):\n    fig = plt.figure()\n    ax = fig.add_subplot(111) # stands for subplot(1,1,1)\n    ax.hist(products[column], bins=25)\n    plt.title('Histgram plot of ' + column)\n    plt.show()\n\ncolumns = ['Milk', 'Grocery', 'Detergents_Paper']\nfor c in columns:\n    hist_plot(c)","4e3bffc9":"#Display the distribution accross all features\nfeatures = products.columns.values\n\n\nfig = plt.figure(figsize=(15,10))\nfor i in range(len(features)):\n    ax = fig.add_subplot(2,3,i+1)\n    ax.set_title(features[i])\n    ax.hist(products[features[i]], bins = 100)\nplt.show()","fb13533f":"from scipy.stats import iqr\nprint('IQR of Fresh item            ' + str(iqr(wholesale_customer_drop_df['Fresh'])))\nprint('IQR of Milk item             ' + str(iqr(wholesale_customer_drop_df['Milk'])))\nprint('IQR of Grocery item          ' + str(iqr(wholesale_customer_drop_df['Grocery'])))\nprint('IQR of Frozen item           ' + str(iqr(wholesale_customer_drop_df['Frozen'])))\nprint('IQR of Detergents_Paper item ' + str(iqr(wholesale_customer_drop_df['Detergents_Paper'])))\nprint('IQR of Delicatessen item     ' + str(iqr(wholesale_customer_drop_df['Delicatessen'])))\n","99c14451":"print(wholesale_customer_drop_df.skew())","1c32e540":"plt.scatter(x = wholesale_customer_df['Milk'], y = wholesale_customer_df['Grocery'])","b3895103":"from scipy.stats import boxcox, probplot, norm, shapiro\n\nshapiro_test = {}\nplt.figure(figsize=(15, 10))\nfor i in range(0,6):\n    ax = plt.subplot(2,3,i+1)\n    probplot(x = products[products.columns[i]], dist=norm, plot=ax)\n    plt.title(products.columns[i])\n    shapiro_test[products.columns[i]] = shapiro(products[products.columns[i]])\n    \nplt.show()\n\npd.DataFrame(shapiro_test, index=['Test Statistic', 'p-value']).transpose()","f1060de3":"\nproducts_log = np.log(products)\n\nshapiro_test = {}\n\nplt.figure(figsize=(15, 10))\nfor i in range(6):\n    ax = plt.subplot(2,3,i+1)\n    probplot(x = products_log[products_log.columns[i]], dist=norm, plot=ax)\n    plt.title(products_log.columns[i])\n    shapiro_test[products.columns[i]] = shapiro(products[products.columns[i]])\n    \nplt.show()\n\npd.DataFrame(shapiro_test, index=['Test Statistic', 'p-value']).transpose()","154abbac":"from scipy.stats import boxcox\n\nshapiro_test = {}\nlambdas = {}\n\nplt.figure(figsize=(15, 10))\nplt.title('BoxCox Transformation')\nfor i in range(6):\n    ax = plt.subplot(2,3,i+1)\n    x, lbd = boxcox(products[products.columns[i]])\n    probplot(x = x, dist=norm, plot=ax)\n    plt.title(products.columns[i])\n    shapiro_test[products.columns[i]] = shapiro(x)\n    lambdas[products.columns[i]] = lbd\n    \nplt.show()\n\npd.DataFrame(shapiro_test, index=['Test Statistic', 'p-value']).transpose()","5473fe8a":"products.corr()","6ded1cd7":"print('Correlation Heat map of the data')\nplt.figure(figsize=(10,6))\nsns.heatmap(products.corr(),annot=True,fmt='.2f',vmin=-1,vmax=1,cmap='Spectral')\nplt.show()","f69b6cf7":"def scatterplot(i,j):\n    sns.regplot(data=products_log,x=i,y=j)\n    plt.show()","d573899c":"scatterplot(i='Milk',j='Grocery')","0b5c8b68":"scatterplot(i='Milk',j='Detergents_Paper')","52034ec3":"scatterplot(i='Detergents_Paper',j='Grocery')","984b17cd":"pd.plotting.scatter_matrix(products, alpha = 0.3, figsize = (14,8), diagonal = 'kde');","7deb9027":"def plot_corr(df,size=10):\n    '''Function plots a graphical correlation matrix for each pair of columns in the dataframe.\n\n    Input:\n        df: pandas DataFrame\n        size: vertical and horizontal size of the plot'''\n\n    corr = df.corr()\n    fig, ax = plt.subplots(figsize=(size, size))\n    cax = ax.matshow(df, interpolation='nearest')\n    ax.matshow(corr)\n    fig.colorbar(cax)\n    plt.xticks(range(len(corr.columns)), corr.columns);\n    plt.yticks(range(len(corr.columns)), corr.columns);\n\n\n\n\nplot_corr(products)","5d2d5495":"There is strong correlation (0.92)  between the \"detergents and paper products\" and the \"grocery products\"","4f822afd":"### In Channel \"Hotel\" Average Highest Spending in Fresh items and Lowest Spending in Detergents_Paper.\n\n### In Channel \"Retail\" Average Highest Spending in Grocery items and Lowest Spending in Frozen items.","735a22ec":"Visualize the outliers in the context of the Fresh's distribution.","60b2054f":"Use Boxplot to see Outliers:\n\nThe black point is the outliers in boxplot graph.","4955b0bb":"## Univariate","7ad390f9":"The Log-Transformation is also not satisfactorily. Let's try BoxCox transformation:","9c7d5d7f":"Our dataset seems to be complete, let's check the type of data that we have:","3630b3d9":"This is a quick example of what the output of out_std looks like on randomly generated data from a normal distribution.","e8801a4b":"##### ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------","26cf5024":"Product Item Distrubtion","a637e074":"##### Use methods of descriptive statistics to summarize data","47065cb6":"obervation.....","7d8c7cf5":"### 1.3. On the basis of the descriptive measure of variability, which item shows the most inconsistent behaviour?\n###        Which items shows the least inconsistent behaviour?","ae498025":"# Load the data","f0d3c951":"Identify the outliers, notice these values are on both low and high","4ab6a079":"# Problem 1 ","ea0a270b":"##### ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------","c146eca4":"From the graphs on the distribution of product it seems that we have some outliers in the data, let's have a closer look before we decide what to do:","ee2a24d6":"obervation.....","aa33eec8":"There are several paris of features exhibit correlations, such as Milk and Grocery, Milk and Detergents_Paper. It confirms my suspicions.\n\nAll these three features are not normally distributed. Most of the points lie on the left, closer to the minimal value. We can see the skewness of all variables are greater than 1, indicates they are righ skewed.","8e22a45b":"obervation.....","e996d672":"## 1.2. There are 6 different varieties of items are considered.\n## Do all varieties show similar behaviour across Region and Channel?","1efdf35a":"Based on the plot, Fresh item is sold more in the Retail channel ","bb568f04":"Description of variables is as folllows:\n\n- FRESH               : annual spending (m.u.) on fresh products (Continuous);\n- MILK                : annual spending (m.u.) on milk products (Continuous);\n- GROCERY             : annual spending (m.u.)on grocery products (Continuous);\n- FROZEN              : annual spending (m.u.)on frozen products (Continuous);\n- DETERGENTS_PAPER    : annual spending (m.u.) on detergents and paper products (Continuous);\n- DELICATESSEN        : annual spending (m.u.)on and delicatessen products (Continuous);\n- CHANNEL             : customers Channel - Hotel (Hotel\/Restaurant\/Cafe) or Retail channel (Nominal);\n- REGION              : customers Region Lisnon, Oporto or Other (Nominal);\n- BUYER\/SPENDER       : it is showing running id number (assumption it is index) (Continuous);\n\nThe dataset gives data about sales of 6 category of products across 3 regions via 2 channel. ","3930c39f":"Region Frequency\nRegion - total :             440 rows\n                Lisbon        77 rows\n                Oporto        47 rows\n                Other        316 row\n\nChannel Frequency\nChannel -total :             440 rows\n                Hotel        298 rows\n                Retail       142 rows","e1f01dbe":"\u201cFresh\u201d item have lowest coefficient of Variation So that is consistent. \n\n\n\u201cDelicatessen\u201d item have highest coefficient of Variation, So that is Inconsistent.","ac6841c6":"#### Fresh item have highest Standard deviation So that is Inconsistent.\n\n#### Delicatessen item have smallest Standard deviation, So that is consistent.","a90fa5b5":"\n    6 continuous types of feature ('Fresh', 'Milk', 'Grocery', 'Frozen', 'Detergents_Paper', 'Delicassen')\n    2 categoricals features ('Channel', 'Region')\n    1 continuous types of feature (Buyer\/Spender) will be dropped as no use for our analysis\n","6ffcfe69":"Compare Standard Deviation and IQR","66325e3c":"##### ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------","752752bf":"### Highest spend in the Region\/Channel is from Others\/Hotel \n### and lowest spend in the Region\/Channel is from Oporto\/Hotel","5400c80a":"##### Based on coeffiecent of Variation","40e37431":"All the variable are statistically significant non normally distributed.\n\nLet's try the Logarithmic Transformation:","ead89bb1":"Let's use Seaborn pairplot to have a first look at how our data is interracting.","f47b835b":"A detailed visualization of the different standard deviation cutoffs for Fresh, note return_thresholds=True in the outlier function:","fb885b7e":"##### Which Region and which Channel seems to spend more?\n##### Which Region and which Channel seems to spend less?","c611b14b":"### Region Count","5a978688":"## Isolation Forest","376c38c2":"IsolationForest is implemented in scikit-learn. It returns an anomaly_score for each data point. ","08ae1fca":"## 1.1. Use methods of descriptive statistics to summarize data.\n## Which Region and which Channel seems to spend more?\n## Which Region and which Channel seems to spend less?","0e9c51af":"# Bivariate","b1173052":"##### -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------","84a631e4":"Outliers are detected but not necessarily removed, it depends of the situation. Here I will assume that the wholesale distributor provided us a dataset with correct data, so I will keep them as is.","b230c67a":"obervation.....","ea10ffb6":"## Highest spend in the Region is from Others and lowest spend in the region is from Oporto\n## Highest spend in the Channel is from Hotel and lowest spend in the Channel is from Retail.","93e58922":"We are going to start exploring our data with the Univariate analysis (each feature individually), before carrying the Bivariate analysis and compare pairs of features to find correlation between them.","0ecf9a1e":"See Behaviour in all items across Channel and Region use Bar Plot. Here we see that they are different in Channel and Region.","aeb55e72":"From the pairplot above, the correlation between the \"detergents and paper products\" and the \"grocery products\" seems to be pretty strong, meaning that consumers would often spend money on these two types of product. Let's look at the Pearson correlation coefficient to confirm this:","d10c5f1a":"### Yes there are outliers in all the items across the product range (Fresh, Milk, Grocery, Frozen, Detergents_Paper & Delicatessen)\n\n#### Outliers are detected but not necessarily removed, it depends of the situation. Here I will assume that the wholesale distributor provided us a dataset with correct data, so I will keep them as is.","25b9d005":"### 1.4. Are there any outliers in the data?","9e7045c2":"Define two functions below (out_std & out_iqr) that statistically identify outliers in a pandas Series using a standard deviation and interquartile range method.\n\nBoth functions return a list of boolean values","79f0727e":"This intermediate level data set has 440 rows and 9 columns. \nThe data set refers to clients of a wholesale distributor. It includes the annual spending in monetary units (m.u.) on diverse product categories.\nThis data set is recommended for learning and practicing your skills in exploratory data analysis, data visualization.\nThe Following data dictionary gives more details on this data set:","c387dce6":"From the above two describe function, we can infer the following\n- Channel has two unique values, with \"Hotel\" as most frequent with 298 out of 440 transactions. i.e 67.7 percentage of spending comes from \"Hotel\" channel.\n\n- Retail has three unique values, with \"Other\" as most frequent with 316 out of 440 transactions. i.e.71.8 percentage of spending comes from \"Other\" region.\n\n- Fresh item (440 records), \n    \n    has a mean of 12000.3, standard deviation of 12647.3, with min value of 3 and max value of 112151 . \n    \n    The other aspect is Q1(25%) is 3127.75, Q3(75%) is 16933.8, with Q2(50%) 8504\n    \n    range = max-min =112151-3=112,148 & IQR = Q3-Q1 = 16933.8-3127.75 = 13,806.05 (this helpful in calculating the outlier(1.5 IQR Lower\/Upper limit))\n    \n    \n- Milk item (440 records),\n\n    has a mean of 5796.27, standard deviation of 7380.38, with min value of 55 and max value of 73498. \n    \n    The other aspect is Q1(25%) is 1533, Q3(75%) is 7190.25, with Q2(50%) 3627\n    \n    range = max-min =73498-55=73443 & IQR = Q3-Q1 = 7190.25-1533 = 5657.25 (this helpful in calculating the outlier(1.5 IQR Lower\/Upper limit))\n    \n    \n- Grocery item (440 records),\n\n    has a mean of 7951.28, standard deviation of 9503.16, with min value of 3 and max value of 92780. \n    \n    The other aspect is Q1(25%) is 2153, Q3(75%) is 10655.8, with Q2(50%) 4755.5\n    \n    range = max-min =92780-3=92777 & IQR = Q3-Q1 = 10655.8-2153 = 8502.8 (this helpful in calculating the outlier(1.5 IQR Lower\/Upper limit))\n    \n\n- Frozen (440 records),\n\n    has a mean of 3071.93, standard deviation of 4854.67, with min value of 25 and max value of 60869. \n    \n    The other aspect is Q1(25%) is 742.25, Q3(75%) is 3554.25, with Q2(50%) 1526\n    \n    range = max-min =60869-25=60844 & IQR = Q3-Q1 = 3554.25-742.25 = 2812 (this helpful in calculating the outlier(1.5 IQR Lower\/Upper limit))\n    \n\n- Detergents_Paper (440 records),\n\n    has a mean of 2881.49, standard deviation of 4767.85, with min value of 3 and max value of 40827. \n    \n    The other aspect is Q1(25%) is 256.75, Q3(75%) is 3922, with Q2(50%) 816.5\n    \n    range = max-min =40827-3=40824 & IQR = Q3-Q1 = 3922-256.75 = 3665.25 (this helpful in calculating the outlier(1.5 IQR Lower\/Upper limit))\n    \n    \n    \n- Delicatessen (440 records),\n\n    has a mean of 1524.87, standard deviation of 2820.11, with min value of 3 and max value of 47943. \n    \n    The other aspect is Q1(25%) is 408.25, Q3(75%) is 1820.25, with Q2(50%) 965.5\n    \n    range = max-min =47943-3=47940 & IQR = Q3-Q1 = 1820.25-408.25 = 1412 (this helpful in calculating the outlier(1.5 IQR Lower\/Upper limit))   \n    \n    ","8a130c7e":"# EDA","26d63fed":"obervation.....","d5be4feb":"Our project goal is to analysis the data and answer the questions asked.Thus, there is no outcome to be predicted, and the EDA just tries to find patterns in the data.","8402d296":"# Check for missing values ","f1d7acfe":"Measure of Central Tendency - Mean, Median, mode\nMeasure of Dispersion - Range, IQR, Standard Deviation\n","35b10e3b":"obervation.....","7d379b50":"# Import the Libraries ","57d7d436":"### Channel Count","730c0a25":"##### ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------","9c050434":"### In Region \"Lisbon\" Average Highest Spending in Fresh and Lowest in Delicatessen items.\n\n### In Region \"Oporto\" Average Highest Spending in Fresh and Lowest in Delicatessen items.\n\n### In Region \"Other\" Average Highest Spending in Fresh and Lowest in Delicatessen items.","71fab730":"### Standard Deviation","232685fb":"# Summary of dataset "}}