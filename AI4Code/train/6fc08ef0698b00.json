{"cell_type":{"ac531540":"code","e90ad743":"code","4ce5b7e6":"code","e62cc5ba":"code","bc30d80c":"code","359d23f1":"code","52f3dfca":"code","85d4875a":"code","f80ade20":"code","a360815c":"code","00992c2d":"code","16519e4d":"code","f11254de":"code","c3ae0a7b":"code","0d6ea25c":"code","d385a408":"code","6fd87e5c":"code","adb50fdf":"code","d4971434":"code","9005201a":"code","4e189721":"code","0ba85082":"code","2517da63":"code","a0d34424":"code","17643167":"markdown","712944ca":"markdown","c1b64ab1":"markdown","0715efa0":"markdown","9aebbfe7":"markdown","81efbb40":"markdown","19562d45":"markdown","0d456d70":"markdown","dcd0a5d6":"markdown"},"source":{"ac531540":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import r2_score, mean_squared_error, accuracy_score\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, cross_val_predict","e90ad743":"bike_df = pd.read_csv('\/kaggle\/input\/london-bike-sharing-dataset\/london_merged.csv')\n\nbike_df.head()","4ce5b7e6":"# no of rows and columns\n\nbike_df.shape","e62cc5ba":"# information about database\n\nbike_df.info()","bc30d80c":"# print some statistical data\n\nbike_df.describe()","359d23f1":"# changning time to datatime object\n\nbike_df['timestamp'] = pd.to_datetime(bike_df['timestamp'], format='%Y-%m-%d %H:%M:%S')\n\ntype(bike_df['timestamp'].iloc[0])","52f3dfca":"# Checking for missing values\n\nbike_df.isnull().sum()","85d4875a":"# getting hour, month, year and days of week from timestamp column\n\nbike_df['hour'] = bike_df['timestamp'].apply(lambda time : time.hour)\n\nbike_df['month'] = bike_df['timestamp'].apply(lambda time : time.month)\n\nbike_df['year'] = bike_df['timestamp'].apply(lambda time : time.year)\n\nbike_df['day_of_week'] = bike_df['timestamp'].apply(lambda time : time.dayofweek)","f80ade20":"# checking the dataframe\n\nbike_df.head()","a360815c":"bike_df['day_of_week'].value_counts()","00992c2d":"# plotting corelation metrix\n\nfig, ax = plt.subplots(figsize= (12, 10))\nsns.heatmap(bike_df.corr(), annot=True, ax=ax)","16519e4d":"# renaming columns\n\nbike_df.rename(columns={'cnt': 'bikes_count'}, inplace=True)\nbike_df","f11254de":"# selecting row with max humidity\n\nbike_df.iloc[bike_df['hum'].idxmax()]\n\n# we can see that if the humidity is high bike count is low","c3ae0a7b":"# selecting the row with min humidity\n\nbike_df.iloc[bike_df['hum'].idxmin()]","0d6ea25c":"# dropping timestamp columns\n\nbike_df.drop('timestamp', axis=1, inplace=True)","d385a408":"# seperate dependent and independent varaible \n\nx = bike_df.drop('bikes_count', axis=1)\ny = bike_df['bikes_count']","6fd87e5c":"# seperate train and test split\n\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, random_state = 42)","adb50fdf":"# create an instance of decision tree regressor\n\ntree_regressor = DecisionTreeRegressor()\n\n# fit the model\n\ntree_regressor.fit(x_train, y_train)\n\n# predict with \n\ny_predict_test = tree_regressor.predict(x_test)\ny_predict_train = tree_regressor.predict(x_train)","d4971434":"# Evaluation of train set\nprint('Evaluation of train set')\nprint('R-square coefficient of determintion: ', r2_score(y_train, y_predict_train))\nprint('Mean squared error: ', mean_squared_error(y_train, y_predict_train))\nprint('Root Mean squared error: ', np.sqrt(mean_squared_error(y_train, y_predict_train)))\n\n# Evaluation of test set\nprint('\\n \\nEvaluation of test set')\nprint('R-square coefficient of determintion: ', r2_score(y_test, y_predict_test))\nprint('Mean squared error: ', mean_squared_error(y_test, y_predict_test))\nprint('Root Mean squared error: ', np.sqrt(mean_squared_error(y_test, y_predict_test)))\n","9005201a":"fig, ax = plt.subplots(figsize = (12, 10))\nax.scatter(y_test, y_predict_test, color = 'blue', edgecolors=(0, 0, 0))\nax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=3)\nax.set_xlabel('Actual')\nax.set_ylabel('Predicted')\nax.set_title(\"Ground Truth vs Predicted\")\nplt.show()","4e189721":"# actual vs predicted value\n\nactual_predict = pd.DataFrame(data = {'actual': y_test, 'predicted': y_predict_test})\n\nactual_predict.head()","0ba85082":"# parameters of decision tree \n\nparam_grid = {\"criterion\": [\"mse\", \"mae\"],\n              \"min_samples_split\": [10, 15, 20, 30, 40],\n              \"max_depth\": [2, 4, 6, 8, 10, 11],\n              \"min_samples_leaf\": [10, 20,30, 40, 60, 100],\n              \"max_leaf_nodes\": [5, 20, 30, 100],\n              }","2517da63":"# Randome search\n\nrandom_search = RandomizedSearchCV(tree_regressor, param_grid, cv=5)\n\nrandom_search.fit(x_test, y_test)","a0d34424":"# print the r square and best paramater\n\nprint('R-square:', random_search.best_score_)\nprint('Best parameter values {}'.format(random_search.best_params_))","17643167":"# Model evaluation","712944ca":"# London Bike sharing demand predicton\n## Machine learning algorithms for prediction of bike sharing demand in London.","c1b64ab1":"# Loading Data","0715efa0":"# Exploring data","9aebbfe7":"# Hyper paramater tunning","81efbb40":"### Since the Randome searchCV is not helping us in imporving the model  we wont be using these parameter","19562d45":"# Loading Libraries","0d456d70":"# spliting train and test data","dcd0a5d6":"# Plotting actual vs predicted data"}}