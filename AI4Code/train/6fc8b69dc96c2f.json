{"cell_type":{"992ff51c":"code","6eb6547e":"code","7bf950f0":"code","2acd53ca":"code","4693728c":"code","5b98df08":"code","52e85e8e":"code","ad5798f1":"code","66151174":"code","02939d25":"code","f1a20fb8":"code","8baadc81":"code","0d338b19":"code","60a1b71a":"code","cf803925":"code","17b639ab":"code","9cf1bfc7":"code","676d27fc":"code","45838361":"code","53ccfa08":"code","b3a24eff":"code","bc901cb9":"code","8dbca84b":"code","ca5e4a1b":"code","b61bc31c":"code","7584df92":"code","c44c29a6":"code","f0ff3b6e":"markdown","0051dbe6":"markdown","82e57c50":"markdown","fb475cf4":"markdown","09bb0573":"markdown"},"source":{"992ff51c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6eb6547e":"#Load necessary libraries\n\nimport nltk\nfrom nltk import FreqDist\nimport spacy\nimport matplotlib.pyplot as plt\nimport seaborn as sns","7bf950f0":"# View the data set\n\nwines=pd.read_csv(\"\/kaggle\/input\/wine-reviews\/wine reviews.csv\")\nwines.head()","2acd53ca":"wines.drop(\"Sl.No.\",axis=1,inplace=True)","4693728c":"# function to plot most frequent terms\n\ndef freq_words(x, terms = 30):\n  all_words = ' '.join([text for text in x])\n  all_words = all_words.split()\n\n  fdist = FreqDist(all_words)\n  words_df = pd.DataFrame({'word':list(fdist.keys()), 'count':list(fdist.values())})\n\n  # selecting top 20 most frequent words\n  d = words_df.nlargest(columns=\"count\", n = terms) \n  plt.figure(figsize=(20,5))\n  ax = sns.barplot(data=d, x= \"word\", y = \"count\")\n  ax.set(ylabel = 'Count')\n  plt.show()","5b98df08":"wines['Reviews Text'].fillna(\"Good\",inplace=True)\nwines['Reviews Title'].fillna(\"Neutral\",inplace=True)","52e85e8e":"freq_words(wines['Reviews Text'])","ad5798f1":"freq_words(wines['Reviews Title'])","66151174":"# remove unwanted characters, numbers and symbols\nwines['Reviews Text'] = wines['Reviews Text'].str.replace(\"[^a-zA-Z#]\", \" \")\nwines['Reviews Title'] = wines['Reviews Title'].str.replace(\"[^a-zA-Z#]\", \" \")","02939d25":"from nltk.corpus import stopwords\nstop_words = stopwords.words('english')","f1a20fb8":"# function to remove stopwords\ndef remove_stopwords(rev):\n    rev_new = \" \".join([i for i in rev if i not in stop_words])\n    return rev_new","8baadc81":"# remove short words (length < 3)\nwines['Reviews Text'] = wines['Reviews Text'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>2]))\nwines['Reviews Title'] = wines['Reviews Title'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>2]))\n\n# remove stopwords from the text\nreviewstext = [remove_stopwords(r.split()) for r in wines['Reviews Text']]\nreviewstitle = [remove_stopwords(r.split()) for r in wines['Reviews Title']]\n\n# make entire text lowercase\nreviewstext = [r.lower() for r in reviewstext]\nreviewstitle = [r.lower() for r in reviewstitle]","0d338b19":"freq_words(reviewstext, 35)","60a1b71a":"freq_words(reviewstitle, 35)","cf803925":"nlp = spacy.load('en', disable=['parser', 'ner'])\n\n# filter noun and adjective\ndef lemmatization(texts, tags=['NOUN', 'ADJ']): \n       output = []\n       for sent in texts:\n             doc = nlp(\" \".join(sent)) \n             output.append([token.lemma_ for token in doc if token.pos_ in tags])\n       return output","17b639ab":"tokenized_reviewstext = pd.Series(reviewstext).apply(lambda x: x.split())\nprint(tokenized_reviewstext[4])","9cf1bfc7":"tokenized_reviewstitle = pd.Series(reviewstitle).apply(lambda x: x.split())\nprint(tokenized_reviewstitle[6])","676d27fc":"reviewstextlem = lemmatization(tokenized_reviewstext)\nprint(reviewstextlem[5])","45838361":"reviewstitlelem = lemmatization(tokenized_reviewstitle)\nprint(reviewstitlelem[10])","53ccfa08":"reviewslemtext = []\nfor i in range(len(reviewstextlem)):\n    reviewslemtext.append(' '.join(reviewstextlem[i]))\n\nwines['reviewstext'] = reviewslemtext\n\nfreq_words(wines['reviewstext'], 35)","b3a24eff":"reviewslemtitle = []\nfor i in range(len(reviewstitlelem)):\n    reviewslemtitle.append(' '.join(reviewstitlelem[i]))\n\nwines['reviewstitle'] = reviewslemtitle\n\nfreq_words(wines['reviewstitle'], 35)","bc901cb9":"import PIL\nfrom PIL import Image\nfrom wordcloud import WordCloud, ImageColorGenerator","8dbca84b":"#Use a image for masking\nwine_mask = np.array(Image.open(\"\/kaggle\/input\/wineimage\/wineimage.jpg\"))\n","ca5e4a1b":"text = \" \".join(review for review in wines.reviewstext)","b61bc31c":"\n# Create a word cloud image using a mask\nwc = WordCloud(background_color=\"white\", max_words=1000, mask=wine_mask)\n               \n\n# Generate a wordcloud\nwc.generate(text)\n\n# store to file\nwc.to_file(\"\/kaggle\/working\/winereviews.jpg\")\n\n# display the image\nplt.figure(figsize=[20,10])\nplt.imshow(wc, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","7584df92":"texttitle = \" \".join(review for review in wines.reviewstitle)","c44c29a6":"# Generate a word cloud image without masking\nwordcloud = WordCloud(background_color=\"black\").generate(texttitle)\n\n\nplt.figure(figsize=(10,10))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","f0ff3b6e":"**Most common words are in the Review text are \"I',\u2018the\u2019, \u2018and\u2019, \u2018a\u2019, etc. In Review Title it is more specific such as, \"Great\", \"Best\", although there are terms like \"the\" and \"I\". These terms are not relevant and they do not tell details about the review. So its important to eliminate these terms as well as numbers, punctuations, and other special characters from the text.**","0051dbe6":"**You can explore more NLP techniques such as topic modeling using this data set.\nFor working on wordclouds refer https:\/\/www.datacamp.com\/community\/tutorials\/wordcloud-python**","82e57c50":"**Now the words are more relevant though there is some more noise. The reviews seem dominated by positive comments. The review text is topped by the word lips maybe due to the reviews given for the lip balm. We can use lemmatization and tokenization to further fine tune the data set.**\n> \n> **Tokenization is the process of breaking a sentences into words. Lemmatization converts words in the second or third forms to their first form variants. **\n\n**These tasks can be achieved using the SpaCy library.**","fb475cf4":"**Now let's generate WordClouds for the processed reveiws.**","09bb0573":"**Online shopping has increased its presence a notch higher after Covid19. Customers rely mostly on online reviews before zeroing on any product. This is applicable for any services bought online. This kernel explores some of the essential steps required for text preprocessing, which is key for any NLP project. Here I will work on a set of Wine reviews collected online. This dataset contains reviews for few other products also like lib balm and food wine though its dominated by reviews for alcohol. This kernel aims to quickly extract the key information covered by the reviews without having to go through all of them manually.**"}}