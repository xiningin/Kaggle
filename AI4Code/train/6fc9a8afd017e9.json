{"cell_type":{"6e9fa311":"code","3b36423b":"code","7054cc4b":"code","9c2a1cf7":"code","9c4cdecd":"code","43c901a0":"code","ffedfc15":"code","168fa543":"code","42f2e11a":"code","6e7322eb":"code","7fbb09ec":"code","f819e550":"markdown","18c97cc6":"markdown","f4855283":"markdown","2b9e33ac":"markdown","c2b89809":"markdown","3bda5df8":"markdown","5b854ef0":"markdown","ccace4eb":"markdown","d0eb6123":"markdown"},"source":{"6e9fa311":"# conventional imports\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","3b36423b":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_dir = \"..\/input\/dogs-cats-images\/dataset\/training_set\"\ntest_dir = \"..\/input\/dogs-cats-images\/dataset\/test_set\"\nIMG_WIDTH, IMG_HEIGHT = 128, 128\nBATCH_SIZE = 200\ntrain_generator = ImageDataGenerator(\n    rescale=1.\/255,\n    horizontal_flip=True,\n    zoom_range=0.2,\n    shear_range=0.2,\n    rotation_range=20,\n    validation_split=0.2\n)\ntest_generator = ImageDataGenerator(\n    rescale=1.\/255\n)\ntrain_data = train_generator.flow_from_directory(\n    train_dir,\n    target_size=(IMG_WIDTH, IMG_HEIGHT),\n    batch_size=BATCH_SIZE,\n    class_mode=\"binary\",\n    subset='training',# training subset\n)\nval_data = train_generator.flow_from_directory(\n    train_dir,\n    target_size=(IMG_WIDTH, IMG_HEIGHT),\n    batch_size=BATCH_SIZE,\n    class_mode=\"binary\",\n    subset='validation',# validation subset\n)\ntest_data = test_generator.flow_from_directory(\n    test_dir,\n    target_size=(IMG_WIDTH, IMG_HEIGHT),\n    batch_size=BATCH_SIZE,\n    class_mode=\"binary\",\n)","7054cc4b":"fig = plt.figure(figsize=(16, 10))\nrows, cols = 2, 2\nfig.add_subplot(rows, cols, 1)\n# showing image\nplt.imshow(train_data[0][0][0])\nplt.axis('off')\nplt.title(\"First\")\n\nfig.add_subplot(rows, cols, 2)\n# showing image\nplt.imshow(train_data[0][0][0])\nplt.axis('off')\nplt.title(\"Second\")\n\nfig.add_subplot(rows, cols, 3)\n# showing image\nplt.imshow(train_data[0][0][0])\nplt.axis('off')\nplt.title(\"Third\")\n\nfig.add_subplot(rows, cols, 4)\n# showing image\nplt.imshow(train_data[0][0][0])\nplt.axis('off')\nplt.title(\"Fourth\")","9c2a1cf7":"model = keras.Sequential([\n    layers.Conv2D(64, (3,3), input_shape=[IMG_WIDTH, IMG_HEIGHT, 3]),\n    layers.MaxPooling2D(2,2),\n    \n    layers.Conv2D(32, (3,3)),\n    layers.MaxPooling2D(2,2),\n    \n    layers.Conv2D(32, (3,3)),\n    layers.MaxPooling2D(2,2),\n    \n    layers.Conv2D(16, (3,3)),\n    layers.MaxPooling2D(2,2),\n    \n    layers.Flatten(),\n    layers.Dense(128, activation=\"relu\"),\n    layers.Dense(1, activation=\"sigmoid\")\n])\nmodel.summary()","9c4cdecd":"model.compile(\n    optimizer=\"adam\",\n    loss=\"binary_crossentropy\",\n    metrics=[\"binary_accuracy\"]\n)\nhistory = model.fit(\n    train_data,\n    epochs=25,\n    validation_data=val_data\n)","43c901a0":"history = pd.DataFrame(history.history)\nhistory.loc[:, ['loss', 'val_loss']].plot()\nhistory.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot()","ffedfc15":"loss, acc = model.evaluate(test_data)\nprint(acc)","168fa543":"path = \"..\/input\/dogs-cats-images\/dataset\/test_set\/cats\/cat.4001.jpg\"\nimage = tf.io.read_file(path)\nimage = tf.io.decode_jpeg(image)\nplt.axis(False)\nplt.imshow(image)\nplt.show()\nimage = tf.image.resize(image, size=[128, 128])\nimage.shape\nx = tf.expand_dims(image, axis=0)\n","42f2e11a":"prediction = model.predict(x)\nindex = round(prediction[0][0])\n[\"cat\", \"dog\"][index]","6e7322eb":"path = \"..\/input\/dogs-cats-images\/dataset\/test_set\/dogs\/dog.4021.jpg\"\nimage = tf.io.read_file(path)\nimage = tf.io.decode_jpeg(image)\nplt.axis(False)\nplt.imshow(image)\nplt.show()\nimage = tf.image.resize(image, size=[128, 128])\nimage.shape\nx = tf.expand_dims(image, axis=0)","7fbb09ec":"prediction = model.predict(x)\nindex = round(prediction[0][0])\n[\"cat\", \"dog\"][index]","f819e550":"# Training the model\nHere we are training the model on train data and for validation, we are using valdation dataset.","18c97cc6":"As you can see, it is doing pretty well. ^_^","f4855283":"Let's test it on some images...","2b9e33ac":"# Reading data...\n\nReading data from the dataset using `ImageDataGenerator` <br>\nAlso, here I am performing **data augmentation** to train our model on a greater data than we already have. Here, we are \n* Flipping the image horizontally\n* Zooming upto 20%\n* Shearing upto 20%\n* Rotating upto 20 degrees\n\nNOTE: The rescale parameter in the `ImageDataGenerator` is to make all the numbers in an image from 0-1 instead of 0-255","c2b89809":"# Plotting the training history\n\nThese graphs will tell us if our model is overfitting or underfitting","3bda5df8":"# Plotting augmented data\n\nThe code below shows the result of all the 4 augmentations.","5b854ef0":"# Creating the model\n\nHere I am creating a model with the following layers.","ccace4eb":"As you can see, we have achieved 82% of accuracy which can be improved...","d0eb6123":"# Evaluating the model\n\nUsing the test data to evaluate the accuracy of our model"}}