{"cell_type":{"5c2ed0a1":"code","87fad165":"code","c78fac1d":"code","34904dac":"code","f2092343":"code","de660313":"code","c488880c":"code","5fb9bba4":"code","f417faa5":"code","7931af28":"code","81951fd8":"code","b1e9ecee":"code","e75d8532":"code","2f4b7214":"code","0dfdb6ff":"code","a1f32a0b":"code","496fe4a7":"code","880ad74c":"code","093b2ae1":"code","b3e260e5":"code","a8c67d9d":"code","2e77df2a":"code","b385fb95":"code","7148143a":"code","92e17244":"code","cba489c4":"code","f37c849e":"code","d5f45104":"code","a7cb15d7":"code","c2894c02":"code","a55e5559":"code","d7d529d8":"markdown","d66288b0":"markdown","eb28af6e":"markdown","bc4a181f":"markdown","ce930213":"markdown","5504ee94":"markdown","ccc49027":"markdown","31264879":"markdown","f5f50117":"markdown","10ef0f7a":"markdown","9dc52d45":"markdown","8d776815":"markdown","538b90bf":"markdown","f6465e4d":"markdown","b7ee2aaa":"markdown","cf2e9bcc":"markdown","bac6636a":"markdown","09912d64":"markdown"},"source":{"5c2ed0a1":"!pip install tensorflow-gpu==2.6 &> \/dev\/null\n!pip install gpflow &> \/dev\/null\n# Little hack so that it works on GPU\n!echo \"__version__ = '2.3.0'\" > \/opt\/conda\/lib\/python3.7\/site-packages\/gpflow\/versions.py\n# Same but for CPU\n# !cp -r \/opt\/conda\/lib\/python3.7\/site-packages\/tensorboard-2.7.0.dist-info\/ \/opt\/conda\/lib\/python3.7\/site-packages\/tensorboard-2.4.1.dist-info\/\n!pip install gpflux &> \/dev\/null\n!echo \"__version__ = '0.2.4'\" > \/opt\/conda\/lib\/python3.7\/site-packages\/gpflux\/version.py","87fad165":"# Basic libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Neural network libraries\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n# Reading images and creating video libraries\nimport cv2\nfrom IPython.display import HTML\nfrom base64 import b64encode\nimport matplotlib.animation as animation\nimport os\n\nimport SimpleITK as sitk","c78fac1d":"def play(filename):\n    html = ''\n    video = open(filename,'rb').read()\n    src = 'data:video\/mp4;base64,' + b64encode(video).decode()\n    html += '<video width=500 controls autoplay loop><source src=\"%s\" type=\"video\/mp4\"><\/video>' % src \n    return HTML(html)\n\ndef create_video(imgs, output='\/kaggle\/working\/predicted.mp4', duration=30, subplot=True, \n                frame_delay=200):\n    fig, ax = plt.subplots(figsize=(15, 10))\n    ims = []\n    if not subplot:\n        shape = imgs.shape[0]\n        for i in range(duration):\n            im = ax.imshow(imgs[i % shape], animated=True)\n            ims.append([im])\n        plt.close(fig)\n    else:\n        shapes = [imgs[views[0]].shape[0], imgs[views[1]].shape[0], \n                  imgs[views[2]].shape[0], imgs[views[3]].shape[0]]\n        fig, ax = plt.subplots(2,2, figsize=(10,10))\n        for k in range(duration):\n            im_ = []\n            for i in range(2):\n                for j in range(2):\n                    im = ax[i,j].imshow(imgs[views[2*i+j]][k % shapes[2*i+j]], animated=True)\n                    im_.append(im)\n                    ax[i,j].set_title(views[2*i+j])\n                    plt.close()\n            ims.append(im_)\n\n    ani = animation.ArtistAnimation(fig, ims, interval=frame_delay, blit=True, repeat_delay=1000)\n\n    ani.save(output)","34904dac":"target = pd.read_csv('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train_labels.csv')\npreds = pd.read_csv('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/sample_submission.csv')","f2092343":"# specify your image path\nviews = ['FLAIR', 'T1w', 'T1wCE', 'T2w']\ndef load_imgs(idx, ignore_zeros=True, train=True):\n    imgs = {}\n    for view in views:\n        save_ds = []\n        if train:\n            dir_path = os.walk(os.path.join(\n            '..\/input\/rsna-miccai-png\/train\/', idx, view\n        ))\n        else:\n            dir_path = os.walk(os.path.join(\n            '..\/input\/rsna-miccai-png\/test\/', idx, view\n        ))\n        for path, subdirs, files in dir_path:\n            for name in files:\n                image_path = os.path.join(path, name) \n                ds = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n                save_ds.append(np.array(ds))\n        if len(save_ds) == 0:\n            save_ds = np.zeros((1,256,256))\n        imgs[view] = np.array(save_ds)\n    return imgs","de660313":"# %%time\n#\u00a0for i in range(32):\n#     idx = str(target.BraTS21ID[i]).zfill(5)\n#     imgs = load_imgs(idx)","c488880c":"# Pathological one\nidx = str(109).zfill(5)\nimgs = load_imgs(idx)","5fb9bba4":"fig, ax = plt.subplots(2,2, figsize=(10,10))\nfor i in range(2):\n    for j in range(2):\n        m = ax[i,j].imshow(imgs[views[2*i+j]].mean(axis=0))\n        ax[i,j].set_title(views[2*i+j])\nplt.show()","f417faa5":"create_video(imgs, duration=60, subplot=True, frame_delay=300)\nplay('predicted.mp4')","7931af28":"!pip install efficientnet &> \/dev\/null","81951fd8":"from sklearn.preprocessing import StandardScaler\n\nclass DataGenerator3D(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, labels=None, batch_size=256, dim=(512,512,512), n_channels=1,\n                 n_classes=2, shuffle=True, is_train=True):\n        'Initialization'\n        self.dim = dim\n        self.batch_size = batch_size\n        self.labels = labels\n        self.is_train = (labels is not None)\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) \/ self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        list_IDs_temp = self.list_IDs[index*self.batch_size:(index+1)*self.batch_size]\n\n        X = self.__data_generation(list_IDs_temp)\n        # Generate data\n        if self.is_train:\n            y = self.labels[index*self.batch_size:(index+1)*self.batch_size]\n            return np.array(X), np.array(y, dtype='float64')\n        else:\n            return np.array(X)\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n\n        # Generate data\n        for i, ID in enumerate(list_IDs_temp):\n            # Store sample\n            idx = str(ID).zfill(5)\n            imgs = load_imgs(idx, ignore_zeros=False, train=self.is_train)\n            new_imgs = []\n            for ii in range(2):\n                for jj in range(2):\n                    if (ii == 1 and jj == 1):\n                        img_ = imgs[views[2*ii+jj]]\n                        img_ = np.array([cv2.resize(img_[k], dsize=(self.dim[1],self.dim[0]), interpolation=cv2.INTER_LINEAR) for k in range(img_.shape[0])])\n                        img_ = np.array([cv2.resize(img_.transpose(1,2,0)[k], dsize=(self.dim[2],self.dim[1]), interpolation=cv2.INTER_LINEAR) for k in range(self.dim[0])])\n\n                        # Removing radiofrequency inhomogeneity using N4 Bias Field Correction \n                        for p in range(len(img_)):\n                            inputImage = sitk.GetImageFromArray(img_[p])\n                            maskImage = sitk.GetImageFromArray((img_[p] >0.1) * 1)\n                            inputImage = sitk.Cast(inputImage, sitk.sitkFloat32)\n                            maskImage = sitk.Cast(maskImage, sitk.sitkUInt8)\n                            corrector = sitk.N4BiasFieldCorrectionImageFilter()\n                            numberFittingLevels = 4\n                            maxIter = 100\n                            if maxIter is not None:\n                                corrector.SetMaximumNumberOfIterations([maxIter]\n                                                                       * numberFittingLevels)\n                            corrected_image = corrector.Execute(inputImage, maskImage)\n                            img_[p] = sitk.GetArrayFromImage(corrected_image)\n\n                        # Normalization\n                        sc = StandardScaler()\n                        img_ = np.array([sc.fit_transform(img_[i]) for i in range(img_.shape[0])])\n\n                        new_imgs.append(img_)\n            new_imgs = np.concatenate(new_imgs).transpose(1,2,0).reshape((*self.dim,-1))\n            X[i,] = new_imgs\n        \n        return X","b1e9ecee":"target_red = target[288:(288+288)]","e75d8532":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(target_red.BraTS21ID, target_red.MGMT_value,\n                                                 test_size=0.3, random_state=0,\n                                                 stratify=target_red.MGMT_value)","2f4b7214":"dim=(32,32,34)\nbatch_size=24\ntrain_dataset = DataGenerator3D(X_train, y_train, batch_size=batch_size, dim=dim)\nval_dataset = DataGenerator3D(X_val, y_val, batch_size=batch_size, dim=dim)\ntest_dataset = DataGenerator3D(preds.BraTS21ID, batch_size=batch_size, dim=dim)","0dfdb6ff":"import efficientnet.tfkeras as efn\n\nwith tf.device('\/gpu:0'):\n    def effNet(inp):\n        inp = tf.reshape(tf.transpose(inp, perm=(0,3,1,2,4)), shape=(-1,dim[0], dim[1], 3))\n        return efn.EfficientNetB0(include_top=False, pooling='avg')(inp)","a1f32a0b":"with tf.device('\/gpu:0'):\n    \n    def build_model():\n        inp = keras.Input(shape=(*dim,3))\n        intermediate = effNet(inp)\n        out = layers.Dense(1, activation='sigmoid')(intermediate)\n        out = tf.reshape(out, shape=(-1,dim[2],out.shape[1]))\n        out = layers.maximum(tf.unstack(out, axis=1))\n        return keras.Model(inputs=inp, outputs=out)\n    \n    model = build_model()\n    \n    earlyStopping = EarlyStopping(patience=2, min_delta=0.001, verbose=1)\n    \n    checkpoint_path = \"training_0\/cp.ckpt\"\n    checkpoint_dir = os.path.dirname(checkpoint_path)\n    # model.load_weights(checkpoint_path)\n\n    # Create a callback that saves the model's weights\n    cp_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                                 save_best_only=True,\n                                                 save_weights_only=True,\n                                                 verbose=1)\n    \n    model.compile(\n        optimizer='adam', \n        loss='binary_crossentropy',\n        metrics=[keras.metrics.AUC()]\n        )\n    \n    #history = model.fit(train_dataset, validation_data=val_dataset,\n    #                             epochs=10, callbacks=[earlyStopping, cp_callback])","496fe4a7":"with tf.device('\/gpu:0'):\n    D = 128\n    \n    def attention(inp):\n        out = layers.Dense(D, activation='tanh')(inp)\n        out = layers.Dense(1)(out)\n        out = tf.reshape(out, shape=(-1,dim[2]))\n        return tf.nn.softmax(out, axis=1)\n    \n    def build_model():\n        inp = keras.Input(shape=(*dim,3))\n        H = effNet(inp)\n        A = attention(H)\n        H = tf.reshape(H, shape=(-1,dim[2], H.shape[1]))\n        A = tf.expand_dims(A, axis=1)\n        intermediate = tf.linalg.matmul(A,H)\n        intermediate = tf.squeeze(intermediate, axis=1)\n        out = layers.Dense(1, activation='sigmoid')(intermediate)\n        return keras.Model(inputs=inp, outputs=out)\n    \n    model = build_model()\n    \n    earlyStopping = EarlyStopping(patience=2, min_delta=0.001, verbose=1)\n    \n    checkpoint_path = \"training_1\/cp.ckpt\"\n    checkpoint_dir = os.path.dirname(checkpoint_path)\n\n    # Create a callback that saves the model's weights\n    cp_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                                 save_weights_only=True,\n                                                 verbose=1)\n\n    model.compile(\n        optimizer='adam', \n        loss='binary_crossentropy',\n        metrics=[keras.metrics.AUC()]\n        )\n    \n    # history = model.fit(train_dataset, validation_data=val_dataset,\n    #                              epochs=3, callbacks=[earlyStopping, cp_callback])","880ad74c":"import gpflow\nimport gpflux\n\nfrom gpflow.config import default_float\n\n# Default float must be same type or it will give errors from time to time\ngpflow.config.set_default_float(\"float32\")\ntf.keras.backend.set_floatx(\"float32\")","093b2ae1":"X = np.linspace(-10,10,1000)\nY = np.sin(X) + np.random.randn(1000) \/ 2","b3e260e5":"X = (X - X.mean()) \/ X.std()\nnum_data = X.shape\ninput_dim = 1","a8c67d9d":"num_data = len(X)\nnum_inducing = 10\noutput_dim = 1\n\nkernel = gpflow.kernels.SquaredExponential()\ninducing_variable = gpflow.inducing_variables.InducingPoints(\n    np.ones((num_inducing,1))\n)\ngp_layer = gpflux.layers.GPLayer(\n    kernel, inducing_variable, num_data=num_data, num_latent_gps=1\n)","2e77df2a":"likelihood = gpflow.likelihoods.Gaussian(0.1)\n\n# So that Keras can track the likelihood variance, we need to provide the likelihood as part of a \"dummy\" layer:\nlikelihood_container = gpflux.layers.TrackableLayer()\nlikelihood_container.likelihood = likelihood\n\ndef build_model():\n    inp = keras.Input(shape=(input_dim))\n    x = layers.Dense(100, activation=\"relu\")(inp)\n    x = layers.Dense(100, activation=\"relu\")(x)\n    x = layers.Dense(1, activation=\"linear\")(x)\n    x = gp_layer.predict(x)\n    # These two operations are to make the covariance matrix appear in the layers output later on\n    x = tf.concat([x[0], x[1]], axis=0)\n    x, y = tf.split(x, 2,axis=0)\n    out = likelihood_container(x)\n    return keras.Model(inputs=inp, outputs=out)\n\nmodel = build_model()\nloss = gpflux.losses.LikelihoodLoss(likelihood)","b385fb95":"model.compile(loss=loss, optimizer=\"adam\")\nhist = model.fit(X, Y, epochs=100, verbose=0)\nplt.plot(hist.history[\"loss\"])\nplt.show()","7148143a":"from tensorflow.keras import backend as K\ndef get_all_outputs(model, input_data, learning_phase=1):\n    outputs = [layer.output for layer in model.layers[1:]] # exclude Input\n    layers_fn = K.function([model.input], outputs)\n    return layers_fn([input_data])\n\ndef get_layer_outputs(model, layer_name, input_data, learning_phase=1):\n    outputs   = [layer.output for layer in model.layers if layer_name in layer.name]\n    layers_fn = K.function([model.input], outputs)\n    return layers_fn([input_data])","92e17244":"def plot(model, X, Y, ax=None):\n    if ax is None:\n        fig, ax = plt.subplots()\n\n    x_margin = 0.2\n    N_test = 100\n    X_test = np.linspace(X.min() - x_margin, X.max() + x_margin, N_test).reshape(-1, 1)\n    f_distribution = model(X_test)\n\n    mean = f_distribution.numpy().squeeze()\n    var = np.max(get_layer_outputs(model, 'tf.linalg.adjoint_', X_test)[0],axis=1).squeeze() + model.layers[-1].likelihood.variance.numpy()\n    X_test = X_test.squeeze()\n    lower = mean - 2 * np.sqrt(var)\n    upper = mean + 2 * np.sqrt(var)\n\n    ax.set_ylim(Y.min() - 0.5, Y.max() + 0.5)\n    ax.plot(X, Y, \"kx\", alpha=0.5)\n    ax.plot(X_test, mean, \"C1\")\n\n    ax.fill_between(X_test, lower, upper, color=\"C1\", alpha=0.3)\n\n\n# plot(model, X, Y)","cba489c4":"with tf.device('\/gpu:0'):\n    num_data = 4\n    num_inducing = 4\n    output_dim = 1\n\n    kernel = gpflow.kernels.SquaredExponential()\n    inducing_variable = gpflow.inducing_variables.InducingPoints(\n        np.ones((num_inducing,1))\n    )\n    gp_layer = gpflux.layers.GPLayer(\n        kernel, inducing_variable, num_data=num_data * dim[2], num_latent_gps=output_dim\n    )\n    \n    likelihood = gpflow.likelihoods.Bernoulli()\n\n    # So that Keras can track the likelihood variance, we need to provide the likelihood as part of a \"dummy\" layer:\n    likelihood_container = gpflux.layers.TrackableLayer()\n    likelihood_container.likelihood = likelihood\n\n    def build_model():\n        inp = keras.Input(shape=(*dim,3))\n        latent = effNet(inp)\n        latent = layers.Dense(1, activation='sigmoid')(latent)\n        out = gp_layer.predict(latent)\n        out = out[0]\n        out = tf.reshape(out, shape=(-1,dim[2],out.shape[1]))\n        out = layers.maximum(tf.unstack(out, axis=1))\n        out = likelihood_container(out)\n        return keras.Model(inputs=inp, outputs=out)\n    \n    model = build_model()\n    \n    earlyStopping = EarlyStopping(patience=2, min_delta=0.001, verbose=1)\n    \n    checkpoint_path = \"training_2\/cp.ckpt\"\n    checkpoint_dir = os.path.dirname(checkpoint_path)\n    # model.load_weights(checkpoint_path)\n\n    # Create a callback that saves the model's weights\n    cp_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                                 save_best_only=True,\n                                                 save_weights_only=True,\n                                                 verbose=1)\n    \n    loss = gpflux.losses.LikelihoodLoss(likelihood)\n    model.compile(\n        optimizer='adam', \n        loss=loss,\n        metrics=[keras.metrics.AUC()]\n        )\n    \n    #history = model.fit(train_dataset, validation_data=val_dataset,\n    #                             epochs=10, callbacks=[earlyStopping, cp_callback])","f37c849e":"class ClusteringLayer(layers.Layer):\n    \"\"\"\n    Clustering layer converts input sample (feature) to soft label.\n\n    # Example\n    ```\n        model.add(ClusteringLayer(n_clusters=10))\n    ```\n    # Arguments\n        n_clusters: number of clusters.\n        weights: list of Numpy array with shape `(n_clusters, n_features)` witch represents the initial cluster centers.\n        alpha: degrees of freedom parameter in Student's t-distribution. Default to 1.0.\n    # Input shape\n        2D tensor with shape: `(n_samples, n_features)`.\n    # Output shape\n        2D tensor with shape: `(n_samples, n_clusters)`.\n    \"\"\"\n\n    def __init__(self, n_clusters, weights=None, alpha=1.0, **kwargs):\n        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n        super(ClusteringLayer, self).__init__(**kwargs)\n        self.n_clusters = n_clusters\n        self.alpha = alpha\n        self.initial_weights = weights\n        self.input_spec = layers.InputSpec(ndim=2)\n\n    def build(self, input_shape):\n        assert len(input_shape) == 2\n        input_dim = input_shape[1]\n        self.input_spec = layers.InputSpec(dtype=K.floatx(), shape=(None, input_dim))\n        self.clusters = self.add_weight(shape=(self.n_clusters, input_dim), initializer='glorot_uniform', name='clusters')\n        if self.initial_weights is not None:\n            self.set_weights(self.initial_weights)\n            del self.initial_weights\n        self.built = True\n\n    def call(self, inputs, **kwargs):\n        \"\"\" student t-distribution, as same as used in t-SNE algorithm.        \n                 q_ij = 1\/(1+dist(x_i, \u00b5_j)^2), then normalize it.\n                 q_ij can be interpreted as the probability of assigning sample i to cluster j.\n                 (i.e., a soft assignment)\n        Arguments:\n            inputs: the variable containing data, shape=(n_samples, n_features)\n        Return:\n            q: student's t-distribution, or soft labels for each sample. shape=(n_samples, n_clusters)\n        \"\"\"\n        q = 1.0 \/ (1.0 + (K.sum(K.square(K.expand_dims(inputs, axis=1) - self.clusters), axis=2) \/ self.alpha))\n        q **= (self.alpha + 1.0) \/ 2.0\n        q = K.transpose(K.transpose(q) \/ K.sum(q, axis=1)) # Make sure each sample's 10 values add up to 1.\n        return q\n\n    def compute_output_shape(self, input_shape):\n        assert input_shape and len(input_shape) == 2\n        return input_shape[0], self.n_clusters\n\n    def get_config(self):\n        config = {'n_clusters': self.n_clusters}\n        base_config = super(ClusteringLayer, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))","d5f45104":"with tf.device('\/gpu:0'):\n    num_data = 4\n    num_inducing = num_data\n    output_dim = 1\n\n    kernel = gpflow.kernels.SquaredExponential()\n    inducing_variable = gpflow.inducing_variables.InducingPoints(\n        np.ones((num_inducing,1))\n    )\n    gp_layer = gpflux.layers.GPLayer(\n        kernel, inducing_variable, num_data=num_data * dim[2], num_latent_gps=output_dim\n    )\n    \n    likelihood = gpflow.likelihoods.Bernoulli()\n\n    # So that Keras can track the likelihood variance, we need to provide the likelihood as part of a \"dummy\" layer:\n    likelihood_container = gpflux.layers.TrackableLayer()\n    likelihood_container.likelihood = likelihood\n\n    def build_model():\n        inp = keras.Input(shape=(*dim,3))\n        latent = effNet(inp)\n        latent = ClusteringLayer(2, name='clustering')(latent)\n        latent = layers.Dense(1, activation='sigmoid')(latent)\n        out = gp_layer.predict(latent)\n        out = out[0]\n        out = tf.reshape(out, shape=(-1,dim[2],out.shape[1]))\n        out = layers.maximum(tf.unstack(out, axis=1))\n        out = likelihood_container(out)\n        return keras.Model(inputs=inp, outputs=out)\n    \n    model = build_model()\n    \n    earlyStopping = EarlyStopping(patience=2, min_delta=0.001, verbose=1)\n    \n    checkpoint_path = \"training_2\/cp.ckpt\"\n    checkpoint_dir = os.path.dirname(checkpoint_path)\n    # model.load_weights(checkpoint_path)\n\n    # Create a callback that saves the model's weights\n    cp_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                                 save_best_only=True,\n                                                 save_weights_only=True,\n                                                 verbose=1)\n    \n    loss = gpflux.losses.LikelihoodLoss(likelihood)\n    model.compile(\n        optimizer='adam', \n        loss=loss,\n        metrics=[keras.metrics.AUC()]\n        )\n    \n    #history = model.fit(train_dataset, validation_data=val_dataset,\n    #                             epochs=10, callbacks=[earlyStopping, cp_callback])","a7cb15d7":"def conv(inp, n, n_out):\n    x = inp\n    for i in range(n):\n        x = layers.BatchNormalization()(x)\n        x = layers.Conv2D(\n                n_out, (5,5), padding='same'\n            )(x)\n        x = layers.Dropout(0.2)(x)\n        x = layers.Activation('relu')(x)\n    return x\n\ndef pool(inp):\n    return layers.MaxPool2D(\n                pool_size=(2, 2), strides=None, padding='valid'\n            )(inp)\n\ndef dense(inp, n_neur, drop=0.2, act='relu'):\n    x = layers.BatchNormalization()(inp)\n    x = layers.Dense(n_neur)(x)\n    x = layers.Dropout(drop)(x)\n    return layers.Activation(act)(x)\n\ndef VGG(inp):\n    inp = tf.reshape(tf.transpose(inp, perm=(0,3,1,2,4)), shape=(-1,dim[0], dim[1], 1))\n    x = conv(inp, 2, 16)\n    x = pool(x)\n    \n    x = conv(x, 3, 32)\n    x = pool(x)\n    \n    x = layers.Flatten()(x)\n    return dense(x, 1, 0.4, act='linear')","c2894c02":"with tf.device('\/gpu:0'):\n    num_data = batch_size\n    num_inducing = 10\n    output_dim = 1\n\n    kernel = gpflow.kernels.SquaredExponential()\n    inducing_variable = gpflow.inducing_variables.InducingPoints(\n        np.ones((num_inducing,output_dim))\n    )\n    gp_layer = gpflux.layers.GPLayer(\n        kernel, inducing_variable, num_data=num_data * dim[2], num_latent_gps=output_dim\n    )\n    \n    likelihood = gpflow.likelihoods.Bernoulli()\n\n    # So that Keras can track the likelihood variance, we need to provide the likelihood as part of a \"dummy\" layer:\n    likelihood_container = gpflux.layers.TrackableLayer()\n    likelihood_container.likelihood = likelihood","a55e5559":"with tf.device('\/gpu:0'):\n\n    def build_model():\n        inp = keras.Input(shape=(*dim,3))\n        latent = VGG(inp)\n        out = gp_layer.predict(latent)\n        out = out[0]\n        out = tf.reshape(out, shape=(-1,dim[2],out.shape[1]))\n        out = layers.maximum(tf.unstack(out, axis=1))\n        out = layers.Activation('sigmoid')(out)\n        out = likelihood_container(out)\n        return keras.Model(inputs=inp, outputs=out)\n    \n    model = build_model()\n    \n    earlyStopping = EarlyStopping(patience=2, min_delta=0.001, verbose=1)\n    \n    checkpoint_path = \"training_4\/cp.ckpt\"\n    checkpoint_dir = os.path.dirname(checkpoint_path)\n    # model.load_weights(checkpoint_path)\n\n    # Create a callback that saves the model's weights\n    cp_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                                 save_best_only=True,\n                                                 save_weights_only=True,\n                                                 verbose=1)\n    \n    loss = gpflux.losses.LikelihoodLoss(likelihood)\n    model.compile(\n        optimizer='adam', \n        loss=loss,\n        metrics=[keras.metrics.AUC(), 'accuracy']\n        )\n    \n    history = model.fit(train_dataset, validation_data=val_dataset,\n                                 epochs=30, callbacks=[earlyStopping, cp_callback])","d7d529d8":"## Utility functions to visualize the images\n\nI display a video with a collection of the images of each folder.","d66288b0":"## Example of Image Visualization","eb28af6e":"### Usual train-validation split","bc4a181f":"#### Toy Example","ce930213":"### Model #2\n\nThe maximum is substituted by an attention layer.","5504ee94":"### Model #4\n\nGaussian process but using clustering to select the inducing points.","ccc49027":"### EfficientNet","31264879":"# RSNA MICCAI Brain Tumor Radiogenomic Classification\n\n[<img src=\"https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/29653\/logos\/header.png?t=2021-07-07-17-26-56\">](http:\/\/google.com.au\/)\n\nIn this notebook I will try to classify the images using differente EfficientNet models. To deal with 3D data I will try several method:\n* Using the maximum as its last layer\n* Adding and attention layer\n* Concatenating the neural network with a gaussian process\n\n## Importing necessary libraries","f5f50117":"### Model #1\n\nApply efficientNet to each band of the image, then take the maximum.","10ef0f7a":"Here we try loading 32 images to see how much it takes. This will be the base to set the batch size later on so that each iteration is less expensive in time.","9dc52d45":"## Read images utility function","8d776815":"# Example of Video Visualization","538b90bf":"## Simpler model\n\nLet's try with a simplified version of VGG for the CNN.","f6465e4d":"## DataGenerator3D\n\nSince the data is massive we need to use a data generator. In the preprocessing we fetch all the images to the same dimensions and reduce bias using N4 Bias Field Correction. Apart from that the values of the images are zero mean and unit variance.\n\nNote: Since we need 3 channels I am just erasing the last one.","b7ee2aaa":"### Model #3\n\nIt's the model #1 plus a gaussian process. I am using the library GPFlux to do so.\n\nNote: Install gpflow before loading any library, otherwise it won't work","cf2e9bcc":"Also, there are some folders without images. For those we simply define a zero-valued image so that the models work fine.","bac6636a":"#### Real data","09912d64":"## Labels"}}