{"cell_type":{"ffd33d82":"code","dae0c6bd":"code","f9e62b43":"code","b449f936":"code","90288faf":"code","848960de":"code","89e2e8bf":"code","d9d67819":"code","79d44f42":"code","fa95e7db":"code","03415175":"code","dcb7ddff":"code","def53e29":"code","220d5191":"code","ee4d0c17":"code","3f21f701":"code","81cc7e9a":"code","0d3945de":"code","e5d4c160":"code","3d1a98be":"code","8dd9ed15":"code","3852cba1":"code","dc801e8e":"code","e6c8b1ad":"markdown","bd078dc4":"markdown","93941711":"markdown","3832d0ca":"markdown","c03bd1e4":"markdown","f6032e62":"markdown","86a99295":"markdown","1dc85bb8":"markdown","22502be8":"markdown"},"source":{"ffd33d82":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dae0c6bd":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"darkgrid\")\nplt.style.use('ggplot')\n\nimport cufflinks as cf\nimport plotly.express as px\nimport plotly.offline as py\nfrom plotly.offline import plot\nimport plotly.graph_objects as go\nimport plotly.graph_objs as go\n\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold, GridSearchCV, RandomizedSearchCV\nfrom sklearn.metrics import f1_score, roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, RobustScaler\nfrom sklearn.utils.multiclass import type_of_target\n\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator","f9e62b43":"#Df\ntrain_df = pd.read_csv(\"..\/input\/covid-19-nlp-text-classification\/Corona_NLP_train.csv\", encoding='latin1')\ntest_df = pd.read_csv(\"..\/input\/covid-19-nlp-text-classification\/Corona_NLP_test.csv\")\ntrain_df.head()","b449f936":"train_df.info()","90288faf":"print(\"We have :\", train_df.shape[0], \"Tweets in the Train set\")\nprint(\"We have :\", test_df.shape[0], \"Tweets in the Test set\")","848960de":"train_df = train_df.drop([\"ScreenName\", \"UserName\"], axis=1)\ntrain_df.head()","89e2e8bf":"test_df = test_df.drop([\"ScreenName\", \"UserName\"], axis=1)\ntest_df.head()","d9d67819":"wc = pd.read_csv(\"..\/input\/world-cities\/world-cities_csv.csv\")\nwc = wc.drop([\"geonameid\"], axis=1)\nwc.head()","79d44f42":"wc = pd.read_csv(\"..\/input\/world-cities\/world-cities_csv.csv\")\nwc.head()\n\nwc_uae = wc[wc[\"country\"] == \"United Arab Emirates\"]\nwc_usa = wc[wc[\"country\"] == \"United States\"]\nwc_uk = wc[wc[\"country\"] == \"United Kingdom\"]\nwc_can = wc[wc[\"country\"] == \"Canada\"]\nwc_afr = wc[(wc[\"country\"] == \"South Africa\") | (wc[\"country\"] == \"Central African Republic\")]\nwc_pak = wc[wc[\"country\"] == \"Pakistan\"]\nwc_ind = wc[wc[\"country\"] == \"India\"]\nwc_fra = wc[wc[\"country\"] == \"France\"]\nwc_ger = wc[wc[\"country\"] == \"Germany\"]\nwc_aus = wc[wc[\"country\"] == \"Australia\"]\nwc_chi = wc[wc[\"country\"] == \"China\"]\nwc_nig = wc[wc[\"country\"] == \"Nigeria\"]\nwc_spa = wc[wc[\"country\"] == \"Spain\"]\nwc_arg = wc[wc[\"country\"] == \"Argentina\"]","fa95e7db":"def encoding_location(item):\n    for i in wc_uae[\"name\"]:\n        if str(i) in str(item):\n            return \"UAE\"\n    for i in wc_uae[\"subcountry\"]:\n        if str(i) in str(item):\n            return \"UAE\"\n    for i in wc_usa[\"name\"]:\n        if str(i) in str(item):\n            return \"USA\"\n    for i in wc_usa[\"subcountry\"]:\n        if str(i) in str(item):\n            return \"USA\"\n    for i in wc_uk[\"name\"]:\n        if str(i) in str(item):\n            return \"UK\"\n    for i in wc_uk[\"subcountry\"]:\n        if str(i) in str(item):\n            return \"UK\"\n    for i in wc_can[\"name\"]:\n        if str(i) in str(item):\n            return \"CAN\"\n    for i in wc_can[\"subcountry\"]:\n        if str(i) in str(item):\n            return \"CAN\"\n    for i in wc_afr[\"name\"]:\n        if str(i) in str(item):\n            return \"AFR\"\n    for i in wc_afr[\"subcountry\"]:\n        if str(i) in str(item):\n            return \"AFR\"\n    for i in wc_ind[\"name\"]:\n        if str(i) in str(item):\n            return \"IND\"\n    for i in wc_ind[\"subcountry\"]:\n        if str(i) in str(item):\n            return \"IND\"\n    for i in wc_pak[\"name\"]:\n        if str(i) in str(item):\n            return \"PAK\"\n    for i in wc_pak[\"subcountry\"]:\n        if str(i) in str(item):\n            return \"PAK\"\n    for i in wc_fra[\"name\"]:\n        if str(i) in str(item):\n            return \"FRA\"\n    for i in wc_fra[\"subcountry\"]:\n        if str(i) in str(item):\n            return \"FRA\"\n    for i in wc_ger[\"name\"]:\n        if str(i) in str(item):\n            return \"GER\"\n    for i in wc_ger[\"subcountry\"]:\n        if str(i) in str(item):\n            return \"GER\"\n    for i in wc_aus[\"name\"]:\n        if str(i) in str(item):\n            return \"AUS\"\n    for i in wc_aus[\"subcountry\"]:\n        if str(i) in str(item):\n            return \"AUS\"\n    for i in wc_chi[\"name\"]:\n        if str(i) in str(item):\n            return \"CHI\"\n    for i in wc_chi[\"subcountry\"]:\n        if str(i) in str(item):\n            return \"CHI\"\n    for i in wc_nig[\"name\"]:\n        if str(i) in str(item):\n            return \"NIG\"\n    for i in wc_nig[\"subcountry\"]:\n        if str(i) in str(item):\n            return \"NIG\"\n    for i in wc_spa[\"name\"]:\n        if str(i) in str(item):\n            return \"SPA\"\n    for i in wc_spa[\"subcountry\"]:\n        if str(i) in str(item):\n            return \"SPA\"\n    for i in wc_arg[\"name\"]:\n        if str(i) in str(item):\n            return \"ARG\"\n    for i in wc_arg[\"subcountry\"]:\n        if str(i) in str(item):\n            return \"ARG\"\n    for i in wc[\"country\"]:\n        if str(i) not in str(item):\n            return \"Other\"\n    if \"?\" in str(item):\n        return \"Other\"\n    elif \"World\" in str(item) \\\n    or \"Global\" in str(item) \\\n    or \"Everywhere\" in str(item) \\\n    or \"Earth\" in str(item) \\\n    or \"Planet \" in str(item):\n        return \"GLO\"\n    elif \"France\" in str(item):\n        return \"FRA\"\n    elif \"Australia\" in str(item):\n        return \"AUS\"\n    elif \"Canada\" in str(item):\n        return \"CAN\"\n    else:\n        return item\n    \ntrain_df[\"Location\"] = train_df[\"Location\"].apply(encoding_location)\ntest_df[\"Location\"] = test_df[\"Location\"].apply(encoding_location)\n\ntrain_df[\"Location\"].value_counts()[:50]","03415175":"#Graph : Country by tweets\nfig = px.bar(train_df[\"Location\"].value_counts()[:10], orientation=\"v\", color=train_df[\"Location\"].value_counts()[:10], color_continuous_scale=px.colors.sequential.Plasma, \n             log_x=False, labels={'value':'Count', \n                                'index':'Country',\n                                 'color':'None'\n                                })\n\nfig.update_layout(\n    font_color=\"black\",\n    title_font_color=\"red\",\n    legend_title_font_color=\"green\",\n    title_text=\"Country by tweets\"\n)\n\nfig.show()","dcb7ddff":"#Graph : Sentiment by count\nfig = px.bar(train_df[\"Sentiment\"].value_counts(), orientation=\"v\", color=train_df[\"Sentiment\"].value_counts(), color_continuous_scale=px.colors.sequential.Plasma, \n             log_x=False, labels={'value':'Count', \n                                'index':'Sentiment',\n                                 'color':'None'\n                                })\n\nfig.update_layout(\n    font_color=\"black\",\n    title_font_color=\"red\",\n    legend_title_font_color=\"green\",\n    title_text=\"Sentiment by count\"\n)\n\nfig.show()","def53e29":"def encoding_sentiment(item):\n    if item == \"Extremely Negative\" \\\n    or item == \"Negative\":\n        return 0\n    elif item == \"Neutral\":\n        return 1\n    elif item == \"Positive\" \\\n    or item == \"Extremely Positive\":\n        return 2\n    \ntrain_df[\"Sentiment\"] = train_df[\"Sentiment\"].apply(encoding_sentiment)\ntest_df[\"Sentiment\"] = test_df[\"Sentiment\"].apply(encoding_sentiment)\n\ntrain_df[\"Sentiment\"].value_counts()","220d5191":"import re\n\ndef hash_finder(text):\n    line=re.findall(r'(?<=#)\\w+',text)\n    return \" \".join(line)\n\ntrain_df['hash'] = train_df['OriginalTweet'].apply(lambda x:hash_finder(x))","ee4d0c17":"#Graph : Hashtags by count (without tweet withtout #)\nfig = px.bar(train_df['hash'].value_counts()[1:20], orientation=\"v\", color=train_df['hash'].value_counts()[1:20], color_continuous_scale=px.colors.sequential.Plasma, \n             log_y=True, labels={'value':'Count', \n                                'index':'Hashtags',\n                                 'color':'None'\n                                })\n\nfig.update_layout(\n    font_color=\"black\",\n    title_font_color=\"red\",\n    legend_title_font_color=\"green\",\n    title_text=\"Hashtags by count\"\n)\n\nfig.show()","3f21f701":"def mentions_finder(text):\n    line=re.findall(r'(?<=@)\\w+',text)\n    return \" \".join(line)\ntrain_df['mention'] = train_df['OriginalTweet'].apply(lambda x:mentions_finder(x))","81cc7e9a":"#Graph : Mentions by count (without tweet withtout #)\nfig = px.bar(train_df['mention'].value_counts()[1:20], orientation=\"v\", color=train_df['mention'].value_counts()[1:20], color_continuous_scale=px.colors.sequential.Plasma, \n             log_y=True, labels={'value':'Count', \n                                'index':'Mentions',\n                                 'color':'None'\n                                })\n\nfig.update_layout(\n    font_color=\"black\",\n    title_font_color=\"red\",\n    legend_title_font_color=\"green\",\n    title_text=\"Mentions by count\"\n)\n\nfig.show()","0d3945de":"def  clean_text(df, text_field):\n    df[\"OriginalTweet\"] = df[\"OriginalTweet\"].str.lower()\n    df[\"OriginalTweet\"] = df[\"OriginalTweet\"].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\\/\\\/\\S+)|^rt|http.+?\", \"\", elem)) \n    \n    return df\n\ntrain_df = clean_text(train_df, \"tweet\")\ntrain_df = clean_text(test_df, \"tweet\")","e5d4c160":"train_df[\"OriginalTweet\"].head()","3d1a98be":"from collections import Counter\n\nmost_used_word_for_cloud = (\" \".join(train_df[\"OriginalTweet\"]))\n\nmost_used_word = Counter(\" \".join(train_df[\"OriginalTweet\"]).split()).most_common(100)\nmost_used_word_df = pd.DataFrame(most_used_word, columns=[\"Words\", \"Frequency\"])\n\nmost_used_word_df.head(3)","8dd9ed15":"#Graph : Words by count\nfig = px.bar(x=most_used_word_df[\"Words\"][:30], y=most_used_word_df[\"Frequency\"][:30], orientation=\"v\", color=most_used_word_df[\"Words\"][:30], color_continuous_scale=px.colors.sequential.Plasma, \n             log_y=False, labels={'value':'Count', \n                                'index':'Words',\n                                  'color':'Word',\n                                  'x':'Words',\n                                  'y':'Frequency'\n                                })\n\nfig.update_layout(\n    font_color=\"black\",\n    title_font_color=\"red\",\n    legend_title_font_color=\"green\",\n    title_text=\"Words by count\"\n)\n\nfig.show()","3852cba1":"# Create and generate a word cloud image :\nwordcloud = WordCloud(background_color='black',colormap=\"Blues\", \n                        width=600,height=400).generate(most_used_word_for_cloud)\n\n# Display the generated image :\nplt.figure(figsize=(12, 8))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","dc801e8e":"#Correlation\nplt.figure(figsize=(12, 8))\nsns.heatmap(test_df.corr(), annot=True)","e6c8b1ad":"## Reading Data \ud83d\udcdd","bd078dc4":"## Import librairies \ud83d\udcda","93941711":"## Most used words \ud83d\udc40","3832d0ca":"### Modelling \ud83d\udfe9","c03bd1e4":"## Data Exploration \ud83d\udcca | Feature Engineering \ud83c\udff7\ufe0f","f6032e62":"## Correlation \ud83d\udd04","86a99295":"## Cleaning tweets \ud83e\uddf9","1dc85bb8":"## Not finished ! Work in progress.","22502be8":"## What will I do ?\n\nSo, i'm gonna try to vizualise tweets by location, date and mostly by sentiment.\nThis period is very hard and I think it's interesting and important to visualize \npeople's feelings and moods over time. Finally, I'll try to create a model\nwho can classify these tweets."}}