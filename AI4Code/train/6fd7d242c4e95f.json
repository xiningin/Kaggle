{"cell_type":{"13459e72":"code","11b4f4ec":"code","70bb629a":"code","4d2512f7":"code","0ce92021":"code","1a8a12b7":"code","1bb8d163":"code","2e4ae946":"code","598d19ec":"code","7f283258":"code","a00c2b66":"code","279355f1":"code","5b77ce4d":"code","fe144160":"code","a52faf44":"markdown"},"source":{"13459e72":"import numpy as np\nimport pandas as pd\n\nimport gc\n\nimport optuna\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\n\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom sklearn.preprocessing import RobustScaler, normalize\nfrom sklearn.model_selection import train_test_split, GroupKFold, KFold\n\nfrom IPython.display import display","11b4f4ec":"DEBUG = False\n\ntrain = pd.read_csv('..\/input\/ventilator-pressure-prediction\/train.csv')\ntest = pd.read_csv('..\/input\/ventilator-pressure-prediction\/test.csv')\nsubmission = pd.read_csv('..\/input\/ventilator-pressure-prediction\/sample_submission.csv')\n\nif DEBUG:\n    train = train[:80*1000]","70bb629a":"# def add_features(df):\n#     # rewritten calculation of lag features from this notebook: https:\/\/www.kaggle.com\/patrick0302\/add-lag-u-in-as-new-feat\n#     # some of ideas from this notebook: https:\/\/www.kaggle.com\/mst8823\/google-brain-lightgbm-baseline\n#     df['last_value_u_in'] = df.groupby('breath_id')['u_in'].transform('last')\n#     df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n#     df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n#     df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n#     df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n#     df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n#     df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n#     df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n#     df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n#     df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n#     df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n#     df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n#     df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n#     df = df.fillna(0)\n\n\n#     df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n\n#     # max value of u_in and u_out for each breath\n#     df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n#     df['breath_id__u_out__max'] = df.groupby(['breath_id'])['u_out'].transform('max')\n\n#     # difference between consequitive values\n#     df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n#     df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n#     df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n#     df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n#     # from here: https:\/\/www.kaggle.com\/yasufuminakama\/ventilator-pressure-lstm-starter\n#     df.loc[df['time_step'] == 0, 'u_in_diff'] = 0\n#     df.loc[df['time_step'] == 0, 'u_out_diff'] = 0\n\n#     # difference between the current value of u_in and the max value within the breath\n#     df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n#     df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n\n#     # OHE\n#     df = df.merge(pd.get_dummies(df['R'], prefix='R'), left_index=True, right_index=True).drop(['R'], axis=1)\n#     df = df.merge(pd.get_dummies(df['C'], prefix='C'), left_index=True, right_index=True).drop(['C'], axis=1)\n#     df = df.merge(pd.get_dummies(df['R__C'], prefix='R__C'), left_index=True, right_index=True).drop(['R__C'], axis=1)\n\n#     # https:\/\/www.kaggle.com\/c\/ventilator-pressure-prediction\/discussion\/273974\n#     df['u_in_cumsum'] = df.groupby(['breath_id'])['u_in'].cumsum()\n#     df['time_step_cumsum'] = df.groupby(['breath_id'])['time_step'].cumsum()\n#     return df","4d2512f7":"def add_features(df):\n    df['area'] = df['time_step'] * df['u_in']\n    df['area'] = df.groupby('breath_id')['area'].cumsum()\n\n    #######################################\n    # fast area calculation\n    df['time_delta'] = df['time_step'].diff()\n    df['time_delta'].fillna(0, inplace=True)\n    df['time_delta'].mask(df['time_delta'] < 0, 0, inplace=True)\n    df['tmp'] = df['time_delta'] * df['u_in']\n    df['area_true'] = df.groupby('breath_id')['tmp'].cumsum()\n    \n    #u_in_max_dict = df.groupby('breath_id')['u_in'].max().to_dict()\n    #df['u_in_max'] = df['breath_id'].map(u_in_max_dict)\n    #u_in_min_dict = df.groupby('breath_id')['u_in'].min().to_dict()\n    #df['u_in_min'] = df['breath_id'].map(u_in_min_dict)\n    u_in_mean_dict = df.groupby('breath_id')['u_in'].mean().to_dict()\n    df['u_in_mean'] = df['breath_id'].map(u_in_mean_dict)\n    del u_in_mean_dict\n    u_in_std_dict = df.groupby('breath_id')['u_in'].std().to_dict()\n    df['u_in_std'] = df['breath_id'].map(u_in_std_dict)\n    del u_in_std_dict\n    \n    # u_in_half is time:0 - time point of u_out:1 rise (almost 1.0s)\n    df['tmp'] = df['u_out']*(-1)+1 # inversion of u_out\n    df['u_in_half'] = df['tmp'] * df['u_in']\n    \n    # u_in_half: max, min, mean, std\n    u_in_half_max_dict = df.groupby('breath_id')['u_in_half'].max().to_dict()\n    df['u_in_half_max'] = df['breath_id'].map(u_in_half_max_dict)\n    del u_in_half_max_dict\n    u_in_half_min_dict = df.groupby('breath_id')['u_in_half'].min().to_dict()\n    df['u_in_half_min'] = df['breath_id'].map(u_in_half_min_dict)\n    del u_in_half_min_dict\n    u_in_half_mean_dict = df.groupby('breath_id')['u_in_half'].mean().to_dict()\n    df['u_in_half_mean'] = df['breath_id'].map(u_in_half_mean_dict)\n    del u_in_half_mean_dict\n    u_in_half_std_dict = df.groupby('breath_id')['u_in_half'].std().to_dict()\n    df['u_in_half_std'] = df['breath_id'].map(u_in_half_std_dict)\n    del u_in_half_std_dict\n    \n    gc.collect()\n    \n    # All entries are first point of each breath_id\n    first_df = df.loc[0::80,:]\n    # All entries are first point of each breath_id\n    last_df = df.loc[79::80,:]\n    \n    # The Main mode DataFrame and flag\n    main_df= last_df[(last_df['u_in']>4.8)&(last_df['u_in']<5.1)]\n    main_mode_dict = dict(zip(main_df['breath_id'], [1]*len(main_df)))\n    df['main_mode'] = df['breath_id'].map(main_mode_dict)\n    df['main_mode'].fillna(0, inplace=True)\n    del main_df\n    del main_mode_dict\n\n    # u_in: first point, last point\n    u_in_first_dict = dict(zip(first_df['breath_id'], first_df['u_in']))\n    df['u_in_first'] = df['breath_id'].map(u_in_first_dict)\n    del u_in_first_dict\n    u_in_last_dict = dict(zip(first_df['breath_id'], last_df['u_in']))\n    df['u_in_last'] = df['breath_id'].map(u_in_last_dict)\n    del u_in_last_dict\n    # time(sec) of end point\n    time_end_dict = dict(zip(last_df['breath_id'], last_df['time_step']))     \n    df['time_end'] = df['breath_id'].map(time_end_dict)\n    del time_end_dict\n    del last_df\n    \n    # u_out1_timing flag and DataFrame: speed up\n    # \u9ad8\u901f\u7248 uout1_df \u4f5c\u6210\n    df['u_out_diff'] = df['u_out'].diff()\n    df['u_out_diff'].fillna(0, inplace=True)\n    df['u_out_diff'].replace(-1, 0, inplace=True)\n    uout1_df = df[df['u_out_diff']==1]\n    \n    gc.collect()\n    \n    #main_uout1 = uout1_df[uout1_df['main_mode']==1]\n    #nomain_uout1 = uout1_df[uout1_df['main_mode']==1]\n    \n    # Register Area when u_out becomes 1\n    uout1_area_dict = dict(zip(first_df['breath_id'], first_df['u_in']))\n    df['area_uout1'] = df['breath_id'].map(uout1_area_dict)\n    del uout1_area_dict\n    \n    # time(sec) when u_out becomes 1\n    uout1_dict = dict(zip(uout1_df['breath_id'], uout1_df['time_step']))\n    df['time_uout1'] = df['breath_id'].map(uout1_dict)\n    del uout1_dict\n    \n    # u_in when u_out becomes1\n    u_in_uout1_dict = dict(zip(uout1_df['breath_id'], uout1_df['u_in']))\n    df['u_in_uout1'] = df['breath_id'].map(u_in_uout1_dict)\n    del u_in_uout1_dict\n    \n    # Dict that puts 0 at the beginning of the 80row cycle\n    first_0_dict = dict(zip(first_df['id'], [0]*len(uout1_df)))\n\n    del first_df\n    del uout1_df   \n    \n    gc.collect()\n    \n    # Faster version u_in_diff creation, faster than groupby\n    df['u_in_diff'] = df['u_in'].diff()\n    df['tmp'] = df['id'].map(first_0_dict) # put 0, the 80row cycle\n    df.iloc[0::80, df.columns.get_loc('u_in_diff')] = df.iloc[0::80, df.columns.get_loc('tmp')]\n\n    # Create u_in vibration\n    df['diff_sign'] = np.sign(df['u_in_diff'])\n    df['sign_diff'] = df['diff_sign'].diff()\n    df['tmp'] = df['id'].map(first_0_dict) # put 0, the 80row cycle\n    df.iloc[0::80, df.columns.get_loc('sign_diff')] = df.iloc[0::80, df.columns.get_loc('tmp')]\n    del first_0_dict\n    \n    # Count the number of inversions, so take the absolute value and sum\n    df['sign_diff'] = abs(df['sign_diff']) \n    sign_diff_dict = df.groupby('breath_id')['sign_diff'].sum().to_dict()\n    df['diff_vib'] = df['breath_id'].map(sign_diff_dict)\n    \n    if 'diff_sign' in df.columns:\n        df.drop(['diff_sign', 'sign_diff'], axis=1, inplace=True)\n    if 'tmp' in df.columns:\n        df.drop(['tmp'], axis=1, inplace=True)\n    \n    gc.collect()\n    #######################################\n    '''\n    '''\n    \n    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n    \n    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n    #df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n    #df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n    #df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n    #df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n    #df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n    #df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n    #df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n    #df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n    df = df.fillna(0)\n    \n    #df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n    df['breath_id__u_out__max'] = df.groupby(['breath_id'])['u_out'].transform('max')\n    \n    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n    #df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n    #df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n    \n    #df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    \n    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n    #df['u_out_diff3'] = df['u_out'] - df['u_out_lag3']\n    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n    #df['u_out_diff4'] = df['u_out'] - df['u_out_lag4']\n    #df['cross']= df['u_in']*df['u_out']\n    #df['cross2']= df['time_step']*df['u_out']\n    \n    df['R_'] = df['R'].astype(str)\n    df['C_'] = df['C'].astype(str)\n    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n      \n    df = pd.get_dummies(df)\n    \n    # Drop an unimportant features\n    df.drop(['R__C_20__20', 'R__C_20__10', 'R__C_5__10', 'R__C_5__10', 'R__20', 'R__50', 'C__20'], axis=1, inplace=True)\n    \n    return df","0ce92021":"%%time\ntrain = add_features(train)","1a8a12b7":"%%time\ntest = add_features(test)","1bb8d163":"train.head()","2e4ae946":"targets = train[['pressure']].to_numpy().reshape(-1, 80)\ntrain.drop(['pressure', 'id', 'breath_id'], axis=1, inplace=True)\ntest = test.drop(['id', 'breath_id'], axis=1)","598d19ec":"RS = RobustScaler()\ntrain = RS.fit_transform(train)\ntest = RS.transform(test)","7f283258":"train = train.reshape(-1, 80, train.shape[-1])\ntest = test.reshape(-1, 80, train.shape[-1])","a00c2b66":"from tensorflow.keras.callbacks import Callback\nimport tensorflow.keras.backend as K\nclass WarmupExponentialDecay(Callback):\n    def __init__(self,lr_base=0.0002,lr_min=0.0,decay=0,warmup_epochs=0):\n        self.num_passed_batchs = 0   #\u4e00\u4e2a\u8ba1\u6570\u5668\n        self.warmup_epochs=warmup_epochs  \n        self.lr=lr_base #learning_rate_base\n        self.lr_min=lr_min #\u6700\u5c0f\u7684\u8d77\u59cb\u5b66\u4e60\u7387,\u6b64\u4ee3\u7801\u5c1a\u672a\u5b9e\u73b0\n        self.decay=decay  #\u6307\u6570\u8870\u51cf\u7387\n        self.steps_per_epoch=0 #\u4e5f\u662f\u4e00\u4e2a\u8ba1\u6570\u5668\n        \n    def on_batch_begin(self, batch, logs=None):\n        # params\u662f\u6a21\u578b\u81ea\u52a8\u4f20\u9012\u7ed9Callback\u7684\u4e00\u4e9b\u53c2\u6570\n        if self.steps_per_epoch==0:\n            #\u9632\u6b62\u8dd1\u9a8c\u8bc1\u96c6\u7684\u65f6\u5019\u5457\u66f4\u6539\u4e86\n            if self.params['steps'] == None:\n                self.steps_per_epoch = np.ceil(1. * self.params['samples'] \/ self.params['batch_size'])\n            else:\n                self.steps_per_epoch = self.params['steps']\n        if self.num_passed_batchs < self.steps_per_epoch * self.warmup_epochs:\n            K.set_value(self.model.optimizer.lr,\n                        self.lr*(self.num_passed_batchs + 1) \/ self.steps_per_epoch \/ self.warmup_epochs)\n        else:\n            K.set_value(self.model.optimizer.lr,\n                        self.lr*((1-self.decay)**(self.num_passed_batchs-self.steps_per_epoch*self.warmup_epochs)))\n        self.num_passed_batchs += 1\n        \n    def on_epoch_begin(self,epoch,logs=None):\n        #\u7528\u6765\u8f93\u51fa\u5b66\u4e60\u7387\u7684,\u53ef\u4ee5\u5220\u9664\n        print(\"learning_rate:\",K.get_value(self.model.optimizer.lr))","279355f1":"EPOCH = 300\nBATCH_SIZE = 1024\nNUM_FOLDS = 10\n\nTPU = False\n\nif TPU:\n    # detect and init the TPU\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n    ## instantiate a distribution strategy\n    xpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # GET GPU STRATEGY\n    xpu_strategy = tf.distribute.get_strategy()\n\nwith xpu_strategy.scope():\n    kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=2021)\n    test_preds = []\n    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n        print('-'*15, '>', f'Fold {fold+1}', '<', '-'*15)\n        X_train, X_valid = train[train_idx], train[test_idx]\n        y_train, y_valid = targets[train_idx], targets[test_idx]\n        model = keras.models.Sequential([\n            keras.layers.Input(shape=train.shape[-2:]),\n            keras.layers.Bidirectional(keras.layers.LSTM(1024, return_sequences=True)),\n            keras.layers.Bidirectional(keras.layers.LSTM(512, return_sequences=True)),\n            keras.layers.Bidirectional(keras.layers.LSTM(256, return_sequences=True)),\n            keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True)),\n#             keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True)),\n            keras.layers.Dense(128, activation='selu'),\n#             keras.layers.Dropout(0.1),\n            keras.layers.Dense(1),\n        ])\n        model.compile(optimizer=\"adam\", loss=\"mae\")\n\n#         scheduler = ExponentialDecay(1e-3, 40*((len(train)*0.8)\/BATCH_SIZE), 1e-5)\n#         lr = LearningRateScheduler(scheduler, verbose=1)\n        lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=10, verbose=1)\n#         lr = WarmupExponentialDecay(lr_base=1e-3, decay=1e-5, warmup_epochs=30)\n        es = EarlyStopping(monitor=\"val_loss\", patience=60, verbose=1, mode=\"min\", restore_best_weights=True)\n    \n        checkpoint_filepath = f\"folds{fold}.hdf5\"\n        sv = keras.callbacks.ModelCheckpoint(\n            checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True,\n            save_weights_only=False, mode='auto', save_freq='epoch',\n            options=None\n        )\n\n        model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=EPOCH, batch_size=BATCH_SIZE, callbacks=[lr, es, sv])\n        #model.save(f'Fold{fold+1} RNN Weights')\n        test_preds.append(model.predict(test).squeeze().reshape(-1, 1).squeeze())","5b77ce4d":"!ls .\/","fe144160":"submission[\"pressure\"] = sum(test_preds)\/NUM_FOLDS\nsubmission.to_csv('submission.csv', index=False)","a52faf44":"# This is a modeling notebook for [EDA about: LSTM Feature Importance](https:\/\/www.kaggle.com\/marutama\/eda-about-lstm-feature-importance)."}}