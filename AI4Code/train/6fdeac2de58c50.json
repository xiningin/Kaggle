{"cell_type":{"4dce3551":"code","65988890":"code","2576a168":"code","7ef58a97":"code","1e93e84d":"code","643dd6dc":"code","bf646ad0":"code","6034b668":"markdown","8de19f0d":"markdown","ab716247":"markdown"},"source":{"4dce3551":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')\n\nplt.rcParams['font.family'] = 'serif'\ncmap = sns.color_palette(\"ch:start=.2,rot=-.3\")\nsns.set_palette(cmap)","65988890":"# read dataframe\ndf_train = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/train.csv')\ndf_test = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/test.csv')\nsample_submission = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/sample_solution.csv')","2576a168":"# prepare dataframe for modeling\nX = df_train.drop(columns=['id','claim']).copy()\ny = df_train['claim'].copy()\n\ntest_data = df_test.drop(columns=['id']).copy()","7ef58a97":"# create preprocessing pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\n\npipeline = Pipeline([\n    ('impute', SimpleImputer()),\n    ('scale', StandardScaler())\n])","1e93e84d":"# model params\nlgbm_params = {\n    'device_type' : 'gpu'\n}\n\ncatb_params = {\n    'task_type' : 'GPU',\n    'devices' : '0',\n    'verbose' : 0\n}\n\nxgb_params = {\n    'predictor': 'gpu_predictor',\n    'tree_method': 'gpu_hist',\n    'gpu_id' : 0,\n    'verbosity': 0\n}","643dd6dc":"# spot checking which model to chose\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=True, random_state=1)\n\n# preprocessing\nX_train = pipeline.fit_transform(X_train)\nX_test = pipeline.transform(X_test)\n\nmodels = [\n    ('LGBM', LGBMClassifier\t(**lgbm_params)),\n    ('CATB', CatBoostClassifier(**catb_params)),\n    ('XGB', XGBClassifier(**xgb_params))\n]\n\nscores = dict()\n\nfor name, model in models:\n    model.fit(X_train, y_train)\n    y_hat = model.predict_proba(X_test)[:,1]\n    fpr, tpr, _ = roc_curve(y_test, y_hat)\n    auc_score = auc(fpr, tpr)\n    scores[name] = auc_score","bf646ad0":"scores_df = pd.DataFrame([scores]).transpose().rename(columns={0:'AUC'})\n\nfig, ax = plt.subplots(figsize=(12,6))\n\nsns.barplot(\n    data=scores_df,\n    x='AUC',\n    y=scores_df.index,\n    orient='h',\n    ax=ax\n)\n\nfor idx in range(0, len(scores_df)):\n    x = scores_df['AUC'][idx]\n    ax.annotate(\n        s=f\"AUC: {np.round(x,3)}\",\n        xy=(x-0.01, idx),\n        va='center', ha='right'\n    )\n\nsns.despine(left=True)\nplt.show()","6034b668":"## <div style='background:#2b6684;color:white;padding:0.5em;border-radius:0.2em'>Introduction<\/div>","8de19f0d":"Hi,\nI just wanted to share a quick notebook sharing the results of spot-checking the \"big-three\".<br>\nThe list of models can be modified to expand your spot-check. The results can then be used to decide on which algorithm to focus on,<br>\nfor Feature-Engineering and Hyperparameter-Tuning.\n\nThanks for checking out this \"quick-one\" and have fun with this competition!\n\nBest Regards","ab716247":"## <div style='background:#2b6684;color:white;padding:0.5em;border-radius:0.2em'>Import, Preprocess, Spot-Check<\/div>"}}