{"cell_type":{"46bc7d90":"code","d03be8f1":"code","6e691230":"code","9247534c":"code","c93a305d":"code","e03d0f59":"code","1522483e":"code","b5e5868a":"code","04829fa0":"code","b16e355a":"code","63838993":"code","2fbc23fd":"code","30e17d72":"code","8f47a6ed":"code","7488a248":"code","a92d3c8f":"code","06a82f26":"markdown","b75bad73":"markdown","ccd296b9":"markdown","ce5518fa":"markdown","69fe3967":"markdown","052e3078":"markdown","ca7bfa85":"markdown","c1952e3d":"markdown","69d8bb36":"markdown","dceb3e3f":"markdown"},"source":{"46bc7d90":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os","d03be8f1":"def getStockData(tickers):\n    df = pd.DataFrame()\n    for ticker in tickers:\n        # loads data for each company\n        data = pd.read_csv(\"..\/input\/nasdaq-and-nyse-stocks-histories\/fh_20181104\/full_history\/\" + ticker + \".csv\")\n        data = data.sort_index(axis=0, ascending=False)\n        data = data.drop(['adjclose', 'high', 'low'], axis=1)\n        \n        data[\"date\"] = pd.to_datetime(data[\"date\"])\n        \n        # Cuts the first 25% of the historical data off\n        data = data[int(len(data)*.25):]\n        \n        # Features and Label:\n        data[\"ticker\"] = ticker\n        \n# --------- Stock Indicators ---------- #\n        \n        # Simple Moving Average (df, column for calculations, window)\n        SMA(data, 'close', 50)\n        SMA(data, 'close', 200)\n        \n        # Exponetial Moving Average\n        EMA(data, 'close', 12)\n        EMA(data, 'close', 26)\n        \n        # Moving Average Convergence Divergence (plus signal) (window1_EMA - window2_EMA) \n        MACD(data, 'close', 12, 26, 9, True)\n        \n        # Stochastic Oscillator (plus signal)\n        SO(data, 'close', 14, 3, True)\n        \n        # Relative Strength Index (EMA, SMA)\n        RSI(data, 'close', 14, True, True)\n        \n        # Bollinger Bands\n        BB(data, 'close', 20)\n\n        # Yesterday's close\n        data['close-1'] = data['close'].shift(1)  \n        \n        # Label Creation\n        data['close+1'] = data['close'].shift(-1)  #Tomorrow's close (use for regression)\n        \n        data['log_label'] = np.where(data['close+1'] > (1.0 * data['close']), 1, 0) # is tomorrow going to close higher than today?\n        \n        \n        # drops any NaN values from stock indicator calculations\n        data = data.dropna()\n        \n        # Calls fundamental data function to add fundamentals\n#        data = fundamentalData(data, ticker)\n        \n        df = df.append(data,ignore_index=True)\n        \n    \n    # one-hot encoding for company\n    df2 = pd.get_dummies(df[\"ticker\"])\n    df = pd.concat([df, df2], axis=1, join='outer')\n    return df","6e691230":"# All indicators are typically done with close\n\ndef SMA(df, dataColumn, window):\n    newColumn = str(window) + \"SMA\" + \"_\" + dataColumn\n    df[newColumn] = df[dataColumn].rolling(window=window).mean()\n    \ndef EMA(df, dataColumn, window):\n    newColumn = str(window) + \"EMA\" + \"_\" + dataColumn\n    # pandas ewm method for moving average (adjust set to false to equal stock website calculations)\n    df[newColumn] = df[dataColumn].ewm(span=window,min_periods=0,adjust=False,ignore_na=False).mean()\n\n# Moving Average Convergence Divergence (12, 26 are most common EMA windows)\ndef MACD(df, dataColumn, window1, window2, signal_window, isSignal):\n    EMA1 = df[dataColumn].ewm(span=window1,min_periods=0,adjust=False,ignore_na=False).mean()\n    EMA2 = df[dataColumn].ewm(span=window2,min_periods=0,adjust=False,ignore_na=False).mean()\n    MACD = EMA1 - EMA2\n    df[str(window1) + \"-\" + str(window2) + \"MACD\" + \"_\" + dataColumn] = MACD\n    if(isSignal):\n        df[\"MACD_\" + str(signal_window) + \"SMA\"] = MACD.ewm(span=signal_window,min_periods=0,adjust=False,ignore_na=False).mean()\n\n        \n# Stochastic Oscillator (14 is most common lookback window)\ndef SO(df, dataColumn, window, signal_window, isSignal):\n    # current open - lowest open \/ (highest open - lowest open) * 100\n    SO = ((df[dataColumn] - df[dataColumn].rolling(window=window).min()) \/\n              (df[dataColumn].rolling(window=window).max() - df[dataColumn].rolling(window=window).min())) * 100\n    df[str(window) + \"SO\" + \"_\" + dataColumn] = SO\n    # Signal line (SMA of Stochstic Oscillator, 3 is most common)\n    if(isSignal):\n        df[\"SO_\" + str(signal_window) + \"SMA\"] = SO.rolling(window=signal_window).mean()\n        \n# Relative Strength Index (14 is most common lookback window)\ndef RSI(df, dataColumn, window, isEMA, isSMA):\n        \n    data = df[dataColumn]\n    delta = data.diff()\n    # Get rid of the first row, which is NaN since it did not have a previous row to calculate the differences\n    delta = delta[1:] \n\n    # Make the positive gains (up) and negative gains (down)\n    up, down = delta.copy(), delta.copy()\n    up[up < 0] = 0\n    down[down > 0] = 0\n\n    if(isEMA):\n        # Calculate the EMAs\n        roll_up1 = up.ewm(span=window,min_periods=0,adjust=False,ignore_na=False).mean()\n        roll_down1 = down.abs().ewm(span=window,min_periods=0,adjust=False,ignore_na=False).mean()\n\n        # Calculate the RSI based on EMA\n        RS1 = roll_up1 \/ roll_down1\n        name1 = str(window) + \"RSI\" + \"_\" + \"EMA\" + \"_\" + dataColumn\n        df[name1] = 100.0 - (100.0 \/ (1.0 + RS1))\n\n    if(isSMA):\n        # Calculate the SMAs\n        roll_up2 = up.rolling(window=window).mean()\n        roll_down2 = down.abs().rolling(window=window).mean()\n\n        # Calculate the RSI based on SMA\n        RS2 = roll_up2 \/ roll_down2\n        name2 = str(window) + \"RSI\" + \"_\" + \"SMA\" + \"_\" + dataColumn\n        df[name2] = 100.0 - (100.0 \/ (1.0 + RS2))\n\n# Bollinger Bands\ndef BB(df, dataColumn, window):\n    SMA = df[dataColumn].rolling(window=window).mean()\n    std = df[dataColumn].rolling(window=window).std()\n    df[str(window) + \"upper_\" + dataColumn] = SMA + (2 * std)\n    df[str(window) + \"middle_\" + dataColumn] = SMA\n    df[str(window) + \"lower_\" + dataColumn] = SMA - (2 * std)","9247534c":"# Adding Fundamental Data function\n\ndef fundamentalData(df, ticker):\n    data = pd.read_csv(\"\/kaggle\/input\/financial-ratios-1980-goog-aapl-amzn\/Fin Ratios 1980-Now AAPL_AMZN_GOOG.csv\")\n    \n    # Most tickers are GOOG, 41 of the most recent are GOOGL - so I changed all of them to GOOG\n    data.loc[data[\"TICKER\"] == 'GOOGL', 'TICKER'] = 'GOOG'\n    data[data[\"TICKER\"] == 'GOOG']\n    \n    data['public_date'] = pd.to_datetime(data[\"public_date\"])\n    data.set_index(\"TICKER\", inplace = True)\n    \n    data = data.loc[ticker]\n\n    data.set_index(\"public_date\", inplace = True)\n    #data = data.drop([ \"gvkey\", \"permno\", 'adate', 'qdate', 'public_date'], axis=1)\n    # forward fill to get a fundamental value for every day\n    data = data.asfreq(freq='D', method='ffill')\n    data[\"date\"] = data.index\n\n    \n    # removes any columns that have any NaN values or is an object\/string (quarter, reported\/reinstated date, etc.)\n    dropCols = []\n    for column in data.columns:\n        if data[column].isna().sum() > 0 or data[column].dtypes == np.object:\n            dropCols += [column]\n    data = data.drop(dropCols, axis=1)\n    #print(dropCols)\n\n    df = pd.merge(df, data, 'outer', on=\"date\")\n    df = df.dropna()\n    return df","c93a305d":"def get_available_tickers():\n    ticker_list = []\n    for filename in os.listdir('\/kaggle\/input\/nasdaq-and-nyse-stocks-histories\/full_history\/'):\n            ticker_list += [filename[0:-4]]\n    return ticker_list\n\nget_available_tickers()","e03d0f59":"sp_df = pd.read_csv(\"..\/input\/sp-500-list\/SP500.csv\")\n#sp_df = sp_df[sp_df.ticker != 'AMCR']\n\n#df.drop(df[df.Fruit.isin([\"Apple\", \"Orange\"])].index)\n#df[~(df.Fruit.isin([\"Apple\", \"Orange\"]))]\n#sp_df = sp_df.drop(sp_df[~sp_df.ticker.isin(avail_tickers)].index)\n\n\n# ~ is not for pandas filting ex: sp_df[~(sp_df.ticker.isin())]\n\n\n\n# drops any tickers we don't have data for\navail_tickers = get_available_tickers()\n\nsp_df = sp_df[(sp_df.ticker.isin(avail_tickers))]\nsp_df","1522483e":"#ticker_list = [\"AAPL\"]\n#ticker_list = [\"AAPL\", \"AMZN\", \"GOOG\"]\nticker_list = [\"AAPL\", \"GOOG\", \"MSFT\", \"FB\", 'IBM', 'HPQ']\n#ticker_list = sp_df.ticker[0:100]\n\n\n\n# Calls function to compile data and calculate features\ndf = getStockData(ticker_list)\n\n# this ensures (relatively) even mix of companies in each data split\ndf = df.sort_values(by=['date'])\n\n# drops columns with na values\ndropCols= []\nfor column in df.columns:\n    if df[column].isna().sum() > 0:\n        dropCols += [column]\ndf = df.drop(dropCols, axis=1)\n\ndf","b5e5868a":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os","04829fa0":"from sklearn.preprocessing import StandardScaler\n\ndf = pd.read_csv(\"..\/input\/intraday-data\/intraday_data.csv\")\ndf = df[df.ticker==\"AAPL\"]\ndf = df.drop(columns=[\"Unnamed: 0\", \"time\", \"date\", \"ticker\"])\ndf['close+1'] = df['close'].shift(-1)  #next time step's close (use for regression)\ndf['log_label'] = np.where(df['close+1'] > (1.05 * df['close']), 1, 0) # is the next timestemp going to close higher than current timestep?\n\n\ndf = df[5:-5]\n\ndisplay(df)\n\nn = len(df)\ntrain_df = df[0:int(n*0.7)]\nval_df = df[int(n*0.7):int(n*0.9)]\ntest_df = df[int(n*0.9):]\n\n# unscaled 0s and 1s\ntrain_y = train_df['log_label']\nval_y = val_df['log_label']\ntest_y = test_df['log_label']\n\n\n\nscaler = StandardScaler()\nscaler.fit(train_df)\nscaled_train_df = pd.DataFrame(scaler.transform(train_df), columns=['volume', 'open', 'close', 'high', 'low', 'close+1', 'log_label'])\nscaled_val_df = pd.DataFrame(scaler.transform(val_df), columns=['volume', 'open', 'close', 'high', 'low', 'close+1', 'log_label'])\nscaled_test_df = pd.DataFrame(scaler.transform(test_df), columns=['volume', 'open', 'close', 'high', 'low', 'close+1', 'log_label'])\n\n\ntrain_X = scaled_train_df.drop(['close+1', 'log_label'], axis=1)\nval_X = scaled_val_df.drop(['close+1', 'log_label'], axis=1)\ntest_X = scaled_test_df.drop(['close+1', 'log_label'], axis=1)\n\ndisplay(train_X)\n\ntrain_y\n","b16e355a":"train_X = np.asarray(train_X)\nval_X = np.asarray(val_X)\ntest_X = np.asarray(test_X)\ntrain_y = np.asarray(train_y)\nval_y = np.asarray(val_y)\ntest_y = np.asarray(test_y)\nprint(len(train_X))\nprint(len(val_X))\nprint(len(test_X))","63838993":"# convert data to sequences of data for LSTM\n\nX_train = []\ny_train = []\nX_val = []\ny_val = []\nX_test = []\ny_test = []\n\nseq_len = 40\n\nfor i in range(len(train_X) - seq_len):\n    X_train.append(train_X[i:i+seq_len])\n    y_train.append(train_y[i+seq_len])\nX_train, y_train = np.array(X_train), np.array(y_train)\n\nprint(X_train.shape, y_train.shape)\n\nfor i in range(len(val_X) - seq_len):\n    X_val.append(val_X[i:i+seq_len])\n    y_val.append(val_y[i+seq_len])\nX_val, y_val = np.array(X_val), np.array(y_val)\n\nprint(X_val.shape, y_val.shape)\n\n\nfor i in range(len(test_X) - seq_len):\n    X_test.append(test_X[i:i+seq_len])\n    y_test.append(test_y[i+seq_len])\nX_test, y_test = np.array(X_test), np.array(y_test)\n\nprint(X_test.shape, y_test.shape)","2fbc23fd":"import tensorflow as tf\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\n# 51% accuracy on test set\n# model = tf.keras.models.Sequential([\n#     tf.keras.layers.LSTM(64, return_sequences=True),#, activation=tf.nn.sigmoid),\n#     tf.keras.layers.Dropout(.25),\n    \n#     tf.keras.layers.LSTM(32, return_sequences=True),# activation=tf.nn.relu),\n#     tf.keras.layers.Dropout(.25),\n    \n#     tf.keras.layers.Flatten(),\n#     tf.keras.layers.Dense(16, activation=tf.nn.relu),\n#     tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n# ])\n\n# 55% accuracy on val set, 54% accuracy on test set\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.LSTM(8, return_sequences=True),#, activation=tf.nn.sigmoid),\n    tf.keras.layers.Dropout(.25),\n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n])\n\n\n# 54% accuracy on val set, 56% accuracy on test set (pred 1 9x)\n# model = tf.keras.models.Sequential([\n#     tf.keras.layers.LSTM(5, return_sequences=False),\n#     tf.keras.layers.Dropout(.4),\n    \n#     tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n# ])\n\nearly_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose = 1, patience = 9, restore_best_weights = False)\n\n# model.compile(loss = \"mse\", optimizer = tf.keras.optimizers.Adam(), metrics=['mse'])\nmodel.compile(loss = tf.keras.losses.BinaryCrossentropy(), optimizer = tf.keras.optimizers.Adam(), metrics=['accuracy'])\n\nhistory = model.fit(X_train, y_train, verbose=1, epochs=200, batch_size=50, validation_data=(X_val, y_val), callbacks = [early_stopping])","30e17d72":"# model architecture\nmodel.summary()","8f47a6ed":"import math\nfrom sklearn.metrics import accuracy_score, mean_squared_error\n\n# function for displaying model evaluation scores\ndef eval_metrics(y_actual, y_predict, dataset):\n    print(\"\\nEvaluation metrics for \" + dataset + \":\\n\")\n    print(\"Accuracy score is: %.2f\" % accuracy_score(y_actual, y_predict))\n    print(\"Mean Squared Error: %.3f\" % mean_squared_error(y_actual, y_predict))\n    print(\"Root Mean Squared Error: %.3f\" % math.sqrt(mean_squared_error(y_actual, y_predict)))\n    print(\"-----------------------------------------\")","7488a248":"# scaler.inverse_transform()\n\nimport matplotlib.pyplot as plt\n\npredictions = model.predict(X_test)\n\nplt.figure(figsize=(20,12))\n\ndf = test_df[0:-40]\n\nx = [i for i in range(len(df['close']))]\n\n# print(len(predictions), len(df['close']), len(df.index))\n\n# print(predictions)\n\npred = [1 if num > 0.5 else 0 for num in predictions]\n\ndf['pred'] = pred\n\ndisplay(df)\n\nplt.scatter(df.index[df['pred'] == 1], (df['close'][df['pred'] == 1] * df['pred'][df['pred'] == 1]), color='Green', label = '1 pred', s=40)\nplt.scatter(df.index[df['pred'] == 0], (df['close'][df['pred'] == 0] + df['pred'][df['pred'] == 0]), color='Red', label = '0 pred', s=10)\n\n\n# plt.scatter(df.index[df['log_label'] == 1], (df['close'][df['log_label'] == 1] * df['log_label'][df['log_label'] == 1]), color='Green', label = '1 actual')\n# plt.scatter(df.index[df['log_label'] == 0], (df['close'][df['log_label'] == 0] + df['log_label'][df['log_label'] == 0]), color='Red', label = '0 actual')\n\nplt.plot(df.index, df['close'])\n\n\nplt.title(\"Intraday AAPL with LSTM Predictions\")\nplt.xlabel(\"Timesteps (1min intervals)\")\nplt.ylabel(\"Price\")\nplt.legend()\nplt.show()\n\neval_metrics(df['log_label'], df['pred'], \"Test data\")\n","a92d3c8f":"from sklearn.metrics import confusion_matrix\n#from sklearn.metrics import ConfusionMatrixDisplay\n\ncm = confusion_matrix(df['log_label'], df['pred'])\n\n#cm_display = ConfusionMatrixDisplay(cm).plot()\ncm_display = pd.DataFrame(cm)\ncm_display\n#X axis is predicted\n#y axis is actual","06a82f26":"## Model Fitting and Predicting\nThe next step is fitting the model to the data.  Then, it predicts for both the test and validation data so we can compare those two segments.","b75bad73":"# Apple LSTM Classification Prediction\n","ccd296b9":"## Data Compilation, Feature Selection, and Data Splitting\nWe must split the data for training, validation, and testing the model.  Also, some data should be dropped that has look-ahead bias, is the label, or poor predictive power.","ce5518fa":"### Company Fundamental Data Function\nThis function adds data on company finnancials into our model.  Because there is normally more than 600 fundamentals per company, I accessed already calculated finnancial ratios to save time.  These ratios are meaningful than the raw data, similar to the stock indicators.\n\nThe documentation of the ratios can be found [here](https:\/\/wrds-www.wharton.upenn.edu\/documents\/793\/WRDS_Industry_Financial_Ratio_Manual.pdf?_ga=2.25016058.1798038680.1607698243-1727031239.1606232862)","69fe3967":"# Feature Engineering\nRaw data rarely provides meaninful insight for machine learning models.  The \"art\" of machine learning is combining the raw data into features that improve a model's accuracy.","052e3078":"### Compile Data and Features\nThe following code calls the above functions and outputs a dataframe with all our data, features, and labels!  It also cleans the data by dropping columns with missing values.","ca7bfa85":"### Test 6 things:\n- Regression vs classification\n    - for classificaition, try buy\/sell vs. strong buy\/ strong sell (top 10% or something)\n- OHLCV Data vs. feature engineering\n    ","c1952e3d":"### Data Compilation Functions","69d8bb36":"### Stock Indicator Functions\nThe below functions calculate various stock indicators under the broad categories of trend following, momentum, mean reversion, and volume indicators.\n\n\n\nInitiallly coded and graphed [here](https:\/\/www.kaggle.com\/colinflueck\/apple-stock-indicators\/notebook?scriptVersionId=46331290)\n","dceb3e3f":"## Model Evaluation\nNow we get to see how the model performs!  The below code shows common machine learning valuation metrics for both validation and test data.  Additonally, it shows the statistical breakdown of the validation data prediction and the actual classification of our test data in a confusion matrix."}}