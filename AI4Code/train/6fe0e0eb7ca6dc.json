{"cell_type":{"750be421":"code","3d03f23e":"code","fb16777c":"code","1279933f":"code","fdb4d082":"code","ee773b5b":"code","178aa479":"code","9eb0b169":"code","7de8ca69":"code","54b43b77":"code","8e1ec0c2":"code","61578dec":"code","7ea6b514":"code","cd5165ca":"code","0a5736f4":"code","5683044b":"code","d4af7abb":"code","03806f98":"code","daab6e7d":"code","22ba801b":"code","4cbb4162":"code","01824949":"code","c986ae64":"code","2832a11a":"code","ce2c9886":"code","4d46d08f":"code","901ad3a4":"code","4e177bcf":"code","c52165a1":"code","65aee086":"code","8b3522f2":"code","39bad47c":"code","3cdb0e7d":"code","d4702df9":"code","6e1a1142":"code","922f9c16":"code","7c4dd6d3":"code","b28509a8":"code","bd2d143c":"code","c19d6db3":"code","0f413c78":"code","dbd9921e":"code","dd00ad57":"code","4defb3e6":"code","1d3da0bf":"code","07854d6f":"code","0d6e26c8":"code","8620226d":"markdown","a9103f5d":"markdown","2d723500":"markdown","a8ec251a":"markdown","1ba96647":"markdown","4d0cf2cc":"markdown","52328afb":"markdown","c9328171":"markdown","c697c2b0":"markdown","8571e5c7":"markdown","4e46e06e":"markdown","29ac3f2d":"markdown","dda944e7":"markdown","9fa5764a":"markdown"},"source":{"750be421":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3d03f23e":"#Load other libraries necessary\nfrom PIL import Image,ImageOps\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg","fb16777c":"#Read the image in the directory\nimg = Image.open(\"\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/train\/NORMAL\/IM-0125-0001.jpeg\")\n\n#Create a numpy array for the img\nimg_array = np.array(img)\n\n#Take a look at the shape\nprint(img_array.shape)\n\n#display the image\nimgplot = plt.imshow(img_array)\n","1279933f":"#Let us resize the image to approx (128,128) maintaining aspect ratio. This would help store the images and fasten the network\ndef Img_resize(img,size=(128,128)):\n    img = img.resize(size)\n    return img\n    \nsize = (128, 128)\nimg = Img_resize(img,size)\n","fdb4d082":"img = Image.open('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/test\/PNEUMONIA\/person101_bacteria_483.jpeg')\nplt.imshow(img)","ee773b5b":"print('The histogram of X-Ray is given as follows:')\nplt.plot(img.histogram())","178aa479":"#Let us equilaize the image histogram\nim2 = ImageOps.equalize(img)\nf, axarr = plt.subplots(1,2)\naxarr[0].imshow(img)\naxarr[1].imshow(im2)","9eb0b169":"plt.plot(im2.histogram())","7de8ca69":"# The image is a grey-scale image of dimension (128, 128). Let us start building the training dataset containing the pixels of image flattened and label indicating presence of pneumonia\n\n# First let us build a binary classifciation to classify Pneumonia vs No-Pneumonia X-rays. Further we shall think of classifying Viral and Bacterial Pneumonia","54b43b77":"# Let us build the pixel_cols required in the dataframe\npixel_cols = []\nfor i in range(128*128):\n    pixel_cols.append('pixel'+str(i))\nlen(pixel_cols)","8e1ec0c2":"#define the remaining cols of the dataset\ndata_col = pixel_cols.copy()\ndata_col.append('X_Ray_Class')\ndata_col.append('Pneumonia_Class')\ndata_col[-5:]","61578dec":"#Let us build the training dataframe\ntrain_df = pd.DataFrame(columns = data_col)\ntrain_df","7ea6b514":"#First let us start by loading the NORMAL chest x_rays from the training set\ncount = 0\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/train\/NORMAL'):\n    for filename in filenames:\n        img = Image.open(os.path.join(dirname, filename))\n        #Equilize th histogram\n        img = ImageOps.equalize(img)\n        #Resize the image\n        img = Img_resize(img)\n        img_array = np.array(img).reshape(img.size[0]*img.size[1]).tolist()\n        img_array = img_array + ['Normal','None']\n        train_df = train_df.append(pd.Series(img_array,index=data_col),ignore_index=True)\n        count = count + 1\n        print('Training data ',count,' loaded into the dataframe')","cd5165ca":"#Lets take a look at the training dataframe having Normal Dataset\nprint('size of train dataframe is ',train_df.shape)\ntrain_df.head()","0a5736f4":"#Write to csv for future use. Will speed up preprocessing\ntrain_df.to_csv('train_normal_1_df.csv',index=False)","5683044b":"#let us build a dataframe for the images with pneumonia. Combine later.\ntrain_pneumonia_df = pd.DataFrame(columns = data_col)\ntrain_pneumonia_df","d4af7abb":"# Let us load the PNEUMONIA chest x_rays from the training set\ncount = 0\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/train\/PNEUMONIA'):\n    for filename in filenames:\n        img = Image.open(os.path.join(dirname, filename)).convert('L')\n       #Equilize th histogram\n        img = ImageOps.equalize(img)\n        #Resize the image\n        img = Img_resize(img)\n        img_array = np.array(img).reshape(img.size[0]*img.size[1]).tolist()\n        pneumonia_class = filename.split(\"_\")[1]\n        img_array = img_array + ['Pneumonia',pneumonia_class]\n        train_pneumonia_df = train_pneumonia_df.append(pd.Series(img_array,index=data_col),ignore_index=True)\n        count = count + 1        \n        print('Training data ',count,' loaded into the dataframe')\n        ","03806f98":"train_pneumonia_df","daab6e7d":"train_pneumonia_df.to_csv('normal_train_pneumonia_df.csv',index=False)","22ba801b":"val_normal_df = pd.DataFrame(columns = data_col)\nval_normal_df","4cbb4162":"# Let us now load the NORMAL chest x_rays from the validation set\ncount = 0\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/val\/NORMAL'):\n    for filename in filenames:\n        img = Image.open(os.path.join(dirname, filename)).convert('L')\n        print(filename)\n        img = ImageOps.equalize(img)\n        img = Img_resize(img)\n        img_array = np.array(img).reshape(img.size[0]*img.size[1]).tolist()\n        img_array = img_array + ['Normal','None']\n        val_normal_df = val_normal_df.append(pd.Series(img_array,index=data_col),ignore_index=True)\n        count = count + 1        \n        print('Validation data ',count,' loaded into the dataframe')\n        ","01824949":"val_normal_df.to_csv('\/kaggle\/working\/val_normal_df.csv',index=False)\nval_normal_df","c986ae64":"val_pneumonia_df = pd.DataFrame(columns = data_col)\nval_pneumonia_df","2832a11a":"# Let us load the PNEUMONIA chest x_rays from the validation set\ncount = 0\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/val\/PNEUMONIA\/'):\n    for filename in filenames:\n        img = Image.open(os.path.join(dirname, filename)).convert('L')\n        print(filename)\n        img = ImageOps.equalize(img)\n        img = Img_resize(img)\n        img_array = np.array(img).reshape(img.size[0]*img.size[1]).tolist()\n        pneumonia_class = filename.split(\"_\")[1]\n        img_array = img_array + ['Pneumonia',pneumonia_class]\n        val_pneumonia_df = val_pneumonia_df.append(pd.Series(img_array,index=data_col),ignore_index=True)\n        count = count + 1        \n        print('Validation data ',count,' loaded into the dataframe')","ce2c9886":"val_pneumonia_df.to_csv('\/kaggle\/working\/val_pneumonia_df.csv',index=False)\nval_pneumonia_df","4d46d08f":"test_normal_df = pd.DataFrame(columns = data_col)\ntest_normal_df","901ad3a4":"# Let us now load the NORMAL chest x_rays from the testing set\ncount = 0\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/test\/NORMAL\/'):\n    for filename in filenames:\n        img = Image.open(os.path.join(dirname, filename)).convert('L')\n        print(filename)\n        img = ImageOps.equalize(img)\n        img = Img_resize(img)\n        img_array = np.array(img).reshape(img.size[0]*img.size[1]).tolist()\n        img_array = img_array + ['Normal','None']\n        test_normal_df = test_normal_df.append(pd.Series(img_array,index=data_col),ignore_index=True)\n        count = count + 1        \n        print('Test data ',count,' loaded into the dataframe')","4e177bcf":"test_normal_df.to_csv('\/kaggle\/working\/test_normal_df.csv',index=False)\ntest_normal_df","c52165a1":"test_pneumonia_df = pd.DataFrame(columns = data_col)\ntest_pneumonia_df","65aee086":"# Let us load the PNEUMONIA chest x_rays from the validation set\ncount = 0\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/test\/PNEUMONIA\/'):\n    for filename in filenames:\n        img = Image.open(os.path.join(dirname, filename)).convert('L')\n        print(filename)\n        img = ImageOps.equalize(img)\n        img = Img_resize(img)\n        img_array = np.array(img).reshape(img.size[0]*img.size[1]).tolist()\n        pneumonia_class = filename.split(\"_\")[1]\n        img_array = img_array + ['Pneumonia',pneumonia_class]\n        test_pneumonia_df = test_pneumonia_df.append(pd.Series(img_array,index=data_col),ignore_index=True)\n        count = count + 1        \n        print('Test data ',count,' loaded into the dataframe')","8b3522f2":"test_pneumonia_df.to_csv('\/kaggle\/working\/test_pneumonia_df.csv',index=False)\ntest_pneumonia_df","39bad47c":"#Load train,val,test dataset from preloaded_dataset\ntrain_normal_df = pd.read_csv('\/kaggle\/input\/preloaded-equalized-dataset\/train_normal_df.csv')\ntrain_pneumonia_df = pd.read_csv('\/kaggle\/input\/preloaded-equalized-dataset\/train_pneumonia_df.csv')\nval_normal_df = pd.read_csv('\/kaggle\/input\/preloaded-equalized-dataset\/val_normal_df.csv')\nval_pneumonia_df = pd.read_csv('\/kaggle\/input\/preloaded-equalized-dataset\/val_pneumonia_df.csv')\ntest_normal_df = pd.read_csv('\/kaggle\/input\/preloaded-equalized-dataset\/test_normal_df.csv')\ntest_pneumonia_df = pd.read_csv('\/kaggle\/input\/preloaded-equalized-dataset\/test_pneumonia_df.csv')","3cdb0e7d":"train_df = pd.concat([train_normal_df,train_pneumonia_df])\ntrain_df.reset_index(drop=True,inplace=True)\nval_df = pd.concat([val_normal_df,val_pneumonia_df])\nval_df.reset_index(drop=True,inplace=True)\ntest_df = pd.concat([test_normal_df,test_pneumonia_df])\ntest_df.reset_index(drop=True,inplace=True)\nprint('Size of train dataset is ',train_df.shape)\nprint('Size of validation dataset is ',val_df.shape)\nprint('Size of test dataset is ',test_df.shape)","d4702df9":"#Import all necessary tools to build the model\nimport tensorflow as tf\nfrom keras import layers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout, Convolution2D, MaxPooling2D, Flatten\n# from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\nfrom keras.models import Model\nfrom keras.preprocessing import image\nfrom keras.utils import layer_utils\nfrom keras.utils.data_utils import get_file\nfrom keras.applications.imagenet_utils import preprocess_input\nimport pydot\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model\nfrom sklearn import preprocessing\n\nimport keras.backend as K\nK.set_image_data_format('channels_last')","6e1a1142":"#convert to one_hot\ndef convert_to_one_hot(Y, C):\n    Y = np.eye(C)[Y.reshape(-1)].T\n    return Y","922f9c16":"train_df['X_Ray_Class']","7c4dd6d3":"#Encode the label. Fit and Transform\nle_Y = preprocessing.LabelEncoder()\nle_Y.fit(train_df['X_Ray_Class'].values)\n\ntrain_df['X_Ray_Class'] = train_df['X_Ray_Class'].map(lambda x: le_Y.transform([x])[0])\nval_df['X_Ray_Class'] = val_df['X_Ray_Class'].map(lambda x: le_Y.transform([x])[0])\ntest_df['X_Ray_Class'] = test_df['X_Ray_Class'].map(lambda x: le_Y.transform([x])[0])","b28509a8":"#Let us create the input(X) and output Y from the given datasets\n\n#get all pixel values into a numpy array as input of dimension (m,128,128,1)\nX_train = train_df.loc[:,:'pixel16383'].to_numpy().reshape(train_df.shape[0],128,128,1)\n#get the column X_Ray_Class as the output\nY_train = train_df['X_Ray_Class'].to_numpy().reshape(train_df.shape[0],)\n#Perform One Hot Encoding\nY_train = convert_to_one_hot(Y_train, 2).T\n#Perform same for val set\nX_val = val_df.loc[:,:'pixel16383'].to_numpy().reshape(val_df.shape[0],128,128,1)\nY_val = val_df['X_Ray_Class'].to_numpy().reshape(val_df.shape[0],)\nY_val = convert_to_one_hot(Y_val, 2).T\n#Perform for test set\nX_test = test_df.loc[:,:'pixel16383'].to_numpy().reshape(test_df.shape[0],128,128,1)\nY_test = test_df['X_Ray_Class'].to_numpy().reshape(test_df.shape[0],)\nY_test = convert_to_one_hot(Y_test, 2).T","bd2d143c":"plt.imshow((X_train[45]\/255).reshape(128,128))","c19d6db3":"X_train = X_train\/255\nX_val = X_val\/255\nX_test = X_test\/255","0f413c78":"#Print the dimensions of the train and test(dev) set to verify.\nprint (\"number of training examples = \" + str(X_train.shape[0]))\nprint (\"number of validation examples = \" + str(X_val.shape[0]))\nprint (\"number of test examples = \" + str(X_test.shape[0]))\nprint (\"X_train shape: \" + str(X_train.shape))\nprint (\"Y_train shape: \" + str(Y_train.shape))\nprint (\"X_val shape: \" + str(X_val.shape))\nprint (\"Y_val shape: \" + str(Y_val.shape))\nprint (\"X_test shape: \" + str(X_test.shape))\nprint (\"Y_test shape: \" + str(Y_test.shape))","dbd9921e":"def simpleModel():\n    img_rows, img_cols = 128, 128\n    input_shape = (img_rows, img_cols, 1)\n    \n    model = Sequential()\n    model.add(Convolution2D(32, (3, 3), padding=\"same\", activation=\"relu\",input_shape=input_shape))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n    model.add(Convolution2D(64, (3, 3), padding=\"same\", activation=\"relu\"))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n    model.add(Convolution2D(64, (3, 3), padding=\"same\", activation=\"relu\"))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n    model.add(Convolution2D(64, (3, 3), padding=\"same\", activation=\"relu\"))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Flatten())\n    model.add(Dense(128,activation = 'relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(2))\n    model.add(Activation('softmax'))\n    \n    return model\n    ","dd00ad57":"model = simpleModel()\nmodel.compile(optimizer=\"adam\",loss='binary_crossentropy',metrics=[\"accuracy\"])","4defb3e6":"model.fit(X_train,Y_train,batch_size=64,epochs=10)","1d3da0bf":"#Compute the accuracy for the val test\npreds = model.evaluate(X_val,Y_val,batch_size=64)\n\nprint (\"Loss = \" + str(preds[0]))\nprint (\"Dev Accuracy = \" + str(preds[1]))","07854d6f":"#Compute the accuracy for the test test\npreds = model.evaluate(X_test,Y_test,batch_size=64)\n\nprint (\"Loss = \" + str(preds[0]))\nprint (\"Test Accuracy = \" + str(preds[1]))","0d6e26c8":"model.summary()","8620226d":"### Let us load the train data corresponding to the pneumonia chest x-rays as well","a9103f5d":"## VGG - 16 Architecture","2d723500":"### In case you dont want to waste time, directly upload dataset from preloaded csv","a8ec251a":"#### Let us first build a simple CNN that classifies an X-Ray image as either Normal(0) or having Pneumonia(1).\nIn this binary classification we do not care about the type of pneumonia present. We shall look into that later on. Hence the Pneumonia_Class in each dataframe is unimportant for this task.","1ba96647":"### Build the training dataset ","4d0cf2cc":"### Histogram Equilization","52328afb":"To avoid hours of toiling to just get the images into a dataframe, I have provided with preloaded dataset where all images have been transformed into dimensions of (128,128) and labels regarding X_Ray_Class and Pneumonia_Class have also been given. The X_Ray_Class in each of the dataframe is either 'Pneuomia' or 'Normal' indicating presence\/absence of pneumonia in given X-Rays. The label Pneumonia_Class is 'None' for 'Normal' X-Rays and 'viral' or 'bacterial' for the 'Pneumonia' X-Rays.\n\n* Training dataset:\nThere are 1341 rows in the train_normal csv and 3875 rows in train_pneumonia csv. Both the dataframes have 16386 cols (16384 pixel cols + 2 Classes).\nValidation dataset:\n\n* Testing dataset:\nThere are 234 rows in the test_normal and 390 rows in test_pneumonia.Both the dataframes have 16386 cols (16384 pixel cols + 2 Classes).","c9328171":"### Let us Load the validation set as well ","c697c2b0":"### Let us Resize the image to ease performance of Neural Net","8571e5c7":"### Let us Load the test set as well ","4e46e06e":"## Let us build the Simple Model","29ac3f2d":"# Binary Classication","dda944e7":"### Let us take a loot at the image","9fa5764a":"### Loading the training datasets into the dataframe"}}