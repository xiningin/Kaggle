{"cell_type":{"4170eee7":"code","cce928c4":"code","0aefed30":"code","8b415336":"code","b81c2356":"code","86abeba0":"code","8cc7daf7":"code","e58cca88":"code","b7b4c295":"code","a1c02b81":"code","359015b3":"code","24abce93":"code","72082e7d":"code","8efde5ea":"code","dba4f9dd":"code","8d821cb1":"code","f497e7d6":"code","386a7d9a":"code","00f3cadd":"code","db61e0d7":"code","4cceab2e":"code","77a5b074":"code","770c7099":"code","614a9762":"code","fd05ef24":"code","2ff8e233":"code","989da1f0":"code","5b880262":"code","74933927":"code","0ae63ca0":"code","b241f11b":"code","f6212297":"code","86feb14b":"code","237175e9":"markdown","6a372f80":"markdown","b40a9a15":"markdown","dd29db63":"markdown","74074b06":"markdown","54d51b50":"markdown","7450b8eb":"markdown","fd2d1539":"markdown","34ad2f78":"markdown","994eb875":"markdown","697b497f":"markdown","48c1d1c7":"markdown","af08065c":"markdown","0070a488":"markdown","11acc2a4":"markdown","2d505f6a":"markdown","b319651e":"markdown","58073b4d":"markdown","5ad86507":"markdown"},"source":{"4170eee7":"import numpy as np\nimport pandas as pd\nimport os\nimport sys\nimport tqdm\nfrom multiprocessing import  Pool\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom math import sqrt\ntrain_on_gpu = False\n\n# Visualisation libs\nimport matplotlib.pyplot as plt\nfrom matplotlib.legend_handler import HandlerLine2D\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import Imputer, StandardScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost.sklearn import XGBRegressor","cce928c4":"print('In input directory:')\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","0aefed30":"train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\nsample_submission = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')\n\ntrain.shape, test.shape, sample_submission.shape","8b415336":"def score(y_actual, y_predicted):\n    # because competetion uses RMSLE\n    return sqrt(mean_squared_log_error(y_actual, y_predicted))\n    \ndef fillNaNInfinity(df):\n    df.replace([np.inf, -np.inf], np.nan)\n    df.fillna(0, inplace=True)\n    return df\n\ndef fillInfinity(df):\n    df.replace([np.inf, -np.inf], np.nan)\n    return df","b81c2356":"data = pd.concat([\n    train.loc[:, train.columns != 'SalePrice'], test\n])\n\ntarget = np.log(train['SalePrice'] + 1)\n\ndata.shape, target.shape","86abeba0":"# From https:\/\/www.kaggle.com\/miguelangelnieto\/pca-and-regression#Simple-Neural-Network, loved it\nnans = pd.isnull(data).sum()\nnans[ nans > 0 ]","8cc7daf7":"columns_to_remove = nans[ nans > 500 ].reset_index()['index'].tolist()\ncolumns_to_remove","e58cca88":"data.drop(labels=columns_to_remove, axis=1, inplace=True)\ndata.shape","b7b4c295":"nans = pd.isnull(data).sum()\nnans[ nans > 5 ]","a1c02b81":"df = data.copy() # don't want to modify orginal data\n\nmore_columns_to_remove = nans[ nans > 5 ].reset_index()['index'].tolist()\ndf.drop(labels=more_columns_to_remove, axis=1, inplace=True)\nprint(df.shape)\ndf = pd.get_dummies(df)\nprint(df.shape)\nxgbr = XGBRegressor(learning_rate=0.01, n_estimators=3460,\n                                     max_depth=3, min_child_weight=0,\n                                     gamma=0, subsample=0.7,\n                                     colsample_bytree=0.7)\nX = df[:1460]\ny = target\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n\nxgbr.fit(X_train, y_train)\n\nscore(np.exp(y_train) - 1, np.exp(xgbr.predict(X_train)) - 1), score(np.exp(y_test) - 1, np.exp(xgbr.predict(X_test)) - 1)","359015b3":"data['LotFrontage'].describe()","24abce93":"sns.distplot(data['LotFrontage'].fillna(0));","72082e7d":"data['Neighborhood'].describe()","8efde5ea":"data.groupby('Neighborhood')['LotFrontage'].agg(['count', 'mean', 'median'])","dba4f9dd":"data[ data['LotFrontage'].isnull() ]['Neighborhood'].reset_index()['Neighborhood'].isnull().sum()","8d821cb1":"# https:\/\/stackoverflow.com\/questions\/39480997\/how-to-use-a-user-function-to-fillna-in-pandas\ndata['LotFrontage'] = data.groupby('Neighborhood')['LotFrontage'].transform(lambda group: group.fillna(group.median()))\n\ndata['LotFrontage'].isnull().sum()","f497e7d6":"data['MasVnrType'].describe()","386a7d9a":"data['MasVnrType'].value_counts()","00f3cadd":"data['MasVnrArea'].describe()","db61e0d7":"sns.distplot(data['MasVnrArea'].fillna(0));","4cceab2e":"data.groupby('MasVnrType')['MasVnrArea'].agg(['mean', 'median', 'count'])","77a5b074":"# data.drop(labels=['MasVnrArea'], axis=1, inplace=True)\n\n# I checked that model works . better if we keep these 2 columns","770c7099":"data[['BsmtCond', 'BsmtQual']].describe()","614a9762":"data[['BsmtCond', 'BsmtQual']].isnull().sum()","fd05ef24":"data['BsmtCond'].value_counts()","2ff8e233":"data['BsmtQual'].value_counts()","989da1f0":"# NA is not available\ndata[['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']].fillna('NA', inplace=True)","5b880262":"data[[\n    'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageQual' \n]].describe()","74933927":"df = data.copy()\ndf = pd.get_dummies(df)\ndf.shape","0ae63ca0":"xgbr = XGBRegressor(learning_rate=0.01, n_estimators=3460,\n                                     max_depth=3, min_child_weight=0,\n                                     gamma=0, subsample=0.7,\n                                     colsample_bytree=0.7)\nX = df[:1460]\ny = target\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n\nxgbr.fit(X_train, y_train)","b241f11b":"score(np.exp(y_train) - 1, np.exp(xgbr.predict(X_train)) - 1), score(np.exp(y_test) - 1, np.exp(xgbr.predict(X_test)) - 1)","f6212297":"test = df[1460:]\nsample_submission['SalePrice'] = xgbr.predict(test)\nsample_submission['SalePrice'] = np.exp(sample_submission['SalePrice']) - 1\nsample_submission.head()","86feb14b":"sample_submission.to_csv('submission.csv', index=False)","237175e9":"# EDA","6a372f80":"## MasVnrType and MasVnrArea","b40a9a15":"Coming soon, garage missing data handling","dd29db63":"Now we will look into each of above fields individually. You can see from above, most of the missing data is of basement and garage.\nBefore that, let's try to see if we just remove all of them, what will happen","74074b06":"See columns which have more than 500 cells null","54d51b50":"# Load the data","7450b8eb":"## Garage","fd2d1539":"The score is little better than when we just removed all null value columns, and far better than [when we just replaced NaNs with 0](https:\/\/www.kaggle.com\/mukul1904\/house-prices-random-forest-and-xgboost).","34ad2f78":"# Import libraries","994eb875":"# Training model","697b497f":"Check the number of null values in each column","48c1d1c7":"# Helper functions","af08065c":"## LotFrontage","0070a488":"# Handle missing data","11acc2a4":"Not a great score, so let's continue with our handling missing data route","2d505f6a":"## Basement","b319651e":"This means, all the records which have LotFrontage has null, but they have Neighborhood filled. From that we can find the LotFrontage, as it shouldn't be too different from other properties.","58073b4d":"One hot-encoding","5ad86507":"I already made a kernel on the House Sales dataset, you can find it [here](https:\/\/www.kaggle.com\/mukul1904\/house-prices-random-forest-and-xgboost). In that, I got around 0.14 score and couldn't get more (less) than that, and I tried everythign from PCA to different models. The trick in this competetion is handling missing data.\n\nSo, in this notebook I'll focus on handling the missing values for each column, by analyzing each column separately."}}