{"cell_type":{"c7d7dadd":"code","dbb64234":"code","3a9dfe5b":"code","f5df0c5d":"code","662ab2eb":"code","79f1492a":"code","90fb173d":"code","b58f07b5":"code","a3571f19":"code","44cdaca5":"code","71f7ca1a":"code","8aad6ed8":"code","4c2f786d":"code","88623711":"code","97e4fcae":"code","bc7fb249":"code","4e2aa696":"code","f5b98f1e":"code","a94499c7":"code","10bc6a33":"code","ccf16007":"code","9ccb725b":"code","66b33433":"code","70a0f9a1":"code","7ba4521e":"code","a67bd6ff":"code","6bb5b7fa":"code","d9964ff6":"code","179cf884":"code","c89f8d14":"code","1ac58043":"code","208cf8aa":"code","71f5b59d":"code","8157fd08":"code","761a9dc6":"code","3f6c3168":"code","c455620b":"code","e3e49bdf":"code","8b5a4d7e":"code","6920da0d":"code","55b49ba3":"markdown","ab1f09e7":"markdown","bdf88434":"markdown","27cd6d3b":"markdown","1226d79c":"markdown","5a3be570":"markdown","9e8089f3":"markdown","a04344d6":"markdown","64335796":"markdown","8a429f21":"markdown","2fbb8d7e":"markdown"},"source":{"c7d7dadd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dbb64234":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()","3a9dfe5b":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","f5df0c5d":"women = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)\/len(women)\n\nprint(\"% of women who survived:\", rate_women)","662ab2eb":"men = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)\/len(men)\n\nprint(\"% of men who survived:\", rate_men)","79f1492a":"train_data.isnull().sum()","90fb173d":"sns.heatmap(train_data.isnull(), yticklabels = False)","b58f07b5":"sns.set_style('whitegrid')\nsns.countplot(train_data['Survived'])","a3571f19":"sns.set_style('whitegrid')\nsns.countplot(x='Survived', hue='Pclass', data=train_data)","44cdaca5":"sns.distplot(train_data['Age'].dropna(), kde= False, bins = 40)","71f7ca1a":"train_data['Age'].hist(bins=40)","8aad6ed8":"sns.countplot(x='SibSp',data=train_data)","4c2f786d":"sns.boxplot(x='Pclass',y='Age',data=train_data)","88623711":"def impute_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n\n        if Pclass == 1:\n            return 37\n\n        elif Pclass == 2:\n            return 29\n\n        else:\n            return 24\n\n    else:\n        return Age","97e4fcae":"train_data['Age'] = train_data[['Age','Pclass']].apply(impute_age,axis=1)","bc7fb249":"sns.heatmap(train_data.isnull(),yticklabels=False)","4e2aa696":"test_data.isnull().sum()","f5b98f1e":"sns.heatmap(test_data.isnull(),yticklabels=False)","a94499c7":"test_data['Age'] = train_data[['Age','Pclass']].apply(impute_age,axis=1)","10bc6a33":"train_data.drop('Cabin', axis =1, inplace= True)","ccf16007":"sns.heatmap(train_data.isnull(),yticklabels=False)","9ccb725b":"test_data.drop('Cabin', axis =1, inplace= True)","66b33433":"test_data['Fare'].fillna((test_data['Fare'].mean()),inplace=True)","70a0f9a1":"test_data.isnull().sum()","7ba4521e":"sns.heatmap(test_data.isnull(),yticklabels=False)","a67bd6ff":"train_data.info()","6bb5b7fa":"train_data.Embarked.value_counts()","d9964ff6":"sex = pd.get_dummies(train_data['Sex'],drop_first=True)\nembark = pd.get_dummies(train_data['Embarked'],drop_first=True)","179cf884":"train_data.drop(['Sex','Embarked','Name','Ticket','PassengerId'],axis=1,inplace=True)","c89f8d14":"train_data.head()","1ac58043":"train_data = pd.concat([train_data,sex,embark],axis=1)","208cf8aa":"train_data.head()","71f5b59d":"test_sex = pd.get_dummies(test_data['Sex'],drop_first=True)\ntest_embark = pd.get_dummies(test_data['Embarked'],drop_first=True)","8157fd08":"test_data.drop(['Sex','Embarked','Name','Ticket'],axis=1,inplace=True)","761a9dc6":"test_data = pd.concat([test_data,test_sex,test_embark],axis=1)","3f6c3168":"x_train = train_data.drop( 'Survived', axis = 1)","c455620b":"x_test = test_data.drop('PassengerId' , axis = 1)","e3e49bdf":"y = train_data[\"Survived\"]","8b5a4d7e":"x_test.isnull().sum()","6920da0d":"from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(x_train, y)\npredictions = model.predict(x_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","55b49ba3":"### On test set ","ab1f09e7":"# Filling Missing Data","bdf88434":"## on train set","27cd6d3b":"# EDA on dataset","1226d79c":"# Explore a pattern","5a3be570":"### on test set","9e8089f3":"### Drop \"Cabin\" column from train and test set","a04344d6":"# Building Model","64335796":"# Converting Categorical Features","8a429f21":"# Read the data ","2fbb8d7e":"### On train set"}}