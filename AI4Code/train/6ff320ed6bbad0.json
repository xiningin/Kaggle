{"cell_type":{"0405a7d3":"code","67cc65a7":"code","278cb23d":"code","ff60ef81":"code","bbc86356":"code","cd45d50c":"code","b9d07473":"code","c1b27753":"code","56f7ad5f":"code","94ecc4c9":"code","a9be973f":"code","37a66ca8":"code","8e5a4bba":"code","21e5e7a1":"code","f2508925":"code","a5e22095":"code","a13796ca":"code","4e129bb8":"code","9c1dd24f":"code","e195a3e3":"code","8df8454a":"code","141288cd":"code","0ba5c55b":"code","0fe984eb":"code","bdbeac01":"code","0bccdbeb":"code","fb677e12":"code","22a32b21":"code","859482eb":"code","c990aa78":"code","ef053063":"code","fc650e4e":"code","2c8c167c":"code","eaea7e9e":"code","8d13eba9":"code","798b8aaf":"markdown","042dcc9e":"markdown","117e943f":"markdown","151a6896":"markdown","84d18ca2":"markdown","1a0bfc91":"markdown","2f680d52":"markdown","042a622d":"markdown","c32c8563":"markdown","c8918a37":"markdown","94f7a18a":"markdown","12b50a26":"markdown","2c8f2583":"markdown","1559297b":"markdown","8bcd9869":"markdown"},"source":{"0405a7d3":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np","67cc65a7":"mnist = tf.keras.datasets.mnist  #28x28 size image","278cb23d":"print(mnist)","ff60ef81":" ## After loading we will divide the data into test and train data","bbc86356":"(x_train,y_train),(x_test,y_test)= mnist.load_data()","cd45d50c":"print(mnist)","b9d07473":"## Checking the shape of the data","c1b27753":"x_train.shape","56f7ad5f":"x_train","94ecc4c9":"x_test.shape","a9be973f":"plt.imshow(x_train[0])","37a66ca8":"plt.imshow(x_train[1])","8e5a4bba":"plt.imshow(x_train[0],cmap=plt.cm.binary) #Before normalizing the image","21e5e7a1":"plt.imshow(x_train[0],cmap='gray')","f2508925":"print(x_train[0]) #before normalization","a5e22095":"x_train=tf.keras.utils.normalize(x_train,axis=1)\nx_test=tf.keras.utils.normalize(x_test,axis=1)","a13796ca":"plt.imshow(x_train[0],cmap=plt.cm.binary) #After normalizing the image","4e129bb8":"print(x_train[0])","9c1dd24f":"print(y_train[0])   #Target","e195a3e3":"IMG_SIZE=28\nx_train= np.array(x_train).reshape(-1,IMG_SIZE,IMG_SIZE,1)\nx_test= np.array(x_test).reshape(-1,IMG_SIZE,IMG_SIZE,1)","8df8454a":"print('Training Samples shape',x_train.shape)\nprint('Testing Samples shape',x_test.shape)","141288cd":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Dropout,Activation,Flatten,Conv2D,MaxPooling2D","0ba5c55b":"#Creating a neural network\nmodel= Sequential()\n\n#Pass 1\nmodel.add(Conv2D(64,(3,3),input_shape= x_train.shape[1:]))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\n#Pass 2\nmodel.add(Conv2D(64,(3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\n#Pass 3\nmodel.add(Conv2D(64,(3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\n# the model so far outputs 3D feature maps (height, width, features)","0fe984eb":"#Fully connected layer-1\nmodel.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\nmodel.add(Dense(64))  # fully connect ANN Network\nmodel.add(Activation('relu'))\n\n#Fully connected layer-2\nmodel.add(Dense(32))  # fully connect ANN Network\nmodel.add(Activation('relu'))\n\n#Fully connected layer-3\nmodel.add(Dense(10))  # fully connect ANN Network #Last layer will give output \nmodel.add(Activation('softmax')) #In this case we have use softmax CLASS PROBABILITIES \n#We can also use sigmoid if one neuron in dense layer dense(1)","bdbeac01":"model.summary()","0bccdbeb":"model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])","fb677e12":"model.fit(x_train,y_train,epochs=5,validation_split=0.3)","22a32b21":"test_loss,test_acc= model.evaluate(x_test,y_test)\nprint('loss=',test_loss*100)\nprint('accuracy=',test_acc*100)","859482eb":"prediction= model.predict(x_test)","c990aa78":"print(prediction)","ef053063":"#All the values given above are giving the probability of the image no. so we need to decode this to show the lable value ","fc650e4e":"print(np.argmax(prediction[1]))","2c8c167c":"plt.imshow(x_test[1])","eaea7e9e":"print(np.argmax(prediction[6788]))","8d13eba9":"plt.imshow(x_test[6788])","798b8aaf":"## Evaluating on testing data","042dcc9e":"## Training the model","117e943f":"## Preprocessing the data","151a6896":"## Importing libraries","84d18ca2":"## Creating model\n","1a0bfc91":"## Resizing image for making it suitable for kernal operation (Convolution)","2f680d52":"## NLP Layers","042a622d":"## Normalization of data","c32c8563":"## Summarizing the model\n","c8918a37":"## Checking the images\n","94f7a18a":"## Prediction","12b50a26":"## Compiling the model","2c8f2583":"## Checking values of each pixel\n","1559297b":"## Converted the image to binary","8bcd9869":"## Importing the data set"}}