{"cell_type":{"6d8af2dc":"code","68269074":"code","787f5195":"code","b5f489cb":"code","78f20987":"code","610b0512":"code","64c633ca":"code","c66106e7":"code","62ad33cc":"code","dfcc95cf":"code","583efa28":"code","022e4287":"code","6e08dc8f":"code","62c329e8":"code","b21b79f1":"code","4ed4fb32":"code","23e5f45e":"code","ab1f914a":"code","372fc9c3":"code","5d94db41":"code","879e4e01":"code","0b23a428":"code","d1fe9a19":"code","0b1de423":"code","81380714":"code","7e99fb23":"code","1f5b9c3d":"code","8c240d52":"markdown","9577367b":"markdown","8902ac07":"markdown","5e09457e":"markdown","46cc9ea5":"markdown","d59e593a":"markdown","cd7e46a1":"markdown","8d4775de":"markdown","3f439632":"markdown"},"source":{"6d8af2dc":"import requests\nimport numpy as np\nimport matplotlib.pyplot as plt","68269074":"# Some labels are defined to be used for plotting the data\nlabels = ['Sepal length (cm)', 'Sepal width (cm)', 'Petal length (cm)', 'Petal width (cm)']\nclasses = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']","787f5195":"# The Iris dataset is retrieved from UCI\nurl = \"https:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/iris\/iris.data\"\ntext = requests.get(url).text","b5f489cb":"# Data is converted to numpy arrays\n# Replacing class labels for an numeric id (0, 1, 2)\nfor i, c in enumerate(classes):\n    text = text.replace(c, str(i))\n\n# Converting to a numerical matrix\ndata = np.array([\n    [\n        float(item) \n        for i, item in enumerate(line.split(\",\"))\n    ]\n    for line in text.strip().split(\"\\n\") # Extract observations\n])\n\n# Array of classes\nX = data[:, :-1]\ny = data[:, 4]","78f20987":"# Colors for plotting\ncolors = [['blue', 'orange', 'green'][int(i)] for i in y]","610b0512":"def mean(X):\n    \"\"\"\n    The mean is computed for a dataset matrix.\n    Input:\n        X : a dataset matrix\n    Return:\n        A d-dimensional array with the mean for each attribute\n    \"\"\"\n    N = X.shape[0]\n    D = X.shape[1]\n    accum = np.zeros(D)\n    for i in range(N):\n        accum += X[i, :]\n    return accum \/ N","64c633ca":"mean(X)","c66106e7":"# The mean for a dataset matrix can be directly computed using numpy\nX.mean(axis=0)","62ad33cc":"def var(x):\n    \"\"\"\n    The variance for a vector attribute is computed\n    Input:\n        x : A vector attribute\n    Return:\n        A scalar representing the variance\n    \"\"\"\n    N = x.shape[0]\n    diff = x - x.mean()\n    return diff.T @ diff \/ N","dfcc95cf":"# Variance for sepal lenght\nx = X[:, 0]\nvar(x)","583efa28":"# The variance for a vector can be computed using directly the numpy library\nx.var()","022e4287":"def cov(x, y):\n    if x.shape != y.shape:\n        raise Exception('mismatch in size of vectors')\n    N = x.shape[0]\n    return (x.T @ y) \/ N  - x.mean() * y.mean()","6e08dc8f":"# Covariance between sepal length and sepal width\ny = data[:, 1]\ncov(x, y)","62c329e8":"plt.scatter(x, y, color=colors)\nplt.xlabel(labels[0])\nplt.ylabel(labels[1])","b21b79f1":"def cov_matrix(X):\n    \"\"\"\n    The covariance matrix for X is computed\n    Input:\n        X : a n x d dataset matrix\n    Return\n        A d x d matrix with covariances\n    \"\"\"\n    centered = X - X.mean(axis=0)\n    N = X.shape[0]\n    return (centered.T @ centered) \/ N","4ed4fb32":"cov_matrix(X)","23e5f45e":"# The covariance matrix can be computed directly using the numpy library\nnp.cov(X.T)","ab1f914a":"def plot_data_matrix(X):\n    fig, ax = plt.subplots(nrows=4, ncols=4, figsize=(16, 16))\n    D = X.shape[1]\n    for i in range(D):\n        for j in range(D):\n            if i != j:\n                ax[i, j].scatter(X[:, i], X[:, j], color=colors, alpha=0.5)\n            else:\n                for k in range(3):\n                    lower = k * 50\n                    upper = (k + 1) * 50\n                    ax[i, j].hist(X[lower:upper, i], color=colors[lower:upper][0], alpha=0.5, label=classes[k])\n        ax[i, 0].set_ylabel(labels[i])\n        ax[-1, i].set_xlabel(labels[i])","372fc9c3":"plot_data_matrix(X)","5d94db41":"def corr(x, y):\n    return cov(x, y) \/ np.sqrt((var(x) * var(y)))","879e4e01":"corr(x, y)","0b23a428":"def corr_matrix(X):\n    sigma = cov_matrix(X)\n    for i in range(sigma.shape[0]):\n        for j in range(i, sigma.shape[1]):\n            sigma[i, j] \/= np.sqrt(var(X[:, i]) * var(X[:, j]))\n            sigma[j, i] = sigma[i, j]\n    return sigma","d1fe9a19":"corr_matrix(X)","0b1de423":"# The correlation matrix can be computed directly using the numpy library\nnp.corrcoef(X.T)","81380714":"def plot_corr_matrix(X):\n    fig, ax = plt.subplots(nrows=4, ncols=4, figsize=(16, 16))\n    D = X.shape[1]\n    for i in range(D):\n        for j in range(D):\n            if i != j:\n                ax[i, j].scatter(X[:, i], X[:, j], color=colors, alpha=0.5)\n                x = X[:, i]\n                y = X[:, j]\n                m = corr(x, y)\n                b = y.mean() - m * x.mean()\n                x1 = x.min()\n                x2 = x.max()\n                y1 = m * x1 + b\n                y2 = m * x2 + b \n                ax[i, j].plot([x1, x2], [y1, y2], color='red', label='Corr(x, y) = %f' % corr(x, y))\n            else:\n                for k in range(3):\n                    lower = k * 50\n                    upper = (k + 1) * 50\n                    ax[i, j].hist(X[lower:upper, i], color=colors[lower:upper][0], alpha=0.5, label=classes[k])\n            ax[i, j].legend()\n        ax[i, 0].set_ylabel(labels[i])\n        ax[-1, i].set_xlabel(labels[i])","7e99fb23":"plot_corr_matrix(X)","1f5b9c3d":"# Checking identities\n\nA = np.random.rand(4, 4)\nb = np.random.rand(4)\n\nassert ((x + y).mean() - (x.mean() + y.mean())) < 1e-9\nassert ((x - y).mean() - (x.mean() - y.mean())) < 1e-9\n\nassert (var(x + y) - (var(x) + var(y) + cov(x, y) + cov(y, x))) < 1e-9\nassert (var(x - y) - (var(x) + var(y) - cov(x, y) - cov(y, x))) < 1e-9\n\nassert np.allclose(mean(X @ A + b), mean(X) @ A + b, 1e-9)\nassert np.allclose(cov_matrix(X @ A + b), A.T @ cov_matrix(X) @ A, 1e-9)","8c240d52":"## Covariance\n\nAssuming we have to vectors $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}$. Ther covariance is given the expected product of their deviations from their respective means.\n\n$$Cov(\\mathbf{x}, \\mathbf{y}) =\n  \\mathbb{E}_{\\mathbf{x},\\mathbf{y}} \n  [\n    (\\mathbf{x} - \\mathbb{E}_{\\mathbf{x}}[\\mathbf{x}])\n    (\\mathbf{y} - \\mathbb{E}_{\\mathbf{y}}[\\mathbf{y}])\n  ]\n$$\n\n$$Cov(\\mathbf{x}, \\mathbf{y}) = \\mathbb{E}[\\mathbf{x} \\mathbf{y}] - \\mathbb{E}[\\mathbf{x}]E[\\mathbf{y}]$$\n\n$$Cov(\\mathbf{x}, \\mathbf{y}) = \\mathbf{\\mu}_{\\mathbf{xy}} - \\mathbf{\\mu}_{\\mathbf{x}} \\mathbf{\\mu}_{\\mathbf{y}}$$","9577367b":"## References\n\n* Fisher, R.A. (1936). Iris Data Set. UCI Machine Learning Repository. Irvine, CA: University of California, School of Information and Computer Science. https:\/\/archive.ics.uci.edu\/ml\/datasets\/iris\n* Deisenroth, M.P., Faisal, A.A., & Ong, C.S. (2019). _Mathematics for Machine Learning_. Cambridge University Press. pp. 187-194.","8902ac07":"## Mean\n\nThe mean is the aritmetic average of obserations for each attribute.\n\n$$\\mathbb{\\mu} = \\frac{1}{N} \\sum_{n=1}^N x_n, x_n \\in \\mathbb{R}^D$$","5e09457e":"## Transformations\n\nMeans and variances meet the following transformations:\n\n$$ \\mathbf{\\mu}(\\mathbf{x} + \\mathbf{y}) = \\mathbf{\\mu}(\\mathbf{x}) + \\mathbf{\\mu}(\\mathbf{y}) $$\n\n$$\\mathbf{\\mu}(\\mathbf{x} - \\mathbf{y}) = \\mathbf{\\mu}(\\mathbf{x}) - \\mathbf{\\mu}(\\mathbf{y})$$\n\n$$Var(\\mathbf{x} + \\mathbf{y}) = Var(\\mathbf{x}) + Var(\\mathbf{y}) + Cov(\\mathbf{x}, \\mathbf{y}) + Cov(\\mathbf{y}, \\mathbf{x})$$\n\n$$Var(\\mathbf{x} - \\mathbf{y}) = Var(\\mathbf{x}) + Var(\\mathbf{y}) - Cov(\\mathbf{x}, \\mathbf{y}) - Cov(\\mathbf{y}, \\mathbf{x})$$\n\n$$\\mathbf{\\mu}(\\mathbf{AX} + \\mathbf{b}) = \\mathbf{A}\\mathbf{\\mu}_\\mathbf{X} + \\mathbf{b}$$\n\n$$Cov(\\mathbf{AX} + \\mathbf{b}) = \\mathbf{A} \\mathbf{\\Sigma}_\\mathbf{X} \\mathbf{A}^T$$\n","46cc9ea5":"## Correlation\n\nThe correlation between two random variables $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}$ is given by:\n\n$$Corr(\\mathbf{x}, \\mathbf{y}) = \\frac{Cov(\\mathbf{x}, \\mathbf{y})}{\\sqrt{Var(\\mathbf{x}) Var(\\mathbf{y})}}$$\n\nValues are in [-1,1].","d59e593a":"# Mean, (Co)Variance, and Correlation\n\nJ. Lopez  \nAug. 13, 2021\n\nIn this notebook the mean, the (co)variance, and the correlation concepts from a linear algebra perspective are explained and tested. As example, the Iris dataset is used.","cd7e46a1":"## Covariance matrix\n\nIf $\\mathbf{X}$ is a random variable with states $\\mathbf{x} \\in \\mathbb{R}^D$ and a mean vector $\\mathbf{\\mu}$, then the covariance matrix is given by:\n\n$$\\mathbf{\\Sigma} = \\mathbb{E}[(\\mathbf{X} - \\mu)^T (\\mathbf{X} - \\mu)]$$","8d4775de":"## Variance\n\n\n$$Var(\\mathbf{x}) = \\frac{1}{N} \\sum_{n=1}^N (x_n - \\mu)^2 $$","3f439632":"## Working dataset\n\nIris dataset (Fished, 1936) is used to develop this topic. Its attributes are:\n\n* sepal length in cm\n* sepal width in cm\n* petal length in cm\n* petal width in cm\n* class:\n    - Iris Setosa\n    - Iris Versicolour\n    - Iris Virginica"}}