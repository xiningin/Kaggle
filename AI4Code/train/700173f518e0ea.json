{"cell_type":{"cd165bf1":"code","76a25b7f":"code","09331340":"code","4a93e70f":"code","5cde3900":"code","ff070e44":"code","14c31e22":"code","622cda27":"code","b0c46314":"code","e8cbcfd5":"markdown","5fe552c9":"markdown","5bf5ad57":"markdown","56af54f3":"markdown"},"source":{"cd165bf1":"# data science basics\nimport numpy as np\nimport pandas as pd\n\n# decision tree\nfrom sklearn import tree\nimport graphviz \nimport lightgbm as lgb\n\n# basic NLP\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n\n# scores\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import f1_score\n\n# utils\nfrom collections import Counter\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom tqdm.notebook import tqdm\nimport os\nos.listdir(\"..\/input\/ykc-cup-2nd\/\")\n\n# visualize\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style\nimport seaborn as sns\nfrom matplotlib import pyplot\nfrom matplotlib.ticker import ScalarFormatter\nsns.set_context(\"talk\")\nstyle.use('seaborn-colorblind') # \u3053\u306e\u30c6\u30fc\u30de\u597d\u304d\n\nimport warnings\nwarnings.filterwarnings('ignore')","76a25b7f":"def read_data(): # \u95a2\u6570\u5316\u3059\u308b\u3068\u65e9\u3044\u3089\u3057\u3044\n    train = pd.read_csv(\"..\/input\/ykc-cup-2nd\/train.csv\")\n    test = pd.read_csv(\"..\/input\/ykc-cup-2nd\/test.csv\")\n    sub = pd.read_csv(\"..\/input\/ykc-cup-2nd\/sample_submission.csv\")\n    return train, test, sub\ntrain, test, sub = read_data()","09331340":"print(train.shape)\ntrain.head()","4a93e70f":"print(test.shape)\ntest.head()","5cde3900":"print(sub.shape)\nsub.head()","ff070e44":"# unique counts\ntrain['department_id'].value_counts()","14c31e22":"fig = plt.figure()\nfor d in range(21):\n    stopwords = set(STOPWORDS)\n    wordcloud = WordCloud(\n                          background_color='black',\n                          stopwords=stopwords,\n                          max_words=200,\n                          max_font_size=40, \n                          random_state=1220\n                         ).generate(str(train.loc[train['department_id'] == d, 'product_name']))\n    plt.imshow(wordcloud)\n    plt.title(f'department_id = {d}')\n    plt.axis('off')\n    plt.show()","622cda27":"train['product_name'].values[:5].tolist()","b0c46314":"# Tf-Idf\nfig = plt.figure()\nfor dpt_id in range(21):\n    corpus = train.loc[train['department_id'] == dpt_id, 'product_name'].values.tolist()\n    vectorizer = TfidfVectorizer()\n    X = vectorizer.fit_transform(corpus)\n\n    # top 20 important words\n    df = pd.DataFrame()\n    df['words'] = vectorizer.get_feature_names()\n    df['tfidf'] = X.toarray().mean(axis=0)\n    g = sns.barplot(x='words', y='tfidf', data=df.sort_values(by='tfidf', ascending=False).iloc[:20]);\n    g.set_xticklabels(g.get_xticklabels(), rotation=45, ha='right')\n    g.set_title(f'department_id = {dpt_id}')\n    plt.show()","e8cbcfd5":"# Wordcloud\n\u305d\u308c\u305e\u308c\u306e\u30bf\u30fc\u30b2\u30c3\u30c8\uff08department_id\uff09\u3054\u3068\u306b\u3001\u3069\u3093\u306a\u5358\u8a9e\u304c\u591a\u3044\u306e\u304b\u898b\u3066\u307f\u3088\u3046\u3088","5fe552c9":"TfIdf\u3084\u3063\u3066\u307f\u308b","5bf5ad57":"# Read data ","56af54f3":"# Tf-idf\n\u6570\u5024\u3067\u898b\u3066\u307f\u3088\u3046\u3088"}}