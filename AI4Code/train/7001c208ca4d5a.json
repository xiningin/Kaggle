{"cell_type":{"4e8f1831":"code","a73e12b7":"code","d847210e":"code","0ea2c1bf":"code","81f59d7f":"code","5cb1ef41":"code","8f298db6":"code","1e3ae8c7":"code","302126c7":"code","413a8742":"code","b9fdcf38":"code","3a232771":"code","8a52586e":"code","41185715":"code","6963f8aa":"code","c4627f74":"code","b8c66d29":"code","92daf09c":"code","ef1ab2ab":"code","b85a2092":"code","8fb61a1e":"code","575f7dae":"code","c9a64c0e":"code","6dd2d142":"code","31944aa1":"code","9825c8b7":"code","bed62622":"code","d13a4784":"code","1002a3ed":"code","51ff2838":"code","7b224688":"code","4a75f240":"code","b1863950":"code","288666bf":"code","fd6ea982":"code","d67c35f2":"code","718f5a77":"code","0ce7b967":"code","93f4030f":"code","f3256dee":"code","042d22aa":"markdown","84604dff":"markdown","89ea72ae":"markdown","750dee2c":"markdown","ddb6db80":"markdown","363f7b3c":"markdown","2b191d04":"markdown","8ba3baed":"markdown","f681a025":"markdown","12253a0d":"markdown","ad4e6e82":"markdown","b7277250":"markdown","e31097a5":"markdown","ed38ab5c":"markdown","670c5707":"markdown","f757f07c":"markdown","725e4861":"markdown","5f0e673e":"markdown","d8e461e7":"markdown"},"source":{"4e8f1831":"import pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns","a73e12b7":"data=pd.read_csv(\"..\/input\/breast-cancer-prediction\/Data.csv\")","d847210e":"data","0ea2c1bf":"data=data.drop(['Sample code number'],axis=1)","81f59d7f":"data","5cb1ef41":"data.isnull().sum()","8f298db6":"data['iscancer']=data.Class\n\n","1e3ae8c7":"for i in  range(0,683):\n    if data['iscancer'][i]== 2:\n        data['iscancer'][i]=0\n    else:\n        data['iscancer'][i]=1\n    ","302126c7":"data=data.drop(['Class'],axis=1)","413a8742":"data","b9fdcf38":"for i in data.columns:\n    data[i].value_counts().plot.bar()\n    plt.xlabel(i)\n    plt.show()\n    ","3a232771":"data.corr()","8a52586e":"plt.figure(figsize=(15,15))\nsns.heatmap(data.corr())","41185715":"x=data.drop(['iscancer'],axis=1)\nx","6963f8aa":"y=data['iscancer']\ny","c4627f74":"from sklearn.preprocessing import StandardScaler ","b8c66d29":"x=StandardScaler().fit_transform(x)","92daf09c":"from sklearn.model_selection import KFold\nfrom sklearn.linear_model import LogisticRegression","ef1ab2ab":"KFold=KFold(n_splits=8,random_state=0,shuffle=False)","b85a2092":"cost_logreg=[]","8fb61a1e":"for train,test in KFold.split(x):\n    x_train=x[train]\n    y_train=y[train]\n    x_test=x[test]\n    y_test=y[test]\n    LR=LogisticRegression()\n    LR.fit(x_train,y_train)\n    print(LR.score(x_test,y_test))\n    cost_logreg.append(LR.score(x_test,y_test))\n    ","575f7dae":"score=[ ]","c9a64c0e":"np.array(cost_logreg).mean()","6dd2d142":"score.append(np.array(cost_logreg).mean())","31944aa1":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import KFold","9825c8b7":"KFold=KFold(n_splits=8,random_state=0,shuffle=False)\n","bed62622":"cost_DTC=[]","d13a4784":"for train,test in KFold.split(x):\n    x_train=x[train]\n    y_train=y[train]\n    x_test=x[test]\n    y_test=y[test]\n    DTC=DecisionTreeClassifier(criterion='gini')\n    DTC.fit(x_train,y_train)\n    print(DTC.score(x_test,y_test))\n    cost_DTC.append(DTC.score(x_test,y_test))","1002a3ed":"np.array(cost_DTC).mean()","51ff2838":"score.append(np.array(cost_DTC).mean())","7b224688":"from sklearn.ensemble import RandomForestClassifier","4a75f240":"RFC=RandomForestClassifier(n_estimators=206,random_state=0,criterion='gini')","b1863950":"cost_RFC=[]\nfor train,test in KFold.split(x):\n    x_train=x[train]\n    y_train=y[train]\n    x_test=x[test]\n    y_test=y[test]\n    RFC.fit(x_train,y_train)\n    print(RFC.score(x_test,y_test))\n    cost_RFC.append(RFC.score(x_test,y_test))","288666bf":"np.array(cost_RFC).mean()","fd6ea982":"score.append(np.array(cost_RFC).mean())","d67c35f2":"score=np.array(score)*100","718f5a77":"score","0ce7b967":"max(score)","93f4030f":"score_name=[\"Logistic Regression\",\"Decision Tree Classifier\",\"Random Forest Classifier\"]","f3256dee":"plt.figure(figsize=(18,15))\nsns.barplot(score_name,score)\nplt.xlabel(\"Accuracy Score\")\nplt.ylabel(\"Algorithm\")","042d22aa":"* So the best fit classifier is Random Forest Classifier with K-fold cross validation with accuracy of 97.07%","84604dff":"# Ploting GIVEN DATA","89ea72ae":"Finding out average of all folds in Logistic Regression","750dee2c":"# Logistic Regression with K-fold cross validation ","ddb6db80":"Let's Drop Sample Code Number, as it is irrelevant","363f7b3c":"# Conclusion","2b191d04":"Finding Out Correlation ","8ba3baed":"# Decision Tree Classifier with K-fold cross validation","f681a025":"# Random Forest Classifier with K-fold cross validation","12253a0d":"# Scaling Our Data\nWe are going to scale our INPUT data using Standard Scaler ","ad4e6e82":"Importing Libraries","b7277250":"SPLITING Data in INPUT AND OUTPUT","e31097a5":"So Our DATA is Clean!","ed38ab5c":"# Using K-fold cross validation Technique \n\nThis technique involves randomly dividing the dataset into **k groups** or folds of **approximately equal size.** The **first fold is kept for testing** and the **model is trained on k-1 folds**.\n\n![](https:\/\/miro.medium.com\/max\/680\/1*M9amI9hGx45i9k5ORS6b8w.png)\n\nThe main Resason we are using this technique is \n* Our Data is less -> (683 rows)\n* We Don't Want that our training model mug up our data\n","670c5707":"Check Whether Our DATA is clean or not?","f757f07c":" Finding out average of all folds in Random Forest Classifier\n","725e4861":"# Breast Cancer Prediction With K-fold cross validation Technique and Different Classification Models\n\n\n![](https:\/\/www.neuraldesigner.com\/images\/breast-cancer-analysis.jpeg)\n\n\n# INTRODUCTION\n\nOut AIM is to classify  whether a lump in a breast could be **malignant (cancerous)** or **benign (non-cancerous)** from the given DATA SET, by using  **K-fold cross validation Techniques and Clasification Models** ,then find out the **Best model**.\n\n\n**DATA SET**\n* **clump_thickness**: (1-10). Benign cells tend to be grouped in monolayers, while cancerous cells are often grouped in multilayers.\n* **cell_size_uniformity**: (1-10). Cancer cells tend to vary in size and shape. That is why these parameters are valuable in determining whether the cells are cancerous or not.\n* **cell_shape_uniformity**: (1-10). Uniformity of cell size\/shape: Cancer cells tend to vary in size and shape. That is why these parameters are valuable in determining whether the cells are cancerous or not.\n* **marginal_adhesion**: (1-10). Normal cells tend to stick together. Cancer cells tend to lose this ability. So the loss of adhesion is a sign of malignancy.\n* **single_epithelial_cell_size**: (1-10). It is related to the uniformity mentioned above. Epithelial cells that are significantly enlarged may be a malignant cell.\n* **bare_nuclei**: (1-10). This is a term used for nuclei not surrounded by cytoplasm (the rest of the cell). Those are typically seen in benign tumors.\n* **bland_chromatin**: (1-10). Describes a uniform \"texture\" of the nucleus seen in benign cells. In cancer cells, the chromatin tends to be more coarse.\n* **normal_nucleoli**: (1-10). Nucleoli are small structures seen in the nucleus. In normal cells, the nucleolus is usually very small if visible at all. In cancer cells, the nucleoli become more prominent, and sometimes there are more of them.\n* **mitoses**: (1-10). Cancer is essentially a disease of uncontrolled mitosis.\n* **Class**: (0 or 1). Benign (non-cancerous) or malignant (cancerous) lump in a breast\n\n\n","5f0e673e":"For Our Convenience Let's change **(2 and 4) to (0 and 1)**","d8e461e7":"Finding out average of all folds in Decision Tree Classifier"}}