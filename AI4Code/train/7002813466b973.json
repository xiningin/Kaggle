{"cell_type":{"47121697":"code","7ff94a15":"code","c3d77332":"code","d81349f0":"code","b0615a36":"code","c80bce5d":"code","e3c27f41":"code","5436f8fa":"code","f1c929c9":"code","a428e189":"code","dc9cf32c":"code","8be05157":"code","56ac5979":"code","3f8e6aa4":"code","40928882":"code","ad632040":"code","b7d27913":"code","fbcaccd9":"code","075ecc03":"code","656417cf":"code","8fb3a67f":"code","adf34db9":"code","9eae8c80":"code","8ab82a91":"code","e500bebe":"code","5cd334e1":"code","5d2dbcad":"code","02ec6e0f":"code","e75979c1":"code","1140fbcd":"code","e5b4044e":"code","da637865":"code","0edd2ae2":"code","f2a43627":"code","11ed1f1e":"code","11d61b91":"code","662c7b00":"code","97aa35ed":"code","f3cb60c7":"code","85e9cb75":"code","5cb8ad83":"code","5fd9ee9b":"code","5eff9264":"code","010fa4b4":"code","bc3de559":"code","2663379d":"code","1017a3d7":"code","b7981602":"code","244bff38":"code","e4ec19d8":"code","53923777":"code","e4b86aa3":"code","fbdf0647":"code","f13efcca":"code","832bd0d2":"code","7239aa37":"code","7566483f":"code","2366d303":"code","801ac640":"code","4c42563f":"code","ae736ee0":"code","afabe211":"code","f8294de9":"code","ffa5492a":"code","92a141c0":"code","86a64ec6":"code","7f479b3f":"code","a68c376c":"code","b699b3c5":"code","34c9fa59":"code","575d60ef":"code","4caf271c":"code","007cf471":"code","0386269e":"code","9bca1fc4":"code","8c5e7161":"code","1338d440":"code","1393d5c4":"code","944bde43":"code","35eb40d5":"code","f73cdd29":"code","01d3f826":"code","fa3a2fa5":"code","64bfc3c2":"code","0f8c7bad":"code","d778b99d":"code","07663f4d":"markdown","594be4f5":"markdown","6f11447e":"markdown","01c5db3f":"markdown","f4c9315c":"markdown","dd02f3a7":"markdown","fa4b4c06":"markdown","242e84b2":"markdown","22cef72b":"markdown","deae3fee":"markdown","6bd7c11e":"markdown","39b30bdb":"markdown","cf936d59":"markdown","6ac10b51":"markdown","fa8edbad":"markdown","9d8ab51c":"markdown","b9dcd65b":"markdown","30add314":"markdown","b6adefa8":"markdown","c5ad0be6":"markdown","cd7f674a":"markdown","d8ff42b1":"markdown","3f26c2a0":"markdown","61a88a67":"markdown","8bf2c9d7":"markdown","edbd10e4":"markdown"},"source":{"47121697":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","7ff94a15":"#Import Ames House Dataset\ndf= pd.read_csv('\/kaggle\/input\/ames-housing-dataset\/AmesHousing.csv')","c3d77332":"df.head()","d81349f0":"df.info()","b0615a36":"#Our objective is to predict the SalePrice based on several Features, \n# Correlation overview:\ndf.corr()['SalePrice'].sort_values()","c80bce5d":"sns.scatterplot(data=df, x='Overall Qual', y='SalePrice' , color='g')\nplt.axhline(y=200000,color='c')","e3c27f41":"df[(df['Overall Qual']>8) &(df['SalePrice']<200000)][['SalePrice', 'Overall Qual']]","5436f8fa":"sns.scatterplot(x='Gr Liv Area', y='SalePrice', data=df, color='g')\nplt.axhline(y=200000, color='c')\nplt.axvline(x=4000, color='c')","f1c929c9":"df[(df['Gr Liv Area']>4000) & (df['SalePrice']<400000)][['SalePrice', 'Gr Liv Area']]","a428e189":"#Remove the outliers:\nindex_drop=df[(df['Gr Liv Area']>4000) & (df['SalePrice']<400000)].index\ndf=df.drop(index_drop, axis=0)","dc9cf32c":"sns.scatterplot(x='Gr Liv Area', y='SalePrice', data=df, color='g')\nplt.axhline(y=200000, color='c')\nplt.axvline(x=4000, color='c')","8be05157":"sns.scatterplot(x='Overall Qual', y='SalePrice', data=df, color='g')\nplt.axhline(y=200000,color='c')","56ac5979":"sns.boxplot(x='Overall Qual', y='SalePrice', data=df)","3f8e6aa4":"df.head()","40928882":"df.info()","ad632040":"df= df.drop('PID', axis=1)","b7d27913":"df.isnull().values.any()","fbcaccd9":"print('max_missing:', df.count().idxmin())","075ecc03":"df.isnull()","656417cf":"#How many missing data is there in each features?\ndf.isnull().sum()","8fb3a67f":"100*(df.isnull().sum()\/len(df))","adf34db9":"def missing_percent(df):\n    nan_percent= 100*(df.isnull().sum()\/len(df))\n    nan_percent= nan_percent[nan_percent>0].sort_values()\n    return nan_percent","9eae8c80":"nan_percent= missing_percent(df)","8ab82a91":"nan_percent","e500bebe":"plt.figure(figsize=(12,6))\nsns.barplot(x=nan_percent.index, y=nan_percent)\nplt.xticks(rotation=90)","5cd334e1":"plt.figure(figsize=(12,6))\nsns.barplot(x=nan_percent.index, y=nan_percent)\nplt.xticks(rotation=90)\n\n#Set 1% threshold:\nplt.ylim(0,1)","5d2dbcad":"nan_percent[nan_percent<1]","02ec6e0f":"nan_percent[nan_percent<1].index","e75979c1":"100\/len(df)\n#It shows that, Feature with just one missing rows has this percent value of missing data","1140fbcd":"df[df['Electrical'].isnull()]","e5b4044e":"df[df['Garage Area'].isnull()]","da637865":"df= df.dropna(axis=0, subset=['Electrical', 'Garage Area'])","0edd2ae2":"nan_percent= missing_percent(df)\n\nplt.figure(figsize=(12,6))\nsns.barplot(x=nan_percent.index, y=nan_percent)\nplt.xticks(rotation=90)\nplt.ylim(0,1)","f2a43627":"#Features related to Basement:","11ed1f1e":"df[df['Total Bsmt SF'].isnull()]","11d61b91":"df[df['Bsmt Half Bath'].isnull()]","662c7b00":"df[df['Bsmt Full Bath'].isnull()]","97aa35ed":"#Numerical Columns fill with 0:\nbsmt_num_cols= ['BsmtFin SF 1', 'BsmtFin SF 2', 'Bsmt Unf SF','Total Bsmt SF' ,'Bsmt Full Bath', 'Bsmt Half Bath']\ndf[bsmt_num_cols]=df[bsmt_num_cols].fillna(0)\n\n#String Columns fill with None:\nbsmt_str_cols= ['Bsmt Qual', 'Bsmt Cond', 'Bsmt Exposure', 'BsmtFin Type 1', 'BsmtFin Type 2']\ndf[bsmt_str_cols]= df[bsmt_str_cols].fillna('None')","f3cb60c7":"nan_percent= missing_percent(df)\n\nplt.figure(figsize=(12,6))\nsns.barplot(x=nan_percent.index, y=nan_percent)\nplt.xticks(rotation=90)\nplt.ylim(0,1)","85e9cb75":"df[\"Mas Vnr Type\"]= df[\"Mas Vnr Type\"].fillna(\"None\")\ndf[\"Mas Vnr Area\"]= df[\"Mas Vnr Area\"].fillna(0)","5cb8ad83":"nan_percent= missing_percent(df)\n\nplt.figure(figsize=(12,6))\nsns.barplot(x=nan_percent.index, y=nan_percent)\nplt.xticks(rotation=90)\n","5fd9ee9b":"df[['Garage Type', 'Garage Yr Blt', 'Garage Finish', 'Garage Qual', 'Garage Cond']]","5eff9264":"#Filling the missing Value:\nGar_str_cols= ['Garage Type', 'Garage Finish', 'Garage Qual', 'Garage Cond']\ndf[Gar_str_cols]=df[Gar_str_cols].fillna('None')\n\ndf['Garage Yr Blt']=df['Garage Yr Blt'].fillna(0)","010fa4b4":"nan_percent= missing_percent(df)\n\nplt.figure(figsize=(12,6))\nsns.barplot(x=nan_percent.index, y=nan_percent)\nplt.xticks(rotation=90)\n","bc3de559":"nan_percent.index","2663379d":"df[['Lot Frontage', 'Fireplace Qu', 'Fence', 'Alley', 'Misc Feature',\n       'Pool QC']]","1017a3d7":"df= df.drop(['Fence', 'Alley', 'Misc Feature','Pool QC'], axis=1)","b7981602":"nan_percent= missing_percent(df)\n\nplt.figure(figsize=(12,6))\nsns.barplot(x=nan_percent.index, y=nan_percent)\nplt.xticks(rotation=90)","244bff38":"df['Fireplace Qu']= df['Fireplace Qu'].fillna('None')","e4ec19d8":"nan_percent= missing_percent(df)\n\nplt.figure(figsize=(12,6))\nsns.barplot(x=nan_percent.index, y=nan_percent)\nplt.xticks(rotation=90)","53923777":"df['Neighborhood'].unique()","e4b86aa3":"plt.figure(figsize=(8,12))\nsns.boxplot(data=df, x='Lot Frontage', y='Neighborhood')","fbdf0647":"#Impute missing data based on other columns:\n\ndf.groupby('Neighborhood')['Lot Frontage']","f13efcca":"df.groupby('Neighborhood')['Lot Frontage'].mean()","832bd0d2":"df.groupby('Neighborhood')['Lot Frontage'].transform(lambda val: val.fillna(val.mean()))","7239aa37":"df['Lot Frontage']=df.groupby('Neighborhood')['Lot Frontage'].transform(lambda val: val.fillna(val.mean()))","7566483f":"nan_percent= missing_percent(df)\n\nplt.figure(figsize=(12,6))\nsns.barplot(x=nan_percent.index, y=nan_percent)\nplt.xticks(rotation=90)","2366d303":"df['Lot Frontage']= df['Lot Frontage'].fillna(0)","801ac640":"nan_percent= missing_percent(df)\n","4c42563f":"nan_percent","ae736ee0":"df['MS SubClass']","afabe211":"df.info()","f8294de9":"df['MS SubClass'].unique()","ffa5492a":"#Convert to String:\ndf['MS SubClass']= df['MS SubClass'].apply(str)","92a141c0":"\ndf.info()\n#or: df['MS SubClass'].dtype","86a64ec6":"df.select_dtypes(include='object')","7f479b3f":"df_num= df.select_dtypes(exclude='object')\ndf_obj= df.select_dtypes(include='object')","a68c376c":"df_num.info()","b699b3c5":"df_obj.info()","34c9fa59":"# Converting:\ndf_obj= pd.get_dummies(df_obj, drop_first=True)","575d60ef":"df_obj.shape","4caf271c":"Final_df= pd.concat([df_num, df_obj], axis=1)","007cf471":"Final_df.head()","0386269e":"plt.figure(figsize=(15,5))\nsns.displot(df['SalePrice'] , bins=30 , kde=True )","9bca1fc4":"from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import metrics\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import LassoCV","8c5e7161":"X= Final_df.drop(['SalePrice'], axis=1)\ny=Final_df['SalePrice']","1338d440":"df['SalePrice']","1393d5c4":"#Preprocessing (Polynomial Conversion)\npolynomial_converter= PolynomialFeatures(degree=2, include_bias=False )\npoly_features=polynomial_converter.fit(X)\nprint(poly_features)\npoly_features= polynomial_converter.fit_transform(X)\npoly_features.shape","944bde43":"X_train, X_test, y_train, y_test = train_test_split(poly_features, y, test_size=0.3, random_state=101)","35eb40d5":"#LinearRegression\nmodel= LinearRegression()\nprint(model.fit(X_train, y_train))\n\ny_pred=model.predict(X_test)\npd.DataFrame({'Y_Test':y_test , 'Y_Pred':y_pred , 'Residuals':(y_test-y_pred)}).head()","f73cdd29":"test_residuals=y_test-y_pred\ntest_residuals.head()","01d3f826":"sns.scatterplot(x=y_test, y=y_pred , color='c')\nplt.xlabel('Y-Test')\nplt.ylabel('Y-Pred')","fa3a2fa5":"sns.scatterplot(x=y_test, y=test_residuals , color='c')\nplt.axhline(y=0, color='r', ls='--')","64bfc3c2":"scaler= StandardScaler()\nprint(scaler.fit(X_train))\n\nX_train= scaler.transform(X_train)\nX_test= scaler.transform(X_test)\n","0f8c7bad":"#Train the Model metrics\nMAE= metrics.mean_absolute_error(y_test, y_pred)\nMSE= metrics.mean_squared_error(y_test, y_pred)\nRMSE=np.sqrt(MSE)\n\n#Evaluating the Model LinearRegression\nMAE_LR= mean_absolute_error(y_test, y_pred)\nMSE_LR= mean_squared_error(y_test, y_pred)\nRMSE_LR= np.sqrt(MSE_LR)\n\n#Train the Model Ridge\nridge_model= Ridge(alpha=10)\nprint(ridge_model.fit(X_train, y_train))\n\n#predict Test Data\ny_pred= ridge_model.predict(X_test)\n\n#Evaluating the Model\nMAE_ridge= mean_absolute_error(y_test, y_pred)\nMSE_ridge= mean_squared_error(y_test, y_pred)\nRMSE_ridge= np.sqrt(MSE)\n\n\n#Train the Model ridge_cv\nridge_cv_model=RidgeCV(alphas=(0.5, 1.0, 10.0), scoring='neg_mean_absolute_error')\nprint(ridge_cv_model.fit(X_train, y_train))\n\nprint('ridge_cv_model.alpha=' , ridge_cv_model.alpha_)\n\n#Predicting Test Data\ny_pred_ridge= ridge_cv_model.predict(X_test)\n\n#Evaluating the Model\nMAE_ridge_cv= mean_absolute_error(y_test, y_pred_ridge)\nMSE_ridge_cv= mean_squared_error(y_test, y_pred_ridge)\nRMSE_ridge_cv= np.sqrt(MSE_ridge)\n\n\n#  Lasso Regression\nlasso_cv_model= LassoCV(eps=0.01, n_alphas=100, cv=5)\nprint(lasso_cv_model.fit(X_train, y_train))\nprint('lasso_cv_model.alpha=' , lasso_cv_model.alpha_)\n\ny_pred_lasso= lasso_cv_model.predict(X_test)\n\n#Evaluating the Model\nMAE_Lasso= mean_absolute_error(y_test, y_pred_lasso)\nMSE_Lasso= mean_squared_error(y_test, y_pred_lasso)\nRMSE_Lasso= np.sqrt(MSE_Lasso)\n\n\n\npd.DataFrame({'LinearRegression':[MAE_LR, MSE_LR, RMSE_LR] , 'metrics':[MAE, MSE, RMSE],'ridge':[MAE_ridge ,MSE_ridge, RMSE_ridge] , \n              'RidgeCV':[MAE_ridge_cv , MSE_ridge_cv , RMSE_ridge_cv] ,'LassoCV':[MAE_Lasso, MSE_Lasso, RMSE_Lasso] }\n             ,index=['MAE', 'MSE', 'RMSE'])","d778b99d":"print('ridge_cv_modelr:','\\n', ridge_cv_model.coef_ , '\\n')\nprint('lasso_cv_model:', '\\n',lasso_cv_model.coef_ )","07663f4d":"### 1- Dealing with Outliers","594be4f5":"**In statistics, missing data, or missing values, occur when no data value is stored for the variable in an observation. missing data are a common occurrence and can have a significant effect on the conclusions that can be drawn from the data.**","6f11447e":"**Columns: Lot Frontage**\n\n**We assume that the Lot Frontage is related to what a Neighborhood a house is in**","01c5db3f":"#  Data Preparation","f4c9315c":" The percent of missing data in any feature:","dd02f3a7":"### C-Working based on Columns Missing Data","fa4b4c06":"## 2-Dealing with Missing Data","242e84b2":"#### A- Numerical Columns to Categorical\nWe need to be careful when it comes to encoding categorical as numbers. We want to make sure that the numerical relationship makes sense for model. For example, the encoding MSSubClass is essentially just a code per class","22cef72b":"### Dropping Rows:","deae3fee":"**Mas Vnr Features:**\n\nBased on the Dataset Document File, missing values for 'Mas Vnr Type' and 'Mas Vnr Area' means the house doesn't have any mansonry veneer. so, we decide to fill the missing value as below: ","6bd7c11e":"Make a Function to calculate the percent of missing data in each columns (feature) and then sort it","39b30bdb":"**We don't have any Missing Data**","cf936d59":"## Dealing with Categorical Data","6ac10b51":"### Fill\/Keep\/Drop?\nRemoving the PID (We already have an index, so we don't need PID unique identifier. \n\nbecuase it doesn't have any information and can't help our learning models)\n","fa8edbad":"every Feature with missing data must be checked!\nWe choose a threshold of 1%. It means, if there is less than 1% of a feature are missing,\nthen we will consider just dropping that rows","9d8ab51c":"### Filling the missing values:","b9dcd65b":"### Garage Columns:\n**Based on the dataset documentation, NaN in Garage Columns seems to indicate no garage.**\n\n**Decision: Fill with 'None' or 0**","30add314":"### D- Imputation of Missing Data","b6adefa8":"### A- How Much Data is Missing?","c5ad0be6":"plot the feature with missing indicating the percent of missing data","cd7f674a":"**If only a few rows are missing some values, then it might just be a good idea to drop those rows.** \n\n**What does this cost you in terms of performace? It essentialy removes potential training\/testing data, but if its only a few rows, its unlikely to change performance.**\n\n\n**Sometimes it is a good idea to remove a feature entirely if it has too many null values. However, you should carefully consider why it has so many null values, in certain situations null could just be used as a separate category.** \n\n(Take for example a feature column for the number of cars that can fit into a garage. Perhaps if there is no garage then there is a null value, instead of a zero. It probably makes more sense to quickly fill the null values in this case with a zero instead of a null. Only you can decide based off your domain expertise and knowledge of the data set!)","d8ff42b1":"**Remove the Columns with more than 80% missing values**","3f26c2a0":"### B- Creating Dummy Variables","61a88a67":"### B- Working base on Rows Missing Data","8bf2c9d7":"Filling in Fireplace Quality based on dataset documentation:\n","edbd10e4":"After checking the data documentation,it shows that missing value (two rows) in Basement Features are becouse of there is no basement in these rows\n\nDecision: Filling in data based on column: numerical basement & string descriptive:"}}