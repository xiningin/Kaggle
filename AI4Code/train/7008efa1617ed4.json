{"cell_type":{"2d132e4a":"code","8f990551":"code","6a5a8e9e":"code","acb60821":"code","a1f2a5a0":"code","c02835ba":"code","b94b1bfe":"code","9f5d16c4":"code","3d79a1e1":"code","2e94090a":"code","093e02ad":"code","ff95b5d1":"code","7055f5b3":"code","8926a010":"code","af1c9007":"code","05e41e94":"code","00ed7c5f":"code","aee23b93":"code","4104389f":"code","a39927f7":"code","8f39c49c":"code","87f361a2":"code","8a051132":"code","a3bdeef4":"markdown","20c5a2c8":"markdown","4e81dcde":"markdown","b7df3f8d":"markdown","d9c97211":"markdown","a63f71c2":"markdown"},"source":{"2d132e4a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8f990551":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport seaborn as sns\nimport keras\nimport tensorflow as tf\nfrom tqdm import tqdm\nfrom keras.preprocessing.image import img_to_array, load_img\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report","6a5a8e9e":"labels = os.listdir('\/kaggle\/input\/walk-or-run\/walk_or_run_train\/train')\nlabels","acb60821":"x_train = []\n\nfor i in labels:\n  path = '\/kaggle\/input\/walk-or-run\/walk_or_run_train\/train\/' + i\n  folder_data = os.listdir(path)\n\n  for j in folder_data:\n    img = load_img(path + '\/' + j, target_size=(200,200))\n    img = img_to_array(img)\n    img = img \/ 255.0\n    x_train.append(img)\n\nx_train = np.array(x_train)\nx_train.shape","a1f2a5a0":"y1 = pd.DataFrame( np.zeros(299, dtype=int) , columns = ['labels'])\ny2 = pd.DataFrame( np.ones(301, dtype=int) , columns=['labels'] )\ny_train = y1.append(y2, ignore_index=True)\ny_train.shape","c02835ba":"y_train['labels'].value_counts()","b94b1bfe":"x_test = []\n\nfor i in labels:\n  path = '\/kaggle\/input\/walk-or-run\/walk_or_run_test\/test\/' + i\n  folder_data = os.listdir(path)\n\n  for j in folder_data:\n    img = load_img(path + '\/' + j, target_size=(200,200))\n    img = img_to_array(img)\n    img = img \/ 255.0\n    x_test.append(img)\n\nx_test = np.array(x_test)\nx_test.shape","9f5d16c4":"y1 = pd.DataFrame( np.zeros(82, dtype=int) , columns = ['labels'])\ny2 = pd.DataFrame( np.ones(59, dtype=int) , columns=['labels'] )\ny_test = y1.append(y2, ignore_index=True)\ny_test.shape","3d79a1e1":"y_test['labels'].value_counts()","2e94090a":"def imshow(a):\n  plt.imshow(np.squeeze(a[np.random.randint(0, 599, size = 1, dtype=int)]))\n\ndef test_imshow(a):\n  plt.imshow(np.squeeze(a[np.random.randint(0, 141, size = 1, dtype=int)]))","093e02ad":"imshow(x_train)","ff95b5d1":"test_imshow(x_test)","7055f5b3":"densenet = tf.keras.applications.DenseNet121(include_top=False, weights='imagenet', input_shape = (200,200,3))\ndensenet.summary()","8926a010":"for layer in densenet.layers:\n  layer.trainable = False\n\ndensenet.summary()","af1c9007":"x = tf.keras.layers.Flatten()(densenet.output)\nprediction = tf.keras.layers.Dense(1, activation='sigmoid')(x)\nprediction","05e41e94":"model = tf.keras.models.Model(inputs = densenet.input, outputs = prediction)\nmodel.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\nmodel.summary()","00ed7c5f":"history = model.fit(x_train,y_train, epochs = 5, validation_split=0.2, batch_size=20)","aee23b93":"def accuracy_learning_curves(x):\n  plt.plot(x.history['accuracy'])\n  plt.plot(x.history['val_accuracy'])\n  plt.title(\"ACCURACY CURVES\")\n  plt.legend(labels = ['Accuracy', 'Val_Accuracy'])\n    \ndef loss_learning_curves(x):\n  plt.plot(x.history['loss'])\n  plt.plot(x.history['val_loss'])\n  plt.title(\"LOSS CURVES\")\n  plt.legend(labels = [\"Loss\", 'Val_Loss'])","4104389f":"accuracy_learning_curves(history)","a39927f7":"loss_learning_curves(history)","8f39c49c":"y_pred = model.predict(x_test)\ny_pred","87f361a2":"y_pred = np.round(y_pred)\n\ncm = confusion_matrix(y_test, y_pred)\naccuracy_score(y_test, y_pred)","8a051132":"plt.figure(figsize=(7,5))\nsns.heatmap(cm,annot=True)\nplt.xlabel('Predicted')\nplt.ylabel('truth')","a3bdeef4":"# Prediction","20c5a2c8":"## Preparing train and test data","4e81dcde":"# Transfer Learning","b7df3f8d":"## Visualizing Data","d9c97211":"## Learning Curves","a63f71c2":"Upvote if it helps you..!\nThanks"}}