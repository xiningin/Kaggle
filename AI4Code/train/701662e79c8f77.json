{"cell_type":{"3fb97439":"code","1bceea0d":"code","d6333175":"code","c4cfe145":"code","d55db166":"code","25c60da8":"code","8d4e54c0":"code","246864d9":"code","1f6daf9b":"code","90109500":"code","31de5a64":"code","76dfa4b2":"code","60007f18":"code","984054ba":"code","7f413df6":"code","5ec539b5":"code","c7203b73":"code","c95bef1a":"code","d73dfecf":"code","8affc0fc":"code","4d7e5deb":"code","c2886010":"code","c618ad25":"code","43e9ab8d":"code","055454e2":"code","9c3a5288":"code","483bb0a5":"code","d12bd2b1":"code","a25eba6f":"code","a5c3dbda":"code","d4b7021c":"code","c8e77904":"code","db2beade":"markdown","9f4efc74":"markdown","54b4600d":"markdown","d8b14d11":"markdown","dd1c1b86":"markdown"},"source":{"3fb97439":"import numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport math\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.linear_model import LinearRegression\n\nfrom catboost import CatBoostRegressor\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\n\nfrom sklearn.ensemble import StackingRegressor\n\nfrom sklearn.model_selection import train_test_split\n\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import median_absolute_error\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error","1bceea0d":"train = pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/train.csv\")\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/test.csv\")\nsubmission = pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/sample_submission.csv\")","d6333175":"train.head()","c4cfe145":"train.shape","d55db166":"test.shape","25c60da8":"sum(train.isnull().sum())","8d4e54c0":"train.drop(['id'], axis=1, inplace=True)","246864d9":"new=test[\"id\"]\ntest.drop(['id'], axis=1, inplace=True)","1f6daf9b":"target= train[\"loss\"].value_counts()\ntarget","90109500":"sns.distplot(train[\"loss\"])","31de5a64":"df = pd.concat([train.drop([\"loss\"], axis=1), test], axis=0)\ncolumns = df.columns.values\n\ncols = 3\nrows = len(columns) \/\/ cols + 1\n\nfig, axs = plt.subplots(ncols=cols, nrows=rows, figsize=(16,100), sharex=False)\n\nplt.subplots_adjust(hspace = 0.4)\ni=0\n\nplt.title(\"Feature values distribution in both datasets\")\nfor r in np.arange(0, rows, 1):\n    for c in np.arange(0, cols, 1):\n        if i >= len(columns):\n            axs[r, c].set_visible(False)\n        else:\n            hist1 = axs[r, c].hist(train[columns[i]].values,\n                                   range=(df[columns[i]].min(),\n                                          df[columns[i]].max()),\n                                   bins=40,\n                                   color=\"deepskyblue\",\n                                   edgecolor=\"black\",\n                                   alpha=0.7,\n                                   label=\"Train Dataset\")\n            hist2 = axs[r, c].hist(test[columns[i]].values,\n                                   range=(df[columns[i]].min(),\n                                          df[columns[i]].max()),\n                                   bins=40,\n                                   color=\"palevioletred\",\n                                   edgecolor=\"black\",\n                                   alpha=0.7,\n                                   label=\"Test Dataset\")\n            axs[r, c].set_title(columns[i], fontsize=14, pad=5)\n            axs[r, c].tick_params(axis=\"y\", labelsize=13)\n            axs[r, c].tick_params(axis=\"x\", labelsize=13)\n            axs[r, c].grid(axis=\"y\")\n            axs[r, c].legend(fontsize=11)\n                                  \n        i+=1\nplt.show();","76dfa4b2":"df = pd.concat([train.drop([\"loss\"], axis=1), test], axis=0)\ncolumns = df.columns.values\n\ncols = 3\nrows = len(columns) \/\/ cols + 1\n\nfig, axs = plt.subplots(ncols=cols, nrows=rows, figsize=(16,100), sharex=False)\n\nplt.subplots_adjust(hspace = 0.4)\ni=0\n\nplt.title(\"Features and loss\")\nfor r in np.arange(0, rows, 1):\n    for c in np.arange(0, cols, 1):\n        if i >= len(columns):\n            axs[r, c].set_visible(False)\n        else:\n            hist1 = axs[r, c].hist(train[columns[i]].values,\n                                   range=(df[columns[i]].min(),\n                                          df[columns[i]].max()),\n                                   bins=40,\n                                   color=\"deepskyblue\",\n                                   edgecolor=\"black\",\n                                   alpha=0.7,\n                                   label=\"Train Dataset feature\")\n            hist2 = axs[r, c].hist(train[\"loss\"].values,\n                                   bins=40,\n                                   color=\"palevioletred\",\n                                   edgecolor=\"black\",\n                                   alpha=0.7,\n                                   label=\"Loss\")\n            axs[r, c].set_title(columns[i], fontsize=14, pad=5)\n            axs[r, c].tick_params(axis=\"y\", labelsize=13)\n            axs[r, c].tick_params(axis=\"x\", labelsize=13)\n            axs[r, c].grid(axis=\"y\")\n            axs[r, c].legend(fontsize=11)\n                                  \n        i+=1\nplt.show();","60007f18":"train.dtypes.value_counts()","984054ba":"train.describe()","7f413df6":"test.head()","5ec539b5":"test.dtypes.value_counts()","c7203b73":"test.describe()","c95bef1a":"# Train data\nX=train.drop(columns = ['loss'])\ny=train['loss'].values\n# Test data\nX_test=test\nprint('Train set:', X.shape)\nprint('Test set:', X_test.shape)","d73dfecf":"X_train, X_test, Y_train, Y_test = train_test_split(X, y, shuffle = True)","8affc0fc":"# Commented to save time\n'''\ngrid_n_estimator = [200,310,330,350]\ngrid_learn = [.01,0.03,0.05]\n\nLGBM = LGBMRegressor()\nG_LGBM = GridSearchCV(LGBM, param_grid= {'learning_rate': grid_learn,\n                                          'n_estimators': grid_n_estimator,\n                                          'max_depth': [8,10]},)\n\nG_LGBM.fit(X_train, Y_train)\nprint('Best Parameters: ', G_LGBM.best_params_)\n'''","4d7e5deb":"LGBM = LGBMRegressor( learning_rate= 0.07,\n                      max_depth= 8, \n                      n_estimators= 200,\n                      objective='regression',\n                      n_jobs = -1)\nLGBM.fit(X_train, Y_train)\npredlgbm = LGBM.predict(X_test)","c2886010":"from sklearn import metrics\n\nrmse = metrics.mean_squared_error(Y_test, predlgbm, squared=False)\nprint('MSE score: ', rmse)","c618ad25":"predictionLGBM = LGBM.predict(test)","43e9ab8d":"'''\ngrid_n_estimator = [200,400, 500]\ngrid_learn = [.001,0.03,0.05]\n\nXGB = XGBRegressor()\nG_XGB = GridSearchCV(XGB, param_grid= {'learning_rate': grid_learn, \n                                        'n_estimators': grid_n_estimator\n                                        })\n\nG_XGB.fit(X_train, Y_train)\nprint('Best Parameters: ', G_XGB.best_params_)\n'''","055454e2":"XGB = XGBRegressor( learning_rate= 0.05, \n                      n_estimators= 200,\n                      min_child_weight =11,\n                      )\nXGB.fit(X_train, Y_train)\npred = XGB.predict(X_test)","9c3a5288":"from sklearn import metrics\n\nrmse = metrics.mean_squared_error(Y_test, pred, squared=False)\nprint('MSE score: ', rmse)","483bb0a5":"predictionXGB = XGB.predict(test)","d12bd2b1":"Cat = CatBoostRegressor(learning_rate=0.07, depth=6)\n\nCat.fit(X_train, Y_train)\npredcat = Cat.predict(X_test)","a25eba6f":"from sklearn import metrics\n\nrmse = metrics.mean_squared_error(Y_test, predcat, squared=False)\nprint('MSE score: ', rmse)","a5c3dbda":"predictioncat = Cat.predict(test)","d4b7021c":"ensembled = predictioncat*0.4 + predictionLGBM *0.4 + predictionXGB *0.2","c8e77904":"predictions = pd.DataFrame()\npredictions[\"id\"] = new\npredictions[\"loss\"] = ensembled\n\npredictions.to_csv('submissionensemb3.csv', index=False, header=predictions.columns)\npredictions.head()","db2beade":"# LightGBM","9f4efc74":"# XGBoost","54b4600d":"## So, there are no missing values","d8b14d11":"# CatBoost","dd1c1b86":"# Overview of test set"}}