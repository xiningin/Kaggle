{"cell_type":{"382d7231":"code","c8fb1259":"code","41bbf814":"code","837fec5d":"code","2467f0f6":"code","8320353a":"code","9d264b73":"code","735ea90f":"code","2c64a624":"code","f1294404":"code","6b0f4165":"markdown","edd4dd00":"markdown","cdcacef7":"markdown","2f858974":"markdown","c284d77c":"markdown","07aef387":"markdown","26602128":"markdown","e51d6cf9":"markdown","f8c2bdf6":"markdown","4f6e193f":"markdown","c853a8ae":"markdown","87f19ba2":"markdown","b743bfbd":"markdown","b27e6680":"markdown","9b30f06c":"markdown","d7d068e5":"markdown"},"source":{"382d7231":"import numpy as np\nfrom pylab import imshow, show\nfrom timeit import default_timer as timer","c8fb1259":"def mandel(x, y, max_iters):\n  \"\"\"\n    Given the real and imaginary parts of a complex number,\n    determine if it is a candidate for membership in the Mandelbrot\n    set given a fixed number of iterations.\n  \"\"\"\n  c = complex(x, y)\n  z = 0.0j\n  for i in range(max_iters):\n    z = z*z + c\n    if (z.real*z.real + z.imag*z.imag) >= 4:\n      return i\n\n  return max_iters","41bbf814":"def create_fractal(min_x, max_x, min_y, max_y, image, iters):\n  height = image.shape[0]\n  width = image.shape[1]\n\n  pixel_size_x = (max_x - min_x) \/ width\n  pixel_size_y = (max_y - min_y) \/ height\n    \n  for x in range(width):\n    real = min_x + x * pixel_size_x\n    for y in range(height):\n      imag = min_y + y * pixel_size_y\n      color = mandel(real, imag, iters)\n      image[y, x] = color","837fec5d":"image = np.zeros((1024, 1536), dtype = np.uint8)\nstart = timer()\ncreate_fractal(-2.0, 1.0, -1.0, 1.0, image, 20) \ndt = timer() - start\n\nprint(\"Mandelbrot created in %f s\" % dt)\nimshow(image)\nshow()","2467f0f6":"create_fractal(-2.0, -1.7, -0.1, 0.1, image, 20) \nimshow(image)\nshow()","8320353a":"from numba import jit\n\n@jit\ndef mandel(x, y, max_iters):\n  \"\"\"\n    Given the real and imaginary parts of a complex number,\n    determine if it is a candidate for membership in the Mandelbrot\n    set given a fixed number of iterations.\n  \"\"\"\n  c = complex(x, y)\n  z = 0.0j\n  for i in range(max_iters):\n    z = z*z + c\n    if (z.real*z.real + z.imag*z.imag) >= 4:\n      return i\n\n  return max_iters\n\n@jit\ndef create_fractal(min_x, max_x, min_y, max_y, image, iters):\n  height = image.shape[0]\n  width = image.shape[1]\n\n  pixel_size_x = (max_x - min_x) \/ width\n  pixel_size_y = (max_y - min_y) \/ height\n    \n  for x in range(width):\n    real = min_x + x * pixel_size_x\n    for y in range(height):\n      imag = min_y + y * pixel_size_y\n      color = mandel(real, imag, iters)\n      image[y, x] = color","9d264b73":"image = np.zeros((1024, 1536), dtype = np.uint8)\nstart = timer()\ncreate_fractal(-2.0, 1.0, -1.0, 1.0, image, 20) \ndt = timer() - start\n\nprint(\"Mandelbrot created in %f s\" % dt)\nimshow(image)\nshow()","735ea90f":"from numba import cuda\nfrom numba import *\n\nmandel_gpu = cuda.jit(restype=uint32, argtypes=[f8, f8, uint32], device=True)(mandel)","2c64a624":"@cuda.jit(argtypes=[f8, f8, f8, f8, uint8[:,:], uint32])\ndef mandel_kernel(min_x, max_x, min_y, max_y, image, iters):\n  height = image.shape[0]\n  width = image.shape[1]\n\n  pixel_size_x = (max_x - min_x) \/ width\n  pixel_size_y = (max_y - min_y) \/ height\n\n  startX, startY = cuda.grid(2)\n  gridX = cuda.gridDim.x * cuda.blockDim.x;\n  gridY = cuda.gridDim.y * cuda.blockDim.y;\n\n  for x in range(startX, width, gridX):\n    real = min_x + x * pixel_size_x\n    for y in range(startY, height, gridY):\n      imag = min_y + y * pixel_size_y \n      image[y, x] = mandel_gpu(real, imag, iters)","f1294404":"gimage = np.zeros((1024, 1536), dtype = np.uint8)\nblockdim = (32, 8)\ngriddim = (32,16)\n\nstart = timer()\nd_image = cuda.to_device(gimage)\nmandel_kernel[griddim, blockdim](-2.0, 1.0, -1.0, 1.0, d_image, 20) \nd_image.to_host()\ndt = timer() - start\n\nprint(\"Mandelbrot created on GPU in %f s\" % dt)\n\nimshow(gimage)\nshow()","6b0f4165":"# Faster Execution with Numba","edd4dd00":"You may notice that when you ran the above code, the image was generated almost instantly. On the Kaggle's NVidia K80 GPU, it ran in at a speed which gave us an additional **74x** speedup over the @jit (compiled CPU) code, or a total of over **2500x** faster than interpreted Python code.","cdcacef7":"`create_fractal` iterates over all the pixels in the image, computing the complex coordinates from the pixel coordinates, and calls the mandel function at each pixel. The return value of mandel is used to color the pixel.","2f858974":"The `mandel` function performs the Mandelbrot set calculation for a given (x,y) position on the imaginary plane. It returns the number of iterations before the computation \"escapes\".","c284d77c":"Let's run the @jit code and see if it is faster.","07aef387":"In addition to various types of automatic vectorization and generalized Numpy Ufuncs, NumbaPro also enables developers to access the CUDA parallel programming model using Python syntax. With CUDA Python, you use parallelism explicitly just as in other CUDA languages such as CUDA C and CUDA Fortran.\n\nLet's write a CUDA version of our Python Mandelbrot set. We need to import cuda from the numbapro module. Then, we need to create a version of the mandel function compiled for the GPU. We can do this without any code duplication by calling cuda.jit on the function, providing it with the return type and the argument types, and specifying device=True to indicate that this is a function that will run on the GPU device.","26602128":"# A Numba + Cuda Mandelbrot Example","e51d6cf9":"The time to compute the 1024x1024 mandelbrot set dropped with a speedup of **33x!** The reason this is so much faster is that Numba uses Numpy type information to convert the dynamic Python code into statically compiled machine code, which is many times faster to execute than dynamically typed, interpreted Python code.","f8c2bdf6":"## Launching Kernels\n\nTo launch a kernel on the GPU, we must configure it, specifying the size of the grid in blocks, and the size of each thread block. For a 2D image calculation like the Mandelbrot set, we use a 2D grid of 2D blocks. We'll use blocks of 32x8 threads, and launch 32x16 of them in a 2D grid so that we have plenty of blocks to occupy all of the multiprocessors on the GPU.\n\nPutting this all together, we launch the kernel like this.","4f6e193f":"# CUDA Python","c853a8ae":"You can play with the coordinates to zoom in on different regions in the fractal.","87f19ba2":"# Even Bigger Speedups with CUDA Python","b743bfbd":"## Device Memory\nCUDA kernels must operate on data allocated on the device. NumbaPro provides the cuda.to_device() function to copy a Numpy array to the GPU.\n\n`d_image = cuda.to_device(image)`\n\nThe return value (d_image) is of type DeviceNDArray, which is a subclass of numpy.ndarray, and provides the to_host() function to copy the array back from GPU to CPU memory\n\n`d_image.to_host()`","b27e6680":"\n[Numba](http:\/\/numba.pydata.org\/) is a Numpy-aware dynamic Python compiler based on the popular LLVM compiler infrastructure.\n\nNumba is an Open Source NumPy-aware optimizing compiler for Python sponsored by Continuum Analytics, Inc. It uses the remarkable compiler infrastructure to compile Python syntax to machine code. It is aware of NumPy arrays as typed memory regions and so can speed-up code using NumPy arrays, such as our Mandelbrot functions.\n\nThe simplest way to use Numba is to decorate the functions you want to compile with @jit. Numba will compile them for the CPU (if it can resolve the types used).","9b30f06c":"In CUDA, a kernel is a function that runs in parallel using many threads on the device. We can write a kernel version of our mandelbrot function by simply assuming that it will be run by a grid of threads. NumbaPro provides the familiar CUDA threadIdx, blockIdx, blockDim and gridDim intrinsics, as well as a grid() convenience function which evaluates to blockDim * blockIdx + threadIdx.\n\nOur example juse needs a minor modification to compute a grid-size stride for the x and y ranges, since we will have many threads running in parallel. We just add these three lines:\n\n`startX, startY = cuda.grid(2)\ngridX = cuda.gridDim.x * cuda.blockDim.x;\ngridY = cuda.gridDim.y * cuda.blockDim.y;`\n\nAnd we modify the range in the x loop to use range(startX, width, gridX) (and likewise for the y loop).\n\nWe decorate the function with @cuda.jit, passing it the type signature of the function. Since kernels cannot have a return value, we do not need the restype argument.","d7d068e5":"Next we create a 1024x1024 pixel image as a numpy array of bytes. We then call `create_fractal` with appropriate coordinates to fit the whole mandelbrot set."}}