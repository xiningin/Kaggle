{"cell_type":{"61244162":"code","47960d78":"code","5cfac37e":"code","4e05365c":"code","ce318dd2":"code","967e06a0":"code","8dcb64d7":"code","71fdd454":"code","8f9f8f35":"code","204588a4":"code","a19fc2c0":"code","c9b56d93":"code","4fb8a2d7":"code","05965ad8":"code","eac3979d":"code","97538f04":"code","44102215":"code","f95b71fd":"code","54b7b5fc":"code","5cf3630e":"markdown","39cf197a":"markdown","9889f9c7":"markdown","2ad6babe":"markdown","df54b295":"markdown","b4dd27b8":"markdown","b95b183b":"markdown","880a19de":"markdown","ec09af3e":"markdown","6ebe6312":"markdown","fb99c032":"markdown"},"source":{"61244162":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","47960d78":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics \nfrom sklearn import preprocessing\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nimport cv2\nfrom keras.preprocessing.image import img_to_array\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\nfrom keras.layers import Dense,GlobalAveragePooling2D\nfrom keras.applications import MobileNet\nfrom keras.applications.mobilenet import preprocess_input\nfrom keras.optimizers import Adam","5cfac37e":"df = pd.read_csv('..\/input\/fast-furious-and-insured\/Fast_Furious_Insured\/train.csv')\ndf.head()","4e05365c":"df_test = pd.read_csv('..\/input\/fast-furious-and-insured\/Fast_Furious_Insured\/test.csv')\ndf_test","ce318dd2":"# Get the number of missing data points per column\nmissing_values_count_train = df.isnull().sum()\nprint(missing_values_count_train)","967e06a0":"# Get the number of missing data points per column\nmissing_values_count_test = df_test.isnull().sum()\nprint(missing_values_count_test)","8dcb64d7":"# Filling missing values\ndf = df.fillna(method='bfill', axis=0).fillna(0)","71fdd454":"# Checking different values in Insurance company in the training set\ndf['Insurance_company'].value_counts()","8f9f8f35":"# Checking different values in Insurance company in the testing set\ndf_test['Insurance_company'].value_counts()","204588a4":"features_num = ['Cost_of_vehicle', 'Min_coverage', 'Max_coverage']\nfeatures_cat = ['Insurance_company']\n\nle= LabelEncoder()   \ndf['Insurance_company'] = le.fit_transform(df['Insurance_company'])\ndf_test['Insurance_company'] = le.transform(df_test['Insurance_company'])\n\npreprocessor = make_column_transformer(\n    (StandardScaler(), features_num),\n)\n\ny = df['Amount']\ntrain_imputed = df.loc[:,['Cost_of_vehicle', 'Min_coverage', 'Max_coverage', 'Insurance_company']]\nX = preprocessor.fit_transform(train_imputed)\n\ntest_imputed = df_test.loc[:,['Cost_of_vehicle', 'Min_coverage',  'Max_coverage', 'Insurance_company']]\ntest_X = preprocessor.transform(test_imputed)\n\ntrain_imputed.columns","a19fc2c0":"#Train-test split\ntrain_X, val_X, train_y, val_y = train_test_split(X,y,random_state=1,test_size=0.2)","c9b56d93":"rf_model = RandomForestRegressor(random_state=1, n_estimators = 1000, max_depth=3)\n# fit your model\nrf_model.fit(train_X,train_y)\nval_preds = rf_model.predict(val_X)\n# Calculate the mean absolute error of your Random Forest model on the validation data\nrf_val_mae = mean_absolute_error(val_y,val_preds)\n\nprint(\"Validation MAE for Random Forest Model: {}\".format(rf_val_mae))","4fb8a2d7":"amount_predictions = rf_model.predict(test_X)","05965ad8":"X = df.loc[:,['Image_path']]\ny = df.loc[:,['Condition']]    \nX_test = df.loc[:,['Image_path']]\nprint('train set shape:', X.shape)\nprint('test set shape:', X_test.shape)","eac3979d":"data = []\nlabels = []\nfor (index_label, row_series) in df.iterrows():\n        img_path = row_series.values[0]\n        condition = row_series.values[-2]\n        labels.append(int(condition))\n        # load the image, pre-process it, and store it in the data list\n        originalImage = cv2.imread('\/kaggle\/input\/fast-furious-and-insured\/Fast_Furious_Insured\/trainImages\/' + img_path)\n        image = cv2.resize(originalImage, (224, 224))\n        image = img_to_array(image)\n        data.append(image)","97538f04":"base_model=MobileNet(weights='imagenet',include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\nx=base_model.output\nx=GlobalAveragePooling2D()(x)\nx=Dense(256,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\npreds=Dense(2,activation='softmax')(x) #final layer with softmax activation\nmodel=Model(inputs=base_model.input,outputs=preds)\n   # we want to set the first 20 layers of the network to be non-trainable\nfor layer in model.layers[:80]:\n    layer.trainable=False\nfor layer in model.layers[80:]:\n    layer.trainable=True","44102215":"from tensorflow.keras import optimizers\n\nprint(len(data),len(labels))\ndata = np.array(data, dtype=\"float\")\nlabels = np.array(labels)\n    \n# partition the data into training and testing splits using 80% of\n# the data for training and the remaining 20% for testing\n(train_images, test_images, train_labels, test_labels) = train_test_split(data,labels, test_size=0.2, random_state=42)\n\n#(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n# Normalize pixel values to be between 0 and 1\ntrain_images, test_images = (train_images \/ 255.0)-0.5, (test_images \/ 255.0) -0.5\n\ntrain_labels = to_categorical(train_labels, 2)\ntest_labels = to_categorical(test_labels, 2)\n\n#compile and train the model\nadam=optimizers.Adam(\n                lr=0.002,\n                beta_1=0.9,\n                beta_2=0.999,\n                epsilon=None,\n                decay=0.0001,\n                amsgrad=False\n                )\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n#callback = callbacks.LearningRateScheduler(scheduler)\nhistory = model.fit(train_images, train_labels, batch_size=32,epochs=5,shuffle=True, validation_data=(test_images, test_labels))","f95b71fd":"condition_predictions = []\nfor (index_label, row_series) in df_test.iterrows():\n        img_path = row_series.values[0]\n        # load the image, pre-process it, and store it in the data list\n        originalImage = cv2.imread('\/kaggle\/input\/fast-furious-and-insured\/Fast_Furious_Insured\/testImages\/' + img_path)\n        image = cv2.resize(originalImage, (224, 224))\n        image = img_to_array(image)\n        image = image.reshape((1,224, 224, 3))\n        image = np.array(image, dtype=\"float\") \/ 255.0 - 0.5\n        prediction = model.predict(image)\n        prediction = prediction[0]\n        condition_predictions.append(np.argmax(prediction))\n       ","54b7b5fc":"submission = pd.DataFrame({'Image_path': df_test.Image_path, 'Condition': condition_predictions, \n                          'Amount': amount_predictions})\nsubmission.to_csv('submission.csv', index=False)","5cf3630e":"## Get the predictions for amount","39cf197a":"# Label encoding and scaling","9889f9c7":"## Pre-processing","2ad6babe":"## Loading required packages","df54b295":"## Getting the test prediction","b4dd27b8":"## Train a random forest regressor","b95b183b":"## Transfer learning with MobileNet","880a19de":"## Loading testing data","ec09af3e":"## Loading training data","6ebe6312":"## Preparing the submission","fb99c032":"## Prepare the images"}}