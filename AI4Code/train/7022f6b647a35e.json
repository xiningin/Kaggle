{"cell_type":{"a88da816":"code","f32765a3":"code","0dc1b500":"code","3e0d9148":"code","e4500c0b":"code","23cc58a4":"code","c0fb196b":"code","03472c58":"markdown","bca69920":"markdown","2208fd31":"markdown","2ab0df18":"markdown","0ff8912c":"markdown","8fe7355d":"markdown"},"source":{"a88da816":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f32765a3":"import pandas as pd\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport math\nimport torchvision.datasets as data\nimport torchvision.transforms as transforms\nimport random\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom sklearn import preprocessing\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nrandom.seed(777)\ntorch.manual_seed(777)\nif device == 'cuda':\n  torch.cuda.manual_seed_all(777)","0dc1b500":"learning_rate = 0.1\ntraining_epochs = 100\nbatch_size = 1\nScaler = MinMaxScaler()\n\ntrain_data=pd.read_csv('\/kaggle\/input\/fired-area-prediction\/forestfires_train.csv',header=None,skiprows=1,usecols=range(4,13))\ntest_data=pd.read_csv('\/kaggle\/input\/fired-area-prediction\/forestfires_test.csv',header=None,skiprows=1,usecols=range(4,12))\n\nx_train_data=train_data.loc[:,0:11]\ny_train_data=train_data.loc[:,12]\n\nx_train_data=np.array(x_train_data)\ny_train_data=np.array(y_train_data)\nx_train_data = Scaler.fit_transform(x_train_data)\n\nx_train_data=torch.FloatTensor(x_train_data)\ny_train_data=torch.FloatTensor(y_train_data)\n\nprint(x_train_data)\n\ntrain_dataset = torch.utils.data.TensorDataset(x_train_data, y_train_data)\ndata_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                            batch_size=batch_size,\n                                            shuffle=True,\n                                            drop_last=True)","3e0d9148":"linear1 = torch.nn.Linear(8,8,bias=True)\nlinear2 = torch.nn.Linear(8,1,bias=True)\n\nrelu = torch.nn.ReLU()","e4500c0b":"# Random Init => Xavier Init\ntorch.nn.init.xavier_uniform_(linear1.weight)\ntorch.nn.init.xavier_uniform_(linear2.weight)","23cc58a4":"model = torch.nn.Sequential(linear1,relu,\n                            linear2).to(device)\nloss = torch.nn.MSELoss().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\ntotal_batch = len(data_loader)\nfor epoch in range(training_epochs):\n  avg_cost = 0\n\n  for X, Y in data_loader:\n    \n    X = X.to(device)\n    Y = Y.to(device)\n\n    # \uadf8\ub798\ub514\uc5b8\ud2b8 \ucd08\uae30\ud654\n    optimizer.zero_grad()\n    # Forward \uacc4\uc0b0\n    hypothesis = model(X)\n    # Error \uacc4\uc0b0\n    cost = loss(hypothesis, Y)\n    # Backparopagation\n    cost.backward()\n    # \uac00\uc911\uce58 \uac31\uc2e0\n    optimizer.step()\n\n    # \ud3c9\uade0 Error \uacc4\uc0b0\n    avg_cost += cost \/ total_batch\n\n    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n    \n  print('Learning finished')","c0fb196b":"# Test the model using test sets\nwith torch.no_grad():\n\n  x_test_data=test_data.loc[:,0:11]\n  x_test_data=np.array(x_test_data)\n  x_test_data = Scaler.transform(x_test_data)\n  x_test_data=torch.from_numpy(x_test_data).float().to(device)\n\n  prediction = model(x_test_data)\n\ncorrect_prediction = prediction.cpu().numpy().reshape(-1,1)\n\nsubmit=pd.read_csv('\/kaggle\/input\/fired-area-prediction\/forestfires_submission.csv')\n\nfor i in range(len(correct_prediction)):\n  submit['prediction'][i]=correct_prediction[i].item()\nsubmit\n\nsubmit.to_csv('submission.csv',index=False,header=True)\n!kaggle competitions submit -c fired-area-prediction -f submission.csv -m \"Message\"","03472c58":"# \ubaa8\ub378 \ud3c9\uac00","bca69920":"# NN \ubaa8\ub378 \uc815\uc758","2208fd31":"> Xavier initialization","2ab0df18":"**baseline code\uc640\uc758 \ucc28\uc774\uc810**\n* dropout \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uc74c\n* \ub370\uc774\ud130 \uc804\ucc98\ub9ac \ubc29\ubc95 \ub2e4\ub984 (rain data \uc0ad\uc81cX, area data \ub85c\uadf8 \ubcc0\ud658X)\n\n**\uc124\uba85 \ub3d9\uc601\uc0c1 \ub9c1\ud06c**\n* https:\/\/youtu.be\/DPHn9WSr2x4","0ff8912c":"> Activation Fuction : ReLU (Rectified Linear Unit","8fe7355d":"# \ubaa8\ub378 \ud559\uc2b5"}}