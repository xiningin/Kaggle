{"cell_type":{"fd84ce5d":"code","68d8ee31":"code","aef89964":"code","e10d2921":"code","9ea950e9":"code","19c6d982":"code","cfdfaefa":"code","73016398":"code","e5562fba":"code","d0776429":"code","eb09ee2b":"code","d3464912":"code","ddfe1b90":"code","16fc9493":"code","6b7b1e54":"code","dc8ec1ba":"code","d0531c93":"code","00168010":"code","e7221969":"code","235554f0":"code","0f3d489a":"code","89e002ba":"code","07858020":"code","f211c8ba":"code","380fc952":"code","f6a50c79":"code","8dd7c594":"markdown","a77243c6":"markdown","968487a8":"markdown","95b49bc9":"markdown","26532c9f":"markdown","dabdd461":"markdown","c8476e10":"markdown","0c0be66b":"markdown","f3bae7ab":"markdown","125396cb":"markdown","6a972510":"markdown","2a2b3d5e":"markdown","488488fb":"markdown","9390575f":"markdown"},"source":{"fd84ce5d":"!pip install pydot","68d8ee31":"!pip install pydotplus","aef89964":"import os, datetime\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import plot_model\n\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimport pydotplus\nimport pydot","e10d2921":"print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))","9ea950e9":"base_dir = \"..\/input\/140k-real-and-fake-faces\/real_vs_fake\/real-vs-fake\/\"\ntrain_dir = os.path.join(base_dir, 'train')\ntest_dir = os.path.join(base_dir, 'test')\nvalid_dir = os.path.join(base_dir, 'valid')","19c6d982":"train_datagen = ImageDataGenerator( rescale = 1.0\/255.,\n                                  rotation_range=40,\n                                  width_shift_range=0.2,\n                                  height_shift_range=0.2,\n                                  shear_range=0.2,\n                                  zoom_range=0.2,\n                                  horizontal_flip=True,\n                                  fill_mode='nearest')\ntest_datagen = ImageDataGenerator( rescale = 1.0\/255. )\nvalid_datagen = ImageDataGenerator( rescale = 1.0\/255. )","cfdfaefa":"train_generator = train_datagen.flow_from_directory(train_dir, batch_size=100, class_mode='binary', target_size=(150, 150))\n\nvalidation_generator = valid_datagen.flow_from_directory(valid_dir, batch_size=100, class_mode='binary', target_size=(150, 150))\n\ntest_generator = test_datagen.flow_from_directory(test_dir, batch_size=100, class_mode='binary', target_size=(150, 150))","73016398":"print(train_generator.class_indices)","e5562fba":"plt.figure(figsize=(10, 10))\nfor i in range(9):\n    img, label = train_generator.next()\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(img[0])\n    if(label[0] == 0.0):\n        plt.title(\"Fake\")\n    else:\n        plt.title(\"Real\")\n    plt.axis(\"off\")","d0776429":"model = tf.keras.models.Sequential(\n    [\n     tf.keras.layers.Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(150, 150, 3)),\n     tf.keras.layers.MaxPooling2D(2,2),\n\n     tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n     tf.keras.layers.MaxPooling2D(2,2),\n\n     tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu'),\n     tf.keras.layers.MaxPooling2D(2,2),\n\n     tf.keras.layers.Flatten(),\n\n     tf.keras.layers.Dense(1064, activation='relu'),\n#      tf.keras.layers.Dense(2, activation='softmax')\n     tf.keras.layers.Dense(2)\n    ]\n)","eb09ee2b":"tf.keras.utils.pydot = pydot","d3464912":"plot_model(model, to_file='model.png', show_shapes=True)","ddfe1b90":"model.summary()","16fc9493":"model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics = ['accuracy'])","6b7b1e54":"%%time\nhistory = model.fit(train_generator, validation_data = validation_generator, epochs = 10, validation_steps = 100, verbose=1)","dc8ec1ba":"model.save(\".\/model.h5\")","d0531c93":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy (training & val)')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='upper right')\nplt.show()\n\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss (training & val)')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='upper right')\nplt.show()","00168010":"test_loss, test_acc = model.evaluate(test_generator)","e7221969":"test_acc","235554f0":"test_loss","0f3d489a":"test_generator.class_indices","89e002ba":"class_names = list(test_generator.class_indices.keys())","07858020":"class_names","f211c8ba":"import numpy as np\nfrom keras.preprocessing import image\n\ntest_image = image.load_img('..\/input\/140k-real-and-fake-faces\/real_vs_fake\/real-vs-fake\/test\/real\/00056.jpg', target_size=(150, 150, 3))\nplt.imshow(test_image)\n\ntest_image_arr = image.img_to_array(test_image)\ntest_image_arr = np.expand_dims(test_image, axis=0)\n","380fc952":"logits = model.predict(test_image_arr)\nprint(logits)\npredictions = tf.nn.softmax(logits).numpy()\nprint(predictions)","f6a50c79":"print(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(class_names[np.argmax(predictions)], 100 * np.max(predictions))\n)\n\nprint(100 * np.max(predictions))\n\nif np.argmax(predictions) == 0:\n    title = \"fake prob: \" + str(100 * np.max(predictions))\nelse:\n    title = \"real prob: \" + str(100 * np.max(predictions))\n    \nplt.title(title)\nplt.imshow(test_image)","8dd7c594":"# Dataset Description\nThe dataset consists of all 70k REAL faces from the Flickr dataset collected by Nvidia, as well as 70k fake faces sampled from the 1 Million FAKE faces (generated by StyleGAN) that was provided by Bojan.\n\nIn this dataset, I convenient combined both dataset, resized all the images into 256px, and split the data into train, validation and test set. I also included some CSV files for convenience.\n\n**Dataset**: https:\/\/www.kaggle.com\/xhlulu\/140k-real-and-fake-faces","a77243c6":"#### Compile and train the model","968487a8":"#### Model summary","95b49bc9":"Logits return the raw value for out prediction. So we applied softmax to normalize the values [0, 1]","26532c9f":"### Evaluate the model on the test data via evaluate():","dabdd461":"#### Visualize training results","c8476e10":"View all the layers of the network using the model's summary method:","0c0be66b":"### Image preparation for CNN Image Classifier","f3bae7ab":"<!-- TODO \npredicted_class_raw = np.argmax(logits) -->","125396cb":"### Import TensorFlow and other libraries","6a972510":"## Visualizing network architectures","2a2b3d5e":"## Model architecture","488488fb":"#### Predict on new data","9390575f":"### Visualize the data"}}