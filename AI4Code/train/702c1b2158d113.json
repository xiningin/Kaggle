{"cell_type":{"c8588087":"code","d591b476":"code","1be0d53e":"code","14e80ffc":"code","4fadec51":"code","7575a4f7":"code","808180fb":"code","cae8e1ab":"code","3795e71d":"code","5df79487":"code","38e05f8a":"code","1c3737cc":"code","111bd4f4":"code","a0c7dcbe":"code","3235e725":"code","e3b428c0":"code","150fbaee":"code","a96f5aa3":"code","e7862f18":"code","8f65cd95":"code","95b1aacf":"code","60987b25":"code","838eb0c6":"code","3d19621f":"code","687c3173":"code","c437c423":"code","89249c4f":"code","8c6730d7":"markdown","af3e3b31":"markdown","adc4ef0d":"markdown","d74ec2ce":"markdown","831a2121":"markdown","1f8666e2":"markdown","53ba267e":"markdown","9b633268":"markdown","ced23f2c":"markdown","881db6f5":"markdown","9b6d8b0b":"markdown","8e4080dd":"markdown","12bde20b":"markdown","6ac62445":"markdown","0376a60f":"markdown","98d62907":"markdown","1eab579a":"markdown","187f0edb":"markdown","ea06ec0a":"markdown","c4ecb186":"markdown","a73c3c2d":"markdown","afeb0c7a":"markdown","a2d9281e":"markdown","d48fdfce":"markdown","0746c2a9":"markdown","2d98de19":"markdown","b72b0f41":"markdown","396c9e03":"markdown","24e89a19":"markdown","48c67b03":"markdown","ef70f45a":"markdown","b0a54286":"markdown","ad61e5bd":"markdown","5bc59c45":"markdown","0036def6":"markdown","74043144":"markdown","2126c2fb":"markdown","e2826c94":"markdown","983def72":"markdown","22b821e5":"markdown","1f47e27b":"markdown","e207469e":"markdown","ec0672a9":"markdown","5b86dc15":"markdown","db33b183":"markdown","9e898221":"markdown","b00061f0":"markdown","56baf44e":"markdown","1363b2ed":"markdown","433ae387":"markdown","245ed868":"markdown","ad7c97bf":"markdown","b0b2e0f4":"markdown","9c2ae3ca":"markdown","9a970174":"markdown","4c4b0f15":"markdown","88d5422c":"markdown","b0a7007a":"markdown"},"source":{"c8588087":"import numpy as np\nimport random\nimport matplotlib.pyplot as plt","d591b476":"shape, scale= 2., 2.,  #mean= 4, std-dev= 2*sqrt(2)\nmu= shape*scale\nsigma= scale*np.sqrt(shape)\ns= np.random.gamma(shape, scale, 1000000)","1be0d53e":"rs= random.choices(s, k= 10000)","14e80ffc":"# set k\nks= [0.1, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0]\n#prob list\nprobs= []\n\nfor k in ks:\n    #start count\n    c=0\n    # for each data sample\n    for i in rs:\n        # count if far from mean in k standard deviation\n        if abs(i- mu)> k*sigma:\n            c+=1\n        # count divided by number of sample\n    probs.append(c\/10000)","4fadec51":"# set figure size\nplt.figure(figsize=(20,10))\n# plot each probability\nplt.plot(ks, probs, marker= 'o')\nplt.show()\n# print each probability\nprint(\"Probability of a sample far from mean more than k standard deviation:\")\nfor i, prob in enumerate(probs):\n    print(\"k:\" + str(ks[i]) + \", probability: \" \\\n          + str(prob)[0:5] + \\\n          \" | in theory, probability should less than: \" \\\n          + str(1\/ks[i]**2)[0:5])","7575a4f7":"shape, scale = 2., 2.  # mean=4, std=2*sqrt(2)\ns = np.random.gamma(shape, scale, 1000000)","808180fb":"samplemeanlist = [] # list of sample mean\nl = [] # list of smaple size, for x-axis of box plots\nnumberofsample = 50 # number of sample in each sample size\n    \n# set sample size (i) between 100 to 8100, step by 500\nfor i in range(100,8101,500):\n    # set x-axis\n    l.append(i)\n    # list of mean of each sample\n    ml = []\n    # sample 50 time.\n    for n in range(0,numberofsample):\n        # random pick from population with sample size = i\n        rs = random.choices(s, k=i)\n        # calculate the mean of each sample and save it in list of mean.\n        ml.append(sum(rs)\/i)  \n    \n    # save the 50 sample mean in samplemeanlist for box plots.\n    samplemeanlist.append(ml)","cae8e1ab":"# set figure size\nplt.figure(figsize=(20,10))\n# plot box plots of each sample mean\nplt.boxplot(samplemeanlist,labels = l)\n# show plot\nplt.show()","3795e71d":"histplot = plt.figure(figsize=(20,10))\nplt.hist(samplemeanlist[0], 10, density=True)\nplt.hist(samplemeanlist[16], 10, density=True)\nhistplot.show()","5df79487":"print(\"sample with 100 sample size,\" + \\\n      \"mean:\" + str(np.mean(samplemeanlist[0])) + \\\n      \", standard deviation: \"+ str(np.std(samplemeanlist[0])))\nprint(\"sample with 8100 sample size,\" + \\\n      \"mean:\" + str(np.mean(samplemeanlist[16])) + \\\n      \", standard deviation: \"+ str(np.std(samplemeanlist[16])))\n","38e05f8a":"# build gamma distribution as population\nshape, scale = 2., 2.  # mean=4, std=2*sqrt(2)\ns = np.random.gamma(shape, scale, 1000000)","1c3737cc":"## sample from population with different number of sampling\n# a list of sample mean\nmeansample = []\n# number of sample\nnumofsample = [1000,2500,5000,10000,25000,50000]\n# sample size\nsamplesize = 500\n# for each number of sampling (1000 to 50000)\nfor i in numofsample:\n    # collect mean of each sample\n    eachmeansample = []\n    # for each sampling\n    for j in range(0,i):\n        # sampling 500 sample from population\n        rc = random.choices(s, k=samplesize)\n        # collect mean of each sample\n        eachmeansample.append(sum(rc)\/len(rc))\n    # add mean of each sampling to the list\n    meansample.append(eachmeansample)","111bd4f4":"# plot\ncols = 2\nrows = 3\nfig, ax = plt.subplots(rows, cols, figsize=(20,15))\nn = 0\nfor i in range(0, rows):\n    for j in range(0, cols):\n        ax[i, j].hist(meansample[n], 200, density=True)\n        ax[i, j].set_title(label=\"number of sampling :\" + str(numofsample[n]))\n        n += 1","a0c7dcbe":"# use last sampling\nsm = meansample[len(meansample)-1]","3235e725":"# calculate start deviation\nstd = np.std(sm)\n# set population mean\nmean = np.mean(sm)","e3b428c0":"# list of standarded sample\nzn = []\n# for each sample subtract with mean and devided by standard deviation\nfor i in sm:\n    zn.append((i-mean)\/std)","150fbaee":"import scipy.stats as stats","a96f5aa3":"# plot hist\nplt.figure(figsize=(20,10))\nplt.hist(zn, 200, density=True)\n# compare with standard normal disrtibution line\nmu = 0\nsigma = 1\nx = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n# draw standard normal disrtibution line\nplt.plot(x, stats.norm.pdf(x, mu, sigma),linewidth = 5, color='red')\nplt.show()","e7862f18":"## sample with different sample size\n# list of sample mean\nmeansample = []\n# number of sampling\nnumofsample = 25000\n# sample size\nsamplesize = [1,5,10,30,100,1000]\n# for each sample size (1 to 1000)\nfor i in samplesize:\n    # collect mean of each sample\n    eachmeansample = []\n    # for each sampling\n    for j in range(0,numofsample):\n        # sampling i sample from population\n        rc = random.choices(s, k=i)\n        # collect mean of each sample\n        eachmeansample.append(sum(rc)\/len(rc))\n    # add mean of each sampling to the list\n    meansample.append(eachmeansample)","8f65cd95":"# plot\ncols = 2\nrows = 3\nfig, ax = plt.subplots(rows, cols, figsize=(20,15))\nn = 0\nfor i in range(0, rows):\n    for j in range(0, cols):\n        ax[i, j].hist(meansample[n], 200, density=True)\n        ax[i, j].set_title(label=\"sample size :\" + str(samplesize[n]))\n        n += 1","95b1aacf":"## expect value of sample\n# use last sampling\nsample = meansample[5]\n# expected value of sample equal to expect value of population\nprint(\"expected value of sample:\", np.mean(sample))\nprint(\"expected value of population:\", shape*scale)\n# standard deviation of sample equl to standard deviation of population divided by squre root of n\nprint(\"standard deviation of sample:\", np.std(sample))\nprint(\"standard deviation of population:\", scale*np.sqrt(shape))\nprint(\"standard deviation of population divided by squre root of sample size:\", scale*np.sqrt(shape)\/np.sqrt(1000))","60987b25":"# build gamma distribution as population\nshape, scale = 2., 2.  # mean=4, std=2*sqrt(2)\ns = np.random.gamma(shape, scale, 1000000)","838eb0c6":"## show that as the sample size increases the mean of sample is close to population mean\n# set expected values of population\nmu = shape*scale # mean\n# sample size\nsamplesize = []\n# collect difference between sample mean and mu\ndiflist = []\n# for each sample size\nfor n in range(10,20000,20): \n    # sample n sample\n    rs = random.choices(s, k=n)\n    # start count\n    c = 0\n    # calculate mean\n    mean = sum(rs)\/len(rs)\n    # collect difference between sample mean and mu\n    diflist.append(mean-mu)\n    samplesize.append(n)","3d19621f":"# set figure size.\nplt.figure(figsize=(20,10))\n# plot each diference.\nplt.scatter(samplesize,diflist, marker='o')\n# show plot.\nplt.show()","687c3173":"# build gamma distribution as population\nshape, scale = 2., 2.  # mean=4, std=2*sqrt(2)  \nmu = shape*scale # mean\ns = np.random.gamma(shape, scale, 1000000)\n# margin of error\nepsilon = 0.05","c437c423":"# list of probability of each sample size\nproberror = []\n# sample size for plotting\nsamplesize = []\n# for each sample size\nfor n in range(100,10101,500): \n    # start count\n    c = 0\n    for i in range(0,100):\n        # sample n sample\n        rs = random.choices(s, k=n)\n        # calculate mean\n        mean = sum(rs)\/len(rs)\n        # check if the difference is larger than error\n        if abs(mean - mu) > epsilon:\n            # if larger count the sampling\n            c += 1\n    # calculate the probability\n    proberror.append(c\/100)\n    # save sample size for plotting\n    samplesize.append(n)","89249c4f":"# set figure size.\nplt.figure(figsize=(20,10))\n# plot each probability.\nplt.plot(samplesize,proberror, marker='o')\n# show plot.\nplt.show()","8c6730d7":"2.) Plot each sample mean.","af3e3b31":"The theorem states that the distribution of independent sample means is an approximately normal distribution, even if the population is not normally distributed. In other words, if we independently sample from population many times and plot a mean of each sampling the plot will be a normal distribution, regardless of the population distribution.","adc4ef0d":"According to the formula, if k increases, the probability will decrease.","d74ec2ce":"Because we assumed that our sample contains independent and identically distributed random variables, we can simplify the right side of the equation.","831a2121":"2.) Sample from the population 100 times using sample size from 100 to 10,100 step by 500, then count the sample that has the differences of mean and expected value larger than error.\n\n3.) Calculate the probability of each sample size, and add the probability plot","1f8666e2":"4.) Plot and print the result.","53ba267e":"### The expected value and standard deviation of sample means\nSuppose that X is a random variable that is independent and identical distributed with the expected value \u03bc and standard deviation \u03c3. If we sample the X n sample, the expectation and variance of X will be as follow.","9b633268":"I will plot another graph to show that the probability that the difference of the sample means and expectation is larger that error is decreasing as the sample size increases.\n\n\nStep:\n\n\n1.) Use the same gamma distribution as a population, and set error to be 0.05.","ced23f2c":"Step:\n1.) Use the same gamma distribution as a population","881db6f5":"One of the reasons we standardize the sample mean is the complexity of a normal distribution function. We have to integrate the complicated function which can take hours to do, so instead, we standardize the distribution and use the Z table to find an area under the function.","9b6d8b0b":"<img src= \"https:\/\/miro.medium.com\/max\/260\/1*fSeZaNW5_mJw5F0iaP0USQ.gif\">","8e4080dd":"2.) Sample 10,000 values from the population","12bde20b":"2.) Sample from the population using sample size from 10 to 20,000 step by 20, then calculate the difference between the sample mean and the population mean.","6ac62445":"<img src=\"https:\/\/miro.medium.com\/max\/258\/1*ZILUKMueMtNbyFyGLa4n5g.gif\">","0376a60f":"3.) Subtract each value by mean and divide it by standard deviation, so the mean and standard deviation of the sample mean is 0, 1 respectively.","98d62907":"We can see that as the sample size increases the difference is decreasing.\nWe can also use the formula to find a sample size that can keep an error of a sample mean within a range. For example, if we want our sample to be a 1% error with a 95% probability, we can set an inequality to be like this.\n<img src= \"https:\/\/miro.medium.com\/max\/593\/1*QqtaSV0ii9npUSXSPoSAeQ.jpeg\">","1eab579a":"## Sample size\nThe rule of thumb of sample size is that it should be larger than 30 to make the sample mean distributed normally. However, the theorem still works if the sample size is less than 30 but the population is normally distributed. I will illustrate what will happen if the sample size is less than 30, 30 and greater than 30.\nStep:\n1.) Sample from the same gamma distribution with 1 sample size, calculate the mean and repeat the step 25,000 times. I repeat this step but increase the sample size until it reaches 1,000 sample size.","187f0edb":"In other words:\n  #  P($\\mu$-k$\\sigma$ < x < $\\mu$+k$\\sigma$)> 1- 1\/$k^2$","ea06ec0a":"<img src= \"https:\/\/miro.medium.com\/max\/395\/1*WbaivSq0Xmjt30cONiu97A.gif\">","c4ecb186":"3.) Count the sample that has a distance from the expected value larger than k standard deviation and use the count to calculate the probabilities. I want to depict a trend of probabilities when k is increasing, so I use a range of k from 0.1 to 3.","a73c3c2d":"We can prove this using Chebyshev\u2019s inequality, which says the probability that a random variable X differs from its mean by some small constant k is less than or equal to the variance of X divided by the the square of the constant k.","afeb0c7a":"# Step:\n1.) Create a population of 1,000,000 values, I use a gamma distribution with shape = 2 and scale = 2, but the theorem works with other distribution as well, such as uniform distribution, normal distribution.","a2d9281e":"# Step:\n1.) Create a gamma distribution with shape = 2 and scale = 2 as a population.","d48fdfce":"We can see from the plots that as the number of sampling increases, the distribution becomes smoother. This theorem is extremely powerful because we can apply to any population, so if we have tools to work with normal distribution, we can use that tool with the sample mean of any distribution such as calculate probability using an area under a normal curve.","0746c2a9":"#### The things you should take away from this are:\n- The sample mean will be a normal distribution regardless of the population mean.\n- As the sample size increases, the variance of the sample mean becomes smaller.\n- Therefore, the probability that the sample mean is far from expectation is also decreasing as a sample size increases.","2d98de19":"# Step:\n1.) Create a population of 1,000,000 values, I use a gamma distribution with shape = 2 and scale = 2 to show that theorem work with non-normal distribution","b72b0f41":"In the plot, we can see that as a sample size increases, the distributions of sample mean decrease and centric around an expected value.\n","396c9e03":"<img src=\"https:\/\/miro.medium.com\/max\/546\/1*ott3FA9HNRWCATfH-81GbA.jpeg\">, \n<img src=\"https:\/\/miro.medium.com\/max\/705\/1*otR7TN90Sv2zCEQGuQjj-Q.jpeg\">","24e89a19":"# Central Limit Theorem","48c67b03":"# Chebyshev's inequality:","ef70f45a":"From the plot, the distribution of sample size that is less than 30 is not normally distributed.\nI will combine this theorem with Chebyshev\u2019s inequality and the weak law of large numbers, but before we go there, let\u2019s look at the expected value and standard deviation of sample means.","b0a54286":"3.) Plot a boxplot of each sample size","ad61e5bd":"4.) Plot the probabilities.","5bc59c45":"4.) Plot the result.","0036def6":"1.) Using the distribution from the last sampling","74043144":"Where n is sample size, n = 10 means we use 10 data and sample mean is an average of 10 data, the expected value and variance can be calculated as above.","2126c2fb":"for a wide class of probability distributions, no more than a certain fraction of values can be more than a certain distance from the mean. Specifically, no more than 1\/k2 of the distribution's values can be more than k standard deviations away from the mean (or equivalently, at least 1 \u2212 1\/k2 of the distribution's values are within k standard deviations of the mean). The rule is often called Chebyshev's theorem.","e2826c94":"<img src=\"https:\/\/miro.medium.com\/max\/240\/1*h4kmMFp3vaIqWGSPGFD3TQ.gif\">","983def72":"2.) Sample from the gamma distribution with 500 sample size, calculate the mean and repeat the step 1,000 times (this is a number of sampling). I repeat this step but increase the number of sampling until the number is 50,000 times.","22b821e5":"For example, the probability that a distance from an expected value is far more than 3 standard deviation is less or equal than one over nine.\n\n**P($\\mu$-3$\\sigma$< x< $\\mu$+3$\\sigma$)> 8\/9**","1f47e27b":"# Probabilistic statement\nLet X (integrable) be a random variable with finite expected value \u03bc and finite non-zero variance \u03c32. Then for any real number k > 0,\n<img src= \"https:\/\/miro.medium.com\/max\/401\/1*DJqMc1N7D9zgMdR78tr8Fw.jpeg\">","e207469e":"### Convergence in sample means\nChebyshev\u2019s inequality works with a wide class of probability distribution, and it also works with a normal distribution. We can change the inequality for working with sample mean as follows.","ec0672a9":"Since the random variable X and the constant k can be anything, we can replace X with the sample mean and replace k with epsilon.","5b86dc15":"<img src= \"https:\/\/miro.medium.com\/max\/806\/1*hQWDcuhgeQn0QlRGPgF0Hg.jpeg\">","db33b183":"*As the sample size n grows to infinity, the probability that the sample mean x-bar differs from the population mean mu by some small amount epsilon is equal to 0.*","9e898221":"We can use Chebyshev\u2019s inequality in many applications, we can estimate a probability that data will fall in a range of k standard deviations. For example, there is a 90% chance that the next sample will be within a range of 3 standard deviations.","b00061f0":"However, it feels a bit counterintuitive because how one sample can have an expectation and a variance, it is just a number. Well, think about this, suppose I ask you to sample student\u2019s height in a school, you will have to knock every classroom and pick 1 student in the room. Before you go into the room, what is your expectation of the height of the student you will pick? You do not know, right? Then, what if I tell you that the average height of students in this school is 5 feet with variance 4 inches. Now, your expectation of the height of a student before you picks one of them should be 5 feet with variance 4 inches. If you pick 10 students, the expectation of the height of those students would be the sum of expectation of each student, which is the same with value 5 feet, divided by the number of students. Thus, try to think of a sample as a random variable, not a number.\nAnother thing I want to mention is, according to formula, when the sample size increases the variance of the sample mean will be smaller, so the variance of the sample mean depend on the sample size. If we sample large enough the sample mean will be close to its expectation.","56baf44e":"## Standardize the Sample Mean\nWe can change sample mean distribution into standard normal distribution by subtracting each sample mean with an expected value and dividing by a standard deviation.\n# Step:","1363b2ed":"Replacing the right side of Chebyshev\u2019s inequality, we have the following.\n<img src= \"https:\/\/miro.medium.com\/max\/218\/1*QgmlUJni53tvK4C2r4d5QA.gif\">\nAs n tends to infinity, it follows that the right side of the inequality equals 0.","433ae387":"2.) Calculate the mean and standard deviation of the sample mean.","245ed868":"I plot two histograms to compare distributions of two sample mean, the blue one is a sample mean with 100 sample size and the orange one is a sample mean with an 8100 sample size.\nOne last thing, what you should take from this blog is the fact that the sample size has a huge effect on the accuracy of sample means to the expected values. If your study has a large sample size the mean of your sample will be close to the population mean.","ad7c97bf":"2.) Set a sample size to 100 at first, sample 50 times and collect a mean of each time, then increase the sample size by 500, repeat the step until the sample size reach 8100.","b0b2e0f4":"3.) Plot the differences.","9c2ae3ca":"3.) Plot each sample mean.","9a970174":"The Weak Law of Large Numbers, also known as Bernoulli\u2019s theorem, states that if you have a sample of independent and identically distributed random variables, as the sample size grows larger, the sample mean will tend toward the population mean.","4c4b0f15":"Where X bar is a sample mean, \u03bc is expected values of a sample mean, \u03b5 is the margin of error which greater than 0, \u03c3 is a standard deviation of the population and n is a sample size.\nUsing the weak law of larger numbers and this formula, if the sample size goes to infinity, the probability that the difference between the sample mean and expected value is greater than a margin of error converges to zero.\nI will use python to show the fact that as a sample size increase the sample mean become closer to the expected value as the following step.","88d5422c":"# Weak Law of Large Numbers","b0a7007a":"From the plot and result, we can see that as the k increases, the probability is decreasing, and the probability of each k follows the inequality. Moreover, only the case that k is larger than 1 is useful. If k is less than 1, the right side of the inequality is larger than 1 which is not useful because the probability cannot be larger than 1."}}