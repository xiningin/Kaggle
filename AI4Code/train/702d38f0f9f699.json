{"cell_type":{"bd805a7b":"code","606ff9a1":"code","d5c985d1":"code","ad463ad0":"code","b52f4192":"code","7c930f0e":"code","5ec4c858":"code","e7de7c32":"code","eb90748f":"code","46b24964":"code","3ccb58da":"code","980c1319":"code","48731a70":"code","a15cd9b4":"code","805798c9":"code","c0bf91dc":"code","346191e3":"code","6c0d2549":"code","4be64375":"code","45e1fc08":"code","0faeefd4":"code","80dc2109":"code","029f7e00":"markdown","c72b02d0":"markdown","d2d44fcc":"markdown","75390128":"markdown","61843596":"markdown","bb9e94bd":"markdown"},"source":{"bd805a7b":"!pip install natsort\n# method to install python pack","606ff9a1":"import os \nfrom os import listdir # os module help for work with file system\nimport numpy as np # for math+optmised work on arrays\n  \n# imports from tensorflow for deep learning\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose, multiply, Lambda, add, Activation\nfrom tensorflow.keras.layers import concatenate\nfrom tensorflow.keras.optimizers import *\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.preprocessing import image\n\nimport matplotlib.pyplot as plt # for plotting\n%matplotlib inline \n# for keeping the plot inside jupyter notebook\n\nfrom sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix # metrics to compare model results\nfrom sklearn.model_selection import KFold\n\nimport natsort # it may need to be installed by 'pip install natsort'\n\nimport datetime\nnow = datetime.datetime.now","d5c985d1":"# Directory with images and ground truths\n# Directory with salient masks, images, and ground truths\npath_imgs = \"..\/input\/brain-tumor-dataset-with-saliency\/images\"\npath_masks = \"..\/input\/brain-tumor-dataset-with-saliency\/masks\"\n\nimagesList = listdir(path_imgs)\n\n# Sort the images in ascending order\nimgList=natsort.natsorted(imagesList)\n\n# Introduce parameters\nimg_row = 256\nimg_col = 256\nimg_chan = 1\nepochnum = 10\nbatchnum = 10\ninput_size = (img_row, img_col, img_chan)\n\nnum_imgs = len(imgList)\nprint(\"Number of images:\", num_imgs)","ad463ad0":"# Load the images \ndef img_load(dir_path, imgs_list, imgs_array):\n    for i in range(num_imgs):\n        if imgs_list[i][-4:] !=\".png\":\n            continue\n        tmp_img = image.load_img(os.path.join(dir_path, imgs_list[i]), target_size=(img_row, img_col, img_chan))\n        img = image.img_to_array(tmp_img)\n        imgs_array[i] = img[:,:,0]\/255.0 \n\n    # Expand the dimensions of the arrays\n    imgs_array = np.expand_dims(imgs_array, axis=3)\n    return imgs_array\n\ndef mask_load(dir_path, imgs_list, imgs_array):\n    for i in range(num_imgs):\n        if imgs_list[i][-4:] !=\".png\":\n            continue\n        tmp_img = image.load_img(os.path.join(dir_path, imgs_list[i][:-4]+\"_mask.png\"), target_size=(img_row, img_col, img_chan))\n        img = image.img_to_array(tmp_img)\n        imgs_array[i] = img[:,:,0]\/255.0 \n\n    # Expand the dimensions of the arrays\n    imgs_array = np.expand_dims(imgs_array, axis=3)\n    return imgs_array\n\n# Initialize the arrays\nimgs = np.zeros((num_imgs, img_row, img_col))\nmasks = np.zeros_like(imgs)\n\nimgs = img_load(path_imgs, imgList, imgs)\nmasks = mask_load(path_masks, imgList, masks)\n\nprint(\"Images\", imgs.shape)\nprint(\"Masks\", masks.shape)","b52f4192":"# Plot the first and last images\nplt.figure(figsize = (14,6))\nplt.subplot(221)\nplt.imshow(np.squeeze(imgs[0]), cmap = \"gray\")\nplt.title('First image')\nplt.subplot(222)\nplt.imshow(np.squeeze(masks[0]), cmap = \"gray\")\nplt.title('First mask')\nplt.subplot(223)\nplt.imshow(np.squeeze(imgs[-5]), cmap = \"gray\")\nplt.title('Last image')\nplt.subplot(224)\nplt.imshow(np.squeeze(masks[-5]), cmap = \"gray\")\nplt.title('Last mask')\nplt.tight_layout()\nplt.show()","7c930f0e":"# pip install opencv-contrib-python  ","5ec4c858":"# import matplotlib.pyplot as plt\n# import cv2\n# from scipy import stats\n# import numpy as np\n# import random\n# import PIL.ImageDraw as ImageDraw\n# import PIL.Image as Image\n# import os.path\n# from tqdm import tqdm\n# import math\n\n\n# def print_img(img, histo_new, histo_old, index, L):\n#     dpi = 80\n#     width = img.shape[0]\n#     height = img.shape[1]\n#     if height > width:\n#         figsize = (img.shape[0]*4) \/ float(dpi), (height)\/ float(dpi)\n#         fig, axs = plt.subplots(1, 3, gridspec_kw={'width_ratios': [3, 1,1]}, figsize=figsize)\n#     else:\n#         figsize = (width) \/ float(dpi), (height*4) \/ float(dpi)\n#         fig, axs = plt.subplots(3, 1, gridspec_kw={'height_ratios': [3, 1,1]}, figsize=figsize)\n\n#     fig.suptitle(\"Enhanced Image with L:\" + str(L))\n#     axs[0].title.set_text(\"Enhanced Image\")\n#     axs[0].imshow(img, vmin=np.amin(img), vmax=np.amax(img), cmap='gray')\n\n#     axs[1].title.set_text(\"Equalized histogram\")\n#     axs[1].plot(histo_new, color='#f77f00')\n#     axs[1].bar(np.arange(len(histo_new)), histo_new, color='#003049')\n\n#     axs[2].title.set_text(\"Main histogram\")\n#     axs[2].plot(histo_old, color='#ef476f')\n#     axs[2].bar(np.arange(len(histo_old)), histo_old, color='#b7b7a4')\n#     plt.tight_layout()\n#     plt.savefig(\"e\" + index + str(L)+\".pdf\")\n#     plt.savefig(\"e\" + index + str(L)+\".png\")\n\n\n# def print_histogram(_histrogram, name, title):\n#     plt.figure()\n#     plt.title(title)\n#     plt.plot(_histrogram, color='#ef476f')\n#     plt.bar(np.arange(len(_histrogram)), _histrogram, color='#b7b7a4')\n#     plt.ylabel('Number of Pixels')\n#     plt.xlabel('Pixel Value')\n#     plt.savefig(\"hist_\" + name)\n\n\n# def generate_histogram(img, print, index):\n#     if len(img.shape) == 3: # img is colorful\n#         gr_img = np.mean(img, axis=-1)\n#     else:\n#         gr_img = img\n#     '''now we calc grayscale histogram'''\n#     gr_hist = np.zeros([256])\n#     for x_pixel in range(gr_img.shape[0]):\n#         for y_pixel in range(gr_img.shape[1]):\n#             pixel_value = int(gr_img[x_pixel, y_pixel])\n#             gr_hist[pixel_value] += 1\n#     '''normalize Histogram'''\n#     gr_hist \/= (gr_img.shape[0] * gr_img.shape[1])\n#     if print:\n#         print_histogram(gr_hist, name=\"neq_\"+str(index), title=\"Normalized Histogram\")\n#     return gr_hist, gr_img\n\n\n# def equalize_histogram(img, histo, L):\n#     eq_histo = np.zeros_like(histo)\n#     en_img = np.zeros_like(img)\n#     for i in range(len(histo)):\n#         eq_histo[i] = int((L - 1) * np.sum(histo[0:i]))\n#     print_histogram(eq_histo, name=\"eq_\"+str(index), title=\"Equalized Histogram\")\n#     '''enhance image as well:'''\n#     for x_pixel in range(img.shape[0]):\n#         for y_pixel in range(img.shape[1]):\n#             pixel_val = int(img[x_pixel, y_pixel])\n#             en_img[x_pixel, y_pixel] = eq_histo[pixel_val]\n#     '''creating new histogram'''\n#     hist_img, _ = generate_histogram(en_img, print=False, index=index)\n#     print_img(img=en_img, histo_new=hist_img, histo_old=histo, index=str(index), L=L)\n#     return eq_histo\n\n\n# def find_value_target(val, target_arr):\n#     key = np.where(target_arr == val)[0]\n\n#     if len(key) == 0:\n#         key = find_value_target(val+1, target_arr)\n#         if len(key) == 0:\n#             key = find_value_target(val-1, target_arr)\n#     vvv = key[0]\n#     return vvv\n\n\n# def match_histogram(inp_img, hist_input, e_hist_input, e_hist_target, _print=True):\n#     '''map from e_inp_hist to 'target_hist '''\n#     en_img = np.zeros_like(inp_img)\n#     tran_hist = np.zeros_like(e_hist_input)\n#     for i in range(len(e_hist_input)):\n#         tran_hist[i] = find_value_target(val=e_hist_input[i], target_arr=e_hist_target)\n#     print_histogram(tran_hist, name=\"trans_hist_\", title=\"Transferred Histogram\")\n#     '''enhance image as well:'''\n#     for x_pixel in range(inp_img.shape[0]):\n#         for y_pixel in range(inp_img.shape[1]):\n#             pixel_val = int(inp_img[x_pixel, y_pixel])\n#             en_img[x_pixel, y_pixel] = tran_hist[pixel_val]\n#     '''creating new histogram'''\n#     hist_img, _ = generate_histogram(en_img, print=False, index=3)\n#     print_img(img=en_img, histo_new=hist_img, histo_old=hist_input, index=str(3), L=L)\n\n\n\n# L=50\n# print(\"\\r\\nLoading Images:\")\n# #    imgs = load_images()\n# img=np.squeeze(imgs[0])\n# print(img.shape)\n# plt.imshow(imgs[0], cmap = \"gray\")\n# print(\"\\r\\ngenerating HistogramS:\")\n# gr_img_arr = []\n# gr_hist_arr = []\n# eq_hist_arr = []\n# index = 0\n# #    for img in tqdm(imgs):\n# hist_img, gr_img = generate_histogram(img, print=True, index=index)\n# gr_hist_arr.append(hist_img)\n# gr_img_arr.append(gr_img)\n# eq_hist_arr.append(equalize_histogram(gr_img, hist_img, L))\n# index += 1\n# match_histogram(inp_img=gr_img_arr[0], hist_input=gr_hist_arr[0], e_hist_input=eq_hist_arr[0], e_hist_target=eq_hist_arr[0])\n    \n\n    \n    \n    \n    \n# gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n# equalized = cv2.equalizeHist(gray)\n    \n\n    \n    \n\n    \n    \n# image=np.squeeze(imgs[0]);\n# plt.imshow(image, cmap = \"gray\");\n# if len(image.shape) == 3: # img is colorful\n#       gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n# else:\n#       gray = image\n        \n# clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n# equalized = clahe.apply(gray)","e7de7c32":"!pip install scikit-image","eb90748f":"# import matplotlib\n# import matplotlib.pyplot as plt\n# import numpy as np\n# from tqdm import tqdm\n\n# from skimage import data, img_as_float\n# from skimage import exposure\n\n\n# matplotlib.rcParams['font.size'] = 8\n\n\n# def plot_img_and_hist(image, axes, bins=256):\n#     \"\"\"Plot an image along with its histogram and cumulative histogram.\n\n#     \"\"\"\n#     image = img_as_float(image)\n#     ax_img, ax_hist = axes\n#     ax_cdf = ax_hist.twinx()\n\n#     # Display image\n#     ax_img.imshow(image, cmap=plt.cm.gray)\n#     ax_img.set_axis_off()\n\n#     # Display histogram\n#     ax_hist.hist(image.ravel(), bins=bins, histtype='step', color='black')\n#     ax_hist.ticklabel_format(axis='y', style='scientific', scilimits=(0, 0))\n#     ax_hist.set_xlabel('Pixel intensity')\n#     ax_hist.set_xlim(0, 1)\n#     ax_hist.set_yticks([])\n\n#     # Display cumulative distribution\n#     img_cdf, bins = exposure.cumulative_distribution(image, bins)\n#     ax_cdf.plot(bins, img_cdf, 'r')\n#     ax_cdf.set_yticks([])\n\n#     return ax_img, ax_hist, ax_cdf\n\n\n# # Load an example image\n# # img = data.moon()\n# img=np.squeeze(imgs[0])\n# print(img.shape)\n# # Contrast stretching\n# p2, p98 = np.percentile(img, (2, 98))\n# img_rescale = exposure.rescale_intensity(img, in_range=(p2, p98))\n\n# # Equalization\n# img_eq = exposure.equalize_hist(img)\n# print(img_eq.shape)\n\n# # Adaptive Equalization\n# img_adapteq = exposure.equalize_adapthist(img, clip_limit=0.03)\n\n\n\n\n\n\n# imgs_adapteq = np.zeros((num_imgs, img_row, img_col))\n# masks_adapteq = np.zeros_like(imgs)\n\n\n# for i in range(num_imgs):\n#         if imgList[i][-4:] !=\".png\":\n#             continue\n#         tmp_img = image.load_img(os.path.join(path_imgs, imgList[i]), target_size=(img_row, img_col, img_chan))\n# #         print(tmp_img.size)\n#         img_adapteq = exposure.equalize_adapthist(np.squeeze(tmp_img), clip_limit=0.03)\n# #         print(img_adapteq.shape)\n#         img_adapteq=img_adapteq[:,:,0]\n# #         print(img_adapteq.shape)\n#         img_adapteq=np.expand_dims(img_adapteq, axis=1)\n# #         img_adapteq=img_adapteq.reshape(256,256)\n#         img = image.img_to_array(img_adapteq)\n#         imgs[i] = img[:,:,0]\/255.0 \n\n#     # Expand the dimensions of the arrays\n# imgs = np.expand_dims(imgs, axis=3)\n#     return imgs_array\n\n# for img in tqdm(imgs):\n#     imgs_adapteq=np.concatenate(imgs_adapteq,exposure.equalize_adapthist(img, clip_limit=0.03))\n#     imgs_adapteq = imgs_adapteq.append(exposure.equalize_adapthist(img, clip_limit=0.03))\n\n# print(imgs.shape)\n    \n\n    \n    \n    \n    \n    \n    \n# # Display results\n# fig = plt.figure(figsize=(8, 5))\n# axes = np.zeros((2, 4), dtype=np.object)\n# axes[0, 0] = fig.add_subplot(2, 4, 1)\n# for i in range(1, 4):\n#     axes[0, i] = fig.add_subplot(2, 4, 1+i, sharex=axes[0,0], sharey=axes[0,0])\n# for i in range(0, 4):\n#     axes[1, i] = fig.add_subplot(2, 4, 5+i)\n\n# ax_img, ax_hist, ax_cdf = plot_img_and_hist(img, axes[:, 0])\n# ax_img.set_title('Low contrast image')\n\n# y_min, y_max = ax_hist.get_ylim()\n# ax_hist.set_ylabel('Number of pixels')\n# ax_hist.set_yticks(np.linspace(0, y_max, 5))\n\n# ax_img, ax_hist, ax_cdf = plot_img_and_hist(img_rescale, axes[:, 1])\n# ax_img.set_title('Contrast stretching')\n\n# ax_img, ax_hist, ax_cdf = plot_img_and_hist(img_eq, axes[:, 2])\n# ax_img.set_title('Histogram equalization')\n\n# ax_img, ax_hist, ax_cdf = plot_img_and_hist(img_adapteq, axes[:, 3])\n# ax_img.set_title('Adaptive equalization')\n\n# ax_cdf.set_ylabel('Fraction of total intensity')\n# ax_cdf.set_yticks(np.linspace(0, 1, 5))\n\n# # prevent overlap of y-axis labels\n# fig.tight_layout()\n# plt.show()\n\n\n\n\n\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom skimage import data, img_as_float\nfrom skimage import exposure\n\n\nmatplotlib.rcParams['font.size'] = 8\n\n\ndef plot_img_and_hist(image, axes, bins=256):\n    \"\"\"Plot an image along with its histogram and cumulative histogram.\n\n    \"\"\"\n    image = img_as_float(image)\n    ax_img, ax_hist = axes\n    ax_cdf = ax_hist.twinx()\n\n    # Display image\n    ax_img.imshow(image, cmap=plt.cm.gray)\n    ax_img.set_axis_off()\n\n    # Display histogram\n    ax_hist.hist(image.ravel(), bins=bins, histtype='step', color='black')\n    ax_hist.ticklabel_format(axis='y', style='scientific', scilimits=(0, 0))\n    ax_hist.set_xlabel('Pixel intensity')\n    ax_hist.set_xlim(0, 1)\n    ax_hist.set_yticks([])\n\n    # Display cumulative distribution\n    img_cdf, bins = exposure.cumulative_distribution(image, bins)\n    ax_cdf.plot(bins, img_cdf, 'r')\n    ax_cdf.set_yticks([])\n\n    return ax_img, ax_hist, ax_cdf\n\n\n# Load an example image\n# img = data.moon()\nimg=np.squeeze(imgs[0])\n\n# Contrast stretching\np2, p98 = np.percentile(img, (2, 98))\nimg_rescale = exposure.rescale_intensity(img, in_range=(p2,p98))\n\n# Equalization\nimg_eq = exposure.equalize_hist(img)\n\n# Adaptive Equalization\nimg_adapteq = exposure.equalize_adapthist(img, clip_limit=0.03)\n\n# Display results\nfig = plt.figure(figsize=(8, 5))\naxes = np.zeros((2, 4), dtype=np.object)\naxes[0, 0] = fig.add_subplot(2, 4, 1)\nfor i in range(1, 4):\n    axes[0, i] = fig.add_subplot(2, 4, 1+i, sharex=axes[0,0], sharey=axes[0,0])\nfor i in range(0, 4):\n    axes[1, i] = fig.add_subplot(2, 4, 5+i)\n\nax_img, ax_hist, ax_cdf = plot_img_and_hist(img, axes[:, 0])\nax_img.set_title('Low contrast image')\n\ny_min, y_max = ax_hist.get_ylim()\nax_hist.set_ylabel('Number of pixels')\nax_hist.set_yticks(np.linspace(0, y_max, 5))\n\nax_img, ax_hist, ax_cdf = plot_img_and_hist(img_rescale, axes[:, 1])\nax_img.set_title('Contrast stretching')\n\nax_img, ax_hist, ax_cdf = plot_img_and_hist(img_eq, axes[:, 2])\nax_img.set_title('Histogram equalization')\n\nax_img, ax_hist, ax_cdf = plot_img_and_hist(img_adapteq, axes[:, 3])\nax_img.set_title('Adaptive equalization')\n\nax_cdf.set_ylabel('Fraction of total intensity')\nax_cdf.set_yticks(np.linspace(0, 1, 5))\n\n# prevent overlap of y-axis labels\nfig.tight_layout()\nplt.show()","46b24964":"imgs_adapteq = np.zeros((num_imgs, img_row, img_col))\nmasks_adapteq = np.zeros_like(imgs)\n\n\nfor i in range(num_imgs):\n        if imgList[i][-4:] !=\".png\":\n            continue\n        tmp_img = image.load_img(os.path.join(path_imgs, imgList[i]), target_size=(img_row, img_col, img_chan))\n#         print(tmp_img.size)\n        img_adapt = exposure.equalize_adapthist(np.squeeze(tmp_img), clip_limit=0.03)\n#         print(img_adapteq.shape)\n        img_adapt=img_adapt[:,:,0]\n#         print(img_adapteq.shape)\n#         img_adapteq=np.expand_dims(img_adapteq, axis=1)\n#         img_adapteq=img_adapteq.reshape(256,256)\n        img = image.img_to_array(img_adapt)\n        imgs_adapteq[i]=img[:,:,0]\/255.0\n#         img=np.expand_dims(img, axis=-1)\n#         img= img.reshape(256,256,1)\n#         imgs[i] = img[:,:,0]\/255.0 \n\n    # Expand the dimensions of the arrays\nimgs_adapteq = np.expand_dims(imgs_adapteq, axis=3)\n#     return imgs_array\n\n# for img in tqdm(imgs):\n#     imgs_adapteq=np.concatenate(imgs_adapteq,exposure.equalize_adapthist(img, clip_limit=0.03))\n#     imgs_adapteq = imgs_adapteq.append(exposure.equalize_adapthist(img, clip_limit=0.03))\n\nprint(imgs_adapteq.shape)","3ccb58da":"    for i in range(num_imgs):\n        if imgList[i][-4:] !=\".png\":\n            continue\n        temp_img = image.load_img(os.path.join(path_masks, imgList[i][:-4]+\"_mask.png\"), target_size=(img_row, img_col, img_chan))\n#         print(temp_img.size)\n        mask_adapt = exposure.equalize_adapthist(np.squeeze(temp_img), clip_limit=0.03)\n        mask_adapt=mask_adapt[:,:,0]\n#         print(mask_adapt.shape)\n        mask = image.img_to_array(mask_adapt)\n        masks_adapteq[i]=mask[:,:,:]\/255.0 \n#         masks_adapteq=masks_adateq[:,:,:,0]\n\n    # Expand the dimensions of the arrays\n    masks_adapteq = np.expand_dims(masks_adapteq, axis=3)\n\n    print(masks_adapteq.shape)","980c1319":"masks_adapteq=masks_adapteq.reshape(masks_adapteq[:,:,:,0].shape)\nprint(masks_adapteq.shape)","48731a70":"plt.figure(figsize = (14,6))\nplt.subplot(221)\nplt.imshow(np.squeeze(imgs_adapteq[0]), cmap = \"gray\")\nplt.title('First image')","a15cd9b4":"plt.figure(figsize = (14,6))\nplt.subplot(221)\nplt.imshow(np.squeeze(masks_adapteq[0]), cmap = \"gray\")\nplt.title('First mask')","805798c9":"# Define loss and performance metrics\n# Partially from Abraham and Khan (2019) - A Novel Focal Tversly Loss Function for Lesion Segmentation\n\n# Dice score coefficient and Dice loss \ndef dsc(y_true, y_pred):\n    smooth = 1.\n    # masks\n    y_true_fm = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_fm * y_pred_f)\n    score = (2. * intersection + smooth) \/ (K.sum(y_true_fm) + K.sum(y_pred_f) + smooth) \n    return score\n\ndef dice_loss(y_true, y_pred):\n    loss = 1 - dsc(y_true, y_pred)\n    return loss\n\n# Performance metrics: Dice score coefficient, IOU, recall, sensitivity\ndef auc(y_true, y_pred):\n    y_pred_pos = np.round(np.clip(y_pred, 0, 1))\n    y_pred_neg = 1 - y_pred_pos\n    y_pos = np.round(np.clip(y_true, 0, 1)) # ground truth\n    y_neg = 1 - y_pos\n    tp = np.sum(y_pos * y_pred_pos)\n    tn = np.sum(y_neg * y_pred_neg)\n    fp = np.sum(y_neg * y_pred_pos)\n    fn = np.sum(y_pos * y_pred_neg)\n    tpr = (tp + K.epsilon()) \/ (tp + fn + K.epsilon()) #recall\n    tnr = (tn + K.epsilon()) \/ (tn + fp + K.epsilon())\n    prec = (tp + K.epsilon()) \/ (tp + fp + K.epsilon()) #precision\n    iou = (tp + K.epsilon()) \/ (tp + fn + fp + K.epsilon()) #intersection over union\n    dsc = (2*tp + K.epsilon()) \/ (2*tp + fn + fp + K.epsilon()) #dice score\n    return [dsc, iou, tpr, prec]","c0bf91dc":"# Convolutional block for UNet\ndef ConvBlock(in_fmaps, num_fmaps):\n    # Inputs: feature maps for UNet, number of output feature maps\n    conv1 = Conv2D(num_fmaps, (3, 3), activation='relu', padding='same')(in_fmaps)\n    conv_out = Conv2D(num_fmaps, (3, 3), activation='relu', padding='same')(conv1)\n    return conv_out","346191e3":"# Build the model\ndef Network():\n    \n    input = Input(shape=input_size)\n\n    conv1 = ConvBlock(input, 32)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\n    conv2 = ConvBlock(pool1, 32)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\n    conv3 = ConvBlock(pool2, 64)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\n    conv4 = ConvBlock(pool3, 64)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n\n    conv5 = ConvBlock(pool4, 128)\n\n    up6 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n    conv6 = ConvBlock(up6, 64)\n\n    up7 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n    conv7 = ConvBlock(up7, 64)\n\n    up8 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n    conv8 = ConvBlock(up8, 32)\n\n    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n    conv9 = ConvBlock(up9, 32)\n\n    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n\n    model = Model(inputs = input, outputs = conv10)\n\n    return model  ","6c0d2549":" from sklearn.model_selection import train_test_split","4be64375":"np.arange(0,3064)","45e1fc08":"train, test = train_test_split(np.arange(0,1000), test_size=0.15, random_state=42)","0faeefd4":"# Define  the model\nmodel = Network()\nprint(\"Model Start\")\n# Split into train and test sets\nimgs_train, masks_train, imgs_test, masks_test = imgs_adapteq[train], masks_adapteq[train], imgs_adapteq[test], masks_adapteq[test]\nprint(\"Images Loaded\")\n\n# Compile and fit the  model\nmodel.compile(optimizer = Adam(lr = 0.0001), loss = dice_loss, metrics = [dsc])\nbatchnum = 50\nepochnum = 80\nt = now()\ncallbacks = [EarlyStopping(monitor='val_loss', patience = 20)]\nprint(\"Fit model on training data\")\nhistory = model.fit(imgs_train, masks_train, validation_split=0.15, batch_size=batchnum, \n                    epochs=epochnum, verbose=1, callbacks=callbacks)\nprint(history)\nprint('Training time: %s' % (now() - t))\n\n# Plot the loss and accuracy\ntrain_loss = history.history['loss']\nval_loss = history.history['val_loss']\nacc = history.history['dsc'] \nval_acc = history.history['val_dsc']\n\nepochsn = np.arange(1, len(train_loss)+1,1)\nplt.figure(figsize = (12,5))\nplt.subplot(121)\nplt.plot(epochsn,train_loss, 'b', label='Training Loss')\nplt.plot(epochsn,val_loss, 'r', label='Validation Loss')\nplt.grid(color='gray', linestyle='--')\nplt.legend()\nplt.title('LOSS, Epochs={}, Batch={}'.format(epochnum, batchnum))\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\n\nplt.subplot(122)\nplt.plot(epochsn, acc, 'b', label='Training Dice Coefficient')\nplt.plot(epochsn, val_acc, 'r', label='Validation Dice Coefficient')\nplt.grid(color='gray', linestyle='--')\nplt.legend()            \nplt.title('DSC, Epochs={}, Batch={}'.format(epochnum, batchnum))\nplt.xlabel('Epochs')\nplt.ylabel('CSC')\nplt.show()\n\n# Make predictions\nt = now()\npreds = model.predict(imgs_test)\nprint('Testing time: %s' % (now() - t))\n\n# Evaluate model\nnum_test = len(imgs_test)\n# Calculate performance metrics\ndsc_sc = np.zeros((num_test,1))\niou_sc = np.zeros_like(dsc_sc)\nrec_sc = np.zeros_like(dsc_sc)\ntn_sc = np.zeros_like(dsc_sc)\nprec_sc = np.zeros_like(dsc_sc)\nthresh = 0.5\nfor i in range(num_test):\n    dsc_sc[i], iou_sc[i], rec_sc[i], prec_sc[i] = auc(masks_test[i], preds[i] >thresh)\nprint('-'*30)\nprint('USING THRESHOLD', thresh)\nprint('\\n DSC \\t\\t{0:^.3f} \\n IOU \\t\\t{1:^.3f} \\n Recall \\t{2:^.3f} \\n Precision\\t{3:^.3f}'.format(\n        np.sum(dsc_sc)\/num_test,  \n        np.sum(iou_sc)\/num_test,  \n        np.sum(rec_sc)\/num_test,\n        np.sum(prec_sc)\/num_test ))\n\n# To plot a set of images with predicted masks uncomment these lines\nnum_disp = 10\nj=1\nplt.figure(figsize = (14,num_disp*3))\nfor i in range(num_disp):\n    plt.subplot(num_disp,4,j)\n    plt.imshow(np.squeeze(imgs_test[i]), cmap='gray')\n    plt.title('Image')\n    j +=1\n    plt.subplot(num_disp,4,j)\n    plt.imshow(np.squeeze(masks_test[i]),cmap='gray')\n    plt.title('Mask')\n    j +=1\n    plt.subplot(num_disp,4,j)\n    plt.imshow(np.squeeze(preds[i]))\n    plt.title('Prediction')\n    j +=1\n    plt.subplot(num_disp,4,j)\n    plt.imshow(np.squeeze(np.round(preds[i])), cmap='gray')\n    plt.title('Rounded; IOU=%0.2f, Rec=%0.2f, Prec=%0.2f' %(iou_sc[i], rec_sc[i], prec_sc[i]))\n    j +=1\nplt.tight_layout()\nplt.show()   \n\n# Confusion matrix\nconfusion = confusion_matrix( masks_test.ravel(),preds.ravel()>thresh)\naccuracy = 0\nif float(np.sum(confusion))!=0:\n    accuracy = float(confusion[0,0]+confusion[1,1])\/float(np.sum(confusion))\nprint(' Global Acc \\t{0:^.3f}'.format(accuracy))\n\n\n# Save outputs \nnumepochs = epochsn[-1]\ndice_score = np.sum(dsc_sc)\/num_test\niou_score = np.sum(iou_sc)\/num_test\nrec_score = np.sum(rec_sc)\/num_test\nprec_score = np.sum(prec_sc)\/num_test\nglobacc_score = accuracy","80dc2109":"{'Epochs Number': numepochs, 'Dice Score': dice_score, 'IOU Score': iou_score, 'Recall (Sensitivity)': rec_score, 'Precision': prec_score, 'Global Accuracy': globacc_score}","029f7e00":"# Import libraries","c72b02d0":"# Performance metrics","d2d44fcc":"# Training","75390128":"# Display the Results","61843596":"# Load the images","bb9e94bd":"# Network"}}