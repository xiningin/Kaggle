{"cell_type":{"48dda291":"code","19e8b37c":"code","673568ed":"code","177153f3":"code","1d310fcb":"code","3719c71c":"code","1b633686":"code","74aa3286":"code","b2c3758a":"code","0718c998":"code","41f221dd":"code","1e64bd39":"code","7522c4fa":"code","ede0d268":"code","282f65d8":"code","642c7735":"code","70fc5289":"code","e6f59634":"code","75e6d60d":"code","0a188379":"code","8d05baea":"code","e2e1c191":"code","8b3f4a6a":"code","b948dd4a":"code","d192ff86":"code","3a8e3289":"code","8bd7d1b2":"code","cad9c344":"code","649dbcb5":"code","1d29df88":"code","ef3dcb1b":"code","dd7c4528":"markdown","02e7c6e4":"markdown","4605e563":"markdown","a5164b58":"markdown","48f81ddd":"markdown","72ab3ff2":"markdown","4f1dc45e":"markdown","f529d76b":"markdown","23f97c76":"markdown","0d7da15e":"markdown","f2a3301b":"markdown","934dc687":"markdown","cabff531":"markdown","c9e78741":"markdown","9df74409":"markdown","31dfb5ef":"markdown","169813b7":"markdown","1759eb9b":"markdown","4bcfdd83":"markdown"},"source":{"48dda291":"import pandas as pd\nimport numpy as np\nimport csv","19e8b37c":"file_path = 'Noshows.csv'\nNoshows = pd.read_csv(file_path)\nNoshows = pd.DataFrame(Noshows)\nprint(Noshows.head())","673568ed":"Noshows['ScheduledDay'] = Noshows['ScheduledDay'].apply(np.datetime64)\nNoshows['AppointmentDay'] = Noshows['AppointmentDay'].apply(np.datetime64)","177153f3":"Noshows['WaitingTime'] = Noshows['ScheduledDay'] - Noshows['AppointmentDay']\nNoshows['WaitingTime'] = Noshows['WaitingTime'].apply(lambda x: x.total_seconds() \/ (3600 * 24))\nNoshows['WaitingTime']","1d310fcb":"Noshows.head()","3719c71c":"print('Age',sorted(Noshows['Age'].unique()))\nprint('Gender',Noshows['Gender'].unique())\n#This was a little bit long so I just commented it\n#print('WaitingTime',sorted(Noshows['WaitingTime'].unique()))\nprint('Diabetes',Noshows['Diabetes'].unique())\nprint('Alcoholism',Noshows['Alcoholism'].unique())\nprint('Hipertension',Noshows['Hipertension'].unique())\nprint('Handcap',Noshows['Handcap'].unique())\nprint('Scholarship', Noshows['Scholarship'].unique())\nprint('SMS_received',Noshows['SMS_received'].unique())\nprint('No-show',Noshows['No-show'].unique())","1b633686":"#Deleting some outlier from age\nNoshows = Noshows[(Noshows['Age'] > 0) & (Noshows['Age'] < 100)]\n#Encoding gender\nNoshows['IsFemale'] = np.where(Noshows['Gender'] == \"F\",1, 0) \n#Encoding no-show\nNoshows['No-show'] = np.where(Noshows['No-show'] == \"Yes\",1, 0)","74aa3286":"#checking if an appointment is on Monday\nimport datetime\nNoshows['IsMonday'] = np.where(Noshows['AppointmentDay'].dt.dayofweek == 0, 1, 0)\n#Also realized in excel that neighborhood JARDIM CAMBURI has a huge rate of not showing up, thus:\nNoshows['IsJARDIMCAMBURI'] = np.where(Noshows['Neighbourhood'] == 'JARDIM CAMBURI', 1, 0)","b2c3758a":"Noshows = Noshows[['Age', 'IsFemale', 'Diabetes','Alcoholism','Hipertension','Handcap',\n                  'Scholarship', 'SMS_received', 'IsMonday', 'IsJARDIMCAMBURI','WaitingTime','No-show']]","0718c998":"features = Noshows[['Age', 'IsFemale', 'Diabetes','Alcoholism','Hipertension','Handcap',\n                  'Scholarship', 'SMS_received', 'IsMonday', 'IsJARDIMCAMBURI', 'WaitingTime']]\nlabels  = Noshows['No-show']","41f221dd":"from sklearn.model_selection import train_test_split \ntr_features, test_features, tr_labels, test_labels = train_test_split(features, labels,\nrandom_state=0)","1e64bd39":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\nDT = DecisionTreeClassifier(random_state=0)\nParameters = {'max_depth':[8]}\nCV = GridSearchCV(DT, Parameters, cv=5)","7522c4fa":"CV.fit(tr_features, tr_labels.values.ravel())\n#ignore the warnings here","ede0d268":"predict = CV.predict(test_features)","282f65d8":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score","642c7735":"accuracy_score(test_labels, predict)","70fc5289":"precision_score(test_labels, predict)","e6f59634":"predict.sum()","75e6d60d":"predictions = pd.DataFrame(predict, columns=['DT'])\nlabels = pd.DataFrame(test_labels, columns=['Labels'])\npredictions['Labels'] = labels['Labels']\npredictions.to_csv('predictions.csv')","0a188379":"from sklearn.linear_model import LogisticRegression\nLR = LogisticRegression(random_state=0)\nParameters = {'C':[0.001, 0.01, 0.1, 1, 10, 100]}\nCV = GridSearchCV(LR, Parameters, cv=5)\nCV.fit(tr_features, tr_labels.values.ravel())","8d05baea":"predict = CV.predict(test_features)\naccuracy_score(test_labels, predict)","e2e1c191":"precision_score(test_labels, predict)","8b3f4a6a":"from sklearn.neural_network import MLPClassifier\nNN = MLPClassifier(random_state=0)\nParameters = {'hidden_layer_sizes':[(5,)]}\nCV = GridSearchCV(NN, Parameters, cv=5)\nCV.fit(tr_features, tr_labels.values.ravel())","b948dd4a":"predict = CV.predict(test_features)\naccuracy_score(test_labels, predict)","d192ff86":"precision_score(test_labels, predict)","3a8e3289":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nRF = RandomForestClassifier()\nParameters = {'n_estimators':[1000],\n             'max_depth':[100]}\nCV = GridSearchCV(RF, Parameters, cv=5)\nCV.fit(tr_features, tr_labels.values.ravel())\nCV.best_params_","8bd7d1b2":"predict = CV.predict(test_features)\naccuracy_score(test_labels, predict)","cad9c344":"precision_score(test_labels, predict)\n","649dbcb5":"recall_score(test_labels, predict)","1d29df88":"f1_score(test_labels, predict)","ef3dcb1b":"predict.sum()\nCV.best_score_","dd7c4528":"9. Dividing the dataset into features (X) and lables (y)","02e7c6e4":"12. fitting the CV","4605e563":"5. Checking data for possible inconsistencies","a5164b58":"3. Changing the dates froma to make sure we can do analysis on them","48f81ddd":"8. Finalizing the dataset","72ab3ff2":"b. Multi-layer Preceptron","4f1dc45e":"7. Creating some new features","f529d76b":"15. Trying the process for some other models:","23f97c76":"a. Logistic Regression","0d7da15e":"11. Cross validation (first model tried: decision trees)","f2a3301b":"1. Importing required packegaes","934dc687":"c. Random Forest","cabff531":"The best results I could get was made by using a random forest of 25 estimators and maximu depth of 8. Thees are the scores: <br>\nAccuracy:0.7520565360454682 <br>\nPrecision:0.4522641981486115 <br>\nRecall:0.258348623853211 <br>\nF1: 0.2953091684434968 <br>\nTotal number of no shows predicted:3997 <br>\n","c9e78741":"6. Cleaning","9df74409":"13. Prediction","31dfb5ef":"4. Creating a waiting time calculater ","169813b7":"14. Exporting the results","1759eb9b":"10. creating train and test sets","4bcfdd83":"2. Importing the dataset"}}