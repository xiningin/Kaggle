{"cell_type":{"1b2bb176":"code","910bb79f":"code","ee1c511d":"code","6ed738ee":"code","e82a76de":"code","ded41959":"code","d1763680":"code","dd439643":"code","019eeac7":"code","d82f552a":"code","6092400f":"code","086a2f23":"code","b460ba14":"code","30e303dc":"code","60df654a":"code","0297d66a":"code","15b3e255":"code","966db70e":"code","dae85b99":"code","730e5a6c":"code","9e5795af":"code","38893844":"code","596de066":"code","42cc18bd":"code","3934863d":"code","c5a24175":"code","e03f3846":"code","be3fc71a":"code","a7b38792":"markdown","4b9f0dca":"markdown","f6b9d40d":"markdown","97c4c115":"markdown"},"source":{"1b2bb176":"import numpy as np\nimport pandas as pd\nimport os\nimport glob\nfrom tqdm.notebook import tqdm\nfrom PIL import Image","910bb79f":"os.listdir('\/kaggle\/input\/fundusimage1000\/1000images\/1000images')","ee1c511d":"import torch\nimport torchvision\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader,Dataset\nimport torch.nn as nn\nimport torch.optim as optim\n\ndevice='cuda' if torch.cuda.is_available() else 'cpu'\ndevice","6ed738ee":"class custom_dataset(Dataset):\n    def __init__(self,root_dir,transform=None):\n\n        self.data=[]\n        self.transform=transform\n\n        for img_path in tqdm(glob.glob(root_dir+\"\/*\/**\")):\n            class_name=img_path.split(\"\/\")[-2]\n            self.data.append([img_path,class_name])\n \n        self.class_map={}\n        for index,item in enumerate(os.listdir(root_dir)):\n             self.class_map[item]=index\n        print(f\"Total Classes:{len(self.class_map)}\")\n                \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self,idx):\n        img_path,class_name=self.data[idx]\n        img=Image.open(img_path)\n        class_id=self.class_map[class_name]\n        class_id=torch.tensor(class_id)\n\n        if self.transform:\n            img=self.transform(img)\n\n        return img,class_id","e82a76de":"root_dir=r'\/kaggle\/input\/fundusimage1000\/1000images\/1000images'","ded41959":"def create_transforms(normalize=False,mean=[0,0,0],std=[1,1,1]):\n    if normalize:\n        my_transforms=transforms.Compose([\n            transforms.Resize((224,224)),\n#             transforms.ColorJitter(brightness=0.3,saturation=0.5,contrast=0.7,),\n#             transforms.RandomRotation(degrees=33),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=mean,std=std)\n        ])\n       \n    else:\n         my_transforms=transforms.Compose([\n            transforms.Resize((512,512)),\n#             transforms.ColorJitter(brightness=0.3,saturation=0.5,contrast=0.7,p=0.57),\n#             transforms.RandomRotation(degrees=33),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor()])\n        \n        \n    return my_transforms\n        ","d1763680":"BS=8\nnum_classes=39","dd439643":"my_transforms=create_transforms(normalize=False)\ndataset=custom_dataset(root_dir,my_transforms)\nprint(len(dataset))\n\ntrain_set, val_set=torch.utils.data.random_split(dataset,[800,200],generator=torch.Generator().manual_seed(7))\ntrain_loader=DataLoader(train_set,batch_size=BS,shuffle=True)\nval_loader=DataLoader(val_set,batch_size=BS,shuffle=True)","019eeac7":"def get_mean_std(loader):\n    #var=E[x^2]-(E[x])^2\n    channels_sum, channels_squared_sum,num_batches=0,0,0\n    for data,_ in tqdm(loader):\n        channels_sum+=torch.mean(data,dim=[0,2,3]) # we dont want to a singuar mean for al 3 channels (in case of RGB)\n        channels_squared_sum+=torch.mean(data**2,dim=[0,2,3])\n        num_batches+=1\n    mean=channels_sum\/num_batches\n    std=(channels_squared_sum\/num_batches-mean**2)**0.5\n    \n    return mean, std","d82f552a":"mean,std=get_mean_std(train_loader)\nprint(mean, std)","6092400f":"#Since these are medical images (differenct from Imagenet data) I'll use the calculated mean, std\nmy_transforms=create_transforms(normalize=True,mean=mean,std = std)\ndataset=custom_dataset(root_dir,my_transforms)\nprint(len(dataset))\n\ntrain_set, val_set=torch.utils.data.random_split(dataset,[800,200],generator=torch.Generator().manual_seed(7))\ntrain_loader=DataLoader(train_set,batch_size=BS,shuffle=True)\nval_loader=DataLoader(val_set,batch_size=BS,shuffle=True)","086a2f23":"import matplotlib.pyplot as plt\n\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\n\nprint(images.shape)\nprint(labels.shape)\n\n\nplt.imshow(images[0].permute(1, 2, 0))","b460ba14":"vgg_model=torchvision.models.vgg16(pretrained=True)\nprint(vgg_model)","30e303dc":"vgg_model=torchvision.models.vgg16(pretrained=True)\n\nfor param in vgg_model.parameters():\n    param.requires_grad=False\n    \nclass Identity(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n    \n    def forward(self,x):\n        return x\n    \n# vgg_model.avgpool=Identity()\nvgg_model.classifier=nn.Sequential(\n    nn.Linear(25088,2048),\n    nn.ReLU(),\n    nn.Dropout(p=0.37),\n    nn.Linear(2048,1024),\n    nn.ReLU(),\n    nn.Dropout(p=0.5),\n    nn.Linear(1024,num_classes)\n)\n\nvgg_model.to(device)\n\n# model.features[30]=nn.AdaptiveAvgPool2d((16,16))\n\n# print(model.features)","60df654a":"EPOCHS=5\nLR=1e-3","0297d66a":"def train_model(model):\n    \n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.AdamW(model.parameters(), lr=LR)\n    scheduler=optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.9,verbose=True)\n    \n    for epoch in range(EPOCHS):\n        losses=[]\n        print(f\"Epoch {epoch+1}\/{EPOCHS}:\")\n        loop=tqdm(enumerate(train_loader),total=len(train_loader))\n        for batch_idx,(data,targets) in loop:\n            data=data.to(device)\n            targets=targets.to(device)\n\n            #forward\n            scores=model(data)\n            loss=criterion(scores,targets)\n\n            losses.append(loss.item())\n\n            #backward\n            optimizer.zero_grad()\n            loss.backward()\n\n            #gradient descent\/adam step\n            optimizer.step()\n        mean_loss=sum(losses)\/len(losses)\n        scheduler.step()\n\n        print(f\"Loss at Epoch {epoch+1}:\\t{mean_loss:.5f}\\n\")","15b3e255":"def check_accuracy(loader, model):\n\n    num_correct = 0\n    num_samples = 0\n    model.eval()\n\n    with torch.no_grad():\n        for x, y in tqdm(loader):\n            x = x.to(device=device)\n            y = y.to(device=device)\n\n            scores = model(x)\n            _, predictions = scores.max(1)\n            num_correct += (predictions == y).sum()\n            num_samples += predictions.size(0)\n\n        print(\n            f\"Got {num_correct} \/ {num_samples} with accuracy {float(num_correct)\/float(num_samples)*100:.2f}\"\n        )\n\n    model.train()","966db70e":"train_model(vgg_model)","dae85b99":"print(\"Training accuracy:\",end='\\t')\ncheck_accuracy(train_loader, vgg_model)\nprint(\"Validation accuracy:\",end='\\t')\ncheck_accuracy(val_loader, vgg_model)","730e5a6c":"!pip install efficientnet_pytorch","9e5795af":"from efficientnet_pytorch import EfficientNet","38893844":"def create_eff_net(version='b1',trainable=False):\n    eff_model = EfficientNet.from_name(f'efficientnet-{version}')\n    \n    for param in eff_model.parameters():\n        param.requires_grad = trainable\n        \n    num_ftrs = eff_model._fc.in_features\n    \n    eff_model._fc = nn.Sequential(\n    nn.Linear(num_ftrs,1024),\n    nn.ReLU(),\n    nn.Dropout(p=0.37),\n    nn.Linear(1024,num_classes)\n    )\n\n    eff_model.to(device)\n    \n    return eff_model\n\n    ","596de066":"eff_model=create_eff_net(version='b3',trainable=True)","42cc18bd":"train_model(eff_model)","3934863d":"print(\"Training accuracy:\",end='\\t')\ncheck_accuracy(train_loader, eff_model)\nprint(\"Validation accuracy:\",end='\\t')\ncheck_accuracy(val_loader, eff_model)","c5a24175":"eff_model2=create_eff_net(version='b3',trainable=False)","e03f3846":"train_model(eff_model2)","be3fc71a":"print(\"Training accuracy:\",end='\\t')\ncheck_accuracy(train_loader, eff_model2)\nprint(\"Validation accuracy:\",end='\\t')\ncheck_accuracy(val_loader, eff_model2)","a7b38792":"#### VGG16\nfrozen inner layers, top trained","4b9f0dca":"#### EfficientNet B3\n\nfull training","f6b9d40d":"## Modelling","97c4c115":"Freeze inner layers, train top now"}}