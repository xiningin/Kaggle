{"cell_type":{"a7f2ee15":"code","ac1a7ede":"code","050994e9":"code","97fff7a0":"code","4b20174b":"code","c08ce2b6":"code","8fb0a2a0":"code","39f01321":"code","bbf193ac":"code","f46c5391":"code","571534f3":"code","b13e3a44":"code","58041e40":"code","0af06f81":"code","69f85df7":"code","1b42702a":"code","ea620fe3":"code","c0360e71":"code","41ce283a":"code","e7f37199":"code","e748e1b0":"code","ad6ed924":"code","d984cacb":"code","4370f28e":"code","d674cecf":"code","f3ba64f8":"code","fd17bcc0":"code","eb5f5faa":"code","e825a8ff":"code","2beb4290":"code","05ac9736":"code","d547aee6":"code","e6d5fcc6":"code","80b5ec0b":"code","81658044":"code","d3929c10":"code","12fb288f":"code","c67f4f69":"code","c48a1e7d":"code","44d75550":"code","398c5317":"code","f8b16b0d":"code","274d00e3":"code","625fcf55":"code","9798f29e":"code","6b56dc7b":"code","1dfbe29e":"code","4727591c":"code","be1e3a25":"code","367e1330":"code","5fe42122":"code","e5333b60":"code","6777eaf5":"code","511037e0":"code","980cde75":"code","fbf18d04":"code","31fe1dbf":"code","ee88e2db":"code","29c97700":"code","57b9c1b3":"code","cf8c6e53":"code","64cd73fa":"code","ac14ec20":"code","a7fe89d9":"code","332ff7e1":"code","507cc0dc":"code","b3e69317":"code","daf5b8ab":"code","3feb855f":"code","56ed72d5":"code","681faaca":"code","97086273":"code","3e9315d8":"code","4ebf53a1":"code","f8f68245":"code","1d23a86d":"code","79fa310a":"code","b9c6be2d":"code","edf1faf4":"code","64c2c0cf":"code","796832b1":"code","0b2b1ae3":"code","4c57a0ab":"code","6e489fa7":"code","81b378bb":"code","59d5591b":"code","7a8d7013":"code","29a0e2d4":"code","bd4e5a4c":"code","c11be77a":"code","9be5d797":"code","9e810b43":"code","696ee8af":"code","ce4abb7a":"code","75bc7ad0":"code","4bf2603d":"code","b3f5978a":"code","0464bdd3":"code","a1aa70cb":"code","95fcb9c2":"code","1e09a6c1":"code","283bf0ac":"code","c01e45c7":"code","ac89660e":"code","82aaeb58":"code","c89edc4c":"code","2ae39638":"code","25df9ef5":"code","d42d996c":"code","bae4c7b5":"code","04ef620f":"code","7432e402":"code","538be039":"code","538ecf4a":"code","3b969204":"code","9fdee7e7":"code","c360d67a":"code","9c1338c3":"code","abbd6393":"code","5036078f":"markdown","5c19261b":"markdown","2016b916":"markdown","aa5610b6":"markdown","913e3680":"markdown","70c52a3d":"markdown","796e4327":"markdown","8f53f373":"markdown","87798cc4":"markdown","5346e181":"markdown","5eb27142":"markdown","05717734":"markdown","aba7941e":"markdown","6eacf79f":"markdown","08527970":"markdown","bc49b13a":"markdown","7e1d090f":"markdown","136f9d39":"markdown","11f74384":"markdown","da217cc0":"markdown","29b5d3c4":"markdown"},"source":{"a7f2ee15":"!pip install pyspellchecker\n!pip install pyspark\n!pip install openpyxl\nimport warnings\nwarnings.filterwarnings(\"ignore\")","ac1a7ede":"from pyspark.sql import SparkSession\nspark = SparkSession.builder.master(\"local[*]\").getOrCreate()","050994e9":"from pyspark import SparkContext, SparkConf\nconf = SparkConf()\nconf.set('spark.sql.autoBroadcastJoinThreshold',-1)","97fff7a0":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","4b20174b":"df = pd.read_excel('\/kaggle\/input\/flight-fare-prediction-mh\/Data_Train.xlsx')","c08ce2b6":"from pyspark.sql.types import *\ndf_schema = StructType([StructField('Airline', StringType(), True),StructField('Date_of_Journey', StringType(), True),\n                       StructField('Source', StringType(), True), StructField('Destination', StringType(), True),\n                       StructField('Route', StringType(), True),StructField('Dep_Time', StringType(), True),\n                       StructField('Arrival_Time', StringType(), True),StructField('Duration', StringType(), True),\n                       StructField('Total_Stops', StringType(), True),StructField('Additional_Info', StringType(), True),\n                       StructField('Price', IntegerType(), True)])\ndata = spark.createDataFrame(df,schema=df_schema)","8fb0a2a0":"data.printSchema()","39f01321":"type(data)","bbf193ac":"#data.show()\ndata.toPandas()","f46c5391":"from pyspark.sql.functions import col,isnan, when, count","571534f3":"# data.select([count(when((col(c) == '') |isnan(c) | col(c).isNull(), c)).alias(c) for c in data.columns]).show()\ndata.select([count(when((col(c) == '') |isnan(c) | col(c).isNull(), c)).alias(c) for c in data.columns]).toPandas()","b13e3a44":"# data.filter(\"Route == 'NaN'\").show()\ndata.filter(\"Route == 'NaN'\").toPandas()","58041e40":"df = data.where(data.Route != 'NaN').where(data.Total_Stops !='NaN')\n# df.show()\ndf.toPandas()","0af06f81":"df.count()","69f85df7":"# df.select([count(when((col(c) == '') |isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()\ndf.select([count(when((col(c) == '') |isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).toPandas()","1b42702a":"from pyspark.sql.functions import *\nfrom datetime import datetime\nimport pyspark.sql.functions as sqlFunc\nimport pyspark.sql.types as types\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.functions import to_timestamp","ea620fe3":"spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\n#df.select('Date_of_Journey', from_unixtime(unix_timestamp('Date_of_Journey', 'dd\/MM\/yyyy')))","c0360e71":"df.select('Dep_Time').show()","41ce283a":"# Split Hour from Dep_Time column\ndf = df.withColumn('Dep_Hour',hour('Dep_Time'))","e7f37199":"# Split minute from Dep_Time column\ndf = df.withColumn('Dep_Minute',minute('Dep_Time'))","e748e1b0":"df.select('Dep_Hour','Dep_Minute').show()","ad6ed924":"df = df.drop('Dep_Time')","d984cacb":"# convert data to date\n#df = df.withColumn(\"Date_of_Journey\",to_date(col(\"Date_of_Journey\"),\"dd\/MM\/yyyy\"))\ndf = df.withColumn('Date_of_Journey',to_timestamp(col('Date_of_Journey'), 'dd\/MM\/yyyy'))","4370f28e":"# Journey Month\ndf = df.withColumn('Journey_Month',month('Date_of_Journey'))","d674cecf":"# Journey Day\ndf = df.withColumn('Journey_Day', dayofmonth('Date_of_Journey'))","f3ba64f8":"df = df.drop('Date_of_Journey')","fd17bcc0":"df.select('Journey_Day','Journey_Month').show()","eb5f5faa":"df.printSchema()","e825a8ff":"df =df.withColumn('Arrival_Time', split(col('Arrival_Time'), ' ').getItem(0))","2beb4290":"df.select('Arrival_Time').show()","05ac9736":"df = df.withColumn('Arrival_Hour', hour('Arrival_Time'))","d547aee6":"df = df.withColumn('Arrival_Minute', minute('Arrival_Time'))","e6d5fcc6":"df.select('Arrival_Hour','Arrival_Minute').show()","80b5ec0b":"df = df.drop('Arrival_Time')","81658044":"df.select('Duration').show()","d3929c10":"# Split hour and minute from duration column\ndf = df.withColumn('Duration_Hour', split(df['Duration'], ' ').getItem(0)).withColumn('Duration_Minute', split(df['Duration'],' ').getItem(1))","12fb288f":"df.select('Duration_Hour',\"Duration_Minute\").show()","c67f4f69":"# Handle null values in Duration_Hour \ndf = df.withColumn(\"Duration_Hour\", expr(\"CASE WHEN Duration_Hour IS NULL THEN '0h' \" +  \"ELSE Duration_Hour END\"))","c48a1e7d":"# Handle null values in Duration_Minute\ndf = df.withColumn(\"Duration_Minute\", expr(\"CASE WHEN Duration_Minute IS NULL THEN '0m' \" +  \"ELSE Duration_Minute END\"))","44d75550":"df.select('Duration_Hour','Duration_Minute').show()","398c5317":"# get values minute \ndf = df.withColumn(\"Duration_Minute\", regexp_extract(\"Duration_Minute\", r'(\\d+)m' , 1 ))","f8b16b0d":"# get values hour\ndf = df.withColumn(\"Duration_Hour\", regexp_extract(\"Duration_Hour\", r'(\\d+)h' , 1 ))","274d00e3":"df.select('Duration_Hour','Duration_Minute').show()","625fcf55":"df = df.withColumn('Duration_Hour', df.Duration_Hour.cast(IntegerType()))","9798f29e":"df = df.withColumn('Duration_Minute', df.Duration_Hour.cast(IntegerType()))","6b56dc7b":"df= df.drop('Duration')","1dfbe29e":"df.select('Price','Journey_Day','Journey_Month','Dep_Hour','Dep_Minute','Arrival_Hour',\n                       'Arrival_Minute','Duration_Hour','Duration_Minute').show()","4727591c":"df.select('Airline', 'Source', 'Destination', 'Route', 'Total_Stops', 'Additional_Info').show()","be1e3a25":"df.select(countDistinct('Airline')).show()","367e1330":"df.select('Airline').distinct().collect()","5fe42122":"df.groupBy('Airline').count().alias('Count').sort(col('Count').desc()).show()","e5333b60":"data = df.toPandas()","6777eaf5":"plt.figure(figsize=(15,8))\nsns.boxplot(y='Price',x='Airline',data=data.sort_values('Price',ascending=False));\nplt.xticks(rotation = 45);","511037e0":"plt.figure(figsize=(15,8))\nsns.boxplot(y='Price',x='Total_Stops',data=data.sort_values('Price',ascending=False));","980cde75":"import pyspark.sql.functions as F \ncateg_air = df.select('Airline').distinct().rdd.flatMap(lambda x:x).collect()\nexprs_air = [F.when(F.col('Airline') == cat,1).otherwise(0).alias(str(cat)) for cat in categ_air]\ndf = df.select(exprs_air + df.columns)","fbf18d04":"test = df.select('Air India','GoAir','IndiGo','Jet Airways','Jet Airways Business','Multiple carriers',\n                    'Multiple carriers Premium economy','SpiceJet','Trujet','Vistara','Vistara Premium economy') # Air Asia","31fe1dbf":"test.toPandas().head()","ee88e2db":"df = df.drop('Air Asia').drop('Airline')","29c97700":"df.select(countDistinct('Source')).show()","57b9c1b3":"df.select('Source').distinct().collect()","cf8c6e53":"df.groupBy('Source').count().alias('Count').sort(col('Count').desc()).show()","64cd73fa":"plt.figure(figsize=(15,8));\nsns.catplot(y='Price',x='Source',data=data.sort_values('Price',ascending=False),kind='boxen');\nplt.xticks(rotation = 0);","ac14ec20":"categ_sou = df.select('Source').distinct().rdd.flatMap(lambda x:x).collect()\nexprs_sou = [F.when(F.col('Source') == cat,1).otherwise(0).alias(str(cat)+'_Sour') for cat in categ_sou]\ndf = df.select(exprs_sou+df.columns)","a7fe89d9":"df.select('Chennai_Sour','Delhi_Sour','Kolkata_Sour','Mumbai_Sour').show()","332ff7e1":"df = df.drop('Banglore_Sour').drop('Source')","507cc0dc":"df.printSchema()","b3e69317":"df.select(countDistinct('Destination')).show()","daf5b8ab":"df.select('Destination').distinct().collect()","3feb855f":"df.groupBy('Destination').count().alias('Count').sort(col('Count').desc()).show()","56ed72d5":"plt.figure(figsize=(15,8));\nsns.catplot(y='Price',x='Destination',data=data.sort_values('Price',ascending=False),kind='boxen');\nplt.xticks(rotation = 45);","681faaca":"categ_des = df.select('Destination').distinct().rdd.flatMap(lambda x:x).collect()\nexprs_des = [F.when(F.col('Destination') == cat,1).otherwise(0).alias(str(cat)+'_Des') for cat in categ_des]\ndf = df.select(exprs_des +df.columns)","97086273":"df = df.drop('Banglore_Des').drop('Destination')","3e9315d8":"df.select('Route').show()","4ebf53a1":"df = df.withColumn('Route_1',split(df['Route'],'\u2192').getItem(0))\\\n            .withColumn('Route_2',split(df['Route'],'\u2192').getItem(1))\\\n            .withColumn('Route_3',split(df['Route'],'\u2192').getItem(2))\\\n            .withColumn('Route_4',split(df['Route'],'\u2192').getItem(3))\\\n            .withColumn('Route_5',split(df['Route'],'\u2192').getItem(4))","f8f68245":"df = df.drop('Route').drop('Additional_Info')","1d23a86d":"df.select('Route_1','Route_2','Route_3','Route_4','Route_5').show()","79fa310a":"df = df.na.fill(\"None\",subset=['Route_1','Route_2','Route_3','Route_4','Route_5'])","b9c6be2d":"df.select('Route_1','Route_2','Route_3','Route_4','Route_5').show()","edf1faf4":"e = df.select('Route_1','Route_2','Route_3','Route_4','Route_5')","64c2c0cf":"from pyspark.ml import Pipeline\nfrom pyspark.ml.feature import StringIndexer","796832b1":"for i in e.columns:\n    indexer = StringIndexer(inputCol=i, outputCol=i+ \"_Label\")\n    df = indexer.fit(df).transform(df)","0b2b1ae3":"df.printSchema()","4c57a0ab":"df.select('Route_1_Label','Route_2_Label','Route_3_Label','Route_4_Label','Route_5_Label').show()","6e489fa7":"# Drop Route_1, Route_2, Route_3, Route_4, Route_5 columns\ndf = df.drop('Route_1').drop('Route_2').drop('Route_3').drop('Route_4').drop('Route_5')","81b378bb":"# Convert Route_1_Label, Route_2_Label, Route_3_Label, Route_4_Label, Route_4_Label columns from DoubleType to IntegerType\ndf = df.withColumn('Route_1_Label', col('Route_1_Label').cast(IntegerType()))\\\n            .withColumn('Route_2_Label', col('Route_2_Label').cast(IntegerType()))\\\n            .withColumn('Route_3_Label', col('Route_3_Label').cast(IntegerType()))\\\n            .withColumn('Route_4_Label', col('Route_4_Label').cast(IntegerType()))\\\n            .withColumn('Route_5_Label', col('Route_5_Label').cast(IntegerType()))","59d5591b":"df.select('Route_1_Label','Route_2_Label','Route_3_Label','Route_4_Label','Route_5_Label').show()","7a8d7013":"df.printSchema()","29a0e2d4":"df.select(countDistinct('Total_Stops')).show()","bd4e5a4c":"df.select('Total_Stops').distinct().collect()","c11be77a":"df.groupBy('Total_Stops').count().alias('Count').sort(col('Count').desc()).show()","9be5d797":"plt.figure(figsize=(15,8));\nsns.catplot(y='Price',x='Total_Stops',data=data.sort_values('Price',ascending=False),kind='boxen');\nplt.xticks(rotation = 45);","9e810b43":"df = df.withColumn('Total_Stops',when(col('Total_Stops')=='1 stop',1)\n                                                    .when(col('Total_Stops')=='2 stops',2)\n                                                    .when(col('Total_Stops')=='3 stops',3)\n                                                    .when(col('Total_Stops')=='4 stops',4)\n                                                    .otherwise(0))","696ee8af":"df.select('Total_Stops').show()","ce4abb7a":"df.printSchema()","75bc7ad0":"def plot(df,col):\n    fig,(ax1,ax2)=plt.subplots(2,1)\n    sns.distplot(df[col],ax=ax1)\n    sns.boxplot(df[col],ax=ax2)","4bf2603d":"dataPlot = df.toPandas()\nplt.figure(figsize=(30,20));\nplot(df.toPandas(),'Price');","b3f5978a":"dataPlot['Price']=np.where(dataPlot['Price']>=40000,dataPlot['Price'].mean(),dataPlot['Price'])","0464bdd3":"df = df.withColumn('Price', \n              F.when((df['Price'] >=40000),\n              F.round(F.lit(df.select(F.mean(F.col('Price')).alias('mean')).collect()[0]['mean'])).cast('Integer')).otherwise(F.col('Price')))","a1aa70cb":"plt.figure(figsize=(30,20));\nplot(dataPlot,'Price') ; ","95fcb9c2":"# Split data to Data Train and Data Test \n(trainDF, testDF) = df.randomSplit([.8, .2], seed=1)","1e09a6c1":"from pyspark.ml.feature import VectorAssembler\n\nassembler = VectorAssembler(inputCols=['Total_Stops', 'Route_1_Label', 'Route_2_Label', 'Route_3_Label', 'Route_4_Label', \n                                       'Route_5_Label','Air India', 'GoAir', 'IndiGo', 'Jet Airways', 'Jet Airways Business',\n                                       'Multiple carriers', 'Multiple carriers Premium economy', 'SpiceJet',\n                                       'Trujet', 'Vistara', 'Vistara Premium economy','Kolkata_Des','Delhi_Des',\n                                       'Cochin_Des','New Delhi_Des','Hyderabad_Des','Chennai_Sour','Mumbai_Sour','Kolkata_Sour',\n                                       'Delhi_Sour', 'Journey_Day', 'Journey_Month', 'Dep_Hour',\n                                       'Dep_Minute', 'Arrival_Hour', 'Arrival_Minute',\n                                       'Duration_Hour', 'Duration_Minute'], outputCol='features') \nassembler_train = assembler.setHandleInvalid(\"skip\").transform(trainDF)\nfinal_train = assembler_train.select('features','Price')\nfinal_train.show(3)","283bf0ac":"from pyspark.ml import Pipeline\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.ml.feature import StringIndexer, VectorIndexer, IndexToString","c01e45c7":"from pyspark.ml.regression import RandomForestRegressor\nrfr = RandomForestRegressor(featuresCol = 'features', labelCol='Price', maxDepth=5, numTrees=100)","ac89660e":"from pyspark.ml.regression import DecisionTreeRegressor\ndt = DecisionTreeRegressor(featuresCol = 'features', labelCol='Price')","82aaeb58":"from pyspark.ml.regression import GBTRegressor\ngbt = GBTRegressor(featuresCol = 'features', labelCol='Price')","c89edc4c":"from pyspark.ml.regression import LinearRegression\nlr = LinearRegression(featuresCol = 'features', labelCol='Price')","2ae39638":"from pyspark.ml.evaluation import RegressionEvaluator\nstages_ = [dt, rfr, gbt, lr]","25df9ef5":"for stage in stages_:\n    \n    #build pipeline for each method\n    pipeline = Pipeline(stages=[assembler, stage])\n\n    # fit model\n    #stage.setMaxBins(40)\n\n    model = pipeline.fit(trainDF)\n    \n    # predict and evaluate model\n\n    predictions = model.transform(testDF)\n\n    predictions.select(\"prediction\",\"Price\", \"features\").show(5)\n\n    evaluator = RegressionEvaluator(labelCol=\"Price\", predictionCol=\"prediction\", metricName=\"rmse\")\n\n    # RMSE\n    rmse = evaluator.evaluate(predictions)\n    print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n\n    # R squared\n    r2 = evaluator.evaluate(predictions, {evaluator.metricName: \"r2\"})\n    print(\"R Squared (R^2) on test data = %g\" % r2)","d42d996c":"maxDepth = []\nfor i in range(1,10):\n  maxDepth.append(i)","bae4c7b5":"from pyspark.ml.tuning import CrossValidator\nfrom pyspark.ml.tuning import ParamGridBuilder\n\nparamGrid_dt = (ParamGridBuilder().addGrid(dt.maxDepth, maxDepth).build())\n# evaluate model by R2\nevaluator = RegressionEvaluator(labelCol=\"Price\", predictionCol=\"prediction\", metricName='rmse')\n\npipeline = Pipeline(stages=[assembler, dt])\n\ncv = CrossValidator(estimator=pipeline,evaluator = evaluator,\n                    estimatorParamMaps = paramGrid_dt,\n                    numFolds=3,seed=42)\n  \n# fit on TrainDF\ndt.setMaxBins(40)\n\nModel = cv.fit(trainDF)\n\nprint(pd.DataFrame(list(zip(Model.getEstimatorParamMaps(), Model.avgMetrics)) ,\n                     columns=['Regression','RMSE']).sort_values(by=\"RMSE\"))","04ef620f":"from pyspark.ml.tuning import CrossValidator\nfrom pyspark.ml.tuning import ParamGridBuilder\n\nparamGrid_rfr = ParamGridBuilder().addGrid(rfr.numTrees, [10,100]) \\\n    .addGrid(rfr.maxDepth, maxDepth) \\\n    .build()\n# evaluate model by R2\nevaluator = RegressionEvaluator(labelCol=\"Price\", predictionCol=\"prediction\", metricName='rmse')\n\npipeline = Pipeline(stages=[assembler, rfr])\n\ncv = CrossValidator(estimator=pipeline,evaluator = evaluator,\n                    estimatorParamMaps = paramGrid_rfr,\n                    numFolds=3,seed=42)\n  \n# fit on TrainDF\nrfr.setMaxBins(40)\n\nModel = cv.fit(trainDF)\n\nprint(pd.DataFrame(list(zip(Model.getEstimatorParamMaps(), Model.avgMetrics)) ,\n                     columns=['Regression','RMSE']).sort_values(by=\"RMSE\"))","7432e402":"from pyspark.ml.tuning import CrossValidator\nfrom pyspark.ml.tuning import ParamGridBuilder\n\nparamGrid_lr = ParamGridBuilder().addGrid(lr.regParam, [0.1, 0.01]).addGrid(lr.elasticNetParam, [0, 1]).build()\n# evaluate model by R2\nevaluator = RegressionEvaluator(labelCol=\"Price\", predictionCol=\"prediction\", metricName='rmse')\n\npipeline = Pipeline(stages=[assembler, lr])\n\ncv = CrossValidator(estimator=pipeline,evaluator = evaluator,\n                    estimatorParamMaps = paramGrid_lr,\n                    numFolds=3,seed=42)\n  \n# fit on TrainDF\n\nModel = cv.fit(trainDF)\n\nprint(pd.DataFrame(list(zip(Model.getEstimatorParamMaps(), Model.avgMetrics)) ,\n                     columns=['Regression','RMSE']).sort_values(by=\"RMSE\"))","538be039":"from pyspark.ml.tuning import CrossValidator\nfrom pyspark.ml.tuning import ParamGridBuilder\n\nparamGrid_gbt = (ParamGridBuilder().addGrid(gbt.maxDepth,maxDepth).addGrid(gbt.maxIter, [10, 100]).build())\n    \n# evaluate model by R2\nevaluator_gbt = RegressionEvaluator(labelCol=\"Price\", predictionCol=\"prediction\", metricName='rmse')\n\npipeline = Pipeline(stages=[assembler, gbt])\n\ncv = CrossValidator(estimator=pipeline,evaluator = evaluator_gbt,\n                    estimatorParamMaps = paramGrid_gbt,\n                    numFolds=3,\n                    parallelism=4, seed=42)\n  \n# fit on TrainDF\ngbt.setMaxBins(40)\n\nModel = cv.fit(trainDF)\n\nprint(pd.DataFrame(list(zip(Model.getEstimatorParamMaps(), Model.avgMetrics)) ,\n                     columns=['Regression','RMSE']).sort_values(by=\"RMSE\"))","538ecf4a":"bestPipeline = Model.bestModel \nbestModel = bestPipeline.stages[1]","3b969204":"print('numTrees - ', bestModel.getNumTrees)\nprint('maxDepth - ', bestModel.getOrDefault('maxDepth'))","9fdee7e7":"rmse = Model.getEvaluator().evaluate(Model.transform(testDF))\nPred = Model.transform(df)\nResult = Pred.toPandas()\nplt.plot(Result.Price, Result.prediction, 'go')\nplt.xlabel('Price')\nplt.ylabel('Prediction')\nplt.suptitle(\"Model Performance RMSE: %f\" % rmse)\nplt.show()","c360d67a":"importances = bestModel.featureImportances\nx_values = list(range(len(importances)))\nplt.figure(figsize=(20,10));\nplt.bar(x_values, importances, orientation = 'vertical')\nfeature_list = ['Total_Stops', 'Route_1_Label', 'Route_2_Label', 'Route_3_Label', 'Route_4_Label', \n                                       'Route_5_Label','Air India', 'GoAir', 'IndiGo', 'Jet Airways', 'Jet Airways Business',\n                                       'Multiple carriers', 'Multiple carriers Premium economy', 'SpiceJet',\n                                       'Trujet', 'Vistara', 'Vistara Premium economy','Kolkata_Des','Delhi_Des',\n                                       'Cochin_Des','New Delhi_Des','Hyderabad_Des','Chennai_Sour','Mumbai_Sour','Kolkata_Sour',\n                                       'Delhi_Sour', 'Journey_Day', 'Journey_Month', 'Dep_Hour',\n                                       'Dep_Minute', 'Arrival_Hour', 'Arrival_Minute',\n                                       'Duration_Hour', 'Duration_Minute']\nplt.xticks(x_values, feature_list, rotation=90)\nplt.ylabel('Importance')\nplt.xlabel('Feature')\nplt.title('Feature Importances');","9c1338c3":"featuresDF = pd.DataFrame(list(zip(assembler.getInputCols(), bestModel.featureImportances)), \n                          columns=[\"feature\", \"importance\"])","abbd6393":"featuresDF.sort_values([\"importance\"], ascending=False)","5036078f":"## Handling Categorical Data","5c19261b":"## Outlier Detection","2016b916":"#### Handle Dep_Time column\n\n\n\n\n\n\n","aa5610b6":"### Gradient booted tree","913e3680":"### Random forest ","70c52a3d":"#### Handle Date_of_Journey column","796e4327":"#### Handle Total_Stops column","8f53f373":"### Decision tree","87798cc4":"## Hyperparameter tuning","5346e181":"## Install pyspark","5eb27142":"### Handle Arrival_Time column","05717734":"#### Handle Duration column","aba7941e":"## Import dataset","6eacf79f":"#### Handle Source column","08527970":"## Build model and pipeline","bc49b13a":"#### Check null values and remove them","7e1d090f":"#### Handle Airline column","136f9d39":"#### Handle Destination column","11f74384":"#### Handle Route column","da217cc0":"## Handle Number Data","29b5d3c4":"### Linear regression"}}