{"cell_type":{"e83d07a1":"code","8dd00d59":"code","afa2e806":"code","fcdd7ef0":"code","4164847e":"code","a8c9e4e5":"code","41fa534b":"code","118a4469":"code","82e27a4e":"code","c526b719":"code","6636c179":"code","d4efae11":"code","288ab354":"code","6ed107aa":"code","580de15d":"code","80a9e699":"markdown","d318bc4c":"markdown","47ca0111":"markdown","f40c3da3":"markdown","99ac0323":"markdown","3bad16c1":"markdown","2a66c1b5":"markdown","3c3d0a38":"markdown","0fb3d85e":"markdown","aa6d4e33":"markdown","794e7387":"markdown","fd010d99":"markdown","c8030e67":"markdown","8d80feb9":"markdown","5da89ae9":"markdown","d8294a90":"markdown","0cd83d06":"markdown","354603b2":"markdown"},"source":{"e83d07a1":"import pandas as pd","8dd00d59":"# Load data\nenergy = pd.read_csv(\"\/kaggle\/input\/buildingdatagenomeproject2\/electricity.csv\", parse_dates=[\"timestamp\"])\nmetadata = pd.read_csv(\"\/kaggle\/input\/buildingdatagenomeproject2\/metadata.csv\")\nweather = pd.read_csv(\"\/kaggle\/input\/buildingdatagenomeproject2\/weather.csv\", parse_dates=[\"timestamp\"])","afa2e806":"# Metadata\nmetadata = metadata.loc[metadata.site_id == \"Panther\"]\n\n# Checkout the data\nmetadata.head()","fcdd7ef0":"metadata.info()","4164847e":"# Filter by columns\nmetadata = metadata[[\"building_id\", \"site_id\", \"primaryspaceusage\", \"sqm\"]]\n\n# Check it out\nmetadata.head()","a8c9e4e5":"# Weather\nweather = weather.loc[weather.site_id == \"Panther\"]\n\n# Checkout the data\nweather.head()","41fa534b":"# Check the data\nenergy.head()","118a4469":"# Check the columns\nenergy.columns","82e27a4e":"# This means: for each column in the columns present in energy data set, return tha ones that contains \"Panther\"\npanther_cols = [col for col in energy.columns if \"Panther\" in col]\n\n# Check them out\npanther_cols","c526b719":"panther_cols = [\"timestamp\"] + panther_cols","6636c179":"# Pass the list to filter columns\nenergy = energy[panther_cols]\n\n# Check it out\nenergy.head()","d4efae11":"# Melt\nenergy = energy.melt(id_vars=\"timestamp\", var_name=\"building_id\", value_name=\"meter_reading\")\n\n# Check it out\nenergy.head()","288ab354":"# Merge\nenergy = pd.merge(energy, metadata, how=\"left\", on=\"building_id\")\n\n# Check it out\nenergy.head()","6ed107aa":"# Merge\nenergy = pd.merge(energy, weather, how=\"left\", on=[\"timestamp\",\"site_id\"])\n\n# Check it out\nenergy.head()","580de15d":"def transform_dataset(metadata_path, weather_path, energy_path, site_id):\n    \"\"\"\n    metadata_path: path to metadata data set\n    weather_path: path to weather data set\n    energy_path: path to energy data set\n    site_id: selected site id\n    \"\"\"\n    # Load data\n    metadata = pd.read_csv(metadata_path)\n    weather = pd.read_csv(weather_path, parse_dates=[\"timestamp\"])\n    energy = pd.read_csv(energy_path, parse_dates=[\"timestamp\"])\n    \n    # Filter\n    metadata = metadata.loc[metadata.site_id == site_id, [\"building_id\", \"site_id\", \"primaryspaceusage\", \"sqm\"]]\n    weather = weather.loc[weather.site_id == site_id]\n    cols = [\"timestamp\"] + [col for col in energy.columns if site_id in col]\n    energy = energy[cols]\n    \n    # Melt\n    energy = energy.melt(id_vars=\"timestamp\", var_name=\"building_id\", value_name=\"meter_reading\")\n    \n    # Merge\n    energy = pd.merge(energy, metadata, how=\"left\", on=\"building_id\")\n    energy = pd.merge(energy, weather, how=\"left\", on=[\"timestamp\",\"site_id\"])\n    \n    return energy","80a9e699":"## Melt\nTime to melt! You can tell this method which column will be your id (by default will use the index) and all the remaining columns will be transformed in a variable with a value asociated. If you don't explicitly pass `var_name` and `value_name` the default name of the columns are *variable* and *value*.\n\nIt's not easy to explain this process in words, it's better to see it working:","d318bc4c":"# (Optional) A function to do it all\nThis part is optional. We are going to write a function that follows all the steps we performed here. This function will be used in the following notebooks.","47ca0111":"And the second steps is to merge the data set obtained, `energy`, with the `weather` data on the common columna `site_id` and `timestamp`:","f40c3da3":"And finally, we filter the columns passing the list we recently obtained:","99ac0323":"## Metadata\nWith the method [*loc*](https:\/\/pandas.pydata.org\/docs\/reference\/api\/pandas.DataFrame.loc.html) we can acces the data in our dataframe by index or label. In this case, we are going to use the label, which is the column name. We want to filter all the rows that have the value *Panther* in the `site_id` column.","3bad16c1":"## Weather\nSame process will be followed for weather data. We are filtering all the rows that belong to site *Panther*.","2a66c1b5":"# Filter data\nOnce the data is loaded, we have to filter the part we want. We are going to filter only the site **Panther**. We are going to use [pandas selection methods](https:\/\/www.kaggle.com\/residentmario\/indexing-selecting-assigning), filtering by a condition on one of the columns.","3c3d0a38":"Before keeping on let's take a minute to inspect this data. Remember you can use the method [*info*](https:\/\/pandas.pydata.org\/docs\/reference\/api\/pandas.DataFrame.info.html) to get a summary of the data types, null values and number of rows.","0fb3d85e":"We need to filter all the columns that contains the word *Panther*. The logic to find them would be:\n\n- Loop over each column of our `energy` dataset\n- Check if the column contains the word *Panther*\n- If `True`, select it. If `False`, ignore it\n\nSounds like a long process, but we can easily achieve it using [list comprehension](https:\/\/www.kaggle.com\/colinmorris\/loops-and-list-comprehensions):","aa6d4e33":"# Introduction\n\nThis is a serie of notebooks thar should be visit in order, they are all linked in the table of content. In this notebook we are going to load the data and transform it to be used in a predictive model in the following notebooks. Before going on with this notebook, make sure you have finished these courses:\n\n- [Python](https:\/\/www.kaggle.com\/learn\/python)\n- [Pandas](https:\/\/www.kaggle.com\/learn\/pandas)\n\n### Content table\n- **Preprocessing 1: Data Transformation** (you are here)\n    - [Load data](#Load-data)\n    - [Filter data](#Filter-data)\n       - [Metadata](#Metadata)\n       - [Weather](#Weather)\n       - [Energy](#Energy)\n    - [Transform data](#Transform-data)\n       - [Melt](#Melt)\n       - [Merge](#Merge)\n- [Preprocessing 2: Encoding Categorical Variables](https:\/\/www.kaggle.com\/ponybiam\/preprocessing-2-encoding-categorical-variables\/)\n- [Preprocessing 3: Handling Missing Values](https:\/\/www.kaggle.com\/ponybiam\/preprocessing-3-handling-missing-values) \n- [Feature engineering 1: Simple Features](https:\/\/www.kaggle.com\/ponybiam\/feature-engineering-1-simple-features)\n- [Feature engineering 2: Clustering & PCA](https:\/\/www.kaggle.com\/ponybiam\/feature-engineering-2-clustering-pca)\n- [Feature engineering 3: Target Encoding](https:\/\/www.kaggle.com\/ponybiam\/feature-engineering-3-target-encoding)","794e7387":"We have a lot of columns with only null values. Let's just keep the columns that seems usefull for us, we will focus on:`building_id`, `site_id`, `primaryspaceusage` and `sqm`. Let's select them.\n\nWhen selecting several columns you can use this sintax:\n```\nfiltered_dataframe = your_dataframe[your_list]\n```","fd010d99":"And don't forget to **include the timestamp column!**. You can \"sum\" lists to add new elements, like this:","c8030e67":"## Merge\nAnd now is time to merge. We will need:\n\n- Two dataframes\n- A common column, present in both dataframe, to merge over\n- How to join\n\nHere is illustrated how two datasets can be joined ([image source](https:\/\/data36.com\/pandas-tutorial-3-important-data-formatting-methods-merge-sort-reset_index-fillna\/)):\n\n![joining](https:\/\/data36.com\/wp-content\/uploads\/2018\/08\/4-pandas-merge-inner-outer-left-right-768x579.png)\n\nWe want **a left join on energy data**: this way we will be adding the metadata and weather columns to our energy readings. We are doing it in two steps. First, we merge `energy` and `metadata` on the common column `building_id`:","8d80feb9":"# Load data\nWe are going to work with **electricity** data and only with the site **Panther**. First we load our datasets:","5da89ae9":"## Energy\nIn energy data we have one column per building: here we are not filtering rows, we are filtering columns. As we did with `metadata`, we can select the columns we want by passing a list of columns\n\n```\nfiltered_dataframe = your_dataframe[your_list]\n```\n\nBut first, we have to find those columns, nobody wants to write them all down.","d8294a90":"# Notebook goal\nThe goal of this notebook is to transform the data to be used in a predictive model (to be used in the following notebooks). Here will be shown only one of the many possibilities in machine learning, feel free to experiment and play around with the data on your own. We will be focusing on the techniques and not on the model performance.","0cd83d06":"Notice that we can tell pandas which are the date\/time columns during the file reading using the option `parse_dates`.","354603b2":"# Transform data\nNext step is to **melt** our energy table: we want our energy data to  be a table having a column for the `building_id` and one for the `meter_reading`. Instead of having a columne per building, we want them as rows. Dont' worry, [there is a pandas method for this](https:\/\/pandas.pydata.org\/docs\/reference\/api\/pandas.melt.html); is called *melting* and is widely used."}}