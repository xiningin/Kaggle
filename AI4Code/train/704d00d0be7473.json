{"cell_type":{"8bc923a2":"code","a1b13b34":"code","78634cf6":"code","aa429b11":"code","6244d9b8":"code","c964ab53":"code","f64b19ec":"code","07c3c17d":"code","bef66d3e":"code","a7794249":"code","773dd91f":"code","ae05d149":"code","9b9d27d6":"code","2accc0ce":"code","e77354a9":"code","098522c2":"code","377292b4":"code","d747ec7b":"code","99c328d6":"code","74002830":"code","f079bf9d":"code","76380005":"code","f1ec9db5":"code","2951c7a4":"code","f80e116f":"code","2f9db54e":"code","1cd5da6f":"code","6a2a482b":"code","2f9999c3":"code","09cbe98d":"code","8ef45733":"code","5f469051":"code","a8a2656f":"code","da8036d6":"code","d122c6a7":"code","9be0c355":"code","5de26d0e":"code","a26a01b8":"code","f25e8199":"code","a14c0638":"code","ee4a980d":"code","5dcf040f":"code","3d459d63":"code","622e9465":"code","37452755":"code","af59efaf":"code","57082e5f":"code","7b206f5a":"code","0c986339":"code","d1225be5":"code","a938fce2":"code","495841d9":"code","b146094f":"code","ba74202c":"code","becfd21e":"code","9e0f7359":"code","1b1e386f":"markdown","1a3f358b":"markdown","d1ef40a8":"markdown","70c94bc8":"markdown","f548015f":"markdown","2fd77070":"markdown","369529a0":"markdown","219d9289":"markdown","6672ab57":"markdown","cf016693":"markdown","d064c5c8":"markdown","80818e41":"markdown","d2153114":"markdown","6a3404c3":"markdown","0249099b":"markdown","8f58376d":"markdown","b5ebbc27":"markdown","4164cf57":"markdown","04238c92":"markdown","3c016d44":"markdown"},"source":{"8bc923a2":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","a1b13b34":"trainData = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")","78634cf6":"testData = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","aa429b11":"sampleData = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')","6244d9b8":"trainData.head()","c964ab53":"trainData.info()","f64b19ec":"sns.distplot(trainData.SalePrice)\nplt.show()","07c3c17d":"SalePrice = trainData.SalePrice","bef66d3e":"SalePrice_log = np.log(SalePrice)","a7794249":"sns.distplot(SalePrice_log)\nplt.show()","773dd91f":"numeric_var = trainData.select_dtypes(exclude='object')","ae05d149":"trainData.drop(columns = ['SalePrice']).corrwith(SalePrice,axis=0).plot.bar(figsize = (12,12))","9b9d27d6":"plt.figure(figsize=(12,12))\nfig = sns.heatmap(trainData.corr(), linewidth = 0.3)","2accc0ce":"train_id = trainData.Id\ntest_id = testData.Id","e77354a9":"trainData.set_index('Id')\ntestData.set_index('Id')","098522c2":"data = pd.concat([trainData, testData])","377292b4":"with pd.option_context('display.max_rows',None,'display.max_columns',None):\n    display(data.isnull().sum())","d747ec7b":"data.drop(columns=['Alley','PoolQC','Fence','MiscFeature'], inplace = True)","99c328d6":"num_col = data.select_dtypes(exclude='object').columns\nobj_cat = data.select_dtypes(include='object').columns","74002830":"for i in num_col:\n    data[i] = data[i].fillna(data[i].mean())","f079bf9d":"for i in obj_cat:\n    data[i] = data[i].fillna(data[i].mode()[0])","76380005":"with pd.option_context('display.max_rows',None,'display.max_columns',None):\n    display(data.isnull().sum())","f1ec9db5":"data.drop(columns = ['SalePrice'], inplace = True)","2951c7a4":"data.drop(['GrLivArea', '1stFlrSF', 'OverallQual', 'GarageCars'], axis=1, inplace=True)","f80e116f":"data = data.set_index('Id')","2f9db54e":"data","1cd5da6f":"data2 = data.copy(deep=True)","6a2a482b":"obj_col = data2.select_dtypes(include='object').columns","2f9999c3":"data_dummy = pd.get_dummies(data2, columns = obj_col, drop_first=True)","09cbe98d":"train = data_dummy.iloc[:train_id.shape[0],:]\ntest = data_dummy.iloc[train_id.shape[0]:,:]","8ef45733":"train","5f469051":"test","a8a2656f":"from sklearn.preprocessing import StandardScaler","da8036d6":"sc = StandardScaler()","d122c6a7":"x = pd.DataFrame(sc.fit_transform(train), columns = train.columns.values)\nx_test = pd.DataFrame(sc.transform(test), columns = test.columns.values)","9be0c355":"x","5de26d0e":"from sklearn.model_selection import train_test_split\n\nx_train,x_test_1, y_train, y_test_1 = train_test_split(x,SalePrice_log,test_size = 0.2, random_state = 0)","a26a01b8":"from sklearn.ensemble import RandomForestRegressor\n\nregressor = RandomForestRegressor()","f25e8199":"regressor.fit(x_train,y_train)","a14c0638":"y_pred= regressor.predict(x_test_1)","ee4a980d":"from sklearn.metrics import r2_score,mean_squared_error","5dcf040f":"r2_score(y_test_1,y_pred)","3d459d63":"mean_squared_error(y_test_1,y_pred)","622e9465":"param = {'max_depth': [3,5,8],\n        'n_estimators': [100,300,500],\n        'criterion': ['mse', 'mae'],\n        'max_features': ['sqrt','log2','auto']}","37452755":"from sklearn.model_selection import RandomizedSearchCV","af59efaf":"regressor = RandomForestRegressor()\nrandom = RandomizedSearchCV(estimator = regressor, param_distributions=param, n_iter = 5,scoring='neg_mean_squared_error',n_jobs=-1,cv=5)","57082e5f":"random.fit(x_train,y_train)","7b206f5a":"random.best_params_","0c986339":"regressor2 = RandomForestRegressor(n_estimators=100,\n max_features='auto',\n max_depth=8,\n criterion='mse')","d1225be5":"regressor2.fit(x_train,y_train)","a938fce2":"y_pred = regressor2.predict(x_test_1)","495841d9":"r2_score(y_test_1,y_pred)","b146094f":"prediction = regressor.predict(x_test)","ba74202c":"pred = np.exp(prediction)","becfd21e":"Id = pd.DataFrame(test_id, columns = ['Id'])\n\npredi = pd.DataFrame(pred, columns = ['SalePrice'])","9e0f7359":"result = pd.concat([Id,predi],axis = 1)","1b1e386f":"Seems pretty good","1a3f358b":"Also lets drop the columns with high correlation","d1ef40a8":"# Feature scaling","70c94bc8":"Also we can also check which variables have high correlation amongst each other so that we can drop that variable.\n","f548015f":"Let's get the dummies","2fd77070":"The previous model was better:p\nSo we'll use that one","369529a0":"Let's see if we can improve our model by changing the parameters.","219d9289":"As we can see there are a lot of null values.\nWe need to take care of that either by deleting completely or by replacing the null values with the mean or mode of that column.\nBefore we do that let's explore our Dependent Variable - SalePrice","6672ab57":"# So this is it .\nAs I said it is a simple model with basic cleaning techniques.\n# Looking forward to learn through your comments.\n","cf016693":"First Things First ..... importing the libraries","d064c5c8":"# Data Cleaning\nLet's check the  null values","80818e41":"We can see that variables OverallCond,GrlivArea,GarageCars(for some reason) have higher correlation with the price as compare to others.\nIts always good to know.\nWe can consider dropping these variables.","d2153114":"# Training the model\nHere I'm going to use Random Forest","6a3404c3":"Looks good to me","0249099b":"Okay let's split the data back into train and test","8f58376d":"# Hello Community!\nThis is my attempt at predicting the house prices using Random Forest regression and some basic cleaning techniques.\nMy very frist notbook so it would be really helpful to know if there is any way to improve the model and please do correct me if I've gone wrong somewhere. I would like to learn:)","b5ebbc27":"Read the Data","4164cf57":"# Data Exploration\nNow that the data has been loaded, let's explore the data","04238c92":"Since the distribution is not normal we'll take the log.","3c016d44":"Okay it looks much better"}}