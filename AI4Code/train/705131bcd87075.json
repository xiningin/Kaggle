{"cell_type":{"0842a679":"code","03a74040":"code","523f2731":"code","ad8d5a95":"code","d75ffc6d":"code","e3676ee6":"code","94623606":"code","d06fb208":"code","d89ab2f1":"code","d12fc2ba":"code","d3565ac4":"code","e0b26f51":"code","596194bd":"code","a5a6eff3":"code","c42302c9":"code","5620802c":"code","a7d91b5d":"code","94f26291":"code","42c2af81":"code","38f631f2":"code","18312a4e":"code","80aa0937":"code","fb5efc6c":"markdown","465d6974":"markdown","b29520f0":"markdown","e8123e67":"markdown","d192f5ef":"markdown","d78e23a8":"markdown","90b31072":"markdown","bb419393":"markdown","ba5f77d3":"markdown","a54a9f12":"markdown","0c818010":"markdown","c802e563":"markdown","69db9aae":"markdown","70242cba":"markdown","a3a34bf9":"markdown","e2d4a067":"markdown","e5d35194":"markdown","3fc8d7b4":"markdown"},"source":{"0842a679":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# coding utilities\n%matplotlib inline\nplt.style.use('fivethirtyeight')\nplt.rcParams[\"figure.figsize\"] = (8, 6)\n%config IPCompleter.use_jedi = False\n\nimport folium\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score, mean_squared_error","03a74040":"in_file = '..\/input\/weatherww2\/Summary of Weather.csv'\nloc_file = '..\/input\/weatherww2\/Weather Station Locations.csv'\n\ndf_loc = pd.read_csv(loc_file)\ndf_loc.head()","523f2731":"# Create the map\nmp = folium.Map(width=800,height=500,tiles='CartoDB positron', zoom_start= 5)\n\n# Add points to the map\nfor idx, row in df_loc.iterrows():\n    folium.Marker(location = [row['Latitude'], row['Longitude']]).add_to(mp)\n    \n# Create title\ntitle_html = '''\n             <h3 align=\"left\" style=\"font-size:28px\"><b>{}<\/b><\/h3>\n             '''.format(\"Overview of Stations\")   \n# Add title\nmp.get_root().html.add_child(folium.Element(title_html))\n\nmp\n","ad8d5a95":"df_tot = pd.read_csv(in_file, parse_dates = [1], low_memory=False)\ndf_tot.head()","d75ffc6d":"df_tot[[\"STA\", \"MeanTemp\"]].describe()","e3676ee6":"df_tot[[\"STA\", \"MeanTemp\"]].isna().value_counts()","94623606":"mask = df_loc.WBAN == 22508\ndf_loc[mask]","d06fb208":"loc = [21.483333,-158.05]\n\nstation = folium.Map(location=loc, width=800,height=500,tiles='CartoDB positron', zoom_start= 10)\nfolium.Marker(location= loc).add_to(station)\nstation\n\ntitle_html = '''\n             <h3 align=\"left\" style=\"font-size:28px\"><b>{}<\/b><\/h3>\n             '''.format(\"Station at Honolulu\")   \n\nstation.get_root().html.add_child(folium.Element(title_html))\nstation","d89ab2f1":"# Create a new dataframe only with relevant information\nint_cols = ['Date','MeanTemp']\nmask_22508 = df_tot[\"STA\"] == 22508\ndf = df_tot.loc[mask_22508, int_cols]\n\ndf.head()","d12fc2ba":"df.dtypes","d3565ac4":"plt.figure(figsize = (20,5))\nplt.plot(df.Date, df.MeanTemp, linewidth = 0.8);\n\ntitle = 'Temprature cycle'\nx_label = 'time'\ny_label = 'Temprature (\u00b0C)'\n\nplt.suptitle(title, fontsize = 'xx-large')\nplt.xlabel(x_label)\nplt.ylabel(y_label)\nplt.show()","e0b26f51":"# Splitting the data set\nmask = df.Date >= '1945-01-01'\ntest_df = df[mask]\ntrain_df = df[~mask]\n\nprint(test_df.head())\nprint(train_df.head())","596194bd":"# Aggregate on Month and date to find the mean\nmean_MeanTemp = train_df.groupby([train_df.Date.dt.month, train_df.Date.dt.day])[\"MeanTemp\"].mean()\n\n# Create a new date column without 29 Feb\nd = [(f'1945-{a[0]}-{a[1]}') for a in mean_MeanTemp.index if a[0] != 2 or a[1] != 29]\ndate = pd.to_datetime(d)\n\n# Attach mean values with related date\nmean_MeanTemp.index.names = [\"Month\", \"Day\"]\nmean_MeanTemp = mean_MeanTemp.reset_index()\nmask = (mean_MeanTemp.Month == 2) & (mean_MeanTemp.Day == 29)\nmean_MeanTemp = mean_MeanTemp[~mask]\nmean_MeanTemp[\"Date\"] = date\n\n# Remove columns created by group by\nmean_MeanTemp.drop([\"Month\", \"Day\"], axis = 1, inplace = True)\n# Standardize\nmean_MeanTemp.columns = [\"avg_MeanTemp\", \"Date\"]\nmean_MeanTemp = mean_MeanTemp[[\"Date\", \"avg_MeanTemp\"]]\nmean_MeanTemp","a5a6eff3":"def model_evalutation(y_true, y_pred):\n    \"\"\" This function produces a short report for regression results\n    \"\"\"\n    r2 = r2_score(y_true, y_pred)\n    mse = mean_squared_error(y_true, y_pred)\n    rmse = np.sqrt(mse)\n    rep = f\"\"\"\n    R2 score: {r2:.2f}\n    MSE:      {mse:.2f}\n    RMSE :    {rmse:.2f}\n    \"\"\"\n    print(rep)\n    \n    return","c42302c9":"# Truth values\ny_true = test_df.MeanTemp.values\n# Naive predictions\ny_naive = mean_MeanTemp.avg_MeanTemp.values\n\nmodel_evalutation(y_true, y_naive)","5620802c":"plt.figure(figsize = (16,4))\nplt.plot(mean_MeanTemp.Date, y_true, linewidth = 0.7,color = 'blue', label = \"True value\")\nplt.plot(mean_MeanTemp.Date, y_naive, linewidth = 0.7, color = 'black', label = \"Naive Prediction\")\n\nplt.legend(loc = \"upper left\")\n\ntitle = 'Naive Prediction of Temprature'\nx_label = 'time'\ny_label = 'Temprature (\u00b0C)'\n\nplt.suptitle(title, fontsize = 'xx-large')\nplt.xlabel(x_label)\nplt.ylabel(y_label)\nplt.show()","a7d91b5d":"from statsmodels.graphics.tsaplots import plot_pacf","94f26291":"plot_pacf(df.MeanTemp, lags=7)\n\nplt.xlabel(\"previous day n.\")\nplt.ylabel(\"correlation\")\nplt.show()","42c2af81":"def to_time_window(df, n):\n    \"\"\" This function creates a new Dataframe containing values from 'n' previous rows\n        First n rows of input dataframe are dropped as they contain missing values\n    \"\"\"\n    label_col = \"MeanTemp\"\n    data = pd.DataFrame(df.copy())\n    cols = []\n    \n    # add the lag of the target variable from current steps back up to n\n    for i in range(1, n+1):\n        new_col = f'day_ - {i}'\n        data[new_col] = data[label_col].shift(i)\n        cols.insert(0,new_col)\n\n    cols.insert(0, \"Date\")\n    cols.append(label_col)\n    \n    return data.dropna()[cols]\n\nX = to_time_window(df, 3)\nX","38f631f2":"mask = X.Date < '1945-01-01'\ndf_train = X[mask]\ndf_test = X[~mask]\n\ndf_test= df_test.drop(\"Date\",axis = 1)\ndf_train= df_train.drop(\"Date\",axis = 1)\n\ntarget = \"MeanTemp\"\nX_train = df_train.drop(target, axis = 1).values\nX_test = df_test.drop(target, axis = 1).values\n\ny_train = df_train[target].values\ny_test = df_test[target].values\n\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","18312a4e":"reg  = LinearRegression()\nreg.fit(X_train, y_train)\ny_pred = reg.predict(X_test)\nmodel_evalutation(y_test, y_pred)","80aa0937":"plt.figure(figsize = (20,6))\nplt.plot(mean_MeanTemp.Date, y_true, linewidth = 1.3, label = \"True value\")\nplt.plot(mean_MeanTemp.Date, y_pred, linewidth = 1.3,  label = \"LR Prediction\")\nplt.plot(mean_MeanTemp.Date, y_naive, linewidth = 0.7, color = 'grey' , label = \"Naive Prediction\")\n\n\n\nplt.legend(loc = \"upper left\")\ntitle = 'Predictions of Temperature'\nx_label = 'time'\ny_label = 'temperature (\u00b0C)'\n\nplt.suptitle(title, fontsize = 'xx-large')\nplt.xlabel(x_label)\nplt.ylabel(y_label)\nplt.show()\n\nerror = np.abs(y_test) - np.abs(y_pred)\n\nplt.figure(figsize = (20,3))\nplt.plot(mean_MeanTemp.Date, error, linewidth = 0.9, label = \"\")\nplt.axhline(np.mean(abs(error)), linewidth = 0.5,color = 'purple', label = \"Average\")\n\nplt.legend(loc = \"upper left\")\ntitle = 'Error in Predictions'\nx_label = 'time'\ny_label = 'temperature (\u00b0C)'\n\nplt.suptitle(title, fontsize = 'xx-large')\nplt.xlabel(x_label)\nplt.ylabel(y_label)\nplt.show()\n\n\nprint(f\"Average error is {np.mean(abs(error)):.2f} with Standard deviation of {np.std(abs(error)):.2f}\")","fb5efc6c":"To use ML models on time series we need to define two sets of variables:\n1. **Predictive or independent variables**\n2. **Target variable**  \n\nThe first ones are used to construct a structured representation of time series.  \nThey are computed from the values already observed from the series. They can also be the values themselves.  \nWe will use a similar strategy to build a features matrix from the training dataset.\nThis matrix includes values in a window of fixed-length T. Each row contains values of MeanTemp from T previous days. \nInstead, the target variable encodes a future event. In our case, it's the mean temperature of a given day.\nThe algorithm will be able to model the relationship between some already-seen temperature values and an upcoming behavior of the series. ","465d6974":"We split our data set into training and testing portions.  \nSince it is a time series, we cannot use conventional sample selection methods to split it.  \nAlthough sklearn provides modules to split time-series data, we will use another simple but effective method.  \nWe will train our models on data from 1940-1944 and predictions will be made on 1945.","b29520f0":"# Conclusions\n\nIn this report, we have seen that a simple linear regression model can perform better than baseline scores.  \nR2 score is improved by 0.16 and predictions are made with an RMS error of 0.87-degrees Celcius.  \n\nIn this experiment, we had true values for the whole year but in real life scenario, we need to update our model every day with the current day temperature.  \n\nLinear Regressor provides a good approximation but its predictions are somewhat lagged.  \nThe model takes at least one day to react to the current trend and so induces a non-zero error.  \nThis error is larger when the temperature difference w.r.t previous day is high.  \n**Although R2 Score is not very high, the average absolute error of 0.64 with the standard deviation is 0.58, might be acceptable values for\nour domain.**\n\n\n\n## Further improvements\nWe can enhance further by including information from past years.  \nFor example, we can include the temperature of the target day from past years, temperatures of previous days from past years.  \nFor this, we may require data from more past years.  \nWe can also use other Regression models to check if they are able to perform better.  Polynomial features can be used to check if the relation between previous days temprature with current day is non-linear.\n\nWith similar approach we can also predict other aspects of weather like minimum\\maximum temprature. humidity level and precipitation probability.","e8123e67":"# Linear Regression","d192f5ef":"# 2. Time Window","d78e23a8":"We will perform our analysis on a single station.  \nLuckily data on hand is clean and we can choose any station ID to perform this analysis.  \nIn the presence of nan values, we would have selected a station with fewer missing values.  \n\nWe choose a station with id 22508 to perform these analyses.  ","90b31072":"We divide our dataset into two train and test chunks.  \nThe model will be trained on the values from 1940-1944 and predictions will be made on 1945.","bb419393":"### Importing useful libraries and models","ba5f77d3":"In the first file we have information about different stations all around the globe.  \nLet's look at the map of all available stations.","a54a9f12":"We can use several naive solutions to set a baseline score.  \nOne possible approach is to calculate the mean value from the training dataset and use that as the prediction for a given day.","0c818010":"Finally, we can have a well-constructed form of time-series and we can build ML models for predictions.  \nWe will use a basic linear regression model to predict the target values.","c802e563":"### Importing the Data","69db9aae":"In the other file, we have weather information for each station.  \nSTA is the common attribute that can be used to merge these two datasets.  ","70242cba":"### Conclusion\n**It is clear from the results that even *naive* predictions are not so 'naive'.  \nThis approach makes predictions with an root mean squared error of around 1-degree Celcius.**\n\nIn the next section, we will try to further improve our predictions.","a3a34bf9":"# 1. Naive Solution","e2d4a067":"# Problem overview\n\nThe dataset contains information on weather conditions recorded on each day at various weather stations around the world.  \nThe time interval goes from 1940 till 1945.  \nThe dataset includes information about weather such as precipitation, snowfall, temperatures, wind.\n\n### Objective\nIn this report, we will perform a regression task of predicting average temperature for a given day.  \nOur task can be divided into these subsections:\n* A naive prediction to set the baseline scores.\n* Sliding window feature extraction and Regression Models.","e5d35194":"As expected, a long-term wave-like pattern is showing us that time series has a cycle of 1 year.","3fc8d7b4":"**From the partial auto-correlation function of mean temperature values, we can observe that values with a lag of one day are highly correlated with the target.**  \nIt is enough for us to create a time window of size 3 to get relevant features."}}