{"cell_type":{"30a86614":"code","64e6859c":"code","6b7dc243":"code","cc95b364":"code","604ef5c5":"code","19a78c4f":"code","6182cb42":"code","9a8911c9":"code","b53fdb04":"code","ec275c9a":"code","f7e4c890":"code","e9505af9":"code","1de91755":"code","5de93021":"code","8ca13a30":"code","dd9c7ce0":"code","2cc8d97b":"code","8db3d418":"code","12366429":"code","2be08f82":"code","77414db6":"code","b93e8149":"code","d94ac7d7":"code","739a61a5":"code","5173021a":"code","0264439d":"code","93da5257":"code","cbf3ada9":"code","f85938ab":"code","e73dddb7":"code","71b52511":"code","a6adb3ec":"code","26359eb0":"code","42f3b1d7":"code","441c1798":"markdown","8ee3bbd3":"markdown","d0765832":"markdown","17343bd7":"markdown","41b1f40a":"markdown","f7ed7237":"markdown","c5070c4e":"markdown","6e388578":"markdown","78f0a258":"markdown","f78b85b7":"markdown","2f4bb744":"markdown","56b23be8":"markdown","4aa5b689":"markdown","11e71efa":"markdown","d250698c":"markdown","ebae405c":"markdown","ffde5703":"markdown"},"source":{"30a86614":"%matplotlib inline\nimport torch\nimport torch.nn as nn\nimport pandas as pd\nimport numpy as np\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nfrom torch import autograd\nimport torch.nn.functional as F\n\nfrom torch.autograd import Variable\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import random_split\n\nimport matplotlib.pyplot as plt","64e6859c":"DATA_DIR = '..\/input\/fashionmnist'\n\n\nTRAIN_CSV = DATA_DIR + '\/fashion-mnist_train.csv'                       # Contains real labels for training images\nTEST_CSV = '\/kaggle\/input\/fashionmnist\/fashion-mnist_test.csv'   # Contains dummy labels for test image","6b7dc243":"class FashionMNIST(Dataset):\n    def __init__(self,  df, root_dir,transform=None):\n        self.df = df\n        self.transform = transform\n        self.root_dir = root_dir\n        self.labels = df.label.values\n        self.images = df.iloc[:, 1:].values.astype('uint8').reshape(-1, 28, 28)\n        \n    def __len__(self):\n        return len(self.df)    \n    \n    def __getitem__(self, idx):\n        label = self.labels[idx]\n        img = Image.fromarray(self.images[idx])\n        \n        if self.transform:\n            img = self.transform(img)\n            \n        return img, label\n        \n        ","cc95b364":"train_df = pd.read_csv(TRAIN_CSV)\ntest_df = pd.read_csv(TEST_CSV)\ntrain_df.head()","604ef5c5":"dataset = FashionMNIST(train_df,DATA_DIR)\ndataset[0][0]","19a78c4f":"transform = transforms.Compose([transforms.ToTensor()])\ndataset = FashionMNIST(train_df, DATA_DIR, transform=transform)\ntest_dataset = FashionMNIST(test_df, DATA_DIR, transform=transform)","6182cb42":"len(dataset)","9a8911c9":"val_size = 10000\ntrain_size = len(dataset) - val_size\ntrain_ds, val_ds = random_split(dataset, [train_size, val_size])\nlen(train_ds), len(val_ds)","b53fdb04":"batch_size=64\ntrain_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\nval_loader = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size*2, num_workers=4, pin_memory=True)","ec275c9a":"def show_batch(dl, invert=False):\n    for images, labels in dl:\n        fig, ax = plt.subplots(figsize=(16, 8))\n        ax.set_xticks([]); ax.set_yticks([])\n        data = 1-images if invert else images\n        ax.imshow(make_grid(data, nrow=16).permute(1, 2, 0))\n        break","f7e4c890":"show_batch(train_loader)","e9505af9":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))","1de91755":"class FashionMnistModelBase(nn.Module):\n    def training_step(self, batch):\n        images, targets = batch \n        out = self(images)                      \n        loss = F.cross_entropy(out, targets)      \n        return loss\n    \n    def validation_step(self, batch):\n        images, targets = batch \n        out = self(images)                           # Generate predictions\n        loss = F.cross_entropy(out, targets)  # Calculate loss\n        acc = accuracy(out, targets)\n        return {'val_loss': loss.detach(), 'val_acc': acc }\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_acc = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_acc).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch,result['train_loss'], result['val_loss'], result['val_acc']))","5de93021":"class FashionMnistModel(FashionMnistModelBase):\n    def __init__(self):\n        super().__init__()\n        self.network = nn.Sequential(\n            nn.Conv2d(1, 28, kernel_size=3, padding=1), #output 28 X 28 X 28\n            nn.ReLU(),\n            nn.Conv2d(28, 64, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 64 x 14 x 14\n\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 128 x 7 x 7\n\n            nn.Flatten(), \n            nn.Linear(128 * 7 * 7, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10))\n        \n    def forward(self, xb):\n        return self.network(xb)","8ca13a30":"#function to ensure that our code uses the GPU if available, and defaults to using the CPU if it isn't.\ndef get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \n# a function that can move data and model to a chosen device.    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\n\n#Finally, we define a DeviceDataLoader class to wrap our existing data loaders and move data to the selected device, \n#as a batches are accessed. Interestingly, we don't need to extend an existing class to create a PyTorch dataloader. \n#All we need is an __iter__ method to retrieve batches of data, and an __len__ method to get the number of batches.\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","dd9c7ce0":"device = get_default_device()\ndevice","2cc8d97b":"train_loader = DeviceDataLoader(train_loader, device)\nval_loader = DeviceDataLoader(val_loader, device)","8db3d418":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    torch.cuda.empty_cache()\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","12366429":"model = to_device(FashionMnistModel(), device)","2be08f82":"history = [evaluate(model, val_loader)]\nhistory","77414db6":"num_epochs = 10\nopt_func = torch.optim.Adam\nlr = 0.001\nhistory = fit(num_epochs, lr, model, train_loader, val_loader, opt_func)","b93e8149":"def plot_scores(history):\n#     scores = [x['val_score'] for x in history]\n    acc = [x['val_acc'] for x in history]\n    plt.plot(acc, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('acc')\n    plt.title('acc vs. No. of epochs');","d94ac7d7":"plot_scores(history)\n","739a61a5":"def plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');","5173021a":"plot_losses(history)\n","0264439d":"# actural item corresponding to each label\nitem = {0: 'T-shirt\/top', 1: 'Trouser', 2: 'Pullover', 3: 'Dress', 4: 'Coat',\n        5: 'Sandal', 6: 'Shirt', 7: 'Sneaker', 8: 'Bag', 9: 'Ankle boot'}","93da5257":"def show_sample(img, target, invert=True):\n        plt.imshow(img.squeeze())\n        print(img.squeeze().shape)\n        print('Labels:', item[target])","cbf3ada9":"def predict_single(image):\n    xb = image.unsqueeze(0)\n    xb = to_device(xb, device)\n    preds = model(xb)\n    prediction = preds[0]\n    print(\"Prediction: \", prediction)\n    show_sample(image,prediction.argmax(dim=0).item())","f85938ab":"predict_single(test_dataset[100][0])","e73dddb7":"predict_single(test_dataset[6257][0])\n","71b52511":"predict_single(test_dataset[4774][0])\n","a6adb3ec":"@torch.no_grad()\ndef predict_dl(dl, model):\n    torch.cuda.empty_cache()\n    batch_probs = []\n    for xb, _ in dl:\n        probs = model(xb)\n        batch_probs.append(probs.cpu().detach())\n    batch_probs = torch.cat(batch_probs)\n    return [x.argmax(dim=0).item() for x in batch_probs]","26359eb0":"test_loader = DeviceDataLoader(test_loader, device)\ntest_preds = predict_dl(test_loader, model)","42f3b1d7":"submission_df = pd.read_csv(TEST_CSV)\nsubmission_df['predictions'] = test_preds\nsubmission_df[['label','predictions']].sample(10)","441c1798":"### Loss Function\n\nWhile the accuracy is a great way for us (humans) to evaluate the model, it can't be used as a loss function for optimizing our model using gradient descent, for the following reasons:\n\n- It's not a differentiable function. torch.max and == are both non-continuous and non-differentiable operations, so we can't use the accuracy for computing gradients w.r.t the weights and biases.\n\n- It doesn't take into account the actual probabilities predicted by the model, so it can't provide sufficient feedback for incremental improvements.\n\nDue to these reasons, accuracy is a great evaluation metric for classification, but not a good loss function. A commonly used loss function for classification problems is the cross entropy,\n\n### How Cross Entropy works\n- For each output row, pick the predicted probability for the correct label. E.g. if the predicted probabilities for an image are [0.1, 0.3, 0.2, ...] and the correct label is 1, we pick the corresponding element 0.3 and ignore the rest.\n\n- Then, take the logarithm of the picked probability. If the probability is high i.e. close to 1, then its logarithm is a very small negative value, close to 0. And if the probability is low (close to 0), then the logarithm is a very large negative value. We also multiply the result by -1, which results is a large postive value of the loss for poor predictions.\n\n- Finally, take the average of the cross entropy across all the output rows to get the overall loss for a batch of data.\n\nUnlike accuracy, cross-entropy is a continuous and differentiable function that also provides good feedback for incremental improvements in the model (a slightly higher probability for the correct label leads to a lower loss). This makes it a good choice for the loss function.\n\nPyTorch provides an efficient and tensor-friendly implementation of cross entropy as part of the torch.nn.functional package. Moreover, it also performs softmax internally, so we can directly pass in the outputs of the model without converting them into probabilities.","8ee3bbd3":"Before we train the model, we need to ensure that the data and the model's parameters (weights and biases) are on the same device (CPU or GPU). We can reuse the to_device function to move the model's parameters to the right device.","d0765832":"### Evaluation Metric and Loss Function\nLet's first define out evaluation metric, we need a way to evaluate how well our model is performing. A natural way to do this would be to find the percentage of labels that were predicted correctly i.e. the accuracy of the prediction","17343bd7":"We can now wrap our data loaders using DeviceDataLoader.","41b1f40a":"### Prediction on test dataset","f7ed7237":"PyTorch datasets allow us to specify one or more transformation functions which are applied to the images as they are loaded. torchvision.transforms contains many such predefined functions, and we'll use the ToTensor transform to convert images into PyTorch tensors.","c5070c4e":"### Training and Validation Datasets\nWhile building real world machine learning models, it is quite common to split the dataset into 3 parts:\n\n- Training set - used to train the model i.e. compute the loss and adjust the weights of the model using gradient descent.\n- Validation set - used to evaluate the model while training, adjust hyperparameters (learning rate etc.) and pick the best version of the model.\n- Test set - used to compare different models, or different types of modeling approaches, and report the final accuracy of the model.\nIn the FashionMNIST dataset, there are 60,000 training images, and 10,000 test images. The test set is standardized so that different researchers can report the results of their models against the same set of images.\n\nSince there's no predefined validation set, we must manually split the 60,000 images into training and validation datasets. Let's set aside 10,000 randomly chosen images for validation. We can do this using the random_spilt method from PyTorch.","6e388578":"We see a improvment from our earlier model which used simple Feed Forward Network!\n\nhttps:\/\/www.kaggle.com\/divyakamat\/fashion-mnist-dnn","78f0a258":"### Read the dataset","f78b85b7":"Dataset class\ntorch.utils.data.Dataset is an abstract class representing a dataset. Your custom dataset should inherit Dataset and override the following methods:\n\n- \\__\\__len\\____ so that len(dataset) returns the size of the dataset.\n- \\__\\__getitem\\____ to support the indexing such that dataset[i] can be used to get ith sample","2f4bb744":"### DataLoader\n\nWe can now created data loaders to help us load the data in batches. \nLarge datasets requires loading them into memory all at once. This leads to memory outage and slowing down of programs. PyTorch offers a solution for parallelizing the data loading process with the support of automatic batching as well. This is the DataLoader class present within the torch.utils.data package.\n\nWe'll use a batch size of 64, we will load 64 samples at a time until all the 50000 images in the training set are loaded and trained to complete 1 epoch.\n\n### What is batch size?\nThe number of samples (data points) that would be passed through the network at a time.\n\n### What is epoch?\nAn epoch is one single pass of all the input data through the network.\n\n### Relation between batch_size and epoch?\nbatch_size is not equal to epoch, consider you have 1000 images. Processing all the 1000 images through the network once is considered as 1 epoch.\nIf we set the batch size as 10, during training we will be passing 100 data points (=1000\/10) at a time until we eventually pass in all the training data to complete 1 single epoch.\n\nGenerally, larger the batch size faster the training. However, you need to have enough hardware to handle. Sometimes, even if our machine can handle heavy computation,by setting larger batch size quality of the model could degrade and could create difficulty in generalizing.\n\n","56b23be8":"Here we are using torch.max() function, this function's default behaviour as you can guess by the name is to return maximum among the elements in the Tensor.\nHowever, this function also helps get the maximum along a particular dimension, as a Tensor, instead of a single element. To specify the dimension (axis \u2013 in numpy), there is another optional keyword argument, called dim. This represents the direction that we take for the maximum.\n\nmax_elements, max_indices = torch.max(input_tensor, dim)\n- dim=0,  (maximum along columns).\n- dim=1   (maximum along rows).\n\nThis returns a tuple, max_elements and max_indices.\n\n- max_elements -> All the maximum elements of the Tensor.\n- max_indices -> Indices corresponding to the maximum elements.\n\n\nIn the above accuracy function, the == performs an element-wise comparison of two tensors with the same shape, and returns a tensor of the same shape, containing 0s for unequal elements, and 1s for equal elements. Passing the result to torch.sum returns the number of labels that were predicted correctly. Finally, we divide by the total number of images to get the accuracy.\n","4aa5b689":"Check the size of the training dataset, there are totally 60000 images, this invokes the len function from the FashionMNIST Dataset Class defined above","11e71efa":"### Using a GPU\nAs the sizes of our models and datasets increase, we need to use GPUs to train our models within a reasonable amount of time. GPUs contain hundreds of cores that are optimized for performing expensive matrix operations on floating point numbers in a short time, which makes them ideal for training deep neural networks with many layers. \n\ndefine helper functions","d250698c":"### Model","ebae405c":"### Import Libraries","ffde5703":"### Training the Model\n"}}