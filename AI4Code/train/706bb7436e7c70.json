{"cell_type":{"916138e2":"code","78e8ac8d":"code","750c4454":"code","de54c6d6":"code","2db22b6c":"code","ee95591d":"code","a6912c16":"code","d65de0bd":"code","18865d52":"code","0b317008":"code","fa3251f3":"code","67d61fcf":"code","8fe2a208":"code","ecf5ff99":"code","c99a4618":"code","3181caa6":"code","ee9ede0c":"code","f53377a2":"code","d1407e71":"code","56e103c8":"code","6a72d0de":"code","5ac47360":"code","05e3f644":"code","17706688":"code","d277bd1d":"code","cb7596b1":"markdown","faa9f400":"markdown","01dd5e7c":"markdown","6ce5274c":"markdown","a92965af":"markdown","c626b04b":"markdown","1258359e":"markdown","4db5a09c":"markdown","1191f819":"markdown","224f3c5a":"markdown","e044b1d0":"markdown","17aac4d1":"markdown","b9e26fec":"markdown","ab84e61c":"markdown"},"source":{"916138e2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","78e8ac8d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator","750c4454":"train_datagen=ImageDataGenerator(rescale=1.\/255,height_shift_range=0.3,width_shift_range=0.3,\n                                horizontal_flip=True,zoom_range=0.2,\n                                shear_range=0.2)\n\ntrain_set=train_datagen.flow_from_directory('..\/input\/waste-classification-data\/DATASET\/TRAIN',\n                                           target_size=(224,224),batch_size=32,class_mode='sparse')","de54c6d6":"test_datagen=ImageDataGenerator(rescale=1.\/255)\n\ntest_set=train_datagen.flow_from_directory('..\/input\/waste-classification-data\/DATASET\/TEST',\n                                           target_size=(224,224),batch_size=32,class_mode='sparse')","2db22b6c":"from tensorflow.keras.applications.vgg16 import VGG16\nfrom keras.models import Input,Model\nfrom keras.layers import Flatten,Dense,Activation,Dropout,Conv2D,MaxPooling2D","ee95591d":"i=Input(shape=(224,224,3))","a6912c16":"conv1=Conv2D(filters=64,kernel_size=(3,3),activation='relu',padding='same')(i)\npool1=MaxPooling2D(pool_size=(2,2))(conv1)\n\nconv2=Conv2D(filters=64,kernel_size=(3,3),activation='relu',padding='same')(pool1)\npool2=MaxPooling2D(pool_size=(2,2))(conv2)\n\nconv3=Conv2D(filters=128,activation='relu',kernel_size=(2,2))(pool2)\npool3=MaxPooling2D(pool_size=(2,2))(conv3)\n\nconv4=Conv2D(filters=256,activation='relu',kernel_size=(2,2))(pool3)\npool4=MaxPooling2D(pool_size=(2,2))(conv4)","d65de0bd":"flat=Flatten()(pool4)\nlayer2=Dense(units=1024,activation='relu')(flat)\nlayer3=Dense(units=2,activation='softmax')(layer2)\nmodel1=Model(inputs=i,outputs=layer3)","18865d52":"model1.summary()               # Summary for CNN Model","0b317008":"tf.keras.utils.plot_model(model1)","fa3251f3":"from keras.callbacks import ReduceLROnPlateau,ModelCheckpoint\nlr_reduce = ReduceLROnPlateau(monitor='val_accuracy', factor=0.6, patience=8, verbose=1, mode='max', min_lr=5e-5)\ncheckpoint = ModelCheckpoint('vgg16_finetune.h15', monitor= 'val_accuracy', mode= 'max', save_best_only = True, verbose= 1)","67d61fcf":"model1.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])","8fe2a208":"model1.fit(x=train_set,validation_data=test_set,epochs=15,callbacks=[lr_reduce,checkpoint])","ecf5ff99":"metric=pd.DataFrame(model1.history.history)","c99a4618":"metric","3181caa6":"metric[['loss','val_loss']].plot()","ee9ede0c":"metric[['accuracy','val_accuracy']].plot()","f53377a2":"import matplotlib.pyplot as plt\nimport matplotlib.image as img\nfrom keras.models import load_model","d1407e71":"from keras.preprocessing.image import img_to_array","56e103c8":"model1.save('vgg16_model.h5')","6a72d0de":"import numpy as np\nfrom keras.preprocessing import image\nimg_path='..\/input\/waste-classification-data\/DATASET\/TEST\/R\/R_10040.jpg'\ntest_image=image.load_img(img_path,target_size=(224,224))\ntest_image=image.img_to_array(test_image)\ntest_image=np.expand_dims(test_image,axis=0)\n\nresult=model1.predict(test_image)\ntrain_set.class_indices\n\nres=np.argmax(result)\nif result[0][0]==1:\n    print(\"Organic Waste\")\n    plt.imshow(img.imread(img_path))\nif result[0][1]==1:\n    print(\"Recycled waste\")\n    plt.imshow(img.imread(img_path))\n    \n\n","5ac47360":"img_path='..\/input\/validation-set\/1568127258-8187.jpg'\ntest_image=image.load_img(img_path,target_size=(224,224))\ntest_image=image.img_to_array(test_image)\ntest_image=np.expand_dims(test_image,axis=0)\n\nresult=model1.predict(test_image)\ntrain_set.class_indices\n\nres=np.argmax(result)\nif result[0][0]==1:\n    print(\"Organic Waste\")\n    plt.imshow(img.imread(img_path))\nif result[0][1]==1:\n    print(\"Recycled waste\")\n    plt.imshow(img.imread(img_path))\n    \n","05e3f644":"img_path='..\/input\/validation-set\/cigarette-mainimage.jpg'\ntest_image=image.load_img(img_path,target_size=(224,224))\ntest_image=image.img_to_array(test_image)\ntest_image=np.expand_dims(test_image,axis=0)\n\nresult=model1.predict(test_image)\ntrain_set.class_indices\n\nres=np.argmax(result)\nif result[0][0]==1:\n    print(\"Organic Waste\")\n    plt.imshow(img.imread(img_path))\nif result[0][1]==1:\n    print(\"Recycled waste\")\n    plt.imshow(img.imread(img_path))\n    ","17706688":"img_path='..\/input\/validation-set\/images (1).jpg'\ntest_image=image.load_img(img_path,target_size=(224,224))\ntest_image=image.img_to_array(test_image)\ntest_image=np.expand_dims(test_image,axis=0)\n\nresult=model1.predict(test_image)\ntrain_set.class_indices\n\nres=np.argmax(result)\nif result[0][0]==1:\n    print(\"Organic Waste\")\n    plt.imshow(img.imread(img_path))\nif result[0][1]==1:\n    print(\"Recycled waste\")\n    plt.imshow(img.imread(img_path))","d277bd1d":"img_path='..\/input\/validation-set\/images (2).jpg'\ntest_image=image.load_img(img_path,target_size=(224,224))\ntest_image=image.img_to_array(test_image)\ntest_image=np.expand_dims(test_image,axis=0)\n\nresult=model1.predict(test_image)\ntrain_set.class_indices\n\nres=np.argmax(result)\nif result[0][0]==1:\n    print(\"Organic Waste\")\n    plt.imshow(img.imread(img_path))\nif result[0][1]==1:\n    print(\"Recycled waste\")\n    plt.imshow(img.imread(img_path))","cb7596b1":"# Predicting Results","faa9f400":"# Training the model ","01dd5e7c":"# Model Visualization","6ce5274c":"# Preprocessing Test set","a92965af":"# Importing libraries","c626b04b":" Test Case -1 ","1258359e":"**Test Case-3**","4db5a09c":"**Test Case-2**","1191f819":"# Preprocessing Training set","224f3c5a":"![](http:\/\/media.makeameme.org\/created\/im-in-training-zmsrgl.jpg)","e044b1d0":"# Test Cases","17aac4d1":"**Test Case-4**","b9e26fec":"**Test Case-5**","ab84e61c":"# Compiling the model"}}