{"cell_type":{"1827fb9a":"code","cf1f63e0":"code","8daec775":"code","cb89a045":"code","bb7fb102":"code","bf2564d8":"code","96818fe4":"code","e418c8f9":"code","0129a367":"code","bb9d22e1":"code","66a26d6c":"code","e1934d65":"code","e2cf1590":"code","f90ba20c":"code","ed8fa19b":"code","6d8b0cfb":"code","5643cee4":"code","5b37cc7f":"markdown","bbfe52b6":"markdown","ec1c1a31":"markdown","c1891d92":"markdown","ba9318a0":"markdown","4d6a6b47":"markdown"},"source":{"1827fb9a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport matplotlib.image as img\nimport cv2\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\ni=0\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    print(dirname)\n   ## for filename in filenames:\n        #print(filename) # png names\n        \n        #print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","cf1f63e0":"train_horses_path = (\"\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/horse-or-human\/train\/horses\/\")\ntrain_humans_path = (\"\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/horse-or-human\/train\/humans\/\")\nvalidation_horses_path = (\"\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/horse-or-human\/validation\/horses\/\")\nvalidation_humans_path = (\"\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/horse-or-human\/validation\/humans\/\")","8daec775":"example = img.imread(\"\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/horse-or-human\/train\/horses\/horse01-6.png\")\nexample = cv2.cvtColor(example, cv2.COLOR_BGR2GRAY) # this is for create a 2D image matrix.\nprint(example.dtype)\nprint(example.shape)\nplt.imshow(example)\nplt.axis('off')\nplt.show()","cb89a045":"train_horse = []\ntrain_human = []\nvalid_horse = []\nvalid_human = []\n\n# read train horses image dataset\nfor png in os.listdir(train_horses_path):\n    imageread = img.imread(train_horses_path+png)\n    imageread = cv2.cvtColor(imageread, cv2.COLOR_BGR2GRAY)\n    train_horse.append(imageread)\n    #print(imgread.shape) # (300, 300)\n\nprint(len(train_horse) , \"horses images found in train folder.\")","bb7fb102":"# read train humans image dataset\nfor png in os.listdir(train_humans_path):\n    imageread = img.imread(train_humans_path+png)\n    imageread = cv2.cvtColor(imageread, cv2.COLOR_BGR2GRAY)\n    train_human.append(imageread)\n    # print(imgread.shape) # (300, 300)\n    \nprint(len(train_human) , \"humans images found in train folder.\")   ","bf2564d8":"# concatenate our train images dataset\nall_train_images = np.concatenate((train_human, train_horse), axis = 0)\nprint(\"All train images :\",all_train_images.shape) # (1027, 300, 300)  -> this means we have 1027 images and these image 300x300 pixels.\n# we do not need this. Only find the total number of images.","96818fe4":"# read horses validation datasets.\nfor png in os.listdir(validation_horses_path):\n    imageread = img.imread(validation_horses_path+png)\n    imageread = cv2.cvtColor(imageread, cv2.COLOR_BGR2GRAY)\n    valid_horse.append(imageread)\n    #print(imgread.shape) # (300, 300)\nprint(len(valid_horse), \"horses images data for validation.\")","e418c8f9":"# read humans validation datasets\nfor png in os.listdir(validation_humans_path):\n    imageread = img.imread(validation_humans_path+png)\n    imageread = cv2.cvtColor(imageread, cv2.COLOR_BGR2GRAY)\n    valid_human.append(imageread)\n    #print(imgread.shape) # (300, 300)\nprint(len(valid_horse), \"humans images data for validation.\")","0129a367":"# concatenate our validation images dataset\nall_valid_images = np.concatenate((valid_horse, valid_human), axis = 0)\nprint(\"All validation images :\",all_valid_images.shape)  # (256, 300, 300) -> we have 256 images for validation.\n# we do not need this. Only find the total number of images.","bb9d22e1":"# all images\nx_data = np.concatenate((train_human, valid_human, train_horse, valid_horse), axis=0)\nprint(x_data.shape[0],\"images have \",x_data.shape[1],\"x\",x_data.shape[2],\"pixels.\")","66a26d6c":"# We create our classify data. 1 for human and 0 for horses. \nzero = np.zeros(len(train_horse) + len(valid_horse)) # all horse images\none = np.ones(len(train_human) + len(valid_human))   # all human images\nprint(\"Number of humans images :\", one.size)\nprint(\"Number of horses images :\", zero.size)","e1934d65":"# Y data\ny = np.concatenate((zero, one), axis= 0).reshape(-1,1)\nprint(y.shape)\n# [ 0 - 627] -> 0 -> horse\n# [628-1282] -> 1 -> human","e2cf1590":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x_data, y, test_size = 0.3, random_state = 42)\n# x_train.shape -> (1026, 300, 300)\n\nnumber_of_train = x_train.shape[0]\nnumber_of_test  = x_test.shape[0]\n\nprint(\"Number of train :\", number_of_train)\nprint(\"Number of test :\", number_of_test)","f90ba20c":"# flatten our data\nx_train_flatten = x_train.reshape(number_of_train, x_train.shape[1] * x_train.shape[2])  # 898, 300*300\nx_test_flatten = x_test.reshape(number_of_test, x_test.shape[1] * x_test.shape[2])       # 385, 300*300\n\nprint(\"X train Flatten : \",x_train_flatten.shape)\nprint(\"X test Flatten : \",x_test_flatten.shape)\nx_train = x_train_flatten\nx_test = x_test_flatten","ed8fa19b":"# import Keras and layers libraries\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom keras.models import Sequential\nfrom keras.layers import Dense","6d8b0cfb":"# this function is our classifier function. we make hidden layers in this funcion.\ndef build_classifier():\n    classifier = Sequential()\n    classifier.add(Dense(units = 50, kernel_initializer = 'uniform', activation = 'relu', input_dim = x_train.shape[1])) # first hidden layer\n    classifier.add(Dense(units = 40, kernel_initializer = 'uniform', activation = 'relu'))   # second hidden layer\n    classifier.add(Dense(units = 30, kernel_initializer = 'uniform', activation = 'relu'))   # third hidden layer\n    classifier.add(Dense(units = 20, kernel_initializer = 'uniform', activation = 'relu'))\n    #classifier.add(Dense(units = 20, kernel_initializer = 'uniform', activation = 'relu'))\n    #classifier.add(Dense(units = 10, kernel_initializer = 'uniform', activation = 'relu'))\n    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid')) # last (output) layer\n    \n    classifier.compile(optimizer='adam', loss = 'binary_crossentropy', metrics=['accuracy'])\n    return classifier","5643cee4":"cf = KerasClassifier(build_fn=build_classifier, epochs = 100) # epochs = number of iteration\naccuracies = cross_val_score(estimator=cf, X = x_train, y = y_train, cv = 3)\nmaks = accuracies.max()\nvariance = accuracies.std()\nmean = accuracies.mean()\n\nprint(\"Accuracy max : \", maks)\nprint(\"Accuracy variance : \", variance)\nprint(\"Accuracy mean : \", mean)","5b37cc7f":"Hi everyone. This is my solution. This results mean, max and variance can be chance every run. But not much difference. For example first run we take 0.84 mean and second run we take 0.83 and the third run 0.85 mean. They are close results. \nI tried this code 11 times with changing parameters epochs, number of hidden layers, hidden layer units etc.\nI will show you all the results. \n\n1. \n    * 7 hidden layers and units : 60 - 50 - 40 - 30 - 20 - 10 - 1(output layer)\n    * epoch = 100\n    * cv = 3\n    * activation = \"relu\"\n\n\n    * Accuracy max :  0.8600000143051147\n    * Accuracy variance :  0.017963577742701624\n    * Accuracy mean :  0.8373913168907166\n\n\n2. \n    * 5 hidden layers and units : 100 - 100 - 100 - 100 - 1(output layer)\n    * epoch = 100\n    * cv = 3\n    * activation = \"relu\"\n\n\n    * Accuracy max :  0.8561872839927673\n    * Accuracy variance :  0.016486297310804213\n    * Accuracy mean :  0.8374135891596476\n\n    * It took a little longer. 5ms\/step.\n\n\n3. \n    * 5 hidden layers and units : 60 - 60 - 60 - 60 - 1(output layer)\n    * epoch = 100\n    * cv = 3\n    * activation = \"relu\"\n    \n    \n    * Accuracy max :  0.8795986771583557\n    * Accuracy variance :  0.01851755188553315\n    * Accuracy mean :  0.8541285991668701\n\n\n4. \n    * 5 hidden layers and units : 60 - 50 - 40 - 30 - 1(output layer)\n    * epoch = 100\n    * cv = 3\n    * activation = \"relu\"\n    \n    \n    * Accuracy max :  0.8662207126617432\n    * Accuracy variance :  0.027488834269085907\n    * Accuracy mean :  0.8274135986963908\n\n\n5. \n    * 5 hidden layers and units : 60 - 50 - 40 - 30 - 1(output layer)\n    * *epoch = 50*\n    * cv = 3\n    * activation = \"relu\"\n    \n    \n    * Accuracy max :  0.8433333039283752\n    * Accuracy variance :  0.03953918337815218\n    * Accuracy mean :  0.8151133259137472\n\n6. \n    * 5 hidden layers and units : 60 - 50 - 40 - 30 - 1(output layer)\n    * *epoch = 150*\n    * cv = 3\n    * activation = \"relu\"\n    \n    \n    * Accuracy max :  0.8695651888847351\n    * Accuracy variance :  0.015466893717157856\n    * Accuracy mean :  0.8485581278800964\n\n\n7. \n    * 5 hidden layer and units : 50 - 40 - 30 - 20 - 1(output layer)\n    * epochs = 100\n    * *cv = 5*\n    * activation = \"relu\"\n    \n    \n    * Accuracy max :  0.8888888955116272\n    * Accuracy variance :  0.032781729181184244\n    * Accuracy mean :  0.836225950717926\n\n\n8. \n    * 4 hidden layer and units 50 - 40 - 30 - 1(output layer)\n    * epochs = 100\n    * cv = 5\n    * activation = \"relu\"\n    \n    \n    * Accuracy max :  0.9166666865348816\n    * Accuracy variance :  0.03252429101929113\n    * Accuracy mean :  0.8607821345329285\n","bbfe52b6":"Now we created our X and Y datas. First read all train humans and horses images datas and concatenate all train datas.\nThen do it again for validation datas. Validation is Y and Train is X. \nNow we use X and Y datas and crate our train and test datas.","ec1c1a31":"Now we have all train and test datas. The train data is (898, 300, 300), this means in train data there are 898 images and these are 300x300 pixels. We need to convert them all to (898, 90000). This is flatten technic. ","c1891d92":"**## CONCLUSION**\n*     As I said, every run, this results can be chance. For this results, I run one time. maybe we take different result for second run, I do not know. \n*     But this result help us, compare different parameters, algorithms etc.\n*     Thank you for reading.\n*     If you have any question, you can ask me every thing.\n*     And if youo find any mistake or bugs please tell me.","ba9318a0":"9. \n    * 4 hidden layer and units 150 - 100 - 80 - 1(output layer)\n    * epoch = 100\n    * cv = 3\n    * activation = \"relu\"\n    \n    \n    * Accuracy max :  0.8566666841506958\n    * Accuracy variance :  0.0073748193863788425\n    * Accuracy mean :  0.8496581315994263\n    * \n    * It takes too much time. 7ms\/step.\n\n\n10. \n    * 3 hidden layer and units : 100 - 80 - 1(output layer)\n    * epoch = 50\n    * cv 3\n    * activation = \"relu\"\n    \n    \n    * Accuracy max :  0.8494983315467834\n    * Accuracy variance :  0.023616515202710592\n    * Accuracy mean :  0.816280206044515\n\n\n**Worst Case:**\n11. \n    * 3 hidden layers and their units : 100 - 80 - 1(output layer)\n    * epoch = 50\n    * cv = 3\n    * activation = \"tanh\"   <------\n    \n    \n    * Accuracy max :  0.5117056965827942\n    * Accuracy variance :  0.02871399475215531\n    * Accuracy mean :  0.475503534078598\n\n    * I try \"tanh\" function for see the result. But it is not good for this dataset.","4d6a6b47":"    ARTIFICIAL NEEURAL NETWORKS"}}