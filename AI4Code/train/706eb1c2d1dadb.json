{"cell_type":{"13956746":"code","cf22cd88":"code","9a332d9f":"code","90690a44":"code","a4e13256":"code","1cd37e89":"code","ef606975":"code","dc9265ee":"code","cf412292":"code","081aa98d":"code","3fc9bfcd":"code","af2ae151":"code","3fa49504":"code","12f19d15":"code","8d8df637":"code","19ca5d75":"code","827d3185":"markdown","585ce977":"markdown","64387a3c":"markdown","6c7a39f1":"markdown","11689800":"markdown","cabf0a54":"markdown","606b5888":"markdown","8bd30695":"markdown","1970b460":"markdown"},"source":{"13956746":"import os\nimport math\nimport random\nimport itertools\nimport numpy as np\nfrom scipy import io\nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nfrom torch.nn.utils import spectral_norm\nimport torch.backends.cudnn as cudnn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\nimport torchvision.utils as vutils\nfrom tqdm import tqdm_notebook as tqdm\nfrom pathlib import Path","cf22cd88":"class SelfAttentionNaive(nn.Module):\n    def __init__(self, nf, nh=False):\n        super(SelfAttentionNaive, self).__init__()\n        if not nh:\n            nh = max(nf\/\/8, 1)\n        self.f = spectral_norm(nn.Conv2d(nf, nh, 1, bias=False))\n        self.g = spectral_norm(nn.Conv2d(nf, nh, 1, bias=False))\n        self.h = spectral_norm(nn.Conv2d(nf, nf, 1, bias=False))\n        self.gamma = nn.Parameter(torch.zeros(1))\n        self.nh = nh\n        self.nf = nf\n    def forward(self, x):\n        fx = self.f(x).view(x.size(0), self.nh, x.size(2)*x.size(3))\n        gx = self.g(x).view(x.size(0), self.nh, x.size(2)*x.size(3))\n        hx = self.h(x).view(x.size(0), self.nf, x.size(2)*x.size(3))\n        s = fx.transpose(-1,-2).matmul(gx)\n        b = F.softmax(s, dim=1)\n        o = hx.matmul(b)\n        return o.view_as(x) * self.gamma + x\n\nclass SelfAttention(nn.Module):\n    def __init__(self, nf, nh=False):\n        super(SelfAttention, self).__init__()\n        if not nh:\n            nh = max(nf\/\/8, 1)\n        self.f = spectral_norm(nn.Conv2d(nf, nh, 1, bias=False))\n        self.g = spectral_norm(nn.Conv2d(nf, nh, 1, bias=False))\n        self.h = spectral_norm(nn.Conv2d(nf, nf\/\/2, 1, bias=False))\n        self.o = spectral_norm(nn.Conv2d(nf\/\/2, nf, 1, bias=False))\n        self.gamma = nn.Parameter(torch.zeros(1))\n        self.nh = nh\n        self.nf = nf\n    def forward(self, x):\n        fx = self.f(x).view(x.size(0), self.nh, x.size(2)*x.size(3))\n        gx = self.g(x)\n        gx = F.max_pool2d(gx, kernel_size=2)\n        gx = gx.view(x.size(0), self.nh, x.size(2)*x.size(3)\/\/4)\n        s = gx.transpose(-1,-2).matmul(fx)\n        s = F.softmax(s, dim=1)\n        hx = self.h(x)\n        hx = F.max_pool2d(hx, kernel_size=2)\n        hx = hx.view(x.size(0), self.nf\/\/2, x.size(2)*x.size(3)\/\/4)\n        ox = hx.matmul(s).view(x.size(0), self.nf\/\/2, x.size(2), x.size(3))\n        ox = self.o(ox)\n        return ox * self.gamma + x\n    \nclass _resDiscriminator128(nn.Module):\n    def __init__(self, nIn=3, nf=64, selfAtt=False):\n        super(_resDiscriminator128, self).__init__()\n        self.blocs = []\n        self.sc = []\n        # first bloc\n        self.bloc0 = nn.Sequential(spectral_norm(nn.Conv2d(nIn, nf, 3, 1, 1, bias=True)),\n                                   nn.ReLU(),\n                                   spectral_norm(nn.Conv2d(nf, nf, 3, 1, 1, bias=True)),\n                                   nn.AvgPool2d(2),)\n        self.sc0 = nn.Sequential(nn.AvgPool2d(2),\n                                 spectral_norm(nn.Conv2d(nIn, nf, 1, bias=True)),)\n        if selfAtt:\n            self.selfAtt = SelfAttention(nf)\n        else:\n            self.selfAtt = nn.Sequential()\n        # Down blocs\n        for i in range(4):\n            nfPrev = nf\n            nf = nf*2\n            self.blocs.append(nn.Sequential(nn.ReLU(),\n                                            spectral_norm(nn.Conv2d(nfPrev, nf, 3, 1, 1, bias=True)),\n                                            nn.ReLU(),\n                                            spectral_norm(nn.Conv2d(nf, nf, 3, 1, 1, bias=True)),\n                                            nn.AvgPool2d(2),))\n            self.sc.append(nn.Sequential(nn.AvgPool2d(2),\n                                         spectral_norm(nn.Conv2d(nfPrev, nf, 1, bias=True)),))\n        # Last Bloc\n        self.blocs.append(nn.Sequential(nn.ReLU(),\n                                        spectral_norm(nn.Conv2d(nf, nf, 3, 1, 1, bias=True)),\n                                        nn.ReLU(),\n                                        spectral_norm(nn.Conv2d(nf, nf, 3, 1, 1, bias=True))))\n        self.sc.append(nn.Sequential())\n        self.dense = nn.Linear(nf, 1)\n        self.blocs = nn.ModuleList(self.blocs)\n        self.sc = nn.ModuleList(self.sc)\n    def forward(self, x):\n        x = self.selfAtt(self.bloc0(x) + self.sc0(x))\n        for k in range(len(self.blocs)):\n            x = self.blocs[k](x) + self.sc[k](x)\n        x = x.sum(3).sum(2)\n        return self.dense(x)\n\nclass _resEncoder128(nn.Module):\n    def __init__(self, nIn=3, nf=64, nOut=8):\n        super(_resEncoder128, self).__init__()\n        self.blocs = []\n        self.sc = []\n        # first bloc\n        self.blocs.append(nn.Sequential(spectral_norm(nn.Conv2d(nIn, nf, 3, 1, 1, bias=True)),\n                                        nn.ReLU(),\n                                        spectral_norm(nn.Conv2d(nf, nf, 3, 1, 1, bias=True)),\n                                        nn.AvgPool2d(2),))\n        self.sc.append(nn.Sequential(nn.AvgPool2d(2),\n                                     spectral_norm(nn.Conv2d(nIn, nf, 1, bias=True)),))\n        # Down blocs\n        for i in range(4):\n            nfPrev = nf\n            nf = nf*2\n            self.blocs.append(nn.Sequential(nn.ReLU(),\n                                            spectral_norm(nn.Conv2d(nfPrev, nf, 3, 1, 1, bias=True)),\n                                            nn.ReLU(),\n                                            spectral_norm(nn.Conv2d(nf, nf, 3, 1, 1, bias=True)),\n                                            nn.AvgPool2d(2),))\n            self.sc.append(nn.Sequential(nn.AvgPool2d(2),\n                                         spectral_norm(nn.Conv2d(nfPrev, nf, 1, bias=True)),))\n        # Last Bloc\n        self.blocs.append(nn.Sequential(nn.ReLU(),\n                                        spectral_norm(nn.Conv2d(nf, nf, 3, 1, 1, bias=True)),\n                                        nn.ReLU(),\n                                        spectral_norm(nn.Conv2d(nf, nf, 3, 1, 1, bias=True))))\n        self.sc.append(nn.Sequential())\n        self.dense = nn.Linear(nf, nOut)\n        self.blocs = nn.ModuleList(self.blocs)\n        self.sc = nn.ModuleList(self.sc)\n    def forward(self, x):\n        for k in range(len(self.blocs)):\n            x = self.blocs[k](x) + self.sc[k](x)\n        x = x.sum(3).sum(2)\n        return self.dense(x)\n    \nclass _resMaskedGenerator128(nn.Module):\n    def __init__(self, nf=64, nOut=3, nc=8, selfAtt=False):\n        super(_resMaskedGenerator128, self).__init__()\n        if selfAtt:\n            self.selfAtt = SelfAttention(nf*2)\n        else:\n            self.selfAtt = nn.Sequential()\n        self.dense = nn.Linear(nc, 4*4*nf*16)\n        self.convA = []\n        self.convB = []\n        self.normA = []\n        self.normB = []\n        self.gammaA = []\n        self.gammaB = []\n        self.betaA = []\n        self.betaB = []\n        self.sc = []\n        nfPrev = nf*16\n        nfNext = nf*16\n        for k in range(5):\n            self.convA.append(nn.Sequential(nn.Upsample(scale_factor=2),\n                                            spectral_norm(nn.Conv2d(nfPrev + 1, nfNext, 3, 1, 1, bias=False)),))\n            self.convB.append(spectral_norm(nn.Conv2d(nfNext, nfNext, 3, 1, 1, bias=True )))\n            self.normA.append(nn.InstanceNorm2d(nfPrev, affine=False))\n            self.normB.append(nn.InstanceNorm2d(nfNext, affine=False))\n            self.gammaA.append(nn.Conv2d(nc, nfPrev, 1, bias=True))\n            self.gammaB.append(nn.Conv2d(nc, nfNext, 1, bias=True))\n            self.betaA.append(nn.Conv2d(nc, nfPrev, 1, bias=True))\n            self.betaB.append(nn.Conv2d(nc, nfNext, 1, bias=True))\n            self.sc.append(nn.Sequential(nn.Upsample(scale_factor=2),\n                                         spectral_norm(nn.Conv2d(nfPrev, nfNext, 1, bias=True))))\n            nfPrev = nfNext\n            nfNext = nfNext \/\/ 2\n        self.convA = nn.ModuleList(self.convA)\n        self.convB = nn.ModuleList(self.convB)\n        self.normA = nn.ModuleList(self.normA)\n        self.normB = nn.ModuleList(self.normB)\n        self.gammaA =nn.ModuleList(self.gammaA)\n        self.gammaB =nn.ModuleList(self.gammaB)\n        self.betaA = nn.ModuleList(self.betaA)\n        self.betaB = nn.ModuleList(self.betaB)\n        self.sc = nn.ModuleList(self.sc)\n        self.normOut = nn.InstanceNorm2d(nf, affine=False)\n        self.gammaOut = nn.Conv2d(nc, nf, 1, bias=True)\n        self.betaOut = nn.Conv2d(nc, nf, 1, bias=True)\n        self.convOut = spectral_norm(nn.Conv2d(nf, nOut, 3, 1, 1))\n        self.convOut = spectral_norm(nn.Conv2d(nf + 1, nOut, 3, 1, 1))\n        ##############################\n    def forward(self, m, z, c):\n        ######### Upsample ###########\n        x = self.dense(z.view(z.size(0),z.size(1))).view(z.size(0), -1, 4, 4)\n        mask_ratio = m.size(-1) \/\/ 4\n        for k in range(5):\n            if k == 4:\n                x = self.selfAtt(x)\n            h = self.convA[k](torch.cat((F.relu(self.normA[k](x) * self.gammaA[k](c) + self.betaA[k](c)),\n                                         F.avg_pool2d(m, kernel_size=mask_ratio)), 1))\n            h = self.convB[k](F.relu(self.normB[k](h) * self.gammaB[k](c) + self.betaB[k](c)))\n            x = h + self.sc[k](x)\n            mask_ratio = mask_ratio \/\/ 2\n        x = self.convOut(torch.cat((F.relu(self.normOut(x) * self.gammaOut(c) + self.betaOut(c)),\n                                    m), 1))\n        x = torch.tanh(x)\n        return x * m\n    \nclass _downConv(nn.Module):\n    def __init__(self, nIn=3, nf=128, spectralNorm=False):\n        super(_downConv, self).__init__()\n        self.mods = nn.Sequential(nn.ReflectionPad2d(3),\n                                  spectral_norm(nn.Conv2d(nIn, nf\/\/4, 7, bias=False)) if spectralNorm else nn.Conv2d(nIn, nf\/\/4, 7, bias=False),\n                                  nn.InstanceNorm2d(nf\/\/4, affine=True),\n                                  nn.ReLU(),\n                                  spectral_norm(nn.Conv2d(nf\/\/4, nf\/\/2, 3, 2, 1, bias=False)) if spectralNorm else nn.Conv2d(nf\/\/4, nf\/\/2, 3, 2, 1, bias=False),\n                                  nn.InstanceNorm2d(nf\/\/2, affine=True),\n                                  nn.ReLU(),\n                                  spectral_norm(nn.Conv2d(nf\/\/2, nf, 3, 2, 1, bias=False)) if spectralNorm else nn.Conv2d(nf\/\/2, nf, 3, 2, 1, bias=False),\n                                  nn.InstanceNorm2d(nf, affine=True),\n                                  nn.ReLU(),\n        )\n    def forward(self, x):\n        return self.mods(x)\nclass _resBloc(nn.Module):\n    def __init__(self, nf=128, spectralNorm=False):\n        super(_resBloc, self).__init__()\n        self.blocs = nn.Sequential(spectral_norm(nn.Conv2d(nf, nf, 3, 1, 1, bias=False)) if spectralNorm else nn.Conv2d(nf, nf, 3, 1, 1, bias=False),\n                                   nn.InstanceNorm2d(nf, affine=True),\n                                   nn.ReLU(),\n                                   spectral_norm(nn.Conv2d(nf, nf, 3, 1, 1, bias=True)) if spectralNorm else nn.Conv2d(nf, nf, 3, 1, 1, bias=True),\n        )\n        self.activationF = nn.Sequential(nn.InstanceNorm2d(nf, affine=True),\n                                         nn.ReLU(),\n        )\n    def forward(self, x):\n        return self.activationF(self.blocs(x) + x)\nclass _upConv(nn.Module):\n    def __init__(self, nOut=3, nf=128, spectralNorm=False):\n        super(_upConv, self).__init__()\n        self.mods = nn.Sequential(nn.Upsample(scale_factor=2, mode='nearest'),\n                                  spectral_norm(nn.Conv2d(nf, nf\/\/2, 3, 1, 1, bias=False)) if spectralNorm else nn.Conv2d(nf, nf\/\/2, 3, 1, 1, bias=False),\n                                  nn.InstanceNorm2d(nf\/\/2, affine=True),\n                                  nn.ReLU(),\n                                  nn.Upsample(scale_factor=2, mode='nearest'),\n                                  spectral_norm(nn.Conv2d(nf\/\/2, nf\/\/4, 3, 1, 1, bias=False)) if spectralNorm else nn.Conv2d(nf\/\/2, nf\/\/4, 3, 1, 1, bias=False),\n                                  nn.InstanceNorm2d(nf\/\/4, affine=True),\n                                  nn.ReLU(),\n                                  nn.ReflectionPad2d(3),\n                                  spectral_norm(nn.Conv2d(nf\/\/4, nOut, 7, bias=True)) if spectralNorm else nn.Conv2d(nf\/\/4, nOut, 7, bias=True),\n        )\n    def forward(self, x):\n        return self.mods(x)\nclass _netEncM(nn.Module):\n    def __init__(self, sizex=128, nIn=3, nMasks=2, nRes=5, nf=128, temperature=1):\n        super(_netEncM, self).__init__()\n        self.nMasks = nMasks\n        sizex = sizex \/\/ 4 \n        self.cnn = nn.Sequential(*([_downConv(nIn, nf)] +\n                                   [_resBloc(nf=nf) for i in range(nRes)]))\n        self.psp = nn.ModuleList([nn.Sequential(nn.AvgPool2d(sizex),\n                                                nn.Conv2d(nf,1,1),\n                                                nn.Upsample(size=sizex, mode='bilinear')),\n                                  nn.Sequential(nn.AvgPool2d(sizex\/\/2, sizex\/\/2),\n                                                nn.Conv2d(nf,1,1),\n                                                nn.Upsample(size=sizex, mode='bilinear')),\n                                  nn.Sequential(nn.AvgPool2d(sizex\/\/3, sizex\/\/3),\n                                                nn.Conv2d(nf,1,1),\n                                                nn.Upsample(size=sizex, mode='bilinear')),\n                                  nn.Sequential(nn.AvgPool2d(sizex\/\/6, sizex\/\/6),\n                                                nn.Conv2d(nf,1,1),\n                                                nn.Upsample(size=sizex, mode='bilinear'))])\n        self.out = _upConv(1 if nMasks == 2 else nMasks, nf+4)\n        self.temperature = temperature\n    def forward(self, x):\n        f = self.cnn(x)\n        m = self.out(torch.cat([f] + [pnet(f) for pnet in self.psp], 1))\n        if self.nMasks == 2:\n            m = torch.sigmoid(m \/ self.temperature)\n            m = torch.cat((m, (1-m)), 1)\n        else:\n            m = F.softmax(m \/ self.temperature, dim=1)\n        return m\n\nclass _netGenX(nn.Module):\n    def __init__(self, sizex=128, nOut=3, nc=8, nf=64, nMasks=2, selfAtt=False):\n        super(_netGenX, self).__init__()\n        if sizex != 128:\n            raise NotImplementedError\n        self.net = nn.ModuleList([_resMaskedGenerator128(nf=nf, nOut=nOut, nc=nc, selfAtt=selfAtt) for k in range(nMasks)])\n        self.nMasks = nMasks\n    def forward(self, masks, c):\n        masks = masks.unsqueeze(2)\n        y = []\n        for k in range(self.nMasks):\n            y.append(self.net[k](masks[:,k], c[:,k], c[:,k]).unsqueeze(1))\n        return torch.cat(y,1)\n    \nclass _netRecZ(nn.Module):\n    def __init__(self, sizex=128, nIn=3, nc=5, nf=64, nMasks=2):\n        super(_netRecZ, self).__init__()\n        if sizex == 128:\n            self.net = _resEncoder128(nIn=nIn, nf=nf, nOut=nc*nMasks)\n        elif sizex == 64:\n            self.net = _resEncoder64(nIn=nIn, nf=nf, nOut=nc*nMasks)\n        self.nc = nc\n        self.nMasks = nMasks\n    def forward(self, x):\n        c = self.net(x)\n        return c.view(c.size(0), self.nMasks, self.nc, 1 , 1)","9a332d9f":"random.seed(2019)\ntorch.manual_seed(2019)\ndevice = torch.device(\"cuda:0\")\ncudnn.benchmark = True\nSIZE_X = 128\nN_X = 3\nN_Z = 64\nN_F = 64\nN_RES_M = 3 # number of residual blocks\nN_MASKS = 2 # number of masks\ninitOrthoGain = 0.8\nwdecay = 1e-4\nwrecZ = 5\nlrG = 1e-4\nlrM = 1e-5\nlrD = 1e-4\nlrZ = 1e-4\nnIteration = 20000\nITER_STEPS = 500 # steps per iteration\nN_TEST = 5\nBATCH_SIZE = 20\ndataroot = Path('..\/input\/oxford-flower-segmentations\/')","90690a44":"class FlowersDataset(torch.utils.data.Dataset):\n    def __init__(self, dataPath, sets='train', transform=transforms.ToTensor()):\n        super(FlowersDataset, self).__init__()\n        self.files =  io.loadmat(os.path.join(dataPath, \"setid.mat\"))\n        if sets == 'train':\n            self.files = self.files.get('tstid')[0]\n        elif sets == 'val':\n            self.files = self.files.get('valid')[0]\n        else:\n            self.files = self.files.get('trnid')[0]\n        self.transform = transform\n        self.datapath = dataPath\n    def __len__(self):\n        return len(self.files)\n    def __getitem__(self, idx):\n        imgname = \"image_%05d.jpg\" % self.files[idx]\n        segname = \"segmim_%05d.jpg\" % self.files[idx]\n        img = self.transform(Image.open(os.path.join(self.datapath, \"jpg\", \"jpg\", imgname)))\n        seg = np.array(Image.open(os.path.join(self.datapath, \"segmim\", \"segmim\", segname)))\n        seg = 1 - ((seg[:,:,0:1] == 0) + (seg[:,:,1:2] == 0) + (seg[:,:,2:3] == 254))\n        seg = (seg * 255).astype('uint8').repeat(3,axis=2)\n        seg = self.transform(Image.fromarray(seg))[:1]\n        return img * 2 - 1, seg","a4e13256":"trainset = FlowersDataset(dataPath=dataroot,\n                                   sets='train',\n                                   transform=transforms.Compose([transforms.Resize(SIZE_X, Image.NEAREST),\n                                                                 transforms.CenterCrop(SIZE_X),\n                                                                 transforms.ToTensor(),\n                                   ]),)\ntestset = FlowersDataset(dataPath=dataroot,\n                              sets='test',\n                              transform=transforms.Compose([transforms.Resize(SIZE_X, Image.NEAREST),\n                                                            transforms.CenterCrop(SIZE_X),\n                                                            transforms.ToTensor(),\n                              ]),)\nvalset = FlowersDataset(dataPath=dataroot,\n                             sets='val',\n                             transform=transforms.Compose([transforms.Resize(SIZE_X, Image.NEAREST),\n                                                           transforms.CenterCrop(SIZE_X),\n                                                           transforms.ToTensor(),\n                             ]),)","1cd37e89":"def weights_init_ortho(m):\n    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n        nn.init.orthogonal_(m.weight, initOrthoGain)","ef606975":"netEncM = _netEncM(sizex=SIZE_X, nIn=N_X, nMasks=N_MASKS, nRes=N_RES_M, nf=N_F, temperature=1).to(device)\nnetGenX = _netGenX(sizex=SIZE_X, nOut=N_X, nc=N_Z, nf=N_F, nMasks=N_MASKS, selfAtt=True).to(device)\nnetDX = _resDiscriminator128(nIn=N_X, nf=N_F, selfAtt=True).to(device)","dc9265ee":"netEncM.apply(weights_init_ortho)\nnetGenX.apply(weights_init_ortho)\nnetDX.apply(weights_init_ortho)","cf412292":"optimizerEncM = torch.optim.Adam(netEncM.parameters(), lr=lrM, betas=(0, 0.9), weight_decay=wdecay, amsgrad=False)\noptimizerGenX = torch.optim.Adam(netGenX.parameters(), lr=lrG, betas=(0, 0.9), amsgrad=False)\noptimizerDX = torch.optim.Adam(netDX.parameters(), lr=lrD, betas=(0, 0.9), amsgrad=False)","081aa98d":"if wrecZ > 0:\n    netRecZ = _netRecZ(sizex=SIZE_X, nIn=N_X, nc=N_Z, nf=N_Z, nMasks=N_MASKS).to(device)\n    netRecZ.apply(weights_init_ortho)\n    optimizerRecZ = torch.optim.Adam(netRecZ.parameters(), lr=lrZ, betas=(0, 0.9), amsgrad=False)","3fc9bfcd":"def evaluate(netEncM, loader, device, nMasks=2):\n    sumScoreAcc = 0\n    sumScoreIoU = 0\n    nbIter = 0\n    if nMasks > 2:\n        raise NotImplementedError\n    for xLoad, mLoad in loader:\n        xData = xLoad.to(device)\n        mData = mLoad.to(device)\n        mPred = netEncM(xData)\n        sumScoreAcc += torch.max(((mPred[:,:1] >= .5).float() == mData).float().mean(-1).mean(-1),\n                                 ((mPred[:,:1] <  .5).float() == mData).float().mean(-1).mean(-1)).mean().item()\n        sumScoreIoU += torch.max(\n            ((((mPred[:,:1] >= .5).float() + mData) == 2).float().sum(-1).sum(-1) \/\n             (((mPred[:,:1] >= .5).float() + mData) >= 1).float().sum(-1).sum(-1)),\n            ((((mPred[:,:1] <  .5).float() + mData) == 2).float().sum(-1).sum(-1) \/\n             (((mPred[:,:1] <  .5).float() + mData) >= 1).float().sum(-1).sum(-1))).mean().item()\n        nbIter += 1\n    return sumScoreAcc \/ nbIter, sumScoreIoU \/ nbIter","af2ae151":"x_test, m_test = next(iter(torch.utils.data.DataLoader(testset, batch_size=N_TEST, shuffle=True, num_workers=4, drop_last=True)))\n\nx_test = x_test.to(device)\n\nz_test = torch.randn((N_TEST, N_MASKS, N_Z, 1, 1), device=device)\nzn_test = torch.randn((N_TEST, N_Z, 1, 1), device=device)\n\nimg_m_test = m_test[:,:1].float()\nfor n in range(N_TEST):\n    img_m_test[n] = (img_m_test[n] \/ img_m_test[n].max()) * 2 - 1\n\nout_X = torch.full((N_MASKS, N_TEST+1, N_TEST+5, N_X, SIZE_X, SIZE_X), -1).to(device)\nout_X[:,1:,0] = x_test\nout_X[:,1:,1] = img_m_test\n\nvalloader = torch.utils.data.DataLoader(valset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n","3fa49504":"trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\ngenData = iter(trainloader)\ndisData = iter(trainloader)","12f19d15":"iteration = 0\nbestValIoU = 0\npbar = tqdm(total=ITER_STEPS)\nwhile iteration <= nIteration:\n    pbar.update(1)\n    ########################## Get Batch #############################\n    try:\n        xLoadG, mLoadG = next(genData)\n    except StopIteration:\n        genData = iter(trainloader)\n        xLoadG, mLoadG = next(genData)\n    try:\n        xLoadD, mLoadD = next(disData)\n    except StopIteration:\n        disData = iter(trainloader)\n        xLoadD, mLoadD = next(disData)\n    xData = xLoadG.to(device)\n    mData = mLoadG.to(device)\n    xReal = xLoadD.to(device)\n    zData = torch.randn((xData.size(0), N_MASKS, N_Z, 1, 1), device=device)\n    ########################## Reset Nets ############################\n    netEncM.zero_grad()\n    netGenX.zero_grad()\n    netDX.zero_grad()\n    netEncM.train()\n    netGenX.train()\n    netDX.train()\n    if wrecZ > 0:\n        netRecZ.zero_grad()\n        netRecZ.train()\n    dStep = (iteration % 4 == 0)\n    gStep = (iteration % 4 == 0)\n    #########################  AutoEncode X #########################\n    if gStep:\n        mEnc = netEncM(xData)\n        hGen = netGenX(mEnc, zData)\n        xGen = (hGen + ((1 - mEnc.unsqueeze(2)) * xData.unsqueeze(1))).view(hGen.size(0) * hGen.size(1), hGen.size(2), hGen.size(3), hGen.size(4))\n        dGen = netDX(xGen)\n        lossG = - dGen.mean()\n        if wrecZ > 0:\n            zRec = netRecZ(hGen.sum(1))\n            err_recZ = ((zData - zRec) * (zData - zRec)).mean()\n            lossG += err_recZ * wrecZ\n        lossG.backward()\n        optimizerEncM.step()\n        optimizerGenX.step()\n        if wrecZ > 0:\n            optimizerRecZ.step()\n    if dStep:\n        netDX.zero_grad()\n        with torch.no_grad():\n            mEnc = netEncM(xData)\n            hGen = netGenX(mEnc, zData)\n            xGen = (hGen + ((1 - mEnc.unsqueeze(2)) * xData.unsqueeze(1))).view(hGen.size(0) * hGen.size(1), hGen.size(2), hGen.size(3), hGen.size(4))\n        dPosX = netDX(xReal)\n        dNegX = netDX(xGen)\n        err_dPosX = (-1 + dPosX)\n        err_dNegX = (-1 - dNegX)\n        err_dPosX = ((err_dPosX < 0).float() * err_dPosX).mean()\n        err_dNegX = ((err_dNegX < 0).float() * err_dNegX).mean()\n        (-err_dPosX - err_dNegX).backward()\n        optimizerDX.step()\n    iteration += 1\n    if iteration % ITER_STEPS == 0:\n        pbar.close()\n        netEncM.eval()\n        netGenX.eval()\n        netDX.eval()\n        if wrecZ > 0:\n            netRecZ.eval()\n        with torch.no_grad():\n            mEnc_test = netEncM(x_test)\n            out_X[:,1:,3] = mEnc_test.transpose(0,1).unsqueeze(2)*2-1\n            out_X[:,1:,2] = ((out_X[:,1:,3] < 0).float() * -1) + (out_X[:,1:,3] > 0).float()\n            out_X[:,1:,4] = (netGenX(mEnc_test, z_test) + ((1 - mEnc_test.unsqueeze(2)) * x_test.unsqueeze(1))).transpose(0,1)\n            for k in range(N_MASKS):\n                for i in range(N_TEST):\n                    zx_test = z_test.clone()\n                    zx_test[:, k] = zn_test[i]\n                    out_X[k, 1:, i+5] = netGenX(mEnc_test, zx_test)[:,k] + ((1 - mEnc_test[:,k:k+1]) * x_test)\n            scoreAccTrain, scoreIoUTrain = evaluate(netEncM, trainloader, device, N_MASKS)\n            scoreAccVal, scoreIoUVal = evaluate(netEncM, valloader, device, N_MASKS)\n            print(\"train:\", scoreAccTrain, scoreIoUTrain)\n            print(\"val:\", scoreAccVal, scoreIoUVal)\n            try:\n                with open( 'train.dat', 'a') as f:\n                    f.write(str(iteration) + ' ' + str(scoreAccTrain) + ' ' + str(scoreIoUTrain) + '\\n')\n            except:\n                print(\"Cannot save in train.dat\")\n            try:\n                with open( 'val.dat', 'a') as f:\n                    f.write(str(iteration) + ' ' + str(scoreAccVal) + ' ' + str(scoreIoUVal) + '\\n')\n            except:\n                print(\"Cannot save in val.dat\")\n            try:\n                vutils.save_image(out_X.view(-1,N_X,SIZE_X, SIZE_X), \"out_%05d.png\" % iteration, normalize=True, range=(-1,1), nrow=N_TEST+5)\n            except:\n                print(\"Cannot save output\")\n        netEncM.zero_grad()\n        netGenX.zero_grad()\n        netDX.zero_grad()\n        stateDic = {\n            'netEncM': netEncM.state_dict(),\n            'netGenX': netGenX.state_dict(),\n            'netDX': netDX.state_dict(),\n            'optimizerEncM': optimizerEncM.state_dict(),\n            'optimizerGenX': optimizerGenX.state_dict(),\n            'optimizerDX': optimizerDX.state_dict(),\n        }\n        if wrecZ > 0:\n            netRecZ.zero_grad()\n            stateDic['netRecZ'] = netRecZ.state_dict()\n            stateDic['optimizerRecZ'] = optimizerRecZ.state_dict(),\n        try:\n            torch.save(stateDic, 'state.pth')\n        except:\n            print(\"Cannot save checkpoint\")\n        if bestValIoU < scoreIoUVal:\n            bestValIoU = scoreIoUVal\n            try:\n                torch.save(stateDic,  'best.pth')\n            except:\n                print(\"Cannot save best\")\n        \n        pbar = tqdm(total=ITER_STEPS)\n        netEncM.train()\n        netGenX.train()\n        netDX.train()\n        if wrecZ > 0:\n            netRecZ.train()","8d8df637":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.rcParams[\"figure.figsize\"] = (15, 10)\nplt.rcParams[\"figure.dpi\"] = 125\nplt.rcParams[\"font.size\"] = 14\nplt.rcParams['font.family'] = ['sans-serif']\nplt.rcParams['font.sans-serif'] = ['DejaVu Sans']\nplt.style.use('ggplot')\nsns.set_style(\"whitegrid\", {'axes.grid': False})\nplt.rcParams['image.cmap'] = 'gray' # grayscale looks better\nfrom skimage.util import montage\nmontage_rgb = lambda x, **kwargs: np.stack([montage(x[:, :, :, i], **kwargs) for i in range(x.shape[3])], -1)","19ca5d75":"out_image = out_X.view(-1,N_X,SIZE_X, SIZE_X).to('cpu').detach().numpy().swapaxes(1, 3).swapaxes(1,2)\nplt.imshow(montage_rgb(out_image, grid_shape=(13, 10)))","827d3185":"# Model\nHere we setup the model (cell is hidden) with the various sub-modules and layers required for this specific problem","585ce977":"# Overview\n\nThe idea is to learn to segment images into foreground and background without explicitly labeling them as such. The model works by having the unsupervised segmentation divide the images into two classes and then redraw one class. \n\n# Setup\n\nThe notebook takes the code (directly stolen) from https:\/\/github.com\/mickaelChen\/ReDO and wraps it together into a self-contained notebook for training on the flower problem.\n\n","64387a3c":"## Assemble Models","6c7a39f1":"## Parameters\nWe initialize the devices, dimensions, filter counts and training parameters in the following block. These can all be tweaked for different datasets and to optimize training","11689800":"# Setup Training","cabf0a54":"## Show Output","606b5888":"Initialize weights","8bd30695":"## Dataset Loaders\nFor this notebook we just focus on the flower and segmentation dataset and so just have this loaded. ","1970b460":"# Run Training Loop"}}