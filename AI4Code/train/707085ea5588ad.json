{"cell_type":{"4a22aa53":"code","3a563880":"code","eedce80d":"code","4604074b":"code","bcd0b7f7":"code","c17189dc":"code","3e306075":"code","790fbee4":"code","810f33ec":"code","159ce4f0":"code","1b2b288f":"code","b0294d62":"code","49e34e37":"code","ee307afb":"code","4801c232":"code","9482824e":"code","c88f2248":"code","69b375e9":"code","4dd98a79":"code","0cb51411":"code","f29ec23f":"code","03b6a7e0":"code","42e3e22b":"code","c34c7f19":"markdown","4fd3479f":"markdown","ab9b1064":"markdown","71fcf67f":"markdown","1bebbcea":"markdown","b30b774a":"markdown","297339af":"markdown","2c3ddca1":"markdown","1667acf3":"markdown","e34ec236":"markdown","4d5ca7ee":"markdown","3f837584":"markdown","7265e070":"markdown"},"source":{"4a22aa53":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nimport seaborn as sns\nimport lightgbm as lgb\nfrom sklearn.model_selection import GroupKFold,StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nfrom sklearn import metrics\n\nprint(os.listdir(\"..\/input\"))","3a563880":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","eedce80d":"train.head()","4604074b":"print (\"Total Train Set : %d\" %len(train))\nprint ('Total Test Set : %d' %len(test))","bcd0b7f7":"train['scalar_coupling_constant'].describe()","c17189dc":"sns.distplot(train['scalar_coupling_constant'])","3e306075":"typelist = list(train['type'].value_counts().index)\ntypelist","790fbee4":"plt.figure(figsize=(26, 24))\nfor i, col in enumerate(typelist):\n    plt.subplot(4,2, i + 1)\n    sns.distplot(train[train['type']==col]['scalar_coupling_constant'],color ='orange')\n    plt.title(col)","810f33ec":"structures = pd.read_csv('..\/input\/structures.csv')","159ce4f0":"structures.head()","1b2b288f":"#https:\/\/www.kaggle.com\/inversion\/atomic-distance-benchmark\/output\ndef map_atom_info(df, atom_idx):\n    df = pd.merge(df, structures, how = 'left',\n                  left_on  = ['molecule_name', f'atom_index_{atom_idx}'],\n                  right_on = ['molecule_name',  'atom_index'])\n    \n    df = df.drop('atom_index', axis=1)\n    df = df.rename(columns={'atom': f'atom_{atom_idx}',\n                            'x': f'x_{atom_idx}',\n                            'y': f'y_{atom_idx}',\n                            'z': f'z_{atom_idx}'})\n    return df\n\ntrain = map_atom_info(train, 0)\ntrain = map_atom_info(train, 1)\n\ntest = map_atom_info(test, 0)\ntest = map_atom_info(test, 1)","b0294d62":"train.head()","49e34e37":"#https:\/\/www.kaggle.com\/inversion\/atomic-distance-benchmark\/output\n\ntrain['dist'] = ((train['x_1'] - train['x_0'])**2 +\n             (train['y_1'] - train['y_0'])**2 +\n             (train['z_1'] - train['z_0'])**2 ) ** 0.5\n\ntest['dist'] = ((test['x_1'] - test['x_0'])**2 +\n             (test['y_1'] - test['y_0'])**2 +\n             (test['z_1'] - test['z_0'])**2 ) ** 0.5","ee307afb":"molecules = train.pop('molecule_name')\ntest = test.drop('molecule_name', axis=1)\nid_train = train.pop('id')\nid_test = test.pop('id')\n\ny = train.pop('scalar_coupling_constant')\n\n# Label Encoding\nfor f in ['type', 'atom_0', 'atom_1']:\n    lbl = LabelEncoder()\n    lbl.fit(list(train[f].values) + list(test[f].values))\n    train[f] = lbl.transform(list(train[f].values))\n    test[f] = lbl.transform(list(test[f].values))","4801c232":"train.head()","9482824e":"## Evaluate matric\n## https:\/\/www.kaggle.com\/abhishek\/competition-metric\ndef metric(df, preds):\n    df[\"prediction\"] = preds\n    maes = []\n    for t in df.type.unique():\n        y_true = df[df.type==t].scalar_coupling_constant.values\n        y_pred = df[df.type==t].prediction.values\n        mae = np.log(metrics.mean_absolute_error(y_true, y_pred))\n        maes.append(mae)\n    return np.mean(maes)\n#df for evaluate\neval_df = pd.DataFrame({\"type\":train[\"type\"]})\neval_df[\"scalar_coupling_constant\"] = y","c88f2248":"n_splits = 5 # Number of K-fold Splits\n\nsplits = list(GroupKFold(n_splits=n_splits).split(train, y, groups=molecules))\nsplits[:3]","69b375e9":"params = {\"learning_rate\" : 0.1,\n          \"depth\": 9,\n          'metric':'MAE',\n          'min_samples_leaf': 3,\n          \"loss_function\": \"MAE\"}","4dd98a79":"oof = np.zeros(len(train))\npredictions = np.zeros(len(test))\nfeature_importance_df = pd.DataFrame()\nfeatures = [c for c in train.columns if c not in ['id']]\n\nfor i, (train_idx, valid_idx) in enumerate(splits):  \n    print(f'Fold {i + 1}')\n    x_train = np.array(train)\n    y_train = np.array(y)\n    trn_data = lgb.Dataset(x_train[train_idx.astype(int)], label=y_train[train_idx.astype(int)])\n    val_data = lgb.Dataset(x_train[valid_idx.astype(int)], label=y_train[valid_idx.astype(int)])\n    \n    num_round = 10000\n    clf = lgb.train(params, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=500, early_stopping_rounds = 200)\n    oof[valid_idx] = clf.predict(x_train[valid_idx], num_iteration=clf.best_iteration)\n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"feature\"] = features\n    fold_importance_df[\"importance\"] = clf.feature_importance()\n    fold_importance_df[\"fold\"] = i + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    #predictions[fake_data.index] += clf.predict(fake_data, num_iteration=clf.best_iteration) \/ n_splits\n    predictions += clf.predict(test, num_iteration=clf.best_iteration) \/ n_splits\n\n#print(\"CV score: {:<8.5f}\".format(np.log(metrics.mean_absolute_error(train, oof))))","0cb51411":"print(\"CV score: {:<8.5f}\".format(metric(eval_df, oof)))","f29ec23f":"cols = (feature_importance_df[[\"feature\", \"importance\"]]\n        .groupby(\"feature\")\n        .mean()\n        .sort_values(by=\"importance\", ascending=False)[:1000].index)\nbest_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\n\nplt.figure(figsize=(14,5))\nsns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\",ascending=False))\nplt.title('LightGBM Features (averaged over folds)')\nplt.tight_layout()\nplt.savefig('lgbm_importances.png')","03b6a7e0":"sample_submission = pd.read_csv('..\/input\/sample_submission.csv')\n\nbenchmark = sample_submission.copy()\nbenchmark['scalar_coupling_constant'] = predictions\nbenchmark.to_csv('LGBM_submission.csv',index=False)","42e3e22b":"benchmark.head()","c34c7f19":"## Label Encoding","4fd3479f":"## Structure X\/Y\/Z","ab9b1064":"## Simple EDA and LightGBM model\n* 5-fold cross validation\n* easy feature engineering and EDA","71fcf67f":"## Plot feature important","1bebbcea":"## Training","b30b774a":"## Submission","297339af":"## Train \/ Test Set","2c3ddca1":"the training set, where the first column (molecule_name) is the name of the molecule where the coupling constant originates (the corresponding XYZ file is located at .\/structures\/.xyz), the second (atom_index_0) and third column (atom_index_1) is the atom indices of the atom-pair creating the coupling and the fourth column (scalar_coupling_constant) is the scalar coupling constant that we want to be able to predict","1667acf3":"## Future work\n* EDA on Additional data\n* More FE\n* NN model build","e34ec236":"## Merge the train set and structure set","4d5ca7ee":"## FE - Distance of atom","3f837584":"### Target : scalar_coupling_constant\n","7265e070":"### Plot type \/ target correlation\nLooks each type have some correlate to target"}}