{"cell_type":{"18fe3fc8":"code","326de9a3":"code","d5577d55":"code","f8cf7c91":"code","d6191fd6":"code","928eeb30":"code","0ec3425f":"code","50b8d28e":"markdown"},"source":{"18fe3fc8":"from tokenizers import BertWordPieceTokenizer","326de9a3":"# Initialize an empty BERT tokenizer\ntokenizer = BertWordPieceTokenizer(\n  clean_text=False,\n  handle_chinese_chars=False,\n  strip_accents=False,\n  lowercase=True,\n)","d5577d55":"files = ['..\/input\/bengali-oscar-corpus\/bn_dedup.txt']\nfiles","f8cf7c91":"# train BERT tokenizer\ntokenizer.train(\n  files,\n  vocab_size=32000,\n  min_frequency=2,\n  show_progress=True,\n  special_tokens=['[PAD]', '[UNK]', '[CLS]', '[SEP]', '[MASK]'],\n  limit_alphabet=1000,\n  wordpieces_prefix=\"##\"\n)","d6191fd6":"tokenizer.save('.\/')\n# tokenizer.save_model(path)","928eeb30":"!head -20 .\/vocab.txt","0ec3425f":"!tail -20 .\/vocab.txt","50b8d28e":"# Building Bengali Vocab File for BERT\n\nIn this notebook, I will show you how you can build bengali vocab file for BERT Model using huggingface `tokenizer`"}}