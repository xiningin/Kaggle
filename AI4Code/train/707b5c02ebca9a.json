{"cell_type":{"24aeec80":"code","ae6572d9":"code","7072891d":"code","771cc936":"code","ffe21b18":"code","1ad19b11":"code","21700663":"code","db7ffaa6":"code","60ec87df":"code","5197e9c0":"code","9dce2736":"code","805a0f6b":"code","5b2c4ec4":"code","e91098da":"code","9406f9cd":"code","846caa5a":"code","bdfd403b":"code","19af1c2d":"code","5ebd92d3":"code","d79a50ef":"code","ef527dfa":"code","ebb64f47":"code","56087baa":"code","7470cd0c":"code","80e41c50":"code","6acea776":"code","8d27e8da":"code","7dcd188b":"code","640ef0d4":"code","928c1e34":"code","5ad26f94":"code","4159f968":"code","e5c1bc17":"code","3ac82354":"code","f4b78243":"code","faae7929":"code","23475828":"code","c9172cad":"code","0c602182":"markdown","dd010655":"markdown","81dec93d":"markdown","d34040f4":"markdown","6208584a":"markdown","0ccf4bfc":"markdown","a453ff0c":"markdown","60fdccfd":"markdown","73bfdc8d":"markdown","1ad01b58":"markdown","84a5d65f":"markdown","50aea9a1":"markdown","39736928":"markdown","cca73121":"markdown","56b4f55a":"markdown","c048ace6":"markdown","95afca6c":"markdown","fc92bc43":"markdown","3e99e23d":"markdown","16d52bc5":"markdown","2cf383c3":"markdown","b090345e":"markdown","09b6f432":"markdown","99a926dc":"markdown","cd48bea3":"markdown","70a8c225":"markdown","f6019a04":"markdown","e553acdc":"markdown","15f06d10":"markdown"},"source":{"24aeec80":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import IsolationForest, RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC","ae6572d9":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\npid = test['PassengerId']\ndata = pd.concat([train, test], axis=0).reset_index(drop=True)","7072891d":"data","771cc936":"data.info()","ffe21b18":"data.describe()","1ad19b11":"data.drop('Cabin', axis=1, inplace=True)","21700663":"g = sns.catplot(x=\"SibSp\", y=\"Survived\", data=data, kind=\"bar\")\ng = g.set_ylabels(\"Survival Probability\")","db7ffaa6":"g = sns.catplot(x='Parch', y='Survived', kind='bar', data=data)\ng.set_ylabels('Survival Probability')","60ec87df":"plt.figure(figsize=(16,5))\nplt.subplot(1,2,1)\ng = sns.distplot(data.loc[data['Survived']==0].Age)\ng.set_title('Age Density of those who did not survive')\n\nplt.subplot(1,2,2)\ng = sns.distplot(data.loc[data['Survived']==1].Age)\ng.set_title('Age Density of those survived')\nplt.show()\n\nplt.figure(figsize=(16,5))\ns = sns.kdeplot(data[data['Survived'] == 0].Age, color=\"red\", label=\"Not Survived\", shade=True)\ns = sns.kdeplot(data[data['Survived'] == 1].Age, color=\"blue\", label=\"Survived\", shade=True)\ns.set_title(\"Survived Age Density\")\ns.set_ylabel(\"Density\")\ns.set_xlabel(\"Age\")\n\nplt.show()","5197e9c0":"data.Fare.fillna(value=data['Fare'].median(), axis=0, inplace=True)","9dce2736":"plt.figure(figsize=(16,5))\nplt.subplot(1,2,1)\ng = sns.distplot(data.loc[data['Survived']==0].Fare)\ng.set_title('Fare Density of those who did not survive')\n\nplt.subplot(1,2,2)\ng = sns.distplot(data.loc[data['Survived']==1].Fare)\ng.set_title('Fare Density of those survived')\nplt.show()\n\nplt.figure(figsize=(16,5))\ns = sns.kdeplot(data[data['Survived'] == 0].Fare, color=\"red\", label=\"Not Survived\", shade=True)\ns = sns.kdeplot(data[data['Survived'] == 1].Fare, color=\"blue\", label=\"Survived\", shade=True)\ns.set_title(\"Survived Fare Density\")\ns.set_ylabel(\"Density\")\ns.set_xlabel(\"Fare\")\nplt.show()","805a0f6b":"S = data[['Fare', 'Survived']].copy()\nS['Fare'] = np.log(S['Fare']).replace(-np.inf, 0)\n\nplt.figure(figsize=(16,5))\nplt.subplot(1,2,1)\ng = sns.distplot(S.loc[S['Survived']==0].Fare)\ng.set_title('Fare Density of those who did not survive')\n\nplt.subplot(1,2,2)\ng = sns.distplot(S.loc[S['Survived']==1].Fare)\ng.set_title('Fare Density of those survived')\nplt.show()\n\nplt.figure(figsize=(16,5))\ns = sns.kdeplot(S[S['Survived'] == 0].Fare, color=\"red\", label=\"Not Survived\", shade=True)\ns = sns.kdeplot(S[S['Survived'] == 1].Fare, color=\"blue\", label=\"Survived\", shade=True)\ns.set_title(\"Survived Fare Density\")\ns.set_ylabel(\"Density\")\ns.set_xlabel(\"Fare\")\nplt.show()","5b2c4ec4":"g = sns.catplot(x='Sex', y='Survived', kind='bar', data=data)\ng.set_ylabels(\"Survival Probability\")","e91098da":"g = sns.catplot(x='Pclass', y='Survived', kind='bar', data=data)\ng.set_ylabels(\"Survival Probability\")","9406f9cd":"data.Embarked.fillna(data.Embarked.mode()[0], inplace=True)","846caa5a":"g = sns.catplot(x='Embarked', kind='count', data=data)\ng.set_ylabels(\"Count\")","bdfd403b":"g = sns.catplot(x='Embarked', y='Survived', kind='bar', data=data)\ng.set_ylabels(\"Survival Probability\")","19af1c2d":"g = sns.catplot(\"Pclass\", col=\"Embarked\",  data=data, kind=\"count\")\ng = g.set_ylabels(\"Count\")","5ebd92d3":"data['Fsize'] = data['Parch'] + data['SibSp']","d79a50ef":"g = sns.catplot(x='Fsize', kind='count', data=data)","ef527dfa":"g = sns.catplot(x='Fsize', y='Survived', kind='bar', data=data)\ng.set_ylabels('Survival Probability')","ebb64f47":"data.drop(['SibSp','Parch'], axis=1, inplace=True)","56087baa":"for i, row in data.iterrows():\n    data.loc[i,'Title'] = row['Name'].split(',')[1].split('.')[0].strip()","7470cd0c":"plt.figure(figsize=(16,5))\ng = sns.countplot(x='Title', data=data)\ng = plt.setp(g.get_xticklabels(), rotation=\"vertical\") ","80e41c50":"row = data['Title'].values\nfor i in range(len(row)):\n    if row[i] not in ['Mr','Mrs','Miss','Master']:\n        row[i] = \"Rare\"\n        \ndata['Title'] = row","6acea776":"plt.figure(figsize=(5,5))\ng = sns.countplot(x='Title', data=data)","8d27e8da":"data.drop('Name', axis=1, inplace=True)","7dcd188b":"avg_age = data[data['PassengerId']<pid[0]].groupby(['Pclass', 'Embarked', 'Sex'])['Age'].mean()\nfor i, row in data.iterrows():\n    if np.isnan(data.loc[i,'Age']):\n        data.loc[i,'Age'] = avg_age[data.loc[i,'Pclass'], data.loc[i,'Embarked'], data.loc[i,'Sex']]","640ef0d4":"data = pd.get_dummies(data, columns=['Embarked'], prefix='Embarked')\ndata = pd.get_dummies(data, columns=['Pclass'], prefix='Pclass')\ndata = pd.get_dummies(data, columns=['Sex'], prefix='Sex')\ndata = pd.get_dummies(data, columns=['Title'], prefix='Title')\ndata.drop('Ticket', axis=1, inplace=True)\n\ntrain=data[data['PassengerId']<pid[0]]\ntest = data[data['PassengerId']>=pid[0]].drop('Survived', axis=1).reset_index(drop=True)\ndata.reset_index()","928c1e34":"train.head()","5ad26f94":"test.head()","4159f968":"model = IsolationForest(contamination=0.02)\nmodel.fit(train)\npred = model.predict(train)\n\nlst=[]\nfor i in range(len(pred)):\n    if (pred[i]==-1):\n        lst.append(i)\ntrain.drop(lst, inplace=True)\n","e5c1bc17":"train.info()","3ac82354":"model_name = ['Logistic Regression', 'K-Neighbors Classifier', \n          'Decision Tree', 'Support Vector Classifier', 'Random Forest Classifier']\nmodel_classifier = [LogisticRegression(), KNeighborsClassifier(n_neighbors=5), DecisionTreeClassifier(),\n                   SVC(), RandomForestClassifier()]\nmodel_acc = []","f4b78243":"from sklearn.model_selection import train_test_split\ntrain_x, train_val_x, train_y, train_val_y = train_test_split(train.drop('Survived', axis=1), train.Survived, test_size=0.2)","faae7929":"print(train_x.shape, train_y.shape, train_val_x.shape, train_val_y.shape)","23475828":"from sklearn.metrics import accuracy_score\nfor i in range(len(model_name)):\n    clf = model_classifier[i]\n    clf.fit(train_x, train_y)\n    model_acc.append(accuracy_score(clf.predict(train_val_x), train_val_y))\n","c9172cad":"df = pd.DataFrame({\"Classifier type\":model_name, \"Accuracy\":model_acc})\ndf","0c602182":"The individual age distributions look like gaussian distribution with a slight exception in the category of passengers of age 0-5, i.e. infants. We can also see that on a compared study, passengers with less age, i.e., children have a higher chance of survival. We can also notice the slight height in the histograms in the 75-80 age range. Thos shows that the youngest and the oldest of the passengers had a greater chance of survival.","dd010655":"## 2. Data Filtering","81dec93d":"### 2.8 Embarked","d34040f4":"The distribution is very skewed and it is difficult to infer anything from such a distribution. So we will plot the distribution curves for the log of the fare values. Remember, we need to assign a value explicitly for the cases where the fare is zero since the its log will turn out to be negative infinity.","6208584a":"The simple inference, that can be drawn, are that the passengers with almost zero fare are very less likely to survive.","0ccf4bfc":"### 3.4 Final Preprocessing","a453ff0c":"We can see that passengers travelling with no spouses\/siblings or 3 or more siblings\/spouses had less chances of survival when compared to passengers travelling with 1 or 2 siblings\/spouses.","60fdccfd":"Before plotiting any graphs, we will just add the most occurred value in the 2 rows with the missing values in the Embarked columns with the help of the mode() function on the corresponding column.","73bfdc8d":"### 2.7 Pclass (Passenger Class)","1ad01b58":"Combining the results of analysis of Parch (section 2.3) and SibSp (section 2.2), we can see and confirm the analysis that passengers with no family or a large family have a lesser survival rate than people with smaller families.","84a5d65f":"# Titanic\n\nhttps:\/\/www.kaggle.com\/c\/titanic\n\nThis is my first ever notebook on kaggle. I went through some EDA notebooks before creating my own, so some parts of it might look similar, and if it does then I take no credit. I am just learning. Hope you like this notebook !!","50aea9a1":"### 2.4 Age","39736928":"### 3.3 Fill Missing Age\n\nBelow, the dataset has been grouped under the categorical varibales 'Pclass', 'Sex' and 'Embarked' and the passengers whose age is missing, will be filled according to the mean of the subset of that grouped data correspopnding to the said passenger.","cca73121":"### 3.5 Removal of Outliers","56b4f55a":"### 2.3 Parch (Parents\/Children)","c048ace6":"The people who embarked at the port of Cherbourg(C) had the highest survival rate although 60% - 65% passengers embarked at the port of Southampton(S).","95afca6c":"We can notice that passengers travelling with no parents\/children or with a large family are less likely to survive than people with small families. For the case of 3 parents\/children, we see a very high standard deviation which might indicate that a different property is affecting this particular case.","fc92bc43":"### 3.1 Family Size (Parents\/Children + Siblings\/Spouses)","3e99e23d":"The survival rate of the passengers decreased as the class number increased.It is safe to assume the the priority was given to the first class passengers and then the others.","16d52bc5":"It can be clearly seen that female passengers had almost 74% survival rate which is very high with respect to the 19% survival rate (approximately) for the male passengers, which also seems logical during an emergency like the Titanic accident.","2cf383c3":"## 4. Model, train, predict","b090345e":"### 2.2 SibSp (Siblings\/Spouses)","09b6f432":"### 2.1 Cabin\n\nWe see that about 77% of the data has its cabin data missing so it will be very difficult to find any statistical correlation of the survival status of the passengers with their cabins. So we can simply drop that column.","99a926dc":"### 2.6 Age","cd48bea3":"### 3.2 Title in Name","70a8c225":"## 3. Feature addition and Pre-processing","f6019a04":"### 2.5 Fare\n\nWe saw that we have one entry missing in the Fare column, so let;\\'s fill it with the md=edian value of the Fare in the entire dataset.","e553acdc":"With the introduction of new columns of categorical varibales and the accuracy obtained in the above trial gives a good level of confidence that Logistic Regression will work the best in achieving highest accuracy.","15f06d10":"## 1. Data Collection\n\nWe will read the data first and keep the passenger ids of the test case separately for future reference.<br>\nWe will then conjoin the training and test datasets into a single dataset to have diffrent simple observations like unimportant data or data with missing values to get the required preliminary inferences."}}