{"cell_type":{"14bbd0f1":"code","7127749d":"code","5e40de4d":"code","e7780af1":"code","75936295":"code","05847ff4":"code","21f87d1c":"code","762f55ad":"code","1b199725":"code","b08e26d6":"code","ea5c4b4c":"code","ea9924df":"code","709440e8":"code","87d4e0bb":"code","0915ff02":"code","90afe3a7":"code","5e40130c":"code","3a2f6e65":"markdown","8631f7d9":"markdown","98e3c829":"markdown","931867a0":"markdown","2ccdcf8d":"markdown","d3e73385":"markdown","fac674d2":"markdown","d7b1c2b5":"markdown","0545d229":"markdown","b5d3d492":"markdown","b8674e11":"markdown","c4478423":"markdown","79f29e23":"markdown","63d3f138":"markdown","36621368":"markdown","3c17d466":"markdown","ac478cb0":"markdown","4afc3809":"markdown","06b2b632":"markdown","b7279993":"markdown","5f9e6d90":"markdown","f4613042":"markdown","a11cfe95":"markdown","debd2ace":"markdown","3b571f5a":"markdown","5b8f7a09":"markdown","6d5243d2":"markdown","d7124d97":"markdown","205aee7a":"markdown","acfe5ff9":"markdown","f128d8b5":"markdown","d951643d":"markdown","b8dc466b":"markdown","dfd078d9":"markdown","1f041ed5":"markdown"},"source":{"14bbd0f1":"from tensorflow import keras\nkeras.__version__\nprint('hello, world')\nprint(\"Welcome to use Jupyter Notebook\")\nprint(\"hello, everyone!\")","7127749d":"from tensorflow.keras.datasets import mnist\n(train_images, train_labels), (test_images, test_labels) = mnist.load_data()","5e40de4d":"digit = train_images[0]\n\nimport matplotlib.pyplot as plt\nplt.imshow(digit, cmap=plt.cm.binary)\nplt.show()","e7780af1":"train_images.shape","75936295":"len(train_labels)","05847ff4":"train_labels","21f87d1c":"test_images.shape","762f55ad":"len(test_labels)","1b199725":"test_labels","b08e26d6":"from tensorflow.keras import layers\nnetwork = keras.Sequential([\n    layers.Dense(512, activation=\"relu\",input_shape=(28 * 28,)),\n    layers.Dense(10, activation=\"softmax\")\n])\n\n#from keras import models\n#from keras import layers\n\n#network = models.Sequential()\n#network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n#network.add(layers.Dense(10, activation='softmax'))","ea5c4b4c":"import numpy as np\nz = [1.0, 2.0, 3.0, 7.0, 1.0, 1.0, 2.0, 3.0, 4.0, 1.0]\nnp.exp(z) \/ np.sum(np.exp(z))  ","ea9924df":"network.compile(optimizer='rmsprop',\n                loss='categorical_crossentropy',\n                metrics=['accuracy'])","709440e8":"train_images = train_images.reshape((60000, 28 * 28))\ntrain_images = train_images.astype('float32') \/ 255\n\ntest_images = test_images.reshape((10000, 28 * 28))\ntest_images = test_images.astype('float32') \/ 255","87d4e0bb":"from tensorflow.keras.utils import to_categorical\n\ntrain_labels = to_categorical(train_labels)\ntest_labels = to_categorical(test_labels)\ntrain_labels\ntest_labels","0915ff02":"network.fit(train_images, train_labels, epochs=5, batch_size=128)","90afe3a7":"test_loss, test_acc = network.evaluate(test_images, test_labels)","5e40130c":"print('test_acc:', test_acc)","3a2f6e65":"## Training data and test data\n\n**Training data:** data used for training an ANN.  \n\n`train_images` and `train_labels` form the \"training set\", the data that the model will learn from. \n\n**Test data:** data used to test the performance of an ANN. The model will then be tested on the \n\"test set\", `test_images` and `test_labels`. \n\nOur images are encoded as Numpy arrays, and the labels are simply an array of digits, ranging from 0 to 9. There is a one-to-one correspondence between the images and the labels.","8631f7d9":"## Workflow of applying ANN\n1. present ANN with the training data, `train_images` and `train_labels`. \n2. ANN learn to associate images and labels \n3. ANN produces predictions for `test_images`, and verify if these predictions match the labels from `test_labels`.","98e3c829":"## Deep neural networks (multilayer perceptron) \n\nMultilayer perceptron (MLP) is a class of feedforward artificial neural networks. Deep neural network (DNN) uses multiple hidden layers between the input and output layer. \"Deep\" referes to many layers. Figure: a deep multilayer perceptron ((https:\/\/medium.com))\n![image.png](attachment:image.png) \n\n* Input layer: input data,e.g. a digit image. The image will be encoded into a numerical array ($x_1, \\cdots, x_n$).  ANNs cannot handle catogorical values like \"good\", \"bad\". They must be encoded into numerical values like \"1 = good\", \"0 = bad\" \n* Hidden layer: process data\n* Output layer: output result, e.g. the probability of the label: $0,1, \\cdots, 9$\n* Node: called neuron, an information processing unit\n* Forward network: no backward or loop\n* Dense: completely connected\n* Weights: represent the importance of an input. Adjustable for best fitting the input","931867a0":"## Build an ANN ","2ccdcf8d":"## Data normalization\n\nBefore training, data are preprocessed: reshaping it into the shape that the network expects, and scaling it so that all values are in \nthe `[0, 1]` interval.\n\nPreviously, our training images for instance were stored in an array of shape `(60000, 28, 28)` of type `uint8` with values in the `[0, 255]` interval. \n\nWe transform it into a `float32` array of shape `(60000, 28 * 28)` with values between 0 and 1.","d3e73385":"## Why Python for machine learning\nPython is a general-purpose programming language.\n* interpreted\n* high-level\n* Top One programming language in 2019 (https:\/\/spectrum.ieee.org\/computing\/software\/the-top-programming-languages-2019)\n![image.png](attachment:image.png)\n* the most popular programming language for machine learning\n* much easier to learn than mst programming languages\n","fac674d2":"## Understand data\n\nThe MNIST dataset is pre-loaded in Keras for deep learning\n\nThe data is in the form of a set of four Numpy arrays.\n\nLoad the MNIST dataset.\n\nChange: <span style=\"color: red;\">**from tensorflow.keras.datasets import mnist**<\/span>","d7b1c2b5":"# Practical Deep Learning for Data Analysis with Python\n\n\nJun He (jun.he@ntu.ac.uk)\n\nThese notebooks are based on Chollet (2018) \"Deep learning with Python\".\n\nIn the part of deep learning, you will\n\n1. learn deep learning learning for data analysis with Python language (Keras)\n2. learn deep artificial neural networks (multi-layer perceptron) for classification and regression\n2. learn convolutional neural networks for computer vision \n3. learn recurrent neural networks for text data\n4. develop Python programming skill for machine learning\n\nAfter the study of this part, you are expected to \n1. have an eseential understanding of deep learning\n2. are able to implement simple deep learning for data analysis project with Python\n\nOur focus is on practical use of machine learning with Python, rather than mathematical understanding of deep learning.","0545d229":"## Neuron\n\nA basic information processing unit. An MLP consists of neurons. Figure: a neuron (https:\/\/medium.com)\n![image.png](attachment:image.png)\n1. weighted sum of input values\n$$\nsum = x_1 w_1 +\\cdots + x_n w_n +b\n$$\n$b$ is called a bias. It is a constant, not an input\n\n2. convert the sum into an output using an activation function \n$$\noutput = f(sum)\n$$\nThere exist different activation functions. For example, the rectifier is an activation function defined as the positive part of its argument:\n$$\nReLU(x) =\\max (x,0)\n$$\nA neuron employing the rectifier is  called a rectified linear unit (ReLU) \n","b5d3d492":"Show the lables of images","b8674e11":"Check lable length","c4478423":"# Keras\nKeras is a Python deep-learning framework. Using Keras, it is easy to define and train deep-learning models. It is a high-level library which supports all low-level deep learning libraires such as TensorFlow.\n\nKeras's features:\n1. Write the same code and run seamlessly on both CPU or GPU.\n2. API is user-friendly API. It is quick to prototype deep-learning models.\n3. Built-in support for convolutional networks (for computer vision), recurrent networks (for sequence processing), and any combination of both.\n4. Supports arbitrary ANN architectures: multi-input or multi-output models, layer sharing, model sharing, and so on. This means Keras is appropriate for building essentially any deep-learning model.","79f29e23":"## Survey Quesion\nHave you learned Python language before?\n1. Yes\n2. No\n\nHave you learned machine learning \/ data mining before?\n1. Yes\n2. No","63d3f138":"## Evaluate Performance of ANN \nEvaluate model performs  on the test set ","36621368":"We build and a train a neural network to classify handwritten digits, in less than 20 lines of Python code.  ","3c17d466":"Show the 1st sample in the data set. Note: the index starts from 0.\n\nQuestion: which digit is in the image?","ac478cb0":"# Deep learning (1): Deep Artificial Neural Networks with Python\n## Learning objectives\n\n1.\tIntroduce Python for deep learning using librairy Keras.\n2.\tUse Jupyter notebook\n3.\tUndestand tensor and tensor operations\n4.\tRevisit artificial neural networks\n5.\tImplement ANNs with Keras for classification\n6.  Implement ANNs with Keras for regression\n","4afc3809":"## Three things in compilation of ANN\nTo make our network ready for training, we need to pick three more things, as part of \"compilation\" step:\n\n* A loss function: the is how the network will be able to measure how good a job it is doing on its training data, and thus how it will be \nable to steer itself in the right direction.\n* An optimizer: this is the mechanism through which the network will update itself based on the data it sees and its loss function.\n* Metrics to monitor during training and testing. Here we will only care about accuracy (the fraction of the images that were correctly \nclassified).\n\nThe more detailed meaning of the loss function and the optimizer will be made clear later","06b2b632":"## Activity: register with Kaggle\n\nGo to https:\/\/www.kaggle.com\/kernels and register with Kaggle\n\nSay yes, after registration\n ","b7279993":"## Softmax activation function:    \nAlso called normalized exponential function\n1. The softmax function takes as input a vector $z$ of $K$ real numbers\n2. Normalizes it into a probability distribution consisting of $K$ probabilities proportional to the exponentials of the input numbers.  \n3. The larger input components will correspond to larger probabilities.\n$$\n\\sigma(\\mathbf{z})_i  =\\frac{e^{z_i}} {\\sum^K_{j=1} e^{z_j}}, \\quad \\mbox{for } i=1, \\cdots, K,  \\mbox{and } \\mathbf{z} =(z_1, \\cdots, z_K) \n$$\nExample: For an input $\\mathbf{z}= [1.0, 2.0, 3.0, 7.0, 1.0, 1.0, 2.0, 3.0, 4.0, 1.0]$,  its softmax output is $[0.00223349, 0.00607127, 0.01650341, 0.90105575, 0.00223349,\n       0.00223349, 0.00607127, 0.01650341, 0.04486092, 0.00223349]$. The fouth input component has a 90\\% probablity. Suppose it represents the digit `3`  ","5f9e6d90":"Check the test data shape","f4613042":"## Textbooks\n1. Chollet, F. (2018). Deep learning with Python. avaiable at https:\/\/www.manning.com\/books\/deep-learning-with-python\n\nA classic book and primer on deep learning with Python. Keras is a popular library for deep learning. \n\nThe author Chollet is the creator of Keras.\n\nThe book is one of the best books for beginners to learn deep learning with Python. \n\n2. Goodfellow, I., Bengio, Y., Courville, A. (2016). Deep learning. Cambridge: MIT press. avaiable at https:\/\/www.deeplearningbook.org\/\n\nA classic textbook book on deep learning. This is an advanced book requiring mathematic knowledge such as linear algebra, probability, calculus. If you want to carry on deep learning to the advanced level, this is the best book.  \n\nAuthors are big names in deep learning. Bengio was a co-recipient of the 2018 ACM A.M. Turing Award for his work in deep learning, regarded as one of Godfathers of Deep Learning.\n","a11cfe95":"# Kaggle Kernels\nKaggle.com is a subsidiary of big name Google LLC\n\nProvide an online community of data science and machine learning practitioners.\n\n* find and publish data sets\n* explore and build models in clouds\n* work with other coollabrators\n* take part in competitions to solve data science challenges\n\nKaggle kernel is a cloud computational environment that enables running of Jupyter noteboos. ","debd2ace":"\nOur test set accuracy turns out to be 97.8% -- that's quite a bit lower than the training set accuracy. \nThis gap between training accuracy and test accuracy is an example of \"overfitting\", \nthe fact that machine learning models tend to perform worse on new data than on their training data. \n","3b571f5a":"## Jupyter Notebook\nJupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. \n\nUses include: data cleaning and transformation, numerical simulation, statistical modeling, data visualization, machine learning, and much more\n\nAdvantage: eidt and run live code\n\nExample: the following code import Keras libary and check its version and print `hello, world'","5b8f7a09":"## Layer and Neuron\n**Layer:** the building block of ANNs. Two layers in the above model.\n\nnetwork = models.Sequential()\nnetwork.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\nnetwork.add(layers.Dense(10, activation='softmax'))\n\n**Neuron:** a data-processing unit, which add inputs together with weight and then through activation function, convert the weighted sum to an output.\n\nLayers extract _representations_ out of the data fed into them -- hopefully \nrepresentations that are more meaningful for the problem at hand. \n\nMost of deep learning really consists of chaining together simple layers which will implement a form of progressive \"data distillation\". \n\nA deep learning model is like a sieve for data processing, made of a \nsuccession of increasingly refined data filters -- the \"layers\".\n\nThe above ANN consists of a sequence of two `Dense` layers, which are  \"fully-connected\"  neural layers.\n\nThe second (and last) layer is a 10-way \"softmax\" layer, which means it will return an array of 10 probability scores (summing to 1). Each \nscore will be the probability that the current digit image belongs to one of our 10 digit classes.\n","6d5243d2":"Check data size","d7124d97":"## Handwritten digist recongition problem\n\nThe problem is to classify grayscale images of handwritten digits (28 pixels x 28 pixels), into their 10 categories (0 to 9). \n\n**Input:** 28 x 28 pixels\n\n**Output:** the probability of images in classes 0, ..., 9\n\nThe dataset is the MNIST dataset, a classic dataset in the machine learning community. It is often taken as an entry problem to deep learning \n\nIt's a set of 60,000 training images, plus 10,000 test  images, assembled by the National Institute of Standards and Technology (the NIST in MNIST) in the 1980s.","205aee7a":"# Relation between Keras and othe deep-learning software\n\nKeras is built upon the top of deep learning libraries. \nHigh level call, so easy to use\n\nFigure: The deep-learning software and hardware stack (Chollet 2018) \n![image.png](attachment:image.png)\n\nGPU (graphics processing unit) is a specialized circuit for processing images. \n \nCUDA (Compute Unified Device Architecture) is a parallel computing platform based on GPU. Designed by Nvidia.\n\nTensorFlow is a open-source software library for dataflow and differentiable programming for machine learning applications such as neural networks, developed by Google.\n\nKeras is a open-source library that provides a Python interface for artificial neural networks. Keras acts as an interface for the TensorFlow library.","acfe5ff9":"## Training ANN\nTo train an ANN, Keras call the `fit` method\n\n\"fit\" the model to its training data.","f128d8b5":"Two quantities are being displayed during training: the \"loss\" of the network over the training data, and the accuracy of the network over \nthe training data.\n\nThe model reach an accuracy of 0.989 (i.e. 98.9%) on the training data.","d951643d":"This is my first Jupyter notbook. \n\nChange: <span style=\"color: red;\">**from tensorflow import keras**<\/span>","b8dc466b":"## Data transformation\n\nANN cannot handle categorical data. Categorically encode the labels\n\nExample, the digit $0 \\to (1,0,0,0,0,0,0,0,0)$ and digit $1\\to (0,1,0,0,0,0,0,0,0)$","dfd078d9":"## Terms\n**class:** a category in classification, e.g., 0, 1, ...,9, ten classes\n\n**sample:** a data point or an instance, e.g., each image is a sample\n\n**lable:** the class of a sample, e.g., the lable for the 6000th image 0","1f041ed5":"Change: <span style=\"color: red;\">**no import models**<\/span>"}}