{"cell_type":{"09bbf9c6":"code","1d02dd49":"code","3cc8bfc0":"code","b3ae39b5":"code","4ef4d7eb":"code","5c7b19b8":"code","5f09d26a":"code","f9e825ea":"code","c6172ee4":"code","ceb86a1b":"code","a50b7f2b":"code","e8481723":"code","6be5d2e5":"code","8806e0d4":"code","3d737ce4":"code","80c48989":"code","4c50f7a0":"code","3ebf3028":"code","19dfe811":"code","21dbcc2f":"code","482f0121":"code","a532862a":"code","d401a943":"code","873f6235":"code","4fe3c3b7":"code","bd539a77":"code","ddd934bc":"code","e94476b6":"code","210d4189":"code","1283a5eb":"code","a9ee09b6":"code","2fb674be":"code","7b07d0b0":"code","1021cd37":"code","2c7ebcfd":"code","8d531cda":"code","1377ff5b":"code","fb3488e1":"code","ca97554f":"code","2c2012d0":"code","cc05af89":"code","36a3d65f":"code","c90a1323":"code","389cb776":"code","52f3a118":"code","4b89fe8e":"code","4c2b471f":"code","4ac43067":"code","0cdbb3af":"markdown","387fa5a6":"markdown","9800f073":"markdown","820ebf1a":"markdown","36c2322c":"markdown","101d4beb":"markdown","20bbe55b":"markdown","0ee0df5e":"markdown","2f4f632b":"markdown","37d19d07":"markdown","a4b9bb52":"markdown"},"source":{"09bbf9c6":"from pathlib import Path\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nimport os\nfrom sklearn.model_selection import KFold\nfrom tqdm.notebook import tqdm\nimport seaborn as sbn\nfrom  datetime import datetime, timedelta\nfrom sklearn import datasets, linear_model\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nimport random\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom scipy.stats import norm","1d02dd49":"pd.options.mode.chained_assignment = None","3cc8bfc0":"path = Path('\/kaggle\/input\/osic-pulmonary-fibrosis-progression')\nassert path.exists()","b3ae39b5":"model_path = Path('\/kaggle\/working\/model')\nif os.path.isdir(model_path) == False:\n    os.makedirs(model_path)\nassert model_path.exists()","4ef4d7eb":"TRAIN_TYPES={\"Patient\": \"category\", \n         \"Weeks\": \"int16\", \"FVC\": \"int32\", 'Percent': 'float32', \"Age\": \"uint8\",\n        \"Sex\": \"category\", \"SmokingStatus\": \"category\" }\nSUBMISSION_TYPES={\"Patient_Week\": \"category\", \"FVC\": \"int32\", \"Confidence\": \"int16\"}\n\ndef read_data(path):\n    train_df = pd.read_csv(path\/'train.csv', dtype = TRAIN_TYPES)\n    test_df = pd.read_csv(path\/'test.csv', dtype = TRAIN_TYPES)\n    submission_df = pd.read_csv(path\/'sample_submission.csv', dtype = SUBMISSION_TYPES)\n    train_df.drop_duplicates(keep='first', inplace=True, subset=['Patient','Weeks'])\n    return train_df, test_df, submission_df","5c7b19b8":"train_df, test_df, submission_df = read_data(path)","5f09d26a":"def prepare_submission(df, test_df):\n    df['Patient'] = df['Patient_Week'].apply(lambda x:x.split('_')[0])\n    df['Weeks'] = df['Patient_Week'].apply(lambda x: int(x.split('_')[-1]))\n    df = df[['Patient','Weeks','Confidence','Patient_Week']]\n    df = df.merge(test_df.drop('Weeks', axis=1).copy(), on=['Patient'])\n    return df","f9e825ea":"submission_df = prepare_submission(submission_df, test_df)","c6172ee4":"submission_df[((submission_df['Patient'] == 'ID00419637202311204720264') & (submission_df['Weeks'] == 6))].head(5)","ceb86a1b":"def adapt_percent_in_submission():\n    previous_match = None\n    for i, r in submission_df.iterrows():\n        in_training = train_df[(train_df['Patient'] == r['Patient']) & (train_df['Weeks'] == r['Weeks'])]\n        if(len(in_training) > 0):\n            previous_match = in_training['Percent'].item()\n            submission_df.iloc[i, submission_df.columns.get_loc('Percent')] = previous_match\n        elif previous_match is not None:\n            submission_df.iloc[i, submission_df.columns.get_loc('Percent')] = previous_match","a50b7f2b":"adapt_percent_in_submission()","e8481723":"train_df['WHERE'] = 'train'\ntest_df['WHERE'] = 'val'\nsubmission_df['WHERE'] = 'test'\ndata = train_df.append([test_df, submission_df])","6be5d2e5":"data['min_week'] = data['Weeks']\ndata.loc[data.WHERE=='test','min_week'] = np.nan\ndata['min_week'] = data.groupby('Patient')['min_week'].transform('min')","8806e0d4":"base = data.loc[data.Weeks == data.min_week]","3d737ce4":"sbn.countplot(base['Sex'])","80c48989":"base = base[['Patient','FVC', 'Percent']].copy()\nbase.columns = ['Patient','min_FVC', 'min_Percent']\nbase['nb'] = 1\nbase['nb'] = base.groupby('Patient')['nb'].transform('cumsum')\nbase = base[base.nb==1]\nbase","4c50f7a0":"data = data.merge(base, on='Patient', how='left')","3ebf3028":"data['base_week'] = data['Weeks'] - data['min_week']\ndata['base_week'] = data['base_week']\ndel base","19dfe811":"data[data['Patient'] == 'ID00421637202311550012437']","21dbcc2f":"COLS = ['Sex','SmokingStatus']\nFE = []\nfor col in COLS:\n    for mod in data[col].unique():\n        FE.append(mod)\n        data[mod] = (data[col] == mod).astype(int)","482f0121":"data = data.rename(columns={\"Age\": \"age\", \"min_FVC\": \"BASE\", \"base_week\": \"week\", \"Percent\": \"percent\"})\nFE += ['age','week','BASE', 'percent']\nFE","a532862a":"train_df = data.loc[data.WHERE=='train']\ntest_df = data.loc[data.WHERE=='val']\nsubmission_df = data.loc[data.WHERE=='test']\ndel data","d401a943":"train_df.sort_values(['Patient', 'Weeks'], inplace=True)","873f6235":"X = train_df[FE]\nX.head(15)","4fe3c3b7":"y = train_df['FVC']\ny","bd539a77":"def seed_everything(seed=2020):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)","ddd934bc":"seed_everything(42)","e94476b6":"C1_val = 70\nC2_val = 1000\nC1, C2 = C1_val, C2_val\nq = np.array([0.2, 0.50, 0.8])\n\ndef score(y_true, y_pred):\n    sigma = y_pred[:, 2] - y_pred[:, 0]\n    fvc_pred = y_pred[:, 1]\n    #sigma_clip = sigma + C1\n    sigma_clip = np.max(sigma)\n    delta = np.abs(y_true[:, 0] - fvc_pred)\n    delta = np.min(delta)\n    sq2 = np.sqrt(2.)\n    metric = (delta \/ sigma_clip)*sq2 + np.log(sigma_clip* sq2)\n    return np.mean(metric)\n\ndef qloss(y_true, y_pred):\n    print('y_true.shape', y_true.shape)\n    print('y_pred.shape', y_pred.shape)\n    e = y_true - y_pred\n    v = np.max(q*e, (q-1)*e)\n    return np.mean(v)\n\ndef mloss(_lambda):\n    def loss(y_true, y_pred):\n        y_true = y_true.reshape(-1, 1)\n        return _lambda * qloss(y_true, y_pred) + (1 - _lambda)*score(y_true, y_pred)\n    return loss\n\ndef tilted_loss(q, y, f):\n    e = (y - f)\n    return keras.backend.mean(keras.backend.maximum(q * e, (q - 1) * e), axis=-1)","210d4189":"\nn_estimators = 30000\n    \nif not 'sub_row' in locals():\n    sub_row = 0.75\n    \nif not 'bagging_freq' in locals():\n    bagging_freq = 1\n    \nif not 'learning_rate' in locals():\n    learning_rate = 0.4\n\nleave_size = 4\n\nlgb_params = {\n    \"objective\": 'quantile',\n    'n_jobs': 1,\n    'max_depth': leave_size + 1,\n    'num_leaves': 2**leave_size-1,\n    \"min_data_in_leaf\": 2**(leave_size + 1)-1,\n#     'subsample': 0.9,\n    \"n_estimators\": n_estimators,\n    'learning_rate': 8e-3,\n    'colsample_bytree': 0.9,\n    'boosting_type': 'gbdt',\n    \"early_stopping_rounds\": 100,\n    'verbosity': 1000,\n    \"metric\": [\"rmse\", \"mse\"]\n}\n\ncat_feats = ['Male', 'Female', 'Ex-smoker', 'Never smoked', 'Currently smokes']","1283a5eb":"optimizer = tf.optimizers.Adam(learning_rate=0.001)\nearly_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\nEPOCHS = 200\nBATCH_SIZE = 32\nUNITS = 75","a9ee09b6":"def keras_pred(x_train, train_labels, q):\n    print(q)\n    \n    train_labels = np.array(train_labels.values, dtype='float32')\n\n    input_dim = x_train.shape[1]\n    model = keras.Sequential([\n        keras.layers.Dense(UNITS, input_dim=input_dim),\n        keras.layers.Activation('relu'),\n        keras.layers.Dense(UNITS, activation=tf.nn.relu),\n        keras.layers.Dense(1)\n    ])\n    \n    model.compile(loss=lambda y, f: tilted_loss(q, y, f), optimizer=optimizer)\n    model.fit(x_train, train_labels, epochs=EPOCHS, batch_size=BATCH_SIZE,\n              verbose=1, validation_split=0.2, callbacks=[early_stop])\n    \n    return model","2fb674be":"def ols_quantile(m, X, q):\n    # m: OLS model.\n    # X: X matrix.\n    # q: Quantile.\n    #\n    # Set alpha based on q. Vectorized for different values of q.\n    mean_pred = m.predict(X)\n    se = np.sqrt(m.scale)\n    return mean_pred + norm.ppf(q) * se","7b07d0b0":"ensemble_weights = [4.\/11, 1.\/11, 6.\/11]\nassert 1.0 - np.sum(ensemble_weights) < 0.00001","1021cd37":"NFOLD = 5\nkf = KFold(n_splits=NFOLD, shuffle=False)\npred = {a: np.zeros((train_df.shape[0])) for a in q.tolist()}","2c7ebcfd":"models = []\nlinear_models = []\nkeras_models = []\nfor cnt, (tr_idx, val_idx) in tqdm(enumerate(kf.split(X)), total=NFOLD):\n    X_train, y_train = X.loc[tr_idx], y.loc[tr_idx]\n    X_valid, y_valid = X.loc[val_idx], y.loc[val_idx]\n    print(f\"FOLD {cnt}\", X_train.shape, y_train.shape, X_valid.shape, y_valid.shape)\n    for qi, quantile_alpha in enumerate(q.tolist()):\n        lgb_params['alpha'] = quantile_alpha\n        m_lgb_regressor = lgb.LGBMRegressor(**lgb_params)\n        m_lgb_regressor.fit(X=X_train, y=y_train, \n                  eval_set=[(X_train, y_train), (X_valid, y_valid)],\n                  eval_names=['train mloss', 'valid mloss'], \n                  eval_metric=lgb_params['metric'],\n                  verbose=lgb_params['verbosity'],\n                  early_stopping_rounds=lgb_params[\"early_stopping_rounds\"],\n                  categorical_feature=cat_feats)\n        \n#         lin_model = sm.RLM(y_train, X_train, M=sm.robust.norms.HuberT()).fit()\n        lin_model = sm.RLM(y_train, X_train, M=sm.robust.norms.AndrewWave()).fit()\n#         lin_model = sm.RLM(y_train, X_train, M=sm.robust.norms.Hampel()).fit()\n#         lin_model = sm.RLM(y_train, X_train, M=sm.robust.norms.RamsayE()).fit()\n        lin_predict = ols_quantile(lin_model, X_valid, quantile_alpha)\n        \n        keras_model = keras_pred(X_train, y_train, quantile_alpha)\n        keras_predict = keras_model.predict(X_valid).reshape(-1)\n        \n        lgb_predict = m_lgb_regressor.predict(X_valid)\n        pred[quantile_alpha][val_idx] = np.average([lin_predict, lgb_predict, keras_predict], axis = 0, weights=ensemble_weights)\n        \n        models.append(m_lgb_regressor)\n        linear_models.append(lin_model)\n        keras_models.append(keras_model)","8d531cda":"full_preds = np.vstack([pred[a] for a in q]).T\nscore(np.array(y).reshape(-1, 1), full_preds)","1377ff5b":"pred = []\nfor i in range(NFOLD):\n    cur_pred = []\n    for j, quantile in enumerate(q):\n        model_idx = i * 3 + j\n        model = models[model_idx]\n        lin_predict = ols_quantile(linear_models[model_idx], submission_df[FE], quantile)\n        dbmc_predict = model.predict(submission_df[FE])\n        keras_predict = keras_models[model_idx].predict(submission_df[FE]).reshape(-1)\n        cur_pred.append(np.average([lin_predict, dbmc_predict, keras_predict], axis = 0, weights=ensemble_weights))\n    pred.append(np.array(cur_pred).T)","fb3488e1":"preds_array = np.array(pred)\npreds_array.shape","ca97554f":"final_preds = np.mean(preds_array, axis=0)\nfinal_preds.shape","2c2012d0":"submission_df['FVC1'] = final_preds[:,1]\nsubmission_df['Confidence1'] = final_preds[:, 2] - final_preds[:, 0]","cc05af89":"submission_df.loc[~submission_df.FVC1.isnull(),'FVC'] = submission_df.loc[~submission_df.FVC1.isnull(),'FVC1']\nsubmission_df.loc[~submission_df.FVC1.isnull(),'Confidence'] = submission_df.loc[~submission_df.FVC1.isnull(),'Confidence1']\nsubmission_df['Confidence'].describe()","36a3d65f":"submission_df['Confidence'] = np.clip(submission_df['Confidence'], a_min=200, a_max=1000)\nsubmission_df['Confidence'].describe()","c90a1323":"submission_df[[\"Patient_Week\",\"FVC\",\"Confidence\"]].to_csv(\"submission.csv\", index=False)","389cb776":"submission_final_df = pd.read_csv(\"submission.csv\")","52f3a118":"submission_final_df","4b89fe8e":"submission_final_df.describe().T","4c2b471f":"for p in test_df['Patient'].unique():\n    submission_final_df[submission_final_df['Patient_Week'].str.find(p) == 0]['FVC'].plot()","4ac43067":"for p in test_df['Patient'].unique():\n    fig, ax = plt.subplots()\n    submission_final_df[submission_final_df['Patient_Week'].str.find(p) == 0]['FVC'].plot(ax=ax)","0cdbb3af":"#### Feature generation","387fa5a6":"##### Keras Configuration","9800f073":"### LightGBM and OLS Training and Keras","820ebf1a":"##### Linear Model (OLS)","36c2322c":"### Path","101d4beb":"#### Seed","20bbe55b":"### Checks","0ee0df5e":"##### LightGBM","2f4f632b":"### Predict","37d19d07":"### Read Data","a4b9bb52":"##### Ensemble and Cross-Validation"}}