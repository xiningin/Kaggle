{"cell_type":{"153c4b95":"code","f6ca95e1":"code","9bbcaefa":"code","08d15a44":"code","9e278c4c":"code","877fc724":"code","258d379e":"code","ddb50e65":"code","ed282e0e":"code","46ec2c03":"code","9e564d0c":"code","74de9182":"code","d46798ca":"code","1702c6bf":"code","77069885":"code","6323a850":"code","c52a0caa":"code","3745108c":"code","dc027f77":"code","8ab68e7e":"code","fb4559bf":"code","928d518a":"code","432a765e":"code","3f97cef0":"code","f29f624a":"code","2278d45b":"code","83a8a416":"code","df741923":"code","ec6dfb96":"code","82b7bfdc":"code","5193bdf9":"code","413e8df0":"code","75a07462":"code","c5293c90":"code","028af9c0":"code","bb7a05aa":"code","b0f078af":"code","b1775334":"code","a645ceac":"code","4ff41d37":"code","3c9ab80c":"code","1a2fa867":"code","54df0d2d":"code","e6b824b8":"code","d864b3c4":"code","1a3356b2":"code","2a02f3c8":"markdown","30d5f704":"markdown","8a1089da":"markdown","b73193b7":"markdown","73ff3fe2":"markdown"},"source":{"153c4b95":"# import required libraries\nimport warnings\nwarnings.filterwarnings(\"ignore\")","f6ca95e1":"import re\nimport os \nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt \nimport tensorflow as tf \nfrom pathlib import Path\nfrom tqdm import tqdm\nfrom datetime import datetime","9bbcaefa":"data_dir = \"..\/input\/split-data-into-directories\/train_val\/\"","08d15a44":"# get to know whats inside the data\nos.listdir(data_dir)","9e278c4c":"# initialize image sizes and parameters\nHEIGHT = 224\nWIDTH = 224\nCHANNELS = 3\nBATCH_SIZE = 32","877fc724":"os.listdir(data_dir + \"train\")","258d379e":"# a function to show the image batch\ndef show_batch(image_batch, label_batch):\n  plt.figure(figsize=(10,10))\n  for n in range(25):\n      ax = plt.subplot(5,5,n+1)\n      plt.imshow(image_batch[n])\n      plt.title(CLASS_NAMES[label_batch[n]==1][0].title())\n      plt.axis('off')","ddb50e65":"# get the number of images\ntrain_image_count = len(list(Path(data_dir + \"train\").glob('*\/*')))\nval_image_count = len(list(Path(data_dir + \"val\").glob('*\/*')))\nprint(train_image_count)\nval_image_count","ed282e0e":"# train data\ntrain_list_ds = tf.data.Dataset.list_files(str(data_dir + \"train\/\" +'*\/*'))\n# validation data\nval_list_ds = tf.data.Dataset.list_files(str(data_dir + \"val\/\" +'*\/*'))","46ec2c03":"# images class names\nCLASS_NAMES = np.array([item.name for item in Path(data_dir + \"train\").glob('*')])\nCLASS_NAMES","9e564d0c":"# check the images file paths\nfor f in train_list_ds.take(5):\n  print(f.numpy())","74de9182":"# read image \n# a function to read data\ndef read_image(img_path):\n    img_loader = tf.io.read_file(img_path)\n    img_decoder = tf.image.decode_jpeg(img_loader, channels=CHANNELS)\n    img = tf.image.convert_image_dtype(img_decoder, tf.float32)\n    img = tf.image.resize(img, [WIDTH, HEIGHT])\n    # img = img\/255.0 # rescale images\n    return img","d46798ca":"# To get labels\ndef get_label(file_path):\n    parts = tf.strings.split(file_path, os.path.sep)\n    return parts[-2] == CLASS_NAMES","1702c6bf":"# process paths\ndef process_path(file_path):\n    label = get_label(file_path)\n    label = tf.cast(label, tf.int32)\n    img = read_image(file_path)\n    return img, label","77069885":"# using tensorflow dataset.map to create a dataset of image, label pairs\ntrain_labeled_ds = train_list_ds.map(process_path, num_parallel_calls=-1)\nval_labeled_ds = val_list_ds.map(process_path, num_parallel_calls=-1)","6323a850":"for image, label in val_labeled_ds.take(1):\n  print(\"Image shape: \", image.numpy().shape)\n  print(\"Label: \", label.numpy())","c52a0caa":"# prepare data for training \ndef prepare_for_training(ds, shuffle_buffer_size=100, training=True):\n  ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n\n  # Repeat forever\n  if training:\n    ds = ds.repeat()\n    print(\"repeating\")\n  else:\n    pass\n  ds = ds.batch(BATCH_SIZE)\n\n  # `prefetch` lets the dataset fetch batches in the background while the model\n  # is training.\n  ds = ds.prefetch(buffer_size=-1)\n\n  return ds","3745108c":"train_ds = prepare_for_training(train_labeled_ds)\nval_ds = prepare_for_training(val_labeled_ds, training=False)\n\n# get some data\nimage_batch, label_batch = next(iter(train_ds))","dc027f77":"show_batch(image_batch.numpy(), label_batch.numpy())","8ab68e7e":"# prepare the test data\ntest_list = \"..\/input\/cgiar-computer-vision-for-crop-disease\/ICLR\/test\/\"","fb4559bf":"test_list_ds = tf.data.Dataset.list_files(str(test_list +'*\/*'))","928d518a":"# test list file names\nfor f in test_list_ds.take(5):\n  print(f.numpy())","432a765e":"# process test\ndef process_test(image_path):\n    img = read_image(image_path)\n    return img, image_path","3f97cef0":"test_ds = test_list_ds.map(process_test, num_parallel_calls=-1)","f29f624a":"for i, j in test_ds.take(1):\n    print(i.numpy().shape)\n    print(j.numpy())\n    plt.imshow(i.numpy())","2278d45b":"# temsorboard\nlog_dir=\"logs\/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n\n# Early stopping\nes = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3)\n\n# model checkpoints\ncheckpoint_path =  \"model\/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"\/cp.ckpt\"\nmodel_checkpoints = tf.keras.callbacks.ModelCheckpoint(\n            checkpoint_path,\n            save_best_only=True,\n            save_weights_only=True,\n            monitor='val_categorical_accuracy',\n            mode='max')","83a8a416":"callbacks = [tensorboard, es]","df741923":"# define class weights\nleaf_rust_count = len(os.listdir(data_dir + \"train\/leaf_rust\"))\nstem_rust_count = len(os.listdir(data_dir + \"train\/stem_rust\"))\nhealthy_wheat_count =len(os.listdir(data_dir + \"train\/healthy_wheat\"))\ntotal = leaf_rust_count + stem_rust_count + healthy_wheat_count\n\nleaf_rust_weight = (1\/leaf_rust_count) * (total) \/ 3.0\nstem_rust_weight = (1\/stem_rust_count) * (total) \/ 3.0\nhealthy_wheat_weight = (1\/healthy_wheat_count) * (total) \/ 3.0\n\nclass_weight = {0:leaf_rust_weight, 1:stem_rust_weight, 2:healthy_wheat_weight}\nprint(class_weight)","ec6dfb96":"def simple_model():\n    model = tf.keras.Sequential()\n    model.add(tf.keras.layers.Conv2D(32 ,(3,3), activation=\"relu\", \n                padding=\"same\", input_shape=(224,224, 3)))\n    model.add(tf.keras.layers.MaxPool2D(2,2, padding=\"same\"))\n    model.add(tf.keras.layers.GlobalAveragePooling2D())\n    model.add(tf.keras.layers.Dense(3, activation=\"softmax\"))\n    model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.01), \n                    loss=tf.keras.losses.categorical_crossentropy, \n                    metrics = [tf.keras.metrics.categorical_accuracy])\n    return model ","82b7bfdc":"steps_per_epoch = train_image_count \/\/ BATCH_SIZE\nvalidation_steps = val_image_count \/\/ BATCH_SIZE\nprint(steps_per_epoch)\nvalidation_steps","5193bdf9":"# fit the model\nmodel = simple_model()","413e8df0":"model.fit(train_ds, epochs=1000, steps_per_epoch=steps_per_epoch, \n                validation_data=val_ds, validation_steps=validation_steps,\n                callbacks=callbacks, class_weight=class_weight)","75a07462":"# test count\ntest_count = len(list(Path(test_list).glob('*\/*')))\ntest_count","c5293c90":"names = []\npreds = []","028af9c0":"for i, j in tqdm(test_ds):\n    i = i.numpy()[np.newaxis, :] # add a new dimension\n    prediction = model.predict_proba(i) # make predictions\n    preds.append(prediction) \n    \n    # use regular expressions to extract the name of image\n    name = j.numpy()\n    name = re.sub(\"[^A-Z0-9]\", \"\", str(name))\n    name = name.replace(\"JPG\", \"\")\n    name = name.replace(\"PNG\", \"\")\n    name = name.replace(\"JPEG\", \"\")\n    name = name.replace(\"JFIF\", \"\")\n    names.append(name)\n    # break","bb7a05aa":"# create a dummy dataset\nleaf_rust = pd.Series(range(610), name=\"leaf_rust\", dtype=np.float32)\nstem_rust = pd.Series(range(610), name=\"stem_rust\", dtype=np.float32)\nhealthy_wheat = pd.Series(range(610), name=\"healthy_wheat\", dtype=np.float32)","b0f078af":"sub = pd.concat([leaf_rust, stem_rust, healthy_wheat], axis=1)","b1775334":"sub.shape","a645ceac":"# append real predictions to the dataset\nfor i in tqdm(range(0 ,len(preds))):\n    sub.loc[i] = preds[i]\n    # break","4ff41d37":"sub.head()","3c9ab80c":"sub[\"ID\"] = names","1a2fa867":"sub.tail()","54df0d2d":"cols = sub.columns.tolist()","e6b824b8":" cols = cols[-1:] + cols[:-1]\n sub = sub[cols]","d864b3c4":"sub.head()","1a3356b2":"# write to csv\nsub.to_csv(\"sub.csv\", index=False)","2a02f3c8":"# create callbacks","30d5f704":"# Make prediction for the test dataset","8a1089da":"#  create a simple model","b73193b7":"# process the data with tf.data \n","73ff3fe2":"# Create a submission file"}}