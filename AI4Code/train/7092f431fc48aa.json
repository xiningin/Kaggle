{"cell_type":{"66a365e3":"code","9ef5ef32":"code","bcd7cdf8":"code","f802749c":"code","6b5e31e5":"code","360b0659":"code","83d4239c":"code","d0e1935a":"code","cbab33ce":"code","d12104ee":"code","1a9ca866":"code","5d0dd305":"code","29b05ad3":"code","450e5fc6":"code","92adae99":"code","5064a167":"code","f145296b":"code","94a93eca":"code","0d29ae05":"code","36bd181d":"code","b7d06b12":"code","cc491141":"code","225a005d":"code","8804459f":"code","de700321":"code","69695849":"code","8ca916d5":"markdown","12e3363c":"markdown","15af34e8":"markdown","e3a52f90":"markdown","4f533c78":"markdown","504f88dc":"markdown","8c6cbe30":"markdown","decadcb2":"markdown","33a7f3a8":"markdown","a18a667b":"markdown","e81a325c":"markdown","8b1d637c":"markdown","a31d5d71":"markdown","4d6bff89":"markdown","6bb75c4b":"markdown","7a3fc399":"markdown","23db4c44":"markdown","5a2a8151":"markdown","a5f8fd2b":"markdown","fc4ba9e1":"markdown","51f1d115":"markdown","712a8ad6":"markdown","5959fcea":"markdown"},"source":{"66a365e3":"import numpy as np \nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom matplotlib import pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_curve, roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, LabelEncoder\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nimport warnings","9ef5ef32":"warnings.simplefilter(action='ignore')\ndf = pd.read_csv(\"..\/input\/heart-disease-cleveland-uci\/heart_cleveland_upload.csv\")\ndf.head()","bcd7cdf8":"df.describe()","f802749c":"df.info()","6b5e31e5":"sns.set_context(\"talk\")\nplt.figure(figsize=(15, 12))\nsns.heatmap(df.corr(), annot=True, fmt=\".2f\")","360b0659":"df.groupby(\"condition\")[[\"thalach\",\"chol\",\"age\",\"trestbps\"]].mean()","83d4239c":"#Histogram of age distribution\nsns.set_style(\"darkgrid\")\nsns.set_context(\"poster\")\nplt.figure(figsize=(12, 9))\nsns.histplot(data=df[\"age\"], alpha=0.6)\nplt.axvline(df[\"age\"].mean(), color=\"red\")\nplt.title(\"Distribution of age in the dataset\")\nplt.text(33, 42, \"Mean age: \" + str(round(df[\"age\"].mean(), 1)), color=\"indianred\", weight=\"heavy\", size=\"larger\", bbox=dict(boxstyle=\"round\", color=\"rosybrown\"))\nplt.xlabel(\"Age\")\nplt.ylabel(\"Count\")\nplt.show()","d0e1935a":"#Histogram of ST depression distribution\nsns.set_style(\"darkgrid\")\nsns.set_context(\"poster\")\nplt.figure(figsize=(12, 9))\nsns.histplot(data=df[\"oldpeak\"], alpha=0.6)\nplt.title(\"Relative ST depression (Exercise-Rest, mm)\")\nplt.xlabel(\"Difference (Exercise-Rest, mm)\")\nplt.ylabel(\"Count\")\nplt.show()","cbab33ce":"#I had to create a new column since Seaborn gave me some trouble with proper legend labeling, it's not essential\ndf[\"Heart condition\"] = df[\"condition\"].replace({1:\"Present\", 0:\"Not present\"})\n\n#Part concerning the actual plotting\nsns.set_style(\"darkgrid\")\nsns.set_context(\"poster\")\nplt.figure(figsize=(12, 9))\nsns.scatterplot(\"chol\", \"age\", hue=df[\"Heart condition\"], data=df)\nplt.title(\"Cases presenting heart disease compared by their age and blood cholesterol\")\nplt.xlabel(\"Blood cholesterol (mg\/dL)\")\nplt.ylabel(\"Age\")\nplt.show()","d12104ee":"sns.set_style(\"darkgrid\")\nsns.set_context(\"poster\")\nplt.figure(figsize=(12, 9))\nsns.scatterplot(\"thalach\", \"age\", hue=df[\"Heart condition\"], data=df)\nplt.title(\"Maximum heart rate achieved by presence of heart condition and distribution of age\")\nplt.xlabel(\"Maximum heart rate (beats per minute)\")\nplt.ylabel(\"Age\")\nplt.show()","1a9ca866":"sns.set_style(\"darkgrid\")\nsns.set_context(\"poster\")\nplt.figure(figsize=(12, 9))\nsns.scatterplot(\"trestbps\", \"age\", hue=df[\"Heart condition\"], data=df)\nplt.title(\"Change of rest heart bpm by age\")\nplt.xlabel(\"Resting heart rate (beats per minute)\")\nplt.ylabel(\"Age\")\nplt.show()","5d0dd305":"plt.figure(figsize=(12, 9))\ng = sns.countplot(\"exang\", hue=\"slope\", data=df)\ng.set_xticklabels([\"Not present\", \"Present\"])\nplt.title(\"Presence of exercise induced angina by the slope's direction on peak of the ST segment\")\nplt.xlabel(\"Presence of exercise induced angina\")\nplt.ylabel(\"Counts\")\nplt.legend([\"Upsloping\", \"Flat\", \"Downsloping\"])\nplt.show()","29b05ad3":"plt.figure(figsize=(12, 9))\ng = sns.countplot(\"cp\", hue=\"sex\", data=df)\ng.set_xticklabels([\"Typical\", \"Atypical\", \"Non-Anginal\", \"Asymptomatic\"])\nplt.title(\"Distribution of anginal pain type by gender\")\nplt.xlabel(\"Anginal pain type\")\nplt.ylabel(\"Count\")\nplt.legend([\"Female\", \"Male\"])\nplt.show()","450e5fc6":"plt.figure(figsize=(20, 9))\ng = sns.countplot(pd.cut(df[\"oldpeak\"], 13), hue=\"Heart condition\", data=df) #I had to bin the x values since there were too many distinct values to interprete\nplt.title(\"Difference ST segment depression (Exercise-Rest) by presence of heart disease\")\nplt.xlabel(\"Difference\")\nplt.ylabel(\"Count\")\nplt.xticks(rotation=75)\nplt.legend([\"Not present\", \"Present\"])\nplt.show()","92adae99":"#Binning continous features together and therefore creating discrete categorical columns could \n#help the model to generalize the data and reduce overfitting\ndf[\"thalach\"] = pd.cut(df[\"thalach\"], 8, labels=range(1, 9))\ndf[\"trestbps\"] = pd.cut(df[\"trestbps\"], 5, labels=range(8, 13))\ndf[\"age\"] = pd.cut(df[\"age\"], 12, labels=range(12, 24))\ndf[\"chol\"] = pd.cut(df[\"chol\"], 10, labels=range(24, 34))\ndf[\"oldpeak\"] = pd.cut(df[\"oldpeak\"], 5, labels=range(34, 39))","5064a167":"a = pd.get_dummies(df, columns=[\"cp\", \"restecg\", \"slope\", \"thalach\", \"trestbps\", \"age\", \"chol\", \"thal\", \"oldpeak\"], \n                   prefix=[\"cp\", \"restecg\", \"slope\", \"thalach\", \"trestbps\", \"age\", \"chol\", \"thal\", \"oldpeak\"], drop_first=True)","f145296b":"a = a.drop(\"Heart condition\", axis=1)","94a93eca":"a.head()","0d29ae05":"rf = RandomForestClassifier()\nrf.fit(a.drop(\"condition\", axis=1), a.condition)\nimportances = rf.feature_importances_\nfeatures = pd.Series(importances, index=a.drop(\"condition\", axis=1).columns)\nplt.figure(figsize=(12, 16))\nfeatures.plot(kind=\"barh\")\nplt.show()","36bd181d":"X = a.drop([\"condition\", \"restecg_1\", \"thalach_2\", \"thalach_8\", \"trestbps_12\", \"age_13\", \"age_22\", \"age_23\", \n            \"chol_29\", \"chol_30\", \"chol_31\", \"chol_32\", \"chol_33\", \"oldpeak_37\", \"oldpeak_38\"], axis=1)\ny = a.condition\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n\n#It took forever for Kaggle's kernel to run GridSearchCV with xGBoosting, however I added the results\n#of hyperparameter tuning as markdown cells below.\n\n#xgb = xgb = XGBClassifier(objective=\"binary:logistic\", eval_metric=\"auc\")\n#params = {\"max_depth\":np.arange(1, 8), \"n_estimators\":[100, 300, 500, 600, 900, 1000], \n#          \"learning_rate\":[0.001, 0.01, 0.03, 0.05, 0.07], \"colsample_bytree\":[0.35, 0.5, 0.65],\n#          \"subsample\":[0.4, 0.5, 0.55, 0.7]\n#          }\n#grid_xgb = GridSearchCV(estimator = xgb, param_grid = params, cv=10, n_jobs=-1)\n#grid_xgb.fit(X_train, y_train)\n#xgb_pred = grid_xgb.predict(X_test)\n#print(classification_report(y_test, xgb_pred))","b7d06b12":"xgb = XGBClassifier(objective=\"binary:logistic\", eval_metric=\"auc\", max_depth=1,\n                    n_estimators=500,learning_rate=0.05,colsample_bytree=0.35,subsample=0.5)\nxgb.fit(X_train, y_train)\nxgb_pred = xgb.predict(X_test)","cc491141":"print(grid_xgb.best_params_)","225a005d":"print(grid_xgb.cv_results_[\"mean_test_score\"].mean())","8804459f":"print(classification_report(y_test, xgb_pred))","de700321":"sns.set_context(\"talk\")\nplt.figure(figsize=(12, 9))\nsns.heatmap(confusion_matrix(y_test, xgb_pred), annot=True, xticklabels=[\"Healthy\", \"Sick\"], yticklabels=[\"Healthy\", \"Sick\"], fmt=\"g\", cmap=\"icefire_r\")\nplt.ylabel(\"Predicted\")\nplt.xlabel(\"Actual\")\nplt.title(\"Confusion matrix of xGBoosting\")\nplt.show()","69695849":"xgb_prob = xgb.predict_proba(X_test)[:, 1]\nfpr, tpr, thresholds = roc_curve(y_test, xgb_prob)\nsns.set_style(\"darkgrid\")\nsns.set_context(\"poster\")\nplt.figure(figsize=(15, 10))\nplt.plot([0, 1], [0, 1], 'k--')\nsns.lineplot(fpr, tpr, alpha=0.6, ci=None)\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve')\nplt.legend([\"Baseline\", \"xGBoosting\"])\nplt.show()\nprint(roc_auc_score(y_test, xgb_prob))","8ca916d5":"## Basic EDA and visualizations","12e3363c":"0.8079008511617207","15af34e8":"Most of the samples fall between a range of 0-2 millimeters' difference regarding the bottom-most points of ST segment depressions in ECG charts as the plot above shows. A difference of 2mm was used as a threshold to interrupt stress testing in this (https:\/\/www.ncbi.nlm.nih.gov\/pmc\/articles\/PMC1768611\/) paper, therefore it's possible to argue that the values that go above this range should be treated as anomalies.","e3a52f90":"## Building the model and hyperparameter tuning","4f533c78":"## Conclusion\n\nFeeding the model with ideal parameters and a favorable train-test split resulted in an AUC score of 0.97. The model seems to be especially potent at detecting healthy people, considering that only 2 people out of 26 were mislabeled as healthy despite being ill. Efficiency of the model does drop a bit compared to predicting \"healthiness\" when it comes to determining whether if an individual is sick or not, however a high false positive rate could be a preferrable trade-off in order to achieve a low false negative count, considering that the priority is to ensure that the model detects as many sick people as possible. Considered that the model's recall is still in a somewhat decent range, it could be argued that this specific model could actually be deployed and be of use in practice.","504f88dc":"I also dropped the renamed condition column that I used for proper legend labeling above on the graphs.","8c6cbe30":"I selected all of the numerical columns, took their average, and grouped them by our target column, \"condition\". \n\n* It appears that the average age of the cases that present with a heart condition were ~4 years younger on average than the people who admitted without a heart disease.  \n\n* A somewhat significant difference is apparent between the maximum heart rates of people who are sick and healthy, since healthy people were able to reach a 20 beats per minute higher maximum heart rate on average compared to those who are ill. \n\n* Those who weren't sick had a lower resting heart rate compared to ill people, however this difference is not that significant (especially compared to the difference between the patients' maximal heart rate) and differs merely by 6 beats per minute on average.\n\n* Finally, people without a heart disease had a lower cholesterol count of ~8 mg\/dL in their blood serum on average compared to cases that presented with a heart disease.","decadcb2":"The above graph is a matrix that shows the correlation of all the columns in the dataset. It's a intuitive method for visualizing the presence of linear relationships for datasets containing relatively fewer features epspecially. However it must be noted that this particular dataset is mostly made up of categorical features, therefore most of the correlation coefficients in the above graph won't make sense, especially for points that contain a non-binary categorical feature. ","33a7f3a8":"Distribution of age in the dataset is somewhat normal-like and the average age is 54.5. ","a18a667b":"I dropped the target (\"condition\") column and all the feature columns that had a relatively lower importance percentage (such as the columns \"chol_31\" and \"chol_32 which weren't been used at all by the model to split nodes) in order to reduce noise and overfitting. I used 80% of the data as to train the model and the remaining 20% for testing, and also included the stratify argument in order to make sure that both the training and validation sets have equal percentages of individuals that *do* present with heart disease and don't. Finally, I used GridSearchCV to tune hyperparameters, using 10-fold cross validation during the process.","e81a325c":"Model producing the best result has a 90% weighted average accuracy score, whereas this accuracy score drops down to ~81% when the scores of 10 cross validation splits of the training and test data are averaged. A difference of 8% between the accuracy scores of the best scoring model and mean of the accuracy scores provided by 10 different train\/test splits plugged into a tuned model indicates the presence of a somewhat significant case of overfitting.","8b1d637c":"There's a slight skewing (or clustering) towards the right side of the plot for healthy individuals, meaning individuals that were able to achieve higher maximum heart rates might be more likely to have a healthy heart. It should also be noted that younger individuals could reach higher heart beats per minute, meaning there's an inverse relationship between age and maximum heart rate. ","a31d5d71":"According to this (https:\/\/www.ncbi.nlm.nih.gov\/pmc\/articles\/PMC1123032\/) article on PubMed: \"...The normal ST segment during exercise therefore slopes sharply upwards...\"\n\nSo simply put, the ST segment slope is expected to be upsloping for healthy individuals during effort testing.","4d6bff89":"## Evaluation of the model","6bb75c4b":"It's important to encode the categorical features since the model will otherwise treat the numbers that represent categories as weights instead, this could create the risk of the model capturing non-existent relationships between the features. I used one hot encoding with pandas by setting the drop_first argument to True.","7a3fc399":"I used a Random Forest Classifier in order to determine feature importances and plotted them. ","23db4c44":"This dataset's been downloaded from Kaggle (link: https:\/\/www.kaggle.com\/cherngs\/heart-disease-cleveland-uci) and the columns descriptions are as following:\n\nThere are 13 attributes:\n\n\n**age**: age (in years)\n\n\n**sex**: gender (1 = male; 0 = female)\n\n\n**cp**: chest pain type\n\nThere are three criteria for classifying different types of angina (chest pain) under three categories (according to this NCBI paper: https:\/\/pubmed.ncbi.nlm.nih.gov\/20494662\/):\n\n\u25fc *Location*: Chest pain occurs around the substernal portion of the body\n\n\u25fc *Cause*: Pain is experienced after induction of emotional\/physical stress\n\n\u25fc *Relief*: The pain goes away after taking nitroglycerine and\/or a rest\n\n-- 0: typical angina (all criteria present)\n\n-- 1: atypical angina (two of three criteria satisfied)\n\n-- 2: non-anginal pain (less than one criteria satisfied)\n\n-- Value 3: asymptomatic (none of the criteria are satisfied)\n\n\n**trestbps**: resting blood pressure (in mmHg, upon admission to the hospital)\n\n\n**chol**: serum cholesterol in mg\/dL\n\n\n**fbs**: fasting blood sugar > 120 mg\/dL (likely to be diabetic) 1 = true; 0 = false\n\n\n**restecg**: resting electrocardiogram results\n\n-- Value 0: normal\n\n-- Value 1: having ST-T wave abnormality (T wave inversions and\/or ST elevation or depression of > 0.05 mV) - more on the effects of these below\n\n-- Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n\n\n**thalach**: maximum heart rate achieved\n\n\n**exang**: exercise induced angina (1 = yes; 0 = no)\n\n\n**oldpeak**: ST depression induced by exercise relative to rest (in mm, achieved by subtracting the lowest ST segment points during exercise and rest)\n\n\n**slope**: the slope of the peak exercise ST segment, ST-T abnormalities are considered to be a crucial indicator for identifying presence of ischaemia (according to this research paper on NCBI: https:\/\/www.ncbi.nlm.nih.gov\/pmc\/articles\/PMC7027664\/)\n\n\n#### Depressed ST segment ECG results by slope direction\n\n![ST-segment-depression-upsloping-downsloping-horizontal.png](attachment:ddabb4d1-c9e9-46fd-a3ea-bb6ed203550d.png) \n\n(image is taken from this article on litfl.com: https:\/\/litfl.com\/myocardial-ischaemia-ecg-library\/)\n\n#### ST segment and T wave abnormalities vs. normal ST segment\n\n![Comparison-of-the-ST-segment-variations-in-a-normal-subject-A-and-in-MI-patients-with.png](attachment:5436cdb7-c5df-4f6f-9e54-76ace305e66d.png)\n\n(image is taken from this paper on ResearchGate: https:\/\/www.researchgate.net\/publication\/333912486_Wearable_Real-Time_Heart_Attack_Detection_and_Warning_System_to_Reduce_Road_Accidents)\n\n-- Value 0: upsloping\n\n-- Value 1: flat\n\n-- Value 2: downsloping\n\n\n**ca**: number of major vessels (0-3) colored by fluoroscopy. Major cardial vessels are as goes: aorta, superior vena cava, inferior vena cava, pulmonary artery (oxygen-poor blood --> lungs), pulmonary veins (oxygen-rich blood --> heart), and coronary arteries (supplies blood to heart tissue).\n\nRadioactive dye is introduced to the body followed by x-ray imaging to detect any structural abnormalities present in the heart. The quantity of vessels colored is positively correlated with presence of heart disease.\n\n\n**thal**: 0 = normal; 1 = fixed defect (heart tissue can't absorb thallium both under stress and in rest); 2 = reversible defect (heart tissue is unable to absorb thallium only under the exercise portion of the test)\n\nThallium testing is a method where the radioactive element thallium (Tl) is introduced to the body through an IV injection, followed by nuclear imaging of the heart with a gamma camera which reveals structural issues and abnormalities of the heart by showing whether if the isotope was absorbed by heart tissue under high (exercise) and low (rest) stress conditions.\n\n\n**condition**: 0 = no disease, 1 = disease","5a2a8151":"## One-hot encoding categorical values","a5f8fd2b":"## Determining feature importances","fc4ba9e1":"I converted all the continous values into categorical ones by binning them. The model is able to interprete the distributed weights of a particular feature when \"there are less options to choose from\" regarding observations.","51f1d115":"## Binning continous numeric values","712a8ad6":"{'colsample_bytree': 0.35, 'learning_rate': 0.05, 'max_depth': 1, 'n_estimators': 500, 'subsample': 0.5}","5959fcea":"While this might not be the most aesthetic looking plot ever, it clearly shows that the incidence of heart disease presence and difference of ST segment depression during exercise-rest move in the same direction, meaning that as the difference of ST segment depression during exercise against depression during rest gets larger, more likely it gets to encounter a person with heart disease."}}