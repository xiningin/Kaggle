{"cell_type":{"2de556ac":"code","77e2581b":"code","5b5c9247":"code","8c4f12cd":"code","a6c3ba1d":"code","67c6ab6e":"code","88ea443f":"code","aed34305":"code","d4e1a618":"code","62ee425b":"code","d1d984bd":"code","75ea2667":"code","fb9aead3":"code","a81ea36a":"code","e3d11823":"code","4900a65b":"code","b34425be":"code","17452506":"code","450f0f08":"code","9cc28e9a":"code","2e967e54":"code","89aac7ef":"code","b5760f33":"code","6dc6752d":"code","effccdb3":"code","63b98ce5":"code","a5db5e37":"code","dc959aee":"code","fdce8d07":"code","e10d9ae5":"code","c0162d78":"markdown","ba9b0976":"markdown","6c767db9":"markdown","5399ceca":"markdown","d69c8c94":"markdown","943139a4":"markdown","25b0920b":"markdown","02e14eb0":"markdown","3b7891ff":"markdown","7f4f120e":"markdown","7ecdcba6":"markdown","21059153":"markdown","80670435":"markdown","842b7eee":"markdown","79fddfd6":"markdown"},"source":{"2de556ac":"from imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split\nimport numpy as np # linear algebra\nimport pandas as pd\n\ndef smoteAdataset(Xig, yig, test_size=0.2, random_state=0):\n    \n    Xig_train, Xig_test, yig_train, yig_test = train_test_split(Xig, yig, test_size=test_size, random_state=random_state)\n    print(\"Number transactions X_train dataset: \", Xig_train.shape)\n    print(\"Number transactions y_train dataset: \", yig_train.shape)\n    print(\"Number transactions X_test dataset: \", Xig_test.shape)\n    print(\"Number transactions y_test dataset: \", yig_test.shape)\n\n    classes=[]\n    for i in np.unique(yig):\n        classes.append(i)\n        print(\"Before OverSampling, counts of label \" + str(i) + \": {}\".format(sum(yig_train==i)))\n        \n    sm=SMOTE(random_state=2)\n    Xig_train_res, yig_train_res = sm.fit_sample(Xig_train, yig_train.ravel())\n\n    print('After OverSampling, the shape of train_X: {}'.format(Xig_train_res.shape))\n    print('After OverSampling, the shape of train_y: {} \\n'.format(yig_train_res.shape))\n    \n    for eachClass in classes:\n        print(\"After OverSampling, counts of label \" + str(eachClass) + \": {}\".format(sum(yig_train_res==eachClass)))\n        \n    return Xig_train_res, yig_train_res, Xig_test, yig_test\n","77e2581b":"#!pip install modin\n\nimport os\nprint(os.listdir(\"..\/input\"))\nprint(os.listdir(\"..\/input\/assemblecustomtestsetrevb\"))\nprint(os.listdir(\"..\/input\/something-different\"))\n# Any results you write to the current directory are saved as output.","5b5c9247":"import pandas as pd\ntraindf=pd.read_csv(\"..\/input\/something-different\/newTrainFeatureOutputUnprocessed.csv\")\nif 'Unnamed: 0' in traindf.columns:\n    traindf=traindf.drop('Unnamed: 0', axis=1)\n#traindf = traindf.round(8)\ntraindf.shape","8c4f12cd":"testdf=pd.read_csv(\"..\/input\/assemblecustomtestsetrevb\/completeTestSetRevB.csv\")","a6c3ba1d":"if 'Unnamed: 0' in testdf.columns:\n    testdf=testdf.drop('Unnamed: 0', axis=1)","67c6ab6e":"\nprint(traindf.shape)\n#traindf.head()","88ea443f":"print(testdf.shape)\ntestdf.columns","aed34305":"def repeatPerBand(df, prefix):\n    \n    df.loc[:,prefix + 'frsq']=df.loc[:,prefix+'med']**2 \/ df.loc[:,prefix+'mfl']**2\n    df.loc[:,prefix + 'frsqxf']=df.loc[:,prefix+'frsq'] * df.loc[:,prefix+'med']\n    \n    return df\n\nprefixes=['le','lm','ll','he','hm','hl']\nfor prefix in prefixes:\n    \n    traindf=repeatPerBand(traindf, prefix)\n    print(traindf.shape)\n    \n#traindf.head()","d4e1a618":"for prefix in prefixes:\n    \n    testdf=repeatPerBand(testdf, prefix)\n    print(testdf.shape)\n    \n#testdf.head()","62ee425b":"def removePerBand(df, prefixes=['le','lm','ll','he','hm','hl']):\n    for prefix in prefixes:\n        df=df.drop([prefix + 'mxd', prefix + 'mnd'], axis=1)\n        print(df.shape)\n    \n\n    return df\n\ntraindf=removePerBand(traindf)  \n#traindf.head()","d1d984bd":"testdf=removePerBand(testdf)  \n#testdf.head()","75ea2667":"#distmod\ntraindf['distmod'] = traindf['distmod'].fillna(value=0)\n#traindf.info()","fb9aead3":"#for column in testdf.columns:\n#    print(column)\n#    joe = testdf[column].isna().sum()\n#    if joe>0:\n#        print(joe)\ntestdf['distmod'] = testdf['distmod'].fillna(value=0)\nprint(testdf['distmod'].isna().sum())\n#hostgal_specz\n#distmod","a81ea36a":"traindf=traindf.drop('hostgal_specz', axis=1)\ntestdf=testdf.drop('hostgal_specz', axis=1)\nprint(traindf.shape)\nprint(testdf.shape)","e3d11823":"def photoztodist(df) :\n    dfhpz=(data[\"hostgal_photoz\"])\n    return ((((((np.log(((dfhpz + (np.log(((dfhpz + (np.sqrt((np.log((np.maximum(((3.0)), (dfhpz * 2.0))))))))))))))) + (12.99870681762695312))) + (1.17613816261291504))) * (3.0))","4900a65b":"#from Helgi's comment on Scirpus' Photoz2Distance kernel\n#np.log(meta _train.hostgal _photoz)\n#https:\/\/www.kaggle.com\/scirpus\/photoz2distance\n#traindf['photozDist']=0\n#distmodnonzero=traindf.loc[:,'distmod']>0\n#traindf.loc[distmodnonzero,'photozDist']=#np.log(traindf.loc[distmodnonzero,'hostgal_photoz'])\n#traindf['photozDist'] = traindf['photozDist'].fillna(value=0)\n#print(traindf.shape)\n#testdf['photozDist']=np.log(testdf['hostgal_photoz'])\n#testdf['photozDist'] = testdf['photozDist'].fillna(value=0)\n#print(testdf.shape)\n#traindf.describe()","b34425be":"print(traindf.shape)\nprint(testdf.shape)\n\n#trobjids=traindf.loc[:,'object_id']\n#print(trobjids.shape)\n\n#traindf=traindf.drop('object_id',axis=1)\n#print(traindf.shape)\n\n","17452506":"#teobjids=testdf.loc[:,'object_id']\n#print(teobjids.shape)\n#testdf=testdf.drop('object_id',axis=1)\n#print(testdf.shape)\n","450f0f08":"#trobjdf=pd.DataFrame(columns=['object_id'], data=trobjids)","9cc28e9a":"#print(trobjdf.shape)\n#teobjdf=pd.DataFrame(columns=['object_id'], data=teobjids)\n#print(teobjdf.shape)","2e967e54":"def convertAllToLogBase(df, excludeLogCols=['ra', 'decl', 'gal_l', 'gal_b', 'hostgal_photoz', 'target',\n                                            'hostgal_photoz_err', 'distmod', 'outlierScore', 'object_id']):\n    \n    for cindex in df.columns:\n        if (cindex not in excludeLogCols) & (len(df.loc[:,cindex].unique()) > 2):\n            #zeroFilter=df.loc[:,cindex]==0 (stays zero)\n            negFilter=df.loc[:,cindex]<0\n            posFilter=df.loc[:,cindex]>0\n            \n            df.loc[negFilter,cindex]=-1.0*np.log(-1.0*df.loc[negFilter,cindex])\n            df.loc[posFilter,cindex]=np.log(df.loc[posFilter,cindex])\n            #print(cindex)\n    return df\n\ntraindf=convertAllToLogBase(traindf)\n","89aac7ef":"testdf=convertAllToLogBase(testdf)","b5760f33":"def reduceExtremeOutliers(df,targCol='target', logStdRng=8.0):\n    \n    #possibleLog=[]\n    #nonLog=[]\n    for cindex in df.columns:\n        \n        if (cindex==targCol) | (len(df.loc[:,cindex].unique())<=2) | (cindex=='object_id'):\n            \n            print('doing nothing for ' + str(cindex))\n            \n        else:\n            stdev=np.std(df.loc[:,cindex])\n            minVal=np.min(df.loc[:,cindex])\n            theRange=np.max(df.loc[:,cindex])-minVal\n            stdRange=theRange \/ stdev\n            if logStdRng < stdRange:\n                #df.loc[:,cindex]=df.loc[:,cindex]-minVal\n                #df.loc[:,cindex]=log(df.loc[:,cindex])\n                print('flagged ' + str(cindex) + ' for high variability')\n                print(stdRange)\n                #possibleLog.append(cindex)\n            \n                \n            newStdev=np.std(df.loc[:,cindex])\n            med=np.median(df.loc[:,cindex])\n            tooBig=med+newStdev*logStdRng\/2\n            tooLittle=med-newStdev*logStdRng\/2\n            tooBigFilter=df.loc[:,cindex]>tooBig\n            tooLittleFilter=df.loc[:,cindex]<tooLittle\n            df.loc[tooBigFilter,cindex]=tooBig\n            df.loc[tooLittleFilter,cindex]=tooLittle\n            \n    return df #, possibleLog, nonLog\n            \ntraindf=reduceExtremeOutliers(traindf)\n\n","6dc6752d":"testdf=reduceExtremeOutliers(testdf)\n","effccdb3":"def featureScaleAllExcept(df, targCol='target'):\n    \n    for cindex in df.columns:\n        if '_TF' not in cindex:\n            if (cindex != targCol) & (cindex !='object_id'):\n                minval=np.min(df.loc[:,cindex])\n                theRange=np.max(df.loc[:,cindex])-minval\n                if theRange==0:\n                    #this feature contains no information\n                    df=df.drop(cindex,axis=1)\n                    print('dropped ' + str(cindex) + ' from dataFrame')\n\n                elif type(df[cindex])==bool:\n                    print(str(cindex) + ' is a boolean, doing nothing')\n\n                elif theRange==1:\n                    print('the range for ' + str(cindex) + ' is already 1, doing nothing')\n\n                else:\n                    #feature scale\n                    df.loc[:,cindex]=(df.loc[:,cindex]-minval)\/theRange\n                \n    return df\n\nprint(traindf.shape)\ntraindf=featureScaleAllExcept(traindf)\nprint(traindf.shape)\nprint(traindf.loc[:,'target'].unique())\n\nprint(testdf.shape)\ntestdf=featureScaleAllExcept(testdf)\nprint(testdf.shape)","63b98ce5":"print(traindf.shape)\n\nprint(testdf.shape)\n","a5db5e37":"#trobjdf.to_csv('trainObjectIds.csv',sep='\\t', encoding='utf-8', index=False)","dc959aee":"traindf = traindf.round(8)\ntraindf.to_csv('traindfNormal.csv', index=False)","fdce8d07":"#teobjdf.to_csv('testObjectIds.csv',sep='\\t', encoding='utf-8', index=False)","e10d9ae5":"testdf = testdf.round(8)\ntestdf.to_csv('testdfNormal.csv', index=False)","c0162d78":"## Save the object_id and then remove for modeling","ba9b0976":"## Call this method on each population split during cross validation\n- It is NOT appropriate to use it prior to cross validation\n- and there's no guarantee every class will be in every cross validated sample\n","6c767db9":"## This kernel expands on **[this work](https:\/\/www.kaggle.com\/qianchao\/smote-with-imbalance-data)**\n- in addition to handling multiclass, it creates a method that can be called repeatedly\n- which is important because [SMOTE should be done AFTER cross validation splits](https:\/\/www.marcoaltini.com\/blog\/dealing-with-imbalanced-data-undersampling-oversampling-and-proper-cross-validation)**","5399ceca":"## Let's get rid of features that shouldn't be used in the model\n- these are features on the way to other features but not necessarily interesting on their own","d69c8c94":"## Let's try to get the distmod analog","943139a4":"## Check for nan","25b0920b":"## Repeat for test","02e14eb0":"## We're ready to start training models\n- We have oversampling training sets for both inter-galactic and extra-galactic objects","3b7891ff":"\n## I don't think we need to split the dataset into inter and extra galactic\n- It was pretty darn easy for us to see the feature to split on\n- I trust that any algorithm we use will find it equally easy","7f4f120e":"## Feature scale and eliminate features that contain no information","7ecdcba6":"## Lets deal with extreme outliers\n- need to keep track so you can reverse this method","21059153":"## since hostgal_specz is missing for most test records, we'll get rid of it\n- in both sets since there's no point in training on it","80670435":"## Repeat for test","842b7eee":"## Let's do some feature engineering on these features\n- Looking at [this discussion](https:\/\/www.kaggle.com\/c\/PLAsTiCC-2018\/discussion\/71827) for guidance\n- But hoping to repeat for each subpopulation","79fddfd6":"## Repeat for test"}}