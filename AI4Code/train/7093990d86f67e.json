{"cell_type":{"9a597c49":"code","96ff05ed":"code","2b570dea":"code","239effc3":"code","639d1da3":"code","b675a61e":"code","d852586d":"code","5a26602c":"code","ef50db38":"code","2e11c8dc":"code","57a954fa":"code","66fd2b42":"code","c47a2b88":"code","122e020a":"code","398b8ffc":"code","3a185b97":"code","36d82f1d":"code","32498cbb":"code","2ce4ccdc":"code","833dcfbb":"code","53fa361b":"code","5bfe5064":"code","771a323f":"code","3c347c6c":"code","2775e48b":"code","2f6c0b06":"code","27ec920c":"code","d1ff07fb":"code","b7437305":"code","dca5c653":"code","60f877f8":"code","f9e8f925":"code","7539cbae":"code","a6205da4":"code","143d5b63":"code","7368dcd0":"code","f648b7e8":"code","06d6bfb1":"code","8aea2483":"code","d5f5356c":"code","4149f4fd":"code","b081d8ac":"code","884e7830":"code","42712752":"code","55077eb4":"code","f8f3726d":"code","56da741c":"code","eb592fbe":"code","cad8195c":"code","e2f76026":"code","1f62c505":"code","27c42873":"code","f581f2b7":"code","779667bd":"code","b5da07da":"code","7011cff6":"code","0dd7988f":"code","59296ea5":"code","0fea3527":"code","48443c25":"code","529933f2":"code","b029b27e":"code","8af74284":"code","8db1ac1f":"code","828906ed":"code","9f512506":"code","951e7233":"code","6260678f":"code","6b89ffd0":"code","2be88659":"code","75f4301d":"code","b2a43766":"code","9b95a05a":"code","b5aa40ae":"code","69dd3ade":"code","9a876389":"code","626a6702":"code","90dbd7e0":"code","f9df5114":"code","eec90d23":"code","28850e55":"code","9e55ead9":"code","f1781b85":"code","3b5c3941":"code","ab930cd1":"code","356e73c2":"code","1f7a5b55":"code","dafd8525":"code","aeb6ada4":"code","e0ff0604":"code","8247fbbd":"code","12064743":"code","a6ff20fe":"code","ddb30f1f":"code","ed5cff23":"code","9c31e9b8":"code","ad64d34b":"code","8a7f6f41":"code","3b317482":"markdown","4307e31d":"markdown","92654193":"markdown","4cad08bc":"markdown","9005420d":"markdown","0237187c":"markdown","d1491167":"markdown","c9220259":"markdown","650cfda7":"markdown","ff3ff4fa":"markdown","14ca88ca":"markdown","7a6f9894":"markdown","51531218":"markdown","c39f18b3":"markdown","7f547e04":"markdown","037fbe9c":"markdown","2168275c":"markdown","2ff742f1":"markdown","3378db1c":"markdown","bc324006":"markdown","bb31ba84":"markdown","00165167":"markdown","2309fe28":"markdown","4474200f":"markdown","7c914f9e":"markdown","1af1b411":"markdown","9cefd083":"markdown","62ed6f33":"markdown","66fc5dd3":"markdown","bfb66377":"markdown","d540e2e6":"markdown","0071a3b9":"markdown","e7745b65":"markdown","204281fe":"markdown","882bd4d0":"markdown","7ff1f874":"markdown","ad804259":"markdown","52e22479":"markdown","f5f57b4c":"markdown","50e82152":"markdown","fd216b64":"markdown","ff8cd3ed":"markdown","c5e18e3e":"markdown","81d852ea":"markdown","f33e0fbc":"markdown","5c0c90ac":"markdown","a30655ac":"markdown","ac6c66bd":"markdown","016c9b65":"markdown","81c6a797":"markdown","848f7115":"markdown"},"source":{"9a597c49":"import numpy as np \nimport pandas as pd\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport seaborn as sns\n# sns.set_palette('Set2')\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Supress Scientific notation in python\npd.set_option('display.float_format', lambda x: '%.2f' % x)\n\n# Display all columns of long dataframe\npd.set_option('display.max_columns', None)\n\nimport time\nimport datetime as dt\n\nwarnings.filterwarnings(\"ignore\")","96ff05ed":"path = \"..\/input\/online-retail-data-set-from-uci-ml-repo\/\"","2b570dea":"# Import datasets\ntrain = pd.read_excel(path+'Online Retail.xlsx', parse_dates=['InvoiceDate'])","239effc3":"# Check the shape of dataset\ntrain.shape","639d1da3":"train.head()","b675a61e":"print(f'Duplicate items in train dataset is {train.duplicated().sum()}')","d852586d":"# Remove duplicate items \ntrain = train[~train.duplicated()]","5a26602c":"# Define function to find missing values\ndef missing_values_table(df):\n        # Total missing values\n        mis_val = df.isnull().sum()        \n        # Percentage of missing values\n        mis_val_percent = 100 * df.isnull().sum() \/ len(df)        \n        # Make a table with the results\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)        \n        # Rename the columns\n        mis_val_table_ren_columns = mis_val_table.rename(columns = {0 : 'Missing Values', 1 : '% of Total Values'})        \n        # Sort the table by percentage of missing descending\n        mis_val_table_ren_columns = mis_val_table_ren_columns[mis_val_table_ren_columns.iloc[:,1] != 0].sort_values('% of Total Values', ascending=False).round(1)        \n        # Print some summary information\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"+\"There are \" + str(mis_val_table_ren_columns.shape[0]) +\" columns that have missing values.\")        \n        # Return the dataframe with missing information\n        return mis_val_table_ren_columns","ef50db38":"missing_values_table(train)","2e11c8dc":"# Create a list of unique InvoiceNo with null CustomerID records\nInvoice_list = train[train.CustomerID.isnull()]['InvoiceNo'].tolist()","57a954fa":"# Check for the number of records with these InvoicNo\nlen(train[train.InvoiceNo.isin(Invoice_list)])    ","66fd2b42":"# We don't need records with Null customer id for RFM analysis so let's remove those first\nrfm_train = train[train.CustomerID.notnull()].copy()","c47a2b88":"# Convert remaining Customer Ids to int type\nrfm_train.CustomerID = (rfm_train.CustomerID).astype(int)","122e020a":"# Check the count of missing values after removing Null customer id records\nmissing_values_table(rfm_train) # Train","398b8ffc":"# Check and remove transactions with cancelled items.\ndesc_df = rfm_train[~rfm_train.InvoiceNo.str.contains('C', na=False)]","3a185b97":"# Let's create a feature with total cost of the transactions\ndesc_df['Total_cost'] = rfm_train.Quantity * rfm_train.UnitPrice","36d82f1d":"# Check the oldest and latest date in the dataset.\nprint(f'Oldest date is - {desc_df.InvoiceDate.min()}\\n')\nprint(f'Latest date is - {desc_df.InvoiceDate.max()}')","32498cbb":"# Check the top ten countries in the dataset with highest transactions\ndesc_df.Country.value_counts(normalize=True).head(10).mul(100).round(1).astype(str) + '%'","2ce4ccdc":"# Count of transactions in different years\ndesc_df.InvoiceDate.dt.year.value_counts(sort=False).plot(kind='bar', rot=45);","833dcfbb":"# Count of transactions in different months within 2011 year.\ndesc_df[desc_df.InvoiceDate.dt.year==2011].InvoiceDate.dt.month.value_counts(sort=False).plot(kind='bar');","53fa361b":"# Let's visualize the top grossing months\nmonthly_gross = desc_df[desc_df.InvoiceDate.dt.year==2011].groupby(desc_df.InvoiceDate.dt.month).Total_cost.sum()\nplt.figure(figsize=(10,5))\nsns.lineplot(y=monthly_gross.values,x=monthly_gross.index, marker='o');\nplt.xticks(range(1,13))\nplt.show();","5bfe5064":"# Boxplot to visualize the Quantity distribution\nplt.figure(figsize=(16,4))\nsns.boxplot(y='Quantity', data=desc_df, orient='h');","771a323f":"# Let's visualize the Unit price distribution\nplt.figure(figsize=(16,4))\nsns.boxplot(y='UnitPrice', data=desc_df, orient='h');","3c347c6c":"desc_df.head()","2775e48b":"# Let's visualize some top products from the whole range.\ntop_products = desc_df['Description'].value_counts()[:20]\nplt.figure(figsize=(10,6))\nsns.set_context(\"paper\", font_scale=1.5)\nsns.barplot(y = top_products.index,\n            x = top_products.values)\nplt.title(\"Top selling products\")\nplt.show();","2f6c0b06":"%%html\n<div class='tableauPlaceholder' id='viz1574249006038' style='position: relative'><noscript><a href='#'><img alt=' ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Mu&#47;Multinationonlineretailstore&#47;OnlineStoreDashboard&#47;1_rss.png' style='border: none' \/><\/a><\/noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' \/> <param name='embed_code_version' value='3' \/> <param name='site_root' value='' \/><param name='name' value='Multinationonlineretailstore&#47;OnlineStoreDashboard' \/><param name='tabs' value='no' \/><param name='toolbar' value='yes' \/><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Mu&#47;Multinationonlineretailstore&#47;OnlineStoreDashboard&#47;1.png' \/> <param name='animate_transition' value='yes' \/><param name='display_static_image' value='yes' \/><param name='display_spinner' value='yes' \/><param name='display_overlay' value='yes' \/><param name='display_count' value='yes' \/><\/object><\/div>                <script type='text\/javascript'>                    var divElement = document.getElementById('viz1574249006038');                    var vizElement = divElement.getElementsByTagName('object')[0];                    if ( divElement.offsetWidth > 800 ) { vizElement.style.width='1100px';vizElement.style.height='877px';} else if ( divElement.offsetWidth > 500 ) { vizElement.style.width='1100px';vizElement.style.height='877px';} else { vizElement.style.width='100%';vizElement.style.height='1777px';}                     var scriptElement = document.createElement('script');                    scriptElement.src = 'https:\/\/public.tableau.com\/javascripts\/api\/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                <\/script>","27ec920c":"# Create a copy of rfm_train dataframe for cohort analysis\ncohort = rfm_train.copy()","d1ff07fb":"# Define a function that will parse the date\ndef get_month(x):\n    return dt.datetime(x.year,x.month,1) \n\n# Create InvoiceMonth column\ncohort['InvoiceMonth'] = cohort['InvoiceDate'].apply(get_month) \n\n# Group by CustomerID and select the InvoiceMonth value\ngrouping = cohort.groupby('CustomerID')['InvoiceMonth'] \n\n# Assign a minimum InvoiceMonth value to the dataset\ncohort['CohortMonth'] = grouping.transform('min')","b7437305":"def get_date_int(df, column):\n    year = df[column].dt.year\n    month = df[column].dt.month\n    return year, month","dca5c653":"# Get the integers for date parts from the `InvoiceMonth` column\ninvoice_year, invoice_month = get_date_int(cohort,'InvoiceMonth')\n\n# Get the integers for date parts from the `CohortMonth` column\ncohort_year, cohort_month = get_date_int(cohort,'CohortMonth')","60f877f8":"# Calculate difference in years\nyears_diff = invoice_year - cohort_year\n\n# Calculate difference in months\nmonths_diff = invoice_month - cohort_month\n\n# Extract the difference in months from all previous values\ncohort['CohortIndex'] = years_diff * 12 + months_diff + 1","f9e8f925":"cohort.head()","7539cbae":"grouping = cohort.groupby(['CohortMonth', 'CohortIndex'])","a6205da4":"# Count the number of unique values per customer ID\ncohort_data = grouping['CustomerID'].apply(pd.Series.nunique).reset_index()\n\n# Create a pivot \ncohort_counts = cohort_data.pivot(index='CohortMonth', columns='CohortIndex', values='CustomerID')\n\n# Select the first column and store it to cohort_sizes\ncohort_sizes = cohort_counts.iloc[:,0]\n\n# Divide the cohort count by cohort sizes along the rows\nretention = cohort_counts.divide(cohort_sizes, axis=0)*100","143d5b63":"month_list = [\"Dec '10\", \"Jan '11\", \"Feb '11\", \"Mar '11\", \"Apr '11\",\\\n              \"May '11\", \"Jun '11\", \"Jul '11\", \"Aug '11\", \"Sep '11\", \\\n              \"Oct '11\", \"Nov '11\", \"Dec '11\"]\n\n# Initialize inches plot figure\nplt.figure(figsize=(15,7))\n\n# Add a title\nplt.title('Retention by Monthly Cohorts')\n\n# Create the heatmap\nsns.heatmap(data=retention,\n            annot = True,\n            cmap = \"Blues\",\n            vmin = 0.0,\n#             vmax = 0.5,\n            vmax = list(retention.max().sort_values(ascending = False))[1]+3,\n            fmt = '.1f',\n            linewidth = 0.3,\n            yticklabels=month_list)\n\nplt.show();","7368dcd0":"# Create a groupby object and pass the monthly cohort and cohort index as a list\ngrouping = cohort.groupby(['CohortMonth', 'CohortIndex']) \n\n# Calculate the average of the unit price column\ncohort_data = grouping['UnitPrice'].mean()\n\n# Reset the index of cohort_data\ncohort_data = cohort_data.reset_index()\n\n# Create a pivot \naverage_price = cohort_data.pivot(index='CohortMonth', columns='CohortIndex', values='UnitPrice')\naverage_price.round(1)\naverage_price.index = average_price.index.date","f648b7e8":"# Initialize plot figure\nplt.figure(figsize=(15, 7))\n\n# Add a title\nplt.title('Average Spend by Monthly Cohorts')\n\n# Create the heatmap\nsns.heatmap(data = average_price,\n            annot=True,\n            vmin = 0.0,\n#             vmax =20,\n            cmap='Blues',\n            vmax = list(average_price.max().sort_values(ascending = False))[1]+3,\n            fmt = '.1f',\n            linewidth = 0.3,\n            yticklabels=month_list)\nplt.show();","06d6bfb1":"# Create a groupby object and pass the monthly cohort and cohort index as a list\ngrouping = cohort.groupby(['CohortMonth', 'CohortIndex']) \n\n# Calculate the average of the Quantity column\ncohort_data = grouping['Quantity'].mean()\n\n# Reset the index of cohort_data\ncohort_data = cohort_data.reset_index()\n\n# Create a pivot \naverage_quantity = cohort_data.pivot(index='CohortMonth', columns='CohortIndex', values='Quantity')\n# average_quantity.round(1)\n# average_quantity.index = average_quantity.index.date","8aea2483":"# Initialize plot figure\nplt.figure(figsize=(15, 7))\n\n# Add a title\nplt.title('Average Quantity per Monthly Cohorts')\n\n# Create the heatmap\nsns.heatmap(data = average_quantity,\n            annot=True,\n            vmin = 0.0,\n            cmap='Blues',\n            vmax = list(average_quantity.max().sort_values(ascending = False))[1]+3,\n            fmt = '.1f',\n            linewidth = 0.3,\n            yticklabels=month_list)\nplt.show();","d5f5356c":"#last date available in our dataset\nrfm_train['InvoiceDate'].max()","4149f4fd":"# Lets set this date as the today's date for further analysis\ncurrent_date = dt.date(2011,12,9)","b081d8ac":"# Lets create a date column for date values only\nrfm_train['Purchase_Date'] = rfm_train.InvoiceDate.dt.date","884e7830":"recency = rfm_train.groupby('CustomerID')['Purchase_Date'].max().reset_index()","42712752":"# Create a separate column for this date.\nrecency = recency.assign(Current_Date = current_date)","55077eb4":"# Compute the number of days since last purchase\nrecency['Recency'] = recency.Purchase_Date.apply(lambda x: (current_date - x).days)","f8f3726d":"recency.head()","56da741c":"# Drop the irrelevant Date columns\nrecency.drop(['Purchase_Date','Current_Date'], axis=1, inplace=True)","eb592fbe":"frequency = rfm_train.groupby('CustomerID').InvoiceNo.nunique().reset_index().rename(columns={'InvoiceNo':'Frequency'})","cad8195c":"frequency.head()","e2f76026":"# Create a separate column for Total Cost of Unit purchased\nrfm_train['Total_cost'] = rfm_train.Quantity * rfm_train.UnitPrice","1f62c505":"monetary = rfm_train.groupby('CustomerID').Total_cost.sum().reset_index().rename(columns={'Total_cost':'Monetary'})","27c42873":"monetary.head()","f581f2b7":"temp_ = recency.merge(frequency, on='CustomerID')\nrfm_table = temp_.merge(monetary, on='CustomerID')","779667bd":"rfm_table.set_index('CustomerID',inplace=True)\nrfm_table.head()","b5da07da":"# Fetch the records corresponding to the first customer id in above table\nrfm_train[rfm_train.CustomerID == rfm_table.index[0]]","7011cff6":"# Check if the number difference of days from the purchase date in original record is same as shown in rfm table.\n(current_date - rfm_train[rfm_train.CustomerID == rfm_table.index[0]].iloc[0].Purchase_Date).days == rfm_table.iloc[0,0]","0dd7988f":"# RFM Quantiles\nquantiles = rfm_table.quantile(q=[0.25,0.5,0.75])\nquantiles","59296ea5":"# Let's convert quartile information into a dictionary so that cutoffs can be picked up.\nquantiles=quantiles.to_dict()\nquantiles","0fea3527":"# Arguments (x = value, p = recency, monetary_value, frequency, d = quantiles dict)\ndef RScore(x,p,d):\n    if x <= d[p][0.25]:\n        return 4\n    elif x <= d[p][0.50]:\n        return 3\n    elif x <= d[p][0.75]: \n        return 2\n    else:\n        return 1","48443c25":"# Arguments (x = value, p = recency, monetary_value, frequency, k = quantiles dict)\ndef FMScore(x,p,d):\n    if x <= d[p][0.25]:\n        return 1\n    elif x <= d[p][0.50]:\n        return 2\n    elif x <= d[p][0.75]: \n        return 3\n    else:\n        return 4","529933f2":"rfm_segment = rfm_table.copy()\nrfm_segment['R_Quartile'] = rfm_segment['Recency'].apply(RScore, args=('Recency',quantiles,))\nrfm_segment['F_Quartile'] = rfm_segment['Frequency'].apply(FMScore, args=('Frequency',quantiles,))\nrfm_segment['M_Quartile'] = rfm_segment['Monetary'].apply(FMScore, args=('Monetary',quantiles,))","b029b27e":"rfm_segment.head()","8af74284":"rfm_segment['RFMScore'] = rfm_segment.R_Quartile.map(str) \\\n                            + rfm_segment.F_Quartile.map(str) \\\n                            + rfm_segment.M_Quartile.map(str)\nrfm_segment.head()","8db1ac1f":"# Reset the index to create a customer_ID column\nrfm_segment.reset_index(inplace=True)","828906ed":"# Create a dictionary for each segment to map them against each customer\nsegment_dict = {\n    'Best Customers':'444',      # Highest frequency as well as monetary value with least recency\n    'Loyal Customers':'344',     # High frequency as well as monetary value with good recency\n    'Big Spenders':'334',        # High monetary value but good recency and frequency values\n    'Almost Lost':'244',         # Customer's shopping less often now who used to shop a lot\n    'Lost Customers':'144',      # Customer's shopped long ago who used to shop a lot.\n    'Recent Customers':'443',    # Customer's who recently started shopping a lot but with less monetary value\n    'Lost Cheap Customers':'122' # Customer's shopped long ago but with less frequency and monetary value\n}","9f512506":"# Swap the key and value of dictionary\ndict_segment = dict(zip(segment_dict.values(),segment_dict.keys()))","951e7233":"# Allocate segments to each customer as per the RFM score mapping\nrfm_segment['Segment'] = rfm_segment.RFMScore.map(lambda x: dict_segment.get(x))","6260678f":"# Allocate all remaining customers to others segment category\nrfm_segment.Segment.fillna('others', inplace=True)","6b89ffd0":"rfm_segment.sample(10)","2be88659":"%%html\n<div class='tableauPlaceholder' id='viz1574249157493' style='position: relative'><noscript><a href='#'><img alt=' ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;RF&#47;RFM_Analysis_15741611609370&#47;RFMAnalysis&#47;1_rss.png' style='border: none' \/><\/a><\/noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' \/> <param name='embed_code_version' value='3' \/> <param name='site_root' value='' \/><param name='name' value='RFM_Analysis_15741611609370&#47;RFMAnalysis' \/><param name='tabs' value='no' \/><param name='toolbar' value='yes' \/><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;RF&#47;RFM_Analysis_15741611609370&#47;RFMAnalysis&#47;1.png' \/> <param name='animate_transition' value='yes' \/><param name='display_static_image' value='yes' \/><param name='display_spinner' value='yes' \/><param name='display_overlay' value='yes' \/><param name='display_count' value='yes' \/><\/object><\/div>                <script type='text\/javascript'>                    var divElement = document.getElementById('viz1574249157493');                    var vizElement = divElement.getElementsByTagName('object')[0];                    if ( divElement.offsetWidth > 800 ) { vizElement.style.width='1100px';vizElement.style.height='877px';} else if ( divElement.offsetWidth > 500 ) { vizElement.style.width='1100px';vizElement.style.height='877px';} else { vizElement.style.width='100%';vizElement.style.height='1777px';}                     var scriptElement = document.createElement('script');                    scriptElement.src = 'https:\/\/public.tableau.com\/javascripts\/api\/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                <\/script>","75f4301d":"# Best Customers who's recency, frequency as well as monetary attribute is highest.\nrfm_segment[rfm_segment.RFMScore=='444'].sort_values('Monetary', ascending=False).head()","b2a43766":"# Biggest spenders\nrfm_segment[rfm_segment.RFMScore=='334'].sort_values('Monetary', ascending=False).head()","9b95a05a":"# Almost Lost i.e. who's recency value is low\nrfm_segment[rfm_segment.RFMScore=='244'].sort_values('Monetary', ascending=False).head()","b5aa40ae":"# Lost customers that don't needs attention who's recency, frequency as well as monetary values are low\nrfm_segment[rfm_segment.RFMScore=='122'].sort_values('Monetary', ascending=False).head()","69dd3ade":"# loyal customers who's purchase frequency is high\nrfm_segment[rfm_segment.RFMScore=='344'].sort_values('Monetary', ascending=False).head()","9a876389":"# customers that you must retain are those whose monetary and frequency was high but recency reduced quite a lot recently\nrfm_segment[rfm_segment.RFMScore=='244'].sort_values('Monetary', ascending=False).head()","626a6702":"# plot\nfig, axes = plt.subplots(3, 1, figsize=(15, 15))\nsns.distplot(rfm_table.Recency , color=\"dodgerblue\", ax=axes[0], axlabel='Recency')\nsns.distplot(rfm_table.Frequency , color=\"deeppink\", ax=axes[1], axlabel='Frequency')\nsns.distplot(rfm_table.Monetary , color=\"gold\", ax=axes[2], axlabel='Monetary')\n# plt.xlim(50,75);\nplt.show();","90dbd7e0":"# Let's describe the table to see if there are any negative values\nrfm_table.describe()","f9df5114":"# Create a copy of rfm table\nrfm_table_scaled = rfm_table.copy()\n\n# Shift all values in the column by adding absolute of minimum value to each value, thereby making each value positive.\nrfm_table_scaled.Monetary = rfm_table_scaled.Monetary + abs(rfm_table_scaled.Monetary.min()) + 1\nrfm_table_scaled.Recency = rfm_table_scaled.Recency + abs(rfm_table_scaled.Recency.min()) + 1\n\n# Check the summary of new values\nrfm_table_scaled.describe()","eec90d23":"# Transform the data before K-Means clustering\nfrom sklearn.preprocessing import StandardScaler\n\n# Taking log first because normalization forces data for negative values\nlog_df = np.log(rfm_table_scaled)\n\n# Normalize the data for uniform averages and means in the distribution.\nscaler = StandardScaler()\nnormal_df = scaler.fit_transform(log_df)\nnormal_df = pd.DataFrame(data=normal_df, index=rfm_table.index, columns=rfm_table.columns)","28850e55":"# plot again on the transformed RFM data\nfig, axes = plt.subplots(3, 1, figsize=(15, 15))\nsns.distplot(normal_df.Recency , color=\"dodgerblue\", ax=axes[0], axlabel='Recency')\nsns.distplot(normal_df.Frequency , color=\"deeppink\", ax=axes[1], axlabel='Frequency')\nsns.distplot(normal_df.Monetary , color=\"gold\", ax=axes[2], axlabel='Monetary')\nplt.show();","9e55ead9":"# find WCSS\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nwcss = []\nfor i in range(1,11):\n    kmeans = KMeans(n_clusters=i, init='k-means++')\n    kmeans.fit(normal_df)\n    wcss.append(kmeans.inertia_)\n\n# plot elbow graph\nplt.plot(range(1,11),wcss,marker='o');","f1781b85":"from sklearn.metrics import silhouette_score\nwcss_silhouette = []\nfor i in range(2,12):\n    km = KMeans(n_clusters=i, random_state=0,init='k-means++').fit(normal_df)\n    preds = km.predict(normal_df)    \n    silhouette = silhouette_score(normal_df,preds)\n    wcss_silhouette.append(silhouette)\n    print(\"Silhouette score for number of cluster(s) {}: {}\".format(i,silhouette))\n\nplt.figure(figsize=(10,5))\nplt.title(\"The silhouette coefficient method \\nfor determining number of clusters\\n\",fontsize=16)\nplt.scatter(x=[i for i in range(2,12)],y=wcss_silhouette,s=150,edgecolor='k')\nplt.grid(True)\nplt.xlabel(\"Number of clusters\",fontsize=14)\nplt.ylabel(\"Silhouette score\",fontsize=15)\nplt.xticks([i for i in range(2,12)],fontsize=14)\nplt.yticks(fontsize=15)\nplt.show()","3b5c3941":"kmeans = KMeans(n_clusters=4, random_state=1, init='k-means++')\nkmeans.fit(normal_df)\ncluster_labels = kmeans.labels_","ab930cd1":"kmeans","356e73c2":"print(f\"Shape of cluster label array is {cluster_labels.shape}\")\nprint(f\"Shape of RFM segment dataframe is {rfm_segment.shape}\")","1f7a5b55":"# Assign the clusters as column to each customer\nCluster_table = rfm_segment.assign(Cluster = cluster_labels)","dafd8525":"# Check counts of records assigned to different clusters\nCluster_table.Cluster.value_counts()","aeb6ada4":"Cluster_table.sample(10)","e0ff0604":"Cluster_table[Cluster_table.Cluster == 3].sample(5)","8247fbbd":"Cluster_table[Cluster_table.Cluster == 2].sample(5)","12064743":"Cluster_table[Cluster_table.Cluster == 1].sample(5)","a6ff20fe":"Cluster_table[Cluster_table.Cluster == 0].sample(5)","ddb30f1f":"# Plotting two dimesional plots of each attributes respectively.\nX = normal_df.iloc[:,0:3].values\ncount=X.shape[1]\nfor i in range(0,count):\n    for j in range(i+1,count):\n        plt.figure(figsize=(15,6));\n        plt.scatter(X[cluster_labels == 0, i], X[cluster_labels == 0, j], s = 10, c = 'red', label = 'Cluster0')\n        plt.scatter(X[cluster_labels == 1, i], X[cluster_labels == 1, j], s = 10, c = 'blue', label = 'Cluster1')\n        plt.scatter(X[cluster_labels == 2, i], X[cluster_labels == 2, j], s = 10, c = 'green', label = 'Cluster2')\n        plt.scatter(X[cluster_labels == 3, i], X[cluster_labels == 3, j], s = 10, c = 'cyan', label = 'Cluster3')\n        plt.scatter(kmeans.cluster_centers_[:,i], kmeans.cluster_centers_[:,j], s = 50, c = 'black', label = 'Centroids')\n        plt.xlabel(normal_df.columns[i])\n        plt.ylabel(normal_df.columns[j])\n        plt.legend()        \n        plt.show();","ed5cff23":"# Assign Cluster values to each customer in normalized dataframe\nnormal_df = normal_df.assign(Cluster = cluster_labels)\n\n# Melt normalized dataframe into long form to have all metric in same column\nnormal_melt = pd.melt(normal_df.reset_index(),\n                      id_vars=['CustomerID','Cluster'],\n                      value_vars=['Recency', 'Frequency', 'Monetary'],\n                      var_name='Metric',\n                      value_name='Value')\nnormal_melt.head()","9c31e9b8":"# a snake plot with K-Means\nplt.figure(figsize=(15,5))\npalette = sns.color_palette(\"mako_r\", 4)\nsns.lineplot(x = 'Metric',\n             y = 'Value',\n             hue = 'Cluster',\n             data = normal_melt,\n             palette = \"ch:4.4,.44\")\n\nplt.suptitle(\"Snake Plot of RFM\",fontsize=20)\nplt.show();","ad64d34b":"# Assign Cluster labels to RFM table\nrfm_table_cluster = rfm_table.assign(Cluster = cluster_labels)\n\n# Average attributes for each cluster\ncluster_avg = rfm_table_cluster.groupby(['Cluster']).mean() \n\n# Calculate the population average\npopulation_avg = rfm_table.mean()\n\n# Calculate relative importance of attributes by \nrelative_imp = cluster_avg \/ population_avg - 1","8a7f6f41":"plt.figure(figsize=(10, 5))\nplt.title('Relative importance of attributes')\nsns.heatmap(data=relative_imp, annot=True, fmt='.2f', cmap='RdYlGn')\nplt.show();","3b317482":"### Snake plots \n\n- Market research technique to compare different segments\n- Visual representation of each segment's attributes\n- Plot each cluster's average normalized values of each attribute\n\n*To plot this we should have normalized data distribution and all the attributes in a single column. We will use pandas melt facility on normal_df to achieve that*","4307e31d":"### Customer segments with RFM Model\nThe simplest way to create customers segments from RFM Model is to use Quantiles. We assign a score from 1 to 4 to Recency, Frequency and Monetary. Four is the best\/highest value, and one is the lowest\/worst value. A final RFM score is calculated simply by combining individual RFM score numbers.","92654193":"We can observe that Monetary contains negative values. So first we need to make sure that minimum range of value starts from 1 otherwise log transformation may lead to errors in graph plotting as well as K-Means clustering. After that we will utilize log transformation and scaling to make data available for for K-Means clustering.","4cad08bc":"### RFM Segment allocation\n\nLets define the customers segment best to our knowledge basis RFM score and assign them to each customer respectively.","9005420d":"## K-Means Clustering\nWe will now cluster our customers with K-Means! So let's visualize the data distribution in RFM table","0237187c":"**Here is the Tableau interactive dashboard for Data analysis of the online store. Please try to explore by clicking on individual attribute in the graphs under the dashboard** \n\n**NOTE**: please disable any ad-blocker if the tableau visual is not visible","d1491167":"### Calculate average quantity per cohort\n\nNow we will calculate the average quantity metric and analyze if there are any differences in shopping patterns across time and across cohorts.","c9220259":"### EDA\n\nNow let's do some Exploratory Data Analysis on the processed dataset","650cfda7":"Here it can be seen that the RFM score for Cluster 3 customers is somwhat average collectively. So these are more or less those customers which shops occasionally and can respond to the targeted campaigns","ff3ff4fa":"**Here is the Tableau interactive dashboard for Data analysis of the online store. Please try to explore by clicking on individual attribute in the graphs under the dashboard** \n\n**NOTE**: please disable any ad-blocker if the tableau visual is not visible","14ca88ca":"### Heat Map\n\nWe will utilize heat map to visualize the relative importance of each attributes in all four customer segments i.e. clusters. It calculates importance score by dividing them and subtracting 1 (ensures 0 is returned when cluster average equals population average). \n\nThe farther a ratio is from 0, the more important that attribute is for a segment relative to the total population.","7a6f9894":"#### Duplicate records\n\nLet's check for any duplicate record first, as those need to be removed first before any further analysis.","51531218":"Cluster 1 has the customer segment with very high monetary value along with good frequency and recency values. These are the most valuable customers to the firm. They should be looked after periodically to access there concerns.","c39f18b3":"We can clearly see the different customers segments with the help of scatter plots. Most evidently from the plot of Recency v\/s frequency almost each segment is seprate without much overlap.\n\nNow let's check the behaviour of these segments with the help of snake plots.","7f547e04":"An increasing pattern can be observed month by month wise with a sharp decline in the month of December. That is evident because only first 8-9 days of December 2011 month is available in the dataset i.e. around 70% of the month transactions are not considered. Due to this fact, sales figure looks legitimate.","037fbe9c":"## Problem Statement\nWe have to perform cohort and RFM analysis to understand the value derived from different customer segments. Further, we will divide customers in different clusters based on the analysis by using K-means algorithm.\n\n## Dataset Description\nThis is a transnational data set which contains all the transactions that occurred between 01\/12\/2010 and 09\/12\/2011 for a UK-based and registered non-store online retail. The company mainly sells unique and all-occasion gifts.\n\n### Variables\tDescription\n- **InvoiceNo**\tInvoice number. Nominal, a six digit integral number uniquely assigned to each transaction. If this code starts with letter 'c', it indicates a cancellation\n- **StockCode**\tProduct (item) code. Nominal, a five digit integral number uniquely assigned to each distinct product\n- **Description**\tProduct (item) name. Nominal\n- **Quantity**\tThe quantities of each product (item) per transaction. Numeric\n- **InvoiceDate**\tInvoice Date and time. Numeric, the day and time when each transaction was generated\n- **UnitPrice**\tUnit price. Numeric, product price per unit in sterling\n- **CustomerID**\tCustomer number. Nominal, a six digit integral number uniquely assigned to each customer\n- **Country**\tCountry name. Nominal, the name of the country where each customer resides","2168275c":"#### Let's visualize different customer segments records in general to answers these questions for the retail business.\n\n- Who are my best customers?\n- Who are the biggest spenders?\n- Which customers are at the verge of churning?\n- Who are lost customers that you don\u2019t need to pay much attention to?\n- Who are your loyal customers?\n- Which customers you must retain?\n- Who has the potential to be converted in more profitable customers?\n- Which group of customers is most likely to respond to your current campaign?","2ff742f1":"### RFM Table integrity Check\n\nLet's check whether the RFM table attributes are in conjunction with the original values","3378db1c":"Here we can observe that the data is highly skewed. So we have to transform and scale the data first because K-Means assumes that the variables should have a symmetric distributions(not skewed) and they should have same average values as well as same variance. ","bc324006":"Similarly, Price of unit data shows heavy skewed distribution towards lower values of unit price.","bb31ba84":"Now Combine all three to form an aggregated RFM Table","00165167":"This shows that Quantity data is highly skewed towards lower quantity values with some outliers. May be data entry error or might be genuine order","2309fe28":"Here we can observe that RFM score is very low for customers in 0 & 3 cluster. Comparetivey, customers in 1&2 clusters have high RFM scores along with above average Recency and frequency values. \n\nLet's checkout customers in each cluster more closely","4474200f":"Since 2010 only includes transactions done in December, therefore it is evident that most of the records belong to 2011","7c914f9e":"## RFM Analysis\n**RFM** analysis is a customer segmentation technique that uses past purchase behavior to divide customers into groups. RFM helps divide customers into various categories or clusters to identify customers who are more likely to respond to promotions and also for future personalization services.\n\n- **Recency** (R): Time since last purchase\n- **Frequency** (F): Total number of purchases \n- **Monetary** (M): Total purchase value\n\n#### Benefits of RFM analysis\n\n- Increased customer retention\n- Increased response rate\n- Increased conversion rate\n- Increased revenue\n\nTo perform RFM analysis, we divide customers into four equal groups according to the distribution of values for recency, frequency, and monetary value. Four equal groups across three variables create 64 (4x4x4) different customer segments, which is a manageable number.\n\n#### For example, let\u2019s look at a customer who:\n\n- is within the group who purchased most recently (R=4),\n- is within the group who purchased most quantity (F=4),\n- is within the group who spent the most (M=4)\n\nThis customer belongs to RFM segment **4-4-4 (Best Customers)**, (R=4, F=4, M=4)\n\nBelow is a table with key RFM segments:\n\n<img src=\"https:\/\/i.imgur.com\/TUCtmPT.png\" style=\"float: left;\">","1af1b411":"We can observe that the means & averages are approximately uniformed now in each distribution. Now the data is apt for unsupervised algo i.e. K-Means. Lets try to find number of appropriate clusters to divide customers as per there spending pattern with **elbow** method first","9cefd083":"## Cohort Analysis\n\nA cohort is a group of subjects who share a defining characteristic. We can observe how a cohort behaves across time and compare it to other cohorts. \n\n#### Types of cohorts:\n\n- **Time Cohorts** are customers who signed up for a product or service during a particular time frame. Analyzing these cohorts shows the customers\u2019 behavior depending on the time they started using the company\u2019s products or services. The time may be monthly or quarterly even daily.\n- **Behavior cohorts** are customers who purchased a product or subscribed to a service in the past. It groups customers by the type of product or service they signed up. Customers who signed up for basic level services might have different needs than those who signed up for advanced services. Understaning the needs of the various cohorts can help a company design custom-made services or products for particular segments.\n- **Size cohorts** refer to the various sizes of customers who purchase company\u2019s products or services. This categorization can be based on the amount of spending in some periodic time after acquisition or the product type that the customer spent most of their order amount in some period of time.\n\n***For cohort analysis, there are a few labels that we have to create:***\n\n- **Invoice period** - A string representation of the year and month of a single transaction\/invoice.\n- **Cohort group:**- A string representation of the the year and month of a customer\u2019s first purchase. This label is common across all invoices for a particular customer.\n- **Cohort period\/Index**- \u200aA integer representation a customer\u2019s stage in its \u201clifetime\u201d. The number represents the number of months passed since the first purchase.","62ed6f33":"### Creation of RFM Segments\nWe will create two segmentation classes since, high recency is bad, while high frequency and monetary value is good","66fc5dd3":"For analysis it is critical to combine the scores to create a single score. There are few approaches. One approach is to just concatenate the scores to create a 3 digit number between 111 and 444. Here the drawback is too many categories (4x4x4).","bfb66377":"Here we can clearly see that optimum number of cluster should be 4 not 2 or 3. Because that is the only point after which the mean cluster distance looks to be plateaued after a steep downfall. So we will assume the 4 number of clusters as best for grouping of customer segments.\n\nNow let's apply K-Means on 4 clusters to segregate the customer base.","d540e2e6":"A similar pattern is also observed in total gross each month as per the count of transactions in each month","0071a3b9":"#### Cancelled items\n\nLet's check those record which shows cancelled items. These records are not needed for Descriptive analysis but are accountable for the RFM analysis. So let's keep them in a different dataframe altogether.","e7745b65":"### Calculate time offset in months\nCalculating time offset for each transaction allows you to report the metrics for each cohort in a comparable fashion.\n\nFirst, we will create some variables that capture the integer value of years and months for Invoice and Cohort Date using the get_date_int() function","204281fe":"Cluster 2 contains customers with low recency, good frequency and high monetary value, These are the loyal customers to the firm","882bd4d0":"### Scatter plots\nThese will help us visualize the division of customers into different segments based on the RFM atributes.","7ff1f874":"Here we see that most of the customers belong to 0 and 3 cluster, whereas very less number of customers assigned to 1 cluster, may be possible that those are some of the best customers out of the pool or worst customer, lets checkout the pattern","ad804259":"From the elbow graph, it seems that good number of cluster would be either 2 or 3 as after that, its a smooth curve i.e. no change of orientation. but to overcome that confusion, we will use **silhouette score** method to find the optimum number of clusters because it is often much better in figuring out the number of valid clusters than the elbow method","52e22479":"We can observe below things through above graph:\n\n- Though the Cluster 1 and 2 shows similar pattern of attributes, but all three attributes in Cluster 1 are given more importance relative to Cluster 2.\n- Again evident that the cluster 3 which is a segment of potential customers shows an average similar importance to all three attributes as shown in the snake plot.\n- In Cluster 0 the all attributes are relatively oppsoite in valuation as compared to cluster 2.","f5f57b4c":"So around **25%** of records don't have customer id value, such records are not useful for the RFM analysis. But let's check further if there are any common records which have null and non-null customer ID but same invoice number, so that we can fill the records with same customer ID and try to decrease the loss.","50e82152":"- **Best Recency score** = 4 (most recently purchase) \n- **Best Frequency score** = 4 (most frequently purchase)\n- **Best Monetary score** = 4 (who spent the most)","fd216b64":"Here we found that the count of the Invoice with null customerID is equivalent to the number of records with missing CustomerID. Therefore we are unable to prevent the loss and have to remove all such records before any further analysis.","ff8cd3ed":"### Frequency\nFrequency is about the number of purchase in a given period. It could be 3 months, 6 months or 1 year. So we can understand this value as for how often or how many a customer used the product of a company. The bigger the value is, the more engaged the customers are. Could we say them as our VIP? Not necessary. Cause we also have to think about how much they actually paid for each purchase, which means monetary value","c5e18e3e":"### Assign monthly acquisition cohort\nDefining a cohort is the first step to cohort analysis. We will now create monthly cohorts based on the month each customer has made their first transaction.","81d852ea":"Almost 90% of records belong to the sales done in UK with some it's and bits in other countries.","f33e0fbc":"#### Missing values\n\nLet's check for any missing values in the dataset","5c0c90ac":"As expected, the last 0 cluster contains the highest number of customers who accounts for lowest value to the firm because there RFM values are lowest. Most of them are in the lost segment or on the verge of churning out. \n\nLet's try to visualize this pattern through the help Clusters","a30655ac":"### Recency\nRecency is about when was the last order of a customer. It means the number of days since a customer made the last purchase. If it\u2019s a case for a website or an app, this could be interpreted as the last visit day or the last login time.","ac6c66bd":"### Calculate retention rate\n\nCustomer retention is a very useful metric to understand how many of all the customers are still active. It gives you the percentage of active customers compared to the total number of customers\n","016c9b65":"So the behaviour of customers in different clusters is evident from the above graph:\n\n- Customer in cluster 1 has highest frequency & monetary along with lowest recency value. These are the most valuable customers to the firm\n- Customers in cluster 2 also shows similar shopping pattern like cluster 1 but on an average less value for each attributes. These are the loyal customers.\n- Customers in cluster 3 shows lower frequency, monetary as well as high recency rates as compared to cluster 2. Some of them are occasional customers who shops during shopping festival. These are more likely to respond to a campaign and has the potential to turn profitable.\n- And the customers in cluster 0 shows a totally opposite behaviour as compared to cluster 2 i.e. the highly unprofitable or the lost customers whom we don't need to pay much attention, May be some targeted offers can bring them back to shopping.","81c6a797":"### Calculate average price per cohort\n\nNow we will calculate the average price metric and analyze if there are any differences in shopping patterns across time and across cohorts.","848f7115":"### Monetary\nMonetary is the total amount of money a customer spent in that given period. Therefore big spenders will be differentiated with other customers such as MVP or VIP."}}