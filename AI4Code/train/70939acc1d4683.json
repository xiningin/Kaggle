{"cell_type":{"1d02b267":"code","68a5474a":"code","9d2094ba":"code","3b24eb21":"code","a6bcbf10":"code","290dd0a7":"code","be32e22f":"code","7675e4d2":"code","30622686":"code","311dd9f1":"code","c5861afa":"code","5caaa5f1":"code","e76ecf2b":"code","efe4fcd0":"code","c6a637ca":"code","669343cf":"code","ebeb1851":"code","dc088851":"code","dc2aa01a":"code","d1220865":"code","06ce137a":"code","7b7151ef":"code","c287b5a9":"code","abaf4abb":"code","e974db25":"code","4e4a8c53":"code","48678431":"code","e0056f2e":"code","97fa9181":"code","9dfeff79":"code","fe030243":"code","1f9a5bff":"code","fae3105d":"code","a502199d":"code","3af95af5":"code","1dd398e7":"code","df40b05f":"code","da35577d":"code","7d4f3590":"code","84c5d64b":"code","7c39d96e":"code","aa6156d8":"code","f9a48812":"code","9903a906":"code","f2484a4c":"code","1cf20143":"code","25c2a72a":"code","e608dd76":"code","fdf245bc":"code","715d564b":"code","acdbdf2f":"code","1fbc3eb0":"code","0d6ba240":"code","4fe3a71c":"code","a44dc6b3":"code","9553e3d5":"code","692c998f":"code","bcf83820":"code","5815ea8c":"code","caf41b7d":"code","d48372d2":"code","89c1ab25":"code","60dfd299":"code","c13321ec":"code","7b3353a2":"code","32991a45":"code","f1e4dcf8":"code","49b1f566":"code","d4b12b9a":"code","455194d4":"code","7b137619":"markdown","36326766":"markdown","4629a0cf":"markdown","45bbc71b":"markdown","3f0d25ae":"markdown","6b4546ac":"markdown","65b8ff4a":"markdown","6b64b5e5":"markdown","ac684333":"markdown","55704db6":"markdown","b26671a6":"markdown","2a6b33be":"markdown","1ea740a4":"markdown","5a15d7fb":"markdown","bf9c51de":"markdown","acfd1750":"markdown","10b455e8":"markdown","723bba49":"markdown","b079f0c4":"markdown","3f2ef805":"markdown","1c09f929":"markdown","96a2c54d":"markdown","0aa8a6aa":"markdown","d7f04739":"markdown","9f646339":"markdown","ca5e814e":"markdown","450853a1":"markdown","8d22d232":"markdown","bbb77b30":"markdown","437cb53f":"markdown","12bfa77e":"markdown","a0b116dc":"markdown"},"source":{"1d02b267":"# basic packages\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\n\n# geodata\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# custom y-axis\nfrom matplotlib.ticker import FuncFormatter\ndef millions(x, pos):\n    return '%1.1fM' % (x * 1e-6)\n\n# ignoring warnings\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\n# NLP\nimport unicodedata\nimport string\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.util import ngrams\nfrom wordcloud import WordCloud, STOPWORDS\nfrom collections import Counter, defaultdict\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom textblob import TextBlob\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\n# kaggle workspace\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","68a5474a":"# Loading the data\ntrump = pd.read_csv('..\/input\/us-election-2020-tweets\/hashtag_donaldtrump.csv', \n                    lineterminator='\\n', parse_dates=True)\nbiden = pd.read_csv('..\/input\/us-election-2020-tweets\/hashtag_joebiden.csv', \n                    lineterminator='\\n', parse_dates=True)\nprint('Trump dataset shape: {}'.format(trump.shape))\nprint('Biden dataset shape: {}'.format(biden.shape))","9d2094ba":"# Trump dataset general information\ntrump.info()","3b24eb21":"# Biden dataset general information\nbiden.info()","a6bcbf10":"# The sample of data\ntrump.head(3)","290dd0a7":"# The sample of data\nbiden.head(3)","be32e22f":"trump_nan = pd.Series(trump.isna().sum()[trump.isna().sum() > 0].\n                      sort_values(ascending = False))\nbiden_nan = pd.Series(biden.isna().sum()[biden.isna().sum() > 0].\n                      sort_values(ascending = False))\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17, 5))\nsns.set_style(\"whitegrid\")\nfig.suptitle('NaN values', size = 15)\n\nsns.barplot(y = trump_nan.index, x = [len(trump)] * len(trump_nan),\n            edgecolor = 'black', color = 'white', alpha = 0.6, ax = ax1)\nsns.barplot(y = trump_nan.index, x = trump_nan, \n            edgecolor = 'black', alpha = 0.8, ax = ax1,\n            palette = sns.color_palette(\"viridis\", len(trump_nan)))\nax1.get_xaxis().get_major_formatter().set_scientific(False)\nax1.set_title('Trump dataset', size = 13)\n\n\nsns.barplot(y = biden_nan.index, x = [len(biden)] * len(biden_nan),\n            edgecolor = 'black', color = 'white', alpha = 0.6, ax = ax2)\nsns.barplot(y = biden_nan.index, x = biden_nan, \n            edgecolor = 'black', alpha = 0.8, ax = ax2,\n            palette = sns.color_palette(\"viridis\", len(biden_nan)))\nax2.get_xaxis().get_major_formatter().set_scientific(False)\nax2.set_title('Biden dataset', size = 13)\n\nsns.despine()","7675e4d2":"sns.set_style(\"whitegrid\")\nplt.figure(figsize=(14, 5))\n\nsns.kdeplot(trump['likes'], label = 'Trump', shade = True, color = 'red')\nsns.kdeplot(biden['likes'], label = 'Biden', shade = True, color = 'blue')\nplt.title('Distributions of likes', size = 15)\nplt.legend(prop={'size': 14})\nplt.show()","30622686":"# the top of #donaldtrump tweets by likes\ntrump.sort_values('likes', ascending = False)[:5]","311dd9f1":"# the top of #joebiden tweets by likes\nbiden.sort_values('likes', ascending = False)[:5]","c5861afa":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\nsns.set_style(\"whitegrid\")\nfig.suptitle(\"The dependence of retweets on likes\", size = 15)\n\nsns.scatterplot(x = trump['likes'], y = trump['retweet_count'],\n                color = 'red', ax = ax1)\nax1.get_yaxis().get_major_formatter().set_scientific(False)\nax1.set_xlabel('Likes')\nax1.set_ylabel('Retweets')\nax1.set_title('Trump', size = 13)\n\n\nsns.scatterplot(x = biden['likes'], y = biden['retweet_count'],\n                color = 'blue', ax = ax2)\nax2.get_yaxis().get_major_formatter().set_scientific(False)\nax2.set_xlabel('Likes')\nax2.set_ylabel('Retweets')\nax2.set_title('Biden', size = 13)\n\nfig.show()","5caaa5f1":"print('Correlation between likes and retweets (Trump): {}'.\n      format(trump['likes'].corr(trump['retweet_count'])))\nprint('Correlation between likes and retweets (Biden): {}'.\n      format(biden['likes'].corr(biden['retweet_count'])))","e76ecf2b":"sns.set_style(\"whitegrid\")\nplt.figure(figsize=(17, 5))\n\nax = sns.lineplot(data = pd.to_datetime(trump.created_at).dt.date.value_counts(), \n                  label = 'Trump', color = 'red', linewidth = 3)\nax = sns.lineplot(data = pd.to_datetime(biden.created_at).dt.date.value_counts(), \n                  label = 'Biden', color = 'blue', linewidth = 3)\nax.xaxis.set_major_locator(mdates.DayLocator(interval=2))\nax.xaxis.set_major_formatter(mdates.DateFormatter('%d %b'))\n\nplt.title('Tweets amount changing', size = 15)\nplt.legend(prop={'size': 14})\nplt.ylabel('Tweets')\nplt.show()","efe4fcd0":"trump_tweets_countries = trump.country.value_counts()[:10]\nbiden_tweets_countries = biden.country.value_counts()[:10]\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17, 5))\nsns.set_style(\"whitegrid\")\nfig.suptitle(\"Tweet authors by countries\", size = 15)\n\nsns.barplot(y = trump_tweets_countries.index, \n            x = [len(trump)] * len(trump_tweets_countries),\n            edgecolor = 'black', color = 'white', alpha = 0.6, ax = ax1)\nsns.barplot(y = trump_tweets_countries.index, \n            x = trump_tweets_countries, \n            edgecolor = 'black', color = 'red', alpha = 0.8, ax = ax1)\nax1.get_xaxis().get_major_formatter().set_scientific(False)\nax1.set_xlabel('')\nax1.set_title('Trump', size = 13)\n\n\nsns.barplot(y = biden_tweets_countries.index, \n            x = [len(biden)] * len(biden_tweets_countries),\n           edgecolor = 'black', color = 'white', alpha = 0.6, ax = ax2)\nsns.barplot(y = biden_tweets_countries.index, \n            x = biden_tweets_countries, \n            edgecolor = 'black', color = 'blue', alpha = 0.8, ax = ax2)\nax2.get_xaxis().get_major_formatter().set_scientific(False)\nax2.set_xlabel('')\nax2.set_title('Biden', size = 13)\n\nsns.despine()","c6a637ca":"trump['country'] = trump['country'].replace(['United States of America', \n                                             'United States'], 'USA')\nbiden['country'] = biden['country'].replace(['United States of America', \n                                             'United States'], 'USA')","669343cf":"trump_tweets_countries = trump.country.value_counts()[:10]\nbiden_tweets_countries = biden.country.value_counts()[:10]\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17, 5))\nsns.set_style(\"whitegrid\")\nfig.suptitle(\"Tweet authors by countries\", size = 15)\n\nsns.barplot(y = trump_tweets_countries.index, x = [len(trump)] * len(trump_tweets_countries),\n            edgecolor = 'black', color = 'white', alpha = 0.6, ax = ax1)\nsns.barplot(y = trump_tweets_countries.index, x = trump_tweets_countries, \n            edgecolor = 'black', color = 'red', alpha = 0.8, ax = ax1)\nax1.get_xaxis().get_major_formatter().set_scientific(False)\nax1.set_xlabel('')\nax1.set_title('Trump', size = 13)\n\n\nsns.barplot(y = biden_tweets_countries.index, x = [len(biden)] * len(biden_tweets_countries),\n           edgecolor = 'black', color = 'white', alpha = 0.6, ax = ax2)\nsns.barplot(y = biden_tweets_countries.index, x = biden_tweets_countries, \n            edgecolor = 'black', color = 'blue', alpha = 0.8, ax = ax2)\nax2.get_xaxis().get_major_formatter().set_scientific(False)\nax2.set_xlabel('')\nax2.set_title('Biden', size = 13)\n\nsns.despine()","ebeb1851":"# preparation of the geodata\ntmp_tr = trump[['lat', 'long']].dropna()\ntmp_bi = biden[['lat', 'long']].dropna()\n\ngeometry_tr = [Point(xy) for xy in zip(tmp_tr['long'], tmp_tr['lat'])]\ngeometry_bi = [Point(xy) for xy in zip(tmp_bi['long'], tmp_bi['lat'])]\n\ngeo_df_tr = gpd.GeoDataFrame(geometry = geometry_tr)\ngeo_df_bi = gpd.GeoDataFrame(geometry = geometry_bi)\n\nwmap = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))","dc088851":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8), facecolor = 'white')\nplt.text(x = -325, y = 120, s = \"The geodata of tweets\", fontsize = 15)\n\nwmap.plot(ax = ax1, edgecolors='black', color = 'white')\ngeo_df_tr.plot(ax = ax1, markersize = 0.5, color = 'red')\nax1.set_title('Trump', size = 13)\nax1.axis('off')\n\nwmap.plot(ax = ax2, edgecolors='black', color = 'white')\ngeo_df_bi.plot(ax = ax2, markersize = 0.5, color = 'blue')\nax2.set_title('Biden', size = 13)\nax2.axis('off')\n\nfig.show()","dc2aa01a":"# Trump tweets authors\ntrump_count = pd.DataFrame(trump['user_name'].value_counts())\ntrump_count = pd.DataFrame({'user_name': trump_count.index, \n                            'count': trump_count.user_name})\ntrump_likes = trump[['user_name', 'likes']].groupby('user_name').sum()\ntrump_agg = pd.merge(trump_count, trump_likes, on = 'user_name', \n                     how = 'left')\n\n# Biden tweets authors\nbiden_count = pd.DataFrame(biden['user_name'].value_counts())\nbiden_count = pd.DataFrame({'user_name': biden_count.index, \n                            'count': biden_count.user_name})\nbiden_likes = biden[['user_name', 'likes']].groupby('user_name').sum()\nbiden_agg = pd.merge(biden_count, biden_likes, on = 'user_name', \n                     how = 'left')","d1220865":"# The dependence of likes sums on tweets amounts\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\nsns.set_style(\"whitegrid\")\nfig.suptitle(\"The dependence of likes sums on tweets amounts\", size = 15)\n\nsns.scatterplot(x = trump_agg['count'], y = trump_agg['likes'],\n                color = 'red', ax = ax1)\nax1.get_yaxis().get_major_formatter().set_scientific(False)\nax1.set_xlabel('Amount of tweets')\nax1.set_ylabel('Sum of likes')\nax1.set_title('Trump', size = 13)\n\n\nsns.scatterplot(x = biden_agg['count'], y = biden_agg['likes'],\n                color = 'blue', ax = ax2)\nax2.get_yaxis().get_major_formatter().set_scientific(False)\nax2.set_xlabel('Amount of tweets')\nax2.set_ylabel('Sum of likes')\nax2.set_title('Biden', size = 13)\n\nfig.show()","06ce137a":"print('Average number of likes per tweet (Trump): {}'.\n      format(round(trump_agg['likes'].sum() \/ trump_agg['count'].sum(), 0)))\nprint('Average number of likes per tweet (Biden): {}'.\n      format(round(biden_agg['likes'].sum() \/ biden_agg['count'].sum(), 0)))","7b7151ef":"# User followers count\ntrump_user_followers = trump[['user_name', \n                              'user_followers_count']].groupby('user_name').max()\nbiden_user_followers = biden[['user_name', \n                              'user_followers_count']].groupby('user_name').max()\n\ntrump_top_authors_by_count = pd.merge(trump_agg[:10], trump_user_followers, \n                                      on = 'user_name', how = 'left')\nbiden_top_authors_by_count = pd.merge(biden_agg[:10], biden_user_followers, \n                                      on = 'user_name', how = 'left')\n\n# Top users by tweets amount\nfig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 8))\nsns.set_style(\"whitegrid\")\nfig.suptitle(\"Top users by tweets amount\", size = 15)\n\nsns.barplot(x = trump_agg['count'][:10], y = trump_agg['user_name'][:10],\n            color = 'red', edgecolor = 'black', alpha = 0.8, ax = ax1)\nax1.get_xaxis().get_major_formatter().set_scientific(False)\nax1.set_xlabel('')\nax1.set_ylabel('User name')\nax1.set_title('Trump', size = 13)\n\n\nsns.barplot(x = biden_agg['count'][:10], y = biden_agg['user_name'][:10],\n            color = 'blue', edgecolor = 'black', alpha = 0.8, ax = ax3)\nax3.get_xaxis().get_major_formatter().set_scientific(False)\nax3.set_xlabel('')\nax3.set_ylabel('User name')\nax3.set_title('Biden', size = 13)\n\n\nsns.barplot(x = trump_top_authors_by_count['user_followers_count'], \n            y = trump_top_authors_by_count['user_name'],\n            color = 'red', edgecolor = 'black', alpha = 0.8, ax = ax2)\nax2.get_xaxis().get_major_formatter().set_scientific(False)\nax2.get_yaxis().set_visible(False)\nax2.set_xlabel('')\nax2.set_title('User followers count', size = 13)\n\n\nsns.barplot(x = biden_top_authors_by_count['user_followers_count'], \n            y = biden_top_authors_by_count['user_name'],\n            color = 'blue', edgecolor = 'black', alpha = 0.8, ax = ax4)\nax4.get_xaxis().get_major_formatter().set_scientific(False)\nax4.get_yaxis().set_visible(False)\nax4.set_xlabel('')\nax4.set_title('User followers count', size = 13)\n\nfig.show()","c287b5a9":"# User followers count\ntrump_top_authors_by_likes = pd.merge(trump_agg.sort_values('likes', ascending = False)[:10], \n                                      trump_user_followers, on = 'user_name', how = 'left')\nbiden_top_authors_by_likes = pd.merge(biden_agg.sort_values('likes', ascending = False)[:10], \n                                      biden_user_followers, on = 'user_name', how = 'left')\n\n# Top users by likes\nfig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 8))\nsns.set_style(\"whitegrid\")\nfig.suptitle('Top users by likes', size = 15)\n\nsns.barplot(x = trump_top_authors_by_likes['likes'], \n            y = trump_top_authors_by_likes['user_name'],\n            color = 'red', edgecolor = 'black', alpha = 0.8, ax = ax1)\nax1.get_xaxis().get_major_formatter().set_scientific(False)\nax1.set_xlabel('')\nax1.set_ylabel('User name')\nax1.set_title('Trump', size = 13)\n\n\nsns.barplot(x = biden_top_authors_by_likes['likes'], \n            y = biden_top_authors_by_likes['user_name'],\n            color = 'blue', edgecolor = 'black', alpha = 0.8, ax = ax3)\nax3.get_xaxis().get_major_formatter().set_scientific(False)\nax3.set_xlabel('')\nax3.set_ylabel('User name')\nax3.set_title('Biden', size = 13)\n\n\nsns.barplot(x = trump_top_authors_by_likes['user_followers_count'], \n            y = trump_top_authors_by_likes['user_name'],\n            color = 'red', edgecolor = 'black', alpha = 0.8, ax = ax2)\nax2.xaxis.set_major_formatter(FuncFormatter(millions))\nax2.get_yaxis().set_visible(False)\nax2.set_xlabel('')\nax2.set_title('User followers count', size = 13)\n\n\nsns.barplot(x = biden_top_authors_by_likes['user_followers_count'], \n            y = biden_top_authors_by_likes['user_name'],\n            color = 'blue', edgecolor = 'black', alpha = 0.8, ax = ax4)\nax4.xaxis.set_major_formatter(FuncFormatter(millions))\nax4.get_yaxis().set_visible(False)\nax4.set_xlabel('')\nax4.set_title('User followers count', size = 13)\n\nfig.show()","abaf4abb":"trump['tweet'][19529]","e974db25":"biden['tweet'][11650]","4e4a8c53":"# Tweet cleaner\ndef tweet_cleaner(text):\n    text = text.lower()\n    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n    text = re.sub('\\[.*?\\]', ' ', text)\n    text = re.sub('https?:\/\/\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', ' ', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text","48678431":"trump_cleaned = trump.copy()\nbiden_cleaned = biden.copy()\n\ntrump_cleaned['tweet'] = trump_cleaned['tweet'].apply(lambda x: tweet_cleaner(x))\nbiden_cleaned['tweet'] = biden_cleaned['tweet'].apply(lambda x: tweet_cleaner(x))","e0056f2e":"trump_cleaned['tweet'][19529]","97fa9181":"biden_cleaned['tweet'][11650]","9dfeff79":"trump_tweet_length = trump_cleaned.tweet.str.len()\nbiden_tweet_length = biden_cleaned.tweet.str.len()\n\nsns.set_style(\"whitegrid\")\nplt.figure(figsize=(14, 5))\n\nsns.distplot(trump_tweet_length, label = 'Trump', color = 'red', kde = False)\nsns.distplot(biden_tweet_length, label = 'Biden', color = 'blue', kde = False)\nplt.legend(prop={'size': 14})\nplt.title('Tweet length', size = 15)\nplt.xlabel('Length of tweet (symbols)')\nplt.show()","fe030243":"trump_words = trump_cleaned.tweet.str.split().map(lambda x: len(x))\nbiden_words = biden_cleaned.tweet.str.split().map(lambda x: len(x))\n\nsns.set_style(\"whitegrid\")\nplt.figure(figsize=(14, 5))\n\nsns.distplot(trump_words, label = 'Trump', color = 'red', kde = False)\nsns.distplot(biden_words, label = 'Biden', color = 'blue', kde = False)\nplt.legend(prop={'size': 14})\nplt.title('The number of words in tweet', size = 15)\nplt.xlabel('Words')\nplt.show()","1f9a5bff":"trump_word_len = trump_cleaned.tweet.str.split().apply(lambda x: [len(i) for i in x]).map(lambda x: np.mean(x))\nbiden_word_len = biden_cleaned.tweet.str.split().apply(lambda x: [len(i) for i in x]).map(lambda x: np.mean(x))\n\nsns.set_style(\"whitegrid\")\nplt.figure(figsize=(14, 5))\n\nsns.distplot(trump_word_len, label = 'Trump', color = 'red', kde = False)\nsns.distplot(biden_word_len, label = 'Biden', color = 'blue', kde = False)\nplt.legend(prop={'size': 14})\nplt.title('The average word length', size = 15)\nplt.xlabel('Length of word')\nplt.show()","fae3105d":"# Tweets with NaN length\ntrump_NaN_len = trump_word_len[trump_word_len.isnull()].index\nbiden_NaN_len = biden_word_len[biden_word_len.isnull()].index\n\n# removing tweets with NaN length\ntrump_cleaned = trump_cleaned.drop(trump_NaN_len, axis = 0)\nbiden_cleaned = biden_cleaned.drop(biden_NaN_len, axis = 0)","a502199d":"# creating word lists\ntrump_corpus = []\nwords = trump_cleaned['tweet'].str.split().values.tolist()\ntrump_corpus = [word for i in words for word in i]\n\nbiden_corpus = []\nwords = biden_cleaned['tweet'].str.split().values.tolist()\nbiden_corpus = [word for i in words for word in i]","3af95af5":"# word frequency\ntrump_counter = Counter(trump_corpus)\ntrump_most = trump_counter.most_common()\n\nbiden_counter = Counter(biden_corpus)\nbiden_most = biden_counter.most_common()","1dd398e7":"# The list of languages\nstopwords.fileids()","df40b05f":"# Stopwords; we use English and Spanish as the most frequent in our data \nstop = set(np.concatenate((stopwords.words('english'), stopwords.words('spanish'))))\n\ntrump_x, trump_y = [], []\nfor word, count in trump_most[:100]:\n    if word not in stop:\n        trump_x.append(word)\n        trump_y.append(count)\n        \nbiden_x, biden_y = [], []\nfor word, count in biden_most[:100]:\n    if word not in stop:\n        biden_x.append(word)\n        biden_y.append(count)","da35577d":"# TOP-20 words for both candidates\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\nsns.set_style(\"whitegrid\")\nplt.suptitle('TOP-20 words', size = 15)\n\nsns.barplot(x = trump_y[:20], y = trump_x[:20], edgecolor = 'black', color = 'red', ax = ax1)\nax1.set_title('Trump', size = 13)\nax1.get_xaxis().get_major_formatter().set_scientific(False)\n\nsns.barplot(x = biden_y[:20], y = biden_x[:20], edgecolor = 'black', color = 'blue', ax = ax2)\nax2.set_title('Biden', size = 13)\nax2.get_xaxis().get_major_formatter().set_scientific(False)\n\nfig.show()","7d4f3590":"# ngrams of words\ndef get_top_ngram(corpus, n = None):\n    vec = CountVectorizer(stop_words = stop, ngram_range = (n, n)).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0)\n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\n    return words_freq","84c5d64b":"# Data for bigrams\ntop_trump_n_bigrams = get_top_ngram(trump_cleaned['tweet'], 2)[:10]\ntrump_x, trump_y = map(list, zip(*top_trump_n_bigrams))\n\ntop_biden_n_bigrams = get_top_ngram(biden_cleaned['tweet'], 2)[:10]\nbiden_x, biden_y = map(list, zip(*top_biden_n_bigrams))","7c39d96e":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8))\nsns.set_style(\"whitegrid\")\nplt.suptitle('TOP Bigrams', size = 15)\n\nsns.barplot(x = trump_y, y = trump_x, edgecolor = 'black', color = 'red', ax = ax1)\nax1.set_title('Trump', size = 13)\nax1.get_xaxis().get_major_formatter().set_scientific(False)\n\nsns.barplot(x = biden_y, y = biden_x, edgecolor = 'black', color = 'blue', ax = ax2)\nax2.set_title('Biden', size = 13)\nax2.get_xaxis().get_major_formatter().set_scientific(False)\n\nfig.show()","aa6156d8":"# Data for trigrams\ntop_trump_n_bigrams = get_top_ngram(trump_cleaned['tweet'], 3)[:10]\ntrump_x, trump_y = map(list, zip(*top_trump_n_bigrams))\n\ntop_biden_n_bigrams = get_top_ngram(biden_cleaned['tweet'], 3)[:10]\nbiden_x, biden_y = map(list, zip(*top_biden_n_bigrams))","f9a48812":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8))\nsns.set_style(\"whitegrid\")\nplt.suptitle('TOP Trigrams', size = 15)\n\nsns.barplot(x = trump_y, y = trump_x, edgecolor = 'black', color = 'red', ax = ax1)\nax1.set_title('Trump', size = 13)\nax1.get_xaxis().get_major_formatter().set_scientific(False)\n\nsns.barplot(x = biden_y, y = biden_x, edgecolor = 'black', color = 'blue', ax = ax2)\nax2.set_title('Biden', size = 13)\nax2.get_xaxis().get_major_formatter().set_scientific(False)\n\nfig.show()","9903a906":"def show_wordcloud(data, title = None, color = 'white'):\n    wordcloud = WordCloud(background_color=color,\n                         stopwords=stop,\n                         max_words=10000,\n                         scale=3,\n                         width = 4000, \n                         height = 2000,\n                         collocations=False,\n                         random_state=1)\n    \n    wordcloud = wordcloud.generate(str(data))\n    \n    plt.figure(1, figsize=(16, 8))\n    plt.title(title, size = 15)\n    plt.axis('off')\n    plt.imshow(wordcloud)\n    plt.show()","f2484a4c":"show_wordcloud(trump_cleaned['tweet'].dropna(), title = 'Trump wordcloud', color = 'black')","1cf20143":"show_wordcloud(biden_cleaned['tweet'].dropna(), title = 'Biden wordcloud', color = 'black')","25c2a72a":"# Text polarity function\ndef polarity(data):\n    return TextBlob(data).sentiment.polarity\n\ntrump_cleaned['polarity'] = trump_cleaned['tweet'].apply(lambda x: polarity(x))\nbiden_cleaned['polarity'] = biden_cleaned['tweet'].apply(lambda x: polarity(x))","e608dd76":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\nsns.set_style(\"whitegrid\")\nplt.suptitle('Polarity (TextBlob)', size = 15)\nplt.text(x=-2.3, y=20.3, s='(from -1 (extremely negative) to 1 (extremely positive))', fontsize=10, alpha=0.8)\n\n\nsns.kdeplot(trump_cleaned['polarity'], color = 'red', ax = ax1, legend = False)\nax1.set_title('Trump', size = 13)\n\nsns.kdeplot(biden_cleaned['polarity'], color = 'blue', ax = ax2, legend = False)\nax2.set_title('Biden', size = 13)\n\nfig.show()","fdf245bc":"# Trump negative tweets\ntrump_cleaned[trump_cleaned['polarity'] == -1]['tweet'][:5]","715d564b":"# Trump positive tweets\ntrump_cleaned[trump_cleaned['polarity'] == 1]['tweet'][:5]","acdbdf2f":"# Biden negative tweets\nbiden_cleaned[biden_cleaned['polarity'] == -1]['tweet'][:5]","1fbc3eb0":"# Biden positive tweets\nbiden_cleaned[biden_cleaned['polarity'] == 1]['tweet'][:5]","0d6ba240":"# VADER Analyzer\nsid = SentimentIntensityAnalyzer()\n\n# Text polarity function\ndef get_vader_score(data):\n    return sid.polarity_scores(data)['compound']\n\ntrump_cleaned['VADER'] = trump_cleaned['tweet'].apply(lambda x: get_vader_score(x))\nbiden_cleaned['VADER'] = biden_cleaned['tweet'].apply(lambda x: get_vader_score(x))","4fe3a71c":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\nsns.set_style(\"whitegrid\")\nplt.suptitle('Polarity (VADER)', size = 15)\nplt.text(x=-2.4, y=9.3, s='(from -1 (extremely negative) to 1 (extremely positive))', fontsize=10, alpha=0.8)\n\n\nsns.kdeplot(trump_cleaned['VADER'], color = 'red', ax = ax1, legend = False)\nax1.set_title('Trump', size = 13)\n\nsns.kdeplot(biden_cleaned['VADER'], color = 'blue', ax = ax2, legend = False)\nax2.set_title('Biden', size = 13)\n\nfig.show()","a44dc6b3":"print(trump_cleaned['tweet'].loc[945451])\nprint('*'*20)\nprint(trump_cleaned[['polarity', 'VADER']].loc[945451])","9553e3d5":"print(biden_cleaned['tweet'].loc[296157])\nprint('*'*20)\nprint(biden_cleaned[['polarity', 'VADER']].loc[296157])","692c998f":"# create 'date' feature\ntrump_cleaned['date'] = pd.to_datetime(trump_cleaned['created_at']).dt.date\nbiden_cleaned['date'] = pd.to_datetime(biden_cleaned['created_at']).dt.date","bcf83820":"def create_line_plot(data1, data2, FUN, ax, title):\n    sns.lineplot(data = data1.groupby('date')[FUN].mean(), \n                 label = 'Trump', color = 'red', linewidth = 3, ax = ax)\n    sns.lineplot(data = data2.groupby('date')[FUN].mean(), \n                 label = 'Biden', color = 'blue', linewidth = 3, ax = ax)\n    ax.xaxis.set_major_locator(mdates.DayLocator(interval=2))\n    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d %b'))\n    ax.set_title(title, size = 13)\n    ax.legend(prop={'size': 14})\n    ax.set_ylabel('Polarity')","5815ea8c":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8))\nsns.set_style(\"whitegrid\")\nplt.suptitle('Sentiment polarity changing', size = 15)\n\ncreate_line_plot(trump_cleaned, biden_cleaned, 'polarity', ax1, '(TextBlob)')\ncreate_line_plot(trump_cleaned, biden_cleaned, 'VADER', ax2, '(VADER)')\n\nfig.show()","caf41b7d":"# Working datasets\n# Trump\ntb_pos_tr = trump_cleaned[trump_cleaned['polarity'] > 0]\ntb_neg_tr = trump_cleaned[trump_cleaned['polarity'] < 0]\nvader_pos_tr = trump_cleaned[trump_cleaned['VADER'] > 0]\nvader_neg_tr = trump_cleaned[trump_cleaned['VADER'] < 0]\n\n# Biden\ntb_pos_bi = biden_cleaned[biden_cleaned['polarity'] > 0]\ntb_neg_bi = biden_cleaned[biden_cleaned['polarity'] < 0]\nvader_pos_bi = biden_cleaned[biden_cleaned['VADER'] > 0]\nvader_neg_bi = biden_cleaned[biden_cleaned['VADER'] < 0]","d48372d2":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8))\nsns.set_style(\"whitegrid\")\nplt.suptitle('Positive polarity changing', size = 15)\n\ncreate_line_plot(tb_pos_tr, tb_pos_bi, 'polarity', ax1, '(TextBlob)')\ncreate_line_plot(vader_pos_tr, vader_pos_bi, 'VADER', ax2, '(VADER)')\n\nfig.show()","89c1ab25":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8))\nsns.set_style(\"whitegrid\")\nplt.suptitle('Negative polarity changing', size = 15)\n\ncreate_line_plot(tb_neg_tr, tb_neg_bi, 'polarity', ax1, '(TextBlob)')\ncreate_line_plot(vader_neg_tr, vader_neg_bi, 'VADER', ax2, '(VADER)')\n\nfig.show()","60dfd299":"trump_users_pol = trump_cleaned.groupby('user_name')['polarity', 'VADER'] \\\n    .mean().sort_values('polarity', ascending = False)\n\nbiden_users_pol = biden_cleaned.groupby('user_name')['polarity', 'VADER'] \\\n    .mean().sort_values('polarity', ascending = False)","c13321ec":"# Datasets\ntrump_top_authors_by_count = pd.merge(trump_top_authors_by_count, \n                                      trump_users_pol, on = 'user_name', \n                                      how = 'left').sort_values('VADER', ascending = True)\n\nbiden_top_authors_by_count = pd.merge(biden_top_authors_by_count, \n                                      biden_users_pol, on = 'user_name', \n                                      how = 'left').sort_values('VADER', ascending = True)\n\ntrump_top_authors_by_likes = pd.merge(trump_top_authors_by_likes, \n                                      trump_users_pol, on = 'user_name', \n                                      how = 'left').sort_values('VADER', ascending = True)\n\nbiden_top_authors_by_likes = pd.merge(biden_top_authors_by_likes, \n                                      biden_users_pol, on = 'user_name', \n                                      how = 'left').sort_values('VADER', ascending = True)","7b3353a2":"def create_lollipop_plot(data, ax, first_color, second_color, title):\n    ax.hlines(y = data['user_name'], xmin = data['polarity'], \n               xmax = data['VADER'], color = first_color, alpha = 0.5)\n    ax.scatter(data['polarity'], data['user_name'], color = first_color, \n                alpha = 1, edgecolors = 'black', label = 'TextBlob')\n    ax.scatter(data['VADER'], data['user_name'], color = second_color, \n                alpha = 1, edgecolors = 'black', label = 'VADER')\n    ax.legend()\n    ax.set_xlim(-1, 1)\n    ax.axvline(x = 0, linestyle = '--', color = 'black', linewidth = 0.7)\n    ax.set_title(title)","32991a45":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 8))\nsns.set_style(\"whitegrid\")\nfig.suptitle('Trump users sentiment polarity', size = 15)\n\ncreate_lollipop_plot(trump_top_authors_by_count, ax1, 'red', 'orange',\n                     'TOP users by tweets count')\n\ncreate_lollipop_plot(trump_top_authors_by_likes, ax2, 'red', 'orange',\n                     'TOP users by likes')\n\nfig.show()","f1e4dcf8":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 8))\nsns.set_style(\"whitegrid\")\nfig.suptitle('Biden users sentiment polarity', size = 15)\n\ncreate_lollipop_plot(biden_top_authors_by_count, ax1, 'blue', 'green',\n                     'TOP users by tweets count')\n\ncreate_lollipop_plot(biden_top_authors_by_likes, ax2, 'blue', 'green',\n                     'TOP users by likes')\n\nfig.show()","49b1f566":"# Datasets\ntr_top_countries = trump_cleaned[trump_cleaned.country.isin(trump_tweets_countries.index)]\nbi_top_countries = biden_cleaned[biden_cleaned.country.isin(biden_tweets_countries.index)]\n\ntrump_countries_pol = tr_top_countries.groupby('country')['polarity', 'VADER'] \\\n    .mean().sort_values('polarity', ascending = True)\n\nbiden_countries_pol = bi_top_countries.groupby('country')['polarity', 'VADER'] \\\n    .mean().sort_values('polarity', ascending = True)","d4b12b9a":"def create_lollipop_plot_2(data, ax, first_color, second_color, title):\n    ax.hlines(y = data.index, xmin = data['polarity'], \n               xmax = data['VADER'], color = first_color, alpha = 0.5)\n    ax.scatter(data['polarity'], data.index, color = first_color, \n                alpha = 1, edgecolors = 'black', label = 'TextBlob')\n    ax.scatter(data['VADER'], data.index, color = second_color, \n                alpha = 1, edgecolors = 'black', label = 'VADER')\n    ax.legend()\n    ax.set_xlim(-1, 1)\n    ax.axvline(x = 0, linestyle = '--', color = 'black', linewidth = 0.7)\n    ax.set_title(title)","455194d4":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 8))\nsns.set_style(\"whitegrid\")\nfig.suptitle('Sentiment polarity by country', size = 15)\n\ncreate_lollipop_plot_2(trump_countries_pol, ax1, 'red', 'orange',\n                     'Trump')\n\ncreate_lollipop_plot_2(biden_countries_pol, ax2, 'blue', 'green',\n                     'Biden')\n\nfig.show()","7b137619":"Note that these features aren't useful for deep analysis because over 50% of the data is NaN and give only a small insight into the distribution of tweets by countries. More useful and interesting can be the 'user_name' feature as a list of candidates' upholders (or haters).","36326766":"As intended, tweets have various kinds of noise, like emojis, special symbols, newline tabulators, links, etc. Also, not all tweets wrote in English (like the tweet above).","4629a0cf":"### A first look at the data","45bbc71b":"The chart above shows that throughout the study period Donald Trump was a more popular target for tweets, but after November 6 this situation changed. It's related to election results and Joe Biden's victory. Two peaks in activity look logical: October 23 - the day after debate day, and November 4 - the day after Election Day.","3f0d25ae":"It's time for sentiment classification of users.","6b4546ac":"The chart above shows that almost all words have a range of lengths from 0 to 20. But there are some words with zero-length (NaN values), and, on the contrary, far longer than 20 letters (80, 100, and even more!). We'll remove only NaN-type outliers because long words are unique and don't have a powerful effect on data.","65b8ff4a":"![Trump vs Biden](https:\/\/therealdeal.com\/wp-content\/uploads\/2020\/09\/1200-Will-real-estate-take-the-stage-in-the-first-presidential-debate_-705x439.jpg)\n# **Introduction**\nHi! \nHere I'll try to find interesting sides of the past USA election in tweets dedicated to two major candidates: Donald Trump and Joe Biden. \nI hope, it'll be an interesting journey. If you'll find it useful, please, **upvote** and **leave a comment**. \nWork is still in progress, so I'll be improving and expanding my analysis. Maybe I'll find some new interesting tasks. \n\nNow, let's start!\n\n### **Notebook changes:**\n**Version 5:** fixed errors in names of some figures; added comments to some parts of the code.","6b64b5e5":"Users who posted the most tweets have a small amount of followers.","ac684333":"Not perfect (because the data still dirty, and the TextBlob method not 100% effective), but it works well enough. Let's try VADER method that works better with negative sentiment.","55704db6":"We see that geographical information (city, state, country, etc.) is mostly unknown, so this data can't be used for analysis. We'll look only at the country feature for a small insight into the distribution of users by countries, and will visualize the geodata (lat and long).","b26671a6":"At first, we have to clean the data up. We'll use a great package [re](https:\/\/docs.python.org\/3\/library\/re.html) for this. Let's look at the random tweets.","2a6b33be":"And also we should look at the sentiment polarity of TOP-countries.","1ea740a4":"### Wordclouds","5a15d7fb":"# **EDA**\n\"US Election 2020 Tweets\" dataset is an NLP task, so the EDA algorithm includes visualizations of interesting and important numeric features (like the amount of NaN values or number of tweets per day), and detailed analysis of tweets text (length, stopwords, sentiment analysis, etc.). Tweets have a very messy structure (with emojis, hashtags, and so on), so we have to clean it up first.","bf9c51de":"### Top-10 bigrams","acfd1750":"There are more tweets dedicated to Donald Trump than Joe Biden, but most of them have less than 6k likes. The most popular tweet has around 74k likes. The most popular tweets dedicated to Joe Biden have 100k+ likes. Let's look at them.","10b455e8":"Almost the same. ","723bba49":"Let's take a look at some extremely positive and extremely negative tweets of both candidates.","b079f0c4":"Wow, VADER really looks better at recognizing negative sentiment.","3f2ef805":"So, we've taken a quick look at the sentiment of tweets. There are a lot of analysis variants. It looks great to study the polarity of tweets by cities, or states, for instance, but these features have a lot of NaN values, and therefore don't cover the actual situation. You free to implement your own ideas (maybe I'll expand my own analysis late, this notebook is still in work). I hope you found this notebook useful. See you!","1c09f929":"Yes, with VADER the percentage of neutral polarities (close to zero) decreased in the negative direction.","96a2c54d":"# **Sentiment analysis**\nWe'll use two tools: TextBlob package, and VADER from NLTK package.","0aa8a6aa":"On the contrary, users whose tweets got many likes have far more followers, that looks logical. We will be able to classify these users into upholders or haters after sentiment analysis.","d7f04739":"There are inconsistent country names in the data: \"United States of America\" and \"United States\", which are the same. Let's clean it up.","9f646339":"There is a strong positive correlation between likes and retweets that looks logical.","ca5e814e":"Now, it's time for **sentiment analysis**.","450853a1":"Among the most frequent words in tweets dedicated to Donald Trump (excluding candidates' proper nouns) occur both popular election words: \"vote\", \"election\", \"president\", \"people\", \"Election Day\", etc., and specific, like \"MAGA\" (Trump's tagline \"Make America Great Again\") or \"die\" (a word with negative sense). Specific words of tweets dedicated to Joe Biden: \"Kamala Harris\" (Vice President-elect of the United States), \"BidenHarris\", \"win\" (a word that is more frequent regarding Joe Biden than Donald Trump). Let's look at Bi and Tri n-grams of words.","8d22d232":"Take a look at the length of tweets.","bbb77b30":"### Top-10 trigrams","437cb53f":"It looks like tweets dedicated to Joe Biden were more positive throughout the studied period. But these are average values. We should look at the changes in the polarity of positive and negative tweets separately.","12bfa77e":"We see that on average, the distributions of tweet length for both candidates are the same.","a0b116dc":"Tweets dedicated to Joe Biden liked more often."}}