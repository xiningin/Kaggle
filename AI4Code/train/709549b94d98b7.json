{"cell_type":{"c1991eb3":"code","19efc444":"code","a9bb2075":"code","50aa9e8a":"code","684c2759":"code","e576d922":"code","58c3c267":"code","5c336630":"code","3761f5d8":"code","53ce37f6":"code","4c435af9":"code","5395a5ba":"code","0d6616ef":"code","0653934b":"code","9e270457":"code","c0b4a39c":"code","db87e520":"code","5df02296":"code","6bef6652":"code","44fb5803":"code","d000ca75":"code","4a582299":"code","4996254b":"code","f3068aed":"code","676b2ef6":"code","479d695f":"code","3b574b3a":"code","31c25bf0":"code","2242bcd7":"code","064e39a0":"code","98caa862":"code","f84eafa4":"code","e1fe1b61":"code","4937d1b5":"code","dba81ef6":"code","170b7919":"code","a2c8daa7":"code","83327536":"code","f963f050":"code","da354120":"code","c6569a99":"code","8810c559":"code","186d6c02":"code","6eba3452":"code","371c8bf2":"code","eb3d9b0e":"code","5157a345":"code","d665d3a2":"code","7bc08a8c":"code","44a4ddca":"code","ded3f4ba":"code","2de8ce55":"code","a202a823":"code","5656436d":"code","8984d984":"code","dc9b8f89":"code","3e138fd9":"code","1ca5ca0b":"code","75e63475":"markdown","b06e31cd":"markdown","ee484a34":"markdown","90e499c3":"markdown","7e366bc0":"markdown","44995bd6":"markdown","bc92b7fd":"markdown"},"source":{"c1991eb3":"# Nabil FATTOUCH \n# Date : 31\/08\/2021 \n# Data source: \"\/kaggle\/input\/salaries\/Salaries.csv\"","19efc444":"# Answer questions asked by  client who is a  human resources   and management control department\n# The client located in San Francisco, wants to know its data. \n# This department asks a set of questions to evaluate the salaries attributed to their employees which are the following:\n\n\n\n\n\n# variable target :  TotalPayBenefits\n\n# Analysis of the data form :\n\n# Rows and columns : (148654, 13)\n# Analysis of NaN \n # \u2022 Elimination of useless columns (Ratio Sum NaN\/ Total ( shape ! ) < 70 %\n # \u2022 Many NaN for columns \"Notes\"and \"Statuts\"(half of the variables > 70% of NaN)\n \n# In-depth analysis : \n # \u2022 Visualization of the target \n # \u2022 Average \n # \u2022 The highest salary in the company, the name of the person and the position held?\n # \u2022 Positions have the lowest salaries and for which people in the company ?\n # \u2022The number of job titles were represented by only one person in 2014\n # \u2022 Top 07 persons works the most overtime ? \n # \u2022 Relationship between the position held and the amount of overtime worked?\n # \u2022 Rbetween OvertimePay and TotalPayBenefits?\n# Exploratory of others  variables :\n # \u2022 The highest amount of OvertimePay in the dataset \n # \u2022 The number of people having the word captain in their job title\n # \u2022 Top-07 jobs in which there are majority of the people ( in %) ?\n # \u2022 The average ( mean) TotalPayBenefit of all employees per year ( 2011-2014)\n   \n ","a9bb2075":"## Import packages \n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","50aa9e8a":"pd.set_option('display.max_row', 111)              # If we want to display the result in full \npd.set_option('display.max_column', 111)  ","684c2759":"filename = \"\/kaggle\/input\/salaries\/Salaries.csv\"\ndf = pd.read_csv(filename)\n","e576d922":"df.head()","58c3c267":"df1= df.copy()\ndf1.head(7)","5c336630":"pd.show_versions()","3761f5d8":"                                      # number of columns and rows \n\ndf1.shape  ","53ce37f6":"df1.columns                            # Columns names ","4c435af9":"print(\"Number of rows in dataset: \",df1.shape[0])\nprint(\"Number of columns in dataset: \",df1.shape[1])","5395a5ba":"#df1.dtypes()\ndf1.dtypes.value_counts()              #  Data types ","0d6616ef":"df1.dtypes.value_counts().plot.pie()   # Data types visualization ","0653934b":"df1.isnull().sum(axis=0)                # Checking the NaN  in the dataset","9e270457":"df1.head()","c0b4a39c":"\n                                      # Visualization of NaN \n\nplt.figure(figsize=(20,10))           # To create a figure of dimensions 20, 10 \nsns.heatmap(df1.isna(), cbar=False)    # cbar = False to eliminate the colored bar\n                                     ","db87e520":"df.isna().sum()","5df02296":"(df1.isna().sum()\/df1.shape[0]).sort_values( ascending = True)","6bef6652":"# \u2022 Elimination of useless columns (Ratio Sum NaN\/ Total ( shape ! ) > 70 %\n # \u2022 Many NaN for columns \"Notes\"and \"Statuts\"(more than half of the variables > 70% of NaN)\n\n ## sns.heatmap(df1.isna() )                          ","44fb5803":"df2= df1[df1.columns[df1.isna().sum()\/df1.shape[0] < 0.7] ]\n    \n    # 1\/ df.isna().sum()\/df.shape[0] >0.7     2\/df.columns[df.isna().sum()\/df.shape[0] > 0.7]\n\n    # What we do here is boolean indexing, i.e. I take the table of columns df.columns[df.isna().sum()\/df.shape[0] < 0.7] \n    # and I inject it in our new dataframe df and we save ","d000ca75":"df2.head(7)","4a582299":"# elimination of rows\n# In the data frame above, it is visible that there are some rows in which no values is entered, \n# which is equal to NaN . So we need to delete these rows.\n\ndf2 = df2[df2['EmployeeName'] != 'Not provided']\ndf2 = df2[df2['JobTitle'] != 'Not provided']\ndf2.reset_index(inplace = True, drop = True)\ndf2","4996254b":"                                     # Unique values in dataset\n    \nprint('Number of unique values in Job-Title column are:',df['JobTitle'].nunique())\nprint('Number of unique values in Agency column are:',df['Agency'].nunique())\nprint('Number of unique values in Year column are:',df['Year'].nunique())","f3068aed":"print(\"Job-Title:\",df['JobTitle'].unique())\n\nprint(\"Agency:\",df['Agency'].unique())\nprint(\"Year:\",df['Year'].unique())","676b2ef6":"# Examination of the Target column : TotalPayBenefits                   ","479d695f":"df2['TotalPayBenefits'].value_counts()  # if you want to display the result in %. , value_counts(normalize=True)","3b574b3a":"df2['TotalPayBenefits'].value_counts(normalize=True) ","31c25bf0":"# meaning of variables (continuous!) ( Histogram of continuous variables )\n\nfor col in df2.select_dtypes('float'): print(col)  \n                                                 # We check what we have as columns \n                                                 # then we will create histograms,\n                                                 # we will observe the distribution, \n                                                 # the distribution of data for each of its columns. \n                                                 # For that, we can use Matplotlib or seaborn \n","2242bcd7":"for col in df2.select_dtypes('float'): \n                                                 # displot: a distribution curve and we will pass through it\n                                                 # each time the column (variable) of our df \n    plt.figure()\n    sns.displot(df[col])          \n                                                \n                                                 # and they appear to have a standard deviation = 1. \n                                                 # This immediately suggests that these data \n                                                 # have been standardized \n                                               \n                                                 #  A perfect positive relationship between the two variables.","064e39a0":"df2[['TotalPay', 'TotalPayBenefits']].corr()\n\n                                            ","98caa862":"\ndf2[['OvertimePay','TotalPayBenefits']].corr()","f84eafa4":"df2.info()","e1fe1b61":"# The highest salary in the company, the name of the Employee and the JobTitle?\n\ndf2[df2['TotalPayBenefits'] == df2['TotalPayBenefits'].max()]","4937d1b5":"df2[df2['TotalPayBenefits'] == df2['TotalPayBenefits'].max()]['EmployeeName']","dba81ef6":"df2[df2['TotalPayBenefits'] == df2['TotalPayBenefits'].max()]['TotalPayBenefits'] \n","170b7919":"df2['TotalPayBenefits'].value_counts().head(15)","a2c8daa7":"df2['Year']== 2014","83327536":"df2[df2['Year']== 2014]['JobTitle']","f963f050":"df2[df2['Year']== 2014]['JobTitle'].value_counts()","da354120":"(df2[df2['Year']== 2014]['JobTitle'].value_counts() ==1).sum()","c6569a99":"df2['TotalPayBenefits'].mean()\n","8810c559":"df2['EmployeeName']== 'PATRICK GARDNER'","186d6c02":"df2[df1['EmployeeName']=='GARY JIMENEZ']['JobTitle']","6eba3452":"df2[df2['EmployeeName']=='GARY JIMENEZ']['TotalPayBenefits']","371c8bf2":"## the average ( mean) TotalPayBenefits of all employees per year ( 2011-2014)","eb3d9b0e":"df2_by_year=df2.groupby('Year').mean()['TotalPayBenefits']\ndf2_by_year","5157a345":"ax = df2_by_year.plot(kind='bar', title =\"Average ( mean) TotalPayBenefits of all employees per year\", figsize=(16, 10), legend=True, fontsize=10)\nax.set_xlabel(\"TotalPayBenefits\", fontsize=12)\nax.set_ylabel(\"Year\", fontsize=12)\nplt.show()","d665d3a2":"df2['JobTitle'].value_counts()","7bc08a8c":"df3= df2['JobTitle'].value_counts().head(7)\ndf3\n","44a4ddca":"\nax = df3.plot(kind='bar', title =\"The top 07  most popular jobs\", figsize=(15, 10), legend=True, fontsize=12)\nax.set_xlabel(\"JobTitle\", fontsize=12)\nax.set_ylabel(\"Year\", fontsize=12)\nplt.show()","ded3f4ba":"df2['Year']== 2014","2de8ce55":"df2[df2['Year']== 2014]['JobTitle']","a202a823":"df2[df2['Year']== 2014]['JobTitle'].value_counts()","5656436d":"(df2[df2['Year']== 2014]['JobTitle'].value_counts() ==1).sum()","8984d984":"def captain(string):\n    if 'captain' in (string.lower()):\n        return True\n    else:\n        return False","dc9b8f89":" captain('CAPTAIN SERVICE') # test of function ","3e138fd9":"(df2['JobTitle'].apply(lambda x: captain(x)))","1ca5ca0b":"(df2['JobTitle'].apply(lambda x: captain(x))).sum()","75e63475":"## The number of people having the word captain in their job title ","b06e31cd":"## The top 07  most popular jobs","ee484a34":"# Visualization of the target","90e499c3":"## The number of job titles were represented by only one person in 2014","7e366bc0":"## The highest amount of OvertimePay in the dataset ","44995bd6":"# Analysis of the data form","bc92b7fd":"# Analysis of NaN : \n\n "}}