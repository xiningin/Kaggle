{"cell_type":{"3fb2b57d":"code","47953cfb":"code","0e6fd87f":"code","818e7554":"code","c76b4358":"code","61d06aa5":"code","bd4df571":"code","31966357":"code","3bda5c90":"code","faaa8638":"code","3825507b":"code","057bcfc0":"code","62eab90a":"code","cce761e8":"code","105f764e":"markdown","0316d98a":"markdown","9a471f19":"markdown","14066775":"markdown","3b364651":"markdown","9ebf570b":"markdown","fe1b902a":"markdown","4fd03924":"markdown"},"source":{"3fb2b57d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom time import time\n\nimport torch\nfrom torch import optim\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom sklearn.preprocessing import MinMaxScaler","47953cfb":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","0e6fd87f":"train = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\n\ntrain_set = np.array(train.drop(['label'], axis=1))\ntrain_label = np.array(train['label'])","818e7554":"trainset = []\nbatch_size = 64\nvalid_size = 0.2\n\nfor i in range(len(train_label)):    \n    trainset.append((torch.tensor(train_set[i]), torch.tensor(train_label[i])))\n\nvalid_num = int(len(trainset)*0.2)\ntrainloader = torch.utils.data.DataLoader(trainset[valid_num:], batch_size=64, shuffle=True)\nvalidloader = torch.utils.data.DataLoader(trainset[:valid_num], batch_size=64, shuffle=True)","c76b4358":"dataiter = iter(trainloader)\nimages, labels = dataiter.next()\nprint(images.shape)\nprint(labels.shape)","61d06aa5":"img = images[3].reshape(1,28,28)\nplt.imshow(img.numpy().squeeze(), cmap='gray_r')","bd4df571":"figure = plt.figure(figsize=(10,10))\nnum_of_images = 60\nfor i in range(0, num_of_images):\n    plt.subplot(6,10,i+1)\n    img = images[i].reshape(1,28,28)\n    plt.imshow(img.numpy().squeeze(), cmap='gray_r')","31966357":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.fc1 = nn.Linear(784, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 10)\n        self.dropout = nn.Dropout(0.2)\n        \n    def forward(self, input):\n        x = F.relu(self.fc1(input))\n        x = self.dropout(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout(x)\n        x = F.log_softmax(self.fc3(x), dim=1)\n        return x","3bda5c90":"model = Net()\n\ncriterion = nn.NLLLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n\nn_epochs = 30\ntime0 = time()\nscaler = MinMaxScaler((0,1))\n\n\nfor epoch in range(n_epochs):\n    train_loss = 0.0\n    valid_loss = 0.0\n    \n    for images, labels in trainloader:\n        optimizer.zero_grad() \n        images_scaling = scaler.fit_transform(images.view(-1,len(images)))\n        output = model(torch.tensor(images_scaling).view(len(images),-1).float())\n        loss = criterion(output, labels)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()*images.size(0)\n        \n    for images, labels in validloader:\n        images_scaling = scaler.fit_transform(images.view(-1, len(images)))\n        output = model(torch.tensor(images_scaling).view(len(images), -1).float())\n        loss = criterion(output, labels)\n        valid_loss += loss.item()*images.size(0)\n    \n    train_loss = train_loss\/len(trainset[valid_num:])\n    valid_loss = valid_loss\/len(trainset[:valid_num])\n    print('Epoch: {} \\tTraining loss: {:.6f} \\tValidation loss: {:.6f}'.format(\n        epoch+1,\n        train_loss,\n        valid_loss\n    ))\n    \n#     if valid_loss <= valid_loss_min\nprint(\"\\nTraining Time (in minutes) =\",(time()-time0)\/60)","faaa8638":"images, labels = next(iter(validloader))\n\nimg = images[1]\nimages_scaling = scaler.fit_transform(img.reshape(-1,1)).reshape(1,-1)\n\nwith torch.no_grad():\n    logps = model(torch.from_numpy(images_scaling).float())\n\nps = torch.exp(logps)\nprobab = list(ps.numpy()[0])\n\nprint(\"Predicted Digit =\", probab.index(max(probab)))\nprint(\"Label Digit =\", labels[1])\n\nimg = img.reshape(1,28,28)\nplt.imshow(img.numpy().squeeze(), cmap='gray_r')","3825507b":"correct_count, all_count = 0, 0\nfor images,labels in validloader:\n    for i in range(len(labels)):\n        img = images[i]\n        images_scaling = scaler.fit_transform(img.reshape(-1,1)).reshape(1,-1) \n        with torch.no_grad():\n            logps = model(torch.from_numpy(images_scaling).float())\n\n        ps = torch.exp(logps)\n        probab = list(ps.numpy()[0])\n        pred_label = probab.index(max(probab))\n        true_label = labels.numpy()[i]\n        if(true_label == pred_label):\n          correct_count += 1\n        all_count += 1\n\nprint(\"Number Of Images Tested =\", all_count)\nprint(\"\\nModel Accuracy =\", (correct_count\/all_count))","057bcfc0":"test_set = np.array(test)\ntestloader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False)\n","62eab90a":"pred_test = []\npred_id = []\nimageid = 1\nfor images in testloader:\n    for i in range(len(images)):\n        img = images[i]\n        images_scaling = scaler.fit_transform(img.reshape(-1,1)).reshape(1,-1) \n        with torch.no_grad():\n            logps = model(torch.from_numpy(images_scaling).float())\n\n        ps = torch.exp(logps)\n        probab = list(ps.numpy()[0])\n        pred_label = probab.index(max(probab))\n        pred_test.append(pred_label)\n        pred_id.append(imageid)\n        imageid += 1","cce761e8":"my_prediction = pd.DataFrame({'ImageId' : pred_id, 'Label' : pred_test})\nmy_prediction.to_csv('my_prediction.csv', index=False)","105f764e":"# 1. Import Libraries","0316d98a":"# 4. Train Model","9a471f19":"# 5. Test and Evaluation","14066775":"# 2. Load Data","3b364651":"# 3. Preprocess Data","9ebf570b":"# Pytorch Handwritten Digit Prediction","fe1b902a":"# 6. Predict Test Data","4fd03924":"# 3. Build Model"}}