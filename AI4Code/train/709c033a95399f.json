{"cell_type":{"e1a3feaa":"code","49414c0f":"code","86921aa7":"code","ecad1b1d":"code","b84d1453":"code","1f160925":"code","959ba179":"code","254ce22b":"code","d6f75c75":"code","af97d616":"code","4ec76582":"code","32d573e6":"code","dd1103ac":"code","2c2d2bbf":"code","10979d12":"code","8be8a88a":"code","ca788c9b":"code","d8c86ef5":"code","c3d6d027":"code","b2f0a31c":"code","40003e4f":"code","fbf495c8":"code","f3bb0dc4":"code","e38f0f83":"code","fa417ccd":"code","c559b144":"code","2751aaf4":"code","8c9df555":"code","00113097":"code","2eaa4a34":"code","bee7d00d":"code","b5a08de8":"code","60cc50bf":"code","ce59c1dc":"code","9d7bea39":"code","02e165c9":"code","f3bbd4cb":"code","81fa5d3d":"code","efedc21b":"code","506734d1":"code","7dab5d31":"code","3270d78f":"code","f21d3aca":"code","4525342e":"code","9b8b9276":"code","9608d9c3":"code","3db8f108":"code","ee4d4cc1":"code","3adbc447":"code","42b05431":"code","5a2b217e":"code","a7924c7e":"code","a358db9d":"code","fa74edf2":"code","1b75b62f":"code","38fd54ca":"code","4e64fc21":"code","1bce1814":"code","3a5bb03c":"code","ae819bc2":"code","cbd650ff":"code","cbfebe25":"code","15cdb87f":"code","9e6d67ca":"code","ac5bcf2f":"code","733a66d4":"code","1df2bcc4":"code","2e350f36":"code","aaeb66b5":"code","c371d8c2":"code","0ae9736e":"code","98e0d1ee":"code","fb4dffbe":"code","d464c2b5":"code","4195bf8b":"code","7154b502":"code","8756476d":"code","00f0f268":"code","0cdafe2c":"code","40325d9d":"markdown","5a354377":"markdown","cb06848f":"markdown","08d0c87d":"markdown","0141098b":"markdown","1503a503":"markdown","9039bb36":"markdown","0d94402c":"markdown","4d5be41a":"markdown","13f37dde":"markdown","ff81c247":"markdown","2295c44e":"markdown","2ca604a9":"markdown","a3c5c063":"markdown","29d70553":"markdown","ac4e8f6c":"markdown","92f96cd1":"markdown","8b6e7166":"markdown","ad439fe5":"markdown","837b5620":"markdown","22c811cf":"markdown","8539b3d7":"markdown","96c32bae":"markdown","dbb8e1a7":"markdown","619a8f89":"markdown","23ee2527":"markdown","df33c740":"markdown","f6e6c673":"markdown","8f5db4f3":"markdown","625eb651":"markdown","141cf3bd":"markdown","c7cf7b6e":"markdown","2498bb9a":"markdown","1e2516cd":"markdown","52fb94eb":"markdown","0a84b110":"markdown","1ca065bd":"markdown","bf27bdae":"markdown","f74f590d":"markdown","580de9b7":"markdown","23f0c993":"markdown","7f69ef57":"markdown"},"source":{"e1a3feaa":"import warnings\nwarnings.simplefilter(action='ignore')\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.linear_model import LinearRegression, Ridge, RidgeCV, ElasticNet, Lasso, LassoCV\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import RobustScaler\n\nHitters=pd.read_csv(\"..\/input\/hitters-baseball-data\/Hitters.csv\")","49414c0f":"df=Hitters.copy()\ndf.info()","86921aa7":"df.describe().T","ecad1b1d":"df[df.isnull().any(axis=1)].head(3)","b84d1453":"df.isnull().sum().sum()","1f160925":"correlation_matrix = df.corr().round(2)\nthreshold=0.75\nfiltre=np.abs(correlation_matrix['Salary']) > 0.50\ncorr_features=correlation_matrix.columns[filtre].tolist()\nsns.clustermap(df[corr_features].corr(),annot=True,fmt=\".2f\")\nplt.title('Correlation btw features')\nplt.show()","959ba179":"import missingno as msno\nmsno.bar(df);","254ce22b":"df1=df.copy()\ndf1=df1.dropna()\ndf1.shape","d6f75c75":"df1=pd.get_dummies(df1,columns = ['League', 'Division', 'NewLeague'], drop_first = True)\ndf1.head()","af97d616":"clf=LocalOutlierFactor(n_neighbors=20, contamination=0.1)\nclf.fit_predict(df1)\ndf1_scores=clf.negative_outlier_factor_\ndf1_scores= np.sort(df1_scores)\ndf1_scores[0:20]","4ec76582":"sns.boxplot(df1_scores);","32d573e6":"threshold=np.sort(df1_scores)[10]\nprint(threshold)\ndf1=df1.loc[df1_scores > threshold]\ndf1=df1.reset_index(drop=True)","dd1103ac":"df1.shape","2c2d2bbf":"df1_X=df1.drop([\"Salary\",\"League_N\",\"Division_W\",\"NewLeague_N\"], axis=1)\ndf1_X.head(2)","10979d12":"from sklearn.preprocessing import StandardScaler\nscaled_cols=StandardScaler().fit_transform(df1_X)\n\n\n\nscaled_cols=pd.DataFrame(scaled_cols, columns=df1_X.columns)\nscaled_cols.head()","8be8a88a":"cat_df1=df1.loc[:, \"League_N\":\"NewLeague_N\"]\ncat_df1.head()","ca788c9b":"Salary=pd.DataFrame(df1[\"Salary\"])\nSalary.head()","d8c86ef5":"df2=pd.concat([Salary,scaled_cols, cat_df1], axis=1)\ndf2.head(2)","c3d6d027":"df2.head()","b2f0a31c":"df5=df.copy()","40003e4f":"df5.corr()","fbf495c8":"df5['Year_lab'] = pd.cut(x=df['Years'], bins=[0, 3, 6, 10, 15, 19, 24])\ndf5.groupby(['League','Division', 'Year_lab']).agg({'Salary':'mean'})","f3bb0dc4":"df5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"A\") & (df5['Division'] == 'E') & (df5['Years'] <= 3), \"Salary\"] = 112\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"A\") & (df5['Division'] == 'E') & (df5['Years'] > 3) & (df5['Years'] <= 6), \"Salary\"] = 656\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"A\") & (df5['Division'] == 'E') & (df5['Years'] > 6) & (df5['Years'] <= 10), \"Salary\"] = 853\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"A\") & (df5['Division'] == 'E') & (df5['Years'] > 10) & (df5['Years'] <= 15), \"Salary\"] = 816\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"A\") & (df5['Division'] == 'E') & (df5['Years'] > 15) & (df5['Years'] <= 19), \"Salary\"] = 665\n\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"A\") & (df5['Division'] == 'W') & (df5['Years'] <= 3), \"Salary\"] = 154\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"A\") & (df5['Division'] == 'W') & (df5['Years'] > 3) & (df5['Years'] <= 6), \"Salary\"] = 401\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"A\") & (df5['Division'] == 'W') & (df5['Years'] > 6) & (df5['Years'] <= 10), \"Salary\"] = 634\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"A\") & (df5['Division'] == 'W') & (df5['Years'] > 10) & (df5['Years'] <= 15), \"Salary\"] = 835\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"A\") & (df5['Division'] == 'W') & (df5['Years'] > 15) & (df5['Years'] <= 19), \"Salary\"] = 479\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"A\") & (df5['Division'] == 'W') & (df5['Years'] > 19), \"Salary\"] = 487\n\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"N\") & (df5['Division'] == 'E') & (df5['Years'] <= 3), \"Salary\"] = 248\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"N\") & (df5['Division'] == 'E') & (df5['Years'] > 3) & (df5['Years'] <= 6), \"Salary\"] = 501\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"N\") & (df5['Division'] == 'E') & (df5['Years'] > 6) & (df5['Years'] <= 10), \"Salary\"] = 824\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"N\") & (df5['Division'] == 'E') & (df5['Years'] > 10) & (df5['Years'] <= 15), \"Salary\"] = 894\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"N\") & (df5['Division'] == 'E') & (df5['Years'] > 15) & (df5['Years'] <= 19), \"Salary\"] = 662\n\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"N\") & (df5['Division'] == 'W') & (df5['Years'] <= 3), \"Salary\"] = 192\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"N\") & (df5['Division'] == 'W') & (df5['Years'] > 3) & (df5['Years'] <= 6), \"Salary\"] = 458\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"N\") & (df5['Division'] == 'W') & (df5['Years'] > 6) & (df5['Years'] <= 10), \"Salary\"] = 563\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"N\") & (df5['Division'] == 'W') & (df5['Years'] > 10) & (df5['Years'] <= 15), \"Salary\"] = 722\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"N\") & (df5['Division'] == 'W') & (df5['Years'] > 15) & (df5['Years'] <= 19), \"Salary\"] = 761\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"N\") & (df5['Division'] == 'W') & (df5['Years'] > 19), \"Salary\"] = 475","e38f0f83":"df5.shape","fa417ccd":"le = LabelEncoder()\ndf5['League'] = le.fit_transform(df5['League'])\ndf5['Division'] = le.fit_transform(df5['Division'])\ndf5['NewLeague'] = le.fit_transform(df5['NewLeague'])","c559b144":"df5.head()","2751aaf4":"df5['Year_lab'] = le.fit_transform(df5['Year_lab'])","8c9df555":"df5.head(2)","00113097":"df5.info()","2eaa4a34":"df5_X= df5.drop([\"Salary\",\"League\",\"Division\",\"NewLeague\"], axis=1)\n\nscaled_cols5=preprocessing.normalize(df5_X)\n\n\nscaled_cols5=pd.DataFrame(scaled_cols5, columns=df5_X.columns)\nscaled_cols5.head()","bee7d00d":"cat_df5=pd.concat([df5.loc[:,\"League\":\"Division\"],df5.loc[:,\"NewLeague\":\"Year_lab\"]], axis=1)\ncat_df5.head()","b5a08de8":"df6= pd.concat([scaled_cols5,cat_df5,df5[\"Salary\"]], axis=1)\ndf6","60cc50bf":"df6.shape","ce59c1dc":"df3= df1.copy()\nprint(df3.shape)\ndf3.head(2)","9d7bea39":"# log transform the variables\ndf3['CRuns'] = np.log(df3['CRuns'])\ndf3['CHits'] = np.log(df3['CHits'])\ndf3['CAtBat'] = np.log(df3['CAtBat'])\ndf3['Years'] = np.log(df3['Years'])\ndf3['CRBI'] = np.log(df3['CRBI'])\ndf3['CWalks'] = np.log(df3['CWalks'])","02e165c9":"df3_X=df3.drop([\"Salary\",\"League_N\",\"Division_W\",\"NewLeague_N\"], axis=1)\ndf3_X.head(2)","f3bbd4cb":"df3_X.shape","81fa5d3d":"Rscaler = RobustScaler().fit(df3_X)\nscaled_cols3=Rscaler.transform(df3_X)\nscaled_cols3=pd.DataFrame(scaled_cols3, columns=df3_X.columns)\nscaled_cols3.head()","efedc21b":"df4=pd.concat([df3_X,df3.loc[:, \"League_N\": \"NewLeague_N\"], df3[\"Salary\"]], axis=1)","506734d1":"df4.head()","7dab5d31":"scaled_cols3.shape","3270d78f":"cat_df3=df3.loc[:, \"League_N\":\"NewLeague_N\"]\ncat_df3.head()","f21d3aca":"df4.head()","4525342e":"df7=df.copy()","9b8b9276":"# Filled NaN values with mean\n\ndf7.loc[(df7[\"Salary\"].isnull()) & (df7[\"League\"] == \"A\") & (df7['Division'] == 'E'),\"Salary\"] = 670.849559\ndf7.loc[(df7[\"Salary\"].isnull()) & (df7[\"League\"] == \"A\") & (df7['Division'] == 'W'),\"Salary\"] = 418.593901\ndf7.loc[(df7[\"Salary\"].isnull()) & (df7[\"League\"] == \"N\") & (df7['Division'] == 'E'),\"Salary\"] = 572.348131\ndf7.loc[(df7[\"Salary\"].isnull()) & (df7[\"League\"] == \"N\") & (df7['Division'] == 'W'),\"Salary\"] = 487.259270","9608d9c3":"le = LabelEncoder()\ndf7['League'] = le.fit_transform(df7['League'])\ndf7['Division'] = le.fit_transform(df7['Division'])\ndf7['NewLeague'] = le.fit_transform(df7['NewLeague'])","3db8f108":"df7_X= df7.drop([\"Salary\",\"League\",\"Division\",\"NewLeague\"], axis=1)\n\nscaled_cols7=preprocessing.normalize(df7_X)\n\n\nscaled_cols7=pd.DataFrame(scaled_cols7, columns=df7_X.columns)","ee4d4cc1":"cat_df7=pd.concat([df7.loc[:,\"League\":\"Division\"],df7[\"NewLeague\"]], axis=1)\ncat_df7.head()","3adbc447":"df8= pd.concat([scaled_cols7,cat_df7,df7[\"Salary\"]], axis=1)\ndf8.head()","42b05431":"df8.shape","5a2b217e":"y=df2[\"Salary\"]\nX=df2.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\n\nlinreg = LinearRegression()\nmodel = linreg.fit(X_train,y_train)\ny_pred = model.predict(X_test)\ndf2_linreg_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf2_linreg_rmse","a7924c7e":"y=df6[\"Salary\"]\nX=df6.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\nlinreg = LinearRegression()\nmodel = linreg.fit(X_train,y_train)\ny_pred = model.predict(X_test)\ndf6_linreg_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf6_linreg_rmse","a358db9d":"y=df4[\"Salary\"]\nX=df4.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\nlinreg = LinearRegression()\nmodel = linreg.fit(X_train,y_train)\ny_pred = model.predict(X_test)\ndf4_linreg_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf4_linreg_rmse","fa74edf2":"y=df8[\"Salary\"]\nX=df8.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\nlinreg = LinearRegression()\nmodel = linreg.fit(X_train,y_train)\ny_pred = model.predict(X_test)\ndf8_linreg_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf8_linreg_rmse","1b75b62f":"y=df2[\"Salary\"]\nX=df2.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\n\nridreg = Ridge()\nmodel = ridreg.fit(X_train, y_train)\ny_pred = model.predict(X_test)\ndf2_ridreg_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf2_ridreg_rmse ","38fd54ca":"y=df6[\"Salary\"]\nX=df6.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\n\nridreg = Ridge()\nmodel = ridreg.fit(X_train, y_train)\ny_pred = model.predict(X_test)\ndf6_ridreg_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf6_ridreg_rmse ","4e64fc21":"y=df4[\"Salary\"]\nX=df4.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\n\nridreg = Ridge()\nmodel = ridreg.fit(X_train, y_train)\ny_pred = model.predict(X_test)\ndf4_ridreg_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf4_ridreg_rmse ","1bce1814":"y=df8[\"Salary\"]\nX=df8.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\n\nridreg = Ridge()\nmodel = ridreg.fit(X_train, y_train)\ny_pred = model.predict(X_test)\ndf8_ridreg_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf8_ridreg_rmse ","3a5bb03c":"y=df2[\"Salary\"]\nX=df2.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\n\nlasreg = Lasso()\nmodel = lasreg.fit(X_train,y_train)\ny_pred = model.predict(X_test)\ndf2_lasreg_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf2_lasreg_rmse","ae819bc2":"y=df6[\"Salary\"]\nX=df6.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\n\nlasreg = Lasso()\nmodel = lasreg.fit(X_train,y_train)\ny_pred = model.predict(X_test)\ndf6_lasreg_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf6_lasreg_rmse","cbd650ff":"y=df4[\"Salary\"]\nX=df4.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\n\nlasreg = Lasso()\nmodel = lasreg.fit(X_train,y_train)\ny_pred = model.predict(X_test)\ndf4_lasreg_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf4_lasreg_rmse","cbfebe25":"y=df8[\"Salary\"]\nX=df8.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\n\nlasreg = Lasso()\nmodel = lasreg.fit(X_train,y_train)\ny_pred = model.predict(X_test)\ndf8_lasreg_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf8_lasreg_rmse","15cdb87f":"y=df2[\"Salary\"]\nX=df2.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\n\nenet = ElasticNet()\nmodel = enet.fit(X_train,y_train)\ny_pred = model.predict(X_test)\ndf2_enet_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf2_enet_rmse","9e6d67ca":"y=df6[\"Salary\"]\nX=df6.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\n\nenet = ElasticNet()\nmodel = enet.fit(X_train,y_train)\ny_pred = model.predict(X_test)\ndf6_enet_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf6_enet_rmse","ac5bcf2f":"y=df4[\"Salary\"]\nX=df4.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\n\nenet = ElasticNet()\nmodel = enet.fit(X_train,y_train)\ny_pred = model.predict(X_test)\ndf4_enet_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf4_enet_rmse","733a66d4":"y=df8[\"Salary\"]\nX=df8.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\n\nenet = ElasticNet()\nmodel = enet.fit(X_train,y_train)\ny_pred = model.predict(X_test)\ndf8_enet_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf8_enet_rmse","1df2bcc4":"y=df2[\"Salary\"]\nX=df2.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\n\nalpha = [0.1,0.01,0.001,0.2,0.3,0.5,0.8,0.9,1]\nridreg_cv = RidgeCV(alphas = alpha, scoring = \"neg_mean_squared_error\", cv = 10, normalize = True)\nridreg_cv.fit(X_train, y_train)\nridreg_cv.alpha_\n\n#Final Model \nridreg_tuned = Ridge(alpha = ridreg_cv.alpha_).fit(X_train,y_train)\ny_pred = ridreg_tuned.predict(X_test)\ndf2_ridge_tuned_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf2_ridge_tuned_rmse","2e350f36":"y=df6[\"Salary\"]\nX=df6.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\n\nalpha = [0.1,0.01,0.001,0.2,0.3,0.5,0.8,0.9,1]\nridreg_cv = RidgeCV(alphas = alpha, scoring = \"neg_mean_squared_error\", cv = 10, normalize = True)\nridreg_cv.fit(X_train, y_train)\nridreg_cv.alpha_\n\n#Final Model \nridreg_tuned = Ridge(alpha = ridreg_cv.alpha_).fit(X_train,y_train)\ny_pred = ridreg_tuned.predict(X_test)\ndf6_ridge_tuned_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf6_ridge_tuned_rmse","aaeb66b5":"y=df4[\"Salary\"]\nX=df4.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\n\nalpha = [0.1,0.01,0.001,0.2,0.3,0.5,0.8,0.9,1]\nridreg_cv = RidgeCV(alphas = alpha, scoring = \"neg_mean_squared_error\", cv = 10, normalize = True)\nridreg_cv.fit(X_train, y_train)\nridreg_cv.alpha_\n\n#Final Model \nridreg_tuned = Ridge(alpha = ridreg_cv.alpha_).fit(X_train,y_train)\ny_pred = ridreg_tuned.predict(X_test)\ndf4_ridge_tuned_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf4_ridge_tuned_rmse","c371d8c2":"y=df8[\"Salary\"]\nX=df8.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\n\nalpha = [0.1,0.01,0.001,0.2,0.3,0.5,0.8,0.9,1]\nridreg_cv = RidgeCV(alphas = alpha, scoring = \"neg_mean_squared_error\", cv = 10, normalize = True)\nridreg_cv.fit(X_train, y_train)\nridreg_cv.alpha_\n\n#Final Model \nridreg_tuned = Ridge(alpha = ridreg_cv.alpha_).fit(X_train,y_train)\ny_pred = ridreg_tuned.predict(X_test)\ndf8_ridge_tuned_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf8_ridge_tuned_rmse","0ae9736e":"y=df2[\"Salary\"]\nX=df2.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\nalpha = [0.1,0.01,0.001,0.2,0.3,0.5,0.8,0.9,1]\nlasso_cv = LassoCV(alphas = alpha, cv = 10, normalize = True)\nlasso_cv.fit(X_train, y_train)\nlasso_cv.alpha_\n\n#Final Model \nlasso_tuned = Lasso(alpha = lasso_cv.alpha_).fit(X_train,y_train)\ny_pred = lasso_tuned.predict(X_test)\ndf2_lasso_tuned_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\ndf2_lasso_tuned_rmse","98e0d1ee":"y=df6[\"Salary\"]\nX=df6.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\nalpha = [0.1,0.01,0.001,0.2,0.3,0.5,0.8,0.9,1]\nlasso_cv = LassoCV(alphas = alpha, cv = 10, normalize = True)\nlasso_cv.fit(X_train, y_train)\nlasso_cv.alpha_\n\n#Final Model \nlasso_tuned = Lasso(alpha = lasso_cv.alpha_).fit(X_train,y_train)\ny_pred = lasso_tuned.predict(X_test)\ndf6_lasso_tuned_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\ndf6_lasso_tuned_rmse","fb4dffbe":"y=df4[\"Salary\"]\nX=df4.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\nalpha = [0.1,0.01,0.001,0.2,0.3,0.5,0.8,0.9,1]\nlasso_cv = LassoCV(alphas = alpha, cv = 10, normalize = True)\nlasso_cv.fit(X_train, y_train)\nlasso_cv.alpha_\n\n#Final Model \nlasso_tuned = Lasso(alpha = lasso_cv.alpha_).fit(X_train,y_train)\ny_pred = lasso_tuned.predict(X_test)\ndf4_lasso_tuned_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\ndf4_lasso_tuned_rmse","d464c2b5":"y=df8[\"Salary\"]\nX=df8.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\nalpha = [0.1,0.01,0.001,0.2,0.3,0.5,0.8,0.9,1]\nlasso_cv = LassoCV(alphas = alpha, cv = 10, normalize = True)\nlasso_cv.fit(X_train, y_train)\nlasso_cv.alpha_\n\n#Final Model \nlasso_tuned = Lasso(alpha = lasso_cv.alpha_).fit(X_train,y_train)\ny_pred = lasso_tuned.predict(X_test)\ndf8_lasso_tuned_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\ndf8_lasso_tuned_rmse","4195bf8b":"y=df2[\"Salary\"]\nX=df2.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\nenet_params = {\"l1_ratio\": [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n              \"alpha\":[0.1,0.01,0.001,0.2,0.3,0.5,0.8,0.9,1]}\n\nenet_model = ElasticNet().fit(X_train,y_train)\nenet_cv = GridSearchCV(enet_model, enet_params, cv = 10).fit(X, y)\nenet_cv.best_params_\n\n#Final Model \nenet_tuned = ElasticNet(**enet_cv.best_params_).fit(X_train,y_train)\ny_pred = enet_tuned.predict(X_test)\ndf2_enet_tuned_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf2_enet_tuned_rmse ","7154b502":"y=df6[\"Salary\"]\nX=df6.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\nenet_params = {\"l1_ratio\": [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n              \"alpha\":[0.1,0.01,0.001,0.2,0.3,0.5,0.8,0.9,1]}\n\nenet_model = ElasticNet().fit(X_train,y_train)\nenet_cv = GridSearchCV(enet_model, enet_params, cv = 10).fit(X, y)\nenet_cv.best_params_\n\n#Final Model \nenet_tuned = ElasticNet(**enet_cv.best_params_).fit(X_train,y_train)\ny_pred = enet_tuned.predict(X_test)\ndf6_enet_tuned_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf6_enet_tuned_rmse ","8756476d":"y=df4[\"Salary\"]\nX=df4.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\nenet_params = {\"l1_ratio\": [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n              \"alpha\":[0.1,0.01,0.001,0.2,0.3,0.5,0.8,0.9,1]}\n\nenet_model = ElasticNet().fit(X_train,y_train)\nenet_cv = GridSearchCV(enet_model, enet_params, cv = 10).fit(X, y)\nenet_cv.best_params_\n\n#Final Model \nenet_tuned = ElasticNet(**enet_cv.best_params_).fit(X_train,y_train)\ny_pred = enet_tuned.predict(X_test)\ndf4_enet_tuned_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf4_enet_tuned_rmse ","00f0f268":"y=df8[\"Salary\"]\nX=df8.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\nenet_params = {\"l1_ratio\": [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n              \"alpha\":[0.1,0.01,0.001,0.2,0.3,0.5,0.8,0.9,1]}\n\nenet_model = ElasticNet().fit(X_train,y_train)\nenet_cv = GridSearchCV(enet_model, enet_params, cv = 10).fit(X, y)\nenet_cv.best_params_\n\n#Final Model \nenet_tuned = ElasticNet(**enet_cv.best_params_).fit(X_train,y_train)\ny_pred = enet_tuned.predict(X_test)\ndf8_enet_tuned_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf8_enet_tuned_rmse ","0cdafe2c":"basicsonuc_df = pd.DataFrame({\"CONDITIONS\":[\"df2: drop NA and Outliers, normalized\",\"df6: filled with mean, normalized\",\"df4: drop NA and Outliers, log transformed\",\"df8: filled with mean,normalized\"],\n                              \"LINEAR\":[df2_linreg_rmse,df6_linreg_rmse,df4_linreg_rmse,df8_linreg_rmse],\n                               \"RIDGE\":[df2_ridreg_rmse,df6_ridreg_rmse,df4_ridreg_rmse,df8_ridreg_rmse],\n                              \"RIDGE TUNED\":[df2_ridge_tuned_rmse,df6_ridge_tuned_rmse,df4_ridge_tuned_rmse,df8_ridge_tuned_rmse],\n                              \"LASSO\":[df2_lasreg_rmse,df6_lasreg_rmse,df4_lasreg_rmse,df8_lasreg_rmse],\n                              \"LASSO TUNED\":[df2_lasso_tuned_rmse,df6_lasso_tuned_rmse,df4_lasso_tuned_rmse,df8_lasso_tuned_rmse],                              \n                              \"ELASTIC NET\":[df2_enet_rmse,df6_enet_rmse,df4_enet_rmse,df8_enet_rmse],\n                              \"ELASTIC NET TUNED\":[df2_enet_tuned_rmse,df6_enet_tuned_rmse,df4_enet_tuned_rmse,df8_enet_tuned_rmse]\n                              })\n\nbasicsonuc_df","40325d9d":"Categorical dataframe:","5a354377":"## Outlier Detection\n\nUsing LOF(Local Outliers Factor) method.","cb06848f":"Total NaN values numbers:","08d0c87d":"### Second Option\nThis is second option and method is fill NA values with mean.","0141098b":"Observe NaN values and take a head:","1503a503":"Let's put all created models into dataframe shape and watch them.","9039bb36":"## Elastic Net Regression with Model Tuning","0d94402c":"and for 'Year_lab' column also.","4d5be41a":"See just 'Salary' feature has NaN values. Now, correlation that is what's going between features. How are they strict relation between them. We gave correlation values more than 0.5 between features","13f37dde":"## Ridge Regression with Model Tuning","ff81c247":"And show all outliers with boxplot.","2295c44e":"## Elastic Net Regression","2ca604a9":"Give threshold for LOF.","a3c5c063":"Concatination for all prepared data frames:","29d70553":"## Lasso Regression","ac4e8f6c":"#### Normalization","92f96cd1":"### Third Option\n\nThis is third option for NaN values considiration. Drop NaN values and outliers like first option and log transformation of the features which have multicorrelation above 0.8 between each other.","8b6e7166":"## Normalization\n\nAfter standartization lets normalize last features.","ad439fe5":"Lets take group between 'League','Division', 'Year_lab' features and use 'mean' aggrigation fonksiyon for 'Salary' column.","837b5620":"Then, convert categorical variable into dummy\/indicator variables with 'drop_first = True'. This is for Dummy trap.","22c811cf":"Statistical view for all features:","8539b3d7":"Concatination for all prepared data frames:","96c32bae":"Lets take a copy and information about data set.","dbb8e1a7":"Concatination for all prepared data frames:","619a8f89":"Now using Label Encoder object then apply 'League', 'Division' and 'NewLeague'.","23ee2527":"# MODEL TUNING\n\nNow, consider with model tunning and get accuracy scores.","df33c740":"#### Concatenate","f6e6c673":"# REPORTING\n\nThe aim of this study is to set up linear regression models for the Hitters data set and minimize error scores in 4 data sets that have undergone different preprocessing. \n\nThe studies conducted are as follows:\n\n#### ** 1) ** Hitters Data Set was read.\n#### ** 2) ** With Exploratory Data Analysis:\n* Structural information of the dataset was checked.\n* Types of variables in data set were examined.\n* The size information of the data set has been accessed.\n* The number of missing observations from which variable in the data set was accessed. It was observed that there were 59 missing observations only in \"Salary\" which was dependent variable.\n* Descriptive statistics of the data set were examined.\n\n#### ** 3) ** In Data PreProcessing:\n* ** For df2: ** NaN values are dropped, Outliers are detected by LOF and dropped. Dummy variables were created. The X variables were normalized.\n* ** For df6: ** NaN values were filled by looking at \"Salary\" averages in age, league and division variables, Dummy variables were created. The X variables were normalized.\n* ** For df4: ** NaN values and outlier detected by LOF were dropped, log transformation was applied to variables with more than 80% correlation. Dummy variables were created. All x variables were brought to the same range as Robust scaler.\n* ** For df8: ** NaN values were filled by looking at \"Salary\" averages in league and division variables, Dummy variables were created. The X variables were normalized.\n\n#### ** 4) ** During the Model Building phase:\n\nUsing the Linear, Ridge, Lasso, ElasticNet machine learning models, ** RMSE ** values representing the difference between actual values and predicted values were calculated. Later, hyperparameter optimizations were applied for Ridge, Lasso and ElasticNet to further reduce the error value.\n","8f5db4f3":"## Standardization\n\nThis is first option with using drop method.","625eb651":"# Baseball Data\n## Description\nMajor League Baseball Data from the 1986 and 1987 seasons.\n\n## Usage\nHitters\n\n## Format\nA data frame with 322 observations of major league players on the following 20 variables.\n\n- AtBat: Number of times at bat in 1986\n\n- Hits: Number of hits in 1986\n\n- HmRun: Number of home runs in 1986\n\n- Runs: Number of runs in 1986\n\n- RBI: Number of runs batted in in 1986\n\n- Walks: Number of walks in 1986\n\n- Years: Number of years in the major leagues\n\n- CAtBat: Number of times at bat during his career\n\n- CHits: Number of hits during his career\n\n- CHmRun: Number of home runs during his career\n\n- CRuns: Number of runs during his career\n\n- CRBI: Number of runs batted in during his career\n\n- CWalks: Number of walks during his career\n\n- League: A factor with levels A and N indicating player's league at the end of 1986\n\n- Division: A factor with levels E and W indicating player's division at the end of 1986\n\n- PutOuts: Number of put outs in 1986\n\n- Assists: Number of assists in 1986\n\n- Errors: Number of errors in 1986\n\n- Salary: 1987 annual salary on opening day in thousands of dollars\n\n- NewLeague: A factor with levels A and N indicating player's league at the beginning of 1987\n\n## Source\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University. This is part of the data that was used in the 1988 ASA Graphics Section Poster Session. The salary data were originally from Sports Illustrated, April 20, 1987. The 1986 and career statistics were obtained from The 1987 Baseball Encyclopedia Update published by Collier Books, Macmillan Publishing Company, New York.\n\n## References\nGames, G., Witten, D., Hastie, T., and Tibshirani, R. (2013) An Introduction to Statistical Learning with applications in R, www.StatLearning.com, Springer-Verlag, New York\n\n## Examples\nsummary(Hitters)\nlm(Salary~AtBat+Hits,data=Hitters)\n--\nDataset imported from https:\/\/www.r-project.org.","141cf3bd":"#### Transformation","c7cf7b6e":"## Conclusion\n\nWhen the model created as a result of Elastic Net Hyperparameter optimization was applied to the df6 Data Frame, the lowest RMSE was obtained. (283)\n\n#### Note: \n- After this notebook, my aim is to prepare 'kernel' which is 'not clear' data set.\n\n- If you have any suggestions, please could you write for me? I wil be happy for comment and critics!\n\n Thank you for your suggestion and votes ;) ","2498bb9a":"## Linear Regression","1e2516cd":"# DATA UNDERSTANDING","52fb94eb":"Let's make assignments to NaN values according to the above grouping.","0a84b110":"Missing values visualization:","1ca065bd":"# MODELING\n\nLet's see different models error accuracy scores according to the DataFrames we created above.","bf27bdae":"### Fourth Option\nThis is fourth option for NaN values and method with mean.","f74f590d":"## Ridge Regression","580de9b7":"###  First Option\nThis method is drop all NaN values.","23f0c993":"# DATA PREPROCESSING\n\nWe will consider some options for Missing Values.","7f69ef57":"## Lasso Regression with Model Tuning"}}