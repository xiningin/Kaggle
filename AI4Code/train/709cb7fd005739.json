{"cell_type":{"998b63c4":"code","63b1a30b":"code","bd4f6b2b":"code","ac2b331a":"code","4cd1019c":"code","8bbdc9f8":"code","c008b9a6":"code","04a51c0d":"code","9c06b632":"code","2096c3e0":"code","b0ff8668":"code","1a33bef1":"code","d5cc8969":"code","cf64d75f":"code","6bb72389":"code","d21cb64a":"code","6022b7eb":"code","4b85f4da":"code","66386d6c":"code","5f0a79b1":"code","f2158ac7":"code","c890a22d":"code","6246483a":"code","f79020a4":"code","ac15ba56":"code","2a8a4c10":"code","84a20da8":"code","5e93af7a":"code","cbeed747":"code","1b155e5e":"code","955c7b17":"markdown","e31dde40":"markdown","ceab604a":"markdown","a3c42686":"markdown","d211b748":"markdown","c5f5f5b6":"markdown","bd7a0822":"markdown","bb6024cc":"markdown","156ea214":"markdown"},"source":{"998b63c4":"import numpy as np\nimport pandas as pd\nimport re\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","63b1a30b":"df = pd.read_csv(\"..\/input\/newyork-room-rentalads\/room-rental-ads.csv\")\ndf.head()","bd4f6b2b":"df.info()","ac2b331a":"df.shape","4cd1019c":"df.rename(columns={'Description': 'desc', 'Vague\/Not': 'vague'},inplace=True)\ndf","8bbdc9f8":"df.count()","c008b9a6":"print(df.isna().sum())","04a51c0d":"df.dropna(how = \"any\", inplace=True)","9c06b632":"df.count()","2096c3e0":"classification = df.groupby('vague').count()\nclassification","b0ff8668":"count = list(df['vague'].value_counts())\ncount","1a33bef1":"x=['vague','Not vague']\ny = count\nfig = plt.figure(figsize = (10, 5)) \n  \nplt.bar(x, y, color ='orange',  \n        width = 0.5) \n  \nplt.xlabel(\"Vague\/Not\") \nplt.ylabel(\"No. of ads in data\") \nplt.xticks(rotation=90)\nplt.title(\"No.of ads in each group\") \nplt.show() ","d5cc8969":"def find_message_length(content):\n    return len(content)","cf64d75f":"df['content_len'] = df['desc'].apply(find_message_length)\ndf","6bb72389":"plt.hist(df['content_len'],bins = 50, weights = np.ones(len(df['content_len']))\/len(df['content_len']))\nplt.xlabel(\"Content length\")\nplt.ylabel(\"Group count\")\nplt.title(\"Analysis of content length\")\nplt.show()","d21cb64a":"vague = df[df['vague']==1].iloc[: ,0]\nnot_vague= df[df['vague']==0].iloc[: ,0]\nplt.hist(vague.apply(lambda desc: len(desc)),bins = 50,label = 'Vague', alpha=0.5)\nplt.hist(not_vague.apply(lambda desc: len(desc)),bins=50,label='Not Vague',alpha=0.5)\nplt.xlabel(\"Content length\")\nplt.ylabel(\"Group count\")\nplt.title(\"Analysis of content length\")\nplt.legend()\nplt.show()","6022b7eb":"import string\nstring.punctuation\n\ndef remove_punctuation(text):\n    new_text=''.join([char for char in text if char not in string.punctuation])\n    return new_text\ndf['new_desc']=df['desc'].apply(lambda row : remove_punctuation(row))\ndf","4b85f4da":"import re\ndef tokenize(text):\n    tokens=re.split('\\W+',text)\n    return tokens","66386d6c":"df['tokenized_text']=df['new_desc'].apply(lambda row : tokenize(row.lower()))\ndf.head()","5f0a79b1":"import nltk\nstopwords=nltk.corpus.stopwords.words('english')\nstopwords[:5]","f2158ac7":"def remove_stopwords(text):\n    clean_text=[word for word in text if word not in stopwords]\n    return clean_text","c890a22d":"df['clean_text'] = df['tokenized_text'].apply(lambda row : remove_stopwords(row))\ndf.head()","6246483a":"from collections import Counter\nwords_collection = Counter([item for subtext in df['clean_text'] for item in subtext])\nfreq_word_df = pd.DataFrame(words_collection.most_common(20))\nfreq_word_df.columns = ['frequently_used_word','count']","f79020a4":"freq_word_df","ac15ba56":"import plotly.graph_objects as go\n\nlabels = list(freq_word_df['frequently_used_word'])\nvalues = list(freq_word_df['count'])\n\n# Use `hole` to create a donut-like pie chart\nfig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.3)])\nfig.show()","2a8a4c10":"vague_content = df[df['vague']==1]\nnot_vague_content= df[df['vague']==0]\nwords_collection_in_vague = Counter([item for subtext in vague_content['clean_text'] for item in subtext])\nwords_collection_in_notvague = Counter([item for subtext in not_vague_content['clean_text'] for item in subtext])\nfreq_word_df_vague = pd.DataFrame(words_collection_in_vague.most_common(20))\nfreq_word_df_notvague = pd.DataFrame(words_collection_in_notvague.most_common(20))\nfreq_word_df_vague.columns = ['frequently_used_word','count']\nfreq_word_df_notvague.columns = ['frequently_used_word','count']","84a20da8":"freq_word_df_vague","5e93af7a":"#vague freq words count\nlabels = list(freq_word_df_vague['frequently_used_word'])\nvalues = list(freq_word_df_vague['count'])\n\n# Use `hole` to create a donut-like pie chart\nfig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.3)])\nfig.show()","cbeed747":"freq_word_df_notvague","1b155e5e":"#nonvague freq words count\nlabels = list(freq_word_df_notvague['frequently_used_word'])\nvalues = list(freq_word_df_notvague['count'])\n\n# Use `hole` to create a donut-like pie chart\nfig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.3)])\nfig.show()","955c7b17":"# 1. Introduction \u2b07\n**This notebook is our attempt to visualize vagueness of Room rental ads in Newyork.**","e31dde40":"# 5. Data Visualization \ud83d\udcc9\n**5.1. Classifying Vague and Non vague ads.**","ceab604a":"# 3. Reading CSV Data \ud83d\udcdd","a3c42686":"# 4. Data Pre-processing \u2699\ufe0f","d211b748":"**5.3. Analysis of Frequent words in ads**","c5f5f5b6":"**5.4. Analysis of Frequent words in both Vague and Non vague ads**","bd7a0822":"**5.2. Analysis of Content length of ads**","bb6024cc":"# Newyork room rentals ads EDA Analysis \ud83c\udfe0\n![cmpczmlqybl1ryn0ep6i.jpg](attachment:cmpczmlqybl1ryn0ep6i.jpg)","156ea214":"# 2. Importing required libraries \ud83d\udcda"}}