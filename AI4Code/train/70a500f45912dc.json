{"cell_type":{"f6975077":"code","f32605e9":"code","2cfe9542":"code","eb7f0d69":"code","06412a92":"code","53ce82aa":"code","9270ec15":"code","1ffce555":"code","0b89eb46":"code","090db207":"code","bb290644":"code","62d5445e":"code","fc477416":"code","22a2da09":"code","f919f3d2":"code","e0b477ff":"code","4c7961e9":"code","a9764eda":"code","ccf4e44f":"code","57f43607":"code","80d1ccc1":"code","5d9760a4":"code","cc4ed87c":"code","4e68bafa":"code","7bcdf487":"code","70982452":"code","38ae72d3":"code","2964363f":"code","3b1b4cd3":"code","23c0b332":"code","fdc3408d":"code","a1a02b5b":"code","01d55a3e":"code","81102112":"code","119626f4":"code","31ddf92a":"code","92e0eb6f":"code","fc4e4db7":"code","9550ee5b":"code","93feb637":"code","7f184823":"code","21827d30":"code","f1acd74b":"code","01ea590a":"code","f8e5c795":"code","426b9b6a":"code","2b5f8d16":"code","eee65f7a":"code","bb7c26e6":"markdown","39373710":"markdown","bbcc9fe2":"markdown","630c1afd":"markdown","0d20d429":"markdown","53d80693":"markdown","cee5dfd0":"markdown","8310e1d4":"markdown","2d060cb7":"markdown","59da0a10":"markdown","47d2d3af":"markdown","2ef52835":"markdown","24d6fc4e":"markdown","c27156ff":"markdown","15a4d178":"markdown","51ad79b6":"markdown","7003d22c":"markdown","ce657325":"markdown","35b69194":"markdown","887447b1":"markdown","563d060b":"markdown","61bcc507":"markdown","cf3e60b1":"markdown","10a2e063":"markdown","eee3e7df":"markdown","75fa77a1":"markdown","34174d9d":"markdown","0c5172ea":"markdown","858299d1":"markdown","bb0b7c9c":"markdown","9b5f7881":"markdown","31f766de":"markdown","d4851324":"markdown","f52d782e":"markdown","a099814d":"markdown","b97c4353":"markdown","7d29537d":"markdown","5b3730cf":"markdown","be61ebcd":"markdown","cbbfd540":"markdown","c9d3d62e":"markdown","dd5905f1":"markdown","76e879f7":"markdown","58999832":"markdown"},"source":{"f6975077":"# Data analysis tools\nimport numpy as np\nimport pandas as pd\n\n# Visualization tools\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Pre-machine learning tools\nfrom sklearn import preprocessing  # Perform data standardization\nfrom sklearn.model_selection import train_test_split  # split data\nfrom sklearn.model_selection import KFold  # Perform train split for validation\nfrom sklearn.decomposition import PCA  # Linear dimensionality reduction\n\n# Machine learning Algorithms\nfrom sklearn.naive_bayes import GaussianNB  # Naive Bayes classifier for categorical features\nfrom sklearn.linear_model import LogisticRegression  # Logistic Regression classifier\nfrom sklearn.neighbors import KNeighborsClassifier  # KNN Classifier\nfrom sklearn.tree import DecisionTreeClassifier  # Decision Tree for classification\nfrom sklearn.ensemble import RandomForestClassifier  # Random Forest ensemble for classification\nfrom sklearn.svm import SVC  # C-Support Vector Classification\nfrom sklearn.model_selection import GridSearchCV  # Exhaustive search over specified parameter values for an estimator\nfrom sklearn.multioutput import MultiOutputClassifier  # Multi target classification\n\n# Post-machine learning analysis\nfrom sklearn.metrics import accuracy_score  # Top-k Accuracy classification score\nfrom sklearn.metrics import classification_report  # Report precision, recall, f1-score, and more\nimport classification_report_plot as crp # Generate heatmap from classification report\n\n# Other\nfrom warnings import filterwarnings  # warning filters\nfilterwarnings(action='ignore') # Prevent convergence warning and math errors","f32605e9":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        df = pd.read_csv(os.path.join(dirname, filename))","2cfe9542":"print(df.dtypes)","eb7f0d69":"df.head()","06412a92":"df.info()","53ce82aa":"df.tail()","9270ec15":"print(df['duration_ms'].value_counts())\nprint('_'*50)\nprint(df['tempo'].value_counts())","1ffce555":"df.duplicated().sum()","0b89eb46":"# 1. Removal of 5 black entries\ndf.dropna(axis=0, how='all', inplace=True)\n\n# 2. Removal of the following features: \"instance_id\", \"artist_name\", \"track_name\", \"obtained_date\"\"\ndf.drop(columns=['instance_id', 'artist_name', 'track_name', 'obtained_date'], axis=1, inplace=True)\n\n# 3. Conversion of duration \"-1\" and tempo \"?\" to mean values of their features.\n# calculating mean of values without '-1':\nduration_without_minus_one = df['duration_ms'].drop(df.loc[df['duration_ms'] == -1].index)\ndf['duration_ms'].replace(-1, duration_without_minus_one.mean(), inplace=True)\n\n# calculating mean of values without '?':\ntempo_without_question_mark = df['tempo'].drop(df.loc[df['tempo'] == '?'].index)\ndf['tempo'].replace('?', tempo_without_question_mark.astype(float).mean(), inplace=True)\n\n# 4. 'tempo' feature conversion from \"object\" to \"float64\".\ndf['tempo'] = df['tempo'].astype(float)","090db207":"print(df.info())\nprint('_'*50)\nprint('Duration:\\n', df['duration_ms'].value_counts())\nprint('_'*50)\nprint('Tempo:\\n', df['tempo'].value_counts())\nprint('_'*50)\nprint('Duplicates:\\n', df[df.index.duplicated()])","bb290644":"df.describe()","62d5445e":"df.describe(include=['O'])","fc477416":"df_numerical_features_list = []\n[df_numerical_features_list.append(feature) for feature in df.columns]\ndf_numerical_features_list.remove('key')\ndf_numerical_features_list.remove('mode')\ndf_numerical_features_list.remove('music_genre')","22a2da09":"for feature in df_numerical_features_list:\n    display(df[[feature, 'music_genre']].groupby(['music_genre'], as_index=False).mean().sort_values(by=feature, ascending=False))","f919f3d2":"for column in df.select_dtypes(include='object'):\n    display(df.groupby(column).mean())","e0b477ff":"scaler = preprocessing.StandardScaler()\nscaler.fit(df[df_numerical_features_list])\ndf[df_numerical_features_list] = scaler.transform(df[df_numerical_features_list], copy=False)","4c7961e9":"plt.figure(figsize=(20, 20))\nsns.heatmap(df.corr(), cmap='RdBu_r', annot=True)","a9764eda":"sns.pairplot(df, diag_kind='kde')","ccf4e44f":"# Create subplots net.\nfig, axes = plt.subplots(figsize=(10, 10))\n\n# Fill subplots.\nfor idx, feature in enumerate(df_numerical_features_list):\n    g = sns.boxplot(x='music_genre', y=feature, data=df)\n    g.set_title('Stacked Box Plots of All Music Genre')\n    plt.xticks(rotation=45)\n    sns.set(font_scale=2)","57f43607":"target_names_list = ['Electronic', 'Anime', 'Jazz', 'Alternative', 'Country', 'Rap', 'Blues', 'Rock', 'Classical', 'Hip-Hop']","80d1ccc1":"# Create subplots net.\nfig, axes = plt.subplots(len(df_numerical_features_list), 1, figsize=(20, 105))\n\n# Fill subplots.\nfor idx, feature in enumerate(df_numerical_features_list):\n    g = sns.boxplot(ax=axes[idx], x='music_genre', y=feature, data=df)\n    g.set_title(feature)\n    plt.sca(axes[idx])\n    plt.xticks(rotation=30)\n    sns.set(font_scale=2)","5d9760a4":"for column in df.select_dtypes(include='object'):\n    sns.catplot(x='music_genre', hue=column, data=df, kind='count', aspect=5)\n    g.set_title(column)","cc4ed87c":"df = pd.get_dummies(df, prefix=['key', 'mode'], columns=['key', 'mode'])","4e68bafa":"plt.figure(figsize=(20, 20))\nsns.heatmap(df.corr(), cmap='RdBu_r')","7bcdf487":"models = []\n\nmodels.append(('GaussianNB', GaussianNB))\nmodels.append(('LogisticRegression', LogisticRegression))\nmodels.append(('SVC', SVC))\nmodels.append(('KNN', KNeighborsClassifier))\nmodels.append(('DecisionTree', DecisionTreeClassifier))\nmodels.append(('RandomForest', RandomForestClassifier))\n","70982452":"models_parameters = []\n\n# GaussianNB\nmodels_parameters.append([{'estimator__var_smoothing': [1e-15, 1e-13, 1e-11]}])\n\n# LogisticRegression\nmodels_parameters.append([{'estimator__intercept_scaling': [0.2, 0.5, 1],\n                           'estimator__max_iter': [100, 200, 500],\n                           'estimator__penalty': ['none']}])\n\n# SVC\nmodels_parameters.append([{'estimator__C': [0.9, 1.1],\n                           'estimator__decision_function_shape': ['ovo'],\n                           'estimator__kernel': ['rbf'],\n                           'estimator__max_iter': [100, 500, 700]}])\n\n# KNeighborsClassifier\nmodels_parameters.append([{'leaf_size': [3, 5],\n                           'n_neighbors': [5, 9, 11],\n                           'weights': ['uniform']}])\n\n\n# DecisionTree\nmodels_parameters.append([{'criterion': ['gini', 'entropy'],\n                           'max_depth': [7 ,11, 13]}])\n\n# RandomForest\nmodels_parameters.append([{'n_estimators': [25, 30, 35],\n                           'min_samples_leaf': [4, 5, 6],\n                           'max_depth': [8, 10, 13]}])","38ae72d3":"models_all_data = np.concatenate((np.array(models), np.array(models_parameters)), axis=1)\nmodels_all_data","2964363f":"df['music_genre'] = df['music_genre'].map({'Electronic': 0, 'Anime': 1, 'Jazz': 2, 'Alternative': 3, 'Country': 4, 'Rap': 5, 'Blues': 6, 'Rock': 7, 'Classical': 8, 'Hip-Hop': 9})","3b1b4cd3":"x_train, x_test, y_train, y_test = train_test_split(df.drop('music_genre', axis=1), df['music_genre'], test_size=0.20, random_state=42)","23c0b332":"# hot encoding to y:\ny_train = pd.get_dummies(y_train)\ny_test = pd.get_dummies(y_test)","fdc3408d":"pca_obj = PCA(n_components=25)\npca_obj.fit(x_train)\nprint('Checking all 25 features: ')\nprint('variance_ratio: ', pca_obj.explained_variance_ratio_)\ncum_eig_vals = np.cumsum(pca_obj.explained_variance_ratio_)\nprint('cum_eig_vals: ', cum_eig_vals)\nbool_components = cum_eig_vals <= 0.95\nprint('Sum of features to reach 95%: ', bool_components.sum())","a1a02b5b":"pca_obj = PCA(n_components=bool_components.sum())\npca_obj.fit(x_train)\nx_train_PCA = pca_obj.transform(x_train)  # create x_train_PCA\nprint(pca_obj.explained_variance_ratio_)\nprint(x_train_PCA[0])","01d55a3e":"# update x test version based of x train analysis\nx_test_PCA = pca_obj.transform(x_test)\nprint(x_test_PCA[0])","81102112":"decision_tree_obj = models_all_data[4, 1]()\nobj_model = GridSearchCV(estimator=decision_tree_obj, param_grid=[models_all_data[4, 2]], cv=5)\nobj_model.fit(x_train, y_train)\ny_prediction_train = obj_model.predict(x_train).astype(int)\naccuracy_score_train = accuracy_score(y_train, y_prediction_train)","119626f4":"print('Decision tree')\nprint('Optimal parameters: ', obj_model.best_params_)\nprint('Train')\nprint('Accuracy score: ', round(accuracy_score_train * 100, 2))\nprint('Validation')\nprint('Accuracy score: ', round(obj_model.best_score_ * 100, 2))","31ddf92a":"print(classification_report(y_train, y_prediction_train))","92e0eb6f":"decision_tree_obj = models_all_data[4, 1]()\nobj_model_PCA = GridSearchCV(estimator=decision_tree_obj, param_grid=[models_all_data[4, 2]], cv=5)\nobj_model_PCA.fit(x_train_PCA, y_train)\ny_prediction_train = obj_model_PCA.predict(x_train_PCA).astype(int)\naccuracy_score_train = accuracy_score(y_train, y_prediction_train)","fc4e4db7":"print('Decision tree with PCA')\nprint('Optimal parameters: ', obj_model_PCA.best_params_)\nprint('Train')\nprint('Accuracy score: ', round(accuracy_score_train * 100, 2))\nprint('Validation')\nprint('Accuracy score: ', round(obj_model_PCA.best_score_ * 100, 2))","9550ee5b":"print(classification_report(y_train, y_prediction_train))","93feb637":"obj_model_list = []\nmodels_score_table = []\ny_prediction_train = []\nfor name, model, parameters in models_all_data:\n    model_starter = model()\n    if any(name in name_in_list for name_in_list in models_all_data[0:3,0]):\n        multilabel_classifier = MultiOutputClassifier(model_starter)\n        obj_model_list.append(GridSearchCV(estimator=multilabel_classifier, param_grid=parameters))\n    else:\n        obj_model_list.append(GridSearchCV(estimator=model_starter, param_grid=parameters))\n    obj_model_list[-1].fit(x_train, y_train)\n    y_prediction_train.append(obj_model_list[-1].predict(x_train).astype(int))\n    accuracy_score_train = accuracy_score(y_train, y_prediction_train[-1])\n    models_score_table.append([name, obj_model_list[-1].best_params_, round(accuracy_score_train * 100, 2), round(obj_model_list[-1].best_score_ * 100, 2)])\n    print(models_score_table[-1])","7f184823":"target_names = np.arange(0,10,1)\nfor idx, prediction in enumerate(y_prediction_train):\n    print(models_all_data[idx, 0])\n    print(classification_report(y_train, y_prediction_train[idx]))","21827d30":"# Convert output table to NumPy and extract methods with the best train and validate scores.\nscore = np.array(models_score_table)\ntrain_score = score[:,2].astype(float)\nvalidate_score = score[:,3].astype(float)\nprint('Best train score', score[np.where(train_score == np.amax(train_score)), :])\nprint('\\nBest validate score', score[np.where(validate_score == np.amax(validate_score)), :])\ntrain_position = np.where(train_score == np.amax(train_score))\nvalidate_position = np.where(validate_score == np.amax(validate_score))\n\n# Find the best balance between train to validate.\nbalanced_model = np.inf\nbalanced_idx = 0\nfor idx, data in enumerate(score):\n    new_balanced_model = float(data[2]) - float(data[3])\n    if new_balanced_model < balanced_model:\n        balanced_model = new_balanced_model\n        balanced_idx = idx\n\nprint('\\nMost balanced model: ', score[balanced_idx, :])","f1acd74b":"score[np.where(validate_score == np.amax(validate_score)), :]","01ea590a":"best_model_index = int(np.where(validate_score == np.amax(validate_score))[0])\ny_prediction_test = obj_model_list[best_model_index].predict(x_test).astype(int)\naccuracy_score_test = accuracy_score(y_test, y_prediction_test)","f8e5c795":"print(models_score_table[best_model_index])\nprint('Test accuracy score:', round(accuracy_score_test * 100, 2))\nprint('_'*50)\ntest_classification_report = classification_report(y_test, y_prediction_test, target_names=target_names_list)\nprint(test_classification_report)","426b9b6a":"# Preparing data from a heatmap.\ntest_classification_report = \"\"\" precision    recall  f1-score   support\n\n  Electronic       0.61      0.44      0.51      1009\n       Anime       0.77      0.64      0.70      1034\n        Jazz       0.48      0.37      0.42       985\n Alternative       0.40      0.20      0.27      1008\n     Country       0.54      0.45      0.49       986\n         Rap       0.40      0.30      0.34      1030\n       Blues       0.54      0.42      0.47      1021\n        Rock       0.51      0.45      0.48       977\n   Classical       0.81      0.75      0.78       955\n     Hip-Hop       0.40      0.31      0.35       995\n\n     avg \/ total       0.43      0.43      0.43     10000\"\"\"","2b5f8d16":"crp.plot_classification_report(test_classification_report)","eee65f7a":"print('Test accuracy score:', round(accuracy_score_test * 100, 2))","bb7c26e6":"# Chapter 3: Wrangle, prepare, cleanse the data","39373710":"# Chapter 6: Visualize, report, and present the problem-solving steps and final solution","bbcc9fe2":"# Chapter 4: Analyze, identify patterns, and explore the data","630c1afd":"**Future improvements:** \n\n* Merge similar music genres will reduce the quality of the result but allow for better predictions as a whole; For example, rap and alternative genres.\n\n* Transfer the names of the songs into a length value to promote a new feature by NLP Word2Vec classifier.\n\n* Examine unsupervised and deep-learning models.","0d20d429":"Convert music_genre music genres to numerical classes:","53d80693":"While PCA demands significantly fewer resources to process due to the smaller dataset, it reduces the performance of the model.\n\nThus, PCA will not be used further.\n\nWe now implement the entire models' list:\n","cee5dfd0":" **Note:** while the tempo feature is an object, it is numerical.","8310e1d4":"The data provided in this project is a '.csv' file with no separation between train and test datasets. Stages 3 & 4 will be conducted on a single dataset to maintain its integrity.","2d060cb7":"**Discussion:**\n\n* Results:\n    \n    * The best performance can be seen in classical music, followed by anime and electronic genres. These genres have unique features. For example, the duration of classical music is very long and has extremely low acousticness comparably to other genres.\n\n    * The lowest performances are with Rap and alternative music. Rap is unique only by popularity with a minor advantage over rock. Alternative is at the top of loudness, with rap at almost similar value. The two least performing genres of rap and alternative share several features, such as acousticness and liveness,  with exceptionally close values that could cause a classification error between the two.\n\n\n* Models performance:\n    \n    * GaussianNB: Naive Bayes performance was the lowest. One way to improve its performance is by splitting the data by its features into a categorical and numerical dataset and a modified version of naive Bayes, which fit each type. The probability of the two models can be used for the final prediction.\n\n    * LogisticRegression: Logistic regression can handle the type of data used in this project. Nevertheless, the final classification decision is ambiguous when features values of different music genres are similar.\n    \n    * SVC: C-Support Vector Classification can handle multiclass datasets. This model is ideal for a multi-dimensional data partition. Nevertheless, the given data is overwhelmingly entangled for a successful separation.\n\n    * KNN: K-nearest Neighbors classifier presented good results in a challenging dataset where many features are indistinguishable between music genres.\n    \n    * DecisionTree: Decision tree performance was the highest. This model is efficient in a multi-classes environment due to its indifference to the number of classes.\n    \n    * RandomForest: Random forest model prospects from applying many trees, which reduces the effect of the data splitting. The grid search for the number of trees yielded an optimal forest of 30 trees. The usage of multiple trees led to overfitting seen in the classification report. The tightly packed data of different classes possibly produced specialized (over-fitted) trees in a specific class. When all trees were merged into a forest, a decision conflict occurred between them, leading to confusion\n    \n\n\nTerminology:\n\nPrecision - True Positives \/ Total Predicted Positive\n\nRecall - True Positives \/ Total Actual Positive\n\nF1-score - 2 x (Precision * Recall \/ Precision * Recall)","59da0a10":"No test file is available to predict and submit.","47d2d3af":"Grouped numeric features by each categorical feature and music genres:","2ef52835":"**Duplicates:**\n\n4 duplicates were found.\n\nSince there are 5 known blank entries, no additional duplicates were found in the dataset.","24d6fc4e":"**Test:**","c27156ff":"# Chapter 2: Import protocol, acquire training and testing data","15a4d178":"# Leak-Tight Prediction of Music Genres\nClassify music into genres by classical machine learning models\n","51ad79b6":" **Features Review:**\n \n **Labels:** music_genre (to be separated)\n \n **Numerical:**\n instance_id, popularity, acousticness, danceability, duration_ms, energy, instrumentalness, liveness, loudness, speechiness, tempo, valence\n \n \n **Categorical:**\n key, mode\n \n **Other:**\n  artist_name, track_name - text\n  \n obtained_date - irrelevant","7003d22c":"Based on the results the best model is:","ce657325":"# Chapter 1: Question or problem definition","35b69194":"Count plots of categorical features:","887447b1":"**Taking Action:**\n\n    1. Removal of 5 black entries.\n\n    2. Removal of the following features: \"instance_id\", \"artist_name\", \"track_name\", \"obtained_date\"\n\n    3. Conversion of duration \"-1\" and tempo \"?\" to mean values of their features.\n\n    4. Tempo feature conversion from \"object\" to \"float64\".","563d060b":"In this Kaggle dataset, the song genre needs to be classified by their genre.\n\nNo early description is given on the feature collection methods, quality, or any other type of data.","61bcc507":"Stacked box-plots of all music genres followed by box-plot matrix separated by genre:","cf3e60b1":"**Model selection**\n\nWe have 10 music genres to classify by performing supervised learning training on an available dataset. Thus, we want to use a supervised learning model to conduct classification and regression. For this project, we focus on classical machine learning algorithms. We shall examine the following algorithms:\n\n  \n    * Naive Bayes\n    * KNN\n    * Logistic Regression\n    * Decision Tree\n    * Random Forrest\n    * Support Vector Machines\n","10a2e063":"Show correlation between features:","eee3e7df":"**Visualization**","75fa77a1":"**Errors or typos:**\n\nartist_name: missing data is represented by \"empty_field\".\n\ntrack_name: non-english ASCI synbols.\n\nduration: unknown duration marked as \"-1\"\n\ntempo: unknown tempo is described as \"?\"","34174d9d":"**missing data:**\n\n5 enteries are blank","0c5172ea":"**Compare Decision tree classifier with and without PCA**","858299d1":"**Distribution of numerical feature values**\n\n* Total of 50,000 samples, following the removal of 5 blank rows.\n* Popularity is well balanced around 45, in the range of {0, 99}.\n* In most songs, acousticness is very low, with 50% below 0.14, in the range of {0, 1}.\n* The danceability of the songs is evenly distributed between {0, 0.99}.\n* The duration of almost all songs is ~4 minutes \u00b140 seconds.\n* Most song energy is higher than the middle range value of 0.5, {0, 0.999}.\n* The vast majority of the songs are not instrumentalness {0, 0.99}.\n* Liveness values are centered at the lower scale at 0.19\u00b10.16  in the full range of {0, 1}.\n* Loudness is mostly a negative ranged parameter centered around -9.13 spanning {-47.04, 3.7}.\n* Most songs speechiness is nearly 0 ranging {0, 0.94}.\n* The tempo of most songs is centered around 120 in range of {34, 220}\n* Valence is evenly distributed at 0.45 in range of {0, 0.99}\n\n","bb0b7c9c":"**PCA**\n\nBy applying PCA, one can see that the first 14 features equal 95% of the energy.\n\nThus we drop the rest of the features.","9b5f7881":"Due to wide variance between features values, a rescaling is required.","31f766de":"# Chapter 5: Model, predict and solve the problem","d4851324":"# Chapter 7: Supply or submit the results.","f52d782e":"Correlation of music genres to feature:","a099814d":"**Checking actions:**","b97c4353":"Transform key and mode features to one-hot encoding:","7d29537d":"List of models and hyperparameters for grid search:","5b3730cf":"**Summary**\n\n* Data was analyzed, cleaned, and organized.\n\n* PCA was not applied to reduce features due to reduced performance.\n\n* 6 machine learning classifiers models were tested with multiple hyperparameters.\n\n* The best model, by validation score, was applied to analyze the test dataset.\n\n* Viewing the final test score, one should note that random pick out of 9 classifications equals an 11.11% success rate:","be61ebcd":"**Analyze by visualizing data**","cbbfd540":"**Distribution of categorical feature values**\n\n* Key values have 12 unique options, with dominant G in ~11% of the songs.\n* Mode variable between two possibilities with a frequency of 2\/3 (Major) and 1\/3 (Minor)\n* Music genres are separable to 10 classes, with Blues as most common with 10%.","c9d3d62e":"Show correlation between all features:","dd5905f1":"Workflow stages:\n\n    1. Question or problem definition.\n    2. Import protocol, acquire training and testing data.\n    3. Wrangle, prepare, cleanse the data.\n    4. Analyze, identify patterns, and explore the data.\n    5. Model, predict and solve the problem.\n    6. Visualize, report, and present the problem-solving steps and final solution.\n    7. Supply or submit the results.\n","76e879f7":"* Good correlation is visible between loudness and energy features.\n* Opposite correlation between acousticness to energy and loudness.\n* No specific correlation was found in the categorical features.\n* Popularity feature has the higher variance between music genres.\n* Electronic, blues, and classical music have the highest valence difference between samples parameters.\n* The classes are equally represented in the dataset.","58999832":"Detailed overview of the relationships of the features:"}}