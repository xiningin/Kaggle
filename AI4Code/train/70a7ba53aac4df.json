{"cell_type":{"e20b915f":"code","72570997":"code","19932eaa":"code","94b21ad8":"code","d7d13a19":"code","effead93":"code","bd37ae33":"code","6c4e3606":"code","5081c78a":"code","f4517acc":"code","ee973376":"code","ed42d84b":"code","a8ae10cc":"code","e56783f9":"code","d12678c4":"code","eab35f47":"code","e759e2a2":"code","43c62f76":"code","fb31473d":"code","f66ffdac":"code","9a7418be":"code","8d914b21":"code","7df5d0af":"code","ee1204bb":"code","77aae220":"code","d1cc6f1a":"code","8fa1c981":"code","62c567d2":"code","69037022":"code","be2ad618":"code","97d90744":"code","9d38ee9d":"code","f81fc8b5":"code","54a89717":"code","c2a389ed":"code","34bc7a15":"code","754eedb4":"code","4e2ebc43":"code","2141f50f":"code","73087aae":"code","bb46047a":"code","a3b2c089":"code","f0e504ca":"code","c08e5720":"code","69066ec1":"code","7235cb82":"code","3a2e16f8":"code","84cac869":"code","c8ad6330":"code","6b0f242e":"code","76a24129":"code","9014b497":"code","a064b650":"code","314cc4c6":"code","ed8dc4ee":"code","9da8c652":"code","89b04ff6":"code","5cb89d64":"code","813ba979":"code","37ced39c":"code","93bf5e4c":"code","b985e327":"code","747a10d0":"code","ffd1edcd":"markdown","9f37ff86":"markdown","aadd9ded":"markdown","b9a61063":"markdown","6be3c01d":"markdown","ea3099de":"markdown","29ee107c":"markdown","e9755f59":"markdown","48207af5":"markdown","c4534380":"markdown","7391c72a":"markdown","db88b076":"markdown","d339e8bd":"markdown","139c0269":"markdown","de3323c7":"markdown","fe2f6383":"markdown","da94b421":"markdown","ce817d0b":"markdown","f1c4a4c4":"markdown","b56f4cd5":"markdown","3e5a8a32":"markdown","2f129939":"markdown","8f7d557f":"markdown","876d0bc2":"markdown","41f9f281":"markdown","14a26f57":"markdown","ac366feb":"markdown","5e117146":"markdown"},"source":{"e20b915f":"!pip install pyspark","72570997":"from pyspark.sql import SparkSession\nspark = SparkSession.builder.appName('classification').getOrCreate()","19932eaa":"from itertools import chain\nfrom pyspark.sql.functions import count, mean, when, lit, create_map, regexp_extract","94b21ad8":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd","d7d13a19":"df1 = spark.read.csv('..\/input\/titanic\/train.csv', header=True, inferSchema=True)\ndf2 = spark.read.csv('..\/input\/titanic\/test.csv', header=True, inferSchema=True)","effead93":"df1.show(15)","bd37ae33":"print('Number of rows: \\t', df1.count())\nprint('Number of columns: \\t', len(df1.columns))","6c4e3606":"df1.printSchema()","5081c78a":"df1.printSchema()","f4517acc":"df1.select('Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare').summary().show()","ee973376":"pandas_df = df1.toPandas()\n\nplt.figure(figsize=(10,5))\nplt.title('Age distribution among all Pasengers')\nsns.distplot(pandas_df['Age']);","ed42d84b":"plt.figure(figsize=(5,5))\nplt.title('Pclass distribution among all Pasengers')\nsns.distplot(pandas_df['Pclass']);","a8ae10cc":"plt.figure(figsize=(10,5))\nplt.title('Fare distribution among all Pasengers')\nsns.distplot(pandas_df['Fare']);","e56783f9":"plt.figure(figsize=(10,5))\nplt.title('SibSp distribution among all Pasengers')\nsns.distplot(pandas_df['SibSp']);","d12678c4":"df1.groupBy('Survived').count().show()","eab35f47":"df1.groupBy('Survived').mean('Fare', 'Age', 'Parch', 'SibSp' ).show()","e759e2a2":"df1.groupBy('Survived').pivot('Sex').count().show()","43c62f76":"df1.groupBy('Survived').pivot('Pclass').count().show()","fb31473d":"df1.groupBy('Survived').pivot('Embarked').count().show()","f66ffdac":"for col in df1.columns:\n    print(col.ljust(20), df1.filter(df1[col].isNull()).count())","9a7418be":"df1 = df1.drop('PassengerID', 'Cabin', 'Ticket')","8d914b21":"df1.select('Age', 'Embarked').summary('mean', '50%', 'max').show()","7df5d0af":"df1 = df1.fillna({'Embarked': 'S'})","ee1204bb":"df1.show(5)","77aae220":"df1 = df1.withColumn('Title', regexp_extract(df1['Name'],'([A-Za-z]+)\\.', 1))\n\ndf1.groupBy('Title').agg(count('Age'), mean('Age')).sort('count(Age)').show()","d1cc6f1a":"df1.where(\" Title == 'Master' \").show()","8fa1c981":"title_dic = {'Mr':'Mr', 'Miss':'Miss', 'Mrs':'Mrs', 'Master':'Master', \\\n             'Mlle': 'Miss', 'Major': 'Mrs', 'Col': 'Mrs', 'Sir': 'Mrs',\\\n             'Don': 'Mrs', 'Mme': 'Miss', 'Jonkheer': 'Mrs', 'Lady': 'Mrs',\\\n             'Capt': 'Mrs', 'Countess': 'Mr', 'Ms': 'Miss', 'Dr':'Mrs', \\\n             'Rev':'Mrs'}\n\nmapping = create_map([lit(x) for x in chain(*title_dic.items())])\n\ndf1 = df1.withColumn('Title', mapping[df1['Title']])\ndf1.groupBy('Title').mean('Age').show()","62c567d2":"def age_imputer(df, title, age):\n    return df.withColumn('Age',when((df['Age'].isNull()) \\\n                            & (df['Title']==title), age).otherwise(df['Age']))","69037022":"dic = {'Mr':33.02, 'Mrs':35.98, 'Miss':21.86, 'Master':4.75}\n\nfor i,j in dic.items():\n    df1 = age_imputer(df1, i, j)","be2ad618":"df1.show(5)","97d90744":"df1 = df1.drop('Name', 'Title')","9d38ee9d":"df1 = df1.withColumn('FamilySize', df1['Parch'] + df1['SibSp']).\\\n            drop('Parch', 'SibSp')","f81fc8b5":"df1.show(15)","54a89717":"for col in df1.columns:\n    print(col.ljust(20), df1.filter(df1[col].isNull()).count())","c2a389ed":"from pyspark.ml.feature import StringIndexer, VectorAssembler\nfrom pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder","34bc7a15":"stringIndex = StringIndexer(inputCols=['Sex', 'Embarked'], outputCols=['SexNum', 'EmbNum'])\nstringIndex_model = stringIndex.fit(df1)\ndf1_ = stringIndex_model.transform(df1).drop('Sex', 'Embarked')\ndf1_.show(5)","754eedb4":"vec_asmbl = VectorAssembler(inputCols=df1_.columns[1:], outputCol='features')\ndf1_ = vec_asmbl.transform(df1_).select('features', 'Survived')","4e2ebc43":"df1_.show(5, truncate=False)","2141f50f":"train_df, test_df = df1_.randomSplit([0.9, 0.1])","73087aae":"train_df.show(5, truncate=False)","bb46047a":"evaluator = MulticlassClassificationEvaluator(labelCol='Survived', metricName='accuracy')\nmeans = []\nstd = []\nscore = 0","a3b2c089":"total = 0\nlista = []\ntmp = 0.1\nfor i in range(20):\n    lista.append(tmp + i*0.05)\nfor j in lista:\n    ridge = LogisticRegression(labelCol='Survived', \n                            maxIter=100, \n                            elasticNetParam=0, # Rigde\n                            regParam=j)\n\n    model = ridge.fit(train_df)\n    pred = model.transform(test_df)\n    tmp = evaluator.evaluate(pred)\n    total += tmp\n    print(tmp)\n    if tmp > score:\n        score = tmp\n        best_model = model\n        print('\u5f97\u5206\uff1a{} regParam\uff1a{}'.format(score,j))\n\ntotal \/= 20\nprint(total)\nmeans.append(total)","f0e504ca":"total = 0\nlista = []\ntmp = 0.1\nfor i in range(20):\n    lista.append(tmp + i*0.05)\nfor j in lista:\n    lasso = LogisticRegression(labelCol='Survived', \n                            maxIter=100, \n                            elasticNetParam=1, # Lasso\n                            regParam=j)\n\n    model = lasso.fit(train_df)\n    pred = model.transform(test_df)\n    tmp = evaluator.evaluate(pred)\n    total += tmp\n    print(tmp)\n    if tmp > score:\n        score = tmp\n        best_model = model\n        print('\u5f97\u5206\uff1a{} regParam\uff1a{}'.format(score,j))\n\ntotal \/= 20\nprint(total)\nmeans.append(total)","c08e5720":"total = 0\nfor i in range(50, 251, 50):\n    for j in range(1,6):\n        rf = RandomForestClassifier(labelCol='Survived', numTrees=i, maxDepth=j)\n\n        model = rf.fit(train_df)\n        pred = model.transform(test_df)\n        tmp = evaluator.evaluate(pred)\n        total += tmp\n        print(tmp)\n        if tmp > score:\n            score = tmp\n            best_model = model\n            print('\u5f97\u5206\uff1a{} numTrees\uff1a{} maxDepth\uff1a{}'.format(score,i,j))\n\ntotal \/= 25\nprint(total)\nmeans.append(total)","69066ec1":"#score = 0.87951","7235cb82":"total = 0\n\nfor j in range(1,6):\n    gb = GBTClassifier(labelCol='Survived', maxIter=100, maxDepth=j)\n\n    model = gb.fit(train_df)\n    pred = model.transform(test_df)\n    tmp = evaluator.evaluate(pred)\n    total += tmp\n    print(tmp)\n    if tmp > score:\n        score = tmp\n        best_model = model\n        print('\u5f97\u5206\uff1a{} maxDepth\uff1a{}'.format(score,j))\n\ntotal \/= 5\nprint(total)\nmeans.append(total)","3a2e16f8":"#means = [0.7271084337349394, 0.5831325301204818, 0.8457831325301204, 0.8626506024096386]","84cac869":"\nres = pd.DataFrame({\"CrossValMeans\":means,\n                    \"Algorithm\":[\"RidgeRegression\",\n                                \"LassoRegression\",\n                                \"RandomForestClassifier\",\n                                \"GBTClassifier\"]})\n\ng = sns.barplot(\"CrossValMeans\",\"Algorithm\",data = res, palette=\"Set3\",orient = \"h\")\ng.set_xlabel(\"Mean Accuracy\")\ng = g.set_title(\"Cross validation scores\")","c8ad6330":"df2.show(15)","6b0f242e":"for col in df2.columns:\n    print(col.ljust(20), df2.filter(df2[col].isNull()).count())","76a24129":"df1.select('Fare').summary('mean', '50%', 'max').show()","9014b497":"df2 = df2.fillna({'Embarked': 'S', 'Fare':14.45})\ndf2 = df2.withColumn('FamilySize', df2['Parch'] + df2['SibSp']).drop('Parch', 'SibSp')","a064b650":"df2 = df2.withColumn('Title', regexp_extract(df2['Name'], '([A-Za-z]+)\\.', 1))\ndf2 = df2.withColumn('Title', mapping[df2['Title']])\ndf2.groupBy('Title').agg(count('Age'), mean('Age')).sort('count(Age)').show()","314cc4c6":"dic = {'Mr':33.02, 'Mrs':35.98, 'Miss':21.86, 'Master':4.75}\n\nfor i,j in dic.items():\n    df2 = age_imputer(df2, i, j)\n\ndf2 = df2.drop('Cabin', 'Name', 'Ticket', 'Title')\ndf2.show(5)","ed8dc4ee":"for col in df2.columns:\n    print(col.ljust(20), df2.filter(df2[col].isNull()).count())","9da8c652":"stringIndex = StringIndexer(inputCols=['Sex', 'Embarked'], outputCols=['SexNum', 'EmbNum'])\nstringIndex_model = stringIndex.fit(df2)\n\ndf2_ = stringIndex_model.transform(df2).drop('Sex', 'Embarked')\ndf2_.show(5)","89b04ff6":"vec_asmbl = VectorAssembler(inputCols=df2_.columns[1:], outputCol='features')\n\ndf2_ = vec_asmbl.transform(df2_).select('features', 'PassengerId')\ndf2_.show(5, truncate=False)","5cb89d64":"pred_test = best_model.transform(df2_)\n\npredictions = pred_test.select('PassengerId', 'prediction')\npredictions = predictions.withColumn('Survived', predictions['prediction'].\\\n                                     cast('integer')).drop('prediction')\npredictions.show(15)","813ba979":"# Writing csv file in Spark \npredictions.coalesce(1).write.csv('submission_file.csv', header=True)","37ced39c":"# Reading the saved file from spark \nspark.read.csv('submission_file.csv', header=True).show(4)","93bf5e4c":"\npredictions.toPandas().to_csv('submission.csv', index=False)","b985e327":"pd.read_csv('submission.csv').head()","747a10d0":"best_model.write().save('classification.model')","ffd1edcd":"### 3\u3001\u4f7f\u7528pyspark\u63d0\u53d6\u6587\u672c\u6570\u636e\u7684\u7279\u5f81\uff1b \n\n\u628a Sex \u548c Embarked \u4ece string \u8f6c\u6362\u6210\u5411\u91cf pyspark \u4e2d\u7684 StringIndexer, VectorAssembler\u5c31\u53ef\u4ee5\u5b9e\u73b0\u5411\u91cf\u5316","9f37ff86":"\u5f00\u542f SparkSession \u5e76\u521b\u5efa spark \u5b9e\u4f8b","aadd9ded":"\u8fd9\u91cc\u6211\u9009\u62e9\u4e86\u56db\u4e2a\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff1a\n   1. \u5cad\u56de\u5f52(Ridge regression\uff09\n   2. \u5957\u7d22\u56de\u5f52\uff08Lasso regression\uff09\n   3. \u968f\u673a\u68ee\u6797\uff08Random forest\uff09\n   4. \u68af\u5ea6\u63d0\u5347\u51b3\u7b56\u6811\uff08GBT\uff09\n  \n  \u5e76\u4e14\u5c1d\u8bd5\u5404\u79cd\u53c2\u6570\u6765\u627e\u5230\u6700\u4f73\u6a21\u578b\uff0c\u6211\u5b9a\u4e49\u4e86best_model\u7531\u4e8e\u4fdd\u5b58\u6700\u4f73\u6a21\u578b","b9a61063":"\u5176\u5b9e\u5e74\u9f84\u7684\u5904\u7406\u5c31\u662f\u7528\u4ed6\u7684\u5934\u8854\uff08name\u4e2d\u7684title\uff0c\u6bd4\u5982\u4e0a\u8868\u4e2d\u7684 Mr \uff0cMiss\uff09\u7684\u5e73\u5747\u503c\u586b\u8865\u7f3a\u5931\u503c\n\u6240\u4ee5\u6211\u5148\u8ba1\u7b97\u5404\u4e2a title \u7684\u5e73\u5747\u503c","6be3c01d":"\u56e0\u4e3a Master \u7684\u5e73\u5747\u5e74\u9f84\u592a\u4f4e\uff0c\u6211\u6000\u7591\u6570\u636e\u53ef\u80fd\u51fa\u9519\uff0c\u6240\u4ee5\u628a Master \u7684\u6570\u636e\u90fd\u6253\u5370\u4e86\u51fa\u6765\uff0c\u8fd8\u662f\u5f88\u6b63\u5e38\u7684","ea3099de":"\u5404\u4e2a\u6307\u6807\u7684\u610f\u4e49\n\n1. PassengerId\uff1a \u4e58\u5ba2 ID\n2. Pclass\uff1a \u8231\u4f4d\u7b49\u7ea7 (1 = 1st, 2 = 2nd, 3 = 3rd)\n3. Name\uff1a \u4e58\u5ba2\u59d3\u540d\n4. Sex\uff1a \u6027\u522b\n5. Age\uff1a \u5e74\u9f84\n6. SibSp\uff1a \u5728\u8239\u4e0a\u7684\u5144\u5f1f\u59d0\u59b9\uff0f\u914d\u5076\u4e2a\u6570\n7. Parch\uff1a \u5728\u8239\u4e0a\u7684\u7236\u6bcd\uff0f\u5c0f\u5b69\u4e2a\u6570\n8. Ticket\uff1a \u8239\u7968\u4fe1\u606f\n9. Fare\uff1a \u7968\u4ef7\n10. Cabin\uff1a \u5ba2\u8231\n11. Embarked\uff1a \u767b\u8239\u6e2f\u53e3 (C = Cherbourg, Q = Queenstown, S = Southampton)","29ee107c":"### \u7c7b\u522b\u53d8\u91cf \u00a0'Sex', 'Pclass', \u2018Embarked\u2019  \u7968\u4ef7\uff0c\u5e74\u9f84\uff0c\u767b\u8239\u6e2f\u53e3","e9755f59":"Age \u7684\u7f3a\u5931\u503c\u5904\u7406\u5b8c\u4e4b\u540e\u628a'Name', 'Title'\u5217\u53bb\u6389\uff0c\u5e76\u4e14\u56e0\u4e3a SibSp \u4e0e Parch \u90fd\u662f\u63cf\u8ff0\u5bb6\u5ead\u6210\u5458\u7684\uff0c\u6240\u4ee5\u6211\u5c06\u8fd9\u4e24\u5217\u52a0\u548c\u5f62\u6210\u65b0\u5217 FamilySize","48207af5":"\u4fdd\u5b58\u7ed3\u679c\u4e0e\u6a21\u578b","c4534380":"\u5728test\u6570\u636e\u4e2d\uff0cEmbarked \u4e0e Fare \u90fd\u6709\u7f3a\u5931\u503c\uff0cEmbarked\u8fd9\u91cc\u91c7\u7528\u548c\u4e4b\u524d\u4e00\u6837\u7684\u5904\u7406\u7528\u51fa\u73b0\u6700\u591a\u7684\u2018S'\u4ee3\u66ff\uff0cFare\u5c31\u7b80\u5355\u7684\u7528\u4e2d\u4f4d\u6570\u4ee3\u66ff","7391c72a":"\u6807\u7b7e\u603b\u4f53\u60c5\u51b5","db88b076":"### ***1\u3001\u4f7f\u7528pyspark\u5bf9\u6570\u636e\u96c6\u6807\u7b7e\u5206\u5e03\u60c5\u51b5\u8fdb\u884c\u5206\u6790\uff1b***","d339e8bd":"### \u975e\u7c7b\u522b\u53d8\u91cf \u00a0'Fare', 'Age', 'Parch', 'SibSp' \u7968\u4ef7\uff0c\u5e74\u9f84\uff0c\u7236\u6bcd\u6570\u91cf\uff0c\u5b69\u5b50\u6570\u91cf","139c0269":"\u56e0\u4e3a\u4e4b\u540e\u5904\u7406 test \u6570\u636e\u8fd8\u9700\u8981\u76f8\u540c\u7684\u5904\u7406\uff0c\u6240\u4ee5\u8fd9\u91cc\u6211\u628a Age \u7f3a\u5931\u503c\u7684\u5904\u7406\u5305\u88c5\u6210\u51fd\u6570","de3323c7":"### \u8231\u4f4d\u7b49\u7ea7","fe2f6383":"### 5\u3001\u4f7f\u7528pyspark\u4e2d\u4efb\u610f\u4e00\u4e2a\u6709\u76d1\u7763\u5b66\u4e60\u7b97\u6cd5\u5728\u8bad\u7ec3\u96c6\u4e0a\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff1b\n    \n    \u524d\u671f\u7684\u51c6\u5907\u5de5\u4f5c\u90fd\u5df2\u5b8c\u6210\uff0c\u5f00\u59cb\u6784\u5efa\u6a21\u578b\u5e76\u8bad\u7ec3\n    \n###      7\u3001\uff08\u4e0e\u6b65\u9aa45\u4e00\u8d77\u5b9e\u73b0\uff09\u4f7f\u7528sklearn\u8ba1\u7b97\u5206\u7c7b\u51c6\u786e\u7387\uff08\u5206\u7c7b\u95ee\u9898\uff09\u6216\u8005R\u65b9\uff08\u56de\u5f52\u95ee\u9898\uff09\n    \n    \u56e0\u4e3a\u6700\u540e\u7684test\u6570\u636e\u6ca1\u6709grand_truth\uff0c\u6240\u4ee5\u6211\u4eec\u5c31\u7528train\u91cc\u5206\u5272\u51fa\u7684test_df\u6765\u8ba1\u7b97\u51c6\u786e\u7387\uff0c\u5e76\u4e14\u8ba1\u7b97\u4e0d\u540c\u7684\u53c2\u6570\u56db\u4e2a\u6a21\u578b\u7684\u51c6\u786e\u7387\u5e73\u5747\u503c\u5e76\u6bd4\u8f83\u753b\u56fe","da94b421":"### \u7968\u4ef7","ce817d0b":"spark \u8bfbcsv\u6587\u4ef6","f1c4a4c4":"\u6700\u540e\u68c0\u67e5\u662f\u5426\u8fd8\u6709\u7f3a\u5931\u503c","b56f4cd5":"### \u7279\u5f81\u63d0\u53d6 \uff0c\u6e05\u6d17\u6570\u636e\u4e2d\u7684\u7f3a\u5931\u503c\u3001\u9519\u8bef\u503c\u548c\u5f02\u5e38\u503c\n\n","3e5a8a32":"### ***2\u3001\u4f7f\u7528pyspark\u5bf9\u6570\u636e\u7279\u5f81\u5206\u5e03\u8fdb\u884c\u5206\u6790\uff0c\u5e76\u6e05\u6d17\u6570\u636e\u4e2d\u7684\u7f3a\u5931\u503c\u3001\u9519\u8bef\u503c\u548c\u5f02\u5e38\u503c\uff1b***","2f129939":"\u6700\u540e\u68c0\u67e5\u9884\u6d4b\u6d4b\u8bd5\u96c6\u6837\u672c\u662f\u5426\u8fd8\u6709\u7a7a\u503c","8f7d557f":"df2\uff08\u6d4b\u8bd5\u6570\u636e\uff09\u548cdf1\uff08\u8bad\u7ec3\u6570\u636e\uff09\u4e00\u6837\u7684\u9884\u5904\u7406","876d0bc2":"1. Cabin    \u56e0\u4e3a\u6709\u5f88\u9ad8\u6bd4\u4f8b\u7684\u7f3a\u5931\u503c\uff0c\u5e76\u4e14 carbine\uff08\u4ed3\u53f7\uff09 \u4e0e pclass \uff08\u7532\u677f\u7b49\u7ea7\uff09\u6709\u5f88\u5927\u7684\u5173\u8054\uff0c\u6240\u4ee5\u6211\u9009\u62e9\u53bb\u9664 carbin \u8fd8\u6709\u4e00\u4e9b\u5bf9\u9884\u6d4b\u95ee\u9898\u6ca1\u6709\u592a\u5927\u4f5c\u7528\u7684\u5c5e\u6027\u4e00\u5e76\u53bb\u9664 \uff08'PassengerID', 'Cabin', 'Name', 'Ticket'\uff0cname \u5148\u4e0d\u53bb\u9664\uff0cage \u7684\u5904\u7406\u9700\u8981\u4f7f\u7528\uff09\n2. Embarked \u7684\u7f3a\u5931\u503c\u6211\u9009\u62e9\u7528\u51fa\u73b0\u6b21\u6570\u6700\u591a\u7684 s\uff08Southampton\uff09\u6765\u586b\u5145\n3. Age      \u53ef\u4ee5\u7b80\u5355\u5730\u7528\u5e73\u5747\u503c\u6216\u8005\u4e2d\u4f4d\u6570\u6765\u4ee3\u66ff\uff0c\u4f46\u662f\u8fd9\u6837\u5bf9\u4e8e Age \u7684\u62df\u5408\u5e76\u4e0d\u597d\uff0c\u4e0b\u9762\u6211\u7528\u4e86\u522b\u7684\u65b9\u6cd5\u4e0e\u5e73\u5747\u503c\u7ed3\u5408\u6765\u5904\u7406 ","41f9f281":"\u56e0\u4e3a\u53ea\u6709\u4e0a\u8868\u6700\u540e\u7684\u56db\u4e2a title = [Master, Mrs, Miss, Mr] \u7684\u6570\u91cf\u5927\u4e8e10\uff0c\u5176\u4ed6\u7684title\u6570\u91cf\u592a\u5c11\uff0c\u53c2\u8003\u7684\u4ef7\u503c\u6bd4\u8f83\u4f4e\uff0c\u6240\u4ee5\u628a\u5176\u4ed6\u7684 title\u6839\u636e\u5e73\u5747\u503c\u7684\u5927\u5c0f \u6620\u5c04\u6210\u8fd9\u56db\u4e2a","14a26f57":"\u4e2a\u522b\u6807\u7b7e\u60c5\u51b5\u5206\u6790\u5e76\u8fdb\u884c\u53ef\u89c6\u5316\n## \u5e74\u9f84","ac366feb":"### 4\u3001\u4f7f\u7528pyspark.dataframe.randomSplit\u5c06\u6570\u636e\u96c6\u5206\u5272\u4e3a\u8bad\u7ec3\u96c6\u4e0e\u6d4b\u8bd5\u96c6\uff1b","5e117146":"### 6\u3001\u4f7f\u7528\u8bad\u7ec3\u597d\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u6d4b\u8bd5\u96c6\u6837\u672c\u7684\u5206\u7c7b\u6216\u56de\u5f52\u503c\uff1b \n    \u6700\u540e\u6211\u4eec\u7528\u627e\u5230\u7684\u6700\u4f73\u6a21\u578bbest_model\u8fdb\u884c\u9884\u6d4b"}}