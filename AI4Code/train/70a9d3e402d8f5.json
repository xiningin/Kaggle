{"cell_type":{"fbed1c80":"code","73389bb0":"code","66461fec":"code","dd1c9b6d":"code","eb71215c":"code","21c0a7a6":"code","d6701aa8":"code","b1033d8e":"code","b8a25ba0":"code","b94cc68e":"code","6041616d":"code","6baf7c07":"code","7bf5b17e":"code","1232a50d":"code","29dcf0c2":"code","981f91d9":"code","bb3ef0cf":"code","aefd1eed":"code","d265a6a3":"code","ca44df57":"code","209e73fc":"code","1685f95b":"code","83e71adf":"code","0897a000":"code","3b4a2279":"code","8f0897ad":"markdown","96ad41c9":"markdown"},"source":{"fbed1c80":"#importing libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","73389bb0":"#importing the dataset\nyelp = pd.read_csv('..\/input\/yelp.csv')\nyelp.head()","66461fec":"yelp.info()","dd1c9b6d":"yelp.describe()","eb71215c":"#creating new column to use length of text as a feature\nyelp[\"text length\"] = yelp[\"text\"].apply(len)\nyelp.head()","21c0a7a6":"g = sns.FacetGrid(yelp,col='stars')\ng.map(plt.hist,'text length')","d6701aa8":"sns.boxplot(y='text length', data=yelp, x='stars')","b1033d8e":"sns.countplot(yelp['stars'])","b8a25ba0":"stars = yelp.groupby('stars')['cool', 'useful', 'funny', 'text length'].mean()\nstars","b94cc68e":"stars_corr = stars.corr()\nstars_corr","6041616d":"sns.heatmap(stars_corr, cmap='coolwarm', annot=True)","6baf7c07":"#creating a dataframe yelp_class such that it contains only 1 star and 5 star reviews\nyelp_class = yelp[(yelp['stars'] == 1) | (yelp['stars'] == 5)]\nyelp_class.head()","7bf5b17e":"X = yelp_class['text']\ny = yelp_class['stars']","1232a50d":"#using bag of words model\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer()\nX_cv = cv.fit_transform(X)","29dcf0c2":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_cv, y, test_size=0.3, random_state=101)","981f91d9":"from sklearn.naive_bayes import MultinomialNB\nnb = MultinomialNB()\nnb.fit(X_train, y_train)","bb3ef0cf":"prediction_nb = nb.predict(X_test)","aefd1eed":"from sklearn.metrics import classification_report, confusion_matrix\nprint(classification_report(y_test, prediction_nb))\nprint(confusion_matrix(y_test, prediction_nb))","d265a6a3":"#using custom analyzer with bag of words model\nimport string\nfrom nltk.corpus import stopwords\ndef clean_data(mess):\n    \"\"\"\n    This function removes punctuation and stopwords \n    and returns a list of clean words.\n    \"\"\"\n    mess = [item for item in mess if item not in string.punctuation]\n    mess = \"\".join(mess)\n    clean = [word for word in mess.split() if word.lower() not in stopwords.words('english')]\n    return clean\ncv2 = CountVectorizer(analyzer = clean_data)\nX_cv2 = cv2.fit_transform(X)\nX_train, X_test, y_train, y_test = train_test_split(X_cv2, y, test_size=0.3, random_state=101)\nnb.fit(X_train, y_train)\nprediction_nb2 = nb.predict(X_test)\nprint(classification_report(y_test, prediction_nb2))\nprint(confusion_matrix(y_test, prediction_nb2))","ca44df57":"#using TFIDF in order to verify if there is a change in the algorithm performance\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.pipeline import Pipeline\n#creating a pipeline\npipeline = Pipeline([('cv', CountVectorizer()), ('tfidf', TfidfTransformer()), ('nb', MultinomialNB())])","209e73fc":"#splitting test and train data again\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n#fitting data to te pipeline\npipeline.fit(X_train, y_train)","1685f95b":"#making prediction\nprediction_pl = pipeline.predict(X_test)","83e71adf":"#evaluating performance\nprint(classification_report(y_test, prediction_pl))\nprint(confusion_matrix(y_test, prediction_pl))","0897a000":"#using logistic regression on bag of words\nX_train, X_test, y_train, y_test = train_test_split(X_cv, y, test_size=0.3, random_state=101)\nfrom sklearn.linear_model import LogisticRegression\nlogr = LogisticRegression()\nlogr.fit(X_train, y_train)\npredict_logr = logr.predict(X_test)\nprint(classification_report(y_test, predict_logr))\nprint(confusion_matrix(y_test, predict_logr))","3b4a2279":"#using random forests on bag of words\nX_train, X_test, y_train, y_test = train_test_split(X_cv, y, test_size=0.3, random_state=101)\nfrom sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier()\nrfc.fit(X_train, y_train)\npredict_rfc = rfc.predict(X_test)\nprint(classification_report(y_test, predict_rfc))\nprint(confusion_matrix(y_test, predict_rfc))","8f0897ad":"This project aims to classify Yelp reviews into 1 and 5 star categories based on the text column in the reviews.\n\nEach observation in this dataset is a review of a particular business by a particular user. The \"stars\" column is the number of stars (1 through 5) assigned by the reviewer to the business. (Higher stars is better.) In other words, it is the rating of the business by the person who wrote the review. The \"cool\" column is the number of \"cool\" votes this review received from other Yelp users.\n\nAll reviews start with 0 \"cool\" votes, and there is no limit to how many \"cool\" votes a review can receive. In other words, it is a rating of the review itself, not a rating of the business.\n\nThe \"useful\" and \"funny\" columns are similar to the \"cool\" column.","96ad41c9":"The bag of words model performed best so far with no custom analyzer."}}