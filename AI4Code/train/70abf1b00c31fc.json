{"cell_type":{"b1bd2427":"code","48a643a7":"code","5c3c4987":"code","c4bebbee":"code","79da9771":"code","0406e1d9":"code","b6ed6123":"code","1d64c8d5":"code","f0924042":"code","14a7907c":"code","bd638182":"code","bb01c37b":"code","4b2bac33":"code","6d58ee68":"code","413a47f6":"code","3f9e13ff":"code","38fb45e7":"code","2f75245c":"code","afba285e":"code","03747cd2":"code","317960ce":"code","2050ffbc":"markdown","94a6846e":"markdown","90287ad2":"markdown","a797fdba":"markdown","995c940f":"markdown","cf099f4d":"markdown","68f310c5":"markdown","369324ee":"markdown"},"source":{"b1bd2427":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","48a643a7":"filename = \"\/kaggle\/input\/data.csv\"\ndata = pd.read_csv(\"\/kaggle\/input\/breast-cancer-wisconsin-data\/data.csv\")\ndata.head()","5c3c4987":"data.info()","c4bebbee":"X=data.iloc[:,2:12].values","79da9771":"y=data.iloc[:,1]","0406e1d9":"X.shape","b6ed6123":"y.shape","1d64c8d5":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20)","f0924042":"from sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()","14a7907c":"X_train=scaler.fit_transform(X_train)","bd638182":"X_test=scaler.fit_transform(X_test)","bb01c37b":"np.sqrt(X_train.shape[0])","4b2bac33":"k=21","6d58ee68":"from sklearn.neighbors import KNeighborsClassifier\nknn=KNeighborsClassifier(n_neighbors=k)","413a47f6":"knn.fit(X_train,y_train)","3f9e13ff":"y_pred=knn.predict(X_test)","38fb45e7":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test,y_pred)","2f75245c":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_test,y_pred)","afba285e":"\nBy seeing the matrix it is clear that we have predicted 111 cases properly out of 114 in X_test","03747cd2":"accuracy=[]\nfor i in range(1,26):\n    knn=KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    accuracy.append(accuracy_score(y_test,knn.predict(X_test)))\nlen(accuracy)\nplt.plot(range(1,26),accuracy)","317960ce":"knn=KNeighborsClassifier(n_neighbors=19)\nknn.fit(X_train,y_train)\ny_pred=knn.predict(X_test)\naccuracy_score(y_test,y_pred)","2050ffbc":"# Training,predicting and calculating accuracy","94a6846e":"# **Splitting the data for Algorithm in test and train set**","90287ad2":"# Conclusion\nSo by taking the value of k=19 we are getting accuracy of 98%\n\nand taking the vallue of k=21 we are getting accuracy of 97%","a797fdba":"#  **Taking the value of k by determinig the sqrt of no of data in the training dataset**","995c940f":"# Predicting the Accuracy of our model","cf099f4d":"# Taking the value of k randomly from 1 to 25 by seeing the maximum point from the graph","68f310c5":"# Confusion Matrix","369324ee":"# Training the model"}}