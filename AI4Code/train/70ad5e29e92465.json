{"cell_type":{"90ef5f38":"code","3505a90f":"code","18d21ac3":"code","a858f1e7":"code","b5e21cae":"code","5acf2608":"code","be8c052c":"code","b0aa3086":"code","15ed5eeb":"code","2594b893":"code","44a295ed":"code","b36cce8d":"code","89fde7e2":"code","35cbcd1b":"code","bcc5e591":"code","04a2fa16":"code","13022314":"code","34a91412":"code","233d906c":"code","c0c39038":"code","886b2e07":"code","ba844daf":"code","8d5d93fd":"code","54c283f4":"code","3d86119a":"markdown","28141b8b":"markdown","32b15fa3":"markdown","0d1ea3c6":"markdown","75ed0964":"markdown","9b58a68a":"markdown","711d04f7":"markdown","0078e212":"markdown"},"source":{"90ef5f38":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3505a90f":"#For data processing\nimport pandas as pd\nimport numpy as np\nimport datetime as dt\n\n#For data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#For training and evaluating models \nfrom sklearn import metrics\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout","18d21ac3":"df = pd.read_csv('..\/input\/price-volume-data-for-all-us-stocks-etfs\/Stocks\/gs.us.txt')\ndf.head()","a858f1e7":"#Convert date to datetime value\ndf['Date'] = pd.to_datetime(df['Date'],format='%Y-%m-%d')","b5e21cae":"df.info()","5acf2608":"plt.rcParams['figure.figsize'] = (17,6)\nplt.grid(True)\nplt.plot(df['Date'],df['Close'], color='b')\nplt.yticks(np.arange(0,350, 50))\nplt.xlabel('Date')\nplt.ylabel('Close Price')\nplt.title('Close Prices for Goldman Sachs Shares over time')\nplt.show()","be8c052c":"#Set datetime as the index value\ndt = df.copy()\ndt = dt.set_index(dt['Date'])\ndt = dt.drop(columns=['Date','High','Low','Open','Volume','OpenInt'], axis=1)\ndt.head()","b0aa3086":"#Scale all of the data before splitting\nsc = MinMaxScaler(feature_range=(0,1))\ndt = sc.fit_transform(np.array(dt).reshape(-1,1))\nprint(df.shape)\nprint(dt.shape)","15ed5eeb":"#Visualization of the training-testing data split\ntest = df[int(len(df)*0.85):]\nax = df['Close'].plot(figsize = (17,6),color='blue', label='Training Data')\nax = test['Close'].plot(figsize = (17,6),color='red', label='Testing Data')\nax.set(xlabel='Dates', ylabel='Daily sales')\nax.legend(loc='lower right')\nplt.grid(True)\nplt.show()","2594b893":"#Split data into training and testing sets\ntotal_size = len(dt)\ntrain_size = int(total_size * 0.85)\ntest_size = total_size - train_size\ntrain_set, test_set = dt[0:train_size,:], dt[train_size:total_size, :1]\nprint(train_set.shape, test_set.shape)","44a295ed":"#convert arrays into matrix\ndef create_dataset(data, timestep):\n    dataX = []\n    dataY = []\n    numdata = len(data)-timestep-1\n    for i in range(numdata):\n        val_X = data[i:(i+timestep),0]\n        val_Y = data[i+timestep,0]\n        dataX.append(val_X)\n        dataY.append(val_Y)\n    X_arr = np.array(dataX)\n    y_arr = np.array(dataY)\n    return X_arr, y_arr","b36cce8d":"#reshape and split our train and test data into X and y\n#selecting same timestep for both train and test sets\ntimestep = 50\nX_train, y_train = create_dataset(train_set, timestep)\nX_test, y_test = create_dataset(test_set, timestep)\n\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","89fde7e2":"#Reshape data as 3D array which is required for LSTM\nX_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\nX_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","35cbcd1b":"#Initialize model\nmodel = Sequential()\n\n#Adding first LSTM layer and dropout regularisation\nmodel.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\nmodel.add(Dropout(0.15))\n\n#Adding second LSTM layer\nmodel.add(LSTM(units=50, return_sequences=True))\n\n#Adding third LSTM layer\nmodel.add(LSTM(units=50))\n\n#Output Layer\nmodel.add(Dense(units=1))","bcc5e591":"#Compile the model\nmodel.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'] )","04a2fa16":"#Get summary of the model details\nmodel.summary()","13022314":"history = model.fit(X_train, y_train, validation_split=0.20, epochs=50, verbose=1)","34a91412":"#Make predictions using the model\ntrain_predict = model.predict(X_train)\ntest_predict = model.predict(X_test)","233d906c":"#Transform data to original form (unscaled values)\ny_train_pred = sc.inverse_transform(train_predict)\ny_test_pred = sc.inverse_transform(test_predict)","c0c39038":"#Finding error produced by model\nmae = metrics.mean_absolute_error(y_test, y_test_pred)\nmse = metrics.mean_squared_error(y_test,y_test_pred)\nrmse = np.sqrt(mse)\n\nprint('Mean Absolute Error:', mae)\nprint('Mean Squared Error:', mse)\nprint('Root Mean Squared Error:', rmse)","886b2e07":"timestep = 50 #since we took the timestep as 50\n#adjust train predictions plot\ntrainPredPlot = np.empty_like(dt)\ntrainPredPlot[:,:] = np.nan\ntrainPredPlot[timestep:len(y_train_pred)+timestep,:] = y_train_pred\n#adjust test predictions plot\ntestPredPlot = np.empty_like(dt)\ntestPredPlot[:,:] = np.nan\ntestPredPlot[len(y_train_pred)+(2*timestep)+1:len(dt)-1,:] = y_test_pred","ba844daf":"#plot predictions\nplt.rcParams['figure.figsize'] = (17,6)\ndt_plot = sc.inverse_transform(dt)\nplt.plot(dt_plot,color='black', label='Actual Data')\nplt.plot(trainPredPlot,color='blue', label='Predict Train Data')\nplt.plot(testPredPlot,color='red', label='Predict Test Data')\nplt.legend()\nplt.grid(True)\nplt.show()","8d5d93fd":"#closer look at test predictions\nplt.rcParams['figure.figsize'] = (18,7)\ndt_plot = sc.inverse_transform(dt)\nplt.plot(dt_plot,color='black', label='Actual Data')\nplt.plot(testPredPlot,color='red', label='Predict Test Data')\nplt.xlim(4000,4700)\nplt.ylim(100,300)\nplt.legend()\nplt.grid(True)\nplt.show()","54c283f4":"# Plot training & validation accuracy values\nplt.rcParams['figure.figsize'] = (15, 6)\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","3d86119a":"## Split Data into Training and Testing Sets","28141b8b":"## Generate Data with TimeSteps\n","32b15fa3":"## Evaluate Model","0d1ea3c6":"## Construct LSTM Model","75ed0964":"## Scaling Data","9b58a68a":"## Import Libraries","711d04f7":"## Train LSTM Model","0078e212":"## Load Data\nWe'll be looking at Goldman Sachs (GS) stock price data"}}