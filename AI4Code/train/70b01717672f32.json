{"cell_type":{"3cdbaa7f":"code","1a99b8ff":"code","4be9bf64":"code","2c7db00e":"code","cb5504e0":"code","fe0a36cc":"code","15d3e9e5":"code","505cfd4e":"code","b5e7708a":"code","ccc5a82c":"code","60afdcae":"code","508d465e":"code","437bcb56":"code","576bc1c2":"code","108fc92f":"code","81563ef9":"code","bb9a594e":"code","62da2f90":"code","64788db8":"code","6d4d0138":"code","43e83f17":"code","229d550d":"code","d997ab86":"code","c95c0a82":"code","3521814e":"code","741089ee":"code","ef71a4c9":"code","03fe69ac":"code","2fd94be1":"code","790afa8e":"code","64c609c9":"code","1d445b00":"code","b54a5bfd":"code","0b4e4ac7":"code","188c55e2":"code","45e6c800":"code","d6202700":"code","46bc0d76":"code","75593dd7":"code","f4394746":"code","8eb7f48a":"code","885ead1b":"code","f1ba8899":"code","4a57515c":"code","b3af825f":"code","def10322":"code","4147d45c":"markdown","5732d61f":"markdown","46e130b1":"markdown","b4775660":"markdown","0e42f3fe":"markdown","47f90896":"markdown","d28545e2":"markdown","c9957a00":"markdown","2a294acc":"markdown","136ddf8b":"markdown","03531350":"markdown","ebfe27c4":"markdown","5cc7398b":"markdown","d3f8f905":"markdown","279219f1":"markdown","bc738061":"markdown","d39c99c4":"markdown","3bcd049e":"markdown"},"source":{"3cdbaa7f":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split,GridSearchCV\nfrom xgboost.sklearn import XGBRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_columns', None)","1a99b8ff":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4be9bf64":"train_data=pd.read_csv('\/kaggle\/input\/home-data-for-ml-course\/train.csv')\ntest_data=pd.read_csv('\/kaggle\/input\/home-data-for-ml-course\/test.csv')","2c7db00e":"train_data.head()","cb5504e0":"train_data.shape,test_data.shape","fe0a36cc":"for col in train_data.columns:\n  na= train_data[col].isnull().sum()\n  if na: print(col,na)","15d3e9e5":"for col in test_data.columns:\n  na= test_data[col].isnull().sum()\n  if na: print(col,na)","505cfd4e":"non_na_cols=['Alley','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','FireplaceQu','GarageType','GarageFinish',\n             'GarageQual','GarageCond','PoolQC','Fence','MiscFeature']","b5e7708a":"for col in non_na_cols:\n  train_data[col]=train_data[col].fillna('Absent')\n  test_data[col]=test_data[col].fillna('Absent')","ccc5a82c":"test_zeros=['BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','BsmtFullBath','BsmtHalfBath','GarageCars','GarageYrBlt','MasVnrArea','GarageArea']\nfor col in test_zeros:\n  test_data[col]=test_data[col].fillna(0)","60afdcae":"train_data['GarageYrBlt']=train_data['GarageYrBlt'].fillna(0)\ntrain_data['MasVnrArea']=train_data['MasVnrArea'].fillna(0)","508d465e":"correct_year=test_data[test_data['GarageYrBlt']==2207.0]['YearBuilt'].values[0]\ntest_data.loc[test_data['GarageYrBlt']==2207.0,'GarageYrBlt']=correct_year","437bcb56":"categorical_cols=train_data.select_dtypes(object).columns\nfor col in categorical_cols:\n  train_data[col]=train_data[col].fillna(train_data[col].mode()[0])\n  test_data[col]=test_data[col].fillna(test_data[col].mode()[0])","576bc1c2":"#Getting non null rows\nLotFrontage_train=train_data[train_data['LotFrontage'].notnull()].reset_index(drop=True)\nLotFrontage_train2=test_data[test_data['LotFrontage'].notnull()].reset_index(drop=True)","108fc92f":"#Combining data\nLotFrontage_train=LotFrontage_train.append(LotFrontage_train2).reset_index(drop=True)","81563ef9":"LotFrontage_train.shape","bb9a594e":"#X and Y for prediction\nLotFrontage_X=LotFrontage_train.drop(columns=['LotFrontage','SalePrice'])\nLotFrontage_y=LotFrontage_train['LotFrontage']","62da2f90":"#Correlation\nLotFrontage_features=(LotFrontage_X.corrwith(LotFrontage_y)).abs().sort_values(ascending=False)\nmodel_features=LotFrontage_features[LotFrontage_features > 0.25].index","64788db8":"model_features","6d4d0138":"LotFrontage_X=LotFrontage_train[model_features]\n\nX_train,X_test,y_train,y_test=train_test_split(LotFrontage_X,LotFrontage_y,test_size=0.2,random_state=2)","43e83f17":"#GridSearch was carried out to get these parameters(didn't include the code because it takes too long to run)\nparam={'max_depth': 10, 'max_features': 4, 'n_estimators': 90, 'warm_start': True}\n\nrf_lot=RandomForestRegressor(**param,random_state=21)\nrf_lot=rf_lot.fit(X_train,y_train)","229d550d":"y_pred=rf_lot.predict(X_test)\nr2_score(y_test,y_pred)","d997ab86":"#Getting the observation where Lotfrontage is null to predict those values\ntrain_LotFrontage=train_data[train_data['LotFrontage'].isnull()].reset_index(drop=True)\ntest_LotFrontage=test_data[test_data['LotFrontage'].isnull()].reset_index(drop=True)","c95c0a82":"#dropping null rows for Lotfrontage\ntrain_data=train_data.dropna(subset=['LotFrontage']).reset_index(drop=True)\ntest_data=test_data.dropna(subset=['LotFrontage']).reset_index(drop=True)","3521814e":"#Prediction rows\npredict_train_data=train_LotFrontage[model_features]\npredict_test_data=test_LotFrontage[model_features]","741089ee":"#Predicting using our trained model\npredicted_train_LotFrontage=rf_lot.predict(predict_train_data)\npredicted_test_LotFrontage=rf_lot.predict(predict_test_data)","ef71a4c9":"#Assigning values\ntrain_LotFrontage['LotFrontage']=predicted_train_LotFrontage\ntest_LotFrontage['LotFrontage']=predicted_test_LotFrontage","03fe69ac":"#Predicted Lotfrontage\ntest_LotFrontage.head()","2fd94be1":"#Adding those observtions back to the train set and test set\ntrain_data=train_data.append(train_LotFrontage).reset_index(drop=True).sort_values(by='Id').reset_index(drop=True)\n\ntest_data=test_data.append(test_LotFrontage).reset_index(drop=True).sort_values(by='Id').reset_index(drop=True)","790afa8e":"train_data.shape,test_data.shape","64c609c9":"combined_data=train_data.append(test_data).reset_index(drop=True)","1d445b00":"combined_data=pd.get_dummies(combined_data,drop_first=True)","b54a5bfd":"train_data=combined_data.iloc[:train_data.shape[0],:]","0b4e4ac7":"test_data=combined_data.iloc[test_data.shape[0]+1:,:].drop(columns='SalePrice')","188c55e2":"train_data.shape,test_data.shape","45e6c800":"del combined_data","d6202700":"X=train_data.drop(columns='SalePrice')\nY=train_data['SalePrice']\n\nx_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=2)","46bc0d76":"#GridSearch\nparam_grid={'n_estimators':[70,80,90,100,120,130,140,150],\n            'max_depth':[8,9,10,11,12,13],\n            'warm_start':[True,False]}\n\ngrid=GridSearchCV(RandomForestRegressor(),param_grid=param_grid,scoring='neg_mean_squared_error',n_jobs=-1,)\ngrid=grid.fit(x_train,y_train)","75593dd7":"grid.best_params_","f4394746":"y_pred=grid.predict(x_test)\nr2_score(y_test,y_pred)","8eb7f48a":"#GridSearch was carried out to get these parameters(didn't include the code because it takes too long to run)\nxgb=XGBRegressor(max_depth= 7, min_child_weight= 3, n_estimators= 100,subsample=0.8, colsample_bytree=0.8, nthread=4, seed=27)\nxgb=xgb.fit(x_train,y_train)","885ead1b":"y_pred=xgb.predict(x_test)\nr2_score(y_test,y_pred)","f1ba8899":"plt.figure(figsize=(10,8))\nax1=sns.distplot(y_test,hist=False,label=\"Actual\")\nax1=sns.distplot(y_pred,hist=False,label=\"Predicted\")\nplt.legend();","4a57515c":"#RandomForestRegressor model\nbest_model=RandomForestRegressor(max_depth= 12, n_estimators =100, warm_start= True)\n\nbest_model=best_model.fit(X,Y)\n\nprediction=best_model.predict(test_data)","b3af825f":"plt.figure(figsize=(10,8))\nax1=sns.distplot(prediction,hist=False,label=\"Predicted\",color='b')\nplt.legend();","def10322":"#Prediction\nsubmission=pd.DataFrame({'Id':test_data['Id'],'SalePrice':prediction})\n\nsubmission.to_csv('submission.csv',index=False)","4147d45c":" #### Looking at the description of the data, we can understand that not all NAs means missing data, For some columns NA has a meaning, example: In the Fence Column NA stands for No Fence and in Alley Column NA stands for No Alley","5732d61f":"### Combining the data for One Hot Encoding","46e130b1":"#### Correcting mistyped year for GarageYrBlt","b4775660":"#### For both trainset and testset, Lotfrontage has lots of NaNs values, we can fill it with the mean, but here we will predict the Lotfrontage for those observations.","0e42f3fe":"# Thank You ","47f90896":"### RandomForest has slighly better accuracy","d28545e2":"## Load Data\n","c9957a00":"#### The columns where NaNs are data itself, we will fill those NaNs with 'Absent' .","2a294acc":"### Splitting data back to train and test sets","136ddf8b":"#### These columns are related to the columns where NaNs are data itself, so we i will replace NaNs with 0","03531350":"# Training with the best model","ebfe27c4":"#### We will take the observation from train and test set then train a model and predict Lotfrontage for those missing observation in train and test set.","5cc7398b":"## Modeling for SalePrice Prediction","d3f8f905":"## 1. RandomForest","279219f1":"## 2. XGBoost","bc738061":"#### Now, the remaining categorical columns where NaNs means missing data, we will fill it with the most frequent value","d39c99c4":"## Looking for null values","3bcd049e":"## Submission"}}