{"cell_type":{"72e8119f":"code","13d9d9ab":"code","a6ffaa20":"code","d3523bf5":"code","abff7f9e":"code","16b5d1e2":"code","7703c6eb":"code","49d05db7":"code","66594814":"code","1ba5c16f":"code","35206f48":"code","5713ed7e":"code","391a78df":"code","5b95637c":"code","344e949e":"code","52b601f0":"code","f5d22499":"markdown","f8b0cc96":"markdown","1dd70a2b":"markdown","09e15ef2":"markdown","be74522b":"markdown"},"source":{"72e8119f":"# import all required libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","13d9d9ab":"# read the datset file\n\ndf = pd.read_csv('..\/input\/pima-daibetes-dataset\/diabetes.csv')\ndf.head()","a6ffaa20":"# check the number of row and column\n\ndf.shape\n\n# here we have 768 rows and 9 columns","d3523bf5":"# lets do preprocessing on data \n# check whether there is any categorical data or there is any null data ?\n# is yes then convert categorical into numeric by LabelEncoder or One hot encoding or StandardScaler or MinMaxScaler\n# and fill all null or empty value by its mean or mode value of that column","abff7f9e":"# check there is any null value?\ndf.isnull().sum()","16b5d1e2":"# so as we observe there is no null value in dataset ","7703c6eb":"# Lets check datatype of all columns","49d05db7":"df.info()","66594814":"# all are numeric data ","1ba5c16f":"# check the how age and pregnancies affect the Outcome i.e. daibetes\n\nsns.relplot(data=df,y='Age',x='Pregnancies',hue='Outcome',kind='line');\n\n# where we can observe that as the value in age and Pregnancies increase Daibetes is also increase\n# or we can say that it is equally affect","35206f48":"# Lets check at what blood pressure Outcome is positive\n\nsns.relplot(data=df,y='BloodPressure',x='Age',kind='line',hue='Outcome');\n\n# we observe that when the bloodpressure increase more than 60 the chances of being diabetes is more","5713ed7e":"# split the dependent and independent variable \n# where x contain all independent variable and y contain dependent or traget variable\n\nx = df.iloc[:,:-1]\ny = df.iloc[:,-1]\n\n# import all library\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\n# split the data into train and test\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.35, random_state=0)\n\n# create LogisticRegression object and fit the training data\nlr = LogisticRegression().fit(x_train, y_train)\n\n# check model accuracy\nprint(lr.score(x_test, y_test))\n\n# lets predoct the test data\ny_pred = lr.predict(x_test)\n\n# find the accuracy_score and classification report\nprint(classification_report(y_test, y_pred))\nprint(accuracy_score(y_test,y_pred))\n\ntn,fp,fn,tp= confusion_matrix(y_test,y_pred).ravel()\nprint(tp,fn)\nprint(fp,tn)","391a78df":"# lets check the skewn value of each column\n\nfrom scipy.stats import skew\nfor col in df:\n    print(col,':',skew(df[col]))\n    sns.distplot(df[col])\n    plt.show()","5b95637c":"# positive skew --> Pregnancies, Insulin, DiabetesPedigreeFunction, Age\n# negative skewness --> BloodPressure\nsns.heatmap(data=df.corr(),annot=True);\n# pregnancies, Age\n\ndf['Pregnancies'] = np.sqrt(df['Pregnancies'])\ndf.head()\n\n# When should we reduce Skewness?\n#     Reduce when both the condition is staisfied:\n#         1. Skew value either < -0.5 or > 0.5\n#         2. Column that has skewness has no correlation with target\n        \n#         When there is -ve skewness and the values of the column have -ve value then dont reduce skewness \n#         Because sqrt, cbrt or log of -ve value is nan","344e949e":"# after reducing skewness lets again find model accuracy and its score\n\nx = df.iloc[:,:-1]\ny = df.iloc[:,-1]\n\n# import all library\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\n# split the data into train and test\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.35, random_state=0)\n\n# create LogisticRegression object and fit the training data\nlr = LogisticRegression().fit(x_train, y_train)\n\n# check model accuracy\nprint(lr.score(x_test, y_test))\n\n# lets predoct the test data\ny_pred = lr.predict(x_test)\n\n# find the accuracy_score and classification report\nprint(classification_report(y_test, y_pred))\nprint(accuracy_score(y_test,y_pred))\n\ntn,fp,fn,tp= confusion_matrix(y_test,y_pred).ravel()\nprint(tp,fn)\nprint(fp,tn)","52b601f0":"# i am pick this data from dataset itself to cross verify model is giving true output or not\n# i am picking the data of patient who has daibetes\n# actual --> 1\n\nx1 = np.array([8,183,64,0,0,23.3,0.672,32]).reshape(1,8)\nlr.predict(x1)\n\n# predicted --> 1 gives perfact output","f5d22499":"# Lets create a LogisticRegression Model","f8b0cc96":"### it is giving bad output as comapre to previous (before reducing skewness) so we assume our model is best at value 0.79","1dd70a2b":"# Lets check our model works perfact or not by giving some mannual input","09e15ef2":"# but still we can try to make model good","be74522b":"# Visualization"}}