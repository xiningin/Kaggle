{"cell_type":{"168abf9e":"code","7d943180":"code","e478a4f9":"code","db811daa":"code","587920ef":"code","a749bcff":"code","cf1b6107":"code","3b9dc362":"code","c5e6e0eb":"code","4bda26e9":"code","776c4e09":"code","8fc1e165":"code","c5074608":"code","07907c0f":"code","e5a49df2":"code","8f4c2aea":"code","5b37a9b7":"code","806e4770":"code","1512aa0d":"code","be3a1203":"code","d815cc05":"code","b59b9f05":"code","62db3bd9":"code","086486cf":"code","6006fde4":"code","cfb3f9f7":"code","63e202a2":"code","d4e2de4c":"code","ffc8085e":"code","056d0c80":"markdown","36152b98":"markdown","98da2021":"markdown","c748c507":"markdown","da6c16e2":"markdown","b81702ab":"markdown","3330fe22":"markdown","34bc0eef":"markdown","0aa84d6f":"markdown","5885f1f7":"markdown","8cc299f8":"markdown","f81ade2b":"markdown","f1caa175":"markdown","066c93a2":"markdown","11e51772":"markdown","e529b775":"markdown"},"source":{"168abf9e":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Dense, Dropout, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\nimport numpy as np\nimport SimpleITK as sitk\nimport cv2 as cv\nimport matplotlib.pyplot as plt\nimport os\n\nfrom sklearn.model_selection import train_test_split\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.metrics import confusion_matrix","7d943180":"image_size = 256       #resize all images to 256*256\n\nlabels = ['NORMAL', 'PNEUMONIA']          #labels from the folders","e478a4f9":"def create_training_data(data_dir):              #creating the training data\n    \n    images = []\n    \n    for label in labels:\n        dir = os.path.join(data_dir,label)\n        class_num = labels.index(label)\n        \n        for image in os.listdir(dir):    #going through all the images in different folders and resizing them\n            \n            image_read = cv.imread(os.path.join(dir,image),cv.IMREAD_GRAYSCALE)\n            image_resized = cv.resize(image_read,(image_size,image_size))\n            images.append([image_resized,class_num])\n            \n    return np.array(images)","db811daa":"train = create_training_data('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/train')\ntest = create_training_data('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/test')\nval = create_training_data('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/val')","587920ef":"train.shape","a749bcff":"test.shape","cf1b6107":"val.shape","3b9dc362":"plt.imshow(train[1][0], cmap='gray')\nprint(labels[train[1][1]])   ","c5e6e0eb":"plt.imshow(train[5000][0], cmap='gray')\nprint(labels[train[5000][1]])","4bda26e9":"X = []\ny = []\n\nfor feature, label in train:\n    X.append(feature)          #appending all images\n    y.append(label)            #appending all labels\n\nfor feature, label in test:\n    X.append(feature)\n    y.append(label)","776c4e09":"X_new = np.array(X).reshape(-1, image_size, image_size, 1)\ny_new = np.array(y)\ny_new = np.expand_dims(y_new, axis =1)","8fc1e165":"X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size=0.2, random_state = 32)","c5074608":"X_train.shape","07907c0f":"y_train.shape","e5a49df2":"X_train = X_train \/ 255            # normalizing\nX_test = X_test \/ 255","8f4c2aea":"i = Input(X_train.shape[1:])                                        # Input Layer\n\na = Conv2D(32, (3,3), activation ='relu', padding = 'same')(i)      # Convolution\na = BatchNormalization()(a)                                         # Batch Normalization\na = Conv2D(32, (3,3), activation ='relu', padding = 'same')(a)\na = BatchNormalization()(a)\na = MaxPooling2D(2,2)(a)                                            # Max Pooling\n\na = Conv2D(64, (3,3), activation ='relu', padding = 'same')(a)\na = BatchNormalization()(a)\na = Conv2D(64, (3,3), activation ='relu', padding = 'same')(a)\na = BatchNormalization()(a)\na = MaxPooling2D(2,2)(a)\n\na = Conv2D(128, (3,3), activation ='relu', padding = 'same')(a)\na = BatchNormalization()(a)\na = Conv2D(128, (3,3), activation ='relu', padding = 'same')(a)\na = BatchNormalization()(a)\na = MaxPooling2D(2,2)(a)\n\na = Conv2D(256, (3,3), activation ='relu', padding = 'same')(a)\na = BatchNormalization()(a)\na = Conv2D(256, (3,3), activation ='relu', padding = 'same')(a)\na = BatchNormalization()(a)\na = MaxPooling2D(2,2)(a)\n\na = Flatten()(a)                                                      # Flatten\na = Dense(512, activation = 'relu')(a)                               # Fully Connected layer\na = Dropout(0.4)(a)\na = Dense(512, activation = 'relu')(a)\na = Dropout(0.3)(a)\na = Dense(512, activation = 'relu')(a)\na = Dropout(0.1)(a)\n\na = Dense(1, activation = 'sigmoid')(a)                               # Output Layer\n\nmodel = Model(i,a)","5b37a9b7":"model.compile(optimizer=Adam(lr = 0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\nmodel.summary()    ","806e4770":"batch_size = 4\n\ntrain_gen = ImageDataGenerator(rotation_range=10,\n                                   horizontal_flip = True,\n                                   width_shift_range=0.1,\n                                   height_shift_range=0.1,\n                                   rescale=1.,\n                                   zoom_range=0.2,\n                                   fill_mode='nearest',\n                                   cval=0)\n\ntrain_generator = train_gen.flow(X_train,y_train,batch_size)\nsteps_per_epoch = X_train.shape[0]\/\/batch_size","1512aa0d":"checkpoint = ModelCheckpoint('Pneumonia1.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n\n#to save the model - epochs with best validation loss","be3a1203":"r = model.fit(train_generator, validation_data=(X_test, y_test), steps_per_epoch = steps_per_epoch, epochs= 15,\n                       callbacks = [checkpoint])","d815cc05":"plt.plot(r.history['loss'],label='loss')\nplt.plot(r.history['val_loss'],label='val_loss')\nplt.legend()","b59b9f05":"new_model = tf.keras.models.load_model('Pneumonia1.h5')   #loading model to train further","62db3bd9":"new_model.compile(optimizer = Adam(lr = 0.00001), loss = 'binary_crossentropy', metrics = ['accuracy']) \n\ncheckpoint1 = ModelCheckpoint('Pneumonia2.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n\nbatch_size = 4\n\nr1 = new_model.fit(train_generator, validation_data=(X_test, y_test), steps_per_epoch = steps_per_epoch, epochs= 10,\n                       callbacks = [checkpoint1])","086486cf":"final_model = tf.keras.models.load_model('Pneumonia2.h5')","6006fde4":"pred = final_model.predict(X_test, batch_size = 8)\npred","cfb3f9f7":"pred_final = np.where(pred>0.5,1,0)\npred_final","63e202a2":"# Get the confusion matrix\nCM = confusion_matrix(y_test, pred_final)\n\nfig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(8,8))\nplt.title('Confusion matrix')\nplt.xticks(range(2), ['Normal','Pneumonia'], fontsize=10)\nplt.yticks(range(2), ['Normal','Pneumonia'], fontsize=10)\nplt.show()","d4e2de4c":"def perf_measure(y_test, pred_final):\n    TP = 0\n    FP = 0\n    TN = 0\n    FN = 0\n\n    for i in range(len(pred_final)): \n        if y_test[i]==pred_final[i]==1:\n           TP += 1\n        if y_test[i]==1 and y_test[i]!=pred_final[i]:\n           FP += 1\n        if y_test[i]==pred_final[i]==0:\n           TN += 1\n        if y_test[i]==0 and y_test[i]!=pred_final[i]:\n           FN += 1\n\n    return(TP, FP, TN, FN)","ffc8085e":"tp, fp, tn ,fn = perf_measure(y_test,pred_final)\n\nprecision = tp\/(tp+fp)\nrecall = tp\/(tp+fn)\nf_score = (2*precision*recall)\/(precision+recall)\n\nprint(\"Recall of the model is {:.2f}\".format(recall))\nprint(\"Precision of the model is {:.2f}\".format(precision))\nprint(\"F-Score is {:.2f}\".format(f_score))","056d0c80":"Compiling and viewing the model summary","36152b98":"If we go through the dataset, we see that there are a lot more Pneumonia images than Normal images. So we load the images from train and test set together, and split them using the train_test_split (https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.train_test_split.html).\n\nWe will use 20% of the images for testing and the remaining 80% for training the Neural network.\n\nThe Validation images (val) will not be shown to the neural network and will be used later to see on how the neural network performs on predicting images, that it has never seen before.","98da2021":"Predictions:","c748c507":"Loading model to try and improve further:","da6c16e2":"**Data Augmentation**\n\nData augmentation - https:\/\/www.tensorflow.org\/tutorials\/images\/data_augmentation","b81702ab":"**Creating the CNN Model:**\n\nConvolutional Neural Network (CNN) Detailed description- https:\/\/towardsdatascience.com\/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53","3330fe22":"Reshaping dimensions before feeding them to the neural network","34bc0eef":"Visualizing some images","0aa84d6f":"Loading the Images and Labels together","5885f1f7":"Confusion Matrix:","8cc299f8":"Loading Final Model for predictions:","f81ade2b":"Preprocessing the images","f1caa175":"**Chest X-Ray Pneumonia Classification**\n\nThe dataset is organized into 3 folders (train, test, val) and contains subfolders for each image category (Pneumonia\/Normal). There are 5,863 X-Ray images (JPEG) and 2 categories (Pneumonia\/Normal).\n\nChest X-ray images (anterior-posterior) were selected from retrospective cohorts of pediatric patients of one to five years old from Guangzhou Women and Children\u2019s Medical Center, Guangzhou. All chest X-ray imaging was performed as part of patients\u2019 routine clinical care.\n\nFor the analysis of chest x-ray images, all chest radiographs were initially screened for quality control by removing all low quality or unreadable scans. The diagnoses for the images were then graded by two expert physicians before being cleared for training the AI system. In order to account for any grading errors, the evaluation set was also checked by a third expert.\n\nDataset Link - https:\/\/www.kaggle.com\/paultimothymooney\/chest-xray-pneumonia\n\nAcknowledgements Data: https:\/\/data.mendeley.com\/datasets\/rscbjbr9sj\/2\n\nLicense: CC BY 4.0\n\nCitation: http:\/\/www.cell.com\/cell\/fulltext\/S0092-8674(18)30154-5\n\n**Importing the libraries**\n\n\nWe will design a Deep Learning Model to classify the images. We will be using Tensorflow 2.0 for the Pneumonia Classification.\n\nTensorflow Documentation -https:\/\/www.tensorflow.org\/tutorials\n\nKeras Documentation - https:\/\/keras.io\/","066c93a2":"Setting all predictions above 0.5 to 1:","11e51772":"Training the model:","e529b775":"Plotting the Losses"}}