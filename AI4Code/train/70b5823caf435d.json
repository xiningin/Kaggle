{"cell_type":{"02bba629":"code","bb8599a7":"code","150ec4b6":"code","9599230b":"code","6e57df1c":"code","1512731b":"code","fc5442ea":"code","40bb0c81":"code","23a2bad5":"code","b9fde1c7":"markdown","f224d844":"markdown","3dd7215b":"markdown","2d244bc7":"markdown","f318843d":"markdown","ccb032d7":"markdown","8ac38ce0":"markdown","b9eb29fa":"markdown","5aa84993":"markdown"},"source":{"02bba629":"#Importing necessary packages\n\nimport pandas as pd\nimport numpy as np\nimport scipy\nimport matplotlib.pyplot as plt","bb8599a7":"df0 = pd.read_csv(r'..\/input\/stocks\/stocks.csv',header = 0)\ndf1 = df0.set_index('Date')\ndf1.head()","150ec4b6":"plt.figure(figsize=(15, 6))\nfor i in range(df1.shape[1]):\n    plt.plot(df1.iloc[:,i], label=df1.columns.values[i])\nplt.legend(loc='upper left', fontsize=12)\nplt.ylabel('Price in $')\nplt.show()","9599230b":"df3 = df1.divide(df1.iloc[0] \/ 100)\n\nplt.figure(figsize=(15, 6))\nfor i in range(df3.shape[1]):\n    plt.plot(df3.iloc[:,i], label=df3.columns.values[i])\nplt.legend(loc='upper left', fontsize=12)\nplt.ylabel('Normalized prices')\nplt.show()\n\n","6e57df1c":"#Calculate daily changes in the stocks' value\ndf2 = df1.pct_change()\n#Remove nan values at the first row of df2. Create a new dataframe df\ndf=df2.iloc[1:len(df2.index),:]\n# Calculate annualized average return for each stock. Annualized average return = Daily average return * 252 business days.\nr = np.mean(df,axis=0)*252\n\n# Create a covariance matrix\ncovar = df.cov()","1512731b":"#Define frequently used functions.\n# r is each stock's return, w is the portion of each stock in our portfolio, and covar is the covariance matrix\n# Rate of return\ndef ret(r,w):\n    return r.dot(w)\n# Risk level - or volatility\ndef vol(w,covar):\n    return np.sqrt(np.dot(w,np.dot(w,covar)))\ndef sharpe (ret,vol):\n    return ret\/vol","fc5442ea":"# All weights, of course, must be between 0 and 1. Thus we set 0 and 1 as the boundaries.\nfrom scipy.optimize import Bounds\nbounds = Bounds(0, 1)\n\n# The second boundary is the sum of weights.\nfrom scipy.optimize import LinearConstraint\nlinear_constraint = LinearConstraint(np.ones((df2.shape[1],), dtype=int),1,1)\n\n# Find a portfolio with the minimum risk.\nfrom scipy.optimize import minimize\n#Create x0, the first guess at the values of each stock's weight.\nweights = np.ones(df2.shape[1])\nx0 = weights\/np.sum(weights)\n#Define a function to calculate volatility\nfun1 = lambda w: np.sqrt(np.dot(w,np.dot(w,covar)))\nres = minimize(fun1,x0,method='trust-constr',constraints = linear_constraint,bounds = bounds)\n\n#These are the weights of the stocks in the portfolio with the lowest level of risk possible.\nw_min = res.x\n\nnp.set_printoptions(suppress = True, precision=2)\nprint(w_min)\nprint('return: % .2f'% (ret(r,w_min)*100), 'risk: % .3f'% vol(w_min,covar))\n","40bb0c81":"#Define 1\/Sharpe_ratio\nfun2 = lambda w: np.sqrt(np.dot(w,np.dot(w,covar)))\/r.dot(w)\nres_sharpe = minimize(fun2,x0,method='trust-constr',constraints = linear_constraint,bounds = bounds)\n\n#These are the weights of the stocks in the portfolio with the highest Sharpe ratio.\nw_sharpe = res_sharpe.x\nprint(w_sharpe)\nprint('return: % .2f'% (ret(r,w_sharpe)*100), 'risk: % .3f'% vol(w_sharpe,covar))","23a2bad5":"w = w_min\nnum_ports = 100\ngap = (np.amax(r) - ret(r,w_min))\/num_ports\n\n\nall_weights = np.zeros((num_ports, len(df.columns)))\nall_weights[0],all_weights[1]=w_min,w_sharpe\nret_arr = np.zeros(num_ports)\nret_arr[0],ret_arr[1]=ret(r,w_min),ret(r,w_sharpe)\nvol_arr = np.zeros(num_ports)\nvol_arr[0],vol_arr[1]=vol(w_min,covar),vol(w_sharpe,covar)\n\nfor i in range(num_ports):\n    port_ret = ret(r,w) + i*gap\n    double_constraint = LinearConstraint([np.ones(df2.shape[1]),r],[1,port_ret],[1,port_ret])\n    \n    #Create x0: initial guesses for weights.\n    x0 = w_min\n    #Define a function for portfolio volatility.\n    fun = lambda w: np.sqrt(np.dot(w,np.dot(w,covar)))\n    a = minimize(fun,x0,method='trust-constr',constraints = double_constraint,bounds = bounds)\n    \n    all_weights[i,:]=a.x\n    ret_arr[i]=port_ret\n    vol_arr[i]=vol(a.x,covar)\n    \nsharpe_arr = ret_arr\/vol_arr  \n\nplt.figure(figsize=(20,10))\nplt.scatter(vol_arr, ret_arr, c=sharpe_arr, cmap='viridis')\nplt.colorbar(label='Sharpe Ratio')\nplt.xlabel('Volatility')\nplt.ylabel('Return')\nplt.show()","b9fde1c7":"Now, we should examine the data and take a look at how the price of each stock has evolved within the given timeframe.","f224d844":"The problem now is how to optimize our portfolio. Let's say we want the lowest level of risk possible. Thus, we should find a portfolio with minimum volatility. It is a straightforward minimization problem. However, there are certain boundaries we must conform to:\n\n1. All weights must be between 0 and 1 (as we cannot buy a negative amount of stocks, and we cannot form a portfolio with more than 100% of 1 stock).\n2. The sum of weights of all stock must be 1.\n\nNow, we should choose an algorithm to optimize our portfolio. *Generalized Reduced Gradient Method* is a feasible choice, but there are no libraries that have it. If you want to, you can read about this algorithm [here](http:\/\/www.numdam.org\/article\/RO_1974__8_3_73_0.pdf?fbclid=IwAR0K2U0P8bb-2mg69reNxVDG2Ao0MLrh-egsVg8gUP1LDmgMZTNfDh-IfIk), or try [this code](https:\/\/github.com\/ishank011\/grgdescent) I found on Github (I haven't). Otherwise, we can explore some of the available choices in [scipy.optimize](https:\/\/docs.scipy.org\/doc\/scipy\/reference\/tutorial\/optimize.html). What I chose is *Trust-Region Constrained Algorithm (method='trust-constr')* since it is suitable for multivariate scalar functions.\n\nI will explain what I do to implement this in the code.","3dd7215b":"We can see that the price of these stocks are very different from one another, making it difficult to compare them. Thus, we should \"normalize\" them to the same starting point.","2d244bc7":"Nice isn't it? If you're wondering why the frontier looks like a half parabola, it's because that's what it is! Please read [here](http:\/\/www.calculatinginvestor.com\/2011\/06\/07\/efficient-frontier-1\/) for more information.","f318843d":"What if we want to find a portfolio with the highest level of risk efficiency - that is, a portfolio that has the highest ratio of return\/risk (Sharpe ratio)?\n\nWe can just use the same algorithm, with the same constraints, but this time, let's optimize for the highest Sharpe ratio, which is a maximization problem. But as one of my favourite lecturers said\n> Maximization is for losers! We want to minimize!!\n\nThus, we will find the minimum of 1\/Sharpe_ratio instead.","ccb032d7":"Next, we should define some functions that we will use later in our calculation.\n\n* Rate of return is the annualized rate of return for the whole portfolio.\n* Volatility is the risk level, defined as the standard diviation of return.\n* Sharpe ratio is risk efficiency; it assesses the return of an investment compared to its risk.","8ac38ce0":"The rise and fall of the stocks in our portfolio generally do not conform to one another. That is, some stocks rise while others fall at the same time. This is very important for portfolio diversification where we should combine stocks with low covariance so that they mitigate each other's risks. \n\n**Calculating the Efficient Frontier**\n\nThere are 2 inputs we must compute before finding the Efficient Frontier for our stocks: annualized rate of return and covariance matrix.\n\nAnnualized rate of return is calculated by multiplying the daily percentage change for all of the stocks with the number of business days each year (252).","b9eb29fa":"Great! Now what if we want to draw the Efficient Frontier? Just to see what it looks like?\n\nEasy, since we already calculated the highest return for the lowest level of risk, we can start there and move up the return axis bit by bit - let's say 100 points. Then, we optimize (minimize) for the level of risk. Of course, we can still use the same algorithm, just with a little tweak.","5aa84993":"****Solving Markowitz's Efficient Frontier with constrainted optimization method in Python****\n\n**Introduction**\n\nIf you are a financial investor or intend to be one, you ought to know about Markowitz's Efficient Frontier. It is an old old theory invented in 1952 - a lot older than many of the stocks we will analyze, but it still rocks. After all, its author -  Harry Markowitz - received a Nobel prize for it.\n\n\nIn short, the theory posits that based on historical data, we can formulate optimum portfolios that have the highest return for a set level of risk - or the lowest level of risk at a set rate of return. These portfolios sit at the frontier of a scatter plot graph formed by possible portfolios and they represent the highest efficiency achievable, hence the name Efficient Frontier (the image is taken from [here](https:\/\/towardsdatascience.com\/python-markowitz-optimization-b5e1623060f5)). You can see a quick explanation [here](https:\/\/www.youtube.com\/watch?v=PiXrLGMZr1g) .\n\n![F\u00e1bio Neves - Plotting Markowitz Efficient Frontier with Python](https:\/\/miro.medium.com\/max\/1200\/1*RQrjkJQhgVLnpyo1lXbizA.png)\n\n\nThe best part is the mathematical theory to solve for an Efficient Frontier is dead simple. You just need to set the rate of return and find the minimum level of risk, or set a level of risk and find the maximum rate of return - a very straightforward optimization problem. Thus you may think that there ought to be countless existing tutorials to teach dummies how to do it. But no! As a dummy myself I spent a lot of time following tutorials on the internet. I followed countless Excel and Python tutorials but none worked for my dataset. Excel tutorials use *Generalized Reduced Gradient Method* as the optimizing algorithm, which should work well, but I don't know why it didn't. Python tutorials simply teach you how to randomize the weight of each stock in your portfolio tens of thousands of times, hoping that with so many random portfolios, some of them would form an efficient frontier. This is, of course, not founded in any mathematic principles and my dataset proved that it didn't even remotely work. If anything, using Excel is better. \n\nSo, I had to figure it out for myself. And I did. This code should work for as many stocks as you want to consider putting in your portfolio and it has a faster runtime than its randomly generated counterpart.\n\n**Data Exploration**\n\nIn this project, we will find the efficient frontier of a portfolio consisting of 9 different stocks. Of course, the code can be used for a much larger portfolio, but I was too lazy to gather more data.\n"}}