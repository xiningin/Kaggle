{"cell_type":{"99ac58ff":"code","50b71e97":"code","974f2131":"code","f826e71b":"code","d2940e00":"code","a10eb64a":"code","b7b751ed":"code","ad6932fd":"code","c236fcfd":"code","edf68f02":"code","822dadb2":"code","13250f93":"code","ce52185d":"code","56b3bbd1":"code","f65bd791":"code","e9ceb976":"code","eab92502":"code","ac8f46a9":"code","7e3140f9":"code","4e0625e0":"code","1fe616cf":"code","0db682c3":"code","7f6734db":"code","4feb0df5":"code","0749abb8":"code","f2088258":"code","bf467f55":"code","95a9686a":"code","a8048842":"code","6ec064fd":"code","410c2e3a":"code","476d36d7":"code","69743ea5":"code","b541f225":"code","05eca636":"code","9d91b93d":"code","fe5f1081":"code","ef3955e9":"code","7ff81f90":"code","4a44d693":"code","648a8886":"code","34fbb94a":"code","8a3f5a8b":"code","8f8b0342":"code","92f7c66e":"code","82c23e36":"code","bef02b2c":"code","636ec18d":"code","00c7b611":"code","12a3d593":"code","5d47d0fb":"code","970ce41a":"code","847a288d":"code","9ae6c184":"code","49971f27":"code","77cb1b5a":"code","b83f256a":"code","f832b14a":"code","0003951f":"code","e09076a7":"code","b12b8dad":"code","329df214":"code","660c2594":"code","c4327831":"code","77923f31":"code","539b6ec2":"code","c2c02f4d":"code","374f98e5":"code","ab948441":"code","41cf2c6a":"code","1d7342f1":"code","3513df29":"code","43395a6c":"code","98c01482":"markdown","109aee8a":"markdown","2e4ee303":"markdown","5c33353c":"markdown","8d87ec6d":"markdown","4f1517b8":"markdown","b9c72b61":"markdown","a2c18e58":"markdown","b594dd2a":"markdown","424db1d8":"markdown","535ea826":"markdown","d324bc98":"markdown","3280d0c5":"markdown","0fe16dd3":"markdown","72e5f4b8":"markdown","111327a2":"markdown","c3956e4e":"markdown","328b60bd":"markdown","ea6a9d1b":"markdown","e64fcd0f":"markdown","4ae23f76":"markdown","8d7aa1f0":"markdown","1243bca0":"markdown","507e5751":"markdown","0f9217c6":"markdown","d4e1d2d7":"markdown","22969961":"markdown"},"source":{"99ac58ff":"import pandas as pd\nimport pandas as pd\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as plt\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')","50b71e97":"# Loading the data\nmain_df = pd.read_csv('..\/input\/customer-personality-analysis\/marketing_campaign.csv', sep='\\t')\ndf = main_df.copy()\ndf.head(10)","974f2131":"#shape of the dataset\ndf.shape","f826e71b":"# basic information of dataset\ndf.info()","d2940e00":"# Finding the number of unique values present in each column\ndf.nunique()","a10eb64a":"# Checking if ny NaN is present in column or not\ndf.isna().any()","b7b751ed":"# Checking number of null values\ndf.isnull().sum()","ad6932fd":"# Checking for null value using heatmap\nsns.heatmap(df.isnull())","c236fcfd":"# Dropping the column beacause they will not contribute in model building\ndf = df.drop(columns=[\"Z_CostContact\", \"Z_Revenue\"], axis=1)\ndf.head(10)","edf68f02":"# Complain: 1 if customer complained in the last 2 years, 0 otherwise\nlabel_complain = [\"No Complain\",\"Complain\"]\n\ncount_complain = pd.value_counts(df['Complain'], sort=True)\ncount_complain.plot(kind='bar', rot=0,color=['Green','Red'])\nplt.title(\"Complain class Distribution\")\nplt.xticks(range(2),label_complain)\nplt.xlabel(\"Complain\")\nplt.ylabel(\"Count of Complain\")","822dadb2":"df['Complain'].value_counts()\n# 1 if customer complained in the last 2 years, 0 otherwise","13250f93":"# Let's checl about response\n\n# Response: 1 if customer accepted the offer in the last 2 campaign, 0 otherwise\nlabel_response = [\"Denied\",\"Accepted\"]\n\ncount_response = pd.value_counts(df['Response'], sort=True)\ncount_response.plot(kind='bar', rot=0,color=['Green','Red'])\nplt.title(\"Reponse class Distribution\")\nplt.xticks(range(2),label_response)\nplt.xlabel(\"Respons\")\nplt.ylabel(\"Count of Response\")","ce52185d":"df['Response'].value_counts()","56b3bbd1":"#Campagin 1\n\nlabels_c1 = [\"Denied\", \"Accepted\"]\n\ncount_c1 = pd.value_counts(df['AcceptedCmp1'], sort=True)\ncount_c1.plot(kind='bar', rot=0,color=['Green','Red'])\nplt.title(\"AcceptedCmp1 class Distribution\")\nplt.xticks(range(2),labels_c1)\nplt.xlabel(\"Campaign 1\")\nplt.ylabel(\"Count of Campagin1\")","f65bd791":"df['AcceptedCmp1'].value_counts()","e9ceb976":"#Campagin 2\n\nlabels_c2 = [\"Denied\", \"Accepted\"]\n\ncount_c2 = pd.value_counts(df['AcceptedCmp2'], sort=True)\ncount_c2.plot(kind='bar', rot=0,color=['Green','Red'])\nplt.title(\"AcceptedCmp2 class Distribution\")\nplt.xticks(range(2),labels_c2)\nplt.xlabel(\"Campaign 2\")\nplt.ylabel(\"Count of Campagin2\")","eab92502":"df[\"AcceptedCmp2\"].value_counts()","ac8f46a9":"#Campagin 3\n\nlabels_c3 = [\"Denied\", \"Accepted\"]\n\ncount_c3 = pd.value_counts(df['AcceptedCmp3'], sort=True)\ncount_c3.plot(kind='bar', rot=0,color=['Green','Red'])\nplt.title(\"AcceptedCmp3 class Distribution\")\nplt.xticks(range(2),labels_c3)\nplt.xlabel(\"Campaign 3\")\nplt.ylabel(\"Count of Campagin3\")","7e3140f9":"df[\"AcceptedCmp3\"].value_counts()","4e0625e0":"#Campagin 4\n\nlabels_c4 = [\"Denied\", \"Accepted\"]\n\ncount_c4 = pd.value_counts(df['AcceptedCmp4'], sort=True)\ncount_c4.plot(kind='bar', rot=0,color=['Green','Red'])\nplt.title(\"AcceptedCmp4 class Distribution\")\nplt.xticks(range(2),labels_c4)\nplt.xlabel(\"Campaign 4\")\nplt.ylabel(\"Count of Campagin4\")","1fe616cf":"df[\"AcceptedCmp4\"].value_counts()","0db682c3":"#Finding the correlation between the feature column\n\nplt.figure(figsize=(20,18))\nsns.heatmap(df.corr(), annot=True)\nplt.show()","7f6734db":"# Filling the missing value in the income by mean\ndf['Income'] = df['Income'].fillna(df['Income'].mean())\ndf.isnull().sum()","4feb0df5":"df.head()","0749abb8":"#Checking the number of unique categories present in the \"Marital_Status\"\n\ndf['Marital_Status'].value_counts()","f2088258":"df['Marital_Status'] = df['Marital_Status'].replace(['Married', 'Together'],'relationship')\ndf['Marital_Status'] = df['Marital_Status'].replace(['Divorced', 'Widow', 'Alone', 'YOLO', 'Absurd','single'],'Single')","bf467f55":"df['Marital_Status'].value_counts()","95a9686a":"# Relationship vs Single\n\nlabels_status = [\"Relationship\", \"Single\"]\n\ncount_status = pd.value_counts(df['Marital_Status'], sort=True)\ncount_c4.plot(kind='bar', rot=0,color=['Orange','Blue'])\nplt.title(\"Marital Status\")\nplt.xticks(range(2),labels_status)\nplt.xlabel(\"Marital Status\")\nplt.ylabel(\"Count of Marital Status\")","a8048842":"# Combining different dataframes into a single column to reduce the number of dimension","6ec064fd":"df['Kids'] = df['Kidhome'] + df['Teenhome']\ndf['Expenses'] = df['MntWines'] + df['MntFruits'] + df['MntMeatProducts'] + df['MntFishProducts'] + df['MntSweetProducts'] + df['MntGoldProds']\ndf['TotalAcceptedCmp'] = df['AcceptedCmp1'] + df['AcceptedCmp2'] + df['AcceptedCmp3'] + df['AcceptedCmp4'] + df['AcceptedCmp5'] + df['Response']\ndf['NumTotalPurchases'] = df['NumWebPurchases'] + df['NumCatalogPurchases'] + df['NumStorePurchases'] + df['NumDealsPurchases']","410c2e3a":"#saving the data for tableau\n# df.to_csv('data_visuals.csv')","476d36d7":"# Deleting some column to reduce dimension and complexity of model\n\ncol_del = [\"AcceptedCmp1\" , \"AcceptedCmp2\", \"AcceptedCmp3\" , \"AcceptedCmp4\",\"AcceptedCmp5\", \"Response\",\"NumWebVisitsMonth\", \"NumWebPurchases\",\"NumCatalogPurchases\",\"NumStorePurchases\",\"NumDealsPurchases\" , \"Kidhome\", \"Teenhome\",\"MntWines\", \"MntFruits\", \"MntMeatProducts\", \"MntFishProducts\", \"MntSweetProducts\", \"MntGoldProds\"]\ndf=df.drop(columns=col_del,axis=1)\ndf.head()","69743ea5":"# Adding 'Age' column\n\ndf['Age'] = 2015 - df['Year_Birth']","b541f225":"df['Education'].value_counts()","05eca636":"# Changing category into UG and PG only\n\ndf['Education'] = df['Education'].replace(['PhD','2n Cycle','Graduation', 'Master'],'PG')  \ndf['Education'] = df['Education'].replace(['Basic'], 'UG')","9d91b93d":"# Number of days a customer was engaged with company\n\n# Changing bt_customer into timestamp format\ndf['Dt_Customer'] = pd.to_datetime(df.Dt_Customer)\ndf['first_day'] = '01-01-2015'\ndf['first_day'] = pd.to_datetime(df.first_day)\ndf['day_engaged'] = (df['first_day'] - df['Dt_Customer']).dt.days","fe5f1081":"df=df.drop(columns=[\"ID\", \"Dt_Customer\", \"first_day\", \"Year_Birth\", \"Dt_Customer\", \"Recency\", \"Complain\"],axis=1)\ndf.shape","ef3955e9":"df.head()","7ff81f90":"fig = px.bar(df, x='Marital_Status', y='Expenses', color='Education')\nfig.show()","4a44d693":"fig = px.bar(df, x='Marital_Status', y='Expenses', color=\"Marital_Status\")\nfig.show()","648a8886":"# Less number of single customer\nfig = px.histogram (df, x = \"Expenses\",  facet_row = \"Marital_Status\",  template = 'plotly_dark')\nfig.show ()","34fbb94a":"fig = px.histogram (df, x = \"Expenses\",  facet_row = \"Education\",  template = 'plotly_dark')\nfig.show ()","8a3f5a8b":"fig = px.histogram (df, x = \"NumTotalPurchases\",  facet_row = \"Education\",  template = 'plotly_dark')\nfig.show ()","8f8b0342":"fig = px.histogram (df, x = \"Age\",  facet_row = \"Marital_Status\",  template = 'plotly_dark')\nfig.show ()","92f7c66e":"fig = px.histogram (df, x = \"Income\",  facet_row = \"Marital_Status\",  template = 'plotly_dark')\nfig.show ()","82c23e36":"fig =  px.pie (df, names = \"Marital_Status\", hole = 0.4, template = \"gridon\")\nfig.show ()","bef02b2c":"fig =  px.pie (df, names = \"Education\", hole = 0.4, template = \"plotly_dark\")\nfig.show ()","636ec18d":"sns.barplot(x=df['Expenses'], y=df['Education'])\nplt.title('Total expense based on the education level')","00c7b611":"sns.barplot(x=df['Income'], y=df['Education'])\nplt.title('Total Income based on the Education Level')","12a3d593":"df.describe()","5d47d0fb":"sns.heatmap(df.corr(),annot=True)","970ce41a":"obj = []\nfor i in df.columns:\n    if(df[i].dtypes==\"object\"):\n        obj.append(i)\n\nprint(obj)","847a288d":"# Label Encoding\nfrom sklearn.preprocessing import LabelEncoder","9ae6c184":"df['Marital_Status'].value_counts()","49971f27":"lbl_encode = LabelEncoder()\nfor i in obj:\n    df[i] = df[[i]].apply(lbl_encode.fit_transform)","77cb1b5a":"df1 = df.copy()\ndf1.head()","b83f256a":"from sklearn.preprocessing import StandardScaler","f832b14a":"scaled_features = StandardScaler().fit_transform(df1.values)\nscaled_features_df = pd.DataFrame(scaled_features, index=df1.index, columns=df1.columns)","0003951f":"scaled_features_df.head()","e09076a7":"# scaled_features_df.describe()","b12b8dad":"from sklearn.cluster import KMeans","329df214":"wcss = []\nfor i in range(1,11):\n    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)\n    kmeans.fit(scaled_features_df)\n    wcss.append(kmeans.inertia_)\n    # inetia_: Sum of squared distances of samples to their closest cluster center, weighted by the sample weights if provided.\nplt.figure(figsize=(16,8))\nplt.plot(range(1,11), wcss, 'bx-')\nplt.title('The Elbow Maethod')\nplt.xlabel('Number of Clusters')\nplt.ylabel('WCSS')\nplt.show()","660c2594":"from sklearn.metrics import silhouette_score","c4327831":"silhouette_scores = []\nfor i in range(2,10):\n    m1 = KMeans(n_clusters=i, random_state=42)\n    c = m1.fit_predict(scaled_features_df)\n    silhouette_scores.append(silhouette_score(scaled_features_df, m1.fit_predict(scaled_features_df)))\n    \nplt.bar(range(2,10), silhouette_scores)\nplt.xlabel('Number of clusters', fontsize=20)\nplt.ylabel('S(i)', fontsize=20)\nplt.show()","77923f31":"# Now we are using Silhouette score to measure the value of K\nsilhouette_scores","539b6ec2":"# Getting the maximum value of silhouette score and adding 2 in index beacure index starts from 2\n\nsc = max(silhouette_scores)\nnum_of_clusters = silhouette_scores.index(sc)+2\nprint(\"Number of Cluster Required is: \", num_of_clusters)","c2c02f4d":"# Training a prediction using K-Means Algorithm.\n\nkmeans = KMeans(n_clusters = num_of_clusters, random_state=42).fit(scaled_features_df)\npred = kmeans.predict(scaled_features_df)","374f98e5":"pred","ab948441":"# Appending those cluster value into the main dataframe (without standardization)\ndf['cluster'] = pred + 1","41cf2c6a":"df.head()","1d7342f1":"# saving clustering csv for Tableau\n# df.to_csv('data_visuals2.csv')","3513df29":"pl = sns.countplot(x=df[\"cluster\"])\npl.set_title(\"Distribution Of The Clusters\")\nplt.show()","43395a6c":"sns.set(rc={'axes.facecolor':'black', 'figure.facecolor':'black', 'axes.grid' : False, 'font.family': 'Ubuntu'})\n\nfor i in df:\n    diag = sns.FacetGrid(df, col = \"cluster\", hue = \"cluster\", palette = \"Set1\")\n    diag.map(plt.hist, i, bins=6, ec=\"k\") \n    diag.set_xticklabels(rotation=25, color = 'white')\n    diag.set_yticklabels(color = 'white')\n    diag.set_xlabels(size=16, color = 'white')\n    diag.set_titles(size=16, color = '#f01132', fontweight=\"bold\")\n    diag.fig.set_figheight(6)","98c01482":"-  From above image we can say that there are not much complains by customers.","109aee8a":"### As we can see here that weightage of customer are more in cluster 1 as compare to other.","2e4ee303":"- AcceptedCmp1: 1 if customer accepted the offer in the 1st campaign, 0 otherwise\n- AcceptedCmp2: 1 if customer accepted the offer in the 2nd campaign, 0 otherwise\n- AcceptedCmp3: 1 if customer accepted the offer in the 3rd campaign, 0 otherwise\n- AcceptedCmp4: 1 if customer accepted the offer in the 4th campaign, 0 otherwise\n- AcceptedCmp5: 1 if customer accepted the offer in the 5th campaign, 0 otherwise\n- Response: 1 if customer accepted the offer in the last campaign, 0 otherwise","5c33353c":"## Imporintg important Libraries","8d87ec6d":"- More than 97% customer are from PG background. and Approx. 2% are from UG. ","4f1517b8":"# Customer Personality Analysis ","b9c72b61":"## Standardization","a2c18e58":"## Data Preprocssing ","b594dd2a":"-  No null value in the dataset","424db1d8":"- 35% of the customer are single whereas more 64% are in relationship.","535ea826":"- Silhouette Score","d324bc98":"- Let's figure out the number of complains complained by customer and number of responses are positive or negative in last 2 years.","3280d0c5":"## Model Building","0fe16dd3":"- Here we have only 3 object type datatype and rest are numerical","72e5f4b8":"# Report\n\n**Based on above information we can divide customer into 3 parts**:- \n1. **Highly Active Customer**: These customers beloing to cluster one.\n2. **Moderately Active Customer** :- These customers belong to cluster two.\n3. **Least Active Customer** :- These customers belong to cluster third.\n\n**Characteristics of Highly Active Customer**\n\n- **In terms of Education**\n   - Highly Active Customer are from PG background\n   \n- **In terms of Marital_status**\n   - Number of people in relationship are approx. two times of single people\n\n- **In terms of Income**\n   - Income of Highly active customer are little less as compare to Moderately active customer.\n   \n- **In terms of Kids**\n   - Highly active customer have more number of children as compare to other customer ( avg. of 1 child ).\n   \n- **In terms of Expenses**\n  - Expenses of Highly Active customer are less as compare to moderate.\n  - These customer spent avg. of approx. 100-200 unit money.\n  \n- **In terms of Age**\n  - Age of these customer are between 25 to 75.\n  - Maximum customer age are between 40 to 50.\n  \n- **In terms of day_engaged**\n  - Highly Active customer are more loyal as they engaged with company for longer period of time.\n\n\n**Characteristics of Moderately Active Customer**\n\n- **In terms of Education**\n  - Moderately Active Customer are also from PG backgroud\n  \n- **In terms of Marital_status**\n  - Number of people in relationship are slightly more as compare to single people.\n  \n- **In terms of Income**\n  - Income of Moderately active customer are higher as compare to other customer.\n  \n- **In terms of Kids**\n  - Moderately active customer have less number of childern as compare to highly active customer ( Max. customer has no child ).\n  \n- **In terms of Expenses**\n  - Expenses of Moderately Active customer are more as compare to Active.\n  - These customer spent avg. of approx. 500-2000 unit money.\n  \n- **In terms of Age**\n  - Age of these customer are between 25 to 75.\n  - Maximum customer age are between 35 to 60.\n  \n- **In terms of day_engaged**\n  - Moderately Active customer are slightly less engaged with company as      compare to Highly Active Customer.","111327a2":"As it is not very clear from the elbow method that which value of K to choose","c3956e4e":"- Income column have some missing value in it so we will need to fill it by either maean or median.","328b60bd":"- From the above figures we clearly see that most of offers has been denied by customers in all campagins.\n- But Campaign 4 had better amount of acceptance.\n- Campaign 4 > Campaign 3 > Campaign 1 > Campagin 2: comparison of acceptance in campaigns.","ea6a9d1b":"## Data Visualization","e64fcd0f":"- No two columns are too much correlated with each other so we can't drop any columns","4ae23f76":"- In the above cell we are grouping 'Married', 'Together' as \"relationship\"\n- Whereas 'Divorced', 'Widow', 'Alone', 'YOLO', 'Absurd' as \"Single\"","8d7aa1f0":"## Check out Data Science Real World Proejct on my github:\n\nhttps:\/\/github.com\/karan842\/Data-Science-Projects","1243bca0":"# Exploratory Data Analysis","507e5751":"- In above cell \"Z_CostContact\" and \"Z_Revenue\" have some value in all the rows that's why they are not going to contribute anything in the model building. So we can drop them","0f9217c6":"- This graph shows that last the offer has been denied by most of the customers","d4e1d2d7":"*Let's check out all campaign offers*","22969961":"## Elbow Method"}}