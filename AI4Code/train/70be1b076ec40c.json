{"cell_type":{"cbf68e58":"code","2aab263b":"code","13ef8e40":"code","10bab830":"code","2bca6ea7":"code","b0b03bfa":"code","bdb74f18":"code","4cb477db":"code","5c44a881":"code","987ecd75":"code","4daee54c":"code","9f8cfcf2":"code","05cd4102":"code","721bc844":"code","f2ca2ae2":"code","7a2dd8b3":"code","b18a418f":"code","79d6ece1":"code","8434f2c2":"code","71a0ea96":"code","5fb24ae2":"code","64e1e535":"code","0f9f4617":"code","a5bf304b":"code","8339a981":"code","8e72618b":"code","47bf2a7b":"code","774a275d":"code","0889276f":"code","718ed621":"code","82ba0be9":"code","59ce2f95":"code","09bd8fcf":"code","6ee7f4c1":"code","63f59a68":"code","f15bf8db":"code","ff4ab327":"code","97cc2917":"code","7d4469c9":"code","7ff5f5c1":"code","2bbf58ef":"code","ee7126e3":"code","599f001e":"code","5e73eeef":"code","393acb2e":"code","40f887f5":"code","b8476370":"code","d11c62d1":"code","3e3d877d":"code","41f59517":"code","b44ef13f":"code","0a2a79a6":"code","a2242035":"code","0092ceda":"code","d206c448":"code","11ec30ca":"code","4dd6b910":"code","8abdede1":"code","18b198ff":"code","4cffca35":"code","fbfc495d":"code","88dff30b":"code","df324000":"code","3a362ea2":"code","f6917ae8":"code","f286b4ef":"code","38f898e7":"code","f49f6177":"code","6c3291e0":"code","d0ae7eb2":"code","d5217ff0":"code","7a47e76e":"code","38ac4e8e":"code","37381a2a":"code","cde19d6e":"code","8d2ea5f3":"code","f3b9eb5b":"code","6dbbae5f":"code","acaff58d":"code","6ba2c23a":"code","2e23a4b3":"code","48bfea47":"code","18dab5e0":"code","b882734f":"code","5f7e5edc":"code","c417ac95":"code","b1de6fe8":"code","5d9a8d95":"code","d4381142":"code","db902f2b":"code","2b018e9a":"code","e45fed6a":"code","41235b93":"code","2f5e749f":"code","b521a55e":"code","4d4188d9":"code","687785b4":"code","8a4f940b":"code","0b550e20":"code","99e89964":"code","3703a597":"code","0e75bad4":"code","ce2717d2":"code","53e41e41":"code","1af74064":"code","afc7d344":"code","df9c6944":"code","65cd7a29":"code","662bf462":"code","cb25258f":"code","186501c0":"code","60f94a17":"code","8d822245":"code","1d03a8d4":"code","72d36959":"code","6cea6e73":"code","46d92c74":"code","8f7beeba":"code","760d8c17":"code","dba7fdf1":"code","3fa38b91":"code","d25fbfb9":"code","2a9d8c3c":"code","a7417ac8":"code","a922d368":"code","9d22e4ea":"code","e04577c2":"markdown","174b998b":"markdown","94e367a2":"markdown","3f598ff3":"markdown","c702020d":"markdown","e0e7f48a":"markdown","237fcde1":"markdown","0d285ba2":"markdown","177bd1fe":"markdown","00e7a32d":"markdown","c7f37c46":"markdown","59520722":"markdown","f5c08a01":"markdown","083abbf3":"markdown","8f8d3f86":"markdown","d161edde":"markdown","0740e090":"markdown","c551397e":"markdown","bfe90fff":"markdown","67f2282f":"markdown","83e2e68a":"markdown","7687299b":"markdown","c1857d38":"markdown","3bedeb99":"markdown","b7d0bb48":"markdown","96a21445":"markdown","aa7eafb6":"markdown","3ae4b425":"markdown","3c10dfb6":"markdown","31d6ab27":"markdown","39ea525b":"markdown","0070ffe3":"markdown","79d3b9ed":"markdown","71721d96":"markdown","98ddc426":"markdown","07b8b9d9":"markdown","08149843":"markdown","2a12aadf":"markdown","c4ef5fb2":"markdown","76da282e":"markdown","908a5741":"markdown","3e1648e6":"markdown","6a0a1c87":"markdown","b61aaa17":"markdown","3a5c20a2":"markdown","94e58d91":"markdown","0fd25a69":"markdown"},"source":{"cbf68e58":"from datetime import datetime\n\nprint(\"last update: {}\".format(datetime.now())) ","2aab263b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","13ef8e40":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction import FeatureHasher\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.svm import LinearSVC\nfrom sklearn.preprocessing import PowerTransformer","10bab830":"# seed\nnp.random.seed(1231)","2bca6ea7":"df_train = pd.read_csv(\"\/kaggle\/input\/learn-together\/train.csv\" , index_col=['Id'])\ndf_test = pd.read_csv(\"\/kaggle\/input\/learn-together\/test.csv\" , index_col=['Id'])","b0b03bfa":"df_train.head()","bdb74f18":"df_test.head()","4cb477db":"print(\"shape training csv: %s\" % str(df_train.shape)) \nprint(\"shape test csv: %s\" % str(df_test.shape)) ","5c44a881":"df_train.dtypes.value_counts()","987ecd75":"df_test.dtypes.value_counts()","4daee54c":"df_train.iloc[:,10:].columns","9f8cfcf2":"df_test.iloc[:,10:].columns","05cd4102":"df_train.iloc[:,10:] = df_train.iloc[:,10:].astype(\"category\")\ndf_test.iloc[:,10:] = df_test.iloc[:,10:].astype(\"category\")","721bc844":"df_train.isna().sum().sum()","f2ca2ae2":"df_test.isna().sum().sum()","7a2dd8b3":"df_train[df_train.duplicated()].shape","b18a418f":"df_train.describe()","79d6ece1":"df_test.describe()","8434f2c2":"#Is it possible to have a negative value in *vertical distance to hydrology* ? how many are?\n\nprint(\"percent of negative values (training): \" + '%.3f' % ((df_train.loc[df_train.Vertical_Distance_To_Hydrology < 0].shape[0] \/ df_train.shape[0])*100))\nprint(\"percent of negative values (testing): \" + '%.3f' % ((df_test.loc[df_test.Vertical_Distance_To_Hydrology < 0].shape[0]\/ df_test.shape[0])*100))","71a0ea96":"sns.boxplot(df_train.Vertical_Distance_To_Hydrology)","5fb24ae2":"sns.boxplot(df_test.Vertical_Distance_To_Hydrology)","64e1e535":"columns_t_analyze = df_train.select_dtypes([\"float64\", \"int64\"]).columns.tolist()\ncolumns_t_analyze.append(\"Cover_Type\")\nplot = sns.pairplot(df_train.loc[:,columns_t_analyze], hue=\"Cover_Type\")\nplot.savefig(\"pairplot.png\")","0f9f4617":"columns_t_analyze = df_train.select_dtypes([\"float64\", \"int64\"])\ntransformer =  PowerTransformer(method='yeo-johnson').fit(columns_t_analyze)","a5bf304b":"columns_t_analyze = df_train.select_dtypes([\"float64\", \"int64\"])\n#columns_transformed =  RobustScaler(quantile_range=(25, 75)).fit_transform(columns_t_analyze)\ncolumns_transformed =  PowerTransformer(method='yeo-johnson').fit_transform(columns_t_analyze)","8339a981":"columns_transformed = pd.DataFrame(columns_transformed)\ncolumns_transformed.columns = columns_t_analyze.columns\ncolumns_transformed = pd.concat([columns_transformed, df_train.loc[:,\"Cover_Type\"]], axis=1, join='inner')","8e72618b":"X_train, X_test, y_train, y_test = train_test_split(columns_transformed.loc[:,columns_transformed.columns].drop(\"Cover_Type\", axis=1), columns_transformed.loc[:,'Cover_Type'], test_size=0.33, random_state=42)","47bf2a7b":"X_train.shape","774a275d":"lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False)\nlsvc.fit(X_train, y_train)\npred = lsvc.predict(X_test)\nprint(\"LinearSVC\")\nprint(classification_report(y_test,pred, labels=None))","0889276f":"from sklearn.linear_model import SGDClassifier\n\nsgdc= SGDClassifier()\nsgdc.fit(X_train, y_train)\npred = sgdc.predict(X_test)\nprint(\"SGDC\")\nprint(classification_report(y_test,pred, labels=None))","718ed621":"from sklearn.ensemble import RandomForestClassifier\nrandomfr= RandomForestClassifier()\nrandomfr.fit(X_train, y_train)\npred = randomfr.predict(X_test)\nprint(\"randomfr\")\nprint(classification_report(y_test,pred, labels=None))","82ba0be9":"model = SelectFromModel(randomfr, prefit=True)\nX_new = model.transform(X_train)\nX_new.shape","59ce2f95":"# elevation, horizontal_distance_to_roadways, horizontal_distance_to_fire_points\n\npd.DataFrame(X_new).describe()","09bd8fcf":"sns.pairplot(pd.concat([pd.DataFrame(X_new), df_train.loc[:,'Cover_Type']], axis=1, join='inner'), hue=\"Cover_Type\")","6ee7f4c1":"sns.pairplot(columns_transformed.drop(columns=[\"Elevation\", 'Horizontal_Distance_To_Roadways', 'Horizontal_Distance_To_Fire_Points'], axis=1), hue=\"Cover_Type\")","63f59a68":"df_train.columns","f15bf8db":"fig, axs = plt.subplots(nrows=2)\nsns.boxplot(df_train.Hillshade_3pm, ax=axs[0])\nsns.boxplot(df_test.Hillshade_3pm, ax=axs[1], color=\"green\")","ff4ab327":"#training \nquan = df_train.select_dtypes([\"int\", \"float64\"])\nQ1 = quan.quantile(0.25)\nQ3 = quan.quantile(0.75)\nIQR =  Q3 - Q1\n\n(((quan < (Q1 - 1.5 * IQR)) | (quan > (Q3 + 1.5 * IQR))).sum() \/ quan.shape[0]) * 100","97cc2917":"#testing \nquan = df_test.select_dtypes([\"int\", \"float\"])\nQ1 = quan.quantile(0.25)\nQ3 = quan.quantile(0.75)\nIQR =  Q3 - Q1\n\n(((quan < (Q1 - 1.5 * IQR)) | (quan > (Q3 + 1.5 * IQR))).sum() \/ quan.shape[0]) * 100","7d4469c9":"quan = df_train.select_dtypes([\"int\", \"float\"]).copy()\nQ1 = quan.quantile(0.25)\nQ3 = quan.quantile(0.75)\nIQR =  Q3 - Q1\nsns.boxplot(quan.loc[~((quan < (Q1 - 1.5 * IQR)) | (quan > (Q3 + 1.5 * IQR))).Hillshade_3pm].Hillshade_3pm)","7ff5f5c1":"for i in list(range(1,8)):\n    sns.distplot(df_train.loc[(~((quan < (Q1 - 1.5 * IQR)) | (quan > (Q3 + 1.5 * IQR))).Hillshade_3pm) & (df_train.Cover_Type == i), 'Hillshade_3pm'])\n","2bbf58ef":"print(\"Normal shape {}\".format(quan.shape[0]))\nprint(\"Without outliers {}\".format(quan.loc[~((quan < (Q1 - 1.5 * IQR)) | (quan > (Q3 + 1.5 * IQR))).Hillshade_3pm].shape[0]))","ee7126e3":"sns.boxplot(quan.loc[~((quan < (Q1 - 1.5 * IQR)) | (quan > (Q3 + 1.5 * IQR))).Slope].Slope)","599f001e":"sns.boxplot(data=df_train, y=\"Slope\", x=\"Cover_Type\")","5e73eeef":"for i in list(range(1,8)):\n    sns.distplot(df_train.loc[(~((quan < (Q1 - 1.5 * IQR)) | (quan > (Q3 + 1.5 * IQR))).Slope) & (df_train.Cover_Type == i), 'Slope'])\n","393acb2e":"print(\"Normal shape {}\".format(quan.shape[0]))\nprint(\"Without outliers {}\".format(quan.loc[~((quan < (Q1 - 1.5 * IQR)) | (quan > (Q3 + 1.5 * IQR))).Slope].shape[0]))","40f887f5":"sns.boxplot(quan.loc[~((quan < (Q1 - 1.5 * IQR)) | (quan > (Q3 + 1.5 * IQR))).Hillshade_Noon].Hillshade_Noon)","b8476370":"sns.boxplot(data=df_train, y=\"Hillshade_Noon\", x=\"Cover_Type\")","d11c62d1":"for i in list(range(1,8)):\n    sns.distplot(df_train.loc[(~((quan < (Q1 - 1.5 * IQR)) | (quan > (Q3 + 1.5 * IQR))).Hillshade_Noon) & (df_train.Cover_Type == i), 'Hillshade_Noon'])\n","3e3d877d":"print(\"Normal shape {}\".format(quan.shape[0]))\nprint(\"Without outliers {}\".format(quan.loc[~((quan < (Q1 - 1.5 * IQR)) | (quan > (Q3 + 1.5 * IQR))).Hillshade_Noon].shape[0]))","41f59517":"sns.boxplot(data=df_train, y=\"Hillshade_9am\", x=\"Cover_Type\")","b44ef13f":"sns.boxplot(data=df_train, y=\"Hillshade_3pm\", x=\"Cover_Type\")","0a2a79a6":"sns.boxplot(data=df_train, y=\"Aspect\", x=\"Cover_Type\")","a2242035":"quan.shape [0] - quan.loc[(~((quan < (Q1 - 1.5 * IQR)) | (quan > (Q3 + 1.5 * IQR))).Hillshade_Noon) & (~((quan < (Q1 - 1.5 * IQR)) | (quan > (Q3 + 1.5 * IQR))).Slope)\n        & (~((quan < (Q1 - 1.5 * IQR)) | (quan > (Q3 + 1.5 * IQR))).Hillshade_3pm)].shape[0]","0092ceda":"df_train_copy = df_train[(~((quan < (Q1 - 1.5 * IQR)) | (quan > (Q3 + 1.5 * IQR))).Hillshade_Noon) & (~((quan < (Q1 - 1.5 * IQR)) | (quan > (Q3 + 1.5 * IQR))).Slope)\n        & (~((quan < (Q1 - 1.5 * IQR)) | (quan > (Q3 + 1.5 * IQR))).Hillshade_3pm)].copy()","d206c448":"df_train_copy.shape","11ec30ca":"columns_t_analyze = df_train_copy.select_dtypes([\"float64\", \"int64\"]).copy()\nX_train, X_test, y_train, y_test = train_test_split(df_train_copy.loc[:,columns_t_analyze.columns], df_train_copy.loc[:,'Cover_Type'], test_size=0.33, random_state=42)\n\nfrom sklearn.ensemble import RandomForestClassifier\nrandomfr= RandomForestClassifier()\nrandomfr.fit(X_train, y_train)\npred = randomfr.predict(X_test)\nprint(\"randomfr\")\nprint(classification_report(y_test,pred, labels=None))","4dd6b910":"model = SelectFromModel(randomfr, prefit=True)\nX_new = model.transform(X_train)\nX_new.shape","8abdede1":"pd.DataFrame(X_new).head()","18b198ff":"X_train.head()","4cffca35":"sns.jointplot(data=df_train_copy, x=\"Horizontal_Distance_To_Hydrology\", y=\"Vertical_Distance_To_Hydrology\", kind=\"reg\",)","fbfc495d":"df_train_copy['Horizontal_Distance_To_Hydrology'].corr(df_train_copy['Vertical_Distance_To_Hydrology'])","88dff30b":"plt.figure(figsize=(15, 15))\nsns.heatmap(df_train_copy.corr(), annot=True, cmap=\"YlGnBu\")","df324000":"from scipy.stats import norm\nsns.distplot(df_train_copy.Horizontal_Distance_To_Hydrology, fit=norm)","3a362ea2":"from scipy import stats\n\nres = stats.probplot(df_train_copy.Horizontal_Distance_To_Hydrology, plot=plt)","f6917ae8":"res = stats.probplot(pd.np.log(df_train_copy.loc[df_train_copy.Horizontal_Distance_To_Hydrology>0].Horizontal_Distance_To_Hydrology), plot=plt)","f286b4ef":"res = stats.probplot(pd.np.log(df_train_copy.loc[df_train_copy.Vertical_Distance_To_Hydrology>0].Vertical_Distance_To_Hydrology), plot=plt)","38f898e7":"sns.boxplot(df_train_copy.Horizontal_Distance_To_Hydrology)","f49f6177":"# np.where()\ndf_train_copy['horizontal_distance_to_hidrology_modified'] = np.where(df_train_copy.Horizontal_Distance_To_Hydrology <=0, df_train_copy.Horizontal_Distance_To_Hydrology.mean(), df_train_copy.Horizontal_Distance_To_Hydrology)\ndf_train_copy['horizontal_distance_to_hidrology_modified'] = np.log(df_train_copy.horizontal_distance_to_hidrology_modified)","6c3291e0":"df_train_copy['vertical_distance_to_hidrology_modified'] = np.where(df_train_copy.Vertical_Distance_To_Hydrology <=0, df_train_copy.Vertical_Distance_To_Hydrology.mean(), df_train_copy.Vertical_Distance_To_Hydrology)\ndf_train_copy['vertical_distance_to_hidrology_modified'] = np.log(df_train_copy.vertical_distance_to_hidrology_modified)","d0ae7eb2":"sns.jointplot(data=df_train_copy, x=\"vertical_distance_to_hidrology_modified\", y=\"horizontal_distance_to_hidrology_modified\", kind=\"reg\")","d5217ff0":"df_train_copy[\"total_distance\"] = (df_train_copy.vertical_distance_to_hidrology_modified**2) + (df_train_copy.horizontal_distance_to_hidrology_modified**2)","7a47e76e":"sns.boxplot(data=df_train_copy, y=\"total_distance\", x=\"Cover_Type\")","38ac4e8e":"#columns_t_analyze = df_train_copy.select_dtypes([\"int64\", \"float64\"]).copy()\nX_train, X_test, y_train, y_test = train_test_split(df_train_copy.loc[:,['Elevation', 'Aspect', 'Slope','Horizontal_Distance_To_Roadways',\n       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n       'Horizontal_Distance_To_Fire_Points',\n       'horizontal_distance_to_hidrology_modified',\n       'vertical_distance_to_hidrology_modified', 'total_distance']], df_train_copy.loc[:,'Cover_Type'], test_size=0.33, random_state=42)\n\nfrom sklearn.ensemble import RandomForestClassifier\nrandomfr= RandomForestClassifier()\nrandomfr.fit(X_train, y_train)\npred = randomfr.predict(X_test)\nprint(\"randomfr\")\nprint(classification_report(y_test,pred, labels=None))\n\nmodel = SelectFromModel(randomfr, prefit=True)\nX_new = model.transform(X_train)\nprint(X_new.shape)","37381a2a":"pd.DataFrame(X_new).head()","cde19d6e":"X_train.head()","8d2ea5f3":"list(range(2,14,2))","f3b9eb5b":"from sklearn.model_selection import cross_val_score\nX_train, X_test, y_train, y_test = train_test_split(df_train_copy[['Slope', 'Cover_Type']],df_train_copy.Cover_Type , test_size = 0.3)\n\nscore_ls = []     \nscore_std_ls = [] \nfor tree_depth in range(2,14,2):\n    tree_model = DecisionTreeClassifier(max_depth=tree_depth)\n    \n    scores = cross_val_score(tree_model, X_train.Slope.to_frame(), y_train, cv=3, scoring='balanced_accuracy')   \n    \n    score_ls.append(np.mean(scores))\n    \n    score_std_ls.append(np.std(scores))\n    \ntemp = pd.concat([pd.Series(list(range(2,14,2))), pd.Series(score_ls), pd.Series(score_std_ls)], axis=1)\ntemp.columns = ['depth', 'accuracy', 'roc_acc_std']\nprint(temp)","6dbbae5f":"\ntree_model = DecisionTreeClassifier(max_depth=2)\n\ntree_model.fit(X_train.Slope.to_frame(), y_train)\n\nX_train['Slope_tree'] = tree_model.predict_proba(X_train.Slope.to_frame())[:,1] \n\nX_train.Slope_tree.unique()","acaff58d":"fig = plt.figure()\nfig = pd.DataFrame(X_train.groupby(['Slope_tree'])[\"Cover_Type\"])[0].plot()\nfig.set_title('Monotonic relationship between discretised Slope and target')\nfig.set_ylabel('Cover_Type')","6ba2c23a":"pd.concat( [X_train.groupby(['Slope_tree'])['Slope'].min(),\n            X_train.groupby(['Slope_tree'])['Slope'].max()], axis=1)","2e23a4b3":"df_train['Slope_tree'] = tree_model.predict_proba(df_train.Slope.to_frame())[:,1]\ndf_test['Slope_tree'] = tree_model.predict_proba(df_test.Slope.to_frame())[:,1]\n\ndf_train.Slope_tree = df_train.Slope_tree.astype(\"category\")\ndf_test.Slope_tree = df_test.Slope_tree.astype(\"category\")\n\n\n\ndf_train_copy['Slope_tree'] = tree_model.predict_proba(df_train_copy.Slope.to_frame())[:,1]\n\ndf_train_copy.Slope_tree = df_train_copy.Slope_tree.astype(\"category\")","48bfea47":"df_train.Cover_Type.value_counts()","18dab5e0":"X = df_train.select_dtypes(\"category\").drop(columns=[\"Cover_Type\"])","b882734f":"from collections import defaultdict\nfrom sklearn.preprocessing import LabelEncoder\nd = defaultdict(LabelEncoder)\nfit = X.apply(lambda x: d[x.name].fit_transform(x))","5f7e5edc":"fit.columns","c417ac95":"Y_train = df_train.loc[:,'Cover_Type']","b1de6fe8":"X_train, X_test, y_train, y_test = train_test_split(fit, Y_train, test_size=0.33, random_state=42)","5d9a8d95":"from sklearn.tree import DecisionTreeClassifier\nclf = DecisionTreeClassifier()\nclf.fit(X_train, y_train)\npred = clf.predict(X_test)\naccuracy = accuracy_score(pred, y_test)\nprint(clf)\nprint(classification_report(pred, y_test, labels=None))","d4381142":"feature_importances = pd.DataFrame(clf.feature_importances_,\n                                   index = X_train.columns,\n                                    columns=['importance']).sort_values('importance',ascending=False)\nfeature_importances","db902f2b":"qualitative = df_train.select_dtypes(\"category\").drop(columns=[\"Cover_Type\"])\ncolumns_t_analyze = df_train.select_dtypes([\"float64\", \"int64\"])\n#columns_transformed =  RobustScaler(quantile_range=(25, 75)).fit_transform(columns_t_analyze)\n\ncolumns_transformed =  PowerTransformer(method='yeo-johnson').fit_transform(columns_t_analyze)\ncolumns_transformed = pd.DataFrame(columns_transformed)\ncolumns_transformed.columns = columns_t_analyze.columns\ncolumns_transformed = pd.concat([columns_transformed, df_train.loc[:,\"Cover_Type\"]], axis=1, join='inner')\nd = defaultdict(LabelEncoder)\nfit = X.apply(lambda x: d[x.name].fit_transform(x))\nfit.reset_index(drop=True, inplace=True)\ncolumns_transformed.reset_index(drop=True, inplace=True)\nfeatures_preprocessing = pd.concat([fit, columns_transformed], axis=1, join='inner')","2b018e9a":"features_preprocessing.columns","e45fed6a":"selected_columns=[\"Elevation\", 'Horizontal_Distance_To_Roadways', 'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area4', 'Soil_Type10', \n                  'Soil_Type38', 'Soil_Type39', 'Soil_Type40', 'Soil_Type4', 'Soil_Type3', 'Soil_Type17', 'Soil_Type2']\n\n","41235b93":"X_train, X_test, y_train, y_test = train_test_split(features_preprocessing.loc[:,selected_columns], features_preprocessing.loc[:,'Cover_Type'], test_size=0.33, random_state=42)","2f5e749f":"from sklearn.neighbors import KNeighborsClassifier\n\nfor i in range(3, 21, 3):\n    neigh = KNeighborsClassifier(n_neighbors=i)\n    neigh.fit(X_train, y_train)\n    pred = neigh.predict(X_test)\n    print(\"KNeighborsClassifier {}\".format(i))\n    print(classification_report(pred, y_test, labels=None))","b521a55e":"from sklearn.naive_bayes import GaussianNB, BernoulliNB\ngnb = GaussianNB()\ngnb.fit(X_train, y_train)\npred = gnb.predict(X_test)\n## accuracy\naccuracy = accuracy_score(y_test,pred)\nprint(\"naive_bayes\")\nprint(classification_report(y_test,pred, labels=None))","4d4188d9":"from sklearn import svm\nSv=svm.SVC(gamma='scale',kernel='rbf')\nSv.fit(X_train, y_train)\n\npred = Sv.predict(X_test)\n# accuracy\naccuracy = accuracy_score(y_test,pred)\nprint(classification_report(y_test,pred, labels=None))","687785b4":"from sklearn.tree import DecisionTreeClassifier\nclf = DecisionTreeClassifier()\nclf.fit(X_train, y_train)\npred = clf.predict(X_test)\naccuracy = accuracy_score(pred, y_test)\nprint(clf)\nprint(classification_report(pred, y_test, labels=None))","8a4f940b":"from xgboost import XGBClassifier\n\nxgb = XGBClassifier(max_depth=10, subsample=0.8, colsample_bytree=0.7,missing=-999)\n\nxgb.fit(X_train, y_train)\npred = xgb.predict(X_test)\naccuracy = accuracy_score(pred, y_test)\nprint(xgb)\nprint(classification_report(pred, y_test, labels=None))","0b550e20":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.metrics import roc_auc_score\nparams = {\n        'min_child_weight': [1, 5, 10, 13, 15],\n        'gamma': [0.5, 1, 1.5, 2, 5],\n        'subsample': [0.2, 0.4, 0.6, 0.8, 1.0],\n        'colsample_bytree': [0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5, 10, 20]\n        }\n\nxgb = XGBClassifier(silent=True, nthread=1)\nfolds = 3\nparam_comb = 5\n\nskf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n\nrandom_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring='accuracy', n_jobs=4, cv=skf.split(X_train, y_train), verbose=3, random_state=1001 )\n\nrandom_search.fit(X_train, y_train)","99e89964":"print('\\n All results:')\nprint(random_search.cv_results_)\nprint('\\n Best estimator:')\nprint(random_search.best_estimator_)\nprint('\\n Best hyperparameters:')\nprint(random_search.best_params_)\nresults = pd.DataFrame(random_search.cv_results_)\nresults.to_csv('xgb-random-grid-search-results-01.csv', index=False)","3703a597":"xgb = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.8, gamma=5,\n              learning_rate=0.1, max_delta_step=0, max_depth=10,\n              min_child_weight=10, missing=None, n_estimators=100, n_jobs=1,\n              nthread=1, objective='multi:softprob', random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n              silent=True, subsample=0.8, verbosity=1)\n\nxgb.fit(X_train, y_train)\npred = xgb.predict(X_test)\nprint(classification_report(pred, y_test, labels=None))","0e75bad4":"parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\nsvc = svm.SVC(gamma=\"scale\")\nclf = GridSearchCV(svc, parameters, cv=5)\nclf.fit(X_train, y_train)\nprint('\\n All results:')\nprint(clf.cv_results_)\nprint('\\n Best estimator:')\nprint(clf.best_estimator_)\nprint('\\n Best hyperparameters:')\nprint(clf.best_params_)","ce2717d2":"clf = svm.SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n    max_iter=-1, probability=False, random_state=None, shrinking=True,\n    tol=0.001, verbose=False)\nclf.fit(X_train, y_train)\npred = clf.predict(X_test)\nprint(classification_report(pred, y_test, labels=None))","53e41e41":"# selected_columns=[\"Elevation\", 'Horizontal_Distance_To_Roadways', 'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area4', 'Soil_Type10', \n#                   'Soil_Type38', 'Soil_Type39', 'Soil_Type40', 'Soil_Type4', 'Soil_Type3', 'Soil_Type17', 'Soil_Type2', 'Soil_Type30', 'Soil_Type13',\n#                  'Soil_Type22', 'Soil_Type12', 'Soil_Type35', 'Soil_Type11', 'Wilderness_Area1', 'Soil_Type14']\n\n\n\nselected_columns=[\"Elevation\", 'Horizontal_Distance_To_Roadways', 'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area4', 'Soil_Type10', \n                  'Soil_Type38', 'Soil_Type39', 'Soil_Type40', 'Soil_Type4', 'Soil_Type3', 'Soil_Type17', 'Soil_Type2', 'Soil_Type30', 'Soil_Type13',\n                 'Soil_Type22', 'Soil_Type12', 'Soil_Type35', 'Soil_Type11', 'Wilderness_Area1', 'Soil_Type14',\n                 'Wilderness_Area3', 'Soil_Type37', 'Soil_Type23', 'Soil_Type16', 'Soil_Type20', 'Soil_Type24', 'Soil_Type18', 'Wilderness_Area2', 'Slope_tree']","1af74064":"df_train_copy.columns","afc7d344":"# without outliers\nX_train, X_test, y_train, y_test = train_test_split(df_train_copy.loc[:,selected_columns], df_train_copy.loc[:,'Cover_Type'], test_size=0.33, random_state=42)","df9c6944":"from sklearn.ensemble import RandomForestClassifier\nrandomfr= RandomForestClassifier()\nrandomfr.fit(X_train, y_train)\npred = randomfr.predict(X_test)\nprint(\"randomfr\")\nprint(classification_report(y_test,pred, labels=None))","65cd7a29":"from sklearn.neighbors import KNeighborsClassifier\n\nfor i in range(3, 21, 3):\n    neigh = KNeighborsClassifier(n_neighbors=i)\n    neigh.fit(X_train, y_train)\n    pred = neigh.predict(X_test)\n    print(\"KNeighborsClassifier {}\".format(i))\n    print(classification_report(pred, y_test, labels=None))","662bf462":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\n# from sklearn.metrics import roc_auc_score\nrandom_grid = {'bootstrap': [True, False],\n               'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n               'max_features': ['auto', 'sqrt'],\n               'min_samples_leaf': [1, 2, 4],\n               'min_samples_split': [2, 5, 10],\n               'n_estimators': [130, 180, 230]}\n\n# skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\nrf = RandomForestClassifier()\nrandom_search = RandomizedSearchCV(rf, param_distributions=random_grid, n_iter=param_comb, scoring='accuracy', n_jobs=4, cv=5, verbose=3, random_state=1001 )\n\nrandom_search.fit(X_train, y_train)","cb25258f":"random_search.best_estimator_.fit(X_train, y_train)\npred = random_search.best_estimator_.predict(X_test)\nprint(\"randomfr\")\nprint(classification_report(y_test,pred, labels=None))","186501c0":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.metrics import roc_auc_score\n\n\nqualitative = df_train_copy.select_dtypes(\"category\").drop(columns=[\"Cover_Type\"])\ncolumns_t_analyze = df_train_copy.select_dtypes([\"float64\", \"int64\"])\n#columns_transformed =  RobustScaler(quantile_range=(25, 75)).fit_transform(columns_t_analyze)\n\ncolumns_transformed =  PowerTransformer(method='yeo-johnson').fit_transform(columns_t_analyze)\ncolumns_transformed = pd.DataFrame(columns_transformed)\ncolumns_transformed.columns = columns_t_analyze.columns\ncolumns_transformed = pd.concat([columns_transformed, df_train_copy.loc[:,\"Cover_Type\"]], axis=1, join='inner')\nd = defaultdict(LabelEncoder)\nfit = X.apply(lambda x: d[x.name].fit_transform(x))\nfit.reset_index(drop=True, inplace=True)\ncolumns_transformed.reset_index(drop=True, inplace=True)\nfeatures_preprocessing = pd.concat([fit, columns_transformed], axis=1, join='inner')\n\n\n\nselected_columns=[\"Elevation\", 'Horizontal_Distance_To_Roadways', 'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area4', 'Soil_Type10', \n                  'Soil_Type38', 'Soil_Type39', 'Soil_Type40', 'Soil_Type4', 'Soil_Type3', 'Soil_Type17', 'Soil_Type2', 'Soil_Type30', 'Soil_Type13',\n                 'Soil_Type22', 'Soil_Type12', 'Soil_Type35', 'Soil_Type11', 'Wilderness_Area1', 'Soil_Type14',\n                 'Wilderness_Area3', 'Soil_Type37', 'Soil_Type23', 'Soil_Type16', 'Soil_Type20', 'Soil_Type24', 'Soil_Type18', 'Wilderness_Area2']\n\nX_train, X_test, y_train, y_test = train_test_split(features_preprocessing.loc[:,selected_columns], features_preprocessing.loc[:,'Cover_Type'], test_size=0.33, random_state=42)\n\nparams = {\n        'min_child_weight': [1, 5, 10, 13, 15],\n        'gamma': [0.5, 1, 1.5, 2, 5],\n        'subsample': [0.2, 0.4, 0.6, 0.8, 1.0],\n        'colsample_bytree': [0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5, 10, 20]\n        }\n\nxgb = XGBClassifier(silent=True, nthread=1)\n#folds = 3\n#param_comb = 5\n\n#skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n\nrandom_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring='accuracy', n_jobs=4, cv=7, verbose=3, random_state=1001 )\n\nrandom_search.fit(X_train, y_train)","60f94a17":"xgb = random_search.best_estimator_\n\nxgb.fit(X_train, y_train)\npred = xgb.predict(X_test)\nprint(classification_report(pred, y_test, labels=None))","8d822245":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\n# from sklearn.metrics import roc_auc_score\nrandom_grid = {'bootstrap': [True, False],\n               'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n               'max_features': ['auto', 'sqrt'],\n               'min_samples_leaf': [1, 2, 4],\n               'min_samples_split': [2, 5, 10],\n               'n_estimators': [130, 180, 230]}\n\n# skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\nrf = RandomForestClassifier()\nrandom_search = RandomizedSearchCV(rf, param_distributions=random_grid, n_iter=param_comb, scoring='accuracy', n_jobs=4, cv=5, verbose=3, random_state=1001 )\n\nrandom_search.fit(X_train, y_train)\n\nrandom_search.best_estimator_.fit(X_train, y_train)\npred = random_search.best_estimator_.predict(X_test)\nprint(\"randomfr\")\nprint(classification_report(y_test,pred, labels=None))","1d03a8d4":"# 1 experiment\n#neigh = KNeighborsClassifier(n_neighbors=3)\n#neigh.fit(features_preprocessing.loc[:,selected_columns], features_preprocessing.loc[:,'Cover_Type'])\n# 2 experiment\n# xgb = XGBClassifier(max_depth=10, subsample=0.8, colsample_bytree=0.7,missing=-999)\n# xgb.fit(features_preprocessing.loc[:,selected_columns], features_preprocessing.loc[:,'Cover_Type'])\n# 3 experiment \n\nselected_columns=[\"Elevation\", 'Horizontal_Distance_To_Roadways', 'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area4', 'Soil_Type10', \n                  'Soil_Type38', 'Soil_Type39', 'Soil_Type40', 'Soil_Type4', 'Soil_Type3', 'Soil_Type17', 'Soil_Type2', 'Soil_Type30', 'Soil_Type13',\n                 'Soil_Type22', 'Soil_Type12', 'Soil_Type35', 'Soil_Type11', 'Wilderness_Area1', 'Soil_Type14',\n                 'Wilderness_Area3', 'Soil_Type37', 'Soil_Type23', 'Soil_Type16', 'Soil_Type20', 'Soil_Type24', 'Soil_Type18', 'Wilderness_Area2', 'Slope_tree']\n\n\n# 4 experiment\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\n# from sklearn.metrics import roc_auc_score\nrandom_grid = {'bootstrap': [True, False],\n               'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n               'max_features': ['auto', 'sqrt'],\n               'min_samples_leaf': [1, 2, 4],\n               'min_samples_split': [2, 5, 10],\n               'n_estimators': [130, 180, 230]}\n\n# skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\nrf = RandomForestClassifier()\nrandom_search = RandomizedSearchCV(rf, param_distributions=random_grid, n_iter=param_comb, scoring='accuracy', n_jobs=4, cv=5, verbose=3, random_state=1001 )\n\nrandom_search.fit(df_train_copy.loc[:,selected_columns], df_train_copy.loc[:,'Cover_Type'])\n\nrandom_search.best_estimator_.fit(df_train_copy.loc[:,selected_columns], df_train_copy.loc[:,'Cover_Type'])\n\n# from sklearn.ensemble import RandomForestClassifier\n# randomfr= RandomForestClassifier()\n# randomfr.fit(df_train_copy.loc[:,selected_columns], df_train_copy.loc[:,'Cover_Type'])\n","72d36959":"columns_t_analyze = df_test.select_dtypes([\"float64\", \"int64\"])\ncolumns_transformed =  transformer.transform(columns_t_analyze)\ncolumns_transformed = pd.DataFrame(columns_transformed)\ncolumns_transformed.columns = columns_t_analyze.columns","6cea6e73":"columns_transformed.shape","46d92c74":"columns_transformed.head()","8f7beeba":"columns_transformed.columns","760d8c17":"from collections import defaultdict\nfrom sklearn.preprocessing import LabelEncoder\nd = defaultdict(LabelEncoder)\nX = df_test.select_dtypes(\"category\")\nfit = X.apply(lambda x: d[x.name].fit_transform(x))","dba7fdf1":"fit.columns","3fa38b91":"fit.reset_index(drop=True, inplace=True)\ncolumns_transformed.reset_index(drop=True, inplace=True)\nfeatures_test_preprocessing = pd.concat([columns_transformed, fit], axis=1, join='inner')\nfeatures_test_preprocessing.shape","d25fbfb9":"features_test_preprocessing.isna().sum().sum()","2a9d8c3c":"#selected_columns=[\"Elevation\", 'Horizontal_Distance_To_Roadways', 'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area4', 'Soil_Type10', \n#                  'Soil_Type38', 'Soil_Type39', 'Soil_Type40', 'Soil_Type4']\n\nresults = xgb.predict(features_test_preprocessing.loc[:,selected_columns])","a7417ac8":"selected_columns=[\"Elevation\", 'Horizontal_Distance_To_Roadways', 'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area4', 'Soil_Type10', \n                  'Soil_Type38', 'Soil_Type39', 'Soil_Type40', 'Soil_Type4', 'Soil_Type3', 'Soil_Type17', 'Soil_Type2']\n\nresults = randomfr.predict(df_test.loc[:,selected_columns])","a922d368":"selected_columns=[\"Elevation\", 'Horizontal_Distance_To_Roadways', 'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area4', 'Soil_Type10', \n                  'Soil_Type38', 'Soil_Type39', 'Soil_Type40', 'Soil_Type4', 'Soil_Type3', 'Soil_Type17', 'Soil_Type2', 'Soil_Type30', 'Soil_Type13',\n                 'Soil_Type22', 'Soil_Type12', 'Soil_Type35', 'Soil_Type11', 'Wilderness_Area1', 'Soil_Type14',\n                 'Wilderness_Area3', 'Soil_Type37', 'Soil_Type23', 'Soil_Type16', 'Soil_Type20', 'Soil_Type24', 'Soil_Type18', 'Wilderness_Area2', 'Slope_tree']\n\nresults = random_search.best_estimator_.predict(df_test.loc[:,selected_columns])\n","9d22e4ea":"output = pd.DataFrame({'Id': df_test.index,\n                       'Cover_Type': results})\noutput.to_csv('submission_all.csv', index=False)","e04577c2":"Experiment 2","174b998b":"Due to we have outliers in our quantitative features the idea is to use an scaler method, I'm going to use the application of a *RobustScaler* due to it is robuts to outliers (same as Quantile transformer)","94e367a2":"### Feature Engineering","3f598ff3":"The last printing allows us to understand that we will not have problems with an objective feature that is imbalanced. ","c702020d":"# Exploration Quantitative Features ","e0e7f48a":"# Explore\n\nIn this phase I'm going to see how is the data","237fcde1":"How many data will we loose for all of them?","0d285ba2":"# Modeling","177bd1fe":"Experiment 3","00e7a32d":"# References\n\n+ https:\/\/towardsdatascience.com\/understanding-feature-engineering-part-2-categorical-data-f54324193e63\n+ https:\/\/www.analyticsvidhya.com\/blog\/2015\/11\/easy-methods-deal-categorical-variables-predictive-modeling\/\n+ https:\/\/pbpython.com\/categorical-encoding.html","c7f37c46":"Through the last plot I could think that some quantitave have a treatment, let's work on that. ","59520722":"***\n*Holdout approach*","f5c08a01":"Nice!!! we are looking the Homoscedasticity \ud83e\udd16","083abbf3":"In the next step let's see what are the feature types","8f8d3f86":"So... 453, these data will be important to analyze, I will keep them in another set","d161edde":"### NaN\n\nLet's see how many NaN we have in our datasets","0740e090":"```\n        \n        |   | \/  |   |  |  |  |  |  |  \/  |   |  |  |  |      [0][1][0]   \n        |       \/    |  |  |  |  |       \/    \\   \\_\/  \/      [1][1][1]   \n        |      \/     |  |  |  |  |      \/      \\  \\_\/ \/       [1][1][1]   \n        |  |\\  \\     |  '--'  |  |  |\\  \\       \\    \/        Data science    \n        | _| `.__\\   |________|  | _| `.__\\      |___|                                \n```","c551397e":"## Treatments","bfe90fff":"We have a lot of categorical features, but, how many of them are really representative for our objective variable?\n\nWe can use statistic functions, change them to dummy variables or use an approach of fueature hashing in oder to filter and select the categorical features,in this case I'm going to change use a feature hashing approach and analyze the feature importances using a decision tree. ","67f2282f":"# Make Predictions","83e2e68a":"Is it possible to have a negative value in *vertical distance to hydrology* ?","7687299b":"Through the last chunks we can assume that we don't have NaN in both datasets","c1857d38":"what is going to happen with the other features? what are their distributions?","3bedeb99":"the last two chunks show that we need to transform the variables to their correct representation","b7d0bb48":"Our objetive variable is cover_type, a feature that is categorical that has 7 values... how is it'[](http:\/\/)s distribution?","96a21445":"Let's see the distribution of some training features without outliers\n.","aa7eafb6":"### Duplicated Data\n\nLet's see if we have duplicated data in our datasets","3ae4b425":"**Wow definetily we have something here, a lot of outliers for this feature**","3c10dfb6":"The last two tables allow us to see that the outlier percent of each quantitative feature is not high individually, so the next idea is to see what are the most important  and their impact collectively in the number of registers. ","31d6ab27":"# Packages","39ea525b":"# Dimensions","0070ffe3":"## Load Datasets","79d3b9ed":"***\n*K fold approach*","71721d96":"I'm going to join the information and make other features which have the data about the initial ones","98ddc426":"# Exploration Qualitative Features","07b8b9d9":"**Tranining with all data.**","08149843":"From the last RF we can filter some of the quantitive features. ","2a12aadf":"# Learn With Other Kaggle Users\n\n*Author: Christian Camilo Urcuqui L\u00f3pez*\n\n*Date: 27 August 2019*\n\n*GitHub: https:\/\/github.com\/urcuqui\/ *\n\nIn this notebook I'm going to use a data science approach in order to evaluate machine learning classifiers for a friendly competition (*Classify forest types based on information about the area*).\n\nThis work is divided in the next sections:\n\n+ [Data Description](#Data-Description)\n+ [Packages](#Packages)\n+ [Explore](#Explore)\n    + [Dimensions](#Dimensions)\n    + [Treatments](#Treatments)\n        + [NaN](#NaN)\n        + [Duplicated Data](#Duplicated-Data)    \n    + [Exploration Quantitative Features](#Exploration-Quantitative-Features) \n    + [Exploration Qualitative Features](#Exploration-Qualitative-Features)\n+ [Modeling](#Modeling)","c4ef5fb2":"Nice, it looks pretty ","76da282e":"By te last process we have a number of features that are more important than the others, we can right \nnow do experiments","908a5741":"Among *The last plost* we can see that some features can be used to segment the types of our forests, some of them might be:\n+ elevation\n+ horizontal_distance_to_the_hidrology\n\nAs we saw the scales of each quantitave variable is significative and the boxplots and distplots allowed us to see that we have outliers (they are a lot of we can't erase them). We will need to standardize them. ","3e1648e6":"+ Horizontal_Distance_To_Roadways\n+ Elevation\n+ Horizontal_Distance_To_Fire_Points","6a0a1c87":"Experiment 1","b61aaa17":"***\n*Another approach*","3a5c20a2":"***\nHow are the distributions of our quantitatve features at test set? ","94e58d91":"# Data Description\n\n<div class=\"DataExplorerDescription_Container-sc-rtvgew bNXSrs\"><div class=\"DataExplorerDescription_DatasourceHeader-sc-1jjl64y hYvtkD\"><img src=\"https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/15767\/logos\/thumb76_76.png?t=2019-08-21-16-24-53\" alt=\"Learn With Other Kaggle Users source image\" class=\"DataExplorerDescription_DatasourceImage-sc-124hjw6 faQqwa\"><div class=\"DataExplorerDescription_DatasourceDetails-sc-6z9az5 cgraVO\"><div class=\"DataExplorerDescription_DatasourceOverview-sc-64u3xx dthRbg\">Classify forest types based on information about the area<\/div><div class=\"DataExplorerDescription_DatasourceLastUpdated-sc-1bnzx7s gFoPLV\">Last Updated: <span title=\"Tue Aug 27 2019 15:56:49 GMT-0500 (hora est\u00e1ndar de Colombia)\">a day ago<\/span><\/div><\/div><\/div><div class=\"DataExplorerDescription_Header-sc-9udzgu kagSZQ\"><div class=\"DataExplorerDescription_HeaderTitle-sc-8yzcy8 kIiVNS\">About this Competition<\/div><div class=\"DataExplorerDescription_HeaderRight-sc-m2iwyg fyjBEU\"><\/div><\/div><div class=\"DataExplorerDescription_Content-sc-yp9anb eysdMp\"><div class=\"markdown-converter__text--rendered data-explorer-overview-description\"><p>The study area includes four wilderness areas located in the Roosevelt National Forest of northern Colorado. Each observation is a 30m x 30m patch. You are asked to predict an integer classification for the forest cover type. The seven types are:<\/p>\n\n<p>1 - Spruce\/Fir<br> 2 - Lodgepole Pine<br> 3 - Ponderosa Pine<br> 4 - Cottonwood\/Willow<br> 5 - Aspen<br> 6 - Douglas-fir<br> 7 - Krummholz<\/p>\n\n<p>The training set (15120 observations) contains both features and the&nbsp;Cover_Type. The test set contains only the features. You must predict the Cover_Type&nbsp;for every row&nbsp;in the test set (565892 observations).<\/p>\n\n<h2>Data Fields<\/h2>\n\n<p><strong>Elevation<\/strong> - Elevation in meters<br><strong>Aspect<\/strong> - Aspect in degrees azimuth<br><strong>Slope<\/strong> - Slope in degrees<br><strong>Horizontal_Distance_To_Hydrology<\/strong> - Horz Dist to nearest surface water features<br><strong>Vertical_Distance_To_Hydrology<\/strong> - Vert Dist to nearest surface water features<br><strong>Horizontal_Distance_To_Roadways<\/strong> - Horz Dist to nearest roadway<br><strong>Hillshade_9am<\/strong> (0 to 255 index) - Hillshade index at 9am, summer solstice<br><strong>Hillshade_Noon<\/strong> (0 to 255 index) - Hillshade index at noon, summer solstice<br><strong>Hillshade_3pm<\/strong> (0 to 255 index) - Hillshade index at 3pm, summer solstice<br><strong>Horizontal_Distance_To_Fire_Points<\/strong> - Horz Dist to nearest wildfire ignition points<br><strong>Wilderness_Area<\/strong> (4 binary columns, 0 = absence or 1 = presence) - Wilderness area designation<br><strong>Soil_Type<\/strong> (40 binary columns, 0 = absence or 1 = presence) - Soil Type designation<br><strong>Cover_Type<\/strong> (7 types, integers 1 to 7) - Forest Cover Type designation<\/p>\n\n<p>The wilderness areas are:<\/p>\n\n<p>1 - Rawah Wilderness Area<br> 2 - Neota Wilderness Area<br> 3 - Comanche Peak Wilderness Area<br> 4 - Cache la Poudre Wilderness Area<\/p>\n\n<p>The soil types are:<\/p>\n\n<p>1 Cathedral family - Rock outcrop complex, extremely stony.<br> 2 Vanet - Ratake families complex, very stony.<br> 3 Haploborolis - Rock outcrop complex, rubbly.<br> 4 Ratake family - Rock outcrop complex, rubbly.<br> 5 Vanet family - Rock outcrop complex complex, rubbly.<br> 6 Vanet - Wetmore families - Rock outcrop complex, stony.<br> 7 Gothic family.<br> 8 Supervisor - Limber families complex.<br> 9 Troutville family, very stony.<br> 10 Bullwark - Catamount families - Rock outcrop complex, rubbly.<br> 11 Bullwark - Catamount families - Rock land complex, rubbly.<br> 12 Legault family - Rock land complex, stony.<br> 13 Catamount family - Rock land - Bullwark family complex, rubbly.<br> 14 Pachic Argiborolis - Aquolis complex.<br> 15 unspecified in the USFS Soil and ELU Survey.<br> 16 Cryaquolis - Cryoborolis complex.<br> 17 Gateview family - Cryaquolis complex.<br> 18 Rogert family, very stony.<br> 19 Typic Cryaquolis - Borohemists complex.<br> 20 Typic Cryaquepts - Typic Cryaquolls complex.<br> 21 Typic Cryaquolls - Leighcan family, till substratum complex.<br> 22 Leighcan family, till substratum, extremely bouldery.<br> 23 Leighcan family, till substratum - Typic Cryaquolls complex.<br> 24 Leighcan family, extremely stony.<br> 25 Leighcan family, warm, extremely stony.<br> 26 Granile - Catamount families complex, very stony.<br> 27 Leighcan family, warm - Rock outcrop complex, extremely stony.<br> 28 Leighcan family - Rock outcrop complex, extremely stony.<br> 29 Como - Legault families complex, extremely stony.<br> 30 Como family - Rock land - Legault family complex, extremely stony.<br> 31 Leighcan - Catamount families complex, extremely stony.<br> 32 Catamount family - Rock outcrop - Leighcan family complex, extremely stony.<br> 33 Leighcan - Catamount families - Rock outcrop complex, extremely stony.<br> 34 Cryorthents - Rock land complex, extremely stony.<br> 35 Cryumbrepts - Rock outcrop - Cryaquepts complex.<br> 36 Bross family - Rock land - Cryumbrepts complex, extremely stony.<br> 37 Rock outcrop - Cryumbrepts - Cryorthents complex, extremely stony.<br> 38 Leighcan - Moran families - Cryaquolls complex, extremely stony.<br> 39 Moran family - Cryorthents - Leighcan family complex, extremely stony.<br> 40 Moran family - Cryorthents - Rock land complex, extremely stony.<\/p><\/div><\/div><\/div>","0fd25a69":"Well... we have more data for the testing phase "}}