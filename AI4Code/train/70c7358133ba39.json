{"cell_type":{"f06cf637":"code","429c8042":"code","a06cbf0c":"code","71b05cdd":"code","3b232f4b":"code","00950129":"code","f3380b46":"code","b61c4335":"code","4c3ce932":"code","7260ad00":"code","b4276b6b":"code","bfac07ce":"code","d0fcc7d0":"code","18978775":"code","ddaf6b07":"code","3954a56c":"code","dba33d8b":"code","987252df":"code","4831df21":"code","c08ea457":"code","49667c53":"code","ffcca991":"code","665c46f1":"code","e4e043b5":"code","04bb8a80":"code","5acde63c":"code","9f295bad":"code","230542e2":"code","b1d8ceb1":"code","3df9f472":"code","24257829":"code","4cf55d86":"code","b89b4203":"code","59de9945":"code","b6deb191":"markdown","ac84f84c":"markdown","bdccd321":"markdown","789c5a51":"markdown","b99f87b2":"markdown","76b5059f":"markdown","7c2a3d85":"markdown"},"source":{"f06cf637":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","429c8042":"## get the full path name of the train_images and test_images \nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        break","a06cbf0c":"from pathlib import Path\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n%matplotlib inline\n\nfrom sklearn.utils import Bunch\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\n\nimport skimage\nfrom skimage.io import imread\nfrom skimage.transform import resize","71b05cdd":"import tensorflow as tf","3b232f4b":"## get the full path name of the train_images and test_images \nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        break","00950129":"def load_image_files(container_path, dimension=(224, 224)):\n    \"\"\"\n    Load image files with categories as subfolder names \n    which performs like scikit-learn sample dataset\n    \n    Parameters\n    ----------\n    container_path : string or unicode\n        Path to the main folder holding one subfolder per category\n    dimension : tuple\n        size to which image are adjusted to\n        \n    Returns\n    -------\n    Bunch\n    \"\"\"\n    image_dir = Path(container_path)\n    folders = [directory for directory in image_dir.iterdir() if directory.is_dir()]\n    categories = [fo.name for fo in folders]\n\n    descr = \"A image classification dataset\"\n    images = []\n    flat_data = []\n    target = []\n    for i, direc in enumerate(folders):\n        for file in direc.iterdir():\n            \n            img = skimage.io.imread(file) ## need to add in plugin for reading png images.\n            #img = img[:,:,:3]\n            img_resized = resize(img, dimension, anti_aliasing=True, mode='reflect')\n            #flat_data.append(img_resized.flatten()) \n            flat_data.append(img_resized)\n            images.append(img_resized)\n            target.append(i)\n    flat_data = np.array(flat_data)\n    target = np.array(target)\n    images = np.array(images)\n\n    return Bunch(data=flat_data,\n                 target=target,\n                 target_names=categories,\n                 images=images,\n                 DESCR=descr)","f3380b46":"train_data = load_image_files(\"\/kaggle\/input\/autistic-children-data-set-traintestvalidate\/train\")","b61c4335":"len(train_data['images'])","4c3ce932":"train_data['target_names']","7260ad00":"train_data['images'][0].shape","b4276b6b":"plt.figure()\nplt.imshow(train_data['images'][0])\nplt.colorbar()\nplt.grid(False)\nplt.show()","bfac07ce":"## read in validation  data \nvalid_data = load_image_files(\"\/kaggle\/input\/autistic-children-data-set-traintestvalidate\/valid\")","d0fcc7d0":"## read in test data \ntest_data = load_image_files(\"\/kaggle\/input\/autistic-children-data-set-traintestvalidate\/test\")","18978775":"len(valid_data['images'])","ddaf6b07":"len(test_data['images'])","3954a56c":"class myCallback(tf.keras.callbacks.Callback):\n    \n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('accuracy')>0.9):\n            print(\"\\nReached 90% accuracy so cancelling training!\")\n            self.model.stop_training = True\n\ncallbacks = myCallback()","dba33d8b":"train_data.keys()","987252df":"train_data['target'].shape","4831df21":"def get_labels(prob_model, images):\n    predictions = prob_model.predict(images)\n\n    ## based on the max value of probability , predict the class.\n    predicted_labels = []\n    for i in range(len(predictions)):\n        pred_label = np.argmax(predictions[i])\n        predicted_labels.append(pred_label)\n    return predicted_labels\n","c08ea457":"# Create a list with the filepaths for training and testing\ntrain_img_Path = \"\/kaggle\/input\/autistic-children-data-set-traintestvalidate\/train\"\n\nvalid_img_Path = \"\/kaggle\/input\/autistic-children-data-set-traintestvalidate\/valid\"\n\ntest_img_Path = \"\/kaggle\/input\/autistic-children-data-set-traintestvalidate\/test\"\n\n\n#img_Path = '..\/input\/resized-plant2021\/img_sz_256'\nprint(train_img_Path)\nprint(valid_img_Path)\nprint(test_img_Path)\n","49667c53":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n#train_datagen = ImageDataGenerator(\n        #rescale=1.\/255,\n        #shear_range=0.2,\n        #zoom_range=0.2,\n        #horizontal_flip=True)\ntrain_datagen = ImageDataGenerator(\n        rescale=1.\/255\n        )\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\ntrain_generator = train_datagen.flow_from_directory(\n        train_img_Path,\n        target_size=(224, 224),\n        batch_size=32,\n        class_mode = 'binary',\n        shuffle = 'False'\n        )\nvalidation_generator = test_datagen.flow_from_directory(\n        valid_img_Path,\n        target_size=(224, 224),\n        batch_size=32,\n        class_mode = 'binary',\n    shuffle = 'False'\n        )\ntest_generator = test_datagen.flow_from_directory(\n        test_img_Path,\n        target_size=(224, 224),\n        batch_size=32,\n        class_mode = 'binary',\n    shuffle = 'False'\n        )","ffcca991":"dict_classes = train_generator.class_indices\ndict_classes","665c46f1":"## model with data_generator \nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D( activation='relu', input_shape=(224, 224, 3), filters = 64, kernel_size = 3),\n    tf.keras.layers.MaxPooling2D(pool_size = (2,2), strides = (2, 2)),\ntf.keras.layers.Flatten(),\ntf.keras.layers.Dense(128, activation=tf.nn.relu),\ntf.keras.layers.Dense(2, activation=tf.nn.softmax)])\n\n\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'], )\nhistory = model.fit(train_generator, epochs=50,validation_data=validation_generator)\n##\ntest_loss, test_acc = model.evaluate(test_generator)\nprint(\"Test image accuracy :{}\".format(test_acc))\n##\nplt.plot(history.history['accuracy'], '-o' ,label='accuracy')\nplt.plot(history.history['val_accuracy'], '-o', label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0.5, 1])\nplt.legend(loc='lower right')","e4e043b5":"plt.plot(history.history['accuracy'], '-o' ,label='accuracy')\nplt.plot(history.history['val_accuracy'], '-o', label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0.5, 1])\nplt.legend(loc='lower right')","04bb8a80":"## model with data_generator and dropout of 0.2 .\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D( activation='relu', input_shape=(224, 224, 3), filters = 64, kernel_size = 3),\n    tf.keras.layers.MaxPooling2D(pool_size = (2,2), strides = (2, 2)),\n    tf.keras.layers.Dropout(0.2),\ntf.keras.layers.Flatten(),\ntf.keras.layers.Dense(128, activation=tf.nn.relu),\ntf.keras.layers.Dense(2, activation=tf.nn.softmax)])\n\n\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'], )\nhistory = model.fit(train_generator, epochs=50,validation_data=validation_generator)\n##\ntest_loss, test_acc = model.evaluate(test_generator)\nprint(\"Test image accuracy :{}\".format(test_acc))\n##\nplt.plot(history.history['accuracy'], '-o' ,label='accuracy')\nplt.plot(history.history['val_accuracy'], '-o', label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0.5, 1])\nplt.legend(loc='lower right')","5acde63c":"probability_model = tf.keras.Sequential([model, \n                                         tf.keras.layers.Softmax()])\n\n\npredictions = model.predict(test_data['data'] , batch_size = 32)\n\n## based on the max value of probability , predict the class.\ntest_predicted_labels = []\nfor i in range(len(predictions)):\n    pred_label = np.argmax(predictions[i])\n    test_predicted_labels.append(pred_label)\n","9f295bad":"print(\"Classification report :\\n{}\\n\".format(\n     classification_report(test_data['target'], test_predicted_labels)))","230542e2":"base_Net = tf.keras.applications.VGG16(include_top = False, \n                         weights ='imagenet', \n                         input_shape = train_generator.image_shape, \n                         pooling='avg',\n                         )","b1d8ceb1":"#Adding the final layers to the above base models where the actual classification is done in the dense layers\nmodel_Net = tf.keras.models.Sequential()\nmodel_Net.add(base_Net)\nmodel_Net.add(tf.keras.layers.Dense(1, activation=tf.nn.sigmoid))\n\nmodel_Net.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\nmodel_Net.summary()\n\n# Training the CNN on the Train data and evaluating it on the val data\n%time history = model_Net.fit(train_generator, validation_data = validation_generator, epochs = 50)\n##\ntest_loss, test_acc = model_Net.evaluate(test_generator)\nprint(\"Test image accuracy :{}\".format(test_acc))\n##\nplt.plot(history.history['accuracy'], '-o' ,label='accuracy')\nplt.plot(history.history['val_accuracy'], '-o', label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0, 1])\nplt.legend(loc='lower right')\n","3df9f472":"mob_Net = tf.keras.applications.MobileNet(include_top = False, \n                         weights =None, \n                         input_shape = train_generator.image_shape, \n                         pooling='avg',\n                         )\n#Adding the final layers to the above base models where the actual classification is done in the dense layers\nmobile_Net = tf.keras.models.Sequential()\nmobile_Net.add(mob_Net)\nmobile_Net.add(tf.keras.layers.Dense(1, activation=tf.nn.sigmoid))\n\nmobile_Net.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\nmobile_Net.summary()\n\n# Training the CNN on the Train data and evaluating it on the val data\n%time history = mobile_Net.fit(train_generator, validation_data = validation_generator, epochs = 50)\n##\ntest_loss, test_acc = mobile_Net.evaluate(test_generator)\nprint(\"Test image accuracy :{}\".format(test_acc))\n##\nplt.plot(history.history['accuracy'], '-o' ,label='accuracy')\nplt.plot(history.history['val_accuracy'], '-o', label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0, 1])\nplt.legend(loc='lower right')","24257829":"## input image size needs to be in (299,299,3)\ntrain_generator = train_datagen.flow_from_directory(\n        train_img_Path,\n        target_size=(299, 299),\n        batch_size=32,\n        class_mode = 'binary',\n        shuffle = 'False'\n        )\nvalidation_generator = test_datagen.flow_from_directory(\n        valid_img_Path,\n        target_size=(299, 299),\n        batch_size=32,\n        class_mode = 'binary',\n    shuffle = 'False'\n        )\ntest_generator = test_datagen.flow_from_directory(\n        test_img_Path,\n        target_size=(299, 299),\n        batch_size=32,\n        class_mode = 'binary',\n    shuffle = 'False'\n        )\n##\nir_Net = tf.keras.applications.InceptionResNetV2(include_top = False, \n                         weights =None, \n                         input_shape = train_generator.image_shape, \n                         pooling='avg',\n                         )\n#Adding the final layers to the above base models where the actual classification is done in the dense layers\nin_r_Net = tf.keras.models.Sequential()\nin_r_Net.add(ir_Net)\nin_r_Net.add(tf.keras.layers.Dense(1, activation=tf.nn.sigmoid))\n\nin_r_Net.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\nin_r_Net.summary()\n\n# Training the CNN on the Train data and evaluating it on the val data\n%time history = in_r_Net.fit(train_generator, validation_data = validation_generator, epochs = 50)\n##\ntest_loss, test_acc = in_r_Net.evaluate(test_generator, batch_size = 1)\nprint(\"Test image accuracy :{}\".format(test_acc))\n##\nplt.plot(history.history['accuracy'], '-o' ,label='accuracy')\nplt.plot(history.history['val_accuracy'], '-o', label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0, 1])\nplt.legend(loc='lower right')","4cf55d86":"test_data.keys()","b89b4203":"test_data['target']","59de9945":"## check for f1 score for both the classes. \ntest_predictions = in_r_Net.predict(test_data['data'], batch_size = 32)\n## based on the max value of probability , predict the class.\ntest_predicted_labels = []\nfor i in range(len(test_predictions)):\n    #pred_label = np.argmax(test_predictions[i])\n    if test_predictions[i] < 0.5:\n        pred_label = 0\n    else:\n        pred_label = 1 \n    test_predicted_labels.append(pred_label)\n##\nprint(\"Classification report :\\n{}\\n\".format(\n     classification_report(test_data['target'], test_predicted_labels)))","b6deb191":"Its'seen that using the pre-trained model architecture , we can increase the accuracy from 0.81 to 0.86 as shown above.  ","ac84f84c":"Test set image accuracy of MobileNet architecture is  slightly increased to 0.835 as compared to 0.81 with a single convolution layer.     \n","bdccd321":"Check if we can increase the accuracy by using some of the pre-trained models.","789c5a51":"Try transfer learning with another pre-trained model InceptionResnetV2.  ","b99f87b2":"VGG16 model structure is not suitable for the given image dataset.  ","76b5059f":"Droput rate has increased the accuracy.  ","7c2a3d85":"Select a lighter model such as MobileNet."}}