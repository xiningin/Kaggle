{"cell_type":{"24ef2bcc":"code","e00365b1":"code","9220dd5b":"code","3b6d0ead":"code","792dccba":"code","118e9a52":"code","f414e706":"code","4606c420":"code","c00f321c":"code","6cfdf047":"code","35deb2c2":"code","064edfd6":"code","ce55391e":"code","1e00f48c":"code","668d2bb3":"code","63c7fc07":"code","9abeff11":"code","765dde03":"code","618fc700":"code","1682d11f":"code","56ef56de":"code","261d2823":"code","8fcbcec2":"code","f4848a07":"code","d022f2fe":"code","f7c52a89":"code","09aab803":"code","5537a140":"code","15f294c8":"code","87f72272":"code","f9984555":"code","d302831a":"code","b0c45eee":"code","fec2e6ea":"code","e8f20545":"code","a4ec4b9e":"code","e1652736":"code","f25b19c5":"code","cef7ece5":"code","c71d9f14":"markdown","8bfd2d50":"markdown","cf660c1c":"markdown","fb0d9ef2":"markdown","148251f6":"markdown","eb952abe":"markdown","8da5b866":"markdown","d425785a":"markdown","337f6a9f":"markdown","7abb1a4c":"markdown","108977ab":"markdown","e92a1f9a":"markdown","b06475c6":"markdown"},"source":{"24ef2bcc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e00365b1":"df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')","9220dd5b":"df.head()","3b6d0ead":"df.isnull()","792dccba":"df.isnull().sum()","118e9a52":"import seaborn as sns\nsns.heatmap(df.isnull(), yticklabels= False, cbar=False, cmap='viridis')","f414e706":"#here we will see the statistic of Survived passangers\nsns.set_style('whitegrid')\nsns.countplot(x= 'Survived', data=df);\n","4606c420":"#Below code will output the Survived passanger according to gender (male and female).\nsns.set_style('whitegrid')\nsns.countplot(x= 'Survived',hue='Sex', data=df);","c00f321c":"#This code will show the result according to the class.\nsns.set_style('whitegrid')\nsns.countplot(x= 'Survived',hue='Pclass', data=df);","6cfdf047":"sns.distplot(df['Age'].dropna(), kde=False, color='darkred', bins=30);","35deb2c2":"df['Age'].hist(bins=30, color='darkred', alpha=0.5)","064edfd6":"sns.countplot(x= 'SibSp', data=df);","ce55391e":"import matplotlib.pyplot as plt\n%matplotlib inline","1e00f48c":"#Here we can check the average age by passenger class\nplt.figure(figsize = (12, 7))\nsns.boxplot(x = 'Pclass', y='Age', data=df, palette='winter');","668d2bb3":"def impute_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n        if Pclass == 1:\n            return 37\n        elif Pclass == 2:\n            return 29\n        else:\n            return 24\n    else:\n        return Age","63c7fc07":"df['Age'] = df[['Age','Pclass']].apply(impute_age, axis=1)","9abeff11":"sns.heatmap(df.isnull(), yticklabels=False, cbar=False, cmap='viridis')","765dde03":"df.drop('Cabin', axis=1, inplace=True)","618fc700":"df.head(3)","1682d11f":"df.dropna(inplace=True)","56ef56de":"df.info()","261d2823":"sex = pd.get_dummies(df['Sex'])","8fcbcec2":"df.head()","f4848a07":"sex = pd.get_dummies(df['Sex'], drop_first=True)\nembark = pd.get_dummies(df['Embarked'],drop_first=True)","d022f2fe":"df.drop(['Sex','Embarked','Name','Ticket'], axis=1, inplace=True)","f7c52a89":"df = pd.concat([df, sex,embark], axis=1)","09aab803":"df","5537a140":"df.columns","15f294c8":"df.dtypes","87f72272":"from sklearn.model_selection import train_test_split","f9984555":"train_test_split","d302831a":"X_train, X_test, y_train, y_test = train_test_split(df.drop('Survived', axis=1), df['Survived'], test_size=0.30, random_state=101)","b0c45eee":"from sklearn.linear_model import LogisticRegression","fec2e6ea":"logmodel = LogisticRegression()\nlogmodel.fit(X_train, y_train);","e8f20545":"predictions = logmodel.predict(X_test)","a4ec4b9e":"from sklearn.metrics import classification_report","e1652736":"print(classification_report(y_test, predictions))","f25b19c5":"from sklearn.metrics import confusion_matrix","cef7ece5":"confusion_matrix(y_test, predictions)","c71d9f14":"sum() function will show you the statistics of null value of every features.","8bfd2d50":"# Evaluation\nwe can check precision, recall, f1-score using calssification report!","cf660c1c":"## Missing Data\nwe will use seaborn library to create some visual like heatmap","fb0d9ef2":"### Dealing with missing values\nwe will define a function to filling the missing values on behaf of their mean which we will get from boxplot above ","148251f6":"## Training and Predicting ","eb952abe":"# Reading Data \nHere is our first line of code where we load the data and read the data of csv file (comma separated value) into pandas dataframe.","8da5b866":"# Building a Logistic Regression Model\nlet's start by splitting our data into train set and tes set.\n## Train Test Split","d425785a":"## Null value checking\nthrough this line of code we are checking the null values in the data frame\nwhere False mean no null value and True means null values","337f6a9f":"# Exploratory Data Analysis\nlet's begin exploratory data analysis.\nWe will start by checking our missing data!\n","7abb1a4c":"Here 0 means no any sibling or partners 1 mean one partner and so on..","108977ab":"In the above map the yellow line shows the missing values so the Age and Cabin has missing values.","e92a1f9a":"## Converting Categorical Features\nwe will need to convert categorical feature to dummy variable using pandas! otherwise our machine learning algorithm won't be able to direct take in those features as inputs.","b06475c6":"# Data Cleaning\nthe first and most work here is filling the missing values so we will fill the missing value instead of dropping."}}