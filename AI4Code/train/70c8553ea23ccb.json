{"cell_type":{"8b08484c":"code","8231506a":"code","b84a51ff":"code","e93e7e29":"code","092ce657":"code","8bdb6c6b":"code","bc365392":"code","ccec392b":"code","c78a320a":"code","607e4f23":"code","3257980a":"code","7af4ecb8":"code","5c6f6de9":"code","5d82a1c7":"code","b4e0dadd":"code","2de8ee1e":"code","92f750e9":"code","923c8c0a":"code","c6eaf3e7":"code","3a34f891":"code","61e86a17":"code","860fd81e":"code","561cc7fc":"code","851117fe":"code","65a0f482":"code","a5a60cb2":"code","10a78be5":"code","a9a6e328":"markdown","748064f4":"markdown","410d49a3":"markdown","6787269d":"markdown","724c5600":"markdown","ac0b043e":"markdown","32d053c9":"markdown","1acfb719":"markdown","29306133":"markdown","38b910fb":"markdown","bd931cc4":"markdown","0d2c6882":"markdown","3d48fd3f":"markdown","f43257bb":"markdown","711a6a0b":"markdown","409445bd":"markdown","dab932c1":"markdown","2eb3e351":"markdown","e5620d95":"markdown","ed33cb9f":"markdown","9192a758":"markdown","b19465e8":"markdown"},"source":{"8b08484c":"import nltk\nimport string\nimport re\nimport sklearn\nimport pandas as pd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler, OrdinalEncoder\nfrom sklearn.cluster import MiniBatchKMeans\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import Pipeline\nfrom scipy import stats\n#nltk.download('stopwords') #<---uncomment if you haven't downloaded the stopwords library\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)","8231506a":"# Load dataset into a pandas dataframe\ndf_reviews_raw = pd.read_csv('\/kaggle\/input\/dataset-of-malicious-and-benign-webpages\/Webpages_Classification_train_data.csv\/Webpages_Classification_train_data.csv').drop(['Unnamed: 0'], axis=1)","b84a51ff":"# Inspect for missing values\ndf_reviews_raw.isna().sum()","e93e7e29":"# Check data types\ndf_reviews_raw.dtypes","092ce657":"# Inspect a small sample\ndf_reviews_raw.head()","8bdb6c6b":"# Check the label distribution\ndf_reviews_raw.label.describe()","bc365392":"# Get an equally distributed sample\ndf_reviews_untrimmed_sample = df_reviews_raw.groupby('label').apply(lambda x: x.sample(25000, random_state=42)).reset_index(drop=True)\n# Remove if content has less than 60 words\ndf_reviews_trimmed = df_reviews_untrimmed_sample[df_reviews_untrimmed_sample.content.str.split().str.len().ge(60)]\ndf_reviews_trimmed.label.describe()","ccec392b":"# Resample trimmed dataframe to make it uniformly distributed\ndf_reviews_sampled = df_reviews_trimmed.groupby('label').apply(lambda x: x.sample(2000, random_state=42)).reset_index(drop=True)\n# Randomly shuffle rows for aesthetics\ndf_reviews = df_reviews_sampled.sample(frac=1, random_state=42).reset_index(drop=True)\ndf_reviews.label.describe()","c78a320a":"df_reviews.head()","607e4f23":"df_reviews[['geo_loc', 'tld','who_is','https', 'label']].describe()","3257980a":"df_reviews['geo_loc'] = OrdinalEncoder().fit_transform(df_reviews.geo_loc.values.reshape(-1,1))\ndf_reviews['tld'] = OrdinalEncoder().fit_transform(df_reviews.tld.values.reshape(-1,1))\ndf_reviews['who_is'] = OrdinalEncoder().fit_transform(df_reviews.who_is.values.reshape(-1,1))\ndf_reviews['https'] = OrdinalEncoder().fit_transform(df_reviews.https.values.reshape(-1,1))\ndf_reviews['label'] = OrdinalEncoder().fit_transform(df_reviews.label.values.reshape(-1,1))\n\n# convert url into human readable string that can be tokenized\ndf_reviews['url'] = df_reviews.url.apply(lambda x: ' '.join(x.split(':\/\/')[1].strip('www.').replace('.','\/').split('\/')))\ndf_reviews.head()","7af4ecb8":"print(\"Before Preprocessing:\")\nprint(df_reviews.content.head())\n\ntqdm.pandas()\nstop = stopwords.words()\n\ndf_reviews.content = df_reviews.content.str.replace(\"[^\\w\\s]\", \"\").str.lower()\ndf_reviews.content = df_reviews.content.progress_apply(lambda x: ' '.join([item for item in x.split() \n                                                               if item not in stop]))\ndf_reviews.url = df_reviews.url.str.replace(\"[^\\w\\s]\", \"\").str.lower()\ndf_reviews.url = df_reviews.url.progress_apply(lambda x: ' '.join([item for item in x.split() \n                                                               if item not in stop]))\n\nprint(\"After Preprocessing:\")\nprint(df_reviews.content.head())","5c6f6de9":"tfidf = TfidfVectorizer(\n    min_df = 5,\n    max_df = 0.95,\n    max_features = 8000,\n    stop_words = 'english'\n)\n\ntfidf.fit(df_reviews.url)\nurl_tfidf = tfidf.transform(df_reviews.url)\n\ntfidf.fit(df_reviews.content)\ncontent_tfidf = tfidf.transform(df_reviews.content)","5d82a1c7":"def find_optimal_clusters(data, max_k):\n    k_list = range(2, max_k+1)\n    \n    sse = []\n    for k in k_list:\n        sse.append(MiniBatchKMeans(n_clusters=k, init_size=1024, batch_size=2048, random_state=20).fit(data).inertia_)\n       \n    plt.style.use(\"dark_background\")\n    f, ax = plt.subplots(1, 1)\n    ax.plot(k_list, sse, marker='o')\n    ax.set_xlabel('Cluster Centers')\n    ax.set_xticks(k_list)\n    ax.set_xticklabels(k_list)\n    ax.set_ylabel('SSE')\n    ax.set_title('SSE by Cluster Center Plot')","b4e0dadd":"find_optimal_clusters(url_tfidf, 20)","2de8ee1e":"df_reviews['url_cluster'] = MiniBatchKMeans(n_clusters=8, init_size=1024, batch_size=2048, \n                                            random_state=20).fit_predict(url_tfidf)","92f750e9":"find_optimal_clusters(content_tfidf, 20)","923c8c0a":"df_reviews['content_cluster'] = MiniBatchKMeans(n_clusters=4, init_size=1024, batch_size=2048, \n                                            random_state=20).fit_predict(content_tfidf)","c6eaf3e7":"X = df_reviews[['url_cluster', 'url_len', 'geo_loc', 'tld', 'who_is', 'https', 'content_cluster',\n                'js_len', 'js_obf_len']]\ny = df_reviews.label\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","3a34f891":"# Decision Tree\nparam_grid=[{\"criterion\":[\"gini\", \"entropy\"],\n             \"splitter\":[\"best\", \"random\"]}]\ngrid=GridSearchCV(estimator=DecisionTreeClassifier(random_state=42),param_grid=param_grid,cv=5)\ngrid.fit(X_train,y_train)","61e86a17":"# Optimal hyperparameters\ngrid.best_params_","860fd81e":"# training accuracy\ngrid.score(X_train,y_train)","561cc7fc":"# test accuracy\ngrid.score(X_test,y_test)","851117fe":"# Random Forest\nparam_grid=[{\"n_estimators\":[x for x in range(10, 120, 10)],\n             \"criterion\":[\"gini\", \"entropy\"]}]\ngrid=GridSearchCV(estimator=RandomForestClassifier(random_state=42),param_grid=param_grid,cv=5)\ngrid.fit(X_train,y_train)","65a0f482":"# Optimal hyperparameters\ngrid.best_params_","a5a60cb2":"# training accuracy\ngrid.score(X_train,y_train)","10a78be5":"# test accuracy\ngrid.score(X_test,y_test)","a9a6e328":"### Import the dataset\u00b6","748064f4":"Training and test accuracies are examined to determine if overfitting or underfitting has occurred.","410d49a3":"### Conclusion","6787269d":"### Clean the data\u00b6","724c5600":"### Text Preprocessing\u00b6","ac0b043e":"The textual data in the url and content columns will be tokenized, converted to lower case, and stopwords and punctuation will be removed.","32d053c9":"### Model selection\u00b6","1acfb719":"I will use the elbow method to find the optimal number of clusters for each feature.","29306133":"\nTo use our decision tree and random forest models, the data will need to be in a numerical format. As the value of one row with respect to another doesn't have an affect on either algorithm's decision when splitting a node (they are considered categorical variables), I will use ordinal encoding to transform the geo_loc, tld, who_is, https, and label columns. Meanwhile, natural language processing will be performed on the url and content columns.","38b910fb":"Both algorithms performed exceptionally well and there is no evidence of overfitting or underfitting. This project serves as validation for using unsupervised learning for labeling textual data and the decision tree and\/or random forest algorithms for identifying malicious webpages.","bd931cc4":"An elbow can be seen where n_clusters equals nine. A new column, full of the clusters each row is assigned to, will be made.","0d2c6882":"### Generate a training and test dataset\u00b6","3d48fd3f":"### Examine the data\u00b6","f43257bb":"\nTo convert the widely varying content of the url and content columns into something more manageable for the decision tree and random forest models, I will label them using mini batch kmeans clustering. First, however, I will convert them into numeric vectors.","711a6a0b":"### Label urls and content using tfidf vectorization and clustering\u00b6","409445bd":"\nThe data must be cleaned and transformed into a format that the machine learning algorithms further down in this notebook expect. Furthermore, there should be a uniform distribution of labels.","dab932c1":"For the decision tree, the \"criterion\" and \"splitter\" hyperparameters will be tuned and cross-validation will be performed using the GridSearchCV sklearn module.","2eb3e351":"The cleaned, transformed dataset will be split into a training and test set using a 70%\/30% split.","e5620d95":"Training and test accuracies are examined to determine if overfitting or underfitting has occurred.","ed33cb9f":"### Malicious Webpage Identification Using Semi Supervised Learning\n\nAlex Liddle","9192a758":"An elbow can be seen where n_clusters equals four. A new column, full of the clusters each row is assigned to, will be made.","b19465e8":"For the random forest, the \"n_estimators\" and \"criterion\" hyperparameters will be tuned and cross-validation will be performed using the GridSearchCV sklearn module."}}