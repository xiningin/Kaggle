{"cell_type":{"971970a5":"code","3f425823":"code","586693f8":"code","286743a6":"code","48e53644":"code","e80ba2cf":"code","b053797c":"code","99a84e2c":"code","7314226b":"code","540485b7":"code","56fb3f53":"code","68b84d1f":"code","e18a49bd":"code","33a2e598":"code","fcc12b7f":"code","68056074":"code","dc8d6dae":"code","fcd12ee0":"code","d102fc51":"code","a47c2b31":"code","40b8124a":"code","84ba5f6b":"code","bac5bace":"code","00bed280":"code","742a1148":"code","7a0a552d":"code","c480f92c":"code","132b2cbf":"code","f875337f":"code","c1298331":"code","29b373e1":"code","25a0c9f7":"code","dcdb3d85":"markdown"},"source":{"971970a5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3f425823":"#!pip install tensorflow\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split","586693f8":"train = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")\ntrain.head()","286743a6":"train[\"label\"].value_counts()","48e53644":"y_train = train['label'].astype('float32')\nX_train = train.drop(['label'], axis=1).astype('int32')\nX_test = test.astype('float32')\nX_train.shape, y_train.shape, X_test.shape","e80ba2cf":"#Data Normalization\nX_train = X_train\/255\nX_test = X_test\/255","b053797c":"X_train = X_train.values.reshape(-1,28,28,1)\nX_test = X_test.values.reshape(-1,28,28,1)\nX_train.shape, X_test.shape","99a84e2c":"# one-hot encoding\ny_train = to_categorical(y_train, num_classes = 10)\ny_train.shape","7314226b":"X_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train, test_size = 0.1, random_state=42)\nX_train","540485b7":"plt.imshow(X_train[0][:,:,0])\nplt.title(y_train[0].argmax());","56fb3f53":"from keras.layers import Input,InputLayer, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import AveragePooling2D, MaxPooling2D, Dropout\nfrom keras.models import Sequential,Model\nfrom tensorflow.keras.optimizers import SGD\nfrom keras.callbacks import ModelCheckpoint,LearningRateScheduler\nimport keras\nfrom keras import backend as K","68b84d1f":"# Building a CNN model\ninput_shape = (28,28,1)\nX_input = Input(input_shape)\n\n# layer 1\nx = Conv2D(32,(3,3),strides=(1,1),name='layer_conv1',padding='same')(X_input)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\nx = MaxPooling2D((2,2),name='maxPool1')(x)\n# layer 2\nx = Conv2D(32,(3,3),strides=(1,1),name='layer_conv2',padding='same')(x)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\nx = MaxPooling2D((2,2),name='maxPool2')(x)\n# layer 3\nx = Conv2D(64,(3,3),strides=(1,1),name='conv3',padding='same')(x)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\nx = MaxPooling2D((2,2), name='maxPool3')(x)\n# fc\nx = Flatten()(x)\nx = Dense(64,activation ='relu',name='fc0')(x)\nx = Dropout(0.25)(x)\nx = Dense(32,activation ='relu',name='fc1')(x)\nx = Dropout(0.25)(x)\nx = Dense(10,activation ='softmax',name='fc2')(x)\n\nconv_model = Model(inputs=X_input, outputs=x, name='Predict')\nconv_model.summary()","e18a49bd":"# Adam optimizer\nconv_model.compile(optimizer=\"adam\",loss='categorical_crossentropy',metrics=['accuracy'])\nconv_model.fit(X_train, y_train, epochs=20, batch_size=100, validation_data=(X_cv,y_cv))","33a2e598":"y_pred = conv_model.predict(X_test)\ny_pred = np.argmax(y_pred,axis=1)\nmy_submission = pd.DataFrame({'ImageId': list(range(1, len(y_pred)+1)), 'Label': y_pred})\nmy_submission.to_csv('submission.csv', index=False)","fcc12b7f":"train_half = train[:21000]\ntest_half = train.iloc[21000:, 1:]","68056074":"train_half_digits = train[train.label < 5]\ntest_half_digits = train[train.label >= 5]\ntest_half_digits = test_half_digits.iloc[:,1:]","dc8d6dae":"y_train_half = train_half['label'].astype('float32')\nX_train_half = train_half.drop(['label'], axis=1).astype('int32')\nX_test_half = test_half.astype('float32')\nX_train_half.shape, y_train_half.shape, X_test_half.shape","fcd12ee0":"#Data Normalization\nX_train_half = X_train_half\/255\nX_test_half = X_test_half\/255","d102fc51":"X_train_half = X_train_half.values.reshape(-1,28,28,1)\nX_test_half = X_test_half.values.reshape(-1,28,28,1)\nX_train_half.shape, X_test_half.shape","a47c2b31":"# one-hot encoding\ny_train_half = to_categorical(y_train_half, num_classes = 10)\ny_train_half.shape","40b8124a":"X_train_half, X_cv_half, y_train_half, y_cv_half = train_test_split(X_train_half, y_train_half, test_size = 0.1, random_state=42)\nX_train_half","84ba5f6b":"# Building a CNN model\ninput_shape = (28,28,1)\nX_input = Input(input_shape)\n\n# layer 1\nx = Conv2D(32,(3,3),strides=(1,1),name='layer_conv1',padding='same')(X_input)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\nx = MaxPooling2D((2,2),name='maxPool1')(x)\n# layer 2\nx = Conv2D(32,(3,3),strides=(1,1),name='layer_conv2',padding='same')(x)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\nx = MaxPooling2D((2,2),name='maxPool2')(x)\n# layer 3\nx = Conv2D(64,(3,3),strides=(1,1),name='conv3',padding='same')(x)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\nx = MaxPooling2D((2,2), name='maxPool3')(x)\n# fc\nx = Flatten()(x)\nx = Dense(64,activation ='relu',name='fc0')(x)\nx = Dropout(0.25)(x)\nx = Dense(32,activation ='relu',name='fc1')(x)\nx = Dropout(0.25)(x)\nx = Dense(10,activation ='softmax',name='fc2')(x)\n\nconv_model = Model(inputs=X_input, outputs=x, name='Predict')\nconv_model.summary()","bac5bace":"# Adam optimizer\nconv_model.compile(optimizer=\"adam\",loss='categorical_crossentropy',metrics=['accuracy'])\nconv_model.fit(X_train_half, y_train_half, epochs=20, batch_size=100, validation_data=(X_cv_half,y_cv_half))\ny_pred_half = conv_model.predict(X_test_half)\ny_pred_half = np.argmax(y_pred_half,axis=1)","00bed280":"my_submission_half = pd.DataFrame({'ImageId': list(range(1, len(y_pred_half)+1)), 'Prediction': y_pred_half, \"Testing Correct Answer\": train.label[21000:]})\nmy_submission_half\n\nwrong_answers = my_submission_half[my_submission_half['Prediction'] != my_submission_half['Testing Correct Answer']]\nwrong_answers\n\n#98.54% accurate","742a1148":"y_train_half_digits = train_half_digits['label'].astype('float32')\nX_train_half_digits = train_half_digits.drop(['label'], axis=1).astype('int32')\nX_test_half_digits = test_half_digits.astype('float32')\nX_train_half_digits.shape, y_train_half_digits.shape, X_test_half_digits.shape","7a0a552d":"#Data Normalization\nX_train_half_digits = X_train_half_digits\/255\nX_test_half_digits = X_test_half_digits\/255","c480f92c":"X_train_half_digits = X_train_half_digits.values.reshape(-1,28,28,1)\nX_test_half_digits = X_test_half_digits.values.reshape(-1,28,28,1)\nX_train_half_digits.shape, X_test_half_digits.shape","132b2cbf":"# one-hot encoding\ny_train_half_digits = to_categorical(y_train_half_digits, num_classes = 10)\ny_train_half_digits.shape","f875337f":"X_train_half_digits, X_cv_half_digits, y_train_half_digits, y_cv_half_digits = train_test_split(X_train_half_digits, y_train_half_digits, test_size = 0.1, random_state=42)\nX_train_half_digits","c1298331":"# Building a CNN model\ninput_shape = (28,28,1)\nX_input = Input(input_shape)\n\n# layer 1\nx = Conv2D(32,(3,3),strides=(1,1),name='layer_conv1',padding='same')(X_input)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\nx = MaxPooling2D((2,2),name='maxPool1')(x)\n# layer 2\nx = Conv2D(32,(3,3),strides=(1,1),name='layer_conv2',padding='same')(x)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\nx = MaxPooling2D((2,2),name='maxPool2')(x)\n# layer 3\nx = Conv2D(64,(3,3),strides=(1,1),name='conv3',padding='same')(x)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\nx = MaxPooling2D((2,2), name='maxPool3')(x)\n# fc\nx = Flatten()(x)\nx = Dense(64,activation ='relu',name='fc0')(x)\nx = Dropout(0.25)(x)\nx = Dense(32,activation ='relu',name='fc1')(x)\nx = Dropout(0.25)(x)\nx = Dense(10,activation ='softmax',name='fc2')(x)\n\nconv_model = Model(inputs=X_input, outputs=x, name='Predict')\nconv_model.summary()","29b373e1":"# Adam optimizer\nconv_model.compile(optimizer=\"adam\",loss='categorical_crossentropy',metrics=['accuracy'])\nconv_model.fit(X_train_half_digits, y_train_half_digits, epochs=20, batch_size=100, validation_data=(X_cv_half_digits,y_cv_half_digits))\ny_pred_half_digits = conv_model.predict(X_test_half_digits)\ny_pred_half_digits = np.argmax(y_pred_half_digits,axis=1)","25a0c9f7":"my_submission_half_digits = pd.DataFrame({'ImageId': list(range(1, len(y_pred_half_digits)+1)), 'Prediction': y_pred_half_digits, \"Testing Correct Answer\": train[train.label >= 5].label})\nmy_submission_half_digits\n\nwrong_answers_digits = my_submission_half_digits[my_submission_half_digits['Prediction'] != my_submission_half_digits['Testing Correct Answer']]\nwrong_answers_digits\n\n#0% accurate","dcdb3d85":"Entire notebook inspired by https:\/\/github.com\/sriram2397\/digit-recognizer-kaggle\/blob\/master\/Digit_Recognizer.ipynb\n\nSources:\nhttps:\/\/www.kaggle.com\/kaggle2007\/mnist-digit-recognizer-simple-solutions\nhttps:\/\/www.analyticsvidhya.com\/blog\/2021\/05\/convolutional-neural-networks-cnn\/\nhttps:\/\/www.pyimagesearch.com\/2018\/12\/31\/keras-conv2d-and-convolutional-layers\/\nhttps:\/\/www.sas.com\/en_us\/insights\/analytics\/neural-networks.html#:~:text=Neural%20networks%20are%20computing%20systems,time%20%E2%80%93%20continuously%20learn%20and%20improve\nhttps:\/\/www.ibm.com\/topics\/computer-vision\nhttps:\/\/machinelearningmastery.com\/difference-between-a-batch-and-an-epoch\/#:~:text=at%20an%20epoch.-,What%20Is%20an%20Epoch%3F,update%20the%20internal%20model%20parameters"}}