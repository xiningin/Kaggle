{"cell_type":{"c16f47a6":"code","c3946984":"code","f0088942":"code","fe0059b6":"code","8cef8035":"code","9860bd91":"code","81f97c39":"code","d6fcdffe":"code","aa653d1f":"code","28d24ea9":"code","bc15c591":"markdown","88438dd0":"markdown","cf830764":"markdown","784f6819":"markdown","92620cd1":"markdown"},"source":{"c16f47a6":"!conda install -c conda-forge -y librosa","c3946984":"import os\n\nimport librosa\nfrom scipy import signal\nfrom scipy.io import wavfile\nfrom sklearn.metrics import roc_auc_score\nimport numpy as np\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom tqdm import tqdm, trange","f0088942":"def load_mel(file_name, start=0, stop=None, n_mels=60):\n    '''Wczytuje mel spektrogram z pliku.\n    \n    Args:\n        file_name (str): Nazwa pliku z nagraniem.\n        start (float): Sekunda, w kt\u00f3rej zaczyna si\u0119 interesuj\u0105cy fragment.\n        stop (float): Sekunda, w kt\u00f3rej ko\u0144czy si\u0119 interesuj\u0105cy fragment.\n        n_mels (int): Liczba meli na spektrogramie (wysoko\u015b\u0107 spektrogramu).\n    \n    Returns:\n        ndarray: Spektrogram.\n    '''\n    samples, sample_rate = librosa.core.load(file_name, sr = None)\n    samples = samples[int(start * sample_rate):int(stop * sample_rate) if stop else None]\n    spectrogram = librosa.feature.melspectrogram(y = samples, sr = sample_rate,\n                                                 n_mels = n_mels, fmin = 4000, fmax = 9500)\n    return spectrogram\n\n\ndef load_spec(file_name, start=0, stop=None):\n    '''Wczytuje standardowy spektrogram z pliku.\n    \n    Args:\n        file_name (str): Nazwa pliku z nagraniem.\n        start (float): Sekunda, w kt\u00f3rej zaczyna si\u0119 interesuj\u0105cy fragment.\n        stop (float): Sekunda, w kt\u00f3rej ko\u0144czy si\u0119 interesuj\u0105cy fragment.\n    \n    Returns:\n        ndarray: Spektrogram.\n    '''\n    sample_rate, samples = wavfile.read(file_name)\n    samples = samples[int(start * sample_rate):int(stop * sample_rate) if stop else None]\n    _, _, spectrogram = signal.spectrogram(samples, sample_rate)\n    return spectrogram\n\n\ndef load_test(load_repr=load_mel):\n    '''Wczytuje dane testowe.\n    \n    Args:\n        load_repr (function): Funkcja wczytuj\u0105ca po\u017c\u0105dan\u0105 reprezentacj\u0119.\n    \n    Returns:\n        ndarray: Tablica z danymi testowymi.\n    '''\n    with open('sampleSubmission.csv', 'r') as file:\n        lines = file.read().split()[1:]\n        sample_ids = [line.split(',')[0] for line in lines]\n        samples = np.array([s.split('\/') for s in sample_ids])\n    \n    X_test = []\n    rec_files = sorted([file_name for file_name in os.listdir('test') \n                        if file_name.endswith('.wav')], key=lambda x: int(x.split('.')[0][3:]))\n    for file_name in rec_files:\n        recording_id = file_name.split('.')[0][3:]\n        time_markers = samples[samples[:, 0] == recording_id, 1].astype(np.int)\n        for t in time_markers:\n            representation = load_repr(os.path.join('test', file_name), start = t, stop = t + 1)\n            X_test.append(representation)\n    return np.array(X_test)\n\n\ndef read_labels():\n    '''Wczytuje etykiety czasowe z pliku labels.txt w folderze train.\n    \n    Returns:\n        ndarray: Tablica z etykietami czasowymi zawieraj\u0105ca kolumny: nr nagrania, sekunda pocz\u0105tku d\u017awi\u0119ku, sekunda ko\u0144ca d\u017awi\u0119ku.\n    '''\n    labels = []\n    with open(os.path.join('train', 'labels.txt'), 'r') as file:\n        text = file.read()\n        for line in text.split('\\n')[1:]:\n            if len(line) > 1:\n                rec, start, stop = line.split(',')\n                rec, start, stop = int(rec[3:]), float(start), float(stop)\n                labels.append([rec, start, stop])\n    return np.array(labels)\n\n\ndef check_voices(second, labels, tol=0.):\n    '''Sprawdza czy w ramce czasowej [second, second+1] znajduje si\u0119 g\u0142os wed\u0142ug etykiet `labels`.\n    \n    Args:\n        second (float): Sekunda nagrania.\n        labels (ndarray): Tablica z etykietami, kt\u00f3rej 2 kolumna oznacza pocz\u0105tek, a 3-cia - koniec nagrania.\n        tol (float): Tolerancja na brzegach fragmentu. D\u017awi\u0119k, \u017ceby by\u0142 uznany, musi si\u0119 ko\u0144czy\u0107 po czasie `second+tol`\n            lub zaczyna\u0107 przed czasem `second+1-tol`.\n    Returns:\n        bool: Czy w ramce czasowej jest odg\u0142os ptaka.\n    '''\n    return (labels[1] >= second and labels[1] < second + 1 - tol) or \\\n           (labels[2] < second + 1 and labels[2] > second + tol) or \\\n           (labels[1] < second and labels[2] > second + 1)\n\n\ndef map_seconds_to_y(labels):\n    '''Tworzy etykiety dla ka\u017cdej kolejnej sekundy 10-sekundowego nagrania. -1 oznacza niepewn\u0105 etykiet\u0119 (urwane d\u017awi\u0119ki na brzegach).\n    \n    Args:\n        labels (ndarray): Tablica z etykietami, kt\u00f3rej 2 kolumna oznacza pocz\u0105tek, a 3-cia - koniec nagrania.\n    Returns:\n        ndarray: Tablica z binarnymi etykietami dla ka\u017cdej z 10 sekund z mo\u017cliw\u0105 niepewn\u0105 etkiet\u0105 -1.\n    '''\n    y = [0] * 10\n    y_restrictive = [0] * 10\n    for s in range(10):\n        for l in labels:\n            if check_voices(s, l):\n                y[s] = 1\n            if check_voices(s, l, 0.02):\n                y_restrictive[s] = 1\n        if y[s] != y_restrictive[s]:\n            y[s] = -1\n    return y\n\n\ndef load_train(load_repr=load_mel):\n    '''Wczytuje dane treningowe.\n    \n    Args:\n        load_repr (function): Funkcja wczytuj\u0105ca po\u017c\u0105dan\u0105 reprezentacj\u0119.\n    \n    Returns:\n        (ndarray, ndarray): Tablica z danymi treningowymi, tablica z binarnymi etykietami treningowymi.\n    '''\n    labels = read_labels()\n    X_train, y_train = [], []\n    rec_files = [file_name for file_name in os.listdir('train') if file_name.endswith('.wav')]\n    for file_name in rec_files:\n        recording_id = int(file_name.split('.')[0][3:])\n        recording_labels = labels[labels[:, 0] == recording_id]\n        y_binary = map_seconds_to_y(recording_labels)\n        for i, y in enumerate(y_binary):\n            if y != -1:\n                try:\n                    representation = load_repr(os.path.join('train', file_name), start = i, stop = i + 1)\n                    X_train.append(representation)\n                    y_train.append(y)\n                except ValueError:\n                    print('Error reading file', file_name)\n                except TypeError:\n                    print('Unsupported type', file_name)\n    return np.array(X_train), np.array(y_train)","fe0059b6":"# Poni\u017csza linijka ustawia folder g\u0142\u00f3wny\nos.chdir('..\/input\/')\n\nX_test = load_test()\n# np.save(os.path.join('test', 'tmp_X_test'), X_test)\n\nX, y = load_train()\n# np.save(os.path.join('train', 'tmp_X_train'), X)\n# np.save(os.path.join('train', 'tmp_y_train'), y)","8cef8035":"class Detector(torch.nn.Module):\n    \n    def __init__(self):\n        super().__init__()\n        self.linear = torch.nn.Linear(60 * 87, 2)\n    \n    def forward(self, x):\n        out = torch.flatten(x, start_dim = 1)\n        out = self.linear(out)\n        return out\n    \nclf = Detector()","9860bd91":"# Dzielenie zbioru danych na treningowy i walidacyjny\nsplit_point = int(len(X) * 0.8)\n\nX_train = torch.Tensor(X[:split_point])\ny_train = torch.LongTensor(y[:split_point])\n\nX_valid = torch.Tensor(X[split_point:])\ny_valid = torch.LongTensor(y[split_point:])\n\nbatch_size = 64\n\ndataset = TensorDataset(X_train, y_train)\ndata_loader = DataLoader(dataset, batch_size = batch_size, shuffle = True)\n\nvalid_dataset = TensorDataset(X_valid, y_valid)\nvalid_data_loader = DataLoader(valid_dataset, batch_size = batch_size)","81f97c39":"# Ustawienie kosztu i optimizera\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(clf.parameters())\n\n# P\u0119tla uczenia\nbest_preds, best_score = None, 0.\nlosses, scores = [], []\nfor epoch in trange(10):\n    running_loss = 0\n    clf.train()\n    for X, y in data_loader:\n        optimizer.zero_grad()\n\n        outputs = clf(X)\n        loss = criterion(outputs, y)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        \n    losses.append(running_loss)\n    \n    clf.eval()\n    preds = []\n    for X, _ in valid_data_loader:\n        out = clf(X)\n        preds.append(torch.softmax(out, dim = 1)[:, 1].detach().numpy())\n    preds = np.concatenate(preds, axis = 0)\n    \n    # Metryk\u0105 testuj\u0105c\u0105 jest ROC AUC\n    score = roc_auc_score(y_valid.numpy(), preds)\n    scores.append(score)\n    if score > best_score:\n        best_score = score\n        best_preds = preds\n        # np.save('tmp_preds', best_preds)\n        \n        # Model daj\u0105cy najlepszy wynik powinien by\u0107 zapisany\n        # torch.save(clf.state_dict(), 'tmp_model.pt')","d6fcdffe":"# Rysowanie lossu i AUC\n\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n\nplt.plot(scores)\nplt.show()\n\nplt.plot(losses)\nplt.show()","aa653d1f":"def save_predictions(preds):\n    '''Zapisuje predykcje do pliku zgodnego z formatem odpowiedzi.\n    \n    Args:\n        preds (list): Lista predykcji (prawdopodobie\u0144stw).\n    '''\n    with open('sampleSubmission.csv', 'r') as file:\n        submission_text = file.read().split()\n        header = submission_text[0]\n        lines = submission_text[1:]\n\n    output_lines = [header]\n    for pred, line in zip(preds, lines):\n        output_lines.append(\"{},{}\".format(line.split(',')[0], pred))\n    \n    with open('mySubmission.csv', 'w') as file:\n        file.write('\\n'.join(output_lines) + '\\n')","28d24ea9":"# Wczytanie najlepszego modelu\n# clf.load_state_dict('tmp_model.pt')\n\n# Tworzenie data loadera testowego\nX_test_tensor = torch.Tensor(X_test)\n\ntest_dataset = TensorDataset(X_test_tensor)\ntest_data_loader = DataLoader(test_dataset, batch_size = batch_size)\n\n# Ewaluacja modelu na danych testowych\nclf.eval()\npreds = []\nfor X in test_data_loader:\n    out = clf(X[0])\n    preds.append(torch.softmax(out, dim = 1)[:, 1].detach().numpy())\npreds = np.concatenate(preds, axis = 0)\n\n# Zapisanie predykcji do poprawnego formatu\n# save_predictions(preds)","bc15c591":"# Model i Trenowanie\n\nPoni\u017cszy przyk\u0142ad u\u017cywa poprawnych metryk i zapisuje parametry modelu.","88438dd0":"# Funkcje Pomocnicze do Zadania\n\nAby wszystkie funkcje zadzia\u0142a\u0142y, notebook powinien by\u0107 uruchamiany z nast\u0119puj\u0105cym u\u0142o\u017ceniem katalog\u00f3w:\n\n```\n|- helpers.ipynb\n|- sampleSubmission.csv\n|- train\n |- {unzipped train files and labels}\n|- test\n |- {unzipped test files}\n```\n\nNale\u017cy odkomentowa\u0107 u siebie linijki zapisuj\u0105ce pliki.","cf830764":"# Zapis Predykcji","784f6819":"# Zapisywanie Wczytanej Reprezentacji\n\nPoniewa\u017c tworzenie reprezentacji mo\u017ce zabiera\u0107 sporo czasu (szczeg\u00f3lnie w tak naiwnej implementacji jak powy\u017csza), warto zapisa\u0107 wczytane dane do plik\u00f3w.","92620cd1":"# Wczytywanie Danych\n\nPoni\u017csze funkcje s\u0105 przyk\u0142adowymi funkcjami wczytuj\u0105cymi dane. Mo\u017cliwe, \u017ce b\u0119d\u0105 potrzebne modyfikacje reprezentacji i bardziej skomplikowana funkcja tworz\u0105ca zbi\u00f3r treningowy. Wczytywanie danych nie jest zaimplementowane optymalnie - mi\u0119dzy innymi kod wczytuje wielokrotnie ten sam plik. Dla bardziej z\u0142o\u017conych reprezentacji mo\u017cliwe, \u017ce trzeba b\u0119dzie przepisa\u0107 te funkcje."}}