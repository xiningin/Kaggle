{"cell_type":{"5d45050b":"code","69312b93":"code","a8c6d8eb":"code","21e777b8":"code","621669ee":"code","eabedbac":"code","19950cce":"code","883870f9":"code","d9c5b589":"code","987f55f8":"code","9322dd9e":"code","4330f044":"code","a495e682":"code","1b4b76a1":"code","d287c066":"code","076c5211":"code","019f4d31":"code","3d6f2916":"code","7f59b725":"code","4f810677":"code","cc90a675":"code","5fd5f7e0":"code","fb051558":"code","7769bd40":"code","7802ee39":"code","8ec7b178":"code","69af5222":"code","fee1b947":"code","8f84d03f":"code","681a4498":"code","1287cfe0":"code","585764bb":"code","220c6a10":"code","6fcb9997":"code","793e1758":"code","c80eaa8b":"code","98f72d5a":"code","b751cc2d":"code","075b43c6":"code","d2e79d1e":"code","f2b23afc":"code","4cab7ff6":"code","c460ec12":"code","e4510b2c":"code","42aa8dca":"code","c58f169a":"code","a76107c4":"code","a719c294":"code","881a4bdc":"code","a174464f":"code","505e833c":"code","a751f8f7":"code","cdbb25ac":"code","ccb44f94":"code","3ebff1b9":"code","a67e1602":"markdown","36a151c4":"markdown"},"source":{"5d45050b":"# we begin by importing useful python packages\n!pip install worldmap\n\nimport worldmap as worldmap\nimport matplotlib.pyplot as plt\nimport matplotlib.colors \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns # plots\nimport matplotlib.pyplot as plt # plot\nimport numpy as np # numerical data\nimport scipy.stats as st # perform correlation calculation \nimport os\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","69312b93":"# Loading data from csv file into pandas dataframes\n\ned_stats_data = pd.read_csv('..\/input\/openclassrooms-project-2\/EdStatsData.csv', sep= ',')\ned_stats_footnote = pd.read_csv('..\/input\/openclassrooms-project-2\/EdStatsFootNote.csv', sep= ',')\ned_stats_series = pd.read_csv('..\/input\/openclassrooms-project-2\/EdStatsSeries.csv', sep= ',')\ned_stats_country = pd.read_csv('..\/input\/openclassrooms-project-2\/EdStatsCountry.csv', sep= ',')\ned_stats_country_series = pd.read_csv('..\/input\/openclassrooms-project-2\/EdStatsCountry-Series.csv', sep= ',')","a8c6d8eb":"# python utilities function :\n\ndef nb_lines(data):\n    ''' function taking a dataframe as input and returns number of rows'''\n    return len(data)\n\ndef nb_columns(data):\n    ''' function taking a dataframe in input and returns number of columns'''\n    return len(data.columns)\n\ndef missing_cells(data):\n    ''' function taking a dataframe in input and returns number of missing cells'''\n    return data.isna().sum().sum()\n\ndef missing_cells_percent(data):\n    ''' function taking a dataframe in input and returns percentage of missing cells'''\n    return data.isna().sum().sum()\/(data.size)\n\ndef count_duplicates_rows(data):\n    ''' function taking a dataframe in input and returns number of duplicate rows'''\n    return len(data)-len(data.drop_duplicates())\n\ndef count_duplicates_rows_percent(data):\n    ''' function taking a dataframe in input and returns percentage of duplicate rows'''\n    return count_duplicates_rows(data)\/nb_lines(data)\n\ndef data_set_overview(data):    \n    ''' function taking a dataframe in input and prints a dataframe summary containing\n    number of rows, columns, missing cells and duplicate rows'''\n    print('--------------------------------------------------------------------------')\n    print('Data : {}'.format(namestr(data, globals())))\n    print('Number of variables : {}'.format(nb_columns(data)))\n    print('Number of observations : {}'.format(nb_lines(data)))\n    print('Missing cells : {}'.format(missing_cells(data)))\n    print('Missing cells in % : {:.2%}'.format(missing_cells_percent(data)))\n    print('Duplicate rows : {}'.format(count_duplicates_rows(data)))\n    print('Duplicate rows in % : {:.2%}'.format(count_duplicates_rows_percent(data)))\n    return None\n\ndef dataset_variables_overview(data):\n    ''' function taking a dataframe in input and returns a summary containing\n    variable name, type, distinct values, missing values, and numerical statistics\n    for numerical variables '''\n    print('--------------------------------------------------------------------------')\n    print('Data : {}'.format(namestr(data, globals())))\n    print('--------------------------------------------------------------------------')\n    df = pd.DataFrame(columns=['Variable name','Variable type','Distinct','% distinct','Missing','% missing', 'Mean', 'Median', 'Skew', 'Kurtosis', 'Variance', 'Stdev', 'min','25%','50%','75%','max'])\n    for column in data.columns:\n        var_type = data[column].dtypes\n        distinct = len(data[column].unique())\n        percent_distinct = len(data[column].unique())\/len(data[column])\n        missing = missing_cells(data[column])\n        percent_missing = missing_cells_percent(data[column])\n        if var_type != 'object':       \n            df = df.append(pd.DataFrame([[column,var_type,distinct,percent_distinct,missing,percent_missing,data[column].mean(),data[column].median(),data[column].skew(),data[column].kurtosis(),data[column].var(ddof=0),\n                                          data[column].std(ddof=0),data[column].min(),data[column].quantile(0.25),data[column].quantile(0.5),data[column].quantile(0.75),data[column].max()]], columns=['Variable name','Variable type','Distinct','% distinct','Missing','% missing', 'Mean', 'Median', 'Skew', 'Kurtosis', 'Variance', 'Stdev', 'min','25%','50%','75%','max']))\n        else:            \n            df = df.append(pd.DataFrame([[column,var_type,distinct,percent_distinct,missing,percent_missing,'','','','','','',''\n                                    ,'','','','']], columns=['Variable name','Variable type','Distinct','% distinct','Missing','% missing', 'Mean', 'Median', 'Skew', 'Kurtosis', 'Variance', 'Stdev', 'min','25%','50%','75%','max']))\n               \n    return df\n            \ndef output_dataset_variables_overview(data):\n    '''output to csv files the variables overview '''\n    summary = dataset_variables_overview(data)\n    summary.to_csv('..\/working\/output_dataset_variables_overview.csv',sep=',', index = False)\n    \ndef dataset_columns(data):\n    ''' function taking a dataframe in input and prints variables in dataframe'''\n    print('--------------------------------------------------------------------------')\n    print('Data : {}'.format(namestr(data, globals())))\n    print('Columns : {}'.format(data.columns.values))\n\ndef namestr(obj, namespace):\n    ''' function that returns variable name in namespace '''\n    return [name for name in namespace if namespace[name] is obj]\n\n# Histogram of column data\ndef plotHistogram(df, nHistogramShown, nHistogramPerRow):\n    ''' function taking a dataframe df, and two integers as number of histograms shown and number of histograms per row '''\n    nunique = df.nunique()\n    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values\n    nRow, nCol = df.shape\n    columnNames = list(df)\n    nHistRow = (nCol + nHistogramPerRow - 1) \/ nHistogramPerRow\n    plt.figure(num=None, figsize=(6*nHistogramPerRow, 8*nHistRow), dpi=80, facecolor='w', edgecolor='k')\n    for i in range(min(nCol, nHistogramShown)):\n        plt.subplot(nHistRow, nHistogramPerRow, i+1)\n        df.iloc[:,i].hist()\n        plt.ylabel('counts')\n        plt.xticks(rotation=90)\n        plt.title(f'{columnNames[i]} (column {i})')\n    plt.tight_layout(pad=1.0, w_pad=1.0, h_pad=1.0)\n    plt.show()\n    \ndef is_in_vector(string,vector):\n    ''' function that takes a strings and tests if it is present in argument vector '''\n    resp = False\n    for entry in vector:\n        if string == entry:\n            resp = True    \n    return resp\n\ndef columns_type(data): \n    ''' function that takes a dataframe and returns a dataframe with data's variable names and types '''\n    df = pd.DataFrame(data.dtypes)[0]\n    summary = pd.DataFrame(columns=['Variable name', 'Variable type'])\n    summary['Variable name']=data.columns\n    summary['Variable type']=list(df)\n    return summary\n\ndef output_dataframe_variable_types(data):\n    ''' function that outputs columns_type method's output in csv file '''\n    summary = columns_type(data)\n    summary.to_csv('..\/working\/output_dataframe_variable_types.csv',sep=',', index = False)\n\ndef missing_values(data):\n    ''' function that takes dataframe as input and output a dataframe containing variables, number of missing values and % of missing'''\n    summary = pd.DataFrame(columns=['Variable name', 'Missing values', '% Missing'])\n    summary['Variable name']=data.columns\n    missing = list()\n    percent_missing = list()\n    for var in data.columns:\n        nb_missing = missing_cells(data[var])\n        pc_missing = missing_cells_percent(data[var])\n        missing.append(nb_missing)\n        percent_missing.append(pc_missing)\n    summary['Missing values'] = list(missing)\n    summary['% Missing'] = list(percent_missing)\n    return summary\n    \ndef output_dataframe_missing_values_summary(data):\n    ''' function that outputs missing_values method's output in csv file '''\n    summary = missing_values(data)\n    summary.to_csv('..\/working\/dataframe_missing_values_summary.csv',sep=',', index = False)\n       \ndef summarize_cat_var(variable,data):\n    ''' function that takes a categorical variable and data returns a dataframe summarizing modalities count, nb uniques, top, less'''\n    nb_modalities = len(data[variable].unique())\n    count = len(data[variable])\n    index = pd.DataFrame(ed_stats_data.groupby(['Country Code'], sort = True).count()).index\n    top = index[0]\n    less = index[len(index)-1]\n    summary = pd.DataFrame(columns=('Variable name','Nb Modalities', 'Count','Top','Less'))  \n    summary['Variable name'] = [variable]\n    summary['Nb Modalities'] = [nb_modalities]\n    summary['Count'] = [count]\n    summary['Top'] = [top]\n    summary['Less'] = [less]\n    return summary\n\ndef output_summarize_cat_var(variable,data):\n    ''' function that outputs summarize_cat_var method's output in csv file '''\n    summary = summarize_cat_var(variable,data)\n    summary.to_csv('..\/working\/output_summarize_cat_var.csv',sep=',', index = False)\n    \ndef dataset_drop_unpopulated_variables(data, limit):\n    ''' function that drops variables from data dataframe with more than limit missing data\n        limit is a float between 0 and 100'''\n    data_temp = pd.DataFrame()\n    data_temp = data\n    for column in data.columns:        \n        var_type = data[column].dtypes\n        percent_missing =  missing_cells_percent(data[column])\n        if var_type == 'float64' and float(missing_cells_percent(data[column]))>limit:\n            print('Dropping variable {} from  {}'.format(column,namestr(data, globals())))\n            data_temp = data_temp.drop([column], axis=1)\n    return data_temp","21e777b8":"columns_type(ed_stats_data)","621669ee":"columns_type(ed_stats_series)","eabedbac":"columns_type(ed_stats_country)","19950cce":"columns_type(ed_stats_footnote)","883870f9":"columns_type(ed_stats_country_series)","d9c5b589":"output_dataframe_variable_types(ed_stats_country)","987f55f8":"missing_values(ed_stats_data)","9322dd9e":"missing_values(ed_stats_series)","4330f044":"missing_values(ed_stats_country)","a495e682":"missing_values(ed_stats_footnote)","1b4b76a1":"missing_values(ed_stats_country_series)","d287c066":"output_dataframe_missing_values_summary(ed_stats_country)","076c5211":"summarize_cat_var('Country Code',ed_stats_data)","019f4d31":"output_summarize_cat_var('Country Code',ed_stats_data)","3d6f2916":"#global overview of datasets\ndata_set_overview(ed_stats_series)\ndata_set_overview(ed_stats_country)\ndata_set_overview(ed_stats_data)\ndata_set_overview(ed_stats_footnote)\ndata_set_overview(ed_stats_country_series)","7f59b725":"# we notice unusual output (number of observations equals missing cells) for the two last dataframes\n# let's have a look at available columns\ndataset_columns(ed_stats_series)\ndataset_columns(ed_stats_country)\ndataset_columns(ed_stats_data)\ndataset_columns(ed_stats_footnote)\ndataset_columns(ed_stats_country_series)","4f810677":"# let us first check the columns 'Unnamed'\nprint(ed_stats_country_series['Unnamed: 3'].describe(include='all'))\nprint(ed_stats_footnote['Unnamed: 4'].describe(include='all'))\nprint(ed_stats_data[['Unnamed: 69']].describe(include='all'))\nprint(ed_stats_country[['Unnamed: 31']].describe(include='all'))\nprint(ed_stats_series[['Unnamed: 20']].describe(include='all'))","cc90a675":"# let's get rid of columns we don't need\ned_stats_country_series = ed_stats_country_series.drop(['Unnamed: 3'], axis=1)\ned_stats_footnote = ed_stats_footnote.drop(['Unnamed: 4'], axis=1)\ned_stats_data=ed_stats_data.drop(['Unnamed: 69'], axis=1)\ned_stats_country=ed_stats_country.drop(['Unnamed: 31'], axis=1)\ned_stats_series=ed_stats_series.drop(['Unnamed: 20'], axis=1)","5fd5f7e0":"#global overview of datasets\n#now it is cleaner\ndata_set_overview(ed_stats_series)\ndata_set_overview(ed_stats_country)\ndata_set_overview(ed_stats_data)\ndata_set_overview(ed_stats_footnote)\ndata_set_overview(ed_stats_country_series)","fb051558":"# we can now dive into our variables\ndataset_variables_overview(ed_stats_series)","7769bd40":"dataset_variables_overview(ed_stats_data)","7802ee39":"dataset_variables_overview(ed_stats_country)","8ec7b178":"#cleaning variables\ned_stats_series_populated = dataset_drop_unpopulated_variables(ed_stats_series,0.95)\ned_stats_country_populated = dataset_drop_unpopulated_variables(ed_stats_country,0.50)\ned_stats_data_populated = dataset_drop_unpopulated_variables(ed_stats_data,100)\n\n# we choose to keep all data from 1970 up to 2017","69af5222":"#global overview of datasets\n#now it is cleaner\ndata_set_overview(ed_stats_series)\ndata_set_overview(ed_stats_country)\ndata_set_overview(ed_stats_data)","fee1b947":"def data_series(data,series, country):\n    '''function that takes data input, a country and series and returns a dictionary '''\n    dic = {}\n    data = data[(data['Indicator Code'] == series) & (data['Country Code'] == country)]\n    for date in range(1970,2017):\n        dic[date] = data[str(date)]    \n    return dic\n \ndef data_series_last(data,series,country,last):\n    '''function that takes data input, a country, a series and an end date and returns a dictionary '''\n    annual_data = []\n    data = data[(data['Indicator Code'] == series) & (data['Country Code'] == country)]\n    for date in range(1970,last):\n        annual_data.append(float(data[str(date)]))    \n    return annual_data","8f84d03f":"# let us know choose our indicators\n\ntopics_of_interest = ['Internet','high-school','university','15-19','20-24', 'population growth', 'computers']\nfiltered_series = ed_stats_series_populated[ed_stats_series_populated['Long definition'].str.contains('|'.join(topics_of_interest))]\n\nprint(\"Number of series related to keywords {} of interest were selected : {}\".format(topics_of_interest,len(filtered_series)))\nprint('-------------------------------------------------')\nprint(\"Topics selected : {}\".format(filtered_series['Topic'].unique()))\nprint('-------------------------------------------------')\nindicators = pd.DataFrame(columns=['Series Code','Long definition'])\nfor serie in filtered_series.iterrows():\n    indicators = indicators.append(pd.DataFrame([[serie[1]['Series Code'],serie[1]['Long definition']]],columns=['Series Code','Long definition']))\nindicators","681a4498":"# we select data filtering with the selected indicators\n\ndataset_filtered = ed_stats_data_populated[ed_stats_data_populated['Indicator Code'].str.contains('|'.join(filtered_series['Series Code']))]\ndataset_filtered.head(5)","1287cfe0":"# now we rapatriate interesting columns from countries dataset\ned_stats_country_populated = ed_stats_country_populated[['Country Code', 'Region','Income Group']]\n# ed_stats_country_populated\nfinal_dataset = pd.merge(dataset_filtered,ed_stats_country_populated,how=\"left\", on=[\"Country Code\"])\n# final_dataset\n# # we rearrange columns for more readability\ncols = dataset_filtered.columns\ncolonnes = list(['Region','Income Group'])\njoined_list = [*colonnes, *cols]\nfinal_dataset = final_dataset[joined_list]","585764bb":"final_dataset.tail(5)","220c6a10":"data_set_overview(final_dataset)","6fcb9997":"dataset_variables_overview(final_dataset)","793e1758":"output_dataset_variables_overview(final_dataset)","c80eaa8b":"golden_regions_var = final_dataset.groupby(['Region','Indicator Code']).mean(numeric_only=True)\ngolden_regions_var","98f72d5a":"golden_source = final_dataset.groupby(['Region','Country Name','Indicator Code']).mean()\ngolden_source","b751cc2d":"# use of built function to describe dataset\n\ndata_set_overview(golden_source)","075b43c6":"dataset_variables_overview(golden_source)","d2e79d1e":"# let us now group by indicator and transpose data so we can calculate correlations between indicators\n\nsource_ = final_dataset.groupby(['Indicator Code']).mean(numeric_only=True)\nsource_","f2b23afc":"year_series = source_.transpose()\nyear_series","4cab7ff6":"data_for_pairplot = year_series[['HH.DHS.YRS.1519', 'HH.MICS.YRS.1519','IT.CMP.PCMP.P2','IT.NET.USER.P2', 'LO.PIAAC.TEC.OPT', 'LO.PIAAC.TEC.YOU.OPT','SP.POP.GROW']].loc[:'2017']\n\nsns_plot = sns.pairplot(data_for_pairplot)\nsns_plot.savefig(\"..\/working\/pairplot.png\")","c460ec12":"fig, ax = plt.subplots(figsize=(15,10))  \nsns.heatmap(year_series.corr(),annot = False,square=True);","e4510b2c":"matrix = np.triu(year_series.corr())\nfig, ax = plt.subplots(figsize=(15,10))  \nsns.heatmap(year_series.corr(), annot=False, mask=matrix);","42aa8dca":"matrix = np.triu(year_series[['IT.NET.USER.P2','IT.CMP.PCMP.P2','SP.POP.GROW','HH.DHS.YRS.1519','HH.DHS.YRS.1519.M', 'BAR.SEC.SCHL.1519','BAR.SEC.SCHL.2024','BAR.TER.SCHL.1519','BAR.TER.SCHL.2024']].corr())\nfig, ax = plt.subplots(figsize=(15,10))  \nsns.heatmap(year_series[['IT.NET.USER.P2','IT.CMP.PCMP.P2','SP.POP.GROW','HH.DHS.YRS.1519','HH.DHS.YRS.1519.M', 'BAR.SEC.SCHL.1519','BAR.SEC.SCHL.2024','BAR.TER.SCHL.1519','BAR.TER.SCHL.2024']].corr(), annot=False, mask=matrix);","c58f169a":"sns.set_theme()\n\nindicators = ['IT.NET.USER.P2','IT.CMP.PCMP.P2','SP.POP.GROW','HH.DHS.YRS.1519']\nfor indicator in indicators:\n    \n    fig = plt.figure(figsize=(15, 10))\n    ax = plt.axes()\n    plt.title(indicator)\n    degrees = 90\n    plt.xticks(rotation=degrees)\n    for region in final_dataset['Region'].dropna().unique():\n        if len(golden_regions_var.loc[region,indicator].dropna())>0:\n            ax.plot(golden_regions_var.loc[region,indicator], label=region)\n            plt.legend()","a76107c4":"sns.pairplot(year_series[['IT.NET.USER.P2','IT.CMP.PCMP.P2','SP.POP.GROW','HH.DHS.YRS.1519']]);\n","a719c294":"regions_ = final_dataset.groupby(['Region']).mean(numeric_only=True).transpose()","881a4bdc":"regions_","a174464f":"sns.pairplot(regions_)","505e833c":"sns.heatmap(regions_.corr());","a751f8f7":"countries_ = final_dataset.groupby(['Indicator Code','Country Name']).mean()\ncountries_","cdbb25ac":"countries = final_dataset['Country Code'].unique()\nopacity = np.array(countries_.loc[['IT.NET.USER.P2','IT.CMP.PCMP.P2','SP.POP.GROW','HH.DHS.YRS.1519']].sum(axis=1).groupby(['Country Name']).sum())\n# cmap = ['#ff0000'] \n\nout = worldmap.plot(countries, opacity=2000-opacity , cmap= 'Blues',map_name='world', verbose = True, showfig = True)","ccb44f94":"scores = pd.DataFrame(countries_.loc[['IT.NET.USER.P2','IT.CMP.PCMP.P2','SP.POP.GROW','HH.DHS.YRS.1519']].mean(axis=1).groupby(['Country Name']).mean(numeric_only=True))[0]\nranking_country = pd.DataFrame([scores.index,scores.values]).transpose()\nranking_country = ranking_country.sort_values(by=[1],ascending=True)\nranking_country.columns = ['Country','Score']\nranking_country.head(20)","3ebff1b9":"golden_regions = final_dataset.groupby(['Region']).mean(numeric_only=True)\n\nscores = pd.DataFrame(golden_regions.mean(axis=1).groupby(['Region']).mean(numeric_only=True))[0]\nranking = pd.DataFrame([scores.index,scores.values]).transpose()\nranking = ranking.sort_values(by=[1],ascending=True)\nranking.columns = ['Region','Score']\nranking","a67e1602":"#  Exploratory analysis for world bank's education statistics\nThe purpose of this work is to get and clean the data and make a business recommendation for academy's international expansion project.","36a151c4":"![worldmap.png](attachment:03f22c8e-e9a6-4479-8b48-f45ef70e6731.png)"}}