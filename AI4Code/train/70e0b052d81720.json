{"cell_type":{"84dabae4":"code","1909aa03":"code","5e5b831e":"code","6240b8ed":"code","85af882b":"code","aa2a4e44":"code","19f35cb1":"code","7f1a7995":"code","23ba348e":"code","ba6a576f":"code","f4b95274":"code","58a060ba":"code","5924c8bb":"code","28de6056":"code","d0f7f1f2":"code","df6361e0":"code","5eca2123":"code","28d64146":"code","3e108459":"code","96acb184":"code","9c122405":"code","f71764e9":"code","4480f2d6":"code","9a75a677":"code","7e42d02d":"code","c1a75247":"code","505faeff":"code","d70a9faa":"code","9cdbdc9d":"code","d641a7eb":"code","546e608a":"code","25b0525f":"code","5936913c":"code","1697a3f8":"markdown","4663940f":"markdown","ab674c7a":"markdown","cd3bbff2":"markdown","ac2de4f0":"markdown","e01f98d4":"markdown","9fbf6621":"markdown","00e5517e":"markdown","962338ee":"markdown","c55ac5ad":"markdown","3d440eaa":"markdown","e996de59":"markdown"},"source":{"84dabae4":"import os\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image, ImageDraw, ImageEnhance\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n","1909aa03":"tf.__version__","5e5b831e":"# sample_path = \"\/kaggle\/input\/state-farm-distracted-driver-detection\/sample_submission.csv\"\nimgs_list_path = \"\/kaggle\/input\/state-farm-distracted-driver-detection\/driver_imgs_list.csv\"\ntrain_path = \"\/kaggle\/input\/state-farm-distracted-driver-detection\/imgs\/train\"","6240b8ed":"# read csv file to get class names\ndriver_imgs_list = pd.read_csv(imgs_list_path)\ndriver_imgs_list.head()","85af882b":"os.listdir(train_path)","aa2a4e44":"# sort through to organize dataset by class rather then random\ndef pair_sort(className,values):\n    for j in range(0,len(className)-1):\n        for i in range(0,len(className)-1):\n            if values[i] > values[i+1]:\n                temp =  values[i+1]\n                values[i+1] = values[i]\n                values[i] = temp\n\n                N_temp =  className[i+1]\n                className[i+1] = className[i]\n                className[i] = N_temp\n    \n    return className,values","19f35cb1":"# create graph to display class weight and number of images in each class\nfrom matplotlib.pyplot import figure\nfigure(num=None, figsize=(15, 5), dpi=80, facecolor='w', edgecolor='k')\n\nclass_names = np.unique(driver_imgs_list['classname'])\nclass_image_list = [len(driver_imgs_list[driver_imgs_list['classname'] == current_class]) for current_class in class_names]\n\nclass_names,class_image_list=  pair_sort(class_names,class_image_list)\n\n#plt.figure()\nplt.suptitle('Number of images per Class')\nplt.bar(class_names,class_image_list,color=(0.2, 0.4, 0.6, 0.6))\nplt.show()","7f1a7995":"# create graph to display number of images per subject\nfrom matplotlib.pyplot import figure\nsub_names = np.unique(driver_imgs_list['subject'])\nsub_image_list = [len(driver_imgs_list[driver_imgs_list['subject'] == current_sub]) for current_sub in sub_names]\nsub_names,sub_image_list=  pair_sort(sub_names,sub_image_list)\n\nfigure(num=None, figsize=(15, 10), dpi=80, facecolor='w', edgecolor='k')\n\ny_pos = np.arange(len(sub_names))\n# Create horizontal bars\nplt.barh(y_pos, sub_image_list,color=(0.2, 0.4, 0.6, 0.6))\n \n# Create names on the y-axis\nplt.yticks(y_pos,sub_names )\nplt.suptitle('Number of images per subject')\n\n# Show graphic\nplt.show()","23ba348e":"# hyperparameters\nimg_width,img_height = (256,256)\nmodel_input_shape = (img_width,img_height,3)\nbatch_size = 16\ninput_image = (img_width,img_height)\n\n# get image path from dataset\ndef load_image(path):\n    read_path = train_path+\"\/\"+path\n    image = Image.open(read_path)\n    image = image.resize(input_image)\n    \n    return np.asarray(image)","ba6a576f":"# load image pixels from input data\ndef show_images(image_ids,class_names):\n    pixels = [load_image(path) for path in image_ids]\n    num_of_images = len(image_ids)\n    fig, axes = plt.subplots(\n        1, \n        num_of_images, \n        figsize=(5 * num_of_images, 5 * num_of_images),\n        \n    )\n   \n    # convert enumeration value to integer\n    for i, image_pixels in enumerate(pixels):\n        axes[i].imshow(image_pixels)\n        axes[i].axis(\"off\")\n        axes[i].set_title(class_names[i])","f4b95274":"# checking input data\nsub_names_imgs = [ current_class+\"\/\"+driver_imgs_list[driver_imgs_list['classname'] == current_class]['img'].values[0] for current_class in class_names]\n\nshow_images(sub_names_imgs[:5],class_names[:5])\nshow_images(sub_names_imgs[5:],class_names[5:])","58a060ba":"# get test and train data\ntrain_path = \"\/kaggle\/input\/state-farm-distracted-driver-detection\/imgs\/train\"\ntest_path = \"\/kaggle\/input\/state-farm-distracted-driver-detection\/imgs\/test\"","5924c8bb":"# x_train = []\n# y_train = []\n\n# x_val = []\n# y_val = []\n\n# # The data is split into a test set and a training set\n# # a driver can only appear in one of the training set or the testing set\n# split_rate = 0.8\n\n# # go through dataset and collecting train and test data suing split factor\n# # training neural network\n# for current_class in class_names:\n#     select_df = driver_imgs_list[driver_imgs_list['classname'] == current_class ]\n#     image_list = select_df['img'].values\n#     train_amount = int(len(image_list)*split_rate)\n#     train_list = image_list[:train_amount]\n#     val_list = image_list[train_amount:]\n    \n#     for filename in train_list:\n#         x_train.append(load_image(current_class+\"\/\"+filename))\n#         y_train.append(current_class.replace('c',''))\n\n#     for filename in val_list:\n#         x_val.append(load_image(current_class+\"\/\"+filename))\n#         y_val.append(current_class.replace('c',''))\n","28de6056":"# search dataset to organize\ndriver_imgs_list[\"img_path\"] = driver_imgs_list[\"classname\"]+\"\/\"+driver_imgs_list[\"img\"]\ndriver_imgs_list","d0f7f1f2":"# display data\nlabels = driver_imgs_list[\"classname\"]\ndata_x = driver_imgs_list[\"img_path\"]\ntrain_df, val_df = train_test_split(driver_imgs_list, test_size = 0.2)","df6361e0":"# display data\nlen(train_df), len(val_df)\nval_df.head()","5eca2123":"# image pre-processing using data generator\ndatagen = ImageDataGenerator(\n        rotation_range=10, # rotation\n        width_shift_range=0.2, # horizontal shift\n        height_shift_range=0.2, # vertical shift\n        zoom_range=0.2, # zoom\n        horizontal_flip=True, # horizontal flip\n        brightness_range=[0.2,1.2]) # brightness\n\n# process train data\ntrain_generator_df = datagen.flow_from_dataframe(dataframe=train_df, \n                                              directory=train_path+\"\/\",\n                                              x_col=\"img_path\", \n                                              y_col=\"classname\", \n                                              class_mode=\"categorical\", \n                                              target_size=(256, 256), \n                                              batch_size=32,\n                                              rescale=1.0\/255)\n# process val data\nval_generator_df = datagen.flow_from_dataframe(dataframe=val_df, \n                                              directory=train_path+\"\/\",\n                                              x_col=\"img_path\", \n                                              y_col=\"classname\", \n                                              class_mode=\"categorical\", \n                                              target_size=(256, 256), \n                                              batch_size=32,\n                                              rescale=1.0\/255)","28d64146":"# # convert vector to matrix\n# x_train = np.asarray(x_train)\n# y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n# x_val = np.asarray(x_val)\n# y_val =tf.keras.utils.to_categorical(y_val, num_classes=10)\n\n# print(\"Train x Shape: \",x_train.shape)\n# print(\"Test x Shape: \",x_val.shape)\n","3e108459":"# print(\"Train y Shape: \",y_train.shape)\n# print(\"Test y Shape: \",y_val.shape)","96acb184":"# create our Resnet model\n# include_top is false to allow us to modify classification\nbase_model  = tf.keras.applications.resnet.ResNet50(include_top = False,\n                                                  weights = 'imagenet',\n                                                  input_shape = model_input_shape)\n# base_model.summary()","9c122405":"# x = base_model.output\n# x = tf.keras.layers.Flatten()(x)\n# x = tf.keras.layers.Dropout(0.5)(x)\n\n# output =tf.keras.layers.Dense(units = len(class_names),activation = tf.nn.softmax)(x)\n# model = tf.keras.models.Model(inputs=base_model.inputs, outputs=output)\n\n# model.compile(optimizer=tf.keras.optimizers.Adam(0.0001),\n#               loss=tf.keras.losses.CategoricalCrossentropy(from_logits = False),\n#               metrics=['accuracy'])\n\n# model.summary()","f71764e9":"# calculating class weights which are inversely proportional to number of training examples\nclasses, counts = np.unique(train_df[\"classname\"], return_counts = True)\ntotal = sum(counts)\nratios = 1\/(counts\/total)\n\nclass_weights = dict()\n\nfor i in range(10):\n    class_weights[i] = ratios[i]","4480f2d6":"class_weights","9a75a677":"#modified model of ResNet\nx = base_model.output\n# flattens input layer to pass  data into every single neuron of the model \nx = tf.keras.layers.Flatten()(x)\nx = tf.keras.layers.Dense(units = 1068, activation = tf.nn.relu)(x)\n# help reduce overfitting\nx = tf.keras.layers.Dropout(0.25)(x)\n# additional dense layers added\nx = tf.keras.layers.Dense(units = 768, activation = tf.nn.relu)(x)\n# normalize flow of data to increase learning rate\nx = tf.keras.layers.BatchNormalization()(x)\n# feeds output to neurons from previous layer\nx = tf.keras.layers.Dense(units = 512, activation = tf.nn.relu)(x)\nx = tf.keras.layers.Dense(units = 256, activation = tf.nn.relu)(x)\nx = tf.keras.layers.Dropout(0.25)(x)\n\noutput =tf.keras.layers.Dense(units = len(class_names),activation = tf.nn.softmax)(x)\nmodel = tf.keras.models.Model(inputs=base_model.inputs, outputs=output)\n\n# Adam = optimization algorithm for stochastic gradient descent - help handle noise\nmodel.compile(optimizer=tf.keras.optimizers.Adam(0.0001),\n              loss=tf.keras.losses.CategoricalCrossentropy(from_logits = False),\n              metrics=['accuracy'])\n\nmodel.summary()","7e42d02d":"num_epochs = 40\ndef lr_schedule(epoch,lr):\n    # Learning Rate Schedule\n\n    lr = lr\n    total_epochs = num_epochs\n\n    # reduce the learning rate as as epochs increase\n    check_1 = int(total_epochs * 0.9)\n    check_2 = int(total_epochs * 0.8)\n    check_3 = int(total_epochs * 0.6)\n    check_4 = int(total_epochs * 0.4)\n\n    if epoch > check_1:\n        lr *= 1e-4\n    elif epoch > check_2:\n        lr *= 1e-3\n    elif epoch > check_3:\n        lr *= 1e-2\n    elif epoch > check_4:\n        lr *= 1e-1\n\n    print(\"[+] Current Lr rate : {} \".format(lr))\n    return lr\nlr_callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule)","c1a75247":"# # setting hyperparameters for using with model\n# history = model.fit(\n#       x = x_train,y=y_train,\n#       validation_data=(x_val,y_val),\n#       steps_per_epoch=141, # will reduce the training data to 128 images per class\n#       batch_size = 40,\n#       epochs=75,\n#     class_weight=class_weights,\n#     callbacks = [lr_callback],\n#       verbose=1)","505faeff":"# setting hyperparameters for using with model\nhistory = model.fit_generator(\n      train_generator_df,\n      validation_data=val_generator_df,\n      # usually 100 - for testing we will use 50\n      steps_per_epoch=100, # will reduce the training data to 128 images per class\n#       batch_size = 40,\n      # usually epoch = 40 - for testing we will use 4\n      epochs=40,\n    class_weight=class_weights,\n    callbacks = [lr_callback],\n      verbose=1)","d70a9faa":"# # create graphs to display training and validation loss and accuracy of the model\n# fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n\n# ax[0].set_title('Training vs Validation Accuracy')\n# ax[0].plot(history.history['accuracy'])\n# ax[0].plot(history.history['val_accuracy'])\n# plt.ylabel('Accuracy')\n# plt.xlabel('Epochs')\n# plt.show()\n\n# ax[1].set_title('Training vs Validation Loss')\n# ax[1].plot(history.history['loss'])\n# ax[1].plot(history.history['val_loss'])\n# plt.ylabel('Loss')\n# plt.xlabel('Epochs')","9cdbdc9d":"# create graphs to display training and validation loss of the model\nloss_train = history.history['loss']\nloss_val = history.history['val_loss']\n# usually up to 41 but for testing changing it to 5\nepochs = range(1,41)\nplt.plot(epochs, loss_train, 'g', label='Training loss')\nplt.plot(epochs, loss_val, 'b', label='validation loss')\nplt.title('Training and Validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(loc = \"upper right\")\nplt.show()","d641a7eb":"# create graphs to display training and validation accuracy of the model\nloss_train = history.history['accuracy']\nloss_val = history.history['val_accuracy']\n# usually up to 41 but for testing changing it to 5\nepochs = range(1,41)\nplt.plot(epochs, loss_train, 'g', label='Training accuracy')\nplt.plot(epochs, loss_val, 'b', label='validation accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(loc = \"upper right\")\nplt.show()","546e608a":"#  display the evaluation results of prediction using part of dataset\ny_pred = model.evaluate_generator(val_generator_df) #predict on x_val\n# y_pred = np.argmax(y_pred, axis = 1) # convert output to class numbers\n# print(\"Predictions:\", y_pred)\n# print(\"True labels:\", np.argmax(y_val, axis = 1)) # print the prediction and true labels for first 10 test images","25b0525f":"# our prediction accuracy using sample set\nprint(\"Accuracy on test set\")\nprint(y_pred[1])","5936913c":"# create graphs to display prediction of sample data\nval = history.history['accuracy']\n# usually up to 41 but for testing changing it to 5\nepochs = range(1,41)\nplt.plot(epochs, val, 'g', label='Training accuracy')\nplt.title('Prediction Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(loc = \"lower right\")\nplt.show()","1697a3f8":"## 8. Create Model\n","4663940f":"# 5. Split and load Train\/Validation ","ab674c7a":"# 3.Check data distribution","cd3bbff2":"# 2. Get data","ac2de4f0":"# 6. Image Pre-processing","e01f98d4":"# 9. Train and Test","9fbf6621":"# 4.Plot class images","00e5517e":"Bailie Geddes, 17beg, 20099792\n\n# **Implementing ResNet for Image Classification:**\n\nThis notebook has portions taken from published source on Kaggle and has been extended by modifying:\n- add image data generator for all pre-processing functions\n    - rotation, width shift, height shift, horizontal flip, brightness, etc.\n- changing the ResNet50 model by adding additional dense layers\n    - add dense layers for additional simple layers of neurons\n    - add new dropout layer\n- changing the classification by altering the class weights \n    - redistributes the balance of images in each class, adding classweights by calculating proportions and inversing them\n- adding batch normalization\n    - standardizes the inputs to a layer for each mini-batch to reduce number of epochs needed\n  \n\nThe dataset that will be worked with is the State Farm Distracted Driver Detection dataset found on Kaggle.com (https:\/\/www.kaggle.com\/c\/state-farm-distracted-driver-detection\/data).\n\nThere are 10 different classes, and 79.7 thousand images. The classes are safe driving, texting with right hand, talking on the phone with right hand, texting with left hand, talking on the phone with left hand, operating the radio, drinking, reaching behind, hair and makeup and talking to passenger. \n\nUsing this Dataset, I\u2019m going to present results of Residual neural networks (ResNet) used for Image classification to test the accuracy they present for these images, first creating it piece by piece and then importing and adapting a pre trained ResNet.","962338ee":"## 7. Encode Labels","c55ac5ad":"## 10. Model Evaluation","3d440eaa":"# 1. Import libraries","e996de59":"# 11. Prediction"}}