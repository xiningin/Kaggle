{"cell_type":{"a77bea7c":"code","45e31278":"code","8e5fe494":"code","c357336a":"code","4fcab17f":"code","5a92cd99":"code","401d09ef":"code","7c0c7500":"code","c5e07635":"code","707b4675":"code","b2ec7797":"code","be4891f2":"code","a131ae7a":"code","d55815ca":"code","400b2cb8":"code","dece450f":"code","27c1f463":"code","d7e26ade":"code","15812823":"code","e001bf25":"code","9c4a0f19":"code","30c0bf1e":"code","762b7434":"code","901b8d3a":"markdown","77eba723":"markdown","84970e9b":"markdown","68b8bff3":"markdown","b4a5c5d6":"markdown","87759e10":"markdown","a0f7e198":"markdown"},"source":{"a77bea7c":"#!pip install imutils\nimport sys\nsys.path.append('..\/input\/imutils\/imutils-0.5.3')","45e31278":"import os\nimport random\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torchvision\nfrom torchvision import transforms\nimport tensorflow as tf\nimport albumentations as A\nimport imgaug.augmenters as iaa\nfrom imgaug import parameters as iap","8e5fe494":"DIR = \"..\/input\/plant-pathology-2021-fgvc8\/train_images\"\nimage_path = f'{DIR}\/800113bb65efe69e.jpg'","c357336a":"chosen_image = cv2.imread(image_path)\nplt.imshow(chosen_image)","4fcab17f":"albumentation_list = [A.RandomSunFlare(p=1), \n                      A.RandomFog(p=1), \n                      A.RandomBrightness(p=1),\n                      A.RandomCrop(p=1,height = 512, width = 512), \n                      A.Rotate(p=1, limit=90),\n                      A.RGBShift(p=1), \n                      A.RandomSnow(p=1),\n                      A.HorizontalFlip(p=1), \n                      A.VerticalFlip(p=1), \n                      A.RandomContrast(limit = 0.5,p = 1),\n                      A.HueSaturationValue(p=1,hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=50),\n                      A.Cutout(p=1),\n                      A.Transpose(p=1), \n                      A.JpegCompression(p=1),\n                      A.CoarseDropout(p=1),\n                      A.IAAAdditiveGaussianNoise(loc=0, scale=(2.5500000000000003, 12.75), per_channel=False, p=1),\n                      A.IAAAffine(scale=1.0, translate_percent=None, translate_px=None, rotate=0.0, shear=0.0, order=1, cval=0, mode='reflect', p=1),\n                      A.IAAAffine(rotate=90., p=1),\n                      A.IAAAffine(rotate=180., p=1)]","5a92cd99":"img_matrix_list = []\nbboxes_list = []\nfor aug_type in albumentation_list:\n    img = aug_type(image = chosen_image)['image']\n    img_matrix_list.append(img)\n\nimg_matrix_list.insert(0,chosen_image)    \n\ntitles_list = [\"Original\",\"RandomSunFlare\",\"RandomFog\",\"RandomBrightness\",\n               \"RandomCrop\",\"Rotate\", \"RGBShift\", \"RandomSnow\",\"HorizontalFlip\", \"VerticalFlip\", \"RandomContrast\",\"HSV\",\n               \"Cutout\",\"Transpose\",\"JpegCompression\",\"CoarseDropout\",\"IAAAdditiveGaussianNoise\",\"IAAAffine\",\"IAAAffineRotate90\",\"IAAAffineRotate180\"]\n\ndef plot_multiple_img(img_matrix_list, title_list, ncols, nrows=5,  main_title=\"\"):\n    fig, myaxes = plt.subplots(figsize=(20, 15), nrows=nrows, ncols=ncols, squeeze=False)\n    fig.suptitle(main_title, fontsize = 30)\n    fig.subplots_adjust(wspace=0.3)\n    fig.subplots_adjust(hspace=0.3)\n    for i, (img, title) in enumerate(zip(img_matrix_list, title_list)):\n        myaxes[i \/\/ ncols][i % ncols].imshow(img)\n        myaxes[i \/\/ ncols][i % ncols].set_title(title, fontsize=15)\n    plt.show()\n    \nplot_multiple_img(img_matrix_list, titles_list, ncols = 4,main_title=\"Different Types of Augmentations with Albumentations\")","401d09ef":"ia_trans_list = [iaa.blend.BlendAlpha(factor=(0.2, 0.8),\n                                      foreground=iaa.Affine(rotate=(-30, 30)),\n                                      per_channel=True),\n                 iaa.Fliplr(1.),\n                 iaa.Flipud(1.),\n                 iaa.SimplexNoiseAlpha(iaa.Multiply(iap.Choice([0.5, 1.5]), per_channel=True)),\n                 iaa.Crop(percent=(0., 0.3)),\n                ]","7c0c7500":"img_matrix_list = []\nbboxes_list = []\nfor aug_type in ia_trans_list:\n    # convert to tensor\n    chosen_image = cv2.imread(image_path)\n    iaa_seq = iaa.Sequential([aug_type])\n    trans_img = iaa_seq.augment_images(chosen_image)\n    img_matrix_list.append(trans_img)\n\nimg_matrix_list.insert(0, chosen_image)    \n\ntitles_list = [\"Original\",\"Ghost Aug\",\"Flip Left Right\",\"Flip Up Down\",\"SimplexNoiseAlpha\", \"Crop\"]\n\nplot_multiple_img(img_matrix_list, titles_list, ncols = 3, nrows=2, main_title=\"Different Types of Augmentations with Albumentations\")","c5e07635":"torch_trans_list = [transforms.CenterCrop((178, 178)),\n                    transforms.Resize(128),\n                    transforms.RandomRotation(45),\n                    transforms.RandomAffine(35),\n                    transforms.RandomCrop(128),\n                    transforms.RandomHorizontalFlip(p=1),\n                    transforms.RandomPerspective(p=1),\n                    transforms.RandomVerticalFlip(p=1)]","707b4675":"img_matrix_list = []\nbboxes_list = []\nfor aug_type in torch_trans_list:\n    # convert to tensor\n    chosen_image = cv2.imread(image_path)\n    chosen_tensor = transforms.Compose([transforms.ToTensor()])(chosen_image)\n    chosen_tensor = transforms.Compose([aug_type])(chosen_tensor)\n    trans_img = transforms.ToPILImage()(chosen_tensor)\n    img_matrix_list.append(trans_img)\n\nimg_matrix_list.insert(0, chosen_image)    \n\ntitles_list = [\"Original\",\"CenterCrop\",\"Resize\",\"RandomRotation\",\"RandomAffine\",\"RandomCrop\",\"RandomHorizontalFlip\",\"RandomPerspective\",\n               \"RandomVerticalFlip\"]\n\nplot_multiple_img(img_matrix_list, titles_list, ncols = 3, nrows=3, main_title=\"Different Types of Augmentations with Albumentations\")","b2ec7797":"chosen_image = cv2.imread(image_path)\n\ntf_trans_list = [\n    tf.image.rot90(chosen_image, k=1), # 90 degrees counter-clockwise\n    tf.image.rot90(chosen_image, k=2), # 180 degrees counter-clockwise\n    tf.image.rot90(chosen_image, k=3), # 270 degrees counter-clockwise\n    tf.image.random_brightness(chosen_image, 0.5), \n    tf.image.random_contrast(chosen_image, 0.2, 0.5), \n    tf.image.random_flip_left_right(chosen_image, seed=42),\n    tf.image.random_flip_up_down(chosen_image, seed=42),\n    tf.image.random_hue(chosen_image, 0.5),\n    tf.image.random_jpeg_quality(chosen_image, 35, 50), \n    tf.image.random_saturation(chosen_image, 5, 10), \n    tf.image.transpose(chosen_image),\n]","be4891f2":"img_matrix_list = []\nbboxes_list = []\nfor aug_image in tf_trans_list:\n    img_matrix_list.append(aug_image)\n\nimg_matrix_list.insert(0, chosen_image)    \n\ntitles_list = [\"Original\",\"Rotate90\",\"Rotate180\",\"Rotate270\",\"RandomBrightness\",\"RandomContrast\",\"RandomLeftRightFlip\",\"RandomUpDownFlip\",\n               \"RandomHue\",\"RandomJPEGQuality\",\"RandomSaturation\",\"Transpose\"]\n\nplot_multiple_img(img_matrix_list, titles_list, ncols = 3, nrows=4, main_title=\"Different Types of Augmentations with Albumentations\")","a131ae7a":"import sys\nsys.path.insert(0, \"..\/input\/timm-efficientdet-pytorch\")\nsys.path.insert(0, \"..\/input\/omegaconf\")\nsys.path.insert(0, \"..\/input\/weightedboxesfusion\")\nimport random\nfrom glob import glob\nfrom torch.utils.data import Dataset,DataLoader\nfrom albumentations.pytorch.transforms import ToTensorV2\nimport cv2\nimport gc\n#from tqdm import df\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import StratifiedKFold","d55815ca":"marking = pd.read_csv('..\/input\/plant-pathology-2021-fgvc8\/train.csv')","400b2cb8":"marking.tail()","dece450f":"TRAIN_ROOT_PATH = '..\/input\/plant-pathology-2021-fgvc8\/train_images'\n\ndef collate_fn(batch):\n    return tuple(zip(*batch))\n\n\nclass DatasetRetriever(Dataset):\n\n    def __init__(self, marking, image_ids, transforms=None, test=False):\n        super().__init__()\n\n        self.image_ids = image_ids\n        self.marking = marking\n        self.transforms = transforms\n        self.test = test\n\n    def __getitem__(self, index: int):\n        image_id = self.image_ids[index]\n\n        image, boxes = self.load_imagees(index)\n        \n        target = {}\n        target['image_id'] = torch.tensor([index])\n\n        if self.transforms:\n            for i in range(10):\n                sample = self.transforms(**{\n                    'mageage': image,\n                })\n\n        return image\n\n    def __len__(self) -> int:\n        return self.image_ids.shape[0]\n\n    def load_images(self, image_id):\n        #image_id = self.image_ids[index]\n        images = cv2.imread(f'{TRAIN_ROOT_PATH}\/{image_id}', cv2.IMREAD_COLOR)\n        #images = cv2.resize(images, dsize=(640, 480), interpolation=cv2.INTER_AREA)\n        images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB).astype(np.float32)\n        images \/= 255\n        records = self.marking[self.marking['image'] == image_id]\n        return images","27c1f463":"def draw_images(list_images):\n    fig, ax = plt.subplots(4, 2, figsize=(16, 32))\n    for i, image in enumerate(list_images):\n        ax.set_axis_off()\n        ax.imshow(image);","d7e26ade":"skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\ndf_folds = marking[['image']].copy()\nf_folds = df_folds.groupby('image').count()","15812823":"def get_valid_transforms():\n    return A.Compose(\n        [\n            A.Resize(height=512, width=512, p=1.0),\n            ToTensorV2(p=1.0),\n        ], \n        p=1.0, \n        bbox_params=A.BboxParams(\n            format='pascal_voc',\n            min_area=0, \n            min_visibility=0,\n            label_fields=['labels']\n        )\n    )","e001bf25":"dataset = DatasetRetriever(\n    image_ids=df_folds['image'].index.values,\n    marking=marking,\n    transforms=get_valid_transforms(),\n    test=True,\n)","9c4a0f19":"count = 4\n\nfig, ax = plt.subplots(count, 3, figsize=(16, 6*count))\n\nfor i in range(count):\n    image = dataset.load_images(marking.loc[random.randint(0, dataset.image_ids.shape[0] - 1)]['image'])\n    r_image = dataset.load_images(marking.loc[random.randint(0, dataset.image_ids.shape[0] - 1)]['image'])\n    mixup_image = (image+r_image)\/2\n        \n    ax[i][0].imshow(image)\n    ax[i][1].imshow(r_image)\n    ax[i][2].imshow(mixup_image)","30c0bf1e":"count = 4\n\nfig, ax = plt.subplots(count, 3, figsize=(16, 6*count))\n\nfor i in range(count):\n    image = dataset.load_images(marking.loc[random.randint(0, dataset.image_ids.shape[0] - 1)]['image'])\n    r_image = dataset.load_images(marking.loc[random.randint(0, dataset.image_ids.shape[0] - 1)]['image'])\n    \n    mixup_image = image.copy()\n\n    imsize = image.shape[0]\n    x1, y1 = [int(random.uniform(imsize * 0.0, imsize * 0.45)) for _ in range(2)]\n    x2, y2 = [int(random.uniform(imsize * 0.55, imsize * 1.0)) for _ in range(2)]\n\n    \n    cv2.rectangle(r_image,(x1, y1),(x2,  y2),(0, 1, 1), 5)\n    \n    mixup_image[y1:y2, x1:x2] = (mixup_image[y1:y2, x1:x2] + r_image[y1:y2, x1:x2])\/2\n    \n    cv2.rectangle(mixup_image,(x1, y1),(x2,  y2),(0, 1, 1), 5)\n\n        \n    ax[i][0].imshow(image)\n    ax[i][1].imshow(r_image)\n    ax[i][2].imshow(mixup_image)","762b7434":"count = 4\n\nfig, ax = plt.subplots(count, 3, figsize=(16, 6*count))\n\nfor i in range(count):\n    image = dataset.load_images(marking.loc[random.randint(0, dataset.image_ids.shape[0] - 1)]['image'])\n    r_image = dataset.load_images(marking.loc[random.randint(0, dataset.image_ids.shape[0] - 1)]['image'])\n    \n\n    imsize = image.shape[0]\n    w,h = imsize, imsize\n    s = imsize \/\/ 2\n\n    xc, yc = [int(random.uniform(imsize * 0.4, imsize * 0.6)) for _ in range(2)]\n    direct = random.randint(0, 3)\n\n    result_image = image.copy()\n    result_boxes = []\n\n    if direct == 0:\n        x1a, y1a, x2a, y2a = max(xc - w, 0), max(yc - h, 0), xc, yc  # xmin, ymin, xmax, ymax (large image)\n        x1b, y1b, x2b, y2b = w - (x2a - x1a), h - (y2a - y1a), w, h  # xmin, ymin, xmax, ymax (small image)\n    elif direct == 1:  # top right\n        x1a, y1a, x2a, y2a = xc, max(yc - h, 0), min(xc + w, s * 2), yc\n        x1b, y1b, x2b, y2b = 0, h - (y2a - y1a), min(w, x2a - x1a), h\n    elif direct == 2:  # bottom left\n        x1a, y1a, x2a, y2a = max(xc - w, 0), yc, xc, min(s * 2, yc + h)\n        x1b, y1b, x2b, y2b = w - (x2a - x1a), 0, max(xc, w), min(y2a - y1a, h)\n    elif direct == 3:  # bottom right\n        x1a, y1a, x2a, y2a = xc, yc, min(xc + w, s * 2), min(s * 2, yc + h)\n        x1b, y1b, x2b, y2b = 0, 0, min(w, x2a - x1a), min(y2a - y1a, h)\n\n    padw = x1a - x1b\n    padh = y1a - y1b\n\n\n    result_image[y1a:y2a, x1a:x2a] = (result_image[y1a:y2a, x1a:x2a] + r_image[y1b:y2b, x1b:x2b]) \/ 2 \n    \n    cv2.rectangle(image,(x1a, y1a),(x2a,  y2a),(0, 1, 1), 5)\n    cv2.rectangle(r_image,(x1b, y1b),(x2b,  y2b),(0, 1, 1), 5)\n    cv2.rectangle(result_image,(x1a, y1a),(x2a,  y2a),(0, 1, 1), 5)\n    \n\n        \n    ax[i][0].imshow(image)\n    ax[i][1].imshow(r_image)\n    ax[i][2].imshow(result_image)","901b8d3a":"* torchvision.transforms : https:\/\/dororongju.tistory.com\/144","77eba723":"# **Mixup**","84970e9b":"# **imgaug Based Augmentations**","68b8bff3":"**Reference :** https:\/\/www.kaggle.com\/khoongweihao\/insect-augmentation-et-al","b4a5c5d6":"# **PyTorch-Based Augmentations (Torchvision)**","87759e10":"# **TensorFlow-Based Augmentations**","a0f7e198":"# **Albumentations Augmentations**"}}