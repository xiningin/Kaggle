{"cell_type":{"0af51900":"code","262630ba":"code","8bd49ec6":"code","dc96d01a":"code","dda79e56":"code","411b4367":"code","acba92df":"code","e47b092a":"code","6561ebcd":"code","4d638629":"code","4dc2a27a":"code","9d04d991":"code","cd977bfa":"code","aca52f6b":"code","d0205ff5":"markdown","1dc6caf0":"markdown","9071d0fa":"markdown","6028fdeb":"markdown","247f5885":"markdown","698ed03f":"markdown","ef135475":"markdown","4544a231":"markdown","ebf3fa0c":"markdown","8cea0292":"markdown","0511918c":"markdown","485af9d7":"markdown","5c3b58f7":"markdown","e1ee66ca":"markdown","c12c3aba":"markdown","b1c20fbc":"markdown","612d5f09":"markdown","95f97826":"markdown","986bf499":"markdown","bc3cdeb1":"markdown","f0e95559":"markdown","5aada240":"markdown","c6e544fc":"markdown"},"source":{"0af51900":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","262630ba":"from google.cloud import bigquery\nclient = bigquery.Client()","8bd49ec6":"javascript_query='''\nCREATE TEMPORARY FUNCTION \ngetDependenciesInPackageJson(content STRING)\nRETURNS STRING\nLANGUAGE js AS\n\"\"\"\n\nvar res = '';\ntry {\n    var x = JSON.parse(content);\n    \n    var list_dep = [];\n    if (x.dependencies) {\n      list_dep = Object.keys(x.dependencies);\n    }\n    \n    var list_devdep = [];\n    if (x.devDependencies) {\n      list_devdep = Object.keys(x.devDependencies);\n    }\n    \n    var list_alldep = list_dep.concat(list_devdep)\n    res = list_alldep.join(',')\n    \n\n} catch (e) {}\n\nreturn res;\n\"\"\";\n'''\nprint (javascript_query)","dc96d01a":"# --- Specify the table names \n\n# # Use sample tables when testing out the query\n# ds_files = 'bigquery-public-data.github_repos.sample_files'\n# ds_contents = 'bigquery-public-data.github_repos.sample_contents'\n\nds_files = 'bigquery-public-data.github_repos.files'\nds_contents = 'bigquery-public-data.github_repos.contents'\n\n\n# --- Specify a list of interested testing framework\nlist_fw = [\n    'mocha', \n    'jest',\n    'jasmine',\n    'qunit',\n    'funcunit',\n    'cypress',\n    'puppeteer',\n    'chai',\n    'sinon'\n]","dda79e56":"my_sql_query=('''\nWITH t_dep AS (\n    SELECT \n        tf.id AS id, \n        tf.repo_name AS repo_name, \n        getDependenciesInPackageJson(tc.content) AS package_dep\n    FROM (\n        SELECT id, repo_name, path\n        FROM `{}`\n            WHERE path LIKE \"package.json\" \n    ) AS tf\n    LEFT JOIN\n      `{}` tc\n    ON\n      tf.id = tc.id\n),\n\nt_dep_check AS (\n    SELECT repo_name, package_dep,\n        REGEXP_CONTAINS(package_dep, r\"{}\") AS is_interested\n    FROM t_dep\n)\n\nSELECT repo_name, package_dep\nFROM t_dep_check\n    WHERE is_interested\n''').format(ds_files, ds_contents, '|'.join(list_fw))","411b4367":"final_query=javascript_query+my_sql_query\nprint (final_query)","acba92df":"my_job_config = bigquery.job.QueryJobConfig()\nmy_job_config.dry_run = True\n\nmy_job = client.query(final_query, job_config=my_job_config)\nBYTES_PER_GB = 2**30\nmy_job.total_bytes_processed \/ BYTES_PER_GB","e47b092a":"query_contents = client.query(final_query)\n\n# Create a dataframe from the queried results\ndf_contents = query_contents.to_dataframe()","6561ebcd":"# Make a copy of this dataframe before cleaning & transforming it\ndf_interested = df_contents.copy()\n\n# Sort by the 'repo_name' column\ndf_interested = df_interested.sort_values(by='repo_name')","4d638629":"# Inspect the data \ndf_contents.head()","4dc2a27a":"df_interested.shape","9d04d991":"for cur_fw in list_fw:\n    df_interested[cur_fw] = df_interested.package_dep.str.contains(cur_fw)","cd977bfa":"df_interested[list_fw].sum(axis=0).sort_values(ascending=False)","aca52f6b":"df_interested.to_csv(\"github_package_deps_June_2019.csv\",index=False)\n","d0205ff5":"Before extracting data from BigQuery, Let's see how much data will be processed in this query to ensure that we won't exceed the free tier quota.","1dc6caf0":"## Where the data is collected?","9071d0fa":"The following query was inspired by\n\nhttps:\/\/www.kaggle.com\/ibadia\/using-javascript-with-bigquery-simple-tutorial","6028fdeb":"Inspect how many repositories depend on those testing frameworks","247f5885":"### Data Requirements\n\n1. Extract data only github project which\n   * contains package.json\n   * package.json contains at lease one of the interested testing frameworks in the 'dependencies' or 'devDependencies' keys\n   \n2. Each row will contains the following columns:\n   * repository name\n   * Name of all listed dependencies\n   * Columns where their name is one of the interested testing framework and its value is a Boolean value which indicate whether that particular testing framework is present in the dependencies listed in package.json","698ed03f":"Inspect the size of the output data","ef135475":"First, create a [User-Defined function](https:\/\/cloud.google.com\/bigquery\/docs\/reference\/standard-sql\/user-defined-functions) that we will use to get a list of dependencies in package.json","4544a231":"## Data Wrangling","ebf3fa0c":"With the current query, it will process around 2.5 TB and we should find a better optimized query for this.\n\nHowever, since we still have enough quota left and we need this data, we will proceed with this query.","8cea0292":"After listing out all requirements and steps, let start the data wrangling process!","0511918c":"We will extract data from the Kaggle's BigQuery dataset **GitHub Repos** which contains a full snapshot of the content of more than 2.8 million open source GitHub repositories  since 2008.\n\nSee more details about this dataset here: https:\/\/www.kaggle.com\/github\/github-repos\n\nNote that this dataset was **LAST UPDATED** on **2019-03-20** at the time this note book this run (2019-06-27)","485af9d7":"### Construct a query","5c3b58f7":"# Extracting data of popular testing framework lised in package.json in github projects via BigQuery","e1ee66ca":"After getting the queried data, we will transform it first before exporting it to a .csv file.\n\nBelow is what we will do in this section:\n1. Sort data by the **repo_name** column\n2. Then, create new columns for all interested testing framework and assign a Boolean value to indicate whether a particular repository depends on those testing framework or not","c12c3aba":"Then, create a query for the steps mentioned earlier","b1c20fbc":"Let's first start by loading all required packages","612d5f09":"<hr \/>","95f97826":"### Steps\n\nBelow are steps that are required to collect the required data\n1. Create a subtable called **tf** which created from:\n   * Filter only rows which contains **package.json** in its file path in the **files** table. \n   * SELECT the **id** and **repo_name** columns\n2. Create a new table called **t_dep** by \n   * JOIN the subtable **tf** with the **contents** table on the **id** column \n   * SELECT the **id** and **repo_name** columns of the subtable tf, and create a new column **package_dep** which contains a list of all packages listed in the ***dependencies*** or ***devDependencies*** in package.json using text in the content column\n3. Create a new table called **t_dep_check** by \n   * SELECT the **repo_name** and **package_dep** columns of the table **t_dep**\n   * Create a new column **is_interested** by checking whether a value in the **package_dep** columh contains any interested testing framework. Set this value if any interested framework to True is found, and False otherwise.\n4. Finally, only return data where the **is_interested** value is True****","986bf499":"This notebook contains steps of how to extract data of popular testing framework lised in package.json in github projects via BigQuery\n\nBelow is a list of interested testing framework that we will use in the query:\n* mocha\n* jest\n* jasmine\n* qunit\n* funcunit\n* cypress\n* puppeteer\n* chai\n* sinon","bc3cdeb1":"Loop through each interested testing framework and update its column by checking whether the **package_dep** contains the current testing framework in the loop","f0e95559":"## Data Transformation","5aada240":"Finally, concatenate the UDF and query to construct a final query","c6e544fc":"## Let's get started!"}}