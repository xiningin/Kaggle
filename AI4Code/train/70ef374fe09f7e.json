{"cell_type":{"e49823a8":"code","111c29d1":"code","f0dadfb5":"code","ba4d3f2c":"code","f45c5c94":"code","c833037b":"code","4be5d7d9":"code","20f952ae":"code","dbf920a1":"code","4bc3d46f":"code","62b60c53":"code","e486fc6a":"code","4dfd948b":"code","6117aabf":"code","9eb750d5":"code","06015403":"code","bf65f2d4":"code","d1994377":"code","4698c0a6":"code","ccee3ef0":"code","48064f70":"code","48ce31a6":"code","c40ec382":"markdown","6b28467b":"markdown","1cbe52b1":"markdown","2f10ff3b":"markdown","c3f9fc68":"markdown","d7439347":"markdown","747be953":"markdown","ef97f98f":"markdown","5fcd296b":"markdown","91ecc810":"markdown","4196cfeb":"markdown","7066eac3":"markdown","6ceae25e":"markdown","a765611d":"markdown","f8dc2b40":"markdown","cb6f0807":"markdown","bc2a1695":"markdown"},"source":{"e49823a8":"!pip install colorgram.py\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # plot data\n\nimport os # read file\nimport colorgram #Extract color from images \n\nimport sklearn #scikit-learn library, where the magic happens!\nimport cv2 #OpenCV, image processing library","111c29d1":"gems_df = pd.DataFrame(columns=['label', 't_set', 'file'])\n\nfor root, _, files in os.walk('\/kaggle\/input\/gemstones-images'):\n    for file in files:\n        path = os.path.join(root, file)\n        label = path.split(os.sep)[-2]\n        t_set = path.split(os.sep)[-3]\n        gems_df.loc[len(gems_df)]=[label,t_set,path]\n\nprint(gems_df)","f0dadfb5":"gems_df['label'].value_counts()","ba4d3f2c":"def get_pallet(gem):\n    n_color = 5\n    colors = colorgram.extract(gem['file'], n_color)\n    for i in range(len(colors)):\n        gem['red'+str(i)] = colors[i].rgb.r\n        gem['green'+str(i)] = colors[i].rgb.g\n        gem['blue'+str(i)] = colors[i].rgb.b\n        gem['proportion'+str(i)] = colors[i].proportion\n    return gem\n\ngems_color_df = gems_df.apply(get_pallet, axis=1)\ngems_color_df.fillna(0,inplace=True)\n\ngems_color_df","f45c5c94":"X_train = gems_color_df[gems_color_df['t_set']=='train'].drop(['file', 't_set', 'label'], axis=1)\ny_train = gems_color_df[gems_color_df['t_set']=='train'][['label']]\n\nX_test = gems_color_df[gems_color_df['t_set']=='test'].drop(['file', 't_set', 'label'], axis=1)\ny_test = gems_color_df[gems_color_df['t_set']=='test'][['label']]\n\nprint(X_train)\nprint(y_train)","c833037b":"from sklearn.tree import DecisionTreeClassifier\n\ntree = DecisionTreeClassifier(random_state=0)\ntree.fit(X_train, y_train)\n\nprint(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(tree.score(X_test, y_test)))","4be5d7d9":"from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\npca = PCA(n_components=20)\npca.fit(X_train)\n\nX_train_pca = pca.transform(X_train)\nX_test_pca = pca.transform(X_test)\n\nprint(\"X_train_pca.shape: {}\".format(X_train_pca.shape))\n\ntree = DecisionTreeClassifier(random_state=0)\ntree.fit(X_train_pca, y_train)\n\nprint(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train_pca, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(tree.score(X_test_pca, y_test)))","20f952ae":"from sklearn.neural_network import MLPClassifier\n\nmlp = MLPClassifier(solver='lbfgs', random_state=0, hidden_layer_sizes=[20])\nmlp.fit(X_train, y_train.values.ravel())\n\nprint(\"Accuracy on training set: {:.3f}\".format(mlp.score(X_train, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(mlp.score(X_test, y_test)))","dbf920a1":"def get_pallet(gem):\n    n_color = 5\n    colors = colorgram.extract(gem['file'], n_color)\n    for i in range(len(colors)):\n        gem['hue'+str(i)] = colors[i].hsl.h\n        gem['sat'+str(i)] = colors[i].hsl.s\n        gem['light'+str(i)] = colors[i].hsl.l\n        gem['proportion'+str(i)] = colors[i].proportion\n    return gem\n\ngems_hsl_df = gems_df.apply(get_pallet, axis=1)\ngems_hsl_df.fillna(0,inplace=True)\n\ngems_hsl_df","4bc3d46f":"X_train = gems_hsl_df[gems_hsl_df['t_set']=='train'].drop(['file', 't_set', 'label'], axis=1)\ny_train = gems_hsl_df[gems_df['t_set']=='train'][['label']]\n\nX_test = gems_hsl_df[gems_hsl_df['t_set']=='test'].drop(['file', 't_set', 'label'], axis=1)\ny_test = gems_hsl_df[gems_hsl_df['t_set']=='test'][['label']]\n\nprint(X_train)\nprint(y_train)","62b60c53":"tree = DecisionTreeClassifier(random_state=0)\ntree.fit(X_train, y_train)\n\nprint(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(tree.score(X_test, y_test)))","e486fc6a":"pca = PCA(n_components=20)\npca.fit(X_train)\n\nX_train_pca = pca.transform(X_train)\nX_test_pca = pca.transform(X_test)\n\nprint(\"X_train_pca.shape: {}\".format(X_train_pca.shape))\n\ntree = DecisionTreeClassifier(random_state=0)\ntree.fit(X_train_pca, y_train)\n\nprint(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train_pca, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(tree.score(X_test_pca, y_test)))","4dfd948b":"mlp = MLPClassifier(solver='lbfgs', random_state=0, hidden_layer_sizes=[5])\nmlp.fit(X_train, y_train.values.ravel())\n\nprint(\"Accuracy on training set: {:.3f}\".format(mlp.score(X_train, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(mlp.score(X_test, y_test)))","6117aabf":"img_w, img_h = 200, 200\n\nprint(gems_df['file'][0])\n\nimage = cv2.imread(gems_df['file'][344])\nimage = cv2.resize(image,(int(img_w*1.5), int(img_h*1.5)))\nimage_cv = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # converts an image from BGR color space to RGB\nimage = np.array(image_cv)\n\nplt.imshow(image)","9eb750d5":"blur = cv2.blur(image_cv, (3,3))\nblur = cv2.bilateralFilter(blur,5,75,75)\n\nplt.imshow(blur)\ncanny = cv2.Canny(blur, img_w, img_h)\nplt.imshow(canny)","06015403":"## find the non-zero min-max coords of canny\npts = np.argwhere(canny>0)\nif pts.any()>0:\n    y1,x1 = pts.min(axis=0)\n    y2,x2 = pts.max(axis=0)\n\n    if abs(y1-y2)>50 or abs(x1-x2)>50:\n        ## crop the region\n        image = image_cv[y1:y2, x1:x2]\n\n#resize\nimage = cv2.resize(image,(img_w, img_h))\n\nplt.imshow(image)","bf65f2d4":"def get_and_crop_image(series):\n    img_w, img_h = 220, 220\n\n    image = cv2.imread(series['file'])\n    image = cv2.resize(image,(int(img_w*1.5), int(img_h*1.5)))\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # converts an image from BGR color space to RGB\n\n    #blur\n    blur = cv2.blur(image, (3,3))\n    blur = cv2.bilateralFilter(blur,5,75,75)\n    \n    #edge detection - canny\n    canny = cv2.Canny(blur, img_w, img_h)\n\n    #crop\n    pts = np.argwhere(canny>0)\n    if pts.any()>0:\n        y1,x1 = pts.min(axis=0)\n        y2,x2 = pts.max(axis=0)\n        \n        \n        if abs(y1-y2)>50 or abs(x1-x2)>50:\n            ## crop the region\n            image = image[y1:y2, x1:x2]\n            \n    image = cv2.resize(image,(img_w, img_h))\n    image = np.array(image).flatten()\n    \n    series['image'] = image\n    return series","d1994377":"def explode(serie):\n    serie = serie.join(pd.DataFrame(serie.image.tolist(),index=serie.index).add_prefix('img_'))\n    print(serie)\n    return serie","4698c0a6":"gems_image_df = gems_df\ngems_image_df = gems_image_df.apply(get_and_crop_image, axis=1)\n\ntags = gems_image_df['image'].apply(pd.Series)\ntags = tags.rename(columns = lambda x : 'img_' + str(x))\ntags\n\ngems_image_df = gems_image_df.drop(['image'], axis=1)\ngems_image_df = pd.concat([gems_image_df[:], tags[:]], axis=1)\n\ngems_image_df","ccee3ef0":"X_train = gems_image_df[gems_image_df['t_set']=='train'].drop(['file', 't_set', 'label'], axis=1)\ny_train = gems_image_df[gems_image_df['t_set']=='train'][['label']]\n\nX_test = gems_image_df[gems_image_df['t_set']=='test'].drop(['file', 't_set', 'label'], axis=1)\ny_test = gems_image_df[gems_image_df['t_set']=='test'][['label']]\n\nfrom sklearn.tree import DecisionTreeClassifier\n\ntree = DecisionTreeClassifier(random_state=0)\ntree.fit(X_train, y_train)\n\nprint(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(tree.score(X_test, y_test)))","48064f70":"from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\n#n_components:20 -> Accuracy: 0.284\n#n_components:14 -> Accuracy: 0.292\n#n_components:12 -> Accuracy: 0.300\n#n_components:11 -> Accuracy: 0.314\n#n_components:10 -> Accuracy: 0.320\n#n_components:9 -> Accuracy: 0.300\n#n_components:8 -> Accuracy: 0.273\n\npca = PCA(n_components=10)\npca.fit(X_train)\n\nX_train_pca = pca.transform(X_train)\nX_test_pca = pca.transform(X_test)\n\nprint(\"X_train_pca.shape: {}\".format(X_train_pca.shape))\n\ntree = DecisionTreeClassifier(random_state=0)\ntree.fit(X_train_pca, y_train)\n\nprint(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train_pca, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(tree.score(X_test_pca, y_test)))","48ce31a6":"from sklearn.neural_network import MLPClassifier\n\n#solver='lbfgs'\n#hidden_layer_sizes:10 -> Accuracy: 0.008\n#hidden_layer_sizes:50 -> Accuracy: 0.011\n#hidden_layer_sizes:100 -> Accuracy: 0.017\n#hidden_layer_sizes:150 -> Accuracy: 0.011\n\n#solver='adam'\n#hidden_layer_sizes:10 -> Accuracy: 0.014\n#hidden_layer_sizes:50 -> Accuracy: 0.014\n#hidden_layer_sizes:100 -> Accuracy: 0.014\n\nmlp = MLPClassifier(solver='lbfgs', random_state=0, hidden_layer_sizes=[150])\nmlp.fit(X_train, y_train.values.ravel())\n\nprint(\"Accuracy on training set: {:.3f}\".format(mlp.score(X_train, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(mlp.score(X_test, y_test)))","c40ec382":"#### 2.3.4. OpenCV Conclusion\n\nUh, with the OpenCV image croping and with the ML applied, we only got to **0.320 accuracy.**\n\n\n## 3. Conclusion\n\n### 3.1. TL;DR\n\n* We tried to use only the 5 most common colors on the image, got a **0.278 accuracy**\n* We tried to use only the 5 most common HSL colors on the image, got a **0.292 accuracy**\n* We tried to use OpenCV to crop the images and used the full image, got a **0.320 accuracy**\n\n### 3.2. Objective & Final Considerations\n\n**Daria got 0.650** using tensorflow and some magic with the OpenCV (Generating more images croping the original image,etc).\nWe should probably studie some tensorflow eventualy and see if we can get better results.\n\nBut for now we at least know that a simple color analisys already get us a **0.292 accuracy.**","6b28467b":"So, a 0.998 result on the training set and 0.275 on the test set on a decision tree method. So we are probably overfitting.\n\n#### 2.1.2. PCA Tree","1cbe52b1":"#### 2.2.4. HSL Conclusion\n\n* **Decision Tree \/** Training:0.998 Test:0.292\n* **PCA Tree \/** Training:0.998 Test:0.240  \n* **MLPClassifier \/** Training:0.037 Test:0.039\n\nSo, with HSL color we got better results. This tell us that probably the 'true' color, without the light information mixed in is better for our analize.\n\nOk, so the best we got till here is 0.292 accuracy.\n\n### 2.3. OpenCV and Image\n\nAlright, know we are cooking with fire.\n\nWith OpenCV we can do some interesting things with the image before processing.\nFor starter, let's just open the images with a stand size (200x200 pixels)","2f10ff3b":"#### 2.2.2. PCA Tree","c3f9fc68":"As we can see, not all gems have the same number of images, and we don't have a lot of images to train, but let's do it and see what results we can get.\n\n## 2. Machine Learning\n\n### 2.1. Color\n\nOk, first we are gonna do a simplification of the problem and check if we can identify the gems using only a color pallet of then.\n\nWe know that this will probably not be enough, ruby and garnets are both a similar shade of red, tourmaline is available in a range simillar to a lot of other gems like sapphire,garnet,opals. [Here is a site with some common similar gems if you have any interese on this](https:\/\/www.gemstonemagnetism.com\/how_to_pg_5.html)\n\nBut this will at least give us a guideline. If our more complex models don't perform better then this simple one, we are probably on the wrong track.","d7439347":"0.998 result on the training set and 0.278 on the test set on a PCA tree method. A little better.\n\n#### 2.1.3. MLPClassifier","747be953":"#### 2.3.2. PCA Tree","ef97f98f":"## 1. Data\n\n### 1.1. Data Import\n\nFortunaly for us, [Daria Chemkaeva](https:\/\/www.kaggle.com\/lsind18) already made a prety sweet [dataset](https:\/\/www.kaggle.com\/lsind18\/gemstones-images) of 87 classes of gemstones, divided in train and test groups.\n\nSince she also made a notebook using tensorflow, let's compare our result on the conclusion.","5fcd296b":"We will get the 5 main colors of every image and see were that lead us.\n\n#### 2.1.1. Decision Tree","91ecc810":"Since the algorith works, let's build a function and apply that to all the images.\n\nFeel free to go get a coffe or something, this will probably take a while.","4196cfeb":"#### 2.2.1. DecisionTree","7066eac3":"0.028 result on the training set and 0.019 on the test set on a MLPClassifier. So we are probably overfitting.\n\n#### 2.1.4. Color Conclusion\n* **Decision Tree \/** Training:0.998 Test:0.275\n* **PCA Tree \/** Training:0.998 Test:0.278  \n* **MLPClassifier \/** Training:0.028 Test:0.019\n\nSo, with only the color info, using a PCA Tree we get a **0.278 accuracy.** Not bad for a quick experiment.\n\n### 2.2. HSL\n\nAnother quick experiment we can do is check if we get better info with a HSL Color analisys.\n\n**HSL contains Hue, Saturation and Lightness.**\n\nSince Hue give us the color without the light condition, maybe we can have better accuracy on our models.","6ceae25e":"#### 2.2.3. MLPClassifier","a765611d":"Now we aply a blur and bilateral filter, and then do a canny edge detection. With the edge determined, we can box and cut only the gem on the image.","f8dc2b40":"#### 2.3.3. MLPClassifier","cb6f0807":"# Gemstones - Multiclass Classification\n\nOn my spare time I am a silversmith, so i work a lot with gems. One of the problems is that a lot of gems are look realy similar to the untrained eye, and some you can only be sure using light refraction.\n\nLet's see if we can make some simple machine leaning exercises and measure how much each common ML aproach respond to images of diferent gems.\n\n## Table of Contents\n- 1. Data\n    - 1.1. Data Import\n- 2. Machine Learning\n    - 2.1. Color\n        - 2.1.1. Decision Tree\n        - 2.1.2. PCA Tree\n        - 2.1.3. MLPClassifier\n        - 2.1.4. Color Conclusion\n    - 2.2. HSL\n        - 2.2.1 DecisionTree\n        - 2.2.2. PCA Tree\n        - 2.2.3. MLPClassifier\n        - 2.2.4. HSL Conclusion\n    - 2.3. OpenCV and Image\n        - 2.3.1. DecisionTree\n        - 2.3.2. PCA Tree\n        - 2.3.3. MLPClassifier\n        - 2.3.4. OpenCV Conclusion\n- 3. Conclusion\n    - 3.1. TL;DR\n    - 3.2. Objective & Final Considerations","bc2a1695":"#### 2.3.1. DecisionTree"}}