{"cell_type":{"bd36b790":"code","0a594187":"code","48f76ebb":"code","ee4dbfdb":"code","80db8f10":"code","c246e293":"code","849f9d53":"code","c411d4e0":"code","b3b1b0bc":"code","1b646479":"code","955b5e0a":"code","2c67138a":"code","334434fc":"code","3a0a896f":"code","9928de01":"code","7fca9b71":"code","3970588d":"code","37ad7338":"code","4b81b9e4":"code","95a3b3a0":"code","1cd10135":"code","d759825c":"code","8833ea2c":"markdown","0ead64e4":"markdown","048c1f99":"markdown","2561bcbf":"markdown","87111c53":"markdown","5adf7bc6":"markdown","0859c0c6":"markdown","3ac6b486":"markdown","ee8eb619":"markdown","fe9b124a":"markdown","608dd461":"markdown","dcacd33f":"markdown","9d73b1e6":"markdown","3bbdab35":"markdown","f3579c8d":"markdown","bcb8496c":"markdown","cc8191d2":"markdown"},"source":{"bd36b790":"# Libraries\nimport os, shutil\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\n\nfrom keras import layers\nfrom keras import models, optimizers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import optimizers\n#from keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.vgg16 import VGG16","0a594187":"# path to the folder where the whole dataset is stored\noriginal_dataset_dir = '..\/input\/microsoft-catsvsdogs-dataset\/PetImages'\n\n# create a folder to store our small sample of images\nbase_dir = '..\/cats_and_dogs_small'\nos.mkdir(base_dir)","48f76ebb":"# create sub-folders for training, validation and test sets\ntrain_dir = os.path.join(base_dir, 'train')\nos.mkdir(train_dir)\n\nvalidation_dir = os.path.join(base_dir, 'validation')\nos.mkdir(validation_dir)\n\ntest_dir = os.path.join(base_dir, 'test')\nos.mkdir(test_dir)\n\n# create sub-folders Cat and Dog \ntrain_Cat_dir = os.path.join(train_dir, 'Cat')\nos.mkdir(train_Cat_dir)\n\ntrain_Dog_dir = os.path.join(train_dir, 'Dog')\nos.mkdir(train_Dog_dir)\n\nvalidation_Cat_dir = os.path.join(validation_dir, 'Cat')\nos.mkdir(validation_Cat_dir)\n\nvalidation_Dog_dir = os.path.join(validation_dir, 'Dog')\nos.mkdir(validation_Dog_dir)\n\ntest_Cat_dir = os.path.join(test_dir, 'Cat')\nos.mkdir(test_Cat_dir)\n\ntest_Dog_dir = os.path.join(test_dir, 'Dog')\nos.mkdir(test_Dog_dir)","ee4dbfdb":"# copy images from the whole dataset to different folders :\n\n# copy the first 1000 cats images to the folder train_dir \nfnames = ['{}.jpg'.format(i) for i in range(1000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir + '\/Cat', fname)\n    dst = os.path.join(train_Cat_dir, fname)\n    shutil.copyfile(src, dst)\n    \n# copy the following 500 cats images to the folder validation_dir \nfnames = ['{}.jpg'.format(i) for i in range(1000, 1500)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir + '\/Cat', fname)\n    dst = os.path.join(validation_Cat_dir, fname)\n    shutil.copyfile(src, dst)\n\n# copy the following 500 cats images to the folder test_dir    \nfnames = ['{}.jpg'.format(i) for i in range(1500, 2000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir + '\/Cat', fname)\n    dst = os.path.join(test_Cat_dir, fname)\n    shutil.copyfile(src, dst)\n\n    \n# copy the first 1000 dogs images to the folder train_dir \nfnames = ['{}.jpg'.format(i) for i in range(1000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir + '\/Dog', fname)\n    dst = os.path.join(train_Dog_dir, fname)\n    shutil.copyfile(src, dst)\n    \n# copy the following 500 dogs images to the folder validation_dir \nfnames = ['{}.jpg'.format(i) for i in range(1000, 1500)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir + '\/Dog', fname)\n    dst = os.path.join(validation_Dog_dir, fname)\n    shutil.copyfile(src, dst)\n\n# copy the following 500 dogs images to the folder test_dir    \nfnames = ['{}.jpg'.format(i) for i in range(1500, 2000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir + '\/Dog', fname)\n    dst = os.path.join(test_Dog_dir, fname)\n    shutil.copyfile(src, dst)","80db8f10":"# quick check\nprint(\"total training cat images :\", len(os.listdir(train_Cat_dir)))\nprint(\"total training dog images :\", len(os.listdir(train_Dog_dir)))\nprint(\"total validation cat images :\", len(os.listdir(validation_Cat_dir)))\nprint(\"total validation dog images :\", len(os.listdir(validation_Dog_dir)))\nprint(\"total test cat images :\", len(os.listdir(test_Cat_dir)))\nprint(\"total test dog images :\", len(os.listdir(test_Dog_dir)))","c246e293":"# size of an image\nimg = cv2.imread(train_Cat_dir + '\/' + os.listdir(train_Cat_dir)[0])\nimg.shape","849f9d53":"# error in data\n# We just replace 666.jpg by 665.jpg\nshutil.copyfile(train_Cat_dir + '\/665.jpg', train_Cat_dir + '\/666.jpg')","c411d4e0":"conv_base = VGG16(weights='..\/input\/vgg16\/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False, input_shape=(150,150,3))","b3b1b0bc":"conv_base.summary()","1b646479":"datagen = ImageDataGenerator(rescale=1.\/255)\nbatch_size = 20\n\n''' Function 'extract_feature()'\n* inputs : \n  * 'directory' : folder containing the images (train_dir, validation_dir or test_dir)\n  * 'sample_count' : number of images in the directory (2000 or 1000)\n* outputs :\n  * 'features' : features extracted, each with the format (4, 4, 512) \n  * 'labels' : labels of the images. \n'''\n\ndef extract_feature(directory, sample_count):\n    # initialize the arrays 'features' and 'labels' with zeros\n    features = np.zeros(shape=(sample_count, 4, 4, 512))\n    labels = np.zeros(shape=(sample_count,))\n    # apply the generator to the directory \n    generator = datagen.flow_from_directory(\n        directory,\n        target_size=(150,150),\n        batch_size=batch_size,\n        class_mode='binary'\n    )\n    # use the convolutional base on the generated images (.predict())\n    # add the extracted features and the generated labels to the arrays 'features' et 'labels'\n    # stop when all the images in the directory are treated\n    i=0\n    for inputs_batch, labels_batch in generator:\n        features_batch = conv_base.predict(inputs_batch)\n        features[i*batch_size : (i+1)*batch_size] = features_batch \n        labels[i*batch_size : (i+1)*batch_size] = labels_batch\n        i += 1\n        if i*batch_size >= sample_count:\n            break\n    return features, labels\n\n# apply the function 'extract_feature()' to the 3 directories train_dir, validation_dir, test_dir\ntrain_features, train_labels = extract_feature(train_dir, 2000)\nvalidation_features, validation_labels = extract_feature(validation_dir, 1000)\ntest_features, test_labels = extract_feature(test_dir, 1000)","955b5e0a":"train_features = np.reshape(train_features, (2000, 4*4*512))\nvalidation_features = np.reshape(validation_features, (1000, 4*4*512))\ntest_features = np.reshape(test_features, (1000, 4*4*512))","2c67138a":"model = models.Sequential()\n\nmodel.add(layers.Dense(256, activation='relu', input_dim=4*4*512))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='rmsprop',  # optimizers.RMSprop(lr=1e-4) ??\n             loss='binary_crossentropy',\n             metrics=['accuracy'])","334434fc":"history = model.fit(\n            train_features, train_labels,\n            epochs=30, \n            batch_size=20,\n            validation_data=(validation_features, validation_labels)\n)","3a0a896f":"# save the trained model\nmodel.save('classifying_cats_dogs_small_3.h5')","9928de01":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc)+1)\n\nplt.plot(epochs, acc, 'bo', label='training')\nplt.plot(epochs, val_acc, 'b', label='validation')\nplt.title(\"Training and Validation Accuracy\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='training')\nplt.plot(epochs, val_loss, 'b', label='validation')\nplt.title(\"Training and Validation Loss\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","7fca9b71":"train_datagen = ImageDataGenerator(rescale=1.\/255,\n                                  rotation_range=40,\n                                  width_shift_range=0.2,\n                                  height_shift_range=0.2,\n                                  shear_range=0.2,\n                                  zoom_range=0.2, \n                                  horizontal_flip=True, \n                                  fill_mode='nearest')\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n                        train_dir,\n                        target_size=(150,150),\n                        batch_size=20,\n                        class_mode='binary' \n                        )\n\nvalidation_generator = test_datagen.flow_from_directory(\n                        validation_dir,\n                        target_size=(150,150),\n                        batch_size=20,\n                        class_mode='binary' \n                        )","3970588d":"model = models.Sequential()\n\nmodel.add(conv_base)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation='relu'))\n#model.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(1, activation='sigmoid'))","37ad7338":"model.summary()","4b81b9e4":"print(\"Number of trainable weights before freezing:\", len(model.trainable_weights))\nconv_base.trainable = False\nprint(\"Number of trainable weights after freezing:\", len(model.trainable_weights))","95a3b3a0":"model.compile(optimizer='rmsprop',  # optimizers.RMSprop(lr=1e-4) ??\n             loss='binary_crossentropy',\n             metrics=['accuracy'])\n\nhistory = model.fit_generator(\n            train_generator,\n            #steps_per_epoch=100,     \n            epochs=30, \n            validation_data=validation_generator,\n            #validation_steps=50      \n)","1cd10135":"# save the trained model \nmodel.save('classifying_cats_dogs_small_4.h5')","d759825c":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc)+1)\n\nplt.plot(epochs, acc, 'bo', label='training')\nplt.plot(epochs, val_acc, 'b', label='validation')\nplt.title(\"Training and Validation Accuracy\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='training')\nplt.plot(epochs, val_loss, 'b', label='validation')\nplt.title(\"Training and Validation Loss\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","8833ea2c":"***\n\n# **Method 2 : with Data Augmentation**\n\nSteps :\n* generate the images with data augmentation\n* build the model with the convolution base and the new classifier together \n* freeze the convolutional base, don't need to be trained\n* train the model\n* evaluate.","0ead64e4":"***\n# Reference \n\n* book : Francois Chollet, L'apprentissage profond avec Python","048c1f99":"# Build the model","2561bcbf":"## Generate the images with data augmentation","87111c53":"## Evaluate the model","5adf7bc6":"## Train the classifier","0859c0c6":"# Evaluate the model","3ac6b486":"***\n# Complement : Fine-tuning\n\nWe can try to go further with this technique. \n\nIdea :\n* unfreeze a certain number of the last convolutional layers, in the convolutional base\n* then train those freed layers with the classifier. ","ee8eb619":"## Train the model","fe9b124a":"## Resize the extracted features\n\nThe extracted features have the format (samples, 4, 4, 512) : we flatten them into the format (samples, 4x4x512).","608dd461":"The accuracy is pretty good, around 90%, but the model is in overfitting from the beginning.","dcacd33f":"# **Classifying Dogs and Cats with a pre-trained model**\n\nOriginal dataset : [Cats-vs-Dogs : image dataset for binary classification](https:\/\/www.kaggle.com\/shaunthesheep\/microsoft-catsvsdogs-dataset)\n\nNotebook related : [Classifying Cats And Dogs 1 : from scratch](https:\/\/www.kaggle.com\/dataandmaths\/classifying-cats-and-dogs-1-from-scratch)\n*** \n\n# **Ideas** \n\nA pre-trained ConvNet is composed of two parts :\n* the **convolutional base** (convolutions + poolings)\n* the **classifier** (fully connected network).\n\nWe keep the convolutional base, which probably has the most generic informations.  \n\nWe change the classifier to adapt to the problem we have to deal with. \n\n***","9d73b1e6":"## Define the new classifier","3bbdab35":"***\n\n# **Data**\n\n* Whole dataset : around 25 000 images (around 12 500 of each class)\n  \n* We use just a small part of those images. \n\n* Steps \n  * Load the dataset\n  * Create 3 sets :\n    * a training set with 1000 images\n    * a validation set with 500 images\n    * a test set with 500 images.\n\n* Functions we use :\n  * os.mkdir() : create a new folder\n  * os.path.join(path, string) : add the string to the path\n  * shutil.copyfile(source, destination) : copy the file from the source to the destination.\n\n* NB : ignore the potential error messages due to multiple use of mkdir to create the same folder.","f3579c8d":"## Freeze the convolutional base","bcb8496c":"***\n\n# **Method 1 : without Data Augmentation**\n\nSteps :\n* use the pre-trained model to extract the features\n* resize the output so that it can used by the classifier\n* train the new classifier\n* evaluate. \n\n\n## Extract the features with the convolutional base\n\nWe use the class **ImageDataGenerator()**. ","cc8191d2":"***\n\n# **Load a pre-trained model**\n\nWe use **VGG16()**, with arguments :\n* weights : from the training on the dataset ImageNet (1.4 millions of images, 1000 classes)\n* include_top : include or not the top part of the network, the fully-connected one\n* input_shape.\n\nNB : error when downloading the model \n* [forum kaggle](https:\/\/www.kaggle.com\/questions-and-answers\/128824#735972)\n* [forum kaggle](https:\/\/www.kaggle.com\/getting-started\/40246)\n* first : 'Add Data' >> 'vgg16' "}}