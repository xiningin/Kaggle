{"cell_type":{"2bfba8cf":"code","f382113f":"code","34c12bd3":"code","5828f9b0":"code","e3dfe19a":"code","1b3fd308":"code","6f0421bf":"code","8af3cc2d":"code","19e84ea4":"code","5e55dcd2":"code","8a3c8017":"code","60ca0dd7":"code","37e94ed5":"code","dd2cadf7":"code","676ce40f":"code","3b85a04b":"code","54687472":"code","7efe60a6":"code","1c6d6e2d":"code","e78d16d8":"code","62c178a1":"code","c83f74a6":"code","68e7ed95":"code","7445ce27":"code","c56c78f8":"code","70a21159":"code","8a3a9902":"code","7c103b40":"code","833128d6":"code","51c2bcb4":"code","8d1e6e6e":"code","8e99cc02":"code","2d54e476":"code","c2656ca1":"code","c5381e15":"code","59f58920":"code","43babd30":"code","9f6b5bc8":"code","72cbbad1":"code","1745b1b6":"code","74df4c32":"code","47736602":"code","00076ad2":"code","351143ba":"code","acf92bb3":"code","97f14819":"code","76e7863a":"code","3627329c":"code","7772946e":"code","fd6e01c9":"markdown","d39267f2":"markdown","d4618ebf":"markdown","0be59d5c":"markdown","bee6082d":"markdown","f7f52128":"markdown","3738f003":"markdown","4b957795":"markdown","5c21ab4a":"markdown","f7d872ea":"markdown","31f46353":"markdown","23ce36e2":"markdown","7695141e":"markdown","bd8fb23a":"markdown"},"source":{"2bfba8cf":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split,KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom bayes_opt import BayesianOptimization\nimport lightgbm as lgb\nimport os, sys\n","f382113f":"# Load data \ntrain = pd.read_csv('..\/input\/bigquery-geotab-intersection-congestion\/train.csv')\ntest = pd.read_csv('..\/input\/bigquery-geotab-intersection-congestion\/test.csv')\nsubmission = pd.read_csv('..\/input\/bigquery-geotab-intersection-congestion\/sample_submission.csv')","34c12bd3":"train.nunique()","5828f9b0":"print(train[\"City\"].unique())\nprint(test[\"City\"].unique())","e3dfe19a":"# test.groupby([\"City\"]).apply(np.unique)\ntest.groupby([\"City\"]).nunique()","1b3fd308":"train.isna().sum(axis=0)","6f0421bf":"test.isna().sum(axis=0)","8af3cc2d":"# %%time\n# def fill_na(df):\n#     df['ExitStreetName'] = df.apply(lambda x: x.EntryStreetName if type(x.ExitStreetName) != str else x.ExitStreetName, axis =1)\n#     df['EntryStreetName'] = df.apply(lambda x: x.ExitStreetName if type(x.EntryStreetName) != str else x.EntryStreetName, axis =1)\n#     df.fillna('ffill', inplace=True)\n#     return df\n# train = fill_na(train)\n# test = fill_na(test)","19e84ea4":"road_encoding = {\n\"Street\":0,\n \"St\":0,\n \"Avenue\":1,\n \"Ave\":1,\n \"Boulevard\":2,\n \"Road\":3,\n \"Drive\":4,\n \"Lane\":5,\n \"Tunnel\":6,\n \"Highway\":7,\n \"Way\":8,\n \"Parkway\":9,\n \"Parking\":10,\n \"Oval\":11,\n \"Square\":12,\n \"Place\":13,\n \"Bridge\":14}","5e55dcd2":"def encode(x):\n    if pd.isna(x):\n        return 0\n    for road in road_encoding.keys():\n        if road in x:\n            return road_encoding[road]\n        \n    return 0","8a3c8017":"train['EntryType'] = train['EntryStreetName'].apply(encode)\ntrain['ExitType'] = train['ExitStreetName'].apply(encode)\ntest['EntryType'] = test['EntryStreetName'].apply(encode)\ntest['ExitType'] = test['ExitStreetName'].apply(encode)","60ca0dd7":"directions = {\n    'N': 0,\n    'NE': 1\/4,\n    'E': 1\/2,\n    'SE': 3\/4,\n    'S': 1,\n    'SW': 5\/4,\n    'W': 3\/2,\n    'NW': 7\/4\n}","37e94ed5":"train['EntryHeading'] = train['EntryHeading'].map(directions)\ntrain['ExitHeading'] = train['ExitHeading'].map(directions)\n\ntest['EntryHeading'] = test['EntryHeading'].map(directions)\ntest['ExitHeading'] = test['ExitHeading'].map(directions)","dd2cadf7":"train['diffHeading'] = train['EntryHeading']-train['ExitHeading']  \ntest['diffHeading'] = test['EntryHeading']-test['ExitHeading'] ","676ce40f":"train.head()","3b85a04b":"train[\"same_street_exact\"] = (train[\"EntryStreetName\"] ==  train[\"ExitStreetName\"]).astype(int)\ntest[\"same_street_exact\"] = (test[\"EntryStreetName\"] ==  test[\"ExitStreetName\"]).astype(int)","54687472":"train[\"Intersection\"] = train[\"IntersectionId\"].astype(str) + train[\"City\"]\ntest[\"Intersection\"] = test[\"IntersectionId\"].astype(str) + test[\"City\"]\n","7efe60a6":"encoder = LabelEncoder()\nencoder.fit(pd.concat([train[\"Intersection\"],test[\"Intersection\"]]).drop_duplicates().values)\ntrain[\"Intersection\"] = encoder.transform(train[\"Intersection\"])\ntest[\"Intersection\"] = encoder.transform(test[\"Intersection\"])","1c6d6e2d":"monthly_av = {'Atlanta1': 43, 'Atlanta5': 69, 'Atlanta6': 76, 'Atlanta7': 79, 'Atlanta8': 78, 'Atlanta9': 73,\n              'Atlanta10': 62, 'Atlanta11': 53, 'Atlanta12': 45, 'Boston1': 30, 'Boston5': 59, 'Boston6': 68,\n              'Boston7': 74, 'Boston8': 73, 'Boston9': 66, 'Boston10': 55,'Boston11': 45, 'Boston12': 35,\n              'Chicago1': 27, 'Chicago5': 60, 'Chicago6': 70, 'Chicago7': 76, 'Chicago8': 76, 'Chicago9': 68,\n              'Chicago10': 56,  'Chicago11': 45, 'Chicago12': 32, 'Philadelphia1': 35, 'Philadelphia5': 66,\n              'Philadelphia6': 76, 'Philadelphia7': 81, 'Philadelphia8': 79, 'Philadelphia9': 72, 'Philadelphia10': 60,\n              'Philadelphia11': 49, 'Philadelphia12': 40}\n# Concatenating the city and month into one variable\ntrain['city_month'] = train[\"City\"] + train[\"Month\"].astype(str)\ntest['city_month'] = test[\"City\"] + test[\"Month\"].astype(str)\n\n# Creating a new column by mapping the city_month variable to it's corresponding average monthly temperature\ntrain[\"average_temp\"] = train['city_month'].map(monthly_av)\ntest[\"average_temp\"] = test['city_month'].map(monthly_av)\n","e78d16d8":"monthly_rainfall = {'Atlanta1': 5.02, 'Atlanta5': 3.95, 'Atlanta6': 3.63, 'Atlanta7': 5.12, 'Atlanta8': 3.67, 'Atlanta9': 4.09,\n              'Atlanta10': 3.11, 'Atlanta11': 4.10, 'Atlanta12': 3.82, 'Boston1': 3.92, 'Boston5': 3.24, 'Boston6': 3.22,\n              'Boston7': 3.06, 'Boston8': 3.37, 'Boston9': 3.47, 'Boston10': 3.79,'Boston11': 3.98, 'Boston12': 3.73,\n              'Chicago1': 1.75, 'Chicago5': 3.38, 'Chicago6': 3.63, 'Chicago7': 3.51, 'Chicago8': 4.62, 'Chicago9': 3.27,\n              'Chicago10': 2.71,  'Chicago11': 3.01, 'Chicago12': 2.43, 'Philadelphia1': 3.52, 'Philadelphia5': 3.88,\n              'Philadelphia6': 3.29, 'Philadelphia7': 4.39, 'Philadelphia8': 3.82, 'Philadelphia9':3.88 , 'Philadelphia10': 2.75,\n              'Philadelphia11': 3.16, 'Philadelphia12': 3.31}\n# Creating a new column by mapping the city_month variable to it's corresponding average monthly rainfall\ntrain[\"average_rainfall\"] = train['city_month'].map(monthly_rainfall)\ntest[\"average_rainfall\"] = test['city_month'].map(monthly_rainfall)","62c178a1":"monthly_snowfall = {'Atlanta1': 0.6, 'Atlanta5': 0, 'Atlanta6': 0, 'Atlanta7': 0, 'Atlanta8': 0, 'Atlanta9': 0,\n              'Atlanta10': 0, 'Atlanta11': 0, 'Atlanta12': 0.2, 'Boston1': 12.9, 'Boston5': 0, 'Boston6': 0,\n              'Boston7': 0, 'Boston8': 0, 'Boston9': 0, 'Boston10': 0,'Boston11': 1.3, 'Boston12': 9.0,\n              'Chicago1': 11.5, 'Chicago5': 0, 'Chicago6': 0, 'Chicago7': 0, 'Chicago8': 0, 'Chicago9': 0,\n              'Chicago10': 0,  'Chicago11': 1.3, 'Chicago12': 8.7, 'Philadelphia1': 6.5, 'Philadelphia5': 0,\n              'Philadelphia6': 0, 'Philadelphia7': 0, 'Philadelphia8': 0, 'Philadelphia9':0 , 'Philadelphia10': 0,\n              'Philadelphia11': 0.3, 'Philadelphia12': 3.4}\n\n# Creating a new column by mapping the city_month variable to it's corresponding average monthly snowfall\ntrain[\"average_snowfall\"] = train['city_month'].map(monthly_snowfall)\ntest[\"average_snowfall\"] = test['city_month'].map(monthly_snowfall)","c83f74a6":"monthly_daylight = {'Atlanta1': 10, 'Atlanta5': 14, 'Atlanta6': 14, 'Atlanta7': 14, 'Atlanta8': 13, 'Atlanta9': 12,\n              'Atlanta10': 11, 'Atlanta11': 10, 'Atlanta12': 10, 'Boston1': 9, 'Boston5': 15, 'Boston6': 15,\n              'Boston7': 15, 'Boston8': 14, 'Boston9': 12, 'Boston10': 11,'Boston11': 10, 'Boston12': 9,\n              'Chicago1': 10, 'Chicago5': 15, 'Chicago6': 15, 'Chicago7': 15, 'Chicago8': 14, 'Chicago9': 12,\n              'Chicago10': 11,  'Chicago11': 10, 'Chicago12': 9, 'Philadelphia1': 10, 'Philadelphia5': 14,\n              'Philadelphia6': 15, 'Philadelphia7': 15, 'Philadelphia8': 14, 'Philadelphia9':12 , 'Philadelphia10': 11,\n              'Philadelphia11': 10, 'Philadelphia12': 9}\n\n# Creating a new column by mapping the city_month variable to it's corresponding average monthly daylight\ntrain[\"average_daylight\"] = train['city_month'].map(monthly_daylight)\ntest[\"average_daylight\"] = test['city_month'].map(monthly_daylight)","68e7ed95":"monthly_sunsine = {'Atlanta1': 5.3, 'Atlanta5': 9.3, 'Atlanta6': 9.5, 'Atlanta7': 8.8, 'Atlanta8': 8.3, 'Atlanta9': 7.6,\n              'Atlanta10': 7.7, 'Atlanta11': 6.2, 'Atlanta12': 5.3, 'Boston1': 5.3, 'Boston5': 8.6, 'Boston6': 9.6,\n              'Boston7': 9.7, 'Boston8': 8.9, 'Boston9': 7.9, 'Boston10': 6.7,'Boston11': 4.8, 'Boston12': 4.6,\n              'Chicago1': 4.4, 'Chicago5': 9.1, 'Chicago6': 10.4, 'Chicago7': 10.3, 'Chicago8': 9.1, 'Chicago9': 7.6,\n              'Chicago10': 6.2,  'Chicago11': 3.6, 'Chicago12': 3.4, 'Philadelphia1': 5.0, 'Philadelphia5': 7.9,\n              'Philadelphia6': 9.0, 'Philadelphia7': 8.9, 'Philadelphia8': 8.4, 'Philadelphia9':7.9 , 'Philadelphia10': 6.6,\n              'Philadelphia11': 5.2, 'Philadelphia12': 4.4}\n\n# Creating a new column by mapping the city_month variable to it's corresponding average monthly sunsine\ntrain[\"average_sunsine\"] = train['city_month'].map(monthly_sunsine)\ntest[\"average_sunsine\"] = test['city_month'].map(monthly_sunsine)","7445ce27":"train.drop('city_month', axis=1, inplace=True)\ntest.drop('city_month', axis=1, inplace=True)","c56c78f8":"train['is_day'] = train['Hour'].apply(lambda x: 1 if 5 < x < 20 else 0)\ntest['is_day'] = test['Hour'].apply(lambda x: 1 if 5 < x < 20 else 0)","70a21159":"def add_distance(df):\n    \n    df_center = pd.DataFrame({\"Atlanta\":[33.753746, -84.386330],\n                             \"Boston\":[42.361145, -71.057083],\n                             \"Chicago\":[41.881832, -87.623177],\n                             \"Philadelphia\":[39.952583, -75.165222]})\n    \n    df[\"CenterDistance\"] = df.apply(lambda row: math.sqrt((df_center[row.City][0] - row.Latitude) ** 2 +\n                                                          (df_center[row.City][1] - row.Longitude) ** 2) , axis=1)\n\nadd_distance(train)\nadd_distance(test)","8a3a9902":"train = pd.concat([train,pd.get_dummies(train[\"City\"],dummy_na=False, drop_first=False)],axis=1).drop([\"City\"],axis=1)\ntest = pd.concat([test,pd.get_dummies(test[\"City\"],dummy_na=False, drop_first=False)],axis=1).drop([\"City\"],axis=1)","7c103b40":"# scale Log and lat columns\nscaler = StandardScaler()\nfor col in ['Latitude','Longitude']:\n    scaler.fit(train[col].values.reshape(-1, 1))\n    train[col] = scaler.transform(train[col].values.reshape(-1, 1))\n    test[col] = scaler.transform(test[col].values.reshape(-1, 1))","833128d6":"train.head()","51c2bcb4":"train.shape,test.shape","8d1e6e6e":"train_road_id = train['RowId']\ntest_road_id = test['RowId']\npreds = train.iloc[:,12:27]\ntrain.drop(['RowId', 'Path','EntryStreetName','ExitStreetName'],axis=1, inplace=True)\ntest.drop(['RowId', 'Path','EntryStreetName','ExitStreetName'],axis=1, inplace=True)\n","8e99cc02":"plt.subplots(figsize=(16,12))\nsns.heatmap(train.corr(), color ='BGR4R')","2d54e476":"train.corr()","c2656ca1":"train.drop(preds.columns.tolist(), axis=1, inplace =True)","c5381e15":"target1 = preds['TotalTimeStopped_p20']\ntarget2 = preds['TotalTimeStopped_p50']\ntarget3 = preds['TotalTimeStopped_p80']\ntarget4 = preds['DistanceToFirstStop_p20']\ntarget5 = preds['DistanceToFirstStop_p50']\ntarget6 = preds['DistanceToFirstStop_p80']","59f58920":"train.columns","43babd30":"cat_feat = ['IntersectionId','Hour', 'Weekend','Month', 'same_street_exact', 'Intersection',\n       'Atlanta', 'Boston', 'Chicago', 'Philadelphia', 'EntryType', 'ExitType']","9f6b5bc8":"all_preds ={0:[],1:[],2:[],3:[],4:[],5:[]}\nall_target = [target1, target2, target3, target4, target5, target6]","72cbbad1":"dtrain = lgb.Dataset(data=train, label=target3)\n\n# Objective Function\ndef hyp_lgbm(num_leaves, feature_fraction, bagging_fraction, max_depth, min_split_gain, min_child_weight, lambda_l1, lambda_l2):\n      \n        params = {'application':'regression','num_iterations': 450,\n                  'learning_rate':0.02,\n                  'metric':'rmse'} # Default parameters\n        params[\"num_leaves\"] = int(round(num_leaves))\n        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n        params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n        params['max_depth'] = int(round(max_depth))\n        params['min_split_gain'] = min_split_gain\n        params['min_child_weight'] = min_child_weight\n        params['lambda_l1'] = lambda_l1\n        params['lambda_l2'] = lambda_l2\n        \n        cv_results = lgb.cv(params, dtrain, nfold=5, seed=17,categorical_feature=cat_feat, stratified=False,\n                            verbose_eval =None)\n#         print(cv_results)\n        return -np.min(cv_results['rmse-mean'])","1745b1b6":"# Domain space-- Range of hyperparameters\npds = {'num_leaves': (120, 230),\n          'feature_fraction': (0.3, 0.9),\n          'bagging_fraction': (0.8, 1),\n           'lambda_l1': (0,3),\n           'lambda_l2': (0,5),\n          'max_depth': (8, 19),\n          'min_split_gain': (0.001, 0.1),\n          'min_child_weight': (1, 20)\n          }","74df4c32":"# Surrogate model\noptimizer = BayesianOptimization(hyp_lgbm,pds,random_state=7)\n                                  \n# Optimize\noptimizer.maximize(init_points=5, n_iter=12)","47736602":"optimizer.max","00076ad2":"p = optimizer.max['params']","351143ba":"param = {'num_leaves': int(round(p['num_leaves'])),\n         'feature_fraction': p['feature_fraction'],\n         'bagging_fraction': p['bagging_fraction'],\n         'max_depth': int(round(p['max_depth'])),\n         'lambda_l1': p['lambda_l1'],\n         'lambda_l2': p['lambda_l2'],\n         'min_split_gain': p['min_split_gain'],\n         'min_child_weight': p['min_child_weight'],\n         'learning_rate':0.05,\n         'objective': 'regression',\n         'boosting_type': 'gbdt',\n         'verbose': 1,\n         'metric': 'rmse',\n         'seed': 7,\n        }","acf92bb3":"param","97f14819":"%%time\nnfold = 5\nkf = KFold(n_splits=nfold, random_state=227, shuffle=True)\nfor i in range(len(all_preds)):\n    print('Training and predicting for target {}'.format(i+1))\n    oof = np.zeros(len(train))\n    all_preds[i] = np.zeros(len(test))\n    n =1\n    for train_index, valid_index in kf.split(all_target[i]):\n        print(\"fold {}\".format(n))\n        xg_train = lgb.Dataset(train.iloc[train_index],\n                               label=all_target[i][train_index]\n                               )\n        xg_valid = lgb.Dataset(train.iloc[valid_index],\n                               label=all_target[i][valid_index]\n                               )   \n\n        clf = lgb.train(param, xg_train, 15000, valid_sets=[xg_valid],categorical_feature=cat_feat\n                        , verbose_eval=200, early_stopping_rounds=500)\n        oof[valid_index] = clf.predict(train.iloc[valid_index], num_iteration=clf.best_iteration) \n\n        all_preds[i] += clf.predict(test, num_iteration=clf.best_iteration) \/ nfold\n        n = n + 1\n\n    print(\"\\n\\nCV RMSE: {:<0.4f}\".format(np.sqrt(mean_squared_error(all_target[i], oof))))  ","76e7863a":"data2 = pd.DataFrame(all_preds).stack()\ndata2 = pd.DataFrame(data2)\nsubmission['Target'] = data2[0].values","3627329c":"submission.head(15)","7772946e":"submission.to_csv('submission.csv', index=False)","fd6e01c9":"<span style='color:blue;background:yellow'>Make a new columns--> Intersection ID + City name","d39267f2":"### Reference: https:\/\/medium.com\/analytics-vidhya\/hyperparameters-optimization-for-lightgbm-catboost-and-xgboost-regressors-using-bayesian-6e7c495947a9","d4618ebf":"<span style='color:blue;background:yellow'> add cordinal direction\n##### turn direction: \nThe cardinal directions can be expressed using the equation: $$ \\frac{\\theta}{\\pi} $$\n\nWhere $\\theta$ is the angle between the direction we want to encode and the north compass direction, measured clockwise.\n\n","0be59d5c":"<span style='color:blue;background:yellow'>  Distance from center of city","bee6082d":"<span style='color:blue;background:yellow'> Add climate data <\/span>","f7f52128":"**References:**\n1. https:\/\/www.kaggle.com\/whatust\/fork-of-kernel56e53f4445\n2. https:\/\/www.kaggle.com\/brokenfulcrum\/geotab-baseline\n3. https:\/\/www.kaggle.com\/danofer\/baseline-feature-engineering-geotab-69-5-lb\n4.  https:\/\/www.kaggle.com\/bgmello\/how-one-percentile-affect-the-others","3738f003":"* <span style='color:blue;background:yellow'>  HotEncoding of cities","4b957795":"<span style='color:blue;background:yellow'> Road Encoding","5c21ab4a":" ### <span style='color:blue;background:yellow'>entering street == exit street?","f7d872ea":"<span style='color:blue;background:yellow'> New feature --> is_day","31f46353":"## <span style='color:blue;background:yellow'>Data Cleaning and Preprocessing\n","23ce36e2":"<span style='color:blue;background:yellow'> Add temperature (\u00b0F) of each city by month <\/span>\n    \n","7695141e":"<center><span style='color:blue;background:yellow;font-size:30px'>**Please upvote this notebook if you like my work. **","bd8fb23a":"#### <span style='color:blue;background:yellow'>**Fill NAs**"}}