{"cell_type":{"c84e2405":"code","7f1a0c81":"code","0304d206":"code","9b481d7c":"code","6d8b43b9":"code","7f02f249":"code","7369ad3a":"code","8aab53bb":"code","054e162d":"code","aba925db":"code","e094e657":"code","90753ea4":"code","e7c3392e":"code","8536b052":"code","f8fff955":"code","9a4f4def":"code","2707f4eb":"code","4e4a97b9":"code","6c2354ce":"code","9c83d395":"code","e2fd6487":"code","1047d9c6":"code","1d17e170":"code","10c67a15":"code","c119ffa2":"code","6760b962":"code","ad720edc":"code","a0ab29f0":"code","9fa102aa":"code","faf1730e":"code","eb4f1e1c":"code","524138bb":"code","318ce00a":"code","44f0aaa4":"code","b4f9bb4d":"code","c6f05fbe":"code","aa41361e":"code","351eaacf":"code","9a5288fe":"code","4b12eaab":"markdown","94f5b6d1":"markdown","6ca623ff":"markdown","8ad35294":"markdown","a968ac89":"markdown","3413a661":"markdown","70ae907e":"markdown","515dc58a":"markdown","f903fc4c":"markdown","cfd3cf17":"markdown","a872bdd1":"markdown","dcc4ea85":"markdown","9ab55766":"markdown","dab1add8":"markdown","26ee0517":"markdown","746c6f0c":"markdown","6744d1fc":"markdown","0f49f307":"markdown","57a3801a":"markdown","41814ccd":"markdown","6689ed95":"markdown","809fe24e":"markdown","e24c1aa7":"markdown","0b78a894":"markdown"},"source":{"c84e2405":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler, normalize,MinMaxScaler\nfrom sklearn.cluster import KMeans\nfrom kmodes.kprototypes import KPrototypes\nimport warnings\nwarnings.filterwarnings(\"ignore\") \n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7f1a0c81":"df = pd.read_csv('\/kaggle\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv')\ndf.head()","0304d206":"missing_cols=df.isnull().sum()\/df.shape[0]\nmissing_cols=missing_cols[missing_cols>0]\nmissing_cols","9b481d7c":"df.set_index('CustomerID',inplace=True)\ndf.head()","6d8b43b9":"num_cols=df.select_dtypes(include=['int64']).columns\nctg_cols=df.select_dtypes(include=['object']).columns\n\nprint('Numerical Cols=',num_cols)\nprint('Categorical Cols=',ctg_cols)","7f02f249":"cols_val=2\nfig, ax = plt.subplots(len(num_cols),cols_val,figsize=(12, 5))\ncolours_val=['c','b','r','g','y','p','m']\ndid_not_ran=True\nfor i,col in enumerate(num_cols):\n    for j in range(cols_val):\n        if did_not_ran==True:\n            sns.boxplot(df[col],ax=ax[i,j],color=colours_val[i+j])\n            ax[i,j].set_title(col)\n            did_not_ran=False\n        else:\n            sns.distplot(df[col],ax=ax[i,j],color=colours_val[i+j])\n            ax[i,j].set_title(col)\n            did_not_ran=True\n            \n            \nplt.suptitle(\"EDA\")\nplt.tight_layout()\nplt.show()","7369ad3a":"plt.figure(figsize=(12,5))\nsns.scatterplot(df['Annual Income (k$)'] ,df['Spending Score (1-100)'])\nplt.title('Scatterplot')\nplt.show()","8aab53bb":"print('Min Age =',df.Age.min())\nprint('Max Age =',df.Age.max())","054e162d":"df['Age_bins']=pd.cut(df.Age,bins=(17,35,50,70),labels=[\"18-35\",\"36-50\",\"50+\"])\ndf[['Age','Age_bins']].drop_duplicates(subset=['Age_bins']).reset_index(drop=True)","aba925db":"df1=df[['Annual Income (k$)', 'Spending Score (1-100)']]\ndf1.shape","e094e657":"std=MinMaxScaler()\narr1=std.fit_transform(df1)\n","90753ea4":"%%time\nkmeans_cluster=KMeans(n_clusters=2,random_state=7)\nresult_cluster=kmeans_cluster.fit_predict(arr1)","e7c3392e":"df1['Clusters']=result_cluster\ndf1['Clusters'].value_counts()","8536b052":"ax=sns.countplot(x=df1.Clusters)\nfor index, row in pd.DataFrame(df1['Clusters'].value_counts()).iterrows():\n    ax.text(index,row.values[0], str(round(row.values[0])),color='black', ha=\"center\")\n    #print(index,row.values[0])\nplt.title('Cluster Count')\nplt.show()","f8fff955":"plt.figure(figsize=(12,5))\nsns.scatterplot(x=df1['Annual Income (k$)'],y=df1['Spending Score (1-100)'],hue=df1.Clusters,palette=\"Set2\",)\nplt.title('2 Clusters')\nplt.show()","9a4f4def":"fig,ax=plt.subplots(1,2,figsize=(12,5))\nsns.heatmap(df1.loc[df1.Clusters==0,['Annual Income (k$)', 'Spending Score (1-100)']].describe().round(),annot=True,fmt='g',ax=ax[0])\nax[0].set_title(\"Cluster-0\")\nsns.heatmap(df1.loc[df1.Clusters==1,['Annual Income (k$)', 'Spending Score (1-100)']].describe().round(),annot=True,fmt='g',ax=ax[1])\nax[1].set_title(\"Cluster-1\")\nplt.suptitle(\"Cluster Analysis\")\nplt.show()","2707f4eb":"%%time\nSSE = []\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, random_state = 7)\n    kmeans.fit(arr1)\n    SSE.append(kmeans.inertia_)","4e4a97b9":"plt.figure(figsize=(12,5))\nsns.lineplot(range(1, 11), SSE,marker='o')\nplt.title('Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('SSE')\nplt.show()","6c2354ce":"kmeans_cluster=KMeans(n_clusters=5,random_state=7)\nresult_cluster=kmeans_cluster.fit_predict(arr1)","9c83d395":"df1['Clusters']=result_cluster\ndf1['Clusters'].value_counts()","e2fd6487":"d1=df[['Gender','Age_bins']].reset_index(drop=True)\ndf1_comb=pd.concat([df1.reset_index(drop=True),d1],axis=1)\ndf1_comb.head()","1047d9c6":"ax=sns.countplot(x=df1_comb.Clusters)\nfor index, row in pd.DataFrame(df1_comb['Clusters'].value_counts()).iterrows():\n    ax.text(index,row.values[0], str(round(row.values[0])),color='black', ha=\"center\")\n    #print(index,row.values[0])\nplt.title('Cluster Count')\nplt.show()","1d17e170":"plt.figure(figsize=(12,7))\nsns.scatterplot(x=df1_comb['Annual Income (k$)'],y=df1_comb['Spending Score (1-100)'],hue=df1_comb.Clusters,palette=\"Set2\",)\nplt.title('5 Clusters')\nplt.show()","10c67a15":"fig,ax=plt.subplots(1,5,figsize=(15,5))\n#cbar_ax = fig.add_axes([1.03, .3, .03, .4])\nfor cluster_val in sorted(df1_comb.Clusters.unique()):\n    #print(cluster_val)\n    sns.heatmap(df1_comb.loc[df1_comb.Clusters==cluster_val,['Annual Income (k$)', 'Spending Score (1-100)']].describe().round(),annot=True,fmt='g',ax=ax[cluster_val],\\\n               cbar=i == 0,vmin=0, vmax=130)\n    titl='Cluster-'+str(cluster_val)\n    ax[cluster_val].set_title(titl)\n    \nplt.suptitle('Clustering Analysis')\n\n#plt.tight_layout()\nplt.show()","c119ffa2":"fig,ax=plt.subplots(1,5,figsize=(16,5))\n#cbar_ax = fig.add_axes([1.03, .3, .03, .4])\nfor cluster_val in sorted(df1_comb.Clusters.unique()):\n    #print(cluster_val)\n    sns.heatmap(df1_comb.loc[df1_comb.Clusters==cluster_val,:].groupby('Age_bins').agg({'Clusters':'size','Annual Income (k$)':'mean','Spending Score (1-100)':'mean'}).\\\n    rename(columns={'Clusters':'Count','Annual Income (k$)':'IncomeMean','Spending Score (1-100)':'SpendScoreMean'})\\\n                .fillna(0).round(),annot=True,fmt='g',ax=ax[cluster_val],cbar=i == 0,vmin=0, vmax=130)\n    titl='Cluster-'+str(cluster_val)+' Analysis'\n    ax[cluster_val].set_title(titl)\n    \n\nplt.suptitle('Clustering Age wise Analysis')\n\n#plt.tight_layout()\nplt.show()","6760b962":"fig,ax=plt.subplots(1,5,figsize=(16,5))\n#cbar_ax = fig.add_axes([1.03, .3, .03, .4])\nfor cluster_val in sorted(df1_comb.Clusters.unique()):\n    #print(cluster_val)\n    sns.heatmap(df1_comb.loc[df1_comb.Clusters==cluster_val,:].groupby('Gender').agg({'Clusters':'size','Annual Income (k$)':'mean','Spending Score (1-100)':'mean'}).\\\n    rename(columns={'Clusters':'Count','Annual Income (k$)':'IncomeMean','Spending Score (1-100)':'SpendScoreMean'})\\\n                .fillna(0).round(),annot=True,fmt='g',ax=ax[cluster_val],cbar=i == 0,vmin=0, vmax=130)\n    titl='Cluster-'+str(cluster_val)+' Analysis'\n    ax[cluster_val].set_title(titl)\n    \n\nplt.suptitle('Clustering Gender Wise Analysis')\n\n#plt.tight_layout()\nplt.show()","ad720edc":"plt.figure(figsize=(12,5))\n\nsns.boxplot(x='Clusters',y='value',hue='variable',\\\n            data=pd.melt(df1,id_vars=['Clusters'],value_vars=['Annual Income (k$)','Spending Score (1-100)']),\\\n           palette=\"Set2\")\nplt.xlabel(\"Clusters\")\nplt.title(\"Boxplot-Annual Income - Spending Score\")\nplt.show()","a0ab29f0":"df_proto=pd.DataFrame(arr1,columns=['AnnualIcome','SpendingScore'])\ndf_proto.head()","9fa102aa":"d2=pd.concat([df_proto,d1],axis=1)\nd2.head()","faf1730e":"%%time\nkproto_clusters=KPrototypes(n_clusters=5,random_state=7,init=\"Cao\")\nresult_cluster=kproto_clusters.fit_predict(d2,categorical=[2,3])","eb4f1e1c":"d2['Clusters']=result_cluster\nd2['Clusters'].value_counts()","524138bb":"ax=sns.countplot(x=d2.Clusters)\nfor index, row in pd.DataFrame(d2['Clusters'].value_counts()).iterrows():\n    ax.text(index,row.values[0], str(round(row.values[0])),color='black', ha=\"center\")\n    #print(index,row.values[0])\nplt.title('Cluster Count')\nplt.show()","318ce00a":"kproto_clusters.cluster_centroids_","44f0aaa4":"df1.drop(['Clusters'],axis=1,inplace=True)\nd3=pd.concat([df1.reset_index(drop=True),d2],axis=1)\nd3.head()","b4f9bb4d":"plt.figure(figsize=(12,5))\nsns.scatterplot(x=d3['Annual Income (k$)'],y=d3['Spending Score (1-100)'],hue=d3.Clusters,palette=\"Set2\",)\nplt.title('5 Clusters')\nplt.show()","c6f05fbe":"fig,ax=plt.subplots(1,5,figsize=(15,5))\n#cbar_ax = fig.add_axes([1.03, .3, .03, .4])\nfor cluster_val in sorted(d3.Clusters.unique()):\n    #print(cluster_val)\n    sns.heatmap(d3.loc[d3.Clusters==cluster_val,['Annual Income (k$)', 'Spending Score (1-100)']].describe().round(),annot=True,fmt='g',ax=ax[cluster_val],\\\n               cbar=i == 0,vmin=0, vmax=130)\n    titl='Cluster-'+str(cluster_val)\n    ax[cluster_val].set_title(titl)\n    \n\nplt.suptitle('Clustering Analysis')\n\n#plt.tight_layout()\nplt.show()","aa41361e":"fig,ax=plt.subplots(1,5,figsize=(16,5))\n#cbar_ax = fig.add_axes([1.03, .3, .03, .4])\nfor cluster_val in sorted(d3.Clusters.unique()):\n    #print(cluster_val)\n    sns.heatmap(d3.loc[d3.Clusters==cluster_val,:].groupby('Age_bins').agg({'Clusters':'size','Annual Income (k$)':'mean','Spending Score (1-100)':'mean'}).\\\n    rename(columns={'Clusters':'Count','Annual Income (k$)':'IncomeMean','Spending Score (1-100)':'SpendScoreMean'})\\\n                .fillna(0).round(),annot=True,fmt='g',ax=ax[cluster_val],cbar=i == 0,vmin=0, vmax=130)\n    titl='Cluster-'+str(cluster_val)+' Analysis'\n    ax[cluster_val].set_title(titl)\n    \n\nplt.suptitle('Clustering Age wise Analysis')\n\n#plt.tight_layout()\nplt.show()","351eaacf":"fig,ax=plt.subplots(1,5,figsize=(16,5))\n#cbar_ax = fig.add_axes([1.03, .3, .03, .4])\nfor cluster_val in sorted(d3.Clusters.unique()):\n    #print(cluster_val)\n    sns.heatmap(d3.loc[d3.Clusters==cluster_val,:].groupby('Gender').agg({'Clusters':'size','Annual Income (k$)':'mean','Spending Score (1-100)':'mean'}).\\\n    rename(columns={'Clusters':'Count','Annual Income (k$)':'IncomeMean','Spending Score (1-100)':'SpendScoreMean'})\\\n                .fillna(0).round(),annot=True,fmt='g',ax=ax[cluster_val],cbar=i == 0,vmin=0, vmax=130)\n    titl='Cluster-'+str(cluster_val)+' Analysis'\n    ax[cluster_val].set_title(titl)\n    \n\nplt.suptitle('Clustering Gender Wise Analysis')\n\n#plt.tight_layout()\nplt.show()","9a5288fe":"plt.figure(figsize=(12,5))\n\nsns.boxplot(x='Clusters',y='value',hue='variable',\\\n            data=pd.melt(d3,id_vars=['Clusters'],value_vars=['Annual Income (k$)','Spending Score (1-100)']),\\\n           palette=\"Set2\")\nplt.xlabel(\"Clusters\")\nplt.title(\"Boxplot-Annual Income - Spending Score\")\nplt.show()","4b12eaab":"#### Clusters Centroid","94f5b6d1":"#### K-Prototype Algorithm  (Number of  Clusters = 5)\n\nStarting with K-Prototype algorithm with 5 clusters \n\n- Parameters \n   - n_clusters : Number of clusters\n   - random_state : for reproducibility\n    \n**Points to consider for K-Prototype**\n\n- In fit_predict method , \"categorical\" parameter takes in the value of  index of the categorical features.\n\n| ColumnIndex | Feature | DataType |\n| --- | --- | --- |\n| 0 | AnnualIcome | float64 |\n| 1 | SpendingScore | float64 |\n| 2 | Gender | object |\n| 3 | Age_bins | object |\n\n**To standardize the numerical data use MinMaxScaler instead of StandardScaler**\n<br>\n\n1. MinMaxScaler will bring the numerical features within range of [0,1], so because of this , distance calculated based on the euclidean distance for numerical features will be comparable to that of hamming distance for categorical data.\n      \n2. If StandardScaler is used to standardize the numerical data , numerical  features will no longer in the range of [0,1] and will drive the analysis and clusters will be biased towards numerical features and in this example resultant cluster will be exactly same as K-means clusters. I would encourage to run the same analysis with StandardScaler to understand this idea better.","6ca623ff":"#### Gender Wise Analysis","8ad35294":"k-modes is used for clustering categorical variables. It defines clusters based on the number of matching categories between data points. (This is in contrast to the more well-known k-means algorithm, which clusters numerical data based on Euclidean distance.) The k-prototypes algorithm combines k-modes and k-means and is able to cluster mixed numerical \/ categorical data.\n\nFor more info, Please refer [Github](https:\/\/github.com\/nicodv\/kmodes)","a968ac89":"#### Missing Values","3413a661":"No missing values , one less thing to worry about :)","70ae907e":"Based on the above scatterplot & heatmap ,\n\n- **Cluster-0** are customers with spending score greater than 50 (approx)\n- **Cluster-1** are customers with spending score less than 50 m(approx)\n\nNo distinctions of customers in terms of Annual income , so basically these clusters are not super useful , \nso try to find optimal clusters using elbow method ","515dc58a":"#### Observations\n\n| Cluster | Income | Spending Score |\n| --- | --- | --- |\n| 0 | Low | Low |  \n| 1 | Medium | Medium |\n| 2 | High | Low |\n| 3 | High | High |\n| 4 | Low | High |\n            \n**Interesting Insight**\n    \n- Cluster-2  are high income customers but they are low spenders \n- Cluster-4  are low income customers but they are high spenders  ( only Age Group 18-35 so mostly youngsters) \n- Cluster-1 have the most number of customers , these are middle class people with medium spending & income.\n    \n    \n*All age-groups & gender are kind of evenly distributed among these clusters ,so these clusters are not super useful if we want to target specific gender or age-group for our marketing campaigns , so lets try to bring in these demographics data and use it to build out clusters but since these demographics data (Age group \/ Gender) are categorical values K-means would not work because it uses euclidean distance as metric to calculate distance so we will be using K-Prototype which takes care of mixed data types , it applies euclidean distance for numerical data and hamming distance for categorical data.*\n \n \n","f903fc4c":"#### Observations \n\n | Cluster | Age-Group | Gender | Income | Spending Score |\n| --- | --- | --- | --- | --- |\n| 0 | 50+ | Females | Medium | Low |  \n| 1 | 36-50 | Males | High | Low |\n| 2 | 18-35 | Males | Medium | High |\n| 3 | 36-50 | Females | Medium | Low |\n| 4 | 18-35 | Females | Medium | High |\n\n**Interesting Insight**\n\n- Cluster 4 & Cluster 2 are youngsters who are high on spending.\n- Cluster 1 & Cluster 3 are middle age adults who are low on spending.\n- Cluster 0 are old age females who are low on spending.\n\nBased on these insights we can map out a marketing strategy to target each cluster and increase the profits.\n\n\n","cfd3cf17":"#### Introduction\n\nClustering is an unsupervised learning problem , its aim is to identify or discover interesting patterns from the data.\n\nThis aim of this tutorial is to apply K-means algorithm on numerical data , K-prototype algorithm on mixed data (numerical + categorical data) and analyze the properties of resulting clusters to gain insights\n\n- **Part 1** :  K-means clustering for numerical data.\n- **Part 2** :  K-prototype clustering on mixed data.","a872bdd1":"**For initial run , considering Only Annual Income & SpendingScore (numerical data) for the K-means algorithm**","dcc4ea85":"#### K-means Algorithm (Number of Cluster = 2)\n\nStarting with K-means algorithm with only 2 clusters \n\n- Parameters \n   - n_clusters : Number of clusters\n   - random_state : for reproducibility\n","9ab55766":"#### Gender Wise Analysis","dab1add8":"#### Age Wise Analysis","26ee0517":"#### Cluster Analysis","746c6f0c":"#### Age wise Analysis","6744d1fc":"#### K-means Algorithm  (Number of  Clusters = 5)\n\nStarting with K-means algorithm with 5 clusters based on the optimal number of clusters from Elbow method \n\n- Parameters \n   - n_clusters : Number of clusters\n   - random_state : for reproducibility\n","0f49f307":"#### Converting Age to bins\n","57a3801a":"Based on the above scatter plot , it seems there is no clear pattern ,but important point here to understand is that we have used 4 features to build out these clusters and we have plotted just 2 features here so appearance could be deceptive ,keep an open mind.","41814ccd":"## K-Prototype","6689ed95":"#### Cluster Analysis","809fe24e":"**Standardize data to bring them in same scale since Annual income & Spending Score are on different scale**","e24c1aa7":"CustomerID will not be input to the clustering algorithm as it doesn't have information so converting it to dataframe index","0b78a894":"#### Explooratory Data Analysis (EDA)"}}