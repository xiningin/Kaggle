{"cell_type":{"3fa48134":"code","c4ed2fb7":"code","637e7888":"code","4e99cb3e":"code","00a53d8b":"code","fbaf0240":"code","9662c651":"code","708c1382":"code","cf8fb714":"code","9f64ccaa":"code","56460cd3":"code","bf7a073a":"code","84404a69":"code","ac1c2fb8":"code","7d354bdc":"code","3b74e2d3":"code","2dd818c6":"code","d01771dd":"code","5eac0c36":"code","ebdb9a3f":"code","aa3de937":"code","033a185d":"code","299e04e2":"code","01cd1aa2":"code","f01e0e83":"code","087135b6":"code","cb4c3f80":"code","065edd18":"code","59a93567":"code","6c2f0f4c":"code","57d157c3":"code","017635bc":"markdown","53543e4f":"markdown","1b8c3e91":"markdown","c2559e12":"markdown","8123e19b":"markdown","46a0090b":"markdown","0305bb4e":"markdown","39a0c176":"markdown","f5f4343f":"markdown","4f7755c5":"markdown","9f7e0d66":"markdown"},"source":{"3fa48134":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","c4ed2fb7":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras import optimizers\nfrom keras.layers import Dropout\nfrom keras.constraints import maxnorm\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom pprint import pprint\nfrom sklearn.feature_selection import RFE\nfrom IPython.core.interactiveshell import InteractiveShell\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve\nInteractiveShell.ast_node_interactivity = \"all\"","637e7888":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","4e99cb3e":"train.head()\ntest.head()\ntrain.shape\ntest.shape","00a53d8b":"train.PassengerId.value_counts()\ntrain.Sex.value_counts()\ntrain.Pclass.value_counts()\ntrain.Name.value_counts()\ntrain.Embarked.value_counts()\ntrain.Cabin.value_counts()\ntrain.SibSp.value_counts()\ntrain.Ticket.value_counts()\ntrain.Parch.value_counts()\ntrain.Fare.value_counts()\ntrain.Age.value_counts()","fbaf0240":"train = train.drop(['PassengerId'], axis=1)\ntrain = train.drop(['Name'], axis=1)\ntrain = train.drop(['Ticket'], axis=1)\ntrain.head()","9662c651":"train['Sex'] = train['Sex'].apply(lambda x: 0 if x == 'male' else 1)\nfor i in train['Pclass']:\n    if i == 1:\n        train['Pclass'] = train['Pclass'].replace(i, 'Upper')\n        \n    elif i == 2:\n        train['Pclass'] = train['Pclass'].replace(i, 'Middle')\n\n    else:\n        train['Pclass'] = train['Pclass'].replace(i, 'Lower')\n        \ntrain.head()","708c1382":"train.isnull().any()","cf8fb714":"train.Cabin.isnull().sum()\ntrain.Embarked.isnull().sum()\ntrain.Age.isnull().sum()","9f64ccaa":"train = train.drop(['Cabin'], axis=1)\ntrain.head()","56460cd3":"train = train.drop_duplicates()\ntrain","bf7a073a":"train = train.dropna(subset=['Embarked', 'Age'])\ntrain.Age.fillna(train.Age.mean())\ntrain.isnull().any()","84404a69":"train.head()\ntrain.shape","ac1c2fb8":"plt.scatter(x = train['Age'], y=train['Age'])\nplt.show()\nplt.scatter(x = train['Fare'], y=train['Fare'])\nplt.show()\nplt.scatter(x = train['SibSp'], y=train['SibSp'])\nplt.show()\nplt.scatter(x = train['Parch'], y=train['Parch'])\nplt.show()","7d354bdc":"train = train[train.Fare < 300]\ntrain.shape","3b74e2d3":"train = pd.get_dummies(train, columns=['Pclass', 'Embarked', 'SibSp', 'Parch'])\ntrain.head()","2dd818c6":"train.Age = train.Age.astype(int)\ntrain.Fare = train.Fare.astype(int)\ntrain.head()","d01771dd":"train = train.drop(['Pclass_Lower'], axis=1)\ntrain = train.drop(['Embarked_C'], axis=1)\n\ntrain.head()","5eac0c36":"train.SibSp_1\ntrain.SibSp_2","ebdb9a3f":"train = train.drop(['SibSp_0'], axis=1)\ntrain.head(20)","aa3de937":"train = train.drop_duplicates()\ntrain.shape","033a185d":"train.head(20)","299e04e2":"sns.countplot(train.Survived)\ntrain.Survived.value_counts()","01cd1aa2":"features = ['Age', 'Embarked_Q', 'Embarked_S', 'Fare', 'Parch_0', 'Pclass_Middle', 'Pclass_Upper', 'Sex', 'SibSp_1', \n            'SibSp_2', 'Parch_1', 'Parch_2', 'SibSp_4', 'SibSp_3', 'SibSp_5', 'Parch_4', 'Parch_3', 'Parch_5', 'Parch_6', 'Survived']\ntrain = train[features]\nX = train.drop(['Survived'], axis=1)\nY = train['Survived']","f01e0e83":"train_features, test_features, train_labels, test_labels = train_test_split(X, Y, test_size=0.2, random_state=0)","087135b6":"rf = RandomForestClassifier()\nrf.fit(train_features, train_labels)\nrf_pred_train = rf.predict(train_features)\nrf_pred_test = rf.predict(test_features)\nprint(classification_report(test_labels,rf_pred_test))\nprint('Random Forest baseline: ' + str(roc_auc_score(train_labels, rf_pred_train)))\nprint('Random Forest: ' + str(roc_auc_score(test_labels, rf_pred_test)))","cb4c3f80":"rf = RandomForestClassifier()\n# Create the parameter grid based on the results of random search \nparam_grid = {\n    'max_depth': [10],\n    'min_samples_leaf': [3],\n    'n_estimators': [1000],\n    'oob_score': [True],\n    'random_state': [0],\n}\n\n# Instantiate the grid search model\ngrid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n                      cv = 3, n_jobs = -1, verbose = 2, return_train_score=True)\n\n# Fit the grid search to the data\ngrid_search.fit(train_features, train_labels);\n\ngrid_search.best_params_\nbest_grid = grid_search.best_estimator_\npprint(best_grid.get_params())\n\nselector = RFE(rf, step=1, verbose=3)\nselector = selector.fit(train_features, train_labels)\nprint(\"Features sorted by their rank:\")\npprint(sorted(zip(map(lambda x: round(x, 4), selector.ranking_), X)))","065edd18":"rf = RandomForestClassifier(**best_grid.get_params())\nrf.fit(train_features, train_labels)\nrf_pred_train = rf.predict(train_features)\nrf_pred_test = rf.predict(test_features)\nprint(classification_report(test_labels,rf_pred_test))\nprint('Random Forest baseline: ' + str(roc_auc_score(train_labels, rf_pred_train)))\nprint('Random Forest: ' + str(roc_auc_score(test_labels, rf_pred_test)))","59a93567":"model = Sequential()\nmodel.add(Dense(12, input_dim=19, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n# Compile model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.fit(train_features, train_labels)\nmodel_pred_train = model.predict(train_features)\nmodel_pred_test = model.predict(test_features)\nprint(classification_report(test_labels,rf_pred_test))\nprint('Neural Network baseline: ' + str(roc_auc_score(train_labels, model_pred_train)))\nprint('Neural Network: ' + str(roc_auc_score(test_labels, model_pred_test)))","6c2f0f4c":"# Function to create model, required for KerasClassifier\ndef create_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(1, input_dim=19, kernel_initializer='normal', activation='tanh', kernel_constraint=maxnorm(2)))\n    model.add(Dropout(0.1))\n    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n    optimizer = optimizers.adam(lr=.001)\n    # Compile model\n    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n    return model\n# fix random seed for reproducibility\nseed = 7\nnp.random.seed(seed)\n# create model\nmodel = KerasClassifier(build_fn=create_model, verbose=0, epochs=100, batch_size=10)\n# define the grid search parameters\nparam_grid = {\n#     'optimizer': ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n#     'batch_size': [10, 20, 40, 60, 80, 100],\n#     'epochs': [10, 50, 100],\n#     'learn_rate': [0.001, 0.01, 0.1, 0.2, 0.3],\n#     'momentum': [0.0, 0.2, 0.4, 0.6, 0.8, 0.9],\n#     'init_mode': ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform'],\n#     'activation': ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],\n#     'weight_constraint': [1, 2, 3, 4, 5],\n#     'dropout_rate': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n#     'neurons': [1, 5, 10, 15, 20, 25, 30]\n    \n}\n\n# Instantiate the grid search model\ngrid_search = GridSearchCV(estimator = model, param_grid = param_grid, \n                      cv = 3, n_jobs = -1, verbose = 2, return_train_score=True)\n\n# Fit the grid search to the data\ngrid_result = grid_search.fit(train_features, train_labels);\n\n# summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","57d157c3":"model.fit(train_features, train_labels)\nmodel_pred_train = model.predict(train_features)\nmodel_pred_test = model.predict(test_features)\nprint(classification_report(test_labels,rf_pred_test))\nprint('Neural Network baseline: ' + str(roc_auc_score(train_labels, model_pred_train)))\nprint('Neural Network: ' + str(roc_auc_score(test_labels, model_pred_test)))","017635bc":"# Hyper parameter tuning and feature selection","53543e4f":"# Build models","1b8c3e91":"# Remove outliers","c2559e12":"# Row-wise deletion for missing Embarked feature","8123e19b":"# Drop duplicates","46a0090b":"# Too many missing values for Cabin. This feature is not useful so performing column-wise deletion","0305bb4e":"# One hot encode variables","39a0c176":"# Random Forest Model","f5f4343f":"# Name and PassengerId are removed since they both are unique and ticket is removed since it has no affect on survived","4f7755c5":"# Neural Network","9f7e0d66":"# Drop features that are linearly dependent of each other"}}