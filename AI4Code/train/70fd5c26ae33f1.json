{"cell_type":{"096cc7aa":"code","f57baa06":"code","d3f4b69b":"code","05a21bcf":"code","ce436be1":"code","1720274b":"code","7a921708":"code","b269b959":"code","d8e33a69":"code","e80d4fa8":"code","3e5efad4":"code","6da4ccce":"code","281dcfa5":"code","831e471c":"code","b4ed9163":"code","c69cb966":"code","c299edda":"code","397b903d":"code","b8055468":"code","01878abb":"code","a5c733be":"code","e749fd81":"code","282bc926":"markdown","f3faa0d9":"markdown","9f5363b0":"markdown","a7221bab":"markdown","d05bbc68":"markdown","85c6815e":"markdown","4c0dc1f1":"markdown","1b9b8c74":"markdown","d9246c43":"markdown","f7a69d7e":"markdown","e5b3c959":"markdown","1a8bf7f4":"markdown","c3888646":"markdown","5ef1977a":"markdown","8f93eedd":"markdown","ec7432fe":"markdown","e43133c6":"markdown","4cb9490f":"markdown","62d03d97":"markdown","6dd99fdb":"markdown","ee18ebcd":"markdown","cd7f1498":"markdown","918dea50":"markdown","6b0638f9":"markdown","423071c9":"markdown","ec618127":"markdown"},"source":{"096cc7aa":"import numpy as np\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom skimage import color\nfrom skimage import measure\nfrom skimage.filters import try_all_threshold\nfrom skimage.filters import threshold_otsu\nfrom skimage.filters import threshold_local\nimport keras\nfrom keras import Sequential\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, AveragePooling2D, MaxPool2D\nfrom keras.optimizers import Adam\nfrom keras.utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint","f57baa06":"df_train = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ndf_test = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","d3f4b69b":"print(\"Train Data Size: \",df_train.shape)\nprint(\"Test Data Size: \",df_test.shape)","05a21bcf":"plt.figure(figsize=(12,7))\nplt.title('Numbers vs Count in Label', fontsize=18, y=1.02)\n\nax = sns.barplot(x=[*range(10)],\n                 y=df_train.label.value_counts().sort_index(),\n                 color='#255db8')\n\nfor p in ax.patches:\n        ax.annotate('{}'.format(int(p.get_height())),\n                    (p.get_x()+0.2, p.get_height()+50))\n\nplt.show()","ce436be1":"plt.style.use('seaborn')\nfig, ax = plt.subplots(1,6,figsize=(10,10))\nfig.suptitle('Sample of Train Images', y=0.6, fontsize=18, color=\"#910356\")\nfig.tight_layout(pad=0.0)\n\nfor col in range(6):\n\n    im_0 = np.array(df_train.drop(\"label\", axis=1).iloc[col]).reshape(28,28)\n    \n    ax[col].imshow(im_0, cmap=\"gray\")\n    \n    ax[col].axis(\"off\")","1720274b":"y_train = df_train['label']\nX_train = df_train.drop('label', axis = 1)\n\nX_test = np.array(df_test)","7a921708":"X_train = np.array(X_train).reshape((-1,28,28,1))\nX_train.shape","b269b959":"X_test = np.array(X_test).reshape((-1,28,28,1))\nX_test.shape","d8e33a69":"y_train = to_categorical(y_train, num_classes = 10)\ny_train.shape","e80d4fa8":"X_train, X_val, y_train, y_val = train_test_split(X_train,\n                                                  y_train,\n                                                  test_size=0.25,\n                                                  random_state=1)","3e5efad4":"kernel_ = (5,5)","6da4ccce":"model = Sequential()\nmodel.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(28, 28, 1)))\nmodel.add(MaxPool2D(strides=2))\nmodel.add(Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'))\nmodel.add(MaxPool2D(strides=2))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(84, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))\nmodel.summary()","281dcfa5":"aug = ImageDataGenerator(\n        rotation_range=10,  \n        zoom_range = 0.1, \n        width_shift_range=0.1,  \n        height_shift_range=0.1)\n\ngen_train = aug.flow(X_train, y_train, batch_size=64)\n\ngen_val = aug.flow(X_val, y_val, batch_size=64)","831e471c":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","b4ed9163":"import tensorflow as tf\n\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",\n                                                 monitor='val_accuracy',\n                                                 verbose=1,\n                                                 save_best_only=True)\n\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n                                                  factor=0.5,\n                                                  patience=3,\n                                                  min_lr=0.00005,\n                                                  verbose=1)\n\nearly_stop = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)","c69cb966":"training = model.fit(gen_train, epochs=50, batch_size=128,\n                    validation_data=gen_val,\n                    callbacks = [checkpoint, reduce_lr], verbose = 1)","c299edda":"model.load_weights(\"weights.hdf5\")","397b903d":"y_test = model.predict(X_test)\ny_pred = np.argmax(y_test, axis=1)","b8055468":"output_csv = {\"ImageId\":[*range(1,1+len(y_pred))], \"Label\":y_pred}\nY_pre = pd.DataFrame(output_csv)\nY_pre.set_index(\"ImageId\", drop=True, append=False, inplace=True)\nY_pre.to_csv(\"\/kaggle\/working\/submission.csv\")","01878abb":"# plot loss function for train and validation.\nplt.title('loss and validation loss with epochs', \n          fontsize=16)\n\nplt.plot(training.history['loss'],\n         marker='o',\n         color=\"green\",\n         label=\"loss\")\n\nplt.plot(training.history['val_loss'],\n         marker='o',\n         color=\"orange\", \n         label=\"val_loss\")\n\nplt.legend()\nplt.show()","a5c733be":"# plot accuracy for train and validation data.\nplt.title('accuracy and validation accuracy with epochs',\n          fontsize=16)\n\nplt.plot(training.history['accuracy'],\n         marker='o',\n         color=\"green\",\n         label=\"accuracy\")\n\nplt.plot(training.history['val_accuracy'],\n         marker='o',\n         color=\"orange\",\n         label=\"val_accuracy\")\n\nplt.legend()\nplt.show()","e749fd81":"plt.style.use('seaborn')\n\nfig, ax = plt.subplots(2,5,figsize=(12,5))\nfig.suptitle('Sample of Test Images and Prediction', y=1.2, fontsize=18, color=\"#910356\")\nfig.tight_layout(pad=-2)\n\nfor col in range(5):\n    \n    im_0 = np.array(df_test.iloc[col]).reshape(28,28)\n    \n    ax[0][col].imshow(im_0, cmap=\"gray\")\n    ax[0][col].set_title('label: '+str(y_pred[col]))\n    ax[0][col].axis(\"off\")\n    \n    im_0 = np.array(df_test.iloc[col+6]).reshape(28,28)\n    \n    ax[1][col].imshow(im_0, cmap=\"gray\")\n    ax[1][col].set_title('label: '+str(y_pred[col+6]))\n    ax[1][col].axis(\"off\")","282bc926":"![](https:\/\/github.com\/MhmdSyd\/needed_image\/blob\/main\/mnist2.png?raw=true)","f3faa0d9":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Helvetica;\n           letter-spacing:0.5px\">\n\n<span style='padding: 10px; font-family:Helvetica; font-size:30px' > Data Preparation <\/span>\n<\/div>","9f5363b0":"- **Reshape Data**","a7221bab":"## Accuracy With epochs for Train and Validation Data","d05bbc68":"- **Generate Image Train Data**","85c6815e":"\n<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Helvetica;\n           letter-spacing:0.5px\">\n\n<span style='padding: 10px; font-family:Helvetica; font-size:30px' > Modeling <\/span>\n<\/div>","4c0dc1f1":"## Value Count Of Target","1b9b8c74":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n\n<span style='padding: 10px; font-family:Helvetica; font-size:30px' > Data Summary <\/span>\n<\/div>","d9246c43":"## Predict Test Target","f7a69d7e":"## MultiClassifier Neural Network","e5b3c959":"## Split Data","1a8bf7f4":"**Read Data and Split to X and Y**","c3888646":"- **Size of the dataset.**","5ef1977a":"### Thanks For Read My NoteBook :)","8f93eedd":"## Create Model and Add Layers","ec7432fe":"**Import Necessary Librariess**","e43133c6":"## Test Sample Image With Its Prediction","4cb9490f":"\n<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Helvetica;\n           letter-spacing:0.5px\">\n\n<span style='padding: 10px; font-family:Helvetica; font-size:30px' > Model Analysis <\/span>\n<\/div>","62d03d97":"- **Save Prediction Target**","6dd99fdb":"- **Loss With epochs for Train and Validation Data**","ee18ebcd":"**The notebook is structured in the following way:**\n\n> Data Summary.\n\n> Data Preparation.\n\n> Modeling.\n\n> Model Analysis.\n","cd7f1498":"- **Split Train Dataset To Train And Validation Data**","918dea50":"## Compile Model","6b0638f9":"## Train Model","423071c9":"- **Set Kernel Matrix Size**","ec618127":"## Display Sample of Train Images"}}