{"cell_type":{"1c0b5a52":"code","ded89811":"code","dbe37158":"code","066192c5":"code","0e8d7632":"code","4456c1e9":"code","6f36d3c5":"code","99e636fc":"code","c0cf47ab":"code","c6ee0ca0":"code","d6d0045d":"code","63a96aa0":"code","a1caff88":"code","90185300":"code","a34e7159":"code","8d9bdcfe":"code","3ed1340d":"code","76ebca72":"code","bdc2b887":"code","2a74abf7":"code","9e108d5e":"code","14f35d22":"code","f141353b":"code","c2daf706":"code","675838cf":"code","9de6f8e2":"code","51ce2ff9":"code","b9fe1d1e":"code","50d3e08d":"code","7e996970":"markdown","19ec93e2":"markdown","2037f668":"markdown","2aa546e0":"markdown","1a2ccc1d":"markdown","ecd1ae14":"markdown"},"source":{"1c0b5a52":"import os\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns","ded89811":"# Let's visualize two images for each categoric, which is a normal lung(NORMAL) and a lung with some type of bacteria or infection(Pneumonia)\ndata_dir = ('..\/input\/chest-xray-pneumonia\/chest_xray\/train')\ncategories = ['NORMAL', 'PNEUMONIA']\nfor i in categories:\n    path = os.path.join(data_dir, i)\n    num = 0\n    for img in os.listdir(path):\n        if num != 2:\n            img_array = cv2.imread(os.path.join(path,img))\n            img_array = cv2.resize(img_array, (250, 250))\n            plt.imshow(img_array)\n            plt.title(i)\n            plt.show()\n            num +=1\n        else:\n            break\n            \n","dbe37158":"# Now, let's see the shape of the one image\nimage_files = os.listdir(path)\nimage = os.path.join(path, image_files[0])\nimage = cv2.imread(image)\nimage.shape","066192c5":"\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom torchvision import transforms\nimport torch \nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torchvision.datasets as dsets\nfrom PIL import Image\n\n# For the same results everytime we need to run this code\ntorch.manual_seed(0)","0e8d7632":"# Are GPU Avaible?\ntorch.cuda.is_available()","4456c1e9":"# Creating a variable with the gpu, it will be needed later\ndevice = torch.device('cuda:0')","6f36d3c5":"# Saving the path to the normal files \nnormal = \"NORMAL\"\nnormal_path = os.path.join(data_dir, normal)\nnormal_files = [os.path.join(normal_path,file) for file in  os.listdir(normal_path) if file.endswith(\".jpeg\")]\nnormal_files.sort()","99e636fc":"normal_files[0]","c0cf47ab":"# Saving the path to the pneumonia files \npneu = \"PNEUMONIA\"\npneu_path = os.path.join(data_dir, pneu)\npneu_files = [os.path.join(pneu_path,file) for file in  os.listdir(pneu_path) if file.endswith(\".jpeg\")]\npneu_files.sort()","c6ee0ca0":"pneu_files[0:5]","d6d0045d":"# We have 5216 files\nnumber_of_samples = len(normal_files) + len(pneu_files)\nnumber_of_samples","63a96aa0":"# Creating a long tensor that will contain the labels.\nY=torch.zeros([number_of_samples])\nY=Y.type(torch.LongTensor)\nY.type()","a1caff88":"# There are 1341 normal files, after that, all files are pneumonia ones.\n# So i'm creating the labels here, were 0 is normal files(file 1 to 1341) and 1 is the pneumonia files(file 1341 to 5216)\nY[:1341] = 0\nY[1341:]= 1\n","90185300":"# Join the files\nall_files = normal_files + pneu_files\n","a34e7159":"# See the results here\nall_files[1339:1345]","8d9bdcfe":"# And the labels are correct\nY.tolist()[1339:1345]","3ed1340d":"# For some better understanding, let's see the files with their paths and labesl\nfor y,file in zip(Y.tolist()[1339:1345], all_files[1339:1345]):\n    print(file)\n    plt.imshow(cv2.imread(file))\n    plt.title(\"y=\"+str(y))\n    plt.show()","76ebca72":"class Dataset(Dataset):\n\n    # Constructor\n    def __init__(self,transform=None, train=True):\n        # The training data\n        if train:\n            directory= \"..\/input\/chest-xray-pneumonia\/chest_xray\/train\"\n            normal = \"NORMAL\"\n            pneu = \"PNEUMONIA\"\n\n            normal_file_path = os.path.join(directory,normal)\n            pneu_file_path = os.path.join(directory,pneu)\n\n            normal_files = [os.path.join(normal_file_path,file) for file in  os.listdir(normal_file_path) if file.endswith(\".jpeg\")]\n            normal_files.sort()\n\n            pneu_files = [os.path.join(pneu_file_path,file) for file in  os.listdir(pneu_file_path) if file.endswith(\".jpeg\")]\n            pneu_files.sort()\n\n            number_of_samples = len(normal_files) + len(pneu_files)\n\n            all_files = [None]*number_of_samples\n            all_files[:len(normal_files)] = normal_files\n            all_files[len(normal_files):] = pneu_files\n            self.all_files = all_files\n            \n            # Saving the lenght\n            self.len = len(self.all_files)\n            \n            # The transform is goint to be used on image\n            self.transform = transform\n            \n            #torch.LongTensor with the labels\n            Y=torch.zeros([number_of_samples]).type(torch.LongTensor)\n            Y[:len(normal_files)] = 0\n            Y[len(normal_files):] = 1\n            self.Y = Y\n       \n    # validation data    \n        else:\n            directory= \"..\/input\/chest-xray-pneumonia\/chest_xray\/test\"\n            normal = \"NORMAL\"\n            pneu = \"PNEUMONIA\"\n\n            normal_file_path = os.path.join(directory,normal)\n            pneu_file_path = os.path.join(directory,pneu)\n\n            normal_files = [os.path.join(normal_file_path,file) for file in  os.listdir(normal_file_path) if file.endswith(\".jpeg\")]\n            normal_files.sort()\n\n            pneu_files = [os.path.join(pneu_file_path,file) for file in  os.listdir(pneu_file_path) if file.endswith(\".jpeg\")]\n            pneu_files.sort()\n\n            number_of_samples = len(normal_files) + len(pneu_files)\n\n            all_files=[None]*number_of_samples\n            all_files[:len(normal_files)]= normal_files\n            all_files[len(normal_files):]= pneu_files\n            self.all_files = all_files\n            \n            # Saving the lenght\n            self.len = len(self.all_files)\n            \n            # The transform is goint to be used on image\n            self.transform = transform\n            #torch.LongTensor\n            Y=torch.zeros([number_of_samples]).type(torch.LongTensor)\n            Y[:len(normal_files)] = 0\n            Y[len(normal_files):] = 1\n            self.Y = Y\n\n\n\n        # Get the length\n    def __len__(self):\n        return self.len\n\n         # Getter\n    def __getitem__(self, idx):\n        \n        \n        image=Image.open(self.all_files[idx])\n        y=self.Y[idx]\n          \n        \n        # If there is any transform method, apply it onto the image\n        if self.transform:\n            image = self.transform(image)\n            \n            \n            \n            \n            \n\n        return image, y","bdc2b887":"# For the purpose of this code to run light, let's resize the images to 250x250. Also, the images are in different sizes, so we need to fix this.\nIMAGE_SIZE = 250\n\n\n# Composed function (Works as a pipeline for the transforms that we need make on the imagens)\n# For the normalizer, a already calculate the mean and std of the images. (Just one mean because I gonna grayscale the images, if I use RGB, it would need 3 mean and std, one for each channel)\ncomposed_train = transforms.Compose([transforms.Grayscale(num_output_channels=1), transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)), transforms.ToTensor(), transforms.Normalize(0.4823, 0.2363)])\ncomposed_test = transforms.Compose([transforms.Grayscale(num_output_channels=1), transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)), transforms.ToTensor(), transforms.Normalize(0.4747, 0.2361)])","2a74abf7":"# Creating the datasets through the class\ndataset_train = Dataset(transform=composed_train,train=True)\ndataset_val = Dataset(transform=composed_test,train=False)","9e108d5e":"# Position 0 is the imagens\ndataset_train[0][0].shape","14f35d22":"# The dataloaders for the model.\n# only batch size of 32 run in this code, others sizes like 64 or plus gets CUDA error (Lack of memory)\ntrain_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=32, shuffle=True, num_workers=1)\ntest_loader = torch.utils.data.DataLoader(dataset=dataset_val, batch_size=32, shuffle=True, num_workers=1)","f141353b":"import torch.nn as nn\nimport numpy as np","c2daf706":"# Creating my PyTorch model.\n# The class has to inherit it's functions from pytorch's nn.Module class\nclass CNN(nn.Module):\n    \n    # Contructor\n    def __init__(self):\n        super(CNN, self).__init__()\n        # Conv1\n        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=5, stride=1, padding=0)\n        self.conv1_bn = nn.BatchNorm2d(64)\n        self.maxpool1=nn.MaxPool2d(kernel_size=2, stride=2)\n        \n        # Conv2\n        self.cnn2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5,stride=1, padding=0)\n        self.conv2_bn = nn.BatchNorm2d(128)\n        self.maxpool2=nn.MaxPool2d(kernel_size=2, stride=1)  \n        \n        # Conv3\n        self.cnn3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=5,stride=1, padding=0)\n        self.conv3_bn = nn.BatchNorm2d(256)\n        self.maxpool3=nn.MaxPool2d(kernel_size=2, stride=2)\n        \n        # Conv4\n        self.cnn4 = nn.Conv2d(in_channels=256, out_channels=128, kernel_size=5,stride=1, padding=0)\n        self.conv4_bn = nn.BatchNorm2d(128)\n        self.maxpool4=nn.MaxPool2d(kernel_size=2, stride=1)\n        \n        # Conv5\n        self.cnn5 = nn.Conv2d(in_channels=128, out_channels=32, kernel_size=5,stride=1, padding=0)\n        self.conv5_bn = nn.BatchNorm2d(32)\n        self.maxpool5=nn.MaxPool2d(kernel_size=2, stride=2)\n        \n      \n        # Fully connected layer 1\n        self.drop_out1 = nn.Dropout(0.2)\n        self.fc1 = nn.Linear(in_features=32 * 24 * 24, out_features=500)\n        self.bn_fc1 = nn.BatchNorm1d(500)\n        \n         # Fully connected layer 2\n        self.drop_out2 = nn.Dropout(0.2)\n        self.fc2 = nn.Linear(in_features=500, out_features=1000)\n        self.bn_fc2 = nn.BatchNorm1d(1000)\n        \n         # Fully connected layer 3\n        self.drop_out3 = nn.Dropout(0.2)\n        self.fc3 = nn.Linear(in_features=1000, out_features=1000)\n        self.bn_fc3 = nn.BatchNorm1d(1000)\n        \n         # Fully connected layer 4\n        self.drop_out4 = nn.Dropout(0.2)\n        self.fc4 = nn.Linear(in_features=1000, out_features=500)\n        self.bn_fc4 = nn.BatchNorm1d(500)\n        \n         # Fully connected layer 5\n        self.drop_out5 = nn.Dropout(0.2)\n        self.fc5 = nn.Linear(in_features=500, out_features=250)\n        self.bn_fc5 = nn.BatchNorm1d(250)\n        \n         # Fully connected layer 6 \n        self.fc6 = nn.Linear(in_features=250, out_features=2)\n        \n    \n        \n    \n    # For Prediction\n    def forward(self, x):\n        # conv1\n        x = self.cnn1(x)\n        x = self.conv1_bn(x)\n        x = torch.relu(x)\n        x = self.maxpool1(x)\n        # conv2\n        x = self.cnn2(x)\n        x = self.conv2_bn(x)\n        x = torch.relu(x)\n        x = self.maxpool2(x)\n        # conv3\n        x = self.cnn3(x)\n        x = self.conv3_bn(x)\n        x = torch.relu(x)\n        x = self.maxpool3(x)\n        # conv4\n        x = self.cnn4(x)\n        x = self.conv4_bn(x)\n        x = torch.relu(x)\n        x = self.maxpool4(x)\n        # conv5\n        x = self.cnn5(x)\n        x = self.conv5_bn(x)\n        x = torch.relu(x)\n        x = self.maxpool5(x)\n        \n        # Fcl1\n        x = x.view(x.size(0), -1)\n        x = self.drop_out1(x)\n        x = self.fc1(x)\n        x = self.bn_fc1(x)\n        x = torch.relu(x)\n        # Fcl2\n        x = self.drop_out2(x)\n        x = self.fc2(x)\n        x = self.bn_fc2(x)\n        x = torch.relu(x)\n        # Fcl3\n        x = self.drop_out3(x)\n        x = self.fc3(x)\n        x = self.bn_fc3(x)\n        x = torch.relu(x)\n        # Fcl4\n        x = self.drop_out4(x)\n        x = self.fc4(x)\n        x = self.bn_fc4(x)\n        x = torch.relu(x)\n        # Fcl5\n        x = self.drop_out5(x)\n        x = self.fc5(x)\n        x = self.bn_fc5(x)\n        x = torch.relu(x)\n        # final fcl\n        x = self.fc6(x)\n        #x = torch.sigmoid(x)\n       \n        return x","675838cf":"# The training function\ndef train_model(model,train_loader,test_loader,optimizer,n_epochs=100):\n    \n    # For computing the accuracy and loss\n    N_test=len(dataset_val)\n    accuracy_list=[]\n    loss_list=[]\n    \n    for epoch in range(n_epochs):\n        cost = 0\n        model.train()\n        print(f\"Epoch: {epoch + 1}\")\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)   # passing the variables to gpu\n            \n            optimizer.zero_grad()  # resetting the gradient\n            z = model(x)           # Fiting the data\n            #y = y.unsqueeze(-1)    # in case of we use BCELoss as criterion\n            #y = y.float()\n            loss = criterion(z, y)   # Passing to the loss funtion with Cross Entropy\n            \n            loss.backward()    # backpropagation\n            optimizer.step()   # updating the weights\n           \n            cost+=loss.item()   \n\n        correct=0\n        model.eval()\n        #perform a prediction on the validation  data  \n        for x_test, y_test in test_loader:\n            x_test, y_test = x_test.to(device), y_test.to(device)  # passing the variables to gpu\n            \n            z = model(x_test)                  # making a prediction\n            _, yhat = torch.max(z.data, 1)     # threshold\n            correct += (yhat == y_test).sum().item()      # Saving the corrects predictions\n        accuracy = correct \/ N_test                       # Getting the accuracy\n        print(f\"correct: {correct}, N_test: {N_test}\")\n        accuracy_list.append(accuracy)\n        loss_list.append(cost)\n        print(f\"------>  loss: {round(cost, 8)}, accuracy_val: %{accuracy * 100}\")\n    \n     \n    return accuracy_list, loss_list","9de6f8e2":"# Creating the model and passing it to the gpu\nmodel = CNN()\nmodel.to(device)","51ce2ff9":"criterion = nn.CrossEntropyLoss()\nlearning_rate = 0.001\noptimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)","b9fe1d1e":"# Training the model for 10 epochs\naccuracy_list, loss_list = train_model(model=model,n_epochs=10, train_loader=train_loader,test_loader = test_loader,optimizer=optimizer)","50d3e08d":"import matplotlib.pyplot as plt\nfig, ax1 = plt.subplots()\ncolor = 'tab:red'\nax1.plot(loss_list, color=color)\nax1.set_xlabel('epoch', color=color)\nax1.set_ylabel('Loss', color=color)\nax1.tick_params(axis='y', color=color)\n    \nax2 = ax1.twinx()  \ncolor = 'tab:blue'\nax2.set_ylabel('Accuracy', color=color) \nax2.set_xlabel('epoch', color=color)\nax2.plot( accuracy_list, color=color)\nax2.tick_params(axis='y', color=color)\nfig.tight_layout()","7e996970":"# Evaluation\n\n","19ec93e2":"# Modelling","2037f668":"# Pneumonia Classification with PyTorch","2aa546e0":"## Data Understanding","1a2ccc1d":"# Data Preparation","ecd1ae14":"## Data Preparation\nI'm gonna creat a class named \"Dataset\", that will have the exactly same process above, and than we are gonna to pass it to the data loader."}}