{"cell_type":{"48bbaf11":"code","46aa5849":"code","935427e4":"code","b0925328":"code","77813395":"code","27e8ac34":"code","10524b65":"code","c5d474d9":"code","fcab1028":"code","6bcdac1f":"code","ae4eb2c8":"code","c34bd42f":"code","44994630":"code","c9a2af59":"code","61de1368":"code","707afa53":"code","9dda9677":"code","8f35ece2":"code","8b94e736":"code","94669ba2":"code","e7cff075":"code","e2a44367":"code","ecfaf594":"code","52fc4133":"code","17cb0ee4":"code","eeb9c18d":"code","11c30a90":"code","c60eea3a":"code","8877006c":"code","2651838a":"code","43462369":"code","1fefdfeb":"code","c3956715":"code","99e2a161":"code","2d22c990":"code","931939f7":"code","5356991d":"code","f399f13a":"code","570dd3d7":"code","160e87a6":"code","1dba06ef":"code","bbdc8e77":"code","757b92be":"code","39151ad9":"code","6d6f734f":"code","d0b4fcb1":"code","ebe4a226":"code","5f0b6113":"code","cbe637ab":"code","6f50c080":"code","9041610a":"markdown","9e285bfe":"markdown","3272c0a5":"markdown","ca6f6fab":"markdown","9e536403":"markdown","00aeba3d":"markdown","1be65696":"markdown","05a77fde":"markdown","670bcc3b":"markdown","e8d70f79":"markdown","56c2c6f7":"markdown","79e52870":"markdown","feba1c19":"markdown","a49c7d3c":"markdown","9ad1935e":"markdown"},"source":{"48bbaf11":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport keras as K\nimport tensorflow as tf\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom keras.utils.vis_utils import model_to_dot\nfrom datetime import timedelta\nfrom datetime import datetime\n\nfrom keras.utils import to_categorical\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","46aa5849":"from tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Flatten\n\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder","935427e4":"full_price = pd.read_csv('..\/input\/coffee-price-noweekend\/price_no_weekend.csv')\nfilled_price = pd.read_csv('..\/input\/coffeevsweather\/price_status.csv')\nstation31 = pd.read_csv('..\/input\/weather\/training_data_beta_31.csv')\nstation32 = pd.read_csv('..\/input\/weather\/training_data_beta_32.csv')\nstation36 = pd.read_csv('..\/input\/weather\/training_data_beta_36.csv')\n\n\nsc = MinMaxScaler()\noh = OneHotEncoder()","b0925328":"def create_lstm_datetime(X, Y, look_back):\n    dataX, dataY = [], []\n    ncol = len(X.columns)\n    \n    for i, row in Y.iterrows():\n        #a.drop(columns='Data')\n        date = row['Data']\n        b = row.iloc[1:]\n        a = X.loc[ (X['Data'] > date-timedelta(days = look_back)) &  (X['Data'] < date) ].copy()                                                         \n        #dataX.append(a.drop(columns='Data').values)\n        \n        if a.shape == (look_back-1,ncol):\n            dataX.append(a.drop(columns='Data').values)\n            dataY.append(b)\n            \n\n    return np.array(dataX), np.expand_dims(np.array(dataY),-1)\n\ndef create_dataset(X, Y, look_back):\n    dataX, dataY = [], []\n    for i in range(len(Y)-look_back-1):\n        a = X[i:(i+look_back)]\n        dataX.append(a)\n\n        #b = Y[i+1:(i+look_back+1)]\n        b = Y[(i+look_back)][0]\n        dataY.append(b)\n    #print(dataX)\n    return np.array(dataX), np.array(dataY)\n\ndef status_def(full_price):\n    v0 = 0\n    status_lst = []\n    previous = 'Alta'\n    for i, row in full_price.iterrows():\n        sample = row['Valor'] - v0\n        if sample>0:\n            result = 1\n        elif sample == 0:\n            result == previous\n        else:\n            result = 0\n\n        v0 = row['Valor']\n        previous = result\n        status_lst.append(result)    \n    return status_lst","77813395":"### Output Classes\n\n\nfull_price['Status'] = status_def(full_price)\n### Input Prep\n\nfull_price['Data'] = pd.to_datetime(full_price['Data'], format='%d\/%m\/%Y')\nheading = ['Precipitacao', 'TempMaxima', 'TempMinima', 'Insolacao', 'Evaporacao Piche', 'Temp Comp Media', 'Umidade Relativa Media', 'Velocidade do Vento Media']\n\n#start_date = '31\/12\/2002'\nstart_date = '01\/01\/2003'\nend_date = '01\/01\/2013'\nprice = full_price.loc[ (full_price['Data'] > datetime.strptime(start_date, \"%d\/%m\/%Y\")) &  (full_price['Data'] < datetime.strptime(end_date, \"%d\/%m\/%Y\")) ]                                                          \n\n# Weather\ndf_full = pd.DataFrame([], columns=heading)\nfor col in heading:\n    x = station31[col].values.astype(float)\n    df_full[col] = sc.fit_transform(np.expand_dims(x, -1)).T[0]\n    x = station32[col].values.astype(float)\n    df_full[col+'2'] = sc.fit_transform(np.expand_dims(x, -1)).T[0]\n    x = station36[col].values.astype(float)\n    df_full[col+'3'] = sc.fit_transform(np.expand_dims(x, -1)).T[0]\n\ndf_full['Data'] = station32['Data']\nX_full_W = df_full\n\n","27e8ac34":"### Output Preparations\n\n#Y = oh.fit_transform(np.expand_dims(price['Status'], -1)).toarray()### Boolean up or down\n#print(Y[:, 0])\n\nprice.head\n","10524b65":"price['Data'] = pd.to_datetime(price['Data'], format='%d\/%m\/%Y')\nX_full_W['Data'] = pd.to_datetime(X_full_W['Data'], format='%d\/%m\/%Y')\n\n\nX_lstm, Y_lstm = create_lstm_datetime(X_full_W, price, 14)\nnp.expand_dims(X_lstm,-1).shape","c5d474d9":"\nX_lstm, Y_lstm = create_lstm_datetime(X_full_W, price, 21)\n#np.expand_dims(X_lstm,-1).shape\nY_lstm_class = Y_lstm[:, 1].astype('int32') \nY_lstm_val = sc.fit_transform(Y_lstm[:, 0])\nY_lstm_val = Y_lstm[:, 0].astype('float64') ","fcab1028":"input_shape = X_lstm[1].shape\ninputA = Input(shape = input_shape)\n\n#x = LSTM(2, input_shape = input_shape)(inputA) ### Camada de LSTM, 2 mem\u00f3rias\nx = LSTM(14, input_shape = input_shape, dropout = 0.3)(inputA) ### Camada de LSTM, 14 mem\u00f3rias\n#x = LSTM(21, input_shape = input_shape)(inputA) ### Camada de LSTM, 21 mem\u00f3rias\n#x = LSTM(31, input_shape = input_shape)(inputA) ### Camada de LSTM, 31 mem\u00f3rias\n#x = LSTM(41, input_shape = input_shape, dropout = 0.1)(inputA) ### Camada de LSTM, 41 mem\u00f3rias\n#x = LSTM(41, input_shape = input_shape, dropout = 0.2)(inputA) ### Camada de LSTM, 41 mem\u00f3rias\n\n############## Output setting\n### Boolean Up vs Down\nx = Dense(5, activation = 'sigmoid')(x)\nz = Dense(1, activation = 'sigmoid')(x)        ### Camada densa de classifica\u00e7\u00e3o\nmodel = Model(inputs=[inputA], outputs=z)\noptimizer = K.optimizers.Adam(lr=0.005)\nmodel.compile( loss='binary_crossentropy', optimizer= optimizer, metrics=['accuracy'])\n\nmodel.summary()\n\n\n\n\n","6bcdac1f":"batch_size = 64\nmax_epochs = 1000\n\n#h = model.fit(x = x_train, y = Y_train, batch_size= batch_size, epochs= max_epochs, verbose=1, validation_split=0.1)\nh = model.fit(x = X_lstm, y = Y_lstm_class, batch_size= batch_size, epochs= max_epochs, verbose=1, validation_split=0.3)","ae4eb2c8":"plt.plot(h.history['accuracy'])\nplt.plot(h.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')","c34bd42f":"input_shape = X_lstm[1].shape\ninputA = Input(shape = input_shape)\n\n#x = LSTM(2, input_shape = input_shape)(inputA) ### Camada de LSTM, 2 mem\u00f3rias\nx = LSTM(7, input_shape = input_shape, dropout = 0.3)(inputA) ### Camada de LSTM, 14 mem\u00f3rias\n\n############## Output setting\n\n\n### Numeric Value \nz = Dense(1)(x)\nmodel = Model(inputs=[inputA], outputs=z)\nmodel.compile(loss='mse', optimizer='adam', metrics=['mse', 'mae'])\nmodel.summary()\n","44994630":"batch_size = 64\nmax_epochs = 1000\n\nh = model.fit(x = X_lstm, y = Y_lstm_val, batch_size= batch_size, epochs= max_epochs, verbose=1, validation_split=0.3)","c9a2af59":"plt.plot(h.history['mse'])\nplt.plot(h.history['val_mse'])\nplt.title('model error')\nplt.ylabel('error')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')","61de1368":"division = int(len(X_lstm) * 0.7)\n\nx_train = X_lstm[0:division]\nx_test = X_lstm[division:]\n\nY_train =  Y_lstm_val[0:division]\nY_test = Y_lstm_val[division:]\n\nnp.expand_dims(x_test,-1).shape\npredictions = model.predict(x_test)","707afa53":"print( x_test.shape)\nplt.plot(predictions)\nplt.plot(Y_test)\nplt.show()","9dda9677":"x_test = X_lstm[division+110 : division+200]\nY_test = Y_lstm_val[division+110 : division+200]\npredictions = model.predict(x_test)\n\nplt.plot(predictions)\nplt.plot(Y_test)\nplt.show()","8f35ece2":"start_date = '01\/01\/2002'\nend_date = '01\/01\/2013'\nfilled_price['Data'] = pd.to_datetime(filled_price['Data'], format='%d\/%m\/%Y')\nprice_filled = filled_price.loc[ (filled_price['Data'] > datetime.strptime(start_date, \"%d\/%m\/%Y\")) &  (filled_price['Data'] < datetime.strptime(end_date, \"%d\/%m\/%Y\")) ]                                                          \n","8b94e736":"\nY = oh.fit_transform(np.expand_dims(price_filled['Status'], -1)).toarray()### Boolean up or down\n\ndf_day_filled = X_full_W\ndf_day_filled['Valor'] = price_filled['Valor']\nX = df_day_filled.drop(columns='Data').to_numpy()\nX_lstm_fill_class, Y_lstm_fill_class = create_dataset(X, np.expand_dims(Y[:, 0], -1), 21)\n\nY_lstm_fill_class.shape","94669ba2":"input_shape = X_lstm_fill_class[1].shape\ninputA = Input(shape = input_shape)\n\n#x = LSTM(7, input_shape = input_shape)(inputA) ### Camada de LSTM, 7 mem\u00f3rias\nx = LSTM(14, input_shape = input_shape, dropout = 0.5)(inputA) ### Camada de LSTM, 7 mem\u00f3rias\n#x = LSTM(21, input_shape = input_shape)(inputA) ### Camada de LSTM, 21 mem\u00f3rias\n#x = LSTM(31, input_shape = input_shape)(inputA) ### Camada de LSTM, 31 mem\u00f3rias\n#x = LSTM(41, input_shape = input_shape)(inputA) ### Camada de LSTM, 41 mem\u00f3rias\n#x = LSTM(41, input_shape = input_shape, dropout = 0.2)(inputA) ### Camada de LSTM, 41 mem\u00f3rias\n\n############## Output setting\n### Boolean Up vs Down\nx = Dense(5, activation = 'sigmoid')(x)\nz = Dense(1, activation = 'sigmoid')(x)        ### Camada densa de classifica\u00e7\u00e3o\nmodel = Model(inputs=[inputA], outputs=z)\noptimizer = K.optimizers.Adam(lr=0.005)\nmodel.compile( loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n\nmodel.summary()","e7cff075":"batch_size = 64\nmax_epochs = 1000\n\nh = model.fit(x = X_lstm_fill_class, y = Y_lstm_fill_class, batch_size= batch_size, epochs= max_epochs, verbose=1, validation_split=0.3)","e2a44367":"plt.plot(h.history['accuracy'])\nplt.plot(h.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')","ecfaf594":"#x = , y = \n\ndivision = int(len(X_lstm_fill_class) * 0.7)\n\n\n#division = len(X_lstm_fill_class) - 1095\n\nx_train = X_lstm_fill_class[0:division]\nx_test = X_lstm_fill_class[division:]\n\nY_train =  Y_lstm_fill_class[0:division]\nY_test = Y_lstm_fill_class[division:]\n\n#np.expand_dims(x_test[0],-1)\n#predictions = model.predict(x_test[0:100])\n#classes = np.argmax(predictions, axis = 1)\n","52fc4133":"eval_test1 = model.evaluate(x_train, Y_train, verbose=0)\nprint(\"Erro m\u00e9dio do treino: Perda {0:.4f}, Acc. {1:.4f}\".format(eval_test1[0], eval_test1[1]))\n","17cb0ee4":"predictions = model.predict(x_test)\nprint( x_test.shape)\nplt.plot(predictions, 'r+')\n\nplt.show()","eeb9c18d":"x_train","11c30a90":"price_week = price_filled.set_index('Data').resample('7D').mean().reset_index()\nprice_week['Status'] = status_def(price_week)\ndf_week = X_full_W.set_index('Data').resample('7D').mean().reset_index()\nX_week = df_week.drop(columns='Data').to_numpy()\ndf_week['Valor'] = price_week['Valor']\nX_week_valor = df_week.drop(columns='Data').to_numpy()","c60eea3a":"\nY = oh.fit_transform(np.expand_dims(price_week['Status'], -1)).toarray()### Boolean up or down\n\n#X = X_full_W.drop(columns='Data').to_numpy()\nX_lstm_fill_class_week, Y_lstm_fill_class_week = create_dataset(X_week_valor, np.expand_dims(Y[:, 0], -1), 8)","8877006c":"input_shape = X_lstm_fill_class_week[1].shape\ninputA = Input(shape = input_shape)\n\nx = LSTM(7, input_shape = input_shape)(inputA) ### Camada de LSTM, 7 mem\u00f3rias\n#x = LSTM(14, input_shape = input_shape, dropout = 0.5)(inputA) ### Camada de LSTM, 7 mem\u00f3rias\n#x = LSTM(21, input_shape = input_shape)(inputA) ### Camada de LSTM, 21 mem\u00f3rias\n#x = LSTM(31, input_shape = input_shape)(inputA) ### Camada de LSTM, 31 mem\u00f3rias\n#x = LSTM(41, input_shape = input_shape)(inputA) ### Camada de LSTM, 41 mem\u00f3rias\n#x = LSTM(41, input_shape = input_shape, dropout = 0.2)(inputA) ### Camada de LSTM, 41 mem\u00f3rias\n\n############## Output setting\n### Boolean Up vs Down\nx = Dense(5, activation = 'sigmoid')(x)\nz = Dense(1, activation = 'sigmoid')(x)        ### Camada densa de classifica\u00e7\u00e3o\nmodel = Model(inputs=[inputA], outputs=z)\noptimizer = K.optimizers.Adam(lr=0.005)\nmodel.compile( loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n\nmodel.summary()","2651838a":"batch_size = 32\nmax_epochs = 500\n\n\nh = model.fit(x = X_lstm_fill_class_week, y = Y_lstm_fill_class_week, batch_size= batch_size, epochs= max_epochs, verbose=1, validation_split=0.3)","43462369":"plt.plot(h.history['accuracy'])\nplt.plot(h.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')","1fefdfeb":"division = int(len(X_lstm_fill_class) * 0.7)\n\n\nx_train = X_lstm_fill_class[0:division]\nx_test = X_lstm_fill_class[division:]\n\nY_train =  Y_lstm_fill_class[0:division]\nY_test = Y_lstm_fill_class[division:]","c3956715":"Y =  np.expand_dims(price_week[\"Valor\"].to_numpy(), -1)\n\nX_lstm_fill_reg_week, Y_lstm_fill_reg_week = create_dataset(X_week_valor,Y, 8)\nY_lstm_fill_reg_week = np.expand_dims(Y_lstm_fill_reg_week, -1)","99e2a161":"type(Y_lstm_fill_reg_week[0][0])\ntype(X_lstm_fill_reg_week[0][0][0])\n","2d22c990":"input_shape = X_lstm_fill_reg_week[1].shape\ninputA = Input(shape = input_shape)\n\n#x = LSTM(14, input_shape = input_shape, dropout = 0.3)(inputA) ### Camada de LSTM, 14 mem\u00f3rias\nx = LSTM(14, input_shape = input_shape)(inputA) ### Camada de LSTM, 14 mem\u00f3rias\n#x = Flatten()(inputA)\n############## Output setting\n\n\n### Numeric Value \n#x = Dense(256, activation = 'tanh')(x)\n#x = Dense(7, activation = 'relu')(x)\nz = Dense(1)(x)\nmodel = Model(inputs=[inputA], outputs=z)\nmodel.compile(loss='mae', optimizer='adam', metrics=['mse', 'mae'])\nmodel.summary()","931939f7":"batch_size = 64\nmax_epochs = 500\n\nh = model.fit(x = X_lstm_fill_reg_week, y = Y_lstm_fill_reg_week, batch_size= batch_size, epochs= max_epochs, verbose=1, validation_split=0.3)\n#h = model.fit(x = X_lstm_fill_reg_week, y = Y_lstm_fill_reg_week, batch_size= batch_size, epochs= max_epochs, verbose=1)","5356991d":"plt.plot(h.history['mse'])\nplt.plot(h.history['val_mse'])\nplt.title('model error')\nplt.ylabel('error')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')","f399f13a":"division = int(len(X_lstm_fill_reg_week) * 0.7)\n\nx_train = X_lstm_fill_reg_week[0:division]\nx_test = X_lstm_fill_reg_week[division:]\n\nY_train =  Y_lstm_fill_reg_week[0:division]\nY_test = Y_lstm_fill_reg_week[division:]\n\npredictions = model.predict(x_test)\n#predictions = model.predict(X_lstm_fill_reg_week)","570dd3d7":"\nplt.plot(predictions, \"r\")\nplt.plot(Y_test)\nplt.grid(True)\nplt.legend(['Previs\u00e3o', 'Real'], loc='upper left')\nplt.show()","160e87a6":"bot, top = 140, 152\nplt.plot(predictions[bot:top], \"r-o\")\nplt.plot(Y_test[bot:top], \"-o\")\nplt.grid(True)\nplt.legend(['Previs\u00e3o', 'Real'], loc='upper left')\nplt.show()","1dba06ef":"Y =  np.expand_dims(price_week[\"Valor\"].to_numpy(), -1)\nX_lstm_week_v, Y_lstm_week_v = create_dataset(Y,Y, 8)\n#X_lstm, Y_lstm = create_dataset(X_full_P, Y, 21)\n#X_lstm = np.expand_dims(X_lstm, -1)\n#X_lstm[1].shape","bbdc8e77":"input_shape = X_lstm[1].shape\ninputA = Input(shape = input_shape)\n\n\n#x = LSTM(7, input_shape = input_shape)(inputA) ### Camada de LSTM, 7 mem\u00f3rias\nx = LSTM(14, input_shape = input_shape, dropout = 0.3)(inputA) ### Camada de LSTM, 21 mem\u00f3rias\n#x = LSTM(31, input_shape = input_shape)(inputA) ### Camada de LSTM, 31 mem\u00f3rias\n#x = LSTM(41, input_shape = input_shape)(inputA) ### Camada de LSTM, 41 mem\u00f3rias\n#x = LSTM(41, input_shape = input_shape, dropout = 0.2)(inputA) ### Camada de LSTM, 41 mem\u00f3rias\n\n############## Output setting\n### Boolean Up vs Down\nz = Dense(1)(x)        ### Camada densa de classifica\u00e7\u00e3o\nmodel = Model(inputs=[inputA], outputs=z)\noptimizer = K.optimizers.Adam(lr=0.005)\nmodel.compile( loss='mse', optimizer= optimizer, metrics=['mse', 'mae'])\n\nmodel.summary()","757b92be":"batch_size = 64\nmax_epochs = 500\n\nh = model.fit(x = X_lstm_week_v, y = Y_lstm_week_v, batch_size= batch_size, epochs= max_epochs, verbose=1, validation_split=0.3)","39151ad9":"plt.plot(h.history['mse'])\nplt.plot(h.history['val_mse'])\nplt.title('model error')\nplt.ylabel('error')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')","6d6f734f":"#X_lstm_week_v, Y_lstm_week_v\n\ndivision = int(len(X_lstm_week_v) * 0.7)\n\nx_train = X_lstm_week_v[0:division]\nx_test = X_lstm_week_v[division:]\n\nY_train =  Y_lstm_week_v[0:division]\nY_test = Y_lstm_week_v[division:]\n\n#predictions = model.predict(x_test)\npredictions = model.predict(X_lstm_week_v)","d0b4fcb1":"plt.plot(predictions, \"--\")\nplt.plot(Y_lstm_week_v)\nplt.show()","ebe4a226":"\neval_test1 = model.evaluate(x_test, Y_test, verbose=0)\n#print(\"Erro m\u00e9dio do teste: Perda {0:.4f}, acuracia {1:.4f}\".format(eval_test1[0], eval_test1[1]*100))\nprint(\"Erro m\u00e9dio do teste: Acuracia {0:.4f}\".format(eval_test1[1]*100))","5f0b6113":"price.groupby(['Status']).describe()","cbe637ab":"price.head()","6f50c080":"price['Valor'].plot()","9041610a":"## Regress\u00e3o usando as vari\u00e1veis de Tempo e pre\u00e7o periodo de medi\u00e7\u00e3o de 1 semana","9e285bfe":"Primeiramente os dados da foram separados, utilizando apenas os dados de pre\u00e7o dispon\u00edveis sem nenhum preenchimento.","3272c0a5":"## Classificador usando as vari\u00e1veis meteorol\u00f3gicas e periodo de medi\u00e7\u00e3o de 1 semana","ca6f6fab":"## Classificador usando as vari\u00e1veis de Tempo e periodo de medi\u00e7\u00e3o de 1 dia","9e536403":"## Resultados:\n\nO modelo n\u00e3o apresenta capacidade de prever o pre\u00e7o do caf\u00e9 de maneira geral, mas ele mostra sinais em diversos trechos de que ela \u00e9 capaz de avaliar o comportamento do pre\u00e7o como mostrado abaixo:","00aeba3d":"## Valor Classifier","1be65696":"## Weather Classifier","05a77fde":"# Valores com preenchimento de Finais de semana","670bcc3b":"## Weather Regression","e8d70f79":"# Trade days only","56c2c6f7":"## Resultado\nEm nenhuma configura\u00e7\u00e3o de modelo utilizada foi capaz de utilizar os dados meteorol\u00f3gicos pare prever se o pre\u00e7o do caf\u00e9 vai subir ou descer. Todas as rede ou nunca convergem para acertar mais do que a distribui\u00e7\u00e3o de Alta e Baixa fornecida pelos dados e tem uma tend\u00eancia ao overfitting.","79e52870":"## Sketch","feba1c19":"## Resultado\n\nMais uma vez, a rede apresentou resultados muito similares, onde ela \u00e9 n\u00e3o demonstra um desempenho suficiente para prever o pre\u00e7o do caf\u00e9. Nenhum resultado demonstrou uma valida\u00e7\u00e3o com resultados acima da distribui\u00e7\u00e3o de Altas e Baixas.","a49c7d3c":"Utilizando modelos similiares aos utilizados para prever as altas e baixas do caf\u00e9 foram utilizadas mas dessa vez foi adicionado o pre\u00e7o do caf\u00e9 aos dados meteorol\u00f3gicos para tentar prever o comportamento do caf\u00e9, mas dado que os dados est\u00e3o completamente pareados, ou seja para cada dado meteorol\u00f3gico existe um dado de pre\u00e7o que corresponde a mesma data, as duas bases foram unidas para tentar melhorar a classifica\u00e7\u00e3o dos dados:","9ad1935e":"A primeira rede implementada foi uma LSTM para correlacionar os dados meteorol\u00f3gicos e a subida e decida do pre\u00e7o do caf\u00e9. Sendo realizados v\u00e1rios treinamentos com diversas configura\u00e7\u00f5es de n\u00famero de neur\u00f4nios, tamanho de mem\u00f3ria."}}