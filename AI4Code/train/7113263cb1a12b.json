{"cell_type":{"40984fc7":"code","d2172890":"code","9fd8ed90":"code","fca052cc":"code","5481d127":"code","907ea125":"code","8b6519bf":"code","7d2344a0":"code","9f5816ef":"code","aca1d671":"code","9eff4d26":"code","264448c5":"code","d12e479f":"code","05c6ed84":"code","3171b912":"code","4789158f":"code","5bc0f79e":"code","5142cda0":"code","58c88540":"code","f8f084e5":"code","c29b8bee":"code","757dac7c":"code","1175bb22":"code","89e9b6ee":"code","dc59260f":"code","ab1d27d0":"code","a466abdc":"code","bde6b687":"code","350a0606":"code","e3ae999c":"code","31f50a72":"code","9f30e66f":"code","6a2577d1":"code","3996c62f":"code","d1452a77":"code","12682554":"code","26155f81":"code","d943b225":"code","c42e65da":"code","cd5a6917":"code","5751b7b0":"code","c0806422":"code","447f88cf":"code","d10a1f2e":"code","6e3a7f79":"code","a15540c2":"code","5903da83":"code","8b8d1154":"code","743d5642":"code","2d69216d":"code","21fe20cd":"code","404c359d":"code","5db954fa":"code","da766408":"code","40e7069f":"code","4059316f":"code","de4e24b0":"code","79d7ec04":"code","cd429f1b":"code","cff6d278":"code","755a2ff1":"code","e59d5aab":"code","5a2d693a":"code","7ba6c952":"markdown","3e7e41a9":"markdown","09001c4b":"markdown","f3b01ca2":"markdown","ac1699ea":"markdown","4c7aecf6":"markdown","db293130":"markdown","fe0cb7c8":"markdown","80054c75":"markdown"},"source":{"40984fc7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d2172890":"# Importando os arquivos\ndftrain = pd.read_csv('..\/input\/train-v9rqx0r\/train_v9rqX0R.csv')\ndftest = pd.read_csv('..\/input\/test-abjtz2i\/test_AbJTz2l.csv')\n\ndftrain.shape, dftest.shape","9fd8ed90":"# Verificando o dataframe de treino\ndftrain.info()","fca052cc":"# Verificando o dataframe de teste\ndftest.info()","5481d127":"dftest.head()","907ea125":"dftrain.head()","8b6519bf":"# Verificando a distribui\u00e7\u00e3o da vari\u00e1vel Item_Outlet_Sales\ndftrain['Item_Outlet_Sales'].plot.hist(bins=50)","7d2344a0":"# Quais colunas do dataframe s\u00e3o do tipo object\ndftrain.select_dtypes('object').head()","9f5816ef":"# Quais colunas do dataframe s\u00e3o do tipo object\ndftest.select_dtypes('object').head()","aca1d671":"# Aplicar log na variavel de resposta para transformar os dados e n\u00e3o perder os valores originais\ndftrain['Item_Outlet_Sales'] = np.log(dftrain['Item_Outlet_Sales'])","9eff4d26":"# Verificando novamente a distribui\u00e7\u00e3o da vari\u00e1vel Item_Outlet_Sales\ndftrain['Item_Outlet_Sales'].plot.hist(bins=50)","264448c5":"# Visualizando os dados\ndftrain.head().T","d12e479f":"# Juntando os dataframes\ndftrain = dftrain.append(dftest)","05c6ed84":"# Identificando os conte\u00fados de Item_Fat_Content\ndftrain['Item_Fat_Content'].value_counts()","3171b912":"# Creating dummy variables para Item_Fat_Content:\ndftrain = pd.get_dummies(dftrain, columns=['Item_Fat_Content'])","4789158f":"# Identificando os conte\u00fados de Outlet_Size\ndftrain['Outlet_Size'].value_counts()","5bc0f79e":"# Creating dummy variables para Outlet_Size:\ndftrain = pd.get_dummies(dftrain, columns=['Outlet_Size'])","5142cda0":"# Verificando os valores nulos\ndftrain.isnull().sum().sort_values()","58c88540":"# Preenchendo com 0 os valores nulos de 'Item_Weight'\ndftrain['Item_Weight'].fillna(0, inplace=True)","f8f084e5":"# Identificando os conte\u00fados de Outlet_Location_Type\ndftrain['Outlet_Location_Type'].value_counts()","c29b8bee":"# Identificando os conte\u00fados de Outlet_Type\ndftrain['Outlet_Type'].value_counts()","757dac7c":"# Creating dummy variables para Outlet_Type:\ndftrain = pd.get_dummies(dftrain, columns=['Outlet_Type'])","1175bb22":"# Vamos transformar coluna Item_Type\nitem_type_trans = {'Baking Goods': 1, 'Breads': 2, 'Breakfast': 3, 'Canned': 4, 'Dairy': 5, 'Frozen Foods': 6 , 'Fruits and Vegetables': 7 , 'Hard Drinks': 8,\n                'Health and Hygiene': 9, 'Household': 10 , 'Meat': 11 , 'Others': 12 , 'Seafood': 13 , 'Snack Foods': 14 , 'Soft Drinks': 15,\n                'Starchy Foods': 16}\n\ndftrain['Item_Type'] = dftrain['Item_Type'].replace(item_type_trans).astype(int)","89e9b6ee":"# Avaliando os maiores valores para Item_Outlet_Sales\ndftrain.nlargest(10,'Item_Outlet_Sales')","dc59260f":"# Avaliando os menores valores para Item_Outlet_Sales\ndftrain.nsmallest(10,'Item_Outlet_Sales')","ab1d27d0":"# Separando os dataframes novamente - com nulos para a target Item_Outlet_Sales\ndftest = dftrain[dftrain['Item_Outlet_Sales'].isnull()]","a466abdc":"# Depois o dataframe de treino - sem nulos para a target Item_Outlet_Sales\ndftrain = dftrain[~dftrain['Item_Outlet_Sales'].isnull()]","bde6b687":"# Verificando tamanhos\ndftrain.shape, dftest.shape","350a0606":"# Importando o metodo do scikitlearn para divisao de treino e validacao\nfrom sklearn.model_selection import train_test_split","e3ae999c":"# Dividir a base de treino e validacao\ndftrain, valid = train_test_split(dftrain, random_state=42)","31f50a72":"# verificando tamanhos\ndftrain.shape, valid.shape","9f30e66f":"# Lista das colunas nao usadas\nremoved_cols = ['Item_Outlet_Sales','Item_Identifier', 'Item_Fat_Content', 'Item_Type', 'Outlet_Identifier','Outlet_Size','Outlet_Location_Type','Outlet_Type']\n\n# Criar a lista das colunas de entrada\nfeats = [c for c in dftrain.columns if c not in removed_cols]\n\n# target\ntarget='Item_Outlet_Sales'","6a2577d1":"feats","3996c62f":"# Importando o modelo\nfrom sklearn.ensemble import RandomForestRegressor","d1452a77":"# Instanciar o modelo\nrf = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)","12682554":"# Treinando o modelo\nrf.fit(dftrain[feats], dftrain['Item_Outlet_Sales'])","26155f81":"# Fazendo previs\u00f5es em cima dos dados de valida\u00e7\u00e3o\npreds = rf.predict(valid[feats])","d943b225":"# Verificando as previsoes\npreds","c42e65da":"# Verificando os dados reais do in\u00edcio do Dataframe\nvalid['Item_Outlet_Sales'].head(5)","cd5a6917":"# Verificando os dados reais do fim do Dataframe\nvalid['Item_Outlet_Sales'].tail(5)","5751b7b0":"# Importando as metricas e bibliotecas\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import utils","c0806422":"# Aplicando a metrica\nmean_squared_log_error(np.exp(valid['Item_Outlet_Sales']), np.exp(preds))**(1\/2)","447f88cf":"# Vamos prever com base nos dados de treino como o modelo se comporta prevendo em cima de dados conhecidos\ntrain_preds = rf.predict(dftrain[feats])\n\nmean_squared_log_error(np.exp(dftrain['Item_Outlet_Sales']), np.exp(train_preds))**(1\/2)","d10a1f2e":"# Gerando as previs\u00f5es para envio ao Kaggle\ndftest['Item_Outlet_Sales'] = np.exp(rf.predict(dftest[feats]))","6e3a7f79":"# Verificando os dados\ndftest.head(10)","a15540c2":"# Gerando o arquivo para submeter ao kaggle\ndftest[['Item_Identifier', 'Outlet_Identifier' , 'Item_Outlet_Sales']].to_csv('rf_acnsa.csv', index=False)","5903da83":"encoder = LabelEncoder()\ndftrain['Item_Outlet_Sales'] = encoder.fit_transform(dftrain['Item_Outlet_Sales'])\n","8b8d1154":"from sklearn.ensemble import GradientBoostingRegressor\n\ngbm = GradientBoostingRegressor(n_estimators=200, max_depth=1, random_state=42)\n\n# Treinando o modelo\ngbm.fit(dftrain[feats], dftrain['Item_Outlet_Sales'])\n\n# Fazendo previs\u00f5es em cima dos dados de valida\u00e7\u00e3o\npreds = gbm.predict(valid[feats])","743d5642":"# Verificando os dados\ndftest.head(10)","2d69216d":"# Aplicando a metrica na base de valida\u00e7\u00e3o\nfrom sklearn.metrics import mean_squared_error\n\ny_real = list(valid['Item_Outlet_Sales'])\ny_pred = list(preds)\nmean_squared_error(y_real, y_pred, squared=False)","21fe20cd":"# Gerando as previs\u00f5es para envio ao Kaggle\ndftest['Item_Outlet_Sales'] = np.exp(rf.predict(dftest[feats]))","404c359d":"# Gerando o arquivo para submeter ao kaggle\ndftest[['Item_Identifier', 'Outlet_Identifier' , 'Item_Outlet_Sales']].to_csv('gbm_acnsa.csv', index=False)","5db954fa":"dftrain.shape, valid.shape, dftest.shape","da766408":"# Importando o modelo\nfrom sklearn.tree import DecisionTreeRegressor","40e7069f":"# Instanciando o modelo\ndtree = DecisionTreeRegressor(random_state = 42)","4059316f":"# Treinando o modelo\ndtree.fit(dftrain[feats], dftrain[target])","de4e24b0":"# Fazendo previs\u00f5es em cima dos dados de valida\u00e7\u00e3o\npreds = dtree.predict(valid[feats])","79d7ec04":"# Valores preditos - inicio\npreds[:5], valid['Item_Outlet_Sales'].head(5)","cd429f1b":"# Valores preditos - fim\npreds[:5], valid['Item_Outlet_Sales'].tail(5)","cff6d278":"# Previs\u00f5es na base de teste\npreds = dtree.predict(dftest[feats])","755a2ff1":"# Gerando as previs\u00f5es para envio ao Kaggle\ndftest['Item_Outlet_Sales'] = np.exp(rf.predict(dftest[feats]))","e59d5aab":"# Gerando o arquivo para submeter ao kaggle\ndftest[['Item_Identifier', 'Outlet_Identifier' , 'Item_Outlet_Sales']].to_csv('dtree_acnsa.csv', index=False)","5a2d693a":"# Trabalhando com AdaBoost\n# from sklearn.ensemble import AdaBoostClassifier\n\n# AdaBoost padr\u00e3o\n# ada_padrao = AdaBoostClassifier(random_state=42)\n\n# ada_padrao.fit(dftrain[feats], dftrain['Item_Outlet_Sales'])\n\n# accuracy_score(dftest['Item_Outlet_Sales'], ada_padrao.predict(dftest[feats]))","7ba6c952":"# Modelo 1 - Random Forest Regressor","3e7e41a9":"# IESB - Miner II - Projeto Final - Andr\u00e9a Campos Neves Silva Andr\u00e9 - Matr\u00edcula 2186324025","09001c4b":"# Juntando e transformando os Dataframes","f3b01ca2":"# Modelo 2 - Modelo GBM","ac1699ea":"# Separando novamente os dataframes depois das transforma\u00e7\u00f5es","4c7aecf6":"# Modelo 3 - \u00c1rvore de Decis\u00e3o","db293130":"# Dividindo o dataframe de treino","fe0cb7c8":"# Verificando o resultado do modelo com m\u00e9trica","80054c75":"# Modelo 4 - Modelo AdaBoost"}}