{"cell_type":{"14e70cbf":"code","e61f1ecd":"code","2303733a":"code","b61850b6":"code","e5a88c5e":"code","12f6d6bc":"code","b16a731d":"code","544028ed":"code","04372636":"code","090cf6c7":"code","ac432a82":"code","6440ffe7":"code","45a419dd":"code","a464c527":"code","53212fb7":"code","958b7f44":"code","0819865f":"code","2357a003":"code","9c44a669":"markdown","6a1c97b1":"markdown","0adc2c80":"markdown","269b46c3":"markdown","a074b249":"markdown","2a07935d":"markdown","d500ef81":"markdown"},"source":{"14e70cbf":"import numpy as np\nimport torch\nfrom torch.autograd import Variable\nfrom torch.optim import SGD\nfrom torchvision import models, transforms\nimport PIL\nimport os\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib import animation\nfrom IPython.display import HTML\n\nimport scipy.ndimage as ndimage\n\n%matplotlib inline\n\nimport scipy.ndimage as nd\nimport PIL.Image\nfrom IPython.display import clear_output, Image, display\nfrom io import BytesIO","e61f1ecd":"#Code by Carlo Alberto Barbano https:\/\/www.kaggle.com\/carloalbertobarbano\/convolutional-network-visualizations-deep-dream\n\ndef showarray(a, fmt='jpeg'):\n    a = np.uint8(np.clip(a, 0, 255))\n    f = BytesIO()\n    PIL.Image.fromarray(a).save(f, fmt)\n    display(Image(data=f.getvalue()))\n    \ndef showtensor(a):\n    mean = np.array([0.485, 0.456, 0.406]).reshape([1, 1, 3])\n    std = np.array([0.229, 0.224, 0.225]).reshape([1, 1, 3])\n    inp = a[0, :, :, :]\n    inp = inp.transpose(1, 2, 0)\n    inp = std * inp + mean\n    inp *= 255\n    showarray(inp)\n    clear_output(wait=True)","2303733a":"#Code by Carlo Alberto Barbano https:\/\/www.kaggle.com\/carloalbertobarbano\/convolutional-network-visualizations-deep-dream\n\ndef plot_images(im, titles=None):\n    plt.figure(figsize=(30, 20))\n    \n    for i in range(len(im)):\n        plt.subplot(10 \/ 5 + 1, 5, i + 1)\n        plt.axis('off')\n        if titles is not None:\n            plt.title(titles[i])\n        plt.imshow(im[i])\n        \n    plt.pause(0.001)\n    \nnormalise = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nnormalise_resize = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])","b61850b6":"#Code by Carlo Alberto Barbano https:\/\/www.kaggle.com\/carloalbertobarbano\/convolutional-network-visualizations-deep-dream\n\ndef init_image(size=(400, 400, 3)):\n    img = PIL.Image.fromarray(np.uint8(np.full(size, 150)))\n    img = PIL.Image.fromarray(np.uint8(np.random.uniform(150, 180, size)))\n    img_tensor = normalise(img).unsqueeze(0)\n    img_np = img_tensor.numpy()\n    return img, img_tensor, img_np\n\ndef load_image(path, resize=False, size=None):\n    img = PIL.Image.open(path)\n    \n    if size is not None:\n        img.thumbnail(size, PIL.Image.ANTIALIAS)\n        \n    if resize:\n        img_tensor = normalise_resize(img).unsqueeze(0)\n    else:\n        img_tensor = normalise(img).unsqueeze(0)\n    img_np = img_tensor.numpy()\n    return img, img_tensor, img_np","e5a88c5e":"#Code by Carlo Alberto Barbano https:\/\/www.kaggle.com\/carloalbertobarbano\/convolutional-network-visualizations-deep-dream\n\ndef tensor_to_img(t):\n    a = t.numpy()\n    mean = np.array([0.485, 0.456, 0.406]).reshape([1, 1, 3])\n    std = np.array([0.229, 0.224, 0.225]).reshape([1, 1, 3])\n    inp = a[0, :, :, :]\n    inp = inp.transpose(1, 2, 0)\n    inp = std * inp + mean\n    inp *= 255\n    inp = np.uint8(np.clip(inp, 0, 255))\n    return PIL.Image.fromarray(inp)\n\ndef image_to_variable(image, requires_grad=False, cuda=False):\n    if cuda:\n        image = Variable(image.cuda(), requires_grad=requires_grad)\n    else:\n        image = Variable(image, requires_grad=requires_grad)\n    return image","12f6d6bc":"model = models.vgg16()\nmodel.load_state_dict(torch.load(\"..\/input\/vgg16\/vgg16.pth\"))","b16a731d":"use_gpu = False\nif torch.cuda.is_available():\n    use_gpu = True\n\nprint(model)\n\nfor param in model.parameters():\n    param.requires_grad = False\n\nif use_gpu:\n    print(\"Using CUDA\")\n    model.cuda()","544028ed":"#Code by Carlo Alberto Barbano https:\/\/www.kaggle.com\/carloalbertobarbano\/convolutional-network-visualizations-deep-dream\n\ndef octaver_fn(model, base_img, step_fn, octave_n=6, octave_scale=1.4, iter_n=10, **step_args):\n    octaves = [base_img]\n    \n    for i in range(octave_n - 1):\n        octaves.append(nd.zoom(octaves[-1], (1, 1, 1.0 \/ octave_scale, 1.0 \/ octave_scale), order=1))\n\n    detail = np.zeros_like(octaves[-1])\n    for octave, octave_base in enumerate(octaves[::-1]):\n        h, w = octave_base.shape[-2:]\n        \n        if octave > 0:\n            h1, w1 = detail.shape[-2:]\n            detail = nd.zoom(detail, (1, 1, 1.0 * h \/ h1, 1.0 * w \/ w1), order=1)\n        \n        src = octave_base + detail\n        \n        for i in range(iter_n):\n            src = step_fn(model, src, **step_args)\n\n        detail = src.numpy() - octave_base\n\n    return src","04372636":"#Code by Carlo Alberto Barbano https:\/\/www.kaggle.com\/carloalbertobarbano\/convolutional-network-visualizations-deep-dream\n\ndef filter_step(model, img, layer_index, filter_index, step_size=5, display=True, use_L2=False):\n    global use_gpu\n    \n    mean = np.array([0.485, 0.456, 0.406]).reshape([3, 1, 1])\n    std = np.array([0.229, 0.224, 0.225]).reshape([3, 1, 1])\n    \n    model.zero_grad()\n    \n    img_var = image_to_variable(torch.Tensor(img), requires_grad=True, cuda=use_gpu)\n    optimizer = SGD([img_var], lr=step_size, weight_decay=1e-4)\n    \n    x = img_var\n    for index, layer in enumerate(model.features):\n        x = layer(x)\n        if index == layer_index:\n            break\n\n    output = x[0, filter_index]\n    loss = output.norm() #torch.mean(output)\n    loss.backward()\n    \n    if use_L2:\n        #L2 normalization on gradients\n        mean_square = torch.Tensor([torch.mean(img_var.grad.data ** 2) + 1e-5])\n        if use_gpu:\n            mean_square = mean_square.cuda()\n        img_var.grad.data \/= torch.sqrt(mean_square)\n        img_var.data.add_(img_var.grad.data * step_size)\n    else:\n        optimizer.step()\n    \n    result = img_var.data.cpu().numpy()\n    result[0, :, :, :] = np.clip(result[0, :, :, :], -mean \/ std, (1 - mean) \/ std)\n    \n    if display:\n        showtensor(result)\n    \n    return torch.Tensor(result)\n\ndef visualize_filter(model, base_img, layer_index, filter_index, \n                     octave_n=6, octave_scale=1.4, iter_n=10, \n                     step_size=5, display=True, use_L2=False):\n    \n    return octaver_fn(\n                model, base_img, step_fn=filter_step, \n                octave_n=octave_n, octave_scale=octave_scale, \n                iter_n=iter_n, layer_index=layer_index, \n                filter_index=filter_index, step_size=step_size, \n                display=display, use_L2=use_L2\n            ) ","090cf6c7":"#Code by Carlo Alberto Barbano https:\/\/www.kaggle.com\/carloalbertobarbano\/convolutional-network-visualizations-deep-dream\n\ndef show_layer(layer_num, filter_start=10, filter_end=20, step_size=7, use_L2=False):\n    filters = []\n    titles = []\n    \n    _, _, img_np = init_image(size=(600, 600, 3))\n    for i in range(filter_start, filter_end):\n        title = \"Layer {} Filter {}\".format(layer_num , i)\n        print(title)\n        filter = visualize_filter(model, img_np, layer_num, filter_index=i, octave_n=2, iter_n=20, step_size=step_size, display=True, use_L2=use_L2)\n        filter_img = tensor_to_img(filter)\n        filter_img.save(title + \".jpg\")\n        filters.append(tensor_to_img(filter))\n        titles.append(title)\n        \n    \n    plot_images(filters, titles)\n    return filters, titles","ac432a82":"import warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nimages, titles = show_layer(1, use_L2=True, step_size=0.05)","6440ffe7":"images, titles = show_layer(10, use_L2=True, step_size=0.05)","45a419dd":"images, titles = show_layer(14, use_L2=True, step_size=0.05)","a464c527":"#Code by Carlo Alberto Barbano https:\/\/www.kaggle.com\/carloalbertobarbano\/convolutional-network-visualizations-deep-dream\n\ndef objective(dst, guide_features):\n    if guide_features is None:\n        return dst.data\n    else:\n        x = dst.data[0].cpu().numpy()\n        y = guide_features.data[0].cpu().numpy()\n        ch, w, h = x.shape\n        x = x.reshape(ch, -1)\n        y = y.reshape(ch, -1)\n        A = x.T.dot(y)\n        diff = y[:, A.argmax(1)]\n        diff = torch.Tensor(np.array([diff.reshape(ch, w, h)])).cuda()\n        return diff\n\n\ndef make_step(model, img, objective=objective, control=None, step_size=1.5, end=28, jitter=32):\n    global use_gpu\n    \n    mean = np.array([0.485, 0.456, 0.406]).reshape([3, 1, 1])\n    std = np.array([0.229, 0.224, 0.225]).reshape([3, 1, 1])\n    \n    ox, oy = np.random.randint(-jitter, jitter+1, 2)\n    \n    img = np.roll(np.roll(img, ox, -1), oy, -2)\n    tensor = torch.Tensor(img) \n    \n    img_var = image_to_variable(tensor, requires_grad=True, cuda=use_gpu)\n    model.zero_grad()\n      \n    x = img_var\n    for index, layer in enumerate(model.features.children()):\n        x = layer(x)\n        if index == end:\n            break\n    \n    delta = objective(x, control)\n    x.backward(delta)\n    \n    #L2 Regularization on gradients\n    mean_square = torch.Tensor([torch.mean(img_var.grad.data ** 2)])\n    if use_gpu:\n        mean_square = mean_square.cuda()\n    img_var.grad.data \/= torch.sqrt(mean_square)\n    img_var.data.add_(img_var.grad.data * step_size)\n    \n    result = img_var.data.cpu().numpy()\n    result = np.roll(np.roll(result, -ox, -1), -oy, -2)\n    result[0, :, :, :] = np.clip(result[0, :, :, :], -mean \/ std, (1 - mean) \/ std)\n    showtensor(result)\n    \n    return torch.Tensor(result)\n                                                             \ndef deepdream(model, base_img, octave_n=6, octave_scale=1.4, \n              iter_n=10, end=28, control=None, objective=objective, \n              step_size=1.5, jitter=32):\n    \n    return octaver_fn(\n              model, base_img, step_fn=make_step, \n              octave_n=octave_n, octave_scale=octave_scale, \n              iter_n=iter_n, end=end, control=control,\n              objective=objective, step_size=step_size, jitter=jitter\n           )","53212fb7":"input_img, input_tensor, input_np = load_image('..\/input\/cartoon-classification\/cartoon_classification\/TRAIN\/tom_and_jerry\/TOM_AND_JERRY1015.jpg', size=[1024, 1024])\nprint(input_img.size)\ninput_img","958b7f44":"dream = deepdream(model, input_np, end=14, step_size=0.06, octave_n=6)\ndream = tensor_to_img(dream)\ndream.save('dream00.jpg')\ndream","0819865f":"dream = deepdream(model, input_np, end=20, step_size=0.06, octave_n=6)\ndream = tensor_to_img(dream)\ndream.save('dream01.jpg')\ndream","2357a003":"dream = deepdream(model, input_np, end=28, step_size=0.06, octave_n=6)\ndream = tensor_to_img(dream)\ndream.save('dream03.jpg')\ndream","9c44a669":"#Psychedelic Tom and Jerry.","6a1c97b1":"#I tried to change Dream to TomJerry, though it resulted in attribute error. So I kept dream. ","0adc2c80":"![](https:\/\/cf-images.us-east-1.prod.boltdns.net\/v1\/static\/689254975001\/c21f5e05-6813-442d-a408-91a9c709d973\/1513f0ae-4e58-41bd-9bd2-609ea6b33405\/1280x720\/match\/image.jpg)spieddigitallibrary.org","269b46c3":"#With GPU less than 1 min","a074b249":"#Code by Carlo Alberto Barbano https:\/\/www.kaggle.com\/carloalbertobarbano\/convolutional-network-visualizations-deep-dream","2a07935d":"With GPU less than 1 minute","d500ef81":"#GPU rules. It was very fast. Without GPU my dreams are almost a nightmare."}}