{"cell_type":{"a3ca2b39":"code","8eaf2221":"code","620c139e":"code","1676329e":"code","046733ae":"code","3003b107":"code","fb5d618c":"code","c7db3715":"code","8885d474":"code","6acc925b":"code","d768f8fc":"code","653801e0":"code","7e108d97":"markdown","f0efd526":"markdown","7c2f499c":"markdown","7f73f890":"markdown","183b312c":"markdown","8c876f2b":"markdown","caed361f":"markdown","791dca14":"markdown"},"source":{"a3ca2b39":"!pip install ..\/input\/detectron-05\/whls\/pycocotools-2.0.2\/dist\/pycocotools-2.0.2.tar --no-index --find-links ..\/input\/detectron-05\/whls \n!pip install ..\/input\/detectron-05\/whls\/fvcore-0.1.5.post20211019\/fvcore-0.1.5.post20211019 --no-index --find-links ..\/input\/detectron-05\/whls \n!pip install ..\/input\/detectron-05\/whls\/antlr4-python3-runtime-4.8\/antlr4-python3-runtime-4.8 --no-index --find-links ..\/input\/detectron-05\/whls \n!pip install ..\/input\/detectron-05\/whls\/detectron2-0.5\/detectron2 --no-index --find-links ..\/input\/detectron-05\/whls ","8eaf2221":"import detectron2\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom fastcore.all import *\n\nimport torch\nfrom PIL import Image\nimport cv2\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os","620c139e":"class CFG:\n    wfold = 0\n    data_folder = '..\/input\/sartorius-cell-instance-segmentation\/'\n    anno_folder = '..\/input\/sartorius-annotations\/'\n    model_folder = '..\/input\/sartorius-dataset\/'\n    model_arch = 'mask_rcnn_R_50_FPN_3x.yaml'\n    nof_iters = 10000\n    THRESHOLDS = [.15, .35, .55]\n    MIN_PIXELS = [75, 150, 75]","1676329e":"# From https:\/\/www.kaggle.com\/stainsby\/fast-tested-rle\ndef rle_decode(mask_rle, shape=(520, 704)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)  # Needed to align to RLE direction\n\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef get_masks(fn, predictor):\n    im = cv2.imread(str(fn))\n    pred = predictor(im)\n    pred_class = torch.mode(pred['instances'].pred_classes)[0]\n    take = pred['instances'].scores >= CFG.THRESHOLDS[pred_class]\n    pred_masks = pred['instances'].pred_masks[take]\n    pred_masks = pred_masks.cpu().numpy()\n    res = []\n#    mat = []\n    used = np.zeros(im.shape[:2], dtype=int) \n    for mask in pred_masks:\n        mask = mask * (1-used)\n        if mask.sum() >= CFG.MIN_PIXELS[pred_class]: \n            used += mask\n#            mat.append(mask)\n            res.append(rle_encode(mask))\n    return res\n\n# def get_masks(fn, predictor):\n#     im = cv2.imread(str(fn))\n#     outputs = predictor(im)\n#     pred_masks = outputs['instances'].pred_masks.cpu().numpy()\n#     res = []\n#     used = np.zeros(im.shape[:2], dtype=int) # to remove overlaps\n#     for mask in pred_masks:\n#         mask = mask * (1-used)\n#         used += mask\n#         res.append(rle_encode(mask))\n#     return res\n","046733ae":"# Taken from\ndef compute_iou(labels, y_pred):\n    \"\"\"\n    Computes the IoU for instance labels and predictions.\n\n    Args:\n        labels (np array): Labels.\n        y_pred (np array): predictions\n\n    Returns:\n        np array: IoU matrix, of size true_objects x pred_objects.\n    \"\"\"\n\n    true_objects = len(np.unique(labels))\n    pred_objects = len(np.unique(y_pred))\n\n    # Compute intersection between all objects\n    intersection = np.histogram2d(\n        labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects)\n    )[0]\n\n    # Compute areas (needed for finding the union between all objects)\n    area_true = np.histogram(labels, bins=true_objects)[0]\n    area_pred = np.histogram(y_pred, bins=pred_objects)[0]\n    area_true = np.expand_dims(area_true, -1)\n    area_pred = np.expand_dims(area_pred, 0)\n\n    # Compute union\n    union = area_true + area_pred - intersection\n    iou = intersection \/ union\n    \n    return iou[1:, 1:]  # exclude background\n\ndef precision_at(threshold, iou):\n    \"\"\"\n    Computes the precision at a given threshold.\n\n    Args:\n        threshold (float): Threshold.\n        iou (np array): IoU matrix.\n\n    Returns:\n        int: Number of true positives,\n        int: Number of false positives,\n        int: Number of false negatives.\n    \"\"\"\n    matches = iou > threshold\n    true_positives = np.sum(matches, axis=1) == 1  # Correct objects\n    false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n    false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n    tp, fp, fn = (\n        np.sum(true_positives),\n        np.sum(false_positives),\n        np.sum(false_negatives),\n    )\n    return tp, fp, fn\n\n\ndef iou_map(truths, preds, verbose=0):\n    \"\"\"\n    Computes the metric for the competition.\n    Masks contain the segmented pixels where each object has one value associated,\n    and 0 is the background.\n\n    Args:\n        truths (list of masks): Ground truths.\n        preds (list of masks): Predictions.\n        verbose (int, optional): Whether to print infos. Defaults to 0.\n\n    Returns:\n        float: mAP.\n    \"\"\"\n    ious = [compute_iou(truth, pred) for truth, pred in zip(truths, preds)]\n\n    if verbose:\n        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n\n    prec = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        tps, fps, fns = 0, 0, 0\n        for iou in ious:\n            tp, fp, fn = precision_at(t, iou)\n            tps += tp\n            fps += fp\n            fns += fn\n\n        p = tps \/ (tps + fps + fns)\n        prec.append(p)\n\n        if verbose:\n            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tps, fps, fns, p))\n\n    if verbose:\n        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n\n    return np.mean(prec)","3003b107":"cfg = get_cfg()\ncfg.merge_from_file(model_zoo.get_config_file('COCO-InstanceSegmentation\/' + CFG.model_arch))\ncfg.INPUT.MASK_FORMAT='bitmask'\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 3 \ncfg.MODEL.WEIGHTS = os.path.join(CFG.model_folder, 'model_f'+str(CFG.wfold)+'.pth')  \ncfg.TEST.DETECTIONS_PER_IMAGE = 1000\npredictor = DefaultPredictor(cfg)\n","fb5d618c":"# RLE for ground truth\nxdat = pd.read_csv('..\/input\/sartorius-annotations\/gt_fold.csv')\nxdat = xdat.loc[xdat.fold == CFG.wfold][['id', 'annotation']].copy()\n\nrle_gt = xdat['annotation'].copy()\nids_gt = xdat['id'].copy()\n\nprint(len(rle_gt), len(ids_gt))\nvalid_names = ids_gt.unique()\n\n\n# RLE for validation set\nids_valid, rle_valid = [], []\n\nfor fn in valid_names:    \n    rles = get_masks(CFG.data_folder + 'train\/' + fn + '.png', predictor)\n    for enc in rles:\n        ids_valid.append(fn)\n        rle_valid.append(enc)\n        \nprint(len(rle_valid), len(ids_valid))\n\n\n# RLE for test set\nids_test, rle_test = [] , []\ntest_names = [f[:-4] for f in os.listdir(CFG.data_folder + 'test')]\n\nfor fn in test_names:\n    rles = get_masks(CFG.data_folder + 'test\/' + fn + '.png', predictor)\n    for enc in rles:\n        ids_test.append(fn)\n        rle_test.append(enc)\n\nprint(len(rle_test), len(ids_test))\n  ","c7db3715":"# translate to masks\nmasks_valid, masks_gt = [], []\n\nfor (ii,rl) in enumerate(rle_valid): \n    m = rle_decode(rl)\n    masks_valid.append(m * ii)\n    \nfor (ii,rl) in enumerate(rle_gt): \n    m = rle_decode(rl)\n    masks_gt.append(m * ii)\n    ","8885d474":"# aggregate \nmasks_valid_agg = pd.DataFrame()\nmasks_valid_agg['id'] = ids_valid\nmasks_valid_agg['masks'] = masks_valid\nmasks_valid_agg = masks_valid_agg.groupby('id').max().reset_index()\n\nmasks_gt_agg = pd.DataFrame()\nmasks_gt_agg['id'] = ids_gt\nmasks_gt_agg['masks'] = masks_gt\nmasks_gt_agg = masks_gt_agg.groupby('id').max().reset_index()\n\n# plt.imshow(masks_valid_agg.masks[0])","6acc925b":"# muh_iou = compute_iou(masks_gt_agg['masks'][0], masks_valid_agg['masks'][0])\n# precision_at(0.5, muh_iou)\n#iou_map(masks_gt_agg['masks'] , masks_gt_agg['masks'], verbose=1)  # This should score 1","d768f8fc":"iou_map(masks_gt_agg['masks'] , masks_valid_agg['masks'], verbose=1) ","653801e0":"pd.DataFrame({'id': ids_test, 'predicted': rle_test}).to_csv('submission.csv', index=False)","7e108d97":"# Data\n\nLoad the weights from a previously fitted model - R50 architecture, 10k iterations,  MaP IoU=0.2554","f0efd526":"Convert RLE for gt \/ validation into masks","7c2f499c":"# Evaluation ","7f73f890":"Get RLE for validation set, ground truth for validation set and RLE for the test set","183b312c":"Calculate the metric:","8c876f2b":"# Functions","caed361f":"# Submission","791dca14":"Combine the masks per file"}}