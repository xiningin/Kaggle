{"cell_type":{"463aed3f":"code","358e166a":"code","24f1bdc2":"code","fb094408":"code","4309d0a5":"code","1ee45a47":"code","8e825ec7":"code","2888aefc":"code","d97846ba":"code","c76ef835":"code","3e7bc53e":"code","8556ff03":"code","fd953bf3":"code","019d8619":"code","8775a48c":"code","bada0816":"code","dde47199":"code","33807a0a":"code","7eb7dcea":"code","843b7d27":"code","fcebe01c":"code","21dd3d8b":"code","16a7e0b7":"markdown","3f435077":"markdown","aada1aa2":"markdown","2633bd67":"markdown"},"source":{"463aed3f":"!pip install pytorch-tabnet -q","358e166a":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline\nfrom colorama import Fore, Back, Style\nimport seaborn as sns\ny_ = Fore.YELLOW\nr_ = Fore.RED\ng_ = Fore.GREEN\nb_ = Fore.BLUE\nm_ = Fore.MAGENTA\nc_ = Fore.CYAN\nsr_ = Style.RESET_ALL\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.style.use('fivethirtyeight')\n\nfrom lightgbm import LGBMRegressor\nfrom pytorch_tabnet.tab_model import TabNetRegressor\nfrom xgboost import XGBRegressor\nfrom pytorch_tabnet.metrics import Metric\nfrom sklearn.metrics import mean_squared_error\nimport os\nfigsize=10,4\nuse_lgb = False\nuse_xgb = True\nuse_tabnet = False","24f1bdc2":"train = pd.read_csv('\/kaggle\/input\/tabular-playground-series-feb-2021\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tabular-playground-series-feb-2021\/test.csv')\nsub = pd.read_csv('\/kaggle\/input\/tabular-playground-series-feb-2021\/sample_submission.csv')","fb094408":"train.head()","4309d0a5":"test.head()","1ee45a47":"sub.head()","8e825ec7":"target = 'target' ","2888aefc":"print(f'{y_}rows: {c_}{train.shape[0]} {y_}columns; {c_}{train.shape[1]}')\nprint(f\"{y_}categorical: {c_}{len(train.select_dtypes(include='object').columns)}, {y_}numerical: {c_}{len(train.select_dtypes(include=np.float64).columns)}\")\nprint(f'{y_}percent of null\\n{c_}{train.isna().mean() * 100} ')","d97846ba":"def plot_continous(df=train, feature_name='cont0'):\n    \"\"\" plots continous variables foe the given dataframe\n        df: pandas dataframe\n        feature_name: name of column\n    \"\"\"\n    fig= plt.figure(figsize=figsize,linewidth=10, edgecolor=\"#04253a\", )\n    fig.suptitle(f'plot continous feature: {feature_name}')\n    plt.subplot(221)\n    sns.distplot(df[feature_name] )\n\n    plt.subplot(222)\n    sns.boxplot(x=df[feature_name])\n\n    plt.subplot(223)\n    sns.histplot(df[feature_name] )\n    plt.rcParams[\"axes.grid\"] = True\n\n    plt.show()\n    ","c76ef835":"for i in range(14):\n    plot_continous(train, f'cont{i}')","3e7bc53e":"def plot_categorical_feature(df=train, feature_name='cat0'):\n    cats = df[feature_name].unique().tolist()\n    data = df[feature_name].value_counts().tolist()\n\n    explode = [x\/10 for x  in range(len(data))]\n\n    colors = ( \"pink\", \"cyan\", \"brown\", \n              \"grey\", \"indigo\", \"beige\") \n\n\n    wp = { 'linewidth' : 1, 'edgecolor' : \"green\" } \n\n\n    def func(pct, allvalues): \n        absolute = int(pct \/ 100.*np.sum(allvalues)) \n        return \"{:.1f}%\\n{:d}\".format(pct, absolute) \n\n\n    fig, ax = plt.subplots(figsize =(10, 7)) \n    wedges, texts, autotexts = ax.pie(data,  \n                                      autopct = lambda pct: func(pct, data), \n                                      explode = explode,  \n                                      labels = cats, \n                                      shadow = True, \n                                      colors = colors, \n                                      startangle = 90, \n                                      wedgeprops = wp, \n                                      textprops = dict(color =\"black\")) \n\n\n    ax.legend(wedges, cats, \n              title =\"categorical plot\", \n              loc =\"center left\", \n              bbox_to_anchor =(1, 0, 0.5, 1)) \n\n    plt.setp(autotexts, size = 8, weight =\"bold\") \n    ax.set_title(f\"pie chart for {feature_name}\") \n\n    plt.show() ","8556ff03":"for i in range(10):\n    plot_categorical_feature(train, f'cat{i}')","fd953bf3":"for feature in train.select_dtypes(include='object').columns.tolist():\n    le = LabelEncoder()\n    le.fit(train[feature])\n    train[feature] = le.transform(train[feature])\n    test[feature] = le.transform(test[feature])","019d8619":"X = train.drop(['id', target], axis=1)\ny = train[target]\ntx = test[X.columns]","8775a48c":"lgb =  LGBMRegressor()\nxgb = XGBRegressor()","bada0816":"lgb.fit(X,y)","dde47199":"xgb.fit(X.values,y.values)","33807a0a":"clf = TabNetRegressor()   ","7eb7dcea":"X_train, X_test, Y_train, Y_test = train_test_split(X, y )","843b7d27":"clf.fit(\n\n        X_train=X_train.values, y_train=Y_train.values.reshape(-1,1),\n        eval_set=[(X_train.values, Y_train.values.reshape(-1,1)), (X_test.values,Y_test.values.reshape(-1,1))],\n        eval_name=['train', 'valid'],\n        eval_metric=[ 'rmse'],\n        max_epochs=20,\n        patience=50,\n        batch_size=1024, virtual_batch_size=128,\n        num_workers=0,\n\n    )","fcebe01c":"sub = pd.DataFrame()\nsub['id'] = test.id.values\nif use_lgb:\n    sub['target'] = lgb.predict(tx)\nif use_xgb:\n    sub['target'] = xgb.predict(tx.values)\nif use_tabnet:\n    sub['target'] = clf.predict(tx.values)\nsub.head()","21dd3d8b":"sub.to_csv('submission2.csv', index=False)","16a7e0b7":"# Submission","3f435077":"# Continous feature analysis","aada1aa2":"# Preprocessing","2633bd67":"# Load Data"}}