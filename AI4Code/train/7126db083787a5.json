{"cell_type":{"c497a7b4":"code","2931c3ca":"code","916e26a3":"code","82a7a51e":"code","b0d717e5":"code","757d5a75":"code","d9e3f100":"code","6f0e1a94":"code","77613225":"code","b7bb88ab":"code","5a1e6e17":"code","9b304a21":"code","c631c770":"code","e3c1eafc":"code","65423fcd":"code","ef090ad9":"code","8c555d8f":"code","c3398002":"code","9a0841ab":"code","0fcbf361":"code","ac98beaa":"code","33d2287b":"code","9b47d183":"code","9ecba001":"code","8125e01b":"code","c9687684":"code","e6ad489f":"code","2c2b8843":"code","0e2a8bd6":"code","7a319a71":"code","ada519f8":"code","e8a94f68":"code","92f34d91":"code","e4dab246":"code","b37d3b54":"code","af190229":"code","95c1170f":"code","859200ba":"code","244aacfd":"code","07dacdea":"code","c2c7a65e":"code","5b651cc2":"code","b9ade490":"code","a89166de":"code","8d2341d1":"code","d32ef49d":"code","a6827e63":"code","cfc1a873":"code","12798d47":"code","64a746b0":"code","9ee801e2":"code","bdabf43d":"code","b080b997":"markdown","46a42928":"markdown","10ac46e0":"markdown","9230ed0f":"markdown","99162877":"markdown","d62aedfa":"markdown","c6eaee84":"markdown","b973eda2":"markdown","ce490c7e":"markdown","f771d33b":"markdown","cffecaa3":"markdown","9076b880":"markdown"},"source":{"c497a7b4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport seaborn as sn\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_score, recall_score\nfrom sklearn.ensemble import ExtraTreesClassifier\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2931c3ca":"!pip install openpyxl","916e26a3":"import pandas as pd\ndata = pd.read_excel(\"..\/input\/covid19\/dataset.xlsx\", engine=\"openpyxl\")\ndata","82a7a51e":"print(data)","b0d717e5":"corr_matrix = data.corr().abs()\nprint(corr_matrix)","757d5a75":"corrMatrix = data.corr()\nsn.heatmap(corrMatrix, annot=True)\nplt.show()\n","d9e3f100":"from sklearn import preprocessing\n \n# label_encoder object knows how to understand word labels.\nlabel_encoder = preprocessing.LabelEncoder()\n \n# Encode labels in column 'species'.\ndata['SARS-Cov-2 exam result']= label_encoder.fit_transform(data['SARS-Cov-2 exam result'])\n \ndata['SARS-Cov-2 exam result'].unique()","6f0e1a94":"data.head()","77613225":"data.columns = [x.lower().strip().replace(' ','_') for x in data.columns]\n","b7bb88ab":"def miss_data(x):\n    total = x.isnull().sum()\n    percent = (x.isnull().sum()\/x.isnull().count()*100)\n    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    types = []\n    for col in data.columns:\n        dtype = str(x[col].dtype)\n        types.append(dtype)\n    tt['Types'] = types\n    return(np.transpose(tt))","5a1e6e17":"miss_data(data)","9b304a21":"for x in data.columns:\n    if data[x].dtype=='float16' or  data[x].dtype=='float32' or  data[x].dtype=='float64':\n        data[x].fillna(data[x].mean())\n\ndata = data.fillna(-999)\n\nfor y in data.columns:\n    if data[y].dtype=='object': \n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(data[y].values))\n        data[y] = lbl.transform(list(data[y].values))","c631c770":"threshold = 0.92\n\ncorr_matrix = data.corr().abs()\n\n\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\nupper.head()","e3c1eafc":"to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n\nprint('There are %d columns to remove.' % (len(to_drop)))\ndataset = data.drop(columns = to_drop)","65423fcd":"data.head()\n","ef090ad9":"data_missing = (data.isnull().sum() \/ len(data)).sort_values(ascending = False)\ndata_missing.head()","8c555d8f":"data.isnull().sum()","c3398002":"data.replace({-np.inf: -1_000_000, np.inf: 1_000_000}, inplace=True)","9a0841ab":"data_missing_ = data_missing.index[data_missing > 0.85]\nall_missing = list(set(data_missing_))\n\n\ndataset = dataset.drop(columns = all_missing)","0fcbf361":"dataset.info()","ac98beaa":"cols = [x for x in dataset.columns if x not in ['patient_id','SARS-Cov-2_exam_result', 'patient_addmited_to_regular_ward_(1=yes,_0=no)', 'patient_addmited_to_semi-intensive_unit_(1=yes,_0=no)', 'patient_addmited_to_intensive_care_unit_(1=yes,_0=no)']]\nnew_df = dataset[cols]\nnew_df","33d2287b":"data.columns","9b47d183":"data_missing.head(10)","9ecba001":"X = new_df\ny = dataset['sars-cov-2_exam_result']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=101)","8125e01b":"model = ExtraTreesClassifier()\nmodel.fit(X,y)\nprint(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n#plot graph of feature importances for better visualization\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(10).plot(kind='barh')\nplt.show()","c9687684":"feat_head = feat_importances.head(10)\nfeat_head.index","e6ad489f":"data.fillna(data.mean(), inplace=True)","2c2b8843":"data.replace([np.inf, -np.inf], np.nan, inplace=True)","0e2a8bd6":"'patient_id','SARS-Cov-2_exam_result', 'patient_addmited_to_regular_ward_(1=yes,_0=no)', 'patient_addmited_to_semi-intensive_unit_(1=yes,_0=no)', 'patient_addmited_to_intensive_care_unit_(1=yes,_0=no)'","7a319a71":"from statsmodels.stats.outliers_influence import variance_inflation_factor\n  \nX = data[['patient_id','sars-cov-2_exam_result', 'patient_addmited_to_regular_ward_(1=yes,_0=no)', 'patient_addmited_to_semi-intensive_unit_(1=yes,_0=no)', 'patient_addmited_to_intensive_care_unit_(1=yes,_0=no)']]  \nvif_data = pd.DataFrame()\nvif_data[\"feature\"] = X.columns\n  \n# calculating VIF for each feature\nvif_data[\"VIF\"] = [variance_inflation_factor(X.values, i)\n                          for i in range(len(X.columns))]\n  \nprint(vif_data)","ada519f8":"newdf = new_df[feat_head.index]\n\nX = newdf\ny = dataset['sars-cov-2_exam_result']\nX\nvif = pd.DataFrame()\nvif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif[\"features\"] = X.columns","e8a94f68":"feat_head = feat_importances.head(10)\nfeat_head.index","92f34d91":"newdf = new_df[feat_head.index]\n\nX = newdf\ny = dataset['sars-cov-2_exam_result']\nX","e4dab246":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 101)","b37d3b54":"X = new_df[feat_head.index]\ny = dataset['sars-cov-2_exam_result']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 101)\n","af190229":"accuracy_lst =[]\n\ndef model_assess(model, name='Default'):\n    model.fit(X_train, y_train)\n    prds = model.predict(X_test)\n    model_acc = accuracy_score(y_test, prds)\n    accuracy_lst.append(100*model_acc)\n    print('---', name, '---', '\\n',\n          confusion_matrix(y_test, prds), '\\n',\n          'Accuracy:', (accuracy_score(y_test, prds)), '\\n',\n          'Classification Report:', (classification_report(y_test, prds)))","95c1170f":"# Logistic Regression\nlg = LogisticRegression()\nmodel_assess(lg, 'Logistic Regression')\nlg.fit(X_train,y_train)","859200ba":"# SVM\nsvm = SVC()\nmodel_assess(svm, 'SVM')\nsvm.fit(X_train,y_train)","244aacfd":"cross_acc = []\n\nca_lg = cross_val_score(lg, X_train, y_train, scoring='accuracy')\nca_lg = ca_lg.mean()\ncross_acc.append(100*ca_lg)\n\n\n\nca_svm = cross_val_score(svm, X_train, y_train, scoring='accuracy')\nca_svm = ca_svm.mean()\ncross_acc.append(100*ca_svm)\n\n","07dacdea":"lg.predict(X_test)","c2c7a65e":"svm.predict(X_test)","5b651cc2":"from sklearn.ensemble import GradientBoostingClassifier","b9ade490":"model1=GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1)\n","a89166de":"model1.fit(X_train, y_train)\n","8d2341d1":"y_pred=model1.predict(X_train)\n","d32ef49d":"rforest = RandomForestClassifier(n_estimators=1000, max_depth=10, random_state=0)\nmodel_assess(rforest, 'Random Forest')","a6827e63":"ca_rforest = cross_val_score(rforest, X_train, y_train, scoring='accuracy')\nca_rforest = ca_rforest.mean()\ncross_acc.append(100*ca_rforest)","cfc1a873":"xgb = XGBClassifier(n_estimators=1000, learning_rate=0.05)\nmodel_assess(xgb, 'XGBoost')","12798d47":"cross_acc = []\nca_xgb = cross_val_score(xgb, X_train, y_train, scoring='accuracy')\nca_xgb = ca_xgb.mean()\ncross_acc.append(100*ca_xgb)","64a746b0":"lg = LogisticRegression()\nmodel_assess(lg, 'Logistic Regression')","9ee801e2":"rforest = RandomForestClassifier(n_estimators=1000, max_depth=10, random_state=0)\nmodel_assess(rforest, 'Random Forest')","bdabf43d":"# SVM\nsvm = SVC()\nmodel_assess(svm, 'SVM')\nsvm.fit(X_train,y_train)","b080b997":"# Null Value Replacement","46a42928":"# XG Boost","10ac46e0":"# Logistic Regression And SVM","9230ed0f":"### Dataset with the most important factors having impact on result","99162877":"# Random Forest","d62aedfa":"# Correlation Matrix","c6eaee84":"# VIF","b973eda2":"# Drop missing columns","ce490c7e":"### Data Split","f771d33b":"# Covid prediction from blood data sample","cffecaa3":"### Import Libraries and Data","9076b880":"# Accuracy of LR, SVM, XG Boost, and Random Forest"}}