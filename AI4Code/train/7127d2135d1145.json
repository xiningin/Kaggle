{"cell_type":{"4eff7668":"code","e72925fb":"code","c83d7855":"code","2b0caf11":"code","915151be":"code","7724bb9a":"code","c4b2f63c":"code","b843a916":"code","0f71405f":"code","800c86f6":"code","9234391b":"code","6f2496d3":"code","d94b1e05":"code","b1d7d618":"code","12e9b4c5":"code","640b9cf8":"code","56af4ea2":"code","e5e0fe14":"code","2da83d27":"markdown","6d21dae9":"markdown","c6a1aab6":"markdown","71c69986":"markdown"},"source":{"4eff7668":"import os\nimport cv2\nimport torch\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom ast import literal_eval\n","e72925fb":"BASE_PATH = '..\/input\/shopee-product-matching\/train_images'\n\ndevice = device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","c83d7855":"oof = pd.read_csv(\"..\/input\/shopee-oofs\/eff_b0_oof.csv\")","2b0caf11":"oof['preds'] = oof.preds.apply(lambda x: literal_eval(str(x)))\noof['preds2'] = oof.preds2.apply(lambda x: literal_eval(str(x)))\noof['preds3'] = oof.preds3.apply(lambda x: literal_eval(str(x)))\n\n\noof['oof'] = oof['oof'].apply(lambda x: \", \".join(x.split(\" \")))\noof['target'] = oof['target'].apply(lambda x: \", \".join(x.split(\" \")))\n\noof['oof'] = oof.oof.apply(lambda x: literal_eval(str(x)))\noof['target'] = oof.target.apply(lambda x: literal_eval(str(x)))","915151be":"def display_images(imgs): \n    f, ax = plt.subplots(1,len(imgs), figsize=(20,5))\n    \n    for index, (i, row) in enumerate(imgs.iterrows()) :                \n        image = cv2.imread(f\"{BASE_PATH}\/{row.image}\")\n        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n    \n        ax[index].imshow(image) \n        ax[index].axis('off') \n                \n        brand = row.posting_id\n        \n        \n        title_len = 30\n        if len(imgs) > 5:\n            title_len = 10\n        \n        ax[index].set_title(f\"{brand}\\n{row.title[:title_len]}\", fontsize=\"12\")\n    plt.show() ","7724bb9a":"def fetch_results(row):\n    \n    if len(row.target) < 10 and (len(row.oof) > 1 and len(row.oof) < 10):\n        print(\"Query Image (posting_id): \", row.posting_id)\n        image = cv2.imread(f\"{BASE_PATH}\/{row.image}\")\n        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)        \n        plt.imshow(image) \n\n        targets = oof.loc[oof.posting_id.isin(row.target)]\n        preds = oof.loc[oof.posting_id.isin(row.oof)]\n\n        print(\"target images: \", len(targets))\n        display_images(targets)\n\n        print(\"predicted images: \", len(preds))\n        display_images(preds)","c4b2f63c":"miss_df = oof.loc[oof.f1 < 0.6]","b843a916":"fetch_results(miss_df.iloc[0])","0f71405f":"fetch_results(miss_df.iloc[1])","800c86f6":"fetch_results(miss_df.iloc[7])","9234391b":"fetch_results(miss_df.iloc[11])","6f2496d3":"fetch_results(miss_df.iloc[19])","d94b1e05":"fetch_results(miss_df.iloc[27])","b1d7d618":"fetch_results(miss_df.iloc[36])","12e9b4c5":"fetch_results(miss_df.iloc[43])","640b9cf8":"fetch_results(miss_df.iloc[67])","56af4ea2":"fetch_results(miss_df.iloc[69])","e5e0fe14":"fetch_results(miss_df.iloc[71])","2da83d27":"## Above shown examples are just few for demonstration, actual number of noisy labels is much bigger.","6d21dae9":"## Taking rows where f1 score is less than 0.6","c6a1aab6":"## Few Examples where target labels are not fully correct and label predicted from model make much more sense ","71c69986":"### As you all may know by now, CV and LB are not very well correlated for this competition, in order to investigate this further, i tried analyzing where my model predictions went wrong.\n"}}