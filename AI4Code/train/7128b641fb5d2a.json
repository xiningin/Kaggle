{"cell_type":{"6209ae56":"code","e41b2a0a":"code","6087ac7a":"code","b83f1be4":"code","d5415ff2":"code","20d663c6":"code","bb1ac36c":"code","0a6e7094":"code","67f26a3a":"code","73612476":"code","bff0ebc0":"code","3cb1c436":"code","ec005e8b":"code","bb8d9574":"code","81bdbd84":"code","b31b51c8":"code","667e9d7f":"code","1ad7a743":"code","cb49ced1":"code","d193f45d":"code","549c1400":"code","301ed282":"code","8598e2c7":"code","a3f7c8f3":"code","f6b7a359":"code","65634e26":"code","8524dbcd":"markdown","097a921a":"markdown","bb66d1bb":"markdown","9513c73d":"markdown","76835ce1":"markdown","54b8889e":"markdown","87dcbc3c":"markdown"},"source":{"6209ae56":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport math\nfrom sklearn.preprocessing import MinMaxScaler\n\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e41b2a0a":"# Read CSV file into DataFrame df\ndf = pd.read_csv('\/kaggle\/input\/in-hospital-mortality-prediction\/data01.csv', index_col=0)\n# Show dataframe\ndf","6087ac7a":"df['outcome'].value_counts().plot(kind='bar', title='Frequency of Heart Failures', xlabel='Heart Failure', ylabel='frequency')","b83f1be4":"import missingno\n# missing value visualisation\nmissingno.bar(df, figsize=(10,5), fontsize=12);","d5415ff2":"# One outcome value to nan: to delete\n# drop rows\n# from dataFrame where outcome is nan\ndf = df.dropna(subset=['outcome'])\ndf = df.reset_index(drop=True)","20d663c6":"# Average Age of non-surviving patients \ndeads = df[df.outcome == 1]\nprint(np.mean(deads.age))","bb1ac36c":"corr = df.corr(method = 'kendall')\ncorrabs = corr.iloc[0,:].map(abs)\ncorr.plot.bar().legend(loc='center left',bbox_to_anchor=(2.0, 1.0))","0a6e7094":"import seaborn as sns\ncorrelation = corr\nplt.figure(figsize=(40,40))\nsns.heatmap(correlation, vmax=1, square=True,annot=True,cmap='viridis')\n\nplt.title('Correlation between different features')","67f26a3a":"df['outcome'].plot(kind='hist', legend=None, bins=100)","73612476":"# create features (data to train)\n\nfeatures = df.iloc[:, 2:]\n\n# Eliminate Nan values\nfrom sklearn.impute import KNNImputer\nimputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\nX_impute = imputer.fit_transform(features)\n\nfrom sklearn.preprocessing import StandardScaler\nX_scale = StandardScaler().fit_transform(X_impute)\nX = X_scale","bff0ebc0":"# create the labels (ground truth)\nlabels = df['outcome']\ny = np.ravel(labels)","3cb1c436":"# creating train and test data\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.33, random_state = 42)","ec005e8b":"# weight the two classes because of unbalanced data \nfrom collections import Counter\n\nnum_patients = df.shape[0]\ndicto = labels.value_counts().to_dict()\ncounter = Counter(dicto)\nmax_val = float(max(counter.values()))\nclass_weight = {class_id : max_val\/num_patients for class_id, num_patients in counter.items()}\nprint(class_weight)","bb8d9574":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n#instanciation of the decision tree\nmodel = DecisionTreeClassifier(class_weight = class_weight)","81bdbd84":"#train the model\nmodel.fit(X_train, y_train)","b31b51c8":"# get the models predicted outcome (death)\ny_predictions = (model.predict(X_test) > 0.5).astype(\"int32\")","667e9d7f":"score = model.score(X_test, y_test)\nscore","1ad7a743":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_predictions))","cb49ced1":"from sklearn.metrics import confusion_matrix\n\nnumber_train = 30\nsumm = 0\nsum_mat = np.zeros((2,2))\nfor seed in range(number_train):\n    # split traing and test data in two subsets\n    X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.33, random_state = seed)\n\n    #instanciation of the decision tree\n    model = RandomForestClassifier(max_depth=8, random_state=seed, class_weight=class_weight)\n\n    #train the model\n    model.fit(X_train, y_train)\n\n    # get the models predicted outcome\n    y_predictions = model.predict(X_test)\n    score = model.score(X_test, y_test)\n    sum_mat += confusion_matrix(y_test, y_predictions)\n    summ += score\n\nprint('accuracy: ' + str(summ\/number_train))\nprint(\"Confusion matrix:\")\nprint(np.round_(sum_mat\/number_train))","d193f45d":"from sklearn.metrics import confusion_matrix\nclasses_str = {0.0, 1.0}\nconf_mat = np.round_(sum_mat\/number_train)\n\ndef print_conf_mat(conf_mat, classes_str):\n    # Creating a dataframe for a array-formatted Confusion matrix,so it will be easy for plotting.\n    cm_df = pd.DataFrame(conf_mat,\n                         index = classes_str, \n                         columns = classes_str)\n    import seaborn as sns\n    #Plotting the confusion matrix\n    plt.figure(figsize=(5,4))\n    sns.heatmap(cm_df, annot=True)\n    plt.title('Confusion Matrix')\n    plt.ylabel('Actual Values')\n    plt.xlabel('Predicted Values')\n    plt.show()\nprint_conf_mat(conf_mat, classes_str)","549c1400":"col = ['age', 'gendera', 'BMI', 'hypertensive',\n       'atrialfibrillation', 'CHD with no MI', 'diabetes', 'deficiencyanemias',\n       'depression', 'Hyperlipemia', 'Renal failure', 'COPD', 'heart rate',\n       'Systolic blood pressure', 'Diastolic blood pressure',\n       'Respiratory rate', 'temperature', 'SP O2', 'Urine output',\n       'hematocrit', 'RBC', 'MCH', 'MCHC', 'MCV', 'RDW', 'Leucocyte',\n       'Platelets', 'Neutrophils', 'Basophils', 'Lymphocyte', 'PT', 'INR',\n       'NT-proBNP', 'Creatine kinase', 'Creatinine', 'Urea nitrogen',\n       'glucose', 'Blood potassium', 'Blood sodium', 'Blood calcium',\n       'Chloride', 'Anion gap', 'Magnesium ion', 'PH', 'Bicarbonate',\n       'Lactic acid', 'PCO2', 'EF']\nX_t = pd.DataFrame(data = X_train, columns=col )","301ed282":"import shap\nshap_values = shap.TreeExplainer(model).shap_values(X_train)\nshap.summary_plot(shap_values, X_t, plot_type=\"bar\")","8598e2c7":"# Get the predictions and put them with the test data.\nX_output = pd.DataFrame(data = X_test, columns=col )\nX_output.loc[:,'predict'] = np.round(model.predict(X_output),2)\n\n# Randomly pick some observations\nrandom_picks = np.arange(1,389,50) # Every 50 rows\nS = X_output.iloc[random_picks]\nS\n","a3f7c8f3":"shap.initjs()\ndef shap_plot(j):\n    explainerModel = shap.TreeExplainer(model)\n    shap_values = explainerModel.shap_values(S.iloc[j,:-1])\n    #p = shap.force_plot(explainerModel.expected_value, shap_values_Model[j], S.iloc[[j]])\n    p = shap.force_plot(explainerModel.expected_value[j], shap_values[j], feature_names=col)\n    return(p)","f6b7a359":"# shap value for a prediction of survival (0.0)\nshap_plot(0)","65634e26":"# shap value for a prediction of Heart Failure (1.0)\nshap_plot(1)","8524dbcd":"**MLP**","097a921a":"**DECISION TREE**","bb66d1bb":"THE DECISION TREE GIVES A BETTER PREDICTION THAN OUR INITIAL NEURAL NETWORK : ~80% instead of ~40%","9513c73d":"**DEAL WITH NAN**","76835ce1":"Confusion Matrix for binary classification problems has the below-mentioned structure.\n\n[[TN, FP ]\n\n [FN, TP ]]\n\n* TN refers to True Negative which is the count of labels which were originally belonged to negative class and model also predicted them as negative.\n* FP refers to False positive which is the count of labels which were actually belonged to negative class but model predicted them as positive.\n* FN refers to False Negative which is the count of labels which were actually belonged to Positive Class but model predicted them as negative.\n* TP refers to True Positive which is the count of labels predicted positive which were actually positive.","54b8889e":"**DEATH PREDICT**\n\n*Predicting heart failure in hospital ICU (Intensive car Unit)*","87dcbc3c":"**we can see that 13% of all patients died of heart failure during the study, which is not evenly balanced**"}}