{"cell_type":{"6153363b":"code","0e67f3ce":"code","082dd930":"code","02749ab5":"code","9b02b027":"code","eb183a43":"code","5d27dda0":"code","7518d084":"code","330d414a":"code","83f3d5af":"code","af5c6ddc":"code","772d109a":"code","973badcc":"code","2b3f3d9c":"code","85ae861b":"code","09450dd1":"code","3c044627":"code","8c4204c7":"code","0fdc90d2":"markdown","82437bf6":"markdown","a8c5d655":"markdown","23824b1f":"markdown","ec92948c":"markdown","8b6790d5":"markdown","37d6dad9":"markdown","8fa865e3":"markdown","9156d563":"markdown","72b1e0a7":"markdown","c89ad648":"markdown","78f0a3e0":"markdown","aaeb9c60":"markdown","22e82663":"markdown","c79849f5":"markdown","4763e7ef":"markdown","cfb5fab4":"markdown","448de9e6":"markdown"},"source":{"6153363b":"import warnings\nwarnings.filterwarnings('ignore')","0e67f3ce":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport re\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nimport plotly.graph_objs as go\nfrom plotly.offline import iplot\n\nimport cufflinks\ncufflinks.go_offline()\ncufflinks.set_config_file(world_readable=True, theme='pearl')","082dd930":"df = pd.read_csv(\"..\/input\/cyberbullying-classification\/cyberbullying_tweets.csv\")\ndf.head()","02749ab5":"# twitter text cleaning pattern from https:\/\/www.kaggle.com\/paoloripamonti\/twitter-sentiment-analysis\n\nTEXT_CLEANING_RE = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n\nfrom wordcloud import STOPWORDS\nSTOPWORDS.update(['rt', 'mkr', 'didn', 'bc', 'n', 'm', 'im', 'll', 'y', 've', 'u', 'ur', 'don', 't', 's'])\n\ndef lower(text):\n    return text.lower()\n\ndef remove_twitter(text):\n    return re.sub(TEXT_CLEANING_RE, ' ', text)\n\ndef remove_stopwords(text):\n    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n\ndef clean_text(text):\n    text = lower(text)\n    text = remove_twitter(text)\n    text = remove_stopwords(text)\n    return text","9b02b027":"def get_top_n_gram(corpus,ngram_range,n=None):\n    vec = CountVectorizer(ngram_range=ngram_range,stop_words = STOPWORDS).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]","eb183a43":"df['tweet_text']=df['tweet_text'].apply(clean_text)","5d27dda0":"from nltk.stem import WordNetLemmatizer\n\nlematizer=WordNetLemmatizer()\n\ndef lemmatizer_words(text):\n    return \" \".join([lematizer.lemmatize(word) for word in text.split()])\n\ndf['tweet_text']=df['tweet_text'].apply(lambda text: lemmatizer_words(text))","7518d084":"df.cyberbullying_type.unique()","330d414a":"from wordcloud import WordCloud\n\nplt.figure(figsize=(20,10))\nsubset1 = df[df['cyberbullying_type']=='gender']\ntext_gender = subset1.tweet_text.values\ncloud1=WordCloud(background_color='black',colormap=\"Dark2\",collocations=False,width=2000,height=1000).generate(\" \".join(text_gender))\n\nplt.axis('off')\nplt.title(\"Gender\",fontsize=40)\nplt.imshow(cloud1)","83f3d5af":"unigrams = get_top_n_gram(text_gender,(1,1),10)\nbigrams = get_top_n_gram(text_gender,(2,2),10)\n\ngender_1 = pd.DataFrame(unigrams, columns = ['Text' , 'count'])\ngender_1.groupby('Text').sum()['count'].sort_values(ascending=True).iplot(\n    kind='bar', yTitle='Count', linecolor='black',color='black', title='Top 10 Unigrams',orientation='h')\n\ngender_2 = pd.DataFrame(bigrams, columns = ['Text' , 'count'])\ngender_2.groupby('Text').sum()['count'].sort_values(ascending=True).iplot(\n    kind='bar', yTitle='Count', linecolor='black',color='black', title='Top 10 Bigrams',orientation='h')","af5c6ddc":"plt.figure(figsize=(20,10))\nsubset2 = df[df['cyberbullying_type']=='religion']\ntext_religion = subset2.tweet_text.values\ncloud2=WordCloud(background_color='black',colormap=\"Dark2\",collocations=False,width=2000,height=1000).generate(\" \".join(text_religion))\n\nplt.axis('off')\nplt.title(\"Religion\",fontsize=40)\nplt.imshow(cloud2)","772d109a":"unigrams = get_top_n_gram(text_religion,(1,1),10)\nbigrams = get_top_n_gram(text_religion,(2,2),10)\n\nreligion_1 = pd.DataFrame(unigrams, columns = ['Text' , 'count'])\nreligion_1.groupby('Text').sum()['count'].sort_values(ascending=True).iplot(\n    kind='bar', yTitle='Count', linecolor='black',color='black', title='Top 10 Unigrams',orientation='h')\n\nreligion_2 = pd.DataFrame(bigrams, columns = ['Text' , 'count'])\nreligion_2.groupby('Text').sum()['count'].sort_values(ascending=True).iplot(\n    kind='bar', yTitle='Count', linecolor='black',color='black', title='Top 10 Bigrams',orientation='h')","973badcc":"plt.figure(figsize=(20,10))\nsubset3 = df[df['cyberbullying_type']=='age']\ntext_age = subset3.tweet_text.values\ncloud3=WordCloud(background_color='black',colormap=\"Dark2\",collocations=False,width=2000,height=1000).generate(\" \".join(text_age))\n\nplt.axis('off')\nplt.title(\"Age\",fontsize=40)\nplt.imshow(cloud3)","2b3f3d9c":"unigrams = get_top_n_gram(text_age,(1,1),10)\nbigrams = get_top_n_gram(text_age,(2,2),10)\n\nage_1 = pd.DataFrame(unigrams, columns = ['Text' , 'count'])\nage_1.groupby('Text').sum()['count'].sort_values(ascending=True).iplot(\n    kind='bar', yTitle='Count', linecolor='black',color='black', title='Top 10 Unigrams',orientation='h')\n\nage_2 = pd.DataFrame(bigrams, columns = ['Text' , 'count'])\nage_2.groupby('Text').sum()['count'].sort_values(ascending=True).iplot(\n    kind='bar', yTitle='Count', linecolor='black',color='black', title='Top 10 Bigrams',orientation='h')","85ae861b":"plt.figure(figsize=(20,10))\nsubset4 = df[df['cyberbullying_type']=='ethnicity']\ntext_ethnicity = subset4.tweet_text.values\ncloud4=WordCloud(background_color='black',colormap=\"Dark2\",collocations=False,width=2000,height=1000).generate(\" \".join(text_ethnicity))\n\nplt.axis('off')\nplt.title(\"Ethnicity\",fontsize=40)\nplt.imshow(cloud4)","09450dd1":"unigrams = get_top_n_gram(text_ethnicity,(1,1),10)\nbigrams = get_top_n_gram(text_ethnicity,(2,2),10)\n\nethnicity_1 = pd.DataFrame(unigrams, columns = ['Text' , 'count'])\nethnicity_1.groupby('Text').sum()['count'].sort_values(ascending=True).iplot(\n    kind='bar', yTitle='Count', linecolor='black',color='black', title='Top 10 Unigrams',orientation='h')\n\nethnicity_2 = pd.DataFrame(bigrams, columns = ['Text' , 'count'])\nethnicity_2.groupby('Text').sum()['count'].sort_values(ascending=True).iplot(\n    kind='bar', yTitle='Count', linecolor='black',color='black', title='Top 10 Bigrams',orientation='h')","3c044627":"plt.figure(figsize=(20,10))\nsubset5 = df[df['cyberbullying_type']=='other_cyberbullying']\ntext_other = subset5.tweet_text.values\ncloud5=WordCloud(background_color='black',colormap=\"Dark2\",collocations=False,width=2000,height=1000).generate(\" \".join(text_other))\n\nplt.axis('off')\nplt.title(\"Other cyberbullying\",fontsize=40)\nplt.imshow(cloud5)","8c4204c7":"unigrams = get_top_n_gram(text_other,(1,1),10)\nbigrams = get_top_n_gram(text_other,(2,2),10)\n\nother_1 = pd.DataFrame(unigrams, columns = ['Text' , 'count'])\nother_1.groupby('Text').sum()['count'].sort_values(ascending=True).iplot(\n    kind='bar', yTitle='Count', linecolor='black',color='black', title='Top 10 Unigrams',orientation='h')\n\nother_2 = pd.DataFrame(bigrams, columns = ['Text' , 'count'])\nother_2.groupby('Text').sum()['count'].sort_values(ascending=True).iplot(\n    kind='bar', yTitle='Count', linecolor='black',color='black', title='Top 10 Bigrams',orientation='h')","0fdc90d2":"# Text preprocessing","82437bf6":"## Most used words and phrases","a8c5d655":"## Most used words and phrases","23824b1f":"## Most used words and phrases","ec92948c":"## Most used words and phrases","8b6790d5":"## Word cloud","37d6dad9":"<a id=\"age\"><\/a>\n# Age-based hate on twitter","8fa865e3":"<a id=\"religion\"><\/a>\n# Religion-based hate on twitter","9156d563":"<a id=\"ethnicity\"><\/a>\n# Ethnicity-based hate on twitter","72b1e0a7":"## Most used words and phrases","c89ad648":"## Word cloud","78f0a3e0":"## Word cloud","aaeb9c60":"<a id=\"gender\"><\/a>\n# Gender-based hate on twitter","22e82663":"## Word cloud","c79849f5":"<a id=\"other\"><\/a>\n# Other hate on twitter","4763e7ef":"![image.png](attachment:073f85c9-a97a-4fba-be90-20d22e717c04.png)","cfb5fab4":"## Word cloud","448de9e6":"# <span style=\"font-size:40px;\"><center>CYBERBULLYING ON TWITTER <\/center> <\/span>\n* [Gender-based hate](#gender)\n* [Religion-based hate](#religion)\n* [Age-based hate](#age)\n* [Ethnicity-based hate](#ethnicity)\n* [Other hate](#other)"}}