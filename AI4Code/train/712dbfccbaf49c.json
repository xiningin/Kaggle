{"cell_type":{"2f4e65d2":"code","887c8049":"code","7effe81a":"code","8c05909b":"code","dfaf8d8f":"code","569e705b":"code","02c924e6":"code","35112472":"code","b01017d6":"code","8b03e57e":"code","ae416101":"code","61463230":"code","753f47dd":"code","3b05e863":"code","e53c3df6":"code","b3f6b17d":"code","f28f8cd0":"code","4986050e":"code","4d43e0c1":"code","b3e38f6a":"code","3f8380ce":"code","3c8e6cea":"code","e689ebc4":"code","613738bd":"code","832a61ad":"code","495b0f43":"code","37219f71":"code","3859324a":"code","66ba2683":"code","635fbb91":"code","6083463c":"code","71797e03":"code","4fd83829":"code","a441533a":"code","2910f92f":"code","7ba1e7f1":"code","63c0032f":"code","0056d09e":"code","021ad1b0":"code","a9605e6b":"code","446a7fc6":"code","c7493dfb":"code","b3a7c809":"code","cc94f477":"code","29b02f99":"code","2e7e2427":"code","aa8b1c46":"code","d7a4d3c2":"code","f616256f":"code","ad6d9d83":"code","d7185f0c":"code","a4e93fe6":"code","8512b60c":"code","a93ac0b9":"code","d5387af4":"code","b600c496":"code","75cd0ecc":"code","32e2842a":"code","b06e212f":"code","498c403c":"code","d773eb4c":"code","72f934a6":"code","777b3cfe":"code","6585814b":"code","99d8be17":"code","2dc47e78":"code","f26f75f3":"markdown","a15b633d":"markdown","53ebafae":"markdown","fe25ea37":"markdown","b8f47009":"markdown","7445a67f":"markdown","61846fa6":"markdown","f4075a64":"markdown","5544fb90":"markdown","f6927dc4":"markdown","2993d3be":"markdown","34d577d3":"markdown","861df188":"markdown","457ea22e":"markdown","d23dbc44":"markdown","a73d79c0":"markdown","f57d433a":"markdown","e6a3a40b":"markdown","5709a913":"markdown","8def14f7":"markdown","1a66bcff":"markdown","893d1f96":"markdown","78fc4e83":"markdown","e96dc26a":"markdown","b72929a1":"markdown","b4ffc3e0":"markdown","c77be4cd":"markdown","bc0312d9":"markdown","3db2c066":"markdown","f55a5f2e":"markdown","de6fbc3a":"markdown","ea97430b":"markdown","aee49fbf":"markdown","73d9b2d2":"markdown","2926b8db":"markdown","008d37a1":"markdown","631ef739":"markdown","7a243475":"markdown","9c82ffe4":"markdown","b60e834d":"markdown","9481d19f":"markdown"},"source":{"2f4e65d2":"import pandas as pd\nimport numpy as np\n#from googletrans import Translator\n\nfrom itertools import product\nimport itertools\n\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nimport matplotlib\nimport seaborn as sns\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom statsmodels.tsa.stattools import adfuller,pacf\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.graphics.gofplots import qqplot\nfrom statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n\nfrom pylab import rcParams\nmatplotlib.rcParams['axes.labelsize'] = 14\nmatplotlib.rcParams['xtick.labelsize'] = 12\nmatplotlib.rcParams['ytick.labelsize'] = 12\nmatplotlib.rcParams['text.color'] = 'k'\n\nimport statsmodels.formula.api as smf\nimport statsmodels.tsa.api as smt\nimport statsmodels.api as sm\nimport scipy.stats as scs\nfrom pandas.plotting import autocorrelation_plot\n\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom scipy import stats","887c8049":"\"\"\"\nimport re\ntranslator = Translator()\ntranslate = [\"item_name\",\"item_category_name\",\"shop_name\"]\nshops = pd.read_csv(\"shops.csv\")\nshops_lst = list(shops.shop_name.unique())\nshops[\"shop_name_en\"] = shops[\"shop_name\"].apply(translator.translate, src = \"ru\", dest = \"en\").apply(getattr, args=('text',))\n\nshops = shops.drop(columns = {\"shop_name\"})\nshop_lst = list(shops.shop_name_en)\nlist_of_list_shops = [re.findall(r'[a-zA-Z]+', i) for i in shop_lst]\nshops[\"City\"] = [list_of_list_shops[i][0] +\" \"+ list_of_list_shops[i][1] \n                 if ((list_of_list_shops[i][0] == \"St\") |(list_of_list_shops[i][0] == \"Itinerant\") | \n                                                                             (list_of_list_shops[i][0] ==\"Digital\"))\n                 else list_of_list_shops[i][0] + \" \"+ list_of_list_shops[i][1] +\" \"+ list_of_list_shops[i][2] \n                 if (list_of_list_shops[i][0] == \"Shop\")\n                 else list_of_list_shops[i][0] for i in range(len(list_of_list_shops))]\n\nshops.to_csv(\"shops_new.csv\", sep = \";\")\n\"\"\"","7effe81a":"test = pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/test.csv\")\nitem_categories = pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/item_categories.csv\")\nsales_train = pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/sales_train.csv\")\nitems = pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/items.csv\")\nshops = pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/shops.csv\")","8c05909b":"sales_train.date = pd.to_datetime(sales_train.date)","dfaf8d8f":"sales_train_after11 = sales_train[(sales_train[\"date\"] >= \"2015-11-01\")]\nsales_train_after11.date.unique()","569e705b":"sales_train = sales_train[(sales_train[\"date\"] < \"2015-11-01\")]\nsales_train.shape","02c924e6":"sales_train.head()","35112472":"items = pd.merge(items, item_categories, on = \"item_category_id\")\nitems.shape","b01017d6":"sales_train = pd.merge(sales_train, items, on = \"item_id\")\nsales_train.head()","8b03e57e":"sales_train = pd.merge(sales_train, shops, on = \"shop_id\")\nsales_train.head()","ae416101":"sales_train.shape","61463230":"sales_train = sales_train[(sales_train[\"date\"] < \"2015-11-01\")]\nsales_train.shape","753f47dd":"sales_per_product = sales_train.groupby(\"item_name\", as_index=False).agg({\"item_cnt_day\":\"sum\"}).sort_values(by = \"item_cnt_day\", ascending = False)[0:10]\n","3b05e863":"sales_per_product","e53c3df6":"ax = sns.barplot(x = \"item_cnt_day\", y = \"item_name\", data = sales_per_product)\nplt.figure(figsize=(20,10))\nplt.tight_layout()\n#sns.set_style(\"whitegrid\")\nax.set_title(\"Bestseller\",y= 1.1, fontsize=18, weight = \"semibold\")\nax.set_xlabel(\"# of products\", fontsize = 18, weight = \"semibold\")\nax.set_ylabel(\"Products\", fontsize = 18, weight = \"semibold\")\n","b3f6b17d":"sales_per_shop = sales_train.groupby(by = \"shop_name\", as_index=False).agg({\"item_cnt_day\":\"sum\"}).sort_values(by = \"item_cnt_day\",ascending = False)[0:10]","f28f8cd0":"ax = sns.barplot(x = \"item_cnt_day\", y = \"shop_name\", data = sales_per_shop, palette=\"gist_heat\")\nsns.set_style(\"whitegrid\")\n\nax.set_title(\"Shops sort by amount of sold products\",y= 1.1, fontsize=20, weight = \"semibold\")\nax.set_xlabel(\"Amount of products\", fontsize = 18, weight = \"semibold\")\nax.set_ylabel(\"shops\", fontsize = 18, weight = \"semibold\")\n","4986050e":"sales_train[\"revenue\"] = sales_train[\"item_cnt_day\"]*sales_train[\"item_price\"]","4d43e0c1":"sales_train.date.min(), sales_train.date.max()","b3e38f6a":"sales = sales_train.groupby('date')['item_cnt_day'].sum().reset_index()","3f8380ce":"sales = sales.set_index('date')","3c8e6cea":"sales.index","e689ebc4":"sales.dtypes","613738bd":"y = sales['item_cnt_day'].resample('MS').mean()","832a61ad":"y[\"2015\":]","495b0f43":"# plot historical data about all sold products per day\ny.plot(figsize=(15, 6))\nplt.show()","37219f71":"coefficients, residuals, _, _, _ = np.polyfit(range(len(y.index)),y,1,full=True)\nmse = residuals[0]\/(len(y.index))\nnrmse = np.sqrt(mse)\/(y.max() - y.min())\nprint('Slope ' + str(coefficients[0]))\nprint('NRMSE: ' + str(nrmse))","3859324a":"(y[33]-y[0])\/y[0]","66ba2683":"rcParams['figure.figsize'] = 18, 8\ndecomposition = sm.tsa.seasonal_decompose(y, freq=12, model='additive')\nfig = decomposition.plot()\nplt.show()","635fbb91":"# check the sum of item_cnt_day per day.\nresult = adfuller(y)\nprint(\"Daily Basis:\")\nprint('ADF Statistic: %f' % result[0])\nprint('p-value: %f' % result[1])\nprint('Critical Values:')\nfor key, value in result[4].items():\n    print('\\t%s: %.3f' % (key, value))\n    \n# p-value is smaller than 0.05 so we can reject the Null Hypothesis, \n# the time series is stationary and has no time dependent structure","6083463c":"p = d = q = range(0, 2)\npdq = list(itertools.product(p, d, q))\nseasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]\nprint('Examples of parameter combinations for Seasonal ARIMA...')\nprint('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[1]))\nprint('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[2]))\nprint('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[3]))\nprint('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[4]))","71797e03":"for param in pdq:\n    for param_seasonal in seasonal_pdq:\n        try:\n            mod = sm.tsa.statespace.SARIMAX(y,\n                                            order=param,\n                                            seasonal_order=param_seasonal,\n                                            enforce_stationarity=False,\n                                            enforce_invertibility=False)\n            results = mod.fit()\n            print('ARIMA{}x{}12 - AIC:{}'.format(param, param_seasonal, results.aic))\n        except:\n            continue","4fd83829":"# The best AIC is:\n# ARIMA(1, 1, 1)x(1, 1, 0, 12)12 - AIC:115.62002802642752\n\nmod = sm.tsa.statespace.SARIMAX(y,\n                                order=(1, 1, 1),\n                                seasonal_order=(1, 1, 0, 12),\n                                enforce_stationarity=False,\n                                enforce_invertibility=False)\nresults = mod.fit()\nprint(results.summary().tables[1])","a441533a":"results.plot_diagnostics(figsize=(16, 8))\nplt.show()","2910f92f":"pred = results.get_prediction(start=pd.to_datetime('2015-01-01'), dynamic=False)\npred_ci = pred.conf_int()\nax = y['2013':].plot(label='observed')\npred.predicted_mean.plot(ax=ax, label='One-step ahead Forecast', alpha=.7, figsize=(14, 7))\nax.fill_between(pred_ci.index,\n                pred_ci.iloc[:, 0],\n                pred_ci.iloc[:, 1], color='k', alpha=.2)\nax.set_xlabel('date')\nax.set_ylabel('item_cnt_day')\nplt.legend()\nplt.show()","7ba1e7f1":"y_forecasted = pred.predicted_mean\ny_truth = y['2015-01-01':]\nmse = ((y_forecasted - y_truth) ** 2).mean()\nprint('The Mean Squared Error of our forecasts is {}'.format(round(mse, 2)))","63c0032f":"print('The Root Mean Squared Error of our forecasts is {}'.format(round(np.sqrt(mse), 2)))","0056d09e":"pred_uc = results.get_forecast(steps=100)\npred_ci = pred_uc.conf_int()\nax = y.plot(label='observed', figsize=(14, 7))\npred_uc.predicted_mean.plot(ax=ax, label='Forecast')\nax.fill_between(pred_ci.index,\n                pred_ci.iloc[:, 0],\n                pred_ci.iloc[:, 1], color='k', alpha=.25)\nax.set_xlabel('date')\nax.set_ylabel('item_cnt_day')\nplt.legend()\nplt.show()","021ad1b0":"pred_uc = results.get_forecast(steps=3)\npred_ci = pred_uc.conf_int()\nax = y.plot(label='observed', figsize=(14, 7))\npred_uc.predicted_mean.plot(ax=ax, label='Forecast')\nax.fill_between(pred_ci.index,\n                pred_ci.iloc[:, 0],\n                pred_ci.iloc[:, 1], color='k', alpha=.25)\nax.set_xlabel('date')\nax.set_ylabel('item_cnt_day')\nplt.legend()\nplt.show()","a9605e6b":"pred_uc = results.get_forecast(steps=24)\npred_ci = pred_uc.conf_int()\nax = y.plot(label='observed', figsize=(14, 7))\npred_uc.predicted_mean.plot(ax=ax, label='Forecast')\nax.fill_between(pred_ci.index,\n                pred_ci.iloc[:, 0],\n                pred_ci.iloc[:, 1], color='k', alpha=.25)\nax.set_xlabel('Date',fontsize=18, weight = \"bold\")\nax.set_ylabel('Amount of sold items',fontsize=18, weight = \"semibold\")\nplt.title(\"Forecast sold products next 2 years\",y= 1.1, fontsize=18, weight = \"semibold\" )\nplt.legend()\nplt.show()\n","446a7fc6":"shops_lst = list(sales_train.shop_id.unique())","c7493dfb":"online_shop = sales_train[(sales_train[\"shop_id\"] == 12)]","b3a7c809":"offline_shop = sales_train[(sales_train[\"shop_id\"] != 12)]","cc94f477":"offline_sales = offline_shop.groupby(['date',\"shop_id\"])['item_cnt_day'].sum().reset_index()","29b02f99":"offline_sales = offline_sales.set_index('date')","2e7e2427":"offline_sales.dtypes","aa8b1c46":"# plot time series for each offline shop\nfor i in shops_lst:\n    sales_shop = offline_sales[(offline_sales[\"shop_id\"] == i)]\n    y = sales_shop[\"item_cnt_day\"].resample(\"MS\").mean()\n    \n    y.plot()\n   \n    \n","d7a4d3c2":"sales_per_online_shop = online_shop.groupby(['date',\"shop_id\"])['item_cnt_day'].sum().reset_index()","f616256f":"sales_per_online_shop = sales_per_online_shop.set_index('date')","ad6d9d83":"o = sales_per_online_shop[\"item_cnt_day\"].resample(\"MS\").mean()\n#X = sales_per_online_shop.index\n\n#plt.plot(X, coefficients[0]*X +residuals, color=\"red\")\naxo = o.plot()\n\nplt.title(\"Online Sales\", y= 1.1, fontsize=18, weight = \"semibold\")\nplt.xlabel(\"Date\", fontsize=14, weight = \"semibold\")\nplt.ylabel(\"# sold products\", fontsize=14, weight = \"semibold\")\nplt.show()\n","d7185f0c":"coefficients, residuals, _, _, _ = np.polyfit(range(len(o.index)),o,1,full=True)\nmse = residuals[0]\/(len(o.index))\nnrmse = np.sqrt(mse)\/(o.max() - o.min())\nprint('Slope ' + str(coefficients[0]))\nprint('NRMSE: ' + str(nrmse))\n","a4e93fe6":"(o[33]-o[0])\/o[0]*100","8512b60c":"rcParams['figure.figsize'] = 18, 8\ndecomposition = sm.tsa.seasonal_decompose(o, freq=12, model='additive')\nfig = decomposition.plot()\nplt.show()","a93ac0b9":"# check the sum of item_cnt_day per day.\nresult = adfuller(o)\nprint(\"Daily Basis:\")\nprint('ADF Statistic: %f' % result[0])\nprint('p-value: %f' % result[1])\nprint('Critical Values:')\nfor key, value in result[4].items():\n    print('\\t%s: %.3f' % (key, value))\n    \n# p-value is smaller than 0.05 so we can reject the Null Hypothesis, \n# the time series is stationary and has no time dependent structure","d5387af4":"p = d = q = range(0, 2)\npdq = list(itertools.product(p, d, q))\nseasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]\nprint('Examples of parameter combinations for Seasonal ARIMA...')\nprint('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[1]))\nprint('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[2]))\nprint('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[3]))\nprint('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[4]))","b600c496":"for param in pdq:\n    for param_seasonal in seasonal_pdq:\n        try:\n            mod = sm.tsa.statespace.SARIMAX(o,\n                                            order=param,\n                                            seasonal_order=param_seasonal,\n                                            enforce_stationarity=False,\n                                            enforce_invertibility=False)\n            results = mod.fit()\n            print('ARIMA{}x{}12 - AIC:{}'.format(param, param_seasonal, results.aic))\n        except:\n            continue","75cd0ecc":"# The best AIC is:\n# ARIMA(1, 1, 0)x(1, 1, 0, 12)12 - AIC:87.79639573691884\n\nmod = sm.tsa.statespace.SARIMAX(o,\n                                order=(1, 1, 0),\n                                seasonal_order=(1, 1, 0, 12),\n                                enforce_stationarity=False,\n                                enforce_invertibility=False)\nresults = mod.fit()\nprint(results.summary().tables[1])","32e2842a":"pred = results.get_prediction(start=pd.to_datetime('2015-01-01'), dynamic=False)\npred_ci = pred.conf_int()\nax = o['2013':].plot(label='observed')\npred.predicted_mean.plot(ax=ax, label='One-step ahead Forecast', alpha=.7, figsize=(14, 7))\nax.fill_between(pred_ci.index,\n                pred_ci.iloc[:, 0],\n                pred_ci.iloc[:, 1], color='k', alpha=.2)\nax.set_xlabel('date')\nax.set_ylabel('item_cnt_day')\nplt.legend()\nplt.show()","b06e212f":"o_forecasted = pred.predicted_mean\no_truth = o['2015-01-01':]\nmse = ((o_forecasted - o_truth) ** 2).mean()\nprint('The Mean Squared Error of our forecasts is {}'.format(round(mse, 2)))","498c403c":"print('The Root Mean Squared Error of our forecasts is {}'.format(round(np.sqrt(mse), 2)))","d773eb4c":"pred_uc = results.get_forecast(steps=100)\npred_ci = pred_uc.conf_int()\nax = o.plot(label='observed', figsize=(14, 7))\npred_uc.predicted_mean.plot(ax=ax, label='Forecast')\nax.fill_between(pred_ci.index,\n                pred_ci.iloc[:, 0],\n                pred_ci.iloc[:, 1], color='k', alpha=.25)\nax.set_xlabel('date')\nax.set_ylabel('item_cnt_day')\nplt.legend()\nplt.show()","72f934a6":"pred_uc = results.get_forecast(steps=15)\npred_ci = pred_uc.conf_int()\nax = o.plot(label='observed', figsize=(14, 7))\npred_uc.predicted_mean.plot(ax=ax, label='Forecast')\nax.fill_between(pred_ci.index,\n                pred_ci.iloc[:, 0],\n                pred_ci.iloc[:, 1], color='k', alpha=.25)\nax.set_xlabel('date')\nax.set_ylabel('item_cnt_day')\nplt.legend()\nplt.show()","777b3cfe":"last_offline_sales = sales_train[(sales_train.date_block_num == 33) & (sales_train.shop_id != 12)]\nw = last_offline_sales.item_cnt_day.sum()","6585814b":"last_online_sales = sales_train[(sales_train.date_block_num == 33) & (sales_train.shop_id == 12)]\nz = last_online_sales.item_cnt_day.sum()","99d8be17":"labels = ['Offline', \"online\"]\nsizes = [(w\/(w+z)),(z\/(w+z))]","2dc47e78":"explode = (0, 0.1)\nplt.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',  startangle=60)\nplt.axis('equal', fontsize=14, weight = \"semibold\")\n\nplt.show()\n","f26f75f3":"> ## Introduction","a15b633d":"### 2. Exploratory Data Analysis","53ebafae":"#### 3.3. Forecast Time Series with ARIMA","fe25ea37":"#### Results","b8f47009":"Merge datasets to have dataset with more informations, columns.\n\nitem_categories.item_category_id = items.item_category_id\n\nitems.item_id = sales_train.item_id\n\nshops.shop_id = sales_train.shop_id\n","7445a67f":"#### 4.3. Extra analysis","61846fa6":"### 3. Prediction Future Sales","f4075a64":"#### Import datasets","5544fb90":"#### Translate (item name, item category and) shop name into english","f6927dc4":"#### Shop with the highest amount of sold products","2993d3be":"Augmented Dicky Fuller Test is to check the stationarity of the sold items per day. Null Hypothesis (H0): If failed to be rejected, it suggests the time series has a unit root, meaning it is non-stationary. It has some time dependent structure.","34d577d3":"It is a Dataset from kaggle with 5 csv files of daily sales data, kindly provided by one of the largest Russian software firms - 1C Company. The sales data is from January 2013 - October 2015, splittet mainly into sold products and shops.\n\nMy challenge is to predict future sales in a time series.\n\n(The challenge of the kaggle competion will be to predict total sales for every product and store in the next month for the test set and to create a robust model that can handle monthly, slightly changes in the list of shops and products.)","861df188":"#### 3.4. Fitting the SARIMAX model","457ea22e":"The data is from 2013-01-01 till 2015-10-31, you can see seasonality over a year, with a peak at the end of the year. The trend goes down.","d23dbc44":"### Agenda","a73d79c0":"Unfortunately items and items_category are too big to translate, they are also not neccessary.","f57d433a":"#### 3.1. Analysing historical data","e6a3a40b":"#### 4.2. Online Shop: sold products per day","5709a913":"#### 4.1. Offline Shops: sold products per day","8def14f7":"The diagnostic plots gave us the suggests that the model residuals are near normally distributed.","1a66bcff":"Analyse the data based on the sold products (item_cnt_day) per day.","893d1f96":"#### 3.6. Visualization of the forecast","78fc4e83":"### 1. Libraries ","e96dc26a":"#### 3.2. Test Stationarity with Augmented Dicky Fuller Test","b72929a1":"#### Bestseller Products","b4ffc3e0":"1. Libraries \n\n2. Exploratory Data Analysis\n\n3. Predict Future Sales\n\n    3.1. Analysing historical data\n    \n    3.2. Test Stationarity with Augmented Dicky Fuller Test\n    \n    3.3. Forecast Time Series with ARIMA\n    \n    3.4. Fitting the SARIMAX model\n    \n    3.5. Validating forecasts\n    \n    3.6. Visualization of the forecast   \n    \n4. Focusing on certain shops\n\n    4.1. Offline Shops: sold products per day\n    \n    4.2. Online Shop: sold products per day\n    \n        4.2.1. Analysing historical data\n    \n        4.2.2 Test Stationarity with Augmented Dicky Fuller Test\n    \n        4.2.3. Forecast Time Series with ARIMA\n    \n        4.2.4. Fitting the SARIMAX model\n    \n        4.2.5. Validating forecasts\n    \n        4.2.6. Visualization of the forecast \n        \n    4.3. Extra Analysis\n","c77be4cd":"Analysing the parameters (p=season, d=trend, q=noise) for the seasonal ARIMA (Autoregressive Integrated Moving Average) to recieve the best AIC (Akaike\u2019s Information Criterion).\nAIC estimates the quality of a model, relative to each of other models. The lower AIC score is, the better the model is. Therefore, a model with lowest AIC - in comparison to others, is chosen.\n\nSince we saw in the analysis before that there is a seasonality over the year, we will use the model SARIMAX, this model allows us to set a seasonality of 12 months.\n","bc0312d9":"##### Data fields\n\nID - an Id that represents a (Shop, Item) tuple within the test set\n\nshop_id - unique identifier of a shop\n\nitem_id - unique identifier of a product\n\nitem_category_id - unique identifier of item category\n\nitem_cnt_day - number of products sold. You are predicting a monthly amount of this measure\n\nitem_price - current price of an item\n\ndate - date in format dd\/mm\/yyyy\n\ndate_block_num - a consecutive month number, used for convenience. January 2013 is 0, February 2013 is 1,..., October 2015 is 33\n\nitem_name - name of item\n\nshop_name - name of shop\n\nitem_category_name - name of item category","3db2c066":"Analysis regarding observation, trend, seasonality and residuals","f55a5f2e":"##### 4.2.3. Forecast Time Series with ARIMA","de6fbc3a":"#### Transform date to datetime","ea97430b":"##### 4.2.4. Fitting the SARIMAX model","aee49fbf":"#### 3.5. Validating forecasts","73d9b2d2":"##### 4.2.6. Visualization of the forecast","2926b8db":"##### 4.2.1 Analysing historical data","008d37a1":"#### Merge Datasets\n","631ef739":"The p-value is smaller than 0.05 so we can reject the Null Hypothesis, the time series is stationary and has no time dependent structure.","7a243475":"##### 4.2.2. Test Stationarity with Augmented Dicky Fuller Test","9c82ffe4":"> # Predict Future Sales","b60e834d":"##### 4.2.5. Validating forecasts","9481d19f":"### 4. Focusing on certain shops"}}