{"cell_type":{"980612a9":"code","3f55a853":"code","a1f9cf91":"code","651a5506":"code","464e8656":"code","d7811dee":"code","cc83eb09":"code","32df35fb":"code","96db6c2f":"code","032a4a0f":"markdown","aa6767a6":"markdown","d9631ea1":"markdown","2266d997":"markdown","64578890":"markdown","853229a2":"markdown","908579f0":"markdown","faaa8848":"markdown","5991dde0":"markdown"},"source":{"980612a9":"import traceback\nimport numpy as np\nimport pandas as pd\nimport xgboost as xgb\nimport datatable as dt\nimport gresearch_crypto\nfrom lightgbm import LGBMRegressor","3f55a853":"TRAIN_JAY = '..\/input\/cryptocurrency-extra-data-binance-coin\/orig_train.jay'\nASSET_DETAILS_JAY = '..\/input\/cryptocurrency-extra-data-binance-coin\/orig_asset_details.jay'","a1f9cf91":"df_train = dt.fread('..\/input\/cryptocurrency-extra-data-binance-coin\/orig_train.jay').to_pandas()\ndf_train.head()","651a5506":"df_asset_details = dt.fread('..\/input\/cryptocurrency-extra-data-binance-coin\/orig_asset_details.jay').to_pandas().sort_values(\"Asset_ID\")\ndf_asset_details.head()","464e8656":"# Two new features from the competition tutorial\ndef upper_shadow(df):\n    return df['High'] - np.maximum(df['Close'], df['Open'])\n\n\ndef lower_shadow(df):\n    return np.minimum(df['Close'], df['Open']) - df['Low']\n\n\n# A utility function to build features from the original df\n# It works for rows to, so we can reutilize it.\ndef get_features(df):\n    df_feat = df[['Count', 'Open', 'High', 'Low', 'Close', 'Volume', 'VWAP']].copy()\n    df_feat['Upper_Shadow'] = upper_shadow(df_feat)\n    df_feat['Lower_Shadow'] = lower_shadow(df_feat)\n    return df_feat","d7811dee":"def get_Xy_and_model_for_asset(df_train, asset_id):\n    df = df_train[df_train[\"Asset_ID\"] == asset_id]\n    \n    # TODO: Try different features here!\n    df_proc = get_features(df)\n    df_proc['y'] = df['Target']\n    df_proc = df_proc.dropna(how=\"any\")\n    \n    X = df_proc.drop(\"y\", axis=1)\n    y = df_proc[\"y\"]\n    \n    model = xgb.XGBRegressor(\n        n_estimators=500,\n        max_depth=11,\n        learning_rate=0.05,\n        subsample=0.9,\n        colsample_bytree=0.7,\n        missing=-999,\n        random_state=2020,\n        # tree_method='gpu_hist'  # THE MAGICAL PARAMETER\n    )\n    model.fit(X, y)\n\n    return X, y, model\n","cc83eb09":"Xs = {}\nys = {}\nmodels = {}\n\nfor asset_id, asset_name in zip(df_asset_details['Asset_ID'], \n                                df_asset_details['Asset_Name']):\n    \n    print(f\"Training model for {asset_name:<16} (ID={asset_id:<2})\")\n    \n    try:\n        X, y, model = get_Xy_and_model_for_asset(df_train, asset_id)    \n        Xs[asset_id], ys[asset_id], models[asset_id] = X, y, model\n    except:         \n        Xs[asset_id], ys[asset_id], models[asset_id] = None, None, None   ","32df35fb":"# Check the model interface\nx = get_features(df_train.iloc[1])\ny_pred = models[0].predict(pd.DataFrame([x]))\ny_pred[0]","96db6c2f":"env = gresearch_crypto.make_env()\niter_test = env.iter_test()\n\nfor i, (df_test, df_pred) in enumerate(iter_test):\n    for j , row in df_test.iterrows():\n        \n        if models[row['Asset_ID']] is not None:\n            try:\n                model = models[row['Asset_ID']]\n                x_test = get_features(row)\n                y_pred = model.predict(pd.DataFrame([x_test]))[0]\n                df_pred.loc[df_pred['row_id'] == row['row_id'], 'Target'] = y_pred\n            except:\n                df_pred.loc[df_pred['row_id'] == row['row_id'], 'Target'] = 0\n                traceback.print_exc()\n        else: \n            df_pred.loc[df_pred['row_id'] == row['row_id'], 'Target'] = 0\n        \n    env.predict(df_pred)","032a4a0f":"## Loop over all assets","aa6767a6":"# 5. Submit to Cometition","d9631ea1":"# 2. Read data\nHere we are going to use an **extra dataset**, that you can add to your notebook: [Cryptocurrency extra data - Binance Coin](https:\/\/www.kaggle.com\/yamqwe\/cryptocurrency-extra-data-binance-coin). This dataset is an extra updating dataset for the G-Research Crypto Forecasting competition.\n","2266d997":"# 1. Libraries","64578890":"### My Previous Competition Notebooks\nHere you can check my other notebooks for this competition: \n* [G-Research Forecast | Overlap | Score = 0.9999](https:\/\/www.kaggle.com\/maricinnamon\/g-research-forecast-overlap-score-0-9999)\n* [G-Research | Exploratory Data Analysis | Lin Regr](https:\/\/www.kaggle.com\/maricinnamon\/g-research-exploratory-data-analysis-lin-regr)","853229a2":"# 3. Feature Engineering","908579f0":"#### *If you liked it, please, make an upvote* \ud83d\udc96","faaa8848":"# G-Research | XGBoost\n\n### Acknowledgements \ud83d\ude0d\nMy acknowledgments are given to:\n\n* [Yam Peleg. G-Research: XGBoost with GPU (Fit in 1min).](https:\/\/www.kaggle.com\/yamqwe\/g-research-xgboost-with-gpu-fit-in-1min)","5991dde0":"# 4. Define Train Function"}}