{"cell_type":{"c10066d1":"code","487339d1":"code","dc6de403":"code","ab828803":"code","15f0632a":"code","7c071068":"code","a316c1fa":"code","13f5ccf0":"code","1c3927b9":"code","c7b1a580":"code","bfb8f68a":"code","d4240897":"code","5e74c5f5":"code","3cc3714f":"code","4b1d60e6":"code","852fe17d":"code","ecc1dacb":"code","a470f517":"code","1af09189":"code","ec1406ac":"code","4a6a6fca":"code","f5d60c4f":"code","b7c54d40":"code","a8b33178":"code","484326de":"code","6dc1e668":"code","cba38954":"code","6351dfad":"code","c014bb74":"code","b25fe56b":"code","bdeaa573":"code","f75d53b6":"code","bd8033aa":"code","a76ecb89":"code","987116b0":"code","7f78c269":"code","cb4dcbc0":"code","15cce165":"code","6f5f6e52":"code","8374b820":"markdown","64ea64c7":"markdown","8a84ec44":"markdown","1899a0e1":"markdown","fe41da51":"markdown","7132dcc1":"markdown","7fc8d536":"markdown","02dc342c":"markdown","11c2b4ed":"markdown","584c490e":"markdown","94d12f2c":"markdown","1ef46592":"markdown","f6609550":"markdown","a1fcfec9":"markdown","a0a6e442":"markdown","e6163c2e":"markdown","abb6160b":"markdown","134f1b77":"markdown","19fa9f90":"markdown","f96b3f25":"markdown","748398f4":"markdown","05764f18":"markdown","1c70764b":"markdown","e0a6e8a3":"markdown","c01ac193":"markdown","1e8549dc":"markdown","46cf43c2":"markdown","aa8eb3a1":"markdown","0f945fe4":"markdown","9348546c":"markdown","8ebb8def":"markdown","5360cdd2":"markdown","14ef8f71":"markdown","00b6ca87":"markdown","ad01783f":"markdown","8876db47":"markdown","bab4f78b":"markdown","575bd3a1":"markdown","4b8bb9dc":"markdown"},"source":{"c10066d1":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport plotly.express as px\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\nfrom sklearn import metrics\nimport xgboost as xgb\nimport plotly.io as pio\npio.renderers.default='notebook'","487339d1":"df=pd.read_csv('..\/input\/world-happiness\/2016.csv')","dc6de403":"df.head(1)","ab828803":"df.shape","15f0632a":"df.info()","7c071068":"df.drop(['Lower Confidence Interval','Upper Confidence Interval'],axis=1,inplace=True)","a316c1fa":"df.columns=df.columns.str.lower().str.replace(' ','_')\ndf.columns=['country', 'region', 'happiness_rank', 'happiness_score', 'economy', 'family', 'health', 'freedom', 'trust','generosity', 'dystopia_residual']","13f5ccf0":"df.head()","1c3927b9":"df.describe()","c7b1a580":"plt.figure(figsize=(10,10))\ncorr = df.corr()\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\nwith sns.axes_style(\"white\"):\n    ax = sns.heatmap(corr, mask=mask, square=True, annot=True, cmap='ocean')\nplt.title('\\nCorrelation Plot of Happiness Data', fontsize=18)\nplt.show()","bfb8f68a":"plt.figure(figsize=(10,7))\ndf.corr()['happiness_score'].sort_values(ascending=False).drop(['happiness_score']).plot(kind='bar',color='c')\nplt.xlabel('Feature',fontsize=14)\nplt.ylabel('Correlation with Happiness Score',fontsize=14)\nplt.title('Correlation of Features with Happiness Score',fontsize=18)\nplt.show()","d4240897":"plt.figure(figsize=(10,7))\nsns.distplot(df['happiness_score'], bins=50, kde=True, hist_kws=dict(edgecolor='w'), color='b')\nplt.xlabel('Happiness Score', fontsize=12)\nplt.ylabel('Frequency', fontsize=12)\nplt.title('Distribution of Happiness Score', fontsize=15)\nplt.show()","5e74c5f5":"df_region=df.groupby('region').mean().sort_values(by='happiness_score', ascending=False).reset_index()","3cc3714f":"plt.figure(figsize=(10,7))\nsns.barplot(x='region', y='happiness_score', data=df_region, palette='rainbow')\nplt.xlabel('Region', fontsize=14)\nplt.ylabel('Happiness Rank', fontsize=14)\nplt.xticks(rotation=90)\nplt.title('Mean Happiness Score Versus Regions\\n', fontsize=18)\nplt.show()","4b1d60e6":"plt.figure(figsize=(10,7))\nsns.boxplot(x='region',y='happiness_score',data=df,palette='Dark2')\nplt.xlabel('Region', fontsize=14)\nplt.ylabel('Happiness Rank', fontsize=14)\nplt.xticks(rotation=90,fontsize=12)\nplt.yticks(fontsize=12)\nplt.title('Distribution Of Happiness Score In Different Regions\\n', fontsize=18)\nplt.show()","852fe17d":"df_country=df.groupby('country').mean().sort_values(by='happiness_score', ascending=False).reset_index().head(10)","ecc1dacb":"plt.figure(figsize=(10,10))\nplt.pie(x=df_country['happiness_score'], labels=df_country['country'], autopct='%1.2f%%', pctdistance=0.6,labeldistance=1.1,shadow=True, colors=['limegreen', 'deeppink','cyan','pink', 'teal', 'lime','paleturquoise', 'mediumpurple','violet','royalblue'], textprops={'fontsize':14}, explode=(0.2,0,0,0,0,0,0,0,0,0))\nplt.title('Top 10 Countries With The Highest Mean Happiness Scores', fontsize=18)\nplt.show()","a470f517":"n=sns.PairGrid(df, x_vars=['happiness_score','economy','family','health','freedom'],y_vars=['happiness_score','economy','family','health','freedom'],height=2, aspect=1.2)\nn.map_upper(plt.scatter,color='teal')\nn.map_diag(sns.distplot,color='lime')\nn.map_lower(sns.regplot,color='royalblue')\nplt.suptitle('Relationship Between Happiness Score, Economy, Family, Health And Freedom',y=1.05,fontsize=14)\nplt.show()","1af09189":"fig=px.scatter_3d(data_frame=df, x='trust', y='generosity', z='dystopia_residual', color='happiness_score',color_continuous_scale='algae')\nfig.update_layout(\n    title={\n        'text': 'Relationship Between Happiness Score, Trust, Generosity, And Dystopia Residual',\n        'y':0.92,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'})\nfig.show()","ec1406ac":"sns.lmplot (x='economy', y='happiness_score', data=df, scatter=False, hue='region', legend=False, height=6.5)\nplt.title('The Influence Of Economy On Happiness Score In Different Regions', fontsize=18)\nplt.legend(title='Region', fontsize=12, title_fontsize=13, bbox_to_anchor=(1.6,0.7), borderaxespad=0, loc='right')\nplt.xlabel('Economy', fontsize=14)\nplt.ylabel('Happiness Score', fontsize=14)\nplt.show()","4a6a6fca":"le1=LabelEncoder()\nle1.fit(df['country'])\ndf['country']=le1.transform(df['country'])","f5d60c4f":"le2=LabelEncoder()\nle2.fit(df['region'])\ndf['region']=le2.transform(df['region'])","b7c54d40":"X=df[['country', 'region', 'economy','family', 'health', 'freedom', 'trust', 'generosity','dystopia_residual']]\ny=df['happiness_score']","a8b33178":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)","484326de":"lr=LinearRegression()\nlr.fit(X,y)\npredictions_lr=lr.predict(X_test)","6dc1e668":"print('MAE_Linear Regression=', metrics.mean_absolute_error(y_test,predictions_lr))\nprint('MSE_Linear Regression=', metrics.mean_squared_error(y_test,predictions_lr))\nprint('RMSE_Linear Regression=', np.sqrt(metrics.mean_squared_error(y_test,predictions_lr)))\nprint('MAPE_Linear Regression=', 100*metrics.mean_absolute_error(y_test,predictions_lr)\/df['happiness_score'].mean())\nprint('R2 Score_Linear Regression=',metrics.r2_score(y_test,predictions_lr))","cba38954":"plt.figure(figsize=(8,6))\nplt.scatter(x=y_test,y=predictions_lr, color='r')\nplt.plot(y_test,y_test, color='b')\nplt.xlabel('Actual Happiness Score',fontsize=14)\nplt.ylabel('Predicted Happiness Score',fontsize=14)\nplt.title('Linear Regression',fontsize=18)\nplt.show()","6351dfad":"dtr=DecisionTreeRegressor()\ndtr.fit(X_train,y_train)\npredictions_dtr=dtr.predict(X_test)","c014bb74":"print('MAE_Decision Tree Regression=', metrics.mean_absolute_error(y_test,predictions_dtr))\nprint('MSE_Decision Tree Regression=', metrics.mean_squared_error(y_test,predictions_dtr))\nprint('RMSE_Decision Tree Regression=', np.sqrt(metrics.mean_squared_error(y_test,predictions_dtr)))\nprint('MAPE_Decision Tree Regression=', 100*metrics.mean_absolute_error(y_test,predictions_dtr)\/df['happiness_score'].mean())\nprint('R2 Score_Decision Tree Regression=',metrics.r2_score(y_test,predictions_dtr))","b25fe56b":"plt.figure(figsize=(8,6))\nplt.scatter(x=y_test, y=predictions_dtr, color='r')\nplt.plot(y_test,y_test, color='b')\nplt.xlabel('Actual Sensitivity',fontsize=14)\nplt.ylabel('Predicted Sensitivity',fontsize=14)\nplt.title('Decision Tree Regression',fontsize=18)\nplt.show()","bdeaa573":"rfr=RandomForestRegressor(n_estimators=200)\nrfr.fit(X_train,y_train)\npredictions_rfr=rfr.predict(X_test)","f75d53b6":"print('MAE_Random Forest Regression=', metrics.mean_absolute_error(y_test,predictions_rfr))\nprint('MSE_Random Forest Regression=', metrics.mean_squared_error(y_test,predictions_rfr))\nprint('RMSE_Random Forest Regression=', np.sqrt(metrics.mean_squared_error(y_test,predictions_rfr)))\nprint('MAPE_Random Forest Regression=', 100*metrics.mean_absolute_error(y_test,predictions_rfr)\/df['happiness_score'].mean())\nprint('R2 Score_Random Forest Regression=',metrics.r2_score(y_test,predictions_rfr))","bd8033aa":"plt.figure(figsize=(8,6))\nplt.scatter(x=y_test, y=predictions_rfr, color='r')\nplt.plot(y_test,y_test, color='b')\nplt.xlabel('Actual Sensitivity',fontsize=14)\nplt.ylabel('Predicted Sensitivity',fontsize=14)\nplt.title('Random Forest Regression' ,fontsize=18)\nplt.show()","a76ecb89":"svr=SVR(gamma='auto')\nsvr.fit(X_train,y_train)\npredictions_svr=svr.predict(X_test)","987116b0":"print('MAE_Support Vector Regression=', metrics.mean_absolute_error(y_test,predictions_svr))\nprint('MSE_Support Vector Regression=', metrics.mean_squared_error(y_test,predictions_svr))\nprint('RMSE_Support Vector Regression=', np.sqrt(metrics.mean_squared_error(y_test,predictions_svr)))\nprint('MAPE_Support Vector Regression=', 100*metrics.mean_absolute_error(y_test,predictions_svr)\/df['happiness_score'].mean())\nprint('R2 Score_Support Vector Regression=',metrics.r2_score(y_test,predictions_svr))","7f78c269":"plt.figure(figsize=(8,6))\nplt.scatter(x=y_test, y=predictions_svr, color='r')\nplt.plot(y_test,y_test, color='b')\nplt.xlabel('Actual Sensitivity',fontsize=14)\nplt.ylabel('Predicted Sensitivity',fontsize=14)\nplt.title('Support Vector Regression',fontsize=18)\nplt.show()","cb4dcbc0":"xgbr= xgb.XGBRegressor(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75, colsample_bytree=1, max_depth=7)\nxgbr.fit(X_train,y_train)\npredictions_xgbr=xgbr.predict(X_test)","15cce165":"print('MAE_XGBoost Regression=', metrics.mean_absolute_error(y_test,predictions_xgbr))\nprint('MSE_XGBoost Regression=', metrics.mean_squared_error(y_test,predictions_xgbr))\nprint('RMSE_XGBoost Regression=', np.sqrt(metrics.mean_squared_error(y_test,predictions_xgbr)))\nprint('MAPE_XGBoost Regression=', 100*metrics.mean_absolute_error(y_test,predictions_xgbr)\/df['happiness_score'].mean())\nprint('R2 Score_XGBoost Regression=',metrics.r2_score(y_test,predictions_svr))","6f5f6e52":"plt.figure(figsize=(8,6))\nplt.scatter(x=y_test, y=predictions_xgbr, color='r')\nplt.plot(y_test,y_test, color='b')\nplt.xlabel('Actual Sensitivity',fontsize=14)\nplt.ylabel('Predicted Sensitivity',fontsize=14)\nplt.title('XGBoost Regression',fontsize=18)\nplt.show()","8374b820":"<h1>Table of Contents<span class=\"tocSkip\"><\/span><\/h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;<\/span>Introduction<\/a><\/span><\/li><li><span><a href=\"#Importing-Libraries\" data-toc-modified-id=\"Importing-Libraries-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;<\/span>Importing Libraries<\/a><\/span><\/li><li><span><a href=\"#Loading-Dataset\" data-toc-modified-id=\"Loading-Dataset-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;<\/span>Loading Dataset<\/a><\/span><\/li><li><span><a href=\"#Feature-Engineering\" data-toc-modified-id=\"Feature-Engineering-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;<\/span>Feature Engineering<\/a><\/span><\/li><li><span><a href=\"#Exploratory-Data-Analysis\" data-toc-modified-id=\"Exploratory-Data-Analysis-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;<\/span>Exploratory Data Analysis<\/a><\/span><\/li><li><span><a href=\"#Predicting-Happiness-Score\" data-toc-modified-id=\"Predicting-Happiness-Score-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;<\/span>Predicting Happiness Score<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Encoding-Categorical-Variables\" data-toc-modified-id=\"Encoding-Categorical-Variables-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;<\/span>Encoding Categorical Variables<\/a><\/span><\/li><li><span><a href=\"#Splitting-the-Data\" data-toc-modified-id=\"Splitting-the-Data-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;<\/span>Splitting the Data<\/a><\/span><\/li><li><span><a href=\"#Linear-Regression\" data-toc-modified-id=\"Linear-Regression-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;<\/span>Linear Regression<\/a><\/span><\/li><li><span><a href=\"#Decision-Tree-Regression\" data-toc-modified-id=\"Decision-Tree-Regression-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;<\/span>Decision Tree Regression<\/a><\/span><\/li><li><span><a href=\"#Random-Forest-Regression\" data-toc-modified-id=\"Random-Forest-Regression-6.5\"><span class=\"toc-item-num\">6.5&nbsp;&nbsp;<\/span>Random Forest Regression<\/a><\/span><\/li><li><span><a href=\"#Support-Vector-Regression\" data-toc-modified-id=\"Support-Vector-Regression-6.6\"><span class=\"toc-item-num\">6.6&nbsp;&nbsp;<\/span>Support Vector Regression<\/a><\/span><\/li><li><span><a href=\"#XGBoost-Regression\" data-toc-modified-id=\"XGBoost-Regression-6.7\"><span class=\"toc-item-num\">6.7&nbsp;&nbsp;<\/span>XGBoost Regression<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;<\/span>Conclusion<\/a><\/span><\/li><\/ul><\/div>","64ea64c7":"### Linear Regression","8a84ec44":"According to the above cor plot, economy plays the most significant role in contributing to happiness. Generosity has the lowest impact on happiness score and happiness_rank has a reverse impact on happiness score.","1899a0e1":"## Importing Libraries","fe41da51":"### Decision Tree Regression ","7132dcc1":"### Encoding Categorical Variables","7fc8d536":"### Random Forest Regression","02dc342c":"### Support Vector Regression","11c2b4ed":"We use strip plot to see the happiness score distribution in different regions.","584c490e":"**Region**","94d12f2c":"We can see that except for North America and Australia and New Zealand, happiness scores increase with economy.","1ef46592":"We explore the correlation between all numeric variables.","f6609550":"# <center>  World Happiness Visualization and Prediction  <center>  ","a1fcfec9":"As mentioned before, economy plays the most significant role in contributing to happiness. So here we explore its influence in different regions throughout the world.","a0a6e442":"-  We performed Exploratory Data Analysis and visualized the impacts of various features on happiness score throughout the world.\n\n-  Linear Regression algorithm with the R2 Score of 99.99% was the best model for predicting  the happiness score across in the world.","e6163c2e":"## Conclusion","abb6160b":"It can be seen that the highest mean happiness score among the regions is related to Australia and New Zealand.","134f1b77":"The World Happiness Report is a landmark survey of the state of global happiness. This report reviews the state of happiness in the world today and show how the new science of happiness explains personal and national variations in happiness. The happiness scores and rankings use data from the Gallup World Poll. The scores are based on answers to the main life evaluation question asked in the poll. \n\nThe dataset that we have chosen is Happiness Dataset 2016, one of Kaggle\u2019s dataset. This dataset gives the happiness rank and happiness score of 155 countries around the world based on factors including family, health, economy, generosity, trust in government, freedom, country, region and dystopia residual.\n\nThere are three parts to my report as follows:\n\n- Feature Engoineering \n- Visualization \n- Prediction\n\nOur first objective is to determine factors that are more important to live a happier life. Our second purpose is to implement several machine learning algorithms including Linear Regression, Decision Tree Regression, Random Forest Regression, Support Vector Regression and XGBoost Regression to predict the happiness scores throughout the world. We will compare the results to discover which algorithm works better for this specific dataset.","19fa9f90":"## Exploratory Data Analysis","f96b3f25":"We remove unnecessary columns.","748398f4":"So we conclude that Linear Regression with the R2 Score of 99.99% is the best model for predicting the happiness score across the world.","05764f18":"It can be seen that the highest mean happiness score among the countries is related to Denmark.","1c70764b":"### XGBoost Regression","e0a6e8a3":"We can observe that most of the happiness_score values are between 5 and 5.5.","c01ac193":"## Loading Dataset","1e8549dc":"### Splitting the Data","46cf43c2":"**Country**","aa8eb3a1":"We can see that the dataset does not contain null values. So it does not need Data Cleaning.","0f945fe4":"## Introduction","9348546c":"## Feature Engineering","8ebb8def":"# ![5.jpg](attachment:5.jpg)","5360cdd2":"We visualize the relationship between happiness_score, economy, family, health and freedom.","14ef8f71":"## Predicting Happiness Score","00b6ca87":"We visualize the mean happiness scores of different regions.","ad01783f":" First, we should split our dataset into training and test set. Our dependent variable is happiness score, and the independent variables are country, continent,family, economy, health, trust, freedom, generosity, and dystopia residual.","8876db47":"Now let's visualize thetop 10 countries with the highest happiness scores.","bab4f78b":"Let's visualize the relationship between happiness_score, trust, generosity, and dystopia_residual.","575bd3a1":"In this section, we will implement several machine learning algorithms to predict happiness score.","4b8bb9dc":"Now we rename some of the columns."}}