{"cell_type":{"0bb23ad6":"code","c0b9ed3c":"code","a2133248":"code","0cdaab5a":"code","db669d2d":"code","832d21f8":"code","96419ddd":"code","ac314e3d":"code","d430d47d":"code","69055b34":"code","fa1d18a3":"markdown","f769e248":"markdown","8d9265a7":"markdown","63b191bd":"markdown","426fbe4b":"markdown","a17e33d8":"markdown","866e76e6":"markdown","29519d78":"markdown","cf2ca210":"markdown"},"source":{"0bb23ad6":"import cv2\nimport pandas as pd\nimport numpy as np\nimport os\nfrom tqdm import tqdm, tqdm_notebook\n\ntrain_df = pd.read_csv('..\/input\/train\/train.csv')\nimg_size = 256\nbatch_size = 16","c0b9ed3c":"pet_ids = train_df['PetID'].values\nn_batches = len(pet_ids) \/\/ batch_size + 1","a2133248":"from matplotlib import pyplot as plt\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 20,10\n\ndef load_raw_image(path, pet_id):\n    image = cv2.imread(f'{path}{pet_id}-1.jpg')\n    return image\n\nfor i in range(1,10):\n    plt.subplot(330+i),plt.imshow(load_raw_image(\"..\/input\/train_images\/\", pet_ids[i]))\nplt.show()","0cdaab5a":"from keras.applications.densenet import preprocess_input, DenseNet121\n\ndef resize_img(im):\n    old_size = im.shape[:2] # old_size is in (height, width) format\n    ratio = float(img_size)\/max(old_size)\n    new_size = tuple([int(x*ratio) for x in old_size])\n    # new_size should be in (width, height) format\n    im = cv2.resize(im, (new_size[1], new_size[0]))\n    delta_w = img_size - new_size[1]\n    delta_h = img_size - new_size[0]\n    top, bottom = delta_h\/\/2, delta_h-(delta_h\/\/2)\n    left, right = delta_w\/\/2, delta_w-(delta_w\/\/2)\n    color = [0, 0, 0]\n    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,value=color)\n    return im\n\ndef resize_to_square(im):\n    old_size = im.shape[:2] # old_size is in (height, width) format\n    ratio = float(img_size)\/max(old_size)\n    new_size = tuple([int(x*ratio) for x in old_size])\n    # new_size should be in (width, height) format\n    im = cv2.resize(im, (new_size[1], new_size[0]))\n    delta_w = img_size - new_size[1]\n    delta_h = img_size - new_size[0]\n    top, bottom = delta_h\/\/2, delta_h-(delta_h\/\/2)\n    left, right = delta_w\/\/2, delta_w-(delta_w\/\/2)\n    color = [0, 0, 0]\n    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,value=color)\n    return new_im","db669d2d":"def load_image(path, pet_id):\n    image = cv2.imread(f'{path}{pet_id}-1.jpg')\n    new_image = resize_to_square(image) # resize\n    return new_image\n\nfor i in range(1,10):\n    plt.subplot(330+i),plt.imshow(load_image(\"..\/input\/train_images\/\", pet_ids[i]))\nplt.show()","832d21f8":"def load_preprocess_image(path, pet_id):\n    image = cv2.imread(f'{path}{pet_id}-1.jpg')\n    new_image = resize_to_square(image)\n    new_image = preprocess_input(new_image) # preprocess_input\n    return new_image\n\nfor i in range(1,10):\n    plt.subplot(330+i),plt.imshow(load_preprocess_image(\"..\/input\/train_images\/\", pet_ids[i]))\nprint('\u306a\u3093\u304b\u4eba\u306e\u76ee\u3067\u306f\u308f\u304b\u308a\u3065\u3089\u304f\u306a\u3063\u305f\u3088\u3046\u306b\u898b\u3048\u308b\u304c\u3001\u3053\u308c\u3067\u3088\u3044\u3089\u3057\u3044')\nplt.show()","96419ddd":"from keras.models import Model\nfrom keras.layers import GlobalAveragePooling2D, Input, Lambda, AveragePooling1D\nimport keras.backend as K\ninp = Input((256,256,3))\nbackbone = DenseNet121(input_tensor = inp, include_top = False)\nx = backbone.output # \u3053\u306e\u6642\u70b9\u3067 8 * 8 * 1024channel\nx = GlobalAveragePooling2D()(x) # \u5404channel\u306e\u753b\u7d20\u5e73\u5747 \u3053\u306e\u307e\u307e\u3067\u30821024\u5217\u306e\u7279\u5fb4\u91cf\u3068\u3057\u3066\u51fa\u529b\u3055\u308c\u308b\nx = Lambda(lambda x: K.expand_dims(x,axis = -1))(x) # 256\u5217\u306b\u3059\u308b\u305f\u3081\u306b\u914d\u5217\u672b\u5c3e\u306bdim\u3092\u633f\u5165 [None,1024] \u2192 [None,1024,1]\nx = AveragePooling1D(4)(x) # 1\/4\u306b\u3059\u308b\u3088\u3046\u306b\u30d7\u30fc\u30ea\u30f3\u30b0\nout = Lambda(lambda x: x[:,:,0])(x) # [None,256,1] \u2192 [None,256]\nm = Model(inp,out)","ac314e3d":"m.summary()","d430d47d":"features = {}\nbatch_pets = pet_ids[0:9]\nbatch_images = np.zeros((len(batch_pets),img_size,img_size,3))\nfor i,pet_id in enumerate(batch_pets):\n    try:\n        batch_images[i] = load_preprocess_image(\"..\/input\/train_images\/\", pet_id)\n    except:\n        pass\nbatch_preds = m.predict(batch_images)\nfor i,pet_id in enumerate(batch_pets):\n    features[pet_id] = batch_preds[i]","69055b34":"train_feats = pd.DataFrame.from_dict(features, orient='index')\ntrain_feats","fa1d18a3":"## \u524d\u51e6\u7406\u3092\u3057\u307e\u3059","f769e248":"## preprocess\n- \u8ee2\u79fb\u5b66\u7fd2\u3059\u308b\u3068\u304d\u306f\u300cpreprocess_input\u300d\u3092\u5165\u308c\u308b\n- \u5143\u3005imagenet\u3067\u753b\u50cf\u3092\u5b66\u7fd2\u3057\u305f\u3068\u304d\u306b\u5408\u308f\u305b\u305f\u524d\u51e6\u7406\u304c\u306a\u3055\u308c\u308b\u3089\u3057\u3044","8d9265a7":"## pet\u306e\u753b\u50cf\u3092\u8aad\u307f\u8fbc\u3093\u3067\u4e0a\u8a18\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3067\u4e88\u6e2c\u3002\u91cd\u307f\u306fimagenet\u3067\u65e2\u306b\u8a13\u7df4\u3055\u308c\u305f\u3082\u306e","63b191bd":"## \u3053\u3053\u304b\u3089\u7279\u5fb4\u91cf\u62bd\u51fa\n- \u3053\u306ekernel\u3067\u306fdensenet121\u306e\u91cd\u307f\u3092\u4f7f\u3063\u3066\u3044\u308b\n- \u4ed6\u306b\u3082\u3044\u308d\u3044\u308d\u306a\u91cd\u307f\u304c\u4f7f\u3048\u308b\u3088 https:\/\/keras.io\/applications\/\n- include_top=False\u306b\u3059\u308b\u3053\u3068\u3067\u3001\u30e2\u30c7\u30eb\u306e\u5168\u7d50\u5408\u5c64\uff08\u7279\u5fb4\u3092\u5206\u985e\u3059\u308b\u5c64\uff09\u3092\u5165\u308c\u306a\u3044\u72b6\u614b\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u5b9a\u7fa9\u3067\u304d\u308b\n- \u51fa\u529b\u306f1024\u6b21\u5143\u3060\u304c\u30011\/4\u306b\u3059\u308b\u3088\u3046\u30d7\u30fc\u30ea\u30f3\u30b0\u3057\u3066\u51fa\u529b","426fbe4b":"## Extra\n\n\u3067\u3001\u753b\u50cf\u306e\u7279\u5fb4\u91cf\u5165\u308c\u308b\u3068\u3069\u3046\u7cbe\u5ea6\u304c\u5909\u308f\u308b\u306e\uff1f\n\n\u307e\u305a\u3001\u62bd\u51fa\u3057\u305f\u7279\u5fb4\u91cf\u3092\u5165\u308c\u305a\u306b\u3001\u5c5e\u6027\u60c5\u5831+sentiment+text\u3001lgb\u3067\u30e2\u30c7\u30ea\u30f3\u30b0\u3057\u305fkernel(private:0.382\uff09\nhttps:\/\/www.kaggle.com\/wrosinski\/baselinemodeling\n\n\u4e0a\u8a18\u306b\u62bd\u51fa\u3057\u305f\u7279\u5fb4\u91cf\uff08+\u03b1\u3067\u753b\u50cf\u306e\u30bf\u30c6\u30e8\u30b3\u3068\u304b\u306e\u7279\u5fb4\u91cf\u3068\u304b\uff09\u3082\u52a0\u3048\u3066xgb\u3067\u30e2\u30c7\u30ea\u30f3\u30b0\u3057\u305fkernel\nhttps:\/\/www.kaggle.com\/ranjoranjan\/single-xgboost-model (private:0.453\uff09\n\n\u304b\u306a\u308a\u7cbe\u5ea6\u304c\u9055\u3046\uff01","a17e33d8":"## \u5143\u753b\u50cf\u306f\u3053\u30fc\u3093\u306a\u611f\u3058","866e76e6":"\u5143\u306e\u5049\u5927\u306a\u30ab\u30fc\u30cd\u30eb\uff08 https:\/\/www.kaggle.com\/christofhenkel\/extract-image-features-from-pretrained-nn \uff09\u3092\u65e5\u672c\u8a9e\u5316\u3057\u307e\u3057\u305f\u3002\n\u3042\u3068\u306f\u8aac\u660e\u7528\u306e\u30b3\u30fc\u30c9\u3092\u591a\u5c11\u8ffd\u52a0\u3057\u307e\u3057\u305f\u3002\n\n- Take only profile picture (if existing else black)\n- pad to square aspect ratio\n- resize to 256\n","29519d78":"## \u7121\u4e8b\u306b\u753b\u50cf\u304b\u3089\u7279\u5fb4\u304c\u62bd\u51fa\u3067\u304d\u307e\u3057\u305f\uff01\n- \u3042\u3068\u306f\u716e\u308b\u306a\u308a\u713c\u304f\u306a\u308a\u304a\u597d\u304d\u306b\u3069\u3046\u305e\n- note:\u4eca\u56de\u306e\u30b3\u30f3\u30da\u306f\u5b66\u7fd2\u6e08\u307f\u306eimagenet\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8( http:\/\/starpentagon.net\/analytics\/ilsvrc2012_class_image\/ )\u306b\u72ac\u3084\u732b\u306e\u753b\u50cf\u304c\u5927\u91cf\u306b\u5165\u3063\u3066\u3044\u308b\u306e\u3067\u7279\u5fb4\u3092\u3061\u3083\u3093\u3068\u6349\u3048\u305f\u7279\u5fb4\u91cf\u306b\u306a\u3063\u3066\u3044\u308b\u306e\u3067\u306f\u3001\u3068\u63a8\u6e2c\u3057\u307e\u3059\u3002\u3082\u3057\u3001imagenet\u3067\u5168\u7136\u4f7f\u7528\u3055\u308c\u3066\u3044\u306a\u3044\u30ab\u30c6\u30b4\u30ea\u306e\u753b\u50cf\u304b\u3089\u7279\u5fb4\u91cf\u3092\u62bd\u51fa\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u5225\u9014\u305d\u306e\u30ab\u30c6\u30b4\u30ea\u306e\u753b\u50cf\u3092\u7528\u610f\u3057\u3066fine tuning\u3057\u305f\u30e2\u30c7\u30eb\u3092\u65b0\u305f\u306b\u4f5c\u3063\u305f\u65b9\u304c\u826f\u3044\u7279\u5fb4\u91cf\u304c\u62bd\u51fa\u3067\u304d\u308b\u3068\u601d\u3044\u307e\u3059\u3002","cf2ca210":"## resize\u306e\u51e6\u7406"}}