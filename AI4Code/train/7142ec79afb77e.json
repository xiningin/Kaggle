{"cell_type":{"c0d53f01":"code","b8469120":"code","e7ca4d4c":"code","950c8034":"code","06733530":"code","e4921603":"code","c1346fa0":"code","2677103e":"code","24d8289a":"code","59a661dd":"code","00a0b7c2":"code","37b3d7c7":"code","ed64715b":"code","5124cb9c":"code","fd082c37":"code","d6c7cdd7":"code","88201148":"code","8a9385bd":"code","fe2e91a2":"code","c05506e8":"code","c9cdcca5":"code","df0d10b3":"code","832a08d5":"code","25a2e362":"code","c83431e8":"code","ec5e9fda":"code","7472c8e1":"code","8da9ae2a":"code","33df3950":"code","730b5719":"code","307e9153":"code","20a2ecd0":"code","e79daed0":"code","44b08185":"code","56ff7dca":"code","5b472991":"code","27973607":"code","8f70e435":"code","104412aa":"code","ef57c838":"code","c82115f8":"code","b17649c5":"code","9ae5df05":"code","883bb893":"code","844cbaea":"code","e96fb7f0":"code","71c9bcf2":"code","a6713745":"code","8caa197f":"code","dc788026":"code","273d3c30":"code","56f8cc8c":"code","715e9083":"code","d7cd4e05":"code","b8cf35dc":"code","7f552f91":"code","e06e0a07":"code","fa205be5":"code","1f61a9b5":"code","d9d0df00":"code","b8272e67":"code","8a6bf693":"code","2337bfa5":"code","e9d3738e":"code","99d09113":"code","7c25debb":"code","60d045bf":"code","1c5886f5":"code","da3c25cf":"code","d578c451":"code","8c92fd62":"code","cc87bfb2":"code","3448d4c2":"code","19c54a05":"code","00496fa2":"code","f89a3aef":"code","9c6c7466":"code","638b8770":"code","07b05cb9":"code","4ec2b0c1":"code","97a0f767":"code","deab4979":"code","37f98ede":"code","471b375c":"code","6b5eea30":"code","8f186c83":"code","61af47e9":"code","ee43dd67":"code","5cf43a0e":"code","64e10c1e":"code","20e25276":"code","93df6905":"code","daeb32d1":"code","dfc6bfc8":"code","203356c0":"code","dc30d1b9":"code","e5f19813":"code","18568111":"code","0015dffe":"code","ca8755e4":"code","7ab9471e":"code","7d0f3bc8":"code","5245429c":"code","9b07be18":"code","3a51ce36":"code","b1d89672":"code","bfddc01f":"code","08cdfa84":"code","06ee93ff":"code","e456359b":"code","f31cf74b":"code","28ffe01a":"code","24515219":"code","07175fab":"code","8b60e41a":"code","e4d58dd0":"code","0cc68070":"code","a0b0b057":"code","ca7ee23a":"code","e1c00c5c":"code","3f4a5272":"code","35f0f9fa":"code","1da91223":"code","c0781299":"markdown","9021a5a8":"markdown","be7b91c0":"markdown","f684c6ed":"markdown","72f5afda":"markdown","2ab35fa3":"markdown","01f4c551":"markdown","33b2577a":"markdown","a4584905":"markdown","f1ed22f4":"markdown","92314200":"markdown","a5a1c571":"markdown","da030460":"markdown","0976c934":"markdown","8648df85":"markdown","e9b18bfe":"markdown","9d79ec7f":"markdown","9a9d8652":"markdown","e270ce5c":"markdown","ab2c2cd4":"markdown","78a3c575":"markdown"},"source":{"c0d53f01":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\\\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\n# Set Matplotlib defaults\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\"figure\", autolayout=True, figsize=(11, 4))\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=16,\n    titlepad=10,\n)\nplot_params = dict(\n    color=\"0.75\",\n    style=\".-\",\n    markeredgecolor=\"0.25\",\n    markerfacecolor=\"0.25\",\n)","b8469120":"from pathlib import Path\nfrom zipfile import ZipFile","e7ca4d4c":"data_path = Path('\/kaggle\/input\/walmart-recruiting-store-sales-forecasting')\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        if filename.split('.')[-1] == 'zip':\n            z_ = ZipFile(os.path.join(dirname, filename))\n            z_.extractall()","950c8034":"pd.read_csv('.\/sampleSubmission.csv')","06733530":"features = pd.read_csv('.\/features.csv', \n                       parse_dates=['Date'], \n                       infer_datetime_format=True)\n\n'''\nfeatures.csv\n\nThis file contains additional data related to the store, department, and regional activity for the given dates. It contains the following fields:\n\nStore - the store number\nDate - the week\nTemperature - average temperature in the region\n\nFuel_Price - cost of fuel in the region\n\nMarkDown1-5 - anonymized data related to promotional markdowns(\ud504\ub85c\ubaa8\uc158 \uac00\uaca9\uc778\ud558) that Walmart is running. \nMarkDown data is only available after Nov 2011, \nand is not available for all stores all the time. Any missing value is marked with an NA.\n\nCPI(\uc18c\ube44\uc790 \ubb3c\uac00\uc9c0\uc218) - the consumer price index\nUnemployment(\uc2e4\uc5c5\ub960) - the unemployment rate\nIsHoliday - whether the week is a special holiday week\nFor convenience, the four holidays fall within the following weeks in the dataset (not all holidays are in the data):\n\nSuper Bowl: 12-Feb-10, 11-Feb-11, 10-Feb-12, 8-Feb-13\nLabor Day: 10-Sep-10, 9-Sep-11, 7-Sep-12, 6-Sep-13\nThanksgiving: 26-Nov-10, 25-Nov-11, 23-Nov-12, 29-Nov-13\nChristmas: 31-Dec-10, 30-Dec-11, 28-Dec-12, 27-Dec-13\n'''\n","e4921603":"features.head()","c1346fa0":"features.Date = features.Date.dt.to_period('D')\nfeatures = features.set_index(['Store', 'Date'])","2677103e":"features_wo_md = features[['Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'IsHoliday']]","24d8289a":"features_wo_md.info() # null \ucc98\ub9ac","59a661dd":"# \uc815\uaddc\ud654\nfor c in features_wo_md.columns:\n    #print(c)\n    features_wo_md[c] = (features_wo_md[c] - features_wo_md[c].mean())\/features_wo_md[c].std()","00a0b7c2":"features_wo_md.join(train)","37b3d7c7":"features_wo_md.groupby(['Store']).mean().plot(style='-', figsize=(11,6))","ed64715b":"features_wo_md.groupby(['Store']).mean().plot(style='-', figsize=(11,6))","5124cb9c":"nrows = 4\nfig, axs = plt.subplots(ncols=1, nrows=nrows, figsize=(10,20))\n# fig, axs = plt.subplots(squeeze=False, **kwargs)\n#ax.set_title(\"Fuel price with store number\")\nfor a_idx, column in zip(range(nrows), ['Temperature','Fuel_Price','CPI','Unemployment']):\n    axs[a_idx].set_title(f'{column} for store number')\n    for i in range(1,46):  \n        #if i == 0:\n        features_wo_md[column].xs(i, level=0).fillna(0).plot( label=f'{i}', ax=axs[a_idx])\n        #else:\n        #    ax = features_wo_md.Fuel_Price.xs(i, level=0).fillna(0).plot(ax=ax, label=f'{i}', ax=axs[0])","fd082c37":"import seaborn as sns\n%matplotlib inline\n\n# calculate the correlation matrix\ncorr = features_wo_md.corr()\ncorr = corr.drop(labels='IsHoliday').drop(columns='IsHoliday')\n# corr.columns.drop('IsHoliday')\n\n# plot the heatmap\nax = sns.heatmap(corr, \n            xticklabels=corr.columns,\n            yticklabels=corr.columns, \n            cmap=\"Blues\", \n            annot=True)","d6c7cdd7":"features_wo_md.groupby(['Store']).mean()[['CPI','Unemployment']].plot(style='-', figsize=(11,4))","88201148":"# cols = list(features_wo_md.columns)\n# #cols = 5\n# fig, axs = plt.subplots(figsize=(16,16), ncols=len(cols), nrows=len(cols))\n# for i in range(len(cols)):\n#     for j in range(i+1,len(cols)):\n#         sns.regplot(x=cols[i], y=cols[j], data=features_wo_md, ax=axs[i][j])","8a9385bd":"tmp = train.groupby(['Store','Date']).mean()\nstore_nums = train.index.levels[0][:5]\nnrows = len(store_nums)\nfig, axs = plt.subplots(ncols=1, nrows=nrows, figsize=(10,20))\n# fig, axs = plt.subplots(squeeze=False, **kwargs)\n#ax.set_title(\"Fuel price with store number\")\nfor a_idx, sn in enumerate(store_nums):\n    axs[a_idx].set_title(f'Weekly_Sales for store number {sn}')\n    for i in range(1,46):  \n        #if i == 0:\n        tmp.Weekly_Sales.xs(sn, level=0).fillna(0).plot( label=f'{i}', ax=axs[a_idx])\n        #else:\n        #    ax = features_wo_md.Fuel_Price.xs(i, level=0).fillna(0).plot(ax=ax, label=f'{i}', ax=axs[0])","fe2e91a2":"corr_w_avg_sales = features_wo_md.join(train.groupby(['Store','Date']).mean(), lsuffix='_').drop(columns=['IsHoliday_','IsHoliday']).dropna().corr()\n# plot the heatmap\nax = sns.heatmap(corr_w_avg_sales, \n            xticklabels=corr_w_avg_sales.columns,\n            yticklabels=corr_w_avg_sales.columns, \n            cmap=\"Blues\", \n            annot=True)","c05506e8":"train.groupby(['Store','Date']).mean()","c9cdcca5":"nrows = len(features_wo_md.columns)\nfig_0, axes_0 = plt.subplots(nrows=nrows, figsize=(10,20))\nfor i, c in enumerate(features_wo_md.columns):\n    axes_0[i].set_title(c)\n    average_fp = features_wo_md.groupby('Date').mean()[c]\n    ((average_sales- average_sales.mean())\/average_sales.std()).plot(**plot_params, ax=axes_0[i])\n    ((average_fp- average_fp.mean())\/average_fp.std()).plot(label=c, ax=axes_0[i])","df0d10b3":"features_wo_md.CPI[features_wo_md.CPI.notna()]","832a08d5":"features.info()","25a2e362":"features[features.IsHoliday]","c83431e8":"dtype = {\n    'store': 'int32',\n    'Dept': 'int32',\n    'Weekly_Sales': 'float32',\n    'IsHoliday': 'bool',\n}\n\ntrain = pd.read_csv('.\/train.csv', \n                    dtype=dtype,\n                    parse_dates=['Date'], \n                    infer_datetime_format=True)\n\n\n#store_sales['date'] = store_sales.date.dt.to_period('D')\n#store_sales = store_sales.set_index(['store_nbr', 'family', 'date']).sort_index()\ntrain['Date'] = train.Date.dt.to_period('D')\ntrain = train.set_index(['Store','Date']).sort_index()\n\n\naverage_sales = train.groupby('Date').mean()[['Weekly_Sales', 'IsHoliday']]\n#train.xs((1,1)).plot(**plot_params)","ec5e9fda":"train.info()","7472c8e1":"train.head()\n#train.groupby(['Store','Date']).mean()\ntrain[train.Dept == 1]['Weekly_Sales'].plot(**plot_params)","8da9ae2a":"store_num = train.groupby(['Store','Dept','Date']).mean()#.xs(1, level=0)","33df3950":"train.groupby(['Store','Dept']).median().sort_values(by=['Weekly_Sales'], ascending=True).xs(1, level=0)['Weekly_Sales'].plot(kind='barh', figsize=(15,15))","730b5719":"train[train.Dept == 1]","307e9153":"store_num.xs((1,1))","20a2ecd0":"num_stores = list(store_num.reset_index(level=1)['Dept'].drop_duplicates().sort_values())#.nunique()\nprint(f'A number of stores: {len(num_stores)}')\nprint(f'Last store num:{num_stores[-1]}')","e79daed0":"tmp = store_num[store_num.Weekly_Sales > 150000]\ntmp.index.get_level_values(2).drop_duplicates()","44b08185":"tmp#.xs(6, level=0)","56ff7dca":"dept_num","5b472991":"store_num = list(tmp.reset_index(level=0)['Store'].drop_duplicates())\ndept_num = list(tmp.reset_index(level=1)['Dept'].drop_duplicates())\n\nfig, axs = plt.subplots(nrows=len(dept_num), sharex=True, figsize=(10,30)) \nfor i, dn in enumerate(dept_num):\n    for sn in store_num:\n        ws_per_dept = train[train.Dept == dn].xs(sn, level=0).Weekly_Sales\n        axs[i].set_title(f'dept_num: {dn}')\n        ws_per_dept.plot(ax=axs[i], marker='.', )","27973607":"store_num = list(tmp.reset_index(level=0)['Store'].drop_duplicates())\ndept_num = list(tmp.reset_index(level=1)['Dept'].drop_duplicates())\n\nfig, axs = plt.subplots(nrows=len(dept_num), sharex=False\n                        , figsize=(10,30)) \nfor i, dn in enumerate(dept_num):\n    for sn in store_num:\n        ws_per_dept = tmp.xs(sn, level=0).reset_index('Dept').Weekly_Sales\n        axs[i].set_title(f'dept_num: {dn}')\n        ws_per_dept.plot(ax=axs[i],style='.')","8f70e435":"# \uc544\ub2d8\nax = average_sales.plot(**plot_params)\nax.set_title('Walmart sales - Check outliers');\nfor l0,l1 in zip(list(tmp.reset_index(level=0)['Store'].drop_duplicates())):\n    print(f'store:{l0}, dept:{l1}')\n    t_idx = tmp.xs((l0, l1), level=[0,1]).index\n    print(t_idx)\n    ax = plt.plot_date(t_idx, average_sales[t_idx], color='C3')\n    ","104412aa":"tmp","ef57c838":"tmp.reset_index(level=1)#.xs(1, level=1)","c82115f8":"tmp.xs('7', level=1)","b17649c5":"#ax = store_num.plot(**plot_params)\n","9ae5df05":"store_num","883bb893":"average_sales","844cbaea":"r_ = average_sales.rolling(window=7, center=True, min_periods=4).mean()\nax = average_sales.plot(**plot_params)\n\nr_.plot(ax=ax,kind='line')","e96fb7f0":"\n# for fuourier\n\n\nfrom pathlib import Path\nfrom warnings import simplefilter\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nfrom statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n\n\n# annotations: https:\/\/stackoverflow.com\/a\/49238256\/5769929\ndef seasonal_plot(X, y, period, freq, ax=None):\n    if ax is None:\n        _, ax = plt.subplots()\n    palette = sns.color_palette(\"husl\", n_colors=X[period].nunique(),)\n    ax = sns.lineplot(\n        x=freq,\n        y=y,\n        hue=period,\n        data=X,\n        ci=False,\n        ax=ax,\n        palette=palette,\n        legend=False,\n    )\n    ax.set_title(f\"Seasonal Plot ({period}\/{freq})\")\n    for line, name in zip(ax.lines, X[period].unique()):\n        y_ = line.get_ydata()[-1]\n        ax.annotate(\n            name,\n            xy=(1, y_),\n            xytext=(6, 0),\n            color=line.get_color(),\n            xycoords=ax.get_yaxis_transform(),\n            textcoords=\"offset points\",\n            size=14,\n            va=\"center\",\n        )\n    return ax\n\n\ndef plot_periodogram(ts, detrend='linear', ax=None):\n    from scipy.signal import periodogram\n    fs = pd.Timedelta(\"1Y\") \/ pd.Timedelta(\"1D\")\n    freqencies, spectrum = periodogram(\n        ts,\n        fs=fs,\n        detrend=detrend,\n        window=\"boxcar\",\n        scaling='spectrum',\n    )\n    if ax is None:\n        _, ax = plt.subplots()\n    ax.step(freqencies, spectrum, color=\"purple\")\n    ax.set_xscale(\"log\")\n    ax.set_xticks([1, 2, 4, 6, 12, 26, 52, 104])\n    ax.set_xticklabels(\n        [\n            \"Annual (1)\",\n            \"Semiannual (2)\",\n            \"Quarterly (4)\",\n            \"Bimonthly (6)\",\n            \"Monthly (12)\",\n            \"Biweekly (26)\",\n            \"Weekly (52)\",\n            \"Semiweekly (104)\",\n        ],\n        rotation=30,\n    )\n    ax.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0))\n    ax.set_ylabel(\"Variance\")\n    ax.set_title(\"Periodogram\")\n    return ax\n\n","71c9bcf2":"average_sales","a6713745":"avg_sales_ = average_sales['Weekly_Sales'].to_frame()\nmean = avg_sales_['Weekly_Sales'].mean()\nstd = avg_sales_['Weekly_Sales'].std()\navg_sales_['sales_norm'] = avg_sales_['Weekly_Sales'].apply(lambda x, mean=mean : (x-mean)\/std)\n\n# outliers on holidays\nholidays = average_sales.loc[avg_sales_[avg_sales_['sales_norm']>1.5].index]","8caa197f":"holidays['holiday_indicator'] = 1.0\nholidays","dc788026":"special_holidays = train.groupby('Date').mean().join(holidays, lsuffix='_', how='left')['holiday_indicator'].fillna(0)","273d3c30":"special_holidays","56f8cc8c":"X = avg_sales_.copy()\n\n# days within a week\nX[\"day\"] = X.index.dayofweek  # the x-axis (freq)\nX[\"week\"] = X.index.week  # the seasonal period (period)\n\n# days within a year\nX[\"month\"] = X.index.month\nX[\"dayofyear\"] = X.index.dayofyear\nX[\"year\"] = X.index.year\n\n#fig, (ax0, ax1) = plt.subplots(2, 1, figsize=(11, 6))\nfig, ax = plt.subplots(figsize=(11, 5))\n\n# seasonal_plot(X, y=\"Weekly_Sales\", period=\"month\", freq=\"week\", ax=ax0)\nseasonal_plot(X, y=\"Weekly_Sales\", period=\"year\", freq=\"week\", ax=ax)\n","715e9083":"X","d7cd4e05":"avg_sales_","b8cf35dc":"plot_periodogram(avg_sales_.Weekly_Sales);","7f552f91":"from statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n\ny = avg_sales_[\"Weekly_Sales\"]\nfourier = CalendarFourier(freq=\"A\", order=30)  # 10 sin\/cos pairs for \"A\"nnual seasonality\n\ndp = DeterministicProcess(\n    index=y.index,\n    constant=True,               # dummy feature for bias (y-intercept)\n    order=1,                     # trend (order 1 means linear)\n    seasonal=True,               # weekly seasonality (indicators)\n    additional_terms=[fourier],  # annual seasonality (fourier)\n    drop=True,                   # drop terms to avoid collinearity\n)\n\nX = dp.in_sample()  # create features for dates in tunnel.index","e06e0a07":"y = avg_sales_[\"Weekly_Sales\"]\n\nmodel = LinearRegression(fit_intercept=False)\n_ = model.fit(X, y)\n\ny_pred = pd.Series(model.predict(X), index=y.index)\nX_fore = dp.out_of_sample(steps=90)\ny_fore = pd.Series(model.predict(X_fore), index=X_fore.index)\n\nax = y.plot(color='0.25', style='.', title=\"Walmart sales - Seasonal Forecast\")\nax = y_pred.plot(ax=ax, label=\"Seasonal\")\nax = y_fore.plot(ax=ax, label=\"Seasonal Forecast\", color='C3')\n_ = ax.legend()","fa205be5":"\ndept_1_y","1f61a9b5":"from statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n\ndept_1_y = train[train.Dept == 1].groupby('Date').mean().Weekly_Sales\nfourier = CalendarFourier(freq=\"A\", order=50)  # 10 sin\/cos pairs for \"A\"nnual seasonality\n\ndp = DeterministicProcess(\n    index=y.index,\n    constant=True,               # dummy feature for bias (y-intercept)\n    order=0,                     # trend (order 1 means linear)\n    seasonal=True,               # weekly seasonality (indicators)\n    additional_terms=[fourier],  # annual seasonality (fourier)\n    drop=True,                   # drop terms to avoid collinearity\n)\n\nX = dp.in_sample()  # create features for dates in tunnel.index\n\n#plot_periodogram(dept_1_y);","d9d0df00":"plot_periodogram(dept_1_y);","b8272e67":"for i in tmp.loc[1,:,:].index.get_level_values(1).drop_duplicates():\n    print(i)","8a6bf693":"train.Dept.drop_duplicates().values","2337bfa5":"tmp = train.reset_index().set_index(['Store','Dept','Date'])['Weekly_Sales']\ny_ = pd.DataFrame() #tmp.loc[1,1,:].reset_index(level=1)\ncols = tmp.loc[1,:,:].index.get_level_values(1).drop_duplicates()\nfor i in cols:\n    y_ = pd.concat([y_,tmp.loc[1,i,:].reset_index(level=1)], axis=1)\n\ny_ = y_.droplevel(0)['Weekly_Sales']\ny_= y_.fillna(0)","e9d3738e":"y_.columns = cols","99d09113":"np.log1p(tmp.loc[1,1,:]).plot(kind='hist')\ntmp.loc[1,1,:].plot(kind='hist')","7c25debb":"y_","60d045bf":"model.predict(X)[:,0].shape","1c5886f5":"dp.out_of_sample(steps=720)","da3c25cf":"model.coef_.shape","d578c451":"pred.shape\ny_.shape","8c92fd62":"#y = avg_sales_[\"Weekly_Sales\"]\n\nmodel = LinearRegression(fit_intercept=False)\n_ = model.fit(X, y_)\n\ndept_sample = [1,2,3]#np.random.choice(cols, size=3)\n\nfig , axs = plt.subplots(nrows= 3,ncols = 1, figsize=(16, 16))\n\npred = model.predict(X)\nX_fore = dp.out_of_sample(steps=720)\nfore = model.predict(X_fore)\nfor i in range(3):\n    ax = y_[[dept_sample[i]]].plot(ax=axs[i], **plot_params)#(color='0.25', style='.')\n    y_pred = pd.Series(pred[:,i], index=y_.index)\n    y_fore = pd.Series(fore[:,i], index=X_fore.index)\n    y_fore_ = y_fore.to_frame('Weekly_Sales').reset_index()\n    y_fore_.columns = ['Date','Weekly_Sales']\n    y_fore_ = y_fore_.set_index('Date')\n    ax = y_fore_.resample(rule='W-WED').mean().plot(ax=ax)\n\n\n    #ax = y.plot(color='0.10', style='*-', title=\"Walmart sales - Seasonal Forecast\")\n    ax = y_pred.plot(ax=axs[i], label=\"Seasonal predict\")\n    #ax = y_fore.plot(ax=axs[i], label=\"Seasonal forecast\")\n#ax = y_fore.plot(ax=ax, label=\"Seasonal Forecast\", color='C3')\n\n_ = ax.legend()","cc87bfb2":"cols","3448d4c2":"y_log = np.log1p(y_).fillna(0.0)\nmodel = LinearRegression(fit_intercept=False)\n_ = model.fit(X, y_log)\n\ndept_sample = [ 4,  5,  6]#np.random.choice(cols, size=3)\n\nfig , axs = plt.subplots(nrows= 3,ncols = 1, figsize=(16, 16))\n\npred = model.predict(X)\nX_fore = dp.out_of_sample(steps=720)\nfore = model.predict(X_fore)\nfor i in range(3):\n    ax = y_log[[dept_sample[i]]].plot(ax=axs[i], **plot_params)#(color='0.25', style='.')\n    y_pred = pd.Series(pred[:,i+3], index=y_.index)\n    y_fore = pd.Series(fore[:,i+3], index=X_fore.index)\n    y_fore_ = y_fore.to_frame('Weekly_Sales').reset_index()\n    y_fore_.columns = ['Date','Weekly_Sales']\n    y_fore_ = y_fore_.set_index('Date')\n    ax = y_fore_.resample(rule='W-WED').mean().plot(ax=ax)\n\n\n    #ax = y.plot(color='0.10', style='*-', title=\"Walmart sales - Seasonal Forecast\")\n    ax = y_pred.plot(ax=axs[i], label=\"Seasonal predict\")\n    #ax = y_fore.plot(ax=axs[i], label=\"Seasonal forecast\")\n#ax = y_fore.plot(ax=ax, label=\"Seasonal Forecast\", color='C3')\n\n_ = ax.legend()","19c54a05":"y_fore_ = y_fore.to_frame('Weekly_Sales').reset_index()\ny_fore_.columns = ['Date','Weekly_Sales']\ny_fore_ = y_fore_.set_index('Date')\n#y_fore_.groupby([pd.Grouper(key='Date', freq='W-MON')])","00496fa2":"y_fore_.resample(rule='W-WED').mean().plot()\n","f89a3aef":"y_pred = pd.Series(model.predict(X), index=y.index)\nX_fore = dp.out_of_sample(steps=90)\ny_fore = pd.Series(model.predict(X_fore), index=X_fore.index)\n\nax = y.plot(color='0.25', style='.', title=\"Walmart sales - Seasonal Forecast\")\nax = y_pred.plot(ax=ax, label=\"Seasonal\")\nax = y_fore.plot(ax=ax, label=\"Seasonal Forecast\", color='C3')\n_ = ax.legend()","9c6c7466":"ax = y.plot(**plot_params)\nplt.plot_date(holidays.index, y[holidays.index], color='C3')\nax.set_title('Walmart sales - Check outliers');","638b8770":"X_holidays = pd.get_dummies(holidays.Weekly_Sales)\nX2 = X.join(X_holidays, on='Date').fillna(0.0)","07b05cb9":"special_holidays","4ec2b0c1":"X3 = X2.join(special_holidays.shift(1), on='Date', how='left').fillna(0.0)","97a0f767":"dp.out_of_sample(steps=90)","deab4979":"dp.out_of_sample(steps=90).shape#.join(X_holidays, how='outer').fillna(0.0).shape","37f98ede":"X4 = X.join(special_holidays.shift(1), on='Date', how='left').fillna(0.0)\nmodel_12 = LinearRegression(fit_intercept=False).fit(X4, y)\n\ny_pred = pd.Series(model_12.predict(X4), index=X3.index)\nX_fore = dp.out_of_sample(steps=730).join(special_holidays.shift(-1)).fillna(0.0)\ny_fore = pd.Series(model_12.predict(X_fore), index=X_fore.index)\n\n#ax = y.plot(color='0.25', style='.', title=\"Walmart sales - Seasonal Forecast\")\nax = y.plot(**plot_params)\nax = y_pred.plot(ax=ax, label=\"Seasonal\")\nax = y_fore.plot(ax=ax, label=\"Seasonal Forecast\", color='C3')\n_ = ax.legend()","471b375c":"model_11 = LinearRegression(fit_intercept=False).fit(X, y)\n\ny_pred = pd.Series(model_11.predict(X), index=X3.index)\nX_fore = dp.out_of_sample(steps=730).fillna(0.0)\ny_fore = pd.Series(model_11.predict(X_fore), index=X_fore.index)\n\n#ax = y.plot(color='0.25', style='.', title=\"Walmart sales - Seasonal Forecast\")\nax = y.plot(**plot_params)\nax = y_pred.plot(ax=ax, label=\"Seasonal\")\nax = y_fore.plot(ax=ax, label=\"Seasonal Forecast\", color='C3')\n_ = ax.legend()","6b5eea30":"model = LinearRegression(fit_intercept=False).fit(X3, y)\n\ny_pred = pd.Series(model.predict(X3), index=X3.index)\nX_fore = dp.out_of_sample(steps=730).join(X_holidays).join(special_holidays.shift(-1)).fillna(0.0)\ny_fore = pd.Series(model.predict(X_fore), index=X_fore.index)\n\n#ax = y.plot(color='0.25', style='.', title=\"Walmart sales - Seasonal Forecast\")\nax = y.plot(**plot_params)\nax = y_pred.plot(ax=ax, label=\"Seasonal\")\nax = y_fore.plot(ax=ax, label=\"Seasonal Forecast\", color='C3')\n_ = ax.legend()","8f186c83":"dp.in_sample().shape\n#X.shape","61af47e9":"y_deseason = dept_1_y - y_pred\ny_deseason.plot(**plot_params)","ee43dd67":"plot_periodogram(avg_sales_.Weekly_Sales);","5cf43a0e":"plot_periodogram(y_deseason)","64e10c1e":"# from statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n\nfourier = CalendarFourier(freq=\"M\", order=30)  # 10 sin\/cos pairs for \"A\"nnual seasonality\n\ndp = DeterministicProcess(\n    index=y.index,\n    constant=True,               # dummy feature for bias (y-intercept)\n    order=1,                     # trend (order 1 means linear)\n    seasonal=True,               # weekly seasonality (indicators)\n    additional_terms=[fourier],  # annual seasonality (fourier)\n    drop=True,                   # drop terms to avoid collinearity\n)\n\nX = dp.in_sample()  # create features for dates in tunnel.index\n\n# y = avg_sales_[\"Weekly_Sales\"]\n\nmodel_2 = LinearRegression(fit_intercept=False)\n_ = model_2.fit(X, y_deseason)\n\ny_pred = pd.Series(model_2.predict(X), index=y.index)\nX_fore = dp.out_of_sample(steps=90)\ny_fore = pd.Series(model_2.predict(X_fore), index=X_fore.index)\n\nax = y_deseason.plot(**plot_params, title=\"Walmart sales - Seasonal Forecast\")\nax = y_pred.plot(ax=ax, label=\"Seasonal\")\nax = y_fore.plot(ax=ax, label=\"Seasonal Forecast\", color='C3')\n_ = ax.legend()","20e25276":"\nfrom datetime import date\nix = pd.date_range(start=date(2012, 10, 27),freq='W', periods=90)\n#test = y_fore.to_frame()\n#test['test'] = ix\n#test.drop(index)\ntest.index.name= 'Date'\n#\n#ix\n#test.reset_index(drop=True, inplace=True)\n#test.test = test.test.dt.to_period('D')\n#test.columns = ['Weekly_Sales','Date']\n#pd.DataFrame(index=ix)","93df6905":"idx = pd.date_range(\"2012-10-27\", freq=\"W\", periods=1)\nX_fore.asfreq(freq='W')","daeb32d1":"y_deseason_2 = y_deseason - y_pred\nplot_periodogram(y_deseason_2)","dfc6bfc8":"ax = y_deseason_2.plot(**plot_params)\ny_deseason.plot(ax = ax)","203356c0":"test = pd.read_csv('.\/test.csv')\ntest","dc30d1b9":"from learntools.time_series.style import *  # plot style settings\nfrom learntools.time_series.utils import plot_lags, make_lags, make_leads\nfrom sklearn.metrics import mean_squared_log_error, mean_squared_error\nfrom statsmodels.graphics.tsaplots import plot_pacf\nfrom statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess","e5f19813":"plot_pacf(y_deseason, lags=14);\nplot_lags(y_deseason, lags=14, nrows=3)","18568111":"make_lags(y_deseason, lags=3)[['y_lag_1','y_lag_3']]","0015dffe":"X_lags = make_lags(y_deseason, lags=6)#[['y_lag_1','y_lag_3']]# \ud544\uc694\ud55c \uac83\ub9cc\n\n# X_promo = pd.concat([\n#     make_lags(onpromotion, lags=1),\n#     onpromotion,\n#     make_leads(onpromotion, leads=1),\n# ], axis=1)\n\n\n#X = pd.concat([X_lags, y_deseason], axis=1)\ny_, X_ = y_deseason.align(X_lags, join='inner')","ca8755e4":"X_","7ab9471e":"X_lags.shape","7d0f3bc8":"from sklearn.model_selection import train_test_split\n\nX_ = X_.fillna(0.0)\nX_train, X_valid, y_train, y_valid = train_test_split(X_, y_, test_size=30, shuffle=False)\n\nmodel_2 = LinearRegression(fit_intercept=False).fit(X_train, y_train)\ny_fit = pd.Series(model_2.predict(X_train), index=X_train.index)#.clip(0.0)\ny_fore_2 = pd.Series(model_2.predict(X_valid), index=X_valid.index)#.clip(0.0)\n\n# rmsle_train = mean_squared_log_error(y_train, y_fit) ** 0.5\n# rmsle_valid = mean_squared_log_error(y_valid, y_pred) ** 0.5\n# print(f'Training RMSLE: {rmsle_train:.5f}')\n# print(f'Validation RMSLE: {rmsle_valid:.5f}')\n\n#ax = y.plot(**plot_params, alpha=0.5, title=\"Average Sales\", ylabel=\"items sold\")\nax = y_deseason.plot(**plot_params)\n#ax = onpromo.plot(**plot_params, ax=ax, alpha=0.8)\nax = y_fit.plot(ax=ax, label=\"Fitted\", color='C0')\nax = y_fore_2.plot(ax=ax, label=\"Forecast\", color='C3')\nax.legend()","5245429c":"# X_lags = make_lags(y_deseason, lags=3)[['y_lag_1','y_lag_3']]# \ud544\uc694\ud55c \uac83\ub9cc\n# y_, X_ = y_deseason.align(X_lags, join='inner')\n# X_ = X_.fillna(0.0)\n# X_train, X_valid, y_train, y_valid = train_test_split(X_, y_, test_size=30, shuffle=False)\n\n# model = LinearRegression(fit_intercept=False).fit(X_train, y_train)\n# y_fit2 = pd.Series(model.predict(X_train), index=X_train.index)#.clip(0.0)\n# y_fore_22 = pd.Series(model.predict(X_valid), index=X_valid.index)#.clip(0.0)\n\n# # rmsle_train = mean_squared_log_error(y_train, y_fit) ** 0.5\n# # rmsle_valid = mean_squared_log_error(y_valid, y_pred) ** 0.5\n# # print(f'Training RMSLE: {rmsle_train:.5f}')\n# # print(f'Validation RMSLE: {rmsle_valid:.5f}')\n\n# #ax = y.plot(**plot_params, alpha=0.5, title=\"Average Sales\", ylabel=\"items sold\")\n# ax = y_deseason.plot(alpha=0.4)\n# #ax = onpromo.plot(**plot_params, ax=ax, alpha=0.8)\n# ax = y_fit2.plot(ax=ax, label=\"Fitted\", color='C0')\n# ax = y_fore_22.plot(ax=ax, label=\"Forecast\", color='C3')\n# ax.legend()","9b07be18":"y_fore_2","3a51ce36":"y_fore_2","b1d89672":"a,b = y_fore_2.align(y_pred)#.fillna(0.0)\n","bfddc01f":"(a.fillna(0.0)+b)","08cdfa84":"b","06ee93ff":"a.dropna()","e456359b":"ax = dept_1_y.plot(**plot_params)\n#ax = (y_pred).plot(ax=ax, label=\"Fitted\", color='C0', alpha=0.6) # season\ub9cc \uc801\uc6a9\ud588\uc744 \ub54c \nax = (y_pred+y_fit).plot(ax=ax, label=\"Fitted\", color='C3') # season + cycle \uc801\uc6a9\n(a.fillna(0.0)+b).loc['2012-04-06':].plot(ax=ax, label=\"Forecast\", color='C4') # season + cycle \uc801\uc6a9 \uc608\uce21\uac12","f31cf74b":"y_train - (a.fillna(0.0)+b)","28ffe01a":"rmsle_train = mean_squared_error(dept_1_y, y_pred) ** 0.5\nprint(f'Only seasonality Training RMSLE: {rmsle_train:.5f}')\n\nrmsle_train = mean_squared_error(y_train, (y_fit)) ** 0.5\nprint(f'Seasonality + Cycle Training RMSLE: {rmsle_train:.5f}')\n\n\nrmsle_train = mean_squared_error(y_valid, (y_fore_2)) ** 0.5\nprint(f'Valid RMSLE: {rmsle_train:.5f}')\n\n# print(f'Validation RMSLE: {rmsle_valid:.5f}')\n","24515219":"a,b = y_fore_2.align(y_pred)#.fillna(0.0)\n\na","07175fab":"b","8b60e41a":"(a.fillna(0.0)+b).loc['2010-02-05':]","e4d58dd0":"y_resid.dropna()\ny_train","0cc68070":"xgb.predict(X_train).shape","a0b0b057":"y_pred.loc['2012-04-06':]\ny_fore_2","ca7ee23a":"from xgboost import XGBRegressor\n\n\ny_resid = y.loc[:'2012-04-05'] - (a.fillna(0.0)+b).loc[:'2012-04-05'].dropna()\n# Train XGBoost on the residuals\nxgb = XGBRegressor()\nxgb.fit(X_train, y_resid)\n\n# Add the predicted residuals onto the predicted trends\ny_fit_boosted = xgb.predict(X_train) + (y_pred+y_fit).dropna()\ny_pred_boosted = xgb.predict(X_valid) + (y_pred.loc['2012-04-06':]+y_fore_2).dropna()  # \uc55e\uc758 seasonality\uc5d0\uc11c train test\ub97c \uc548 \ub098\ub204\uace0 \uadf8\ub0e5 \ud574\uac00\uc9c0\uace0.","e1c00c5c":"ax = y.plot(**plot_params)\nax = y_fit_boosted.plot(label=\"Fitted\", color='C0', alpha=0.6) # season\ub9cc \uc801\uc6a9\ud588\uc744 \ub54c \nax = y_pred_boosted.plot(ax=ax, label=\"Fitted\", color='C3') # season + cycle \uc801\uc6a9\n#y_fore_2.plot(ax=ax)\n#(a.fillna(0.0)+b).loc['2012-04-06':].plot(ax=ax, label=\"Forecast\", color='C4') # season + cycle \uc801\uc6a9 \uc608\uce21\uac12\n","3f4a5272":"import tensorflow as tf","35f0f9fa":"MAX_EPOCHS = 20\n\ndef compile_and_fit(model, window, patience=2):\n    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n                                                    patience=patience,\n                                                    mode='min')\n\n    model.compile(loss=tf.losses.MeanSquaredError(),\n                optimizer=tf.optimizers.Adam(),\n                metrics=[tf.metrics.MeanAbsoluteError()])\n\n    history = model.fit(window.train, epochs=MAX_EPOCHS,\n                      validation_data=window.val,\n                      callbacks=[early_stopping])\n    return history","1da91223":"CONV_WIDTH = 30\nconv_model = tf.keras.Sequential([\n    tf.keras.layers.Conv1D(filters=32,\n                           kernel_size=(CONV_WIDTH,),\n                           activation='relu'),\n    tf.keras.layers.Dense(units=32, activation='relu'),\n    tf.keras.layers.Dense(units=1),\n])","c0781299":"\ucc28\uc218\uac00 \ub192\uc744 \ub54c (order=20 -> 30 ) holidy pred\uac12 \uc815\ud655\ub3c4 \uc62c\ub9ac\ub824\uace0 X2 -> X3\ub85c \ud6c8\ub828\uc2dc\ud0a8 \uac74 \uc774\ub807\uac8c \uacb0\uacfc\uac00 \ub098\uc624\ub124...\n- \ubc11\uc5d0 \uadf8\ub798\ud504\ub294 X4 \ub370\uc774\ud130 (holiday \ub370\uc774\ud130 \ube7c\uace0 holiday_indicator(\ub9e4\ucd9c \ud655 \uc624\ub974\ub294 \ud734\uc77c lead data))\ub85c \ud6c8\ub828\uc2dc\ucf30\uc744 \ub54c","9021a5a8":"Check outlier from average sales which looks like holiday.","be7b91c0":"###  y_\uc5d0 log1p \uc801\uc6a9\ub418\ub294\uc9c0 \ud655\uc778","f684c6ed":"It looks the data has an annual cycle.","72f5afda":"\uc784\uacc4\uce58 \ub118\uc740? lag\ub9cc \ubf51\uc544\ub2e4\uac00 \uc37c\ub294\ub370 \ud06c\uac8c \ub3c4\uc6c0\uc774 \ub418\ub294 \uac83 \uac19\uc9c0 \uc54a\ub2e4.","2ab35fa3":"## target\uac12\uc5d0 log1p \ud574\uc900 \ud6c4 \ud559\uc2b5 -> \uacb0\uacfc \ud655\uc778\n- \uc721\uc548\uc73c\ub85c \ud070 \ucc28\uc774\ub294 \uc5c6\ub294 \ub4ef \ud55c\ub370 rmse \uacc4\uc0b0\uc744","01f4c551":"# \uc5ec\uae30\uae4c\uc9c0 \uc0ac\uc6a9 \uc548 \ud568----------------","33b2577a":"# \ud478\ub9ac\uc5d0\ud568\uc218 \ucc28\uc218\uac00 10\uc774\uc5c8\uc744 \ub54c \ud2b9\uc774\uc810 \ubc18\uc601\uc774 \uc548 \ub418\uc5b4\uc11c \ud55c \uc791\uc5c5. \n- order=30\uae4c\uc9c0 \uc62c\ub9ac\ub2c8 \ud2b9\uc774\uc810 \uc801\uc6a9\uc774 \ub418\ub124.. \n- \ucc28\uc218 \ub192\uc73c\uba74 \uacc4\uc0b0 \uc624\ub798 \uac78\ub9ac\ub824\ub098?","a4584905":"## DeterministicProcess\uc5d0\uc11c trend order = 0\uc73c\ub85c \uc124\uc815","f1ed22f4":"holiday indicator\ub294 \uadf8\ub2e5 \uc18c\uc6a9\uc774 \uc5c6\ub294\ub4ef ;;;","92314200":"Fuel_price Graph","a5a1c571":"# 1. Check seasonality","da030460":"# TF\ub85c \uc608\uce21\ud574\ubcf4\uae30. \n- \uc65c? \uc77c\ubc18 \uba38\uc2e0\ub7ec\ub2dd\uc73c\ub85c\ub294 \ud2b9\uc815 \ud734\uc77c(\ucd94\uc218\uac10\uc0ac\uc808? \ud06c\ub9ac\uc2a4\ub9c8\uc2a4)\uc758 \ub9e4\ucd9c\uc774 \ubc18\uc601\uc774 \uc548 \ub418\uae30 \ub54c\ubb38\uc784","0976c934":"Remove the annaul cycle and see periodogram. <br>\norder=30\uc73c\ub85c \ud55c \ud6c4 \uacb0\uacfc\uc784","8648df85":"Check how to sumit forecast result:\n- id: store-dept-date","e9b18bfe":"# residual \uacc4\uc0b0","9d79ec7f":"Feature graph on Time for Store. <br> \nTheir entire flows are similar and their correlations are low by heatmap. <br>\nMaybe check they affect department sales.","9a9d8652":"\uc774\uac74 order=10\uc77c \ub54c","e270ce5c":"# 2. Cycle","ab2c2cd4":"Moving average with 7 days","78a3c575":"# \uc5ec\uae30\ub294 seasonality \ud55c\ubc88 \ub354 \uccb4\ud06c\ud558\uace0 \uac78\ub7ec\ub0b4\ub294 \uac74\ub370 \uc548 \ud574\ub3c4 \ub428"}}