{"cell_type":{"626ec24a":"code","0b5faefb":"code","b79d5804":"code","3527bc60":"code","2abe3cc9":"code","6a602bf6":"code","17b44de3":"code","edede069":"code","15f194db":"code","15716812":"code","54aef18e":"code","bee43196":"code","640b31ca":"code","1549b059":"code","6ffd9e5f":"markdown","7ec387e8":"markdown","cc5c9aba":"markdown","f855e106":"markdown","74ed6fe3":"markdown","56a146c1":"markdown","f90b41d7":"markdown","96a2f2f4":"markdown"},"source":{"626ec24a":"%matplotlib inline\n\nfrom random import randint\nimport numpy as np\nimport torch\nimport shutil\nimport string\nimport nltk.data\nimport matplotlib\n\nmatplotlib.rcParams['figure.figsize'] = (20.0, 10.0)","0b5faefb":"# here we need to restructure working directory, so that script imports working properly\nshutil.copytree(\"\/kaggle\/input\/infersent\/\", \"\/kaggle\/working\/infersent\")\n! mv \/kaggle\/working\/infersent\/* \/kaggle\/working\/","b79d5804":"%%time\n\n# TODO: add encoder to dataset as well\n# If this cell freezes, probably you haven't enabled Internet access for the notebook\n! mkdir encoder\n! curl -Lo encoder\/infersent1.pkl https:\/\/dl.fbaipublicfiles.com\/infersent\/infersent1.pkl","3527bc60":"model_version = 1\nMODEL_PATH = \"encoder\/infersent%s.pkl\" % model_version\nW2V_PATH = '\/kaggle\/input\/glove-840b-300d\/glove.840B.300d.txt'\nVOCAB_SIZE = 1e5  # Load embeddings of VOCAB_SIZE most frequent words\nUSE_CUDA = False  # Keep it on CPU if False, otherwise will put it on GPU","2abe3cc9":"from models import InferSent\nparams_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n                'pool_type': 'max', 'dpout_model': 0.0, 'version': model_version}\nmodel = InferSent(params_model)\nmodel.load_state_dict(torch.load(MODEL_PATH))","6a602bf6":"%%time\nmodel = model.cuda() if USE_CUDA else model\n\nmodel.set_w2v_path(W2V_PATH)\n\nmodel.build_vocab_k_words(K=VOCAB_SIZE)","17b44de3":"sentences = ['Everyone really likes the newest benefits',\n 'The Government Executive articles housed on the website are not able to be searched .',\n 'I like him for the most part , but would still enjoy seeing someone beat him .',\n 'My favorite restaurants are always at least a hundred miles away from my house .',\n 'What a day !',\n 'What color is it ?',\n 'I know exactly .']","edede069":"tokenizer = nltk.data.load('tokenizers\/punkt\/english.pickle')\n\ndef format_text(text):\n    global tokenizer\n    padded_text = text.translate(str.maketrans({key: \" {0} \".format(key) for key in string.punctuation}))\n    return tokenizer.tokenize(padded_text)\n\ntext = 'Everyone really likes the newest benefits. The Government Executive articles housed on the website are not able to be searched.'\\\n'I like him for the most part, but would still enjoy seeing someone beat him. My favorite restaurants are always at least a hundred '\\\n'miles away from my house. What a day! What color is it? I know exactly.'\n\nsentences = format_text(text)\nsentences","15f194db":"embeddings = model.encode(sentences, bsize=128, tokenize=False, verbose=True)\nprint('nb sentences encoded : {0}'.format(len(embeddings)))","15716812":"np.linalg.norm(model.encode(['the cat eats.']))","54aef18e":"def cosine(u, v):\n    return np.dot(u, v) \/ (np.linalg.norm(u) * np.linalg.norm(v))\n\ncosine(model.encode(['the cat eats.'])[0], model.encode(['the cat drinks.'])[0])","bee43196":"idx = randint(0, len(sentences) - 1)\n_, _ = model.visualize(sentences[idx])","640b31ca":"_, _ = model.visualize('The cat is drinking milk.')","1549b059":"%%time\nmodel.build_vocab_k_words(5e5) # getting 500K words vocab\n_, _ = model.visualize(\"barack-obama is the former president of the United-States.\")","6ffd9e5f":"If you have a text in a single string, you can use `format_text` helper funtion to split it by sentences and pad appropriately","7ec387e8":"## Visualization","cc5c9aba":"## Encode Sentences","f855e106":"## Environment Setup","74ed6fe3":"We need to specify input sentences as a list, where each punctuation sign is padded with a space from both sides","56a146c1":"## InferSent demo\n#### Disclaimer: this notebook is adaptation of [InferSent Github repo](https:\/\/github.com\/facebookresearch\/InferSent)\nInferSent is a sentence embeddings method that provides semantic representations for English sentences. It is trained on natural language inference data and generalizes well to many different tasks.\n\nIn this notebook we only present InferSent pretrained on GloVe. For model pretrained on fastText, please fork this notebook and substitute appropriate binaries from official repository","f90b41d7":"## Load Model","96a2f2f4":"* gpu mode : >> 1000 sentences\/s\n* cpu mode : ~100 sentences\/s"}}