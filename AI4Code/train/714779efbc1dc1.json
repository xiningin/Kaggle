{"cell_type":{"2d2d49e9":"code","4e318217":"code","c3e614e3":"code","16a08c02":"code","33a6b93a":"code","81b1c0b6":"code","4bd62439":"code","9ed9e2bc":"code","272e3b66":"code","8b271916":"code","d542e660":"markdown"},"source":{"2d2d49e9":"import os\nimport pandas as pd\nimport numpy as np\nimport cv2 as cv\nimport glob\n\nfrom tqdm.auto import tqdm\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nimport albumentations\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport sys\nsys.path.append('..\/input\/timm-pytorch-image-models\/pytorch-image-models-master')\nimport timm\n\nimport gc\ngc.enable()\n\nimport warnings\nimport sklearn.exceptions\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)","4e318217":"if torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')","c3e614e3":"class PetNet(nn.Module):\n    def __init__(self, model_name, out_features, inp_channels, pretrained, num_dense):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=inp_channels)\n        n_features = self.model.head.in_features\n        self.model.head = nn.Linear(n_features, 128)\n        self.fc = nn.Sequential(\n            nn.Linear(128 + num_dense, 64),\n            nn.ReLU(),\n            nn.Linear(64, out_features)\n        )\n        self.dropout = nn.Dropout(0.2)\n    \n    def forward(self, image, dense):\n        embeddings = self.model(image)\n        x = self.dropout(embeddings)\n        x = torch.cat([x, dense], dim=1)\n        output = self.fc(x)\n        return output","16a08c02":"def test_fn(test_loader, model, device):\n    model.eval()\n    stream = tqdm(test_loader)\n    final_outputs = []\n    \n    with torch.no_grad():\n        for i, (image, dense) in enumerate(stream, start=1):\n            image = image.to(device, non_blocking=True)\n            dense = dense.to(device, non_blocking=True)\n            output = model(image, dense)\n            outputs = (torch.sigmoid(output).detach().cpu().numpy()*100).tolist()\n            final_outputs.extend(outputs)\n        \n    return final_outputs","33a6b93a":"def test_transform_object(DIM = 384):\n    return albumentations.Compose(\n        [\n            albumentations.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(p=1.0)\n        ]\n    )","81b1c0b6":"class PetTestset(Dataset):\n    \n    def __init__(self, image_paths, dense_features, transform=None):\n        self.image_paths = image_paths\n        self.dense_feats = dense_features\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, index):\n        #read the image using the path.\n        img = cv.imread(self.image_paths[index], 1)\n        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n        img = cv.resize(img, (224, 224), interpolation = cv.INTER_AREA)\n#         img = np.transpose(img, (2, 0, 1))\n#         img = torch.Tensor(img)\n        \n        if self.transform is not None:\n            img = self.transform(image=img)['image']\n            \n        img = img.float()\n            \n        #get the dense features.\n        dense = self.dense_feats[index, :]\n        \n        return (img, dense)","4bd62439":"predicted_labels = None\nmodels_dir = '..\/input\/modelv7'\nmodel_params = {\n    'model_name' : 'swin_small_patch4_window7_224',\n    'out_features' : 1,\n    'inp_channels' : 3,\n    'num_dense' : 12,\n    'pretrained' : False\n}\n\ndef get_testset(df, images):\n    ids = list(df['Id'])\n    image_paths = [os.path.join(images, idx + '.jpg') for idx in ids]\n    df.drop(['Id'], inplace=True, axis=1)\n    dense_feats = df.values\n    test_transform = test_transform_object()\n    return PetTestset(image_paths, dense_feats, test_transform)\n\noutputs = None\nfor model_name in glob.glob(models_dir + '\/*.pth'):\n    model = PetNet(**model_params)\n    model.load_state_dict(torch.load(model_name))\n    model = model.to(device)\n    \n    test_images = '..\/input\/petfinder-pawpularity-score\/test'\n    test_df = pd.read_csv('..\/input\/petfinder-pawpularity-score\/test.csv')\n    testset = get_testset(test_df, test_images)\n    test_loader = DataLoader(testset, batch_size=16, shuffle=False)\n    \n    if outputs is None:\n        outputs = test_fn(test_loader, model, device)\n    else:\n        temp = test_fn(test_loader, model, device)\n        for i in range(len(temp)):\n            outputs[i].append(temp[i][0])\n            \nfor i in range(len(outputs)):\n    outputs[i] = [sum(outputs[i]) \/ (len(glob.glob(models_dir + '\/*.pth')))]","9ed9e2bc":"sub_csv = pd.read_csv('..\/input\/petfinder-pawpularity-score\/sample_submission.csv')\nfor i in range(len(outputs)):\n    sub_csv.loc[i, 'Pawpularity'] = outputs[i][0]","272e3b66":"sub_csv.to_csv('submission.csv', index=False)","8b271916":"sub_csv.head()","d542e660":"## For the training part refer to link https:\/\/www.kaggle.com\/nayakroshan\/pytorch-efficientnet-folds"}}