{"cell_type":{"43c479f5":"code","4347df69":"code","4908372a":"code","6568ca7d":"code","12015770":"code","1c87964e":"code","f92675f8":"code","c99b2a3f":"code","55573776":"code","9ac455be":"code","00d1d174":"code","ca532bb1":"code","13d4436f":"code","0350ca06":"markdown","85f7d6b3":"markdown","8eb98910":"markdown","7b94aaee":"markdown","69a07960":"markdown","3f6162c4":"markdown","d1abfff5":"markdown","052c8e45":"markdown","6aafd8d6":"markdown","eaa43ecc":"markdown","199e0930":"markdown"},"source":{"43c479f5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4347df69":"import pandas as pd\n\nimport nltk\n\nfrom gensim.utils import simple_preprocess\n'''\ngensim.utils.simple_preprocess(doc, deacc=False, min_len=2, max_len=15)\nConvert a document into a list of lowercase tokens, \nignoring tokens that are too short or too long.\n'''\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom sklearn.svm import LinearSVC","4908372a":"train_data = pd.read_csv(\"..\/input\/i2a2-nlp-2021-text-classification\/train.csv\",\n                         usecols = [\"title\", \"category\", \"label_quality\"])\n\ntest_data = pd.read_csv(\"..\/input\/i2a2-nlp-2021-text-classification\/test.csv\",\n                         usecols = [\"title\", \"id\"])","6568ca7d":"train_data_sample = train_data[train_data[\"label_quality\"] == \"reliable\"]\n\ntrain_data_sample.describe()","12015770":"\"\"\"\ntrain_data_sample = train_data.sample(n = int(train_data.shape[0] * 0.05))\n\ntrain_data_sample.describe()\n\"\"\"","1c87964e":"train_data_sample.head()","f92675f8":"stop_words = nltk.corpus.stopwords.words(['portuguese','spanish'])\n\ntrain_data_sample[\"title\"] = train_data_sample[\"title\"].apply(lambda x: \" \".join([word for word in simple_preprocess(x) \n                                                                                  if word not in stop_words]))\n\ntest_data[\"title\"] = test_data[\"title\"].apply(lambda x: \" \".join([word for word in simple_preprocess(x) \n                                                                  if word not in stop_words]))\n\ntrain_data_sample.head()","c99b2a3f":"X_train = train_data_sample['title']\n\nX_test = test_data[\"title\"]\n\ny = train_data_sample['category']","55573776":"vect = TfidfVectorizer()\n\nX_train = vect.fit_transform(X_train)\n\nX_test = vect.transform(X_test)","9ac455be":"'''\n!pip3 install tensorflow_text>=2.0.0rc0\nimport tensorflow_hub as hub\nimport tensorflow_text\n\ndef embed_document(data):\n    model = hub.load(\"https:\/\/tfhub.dev\/google\/universal-sentence-encoder-multilingual\/3\")\n    embeddings = np.array([np.array(model([i])) for i in data])\n    return pd.DataFrame(np.vstack(embeddings))\n\nX_train_vec = embed_document(X_train)\nX_test_vec = embed_document(X_test)\n'''","00d1d174":"model = LinearSVC()\n\nmodel = model.fit(X_train, y)\n\npredict = model.predict(X_test)","ca532bb1":"output = pd.DataFrame({'id': test_data[\"id\"],\n                       'category': predict})\n\noutput.to_csv('Sumbmission - 3.csv', index = False)\n\noutput.head()","13d4436f":"test_data.head()","0350ca06":"# Model","85f7d6b3":"## Google\u2019s Universal Sentence Encoder","8eb98910":"## Import data","7b94aaee":"# Data","69a07960":"## Tf-Idf vectorizer","3f6162c4":"## Text Preprocessing","d1abfff5":"# Libraries","052c8e45":"## Linear SVC","6aafd8d6":"## Submission","eaa43ecc":"## Train Data Sample","199e0930":"## Split Data"}}