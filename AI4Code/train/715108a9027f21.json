{"cell_type":{"6e5e01b4":"code","7f57a160":"code","81afe1c0":"code","bbb7dc87":"code","f1096289":"code","cfac7e63":"code","b773a4bd":"code","c8cde09c":"code","7304c066":"code","12a69d06":"code","7cd49cc6":"code","c6bd695e":"code","daf23397":"code","bfa43779":"code","14425124":"code","afe6b3e0":"code","00928439":"code","837cd7ba":"code","51867ab9":"code","49c7d8a8":"code","248bb889":"code","4f3ea522":"code","d826b5a5":"code","53371a03":"code","6097a622":"code","c57d3ea4":"code","1ba30719":"code","b1184b23":"code","94e3f162":"code","fb321211":"code","d650ae74":"code","b2f9c042":"code","c83665f1":"code","d285f9b1":"code","47a3d666":"code","9a620783":"code","9314adbb":"code","8f879fe7":"markdown","ae53363d":"markdown","13145c09":"markdown","9a07f5e7":"markdown","56988bb7":"markdown","18b53df4":"markdown","3aabb726":"markdown","e138c212":"markdown","47b94bd3":"markdown","ca401985":"markdown","720577d2":"markdown","c3c5e1e4":"markdown","1a176f61":"markdown","5296d560":"markdown","6ad3dc44":"markdown","c0d68845":"markdown","73aa6c87":"markdown","36b332f1":"markdown","97bc790d":"markdown","c4a7fbf4":"markdown","94c3c35a":"markdown","81ae195d":"markdown","b0d11fe8":"markdown","7b614858":"markdown","c88579a1":"markdown","35e48e63":"markdown","271dfa85":"markdown","a8e7021e":"markdown","d1591e3c":"markdown","34cbe5a7":"markdown","347f391b":"markdown","061c030a":"markdown","ddac2a09":"markdown","4513dd82":"markdown","c4def266":"markdown","55c3f266":"markdown","9879e811":"markdown","c29f5145":"markdown"},"source":{"6e5e01b4":"# Run these if OpenCV doesn't load\n\nimport sys\n# sys.path.append('\/Library\/Frameworks\/Python.framework\/Versions\/3.6\/lib\/python3.6\/site-packages\/cv2\/')","7f57a160":"import cv2\nimport numpy as np\nimport math\nimport matplotlib.pyplot as plt\n%matplotlib inline ","81afe1c0":"# function to plot n images using subplots\ndef plot_image(images, captions=None, cmap=None ):\n    f, axes = plt.subplots(1, len(images), sharey=True)\n    f.set_figwidth(15)\n    for ax,image,caption in zip(axes, images, captions):\n        ax.imshow(image, cmap)\n        ax.set_title(caption)","bbb7dc87":"# Here, we define some colours\nSCALAR_BLACK = (0.0,0.0,0.0)\nSCALAR_WHITE = (255.0,255.0,255.0)\nSCALAR_YELLOW = (0.0,255.0,255.0)\nSCALAR_GREEN = (0.0,255.0,0.0)\nSCALAR_RED = (0.0,0.0,255.0)\nSCALAR_CYAN = (255.0,255.0,0.0)","f1096289":"# image\nimage = np.array([[20,20,20,10,10,10], [20,20,20,10,10,10],[20,20,20,10,10,10],[20,20,20,10,10,10],[20,20,20,10,10,10],[20,20,20,10,10,10]],dtype=np.float32)\nplt.imshow(image, cmap= 'gray')","cfac7e63":"#defining the kernel\nkernel = np.array([[1,0,-1], [1,0,-1],[1,0,-1]],dtype=np.float32) \nkernel","b773a4bd":"# The output we get after convolving image with filter\noutput = cv2.filter2D(image,-1,kernel)\nprint(output)\nplt.imshow(output, cmap = 'gray')","c8cde09c":"img = cv2.imread('..\/input\/image-processing-learning\/virat1.jpg',0)\nedges = cv2.Canny(img,100,200)\nplot_image([img, edges], cmap='gray', captions = [\"Virat Kohli\", \"Virat Kohli Edge\"])\n","7304c066":"# import the tesseract library\nimport pytesseract\n# # If you don't have tesseract executable in your PATH, include the following:\n# pytesseract.pytesseract.tesseract_cmd =r'C:\\Program Files (x86)\\Tesseract-OCR\\tesseract'","12a69d06":"import matplotlib as mpl\n\ndef plotting(image, cmap = None):\n    if cmap == 'gray':\n        height, width = image.shape\n    else:      \n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        height, width, depth = image.shape\n        \n    dpi = mpl.rcParams['figure.dpi']\n    # What size does the figure need to be in inches to fit the image?\n    figsize = width \/ float(dpi), height \/ float(dpi)\n\n    # Create a figure of the right size with one axes that takes up the full figure\n    fig = plt.figure(figsize=figsize)\n\n    # Display the image.\n    plt.imshow(image, cmap)\n    ","7cd49cc6":"# Reading image and converting it into RGB\nimage = cv2.imread('..\/input\/image-processing-learning\/image2.png')\n\nplotting(image)","c6bd695e":"text = pytesseract.image_to_string(image)\nprint(text)","daf23397":"image = cv2.imread('..\/input\/image-processing-learning\/text_bicubic_y.png')\nplotting(image)","bfa43779":"# Extracting text\ntext = pytesseract.image_to_string(image)\nprint(text)","14425124":"gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\nplotting(gray, cmap = 'gray')","afe6b3e0":"# Add some Gaussian Blur\ngaussian = cv2.GaussianBlur(gray,(3,3),0)\n\n#plotting\nplotting(gaussian, cmap = 'gray')","00928439":"# Median Blur\nmedian = cv2.medianBlur(gray,3)\n\n#plotting\nplotting(median, cmap = 'gray')","837cd7ba":"text = pytesseract.image_to_string(median)\n\nprint(text)","51867ab9":"ret, simple_threshold = cv2.threshold(median,127,255,cv2.THRESH_BINARY)\nplotting(simple_threshold, cmap = 'gray')","49c7d8a8":"adaptive_threshold_mean = cv2.adaptiveThreshold(median,255,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n            cv2.THRESH_BINARY,11,2)\nadaptive_threshold_gaussian = cv2.adaptiveThreshold(median,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n            cv2.THRESH_BINARY,11,2)\n\nplot_image([adaptive_threshold_mean, adaptive_threshold_gaussian], cmap='gray', captions = [\"Adaptive Threshold Mean\", \"Adaptive Threshold Gaussian\"])","248bb889":"# Otsu's thresholding\nret2,otsu_threshold = cv2.threshold(median,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n\n# Otsu's thresholding after Gaussian filtering\nblur = cv2.GaussianBlur(median,(5,5),0)\nret3,otsu_gaussian_threshold = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\nplot_image([otsu_threshold, otsu_gaussian_threshold], cmap='gray', captions = [\"Otsu Threshold\", \"Otsu Gaussian Threshold\"])","4f3ea522":"# Now, we define structuring elements\n\nstrucEle3x3 = cv2.getStructuringElement(cv2.MORPH_RECT,(2,2))\nstrucEle5x5 = cv2.getStructuringElement(cv2.MORPH_RECT,(5,5))\nstrucEle7x7 = cv2.getStructuringElement(cv2.MORPH_RECT,(7,7))        \nstrucEle15x15 = cv2.getStructuringElement(cv2.MORPH_RECT,(15,15))\n\nplot_image([strucEle3x3, strucEle5x5, strucEle7x7, strucEle15x15], cmap='gray', captions = [\"strucEle3x3\", \"strucEle5x5\", \"strucEle7x7\", \"strucEle15x15\"])","d826b5a5":"for i in range(2):\n    imgThresh = cv2.dilate(adaptive_threshold_gaussian,strucEle3x3,iterations = 2)\n    imgThresh = cv2.erode(imgThresh,strucEle3x3,iterations = 2)\n\nplot_image([adaptive_threshold_gaussian, imgThresh], cmap='gray', captions = [\"Adaptive Threshold Gaussian\", \"Dilation and Erosion\"])            ","53371a03":"plotting(adaptive_threshold_gaussian, cmap = 'gray')","6097a622":"text = pytesseract.image_to_string(imgThresh)\n\nprint(text)","c57d3ea4":"image_reverse = cv2.bitwise_not(adaptive_threshold_gaussian)\nplotting(image_reverse, cmap = 'gray')","1ba30719":"def drawAndShowContours(wd,ht,contours,strImgName):\n    global SCALAR_WHITE\n    global SHOW_DEBUG_STEPS\n    \n    # Defining a blank frame. Since it is initialised with zeros, it will be black\n    blank_image = np.zeros((ht,wd), np.uint8)\n    #cv2.drawContours(blank_image,contours,10,SCALAR_WHITE,-1)\n    # Adding all possible contour to the blank frame \n    # Contour is white \n    cv2.drawContours(blank_image,contours,-1,SCALAR_WHITE,-1)\n    \n    #plt.imshow(blank_image, cmap = 'gray')\n    # For better clarity, lets just view countour 9\n    blank_image_contour_9 = np.zeros((ht,wd), np.uint8)\n    \n    # Let's just add contour 9th to the blank image and view it\n    cv2.drawContours(blank_image_contour_9,contours,8,SCALAR_WHITE,-1)\n    \n    # Plotting\n    plot_image([blank_image, blank_image_contour_9], cmap='gray', captions = [\"All possible contours\", \"Only the 9th contour\"])\n\n        \n    return blank_image","b1184b23":"ht = np.size(image_reverse,0)\nwd = np.size(image_reverse,1)\n\ncontours, hierarchy = cv2.findContours(image_reverse,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\nprint ('contours.shape: ' + str(len(contours)))\nim2 = drawAndShowContours(wd,ht,contours,'imgContours')","94e3f162":"class Blob:\n    currentContour = [[0,0]]\n    \n    # First, let's define the 'Blob' function, which creates a 'Blob', with all the necessary parameters\n    \n    def Blob(self,_contour):\n        self.currentContour = _contour\n        self.currentBoundingRect = cv2.boundingRect(_contour) \n        \n        \n    ","fb321211":"def drawAndShowBlobs(wd,ht,blobs,strImgName):\n    global SCALAR_WHITE\n    global SHOW_DEBUG_STEPS\n    blank_image = np.zeros((ht,wd,3), np.uint8)\n    \n    contours=[]\n    for blob in blobs:\n        contours.append(blob.currentContour)\n    #print(\"C is\", contours)  \n    contours.pop(0)\n    #print(\"contours \", contours)\n    cv2.drawContours(blank_image,contours,-1,SCALAR_WHITE,-1)\n    \n\n    plt.imshow(blank_image, cmap = 'gray')\n         \n    return blank_image ","d650ae74":"blob = Blob()\nblobs = [blob]\n\narea = 30\n\nfor contour in contours:\n    # This is an instance of the class Blob()\n    possiBlob = Blob()\n    # This is the Blob function inside the class Blob()\n    possiBlob.Blob(contour) # does it work? yes\n    contourArea = cv2.contourArea(contour)\n    if(contourArea < area):\n        blobs.append(possiBlob)\n\n# Now, using the hulls, we draw the blob objects.\n\ndots = drawAndShowBlobs(wd,ht,blobs,'Blobs')","b2f9c042":"dots_ = cv2.cvtColor(dots, cv2.COLOR_BGR2GRAY)\nimgDiff = cv2.absdiff(dots_, image_reverse)\nplotting(imgDiff, cmap = 'gray')","c83665f1":"image_clean = cv2.bitwise_not(imgDiff)\nplotting(image_clean, cmap = 'gray')","d285f9b1":"text = pytesseract.image_to_string(image_clean)\n\nprint(text)","47a3d666":"bilateral = cv2.bilateralFilter(gray,9,75,75)\n#plotting\nplotting(bilateral, cmap = 'gray')","9a620783":"adaptive_threshold_mean = cv2.adaptiveThreshold(bilateral,255,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n            cv2.THRESH_BINARY,11,2)\nadaptive_threshold_gaussian = cv2.adaptiveThreshold(bilateral,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n            cv2.THRESH_BINARY,11,2)\n\nplot_image([adaptive_threshold_mean, adaptive_threshold_gaussian], cmap='gray', captions = [\"Adaptive Threshold Mean\", \"Adaptive Threshold Gaussian\"])","9314adbb":"text = pytesseract.image_to_string(adaptive_threshold_gaussian)\n\nprint(text)","8f879fe7":"## Thresholding the image\n\nThe image after smoothing gets blurred. Generally, for OCR to work better, we want sharp borders between characters with high contrast. Binarization makes the image sharp. Also, it reduces the size of the image, which helps in preprocessing in OCR. Let's see some thresholding techniques:\n\n1. Simple Thresholding\n2. Adaptive Thresholding\n3. Otsu\u2019s Binarization\n\nhttps:\/\/opencv-python-tutroals.readthedocs.io\/en\/latest\/py_tutorials\/py_imgproc\/py_thresholding\/py_thresholding.html","ae53363d":"### Morphological transformations\nMorphological transformations is normally performed on binary images. It needs two inputs, one is the image, other is structuring element or kernel which decides the nature of operation. Two basic morphological operators are Erosion and Dilation. \nhttps:\/\/docs.opencv.org\/3.4\/d9\/d61\/tutorial_py_morphological_ops.html","13145c09":"### Converting to grayscale\nGenerally, we convert any colour image to grayscale for better perprocessing. ","9a07f5e7":"OpenCV is popular image processing library. It has wide variety of applications. Some of the popular applications are:\n1. Pre-processing image\n2. Detecting lines, circles, other shapes etc.\n3. Edge detection\n4. Image segmentation\n5. Object Tracking","56988bb7":"### Now that we are not able to extract text from image, let's try to improve the result using some pre-processing ","18b53df4":"#### Median blur","3aabb726":"## Contours\nContours is an outline representing or bounding the shape or form of something. It is a curve joining all the continuous points (along the boundary), having same color or intensity. Here, we will identify the shape of the dots using contours and remove it. Once we find all the shapes\/contours, we will identify the dots which will have shapes having areas less than certain number, aspect ratio etc.  https:\/\/docs.opencv.org\/3.3.1\/d4\/d73\/tutorial_py_contours_begin.html","e138c212":"#### Function to plot the Blob","47b94bd3":"## Edge detection example\nLet's see one more example edge detection, that is 'canny' edge detection. It is an inbuilt funtion in OpenCV. You can read more it at https:\/\/docs.opencv.org\/3.1.0\/da\/d22\/tutorial_py_canny.html","ca401985":"### You can see that results have greatly improved. But the results are not great as the text image itself had problems. ","720577d2":"# Image Processing Notebook","c3c5e1e4":"## Blob\n\n#### Defining Blob class to store the properties of the contours such as centre of contour, aspect ratio, diagonal size etc. ","1a176f61":"### Simple edge detection example","5296d560":"# Optical Character Recognition(OCR)\nHere, you will see the process of extracting text from image. You will use OpenCV to preprocess the image and use open-source tesseract library to extract text from pre-processed image","6ad3dc44":"#### Finding the dots","c0d68845":"#### You can see that the results have improved but still, the results are not that good. Let's do further preprocessing.","73aa6c87":"Here, there is not much difference between gaussian blur and median blur. ","36b332f1":"#### Finding all the possible contours in image and showing the contours. ","97bc790d":"###  Otsu's Thresholding","c4a7fbf4":"### Function to plot multiple images ","94c3c35a":"### Simple Thresholding","81ae195d":"## OpenCV vs Deep Learning Library (Keras, Tensorflow etc)\nIn Deep Learning, the kernels are learned. You have done image classification, where we just initialise the kernel(filter). The kernels are learned during backpropagation.\n\nIn OpenCV, we define particular kernel for particular task. There is no backpropagation, so the value of kernel is not changed. You have seen the example of Edge Detection, where you define a specific value of kernel $\\begin{bmatrix}\n    1 & 0 & -1  \\\\\n    1 & 0 & -1  \\\\\n    1 & 0 & -1  \n\\end{bmatrix}$ for extracting the edges. \n![edge_detection.PNG](attachment:edge_detection.PNG)","b0d11fe8":"## Another method\nLet's use bilateral filter in the first stage itself and see the results. Sometimes the filters do not only dissolve the noise, but also smooth away the edges. To avoid this (at certain extent at least), we can use a bilateral filter.","7b614858":"### Was it easy? Let's take a difficult image and try to extract text","c88579a1":"#### Image after removing the dots","35e48e63":"### Smoothening using blur\nThere is no need to do descrewing as the fonts are almost straight. The resolution of the image is also good. \n\n1. Gaussian Noise:\nGaussian Noise is modeled by adding random values to an image. Gaussian filter helps in removing Gaussian noise from the image.\n\n2. Salt and Pepper Noise:\nAn image containing salt-and-pepper noise will have dark pixels in bright regions and bright pixels in dark regions. Median Filter helps in removing salt-and-pepper noise.\n\n![blurring.PNG](attachment:blurring.PNG)\n\nLet's blur the image for smoothing. https:\/\/docs.opencv.org\/3.1.0\/d4\/d13\/tutorial_py_filtering.html\n\n1. Gaussian blur\n2. Median blur","271dfa85":"#### If you perform more dilation and erosion, the characters will also detoriate. As you can see, because of dots, the result have deteroiated instead of improving ","a8e7021e":"### Function to plot image with better aspect ratio","d1591e3c":"#### The function cv2.filter2D() in OpenCV does the convolution while preserving the image dimension.","34cbe5a7":"#### You can see that 1790 contours have been identified and we are plotting just the 9the contour which is a dot. Now, we have to remove all such dots. ","347f391b":"###  Adaptive Thresholding","061c030a":"First, we import the necessary libraries","ddac2a09":"### Reverse the image\nGenerally, the object that we want to identify is in white and background is in black when using contours. So, revering the image to convert it in required format. ","4513dd82":"#### Let's find the text output after bluring","c4def266":"#### Function to draw and show contours","55c3f266":"## Extracting text using OCR","9879e811":"#### Gaussin blur","c29f5145":"## Pre-processing techniques\nYou can improve the result by some of the following pre-processing techniques:\n1. Increasing resolution: Increase the resolution of image\n2. Deskewing: Deskew the image. It also makes it easier to do more processing.\n3. Blurring: It is useful for removing noise. \n3. Convert to Black and White: Convert the image into black and white after deskewing and resizing. It will produce consistent character size and thickness.  \n4. Remove Noise: Remove noise from black and white image. Perform operations like morphological transformation, contours etc. to remove the noise. \n5. Train Tesseract on the Font"}}