{"cell_type":{"f882b029":"code","e155ee5d":"code","aa1d9c0b":"code","d2ff65c3":"code","56665094":"markdown"},"source":{"f882b029":"def clusteringFunc(x_data,y_data,k):    \n    import numpy as np\n    from sklearn.cluster import KMeans\n\n\n \n    print('Start Clustering.............!')\n    normals=[]\n    sicks=[]\n    for i in range(len(y_data)):\n        if y_data[i]==0:\n            normals.append(x_data[i])\n        else:\n            sicks.append(x_data[i])\n\n    normals=np.array(normals)\n    sicks=np.array(sicks)\n\n\n    model=KMeans(n_clusters=k)   \n    y_n=model.fit_predict(normals)  \n    y_s=model.fit_predict(sicks)\n    \n\n    y_s2=[]\n    for item in y_s:\n        y_s2.append(item+k)\n\n\n    y_n=list(y_n)\n    y_n.extend(y_s2)\n    y=np.array(y_n)\n\n\n    normals=list(normals)\n    sicks=list(sicks)\n    normals.extend(sicks)\n    x=np.array(normals)\n\n    return x,y","e155ee5d":"def NetPlot(net_histories,n_epch):\n    import numpy as np\n    import matplotlib.pyplot as plt\n  \n    losses=[]\n    val_losses=[]\n    accuracies=[]\n    val_accuracies=[]\n\n    for item in net_histories:\n        \n        history=item.history\n        loss=history['loss']\n        val_loss=history['val_loss']\n        accuracy=history['acc']\n        val_accuracy=history['val_acc']\n        \n        losses.append(loss)\n        val_losses.append(val_loss)\n        accuracies.append(accuracy)\n        val_accuracies.append(val_accuracy)\n\n\n    losses2=np.zeros((1,n_epch))\n    val_losses2=np.zeros((1,n_epch))\n    accuracies2=np.zeros((1,n_epch))\n    val_accuracies2=np.zeros((1,n_epch))\n\n    for i in losses:\n        losses2+=i\n\n    for i in val_losses:\n        val_losses2+=i\n    \n    for i in accuracies:\n        accuracies2+=i\n    \n    for i in val_accuracies:\n        val_accuracies2+=i\n\n\n    # 10 is number of folds\n    losses2=(losses2\/10).flatten()\n    accuracies2=(accuracies2\/10).flatten()\n    val_losses2=(val_losses2\/10).flatten()\n    val_accuracies2=(val_accuracies2\/10).flatten()\n\n    plt.figure('Accracy Diagram',dpi=600)\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.plot(accuracies2,color='black')\n    plt.plot(val_accuracies2,color='green')\n    plt.legend(['Train Data','Validation Data'])\n    plt.savefig('Accuracy Diagram.jpg')\n\n    plt.figure('Loss Diagram',dpi=600)\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.plot(losses2,color='black')\n    plt.plot(val_losses2,color='green')\n    plt.legend(['Train Data','Validation Data'])\n    plt.savefig('Loss Diagram.jpg')","aa1d9c0b":"def DeepCNN(x_data,y_data,k):\n\n    import datetime\n    from sklearn.metrics import ( auc, classification_report,\n                                confusion_matrix, roc_curve)\n    from sklearn.model_selection import KFold, train_test_split\n    from keras.layers import Conv1D,Dense, Dropout, Flatten\n    from keras.losses import binary_crossentropy\n    from keras.models import Sequential\n    from keras.optimizers import Adam\n    from keras.utils import np_utils\n    from keras.callbacks import CSVLogger\n\n\n\n    print('Start Deep Learning............!')\n\n\n    lst_loss=[]\n    lst_acc=[]\n    lst_reports=[]\n    lst_AUC=[]\n    lst_matrix=[]\n    lst_times=[]\n    lst_history=[]\n    fold_number=1\n    n_epch=30\n\n    kfold=KFold(n_splits=10,shuffle=True,random_state=None)\n    for train,test in kfold.split(x_data,y_data):\n\n        x_train=x_data[train]\n        x_test=x_data[test]\n        y_train=y_data[train]\n        y_test=y_data[test]\n\n        x_train,y_train=clusteringFunc(x_train,y_train,k)\n        x_test,y_test=clusteringFunc(x_test,y_test,k)\n\n\n        x_train=x_train.reshape((x_train.shape[0],100,100))\n        x_test=x_test.reshape((x_test.shape[0],100,100))\n\n        x_train,x_valid,y_train,y_valid=train_test_split(x_train,y_train,test_size=0.2,random_state=None)\n\n\n        print(f'train: {x_train.shape}  {y_train.shape}')\n        print(f'test: {x_test.shape}  {y_test.shape}')\n        print(f'valid: {x_test.shape}  {y_valid.shape}')\n\n\n        calback=CSVLogger(f'logger_fold{fold_number}.log')\n\n        y_train=np_utils.to_categorical(y_train)\n        y_test=np_utils.to_categorical(y_test)\n        y_valid=np_utils.to_categorical(y_valid)\n\n\n\n        # CNN Architecture\n        model=Sequential()\n        model.add(Conv1D(32,3,padding='same',activation='relu',strides=2,input_shape=(100,100)))\n        model.add(Conv1D(64,3,padding='same',activation='relu',strides=2))\n        model.add(Conv1D(128,3,padding='same',activation='relu',strides=2))\n        model.add(Conv1D(256,3,padding='same',activation='relu',strides=1))\n        model.add(Conv1D(256,3,padding='same',activation='relu',strides=1))\n        model.add(Conv1D(256,3,padding='same',activation='relu',strides=1))\n        model.add(Flatten())\n        model.add(Dense(256,activation='relu'))\n        model.add(Dense(128,activation='relu'))\n        model.add(Dense(64,activation='relu'))\n        model.add(Dropout(0.5))\n        model.add(Dense(k*2,activation='sigmoid'))\n\n\n\n        model.compile(optimizer=Adam(),loss=binary_crossentropy,metrics=['accuracy'])\n            \n        start=datetime.datetime.now()\n        net_history=model.fit(x_train, y_train, batch_size=512, epochs=n_epch,validation_data=[x_valid,y_valid],callbacks=[calback])\n        end=datetime.datetime.now()\n        training_time=end-start\n\n        model.save(f'CNN_fold{fold_number}.h5')\n\n        test_loss, test_acc=model.evaluate(x_test,y_test)\n\n        predicts=model.predict(x_test)\n        predicts=predicts.argmax(axis=1)\n        actuals=y_test.argmax(axis=1)\n\n        fpr,tpr,_=roc_curve(actuals,predicts)\n        a=auc(fpr,tpr)\n        r=classification_report(actuals,predicts)\n        c=confusion_matrix(actuals,predicts)\n\n\n\n        lst_history.append(net_history)\n        lst_times.append(training_time)\n        lst_acc.append(test_acc)\n        lst_loss.append(test_loss)\n        lst_AUC.append(a)\n        lst_reports.append(r)\n        lst_matrix.append(c)\n\n        fold_number+=1\n\n        \n    # plot loss and accuracy diagrams\n    NetPlot(lst_history,n_epch)\n\n    path=f'CNN_Kmeans_Results.txt' \n    f1=open(path,'a')\n    f1.write('\\nAccuracies: '+str(lst_acc)+'\\nLosses: '+str(lst_loss))\n    f1.write('\\n\\nMetrics for all Folds: \\n\\n')\n    for i in range(len(lst_reports)):\n        f1.write(str(lst_reports[i]))\n        f1.write('\\n\\nTraining Time: '+str(lst_times[i])+'\\nAUC: '+str(lst_AUC[i]))\n        f1.write('\\n\\nCofusion Matrix: \\n'+str(lst_matrix[i])+'\\n\\n__________________________________________________________\\n')\n    f1.close()","d2ff65c3":"def Read_Data():    \n    import numpy as np\n    import cv2\n    from skimage.io import imread\n    import glob\n    import os\n\n\n    normals=[]\n    main_path='\/kaggle\/input\/myocarditis-dataset\/Normal\/'\n    main_folders=next(os.walk(main_path))[1]\n    for i in main_folders:\n        path=main_path+i+'\/'\n        folders=next(os.walk(path))[1]\n        for x in folders:\n            new_path=path+x+'\/'\n            data=glob.glob(new_path+'*.jpg')\n            if len(data)<1:\n                indent_folders=next(os.walk(new_path))[1]\n                for y in indent_folders:\n                    new_path=new_path+y+'\/'\n                    data=glob.glob(new_path+'*.jpg')\n            normals.extend(data)\n\n\n\n\n    #read sicks files\n    sicks=[]\n    main_path='\/kaggle\/input\/myocarditis-dataset\/Sick\/'\n    main_folders=next(os.walk(main_path))[1]\n    for i in main_folders:\n        path=main_path+i+'\/'\n        folders=next(os.walk(path))[1]\n        for x in folders:\n            new_path=path+x+'\/'\n            data=glob.glob(new_path+'*.jpg')\n            if len(data)<1:\n                indent_folders=next(os.walk(new_path))[1]\n                for y in indent_folders:\n                    new_path=new_path+y+'\/'\n                    data=glob.glob(new_path+'*.jpg')\n            sicks.extend(data)\n    \n    #load normal files\n    labels_n=[]\n    train_data_n=[]\n    for id in normals:    \n        img=imread(id)\n        img=cv2.resize(img,(100,100))\n        # img=img.astype('float32')\n        img=img.flatten()\n        train_data_n.append(img)\n        labels_n.append(0)\n\n\n\n    #load sick files\n    labels_s=[]\n    train_data_s=[]\n    for id in sicks:    \n        img=imread(id)\n        img=cv2.resize(img,(100,100))\n        # img=img.astype('float32')\n        img=img.flatten()\n        train_data_s.append(img)\n        labels_s.append(1)\n\n    train_data_n.extend(train_data_s)\n    labels_n.extend(labels_s)\n\n    x_data=np.array(train_data_n)\n    y_data=np.array(labels_n)\n\n    \n    # calling deep learning method\n    k=2\n    DeepCNN(x_data,y_data,k)\n\n\nRead_Data()\n","56665094":"\n# CNN-KCL: Automatic Myocarditis Diagnosis using Convolutional Neural Network Combined with K-means Clustering\n**Danial Sharifrazi et al.**\n* This code is related to the mentioned paper. Please cite the paper."}}