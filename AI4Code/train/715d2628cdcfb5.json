{"cell_type":{"6c7b276d":"code","f796c14d":"code","6fe351ac":"code","371c1472":"code","42abe19d":"code","e4b3b491":"code","83716930":"code","5e2cb695":"code","99c9a073":"code","5359ba8f":"code","475af128":"code","cf3a6ca0":"code","8c7ff325":"code","ffb30237":"code","47ce9bf1":"code","9288c8b4":"code","242b948e":"code","a44084dc":"code","ba2585e2":"code","59c71148":"code","b22a28c1":"code","fc086a96":"code","92909c9d":"code","13593083":"code","1f822549":"code","10c9c3f1":"code","5001bb5f":"code","4ddc398a":"code","f1d2d086":"code","47a0dd95":"code","f0bb05f9":"code","89bfe161":"code","256ebc7e":"markdown","edb24a01":"markdown","0bca1952":"markdown","e094d0dc":"markdown","47e4062e":"markdown","e97c4c37":"markdown","d2ad25bc":"markdown","bbadcec2":"markdown","4e7c3a61":"markdown","a4dfee2f":"markdown","a2e600ad":"markdown","7594fd18":"markdown","1b7f4345":"markdown","1f443828":"markdown","3b66df56":"markdown","502ea057":"markdown","e06f76cc":"markdown","4d09b14a":"markdown","b142191f":"markdown"},"source":{"6c7b276d":"pip install pingouin","f796c14d":"## Imports\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport folium\nfrom folium import plugins\n\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\nfrom scipy import stats\nfrom pingouin import pairwise_tukey\nimport scipy.stats as stats","6fe351ac":"## Import data\n\ndf = pd.read_csv('\/kaggle\/input\/serial_murder.csv', index_col = 0)","371c1472":"fig, ax = plt.subplots(4,2, figsize = (25, 20))\n\nplt.suptitle('Number of Proven Vitims by MO')\nax[0,0].hist(df[df['involving children'] == 1]['Proven victims'], bins = 50,)\nax[0,0].set_title('Crimes involving children')\nax[0,1].hist(df[df['sexually motivated'] == 1]['Proven victims'], bins = 50)\nax[0,1].set_title('Sexual assault')\nax[1,0].hist(df[df['torture'] == 1]['Proven victims'], bins = 50)\nax[1,0].set_title('Torture')\nax[1,1].hist(df[df['arsenist'] == 1]['Proven victims'], bins = 50)\nax[1,1].set_title('Arson')\nax[2,0].hist(df[df['cannibalism'] == 1]['Proven victims'], bins = 50)\nax[2,0].set_title('Cannibalism')\nax[2,1].hist(df[df['strangulation'] == 1]['Proven victims'], bins = 50)\nax[2,1].set_title('Strangulation')\nax[3,0].hist(df[df['guns'] == 1]['Proven victims'], bins = 50)\nax[3,0].set_title('Gun')\nax[3,1].hist(df[df['poison'] == 1]['Proven victims'], bins = 50)\nax[3,1].set_title('Poison')","42abe19d":"## Examine possible correlation between number of active years and number of active areas\n\ndf['Country'].replace('United States', 'US', inplace = True)\n\ncross_cntries = []\nfor index, row in df.iterrows():\n        \n    ## Filter to killers active in more than 2 areas\n      if len(row['Country'].split(' ')) >= 2:\n            cross_cntries.append((row['Name'], len(row['Country'].split(' ')), row['Country'], \n                          row['Number of years active']))\n\n            \nactive_areas_df = pd.DataFrame(columns = ['Name', 'Areas active', 'Countries', 'Years active'], data = cross_cntries)\nactive_areas_df = active_areas_df.sort_values(['Years active', 'Areas active'], ascending = False)","e4b3b491":"facet = sns.FacetGrid(active_areas_df, col=\"Areas active\", hue = 'Areas active', size = 10, col_wrap=3,  margin_titles=True,\n                     sharey = False)\nfacet.map(plt.hist, \"Years active\")","83716930":"plt.figure(figsize = (15, 10))\nax = sns.scatterplot(x = 'Methods of killing', y = 'Proven victims', data = df)\nax.set_title(\"Dotplot of number of MO's vs. Number of victims\")","5e2cb695":"conviction = {'prison': np.sum(df['prison']), 'execution':np.sum(df['execution']), 'mental institution':np.sum(df['mental institution']), 'suicide':np.sum(df['suicide'])}\nplt.figure(figsize=(15,10))\nplt.bar(conviction.keys(), conviction.values())\nplt.title('Types of treatment for the convicted')","99c9a073":"\ndata = [df[df['execution']==1]['Proven victims'],df[df['mental institution']==1]['Proven victims'],\n        df[df['prison']==1]['Proven victims'],df[df['suicide']==1]['Proven victims']]\nlabels=['execution','mental institution','prison','suicide']\nplt.figure(figsize=(15,10))\nboxplot = plt.boxplot(data,labels=labels,patch_artist=True)\nplt.title('Number of proven victims as per each treatment type')\ncolors = ['pink','lightblue','lightgreen','lightyellow']\nfor patch, color in zip(boxplot['boxes'], colors):\n  patch.set_facecolor(color)\nplt.ylabel('Number of proven victims')\nplt.show()","5359ba8f":"# summary statistics of each type\nfor d,con in zip(data,labels):\n  print(con.title())\n  print(d.describe(),end='\\n\\n')","475af128":"active_countries = active_areas_df['Countries'].str.replace('\\xa0\\xa0',',').tolist()\n# split each killer's active countries \ntemp = []\nfor country in active_countries:\n  country = country.replace('\\xa0',',').split(',')\n  temp.extend([c.strip() for c in country])\n\n# resolve different naming issues\ntemp2 = []\nfor country in temp:\n    if '(' in country:\n        country = country[:country.index('(')-1]\n    if country in ['Allied-occupied Germany','German Empire','German Reich','Nazi Germany','Weimar Germany', 'Weimar Republic', 'West Germany',]:\n        country = 'Germany'\n    if country == 'Kingdom of Italy':\n        country = 'Italy'\n    if country == 'Persia':\n        country = 'Iran'\n    if country == 'Ottoman Empire':\n        country = 'Turkey'\n    if country == 'Portuguese Angola':\n        country = 'Angola'\n    if country == 'Czechoslovakia':\n        country = 'Slovakia'\n    if country == 'Yugoslavia':\n        country = 'Croatia'\n    if country == 'Soviet Union':\n        country = 'Russia'\n    if country == 'Czech Republic':\n        country = 'Czechia'\n    if country == 'United States':\n        country = 'United States of America'\n    if len(country)>2:\n        temp2.append(country)\n\nactive_countries_count = {}\n\nfor country in temp2:\n      active_countries_count[country] = active_countries_count.get(country,0)+1\nactive_countries_count = dict(sorted(active_countries_count.items(), key = lambda kv:(kv[1],kv[0]), reverse=True))\n\nactive_areas_df['Countries'] = active_areas_df['Countries'].apply(lambda x: x.replace('\\xa0',','))\n\ndef Replace_cntries (country):\n    country = country.strip()\n    if '(' in country:\n        country = country[:country.index('(')-1]\n    if country in ['Allied-occupied Germany', 'German Empire','German Reich','Nazi Germany','Weimar Germany', 'Weimar Republic', 'West Germany']:\n        country = 'Germany'\n    if country == 'Kingdom of Italy':\n        country = 'Italy'\n    if country == 'Persia':\n        country = 'Iran'\n    if country == 'Ottoman Empire':\n        country = 'Turkey'\n    if country == 'Portuguese Angola':\n        country = 'Angola'\n    if country == 'Czechoslovakia':\n        country = 'Slovakia'\n    if country == 'Yugoslavia':\n        country = 'Croatia'\n    if country == 'Soviet Union':\n        country = 'Russia'\n\n    return country\n\nlocs_2 = active_areas_df.copy()[['Name', 'Countries']]\n\n## \"Explode\" cells into rows\nlocs_2 = locs_2.set_index(['Name']).apply(lambda x: x.str.split(',').explode()).reset_index()\n\n## Resolve naming issues\nlocs_2['Countries'] = locs_2['Countries'].apply(Replace_cntries)\n\n## Drop nas's\nlocs_2.drop(locs_2.index[locs_2['Countries'] == ''], axis = 0, inplace = True)\nlocs_2","cf3a6ca0":"# plot\n#y_pos = np.arange(len(active_countries_count))\n#frequency = list(active_countries_count.values())\n#labels = tuple(active_countries_count.keys())\n\n#fig, ax = plt.subplots(figsize=(15,10))\n#ax.barh(y_pos, frequency ,color='teal')\n#ax.set_yticks(y_pos)\n#ax.set_yticklabels(labels)\n#ax.invert_yaxis()\n#ax.set_xlabel('Frequency')\n#ax.set_title('Frequencies of the active countries')\n#plt.show()\nplt.figure(figsize=(15,10))\nlocs_2.Countries.value_counts().plot.barh(alpha=0.8)","8c7ff325":"## Coordinates dataset\nloc = pd.read_html('https:\/\/developers.google.com\/public-data\/docs\/canonical\/countries_csv')\nloc_df = pd.DataFrame(data = loc[0])\nloc_df.drop(['country'], axis = 1, inplace = True)\nloc_df","ffb30237":"## Rename column\n\nloc_df.rename(columns = {'name': 'Countries'}, inplace = True)\n\n## Merge loc_df and locs_2\n\nmerged_areas = locs_2.merge(loc_df, how = 'outer', on = ['Countries']).dropna().sort_values(['Name'])\nmerged_areas","47ce9bf1":"## Only keep those offenders that move across country borders as a few of them relocated within their countries\n\nnew_names = []\nfor i in merged_areas['Name'].unique():\n    cntries = set(merged_areas[merged_areas['Name'] == i]['Countries'].to_list())\n    if len(cntries) > 2:\n        new_names.append(i)\n\nnew_areas = merged_areas[merged_areas['Name'].isin(new_names)]\nnew_areas","9288c8b4":"## Create an empty map\nfolium_map = folium.Map(location=[37.2972,1.9577],  #  Europe coordinates\n                       zoom_start = 4,\n                       tiles = 'stamentoner')\n\n## Colors to identify each offender\ncolors = ['red', 'blue', 'green', 'grey', 'purple', 'orange', 'yellow', 'cyan', 'brown']\n## This is to adjust the size of the circles according to the killers' active years\nyears_active = active_areas_df[active_areas_df['Name'].isin(new_names)].sort_values(['Name'])['Years active'].to_list()\n\n\nfor killer in new_areas['Name'].unique().tolist():\n\n    color = colors[new_names.index(killer)]\n    ## Size of the marker is their number of active years\n    radius = years_active[new_names.index(killer)]\n\n    ## This is to add lines connecting the circle at the end of the for loop\n    coords = []\n\n    df1 = new_areas[new_areas['Name'] == killer]\n\n    for index, row in df1.iterrows():\n      ## Add popup text\n        popup_text = \"\"\"{}, {}, {}\"\"\"\n        popup_text = popup_text.format('Offender: ' + killer + '\\n',\n                               'Country: ' + row['Countries'] + '\\n', str(radius) + ' years')\n        lon = row['longitude']\n        lat = row['latitude']\n\n      ## Polyline requires that locations be put in a list of lists\n        coords.append([lat, lon])\n\n      ## Locate the killer's zones on map\n        folium.CircleMarker(location = (lat, lon),\n                       weight = 5, radius = radius, color = color,\n                       fill = True, fill_color = color,\n                       popup = popup_text).add_to(folium_map)\n        \n    ## Use the locations list to draw connecting lines\n    my_PolyLine=folium.PolyLine(locations=coords, weight=2, color = color)\n    folium_map.add_child(my_PolyLine)\n    \nfolium_map","242b948e":"world_homocides = pd.DataFrame(data = active_countries_count.items(), columns = ['Country', 'Total killers in area'])\nworld_homocides","a44084dc":"url = 'https:\/\/raw.githubusercontent.com\/python-visualization\/folium\/master\/examples\/data'\nworld_geo = f'{url}\/world-countries.json'\n\n## Create an empty map\nm = folium.Map(location=[37.2972,1.9577], zoom_start=3, tiles = 'stamentoner')\n\n## add choropleth layer\nchoropleth = folium.Choropleth(\n    geo_data=world_geo,\n    name='choropleth',\n    data=world_homocides,\n    columns=['Country', 'Total killers in area'],\n    key_on='feature.properties.name',\n    fill_color='OrRd',\n    fill_opacity=1,\n    line_opacity=1,\n    legend_name='Total killers in country'\n).add_to(m)\n\n# add labels indicating the name of the country\nstyle_function = \"font-size: 15px; font-weight: bold\"\nchoropleth.geojson.add_child(\n    folium.features.GeoJsonTooltip(['name'], style=style_function, labels=False))\n\n## Add layer\nfolium.LayerControl().add_to(m)\n\n## Display map\nm","ba2585e2":"## extract the serial killer group\/organization\n# remove unidentified killers\nnames = df[~(df.Notes.apply(lambda x: ('unidentified serial killer' in x.lower()) | \n                                         ('theoretical' in x.lower()) |\n                                        ('unidentified killer' in x.lower())))\n          ## remove the nicknames which represent unidentified killers\n          & ~(df.Name.apply(lambda x: ('The' in x) or ('Killer' in x) or ('Maniac' in x) or ('serial' in x)))].Name.to_list() \ngroup_names = names[names.index('Murder Incorporated'): names.index('Beasts of Satan')+1]\n#groups = df1.loc[df1.Name.isin(group_names)]\n\n## df2 only contains individual killers\ndf2 = df[df.Name.isin(names) & ~df.Name.isin(group_names)]\n\n## convert the methods of killing to a categorical variable\ndf2['Methods of killing'] = df2['Methods of killing'].astype('category')\n\n## check the value counts\ndf2['Methods of killing'].value_counts()","59c71148":"# boxplots\nplt.figure(figsize = (8, 15))\nsns.boxplot(x = 'Methods of killing', y = 'Proven victims', data = df2)\nplt.title(\"Boxplot of number of proven victims by number of MO's used\")","b22a28c1":"# Remove extreme outliers\nplt.figure(figsize = (8, 15))\nsns.boxplot(x = 'Methods of killing', y = 'Proven victims', data = df2[df2['Proven victims']<200])\nplt.title(\"Boxplot of number of proven victims by number of MO's used\")","fc086a96":"# Create a list of lists that contain the Proven victims values by Methods of killing\nmo_list = []\nfor i in df2['Methods of killing'].unique():\n    mo_list.append(df2[(df2['Methods of killing'] == i) & (df2['Proven victims']<200)]['Proven victims'].to_list())\n\n# perform one-way ANOVA test\n\nf_val, p_val = stats.f_oneway(*mo_list)\nprint(f_val, p_val)","92909c9d":"# uses panda dataframe for the one-way ANOVA test\nanova_df = df2[['Methods of killing','Proven victims']][df2['Proven victims']<200].sort_values(by='Methods of killing').reset_index(drop=True)\n\nmo1 = anova_df[anova_df['Methods of killing']==1]['Proven victims'].copy()\nmo2 = anova_df[anova_df['Methods of killing']==2]['Proven victims'].copy()\nmo3 = anova_df[anova_df['Methods of killing']==3]['Proven victims'].copy()\nmo4 = anova_df[anova_df['Methods of killing']==4]['Proven victims'].copy()\n\n\nf_val, p_val = stats.f_oneway(mo1, mo2, mo3, mo4)\nprint(f_val,p_val)","13593083":"# Ordinary Least Squares (OLS) model\n\nanova_df.columns = ['MOs','Proven_victims']\nmodel = ols(\"Proven_victims ~ MOs\", data=anova_df).fit()","1f822549":"## Post-hoc comparison using Tukey HSD test\n\n# perform multiple pairwise comparison (Tukey HSD)\n# for unbalanced data, pairwise_tukey uses Tukey-Kramer test\nm_comp = pairwise_tukey(data=anova_df, dv='Proven_victims', between='MOs')\nm_comp","10c9c3f1":"# Normal distribution of residuals\n# Null hypothesis: data is drawn from normal distribution.\n# Shapiro test\n\nw, p_value = stats.shapiro(model.resid)\nprint(w, p_value)","5001bb5f":"# Homogeneity of variances\n# Null hypothesis: samples from populations have equal variances.\n# Levene test\nl, p_value = stats.levene(mo1, mo2, mo3, mo4)\nprint(l, p_value)","4ddc398a":"import sqlite3\n\n# Establish connection and cursor\nconn = sqlite3.connect('SerialKillerData.db')\nc = conn.cursor()\n\n# Country\nc.execute('DROP TABLE IF EXISTS country;') # remove duplicate table first\nc.execute('''CREATE TABLE country \n             (cid INTEGER PRIMARY KEY, Name TEXT);''') # create table\nfor country in active_countries_count.keys():\n  c.execute(\"INSERT INTO country (Name) VALUES ('%s');\" %country) # insert row into table\nconn.commit() # Save (commit) the changes\n\n# Methods of killing\nmos = ['children','sexual assault','torture','arson','cannibalism','strangulation','gun','poison']\nc.execute('DROP TABLE IF EXISTS methods_killing;') # remove duplicate table first\nc.execute('''CREATE TABLE methods_killing \n             (moid INTEGER PRIMARY KEY, Method TEXT);''') # create table\nfor m in mos:\n  c.execute(\"INSERT INTO methods_killing (Method) VALUES ('%s');\" %m) # insert row into table\nconn.commit() # Save (commit) the changes\n\n# Organization\norganization = ['individual','group']\nc.execute('DROP TABLE IF EXISTS organization;') # remove duplicate table first\nc.execute('''CREATE TABLE organization \n             (oid INTEGER PRIMARY KEY, Form TEXT);''') # create table\nfor o in organization:\n  c.execute(\"INSERT INTO organization (Form) VALUES ('%s');\" %o) # insert row into table\nconn.commit() # Save (commit) the changes","f1d2d086":"# df with only identified killers\ndf_indentified = df1[df1.Name.isin(names)]\ndf_indentified['Organization'] = df_indentified['Name'].apply(lambda x: 2 if x in group_names else 1) # label individual (1), group (2)\n\n# serial killers dataset\nserial_killer = df_indentified.reset_index(drop=True).reset_index().rename(columns={'index':'id'}).copy()\nserial_killer['id'] = serial_killer['id'].apply(lambda x: x+1) # fix key to start from 1","47a0dd95":"# Serial Killer\nc.execute('DROP TABLE IF EXISTS serial_killer;') # remove duplicate table first\nc.execute('''CREATE TABLE serial_killer \n             (id INTEGER PRIMARY KEY, Name TEXT, Proven_victims INTEGER(0), \n             Organization INTEGER(0), Start_year INTEGER(0), End_year INTEGER(0),\n             Active_years INTEGER(0));''') # create table\ncols = ['id','Name','Proven victims','Organization','Start year','End year','Number of years active']\nserial_killer[cols].to_sql('serial_killer', conn, if_exists='replace', index = False) # insert row into table\nconn.commit() # Save (commit) the changes","f0bb05f9":"#for me in c.execute('SELECT * FROM serial_killer'):\n#  print(me)","89bfe161":"# We can also close the connection if we are done with it.\n# Just be sure any changes have been committed or they will be lost.\nconn.close()","256ebc7e":"The p-value of this one-way ANOVA test is 0.0007 which is less than the alpha level of 0.05. Therefore, the null hypothesis is rejected in favor of the alternative hypothesis. \n\nNext, we perform a Post-Hoc test to determin which methods of killing is significantly different from others. ","edb24a01":"The above map shows the route each of the serial killers took. Using this geographic representation, one can determine the killer's comfort zone. The routes represented in this map are recorded by the dumping sites where the victims were disposed of\/killed.","0bca1952":"## Test ANOVA assumptions\n\n1. Normal distribution of residuals: Shapiro-Wilk test. \n  \n  *Null hypothesis*: data is drawn from normal distribution.\n2. Homogeneity of variances: Bartlett's test. Levene test can be used when data is not drawn from normal distribution. \n  \n  *Null hypothesis*: samples from populations have equal variances.","e094d0dc":"Insights:\n\n- Most of the convicted were sent to prison while the rest was sent to mental institutions.\n\n- The executed group of convicted kill 15 people on median. This median number of victims is the highest among the three types of treatment.","47e4062e":"Since the p-value (0.0003) is significant, we reject the null hypothesis in favor of the alternative hypothesis and conclude that the groups of methods of killings **do not have equal variances.** \n","e97c4c37":"# SERIAL MURDER ANALYSIS\n#### AUTHORS: Liying Lu, Vi Nguyen","d2ad25bc":"Insights: \n\n- Killers who moved between different locations have higher number of years active. \n\n--> Moving across country borders could be used as a counterforensic measure to avoid detection","bbadcec2":"## 2. Visualizations","4e7c3a61":"Serial killers and their active areas","a4dfee2f":"## 4. Database","a2e600ad":"## 1. Data Cleaning\/Transformation\n\nThe data used in this analysis is collected from [Wikipedia](https:\/\/en.m.wikipedia.org\/wiki\/List_of_serial_killers_by_number_of_victims). This is a publicly available dataset that can be edited by anyone. That is, this dataset contains information that is either in progress or subject to the reliability of the editors. \n\nTo store the data into a nicely formatted Pandas dataframe, data cleaning and transformation techniques were applied to the original content of the webpage. Refer to this [link](https:\/\/colab.research.google.com\/drive\/1vFXoUHzGY53rzG08q9V54KzXpJ7r5f6z?usp=sharing) to see how this was done. Relevant keywords extracted through the use of Natural Language Processing were used to classify the type of offender and the Modus operandi (M.0.) used by respective offender. ","7594fd18":"## 3. Hypothesis Testing","1b7f4345":"*Null Hypothesis*: There is no variation in the mean number of confirmed victims for all groups of number of methods of killing.\n\n*Alternative Hypothesis*: At least the mean number of confirmed victims of one group of number of methods of killing differs from other groups.\n\nReference:\nhttps:\/\/reneshbedre.github.io\/blog\/anova.html","1f443828":"### Post-Hoc test: Tukey HSD test","3b66df56":"A few of them only moved within their countries' borders","502ea057":"Since the p-value (6.32e-31) of the Shapiro test is less than the alpha level of 0.05, we reject the null hypothesis in favor of the alternative hypothesis and conclude that the **data is not drawn from normal distribution**.","e06f76cc":"Insight:\n\n- Killers who have only 1 MO are more variant in terms of how many people they target\n\n--> Offenders who exhibit more than 3 MO's tend to spend more time with their victims thus having lower victim count. Those with lower MO's, on the other hand, are more focused on quantity. ","4d09b14a":"Insight:\n\nThe above graph is faceted over the different types of MO used by the killers with the x-axis being the number of proven victims.\n\n- There are extreme cases in all types of MO with high counts of victims\n\n** Note: a killer can have more than 1 MO, thus is accounted for in one or more histograms","b142191f":"The results from the Tukey HSD test suggest that the group with 4 methods of killing with all other groups reject the null hypothesis (p-tukey < 0.05) and indicates statistical significant difference in the mean number of proven victims."}}