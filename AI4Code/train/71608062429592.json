{"cell_type":{"8178f8e4":"code","442bffc8":"code","e5ef8201":"code","bfce8071":"code","3e90c9a2":"code","26a8fcc9":"code","b9f60122":"code","a8d9c952":"code","a258c642":"code","648b702a":"code","d9248865":"code","b8a31020":"code","7f7d1f31":"code","e9fe9129":"code","91ba17cd":"code","19d8d1d1":"code","08ce5d54":"code","fa31b8f2":"code","18e31713":"code","b4fd693c":"code","d5020c1a":"code","f3d0a1d9":"code","83acb8fb":"code","133e0638":"markdown","7d53f1c3":"markdown","1c3e9c29":"markdown","a577de43":"markdown","ea565741":"markdown","2803323a":"markdown","581da5b3":"markdown","fa8b285b":"markdown","91dca429":"markdown","552dec50":"markdown","6e1f536d":"markdown","8a6ab5ef":"markdown","ac5c41d2":"markdown","0798feba":"markdown","a7a5e57f":"markdown","f93d1033":"markdown","8f479fbb":"markdown","7285c503":"markdown","86b85919":"markdown","990089f3":"markdown","716e71c7":"markdown","5900000a":"markdown","00b8e326":"markdown","08ff509b":"markdown"},"source":{"8178f8e4":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nPath.ls = lambda x: list(x.iterdir())\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.decomposition import PCA\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport math\nfrom scipy import stats\nfrom sklearn.cluster import KMeans","442bffc8":"path = Path('\/kaggle\/input\/ccdata\/')\npath.ls()","e5ef8201":"df = pd.read_csv(path\/'CC GENERAL.csv')\ndf.head()","bfce8071":"df.describe()","3e90c9a2":"df.info(), df.isna().sum(), df.isna().sum()\/len(df)","26a8fcc9":"na_cols = df.columns[df.isna().sum() > 0].tolist()\ndf.loc[:,na_cols] = df.loc[:,na_cols].fillna(df[na_cols].median())","b9f60122":"df.isna().sum().sum()","a8d9c952":"# I am too lazy to write down all the columns for cont cols ;) \ncat_cols = ['TENURE']\ncont_cols = df.columns.tolist()\ncont_cols.remove(cat_cols[0])\ncont_cols.remove('CUST_ID')","a258c642":"def plot_univariable_plots(df, cat_cols, cont_cols):\n    total_cols = len(cat_cols)+len(cont_cols)\n    fig, axes = plt.subplots(math.ceil(total_cols\/3),3, figsize=(20,20),constrained_layout=True)\n    axes = axes.flatten()\n    fig.suptitle(f'Univariate plots'.title(),fontsize=18)\n    \n    for i, (col, ax) in enumerate(zip(cont_cols, axes)):\n        sns.distplot(df[col], ax=ax)\n        ax.set_title(f'Histogram of {col}')\n    \n    for col in cat_cols:\n        sns.countplot(df[col],ax=axes[i+1])\n        ax.set_title(f'Histogram of {col}')\n        \n    plt.show()","648b702a":"plot_univariable_plots(df, cat_cols, cont_cols)","d9248865":"transformed_df = df.copy()\ntransformed_df.loc[:,cont_cols] = transformed_df[cont_cols].apply(lambda x: stats.boxcox(x+1)[0], axis=0)\nplot_univariable_plots(transformed_df, cat_cols, cont_cols)","b8a31020":"scaler = MinMaxScaler()\nscaler.fit(transformed_df[cont_cols+cat_cols])\nscaled = scaler.transform(transformed_df[cont_cols+cat_cols])\nscaled_df = pd.DataFrame(scaled, columns=cont_cols+cat_cols)","7f7d1f31":"N_COMPONENTS = 15\npca = PCA(n_components=N_COMPONENTS)\npca.fit(scaled_df)\npca.explained_variance_ratio_[:4].sum()","e9fe9129":"pca_data = pca.transform(scaled_df)\npca_df = pd.DataFrame(pca_data).iloc[:,:4]\npca_df.columns = list(map(lambda x: f'pca_{x+1}', pca_df.columns))\n# pca_df['TENURE'] = df.TENURE","91ba17cd":"fig = px.scatter_3d(pca_df,x='pca_1',y='pca_2',z='pca_3',opacity=0.3,color='pca_4')\nfig.show()","19d8d1d1":"cost = []\nks = []\nfor i in range(3,30):\n    kmeans = KMeans(n_clusters=i)\n    kmeans.fit(pca_df)\n    cost.append(kmeans.inertia_)\n    ks.append(i)\nsns.lineplot(x=np.array(ks), y=np.array(cost))\nplt.xticks(ks)\nplt.show()","08ce5d54":"kmeans = KMeans(n_clusters=5)\nkmeans.fit(pca_df)\nout = kmeans.predict(pca_df)","fa31b8f2":"fig = px.scatter_3d(pca_df,x='pca_1',y='pca_2',z='pca_3',color=out,opacity=0.5,\n                    title='KMeans cluster with k=5')\nfig.show()","18e31713":"def display_component(v, features_list, component_num,ax):\n    \n    row_idx = component_num\n    \n    v_1_row = v.iloc[:,row_idx]\n    v_1 = np.squeeze(v_1_row.values)\n    \n    comps = pd.DataFrame(list(zip(v_1, features_list)),\n                         columns=['weights', 'features'])\n    \n    comps['abs_weights']=comps['weights'].apply(lambda x: np.abs(x))\n    sorted_weight_data = comps.sort_values('abs_weights',ascending=False).head()\n    \n    sns.barplot(data=sorted_weight_data,\n                   x=\"weights\",\n                   y=\"features\",\n                   palette=\"Blues_d\",ax=ax)\n    ax.set_title(\"PCA Component Makeup, Component #\" + str(component_num), fontsize=20)\n","b4fd693c":"features_list = np.array(cont_cols+cat_cols)\nv = pd.DataFrame(pca.components_)","d5020c1a":"fig, axes = plt.subplots(2,2,figsize=(20,8),constrained_layout=True)\naxes=axes.flatten()\nfor i,ax in enumerate(axes):\n    display_component(v, features_list, i,ax=ax)\nplt.show()","f3d0a1d9":"cluster_centers = kmeans.cluster_centers_\nbehaviours = cluster_centers.dot(v[:4])","83acb8fb":"fig, axes = plt.subplots(3,2,figsize=(15,12),constrained_layout=True)\naxes=axes.flatten()\nthreshold = 0.2\nfor i,behaviour in enumerate(behaviours):\n    thresh_mask = np.nonzero(np.abs(behaviour)>threshold)[0].tolist()\n    sns.barplot(behaviour[thresh_mask], y=features_list[thresh_mask],ax=axes[i])\n    axes[i].set_title(f'Cluster {i+1} features')\nplt.show()\n","133e0638":"#### Observations: \n* We can see most of the features are heavily skewed. We can try transforming with log\n* We can see that some features are left skewed and most are right skewed. \n\nLets transform skewed data with boxcox transform from scipy.stats.","7d53f1c3":"We can already see the clusters in the 3d scatterplot. **The plots are interactive. Try playing with it.**","1c3e9c29":"We can see that how pca features correspond to the actual features in the dataset. \n\n**The 1st PCA component has high positive correlation with BALANCE_FREQUENCY and is has negative correlation with ONEOFF_PURCHASES and so on**","a577de43":"## Looking at the data distribution","ea565741":"# KMeans Clustering","2803323a":"Lets fill the nas with median","581da5b3":"# Normalizing Data for PCA","fa8b285b":"# Understanding the clusters","91dca429":"#### Observations:\n* We can see there are missing values in `CREDIT_LIMIT` and `MINIMUM_PAYMENTS`. \n* We can also see that the missing values account for only 3 percent data in `MINIMUM_PAYMENTS` and there is only one missing value in `CREDIT_LIMIT`. \n* We can easily use median to fill the NAs.\n","552dec50":"We have handled the null values. Lets move on now. Lets list all the columns by their type.\n\n* `categorical_cols`: 'TENURE'\n* `continuous_cols`: 'BALANCE', 'BALANCE_FREQUENCY', 'PURCHASES', 'ONEOFF_PURCHASES', 'INSTALLMENTS_PURCHASES', 'CASH_ADVANCE', 'PURCHASES_FREQUENCY', 'ONEOFF_PURCHASES_FREQUENCY', 'PURCHASES_INSTALLMENTS_FREQUENCY', 'CASH_ADVANCE_FREQUENCY', 'CASH_ADVANCE_TRX', 'PURCHASES_TRX', 'CREDIT_LIMIT', 'PAYMENTS', 'MINIMUM_PAYMENTS', 'PRC_FULL_PAYMENT'.\n* `index_col`: 'CUST_ID'","6e1f536d":"We will now take the cluster centers and use the features in the **PCA** feature space to visualize customer behaviour","8a6ab5ef":"Lets check for NAs","ac5c41d2":"Please have a look at the 3d plots to understand the clusters. ","0798feba":"To perform PCA on our data, we need to scale our data between 0 and 1. We will use MinMaxScaler from scikit learn to achieve that","a7a5e57f":"#### Observations: \n\n* We have skewed data. We can see 0's in `25th` and `50th` percentile. We will have to plot the histograms to find out more.\n* The Tenure looks like a categorical column which makes sense. \n","f93d1033":"# Finally Understanding Customer behaviour","8f479fbb":"# EDA","7285c503":"## Behaviours observed:\n\n* **Cluster 1** : Customers who use credit card for Installment Purchases. They do not make oneoff purchases at all. \n* **Cluster 2** : Customers who use their credit card for all types of purchases and pay their bills in advance.  \n* **Cluster 3** : Customers who have a huge tendency of oneoff purchases and do it frequently. They also have high amount purchases.\n* **Cluster 4** : Customers who dont make huge purchases on the credit card. Also, they pay the bill in advance. \n* **Cluster 5** : Customers who use the credit card mostly for oneoff Purchases only. They also don't pay bills in advance.","86b85919":"Now that our data is scaled, we are ready to apply PCA","990089f3":"## Check out the interactive plots at the bottom.","716e71c7":"# PCA","5900000a":"## Please upvote the notebook if you like my work. Keeps me motivated.","00b8e326":"We get a 84% explained variance with just 4 components. We have successfully reduced the dimensions from 16 continuous variables to 4. It will help a lot in visualizing the data now.","08ff509b":"We are going to use PCA and KMeans clustering to perform customer segmentation with credit card data in this notebook.\nWe have the following features: \n\n* CUSTID : Identification of Credit Card holder (Categorical)\n* BALANCE : Balance amount left in their account to make purchases (\n* BALANCEFREQUENCY : How frequently the Balance is updated, score between 0 and 1 (1 = frequently updated, 0 = not frequently updated)\n* PURCHASES : Amount of purchases made from account\n* ONEOFFPURCHASES : Maximum purchase amount done in one-go\n* INSTALLMENTSPURCHASES : Amount of purchase done in installment\n* CASHADVANCE : Cash in advance given by the user\n* PURCHASESFREQUENCY : How frequently the Purchases are being made, score between 0 and 1 (1 = frequently purchased, 0 = not frequently purchased)\n* ONEOFFPURCHASESFREQUENCY : How frequently Purchases are happening in one-go (1 = frequently purchased, 0 = not frequently purchased)\n* PURCHASESINSTALLMENTSFREQUENCY : How frequently purchases in installments are being done (1 = frequently done, 0 = not frequently done)\n* CASHADVANCEFREQUENCY : How frequently the cash in advance being paid\n* CASHADVANCETRX : Number of Transactions made with \"Cash in Advanced\"\n* PURCHASESTRX : Numbe of purchase transactions made\n* CREDITLIMIT : Limit of Credit Card for user\n* PAYMENTS : Amount of Payment done by user\n* MINIMUM_PAYMENTS : Minimum amount of payments made by user\n* PRCFULLPAYMENT : Percent of full payment paid by user\n* TENURE : Tenure of credit card service for user"}}