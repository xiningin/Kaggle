{"cell_type":{"e9169950":"code","73daba94":"code","76ae471c":"code","8412cf6a":"code","706cf4df":"code","8815973c":"code","dae00178":"code","927c8e0a":"code","f45cf692":"code","53f59d63":"code","1166f58c":"code","9fdb4378":"code","7c4aad27":"code","c10bde3a":"code","1d3ac25e":"code","e7f72d39":"code","1c0a90bd":"code","a08ad0f8":"code","c6e623da":"code","f5ba47d2":"code","e99000b9":"code","20d04ee5":"code","4e5c2724":"code","8d7c61cd":"code","122d75a7":"code","aeac4754":"code","7ec4f77f":"code","fc4c4d57":"code","844f4b22":"code","48d0c707":"code","fbf7e43d":"code","48563fbc":"code","a05a92b4":"code","0d55d9c4":"code","f9208836":"code","c16b669d":"code","3d2b4c01":"code","b12c7685":"code","0b4c4778":"code","daf692da":"code","6d505fd1":"code","21cc2bed":"code","4f4c7f25":"code","1e90ec7a":"code","dee3c218":"code","73b806b4":"code","fef785f2":"code","60ef4e95":"code","c71cd2e2":"code","3ff035ea":"code","0261d24b":"code","eac25d28":"code","ac170284":"code","9856a292":"code","1c6064d0":"code","86eda768":"code","f5daaaa4":"code","75ea7eba":"code","553713ed":"code","97a5dcb5":"code","86abc85f":"code","af829e5f":"code","cf7463b5":"code","0390165b":"code","c7fc4e08":"code","bd7887c3":"code","97497a89":"code","94712400":"code","73305699":"code","b57ea1e1":"code","01d99be8":"code","7cd3045f":"markdown","b1ec0d20":"markdown","9de26b21":"markdown","887a7fe1":"markdown","dbdc8b92":"markdown","57d9b7b6":"markdown","540b35a6":"markdown","c3411ea8":"markdown","6ac882e3":"markdown","ffc05236":"markdown","d40041fe":"markdown","28268577":"markdown","75574bf7":"markdown","7d813b08":"markdown","35d57c11":"markdown","7ccfdf7f":"markdown","db41fca2":"markdown","f6c1c133":"markdown"},"source":{"e9169950":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","73daba94":"import numpy as np\nimport pandas as pd\nfrom pandas import DataFrame as df\nimport matplotlib.pyplot as plt\nimport seaborn as sns","76ae471c":"data=pd.read_csv(\"\/kaggle\/input\/used-cars-price-prediction\/train-data.csv\")","8412cf6a":"data.head()","706cf4df":"data.describe()","8815973c":"print(data.shape)\nprint('--'*20)\n#checking percentage of data which is empty\nprint(data.isnull().sum()\/data.shape[0]*100)","dae00178":"#removing columns which are null for more than 70%\n#i.e removing \"New Price\" column\n\ncols = [col for col in data.columns if (data[col].isnull().sum()\/data.shape[0] * 100 < 70)]\ndata_trimmed = data[cols]\n\nprint ('Legitimate columns after dropping null columns: %s' % data_trimmed.shape[1])","927c8e0a":" data_trimmed.isnull().sum()\/data.shape[0]*100","f45cf692":"data_trimmed=df.drop(data_trimmed,labels=\"Unnamed: 0\",axis=1)#removing \"unnamend\" column","53f59d63":"data_trimmed.head()","1166f58c":"data_trimmed.dtypes","9fdb4378":"#Fill remaining null values. \n#We will use \"ffil\" i.e forward fill.(bffil also exists)\n\ndata_trimmed.fillna(method='ffill', inplace=True)\n\n\ndata_trimmed.isnull().sum()\n#Well we have no more NaN and null values to worry about","7c4aad27":"#Converting string data to numeric form, i.e removing units etc.\ndata_trimmed['Mileage'] = pd.to_numeric(data_trimmed['Mileage'].str.lower().str.split().str.get(0), errors='coerce')\ndata_trimmed['Engine'] = pd.to_numeric(data_trimmed['Engine'].str.lower().str.split().str.get(0), errors='coerce')\ndata_trimmed['Power'] = pd.to_numeric(data_trimmed['Power'].str.lower().str.split().str.get(0), errors='coerce')","c10bde3a":"data_trimmed.dtypes","1d3ac25e":"data_trimmed","e7f72d39":"cars=data_trimmed['Name'].str.lower().unique()","1c0a90bd":"num_cars=len(cars)","a08ad0f8":"print(num_cars)","c6e623da":"companies=data_trimmed['Name'].str.lower().str.split().str.get(0).unique()","f5ba47d2":"len(companies)","e99000b9":"companies","20d04ee5":"company_count=data_trimmed['Name'].str.lower().str.split().str.get(0).to_frame()[\"Name\"].value_counts()","4e5c2724":"plt.figure(figsize=(12,12))\nplt.xlabel('Company Name')\nplt.ylabel('No. of cars sold')\nplt.title('Cars sold per company')\ncompany_count.plot(kind='bar')","8d7c61cd":"fuel_type=data_trimmed['Fuel_Type'].str.lower().unique()","122d75a7":"fuel_type","aeac4754":"len(fuel_type)","7ec4f77f":"mileage = data_trimmed.groupby('Fuel_Type').Mileage.mean()","fc4c4d57":"print(mileage)","844f4b22":"plt.xlabel('Fuel Type')\nplt.ylabel('Average Mileage')\nplt.title('Mileage v\/s Fuel Type')\nmileage.plot(kind='bar')","48d0c707":"year = data_trimmed['Year'].value_counts()","fbf7e43d":"print(year)","48563fbc":"plt.xlabel('Year')\nplt.ylabel('No.of Cars')\nplt.title('Cars purchased per year')\nyear.plot(kind='bar')","a05a92b4":"comp = data_trimmed['Name'].str.split().str.get(0)\n\ndata_trimmed.insert(0, \"Company\", comp, True)","0d55d9c4":"data_trimmed","f9208836":"p = data_trimmed.groupby('Company').Price.mean()","c16b669d":"print(p)","3d2b4c01":"plt.xlabel('Company Name')\nplt.ylabel('Average price (in lacs) in rupees')\np.plot(kind='bar', title = 'Average price of cars per company')","b12c7685":"company = np.unique(data_trimmed['Company'])\ncompany","0b4c4778":"km = data_trimmed.groupby('Company').Kilometers_Driven.mean()","daf692da":"plt.xlabel('Company Name')\nplt.ylabel('Average km_driven')\nkm.plot(kind='bar', title = 'km_driven vs company plot')","6d505fd1":"feat_analysis=data_trimmed.drop(['Name', 'Company', 'Location', 'Fuel_Type', 'Transmission', 'Owner_Type'], axis = 1) #Getting numerical data","21cc2bed":"feat_analysis.corr()","4f4c7f25":"plt.figure(figsize=(8,8))\nplt.title('Feature Correlation Map')\ncorrMatrix = feat_analysis.corr()\nsns.heatmap(corrMatrix, annot=True)\nplt.show()","1e90ec7a":"# Linear model","dee3c218":"#First we need to convert string features to numeric data type i.e. one-hot encoding","73b806b4":"name_dummies = pd.get_dummies(data_trimmed.Name, drop_first=True)\ncompany_dummies = pd.get_dummies(data_trimmed.Company, drop_first=True)\nlocation_dummies = pd.get_dummies(data_trimmed.Location, drop_first=True)\nfuel_dummies = pd.get_dummies(data_trimmed.Fuel_Type, drop_first=True)\ntransmission_dummies = pd.get_dummies(data_trimmed.Transmission, drop_first=True)\nowner_dummies = pd.get_dummies(data_trimmed.Owner_Type, drop_first=True)\nseats_dummies = pd.get_dummies(data_trimmed.Seats, drop_first=True)","fef785f2":"\nfeatures = data_trimmed.drop(['Name', 'Company', 'Location', 'Fuel_Type', 'Transmission', 'Owner_Type', 'Seats'], axis = 1)\n\n","60ef4e95":"dfle = pd.concat([name_dummies, location_dummies, features, fuel_dummies, transmission_dummies, owner_dummies, seats_dummies], axis = 1)\ndfle","c71cd2e2":"from sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\n","3ff035ea":"dfle = dfle.dropna()\n\n","0261d24b":"X = dfle.drop('Price', axis = 1)\nX.Year=2020-X[\"Year\"] #Converting year to age of car,thus getting a better feature\ny = dfle.Price\nX_copy=X","eac25d28":"model.fit(X, y)","ac170284":"model.score(X,y)","9856a292":"y_pred_1=model.predict(X)\n","1c6064d0":"from sklearn.preprocessing import MinMaxScaler\nX[['Kilometers_Driven', 'Mileage']] = MinMaxScaler().fit_transform(X[['Kilometers_Driven', 'Mileage']])","86eda768":"from sklearn.linear_model import LinearRegression\nmodel = LinearRegression()","f5daaaa4":"\n\nmodel.fit(X, y)","75ea7eba":"LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)","553713ed":"model.score(X,y)","97a5dcb5":"y_pred_2=model.predict(X)\n","86abc85f":"from sklearn.preprocessing import StandardScaler\nX_copy[['Kilometers_Driven', 'Mileage']] = StandardScaler().fit_transform(X_copy[['Kilometers_Driven', 'Mileage']])","af829e5f":"model = LinearRegression()\n\n\n\nmodel.fit(X_copy, y)","cf7463b5":"model.score(X_copy,y)","0390165b":"y_pred_3=model.predict(X_copy)\n","c7fc4e08":"import tensorflow as tf\nfrom tensorflow import keras\n!pip install git+https:\/\/github.com\/tensorflow\/docs\nimport tensorflow_docs as tfdocs\nimport tensorflow_docs.plots\nimport tensorflow_docs.modeling\n\n","bd7887c3":"from keras import backend as K","97497a89":"dfle.Year=2020-dfle[\"Year\"]# converting year to age to get a better feature\ntrain_dataset = dfle.sample(frac=0.8,random_state=0)\ntest_dataset = dfle.drop(train_dataset.index)\ntrain_labels=train_dataset.Price\ntest_labels=test_dataset.Price\n\ntrain_dataset=train_dataset.drop(\"Price\",axis=1)","94712400":"model = keras.Sequential([\n    keras.layers.Dense(32, activation='relu', input_shape=[train_dataset.shape[1]]),\n    keras.layers.Dropout(0.2),\n    keras.layers.Dense(8, activation='relu'),\n    keras.layers.Dense(8, activation='relu'),\n    keras.layers.Dense(1)\n  ])\n\noptimizer = tf.keras.optimizers.Adam(0.001)\ndef R2_coeff(y_true, y_pred):\n    u = K.sum(K.square(y_true - y_pred))\n    v = K.sum(K.square(y_true - K.mean(y_true)))\n    return K.ones_like(v) - (u \/ v)\nmodel.compile(loss='mse',\n                optimizer=optimizer,\n                metrics=[R2_coeff])\n#R_2 coeff is used so that model can be compared to performance of linear regression model","73305699":"model.summary()","b57ea1e1":"\nEPOCHS = 1000\n\nhistory = model.fit(\n  train_dataset, train_labels,batch_size=64,\n  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n  callbacks=[tfdocs.modeling.EpochDots()])\n","01d99be8":"plt.figure(figsize=(16,9))\nplt.plot(history.history['loss'][50:])\nplt.plot(history.history['val_loss'][50:])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='upper right')\nplt.show()","7cd3045f":"### Q.)  What is the number of cars originally purchased per year?","b1ec0d20":"### The notebook demonstrates basic data insights and model to  make predictions.\nInstead doing EDA I have addressed data with questions.\nNecessary plots are drawn.\nThanks for reading.","9de26b21":"Expensive company cars are sold before being driven  much","887a7fe1":"Different hyperparameter were used.These seems to be optimum,however regression model has better R2_coeff than neural net.\nDropping out features affected model in a poor way.Same for dropout rate.\nI will keep doing hyperparameter tuning for optimal predictions.","dbdc8b92":"### Q) After driving for how much KMs people like to sell their cars?","57d9b7b6":"However, it was observed dropping any features reduces the score of model.","540b35a6":" Maruti followed by hyundai has the most number of selling cars","c3411ea8":"### Analysis of features:","6ac882e3":"It can be observed that electric and petrols cars are not good at mileage.Electric being worst and CNG being best","ffc05236":"# Linear Regression by standardization(of continuous data features)","d40041fe":"# What is the average price per company?","28268577":"### Importing dataset","75574bf7":"\n\n### Q.)Which  fuel Type has lesser mileage?","7d813b08":"# Neural Network Model","35d57c11":"# Linear Regression by Normalization(of continuous data features)","7ccfdf7f":"Hence, The cheapest car producer is Ambassador and the most expensive company is Lamborghini.","db41fca2":"### Linear Model","f6c1c133":"### Q.)Which company sells most Number of cars?"}}