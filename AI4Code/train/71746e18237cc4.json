{"cell_type":{"78da8f96":"code","c1302528":"code","f6c34a0f":"code","2f05cc9f":"code","0881c756":"code","0eff5a11":"code","472fad36":"code","9446dc72":"code","af466d72":"code","02cb6242":"code","668b4aeb":"code","8304d1cf":"code","87877ae8":"code","265f73f6":"code","2cdb7437":"code","a9d6247f":"code","1506f934":"code","2f245958":"code","56edb106":"code","37214bce":"code","daa7b425":"code","e604c1ae":"code","0d274db3":"code","ac0e0821":"code","0637da81":"code","baf9c98b":"code","9f069ca6":"code","72ee01c7":"code","fbff6f85":"code","544ac44b":"code","79e7a03c":"code","a3e62740":"code","71a8af36":"code","58ccd106":"code","43adc99d":"code","39bec838":"code","177c8140":"code","eb2c2492":"code","dc24a1b9":"code","c2cccb5e":"code","cbcc9703":"code","85b3b997":"code","5855f2f6":"code","2fa1e193":"code","7a8f8827":"code","ebfe1bd6":"code","55349e69":"code","cf981415":"code","c881f46e":"code","90f6386d":"code","6ceb1db0":"code","30cfbbc8":"code","5b9e86e8":"code","8b03e183":"code","f81b19e8":"code","db8c7df3":"code","4b706ff3":"markdown","45e93b63":"markdown","102a2a57":"markdown","e135a37d":"markdown","15ba13bb":"markdown","0e0bac66":"markdown","b27f303d":"markdown","d8f6bf89":"markdown","d7f9048f":"markdown","f8209ebd":"markdown","0fc23240":"markdown","058774d2":"markdown","7fadf611":"markdown","920e12c6":"markdown","726cc6ed":"markdown","bddb3b09":"markdown","24bfee86":"markdown","22dc52e4":"markdown","76916e9b":"markdown","cbae007d":"markdown","291da992":"markdown","2088c989":"markdown","da66f81f":"markdown","e59c9303":"markdown","48cbf484":"markdown","8da46770":"markdown","fd8696e0":"markdown","58f1ec88":"markdown","a1d446d9":"markdown","519db91f":"markdown","eeb910a9":"markdown","d0f0a28a":"markdown","b3a43e46":"markdown","db0c6be3":"markdown","6ba17a79":"markdown","1e5e013f":"markdown","028da610":"markdown","dc4e35df":"markdown","dcaf42d0":"markdown","23a7db3a":"markdown","75e2d71b":"markdown","f26ed0ad":"markdown","41b14bb5":"markdown","9c58621a":"markdown","5b8e2670":"markdown","3298f812":"markdown","9cba38ec":"markdown","9e7cb880":"markdown","ca594f68":"markdown","66d03f30":"markdown","e120e575":"markdown","7bd0cda3":"markdown","f4f890d1":"markdown","5de040c7":"markdown","7da9728d":"markdown","cde33f26":"markdown","25af67fb":"markdown","673d5529":"markdown","e3d5ce04":"markdown","f64e9fa1":"markdown","bbf52aec":"markdown","3c41a2f5":"markdown","8504c693":"markdown","dccec8ac":"markdown","55189f4f":"markdown","33278e4d":"markdown","97d1fcfa":"markdown","7ba886a7":"markdown","117a322e":"markdown","c776a0b1":"markdown","1752427c":"markdown","9c81e2e0":"markdown","83ce5f1c":"markdown"},"source":{"78da8f96":"import pandas as pd\nimport numpy as np\nfrom scipy.stats import norm, probplot, linregress\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.metrics import mean_squared_error\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport re","c1302528":"# Set the enviorment variables\ntrain_file = os.path.join('..', 'input', 'house-prices-advanced-regression-techniques','train.csv')\ntrain_file","f6c34a0f":"df = pd.read_csv(train_file)\nprint(\"Shape of Data is {} rows and {} columns\".format(df.shape[0], df.shape[1]))\ndf.sample(3)","2f05cc9f":"# lambda function to calculate the null value distribution in dataframe\nnull_per = lambda x : ((x.isna()).sum()\/len(x) * 100).sort_values(ascending=False)","0881c756":"null_per(df).head(20)","0eff5a11":"# Columns with more than 20% missing values\ndf[['PoolQC','MiscFeature','Alley','Fence','FireplaceQu']].sample(10)","472fad36":"print('What Kind of Data Types we are dealing with ?')\nprint(\"=\"*50)\ndf.dtypes.value_counts()","9446dc72":"cat_cols = df.drop('Id', axis=1).dtypes[df.dtypes == 'object'].index\nnum_cols = df.drop('Id', axis=1).dtypes[(df.dtypes == 'int64') | (df.dtypes == 'float64')].index","af466d72":"temp = df.loc[:,cat_cols]\nuni_count = dict()\nprint(\"Unique Values Distribution in Categorical Values\")\nprint(\"=\"*50)\nfor col in temp.columns:\n    uni_count[col] = len(temp[col].unique())\npd.Series(uni_count).sort_values()","02cb6242":"print(\"Standard Deviation of Numerical Features\")\nprint(\"=\"*50)\ndf.loc[:,num_cols].std().sort_values()","668b4aeb":"corr_df = df.loc[:,num_cols].corr()","8304d1cf":"fig,ax = plt.subplots(figsize=(12,10), dpi=100)\nax = sns.heatmap(corr_df, ax=ax, cmap='YlGnBu')","87877ae8":"sale_price_corr = corr_df['SalePrice'].drop('SalePrice',axis=0).sort_values(ascending=False)\nfig, ax = plt.subplots(figsize=(6,10),dpi=100)\nax =sns.barplot(x=sale_price_corr.values,y=sale_price_corr.keys(),)","265f73f6":"corr_df_zoom = df[['SalePrice','OverallQual','GrLivArea','GarageCars','GarageArea','TotalBsmtSF',\n                   '1stFlrSF','FullBath','TotRmsAbvGrd']].corr()\nfig,ax = plt.subplots(figsize=(4,3), dpi=100)\nsns.heatmap(corr_df_zoom,ax=ax, cmap='Blues')","2cdb7437":"sns.pairplot(df[['SalePrice','OverallQual','GrLivArea','GarageCars','GarageArea','TotalBsmtSF',\n                   '1stFlrSF','FullBath','TotRmsAbvGrd']])","a9d6247f":"X = df['SalePrice']\nfig, ax = plt.subplots(ncols=2,figsize=(16,6))\nsns.distplot(X,ax=ax[0], fit=norm)\nax[0].title.set_text('Sale Price')\nax[0].grid()\nprobplot(X, fit=norm, plot=ax[1])\nax[1].title.set_text('Sale Price')\nax[1].grid()","1506f934":"X = np.log(df['SalePrice'])\nfig, ax = plt.subplots(ncols=2,figsize=(16,6))\nsns.distplot(X,ax=ax[0], fit=norm, color='green')\nax[0].title.set_text('Probability Mass Function')\nax[0].grid()\n\nprobplot(X, fit=norm, plot=ax[1])\nax[1].get_lines()[0].set_markerfacecolor('g')\nax[1].get_lines()[0].set_markeredgecolor('g')\nax[1].title.set_text('Q-Q Plot')\nax[1].grid()","2f245958":"X = df['GrLivArea']\nfig, ax = plt.subplots(ncols=2,figsize=(16,6))\nsns.distplot(X,ax=ax[0], fit=norm)\nax[0].title.set_text('Probability Mass Function')\nax[0].grid()\n\nprobplot(X, fit=norm, plot=ax[1])\nax[1].title.set_text('Q-Q Plot')\nax[1].grid()","56edb106":"X = np.log(df['GrLivArea'])\nfig, ax = plt.subplots(ncols=2,figsize=(16,6))\nsns.distplot(X,ax=ax[0], fit=norm)\nax[0].title.set_text('Probability Mass Function')\nax[0].grid()\n\nprobplot(X, fit=norm, plot=ax[1])\nax[1].get_lines()[0].set_markerfacecolor('g')\nax[1].get_lines()[0].set_markeredgecolor('g')\nax[1].title.set_text('Q-Q Plot')\nax[1].grid()","37214bce":"X = df['GarageArea']\nfig, ax = plt.subplots(ncols=2,figsize=(16,6))\nsns.distplot(X,ax=ax[0], fit=norm)\nax[0].title.set_text('Probability Mass Function')\nax[0].grid()\n\nprobplot(X, fit=norm, plot=ax[1])\nax[1].title.set_text('Q-Q Plot')\nax[1].grid()","daa7b425":"X = df['TotalBsmtSF']\nfig, ax = plt.subplots(ncols=2,figsize=(16,6))\nsns.distplot(X,ax=ax[0], fit=norm)\nax[0].title.set_text('Probability Mass Function')\nax[0].grid()\n\nprobplot(X, fit=norm, plot=ax[1])\nax[1].title.set_text('Q-Q Plot')\nax[1].grid()","e604c1ae":"X = df[df['TotalBsmtSF'] < 4000]['TotalBsmtSF']\nfig, ax = plt.subplots(ncols=2,figsize=(16,6))\nsns.distplot(X,ax=ax[0], fit=norm)\nax[0].title.set_text('Probability Mass Function')\nax[0].grid()\n\nprobplot(X, fit=norm, plot=ax[1])\nax[1].title.set_text('Q-Q Plot')\nax[1].grid()","0d274db3":"X = df[df['1stFlrSF'] < 3500]['1stFlrSF']\nfig, ax = plt.subplots(ncols=2,figsize=(16,6))\nsns.distplot(X,ax=ax[0], fit=norm)\nax[0].title.set_text('Probability Mass Function')\nax[0].grid()\n\nprobplot(X, fit=norm, plot=ax[1])\nax[1].title.set_text('Q-Q Plot')\nax[1].grid()","ac0e0821":"X = np.log(df[df['1stFlrSF'] < 3500]['1stFlrSF'])\nfig, ax = plt.subplots(ncols=2,figsize=(16,6))\nsns.distplot(X,ax=ax[0], fit=norm)\nax[0].title.set_text('Probability Mass Function')\nax[0].grid()\n\nprobplot(X, fit=norm, plot=ax[1])\nax[1].title.set_text('Q-Q Plot')\nax[1].grid()","0637da81":"X = df['TotRmsAbvGrd']\nfig, ax = plt.subplots(ncols=2,figsize=(16,6))\nsns.distplot(X,ax=ax[0], fit=norm)\nax[0].title.set_text('Probability Mass Function')\nax[0].grid()\n\nprobplot(X, fit=norm, plot=ax[1])\nax[1].title.set_text('Q-Q Plot')\nax[1].grid()","baf9c98b":"x = df['OverallQual']\ny = df['SalePrice']\nfig, ax = plt.subplots(figsize=(14,6))\nsns.boxplot(x=x, y=y, ax=ax)\nax.grid()","9f069ca6":"x = np.log(np.array(df['GrLivArea']))\ny = np.log(np.array(df['SalePrice']))\nfig, ax = plt.subplots(figsize=(14,6))\nsns.scatterplot(x=x, y=y, ax=ax)\nlnrg = linregress((x,y))\ny_lr = lnrg.slope*x + lnrg.intercept\nsns.lineplot(x=x,y=y_lr,color='black')\nax.grid()","72ee01c7":"x = df['GarageCars']\ny = np.log(df['SalePrice'])\nfig, ax = plt.subplots(figsize=(14,6))\nsns.boxplot(x=x, y=y, ax=ax)\nax.grid()","fbff6f85":"x = np.array(df['GarageArea'])\ny = np.log(np.array(df['SalePrice']))\nfig, ax = plt.subplots(figsize=(14,6))\nsns.scatterplot(x=x, y=y, ax=ax)\nlnrg = linregress((x,y))\ny_lr = lnrg.slope*x + lnrg.intercept\nsns.lineplot(x=x,y=y_lr,color='black')\nax.grid()","544ac44b":"x = np.array(df['TotalBsmtSF'])\ny = np.array(df['SalePrice'])\nfig, ax = plt.subplots(figsize=(14,6))\nsns.scatterplot(x=x, y=y, ax=ax)\nlnrg = linregress((x,y))\ny_lr = lnrg.slope*x + lnrg.intercept\nsns.lineplot(x=x,y=y_lr,color='black')\nax.grid()","79e7a03c":"x = np.array(df['1stFlrSF'])\ny = np.log(np.array(df['SalePrice']))\nfig, ax = plt.subplots(figsize=(14,6))\nsns.scatterplot(x=x, y=y, ax=ax)\nlnrg = linregress((x,y))\ny_lr = lnrg.slope*x + lnrg.intercept\nsns.lineplot(x=x,y=y_lr,color='black')\nax.grid()","a3e62740":"x = df['FullBath']\ny = df['SalePrice']\nfig, ax = plt.subplots(figsize=(14,6))\nsns.boxplot(x=x, y=y, ax=ax)\nax.grid()","71a8af36":"x = df['TotRmsAbvGrd']\ny = df['SalePrice']\nfig, ax = plt.subplots(figsize=(14,6))\nsns.boxplot(x=x, y=y, ax=ax)\nax.grid()","58ccd106":"x = np.array(df[df['TotalBsmtSF'] > 0]['GrLivArea'])\ny = np.array(df[df['TotalBsmtSF'] > 0]['TotalBsmtSF'])\nfig, ax = plt.subplots(figsize=(14,6))\nsns.scatterplot(x=x, y=y, ax=ax)\nlnrg = linregress((x,y))\ny_lr = lnrg.slope*x + lnrg.intercept\nsns.lineplot(x=x,y=y_lr,color='black')\nax.grid()","43adc99d":"x = np.array(df['1stFlrSF'])\ny = np.array(df['TotalBsmtSF'])\nfig, ax = plt.subplots(figsize=(14,6))\nsns.scatterplot(x=x, y=y, ax=ax)\nlnrg = linregress((x,y))\ny_lr = lnrg.slope*x + lnrg.intercept\nsns.lineplot(x=x,y=y_lr,color='black')\nax.grid()","39bec838":"df['has_basement'] = df['TotalBsmtSF'].apply(lambda x : 'Yes' if x > 0 else 'No')\ndf['has_garage'] = df['GarageArea'].apply(lambda x : 'Yes' if x > 0 else 'No')","177c8140":"print('Properties Having Basement-Distribution : ')\nprint(df['has_basement'].value_counts()\/len(df)*100)\nprint('='*50)\nprint('Properties Having Garage-Distribution : ')\nprint(df['has_garage'].value_counts()\/len(df)*100)\nprint('='*50)","eb2c2492":"df = df.drop(['PoolQC','MiscFeature','Alley','Fence','FireplaceQu'],axis=1)","dc24a1b9":"cat_cols = df.dtypes[df.dtypes == 'object'].index\ncat_cols","c2cccb5e":"X_dum = pd.get_dummies(df.loc[:,df.dtypes[df.dtypes == 'object'].index])\ny = np.log(df['SalePrice'])","cbcc9703":"clf = RandomForestRegressor(n_estimators=100)\nclf.fit(X_dum, y)","85b3b997":"feat_import = pd.Series(dict(zip(X_dum.columns,clf.feature_importances_))).sort_values(ascending=False)\ndummy_cols = list(X_dum.columns)\nrows = dict()\nfor col in cat_cols:\n    cols_to_sum = [w for w  in dummy_cols if re.search(col,w) != None]\n    rows[col] = np.median(feat_import[cols_to_sum].sum())\nrows = pd.Series(rows).sort_values(ascending=False)\nprint(\"Sum of Feature Importance of each feature, across it different categories\")\nprint('='*80)\nrows.head(10)","5855f2f6":"feat_import = pd.Series(dict(zip(X_dum.columns,clf.feature_importances_))).sort_values(ascending=False)\nfig, ax = plt.subplots(figsize=(10,12),dpi=100)\nx = list(rows.values)\ny = list(rows.index)\nsns.barplot(x=x, y=y)","2fa1e193":"x = df['ExterQual'].sort_values()\ny = df['SalePrice']\nfig, ax = plt.subplots(ncols=2,figsize=(12,4),dpi=100)\nsns.boxplot(x=x, y=y, ax=ax[1])\nx = x.value_counts().sort_index()\nsns.barplot(x=x.keys(),y=x.values,ax=ax[0])\nax[1].grid()","7a8f8827":"x = df['BsmtQual'].sort_values()\ny = df['SalePrice']\nfig, ax = plt.subplots(ncols=2,figsize=(12,4),dpi=100)\nsns.boxplot(x=x, y=y, ax=ax[1])\nx = x.value_counts().sort_index()\nsns.barplot(x=x.keys(),y=x.values,ax=ax[0])\nax[1].grid()","ebfe1bd6":"x = df['Neighborhood'].sort_values()\ny = df['SalePrice']\nfig, ax = plt.subplots(ncols=2,figsize=(16,4),dpi=100)\nsns.boxplot(x=x, y=y, ax=ax[1])\nx = x.value_counts().sort_index()\nsns.barplot(x=x.keys(),y=x.values,ax=ax[0])\nax[1].grid()","55349e69":"x = df['GarageType'].sort_values()\ny = df['SalePrice']\nfig, ax = plt.subplots(ncols=2,figsize=(16,4),dpi=100)\nsns.boxplot(x=x, y=y, ax=ax[1])\nx = x.value_counts().sort_index()\nsns.barplot(x=x.keys(),y=x.values,ax=ax[0])\nax[1].grid()","cf981415":"x = df['KitchenQual'].sort_values()\ny = df['SalePrice']\nfig, ax = plt.subplots(ncols=2,figsize=(16,4),dpi=100)\nsns.boxplot(x=x, y=y, ax=ax[1])\nx = x.value_counts().sort_index()\nsns.barplot(x=x.keys(),y=x.values,ax=ax[0])\nax[1].grid()","c881f46e":"x = df['MSZoning'].sort_values()\ny = df['SalePrice']\nfig, ax = plt.subplots(ncols=2,figsize=(16,4),dpi=100)\nsns.boxplot(x=x, y=y, ax=ax[1])\nx = x.value_counts().sort_index()\nsns.barplot(x=x.keys(),y=x.values,ax=ax[0])\nax[1].grid()","90f6386d":"num_cols_selected = ['OverallQual','GrLivArea','GarageCars','GarageArea','TotalBsmtSF','1stFlrSF','FullBath',\n                 'TotRmsAbvGrd']\ncat_cols_selected = ['ExterQual', 'BsmtQual', 'Neighborhood', 'GarageType', 'KitchenQual','MSZoning']\ntarget = 'SalePrice'","6ceb1db0":"train, test = train_test_split(df, random_state=42, test_size=0.2)","30cfbbc8":"train[cat_cols_selected] = train[cat_cols_selected].fillna('missing')\ntest[cat_cols_selected] = test[cat_cols_selected].fillna('missing')\n\none_hot = OneHotEncoder()\none_hot.fit(train[cat_cols_selected])\nX_train_cat = one_hot.transform(train[cat_cols_selected]).toarray()\nX_test_cat = one_hot.transform(test[cat_cols_selected]).toarray()","5b9e86e8":"ss = StandardScaler()\nss.fit(train[num_cols_selected])\nX_train_num = ss.transform(train[num_cols_selected])\nX_test_num = ss.transform(test[num_cols_selected])","8b03e183":"X_train = np.c_[X_train_cat, X_train_num]\nX_test = np.c_[X_test_cat, X_test_num]\n\ny_train, y_test = train[target], test[target]","f81b19e8":"clf = RandomForestRegressor(n_estimators=100, bootstrap=True)\nclf.fit(X_train, np.log(y_train))","db8c7df3":"y_pred = clf.predict(X_test)\nmse = mean_squared_error(np.log(y_test), y_pred)\nrmse = np.sqrt(mse)\nprint('Root Mean Squared Error - Base Model - {}'.format(rmse))","4b706ff3":"# Numerical Feature Analysis","45e93b63":"<b>For the features we have discovered log therapy as a useful tool, we will continue to use there log values in future analysis as well<\/b>","102a2a57":"## Total Basement Surface Area","e135a37d":"<b>Vola!!!<\/b>","15ba13bb":"## Total Rooms Above Ground","0e0bac66":"<b>We would like to make sure that the selected features are not some wirdos, for example, does one single category dominates, or is if it has too many categories with small distribution, so we can group them together.<\/b>","b27f303d":"# Data Loading & Wrangling","d8f6bf89":"## Neighborhood -vs- Sale Price","d7f9048f":"## Overall Quality","f8209ebd":"## 1st Floor Surface Area","0fc23240":"<b>Probability Density Function : <\/b> It helps us understand where the data is concentrated, and how much variance are we dealing with, for example, we have a distribution which has mutiple peak point, it would better to bin them. On the other hand if any distribution has a long tail, we might want to set and value above a thereshold as maximum, or use a log function to correct that.\n\n\n<b>Q-Q-Plot : <\/b>or quantile-quantile plot, is a graphical tool to help us assess if a set of data plausibly came from some theoretical distribution such as a Normal or exponential. For example, if we run a statistical analysis that assumes our dependent variable is Normally distributed, we can use a Normal Q-Q plot to check that assumption. It\u2019s just a visual check, not an air-tight proof, so it is somewhat subjective. But it allows us to see at-a-glance if our assumption is plausible, and if not, how the assumption is violated and what data points contribute to the violation","058774d2":"<b>using the current model will place us in top 30% in Housing Regression Challenge, but we would need to reduce the score by third to have a descent shot at top 5%-10%.<\/b>","7fadf611":"<b>Or as I like to call it, <i>smell the data, before dinner<\/i><\/b>","920e12c6":"**Lets create new Binary Columns for Basement & Garage, so we can analyze there distribution as well.**","726cc6ed":"<b>That is Ordinal Feature Hiding as Continues one.. But preet good looking shape it has..<\/b>","bddb3b09":"<b>If you look closely, this distribution tells you nice story. Most property with a basement have similar basement area as the ground floor living area, but some have smaller basements then the ground floor area, which makes perfect sense, bulding basements is expensive. But the intresting this is, there are few properties with basements bigger than the groundfloor. One might wonder, whats going on there!!!<\/b>","24bfee86":"## Zoning Classifcation -vs- Sale Price","22dc52e4":"<b>We can use Pearson's Correlation to find the useful features which might have strong impact on the dependent variable. As we have too many features, we can use a heatmap to visualize the correlation, between features.<\/b>\n\n<b><i>Below is the Formula for calculating pearson correlation between two features.<\/i><\/b>","76916e9b":"## Kitchen Quality -vs- Sale Price","cbae007d":"## Total Rooms Above Ground","291da992":"So lets get started, I hope you have as much fun reading this, as I had writing.\nPlease leave your thoughts in comments below.","2088c989":"![image.png](attachment:image.png)","da66f81f":"## Ground Living Area -vs- Total Basement Surface Area","e59c9303":"## Categorical Data, Univariant & MultiVariant Analysis","48cbf484":"<b>Ahh!! the distribution is just slightly skewed, lets see a small dose of \"log therapy\" helps<\/b>","8da46770":"<b>Also called <i>Personal Interview<\/i><\/b>\n\n<b>Now That we have a small set of correlated features, we can start poking them individually, and try to find out there dirty secret<\/b>","fd8696e0":"I have tried to be as descriptive as possible, but if i have missed something please feel free to ask in comments.","58f1ec88":"<b>The aim of the notebook is as follows<\/b>\n<ul>\n    <li>Identify Null value distribution in the dataset<\/li>\n    <li>Find features\/variables that will be useful for modeling<\/li>\n    <li>Perform Unvariant and Multivariant analysis of selected features<\/li>\n    <li>Build a baseline model, so future models can be comparable<\/li>\n<\/ul>","a1d446d9":"## Garage Type -vs- Sale Price","519db91f":"## Total Basement Surface Area","eeb910a9":"<b>Note : <\/b>We will drop any feature which has more than 20% null values, as they wont be useful for modeling","d0f0a28a":"<b>We can start by looking at features highly correlated with Sale Price<\/b>","b3a43e46":"## Basement Quality -vs- Sale Price","db0c6be3":"<b>Log Therapy to the rescue<\/b>","6ba17a79":"<b>Before we can begain with feature engineering or model development, it is important to set our baseline, across which any future improvements will be measured. For example if we desgin a new feature and want to find its impact on our model, we can use our baseline model to compare the results.<\/b>\n\n<b>For this exercise its important to split the dataset into training and testing sets, as we do not want a overfit model to be our baseline model.<\/b>","1e5e013f":"<b>Or as know in the streets.. <i>Couples Therapy<\/i><\/b>","028da610":"<b> We want to over fit a simple model on the dataset<\/b>","dc4e35df":"<h2><i>\u201cThe great aim of education is not knowledge but action.\u201d \u2014 Herbert Spencer<\/i><\/h2>","dcaf42d0":"## Garage Cars","23a7db3a":"# BaseLine Model","75e2d71b":"## Full Bathrooms","f26ed0ad":"<b>Let's select features with absolute correlation atleat above 0.6, as anything below that would not be useful for model development<\/b>\n\n<b>We can zoom in on the selected features and get a better idea on correlation<\/b>","41b14bb5":"Although, Excellent Quality may have very high mean sale price, its distribution is too small to make an impact on the model.","9c58621a":"**The distribution of properties without basement is very small, there would not be of much use for us, but the properties without garage is significant, and can be important, let see if it is picked up in our next feature selection technique for categorical features.**","5b8e2670":"<b>Same problem, Same solution<\/b>","3298f812":"# House Price Regression - Exploratory Analysis","9cba38ec":"## 1st Floor Surface Area","9e7cb880":"<b>Ma Ma Mia!!<\/b>","ca594f68":"We might be tempted to apply log therapy to all the distributions we encounter, but remember, if it ain't broken, dont fix it.\n\n<b>Feature Note : <\/b> As a substantial number of data points have zero garage area, we can use that build a new boolean feature, representing the presence of garage on the property","66d03f30":"## Total Basement Surface Area -vs- 1st Floor Surface Area","e120e575":"## Sale Price","7bd0cda3":"<b>Box Plot Distribution<\/b> : Helps visualize the distribution between continues and categorical features. It also gives a visual idea of trend in one feature as other varies. This can reveal useful information as to how the our dependent impacts the categorical feature, and might help us discover some new feature engineering ideas.\n\n<b>Scatter Plot with Regression Fit<\/b> : Scatter plot is useful to visuallize the distribution between two continues features, but having a regression line fit through it, helps get an idea on the direction and strength of distribution.","f4f890d1":"# Univariant Analysis","5de040c7":"<b>As any model we build, we will most certainly be performing feature scaling and one hot encoding, it is good idea to use the same basic transformations on our baseline model<\/b>","7da9728d":"<b><i>This is part 1 of a 3 part series I am working on, to model the House Price Data in a professional manner<\/i><\/b>","cde33f26":"<b>before we do any kind of analysis, we must check the kind of features we are working with & what percentage of those are null<\/b>","25af67fb":"## Ground Living Area","673d5529":"## Garage Area","e3d5ce04":"<b>Feature Selection with categorical features can be a bit tricky, as there are many proven ways to do so, but no standard process. One of the proven technique is an overfitted Random Forest Regressor. We can use the feature importance statistic to select our features. There are many other ways you can try out, for example stepwise selection with Logistic Regression, but recently there has been some critisiom of these variance based techniques as they put too much importance on distribution of variable than the its predictive prowes.<\/b>","f64e9fa1":"I have done the project before, but as an amateur I made a mess out of the work I did. I wanted to revisit this work and use my updated skill set & professional experience to build something better. When I started out on my journey of becoming self taught Machine Learning Engineer, i thought the performance of your model is the only thing that matters, but now completing over an year in the industry, i have come to the realization that the journey to the final model is a long one and there are every step in itelf is a learning experince. I have started to enjoy the data cleaning and analysis part, as much as the model building part.\n\nKaggle has been a important part of my learning experince and I want to thank all the kagglers for it.","bbf52aec":"<b>Next we will be looking into Feature engineering and Pipeline building to streamline the transformations<\/b>","3c41a2f5":"## Garage Area","8504c693":"<h2>UpVote<\/h2>\n\nIf you enjoyed the notebook, this will motivate me to work harder on the next one.","dccec8ac":"# Categorical Variable Analysis","55189f4f":"## Exterior Quality -vs- Sale Price","33278e4d":"<b>Our Q-Q Plot tells us that there is single outlier over 4000, which is causing major problems to the distribution. Lets throw it out and see what happens<\/b>","97d1fcfa":"## Ground Living Area","7ba886a7":"<b>That was kind of obvious, but i wonder what do they mean by Overall Quality, is it an aggreate of existing features<\/b>","117a322e":"<b>As there are too many categories for this feature, we might want bin them together based on there mean sale price, or geographicaly<\/b>","c776a0b1":"# Bivariant Analysis","1752427c":"<h3><b><i>\u201cIn God we trust. All others must bring data.\u201d \u2013 W. Edwards Deming<\/i><\/b><\/h3>\n\n<i>Ironically there is no proof of him saying that<\/i>","9c81e2e0":"![image.png](attachment:image.png)","83ce5f1c":"<b>As categories other than Residential are very small in number, perhaps we can group them together into a single \"others\" bin<\/b>"}}