{"cell_type":{"3e61fe14":"code","14313530":"code","9371c5e3":"code","bba370f1":"code","04395077":"code","d668ac73":"code","dd448182":"code","a113c50d":"code","4c6e0793":"code","07927d6f":"code","f8a3cb37":"code","c7772113":"code","081aac16":"markdown","1581f230":"markdown"},"source":{"3e61fe14":"pip install pymorphy2","14313530":"import os\nimport string\nimport annoy\nimport json\n\nfrom pymorphy2 import MorphAnalyzer\nfrom stop_words import get_stop_words\nfrom gensim.models import Word2Vec\nfrom gensim.models import KeyedVectors\n\nimport numpy as np\nfrom tqdm import tqdm_notebook\nimport pandas as pd","9371c5e3":"question = None\nwritten = False\n\n#\u041c\u044b \u0438\u0434\u0435\u043c \u043f\u043e \u0432\u0441\u0435\u043c \u0437\u0430\u043f\u0438\u0441\u044f\u043c, \u0431\u0435\u0440\u0435\u043c \u043f\u0435\u0440\u0432\u0443\u044e \u0441\u0442\u0440\u043e\u043a\u0443 \u043a\u0430\u043a \u0432\u043e\u043f\u0440\u043e\u0441\n# \u0438 \u043f\u043e\u0441\u043b\u0435 \u0437\u043d\u0430\u043a\u0430 --- \u043d\u0430\u0445\u043e\u0434\u0438\u043c \u043e\u0442\u0432\u0435\u0442\nwith open(\"prepared_answers.txt\", \"w\") as fout:\n    with open(\"..\/input\/otvety\/Otvety.txt\", \"r\") as fin:\n        for line in tqdm_notebook(fin):\n            if line.startswith(\"---\"):\n                written = False\n                continue\n            if not written and question is not None:\n                fout.write(question.replace(\"\\t\", \" \").strip() + \"\\t\" + line.replace(\"\\t\", \" \"))\n                written = True\n                question = None\n                continue\n            if not written:\n                question = line.strip()\n                continue\n","bba370f1":"def preprocess_txt(line):\n    spls = \"\".join(i for i in line.strip() if i not in exclude).split()\n    spls = [morpher.parse(i.lower())[0].normal_form for i in spls]\n    spls = [i for i in spls if i not in sw and i != \"\"]\n    return spls","04395077":"sentences = []\n\nmorpher = MorphAnalyzer()\nsw = set(get_stop_words(\"ru\"))\nexclude = set(string.punctuation)\nc = 0\n\nwith open(\"..\/input\/otvety\/Otvety.txt\", \"r\") as fin:\n    for line in tqdm_notebook(fin):\n        spls = preprocess_txt(line)\n        sentences.append(spls)\n        c += 1\n        if c > 500000:\n            break\n","d668ac73":"sentences[:5]","dd448182":"# Apply Word2Vec\nsentences = [i for i in sentences if len(i) > 2]\nmodel = Word2Vec(sentences=sentences, vector_size=100, min_count=1, window=5)\nmodel.save(\"w2v_model.model\")","a113c50d":"# Store just the words + their trained embeddings.\nword_vectors = model.wv\nword_vectors.save(\"word2vec.wordvectors\")\n\n# Load back with memory-mapping = read-only, shared across processes.\n#word_vectors = KeyedVectors.load(\"..\/input\/models\/word2vec.wordvectors\", mmap='r')","4c6e0793":"keys = word_vectors.key_to_index # dictionary of all words in Word2Vec model","07927d6f":"len(keys)","f8a3cb37":"index = annoy.AnnoyIndex(100 ,'angular')\n\nindex_map = {}\ncounter = 0\n\nwith open(\"..\/input\/d\/irynaalshakova\/models\/prepared_answers.txt\", \"r\") as f:\n    for line in tqdm_notebook(f):\n        n_w2v = 0\n        spls = line.split(\"\\t\")\n        index_map[counter] = spls[1]\n        question = preprocess_txt(spls[0])\n        vector = np.zeros(100)\n        for word in question:\n            if word in keys.keys():\n                vector += word_vectors[word]\n                n_w2v += 1\n        if n_w2v > 0:\n            vector = vector \/ n_w2v\n        index.add_item(counter, vector)\n            \n        counter += 1\n\nindex.build(10)\nindex.save('speaker.ann')","c7772113":"with open('index_map.json', 'w') as fp:\n    json.dump(index_map, fp)","081aac16":"### Preprocess the mail.ru responses from the file: attach 1 answer to each question and write it down to a new file, which will be used further.","1581f230":"# ChatBot"}}