{"cell_type":{"5f36bdf0":"code","726cb946":"code","4549d235":"code","40549b3a":"code","1aff684e":"code","e22a01e4":"code","8d19b922":"code","76aae059":"code","cd090e72":"code","b98adc6f":"code","a75ffcaa":"code","84479ca7":"code","b3350ba1":"code","7f0f747c":"code","5d92aa20":"code","e7f57c54":"code","2b179a50":"code","5647bcd0":"code","0679236f":"code","ebbdecdf":"code","20b40cb0":"code","a8694c50":"code","16ff670c":"code","fde50f5f":"code","5121076a":"code","d8e5aff5":"code","065e678d":"markdown","25d0f8b7":"markdown","70020c25":"markdown","4e545d41":"markdown","836e303c":"markdown","2327437e":"markdown","1f8613d2":"markdown","244237a3":"markdown","988d4567":"markdown","8e5ee3e0":"markdown","de219ba2":"markdown","64d5e9e8":"markdown","249fb3ff":"markdown","3906ec6f":"markdown","5148e91f":"markdown","d5ec79b1":"markdown"},"source":{"5f36bdf0":"## Import Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport nltk\nfrom nltk.stem import PorterStemmer\nimport re\nimport tensorflow\nfrom tensorflow.keras.layers import Embedding, Dense, LSTM\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import one_hot","726cb946":"## This is the test Data\ntest_data = pd.read_csv('..\/input\/fake-news\/test.csv')","4549d235":"## Import dataset\n\ndf = pd.read_csv('..\/input\/fake-news\/train.csv')","40549b3a":"df.head()","1aff684e":"## Check the Null Values \ndf.isnull().sum()","e22a01e4":"# Drop Null values\ndf = df.dropna()","8d19b922":"# Now count the Unique values to check the data is balanced or not\ncount = np.unique(df['label'], return_counts=True)\ncount","76aae059":"import seaborn as sns\nsns.countplot(x='label', data = df)","cd090e72":"# Dependent Features\nY = df['label']\n\n# Independent Features\nX = df.drop('label', axis=1)","b98adc6f":"# make the copy of Dependent Featues and reset the index because we drop the nan values due to this \n# the index is disturb\nmessages = X.copy()\n# messages.reset_index(inplace=True)\n","a75ffcaa":"messages['title'][1]","84479ca7":"messages.reset_index(inplace=True)","b3350ba1":"nltk.download('stopwords')","7f0f747c":"from nltk.corpus import stopwords\nstopwords = set(stopwords.words('english'))","5d92aa20":"ps = PorterStemmer()\ncorpus = []\nfor i in range(0, len(messages)):\n    review = re.sub('[^a-zA-Z]', ' ', messages['title'][i])\n    review = review.lower()\n    review = review.split()\n    \n    review = [ps.stem(word) for word in review if not word in stopwords]\n    review = ' '.join(review)\n    corpus.append(review)","e7f57c54":"corpus[1]","2b179a50":"voc_size = 5000\nonehot_repre = [one_hot(words, voc_size) for words in corpus]\nonehot_repre[0]","5647bcd0":"sent_length = 20\nembedded_docs = pad_sequences(onehot_repre, padding='pre', maxlen=sent_length)\nprint(embedded_docs[0])","0679236f":"embedding_vector_features = 40\nmodel = Sequential()\nmodel.add(Embedding(voc_size, embedding_vector_features, input_length=sent_length))\nmodel.add(LSTM(100))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nprint(model.summary())\n","ebbdecdf":"x_final = np.array(embedded_docs)\ny_final = np.array(Y)","20b40cb0":"x_final.shape, y_final.shape","a8694c50":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(x_final, y_final, test_size=0.33, random_state=42)","16ff670c":"model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=64)","fde50f5f":"classes_x = (model.predict(X_test) > 0.5).astype(\"int32\")","5121076a":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_test, classes_x)","d8e5aff5":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test,classes_x)","065e678d":"### Model Training","25d0f8b7":"**In above cell we change every sentence into 20 words, if the sentence is less then 20 words then we add zeros at the start.**","70020c25":"**First split the dataset into Dependent and Independent Features**","4e545d41":"### Split the Data into Train and Test","836e303c":"## Word Embedding","2327437e":"## Creating a Model","1f8613d2":"## Basic Analysis","244237a3":"**Confusion Matrix**","988d4567":"As you can see the data is balanced, so we don't need to do something here","8e5ee3e0":"## One Hot Representation\n\nIn this step we change the dataset into Numerical representation","de219ba2":"As you can see there are some **Null Values**. Drop all these Null values because we can not add word by us randomly.","64d5e9e8":"**Accuracy Score**","249fb3ff":"**Data Preprocessing**","3906ec6f":"As you can see we stemmed the data and change the data into numerical representation","5148e91f":"# Fake News Detection Using LSTM","d5ec79b1":"### Performance Metrics and Accuracy"}}