{"cell_type":{"9b86c8de":"code","8cee2795":"code","cb8eee11":"code","6ca61267":"code","c7fa1599":"code","281607e7":"code","141ca07e":"code","b2e14fe4":"code","a50798bd":"code","070f498a":"code","7ee1b935":"code","43abec5f":"code","6ea71fb4":"code","5cfeef29":"code","abfc1b8f":"code","722ece73":"code","e0806edc":"code","889526b5":"code","20f9e688":"code","99145d7d":"code","53089393":"code","ef1bbcbc":"code","2d834838":"code","0a7ef9fb":"code","50875754":"code","15bb98b6":"code","a96a5a94":"code","d6b4dc24":"code","ad148a6a":"code","7dc6b994":"code","3307c989":"code","0cde2858":"code","096e68b1":"code","f8862cd8":"code","dc5fe358":"code","618b2c5c":"code","68088e0d":"code","49218a2e":"code","d3ba4c98":"code","a0278714":"code","361f4387":"code","45138b0d":"code","7223182a":"code","9c758608":"code","8a3f0541":"code","c1aba0f0":"code","d3649d35":"code","3b8098ae":"code","640e4a1a":"code","73a9b9c4":"code","3db3e582":"code","0a19af23":"code","0a9a4226":"code","32c6b8cc":"code","bd231262":"markdown","a1a7ef09":"markdown","83ae11ad":"markdown","614054b4":"markdown","587c6a10":"markdown","543f2928":"markdown","054224dc":"markdown","00cd7b42":"markdown","fbd8cbb2":"markdown","b6e2bfd6":"markdown","27c18800":"markdown","007915b5":"markdown","ba33e645":"markdown","a1f5508a":"markdown","44d5c3ee":"markdown","b1d1a95b":"markdown","babd250c":"markdown","e48f62ff":"markdown","d1c0c060":"markdown","98b082f9":"markdown","d1464ff6":"markdown","dca63a45":"markdown","0052ebfc":"markdown","03cbbab8":"markdown","68994f37":"markdown","4009dac4":"markdown","f506c4e5":"markdown","74ff5bd6":"markdown","d4c1b619":"markdown","8ae36905":"markdown","e9113f6b":"markdown","940de283":"markdown","9c052679":"markdown","d3dab155":"markdown","43343ee7":"markdown","f33541fc":"markdown","a33dcc3d":"markdown","7713e22e":"markdown","04cec3c8":"markdown","46388e95":"markdown","4c4732aa":"markdown","380f77bd":"markdown","fa03f85a":"markdown"},"source":{"9b86c8de":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","8cee2795":"import os\nimport os.path\nfrom pathlib import Path\nimport glob","cb8eee11":"from PIL import Image\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","6ca61267":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers","c7fa1599":"from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve","281607e7":"from keras.optimizers import RMSprop,Adam,Optimizer","141ca07e":"from tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN, LSTM, GlobalAveragePooling2D\nfrom keras import models\nfrom keras import layers\nimport tensorflow as tf\nfrom keras.applications import VGG16,VGG19","b2e14fe4":"from warnings import filterwarnings\n\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","a50798bd":"Brain_CT_Path = Path(\"..\/input\/brain-ct-hemorrhage-dataset\/Data\")","070f498a":"JPG_Path = list(Brain_CT_Path.glob(r\"**\/*.jpg\"))","7ee1b935":"JPG_Labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],JPG_Path))","43abec5f":"JPG_Path_Series = pd.Series(JPG_Path,name=\"JPG\").astype(str)","6ea71fb4":"JPG_Labels_Series = pd.Series(JPG_Labels,name=\"CATEGORY\")","5cfeef29":"Main_Data = pd.concat([JPG_Path_Series,JPG_Labels_Series],axis=1)","abfc1b8f":"print(Main_Data.head(-1))","722ece73":"Main_Data[\"CATEGORY\"].replace({\"11[11]\":\"Hemorrhage\",\"11[11]\":\"Hemorrhage\",\"12[12]\":\"Hemorrhage\",\"13[13]\":\"Hemorrhage\",\n                               \"14[14]\":\"Hemorrhage\",\"15[15]\":\"Hemorrhage\",\"17[17]__\":\"Hemorrhage\",\n                               \"19[19]\":\"Hemorrhage\",\"1[1]\":\"Hemorrhage\",\"20[20]_2\":\"Hemorrhage\",\n                               \"21[21] _2\":\"Hemorrhage\",\"2[2]\":\"Hemorrhage\",\"3[3]\":\"Hemorrhage\",\"4[4]\":\"Hemorrhage\",\"5[5]\":\"Hemorrhage\",\n                               \"6[6]\":\"Hemorrhage\",\"7[7]\":\"Hemorrhage\",\"8[8]\":\"Hemorrhage\",\"9[9]\":\"Hemorrhage\"},inplace=True)","e0806edc":"Main_Data[\"CATEGORY\"].replace({\"N10[N10]\":\"Normal\",\"N11[N11]\":\"Normal\",\"N12[N12]\":\"Normal\",\"N13[N13]\":\"Normal\",\"N14[N14]\":\"Normal\",\n                               \"N15[N15]\":\"Normal\",\"N15[N15]\":\"Normal\",\n                               \"N16[N16]\":\"Normal\",\"N17[N17]\":\"Normal\",\"N18[N18]\":\"Normal\",\n                               \"N19[N19]\":\"Normal\",\"N1[N1]\":\"Normal\",\"N20[N20]\":\"Normal\",\"N21[N21]\":\"Normal\",\n                               \"N22[N22]\":\"Normal\",\"N23[N23]\":\"Normal\",\"N24[N24]\":\"Normal\",\n                               \"N25[N25]\":\"Normal\",\"N26[N26]\":\"Normal\",\"N27[N27]\":\"Normal\",\"N2[N2]\":\"Normal\",\n                               \"N3[N3]\":\"Normal\",\"N4[N4]\":\"Normal\",\"N5[N5]\":\"Normal\",\n                               \"N6[N6]\":\"Normal\",\"N7[N7]\":\"Normal\",\"N8[N8]\":\"Normal\",\"N9[N9]\":\"Normal\"},inplace=True)","889526b5":"print(Main_Data.head(-1))","20f9e688":"print(Main_Data[\"CATEGORY\"].value_counts())","99145d7d":"Main_Data = Main_Data.sample(frac=1).reset_index(drop=True)","53089393":"print(Main_Data.head(-1))","ef1bbcbc":"plt.style.use('dark_background')","2d834838":"sns.countplot(Main_Data[\"CATEGORY\"])\nplt.show()","0a7ef9fb":"Main_Data['CATEGORY'].value_counts().plot.pie(figsize=(5,5))\nplt.show()","50875754":"sns.histplot(Main_Data['CATEGORY'].index)\nplt.show()","15bb98b6":"figure = plt.figure(figsize=(10,10))\nx = plt.imread(Main_Data[\"JPG\"][0])\nplt.imshow(x)\nplt.xlabel(x.shape)\nplt.title(Main_Data[\"CATEGORY\"][0])","a96a5a94":"figure = plt.figure(figsize=(10,10))\nx = plt.imread(Main_Data[\"JPG\"][25])\nplt.imshow(x)\nplt.xlabel(x.shape)\nplt.title(Main_Data[\"CATEGORY\"][6769])","d6b4dc24":"fig, axes = plt.subplots(nrows=5,\n                        ncols=5,\n                        figsize=(10,10),\n                        subplot_kw={\"xticks\":[],\"yticks\":[]})\n\nfor i,ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(Main_Data[\"JPG\"][i]))\n    ax.set_title(Main_Data[\"CATEGORY\"][i])\nplt.tight_layout()\nplt.show()","ad148a6a":"Train_Data,Test_Data = train_test_split(Main_Data,train_size=0.9,shuffle=True,random_state=42)","7dc6b994":"print(\"TRAIN SHAPE: \",Train_Data.shape)\nprint(\"TEST SHAPE: \",Test_Data.shape)","3307c989":"print(Train_Data.head(-1))\nprint(\"----\"*20)\nprint(Test_Data.head(-1))","0cde2858":"Generator = ImageDataGenerator(rescale=1.\/255,\n                               zoom_range=0.2,\n                              shear_range=0.2,\n                              rotation_range=40,\n                              horizontal_flip=True,\n                               fill_mode=\"nearest\",\n                              validation_split=0.1)","096e68b1":"Test_Generator = ImageDataGenerator(rescale=1.\/255)","f8862cd8":"example_Image = Train_Data[\"JPG\"][99]\nLoad_Image = image.load_img(example_Image,target_size=(200,200))\nArray_Image = image.img_to_array(Load_Image)\nArray_Image = Array_Image.reshape((1,) + Array_Image.shape)\n\ni = 0\nfor batch in Generator.flow(Array_Image,batch_size=1):\n    plt.figure(i)\n    IMG = plt.imshow(image.array_to_img(batch[0]))\n    i += 1\n    if i % 4 == 0:\n        break\nplt.show()","dc5fe358":"Train_IMG_Set = Generator.flow_from_dataframe(dataframe=Train_Data,\n                                             x_col=\"JPG\",\n                                             y_col=\"CATEGORY\",\n                                             color_mode=\"grayscale\",\n                                             class_mode=\"categorical\",\n                                             subset=\"training\")","618b2c5c":"Validation_IMG_Set = Generator.flow_from_dataframe(dataframe=Train_Data,\n                                                  x_col=\"JPG\",\n                                                  y_col=\"CATEGORY\",\n                                                  color_mode=\"grayscale\",\n                                                  class_mode=\"categorical\",\n                                                  subset=\"validation\")","68088e0d":"Test_IMG_Set = Generator.flow_from_dataframe(dataframe=Test_Data,\n                                                 x_col=\"JPG\",\n                                                 y_col=\"CATEGORY\",\n                                                 color_mode=\"grayscale\",\n                                                 class_mode=\"categorical\")","49218a2e":"for data_batch,label_batch in Train_IMG_Set:\n    print(\"DATA SHAPE: \",data_batch.shape)\n    print(\"LABEL SHAPE: \",label_batch.shape)\n    break","d3ba4c98":"for data_batch,label_batch in Validation_IMG_Set:\n    print(\"DATA SHAPE: \",data_batch.shape)\n    print(\"LABEL SHAPE: \",label_batch.shape)\n    break","a0278714":"print(\"TRAIN: \")\nprint(Train_IMG_Set.class_indices)\nprint(Train_IMG_Set.classes[0:5])\nprint(Train_IMG_Set.image_shape)\nprint(\"---\"*20)\nprint(\"VALIDATION: \")\nprint(Validation_IMG_Set.class_indices)\nprint(Validation_IMG_Set.classes[0:5])\nprint(Validation_IMG_Set.image_shape)\nprint(\"---\"*20)\nprint(\"TEST: \")","361f4387":"print(Test_IMG_Set.batch_size)\nprint(Test_IMG_Set.image_shape)","45138b0d":"Model = Sequential()\n\nModel.add(Conv2D(12,(3,3),activation=\"relu\",\n                 input_shape=(256,256,1)))\nModel.add(BatchNormalization())\nModel.add(MaxPooling2D((2,2)))\n\n#\nModel.add(Conv2D(24,(3,3),\n                 activation=\"relu\",padding=\"same\"))\nModel.add(Dropout(0.2))\nModel.add(MaxPooling2D((2,2)))\n\n#\nModel.add(Conv2D(64,(3,3),\n                 activation=\"relu\",padding=\"same\"))\nModel.add(Dropout(0.5))\nModel.add(MaxPooling2D((2,2)))\n\n\n#\nModel.add(TimeDistributed(Flatten()))\nModel.add(Bidirectional(LSTM(32,\n                                  return_sequences=True,\n                                  dropout=0.5,\n                                  recurrent_dropout=0.5)))\nModel.add(Bidirectional(GRU(32,\n                                  return_sequences=True,\n                                  dropout=0.5,\n                                  recurrent_dropout=0.5)))\n\n#\nModel.add(Flatten())\nModel.add(Dense(256,activation=\"relu\"))\nModel.add(Dropout(0.5))\nModel.add(Dense(2,activation=\"softmax\"))","7223182a":"Call_Back = tf.keras.callbacks.EarlyStopping(monitor=\"loss\",patience=5,mode=\"min\")","9c758608":"Model.compile(optimizer=\"rmsprop\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])","8a3f0541":"CNN_Model = Model.fit(Train_IMG_Set,\n                      validation_data=Validation_IMG_Set,\n                            callbacks=Call_Back,\n                      epochs=50)","c1aba0f0":"Model_Results = Model.evaluate(Test_IMG_Set,verbose=False)\nprint(\"LOSS:  \" + \"%.4f\" % Model_Results[0])\nprint(\"ACCURACY:  \" + \"%.2f\" % Model_Results[1])","d3649d35":"print(Model.summary())","3b8098ae":"plt.plot(CNN_Model.history[\"accuracy\"])\nplt.plot(CNN_Model.history[\"val_accuracy\"])\nplt.ylabel(\"ACCURACY\")\nplt.legend()\nplt.show()","640e4a1a":"plt.plot(CNN_Model.history[\"loss\"])\nplt.plot(CNN_Model.history[\"val_loss\"])\nplt.ylabel(\"LOSS\")\nplt.legend()\nplt.show()","73a9b9c4":"plt.plot(CNN_Model.history[\"loss\"])\nplt.plot(CNN_Model.history[\"accuracy\"])\nplt.ylabel(\"LOSS - ACCURACY\")\nplt.legend()\nplt.show()","3db3e582":"plt.plot(CNN_Model.history[\"val_loss\"])\nplt.plot(CNN_Model.history[\"val_accuracy\"])\nplt.ylabel(\"VAL LOSS - VAL ACCURACY\")\nplt.legend()\nplt.show()","0a19af23":"Dict_Summary = pd.DataFrame(CNN_Model.history)\nDict_Summary.plot()\n","0a9a4226":"Prediction = Model.predict(Test_IMG_Set)\nPrediction = Prediction.argmax(axis=-1)","32c6b8cc":"fig, axes = plt.subplots(nrows=5,\n                         ncols=5,\n                         figsize=(20, 20),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(Test_Data[\"JPG\"].iloc[i]))\n    ax.set_title(f\"PREDICTION:{Prediction[i]}\")\nplt.tight_layout()\nplt.show()","bd231262":"#### PATH","a1a7ef09":"#### CHECKING","83ae11ad":"#### How Generator Applied Image Look Like","614054b4":"# LABEL","587c6a10":"# VISUALIZATION","543f2928":"#### APPLYING GENERATOR AND TRANSFORMATION TO TENSOR","054224dc":"#### PREDICTION","00cd7b42":"#### OPTIMIZER","fbd8cbb2":"#### ACCURACY CONTROL","b6e2bfd6":"# IMAGE GENERATOR","27c18800":"* we don't need diversification for test data, we will use it as it is","007915b5":"# SHUFFLING","ba33e645":"* file path is determined","a1f5508a":"#### SCALER & TRANSFORMATION","44d5c3ee":"* we used diversification so that the model does not shift to the overfitting orientation","b1d1a95b":"Loss Function We Used:\n\n\n![](https:\/\/gombru.github.io\/assets\/cross_entropy_loss\/intro.png)","babd250c":"# CNN STRUCTURE WITH LSTM \/ RCNN","e48f62ff":"* we have to change the names because the categories in the data are complex","d1c0c060":"# PATH","98b082f9":"# TRANSFORMATION TO DATAFRAME","d1464ff6":"* Activation Function:\n\n![](http:\/\/rasbt.github.io\/mlxtend\/user_guide\/general_concepts\/activation-functions_files\/activation-functions.png)","dca63a45":"* we used it with Dropout so that the model does not shift to overfitting orientation\n* we made return_success True because we wanted each process to generate output separately","0052ebfc":"* the categories of the images are separated","03cbbab8":"* LSTM and GRU serve to inject past information into the future, thereby reducing the gradient destruction problem","68994f37":"* it is converted to Series structure before it is converted to DataFrame","4009dac4":"#### CHECKING","f506c4e5":"* we have to mix the data to increase the success of the model and maintain its objectivity.","74ff5bd6":"# DETERMINATION TRAIN AND TEST DATA","d4c1b619":"* all images in the file path are assigned to a list","8ae36905":"* LSTM and GRU are iterative layers","e9113f6b":"#### MODEL LAYERS","940de283":"* we wanted the training of the model to stop where the loss value is minimal","9c052679":"#### IGNORING WARNINGS","d3dab155":"* it is converted to DataFrame","43343ee7":"* less problem of gradient disappearance in LSTM and GRU","f33541fc":"# PACKAGES AND LIBRARIES","a33dcc3d":"#### IMAGE PROCESS","7713e22e":"#### GENERAL","04cec3c8":"* we used LSTM and GRU layers both with fully-connetted layers and Conv2D\n* RCNN structure is created in this way\n* we determined the LSTM and GRU layers as bidirectional","46388e95":"* we also used dropout within the GRU and LSTM layers to prevent the model from shifting to the overfitting orientation\n* recurrent_dropout means transmission damping ratio of iterative layers","4c4732aa":"* we divided it into test and training set\n* we set the shuffle parameter to True for training quality\n* we told it to use the same data as random state","380f77bd":"#### REPLACING","fa03f85a":"# TRANSFORMATION TO SERIES"}}