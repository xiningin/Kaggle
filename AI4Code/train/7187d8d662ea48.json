{"cell_type":{"358d2389":"code","c4b6627e":"code","72f31787":"code","760eb9d7":"code","4c494c3b":"code","14af18ef":"code","8fc69ae4":"code","da098bb1":"code","f16f30d2":"code","fc04cb23":"code","bb786e73":"code","bdc6fc89":"code","b3386a81":"code","008835d6":"code","6c4d6688":"code","23883aff":"code","f6272355":"code","b545451a":"code","58b5616f":"code","7f1d2be8":"code","692a3e21":"code","05de6c43":"code","37a4bc5e":"code","3a70f0e9":"markdown","c2a0e2c7":"markdown","364c91e1":"markdown","49fc852a":"markdown","473d5851":"markdown","e893ff8e":"markdown","458fa42c":"markdown","eca2758e":"markdown","d53a9da4":"markdown","9205c9ec":"markdown","31ad653f":"markdown","a9cf9979":"markdown","8f5bafca":"markdown"},"source":{"358d2389":"#import required libraries\nimport pandas as pd\nimport numpy as np\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D","c4b6627e":"train = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')","72f31787":"#let's check out our data\ntrain.head()","760eb9d7":"#init our training and testing\ny_train = train['label']\nX_train = train.drop(labels = ['label'], axis = 1)","4c494c3b":"#How many classes do we have.\nprint(train['label'].unique())\nprint('The number of classes is: ' + str(len(train['label'].unique())))","14af18ef":"y_train.value_counts()","8fc69ae4":"print('Number of missing values is: ' + str(X_train.isnull().any().sum()))","da098bb1":"print('Range is: ' + str(X_train.values.min()) + '-' + str(X_train.values.max()))","f16f30d2":"X_train = X_train \/ 255.0\ntest = test \/ 255.0\nX_train = X_train.astype('float32')\ntest = test.astype('float32')","fc04cb23":"X_train.shape","bb786e73":"X_train = X_train.values.reshape(-1, 28, 28, 1)\ntest = test.values.reshape(-1, 28, 28, 1)","bdc6fc89":"y_train = to_categorical(y_train, num_classes = 10)","b3386a81":"#splitting into training and validation sets to measure model performance.\nX_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.1, random_state = 42)","008835d6":"X_train.shape","6c4d6688":"#look at data shape above. We choose 1st row, then all 28 X 28 pixel values and then 1 to allow matplotlib to identify the image.\nimg = plt.imshow(X_train[0][:,:,0])","23883aff":"model = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\")) #10 classes ","f6272355":"model.compile (optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])","b545451a":"#can use GPU to speed up training times here.\nhistory = model.fit(X_train, y_train,\n                   batch_size = 100,\n                    epochs = 20,\n                    validation_data = (X_valid, y_valid),\n                    verbose = 1,\n                   steps_per_epoch = X_train.shape[0] \/\/ 100)","58b5616f":"fig, ax = plt.subplots(1,2, figsize = (10,5))\n\n#accuracy plot\nax[0].plot(history.history['accuracy'], color = 'b', label = 'Training Accuracy', marker = 'o')\nax[0].plot(history.history['val_accuracy'], color = 'r', label = 'Validation Accuracy', marker = 'o')\nax[0].set_title('Accuracy')\nax[0].legend(loc = 'best')\n\n#loss plot\nax[1].plot(history.history['loss'], color = 'b', label = 'Training Loss', marker = 'o')\nax[1].plot(history.history['val_loss'], color = 'r', label = 'Validation Loss', marker = 'o')\nax[1].set_title('Loss')\nax[1].legend(loc = 'best')","7f1d2be8":"predicted_classes = model.predict_classes(test)\npredicted_classes = predicted_classes.reshape(-1,1)","692a3e21":"submission_df = pd.DataFrame(predicted_classes)\nsubmission_df.index.rename('ImageId', inplace = True)\nsubmission_df.index+=1\ncols = ['Label']\nsubmission_df.columns = [i for i in cols]","05de6c43":"#write file to csv output\nsubmission_df.to_csv('submission.csv')","37a4bc5e":"submission_df","3a70f0e9":"Above we see that the dataframe has 785 columns with 1 column referring to the label. Our data will take the shape 28X28 = 784 when visualizing images. The label column refers to what class each digit takes. (i.e. digit 5 will be in class 5 and vice-versa). To proceed we will visualize the number of values per digit and also create our y column ('label').","c2a0e2c7":"## Normalize\n* Our machine learning algorithm will perform much better if we normalize the data. We can look at what range the values take, however in this dataset they are images and we have pixel values ranging from 0-255 inclusively. Therefore if we divide each value by 255.0 we will normalize all of our data to be on a 0-1 scale which will help out our classification model a lot.","364c91e1":"For the most part, our labels look to be pretty evenly distributed. The next step is to look at whether there are any missing values in the data.","49fc852a":"## CNN","473d5851":"## Predictions","e893ff8e":"## Prepare Data","458fa42c":"## One Hot Encoding\n* We will use keras to_categorical to one hot encode our labels. Therefore it will create an array of length 10 with a 1 representing True. Each position (index) in the array will correspond to the class. So if we have a 1 in index 2 then that will represent a classification of class 2 (assuming index 0 represents class 0). ","eca2758e":"## Training-Testing","d53a9da4":"## Reshaping \n* We must reshape our data because if we investigate the shape of our training dataset we see that there are 784 columns. In order for our algorithm to classify our data we must reshape it into 28X28 values.","9205c9ec":"We can easily plot our training and validation accuracy & loss to show whether or not our model overfit.","31ad653f":"## Table of Contents\n* [Prepare Data](#Prepare-Data)\n* [Normalize](#Normalize)\n* [Reshaping](#Reshaping)\n* [One Hot Encoding](#One-Hot-Encoding)\n* [Training & Testing](#Training-Testing)\n* [Visualizing Images](#Visualizing-Images)\n* [CNN](#CNN)\n* [Predictions](#Predictions)\n","a9cf9979":"## Visualizing Images\n* It will be helpful to visualize our images so we can understand what data will be fed into our algorithm","8f5bafca":"# Classifying Digits: A Beginner's Tutorial\n* In this notebook we use a CNN to train and classify images to 10 different classes (handwritten digits 0-9)."}}