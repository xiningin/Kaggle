{"cell_type":{"0ed512d1":"code","66bedff9":"code","1260c8fd":"code","65846934":"code","6ca22dc1":"code","fe7d73f1":"code","3abda1fa":"code","a6a09cb3":"code","12239aad":"code","1876e102":"code","3fa65684":"code","995b5018":"code","9b75ca17":"code","7f87bd08":"code","4acaae0c":"code","99fe4631":"code","f1679fa1":"code","dc22ed78":"code","6f352816":"code","5fb0dd56":"code","cf58cbae":"code","1f0477b1":"code","bd1d178b":"code","68fc3958":"markdown","fdead058":"markdown","7020d654":"markdown","0d7a6906":"markdown","c417af80":"markdown","914f565e":"markdown","c96c3f36":"markdown","9f37b28a":"markdown","22bd9f25":"markdown","cd9399af":"markdown","9e369cd4":"markdown","d9b414fc":"markdown","ee85397b":"markdown","9a96f4ba":"markdown","d341cc3d":"markdown","c9b7d942":"markdown","e10598d8":"markdown","f250a678":"markdown","6836af50":"markdown","f0356634":"markdown","0fbb1d70":"markdown","eba09084":"markdown","c1b093a8":"markdown","8daab0eb":"markdown","8e4d1781":"markdown","ca7ffff2":"markdown","efe93857":"markdown","95a4c063":"markdown","025d6a63":"markdown"},"source":{"0ed512d1":"#Import libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\nimport seaborn as sns # charts\nimport matplotlib.pyplot as plt  #charts\nimport matplotlib.patches as patches\nimport matplotlib as mpl\nfrom matplotlib.gridspec import GridSpec\nimport math as math\nimport graphviz as gv\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()\n\n#Magic function to display plots below the code cell that produced it.\n%matplotlib inline\n#Generator for figures numbering\ndef figcount(start=1):\n    num = start\n    while True:\n        yield str(num)\n        num += 1\nfig_n = figcount()","66bedff9":"sns.set_style('whitegrid')\n#color coding the roles\nroles = ['Business Analyst','Data Analyst','Data Scientist']\nroles_c = {'Business Analyst':'#CAD49D', 'Data Analyst': '#8D89C0', 'Data Scientist':'#1F78B4'}\nsingle_color = '#1F78B4'\n\n\ngoogle_trends = pd.read_csv(\"..\/input\/google-trends-data-scientist-comparison\/GoogleTrends-DS-DA-BA.csv\")\ngoogle_trends = google_trends.set_index(\"Month\")\ngoogle_trends = google_trends.rename(columns={\n    'business analyst: (Worldwide)':'Business Analyst', 'data analyst: (Worldwide)' :'Data Analyst',\n       'data scientist: (Worldwide)':'Data Scientist'})\n\ngoogle_trends.loc[google_trends['Data Scientist']=='<1']\ngoogle_trends['Data Scientist'] = google_trends['Data Scientist'].replace('<1',0.9)\ngoogle_trends = google_trends.astype(float)\ngoogle_trends.index = pd.to_datetime(google_trends.index,format='%Y-%m')\n\ncolors = list(roles_c.values())\nc_palette = sns.color_palette(colors)\n\nfig, ax = plt.subplots(figsize=(12, 5))\nax = sns.lineplot(data=google_trends, palette=c_palette, dashes = False)\nax.set(xticks=pd.date_range(start=google_trends.index.min(), end=google_trends.index.max(), freq='12M'),xlabel = 'Year')\nax.grid(False)\nax.xaxis.set_label_text(\"\")\nax.tick_params(labelsize=12)\nannotation_text = (\"Figure \"+next(fig_n)+\": Worldwide interest in selected search terms from 2004 until present\"\n                  +\"\\nSource: Google Trends\\n100 is the peak popularity for the term. 50 means that the term is half as popular. 0 means not enough data\")\nsns.despine(left=True, bottom=True)\nplt.annotate(annotation_text, (0,0), (0, -40), xycoords='axes fraction', textcoords='offset points', va='top', ha='left', fontsize=11)\nplt.tight_layout()","1260c8fd":"#Data import and pre-processing:\nresponses = pd.read_csv(\"..\/input\/kaggle-survey-2019\/multiple_choice_responses.csv\", skiprows = [1], low_memory = False) \nother_text_responses = pd.read_csv(\"..\/input\/kaggle-survey-2019\/other_text_responses.csv\", dtype='object')\nquestions_only = pd.read_csv(\"..\/input\/kaggle-survey-2019\/questions_only.csv\", dtype='object').T.reset_index().rename(columns = {'index':'q_num', 0:'q_text'})\nsurvey_schema = pd.read_csv(\"..\/input\/kaggle-survey-2019\/survey_schema.csv\", dtype='object')\nbig_mac_data = pd.read_csv(\"..\/input\/worldwide-big-mac-prices\/big-mac-source-data.csv\")\n#add indicator whether the question is single choice\nquestions_only['single_choice'] = questions_only.apply(lambda row: False if 'select all' in str(row['q_text']).lower() else True, axis=1)\nquestions_only = questions_only.drop([0])\n\n#columns renaming and casting\nresponses = responses.rename(columns={\"Time from Start to Finish (seconds)\":\"Survey_time\"})\nresponses['Survey_time'] = responses['Survey_time'].astype(int)\nresponses = responses.rename(columns=lambda x: x.replace('Part_','A') if '_Part' in x else x)\n\n#add metrics whether respondent answered each of the multiple choice questions\nfor q in questions_only.loc[questions_only['single_choice']==False, 'q_num']:\n    #count non empty values in columns containing answers to our question excluding _OTHER_TEXT_COLUMN\n    q_regex = '^'+q+'_.*\\d$'\n    responses.insert(responses.columns.get_loc(q+'_OTHER_TEXT'),q+'_choices_cnt',responses.filter(regex=q_regex).count(axis=1))\n#responses.head(2)\n\n#According to survey schema there were 3 possible exit points for different respondents: Q15, Q28 or Q38\n#Exit_question - question which was supposed to be the last question of the survey for this individual\n#conditions & outputs\nconditions = [\n    responses['Q15']=='I have never written code',\n    (responses['Q15']!='I have never written code')&\n        ((responses['Q5']=='Student')|(responses['Q5']=='Not employed')|(responses['Q11']=='$0 (USD)'))\n    ]\noutputs = ['Q15','Q28']\n\nresponses['Exit_question'] = np.select(conditions, outputs, 'Q34')\n\n#Adding info about whether respondent finished the whole survey\nresponses['Finished'] = (\n        ((responses['Exit_question']=='Q34')&(responses['Q34_choices_cnt']!=0))|\n        (responses['Exit_question']=='Q15')|\n        ((responses['Exit_question']=='Q28')&(responses['Q28_choices_cnt']!=0))\n                        )\n#Creating separate data frame for those who finished the survey (26% respondents were removed)\nresponses_f=responses.loc[responses['Finished']==True].copy()\n\n#Calculating quantiles on time it took respondents to finish the survey \n#(separately for those who exit after Q15, Q28 or Q34)\nresponses_f['rank_by_q'] = responses_f[['Exit_question','Survey_time']].groupby('Exit_question').rank(method='first')\nresponses_f['size_by_q'] = responses_f.groupby('Exit_question')['Survey_time'].transform('size')\nresponses_f['quantile'] = responses_f['rank_by_q'] \/ responses_f['size_by_q']\n#Creating a separate data frame, where 1% were removed \nresponses_ff = responses_f.loc[(responses_f['quantile']>=0.01)].copy()","65846934":"#data preparation\n#calculate how many respondents finished survey by job title\nchart1_d = responses.groupby(['Q5','Finished']).size()\n#express this number as percentage of the group\nchart1_d = chart1_d.div(chart1_d.sum(level='Q5'), axis=0)*100\nchart1_d = chart1_d.unstack('Finished').rename(columns={False:'Did not finish',True:'Finished'}).reset_index().sort_values('Finished')\n\n#plotting\nfig, ax = plt.subplots(figsize=(12, 5))\n#plt.barh(y=chart1_d['Q5'].str.upper(), width=chart1_d[\"Finished\"], height=0.8, color=single_color)\nplt.hlines(y=chart1_d['Q5'].str.upper(), xmin=0, xmax=chart1_d[\"Finished\"], color=single_color, alpha=0.7, linewidth=2)\nplt.scatter(y=chart1_d['Q5'].str.upper(), x=chart1_d[\"Finished\"], s=75, color=single_color, alpha=0.7)\n#plot decoration\nax.set(xlim=(0, 100))\nax.xaxis.set_ticks(np.arange(0, 101, 10))\nax.yaxis.grid(False)\nax.set_title((\"Only people who are not employed were more dedicated to\\nfinishing the survey than data scientists\"), fontsize=14)\nax.xaxis.set_label_text(\"% respondents\", fontsize=14)\nax.tick_params(labelsize=10)\nannotation_text = \"Figure \"+next(fig_n)+\": Percentage of respondents who finished the survey by job title\"\nsns.despine(left=True, bottom=True)\nplt.annotate(annotation_text, (0,0), (0, -50), xycoords='axes fraction', textcoords='offset points', va='top', ha='left', fontsize=11)\nplt.tight_layout()\nplt.show()","6ca22dc1":"#data preparation - calculate for each repported job role total number of respondents and those who were excluded from analysis\nchart2_t = responses.loc[responses['Q5'].isin(roles)].groupby('Q5').size()\nchart2_d = responses_ff.loc[responses_ff['Q5'].isin(roles)].groupby('Q5').size()\nchart2_dd = pd.concat([chart2_d, chart2_t], axis=1).reset_index().rename(columns={0:'Not excluded',1:'All'})\nchart2_dd['Excluded'] = chart2_dd['All']-chart2_dd['Not excluded']\nchart2_d = chart2_dd[['Q5','Not excluded','Excluded']]\n\n#plotting\nfig, ax = plt.subplots(figsize=(12, 5))\nfor r in roles:\n    #choose color\n    bc = roles_c[r] if r in roles else '#bbbbbb'\n    #plot stacked bars:\n    plt.bar(x=r, height=chart2_d.loc[chart2_d['Q5']==r]['Not excluded'], color=bc, alpha=0.8)\n    plt.bar(x=r, height=chart2_d.loc[chart2_d['Q5']==r]['Excluded'], bottom=chart2_d.loc[chart2_d['Q5']==r]['Not excluded'], color='#eeeeee')\n    total_height = (chart2_d.loc[chart2_d['Q5']==r]['Not excluded']+chart2_d.loc[chart2_d['Q5']==r]['Excluded']).iloc[0]\n    included_height = (chart2_d.loc[chart2_d['Q5']==r]['Not excluded']).iloc[0]\n    ax.text(r, total_height+5, str(total_height)+\"\\n(total)\", ha='center', va='bottom', fontsize=12)\n    ax.text(r, included_height\/2, str(included_height)+\"\\n(analyzed)\", ha='center', va='center', fontsize=12)\n#plot decoration\nax.set_title((\"Almost twice as many data scientists participated in the survey\\ncompared to business analysts and data analysts combined\"), fontsize=14)\nax.yaxis.set_label_text(\"# respondents\", fontsize=12)\nax.xaxis.set_label_text(\"\")\nax.set_xticklabels(chart2_d['Q5'], rotation = 0, fontsize=12)\nax.set(ylim=(0, 4600))\nax.tick_params(labelsize=12)\nax.xaxis.grid(False)\nsns.despine(left=True, bottom=True)\n#create a special legend, for \"excluded\" \nhandles = [plt.bar(x=0, height=0, color='#eeeeee')]\nplt.legend(handles, ['Excluded*'], loc = 'upper left', bbox_to_anchor=(0, 1), ncol=1, labelspacing=0.5, fontsize=12)\n\nannotation_text = (\"Figure \"+next(fig_n)+\": Number of respondents in selected groups\"+\n                    \"\\nSource: ML&DL survey 2019, question 5\"+\n                    \"\\n*those who dropped out in the middle (~23%) or were too quick (~1%)\")\nplt.annotate(annotation_text, (0,0), (0, -40), xycoords='axes fraction', textcoords='offset points', va='top', ha='left', fontsize=11)\n\n    \n\nplt.tight_layout()\nplt.show()","fe7d73f1":"#age distribution by roles\nage_raw = responses_ff.loc[responses_ff['Q5'].isin(roles),['Q1','Q5']]                                   \nage_dist = age_raw.groupby(['Q5','Q1']).size()\nage_dist = age_dist.div(age_dist.sum(level='Q5')).reset_index().rename(columns={0:'Percentage'})\nage_dist = age_dist.pivot(index='Q1', columns='Q5', values='Percentage').reset_index()\n\nfig, ax = plt.subplots(figsize=(12,5))\n\n#line plot for age\nfor role_name, role_color in roles_c.items():\n    ax.plot(age_dist['Q1'].str.upper(), age_dist[role_name]*100, label=age_dist[role_name].name,\n         color = role_color, linestyle = '--', marker = 'o', markersize=12, linewidth=1.5, alpha = 0.9)\n\n#plots decoration\nax.set_xticklabels(age_dist['Q1'].str.lower(), rotation=0, fontsize=12)\nax.set_title((\"Age distributions within the groups are similar, with a slightly\\nhigher share of older respondents among business analysts\"), fontsize=14)\nax.set_ylim(-1,35)\nax.tick_params(labelsize=12)\nax.yaxis.set_label_text(\"% respondents\", fontsize=12)\nannotation_text = (\"Figure \"+next(fig_n)+\": Age distribution of selected groups\"+\n                    \"\\nSource: ML&DL survey 2019, question 1\")\nax.annotate(annotation_text,(0,0), (0, -40), xycoords='axes fraction', textcoords='offset points', va='top', ha='left',fontsize=11)\nax.legend(loc='upper right', bbox_to_anchor=(0.98, 0.98), ncol=1, labelspacing=0.5, fontsize=11)\n\nsns.despine(left=True, bottom=True)\nplt.tight_layout()\nplt.show()","3abda1fa":"#education by roles mapping to make labels shorter\ned_levels_map = {\n    'No formal education past high school' : 'No\\ndegree',\n    'Some college\/university study without earning a bachelor\u2019s degree' : 'No\\ndegree', \n    'Bachelor\u2019s degree' : 'Bachelor\u2019s\\ndegree',  \n    'Professional degree' : 'Professional\\ndegree',\n    'Master\u2019s degree': 'Master\u2019s\\ndegree', \n    'Doctoral degree': 'Doctoral degree\\n(PhD)',\n    'I prefer not to answer':'I prefer not to answer'}\ned_levels = ['No\\ndegree','Bachelor\u2019s\\ndegree','Professional\\ndegree', 'Master\u2019s\\ndegree','Doctoral degree\\n(PhD)','I prefer not to answer']\ned_raw = responses_ff.loc[responses_ff['Q5'].isin(roles)][['Q4','Q5']]\n#map original levels to the new ones desribe in the dictionary ed_levels_map\ned_raw['Education'] = ed_raw['Q4'].map(ed_levels_map) \n#calculate data for plot\ned_dist = ed_raw.groupby(['Q5','Education']).size()\ned_dist = ed_dist.div(ed_dist.sum(level='Q5')).reset_index().rename(columns={0:'Percentage'})\ned_dist = ed_dist.pivot(index='Education', columns='Q5', values='Percentage').reset_index()\ned_dist = ed_dist.loc[(ed_dist['Education']!='I prefer not to answer')] #do not plot because this group is small,  &(ed_dist['Education']!='No degree')\ned_dist['Education'] = pd.Categorical(ed_dist['Education'],ed_levels)\ned_dist = ed_dist.sort_values('Education')\ned_dist = ed_dist.set_index('Education').multiply(100)\n\nfig, ax = plt.subplots(figsize=(12,6))\n\n#education bar chart\ned_dist.plot(kind='bar',  ax=ax, color=list(roles_c.values()))    \n\n#plot decoration\nax.set_xticklabels(ed_dist.index, rotation=0, fontsize=12)\nax.set_title((\"A data scientist is 3 times more likely to have a doctoral degree\\nthan a business analyst or data analyst\"), fontsize=14)\nax.tick_params(labelsize=12)\nax.xaxis.set_label_text(\"\")\nax.set_ylim(0,63)\nax.yaxis.set_label_text(\"% respondents\", fontsize=12)\nannotation_text = (\"Figure \"+next(fig_n)+\": Education level of selected groups\"+\n                   \"\\nSource: ML&DL survey 2019, question 4\")\nax.annotate(annotation_text,(0,0), (0, -50), xycoords='axes fraction', textcoords='offset points', va='top', ha='left',fontsize=11)\nax.legend(loc='upper left', bbox_to_anchor=(0.02, 0.98), ncol=1, labelspacing=0.5, fontsize=12)\n\nsns.despine(left=True, bottom=True)\nplt.tight_layout()\nplt.show()","a6a09cb3":"ml_states_map = {\n    'I do not know' : 'Unaware of ML state in the company', \n    'No (we do not use ML methods)' : \"Company don't use ML\",\n    'We are exploring ML methods (and may one day put a model into production)': 'Company explore\/use ML',\n    'We use ML methods for generating insights (but do not put working models into production)' : 'Company explore\/use ML',\n    'We recently started using ML methods (i.e., models in production for less than 2 years)' : 'Company explore\/use ML',\n    'We have well established ML methods (i.e., models in production for more than 2 years)': 'Company explore\/use ML'}\n\nml_states_map_detailed = {\n    'We are exploring ML methods (and may one day put a model into production)': 'Exploring ML',\n    'We use ML methods for generating insights (but do not put working models into production)' : 'Generate insights with ML',\n    'We recently started using ML methods (i.e., models in production for less than 2 years)' : 'Models in production less than 2 years',\n    'We have well established ML methods (i.e., models in production for more than 2 years)': 'Models in prodution more than 2 years'}\n\nq9_answers_map = {\n    'Q9_A1': 'Data analysis',\n    'Q9_A2': 'Build or run data infrastructure',\n    'Q9_A3': 'Build ML\\nprototypes',\n    'Q9_A4': 'Build or run\\nML services',\n    'Q9_A5': 'Improve\\nML models',\n    'Q9_A6': 'Research to\\nadvance ML',\n    'Q9_A7': 'None',\n    'Q9_A8': 'Other'}\n\n#data for chart a and b\ncompany_ML_state = responses_ff.loc[responses['Q5'].isin(roles),['Q5','Q8']]\ncompany_ML_state['Q8'] = company_ML_state['Q8'].map(ml_states_map)\ncompany_ML_state = company_ML_state.groupby(['Q5','Q8']).size().unstack('Q8')\ncompany_ML_state['Unaware']=company_ML_state['Unaware of ML state in the company']*100\/(company_ML_state.sum(axis=1))\ncompany_ML_state['Informed'] = 100 - company_ML_state['Unaware']\ncompany_ML_state['no ML']=company_ML_state[\"Company don't use ML\"]*100\/(company_ML_state[[\"Company don't use ML\",\"Company explore\/use ML\"]].sum(axis=1))\ncompany_ML_state['ML is used']=company_ML_state[\"Company explore\/use ML\"]*100\/(company_ML_state[[\"Company don't use ML\",\"Company explore\/use ML\"]].sum(axis=1))\ncompany_ML_state.index = company_ML_state.index.str.wrap(9)\n\nfig, ax = plt.subplots(1,2, figsize=(12,5))\n\nyaxis_labels = {\n    0:\"% respondents informed on ML state\",\n    1:\"% respondents\"}\n\ntitles = {\n    0:(\"Data scientists are best informed on\\nwhether ML methods are used\\nin the company\"),\n    1:(\"94% of data scientists work at\\ncompanies which either use or explore\\nML methods\")}\n\naxis_colors = {\n    0:[single_color],\n    1:['#8A716A','#B0BAB8']}\n\nannotations = {\n    0:\"Figure \"+next(fig_n)+\": ML usage in companies of employment\"\n    +\"\\nSource: ML&DS survey 2019, question 8.\",\n    1:\"\"}\n\n \n#plot a - anaware\ncompany_ML_state['Informed'].plot(kind='bar', ax=ax[0], label='Informed on whether company uses ML',color=axis_colors[0], alpha=0.7, width=0.8)\nfor i, val in enumerate(company_ML_state['Informed'].values):\n    ax[0].text(i, val\/2, '{:.0f}%'.format(val), ha='center', va='bottom', fontsize=12)\n\n#plot b - company uses\/does not use ML\ncompany_ML_state[['ML is used','no ML']].plot(kind='bar', stacked='True', ax=ax[1], color = axis_colors[1], alpha=0.8,  width=0.8)\nfor i, val in enumerate(company_ML_state['ML is used'].values):\n    ax[1].text(i, val\/2, '{:.0f}%'.format(val), ha='center', va='bottom', fontsize=12)\n\n#plots decoration\nfor i in [0,1]:\n    c_ax = ax[i]\n    \n    c_ax.xaxis.grid(False)\n    c_ax.set_xticklabels(c_ax.get_xticklabels(), rotation=0, fontsize=12)\n    c_ax.xaxis.set_label_text(\"\")\n    c_ax.yaxis.set_label_text(yaxis_labels[i], fontsize=12)\n    c_ax.tick_params(labelsize=12)\n    c_ax.set_title(titles[i], fontsize=14)\n    c_ax.annotate(annotations[i],(0,0), (0, -80), xycoords='axes fraction', textcoords='offset points', \n                  va='top', ha='left',fontsize=11)\n\nax[1].legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=2, labelspacing=0.5, fontsize=12)    \nsns.despine(left=True, bottom=True)\nplt.show()","12239aad":"d = responses_ff.loc[(responses_ff['Q5'].isin(roles))&responses['Q8'].isin(list(ml_states_map_detailed.keys())),['Q5','Q8']+list(q9_answers_map.keys())]\nd['Q8'] = d['Q8'].map(ml_states_map_detailed)\nd['Q8'] = pd.Categorical(d['Q8'],list(ml_states_map_detailed.values()))\nd['ML is part of the role'] = (d['Q9_A3'].notna())| (d['Q9_A4'].notna())|(d['Q9_A5'].notna())|(d['Q9_A6'].notna())\nactivities_raw = d\n\nml_agg = activities_raw.groupby(['Q5','ML is part of the role']).size().unstack('ML is part of the role')\nml_agg = ml_agg.rename(columns={True:'Involved in ML',False:'Not involved in ML'})\nml_agg = ml_agg.div(ml_agg.sum(axis=1),axis=0)\nml = ml_agg['Involved in ML']*100\n\n#NON ML regarless company\nnonml = activities_raw\nnonml_bool = nonml[['Q9_A1','Q9_A2','Q9_A7','Q9_A8']].notna().multiply(1).add_suffix('_bool')\n#decode activities combination with a sequence of ones and zeros\nnonml_bool['nonml_set']=(nonml_bool['Q9_A1_bool']*100+\n                      nonml_bool['Q9_A2_bool']*10)#+\n                      #((nonml_bool['Q9_A7_bool'])|(nonml_bool['Q9_A8_bool']))*1)\n                   \nnonml_data = pd.concat([nonml[['Q5','Q8']], nonml_bool['nonml_set']],axis=1)\nnonml_data_grouped = nonml_data.groupby(['Q5','nonml_set']).size().unstack('Q5')\nd = nonml_data_grouped.sort_values(by=['Data Scientist'],ascending=False)\nd = d.div(d.sum(axis=0),axis=1)*100\na = d.loc[[100,110],:].sum(axis=0) #analysis\ni = d.loc[[10,110],:].sum(axis=0) #infrastructure\n\n\nnonml_data_to_plot = pd.DataFrame({ 'Data Analysis': a, \n                                  'Data Infrastructure\\n(run or build)': i,\n                                   'ML related activities': ml\n                                  })\n\n\nq9_answers_ml_map = {\n    'Q9_A3' : 'Build ML\\nprototypes',\n    'Q9_A4': 'Build or run\\nML services',\n    'Q9_A5': 'Improve\\nML models',\n    'Q9_A6': 'Research to\\nadvance ML',\n}\n\n\n#select those for whom ML is part of the role\nml = activities_raw.loc[activities_raw['ML is part of the role']]\nml_bool = ml[['Q9_A3','Q9_A4','Q9_A5','Q9_A6']].notna().multiply(1).add_suffix('_bool')\n#decode activities combination with a sequence of ones and zeros\nml_bool['ml_set']=(ml_bool['Q9_A3_bool']*1000+\n                   ml_bool['Q9_A4_bool']*100+\n                   ml_bool['Q9_A5_bool']*10+\n                   ml_bool['Q9_A6_bool'])\nml_data_raw = pd.concat([ml[['Q5','Q8']], ml_bool['ml_set']],axis=1)\nml_data_grouped = ml_data_raw.groupby(['Q5','ml_set']).size().unstack('Q5')\n\n\ndd = ml_data_grouped.sort_values(by=['Data Scientist'],ascending=False)\ndd = dd.div(dd.sum(axis=0),axis=1)*100\n\np = dd.loc[dd.index\/\/1000%2 == 1].sum(axis=0) #prototyping\ns = dd.loc[dd.index\/\/100%2 == 1].sum(axis=0) #services\nm = dd.loc[dd.index\/\/10%2 == 1].sum(axis=0) #models improvement\nr = dd.loc[dd.index\/\/1%2 == 1].sum(axis=0) #research\n\nml_data_to_plot = pd.DataFrame({'Build ML\\nprototypes': p, \n                                'Build or run\\nML services': s,\n                                'Improve\\nML models': m,\n                                'Research to\\nadvance ML': r})\n\n\n  \nplot_colors = [roles_c[x] for x in ['Business Analyst','Data Analyst','Data Scientist']]\n\nfig, ax = plt.subplots(2,1, figsize=(12, 12))\n#plots\nax[0].axvspan(1.5, 2.5, color='grey', alpha = 0.2)\nnonml_data_to_plot.T.plot(kind='bar', color = plot_colors, ax=ax[0])\nml_data_to_plot.T.plot(kind='bar', color = plot_colors, ax=ax[1])\n\n\nyaxis_labels = {\n    0:\"% respondents\",\n    1:\"% respondents\"}\n\ntitles = {\n    0:(\"Data Analysis is an important part of one's job regardless of their title,\"+\n    \"\\nwhereas ML tasks are more often performed by data scientists\"),\n    1:(\"Building prototypes was the top chosen activity among those\"+\n    \"\\nwho are involved in ML\")}\n\nyaxis_limits = {\n    0:100,\n    1:100}\nfignum = next(fig_n)\nannotations = {\n    0:\"Figure \"+fignum+\"a: Activities that make up an important part of one's role at work\"+\n    \"\\nSource: ML&DS survey 2019, question 9.\",\n    1:\"Figure \"+fignum+\"b: ML related activities for those involved* in the ML\"+\n    \"\\nSource: ML&DS survey 2019, question 9.\"+\n    \"\\n*respondent selected at least one option that mentioned ML\"}\n\n#plots decoration\nfor i in [0,1]:\n    ax[i].xaxis.grid(False)\n    ax[i].set_xticklabels(ax[i].get_xticklabels(), rotation=0, fontsize=12)\n    ax[i].yaxis.set_label_text(yaxis_labels[i], fontsize=12)\n    ax[i].set_title(titles[i], fontsize=14)\n    ax[i].set_ylim(0,yaxis_limits[i])\n    ax[i].annotate(annotations[i],\n                  (0,0), (0, -50), xycoords='axes fraction', textcoords='offset points', \n                  va='top', ha='left',fontsize=11)\n    ax[i].tick_params(labelsize=12)\n\nax[0].legend().set_visible(False)\nax[1].legend(loc='upper right', bbox_to_anchor=(0.98, 0.98), ncol=1, labelspacing=0.5, fontsize=12)\n\n#ax[1].set_facecolor('#0E3A70')\n\nax[1].patch.set_facecolor('grey')\nax[1].patch.set_alpha(0.2)\n\nsns.despine(left=True, bottom=True)\nplt.tight_layout()\nplt.show()","1876e102":"tools_map = {\n    'Local development environments (RStudio, JupyterLab, etc.)':'Local IDE',\n    'Basic statistical software (Microsoft Excel, Google Sheets, etc.)':'Spreadsheets',\n    'Cloud-based data software & APIs (AWS, GCP, Azure, etc.)':'Cloud APIs',\n    'Business intelligence software (Salesforce, Tableau, Spotfire, etc.)': 'BI software',\n    'Advanced statistical software (SPSS, SAS, etc.)': 'Advanced\\nstat. software',\n    'Other':'Other'\n}\ntools_raw = responses_ff.loc[responses_ff['Q5'].isin(roles),['Q14','Q5']].groupby(['Q14','Q5']).size().unstack('Q5')\ntools_agg = tools_raw.div(tools_raw.sum(axis=0),axis=1)\ntools_agg.index = tools_agg.index.map(tools_map)\ntools_agg.index = pd.Categorical(tools_agg.index, list(tools_map.values()), ordered=True)\ntools_agg = tools_agg.sort_index() #data for bar chart\ntools_agg.columns.name=None\nce_buckets_map = {\n    'I have never written code':'0', \n    '< 1 years':'< 1 year',\n    '1-2 years':'1-2',\n    '3-5 years':'3-5',\n    '5-10 years':'5-10',\n    '10-20 years':'10-20',\n    '20+ years':'20+ years'}\n\ntools_ce_raw = responses_ff.loc[responses_ff['Q5'].isin(roles),['Q5','Q14','Q15']].copy()\n#tools_ce_raw['Q5'] = tools_ce_raw['Q5'].str.wrap(10)\ntools_ce_raw = tools_ce_raw.groupby(['Q5','Q14','Q15']).size().unstack('Q15')\ntools_ce_raw = tools_ce_raw.rename(columns=ce_buckets_map)\ntools_ce_raw = tools_ce_raw[list(ce_buckets_map.values())].unstack('Q14').stack('Q15').fillna(0)\ntools_ce_agg = tools_ce_raw.div(tools_ce_raw.sum(axis=1),axis=0)\ntools_ce_agg = tools_ce_agg.rename(columns=tools_map) #data for heatmaps\n\n\nfig, ax = plt.subplots(figsize=(12,5))\n#highlight the area of interest \nax.axvspan(-0.5, 0.5, color='#586BA4', alpha = 0.2)\nax.axvspan(0.5, 1.5, color='#CAE7B9', alpha = 0.2)\n#plot\n(tools_agg*100).plot.bar(color = list(roles_c.values()) , ax=ax)\n#plot decoration\nax.yaxis.set_label_text(\"% of respondents\", fontsize=12)\nax.set_xticklabels(ax.get_xticklabels(), rotation=0, fontsize=12)\nax.set_title((\"The majority of data scientists choose IDEs as their primary tool,\\nwhereas 38% of business analysts choose Spreadsheets\"), fontsize=14)\nannotation_text=(\"Figure \"+next(fig_n)+\": Primary tool to analyze data\\nSource: ML&DS survey 2019, question 14\")\nax.annotate(annotation_text,(0,0), (0, -50), xycoords='axes fraction', textcoords='offset points', va='top', ha='left',fontsize=11)\nax.tick_params(labelsize=12)\nax.set_ylim(0,75)\nax.xaxis.grid(False)\nhandles, labels = ax.get_legend_handles_labels()\nax.legend(handles, labels)\nsns.despine(left=True, bottom=True)\nplt.tight_layout()\n\nplt.show()\n","3fa65684":"#how long have you been written code to analyze data?\nq15_raw = responses_ff.loc[(responses_ff['Q5'].isin(roles)),['Q15','Q5']]                                   \nq15_dist = q15_raw.groupby(['Q5','Q15']).size()\nq15_dist = q15_dist.div(q15_dist.sum(level='Q5')).reset_index().rename(columns={0:'Percentage'})\nq15_dist = q15_dist.pivot(index='Q15', columns='Q5', values='Percentage').reset_index()\nq15_answers_map = {\n    'I have never written code':'0', \n    '< 1 years':'< 1 year',\n    '1-2 years':'1-2',\n    '3-5 years':'3-5',\n    '5-10 years':'5-10',\n    '10-20 years':'10-20',\n    '20+ years':'20+ years'\n}\nq15_labels_ordered = list(q15_answers_map.values())\nq15_dist['Q15'] = q15_dist['Q15'].map(q15_answers_map)\nq15_dist['Q15'] = pd.Categorical(q15_dist['Q15'],q15_labels_ordered)\nq15_dist = q15_dist.sort_values(by=['Q15'])\n\n\nfig, ax = plt.subplots(figsize=(12,5))\n\n\n#line plot for age\nfor role_name, role_color in roles_c.items():\n    ax.plot(q15_dist['Q15'].astype('str'), q15_dist[role_name]*100, \n               color = role_color, linestyle = '--', marker = 'o', markersize=12, linewidth=1.5, alpha = 0.9)\n\n\nax.yaxis.set_label_text('% of respondents', fontsize=12)\nax.set_title((\"Data Scientists have more years of experience in writing code to analyze data\"), fontsize=14)\nax.set_xticklabels(q15_dist['Q15'].astype('str'), rotation=0, fontsize=12)\nannotation_text = \"Figure \"+next(fig_n)+\": Distribution by years of experience in writing code to analyze data\\nSource: ML&DL Survey 2019, question 15\"\nax.annotate(annotation_text,\n                  (0,0), (0, -50), xycoords='axes fraction', textcoords='offset points', \n                  va='top', ha='left',size=11)\nax.tick_params(labelsize=12)\nax.set_ylim(-1,55)\nax.legend(loc='upper right', bbox_to_anchor=(0.98, 0.98), ncol=1, labelspacing=0.5, fontsize=11)\n\nsns.despine(left=True, bottom=True)\nplt.tight_layout()\nplt.show()","995b5018":"tools_colors ={\n    'Spreadsheets':'Greens',\n    'Local IDE':'Purples'}\nfignum = next(fig_n)\nanotations = {\n        0: \"Figure \"+fignum+\"a: Spreadsheet usage within groups by job title and years of writing code for data analysis\",\n        1: \"Figure \"+fignum+\"b: Local IDE usage within groups by job title and years of writing code for data analysis\"+\n            \"\\n\\nSource: ML&DS Survey 2019, questions 14&15\"+\n            \"\\n*an empty square on the heatmap means that there were fewer than 30 respondents in this group\"}\n\ntitles = {\n    0:(\"Although business analysts turn away from Spreadsheets\\nas they gain experience in writing code,\"+\n       \" data scientists do it faster\"),\n    1:(\"The majority of data scientists use local IDEs as their primary tool for data analysis\"+\n        \"\\nas soon as they learn how to write code to analyze data\")}\n\nfig, ax = plt.subplots(2,1,figsize=(9,12) )\n\n\nfor i, tool in enumerate(tools_colors):\n    \n    #heatmaps plotting\n    heatmap_data = tools_ce_agg[tool].unstack('Q15')[list(ce_buckets_map.values())]\n    heatmap_data[tools_ce_raw.sum(axis=1).unstack() < 30] = np.nan #mask values where were less than 30 respondents\n    \n    sns.heatmap(heatmap_data, vmin = 0, vmax = 1, \n                annot=True, annot_kws={\"size\": 12}, fmt='.0%', square=True,\n            cmap=tools_colors[tool], linewidths=.5, ax=ax[i], cbar=False )\n    #heatmap decoration\n    ax[i].set_yticklabels(ax[i].get_yticklabels(), rotation=0,ha='right',va='center')\n    ax[i].set(xlabel=\"\", ylabel=\"\")\n    ax[i].tick_params(labelsize=12)\n    ax[i].set_title(titles[i], fontsize=13)\n    ax[i].annotate(anotations[i],\n                  (0,0), (0, -50), xycoords='axes fraction', textcoords='offset points', va='top', ha='left',size=11)\n    \nsns.despine(left=True, bottom=True) \n\nplt.show()\n","9b75ca17":"# years ML experience\nq23_raw = responses_ff.loc[(responses_ff['Q5'].isin(roles))&(responses_ff['Q15']!='I have never written code'),['Q23','Q5']]                                   \nq23_dist = q23_raw.groupby(['Q5','Q23']).size()\nq23_dist = q23_dist.div(q23_dist.sum(level='Q5')).reset_index().rename(columns={0:'Percentage'})\nq23_dist = q23_dist.pivot(index='Q23', columns='Q5', values='Percentage').reset_index()\nq23_answers_map = {\n    '< 1 years':'< 1 year',\n    '1-2 years':'1-2',\n    '2-3 years':'2-3',\n    '3-4 years':'3-4',\n    '4-5 years':'4-5',\n    '5-10 years':'5-10',\n    '10-15 years':'10-15',\n    '20+ years':'20+ years'\n}\nq23_labels_ordered = list(q23_answers_map.values())\nq23_dist['Q23'] = q23_dist['Q23'].map(q23_answers_map)\nq23_dist['Q23'] = pd.Categorical(q23_dist['Q23'],q23_labels_ordered)\nq23_dist = q23_dist.sort_values(by=['Q23'])\nq23_dist_cumsum = q23_dist.set_index('Q23').cumsum(axis=0).reset_index()\n\n\nd2 = responses_ff.loc[(responses_ff['Q5'].isin(roles))&responses['Q8'].isin(list(ml_states_map_detailed.keys())),\n                         ['Q5','Q8','Q23']+list(q9_answers_map.keys())]\nd2['Q8'] = d2['Q8'].map(ml_states_map_detailed)\nd2['Q8'] = pd.Categorical(d2['Q8'],list(ml_states_map_detailed.values()))\n\nq23_labels_ordered = list(q23_answers_map.values())\nd2['Q23'] = d2['Q23'].map(q23_answers_map)\nd2['Q23'] = pd.Categorical(d2['Q23'],q23_labels_ordered)\nd2['ML is part of the role'] = (d2['Q9_A3'].notna())| (d2['Q9_A4'].notna())|(d2['Q9_A5'].notna())|(d2['Q9_A6'].notna())\nactivities_raw = d2\n\nfig, ax = plt.subplots(figsize=(12,5))\n\n\n#line plot for age\nfor role_name, role_color in roles_c.items():\n    ax.plot(q23_dist['Q23'].astype('str'), q23_dist[role_name]*100, \n               color = role_color, linestyle = '--', marker = 'o', markersize=12, linewidth=1.5, alpha = 0.9)\n\n\nax.yaxis.set_label_text('% of respondents', fontsize=12)\nax.set_title((\"Overall, data scientists have more years of ML experience\"), fontsize=14)\nax.set_xticklabels(q23_dist['Q23'].astype('str'), rotation=0, fontsize=12)\nannotation_text = \"Figure \"+next(fig_n)+\": Distribution by years of ML experience\\nSource: ML&DL Survey 2019, question 23\"\nax.annotate(annotation_text,\n                  (0,0), (0, -50), xycoords='axes fraction', textcoords='offset points', \n                  va='top', ha='left',size=11)\nax.tick_params(labelsize=12)\nax.set_ylim(-1,55)\nax.legend(loc='upper right', bbox_to_anchor=(0.98, 0.98), ncol=1, labelspacing=0.5, fontsize=11)\n\nsns.despine(left=True, bottom=True)\nplt.tight_layout()\nplt.show()","7f87bd08":"ml = activities_raw.loc[activities_raw['ML is part of the role']]\nml_bool = ml[['Q9_A3','Q9_A4','Q9_A5','Q9_A6']].notna().multiply(1).add_suffix('_bool')\n#decode activities combination with a sequence of ones and zeros\nml_bool['ml_set']=(ml_bool['Q9_A3_bool']*1000+\n                   ml_bool['Q9_A4_bool']*100+\n                   ml_bool['Q9_A5_bool']*10+\n                   ml_bool['Q9_A6_bool'])\nml_data_raw = pd.concat([ml[['Q23','Q8']], ml_bool['ml_set']],axis=1)\nml_data_g = ml_data_raw.groupby(['Q23','ml_set']).size().unstack('Q23')\ndd = ml_data_g.sort_values(by=['20+ years'],ascending=False)\n\np = dd.loc[dd.index\/\/1000%2 == 1].sum(axis=0) #prototyping\ns = dd.loc[dd.index\/\/100%2 == 1].sum(axis=0) #services\nm = dd.loc[dd.index\/\/10%2 == 1].sum(axis=0) #models improvement\nr = dd.loc[dd.index\/\/1%2 == 1].sum(axis=0) #research\nt = ml_data_g.sum(axis=0)#total\n\nml_e = pd.DataFrame({'Build ML\\nprototypes': p, \n                                'Build or run\\nML services': s,\n                                'Improve\\nML models': m,\n                                'Research to\\nadvance ML': r,\n                                'Total': t})\n\nml_e = ml_e.div(ml_e['Total'],axis=0)*100\nml_e = ml_e.drop(['Total'],axis=1)\nml_e.index.name = 'ML experience'\nml_e = ml_e.sort_values(by=['ML experience'],ascending= False)\n\nfig, ax = plt.subplots(1,4,figsize=(12,3), sharex=True, sharey=True)\n\nfor i,c in enumerate(ml_e.columns.to_list()):\n    ax[i].hlines(y=ml_e.index, xmin=0, xmax=ml_e[c], color='#1F78B4', alpha=0.7, linewidth=2)\n    ax[i].scatter(y=ml_e.index, x=ml_e[c], s=75, color='#1F78B4', alpha=0.7)\n    ax[i].set_title(c, fontsize=12)\n    ax[i].set_xticks((np.arange(0, 100, 20)))\n    ax[i].set_xlabel('% respondents', fontsize=12)\n    ax[i].tick_params(labelsize=11)\n    \n\nsns.despine(left=True, bottom=True)\n\nannotation_text = \"Figure \"+next(fig_n)+\": Involvment in ML activities for groups with different amount of ML experience\\nSource: ML&DL Survey 2019, questions 9&23\"\nax[0].annotate(annotation_text, (0,0), (0, -60), xycoords='axes fraction', textcoords='offset points', va='top', ha='left', fontsize=11)\n\n\nsns.despine(left=True, bottom=True)\nplt.show()","4acaae0c":"fig, ax = plt.subplots(3, 1, figsize=(14,18))\n\nfor i, role_name in enumerate(reversed(roles)):\n\n    role_color = roles_c[role_name] #bar colors\n    #prepare data\n    ml_by_role = ml_data_grouped[role_name].sort_values(ascending=False)\n    ml_by_role = ml_by_role.div(ml_by_role.sum(axis=0),axis=0).to_frame(name='per') #calculate percent from the group\n    \n    #dict to translates ml combinations into checkboxes\n    x_coordinates = {-4:1000,\n                     -3:100,\n                     -2:10,\n                     -1:1}\n    #what is the maximum value?\n    max_val = float(ml_by_role.iloc[0])*100 #maxium x value (as data frame is sorted in descending order)\n    # round it to the nearest number devisible by 5\n    max_x = math.ceil(max_val\/5)*5\n    if max_x-max_val < 1:\n        max_x = max_x + 5 #increase by 5 if value was already close to the devisible by 5\n    \n    # scale factor - so that y-axis will be aligned for all 3 charts\n    scale_factor = max_x\/6\n    #how many y points are in data frame?\n    y_points = ml_by_role.index.shape[0]\n    #add horizontal line\n    ax[i].hlines(y=y_points+0.5, xmin=(-4)*scale_factor, xmax=max_x, color='grey', alpha=0.8, linewidth=1.5)\n        \n    for j, ml_set_code in enumerate(ml_by_role.index):\n        #print(i, ml_set_code)\n        xs, ys = [],[]\n        for x in list(x_coordinates.keys()):\n            if (ml_set_code\/\/x_coordinates[x])%2==1:\n                xs.append((x+0.5)*scale_factor)\n                ys.append(y_points-j) \n                \n        ax[i].scatter(y=ys, x=xs, s=12*12, color='grey', marker='$\u2714\ufe0e$')   \n        val_x = float(ml_by_role.iloc[j])*100 #value_x\n        val_y = y_points-j #value_y\n        #plot the horizontal bar\n        ax[i].barh(y=val_y, left=0, width=val_x, color=role_color, height = 0.8, alpha=0.8)\n        #annotate bar\n        ax[i].text(x=val_x+0.1, y=val_y, s='{:.1f}%'.format(val_x), color='grey', ha= 'left', va='center', fontsize=12)\n        #highlight particular combinations\n        if ml_set_code in [1110,1111]: ax[i].barh(y=val_y, left=0, width=-4*scale_factor, color='#FFE714', height = 0.8, alpha=0.3)\n        if ml_set_code in [1000,100,10,1]: ax[i].barh(y=val_y, left=0, width=-4*scale_factor, color='#FF9A47', height = 0.8, alpha=0.3)\n\n    \n    # Plots decoraation\n    x_major_ticks = np.arange(0, max_x, 5)\n    x_minor_ticks = np.arange(list(x_coordinates.keys())[0]*scale_factor, 0, scale_factor)\n    ax[i].set_xticks(x_major_ticks)\n    ax[i].set_xticks(x_minor_ticks, minor=True)\n    ax[i].set_xlim(list(x_coordinates.keys())[0]*scale_factor, max_x) \n\n    y_minor_ticks = np.arange(0.5, ml_by_role.shape[0]+0.6, 1)\n    y_major_ticks = np.arange(y_points+0.5, y_points+3, 3)\n    ax[i].set_yticks(y_major_ticks)\n    ax[i].set_yticks(y_minor_ticks,minor=True)\n    ax[i].set_yticklabels([])\n    ax[i].set_ylim(0.5,y_points+3.5)\n\n    ax[i].grid(which='minor', alpha=0.5)\n    ax[i].grid(which='major', alpha=0.5)\n    ax[i].xaxis.set_label_text(\"\")\n    ax[i].tick_params(labelsize=12)\n\n    #put a white bar on the part with text (to hide grid lines)\n    for j in [1,2,3]: ax[i].barh(y=y_points+j, left=0.1, width=max_x, height=0.9, color='white')\n\n    #anotating and labeling\n    for j,ml_label in enumerate(list(q9_answers_ml_map.values())):\n        ax[i].text(((-4+j+0.5)*scale_factor),y_points+2, s=ml_label, ha= 'center', va='center', fontsize=12)\n\n    ax[i].text(max_x\/2,y_points+2, s='% of all '+role_name +'s involved in ML*', ha='center', va='bottom', fontsize=12) \n\n#figure annotation    \nannotation_text = (\"Figure \"+next(fig_n)+\": Detailed look at combinations of Machine Learning activities for each job title\"+\n                \"\\nSource: ML&DL Survey 2019,question 9\"+\n                \"\\n\\n*selected at least one option that mentioned ML in question 9\")\nax[2].annotate(annotation_text, (0,0), (2, -50), xycoords='axes fraction', textcoords='offset points', va='top', ha='left') \n\nplt.show()\n\n","99fe4631":"#ML algorithms\nq24_c = responses_ff.filter(like='Q24_A', axis=1).columns.to_list()\n\nML_methods_map = {\n    'Q24_A1': 'Linear\\nor\\nLogistic\\nRegression',\n    'Q24_A2': 'Decision\\nTrees\\nor\\nRandom\\nForests',\n    'Q24_A3': 'Gradient\\nBoosting\\nMachines',\n    'Q24_A4': 'Bayesian\\nApproaches',\n    'Q24_A5': 'Evolu-\\ntionary\\nApproaches',\n    'Q24_A6': 'Dense\\nNeural\\nNetworks',\n    'Q24_A7': 'Convolu- \\ntional\\nNeural\\nNetworks',\n    'Q24_A8': 'Generative\\nAdver-\\nsarial\\nNetworks',\n    'Q24_A9': 'Recurrent\\nNeural\\nNetworks',\n    'Q24_A10': 'Transformer\\nNetworks',\n    'Q24_A11': 'None',\n    'Q24_A12': 'Other'}\n\nq24_raw = responses_ff.loc[(responses_ff['Q5'].isin(roles))&(responses_ff['Q24_choices_cnt']>0)][['Survey_time','Q5']+q24_c].groupby(['Q5']).count()\nq24_raw = q24_raw.div(q24_raw['Survey_time'], axis=0)\nq24_raw = q24_raw.rename(columns=ML_methods_map)\nq24_plot = q24_raw.T.drop(['Survey_time'],axis=0).sort_values(['Data Scientist'],ascending=False)*100\nq24_plot.columns.name = ''\n#plot\nfig, ax = plt.subplots(figsize=(12,4))\nq24_plot.plot(color = list(roles_c.values()), ax=ax, kind='bar')\nax.set_ylim(0,100)\nax.yaxis.set_label_text(\"% repsondents\",fontsize=12)\nax.set_xticklabels(ax.get_xticklabels(), rotation=0, fontsize=11)\nax.set_title((\"Overall, data scientist use more ML algorithms\"), fontsize=14)\nax.tick_params(labelsize=10)\nannotation_text = (\"Figure \"+next(fig_n)\n            +\": Penetration of ML agorithms for different job titles (only people with coding experience were asked)\\nSource: ML&DL Survey 2019, question 24\")\nplt.annotate(annotation_text, (0,0), (0, -100), xycoords='axes fraction', textcoords='offset points', va='top', ha='left', fontsize=11)\n  \nsns.despine(left=True, bottom=True)\nplt.show() \n","f1679fa1":"#ML tools\nq25_c = responses_ff.filter(like='Q25_A', axis=1).columns.to_list()\n\nML_tools_cat_map = {\n    'Q25_A1': 'Automated\\ndata\\naugmentation',\n    'Q25_A2': 'Automated\\nfeature\\nengineering',\n    'Q25_A3': 'Automated\\nmodel\\nselection',\n    'Q25_A4': 'Automated\\nmodel\\narchitecture\\nsearches',\n    'Q25_A5': 'Automated\\nhyperparameter\\ntuning',\n    'Q25_A6': 'Automation\\nof full ML\\npipelines',\n    'Q25_A7': 'None',\n    'Q25_A8': 'Other'}\n\nq25_raw = responses_ff.loc[(responses_ff['Q5'].isin(roles))&(responses_ff['Q25_choices_cnt']>0)][['Survey_time','Q5']+q25_c].groupby(['Q5']).count()\nq25_raw = q25_raw.div(q25_raw['Survey_time'], axis=0)\nq25_raw = q25_raw.rename(columns=ML_tools_cat_map)\nq25_plot = q25_raw.T.drop(['Survey_time'],axis=0).sort_values(['Data Scientist'],ascending=False)*100\nq25_plot.columns.name = ''\n#plot\nfig, ax = plt.subplots(figsize=(12,4))\nq25_plot.plot(color = list(roles_c.values()), kind ='bar', ax=ax)\n#plot decoration\nax.set_ylim(0,80)\nax.yaxis.set_label_text(\"% repsondents\",fontsize=12)\nax.set_xticklabels(ax.get_xticklabels(), rotation=0, fontsize=10)\nax.set_title((\"Less than half of data analysts and business analysts use ML tools.\\nUsage among data scientists is a bit higher\"), fontsize=14)\nax.tick_params(labelsize=11)\nannotation_text = \"Figure \"+next(fig_n)+\": Penetration of ML tools for different job titles (only people with coding experience were asked)\\nSource: ML&DL Survey 2019, question 25\"\nplt.annotate(annotation_text, (0,0), (0, -60), xycoords='axes fraction', textcoords='offset points', va='top', ha='left', fontsize=11)\n  \nsns.despine(left=True, bottom=True)\nplt.show()","dc22ed78":"q18_c = responses_ff.filter(like='Q18_A', axis=1).columns.to_list()\nlanguages_map = responses_ff.filter(regex='Q18_.*\\d$').fillna('').max().to_dict()\n#data preparation\npl_raw = responses_ff.loc[(responses_ff['Q5'].isin(roles))&(responses_ff['Q15']!='I have never written code')][['Q5']+q18_c+['Q18_choices_cnt']]\npl_agg = pl_raw.groupby(['Q5']).count().rename(columns={'Q18_choices_cnt':'cnt'})\npl_agg = pl_agg.rename(columns=languages_map)\npl_agg = (pl_agg.div(pl_agg['cnt'],axis=0)*100).drop(['cnt'],axis=1)\npl_agg.index.name=\"\"\n#plot\nfig, ax = plt.subplots(figsize=(12,4))\npl_agg.T.plot(color = list(roles_c.values()), ax=ax, kind='bar')\n#plot decoration\nax.set_xticklabels(pl_agg.columns, rotation=90, fontsize=12)\nax.set_ylim(0,100)\nax.yaxis.set_label_text(\"% repsondents\",fontsize=12)\nax.set_xticklabels(ax.get_xticklabels(), rotation=0, fontsize=11)\nax.set_title((\"Python, R, and SQL are the most popular languages among all job titles,\\nwith 94% of data scientists using Python on a regular basis\"), fontsize=14)\nax.tick_params(labelsize=11)\nannotation_text = \"Figure \"+next(fig_n)+\": Language popularity (only people with coding experience were asked)\\nSource: ML&DL Survey 2019, question 18\"\nplt.annotate(annotation_text, (0,0), (0, -30), xycoords='axes fraction', textcoords='offset points', va='top', ha='left', fontsize=11) \nsns.despine(left=True, bottom=True)\nplt.tight_layout()\nplt.show()","6f352816":"#combinations\npl_bool = pl_raw[['Q18_A1','Q18_A2','Q18_A3']].notna().multiply(1).add_suffix('_bool')\npl_bool['pl_set']=(pl_bool['Q18_A1_bool']*100+\n                   pl_bool['Q18_A2_bool']*10+\n                   pl_bool['Q18_A3_bool'])\npl_combinations = pd.concat([pl_raw['Q5'], pl_bool['pl_set']],axis=1)\npl_combinations_agg = pl_combinations.groupby(['Q5','pl_set']).size().unstack('Q5')\npl_comb_plot = (pl_combinations_agg.div(pl_combinations_agg.sum(axis=0),axis=1)*100)\npl_comb_plot.columns.name, pl_comb_plot.index.name = \"\",\"\"\ncombinations_map = {\n    111:'ALL THREE',\n    101:'Python + SQL',\n    110:'Python + R',\n    100:'ONLY Python',\n    10: 'ONLY R',\n    11: 'R + SQL',\n    1: 'ONLY SQL',\n    0: 'NONE of THREE'}\npl_comb_plot.index = pl_comb_plot.index.map(combinations_map)\npl_comb_plot.index = pd.Categorical(pl_comb_plot.index, list(combinations_map.values()))\npl_comb_plot = pl_comb_plot.sort_index()\n\n#plot\nfig, ax = plt.subplots(figsize=(12,4))\nax.axvspan(-0.5, 3.5, color='grey', alpha = 0.2)\npl_comb_plot.plot(kind='bar', color=list(roles_c.values()),ax=ax)\n#plot decoration\nax.set_xticklabels(pl_comb_plot.index, rotation=90, fontsize=12)\nax.set_ylim(0,40)\nax.yaxis.set_label_text(\"% repsondents\",fontsize=12)\nax.set_xticklabels(ax.get_xticklabels(), rotation=0, fontsize=11)\nax.set_title((\"A quarter of data scientists use all 3 languages on a regular basis,\\nwith another 29% using Python and SQL\"), fontsize=14)\nax.tick_params(labelsize=11)\nannotation_text = \"Figure \"+next(fig_n)+\": Which combinations of the 3 most popular languages are used\\nSource: ML&DL Survey 2019, question 18\"\nplt.annotate(annotation_text, (0,0), (0, -30), xycoords='axes fraction', textcoords='offset points', va='top', ha='left', fontsize=11) \nsns.despine(left=True, bottom=True)\nplt.tight_layout()\nplt.show()\n\n","5fb0dd56":"#colors\nlang_colors = [single_color,'#C3E4E5','#E8A87D','#AAAAAA']\n#which language recommend those who know all 3\npl_q19 = pd.concat([pl_combinations, responses_ff.loc[responses_ff['Q5'].isin(roles)]['Q19']], axis=1)\npl_q19_agg = pl_q19.loc[pl_q19['pl_set']==111].groupby(['Q5','Q19']).size().unstack('Q19').fillna(0)\npl_q19_agg = pl_q19_agg.div(pl_q19_agg.sum(axis=1),axis=0)\npl_q19_agg['Other '] = 1 - pl_q19_agg[['Python','R','SQL']].sum(axis=1) \npl_q19_agg.index.name = \"\"\n#plot\nfig, ax = plt.subplots(figsize=(12,4))\n(pl_q19_agg[['Python','R','SQL','Other ']]*100).plot(kind='barh', stacked='True', ax=ax, width=0.8, color=lang_colors, alpha=0.7)\n#plot decoration\nax.set_title((\"The majority of those who know the 3 most popular languages recommend to learn Python first\"), fontsize=14)\nax.set_xlim(0,100)\nax.tick_params(labelsize=12)\nax.legend(loc='center', bbox_to_anchor=(0.5, -0.05), ncol=4, labelspacing=0.5, fontsize=14)\nannotation_text = \"Figure \"+next(fig_n)+\": Language recommendation to an aspiring data scientist\\nfrom those who know all 3 most popular languages\\nSource: ML&DL Survey 2019, question 18&19\"\nplt.annotate(annotation_text, (0,0), (0, -40), xycoords='axes fraction', textcoords='offset points', va='top', ha='left', fontsize=11) \nsns.despine(left=True, bottom=True)\nax.get_xaxis().set_visible(False)\n# add annotations!\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    if width > 5: \n        ax.text(x+width\/2, y+height\/2, '{:.0f} %'.format(width), ha='center', va='center', fontsize=12)\n\nplt.show()\n","cf58cbae":"#Learning platforms\nq13_c = responses_ff.filter(like='Q13_A', axis=1).columns.to_list()\n\nplatforms_map = {\n    'Q13_A1':  'Udacity',\n    'Q13_A2':  'Coursera',\n    'Q13_A3':  'edX',\n    'Q13_A4':  'DataCamp',\n    'Q13_A5':  'DataQuest',\n    'Q13_A6':  'Kaggle Courses',\n    'Q13_A7':  'Fast.ai',\n    'Q13_A8':  'Udemy',\n    'Q13_A9':  'LinkedIn Learning',\n    'Q13_A10':  'University Courses*',\n    'Q13_A11':  'None',\n    'Q13_A12':  'Other'\n}\n\nq13_raw = responses_ff.loc[responses_ff['Q5'].isin(roles)][['Survey_time','Q5']+q13_c].groupby(['Q5']).count()\nq13_raw = q13_raw.div(q13_raw['Survey_time'], axis=0)\nq13_raw = q13_raw.rename(columns=platforms_map)\n#condition = q13_raw > 0.05  #subjective treshhold - less than 15% mentioned particular platform\nq13_reduced = q13_raw.drop(['Survey_time','None','Other'],axis=1)\nq13_ranks = q13_reduced.rank(method='first',ascending=False,axis=1)\n\n#decide which one to highlight:\nq13_ranks_min_max = pd.DataFrame({'diff': q13_ranks.max(axis=0)-q13_ranks.min(axis=0)})\ncondition = (q13_ranks_min_max['diff'] > 2)\nlist_highlights = (q13_ranks_min_max.sort_values(by=['diff'],ascending=False)\n                       .where(condition, np.nan).dropna(axis=0,how='all').index.tolist())\nhighlight_colors = ['#FFE8A5','#CAE7B9','#EB9486','#586BA4','#8A716A','#F2F3AE','#1F78B4']\n\nfig, ax = plt.subplots(figsize=(12,5))\n#tools_agg.plot(kind='bar', color = list(roles_c.values()), ax=ax)\n\nxs = {'Data Scientist':0,\n      'Data Analyst':0.4,\n      'Business Analyst':0.8}\n\nfor role, role_c in roles_c.items(): \n    row = q13_ranks.loc[role,:]\n    interval = 0.8\/(row.shape[0])\n    ax.text(xs[role], 0.92, role.upper(), \n            ha='left', va='top', fontdict={'fontweight':600, 'size':12},\n            bbox={'facecolor':'grey', 'boxstyle':'round',  'alpha':0.5}) \n    for label, value in row.items(): #iterating over series\n        y = 0.8 - value*interval\n        t = ('#'+str(int(value))+' '+label).upper()\n        \n        #ax.text(xs[role], y+0.1, t, ha='left', va='center', fontdict={'fontweight':540, 'size':12})\n        if label in list_highlights:\n            ii = (list_highlights.index(label))%7\n            highlight_color = highlight_colors[ii]\n            ax.text(xs[role], y+0.1, t, ha='left', va='center', fontdict={'fontweight':540, 'size':12},\n                   bbox={'facecolor':highlight_color, 'boxstyle':'round', 'edgecolor':'none', 'alpha':0.5})\n        else:\n            ax.text(xs[role], y+0.1, t, ha='left', va='center', fontdict={'fontweight':540, 'size':12})\n\nannotation_text = (\"Figure \"+next(fig_n)+\":Top 10 platforms with data science courses for each job title\\nSource:ML&DL Survey 2019, question 13\"+\n                  \"\\n*resulting in a university degree\")\nplt.annotate(annotation_text, (0,0), (0, -5), xycoords='axes fraction', textcoords='offset points', va='top', ha='left', fontsize=11)\n                             \nax.grid(False)\nax.axis('off')\nplt.show()","1f0477b1":"#Media resources\nq12_c = responses_ff.filter(like='Q12_A', axis=1).columns.to_list()\n\nmedia_map = {\n    'Q12_A1':  'Twitter',\n    'Q12_A2':  'Hacker News',\n    'Q12_A3':  'Reddit',\n    'Q12_A4':  'Kaggle',\n    'Q12_A5':  'Course Forums',\n    'Q12_A6':  'YouTube',\n    'Q12_A7':  'Podcasts',\n    'Q12_A8':  'Blogs', \n    'Q12_A9':  'Journal Publications',\n    'Q12_A10':  'Slack Communities',\n    'Q12_A11':  'None',\n    'Q12_A12':  'Other'\n}\n\nq12_raw = responses_ff.loc[responses_ff['Q5'].isin(roles)][['Survey_time','Q5']+q12_c].groupby(['Q5']).count()\nq12_raw = q12_raw.div(q12_raw['Survey_time'], axis=0)\nq12_raw = q12_raw.rename(columns=media_map)\nq12_reduced = q12_raw.dropna(axis=1, how='all').drop(['Survey_time','Other','None'],axis=1)\nq12_ranks = q12_reduced.rank(method='first', ascending=False,axis=1)\n\n#decide which ones to highlight:\nq12_ranks_min_max = pd.DataFrame({'diff': q12_ranks.max(axis=0)-q12_ranks.min(axis=0)})\ncondition = (q12_ranks_min_max['diff'] >= 2)\nlist_highlights = (q12_ranks_min_max.sort_values(by=['diff'],ascending=False)\n                       .where(condition, np.nan).dropna(axis=0,how='all').index.tolist())\nhighlight_colors = ['#FFE8A5','#CAE7B9','#EB9486','#586BA4','#8A716A','#F2F3AE','#1F78B4']\n\nfig, ax = plt.subplots(figsize=(12,5))\n#tools_agg.plot(kind='bar', color = list(roles_c.values()), ax=ax)\n\nxs = {'Data Scientist':0,\n      'Data Analyst':0.4,\n      'Business Analyst':0.8}\n\nfor role, role_c in roles_c.items(): \n    row = q12_ranks.loc[role,:]\n    interval = 0.8\/(row.shape[0])\n    ax.text(xs[role], 0.92, role.upper(), \n            ha='left', va='top', fontdict={'fontweight':600, 'size':12},\n            bbox={'facecolor':'grey', 'boxstyle':'round',  'alpha':0.5}) \n    for label, value in row.items(): #iterating over series\n        y = 0.8 - value*interval\n        t = ('#'+str(int(value))+' '+label).upper()\n        \n        #ax.text(xs[role], y+0.1, t, ha='left', va='center', fontdict={'fontweight':540, 'size':12})\n        if label in list_highlights:\n            ii = (list_highlights.index(label))%7\n            highlight_color = highlight_colors[ii]\n            ax.text(xs[role], y+0.1, t, ha='left', va='center', fontdict={'fontweight':540, 'size':12},\n                   bbox={'facecolor':highlight_color, 'boxstyle':'round', 'edgecolor':'none', 'alpha':0.5})\n        else:\n            ax.text(xs[role], y+0.1, t, ha='left', va='center', fontdict={'fontweight':540, 'size':12})\n\nannotation_text = \"Figure \"+next(fig_n)+\":Top 10 media resourses reporting on data science by job titles\\nSource:ML&DL Survey 2019, question 12\"\nplt.annotate(annotation_text, (0,0), (0, -5), xycoords='axes fraction', textcoords='offset points', va='top', ha='left', fontsize=11)\n                \n\nax.grid(False)\nax.axis('off')\nplt.show()","bd1d178b":"responses_ff=responses_ff.replace({'Q3':'United States of America'},'USA')\n#Take only 6 countries (same as in executive summary,as other countries have too few responses for this analysis) \nresponses_by_country_cnt = responses_ff['Q3'].value_counts()\ncountries_list = responses_by_country_cnt.where(responses_by_country_cnt > 390).dropna().index.tolist()\ncountries_list.remove('Other')\n\n#take latest big mac prices\nbig_mac_prices = big_mac_data.loc[(big_mac_data['date'] == big_mac_data['date'].max())&\n                 big_mac_data['name'].isin(countries_list+['United States'])].replace('United States', 'USA')\nbig_mac_prices = big_mac_prices.rename(columns={'name':'Q3'})\nbig_mac_prices['burger_price_USD'] = big_mac_prices['local_price']\/big_mac_prices['dollar_ex']\n\n#medians for salary bins:\nsalary_bins_map = {\n    '$0-999' : 500,'1,000-1,999': 1500,'2,000-2,999': 2500, '3,000-3,999': 3500,'4,000-4,999': 4500,\n    '5,000-7,499': 6250,'7,500-9,999': 8750,\n    '10,000-14,999': 12500,'15,000-19,999': 17500,'20,000-24,999': 22500,'25,000-29,999': 27500, \n    '30,000-39,999': 35000,'40,000-49,999': 45000,'50,000-59,999': 55000,'60,000-69,999': 65000,\n    '70,000-79,999': 75000,'80,000-89,999': 85000,'90,000-99,999': 95000,\n    '100,000-124,999': 112500,'125,000-149,999': 137500,\n    '150,000-199,999': 175000,'200,000-249,999': 212500,'250,000-299,999': 275000, \n    '300,000-500,000': 400000,'> $500,000': 500000\n}\n\nsalary = responses_ff.loc[responses_ff['Q3'].isin(countries_list),['Q3','Q5','Q10']].copy()\n\nsalary['Q10'] = salary['Q10'].map(salary_bins_map) #put a numeric value for the salary for each respondent (median of the bin interval)\n\n#create table with salary medians with countries in rows and job roles in columns\nsalary_medians = salary.groupby(['Q3','Q5'])['Q10'].mean().unstack('Q5')\nsalary_medians = salary_medians['Data Scientist'] #yearly compensation \nsalary_medians = pd.merge(salary_medians, big_mac_prices[['Q3','burger_price_USD']], how = 'inner', on='Q3').set_index('Q3')\nsalary_medians = salary_medians.rename(columns={'Data Scientist':'DS yearly salary, USD'})\nsalary_medians['DS yearly salary, burgers'] = salary_medians['DS yearly salary, USD']\/salary_medians['burger_price_USD']\nsalary_medians = salary_medians.sort_values(['DS yearly salary, USD'])\n\n# plotting\nfig, ax = plt.subplots(1,2, figsize=(12,5))\n\naxis_colors = {\n    1:'#8A716A',\n    0:'#018E42'}\naxis_handels = {\n    0:'US dollars',\n    1:\"McDonald's Big Macs\"}    \nyaxis_labels = {\n    0:'yearly compensation, USD',\n    1:'yearly compensation, big macs'}\n\nfignum = next(fig_n)\nannotations = {\n    0:\"Figure \"+fignum+\"a: Average yearly compensation in US dollars.\\nSource: ML&DS survey 2019, question 10.\",\n    1:\"Figure \"+fignum+\"b: Average yearly compensation in Big Macs equivalents.\\nSource: The Economist - The Big Mac Index\"}\ntitles = {\n    0:(\"Data Scientists residing in the USA\\non average earn 5 times more than\\nthose who live in Brazil and India\"),\n    1:(\"The disparity in salaries\\nlooks less shocking\\nwhen they are measured in Big Macs\")}\nyaxis_limits = {\n    0:salary_medians['DS yearly salary, USD'].max()*1.1,\n    1:salary_medians['DS yearly salary, burgers'].max()*1.1}\n\n\n\nsalary_medians['DS yearly salary, USD'].plot(kind='bar',  color = axis_colors[0], alpha = 0.8 , width=0.8, ax=ax[0])\nsalary_medians['DS yearly salary, burgers'].plot(kind='bar',  color = axis_colors[1], alpha = 0.8 ,  width=0.8, ax=ax[1])\n\n#plots decoration\nfor i in [0,1]:\n    handels = [plt.bar(x=0, height=0, color=axis_colors[i])]\n    ax[i].legend(handels, [axis_handels[i]], loc = 'upper left', bbox_to_anchor=(0.01, 0.98), ncol=1, labelspacing=0.5, fontsize=12)\n    ax[i].xaxis.grid(False)\n    ax[i].set_xticklabels(ax[i].get_xticklabels(), rotation=0, fontsize=12)\n    ax[i].xaxis.set_label_text(\"\")\n    ax[i].yaxis.set_label_text(yaxis_labels[i], fontsize=12)\n    ax[i].set_title(titles[i], fontsize=14)\n    ax[i].set_ylim(0,yaxis_limits[i])\n    ax[i].annotate(annotations[i],\n                  (0,0), (0, -30), xycoords='axes fraction', textcoords='offset points', \n                  va='top', ha='left',size=11)\n    ax[i].tick_params(labelsize=12)\n\nsns.despine(left=True, bottom=True)\nplt.tight_layout()\nplt.show()","68fc3958":"*Note: There was already aggregated information on salaries in the executive summary. As I filtered out some responses ([see data preparation section](#section-data-preparation)), my figures are slightly different. I got a higher average monthly salary for India than for Brazil. I've checked that if I calculate the figures using all answers, they are aligned with the Kaggle team calculations.*","fdead058":"We can expect that if you have more experience in ML, you use more algorithms. So, it's no surprise that a higher percentage of data scientists use different ML algorithms (*see figure 14*).","7020d654":"More data scientists utilize automated model optimization techniques, letting the machines do all the hard work :)","0d7a6906":"### What changes as you gain experience in machine learning?<a class=\"anchor\" id=\"section-work-ml\"><\/a>\n48% and 43% of business analysts and data analysts (out of those who work in companies which use or explore ML methods) have less than a year of machine learning experience, whereas most data scientists have more than one year of experience in ML.","c417af80":"From the chart above, it is hard to understand whether respondents use Python together with R, Python together with SQL, or all 3 together. Let's look at these 3 languages separately and clarify this.","914f565e":"## More than a fancy job title.\n\nOn the 11th of November, I got an email from Kaggle announcing [the 2019 ML&DS survey challenge](https:\/\/www.kaggle.com\/c\/kaggle-survey-2019) (as probably most readers of this notebook did). As a business\/data analyst who is in the middle of transition to data science, I found this challenge exciting and took it on. Several things led me to focus my analysis on exploring the differences between three job titles: business analyst, data analyst and data scientist.  \n\nFirst of all, whenever I talk about my career pursuit, I hear the following questions: what is a data scientist? Isn't it just another name for data analyst? Don't business analysts and data scientists do the same things? The confusion can be partially explained by the novelty of the term. If we look at the *interest over time* metric on Google Trends (*Figure 1*) for these three job titles, we see that there was almost zero interest in the term \"data scientist\" before 2012. Since then, the interest has quadrupled. Judging by this trend, it is quite plausible that soon there will be more people searching for \"data scientist\" than for \"business analyst\", which is still the most searched for among these three terms today.\n\nAnother reason that made me choose this topic is the fact that my friends and I are not the only ones wondering. The question [What is the difference between a data analyst and a data scientist?](https:\/\/www.quora.com\/What-is-the-difference-between-a-data-analyst-and-a-data-scientist-1\/log) on Quora got more than 100 answers and 375K views.\n\nI hope that my analysis of the Kaggle survey results will bring some clarity to the matter and answer the question of whether \"data scientist\" is just a fancier job title or if it is indeed a different role.","c96c3f36":"Can this difference in tool usage be explained by the fact that data scientists have more experience in writing code to analyze data? (*see figure 9*)","9f37b28a":"Data Scientist seems to value formal education more than data analysts and business analysts, as university courses rank higher for them, which is aligned with the fact that more data scientists have a PhD degree, which we learned earlier ([see section on education](#section-education)).\n\nWhen it comes to favourite media sources, Kaggle, blogs and YouTube are in the top 3 for each job title. Preferences vary slightly for resources which are in the middle of the popularity rankings.","22bd9f25":"In the figure 12, we can see that involvement in ML grows with experience.","cd9399af":"* <small>Local IDE: RStudio, JupyterLab, etc.<\/small>\n* <small>Spreadsheets: Microsoft Excel, Google Sheets, etc.<\/small>\n* <small>Cloud APIs: AWS, GCP, Azure, etc.<\/small>\n* <small>BI software: Salesforce, Tableau, Spotfire, etc.<\/small>\n* <small>Advanced stat. software: SPSS, SAS, etc.<\/small>\n* <small>Other: free text<\/small>","9e369cd4":"<a class=\"anchor\" id=\"section-work-back-link\"><\/a>","d9b414fc":"### Wait.. what about money?<a class=\"anchor\" id=\"section-money\"><\/a>\nSure, it is important to understand how much money you can make in each role. To make the comparison meaningful, we should look at each country separately. However, it is problematic to do so for data analysts and business analysts, as we have too few responses. Luckily, in some countries we do have enough data for data scientists, so we'll look at them.\n\nOn its own, information about salaries lacks an anchor. What does it mean to earn $ 40K+ in Japan? Is it good? To level the field, I decided to use information from the McDonald's Big Mac prices in each country and translate yearly compensation to the number of Big Macs you can buy. The Big Mac index was invented by *the Economist* and is based on the theory of purchasing-power parity. You can read more about it [here](https:\/\/en.wikipedia.org\/wiki\/Big_Mac_Index).\n\nUnsurprisingly, the US is in the lead in terms of salaries, no matter which \"currency\" you measure average yearly compensation in. Brazil is at the bottom of the salary ranking. Despite the fact that on average data scientists in Russia make half as much money in USD as those in Germany, they are able to buy the same number of Big Macs in their home country. So, if you're Russian, think twice before looking for a data scientist position in Germany.","ee85397b":"Unsurprisingly, Python, R and SQL are the three most popular languages. Almost all data scientists (94%) use Python.  Additionally, many use R and SQL.\n","9a96f4ba":"<small>ML is used includes answers:<\/small>\n * <small>\"We are exploring ML methods (and may one day put a model into production)\"<\/small>\n * <small>\"We use ML methods for generating insights (but do not put working models into production)\"<\/small>\n * <small>\"We recently started using ML methods (i.e., models in production for less than 2 years)\"<\/small>\n * <small>\"We have well established ML methods (i.e., models in production for more than 2 years)\"<\/small>","d341cc3d":"### Final thoughts<a class=\"anchor\" id=\"section-conclusion\"><\/a>\nAfter looking at respondents with 3 job titles in depth, I am convinced that data scientists are a different breed compared to business analysts and data analysts. Surely, there are companies that use these terms interchangeably, but in general, the role of data scientist requires more technical education in programming and ML.\n\nA data scientist's job involves analyzing data, and most data scientists do it in IDEs, so you should forget about Spreadsheets, install Jupiter and learn Python... that is, if you haven\u2019t already done so. Then, study machine learning algorithms, as this is another area where data scientists stand out from business analysts and data analysts. If you are still a college\/university student - take your studies seriously, and complement it with resources like Coursera and Kaggle.\n\nBest of luck to all of us aspiring data scientists!","c9b7d942":"More than a quarter of respondents use Python and SQL on a regular basis, and 26%, 24% and 17% of data scientists, data analysts and business analysts respectively use all 3 languages.\n\nIf you know only Python, which language should you learn next? Seems like SQL? And if you know none?\nIn the survey, there was a question asking what programming language you would recommend for an aspiring data scientist to learn. Let's check which one is recommended by respondents who know all three programming languages (see figure 20).\n\nOk, the top choice is Python indeed, but the second most popular recommendation among data scientists and business analysts is actually R. Only data analysts recommend learning SQL more often than R.","e10598d8":"* <small>\"No formal education past high school\" and \"Some college\/university study without earning a bachelor\u2019s degree\" were combined in \"No degree\"<\/small>\n* <small>\"I prefer not to answer\" isn't displayed as only 1% chose this option<\/small>","f250a678":"#### Navigation\n* [Setting the scene for the analysis](#section-data-preparation)\n* [You are never too young or too old for anything](#section-age)\n* [Everyone is a scientist at heart, but some also have a doctoral degree](#section-education)\n* [Who does what? (Overview)](#section-work)\n* [Does your job title define what tools you use for data analysis?](#section-work-da)\n* [What changes as you gain experience in machine learning?](#section-work-ml)\n* [Which programming language should you learn?](#section-python)\n* [Advice on how to advance your career in data science](#section-resources)\n* [Wait... What about money?](#section-money)\n* [Final thoughts](#section-conclusion)","6836af50":"### Does your job title define which tools you use for data analysis?<a class=\"anchor\" id=\"section-work-da\"><\/a>\nWe learned in the previous section that no matter whether you are called data scientist, business analyst or data analyst, you analyze and understand data to influence product or business decisions. How you do it - is another question. \n\nFigure 8 suggests that if you are a data scientist you are more likely to use a local development environment (RStudio, JupyterLab, etc.), whereas the majority of business analysts use Spreadsheets (Microsoft Excel, Google Sheets, etc.).\n","f0356634":"I excluded responses from those who didn't finish the survey from my analysis. We shouldn't trust those who don't finish what they start, especially when the time commitment is only 10 minutes :) \n\nI also excluded those who were too fast answering the survey (by calculating 1% quantile on survey time, separately for different survey paths). \n\nThus, my analysis is based on responses from:\n* 3239 data scientists\n* 1182 data analysts\n* 557 business analysts","0fbb1d70":"### Who does what?<a class=\"anchor\" id=\"section-work\"><\/a>\nIf your title says \"data scientist\", I can bet that your company incorporates machine learning methods into its business. The majority of data scientists work in such companies (94%). For business analysts and data analysts this number is lower - 66% and 77% of them respectively work at companies which either use or explore machine learning methods.","eba09084":"### Advice on how to advance your career in data science <a class=\"anchor\" id=\"section-resources\"><\/a>\nToday, if you want to gain knowledge in any topic, including data science, you could do it without leaving your home, thanks to the Internet, and MOOCs in particular. How should you choose the best course or resource among the numerous options? Ask a more experienced colleague or read reviews about courses... or look at the answers to question number 13 of the Kaggle survey. However, be cautious, as respondents were asked to choose the platforms where they had begun or completed data science courses. So, we don't really know if they were happy with the quality.\n\nAnyway, below are the top 10 learning platforms for each job title (see figure 19).","c1b093a8":"### Setting the scene for the analysis <a class=\"anchor\" id=\"section-data-preparation\"><\/a>\nThe survey was designed so that respondents with more experience were asked more questions. For example, students and unemployed respondents didn't get questions about their salary and company, those who said that they'd never written code to analyze data weren't asked about software and products they use, and so on. According to the survey schema, there were 3 possible exit points from the survey:\n* question 15 - for those who don't have experience in writing code to analyze data \n* question 28 - for students and unemployed respondents with coding experience, and for employed respondents whose company spent zero on machine learning \n* question 34 - for everyone else\n\nBased on this information, I determined which question was supposed to be the last one for each respondent. It turned out that about 27% of respondents actually dropped out at some point. Statisticians seem to be the busiest people of all, as 31% of them didn't finish the survey, whereas 80% of data scientists did proceed until the very end (see figure 2).\n\n*Fun Fact: unemployed people took the lead in this rating, as the biggest proportion of them finished the survey*","8daab0eb":"### Are data scientists older than others? <a class=\"anchor\" id=\"section-age\"><\/a>\nThe short answer is no. The biggest age group for all three job titles is 25-29, and we actually have a higher share of older respondents among business analysts, and the proportion of younger respondents is slightly higher among data analysts (*see figure 3*).","8e4d1781":"The fact that your company uses or explores ML methods doesn't necessarily mean that you yourself are involved. Let's explore this further.\n\nEveryone who said that their employer incorporates machine learning methods into their business were asked about activities that make up an important part of their role at work. Respondents were given a list of 6 activities, from which they could choose none, some or all activities. From their answers we can't say what portion of their day-to-day work each activity takes up, but we can get an idea of whether they are involved in certain types of tasks.\n\n\nI grouped these activities into 3 major categories:\n1. Data Analysis related: \n    * \"Analyze and understand data to influence product or business decisions\"\n2. Data Infrastructure related:\n    * \"Build and\/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data\"\n3.  Machine learning related: \n    * \"Build prototypes to explore applying machine learning to new areas\"\n    * \"Build and\/or run a machine learning service that operationally improves my product or workflows\"\n    * \"Experimentation and iteration to improve existing ML models\"\n    * \"Do research that advances the state of the art of machine learning\"\n\nLooking at figure 7a, we can conclude that analyzing data is an important part of every role. Activities related to machine learning are performed by the majority of data scientists (~90%), whereas only half of data analysts and business analysts (~53%) are involved in machine learning.\n\nFigure 7b provides a detailed view of those who selected at least one of the activities related to machine learning","ca7ffff2":"### Which programming language should you learn? <a class=\"anchor\" id=\"section-python\"><\/a>","efe93857":"It is very likely so, but let's explore it further... with heatmaps! Darker green squares will reveal groups with a higher share of Spreadsheet users, and purple is for those who use IDEs.\n\nWith a quick glance we can see that few data scientists use Spreadsheets, and with more experience almost nobody does. For business analysts the picture is different. Even when they have 3-5 years of experience in writing code, 28% of them still analyze data in Spreadsheets. Data analysts are somewhere in the middle.","95a4c063":"### Everyone is a scientist at heart, but some also have a doctoral degree.<a class=\"anchor\" id=\"section-age-education\"><\/a>\nWhen I researched job prospects for a data scientist, I saw that many job postings mention that suitable candidates should have a Master's, PhD, or equivalent experience in a quantitative field. The survey results align with this. The majority of data scientists do have a Master's degree and almost 20% have a PhD, whereas only a small percentage of business and data analysts continue their study past a Master's degree.\n","025d6a63":"Earlier, we saw that more data scientists than business analysts and data analysts mentioned prototyping and experimenting with ML models, as well as doing ML research (*see figure 7 in [Who does what?](#section-work-back-link)*)\n\nI was curious to know if data scientists do everything from prototyping to research and business analysts and data analysts do only some of machine learning tasks.\n\n4 activities means 16 combinations. I decided to draw a table with all possible combinations and see which are the most common for each job title. \nBy studying these tables, I learned that many of data analysts and business analysts selected only 1 activity (with prototyping being the top choice), whereas considerably more data scientists selected multiple activities.\n\n<small>In the figure below, I highlighted in yellow the combinations that include building prototypes, building or running a machine learning service, and experimentation. Orange indicates sets with a single activity.<\/small>\n"}}