{"cell_type":{"014fc442":"code","37fdfaa2":"code","49a78f33":"code","4fbf76bf":"code","106b4caa":"code","f8c588af":"code","177f6243":"markdown","d27a57b2":"markdown","3d87f3ca":"markdown","cc065a5c":"markdown","9da77c33":"markdown","c1342a98":"markdown"},"source":{"014fc442":"import numpy as np # linear algebra\nimport pandas as pd # data processing\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","37fdfaa2":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()","49a78f33":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","4fbf76bf":"women = train_data.loc[train_data.Sex == 'female']['Survived']\nrate_women = sum(women) \/ len(women)\nprint('% of women who survived:', rate_women)","106b4caa":"men = train_data.loc[train_data.Sex == 'male']['Survived']\nrate_men = sum(men) \/ len(men)\nprint('% of men who survived:', rate_men)","f8c588af":"from sklearn.ensemble import RandomForestClassifier\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","177f6243":"# Getting started with Titanic\n## Kaggle Tutorial\n\nLet's being with the default Kaggle notebook starting commands which will load the `numPy` and `pandas` packages and show a list of available files in the `kaggle\/input\/` folder.","d27a57b2":"And do the same for the `test.csv` file.","3d87f3ca":"Let's see what proportion of male passengers survived.","cc065a5c":"From the data in `train.csv` we can see that almost 75% of women survived whereas only 19% of men survived. Gender does appear to be a fairly strong indicator of survival. However, the gender-based submission only considers one column. By considering multiple columns we can uncover more complex patterns that may potentially lead to better predictions. Doing this by hand is difficult, and this is where we can use machine learning to help.\n\n### Our first machine learning model\nWe will build what is known as a **random forest model**. This model is constructed of several \"trees\" (there are three trees in the picture below but we will construct 100) that will individually consider each passenger's data and vote on whether that passenger survived. Then the random forest model makes a democratic decision: the outcome with the most votes wins.\n\n![](https:\/\/i.imgur.com\/AC9Bq63.png)\n\nThe code cell below looks for patterns in four different columns (`Pclass`, `Sex`, `SibSp`, and `Parch`) of the data. It constructs the trees in the random forest model based on patterns in the `train.csv` file, before generating predictions for the passengers in `test.csv`. The code also saves these new predictions in a CSV file `my_submission.csv`.","9da77c33":"Now we can read the `train.csv` file into pandas and view the `head`.","c1342a98":"## Improving our score\nOur goal is to find patterns in `train.csv` that help us predict whether the passengers in `test.csv` survived. We'll start simple.\n\n### Exploring a pattern\nRemember that the sample submission file in `submissions\/gender_submission.csv` assumes that all female passengers survived (and all male passengers survived). Let's check if this pattern holds true in `train.csv`."}}