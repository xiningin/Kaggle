{"cell_type":{"443438d5":"code","c1437877":"code","b4eb17b7":"code","b32ee357":"code","6a9f954c":"code","a03554a4":"code","ec873076":"code","22e9144a":"code","a072d6da":"code","fa6bbeb6":"code","cd0c67ab":"code","8af43a2f":"code","08e5fe23":"code","80529eb6":"code","da2e77c3":"code","1e950ce1":"code","a05d6559":"code","2a4912dc":"code","1e2f5d79":"code","cf4144bf":"code","7255dbd4":"code","6c6e2cf8":"code","e39b9577":"code","e54b83a0":"code","41d7c748":"code","19e56a72":"code","a5eddbd3":"code","6ae94e44":"code","7828b9d2":"code","01f77ac7":"code","efa95050":"code","ff90b86d":"code","f5838039":"code","93914eb1":"code","f6679e4a":"code","12bf8940":"code","e7f8851e":"code","88681416":"code","c0745f26":"code","b64be5f0":"code","d90db2f4":"code","db3d8258":"code","e2b79dbf":"code","9813929f":"code","c8522f68":"code","eb1f1a52":"code","ccbbc724":"code","bb5ddbbb":"markdown","3bf7e3e8":"markdown"},"source":{"443438d5":"# To remove deprecated warnings from the tensorflow\nimport warnings\nwarnings.filterwarnings(\"ignore\")","c1437877":"pwd","b4eb17b7":"import os\nos.chdir(\"\/kaggle\/input\/brain-mri-images-for-brain-tumor-detection\")","b32ee357":"pwd","6a9f954c":"PATH = os.getcwd()","a03554a4":"DATA_PATH = os.path.join(PATH, \"brain_tumor_dataset\")\ndata_dir_list = os.listdir(DATA_PATH)","ec873076":"print(data_dir_list)","22e9144a":"import cv2\n\nclasses_names_list=[]\nimg_data_list=[]\n\nfor dataset in data_dir_list:\n    classes_names_list.append(dataset) \n    print ('Loading images from {} folder\\n'.format(dataset)) \n    img_list=os.listdir(DATA_PATH+'\/'+ dataset)\n    for img in img_list:\n        input_img=cv2.imread(DATA_PATH + '\/'+ dataset + '\/'+ img )\n        input_img_resize=cv2.resize(input_img,(224, 224))\n        (b, g, r)=cv2.split(input_img_resize) \n        img=cv2.merge([r,g,b])\n        img_data_list.append(img)","a072d6da":"num_classes = len(classes_names_list)\nprint(num_classes)","fa6bbeb6":"import numpy as np\n\nimg_data = np.array(img_data_list)\nimg_data = img_data.astype('float32')\nimg_data \/= 255","cd0c67ab":"print (img_data.shape)","8af43a2f":"#show one training sample\nfrom matplotlib import pyplot as plt\nplt.imshow(img_data[97])\nplt.show()","08e5fe23":"num_of_samples = img_data.shape[0]\ninput_shape = img_data[0].shape","80529eb6":"classes = np.ones((num_of_samples,), dtype='int64')\n\nclasses[0:98]=0\nclasses[98:]=1","da2e77c3":"from keras.utils import to_categorical\n\nclasses = to_categorical(classes, num_classes)","1e950ce1":"from sklearn.utils import shuffle\n\nX, Y = shuffle(img_data, classes, random_state=456)","a05d6559":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=456)","2a4912dc":"# Check the number of images in each dataset split\nprint(X_train.shape, X_test.shape)\nprint(y_train.shape, y_test.shape)","1e2f5d79":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D","cf4144bf":"#### Build the model\nmodel = Sequential()\n\nmodel.add(Conv2D(32, (3, 3),activation='relu', input_shape=input_shape))\nmodel.add(Conv2D(32, (3, 3),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(64, (3, 3),activation='relu'))\nmodel.add(Conv2D(64, (3, 3),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(num_classes, activation='sigmoid'))","7255dbd4":"model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])","6c6e2cf8":"model.summary()","e39b9577":"%%time\nhist = model.fit(X_train, y_train, batch_size=32, epochs=20, verbose=1, validation_data=(X_test, y_test))","e54b83a0":"score = model.evaluate(X_test, y_test, batch_size=32)\n\nprint('Test Loss:', score[0])\nprint('Test Accuracy:', score[1])","41d7c748":"from sklearn.metrics import confusion_matrix\n\nY_pred = model.predict(X_test)","19e56a72":"y_pred = np.argmax(Y_pred, axis=1)\nprint(y_pred)","a5eddbd3":"print(confusion_matrix(np.argmax(y_test, axis=1), y_pred))","6ae94e44":"from keras.preprocessing.image import ImageDataGenerator\n\ntrain_data_gen = ImageDataGenerator(\n    rotation_range=15,\n    shear_range=0.1, \n    zoom_range=0.4, \n    vertical_flip=True,\n    brightness_range=[0.5, 1.5],\n    rescale=1.\/255,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True)\n\ntest_data_gen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator = train_data_gen.flow_from_directory(\n        DATA_PATH,\n        target_size=(224, 224), \n        batch_size=32,\n        class_mode='binary',\n        color_mode='rgb', \n        shuffle=True,  \n        #save_to_dir='Train_Augmented_Images', \n        #save_prefix='TrainAugmented', \n        #save_format='jpeg'\n)\n\ntest_generator = test_data_gen.flow_from_directory(\n        DATA_PATH,\n        target_size=(224, 224),\n        batch_size=32,\n        class_mode='binary',\n        color_mode='rgb',\n        shuffle=True, \n        seed=None, \n        #save_to_dir='Test_Augmented_Images', \n        #save_prefix='TestAugmented', \n        #save_format='jpeg'\n)","7828b9d2":"train_generator.class_indices","01f77ac7":"test_generator.class_indices","efa95050":"#### Build the model\nmodel = Sequential()\n\nmodel.add(Conv2D(32, (3, 3),activation='relu', input_shape=input_shape))\nmodel.add(Conv2D(32, (3, 3),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(64, (3, 3),activation='relu'))\nmodel.add(Conv2D(64, (3, 3),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1, activation='sigmoid'))","ff90b86d":"model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])","f5838039":"model.summary()","93914eb1":"%%time\nmodel.fit_generator(train_generator, epochs=20, validation_data=test_generator)","f6679e4a":"from keras.layers import Input, Dense\nfrom keras.models import Model","12bf8940":"image_input = Input(shape=(224, 224, 3))","e7f8851e":"from keras.applications.vgg16 import VGG16\n\nmodel = VGG16(input_tensor=image_input, include_top=False, weights='imagenet')","88681416":"last_layer = model.get_layer('block5_pool').output\nx = Flatten(name='flatten')(last_layer)\nx = Dense(128, activation='relu', name='fc1')(x)\nx = Dense(128, activation='relu', name='fc2')(x)\nout = Dense(num_classes, activation='softmax', name='output')(x)\ncustom_vgg_model = Model(image_input, out)","c0745f26":"custom_vgg_model.summary()","b64be5f0":"# freeze all the layers except the dense layers\nfor layer in custom_vgg_model.layers[:-3]:\n    layer.trainable = False","d90db2f4":"custom_vgg_model.summary()","db3d8258":"custom_vgg_model.compile(loss='binary_crossentropy', optimizer='adadelta', metrics=['accuracy'])","e2b79dbf":"%%time\nhist = custom_vgg_model.fit(X_train, y_train, batch_size=32, epochs=20, verbose=1, validation_data=(X_test, y_test))","9813929f":"(loss, accuracy) = custom_vgg_model.evaluate(X_test, y_test, batch_size=32, verbose=1)\n\nprint(\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))","c8522f68":"Y_train_pred = custom_vgg_model.predict(X_test)","eb1f1a52":"y_train_pred = np.argmax(Y_train_pred, axis=1)\nprint(y_train_pred)","ccbbc724":"print(confusion_matrix(np.argmax(y_test, axis=1), y_train_pred))","bb5ddbbb":"### TL - VGG16","3bf7e3e8":"## Data Augementation"}}