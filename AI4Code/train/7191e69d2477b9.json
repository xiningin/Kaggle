{"cell_type":{"995e7703":"code","b5a28f57":"code","9abb4495":"code","2af6d305":"code","9a71575c":"code","71cbde08":"code","ad4cd5e4":"code","9c9a1cfe":"code","fe139067":"code","ff4fba9e":"code","f37d9830":"code","3c10e2f6":"code","03adc339":"code","c78c5aff":"code","2b668624":"markdown","cc684898":"markdown","883cb2cc":"markdown","e49eaf83":"markdown","5f9b696f":"markdown","ff25dfbc":"markdown","d53717cb":"markdown","3b502143":"markdown","5962084d":"markdown","8c8ae588":"markdown","363066d9":"markdown","80ca6168":"markdown","634d396d":"markdown"},"source":{"995e7703":"import numpy as np  \nimport pandas as pd  \nimport matplotlib.pyplot as plt \nfrom scipy import stats\nfrom scipy.stats import norm, skew  \n\nimport warnings\ndef ignore_warn(*args, **kwargs):\n    pass\nwarnings.warn = ignore_warn \n\n# Limiting floats output to 3 decimal points\npd.set_option('display.float_format', lambda x: '{:.3f}'.format(x))  ","b5a28f57":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")","9abb4495":"# Save the 'Id' column\ntrain_ID = train['Id']\ntest_ID = test['Id']\n\n# Now drop the  'Id' colum since it's unnecessary for  the prediction process.\ntrain.drop(\"Id\", axis=1, inplace=True)\ntest.drop(\"Id\", axis=1, inplace=True)\n\n# check again the data size after dropping the 'Id' variable\nprint(\"\\nThe train data size after dropping Id feature is : {} \".format(train.shape))\nprint(\"The test data size after dropping Id feature is : {} \".format(test.shape))","2af6d305":"# Deleting outliers\ntrain = train.drop(train[(train['GrLivArea'] > 4000) & (train['SalePrice'] < 300000)].index)\n\n# We use the numpy fuction log1p which  applies log(1+x) to all elements of the column\ntrain[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n\nntrain = train.shape[0]\nntest = test.shape[0]\ny_train = train.SalePrice.values\nall_data = pd.concat((train, test)).reset_index(drop=True)\nall_data.drop(['SalePrice'], axis=1, inplace=True)\nprint(\"all_data size is : {}\".format(all_data.shape))","9a71575c":"# fillna\nall_data[\"PoolQC\"] = all_data[\"PoolQC\"].fillna(\"None\")\n\nall_data[\"MiscFeature\"] = all_data[\"MiscFeature\"].fillna(\"None\")\n\nall_data[\"Alley\"] = all_data[\"Alley\"].fillna(\"None\")\n\nall_data[\"Fence\"] = all_data[\"Fence\"].fillna(\"None\")\n\nall_data[\"FireplaceQu\"] = all_data[\"FireplaceQu\"].fillna(\"None\")","71cbde08":"# Group by neighborhood and fill in missing value by the median LotFrontage of all the neighborhood\nall_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n    lambda x: x.fillna(x.median()))","ad4cd5e4":"for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n    all_data[col] = all_data[col].fillna('None')\nfor col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n    all_data[col] = all_data[col].fillna(0)\nfor col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n    all_data[col] = all_data[col].fillna(0)\nfor col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    all_data[col] = all_data[col].fillna('None')","9c9a1cfe":"all_data[\"MasVnrType\"] = all_data[\"MasVnrType\"].fillna(\"None\")\nall_data[\"MasVnrArea\"] = all_data[\"MasVnrArea\"].fillna(0)\nall_data['MSZoning'] = all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])\nall_data = all_data.drop(['Utilities'], axis=1)\nall_data[\"Functional\"] = all_data[\"Functional\"].fillna(\"Typ\")\nall_data['Electrical'] = all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])\nall_data['KitchenQual'] = all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])\nall_data['Exterior1st'] = all_data['Exterior1st'].fillna(all_data['Exterior1st'].mode()[0])\nall_data['Exterior2nd'] = all_data['Exterior2nd'].fillna(all_data['Exterior2nd'].mode()[0])\nall_data['SaleType'] = all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])\nall_data['MSSubClass'] = all_data['MSSubClass'].fillna(\"None\")","fe139067":"# MSSubClass is the building class\nall_data['MSSubClass'] = all_data['MSSubClass'].apply(str)\n\n# Changing OverallCond into a categorical variable\nall_data['OverallCond'] = all_data['OverallCond'].astype(str)\n\n# Year and month sold are transformed into categorical features.\nall_data['YrSold'] = all_data['YrSold'].astype(str)\nall_data['MoSold'] = all_data['MoSold'].astype(str)","ff4fba9e":"from sklearn.preprocessing import LabelEncoder\ncols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond',\n            'ExterQual', 'ExterCond', 'HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1',\n            'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n            'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond',\n            'YrSold', 'MoSold')\n# process columns, apply LabelEncoder to categorical features\nfor c in cols:\n    lbl = LabelEncoder()\n    lbl.fit(list(all_data[c].values))\n    all_data[c] = lbl.transform(list(all_data[c].values))\n\n# control shape\nprint('Shape all_data: {}'.format(all_data.shape))","f37d9830":"# Adding total sqfootage feature\nall_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']","3c10e2f6":"numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n\n# Check the skew of all numerical features\nskewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nprint(\"\\nSkew in numerical features: \\n\")\nskewness = pd.DataFrame({'Skew': skewed_feats})\n\nskewness = skewness[abs(skewness) > 0.75]\nprint(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))","03adc339":"from scipy.special import boxcox1p\nskewed_features = skewness.index\nlam = 0.15\nfor feat in skewed_features:\n    all_data[feat] = boxcox1p(all_data[feat], lam)\n\nall_data = pd.get_dummies(all_data)\nprint(all_data.shape)\n\ntrain = all_data[:ntrain]\ntest = all_data[ntrain:]","c78c5aff":"%%time\nimport h2o\nfrom h2o.automl import H2OAutoML\nh2o.init()\n\ntrain['SalePrice'] = y_train\nhtrain = h2o.H2OFrame(train)\nhtest = h2o.H2OFrame(test)\nx = htrain.columns\ny = \"SalePrice\"\nx.remove(y)\n\n# train the model for 2-3 hours instead of 20 seconds\naml = H2OAutoML(max_runtime_secs = 3600, seed = 1) \naml.train(x=x, y =y, training_frame=htrain)\nlb = aml.leaderboard\nprint (lb)\nprint(\"generate predictions\")\ntest_y = aml.leader.predict(htest)\ntest_y = test_y.as_data_frame()\n\n# submit results\nsub = pd.DataFrame()\nsub['Id'] = test_ID\nsub['SalePrice'] = np.expm1(test_y)\nsub.to_csv('submission.csv',index=False)","2b668624":"**Box Cox Transformation of (highly) skewed features**","cc684898":"**H2O AutoML Solution for Kaggle Housing Prices Competition.\nAutomated model stacking from H2O gives TOP 1% solution.\nI have used this for feature processing, but kept it much shorter:\nhttps:\/\/www.kaggle.com\/sagarmainkar\/sagar**","883cb2cc":"**Now read the train and test datasets in pandas dataframes**","e49eaf83":"**Convert some features to str type to be a cathegorical one**","5f9b696f":"**Save ID column and drop it from train & test dataframes **","ff25dfbc":"**H2O AutoML example. Train it for 2-3 hours to get a TOP 1% solution.\nLink to the documentation:\nhttp:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/automl.html\n**","d53717cb":"**Some more nan filling**","3b502143":"**Import librairies**","5962084d":"**If you found this notebook helpful, please upvote ** :-)","8c8ae588":"**Delete outliers - incredibly large homes with low prices and drop SalePrice column**","363066d9":"**Process some features with LabelEncoder**","80ca6168":"**Fill nans**","634d396d":"**Apply Cox Box transformation and create cleaned train & test data**"}}