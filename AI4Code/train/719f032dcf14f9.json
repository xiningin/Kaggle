{"cell_type":{"ff494fa3":"code","080ad30d":"code","b055d553":"code","c9cec167":"code","aa9c3993":"code","69c06853":"code","82c6be32":"code","1a1405f9":"code","4de01862":"code","bb7daee5":"code","275499a3":"code","2a93c5ba":"code","b837f98a":"code","718eb893":"code","9b1d87c4":"code","11bc3165":"code","aa749b1d":"code","2d1f8966":"code","386f9b2e":"code","20e19564":"code","5eb9b45f":"code","dda2673a":"markdown","4eef5e76":"markdown","569f15da":"markdown"},"source":{"ff494fa3":"#Import Lib\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os, sys\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression","080ad30d":"# Read the CSV \ndf = pd.read_csv('..\/input\/parkinsons\/parkinsons.csv')\ndf.head()","b055d553":"df.info()","c9cec167":"df.describe()","aa9c3993":"sns.pairplot(data=df[df.columns[0:24]])\nplt.show()","69c06853":"plt.figure(figsize=(8,5))\nsns.heatmap(df.corr(),annot=True,cmap='cubehelix_r') \nplt.show()","82c6be32":"# Get the features and labels\nall_features=df.loc[:,df.columns!='status'].values[:,1:]#all featueres \nout_come=df.loc[:,'status'].values#labels is status","1a1405f9":"out_come","4de01862":" #Get the count of each label (0 and 1) in labels\nprint(out_come[out_come==1].shape[0], out_come[out_come==0].shape[0])","bb7daee5":"#DataFlair - Scale the features to between -1 and 1\nscaler=MinMaxScaler((-1,1))\nX=scaler.fit_transform(all_features)\ny=out_come","275499a3":"print(X)","2a93c5ba":"print(y)","b837f98a":"#Split the dataset train = 80 % and test =20 %\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)","718eb893":"#Applying SVC (Support Vector Classification)\nfrom sklearn.svm import SVC\n\nsvm = SVC(kernel='rbf', random_state=0, gamma=.10, C=1.0)\nsvm.fit(X_train, y_train)","9b1d87c4":"#Applying XGBoost\nimport xgboost as xgb\n\nxgb_clf = xgb.XGBClassifier()\nxgb_clf = xgb_clf.fit(X_train, y_train)\n","11bc3165":"  #Applying KNeighborsClassifier \n  from sklearn.neighbors import KNeighborsClassifier\n\n  knn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n  knn.fit(X_train, y_train)\n","aa749b1d":"#Applying Decision Tree\nfrom sklearn import tree\n\n#Create tree object\ndecision_tree = tree.DecisionTreeClassifier(criterion='gini')\n\n#Train DT based on scaled training set\ndecision_tree.fit(X_train, y_train)","2d1f8966":"#Applying RandomForest\nfrom sklearn.ensemble import RandomForestClassifier\n\n#Create Random Forest object\nrandom_forest = RandomForestClassifier()\n\n#Train model\nrandom_forest.fit(X_train, y_train)","386f9b2e":"#Applying Regression classifier \nlg = LogisticRegression(solver='lbfgs')\nlg.fit(X_train, y_train)","20e19564":"#Applying GaussianNB\nfrom sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(X_train , y_train)","5eb9b45f":"#Print performance\nprint ('The accuracy of the performance training data and test data   ')\nprint('')\nprint('')\nprint('+++++++++++++++++++++++++++++++++++++++++++++++++++++++')\nprint('')\nprint('The accuracy of the SVM classifier on training data is : {:.2f}'.format(svm.score(X_train, y_train)*100))\nprint('The accuracy of the SVM classifier on test data is : {:.2f}'.format(svm.score(X_test ,y_test)*100))\nprint('')\nprint('+++++++++++++++++++++++++++++++++++++++++++++++++++++++')\nprint('')\nprint('The accuracy of the XGBoost classifier on training data is : {:.2f}'.format(xgb_clf.score(X_train, y_train)*100))\nprint('The accuracy of the XGBoost classifier on test data is : {:.2f}'.format(xgb_clf.score(X_test, y_test)*100))\nprint('')\nprint('+++++++++++++++++++++++++++++++++++++++++++++++++++++++')\nprint('')\nprint('The accuracy of the Knn classifier on training data is : {:.2f}'.format(knn.score(X_train, y_train)*100))\nprint('The accuracy of the Knn classifier on test data is : {:.2f}'.format(knn.score(X_test, y_test)*100))\nprint('')\nprint('+++++++++++++++++++++++++++++++++++++++++++++++++++++++')\nprint('')\nprint('The accuracy of the Decision Tree classifier on training data is : {:.2f}'.format(decision_tree.score(X_train, y_train)*100))\nprint('The accuracy of the Decision Tree classifier on test data is : {:.2f}'.format(decision_tree.score(X_test, y_test)*100))\nprint('')\nprint('+++++++++++++++++++++++++++++++++++++++++++++++++++++++')\nprint('')\nprint('The accuracy of the Random Forest classifier on training data is : {:.2f}'.format(random_forest.score(X_train, y_train)*100))\nprint('The accuracy of the Random Forest classifier on test data is : {:.2f}'.format(random_forest.score(X_test, y_test)*100))\nprint('')\nprint('+++++++++++++++++++++++++++++++++++++++++++++++++++++++')\nprint('')\nprint('The accuracy of the Logistic Regression classifier on training data is : {:.2f}'.format(lg.score(X_train, y_train)*100))\nprint('The accuracy of the Logistic Regression classifier on test data is : {:.2f}'.format(lg.score(X_test, y_test)*100))\nprint('')\nprint('+++++++++++++++++++++++++++++++++++++++++++++++++++++++')\nprint('')\nprint('The accuracy of the GaussianNB classifier on training data is : {:.2f}'.format(nb.score(X_train, y_train)*100))\nprint('The accuracy of the GaussianNB classifier on test data is : {:.2f}'.format(nb.score(X_test, y_test)*100))","dda2673a":"### Parkinson's disease (PD), or simply Parkinson's\n\n It is a long-term degenerative disorder of the central nervous system that mainly affects the motor system. The symptoms usually emerge slowly and, as the disease worsens, non-motor symptoms become more common.\n\n\n","4eef5e76":"[![image.png](attachment:image.png)](http:\/\/)","569f15da":"### Data Set Information:\nThis dataset is composed of a range of biomedical voice measurements from 31 people, 23 with Parkinson's disease (PD). Each column in the table is a particular voice measure, and each row corresponds one of 195 voice recording from these individuals (\"name\" column). The main aim of the data is to discriminate healthy people from those with PD, according to \"status\" column which is set to 0 for healthy and 1 for PD.\n\nThe data is in ASCII CSV format. The rows of the CSV file contain an instance corresponding to one voice recording. There are around six recordings per patient, the name of the patient is identified in the first column.For further information or to pass on comments, please contact Max Little (littlem '@' robots.ox.ac.uk).\n\nFurther details are contained in the following reference -- if you use this dataset, please cite:\nMax A. Little, Patrick E. McSharry, Eric J. Hunter, Lorraine O. Ramig (2008), 'Suitability of dysphonia measurements for telemonitoring of Parkinson's disease', IEEE Transactions on Biomedical Engineering (to appear).\n\n### Attribute Information:\nMatrix column entries (attributes):\nname - ASCII subject name and recording number\nMDVP:Fo(Hz) - Average vocal fundamental frequency\nMDVP:Fhi(Hz) - Maximum vocal fundamental frequency\nMDVP:Flo(Hz) - Minimum vocal fundamental frequency\nMDVP:Jitter(%),MDVP:Jitter(Abs),MDVP:RAP,MDVP:PPQ,Jitter:DDP - Several measures of variation in fundamental frequency\nMDVP:Shimmer,MDVP:Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,MDVP:APQ,Shimmer:DDA - Several measures of variation in amplitude\nNHR,HNR - Two measures of ratio of noise to tonal components in the voice\nstatus - Health status of the subject (one) - Parkinson's, (zero) - healthy\nRPDE,D2 - Two nonlinear dynamical complexity measures\nDFA - Signal fractal scaling exponent\nspread1,spread2,PPE - Three nonlinear measures of fundamental frequency variation\n\n### Link:\nhttps:\/\/archive.ics.uci.edu\/ml\/datasets\/Parkinsons"}}