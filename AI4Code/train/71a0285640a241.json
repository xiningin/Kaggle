{"cell_type":{"7764e86d":"code","36d33c1a":"code","867be3d0":"code","3365b1ba":"code","4b35375f":"code","81facb19":"code","b3ae5996":"code","0a52b891":"code","8034f879":"code","79671225":"code","9e260e5f":"code","485780ac":"code","00df7e2a":"code","25c74f9c":"code","588fc889":"code","a2567120":"code","f96f2122":"code","38edf686":"code","d75d6886":"code","c7ec2a44":"markdown","e6f49919":"markdown","4932ae3a":"markdown","3ad15abd":"markdown","5cd54be1":"markdown"},"source":{"7764e86d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline","36d33c1a":"#Load dataset\ndf = pd.read_csv('..\/input\/house-prices-dataset\/train.csv',usecols=['BsmtQual','FireplaceQu','GarageType','SalePrice'])\ndf.head()","867be3d0":"#Checking the no. of null values present\ndf.isnull().sum()","3365b1ba":"#To check the null values in a column (Obnly demonstrating using one column right now)\ndf.BsmtQual.value_counts()","4b35375f":"#To print the same in Graphical format\ndf.BsmtQual.value_counts().plot.bar()","81facb19":"#Showing the most frequent variable\nmost_freq_variable = df.BsmtQual.value_counts().index[0]\nmost_freq_variable","b3ae5996":"#Function to replace the null value with most frequent value\ndef most_freq(df,variable):\n    df[variable]=df[variable].fillna(df.BsmtQual.value_counts().index[0])","0a52b891":"#Calling the function in a loop for all columns\nfor i in ['BsmtQual','FireplaceQu','GarageType']:\n    most_freq(df,i)","8034f879":"#Checking the count of NaN values now\ndf.isnull().sum()","79671225":"#Load dataset\ndf = pd.read_csv('..\/input\/house-prices-dataset\/train.csv',usecols=['BsmtQual','FireplaceQu','GarageType','SalePrice'])\ndf.head()","9e260e5f":"#Writing a function to create a new column for each existing columns and replace it with 1 if NaN value else 0\ndef impute_nan(df, variable, frequent):\n    df[variable+'_new'] = np.where(df[variable].isnull(),1,0)\n    df[variable].fillna(frequent, inplace = True)","485780ac":"#Replacing the existing Column NaN values with the most freq value as done in method 1\nfor feature in ['BsmtQual','FireplaceQu','GarageType']:\n    frequent = df[feature].mode()[0]\n    impute_nan(df, feature, frequent)","00df7e2a":"df.head()","25c74f9c":"#Load dataset\ndf = pd.read_csv('..\/input\/house-prices-dataset\/train.csv',usecols=['BsmtQual','FireplaceQu','GarageType','SalePrice'])\ndf.head()","588fc889":"#Creating a new column where the missing values will be replaced by 'missing' variable and non missing variables will be copied\ndef impute_nan(df, variable):\n    df[variable+'_new_var'] = np.where(df[variable].isnull(),'missing',df[variable])","a2567120":"#Implementing all the columns using for loop\nfor feature in ['BsmtQual','FireplaceQu','GarageType']:\n    impute_nan(df, feature)","f96f2122":"df.head()","38edf686":"#Dropping the original columns as new columns are more useful because of no null values\ndf = df.drop(['BsmtQual','FireplaceQu','GarageType'], axis=1)","d75d6886":"df.head()","c7ec2a44":"## 1. Frequent Category imputation","e6f49919":"### Advantages and Disadvantages\n#### Advantages\n1. Easy to implement\n2. Capture the importance of missing values\n\n#### Disadvantage\n3. Creating additional feature (Curse of Dimentionality)","4932ae3a":"## 3. If you have more frequent categories, we just replace NAN with a new category\n\n### Note: This is the most used technique","3ad15abd":"## 2. Adding a variable to capture nan","5cd54be1":"### Advantages of replacing nan with mode\n#### Advanatages\n1. Easy To implement\n2. Faster way to implement\n\n#### Disadvantages\n1. Since we are using the more frequent labels, it may use them in an over respresented way, if there are many nan's\n1. It distorts the relation of the most frequent label"}}