{"cell_type":{"b71fdc77":"code","5d0e188b":"code","404f8370":"code","97267b6c":"code","917df8ad":"code","720f252e":"code","3701a61c":"code","3c710958":"code","6ccc5469":"code","fe75756f":"code","cabc4a0a":"code","1fdd5ef5":"code","932d4f45":"code","ce2085e9":"code","641f3303":"code","9a27fc62":"markdown","0bb69dc3":"markdown","9c0697b2":"markdown","b765155b":"markdown","069ee53f":"markdown"},"source":{"b71fdc77":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5d0e188b":"train = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-sep-2021\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-sep-2021\/test.csv\")\nsubmission = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-sep-2021\/sample_solution.csv\")","404f8370":"train.head()","97267b6c":"test.head()","917df8ad":"def check(df):\n    col_list = train.columns.values\n    rows = []\n    for col in col_list:\n        tmp = (col,\n              train[col].dtype,\n              train[col].isnull().sum(),\n              train[col].count(),\n              train[col].nunique(),\n              train[col].unique())\n        rows.append(tmp)\n    df = pd.DataFrame(rows) \n    df.columns = ['feature','dtype','nan','count','nunique','unique']\n    return df\n\ncheck(train)","720f252e":"def check(df):\n    col_list = test.columns.values\n    rows = []\n    for col in col_list:\n        tmp = (col,\n              test[col].dtype,\n              test[col].isnull().sum(),\n              test[col].count(),\n              test[col].nunique(),\n              test[col].unique())\n        rows.append(tmp)\n    df = pd.DataFrame(rows) \n    df.columns = ['feature','dtype','nan','count','nunique','unique']\n    return df\n\ncheck(test)","3701a61c":"train.claim.hist()","3c710958":"total_cell = np.product(train.shape)\nmissing_values_count = train.isnull().sum()\ntotal_missing = missing_values_count.sum()\npercent_missing = (total_missing \/ total_cell)* 100\n\nprint(percent_missing, \" % missing\")","6ccc5469":"from sklearn.preprocessing import StandardScaler\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\nfrom lightgbm import LGBMRegressor\nimport lightgbm as lgb","fe75756f":"from sklearn.model_selection import KFold\n\ntrain[\"kfold\"] = -1\nkf = KFold(n_splits = 10, shuffle=True, random_state = 0)\nfor fold,(train_index, valid_index) in enumerate(kf.split(X = train)):\n    print(fold,train_index, valid_index)\n    train.loc[valid_index, \"kfold\"] = fold\ntrain.kfold.value_counts()","cabc4a0a":"useful = [col for col in train.columns if col not in ('id','claim','kfold')]\ntest = test[useful]","1fdd5ef5":"param = {      \n        \"objective\": \"binary\",\n        \"metric\": \"auc\",\n        \"verbosity\": -1,\n        \"boosting_type\": \"gbdt\",\n        \"device\": \"gpu\",\n        \"gpu_platform_id\": 0,\n        \"gpu_device_id\": 0,\n        \"n_estimators\" : 1000,\n        \"early_stopping_rounds\" : 10,\n    \n        \"feature_fraction\" : 1.0,\n        \"num_leaves\" : 94,\n        \"bagging_fraction\": 0.6737009142690187,\n        \"bagging_freq\": 1,\n        \"lambda_l1\": 5.559056252126386, \n        \"lambda_l2\": 9.77312118560801,\n        \"min_child_samples\" : 50\n     }","932d4f45":"score = []\ntest_pred = []\nvalid_pred = {}\nfor fold in range(10):\n    \n    X_train = train[train.kfold != fold].reset_index(drop = True)\n    X_valid = train[train.kfold == fold].reset_index(drop = True)\n    \n    X_test = test.copy()\n    valid_ids = X_valid.id.values.tolist()\n    \n    y_train = X_train.claim\n    y_valid = X_valid.claim\n    \n    X_train = X_train[useful]\n    X_valid = X_valid[useful]\n    \n    feature = list(X_train.columns[1:])\n    \n    X_train['n_missing'] = X_train[feature].isna().sum(axis = 1)\n    X_train['std'] = X_train[feature].std(axis = 1)\n    X_train['mean'] = X_train[feature].mean(axis = 1)\n    X_train['median'] = X_train[feature].mean(axis = 1)\n    X_train['kurt'] = X_train[feature].kurtosis(axis = 1)\n\n    X_valid['n_missing'] = X_valid[feature].isna().sum(axis = 1)\n    X_valid['std'] = X_valid[feature].std(axis = 1)\n    X_valid['mean'] = X_valid[feature].mean(axis = 1)\n    X_valid['median'] = X_valid[feature].mean(axis = 1)\n    X_valid['kurt'] = X_valid[feature].kurtosis(axis = 1)\n\n    X_test['n_missing'] = X_test[feature].isna().sum(axis = 1)\n    X_test['std'] = X_test[feature].std(axis = 1)\n    X_test['mean'] = X_test[feature].mean(axis = 1)\n    X_test['median'] = X_train[feature].mean(axis = 1)\n    X_test['kurt'] = X_test[feature].kurtosis(axis = 1)\n    \n    feature += ['n_missing','std','mean','median','kurt']\n    X_train[feature] = X_train[feature].fillna(X_train[feature].mean())\n    X_valid[feature] = X_valid[feature].fillna(X_valid[feature].mean())\n    X_test[feature] = X_test[feature].fillna(X_test[feature].mean())\n    \n    scaler= StandardScaler()\n    X_train = pd.DataFrame(scaler.fit_transform(X_train))\n    X_valid = pd.DataFrame(scaler.transform(X_valid))\n    X_test = pd.DataFrame(scaler.transform(X_test))\n                                \n    lgb_train = lgb.Dataset(X_train, y_train)\n    lgb_valid = lgb.Dataset(X_valid, y_valid,reference = lgb.train)\n    \n    model = LGBMRegressor()\n    model = lgb.train(param,   lgb_train, valid_sets = [lgb_valid],verbose_eval = 100)\n                   \n    pred_valid = model.predict(X_valid)\n    valid_pred.update(dict(zip(valid_ids, pred_valid)))\n    test_preds = model.predict(X_test)\n    test_pred.append(test_preds)\n    \n    auc = roc_auc_score(y_valid, pred_valid)\n    print(fold,auc)\n    score.append(auc)\n    \nprint(score)","ce2085e9":"valid_prediction = pd.DataFrame.from_dict(valid_pred, orient = \"index\").reset_index()\nvalid_prediction.columns = ['id', 'pred_23']\nvalid_prediction.to_csv(\"valid_pred_23.csv\", index = False)","641f3303":"submission['claim'] = np.mean(np.column_stack(test_pred), axis = 1)\nsubmission.to_csv(\"submission.csv\", index = False)","9a27fc62":"I hope this will help.","0bb69dc3":"10 splits is better than 5","9c0697b2":"* I tried SimpleImputing, StandardScalaer, RobustScaler, QuantileTransform, and pipeline.\n* StandardScaler is better than other preprocessing.\n* add the train's colums \"Std\", \"mean\", \"median\", \"kurt\" is much better.","b765155b":"* Use oputna.integration.lightgbm\n* import optuna.integration.lightgbm as lgb\n* Choose the best params.(It took a lot of time to find the best params this competition)","069ee53f":"--------------------"}}