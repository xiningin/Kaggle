{"cell_type":{"5027b77d":"code","1b9f8e16":"code","1d2fa115":"code","df6417d7":"code","21d5b555":"code","5fda8867":"code","144b298a":"code","1bf785a1":"code","1f7d1b40":"code","20d04441":"code","9f1d69aa":"code","f52a12e8":"markdown","7b84c72d":"markdown","a97ac90f":"markdown"},"source":{"5027b77d":"import os\nimport numpy as np\nimport pandas as pd\nimport scipy.io\nimport matplotlib.pyplot as plt\n\n# keras\nfrom keras.models import Model, load_model\nfrom keras.layers import Input\nfrom keras.layers.core import Dropout, Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras import backend as K\n\nimport tensorflow as tf","1b9f8e16":"# Settings\ninput_path = os.path.join('..', 'input', '2015_boe_chiu', '2015_BOE_Chiu')\nsubject_path = [os.path.join(input_path, 'Subject_0{}.mat'.format(i)) for i in range(1, 10)] + [os.path.join(input_path, 'Subject_10.mat')]\n\ndata_indexes = [10, 15, 20, 25, 28, 30, 32, 35, 40, 45, 50]\n\nwidth = 768\nheight = 496","1d2fa115":"mat = scipy.io.loadmat(subject_path[0])\nimg_tensor = mat['images']\nmanual_fluid_tensor_1 = mat['manualFluid1']\n\nimg_array = np.transpose(img_tensor, (2, 0, 1))\nmanual_fluid_array = np.transpose(manual_fluid_tensor_1, (2, 0, 1))","df6417d7":"plt.imshow(img_array[25])","21d5b555":"plt.imshow(manual_fluid_array[25])","5fda8867":"def thresh(x):\n    if x == 0:\n        return 0\n    else:\n        return 1\n\nthresh = np.vectorize(thresh, otypes=[np.float])\n\ndef create_dataset(paths):\n    x = []\n    y = []\n    \n    for path in paths:\n        mat = scipy.io.loadmat(path)\n        img_tensor = mat['images']\n        fluid_tensor = mat['manualFluid1']\n        \n        img_array = np.transpose(img_tensor, (2, 0 ,1)) \/ 255\n        fluid_array = np.transpose(fluid_tensor, (2, 0 ,1))\n        fluid_array = thresh(fluid_array)\n        \n        for idx in data_indexes:\n            x += [np.expand_dims(img_array[idx], 2)]\n            y += [np.expand_dims(fluid_array[idx], 2)]\n        \n    return np.array(x), np.array(y)\n\nx_train, y_train = create_dataset(subject_path[:9])\nx_val, y_val = create_dataset(subject_path[9:])","144b298a":"# CNN model\ndef mean_iou(y_true, y_pred):\n    prec = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        y_pred_ = tf.to_int32(y_pred > t)\n        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n        K.get_session().run(tf.local_variables_initializer())\n        with tf.control_dependencies([up_opt]):\n            score = tf.identity(score)\n        prec.append(score)\n    return K.mean(K.stack(prec), axis=0)\n\ninputs = Input((height, width, 1))\n\nc1_1 = Conv2D(8, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(inputs)\nc1_2 = Conv2D(8, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c1_1)\np1 = MaxPooling2D((2, 2))(c1_2)\n\nc2_1 = Conv2D(12, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(p1)\nc2_2 = Conv2D(12, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c2_1)\np2 = MaxPooling2D((2, 2))(c2_2)\n\nc3_1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(p2)\nc3_2 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c3_1)\np3 = MaxPooling2D((2, 2))(c3_2)\n\nc4_1 = Conv2D(24, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(p3)\nc4_2 = Conv2D(24, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c4_1)\np4 = MaxPooling2D((2, 2))(c4_2)\n\nc5_1 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(p4)\nc5_2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c5_1)\n\nc6_t = Conv2DTranspose(24, (2, 2), strides=(2, 2), padding='same') (c5_2)\nc6_c = concatenate([c6_t, c4_2])\nc6_1 = Conv2D(24, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c6_c)\nc6_2 = Conv2D(24, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c6_1)\n\nc7_t = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c6_2)\nc7_c = concatenate([c7_t, c3_2])\nc7_1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c7_c)\nc7_2 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c7_1)\n\nc8_t = Conv2DTranspose(12, (2, 2), strides=(2, 2), padding='same') (c7_2)\nc8_c = concatenate([c8_t, c2_2])\nc8_1 = Conv2D(12, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c8_c)\nc8_2 = Conv2D(12, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c8_1)\n\nc9_t = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8_2)\nc9_c = concatenate([c9_t, c1_2])\nc9_1 = Conv2D(8, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c9_c)\nc9_2 = Conv2D(8, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c9_1)\n\noutputs = Conv2D(1, (1, 1), activation='sigmoid') (c9_2)\n\nmodel = Model(inputs=[inputs], outputs=[outputs])\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\nmodel.summary()","1bf785a1":"results = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=11, epochs=10)","1f7d1b40":"pred = model.predict(x_val)","20d04441":"pred = (pred > 0.5).astype(np.uint8)","9f1d69aa":"# prediction visualization\nnrows = 6\nfig, axes = plt.subplots(nrows=nrows, ncols=3, figsize=(15, 10))\nfor i in range(nrows):\n    axes[i][0].imshow(np.reshape(x_val[2*i], (496, 768)), cmap='Greys_r')\n    axes[i][1].imshow(np.reshape(y_val[2*i], (496, 768)), cmap='Greys_r')\n    axes[i][2].imshow(np.reshape(pred[2*i], (496, 768)), cmap='Greys_r')\n\nplt.show()","f52a12e8":"## Data visualization","7b84c72d":"## Segmentation net training","a97ac90f":"# OCT Segmentation\nThis is a small segmentation tutorial on OCT images.\n\nThe U-net model implementation comes from this kernel : https:\/\/www.kaggle.com\/keegil\/keras-u-net-starter-lb-0-277"}}