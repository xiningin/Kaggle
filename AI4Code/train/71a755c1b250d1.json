{"cell_type":{"64a2039d":"code","6fdf55fd":"code","7c68ac73":"code","4c545424":"code","49238036":"code","2bd6303f":"code","f8d30b0d":"code","62d5d3ae":"code","9991d809":"code","0cf7b2f0":"code","a1262b91":"code","040aca47":"code","f340be8f":"code","bbb65d09":"code","9a44dd69":"code","763d215f":"code","b741db28":"code","48527c6b":"code","0136ce39":"code","0fb073a9":"code","05f36282":"code","36bb8a72":"code","897a626c":"code","aac7a486":"code","64f6e136":"code","8df128dd":"code","78404313":"code","4db148f6":"code","6475798e":"code","c82f3e34":"code","ac05ca6d":"code","19730f1f":"code","7a04c23d":"code","8215c0e8":"code","1551e05c":"code","1523e03d":"code","f0991276":"code","d75b790f":"code","cb4603dc":"code","e55bf3da":"code","bd24ecea":"code","f52d6727":"code","20a28cc0":"code","26f8d102":"code","2d70e63f":"code","e252a02f":"code","5ebb1efc":"code","6236e2d2":"code","424b7148":"code","9819716a":"code","cfc5e158":"code","28807a17":"code","85c86dc6":"code","ef4866e2":"code","0d7bd7e0":"code","dadac192":"code","6bb81f00":"code","91450c7d":"code","494d4e0a":"code","30df9ab5":"code","3b60ddb4":"code","a9b5835d":"code","4aca6216":"code","55bdb896":"code","53464ffb":"code","f87b5b24":"code","333c82d8":"code","a936b61d":"code","195992f9":"code","2668d206":"code","9867096a":"code","6f17b17a":"code","e86305fd":"code","736f12ad":"code","6a7db7f5":"code","5b3c0b75":"code","d5bdf057":"code","f9d79d77":"code","e06f2fd2":"code","59bb0b09":"code","f6a21ac1":"code","b16131d1":"code","3925c594":"code","e0fbe2cb":"code","e0e6b21d":"code","4a29816b":"code","58dbc45d":"code","f1620564":"code","72c8f2a3":"code","a25a9540":"code","b1e4a81c":"code","ff7c5284":"code","6150d1b9":"code","9fdeb93c":"code","e4ea5179":"code","1942d3a8":"code","5c49484c":"code","1539217f":"code","24609b1e":"code","27d696ec":"code","4ac8b605":"code","575a1fb3":"code","1190ed2a":"code","7afef498":"code","037836e9":"code","bdba6c8e":"code","0f01c49f":"code","80ce9583":"code","ee25b518":"code","4de0c593":"code","08339822":"code","87935924":"code","d3bf76ed":"code","98e1d056":"code","cbe70e12":"code","a67aea0b":"code","4f501746":"code","a5caf836":"code","94bfcad4":"code","e25715f6":"code","b3a7c12c":"code","589de780":"code","486a625a":"code","965ff117":"code","acd03e65":"code","990b3004":"code","a62adb48":"code","3af77b2b":"code","442268c7":"code","11e9d297":"code","98d8459b":"code","11c03c5d":"code","6dd7dbcf":"code","ab6e703a":"code","06532d1f":"code","174114f0":"code","37b3cc7c":"code","b0cd9df4":"code","93df0d27":"code","f32b8f21":"code","16147373":"code","b10f2b52":"code","f909a33f":"code","11955597":"code","1e6438d8":"code","7acfbe74":"code","3ad83149":"code","e71947dc":"code","524a71c8":"code","bfcfd6ba":"code","9a9e167f":"code","d8ae3d79":"code","ca8e6233":"code","f8e1fd55":"code","d1bb08dc":"code","76e0013e":"code","cd11225a":"code","4f1f784b":"code","9bec9001":"code","b3b7da03":"code","518b475c":"code","da6e38cf":"code","c6d8f59c":"code","8671feb0":"code","9747e6cd":"code","c9b7c010":"code","461520d9":"code","f7d6f3f2":"code","99e05afe":"code","97767ac8":"code","673c9430":"code","bf66aeb5":"code","385c2bef":"code","673c41d2":"code","b806bde9":"code","4fc79b92":"code","5ff5d016":"code","91c7dd85":"code","91d16078":"code","ae242078":"code","8e95f02a":"code","66382a32":"code","d2f901f6":"code","ca759bbb":"code","0c9807a2":"code","0b9f7e85":"code","e0d359ad":"code","577a0fcb":"code","1ccc488a":"code","f808c1cd":"code","44bb4416":"code","0064c4ee":"code","54aa5053":"code","65ba34d2":"code","b0aca73d":"code","d04613c7":"code","a4200f71":"code","a3f88fca":"code","433a00ad":"code","79604580":"code","90c002cd":"code","290de2e6":"code","6b5048fd":"code","2aa5657b":"code","69d8ee84":"markdown","c9ca1ed3":"markdown","00331a1d":"markdown","980d44da":"markdown","5585f1e1":"markdown","b673b6f3":"markdown","67586d89":"markdown","db0fe963":"markdown","c31b97a5":"markdown","7e52e03a":"markdown","9d81bc08":"markdown","d8380815":"markdown","02422808":"markdown","1aae9922":"markdown","d11e69ca":"markdown","159c9d36":"markdown","f6485890":"markdown","44bbcb9f":"markdown","4441ee72":"markdown","98c08476":"markdown","32b153e9":"markdown","16d45799":"markdown","73ce8917":"markdown","9b4e778e":"markdown","627a28ad":"markdown","6295b9fc":"markdown","9cd7b3a2":"markdown","efc11006":"markdown","388d430d":"markdown","decbbf67":"markdown","428b48cf":"markdown","d2c14b57":"markdown","86ec9575":"markdown","f9ac673a":"markdown","d8ed08dc":"markdown","20c198a3":"markdown","65ab6923":"markdown","057aa9e0":"markdown","4c1b2d22":"markdown","a83341a5":"markdown","9b6e5d60":"markdown","2c09a847":"markdown","c02e2b42":"markdown","eab0a06c":"markdown","9fe8dd45":"markdown","98aa3d49":"markdown","f7cffabc":"markdown","5767e01f":"markdown","88273eee":"markdown","c662d523":"markdown","f3727cc1":"markdown","4de93f9c":"markdown","383895b2":"markdown","34dec812":"markdown","f0f7f10f":"markdown","b7e98cc0":"markdown","a38167a2":"markdown","245f16d6":"markdown","1cd87a0c":"markdown","9e6c81be":"markdown","f2ede06d":"markdown","3af10ba1":"markdown","b0db1dfc":"markdown","cc7af2a6":"markdown","12892dbe":"markdown","8bcacbaa":"markdown","04346f11":"markdown","856869d4":"markdown","6fed7e88":"markdown","a7e19a57":"markdown","f1347aa5":"markdown","5383651f":"markdown","0bfed24d":"markdown","a09ee30a":"markdown","6c526d90":"markdown","263d9187":"markdown"},"source":{"64a2039d":"import os\nimport pandas as pd","6fdf55fd":"path = \"..\/input\/heart-disease-uci\/\"","7c68ac73":"df = pd.read_csv(os.path.join(path,'heart.csv'))","4c545424":"df.head()","49238036":"df.shape","2bd6303f":"df.describe()","f8d30b0d":"df.info()","62d5d3ae":"## Plotting a heatmap to observe correlation \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np","9991d809":"corr = df.corr()","0cf7b2f0":"fig, ax = plt.subplots(figsize = (8,8))\nsns.heatmap(corr, ax= ax, linewidth = 0.1 );","a1262b91":"df['cp'].value_counts()","040aca47":"df['trestbps'].describe()","f340be8f":"df['chol'].describe()","bbb65d09":"df['fbs'].describe()","9a44dd69":"df['restecg'].describe()","763d215f":"df['thalach'].describe()","b741db28":"df['exang'].describe()","48527c6b":"df['oldpeak'].describe()","0136ce39":"df['slope'].describe()","0fb073a9":"df['ca'].describe()","05f36282":"df['thal'].describe()","36bb8a72":"df['target'].describe()","897a626c":"df.describe()","aac7a486":"## Quickly checking on 'Chol'","64f6e136":"plt.figure(figsize = (10,5))\nsns.boxplot(x = 'chol', data = df);","8df128dd":"## let's clone our dataset\n\nxdf = df.copy()","78404313":"## Lets clean the dataset","4db148f6":"Q1 = xdf['chol'].quantile(0.25)\nQ3 = xdf['chol'].quantile(0.75)\n\nIQR = Q3 - Q1\nmin = Q1 - 1.5 * IQR\nmax = Q3 + 1.5 * IQR","6475798e":"filter = (xdf['chol'] >= min) & (xdf['chol'] <= max)\ninit_size = xdf.count()['chol']\nxdf = xdf.loc[filter]\nfiltered_size = xdf.count()['chol']\nprint(init_size - filtered_size, '(', '{:.2f}'.format(100 * (init_size - filtered_size) \/ init_size), '%', ')', 'outliers removed from dataset')","c82f3e34":"plt.figure(figsize = (10,5))\nsns.boxplot(x = 'chol', data = xdf);","ac05ca6d":"fig, ax = plt.subplots(figsize = (12,12))\nsns.heatmap(corr, ax= ax, annot = True, linewidth = 0.1 );","19730f1f":"df.shape","7a04c23d":"## Since it has less features we will not drop any featuers ","8215c0e8":"xdf.shape","1551e05c":"df.isnull().sum()","1523e03d":"dfvis = df.copy()","f0991276":"## Sex\n\nfor i in dfvis['sex']:\n    if i==0:\n        dfvis['sex'] = dfvis['sex'].replace(0, \"female\")\n    else:\n        dfvis['sex'] = dfvis['sex'].replace(1, \"male\")\n","d75b790f":"## Cp\n\nfor i in dfvis['cp']:\n    if i==0:\n        dfvis['cp'] = dfvis['cp'].replace(0, \"asymptomatic\")\n    elif i==1:\n        dfvis['cp'] = dfvis['cp'].replace(1,\"typical-angina\")\n    elif i==2:\n        dfvis['cp'] = dfvis['cp'].replace(2,'atypical-angina')\n    else:\n        dfvis['cp'] = dfvis['cp'].replace(3,'non-anginal_pain')","cb4603dc":"## fbs\n\nfor i in dfvis['fbs']:\n    if i==0:\n        dfvis['fbs'] = dfvis['fbs'].replace(0, \"false\")\n    else:\n        dfvis['fbs'] = dfvis['fbs'].replace(1, \"true\")","e55bf3da":"## restecg\n\nfor i in dfvis['restecg']:\n    if i==0:\n        dfvis['restecg'] = dfvis['restecg'].replace(0, \"false\")\n    else:\n        dfvis['restecg'] = dfvis['restecg'].replace(1, \"true\")","bd24ecea":"## exang\n\nfor i in dfvis['exang']:\n    if i==0:\n        dfvis['exang'] = dfvis['exang'].replace(0, \"false\")\n    else:\n        dfvis['exang'] = dfvis['exang'].replace(1, \"true\")","f52d6727":"## slope\n\nfor i in dfvis['slope']:\n    if i==0:\n        dfvis['slope'] = dfvis['slope'].replace(0, \"down\")\n    elif i==1:\n        dfvis['slope'] = dfvis['slope'].replace(1, \"flat\")\n    else:\n        dfvis['slope'] = dfvis['slope'].replace(2, \"up\")","20a28cc0":"## thal\n\nfor i in dfvis['thal']:\n    if i==0:\n        dfvis['thal'] = dfvis['thal'].replace(0, 2)\n    elif i==1:\n        dfvis['thal'] = dfvis['thal'].replace(1, \"fixed_defect\")\n    elif i==2:\n        dfvis['thal'] = dfvis['thal'].replace(2, \"normal\")\n    else:\n        dfvis['thal'] = dfvis['thal'].replace(3, \"reversible_defect\")","26f8d102":"## target\n\nfor i in dfvis['target']:\n    if i==0:\n        dfvis['target'] = dfvis['target'].replace(0, \"no\")\n    else:\n        dfvis['target'] = dfvis['target'].replace(1, \"yes\")","2d70e63f":"## target\n","e252a02f":"dfvis.head()","5ebb1efc":"sns.displot(x = 'age', data = dfvis,aspect = 1, height = 7);","6236e2d2":"sns.displot(x = 'age', data = dfvis,hue = 'target', multiple=\"stack\", aspect = 1, height = 7);","424b7148":"plt.figure(figsize = (8,8))\nsns.boxplot(y = 'age',x='target',  data = dfvis);","9819716a":"plt.figure(figsize = (8,8))\nsns.boxplot(y = 'age',x='target',hue = 'sex',  data = dfvis);","cfc5e158":"plt.figure(figsize = (8,8))\nsns.countplot(x = 'sex', data = dfvis);","28807a17":"plt.figure(figsize = (8,8))\nsns.countplot(x = 'sex', hue = 'target',data = dfvis);","85c86dc6":"dfvis['sex'].shape","ef4866e2":"malecount = 0\nfor i in dfvis['sex']:\n    if i==\"male\":\n        malecount = malecount + 1","0d7bd7e0":"print(\"There are:\", malecount, \" number of males which is : {:.2f} %\".format((malecount\/303)*100))","dadac192":"femalecount = 0\nfor i in dfvis['sex']:\n    if i==\"female\":\n        femalecount = femalecount + 1","6bb81f00":"print(\"There are : {} total number of females which is : {:.2f}% \".format(femalecount, ((femalecount)\/303)* 100))","91450c7d":"dfvis['cp'].value_counts()","494d4e0a":"plt.figure(figsize = (8,8))\nsns.countplot(x = 'cp', data = dfvis);","30df9ab5":"plt.figure(figsize = (8,8))\nsns.countplot(x = 'cp', hue = 'target',data = dfvis);","3b60ddb4":"sns.catplot(y = 'age', x='cp',hue = 'target',  data = dfvis, aspect = 1, height = 7);","a9b5835d":"sns.displot(x = 'trestbps', data = dfvis, aspect = 1, height = 7);","4aca6216":"plt.figure(figsize = (8,8))\nsns.scatterplot(x = 'age', y = 'trestbps',hue = 'target',data = dfvis);","55bdb896":"sns.displot(x = 'trestbps', data = dfvis, hue= 'target', kind = 'kde',aspect = 1, height = 7);","53464ffb":"plt.figure(figsize = (8,8))\nsns.boxplot(y = 'trestbps',x='target', hue = 'sex', data = dfvis);","f87b5b24":"sns.catplot(y = 'trestbps', x='target',hue = 'sex',  data = dfvis, aspect = 1, height = 7);","333c82d8":"sns.displot(x = 'chol', data = dfvis, hue= 'target', kind = 'kde',aspect = 1, height = 7);","a936b61d":"plt.figure(figsize = (8,8))\nsns.scatterplot(x = 'age', y = 'chol',hue = 'target',data = dfvis);","195992f9":"plt.figure(figsize = (8,8))\nsns.boxplot(y = 'chol',x='target',hue = 'sex',  data = dfvis);","2668d206":"sns.catplot(y = 'chol', x='target',hue = 'sex',  data = dfvis, aspect = 1, height = 7);","9867096a":"dfvis['fbs'].value_counts()","6f17b17a":"plt.figure(figsize = (8,8))\nsns.boxplot(y = 'age',x='target',hue = 'fbs',  data = dfvis);","e86305fd":"sns.catplot(y = 'age', x='fbs',hue = 'target',  data = dfvis, aspect = 1, height = 7);","736f12ad":"sns.displot(x = 'thalach', data = dfvis, hue= 'target', kind = 'kde',aspect = 1, height = 7);","6a7db7f5":"plt.figure(figsize = (8,8))\nsns.boxplot(y = 'thalach', x='target',hue = 'sex',  data = dfvis);","5b3c0b75":"sns.catplot(y = 'thalach', x='target',hue = 'sex',  data = dfvis, aspect = 1, height = 7);","d5bdf057":"dfvis['slope'].value_counts()","f9d79d77":"sns.catplot(y = 'age', x='slope',hue = 'target',  data = dfvis, aspect = 1, height = 7);","e06f2fd2":"from sklearn.model_selection import train_test_split","59bb0b09":"## Splitting original dataset (df) without normalization\n\nX_train, X_test, y_train, y_test = train_test_split(df.drop('target', axis = 1), df['target'], test_size = 0.30, random_state = 42)","f6a21ac1":"## Original Data (df) with normalizing\nX_train2, X_test2, y_train2, y_test2 = train_test_split(df.drop('target', axis = 1), df['target'], test_size = 0.30, random_state = 42)","b16131d1":"## Outliers removed dataset (xdf) with normalization\nX_train3, X_test3, y_train3, y_test3 = train_test_split(xdf.drop('target', axis = 1), xdf['target'], test_size = 0.30, random_state = 42)","3925c594":"from sklearn.preprocessing import StandardScaler","e0fbe2cb":"sc = StandardScaler()","e0e6b21d":"X_train2 = sc.fit_transform(X_train2)\nX_test2 = sc.fit_transform(X_test2)\n\nX_train3 = sc.fit_transform(X_train3)\nX_test3 = sc.fit_transform(X_test3)\n","4a29816b":"model_score = pd.DataFrame(columns = (\"df\",\"df_norm\",\"xdf_norm\"))","58dbc45d":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix","f1620564":"lrmodel = LogisticRegression(max_iter = 1000)","72c8f2a3":"lrmodel.fit(X_train, y_train)","a25a9540":"lrmodel.score(X_test, y_test)","b1e4a81c":"lrscore1 = lrmodel.score(X_test, y_test)","ff7c5284":"y_pred = lrmodel.predict(X_test)","6150d1b9":"cm = confusion_matrix(y_test, y_pred)","9fdeb93c":"print(\"Confusion Matrix: \\n\", cm)","e4ea5179":"print(classification_report(y_test, y_pred))","1942d3a8":"lrmodel2 = LogisticRegression(max_iter = 1000)","5c49484c":"lrmodel2.fit(X_train2, y_train2)","1539217f":"lrmodel2.score(X_test2, y_test2)","24609b1e":"scorelr2 =  lrmodel2.score(X_test2, y_test2)","27d696ec":"#### Confusion matrix for Dataset","4ac8b605":"y_pred2 = lrmodel2.predict(X_test2)","575a1fb3":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test2, y_pred2)","1190ed2a":"print(\"Confusion Matrix: \\n\", cm)","7afef498":"print(classification_report(y_test2, y_pred2))","037836e9":"lrmodel3 = LogisticRegression(max_iter = 1000)","bdba6c8e":"lrmodel3.fit(X_train3, y_train3)","0f01c49f":"lrmodel3.score(X_test3, y_test3)","80ce9583":"y_pred3 = lrmodel3.predict(X_test3)","ee25b518":"cm = confusion_matrix(y_test3, y_pred3)","4de0c593":"print(\"Confusion Matrix: \\n\", cm)","08339822":"print(classification_report(y_test3, y_pred3))","87935924":"model_score = model_score.append(pd.DataFrame({'df':[lrmodel.score(X_test,y_test)],'df_norm':[lrmodel2.score(X_test2,y_test2)], 'xdf_norm':[lrmodel3.score(X_test3, y_test3)]}, index = ['Logistic Regression']))","d3bf76ed":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix","98e1d056":"naiveb = GaussianNB()","cbe70e12":"naiveb.fit(X_train, y_train)","a67aea0b":"naiveb.score(X_test, y_test)","4f501746":"naiveb2 = GaussianNB()","a5caf836":"naiveb2.fit(X_train2, y_train2)","94bfcad4":"naiveb2.score(X_test2, y_test2)","e25715f6":"naiveb3 = GaussianNB()","b3a7c12c":"naiveb3.fit(X_train3, y_train3)","589de780":"naiveb3.score(X_test3, y_test3)","486a625a":"model_score = model_score.append(pd.DataFrame({'df':[naiveb.score(X_test,y_test)],'df_norm':[naiveb2.score(X_test2,y_test2)], 'xdf_norm':[naiveb3.score(X_test3, y_test3)]}, index = ['Naive Bayes']))","965ff117":"from sklearn.neighbors import KNeighborsClassifier\nimport numpy as np","acd03e65":"knn = KNeighborsClassifier(n_neighbors = 7)","990b3004":"knn.fit(X_train, y_train)","a62adb48":"knn.score(X_test, y_test)","3af77b2b":"knn_pred = knn.predict(X_test)","442268c7":"print(\"Confusion Matrix: \\n\",confusion_matrix(y_test, knn_pred))","11e9d297":"error_rate = []\n\nfor i in range(1,40):\n    knn = KNeighborsClassifier(n_neighbors = i)\n    knn.fit(X_train,y_train)\n    pred_knn = knn.predict(X_test)\n    error_rate.append(np.mean(pred_knn != y_test))","98d8459b":"plt.figure(figsize = (8,8))\nplt.plot(range(1,40), error_rate, color = 'blue', linestyle = 'dashed', marker = 'o', markerfacecolor = 'red', markersize = 10);\nplt.title('Error Rate vs K Value')\nplt.xlabel('K')\nplt.ylabel('Error Rate')","11c03c5d":"## let's chose the k-value\n\nknn = KNeighborsClassifier(n_neighbors = 21)\nknn.fit(X_train, y_train)\npred_knn = knn.predict(X_test)\nprint(knn.score(X_test, y_test))\n\nprint(\"\\n With k = 21\")\nprint('\\n')\nprint(\"Confusion Matrix: \\n\", confusion_matrix(y_test, pred_knn))\nprint('\\n')\nprint(classification_report(y_test,pred_knn))\n","6dd7dbcf":"knn2 = KNeighborsClassifier(n_neighbors = 7)","ab6e703a":"knn2.fit(X_train2, y_train2)","06532d1f":"knn2.score(X_test2, y_test2)","174114f0":"knn_pred2 = knn2.predict(X_test2)","37b3cc7c":"print(\"Confusion Matrix: \\n\",confusion_matrix(y_test2, knn_pred2))","b0cd9df4":"error_rate = []\n\nfor i in range(1,40):\n    knn2 = KNeighborsClassifier(n_neighbors = i)\n    knn2.fit(X_train2,y_train2)\n    pred_knn2 = knn2.predict(X_test2)\n    error_rate.append(np.mean(pred_knn2 != y_test2))","93df0d27":"plt.figure(figsize = (8,8))\nplt.plot(range(1,40), error_rate, color = 'blue', linestyle = 'dashed', marker = 'o', markerfacecolor = 'red', markersize = 10);\nplt.title('Error Rate vs K Value')\nplt.xlabel('K')\nplt.ylabel('Error Rate')","f32b8f21":"## let's chose the k-value\n\nknn2 = KNeighborsClassifier(n_neighbors = 21)\nknn2.fit(X_train2, y_train2)\npred_knn2 = knn2.predict(X_test2)\nprint(knn2.score(X_test2, y_test2))\n\nprint(\"\\n With k = 21\")\nprint('\\n')\nprint(\"Confusion Matrix: \\n\", confusion_matrix(y_test2, pred_knn2))\nprint('\\n')\nprint(classification_report(y_test2,pred_knn2))\n","16147373":"#### Outliers removed dataset after normalization","b10f2b52":"knn3 = KNeighborsClassifier(n_neighbors = 7)","f909a33f":"knn3.fit(X_train3, y_train3)","11955597":"knn3.score(X_test3, y_test3)","1e6438d8":"knn_pred3 = knn.predict(X_test3)","7acfbe74":"print(\"Confusion Matrix: \\n\",confusion_matrix(y_test3, knn_pred3))","3ad83149":"error_rate = []\n\nfor i in range(1,40):\n    knn3 = KNeighborsClassifier(n_neighbors = i)\n    knn3.fit(X_train3,y_train3)\n    pred_knn3 = knn3.predict(X_test3)\n    error_rate.append(np.mean(pred_knn3 != y_test3))","e71947dc":"plt.figure(figsize = (8,8))\nplt.plot(range(1,40), error_rate, color = 'blue', linestyle = 'dashed', marker = 'o', markerfacecolor = 'red', markersize = 10);\nplt.title('Error Rate vs K Value')\nplt.xlabel('K')\nplt.ylabel('Error Rate')","524a71c8":"## let's chose the k-value\n\nknn3 = KNeighborsClassifier(n_neighbors = 28)\nknn3.fit(X_train3, y_train3)\npred_knn3 = knn.predict(X_test3)\nprint(knn3.score(X_test3, y_test3))\n\nprint(\"\\n With k = 28\")\nprint('\\n')\nprint(\"Confusion Matrix: \\n\", confusion_matrix(y_test3, pred_knn3))\nprint('\\n')\nprint(classification_report(y_test3,pred_knn3))\n","bfcfd6ba":"model_score = model_score.append(pd.DataFrame({'df':[knn.score(X_test,y_test)],'df_norm':[knn2.score(X_test2,y_test2)], 'xdf_norm':[knn3.score(X_test3, y_test3)]}, index = ['KNN']))","9a9e167f":"from sklearn.tree import DecisionTreeClassifier","d8ae3d79":"dt = DecisionTreeClassifier()","ca8e6233":"dt = dt.fit(X_train, y_train)","f8e1fd55":"dt_pred = dt.predict(X_test)","d1bb08dc":"print(\"Accuracy:\", metrics.accuracy_score(y_test, dt_pred))","76e0013e":"dtcm = confusion_matrix(y_test, dt_pred)\nprint(\"Confusion Matrix: \\n\", dtcm)","cd11225a":"dt2 = DecisionTreeClassifier()","4f1f784b":"dt2 = dt.fit(X_train2, y_train2)","9bec9001":"dt2.score(X_test2, y_test2)","b3b7da03":"dt_pred2 = dt2.predict(X_test2)","518b475c":"dtcm = confusion_matrix(y_test2, dt_pred2)\nprint(\"Confusion Matrix: \\n\", dtcm)","da6e38cf":"dt3 = DecisionTreeClassifier()","c6d8f59c":"dt3 = dt3.fit(X_train3, y_train3)","8671feb0":"dt3.score(X_test3, y_test3)","9747e6cd":"dt_pred3 = dt.predict(X_test3)","c9b7c010":"dtcm = confusion_matrix(y_test3, dt_pred3)\nprint(\"Confusion Matrix: \\n\", dtcm)","461520d9":"model_score = model_score.append(pd.DataFrame({'df':[dt.score(X_test,y_test)],'df_norm':[dt2.score(X_test2,y_test2)], 'xdf_norm':[dt3.score(X_test3, y_test3)]}, index = ['Decision Trees']))","f7d6f3f2":"from sklearn.ensemble import RandomForestClassifier","99e05afe":"rfclf = RandomForestClassifier(n_estimators = 100)","97767ac8":"rfclf.fit(X_train, y_train)","673c9430":"rfclf.score(X_test, y_test)","bf66aeb5":"rf_pred = rfclf.predict(X_test)","385c2bef":"print(\"Confusion Matrix:\\n\",confusion_matrix(y_test, rf_pred))","673c41d2":"rfclf2 = RandomForestClassifier(n_estimators = 100)","b806bde9":"rfclf2 = RandomForestClassifier(n_estimators = 100)","4fc79b92":"rfclf2.fit(X_train2, y_train2)","5ff5d016":"rfclf2.score(X_test2, y_test2)","91c7dd85":"rf_pred = rfclf2.predict(X_test2)","91d16078":"print(\"Confusion Matrix:\\n\",confusion_matrix(y_test2, rf_pred))","ae242078":"rfclf3 = RandomForestClassifier(n_estimators = 100)","8e95f02a":"rfclf3 = RandomForestClassifier(n_estimators = 100)","66382a32":"rfclf3.fit(X_train3, y_train3)","d2f901f6":"rfclf3.score(X_test3, y_test3)","ca759bbb":"rf_pred = rfclf3.predict(X_test3)","0c9807a2":"print(\"Confusion Matrix:\\n\",confusion_matrix(y_test3, rf_pred))","0b9f7e85":"model_score = model_score.append(pd.DataFrame({'df':[rfclf.score(X_test,y_test)],'df_norm':[rfclf2.score(X_test2,y_test2)], 'xdf_norm':[rfclf3.score(X_test3, y_test3)]}, index = ['Random Forest']))","e0d359ad":"from sklearn import svm","577a0fcb":"clf_svm = svm.SVC(kernel='linear')","1ccc488a":"clf_svm.fit(X_train, y_train)","f808c1cd":"clf_svm.score(X_test, y_test)","44bb4416":"svm_pred = clf_svm.predict(X_test)","0064c4ee":"print(\"Confusion Matrix:\\n\",confusion_matrix(y_test, svm_pred))","54aa5053":"clf_svm2 = svm.SVC(kernel='linear')","65ba34d2":"clf_svm2.fit(X_train2, y_train2)","b0aca73d":"clf_svm2.score(X_test2, y_test2)","d04613c7":"svm_pred2 = clf_svm2.predict(X_test2)","a4200f71":"print(\"Confusion Matrix:\\n\",confusion_matrix(y_test2, svm_pred2))","a3f88fca":"clf_svm3 = svm.SVC(kernel='linear')","433a00ad":"clf_svm3.fit(X_train3, y_train3)","79604580":"clf_svm3.score(X_test3, y_test3)","90c002cd":"svm_pred3 = clf_svm3.predict(X_test3)","290de2e6":"print(\"Confusion Matrix:\\n\",confusion_matrix(y_test3, svm_pred3))","6b5048fd":"model_score = model_score.append(pd.DataFrame({'df':[clf_svm.score(X_test,y_test)],'df_norm':[clf_svm2.score(X_test2,y_test2)], 'xdf_norm':[clf_svm3.score(X_test3, y_test3)]}, index = ['SVM']))","2aa5657b":"model_score","69d8ee84":"Since Data Visulaization on numbers is difficult. We will replace all the numbers with labels. ","c9ca1ed3":"### Age","00331a1d":"#### Sorry it's taking more space ","980d44da":"### chol (Cholesterol)\n\nCholesterol is a type of fat found in your blood. Your liver makes cholesterol for your body. You also can get cholesterol from your foods you eat. \nWhen there is too much <b> cholesterol <\/b> in your blood, it builds up in the walls of your arteries, causing a process called <b> atherosclerosis, <\/b> a form of heart disease The person's cholesterol measurement in mg\/dl\n\n![fromverywellhealthcom.PNG](attachment:fromverywellhealthcom.PNG)","5585f1e1":"![fromheartorg.PNG](attachment:fromheartorg.PNG)","b673b6f3":"### 2.1 Treating Outliers","67586d89":"#### outliers removed data after norm","db0fe963":"## Naive Bayes","c31b97a5":"# Diagnosing Heart Disease\n\n\n\n## Contents:\n\n- <b>1. Read Dataset <\/b>\n    - Observing dataset\n-  <b> 2. Data Cleaning <\/b>\n    - 2.1 Outliers\n    - 2.2 Uncorrelated Columns\n    - 2.3 Filling null values\n- <b> 3. Data Visulatization\n- <b>4. Model Preparation <\/b>\n    - 4.1 Encoding categorical features\n    - 4.2 Normalization\n    - 4.3 Split training and testing set\n    \n- <b>5 Models and tuning <\/b>\n    - 5.1 Linear Regression\n    - 5.2 Lasso Regression\n    - 5.3 Multi-layer perceptron\n    - 5.4 K-Nearest Neighbor\n    - 5.5 Decision Tree\n    - 5.6 Random Forest\n    - 5.7 SVM\n  ","7e52e03a":"### slope \nthe slope of the peak exercise ST segment","9d81bc08":"Let's see it's relationship with <b> Target i.e Heart Disease <\/b>","d8380815":"### chol (cholestrol)","02422808":"### restecg (resting electrocardiogram)\n\nThe resting electrocardiogram is a test that measures the electrical activity of the heart. The heart is a muscular organ which pumps blood through rhythmic contractions induced by electric impulses generated by the sinus node, the heat's natural pacemaker.\n\nElectrocardiogram (ECG) to assess the heart rate and rhythm. This test can often detect heart disease, heart attack, an enlarged heart, or abnormal heart rhythms that may cause heart failure\n\n<b> ( 0 = normal, 1 = having ST-T wave abnormality, 2 = showing probable or definite left ventricular hypertrophy by Estes' criteria) ","1aae9922":"As we can from the above diagram:\n- <b> cp\n- thalach\n- slope\n- restecg <\/b>\n\nare the ones that are highly correlated. Anyway, let's reasearch more about the features and it roles for a Heart Disease.","d11e69ca":"### thalach (Maximum Heart Rate Achieved)","159c9d36":"target: yes = heart disease and no = no heart disease\n\n(which indicates that, there are more number of <b> Males <\/b> than <b> Females <\/b>. Also, more <b> Males <\/b> are victim of heart disease than <b> Females. <\/b>\n\nBut as compared to total number of <b> Males <\/b> , less number of <b> Males <\/b> has <b> Heart diseases <\/b>\n\nAlso, largest number of <b>Females <\/b> has heart disease overall, on the total of <b> Females. <\/b>\n","f6485890":"### thal ( Thalassemia)\n\nThalassemia is an inherited blood disorder that causes your body to have less hemoglobin than normal. Hemoglobin enables red blood cells to cary oxygen.\n\nHeart problems. Congestive heart failure and abnormal heart rhythms can be associated with severe thalassemia.\n\n- 0 (dataset): null\n- 1 (dataset): 6 = fixed defect \n- 2 (dataset): 3 = normal\n- 3 (dataset) 7 = reversable defect","44bbcb9f":"# 2. Data Cleaning\n    2.1 Outliers\n    2.2 Uncorrelated Columns\n    2.3 Filling null values","4441ee72":"As we can see, <b> atypical-angina <\/b> and <b>typical-angina <\/b> has the higher chance to cause heart disease.","98c08476":"### target \n\nHeart disease (0 = no, 1 = yes)","32b153e9":"### 2.2 Uncorrelated Columns\n\nSince there are less columns. We will not be dropping any columns. ","16d45799":"# 5. Models and tuning\n\nSince it is classification problem, we will test it with following algorithms\n- <b> Logistic Regression\n- Linear Regression\n- Naive Bayes\n- KNN \n- Decision Trees\n- Random Forest\n- SVM\n  \n    \nWe use <b> F1 Score, Precision, Recall, ROC Curve, Confusion Matrix <\/b> and <b> PR Curve <\/b> as the way to evaluate our models","73ce8917":"#### Outliers removed Dataset after Norm","9b4e778e":"### Sex\n\n(0 = Female, 1 = Male)","627a28ad":"### exang (Exercise induced angina) \n\nAngina is a type of pain that occurs when not enough blood flows to the heart muscle. Angina may feel like pressure in the chest, jaw or arm. It frequently may occur with exercise or stress.\n<b> (1 = Yes; 0 = no) <\/b>","6295b9fc":"### thalach (Maximum Heart Rate Achieved)","9cd7b3a2":"### 2.1 Filling missing values ","efc11006":"As we can see there is one or more outlier, but it's not huge. Since our dataset is so small, it will not make any huge difference. \nEven though, to satisfy my curiosity I am going to train the model with both the dataset, with and without outlier.","388d430d":"#### Original dataset (after norm) (X_train2)","decbbf67":"We can clearly see, \n- <b> Logistic Regression <\/b> : has higher accuracy after normalization *xdf_norm*\n- <b> Naive Bayes <\/b> : has higher accuracy before normalization *df*\n- <b> KNN <\/b> : has higher accuracy after normalization *xdf_norm*\n- <b> Decision Trees <\/b> : has higher accuracy has higher accuracy after normalization\n- <b> Random Forest <\/b> : higher accuracy after normalization\n- <b> SVM <\/b> : higher accuracy before normalization","428b48cf":"#### With original dataset before norm(df)","d2c14b57":"- <b> xdf : <\/b> The dataset will clean all outliers\n- <b> df : <\/b> This dataset is with the outliers.","86ec9575":"<b> Checking its relation with Target","f9ac673a":"#### Normalization dataset (xdf) (after norm)","d8ed08dc":"## Decision Tree","20c198a3":"#### Original Data \n\nOriginal Data (df) with normalizing i.e X_train2","65ab6923":"### We know\n\n- <b> df = original dataset (without norm and without removing outliers)\n- df_norm = original dataset without removing outliers with normalization\n- xdf_norm = dataset after removing outliers and normalization\n","057aa9e0":".","4c1b2d22":"### 4.2 Split training and testing","a83341a5":"#### With original Dataset","9b6e5d60":"### trestbps (Resting blood pressure)","2c09a847":"### fbs (fasting blood sugar)","c02e2b42":"#### original data","eab0a06c":"### slope \n\nthe slope of the peak exercise ST segment (Value 1: upsloping, Value 2: flat, Value 3: downsloping)","9fe8dd45":"### CP (Chest Pain): \n\nSince there are four type of Chest Pains. \n   - Typical Angina (1)\n   - Atypical angina (2)\n   - Non-anginal Pain (3)\n   - Asymptomatic (0) ","98aa3d49":"#### Original Data \n\nOriginal Data (df) with normalizing i.e X_train2","f7cffabc":"#### Original Data\nOriginal Data (df) with normalizing i.e X_train2","5767e01f":"### trestbps: \nResting blood pressure (in mm Hg on admission to the hospital)\n\n![fromheartorg.PNG](attachment:fromheartorg.PNG)","88273eee":"#### Outlier removed data (xdf)\n\nOutlier removed data (xdf) with normalization (X_train3)","c662d523":"*Noice* There are no nan values.","f3727cc1":"#### original data (after norm)","4de93f9c":"### Logistic Regression","383895b2":"From the above figure, we can see <b> exang <\/b>, <b> oldpeak <\/b>, <b> ca <\/b> and <b> thal <\/b> are less important to predict <b> target i.e heart disease <\/b>.\n\nWe will drop these features on new dataset <b> xdf <\/b> and we will test the accuracy with default dataset <b> df <\/b>","34dec812":"# 3. Data Visualization","f0f7f10f":"### fbs (fasting blood sugar)\n\nA fasting blood sugar level less than <b> 100 mg\/dL (5.6 mmol\/L) <\/b> is  <b> normal <\/b>. A fasting blood sugar level from <b> 100 to 125 mg\/dL (5.6 to 6.9 mmol\/L) <\/b> is considered prediabetes. If it's <b> 126 mg\/dL (7 mmol\/L) <\/b> or <b> higher <\/b> on two separate tests, you have diabetes.","b7e98cc0":"From the research we know, there are 4 types of chest pain:\n   - <b> Typical Angina <\/b> (substernal chest pain precipitated by physical exertion or emotional stress and relieved with rest or nitroglycerin)\n   - <b> Atypical angina <\/b> (When one experiences chest pain that doesn't meet the criteria for angina, it's known as atypical chest pain)\n   - <b> Non-anginal Pain <\/b> (The pain typically is felt behind the breast bone (sternum) and is described as oppressive, squeezing or pressure-like.)\n   - <b> Asymptomatic <\/b> (Silent Heart Attack)\n   \nIf this is wrong please feel free to correct me. Thanks\n\nAnyways, from the above dataset <b> asymptomatic <\/b> and <b>atypical-angina <\/b> is common \n\nLet's see its relation with target (Heart Disease)","a38167a2":"#### With Original dataset after normalizaing","245f16d6":"### ca \n\nThe number of major vessels (0-3)","1cd87a0c":"### cp (chest pain)","9e6c81be":"## K- Nearest Neighbour","f2ede06d":"We couldn't get more accuracy as data was quite less","3af10ba1":"These datasets contains all types of shortforms. Let's reserach the features and it's importance for the dataset","b0db1dfc":"### Observing Datset","cc7af2a6":"#### Original Dataset\n(Without removing outliers and without normalizing)","12892dbe":"#### Original Dataset after normalization","8bcacbaa":"### oldpeak (ST depression)\n\n<b> ST-segment depression <\/b> is associated with a 100% increase in the occurrence of three-vessel\/left main <b> disease <\/b> and to an increased risk of subsequent cardiac events.","04346f11":"#### With Outlier removed dataset after normalizaing","856869d4":"# 4. Model Preparation\n- 4.1 Encoding Categorical Features\n- 4.2 Normalization\n- 4.3 Split training and testing set","6fed7e88":"If you are confused, see this:\n- <b>df = original dataset\n- df_norm = original dataset with normalization\n- xdf_norm = outliers removed dataset with normalization","a7e19a57":"## Random Forest","f1347aa5":"### 4.2 Normalization","5383651f":"We will follow the given outlies. ","0bfed24d":"#### With original dataset after norm ","a09ee30a":"If you are confused:\n- <b> X_train = original dataset (no norm and no outlier removal)\n- X_train2 = original datset (no outlier removal (df): with only norm)\n- X_train3 = outlier removed dataset (xdf: with norm )","6c526d90":"# 1. Read Dataset","263d9187":"## Support Vector Machine"}}