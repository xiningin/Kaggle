{"cell_type":{"159cabbd":"code","2f33a274":"code","001e5382":"code","e0adc481":"code","1c33d18a":"code","2b5411af":"code","68f6aec1":"code","3c3bf7ec":"code","359e62d7":"code","c404afb7":"code","b657a817":"code","bbb15bef":"code","7e72dab1":"code","cdcfb98c":"code","7dc550eb":"code","2918f064":"code","5f021cbc":"code","79a04b41":"code","2f51542e":"code","14943d60":"code","1efe00b8":"code","0eb7657a":"code","a9c4a424":"code","de55e91f":"code","f861875d":"markdown","7017631c":"markdown","f58be76e":"markdown","7c089e76":"markdown","192074c6":"markdown","9c18e822":"markdown","7429cc97":"markdown","9fd51844":"markdown","a80cc606":"markdown","448ccafa":"markdown","d0a75bc6":"markdown","45d46186":"markdown","aeb6557c":"markdown","db73c35a":"markdown","9e06b60a":"markdown","b2e6f440":"markdown","1141d61a":"markdown","5b5f7a3d":"markdown","7ae12b3f":"markdown","1bb95db3":"markdown","7a5f0c65":"markdown"},"source":{"159cabbd":"import torch\nimport torchvision\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom  torchvision.datasets import MNIST\nfrom torchvision.transforms import ToTensor\nfrom torchvision import datasets, transforms\nfrom torchvision.utils import make_grid\nfrom torch.utils.data.dataloader import DataLoader\nfrom torch.utils.data import random_split\n%matplotlib inline","2f33a274":"batch_size=128\nval_size = 10000\n\ntorch.manual_seed(1)\n\n\ndataset = MNIST(root='data\/', download=True, transform=ToTensor())\n\ntrain_size = len(dataset) - val_size\ntrain_ds, val_ds = random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)","001e5382":"train_mean = 0.\ntrain_std = 0.\nfor images, _ in train_loader:\n    batch_samples = images.size(0) # batch size (the last batch can have smaller size!)\n    images = images.view(batch_samples, images.size(1), -1)\n\n    train_mean += images.mean(2).sum(0)\n    train_std += images.std(2).sum(0)\n\ntrain_mean \/= len(train_loader.dataset)\ntrain_std \/= len(train_loader.dataset)\n\nprint('Mean: ', train_mean)\nprint('Std: ', train_std)","e0adc481":"dataset = MNIST(root='data\/', download=True, transform=transforms.Compose([\n                        transforms.ToTensor(),\n                        transforms.Normalize((0.1308,), (0.3016,))\n                    ]))\ntest_dataset = MNIST(root='data\/', train=False,transform=transforms.Compose([\n                        transforms.ToTensor(),\n                        transforms.Normalize((0.1308,), (0.3016,))\n                    ]))","1c33d18a":"torch.manual_seed(1)\n\nval_size = 10000\ntrain_size = len(dataset) - val_size\ntrain_ds, val_ds = random_split(dataset, [train_size, val_size])\nlen(train_ds), len(val_ds)","2b5411af":"batch_size=128\n\ntrain_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\nval_loader = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size*2, num_workers=4, pin_memory=True)","68f6aec1":"# sanity check for training data\nimgs, lbls = next(iter(train_loader))\nimgs[7].data.shape\nprint(\"min value\", imgs.data.min())\nprint(\"max value\",imgs.data.max())\nprint(\"Mean\",imgs.data.mean())\nprint(\"Std deviation\",imgs.data.std())\nplt.imshow(imgs[0].data.reshape((28,28)), cmap=\"gray\")","3c3bf7ec":"def show_batch(dl, invert=False):\n    for images, labels in dl:\n        fig, ax = plt.subplots(figsize=(16, 8))\n        ax.set_xticks([]); ax.set_yticks([])\n        data = 1-images if invert else images\n        ax.imshow(make_grid(data, nrow=16).permute(1, 2, 0))\n        break","359e62d7":"show_batch(train_loader)\n","c404afb7":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))","b657a817":"class MnistModelBase(nn.Module):\n    def training_step(self, batch):\n        images, targets = batch \n        out = self(images)                      \n        loss = F.cross_entropy(out, targets)      \n        return loss\n    \n    def validation_step(self, batch):\n        images, targets = batch \n        out = self(images)                           # Generate predictions\n        loss = F.cross_entropy(out, targets)  # Calculate loss\n        acc = accuracy(out, targets)\n        return {'val_loss': loss.detach(), 'val_acc': acc }\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_acc = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_acc).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch,result['train_loss'], result['val_loss'], result['val_acc']))","bbb15bef":"class MnistModel(MnistModelBase):\n    \"\"\"Feedfoward neural network with 2 hidden layer\"\"\"\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(in_channels = 1, out_channels = 16, kernel_size=3),   #RF - 3x3 # 26x26\n            nn.ReLU(),\n            nn.BatchNorm2d(16),\n            nn.Dropout2d(0.1),\n\n            nn.Conv2d(16, 16, 3),   #RF - 5x5 # 24x24\n            nn.ReLU(),\n            nn.BatchNorm2d(16),\n            nn.Dropout2d(0.1),\n\n            nn.Conv2d(16, 32, 3),   #RF - 7x7 # 22x22\n            nn.ReLU(),\n            nn.BatchNorm2d(32),\n            nn.Dropout2d(0.1),\n        )\n\n        # translation layer\n        # input - 22x22x64; output - 11x11x32\n        self.trans1 = nn.Sequential(\n            # RF - 7x7\n            nn.Conv2d(32, 16, 1), # 22x22\n            nn.ReLU(),\n            nn.BatchNorm2d(16),\n\n\n            # RF - 14x14\n            nn.MaxPool2d(2, 2), # 11x11\n        )\n\n        self.conv2 = nn.Sequential(\n            nn.Conv2d(16,16,3),   #RF - 16x16 #output- 9x9\n            nn.ReLU(),\n            nn.BatchNorm2d(16),\n            nn.Dropout2d(0.1),\n\n            nn.Conv2d(16, 16, 3),   #RF - 18x18 #output- 7x7\n            nn.ReLU(),\n            nn.BatchNorm2d(16),\n            nn.Dropout2d(0.1),\n        ) \n\n         \n        self.conv3 = nn.Sequential(\n            nn.Conv2d(16,16,3),   #RF - 20x20  #output- 5x5\n            nn.ReLU(),\n            nn.BatchNorm2d(16),\n            nn.Dropout2d(0.1),\n\n            nn.Conv2d(16, 32, 3),   #RF - 22x22  #output- 3x3\n            nn.ReLU(),\n            nn.BatchNorm2d(32),\n            nn.Dropout2d(0.1),\n        )   \n\n        # GAP Layer\n        # input - 5x5x16; output - 1x1x10\n        self.avg_pool = nn.Sequential(\n            # # RF - 22x22\n            nn.Conv2d(32, 10, 1, bias=False),\n            nn.AvgPool2d(3)\n        )     \n\n        \n    def forward(self, xb):\n        x = self.conv1(xb)\n        x = self.trans1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.avg_pool(x)\n\n        x = x.view(-1, 10)\n        return x","7e72dab1":"#function to ensure that our code uses the GPU if available, and defaults to using the CPU if it isn't.\ndef get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \n# a function that can move data and model to a chosen device.    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\n\n#Finally, we define a DeviceDataLoader class to wrap our existing data loaders and move data to the selected device, \n#as a batches are accessed. Interestingly, we don't need to extend an existing class to create a PyTorch dataloader. \n#All we need is an __iter__ method to retrieve batches of data, and an __len__ method to get the number of batches.\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","cdcfb98c":"device = get_default_device()\ntrain_loader = DeviceDataLoader(train_loader, device)\nval_loader = DeviceDataLoader(val_loader, device)\ntest_loader = DeviceDataLoader(test_loader, device)","7dc550eb":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    torch.cuda.empty_cache()\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","2918f064":"# Model (on GPU)\nmodel = MnistModel()\nto_device(model, device)","5f021cbc":"!pip install torchsummary","79a04b41":"from torchsummary import summary\n# print the summary of the model\nsummary(model, input_size=(1, 28, 28), batch_size=-1)","2f51542e":"history = [evaluate(model, val_loader)]\nhistory","14943d60":"history += fit(19, 0.01, model, train_loader, val_loader)\n","1efe00b8":"def plot_scores(history):\n#     scores = [x['val_score'] for x in history]\n    acc = [x['val_acc'] for x in history]\n    plt.plot(acc, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('acc')\n    plt.title('acc vs. No. of epochs');","0eb7657a":"def plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');","a9c4a424":"plot_losses(history)\n","de55e91f":"plot_scores(history)\n","f861875d":"## Plot Metrics","7017631c":"Host to GPU copies are much faster when they originate from pinned (page-locked) memory. For data loading, passing pin_memory=True to a DataLoader will automatically put the fetched data Tensors in pinned memory, and thus enables faster data transfer to CUDA-enabled GPUs.","f58be76e":"## Model\nwe will use a convolutional neural network, using the nn.Conv2d class from PyTorch.\nThe 2D convolution is a fairly simple operation at heart: you start with a kernel, which is simply a small matrix of weights. This kernel \u201cslides\u201d over the 2D input data, performing an elementwise multiplication with the part of the input it is currently on, and then summing up the results into a single output pixel.\n\nThe activation function we'll use here is called a Rectified Linear Unit or ReLU, and it has a really simple formula: relu(x) = max(0,x) i.e. if an element is negative, we replace it by 0, otherwise we leave it unchanged.\n\nTo define the model, we extend the nn.Module class","7c089e76":"The initial accuracy is around 10%, which is what one might expect from a randomly intialized model (since it has a 1 in 10 chance of getting a label right by guessing randomly).\n\nWe are now ready to train the model. Let's train for 5 epochs and look at the results. We can use a relatively higher learning of 0.01.","192074c6":"## Evaluation Metric and Loss Function\u00b6\nLet's first define out evaluation metric, we need a way to evaluate how well our model is performing. A natural way to do this would be to find the percentage of labels that were predicted correctly i.e. the accuracy of the prediction","9c18e822":"Before we train the model, we need to ensure that the data and the model's parameters (weights and biases) are on the same device (CPU or GPU). We can reuse the to_device function to move the model's parameters to the right device.","7429cc97":"Next, let's use the random_split helper function to set aside 10000 images for our validation set.","9fd51844":"### Conclusion\n\n- 99.9% validation accuracy\n- 19k parameters\n- 20 epochs\n- batch norm used\n- used dropout after each layer\n- no fully connected layer (GAP layer used)","a80cc606":"Let's see how the model performs on the validation set with the initial set of weights and biases.","448ccafa":"Calculate mean and std of training data - used for normalization later","d0a75bc6":"We can now create PyTorch data loaders for training and validation.","45d46186":"We download the data and create a PyTorch dataset using the MNIST class from torchvision.datasets.","aeb6557c":"### Sanity check\n to make sure data is of normal distribution (zero mean and unit standard dev)","db73c35a":"### Model Training\n\n\n","9e06b60a":"### Convolutional Neural Networks\nConvolutional Neural Networks are very similar to feed forward Neural Networks They are made up of neurons that have learnable weights and biases. Each neuron receives some inputs, performs a dot product and optionally follows it with a non-linearity. The whole network still expresses a single differentiable score function: from the raw image pixels on one end to class scores at the other. And they still have a loss function (e.g. Softmax) on the last (fully-connected) layer.\n\nConvNet architectures make the explicit assumption that the inputs are images, which allows us to encode certain properties into the architecture. These then make the forward function more efficient to implement and vastly reduce the amount of parameters in the network.\n\nA ConvNet is made up of Layers. Every Layer has a simple API: It transforms an input 3D volume to an output 3D volume with some differentiable function that may or may not have parameters.\n\nHere is a very good visual explaination of CNN\nhttps:\/\/poloclub.github.io\/cnn-explainer\/\n\n\n### Import necessary libraries","b2e6f440":"### Using a GPU\nAs the sizes of our models and datasets increase, we need to use GPUs to train our models within a reasonable amount of time. GPUs contain hundreds of cores that are optimized for performing expensive matrix operations on floating point numbers in a short time, which makes them ideal for training deep neural networks with many layers.\n\ndefine helper functions","1141d61a":"\n\nLet's visualize a batch of data in a grid using the make_grid function from torchvision. We'll also use the .permute method on the tensor to move the channels to the last dimension, as expected by matplotlib.","5b5f7a3d":"<a href=\"https:\/\/colab.research.google.com\/github\/divya-r-kamat\/PyTorch\/blob\/master\/MNIST_CNN_(Fine_Tuning).ipynb\" target=\"_parent\"><img src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\" alt=\"Open In Colab\"\/><\/a>","7ae12b3f":"We can now wrap our data loaders using DeviceDataLoader.","1bb95db3":"Print Summary of the model","7a5f0c65":"\nHere we are using torch.max() function, this function's default behaviour as you can guess by the name is to return maximum among the elements in the Tensor. However, this function also helps get the maximum along a particular dimension, as a Tensor, instead of a single element. To specify the dimension (axis \u2013 in numpy), there is another optional keyword argument, called dim. This represents the direction that we take for the maximum.\n\n*max_elements, max_indices = torch.max(input_tensor, dim)*\n\n- dim=0, (maximum along columns).\n- dim=1 (maximum along rows).\n\nThis returns a tuple, max_elements and max_indices.\n\n* max_elements -> All the maximum elements of the Tensor.\n* max_indices -> Indices corresponding to the maximum elements.\n\nIn the above accuracy function, the == performs an element-wise comparison of two tensors with the same shape, and returns a tensor of the same shape, containing 0s for unequal elements, and 1s for equal elements. Passing the result to torch.sum returns the number of labels that were predicted correctly. Finally, we divide by the total number of images to get the accuracy.\n\n## Loss Function\nWhile the accuracy is a great way for us (humans) to evaluate the model, it can't be used as a loss function for optimizing our model using gradient descent, for the following reasons:\n\nIt's not a differentiable function. torch.max and == are both non-continuous and non-differentiable operations, so we can't use the accuracy for computing gradients w.r.t the weights and biases.\n\nIt doesn't take into account the actual probabilities predicted by the model, so it can't provide sufficient feedback for incremental improvements.\n\nDue to these reasons, accuracy is a great evaluation metric for classification, but not a good loss function. A commonly used loss function for classification problems is the cross entropy,\n\n## How Cross Entropy works\nFor each output row, pick the predicted probability for the correct label. E.g. if the predicted probabilities for an image are [0.1, 0.3, 0.2, ...] and the correct label is 1, we pick the corresponding element 0.3 and ignore the rest.\n\nThen, take the logarithm of the picked probability. If the probability is high i.e. close to 1, then its logarithm is a very small negative value, close to 0. And if the probability is low (close to 0), then the logarithm is a very large negative value. We also multiply the result by -1, which results is a large postive value of the loss for poor predictions.\n\nFinally, take the average of the cross entropy across all the output rows to get the overall loss for a batch of data.\n\nUnlike accuracy, cross-entropy is a continuous and differentiable function that also provides good feedback for incremental improvements in the model (a slightly higher probability for the correct label leads to a lower loss). This makes it a good choice for the loss function.\n\nPyTorch provides an efficient and tensor-friendly implementation of cross entropy as part of the torch.nn.functional package. Moreover, it also performs softmax internally, so we can directly pass in the outputs of the model without converting them into probabilities."}}