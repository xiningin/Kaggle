{"cell_type":{"edaee47b":"code","0a82bdb5":"code","94e39e9b":"code","5d72545f":"code","5ad1f188":"code","5713afd6":"code","7d9034ef":"code","dd9e3bd8":"code","c4a9f0a0":"code","ba3b094e":"code","e0651896":"code","b45aea2d":"code","4a4ee453":"code","1e0d8f56":"code","9f8174df":"code","6a5a3c43":"code","ff630e6b":"code","0caf64f1":"code","a85ba3ec":"markdown"},"source":{"edaee47b":"import numpy as np\nimport pandas as pd","0a82bdb5":"# Read the dataset\ndf=pd.read_csv('..\/input\/vehicle-dataset-from-cardekho\/car data.csv')\ndf.shape, df.columns","94e39e9b":"print(df['Seller_Type'].unique())\nprint(df['Fuel_Type'].unique())\nprint(df['Transmission'].unique())\nprint(df['Owner'].unique())","5d72545f":"##check missing values\ndf.isnull().sum()","5ad1f188":"df.describe()","5713afd6":"#Filter Dataset and add column with Current year\nfinal_dataset=df[['Year','Selling_Price','Present_Price','Kms_Driven','Fuel_Type','Seller_Type','Transmission','Owner']]\nfinal_dataset['Current Year']=2021\nfinal_dataset.head()","7d9034ef":"# Add new column with Age of vehicle\nfinal_dataset['Age']=final_dataset['Current Year']- final_dataset['Year']","dd9e3bd8":"# Convert categorical columns with get_dummies\nfinal_dataset=pd.get_dummies(final_dataset,drop_first=True)","c4a9f0a0":"# Pairplot\nimport seaborn as sns\nfinal_dataset=final_dataset.drop(['Current Year'],axis=1)\nfinal_dataset.corr()\nsns.pairplot(final_dataset)","ba3b094e":"#get correlations of each features in dataset\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ncorrmat = df.corr()\ntop_corr_features = corrmat.index\nplt.figure(figsize=(20,20))\n#plot heat map\ng=sns.heatmap(df[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")","e0651896":"final_dataset.head()","b45aea2d":"# Set up x and y(target) data\ny=final_dataset['Selling_Price']\nx= final_dataset[['Present_Price', 'Kms_Driven', 'Owner', 'Age','Fuel_Type_Diesel', \n                 'Fuel_Type_Petrol', 'Seller_Type_Individual','Transmission_Manual']]","4a4ee453":"# Find feature Importance from ExtraTreeregg\nfrom sklearn.ensemble import ExtraTreesRegressor\nimport matplotlib.pyplot as plt\nmodel = ExtraTreesRegressor()\nmodel.fit(x,y)\n#plot graph of feature importances \nfeat_importances = pd.Series(model.feature_importances_, index=x.columns)\nfeat_importances.nlargest(20).plot(kind='barh')","1e0d8f56":"from sklearn import model_selection\nfrom catboost import CatBoostRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn import neighbors\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nimport random","9f8174df":"import warnings\nwarnings.filterwarnings('ignore')","6a5a3c43":"#!pip install xgboost==1.3.3","ff630e6b":"# Find performance of each model\noutcome = []\nmodel_names = []\nmodels = [('CatBoost', CatBoostRegressor(verbose=0, n_estimators=100)), \n          ('RandomForest', RandomForestRegressor(n_estimators=100)), \n          ('DecTree', DecisionTreeRegressor(max_depth=5)),\n          ('ExtraTrees', ExtraTreesRegressor(n_estimators=100)),\n          ('KNN', neighbors.KNeighborsRegressor(n_neighbors = 5)),\n          ('LGBM', LGBMRegressor()),\n          ('XGB', XGBRegressor()),\n          ('GB',GradientBoostingRegressor())]\n\n\n\nfor model_name, model in models:\n    k_fold_validation = model_selection.KFold(n_splits=5, random_state=30, shuffle= True)\n    results = model_selection.cross_val_score(model, x, y, cv=k_fold_validation, scoring='neg_root_mean_squared_error')\n    outcome.append(results)\n    model_names.append(model_name)\n    output_message = \"%s| Mean=%f STD=%f Min=%f Max=%f\" % (model_name, results.mean(), results.std(), results.min(), results.max())\n    print(output_message)","0caf64f1":"\nimport sklearn\nprint(sorted(sklearn.metrics.SCORERS.keys()))","a85ba3ec":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session"}}