{"cell_type":{"d8fe684c":"code","04de36fd":"code","f8d30162":"code","d7fc0e25":"code","04c8ec7d":"code","2397451e":"code","8bad9c3e":"code","18cc63ad":"code","d569c06b":"code","d7d25e9d":"code","b34dd244":"code","73b6f373":"code","2c5fb121":"code","9b0fe8a6":"code","4986edb2":"markdown","e03c9a9f":"markdown","99f11ccd":"markdown","9f1bc8ae":"markdown","737632ff":"markdown","0144782d":"markdown","7c17f04d":"markdown","6925d728":"markdown","0cdee2d4":"markdown"},"source":{"d8fe684c":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nfrom tensorflow.python.util import compat\nfrom tensorflow.core.protobuf import saved_model_pb2\nfrom google.protobuf import text_format\nimport pprint\nimport os","04de36fd":"! rm -rf .\/models && git clone https:\/\/github.com\/tensorflow\/models.git \\\n    && cd models\/research \\\n    && protoc object_detection\/protos\/*.proto --python_out=. \\\n    && cp object_detection\/packages\/tf2\/setup.py . && \\\n    python3 -m pip install --use-feature=2020-resolver .","f8d30162":"from object_detection.utils import visualization_utils as vis_util\nfrom object_detection.utils import dataset_util, label_map_util\nfrom object_detection.protos import string_int_label_map_pb2","d7fc0e25":"# reconstruct frozen graph\ndef reconstruct(pb_path):\n    if not os.path.isfile(pb_path):\n        print(\"Error: %s not found\" % pb_path)\n\n    print(\"Reconstructing Tensorflow model\")\n    detection_graph = tf.Graph()\n    with detection_graph.as_default():\n        od_graph_def = tf.compat.v1.GraphDef()\n        with tf.io.gfile.GFile(pb_path, 'rb') as fid:\n            serialized_graph = fid.read()\n            od_graph_def.ParseFromString(serialized_graph)\n            tf.import_graph_def(od_graph_def, name='')\n    print(\"Success!\")\n    return detection_graph","04c8ec7d":"# visualize detection\ndef image2np(image):\n    (w, h) = image.size\n    return np.array(image.getdata()).reshape((h, w, 3)).astype(np.uint8)\n\ndef image2tensor(image):\n    npim = image2np(image)\n    return np.expand_dims(npim, axis=0)\n\n%matplotlib inline\ndef detect(detection_graph, test_image_path):\n    with detection_graph.as_default():\n        gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.01)\n        with tf.compat.v1.Session(graph=detection_graph,config=tf.compat.v1.ConfigProto(gpu_options=gpu_options)) as sess:\n            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n            detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n            detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n            detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n\n            image = Image.open(test_image_path)\n            (boxes, scores, classes, num) = sess.run(\n                [detection_boxes, detection_scores, detection_classes, num_detections],\n                feed_dict={image_tensor: image2tensor(image)}\n            )\n\n            npim = image2np(image)\n            vis_util.visualize_boxes_and_labels_on_image_array(\n                npim,\n                np.squeeze(boxes),\n                np.squeeze(classes).astype(np.int32),\n                np.squeeze(scores),\n                category_index,\n                use_normalized_coordinates=True,\n                line_thickness=5)\n            plt.figure(figsize=(12, 8))\n            plt.imshow(npim)\n            plt.show()","2397451e":"categories = [\"hardhat\", \"none\"]\nNCLASSES = 2","8bad9c3e":"print('Building label map from examples')\n\nlabelmap = string_int_label_map_pb2.StringIntLabelMap()\nfor idx,category in enumerate(categories):\n    item = labelmap.item.add()\n    # label map id 0 is reserved for the background label\n    item.id = idx+1\n    item.name = category\n\nwith open('.\/labelmap.pbtxt', 'w') as f:\n    f.write(text_format.MessageToString(labelmap))\n\nprint('Label map witten to labelmap.pbtxt')\n\nwith open('.\/labelmap.pbtxt') as f:\n    pprint.pprint(f.readlines())","18cc63ad":"label_map = label_map_util.load_labelmap('labelmap.pbtxt')\ncategories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NCLASSES, use_display_name=True)\ncategory_index = label_map_util.create_category_index(categories)","d569c06b":"detection_graph = reconstruct(\"\/kaggle\/input\/pretrained-trt-engines-cocotacohardhatposenet\/base-models\/ssd_mobilenet_v2_hardhat_2018_03_29.pb\")","d7d25e9d":"detect(detection_graph, '\/kaggle\/input\/hardhat-and-safety-vest-image-for-object-detection\/train\/neg_100.jpg')","b34dd244":"detect(detection_graph, '\/kaggle\/input\/hardhat-and-safety-vest-image-for-object-detection\/train\/neg_1099.jpg')","73b6f373":"detect(detection_graph, '\/kaggle\/input\/hardhat-and-safety-vest-image-for-object-detection\/train\/pos_942.jpg')","2c5fb121":"detect(detection_graph, '\/kaggle\/input\/hardhat-and-safety-vest-image-for-object-detection\/train\/pos_971.jpg')","9b0fe8a6":"! rm -rf .\/models","4986edb2":"First we need to create the label map.","e03c9a9f":"# Cleanup","99f11ccd":"# Reconstruct Frozen Graph","9f1bc8ae":"# Hardhat Detection (SSD MobileNet v2) with TensorFlow","737632ff":"# Validate Test Images","0144782d":"We are going to use pretrained models in this notebook to show how you can do inference on them of unseen images. The pretrained models can be found here: https:\/\/www.kaggle.com\/bouweceunen\/pretrained-trt-engines-cocotacohardhatposenet","7c17f04d":"We can now test it on some test images.","6925d728":"Now we are going to reconstruct the TensorFlow frozen graph (.pb).","0cdee2d4":"# Create LabelMap"}}