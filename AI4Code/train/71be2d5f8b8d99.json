{"cell_type":{"16c08b70":"code","ce6fafc9":"code","f7a16433":"code","e29c6f86":"code","7313bb96":"code","1d134d80":"code","3d4e75d2":"code","a7b5871d":"code","3738e91f":"markdown","8f1d637f":"markdown","471def07":"markdown","e2ccd90d":"markdown","621fbaca":"markdown","9adb78ba":"markdown","40eea6d6":"markdown","42267a91":"markdown","2514ecad":"markdown"},"source":{"16c08b70":"import cv2 as cv2 \nimport os\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.optimizers import SGD\nfrom keras import backend as K\nK.set_image_data_format('channels_first')\nfrom keras.callbacks import LearningRateScheduler, ModelCheckpoint\nimport tensorflow as tf \n\nnp.random.seed(1)\nfinalAct = 'softmax' \nIMG_SIZE = 48\nNUM_CLASSES = int(8)","ce6fafc9":"def init_img(img):\n    #histogram normalization\n    res = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n    res[:, :, 0] = cv2.equalizeHist(res[:, :, 0])\n    res = cv2.cvtColor(res, cv2.COLOR_YUV2BGR)\n\n    #resize image\n    res = cv2.resize(res, (IMG_SIZE, IMG_SIZE))\n\n    #roll axis\n    res = np.rollaxis(res, -1)\n\n    return res","f7a16433":"def load_image_from_folder(folder, arr):\n    len = 0\n    for filename in os.listdir(folder):\n        img = cv2.imread(os.path.join(folder, filename), 1)\n        if img is not None:\n            arr.append(init_img(img))\n            len+=1\n    return arr, len\n\nX = []\nY = []\nlabels = []\n\nfor i in range(8):\n    X, num = load_image_from_folder('train\/' + str(i), X)\n    for j in range(num):\n        labels.append(i)\n\nX = np.array(X, dtype = 'float32')\n","e29c6f86":"per = np.random.permutation(X.shape[0])\n\ntmp_X = []\ntmp_Y = []\n\ni = 0 \nfor j in per:\n        tmp_X.append(X[j])\n        tmp_Y.append(labels[j])\n\nX = tmp_X\nlabels = tmp_Y\n\nX = np.array(X, dtype = 'float32')\nlabels = np.array(labels, dtype = 'uint8')\nY = np.eye(NUM_CLASSES, dtype = 'uint8')[labels]\nX = tf.keras.utils.normalize(X, axis=1)\n","7313bb96":"\ndef cnn_model():\n    model = Sequential() #Init\n    #Convolutinal Layer, we'll use a 3x3 kernel to load through our image, and return feature map\n    model.add(Conv2D(32, (3, 3), padding='same',\n                     input_shape=(3, IMG_SIZE, IMG_SIZE),\n                     activation='relu'))\n    model.add(Conv2D(32, (3, 3), activation='relu'))\n    #MaxPolling Layer, it help us to reduce spatial dimension\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(64, (3, 3), padding='same',\n                     activation='relu'))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(128, (3, 3), padding='same',\n                     activation='relu'))\n    model.add(Conv2D(128, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n\n    #Flat to prepare for the next fully connection layer\n    model.add(Flatten())\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.5))\n    #finalAct = softmax, it will return a tuple, in this tuple that n-class size, i-th element mean the probality to become ith-class\n    #and sum of them = 1\n    model.add(Dense(NUM_CLASSES, activation=finalAct))\n    return model\n\nmodel = cnn_model()","1d134d80":"lr = 0.01\nsgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=sgd,\n              metrics=['accuracy'])\n","3d4e75d2":"batch_size = 32\nepochs = 30\n\nmodel_trained = model.fit(X, Y,\n          batch_size=batch_size,\n          epochs=epochs,\n          validation_split=0.2,\n          callbacks=[LearningRateScheduler(lr_schedule),\n                     ModelCheckpoint('model.h5', save_best_only=True)]\n          )\n          \nmodel.save('my_model.h5')","a7b5871d":"from keras.models import load_model\nimport cv2\nimport numpy as np \nimport tensorflow as tf \nimport os\n\n#Load our model that have been fitted before\nmodel = load_model('model.h5')\nPATH = 'data_private'\n\nIMG_SIZE = 48\n\n#reuse our init function in the training phase\ndef init_img(img):\n    #histogram normalization\n    res = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n    res[:, :, 0] = cv2.equalizeHist(res[:, :, 0])\n    res = cv2.cvtColor(res, cv2.COLOR_YUV2BGR)\n\n    #resize image\n    res = cv2.resize(res, (IMG_SIZE, IMG_SIZE))\n\n    #roll axis\n    res = np.rollaxis(res, -1)\n\n    return res\n\n#yeah, reused it again\ndef load_image_from_folder(folder):\n    name = []\n    arr = []\n    for filename in os.listdir(folder):\n        img = cv2.imread(os.path.join(folder, filename), 1)\n        if img is not None:\n            arr.append(init_img(img))\n            name.append(filename)\n    return arr, name\n\nimg, filename = load_image_from_folder(PATH)\n\n#turn list data to ndarray, and normalize them\ntest_data = np.array(img, dtype = 'float32')\ntest_data = tf.keras.utils.normalize(test_data, axis=1)\n\n#1 line to predict our test data, return a ndarray of labels\nresult = model.predict_classes(test_data)\n\n#write to \"data_output.csv\" file\nfout = open('data_output.csv', 'w')\nfor i in range(len(test_data)):\n    fout.write(filename[i] + ',' + str(result[i]) + '\\n')","3738e91f":"Compile our model, in this model, the optimization function is SGD (Stochastic Gradien Decent), and loss function is cross entropy, you can easily find them.","8f1d637f":"In this time, we will use Convolutional Neural Network to classify images. First, We'll import some essential packages:\n    - We'll use Keras to build our model by easiest way, that's very simple for newbie\n    - We'll use cv2 to not only load our data set, but also initialize them.","471def07":"And now, the most important and interested path, we'll build our model.\nThat's is a big model (I think so) but it haven return the best answer.","e2ccd90d":"Load training data set:\nTraining folder contain 8 files, that be numbered from 0 to 7, each file contain about 85 pictures. We'll load all of them, then make them a label","621fbaca":"At first, we'll use cv2 to initalize our data, transform them to the type that our model will take and easily use them.","9adb78ba":"Harvest time !!, We will create another file, to load image and predict our test data\nDetail about each path, i'll comment in this code","40eea6d6":"The last step, train our model, we will save our weights and bias in a file named \"model.h5\"\nThere are some simple ways to explain 2 important function, batch_size and epochs\nBatch_size, in a easy way to understand, is number that we loop through a sample in data set to optimize our weights and bias\nEpochs, in a easy way to understand, is number of time we re-do our homework (in this case, that's number of time we learn again and again)\nYou can modify 2 parameter.","42267a91":"**There are some insufficient in my kernel, That's because my short of knowledge in CNN, but I hope you can imagine how to train a model to classify images, that's not too hard when we use Keras.**\nOnce again, thank you for reading my kernel !!","2514ecad":"Mix data set and normalize \n(normalize is an action that reduce our data from size 255 to less than 1, that will help our model)"}}