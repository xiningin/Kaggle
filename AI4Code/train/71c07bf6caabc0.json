{"cell_type":{"0ca0ebfc":"code","5e286811":"code","17056a4e":"code","527e5cd4":"code","3bd11fbd":"code","25b0fe31":"code","63edf646":"code","6560d928":"code","c1a50f44":"code","0ef69e48":"code","f0709aa0":"code","2caf34ca":"code","62facc69":"code","0c526a31":"code","f4a11a83":"code","169c50ca":"code","16db468b":"code","80bf21c6":"markdown","4c8c52c1":"markdown","0e5a8e8c":"markdown"},"source":{"0ca0ebfc":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n#import gc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n\nfrom sklearn.metrics import mean_squared_error\nimport lightgbm as lgb\nimport xgboost as xgb\n\nimport warnings\nwarnings.filterwarnings('ignore')","5e286811":"train_df = pd.read_csv('\/kaggle\/input\/santander-value-prediction-challenge\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/santander-value-prediction-challenge\/test.csv')","17056a4e":"print('Shape of train data', train_df.shape)\nprint('Shape of test data', test_df.shape)","527e5cd4":"# check for null values\nprint('num of null values in train set', train_df.isnull().sum().sum())\n\n# check for null values\nprint('num of null values in test set', test_df.isnull().sum().sum())","3bd11fbd":"train_df.head(10)","25b0fe31":"train_df.tail(10)","63edf646":"dtype_df = train_df.dtypes.reset_index()\ndtype_df.columns = [\"Count\", \"Column Type\"]\ndtype_df.groupby(\"Column Type\").aggregate('count').reset_index()","6560d928":"plt.figure(figsize=(12,8))\nsns.distplot(train_df[\"target\"].values, bins=50, kde=False)\nplt.xlabel('Target', fontsize=12)\nplt.title(\"Target Histogram\", fontsize=14)\n","c1a50f44":"# use log1p instead of log to get the normalized value for even tiny values -> 0\n\nplt.figure(figsize=(12,8))\nsns.distplot( np.log1p(train_df[\"target\"].values), bins=50, kde=False)\nplt.xlabel('Target', fontsize=12)\nplt.title(\"Log of Target Histogram\", fontsize=14)\n","0ef69e48":"# check and remove constant columns\ncolsToRemove = []\nfor col in train_df.columns:\n    if col != 'ID' and col != 'target':\n        if train_df[col].std() == 0: \n            colsToRemove.append(col)\n        \n# remove constant columns in the training set\ntrain_df.drop(colsToRemove, axis=1, inplace=True)\n\n# remove constant columns in the test set\ntest_df.drop(colsToRemove, axis=1, inplace=True) \n\nprint(f\"Removed `{len(colsToRemove)}` Constant Columns\\n\")\n","f0709aa0":"# check for duplicate columns\n\ndef duplicate_columns(df):\n    dups = []\n    columns = df.columns\n\n    for i in range(len(columns)):\n        col1 = df.iloc[:, i]\n        for j in range(i + 1, len(columns)):\n            col2 = df.iloc[:, j]\n            # break early if dtypes aren't the same (helps deal with\n            # categorical dtypes)\n            if col1.dtype is not col2.dtype:\n                break\n            # otherwise compare values\n            if col1.equals(col2):\n                dups.append(columns[i])\n                break\n    return dups\n\n\ntrain_dups = duplicate_columns(train_df)\nprint('num of duplicated cols in the train set: ', len(train_dups))\n\n","2caf34ca":"# dropping useless features\n\nuseless_features = list(set( train_dups))\n\ntrain_df = train_df.drop(useless_features, axis=1)\ntest_df = test_df.drop(useless_features, axis=1)","62facc69":"x = train_df.drop(train_df[['ID','target']],axis = 1)\ny = np.log1p(train_df[\"target\"])\nX_test = test_df.drop([\"ID\"], axis=1)\n","0c526a31":"from sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(x, y,test_size=0.2, random_state=22)","f4a11a83":"def run_xgb(train_X, train_y, val_X, val_y, test_X):\n    params = {'objective': 'reg:linear', \n          'eval_metric': 'rmse',\n          'eta': 0.005,\n          'max_depth': 15, \n          'subsample': 0.7, \n          'colsample_bytree': 0.5,\n          'alpha':0,\n          'random_state': 42, \n          'silent': True}\n    \n    tr_data = xgb.DMatrix(X_train, y_train)\n    va_data = xgb.DMatrix(X_valid, y_valid)\n    \n    watchlist = [(tr_data, 'train'), (va_data, 'valid')]\n    \n    model_xgb = xgb.train(params, tr_data, 2000, watchlist, maximize=False, early_stopping_rounds = 30, verbose_eval=100)\n    \n    dtest = xgb.DMatrix(test_X)\n    xgb_pred_y = np.expm1(model_xgb.predict(dtest, ntree_limit=model_xgb.best_ntree_limit))\n    \n    return xgb_pred_y, model_xgb","169c50ca":"pred_test_xgb, model_xgb = run_xgb(X_train, X_valid, y_train, y_valid, X_test)\nprint(\"XGB Training Completed...\")","16db468b":"sub = pd.read_csv('..\/input\/santander-value-prediction-challenge\/sample_submission.csv')\nsub[\"target\"] = pred_test_xgb\nprint(sub.head())\nsub.to_csv('sub_lgb_xgb.csv', index=False)","80bf21c6":"# Submit to the competition\n","4c8c52c1":"# create model","0e5a8e8c":"# EDA"}}