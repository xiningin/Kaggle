{"cell_type":{"34c38926":"code","69a29274":"code","793ed680":"code","dc10359f":"code","4b152461":"code","c2b4bbff":"code","7cf7b505":"code","87cd700b":"code","5d2c879e":"code","c5f05bb0":"code","209e9784":"code","335a27f8":"code","83188615":"code","6a6fe006":"code","87101326":"code","1ff54a9b":"code","3a80b7a9":"code","b610fca5":"code","1175a137":"code","80be63b0":"code","1b3f9b58":"code","c7d8d7ae":"code","ed68d01d":"code","7699f46c":"code","69901f99":"code","f9337e18":"code","d3e39660":"code","af5cde23":"code","fe4227b9":"code","d7165d62":"code","c7a81da3":"code","2233de8d":"code","ffea9e07":"code","78a38bf2":"code","1ef5a00c":"code","d5570c6f":"code","37c72904":"code","3ca2777f":"code","67b6c2c1":"code","185ec93b":"code","26ac12dc":"code","bd0b1b10":"code","52082511":"code","1703b85e":"code","aeadefe4":"code","7830d820":"code","aac6eced":"code","98932c7f":"code","1fbb1378":"code","ad9861f8":"code","f555d709":"code","f79e1ab8":"code","0a0eb22c":"code","ee1ec5dd":"code","7bb31663":"code","6d15c7e7":"code","641b992c":"code","6837f3c1":"code","c7ecc567":"code","b2d4541a":"code","d0442573":"markdown","4ade9dcd":"markdown","5a9acc09":"markdown","ae194824":"markdown","c70aef82":"markdown","5a00e5ef":"markdown","8fdf31e4":"markdown","01bd2567":"markdown","c2c3dbe2":"markdown","812fb3ad":"markdown","752992c1":"markdown","f79ece77":"markdown","4f23f72f":"markdown","92c9bdbb":"markdown","a104fc94":"markdown","9b7d912e":"markdown","3e50a3ae":"markdown","256a72be":"markdown","67e7c970":"markdown","64afcc11":"markdown","0d722c43":"markdown","61c77d73":"markdown","57f6ceec":"markdown","0d362364":"markdown","e8c86f46":"markdown","ddf65d52":"markdown","6fa45c7d":"markdown","412fd162":"markdown","0a3c5801":"markdown","bf95fb6a":"markdown","315e849a":"markdown","85c3d9cf":"markdown","565f70f9":"markdown","0483ae2b":"markdown","a57a9910":"markdown","b87defb5":"markdown","e0a2876a":"markdown","8818a75d":"markdown","c5f35f91":"markdown","f4a0ae56":"markdown","95b22b63":"markdown","a05fa1cc":"markdown","e9165c1d":"markdown","c412b0f2":"markdown"},"source":{"34c38926":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","69a29274":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib import rcParams\nimport re\n\n%matplotlib inline\nrcParams['figure.figsize'] = 10,8","793ed680":"df_train = pd.read_csv(\"\/kaggle\/input\/challenge-housepricing-valeuriadepitech-2021\/train_titanic.csv\")\ndf_test = pd.read_csv(\"\/kaggle\/input\/challenge-housepricing-valeuriadepitech-2021\/test_titanic.csv\")","dc10359f":"df_test","4b152461":"df_train","c2b4bbff":"#On s'int\u00e9resse principalement au typage des donn\u00e9es et aux observations manquantes.\nprint(df_train.info())\nprint(df_test.info())","7cf7b505":"#Statistiques de base (pour les variables num\u00e9riques)\ndf_train.describe()","87cd700b":"f,ax = plt.subplots(3,4,figsize=(20,16))\nsns.countplot('Pclass',data=df_train,ax=ax[0,0])\nsns.countplot('Sex',data=df_train,ax=ax[0,1])\nsns.boxplot(x='Pclass',y='Age',data=df_train,ax=ax[0,2])\nsns.countplot('SibSp',hue='Survived',data=df_train,ax=ax[0,3],palette='husl')\nsns.distplot(df_train['Fare'].dropna(),ax=ax[2,0],kde=False,color='b')\nsns.countplot('Embarked',data=df_train,ax=ax[2,2])\n\nsns.countplot('Pclass',hue='Survived',data=df_train,ax=ax[1,0],palette='husl')\nsns.countplot('Sex',hue='Survived',data=df_train,ax=ax[1,1],palette='husl')\nsns.distplot(df_train[df_train['Survived']==0]['Age'].dropna(),ax=ax[1,2],kde=True,color='r',bins=30)\nsns.distplot(df_train[df_train['Survived']==1]['Age'].dropna(),ax=ax[1,2],kde=True,color='g',bins=30)\nsns.countplot('Parch',hue='Survived',data=df_train,ax=ax[1,3],palette='husl')\nsns.swarmplot(x='Pclass',y='Fare',hue='Survived',data=df_train,palette='husl',ax=ax[2,1])\nsns.countplot('Embarked',hue='Survived',data=df_train,ax=ax[2,3],palette='husl')\n\nax[0,0].set_title('Total Passengers by Class')\nax[0,1].set_title('Total Passengers by Gender')\nax[0,2].set_title('Age Box Plot By Class')\nax[0,3].set_title('Survival Rate by SibSp')\nax[1,0].set_title('Survival Rate by Class')\nax[1,1].set_title('Survival Rate by Gender')\nax[1,2].set_title('Survival Rate by Age')\nax[1,3].set_title('Survival Rate by Parch')\nax[2,0].set_title('Fare Distribution')\nax[2,1].set_title('Survival Rate by Fare and Pclass')\nax[2,2].set_title('Total Passengers by Embarked')\nax[2,3].set_title('Survival Rate by Embarked')","5d2c879e":"# Premi\u00e8res id\u00e9e : les femmes et les enfants d'abord !\n# On construit un vecteur de bool\u00e9ens o\u00f9 TRUE == survivant et FALSE == non survivant\nsurvivors_or_iceblock = (df_train[\"Age\"] < 10) | (df_train[\"Sex\"] == \"female\")\n# On peut ensuite tester si nos valeurs bool\u00e9ennes sont \u00e9gales ou pas \u00e0 la colonne Survived (TRUE == 1 & FALSE == 0)\n# En faisant la moyenne de ce nouveau vecteur, on obtient notre pourcentage de bonnes r\u00e9ponses\nnp.mean(df_train[\"Survived\"]==survivors_or_iceblock)","c5f05bb0":"from sklearn import tree\nclf = tree.DecisionTreeClassifier(max_depth = 5)\ndf_train['Sex_bin'] = df_train.Sex.apply(lambda x: 1 if x == \"female\" else 0)\n\ntrain = df_train[[\"Age\",\"Sex_bin\",\"Pclass\",\"Survived\"]]\nmedian_age = df_train[\"Age\"].median()\ntrain = train.fillna({\"Age\":median_age})\nclf = clf.fit(train[[\"Age\",\"Pclass\",\"Sex_bin\"]].values,train[\"Survived\"].values)\n","209e9784":"print('Importance des variables: ')\nfor i, feat in enumerate([\"Age\",\"Pclass\",\"Sex_bin\"]):\n    print(f\"{feat} : {round(clf.feature_importances_[i] * 100, 2)} %\")","335a27f8":"np.mean(clf.predict(train[[\"Age\",\"Pclass\",\"Sex_bin\"]].values) == train[\"Survived\"])","83188615":"#Quelques exemples de noms\ndf_train[\"Name\"].head()","6a6fe006":"#On r\u00e9cup\u00e8re uniquement le titre via une regexp\ndf_train['Title'] = df_train.Name.apply(lambda x: re.search(' ([A-Z][a-z]+)\\.', x).group(1))\n\nplt.figure(figsize=(12,5))\n\n#On plot les fr\u00e9quences des titres\nsns.countplot(x='Title', data=df_train, palette=\"hls\")\nplt.xlabel(\"Title\", fontsize=16)\nplt.ylabel(\"Count\", fontsize=16)\nplt.title(\"Title Count\", fontsize=20)\nplt.xticks(rotation=45)\nplt.show()","87101326":"#On fait la m\u00eame chose sur l'ensemble de test \ndf_test['Title'] = df_test.Name.apply(lambda x: re.search(' ([A-Z][a-z]+)\\.', x).group(1))","1ff54a9b":"Title_Dictionary = {\n        \"Capt\":       \"Off\",\n        \"Col\":        \"Off\",\n        \"Major\":      \"Off\",\n        \"Dr\":         \"Dr\",\n        \"Rev\":        \"Fai\",\n        \"Jonkheer\":   \"Roy\",\n        \"Don\":        \"Roy\",\n        \"Sir\" :       \"Roy\",\n        \"the Countess\":\"Roy\",\n        \"Dona\":       \"Roy\",\n        \"Lady\" :      \"Roy\",\n        \"Mme\":        \"Mrs\",\n        \"Ms\":         \"Mrs\",\n        \"Mrs\" :       \"Mrs\",\n        \"Mlle\":       \"Miss\",\n        \"Miss\" :      \"Miss\",\n        \"Mr\" :        \"Mr\",\n        \"Master\" :    \"Master\"\n                   }\n    \n# we map each title to correct category\ndf_train['Title'] = df_train.Title.map(Title_Dictionary)\ndf_test['Title'] = df_test.Title.map(Title_Dictionary)","3a80b7a9":"print(df_train.groupby(\"Title\")[\"Survived\"].mean())\nprint(df_train[\"Title\"].unique())\nplt.figure(figsize=(12,5))\n#Plotting the results\nsns.countplot(x='Title', data=df_train, palette=\"hls\",hue=\"Survived\")\nplt.xlabel(\"Titles\", fontsize=16)\nplt.ylabel(\"Count\", fontsize=16)\nplt.title(\"Title Grouped Count\", fontsize=20)\nplt.xticks(rotation=45)\nplt.show()","b610fca5":"#Looking the Fare distribution to survivors and not survivors\nplt.figure(figsize=(12,5))\nprint(df_train.Fare.describe())\nsns.distplot(df_train[df_train.Survived == 0][\"Fare\"], \n             bins=50, color='r')\nsns.distplot(df_train[df_train.Survived == 1][\"Fare\"], \n             bins=50, color='g')\nplt.title(\"Fare Distribution by Survived\", fontsize=20)\nplt.xlabel(\"Fare\", fontsize=15)\nplt.ylabel(\"Density\",fontsize=15)\nplt.show()\n","1175a137":"df_train[df_train[\"Fare\"]<=10].Survived.value_counts()","80be63b0":"#On remplace les valeurs NaN par un placeholder\ndf_train.Fare = df_train.Fare.fillna(-4)\ndf_test.Fare = df_test.Fare.fillna(-4)\n\n\n\n#On va cat\u00e9goriser la variable en fonction de ses quantiles\nquant = (-4, -0.5, 2, 8, 15, 31, 600)\nlabel_quants = ['NoInf','zero' , 'quart_1', 'quart_2', 'quart_3', 'quart_4']\n\n#doing the cut in fare and puting in a new column\ndf_train[\"Fare_cat\"] = pd.cut(df_train.Fare, quant, labels=label_quants)\n\nplt.figure(figsize=(12,5))\n\n#Plotting the new feature\nsns.countplot(x=\"Fare_cat\", hue=\"Survived\", data=df_train, palette=\"hls\")\nplt.title(\"Count of survived wrt Fare expending\",fontsize=20)\nplt.xlabel(\"Fare Cat\",fontsize=15)\nplt.ylabel(\"Count\",fontsize=15)\n\nplt.show()\n\n# Replicate the same to df_test\n\n\nquant = (-4, -0.5, 2, 8, 15, 31, 600)\nlabel_quants = ['NoInf','zero' , 'quart_1', 'quart_2', 'quart_3', 'quart_4']\n\ndf_test[\"Fare_cat\"] = pd.cut(df_test.Fare, quant, labels=label_quants)","1b3f9b58":"#rappel de la distribution \nage_high_zero_died = df_train[(df_train[\"Age\"] > 0) & \n                              (df_train[\"Survived\"] == 0)]\nage_high_zero_surv = df_train[(df_train[\"Age\"] > 0) & \n                              (df_train[\"Survived\"] == 1)]\nplt.figure(figsize=(10,5))\n\nsns.distplot(age_high_zero_surv[\"Age\"], bins=24, color='g')\nsns.distplot(age_high_zero_died[\"Age\"], bins=24, color='r')\nplt.title(\"Distribution and density by Age\",fontsize=20)\nplt.xlabel(\"Age\",fontsize=15)\nplt.ylabel(\"Distribution Died and Survived\",fontsize=15)\nplt.show()","c7d8d7ae":"#On va utiliser les variables Sex, Fare_cat, Pclass & Title que l'on vient de cr\u00e9er\n\nage_group = df_train.groupby([\"Sex\",\"Fare_cat\",\"Pclass\",\"Title\"])[\"Age\"]\n","ed68d01d":"#Imputation des valeurs NaN de l'age par les m\u00e9dianes des cat\u00e9gories\ndf_train.loc[df_train.Age.isnull(), 'Age'] = df_train.groupby([\"Sex\", \"Fare_cat\",'Pclass','Title']).Age.transform('median')\ndf_test.loc[df_test.Age.isnull(), 'Age'] = df_train.groupby([\"Sex\", \"Fare_cat\",'Pclass','Title']).Age.transform('median')\n\nprint(df_train[\"Age\"].isnull().sum())\nprint(df_test[\"Age\"].isnull().sum())","7699f46c":"#il y a encore 8 & 1 entr\u00e9es pour lesquelles nous n'avions pas de correspondance, \n#on va donc faire l'imputation sur ces entr\u00e9es avec Sex, Pclass & Title\ndf_train.loc[df_train.Age.isnull(), 'Age'] = df_train.groupby([\"Sex\", 'Pclass','Title']).Age.transform('median')\ndf_test.loc[df_test.Age.isnull(), 'Age'] = df_train.groupby([\"Sex\", 'Pclass','Title']).Age.transform('median')\nprint(df_train[\"Age\"].isnull().sum())\nprint(df_test[\"Age\"].isnull().sum())","69901f99":"#Voyons le r\u00e9sultat\n\nplt.figure(figsize=(12,5))\nsns.distplot(df_train[\"Age\"], bins=24)\nplt.title(\"Distribution and density by Age\")\nplt.xlabel(\"Age\")\nplt.show()","f9337e18":"#S\u00e9paration survived \/ rip\nplt.figure(figsize=(12,5))\n\ng = sns.FacetGrid(df_train, col='Survived',size=5)\ng = g.map(sns.distplot, \"Age\")\nplt.show()","d3e39660":"interval = (0, 5, 12, 18, 25, 35, 60, 120)\ncats = ['baby', 'Child', 'Teen', 'Student', 'Young', 'Adult', 'Senior']\n\ndf_train[\"Age_cat\"] = pd.cut(df_train.Age, interval, labels=cats)\n\ndf_train[\"Age_cat\"].head()","af5cde23":"#On fait la m\u00eame chose sur df_test\ninterval = (0, 5, 12, 18, 25, 35, 60, 120)\ncats = ['babies', 'Children', 'Teen', 'Student', 'Young', 'Adult', 'Senior']\n\ndf_test[\"Age_cat\"] = pd.cut(df_test.Age, interval, labels=cats)","fe4227b9":"#Ca donne quoi ?\nplt.figure(figsize=(12,5))\nsns.countplot(\"Age_cat\",data=df_train,hue=\"Survived\", palette=\"hls\")\nplt.xlabel(\"Categories names\", fontsize=15)\nplt.xlabel(\"Count\", fontsize=15)\nplt.title(\"Age Distribution \", fontsize=20)\nplt.show()","d7165d62":"# Distribution de la variable Pclass\nprint(pd.crosstab(df_train.Pclass, df_train.Embarked))\n\nplt.figure(figsize=(12,5))\n\nsns.countplot(x=\"Embarked\", data=df_train, hue=\"Pclass\",palette=\"hls\")\nplt.title('Embarked x Pclass Count', fontsize=20)\nplt.xlabel('Embarked with PClass',fontsize=15)\nplt.ylabel('Count', fontsize=15)\n\nplt.show()","c7a81da3":"#Il y a des valeurs manquantes dans Embarked, vu la sur-repr\u00e9sentation de S (Southampton) on peut remplacer les NA par S\ndf_train[\"Embarked\"] = df_train[\"Embarked\"].fillna('S')\ndf_test[\"Embarked\"] = df_test[\"Embarked\"].fillna('S')","2233de8d":"# Relation entre Embarked & Survived\nprint(pd.crosstab(df_train.Survived, df_train.Embarked))\n\nplt.figure(figsize=(12,5))\n\nsns.countplot(x=\"Embarked\", data=df_train, hue=\"Survived\",palette=\"hls\")\nplt.title('Class Distribution by survived or not',fontsize=20)\nplt.xlabel('Embarked',fontsize=15)\nplt.ylabel('Count', fontsize=15)\n\nplt.show()","ffea9e07":"# Survived vs Pclass\nprint(pd.crosstab(df_train.Survived, df_train.Pclass))\n\nplt.figure(figsize=(12,5))\n\nsns.countplot(x=\"Pclass\", data=df_train, hue=\"Survived\",palette=\"hls\")\nplt.xlabel('PClass',fontsize=15)\nplt.ylabel('Count', fontsize=15)\nplt.title('Class Distribution by Survived or not', fontsize=20)\n\nplt.show()","78a38bf2":"g = sns.factorplot(x=\"SibSp\",y=\"Survived\",data=df_train,kind=\"bar\", size = 5, aspect= 1.6, palette = \"hls\")\ng.set_ylabels(\"Probability(Survive)\", fontsize=15)\ng.set_xlabels(\"SibSp Number\", fontsize=15)\n\nplt.show()\n","1ef5a00c":"# \ng  = sns.factorplot(x=\"Parch\",y=\"Survived\",data=df_train, kind=\"bar\", size = 6,palette = \"hls\")\ng = g.set_ylabels(\"survival probability\")","d5570c6f":"#Nouvelle colonne, FSize = Parch+SibSp+1\ndf_train[\"FSize\"] = df_train[\"Parch\"] + df_train[\"SibSp\"] + 1\n\ndf_test[\"FSize\"] = df_test[\"Parch\"] + df_test[\"SibSp\"] + 1","37c72904":"print(pd.crosstab(df_train.FSize, df_train.Survived))\nsns.factorplot(x=\"FSize\",y=\"Survived\", data=df_train, kind=\"bar\",size=6, aspect=1.6)\nplt.show()","3ca2777f":"df_train.head()","67b6c2c1":"del df_train[\"Name\"]\ndel df_train[\"SibSp\"]\ndel df_train[\"Parch\"]\ndel df_train[\"Ticket\"]\ndel df_train[\"Fare\"]\ndel df_train[\"Cabin\"]\ndel df_train[\"Sex_bin\"]\n\ndel df_test[\"Name\"]\ndel df_test[\"SibSp\"]\ndel df_test[\"Parch\"]\ndel df_test[\"Ticket\"]\ndel df_test[\"Fare\"]\ndel df_test[\"Cabin\"]\n\n#OHE\n\ndf_train = pd.get_dummies(df_train, columns=[\"Sex\",\"Embarked\",\"Age_cat\",\"Fare_cat\",\"Title\"],\\\n                          prefix=[\"Sex\",\"Emb\",\"Age\",\"Fare\",\"Prefix\"], drop_first=True)\n\ndf_test = pd.get_dummies(df_test, columns=[\"Sex\",\"Embarked\",\"Age_cat\",\"Fare_cat\",\"Title\"],\\\n                         prefix=[\"Sex\",\"Emb\",\"Age\",\"Fare\",\"Prefix\"], drop_first=True)","185ec93b":"df_train.columns","26ac12dc":"#On peut regarder une matrice de correlation globale\nplt.figure(figsize=(15,12))\nplt.title('Correlation of Features for Train Set')\nsns.heatmap(df_train.astype(float).corr(),vmax=1.0,  annot=True)\nplt.show()","bd0b1b10":"df_train.head()","52082511":"X_train = df_train.drop([\"Survived\",\"PassengerId\"],axis=1).values\ny_train = df_train[\"Survived\"].values","1703b85e":"# On centre-r\u00e9duit les variables pour qu'elles soient toutes sur la m\u00eame \u00e9chelle\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)","aeadefe4":"from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier(max_depth = 15, n_estimators = 100 )\nrfc = rfc.fit(X_train, y_train)\n\nres = rfc.predict(X_train)","7830d820":"np.mean(res == y_train)","aac6eced":"from sklearn.model_selection import train_test_split","98932c7f":"train, valid = train_test_split(df_train, test_size=0.2, random_state=42)","1fbb1378":"print(train.shape)\nprint(valid.shape)","ad9861f8":"X_train = train.drop([\"Survived\",\"PassengerId\"],axis=1).values\ny_train = train[\"Survived\"].values\n\nX_valid = valid.drop([\"Survived\",\"PassengerId\"],axis=1).values\ny_valid = valid[\"Survived\"].values","f555d709":"rfc = RandomForestClassifier(max_depth = 4, n_estimators = 40, random_state = 42)\nrfc = rfc.fit(X_train, y_train)\n\nres_train = rfc.predict(X_train)\nres_valid = rfc.predict(X_valid)","f79e1ab8":"print(np.mean(res_train == y_train))\nprint(np.mean(res_valid == y_valid))","0a0eb22c":"rfc = RandomForestClassifier(max_depth = 7, n_estimators = 100, random_state = 42)\nrfc = rfc.fit(X_train, y_train)\n\nres_train = rfc.predict(X_train)\nres_valid = rfc.predict(X_valid)","ee1ec5dd":"print(np.mean(res_train == y_train))\nprint(np.mean(res_valid == y_valid))","7bb31663":"from sklearn.preprocessing import MinMaxScaler\n# Normalization X_train & X_valid\nscaler = MinMaxScaler()\nX_train_normalized = scaler.fit_transform(X_train)\nX_valid_normalized = scaler.transform(X_valid)  # On applique le m\u00eame scaler \u00e0 X_valid !!!\n# Il faut transformer y_train en \"dummies\" pour \ny_train_dummies = pd.get_dummies(y_train)\n\n# On r\u00e9cup\u00e8re l'ordre des classes\nlist_classes = list(y_train_dummies.columns)\ndict_classes = {i: col for i, col in enumerate(list_classes)}","6d15c7e7":"y_train_dummies","641b992c":"from tensorflow.keras.layers import (ReLU, ELU, BatchNormalization,\n                                     Dense, Dropout)\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.utils import plot_model\n\n\nimport tensorflow as tf\ntf.config.run_functions_eagerly(True)\n\n# Get input\/output dimensions\ninput_dim = X_train_normalized.shape[1]\nnum_classes = 2\n\n# Create model\nmodel = Sequential()\nmodel.add(Dense(40, activation='relu', input_shape=(input_dim,)))\nmodel.add(Dense(20, activation='relu', input_shape=(input_dim,)))\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# Compile model\noptimizer = Adam(lr=0.001, decay=0.0)\nloss = 'categorical_crossentropy'\nmetrics = ['accuracy']\nmodel.compile(optimizer=optimizer, loss=loss, metrics=metrics)\nplot_model(model)\nmodel.summary()","6837f3c1":"batch_size = 32\nepochs = 20\nvalidation_split = 0.2\n\n\ncallbacks = [EarlyStopping(monitor=\"val_accuracy\", patience=7, mode='max', restore_best_weights=True)]\n\n# Apprentissage\nfit_history = model.fit(\n    X_train_normalized,\n    y_train_dummies,\n    batch_size=batch_size,\n    epochs=epochs,\n    validation_split=validation_split,\n    callbacks=callbacks,\n    verbose=1,\n)","c7ecc567":"predicted_probas_train = model.predict(X_train_normalized)\nres_train = np.vectorize(lambda x: dict_classes[x])(predicted_probas_train.argmax(axis=-1))\npredicted_probas_valid = model.predict(X_valid_normalized)\nres_valid = np.vectorize(lambda x: dict_classes[x])(predicted_probas_valid.argmax(axis=-1))","b2d4541a":"print(np.mean(res_train == y_train))\nprint(np.mean(res_valid == y_valid))","d0442573":"<p> On avance, essayons de tirer de l'information utile \u00e0 partir des autres variables. <\/p>","4ade9dcd":"En conclusion, le mod\u00e8le de Deep Learning ne donne pas de meilleurs r\u00e9sultats !  \nD'une mani\u00e8re g\u00e9n\u00e9rale, il y a une \"hype\" autour du Deep Learning, mais les mod\u00e8les classiques de Machine Leaning sont souvent tout aussi efficaces, voire meilleurs, principalement sur les donn\u00e9es tabulaires.  \nDe plus, les mod\u00e8les de Deep Learning sont tr\u00e8s souvent complexes et les pr\u00e9dictions difficilement interpr\u00e9tables par l'humain !","5a9acc09":"<p> Nous allons s\u00e9parer notre fichier d'entrainement en deux fichiers, un fichier qui continuera \u00e0 servir pour l'entra\u00eenement et un fichier qui va nous servir pour tester la performance du mod\u00e8le. <\/p>","ae194824":"?","c70aef82":"### Ex\u00e9cuter le nouvel arbre de d\u00e9cision ! \u00e0 r\u00e9aliser !","5a00e5ef":"<h2>Description du sujet: <\/h2>\nLe naufrage du Titanic est l'un des naufrages les plus c\u00e9l\u00e8bres de l'histoire. Le 15 Avril 1912, durant son voyage inaugural, le titanic a coul\u00e9 apr\u00e8s une collision avec un iceberg, tuant 1502 de ses 2224 passagers et members d'\u00e9quipage. Cette trag\u00e9die a choqu\u00e9 la communaut\u00e9 internationale et a entra\u00een\u00e9 un durcissement des r\u00e9gulations de s\u00e9curit\u00e9s pour les paquebots.\n\nL'une des raisons principales de ce terrible bilan humain vient du fait qu'il n'y avait pas suffisamment de canots de sauvetage pour tout le monde. Bien qu'une part de chance ait jou\u00e9, certains groupes de personnes avaient plus de chances de s'en sortir que les autres.\n\n<h2>Un peu de **roleplay**:<\/h2> \nNous sommes missionn\u00e9s par la Royal Assurance (assureur du Titanic). De plus en plus de gens demandent des d\u00e9domagements pour la disparition d'un de leurs proches lors de ce drame mais leur listing est incomplet; ils sont incapables de savoir si certaines personnes ont r\u00e9ellement disparu.\n\nNotre objectif est simple: utiliser le listing existant pour d\u00e9velopper un algorithme permettant de pr\u00e9dire si une personne qui ne figure pas sur le listing a surv\u00e9cu ou non. ","8fdf31e4":"<p> Pour terminer l'analyse, on peut se pencher sur les variables SibSp & Parch: les survivants se sont peut \u00eatre \"\u00e9chapp\u00e9s\" en famille <\/p>","01bd2567":"On va \u00e9galement essay\u00e9 d'\u00eatre plus malin avec notre variable \"age\" en rempla\u00e7ant les valeurs manquantes par autre chose que la valeur m\u00e9diane de toute la population.","c2c3dbe2":"---","812fb3ad":"<h2> Acquisition des donn\u00e9es<\/h2>\nOn est dans un cadre facile, la Royal Assurance (mm.. Kaggle) nous a fournit deux fichiers csv : train.csv (pour entra\u00eener le mod\u00e8le) et test.csv pour les soumissions.\nIls nous ont \u00e9galement fourni le dictionnaire suivant :    ","752992c1":"<h2> Random forests <\/h2>\nUne combinaison d'arbres de d\u00e9cision simples qui vont \"voter\".","f79ece77":"<p> Attaquons-nous maintenant \u00e0 la variable Embarked; qui d\u00e9crit le port o\u00f9 la personne a embarqu\u00e9. Peut \u00eatre que les cabines \u00e9taient remplies en FIFO et que les gens plus loins\/plus proches des escaliers avaient moins de chances de s'en sortir ? <\/p>","4f23f72f":"On commence par normaliser les entr\u00e9es, et modifier la cible pour l'adapter aux r\u00e9seaux de neurones.","92c9bdbb":"<p> On va d\u00e9sormais s'attaquer \u00e0 la variable Fare qui contient le tarif que la personne a pay\u00e9. <\/p>","a104fc94":"<p> On r\u00e9entraine le mod\u00e8le sur le nouveau jeu d'entra\u00eenement et on peut calculer les performances sur le jeu de validation <\/p>","9b7d912e":"Et \u00e7a donne quoi niveau r\u00e9sultat ?","3e50a3ae":"<p> On peut utiliser un arbre de d\u00e9cision qui va faire \u00e7a tout seul. <\/p>","256a72be":"<p> Les noms sont au format Nom_famille, Titre, Pr\u00e9noms. Les titres peuvent peut \u00eatre nous en dire plus sur les passagers ? <\/p>","67e7c970":"<p> On peut d\u00e9sormais regarder si cette cat\u00e9gorisation \"manuelle\" fait \u00e9merger diff\u00e9rentes chances de survie <\/p>","64afcc11":"?","0d722c43":"?","61c77d73":"Pour compl\u00e9ter notre introduction \u00e0 la Data Science, nous avons fait une rapide pr\u00e9sentation du Deep Learning.  \nDans cette partie, nous pr\u00e9sentons brievement comment d\u00e9finir et entrainer un mod\u00e8le pour le probl\u00e8me du titanic.  ","57f6ceec":"?","0d362364":"<h3>Premier aper\u00e7u des donn\u00e9es<\/h3><br>","e8c86f46":"<p> On est dans un environnement Data Science, on va quand m\u00eame pas regarder du texte ?! <\/p>","ddf65d52":"<h2>Data Preparation<\/h2><br>\n<h3>Libs<\/h3><br>\n","6fa45c7d":"<p> On peut combiner ces deux informations en une nouvelle colonne \"Family size\" <\/p>","412fd162":"<p> Mieux vallait voyager \u00e0 2 ou 3 ? <\/p>","0a3c5801":"<p> C'est un bon d\u00e9but mais on doit pouvoir faire mieux. On peut faire varier l'age ? Mais on ne va quand m\u00eame pas tester toutes les valeurs \u00e0 la main ... <p>\n<p> En plus de \u00e7a il nous reste encore 8 colonnes qui, intuivivement doivent pouvoir nous aider \u00e0 am\u00e9liorer le r\u00e9sultat (1ere classe > 2e classe > 3e classe; fare ~ change de survie, etc..)<\/p>\n<p> Quelqu'un veut faire le block if...else de 300 lignes ? Et comment on choisit les bornes comme l'age ?<\/p>\n\n<p> ","bf95fb6a":"<h2>Mod\u00e9lisation & hypoth\u00e8ses<\/h2>\nOn commence \u00e0 comprendre \u00e0 quoi ressemblent les donn\u00e9es et il est temps de formuler une premi\u00e8re hypoth\u00e8se. <b>Des id\u00e9es<\/b> ?\n","315e849a":"<h2> A l'attaque de la variable \"Name\"<\/h2>","85c3d9cf":"<b>Comme on l'a d\u00e9j\u00e0 vu au d\u00e9but de ce notebook, le film \u00e9tait dans le vrai, les gens de la 3e classe avaient peu de chances de s'en sortir.<\/b>","565f70f9":"<p> On regroupe ensuite les titres dont la \"s\u00e9mantique\" nous semble proche <\/p>","0483ae2b":"<h2> Modelling post feature engineering <\/h2>","a57a9910":"<p> Il y a un gros spike de \"mortalit\u00e9\" autour des billets les moins chers.<\/p>","b87defb5":"Now we might have information enough to think about the model structure","e0a2876a":"## (Optionnel) Quid du Deep Learning ?","8818a75d":"<p> On voit que les distributions ne sont pas du tout \u00e9quivalentes. On va pouvoir cat\u00e9goriser les ages; encore une fois pour guider l'algorithme d'apprentissage.<\/p>","c5f35f91":"<h1> A la rescousse des passagers du Titanic! <\/h1>\n<h2> Ce notebook couvre les \u00e9tapes d'un projet data science autour de donn\u00e9es relative \u00e0 la survie ou non des passagers du Titanic <\/h2><br>\nCe notebook est grandement inspir\u00e9 des notebooks pr\u00e9sents sur la comp\u00e9tition Titanic.<br>\nThis notebook is higlihly inspired\/copied from notebooks on the Kaggle competition.\n","f4a0ae56":"<h2> On arr\u00eate de tricher !!!!<\/h2>","95b22b63":"---","a05fa1cc":"---","e9165c1d":"<p> Depuis tout \u00e0 l'heure, on fait nos tests sur notre dataset d'entra\u00eenement. Mais c'est de la \"triche\" puisque ce sont des donn\u00e9es que le mod\u00e8le a d\u00e9j\u00e0 vu lors de son entra\u00eenement. Pour se faire une r\u00e9elle id\u00e9e des performances de notre mod\u00e8le, nous allons cr\u00e9er un fichier de test. <\/p>","c412b0f2":"<h2>Data Understanding<\/h2><br>\n<p>La Royal insurance fait bien les choses, les donn\u00e9es sont au format tabulaire avec des noms de colonnes clairs, accompagn\u00e9s d'une description ! <\/p>\n<b>survival<\/b>\tSurvival\t0 = No, 1 = Yes<br>\nBien \u00e9videmment, cette colonne n'est pr\u00e9sente que dans le dataset d'entra\u00eenement, Royal Assurance l'a gard\u00e9 pour elle pour le dataset de test pour voir si notre algorithme fonctionne vraiment. <br>\n<b>pclass<\/b>\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd<br>\n<b>sex<\/b>\tSex\t<br>\n<b>Age<\/b>\tAge in years\t<br>\n<b>sibsp<\/b>\t# of siblings \/ spouses aboard the Titanic\t<br>\n<b>parch<\/b>\t# of parents \/ children aboard the Titanic\t<br>\n<b>ticket<\/b>\tTicket number\t<br>\n<b>fare<\/b>\tPassenger fare\t<br>\n<b>cabin<\/b>\tCabin number\t<br>\n<b>embarked\t<\/b>Port of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton<br>\n<h3>Notes<\/h3><br>\n<b>pclass: <\/b>A proxy for socio-economic status (SES)<br>\n1st = Upper<br>\n2nd = Middle<br>\n3rd = Lower<br>\n<b>age: <\/b>Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br>\n<b>sibsp:<\/b> Number of siblings \/ spouses<br>\n- <b>Sibling <\/b>= brother, sister, stepbrother, stepsister<br>\n- <b>Spouse <\/b>= husband, wife (mistresses and fianc\u00e9s were ignored)<br>\n\n<b>parch: <\/b>Number of parents\/children<br>\n- <b>Parent<\/b> = mother, father<br>\n- <b>Child <\/b>= daughter, son, stepdaughter, stepson<br>\n\nCertains enfants voyageaient avec leur nounou, pour eux, parch = 0<br>"}}