{"cell_type":{"30ca81f9":"code","49dd6c29":"code","ce038ef0":"code","c7dad6fa":"code","d61123f8":"code","aafdf8cd":"code","502ec1d7":"code","50c75f85":"code","8eca94eb":"code","344bfbc9":"code","8403f789":"code","c1c61d7f":"code","5d9999a4":"code","fa093325":"code","2044fb1c":"code","e3090775":"code","ed02a73b":"code","622673d1":"code","a923b507":"code","e880156d":"code","54223e98":"code","c4d49858":"code","799adfba":"code","ee44bc74":"code","51bd49ff":"code","0605794a":"code","73efe963":"code","d8f8870b":"code","2b16dac2":"code","1f8cfac1":"code","6d145493":"code","b88f2775":"code","110e51fb":"code","c90d580b":"code","be9f8bb6":"code","d8c5da6f":"code","8b8a8f60":"code","4883bd7f":"code","6d2876a5":"code","fca2fa0d":"code","38012751":"code","9948212d":"code","afbc3381":"code","d8bcc7f1":"code","4a9dcc1b":"code","df007492":"code","35e8a0da":"code","622d8c7d":"code","ad360105":"code","c8e1acfd":"code","45ed9af2":"code","03cd2976":"code","bf55613c":"code","68554e27":"code","e9ebea58":"code","c2ccee22":"code","13419c1c":"code","44cd10bd":"code","c425eaf9":"code","70553b05":"code","ae7db661":"code","0843c11b":"code","355ca656":"code","a8ccba89":"code","af2ab27f":"code","d8591165":"code","26b2bd00":"code","a610cd84":"code","f8d3bba8":"code","482b6b46":"code","12b5f3b3":"code","0879f1c2":"code","d5b0d4d9":"code","127f74c7":"code","0858b10b":"code","85ae79ce":"code","2bd471be":"code","c5e2d381":"code","bd877023":"code","f9151c77":"code","91393485":"code","193f0594":"code","9af6a88a":"code","92399856":"code","33f14b8a":"code","b1f02ee5":"markdown","e784b317":"markdown","a78f28b1":"markdown","a81e0cf3":"markdown","af460fe0":"markdown","4478d6bb":"markdown","e5250027":"markdown","fddc8277":"markdown","4d42069e":"markdown","8bc4ed3a":"markdown","9a008e0e":"markdown","fa51e846":"markdown","1f5405cb":"markdown","b9dff643":"markdown","bb8356ec":"markdown","f629c427":"markdown","d031f858":"markdown","209c435e":"markdown","00f6675a":"markdown","8488220d":"markdown","a27a6932":"markdown","987ced42":"markdown","b1548ea9":"markdown","9c2b8563":"markdown","b98f06bd":"markdown","fff8ccd3":"markdown","a5c2d48c":"markdown","a61328eb":"markdown","e011adca":"markdown","75373a71":"markdown"},"source":{"30ca81f9":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","49dd6c29":"from pandasql import sqldf","ce038ef0":"from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","c7dad6fa":"data_train_all = pd.read_csv(\"..\/input\/train.csv\")\ndata_test_all=pd.read_csv(\"..\/input\/test.csv\")","d61123f8":"data_test_all_pred=pd.read_csv(\"..\/input\/test.csv\")      ## This dataframe will be used in the last . This Dataframe doesn't have much significance","aafdf8cd":"data_train_all.head()","502ec1d7":"data_train_all.info()","50c75f85":"data_test_all.info()","8eca94eb":"import re","344bfbc9":"data_train_all['Title']= data_train_all.Name.apply(lambda a:re.search(' ([A-Z][a-z]+)\\.',a).group(1))","8403f789":"data_test_all['Title'] = data_test_all.Name.apply(lambda a:re.search(' ([A-Z][a-z]+)\\.',a).group(1))","c1c61d7f":"data_train_all['Title'].head()","5d9999a4":"data_train_all.Title.value_counts()","fa093325":"data_test_all.Title.value_counts()","2044fb1c":"data_train_all['Title'] = data_train_all['Title'].replace(['Mlle','Ms'],'Miss')  \ndata_train_all['Title'] = data_train_all['Title'].replace('Mme','Mrs')\ndata_train_all['Title'] = data_train_all['Title'].replace(['Capt','Col','Major'],'Army')\ndata_train_all['Title'] = data_train_all['Title'].replace(['Countess','Don','Dona','Jonkheer','Lady','Sir'],'Noble')","e3090775":"data_test_all['Title'] = data_test_all['Title'].replace(['Mlle','Ms'],'Miss')  \ndata_test_all['Title'] = data_test_all['Title'].replace('Mme','Mrs')\ndata_test_all['Title'] = data_test_all['Title'].replace(['Capt','Col','Major'],'Army')\ndata_test_all['Title'] = data_test_all['Title'].replace(['Countess','Don','Dona','Jonkheer','Lady','Sir'],'Noble')","ed02a73b":"data_train_all['Title'].value_counts()","622673d1":"data_test_all['Title'].value_counts()","a923b507":"data_train_all=data_train_all.drop(columns='Ticket')  ## we could have also used (inplace= True) and then we need not do data_train _all= data_train_all.drop(xxxxxx)","e880156d":"data_test_all=data_test_all.drop(columns='Ticket')","54223e98":"f= lambda x: str(x)[0]","c4d49858":"data_train_all.Cabin=data_train_all.Cabin.apply(f)","799adfba":"data_train_all['Cabin']=data_train_all['Cabin'].replace(['T'],'n')","ee44bc74":"data_test_all.Cabin=data_test_all.Cabin.apply(f)","51bd49ff":"data_train_all.Cabin.value_counts()","0605794a":"data_test_all.Cabin.value_counts()","73efe963":"data_train_all.groupby(['Cabin'])['Survived'].sum()","d8f8870b":"data_train_all.groupby(['Sex'])['Age'].median()","2b16dac2":"data_train_all.Age.median()","1f8cfac1":"data_train_all.groupby(['Pclass']).Age.mean()","6d145493":"## we will be replaceing Age by median value","b88f2775":"data_train_all.Age=data_train_all.Age.fillna(data_train_all.Age.median())","110e51fb":"data_test_all.Age=data_test_all.Age.fillna(data_train_all.Age.median())","c90d580b":"# Binning by quantile\n#data_train_all.Age=pd.qcut(data_train_all.Age, q=4, labels=False)","be9f8bb6":"# Binning by fixed Interval","d8c5da6f":"data_train_all.Age=pd.cut(data_train_all.Age, bins=[0,20,40,60,80,100],right=True, labels=False, retbins=0, include_lowest=1)","8b8a8f60":"data_test_all.Age=pd.cut(data_test_all.Age, bins=[0,20,40,60,80,100],right=True, labels=False, retbins=0, include_lowest=1)","4883bd7f":"data_test_all.Age.hist()","6d2876a5":"data_train_all.Fare.min()","fca2fa0d":"data_train_all.Fare=pd.cut(data_train_all.Fare, bins=[0,10,20,30,40,50,100,600],right=True, labels=False, retbins=0, include_lowest=1)","38012751":"data_train_all.Fare.value_counts()","9948212d":"data_train_all.Fare.hist(bins=20)","afbc3381":"data_test_all.Fare=pd.cut(data_test_all.Fare, bins=[0,10,20,30,40,50,100,600],right=True, labels=False, retbins=0, include_lowest=1)","d8bcc7f1":"data_test_all.Fare.hist(bins=20)","4a9dcc1b":"data_train_all.info()","df007492":"data_test_all.info()","35e8a0da":"### Missing Value Treatment of Column Fare in Test Set","622d8c7d":"data_test_all.Fare.fillna(0,inplace=True)","ad360105":"data_test_all.Fare.value_counts()","c8e1acfd":"data_train_all.Embarked.value_counts()","45ed9af2":"data_train_all.Embarked.fillna('S', inplace=True)","03cd2976":"data_train_all.drop(columns=['Name','PassengerId'],inplace=True)","bf55613c":"data_train_all.head()","68554e27":"data_test_all.drop(columns=['Name','PassengerId'],inplace=True)","e9ebea58":"data_test_all.info()","c2ccee22":"type(data_train_all.Title[2])","13419c1c":"## Create the dummy variables","44cd10bd":"data_train_all=pd.get_dummies(data_train_all,drop_first=False)  ## In case of categorical variable you dont need to drop one dummy variable.","c425eaf9":"data_test_all=pd.get_dummies(data_test_all,drop_first=False) ","70553b05":"data_train_all.head()","ae7db661":"data_test_all.head()","0843c11b":"data_train_all.info()","355ca656":"## Column Family","a8ccba89":"data_train_all['Family']=data_train_all['SibSp']+data_train_all['Parch']","af2ab27f":"data_test_all['Family']=data_test_all['SibSp']+data_test_all['Parch']","d8591165":"data_train_all.drop(columns=['SibSp','Parch'],inplace=True)\ndata_test_all.drop(columns=['SibSp','Parch'],inplace=True)","26b2bd00":"data_test_all.Family.value_counts()","a610cd84":"data_test_all.info()","f8d3bba8":"data_train_all.Fare=data_train_all.Fare.astype(float)","482b6b46":"data_train_all.info()","12b5f3b3":"import h2o\nh2o.init()","0879f1c2":"data_train_h2o=h2o.H2OFrame(data_train_all)","d5b0d4d9":"data_test_h2o=h2o.H2OFrame(data_test_all)","127f74c7":"type(data_test_h2o)","0858b10b":"data_train_h2o['Survived']=data_train_h2o['Survived'].asfactor()    ## Converting Target Variable as Factor","85ae79ce":"from h2o.estimators.gbm import H2OGradientBoostingEstimator  # import gbm estimator","2bd471be":"model = H2OGradientBoostingEstimator(## more trees is better if the learning rate is small enough \n  ## here, use \"more than enough\" trees - we have early stopping\n  ntrees = 10000,                                                            \n\n  ## smaller learning rate is better (this is a good value for most datasets, but see below for annealing)\n  learn_rate = 0.01,                                                         \n\n  ## early stopping once the validation AUC doesn't improve by at least 0.01% for 5 consecutive scoring events\n  stopping_rounds = 5, stopping_tolerance = 1e-4, stopping_metric = \"AUC\", \n\n  ## sample 80% of rows per tree\n  sample_rate = 0.8,                                                       \n\n  ## sample 80% of columns per split\n  col_sample_rate = 0.8,                                                   \n\n  ## fix a random number generator seed for reproducibility\n  seed = 1234,                                                             \n\n  ## score every 10 trees to make early stopping reproducible (it depends on the scoring interval)\n  score_tree_interval = 10, nfolds=5, max_depth=3)   ## Instantiating the class","c5e2d381":"model.train(x=data_train_h2o.names[1:],y=data_train_h2o.names[0], training_frame=data_train_h2o, model_id=\"GBM_Titanic\",\n            validation_frame=data_train_h2o)","bd877023":"dir(model)","f9151c77":"model.cross_validation_metrics_summary()","91393485":"model.params","193f0594":"f=model.predict(test_data=data_test_h2o)","9af6a88a":"f=f.as_data_frame()             ## Converting Predicted Results to Python Dataframe","92399856":"submission_H2O = pd.DataFrame({'PassengerId':data_test_all_pred['PassengerId'],'Survived':f['predict']})","33f14b8a":"## submission_H2O.to_csv('D:\/Titanic\/Titanic Predictions_H2O.csv',index=False)","b1f02ee5":"# Basic Implementation of H2O Gradient Boosting for Classification on Titatnic DataSet","e784b317":"**Instantiate the H2OGradientBoostingEstimator Class as model with some important parameters **","a78f28b1":"**Check Model Parameters**","a81e0cf3":"Regular Expression","af460fe0":"Columns Age , Cabin and Embarked has missing Values in training data","4478d6bb":"**Predict the Target variable for the Test Set**","e5250027":"### Data Pre-Processing","fddc8277":"Group the titles of same types","4d42069e":"**Convert Data from Pandas Data Frame to H2O data Frame**","8bc4ed3a":"**NOTE : Always remember to convert the Target variable in training Data Set as Factor or categorical variable.\nElse the the H2O's GBM algorithm will not create a classification algorithm. **","9a008e0e":"**Train the model.**\n\nNote1: We are using train not fit as in scikit learn\n\nNote2: Since we are using N fold cross validation, and the size of data set being small; I am not spliting the the training set,\n instead, using the whole training set.\n    \nNote3: Will check the Bias and the Variance of the model from our N fold Cross Validation's mean and Std Dev of accuracy score.","fa51e846":"**Convert the H2O dataframe to pandas DataFrame**","1f5405cb":"# Part 2\n# Implementation of GBM in H2O.ai for predicting ","b9dff643":"**Import H2O in python **","bb8356ec":"**5 fold Cross Validation Score**\n\n\nNote: Important Metrics to be seen here are as follows:\n\n     1. Accuracy Metric   : the mean accuracy of the model is 83.8% and the std dev is 2.3%\n     2. auc Metric        : Mean AUC is 87% \n     \n     \n     From these metrics we can say that our model is fairly ok.\n     We can further improve it by parameter tuning.","f629c427":"#### Discretization of the Numeric columns : Fare","d031f858":"# Part 1","209c435e":"**Import H2O's GBM **","00f6675a":"**Check the type of the data after conversion **","8488220d":"## The First Part is Data Preprocessing & Feature Engineering and the Second Part is H2O-GBM implementation\n\n## Important Note:  You can leave the first part because the objective of this Notebook is to learn some implementation basics of H20.","a27a6932":"### Missing Value Treatment of the Column Embark in the Training Set.","987ced42":"#### Discretization of the Numeric columns : Age ","b1548ea9":"Columns Age, Cabin, Fare have Missing Values in Test Set.","9c2b8563":"# There are two ways of doing it\n1. Binning by quantiles.\n2. Fixed interval Binning","b98f06bd":"**Create the Submission file for the Kaggle.**","fff8ccd3":"Have a look at all the methods of the object 'model'","a5c2d48c":"##### Column: Age: Missing Value Treatment","a61328eb":"Column:Drop the Column Ticket","e011adca":"#### Column: Cabin: The Nan values in the Cabin column means that the passangers didnt had the cabin.","75373a71":"##### Column: Name : Feature Engineer Column 'Name'"}}