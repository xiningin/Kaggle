{"cell_type":{"83008fad":"code","d38ca76e":"code","3fcd1d86":"code","207647b6":"code","9e4f8b21":"code","2817e35f":"code","06b1809a":"code","f5be9a01":"code","18fc7cc9":"code","107fc3e7":"code","5ab68198":"code","a4121584":"code","9c2a77e7":"code","d38f9bfa":"code","00841f97":"code","7b0d12e0":"code","2c0a83f3":"code","232939a5":"code","cda8ce21":"code","2ee7f2ff":"code","fc089872":"code","c2474b1f":"code","9ed5a3b5":"code","5c6aab4d":"code","3dbc2b9b":"code","41a26a48":"code","fa6b05b1":"code","22dc3e06":"code","55e3082f":"code","2311d2c1":"code","f4234862":"code","f5d7184c":"code","3a3e8775":"code","15fc04f5":"code","78bedbfa":"code","17c20390":"code","b7760a71":"code","21f0212e":"code","000ce4f1":"code","f1d87469":"code","90d7485a":"code","e7fda9a4":"code","61700809":"code","ea0d98f9":"code","2ab669fb":"code","2db87b2a":"code","289ff44e":"code","0d47fe05":"code","4e5f4bd8":"code","958e562b":"code","0c541e19":"code","6adde704":"code","e40b1eaa":"code","310124fe":"code","6f9a622e":"code","340390de":"markdown","ac3a3a86":"markdown","c25c8d95":"markdown","caf57f87":"markdown","cf16a7c5":"markdown","0958b5f1":"markdown","2522f5a3":"markdown","77e28478":"markdown","e9ce5b98":"markdown","34b49791":"markdown","dbaefb58":"markdown","5ca81e93":"markdown","6ee91e1a":"markdown","d12672c1":"markdown","00ae85f0":"markdown","b2cb4df7":"markdown","76073a0c":"markdown","537b93cf":"markdown","7f617cc7":"markdown","e92328f9":"markdown","70da68d0":"markdown","e621166e":"markdown","36a26aa6":"markdown","6c601a67":"markdown","dade3d73":"markdown","5a92d2fe":"markdown","6265a384":"markdown","18afe72d":"markdown"},"source":{"83008fad":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\n\n#filter out warnings\nimport warnings \nwarnings.filterwarnings('ignore')\n\n#To style plots\nplt.style.use('fivethirtyeight')\n\n#cycle the colors\nfrom itertools import cycle\ncolor_cycle = cycle(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n\n#Get the kaggle input\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d38ca76e":"train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\ntrain.head()\nprint(train.shape)\nprint(test.shape)","3fcd1d86":"train.isnull().sum().sort_values(ascending=False)[0:20]","207647b6":"sns.heatmap(train.isnull(),yticklabels=False,cbar='BuPu')\n","9e4f8b21":"\ntrain.info()","2817e35f":"\n'''train['LotFrontage'] = train['LotFrontage'].fillna(train['LotFrontage'].mean)\ntrain.drop(['Alley'], axis = 1, inplace=True)\n\ntrain['BsmtCond']=train['BsmtCond'].fillna(train['BsmtCond'].mode()[0])\ntrain['BsmtQual']=train['BsmtQual'].fillna(train['BsmtQual'].mode()[0])\ntrain.drop(['PoolQC'], axis = 1, inplace=True)\ntrain.drop(['Fence'], axis = 1, inplace=True)    \ntrain.drop(['MiscFeature'], axis = 1, inplace=True)'''\n\n\n#clean the train data\nfor i in list(train.columns):\n    dtype = train[i].dtype\n    values = 0\n    if(dtype == float or dtype == int):\n        method = 'mean'\n    else:\n        method = 'mode'\n    if(train[i].notnull().sum() \/ 1460 <= .5):\n        train.drop(i, axis = 1, inplace=True)\n    elif method == 'mean':\n        train[i]=train[i].fillna(train[i].mean())\n\n    else:\n        train[i]=train[i].fillna(train[i].mode()[0])\n        print(train[i])\n\n\n#clean the test data\nfor i in list(test.columns):\n    dtype = test[i].dtype\n    values = 0\n    if(dtype == float or dtype == int):\n        method = 'mean'\n    else:\n        method = 'mode'\n    if(test[i].notnull().sum() \/ 1460 <= .5):\n        test.drop(i, axis = 1, inplace=True)\n    elif method == 'mean':\n        test[i]=test[i].fillna(test[i].mean())\n\n    else:\n        test[i]=test[i].fillna(test[i].mode()[0])\n\n\ntrain.head()\ntest.shape","06b1809a":"test.drop(columns=['Id'], inplace=True)\ntrain.dropna(inplace=True)\n\ntrain.drop(columns=['Id'], inplace=True)\nprint(train.shape)\nprint(test.shape)","f5be9a01":"train.isnull().any().any()\ntrain.head()\n#df1=pd.get_dummies(train['MSZoning'],drop_first=True)\n#print(df1)","18fc7cc9":"plt.figure(figsize=(15,5))\nplt.plot(train.SalePrice,linewidth=2,color=next(color_cycle))\nplt.title('Distribution Plot for Sales Prices')\nplt.ylabel('Sales Price');","107fc3e7":"#sort the values\nplt.figure(figsize=(15,5))\nplt.plot(train.SalePrice.sort_values().reset_index(drop=True),color=next(color_cycle))\nplt.title('Distribution Plot for Sales Prices')\nplt.ylabel('Sales Price');","5ab68198":"fig = px.scatter(train,x=train.index, y='SalePrice', labels={'x':'Index'},\n                 color=train.MSZoning, template=\"seaborn\",\n                 title='Sale Price distriution of MSZoning')\nfig.show()","a4121584":"fig = px.scatter(train,x=train.index, y='SalePrice', labels={'x':'Index'},\n                 color=train.Street, template=\"seaborn\",\n                 title='Sale Price distriution ---> Street')\nfig.show()","9c2a77e7":"plt.figure(figsize=(20,10))\n\nplt.subplot(2,2,1)\nplt.scatter(x=train[train.LotConfig == 'FR3'].index,\n           y=train[train.LotConfig == 'FR3'].SalePrice,color=next(color_cycle))\nplt.title('SalePrice distribution of FR3 value of LotConfig')\n\nplt.subplot(2,2,2)\nplt.scatter(x=train[train.LotConfig == 'CulDSac'].index,\n           y=train[train.LotConfig == 'CulDSac'].SalePrice,color=next(color_cycle))\nplt.title('SalePrice distribution of CulDSac value of LotConfig')\n\nplt.subplot(2,2,3)\nplt.scatter(x=train[train.LotConfig == 'Corner'].index,\n           y=train[train.LotConfig == 'Corner'].SalePrice,color=next(color_cycle))\nplt.title('SalePrice distribution of Corner value of LotConfig')\n\nplt.subplot(2,2,4)\nplt.scatter(x=train[train.LotConfig == 'FR2'].index,\n           y=train[train.LotConfig == 'FR2'].SalePrice,color=next(color_cycle))\nplt.title('SalePrice distribution of FR2 value of  LotConfig');","d38f9bfa":"columns = ['MSZoning', 'Street',\n       'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope',\n       'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', \n       'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n       'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n       'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n       'Heating', 'HeatingQC', 'CentralAir', 'Electrical',\n       'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish',\n       'GarageQual', 'GarageCond', 'PavedDrive', 'SaleType', 'SaleCondition']","00841f97":"\ntrain_test_data = pd.concat([train, test], axis = 0)\nprint(test.shape)\nprint(train.shape)\n\ntrain_test_data.head()\ntrain_test_data.shape","7b0d12e0":"def One_hot_encoding(columns):\n    df_final=train_test_data\n    i=0\n    for fields in columns:\n        df1=pd.get_dummies(train_test_data[fields],drop_first=True)\n        \n        train_test_data.drop([fields],axis=1,inplace=True)\n        if i==0:\n            df_final=df1.copy()\n        else:           \n            df_final=pd.concat([df_final,df1],axis=1)\n        i=i+1\n       \n        \n    df_final=pd.concat([train_test_data,df_final],axis=1)\n        \n    return df_final","2c0a83f3":"train_test_data = One_hot_encoding(columns)\nprint(train_test_data.shape)\ntrain_test_data.head()","232939a5":"train_test_data.columns.duplicated()\n","cda8ce21":"train_test_data =train_test_data.loc[:,~train_test_data.columns.duplicated()]\n\ntrain_test_data.shape","2ee7f2ff":"from scipy.stats import norm, skew\nfrom scipy import stats","fc089872":"sns.distplot(train['SalePrice'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(train['SalePrice'], plot=plt)","c2474b1f":"train[\"SalePrice\"] = np.log(train[\"SalePrice\"])\n","9ed5a3b5":"\nres = stats.probplot(train['SalePrice'], plot=plt)","5c6aab4d":"df_Train=train_test_data.iloc[:1460,:]\ndf_Test=train_test_data.iloc[1460:,:]\nprint(df_Test.shape)\n\ndf_Test.head()","3dbc2b9b":"df_Test.drop(['SalePrice'],axis=1,inplace=True)\nX_train_final=df_Train.drop(['SalePrice'],axis=1)\ny_train_final=df_Train['SalePrice']\nX_train_final.shape","41a26a48":"from sklearn.preprocessing import StandardScaler\n#make the data into a normal distrubition\n#mean = 0 \nX_std = StandardScaler().fit_transform(X_train_final)\n\nmy_columns = X_train_final.columns\nnew_df = pd.DataFrame(X_std, columns=my_columns)","fa6b05b1":"from sklearn.decomposition import PCA\npca = PCA(n_components = 2)\ndf_pca = pca.fit_transform(new_df)\nprint(df_pca)","22dc3e06":"plt.figure(figsize =(8, 6))\nplt.scatter(df_pca[:, 0], df_pca[:, 1], c = y_train_final, cmap ='plasma')\n# labeling x and y axes\nplt.xlabel('First Principal Component')\nplt.ylabel('Second Principal Component');","55e3082f":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n#split the data set into train and test\nX_train, X_test, y_train, y_test = train_test_split(X_train_final, y_train_final)\nlinreg = LinearRegression()\nlinreg.fit(X_train, y_train)\n\n#Accuracy\nprint(\"R-Squared Value for Training Set: \",linreg.score(X_train, y_train))\nprint(\"R-Squared Value for Test Set: \",linreg.score(X_test, y_test))","2311d2c1":"from sklearn.neighbors import KNeighborsRegressor\n\nknnreg = KNeighborsRegressor(n_neighbors = 2)\nknnreg.fit(X_train, y_train)\n\nprint('R-squared train score:',knnreg.score(X_train, y_train))\nprint('R-squared test score: ',knnreg.score(X_test, y_test))","f4234862":"from sklearn.linear_model import Ridge\nridge = Ridge()\nridge.fit(X_train, y_train)\nprint('R-squared train score:',ridge.score(X_train, y_train))\nprint('R-squared test score: ',ridge.score(X_test, y_test))","f5d7184c":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\n\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nridge = Ridge(alpha=20)\nridge.fit(X_train_scaled, y_train)\n\n\nprint('R-squared score (training): {:.3f}'.format(ridge.score(X_train_scaled, y_train)))\nprint('R-squared score (test): {:.3f}'.format(ridge.score(X_test_scaled, y_test)))","3a3e8775":"from sklearn.linear_model import Lasso\n\nlasso = Lasso(max_iter = 10000)\nlasso.fit(X_train, y_train)\n\nprint('R-squared score (training): {:.3f}'.format(lasso.score(X_train, y_train)))\nprint('R-squared score (test): {:.3f}'.format(lasso.score(X_test, y_test)))\n\nlasso = Lasso(alpha=100, max_iter = 10000)\nlasso.fit(X_train_scaled, y_train)\n\nprint('R-squared score (training): {:.3f}'.format(lasso.score(X_train_scaled, y_train)))\nprint('R-squared score (test): {:.3f}'.format(lasso.score(X_test_scaled, y_test)))\n","15fc04f5":"from sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\n\nlasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\nlasso.fit(X_train_scaled, y_train)\nprint('R-squared score (training): {:.3f}'.format(lasso.score(X_train_scaled, y_train)))\nprint('R-squared score (test): {:.3f}'.format(lasso.score(X_test_scaled, y_test)))\n","78bedbfa":"df_Test.head()","17c20390":"from sklearn.ensemble import GradientBoostingRegressor\nGBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n                                   max_depth=4, max_features='sqrt',\n                                   min_samples_leaf=15, min_samples_split=10, \n                                   loss='huber', random_state =5)\nGBoost.fit(X_train_final, y_train_final)\n\ny_pred = GBoost.predict(df_Test)\ny_pred","b7760a71":"from sklearn.ensemble import RandomForestClassifier\n\nregressor = RandomForestClassifier()\nregressor.fit(X_train_scaled, y_train)\nprint('R-squared score (training): {:.3f}'.format(regressor.score(X_train_scaled, y_train)))\nprint('R-squared score (test): {:.3f}'.format(regressor.score(X_test_scaled, y_test)))\n","21f0212e":"'''from sklearn.model_selection import RandomizedSearchCV\n\nn_estimators = [100,200, 300, 500,700, 900]\ncriterion = ['gini', 'entropy']\ndepth = [3,5,10,15]\nmin_split=[2,3,4]\nmin_leaf=[2,3,4]\nbootstrap = ['True', 'False']\nverbose = [5]\n\nhyperparameter_grid = {\n    'n_estimators': n_estimators,\n    'max_depth':depth,\n    'criterion':criterion,\n    'bootstrap':bootstrap,\n    'verbose':verbose,\n    'min_samples_split':min_split,\n    'min_samples_leaf':min_leaf\n    }\n\nrandom_cv = RandomizedSearchCV(estimator=regressor,\n                               param_distributions=hyperparameter_grid,\n                               cv=5, \n                               scoring = 'neg_mean_absolute_error',\n                               n_jobs = 4, \n                               return_train_score = True,\n                               random_state=42)'''\n","000ce4f1":"X_train_final","f1d87469":"#random_cv.fit(X_train_final,y_train_final)","90d7485a":"#random_cv.best_estimator_#","e7fda9a4":"regressor = RandomForestClassifier(bootstrap='False', max_depth=15, min_samples_leaf=4,n_estimators=900, verbose=5)\n#regressor.fit(X_train_final,y_train_final)","61700809":"#y_pred = regressor.predict(df_Test)\n#y_pred","ea0d98f9":"#prediction=pd.DataFrame(y_pred)\n#samp = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\n#print(samp['Id'])\n#sub = pd.concat([samp['Id'],prediction], axis=1)\n#sub.columns=['Id','SalePrice']\n","2ab669fb":"#print(sub)\n","2db87b2a":"#sub.to_csv('My_submission.csv',index=False)\n","289ff44e":"import xgboost\nregressor=xgboost.XGBRegressor()","0d47fe05":"'''n_estimators = [100, 500, 900, 1100, 1500]\nmax_depth = [2, 3, 5, 10, 15]\nbooster=['gbtree','gblinear']\nlearning_rate=[0.05,0.1,0.15,0.20]\nmin_child_weight=[1,2,3,4]\nbase_score=[0.25,0.5,0.75,1]\n\n# Define the grid of hyperparameters to search\nhyperparameter_grid = {\n    'n_estimators': n_estimators,\n    'max_depth':max_depth,\n    'learning_rate':learning_rate,\n    'min_child_weight':min_child_weight,\n    'booster':booster,\n    'base_score':base_score\n    }\nrandom_cv = RandomizedSearchCV(estimator=regressor,\n            param_distributions=hyperparameter_grid,\n            cv=5, n_iter=50,\n            scoring = 'neg_mean_absolute_error',n_jobs = 4,\n            verbose = 5, \n            return_train_score = True,\n            random_state=42)'''","4e5f4bd8":"#random_cv.fit(X_train_final,y_train_final)\n#andom_cv.best_estimator_","958e562b":"regressor = xgboost.XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n             importance_type='gain', interaction_constraints='',\n             learning_rate=0.1, max_delta_step=0, max_depth=2,\n             min_child_weight=1, missing=None, monotone_constraints='()',\n             n_estimators=900, n_jobs=0, num_parallel_tree=1, random_state=0,\n             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n             tree_method='exact', validate_parameters=1, verbosity=None)","0c541e19":"regressor.fit(X_train_final,y_train_final)","6adde704":"#y_pred = regressor.predict(df_Test)\n#y_pred","e40b1eaa":"pred=pd.DataFrame(y_pred)\nsamp = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\nsub = pd.concat([samp['Id'],pred], axis=1)\nsub.columns=['Id','SalePrice']","310124fe":"sub\n","6f9a622e":"sub.to_csv('My_sub1.csv',index=False)","340390de":"# **EDA**","ac3a3a86":"# **Missing Values**","c25c8d95":"**Hope you enjoyed the notebook! Please drop a upvote if this notebook helped you out!**\n\n**Have a great day, peace!**","caf57f87":"# **Ridge**","cf16a7c5":"**MS Zoning**","0958b5f1":"**We first need a few things imported...**","2522f5a3":"# **Normalization**","77e28478":"# **Regression**","e9ce5b98":"# **KNN Regression**","34b49791":"Lets do some modeling now!","dbaefb58":"# **XGBOOST**","5ca81e93":"**Basic Table of Contents**\n1. Data Cleaning\n2. PCA\n3. Modeling\n4. Lets TUNE our model! (XGBOOST) (RandomSearchCV)","6ee91e1a":"**To whom does this notebook appeal to?**\n* If you are just getting started and know some basic modeling strategies such as Regression and Classification, but want to increase your model accuracy a lot!\n* This notebook aims at basic EDA, Feature engineering, and most importantly HYPER PARAMATER TUNING! With **RANDOMSEARCHCV** and **XGBOOST**\n","d12672c1":"# **Lasso Regression**","00ae85f0":"Lets log the data, so that it can be linear.","b2cb4df7":"# **HyperTuning**","76073a0c":"# **PCA -- Principal Component Analysis**","537b93cf":"In this notebook, I am just going to scale the data, not making any new columns.","7f617cc7":"# **Lets get started!**","e92328f9":"Let's first take a look at the distrubution of house prices.","70da68d0":"Rearange the prices from lowest to highest.\n","e621166e":"[](https:\/\/a57.foxnews.com\/static.foxbusiness.com\/foxbusiness.com\/content\/uploads\/2020\/08\/1440\/810\/House-For-Sale-iStock.jpg?ve=1&tl=1)","36a26aa6":"# **Introduction**","6c601a67":"# **Catagorical Variables**\n","dade3d73":"![](https:\/\/a57.foxnews.com\/static.foxbusiness.com\/foxbusiness.com\/content\/uploads\/2020\/08\/1440\/810\/House-For-Sale-iStock.jpg?ve=1&tl=1)","5a92d2fe":"# **Feature Engineering**","6265a384":"***Greetings buyers, Welcome to the Housing Market!***","18afe72d":"# **MODELING**"}}