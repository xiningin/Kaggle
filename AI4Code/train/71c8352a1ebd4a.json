{"cell_type":{"c7c6cd5f":"code","ab611872":"code","293f4bb8":"code","4b3dbc2f":"code","cd9c0846":"code","99c3a397":"code","92c0b881":"code","4107ba20":"code","9e3de5dd":"code","1e690e5a":"code","f1e8b181":"code","75719313":"code","42679669":"code","04a18b85":"code","291e22e3":"code","268cc5f8":"code","7bedf48f":"code","474312b6":"code","40552804":"code","40e07a71":"code","aedc513e":"code","7adbc988":"code","55ea45dc":"code","af0758eb":"code","2375fbdb":"code","b89b63cd":"code","568fb900":"code","461916b8":"code","a6b21028":"code","29f0e2ce":"code","e41b1f01":"code","9888a1df":"code","cfb9c450":"code","a7f2641c":"code","d9ddb5d3":"code","665f0d31":"code","1d5e2dda":"code","73c6de7b":"code","f21582f2":"code","6bde7b42":"code","1a727de6":"code","161a4e51":"code","7ac5a164":"code","8fa43518":"code","c06ac855":"code","64d83850":"code","d2531fd2":"code","8f792377":"code","5607a431":"code","1c963b58":"code","39a33baf":"code","50a7edd5":"code","be840eb2":"code","dfa60d0f":"code","f7257556":"code","198814ba":"code","58642f8f":"code","b83d35fa":"code","bf5a97de":"code","d1a2ad43":"code","0df67422":"code","6310636e":"code","cb212ad2":"code","8dcb5dcd":"code","55e32a19":"code","063fe44a":"code","30340a9c":"code","fdc02c78":"code","f8ac9876":"code","3fb04679":"code","4aac85b9":"code","b5855762":"code","ac837540":"code","e9d715c0":"code","48b06eff":"code","cb61b4a8":"code","a0e37137":"code","cb7a8c4d":"code","df55fd45":"code","dd36e07b":"code","a580f1d1":"code","80322a40":"code","0447c14b":"code","006aff31":"code","fcc332c9":"code","318b6371":"code","48ed8236":"code","5579289d":"code","2e138a20":"code","6d9f7ef3":"code","2467f7da":"code","328396c9":"code","79031d3c":"code","369cfd5f":"code","43169460":"code","cbfebd04":"code","bf3cb80b":"code","0f70e2a7":"code","e149f24b":"code","8aa26c3f":"code","cbc1b441":"code","7ce5a9a3":"code","18fb9937":"code","06fed7e0":"code","6e4f5787":"code","694d6e46":"code","7184a0db":"code","2f91c724":"code","539d1874":"code","35331a1a":"code","de8daaed":"code","e14250af":"code","5daedfac":"code","e1866f7d":"code","6e384dd9":"code","3f0a9c77":"code","97812d22":"code","c0379bc3":"code","7d2f7997":"code","0ea8ea33":"code","f10af347":"code","649d2a0a":"code","6b412c83":"code","e539d328":"code","9ba4629e":"code","1bcf79c3":"code","ff65cecb":"code","a355a80c":"code","652d3e97":"code","5761fc23":"code","e0099a37":"code","ee47ad38":"code","6a50f000":"code","7d7a5eee":"code","2fd677ca":"code","dca49b5c":"markdown","0501afad":"markdown","c6b94093":"markdown","b84dd625":"markdown","f7e70faf":"markdown","59cc79e0":"markdown","db7696a1":"markdown","fdb84d0f":"markdown","1d377259":"markdown","eff951e4":"markdown","ba96b890":"markdown","37407dd5":"markdown","97a0f373":"markdown","c5c0d776":"markdown","93db8c55":"markdown","75d92ec4":"markdown","579fcc29":"markdown","72d89630":"markdown","13ff69dc":"markdown","3841f377":"markdown","feb618f7":"markdown"},"source":{"c7c6cd5f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ab611872":"# Import all Requiring Libraries\nimport os\nimport pandas as pd\nimport numpy as np\nimport requests\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\n\nfrom datetime import timedelta\n\n# Combining several CSV files\nfrom glob import glob \n\n# to get web contents\nimport json\nfrom urllib.request import urlopen\n\nimport holidays\n\nimport pycountry\nimport plotly.express as px\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\nfrom collections import namedtuple\n\n# for offline ploting\nfrom plotly.offline import plot, iplot, init_notebook_mode\ninit_notebook_mode(connected=True)\n\n# hide warnings\nimport warnings\nwarnings.simplefilter('ignore')","293f4bb8":"# Using glob function to combine several CSV files with same strucure at 2017 \nfiles = sorted (glob('\/kaggle\/input\/bikeshare-toronto-ridership-data-20172020\/Bikeshare 2017\/2017-Q*.csv'))\nfiles","4b3dbc2f":"# Using concat to combined all files and assign() methods\nY_2017 = pd.concat((pd.read_csv(file).assign(filename = file) for file in files), ignore_index = True)\nY_2017","cd9c0846":"# check unique file's names\nY_2017.filename.unique()","99c3a397":"# Modify file path to Y_2017 number.\nY_2017.filename = Y_2017.filename.str.replace('\/kaggle\/input\/bikeshare-toronto-ridership-data-20172020\/Bikeshare 2017\/', '')\nY_2017.filename = Y_2017.filename.str.replace('.csv', '')\n\nY_2017.head()","92c0b881":"# Change column \"filename to \"Quarter\"\nY_2017 = Y_2017.rename(columns = {'filename' :'Quarter'})\nY_2017.head()","4107ba20":"# Check Dataframe shape\nY_2017.shape","9e3de5dd":"# Check Dataframe info()\nY_2017.info()","1e690e5a":"# check Dataframe NULL values\nY_2017.isnull().sum()","f1e8b181":"# Found \"NULLNULL\" values\nY_2017.query('trip_stop_time == \"NULLNULL\"')","75719313":"# Drop Row's have NULLNULL Values\nY_2017 = Y_2017[Y_2017['trip_stop_time'] != 'NULLNULL']\nY_2017","42679669":"# Check \"NULLNULL\" values are droped\nY_2017.query('trip_stop_time == \"NULLNULL\"')","04a18b85":"# Check Dataframe NULL values\nY_2017.isnull().sum()","291e22e3":"# Select certian columns and add it at new DataFrame \"Y_17\"\nY_17 = Y_2017[['from_station_id','from_station_name']]\nY_17 = Y_17.rename(columns = {'from_station_id':'station_id','from_station_name':'station_name'})\nY_17","268cc5f8":"# Select certian columns and add it at new DataFrame \"Z_17\"\nZ_17 = Y_2017[['to_station_id','to_station_name']]\nZ_17 = Z_17.rename(columns = {'to_station_id':'station_id','to_station_name':'station_name'})\nZ_17","7bedf48f":"# Concatenate new Dtaframes \"Y_17 & Z_17\" at new Dtaframe \"X_17\"\nX_17 = pd.concat([Y_17,Z_17])\nX_17","474312b6":"# Check number of Unique values\nX_17.station_id.nunique()","40552804":"# Check Dataframe duplication\nX_17.duplicated().sum()","40e07a71":"# Drop douplication at X_17\nX_17 = X_17.drop_duplicates()\nX_17","aedc513e":"# Drop Row's have NULL Values in column \"station_id\"\nX_17 = X_17[pd.notnull(X_17['station_id'])]\nX_17","7adbc988":"# Merge 2 Dataframe \"X_17\" and \"Y_2017\"\nY_2017 = Y_2017.merge(X_17, left_on = 'from_station_name', right_on = 'station_name', how = 'left')\nY_2017","55ea45dc":"# Replace NUll Value in column \"from_station_id\" with data at column \"station_id\"\nY_2017['from_station_id'] = Y_2017.from_station_id.fillna(Y_2017.station_id)\n\n# Drop un-necessary columns\nY_2017 = Y_2017.drop(['station_id','station_name'], axis = 1)\n\n# check Dataframe NULL values\nY_2017.isnull().sum()","af0758eb":"# merge 2 Dataframe \"X_17\" and \"Y_2017\"\nY_2017 = Y_2017.merge(X_17, left_on = 'to_station_name', right_on = 'station_name', how = 'left')\nY_2017","2375fbdb":"# Replace NUll Value in column \"to_station_id\" with data at column \"station_id\"\nY_2017['to_station_id'] = Y_2017.to_station_id.fillna(Y_2017.station_id)\n\n# Drop un-necessary columns\nY_2017 = Y_2017.drop(['station_id','station_name'], axis = 1)\n\n# Check Dataframe NULL values\nY_2017.isnull().sum()","b89b63cd":"# save \"Y_2017\" dataframe in CSV format at new created folder(gathering_data)\nY_2017.to_csv('\/kaggle\/working\/Y_2017.csv', index=False)","568fb900":"## Using glob function to combine several CSV files with same strucure at 2018 \nfiles = sorted (glob('\/kaggle\/input\/bikeshare-toronto-ridership-data-20172020\/Bikeshare 2018\/2018-Q*.csv'))\nfiles","461916b8":"# Using concat to combined all files and assign() methods\nY_2018 = pd.concat((pd.read_csv(file).assign(filename = file) for file in files), ignore_index = True)\nY_2018","a6b21028":"# Check unique file's names\nY_2018.filename.unique()","29f0e2ce":"# Modify file path to Y_2018 number.\nY_2018.filename = Y_2018.filename.str.replace('\/kaggle\/input\/bikeshare-toronto-ridership-data-20172020\/Bikeshare 2018\/', '')\nY_2018.filename = Y_2018.filename.str.replace('.csv', '')\n\nY_2018.head()","e41b1f01":"# Change column \"filename to \"Quarter\"\nY_2018 = Y_2018.rename(columns = {'filename' :'Quarter'})\nY_2018.head()","9888a1df":"# Check Dataframe shape\nY_2018.shape","cfb9c450":"# Check Dataframe info()\nY_2018.info()","a7f2641c":"# Select certian columns and add it at new DataFrame \"Y_18\"\nY_18 = Y_2018[['from_station_id','from_station_name']]\nY_18 = Y_18.rename(columns = {'from_station_id':'station_id','from_station_name':'station_name'})\nY_18","d9ddb5d3":"# Select certian columns and add it at new DataFrame \"Z_18\"\nZ_18 = Y_2018[['to_station_id','to_station_name']]\nZ_18 = Z_18.rename(columns = {'to_station_id':'station_id','to_station_name':'station_name'})\nZ_18","665f0d31":"# Concatenate new Dtaframes \"Y_18 & Z_18\" at new Dtaframe \"X_18\"\nX_18 = pd.concat([Y_18,Z_18])\nX_18","1d5e2dda":"# Check number of Unique values\nX_18.station_id.nunique()","73c6de7b":"# check Dataframe duplication\nX_18.duplicated().sum()","f21582f2":"# Drop douplication at X_18\nX_18 = X_18.drop_duplicates()\nX_18","6bde7b42":"# Drop Row's have NULL Values\nX_18 = X_18.dropna(axis = 0)\nX_18","1a727de6":"# Check Dataframe NULL values\nY_2018.isnull().sum()","161a4e51":"# Check Dataframe duplication\nY_2018.duplicated().sum()","7ac5a164":"# save \"Y_2018\" dataframe in CSV format at new created folder(gathering_data)\nY_2018.to_csv('\/kaggle\/working\/Y_2018.csv', index=False)","8fa43518":"## Using glob function to combine several CSV files with same strucure at 2019 \nfiles = sorted (glob('\/kaggle\/input\/bikeshare-toronto-ridership-data-20172020\/Bikeshare 2019\/2019-Q*.csv'))\nfiles","c06ac855":"# Using concat to combined all files and assign() methods\nY_2019 = pd.concat((pd.read_csv(file).assign(filename = file) for file in files), ignore_index = True)\nY_2019","64d83850":"# Check unique file's names\nY_2019.filename.unique()","d2531fd2":"# Modify file path to Y_2019 number.\nY_2019.filename = Y_2019.filename.str.replace('\/kaggle\/input\/bikeshare-toronto-ridership-data-20172020\/Bikeshare 2019\/', '')\nY_2019.filename = Y_2019.filename.str.replace('.csv', '')\n\nY_2019.head()","8f792377":"# Change column \"filename to \"Quarter\"\nY_2019 = Y_2019.rename(columns = {'filename' :'Quarter'})\nY_2019.head()","5607a431":"# Check Dataframe shape\nY_2019.shape","1c963b58":"# Check Dataframe info()\nY_2019.info()","39a33baf":"# Rename columns to matching with columns at other years.\nY_2019 = Y_2019.rename(columns = {'Trip Id':'trip_id', 'Trip  Duration':'trip_duration_seconds', 'Start Station Id':'from_station_id',\n                                  'Start Time':'trip_start_time', 'Start Station Name':'from_station_name', 'End Station Id':'to_station_id',\n                                 'End Time':'trip_stop_time', 'End Station Name':'to_station_name', 'User Type': 'user_type'})","50a7edd5":"# Drop un-necessary column\nY_2019 = Y_2019.drop(['Subscription Id','Bike Id'], axis = 1)\nY_2019.info()","be840eb2":"# Check Dataframe NULL values\nY_2019.isnull().sum()","dfa60d0f":"# Select certian columns and add it at new DataFrame \"Y_19\"\nY_19 = Y_2019[['from_station_id','from_station_name']]\nY_19 = Y_19.rename(columns = {'from_station_id':'station_id','from_station_name':'station_name'})\nY_19","f7257556":"# Select certian columns and add it at new DataFrame \"Z_19\"\nZ_19 = Y_2019[['to_station_id','to_station_name']]\nZ_19 = Z_19.rename(columns = {'to_station_id':'station_id','to_station_name':'station_name'})\nZ_19","198814ba":"# Concatenate new Dtaframes \"Y_19 & Z_19\" at new Dtaframe \"X_19\"\nX_19 = pd.concat([Y_19,Z_19])\nX_19","58642f8f":"# Check number of Unique values\nX_19.station_id.nunique()","b83d35fa":"# Check Dataframe duplication\nX_19.duplicated().sum()","bf5a97de":"# Drop douplication at X_19\nX_19 = X_19.drop_duplicates()\nX_19","d1a2ad43":"# Drop Row's have NULL Values related column \"station_name\"\nX_19 = X_19[pd.notnull(X_19['station_name'])]\nX_19","0df67422":"# Check Dataframe NULL values\nY_2019.isnull().sum()","6310636e":"# Merge 2 Dataframe \"X_19\" and \"Y_2019\"\nY_2019 = Y_2019.merge(X_19, left_on = 'to_station_name', right_on = 'station_name', how = 'left')\nY_2019","cb212ad2":"# Replace NUll Value in column \"to_station_id\" with data at column \"station_id\"\n# Replace NUll Value in column \"to_station_name\" with data at column \"station_name\"\nY_2019['to_station_id'] = Y_2019.to_station_id.fillna(Y_2019.station_id)\nY_2019['to_station_name'] = Y_2019.to_station_name.fillna(Y_2019.station_name)\n\n# Drop un-necessary column\nY_2019 = Y_2019.drop(['station_id','station_name'], axis = 1)\n\n# Check Dataframe NULL values\nY_2019.isnull().sum()","8dcb5dcd":"# Check Dataframe duplication\nY_2019.duplicated().sum()","55e32a19":"# Save \"Y_2019\" dataframe in CSV format at new created folder(gathering_data)\nY_2019.to_csv('\/kaggle\/working\/Y_2019.csv', index=False)","063fe44a":"## Using glob function to combine several CSV files with same strucure at 2020 \nfiles = sorted (glob('\/kaggle\/input\/bikeshare-toronto-ridership-data-20172020\/Bikeshare 2020\/2020-*.csv'))\nfiles","30340a9c":"# Using concat to combined all files and assign() methods\nY_2020 = pd.concat((pd.read_csv(file).assign(filename = file) for file in files), ignore_index = True)\nY_2020.head()","fdc02c78":"# Check unique file's names\nY_2020.filename.unique()","f8ac9876":"# Modify file path to Y_2020 number.\nY_2020.filename = Y_2020.filename.str.replace('\/kaggle\/input\/bikeshare-toronto-ridership-data-20172020\/Bikeshare 2020\/2020-01','2020-Q1')\nY_2020.filename = Y_2020.filename.str.replace('\/kaggle\/input\/bikeshare-toronto-ridership-data-20172020\/Bikeshare 2020\/2020-02','2020-Q1')\nY_2020.filename = Y_2020.filename.str.replace('\/kaggle\/input\/bikeshare-toronto-ridership-data-20172020\/Bikeshare 2020\/2020-03','2020-Q1')\nY_2020.filename = Y_2020.filename.str.replace('\/kaggle\/input\/bikeshare-toronto-ridership-data-20172020\/Bikeshare 2020\/2020-04','2020-Q2')\nY_2020.filename = Y_2020.filename.str.replace('\/kaggle\/input\/bikeshare-toronto-ridership-data-20172020\/Bikeshare 2020\/2020-05','2020-Q2')\nY_2020.filename = Y_2020.filename.str.replace('\/kaggle\/input\/bikeshare-toronto-ridership-data-20172020\/Bikeshare 2020\/2020-06','2020-Q2')\nY_2020.filename = Y_2020.filename.str.replace('\/kaggle\/input\/bikeshare-toronto-ridership-data-20172020\/Bikeshare 2020\/2020-07','2020-Q3')\nY_2020.filename = Y_2020.filename.str.replace('\/kaggle\/input\/bikeshare-toronto-ridership-data-20172020\/Bikeshare 2020\/2020-08','2020-Q3')\nY_2020.filename = Y_2020.filename.str.replace('\/kaggle\/input\/bikeshare-toronto-ridership-data-20172020\/Bikeshare 2020\/2020-09','2020-Q3')\nY_2020.filename = Y_2020.filename.str.replace('\/kaggle\/input\/bikeshare-toronto-ridership-data-20172020\/Bikeshare 2020\/2020-10','2020-Q4')\nY_2020.filename = Y_2020.filename.str.replace('\/kaggle\/input\/bikeshare-toronto-ridership-data-20172020\/Bikeshare 2020\/2020-11','2020-Q4')\nY_2020.filename = Y_2020.filename.str.replace('\/kaggle\/input\/bikeshare-toronto-ridership-data-20172020\/Bikeshare 2020\/2020-12','2020-Q4')\nY_2020.filename = Y_2020.filename.str.replace('.csv', '')\n\nY_2020.head()","3fb04679":"# Change column \"filename to \"Quarter\"\nY_2020 = Y_2020.rename(columns = {'filename' :'Quarter'})\nY_2020.head()","4aac85b9":"# Check Columns names at DataFrame \"Y_2020\"\nY_2020.columns","b5855762":"# Check Dataframe shape\nY_2020.shape","ac837540":"# Check Dataframe info()\nY_2020.info()","e9d715c0":"# Rename columns to matching with columns at other years.\nY_2020 = Y_2020.rename(columns = {'Trip Id':'trip_id', 'Trip  Duration':'trip_duration_seconds', 'Start Station Id':'from_station_id',\n                                  'Start Time':'trip_start_time', 'Start Station Name':'from_station_name', 'End Station Id':'to_station_id',\n                                 'End Time':'trip_stop_time', 'End Station Name':'to_station_name', 'User Type': 'user_type'})","48b06eff":"# Check Dataframe info()\nY_2020.info()","cb61b4a8":"# Drop un-necessary column\nY_2020 = Y_2020.drop(['Subscription Id','Bike Id', '10293877', '863410', '905', '7038', '11\/01\/2020 00:00', 'Dundas St W \/ Yonge St',\n                     '7253', '11\/01\/2020 00:15', 'John St  \/ Mercer St - SMART', '2260', 'Casual Member', '10529965', '832983', '304', '7542',\n                     '12\/01\/2020 00:02', 'Queen St W \/ John St', '7544', '12\/01\/2020 00:07', 'Foster Pl \/ Elizabeth St - SMART', '1182',\n                     'Annual Member'], axis = 1)\nY_2020.info()","a0e37137":"# Check Dataframe NULL values\nY_2020.isnull().sum()","cb7a8c4d":"# Drop Row's have NULL Values related column \"trip_id\"\nY_2020 = Y_2020[pd.notnull(Y_2020['trip_id'])]\nY_2020","df55fd45":"# Check Dataframe NULL values\nY_2020.isnull().sum()","dd36e07b":"# Select certian columns and add it at new DataFrame \"Y_20\"\nY_20 = Y_2020[['from_station_id','from_station_name']]\nY_20 = Y_20.rename(columns = {'from_station_id':'station_id','from_station_name':'station_name'})\nY_20","a580f1d1":"# Select certian columns and add it at new DataFrame \"Z_20\"\nZ_20 = Y_2020[['to_station_id','to_station_name']]\nZ_20 = Z_20.rename(columns = {'to_station_id':'station_id','to_station_name':'station_name'})\nZ_20","80322a40":"# Concatenate new Dtaframes \"Y_20 & Z_20\" at new Dtaframe \"X_20\"\nX_20 = pd.concat([Y_20,Z_20])\nX_20","0447c14b":"# Check Dataframe duplication\nX_20.duplicated().sum()","006aff31":"# Drop douplication at X_20\nX_20 = X_20.drop_duplicates()\nX_20","fcc332c9":"# Drop Row's have NULL Values related column \"station_name\"\nX_20 = X_20[pd.notnull(X_20['station_name'])]\nX_20","318b6371":"# Merge 2 Dataframe \"X_20\" and \"Y_2020\"\nY_2020 = Y_2020.merge(X_20, left_on = 'from_station_id', right_on = 'station_id', how = 'left')\nY_2020","48ed8236":"# Replace NUll Value in column \"from_station_name\" with data at column \"station_name\"\nY_2020['from_station_name'] = Y_2020.from_station_name.fillna(Y_2020.station_name)\n\n# Drop un-necessary column\nY_2020 = Y_2020.drop(['station_id','station_name'], axis = 1)\n\n# Check Dataframe NULL values\nY_2020.isnull().sum()","5579289d":"# Merge 2 Dataframe \"X_20\" and \"Y_2020\"\nY_2020 = Y_2020.merge(X_20, left_on = 'to_station_id', right_on = 'station_id', how = 'left')\nY_2020","2e138a20":"# Replace NUll Value in column \"to_station_name\" with data at column \"station_name\"\nY_2020['to_station_name'] = Y_2020.to_station_name.fillna(Y_2020.station_name)\n\n# Drop un-necessary column\nY_2020 = Y_2020.drop(['station_id','station_name'], axis = 1)\n\n# Check Dataframe NULL values\nY_2020.isnull().sum()","6d9f7ef3":"# check Dataframe duplication\nY_2020.duplicated().sum()","2467f7da":"# Save \"Y_2020\" dataframe in CSV format at new created folder(gathering_data)\nY_2020.to_csv('\/kaggle\/working\/Y_2020.csv', index=False)","328396c9":"## Using glob function to combine several CSV files with same strucure at gathering_data\nfiles = sorted (glob('\/kaggle\/working\/Y_20*.csv'))\nfiles","79031d3c":"# using concat to combined all files\nY_All = pd.concat((pd.read_csv(file) for file in files), ignore_index = True)\nY_All","369cfd5f":"# Select certian columns and add it at new DataFrame \"Y\"\nY = Y_All[['from_station_id','from_station_name']]\nY = Y.rename(columns = {'from_station_id':'station_id','from_station_name':'station_name'})\nY","43169460":"# Select certian columns and add it at new DataFrame \"Z\"\nZ = Y_All[['to_station_id','to_station_name']]\nZ = Z.rename(columns = {'to_station_id':'station_id','to_station_name':'station_name'})\nZ","cbfebd04":"# Concatenate new Dtaframes \"Y & Z\" at new Dtaframe \"X\"\nX = pd.concat([Y,Z])\nX","bf3cb80b":"# Check Dataframe duplication\nX.duplicated().sum()","0f70e2a7":"# Drop douplication at X\nX = X.drop_duplicates()\nX","e149f24b":"# Check NULL values at Column \"station_id\"\nX.query('station_id.isnull()', engine='python')","8aa26c3f":"# Update the repeated stations with same ID number\n# Update station_id = 7183 for station \"Margueretta St \/ College St\"\nX['station_id'][465831] = 7183.0\n\n# Update station_id = 7180 for station \"Lansdowne Subway Green P\"\nX['station_id'][465850] = 7180.0\n\n# Update station_id = 7161 for station \"Beverly St \/ College St\"\nX['station_id'][465532] = 7161.0","cbc1b441":"# Update station without ID by adding ID for them\n# Station \"Michael Sweet Ave \/ St. Patrick St\" using station_id = 7080.0\nX['station_id'][465490] = 7080.0\n\n# Station \"Roxton Rd \/ College St\" using station_id = 7081.0\nX['station_id'][728511] = 7081.0\n\n# Station \"Base Station\" using station_id = 7082.0\nX['station_id'][731204] = 7082.0\n\n# Station \"Lake Shore Blvd W \/ Ontario Dr(Ontario Place)\" using station_id = 7212.0\nX['station_id'][734637] = 7212.0\n\n# Station \"Dovercourt Rd \/ Harrison St - SMART\" using station_id = 7213.0\nX['station_id'][797267] = 7213.0\n\n# Station \"Summerhill Ave \/ MacLennan Ave - SMART\" using station_id = 7214.0\nX['station_id'][800483] = 7214.0\n\n# Station \"Fringe Next Stage - 7219\" using station_id = 7215.0\nX['station_id'][1038094] = 7215.0","7ce5a9a3":"# Check above stations name related column\"station_name\"\nX.query('station_name == \"Fringe Next Stage - 7219\" ')","18fb9937":"# Check NULL values at Column \"station_id\"\nX.query('station_id.isnull()', engine='python')","06fed7e0":"# Drop Row's have NULL Values at X\nX = X.dropna(axis = 0)\nX","6e4f5787":"# Check Dataframe NULL values\nY_All.isnull().sum()","694d6e46":"# Merge 2 Dataframe \"X\" and \"Y_All\"\nY_All = Y_All.merge(X, left_on = 'from_station_name', right_on = 'station_name', how = 'left')\nY_All","7184a0db":"# Replace NUll Value in column \"from_station_id\" with data at column \"station_id\"\nY_All['from_station_id'] = Y_All.from_station_id.fillna(Y_All.station_id)\n\n# Drop un-necessary column\nY_All = Y_All.drop(['station_id','station_name'], axis = 1)\n\n# Check Dataframe NULL values\nY_All.isnull().sum()","2f91c724":"# Merge 2 Dataframe \"X\" and \"Y_All\"\nY_All = Y_All.merge(X, left_on = 'to_station_name', right_on = 'station_name', how = 'left')\nY_All","539d1874":"# Replace NUll Value in column \"to_station_id\" with data at column \"station_id\"\nY_All['to_station_id'] = Y_All.to_station_id.fillna(Y_All.station_id)\n\n# Drop un-necessary column\nY_All = Y_All.drop(['station_id','station_name'], axis = 1)\n\n# Check Dataframe NULL values\nY_All.isnull().sum()","35331a1a":"# Correct data type for \"trip_start_time , trip_stop_time\" to be time stamp\nY_All['trip_start_time']= pd.to_datetime(Y_All.trip_start_time)\nY_All['trip_stop_time'] = pd.to_datetime(Y_All.trip_stop_time)\nY_All.info()","de8daaed":"# check total trip time in seconds for all trips and convert it to integer \nY_All['trip_duration_seconds'] = (Y_All.trip_stop_time - Y_All.trip_start_time).dt.total_seconds().astype('int64')\n\n# Check Dataframe info()\nY_All.info()","e14250af":"# check trip_duration_seconds = zero values ( that mean trips are cancelled)\nY_All.query('trip_duration_seconds == 0')","5daedfac":"# Drop Row's have trip_duration_seconds = zero values \nY_All = Y_All[(Y_All['trip_duration_seconds'] > 0)]\nY_All","e1866f7d":"# Check trip_duration_seconds = zero values are all removed\nY_All.query('trip_duration_seconds == 0')","6e384dd9":"# Check Dataframe NULL values\nY_All.isnull().sum()","3f0a9c77":"# Modify \"Casual\" to \"Casual Member\" at \"user_type\" column\nY_All.user_type = Y_All.user_type.replace('Casual', 'Casual Member')\n\n# Modify \"Member\" to \"Annual Member\" at \"user_type\" column\nY_All.user_type = Y_All.user_type.replace('Member', 'Annual Member')\n\n# Check changes applied\nY_All.user_type.unique()","97812d22":"# Save \"Y_All\" dataframe in CSV format at new created folder(gathering_data)\nY_All.to_csv('\/kaggle\/working\/Y_All.csv', index=False)","c0379bc3":"# Copying the merged DataFrame\ndf_All = Y_All.copy()\ndf_All","7d2f7997":"# Plot \"user_type\" Analysis\nplt.figure(figsize=[6, 6])\ncolor_base = sns.color_palette()[0]\n\nax = sns.countplot(data = df_All, x = 'user_type', color = color_base, order = df_All.user_type.value_counts().index)\n\nfor i,j in enumerate (df_All.user_type.value_counts()):\n    ax.text(i,100 + df_All.user_type.value_counts()[i], j, weight = \"bold\", size = 13,va='baseline', ha='center')\n    \nplt.yticks([0, 1e6, 2e6, 3e6, 4e6, 5e6, 6e6],['0','1M','2M','3M','4M','5M','6M'])\nplt.xlabel(\"User's Type\", size = 15)\nplt.ylabel(\"Total User's Count\", size = 15)\nplt.title(\"User's Type Distribution\", size = 15, weight = 'bold')\nplt.show();","0ea8ea33":"# Plot \"user_type\" Analysis\ndate_quarter = df_All.groupby(df_All.Quarter)['user_type'].count()\n\nax = date_quarter.plot(kind ='line',figsize = (20,10), marker = 'o')       \nplt.xticks([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], ['2017-Q1', '2017-Q2', '2017-Q3', '2017-Q4','2018-Q1', '2018-Q2', '2018-Q3', '2018-Q4',\n                                                                    '2019-Q1', '2019-Q2', '2019-Q3', '2019-Q4','2020-Q1', '2020-Q2', '2020-Q3', '2020-Q4'])\nplt.yticks([0, 0.2e6, 0.4e6, 0.6e6, 0.8e6, 1.0e6, 1.2e6, 1.4e6, 1.6e6],['0', '200K', '400K', '600K','800K', '1M', '1.2M', '1.4M', '1.6M'])\nplt.xlabel(\"Date(Year-Quarter)\", size = 15)\nplt.ylabel('Total Trips', size = 15)\nplt.title(\"User's Type Distribution \/ Quarter\", weight = 'bold', size = 15)\n\nplt.grid(True)\nplt.show();","f10af347":"date_year = df_All.trip_start_time.groupby(df_All.trip_start_time.dt.year).count()\n\nax = date_year.plot(kind ='line',figsize = (6,6), marker = 'o')       \nplt.title('Trips per Years', weight = 'bold', size = 15)\nplt.xlabel(\"Date(Year's)\", size = 15)\nplt.ylabel('Total Trips', size = 15)\nplt.xticks([2017.0,2018.0, 2019.0, 2020.0], ['2017', '2018', '2019','2020'])\nplt.yticks([1.6e6, 1.8e6, 2.0e6, 2.2e6, 2.4e6, 2.6e6], ['1.6M', '1.8M', '2M','2.2M', '2.4M', '2.6M'])\nplt.grid(True)\nplt.show();","649d2a0a":"trips_month = df_All.trip_start_time.groupby([df_All.trip_start_time.dt.year, df_All.trip_start_time.dt.month]).count()\n\nax = trips_month.plot(kind ='line',figsize = (20,8), marker = 'o')       \nplt.title('Total Count Trips per Month', weight = 'bold', size = 15)\nplt.xlabel(\"Date(Month-Year)\", size = 15)\nplt.ylabel('Total Trips', size = 15)\nplt.xticks([0, 2, 5, 8, 11, 14, 17, 20, 23, 26, 29, 32, 35, 38, 41, 44, 47], ['Jan-17', 'Mar-17', 'Jun-17', 'Sep-17', 'Dec-17', 'Mar-18', 'Jun-18', 'Sep-18', 'Dec-18',\n                                                                  'Mar-19', 'Jun-19', 'Sep-19', 'Dec-19', 'Mar-20', 'Jun-20', 'Sep-20', 'Dec-20' ])\nplt.yticks([100000, 200000, 300000, 400000, 500000], ['100K', '200K', '300K','400K', '500K'])\nplt.grid(True)\nplt.show();","6b412c83":"# Plot \"user_type\" Analysis\ntrips_quarter = df_All.groupby(['Quarter','user_type'])['trip_id'].count().reset_index()\ntrips_quarter.head()","e539d328":"# combine 2 colums \"user_type\" & \"trip_start_time\" \nAnnual = pd.DataFrame(trips_quarter.query('user_type == \"Annual Member\"').value_counts()).reset_index()\n# combine 2 colums \"user_type\" & \"trip_start_time\" \nCasual = pd.DataFrame(trips_quarter.query('user_type == \"Casual Member\"').value_counts()).reset_index()\nAnnual","9ba4629e":"fig,(ax1,ax2) = plt.subplots (1,2,figsize = (20,20))\n\n# figure \"a\" represent number of Annual Member in user type \na = sns.barplot (x = Annual.trip_id, y = Annual.Quarter, ax = ax1 , \n                 linewidth = 1 ,alpha = 0.7, palette = 'Blues_r')\n\n# figure \"a\" represent number of  Casual Member in user type\nb = sns.barplot (x = Casual.trip_id, y = Casual.Quarter, ax = ax2 , \n                 linewidth = 1 ,alpha = 0.7, palette = 'Blues_r')\n\n# create loop to count number of Trips in each Annual Member\nfor i,j in enumerate(Annual.trip_id):\n        ax1.text(.07,i+0.15,j,weight = \"bold\", size = 15)\n\n# create loop to count number of Trips in each Casual Member\nfor k,l in enumerate(Casual.trip_id):\n        ax2.text(.07,k+0.15,l,weight = \"bold\", size = 15)     \n        \na.set_title(\"Total Count Trips \/ Quarter as Annual Member\" , weight = 'bold', size = 15)\na.set_xlabel('Total Annual Member Count \/ Quarter', size = 15)\na.set_ylabel(\"Date(Year-Quarter)\", size = 15)\n\n\nb.set_title(\"Total Count Trips \/ Quarter as Casual Member\" , weight = 'bold', size = 15)\nb.set_xlabel('Total Casual Member Count \/ Quarter', size = 15)\nb.set_ylabel(\"Date(Year-Quarter)\", size = 15)\n\nplt.show();","1bcf79c3":"total_month_trip = pd.DataFrame(df_All.groupby([df_All.trip_start_time.dt.year, df_All.trip_start_time.dt.month])['trip_duration_seconds'].sum())\n\nax = total_month_trip.plot(kind ='line',figsize = (20,8), marker = 'o')       \nplt.title('Max. Period Trip per Month', weight = 'bold', size = 15)\nplt.xlabel(\"Date(Month-Year)\", size = 15)\nplt.ylabel('Total Trips \/ Seconds', size = 15)\nplt.xticks([0, 2, 5, 8, 11, 14, 17, 20, 23, 26, 29, 32, 35, 38, 41, 44, 47], ['Jan-17', 'Mar-17', 'Jun-17', 'Sep-17', 'Dec-17', 'Mar-18', 'Jun-18', 'Sep-18', 'Dec-18',\n                                                                  'Mar-19', 'Jun-19', 'Sep-19', 'Dec-19', 'Mar-20', 'Jun-20', 'Sep-20', 'Dec-20' ])\nplt.yticks([1e8, 2e8, 3e8, 4e8, 5e8, 6e8, 7e8, 8e8, 9e8], ['100M', '200M', '300M','400M', '500M', '600M', '700M', '800M', '900M'])\nplt.grid(True)\nplt.legend('')\nplt.show();","ff65cecb":"min_month_trip = pd.DataFrame(df_All.groupby([df_All.trip_start_time.dt.year, df_All.trip_start_time.dt.month])['trip_duration_seconds'].idxmin())\n\nax = min_month_trip.plot(kind ='line',figsize = (20,8), marker = 'o')       \nplt.title('Max. Period Trip per Month', weight = 'bold', size = 15)\nplt.xlabel(\"Date(Month-Year)\", size = 15)\nplt.ylabel('Total Trips \/ Seconds', size = 15)\nplt.xticks([0, 2, 5, 8, 11, 14, 17, 20, 23, 26, 29, 32, 35, 38, 41, 44, 47], ['Jan-17', 'Mar-17', 'Jun-17', 'Sep-17', 'Dec-17', 'Mar-18', 'Jun-18', 'Sep-18', 'Dec-18',\n                                                                  'Mar-19', 'Jun-19', 'Sep-19', 'Dec-19', 'Mar-20', 'Jun-20', 'Sep-20', 'Dec-20' ])\nplt.yticks([0, 1e6, 2e6, 3e6, 4e6, 5e6, 6e6, 7e6, 8e6, 9e6], ['0', '1M', '2M', '3M','4M', '5M', '6M', '7M', '8M', '9M'])\nplt.grid(True)\nplt.legend('')\nplt.show();","a355a80c":"max_month_trip = pd.DataFrame(df_All.groupby([df_All.trip_start_time.dt.year, df_All.trip_start_time.dt.month])['trip_duration_seconds'].idxmax())\n\nax = max_month_trip.plot(kind ='line',figsize = (20,8), marker = 'o')       \nplt.title('Max. Period Trip per Month', weight = 'bold', size = 15)\nplt.xlabel(\"Date(Month-Year)\", size = 15)\nplt.ylabel('Total Trips \/ Seconds', size = 15)\nplt.xticks([0, 2, 5, 8, 11, 14, 17, 20, 23, 26, 29, 32, 35, 38, 41, 44, 47], ['Jan-17', 'Mar-17', 'Jun-17', 'Sep-17', 'Dec-17', 'Mar-18', 'Jun-18', 'Sep-18', 'Dec-18',\n                                                                  'Mar-19', 'Jun-19', 'Sep-19', 'Dec-19', 'Mar-20', 'Jun-20', 'Sep-20', 'Dec-20' ])\nplt.yticks([1e6, 2e6, 3e6, 4e6, 5e6, 6e6, 7e6, 8e6, 9e6], ['1M', '2M', '3M','4M', '5M', '6M', '7M', '8M', '9M'])\nplt.grid(True)\nplt.legend('')\nplt.show();","652d3e97":"average_month_trip = pd.DataFrame(df_All.groupby([df_All.trip_start_time.dt.year, df_All.trip_start_time.dt.month])['trip_duration_seconds'].mean())\n\nax = average_month_trip.plot(kind ='line',figsize = (20,8), marker = 'o')       \nplt.title('Max. Period Trip per Month', weight = 'bold', size = 15)\nplt.xlabel(\"Date(Month-Year)\", size = 15)\nplt.ylabel('Total Trips \/ Seconds', size = 15)\nplt.xticks([0, 2, 5, 8, 11, 14, 17, 20, 23, 26, 29, 32, 35, 38, 41, 44, 47], ['Jan-17', 'Mar-17', 'Jun-17', 'Sep-17', 'Dec-17', 'Mar-18', 'Jun-18', 'Sep-18', 'Dec-18',\n                                                                  'Mar-19', 'Jun-19', 'Sep-19', 'Dec-19', 'Mar-20', 'Jun-20', 'Sep-20', 'Dec-20' ])\nplt.yticks([2e3, 4e3, 6e3, 8e3, 10e3, 12e3, 14e3], ['2K', '4K', '6K','8K', '10K', '12K', '14K'])\nplt.grid(True)\nplt.legend('')\nplt.show();","5761fc23":"# combine 2 colums \"from_station_id\" & \"trip_id\" then sort stations desending regarding number of trips results\nmost_Start_id = df_All.groupby('from_station_name')['trip_id'].count().reset_index().sort_values( by = 'trip_id', ascending = False )","e0099a37":"fig, ax1 = plt.subplots (1,figsize = (10,12))\n\n# figure \"a\" represent number of player heighest\na = sns.barplot (x = most_Start_id.trip_id, y = most_Start_id.from_station_name[:20], ax = ax1 , linewidth = 1 ,alpha = 0.7, palette = 'Blues_r')\n\n# create loop to count players depend on height player.\nfor i,j in enumerate(most_Start_id.trip_id[:20]):\n        ax1.text(.7,i+0.08,j,weight = \"bold\", size = 15)\n\na.set_title(\"Top 20 Stations at start Point Distribution\" , weight = 'bold', size = 15)\na.set_xlabel('Total Count', size = 15)\na.set_ylabel(\"Top Station's Distribution\", size = 15)\nplt.xticks([0, 2e4, 4e4, 6e4, 8e4, 1e5], ['0', '20K', '40K','60K', '80K', '100K'])\nplt.show();","ee47ad38":"# combine 2 colums \"to_station_name\" & \"trip_id\" then sort stations desending regarding number of trips results\nmost_End_id = df_All.groupby('to_station_name')['trip_id'].count().reset_index().sort_values( by = 'trip_id', ascending = False )","6a50f000":"fig, ax1 = plt.subplots (1,figsize = (10,12))\n\n# figure \"a\" represent number of player heighest\na = sns.barplot (x = most_End_id.trip_id, y = most_End_id.to_station_name[:20], ax = ax1 , linewidth = 1 ,alpha = 0.7, palette = 'Blues_r')\n\n# create loop to count players depend on height player.\nfor i,j in enumerate(most_End_id.trip_id[:20]):\n        ax1.text(.7,i+0.08,j,weight = \"bold\", size = 15)\n\na.set_title(\"Top 20 Stations at End Point Distribution\" , weight = 'bold', size = 15)\na.set_xlabel('Total Count', size = 15)\na.set_ylabel(\"Top Station's Distribution\", size = 15)\nplt.xticks([0, 2e4, 4e4, 6e4, 8e4, 1e5], ['0', '20K', '40K','60K', '80K', '100K'])\nplt.show();","7d7a5eee":"# get correlation in specific columns\ncorrelation = df_All.corr()\nplt.figure(figsize=(8,8))\n\n# create heatmap plot\nsns.heatmap(correlation,annot=True ,cmap = plt.cm.plasma, linecolor='white', linewidths=2)\nplt.title('Correlation Between Variables')\nplt.show();","2fd677ca":"from wordcloud import WordCloud\n# get player counts value acheived gameId > 32000 \ntop_rate = most_Start_id[most_Start_id.trip_id  > 30000 ]['from_station_name'].value_counts().index\n\n# using bckground\" WorldCloud\nw_c = WordCloud(background_color=\"white\",scale=2).generate(\" \".join(top_rate))\nfig = plt.figure(figsize=(15,8))\n\n# plot show in \"bilionear style\"\nplt.imshow(w_c,interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.title(\"Top stations at Start Point\")\nplt.show();","dca49b5c":"><span style=\"color:orange\"><font size=\"3\"> **Q4:What's the Total Count Trips per Month?** <\/font><\/span>","0501afad":"><span style=\"color:orange\"><font size=\"3\"> **Q8: What's the Max. Period Trip \/ Month?** <\/font><\/span>","c6b94093":"<font size=\"6\"> (BikeShare_Toronto_Ridership_Data_2017-2020.)<\/font>\n\n [BikeShare Toronto Ridership Data 2017-2020](https:\/\/www.kaggle.com\/jasonzxho\/bikeshare-toronto-ridership-data-20172020)\n \n<font size=\"6\"> by (Peter Gamal Girgis)<\/font>\n\n<span style=\"color:orange\"><font size=\"4\"> **Task Details:** <\/font><\/span>\n\n><font size=\"5\"> About the Dataset<\/font>\n>\n>The following dataset contain bike trips taken during the year 2017-2020 across more than 600 stations across the City of Toronto. The CSVs for 2017 and 2018 contains 9 features. The description of each feature is listed below:\n>\n>>    `trip_id`: Unique ID code for individual trip taken.\n>>\n>>    `trip_start_time`: Trip start time.\n>>\n>>    `trip_end_time`: Trip end time.\n>>\n>>    `trip_duration_seconds`: Duration of the trip in seconds.\n>>\n>>    `from_station_id`: Unique ID code for the start station.\n>>\n>>    `from_station_name`: Name of start station.\n>>\n>>    `to_station_id`: Unique ID code for the end station.\n>>\n>>    `to_station_name`: Name of end station.\n>>\n>>    `user_type`: Type of user, either Member or Casual.\n>>\n>\n> The CSVs for 2019 and 2020 contains 11 features. The description of each feature is listed below:\n>\n>>    `Trip Id`: Unique ID code for individual trip taken.\n>>    Subscription Id: Unique ID code for the individual member, this can be used to track Annual Member usage.\n>>\n>>    `Trip Duration`: Duration of the trip in seconds.\n>>\n>>    `Start Station Id`: Unique ID code for the start station.\n>>\n>>    `Start Time`: Trip start time.\n>>\n>>    `Start Station Name`: Name of start station.\n>>\n>>    `End Station Id`: Unique ID code for the end station.\n>>\n>>    `End Time`: Trip end time.\n>>\n>>    `End Station Name`: Name of end station.\n>>\n>>   `Bike Id`: Unique ID for the individual bike used.\n>> \n>>   `User Type`: Type of user, either Annual or Casual.\n ","b84dd625":"><span style=\"color:orange\"><font size=\"3\"> **Q6: What's the Total Period Trip \/ Month?** <\/font><\/span>","f7e70faf":"><span style=\"color:orange\"><font size=\"3\"> **Q13: Using \"worldcloud\" to print Top stations at Start Point?** <\/font><\/span>","59cc79e0":"><span style=\"color:orange\"><font size=\"3\"> **Q2:How Many User Type \/ Quarter in each Year ?** <\/font><\/span>","db7696a1":"<span style=\"color:orange\"><font size=\"4\"> **2. Year_2018** <\/font><\/span>","fdb84d0f":"><span style=\"color:orange\"><font size=\"3\"> **Q5: What's the Total Count Trips per Quarter as (Annual \/ Casual) Member?** <\/font><\/span>","1d377259":"> Cancel trip while `trip_duration_seconds` & `trip_stop_time` equal Zero and no distination at `to_station_name` or `to_station_id`","eff951e4":"><span style=\"color:orange\"><font size=\"3\"> **Q10: What's the Top 20 Stations at Start Point?** <\/font><\/span>","ba96b890":"<span style=\"color:orange\"><font size=\"4\"> **7. Exploratory Data Analysis ( Analyzing and Visualization)** <\/font><\/span>\n><span style=\"color:orange\"><font size=\"3\"> **Q1:How Many user type at All Period?** <\/font><\/span>","37407dd5":"><span style=\"color:orange\"><font size=\"3\"> **Q11: What's the Top 20 Stations at End Point?** <\/font><\/span>","97a0f373":"<span style=\"color:orange\"><font size=\"4\"> **3. Year_2019** <\/font><\/span>","c5c0d776":"><span style=\"color:orange\"><font size=\"3\"> **Q12: What's the Q10: What's Correlation Between Variables?** <\/font><\/span>","93db8c55":"<span style=\"color:orange\"><font size=\"4\"> **5. Combine All DF's** <\/font><\/span>","75d92ec4":"<span style=\"color:orange\"><font size=\"4\"> **1. Year_2017** <\/font><\/span>","579fcc29":"<span style=\"color:orange\"><font size=\"4\"> **6. Copying DataFrame** <\/font><\/span>","72d89630":"<span style=\"color:orange\"><font size=\"4\"> **4. Year_2020** <\/font><\/span>","13ff69dc":"><span style=\"color:orange\"><font size=\"3\"> **Q3:What's Total Trips per year?** <\/font><\/span>","3841f377":"><span style=\"color:orange\"><font size=\"3\"> **Q7: What's the Min. Period Trip \/ Month?** <\/font><\/span>","feb618f7":"><span style=\"color:orange\"><font size=\"3\"> **Q9: What's the Average Period Trip \/ Month?** <\/font><\/span>"}}