{"cell_type":{"c57f888f":"code","f7795d15":"code","174016f8":"code","b2ed0621":"code","641c8a8b":"code","adfb9268":"code","71fdb2e8":"code","a3e9826e":"code","2245fc3f":"code","37cbc0e9":"code","a67fbf80":"code","89aae0f1":"code","3b05bba5":"code","c101e7e4":"code","61c00af9":"code","887d54c1":"code","910d45e4":"code","53539ea6":"code","8b48d9de":"code","9cc01843":"code","08f729dd":"code","8878525b":"code","787861b7":"code","2013ded3":"code","76662d7b":"code","9eb78678":"code","f1b6cd89":"code","aae3316e":"code","4db7e352":"code","83b8d0b4":"code","ece40655":"code","24ed6f48":"code","42ab3a8b":"code","eb370ea7":"code","ec2d15ba":"code","d21487ad":"code","af45ea9c":"code","0554c2cb":"code","4db8f0d1":"code","d8f5365f":"code","5f687f24":"code","effb76aa":"code","bb0f2256":"code","8fd7db06":"code","f7d12d46":"code","47bb2860":"code","323f23c6":"code","45287f84":"code","83e4fce9":"code","61d4524f":"code","3f8dd2b9":"code","d9018170":"code","a64ff852":"code","e6e751c5":"code","2707970c":"code","e30fae2c":"code","c6b02329":"code","16295038":"code","e7296c4d":"code","30891eea":"code","34aa8e07":"code","494df792":"code","c368115a":"code","f689d526":"code","ea73bd1d":"code","457f12e2":"code","7e55f563":"code","056fc9bd":"code","4b8a04c0":"code","b88e0bc3":"code","46cca9c8":"code","df0b6d92":"code","faa377de":"code","8f033e53":"code","8d9433c7":"code","7db9c0ec":"code","d77c1469":"code","60ff2fdd":"code","2ee370f8":"code","6ba1bafc":"code","e60e8709":"code","5f36f910":"code","58f4ce4f":"code","ab6dac86":"markdown","6c7c89c9":"markdown","e43d4965":"markdown","303351e4":"markdown","151790d4":"markdown","5c794998":"markdown","6fda075f":"markdown","58d4ddb1":"markdown","36fc978e":"markdown","24d7a1e2":"markdown","512ea499":"markdown","0ae78337":"markdown","500ef8e2":"markdown","c1700fba":"markdown","f5b22ef9":"markdown","c3e0a496":"markdown","4a216d01":"markdown","6f377df2":"markdown","1275c191":"markdown","f27ead0e":"markdown","85f3bde2":"markdown","1e260598":"markdown","8c6b1d04":"markdown","c43a2228":"markdown","8d3aa876":"markdown","cae2ea88":"markdown","c58a823e":"markdown","3362ab96":"markdown","9617922d":"markdown","18b23fbf":"markdown","0dd2f5a1":"markdown","f451a087":"markdown","7e3dc23a":"markdown","4a36c0a3":"markdown","e4b8e077":"markdown","5d0c8981":"markdown","775a72ae":"markdown","b409690a":"markdown","e05fabc4":"markdown","8d060b9c":"markdown","b4380134":"markdown","e7421228":"markdown","16263f92":"markdown","f4dec59c":"markdown","600bde9c":"markdown","3e8a455d":"markdown","06077e54":"markdown","a01dc3f8":"markdown","ed7bf6c2":"markdown","c788bdc6":"markdown","0537fb22":"markdown","78719945":"markdown","126475b3":"markdown","232f135b":"markdown","7b43290e":"markdown","9357617e":"markdown"},"source":{"c57f888f":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use('default')","f7795d15":"np.random.randint(0,100, size=5)","174016f8":"np.random.rand(10)","b2ed0621":"rng = np.random.default_rng(seed=42)\narr = rng.random(10)\narr2 = rng.integers(low=0, high=10, size=10)\nprint(arr)\nprint(arr2)","641c8a8b":"dis=np.random.choice([1, 3, 5, 7, 9, 11], p=[0.15, 0.09, 0.22, 0.4, 0.11, 0.03], size=100)\n\nsns.displot(dis, kde=True);","adfb9268":"normal_dis=np.random.normal(loc=1, scale=10, size=1000)\n\nsns.displot(normal_dis, kde=True);","71fdb2e8":"from scipy.stats import probplot\n\nf, ax = plt.subplots(1,2,figsize=(15,6))\nsns.histplot(normal_dis, stat=\"density\", ax=ax[0])\nprobplot(normal_dis, dist=\"norm\", fit=True, rvalue=True, plot=plt);","a3e9826e":"from scipy.stats import norm, t, gamma, loggamma, crystalball, beta, alpha\n\nprint(\"Real\")\nprint(f\"mean: {np.mean(normal_dis)} - std: {np.std(normal_dis)}\")\nprint(f\"min: {np.min(normal_dis)} - max: {np.max(normal_dis)}\")\n\nprint(\"\\nFit normal\")\nloc_norm, scale_norm = norm.fit(normal_dis)\nprint(loc_norm, scale_norm)\n\nprint(\"\\nFit gamma\")\nshape_gamma, loc_gamma, scale_gamma = gamma.fit(normal_dis)\nprint(shape_gamma, loc_gamma, scale_gamma)\n\nprint(\"\\nFit t\")\ndf_t, loc_t, scale_t=t.fit(normal_dis)\nprint(df_t, loc_t, scale_t)\n\n# print(\"\\nFit beta\")\n# alpha_beta, beta_beta, loc_beta, scale_beta = beta.fit(normal_dis)\n# print(alpha_beta, beta_beta, loc_beta, scale_beta)\n\n# print(\"\\nFit alpha\")\n# a_alpha, loc_alpha, scale_alpha = alpha.fit(normal_dis)\n# print(a_alpha, loc_alpha, scale_alpha)\n\n# print(\"\\nFit loggamma\")\n# c_loggamma, loc_loggamma, scale_loggamma = loggamma.fit(normal_dis)\n# print(c_loggamma, loc_loggamma, scale_loggamma)\n\n# print(\"\\nFit crystalball\")\n# beta_crystalball, m_crystalball, loc_crystalball, scale_crystalball = crystalball.fit(normal_dis)\n# print(beta_crystalball, m_crystalball, loc_crystalball, scale_crystalball)\n\n\nx = np.arange(np.min(normal_dis), np.max(normal_dis), 0.01)\n\nf, ax = plt.subplots(figsize=(15, 6))\nsns.histplot(normal_dis, stat=\"density\", fill=False, element=\"step\", ax=ax, label='distribution')\nsns.lineplot(x=x, y=norm.pdf(x, loc=loc_norm, scale=scale_norm) , ax=ax, label='normal')\nsns.lineplot(x=x, y=t.pdf(x, df=df_t, loc=loc_t, scale=scale_t) , ax=ax, label='t')\nsns.lineplot(x=x, y=gamma.pdf(x, a=shape_gamma, loc=loc_gamma, scale=scale_gamma) , ax=ax, label='gamma')\n# sns.lineplot(x=x, y=beta.pdf(x, a=alpha_beta, b=beta_beta, loc=loc_beta, scale=scale_beta) , ax=ax, label='beta')\n# sns.lineplot(x=x, y=alpha.pdf(x, a=a_alpha, loc=loc_alpha, scale=scale_alpha) , ax=ax, label='alpha')\n# sns.lineplot(x=x, y=loggamma.pdf(x, c=c_loggamma, loc=loc_loggamma, scale=scale_loggamma) , ax=ax, label='loggamma')\n# sns.lineplot(x=x, y=crystalball.pdf(x, beta=beta_crystalball, m=m_crystalball, loc=loc_crystalball, scale=scale_crystalball) , ax=ax, label='crystalball')\n\nax.legend();","2245fc3f":"def map_graphs(n, start1, stop1, start2, stop2):\n    return ((n-start1)\/(stop1-start1))*(stop2-start2)+start2\n\nmean=100\nstd=12\nnorm_dis = norm(loc=mean, scale=std)\n\n#To find the probability that the variable has a value LESS than or equal\n#let's say 124, you'd use CDF cumulative Density Function\nprint(f\"cdf <124: {norm_dis.cdf(124.64)*100:.2f}%\")\nprint(f\"cdf 100 - 124: {(norm_dis.cdf(124.64) - norm_dis.cdf(100))*100:.2f}%\")\n\n#To find the probability that the variable has a value GREATER than or\n#equal to let's say 125, you'd use SF Survival Function \nprint(f\"sf >125: {norm_dis.sf(125)*100:.2f}%\")\nprint(f\"cdf >125: {(1-norm_dis.cdf(125))*100:.2f}%\")\n\n# To find the probability for a value equal to 100\n#PDF probability density function \nprint(f\"pdf 100: {norm_dis.pdf(100)*100:.2f}%\")\n\n#To find the variate for which the probability is given, let's say the value which needed to provide a 98% probability, you'd use the \n#PPF Percent Point Function\n# One-tail\nprint(f\"One-tail ppf 95%: {norm_dis.ppf(0.95):.2f}\")\n\n# Two-tail\nprint(f\"Two-tail ppf 95%: {norm_dis.ppf((1+0.95)\/2):.2f}\")\nprint(norm_dis.ppf([0.001, 0.25, 0.5, 0.68, 0.95, 0.997, 0.999]))\n\nprint(f\"mean: {norm_dis.mean()}\")\nprint(f\"median: {norm_dis.median()}\")\nprint(f\"var: {norm_dis.var()}\")\nprint(f\"std: {norm_dis.std()}\")\n\n# Confidence interval\nprint(f\"CI 68%: {norm_dis.interval(alpha=0.68)}\")\nprint(f\"CI 95%: {norm_dis.interval(alpha=0.95)}\")\nprint(f\"CI ppf 95%: {norm_dis.ppf(0.025)}, {norm_dis.ppf(0.975)}\")\nprint(f\"CI 99.7%: {norm_dis.interval(alpha=0.997)}\")\n\nprint(\"\\nSample\")\nsample_dis=norm_dis.rvs(size=50)\nsample_mean=np.mean(sample_dis)\nsample_error=np.std(sample_dis)\/np.sqrt(50)\nprint(f\"CI 95%: {norm.interval(alpha=0.95, loc=sample_mean, scale=sample_error)}\")\nprint(f\"CI 95%: {norm.ppf(0.025, loc=sample_mean, scale=sample_error)}, {norm.ppf(0.975, loc=sample_mean, scale=sample_error)}\")\n\nx = np.arange(40, 160, 0.01)\ny = norm_dis.pdf(x)\n\nf, ax = plt.subplots(figsize=(15, 6))\nsns.lineplot(x=x, y=y , color='black', ax=ax, label='distribution')\nsns.histplot(norm_dis.rvs(size=10000), stat=\"density\", fill=False, element=\"step\", ax=ax, label='sample')\n\nax.axvline(100, color='r', linestyle='--', label=\"Mean\")\nax.axvline(119.74, color='b', linestyle='-.', label=\"Value\")\n\nax.axvline(norm_dis.interval(alpha=0.997)[0], ymin=0, ymax=norm_dis.pdf(norm_dis.ppf((1+0.997)\/2))\/0.04, color='grey', linestyle='--')\nax.axvline(norm_dis.interval(alpha=0.997)[1], ymin=0, ymax=norm_dis.pdf(norm_dis.ppf((1+0.997)\/2))\/0.04, color='grey', linestyle='--')\n\nax.axvline(norm_dis.interval(alpha=0.95)[0], ymin=0, ymax=norm_dis.pdf(norm_dis.ppf((1+0.95)\/2))\/0.04, color='grey', linestyle='--')\nax.axvline(norm_dis.interval(alpha=0.95)[1], ymin=0, ymax=norm_dis.pdf(norm_dis.ppf((1+0.95)\/2))\/0.04, color='grey', linestyle='--')\n\nax.axvline(norm_dis.interval(alpha=0.68)[0], ymin=0, ymax=norm_dis.pdf(norm_dis.ppf((1+0.68)\/2))\/0.04, color='grey', linestyle='--')\nax.axvline(norm_dis.interval(alpha=0.68)[1], ymin=0, ymax=norm_dis.pdf(norm_dis.ppf((1+0.68)\/2))\/0.04, color='grey', linestyle='--')\n\nax.axhline(norm_dis.pdf(norm_dis.ppf((1+0.68)\/2)), xmin=map_graphs(norm_dis.ppf((1-0.68)\/2), 40, 160, 0, 1), xmax=map_graphs(norm_dis.ppf((1+0.68)\/2), 40, 160, 0, 1), color='g', linestyle='--')\nax.axhline(norm_dis.pdf(norm_dis.ppf((1+0.95)\/2)), xmin=map_graphs(norm_dis.ppf((1-0.95)\/2), 40, 160, 0, 1), xmax=map_graphs(norm_dis.ppf((1+0.95)\/2), 40, 160, 0, 1), color='g', linestyle='--')\nax.axhline(norm_dis.pdf(norm_dis.ppf((1+0.997)\/2)), xmin=map_graphs(norm_dis.ppf((1-0.997)\/2), 40, 160, 0, 1), xmax=map_graphs(norm_dis.ppf((1+0.997)\/2), 40, 160, 0, 1), color='g', linestyle='--')\n\nx_fill = np.arange(norm_dis.ppf(0.001), norm_dis.ppf(0.95), 0.001)\ny_fill = norm_dis.pdf(x_fill)\nax.fill_between(x_fill, y_fill, 0, alpha=0.2, color='blue')\n\nplt.title('Normal Distribution (Mean = 100, STD = 12)', fontsize='15')\nplt.xlabel('Data')\nplt.xlim(40, 160)\nplt.ylabel('Probability Density')\nplt.ylim(0, 0.04)\nplt.legend();","37cbc0e9":"z = (123 - mean) \/ std\nprint(f\"z-score: {z} - <{norm.cdf(z)*100:.2f}%\")\n\n# One-tailed test\nprint(f\"p-value: {norm.sf(abs(z))}\")\n\n# Two-tailed test\nprint(f\"p-value: {norm.sf(abs(z))*2}\")\n\nprint(norm.ppf(0.975))\n\nprint(\"\\nSample\")\nsample = norm_dis.rvs(size=50)\nprint(f\"mean: {np.mean(sample)} - std: {np.std(sample)}\")\nz_sample=(np.mean(sample) - 104) \/ (np.std(sample)\/np.sqrt(50))\nprint(f\"z-score: {z_sample} - p-value: {norm.sf(abs(z_sample)):.5f}\")\n\nprint(f\"{np.mean(sample) - norm.ppf(0.975)*(np.std(sample)\/np.sqrt(50))} - {np.mean(sample) + norm.ppf(0.975)*(np.std(sample)\/np.sqrt(50))}\")\nprint(f\"{norm.interval(alpha=0.95, loc=np.mean(sample), scale=np.std(sample)\/np.sqrt(50))}\")\nprint(f\"{norm.ppf(0.025, loc=np.mean(sample), scale=np.std(sample)\/np.sqrt(50))}, {norm.ppf(0.975, loc=np.mean(sample), scale=np.std(sample)\/np.sqrt(50))}\")","a67fbf80":"iq_score=126\ndis_iq = norm(loc=100, scale=15)\n\nprint(f\"IQ score higher than >{iq_score}: {dis_iq.sf(iq_score)*100:.2f}%\")\nprint(f\"IQ score lower than <{iq_score}: {dis_iq.cdf(iq_score)*100:.2f}%\")\n\nx = np.arange(40, 160, 0.01)\ny = dis_iq.pdf(x)\n\nf, ax = plt.subplots(figsize=(15, 6))\nsns.lineplot(x=x, y=y , color='black', ax=ax, label='Distribution')\n\nax.axvline(100, color='r', ymin=0, ymax=dis_iq.pdf(dis_iq.ppf(0.5))\/0.028, linestyle='--', label=\"Mean\")\nax.axvline(iq_score, color='b', ymin=0, ymax=dis_iq.pdf(iq_score)\/0.028, linestyle='-.', label=f\"Score - {iq_score}\")\n\nax.axvline(dis_iq.interval(alpha=0.997)[0], ymin=0, ymax=dis_iq.pdf(dis_iq.ppf((1+0.997)\/2))\/0.028, color='grey', linestyle='--')\nax.axvline(dis_iq.interval(alpha=0.997)[1], ymin=0, ymax=dis_iq.pdf(dis_iq.ppf((1+0.997)\/2))\/0.028, color='grey', linestyle='--')\n\nax.axvline(dis_iq.interval(alpha=0.95)[0], ymin=0, ymax=dis_iq.pdf(dis_iq.ppf((1+0.95)\/2))\/0.028, color='grey', linestyle='--')\nax.axvline(dis_iq.interval(alpha=0.95)[1], ymin=0, ymax=dis_iq.pdf(dis_iq.ppf((1+0.95)\/2))\/0.028, color='grey', linestyle='--')\n\nax.axvline(dis_iq.interval(alpha=0.68)[0], ymin=0, ymax=dis_iq.pdf(dis_iq.ppf((1+0.68)\/2))\/0.028, color='grey', linestyle='--')\nax.axvline(dis_iq.interval(alpha=0.68)[1], ymin=0, ymax=dis_iq.pdf(dis_iq.ppf((1+0.68)\/2))\/0.028, color='grey', linestyle='--')\n\nx_fill = np.arange(dis_iq.ppf(0.001), dis_iq.ppf(dis_iq.cdf(iq_score)), 0.001)\ny_fill = dis_iq.pdf(x_fill)\nax.fill_between(x_fill, y_fill, 0, alpha=0.2, color='blue')\n\nplt.xlabel('Score')\nplt.xlim(40, 160)\nplt.ylabel('Probability')\nplt.ylim(0, 0.028)\nplt.legend();","89aae0f1":"import scipy.stats as st\n\ndis=np.random.normal(loc=0, scale=10, size=1000)\n\n# n<30\n# ci_t=st.t.interval(alpha=0.995, df=len(dis)-1, loc=np.mean(dis), scale=np.std(dis))\n# print(ci_t)\n\n# n\u226530\nci_normal_997=st.norm.interval(alpha=0.997, loc=np.mean(dis), scale=np.std(dis))\nprint(ci_normal_997)\n\nci_normal_95=st.norm.interval(alpha=0.95, loc=np.mean(dis), scale=np.std(dis))\nprint(ci_normal_95)\n\nci_normal_68=st.norm.interval(alpha=0.68, loc=np.mean(dis), scale=np.std(dis))\nprint(ci_normal_68)\n\nf, ax = plt.subplots(figsize=(20, 6))\nsns.kdeplot(dis, shade=False, ax=ax)\n\nax.axvline(ci_normal_997[0], color='blue', linestyle='--')\nax.axvline(ci_normal_997[1], color='blue', linestyle='--')\n\nax.axvline(ci_normal_95[0], color='green', linestyle='--')\nax.axvline(ci_normal_95[1], color='green', linestyle='--')\n\nax.axvline(ci_normal_68[0], color='red', linestyle='--')\nax.axvline(ci_normal_68[1], color='red', linestyle='--')\n\nax.spines.right.set_visible(False)\nax.spines.top.set_visible(False)\nax.xaxis.set_ticks_position('bottom')\n\n\nkde = st.gaussian_kde(dis)\npos = np.linspace(dis.min(), dis.max(), 101)\n\n# 99.7%\nshade = np.linspace(ci_normal_997[0], ci_normal_95[0], 101)\nax.fill_between(shade, kde(shade), alpha=0.5, color=\"blue\")\n\nshade = np.linspace(ci_normal_95[1], ci_normal_997[1], 101)\nax.fill_between(shade, kde(shade), alpha=0.5, color=\"blue\")\n\n# 95%\nshade = np.linspace(ci_normal_95[0], ci_normal_68[0], 101)\nax.fill_between(shade, kde(shade), alpha=0.5, color=\"green\")\n\nshade = np.linspace(ci_normal_68[1], ci_normal_95[1], 101)\nax.fill_between(shade, kde(shade), alpha=0.5, color=\"green\")\n\n# 68%\nshade = np.linspace(ci_normal_68[0], ci_normal_68[1], 101)\nax.fill_between(shade, kde(shade), alpha=0.5, color=\"red\");","3b05bba5":"n = 4\nnumber_trials = 100\n\nsample_list = []\n\nfor i in range(number_trials):\n    sample = norm_dis.rvs(size=n)\n    sample_list.append(sample)\n\nfig, ax = plt.subplots(1, 1, figsize=(6, 10))\nax.axvline(mean, color='darkorange')\n\nfor i in range(number_trials):   \n    if (mean<np.mean(sample_list[i])-2*np.std(sample_list[i])) or (mean>np.mean(sample_list[i])+2*np.std(sample_list[i])):\n        ax.errorbar(x=np.mean(sample_list[i]), y=(i*10)+10, xerr=2*np.std(sample_list[i]), yerr=0, lolims=True, linestyle='', c='red')\n    else:\n        ax.errorbar(x=np.mean(sample_list[i]), y=(i*10)+10, xerr=2*np.std(sample_list[i]), yerr=0, lolims=True, linestyle='', c='black')\n\nax.axvline(norm_dis.interval(alpha=0.95)[0], ymin=0, ymax=1, color='grey', linestyle='--')\nax.axvline(norm_dis.interval(alpha=0.95)[1], ymin=0, ymax=1, color='grey', linestyle='--')\n\nplt.ylim(0,1000);","c101e7e4":"n = 30\nnumber_samples = 10000\n\nsample_means = []\n\nfor i in range(number_samples):\n    sample = norm_dis.rvs(size=n)\n    sample_means.append(np.mean(sample))\n    \nprint(f\"population mean: {mean}, mean of samples means: {np.mean(sample_means)}\")\nprint(f\"population std: {std}, std of samples means: {np.std(sample_means)}\")\n    \nf, ax = plt.subplots(figsize=(10, 5))\nsns.histplot(sample_means, stat=\"density\", ax=ax);","61c00af9":"np.random.binomial(n=1, p=0.5, size=100)","887d54c1":"f, ax = plt.subplots(figsize=(10, 5))\nsns.histplot(np.random.binomial(n=10, p=0.5, size=5000), stat=\"probability\");","910d45e4":"from scipy.stats import binom\n\nk=7\nn=15\np=0.6\nprint(f\"Probability to throw {k} balls in a ring from {n} attempts: {(binom.pmf(k=k, n=n, p=p)*100):.2f}%\")\nprint(f\"Probability to throw less than {k} balls in a ring from {n} attempts: {(binom.cdf(k=k, n=n, p=p)*100):.2f}%\")\nprint(f\"Probability to throw more than {k} balls in a ring from {n} attempts: {(binom.sf(k=k, n=n, p=p)*100):.2f}%\")\nprint(f\"95% probability: {binom.ppf(q=0.95, n=n, p=p)}\")","53539ea6":"xs = np.arange(0, 15)\ndist = []\n\nfor i in range(xs.shape[0]):\n    dist.append(binom.pmf(k=i, n=n, p=p))\n\nf, ax = plt.subplots(figsize=(10, 5))\nsns.barplot(x=xs, y=dist, color=\"b\");","8b48d9de":"from scipy.stats import binom_test\n\np = binom_test(x=8, n=24, p=1\/6, alternative='greater')\nprint(f'p-value: {p:.5f}')\n\nif p > 0.05:\n    print('Probably die is not biased')\nelse:\n    print('Probably die is biased')","9cc01843":"np.random.poisson(lam=2, size=100)","08f729dd":"f, ax = plt.subplots(figsize=(10, 5))\nsns.histplot(np.random.poisson(lam=5, size=5000), stat=\"probability\");","8878525b":"from scipy.stats import poisson\n\nmean=5\nobserved=3\nprint(f\"Probability to see 3 meteors in one hour: {(poisson.pmf(k=observed, mu=mean)*100):.2f}%\")\nprint(f\"Probability to see less than 3 meteors in one hour: {(poisson.cdf(k=observed, mu=mean)*100):.2f}%\")\nprint(f\"Probability to see more than 3 meteors in one hour: {(poisson.sf(k=observed, mu=mean)*100):.2f}%\")\nprint(f\"95% probability: {poisson.ppf(q=0.95, mu=mean)}\")","787861b7":"xs = np.arange(0, 15)\ndist = []\n\nfor i in range(xs.shape[0]):\n    dist.append(poisson.pmf(i, mean))\n\nf, ax = plt.subplots(figsize=(10, 5))\nsns.barplot(x=xs, y=dist, color=\"b\");","2013ded3":"np.random.uniform(size=10)","76662d7b":"np.random.logistic(loc=1, scale=2, size=10)","9eb78678":"np.random.multinomial(n=6, pvals=[1\/6, 1\/6, 1\/6, 1\/6, 1\/6, 1\/6])","f1b6cd89":"np.random.exponential(scale=2, size=10)","aae3316e":"np.random.chisquare(df=2, size=10)","4db7e352":"np.random.rayleigh(scale=2, size=10)","83b8d0b4":"np.random.pareto(a=2, size=10)","ece40655":"sns.kdeplot(np.random.normal(loc=50, scale=7, size=1000), label='normal')\nsns.kdeplot(np.random.binomial(n=50, p=0.5, size=1000), label='binomial')\nsns.kdeplot(np.random.poisson(lam=50, size=1000), label='poisson')\nsns.kdeplot(np.random.logistic(loc=50, scale=7, size=1000), label='logistic')\nsns.kdeplot(np.random.exponential(scale=10, size=1000), label='exponential')\nsns.kdeplot(np.random.chisquare(df=10, size=1000), label='chi square')\nsns.kdeplot(np.random.pareto(a=1.002, size=100), label='pareto')\n\nplt.legend();","24ed6f48":"dis1=np.random.normal(loc=0, scale=10, size=1000)\ndis2=np.random.normal(loc=0.5, scale=5, size=1000)\ndis_exp=np.random.exponential(scale=15, size=1000)\n\nprint(f\"dis1 mean: {np.mean(dis1)}\")\nprint(f\"dis2 mean: {np.mean(dis2)}\")\nprint(f\"dis_exp mean: {np.mean(dis_exp)}\")\n\nsns.kdeplot(dis1, label='dis1')\nsns.kdeplot(dis2, label='dis2')\nsns.kdeplot(dis_exp, label='dis_exp')\n\nplt.legend();","42ab3a8b":"pip install --quiet fitter","eb370ea7":"data = gamma.rvs(2, loc=1.5, scale=2, size=10000)","ec2d15ba":"from fitter import Fitter\n\nf = Fitter(data, distributions=['gamma', 'rayleigh', 'uniform', 'norm', 't'])\nf.fit()\nf.summary()","d21487ad":"f = Fitter(dis1, distributions=['gamma', 'rayleigh', 'uniform', 'norm', 't'])\nf.fit()\nf.summary()","af45ea9c":"mean, var, skew = f.fitted_param['gamma']\n\nprint(f'mean: {mean}\\nsigma: {var}\\nshape: {skew}')","0554c2cb":"from scipy.stats import shapiro\n\nstat, p = shapiro(dis1)\nprint(f'stat: {stat:.5f}\\np-value: {p:.5f}')\n\nif p > 0.05:\n    print('Probably Gaussian')\nelse:\n    print('Probably not Gaussian')","4db8f0d1":"from scipy.stats import normaltest\n\nstat, p = normaltest(dis1)\nprint(f'stat: {stat:.5f}\\np-value: {p:.5f}')\n\nif p > 0.05:\n    print('Probably Gaussian')\nelse:\n    print('Probably not Gaussian')","d8f5365f":"from scipy.stats import anderson\n\nresult = anderson(dis1)\nprint(f'stat: {result.statistic:.3f}')\n\nfor i in range(len(result.critical_values)):\n    sl, cv = result.significance_level[i], result.critical_values[i]\n    \n    if result.statistic < cv:\n        print('Probably Gaussian at the %.1f%% level' % (sl))\n    else:\n        print('Probably not Gaussian at the %.1f%% level' % (sl))","5f687f24":"from scipy.stats import pearsonr\n\nstat, p = pearsonr(dis1, dis2)\nprint(f'stat: {stat:.5f}\\np-value: {p:.5f}')\n\nif p > 0.05:\n    print('Probably independent')\nelse:\n    print('Probably dependent')","effb76aa":"from scipy.stats import spearmanr\n\nstat, p = spearmanr(dis1, dis2)\nprint(f'stat: {stat:.5f}\\np-value: {p:.5f}')\n\nif p > 0.05:\n    print('Probably independent')\nelse:\n    print('Probably dependent')","bb0f2256":"from scipy.stats import kendalltau\n\nstat, p = kendalltau(dis1, dis2)\nprint(f'stat: {stat:.5f}\\np-value: {p:.5f}')\n\nif p > 0.05:\n    print('Probably independent')\nelse:\n    print('Probably dependent')","8fd7db06":"from scipy.stats import chi2_contingency\n\nstat, p, dof, expected = chi2_contingency([np.random.normal(loc=100, scale=10, size=1000), np.random.normal(loc=100, scale=10, size=1000)])\nprint(f'stat: {stat:.5f}\\np-value: {p:.5f}\\ndf: {dof}')\n\nprint(expected)\n\nif p > 0.05:\n    print('Probably independent')\nelse:\n    print('Probably dependent')","f7d12d46":"!pip install permutation_test","47bb2860":"from mlxtend.evaluate import permutation_test\n\np_value = permutation_test(dis1, dis2, method='approximate', num_rounds=10000, seed=0)\nprint(f\"{p_value:.9f}\")\n\nif p_value > 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')","323f23c6":"def exact_mc_perm_test(xs, ys, nmc):\n    n, k = len(xs), 0\n    diff = np.abs(np.mean(xs) - np.mean(ys))\n    zs = np.concatenate([xs, ys])\n    for j in range(nmc):\n        np.random.shuffle(zs)\n        k += diff < np.abs(np.mean(zs[:n]) - np.mean(zs[n:]))\n    return k \/ nmc\n\nexact_mc_perm_test(dis1, dis2, 10000)","45287f84":"from scipy.stats import ttest_ind\n\nprint(f\"sample1 var: {dis1.var():.2f}\\nsample2 var: {dis2.var():.2f}\\n\")\nprint(f\"sample1 mean: {dis1.mean():.2f}\\nsample2 mean: {dis2.mean():.2f}\\n\")\n\nstat, p = ttest_ind(dis1, dis2, equal_var=False)\nprint(f'stat: {stat:.5f}\\np-value: {p:.5f}')\n\nif p > 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')","83e4fce9":"from scipy.stats import ttest_rel\n\nstat, p = ttest_rel(dis1, dis2)\nprint(f'stat: {stat:.5f}\\np-value: {p:.5f}')\n\nif p > 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')","61d4524f":"from scipy.stats import f_oneway\n\nstat, p = f_oneway(dis1, dis2)\nprint(f'stat: {stat:.5f}\\np-value: {p:.5f}')\n\nif p > 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')","3f8dd2b9":"from scipy.stats import mannwhitneyu\n\nstat, p = mannwhitneyu(dis1, dis2)\nprint(f'stat: {stat:.3f}\\np-value: {p:.3f}')\n\nif p > 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')","d9018170":"from scipy.stats import wilcoxon\n\nstat, p = wilcoxon(dis1, dis2)\nprint(f'stat: {stat:.3f}\\np-value: {p:.3f}')\n\nif p > 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')","a64ff852":"from scipy.stats import kruskal\n\nstat, p = kruskal(dis1, dis2)\nprint(f'stat: {stat:.3f}\\np-value: {p:.3f}')\n\nif p > 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')","e6e751c5":"from scipy.stats import friedmanchisquare\n\nstat, p = friedmanchisquare(dis1, dis2, dis1)\nprint(f'stat: {stat:.3f}\\np-value: {p:.3f}')\n\nif p > 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')","2707970c":"dis_sim = norm(loc=100, scale=35)\nprint(\"Population\")\nprint(f\"mean: {dis_sim.mean()}\\nstd: {dis_sim.std()}\")\nprint(f\"CI 95%: {dis_sim.interval(alpha=0.95)}\")\n\nsize = 1500\n\nprint(\"\\nSample 1\")\nsample1 = dis_sim.rvs(size=size)\n\nprint(f\"mean: {sample1.mean():.1f}\\nvar: {sample1.var():.1f}\\nstd: {sample1.std():.1f}\")\nprint(f\"CI 95%: {norm.interval(alpha=0.95, loc=np.mean(sample1), scale=np.std(sample1)\/np.sqrt(size))}\")\n\nprint(\"\\nSample 2\")\nsample2 = dis_sim.rvs(size=size)\n\nprint(f\"mean: {sample2.mean():.1f}\\nvar: {sample2.var():.1f}\\nstd: {sample2.std():.1f}\")\nprint(f\"CI 95%: {norm.interval(alpha=0.95, loc=np.mean(sample2), scale=np.std(sample2)\/np.sqrt(size))}\")\n\nprint(\"\\nSample 3\")\nsample3 = dis_sim.rvs(size=size)\n\nprint(f\"mean: {sample3.mean():.1f}\\nvar: {sample3.var():.1f}\\nstd: {sample3.std():.1f}\")\nprint(f\"CI 95%: {norm.interval(alpha=0.95, loc=np.mean(sample3), scale=np.std(sample3)\/np.sqrt(size))}\")","e30fae2c":"from scipy.stats import ttest_1samp\n\nfor i in range(90,111):\n    stat, p = ttest_1samp(a=norm.rvs(loc=100, scale=10, size=27), popmean=i)\n    print(f'{i} - stat: {stat:.5f} \/\/ p-value: {p:.5f} - {\"Yes\" if p > 0.05 else \"No\"}')","c6b02329":"# z = (sample1.mean() - dis_sim.mean())\/(dis_sim.std()\/np.sqrt(size))\n# print(f\"z-test: {z}\")\n\n# One-tailed test\n# print(f\"p-value: {norm.sf(abs(z))}\")\n\n# Two-tailed test\n# print(f\"p-value: {(norm.sf(abs(z))*2)}\")\n\nsteps = np.arange(90, 110, 1)\nfor i in range(len(steps)):\n    p = norm.sf(abs((sample1.mean() - steps[i])\/(dis_sim.std()\/np.sqrt(size))))\n    print(f'{steps[i]} - p-value: {p:.5f} - {\"Yes\" if p > 0.05 else \"No\"}')","16295038":"from scipy.stats import chi2\n\nprint(np.sqrt(((size-1)*sample1.std()**2)\/chi2.ppf(0.95, df=size-1)))\nprint(np.sqrt(((size-1)*sample1.std()**2)\/chi2.ppf(0.05, df=size-1)))","e7296c4d":"print(sample1.mean()-norm.ppf(1-0.05\/2)*(sample1.std()\/np.sqrt(size)))\nprint(sample1.mean()+norm.ppf(1-0.05\/2)*(sample1.std()\/np.sqrt(size)))","30891eea":"sp=((size-1)*sample1.std()**2 + (size-1)*sample2.std()**2)\/(size+size-2)\nprint((sample1.mean()-sample2.mean())-t.ppf(q=1-0.05\/2, df=2*size-2)*np.sqrt((sp\/size)+(sp\/size)))\nprint((sample1.mean()-sample2.mean())+t.ppf(q=1-0.05\/2, df=2*size-2)*np.sqrt((sp\/size)+(sp\/size)))","34aa8e07":"f, ax = plt.subplots(figsize=(15, 6))\n\ndis_s1 = norm.fit(sample1)\ndis_s2 = norm.fit(sample2)\n\nx = np.arange(0, 200, 0.01)\ny1 = norm.pdf(x, *dis_s1)\ny2 = norm.pdf(x, *dis_s2)\n\nsns.lineplot(x=x, y=y1 , color='darkblue', ax=ax, label='dis1')\nsns.lineplot(x=x, y=y2 , color='brown', ax=ax, label='dis2')\n\nsns.histplot(sample1, bins=15, stat=\"density\", ax=ax, fill=False, element=\"step\", label='sample1')\nsns.histplot(sample2, bins=15, stat=\"density\", ax=ax, fill=False, element=\"step\", label='sample2')\n\nplt.legend();","494df792":"f, ax = plt.subplots(figsize=(15, 6))\nsns.kdeplot(sample1, label='sample1')\nsns.kdeplot(sample2, label='sample2')\n\nplt.legend();","c368115a":"f, ax = plt.subplots(figsize=(15, 6))\nsns.ecdfplot(sample1, label='sample1')\nsns.ecdfplot(sample2, label='sample2')\n\nplt.legend();","f689d526":"def cohend(d1, d2):\n    n1, n2 = len(d1), len(d2)\n    s1, s2 = np.var(d1, ddof=1), np.var(d2, ddof=1)\n    s = np.sqrt(((n1 - 1) * s1 + (n2 - 1) * s2) \/ (n1 + n2 - 2))\n    u1, u2 = np.mean(d1), np.mean(d2)\n    return (u1 - u2) \/ s\n\nd = cohend(sample1, sample2)\nprint(f'Cohens d: {d:.3f}')\n\nif d < 0.2:\n    print('small effect size')\nelif d < 0.8:\n    print('medium effect size')\nelse:\n    print('large effect size')","ea73bd1d":"print(f\"Sample 1 - mean: {sample1.mean():.1f} \\\\\\ var: {sample1.var():.1f} \\\\\\ std: {sample1.std():.1f}\")\nprint(f\"Sample 2 - mean: {sample2.mean():.1f} \\\\\\ var: {sample2.var():.1f} \\\\\\ std: {sample2.std():.1f}\")\nprint(f\"Sample 3 - mean: {sample3.mean():.1f} \\\\\\ var: {sample3.var():.1f} \\\\\\ std: {sample3.std():.1f}\")","457f12e2":"from scipy.stats import bartlett\n\nstat, p = bartlett(sample1, sample2, sample3)\nprint(f'stat: {stat:.5f}\\np-value: {p:.5f}')\n\nif p > 0.05:\n    print('The variances among the populations are equal')\nelse:\n    print('The variances among the populations are not equal')","7e55f563":"from scipy.stats import levene\n\nstat, p = levene(sample1, sample2, sample3, center='median')\nprint(f'stat: {stat:.5f}\\np-value: {p:.5f}')\n\nif p > 0.05:\n    print('The variances among the populations are equal')\nelse:\n    print('The variances among the populations are not equal')","056fc9bd":"from scipy.stats import f_oneway\n\nstat, p = f_oneway(sample1, sample2, sample3)\nprint(f'stat: {stat:.5f}\\np-value: {p:.5f}')\n\nif p > 0.05:\n    print('The mean is equal across all groups')\nelse:\n    print('The mean is not equal across all groups')","4b8a04c0":"from scipy.stats import kruskal\n\nstat, p = kruskal(sample1, sample2, sample3)\nprint(f'stat: {stat:.3f}\\np-value: {p:.3f}')\n\nif p > 0.05:\n    print('The median is equal across all groups')\nelse:\n    print('The median is not equal across all groups')","b88e0bc3":"from scipy.stats import friedmanchisquare\n\nstat, p = friedmanchisquare(sample1, sample2, sample3)\nprint(f'stat: {stat:.3f}\\np-value: {p:.3f}')\n\nif p > 0.05:\n    print('The mean is equal across all groups')\nelse:\n    print('The mean is not equal across all groups')","46cca9c8":"!pip install scikit-posthocs","df0b6d92":"import scikit_posthocs as sp\n\nsp.posthoc_dunn([sample1, sample2, sample3], p_adjust = 'bonferroni')","faa377de":"sp.posthoc_dunn([sample1, sample2, sample3], p_adjust = 'sidak')","8f033e53":"sp.posthoc_tukey_hsd(np.concatenate([sample1, sample2, sample3]), np.concatenate([['sample1'] * 1500, ['sample2'] * 1500, ['sample3'] * 1500]), alpha=0.05)","8d9433c7":"from statsmodels.stats.multicomp import pairwise_tukeyhsd\n\ntukey = pairwise_tukeyhsd(endog=np.concatenate([sample1, sample2, sample3]), \n                          groups=np.concatenate([['sample1'] * 1500, ['sample2'] * 1500, ['sample3'] * 1500]), alpha=0.05)\n\nprint(tukey)","7db9c0ec":"d=np.array([sample1, sample2, sample3])\nsp.posthoc_nemenyi_friedman(d.T)","d77c1469":"x = pd.DataFrame({\"sample1\": sample1, \"sample2\": sample2, \"sample3\": sample3})\nx = x.melt(var_name='groups', value_name='values')\nsp.posthoc_scheffe(x, val_col='values', group_col='groups')","60ff2fdd":"# ps = np.linspace(0, 100, 100)\n\nps = 100 * norm.cdf(np.linspace(-3, 3, 100))\nps = np.concatenate(([0], ps, [100]))\n\nx_p = np.percentile(sample1, ps)\n\nxs = np.sort(sample1)\nys = np.linspace(0, 1, len(sample1))\n\nf, ax = plt.subplots(figsize=(15, 6))\nsns.lineplot(x=xs, y=ys*100, label=\"ECDF\")\nsns.lineplot(x=x_p, y=ps, label=\"Percentiles\", marker=\".\", ms=12)\n\nplt.ylabel(\"Percentile\");\nplt.legend();","2ee370f8":"from scipy.interpolate import interp1d\n\nn = int(1e6)\nu = np.random.uniform(size=n)\nsamp_percentile_1 = interp1d(ps\/100, x_p)(u)\n\nf, ax = plt.subplots(figsize=(15, 6))\n_, bins, _ = plt.hist(sample1, bins=50, density=True, alpha=0.3, label=\"Data\")\nplt.hist(samp_percentile_1, bins=bins, density=True, histtype=\"step\", label=\"Percentiles\")\nplt.ylabel(\"Probability\")\nplt.legend();","6ba1bafc":"xs = [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5, 9.0, 9.5, 10.0]\nys = [0.2, 0.165, 0.167, 0.166, 0.154, 0.134, 0.117, 0.108, 0.092, 0.06, 0.031, 0.028, 0.048, 0.077, 0.103, 0.119, 0.119, 0.103, 0.074, 0.038, 0.003]\n\nsns.scatterplot(x=xs, y=ys)\nplt.xlabel(\"x\")\nplt.ylabel(\"Observed PDF\");\n\nx = np.linspace(min(xs), max(xs), 1000)\ny1 = interp1d(xs, ys)(x)\ny2 = interp1d(xs, ys, kind=\"nearest\")(x)\ny3 = interp1d(xs, ys, kind=\"quadratic\")(x)\ny4 = interp1d(xs, ys, kind=\"cubic\")(x)\n\nfrom scipy.interpolate import splev, splrep\ny5 = splev(x, splrep(xs, ys))\n\nplt.scatter(xs, ys, s=30, label=\"Data\", c=\"black\")\nplt.plot(x, y1, label=\"Linear (default)\")\nplt.plot(x, y2, label=\"Nearest\", alpha=0.3)\nplt.plot(x, y3, label=\"Quadratic\", ls='-')\nplt.plot(x, y4, label=\"Cubic\", ls='-')\nplt.plot(x, y5, label=\"Spline\", ls='-', alpha=1)\nplt.ylim(0, 0.21)\nplt.legend();","e60e8709":"from scipy.integrate import simps\n\ndef get_prob(xs, ys, a, b, resolution=1000):\n    x_norm = np.linspace(min(xs), max(xs), resolution)\n    y_norm = interp1d(xs, ys, kind=\"quadratic\")(x_norm)\n    normalisation = simps(y_norm, x=x_norm)\n    x_vals = np.linspace(a, b, resolution)\n    y_vals = interp1d(xs, ys, kind=\"quadratic\")(x_vals)\n    return simps(y_vals, x=x_vals) \/ normalisation\n\ndef get_cdf(xs, ys, v):\n    return get_prob(xs, ys, min(xs), v)\n\ndef get_sf(xs, ys, v):\n    return 1 - get_cdf(xs, ys, v)\n\nprint(get_prob(xs, ys, 0, 10))\nprint(get_cdf(xs, ys, 5))\nprint(get_sf(xs, ys, 5))","5f36f910":"v1, v2 = 6, 9.3\narea = get_prob(xs, ys, v1, v2)\n\nplt.scatter(xs, ys, s=30, label=\"Data\", color=\"black\")\nplt.plot(x, y3, linestyle=\"-\", label=\"Interpolation\")\nplt.fill_between(x, 0, y3, where=(x>=v1)&(x<=v2), alpha=0.2)\nplt.annotate(f\"p = {area:.3f}\", (7, 0.05))\nplt.ylim(0, 0.21)\nplt.legend();","58f4ce4f":"x_new = np.linspace(min(xs), max(xs), 100)\ncdf_new = [get_cdf(xs, ys, i) for i in x_new]\ncheap_cdf = y3.cumsum() \/ y3.sum()\n\nplt.plot(x_new, cdf_new, label=\"Interpolated CDF\")\nplt.plot(x, cheap_cdf, label=\"Super cheap CDF for specific cases\")\nplt.ylabel(\"CDF\")\nplt.xlabel(\"x\");","ab6dac86":"## Tukey\u2019s Test","6c7c89c9":"## Logistic Distribution\nUsed extensively in machine learning in logistic regression, neural networks etc.\n- **loc** - mean, where the peak is. Default 0.\n- **scale** - standard deviation, the flatness of distribution. Default 1.\n- **size** - The shape of the returned array.","e43d4965":"## Pareto Distribution\nA distribution following Pareto's law i.e. 80-20 distribution (20% factors cause 80% outcome).\n- **a** - shape parameter.\n- **size** - The shape of the returned array.","303351e4":"## Exponential Distribution\nExponential distribution is used for describing time till next event e.g. failure\/success etc.\n- **scale** - inverse of rate ( see lam in poisson distribution ) defaults to 1.0.\n- **size** - The shape of the returned array.","151790d4":"## Normal Distribution\n- **loc** - (Mean) where the peak of the bell exists.\n- **scale** - (Standard Deviation) how flat the graph distribution should be.\n- **size** - The shape of the returned array.","5c794998":"## One Sample z-test\n$$\\LARGE \\frac{\\bar{x}-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}$$","6fda075f":"## Brown-Forsythe Test","58d4ddb1":"### Pearson\u2019s Correlation Coefficient","36fc978e":"# Test distributions","24d7a1e2":"## Friedman Test","512ea499":"### D\u2019Agostino\u2019s $K^2$ Test","0ae78337":"## Kruskal-Wallis H Test","500ef8e2":"## Chi Square Distribution\nChi Square distribution is used as a basis to verify the hypothesis.\n- **df** - (degree of freedom).\n- **size** - The shape of the returned array.","c1700fba":"# Parametric Statistical Hypothesis Tests","f5b22ef9":"# Fitter","c3e0a496":"## Scheffe\u2019s Test","4a216d01":"## Permutation Test","6f377df2":"## One Sample t-test\n$$\\LARGE \\frac{\\bar{x}-\\mu}{\\frac{s}{\\sqrt{n}}}$$","1275c191":"## Binomial Test","f27ead0e":"# Normality Tests","85f3bde2":"# Correlation Tests","1e260598":"## Central Limit Theorem","8c6b1d04":"## Dunn\u2019s Test","c43a2228":"## Mann-Whitney U Test","8d3aa876":"## IQ score","cae2ea88":"## Confidence Interval for a Standard Deviation\n$$\\LARGE \\left [\\sqrt{\\frac{(n-1)s^2}{X^2_{\\alpha\/2}}}, \\sqrt{\\frac{(n-1)s^2}{X^2_{1-\\alpha\/2}}}\\right ]$$","c58a823e":"## Confidence Interval for the Difference Between Means\n$$\\LARGE sp = \\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1+n_2-2}$$  \n\n$$\\LARGE (\\bar{x}_1-\\bar{x}_2) \\pm t\\sqrt{\\frac{sp}{n_1} + \\frac{sp}{n_2}}$$","3362ab96":"## Effect Size","9617922d":"## Chi-Squared Test","18b23fbf":"## Multinomial Distribution\nIt describes outcomes of multi-nomial scenarios unlike binomial where scenarios must be only one of two. e.g. Blood type of a population, dice roll outcome.\n- **n** - number of possible outcomes (e.g. 6 for dice roll).\n- **pvals** - list of probabilties of outcomes (e.g. [1\/6, 1\/6, 1\/6, 1\/6, 1\/6, 1\/6] for dice roll).\n- **size** - The shape of the returned array.","0dd2f5a1":"## Wilcoxon Signed-Rank Test","f451a087":"# Simulations","7e3dc23a":"## Binomial Distribution\nIt describes the outcome of binary scenarios, e.g. toss of a coin, it will either be head or tails.\n- **n** - number of trials.\n- **k** - number of successes\n- **p** - probability of occurence of each trial (e.g. for toss of a coin 0.5 each).\n- **size** - The shape of the returned array.","4a36c0a3":"## Student\u2019s t-test\nCalculate the T-test for the means of two independent samples of scores.","e4b8e077":"## Nemenyi Test","5d0c8981":"### Generate a random float from 0 to 1","775a72ae":"## Friedman Test","b409690a":"## ANOVA","e05fabc4":"# Distributions","8d060b9c":"# Nonparametric Statistical Hypothesis Tests","b4380134":"### Generate an array containing 100 values, where each value has to be 1, 3, 5, 7, 9 or 11","e7421228":"## Confidence Interval","16263f92":"## Rayleigh Distribution\nRayleigh distribution is used in signal processing.\n- **scale** - (standard deviation) decides how flat the distribution will be default 1.0).\n- **size** - The shape of the returned array.","f4dec59c":"### Generate a random integer from 0 to 100","600bde9c":"## Poisson Distribution\nIt estimates how many times an event can happen in a specified time. e.g. If someone eats twice a day what is probability he will eat thrice?\n- **lam** - rate or known number of occurences e.g. 2 for above problem.\n- **size** - The shape of the returned array.","3e8a455d":"### Anderson-Darling Test","06077e54":"### Kendall\u2019s Rank Correlation","a01dc3f8":"## Kruskal-Wallis Test","ed7bf6c2":"## Paired Student\u2019s t-test\nCalculate the t-test on TWO RELATED samples of scores, a and b.","c788bdc6":"## Uniform Distribution\nUsed to describe probability where every event has equal chances of occuring.\n- **low** - lower bound - default 0 .0.\n- **high** - upper bound - default 1.0.\n- **size** - The shape of the returned array.","0537fb22":"# Random numbers","78719945":"### Spearman\u2019s Rank Correlation","126475b3":"## Bartlett\u2019s Test","232f135b":"## Analysis of Variance Test (ANOVA)","7b43290e":"### Shapiro-Wilk Test","9357617e":"## Confidence Interval for a Mean\n$$\\LARGE \\bar{x}\\pm z\\frac{s}{\\sqrt{n}}$$"}}