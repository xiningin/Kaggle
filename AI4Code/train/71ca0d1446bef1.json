{"cell_type":{"7e0b5831":"code","c2398085":"code","d15083d8":"code","88f8d76f":"code","417b1340":"code","e60bcc17":"code","e95b83d8":"code","22b4648c":"code","dcc3bf50":"code","e7b28f45":"code","2203b4d2":"code","51ff70f7":"code","144ca03c":"code","88068a29":"code","5789937f":"code","1d30fdea":"code","9dbbde88":"code","1859bfd2":"code","ed4aac71":"code","3919c488":"code","eb8de42c":"code","a2757dd1":"code","8921bed2":"code","4a048289":"code","b35a83dc":"code","f347a04d":"code","c12afd6d":"code","469a87ba":"code","7cf8005d":"code","b9eb5f26":"code","17c66b75":"code","0693fda0":"code","4a852124":"code","e6045ba9":"code","e5854e66":"code","97619af4":"code","9440cc4d":"code","a60cd2de":"code","a1548aab":"code","173ddd19":"code","e89666dd":"code","56068f19":"code","e2fae232":"code","75ba0e72":"code","164e0052":"code","82ed843a":"code","af37e96a":"code","fccb518e":"code","15a60da6":"code","a77df374":"code","1a797aa0":"code","a2dc325b":"code","10d5a36b":"code","8d3997d0":"code","99872f30":"code","920f310d":"code","f9f0645a":"code","7557bf81":"code","50ba8408":"code","d0e73eb2":"code","e76685ad":"code","e401a3f7":"code","798f8180":"code","b2624b5b":"code","fe922007":"code","99eaf229":"code","f5f78395":"code","6b2dcec5":"code","e7dbd116":"code","91c72bb0":"code","0975ded4":"code","831157fe":"code","9c4cceff":"code","865b2c39":"code","228af87d":"code","943c81f5":"code","836da763":"code","fcd07b48":"markdown","ff913132":"markdown","d032329d":"markdown","02cc0d82":"markdown","e514283f":"markdown","8fdc70e7":"markdown","49053cd8":"markdown","d9e8ad86":"markdown","72f9185a":"markdown","e6e9c342":"markdown","46e5e339":"markdown","f3be0c33":"markdown","2ab748aa":"markdown","17b93add":"markdown","5f6bf7c9":"markdown"},"source":{"7e0b5831":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n","c2398085":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","d15083d8":"df = pd.read_csv('..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')","88f8d76f":"df.head()","417b1340":"df.drop('customerID',axis=1,inplace= True)","e60bcc17":"df.head()","e95b83d8":"df.shape","22b4648c":"df.info()","dcc3bf50":"df.describe(include = 'all')","e7b28f45":"#finding the unique values in each column\nfor i in df.columns:\n    print(str(i)+ ':  '+ str(df[i].unique()))","2203b4d2":"#replacing NO internet service as No\ndf.replace('No internet service','No',inplace = True)","51ff70f7":"#finding the unique values in each column\nfor i in df.columns:\n    print(str(i)+ ':  '+ str(df[i].unique()))","144ca03c":"#replacing No phone service as No\ndf.replace('No phone service','No',inplace = True)","88068a29":"#finding the unique values in each column\nfor i in df.columns:\n    print(str(i)+ ':  '+ str(df[i].unique()))","5789937f":"df['Churn'].hist()","1d30fdea":"len(df[df['Churn']=='Yes'])","9dbbde88":"len(df[df['Churn']=='No'])","1859bfd2":"1869\/(1869+5174)","ed4aac71":"#check for the missing values in the dataset\ndf.isnull().sum()","3919c488":"#from the above error we can see that there are values with blank\nlen(df[df['TotalCharges']==' '])","eb8de42c":"df[df['TotalCharges']==' ']","a2757dd1":"pd.to_numeric(df.TotalCharges,errors='coerce').isnull()","8921bed2":"#removin the blank rows in Total Charges\ndf1 = df[df.TotalCharges!=' ']\ndf1.shape","4a048289":"df1.TotalCharges = pd.to_numeric(df1.TotalCharges)","b35a83dc":"df1['TotalCharges'].dtype","f347a04d":"#findin the categorical and numerical columns in the dataset\ncat_col = []\nnum_col = []\nfor i in df1.columns:\n    if df1[i].dtypes == 'O':\n        cat_col.append(i)\n    else:\n        num_col.append(i)","c12afd6d":"cat_col","469a87ba":"num_col","7cf8005d":"sns.heatmap(df1.corr(),annot = True)","b9eb5f26":"# import necessary libraries for chi-square test\nfrom scipy.stats import stats,chi2_contingency\n# creating function for performing chi-sqaure test on two columns\ndef chisq(i1,i2):\n    print(str(i1) + \" \" + str(i2))\n    dataset_table = pd.crosstab(df1[i1],df1[i2])\n    #Contingency Table  \n    stat, p, dof, expected = chi2_contingency(dataset_table)\n    #Observed Values\n    print(dataset_table.values)\n    #Expected Values\n    print(expected)   \n    #Degree of Freedom\n    print(dof)  \n    \n    #Significance Level 5%\n    alpha = 0.05\n    #chi-square statistic\n    from scipy.stats import chi2\n    chi_square=sum([(o-e)**2.\/e for o,e in zip(dataset_table.values,expected)])\n    chi_square_statistic=chi_square[0]+chi_square[1]\n    print(\"chi-square statistic:-\",chi_square_statistic)\n    #critical_value\n    critical_value=chi2.ppf(q=1-alpha,df=dof)\n    print('critical_value:',critical_value)\n    \n    #p-value\n    p_value=1-chi2.cdf(x=chi_square_statistic,df=dof)\n    print('p-value:',p_value)\n    print('Significance level: ',alpha)\n    print('Degree of Freedom: ',dof)\n    print('p-value:',p_value)\n\n    # conditional statements for checking chi-sqaure test condition for hypothesis selection based on chi_square_statistic and critical_value     \n    if chi_square_statistic>=critical_value:\n        print(\"Reject H0,There is a relationship between 2 categorical variables\")\n    else:\n        print(\"Retain H0,There is no relationship between 2 categorical variables\")\n    # conditional statements for checking chi-sqaure test condition for hypothesis selection based on p_value and alpha\n    if p_value<=alpha:\n        print(\"Reject H0,There is a relationship between 2 categorical variables\")\n    else:\n        print(\"Retain H0,There is no relationship between 2 categorical variables\")\n    \n    print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")","17c66b75":"for i in range(len(cat_col)):\n    for j in range(i+1):\n        if i==j:\n            continue\n        else:\n            chisq(cat_col[i],cat_col[j])","0693fda0":"tenure_churn_no = df1[df1.Churn=='No'].tenure\ntenure_churn_yes = df1[df1.Churn=='Yes'].tenure\n\nplt.xlabel(\"tenure\")\nplt.ylabel(\"Number Of Customers\")\nplt.title(\"Telecom Churn Prediction Visualiztion\")\n\n\nplt.hist([tenure_churn_yes, tenure_churn_no], rwidth=0.95, color=['green','red'],label=['Churn=Yes','Churn=No'])\nplt.legend()","4a852124":"mc_churn_no = df1[df1.Churn=='No'].MonthlyCharges      \nmc_churn_yes = df1[df1.Churn=='Yes'].MonthlyCharges      \n\nplt.xlabel(\"Monthly Charges\")\nplt.ylabel(\"Number Of Customers\")\nplt.title(\"Telecom Churn Prediction Visualiztion\")\n\nplt.hist([mc_churn_yes, mc_churn_no], rwidth=0.95, color=['green','red'],label=['Churn=Yes','Churn=No'])\nplt.legend()","e6045ba9":"# Scatter plot using matplotlib \nimport itertools\nimport matplotlib.pyplot as plt\n# create function for ploting scatterplot between two columns of dataset\ndef scatter(i,j):\n    plt.scatter(df1[i],df1[j],c =\"blue\")\n    plt.xlabel(i)\n    plt.ylabel(j)\n    plt.show()\n\n# Loop through numerical data list and use function to scatter plot between two columns\nl1 = list(itertools.permutations(num_col, 2))\n\nfor i in l1:\n    scatter(i[0],i[1])","e5854e66":"# Histogram using pandas \ndf1[num_col].hist(figsize =(15,8))","97619af4":"# goup data by jobType and plot count plot\ndf1.groupby('Churn').count().plot(kind='bar',figsize = (18,8))","9440cc4d":"for i in num_col:\n    sns.boxplot(df1[i])\n    plt.show()","a60cd2de":"cat_col","a1548aab":"for i in cat_col:\n    print(str(i) + \": \"+str(df1[i].unique()))","173ddd19":"#Replacing the Yes and No with 0 and 1\nyes_no_columns = ['Partner','Dependents','PhoneService','MultipleLines','OnlineSecurity','OnlineBackup',\n                  'DeviceProtection','TechSupport','StreamingTV','StreamingMovies','PaperlessBilling','Churn']\nfor col in yes_no_columns:\n    df1[col].replace({'Yes': 1,'No': 0},inplace=True)","e89666dd":"for col in df1:\n    print(f'{col}: {df1[col].unique()}') ","56068f19":"df1['gender'].replace({'Female':1,'Male':0},inplace=True)","e2fae232":"df2 = pd.get_dummies(data=df1, columns=['InternetService','Contract','PaymentMethod'])\ndf2.columns","75ba0e72":"df2.head()","164e0052":"from sklearn.preprocessing import MinMaxScaler\ndef scaling(df,col):\n    scalar = MinMaxScaler()\n    df[col] = scalar.fit_transform(df[col])\n    return df","82ed843a":"# Making a list of the column names to be scaled \ncols = df2.columns\n# passing data and column name for scaling\ndf2 = scaling(df2,cols)","af37e96a":"df2.head()","fccb518e":"from sklearn.model_selection import train_test_split","15a60da6":"X = df2.drop('Churn',axis='columns')\ny = df2['Churn']\n\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=5)","a77df374":"x_train.shape","1a797aa0":"x_test.shape","a2dc325b":"y_train.shape","10d5a36b":"from imblearn.over_sampling import RandomOverSampler","8d3997d0":"from collections import Counter\nos=RandomOverSampler(0.80)\nX_train_ns,y_train_ns=os.fit_resample(x_train,y_train)\nprint(\"The number of classes before fit {}\".format(Counter(y_train)))\nprint(\"The number of classes after fit {}\".format(Counter(y_train_ns)))","99872f30":"# Applying SMOTE\nfrom imblearn.over_sampling import SMOTE\nfrom collections import Counter\nsmote = SMOTE(sampling_strategy='minority')\nX_train_sm,y_train_sm = smote.fit_resample(x_train,y_train)\nprint(\"The number of classes before fit {}\".format(Counter(y_train)))\nprint(\"The number of classes after fit {}\".format(Counter(y_train_sm)))","920f310d":"import tensorflow as tf\nfrom tensorflow import keras\n\n\nmodel = keras.Sequential([\n    keras.layers.Dense(26, input_shape=(26,), activation='relu'),\n    keras.layers.Dropout(0.3),\n    keras.layers.Dense(15, activation='relu'),\n    keras.layers.Dropout(0.3),\n    keras.layers.Dense(1, activation='sigmoid')\n])\n\n# opt = keras.optimizers.Adam(learning_rate=0.01)\n\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nmodel.fit(X_train_sm,y_train_sm, epochs=100)","f9f0645a":"model.evaluate(x_test, y_test)","7557bf81":"yp = model.predict(x_test)\n\ny_pred = []\nfor element in yp:\n    if element > 0.5:\n        y_pred.append(1)\n    else:\n        y_pred.append(0)","50ba8408":"from sklearn.metrics import confusion_matrix , classification_report,accuracy_score\n\nprint(classification_report(y_test,y_pred))\nprint(confusion_matrix(y_test,y_pred))\nprint(accuracy_score(y_test,y_pred))\n","d0e73eb2":"import seaborn as sn\ncm = tf.math.confusion_matrix(labels=y_test,predictions=y_pred)\n\nplt.figure(figsize = (10,7))\nsn.heatmap(cm, annot=True, fmt='d')\nplt.xlabel('Predicted')\nplt.ylabel('Truth')","e76685ad":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Embedding, Flatten, LeakyReLU, BatchNormalization, Dropout\nfrom keras.activations import relu, sigmoid\nfrom keras.layers import LeakyReLU\n\nfrom sklearn.preprocessing import StandardScaler","e401a3f7":"from keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import GridSearchCV","798f8180":"def create_model(layers, activation):\n    model = Sequential()\n    for i, nodes in enumerate(layers):\n        if i==0:\n            model.add(Dense(nodes,input_dim=x_train.shape[1]))\n            model.add(Activation(activation))\n            \n        else:\n            model.add(Dense(nodes))\n            model.add(Activation(activation))\n            model.add(Dropout(0.3))\n    model.add(Dense(1)) # Note: no activation beyond this point\n    model.add(Activation(activation))\n    \n    model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n    return model\n    \nmodel = KerasClassifier(build_fn=create_model, verbose=0)","b2624b5b":"model","fe922007":"layers = [[20], [40, 20], [45, 30, 15],[60,40,20],[60,50,40,30,20,10]]\nactivations = ['sigmoid', 'relu']\nparam_grid = dict(layers=layers, activation=activations, batch_size = [128, 256], epochs=[10])\ngrid = GridSearchCV(estimator=model, param_grid=param_grid)","99eaf229":"grid_result = grid.fit(X_train_sm,y_train_sm)","f5f78395":"[grid_result.best_score_,grid_result.best_params_]","6b2dcec5":"import kerastuner\nfrom kerastuner.tuners import RandomSearch, Hyperband, BayesianOptimization","e7dbd116":"import pandas as pd\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras_tuner.tuners import RandomSearch","91c72bb0":"def build_model(hp):\n    model = keras.Sequential()\n    for i in range(hp.Int('num_layers', 2, 30)):\n        model.add(layers.Dense(units=hp.Int('units_' + str(i),\n                                            min_value=32,\n                                            max_value=512,\n                                            step=4),\n                               activation='relu'))\n    model.add(layers.Dense(1, activation='sigmoid'))\n    model.compile(\n        optimizer=keras.optimizers.Adam(\n            hp.Choice('learning_rate', [1e-1,1e-2, 1e-3, 1e-4])),\n        loss='binary_crossentropy',\n        metrics=['accuracy'])\n    return model","0975ded4":"tuner = RandomSearch(\n    build_model,\n    objective='val_accuracy',\n    max_trials=10,\n    executions_per_trial=1,\n    directory='my_dir9') #change the directory name here  when rerunning the cell else it gives \"Oracle exit error\" \n\ntuner.search_space_summary()","831157fe":"tuner.search(X_train_sm,y_train_sm,\n             epochs=100,\n             validation_data=(x_test,y_test))","9c4cceff":"tuner.results_summary()","865b2c39":"best_hyperparameters = tuner.get_best_hyperparameters(1)[0]\nprint(best_hyperparameters.values)\n\n# probing function tuner.get_best_hyperparameters(1) #skip this if details are not required\nprint(type(tuner.get_best_hyperparameters(1))) #list\nfor data in tuner.get_best_hyperparameters(1):\n  print(data.values)","228af87d":"model = tuner.hypermodel.build(best_hyperparameters)\nhistory = model.fit(X_train_sm,y_train_sm,\n             epochs=100,\n             validation_data=(x_test,y_test))","943c81f5":"# evaluate model\n_, acc = model.evaluate(x_test,y_test, verbose=0)\nprint('> %.3f' % (acc * 100.0))","836da763":"# Plot training & validation accuracy values\nepoch_range = range(1, 101) #6 here is the number of epochs of final training\nplt.plot(epoch_range, history.history['accuracy'])\nplt.plot(epoch_range, history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(epoch_range, history.history['loss'])\nplt.plot(epoch_range, history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='upper left')\nplt.show()","fcd07b48":"# scaling the data","ff913132":"###  Build a model (ANN) in tensorflow\/keras","d032329d":"# Converting categorical features to numerical features","02cc0d82":"# groupby","e514283f":"# results\n1. As the tenure increases Monthly chares are also increasing\n2. As the tenure increases Total chares are also increasing\n3. As Monthly Charges increase Total charges are also increasin","8fdc70e7":"# Handling Imbalanced Dataset","49053cd8":"# Data Visualization","d9e8ad86":"# hyper parameter tuning ","72f9185a":"## Box Plot","e6e9c342":"# Hyper parameter tuning using Keras-tuner","46e5e339":"# Correlation Matrix","f3be0c33":"1. As the tenure increases Monthly charges are also increasing\n2. As the tenure increases Total charges are also increasing(highly correlated) \n3. As Monthly Charges increase Total charges are also increasing","2ab748aa":"# Splitting the data into train_test split","17b93add":"# One hot encoding for categorical columns","5f6bf7c9":"# Chi-square Test"}}