{"cell_type":{"b5fa8346":"code","ea426cae":"code","52f179dc":"code","c6d680c3":"code","ba5233a0":"code","be87a1ea":"code","b1b65682":"code","18ca585e":"code","50cdb0e2":"code","aea141ca":"code","bd20942c":"markdown","7f1cd4c4":"markdown"},"source":{"b5fa8346":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ea426cae":"#importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","52f179dc":"#importing dataset\nds = pd.read_csv('..\/input\/mall-customer-relation\/mall customers.csv')\nds.head()","c6d680c3":"#getting dimensions\nds.shape","ba5233a0":"#to check for missing values\nds.isnull().any()","be87a1ea":"x = ds.iloc[:, [3,4]].values","b1b65682":"#using elbow method to find optimal no of clusters\nfrom sklearn.cluster import KMeans\nwcss = []\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n    kmeans.fit(x)\n    wcss.append(kmeans.inertia_)\nplt.plot(range(1, 11), wcss)\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()","18ca585e":"#training the k-means model on the dataset\nkmeans = KMeans(n_clusters = 5, init = 'k-means++', random_state = 42)\ny_kmeans = kmeans.fit_predict(x)","50cdb0e2":"#dependent variable created using k-means\nprint(y_kmeans)","aea141ca":"#visualising clusters\nplt.scatter(x[y_kmeans == 0, 0], x[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\nplt.scatter(x[y_kmeans == 1, 0], x[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\nplt.scatter(x[y_kmeans == 2, 0], x[y_kmeans == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\nplt.scatter(x[y_kmeans == 3, 0], x[y_kmeans == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4')\nplt.scatter(x[y_kmeans == 4, 0], x[y_kmeans == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5')\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 300, c = 'yellow', label = 'Centroids')\nplt.title('Clusters of customers')\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.show()","bd20942c":"NO MISSING DATA","7f1cd4c4":"**K-Means Clustering** to determine the behaviour\/pattern of the customers in a mall"}}