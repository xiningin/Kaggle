{"cell_type":{"92d737d4":"code","4286fb5f":"code","9a3e4cae":"code","f1eb0bb5":"code","6b50c1a4":"code","e2f99480":"code","4f7b4843":"code","ad9c335d":"code","4be78afb":"code","36e1f143":"code","17869288":"code","9ab846dd":"code","da59ff59":"code","b38e008f":"code","1bc82a36":"code","535062ce":"code","a273d606":"markdown","882928db":"markdown","c6d7757e":"markdown","43e49ad4":"markdown","be0d689c":"markdown","c86a0b52":"markdown"},"source":{"92d737d4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4286fb5f":"import sklearn\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import LabelEncoder","9a3e4cae":"print('Pandas : %s'%(pd.__version__))\nprint('Numpy : %s'%(np.__version__))\nprint('Scikit-Learn : %s'%(sklearn.__version__))\n!python --version","f1eb0bb5":"def grap_year(data):\n    data = str(data)\n    return int(data[:4])","6b50c1a4":"def grap_month(data):\n    data = str(data)\n    return int(data[4:])","e2f99480":"#\ub0a0\uc9dc \ucc98\ub9ac\ndata = pd.read_csv('..\/input\/jejudata\/jeju_data_ver1\/201901-202003.csv')","4f7b4843":"data = data.fillna('')\ndata['year'] = data['REG_YYMM'].apply(lambda x: grap_year(x))\ndata['month'] = data['REG_YYMM'].apply(lambda x: grap_month(x))\ndata = data.drop(['REG_YYMM'], axis=1)","ad9c335d":"#\ub370\uc774\ud130 \uc815\uc81c\n\ndf = data.copy()\ndf = df.drop(['CARD_CCG_NM', 'HOM_CCG_NM'], axis=1)\n\n\n\n","4be78afb":"columns = ['CARD_SIDO_NM', 'STD_CLSS_NM', 'HOM_SIDO_NM', 'AGE', 'SEX_CTGO_CD', 'FLC', 'year', 'month']\ndf = df.groupby(columns).sum().reset_index(drop=False)","36e1f143":"# \uc778\ucf54\ub529\ndtypes = df.dtypes\nencoders = {}\nfor column in df.columns:\n    if str(dtypes[column]) == 'object':\n        encoder = LabelEncoder()\n        encoder.fit(df[column])\n        encoders[column] = encoder\n        \ndf_num = df.copy()        \nfor column in encoders.keys():\n    encoder = encoders[column]\n    df_num[column] = encoder.transform(df[column])","17869288":"# feature, target \uc124\uc815\ntrain_num = df_num.sample(frac=1, random_state=0)\ntrain_features = train_num.drop(['CSTMR_CNT', 'AMT', 'CNT'], axis=1)\ntrain_target = np.log1p(train_num['AMT'])","9ab846dd":"# \ud6c8\ub828\nmodel = RandomForestRegressor(n_jobs=-1, random_state=0)\nmodel.fit(train_features, train_target)","da59ff59":"# \uc608\uce21 \ud15c\ud50c\ub9bf \ub9cc\ub4e4\uae30\nCARD_SIDO_NMs = df_num['CARD_SIDO_NM'].unique()\nSTD_CLSS_NMs  = df_num['STD_CLSS_NM'].unique()\nHOM_SIDO_NMs  = df_num['HOM_SIDO_NM'].unique()\nAGEs          = df_num['AGE'].unique()\nSEX_CTGO_CDs  = df_num['SEX_CTGO_CD'].unique()\nFLCs          = df_num['FLC'].unique()\nyears         = [2020]\nmonths        = [4, 7]\n\ntemp = []\nfor CARD_SIDO_NM in CARD_SIDO_NMs:\n    for STD_CLSS_NM in STD_CLSS_NMs:\n        for HOM_SIDO_NM in HOM_SIDO_NMs:\n            for AGE in AGEs:\n                for SEX_CTGO_CD in SEX_CTGO_CDs:\n                    for FLC in FLCs:\n                        for year in years:\n                            for month in months:\n                                temp.append([CARD_SIDO_NM, STD_CLSS_NM, HOM_SIDO_NM, AGE, SEX_CTGO_CD, FLC, year, month])\ntemp = np.array(temp)\ntemp = pd.DataFrame(data=temp, columns=train_features.columns)","b38e008f":"# \uc608\uce21\npred = model.predict(temp)\npred = np.expm1(pred)\ntemp['AMT'] = np.round(pred, 0)\ntemp['REG_YYMM'] = temp['year']*100 + temp['month']\ntemp = temp[['REG_YYMM', 'CARD_SIDO_NM', 'STD_CLSS_NM', 'AMT']]\ntemp = temp.groupby(['REG_YYMM', 'CARD_SIDO_NM', 'STD_CLSS_NM']).sum().reset_index(drop=False)","1bc82a36":"# \ub514\ucf54\ub529 \ntemp['CARD_SIDO_NM'] = encoders['CARD_SIDO_NM'].inverse_transform(temp['CARD_SIDO_NM'])\ntemp['STD_CLSS_NM'] = encoders['STD_CLSS_NM'].inverse_transform(temp['STD_CLSS_NM'])","535062ce":"# \uc81c\ucd9c \ud30c\uc77c \ub9cc\ub4e4\uae30\nsubmission = pd.read_csv('..\/input\/jejudata\/jeju_data_ver1\/submission.csv', index_col=0)\nsubmission = submission.drop(['AMT'], axis=1)\nsubmission = submission.merge(temp, left_on=['REG_YYMM', 'CARD_SIDO_NM', 'STD_CLSS_NM'], right_on=['REG_YYMM', 'CARD_SIDO_NM', 'STD_CLSS_NM'], how='left')\nsubmission.index.name = 'id'\nsubmission.to_csv('submission.csv', encoding='utf-8-sig')\nsubmission.head()","a273d606":"3. \ud0d0\uc0c9\uc801 \uc790\ub8cc\ubd84\uc11d\nExploratory Data Analysis","882928db":"5. \ubaa8\ub378 \ud559\uc2b5 \ubc0f \uac80\uc99d\nModel Tuning & Evaluation","c6d7757e":"1. \ub77c\uc774\ube0c\ub7ec\ub9ac \uac00\uc838\uc624\uae30","43e49ad4":"6. \uacb0\uacfc \ubc0f \uacb0\uc5b8\nConclusion & Discussion","be0d689c":"4. \ubcc0\uc218 \uc120\ud0dd \ubc0f \ubaa8\ub378 \uad6c\ucd95\nFeature Engineering & Initial Modeling","c86a0b52":"2. \ub370\uc774\ud130 \uc804\ucc98\ub9ac"}}