{"cell_type":{"57a5579d":"code","cc344fc7":"code","cde87b64":"code","c1cd1afe":"code","f4ddfe07":"code","42c5dc3c":"code","104ae178":"code","98c122d3":"code","8d799d36":"code","0da9d541":"code","00454ca5":"code","7809a75c":"code","601b90e9":"code","4447075e":"code","906c509c":"code","271fcf3c":"code","c7394cbf":"code","1c4d45ca":"code","1b7a2df5":"code","61359f3a":"code","be3ca276":"code","3cd2e522":"code","4a6a613c":"code","ff0d167b":"code","80c0aa4f":"code","058b535a":"code","af26a439":"markdown","f065eebf":"markdown","6b66438c":"markdown","98d604c1":"markdown","3a20217d":"markdown","83c0e0d8":"markdown","2ea199ab":"markdown","a8eada5a":"markdown","a92f29ff":"markdown","8ba4a5b3":"markdown"},"source":{"57a5579d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cc344fc7":"import matplotlib.pyplot as plt\nfrom PIL import Image\nfrom pathlib import Path","cde87b64":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.layers import GlobalAvgPool2D\n\nfrom tensorflow.keras.applications import InceptionResNetV2","c1cd1afe":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping\nfrom keras.models import load_model \nfrom keras.preprocessing.image import load_img,img_to_array","f4ddfe07":"base_model = InceptionResNetV2(weights=\"imagenet\", include_top=False, input_shape=(299,299,3))\n\nbase_model.summary()","42c5dc3c":"base_model.input","104ae178":"base_model.output","98c122d3":"# don't train existing weights\nfor layer in base_model.layers:\n    layer.trainable = False","8d799d36":"gap_layer = GlobalAvgPool2D() (base_model.output) # in-place of flatten\n\ndense_layer_1 = Dense(512, activation=\"relu\") (gap_layer)\ndense_layer_2 = Dense(256, activation=\"relu\") (dense_layer_1)\n\noutput_layer = Dense(10, activation=\"softmax\") (dense_layer_2)","0da9d541":"# create a model object\nmodel = Model(inputs=base_model.input, outputs=output_layer)","00454ca5":"#compile the model\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])","7809a75c":"# summery \nmodel.summary()","601b90e9":"training_path = \"..\/input\/10-monkey-species\/training\/training\/\"\ntesting_path = \"..\/input\/10-monkey-species\/validation\/validation\/\"","4447075e":"#for train datasets\ngenerator = ImageDataGenerator(rescale=1\/255,\n                               zoom_range = 0.2,\n                               width_shift_range=0.15,\n                               height_shift_range=0.15,\n                               horizontal_flip=True)\ntraining_instances = generator.flow_from_directory(training_path, \n                                                   target_size=(299, 299),\n                                                   batch_size=32)\n#for test dataset\ngenerator = ImageDataGenerator(rescale=1\/255)\ntest_instances = generator.flow_from_directory(testing_path,\n                                               target_size=(299, 299),\n                                               batch_size=32)","906c509c":"Epochs=20\nBatch_size=32\n#early stopping\nes=EarlyStopping(monitor=\"val_loss\",\n                           patience=5)\n#fit\nmodel_fit=model.fit(training_instances, \n                    steps_per_epoch=1098\/\/Batch_size,\n                    epochs=Epochs,\n                    validation_data=test_instances,\n                    callbacks=[es]\n                   )\n","271fcf3c":"# evaluate model\ntest_eval = model.evaluate(test_instances , verbose=0)\nprint('Test loss:', test_eval[0])\nprint('Test accuracy:', test_eval[1])\n\n#---------------------------------------------------\n\naccuracy = model_fit.history['accuracy']\nval_accuracy = model_fit.history['val_accuracy']\nloss = model_fit.history['loss']\nval_loss = model_fit.history['val_loss']\n\nepochs = range(len(accuracy))\n\nplt.figure(figsize=(15,6))\n\nplt.subplot(121)\nplt.plot(epochs, accuracy, 'bo', label='Training accuracy')\nplt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.subplot(122)\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","c7394cbf":"model.save(\"model_save.h5\")","1c4d45ca":"\nmodel_loaded = load_model('model_save.h5')","1b7a2df5":"model_loaded.evaluate(test_instances )","61359f3a":"labels_info = []\n\nlabels_path = Path(\"..\/input\/10-monkey-species\/monkey_labels.txt\")\n\n# Read the file\nlines = labels_path.read_text().strip().splitlines()[1:]\nfor line in lines:\n    line = line.split(',')\n    line = [x.strip(' \\n\\t\\r') for x in line]\n    line[3], line[4] = int(line[3]), int(line[4])\n    line = tuple(line)\n    labels_info.append(line)\n    \n# Convert the data into a pandas dataframe\nlabels_info = pd.DataFrame(labels_info, columns=['Label', 'Latin Name', 'Common Name', \n                                                 'Train Images', 'Validation Images'], index=None)\n# Sneak peek \nlabels_info","be3ca276":"# #load the image \nimg_path=training_path+\"n1\/n1017.jpg\"\nimg = load_img(path=img_path, target_size=(299, 299,3))\n# #convert to array\nimg_arr = img_to_array(img)\n# # prepare pixel data\nimg_arr=img_arr\/255\n# # reshape into a single sample with 3 channels\nimg_reshape = img_arr.reshape(1, 299, 299, 3)   #\/ 255\n# # img_arr\n# plt.imshow(img_arr)","3cd2e522":"Image.open(img_path)","4a6a613c":"y_pred = model_loaded.predict(img_reshape)\ny_pred","ff0d167b":"y_pred_label = np.argmax(y_pred, axis=1)\ndisplay(y_pred_label)","80c0aa4f":"lab=training_instances.class_indices\nlabel=list(lab.keys())\nlabel_name=labels_info['Common Name'].tolist()","058b535a":"print(f\"label : {label[y_pred_label[0]]}\")\nprint(f\"label_name : {label_name[y_pred_label[0]]}\")\n","af26a439":"## Attach new layers to base model ; FC Layer","f065eebf":"## Save and Load  the  train model","6b66438c":"## Load model without last Fully-Connected Layers for Transfer Learning","98d604c1":"## Fit the model to train-data","3a20217d":"## Test the images to the model","83c0e0d8":"## The end  :: For Now","2ea199ab":"## Read .txt file for label_name","a8eada5a":"## Evaluate the model with test dataset","a92f29ff":"## Loading Data with  ImageDataGenerator","8ba4a5b3":"#### Dataset : https:\/\/www.kaggle.com\/slothkong\/10-monkey-species"}}