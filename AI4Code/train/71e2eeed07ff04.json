{"cell_type":{"183920ad":"code","2b40ca8c":"code","76c02448":"code","41a1cc8d":"code","3b709e93":"code","a46617cb":"code","82c2f324":"code","e1e3b000":"code","0f97ef9d":"code","db0c693a":"code","568bb04c":"code","e8fce118":"code","7c1aa1e8":"code","63b2089e":"code","a5f52ae4":"code","64f21e69":"code","6f6abaf2":"code","25b6d77d":"code","a5e62d46":"code","b8ff53f2":"code","d0e0ee37":"code","a1f9e458":"code","2286accc":"code","aee37e21":"code","f44af6f0":"code","b520cf62":"code","61ed0a5e":"code","a5aacb8e":"code","ec5af553":"code","ed18cd2f":"code","30799242":"code","10152cb1":"code","0058da75":"code","f2f42241":"code","533d1abb":"code","5997aa90":"code","61e02d85":"code","7dab959a":"code","175fcc0f":"code","e026c9b2":"code","ddeb5e79":"code","a23b10bf":"code","9b9beda8":"code","727bc361":"code","9bcdb8c8":"code","45d5dc03":"code","4889522e":"code","97bad97e":"code","ba5d984d":"code","5239304a":"code","d6552aa2":"code","bc3518fa":"code","8a196ae6":"code","fe461adc":"code","98299947":"code","1a3e8dca":"code","1c759c11":"code","faf93432":"code","4b70d43f":"code","690275ed":"code","4b072a47":"code","b93e00f9":"code","977757e0":"code","03372d90":"code","52c53710":"code","3fd3e1e7":"code","b3bc2bc1":"code","9d64c29a":"code","7109b864":"code","7ef41579":"code","1e7d39d0":"code","2fd17026":"code","88772b48":"code","98ae35b2":"code","aeb3017d":"code","61ca665a":"code","9c6cbb26":"code","199c1cbd":"code","2a3165ed":"code","17618745":"code","b715ee20":"code","c0bb0a5c":"code","8b83cda2":"code","c027fd69":"code","4244de24":"code","f3d3a468":"code","69f695a9":"code","537c6c71":"code","7b45a1ea":"code","98502509":"code","0d37d8d2":"code","c64d5c06":"code","b440797c":"code","68b51222":"code","360f3565":"code","6eeda415":"code","a6e8f026":"code","92c5e1a6":"code","fb4364b9":"code","45fa4aff":"code","e212f05b":"code","10a22140":"code","ebc457c0":"code","ecf448a7":"code","634ec1b8":"code","acbf4d65":"code","7d1dd8d1":"code","1833b502":"code","09945d47":"code","3efd6978":"code","b9d58851":"code","3dd66935":"code","34f562e5":"code","a0cae80d":"code","0d9950c3":"code","fd2ab699":"code","153e696b":"code","ddaf4783":"code","344d38b6":"code","8e69b4dd":"code","ee044853":"code","c02029b0":"code","0591f99c":"code","3bc118ad":"code","31543489":"code","6105a027":"code","89164141":"code","b5d81574":"code","ee0972c3":"code","fccd4b68":"code","dc131085":"code","246ee10b":"code","b1c82c97":"code","8662d7c2":"code","7c1380ab":"code","f304e9cc":"code","2c98cd6b":"code","34002983":"code","abdae2f1":"code","dde6c1ed":"code","b645f24e":"code","b2e00b3a":"code","fc96920a":"code","9d572c66":"code","358c9da9":"code","39bf433b":"code","9233a558":"code","8e87b401":"code","0b5e8051":"code","ef512be8":"code","2f6f5e15":"code","eb7348ee":"code","2d0ca417":"code","db58d765":"code","1b2d4888":"code","068006a0":"code","fc965c6e":"code","b21388ae":"code","dc66f7ef":"code","f13285ce":"code","e92d872d":"code","9bca4c34":"code","42aa33ee":"code","c6aa639d":"code","9dd19838":"code","8afdd77d":"code","9d87f920":"code","d6083e8a":"code","4e61f85f":"code","e8d1cc0f":"code","1b223d9c":"code","f9978038":"code","344ff9b8":"code","04dab405":"code","f2ae9b54":"code","0bdc7ce9":"code","522faad9":"code","a51fe135":"code","fed65b79":"code","fbf81f8c":"code","88d59226":"code","a215612f":"markdown","b1544b8a":"markdown","3a93722e":"markdown","5dee5d6a":"markdown","bbf233f7":"markdown","7c2afac4":"markdown","047cc815":"markdown","5940c8fe":"markdown","70c30a6d":"markdown","843a3e21":"markdown","9372d12c":"markdown","6303b068":"markdown","0c602b50":"markdown","61a4e247":"markdown","7b864010":"markdown","4cfae3c2":"markdown","f2444071":"markdown","02d24344":"markdown","008f6017":"markdown","a192c91e":"markdown","6739ab43":"markdown","cf8a8f79":"markdown","d3d41888":"markdown","2419c434":"markdown","7e49dcf9":"markdown","aaf622a2":"markdown","ff60db72":"markdown","5a15f878":"markdown","d62ddcbc":"markdown","3e701da0":"markdown","ea2d186d":"markdown","fde7364a":"markdown","e6122c89":"markdown","d29a9a89":"markdown","9172e4bd":"markdown","8a8a92dc":"markdown","800843bc":"markdown","11475c5d":"markdown","bf17de64":"markdown","57d75ebf":"markdown","745dffa3":"markdown","ac7214ff":"markdown","dba6a596":"markdown","f5aee17d":"markdown","a40b9a27":"markdown","ed4cc4fb":"markdown","8f756d3a":"markdown","981d894d":"markdown","db92186a":"markdown","8cdfdef3":"markdown","4b086f83":"markdown","f83c9d81":"markdown","0f2f90e1":"markdown","e896a5f7":"markdown","f6b12429":"markdown","40b39a87":"markdown","80af9116":"markdown","26b6bed6":"markdown","96503d7f":"markdown","d8c042d8":"markdown","28ac6bc1":"markdown","ddcf99f3":"markdown","e1e3b00b":"markdown","7a2f1e45":"markdown","013f2c3c":"markdown","22d1a101":"markdown","0f9bd6a6":"markdown","9fa34710":"markdown","dd015b97":"markdown","b222277e":"markdown","862eb9d3":"markdown","1ad2a227":"markdown","adcc0146":"markdown","b1698c77":"markdown","b33adcbb":"markdown","553487ad":"markdown","7f951d0f":"markdown","0d05e16e":"markdown","601570ca":"markdown","a0d6cbca":"markdown","b8d464c6":"markdown","32ea2645":"markdown","84433796":"markdown"},"source":{"183920ad":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport cufflinks as cf\ncf.go_offline()\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score,roc_curve,roc_auc_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier,VotingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation,Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping\n#from regressors import stats\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom scipy.stats import skew\nimport warnings\n","2b40ca8c":"warnings.simplefilter(action='ignore', category=FutureWarning)\npd.set_option('display.float_format', lambda x: '%.3f' % x)","76c02448":"train = pd.read_csv('..\/input\/titanic\/train.csv',index_col='PassengerId')\ntest = pd.read_csv('..\/input\/titanic\/test.csv',index_col='PassengerId')","41a1cc8d":"test.index","3b709e93":"train.info()","a46617cb":"train.head()","82c2f324":"train.describe()","e1e3b000":"titanic_dict = {'survived':'survived',\n               'Pclass':'Ticket class',\n               'sex':'Sex',\n               'Age':'Age in years',\n               'Sibsp':'# of siblings \/ spouses aboard the Titanic',\n               'parch':'# of parents \/ children aboard the Titanic',\n               'ticket':'Ticket number',\n               'Fare':'Passenger fare',\n               'cabin':'Cabin number',\n               'Embarked':'Port of Embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)'}","0f97ef9d":"test.info()","db0c693a":"test.head()","568bb04c":"test.describe()","e8fce118":"train.isnull().sum()","7c1aa1e8":"plt.figure(figsize=(10,6))\nsns.heatmap(train.isnull(),cbar = False,yticklabels = False,cmap = \"coolwarm\") \nsns.set(font_scale=1.4)\nplt.title('Missing data features',fontsize = 20)\nplt.show()","63b2089e":"plt.figure(figsize=(10,6))\nsns.set_style('whitegrid')\nsns.countplot(x='Survived',data=train,palette='RdBu_r')\nplt.title(\"Survived\/not survived\")\nplt.show()","a5f52ae4":"plt.figure(figsize=(10,6))\nsns.set_style('whitegrid')\nsns.countplot(x='Survived',hue='Sex',data=train,palette='RdBu_r')\nplt.title('Survived\/not survived by sex')\nplt.show()","64f21e69":"plt.figure(figsize=(10,6))\nsns.countplot(x=\"Survived\",data = train, hue = \"Pclass\")\nplt.legend(title = titanic_dict['Pclass'])\nplt.show()","6f6abaf2":"plt.figure(figsize=(10,6))\nsns.distplot(train['Age'].dropna(),kde=False,color='darkred',bins=30)\nplt.title('Histogram of passengers age')\nplt.show()","25b6d77d":"plt.figure(figsize=(10,6))\nsns.distplot(train['Age'].dropna(),kde=False,color='darkred',bins=10)\nplt.title('Distribution of passengers age')\nplt.show()","a5e62d46":"plt.figure(figsize=(10,6))\nsns.countplot(x='SibSp',data=train)\nplt.xlabel(titanic_dict['Sibsp'])\nplt.title(\"Number of siblings \/ spouses abroad the Titanic\")\nplt.show()","b8ff53f2":"plt.figure(figsize=(10,6))\ntrain['Fare'].hist(color='green',bins=40,figsize=(10,6))\nplt.title(\"Histogram of passengers fare\")\nplt.xlabel(titanic_dict['Fare'])\nplt.show()","d0e0ee37":"train['Fare'].iplot(kind='hist',bins=30,color='green')","a1f9e458":"train['Age'].isnull().sum()\/(train['Age'].count()+train['Age'].isnull().sum())*100","2286accc":"plt.figure(figsize=(12, 7))\nsns.boxplot(x='Pclass',y='Age',data=train,palette='winter')","aee37e21":"train.groupby(\"Pclass\").mean()[\"Age\"]","f44af6f0":"def age_imputation(column):\n    Age = column[0]\n    Pclass = column[1]\n    if pd.isnull(Age):\n        if Pclass == 1:\n            return train[train[\"Pclass\"]==1].mean()[\"Age\"].round()\n        elif Pclass == 2:\n            return train[train[\"Pclass\"]==2].mean()[\"Age\"].round()\n        elif Pclass == 3:\n            return train[train[\"Pclass\"]==3].mean()[\"Age\"].round()\n    else:\n        return Age","b520cf62":"train[\"Age\"] = train[[\"Age\",\"Pclass\"]].apply(age_imputation,axis = 1)","61ed0a5e":"train.isnull().sum()","a5aacb8e":"train['Cabin'].isnull().sum()\/(train['Cabin'].count()+train['Cabin'].isnull().sum())*100","ec5af553":"train.drop(\"Cabin\", axis = 1, inplace = True)","ed18cd2f":"train.count()","30799242":"train.fillna(method = 'ffill',inplace=True)","10152cb1":"train.isnull().sum()","0058da75":"train['Name'].head()","f2f42241":"train['Name'].apply(lambda x:x.split()[1]).value_counts()","533d1abb":"train['Title'] = train.Name.str.extract(r',\\s([a-zA-Z ]+)', expand = True)","5997aa90":"train['Title'].value_counts()","61e02d85":"titles_dir = {'Master':'an English honorific for boys and young men',\n              'Dr':'an academic title that originates from the Latin word of the same spelling and meaning',\n             'Rev':'a title used before the name or rank of an officially appointed religious leader',\n             'Major':'a military rank standing above captain',\n             'Mlle':'the French equivalent of Miss',\n             'Col':'a written abbreviation for Colonel where Colonel is a honorary title',\n             'Don':'an honorific prefix primarily used in Spain and the former Spanish Empire (including the Philippines and Hispanoamerica), Croatia, India (in particular Goa), Italy, Portugal and Sri Lanka',\n             'Jonkheer':'an honorific in the Low Countries denoting the lowest rank within the nobility. In the Netherlands, this in general concerns a prefix used by the untitled nobility',\n             'Lady':'used before the family name of a woman with a title of nobility or honorary title suo jure (in her own right), or the wife of a lord, a baronet, Scottish feudal baron, laird, or a knight, and also before the first name of the daughter of a duke, marquess, or earl',\n             'the Countess':'a historical title of nobility in certain European countries, varying in relative status, generally of middling rank in the hierarchy of nobility',\n             'Ms':'an English honorific used with the last name or full name of a woman, intended as a default form of address for women regardless of marital status',\n             'Capt':'a title for the commander of a military unit, the commander of a ship, aeroplane, spacecraft, or other vessel, or the commander of a port, fire department or police department, election precinct, etc.',\n             'Sir':' formal English honorific address for men, derived from Sire in the High Middle Ages. Traditionally, as governed by law and custom, Sir is used for men titled knights i.e. of orders of chivalry, and later also to baronets, and other offices',\n             'Mme':'a traditional alternative for an unmarried woman. The plural is Mesdemoiselles (Mlles'}","7dab959a":"train['Title'] = train['Title'].replace(to_replace = ['Mlle','Ms'],value = 'Miss')","175fcc0f":"train['Title'] = train['Title'].replace(to_replace = ['Dr','Rev','Major','Col','Don','Jonkheer','Lady','the Countess','Capt','Sir'],value = 'Other')","e026c9b2":"train['Title'] = train['Title'].replace(to_replace = 'Mme',value = 'Mrs')","ddeb5e79":"train['Title'].value_counts()","a23b10bf":"plt.figure(figsize=(10,6))\nsns.boxplot(x='Title',y='Age', data = train)\nplt.show()","9b9beda8":"plt.figure(figsize=(10,6))\nsns.countplot(x = 'Survived', data = train, hue = 'Title')","727bc361":"map_title = {'Mr':1,'Miss':2,'Mrs':2,'Master':3,'Other':4}","9bcdb8c8":"train['Title'] = train['Title'].map(map_title)","45d5dc03":"skew_train = train.dtypes[train.dtypes != 'object'].index\nskew_train","4889522e":"skew_train_check = train[skew_train].apply(lambda x:skew(x)).sort_values(ascending=False)\nskew_train_check","97bad97e":"train['Fare'] = np.log(train['Fare']+1)","ba5d984d":"titanic_dict['Embarked']","5239304a":"map_embarked = {'C':1,'Q':2,'S':3}","d6552aa2":"train['Embarked'] = train['Embarked'].map(map_embarked)","bc3518fa":"dummy_sex = pd.get_dummies(train['Sex'],drop_first=True)","8a196ae6":"train = pd.concat([train,dummy_sex], axis = 1)","fe461adc":"train.drop(['Name','Sex','Ticket'],axis = 1, inplace = True)","98299947":"train.head()","1a3e8dca":"test.isnull().sum()","1c759c11":"plt.figure(figsize=(12, 7))\nsns.boxplot(x='Pclass',y='Age',data=test,palette='winter')","faf93432":"def age_imputation_test(column):\n    Age = column[0]\n    Pclass = column[1]\n    if pd.isnull(Age):\n        if Pclass == 1:\n            return test[test[\"Pclass\"]==1].mean()[\"Age\"].round()\n        elif Pclass == 2:\n            return test[test[\"Pclass\"]==2].mean()[\"Age\"].round()\n        elif Pclass == 3:\n            return test[test[\"Pclass\"]==3].mean()[\"Age\"].round()\n    else:\n        return Age","4b70d43f":"test[\"Age\"] = test[[\"Age\",\"Pclass\"]].apply(age_imputation_test,axis = 1)","690275ed":"test.isnull().sum()","4b072a47":"test['Cabin'].isnull().sum()\/(test['Cabin'].count()+test['Cabin'].isnull().sum())*100","b93e00f9":"test.drop(\"Cabin\", axis = 1, inplace = True)","977757e0":"plt.figure(figsize=(12, 7))\nsns.boxplot(x='Pclass',y='Fare',data=test,palette='winter')","03372d90":"test[test['Fare'].isnull()]","52c53710":"titanic_dict['Pclass']","3fd3e1e7":"test.fillna(value = test[test['Pclass']==3].mean()['Fare'], inplace = True)","b3bc2bc1":"test[test['Name']=='Storey, Mr. Thomas']","9d64c29a":"test.isnull().sum()","7109b864":"test['Title'] = test.Name.str.extract(r',\\s([a-zA-Z ]+)', expand = True)","7ef41579":"test['Title'].value_counts()","1e7d39d0":"test['Title'] = test['Title'].replace(to_replace = 'Ms',value = 'Miss')","2fd17026":"test['Title'] = test['Title'].replace(to_replace = ['Dr','Rev','Col','Dona'],value = 'Other')","88772b48":"test['Title'].value_counts()","98ae35b2":"plt.figure(figsize=(10,6))\nsns.boxplot(x='Title',y='Age', data = test)","aeb3017d":"test['Title'] = test['Title'].map(map_title)","61ca665a":"skew_test = test.dtypes[test.dtypes!='object'].index\nskew_test","9c6cbb26":"skew_test_check = test[skew_test].apply(lambda x:skew(x)).sort_values(ascending=False)\nskew_test_check","199c1cbd":"test['Fare'] = np.log(test['Fare']+1)","2a3165ed":"test['Embarked'] = test['Embarked'].map(map_embarked)","17618745":"dummy_sex_test = pd.get_dummies(test['Sex'],drop_first=True)","b715ee20":"test = pd.concat([test,dummy_sex_test], axis = 1)","c0bb0a5c":"test.drop(['Name','Sex','Ticket'],axis = 1, inplace = True)","8b83cda2":"test.head()","c027fd69":"train.head()","4244de24":"Evaluations = pd.DataFrame({'Model':[],'AUC_score':[],'F1_score':[]})","f3d3a468":"X = train.drop('Survived', axis = 1)\ny = train['Survived']","69f695a9":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)","537c6c71":"logmodel = LogisticRegression()\nlogmodel.fit(X_train,y_train)","7b45a1ea":"#features = ['Intercept','Pclass', 'Age', 'SibSp', 'Parch', 'Fare','Embarked','Title', 'male']","98502509":"#logmodel_p_value = pd.DataFrame({'Feature':features,'p-value':stats.coef_pval(logmodel,X_train, y_train)})","0d37d8d2":"#logmodel_p_value","c64d5c06":"logmodel_predictions = logmodel.predict(X_val)","b440797c":"logmodel_train_predictions = logmodel.predict(X_train)","68b51222":"fpr_log_model, tpr_log_model, threshold = roc_curve(y_val, logmodel_predictions)\nfpr_log_model_train, tpr_log_model_train, threshold = roc_curve(y_train, logmodel_train_predictions)\n","360f3565":"plt.figure(figsize=(10,6))\nplt.plot(fpr_log_model, tpr_log_model, label = 'Validation data')\nplt.plot(fpr_log_model_train, tpr_log_model_train, label = 'Training data')\nplt.title('Receiver operating characteristic (ROC)')\nplt.legend(loc = 'lower right',bbox_to_anchor=(1.45, 0.2))\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')","6eeda415":"Logmodel_evaluations = pd.DataFrame({'Model':['Logistic Regression'],\n                                     'F1_score':[f1_score(y_val,logmodel_predictions)],\n                                     'AUC_score':[roc_auc_score(y_val,logmodel_predictions)]})","a6e8f026":"Evaluations = Evaluations.append(Logmodel_evaluations)","92c5e1a6":"dtree = DecisionTreeClassifier()","fb4364b9":"dtree.fit(X_train,y_train)","45fa4aff":"d_tree_predictions = dtree.predict(X_val)","e212f05b":"d_tree_train_predictions = dtree.predict(X_train)","10a22140":"fpr_d_tree, tpr_d_tree, threshold = roc_curve(y_val, d_tree_predictions)\nfpr_d_tree_train, tpr_d_tree_train, threshold = roc_curve(y_train, d_tree_train_predictions)\n","ebc457c0":"plt.figure(figsize=(10,6))\nplt.plot(fpr_d_tree, tpr_d_tree, label = 'Validation data')\nplt.plot(fpr_d_tree_train, tpr_d_tree_train, label = 'Training data')\nplt.title('Receiver operating characteristic (ROC)')\nplt.legend(loc = 'lower right',bbox_to_anchor=(1.45, 0.2))\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')","ecf448a7":"dtree = DecisionTreeClassifier()","634ec1b8":"param_grid = {'max_depth':list(np.arange(1,10)),\n             'max_features': ['auto', 'sqrt', 'log2']}","acbf4d65":"grid_search_dtree = GridSearchCV(dtree,param_grid = param_grid,cv = 5)","7d1dd8d1":"grid_search_dtree.fit(X_train,y_train)","1833b502":"dtree = grid_search_dtree.best_estimator_","09945d47":"dtree","3efd6978":"d_tree_predictions = dtree.predict(X_val)","b9d58851":"d_tree_train_predictions = dtree.predict(X_train)","3dd66935":"fpr_d_tree, tpr_d_tree, threshold = roc_curve(y_val, d_tree_predictions)\nfpr_d_tree_train, tpr_d_tree_train, threshold = roc_curve(y_train, d_tree_train_predictions)\n","34f562e5":"plt.figure(figsize=(10,6))\nplt.plot(fpr_d_tree, tpr_d_tree, label = 'Validation data')\nplt.plot(fpr_d_tree_train, tpr_d_tree_train, label = 'Training data')\nplt.title('Receiver operating characteristic (ROC)')\nplt.legend(loc = 'lower right',bbox_to_anchor=(1.45, 0.2))\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')","a0cae80d":"d_tree_evaluations = pd.DataFrame({'Model':['Classification tree'],\n                                     'F1_score':[f1_score(y_val,d_tree_predictions)],\n                                     'AUC_score':[roc_auc_score(y_val,d_tree_predictions)]})","0d9950c3":"Evaluations = Evaluations.append(d_tree_evaluations)","fd2ab699":"random_forest = RandomForestClassifier(n_estimators=100)","153e696b":"random_forest.fit(X_train, y_train)","ddaf4783":"random_forest_predictions = random_forest.predict(X_val)","344d38b6":"random_forest_train_predictions = random_forest.predict(X_train)","8e69b4dd":"fpr_random_forest, tpr_random_forest, threshold = roc_curve(y_val, random_forest_predictions)\nfpr_random_forest_train, tpr_random_forest_train, threshold = roc_curve(y_train, random_forest_train_predictions)","ee044853":"plt.figure(figsize=(10,6))\nplt.plot(fpr_random_forest, tpr_random_forest, label = 'Validation data')\nplt.plot(fpr_random_forest_train, tpr_random_forest_train, label = 'Training data')\nplt.title('Receiver operating characteristic (ROC)')\nplt.legend(loc = 'lower right',bbox_to_anchor=(1.45, 0.2))\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')","c02029b0":"random_forest = RandomForestClassifier()","0591f99c":"param_grid = {'max_depth':list(np.arange(1,10)),\n              'n_estimators':[100,1000],\n             'max_features': ['auto', 'sqrt', 'log2']}","3bc118ad":"grid_search_rf = GridSearchCV(random_forest,param_grid = param_grid,cv = 5)","31543489":"grid_search_rf.fit(X_train, y_train)","6105a027":"random_forest = grid_search_rf.best_estimator_","89164141":"random_forest","b5d81574":"random_forest_predictions = random_forest.predict(X_val)","ee0972c3":"random_forest_train_predictions = random_forest.predict(X_train)","fccd4b68":"fpr_random_forest, tpr_random_forest, threshold = roc_curve(y_val, random_forest_predictions)\nfpr_random_forest_train, tpr_random_forest_train, threshold = roc_curve(y_train, random_forest_train_predictions)","dc131085":"plt.figure(figsize=(10,6))\nplt.plot(fpr_random_forest, tpr_random_forest, label = 'Validation data')\nplt.plot(fpr_random_forest_train, tpr_random_forest_train, label = 'Training data')\nplt.title('Receiver operating characteristic (ROC)')\nplt.legend(loc = 'lower right',bbox_to_anchor=(1.45, 0.2))\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')","246ee10b":"random_forest_evaluations = pd.DataFrame({'Model':['Random forest'],\n                                     'F1_score':[f1_score(y_val,random_forest_predictions)],\n                                     'AUC_score':[roc_auc_score(y_val,random_forest_predictions)]})","b1c82c97":"Evaluations = Evaluations.append(random_forest_evaluations)","8662d7c2":"extra_trees = ExtraTreesClassifier()","7c1380ab":"param_grid = {'max_depth':list(np.arange(1,10)),\n              'n_estimators':[100,1000],\n             'max_features': ['auto', 'sqrt', 'log2']}","f304e9cc":"grid_extra_trees = GridSearchCV(extra_trees,param_grid=param_grid, cv=5)","2c98cd6b":"grid_extra_trees.fit(X_train,y_train)","34002983":"extra_trees = grid_extra_trees.best_estimator_","abdae2f1":"extra_trees","dde6c1ed":"extra_trees_predictions = extra_trees.predict(X_val)","b645f24e":"extra_trees_train_predictions = extra_trees.predict(X_train)","b2e00b3a":"fpr_extra_trees, tpr_extra_trees, threshold = roc_curve(y_val, extra_trees_predictions)\nfpr_extra_trees_train, tpr_extra_trees_train, threshold = roc_curve(y_train, extra_trees_train_predictions)","fc96920a":"plt.figure(figsize=(10,6))\nplt.plot(fpr_extra_trees, tpr_extra_trees, label = 'Validation data')\nplt.plot(fpr_extra_trees_train, tpr_extra_trees_train, label = 'Training data')\nplt.title('Receiver operating characteristic (ROC)')\nplt.legend(loc = 'lower right',bbox_to_anchor=(1.45, 0.2))\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')","9d572c66":"extra_trees_evaluations = pd.DataFrame({'Model':['Extra Trees'],\n                                     'F1_score':[f1_score(y_val,extra_trees_predictions)],\n                                     'AUC_score':[roc_auc_score(y_val,extra_trees_predictions)]})","358c9da9":"Evaluations = Evaluations.append(extra_trees_evaluations)","39bf433b":"param_grid = {'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['rbf','linear']} ","9233a558":"grid_svc = GridSearchCV(SVC(),param_grid=param_grid,refit=True)","8e87b401":"grid_svc.fit(X_train,y_train)","0b5e8051":"svc = grid_svc.best_estimator_","ef512be8":"svc","2f6f5e15":"svc_pip = Pipeline([\n    ('StandardScaler',StandardScaler()),\n    ('svc',svc)\n])","eb7348ee":"svc_pip.fit(X_train,y_train)","2d0ca417":"svc_pip_predictions = svc_pip.predict(X_val)","db58d765":"svc_pip_train_predictions = svc_pip.predict(X_train)","1b2d4888":"fpr_svc, tpr_svc, threshold = roc_curve(y_val, svc_pip_predictions)\nfpr_svc_train, tpr_svc_train, threshold = roc_curve(y_train, svc_pip_train_predictions)","068006a0":"plt.figure(figsize=(10,6))\nplt.plot(fpr_svc, tpr_svc, label = 'Validation data')\nplt.plot(fpr_svc_train, tpr_svc_train, label = 'Training data')\nplt.title('Receiver operating characteristic (ROC)')\nplt.legend(loc = 'lower right',bbox_to_anchor=(1.45, 0.2))\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')","fc965c6e":"svc_evaluations = pd.DataFrame({'Model':['Support vector machines'],\n                                     'F1_score':[f1_score(y_val,svc_pip_predictions)],\n                                     'AUC_score':[roc_auc_score(y_val,svc_pip_predictions)]})","b21388ae":"Evaluations = Evaluations.append(svc_evaluations)","dc66f7ef":"X = train.drop('Survived', axis = 1).values\ny = train['Survived'].values","f13285ce":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=123)","e92d872d":"X_train.shape","9bca4c34":"neural_networks = Sequential()\n\nneural_networks.add(Dense(units=11,activation='relu'))\n\nneural_networks.add(Dense(units=6,activation='relu'))\n\nneural_networks.add(Dense(units=1,activation='sigmoid'))\n\nneural_networks.compile(loss='binary_crossentropy', optimizer='adam')\n#The Adam optimization algorithm is an extension to stochastic gradient descent that has recently seen \n#broader adoption for deep learning applications in computer vision and natural language processing.\n#https:\/\/machinelearningmastery.com\/adam-optimization-algorithm-for-deep-learning\/","42aa33ee":"early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)\n#https:\/\/keras.io\/api\/callbacks\/","c6aa639d":"neural_networks.fit(x=X_train, \n          y=y_train, \n          epochs=600,\n          validation_data=(X_val, y_val),\n          callbacks=[early_stop]\n          )\n#patience = wait 25 after stoppoint","9dd19838":"neural_networks_predictions = neural_networks.predict_classes(X_val)","8afdd77d":"neural_networks_evaluations = pd.DataFrame({'Model':['Neural networks'],\n                                     'F1_score':[f1_score(y_val,neural_networks_predictions)],\n                                     'AUC_score':[roc_auc_score(y_val,neural_networks_predictions)]})","9d87f920":"Evaluations = Evaluations.append(neural_networks_evaluations)","d6083e8a":"fpr_neural_networks, tpr_neural_networks, threshold = roc_curve(y_val, neural_networks_predictions)","4e61f85f":"vc = VotingClassifier(estimators=[\n    ('logmodel',logmodel),\n    ('dtree',dtree),\n    ('random_forest',random_forest),\n    ('extra_trees',extra_trees),\n    ('svc',svc_pip)\n],voting='hard')","e8d1cc0f":"vc.fit(X_train,y_train)","1b223d9c":"vc_predictions = vc.predict(X_val)","f9978038":"vc_train_predictions = vc.predict(X_train)","344ff9b8":"fpr_vc, tpr_vc, threshold = roc_curve(y_val, vc_predictions)\nfpr_vc_train, tpr_vc_train, threshold = roc_curve(y_train, vc_train_predictions)","04dab405":"plt.figure(figsize=(10,6))\nplt.plot(fpr_vc, tpr_vc, label = 'Validation data')\nplt.plot(fpr_vc_train, tpr_vc_train, label = 'Training data')\nplt.title('Receiver operating characteristic (ROC)')\nplt.legend(loc = 'lower right',bbox_to_anchor=(1.45, 0.2))\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')","f2ae9b54":"vc_evaluations = pd.DataFrame({'Model':['Voting Classifier'],\n                                     'F1_score':[f1_score(y_val,vc_predictions)],\n                                     'AUC_score':[roc_auc_score(y_val,vc_predictions)]})","0bdc7ce9":"Evaluations = Evaluations.append(vc_evaluations)","522faad9":"Evaluations","a51fe135":"plt.figure(figsize=(10,6))\nplt.plot(fpr_log_model, tpr_log_model, label = 'Logistic regression')\nplt.plot(fpr_d_tree, tpr_d_tree, label = 'Classification tree')\nplt.plot(fpr_random_forest, tpr_random_forest, label = 'Random forest')\nplt.plot(fpr_extra_trees, tpr_extra_trees, label = 'Extra trees')\nplt.plot(fpr_svc, tpr_svc, label = 'Support vector machines')\nplt.plot(fpr_neural_networks, tpr_neural_networks, label = 'Neural networks')\nplt.plot(fpr_vc, tpr_vc, label = 'Voting Classifier')\nplt.title('Receiver operating characteristic (ROC)')\nplt.legend(loc = 'lower right',bbox_to_anchor=(1.45, 0.2))\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')","fed65b79":"test_predictions = vc.predict(test)","fbf81f8c":"Test_results = pd.DataFrame({'PassengerId':test.index,\n                            'Survived':test_predictions})","88d59226":"Test_results.to_csv(\"Submission.csv\",index=False)","a215612f":"Let's drop unnecessary columns","b1544b8a":"Let's fill this empty value by mean 3rd ticket class ","3a93722e":"After moment of reflection, we can rename Mlle, Ms to Miss, Dr, Rev, Major, Col, Don, Jonkheer, Lady, Count, Captain, Sir to Other and Mme to Mrs as well.","5dee5d6a":"We can see from the plot that most of passengers were between 20-30 years old.\nLet's check with less number of bins","bbf233f7":"### Support vector machines","7c2afac4":"Let's check if we did not miss any title from Name variable","047cc815":"We can see that ROC curve for training data is very similar to ROC curve for validation data. It means that model is not overfitted. \nLet's save the results in prepared dataframe.","5940c8fe":"We can see from the plot that most passengers bought tickets for third class (more over 400). However from passengers who died in the distaster most passengers bought first class tickets.  \nNow let's check the distribution of passengers age.","70c30a6d":"As we have test data in different file let's split training data to training and validation set","843a3e21":"## Machine learning algorithms","9372d12c":"## Data modelling - training data","6303b068":"As we saw earlier we have some lacks of data for variable age. \nLet's check how many values are missing and how we can impute missing values. ","0c602b50":"## TEST DATA - overview","61a4e247":"### Random forest","7b864010":"In this project I will check below estimators:\n    \n- Logistic regression\n- Classification tree (Decision tree)\n- Random forest classification\n- Extra trees\n- Support vector machines\n- Neural networks\n- Voting Classifier\n\nThe best estimator will be used to predict test dataset.\n","4cfae3c2":"We can see that 77% of values in Cabin column is missing. Let's go ahead and drop the Cabin column","f2444071":"ROC curve for training data is similar for ROC curve for validation data. Model is not overfitted so we can save the results!","02d24344":"The Adam optimization algorithm is an extension to stochastic gradient descent that has recently seen broader adoption for deep learning applications in computer vision and natural language processing.\n","008f6017":"We can see that our model is overfitted. Let's use RandomSearchCV to find better parameters and check if it can help.","a192c91e":"#### Checking if model is not overfitted on training data","6739ab43":"When we divided passengers by sex we can notice that twice more women died in the disaster than men and four times more men survived than women.\nNow let's check how it look's when we divide survival of passengers by Ticket class.","cf8a8f79":"## Import all necessary libraries","d3d41888":"#### Checking if model is not overfitted on training data","2419c434":"Let's check the skewness and make a log is variable is highly skewed.","7e49dcf9":"## Missing data on training data","aaf622a2":"When we will compare the result and check the area under the ROC curve value we can annouce random forest as a best algorithm to predict survivals. Let's predict the test dependence variable and finish the project!","ff60db72":"### Receiver operating characteristic (ROC)","5a15f878":"Now let's concat new dummy variable with our training dataset","d62ddcbc":"After fitting Logistic Regression model let's check if there is a variable which does not have the statistical significance.","3e701da0":"### Logistic regression","ea2d186d":"Let's remind what does Embarked mean and map to numbers.","fde7364a":"### Checking if model is not overfitted on training data","e6122c89":"#### Checking if model is not overfitted on training data","d29a9a89":"## Evaluations","9172e4bd":"We can see that passengers who bought tickets in first class are older than passengers in other classes. \nWe may assume that richer and older passengers are sitting in the first class. \nSo then, let's impute missing values for age depending on ticket class.","8a8a92dc":"Now we can move to use machine learning algorithms to predict whether a passenger survived or not.","800843bc":"We can see that Name feature has title in it's body. Let's grab a title and create new variable called Title. We can suppose that always title is second after spliting the word. Let's check it ","11475c5d":"Now title column looks better. However we have some titles which appends only one time in our dataset. Let's check how we deal with some titles.","bf17de64":"## Exploratory analysis on trainingset","57d75ebf":"#### Checking if model is not overfitted on training data","745dffa3":"### Classification tree","ac7214ff":"Let's recreate the steps which we have already done on training data to test data","dba6a596":"ROC Curve looks pretty good. Let's save the results in dataframe.","f5aee17d":"After fitting Logistic Regression model let's check if there is a variable which does not have the statistical significance. Note: For some reasons I can not import regressors into kaggle kernel and below cells are commented.","a40b9a27":"## TRAINING DATA - overview","ed4cc4fb":"We have one empty value on fare feature. Let's check if we can impute the fare based on Pclass column.","8f756d3a":"Let's fill two empty embarked observations by forward fill (ffill) method.","981d894d":"Let's now check what is the passenger who does not have Fare price.","db92186a":"Let's assure that we do not have missing values in our dataset.","8cdfdef3":"Now we can convert categorical features to numeric variables.","4b086f83":"Now we can confirm that most of passengers were between 20-30 years old.","f83c9d81":"## Age imputation on training data","0f2f90e1":"As we do not want to make dummy variable from title, let's map title to number values and combine Miss with Mrs.","e896a5f7":"Now let's make a few visualisations to check the features in the dataset","f6b12429":"### Neural networks","40b39a87":"We can see that we have got 177 missing values for feature Age, 687 missing values for feature Cabin and 2 missing values for feature Embarked. Let's make a heatmap which sum up the missing data features.","80af9116":"Now it looks much better. ROC curve for training data is closer to ROC curve for validation data than it was at the beggining.\nLet's save the results.","26b6bed6":"## Voting Classifier","96503d7f":"We can see that more than 500 passengers survived the disaster but more than 300 passengers dead.\nLet's check if there is dependence of sex of passenger who survived or not survived.","d8c042d8":"Most of passengers as we checked out earlier were travelling in first class. As we can see from the plot tickets for the first class were not too expensive. There are some outliers, propably some of passengers in first class bought some extra services.\nFor better understanding of fare distribution let's use a iplot.","28ac6bc1":"Let's make a dummy variable for embarked and sex as well.","ddcf99f3":"As we can see we should not do it in this in the way below. Let's grab the title using other method","e1e3b00b":"We can see that almost 1\/5 of passengers don't have information about their age.\nLet's make a boxplot to check if age can depend on the passenger class","7a2f1e45":"Now it looks much better. Let's save the results in our table!","013f2c3c":"We can see from the plot that most of the passengers travelled alone. Around 200 passengers travelled together, possibly a married or couples.\nLet's check the distribution of passengers fare.","22d1a101":"#### Checking if model is not overfitted on training data","0f9bd6a6":"### Data splitting","9fa34710":"## ExtraTreesClassifier","dd015b97":"We can see that our random forest is also overfitted. Let's use GridSearchCV to raise the results.","b222277e":"#### Checking if model is not overfitted on training data","862eb9d3":"Now after age imputation let's check using heatmap what we can do with other lacks od values","1ad2a227":"## Test data cleaning ","adcc0146":"Let's make the boxplot for new title variable versus age","b1698c77":"## Data dictionary\n### Let's create a data dictionary based on information on kaggle","b33adcbb":"As we can see from the plot most passengers with Miss title died during the distater.\nLet's make a dummy variable and use drop_first to avoid collinearity problems.","553487ad":"## Training data cleaning ","7f951d0f":"## Load the data","0d05e16e":"Now we can see that passengers with Other title name to whom belongs mainly passengers with honorific title are older than passengers with Mr, Mrs and Miss titles.\nLet's check the survival grouped by Title of passangers.","601570ca":"In first step let's make a data frame to evaluate how good are our models on validation data by two metrics: F_score and AUC_score.\n\nThe F1 score is the harmonic mean of precision and recall taking both metrics into account in the following equation:\n\nPrecision is defined as the number of true positives divided by the number of true positives plus the number of false positives.\nRecall is the number of true positives divided by the number of true positives plus the number of false negatives. \n\nAUC stands for \"Area under the ROC Curve.\" That is, AUC measures the entire two-dimensional area underneath the entire ROC curve\n\nAn ROC curve (receiver operating characteristic curve) is a graph showing the performance of a classification model at all classification thresholds. This curve plots two parameters:\n- True Positive Rate (sensitivity, recall)\n- False Positive Rate (1 - specificity)\n\nSpecificity is the number of true negatives divided by the number of true negativies plus the number of false positives","a0d6cbca":"Dona is feminine form for dom (title), titled nobility in Portugal and Brazil, and in English for certain Benedictine and Carthusian monks. Let's add this observation to others","b8d464c6":"Now we have only one column with missing values - Embarked. As there are only two observations with missing values we can delete this observations.","32ea2645":"## Convering categorical variables on training data","84433796":"With data dictionary we can easilly check in any time what our variable means on use for instance on plot instead of variable name."}}