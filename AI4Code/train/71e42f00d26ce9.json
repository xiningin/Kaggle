{"cell_type":{"4e58ce7b":"code","c868aca5":"code","bf1d40ba":"code","24b77969":"code","117fdb94":"code","115b7811":"code","746fc114":"code","31e4cc3f":"code","ca43858b":"code","58b192ca":"code","2853f066":"code","db2e946c":"code","b19265fa":"code","257db2a8":"code","da25c4c1":"code","e8c5c81a":"code","a1bde879":"code","511a6a67":"code","46d032c8":"code","c7b2c7c5":"code","1efe5f30":"code","c201b01d":"code","d2f83263":"code","b08a6493":"code","6e4859d6":"code","28327e26":"code","8d4ed87b":"code","339d6a85":"code","8693ce60":"code","5dec262f":"code","4cf3c6c0":"code","5829654b":"code","d6c1b0c7":"code","96d35df8":"code","f4af14e9":"code","6e76b0af":"code","cbc8110d":"code","aad35709":"code","fc4cb93b":"code","8bae6e81":"code","f1355cfd":"code","aff961a1":"code","dbcdd3a0":"code","743dccc9":"code","88c4d0c7":"code","f123e70b":"code","97f3582b":"markdown","b379d731":"markdown","0eec0f25":"markdown","ea5906ca":"markdown","f7dbb4b4":"markdown","83b88014":"markdown","bcdbc332":"markdown","713002a1":"markdown","fee15204":"markdown","92af7ce9":"markdown","789f78e9":"markdown","41dae34d":"markdown","1c6edf76":"markdown","f1e7e3c6":"markdown","f28ea773":"markdown","866da6b0":"markdown","5fb86ce1":"markdown","510d1c52":"markdown","e4f30c33":"markdown","a3be38d8":"markdown","c937815d":"markdown","74dc388c":"markdown","3a377bc1":"markdown","799c823f":"markdown","9efdcf1f":"markdown","d7d1d856":"markdown","60f71947":"markdown","e633059f":"markdown","69793a1b":"markdown","5371fd33":"markdown","d858cd8f":"markdown","7f80bf57":"markdown","b10f026f":"markdown","ee16494f":"markdown","e9aa2ef1":"markdown","5000a361":"markdown","fd9a15e6":"markdown"},"source":{"4e58ce7b":"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","c868aca5":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","bf1d40ba":"#Load datasets\ntrain=pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntrain","24b77969":"\n#Load datasets\ntest=pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv\")\ntest\n","117fdb94":"submission = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv\")\nsubmission","115b7811":"target = train['SalePrice']\nsns.distplot(train['SalePrice']);\n","746fc114":"var = 'OverallQual'\ndata = pd.concat([train['SalePrice'], train[var]], axis=1)\nf, ax = plt.subplots(figsize=(14, 8))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nfig.axis(ymin=0, ymax=800000);","31e4cc3f":"corrmat = train.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.8, square=True);","ca43858b":"train_copy = train\ncombi = train_copy.drop('SalePrice', axis =1)\ncombi = combi.append(test)\ncombi","58b192ca":"combi.drop(['Id'], axis=1, inplace=True)\ncombi","2853f066":"combi.isnull().sum()","db2e946c":"from sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\nimp = IterativeImputer(random_state=42)\n\n\nfor col in combi:\n    if combi[col].dtype==\"object\":\n        combi[col].fillna(\"not listed\", inplace=True)\n    if combi[col].dtype==\"int\":\n        #combi[col].fillna(combi[col].mode()[0], inplace=True)\n        combi[col].fillna(combi[col].mean(), inplace=True)\n    if combi[col].dtype=='float':\n        combi[col] = imp.fit_transform(combi[col].values.reshape(-1,1))\ncombi","b19265fa":"combi.isnull().sum()","257db2a8":"from sklearn import preprocessing\nfrom sklearn.preprocessing import OrdinalEncoder\n\nenc = OrdinalEncoder()\n\nfor col in combi:\n    if combi[col].dtype==\"object\":\n        combi[col] = enc.fit_transform(combi[col].values.reshape(-1,1))\ncombi","da25c4c1":"combi = (combi - np.average(combi)) \/ (np.std(combi))\ncombi","e8c5c81a":"#combi = (combi - combi.min()) \/ (combi.max() - combi.min())\n#combi","a1bde879":"long_train = combi[: len(train)]\nlong_test = combi[len(train) :]\nlong_train['target'] = target\nlong_train","511a6a67":"for col in long_train:\n    q_low = long_train[col].quantile(0.01)\n    q_hi  = long_train[col].quantile(0.99)\n    long_train_filtered = long_train[(long_train[col] < q_hi) & (long_train[col] > q_low)]\n\nlong_train_filtered","46d032c8":"long_train_filtered.isnull().sum()","c7b2c7c5":"y = long_train_filtered.target\nlong_train_filtered.drop(['target'], axis=1, inplace=True)","1efe5f30":"combi_filtered = long_train_filtered.append(long_test)\ncombi_filtered","c201b01d":"X = combi_filtered[: len(long_train_filtered)]\nX_test = combi_filtered[len(long_train_filtered) :]","d2f83263":"from sklearn.feature_selection import SelectKBest, f_regression\n\nskb = SelectKBest(f_regression, k=20)\n\nX = skb.fit_transform(X, y)\nX_test = skb.transform(X_test)\nX.shape, y.shape, X_test.shape\n","b08a6493":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\nX_train.shape, X_val.shape, y_train.shape,y_val.shape, X_test.shape","6e4859d6":"from sklearn.linear_model import LinearRegression\n\nmodel1 = LinearRegression().fit(X_train, y_train)\nprint(model1.score(X_train, y_train))","28327e26":"y_pred1 = model1.predict(X_val)\nprint(model1.score(X_val, y_val))","8d4ed87b":"from sklearn.metrics import mean_squared_error\n\nrmse = mean_squared_error(y_val, y_pred1, squared=False)\nrmse","339d6a85":"df=pd.DataFrame({'Actual': y_val, 'Predicted':y_pred1})\ndf","8693ce60":"fig, ax = plt.subplots()\nax.scatter(y_val, y_pred1, edgecolors=(0, 0, 0))\nax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4)\nax.set_xlabel('Measured')\nax.set_ylabel('Predicted')\nplt.show()","5dec262f":"from sklearn.neighbors import KNeighborsRegressor\n\nmodel2 = KNeighborsRegressor(algorithm='auto', n_neighbors=7,p=1, weights='distance').fit(X_train, y_train)\nprint(model2.score(X_train, y_train))","4cf3c6c0":"y_pred2 = model2.predict(X_val)\nprint(model2.score(X_val, y_val))","5829654b":"from sklearn import metrics\n\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_val, y_pred2))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_val, y_pred2))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_val, y_pred2)))","d6c1b0c7":"compare = pd.DataFrame({'actual': y_val.values.ravel(), 'predicted': y_pred2})\ncompare","96d35df8":"fig, ax = plt.subplots()\nax.scatter(y_val, y_pred2, edgecolors=(0, 0, 0))\nax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4)\nax.set_xlabel('Measured')\nax.set_ylabel('Predicted')\nplt.show()","f4af14e9":"from sklearn.ensemble import ExtraTreesRegressor\n\nmodel3 = ExtraTreesRegressor(ccp_alpha=0, criterion='mse', max_features='auto', n_estimators=500, random_state=42).fit(X_train, y_train)\nprint(model3.score(X_train, y_train))","6e76b0af":"y_pred3 = model3.predict(X_val)\nprint(model3.score(X_val, y_val))","cbc8110d":"from sklearn import metrics\n\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_val, y_pred3))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_val, y_pred3))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_val, y_pred3)))","aad35709":"compare = pd.DataFrame({'actual': y_val.values.ravel(), 'predicted': y_pred3})\ncompare","fc4cb93b":"fig, ax = plt.subplots()\nax.scatter(y_val, y_pred3, edgecolors=(0, 0, 0))\nax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4)\nax.set_xlabel('Measured')\nax.set_ylabel('Predicted')\nplt.show()","8bae6e81":"from sklearn.ensemble import VotingRegressor\n\nemodel1 = VotingRegressor(estimators=[('LR', model1), ('KNN', model2), ('ET', model3)]).fit(X_train, y_train)\nprint(emodel1.score(X_train, y_train))","f1355cfd":"y_pred4 = emodel1.predict(X_val)\nprint(emodel1.score(X_val, y_val))","aff961a1":"from sklearn import metrics\n\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_val, y_pred4))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_val, y_pred4))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_val, y_pred4)))","dbcdd3a0":"compare = pd.DataFrame({'actual': y_val.values.ravel(), 'predicted': y_pred4})\ncompare","743dccc9":"fig, ax = plt.subplots()\nax.scatter(y_val, y_pred4, edgecolors=(0, 0, 0))\nax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4)\nax.set_xlabel('Measured')\nax.set_ylabel('Predicted')\nplt.show()","88c4d0c7":"preds = emodel1.predict(X_test)\npreds = preds.astype(int)\npreds[preds < 0] = 0\npreds","f123e70b":"submission.SalePrice = preds\nsubmission.to_csv('submission.csv', index=False)\nsubmission = pd.read_csv(\"submission.csv\")\nsubmission","97f3582b":"Append train and test","b379d731":"Normalise","0eec0f25":"Fill null values","ea5906ca":"KNN","f7dbb4b4":"Metrics","83b88014":"Standardise","bcdbc332":"Heatmap","713002a1":"Graph of SalePrice","fee15204":"Predict on validation","92af7ce9":"Predict on validation set","789f78e9":"Compare","41dae34d":"Plot predictions","1c6edf76":"Predict on test set and submit","f1e7e3c6":"Remove outliers","f28ea773":"Load and read csv files","866da6b0":"Extra Trees","5fb86ce1":"Problem statement","510d1c52":"Select model - Linear Regression","e4f30c33":"Compare","a3be38d8":"Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n\nWith 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.\n\nAcknowledgments\n\nThe Ames Housing dataset was compiled by Dean De Cock for use in data science education. It's an incredible alternative for data scientists looking for a modernized and expanded version of the often cited Boston Housing dataset.","c937815d":"Metrics","74dc388c":"Select K Best","3a377bc1":"Plot graph","799c823f":"Drop Id","9efdcf1f":"Metrics","d7d1d856":"Predict on validation set","60f71947":"Encode","e633059f":"Plot predictions","69793a1b":"Voting Regressor","5371fd33":"Submit","d858cd8f":"Split X_Train for training and validation","7f80bf57":"Compare","b10f026f":"Predict on validation set","ee16494f":"Graphics","e9aa2ef1":"Import libraries","5000a361":"Define X and y","fd9a15e6":"Check null values"}}