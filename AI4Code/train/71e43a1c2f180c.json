{"cell_type":{"3a2fad3f":"code","a014c2bf":"code","1e3f3cc6":"code","74313f50":"code","db97dbb1":"code","49f963af":"code","6616fd29":"code","4dcfd9fb":"code","e8fd599c":"code","7cded9fc":"code","c3bde1cf":"code","80faa831":"code","0edcabda":"code","5a05b4a1":"code","f635caf8":"code","e37905a9":"code","644f987d":"code","5ac6eb23":"code","b1a04394":"code","389eb163":"code","bf6626ea":"code","790d1610":"code","257fbb12":"code","e0f84ed9":"code","def04ef5":"code","1058f917":"code","2e00be5f":"code","6047445e":"code","02006bb3":"code","76937cf7":"code","566a4a38":"code","4e8371c6":"code","f50da150":"code","2aba2ebb":"code","a51b1680":"code","99e37e60":"code","eb2909d6":"code","bd4ab0b4":"code","b7967ce6":"code","7617342f":"code","7c0a1963":"code","66556ebb":"code","c03209a7":"code","b60721f5":"code","79270724":"code","23976f9d":"code","a23c7d7d":"code","c841efa8":"code","bcec57df":"code","5b5441f6":"code","150e98d6":"code","dba6cb82":"code","2f87958c":"code","f65a8ee0":"code","0f430e56":"code","97561388":"code","0eba0d43":"code","33594ef8":"code","f10b8661":"code","189099bd":"code","cb60a0e4":"code","3d65ac1c":"code","b5791644":"code","4ae904ba":"code","bc123048":"code","c9c4a52f":"code","0f3bcfff":"code","566cc266":"code","e5cd888a":"code","18b4cac4":"code","6879610f":"code","447ca358":"code","c0c90483":"code","a6627fe4":"markdown","ae4f5265":"markdown","ced9be77":"markdown","61aee7e7":"markdown","b0dc1990":"markdown","a6a793b9":"markdown","61c95009":"markdown","b03be79a":"markdown","43ac5010":"markdown"},"source":{"3a2fad3f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a014c2bf":"import numpy as np\nimport pandas as pd\nimport json\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import MinMaxScaler","1e3f3cc6":"credits = pd.read_csv(\"\/kaggle\/input\/tmdb-movie-metadata\/tmdb_5000_credits.csv\")\nmovies = pd.read_csv(\"\/kaggle\/input\/tmdb-movie-metadata\/tmdb_5000_movies.csv\")\n\ncredits.head()","74313f50":"credits.describe()","db97dbb1":"movies.head()","49f963af":"movies.describe()","6616fd29":"print(credits.shape)\nprint(movies.shape)","4dcfd9fb":"credits.columns = ['id','title','cast','crew']\nmovies = movies.merge(credits, on=\"id\")\nmovies.head()","e8fd599c":"movies.shape","7cded9fc":"movies_cleaned = movies.drop(columns = ['homepage', 'title_x', 'title_y', 'status', 'spoken_languages'])\nmovies_cleaned.head()","c3bde1cf":"# Changing 'genres' column from json to string\nmovies_cleaned['genres'] = movies_cleaned['genres'].apply(json.loads)\nfor index,i in zip(movies_cleaned.index, movies_cleaned['genres']):\n    l1 = []\n    for j in range(len(i)):\n        l1.append((i[j]['name']))     # \"name\" contains => name of the genre\n    movies_cleaned.loc[index, 'genres'] = str(l1)\n    \n# Changing 'keywords' column from json to string\nmovies_cleaned['keywords'] = movies_cleaned['keywords'].apply(json.loads)\nfor index,i in zip(movies_cleaned.index, movies_cleaned['keywords']):\n    l1 = []\n    for j in range(len(i)):\n        l1.append((i[j]['name']))     # \"name\" contains => name of the keyword\n    movies_cleaned.loc[index, 'keywords'] = str(l1)\n    \n# Changing 'production_companies' column from json to string\nmovies_cleaned['production_companies'] = movies_cleaned['production_companies'].apply(json.loads)\nfor index,i in zip(movies_cleaned.index, movies_cleaned['production_companies']):\n    l1 = []\n    for j in range(len(i)):\n        l1.append((i[j]['name']))     # \"name\" contains => name of the keyword\n    movies_cleaned.loc[index, 'production_companies'] = str(l1)\n    \n# Changing 'production_companies' column from json to string\nmovies_cleaned['production_countries'] = movies_cleaned['production_countries'].apply(json.loads)\nfor index,i in zip(movies_cleaned.index, movies_cleaned['production_countries']):\n    l1 = []\n    for j in range(len(i)):\n        l1.append((i[j]['name']))     # \"name\" contains => name of the keyword\n    movies_cleaned.loc[index, 'production_countries'] = str(l1)\n    \n# Changing 'cast' column from json to string\nmovies_cleaned['cast'] = movies_cleaned['cast'].apply(json.loads)\nfor index,i in zip(movies_cleaned.index, movies_cleaned['cast']):\n    l1 = []\n    for j in range(len(i)):\n        l1.append((i[j]['name']))     # \"name\" contains => name of the keyword\n    movies_cleaned.loc[index, 'cast'] = str(l1)\n\n\nmovies_cleaned['crew']=movies_cleaned['crew'].apply(json.loads)\ndef director(x):\n    for i in x:\n        if i['job'] == 'Director':\n            return i['name']\nmovies_cleaned['crew']=movies_cleaned['crew'].apply(director)\nmovies_cleaned.rename(columns={'crew':'director'},inplace=True)\n\nmovies_cleaned.head()","80faa831":"movies_cleaned['genres']=movies_cleaned['genres'].str.strip('[]').str.replace(' ','').str.replace(\"'\",'')\nmovies_cleaned['genres']=movies_cleaned['genres'].str.split(',')\n\nmovies_cleaned['keywords']=movies_cleaned['keywords'].str.strip('[]').str.replace(' ','').str.replace(\"'\",'')\nmovies_cleaned['keywords']=movies_cleaned['keywords'].str.split(',')\n\nmovies_cleaned['production_companies']=movies_cleaned['production_companies'].str.strip('[]').str.replace(' ','').str.replace(\"'\",'')\nmovies_cleaned['production_companies']=movies_cleaned['production_companies'].str.split(',')\n\nmovies_cleaned['production_countries']=movies_cleaned['production_countries'].str.strip('[]').str.replace(' ','').str.replace(\"'\",'')\nmovies_cleaned['production_countries']=movies_cleaned['production_countries'].str.split(',')\n\nmovies_cleaned['cast']=movies_cleaned['cast'].str.strip('[]').str.replace(' ','').str.replace(\"'\",'')\nmovies_cleaned['cast']=movies_cleaned['cast'].str.split(',')\n\nmovies_cleaned.head()","0edcabda":"movies_cleaned.info()","5a05b4a1":"v = movies_cleaned['vote_count']\nR = movies_cleaned['vote_average']\nC = movies_cleaned['vote_average'].mean()\nm = movies_cleaned['vote_count'].quantile(0.70)    # Movies > 70th percentile votes","f635caf8":"movies_cleaned['weighted_avg'] = ((R*v)+(C*m))\/(v+m)\nmovies_cleaned.head()","e37905a9":"sorted_ranking = movies_cleaned.sort_values('weighted_avg', ascending=False)\nsorted_ranking","644f987d":"sorted_ranking[['original_title', 'vote_count', 'vote_average', 'weighted_avg', 'popularity']].head(20)","5ac6eb23":"weight_avg = sorted_ranking.sort_values('weighted_avg', ascending=False)\nplt.figure(figsize=(12, 6))\nax = sns.barplot(x = weight_avg['weighted_avg'].head(10), y=weight_avg['original_title'].head(10), data=weight_avg)\nplt.xlim(4, 10)\nplt.title(\"Best Movies by Votes\", weight=\"bold\")\nplt.xlabel(\"Weighted Average Score\", weight=\"bold\")\nplt.ylabel(\"Movie Title\", weight=\"bold\")\nplt.show()","b1a04394":"popularity = sorted_ranking.sort_values('popularity', ascending=False)\npopularity.head(10)","389eb163":"plt.figure(figsize=(12, 6))\nax = sns.barplot(x = popularity['popularity'].head(10), y=popularity['original_title'].head(10), data=popularity)\nplt.title(\"Best Movies by Popularity\", weight=\"bold\")\nplt.xlabel(\"Popularity Score\", weight=\"bold\")\nplt.ylabel(\"Movie Title\", weight=\"bold\")\nplt.show()","bf6626ea":"# Scaling down the Popularity Score and Weighted Average due to difference in magnitude\nscaling = MinMaxScaler()\nmovie_scaled = scaling.fit_transform(movies_cleaned[['weighted_avg', 'popularity']])\nmovie_normalized = pd.DataFrame(movie_scaled, columns=['weighted_avg', 'popularity'])\nmovie_normalized.head()","790d1610":"movies_cleaned[['normalized_weighted_avg', 'normalized_popularity']] = movie_normalized\nmovies_cleaned.head(20)","257fbb12":"movies_cleaned['score'] = movies_cleaned['normalized_weighted_avg'] * 0.5 + movies_cleaned['normalized_popularity'] * 0.5\nmovies_cleaned = movies_cleaned.sort_values(['score'], ascending=False)\nmovies_cleaned[['original_title','normalized_weighted_avg', 'normalized_popularity', 'score']].head(10)","e0f84ed9":"movies_score = movies_cleaned.sort_values('score', ascending=False)\n\nplt.figure(figsize=(16, 6))\nax = sns.barplot(x = movies_score['score'].head(10), y=movies_score['original_title'].head(10), data=movies_score)\nplt.title(\"Best Rated and Most Popular Movies\", weight=\"bold\")\nplt.xlabel(\"Score\", weight=\"bold\")\nplt.ylabel(\"Movie Titles\", weight=\"bold\")\nplt.show()","def04ef5":"df = pd.read_csv(\"\/kaggle\/input\/movielens-20m-dataset\/rating.csv\")\ndf.head()","1058f917":"df.shape","2e00be5f":"# Using smaller amount of data => otherwise pandas gives error => pivot_table on large data does not work, int32 overflow\ndf = df[:100003]\ndf.shape","6047445e":"titles = pd.read_csv(\"\/kaggle\/input\/movielens-20m-dataset\/movie.csv\")\ntitles.head()","02006bb3":"# Merge the ratings and movies dataframe\ndf = pd.merge(df, titles, on=\"movieId\")\ndf.head()","76937cf7":"# Sort the rating from highest to lowest based on the rating value\ndf.groupby('title')['rating'].mean().sort_values(ascending=False).head()","566a4a38":"# Sort based on the count of number of ratings given to the movies\ndf.groupby('title')['rating'].count().sort_values(ascending=False).head()","4e8371c6":"# Storing the mean values of the ratings for each movie\nratings = pd.DataFrame(df.groupby('title')['rating'].mean())\nratings.head()","f50da150":"ratings['num_of_ratings'] = pd.DataFrame(df.groupby('title')['rating'].count())\nratings.head()","2aba2ebb":"# Plot histogram wrt number of ratings\nplt.figure(figsize=(10,4))\nratings['num_of_ratings'].hist(bins=70)","a51b1680":"plt.figure(figsize=(10,4))\nratings['rating'].hist(bins=70)    # Follow normal Gaussian Distribution with some outliers","99e37e60":"sns.jointplot(x='rating', y='num_of_ratings', data=ratings, alpha=0.5)","eb2909d6":"ratings.sort_values('num_of_ratings', ascending=False).head(10)","bd4ab0b4":"moviemat = df.pivot_table(index=\"userId\", columns=\"title\", values='rating')\nmoviemat.head()","b7967ce6":"forrest_gump_user_ratings = moviemat['Forrest Gump (1994)']\nshawshank_user_ratings = moviemat['Shawshank Redemption, The (1994)']\n\nforrest_gump_user_ratings.head()","7617342f":"shawshank_user_ratings.head()","7c0a1963":"# Find correlations\nsimilar_forrest_gump = moviemat.corrwith(forrest_gump_user_ratings)\nsimilar_shawshank = moviemat.corrwith(shawshank_user_ratings)","66556ebb":"similar_forrest_gump.head()","c03209a7":"similar_shawshank.head()","b60721f5":"# Drop 'NaN' values and convert the correlations to a dataframe\n# Higher Correlation => first recommendation\n# Max Correlation = 1\ncorr_forrest_gump = pd.DataFrame(similar_forrest_gump, columns=['Correlation'])\ncorr_forrest_gump.dropna(inplace=True)\ncorr_forrest_gump.head()","79270724":"corr_forrest_gump.shape","23976f9d":"corr_forrest_gump.sort_values('Correlation', ascending=False).head(20)","a23c7d7d":"corr_shawshank = pd.DataFrame(similar_shawshank, columns=['Correlation'])\ncorr_shawshank.dropna(inplace=True)\ncorr_shawshank.head()","c841efa8":"corr_shawshank.shape","bcec57df":"corr_shawshank.sort_values('Correlation', ascending=False).head(20)","5b5441f6":"corr_forrest_gump = corr_forrest_gump.join(ratings['num_of_ratings'])\ncorr_forrest_gump.head(10)","150e98d6":"corr_shawshank = corr_shawshank.join(ratings['num_of_ratings'])\ncorr_shawshank.head(10)","dba6cb82":"# Considering correlations where number of ratings>100\ncorr_forrest_gump[corr_forrest_gump['num_of_ratings']>100].sort_values('Correlation', ascending=False).head(10)","2f87958c":"corr_shawshank[corr_shawshank['num_of_ratings']>100].sort_values('Correlation', ascending=False).head(10)","f65a8ee0":"movies = pd.read_csv(\"\/kaggle\/input\/movielens-20m-dataset\/movie.csv\", usecols=['movieId','title'],\n                    dtype={'movieId':'int32', 'title': 'str'})\nratings = pd.read_csv(\"\/kaggle\/input\/movielens-20m-dataset\/rating.csv\", usecols=['userId', 'movieId', 'rating'],\n                     dtype={'userId':'int32', 'movieId':'int32', 'rating':'float32'})","0f430e56":"movies.head()","97561388":"ratings.head()","0eba0d43":"df = pd.merge(movies, ratings, on=\"movieId\")\ndf.head()","33594ef8":"# Count Ratings for each and every movie\nratings = df.dropna(axis=0, subset = ['title'])    # Drop all 'NaN' values\nmovie_rating_Count = (ratings.groupby(by=['title'])['rating'].count().reset_index().\n                     rename(columns = {'rating':'TotalRatingCount'})[['title', 'TotalRatingCount']])\n\nmovie_rating_Count.head(10)","f10b8661":"movie_rating_Count.describe()","189099bd":"# Merging the rating counts with the ratings\nratings = ratings.merge(movie_rating_Count, left_on='title', right_on='title', how='left')\n# left_on => on left dataframe which column considered, right_on => on right dataframe which column considered\nratings.head()","cb60a0e4":"plt.figure(figsize=(10,4))\nratings['TotalRatingCount'].hist(bins=70)","3d65ac1c":"popularity_threshold = 10000\nrating_popular_movie = ratings.query('TotalRatingCount >= @popularity_threshold')\nrating_popular_movie.head()","b5791644":"rating_popular_movie.shape","4ae904ba":"s = set(rating_popular_movie['title'])\ns","bc123048":"# Create a Pivot Table\nfeatures = rating_popular_movie.pivot_table(index='title', columns='userId', values='rating').fillna(0)\nfeatures.head()","c9c4a52f":"# Convert the pivot_table into an array matrix\nfrom scipy.sparse import csr_matrix\nfeatures_matrix = csr_matrix(features.values)    # All info of pivot table converted into an array\nfeatures_matrix","0f3bcfff":"from sklearn.neighbors import NearestNeighbors   # Not KNearestNeighbors, NearestNeighbors => Unsupervised Algo\nmodel = NearestNeighbors(metric = \"cosine\", algorithm=\"brute\")\nmodel.fit(features_matrix)    # p=2 => Euclidean Distance Parameter","566cc266":"features.shape","e5cd888a":"# Taking a new movie at random\nquery_index = np.random.choice(features.shape[0])    # Collect 1 record\nprint(query_index)","18b4cac4":"# Find similar movies(nearer to the selected movie) using kneighbors\ndistances, indices = model.kneighbors(features.iloc[query_index,:].values.reshape(1, -1), n_neighbors=6)\n# n_neighbors = 6 => will include the movie itself => We will be getting 5 other movie recommendations","6879610f":"# distances = 0 => Same movie itself\ndistances","447ca358":"indices","c0c90483":"# Print top 5 movie name recommendations for movie along with the distances from original movie\nfor i in range(0, len(distances.flatten())):     # Convert 'distances' array into 1-D array\n    if(i==0):\n        print(\"Recommendations for {0}:\\n\".format(features.index[query_index]))    # 1st recommendation => same movie itself\n    else:\n        print(\"{0}: {1}, with distance of {2}:\".format(i, features.index[indices.flatten()[i]], distances.flatten()[i]))","a6627fe4":"### Movie Recommandations for \"Forrest Gump\"","ae4f5265":"# Movie Recommendation Based on Weighted Average Scores(TMDB Dataset)\n\n### W = (Rv+Cm)\/(v+m)\n\n> W = Weighted Rating<br>\n> R = average for the movie(0 to 10) = Rating<br>\n> v = number of votes for the movie<br>\n> m = minimum votes required to be listed in Top 250<br>\n> C = Mean vote across whole Report","ced9be77":"# Recommender System using K Nearest Neighbors based Collaborative Filtering (Movielens Dataset)","61aee7e7":"#### Using Cosine Similarity\n\n> similarity(A, B) = cos(theta) = (A.B) \/ (||A|| * ||B||) => [Dot Product of the vectors\/Product of magnitudes of vector]<br>\n> theta = angle between the two vectors A and B<br>\n> Cos(0) => similarity = 1<br>\n> Cos(90) => similarity = 0<br>\n> Cos(45) => similarity = 0.5\n\n###### We will use KNN along with cosine similarity as KNN works on the concept of Euclidean Distance","b0dc1990":"# Recommender System using Correlation Concept (Movielens Dataset)","a6a793b9":"### 3 Types of Recommender Systems:\n> Collaborative Filtering => Recommend based on items bought by User (Same recommendations if two persons buy same product)<br>\n> Content-Based Filtering => Focus completely on Content (Same recommendations to two persons if both give same rating to an article)<br>\n> Hybrid Filtering (Combining Collaborative and Content-Based)","61c95009":"For higher values of correlations, the number of ratings may be very less. So we will consider only those correlations where number of ratings is >100","b03be79a":"## Recommendations based on both Popularity Score and Weighted Avg(both 50% priority)","43ac5010":"### Movie Recommendations for Shawshank Redemption"}}