{"cell_type":{"12fc35da":"code","fb16abbe":"code","b4b6961a":"code","c6a60ec8":"code","6bd1a65b":"code","cb7b7a14":"code","ae392ed9":"code","49f135dd":"code","9c994aab":"code","f5cd3fb8":"code","859d53af":"code","a39479cf":"code","9ebd1140":"code","07740515":"code","280f9b72":"code","efc776f9":"code","29f8bee1":"code","8483d77a":"code","96911827":"code","c39b5712":"code","d9033385":"code","25794f38":"code","44a1f109":"code","d067a238":"code","871a633d":"code","72bb8244":"code","bbcd47f6":"code","7cd58bb5":"code","0cd2f732":"code","c02a5d45":"code","c50e3b5a":"code","ef2a6169":"code","f55d9a8f":"code","3330bd19":"code","bb5b3797":"code","7ad3787d":"code","7de8b7b9":"code","75da0bcd":"code","87e95d50":"code","3596adfa":"code","4c95cb4e":"code","8e176d46":"code","6ae45a5a":"code","b6a4960f":"code","84017811":"code","bebc1105":"code","784ea05e":"code","51ba1285":"code","640c609d":"code","4e5c82d7":"code","9119f267":"code","a7ee1e3e":"code","61825ab9":"code","4d387665":"code","ed47804c":"code","e1bda802":"code","a7aa0bc3":"code","30be31b7":"code","808bc813":"code","e92109ad":"code","65d79a92":"code","4eae80ab":"code","3a1c27d5":"code","a7d43994":"code","d46bab37":"markdown","d10ad5c1":"markdown","d78d75b9":"markdown","4e2067fa":"markdown","4e0d4f4d":"markdown","acf39b10":"markdown","010bfb6e":"markdown","0c251216":"markdown","39255932":"markdown","78f62f8b":"markdown","b621a60b":"markdown","b0ba7385":"markdown","e92529d9":"markdown","7be9adca":"markdown","2889b2b1":"markdown","16da654e":"markdown","6cc952f0":"markdown","e5e5416f":"markdown","6bba32f3":"markdown","9c51b191":"markdown","da2ea67c":"markdown","4d446e00":"markdown","11a3f307":"markdown","34d20cb7":"markdown","4cde6f22":"markdown","0a4555ca":"markdown","d42ad8e5":"markdown","7bb0eae9":"markdown","5c236927":"markdown","045dd2ff":"markdown","8b1eec61":"markdown","e3f1568f":"markdown","2efd3ed8":"markdown","63b15f60":"markdown","6903be57":"markdown","1552e0cd":"markdown","a7078cb0":"markdown","b8e77efd":"markdown","0e3909ab":"markdown","6a4ec1a5":"markdown","7bf93635":"markdown","c1e52a56":"markdown","8727f6bc":"markdown","9fefc628":"markdown","38ae3ed5":"markdown","361cc362":"markdown","5edd9dee":"markdown","296a86bc":"markdown","966eb362":"markdown","5f916b55":"markdown","06f49731":"markdown","b8ebc754":"markdown","6b836f17":"markdown","00e7dc15":"markdown","cdb6a538":"markdown","bc849983":"markdown","aaa25b81":"markdown","a5f02a23":"markdown","469a679a":"markdown","e9c9fe09":"markdown","67359fbd":"markdown","d03dfc29":"markdown","1dd987ed":"markdown","a59ec447":"markdown","b8e4a65a":"markdown","e8c79443":"markdown"},"source":{"12fc35da":"from sklearn.datasets import make_regression\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport scipy.stats\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nimport math\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.decomposition import PCA\nfrom matplotlib.pyplot import figure\nfrom sklearn.metrics import r2_score\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nimport category_encoders as ce #pip install category_encoders\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nfrom sklearn.cluster import KMeans\nimport pandas_profiling as pdp #conda install -c conda-forge pandas-profiling","fb16abbe":"def load_dataset(path):\n    dataset = pd.read_csv(path, header=0, delimiter=',')\n    return dataset","b4b6961a":"def missing_values(dataset):\n    nanNum = dataset.isnull().sum()\n    print(nanNum\/dataset.shape[0]*100)\n    #Si columna con 30% de valores missing la eliminamos\n    for (index, item) in enumerate(nanNum):\n        if item > dataset.shape[0]*0.65:\n            dataset = dataset.drop(dataset.columns[index], axis=1)\n            \n    #Si hay alg\u00fan missing value eliminamos la fila\n    dataset = dataset.dropna(axis=0)\n    \n    return dataset","c6a60ec8":"def remove_outliers(df, df_entero):\n    z_scores = scipy.stats.zscore(df)\n    abs_z_scores = np.abs(z_scores)\n    filtered_entries = (abs_z_scores < 3).all(axis=1)\n    return df_entero[filtered_entries]","6bd1a65b":"path = '..\/input\/suicide-rates-overview-1985-to-2016\/master.csv'\ndataset = load_dataset(path)\nprint('Dimensi\u00f3n inicial del dataset es de ', dataset.shape)\ndataset.head()","cb7b7a14":"prof = pdp.ProfileReport(dataset)\nprof.to_file(output_file='report.html')\nprof","ae392ed9":"dataset.sort_values(by=['population'], ascending=False).head(20)","49f135dd":"dataset.sort_values(by=['suicides\/100k pop'], ascending=False).head(20)","9c994aab":"dataset.sort_values(by=['gdp_per_capita ($)'], ascending=False).head(20)","f5cd3fb8":"dataset[dataset['country'] == 'Luxembourg']['gdp_per_capita ($)'].describe()","859d53af":"dataset2 = missing_values(dataset)\ndataset2.head()","a39479cf":"dataset3 = dataset2.drop(['suicides_no', ' gdp_for_year ($) ', 'country-year', 'generation'], axis=1)\ndataset3.head()","9ebd1140":"dataset4 = remove_outliers(dataset3[['suicides\/100k pop']], dataset3)\ndataset4.describe()","07740515":"print('Dimensiones del dataset limpio: ', dataset4.shape)\ndataset4.head()","280f9b72":"def histogramas(dataset, index):\n    figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n    data = dataset.values\n    columnName = list(dataset)\n    x = data[:, index]\n    plt.figure()\n    title=\"Histograma de l'atribut \"\n    plt.title(title)\n    plt.xlabel(columnName[index])\n    plt.ylabel(\"Count\")\n    hist = plt.hist(x, bins=11, histtype=\"bar\", rwidth=0.8)\n    plt.show()","efc776f9":"for i in range(dataset4.shape[1]):\n    histogramas(dataset4, i)","29f8bee1":"dict_df = {}\ncountry_name = []\nfor item in dataset4['country'].unique():\n    df = dataset4.loc[dataset4['country'] == item]\n    if df.shape[0] > 50:\n            dict_df[item] = df\n            country_name.append(item)","8483d77a":"if 'country' in dict_df['United States']:\n    for item in country_name:\n        dict_df[item] = dict_df[item].drop(['country'], axis=1)\ndict_df['United States'].head()","96911827":"aux = []\nfor item in country_name:\n    if dict_df[item]['suicides\/100k pop'].quantile(0.50) < 5:\n        del dict_df[item]\n        aux.append(item)\nfor x in aux:\n    country_name.remove(x)\nprint('N\u00famero de pa\u00edses: ', len(country_name))\nprint(country_name)","c39b5712":"for item in country_name:\n    print('----------------------------------------')\n    print(item)\n    for i in range(dict_df[item].shape[1]):\n        histogramas(dict_df[item], i)","d9033385":"if dict_df['United States']['sex'].dtype != 'int64':\n    le_s = preprocessing.LabelEncoder()\n    le_a = preprocessing.LabelEncoder()\n    age = np.sort(dataset3['age'].unique())\n    for i in range(4):\n        aux = age[i]\n        age[i] = age[3]\n        age[3] = aux\n    le_s.fit(['female', 'male'])\n    le_a.classes_ = age\n    for item in country_name:\n        dict_df[item][['sex']] = le_s.transform(dict_df[item]['sex'])\n        dict_df[item][['age']] = le_a.transform(dict_df[item]['age'])\ndict_df['United States'].head()","25794f38":"for item in country_name:\n    corr = dict_df[item].corr()\n\n    plt.figure(figsize=(10,10))\n\n    ax = sns.heatmap(corr, annot=True, linewidths=1, center=0)\n    \n    ax.set_title(item)\n","44a1f109":"def standarize(x_train, x_test):\n    scaler = preprocessing.MinMaxScaler()\n    scaler.fit(x_train)\n    return scaler.transform(x_train), scaler.transform(x_test)","d067a238":"dict_x_y = {}\nfor item in country_name:\n    dict_x_y[item] = {}\n    dict_x_y[item]['x'] = dict_df[item].loc[:,dict_df[item].columns != \"suicides\/100k pop\"].to_numpy()\n    dict_x_y[item]['y'] = dict_df[item].loc[:,\"suicides\/100k pop\"].to_numpy()\n    dict_x_y[item]['x_s'], aux = standarize(dict_x_y[item]['x'], dict_x_y[item]['x'])\nprint(dict_x_y['United States']['x_s'][2])","871a633d":"country_scores = {}\nfor item in country_name:\n    country_scores[item] = {}\n    for i in [2, 3, 4, 5, 6, 7, 8, 9, 10]:\n        reg = LinearRegression()\n        country_scores[item][i] = cross_validate(reg, dict_x_y[item]['x_s'], dict_x_y[item]['y'], cv=i, scoring=['neg_mean_squared_error', 'r2'], return_estimator=True)\n","72bb8244":"dict_scores_resume = {}\nfor item in country_name:\n    dict_scores_resume[item] = {}\n    for k in country_scores[item]:\n        dict_scores_resume[item][k] = {}\n        for numbers in country_scores[item][k]:\n            i = 0\n            aux = 0\n            if numbers != 'estimator':\n                dict_scores_resume[item][k][numbers] = {}\n                for num in np.nditer(country_scores[item][k][numbers]):\n                    i = i + 1\n                    aux = aux + num\n                result = aux\/i\n                dict_scores_resume[item][k][numbers] = result","bbcd47f6":"for pais, info_pais in dict_scores_resume.items():\n    print(pais, ':')\n    for k, info_k in info_pais.items():\n        print('k =', k, ':')\n        print('MSE:', info_k['test_neg_mean_squared_error'], 'R2:', info_k['test_r2'])\n    print('--------------------------------------------------------------')","7cd58bb5":"dict_best_k = {}\nfor pais, info_pais in dict_scores_resume.items():\n    dict_best_k[pais] = {}\n    dict_best_k[pais]['k'] = -1\n    dict_best_k[pais]['value'] = float('-inf')\n    for k, values in info_pais.items():\n        if dict_best_k[pais]['value'] < (values['test_neg_mean_squared_error'] + values['test_r2'])\/2:\n            dict_best_k[pais]['value'] = (values['test_neg_mean_squared_error'] + values['test_r2'])\/2\n            dict_best_k[pais]['k'] = k\n    val = country_scores[pais][dict_best_k[pais]['k']]['test_neg_mean_squared_error'] + country_scores[pais][dict_best_k[pais]['k']]['test_neg_mean_squared_error']\n    dict_best_k[pais]['iter'] = val.argmax()\nprint(dict_best_k['Spain'])","0cd2f732":"dict_best_regr = {}\nfor item in country_name:\n    dict_best_regr[item] = country_scores[item][dict_best_k[item]['k']]['estimator'][dict_best_k[item]['iter']]\nprint(dict_best_regr['Spain'])","c02a5d45":"for pais, info_pais in dict_scores_resume.items():\n    print(pais, ':')\n    print('k =', dict_best_k[pais]['k'], ':')\n    print('MSE:', country_scores[pais][dict_best_k[pais]['k']]['test_neg_mean_squared_error'][dict_best_k[pais]['iter']], 'R2:', country_scores[pais][dict_best_k[pais]['k']]['test_r2'][dict_best_k[pais]['iter']])\n    print('--------------------------------------------------------------')","c50e3b5a":"list_attr = ['country'] + list(dict_df['Spain'])\nlist_attr.remove('suicides\/100k pop')\ndf_coef = pd.DataFrame(columns=list_attr)\ni = 0\nfor pais, regr in dict_best_regr.items():\n    df_coef.loc[i, 'country'] = pais\n    df_coef.values[i, 1:] = regr.coef_\n    i += 1\ndf_coef = df_coef.set_index('country')\ndf_coef.head(df_coef.shape[0])","ef2a6169":"df_coef[df_coef.index.isin(['Spain', 'United States', 'France'])].plot(kind='bar', figsize=[15,10],\n             title ='Agrupaci\u00f3n de paises por la proporci\u00f3n de suicidios en 2014')","f55d9a8f":"df = pd.DataFrame(columns=['country', 'year', 'population', 'suicides\/100k pop', 'gdp_per_capita ($)'])\ndf['country'] = dataset4['country']\ndf['year'] = dataset4['year']\ndf['population'] = dataset4['population']\nfor i, fila in dataset4.iterrows():\n    df.loc[i, 'suicides\/100k pop'] = dataset2.loc[i, 'suicides_no']\n    \ndf = df.fillna(0)\ndf = df.groupby(['country', 'year'], as_index=False).sum()\n\ndf_rich = dataset4.groupby(['country', 'year'], as_index=False).mean()\ndf['gdp_per_capita ($)'] = df_rich['gdp_per_capita ($)']\nfor i, fila in df.iterrows():\n    df.loc[i, 'suicides\/100k pop'] = (fila['suicides\/100k pop'] \/ fila['population'])*100000\n    \nprint(df.shape)\ndf.head()","3330bd19":"for i in range(df.shape[1]):\n    histogramas(df, i)","bb5b3797":"corr = df.corr()\n\nplt.figure(figsize=(10,10))\n\nax = sns.heatmap(corr, annot=True, linewidths=1)","7ad3787d":"plt.figure(figsize=(30, 100))\norder = df.groupby(by=[\"country\"])[\"suicides\/100k pop\"].mean().sort_values().iloc[::-1].index\nax = sns.boxplot(y=\"country\", x=\"suicides\/100k pop\", data=df, order = order)","7de8b7b9":"encoder = ce.binary.BinaryEncoder(cols=['country'])\ndf_e = encoder.fit_transform(df)\ndf_e = df_e.drop('country_0', axis=1)\ndf_e.head()","75da0bcd":"x = df_e.loc[:,df_e.columns != \"suicides\/100k pop\"].to_numpy()\ny = df_e.loc[:,\"suicides\/100k pop\"].to_numpy()\n\nx_train = x[df_e.loc[:, 'year'] <= 2010]\nx_val = x[df_e.loc[:, 'year'] > 2010]\ny_train = y[df_e.loc[:, 'year'] <= 2010]\ny_val = y[df_e.loc[:, 'year'] > 2010]","87e95d50":"x_train_s, x_val_s = standarize(x_train, x_val)\nprint(x_train_s[0])","3596adfa":"scores = {}\nfor d in [1, 2]:\n    scores[d] = {}\n    for i in [2, 3, 4, 5, 6, 7, 8, 9, 10]:\n        reg = LinearRegression()\n        pf = PolynomialFeatures(degree=d)\n        atribut_train=pf.fit_transform(x_train_s)\n        scores[d][i] = cross_validate(reg, atribut_train, y_train, cv=i, scoring=['neg_mean_squared_error', 'r2'], return_estimator=True)\n","4c95cb4e":"scores_resume = {}\nfor k in scores:\n    scores_resume[k] = {}\n    for degree in scores[k]:\n        scores_resume[k][degree] = {}\n        for numbers in scores[k][degree]:\n            i = 0\n            aux = 0\n            if numbers != 'estimator':\n                scores_resume[k][degree][numbers] = {}\n                for num in np.nditer(scores[k][degree][numbers]):\n                    i = i + 1\n                    aux = aux + num\n                result = aux\/i\n                scores_resume[k][degree][numbers] = result","8e176d46":"for degree, info_degree in scores_resume.items():\n    print('Regresion lineal de grado', degree, ':')\n    for k, info_k in info_degree.items():\n        print('k =', k, ':')\n        print('MSE:', info_k['test_neg_mean_squared_error'], 'R2:', info_k['test_r2'])\n    print('--------------------------------------------------------------')","6ae45a5a":"best_k = {}\nbest_k['degree'] = -1\nbest_k['k'] = -1\nbest_k['value'] = float('-inf')\nfor degree, info_degree in scores_resume.items():\n    for k, values in info_degree.items():\n        if best_k['value'] < (values['test_neg_mean_squared_error'] + values['test_r2'])\/2:\n            best_k['value'] = (values['test_neg_mean_squared_error'] + values['test_r2'])\/2\n            best_k['k'] = k\n            best_k['degree'] = degree\nval = scores[best_k['degree']][best_k['k']]['test_neg_mean_squared_error'] + scores[best_k['degree']][best_k['k']]['test_neg_mean_squared_error']\nbest_k['iter'] = val.argmax()\nprint(best_k)","b6a4960f":"best_regr = scores[best_k['degree']][best_k['k']]['estimator'][best_k['iter']]\ny_predict = best_regr.predict(np.insert(x_val_s, 0, 1, axis=1))\nmse = mean_squared_error(y_val, y_predict)\nr2 = r2_score(y_val, y_predict)\nprint('MSE:', mse, 'R2:', r2)","84017811":"fig, (ax1, ax2) = plt.subplots(1, 2)\nfig.set_figheight(5)\nfig.set_figwidth(15)\n\nax1.set(ylim=(0, 30))\nax1.set_title('Sucesos reales')\nax1.scatter(x_val[:, list(df_e).index('year')], y_val)\n\nax2.set(ylim=(0, 30))\nax2.set_title('Sucesos predecidos')\nax2.scatter(x_val[:, list(df_e).index('year')], y_predict, color='red')\n","bebc1105":"y_plot = (y_val-y_predict)\nplt.scatter(x_val[:, list(df_e).index('year')], y_plot)\nplt.axhline(y=0, color='red', linewidth=2)","784ea05e":"plt.scatter(y_val, y_predict)\nplt.plot([0, 25], [0, 25], color='red', linewidth=3)","51ba1285":"df_clusters_demografia = pd.DataFrame(columns=['country', 'year', 'population', 'female (%)', '5-14 years',\n                                    '15-24 years', '25-34 years', '35-54 years', '55-74 years', '75+ years',\n                                    'suicides\/100k pop', 'gdp_per_capita ($)'])\ndf_clusters_demografia['country'] = dataset4['country']\ndf_clusters_demografia['year'] = dataset4['year']\ndf_clusters_demografia['population'] = dataset4['population']\nfor i, fila in dataset4.iterrows():\n    if 'female' == fila['sex']:\n        df_clusters_demografia.loc[i, 'female (%)'] = fila['population']\n    #else:\n        #df_clusters_demografia.loc[i, 'female (%)'] = fila['population']\n    df_clusters_demografia.loc[i, fila['age']] = fila['population']\n    df_clusters_demografia.loc[i, 'suicides\/100k pop'] = dataset2.loc[i, 'suicides_no']\n    \ndf_clusters_demografia = df_clusters_demografia.fillna(0)\ndf_clusters_demografia = df_clusters_demografia.groupby(['country', 'year'], as_index=False).sum()\n\ndf_rich = dataset4.groupby(['country', 'year'], as_index=False).mean()\ndf_clusters_demografia['gdp_per_capita ($)'] = df_rich['gdp_per_capita ($)']\nfor i, fila in df_clusters_demografia.iterrows():\n    df_clusters_demografia.loc[i, 'suicides\/100k pop'] = (fila['suicides\/100k pop'] \/ fila['population'])*100000\n    df_clusters_demografia.loc[i, 'female (%)'] = (fila['female (%)'] \/ fila['population'])\n    df_clusters_demografia.loc[i, '5-14 years'] = (fila['5-14 years'] \/ fila['population'])\n    df_clusters_demografia.loc[i, '15-24 years'] = (fila['15-24 years'] \/ fila['population'])\n    df_clusters_demografia.loc[i, '25-34 years'] = (fila['25-34 years'] \/ fila['population'])\n    df_clusters_demografia.loc[i, '35-54 years'] = (fila['35-54 years'] \/ fila['population'])\n    df_clusters_demografia.loc[i, '55-74 years'] = (fila['55-74 years'] \/ fila['population'])\n    df_clusters_demografia.loc[i, '75+ years'] = (fila['75+ years'] \/ fila['population'])\n    \nscaler = preprocessing.MinMaxScaler()\na, aux = standarize(df_clusters_demografia.values[:,2:], df_clusters_demografia.values[:,2:])\nnombres = list(df_clusters_demografia)\nindice_fila = 0\nfor i, fila in df_clusters_demografia.iterrows():\n    index = 0\n    for index in range(len(nombres)-2):\n        df_clusters_demografia.loc[i, nombres[index+2]] = a[indice_fila][index]\n        index +=1\n    indice_fila += 1\n    \ndf_clusters_demografia.head()","640c609d":"prof = pdp.ProfileReport(df_clusters_demografia)\nprof.to_file(output_file='clusters_demografia.html')\nprof","4e5c82d7":"df_clusters_demografia_2014 = df_clusters_demografia[df_clusters_demografia['year'] == 2014].drop(['country', 'year'], axis=1)\ndf_clusters_demografia_2014.shape","9119f267":"nc = range(1, 20)\nkmeans = [KMeans(n_clusters=i) for i in nc]\nscore = [kmeans[i].fit(df_clusters_demografia_2014).score(df_clusters_demografia_2014) for i in range(len(kmeans))]\nscore\nplt.xlabel('N\u00famero de cl\u00fasteres (k)')\nplt.ylabel('Suma de los errores cuadr\u00e1ticos')\nplt.plot(nc,score)","a7ee1e3e":"kmeans_demografia_2014 = KMeans(n_clusters=4).fit(df_clusters_demografia_2014)\nprint(kmeans_demografia_2014.cluster_centers_)","61825ab9":"centroids_demografia_2014 = kmeans_demografia_2014.cluster_centers_\nname_centroids = []\nfor i in range(centroids_demografia_2014.shape[0]):\n    name_centroids.append('centroid '+str(i))\ndf_centroids_demografia_2014 = pd.DataFrame(data=centroids_demografia_2014.transpose(), index=list(df_clusters_demografia_2014), columns=name_centroids)\ndf_centroids_demografia_2014","4d387665":"plot_dem_2014 = df_centroids_demografia_2014.plot(kind='bar', figsize=[30,10],\n                                            title='Agrupaci\u00f3n de paises por la demograf\u00eda en 2014')\n","ed47804c":"df_clusters_demografia_1995 = df_clusters_demografia[df_clusters_demografia['year'] == 1995].drop(['country', 'year'], axis=1)\nkmeans_demografia_1995 = KMeans(n_clusters=4).fit(df_clusters_demografia_1995)\ncentroids_demografia_1995 = kmeans_demografia_1995.cluster_centers_\nname_centroids = []\nfor i in range(centroids_demografia_1995.shape[0]):\n    name_centroids.append('centroid '+str(i))\ndf_centroids_demografia_1995 = pd.DataFrame(data=centroids_demografia_1995.transpose(), index=list(df_clusters_demografia_1995), columns=name_centroids)\nplot_dem_1995 = df_centroids_demografia_1995.plot(kind='bar', figsize=[30,10],\n                                                 title='Agrupaci\u00f3n de paises por la demograf\u00eda en 1995')","e1bda802":"df_clusters_rate = pd.DataFrame(columns=['country', 'year', 'population', 'male', 'female', '5-14 years',\n                                    '15-24 years', '25-34 years', '35-54 years', '55-74 years', '75+ years',\n                                    'suicides\/100k pop', 'gdp_per_capita ($)'])\ndf_clusters_rate['country'] = dataset4['country']\ndf_clusters_rate['year'] = dataset4['year']\ndf_clusters_rate['population'] = dataset4['population']\nfor i, fila in dataset4.iterrows():\n    if 'male' == fila['sex']:\n        df_clusters_rate.loc[i, 'male'] = dataset2.loc[i, 'suicides_no']\n    else:\n        df_clusters_rate.loc[i, 'female'] = dataset2.loc[i, 'suicides_no']\n    df_clusters_rate.loc[i, fila['age']] = dataset2.loc[i, 'suicides_no']\n    df_clusters_rate.loc[i, 'suicides\/100k pop'] = dataset2.loc[i, 'suicides_no']\n    \ndf_clusters_rate = df_clusters_rate.fillna(0)\ndf_clusters_rate = df_clusters_rate.groupby(['country', 'year'], as_index=False).sum()\n\ndf_rich = dataset4.groupby(['country', 'year'], as_index=False).mean()\ndf_clusters_rate['gdp_per_capita ($)'] = df_rich['gdp_per_capita ($)']\nfor i, fila in df_clusters_rate.iterrows():\n    df_clusters_rate.loc[i, 'suicides\/100k pop'] = (fila['suicides\/100k pop'] \/ fila['population'])*100000\n    df_clusters_rate.loc[i, 'male'] = (fila['male'] \/ fila['population'])*100000\n    df_clusters_rate.loc[i, 'female'] = (fila['female'] \/ fila['population'])*100000\n    df_clusters_rate.loc[i, '5-14 years'] = (fila['5-14 years'] \/ fila['population'])*100000\n    df_clusters_rate.loc[i, '15-24 years'] = (fila['15-24 years'] \/ fila['population'])*100000\n    df_clusters_rate.loc[i, '25-34 years'] = (fila['25-34 years'] \/ fila['population'])*100000\n    df_clusters_rate.loc[i, '35-54 years'] = (fila['35-54 years'] \/ fila['population'])*100000\n    df_clusters_rate.loc[i, '55-74 years'] = (fila['55-74 years'] \/ fila['population'])*100000\n    df_clusters_rate.loc[i, '75+ years'] = (fila['75+ years'] \/ fila['population'])*100000\n    \nscaler = preprocessing.MinMaxScaler()\na, aux = standarize(df_clusters_rate.values[:,2:], df_clusters_rate.values[:,2:])\nnombres = list(df_clusters_rate)\nprint(type(a))\nindice_fila = 0\nfor i, fila in df_clusters_rate.iterrows():\n    index = 0\n    for index in range(len(nombres)-2):\n        df_clusters_rate.loc[i, nombres[index+2]] = a[indice_fila][index]\n        index +=1\n    indice_fila += 1\n    \ndf_clusters_rate","a7aa0bc3":"prof = pdp.ProfileReport(df_clusters_rate)\nprof.to_file(output_file='clusters_rate.html')\nprof","30be31b7":"df_clusters_rate_2014 = df_clusters_rate[df_clusters_rate['year'] == 2014].drop(['country', 'year'], axis=1)\ndf_clusters_rate_2014.shape","808bc813":"nc = range(1, 20)\nkmeans = [KMeans(n_clusters=i) for i in nc]\nscore = [kmeans[i].fit(df_clusters_rate_2014).score(df_clusters_rate_2014) for i in range(len(kmeans))]\nscore\nplt.xlabel('N\u00famero de cl\u00fasteres (k)')\nplt.ylabel('Suma de los errores cuadr\u00e1ticos')\nplt.plot(nc,score)","e92109ad":"kmeans_rate_204 = KMeans(n_clusters=5).fit(df_clusters_rate_2014)\nprint(kmeans_rate_204.cluster_centers_)","65d79a92":"centroids_rate_2014 = kmeans_rate_204.cluster_centers_\nname_centroids = []\nfor i in range(centroids_rate_2014.shape[0]):\n    name_centroids.append('centroid '+str(i))\ndf_centroids_rate_2014 = pd.DataFrame(data=centroids_rate_2014.transpose(), index=list(df_clusters_rate_2014), columns=name_centroids)\ndf_centroids_rate_2014","4eae80ab":"plot_rate_2014 = df_centroids_rate_2014.plot(kind='bar', figsize=[30,10],\n                                            title ='Agrupaci\u00f3n de paises por la proporci\u00f3n de suicidios en 2014')","3a1c27d5":"df_clusters_rate_1995 = df_clusters_rate[df_clusters_rate['year'] == 1995].drop(['country', 'year'], axis=1)\nkmeans_rate_1995 = KMeans(n_clusters=5).fit(df_clusters_rate_1995)\ncentroids_rate_1995 = kmeans_rate_1995.cluster_centers_\nname_centroids = []\nfor i in range(centroids_rate_1995.shape[0]):\n    name_centroids.append('centroid '+str(i))\ndf_centroids_rate_1995 = pd.DataFrame(data=centroids_rate_1995.transpose(), index=list(df_clusters_rate_1995), columns=name_centroids)\nplot_rate_1995 = df_centroids_rate_1995.plot(kind='bar', figsize=[30,10],\n                                            title ='Agrupaci\u00f3n de paises por la proporci\u00f3n de suicidios en 1995')","a7d43994":"fig, axs = plt.subplots(ncols=2, nrows=2)\ndf_centroids_demografia_2014.plot(kind='bar', figsize=[35,30], ax = axs[0][1],\n                                        title ='Agrupaci\u00f3n de paises por la demograf\u00eda en 2014')\ndf_centroids_demografia_1995.plot(kind='bar', figsize=[35,30], ax = axs[0][0],\n                                        title ='Agrupaci\u00f3n de paises por la demograf\u00eda en 1995')\ndf_centroids_rate_2014.plot(kind='bar', figsize=[35,30], ax = axs[1][1],\n                                        title ='Agrupaci\u00f3n de paises por la proporci\u00f3n de suicidios en 2014')\ndf_centroids_rate_1995.plot(kind='bar', figsize=[35,30], ax = axs[1][0],\n                                        title ='Agrupaci\u00f3n de paises por la proporci\u00f3n de suicidios en 1995')","d46bab37":"Ahora en 1995 han cambiado las clases y tiene otras caracter\u00edsticas diferentes:\n\n- Cluster 0: Este grupo tiene paises con un alto indice de suicidios, tienen bastante riqueza y tiene muy poca poblaci\u00f3n con igualdad en g\u00e9nero, son paises con la media de edad entre los 35 y los 74 a\u00f1os.\n\n- Cluster 1: Estos son paises con baja proporci\u00f3n de suicidios pero bastante pobres y con poca poblaci\u00f3n con un ligero debalace a favor de los hombres y es una poblaci\u00f3n muy joven, con dominaci\u00f3n de la poblaci\u00f3n joven entre los 5 y los 14 a\u00f1os.\n\n- Cluster 2: Estos son paises tiene un ratio de suicidios alto y con riqueza muy alta y con poblaci\u00f3n muy abundante y equilibrada, la poblaci\u00f3n mayoritar\u00eda tiene una edad comprendida entre los 35 y los 55 a\u00f1os.\n\n- Cluster 3: El grupo que conforma estos paises tiene mucha proporci\u00f3n de suicidios y son muy pobres, la poblaci\u00f3n es estandard pero con mucho dominio femenino, es un poblaci\u00f3n bastante equilibrada en edades, los rangos de edades m\u00e1s frecuentes son de 5 a 14 a\u00f1os y entre 53 y 74 a\u00f1os.\n\nDespu\u00e9s de ver esto pasaremos a hacer la clusterizaci\u00f3n teniendo en cuenta el ratio de suicidios de cada grupo de personas por pa\u00eds y a\u00f1o.","d10ad5c1":"Lo que queremos ver en este estudio es la proporci\u00f3n de suicidios por cada 100k habitantes. La distribuci\u00f3n de estos es bastante malo por lo que la mejor es descomponer el estudio en otros de tal forma que podamos predecir algo. Se realizar\u00edan los siguientes estudios y luego se contrastar\u00eda la informaci\u00f3n entre estos para razonar cosas. Los estudios ser\u00edan:\n\n- Por cada pa\u00eds mirariamos los suicidios independientemente. Aqu\u00ed podriamos ver m\u00e1s en detalle por cada pa\u00eds que ocurre, si una franja de edad o un sexo es m\u00e1s propenso.\n\n- Por cada pa\u00eds y a\u00f1o mirariamos los suicidios totales, con este estudio podr\u00edamos ver la diferenca entre los paises y ver si paises ricos tiene m\u00e1s suicidios o al rev\u00e9s o si todos actu\u00e1n de un forma similar.\n\n- Por \u00faltimo har\u00edamos una clusterizaci\u00f3n para agrupar los paises y as\u00ed analizar ciertas tendencias segu\u00fan las caracter\u00edsticas de cada grupo.","d78d75b9":"Aqu\u00ed podemos ver la media por cada k del mse y el r2, ahora con esta informaci\u00f3n pasaremos a encontrar el mejor regresor.","4e2067fa":"Podemos ver los valores de los centroides, ahora los representaremos para que sean m\u00e1s entendibles.","4e0d4f4d":"Aqui cargamos los datos y observamos como son nuestros datos","acf39b10":"# 3. Experimentaci\u00f3n\nPrimero de todo sacaremos los histogramas para ver como est\u00e1n distribuidos los valores de los atributos.","010bfb6e":"Aqu\u00ed tenemos el error y el r2 para el mejor modelo de cada pa\u00eds, depende del pa\u00eds cambian mucho los valores, para algunos paises ha sido m\u00e1s f\u00e1cil hacer la predicci\u00f3n y para otros ha sido imposible predecirlos. Ahora vamos a ver el peso que le han dado a caa uno de los atributos en los regresores de cada pa\u00eds y as\u00ed podremos ver los atributos m\u00e1s importantes seg\u00fan el lugar.","0c251216":"# 1. Introducci\u00f3n\nVamos a hacer un estudio sobre la base de datos *Suicide Rates Overview 1985 to 2016*, que es un conjunto compilado de otras 4 fuentes de informaci\u00f3, *United Nations Development Program*, *World Bank*, un dataset de *kaggle* denominado *Suicide in the Twenty-First Century* y la *World Health Organization*. El conjunto de estos datos forma esta base de datos que contiene el ratio de suicidios por pa\u00eds y a\u00f1o dividido por lo diferentes grupos que hay en la ciudad, grupos distingidos por sexo y franja de edad. Si bien no hay un objetivo especificado la motivaci\u00f3n de este conjunto de datos es la prevenci\u00f3n de los suicidios, es por esto que vamos a afrontar con diferentes enfoques para ver si se puede realizar un estudio que nos ayude a predecir las causas de estos sucesos.","39255932":"Podemos ver que lo que deciamos anteriormente se corresponde con la ejecuci\u00f3n de nuestra funci\u00f3n y por lo tanto la columna *HDI for year* ha sido eliminada. El siguiente paso es eliminar aquellas columnas que anteriormente hemos dicho que no nos eran \u00fatiles porque estan formadas a trav\u00e9s de la composici\u00f3n de otras o es informaci\u00f3n redundante que indice a errores a los algoritmos.","78f62f8b":"Ahora tenemos un diccionario donde tenemos las x de estandarizadas y las y de cada pa\u00eds. En la ejecuci\u00f3n podemos ver un ejemplo de una fila de atributos estandarizados de Estados Unidos.\n\nYa lo tenemos todo listo para poder realizar las experimentaciones as\u00ed que en el siguiente subapartado procederemos a realizarlo.","b621a60b":"Aqu\u00ed ya podemos ver cual es el mejor grado para la regresion, la mejor k y dentro de la cross validaci\u00f3n la mejor iteraci\u00f3n. Vamos ahora a utilizar ese regresor para hacer la validaci\u00f3n con los \u00faltimos a\u00f1os.","b0ba7385":"Aqu\u00ed podemos ver la elbow curve qye no indica que la mejor k se situar\u00eda alrededos de un valor aproximado de 5, por lo que se har\u00e1n agrupaciones de 5 grupos diferentes.","e92529d9":"El report nos avisa de que todas las proporciones de suicidios contiene muchos 0, por ejemplo pordemos ver que para gente entre 5 y 14 a\u00f1os tenemos aproximadamente un cuarto de los datos que son 0, lo que significa que en esa franja de edad hay muchos a\u00f1os en algunos paises que no se suicida nadie. Otra cosa curiosa que vemos es que la proporcion total de suicidios por cada 100 mil personas esta muy correlacionado con la proporci\u00f3n de suicidios entre las mujeres y el rango de suicidios de poblaci\u00f3n entre 35 y 54 a\u00f1os. Luego tambi\u00e9n nos avisa como siempre sobre la alta cardinalidad del atributo con el nombre de los pa\u00edses.\n\nLa idea es con esto agrupar en grupos donda cada grupo contendr\u00e1 unas caracter\u00edsticas diferenciadoras de los dem\u00e1s, primero miraremos un a\u00f1o m\u00e1s actual como 2014 y un m\u00e1s antiguo, 1995. Por el n\u00famero de muestras que contiene son los a\u00f1os m\u00e1s separados y que contiene un alto n\u00famero de muestras.","7be9adca":"Igualmente que antes explicaremos los atributos nuevos que se han creado:\n- *country*: Es el nombre del pa\u00eds, no requiere estandarizaci\u00f3n, es nuestro output.\n- *year*: A\u00f1o, no requiere estandarizaci\u00f3n, vamos a diferenciar los a\u00f1os.\n- *population*: Cantidad de poblaci\u00f3n ese a\u00f1o en ese pa\u00eds.\n- *female*: Proporci\u00f3n por 100 mil personas de mujeres que se han suicidado.\n- *male*: Proporci\u00f3n por 100 mil personas de hombres que se han suicidado.\n- *5-14 years*:  Proporci\u00f3n por 100 mil personas en el rango de edad de 5 a 14 a\u00f1os.\n- *15-24 years*: Proporci\u00f3n por 100 mil personas en el rango de edad de 15 a 14 a\u00f1os.\n- *25-34 years*: Proporci\u00f3n por 100 mil personas en el rango de edad de 25 a 34 a\u00f1os.\n- *35-54 years*: Proporci\u00f3n por 100 mil personas en el rango de edad de 35 a 54 a\u00f1os.\n- *55-74 years*: Proporci\u00f3n por 100 mil personas en el rango de edad de 55 a 74 a\u00f1os.\n- *75+ years*: Proporci\u00f3n por 100 mil personas con edad superior a los 75 a\u00f1os.\n- *suicides\/100k pop*: Proporci\u00f3n de suicidios por cada 100 mil personas.\n- *gdp_per_capita (\\$)*: PIB por capita.\n\nLo siguiente que vamos a hacer es ver un report de este dataframe a ver si tenemos algo relevante que destacar.","2889b2b1":"Como se puede apreciar a lo largo de los a\u00f1os hay peque\u00f1os cambios que hacen que no se puedan agrupar los grupos igual para todos los a\u00f1os, sin embargo hay tendencias que perdur\u00e1n y nos da informaci\u00f3n de lo que ocurre.\n\nEn lo que respecta a la demograf\u00eda vemos que el rango de edad es lo m\u00e1s importante a la hora de determinar la proporci\u00f3n de suicidios en el pa\u00eds, si son una poblaci\u00f3n joven tienden a gaber menos suicidios que en poblaciones con edades m\u00e1s avanzadas.\n\nCuando hemos agrupado por ratio de suicidios de cada tipo de persona hemos visto que hay una tendencia clara, los hombres entre que comprenden edades entre los 35 y los 74 son los m\u00e1s propensoso al suicidio\n\nCon esto podemos ver que, a pesar de que a simple vista pueda parecer que el dinero es un factor determinante para ver si una poblaci\u00f3n tiende o no al suicidio esto no es cierto. La poblaci\u00f3n tampoco es algo que nos aporte demsiada informaci\u00f3n. Concluimos que sabiendo la edad de las personas que viven en estos paises y el genero podemos determinar si ser\u00e1 un pa\u00eds con muchos o pocos suicidios y que seguramente la mayor porte vengan del g\u00e9nero masculino de mediana edad.","16da654e":"Lo primero que vamos a mirar son los missing values, en este caso ning\u00fan atributo tiene, excepto la columna *HDI for year* que contiene el 69.9% de valores *NaN*. Para solucionar esto vamos a aplicar la funci\u00f3n que hab\u00edamos creado antes que si una columna ten\u00eda m\u00e1s de 65% de valores perdidos se eliminaba directamente.\n\nLo segundo que vemos es que los atributos *country*, *country-year* y *gdp_for_year (\\$)* tienen una alta cardinalidad, pero no hay que preocuparse, ya que el \u00faltimo es simplemente que el formato est\u00e1 mal, deber\u00eda ser de tipo num\u00e9rico pero est\u00e1 representado como si fuese un *string*. El caso del *country-year* es que es un atributo de la combinaci\u00f3n de *country* y de *year* as\u00ed que acabar\u00e1 siendo eliminado.\n\nLos atributos *age*, *sex*, *country-year* y *gdp_for_year (\\$)* est\u00e1n balanceados lo cu\u00e1l es bueno, ya que esto va hacer que no se distorsionen los c\u00e1lculos.\n\nLas columnas *suicides_no* y *suicides\/100k pop* tiene muchos valores que son 0, concretamente el 15.4%, el atributo *suicides_no* no importa porque ser\u00e1 eliminado, ya que mirar el n\u00famero de suicidios en total es bastante deficiente y nos basaremos en la proporci\u00f3n por cada 100 mil personas, pero ese atributo tambi\u00e9n tiene muchos 0, es algo que de momento obviaremos y m\u00e1s adelante lo retomaremos para darle una soluci\u00f3n.\n\nMirando el mapa de correlaciones podemos ver que excepto el n\u00famero de suicidios con la poblaci\u00f3n no hay atributos muy correlacionados, pero esto es lo que comentabamos antes de porque vamos a eliminar la columna *suicides_no*. Otra cosa que no se puede apreciar en el mapa de correlaciones es que el PIB per c\u00e1pita y el de por a\u00f1o siguen una correlaci\u00f3n de 1, ya que son proporcionales, as\u00ed que eliminaremos el *gdp_for_year (\\$)*, ya que al no estar en formato num\u00e9rico habr\u00eda que transformarlo y es m\u00e1s simple utilizar el otro. La generaci\u00f3n tambi\u00e9n se puede eliminar ya que tiene una alta relaci\u00f3n con el atributo de la franja de edad, nos viene a explicar pr\u00e1cticamente lo mismo, adem\u00e1s sabiendo el a\u00f1o y la franja de edad puedes saber la generaci\u00f3n, realmente no es informaci\u00f3n adicional.\n\nLo que tambi\u00e9n se puede observar son los valores extremos de cada atributo, los atributos que tenemos que mirar a fondo para ver si hay *outliers* son los num\u00e9ricos. El a\u00f1o no posee outliers ya que se mueve entre valores comprendidos entre 1985 y 2016, tal y como se especifica en el t\u00edtulo de la p\u00e1gina de la base de datos de *kaggle*. Los atributos que hemos dicho que vamos a eliminar no vamos a analizarlos. La poblaci\u00f3n si que posee algunos *outliers* ya que el tercr percentil es de 1486143.25 y el percentil 95 es de 8850239.6 y si nos vamos al valor m\u00e1ximo es de \t43805214, estas diferencias entre los percentiles son demasiado grandes. El caso de *suicides\/100k pop* tambi\u00e9n es grande, en el tercer percentil es de 16.62 y en el percentil 95 es de 50.5305 y el valor m\u00e1ximo asciende a 224.97. El *gdp_per_capita (\\$)* tambi\u00e9n tiene algunos, ya que del percentil 95 que es de 54294 asciendo el valor m\u00e1ximo a 126352.\n\nAntes de modificar las tablas vamos a analizar si estos outliers son anomalias o es por la descompensaci\u00f3n entre paises, para hacer esto lo que vamos a hacer es ver de donde salen estos datos.","6cc952f0":"Con esta funci\u00f3n eliminamos las columnas que tengan m\u00e1s de un 65% de los datos perdidos, y para los que tienen menos de un 65% eliminamos toda la fila","e5e5416f":"Podemos ver que se han eliminado alrededor de 800 elementos, es bastante poco teniendo en cuenta la cantidad de datos que tenemos, as\u00ed que seguimos contando un buen volumen de datos para hacer el estudio.","6bba32f3":"En el caso del ratio de suicidios si que son casos donde mejor no contarlos en la estadistica, ya son paises de poblaci\u00f3n muy baja y que se han suicidado muy pocas personas, pero hace que la proporcion sea muy alta, y adem\u00e1s no es siempre el mismo pa\u00eds por lo que parece que no es una tendencia de ese pa\u00eds si con son situaciones at\u00edpicas. Aunque si lo que vemos relevante es que la major\u00eda de sitios que ocurre son en la Republica de Korea, as\u00ed que aunque los vayamos a tratar como valores at\u00edpocos hay que tene en cuenta que no todos lo son.","9c51b191":"Podemos ver como han quedado nuestras variables independientes estandarizadas, no pasa nada por haber estandarizado las columnas de country porque tal y como son no modican su valor y siguen siendo 1 y 0.\n\nYa tenemos todo preparado para comenzar a aplicar la regressi\u00f3n lineal, as\u00ed que hasta aqu\u00ed llega el preprocesado.","da2ea67c":"Podemos ver una clara mejora de los datos en el atributo objetivo, no se puede decir que posea distribuci\u00f3n gaussiana pero a\u00fan as\u00ed ha mejorado mucho su distribuci\u00f3n.\n\nVisto esto pasaremos a mirar las correlaciones entre atributos.","4d446e00":"Empezando por Francia podemos ver que la edad es el atributo con mayor pero con diferencia, seguido del sexo y luego los a\u00f1os de manera negativa, la poblaci\u00f3n le otorga muy poca importancia para saber el ratio de suicidios.\n\nEn cuanto a Espa\u00f1a vemos que la edad tambi\u00e9n es el atributo m\u00e1s relevante, pero muy seguido de la poblaci\u00f3n con signo negativo, luego tenemos el g\u00e9nero tambi\u00e9n como importante, en este caso los menos relevante son los a\u00f1os, pr\u00e1cticamente tienen valor 0.\n\nEn Estados Unidos tenemos la edad y luego el g\u00e9nero con valores muy parejos, el resto de atributos tiene poco valor, resaltando la riqueza del pa\u00eds como el menos importante.\n\nDe estos tres pa\u00edses podemos ver que act\u00faan de una manera muy parecida, la edad y el g\u00e9nero cobran mucha importancia a la hora de saber la proporci\u00f3n de suicidios.","11a3f307":"Ni los a\u00f1os ni el PIB per c\u00e1pita parecen tener relaci\u00f3n con el atributo objetivo, esto nos da que pensar que lo que determina el n\u00famero de suicidios es la localizaci\u00f3n con bastante independencia de su nivel econ\u00f3mico.\n\nVeremos como se relaciona el atributo *country* con un *boxplot*.","34d20cb7":"## 3.2. Estudio conjunto del pa\u00eds\nLa idea de aqu\u00ed es agrupar los suicidios de cada pa\u00eds por a\u00f1o y pa\u00eds sin distinguir por sexo ni edad, as\u00ed podemos crear un modelo predictivo m\u00e1s general de lo que ocurre a nivel global\n\n### 3.2.1 Preprocesado\n\nPrimeramente eliminamos los atributos de sexo, edad y generaci\u00f3n y hacemos una agrupaci\u00f3n por pa\u00eds y a\u00f1o. Luego de esto mostraremos los atributos a ver como quedan las distribuciones de los datos, y seguidamente mostraremos las correlaciones. La variable categorica del pa\u00eds no es ordinal por lo que no podemos hacer esto para ver su relaci\u00f3n, mostraremos su relaci\u00f3n con el atributo objetivo con un boxplot y despu\u00e9s la codificaremos de forma binaria, ya que para una codificaci\u00f3n *One Hot* tiene demasiada cardinalidad. Finalmente separaremos las muestras en entreno y validaci\u00f3n y estandarizaremos con el *MinMaxScaler*, para la creaci\u00f3n del set de entreno y el de validaci\u00f3n lo que vamos hacer es entrenar con los datos hasta 2010 y validaremos con los a\u00f1os restante, as\u00ed veremos si creando un regesor lineal de los a\u00f1os pasados podemos predecir lo que ha ocurrido en los \u00faltimos a\u00f1os.","4cde6f22":"Aqu\u00ed tenemos un diccionario con el mejor regresor lineal por cada pa\u00eds, como se ve en la ejecuci\u00f3n lo \u00fanico que tenemos es el objeto del regresor lineal que nos servir\u00e1 para llegar a conclusiones.","0a4555ca":"En esta funci\u00f3n cargamos los datos en un objeto dataframe de la libreria de pandas","d42ad8e5":"Como vemos tenemos atributos diferentes, pero son simplemente transformaciones de la informaci\u00f3n que ya ten\u00edamos antes, para agilizar hemos estandarizado directamente los datos con el *MinMaxScaler*. Vamos a pasar a explicar cada atributo lo que significa:\n- *country*: Es el nombre del pa\u00eds, no requiere estandarizaci\u00f3n, es nuestro output.\n- *year*: A\u00f1o, no requiere estandarizaci\u00f3n, vamos a diferenciar los a\u00f1os.\n- *population*: Cantidad de poblaci\u00f3n ese a\u00f1o en ese pa\u00eds.\n- *female (%)*: Porcentage de mujeres en el pa\u00eds.\n- *5-14 years*: Porcentage de poblaci\u00f3n en el rango de edad de 5 a 14 a\u00f1os.\n- *15-24 years*: Porcentage de poblaci\u00f3n en el rango de edad de 15 a 14 a\u00f1os.\n- *25-34 years*: Porcentage de poblaci\u00f3n en el rango de edad de 25 a 34 a\u00f1os.\n- *35-54 years*: Porcentage de poblaci\u00f3n en el rango de edad de 35 a 54 a\u00f1os.\n- *55-74 years*: Porcentage de poblaci\u00f3n en el rango de edad de 55 a 74 a\u00f1os.\n- *75+ years*: Porcentage de poblaci\u00f3n superior a los 75 a\u00f1os de edad.\n- *suicides\/100k pop*: Proporci\u00f3n de suicidios por cada 100 mil personas.\n- *gdp_per_capita (\\$)*: PIB por capita.\n\nLo siguiente que vamos a hacer es ver un report de este dataframe a ver si tenemos algo relevante que destacar.","7bb0eae9":"Aqu\u00ed vemos un ejemplo de Estados Unidos de como quedan los dataset despu\u00e9s de la eliminaci\u00f3n de las columnas.","5c236927":"En esta ejecuci\u00f3n podemos ver para cada pa\u00eds que peso se ha asignado a cada uno de los atributos, se puede ver el pa\u00eds que se desee pero lo que vamos hacer es profundizar en tres pa\u00edses, Espa\u00f1a, Estados Unidos y Francia.","045dd2ff":"Aqu\u00ed lo que hemos extraido es la mejor k con el valor medio entre el valor del mse y el del r2. Dentro de esa k el mejor modelo encontrado ser\u00eda el sexto en caso de Espa\u00f1a, esto nos servir\u00e1 para encontrar el mejor regresor.","8b1eec61":"Podemos ver la elbow curve la cu\u00e1l nos dice que la mejor k es aquella en la que esta curva comienza a suavizarse, en este caso ser\u00eda de 10, pero analizando nuestros datos vemos que tenemos pocos atributos, en concreto 12 contando el a\u00f1o y el pa\u00eds que no se van a utilizar para el Kmeans. As\u00ed que para que no haya los mismos grupos que atributos vamos a escoger una k de 4.","e3f1568f":"Hemos creado 4 grupos diferentes seg\u00fan la demagraf\u00eda en 2014, vamos a pasar a definir cada uno de estos grupos y ver que caracter\u00edsticas tiene cada uno.\n\n- Cluster 0: Es el grupo con mayor ratio de suicidios y son paises con poco nivel econ\u00f3mico. Su poblaci\u00f3n es m\u00e1s abundante en las franjas de edad superiores de 34 a\u00f1os, no hay mucha cantidad de poblaci\u00f3n y el porcentage de hombre y mujeres es equilibrado pero con un ligero dominio de la poblaci\u00f3n masculina.\n\n- Cluster 1: Estos paises han pocos suicidios y son los paises mas pobres, su poblaci\u00f3n es abundante y equilibrada en g\u00e9nero, las edad m\u00e1s habituales son la franja de 35 a 54 a\u00f1os y lo de 5 a 14 a\u00f1os.\n\n- Cluster 2: Estos son paises con gran indice de suicidios pero son los m\u00e1s ricos, su poblaci\u00f3n es muy abundante y con predominancia entre las edades mayores a 34 a\u00f1os, el genero de la poblaci\u00f3n esta equilibrado.\n\n- Cluster 3: Este grupo lo conforman paises con muy pocos suicidios, muy poca poblaci\u00f3n y paises ricos, con poco porcentage de mujeres y poblaci\u00f3n en la franja de edad joven y media, entre 25 y 54, la poblaci\u00f3n mayor de esta edad es muy escasa en estos paises.\n\nAhora que ya hemos visto los 4 grupos formados en 2014, vamos a ver que 4 grupos se forman en 1995.","2efd3ed8":"En esta gr\u00e1fica lo que podemos observar esque las predicciones de cada a\u00f1o no se corresponden demasiado con los sucesos que han pasado realmente, las predicciones por cada a\u00f1o son muy parecidas entre ellas. Por todo esto estimamos que las predicciones de estos \u00faltimos 6 a\u00f1os son malos y aproximadamente siempre nos devuelve el mismo valor. Ahora veremos una gr\u00e1fica que nos muestra el error de cada muestra divididas por a\u00f1os. ","63b15f60":"En esta ejecuci\u00f3n podemos ver que el n\u00famero de pa\u00edses de los que se va hacer el estudio es de 53 y podemos ver el nombre de los pa\u00edses en cuesti\u00f3n. Ahora vamos a ver el histograma de los atributos para ver si han mejorado en algo.","6903be57":"## 3.1. Estudio por paises\nEn este caso crearemos modelos predictivos para cada pa\u00eds para poder ver como act\u00faa la poblaci\u00f3n de un mismo lugar.\n\n### 3.1.1 Preprocesado\nLo primero que vamos a hacer es crear un diccionario donda cada entrada ser\u00e1 un dataframe con la informaci\u00f3n de cada pa\u00eds. Si un pa\u00eds tiene menos de 50 columnas es eliminado, ya que con pocos datos no se puede hacer nada.\n\nDe estos datos tenemos que eliminar la columna de *country* ya que ha dejado de tener sentido, ya que ahora los paises ser\u00e1n modelos independientes. Luego de esto vamos a mirar aquellos lugares que tengan en la mediana almenos un valor de 5, ya que con menos significa que casi todo es 0 y nos sirve de poco hacer un modelo sobre un pa\u00eds as\u00ed.","1552e0cd":"### 3.1.2 Experimentaci\u00f3n\nLo que vamos hacer en este apartado es hacer un cross validate para cada pa\u00eds aplicando una regresi\u00f3n lineal, sacaremos cual es el mejor modelo para diferentes k teniendo en cuenta la mse y el r2.","a7078cb0":"## 3.3. Clusterizaci\u00f3n\nEn este apartado aplicaremos un algoitmo de clusterizaci\u00f3n no supervisado, el kmeans, para hacer agrupaciones de los pa\u00edses que m\u00e1s se parecen entre ellos, de esta manera podemos encontrar que pa\u00edses son m\u00e1s parecidos entre ellos y que caracter\u00edsticas son m\u00e1s relevantes de cada uno.\n\nPara esto vamos a transformar el dataset para poder hacer una clusterizaci\u00f3n seg\u00fan la demograf\u00eda y otra seg\u00fan la proporci\u00f3n de suicidios de cada grupo de individuos.\n\n### 3.3.1. Clusterizaci\u00f3n por demograf\u00eda\nAhora en la funci\u00f3n de abajo vamos a crear nuestro nuevo dataset, en el cu\u00e1l veremos que porcentage de cada grupo de personas hay en cada pa\u00eds por a\u00f1o.","b8e77efd":"Aplicando la t\u00e9cnica de *Z-Score* identificaremos los valores que son demasiado distantes de la distribuci\u00f3n y los eliminaremos considerandolos *outliers*.","0e3909ab":"Pdemos ver que hay mucha variaci\u00f3n dependiendo de cada pa\u00eds, esto nos hace pensar que este artibuto si que esta altamente correlacionado con el target, pero ser\u00e1 el modelo quien nos determine esto exactamente.\n\nLo siguiente a hacer es aplicar la codificaci\u00f3n para la variable *country*","6a4ec1a5":"Vemos que varias filas han sido eliminadas y las desviaciones de los datos ya no son tan grandes y los valores m\u00e1ximos son m\u00e1s reducidos ahora.","7bf93635":"### 3.3.2. Clusterizaci\u00f3n por ratio de suicidios de grupos\nVamos a crear el nuevo dataset el con el que veremos por cada pa\u00eds y a\u00f1o que proporci\u00f3n de suicidios hay de cada grupo de personas.","c1e52a56":"Aqu\u00ed podemos ver como queda nuestro dataset ahora tenemos 7 columnas adicionales y hemos perdido la que nos indicaba el nombre del pa\u00eds con un *string*. Ahora pasaremos partir los datos en entrenamiento y validaci\u00f3n como hemos dicho anteriormente y estandarizaremos con un *MinMaxScaler* ya que nuestros datos no tienen distribuci\u00f3n normal y por lo tanto un *StandardScaler* dar\u00eda malos resultados.","8727f6bc":"Lo primero que vemos es que Luxemburgo es pa\u00eds muy rico, pero si nos fijamos es siempre del mismo a\u00f1o, vamos a analizar si para este pa\u00eds son valores normales, si lo son habr\u00e1 que dejarlos, pero si no lo son habr\u00e1 que eliminarlos.\n\nDespu\u00e9s de ver esto concluimos que solo tenemos que eliminar los *outliers* de la columna *suicides\/100k pop*.","9fefc628":"En esta gr\u00e1fica podemos ver el error que se cometido entre lo que ha ocurrido y lo que se ha predicho, los valores contra m\u00e1s lejos de la l\u00ednea roja est\u00e1n m\u00e1s error ha habido, ninguno de los a\u00f1os se puede decir que sea preciso. Por \u00faltimo vamos a ver una gr\u00e1fica de todos los valores de estos \u00faltimos 6 a\u00f1os que nos mostrar\u00e1 tambi\u00e9n el error de caa muestra pero de una manera m\u00e1s visual.","38ae3ed5":"Este es el resultado de la anteriormente descrito, podemos ver que nos hemos quedado con 2321 filas y solamente 5 columnas. Lo siguiente que haremos ser\u00e1 printar los histogramas de los atributos para ver como se distribuyen los datos.","361cc362":"### 3.2.2. Experimentaci\u00f3n\nLo que haremos aqu\u00ed es aplicar un regresor lineal de grado 1 y de grado 2 en un cross validate con diferentes k para comprobar cual es la mejor manera de entrenar los datos, extraeremos el mejor modelo y luego haremos la validaci\u00f3n con los datos de 2010 hasta 2016. Con esto veremos si es buen modelo predictivo o no.","5edd9dee":"Siguen sin tener la mejor forma posible pero vemos que han mejorado bastante al separarlo por paises, ahora buscaremos las correlaciones entre los atributos y para eso lo que haremos ser\u00e1 codificar el atributo *sex*, como 1 para *male* y 0 para *female* y tambi\u00e9n codificaremos el atributo *age* de manera ordinal, ya que al hacer eferencia a edades es l\u00f3gico que por ejemplo el intervalo entre 55 y 74 a\u00f1os tenga un valor mayor al intervalo de 15 y 24 a\u00f1os.","296a86bc":"# 2. Exploratory Data Analysis\nLo primero que se va a hacer es cargar los datos en un objeto *dataframe* de la librer\u00eda *pandas* para poder hacer el EDA y eliminar aquellas columnas que aporten informaci\u00f3n redundante. Identificaremos que atributos contiene la base de datos y si tiene sentido tenerlos en cuenta en nuestro estudio.","966eb362":"Parece ser que este es un pa\u00eds bastante rico, por lo que tampoco deberiamos eliminar los *outliers*.","5f916b55":"No hay nada especialmente llamativo a resaltar,lo mas relevante quizas sea la alta cardinalidad del atributo *country* y que el atributo *suicides\/100k pop* contiene tambi\u00e9n una alta frecuencia de zeros, pero eso es algo que hemos sufrido durante todo el estudio.\n\nLa idea ahora es la siguiente, cogeremos un a\u00f1o actual, como 2014 y agruparemos por clusters y luego cogeremos un a\u00f1o lejano, 1995, y veremos si los clusters mantienen las mismas propiedades, en caso afirmativo veremos un patr\u00f3n constante durante el paso de los a\u00f1os, si por el contrario son diferentes veremos que el paso de los a\u00f1os afecta a la poblaci\u00f3n.","06f49731":"Tenemos el error y el coeficiente r2, con esto en el apartado siguiente llegaremos a las conclusiones pertinentes.","b8ebc754":"El eje de las X son los valores reales y el eje vertical son los valors predichos, en una perfecta predicci\u00f3n los puntos seguiri\u00e1n la l\u00ednia roja diagonal, pero este no es el caso y los puntos se encuentran muy dispersos.","6b836f17":"### 3.3.3 Conclusiones\nDespu\u00e9s de haber terminado con esto vamos extraer toda la informaci\u00f3n que se pueda de la clusterizaci\u00f3n que hemos realizado en los apartados anteriores.","00e7dc15":"### 3.2.3 Conclusiones\n","cdb6a538":"Bueno aqu\u00ed tenemos los centroides de cada cluster, pero esto no es muy visual y es dif\u00edcil de interpretar, por eso vamos a representarlos de manera gr\u00e1fica y a partir de aqu\u00ed extraeremos las conclusiones pertinentes.","bc849983":"# Librerias\nLas diferentes librer\u00edas que se han necesitado se encuentran aqu\u00ed.","aaa25b81":"Vamos a difentificar los 5 grupos formados por los ratios de suicidios de cada tipo de persona:\n\n- Cluster 0: El primer grupo lo conforman pa\u00edses con una alta proporci\u00f3n de suicidios, son pa\u00edses pobres y con un valor bajo de poblaci\u00f3n. Los hombres se suicidan en proporci\u00f3n mucho m\u00e1s alta que los hombres y el rango de edad m\u00e1s propenso es el de 55 a 74 a\u00f1os, siendo los m\u00e1s peque\u00f1os los que menos se suicidan.\n\n- Cluster 1: Estos pa\u00edses son muy ricos pero no tiene un gran \u00edndice de suicidio, la poblaci\u00f3n es grande y son tambi\u00e9n los hombres los que m\u00e1s se suicidan, el rango m\u00e1s alto en suicidios es de 55 a 74 a\u00f1os y los m\u00e1s peque\u00f1os apenas se suicidan.\n\n- Cluster 2: Son un grupo con un \u00edndice de suicidios relativamente bajo, son pobres y con bastante poblaci\u00f3n, domina el g\u00e9nero masculino como el m\u00e1s propenso y siendo los frecuente la poblaci\u00f3n comprendida entre los 25 a los 54.\n\n- Cluster 3: Son el grupo con mayor indice de suicidios y son ligeramente mas ricos que el grupo anterior. Su poblaci\u00f3n es abundante y con propensi\u00f3n a los suicidios de hombre entre 55 y 74 a\u00f1os.\n\n- Cluster 4: Este es un grupo con muy bajo \u00edndice de suicidios y con buen nivel econ\u00f3mico, la poblaci\u00f3n es escasa y son los hombre quien se suicidan en mayor proporci\u00f3n siendo el ranfo de 25 a 34 los que m\u00e1s.\n\nIgual que antes vamos a comparar si el paso de los a\u00f1os mantiene una tendencia en los grupos o por si lo contrario las conclusiones que se extraen de los a\u00f1os m\u00e1s antiguos no aplican en los tiempos modernos.","a5f02a23":"Aqu\u00ed podemos ver como queda nuestro dataset despu\u00e9s de la eliminaci\u00f3n. El siguiente paso es la eliminaci\u00f3n de los outliers de nuestros atributos num\u00e9ricos, excepto del atributo *year*, tal y como hab\u00edamos dicho anteriormente. Vamos a aplicar el m\u00e9todo que hemos creado al principio que aplica la t\u00e9cnica *Z-Score*","469a679a":"Vemos que el error es bastante grande y el r2 es cercano a cero y negativo, lo cual indica que este no es un buen modelo, igualemente vamos a ver una gr\u00e1fica que nos muestre los que a pasado desde 2011 hasta 2016 y que el lo que ha predicho nuestro modelo","e9c9fe09":"Podemos ver para cada pa\u00eds el mse y el r2 medio para cada k, hay que decir que el mse est\u00e1 negativo porque as\u00ed lo fuerza la librer\u00eda, con esto nos quieren indicar que esa variable es una variable a minimizar. Ahora lo que haremos ser\u00e1 valorar cual es la mejor k para cada pa\u00eds y extraer el mejor modelo que haya creado la cross validaci\u00f3n para poder ver los coeficientes y as\u00ed ver a que atributos asigna m\u00e1s peso. ","67359fbd":"Como podemos ver estos datos van a tener que adaptarse para poder trabajar con ellos ya que existen muchos valores discretos que no podemos tratar tal y como estan. Tambi\u00e9n vemos que la columna *HDI for year* tiene los 5 primeros valores a *NaN*, esto nos hace sospechar as\u00ed que mirarmemos si son solo estos o esta columna tiene demasiados valores as\u00ed.\n\nAntes de continuar vamos a describir todos los atributos que contienen nuestros datos de manera que cuando avancemos y tomemos ciertas decisiones se entienda bien lo que se esta haciendo:\n\n- *country*: Pa\u00eds donde ha ocurrido.\n\n- *year*: A\u00f1o que ha sucedido.\n\n- *sex*: Genero del fallecido.\n\n- *age*: Edad del fallecido.\n\n- *suicides_no*: N\u00famero de suicidios.\n\n- *population*: Poblaci\u00f3n.\n\n- *suicides\/100k pop*: Proporci\u00f3n del n\u00famero de suicidios por cada 100 mil personas.\n\n- *country-year*: Pa\u00eds y a\u00f1o del suceso.\n\n- *HDI for year: \u00cdndice de desarrollo humano, es una media aritm\u00e9tica de tres indices, tener una vida larga y saludable, adquirir conocimientos y disfrutar de un nivel de vida digno.\n- gdp_for_year (\\$)*: PIB por a\u00f1o.\n\n- *gdp_per_capita (\\$)*: PIB per c\u00e1pita.\n\n- *generation*: Generaci\u00f3n del fallecido.\n\nAhora que ya tenemos una idea de como es nuestro *dataframe* vamos a ver el report de los datos, analizaremos lo m\u00e1s importante para poder tomar posteriores decisiones de manera correcta.","d03dfc29":"Ahora los grupos han variado as\u00ed que explicaremos un poco las caracter\u00edsticas de cada grupo:\n- Cluster 0: Este grupo tiene los suicidios generales relativamente bajos y son un pa\u00eds rico con mucha poblaci\u00f3n. Es el g\u00e9nero masculino en el rango de los 35 a los 54 el m\u00e1s predispuesto.\n\n- Cluster 1: Estos pa\u00edses son muy ricos pero con el mayor \u00edndice de suicidios, la poblaci\u00f3n es grande y son tambi\u00e9n los hombres los que m\u00e1s se suicidan, el rango m\u00e1s alto en suicidios es de 55 a 74 a\u00f1os y los m\u00e1s peque\u00f1os apenas se suicidan.\n\n- Cluster 2: Son un grupo con un \u00edndice de suicidios bajo y son pobres y con poca poblaci\u00f3n, domina el g\u00e9nero masculino como el m\u00e1s propenso y siendo los frecuente la poblaci\u00f3n comprendida entre los 25 a los 34.\n\n- Cluster 3: Son el grupo con indice de suicidios  muy grande y son muy pobres. Su poblaci\u00f3n es abundante y con propensi\u00f3n a los suicidios de mujeres mayores de 75 y entre 15 y 24 a\u00f1os.\n\n- Cluster 4: Este es un grupo con alto \u00edndice de suicidios y con muy bajo nivel econ\u00f3mico, la poblaci\u00f3n es muy escasa y son los hombre quien se suicidan en mayor proporci\u00f3n siendo el ranfo de 25 a 34 los que m\u00e1s.\n\nUna vez visto esto lo que vamos a hacer es analizar lo que hemos ido haciendo en el apartado de clusterizaci\u00f3n y extraer todas las conclusiones que se pueda.","1dd987ed":"Aqu\u00ed parece que la descompensaci\u00f3n esta en la poblaci\u00f3n de estados unidos que es muy grande y por lo tanto distorsiona los datos, pero en este caso es mejor no eliminar estas filas ya que lo que haremos es dejar de tener en cuenta a la poblaci\u00f3n de Estados Unidos y no sabiendo eso no podemos decir que aplique como estudio universal.","a59ec447":"### 3.1.3. Conclusiones\nUna vez ya hemos encontrado el mejor modelo vamos a ense\u00f1ar para cada pa\u00eds que pesos a asignado a cada atributos y analizaremos un poco algunos de los pa\u00edses m\u00e1s interesantes, como son Espa\u00f1a, Estados Unidos, Francia.","b8e4a65a":"Entre cada pa\u00eds hay variaciones, pero por lo general vemos tendencia a ver los atributos de sexo y edad como los m\u00e1s relacionados, lo que implica que al ser de forma positiva existe cierta tendencia de ser el g\u00e9nero masculino el que sufre de m\u00e1s suicidios y en una edad m\u00e1s avanzada, no son los m\u00e1s jovenes los que se suicidan m\u00e1s.\n\nLos siguientes pasos son partir el dataset en test y train y estandatizarlo, para eso utilizaremos la funci\u00f3n de abajo. Aplicaremos la estandarizaci\u00f3n *MinMaxScaler* ya que una estandarizaci\u00f3n est\u00e1ndar no dar\u00eda bueno resultados, nuestros datos distan demasiado de una distribuci\u00f3n normal as\u00ed que que el c\u00e1lculo dar\u00eda unos malos resultados.","e8c79443":"Podemos ver como se han quedado las columnas categoricas codificadas, con esto podemos sacar las correlaciones y observar los atributos que m\u00e1s relacionados est\u00e1n."}}