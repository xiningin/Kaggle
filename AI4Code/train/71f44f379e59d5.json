{"cell_type":{"475021ce":"code","1dd188f0":"code","5f3e0121":"code","d78d59f5":"code","cbe9f72d":"code","8c35ad6a":"code","92c51b85":"code","7d369eb0":"code","0f4f5841":"code","8e7a4d72":"code","6ac8dbcf":"code","bf09a319":"code","4b1a3daa":"code","79bad31f":"code","c28df339":"markdown","d5f1b210":"markdown","4125bb71":"markdown","8d75d2ac":"markdown","d36b0605":"markdown","9a4cf610":"markdown","a4c6e2a9":"markdown","e2b04dd7":"markdown","a0e48172":"markdown","644d1c11":"markdown","0ef0f463":"markdown","b433338c":"markdown","01f9f385":"markdown","8ded5baf":"markdown","30f566dc":"markdown","389f00fb":"markdown","57d0fdb7":"markdown","aee5d5b8":"markdown"},"source":{"475021ce":"# Import torch and other required modules\nimport torch\nimport numpy as np","1dd188f0":"# Example 1 \nx = torch.tensor([[3.14]])\ny = x.item()\n\nprint(x.dtype)\nprint(type(y))","5f3e0121":"# Example 2\nx = torch.tensor([[1, 2], [3, 4]])\ny = x.item()\n","d78d59f5":"# Example 1 - \ntensor = torch.zeros((2,), dtype=torch.float64)\nx = [[2, 6], [26, 1728]]\ny = tensor.new_tensor(x)\nprint(tensor)\nprint(y)\nprint(tensor.shape)\nprint(y.shape)\n","cbe9f72d":"tensor = torch.zeros((2,), dtype=torch.float64)\nx = [[2, 6], [26, 1729]]\ny = tensor.new_tensor(x)\nprint(\"Before changing value at x[1][1] : \")\nprint(y)\nx[1][1] = 1.618\nprint(\"After changing value at x[1][1] : \")\nprint(\"x : \", x)\nprint(\"y : \", y)\n","8c35ad6a":"tensor = torch.zeros((2,), dtype=torch.float64)\nx = np.array([[2., 6.], [26., 1729.]])\ny = torch.from_numpy(x)\nprint(\"Before changing value at x[1][1] : \")\nprint(y)\nx[1][1] = 1.618\nprint(\"After changing value at x[1][1] : \")\nprint(\"x : \", x)\nprint(\"y : \", y)","92c51b85":"x = torch.tensor([[11.2, 6.022], [1.380, 6.674]])\ny = torch.exp(x)\nprint(y)","7d369eb0":"x = torch.tensor([[11.2, 6.022], [1.380, 6.674]])\ny = torch.sigmoid(x)\nprint(y)","0f4f5841":"x = torch.tensor([1.380, 6.022, 1.602, 6.674])\ntorch.std_mean(x)","8e7a4d72":"x = torch.tensor([[2,3,6,26], [1.380, 6.022, 1.602, 6.674]])\ntorch.std_mean(x,1)","6ac8dbcf":"x = torch.tensor([2,3,6,26])\ntorch.std_mean(x)","bf09a319":"!pip install jovian --upgrade --quiet","4b1a3daa":"import jovian","79bad31f":"jovian.commit()","c28df339":"As we can see in above example, this function only accepts floating point (decimal) numbers.","d5f1b210":"Here we see that we changed the value of x[1][1] from 1729 to 1.618 it is reflected in both, that is, the tensor y and the numpy array x. ","4125bb71":"As we can see above a tensor with single value is converted into a float data-type in python","8d75d2ac":"As we can see in above example, whatever be dimension the initial tensor, we can change it according to the python list, also we can see that the data-type of element when copied to the tensor, gets changed according to the data-type tensor is previously created with.","d36b0605":"The above example we can see that new_tensor() copies the value from a python list to self. If you want to avoid this use torch.from_numpy()","9a4cf610":"# Exploring the world's coolest tensor using PyTorch functions.\n\nFor this assignment, My choice of 5 functions are \n- torch.tensor.item()\n- torch.new_tensor(data, dtype=None, device=None, requires_grad=False)    \n- torch.exp(input, out=None)         \n- torch.sigmoid(input, out=None)     \n- torch.std_mean(input, dim, unbiased=True, keepdim=False)    ","a4c6e2a9":"## Function 1 - torch.tensor.item() \nThis function is used to retrieve a scalar quantity from a single valued tensor, in other                         words, it is used to convert a single valued tensor to python number.","e2b04dd7":"This function is used to calculate sigmod value of the elements in a tensor. Sigmoid function in simple terms is used to place a number's value between 0 to 1. It is useful in logistic regression. To read more about it follow the reference below!","a0e48172":"## Function 5 - torch.std_mean(input, dim, unbiased=True, keepdim=False)    \n\nThis function calculates and returns standard deviation and mean of all the values in a tensor","644d1c11":"## Function 3 - torch.exp(input, out=None)         \n       \nThis function is used to return the exponential value of elements in a tensor. Highly useful in calculating softmax function","0ef0f463":"## Function 2 - torch.new_tensor(data, dtype=None, device=None, requires_grad=False)    \n\nThis function is used to intialize a pytorch tensor from a pre-existing python list.","b433338c":"## Reference Links\n\n* Official documentation for `torch.Tensor`: https:\/\/pytorch.org\/docs\/stable\/tensors.html\n* Softmax function : https:\/\/medium.com\/data-science-bootcamp\/understand-the-softmax-function-in-minutes-f3a59641e86d\n* Multi-class classification : https:\/\/medium.com\/apprentice-journal\/evaluating-multi-class-classifiers-12b2946e755b\n* Logistic regression : https:\/\/medium.com\/greyatom\/logistic-regression-89e496433063","01f9f385":"for a tensor whose dimension is greater than (x,1) or in this case a 2 dimensional tensor (matrix), if we pass dim = 1 it calculates the value value of standard deviation and mean by each column.","8ded5baf":"## Conclusion\n\nThe function that we saw above are one of the most commonly used function and very powerful for performing complex things with fewer and most of the time single line of code.","30f566dc":"## Function 4 - torch.sigmoid(input, out=None)     \n\nThis function is used to calculate elemet-wise sigmoid value. Used in logistic regression.   ","389f00fb":"In the above example we can see this fucntion calculates the exponential value of the given tensor. this function along with torch.sum() can be used to create one-liner softmax function used in multi-class classification (easy-peesy). To read more about it check out the reference below!","57d0fdb7":"This above example shows that only a single valued tensor can be converted to a python number.","aee5d5b8":"As we can see in above example, to quickly calculate standard devation and mean of a tensor. we can use this function."}}