{"cell_type":{"6a819986":"code","0ad7a3dd":"code","a7bbefc4":"code","dabbf7ef":"code","6a0bd362":"code","318c2f8f":"code","2808d3db":"code","bee48cb1":"code","d749af66":"code","d5a72d8e":"code","36ec0a03":"code","9f1f09d7":"code","1d55c240":"code","826b3aa9":"code","fadb57a7":"markdown","37f8cbd2":"markdown","0f5fb721":"markdown","d1809528":"markdown","08ea5c3e":"markdown","137bc8d0":"markdown","f3ea3628":"markdown","afbcb162":"markdown","f2a56b3f":"markdown","749f2443":"markdown","f072a0d8":"markdown","cea01589":"markdown","0e9ae17b":"markdown","4c63abaf":"markdown","3355f2a3":"markdown","ee0e5216":"markdown","31ce2406":"markdown","ef998777":"markdown","7a0963dc":"markdown","10b3fb85":"markdown"},"source":{"6a819986":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\n\nos.chdir('\/kaggle\/input\/covid19')\n\nconf_raw = pd.read_csv('confirmed_cases.csv') # 'total-confirmed-cases-of-covid-19-per-million-people.csv' from Our World in Data\ntests_raw = pd.read_csv('tests.csv') # 'full-list-cumulative-total-tests-per-thousand.csv' from Our World in Data\ndeaths_raw = pd.read_csv('deaths.csv') # 'total-daily-covid-deaths-per-million.csv' from Our World in Data\ndaily_conf_raw = pd.read_csv('daily_confirmed_cases.csv') # 'total-and-daily-cases-covid-19.csv' from Our World in Data\n\ntests_raw['Entity'] = tests_raw['Entity'].apply(lambda s: s.split('-')[0][:-1])","0ad7a3dd":"correl = deaths_raw.merge(daily_conf_raw, on=['Entity','Date']).rename(\n    columns={'Daily confirmed deaths per million (deaths per million)':'Daily deaths\/million',\n             'Daily new confirmed cases (cases)':'Daily cases'}\n)[['Entity','Date','Daily deaths\/million','Daily cases']]\ncorrel['Date'] = pd.to_datetime(correl['Date'])\ncorrel = correl[correl['Daily cases']>50] # Reducing noisy data\ncountries_correl = correl['Entity'].value_counts()\ncountries_correl = countries_correl[countries_correl > 10].index.to_list()\ncorrel = correl[correl['Entity'].apply(lambda i: i in countries_correl)]","a7bbefc4":"def plot_correl(country):    \n    df = correl[correl['Entity']==country]\n    df = df.sort_values('Date', ascending=True)\n    plt.figure(figsize=(20,7))\n    plt.plot(df['Date'], df['Daily deaths\/million'].rolling(window=6).mean()\/df['Daily deaths\/million'].max(), label='Daily deaths (scaled)')\n    plt.plot(df['Date'], df['Daily cases'].rolling(window=6).mean()\/df['Daily cases'].max(), label='Daily cases (scaled)')\n    plt.xticks(ticks=df['Date'],rotation=45)\n    plt.title(country)\n    plt.legend()\n    plt.show()\nplot_correl('France')\nplot_correl('Italy')\nplot_correl('Spain')\nplot_correl('South Korea')\nplot_correl('United Kingdom')","dabbf7ef":"from pandas.tseries.offsets import DateOffset\nN = 4\n\noffset_deaths = deaths_raw[['Entity','Date','Total confirmed deaths per million (deaths per million)']]\noffset_deaths['Date'] = pd.to_datetime(offset_deaths['Date'])\noffset_deaths['Date'] = offset_deaths['Date'].apply(lambda t : t-DateOffset(days=N))\nconf_raw['Entity-1'] = conf_raw['Entity'].apply(lambda s: s[:-1])\ntests_raw['Entity-1'] = tests_raw['Entity']\nfull = tests_raw.merge(conf_raw, on=['Entity-1','Date']).rename(columns={'Entity_y':'Entity'})\nfull['Date'] = pd.to_datetime(full['Date'])\nfull = full.merge(offset_deaths, on=['Entity','Date'])\n\ndata = full[['Entity', \n             'Date', \n             'Total tests per thousand',\n             'Total confirmed cases of COVID-19 per million people (cases per million)',\n             'Total confirmed deaths per million (deaths per million)']]\ndata = data.rename(columns={'Total tests per thousand':'Tests\/thousand',\n                            'Total confirmed cases of COVID-19 per million people (cases per million)':'Cases\/million',\n                            'Total confirmed deaths per million (deaths per million)':f'Deaths\/million d+{N}',\n                            })\ndata['Date'] = pd.to_datetime(data['Date'])\neps = 0.0\ndata = data[data[f'Deaths\/million d+{N}'] > eps]","6a0bd362":"# Will only consider data from after this date, in order to have a more homogenous dataset\nstart_date = pd.to_datetime('2020-03-15')\ndata = data[data['Date']>start_date]\n\n# Some countries are excluded from the dataset because of reliability issues\ncountries_to_exclude = ['Malaysia', 'Philippines', 'Australia', 'Bahrain', 'Indonesia', 'India',\n                        'Pakistan', 'Costa Rica', 'Ecuador', 'Uruguay', 'Thailand', 'Lithuania', \n                        'Tunisia', 'Senegal', 'Turkey', 'Serbia', 'Panama', 'Peru', 'Paraguay',\n                        'Mexico', 'Bangladesh', 'Bolivia', 'Chile', 'Ethiopia', 'Argentina',\n                        'Ghana', 'Colombia', 'El Salvador', 'Hungary']\ndata = data[data['Entity'].apply(lambda i: i not in countries_to_exclude)]\n\n# Computing the relevant ratios\ndata['Confirmed\/test'] = data['Cases\/million']\/(1000*data['Tests\/thousand']) # Converted to Tests\/million\ndata[f'Death d+{N}\/test'] = data[f'Deaths\/million d+{N}']\/(1000*data['Tests\/thousand'])\n\n# Final list of countries to be considered\ncountries = data['Entity'].value_counts().sort_values(ascending=False).index.to_list()\nprint('List of countries to be considered (sorted by descending number of data points):\\n', countries)\nprint(f'\\nNumber of countries: {len(countries)}')\nprint(f'Number of data points: {len(data)}')","318c2f8f":"# Some corrections need to be made to further homogenize our data\ncorrection = dict(zip(countries, [1.0]*len(countries))) # The value in this dict will be applied \n                                                        # as a multiplier of the value of\n                                                        # Deaths d+N \/ tests for each country\n\n# Correcting for differences in mortality rates due to age distribution and possibly genetic and cutural factors\n# Source: https:\/\/twitter.com\/TrevorSutcliffe\/status\/1246944321107976192\ncorrection['Italy'] = 0.5\ncorrection['Austria'] = 1.5\ncorrection['Germany'] = 1.5\n\n# Converting number of people tested into number of samples, assuming 2 samples\/person on average\n# (Some countries report the number of people tested, others report the number of samples)\ncorrection['South Korea'] = 0.5\ncorrection['United Kingdom'] = 0.5\ncorrection['Norway'] = 0.5\ncorrection['Netherlands'] = 0.5\ncorrection['Sweden'] = 0.5\n\n# Correcting for potential relative undercount in deaths (these are assumptions)\ncorrection['Belgium'] *= 0.5\ncorrection['France'] *= 0.8\ncorrection['Italy'] *= 1.2\n\n\nfor i in data.index:\n    line = data.loc[i]\n    data.loc[i,f'Death d+{N}\/test'] = line[f'Death d+{N}\/test'] * correction[line['Entity']]\n\n# Removing outliers from dataset    \nfrom scipy import stats\ndata = data[(np.abs(stats.zscore(data[['Confirmed\/test',f'Death d+{N}\/test']])) < 3).all(axis=1)]","2808d3db":"import matplotlib.pyplot as plt\nplt.rcParams['axes.prop_cycle'] = plt.cycler(color=plt.cm.tab20.colors)\ndef scatter_countries(countries,m=None,alpha=1,scale='linear', n_countries=19):\n    \"\"\"\n    This function plots a scatter plot using Matplotlib.\n        * countries: list of Strings corresponding to values of 'Entity' in data\n        * m: first parameter of the regression (optional)\n        * alpha: second paramter of the regression (optional)\n        * scale: String (optional) is the scale used for x values\n    \"\"\"\n    plt.figure(figsize=(10,10))\n    for country in countries[:n_countries]:\n        df = data[data['Entity']==country]\n        plt.scatter(df[f'Death d+{N}\/test'], df['Confirmed\/test'],marker='+', label=country)\n    df = data[data['Entity'].apply(lambda i: i in countries[n_countries:])]\n    plt.scatter(df[f'Death d+{N}\/test'], df['Confirmed\/test'],marker='+', label='Other')\n    if m is not None:\n        eps = 0.00001\n        x = np.linspace(eps, data[f'Death d+{N}\/test'].max(), 1000)\n        plt.plot(x,m*np.exp(alpha*np.log(x)))\n    plt.xscale(scale)\n    plt.xlabel(f'Deaths $d+{N}$ per test')\n    plt.ylabel('Positives per test')\n    plt.legend()\n    plt.show()\n\ncountries_plot = countries[:19]\nscatter_countries(countries, n_countries=19) # Limiting number of countries for readability","bee48cb1":"import statsmodels.formula.api as sfa\nfrom scipy.stats import pearsonr\n\n# Linear regression without intercept between y and sqrt(x)\nx = data[f'Death d+{N}\/test'].values\ny = data['Confirmed\/test'].values\ndf = pd.DataFrame({'x': np.sqrt(x), 'y': y})\nr = sfa.ols('y ~ x + 0', data=df).fit()\n\nfig, ax = plt.subplots(figsize=(10, 10))\nplt.xlabel(\"$\\sqrt{x}$\")\nplt.ylabel(\"$y$\")\nax.scatter(x=np.sqrt(x), y=y)\nax.plot(np.sqrt(x), r.fittedvalues)\n\ncorr, _ = pearsonr(np.sqrt(x), y)\nprint(f'Pearson Correlation - R^2: {corr:.4f}')","d749af66":"from scipy.optimize import curve_fit\n\ndef f(x,m,alpha):\n    return(m*np.power(x,alpha))\n\npopt, pcov = curve_fit(f, x, y,[1.5,0.5], bounds=(0.2,2))\nm, alpha = popt\nprint(f\"Optimal parameters found:\\n\\tm = {m:.4f}\\n\\talpha = {alpha:.4f}\")\ncorr, _ = pearsonr(np.power(x,alpha), y)\nprint(f'Pearson Correlation - R^2: {corr:.4f}')\n\nscatter_countries(countries,*popt, n_countries=19)","d5a72d8e":"def pred(d,pop,popt,test_sensitivity=0.50):\n    \"\"\"\n    This function computes a prediction of the proportion of infected people in country with:\n        * d: number of deaths in the country\n        * pop: population of the country\n        * popt: parameters to be used in the model\n        * test_precision: assumption on the probability of being tested positive, if infected.\n    \"\"\"\n    frac = d\/pop\n    return(f(frac,*popt)\/test_sensitivity)\n\n# April 24 data --> predictions about April 20\noff_deaths_Italy = 25549 * 1.2\npop_Italy = 60480000\nprint(f\"In Italy: {100*pred(off_deaths_Italy,pop_Italy,popt):.2f}% infected\")\noff_deaths_France = 21889 * 0.8\npop_France = 66990000\nprint(f\"In France: {100*pred(off_deaths_France,pop_France,popt):.2f}% infected\")\noff_deaths_NYC = 16388\npop_NYC = 8623000\nprint(f\"In NYC: {100*pred(off_deaths_NYC,pop_NYC,popt):.2f}% infected\")\n\nprint(f\"\\nEstimated current IFR in France: {100*(off_deaths_France\/(pred(off_deaths_France,pop_France,popt)*pop_France)):.3f}%\")\nprint(f\"Estimated current IFR in NYC: {100*(off_deaths_NYC\/(pred(off_deaths_NYC,pop_NYC,popt)*pop_NYC)):.3f}%\")\nprint(f\"Estimated current IFR in Italy: {100*(off_deaths_Italy\/(pred(off_deaths_Italy,pop_Italy,popt)*pop_Italy)):.3f}%\")","36ec0a03":"off_deaths_world = 191962\npop_world = 7794799000\nprint(f\"World: \\n\\n{100*pred(off_deaths_world,pop_world,popt):.2f}% infected\")\nprint(f\"{100*(off_deaths_world\/(pred(off_deaths_world,pop_world,popt)*pop_world)):.3f}% estimated current IFR\")","9f1f09d7":"print('At the end of March:')\n\noff_deaths_Netherlands = 540 # At the end of March\npop_Netherlands = 17280000\nprint(f\"\\nIn the Netherlands: {100*pred(off_deaths_Netherlands,pop_Netherlands,popt):.2f}% infected\")\n\noff_deaths_SantaClara = 25 # At the end of March\npop_SantaClara = 1928000\nprint(f\"In Santa Clara county: {100*pred(off_deaths_SantaClara,pop_SantaClara,popt):.2f}% infected\")\n\noff_deaths_LA = 617 * 7994\/13816 # early April data\npop_LA = 10040000\nprint(f\"In Los Angeles county: {100*pred(off_deaths_LA,pop_LA,popt):.2f}% infected\")\n\nprint(\"\\nAs of April 14:\")\noff_deaths_Stockholm = 1400 * 944\/1580\npop_Stockholm = 2377081\nprint(f\"\\nIn Stockholm county: {100*pred(off_deaths_Stockholm,pop_Stockholm,popt):.2f}% infected\")\n\nprint(\"\\nIn Geneva county:\")\noff_deaths_Geneva_10 = 858 * 4438\/27856\noff_deaths_Geneva_17 = 1141 * 4438\/27856\npop_geneva = 499480\nprint(f\"\\nBy April 10: {100*pred(off_deaths_Geneva_10,pop_geneva,popt):.2f}% infected\")\nprint(f\"By April 17: {100*pred(off_deaths_Geneva_17,pop_geneva,popt):.2f}% infected\")\n\nprint(\"\\nAs of April 20:\")\noff_deaths_NYS = 20982 # April 24 data\noff_deaths_NYC = 16388\npop_NYS = 19450000\npop_NYC = 8623000\nprint(f\"\\nIn New York State: {100*pred(off_deaths_NYS,pop_NYS,popt):.2f}% infected\")\nprint(f\"In New York City: {100*pred(off_deaths_NYC,pop_NYC,popt):.2f}% infected\")","1d55c240":"belgium = data[data['Entity']=='Belgium']\nx = belgium[f'Death d+{N}\/test'].values\ny = belgium['Confirmed\/test'].values\n\ndef f(x,m,alpha):\n    return(m*np.power(x,alpha))\n\npopt_belgium, pcov_belgium = curve_fit(f, x, y,[1.5,0.5], bounds=(0.2,2))\nscatter_countries([\"Belgium\"],*popt_belgium)\nm, alpha = popt_belgium\ncorr, _ = pearsonr(np.power(x,alpha), y)\nprint(f'Pearson Correlation - R^2: {corr:.4f}')\n\noff_deaths_Belgium = 5453 * 0.5\npop_Belgium = 11400000\nprint(f\"\\nIn Belgium: {100*pred(off_deaths_Belgium,pop_Belgium,popt_belgium):.2f}% infected\")\nprint(f\"Estimated death rate in Belgium: {100*(off_deaths_Belgium\/(pred(off_deaths_Belgium,pop_Belgium,popt_belgium)*pop_Belgium)):.3f}%\")\n","826b3aa9":"countries_to_include = ['Netherlands']\ncp_data = data[data['Entity'].apply(lambda i: i in countries_to_include)]\nx = cp_data[f'Death d+{N}\/test'].values\ny = cp_data['Confirmed\/test'].values\n\ndef f(x,m,alpha):\n    return(m*np.power(x,alpha))\n\npopt_cp_data, pcov_cp_data = curve_fit(f, x, y,[1.5,0.5], bounds=(0.2,2))\nscatter_countries(countries_to_include,*popt_cp_data)\nm, alpha = popt_cp_data\ncorr, _ = pearsonr(np.power(x,alpha), y)\nprint(f'Pearson Correlation - R^2: {corr:.4f}')\noff_deaths_Netherlands = 3601\npop_Netherlands = 17280000\nprint(f\"\\nIn the Netherlands, April 14: {100*pred(off_deaths_Netherlands,pop_Netherlands,popt_cp_data):.2f}% infected\")\nprint(f\"Estimated death rate in the Netherlands: {100*(off_deaths_Netherlands\/(pred(off_deaths_Netherlands,pop_Netherlands,popt_cp_data)*pop_Netherlands)):.3f}%\")\noff_deaths_Netherlands = 540 # At the end of March\npop_Netherlands = 17280000\nprint(f\"\\nIn the Netherlands, end of March: {100*pred(off_deaths_Netherlands,pop_Netherlands,popt_cp_data):.2f}% infected\")\nprint(f\"Estimated death rate in the Netherlands: {100*(off_deaths_Netherlands\/(pred(off_deaths_Netherlands,pop_Netherlands,popt_cp_data)*pop_Netherlands)):.3f}%\")","fadb57a7":"# On single countries","37f8cbd2":"As you can see, $R^2$ coefficients are stronger when using data from fewer countries, but then model we get is more biased and less generalizable to unseen countries.","0f5fb721":"This heuristic justifies the use of a value in the range $4-6$. I will keep the value of $4$, as changing it to $5$ or $6$ does not fundamentally change the results, and a lower $N$ allows to have more data.","d1809528":"# Final words\n\nI hope this notebook allowed you to have a better understanding of the Covid-19 pandemic. I did all this simply out of curiosity and, probably, looking for some good news. Unfortunately, even if the mortality rates found may strike you as being low, in reality, they are not lower than what most experts believe and the fact is that, even in countries as hardly hit as France or Italy, the prevalence of the virus is still well under $10\\%$ nationally, which means that this is nowhere near the end of this crisis. Nonetheless, the proportion of infected found for areas like NYC is good news because it means that herd immunity could kick in sooner that expected, even if the mortality rate there is not as low as what could be hoped for.","08ea5c3e":"The profile of this scatter plot is concave. Furthermore, for coherence purposes, the model needs to be equal to $0$ on $0$. As a first model, I fitted a linear regression between $y$ and $\\sqrt{x}$. ","137bc8d0":"The idea here is to reduce our dataset to one single country and compute predictions for that country alone. ","f3ea3628":"### In addition to being close to these sero-survey results, the model's predictions are all underestimations, except for Geneva which is expected due to Switzerland's aggressive testing policy that makes it an outlier country in our dataset.","afbcb162":"\n    \n    \n# <center>Using Testing Data to Estimate The True Number of Infected People<\/center>\n### <center>Tarek Ayed<\/center>\n\n![kaggleviz.png](attachment:kaggleviz.png)\n\n\n# Abstract\n\nThis notebook examines the possibility of **extrapolating the proportion of infected people in a given country or area**, by using testing data and fitting a model that predicts the probability of testing positive, given how much a country tests. This is achieved by fitting a model that predicts the ratio $\\frac{confirmed\\ cases}{samples\\ tested}$ as a function of $\\frac{deaths\\ at\\ d+4}{samples\\ tested}$, in the form of $f(x)=m\\times x^\\alpha$. Pearson **correlation coefficients ($R^2$) range from $0.92$ to $0.99$** depending on how much data is used to fit the model. This model estimates that, before April 20, **$14.48\\%$ of NYC** had been infected, **$5.70\\%$ of France** and **$7.78\\%$ of Italy**. The model's predictions are also **close underestimations of all available serological survey results**. The estimated death rates given by the model are within the range of expert estimates.\n","f2a56b3f":"# Introduction\n\nThe starting point is the publication by *Our World in Data* of **testing data** for several countries, and the fact that the proportion of tests that are positive decreases when the number of tests increases. The fact is that **even countries which test the most don't know what the true number of infected people is**. This is why I chose to examine the possibility of extrapolating the evolution of this proportion and extract its value *if the whole population was tested*.\n\nIn order to know if a country is *testing as much as another*, the absolute number of tests is not sufficient, as it needs to be treated relatively to Covid-19's penetration in the country. To assess the prevalence of the virus, I used the number of deaths at day $d+N$ as a proxy. The first part of this notebook is dedicated to find the best $N$ to choose by observing the time series of daily confirmed cases and daily deaths in different countries, and measuring the delay between peaks in countries like Italy or China.","749f2443":"#### The $R^2$ coefficient here is almost the same as previously but the value of $\\alpha$ is different from $\\frac{1}{2}$.\n\nIn order to use this model to predict the proportion of infected people, I use the predicted value while inputting the value of the $x$ ratio when the entire population is tested. This means replacing $n_{tests}$ by $n_{pop}$.\n\nOne needs to assume something about the undercount in the number of deaths, as that has a big impact on the result. Also, the prediction gives the proportion of *positives if the entire country had been tested exactly once*. To get the proportion of *infected*, we need an assumption on the efficiency of Covid-19 tests, precisely, the probability of being tested positive if infected (*test sensitivity*). One study suggests that this probability could be around $0.5$ for both mild and severe cases (Source: https:\/\/www.medrxiv.org\/content\/10.1101\/2020.02.11.20021493v2).","f072a0d8":"#### As you can see, this model fits relatively well, with a Pearson coefficient of $0.92$.\n\nIn order to generalize this heuristic and optimize a bit further, a model in the form of $$y=m\\times x^\\alpha$$ is adopted, with $\\alpha \\in ]0,1]$.","cea01589":"Some preprocessing and corrections are done to the dataset, to improve coherence and homogeneity.","0e9ae17b":"The following cell can be used to visualize results for any combination of countries.","4c63abaf":"## Comparison\/Validation\n\nAs of today, several **serological surveys** have been conducted, not always following the same sampling methodology nor using the same tests. I will be reporting these results in this section for validation purposes and comparing them with my model's estimations.\n\n**Reported results are:**\n\nSanta Clara - end of March: **1.80 to 5.70 %** according to https:\/\/www.medrxiv.org\/content\/10.1101\/2020.04.14.20062463v1.full.pdf (preprint)\n\nNetherlands - end of March: **3%** according to https:\/\/www.reddit.com\/r\/COVID19\/comments\/g2ec30\/3_of_dutch_blood_donors_have_covid19_antibodies\/ \n\nSweden (Stockholm area) - April 14: **11%** according to https:\/\/www.reddit.com\/r\/COVID19\/comments\/g4znbg\/at_least_11_of_tested_blood_donors_in_stockholm\/\n\nLos Angeles county - early April: **2.8% to 5.6%** accordint to http:\/\/publichealth.lacounty.gov\/phcommon\/public\/media\/mediapubhpdetail.cfm?prid=2328\n\nGeneva, Switzerland - April 17: **3,3% to 7,7%** according to https:\/\/www.hug-ge.ch\/medias\/communique-presse\/seroprevalence-covid-19-premiere-estimation\n\nGeneva, Switzerland - April 10: **1,6% to 5,4%%** according to https:\/\/www.hug-ge.ch\/medias\/communique-presse\/seroprevalence-covid-19-premiere-estimation\n\nNew York state - April 19-24: **13.9%** according to https:\/\/eu.usatoday.com\/story\/news\/nation\/2020\/04\/23\/coronavirus-new-york-millions-residents-may-have-been-infected-antibody-test\/3012920001\/\n\nNew York City - April 19-24: **21.2%** according to https:\/\/eu.usatoday.com\/story\/news\/nation\/2020\/04\/23\/coronavirus-new-york-millions-residents-may-have-been-infected-antibody-test\/3012920001\/","3355f2a3":"# Known issues\n\n* There is no prior justification for the use of a model in the form of $y = m\\times x^\\alpha$ and it is unclear wether the $R^2$ coefficients we get are a strong enough validation of the model.\n\n* There is some fair amount of variance in the dataset, which could be explained by inconsistencies in testing data, intrinsic differences in mortality between countries, differences of performance in tests used by different countries, or other factors.\n\n* The conclusions are very dependent on Covid-19's RT-PCR test sensitivity (How many infected people would have tested negative? There is a lack of evidence about this)","ee0e5216":"# Finding best number N of days for offset","31ce2406":"# Building a model","ef998777":"Comparing the evolution of daily confirmed cases and daily confirmed deaths, using a moving average of $6$ days, for different countries:","7a0963dc":"# Main Results","10b3fb85":"Although it is technically possible to compute estimations for the entire world, it is unclear how reliable such estimations are and how they should be interpreted."}}