{"cell_type":{"083970bb":"code","0f76857e":"code","f0fc052e":"code","12f3150c":"code","14dcd9cb":"code","68b4d608":"code","4451a6bd":"code","811dc955":"code","cf1a9f66":"code","5a1b7759":"code","01c2c2ce":"code","a1f84ba7":"code","7eb8210e":"code","d4929e4c":"code","aaa170b9":"code","e5fcf0fb":"code","0ed721fa":"code","a0d348ec":"code","adab779c":"code","298f123f":"code","3b664e40":"code","4a2130cc":"code","d05372b0":"code","926cc86d":"code","5333faa0":"code","c3c4b0bd":"code","7afbd461":"code","dc65e748":"code","1ee204db":"code","b6ff9254":"code","cf620db5":"markdown","842de4cf":"markdown","c9f596ea":"markdown","4d929d5a":"markdown","516632d9":"markdown","e476ffbc":"markdown","f69482b1":"markdown","9a1db04f":"markdown","528bb146":"markdown","5446e867":"markdown","300b0afb":"markdown","be31e2f0":"markdown","528df8f4":"markdown","79dbff96":"markdown","454d502f":"markdown","ced68e60":"markdown"},"source":{"083970bb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0f76857e":"df = pd.read_csv(\"\/kaggle\/input\/heart-failure-prediction\/heart.csv\")","f0fc052e":"df.info()","12f3150c":"df.isnull().sum()","14dcd9cb":"df.describe()","68b4d608":"duplicate = df[df.duplicated()]\nprint(\"Duplicate Rows : \")\nduplicate","4451a6bd":"import matplotlib.pyplot as plt\nimport seaborn as sns","811dc955":"for column in df.columns:\n    plt.figure(figsize=(30,5))\n    sns.histplot(df[column])\n    plt.show()","cf1a9f66":"sns.pairplot(df,hue='Sex')\nplt.show()","5a1b7759":"cor = df.corr()\nsns.heatmap(cor,annot=True)\nplt.show()","01c2c2ce":"sex_cat = pd.get_dummies(df['Sex'],drop_first = True)\ndf = pd.concat([df,sex_cat],axis = 1)\ndf.info()","a1f84ba7":"chest_pain = pd.get_dummies(df['ChestPainType'],drop_first = True)\ndf = pd.concat([df,chest_pain],axis = 1)\ndf.info()","7eb8210e":"ecg = pd.get_dummies(df['RestingECG'],drop_first = True)\ndf = pd.concat([df,ecg],axis = 1)\ndf.info()","d4929e4c":"angina = pd.get_dummies(df['ExerciseAngina'],drop_first = True)\ndf = pd.concat([df,angina],axis = 1)\ndf.info()","aaa170b9":"slope = pd.get_dummies(df['ST_Slope'],drop_first = True)\ndf = pd.concat([df,slope],axis = 1)\ndf.info()","e5fcf0fb":"new_df = df.drop(['Sex', 'ChestPainType','RestingECG','ExerciseAngina','ST_Slope'], axis=1)\nnew_df.info()","0ed721fa":"new_df.describe()","a0d348ec":"y = new_df['HeartDisease']\nX = new_df.drop(['HeartDisease'],axis = 1)","adab779c":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,stratify=y,random_state=42)","298f123f":"from sklearn.preprocessing import MinMaxScaler\nmm = MinMaxScaler()\nX_train_scaled = mm.fit_transform(X_train)\nX_test_scaled = mm.transform(X_test)","3b664e40":"from sklearn.metrics import classification_report","4a2130cc":"from sklearn.tree import DecisionTreeClassifier\ndtc = DecisionTreeClassifier()\ndtc.fit(X_train_scaled,y_train)\ny_pred = dtc.predict(X_test_scaled)\nprint(classification_report(y_test, y_pred, target_names=['0','1']))","d05372b0":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier()\nrfc.fit(X_train_scaled,y_train)\ny_pred = rfc.predict(X_test_scaled)\nprint(classification_report(y_test, y_pred, target_names=['0','1']))","926cc86d":"import xgboost as xgb\nxgb_clf = xgb.XGBClassifier()\nxgb_clf.fit(X_train_scaled,y_train)\ny_pred = xgb_clf.predict(X_test_scaled)\nprint(classification_report(y_test, y_pred, target_names=['0','1']))","5333faa0":"import lightgbm as lgb\nlgbm = lgb.LGBMClassifier()\nlgbm.fit(X_train_scaled, y_train)\ny_pred = lgbm.predict(X_test_scaled)\nprint(classification_report(y_test, y_pred, target_names=['0','1']))","c3c4b0bd":"from sklearn.model_selection import RandomizedSearchCV","7afbd461":"n_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 20)]\nmax_features = ['auto', 'sqrt']\nmax_depth = [int(x) for x in np.linspace(3, 110, num = 20)]\nmin_samples_split = [2, 5, 10]\nmin_samples_leaf = [1, 2, 4]\n\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf\n              }\n\nprint(random_grid)","dc65e748":"rf_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid, n_iter = 50, cv = 5, verbose=2, random_state=100, n_jobs = -1)","1ee204db":"rf_random.fit(X_train_scaled, y_train)","b6ff9254":"y_pred = rf_random.predict(X_test_scaled)\nprint(classification_report(y_test, y_pred, target_names=['0','1']))","cf620db5":"*XGBOOST:*","842de4cf":"*Random Forest Classifier:*","c9f596ea":"After converting all categorical variables to numeric columns, we are left with 15 columns for model building","4d929d5a":"Note: Hyperparameter tuning not included for all models in this notebook. In order to improve the performance of the models, hyperparameter tuning can be performed on all models. Since, without any tuning we got best value of accuracy with RandomForestClassifier, we will only tune that model:","516632d9":"# **Extracting data and gathering insights:**","e476ffbc":"We were able to achieve a slight increase in the accuracy.","f69482b1":"# **Model Building:**","9a1db04f":"We observe that some of the columns are integers while some are categorical which needs to be converted","528bb146":"We dont observe any major correlation between any variables. If major correlation found, we can use statsmodel library and find VIF values for dropping unnecessary columns.","5446e867":"No null values and duplicate rows found. If present handle accordingly.","300b0afb":"# **Hyperparameter Tuning : RFC (Random Forest Classifier)**","be31e2f0":"*LGBM:*","528df8f4":"*Decision Tree Classifier:*","79dbff96":"We dont find any apparent trends in the bivariate distribution above. But, it looks like majority of the patients who have a heart disease are males which validates our previous trend which states most of the patients are male.","454d502f":"# **Data preprocessing for model building:**","ced68e60":"Here, one important trend that we observe is that the number of female patients are far less compared to male patients."}}