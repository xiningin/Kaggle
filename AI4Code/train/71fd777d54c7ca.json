{"cell_type":{"d778d53e":"code","22f0d5ab":"code","352dec33":"code","93d30a7f":"code","f3c68592":"code","a1414444":"code","730d995f":"code","de34fc47":"code","9630132f":"code","dc72d318":"code","28d48b2d":"code","37890daf":"code","b5b90253":"code","485c6e64":"code","5e50abe9":"code","0c3ade8f":"code","3561583b":"code","f606514a":"code","c94ea716":"code","eba8f18f":"code","0c34e160":"code","c25c5ea1":"code","ebb38ab4":"code","434c5cf1":"code","e53c0d94":"code","7be72729":"code","18aca25f":"code","d5e55432":"markdown","c89a7caf":"markdown","812341aa":"markdown","5c0712e3":"markdown","3ebae681":"markdown","867ab165":"markdown","be64b80c":"markdown","34274390":"markdown","56261ee3":"markdown","0192e193":"markdown","077538fa":"markdown"},"source":{"d778d53e":"# Import all necessary Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","22f0d5ab":"#import Data:\ndf=pd.read_csv('..\/input\/sonaralldata\/sonar-all-data.csv')","352dec33":"#Data overview:\ndf.head()","93d30a7f":"df","f3c68592":"df.shape","a1414444":"df.info()","730d995f":"sns.countplot(data=df,x='Label')","de34fc47":"df['Label'].value_counts()","9630132f":"sns.scatterplot(data=df,x='Freq_57',y='Freq_58',hue='Label')\n","dc72d318":"sns.scatterplot(data=df,x='Freq_3',y='Freq_4',hue='Label')","28d48b2d":"#Determine the Features & Target Variable:\nX= df.drop('Label', axis=1)\ny= df['Label']","37890daf":"#Split the Data to Train & Test:\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","b5b90253":"#scaling the features:\nfrom sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()\nscaler.fit(X_train)\nscaled_X_train=scaler.transform(X_train)\nscaled_X_test=scaler.transform(X_test)\n","485c6e64":"#train the Model:\nfrom sklearn.neighbors import KNeighborsClassifier\nknn_model=KNeighborsClassifier(n_neighbors=3)\nknn_model.fit(scaled_X_train,y_train)\n","5e50abe9":"#Predicting Test Data:\ny_pred=knn_model.predict(scaled_X_test)\npd.DataFrame({'y_test':y_test,'y_pred':y_pred})","0c3ade8f":"#Evaluating the model:\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score\naccuracy_score(y_test,y_pred)","3561583b":"confusion_matrix(y_test,y_pred)","f606514a":"print(classification_report(y_test,y_pred))","c94ea716":"test_error_rate=[]\nfor k in range(1,30):\n    knn_model = KNeighborsClassifier(n_neighbors=k)\n    knn_model.fit(scaled_X_train, y_train)\n    \n    y_pred_test = knn_model.predict(scaled_X_test)\n    \n    test_error=1- accuracy_score(y_test, y_pred_test)\n    test_error_rate.append(test_error)","eba8f18f":"test_error_rate","0c34e160":"plt.figure(figsize=(10, 6))\nplt.plot(range(1, 30), test_error_rate, label='Test Error')\nplt.legend()\nplt.ylabel('Error Rate')\nplt.xlabel('K Value')","c25c5ea1":"plt.figure(figsize=(10, 6))\nplt.plot(range(1, 30), test_error_rate, label='Test Error')\nplt.legend()\nplt.ylabel('Error Rate')\nplt.xlabel('K Value')\nplt.xlim(0,5)","ebb38ab4":"scaler=StandardScaler()\nknn=KNeighborsClassifier()\nknn.get_params().keys()","434c5cf1":"operations=[('scaler',scaler),('knn',knn)]\nfrom sklearn.pipeline import Pipeline\npipe=Pipeline(operations)\nfrom sklearn.model_selection import GridSearchCV\nk_values=list(range(1,20))\nparam_grid={'knn__n_neighbors':k_values}\nfull_cv_classifier=GridSearchCV(pipe,param_grid,cv=5,scoring='accuracy')\nfull_cv_classifier.fit(X_train,y_train)\n","e53c0d94":"full_cv_classifier.best_estimator_.get_params()","7be72729":"scaler=StandardScaler()\nknn1=KNeighborsClassifier(n_neighbors=1)\noperations=[('scaler',scaler),('knn1',knn1)]\npipe=Pipeline(operations)\npipe.fit(X_train, y_train)\npipe_pred= pipe.predict(X_test)","18aca25f":"print(classification_report(y_test, pipe_pred))","d5e55432":"The plot shows n_neighbors=3 can improve the best model.","c89a7caf":"It is obvious that Precision improved well .","812341aa":"The distributon of data in label is approximatly balanced.","5c0712e3":"# Final Model:","3ebae681":"**Finding the most optimal 'n_neighbors' value for the model with Creating a Pipeline: **","867ab165":"**Finding the most optimal 'n_neighbors' value for the model with Elbow method:**","be64b80c":"so with this method the best 'n_neighbors' value is 1","34274390":"as we can see in there are some errors.","56261ee3":"the information shows there is not any missing data.","0192e193":"The features ara mixed up to each other ","077538fa":"# (The Sonar Data) \nSonar (sound navigation ranging) is a technique that uses sound propagation (usually underwater, as in submarine navigation) to navigate, communicate with or detect objects on or under the surface of the water, such as other vessels.\nThe data set contains the response metrics for 60 separate sonar frequencies sent out against a known mine field (and known rocks). These frequencies are then labeled with the known object they were beaming the sound at (either a rock or a mine.\nOur main goal is to create a machine learning model capable of detecting the difference between a rock or a mine based on the response of the 60 separate sonar frequencies. \nData Source: \nhttps:\/\/archive.ics.uci.edu\/ml\/datasets\/Connectionist+Bench+(Sonar,+Mines+vs.+Roc ks) "}}