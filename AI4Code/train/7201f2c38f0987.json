{"cell_type":{"f3f79151":"code","c546e9e1":"code","2a106e3e":"code","68adb105":"code","81b08a43":"code","68479884":"code","df7cc72f":"code","502c23f3":"code","5969c2d9":"code","09a7c2e7":"code","8ae9b8d7":"code","9ea52dd4":"markdown","23480748":"markdown","47a199f7":"markdown","c4d1ea9d":"markdown","2723c399":"markdown","a7d933b7":"markdown"},"source":{"f3f79151":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","c546e9e1":"from sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV, KFold\nfrom sklearn.metrics import mean_squared_error","2a106e3e":"data_dir = '\/kaggle\/input\/tabular-playground-series-jan-2021'\ntrain_path = os.path.join(data_dir, 'train.csv')\ntest_path = os.path.join(data_dir, 'test.csv')\nsam_sub_path = os.path.join(data_dir, 'sample_submission.csv')\n\ndf = pd.read_csv(train_path)\ntest_df = pd.read_csv(test_path)\nsam_sub_df = pd.read_csv(sam_sub_path)\n\n# remove target outliers from train\ndf.drop(df[df['target'] <= 5].index, axis=0, inplace=True)\n\ndf.head()","68adb105":"target = df['target'].values\ndata = df.drop(['target', 'id'], axis=1).values\nX_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=17, shuffle=False)","81b08a43":"def plot_feature_importance(tree_grid, n_cols=10):\n    f_imp = pd.DataFrame({'feature': list(df.drop(['target', 'id'], axis=1).columns),\n                          'importance': tree_grid.best_estimator_.feature_importances_}\n                         ).sort_values('importance', ascending=False).reset_index()\n    f_imp['importance_normalized'] = f_imp['importance'] \/ f_imp['importance'].sum()\n\n    ax = plt.subplot()\n    ax.barh(list(reversed(list(f_imp.index[:n_cols]))),\n            f_imp['importance_normalized'].head(n_cols),\n            align='center', edgecolor='k')\n    ax.set_yticks(list(reversed(list(f_imp.index[:n_cols]))))\n    ax.set_yticklabels(f_imp['feature'].head(n_cols))\n    plt.show()\n\n\ndef train_by_grid_search(train_set, test_set, model, params, cv, n_cols=10):\n    tree_grid = GridSearchCV(model, params, cv=cv, scoring='neg_mean_squared_error', n_jobs=-1, verbose=10)\n    tree_grid.fit(train_set, test_set)\n\n    return tree_grid.best_estimator_, tree_grid\n\n\ndef print_info(model, greed):\n    train_score = mean_squared_error(model.predict(X_train), y_train, squared=False)\n    test_score = mean_squared_error(model.predict(X_test), y_test, squared=False)\n    best_params = greed.best_params_\n    print(f'Train Score = {train_score}')\n    print(f'Test Score = {test_score}')\n    print(f'Best Params:', best_params)","68479884":"kf = KFold(n_splits=5, shuffle=True, random_state=17)\n\nparams = {\n    'max_depth': [None, 2, 3, 5, 7, 8, 10],\n    'n_estimators': [None, 15, 50, 100, 125, 150, 200],\n}\n\nmodel, greed = train_by_grid_search(\n    X_train, y_train,\n    model=RandomForestRegressor(random_state=17), params=params, cv=kf)","df7cc72f":"print_info(model, greed)","502c23f3":"plot_feature_importance(tree_grid=greed, n_cols=14)","5969c2d9":"result_model = RandomForestRegressor(**greed.best_params_).fit(data, target)","09a7c2e7":"print_info(result_model, greed)","8ae9b8d7":"test = test_df.drop('id', axis=1).values\nsubmission = pd.DataFrame(data={'id': test_df['id'], 'target': result_model.predict(test)})\n(sam_sub_df['id'] == submission['id']).all()\n\noutput_dir=''\nsubmission.to_csv(os.path.join(output_dir, 'submission.csv'), index=False)","9ea52dd4":"# Make Prediction and Save Submission","23480748":"# Training Final Model","47a199f7":"# Loading and Viewing Data","c4d1ea9d":"# Hyperparameter Optimization using GridSearchCV","2723c399":"# Training Tools","a7d933b7":"# Importing Libraries"}}