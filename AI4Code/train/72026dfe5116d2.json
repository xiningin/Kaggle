{"cell_type":{"74c930e7":"code","6567b9a3":"code","66d401f5":"code","9e658aa0":"code","bc53b4cd":"code","c73560ae":"code","4211a0a0":"code","723c4f0c":"code","57345ece":"code","6ebf88cc":"code","0c3147ee":"markdown","7a9b22a6":"markdown","0437e575":"markdown"},"source":{"74c930e7":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport lightgbm as lgb\nfrom sklearn.model_selection import KFold\nimport warnings\nimport gc\nimport time\nimport sys\nimport datetime","6567b9a3":"train = pd.read_csv('..\/input\/train.csv')","66d401f5":"head_name = train.columns.values.tolist()\ncateg_name = []\nfor i in head_name:\n    if train[i].value_counts().shape[0] <= 2:\n        categ_name.append(i)\n\ntrain_category = train[categ_name]\ntrain_category = train_category.dropna(how='any', axis=1)\nx_train = train_category.iloc[:,:9]\ny_train = train_category.iloc[:,9:10]","9e658aa0":"from sklearn.preprocessing import OneHotEncoder\nimport os\nimport numpy as np\nimport torch\nimport torchvision\nfrom torch import nn\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\n\n\noe = OneHotEncoder()\nx_train = oe.fit_transform(x_train).toarray()\ny_train = np.array(y_train)","bc53b4cd":"import torch.nn.functional as F \n\nclass NN(nn.Module):  \n    def __init__(self):\n        super(NN, self).__init__()\n        self.fc1 = nn.Linear(18, 10)\n        self.fc2 = nn.Linear(10, 4)\n        self.fc3 = nn.Linear(4, 1)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n    \n\nmodel = NN()\n#y_train = oe.fit_transform(y_train).toarray()\ntrain = torch.utils.data.TensorDataset(torch.from_numpy(x_train), torch.from_numpy(y_train))\ntrain_loader = torch.utils.data.DataLoader(train, batch_size=100, shuffle=True)","c73560ae":"criterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(),\n                             lr=0.001,\n                             weight_decay=1e-5)\n\nloss_list = []\nepoch_nums = 2\nfor epoch in range(epoch_nums):\n    for data in train_loader:\n        x, y = data\n        x =  Variable(x).float()\n        y =  Variable(y).float()\n        y_pred = model(x)\n        loss = criterion(y_pred, y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        loss_list.append(loss.item())\n    \n    print('epoch [{}\/{}], loss: {:.6f}'.format(\n        epoch + 1,\n        epoch_nums,\n        loss.item()))\n    \ntorch.save(model.state_dict(), 'weight_AE.pth')","4211a0a0":"x_train_torch = torch.from_numpy(x_train)\nx_train_torch = Variable(x_train_torch).float()","723c4f0c":"test = pd.read_csv('..\/input\/test.csv')\nhead_name = test.columns.values.tolist()\ncateg_name = []\nfor i in head_name:\n    if test[i].value_counts().shape[0] <= 2:\n        categ_name.append(i)\n\ntest_category = test[categ_name]\ntest_category = test_category.dropna(how='any', axis=1)\nx_test = test_category.iloc[:,:9]","57345ece":"oe = OneHotEncoder()\nx_test = oe.fit_transform(x_test).toarray()\nx_test = torch.from_numpy(x_test)\nx_test = Variable(x_test).float()\nprediction = model(x_test)\ncpu_pred = prediction.cpu()\ny_predict = cpu_pred.data.numpy()\ny_predict.shape","6ebf88cc":"sub_df = pd.DataFrame({\"MachineIdentifier\": test[\"MachineIdentifier\"].values})\nsub_df[\"HasDetections\"] = y_predict\nsub_df.to_csv(\"submit.csv\", index=False)","0c3147ee":"### data preprocess!\nit use only binary data and non deficit data in this kernel. The feature num is 18.","7a9b22a6":"one hot encode from label data","0437e575":"## Simple Neural network\nThis kernel is simple neural network used only columns that (0 or 1) labeling data.\nI used Pytorch!"}}