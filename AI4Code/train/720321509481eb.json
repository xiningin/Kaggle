{"cell_type":{"df75db91":"code","46974128":"code","e2bd0357":"code","8bb306f5":"code","78206ae1":"code","0d129705":"code","ab475726":"code","2eddd785":"code","1cfbe8f3":"code","13bb9d93":"code","91d25996":"code","9bd18240":"code","8cb4e991":"code","8e201a9e":"code","8b4e59c8":"code","6977ca06":"code","99a3b180":"code","77e3254d":"code","1a92ed98":"code","52f5181b":"code","aa3df514":"markdown"},"source":{"df75db91":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","46974128":"#reading the data... \ndata = pd.read_csv('..\/input\/digit-recognizer\/train.csv')","e2bd0357":"#printing the shape of data\ndata.shape","8bb306f5":"data.head()","78206ae1":"labels = data['label']\nfeatures = data.drop('label',axis =1)","0d129705":"features.shape","ab475726":"#importing library for standardizing the data...\n\nfrom sklearn.preprocessing import StandardScaler\nstandarized_data = StandardScaler().fit_transform(features)","2eddd785":"#finding the covariance matrix...\ncovar_mat = np.matmul(standarized_data.T,standarized_data)\n    \ncovar_mat.shape   ","1cfbe8f3":"#importing eigen_vectors \n\nfrom scipy.linalg import eigh \n\n\n#finding the top 2 eigen vectors ( as the data is arrannged in ascending we have to choose last 2. why 2? because we want to visualise the data.) \nvalues, vectors = eigh(covar_mat,eigvals = (782,783))\n ","13bb9d93":"print(vectors.shape) \n\n#as we know that the shape of X is 42000,784 we can't muliuplty it with above vectors. \n\nvectors = vectors.T\n\n#after changing shape we can multiply with vectors. ","91d25996":" new_variables = np.matmul(vectors,features.T)\n    \n new_variables.shape   ","9bd18240":"import pandas as pd\n\nnew_cordinates = np.vstack((new_variables,labels)).T\n\ndf = pd.DataFrame(data=new_cordinates,columns = ('p0','p1','labels'))","8cb4e991":"print(df.shape)\ndf.head()\n","8e201a9e":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.FacetGrid(df,hue='labels',size = 5).map(plt.scatter,'p0','p1').add_legend()\nplt.show()","8b4e59c8":"from sklearn import decomposition\npca = decomposition.PCA()","6977ca06":"pca.n_components = 2 \n\npca_data = pca.fit_transform(features)\n\nprint(pca_data.shape)","99a3b180":"pca_data = np.vstack((pca_data.T,labels)).T\n\nnew_df = pd.DataFrame(data = pca_data, columns = ['p0','p1','labels'])","77e3254d":"new_df","1a92ed98":"sns.FacetGrid(new_df,hue='labels',size =5).map(plt.scatter,'p0','p1').add_legend()\nplt.show()","52f5181b":"pca.n_components = 784\npca_data = pca.fit_transform(features)\npercentag_var_explained = pca.explained_variance_\/np.sum(pca.explained_variance_)\n\ncum_var_exp = np.cumsum(percentag_var_explained)\n\nplt.figure(1,figsize = (6,4))\n\nplt.clf()\nplt.plot(cum_var_exp,linewidth =2)\nplt.axis('tight')\nplt.grid\nplt.xlabel('n_components')\nplt.ylabel('Cum explained var')\nplt.show()\n\n\n#this graph shows how much variance is explained with number of compondents \n","aa3df514":"Using sklearn "}}