{"cell_type":{"2ccae09a":"code","93569397":"code","9d917300":"code","05e877c0":"code","5f0c1fdb":"code","f7ae28a3":"code","5ca511b8":"code","7f5a8677":"code","96cd32d5":"code","411dd4e9":"code","21ce2457":"code","1aa4365b":"code","29d7f33b":"code","737d24f5":"code","c819dbce":"code","ccd2d30e":"code","1c630bf4":"code","d3ebe5ea":"code","03fd38b5":"code","f2ee055c":"code","0320713d":"code","df75d54d":"code","1ae85fb0":"code","0613fd42":"code","362da48a":"code","ce3ec2ad":"code","561ea0ce":"code","aebf5aab":"code","9d7decb3":"code","049a63e2":"code","07e4b5ff":"code","8d91318b":"code","3d666b91":"code","f5783eeb":"code","4e767670":"code","632be794":"code","b76b8e7a":"code","7bca3e8d":"code","90c6deeb":"code","066c7200":"code","229254ff":"code","c84b0f5e":"code","0cc2554c":"code","286fc5a9":"code","27250f29":"code","6c67022c":"code","46485b85":"code","a2cdd043":"code","c4febc43":"code","47d23d25":"code","22f0352a":"markdown","6559a0f9":"markdown","26ae704b":"markdown","3eeb8bb9":"markdown","3dd7e278":"markdown","2cddd657":"markdown"},"source":{"2ccae09a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","93569397":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n\nprint(train_data.head())","9d917300":"length = train_data.shape[0]\nprint(train_data.isnull().sum())","05e877c0":"print(\"Percentage of data missing in Age: {}\".format((train_data[\"Age\"].isnull().sum()\/length)*100))\nprint(\"Percentage of data missing in Cabin: {}\".format((train_data[\"Cabin\"].isnull().sum()\/length)*100))","5f0c1fdb":"# Since more than 77% of data is missing Cabin is droped\n\ntrain_data.drop(\"Cabin\",axis = 1,inplace = True)\nprint(train_data.isnull().sum())","f7ae28a3":"# Since only 2 values of Embarked is missing it is filled with the maximum occuring value.\n\nprint(train_data[\"Embarked\"].value_counts())\ntrain_data[\"Embarked\"].fillna(\"S\",inplace = True)\nprint(train_data.isnull().sum())","5ca511b8":"# Seeing the Distribution of Age\n\nsns.histplot(x = train_data[\"Age\"],bins = 10)","7f5a8677":"train_data[train_data[\"Age\"].isna()]","96cd32d5":"split_name = train_data[\"Name\"].str.split(\", \",expand = True)\ntrain_data[\"Title\"] = split_name[1].str.split(\".\",expand = True)[0]\ntrain_data[\"Title\"].value_counts()","411dd4e9":"train_data.groupby([\"Title\"])[\"Age\"].describe()","21ce2457":"train_data[train_data[\"Age\"].isna()][\"Title\"].value_counts()","1aa4365b":"train_data.loc[(train_data[\"Age\"].isna()) & (train_data[\"Title\"] == \"Mr\"),\"Age\"]= train_data[train_data[\"Title\"] == \"Mr\"][\"Age\"].mean(skipna = True)\ntrain_data.loc[(train_data[\"Age\"].isna()) & (train_data[\"Title\"] == \"Miss\"),\"Age\"]= train_data[train_data[\"Title\"] == \"Miss\"][\"Age\"].mean(skipna = True)\ntrain_data.loc[(train_data[\"Age\"].isna()) & (train_data[\"Title\"] == \"Mrs\"),\"Age\"]= train_data[train_data[\"Title\"] == \"Mrs\"][\"Age\"].mean(skipna = True)\ntrain_data.loc[(train_data[\"Age\"].isna()) & (train_data[\"Title\"] == \"Master\"),\"Age\"]= train_data[train_data[\"Title\"] == \"Master\"][\"Age\"].mean(skipna = True)\ntrain_data.loc[(train_data[\"Age\"].isna()) & (train_data[\"Title\"] == \"Dr\"),\"Age\"]= train_data[train_data[\"Title\"] == \"Dr\"][\"Age\"].mean(skipna = True)","29d7f33b":"print(train_data.isnull().sum())","737d24f5":"# Dropping Columns that are not needed for model building\n\ntrain_data.drop([\"PassengerId\",\"Name\",\"Ticket\",\"Title\"],axis = 1,inplace = True)","c819dbce":"train_data.info()","ccd2d30e":"print(train_data[\"Sex\"].unique())\nprint(train_data[\"Embarked\"].unique())","1c630bf4":"# Encoding Sex and Embarked values\n\ntrain_data[\"Sex\"].replace({\"male\":0,\"female\":1},inplace = True)\ntrain_data[\"Embarked\"].replace({\"S\":0,\"C\":1,\"Q\":2},inplace = True)","d3ebe5ea":"train_data.info()","03fd38b5":"sns.heatmap(train_data.corr(),annot = True)","f2ee055c":"sns.countplot(x = \"Survived\",hue = \"Sex\",data = train_data)","0320713d":"sns.countplot(x = \"Survived\",hue = \"Pclass\",data = train_data)","df75d54d":"sns.countplot(x = \"Sex\",hue = \"Pclass\",data = train_data)","1ae85fb0":"sns.countplot(x = \"SibSp\",hue = \"Survived\",data = train_data)","0613fd42":"sns.countplot(x = \"Parch\",hue = \"Survived\",data = train_data)","362da48a":"sns.scatterplot(x = \"Age\",y = \"Fare\",hue = \"Survived\",data = train_data)","ce3ec2ad":"X = train_data.drop([\"Survived\",\"SibSp\",\"Parch\"],axis = 1)\ny = train_data[\"Survived\"]","561ea0ce":"# We shall use RandomForestClassifier\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split,cross_val_score\nfrom sklearn.metrics import accuracy_score,confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier","aebf5aab":"# Scaling Fare Column.\n\nscaler = MinMaxScaler()\nX[[\"Fare\"]] = scaler.fit_transform(X[[\"Fare\"]])\nX.head()","9d7decb3":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3)","049a63e2":"model = RandomForestClassifier()\nmodel.fit(X_train,y_train)","07e4b5ff":"score = cross_val_score(model,X_train,y_train,cv = 10)","8d91318b":"print(\"Cross Validation Score : {}\".format(np.mean(score) * 100))","3d666b91":"y_pred = model.predict(X_test)\nprint(\"Model Accuracy: {}\".format(accuracy_score(y_pred,y_test)))","f5783eeb":"print(confusion_matrix(y_test,y_pred))","4e767670":"print(test_data.isnull().sum())\nprint(test_data.shape)","632be794":"test_data.drop([\"Cabin\"],axis = 1,inplace = True)","b76b8e7a":"split_name = test_data[\"Name\"].str.split(\", \",expand = True)\ntest_data[\"Title\"] = split_name[1].str.split(\".\",expand = True)[0]\ntest_data[\"Title\"].value_counts()","7bca3e8d":"test_data.groupby([\"Title\"])[\"Age\"].describe()","90c6deeb":"test_data[test_data[\"Age\"].isna()][\"Title\"].value_counts()","066c7200":"test_data.loc[(test_data[\"Age\"].isna()) & (test_data[\"Title\"] == \"Mr\"),\"Age\"]= test_data[test_data[\"Title\"] == \"Mr\"][\"Age\"].mean(skipna = True)\ntest_data.loc[(test_data[\"Age\"].isna()) & (test_data[\"Title\"] == \"Miss\"),\"Age\"]= test_data[test_data[\"Title\"] == \"Miss\"][\"Age\"].mean(skipna = True)\ntest_data.loc[(test_data[\"Age\"].isna()) & (test_data[\"Title\"] == \"Mrs\"),\"Age\"]= test_data[test_data[\"Title\"] == \"Mrs\"][\"Age\"].mean(skipna = True)\ntest_data.loc[(test_data[\"Age\"].isna()) & (test_data[\"Title\"] == \"Master\"),\"Age\"]= test_data[test_data[\"Title\"] == \"Master\"][\"Age\"].mean(skipna = True)\ntest_data.loc[(test_data[\"Age\"].isna()) & (test_data[\"Title\"] == \"Ms\"),\"Age\"]= test_data[test_data[\"Title\"] == \"Miss\"][\"Age\"].mean(skipna = True)","229254ff":"test_data[test_data[\"Fare\"].isna()]","c84b0f5e":"test_data[\"Fare\"].fillna(test_data[test_data[\"Pclass\"] == 3][\"Fare\"].mean(),inplace = True)","0cc2554c":"print(test_data.isnull().sum())","286fc5a9":"gender_submission = pd.DataFrame(index = test_data[\"PassengerId\"])","27250f29":"t_data = test_data.drop([\"PassengerId\",\"Name\",\"SibSp\",\"Parch\",\"Ticket\",\"Title\"],axis = 1)","6c67022c":"t_data.head()","46485b85":"t_data[\"Sex\"].replace({\"male\":0,\"female\":1},inplace = True)\nt_data[\"Embarked\"].replace({\"S\":0,\"C\":1,\"Q\":2},inplace = True)","a2cdd043":"t_data[[\"Fare\"]] = scaler.fit_transform(t_data[[\"Fare\"]])\nt_data.head()","c4febc43":"gender_submission[\"Survived\"] = model.predict(t_data)","47d23d25":"gender_submission.to_csv(\"submission.csv\")","22f0352a":"# 3. Cleaning Test data and Predicting Value","6559a0f9":"# 1. Data Cleaning","26ae704b":"# 2. Data Analysis","3eeb8bb9":"*We can impute age based on the Title of the Name to get better results*","3dd7e278":"We are dropping SibSp and Parch since it has less impact on the Target column.","2cddd657":"The above Title has missing Age values.\nSo for each title the age is imputed with its mean"}}