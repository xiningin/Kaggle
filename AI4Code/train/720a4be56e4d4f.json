{"cell_type":{"a255892e":"code","c2df82e8":"code","ee1aea6c":"code","f0748510":"code","20d9265a":"code","83c0a38c":"code","82d88fe3":"code","5c924b1b":"code","569cbbbb":"code","6062cf99":"code","b7b340e4":"code","a1b4dd05":"code","320c214d":"code","d986dc76":"code","7e9d518b":"code","a90d4246":"code","5dde6fa3":"code","e40d69b5":"code","8dd48509":"code","c323bc06":"code","76df8944":"code","01fc7462":"code","f46a8cb9":"code","9b30b951":"code","077c81b4":"code","94457d7f":"code","e7cec08b":"code","8807e453":"code","2ffb61dc":"code","563b6a2f":"code","eac27d09":"code","4e0f02a5":"code","904a34ab":"code","12b7afb9":"code","39b53fd2":"code","15b62c6e":"code","70be5b11":"code","51c34dca":"code","943a6893":"code","5ba5f4d6":"code","25e2e16c":"code","c91942ae":"code","25c4277e":"code","81ddc0ae":"code","97823e4a":"code","abf8e1f3":"code","229e9034":"code","e2a41e21":"code","ee6cf385":"code","2346b6eb":"code","df3aa2f1":"code","b3ee6447":"code","2cb81f2e":"code","aa4f604a":"code","073a03d6":"code","e023bf87":"code","382491a6":"code","a0fd2c94":"code","1766097c":"code","1051dd51":"code","8f64e59e":"code","4d177888":"code","e1d31d50":"code","7bc24365":"code","3e7598bb":"code","d4eed816":"code","333f5588":"code","28144f68":"code","51a81a16":"code","32cf1c5a":"code","3d762b16":"code","f6747d44":"code","f2ff4222":"code","f55a510c":"code","a616f567":"code","2faa3b2e":"code","47711b58":"code","46f7678e":"code","7fcb885e":"code","ccd7abb0":"code","6a60333b":"code","491ba286":"code","6e497322":"code","02a4ddec":"code","da7755ea":"code","0890eae1":"code","3fd4e4f3":"code","e7ad6d07":"code","509007ea":"code","f450b333":"code","e92069cf":"code","23c06e86":"code","63f6da43":"markdown"},"source":{"a255892e":"%reset -f\n\nimport numpy as np\nimport pandas as pd\n\n# For plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns","c2df82e8":"# Class for applying multiple data transformation jobs\nfrom sklearn.compose import ColumnTransformer as ct\n# Scale numeric data\nfrom sklearn.preprocessing import StandardScaler as ss\n#  One hot encode data--Convert to dummy\nfrom sklearn.preprocessing import OneHotEncoder as ohe\n#  For clustering\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA","ee1aea6c":"# For modeling\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.tree import DecisionTreeClassifier","f0748510":"# For generating dataset\nfrom sklearn.datasets import make_hastie_10_2\n\n# For performance measures\nfrom sklearn.metrics import accuracy_score\n# From sklearn.metrics import\nfrom sklearn.metrics import auc, roc_curve\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_recall_fscore_support\n\n# For data splitting\nfrom sklearn.model_selection import train_test_split","20d9265a":"import os","83c0a38c":"#os.chdir(\"C:\\Imp_Docs\\Machine Learning\\Exercises\\Exercise - 4\")","82d88fe3":"df = pd.read_csv(\"..\/input\/data.csv\")","5c924b1b":"df.shape","569cbbbb":"df.head()","6062cf99":"df.tail()","b7b340e4":"df.info()","a1b4dd05":"df.describe()","320c214d":"# Plotting the Countplot graph\n\nsns.countplot(x='diagnosis',data=df)","d986dc76":"# Plotting the Jointplot graph\n\nsns.jointplot(x='radius_mean',y='perimeter_mean',data=df)","7e9d518b":"# Checking if there are any Null values\ndf.isnull().values.any()\ndf.isnull().sum()","a90d4246":"# Dropping columns \"ID\" and \"Unnamed: 32\"\n \ndf.drop(['id', 'Unnamed: 32'], axis=1, inplace=True)","5dde6fa3":"df.columns","e40d69b5":"# Assigning values 1 and 0 to \"M\" and \"B\"\n\ndf.diagnosis[df.diagnosis == 'M'] = 1\ndf.diagnosis[df.diagnosis == 'B'] = 0","8dd48509":"print(df)","c323bc06":"y = df['diagnosis']\ny=y.astype('int')","76df8944":"y","01fc7462":"# Plotting the Boxplot Graph\n\nfig = plt.figure(figsize=(12,8))\nax1 = fig.add_subplot(1,4,1)\nax1.set_xticklabels(labels = 'Radius mean', rotation=90)\n\nsns.boxenplot(x='diagnosis',y='radius_mean',data=df)\nax1 = fig.add_subplot(1,4,2)\nsns.boxenplot(x='diagnosis',y='texture_mean',data=df)\nax1 = fig.add_subplot(1,4,3)\nsns.boxenplot(x='diagnosis',y='perimeter_mean',data=df)\nax1 = fig.add_subplot(1,4,4)\nsns.boxenplot(x='diagnosis',y='area_mean',data=df)","f46a8cb9":"fig2 = plt.figure(figsize=(12,12))\nax2 = fig2.add_subplot(1,4,1)\nsns.boxenplot(x='diagnosis',y='smoothness_mean',data=df)\nax2 = fig2.add_subplot(1,4,2)\nsns.boxenplot(x='diagnosis',y='compactness_mean',data=df)\nax2 = fig2.add_subplot(1,4,3)\nsns.boxenplot(x='diagnosis',y='concavity_mean',data=df)\nax2 = fig2.add_subplot(1,4,4)\nsns.boxenplot(x='diagnosis',y='concave points_mean',data=df)","9b30b951":"# Selecting the Columns \nX = df.loc[:, 'radius_mean' : 'fractal_dimension_worst']","077c81b4":"X.isnull().sum()","94457d7f":"X.head()","e7cec08b":"X.shape","8807e453":"# Scale the Numeric data\n\nscaleit = ss()\ns=scaleit.fit_transform(df.loc[:, 'radius_mean' : 'fractal_dimension_worst'])\ns=scaleit.fit_transform(X)","2ffb61dc":"pca = PCA()\nprincipleComp = pca.fit_transform(X)","563b6a2f":"principleComp.shape","eac27d09":"pca.explained_variance_ratio_","4e0f02a5":"X = pca.explained_variance_ratio_.cumsum()","904a34ab":"X","12b7afb9":"# Plotting the Distplot graph\nsns.distplot(X,bins=5)","39b53fd2":"X = principleComp[:,0:11]","15b62c6e":"# Splitting and Shuffling the Data\nX_train, X_test, y_train, y_test = train_test_split(X,\n                                                    y,\n                                                    test_size = 0.2,\n                                                    shuffle = True\n                                                    )","70be5b11":"X_train.shape","51c34dca":"X_test.shape","943a6893":"y_train[:4]","5ba5f4d6":"X_test","25e2e16c":"y_train","c91942ae":"y_test","25c4277e":"# Instantiate the Classifiers\ndt = DecisionTreeClassifier()\nrf = RandomForestClassifier(n_estimators=5)\net = ExtraTreesClassifier(n_estimators=10)\nxgb = XGBClassifier(learning_rate=0.5,\n                   reg_alpha= 5,\n                   reg_lambda= 0.1)\ngbm = GradientBoostingClassifier()\nkn = KNeighborsClassifier(n_neighbors=10)","81ddc0ae":"# Train the data\ndt1 = dt.fit(X_train,y_train)\nrf1 = rf.fit(X_train,y_train)\net1 = et.fit(X_train,y_train)\nxgb1 = xgb.fit(X_train,y_train)\ngbm1 = gbm.fit(X_train,y_train)\nkn1 = kn.fit(X_train,y_train)","97823e4a":"# Data Predictions\ny_pred_dt = dt1.predict(X_test)\ny_pred_rf = rf1.predict(X_test)\ny_pred_et = et1.predict(X_test)\ny_pred_xgb= xgb1.predict(X_test)\ny_pred_gbm = gbm1.predict(X_test)\ny_pred_kn = kn1.predict(X_test)","abf8e1f3":"y_pred_dt_prob = dt1.predict_proba(X_test)","229e9034":"y_pred_rf_prob = rf1.predict_proba(X_test)\ny_pred_et_prob = et1.predict_proba(X_test)\ny_pred_xgb_prob = xgb1.predict_proba(X_test)\ny_pred_gbm_prob= gbm1.predict_proba(X_test)\ny_pred_kn_prob = kn1.predict_proba(X_test)","e2a41e21":"y_pred_dt_prob","ee6cf385":"y_pred_rf_prob","2346b6eb":"y_pred_et_prob","df3aa2f1":"y_pred_xgb_prob","b3ee6447":"y_pred_gbm_prob","2cb81f2e":"y_pred_kn_prob","aa4f604a":"# Calculate accuracy\naccuracy_score(y_test,y_pred_dt)","073a03d6":"accuracy_score(y_test,y_pred_rf)","e023bf87":"accuracy_score(y_test,y_pred_et)","382491a6":"accuracy_score(y_test,y_pred_xgb)","a0fd2c94":"accuracy_score(y_test,y_pred_gbm)","1766097c":"accuracy_score(y_test,y_pred_kn)","1051dd51":"# Draw Confusion matrix\n\nconfusion_matrix(y_test,y_pred_dt)","8f64e59e":"confusion_matrix(y_test,y_pred_rf)","4d177888":"confusion_matrix(y_test,y_pred_et)","e1d31d50":"confusion_matrix(y_test,y_pred_xgb)","7bc24365":"confusion_matrix(y_test,y_pred_gbm)","3e7598bb":"confusion_matrix(y_test,y_pred_kn)","d4eed816":"tn,fp,fn,tp= confusion_matrix(y_test,y_pred_dt).flatten()","333f5588":"# ROC graph\nfpr_dt, tpr_dt, thresholds = roc_curve(y_test,\n                                 y_pred_dt_prob[: , 1],\n                                 pos_label= 1\n                                 )","28144f68":"fpr_rf, tpr_rf, thresholds = roc_curve(y_test,\n                                 y_pred_rf_prob[: , 1],\n                                 pos_label= 1\n                                 )","51a81a16":"fpr_et, tpr_et, thresholds = roc_curve(y_test,\n                                 y_pred_et_prob[: , 1],\n                                 pos_label= 1\n                                 )","32cf1c5a":"fpr_xgb, tpr_xgb, thresholds = roc_curve(y_test,\n                                 y_pred_xgb_prob[: , 1],\n                                 pos_label= 1\n                                 )","3d762b16":"fpr_gbm, tpr_gbm,thresholds = roc_curve(y_test,\n                                 y_pred_gbm_prob[: , 1],\n                                 pos_label= 1\n                                 )","f6747d44":"fpr_kn, tpr_kn, thresholds = roc_curve(y_test,\n                                 y_pred_kn_prob[: , 1],\n                                 pos_label= 1\n                                 )","f2ff4222":"fpr_dt","f55a510c":"tpr_dt","a616f567":"fpr_rf","2faa3b2e":"tpr_rf","47711b58":"fpr_et","46f7678e":"tpr_et","7fcb885e":"fpr_xgb","ccd7abb0":"tpr_xgb","6a60333b":"fpr_gbm","491ba286":"tpr_gbm","6e497322":"fpr_kn","02a4ddec":"tpr_kn","da7755ea":"# Get AUC values\n\nauc(fpr_dt,tpr_dt)","0890eae1":"auc(fpr_rf,tpr_rf)","3fd4e4f3":"auc(fpr_et,tpr_et)","e7ad6d07":"auc(fpr_gbm,tpr_gbm)","509007ea":"auc(fpr_xgb,tpr_xgb)","f450b333":"auc(fpr_kn,tpr_kn)","e92069cf":"# Plot the ROC curve\n\nfig = plt.figure(figsize=(12,10))          # Create window frame\nax = fig.add_subplot(111)   # Create axes\n\n# Also connect diagonals\nax.plot([0, 0], [1, 1], ls=\"--\")   # Dashed diagonal line\n# 9.3 Labels etc\nax.set_xlabel('False Positive Rate')  # Final plot decorations\nax.set_ylabel('True Positive Rate')\nax.set_title('ROC curve for models')\n# 9.4 Set graph limits\nax.set_xlim([0.0, 1.0])\nax.set_ylim([0.0, 1.0])\n\nax.plot(fpr_dt, tpr_dt, label = \"Decision Tree\")\nax.plot(fpr_rf, tpr_rf, label = \"Random Forest\")\nax.plot(fpr_et, tpr_et, label = \"Extra Trees\")\nax.plot(fpr_xgb, tpr_xgb, label = \"XGBoost\")\nax.plot(fpr_gbm, tpr_gbm, label = \"Gradient Boosting\")\nax.plot(fpr_kn, tpr_kn, label = \"KNeighbors\")\n\n# 9.6 Set legend and show plot\nax.legend(loc=\"lower right\")\nplt.show()","23c06e86":"# For AUC Graph\n\nmodels = [(dt, \"DecisionTree\"), (rf, \"RandomForest\"), (et, \"ExtraTrees\"), (gbm, \"GradientBoost\"),(xgb,\"XGBoost\"), (kn, \"KNeighbors\")]\n#  Plot the ROC curve\nfig = plt.figure(figsize=(12,10))          # Create window frame\nax = fig.add_subplot(111)   # Create axes\n# Also connect diagonals\nax.plot([0, 1], [0, 1], ls=\"--\")   # Dashed diagonal line\n#  Labels etc\nax.set_xlabel('False Positive Rate')  # Final plot decorations\nax.set_ylabel('True Positive Rate')\nax.set_title('ROC curve for models')\n\nax.set_xlim([0.0, 1.0])\nax.set_ylim([0.0, 1.0])\nAUC = []\nfor clf,name in models:\n    clf.fit(X_train,y_train)\n    y_pred_prob = clf.predict_proba(X_test)\n    fpr, tpr, thresholds = roc_curve(y_test,\n                                     y_pred_prob[: , 1],\n                                     pos_label= 1\n                                     )\n    AUC.append((auc(fpr,tpr)))\n    ax.plot(fpr, tpr, label = name)           # Plot on the axes\n\nax.legend(loc=\"lower right\")\nplt.show()","63f6da43":"Get probability values"}}