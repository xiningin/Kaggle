{"cell_type":{"c9d204d3":"code","9f1f43ba":"code","5250d325":"code","a7f6a120":"code","6e6495b1":"code","283db0b9":"code","a003986c":"code","83b6d732":"code","f6260074":"code","078eb0a9":"code","6fe7788e":"code","06b780c5":"code","b553c35c":"code","0e26aacc":"code","c9f97bb5":"code","0b0626c4":"code","4738c90a":"code","fa4ab19d":"code","7211d082":"code","522c04b1":"code","9cc2dfab":"code","2d3b85d3":"code","66c62728":"code","bb058d8c":"code","95359927":"code","a9fdc12a":"code","fb63c1f6":"code","e10e148a":"code","8b631c02":"code","a189c9bf":"code","e8f58242":"code","e94d3ea1":"code","03e0fe16":"code","ab0fd83c":"code","a25df6c8":"code","1aa89e45":"code","25122c7d":"code","a0a7fbe3":"code","e988e1ef":"code","509f1b9d":"code","a0816041":"code","7f83a1cc":"code","b59b2862":"code","793ccb62":"code","b27a6f04":"code","0dca7faf":"code","bc1eeeff":"code","9afb64bb":"code","533e58c9":"code","4dcce566":"code","aa83d4fc":"code","30388e6e":"code","e1718ff4":"code","379b1e02":"code","17b0798b":"code","bf6da23b":"code","17de08b2":"code","5bf48995":"code","05a90e43":"code","14246419":"code","a0a4496a":"code","d59b9407":"code","047d0b53":"code","312fbd0b":"code","f2bed99d":"code","655ea9ab":"code","0bbc4523":"code","bcda2aa8":"code","2787dbb7":"code","92f8a519":"code","b6f8eb17":"code","69dfba57":"code","ca2eea3e":"code","5e68afaf":"code","da93bb83":"code","0cb56659":"code","a5da191b":"code","7b4f319d":"code","19b61380":"code","86fcb4a3":"code","21860090":"code","1283e485":"code","f282f8ac":"code","c3f3affa":"code","45f73443":"code","f14206bf":"code","95376722":"code","fee6f1e9":"code","c75013d9":"code","d692c069":"code","cc5896e7":"code","3dae81bf":"code","86bcf21d":"code","7f3a3c78":"code","c9599f91":"code","54b6c221":"code","dc6ddeac":"code","05586df6":"code","30f4dbf6":"code","32340a0e":"code","1ce9c396":"code","a57cf884":"code","c1d65b9b":"code","7b3cae32":"code","e9e5947d":"code","25968844":"code","aedc797d":"code","bf7d0ea9":"code","dc9b26de":"code","a41b1dc1":"code","f0e69520":"code","99eec3a7":"code","b3cbb788":"code","39b9fa7a":"code","e378b83f":"code","56ad6130":"code","13f2f668":"code","c65bd776":"code","e2575236":"code","616cccf8":"code","9e4cdfd1":"code","513bcaca":"code","03b92efe":"code","f91df5b3":"code","fbd61cff":"code","b6253a32":"code","6385ea60":"code","29b2075b":"code","2ea301ad":"code","1c6fe8a2":"code","d5ff9eef":"code","61cb1dc7":"markdown","9ee49b9b":"markdown","f2696b1a":"markdown","8b238ee1":"markdown","b23467fe":"markdown","b03ed23e":"markdown","7a18d796":"markdown","3091b4f2":"markdown","d8655a36":"markdown","4632e881":"markdown","65218b62":"markdown","3bec3142":"markdown","d00ebf32":"markdown","bfa677e4":"markdown","8933f0d1":"markdown","4ebf247c":"markdown","fbd3f48d":"markdown","37ac8d16":"markdown","cc5af446":"markdown","30d8c904":"markdown","e9e87a71":"markdown","a315954d":"markdown","d706f77a":"markdown","0116fd98":"markdown","d3b91717":"markdown","6ec418ec":"markdown","998759ae":"markdown","987ae85c":"markdown"},"source":{"c9d204d3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9f1f43ba":"sub_data = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')\nsub_data.head()","5250d325":"train_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntrain_data.head()","a7f6a120":"test_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest_data.head()","6e6495b1":"print(train_data.shape)\nprint(test_data.shape)","283db0b9":"train_data.describe()","a003986c":"train_data.describe(include='all')","83b6d732":"train_data.info()","f6260074":"train_data.drop_duplicates(keep='first',inplace=True)\ntrain_data.shape","078eb0a9":"import matplotlib.pyplot as plt\ntrain_data['Survived'].value_counts().plot(kind=\"bar\")","6fe7788e":"train_survived = train_data['Survived'].value_counts()\nnot_surv = (train_survived[0]\/(train_survived[1]+train_survived[0]))*100\nprint('Not survived %: ',\"{:.2f}\".format(not_surv))\nprint('Survived %: ',\"{:.2f}\".format(100-not_surv))","06b780c5":"import matplotlib.pyplot as plt\nplt.figure()\ntrain_data.plot(subplots=True,figsize=(10,8))\nplt.legend(loc='best')","b553c35c":"#Box plot\nbp = train_data.boxplot()","0e26aacc":"train_data.columns.values","c9f97bb5":"#plot each column against target column\ntrain_data.plot(subplots=True,x ='Survived',y=['Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],kind='bar',figsize=(10,8))\nplt.show()","0b0626c4":"train_data['Age'].plot(kind=\"hist\")","4738c90a":"train_data[['Age']].plot(kind='hist',bins=[0,20,40,60,80,100],rwidth=0.8)","fa4ab19d":"train_data['Survived'].plot(kind=\"hist\")","7211d082":"train_data['Pclass'].plot(kind=\"hist\")","522c04b1":"train_data.Sex.astype('category').cat.codes.plot(kind=\"hist\")","9cc2dfab":"train_data['Fare'].plot(kind=\"hist\")","2d3b85d3":"train_data['Survived'][train_data['Fare']>100].plot(kind=\"hist\")","66c62728":"train_data[train_data['Fare']>100].shape\n#train_data.columns.values","bb058d8c":"train_data['Survived'][train_data['Pclass']<3].plot(kind=\"hist\")","95359927":"train_data['Survived'][train_data['Sex'] == 'female'].plot(kind=\"hist\")","a9fdc12a":"train_data['Survived'][train_data['Sex']=='male'].plot(kind=\"hist\")","fb63c1f6":"train_data['PassengerId'][train_data['Age']>20][train_data['Age']<55].count()","e10e148a":"train_data['Survived'][train_data['Age']>20][train_data['Age'] < 55].plot(kind=\"hist\")","8b631c02":"import seaborn as sns\ncorr_matrix = train_data.corr()\nsns.heatmap(corr_matrix, annot=True)","a189c9bf":"train_data['SibSp'].plot(kind=\"hist\")","e8f58242":"train_data['Parch'].plot(kind=\"hist\")","e94d3ea1":"train_data['Ticket'].astype('category').cat.codes.plot(kind=\"hist\")","03e0fe16":"train_data.Embarked.astype('category').cat.codes.plot(kind=\"hist\")\n#train_data.Embarked.plot(kind=\"hist\")\nplt.show()","ab0fd83c":"plt.plot(train_data[\"Age\"],train_data[\"Survived\"])","a25df6c8":"train_data['Cabin'].isnull().sum()","1aa89e45":"#check if column is unique\nprint(train_data['PassengerId'].is_unique)\n#List unique values\n#train_data.PassengerId.unique()\n#train_data.var()","25122c7d":"#Dropping to be done in test data as well\ntrain_df = train_data.copy()\ntrain_df.drop(columns=['PassengerId','Cabin','Name'],inplace=True)\ntrain_df.head()","a0a7fbe3":"#Dropping columns in test data\ntest_df = test_data.copy()\ntest_df.drop(columns=['PassengerId','Cabin','Name'],inplace=True)\ntest_df.head()","e988e1ef":"test_df.isnull().sum()","509f1b9d":"# Check for Null values\ntrain_df.isnull().sum()","a0816041":"x_df = train_df.iloc[:,1:11]\ny_df = train_df.iloc[:,0:1]\nx_df.head(10)\nprint(type(x_df))","7f83a1cc":"from sklearn.model_selection import train_test_split\nx_train,x_val,y_train,y_val = train_test_split(x_df,y_df,test_size=.20,random_state=1,stratify=y_df)\nx_train.head()","b59b2862":"#x_train_df[['Age']]\n# x_train_df[['Age']]=x_train_df[['Age']].replace(np.nan,0)\n# x_train_df[['Embarked']]=x_train_df[['Embarked']].replace(np.nan,'')\n# print(x_train_df)\nprint(x_train.isnull().sum())","793ccb62":"x_val.isnull().sum()","b27a6f04":"x_train['Embarked'].unique()","0dca7faf":"type(x_train[[\"Age\"]].values)","bc1eeeff":"x_train.sample(3)","9afb64bb":"x_train['Age'].values","533e58c9":"# Impute missing values for x_train\nfrom sklearn.impute import SimpleImputer\nvalues_age = x_train['Age'].values.reshape(-1,1)\n#print(values_age)\nnum_imputer = SimpleImputer(missing_values=np.nan,strategy='mean')\nx_train[['Age']] =  num_imputer.fit_transform(values_age)\nvalues_embarked = x_train[['Embarked']].values\nalpha_imputer = SimpleImputer(missing_values=np.nan,strategy='most_frequent')\nx_train[['Embarked']] = alpha_imputer.fit_transform(values_embarked)\nx_train.head()","4dcce566":"x_train.isnull().sum()","aa83d4fc":"print(x_val.isnull().sum())","30388e6e":"type(x_val.Pclass)","e1718ff4":"def imputer_null(df):\n#     age=df['Age'].values.reshape(-1,1)\n#     df[['Age']]=num_imputer.transform(age)\n#     embarked = df['Embarked'].values.reshape(-1,1)\n#     df[['Embarked']]=alpha_imputer.transform(embarked)\n    for cols in df.columns.values:\n        if df[cols].values.dtype=='object':\n            df[[cols]]=alpha_imputer.transform(df[cols].values.reshape(-1,1))\n        else:\n            df[[cols]]=num_imputer.transform(df[cols].values.reshape(-1,1))\n    return df","379b1e02":"x_val = imputer_null(x_val)\nprint(x_val.isnull().sum())","17b0798b":"x_train.head()","bf6da23b":"x_train.shape","17de08b2":"x_train_df = x_train.copy()\nx_train_df.shape","5bf48995":"#x_train = x_train_df.copy()","05a90e43":"x_train.tail()","14246419":"x_train.reset_index(drop=True,inplace=True)\nx_train\nx_val.reset_index(drop=True,inplace=True)\nx_val","a0a4496a":"y_train.reset_index(drop=True,inplace=True)\ny_train\ny_val.reset_index(drop=True,inplace=True)","d59b9407":"x_train['Ticket'].values","047d0b53":"x_train.head()","312fbd0b":"ticket_new = x_train['Ticket'].str.split(\" \",n=1,expand=True)\nprint(ticket_new)\nprint(type(ticket_new))\nprint(x_train.head())","f2bed99d":"\nx_train_new = pd.concat([x_train,ticket_new],axis=1).drop(['Ticket'],axis=1)\nx_train_new\n","655ea9ab":"x_train_new.rename(columns={0:\"Ticket_ind\",1:\"Ticket_no\"},inplace=True)\nx_train=x_train_new.copy()\nx_train.head()","0bbc4523":"x_train['Ticket_ind'].values","bcda2aa8":"x_train['Ticket_no'].values\nx_train.drop(columns=['Ticket_no'],axis=1,inplace=True)\nx_train.head()","2787dbb7":"x_num = x_train[x_train['Ticket_ind'].str.isnumeric()]\nx_num","92f8a519":"x_alpha = x_train[x_train['Ticket_ind'].str.isalpha()]\nx_alpha.head(30)","b6f8eb17":"## Visualizing the relationship between Ticket and Pclass\nimport seaborn as sns\nsns.relplot(x=\"Pclass\",y=\"Ticket_ind\",data=x_alpha)","69dfba57":"corr=x_alpha.corr()\nsns.heatmap(corr,annot=True)","ca2eea3e":"#Drop ticket_ind\nx_train.drop(columns=['Ticket_ind'],axis=1,inplace=True)","5e68afaf":"x_val.drop(columns=['Ticket'],axis=1,inplace=True)","da93bb83":"# Encode Columns- Sex, Embarked; \n#Method1\nfrom sklearn.preprocessing import OneHotEncoder\none_enc = OneHotEncoder(handle_unknown='ignore')\ndf_new=pd.DataFrame()\ncol_names={}\nto_be_enc_cols = ['Pclass','Sex','Embarked']\nfor column_ind in range(len(to_be_enc_cols)):\n    #one_hot_enc = one_enc.fit_transform(np.array(x_train[to_be_enc_cols[column_ind]]).reshape(-1,1)).toarray() \n    one_hot_enc = one_enc.fit_transform(np.array(x_train[to_be_enc_cols[column_ind]]).reshape(-1,1)).toarray()\n    col_names[to_be_enc_cols[column_ind]] = one_enc.get_feature_names([to_be_enc_cols[column_ind]])\n    df = pd.DataFrame(one_hot_enc,columns=col_names[to_be_enc_cols[column_ind]])\n    df_new = pd.concat([df,df_new], axis = 1)\n    #print(df_new)\nx_train = pd.concat([x_train,df_new], axis = 1).drop(['Pclass','Sex','Embarked'],axis=1)\nprint(x_train)\n#x_train_new.drop(['Pclass','Sex','Embarked'],axis=1,inplace=True)\n# print(x_train_new.tail())","0cb56659":"def one_hot(df):\n    df2=pd.DataFrame()\n    col_names={}\n    to_be_enc_cols = ['Pclass','Sex','Embarked']\n    for column_ind in range(len(to_be_enc_cols)):\n        #one_hot_enc = one_enc.fit_transform(np.array(x_train[to_be_enc_cols[column_ind]]).reshape(-1,1)).toarray() \n        one_hot_enc = one_enc.fit_transform(np.array(df[to_be_enc_cols[column_ind]]).reshape(-1,1)).toarray()\n        col_names[to_be_enc_cols[column_ind]] = one_enc.get_feature_names([to_be_enc_cols[column_ind]])\n        df1 = pd.DataFrame(one_hot_enc,columns=col_names[to_be_enc_cols[column_ind]])\n        df2 = pd.concat([df1,df2], axis = 1)\n        #print(df_new)\n    one_hot_df = pd.concat([df,df2], axis = 1).drop(['Pclass','Sex','Embarked'],axis=1)\n    return one_hot_df","a5da191b":"#from sklearn.preprocessing import LabelEncoder\n#le = LabelEncoder()\n#print(one_hot_enc)\n# sex_label_encoded=le.fit_transform(x_train_df['Sex'])\n# emb_label_encoded=le.fit_transform(x_train_df['Embarked'])\n# print(sex_label_encoded.shape)\n#Apply onehot encoding\n# enc=OneHotEncoder(handle_unknown='ignore')\n# sex_encoded = sex_label_encoded.reshape(-1,1)\n# emb_encoded = emb_label_encoded.reshape(-1,1)\n# sex_one_hot_enc=enc.fit_transform(sex_encoded).toarray()\n# emb_one_hot_enc=enc.fit_transform(emb_encoded).toarray()\n# print(sex_one_hot_enc)","7b4f319d":"#Apply onehot encoding\n# from sklearn.preprocessing import OneHotEncoder\n# enc=OneHotEncoder(handle_unknown='ignore')\n# age_encoded = x_train_df['Age'].values.reshape(-1,1)\n# emb_encoded = x_train_df['Embarked'].values.reshape(-1,1)\n# x_train_df['Sex']=enc.fit_transform(age_encoded)\n# x_train_df['Embarked']=enc.fit_transform(emb_encoded)\n# x_train_df.head()","19b61380":"#Method2\n#One hot encoding with keras\n# from keras.utils import to_categorical\n# from sklearn.preprocessing import LabelEncoder\n\n# le = LabelEncoder()\n# sex_label_encoded=le.fit_transform(x_train_df['Sex'])\n# emb_label_encoded=le.fit_transform(x_train_df['Embarked'])\n# print(sex_label_encoded.shape)\n# keras_sex_encoded = to_categorical(sex_label_encoded)\n# keras_emb_encoded = to_categorical(emb_label_encoded)\n# print(keras_sex_encoded)","86fcb4a3":"x_val = one_hot(x_val)\nx_val","21860090":"def add_family_feature(df):\n    df['Family'] = df['SibSp']+df['Parch']\n    df.drop(['SibSp','Parch'],axis=1,inplace=True)\n    return df","1283e485":"x_train = add_family_feature(x_train)\nx_val = add_family_feature(x_val)\nx_val.head()","f282f8ac":"x_train.var(axis=0)","c3f3affa":"x_train.sample(8)","45f73443":"from sklearn.preprocessing import MinMaxScaler\nnormalize = MinMaxScaler()\nnormalize_col = ['Age','Fare']\ndf_new = pd.DataFrame()\nfor cols in normalize_col:\n    x_train_scaled =  normalize.fit_transform(np.array(x_train[cols]).reshape(-1,1))\n    df_scaled = pd.DataFrame(x_train_scaled,columns=[cols+'_new'])\n    df_new = pd.concat([df_new,df_scaled],axis=1)\n    print(df_new)\nx_train = pd.concat([x_train,df_new],axis=1)\nx_train.drop(columns=['Age','Fare'],axis=1,inplace=True)\nx_train.head()","f14206bf":"def normalize_feature(df):\n    normalize_col = ['Age','Fare']\n    df_new = pd.DataFrame()\n    for cols in normalize_col:\n        x_scaled =  normalize.fit_transform(np.array(df[cols]).reshape(-1,1))\n        df_scaled = pd.DataFrame(x_scaled,columns=[cols+'_new'])\n        df_new = pd.concat([df_new,df_scaled],axis=1)\n    df = pd.concat([df,df_new],axis=1)\n    df.drop(columns=['Age','Fare'],axis=1,inplace=True)\n    return df","95376722":"x_val = normalize_feature(x_val)\nx_val.head()","fee6f1e9":"x_train_data = x_train.copy()\nx_train_data.head()\nx_val_data = x_val.copy()","c75013d9":"x_train.boxplot(figsize=(10,10))\n#Outliers are present in Family feature","d692c069":"train_all = pd.concat([x_train,y_train],axis=1)\ntrain_all.head()","cc5896e7":"corr = train_all.corr()\nsns.heatmap(corr,annot=True)","3dae81bf":"from sklearn.linear_model import LogisticRegression\nclf_log_reg = LogisticRegression(penalty='l2',random_state=1,solver='lbfgs',tol=0.001).fit(x_train,y_train)","86bcf21d":"clf_log_reg.predict(x_val)","7f3a3c78":"print(clf_log_reg.decision_function(x_val))","c9599f91":"clf_log_reg.predict_proba(x_val)","54b6c221":"clf_log_reg.get_params()","dc6ddeac":"clf_log_reg.score(x_val,y_val)","05586df6":"test_df.head()","30f4dbf6":"#test_df.drop(columns=['Ticket'],axis=1,inplace=True)\ntest_df = imputer_null(test_df)\ntest_df = one_hot(test_df)\ntest_df = add_family_feature(test_df)\ntest_df = normalize_feature(test_df)\ntest_df.head()","32340a0e":"#test_df.Ticket.values","1ce9c396":"test_data[['PassengerId']]","a57cf884":"test_df.drop(columns=['Ticket'],axis=1,inplace=True)\ntest_pred = clf_log_reg.predict(test_df)\ntest_pred_df = pd.DataFrame(test_pred,columns=['Survived'])\ntest_pred_df\ny_test = pd.concat([test_data[['PassengerId']],test_pred_df],axis=1)\ny_test.head()","c1d65b9b":"# import os\n# os.remove('\/kaggle\/working\/submission.csv')","7b3cae32":"val_prob = np.array(clf_log_reg.predict_proba(x_val))\nprint(val_prob[:,1])","e9e5947d":"val_score = clf_log_reg.score(x_val,y_val)\nprint(\"Score of Validation set is :\" \"{:.2f}\".format(val_score*100))","25968844":"from sklearn.metrics import roc_auc_score\nroc_auc = \"{:.2f}\".format(roc_auc_score(y_val,val_prob[:,1])*100)\nprint(roc_auc)","aedc797d":"from sklearn.metrics import roc_curve\n ","bf7d0ea9":"# Write to a csv file\ny_test.to_csv(\"logistic_submission.csv\",index=False)","dc9b26de":"from sklearn import svm\nclf_svc = svm.NuSVC().fit(x_train,y_train)","a41b1dc1":"clf_svc.predict(x_val)","f0e69520":"clf_svc.score(x_val,y_val)","99eec3a7":"test_df.head()","b3cbb788":"test_pred = clf_svc.predict(test_df)\ntest_pred_df = pd.DataFrame(test_pred,columns=['Survived'])\ntest_pred_df\ny_test = pd.concat([test_data[['PassengerId']],test_pred_df],axis=1)\ny_test.head()","39b9fa7a":"y_test.to_csv(\"svc.submission.csv\",index=False)","e378b83f":"from sklearn.naive_bayes import GaussianNB\nclf_nb = GaussianNB().fit(x_train,y_train)\nclf_nb.predict(x_val)","56ad6130":"clf_nb.score(x_val,y_val)","13f2f668":"y_test = clf_nb.predict(test_df)\ny_test","c65bd776":"y_pred_df = pd.DataFrame(y_test,columns=['Survived'])\ntest_data = pd.concat([test_data[['PassengerId']],y_pred_df],axis=1)\ntest_data.head()","e2575236":"test_data.to_csv(\"naive_bayes_submission.csv\",index=False)","616cccf8":"from sklearn import tree\nclf_dt = tree.DecisionTreeClassifier(max_depth=3,min_samples_split=15,min_samples_leaf=3,random_state=1).fit(x_train,y_train)\nclf_dt.predict(x_val)\n","9e4cdfd1":"y_val","513bcaca":"clf_dt.score(x_val,y_val)","03b92efe":"clf_dt.get_params()","f91df5b3":"tree.plot_tree(clf_dt)","fbd61cff":"y_test = clf_dt.predict(test_df)\ny_test = pd.DataFrame(y_test,columns=['Survived'])\ny_test = pd.concat([test_data[['PassengerId']],y_test],axis=1)\ny_test","b6253a32":"y_test.to_csv(\"dt_submission.csv\",index=False)","6385ea60":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=200,max_depth=3,min_samples_split=5,random_state=1,oob_score=True)\nclf_rf = rf.fit(x_train,y_train)\nclf_rf","29b2075b":"clf_rf.predict(x_val)","2ea301ad":"clf_rf.score(x_val,y_val)","1c6fe8a2":"y_test = clf_rf.predict(test_df)\ny_test = pd.DataFrame(y_test,columns=['Survived'])\ny_pred = pd.concat([test_data[['PassengerId']],y_test],axis=1)\ny_pred","d5ff9eef":"y_pred.to_csv(\"rf_submission.csv\",index=False)","61cb1dc7":"### Function for Normalizing Age and Fare","9ee49b9b":"### Normalise Age and Fare","f2696b1a":"### Function for one-hot encoding for Validation and Testing","8b238ee1":"### Check statistics for all columns","b23467fe":"### ROC - AUC Curve","b03ed23e":"### Reset Index","7a18d796":"## Data Visualization","3091b4f2":"### Add Family column function for Validation and Testing data","d8655a36":"## To be done \n### Split ticket into two columns\nFor Logistic Regression,DT,SVM numerical values are required","4632e881":"### Naive Bayes Classifier","65218b62":"## Model Development","3bec3142":"## Pre-Processing\n## Impute Null Values","d00ebf32":"### Check the ratio of survived and not survived","bfa677e4":"### Loading Data","8933f0d1":"### 4) Decision Trees","4ebf247c":"### Feature Engineering\n### Add Family column","fbd3f48d":"### Correlation Plot","37ac8d16":"### 2) Support Vector Machine","cc5af446":"### One-hot encoding of Validation and Test function","30d8c904":"### Impute Validation set","e9e87a71":"### Reading Train and Test Data","a315954d":"## One hot Encoding for 3 columns- Pclass, Sex, Embarked","d706f77a":"### Imputer Function","0116fd98":"## Train Validation Split\n#### train_df --->main before pre-processing","d3b91717":"### Do Test Pre-Processing same as Train","6ec418ec":"### 1) Logistic Regression\nFinding: Logistic Regression will not allow any strings in columns;Convert everything to number;Else will throw error","998759ae":"### Check statistics for numerical values","987ae85c":"### 5) Random Forest"}}