{"cell_type":{"be98ca7e":"code","03948c1f":"code","8b0fadc0":"code","3fa1f7d5":"code","04cfd4ba":"code","1feff5e3":"code","b2ffa2ce":"code","1d27b57a":"code","c7f12a35":"code","4874d861":"code","bb890f4c":"code","36622652":"code","b68efcd5":"code","39b58e7f":"code","e57ed05e":"code","801cc994":"code","be633705":"code","530d4eb6":"code","e5d2b707":"code","c59e453a":"code","854390f9":"code","21a15ef6":"code","20406f9d":"code","c0a3db2a":"code","45665dc6":"code","661122a0":"code","e6efdeba":"code","f22d4401":"code","52f608ec":"code","9a7544e7":"code","8ff4b967":"code","32dc4f2d":"code","5bae5824":"code","39bf486b":"code","1a98f1f2":"code","8debca37":"code","2d1534fb":"markdown","f78f1eb5":"markdown","b5c06f33":"markdown","0d814f16":"markdown","995e0e52":"markdown","fcfaa18d":"markdown","24547b50":"markdown","45ed8d07":"markdown","8e7e3811":"markdown","efef72b1":"markdown","2a8981a4":"markdown","199842b5":"markdown","f8f3920a":"markdown","a6eff76a":"markdown","1e26e260":"markdown","41335631":"markdown","57012eae":"markdown","23dd42e3":"markdown","e4f5ec1b":"markdown","a9736a38":"markdown","10eb4eb9":"markdown","2a2c3c04":"markdown","5242b95c":"markdown","374f6ce0":"markdown","10406f4a":"markdown","82b9b896":"markdown"},"source":{"be98ca7e":"import warnings\nimport itertools\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport lightgbm as lgb\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook as tqdm\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, log_loss\n\nwarnings.simplefilter(action='ignore')\nsns.set_style('whitegrid')","03948c1f":"dtypes = {\"crew\": \"int8\",\n          \"experiment\": \"category\",\n          \"time\": \"float32\",\n          \"seat\": \"int8\",\n          \"eeg_fp1\": \"float32\",\n          \"eeg_f7\": \"float32\",\n          \"eeg_f8\": \"float32\",\n          \"eeg_t4\": \"float32\",\n          \"eeg_t6\": \"float32\",\n          \"eeg_t5\": \"float32\",\n          \"eeg_t3\": \"float32\",\n          \"eeg_fp2\": \"float32\",\n          \"eeg_o1\": \"float32\",\n          \"eeg_p3\": \"float32\",\n          \"eeg_pz\": \"float32\",\n          \"eeg_f3\": \"float32\",\n          \"eeg_fz\": \"float32\",\n          \"eeg_f4\": \"float32\",\n          \"eeg_c4\": \"float32\",\n          \"eeg_p4\": \"float32\",\n          \"eeg_poz\": \"float32\",\n          \"eeg_c3\": \"float32\",\n          \"eeg_cz\": \"float32\",\n          \"eeg_o2\": \"float32\",\n          \"ecg\": \"float32\",\n          \"r\": \"float32\",\n          \"gsr\": \"float32\",\n          \"event\": \"category\",\n         }","8b0fadc0":"train_df = pd.read_csv(\"..\/input\/train.csv\", dtype=dtypes)\ntest_df = pd.read_csv(\"..\/input\/test.csv\", dtype=dtypes)","3fa1f7d5":"train_df.info()","04cfd4ba":"train_df.head()","1feff5e3":"test_df.head()","b2ffa2ce":"plt.figure(figsize=(15,10))\nsns.countplot(train_df['event'])\nplt.xlabel(\"State of the pilot\", fontsize=12)\nplt.ylabel(\"Count\", fontsize=12)\nplt.title(\"Target repartition\", fontsize=15)\nplt.show()","1d27b57a":"plt.figure(figsize=(15,10))\nsns.countplot('experiment', hue='event', data=train_df)\nplt.xlabel(\"Experiment and state of the pilot\", fontsize=12)\nplt.ylabel(\"Count (log)\", fontsize=12)\nplt.yscale('log')\nplt.title(\"Target repartition for different experiments\", fontsize=15)\nplt.show()","c7f12a35":"plt.figure(figsize=(15,10))\nsns.countplot('event', hue='seat', data=train_df)\nplt.xlabel(\"Seat and state of the pilot\", fontsize=12)\nplt.ylabel(\"Count (log)\", fontsize=12)\nplt.yscale('log')\nplt.title(\"Left seat or right seat ?\", fontsize=15)\nplt.show()","4874d861":"plt.figure(figsize=(15,10))\nsns.violinplot(x='event', y='time', data=train_df.sample(50000))\nplt.ylabel(\"Time (s)\", fontsize=12)\nplt.xlabel(\"Event\", fontsize=12)\nplt.title(\"Which time do events occur at ?\", fontsize=15)\nplt.show()","bb890f4c":"plt.figure(figsize=(15,10))\nsns.distplot(test_df['time'], label='Test set')\nsns.distplot(train_df['time'], label='Train set')\nplt.legend()\nplt.xlabel(\"Time (s)\", fontsize=12)\nplt.title(\"Reparition of the time feature\", fontsize=15)\nplt.show()","36622652":"eeg_features = [\"eeg_fp1\", \"eeg_f7\", \"eeg_f8\", \"eeg_t4\", \"eeg_t6\", \"eeg_t5\", \"eeg_t3\", \"eeg_fp2\", \"eeg_o1\", \"eeg_p3\", \"eeg_pz\", \"eeg_f3\", \"eeg_fz\", \"eeg_f4\", \"eeg_c4\", \"eeg_p4\", \"eeg_poz\", \"eeg_c3\", \"eeg_cz\", \"eeg_o2\"]","b68efcd5":"plt.figure(figsize=(20,25))\ni = 0\n\nfor egg in eeg_features:\n    i += 1\n    plt.subplot(5, 4, i)\n    sns.boxplot(x='event', y=egg, data=train_df.sample(50000), showfliers=False)\n\nplt.show()","39b58e7f":"plt.figure(figsize=(20,25))\nplt.title('Eeg features distributions')\ni = 0\n\nfor eeg in eeg_features:\n    i += 1\n    plt.subplot(5, 4, i)\n    sns.distplot(test_df.sample(10000)[eeg], label='Test set', hist=False)\n    sns.distplot(train_df.sample(10000)[eeg], label='Train set', hist=False)\n    plt.xlim((-500, 500))\n    plt.legend()\n    plt.xlabel(eeg, fontsize=12)\n\nplt.show()","e57ed05e":"plt.figure(figsize=(15,10))\nsns.violinplot(x='event', y='ecg', data=train_df.sample(50000))\nplt.ylabel(\"Electrocardiogram Signal (\u00b5V)\", fontsize=12)\nplt.xlabel(\"Event\", fontsize=12)\nplt.title(\"Electrocardiogram signal influence\", fontsize=15)\nplt.show()","801cc994":"plt.figure(figsize=(15,10))\nsns.distplot(test_df['ecg'], label='Test set')\nsns.distplot(train_df['ecg'], label='Train set')\nplt.legend()\nplt.xlabel(\"Electrocardiogram Signal (\u00b5V)\", fontsize=12)\nplt.title(\"Electrocardiogram Signal Distribution\", fontsize=15)\nplt.show()","be633705":"plt.figure(figsize=(15,10))\nsns.violinplot(x='event', y='r', data=train_df.sample(50000))\nplt.ylabel(\"Respiration Signal (\u00b5V)\", fontsize=12)\nplt.xlabel(\"Event\", fontsize=12)\nplt.title(\"Respiration influence\", fontsize=15)\nplt.show()","530d4eb6":"plt.figure(figsize=(15,10))\nsns.distplot(test_df['r'], label='Test set')\nsns.distplot(train_df['r'], label='Train set')\nplt.legend()\nplt.xlabel(\"Respiration Signal (\u00b5V)\", fontsize=12)\nplt.title(\"Respiration Signal Distribution\", fontsize=15)\nplt.show()","e5d2b707":"plt.figure(figsize=(15,10))\nsns.violinplot(x='event', y='gsr', data=train_df.sample(50000))\nplt.ylabel(\"Electrodermal activity measure (\u00b5V)\", fontsize=12)\nplt.xlabel(\"Event\", fontsize=12)\nplt.title(\"Electrodermal activity influence\", fontsize=15)\nplt.show()","c59e453a":"plt.figure(figsize=(15,10))\nsns.distplot(test_df['gsr'], label='Test set')\nsns.distplot(train_df['gsr'], label='Train set')\nplt.legend()\nplt.xlabel(\"Electrodermal activity measure (\u00b5V)\", fontsize=12)\nplt.title(\"Electrodermal activity Distribution\", fontsize=15)\nplt.show()","854390f9":"features_n = [\"eeg_fp1\", \"eeg_f7\", \"eeg_f8\", \"eeg_t4\", \"eeg_t6\", \"eeg_t5\", \"eeg_t3\", \"eeg_fp2\", \"eeg_o1\", \"eeg_p3\", \"eeg_pz\", \"eeg_f3\", \"eeg_fz\", \"eeg_f4\", \"eeg_c4\", \"eeg_p4\", \"eeg_poz\", \"eeg_c3\", \"eeg_cz\", \"eeg_o2\", \"ecg\", \"r\", \"gsr\"]","21a15ef6":"train_df['pilot'] = 100 * train_df['seat'] + train_df['crew']\ntest_df['pilot'] = 100 * test_df['seat'] + test_df['crew']\n\nprint(\"Number of pilots : \", len(train_df['pilot'].unique()))","20406f9d":"def normalize_by_pilots(df):\n    pilots = df[\"pilot\"].unique()\n    for pilot in tqdm(pilots):\n        ids = df[df[\"pilot\"] == pilot].index\n        scaler = MinMaxScaler()\n        df.loc[ids, features_n] = scaler.fit_transform(df.loc[ids, features_n])\n        \n    return df","c0a3db2a":"train_df = normalize_by_pilots(train_df)\ntest_df = normalize_by_pilots(test_df)","45665dc6":"train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=420)\nprint(f\"Training on {train_df.shape[0]} samples.\")","661122a0":"features = [\"crew\", \"seat\"] + features_n\n      \ndef run_lgb(df_train, df_test):\n    # Classes as integers\n    dic = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n    try:\n        df_train[\"event\"] = df_train[\"event\"].apply(lambda x: dic[x])\n        df_test[\"event\"] = df_test[\"event\"].apply(lambda x: dic[x])\n    except: \n        pass\n    \n    params = {\"objective\" : \"multiclass\",\n              \"num_class\": 4,\n              \"metric\" : \"multi_error\",\n              \"num_leaves\" : 30,\n              \"min_child_weight\" : 50,\n              \"learning_rate\" : 0.1,\n              \"bagging_fraction\" : 0.7,\n              \"feature_fraction\" : 0.7,\n              \"bagging_seed\" : 420,\n              \"verbosity\" : -1\n             }\n    \n    lg_train = lgb.Dataset(df_train[features], label=(df_train[\"event\"]))\n    lg_test = lgb.Dataset(df_test[features], label=(df_test[\"event\"]))\n    model = lgb.train(params, lg_train, 1000, valid_sets=[lg_test], early_stopping_rounds=50, verbose_eval=100)\n    \n    return model","e6efdeba":"model = run_lgb(train_df, val_df)","f22d4401":"fig, ax = plt.subplots(figsize=(12,10))\nlgb.plot_importance(model, height=0.8, ax=ax)\nax.grid(False)\nplt.ylabel('Feature', size=12)\nplt.xlabel('Importance', size=12)\nplt.title(\"Importance of the Features of our LightGBM Model\", fontsize=15)\nplt.show()","52f608ec":"pred_val = model.predict(val_df[features], num_iteration=model.best_iteration)\n#pred_train = model.predict(train_df[features], num_iteration=model.best_iteration)","9a7544e7":"print(\"Log loss on validation data :\", round(log_loss(np.array(val_df[\"event\"].values), pred_val), 3))","8ff4b967":"def plot_confusion_matrix(cm, classes, title='Confusion matrix', normalize=False, cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n    fmt = '.2f' if normalize else 'd'\n\n    fig, ax = plt.subplots(figsize=(15, 10))\n    ax.imshow(cm, interpolation='nearest', cmap=cmap)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, size=15)\n    plt.colorbar()\n    plt.grid(False)\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = (cm.max()+cm.min()) \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label', size=12)\n    plt.xlabel('Predicted label', size=12)","32dc4f2d":"conf_mat_val = confusion_matrix(np.argmax(pred_val, axis=1), val_df[\"event\"].values)\nplot_confusion_matrix(conf_mat_val, [\"A\", \"B\", \"C\", \"D\"], title='Confusion matrix on Validation data', normalize=True)","5bae5824":"pred_test = model.predict(test_df[features], num_iteration=model.best_iteration)","39bf486b":"submission = pd.DataFrame(np.concatenate((np.arange(len(test_df))[:, np.newaxis], pred_test), axis=1), columns=['id', 'A', 'B', 'C', 'D'])\nsubmission['id'] = submission['id'].astype(int)","1a98f1f2":"submission.head()","8debca37":"submission.to_csv(\"submission.csv\", index=False)","2d1534fb":"The experiment of the test set is LOFT (Line Oriented Flight Training), which is a full flight (take off, flight, and landing) in a flight simulator. ","f78f1eb5":"### Electrocardiogram\n- 3-point Electrocardiogram signal. The sensor had a resolution\/bit of .012215 \u00b5V and a range of -100mV to +100mV. The data are provided in microvolts.","b5c06f33":"### Normalizing \n\nBecause of earlier remarks, we normalize our features. \n\nI do believe the following features depend a lot of the person, therefore I apply a Min\/Max Scaler for each pilot.","0d814f16":"### Seat\nWhich seat the pilot is sitting in.\n- 0 : left seat\n- 1 : right seat\n\nThis probably has nothing to do with the outcome of the experiment though.","995e0e52":"Again, quite similar.","fcfaa18d":"### Model\nNote that I did not bother tweaking the parameters yet.","24547b50":"### Submission","45ed8d07":"### Time of the experiment","8e7e3811":"### Target & Experiment\n\nThe pilots experienced distractions intended to induce one of the following three cognitive states:\n\n- Channelized Attention (CA) is, roughly speaking, the state of being focused on one task to the exclusion of all others. This is induced in benchmarking by having the subjects play an engaging puzzle-based video game.\n- Diverted Attention (DA) is the state of having one\u2019s attention diverted by actions or thought processes associated with a decision. This is induced by having the subjects perform a display monitoring task. Periodically, a math problem showed up which had to be solved before returning to the monitoring task.\n- Startle\/Surprise (SS) is induced by having the subjects watch movie clips with jump scares.\n\nSamples are labelled the following way : \n- A = baseline\n- B = SS\n- C = CA\n- D = DA","efef72b1":"## 1 - Loading the Data","2a8981a4":"### Respiration \n- A measure of the rise and fall of the chest. The sensor had a resolution\/bit of .2384186 \u00b5V and a range of -2.0V to +2.0V. The data are provided in microvolts.","199842b5":"## 2 - EDA","f8f3920a":"Reparitions seem consistent :  Gaussians with a sinuso\u00efdal noise centered at 0. Note that the variance is larger on the test set.","a6eff76a":"### Train \/ Test split","1e26e260":"### Confusion Matrix","41335631":"## 3 - Gradient Boosting","57012eae":"### Galvanic Skin Response\n - A measure of electrodermal activity. The sensor had a resolution\/bit of .2384186 \u00b5V and a range of -2.0V to +2.0V. The data are provided in microvolts.\n > \"The galvanic skin response (GSR, which falls under the umbrella term of electrodermal activity, or EDA) refers to changes in sweat gland activity that are reflective of the intensity of our emotional state, otherwise known as emotional arousal.\"","23dd42e3":"Nothing much to say here, the test set has a bunch of sample with lower values though.","e4f5ec1b":"The repartition of events is interesting. However, we can't use this feature because time in the flight simulator has nothing to do with time in the experiments. \nIt's a shame because take-off and landing could have been exploited.","a9736a38":"We Also check if features have the same distribution on the test and train set","10eb4eb9":"Except foir the >20000-ish samples, train\/test repartitions are similar.","2a2c3c04":"No missing values.","5242b95c":"# Starter Code : EDA and LGBM Baseline ","374f6ce0":"### Feature importance","10406f4a":"### Electroencephalogram recordings","82b9b896":"Any feedback is always appreciated ! \n\n### *Thanks for reading !*\n"}}