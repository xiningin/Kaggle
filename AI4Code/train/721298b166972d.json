{"cell_type":{"1b14bfa9":"code","6417b38b":"code","075fea95":"code","25bf2cdc":"code","2ad448ce":"code","7836ce85":"code","a545ec8c":"code","38d4545b":"code","29736e8c":"code","fef19ba1":"code","5b27cd50":"code","7936f1ed":"code","9d38b71d":"code","277a675c":"code","52a1faf1":"code","07a9035a":"code","86109de9":"code","d679a96c":"code","128af8a7":"code","5fd2d2d0":"code","a62edfbd":"code","f3d23b4c":"code","cbb67033":"code","3f1e2d7b":"code","f5871604":"code","fcc976a8":"code","f43263e6":"code","0aae3505":"code","c5f33c1d":"code","e267c75d":"code","9d95a1e7":"code","84922f9d":"code","48184372":"code","b803ecb5":"markdown","192e4597":"markdown","9b3cf4e1":"markdown","6acb758f":"markdown","5da0ff26":"markdown","26ba2d63":"markdown","c87bed09":"markdown","954c92ee":"markdown","2673231d":"markdown","482e6d9c":"markdown","b9c9f729":"markdown","37e6f1a2":"markdown","4f02eaa8":"markdown","44fb5982":"markdown","01b4f4f2":"markdown","b52372d3":"markdown","c963f75c":"markdown","391699e8":"markdown","e5a2c6ed":"markdown","1f2d31fe":"markdown","fcf66dc7":"markdown","8afbaac8":"markdown","203508d0":"markdown","e60143a8":"markdown","6341eaad":"markdown","777377dc":"markdown","0c31e208":"markdown","f3f73b8e":"markdown","83fbfb76":"markdown","d95ca14e":"markdown","50286d9b":"markdown","af7ed0df":"markdown","f6cc058d":"markdown","3a801178":"markdown","c3738c70":"markdown","94c68b7c":"markdown","6105bec7":"markdown","22222334":"markdown","fe6c4aff":"markdown"},"source":{"1b14bfa9":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # For Plotting and Visualization\nimport seaborn as sns # For Plotting and Visualization\nfrom sklearn.model_selection import train_test_split # For Splitting the Dataset into Training and Test Dataset\nimport statsmodels.api as sm # For Building Linear Model\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor # To Calculate Variance Inflation Factor Between Indepenent Variables\nimport os\nprint(os.listdir(\"..\/input\"))\n    ","6417b38b":"class PredictGreScore():\n    \n    def __init__(self,x,y,model):\n        self.predictordata=x\n        self.actualresponsevalue=y\n        self.model=model\n        # Calculate Degree of Freedom of Predictor Variable Variance\n        self.df_pred=x.shape[0]-1\n        # Calculate Degree of Freedom of Population Error Variance\n        self.df_error=x.shape[0]-x.shape[1]-1\n    \n    # Calculate Total Sum of Squares\n    \n    def TSS(self):\n        avg_y=np.mean(self.actualresponsevalue)\n        squared_errors=((self.actualresponsevalue)-(avg_y))**2\n        return np.sum(squared_errors)\n    \n    # Calculate Residual Sum of Squares\n    \n    def RSS(self):\n        ActualValue=self.actualresponsevalue\n        PredictedValue=self.model.predict(self.predictordata)\n        ResidualError = (ActualValue-PredictedValue)**2\n        return np.sum(ResidualError)\n    \n    # Calculate R-Squared Value\n    \n    def r_squared(self):\n        return 1 - self.RSS()\/self.TSS()\n    \n    # Calculate Adjusted R-Squared Value\n    \n    def adj_rsquared(self):\n        return 1-(self.RSS()\/self.df_error)\/(self.TSS()\/self.df_pred)\n    \n    # Plot Residual Analysis of Error Data\n    \n    def plot_residualanalysis(self):\n        fig=plt.figure()\n        sns.distplot(self.actualresponsevalue-self.model.predict(self.predictordata))\n        plt.xlabel('Errors',fontsize=18)\n        \n    ","075fea95":"def print_statsresults(stats_obj):\n    items=(('Residual Sum of Squares:',stats_obj.RSS()),('Total Sum of Squares:',stats_obj.TSS()),('R-Squared:',stats_obj.r_squared()),('Adjusted R-Squared:',stats_obj.adj_rsquared()))\n    for item in items:\n        print('{0:8}{1:.4f}'.format(item[0],item[1]))","25bf2cdc":"# Supress Warnings\n\nimport warnings\nwarnings.filterwarnings('ignore')","2ad448ce":"# Read the input dataset\ninput=pd.read_csv(\"..\/input\/Admission_Predict_Ver1.1.csv\")\ninput.head()","7836ce85":"# Rows and Columns in the dataset\ninput.shape\n","a545ec8c":"# Datatypes of each Column in the Dataset\ninput.info()","38d4545b":"# Understand the Correlation between each Column in the dataset\n\nsns.set(style='ticks',color_codes=True)\nsns.pairplot(input)\nplt.show()\n","29736e8c":"# check for missing values in the dataset\n\ninput.isnull().sum()","fef19ba1":"# Dataset is divided into Training and Testing Data using train_test_split imported from sklearn.model_selection\n\nnp.random.seed(0)\n\n# split the dataframe\n\ninput_train,input_test=train_test_split(input,train_size=0.6,test_size=0.4,random_state=None)","5b27cd50":"# Perform Correlation on the Training Data to identify the Predictor Variables Highly Correlated with the Response Variable\n\nplt.figure(figsize = (25, 10))\nsns.heatmap(input_train.corr(),annot=True,cmap='YlGnBu')\nplt.show()\n","7936f1ed":"y_train=input_train.pop('GRE Score')\nx_train=input_train","9d38b71d":"# Adding the Constant\n\nx_train_lm=sm.add_constant(x_train[['TOEFL Score','CGPA','Chance of Admit ']])\n","277a675c":"# Create Linear Regression Model\n\nlr=sm.OLS(y_train,x_train_lm).fit()","52a1faf1":"x_train_lm.head()","07a9035a":"print(lr.summary())","86109de9":"# Creating a dataframe which contains the list of Predictor Variables and their VIF's\n\nvif=pd.DataFrame()\nvif['Features']=x_train_lm.columns\nvif['vif']=[variance_inflation_factor(x_train_lm.values,i) for i in range(x_train_lm.shape[1])]\nvif['vif']=round(vif['vif'],2)\nvif=vif.sort_values(by=\"vif\",ascending=False)\nvif","d679a96c":"ResidualAnalysis=PredictGreScore(x_train_lm,y_train,lr)\nResidualAnalysis.plot_residualanalysis()","128af8a7":"stats=PredictGreScore(x_train_lm,y_train,lr)\nprint_statsresults(stats)","5fd2d2d0":"# Building a new model by Considering TOEFL Score and Chance of Admit as Predictor Variables and removed CGPA which has high VIF \nx_train_model2=sm.add_constant(x_train[['TOEFL Score','Chance of Admit ']])","a62edfbd":"# Run the Model\nlr_model2=sm.OLS(y_train,x_train_model2).fit()","f3d23b4c":"print(lr_model2.summary())","cbb67033":"# Plotting Residual Analysis to see if error terms are normally dsitributed\nResidualAnalysis=PredictGreScore(x_train_model2,y_train,lr_model2)\nResidualAnalysis.plot_residualanalysis()","3f1e2d7b":"stats=PredictGreScore(x_train_model2,y_train,lr_model2)\nprint_statsresults(stats)","f5871604":"x_train_model3=sm.add_constant(x_train[['TOEFL Score','CGPA','University Rating','Chance of Admit ']])","fcc976a8":"lr_model3=sm.OLS(y_train,x_train_model3).fit()","f43263e6":"print(lr_model3.summary())","0aae3505":"# Plotting Residual Analysis to see if error terms are normally dsitributed\nResidualAnalysis=PredictGreScore(x_train_model3,y_train,lr_model3)\nResidualAnalysis.plot_residualanalysis()","c5f33c1d":"stats=PredictGreScore(x_train_model3,y_train,lr_model3)\nprint_statsresults(stats)","e267c75d":"# Let us split the test data into x_test and y_test\ny_test=input_test.pop('GRE Score')\nx_test=input_test","9d95a1e7":"# Now lets use Model 1 to make Predictions and select the Predictor Variables used in Model 1\n\n# Drop the Constant Variable Column from the train columns used in the Model 1\nx_train_new=x_train_lm.drop(['const'],axis=1)\n\nx_test_new=x_test[x_train_new.columns]\n\n# Adding a Constant Variable\nx_test_new=sm.add_constant(x_test_new)\n\n#Making the Predictions\n\ny_pred=lr.predict(x_test_new)","84922f9d":"stats=PredictGreScore(x_test_new,y_test,lr)\nprint_statsresults(stats)\n","48184372":"# Plotting the y_test and y_pred to Understand the Spread\n\nfig=plt.figure()\nplt.scatter(y_test,y_pred)\nfig.suptitle('y_test vs y_pred',fontsize=20)\nplt.xlabel('y_test',fontsize=18)\nplt.ylabel('y_pred',fontsize=16)","b803ecb5":"## Model Prediction","192e4597":"## Divide the Dataset into Training and Test Data","9b3cf4e1":"## Building the Linear Model","6acb758f":"## Equation for Best Fit Regression Line","5da0ff26":"Residual Analysis Plot clearly shows the Error Terms are Normally Dsitributed from which we can confirm we built a model which produced the best estimates","26ba2d63":"**Display the Statistical Results of the Model**","c87bed09":" GRE Score = 175.4594 + 0.712 * `TOEFL Score` + 5.9518*`CGPA` + 18.4741*`Chance of Admit`\n\n","954c92ee":"- There is no missing values in any of the Columns in the Dataset.\n- we have necessary data to build the Linear Regression Model\n","2673231d":"- `Model 3` has Residual Sum of Squres equal to `Model 1` and `Adjsuted R-Squared` is more or less equal to `Model 1`\n- But the `University Rating` Predictor has `high p-value(>0.05)` which proves there is not enough evidence to reject the null hypothesis and also to conclde that non-zero correlation exists.\n- So `Univesrity Rating` Predictor is said to be statistically `insignificant` and thus we can avoid Model 3","482e6d9c":"- We have built a model with `Adjusted R-Squared Value` of `77%` and `Residual Sum of Squares value` said to be `8756.0620`\n- Let us Compare this Model with other Linear Regression Models and then decide which Model fits the best fil regression line.","b9c9f729":"** Display the Statistical Results of the Model**","37e6f1a2":"-  We have successfully split the dataset into training and testing datasets. \n-  Identified the highly Correlated Predictor Variables with Response Variable\n- Next Step is to split the training dataset into Predictor(X) and Response (Y) models","4f02eaa8":"## Multiple Linear Regression - Model 3","44fb5982":"After Comparison of all the models, we choose `Model 1` as the model which is able to produce the best estimates and will be making prediction of the test data using `Model 1`","01b4f4f2":"**Residual Analysis**","b52372d3":"**Display the Statistical Results of Predicted Values**","c963f75c":"**Variance Inflation Factor**","391699e8":"- Let say we consider the VIF Value to be less than or almost equal to 3 is ideal\n- Let us remove CGPA which has High VIF when compared to other Predictor Variables and observe how the model behaves","e5a2c6ed":"**Considered Predictor Variables which are highly correlated**","1f2d31fe":"* From the Correlation Plot, we can notice University Rating has good Correlation with GRE Score.Let us build a Model which contains University Rating also as one of the Predictor Varibles.","fcf66dc7":"## Model Evalulation","8afbaac8":"## Packages used in the Project","203508d0":"- When Compared to the results of `Model1` ,`Model2` has high Residual Sum of Squares and Adjsuted R - Squared Value is deceased when Compared to Model1\n- After Comaprison, We can say Model 1 is better when Compared to Model 2 as for a Model to be significant and to best fit the Regression Line its Residual Sum of Squares should be minimal and Adjusted R-Square should be moderate.","e60143a8":"- To build the best fit **Multiple LinearRegression Model** ,**Feature Selection** is one of the most crucial aspects .\n-  I will be using  **Manual Feature Elimination**  Procedure as the number of Predictor Variables is very less.\n-  As part of **Manual Feature Elimination** ,we build multiple models and choose the best fit model whose Residual Sum of Squares       is minimal and high Adjusted R-Squared Value.","6341eaad":"**Function to Print the Statistical Results**","777377dc":" Created a Class which contains reusable functions used for retrieving statistical information from the Linear Regession Model","0c31e208":"From the plot it is evident that there is a Linear Relationship established between the Actual Response Variable and Predicted Response Variable","f3f73b8e":"## Multiple Linear Regression - Model 2","83fbfb76":"Let us fit a regression line for training data using statsmodels. when statsmodels library is used for building the model\nwe need to explicitly define the constant.","d95ca14e":"## Classes and Functions","50286d9b":"`GRE Score` is said to be highly correlated with `TOEFL Score`, `CGPA` and `Chance of Admit`","af7ed0df":"**Model Selection**","f6cc058d":"Acheived  Residual Sum of Squares Value of `6257.6383` and  `72%` Adjusted R-Squared","3a801178":"`GRE Score` is said to be highly correlated with `TOEFL Score` ,`CGPA`and `Chance of Admit`","c3738c70":"** Display the Statistical Results of Model**","94c68b7c":"- From the warnings in the Model, it has been observed there is multicollinearity existing between the predictor variables.\n- Let us calculate the Variance Inflation Factor to identify how much strong each predictor variables are correlated against each other","6105bec7":"1. VIF values obtained for the predicted variables (CGPA, Chance of Admit ,TOEFL Score) is within the level of acceptance.\n2. VIF Under Ideal Conditions should be less than 3 but it is still acceptable if it under 10\n3. So this concludes i have selected decent predictor variables for the Model","22222334":"## Multiple Linear Regression - Model 1","fe6c4aff":"## Dividing the Training Dataset into X and Y Models"}}