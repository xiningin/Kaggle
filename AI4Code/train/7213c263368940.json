{"cell_type":{"fc8bf941":"code","a2c22bef":"code","b2a534ec":"code","d8931976":"code","07a76058":"code","7bf4836d":"code","ab8f5975":"code","58c16372":"code","67ba4004":"code","85db9296":"code","a61e7c4b":"code","bca58849":"code","c77366b3":"code","7eda8493":"code","e5477431":"code","fafe22bf":"code","851747c3":"code","c3ec8500":"code","ff8ed84b":"code","78f1f840":"code","f6dd97fd":"code","8df0f5b3":"code","73915c2c":"code","2db76ad2":"markdown","8e9a925a":"markdown","c47df65b":"markdown","94bbbe44":"markdown","d971d0c0":"markdown"},"source":{"fc8bf941":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\n\nfrom sklearn.neighbors import BallTree\nfrom sklearn.base import BaseEstimator\n\nfrom sklearn.pipeline import make_pipeline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","a2c22bef":"# Read file\nlines = [line.rstrip('\\n').replace('\\\\n',' ').replace('>','') for line in open('..\/input\/input (Cleaned).txt')]","b2a534ec":"# Make dataframe with context and reply\n# I assume that each line is a reply for the previous replic\n\nsubtitles = pd.DataFrame(columns=['context', 'reply'])\nsubtitles['context'] = lines\nsubtitles['context'] = subtitles['context'].apply(lambda x: x.lower())\nsubtitles['reply'] = lines[1:] + ['...']\nsubtitles['reply'] = subtitles['reply'].apply(lambda x: x.lower())","d8931976":"# Add whitespaces before every sign\nfor sign in ['!', '?', ',', '.', ':']:\n    subtitles['context'] = subtitles['context'].apply(lambda x: x.replace(sign, f' {sign}'))\n    subtitles['reply'] = subtitles['reply'].apply(lambda x: x.replace(sign, f' {sign}'))","07a76058":"subtitles.info()","7bf4836d":"subtitles.iloc[100:120]","ab8f5975":"# Lets vectorize our context corpus\nvectorizer = TfidfVectorizer()\nvectorizer.fit(subtitles.context)\n\nmatrix_big = vectorizer.transform(subtitles.context)","58c16372":"matrix_big.shape","67ba4004":"# SVD dimensionality reduction\n# You may try to increase number of components, but performance will become lower and may rise memory error\nsvd = TruncatedSVD(n_components=300, algorithm='arpack')\n\nsvd.fit(matrix_big)\nmatrix_small = svd.transform(matrix_big)\n\n# Print new dimensionality and explained variance ratio\nprint(matrix_small.shape)\nprint(svd.explained_variance_ratio_.sum())","85db9296":"# Probability  function for choosing one of the relevant answers\ndef softmax(x):\n    proba = np.exp(-x)\n    return proba\/sum(proba)\n\n# Choosing one of the k nearest neighbors with BallTree algorithm\nclass NeighborSampler(BaseEstimator):\n    def __init__(self, k=5, temperature = 1.0):\n        self.k = k\n        self.temperature = temperature\n    \n    def fit(self, X, y):\n        self.tree_ = BallTree(X)\n        self.y_ = np.array(y)\n        \n    def predict(self, X, random_state = None):\n        distances, indeces = self.tree_.query(X, return_distance = True, k = self.k)\n        result = []\n        for distance, index in zip(distances, indeces):\n            result.append(np.random.choice(index, p = softmax(distance * self.temperature)))\n            \n        return self.y_[result]","a61e7c4b":"ns = NeighborSampler()\nns.fit(matrix_small, subtitles.reply)\n\n# Vectorize, SVD and then chose an answer\npipe = make_pipeline(vectorizer, svd, ns)","bca58849":"print(pipe.predict(['Hello !']))","c77366b3":"print(pipe.predict(['Do you like me?']))","7eda8493":"print(pipe.predict(['Do you like me?']))","e5477431":"print(pipe.predict(['you are weird']))","fafe22bf":"print(pipe.predict(['how are you ?']))","851747c3":"print(pipe.predict(['lets kill him']))","c3ec8500":"print(pipe.predict(['i am sorry']))","ff8ed84b":"print(pipe.predict(['check out this thing']))","78f1f840":"print(pipe.predict(['konoha is in danger']))","f6dd97fd":"print(pipe.predict(['i will destroy this city']))","8df0f5b3":"print(pipe.predict(['prepare for battle']))","73915c2c":"print(pipe.predict(['never forget me']))","2db76ad2":"Are u sure?","8e9a925a":"That's all for now!","c47df65b":"Now we can \"talk\" with our bot, trained on anime dialogs","94bbbe44":"That's better","d971d0c0":"We reduced number of features from 41k to 300 with keeping 46.5% of variance"}}