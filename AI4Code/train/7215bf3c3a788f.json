{"cell_type":{"21852229":"code","c2e269ef":"code","f0461ae1":"code","ffae8e04":"code","e61c41bf":"code","d3cd49a1":"code","5e85fc0c":"code","649c130f":"code","eaf31900":"code","ef751d86":"code","b506e1e0":"code","62371efb":"code","fbfb4f3c":"markdown","ff33e950":"markdown","02fd5ffb":"markdown","239c85fa":"markdown","583d0f19":"markdown","94dbdff1":"markdown","076a0080":"markdown","89fe2607":"markdown","62def8d3":"markdown"},"source":{"21852229":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.metrics import roc_auc_score","c2e269ef":"DATA_DIR = '\/kaggle\/input\/killer-shrimp-invasion\/'\nRANDOM_STATE = 0\n\ntrain = pd.read_csv(DATA_DIR + 'train.csv')\ntest = pd.read_csv(DATA_DIR + 'test.csv')","f0461ae1":"X_train = train[['Salinity_today', 'Temperature_today', 'Substrate', 'Depth', 'Exposure']]\nX_test = test[['Salinity_today', 'Temperature_today', 'Substrate', 'Depth', 'Exposure']]","ffae8e04":"# Iterative imputer\nimputer = IterativeImputer(max_iter = 10, random_state = RANDOM_STATE)\nimputer.fit(X_train)\nX_train = pd.DataFrame(imputer.transform(X_train), columns = X_train.columns)\nX_test = pd.DataFrame(imputer.transform(X_test), columns = X_test.columns)\n\n# Scaling\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train = pd.DataFrame(scaler.transform(X_train), columns = X_train.columns)\nX_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)","e61c41bf":"def five_fold_cv(model, X_train, Y_train, verbose = True):\n    skf = StratifiedKFold(n_splits = 5)\n    fold = 1\n    scores = []\n    \n    for train_index, test_index in skf.split(X_train, Y_train):\n        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n        Y_train_fold, Y_test_fold = Y_train.iloc[train_index], Y_train.iloc[test_index]\n\n        model.fit(X_train_fold, Y_train_fold)\n\n        preds = model.predict_proba(X_test_fold)\n        preds = [x[1] for x in preds]\n\n        score = roc_auc_score(Y_test_fold, preds)\n        scores.append(score)\n        if verbose:\n            print('Fold', fold, '     ', score)\n        fold += 1\n    \n    avg = np.mean(scores)\n    if verbose:\n        print()\n        print('Average:', avg)\n    return avg","d3cd49a1":"avg = five_fold_cv(LogisticRegression(random_state = RANDOM_STATE), X_train, train['Presence'])","5e85fc0c":"temperatures = X_train[['Temperature_today']]\navg = five_fold_cv(LogisticRegression(random_state = RANDOM_STATE), temperatures, train['Presence'])","649c130f":"#temperatures['Temperature 0.5'] = temperatures['Temperature_today'].apply(lambda x: x ** 0.5)\ntemperatures['Temperature 1'] = temperatures['Temperature_today']\n#temperatures['Temperature 1.5'] = temperatures['Temperature_today'].apply(lambda x: x ** 1.5)\ntemperatures['Temperature 2'] = temperatures['Temperature_today'] ** 2\ntemperatures['Temperature 3'] = temperatures['Temperature_today'] ** 3\ntemperatures['Temperature 4'] = temperatures['Temperature_today'] ** 4\ntemperatures['Temperature 5'] = temperatures['Temperature_today'] ** 5\ntemperatures['Temperature 6'] = temperatures['Temperature_today'] ** 6\ntemperatures['Temperature 7'] = temperatures['Temperature_today'] ** 7\ntemperatures['Temperature 8'] = temperatures['Temperature_today'] ** 8\ntemperatures['Temperature 9'] = temperatures['Temperature_today'] ** 9\ntemperatures['Temperature 10'] = temperatures['Temperature_today'] ** 10","eaf31900":"dof_temp_scores = []\ndof_temp = ['Temperature 1', 'Temperature 2', 'Temperature 3', 'Temperature 4', 'Temperature 5', 'Temperature 6', 'Temperature 7', 'Temperature 8', 'Temperature 9', 'Temperature 10']\nfor i in range(10):\n    dof_temp_scores.append(five_fold_cv(LogisticRegression(random_state = RANDOM_STATE), temperatures[dof_temp[:i + 1]], train['Presence'], verbose = False))\n    \nplt.plot(range(1, 11), dof_temp_scores)\nplt.xlabel('Degrees of Freedom')\nplt.ylabel('Cross Validation Score')\nplt.title('Cross Validation Scores For Polynomial Temperature Models')\nplt.show()","ef751d86":"# Get salinity polynomial features\nsalinities = X_train[['Salinity_today']]\nfor i in range(1, 11):\n    salinities['Salinity ' + str(i)] = salinities['Salinity_today'] ** i\n\n# Perform cross validation on models\ndof_sal_scores = []\ndof_sal = ['Salinity 1', 'Salinity 2', 'Salinity 3', 'Salinity 4', 'Salinity 5', 'Salinity 6', 'Salinity 7', 'Salinity 8', 'Salinity 9', 'Salinity 10']\nfor i in range(10):\n    dof_sal_scores.append(five_fold_cv(LogisticRegression(random_state = RANDOM_STATE), salinities[dof_sal[:i + 1]], train['Presence'], verbose = False))\n\n# Create graph of cross validation scores\nplt.plot(range(1, 11), dof_sal_scores, label = 'Salinity Model')\nplt.plot(range(1, 11), dof_temp_scores, label = 'Temperature Model')\nplt.xlabel('Degrees of Freedom')\nplt.ylabel('Cross Validation Score')\nplt.title('Cross Validation Scores For Polynomial Salinity and Temperature Models')\nplt.show()","b506e1e0":"degrees = 6\n\n# Cross validation\nfive_fold_cv(LogisticRegression(random_state = RANDOM_STATE), temperatures[dof_temp[:degrees]], train['Presence'])\n\n# Feature extraction from the test data (test data has already been scaled)\ntest_temperatures = pd.DataFrame()\nfor i in range(1, degrees + 1):\n    test_temperatures['Temperature ' + str(i)] = X_test['Temperature_today'] ** i\n\n# Building the actual model\nmodel = LogisticRegression(random_state = RANDOM_STATE)\nmodel.fit(temperatures[dof_temp[:degrees]], train['Presence'])\n\n# View coefficients\nprint()\nprint('Coefficients:', model.coef_)\nprint('Intercept:   ', model.intercept_)","62371efb":"# Make predictions\npreds = model.predict_proba(test_temperatures)\npreds = [x[1] for x in preds]\n\n# Save preds to file\nres = pd.DataFrame()\nres['pointid'] = test['pointid']\nres['Presence'] = preds\nres.to_csv('predictions.csv', index = False)","fbfb4f3c":"From this graph, it is evident that the salinity models do not perform as well as the temperature models. The salinity models achieves an approximate score of 0.58, plateauing at 2 degrees of freedom. The temperature models achieve an approximate score of 0.89 as you approach 10 degrees of freedom, but plateau before that (at around 6 degrees of freedom).\n\n# Our Chosen Model\nFrom the models we have created we can choose a model for making predictions. We will choose the temperature model with 6 degrees of freedom as that is where our model begins to plateau. We will perform cross validation again to see how it performs on each fold, and then use a completely fitted model to generate our predictions.","ff33e950":"# Baselines\nTo compare the performance of the models we create in this notebook we create two different baseline models. The first is a logistic regression model using the data given in train.csv. The second is a logistic regression model using only the temperature feature. One important observation is that the temperature model only scores 0.59823 with ROC-AUC (any models in this notebook that use temperature should ideally be beating that score).","02fd5ffb":"After creating these features, we then create different logistic regression models using these features. Model scores are compared on a simple plot to show how the cross validation score changes as we increase the degrees of freedom (number of polynomial features).","239c85fa":"# Fill In Missing Values\nAs there are many NaN values within the training and test data, they need to be handled before we can create a model. To get values for these, we use the Iterative Imputer from sklearn.","583d0f19":"# Import Data\nFirstly we import the training and test data. They are both put into seperate dataframes with pointid and presence removed, so that they can be used for fitting models, etc.","94dbdff1":"# Salinity\nThe same method can be repeated for salinity. We have not repeated the baseline for salinity, as you will find it is the same as the first point plotted on the graph (where only the 'Salinity 1' feature is used). This time in the graph we have compared the models using salinity and temperature.","076a0080":"With that we have created our final model. Since we are using logistic regression we can express this model as an equation, given below:\n$$ p(Shrimp) = \\frac{1}{1 + e^{-f(t)}}$$  \n\n$$ f(t) = -10.52910058 + 2.21529641*t - 0.57623745*t^2 - 2.06832485*t^3\\\\ + 0.30713969*t^4 - 2.21781761*t^5 - 1.85363275*t^6$$\n\nAll there is left to do at this point is to make our predictions on the test set, which is done below.","89fe2607":"# Five Fold Cross Validation Function\nThis cross validation function has been written just to make the rest of the notebook simpler to do. When the function is called, 5-fold stratified cross validation is performed with the given model. Verbose mode will output the ROC-AUC score for each fold as well as the mean score across all folds. The mean score is returned regardless.","62def8d3":"# Different Polynomials For Temperature\nTo improve our logistic regression model we create different polynomial features for temperature. These are from powers 1 to 7 as well as 0.5 and 1.5. We could create further polynomial features, or even apply different functions such as a logarithmic function if we wanted to."}}