{"cell_type":{"4d43e374":"code","93a29791":"code","bf31c7f5":"code","2dfab3ae":"code","9e3a9417":"code","c779ee37":"code","c252a112":"code","a5355600":"code","208fc8e1":"code","73e345c4":"code","229b8bb2":"code","10405d7f":"code","2546d23c":"code","9f96aa9c":"code","dac63956":"code","6c31184d":"code","1e35c9de":"code","61af1909":"code","7f448178":"code","13a5e53d":"code","9283d4af":"code","bbdddf7a":"code","fc2957ec":"code","c356b49c":"code","f615b9ed":"code","1143f1bf":"code","870dbb2e":"code","3589a034":"markdown","cdad0991":"markdown","430bfd82":"markdown","329187f1":"markdown","ce441d8d":"markdown","9ff34475":"markdown","f0b2f1fc":"markdown","6c9f0d2f":"markdown","a5e3f430":"markdown","db7eac04":"markdown","adfbfe18":"markdown","87ce5176":"markdown","4f838fff":"markdown","da468fa7":"markdown","d25e5629":"markdown","a90dbaba":"markdown","0efa1dda":"markdown","ae607c79":"markdown","6ce7205d":"markdown","f01166ac":"markdown","0bf49ca9":"markdown","5cbf16df":"markdown"},"source":{"4d43e374":"from collections import defaultdict\nfrom itertools import combinations\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline","93a29791":"class pairwise_association_mining:\n    def __init__(self, list_of_sets, threshold, min_count):\n        \"\"\"\n        * Accepts a list of sets of unique items as input\n        * Uses Bayes Rule to calculate the probability of\n          co-occurence between items\n        * Only works on unique items with user-specified\n          minimum number of co-occurrences\n        * Prints item pairs with probability\n          greater than user-specified threshold\n        \n        Args:\n            list_of_sets: list of unique items\n            threshold: minimum probability of co-occurrence\n            min_count: minimum number of co-occurrences\n        Raises:\n            Assertion errors for incorrect input types\n        Returns:\n            Prints co-occurence probability for each item pair\n        \"\"\"\n        assert isinstance(list_of_sets, list), \"list_of_sets must be a list of sets\"\n        assert isinstance(list_of_sets[0], set), \"list_of_sets must be a list of sets\"\n        assert isinstance(threshold, float) and threshold > 0  and threshold < 1, \"threshold must be between 0 and 1\"\n        assert isinstance(min_count, int), \"min_count must be an int\"\n        \n        self.list_of_sets = list_of_sets\n        self.threshold = threshold\n        self.min_count = min_count\n        \n        self.pair_counts = defaultdict(int)\n        self.item_counts = defaultdict(int)\n        \n        self.rules = dict()\n        self.find_assoc_rules()\n        \n        self.pairwise_confidence = {pair:self.rules[pair] for pair in self.rules.keys() \\\n                             if self.item_counts[pair[0]] >= self.min_count}\n        \n    def update_pair_counts(self, itemset):\n        \"\"\"\n        Updates a dictionary of pair counts for\n        all pairs of items in a given itemset.\n        \"\"\"\n        for a,b in combinations(itemset,2):\n            self.pair_counts[(a,b)] += 1\n            self.pair_counts[(b,a)] += 1\n            \n    def update_item_counts(self, itemset):\n        \"\"\"\n        Updates a dictionary of item counts for\n        all pairs of items in a given itemset.\n        \"\"\"\n        for item in itemset:\n            self.item_counts[item] += 1\n            \n    def filter_rules_by_conf(self):\n        \"\"\"\n        Filters out pairs whose confidence is\n        below the user defined threshold.\n        \"\"\"\n        for (a,b) in self.pair_counts:\n            confidence = self.pair_counts[(a,b)] \/ self.item_counts[a]\n            if confidence >= self.threshold:\n                self.rules[(a,b)] = confidence\n\n    def find_assoc_rules(self):\n        \"\"\"\n        Set final rules dictionary using\n        pairs that appear together with\n        confidence greater than or equal to\n        the user defined threshold.\n        \"\"\"\n        for itemset in self.list_of_sets:\n            self.update_pair_counts(itemset)\n            self.update_item_counts(itemset)\n        rules = self.filter_rules_by_conf()\n        return rules\n    \n    @staticmethod\n    def gen_rule_str(a, b, val=None, val_fmt='{:.3f}', sep=\" = \"):\n        text = \"{} => {}\".format(a, b)\n        if val:\n            text = \"conf(\" + text + \")\"\n            text += sep + val_fmt.format(val)\n        return text\n\n    def print_rules(self):\n        \"\"\"\n        Pretty print pairwise associations\n        \"\"\"\n        from operator import itemgetter\n        ordered_rules = sorted(self.pairwise_confidence.items(), key=itemgetter(1), reverse=True)\n        for (a, b), conf_ab in ordered_rules:\n            print(self.gen_rule_str(a, b, conf_ab))","bf31c7f5":"df = pd.read_csv('..\/input\/BreadBasket_DMS.csv')\ndf.head()","2dfab3ae":"df.info()","9e3a9417":"df['Date'] = pd.to_datetime(df['Date'])\ndf['Time'] = pd.to_datetime(df['Time'], format='%H:%M:%S')\ndf['Day'] = df['Date'].dt.day_name()\ndf['Hour'] = df['Time'].dt.hour\ndf['Time'] = df['Time'].dt.time","c779ee37":"df.head()","c252a112":"df.info()","a5355600":"df.Item.unique()","208fc8e1":"df.groupby('Item', as_index=False)['Transaction'].\\\ncount().sort_values(by='Transaction', ascending=False)[:20].plot(x='Item', kind='bar')\nplt.title('Number of Transactions by Item')\nplt.ylabel('Transactions')\nplt.tight_layout()","73e345c4":"df = df[df['Item']!='NONE']","229b8bb2":"df.groupby('Date')['Transaction'].count().reset_index().plot(x='Date', y='Transaction')\nplt.title('Number of Transactions Vs. Date')\nplt.ylabel('Transactions')\nplt.tight_layout()","10405d7f":"df.groupby('Date', as_index=False)['Transaction'].count().\\\nsort_values(by='Transaction').reset_index().drop('index',axis=1).iloc[0]","2546d23c":"df.groupby('Date', as_index=False)['Transaction'].count().\\\nsort_values(by='Transaction', ascending=False).reset_index().drop('index',axis=1).iloc[0]","9f96aa9c":"df.groupby('Day')['Transaction'].count().reset_index().plot(x='Day', y='Transaction', kind='bar', legend=None, color='#1f77b4')\nplt.title('Number of Transactions by Day')\nplt.ylabel('Transactions')\nplt.tight_layout()","dac63956":"coffee = df[df['Item']=='Coffee']\ncoffee.groupby('Day')['Transaction'].count().reset_index().plot(x='Day', y='Transaction', kind='bar', legend=None, color='#1f77b4')\nplt.title('Number of Coffee Transactions by Day')\nplt.ylabel('Transactions')\nplt.tight_layout()","6c31184d":"bread = df[df['Item']=='Bread']\nbread.groupby('Day')['Transaction'].count().reset_index().plot(x='Day', y='Transaction', kind='bar', legend=None, color='#1f77b4')\nplt.title('Number of Bread Transactions by Day')\nplt.ylabel('Transactions')\nplt.tight_layout()","1e35c9de":"transactions_per_day = df.groupby(['Date', 'Day'])['Transaction'].\\\ncount().reset_index()\n\ntransactions_per_day.groupby('Day')['Transaction'].mean().reset_index().\\\nplot(x='Day', y='Transaction', kind='bar', legend=None, color='#1f77b4')\nplt.title('Average Number of Transactions by Day')\nplt.ylabel('Transactions')\nplt.tight_layout()","61af1909":"transactions_per_day.groupby('Day')['Transaction'].min().reset_index().\\\nplot(x='Day', y='Transaction', kind='bar', legend=None, color='#1f77b4')\nplt.title('Minimum Number of Transactions by Day')\nplt.ylabel('Transactions')\nplt.tight_layout()","7f448178":"df[df['Date']=='2017-01-01']['Day']","13a5e53d":"transactions_per_day.groupby('Day')['Transaction'].max().reset_index().\\\nplot(x='Day', y='Transaction', kind='bar', legend=None, color='#1f77b4')\nplt.title('Maximum Number of Transactions by Day')\nplt.ylabel('Transactions')\nplt.tight_layout()","9283d4af":"df.groupby('Hour')['Transaction'].count().reset_index().\\\nplot(x='Hour', y='Transaction', kind='bar', legend=None, color='#1f77b4')\nplt.title('Number of Transactions by Hour')\nplt.ylabel('Transactions')\nplt.tight_layout()","bbdddf7a":"transactions_per_time = df.groupby(['Date', 'Hour']).count().reset_index()\n\ntransactions_per_time.groupby('Hour')['Transaction'].mean().reset_index().\\\nplot(x='Hour', y='Transaction', kind='bar', legend=None, color='#1f77b4')\n\nplt.title('Average Number of Transactions by Hour')\nplt.ylabel('Transactions')\nplt.tight_layout()","fc2957ec":"checkout_list = defaultdict(list)\ntrans = dict()\nfor row in df.groupby(by='Transaction').\\\nfilter(lambda x: len(x['Item']) >= 1)[['Transaction','Item']].itertuples():\n    checkout_list[row.Transaction].append(row.Item)","c356b49c":"# Confidence threshold\nTHRESHOLD = 0.7\n\n# Only consider rules for items appearing at least `MIN_COUNT` times.\nMIN_COUNT = 5","f615b9ed":"bakery_itemset = [set(lst) for lst in checkout_list.values()]\npam = pairwise_association_mining(bakery_itemset, THRESHOLD, MIN_COUNT)\npam.print_rules()","1143f1bf":"youdoyou1 = df[df['Item'] == 'Extra Salami or Feta']\nyoudoyou2 = df.loc[df['Item'] == 'Coffee', ['Transaction','Item']]\nyoudoyou2.head()","870dbb2e":"youdoyou2['Item2'] = youdoyou2.Transaction.\\\nmap(pd.Series(youdoyou1.Item.values,index=youdoyou1.Transaction).to_dict())\nyoudoyou2.dropna().drop_duplicates(['Transaction']).\\\nreset_index().drop('index',axis=1).iloc[-2:]","3589a034":"New Years Day obviously fell on a Sunday in 2017...","cdad0991":"Now that we have our dictionary of lists containing items purchased during the same transaction, let's apply Baye's Rule! Feel free to play around with the `THRESHOLD` and `MIN_COUNT` parameters.","430bfd82":"# Exploratory Data Analysis\n\nLet's explore the data! First lets look at the items sold at this bakery.","329187f1":"Sure enough. What day were sales the highest?","ce441d8d":"Lovebirds getting ready for Valentines day? Maybe...","9ff34475":"Looks like this bakery is actually busier during the lunch hours. What about the expected number of transactions per hour?","f0b2f1fc":"Looks like weekends are the most popular. What about the worst case scenario?","6c9f0d2f":"Sure enough... 30 unique transactions of Extra Salami or Feta and Coffee... what a time to be alive!","a5e3f430":"What about the best case scenario?","db7eac04":"Pretty standard fare. Let's examine the best sellers.","adfbfe18":"# Preprocess `Date` and `Time`\n\nLet's convert these to datetime and time types.","87ce5176":"# Load Data","4f838fff":"That's interesting! Our data appears to be somewhat bimodal in nature with the peak during lunchtime and early-afternoon hours and another mini-rush during the dinner hours.","da468fa7":"Next let's look at the trend of number of transactions.","d25e5629":"Saturday looks like the prime day to go to the bakery! What about coffee and bread sales by day?","a90dbaba":"# Time of Day\n\nIt's a bakery so my hypothesis is that they are busier in the mornings. Let's see if this is reflected in the data.","0efa1dda":"Sums are fine and dandy but what about the expected number of transactions by day of the week?","ae607c79":"# Day of Week Sales Analysis\n\nLet's explore the relationship between sales and the day of the week.","6ce7205d":"Top 5 make the most sense. I wonder what the NONE values represent? Maybe customers just getting cash back? Regardless, we should probably exclude these transactions from our analysis.","f01166ac":"Enough with the visualizations! Let's figure out which items are most likely to be sold together. We'll use our good old friend Bayes Rule:\n\n$$\nP\\left(A | B\\right) = \\frac{P\\left(B | A\\right)P\\left(A\\right)}{P\\left(B\\right)}\n$$\n\nAnd the class we wrote out above. Ignore my lack of adherence to PEP 8.","0bf49ca9":"The dip right at the new year is most likely due to the New Years Day holiday.","5cbf16df":"Extra Salami or Feta and Coffee? You do you! "}}