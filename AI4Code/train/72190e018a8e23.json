{"cell_type":{"f3e933fb":"code","bf00ea0e":"code","61788ffe":"code","7e828b1f":"code","229767fd":"code","474487ee":"code","ec316e70":"code","f23303b0":"code","f4d41fd6":"code","b1089ba7":"code","689900d5":"code","8c94d042":"code","7c9e0209":"code","ca04af3c":"code","c2a92be2":"code","48c9b67a":"code","17e66b60":"code","4a543a33":"markdown","fc4ee859":"markdown"},"source":{"f3e933fb":"!pip install -U lightautoml >> \/dev\/null","bf00ea0e":"# Standard python libraries\nimport os\nimport time\nimport re\n\n# Installed libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import train_test_split\n\n# Imports from our package\nfrom lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\nfrom lightautoml.tasks import Task\nfrom lightautoml.dataset.roles import NumericRole\n\n\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import preprocessing\nfrom sklearn.metrics import log_loss\n\nimport gc\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport tensorflow.keras.backend as K\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import activations,callbacks\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras import initializers\n\nfrom keras.models import Model\n\nimport warnings\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore', category=RuntimeWarning)\nwarnings.filterwarnings('ignore', category=UserWarning)","61788ffe":"N_THREADS = 4 \nN_FOLDS = 5 \nRANDOM_STATE = 42 \nTEST_SIZE = 0.2 \nTIMEOUT = 2*3600 \nTARGET_NAME = 'target'","7e828b1f":"train_data = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/train.csv')\ntrain_data[TARGET_NAME] = train_data[TARGET_NAME].str.slice(start=6).astype(int) - 1\ntargets = pd.get_dummies(train_data[TARGET_NAME])","229767fd":"test_data = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/test.csv')\nsubmission = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/sample_submission.csv')","474487ee":"def custom_metric(y_true, y_pred):\n    y_pred = K.clip(y_pred, 1e-15, 1-1e-15)\n    loss = K.mean(cce(y_true, y_pred))\n    return loss","ec316e70":"cce = tf.keras.losses.CategoricalCrossentropy()\n\nes = tf.keras.callbacks.EarlyStopping(\n    monitor='val_custom_metric', min_delta=1e-05, patience=5, verbose=0,\n    mode='min', baseline=None, restore_best_weights=True)\n\nplateau = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_custom_metric', factor=0.7, patience=2, verbose=0,\n    mode='min')","f23303b0":"def conv_model():\n\n    conv_inputs = layers.Input(shape = (75))\n    #----------- Embedding layers ----------------------\n    embed = layers.Embedding (input_dim = 354, \n                              output_dim = 7,\n                              embeddings_regularizer='l2')(conv_inputs)\n    #----------- Convolution layers ----------------------\n    embed = layers.Conv1D(12,1,activation = 'relu')(embed)        \n    embed = layers.Flatten()(embed)\n    hidden = layers.Dropout(0.3)(embed)\n    \n    #----------- Residual blocks layers ----------------------\n    hidden = tfa.layers.WeightNormalization(\n                layers.Dense(\n                units=32,\n                activation ='selu',\n                kernel_initializer = \"lecun_normal\"))(hidden)\n    \n    output = layers.Dropout(0.3)(layers.Concatenate()([embed, hidden]))\n    output = tfa.layers.WeightNormalization(\n    layers.Dense(\n                units = 32,\n                activation='relu',\n                kernel_initializer = \"lecun_normal\"))(output) \n    output = layers.Dropout(0.4)(layers.Concatenate()([embed, hidden, output]))\n    output = tfa.layers.WeightNormalization(\n    layers.Dense(\n                units = 32, \n                activation = 'elu',\n                kernel_initializer = \"lecun_normal\"))(output)\n    \n    #----------- Final layer -----------------------\n    conv_outputs = layers.Dense(\n                units = 9, \n                activation ='softmax',\n                kernel_initializer =\"lecun_normal\")(output)\n    \n    #----------- Model instantiation  ---------------\n    model = Model(conv_inputs,conv_outputs)\n    \n    return model","f4d41fd6":"oof_NN_a = np.zeros((train_data.shape[0],9))\npred_NN_a = np.zeros((test_data.shape[0],9))\n\nN_FOLDS = 20\nSEED = 2021\nEPOCH = 50\n\n\nskf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n\nfor fold, (tr_idx, ts_idx) in enumerate(skf.split(train_data,train_data.iloc[:,-1])):\n    print(f\"\\n ====== TRAINING FOLD {fold} =======\\n\")\n\n    X_train = train_data.iloc[:,1:-1].iloc[tr_idx]\n    y_train = targets.iloc[tr_idx]\n    X_test = train_data.iloc[:,1:-1].iloc[ts_idx]\n    y_test = targets.iloc[ts_idx]\n\n    K.clear_session()\n\n    #================= NN CONV MODEL training =========\n    \n    print(\"\\n-----Convolution model Training----\\n\")\n\n    model_conv = conv_model()\n\n    model_conv.compile(loss='categorical_crossentropy', \n                            optimizer = keras.optimizers.Adam(learning_rate=2e-4), \n                            metrics=custom_metric)\n    model_conv.fit(X_train, y_train,\n              batch_size = 256, epochs = EPOCH,\n              validation_data=(X_test, y_test),\n              callbacks=[es, plateau],\n              verbose = 0)\n   \n    #============== Convolution Model prediction ==========\n\n    pred_a = model_conv.predict(X_test) \n    oof_NN_a[ts_idx] += pred_a \n    score_NN_a = log_loss(y_test, pred_a)\n    print(f\"\\nFOLD {fold} Score convolution model: {score_NN_a}\\n\")\n    pred_NN_a += model_conv.predict(test_data.iloc[:,1:]) \/ N_FOLDS \n\n\nscore_a = log_loss(targets, oof_NN_a)\nprint(f\"\\n=== FINAL SCORE CONVOLUTION MODEL : {score_a}===\\n\") ","b1089ba7":"cols = [f'Class_{x+1}' for x in range(9)]","689900d5":"OOF_PREDS_NN = pd.DataFrame(oof_NN_a, columns=cols)\nTEST_PREDS_NN = pd.DataFrame(pred_NN_a, columns=cols)","8c94d042":"for col in cols:\n    train_data[col] = OOF_PREDS_NN[col]\n    test_data[col] = TEST_PREDS_NN[col]","7c9e0209":"%%time\n\ntask = Task('multiclass',metric = custom_metric, greater_is_better = False)","ca04af3c":"%%time\n\nroles = {\n    'target': TARGET_NAME,\n    'drop': ['id'],\n}","c2a92be2":"%%time \n\nroles = {\n    'target': TARGET_NAME,\n    'drop': ['id'],\n    NumericRole(np.float32, prob = True): cols\n}\n\nautoml = TabularUtilizedAutoML(task = task, \n                       timeout = TIMEOUT,\n                       cpu_limit = N_THREADS,\n                       general_params = {\n                           'use_algos': [['lgb_tuned', 'cb_tuned']],\n                       },\n                       tuning_params = {'max_tuning_time': 1800},\n                       reader_params = {'n_jobs': N_THREADS},\n                       configs_list = ['..\/input\/lightautoml-configs\/conf_1_sel_type_1.yml'],\n                       max_runs_per_config=1\n                       )\noof_pred = automl.fit_predict(train_data, roles = roles)\nprint('oof_pred:\\n{}\\nShape = {}'.format(oof_pred[:10], oof_pred.shape))","48c9b67a":"test_pred = automl.predict(test_data)","17e66b60":"submission.iloc[:, 1:] = test_pred.data\nsubmission.to_csv('TPS_June_lightautoml_v5.csv', index = False)","4a543a33":"<center> <h2> <b> Light AutoML <\/b> <\/h2><\/center>","fc4ee859":"This notebook is starter code to explore automl and optuna models, more tweekings can improve scores. Will try experiment with more packages.  \nFollowing AutoML and Optuna models are tried:\n<ol type=\"1\">\n<li>Player-1 (Version 5): <b>H2O AutoML<\/b> <\/li>\n<li>Player-2 (Version 6): <b>Auto Keras<\/b><\/li>\n<li>Player-3 (Version 9): <b>Auto Glucon<\/b><\/li>\n<li>Player-4 (Version 13): <b>XGBoost with Optuna<\/b><\/li>   \n<li>Player-5 (Version 14): <b>CatBoost with Optuna<\/b><\/li>  \n<li>Player-6 (Version 15): <b>TPOT<\/b><\/li> \n<li>Player-7 (Version 18): <b>Light AutoML<\/b><\/li>\n<\/ol>  \n\nThis notebook is completely inspired from approach by <b>Alexander Ryzhkov's<\/b> <a href=\"https:\/\/www.kaggle.com\/alexryzhkov\/lightautoml-baseline-tps-june-2021\">notebook<\/a> and <b>Laurent Pourchot's<\/b> <a href=\"https:\/\/www.kaggle.com\/pourchot\/simple-neural-network\/notebook\"> notebook<\/a>"}}