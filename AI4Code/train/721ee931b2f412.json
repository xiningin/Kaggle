{"cell_type":{"908a114f":"code","d05b89d1":"code","339a68f2":"code","bf880a7e":"code","5ffeabf2":"code","f3851e3d":"code","5844c1eb":"code","6af23034":"code","c9e93fac":"code","46a0520c":"code","bdc9d5e8":"code","6198d8ae":"code","7ac59cb3":"code","3b5668eb":"code","bc994951":"code","6625f447":"code","84a55a11":"markdown","f06805ce":"markdown","f84464f7":"markdown","da95750a":"markdown","cf1ac78f":"markdown","694b2419":"markdown","3edd8145":"markdown","b2ed2ae5":"markdown","1ffcae17":"markdown","01e91424":"markdown","71d25be5":"markdown","eecdd6ae":"markdown","49c1579a":"markdown","11819a9e":"markdown","a803a718":"markdown"},"source":{"908a114f":"!pip install imutils","d05b89d1":"# import the necessary packages\nfrom keras.models import Sequential \nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation\nfrom keras.layers.core import Dense\nfrom keras.layers.core import Flatten\nfrom keras.layers.core import Dropout\nfrom keras import backend as K \n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import img_to_array\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot  as plt \nfrom imutils import paths \nimport imutils\nimport numpy as np \nimport random \nimport pickle \nimport cv2 \nimport os ","339a68f2":"class SmallVGGNet:\n    @staticmethod\n    def build(width, heigth, depth, classes):\n        # initialize the model along with the input shape to be\n        # \"channels last\" and the channels dimension itself\n        model = Sequential()\n        inputShape = (width, heigth, depth)\n        chanDim = -1\n\n        # if we are using \"channels first\", update the input shape and channels dimension\n        if K.image_data_format() == \"channels_first\":\n            inputShape = (depth, width, heigth)\n            chanDim = 1\n\n        # CONV => RELU => POOL\n        model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=inputShape))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(MaxPooling2D(pool_size=(3,3)))\n        model.add(Dropout(0.25))\n\n        # (CONV => RELU) * 2 => POOL\n        model.add(Conv2D(64, (3,3), padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(Conv2D(64, (3,3), padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(MaxPooling2D(pool_size=(2,2)))\n        model.add(Dropout(0.25))\n\n        # (CONV => RELU) * 2 => POOL\n        model.add(Conv2D(128, (3,3), padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(Conv2D(128, (3,3), padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(MaxPooling2D(pool_size=(2,2)))\n        model.add(Dropout(0.25))\n\n        # first (and only) set of FC => RELU layers\n        model.add(Flatten())\n        model.add(Dense(1024))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization())\n        model.add(Dropout(0.5))\n\n        # softmax classifier\n        model.add(Dense(classes))\n        model.add(Activation(\"softmax\"))\n\n        # return the constructed network architecture\n        return model","bf880a7e":"EPOCHS = 10\nINIT_LR = 1e-3\nBS = 32\nIMAGE_DIMS = (96, 96, 3)","5ffeabf2":"data = []\nlabels = []","f3851e3d":"print(\"[INFO] loading images...\")\nimagePaths = sorted(list(paths.list_images(\"\/kaggle\/input\/the-simpsons-characters-dataset\/simpsons_dataset\/simpsons_dataset\/\")))\nrandom.seed(42)\nrandom.shuffle(imagePaths)","5844c1eb":"for imagePath in imagePaths:\n    # load the image, pre-process it, and store it in the data list\n    image = cv2.imread(imagePath)\n    image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n    image = img_to_array(image)\n    data.append(image)\n\n    # extract the class label from the image path and update the labels list\n    label = imagePath.split(os.path.sep)[-2]\n    labels.append(label)","6af23034":"data = np.array(data, dtype=\"float\") \/ 255.0\nlabels = np.array(labels)\nprint(\"[INFO] data matrix: {:.2f}MB\".format(data.nbytes \/ (1024 * 1000.0)))","c9e93fac":"lb = LabelBinarizer()\nlabels = lb.fit_transform(labels)","46a0520c":"(train_X, val_X, train_Y, val_Y) = train_test_split(data, labels, test_size=0.2, random_state=42)","bdc9d5e8":"aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n                         height_shift_range=0.1, shear_range=0.2,\n                         horizontal_flip=True, fill_mode=\"nearest\")","6198d8ae":"print(\"[INFO] compiling model...\")\nmodel = SmallVGGNet.build(width=IMAGE_DIMS[1], heigth=IMAGE_DIMS[0],\n                          depth=IMAGE_DIMS[2], classes=len(lb.classes_))\nopt = Adam(lr=INIT_LR, decay=INIT_LR \/ EPOCHS)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])","7ac59cb3":"print(\"[INFO] training network...\")\nH = model.fit_generator(aug.flow(train_X, train_Y, batch_size=BS),\n                        validation_data=(val_X, val_Y),\n                        steps_per_epoch=len(train_X) \/\/ BS,\n                        epochs=EPOCHS, verbose=1)","3b5668eb":"plt.style.use(\"ggplot\")\nplt.figure()\nN = EPOCHS\nplt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss\/Accuracy\")\nplt.legend(loc=\"upper left\")","bc994951":"def get_pred_res(file):\n    image = cv2.imread(character_image)\n    output = image.copy()\n    #print(f\"[INFO] character image:  {character_image.split(os.path.sep)[-1]}\")\n    \n    # pre-process the image for classification\n    image = cv2.resize(image, (96, 96))\n    image = image.astype(\"float\") \/ 255.0\n    image = img_to_array(image)\n    image = np.expand_dims(image, axis=0)\n    \n    # classify the input image\n    #print(\"[INFO] classifying image...\")\n    proba = model.predict(image)[0]\n    idx = np.argmax(proba)\n    label = lb.classes_[idx]\n    \n    filename = \"_\".join(character_image.split(os.path.sep)[-1].split(\".\")[0].split(\"_\")[:-1])\n    correct = \"correct\" if filename == label else \"incorrect\"\n    \n    label = \"{}: {:.2f}% ({})\".format(label, proba[idx] * 100, correct)\n    output = imutils.resize(output, width=400)\n\n    return label, output\n    #plt.imshow(output)","6625f447":"character_image = random.choice(list(paths.list_images(\"\/kaggle\/input\/the-simpsons-characters-dataset\/kaggle_simpson_testset\/kaggle_simpson_testset\")))\nlabel, output = get_pred_res(character_image)\nplt.title(label)\nplt.imshow(output)","84a55a11":"# Loop over the input images","f06805ce":"# Initialize the data and labels","f84464f7":"# load the image","da95750a":"# Scale the raw pixel intensities to the range [0, 1]","cf1ac78f":"# Construct the image generator for data augmentation","694b2419":"# Grab the image paths and randomly shuffle them","3edd8145":"# Partition the data into training and validation splits using 80% of the data for training and the remaining 20% for valid","b2ed2ae5":"# Initialize the number of epochs to train for, initial learning rate, batch size, and image dimensions","1ffcae17":"# Showing what we get","01e91424":"# Binarize the labels","71d25be5":"# Traing the network","eecdd6ae":"# Initialize the model","49c1579a":"# Let's look to our result","11819a9e":"# Get predict","a803a718":"# Build our model"}}