{"cell_type":{"48ac41b6":"code","90ab5230":"code","f574ec1b":"code","c3714f57":"code","12c1eab5":"code","9cf65a95":"code","535336e0":"code","0ef70035":"code","ac1c193a":"code","fbb4ad21":"code","a9d19f92":"code","f13803ef":"code","c7507732":"code","0ff40492":"code","33a62ecc":"code","029bfe97":"code","04253b48":"code","16ca0024":"code","a3a1fbb7":"code","08098fc2":"code","b7bbdbf1":"code","ed70ca5e":"markdown","dae82547":"markdown","19e2b1af":"markdown","806bb0f2":"markdown","ad16f881":"markdown","3cbdc446":"markdown"},"source":{"48ac41b6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # for data visualization\nimport seaborn as sns\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import MinMaxScaler\nsns.set(style='darkgrid')\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","90ab5230":"orgData = pd.read_csv(\"\/kaggle\/input\/breast-cancer-wisconsin-data\/data.csv\")\norgData.head()","f574ec1b":"orgData.isnull().count().count()","c3714f57":"orgData.drop('Unnamed: 32', axis=1, inplace=True)\norgData.drop('id', axis=1, inplace=True)\norgData.head()","12c1eab5":"orgData.info()","9cf65a95":"## Plotting the bar char to identify the frequnecy of values\nsns.countplot(orgData[\"diagnosis\"])\n##prinitng number of values for each type\nprint(orgData[\"diagnosis\"].value_counts())","535336e0":"diag_binary = {'M': 1,'B': 0}\norgData[\"diagnosis\"]= [diag_binary[item] for item in orgData[\"diagnosis\"]]\norgData.head()","0ef70035":"orgData.describe()","ac1c193a":"fig, ax = plt.subplots(3, 4, figsize=(20, 10))\nbatch1=['radius_mean','texture_mean','perimeter_mean','area_mean','smoothness_mean','compactness_mean','concavity_mean','concave points_mean','concave points_worst','symmetry_worst','fractal_dimension_worst']\nfor variable, subplot in zip(batch1, ax.flatten()):\n    sns.boxplot(orgData[variable], ax=subplot)\n    for label in subplot.get_xticklabels():\n        label.set_rotation(0)","fbb4ad21":"fig, ax = plt.subplots(4, 5, figsize=(20, 10))\nbatch1=['symmetry_mean','fractal_dimension_mean','radius_se','texture_se','perimeter_se','area_se','smoothness_se', 'compactness_se','concavity_se','concave points_se' , 'concavity_se','concave points_se','symmetry_se','fractal_dimension_se','radius_worst','texture_worst', 'perimeter_worst','area_worst','smoothness_worst','compactness_worst','concavity_worst']\nfor variable, subplot in zip(batch1, ax.flatten()):\n    sns.boxplot(orgData[variable], ax=subplot)\n    for label in subplot.get_xticklabels():\n        label.set_rotation(0)","a9d19f92":"orgData.shape","f13803ef":"Q1 = orgData.quantile(0.25)\nQ3 = orgData.quantile(0.75)\nIQR = Q3 - Q1\n\ndf = orgData[~((orgData < (Q1 - 1.5 * IQR)) |(orgData > (Q3 + 1.5 * IQR))).any(axis=1)]\norgData=pd.DataFrame(df)\norgData.shape","c7507732":"## Applying Min Max scaller makes more sense\nscaler = MinMaxScaler()\nMinMaxData = pd.DataFrame(scaler.fit_transform(orgData),columns=orgData.columns.values)\nMinMaxData.head()","0ff40492":"y=MinMaxData[\"diagnosis\"]\nMinMaxData=MinMaxData.drop('diagnosis',axis = 1 )","33a62ecc":"y.head()","029bfe97":"f,ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(MinMaxData.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","04253b48":"corr_matrix = MinMaxData.corr().abs()\n\n#the matrix is symmetric so we need to extract upper triangle matrix without diagonal (k = 1)\nsol = (corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n                 .stack()\n                 .sort_values(ascending=False))\n#first element of sol series is the pair with the bigest correlation","16ca0024":"print(sol.head(30))","a3a1fbb7":"drop_list1 = ['perimeter_mean','radius_mean','compactness_mean','concavity_worst','concave points_mean','area_se','smoothness_mean','radius_se','perimeter_se','radius_worst','perimeter_worst','compactness_worst','concave points_worst','compactness_se','concave points_se','texture_worst','area_worst']\ndf = MinMaxData.drop(drop_list1,axis = 1 )        # do not modify x, we will use it later \ndf.head()","08098fc2":"f,ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(df.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","b7bbdbf1":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score,confusion_matrix\nfrom sklearn.metrics import accuracy_score\n\n# split data train 70 % and test 30 %\nx_train, x_test, y_train, y_test = train_test_split(df, y, test_size=0.3, random_state=42)\n\n#random forest classifier with n_estimators=10 (default)\nclf_rf = RandomForestClassifier(random_state=43)      \nclr_rf = clf_rf.fit(x_train,y_train)\n\nac = accuracy_score(y_test,clf_rf.predict(x_test))\nprint('Accuracy is: ',ac)\ncm = confusion_matrix(y_test,clf_rf.predict(x_test))","ed70ca5e":"<p> As per the above info, we can see 30 columns  are floats(Numerical Data) and 1 column(Dignosis) is Categorical Data which is Class Label, we can find the frequency of values in Class label. <\/p>","dae82547":"<h1>Data Visualization<\/h1>","19e2b1af":"**In the dataset column - \"UNNAMED:32\" has nulls and it doesn't have any contextual meaning, so we are going to remove the entire column.\nID is just an indexing column, so no need to have it in the dataset. diagnosis is the column we need to predict**","806bb0f2":"<h3> Step-1: Finding out Numerical and Categorical Data  <\/h3>","ad16f881":"From the above box plots, it is evident that except column - <b>concave points_worst<\/b> all other columns have outliers,\nso if we apply min max scaler it will affect the data\n","3cbdc446":"<p>As there are only two values in class label we can convert them into binary for our convienence <\/p>"}}