{"cell_type":{"ecc77726":"code","8e3f6ae8":"code","b4e32467":"code","e6c5d68e":"code","24554cfa":"code","d7807918":"code","d228dc55":"code","bbec859d":"code","974f11f1":"code","4cd2fe05":"code","ccf47871":"code","a4377704":"code","1c258e94":"code","6fcaf9cb":"code","f3c12e09":"code","c848a01c":"code","35ff4e6d":"code","19da0395":"code","68e1067e":"code","211eee9d":"code","b3d872da":"code","cd81746c":"code","b0bf39e8":"code","606a7dea":"code","8e075fdf":"code","0cb518c9":"code","fe0a9e2c":"code","a4f81c56":"code","ed847973":"code","ed9a3456":"code","4c319b8c":"code","cbb4032b":"code","91462a96":"code","4511132c":"code","65c680b6":"code","843f3c4c":"code","04670821":"markdown","60de48c8":"markdown"},"source":{"ecc77726":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8e3f6ae8":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","b4e32467":"filename = '\/kaggle\/input\/insurance-premium-prediction\/insurance.csv'\ndf = pd.read_csv(filename)\ndf.head()","e6c5d68e":"df.rename(columns = {'expenses':'charges'}, inplace = True) ","24554cfa":"df.head()","d7807918":"df.shape","d228dc55":"df.info()","bbec859d":"df.describe()","974f11f1":"corr = df.corr()\ncorr","4cd2fe05":"df.isnull().sum()","ccf47871":"plt.figure(figsize=(8,6))\nsns.heatmap(corr, annot = True)","a4377704":"fig, axes = plt.subplots(ncols = 3, figsize = (15,6), squeeze=True)\nplt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.4, hspace=None)\ndf.plot(kind='scatter', x='age', y='charges', ax=axes[0])\ndf.plot(kind='scatter', x='children', y='charges', ax=axes[1])\ndf.plot(kind='scatter', x='bmi', y='charges', ax=axes[2])","1c258e94":"fig, axes = plt.subplots(nrows = 2, ncols = 2, figsize = (15,10))\n\ndf.plot(kind='hist', y='age', ax=axes[0][0], color = 'blue')\ndf.plot(kind='hist', y='bmi', ax=axes[0][1], color = 'orange', bins = 54)\ndf.plot(kind='hist', y='children', ax=axes[1][0], color = 'red', bins = 6)\ndf.plot(kind='hist', y='charges', ax=axes[1][1], color = 'green', bins = 80)","6fcaf9cb":"palette=['#EB5050','#3EA2FF']\nfig, axes = plt.subplots(ncols = 3, figsize = (15,6), squeeze=True)\nsns.scatterplot(x='bmi', y='charges', ax=axes[0], data=df,hue='sex', palette=palette)\nsns.scatterplot(x='bmi', y='charges', ax=axes[1], data=df,hue='smoker', palette=palette)\nsns.scatterplot(x='bmi', y='charges', ax=axes[2], data=df,hue='region')","f3c12e09":"fig, axes = plt.subplots(ncols=3, figsize = (15,6))\ndf['sex'].value_counts().plot(kind='bar', color = 'orange', ax=axes[0],title=\"Sex\", legend = 'sex') \ndf['region'].value_counts().plot(kind='bar', color = 'green', ax=axes[1],title=\"Region\", legend = 'region')\ndf['smoker'].value_counts().plot(kind='bar', ax=axes[2],title=\"Smoker\", legend = 'smoker')\n","c848a01c":"palette=['#EB5050','#3EA2FF']\nsns.catplot(x='sex', y='charges', kind='violin', palette=palette, data=df)","35ff4e6d":"palette=['#EB5050','#2DFFAB'] \nsns.catplot(x='sex', y='charges', kind='violin', hue='smoker', palette=palette, data=df)","19da0395":"from scipy import stats\nfrom scipy.stats import norm\nfig =plt.figure(figsize=(18,6))\nplt.subplot(1,2,1)\nsns.distplot(df['charges'], fit=norm)\n(mu,sigma)= norm.fit(df['charges'])\nplt.legend(['For Normal dist. mean: {:.2f} | std: {:.2f}'.format(mu,sigma)])\nplt.ylabel('Frequency')\nplt.title('Distribution of Charges')\n","68e1067e":"palette=['#EB5050','#2DFFAB'] \nsns.set(style=\"ticks\")\nsns.pairplot(data=df, hue='smoker', palette=palette)","211eee9d":"df.head()","b3d872da":"df.drop([\"region\"], axis=1, inplace=True) \ndf.head()","cd81746c":"# Changing binary categories to 1s and 0s\ndf['sex'] = df['sex'].map(lambda s :1  if s == 'female' else 0)\ndf['smoker'] = df['smoker'].map(lambda s :1  if s == 'yes' else 0)\n\ndf.head()","b0bf39e8":"X = df.drop(['charges'], axis = 1)\ny = df.charges\nprint('Shape of X: ', X.shape)\nprint('Shape of y: ', y.shape)\n","606a7dea":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\nlr = LinearRegression().fit(X_train, y_train)\n\ny_train_pred = lr.predict(X_train)\ny_test_pred = lr.predict(X_test)\n\nprint(lr.score(X_test, y_test))","8e075fdf":"results = pd.DataFrame({'Actual': y_test, 'Predicted': y_test_pred})\nresults","0cb518c9":"# Normalize the data\nfrom sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","fe0a9e2c":"pd.DataFrame(X_train).head()","a4f81c56":"pd.DataFrame(y_train).head()","ed847973":"def model_summary(model, model_name, cvn=20): # Default value for cvn = 20\n    print(model_name)\n    y_pred_model_train = model.predict(X_train)\n    y_pred_model_test = model.predict(X_test)\n    accuracy_model_train = r2_score(y_train, y_pred_model_train)\n    print(\"Training Accuracy: \", accuracy_model_train)\n    accuracy_model_test = r2_score(y_test, y_pred_model_test)\n    print(\"Testing Accuracy: \", accuracy_model_test)\n    RMSE_model_train = sqrt(mean_squared_error(y_train, y_pred_model_train))\n    print(\"RMSE for Training Data: \", RMSE_model_train)\n    RMSE_model_test = sqrt(mean_squared_error(y_test, y_pred_model_test))\n    print(\"RMSE for Testing Data: \", RMSE_model_test)\n#     if model == polynomial_reg:\n#         polynomial_features = PolynomialFeatures(degree=3)\n#         y_pred_cv_PR = cross_val_predict(model, polynomial_features.fit_transform(X), y, cv=20)\n#     else:\n    y_pred_cv_model = cross_val_predict(model, X, y, cv=cvn)\n    accuracy_cv_model = r2_score(y, y_pred_cv_model)\n    print(\"Accuracy for\", cvn,\"- Fold Cross Predicted: \", accuracy_cv_model)","ed9a3456":"from math import sqrt \nfrom sklearn.model_selection import cross_val_predict  \nfrom sklearn.metrics import r2_score, mean_squared_error  ","4c319b8c":"from sklearn.linear_model import LinearRegression  \n\nmultiple_linear_reg = LinearRegression(fit_intercept=False)  \nmultiple_linear_reg.fit(X_train, y_train)  \nmodel_summary(multiple_linear_reg, \"Multiple_linear_Regression\")","cbb4032b":"from sklearn.svm import SVR  \n\nsupport_vector_reg = SVR(gamma=\"auto\", kernel=\"linear\", C=1000)  \nsupport_vector_reg.fit(X_train, y_train)  \nmodel_summary(support_vector_reg, \"Support_Vector_Regressor\")","91462a96":"from sklearn.preprocessing import PolynomialFeatures\n\npolynomial_features = PolynomialFeatures(degree=3)  \nx_train_poly = polynomial_features.fit_transform(X_train)  \nx_test_poly = polynomial_features.fit_transform(X_test) \n\npolynomial_reg = LinearRegression(fit_intercept=False)  \npolynomial_reg.fit(x_train_poly, y_train)  \nprint(\"PolynomialFeatures\")\ny_pred_PR_train = polynomial_reg.predict(x_train_poly)\ny_pred_PR_test = polynomial_reg.predict(x_test_poly)\naccuracy_PR_train = r2_score(y_train, y_pred_PR_train)\nprint(\"Training Accuracy: \", accuracy_PR_train)\naccuracy_PR_test = r2_score(y_test, y_pred_PR_test)\nprint(\"Testing Accuracy: \", accuracy_PR_test)\nRMSE_PR_train = sqrt(mean_squared_error(y_train, y_pred_PR_train))\nprint(\"RMSE for Training Data: \", RMSE_PR_train)\nRMSE_PR_test = sqrt(mean_squared_error(y_test, y_pred_PR_test))\nprint(\"RMSE for Testing Data: \", RMSE_PR_test)\ny_pred_cv_PR = cross_val_predict(polynomial_reg, polynomial_features.fit_transform(X), y, cv=20)\naccuracy_cv_PR = r2_score(y, y_pred_cv_PR)\nprint(\"Accuracy for 20-Fold Cross Predicted: \", accuracy_cv_PR)","4511132c":"from sklearn.tree import DecisionTreeRegressor\n\ndecision_tree_reg = DecisionTreeRegressor(max_depth=5, random_state=13)  \ndecision_tree_reg.fit(X_train, y_train) \nmodel_summary(decision_tree_reg, \"Decision_Tree_Regression\")","65c680b6":"import sklearn\nfrom sklearn import tree\nfig, ax = plt.subplots(figsize=(10, 10))\nsklearn.tree.plot_tree(decision_tree_reg)","843f3c4c":"from sklearn.ensemble import RandomForestRegressor  \n\nrandom_forest_reg = RandomForestRegressor(n_estimators=400, max_depth=5, random_state=13)  \nrandom_forest_reg.fit(X_train, y_train) \nmodel_summary(random_forest_reg, \"Random_Forest_Regression\")","04670821":"Heyy Everyone! This is my work on prediction of medical insurance. Seeking your sincere feedback on further improvement. Thank you!","60de48c8":"**The model with the highest accuracy is Random Forest compared to other models.**"}}