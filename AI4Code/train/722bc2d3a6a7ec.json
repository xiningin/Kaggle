{"cell_type":{"e209f5a3":"code","937fa0ec":"code","39be29df":"code","a5dbef26":"code","dc68738e":"code","63fe1159":"code","339e9993":"code","ab78581f":"code","27443e59":"code","82dba1fe":"code","ef047f9b":"code","bc9c6ff0":"code","380e6466":"code","c2cecdc7":"code","7bd38f59":"code","9566396c":"code","6ca07cb1":"code","51961fd7":"code","41698b71":"code","c5908930":"code","8f45bc23":"code","1eeb1cd7":"code","e6f47ad2":"code","84e44865":"code","4adb3f40":"code","93f3c1b9":"code","b3a60cb0":"code","c57eea97":"code","0c0ba85e":"code","1cc117d9":"code","dd9db4c9":"code","4654ab8c":"code","fbed7c9c":"code","3a8ddb6e":"code","40873bec":"code","553a096a":"code","94df0ef3":"code","7dd7b18c":"code","98db3025":"code","e4b7bd5e":"code","62cb9d7d":"code","06482bd8":"code","0b01f593":"code","00949576":"code","6517f0da":"code","eda83ef5":"code","9b460279":"code","f3c02565":"code","1521a6da":"code","4592f01b":"code","0605ac6c":"code","c797724c":"code","8b6a801d":"code","e3c53e15":"markdown","539585ea":"markdown","a5a166da":"markdown","386aba49":"markdown","ec1b9ad7":"markdown","9d4c8f10":"markdown","85ab56ee":"markdown","4996edd7":"markdown","fd28c130":"markdown","49630157":"markdown","40b4e41e":"markdown","c55450e0":"markdown","b1b05c5e":"markdown","c6f8dc0b":"markdown","5f4aa53d":"markdown","c1769fb6":"markdown","977adc50":"markdown","7892e760":"markdown"},"source":{"e209f5a3":"import pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport random\nimport numpy as np  # linear algebra\nimport pandas as pd  #\nfrom datetime import datetime\n\nfrom scipy.stats import skew  # for some statistics\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\n\nfrom sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.metrics import mean_squared_error\n\nfrom mlxtend.regressor import StackingCVRegressor\n\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nrandom.seed(1)","937fa0ec":"\ntrain_data = pd.read_csv('..\/input\/train.csv')\ntest_data = pd.read_csv('..\/input\/test.csv')\ntrain_data.info()\n","39be29df":"# Converting MSZoning to numerical\ntrain_data.MSZoning.value_counts(dropna = False).plot.bar()\ntrans_dict = {'RL':0,'RM':1,'FV':2,'RH':3,'C (all)':4}\ntrain_data.MSZoning = train_data.MSZoning.replace(trans_dict)\ntest_data.MSZoning = test_data.MSZoning.replace(trans_dict)","a5dbef26":"#converting LotShape to numerical\ntrain_data.LotShape.value_counts(dropna = False).plot.bar()\ntrans_dict = {'Reg':0,'IR1':1,'IR2':2,'IR3':3}\ntrain_data.LotShape = train_data.LotShape.replace(trans_dict)\ntest_data.LotShape = test_data.LotShape.replace(trans_dict)","dc68738e":"#converting Street to numerical\ntrain_data.Street.value_counts(dropna = False).plot.bar()\ntrans_dict = {'Pave':0,'Grvl':1}\ntrain_data.Street = train_data.Street.replace(trans_dict)\ntest_data.Street = test_data.Street.replace(trans_dict)\n","63fe1159":"#Handling Alley , as it has lot of NaN we will drop it.\ntrain_data.Alley.value_counts(dropna = False).plot.bar()\ntrain_data.drop('Alley',inplace = True,axis = 1) \ntest_data.drop('Alley',inplace = True,axis = 1) ","339e9993":"# Handling LandContour\ntrain_data.LandContour.value_counts(dropna = False).plot.bar()\ntrans_dict = {'Lvl':0,'Bnk':1,'HLS':2,'Low':3}\ntrain_data.LandContour = train_data.LandContour.replace(trans_dict)\ntest_data.LandContour = test_data.LandContour.replace(trans_dict)","ab78581f":"#Handling Utilities\ntrain_data.Utilities.value_counts(dropna = False).plot.bar()\n# as it has a lot of skewness towards the AllPub, we can drop it, it is not that important for the model.\ntrain_data.drop('Utilities',inplace = True,axis = 1)\ntest_data.drop('Utilities',inplace = True,axis = 1)","27443e59":"#Handling LotConfig\ntrain_data.LotConfig.value_counts(dropna = False).plot.bar()\ntrans_dict = {'Inside':0,'Corner':1,'CulDSac':2,'FR2':3,'FR3':4}\ntrain_data.LotConfig = train_data.LotConfig.replace(trans_dict)\ntest_data.LotConfig = test_data.LotConfig.replace(trans_dict)","82dba1fe":"# Handling LandSlope\ntrain_data.LandSlope.value_counts(dropna = False).plot.bar()\ntrans_dict = {'Gtl':0,'Mod':1,'Sev':2}\ntrain_data.LandSlope = train_data.LandSlope.replace(trans_dict)\ntest_data.LandSlope = test_data.LandSlope.replace(trans_dict)","ef047f9b":"#Handling Neighborhood\ntrain_data.Neighborhood.value_counts(dropna = False).plot.bar()\nle = LabelEncoder()\ntrain_data.Neighborhood = le.fit_transform(train_data.Neighborhood)\ntest_data.Neighborhood = le.transform(test_data.Neighborhood)\n","bc9c6ff0":"#Handling Condition1\ntrain_data.Condition1.value_counts(dropna = False).plot.bar()\ntrain_data.Condition1 = le.fit_transform(train_data.Condition1)\ntest_data.Condition1 = le.transform(test_data.Condition1)\n","380e6466":"#Handling Condition2\ntrain_data.Condition2.value_counts(dropna = False).plot.bar()\n# very skewed therefore we can drop it\ntrain_data.drop('Condition2',axis = 1,inplace = True)\ntest_data.drop('Condition2',axis = 1,inplace = True)\n","c2cecdc7":"#Handling BldgType \ntrain_data.BldgType.value_counts(dropna = False).plot.bar()\ntrain_data.BldgType = le.fit_transform(train_data.BldgType)\ntest_data.BldgType = le.transform(test_data.BldgType)\n","7bd38f59":"#Handling HouseStyle\nprint(train_data.HouseStyle.value_counts(dropna = False))\ntrain_data.HouseStyle.value_counts(dropna = False).plot.bar()\ntrain_data.HouseStyle = le.fit_transform(train_data.HouseStyle)\ntest_data.HouseStyle = le.transform(test_data.HouseStyle)\n","9566396c":"#Handling RoofStyle\nprint(train_data.RoofStyle.value_counts(dropna = False))\ntrain_data.RoofStyle.value_counts(dropna = False).plot.bar()\ntrain_data.RoofStyle = le.fit_transform(train_data.RoofStyle)\ntest_data.RoofStyle = le.transform(test_data.RoofStyle)\n","6ca07cb1":"#Handling RoofMatl\nprint(train_data.RoofMatl.value_counts(dropna = False))\ntrain_data.RoofMatl.value_counts(dropna = False).plot.bar()\nprint(\"Skewed towards a single feature :\",train_data.RoofMatl.value_counts()[0]\/len(train_data))\n#very skewed therefore dropping it.\ntrain_data.drop('RoofMatl',axis = 1,inplace = True)\ntest_data.drop('RoofMatl',axis = 1,inplace = True)\n","51961fd7":"#Handling Exterior1st\nprint(train_data.Exterior1st.value_counts(dropna = False))\nprint(test_data.Exterior1st.value_counts(dropna = False))\ntrain_data.Exterior1st.value_counts(dropna = False).plot.bar()\ntest_data.Exterior1st.fillna('VinylSd',inplace = True)\n# there is a lot of values which are not in train but in test therefore drop it.\nle = le.fit(train_data.Exterior1st.unique().tolist()+test_data.Exterior1st.unique().tolist())\ntrain_data.Exterior1st = le.transform(train_data.Exterior1st)\ntest_data.Exterior1st = le.transform(test_data.Exterior1st)\n","41698b71":"#Handling Exterior2nd\nprint(train_data.Exterior2nd.value_counts(dropna = False))\nprint(test_data.Exterior2nd.value_counts(dropna = False))\ntrain_data.Exterior2nd.value_counts(dropna = False).plot.bar()\ntest_data.Exterior2nd.fillna('VinylSd',inplace = True)  #filling the nan or null values in test data\nle = le.fit(train_data.Exterior2nd.unique().tolist()+test_data.Exterior2nd.unique().tolist())\ntrain_data.Exterior2nd = le.transform(train_data.Exterior2nd)\ntest_data.Exterior2nd = le.transform(test_data.Exterior2nd)\n","c5908930":"#Handling MasVnrType\nprint(train_data.MasVnrType.value_counts(dropna = False))\nprint(test_data.MasVnrType.value_counts(dropna = False))\ntrain_data.MasVnrType.value_counts(dropna = False).plot.bar()\ntest_data.MasVnrType.fillna('None',inplace = True)\ntrain_data.MasVnrType.fillna('None',inplace = True)\nle = le.fit(train_data.MasVnrType.unique().tolist()+test_data.MasVnrType.unique().tolist())\ntrain_data.MasVnrType = le.transform(train_data.MasVnrType)\ntest_data.MasVnrType = le.transform(test_data.MasVnrType)\n\n","8f45bc23":"#Handling ExterQual\nprint(train_data.ExterQual.value_counts(dropna = False))\nprint(test_data.ExterQual.value_counts(dropna = False))\ntrain_data.ExterQual.value_counts(dropna = False).plot.bar()\nle = le.fit(train_data.ExterQual.unique().tolist())\ntrain_data.ExterQual = le.transform(train_data.ExterQual)\ntest_data.ExterQual = le.transform(test_data.ExterQual)\n","1eeb1cd7":"#Handling ExterCond\nprint(train_data.ExterCond.value_counts(dropna = False))\nprint(test_data.ExterCond.value_counts(dropna = False))\ntrain_data.ExterCond.value_counts(dropna = False).plot.bar()\nle = le.fit(train_data.ExterCond.unique().tolist())\ntrain_data.ExterCond = le.transform(train_data.ExterCond)\ntest_data.ExterCond = le.transform(test_data.ExterCond)\n","e6f47ad2":"#Handling Foundation\nprint(train_data.Foundation.value_counts(dropna = False))\nprint(test_data.Foundation.value_counts(dropna = False))\ntrain_data.Foundation.value_counts(dropna = False).plot.bar()\nle = le.fit(train_data.Foundation.unique().tolist())\ntrain_data.Foundation = le.transform(train_data.Foundation)\ntest_data.Foundation = le.transform(test_data.Foundation)\n\n","84e44865":"#Handling BsmtQual\nprint(train_data.BsmtQual.value_counts(dropna = False))\nprint(test_data.BsmtQual.value_counts(dropna = False))\ntrain_data.BsmtQual.value_counts(dropna = False).plot.bar()\ntest_data.BsmtQual.fillna('TA',inplace = True)\ntrain_data.BsmtQual.fillna('TA',inplace = True)\nle = le.fit(train_data.BsmtQual.unique().tolist())\ntrain_data.BsmtQual = le.transform(train_data.BsmtQual)\ntest_data.BsmtQual = le.transform(test_data.BsmtQual)\n\n\n","4adb3f40":"#Handling BsmtCond\nprint(train_data.BsmtCond.value_counts(dropna = False))\nprint(test_data.BsmtCond.value_counts(dropna = False))\ntrain_data.BsmtCond.value_counts(dropna = False).plot.bar()\ntest_data.BsmtCond.fillna('TA',inplace = True)\ntrain_data.BsmtCond.fillna('TA',inplace = True)\nle = le.fit(train_data.BsmtCond.unique().tolist())\ntrain_data.BsmtCond = le.transform(train_data.BsmtCond)\ntest_data.BsmtCond = le.transform(test_data.BsmtCond)\n\n","93f3c1b9":"#Handling BsmtExposure\nprint(train_data.BsmtExposure.value_counts(dropna = False))\nprint(test_data.BsmtExposure.value_counts(dropna = False))\ntrain_data.BsmtExposure.value_counts(dropna = False).plot.bar()\ntest_data.BsmtExposure.fillna('No',inplace = True)\ntrain_data.BsmtExposure.fillna('No',inplace = True)\nle = le.fit(train_data.BsmtExposure.unique().tolist())\ntrain_data.BsmtExposure = le.transform(train_data.BsmtExposure)\ntest_data.BsmtExposure = le.transform(test_data.BsmtExposure)\n\n\n","b3a60cb0":"#Handling BsmtFinType1\nprint(train_data.BsmtFinType1.value_counts(dropna = False))\nprint(test_data.BsmtFinType1.value_counts(dropna = False))\ntrain_data.BsmtFinType1.value_counts(dropna = False).plot.bar()\ntest_data.BsmtFinType1.fillna('GLQ',inplace = True)\ntrain_data.BsmtFinType1.fillna('Unf',inplace = True)\nle = le.fit(train_data.BsmtFinType1.unique().tolist())\ntrain_data.BsmtFinType1 = le.transform(train_data.BsmtFinType1)\ntest_data.BsmtFinType1 = le.transform(test_data.BsmtFinType1)\n\n","c57eea97":"#Handling BsmtFinType2\nprint(train_data.BsmtFinType2.value_counts(dropna = False))\nprint(test_data.BsmtFinType2.value_counts(dropna = False))\ntrain_data.BsmtFinType2.value_counts(dropna = False).plot.bar()\ntest_data.BsmtFinType2.fillna('Unf',inplace = True)\ntrain_data.BsmtFinType2.fillna('Unf',inplace = True)\nle = le.fit(train_data.BsmtFinType2.unique().tolist())\ntrain_data.BsmtFinType2 = le.transform(train_data.BsmtFinType2)\ntest_data.BsmtFinType2 = le.transform(test_data.BsmtFinType2)\n\n\n","0c0ba85e":"#Handling Heating\nprint(train_data.Heating.value_counts(dropna = False))\nprint(test_data.Heating.value_counts(dropna = False))\ntrain_data.Heating.value_counts(dropna = False).plot.bar()\n#very skewed therefore drop it.\ntest_data.drop('Heating',axis = 1,inplace = True)\ntrain_data.drop('Heating',axis = 1,inplace = True)\n\n\n","1cc117d9":"#Handling HeatingQC\nprint(train_data.HeatingQC.value_counts(dropna = False))\nprint(test_data.HeatingQC.value_counts(dropna = False))\ntrain_data.HeatingQC.value_counts(dropna = False).plot.bar()\nle = le.fit(train_data.HeatingQC.unique().tolist())\ntrain_data.HeatingQC = le.transform(train_data.HeatingQC)\ntest_data.HeatingQC = le.transform(test_data.HeatingQC)\n\n\n","dd9db4c9":"#Handling CentralAir\nprint(train_data.CentralAir.value_counts(dropna = False))\nprint(test_data.CentralAir.value_counts(dropna = False))\ntrain_data.CentralAir.value_counts(dropna = False).plot.bar()\nle = le.fit(train_data.CentralAir.unique().tolist())\ntrain_data.CentralAir = le.transform(train_data.CentralAir)\ntest_data.CentralAir = le.transform(test_data.CentralAir)\n\n\n","4654ab8c":"#Handling Electrical\nprint(train_data.Electrical.value_counts(dropna = False))\nprint(test_data.Electrical.value_counts(dropna = False))\ntrain_data.Electrical.value_counts(dropna = False).plot.bar()\n#very skewed therefore we can drop it.\ntrain_data.drop('Electrical',axis = 1,inplace = True)\ntest_data.drop('Electrical',axis = 1,inplace = True)\n\n\n","fbed7c9c":"#Handling KitchenQual\nprint(train_data.KitchenQual.value_counts(dropna = False))\nprint(test_data.KitchenQual.value_counts(dropna = False))\ntrain_data.KitchenQual.value_counts(dropna = False).plot.bar()\ntest_data.KitchenQual.fillna('TA',inplace = True)\nle = le.fit(train_data.KitchenQual.unique().tolist())\ntrain_data.KitchenQual = le.transform(train_data.KitchenQual)\ntest_data.KitchenQual = le.transform(test_data.KitchenQual)\n\n\n","3a8ddb6e":"#Handling Functional\nprint(train_data.Functional.value_counts(dropna = False))\nprint(test_data.Functional.value_counts(dropna = False))\ntrain_data.Functional.value_counts(dropna = False).plot.bar()\n#very skewed therefore we can drop it.\ntrain_data.drop('Functional',axis = 1,inplace = True)\ntest_data.drop('Functional',axis = 1,inplace = True)\n\n\n","40873bec":"#Handling FireplaceQu\nprint(train_data.FireplaceQu.value_counts(dropna = False))\nprint(test_data.FireplaceQu.value_counts(dropna = False))\ntrain_data.FireplaceQu.value_counts(dropna = False).plot.bar()\ntest_data.FireplaceQu.fillna('None',inplace = True)\ntrain_data.FireplaceQu.fillna('None',inplace = True)\nle = le.fit(train_data.FireplaceQu.unique().tolist())\ntrain_data.FireplaceQu = le.transform(train_data.FireplaceQu)\ntest_data.FireplaceQu = le.transform(test_data.FireplaceQu)\n\n\n","553a096a":"#Handling GarageType\nprint(train_data.GarageType.value_counts(dropna = False))\nprint(test_data.GarageType.value_counts(dropna = False))\ntrain_data.GarageType.value_counts(dropna = False).plot.bar()\ntest_data.GarageType.fillna('Attchd',inplace = True)\ntrain_data.GarageType.fillna('Attchd',inplace = True)\nle = le.fit(train_data.GarageType.unique().tolist())\ntrain_data.GarageType = le.transform(train_data.GarageType)\ntest_data.GarageType = le.transform(test_data.GarageType)\n\n\n","94df0ef3":"#Handling GarageFinish\nprint(train_data.GarageFinish.value_counts(dropna = False))\nprint(test_data.GarageFinish.value_counts(dropna = False))\ntrain_data.GarageFinish.value_counts(dropna = False).plot.bar()\ntest_data.GarageFinish.fillna('None',inplace = True) # filling nan or null values with None\ntrain_data.GarageFinish.fillna('None',inplace = True) # filling nan or null values with None\nle = le.fit(train_data.GarageFinish.unique().tolist())\ntrain_data.GarageFinish = le.transform(train_data.GarageFinish)\ntest_data.GarageFinish = le.transform(test_data.GarageFinish)\n\n\n","7dd7b18c":"#Handling GarageQual\nprint(train_data.GarageQual.value_counts(dropna = False))\nprint(test_data.GarageQual.value_counts(dropna = False))\ntrain_data.GarageQual.value_counts(dropna = False).plot.bar()\n#very skewed we can drop it.\ntrain_data.drop('GarageQual',axis = 1,inplace = True)\ntest_data.drop('GarageQual',axis = 1,inplace = True)\n\n","98db3025":"#Handling GarageCond\nprint(train_data.GarageCond.value_counts(dropna = False))\nprint(test_data.GarageCond.value_counts(dropna = False))\ntrain_data.GarageCond.value_counts(dropna = False).plot.bar()\n#very skewed we can drop it.\ntrain_data.drop('GarageCond',axis = 1,inplace = True)\ntest_data.drop('GarageCond',axis = 1,inplace = True)\n","e4b7bd5e":"#Handling PavedDrive\nprint(train_data.PavedDrive.value_counts(dropna = False))\nprint(test_data.PavedDrive.value_counts(dropna = False))\ntrain_data.PavedDrive.value_counts(dropna = False).plot.bar()\nle = le.fit(train_data.PavedDrive.unique().tolist())\ntrain_data.PavedDrive = le.transform(train_data.PavedDrive)\ntest_data.PavedDrive = le.transform(test_data.PavedDrive)\n","62cb9d7d":"#Handling PoolQC\nprint(train_data.PoolQC.value_counts(dropna = False))\nprint(test_data.PoolQC.value_counts(dropna = False))\ntrain_data.PoolQC.value_counts(dropna = False).plot.bar()\n#too much NaN values we can drop it.\ntrain_data.drop('PoolQC',axis = 1,inplace = True)\ntest_data.drop('PoolQC',axis = 1,inplace = True)\n","06482bd8":"#Handling Fence\nprint(train_data.Fence.value_counts(dropna = False))\nprint(test_data.Fence.value_counts(dropna = False))\ntrain_data.Fence.value_counts(dropna = False).plot.bar()\n#too much NaN values we can drop it.\ntrain_data.drop('Fence',axis = 1,inplace = True)\ntest_data.drop('Fence',axis = 1,inplace = True)\n","0b01f593":"#Handling MiscFeature\nprint(train_data.MiscFeature.value_counts(dropna = False))\nprint(test_data.MiscFeature.value_counts(dropna = False))\ntrain_data.MiscFeature.value_counts(dropna = False).plot.bar()\n#too much NaN values we can drop it.\ntrain_data.drop('MiscFeature',axis = 1,inplace = True)\ntest_data.drop('MiscFeature',axis = 1,inplace = True)\n","00949576":"#Handling SaleType\nprint(train_data.SaleType.value_counts(dropna = False))\nprint(test_data.SaleType.value_counts(dropna = False))\ntrain_data.SaleType.value_counts(dropna = False).plot.bar()\n#very skewed we can drop it.\ntrain_data.drop('SaleType',axis = 1,inplace = True)\ntest_data.drop('SaleType',axis = 1,inplace = True)\n","6517f0da":"#Handling SaleCondition\nprint(train_data.SaleCondition.value_counts(dropna = False))\nprint(test_data.SaleCondition.value_counts(dropna = False))\ntrain_data.SaleCondition.value_counts(dropna = False).plot.bar()\nle = le.fit(train_data.SaleCondition.unique().tolist())\ntrain_data.SaleCondition = le.transform(train_data.SaleCondition)\ntest_data.SaleCondition = le.transform(test_data.SaleCondition)\n","eda83ef5":"#Let's get the shape of our data to know number of features and samples\ntrain_data.shape","9b460279":"#Let's get our X_train and y_train\nX_train = train_data.drop(['SalePrice'],axis = 1)\ny_train = train_data['SalePrice']\nX_train.fillna(method = 'ffill',inplace = True)","f3c02565":"#Let's prepare our training and testing data\nX_train,X_test,y_train,y_test = train_test_split(X_train,y_train,test_size = 0.2)","1521a6da":"#preparing data for lightgbm\nlgb_train = lgb.Dataset(X_train,y_train)\nlgb_test = lgb.Dataset(X_test,y_test)","4592f01b":"#Let's set parameters for our model\nparams = {\n    'boosting_type': 'gbdt',\n    'objective': 'regression',\n    'metric': {'rmse'},\n    'num_leaves': 31,\n    'learning_rate': 0.01,\n    'feature_fraction': 0.9,\n    'bagging_fraction': 0.8,\n    'bagging_freq': 5,\n    'verbose': 0\n}\n","0605ac6c":"#training our lightgbm model\nmodel = lgb.train(params,lgb_train,num_boost_round=10000,valid_sets=lgb_test,early_stopping_rounds=100)","c797724c":"test_data.head()","8b6a801d":"test_data.fillna(method = 'ffill',inplace = True)\npred = model.predict(test_data)\nsample = pd.read_csv('..\/input\/sample_submission.csv')\nsample['SalePrice'] = pred\nsample.to_csv('sub.csv',index = False)\nsample.head()","e3c53e15":"This feature is skewed therefore dropping it.","539585ea":"Keeping feature and aloted a number to each feature by using Label Encoder.","a5a166da":"<h2>Let's Start <\/h2>\nIn this competition we have to predict the price of the houses. We have been given a lot of information about the houses. Here feature engineering is very important. We will see which features we should keep and which we should not and why. ","386aba49":"This feature is very skewed but still I am taking it just for fun.","ec1b9ad7":"This feature is great to keep. Lot of categories. I have aloted a number to each category by using Label Encoder.","9d4c8f10":"This feature has a lot of nan or null values. Therefore, I am dropping it. It is not usefull for our model.","85ab56ee":"<h3> I would appreciate if you could upvote this kernel. <\/h3>","4996edd7":"This feature has a lot of skewness therefore I dropped it.","fd28c130":"This feature seems good. Replaced values with numeric.","49630157":"This feature is skewed towards a single feature therefore it is of no use. Dropping it.","40b4e41e":"Loading training and testing data.","c55450e0":"**Hope you like it. I would appreciate if you could upvote this kernel and let me know in the comments if you have any suggestion or question.**","b1b05c5e":"Here we just replaced values with numeric values so that we can easily work on it while training our model.","c6f8dc0b":"Using Label Encoder every category is given a number in the features.","5f4aa53d":"Now we will check every feature which is not numerical. We will convert that feature to numerical value or drop that feature. I am taking all numerical features for training.","c1769fb6":"This feature seems little skewed but still keep and replacing the values.","977adc50":"Good feature keeping it. Converting to numeric values.","7892e760":"Importing required libraries."}}