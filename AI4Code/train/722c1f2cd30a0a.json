{"cell_type":{"a338bbe4":"code","d590ac50":"code","51d21149":"code","d98a34bc":"code","badd632f":"code","f61a7ef9":"code","000f0f86":"code","8394e27e":"code","2a9ee647":"code","9a0608b3":"code","89098259":"code","ed131161":"code","be9cf8aa":"code","58a84e68":"code","94dd3543":"code","8205492b":"code","84a40dab":"code","ad5bacdc":"code","68d4e73a":"code","313581f0":"code","27e51a55":"code","f9360bfa":"code","70209d93":"code","b3a4161e":"code","c108250f":"code","4c61d7a4":"code","68334253":"markdown","0193c987":"markdown"},"source":{"a338bbe4":"#Importing the libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","d590ac50":"# Importing the data set\ndataset = pd.read_csv('\/kaggle\/input\/Churn_Modelling.csv')\ndataset","51d21149":"# Taking dataset in numpy\ndset = dataset.iloc[:, 3:].values","d98a34bc":"# Encoding categorical Variables\nfrom sklearn.preprocessing import LabelEncoder\nle_country = LabelEncoder()\ndset[:, 1] = le_country.fit_transform(dset[:, 1])\nle_country = LabelEncoder()\ndset[:, 2] = le_country.fit_transform(dset[:, 2])\nnp.set_printoptions(threshold=np.inf)","badd632f":"dset","f61a7ef9":"# Creating dummy variables\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer","000f0f86":"ct = ColumnTransformer([('one_hot_encoder', OneHotEncoder(categories = 'auto'), [1, 2])], remainder='passthrough')\ndset = ct.fit_transform(dset)\nnp.set_printoptions(threshold=np.inf)\nprint(dset)","8394e27e":"#Splitting into x and y\nx = dset[:, 1:13]\ny = dset[:, 13:14]\nprint(x)\nprint(y)","2a9ee647":"x = np.delete(x,[3],1)\nprint(x)\n# First two coulmn are of country and then the third one is of gender","9a0608b3":"# mising data sklearn not found skipping that and Categorical Variables\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n\"\"\"print('x train= ',x_train)\nprint('x test= ',x_test)\nprint('y train= ',y_train)\nprint('y test= ',y_test)\"\"\"","89098259":"# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc_x = StandardScaler()\nx_train = sc_x.fit_transform(x_train)\nx_test = sc_x.transform(x_test)","ed131161":"#Importing the keras libraries\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense","be9cf8aa":"# Intialising the ANN\nclassifier = Sequential()","58a84e68":"# Adding the input Layer And the first hidden layer\nclassifier.add(Dense(output_dim = 6, kernel_initializer='uniform', activation = 'relu', input_dim = 11))","94dd3543":"# Adding the second hidden layer\nclassifier.add(Dense(output_dim = 6, kernel_initializer='uniform', activation = 'relu'))","8205492b":"# Adding the output layer\nclassifier.add(Dense(output_dim = 1, kernel_initializer='uniform', activation = 'sigmoid'))","84a40dab":"#Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","ad5bacdc":"# Fitting the ANN to the training set\nclassifier.fit(x_train, y_train, batch_size = 10, nb_epoch = 100)","68d4e73a":"#Predicting the test set results\ny_pred = classifier.predict(x_test)\ny_pred = (y_pred > 0.5)","313581f0":"y_pred","27e51a55":"y_test","f9360bfa":"#Taking y_pred to boolean\ny_tested = []\nfor i in range(len(y_test)):\n    if y_test[i] == 1:\n        y_tested.append([True])\n    else:\n        y_tested.append([False])","70209d93":"y_tested","b3a4161e":"# Making the confucion matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_tested, y_pred)","c108250f":"cm","4c61d7a4":"print(\"accuracy = \", (cm[0][0] + cm[1][1])*100\/2000,\"%\")","68334253":"#Part 2 : Forming Artificial Neural Network","0193c987":"# Part 3 - making the predictions and evaluating teh model"}}