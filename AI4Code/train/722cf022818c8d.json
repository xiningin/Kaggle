{"cell_type":{"ef333915":"code","ede4b12d":"code","712234ea":"code","c509b882":"code","2ce1b346":"code","4cd6045a":"code","bc671de7":"code","1b7694f0":"code","795de022":"code","600070a3":"code","5ff68303":"code","5a455f10":"code","5c2c4476":"code","3c01ba8f":"code","fd7050b6":"code","1d3c6367":"code","924dfb99":"code","85bf07af":"code","329d12eb":"code","44169104":"code","4ba9fdb7":"code","61de3663":"code","fa24ece0":"code","bdef2ccc":"code","9c34db5e":"code","27fd332f":"code","13df571d":"code","5ca0c523":"code","ec6fa91e":"code","2e7ef036":"code","8e12a374":"code","2b781e61":"code","987c1c50":"code","50068ec2":"code","2583cc40":"code","ef6f0dca":"code","76fe470e":"code","d340907e":"code","af86a09e":"code","0d7dc5b6":"code","1bb2815c":"code","5dcc0b96":"code","1803e3a4":"code","839ab7e3":"code","cb8bb405":"code","f48817de":"code","29490c6a":"code","69ad9a7b":"code","c5df366d":"code","abd8c71e":"code","82600803":"code","d968b959":"code","22c06c8e":"code","04544a3a":"code","74e0dac4":"code","be14d7d1":"code","559a4ab4":"code","65104830":"code","88c18f49":"code","0da2133e":"markdown","c4f07f1e":"markdown","9b997d0e":"markdown","0cda3321":"markdown","4288debc":"markdown","d6c82278":"markdown","126cba12":"markdown","b007cdfb":"markdown","6c3ec53a":"markdown","4a664584":"markdown","d97f474e":"markdown","382ef049":"markdown","eeb8debe":"markdown","d92ec518":"markdown","77a1054d":"markdown","7f7a3b60":"markdown"},"source":{"ef333915":"import numpy as np\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom statsmodels.formula.api import ols","ede4b12d":"#Importing neccessary plotting libraries\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","712234ea":"df = pd.read_csv('..\/input\/Admission_Predict_Ver1.1.csv')\ndf.head(10)","c509b882":"type(df)","2ce1b346":"print('Descriptive Statastics of our Data:')\ndf.describe().T","4cd6045a":"print('Showing Meta Data :')\ndf.info()","bc671de7":"df.columns","1b7694f0":"#Renaming columns \ndf.columns = ['sno','GRE','TOEFL','university_rating','SOP','LOR','CGPA','research','admit_chance']\ndf.head()","795de022":"#Checking for missing values\npd.isnull(df).sum()","600070a3":"sns.pairplot(data=df,diag_kind='kde')","5ff68303":"df[['GRE','TOEFL','university_rating','CGPA','SOP','LOR','research']].hist(figsize=(10,8),bins=15,linewidth='1',edgecolor='black')\nplt.tight_layout()\nplt.show()","5a455f10":"df.research.value_counts()","5c2c4476":"#Chances of admission wrt research\nchances=df.groupby('research')['admit_chance'].median()\nprint(chances)\nsns.factorplot('research','admit_chance',data=df)\nplt.show()","3c01ba8f":"sns.regplot(x=\"GRE\",y=\"CGPA\", data=df,line_kws={'color':'red'})\nplt.title(\"GRE Score vs CGPA\")\nplt.show()","fd7050b6":"sns.regplot(x=\"GRE\",y=\"TOEFL\", data=df,line_kws={'color':'red'})\nplt.title(\"GRE Score vs TOEFL Score\")\nplt.show()","1d3c6367":"df.university_rating.value_counts()","924dfb99":"sns.countplot(df.university_rating)","85bf07af":"sns.scatterplot(x=\"CGPA\", y=\"university_rating\", hue=\"research\", data=df)\nplt.show()","329d12eb":"print('Avg. GRE scores based on University Ratings')\n\npd.DataFrame(df.groupby('university_rating')['GRE'].mean())","44169104":"print('Avg. TOEFL scores based on University Ratings')\n\npd.DataFrame(df.groupby('university_rating')['TOEFL'].mean())","4ba9fdb7":"df.groupby('university_rating')[['SOP','LOR','CGPA']].mean()","61de3663":"sns.regplot(x=\"CGPA\",y=\"admit_chance\", data=df,line_kws={'color':'red'})\nplt.title(\"CGPA vs Chance of Admit\")\nplt.show()","fa24ece0":"#The mean values for getting admisssion chances greater than 80%\n\nadmt_sort = df.sort_values(by=df.columns[-1],ascending=False)\n\nadmt_sort[(admt_sort['admit_chance']>0.80)].mean().reset_index().T","bdef2ccc":"cat = ['university_rating','research']\ncont = ['GRE','TOEFL','SOP','LOR','CGPA','admit_chance']","9c34db5e":"print('Correlation Heat map of the data')\nplt.figure(figsize=(12,8))\nsns.heatmap(df[cont].corr(),annot=True,fmt='.2f',vmin=-1,vmax=1)\nplt.show()","27fd332f":"sns.boxplot(x='university_rating',y='admit_chance',data=df)","13df571d":"sns.boxplot(x='research',y='admit_chance',data=df)","5ca0c523":"x = df.drop(['sno','admit_chance'],axis=1)\nx.head()","ec6fa91e":"y=df['admit_chance']","2e7ef036":"from sklearn.preprocessing import StandardScaler,MinMaxScaler\nx_std = StandardScaler().fit_transform(x)\nx_std = pd.DataFrame(x_std,columns=x.columns)\nx_std.head()","8e12a374":"x_std1 = MinMaxScaler().fit_transform(x)\nx_std1 = pd.DataFrame(x_std1,columns=x.columns)\nx_std1.head()","2b781e61":"plt.figure(figsize=(14,8))\nsns.boxplot(data=x_std,orient='h')\nplt.show()","987c1c50":"std_df=pd.concat([x_std,y],axis=1)\nprint(std_df.shape)\nstd_df.head()","50068ec2":"std_df1 = pd.concat([x_std1,y],axis=1)\nprint(std_df1.shape)\nstd_df1.head()","2583cc40":"from statsmodels.formula.api import ols\nM2 = ols('admit_chance~GRE+TOEFL+SOP+LOR+CGPA+university_rating+research',std_df).fit()\nM2.summary()","ef6f0dca":"#best estimators:\nM = ols('admit_chance ~ CGPA+GRE+TOEFL+LOR+research',std_df1).fit()\nM.summary()","76fe470e":"from sklearn.linear_model import Lasso","d340907e":"ls = Lasso(alpha=0.025)\nls.fit(x_std,y)","af86a09e":"ls.coef_","0d7dc5b6":"pd.DataFrame([x_std.columns,ls.coef_]).T","1bb2815c":"from sklearn.decomposition import PCA\npca = PCA(n_components=7)\npc = pca.fit_transform(x_std)\npc_df = pd.DataFrame(pc)\npc_df.head()","5dcc0b96":"pc_df.shape","1803e3a4":"#Explained Variance Ratio\nevr = pca.explained_variance_ratio_\nprint(evr)","839ab7e3":"#cumulative Variance Ratio\ncvr=np.cumsum(evr)\nprint(cvr)","cb8bb405":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold","f48817de":"X = x_std1.drop(['university_rating','SOP'],axis=1)\ny = df['admit_chance']\nX.head()","29490c6a":"Xtrain, Xtest, ytrain, ytest = train_test_split(X,y,test_size = 0.30, shuffle=True,random_state = 25)\nXtrain.shape,Xtest.shape","69ad9a7b":"model = LinearRegression()\nmodel.fit(Xtrain,ytrain)","c5df366d":"prediction = model.predict(Xtest)\nmse = mean_squared_error(ytest,prediction)\nerror = np.sqrt(mse)\nprint('The RMSE value is :',error)","abd8c71e":"Xp = pc_df.iloc[:,:4]\nY = y\nXp.head(2)","82600803":"Xtrain, Xtest, ytrain, ytest = train_test_split(Xp,Y,test_size = 0.30, shuffle=True,random_state = 25)\nXtrain.shape,Xtest.shape","d968b959":"model = LinearRegression()\nmodel.fit(Xtrain,ytrain)\n\nprediction = model.predict(Xtest)\nmse = mean_squared_error(ytest,prediction)\nerror = np.sqrt(mse)\nprint('The RMSE value is :',error)","22c06c8e":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV","04544a3a":"kf = KFold(n_splits=5,shuffle=True,random_state=0)\ntraining = []\ntesting = []\nrmse = []\n\nfor train,test in kf.split(X,y):\n    M = LinearRegression()\n    Xtrain,Xtest = X.iloc[train,:],X.iloc[test,:]\n    Ytrain,Ytest = y.iloc[train],y.iloc[test]\n    M.fit(Xtrain,Ytrain)\n    Y_PRED = M.predict(Xtest)\n    \n    train_score = M.score(Xtrain,Ytrain)\n    test_score = M.score(Xtest,Ytest)\n    training.append(np.round(train_score,3))\n    testing.append(np.round(test_score,3))\n    mse = mean_squared_error(Ytest,Y_PRED)\n    error = np.sqrt(mse)\n    rmse.append(error)\n    \nprint('Training scores: ',training)\nprint('\\nTesting scores: ', testing)\nprint('\\nroot mean squared errors are : ',np.round(rmse,4))\nprint(\"\\nthe Average RMSE is : \" ,np.mean(rmse)) \nprint(\"the Model variance is : \" ,np.var(rmse)) ","74e0dac4":"lr = LinearRegression()\ndtr = DecisionTreeRegressor(max_depth=3,random_state=25)\nrfr = RandomForestRegressor(n_estimators=28,random_state=25)\nabr = AdaBoostRegressor(lr,n_estimators=5,random_state=25)\ngbr = GradientBoostingRegressor(n_estimators=29,random_state=25)\nbr = BaggingRegressor(lr,n_estimators=55,random_state=25)","be14d7d1":"#parameter={'n_estimators':np.arange(1,81)}\n#gs= GridSearchCV(abr,parameter,cv=4,scoring='neg_mean_squared_error')\n#gs.fit(Xtrain,ytrain)\n#gs.best_params_","559a4ab4":"models = []\n\nmodels.append(('linear regression',lr))\nmodels.append(('DT regressor',dtr))\nmodels.append(('RF regressor',rfr))\nmodels.append(('ADA boost regressor',abr))\nmodels.append(('Gradient boost',gbr))\nmodels.append(('Bagging Regressor',br))","65104830":"results = []\nnames =  []\n\nfor name,mod in models:\n    kf=KFold(n_splits=5)\n    cv_results = cross_val_score(mod,X,y,cv = kf,scoring='neg_mean_squared_error')\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, np.mean(cv_results), cv_results.var())\n    print(msg)  ","88c18f49":"# boxplot algorithm comparison\nfig = plt.figure(figsize=[12,6])\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(1,1,1)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()","0da2133e":"# Building Models","c4f07f1e":"parameter={'max_depth':np.arange(1,15) }\ngs= GridSearchCV(dtr,parameter,cv=4,scoring='neg_mean_squared_error')\ngs.fit(Xtrain,ytrain)\ngs.best_params_","9b997d0e":"# Outlier Detection","0cda3321":"From the statastical summary and by using Lasso we can conclude that 'SOP' and 'University rating' has no significance in predicting 'Y'","4288debc":"# GRADUATE ADMISSIONS\n\nOur aim here is to conduct a wide variety of analyzes and forecasting operations using the data set here.\n\nThe dataset contains several parameters which are considered important during the application for Masters Programs. \n\nThe parameters included are :\n\n#GRE Scores ( out of 340 )\n#TOEFL Scores ( out of 120 )\n#University Rating ( out of 5 )\n#Statement of Purpose and Letter of Recommendation Strength ( out of 5 )\n#Undergraduate GPA ( out of 10 )\n#Research Experience ( either 0 or 1 )\n#Chance of Admit ( ranging from 0 to 1 )","d6c82278":"We can see that the Linear Regression fits the data very well with least mean squraed error followd by Bagging Regressor\nHence,Linear regression model will be chosen as the best suitable model for this problem","126cba12":"# Linear Regression ","b007cdfb":"## Cross Validation","6c3ec53a":"# Principle Component Analysis","4a664584":"## Exploratory Data Analysis(EDA)","d97f474e":"# Ensemble Methods and Algorithm Comparision","382ef049":"# INTRODUCTION\nIn this project, there are many exam points taken in various exam systems. A variety of analyzes will be obtained from these exams. We will use python programming language. Our system will consist of three stages. The first stage data will be preprocessed. However, there are various analyzes and graphs. In the next step, a wide variety of analyzes will be made by using Regression algorithms. ","eeb8debe":"# Lasso","d92ec518":"**Thank You for reading my work. If you like it, please UPVOTE. It will motivate me to keep adding content and share with you guys.**","77a1054d":"# Standardization","7f7a3b60":"# Linear Regression on Principle components"}}