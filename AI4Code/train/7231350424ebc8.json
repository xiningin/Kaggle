{"cell_type":{"edcfa6e6":"code","e53f803e":"code","f1db482f":"code","bacba3d5":"code","ae3022a8":"code","c704d7fd":"code","f3e4ada2":"code","177df1a6":"code","100fa862":"code","d194b3de":"code","8fc5220a":"code","7b7eb05f":"code","fadde9a9":"code","e78ae27d":"code","d96f0313":"code","5bb9869c":"code","02f693da":"code","c7403b06":"code","4494f4a3":"code","14fa45f2":"code","bb79c885":"code","3df53b75":"code","898396a6":"code","5c91537d":"code","f6761d5e":"code","cb24f993":"code","f4083aeb":"markdown","888ac80c":"markdown","28ce40e4":"markdown","d80c336f":"markdown"},"source":{"edcfa6e6":"import shutil\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom shutil import copyfile","e53f803e":"%env JOBLIB_TEMP_FOLDER=\/tmp","f1db482f":"#shutil.rmtree('\/tmp')","bacba3d5":"## Creating Directories\n\ncategories = list(np.arange(42))\ncategories = [str(i) for i in categories]\ncategories[0:10] = ['0' + i for i in categories[0:10]]\n\ntry: \n    \n    base_dir = '\/tmp\/products\/'\n    os.mkdir(base_dir)\n    \n    train_dir = os.path.join(base_dir, 'training')\n    validation_dir = os.path.join(base_dir, 'validation')\n    os.mkdir(train_dir)\n    os.mkdir(validation_dir)\n    \n    for cat in categories:\n        os.mkdir(os.path.join(train_dir, str(cat)))\n        os.mkdir(os.path.join(validation_dir, str(cat)))\n        print(cat+' created successfully in both train and validation')\n    \nexcept OSError:\n    pass","ae3022a8":"len(os.listdir('\/tmp\/products\/validation'))","c704d7fd":"# Splitting files to Train\/Valid sets (training on smaller subset)\nimport random\ndef split_data(source, train, validation, split_size, subset):\n    \n    all_files = []\n    for file_name in os.listdir(source):\n        file_path = source + file_name\n        \n        if os.path.getsize(file_path)>0:\n            all_files.append(file_name)\n        else:\n            print('{} is zero length, so ignoring'.format(file_name))\n    \n    \n    n_files = len(all_files)\n    subset_size = int(n_files * subset)  ## 30% of all images\n    split_point = int(subset_size * split_size)  ## split accordingly to the 30% images\n    \n    shuffled = random.sample(all_files, n_files)\n    shuffled = shuffled[:subset_size]  ## getting 30% of shuffled images\n    \n    train_set = shuffled[:split_point] \n    test_set = shuffled[split_point:]\n    \n    for file_name in train_set:\n        copyfile(source + file_name, train + file_name)\n    \n    for file_name in test_set:\n        copyfile(source + file_name, validation + file_name)","f3e4ada2":"import random\ndef specialised_data(source, train, validation):\n    \n    all_files = []\n    for file_name in os.listdir(source):\n        file_path = source + file_name\n        \n        if os.path.getsize(file_path)>0:\n            all_files.append(file_name)\n        else:\n            print('{} is zero length, so ignoring'.format(file_name))\n    \n    \n    n_files = len(all_files) \n    \n    shuffled = random.sample(all_files, n_files)\n    \n    train_set = shuffled[:500] \n    test_set = shuffled[500:750]\n    \n    for file_name in train_set:\n        copyfile(source + file_name, train + file_name)\n    \n    for file_name in test_set:\n        copyfile(source + file_name, validation + file_name)","177df1a6":"sources = ['\/kaggle\/input\/shopee-dataset\/train\/train\/' + cat + '\/' for cat in categories]\ntraining_source = ['\/tmp\/products\/training\/' + cat + '\/' for cat in categories]\nvalidation_source = ['\/tmp\/products\/validation\/' + cat + '\/' for cat in categories]\n\n# Train\/Val Size\nsplit_size = 0.95\n\n# Set how much of the data you want to train with\nsubset = 1.0","100fa862":"for source, train, valid in zip(sources, training_source, validation_source):\n    \n    split_data(source, train, valid, split_size, subset)","d194b3de":"print(len(os.listdir('\/tmp\/products\/training\/00')))\nprint(len(os.listdir('\/tmp\/products\/validation\/00')))","8fc5220a":"!pip install -U efficientnet","7b7eb05f":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\n#from tensorflow.keras.applications.EfficientNetB7 import EfficientNetB7\nfrom efficientnet.tfkeras import EfficientNetB7\n\nimg_size = 75\n\npre_trained_model = EfficientNetB7(input_shape=(img_size, img_size, 3),\n                                      include_top=False,\n                                      weights='imagenet')\n\n#for layer in pre_trained_model.layers[0:700]:\n    #layers.trainable = False\n    \n#for layer in pre_trained_model.layers[700:]:\n    #layers.trainable = True\n  \n#pre_trained_model.summary()\n#last_layer = pre_trained_model.get_layer('block8_7_mixed')\n#last_output = last_layer.output\n\nlast_output = pre_trained_model.output","fadde9a9":"cost = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\noptimize = tf.keras.optimizers.Adam(lr=0.001)\n\nx = layers.Flatten()(last_output)\nx = layers.Dense(64, activation='relu', kernel_regularizer = tf.keras.regularizers.l2(0.05))(x)\nx = layers.Dropout(0.3)(x)\nx = layers.Dense(42, activation='softmax')(x)\n\nmodel = Model(pre_trained_model.input, x)\n\nmodel.compile(optimizer=optimize,\n              loss=cost,\n              metrics=['accuracy'])","e78ae27d":"model.summary()","d96f0313":"train_dir = '\/tmp\/products\/training'\nvalidation_dir = '\/tmp\/products\/validation'\n\ntrain_datagen = ImageDataGenerator(rescale=1\/255)\n\n\ntrain_generator = train_datagen.flow_from_directory(train_dir,\n                                                    batch_size=64,\n                                                    class_mode='categorical',\n                                                    target_size=(img_size,img_size),\n                                                    color_mode = 'rgb')\n\nvalidation_datagen = ImageDataGenerator(rescale=1\/255)\nvalidation_generator = validation_datagen.flow_from_directory(validation_dir,\n                                                              batch_size=32,\n                                                              class_mode='categorical',\n                                                              target_size=(img_size,img_size),\n                                                              color_mode = 'rgb')","5bb9869c":"checkpoint_path = '\/kaggle\/working\/EfficientNetB7.ckpt'\ncheckpoint_dir = os.path.dirname(checkpoint_path)\ncp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n                                                 save_weights_only=True,\n                                                 verbose=1)","02f693da":"#model.load_weights('\/kaggle\/input\/gpuweights\/InceptionResNetV2.ckpt')\nmodel.load_weights('\/kaggle\/working\/EfficientNetB7.ckpt')","c7403b06":"history = model.fit(train_generator,\n                    epochs = 2, \n                    verbose = 1,\n                    validation_data = validation_generator,\n                    callbacks=[cp_callback])","4494f4a3":"from tqdm import tqdm\nimport cv2\n\ndf_test = pd.read_csv('\/kaggle\/input\/shopee-dataset\/test.csv')\nX_test = []\n\nfor imageName in tqdm(df_test['filename']): \n    image = cv2.imread('\/kaggle\/input\/shopee-dataset\/test\/test\/' + imageName)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, (img_size,img_size))\n    X_test.append(image)\n    \nX_test = np.array(X_test).astype('float32')\/255","14fa45f2":"predictions = model.predict(X_test, batch_size=32)\npreds = predictions.argmax(axis=-1)","bb79c885":"preds","3df53b75":"your_choice = 85\nprint('Your choice belongs to category {}'.format(preds[your_choice]))\n\nfrom keras.preprocessing import image\nimport matplotlib.image as mpimg\n\nfile_names = os.listdir('\/kaggle\/input\/shopee\/test\/test')\npath = '\/kaggle\/input\/shopee\/test\/test\/' + file_names[your_choice]\n\ntest_img = mpimg.imread(path)\nplt.figure(figsize=(8,8))\nplt.imshow(test_img)\nplt.show()","898396a6":"## Category Class\ncat = '02'\npath_cat = '\/tmp\/products\/training\/' + str(cat) + '\/' + os.listdir('\/tmp\/products\/training\/'+ cat)[100]\n\nplt.figure(figsize=(8,8))\ncat_img = mpimg.imread(path_cat)\nplt.imshow(cat_img)\nplt.show()","5c91537d":"df_test['category'] = preds\ndf_test['category'] = df_test.category.apply(lambda c : str(c).zfill(2))","f6761d5e":"df_test","cb24f993":"df_test.to_csv('\/kaggle\/working\/final.csv', index=False)","f4083aeb":"# Splitting Function for General Training","888ac80c":"## Convert to CSV for submission","28ce40e4":"## Testing and Comparison","d80c336f":"# Splitting Function for Specialised Training"}}