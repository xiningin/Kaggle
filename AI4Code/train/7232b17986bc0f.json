{"cell_type":{"1184740f":"code","565c9214":"code","c5ff1b10":"code","cc227ae8":"code","b5deb778":"code","a10d0618":"code","e702af2e":"code","5e20f812":"code","7c497e51":"code","137b1361":"code","a1190e1a":"code","02c2e8de":"code","cf3f66b2":"code","c55deb00":"code","2fc79dbd":"code","95c64b0d":"code","1db12ea9":"code","1dfdd0a9":"code","c3e3287d":"code","42a48f60":"code","db810426":"markdown","6dfbf61d":"markdown"},"source":{"1184740f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom spacy.lang.ta import Tamil\nfrom spacy.lang.ta import STOP_WORDS as tamil_stopwords\nfrom wordcloud import WordCloud\nfrom collections import Counter\n\nfrom spacy.lang.hi import Hindi\nfrom spacy.lang.hi import STOP_WORDS as hindi_stopwords\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","565c9214":"!pip install openpyxl","c5ff1b10":"df = pd.read_excel('\/kaggle\/input\/popular-words-in-different-languages\/translations.xlsx')\npd.set_option('display.max_columns', None)\ndf.head(2)","cc227ae8":"df.isnull().sum()","b5deb778":"df[\"PopularWords\"].value_counts()","a10d0618":"# Get the text for both the languages\ntamil_text = \" \".join(df[df[\"Tamil\"]==\"tamil\"][\"PopularWords\"])\nnepali_text = \" \".join(df[df[\"Nepali\"]==\"nepali\"][\"PopularWords\"])","e702af2e":"# Download and extract the fonts\n!wget -q http:\/\/www.lipikaar.com\/sites\/www.lipikaar.com\/themes\/million\/images\/support\/fonts\/Devanagari.zip\n!wget -q http:\/\/www.lipikaar.com\/sites\/www.lipikaar.com\/themes\/million\/images\/support\/fonts\/Tamil.zip\n\n!unzip -qq Devanagari.zip\n!unzip -qq Tamil.zip","5e20f812":"from spacy.lang.ne import Nepali\nfrom spacy.lang.ne import STOP_WORDS as nepali_stopwords\n\n\n# Get the tokens and frequencies for Nepali language\n\nnepali_nlp = Nepali()\nnepali_doc = nepali_nlp(nepali_text)\nnepali_tokens = set([token.text for token in nepali_doc])\nnepali_tokens_counter = Counter(nepali_tokens)\n\n\n# Get the tokens and frequencies for Tamil language\ntamil_nlp = Tamil()\ntamil_doc = tamil_nlp(tamil_text)\ntamil_tokens = set([token.text for token in tamil_doc])\ntamil_tokens_counter = Counter(tamil_tokens)","7c497e51":"def plot_wordcloud(\n    font_path,\n    frequencies,\n    stopwords,\n    width=500,\n    height=500,\n    background_color=\"white\",\n    collocations=True,\n    min_font_size=5,\n):\n    \"\"\"Generates wordcloud from word frequencies.\"\"\"\n    \n    wordcloud = WordCloud(font_path=font_path,\n                      width=width,\n                      height=height,\n                      background_color=background_color,\n                      stopwords=stopwords,\n                      collocations=collocations,\n                      min_font_size=min_font_size).generate_from_frequencies(frequencies)\n\n    \n    plt.figure(figsize=(10, 10))\n    plt.imshow(wordcloud)\n    plt.axis(\"off\")\n    plt.show()","137b1361":"##Code by Taha07  https:\/\/www.kaggle.com\/taha07\/data-scientists-jobs-analysis-visualization\/notebook\n\nfrom wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\nstopwords = set(STOPWORDS)\nwordcloud = WordCloud(background_color = 'lightblue',\n                      font_path=\"Devanagari\/Lohit-Devanagari.ttf\",\n                      colormap='Oranges',\n                      height =2000,\n                      width = 2000\n                     ).generate(str(df[\"Marathi\"]))\nplt.rcParams['figure.figsize'] = (12,12)\nplt.axis(\"off\")\nplt.imshow(wordcloud)\nplt.title(\"Marathi Words\")\nplt.show()","a1190e1a":"##Code by Taha07  https:\/\/www.kaggle.com\/taha07\/data-scientists-jobs-analysis-visualization\/notebook\n\nfrom wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\nstopwords = set(STOPWORDS)\nwordcloud = WordCloud(background_color = 'black',\n                      font_path=\"Devanagari\/Lohit-Devanagari.ttf\",\n                      colormap='Set3',\n                      height =2000,\n                      width = 2000\n                     ).generate(str(df[\"Nepali\"]))\nplt.rcParams['figure.figsize'] = (12,12)\nplt.axis(\"off\")\nplt.imshow(wordcloud)\nplt.title(\"Nepali Words\")\nplt.show()","02c2e8de":"##Code by Taha07  https:\/\/www.kaggle.com\/taha07\/data-scientists-jobs-analysis-visualization\/notebook\n\nfrom wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\nstopwords = set(STOPWORDS)\nwordcloud = WordCloud(background_color = 'black',\n                      colormap='Set3',\n                      height =2000,\n                      width = 2000\n                     ).generate(str(df[\"Portuguese\"]))\nplt.rcParams['figure.figsize'] = (12,12)\nplt.axis(\"off\")\nplt.imshow(wordcloud)\nplt.title(\"Portuguese Words\")\nplt.show()","cf3f66b2":"##Code by Taha07  https:\/\/www.kaggle.com\/taha07\/data-scientists-jobs-analysis-visualization\/notebook\n\nfrom wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\nstopwords = set(STOPWORDS)\nwordcloud = WordCloud(background_color = 'Green',\n                      font_path=\"Devanagari\/Lohit-Devanagari.ttf\",\n                      colormap='Purples',\n                      height =2000,\n                      width = 2000\n                     ).generate(str(df[\"Hindi\"]))\nplt.rcParams['figure.figsize'] = (12,12)\nplt.axis(\"off\")\nplt.imshow(wordcloud)\nplt.title(\"Hindi Words\")\nplt.show()","c55deb00":"##Code by Taha07  https:\/\/www.kaggle.com\/taha07\/data-scientists-jobs-analysis-visualization\/notebook\n\nfrom wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\nstopwords = set(STOPWORDS)\nwordcloud = WordCloud(background_color = 'Red',\n                      colormap='BuPu',\n                      height =2000,\n                      width = 2000\n                     ).generate(str(df[\"French\"]))\nplt.rcParams['figure.figsize'] = (12,12)\nplt.axis(\"off\")\nplt.imshow(wordcloud)\nplt.title(\"French Words\")\nplt.show()","2fc79dbd":"##Code by Taha07  https:\/\/www.kaggle.com\/taha07\/data-scientists-jobs-analysis-visualization\/notebook\n\nfrom wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\nstopwords = set(STOPWORDS)\nwordcloud = WordCloud(background_color = 'Yellow',\n                      colormap='afmhot',\n                      height =2000,\n                      width = 2000\n                     ).generate(str(df[\"German\"]))\nplt.rcParams['figure.figsize'] = (12,12)\nplt.axis(\"off\")\nplt.imshow(wordcloud)\nplt.title(\"German Words\")\nplt.show()","95c64b0d":"##Code by Taha07  https:\/\/www.kaggle.com\/taha07\/data-scientists-jobs-analysis-visualization\/notebook\n\nfrom wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\nstopwords = set(STOPWORDS)\nwordcloud = WordCloud(background_color = 'Red',\n                      colormap='YlOrRd',\n                      height =2000,\n                      width = 2000\n                     ).generate(str(df[\"Spanish\"]))\nplt.rcParams['figure.figsize'] = (12,12)\nplt.axis(\"off\")\nplt.imshow(wordcloud)\nplt.title(\"Spanish Words\")\nplt.show()","1db12ea9":"#Code by Nain https:\/\/www.kaggle.com\/aakashnain\/chaii-explore-the-data\n\n# Get the text for Tamil language\ntamil_text = \" \".join(df[df[\"Tamil\"]==\"tamil\"][\"PopularWords\"])","1dfdd0a9":"#Code by Nain https:\/\/www.kaggle.com\/aakashnain\/chaii-explore-the-data\n\n# Get the tokens and frequencies for Tamil language\ntamil_nlp = Tamil()\ntamil_doc = tamil_nlp(tamil_text)\ntamil_tokens = set([token.text for token in tamil_doc])\ntamil_tokens_counter = Counter(tamil_tokens)","c3e3287d":"#Code by Nain https:\/\/www.kaggle.com\/aakashnain\/chaii-explore-the-data\n\ndef plot_wordcloud(\n    font_path,\n    frequencies,\n    stopwords,\n    width=500,\n    height=500,\n    background_color=\"black\",\n    collocations=True,\n    min_font_size=5,\n):\n    \"\"\"Generates wordcloud from word frequencies.\"\"\"\n    \n    wordcloud = WordCloud(font_path=font_path,\n                      width=width,\n                      height=height,\n                      background_color=background_color,\n                      stopwords=stopwords,\n                      collocations=collocations,\n                      min_font_size=min_font_size).generate(str(df[\"Tamil\"]))\n\n    \n    plt.figure(figsize=(10, 10))\n    plt.imshow(wordcloud)\n    plt.axis(\"off\")\n    plt.title(\"Tamil Popular words\")\n    plt.show()","42a48f60":"##Code by Taha07  https:\/\/www.kaggle.com\/taha07\/data-scientists-jobs-analysis-visualization\/notebook\n\nfrom wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\nstopwords = set(STOPWORDS)\nwordcloud = WordCloud(background_color = 'white',\n                      font_path=\"Tamil\/Lohit-Tamil.ttf\",\n                      colormap='Set2',\n                      height =2000,\n                      width = 2000\n                     ).generate(str(df[\"Tamil\"]))\nplt.rcParams['figure.figsize'] = (12,12)\nplt.axis(\"off\")\nplt.imshow(wordcloud)\nplt.title(\"Tamil Words\")\nplt.show()","db810426":"#With the code below, the 3 snippets below became useless.\n\nI changed that because the code that worked on the 1st version returned Zero words to plot.\nSince I couldn't fix it I kept the snippets above and ran Taha07's snippet below. Since the Tamil WordCloud can be seen I'm satisfied with the result.","6dfbf61d":"That's all for now."}}