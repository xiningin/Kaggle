{"cell_type":{"de8ce792":"code","2e23b1e7":"code","08fe48e0":"code","0da5f10b":"code","6cc71a50":"code","8187790c":"code","cc201fba":"code","606a289b":"code","083461f1":"code","e1536b3b":"code","a36819a9":"code","5b0c19ce":"code","703c4662":"markdown","0886be67":"markdown","637e190a":"markdown","fc5ebe7f":"markdown","94fa5f82":"markdown","48ddd961":"markdown","d74c29dd":"markdown","10718e25":"markdown","5ff5ee54":"markdown","cbf539d6":"markdown"},"source":{"de8ce792":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","2e23b1e7":"import time\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns","08fe48e0":"sns.set_context(context='talk')","0da5f10b":"# Import raw data\nprint(\"Started at \", time.ctime())\ndata_path = \"..\/input\/8anu-climbing-logbook-csv-files\/\"\ndf_ascent = pd.read_csv(\"{path}ASCENT.csv\".format(path=data_path), low_memory=False, index_col=0)\ndf_grade = pd.read_csv(\"{path}GRADE.csv\".format(path=data_path), index_col=0)\ndf_user = pd.read_csv(\"{path}USER.csv\".format(path=data_path), low_memory=False, index_col=0)\nprint(\"Finished at \", time.ctime())","6cc71a50":"def standardize_usa_boulder_ratings(row):\n    \"\"\"Group and standardize V-scale ratings\"\"\"\n    rating = row.usa_boulders\n    if rating == 'VB':\n        rating = 'V0-'\n    elif rating == 'V3\/4':\n        rating = 'V3'\n    elif rating == 'V4\/V5':\n        rating = 'V4'\n    elif rating == 'V5\/V6':\n        rating = 'V5'\n    elif rating == 'V8\/9':\n        rating = 'V8'\n    row.usa_boulders = rating\n    \n    return row\n\n\n# Pre-process raw data\ndf_grade_processed = (\n    df_grade\n    .loc[df_grade.usa_boulders != '', :] # filter for climbs with V-scale ratings \n    .apply(standardize_usa_boulder_ratings, axis=1)  # group and standardize V-scale ratings\n)\ndf_ascent_processed = df_ascent.loc[df_ascent.climb_type == 1, :] # filter for bouldering climbs","8187790c":"# Merge and filter data to create interim dataset\ndf_interim = (\n    df_ascent_processed\n    .merge(df_grade_processed, how='inner', left_on='grade_id', right_on='id', suffixes=('_ascent', '_grade'))\n    .loc[:, ['id_ascent', 'id_grade', 'user_id', 'date', 'year', 'usa_boulders', 'name']]  # select relevant columns for project\n    .sort_values(by=['user_id', 'date'])\n    .reset_index(drop=True)   \n)\n\ndisplay(df_interim.head())","cc201fba":"# Pivot interim data to setup for analysis\ndf_interim_pivot = (\n    df_interim\n    .groupby(['user_id', 'usa_boulders'])\n    .nth(0, dropna=None)  # select first ascent at each level for each climber\n    .reset_index()\n    .pivot_table(index='user_id', columns='usa_boulders', values='date')\n    .loc[:, ['V0-', 'V0', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10']]  # limit analysis to V0- to V10 problems\n    .reset_index()\n)\n\ndisplay(df_interim_pivot.head())","606a289b":"df_clean = (\n    df_interim_pivot\n    .drop('user_id', axis=1)\n)","083461f1":"# Visualize avaialble data\nplt.figure(figsize=(10, 5))\nsns.heatmap(df_clean.notnull().applymap(lambda x: int(x)), cbar=False, cmap='Blues')\nplt.title(\"Missing Value Heatmap\")\nplt.xlabel(\"Boulder Grade\")\nplt.ylabel(\"Climbers\")\nplt.show()\n\nprint(\"Blue indicates available data\")\nprint(\"Number of Climbs: {}\".format(df_clean.notnull().sum().sum()))\nprint(\"Number Climbers: {}\".format(len(df_clean)))","e1536b3b":"# Compute time spent at each grade\ndf_clean_diff = (\n    df_clean\n    .diff(axis=1)\n    .applymap(lambda x: np.nan if x < 0 else x)  # remove negative time intervals\n    .applymap(lambda x: x \/ (3600*24*30))  # convert timestamps to months\n    .drop('V0-', axis=1)\n    .rename(index=str, columns={\n        \"V0\": \"V0-\", \"V1\": \"V0\", \"V2\": \"V1\",\n        \"V3\": \"V2\", \"V4\": \"V3\", \"V5\": \"V4\",\n        \"V6\": \"V5\", \"V7\": \"V6\",\"V8\": \"V7\",\n        \"V9\": \"V8\", \"V10\": \"V9\",\n    })  # shift column labels down a grade to account for diff command\n)\n\n# Remove outliers\nthresh = df_clean_diff.quantile(q=0.99, axis='index')\nmask = df_clean_diff.apply(lambda row: row < thresh.values, axis=1)\ndf_clean_diff_thresh = df_clean_diff[mask]\n\ndisplay(df_clean_diff_thresh.head())","a36819a9":"vals = (\n    df_clean_diff_thresh\n    .rename(index=str, columns={'V0-': '-V0'}) # rename column for plotting purposes\n    .mean()\n    .cumsum()\n)\nerrs = (\n    df_clean_diff_thresh\n    .std()\n)","5b0c19ce":"# Define colors for plot\ncmap = cm.Pastel1\ncolors = []\ncolors.extend(cmap(np.linspace(0, 0.1, 2)))\ncolors.extend(cmap(np.linspace(0.15, 0.2, 3)))\ncolors.extend(cmap(np.linspace(0.25, 0.3, 2)))\ncolors.extend(cmap(np.linspace(0.35, 0.4, 4)))\n\n# Create figure\nplt.figure(figsize=(15, 10))\nax = plt.gca()\n\n# Creat  Plot\nax.set_facecolor('ghostwhite')\nfor i, c in enumerate(colors):    \n    plt.errorbar(\n        vals[i], \n        i, \n        xerr=errs[i], \n        color=c,\n        fmt='o', \n        markersize=25,\n        markeredgecolor='black',\n        markeredgewidth=2.0,\n        linewidth=5,\n        ecolor=c,\n        capsize=7\n    )\n\n# Alter y-axis\nplt.yticks(\n    np.arange(11),\n    vals.index\n)\n    \n# Alter x-axis\nplt.xticks(\n    np.arange(0, 85, 6),\n    ['Start', '6 mos', '1yr', '1.5yrs', '2yrs', '', '3yrs', '', '4yrs', '', '5yrs', '', '6yrs', '', '7yrs'])\nplt.xlim((-0.1, 78.1))\n\n# Grid\nplt.grid(False, axis='y', which='both')\nplt.grid(True, axis='x', which='both', linestyle='--', linewidth=1)\n\n# Titles\nplt.title(\"Expected Bouldering Grade\\nBased on Time Climbing\", fontsize=35)\nplt.ylabel(\"Outdoor Bouldering Grade\", fontsize=35)\nplt.xlabel(\"Time Bouldering Outdoors\", fontsize=35)\n\n# Font size\nplt.rc('xtick', labelsize=20)\nplt.rc('ytick', labelsize=20)\n\nplt.show()\n\nprint(\"Plot Values:\")\ndisplay(vals)","703c4662":"## Values for Plot","0886be67":"# Introduction\n\nThe following analysis was used to create the plot seen in the Medium Article: [\"How Long Before You Get \"Good\" at Bouldering\"](https:\/\/medium.com\/@aarontrefler\/how-long-before-you-get-good-at-bouldering-6df816e3fa25).\n\nNote: Relevent data from the original SQLite databasewas extracted offline and re-uploaded as CSV files. This was done due to technical difficulties getting `sqlite3` package to work on a Kaggle Kernel.\n\nSpecial thanks to the following:\n- 8a.nu Climbing Logbook, Kaggle Dataset, by David Cohen\n- 8a EDA, Kaggle Kernel, by christophergian\n- Climber-characteristic-analysis, GitHub Repository, by stevebachmeier\n- Plotting progression times per grade, Kaggle Kernel, by Durand D'souza","637e190a":"# Create Figure","fc5ebe7f":"# Raw Data\nImport and process raw data.","94fa5f82":"# Interim Data\nMerge, filter, transform, and pivot data to create interim datasets.","48ddd961":"# Clean Data\nCreate final dataset to be used for analysis, and visualize available data points.","d74c29dd":"## Create Plot","10718e25":"# Personal Setup\nPersonal imports and plot settings.","5ff5ee54":"Compute final dataset used for generating plotting values.","cbf539d6":"# Kaggle Setup\nDefault code provided with Kaggle Kernel."}}