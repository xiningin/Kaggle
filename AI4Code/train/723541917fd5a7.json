{"cell_type":{"224c5ad7":"code","9fb03ebb":"code","0e35168f":"code","3f2418f0":"code","bc8b5089":"code","cbc8ac9d":"code","01563dc4":"code","1976533a":"code","689f9c11":"code","8d455b34":"code","bc5459bc":"code","45e589ac":"code","b364121f":"code","5bdf8564":"code","6fa8424d":"code","ab05bc3a":"code","9d65676b":"code","88c1f654":"code","42d8a909":"code","719cf2ac":"code","9098ac47":"code","1851dad1":"code","3ee566ed":"code","a11c8b4f":"code","a020a2df":"code","71f0ea3b":"code","f8818bcd":"code","69ac09b8":"code","9e29db60":"code","40ae6cde":"code","ef3fe2da":"code","9269510f":"code","5bbeaed9":"code","df236a07":"code","31da78e5":"code","17206f08":"code","ee7c6a3f":"code","15c1074e":"code","07c43576":"code","6e20415e":"code","e2aa00f8":"code","2b094d46":"code","44be5a8b":"code","77db2a3b":"code","ea164238":"code","c72c2ad0":"code","3eb26c4d":"code","dba15653":"code","0b4b394e":"code","171dfe71":"code","ce01c2b6":"code","39c13ef7":"code","43274e64":"code","f49c0891":"code","ef36e707":"code","0f79b953":"code","52c1b0c8":"code","7c2213d3":"code","8cbe6ce1":"code","cef6c154":"code","04264dff":"code","a42520ff":"code","933ab7a4":"markdown","5e843d91":"markdown","4bde909c":"markdown","16ef279f":"markdown","53d1ef5e":"markdown","3877da5f":"markdown","8c620a8f":"markdown","5c585ea5":"markdown","3face3fe":"markdown","fb9c611e":"markdown","61b88f42":"markdown","00263ea2":"markdown","c696c6e6":"markdown","1288b9a6":"markdown","5c139432":"markdown","d3382e68":"markdown","2f2d2404":"markdown","66de5f2e":"markdown","6204214a":"markdown","a8d4077d":"markdown","58f09f1e":"markdown","ba87738a":"markdown","0d8d02e7":"markdown","2b6c254f":"markdown","0096c843":"markdown","1af331b8":"markdown"},"source":{"224c5ad7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport datetime\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom PIL import Image\nimport warnings\nwarnings.filterwarnings(\"ignore\")","9fb03ebb":"data = pd.read_csv(\"\/kaggle\/input\/netflix-shows\/netflix_titles.csv\")\nprint(data.shape)\ndata.head()","0e35168f":"data.nunique() # To find unique content on each row","3f2418f0":"data.isnull().sum() # It will give the Count of each column where NaN is present","bc8b5089":"data.director.fillna(\"No Director\", inplace=True)\ndata.cast.fillna(\"No Cast\", inplace=True)\ndata.country.fillna(\"Country Unavailable\", inplace=True)\ndata.dropna(subset=[\"date_added\", \"rating\"], inplace=True) # dropped the rows with NaN values in \"date_added\",\"rating\" columns because they are very few.","cbc8ac9d":"data.isnull().sum()","01563dc4":"Visualization = px.pie(values=data['type'].value_counts(), \n             names=data['type'].value_counts().index,title='Type of Content on Netflix')\n\nVisualization.show()","1976533a":"data['country'] = [countries[0] for countries in data['country'].str.split(',')]","689f9c11":"def visualise_country(country):\n    if (country == ALL):\n        data_vis = data\n    \n    else:\n        data_vis = data[data.country == country]\n        \n    Visualization = px.pie(values=data_vis['type'].value_counts(), \n             names=data_vis['type'].value_counts().index, \n             title=f'Total number of TV-Shows and Movies from {country}.')\n    Visualization.show()","8d455b34":"import ipywidgets as widgets\nfrom ipywidgets.widgets.interaction import show_inline_matplotlib_plots\n\nALL = 'ALL'\ndef total_unique_country_names(array):\n    unique = array.unique().tolist()\n    unique.sort()\n    unique.insert(0, ALL)\n    return unique\n\ndropdown_country = widgets.Dropdown(options = total_unique_country_names(data.country))\noutput_country = widgets.Output()\n\ndef dropdown_country_eventhandler(change):\n    output_country.clear_output()\n    with output_country:\n        display(visualise_country(change.new))\n        \ndropdown_country.observe(dropdown_country_eventhandler, names='value')\ndisplay(dropdown_country)","bc5459bc":"display(output_country)","45e589ac":"data_country = data['country'].value_counts().sort_values(ascending=False)\ntop15countries = data_country.head(15)\ntop15countries","b364121f":"Visualization = px.pie(values=top15countries, \n                       names=top15countries.index,title='Top 15 Countries producing the content to Netflix')\n\nVisualization.show()","5bdf8564":"Ratings = data['rating'].value_counts()\nRatings","6fa8424d":"Visualization = px.funnel(Ratings,title='Types of Rating on Netflix')\n\nVisualization.show()","ab05bc3a":"def group_by_rating(rating):\n    if rating in ['TV-Y', 'TV-Y7', 'TV-Y7-FV', 'G', 'TV-G', 'PG', 'TV-PG']:\n        new_rating = 'Kids'\n    elif rating in ['PG-13', 'TV-14']:\n        new_rating = 'Teens'\n    elif rating in ['R', 'NC-17', 'TV-MA']:\n        new_rating = 'Adults'\n    else:\n        new_rating = 'Unrated'\n    return new_rating\n        \n\ndata['rating_group'] = data.apply(lambda x: group_by_rating(x['rating']), axis=1)\n\nprint(data.rating_group.value_counts())\n\norder_rating = ['Kids', 'Teens', 'Adults', 'Unrated']\n\nVisualization = px.bar(y = data['rating_group'].value_counts(), \n             x = data['rating_group'].value_counts().index,\n             labels = dict(x=\"Rating\", y=\"Total Number\"),\n             title = 'TV-Shows and Movies Rating in Netflix'\n            )\n\nVisualization.update_xaxes(categoryorder = 'array', categoryarray= order_rating)\n\nVisualization.show()","9d65676b":"Movie_Names = data[data['type'] == 'Movie'].title\n\ntext = list(Movie_Names)\n\nplt.rcParams['figure.figsize'] = (15, 15)\n\nwordcloud = WordCloud(max_words=1000000,background_color=\"White\").generate(str(text))\n\nplt.imshow(wordcloud,interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.margins(x=3, y=1)\nplt.show()","88c1f654":"imdb_movie_names = pd.read_csv('..\/input\/imdb-extensive-dataset\/IMDb movies.csv',\n                               usecols=['title', 'year', 'avg_vote'])\n\nnew_ratings = pd.DataFrame({'Title':imdb_movie_names.title,\n                    'Rating': imdb_movie_names.avg_vote,\n                           'Year' : imdb_movie_names.year})\n\nnew_ratings.drop_duplicates(subset=['Title','Year','Rating'], inplace=True)\nprint(new_ratings.shape)\nnew_ratings.head(5)","42d8a909":"Inner_join_data = new_ratings.merge(data,left_on='Title', right_on='title', how='inner')\nInner_join_data=Inner_join_data.sort_values(by='Rating', ascending=False)","719cf2ac":"top_rated=Inner_join_data[0:15]\nfig =px.sunburst(\n    top_rated,\n    path=['title','country'],\n    values='Rating',\n    color='Rating')\nfig.show()","9098ac47":"countries_data = Inner_join_data['country'].value_counts().sort_values(ascending=False)\ncountry_count = pd.DataFrame(countries_data)\nTop_countries = country_count.head(15)","1851dad1":"Visualization = px.bar(Top_countries, title = \"Countries with highest rated content\")\nVisualization.show()","3ee566ed":"from plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\niplot([go.Scatter(x=data['country'], y=data['director'], mode='markers')])","a11c8b4f":"# iplot([go.Histogram2dContour(x=data.head(15)['country'], \n#                              y=data.head(15)['type'], \n#                              contours=go.Contours(coloring='heatmap')),\n#        go.Scatter(x=data['country'].head(20), y=data['type'].head(20), mode='markers')])","a020a2df":"# df = data.assign(n=0).groupby(['release_year', 'country'])['n'].count().reset_index()\n# df = df[df['release_year'] < 2010 ]\n# v = df.pivot(index='release_year', columns='country', values='n').fillna(0).values.tolist()\n\n# iplot([go.Surface(z=v)])","71f0ea3b":"# Visualization using Choropleth\n\ndf = data['country'].value_counts()\n\niplot([go.Choropleth(\n    locationmode='country names',\n    locations=df.index.values,\n    text=df.index,\n    z=df.values,\n)])","f8818bcd":"sns.countplot(data['rating'])","69ac09b8":"sns.kdeplot(data.query('release_year > 2015').release_year)","9e29db60":"# These two are usefel for the recommendations\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ndata.columns","40ae6cde":"features = ['description', 'cast', 'director', 'listed_in']","ef3fe2da":"def combine_features(row):\n    return row['description']+\" \"+row['cast']+\" \"+row['director']+\" \"+row['listed_in']","9269510f":"data[\"combined_features\"] = data.apply(combine_features,axis=1) #applying combined_features() method over each rows of dataframe and storing the combined string in \"combined_features\" column","5bbeaed9":"data.iloc[0].combined_features","df236a07":"cv = CountVectorizer() #creating new CountVectorizer() object\ncount_matrix = cv.fit_transform(data[\"combined_features\"]) #feeding combined strings(movie contents) to CountVectorizer() object","31da78e5":"cosine_sim = cosine_similarity(count_matrix) #It will calculate the cosine similarity of the data present in count_matri that is all the combined features \ncosine_sim","17206f08":"# Adding Index column to the dataset for unique identification\n\ni =[]\nfor j in range(0, len(data)):\n    i.append(j)\ndata[\"index\"] = i","ee7c6a3f":"data.columns\n\ndata.tail(5)","15c1074e":"# functions to get the title and index\n\ndef get_title_from_index(index):\n    return data[data.index == index][\"title\"].values[0]\n\ndef get_index_from_title(title):\n    return data[data.title == title][\"index\"].values[0]","07c43576":"recommend_movie = \"3 Idiots\"\nmovie_index = get_index_from_title(recommend_movie)\nsimilar_movies = list(enumerate(cosine_sim[movie_index]))","6e20415e":"sorted_similar_movies = sorted(similar_movies,key=lambda x:x[1],reverse=True)[1:]","e2aa00f8":"i=0\nprint(\"Top 10 similar movies to \"+recommend_movie+\" are:\\n\")\nfor element in sorted_similar_movies:\n    print(get_title_from_index(element[0]))\n    i+= 1\n    if i>9:\n        break","2b094d46":"from sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping","44be5a8b":"IMDB_Reviews = pd.read_csv('..\/input\/imdb-extensive-dataset\/IMDb movies.csv', low_memory=False)\nIMDB_Reviews.head(3)","77db2a3b":"New_ratings = pd.DataFrame({'Title':IMDB_Reviews.title,\n                    'Rating': IMDB_Reviews.avg_vote})\n\nNew_ratings.drop_duplicates(subset=['Title', 'Rating'], inplace=True)\n\nprint(New_ratings.shape)\nNew_ratings.head(5)","ea164238":"Inner_join_data = New_ratings.merge(data,left_on='Title', right_on='title', how='inner')\nInner_join_data=Inner_join_data.sort_values(by='Rating', ascending=False)\n\nprint(Inner_join_data.shape)\nInner_join_data.head(5)","c72c2ad0":"New_Data = Inner_join_data[['Title', 'Rating', 'type']]\n\nNew_Data.drop_duplicates(subset=['Title','Rating', 'type'], inplace=True)\nprint(New_Data.shape)\nNew_Data.head(5)","3eb26c4d":"Movies_Data = New_Data[New_Data.type == 'Movie']\nTV_Data = New_Data[New_Data.type == 'TV Show']\nprint(Movies_Data.shape)\nprint(TV_Data.shape)","dba15653":"Movies_Data = Movies_Data.drop(['type'], axis=1)\n\nMovies_Data","0b4b394e":"Movies_Data['Polarity_Rating'] = Movies_Data['Rating'].apply(lambda x: 'Positive' if x > 6 else 'Negative')\nMovies_Data","171dfe71":"fig = px.pie(values=Movies_Data['Polarity_Rating'].value_counts(), \n             names=Movies_Data['Polarity_Rating'].value_counts().index)\nfig.show()","ce01c2b6":"Positive = Movies_Data[Movies_Data['Polarity_Rating'] == 'Positive']\nNegative = Movies_Data[Movies_Data['Polarity_Rating'] == 'Negative']\n\nprint(Positive.shape)\nprint(Negative.shape)","39c13ef7":"df = Movies_Data[['Title','Polarity_Rating']]\ndf","43274e64":"one_hot = pd.get_dummies(df[\"Polarity_Rating\"])\ndf.drop(['Polarity_Rating'],axis=1,inplace=True)\ndf = pd.concat([df,one_hot],axis=1)\ndf","f49c0891":"X = df['Title'].values\ny = df.drop('Title', axis=1).values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)","ef36e707":"X_train","0f79b953":"y_train","52c1b0c8":"vect = CountVectorizer()\nX_train = vect.fit_transform(X_train)\nX_test = vect.transform(X_test)\n\ntfidf = TfidfTransformer()\nX_train = tfidf.fit_transform(X_train)\nX_test = tfidf.transform(X_test)\nX_train = X_train.toarray()\nX_test = X_test.toarray()","7c2213d3":"model = Sequential()\n\nmodel.add(Dense(units=12673,activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(units=4000,activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(units=500,activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(units=2, activation='sigmoid'))\n\nopt=tf.keras.optimizers.Adam(learning_rate=0.001)\nmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['binary_accuracy'])\n\nearly_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)","8cbe6ce1":"xyz= model.fit(x=X_train, y=y_train, batch_size=50, epochs=80, validation_data=(X_test, y_test), verbose=1, \n               callbacks=early_stop)\nxyz","cef6c154":"model_score = model.evaluate(X_test, y_test, batch_size=64, verbose=1)\nprint('Test accuracy:', model_score[1])","04264dff":"a = pd.DataFrame(xyz.history)\n\na.loc[1:, ['loss', 'val_loss']].plot()\na.loc[1:, ['binary_accuracy', 'val_binary_accuracy']].plot()\n\nprint((\"Best Validation Loss: {:0.4f}\" +\\\n      \"\\nBest Validation Accuracy: {:0.4f}\")\\\n      .format(a['val_loss'].min(), \n              a['val_binary_accuracy'].max()))","a42520ff":"predict = model.predict(X_test)\npredict","933ab7a4":"**Sentiment Analysis is widely used to find the opinion of the customers such as reviews, survey responses in websites or social media. Since the customers are\nexpressing their thoughts, feelings and opinions more openly than ever before, sentiment analysis is becoming an essential tool to monitor and understand that sentiment in their reviews, comments, feedback etc.**","5e843d91":"**With the above data, it's difficult to say which are only applicable to Kids, Adults, etc.. because there are many ratings which are related to Kids and Adults. So better understanding for the end users, we are groping the ratings and displaying the result.**\n\n**1. Adults**\n* R - Restricted. May be inappropriate for ages 17 and under.\n* TV-MA - For Mature Audiences. May not be suitable for ages 17 and under.\n* NC-17 - Inappropriate for ages 17 and under\n\n**2. Teens**\n* PG-13 - Parents strongly cautioned. May be Inappropriate for ages 12 and under.\n* TV-14 - Parents strongly cautioned. May not be suitable for ages 14 and under.\n\n**3. Kids**\n\n* TV-Y - Designed to be appropriate for all children\n* TV-Y7 - Suitable for ages 7 and up\n* G - Suitable for General Audiences\n* TV-G - Suitable for General Audiences\n* PG - Parental Guidance suggested\n* TV-PG - Parental Guidance suggested\n\n*Note: TV and movie ratings may vary by region. The above ratings are applicable only to the United States.*","4bde909c":"**Certain films and television shows have many country names. We only took into account the first country name that appeared in the country column.**","16ef279f":"**From the above result, we can see that director,cast,country,date_added and rating columns have missing values. First, I'm handling those missing values.**","53d1ef5e":"# Importing the Data to perform the Operations","3877da5f":"# Cleaning the Data","8c620a8f":"# **Data Visualization, Recommendations, Sentiment Analysis**","5c585ea5":"*The amount of data generated per year is increasing at a faster rate than it has ever been. In only a year, the total amount of data on the planet would have grown to 44 zettabytes (44 trillion gigabytes)! In today's terms, it's about 4.4 zettabytes. By 2025, the total amount of data on the planet is projected to reach 175 zettabytes. This rapid expansion of data processing has led to a new age of data.* \n\n*Visual information is collected, understood, and responded to in less than 250 milliseconds by our brain. Comparing several tables of raw data, on the other hand, necessitates an effort of abstraction and memory that is simply not achievable beyond a certain volume of data. Companies like Netflix, Twitter, and Amazon use data visualization as a solution to exploit their data. Raw data sets can certainly be ambiguous, as readers can draw their own conclusions. This impact is mitigated by data visualization, which makes data more available and shareable*.\n\n*Data is being used to develop more efficient systems and that's where recommendation systems are coming into the picture. Recommender systems will take the input data from user's preferences and suggest similar content that the user may also be interested in.*","3face3fe":"# Data Visualization","fb9c611e":"**We applied an inner join on the 'new_ratings' dataset and netflix dataset to get the titles that has both ratings on IMDB and are available on Netflix.**","61b88f42":"**Plotly provides a variety of APIs that range in complexity from low-level to high-level. The most convenient API for general-purpose use is iplot, which is the highest-level API.**\n\n**These graphs are interactive in every way. The toolbar on the top-right can be used to perform various operations on the data, such as zooming and panning. A tooltip appears when we hover over a data point. The plot can also be saved as a PNG picture.**","00263ea2":"# Sentiment Analysis on IMDB reviews","c696c6e6":"**We are doing this with the Content based Recommendation. For this, we have considered the information from these columns - description, cast, director, genre and find the similarity of the movies which are present in the dataset.**\n\n**Steps involved in finding the recommendation.**\n\n* First, convert the text data to matrix form using the CountVectorizer function.\n* Next perform Cosine similarity on the data matrix and convert it into a list of tuples where the first element is its index and second is the similarity score.\n* Sort the tuples based on the highest similarity score.\n* After that, get the Index of the movie which user wants recommendations.\n* Then pass the Index value to Cosine similarity matrix that we calculated above.\n* Finally, return the top 10 movies which have similar cosine value.","1288b9a6":"# 3)Top 15 Countries producing the content to Netflix","5c139432":"**From the above pie chart, we can clearly see that the Movie content is more comare to the TV shows.**","d3382e68":"# 1) Types of Content Present on Netflix","2f2d2404":"# 2) Displaying the content type based on the selected Country","66de5f2e":"# 5) Movies Wordcloud","6204214a":"**Unlike pandas, seaborn doesn't require us to use value counts to form the data; instead, the countplot aggregates the data**","a8d4077d":"**The \"ipywidgets\" library was used to pick the country we wanted to view using a dropdown menu. The function visualise_country represents the number of TV shows and movies available in the selected country.**","58f09f1e":"# Recommendations","ba87738a":"**For finding Top rated movies, we are adding one more dataset \"imdb-extensive-dataset\". We will join this with Netflix data and display the top rated movies by matching the \"Title\" in both data sets.**","0d8d02e7":"# Interacting Visualizations using iPlot, Seaborn","2b6c254f":"**When it comes to determining the \"real shape\" of interval results, a KDE plot outperforms a line map.**","0096c843":"# 6) Finding Top rated Movies","1af331b8":"# 4) Ratings classification on Netflix"}}