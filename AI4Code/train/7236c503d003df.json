{"cell_type":{"27aaca86":"code","e1fda1c6":"code","9f2798ec":"code","e69c94a6":"code","0b681926":"code","d291dc50":"code","72f81158":"code","979a6458":"code","c2566bc5":"code","5185f432":"code","680c6692":"code","11f92469":"code","c7de8aaa":"code","69b7400f":"code","bbdaf04c":"code","44c3f81f":"code","52f99286":"code","c970a2bd":"code","2b297a15":"code","17e2231a":"code","aa5c2065":"code","b1e948a9":"code","b178e82b":"code","39e51fc2":"code","4a8e288e":"code","32618a35":"code","77a5b1c1":"code","ee6e97db":"code","be53e520":"code","bfc175c2":"code","bd663c1e":"code","5b065587":"code","cf8bdbf3":"code","fc58bea8":"code","8ab15778":"code","ef632675":"code","b3aa0cf1":"code","77e6a242":"code","27c8516d":"code","a2568caf":"code","f0a4a1fa":"code","bf409d47":"code","f7eeb1ac":"code","a84ff1f8":"code","e49b3189":"code","ddf97493":"markdown","c83f76c4":"markdown","37bf778f":"markdown","e55a7e4b":"markdown","986cae6f":"markdown","d24e21b7":"markdown","108b8a14":"markdown","d385bef8":"markdown","1bcc063f":"markdown","26095f9b":"markdown","909be337":"markdown","d845cfb1":"markdown","8177a40a":"markdown","15af2e8d":"markdown","5d6a03d4":"markdown","fc7d95f0":"markdown","a6b80e59":"markdown","c8505e7e":"markdown","ae98ca97":"markdown","d00be4e7":"markdown","b3c9a284":"markdown"},"source":{"27aaca86":"#Importing required packages.\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","e1fda1c6":"#Loading dataset\ndf_covid = pd.read_csv('..\/input\/covid19-dataset\/owid-covid-data.csv')","9f2798ec":"#Let's check how the data is distributed\ndf_covid.head()","e69c94a6":"# df_covid.tail()","0b681926":"# df_covid.shape","d291dc50":"# df_covid.columns","72f81158":"#Information about the data columns\ndf_covid.info()","979a6458":"# Information on the Dataset\ndf_covid.describe()","c2566bc5":"#Checking Null values on the dataset\ndf_covid.isnull().sum()","5185f432":"# Subsetting those rows where location is India\ndf=df_covid[df_covid[\"location\"]==\"India\"]","680c6692":"# Let's check the new dataset\ndf.head()","11f92469":"# df.tail()","c7de8aaa":"# df.shape","69b7400f":"# Information about the new Dataset\ndf.info()","bbdaf04c":"# More information on the new dataset\ndf.describe()","44c3f81f":"#Checking Null values on the new dataset\ndf.isnull().sum()","52f99286":"# To check for number of columns\ndf.columns","c970a2bd":"# Defining a variable cols \ncols=['total_cases', 'new_cases',\n       'total_deaths', 'new_deaths', 'total_cases_per_million',\n       'new_cases_per_million', 'total_deaths_per_million',\n       'new_deaths_per_million', 'total_tests', 'new_tests',\n       'total_tests_per_thousand', 'new_tests_per_thousand',\n       'new_tests_smoothed', 'new_tests_smoothed_per_thousand',\n       'stringency_index', 'population', 'population_density', 'median_age',\n       'aged_65_older', 'aged_70_older', 'gdp_per_capita', 'extreme_poverty',\n       'cvd_death_rate', 'diabetes_prevalence', 'female_smokers',\n       'male_smokers', 'handwashing_facilities', 'hospital_beds_per_thousand',\n       'life_expectancy']","2b297a15":"#Plotting Histograms\nfor i in cols:\n  sns.distplot(df[i],kde=False,hist=True,bins=11,hist_kws=dict(edgecolor=\"k\", linewidth=1))\n  plt.title(\"Histogram\")\n  plt.ylabel(\"Frequency\")\n  plt.show()","17e2231a":"#Plotting Boxplots\n\n# for i in cols:\n#   sns.boxplot(y=i, data = df)\n#   #sns.boxplot(y=i, data = df)\n#   plt.title(\"Boxplot 11\")\n#   plt.show()","aa5c2065":"# Checking the mean of each column in the new dataset\ndf.mean()","b1e948a9":"# Checking the median of each column in the new dataset\ndf.median()","b178e82b":"# Checking the mode of each column in the new dataset\ndf.mode()","39e51fc2":"#sns.pairplot(df)","4a8e288e":"# Plotting ScatterPlots\n\n# for i in cols:\n#   for j in reversed(cols):\n#     sns.scatterplot(x=i, y=j, data=df)\n#     plt.title(\"Scatter Plot\")\n#     plt.show()","32618a35":"# Defining  new variables for cols \ncols=[ 'new_cases',\n       'total_deaths', 'new_deaths', 'total_cases_per_million',\n       'new_cases_per_million', 'total_deaths_per_million',\n       'new_deaths_per_million', 'total_tests', 'new_tests',\n       'total_tests_per_thousand', 'new_tests_per_thousand',\n       'new_tests_smoothed', 'new_tests_smoothed_per_thousand',\n       'stringency_index', 'population', 'population_density', 'median_age',\n       'aged_65_older', 'aged_70_older', 'gdp_per_capita', 'extreme_poverty',\n       'cvd_death_rate', 'diabetes_prevalence', 'female_smokers',\n       'male_smokers', 'handwashing_facilities', 'hospital_beds_per_thousand',\n       'life_expectancy']","77a5b1c1":"# Plotting ScatterPlots\nfor i in cols:\n    sns.scatterplot(x='total_cases', y=i, data=df)\n    plt.title(\"Scatter Plot\")\n    plt.show()","ee6e97db":"#Plotting Lineplots\n\n# for i in cols:\n#   for j in reversed(cols):\n#     sns.lineplot(x=i,y=j,data=df)\n#     plt.title(\"Line Plots\")\n#     plt.show()","be53e520":"# Plotting Lineplots\nfor i in cols:\n    sns.lineplot(x='total_cases',y=i,data=df)\n    plt.title(\"Line Plots\")\n    plt.show()","bfc175c2":"# Removing outliers in the dataset\ndf.drop(df.index[168],inplace=True)","bd663c1e":"# Checking the info once again\n# df.info","5b065587":"# Observe the changes after removing outliers\ndf.describe()","cf8bdbf3":"# Replacing the null values with the mean of the columns\n#df.fillna(df.mean(), inplace=True)\ndf=df.fillna(df.mean())","fc58bea8":"# Replacing the null categorical columns with their mode\ndf['tests_units'].fillna(df['tests_units'].mode()[0],inplace=True)","8ab15778":"# Now there are no Null values in the Dataset\n#df.info()\ndf.isnull().sum()","ef632675":"# Convert date column to ordinal\nimport datetime as dt \ndf[\"date\"]=pd.to_datetime(df[\"date\"]) \ndf[\"date\"]=df[\"date\"].map(dt.datetime.toordinal)","b3aa0cf1":"# Date column was changed to ordinal\ndf.head()","77e6a242":"# Droping the categorical columns to prepare the dataset for training\ndf.drop(['iso_code', 'continent','location','tests_units'], axis=1, inplace=True)\ndf.head()","27c8516d":"# Create arrays for the features and the response variable\ny = df[\"total_cases\"].values\nX = df.drop([\"total_cases\"],axis=1).values","a2568caf":"# Train and Test splitting of data \nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=4)","f0a4a1fa":"# Import necessary modules\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\n# Create the regressor: reg\nreg= LinearRegression()\n\n# Fit the regressor to the training data\nreg.fit(X_train,y_train)\n\n# Predict on the test data: y_pred\ny_pred=reg.predict(X_test)\n\n#Score the model\nreg.score(X_test,y_test)","bf409d47":"# Compute and print R^2 and RMSE\nprint(\"R^2: {}\".format(reg.score(X_test, y_test)))\nrmse = np.sqrt(mean_squared_error(y_test,y_pred))\nprint(\"Root Mean Squared Error: {}\".format(rmse))\n","f7eeb1ac":"# Import RandomForestRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Instantiate rf\nrf = RandomForestRegressor()\n            \n# Fit rf to the training set    \nrf.fit(X_train, y_train) \n\n# Predict on the test data: y_pred\ny_pred=rf.predict(X_test)\n\n#Score the model\nrf.score(X_test,y_test)","a84ff1f8":"#Predict total cases for a new data through Linear regression\nreg.predict([[733828,10974,11903,2003,256.568,7.952,8.625,1.451,6084256,163187,4.409,0.118,146132,0.106,76.85,1.38e+09,450.419,28.2,5.989,3.414,6426.674,21.2,282.28,10.39,1.9,20.6,59.55,0.53,69.66]])","e49b3189":"#Predict total cases for a new data through RandomForestRegressor\nrf.predict([[733828,10974,11903,2003,256.568,7.952,8.625,1.451,6084256,163187,4.409,0.118,146132,0.106,76.85,1.38e+09,450.419,28.2,5.989,3.414,6426.674,21.2,282.28,10.39,1.9,20.6,59.55,0.53,69.66]])","ddf97493":"Now we are going to plot Scatterplots as well as lineplots for the new dataset.Here we are going to use bivariate analysis. We are going to separate the target column from the other numerical columns. And then do the analysis on the target columns versus numerical columns","c83f76c4":"From the first 5 lines of the dataset I already got some null values. So I have to remove the null values in the dataset. Before that I have to separate the dataset where the location is India.","37bf778f":"Now we have to drop the categorical columns 'iso_code', 'continent' , 'location' , 'tests_units' .","e55a7e4b":"The accuracy score for these model is 98.1% which is also a very good . Although the accuracy score is less than the LinearRegression model.","986cae6f":"Now we have to separete the data where the location is India. We will do the analysis in future on the indian dataset.","d24e21b7":"The Root Mean Squared Error for these model is also very less which is  0.35 .","108b8a14":"The Null values on the new dataset are listed above.","d385bef8":"Now after removing the outliers we have to remove the null values also .So we will replace the null values of the numerical columns by the mean and for the categorical by the mode.","1bcc063f":"Here Null values are present on the dataset. Here the categorical columns also have null values so we have to replace them by the mode of that column. And for the numerical columns the Null values must be replaced by the mean.","26095f9b":"The null values in the whole dataset are listed above.","909be337":"Now calculating the mean median mode of the new dataset.","d845cfb1":"From these histograms we observe that the columns new_deaths , new_deaths_per_million consists of outliers . So we have to remove the outliers before making prediction on the model.","8177a40a":"Now we are going to predict the model for a new data provided by us as instructed in the project. We will predict the new data on both the model Linear regression and RandomForestRegressor.","15af2e8d":"Now we are going to plot the histogram for all numerical column. The numerical columns are listed above in a variable named cols. Here we will do univariate analysis that mean we will draw histograms on each columns.","5d6a03d4":"1. Load dataset from - https:\/\/covid.ourworldindata.org\/data\/owid-covid-data.csv \n\n2. Subset only those rows that have \u201cIndia\u201d in the \u201clocation\u201d column(This subsetted dataframe has to be used for modelling) \n\n3. Univariate Analysis: \n       a. Draw histograms of each numerical variable \n       b. Find mean, median and mode of each column \n\n4. Bivariate Analysis: \n       a. Draw scatter plots of each numerical column versus one another \n       b. Draw line plots of each numerical column versus one another \n\n5. Handle Missing values:   \n       a. If there are null values in numerical column, replace the null values by the mean of that column  \n       b. If there are null values in categorical column, replace the null values by the mode of that column \n       c. If more than 50%the values in a column are null, then drop that entire column \n\n6. Convert date column to ordinal \n       a. Code: import datetime as dt \n                df[\"date\"]=pd.to_datetime(df[\"date\"]) \n                df[\"date\"]=df[\"date\"].map(dt.datetime.toordinal)\n\n7. Drop all categorical columns \n\n8. Select \u201ctotal_cases\u201d column as the target variable \n\n9. Select the other columns as the features(the \u201cdate\u201d column has to be in the features) \n\n10. Perform train-test split \n\n11. Modelling: \n        a. Linear Regression \n        b. Random Forest Regressor \n\n12. Get accuracy \n\n13. Predict Total case for a new date \n\nNOTE: To convert anytime back from ordinal to date-time use the following sample code: from datetime import datetime ordinal value = 733828 # This is an example","fc7d95f0":"From the LinearRegression classifier we get a accuracy score of 99.99% and that was quiet good for a model .For a buisness model a accuracy percentage of more than 80% is good . So the accuracy score is quiet good for these model.","a6b80e59":"In these model we observed that the accuracy for the Linear regression is 99.99%  and for the RandomForestRegressor accuracy is 98.1% which is also very much . So both the Linear regression and RandomForestRegressor shows better performance. So the Linear regression is much better than the RandomForestRegressor in these dataset.","c8505e7e":"Now we are prepairing the model for training . For that we are creating the feature and the response variable. Next we will train the model using LinearRegression and RandomForestRegressor as mentioned in the project.","ae98ca97":"So from the previously plotted histograms we observed that outliers are present on the new dataset. And when we observe the dataset carefully we will observe that most of the outliers are mainly present on the 168 row of the dataset . So we will drop that entire row to make better prediction and more accuracy on the model.","d00be4e7":"Now we have cleaned the dataset properly. And the next task will be to convert the date column to ordinal.","b3c9a284":"The dataset have many null values. Categorial columns are also present. "}}