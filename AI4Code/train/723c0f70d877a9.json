{"cell_type":{"b8813f39":"code","c685f92e":"code","4697d63f":"code","0accd605":"code","cde547be":"code","66de33a0":"code","f3296705":"code","4774e79c":"code","ae842bf1":"code","2f6099bc":"code","e11a75b1":"code","090268e8":"code","6c6d6768":"code","008830ab":"code","d27d0636":"code","de50f2ab":"code","3491794a":"code","fce00dba":"code","a44f3bbc":"code","a255cfb6":"code","edd616f5":"code","efd3b6a9":"code","8e5a1031":"code","d704ca2f":"code","a772ec26":"code","6b4d8484":"code","6ee85059":"code","a5fb8b8e":"code","c3bd4879":"code","e1815bbc":"code","48a73b78":"code","f90514ca":"code","c005f04b":"code","e00d0321":"code","bc21ef62":"code","558b129f":"code","2db6ec0f":"code","474d29d2":"code","141b372d":"code","686fbf59":"code","4a9ae88f":"code","0a62d853":"code","7916605b":"code","367b6f35":"code","3ee84165":"code","5d7cb3d0":"code","ae485fe5":"code","758ba985":"code","2a5954d3":"code","09c29b28":"code","2c7cf33f":"markdown"},"source":{"b8813f39":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport html\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","c685f92e":"path = \"\/kaggle\/input\/aclimdb\/aclImdb\/\"\npositiveFiles = [x for x in os.listdir(path+\"train\/pos\/\")\n                 if x.endswith(\".txt\")]\nnegativeFiles = [x for x in os.listdir(path+\"train\/neg\/\")\n                if x.endswith(\".txt\")]\ntestFiles = [x for x in os.listdir(path+\"test\/\") \n             if x.endswith(\".txt\")]","4697d63f":"#positiveFiles","0accd605":"positiveReviews, negativeReviews, testReviews = [], [], []\nfor pfile in positiveFiles:\n    with open(path+\"train\/pos\/\"+pfile, encoding=\"latin1\") as f:\n        positiveReviews.append(f.read())\nfor nfile in negativeFiles:\n    with open(path+\"train\/neg\/\"+nfile, encoding=\"latin1\") as f:\n        negativeReviews.append(f.read())\nfor tfile in testFiles:\n    with open(path+\"test\/\"+tfile, encoding=\"latin1\") as f:\n        testReviews.append(f.read())","cde547be":"print(len(positiveReviews))\nprint(len(negativeReviews))\nprint(len(testReviews))","66de33a0":"# testReviews","f3296705":"reviews = pd.concat([pd.DataFrame({\"review\":positiveReviews, \"label\":1,\n                                   \"file\":positiveFiles}),\n                    pd.DataFrame({\"review\":negativeReviews, \"label\":0,\n                                   \"file\":negativeFiles}),\n                    pd.DataFrame({\"review\":testReviews, \"label\":-1,\n                                   \"file\":testFiles})\n                    ], ignore_index=True).sample(frac=1, random_state=1)\n                    ","4774e79c":"reviews.shape","ae842bf1":"reviews[0:10]","2f6099bc":"from nltk.corpus import stopwords\nimport re","e11a75b1":"stopWords = stopwords.words('english')","090268e8":"def CleanData(sentence):\n    processedList = \"\"\n    \n    #convert to lowercase and ignore special charcter\n    sentence = re.sub(r'[^A-Za-z0-9\\s.]', r'', str(sentence).lower())\n    sentence = re.sub(r'\\n', r' ', sentence)\n    \n    sentence = \" \".join([word for word in sentence.split() if word not in stopWords])\n    \n    return sentence","6c6d6768":"reviews.info()","008830ab":"reviews['review'][0]","d27d0636":"CleanData(reviews['review'][0])","de50f2ab":"reviews['review'] = reviews['review'].map(lambda x: CleanData(x))","3491794a":"reviews['review'].head()","fce00dba":"tmp_corpus = reviews['review'].map(lambda x:x.split('.'))","a44f3bbc":"from tqdm import tqdm","a255cfb6":"#corpus [[w1, w2, w3,...],[...]]\ncorpus = []\n\nfor i in tqdm(range(len(reviews))):\n    for line in tmp_corpus[i]:\n        words = [x for x in line.split()]\n        corpus.append(words)","edd616f5":"len(corpus)","efd3b6a9":"#removing blank list\ncorpus_new = []\nfor i in range(len(corpus)):\n    if (len(corpus[i]) != 0):\n        corpus_new.append(corpus[i])","8e5a1031":"# corpus[1:100]","d704ca2f":"num_of_sentences = len(corpus_new)\nnum_of_words = 0\nfor line in corpus_new:\n    num_of_words += len(line)\n\nprint('Num of sentences - %s'%(num_of_sentences))\nprint('Num of words - %s'%(num_of_words))","a772ec26":"from gensim.models import Word2Vec","6b4d8484":"# sg - skip gram |  window = size of the window | size = vector dimension\nsize = 100\nwindow_size = 2 # sentences weren't too long, so\nepochs = 100\nmin_count = 2\nworkers = 4\n\nmodel = Word2Vec(corpus_new)","6ee85059":"model.build_vocab(sentences= corpus_new, update=True)\n\nfor i in range(5):\n    model.train(sentences=corpus_new, epochs=50, total_examples=model.corpus_count)\n    ","a5fb8b8e":"#save model\nmodel.save('w2v_model')","c3bd4879":"model = Word2Vec.load('w2v_model')","e1815bbc":"model.wv.most_similar('movie')","48a73b78":"reviews.head()","f90514ca":"reviews = reviews[[\"review\", \"label\", \"file\"]].sample(frac=1,\n                                                      random_state=1)\ntrain = reviews[reviews.label!=-1].sample(frac=0.6, random_state=1)\nvalid = reviews[reviews.label!=-1].drop(train.index)\ntest = reviews[reviews.label==-1]","c005f04b":"print(train.shape)\nprint(valid.shape)\nprint(test.shape)","e00d0321":"valid.head()","bc21ef62":"num_features = 100","558b129f":"index2word_set = set(model.wv.index2word)","2db6ec0f":"model = model","474d29d2":"def featureVecorMethod(words):\n    featureVec = np.zeros(num_features, dtype='float32')\n    nwords = 0\n    \n    for word in words:\n        if word in index2word_set:\n            nwords+= 1\n            featureVec = np.add(featureVec, model[word])\n            \n    #average of feature vec\n    featureVec = np.divide(featureVec, nwords)\n    return featureVec","141b372d":"def getAvgFeatureVecs(reviews):\n    counter = 0\n    \n    reviewFeatureVecs = np.zeros((len(reviews), num_features), dtype='float32')\n    for review in reviews:\n#         print(review)\n        if counter%1000 == 0:\n            print(\"Review %d of %d\"%(counter, len(reviews)))\n            \n        reviewFeatureVecs[counter] = featureVecorMethod(review)\n        counter = counter+1\n    return reviewFeatureVecs","686fbf59":"clean_train_reviews = []\nfor review in train['review']:\n#     print(review)\n    clean_train_reviews.append(list(CleanData(review).split()))\n# print(len(clean_train_reviews))\\\n\ntrainDataVecs = getAvgFeatureVecs(clean_train_reviews)\n","4a9ae88f":"len(valid['review'])","0a62d853":"clean_test_reviews = []\nfor review in valid['review']:\n#     print(review)\n    clean_test_reviews.append(list(CleanData(review).split()))\n# print(len(clean_train_reviews))\\\n\ntestDataVecs = getAvgFeatureVecs(clean_test_reviews)","7916605b":"print(len(print(len(testDataVecs))))\nprint(len(testDataVecs))","367b6f35":"import sklearn","3ee84165":"from sklearn.ensemble import RandomForestClassifier\nforest = RandomForestClassifier(n_estimators=100)\n\nprint(\"fitting data\")\nforest = forest.fit(trainDataVecs, train['label'])","5d7cb3d0":"# valid.index","ae485fe5":"result = forest.predict(testDataVecs)","758ba985":"output = pd.DataFrame(data={\"id\":valid.index, \"sentiment\": result})\n","2a5954d3":"from sklearn.metrics import accuracy_score","09c29b28":"accuracy_score(valid['label'], result)","2c7cf33f":"Going to use [gensim](https:\/\/radimrehurek.com\/gensim\/models\/word2vec.html) library to train word2vec model. Gensim accepts input in form of list of lists, where each internal list consists of review sentence.  \n  \nEach review in our data may have more than one sentence. We'll split each sentence and create a list of sentences to pass it to gensim."}}