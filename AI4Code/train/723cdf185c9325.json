{"cell_type":{"f21d122c":"code","647b6420":"code","0fa1de51":"code","b280cb52":"code","9adf7c23":"code","4c038db5":"code","15d30cf2":"code","6c389667":"code","d1944ff1":"markdown","4b122847":"markdown"},"source":{"f21d122c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n# importing stuff\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# a lot of stuff\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Z-score \/ outliers stuff\nfrom scipy import stats\n\n# Rede Neural stuff\nfrom tensorflow.keras import regularizers\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.utils import plot_model\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","647b6420":"#id,datapath, in_port, bc_diff, pc_diff, rx_packets, tx_packets, rx_bytes, tx_bytes, rx_dropped, tx_dropped, rx_errors, tx_errors, collisions\ndf = pd.read_csv('..\/input\/flowcsv\/flow.csv', names=[\"id\", \"datapath\", \"in_port\", \"bc_diff\", \"pc_diff\", \"rx_packets\", \"tx_packets\", \"rx_bytes\", \"tx_bytes\", \"rx_dropped\", \"tx_dropped\", \"rx_errors\", \"tx_errors\", \"collisions\", \"time\"])\ndf","0fa1de51":"graph = {\n    \"10_1\": \"20_1\",\n    \"10_2\": \"21_1\",\n    \"20_1\": \"10_1\",\n    \"20_2\": \"30_2\",\n    \"20_3\": \"31_2\",\n    \"21_1\": \"10_2\",\n    \"21_2\": \"32_2\",\n    \"21_3\": \"33_3\",\n    \"30_1\": \"h0\",\n    \"30_2\": \"20_2\",\n    \"31_1\": \"h1\",\n    \"31_2\": \"20_3\",\n    \"32_1\": \"h2\",\n    \"32_2\": \"21_2\",\n    \"33_1\": \"h3\",\n    \"33_2\": \"21_3\"\n}\n\ndef include_link(column):\n    return graph[column]\n\ndf['out_id'] = [include_link(x) for x in df['id']]\n# df.drop(df[df['out_id'] == \"h0\"].index, inplace=True)\n# df.drop(df[df['out_id'] == \"h1\"].index, inplace=True)\n# df.drop(df[df['out_id'] == \"h2\"].index, inplace=True)\n# df.drop(df[df['out_id'] == \"h3\"].index, inplace=True)\ndf","b280cb52":"df.sort_values(by=['time', 'id'])","9adf7c23":"def afa(id, time):\n    return \"{}_{}\".format(id,time)\ndef afa2(id, time):\n    return \"{}_{}\".format(id,time)\ndf['id_time'] = [afa(x,y) for x,y in zip(df['id'], df['time'])]\ndf['out_id_time'] = [afa2(x,y) for x,y in zip(df['out_id'], df['time'])]\ndf","4c038db5":"result = df.merge(df, how=\"inner\", left_on=[\"id_time\"], right_on=[\"out_id_time\"], suffixes=[\"_from\", \"_to\"])\nresult\n","15d30cf2":"def get_packet_loss(a, b):\n    if (a > 0):\n        return (a - b)\/a\n    else:\n        return 0\nresult['packet_loss'] = [get_packet_loss(x,y) for x,y in zip(result['tx_packets_from'], result['rx_packets_to'])]\nresult","6c389667":"result.to_csv('..\/working\/out.csv',index=False) # save to notebook output\nresult","d1944ff1":"![Inicial.drawio.png](attachment:1d4ba817-8580-4403-abbf-0cc2234503f4.png)","4b122847":"Hi!\n\nMy name is Filipe da Silva de Oliveira, I\u00b4m a computer science student at UDESC, a University from Brasil. I created this notebook to work in my graduate project.\n\nApplying Machine Learning to identify traffic congestion in Datacenters using Software Defined Network.\n\nUsing the [framework RYU](https:\/\/ryu-sdn.org\/) (wich uses the protocol [OpenFlow](https:\/\/dl.acm.org\/doi\/10.1145\/1355734.1355746)) to build a controller in a Data center topology, emulated in [Mininet](http:\/\/mininet.org\/walkthrough\/) I was able to collect some data about the port statics of the switch, and flow table statics.\n\n![image.png](attachment:ffb3166f-485f-48ad-b6e9-eb6f00c3bc92.png)\n\n\n#### Port stats\n\n| 0             | 1       | 2       | 3        | 4        | 5          | 6          | 7         | 8         | 9          |\n|---------------|---------|---------|----------|----------|------------|------------|-----------|-----------|------------|\n| datapath_port | rx-pkts | tx-pkts | rx-bytes | tx-bytes | rx-dropped | tx-dropped | rx-errors | tx-errors | collisions |\n\n#### Flow stats\n\n| 0        | 1       | 2        | 3       | 4       | 5       | 6     | 7        | 8        | 9        | 10       | 11       | 12       |\n|----------|---------|----------|---------|---------|---------|-------|----------|----------|----------|----------|----------|----------|\n| datapath | in-port | out-port | eth-src | eth-dst | packets | bytes | eth-type | ip-proto | ipv4-src | ipv4-dst | port-src | port-dst |\n\n\nNow I\u00b4m trying to model this data.\n"}}