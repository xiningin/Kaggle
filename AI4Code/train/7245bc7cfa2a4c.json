{"cell_type":{"fc8a092d":"code","45d1fdc8":"code","41117020":"code","40b144ea":"code","20d369ff":"code","0b5b4c29":"code","6e3140b7":"code","97daa17a":"code","110d664d":"code","6879c338":"code","354397cd":"code","76b31f85":"code","d60dad73":"code","8eb6e3e2":"code","193946f0":"code","40a5aa75":"code","b5c820ee":"code","b6daf42f":"code","76db7b75":"code","b251bd42":"code","21b29998":"code","3fc12893":"code","ff764b95":"code","9e7bb3c4":"code","e52fa52a":"code","5f0999c8":"code","78dcbddc":"code","52a1b40c":"code","3651cb9f":"markdown","8f9d6a02":"markdown","a2f97af3":"markdown","7a9594ce":"markdown","3f5947c9":"markdown","c04920a0":"markdown","5eee7bdf":"markdown","0c1d3cd4":"markdown","3534346c":"markdown","f204a1d5":"markdown","d3c1e5bc":"markdown","b8ed0d78":"markdown","58083597":"markdown","bf30f1c5":"markdown","5481402c":"markdown","021522e5":"markdown","8800b8c3":"markdown"},"source":{"fc8a092d":"!pip install tensorflow-gpu==2.0.0-rc1","45d1fdc8":"import tensorflow as tf","41117020":"tf.__version__","40b144ea":"# GIF\ub97c \ub9cc\ub4e4\uae30\uc704\ud574 \uc124\uce58\ud569\ub2c8\ub2e4.\n!pip install imageio","20d369ff":"import glob\nimport imageio\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport numpy as np\nimport os\nimport PIL\nfrom PIL import Image\nfrom tensorflow.keras import layers\nimport time\nimport random\n%load_ext tensorboard\nfrom IPython import display\nfrom tensorflow.keras.initializers import RandomNormal\n\n%matplotlib inline","0b5b4c29":"(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()","6e3140b7":"train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\ntrain_images = (train_images - 127.5) \/ 127.5 # \uc774\ubbf8\uc9c0\ub97c [-1, 1]\ub85c \uc815\uaddc\ud654\ud569\ub2c8\ub2e4.","97daa17a":"BUFFER_SIZE = 60000\nBATCH_SIZE = 256","110d664d":"# \ub370\uc774\ud130 \ubc30\uce58\ub97c \ub9cc\ub4e4\uace0 \uc11e\uc2b5\ub2c8\ub2e4.\ntrain_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)","6879c338":"def make_generator_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Reshape((7, 7, 256)))\n    assert model.output_shape == (None, 7, 7, 256) \n\n    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n    assert model.output_shape == (None, 7, 7, 128) \n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n    assert model.output_shape == (None, 14, 14, 64) \n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')) \n    assert model.output_shape == (None, 28, 28, 1) \n\n    return model\n\n   ","354397cd":"generator = make_generator_model()\n\nnoise = tf.random.normal([1, 100])\ngenerated_image = generator(noise, training=False) # \uc790\ub3d9\ucc28 \uc138\ud2b8\uc5d0\uc11c\ub294 training\uc744 True\ub85c \ub450\uace0 \ud574\ubcf4\uc558\ub294\ub370, \uc5ec\uae30\uc11c\ub294 False\ub85c \ud574\uc11c \ud6c8\ud604\ud558\uc9c0 \uc54a\uc740 \uc0c1\ud0dc\uc758 \ubaa8\uc2b5\uc744 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4\n\nplt.imshow(generated_image[0, :, :, 0], cmap='gray')","76b31f85":"def make_critc_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n                                     input_shape=[28, 28, 1]))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Flatten())\n    model.add(layers.Dense(1))\n\n    return model\n\n    ","d60dad73":"critic = make_critc_model()\ndecision = critic(generated_image)\nprint (decision)","8eb6e3e2":"# wgan\uc5d0\uc11c\ub294 cross entrophy\ub97c \uc4f0\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4 \n# cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)","193946f0":"def critic_loss(real_output, fake_output):\n    real_loss = - tf.reduce_mean(real_output)\n    fake_loss = tf.reduce_mean(fake_output)\n    return real_loss, fake_loss\n","40a5aa75":"def generator_loss(fake_output):\n    fake_loss = - tf.reduce_mean(fake_output)\n    return fake_loss","b5c820ee":"# Adam\uc744 Optimizer\ub85c \uc0ac\uc6a9\ud569\ub2c8\ub2e4\ngenerator_optimizer = tf.keras.optimizers.Adam(1e-4)\ncritic_optimizer = tf.keras.optimizers.Adam(1e-4)","b6daf42f":"checkpoint_dir = '.\/training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n                                 critic_optimizer=critic_optimizer,\n                                 generator=generator,\n                                 critic=critic)","76db7b75":"# \ud6c8\ub828 \ub8e8\ud504 \uc815\uc758\ud558\uae30\n\nEPOCHS = 500\nnoise_dim = 100\nnum_examples_to_generate = 16\n\n# \uc774 \uc2dc\ub4dc\ub97c \uc2dc\uac04\uc774 \uc9c0\ub098\ub3c4 \uc7ac\ud65c\uc6a9\ud558\uaca0\uc2b5\ub2c8\ub2e4. \n# (GIF \uc560\ub2c8\uba54\uc774\uc158\uc5d0\uc11c \uc9c4\uc804 \ub0b4\uc6a9\uc744 \uc2dc\uac01\ud654\ud558\ub294\ub370 \uc27d\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4.) \nseed = tf.random.normal([num_examples_to_generate, noise_dim])\n# \ud6c8\ub828 \ub8e8\ud504\ub294 Generator\uac00 \uc785\ub825\uc73c\ub85c \ub79c\ub364\uc2dc\ub4dc\ub97c \ubc1b\ub294 \uac83\uc73c\ub85c\ubd80\ud130 \uc2dc\uc791\ub429\ub2c8\ub2e4. \uadf8 \uc2dc\ub4dc\uac12\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc774\ubbf8\uc9c0\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4. Discrimintor\ub97c \uc0ac\uc6a9\ud558\uc5ec (\ud6c8\ub828 \uc138\ud2b8\uc5d0\uc11c \uac16\uace0\uc628) \uc9c4\uc9dc \uc774\ubbf8\uc9c0\uc640 (Generator\uac00 \uc0dd\uc131\ud574\ub0b8) \uac00\uc9dc\uc774\ubbf8\uc9c0\ub97c \ubd84\ub958\ud569\ub2c8\ub2e4. \uac01 \ubaa8\ub378\uc758 \uc190\uc2e4\uc744 \uacc4\uc0b0\ud558\uace0, \uadf8\ub798\ub514\uc5b8\ud2b8 (gradients)\ub97c \uc0ac\uc6a9\ud574 Generator\uc640 Discrimintor\ub97c \uc5c5\ub370\uc774\ud2b8\ud569\ub2c8\ub2e4.\n","b251bd42":"# \uc774 \ub370\ucf54\ub808\uc774\ud130\ub294 \ud568\uc218\ub97c \"\ucef4\ud30c\uc77c\"\ud569\ub2c8\ub2e4.\n@tf.function\ndef train_step(images):\n    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as cri_tape:\n      generated_images = generator(noise, training=True)\n\n      real_output = critic(images, training=True)\n      fake_output = critic(generated_images, training=True)\n\n      gen_loss = generator_loss(fake_output)\n      cri_loss = critic_loss(real_output, fake_output)\n\n    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n    gradients_of_critic = cri_tape.gradient(cri_loss, critic.trainable_variables)\n\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    critic_optimizer.apply_gradients(zip(gradients_of_critic, critic.trainable_variables))","21b29998":"def train(dataset, epochs):\n  for epoch in range(epochs):\n    start = time.time()\n\n    for image_batch in dataset:\n      train_step(image_batch)\n\n    # GIF\ub97c \uc704\ud55c \uc774\ubbf8\uc9c0\ub97c \ubc14\ub85c \uc0dd\uc131\ud569\ub2c8\ub2e4.\n    display.clear_output(wait=True)\n    generate_and_save_images(generator,\n                             epoch + 1,\n                             seed)\n\n    # 15 \uc5d0\ud3ec\ud06c\uac00 \uc9c0\ub0a0 \ub54c\ub9c8\ub2e4 \ubaa8\ub378\uc744 \uc800\uc7a5\ud569\ub2c8\ub2e4.\n    if (epoch + 1) % 15 == 0:\n      checkpoint.save(file_prefix = checkpoint_prefix)\n    \n    # print (' \uc5d0\ud3ec\ud06c {} \uc5d0\uc11c \uac78\ub9b0 \uc2dc\uac04\uc740 {} \ucd08 \uc785\ub2c8\ub2e4'.format(epoch +1, time.time()-start))\n    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n\n  # \ub9c8\uc9c0\ub9c9 \uc5d0\ud3ec\ud06c\uac00 \ub05d\ub09c \ud6c4 \uc0dd\uc131\ud569\ub2c8\ub2e4.\n  display.clear_output(wait=True)\n  generate_and_save_images(generator,\n                           epochs,\n                           seed)\n","3fc12893":"# \uc774\ubbf8\uc9c0 \uc0dd\uc131 \ubc0f \uc800\uc7a5\n\ndef generate_and_save_images(model, epoch, test_input):\n  # `training`\uc774 False\ub85c \ub9de\ucdb0\uc9c4 \uac83\uc744 \uc8fc\ubaa9\ud558\uc138\uc694.\n  # \uc774\ub807\uac8c \ud558\uba74 (\ubc30\uce58\uc815\uaddc\ud654\ub97c \ud3ec\ud568\ud558\uc5ec) \ubaa8\ub4e0 \uce35\ub4e4\uc774 \ucd94\ub860 \ubaa8\ub4dc\ub85c \uc2e4\ud589\ub429\ub2c8\ub2e4. \n  predictions = model(test_input, training=False)\n\n  fig = plt.figure(figsize=(4,4))\n\n  for i in range(predictions.shape[0]):\n      plt.subplot(4, 4, i+1)\n      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n      plt.axis('off')\n\n  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n  plt.show()\n","ff764b95":"# \ubaa8\ub378 \ud6c8\ub828\n# \uc704\uc5d0 \uc815\uc758\ub41c train() \uba54\uc11c\ub4dc\ub97c Generator\uc640 Critic\uc744 \ub3d9\uc2dc\uc5d0 \ud6c8\ub828\ud558\uae30 \uc704\ud574 \ud638\ucd9c\ud569\ub2c8\ub2e4. \uc0dd\uc131\uc801 \uc801\ub300 \uc2e0\uacbd\ub9dd\uc744 \ud559\uc2b5\ud558\ub294 \uac83\uc740 \ub9e4\uc6b0 \uae4c\ub2e4\ub85c\uc6b8 \uc218 \uc788\uc2b5\ub2c8\ub2e4. Generator\uc640 Critic\uc774 \uc11c\ub85c\ub97c \uc81c\uc555\ud558\uc9c0 \uc54a\ub294 \uac83\uc774 \uc911\uc694\ud569\ub2c8\ub2e4. (\uc608\ub97c \ub4e4\uc5b4 \ud559\uc2b5\ub960\uc774 \ube44\uc2b7\ud558\uba74 \ud55c\ucabd\uc774 \uc6b0\uc138\ud574\uc9d1\ub2c8\ub2e4.) \ud6c8\ub828 \ucd08\ubc18\ubd80\uc5d0\ub294 \uc0dd\uc131\ub41c \uc774\ubbf8\uc9c0\ub294 \ub79c\ub364\ud55c \ub178\uc774\uc988\ucc98\ub7fc \ubcf4\uc785\ub2c8\ub2e4. \ud6c8\ub828\uc774 \uc9c4\ud589\ub420\uc218\ub85d, \uc0dd\uc131\ub41c \uc22b\uc790\ub294 \uc810\ucc28 \uc9c4\uc9dc\ucc98\ub7fc \ubcf4\uc77c \uac83\uc785\ub2c8\ub2e4. \uc57d 50 \uc5d0\ud3ec\ud06c\uac00 \uc9c0\ub09c \ud6c4, MNIST \uc22b\uc790\uc640 \ub2ee\uc740 \uc774\ubbf8\uc9c0\uac00 \uc0dd\uc131\ub429\ub2c8\ub2e4. \ucf54\ub7a9\uc5d0\uc11c \uae30\ubcf8 \uc124\uc815\uc73c\ub85c \uc2e4\ud589\ud558\uba74, \uc5d0\ud3ec\ud06c\ub9c8\ub2e4 1\ubd84\uc815\ub3c4 \uc18c\uc694\ub420 \uac83\uc785\ub2c8\ub2e4.\n%%time\ntrain(train_dataset, EPOCHS)","9e7bb3c4":"# \ub9c8\uc9c0\ub9c9 \uccb4\ud06c\ud3ec\uc778\ud2b8\ub97c \ubcf5\uad6c\ud569\ub2c8\ub2e4.\ncheckpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))","e52fa52a":"# GIF \uc0dd\uc131\n\n# \uc5d0\ud3ec\ud06c \uc22b\uc790\ub97c \uc0ac\uc6a9\ud558\uc5ec \ud558\ub098\uc758 \uc774\ubbf8\uc9c0\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.\ndef display_image(epoch_no):\n  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))","5f0999c8":"display_image(EPOCHS)","78dcbddc":"# imageio\ub85c \ud6c8\ub828 \uc911\uc5d0 \uc800\uc7a5\ub41c \uc774\ubbf8\uc9c0\ub97c \uc0ac\uc6a9\ud574 GIF \uc560\ub2c8\uba54\uc774\uc158\uc744 \ub9cc\ub4ed\ub2c8\ub2e4.\n\nanim_file = 'wgan.gif'\n\nwith imageio.get_writer(anim_file, mode='I') as writer:\n  filenames = glob.glob('image*.png')\n  filenames = sorted(filenames)\n  last = -1\n  for i,filename in enumerate(filenames):\n    frame = 2*(i**0.5)\n    if round(frame) > round(last):\n      last = frame\n    else:\n      continue\n    image = imageio.imread(filename)\n    writer.append_data(image)\n  image = imageio.imread(filename)\n  writer.append_data(image)\n\nimport IPython\nif IPython.version_info > (6,2,0,''):\n  display.Image(filename=anim_file)","52a1b40c":"# \ucf54\ub7a9\uc5d0\uc11c \uc791\uc5c5\ud558\uace0 \uc788\ub2e4\uba74, \uc544\ub798\uc758 \ucf54\ub4dc\uc5d0\uc11c \uc560\ub2c8\uba54\uc774\uc158\uc744 \ub2e4\uc6b4\ub85c\ub4dc \ubc1b\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4:\n\ntry:\n  from google.colab import files\nexcept ImportError:\n  pass\nelse:\n  files.download(anim_file)","3651cb9f":"Generator\uc640 \ub9c8\ucc2c\uac00\uc9c0\ub85c (\uc544\uc9c1\uae4c\uc9c0 \ud6c8\ub828\uc774 \ub418\uc9c0 \uc54a\uc740) critic\ub97c \uc0ac\uc6a9\ud558\uc5ec, \uc0dd\uc131\ub41c \uc774\ubbf8\uc9c0\uac00 \uc9c4\uc9dc\uc778\uc9c0 \uac00\uc9dc\uc778\uc9c0 \ud310\ubcc4\ud569\ub2c8\ub2e4. \ubaa8\ub378\uc740 \uc9c4\uc9dc \uc774\ubbf8\uc9c0\uc5d0\ub294 \uc591\uc218\uc758 \uac12 (positive values)\uc744, \uac00\uc9dc \uc774\ubbf8\uc9c0\uc5d0\ub294 \uc74c\uc218\uc758 \uac12 (negative values)\uc744 \ucd9c\ub825\ud558\ub3c4\ub85d \ud6c8\ub828\ub418\uc5b4\uc9d1\ub2c8\ub2e4.","8f9d6a02":"Generator \uc190\uc2e4\ud568\uc218\nGenerator\uc758 \uc190\uc2e4\ud568\uc218\ub294 critic\ub97c \uc5bc\ub9c8\ub098 \uc798 \uc18d\uc600\ub294\uc9c0\uc5d0 \ub300\ud574 \uc218\uce58\ud654\ub97c \ud569\ub2c8\ub2e4. \uc9c1\uad00\uc801\uc73c\ub85c Generator\uac00 \uc6d0\ud65c\ud788 \uc218\ud589\ub418\uace0 \uc788\ub2e4\uba74, critic\ub294 \uac00\uc9dc \uc774\ubbf8\uc9c0\ub97c \uc9c4\uc9dc (\ub610\ub294 1)\ub85c \ubd84\ub958\ub97c \ud560 \uac83\uc785\ub2c8\ub2e4. \uc5ec\uae30\uc11c \uc6b0\ub9ac\ub294 \uc0dd\uc131\ub41c \uc774\ubbf8\uc9c0\uc5d0 \ub300\ud55c critic\uc758 \uacb0\uc815\uc744 1\ub85c \uc774\ub8e8\uc5b4\uc9c4 \ud589\ub82c\uacfc \ube44\uad50\ub97c \ud560 \uac83\uc785\ub2c8\ub2e4.","a2f97af3":"\ub2e4\uc74c\uc5d0\ub294 \ub611 \uac19\uc740 DB\ub85c WGAN-GP\uc744 \ud574\ubd05\ub2c8\ub2e4","7a9594ce":"### \ud150\uc11c\ud50c\ub85c\uc640 \ub2e4\ub978 \ub77c\uc774\ube0c\ub7ec\ub9ac \ubd88\ub7ec\uc624\uae30","3f5947c9":"## \uc190\uc2e4\ud568\uc218\uc640 \uc635\ud2f0\ub9c8\uc774\uc800 \uc815\uc758\n\ub450 \ubaa8\ub378\uc758 \uc190\uc2e4\ud568\uc218\uc640 \uc635\ud2f0\ub9c8\uc774\uc800\ub97c \uc815\uc758\ud569\ub2c8\ub2e4. ","c04920a0":"## \ub2e4\uc74c \ub2e8\uacc4","5eee7bdf":"Acknowledgement: Portions of this page are reproduced and modified from work created and shared by Google and used according to terms described in the Creative Commons 4.0 Attribution License.\n\n* DCGAN Model\uc5d0\uc11c WGAN\ubaa8\ub378\ub85c \ubc14\uafb8\uc5b4\uc11c \ud574\ubd05\ub2c8\ub2e4","0c1d3cd4":"*\uc6b0\uc120 \ud150\uc11c \ud50c\ub85c\uc6b0\ub97c \uc124\uce58\ud569\ub2c8\ub2e4","3534346c":"### Discriminator --> Critic\n Discriminator\ub294 wgan\uc5d0\uc11c\ub294 critic\uc73c\ub85c \ubc14\ub01d\ub2c8\ub2e4","f204a1d5":"### \uccb4\ud06c\ud3ec\uc778\ud2b8 \uc800\uc7a5\n\uc774 \ub178\ud2b8\ubd81\uc740 \uc624\ub7ab\ub3d9\uc548 \uc9c4\ud589\ub418\ub294 \ud6c8\ub828\uc774 \ubc29\ud574\ub418\ub294 \uacbd\uc6b0\uc5d0 \uc720\uc6a9\ud558\uac8c \uc4f0\uc77c \uc218 \uc788\ub294 \ubaa8\ub378\uc758 \uc800\uc7a5\ubc29\ubc95\uacfc \ubcf5\uad6c\ubc29\ubc95\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. ","d3c1e5bc":"### Model Traning","b8ed0d78":"(\uc544\uc9c1 \ud6c8\ub828\uc774 \ub418\uc9c0\uc54a\uc740) generator\ub97c \uc774\uc6a9\ud574 \uc774\ubbf8\uc9c0\ub97c \uc0dd\uc131\ud574\ubd05\uc2dc\ub2e4. ","58083597":"### Critic Loss Function\n\nWasserstein GAN\uc740 1-Wasserstein distance\ub97c \uc0ac\uc6a9\ud558\uace0 JS-Divergence\ub97c \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uace0 \ubaa8\ub378 \ubc0f \ud0c0\uac9f \ub514\uc2a4\ud2b8\ub9ac\ubdf0\uc158\uc744 \uce21\ub7c9\ud569\ub2c8\ub2e4","bf30f1c5":"### Experiment utils (RUN ME!)","5481402c":"### Generator\n\nGenerator\ub294 \uae30\ubcf8\uc801\uc73c\ub85c dcgan\uc774\ub098 wgan\uc774\ub098 \ub9c8\ucc2c\uac00\uc9c0\ub85c \ud569\ub2c8\ub2e4","021522e5":"### \ub370\uc774\ud130\uc14b \ub85c\ub529 \ubc0f \uc900\ube44\nGenerator\uc640 critic\ub97c \ud6c8\ub828\ud558\uae30\uc704\ud574 MNIST \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud560\uac83\uc785\ub2c8\ub2e4. Generator\ub294 \uc218\uae30 \uc22b\uc790 \ub370\uc774\ud130\ub97c \ub2ee\uc740 \uc22b\uc790\ub4e4\uc744 \uc0dd\uc131\ud560 \uac83\uc785\ub2c8\ub2e4. ","8800b8c3":"## \ubaa8\ub378 \ub9cc\ub4e4\uae30 \nGenerator\uc640 critic\ub294 [\ucf00\ub77c\uc2a4 Sequential API](https:\/\/www.tensorflow.org\/guide\/keras#sequential_model)\ub97c \uc774\uc6a9\ud574 \uc815\uc758\ub429\ub2c8\ub2e4. "}}