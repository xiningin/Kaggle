{"cell_type":{"15c547e1":"code","5d32c1b4":"code","0813152b":"code","bca789ea":"code","d8fa1831":"code","4528277e":"code","efcbe109":"code","7cffee53":"code","f1dc7963":"code","bbfa5fe7":"code","27f8caa2":"code","24184bcd":"code","0a9caf62":"code","e36a95fe":"code","8e97d767":"code","8b46555a":"code","3a76febd":"code","e1ac826a":"code","6c59d6e7":"code","70657036":"code","67276fce":"code","19a2b89f":"code","43069f37":"code","0a5ad39d":"code","14db9a3a":"code","6ad900da":"code","b233aebf":"code","709481fa":"code","4b5e595c":"code","8dab4e9b":"code","2f0dca0d":"code","a72006c0":"code","c9a4fecf":"code","a8ae932c":"code","c7afb490":"code","1fd3936a":"code","cc256693":"code","d16036f1":"code","526aa644":"code","154a0ee2":"code","226d85d6":"code","b46e87ec":"code","6b82aec3":"code","c676ccd5":"markdown"},"source":{"15c547e1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5d32c1b4":"### Loading all the required modules- \nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import GradientBoostingClassifier\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n### Create a datapipeline for numeric and categorical attributes\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer","0813152b":"## Reading the train and test data sets\ntr_data=pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data=pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n","bca789ea":"tr_data.head(5)","d8fa1831":"## Number of instances and Attributes\nprint(\"The data has {} instances and {} attributes and {} target variable\".format(tr_data.shape[0],tr_data.shape[1]-1,1))\nprint(\"\\n\")\n\n## Data types as interpreted in pandas\nprint(tr_data.dtypes)\nprint(\"\\n\")\n\n## Are there any missing values\nprint(tr_data.isnull().sum())","4528277e":"### How many instances in each class of target (survived in this case)\nprint(tr_data['Survived'].value_counts())\nprint(\"\\n\")\nprint(tr_data['Survived'].value_counts(normalize=True))","efcbe109":"## Visualizing the data\ntr_data['Survived'].value_counts().plot(kind='bar')","7cffee53":"## Any relationship of survival with gender\nsns.barplot('Sex','Survived',hue='Sex',data= tr_data) \n## There is about 74%  chance for women to survive and 19% survival for male","f1dc7963":"#### Relation between age and survival\nbins = [0, 15, 30, 45, 60, np.inf]\ntr_data['Age_bins'] = pd.cut(tr_data['Age'], bins)\nprint(tr_data['Age'].describe())\nprint(\"\\n\")\nsns.barplot('Age_bins','Survived',hue= 'Sex',data=tr_data)\n\n## Children below 15 years has a higher rate of survival. Female has higher survival rate","bbfa5fe7":"#### Relation between Class and survival\nsns.barplot('Pclass','Survived',data= tr_data) \n## Chances of survival are greater for class 1 compared to other classes","27f8caa2":"### Data Preprocessing\ncols= ['Pclass','Survived','Name','Sex','SibSp','Parch','Cabin','Embarked']\nfor col in cols:\n    tr_data[col]=tr_data[col].astype('category')\n","24184bcd":"y= tr_data['Survived']\nx=tr_data['Name'].str.split(\".\",expand=True)\ntr_data['Last Name']= x[0]\n\n## Again\nx= tr_data['Last Name'].str.split(\",\",expand=True)\ntr_data['Last Name']= x[0]\ntr_data['Title']= x[1]\n\n\nprint(tr_data['Last Name'].nunique())\nprint(\"\\n\")\nprint(tr_data['Title'].nunique())\n","0a9caf62":"### For tickets\ntr_data['len']=tr_data['Ticket'].str.len()\ntr_data['ticket']=0\ntr_data.loc[tr_data['len'] <5, 'ticket']=1\ntr_data.loc[(tr_data['len'] >5) & ( tr_data['len'] <= 7), 'ticket']=2\ntr_data.loc[(tr_data['len'] >7 )& (tr_data['len']<=10), 'ticket']=3\ntr_data.loc[tr_data['len'] >10, 'ticket']=4","e36a95fe":"tr_data.head(20)","8e97d767":"tr_data.drop(['Survived','Ticket','Name','PassengerId','len','Last Name','Age_bins'],axis=1,inplace=True)\n","8b46555a":"cat_attr=['Pclass','Sex','SibSp','Parch','Cabin','Embarked','ticket','Title']\nnum_attr=['Age','Fare']\ntr_data.dtypes","3a76febd":"tr_data['ticket']=tr_data['ticket'].astype('category')\ntr_data['Title']=tr_data['Title'].astype('category')\ntr_data.dtypes","e1ac826a":"### Split the data into train and validation\nX_train,X_val,y_train,y_val = train_test_split(tr_data,y, test_size=0.02,random_state=1234)","6c59d6e7":"print(X_train.shape, y_train.shape)\nprint(\"\\n\")\nprint(X_val.shape, y_val.shape)\n","70657036":"#### Dealing with missing values\nX_train['Cabin']=X_train['Cabin'].cat.add_categories(\"Unknown\").fillna(\"Unknown\")\nX_val['Cabin']=X_val['Cabin'].cat.add_categories(\"Unknown\").fillna(\"Unknown\")\n\nX_train['Age']","67276fce":"### Using pipelines for handling the train and test data\nnum_transformer=Pipeline(steps=[('numimputer',SimpleImputer(strategy=\"mean\")),\n                                ('scaler',StandardScaler())])\ncategorical_transformer = Pipeline(steps=[('catimputer', SimpleImputer(strategy='most_frequent')),('onehot', OneHotEncoder(handle_unknown='ignore'))])\n\npreprocessor = ColumnTransformer(transformers=[('num', num_transformer, num_attr),\n                                               ('cat', categorical_transformer, cat_attr)])\n","19a2b89f":"### Logistic Regression model\nclf_logreg = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('classifier', LogisticRegression(class_weight='balanced'))])","43069f37":"clf_logreg.fit(X_train,y_train)","0a5ad39d":"X_val.isnull().sum()","14db9a3a":"### Predictions from trained model\ntrain_pred = clf_logreg.predict(X_train)\nval_pred = clf_logreg.predict(X_val)","6ad900da":"from sklearn.metrics import classification_report,confusion_matrix\nprint(confusion_matrix(y_true=y_val, y_pred = val_pred))\nprint(classification_report(y_true=y_val, y_pred =  val_pred))","b233aebf":"cols= ['Pclass','Name','Sex','SibSp','Parch','Cabin','Embarked']\nfor col in cols:\n    test_data[col]=test_data[col].astype('category')\n    \n","709481fa":"test_data['len']=test_data['Ticket'].str.len()\ntest_data['ticket']=0\ntest_data.loc[test_data['len'] <5, 'ticket']=1\ntest_data.loc[(test_data['len'] >5) & ( test_data['len'] <= 7), 'ticket']=2\ntest_data.loc[(test_data['len'] >7 )& (test_data['len']<=10), 'ticket']=3\ntest_data.loc[test_data['len'] >10, 'ticket']=4","4b5e595c":"x=test_data['Name'].str.split(\".\",expand=True)\ntest_data['Last Name']= x[0]\n\n## Again\nx= test_data['Last Name'].str.split(\",\",expand=True)\ntest_data['Last Name']= x[0]\ntest_data['Title']= x[1]\n\ntest_data['Title']=test_data['Title'].astype('category')\n\ndel x","8dab4e9b":"test_data.drop(['PassengerId','Ticket','Name','len','Last Name'],axis=1,inplace=True)","2f0dca0d":"test_data.dtypes","a72006c0":"test_data.isnull().sum()","c9a4fecf":"test_data['Cabin']=test_data['Cabin'].cat.add_categories(\"Unknown\").fillna(\"Unknown\")","a8ae932c":"test_pred = clf_logreg.predict(test_data)\ntest_pred=pd.DataFrame(test_pred,columns=['Survived'])","c7afb490":"test_pass=pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\",usecols=['PassengerId'])\nsubmission=pd.concat([test_pass,test_pred],axis=1)\nsubmission.head()","1fd3936a":"submission.to_csv(\"gender_submission8.csv\",index=False)","cc256693":"from sklearn.ensemble import RandomForestClassifier\n\n## Lets Use a differnt algorithm\nclf_rf = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('classifier', RandomForestClassifier(n_estimators=300,class_weight='balanced',criterion='entropy',max_depth=5))])","d16036f1":"clf_rf.fit(X_train,y_train)\n\n### Predictions from trained model\ntrain_pred = clf_rf.predict(X_train)\nval_pred = clf_rf.predict(X_val)\n","526aa644":"print(confusion_matrix(y_true=y_val, y_pred = val_pred))\nprint(classification_report(y_true=y_val, y_pred =  val_pred))","154a0ee2":"test_pred = clf_logreg.predict(test_data)\ntest_pred=pd.DataFrame(test_pred,columns=['Survived'])\n","226d85d6":"test_pred.value_counts()","b46e87ec":"test_pred.head(20)","6b82aec3":"submission=pd.concat([test_pass,test_pred],axis=1)\nsubmission.head()\nsubmission.to_csv(\"gender_submission9.csv\",index=False)","c676ccd5":"#### To get a basic understanding of the data"}}