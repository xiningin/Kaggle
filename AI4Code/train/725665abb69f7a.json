{"cell_type":{"5b182995":"code","2382ae0c":"code","27389cc3":"code","cc05c69f":"code","4ee9ef94":"code","7ed04b5b":"code","7c6247d6":"code","282b1edc":"code","4f9055db":"code","765aa44f":"code","f497cdd9":"code","9bd6a78f":"code","637edd5d":"code","01bd85a9":"code","dce99005":"code","73f20b13":"code","79119151":"code","3067793e":"code","82943946":"code","e27bb2ed":"code","895bde51":"code","119454a5":"code","a6c0381e":"code","8f6842b8":"code","b745d4d3":"code","c4205d74":"code","8ab0b582":"markdown","7876ddbd":"markdown","70cf9833":"markdown","3206fe57":"markdown","262e3dcb":"markdown","752f7927":"markdown","e5cce784":"markdown","ab2d1489":"markdown"},"source":{"5b182995":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2382ae0c":"os.system('apt-get install p7zip')","27389cc3":"!pip install pyunpack\n!pip install patool","cc05c69f":"from pyunpack.cli import Archive\n\ndirectory = '\/kaggle\/working\/'\nArchive('\/kaggle\/input\/kkbox-music-recommendation-challenge\/train.csv.7z').extractall(directory)\nArchive('\/kaggle\/input\/kkbox-music-recommendation-challenge\/test.csv.7z').extractall(directory)","4ee9ef94":"train = pd.read_csv('\/kaggle\/working\/train.csv')\ntest = pd.read_csv('\/kaggle\/working\/test.csv')","7ed04b5b":"validation = train.sample(frac=0.1, random_state=2020)\ntrain = train.drop(validation.index, axis=0)\n\ntrain = train.reset_index(drop=True)\nvalidation = validation.reset_index(drop=True)","7c6247d6":"from scipy.sparse import csr_matrix","282b1edc":"def dataframe_to_matrix(df):\n    users = df.msno.unique()\n    songs = df.song_id.unique()\n\n    user2idx = {user:idx for idx, user in enumerate(users)}\n    song2idx = {song:idx for idx, song in enumerate(songs)}\n    \n    rows = np.array(df.msno.map(user2idx))\n    cols = np.array(df.song_id.map(song2idx))\n    data = np.array(df.target)\n    \n    matrix = csr_matrix((data, (rows, cols)))\n    \n    return user2idx, song2idx, matrix","4f9055db":"user2idx, song2idx, matrix = dataframe_to_matrix(train)","765aa44f":"from sklearn.decomposition import TruncatedSVD","f497cdd9":"def matrix_factorization(matrix, n_components=100, n_iter=5):\n    svd = TruncatedSVD(n_components=n_components, n_iter=n_iter, random_state=2020)\n    U = svd.fit_transform(matrix)\n    S = np.diag(svd.singular_values_)\n    Vt = svd.components_.T\n    \n    return svd, U, S, Vt","9bd6a78f":"svd, U, S, Vt = matrix_factorization(matrix, n_components=200, n_iter=10)","637edd5d":"def predict(user, item, S, threshold):\n    user = user.reshape((1, -1))\n    item = item.reshape((-1, 1))\n    rating = np.dot(np.dot(user, S), item)\n    return rating, int(rating >= threshold)","01bd85a9":"def calculate_accuracy(prediction, real):\n    return np.mean(np.equal(prediction, real))","dce99005":"def item_to_idx(item, dictionary):\n    return dictionary[item] if item in dictionary else -1","73f20b13":"from tqdm import tqdm","79119151":"scores = dict()\n\nreal = np.array(validation.target)\nthresholds = np.arange(0, 50, 10)\n\nfor threshold in tqdm(thresholds):\n    prediction = list()\n    for user, song in zip(validation.msno, validation.song_id):\n        user_idx, song_idx = item_to_idx(user, user2idx), item_to_idx(song, song2idx)\n        if user_idx == -1 or song_idx == -1:\n            p = 0\n        else:\n            _, p = predict(U[user_idx], Vt[song_idx], S, threshold)\n        prediction.append(p)\n        \n    accuracy = calculate_accuracy(prediction, real)\n    scores[threshold] = accuracy\nscores","3067793e":"import matplotlib.pyplot as plt","82943946":"plt.figure(figsize=(16, 9))\nplt.plot(list(scores.keys()), list(scores.values()))\nplt.title('Validation Accuracy by Threshold')\nplt.xlabel('Threshold')\nplt.ylabel('Validation Accuracy')\nplt.show()","e27bb2ed":"thresholds = np.arange(0, 50, 10)\nmetrics = [(100, 5, \n             np.array([0.5163769990050723, \n                       0.6042369825765647, \n                       0.6067568336898266, \n                       0.6048428854531801, \n                       0.6009512810711604])\n           ),\n           (100, 10, \n             np.array([0.5163024471969876, \n                       0.6042681587872183,\n                       0.6069086482808353,\n                       0.6049811451699917,\n                       0.6010759859137748])\n           ),\n           (200, 5, \n             np.array([0.5181066009526366,\n                       0.6068937379192184,\n                       0.6096548657931906,\n                       0.6073640920538617,\n                       0.6031593700778863])\n           ),\n           (200, 10, \n             np.array([0.5180930460784393,\n                       0.6067500562527279,\n                       0.6097795706358049,\n                       0.6075877474781156,\n                       0.6033626931908445])\n           ),\n          ]\n\nplt.figure(figsize=(16, 9))\nfor c, i, score in metrics:\n    plt.plot(thresholds, score, label='n_component={}, n_iter={}'.format(c, i))\nplt.legend()\nplt.xlabel('Threshold')\nplt.ylabel('Accuracy')\nplt.title('Accuracy by Threshold. (Hyperparameter Adjusting)')\nplt.savefig('\/kaggle\/working\/Hyperparameter_Comparison.png')\nplt.show()","895bde51":"n_components = 200\nn_iter = 10\nthreshold = 20","119454a5":"train = pd.concat([train, validation], axis=0, ignore_index=True, sort=False).reset_index(drop=True)","a6c0381e":"user2idx, song2idx, matrix = dataframe_to_matrix(train)","8f6842b8":"svd, U, S, Vt = matrix_factorization(matrix, n_components=n_components, n_iter=n_iter)","b745d4d3":"real = np.array(validation.target)\nprediction = list()\nfor user, song in tqdm(zip(test.msno, test.song_id)):\n    user_idx, song_idx = item_to_idx(user, user2idx), item_to_idx(song, song2idx)\n    if user_idx == -1 or song_idx == -1:\n        p = 0\n    else:\n        _, p = predict(U[user_idx], Vt[song_idx], S, threshold)\n    prediction.append(p)","c4205d74":"submission = pd.DataFrame(columns=['id', 'target'])\nsubmission['id'] = test.id\nsubmission['target'] = prediction\nsubmission.head()\nsubmission.to_csv('\/kaggle\/working\/submission.csv', index=False)","8ab0b582":"### Unzip Dataset","7876ddbd":"### Prediction(Recommendataion) - Test for Submission","70cf9833":"### Data Preprocessing","3206fe57":"### Matrix Factorization","262e3dcb":"0. original n_component=100, n_iter=5\n\n<table>\n    <thead>\n        <tr>\n            <th>threshold<\/th><th>accuracy<\/th>\n        <\/tr>\n    <\/thead>\n    <tbody>\n        <tr>\n            <td>0<\/td><td>0.5163769990050723<\/td>\n        <\/tr>\n        <tr>\n            <td>10<\/td><td>0.6042369825765647<\/td>\n        <\/tr>\n        <tr>\n            <td>20<\/td><td>0.6067568336898266<\/td>\n        <\/tr>\n        <tr>\n            <td>30<\/td><td>0.6048428854531801<\/td>\n        <\/tr>\n        <tr>\n            <td>40<\/td><td>0.6009512810711604<\/td>\n        <\/tr>\n    <\/tbody>\n<\/table>\n\n<hr>\n\n1. increase n_iter from 5 to 10 (n_component = 100)\n\n<table>\n    <thead>\n        <tr>\n            <th>threshold<\/th><th>accuracy<\/th>\n        <\/tr>\n    <\/thead>\n    <tbody>\n        <tr>\n            <td>0<\/td><td>0.5163024471969876<\/td>\n        <\/tr>\n        <tr>\n            <td>10<\/td><td>0.6042681587872183<\/td>\n        <\/tr>\n        <tr>\n            <td>20<\/td><td>0.6069086482808353<\/td>\n        <\/tr>\n        <tr>\n            <td>30<\/td><td>0.6049811451699917<\/td>\n        <\/tr>\n        <tr>\n            <td>40<\/td><td>0.6010759859137748<\/td>\n        <\/tr>\n    <\/tbody>\n<\/table>\n\n<hr>\n\n2. increase n_component from 100 to 200 (n_iter = 5)\n\n<table>\n    <thead>\n        <tr>\n            <th>threshold<\/th><th>accuracy<\/th>\n        <\/tr>\n    <\/thead>\n    <tbody>\n        <tr>\n            <td>0<\/td><td>0.5181066009526366<\/td>\n        <\/tr>\n        <tr>\n            <td>10<\/td><td>0.6068937379192184<\/td>\n        <\/tr>\n        <tr>\n            <td>20<\/td><td>0.6096548657931906<\/td>\n        <\/tr>\n        <tr>\n            <td>30<\/td><td>0.6073640920538617<\/td>\n        <\/tr>\n        <tr>\n            <td>40<\/td><td>0.6031593700778863<\/td>\n        <\/tr>\n    <\/tbody>\n<\/table>\n\n<hr>\n\n3. increase both n_component from 100 to 200 and n_iter form 5 to 10\n\n<table>\n    <thead>\n        <tr>\n            <th>threshold<\/th><th>accuracy<\/th>\n        <\/tr>\n    <\/thead>\n    <tbody>\n        <tr>\n            <td>0<\/td><td>0.5180930460784393<\/td>\n        <\/tr>\n        <tr>\n            <td>10<\/td><td>0.6067500562527279<\/td>\n        <\/tr>\n        <tr>\n            <td>20<\/td><td>0.6097795706358049<\/td>\n        <\/tr>\n        <tr>\n            <td>30<\/td><td>0.6075877474781156<\/td>\n        <\/tr>\n        <tr>\n            <td>40<\/td><td>0.6033626931908445<\/td>\n        <\/tr>\n    <\/tbody>\n<\/table>","752f7927":"### Prediction(Recommendataion) - Validation","e5cce784":"### Train and Validation Split","ab2d1489":"### Load Dataset"}}