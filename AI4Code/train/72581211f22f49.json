{"cell_type":{"55f02ce5":"code","2baed710":"code","9063645c":"code","8441106e":"code","5fd17af5":"code","02a3869b":"code","8d570daf":"code","ee14b423":"code","68db6ef5":"code","779b8a94":"code","1d820240":"code","a041733b":"code","9573c3d4":"code","228cb7fc":"code","abb73bbc":"code","923d8e40":"code","cf3844c9":"code","a30cafec":"code","b546f895":"code","43ef9aa3":"code","beb7cc9e":"code","92336f7e":"code","b2c35ebe":"code","1fb087a7":"markdown","49d918dc":"markdown","74181b89":"markdown","9f40f5fb":"markdown","ab87296a":"markdown","49e43746":"markdown","07f2f675":"markdown","71b9b32f":"markdown","fb27d39b":"markdown","26da391b":"markdown","517a1d29":"markdown","edb0cfcc":"markdown","205be54a":"markdown","b26171a7":"markdown","be3e3791":"markdown","0dd02df6":"markdown","97fccd7e":"markdown","5e7e3d55":"markdown","b36d8437":"markdown","6d98f156":"markdown","a1027a66":"markdown","f22dbe3b":"markdown","289449ce":"markdown","438dd6b0":"markdown","6f587fc9":"markdown","9b6bad8d":"markdown","c9778f1d":"markdown","f07e491a":"markdown","990d3109":"markdown","f6df6a51":"markdown"},"source":{"55f02ce5":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))","2baed710":"# load the iris dataset\niris_data = pd.read_csv('..\/input\/Iris.csv')","9063645c":"# my personal reusable function for detecting missing data\ndef missing_value_describe(data):\n    # check missing values in training data\n    missing_value_stats = (data.isnull().sum() \/ len(data)*100)\n    missing_value_col_count = sum(missing_value_stats > 0)\n    missing_value_stats = missing_value_stats.sort_values(ascending=False)[:missing_value_col_count]\n    print(\"Number of columns with missing values:\", missing_value_col_count)\n    if missing_value_col_count != 0:\n        # print out column names with missing value percentage\n        print(\"\\nMissing percentage (desceding):\")\n        print(missing_value_stats)\n    else:\n        print(\"No misisng data!!!\")\nmissing_value_describe(iris_data)","8441106e":"# take a peek\niris_data.head()","5fd17af5":"iris_data = iris_data.drop(['Id'], axis=1)\niris_data.columns","02a3869b":"# dimension\nprint(\"the dimension:\", iris_data.shape)","8d570daf":"print(iris_data.describe())","ee14b423":"# class distribution\nprint(iris_data.groupby('Species').size())","68db6ef5":"# import ploting tool\nimport matplotlib.pyplot as plt","779b8a94":"# iris flower dataset class distribution\nnameplot = iris_data['Species'].value_counts().plot.bar(title='Flower class distribution')\nnameplot.set_xlabel('class',size=20)\nnameplot.set_ylabel('count',size=20)","1d820240":"# box and whisker plots\niris_data.plot(kind='box', subplots=True, layout=(2,2), \n               sharex=False, sharey=False, title=\"Box and Whisker plot for each attribute\")\nplt.show()","a041733b":"# plot histogram\niris_data.hist()\nplt.show()","9573c3d4":"import seaborn as sns\nsns.set(style=\"ticks\")\nsns.pairplot(iris_data, hue=\"Species\")","228cb7fc":"from sklearn.model_selection import train_test_split","abb73bbc":"# we will split data to 80% training data and 20% testing data with random seed of 10\nX = iris_data.drop(['Species'], axis=1)\nY = iris_data['Species']\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=7)","923d8e40":"print(\"X_train.shape:\", X_train.shape)\nprint(\"X_test.shape:\", X_test.shape)\nprint(\"Y_train.shape:\", X_train.shape)\nprint(\"Y_test.shape:\", Y_test.shape)","cf3844c9":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score","a30cafec":"# models\nmodels = []\n\n# linear models\nmodels.append(('LR', LogisticRegression(solver='liblinear', multi_class=\"auto\")))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\n\n# nonlinear models\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('GNB', GaussianNB()))\nmodels.append(('SVC', SVC(gamma=\"auto\")))\n\n# evaluate each model in turn\nprint(\"Model Accuracy:\")\nnames = []\naccuracy = []\nfor name, model in models:\n    # 10 fold cross validation to evalue model\n    kfold = KFold(n_splits=10, random_state=7)\n    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n    \n    # display the cross validation results of the current model\n    names.append(name)\n    accuracy.append(cv_results)\n    msg = \"%s: accuracy=%f std=(%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)","b546f895":"ax = sns.boxplot(x=names, y=accuracy)\nax.set_title('Model Accuracy Comparison')","43ef9aa3":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix","beb7cc9e":"# models\nmodels = []\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('GNB', GaussianNB()))\nmodels.append(('SVC', SVC(gamma=\"auto\")))","92336f7e":"# reusable function to test our model\ndef test_model(model):\n    model.fit(X_train, Y_train) # train the whole training set\n    predictions = model.predict(X_test) # predict on test set\n    \n    # output model testing results\n    print(\"Accuracy:\", accuracy_score(Y_test, predictions))\n    print(\"Confusion Matrix:\")\n    print(confusion_matrix(Y_test, predictions))\n    print(\"Classification Report:\")\n    print(classification_report(Y_test, predictions))","b2c35ebe":"# predict values with our test set\nfor name, model in models:\n    print(\"----------------\")\n    print(\"Testing\", name)\n    test_model(model)","1fb087a7":"## Conclusion:\n### This kernel described and explored the classic Iris dataset with data visualizations. And we also experimented with 4 machine learning models: 2 linear and 4 non-linear models.\n### I examined the training results with 10-fold cross validation and chose SVC as the best model with testing confusion matrix output and classification report.","49d918dc":"### From the above visualization and the summary, we can see each class has equal distribution in the dataset. It's very \"ideal\" in machine learning project.","74181b89":"### 3.4 Multivariate scatter plot:\n\n### Multivariate scatter plot helps us to visualize the pair-wise relationship in our dataset","9f40f5fb":"### 2.0 Do we have missing data?","ab87296a":"### 4.2 Models Building\n### Let's build multiple machine learning models to evaluate how they will perform on our classification problem","49e43746":"### Let's visualize the training with Box Plot","07f2f675":"### Id is the unique identifier for each flower. In this machine learning project, it will not help with our model's training and testing. Let's drop the Id column first","71b9b32f":"### 3.1 Let's visualize the distribution:","fb27d39b":"### 2.2 Statistical summary using .describe()","26da391b":"### From the printed column names, we can see the \"Id\" column is dropped now.","517a1d29":"### Great!!! We have no missing data","edb0cfcc":"### training the models and evaluate with 10-fold cross validation","205be54a":"### 3.3 Histogram:\n### Histogram is an very important tool to help visualize the dataset's value distribution.","b26171a7":"## 4. Data Modeling:\n### Classification problem: our goal is to predict the flow 'Species' with given 4 features: 'SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', and 'PetalWidthCm'.","be3e3791":"### The highest testing accuracy is 0.93 from Support Vector Classifier.\n### The SVC's confustion matrix has the highest diagonal values indicated that SVC predicted the class type better than the other 2 models.\n### From above confusion matrix and classification report, the SVC model is the best model for our classification problem. ","0dd02df6":"### From the above Box and Whisker plot and histogram, they show 2 of the attirbutes has normal distribution. This is the assumption for many machine learning algorithms. We can utilize the distribution to model our data. ","97fccd7e":"### In the above scatter plot, we can see PetalWidthCm and PetalLengthCm has the strongest pari-wise relationship for classification. Each class are separated clearly for the pair-wise scatter plot between PetalWidthCm and PetalLengthCm","5e7e3d55":"### 4.1 Train-Test Split:\n### We will use Sklean to Split arrays or matrices into random train and test subsets for training and testing machine learning model.\n### Our X will be the features of the flowers and Y will be the label of the flowers","b36d8437":"## 2. Quick dataset summary","6d98f156":"### 2.3 Distribution of each class? \n### Since we are predicting the class of a given flower, let's exam what's the class distribution for this dataset","a1027a66":"### We can see we have a dataset with 150 observations and each observation has 6 columns.\n### 4 of the columns are numeric attributes we can use to train machine learning models and the last column is the label of a given flower.","f22dbe3b":"### Test the KNN, GNB, and SVC models with test data and output their accuracy with confusion matrix together for selecting model","289449ce":"### We will evalue the testing with [accuracy score](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.accuracy_score.html), [confusion matrix](https:\/\/www.dataschool.io\/simple-guide-to-confusion-matrix-terminology\/), and [classification report](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.classification_report.html) with Sklearn","438dd6b0":"### Let's interpret the above statistical desciption of our dataset:\n### The descriptoin shows we have data with super low std(standard deviation) \n### the range of the SepalLengthCm is: 4.300000 - 7.900000\n### the range of the SepalWidthCm is: 2.000000 - 4.400000\n### the range of the PetalLengthCm is: 1.000000 - 6.900000\n### the range of the PetalWidthCm is: 0.100000 - 2.500000","6f587fc9":"## 3. Explore data with visualization","9b6bad8d":"### From above box plot, we can see the accuracy of the KNN, GNB, and SVC models has small deviation although the GNB model has a lowest accuracy score near 0.825.","c9778f1d":"### 3.2 Box and Whisker plot:\n### We will use it see how the values are distributed in each attribute","f07e491a":"## 1. Load the dataset","990d3109":"## A step-by-step machine learning project with Iris Flower dataset \n#### The Iris flower data set is a specific set of information compiled by Ronald Fisher, a biologist, in the 1930s. It describes particular biological characteristics of various types of Iris flowers, specifically, the length and width of both pedals and the sepals, which are part of the flower\u2019s reproductive system.\n![image.png](attachment:image.png)","f6df6a51":"### 2.1 Dimension of the dataset"}}