{"cell_type":{"32118515":"code","502ab297":"code","6a380496":"code","4ebebd5f":"code","239633ba":"code","d1db51a5":"code","85e6a326":"code","997a26c4":"code","89f5c7ad":"code","7e06ddc6":"code","0d174f91":"code","4c89fe05":"code","98748a7f":"code","be04198e":"code","05a20e79":"code","87cf2be5":"code","4ee6f25e":"code","189a82b9":"code","1e399516":"code","5018caff":"code","daa36b92":"code","03b3b20a":"code","073bed23":"code","df687cff":"code","9746db10":"code","fb897ac4":"code","20195102":"code","1b94d711":"code","5f8edcea":"code","4a63b52b":"code","c6f4dd5a":"code","2e6e5943":"code","6c421e7e":"code","a6a31a51":"code","acb42ce0":"code","d13bf3ad":"code","a65616d5":"code","25d5ba21":"code","6a4ea633":"code","c632dc54":"code","88e2d348":"code","61dfcab4":"code","8f7ffcd2":"code","07772936":"markdown","e06a2e86":"markdown","cdc2a8e1":"markdown","e386fc9a":"markdown","14bc727f":"markdown","16859f67":"markdown","5ba978f1":"markdown","95c09c62":"markdown","fb59b47f":"markdown","a35a9f9f":"markdown","f8095c27":"markdown","aaf8f465":"markdown","e0f82083":"markdown","0c30f799":"markdown","fac0e4dc":"markdown","0a902f33":"markdown","19631e60":"markdown","2587634c":"markdown","f0fc56ce":"markdown","0a818fdf":"markdown","92748cbc":"markdown","ab3bf05a":"markdown","22b41cdf":"markdown","3edd79dd":"markdown","9cc9cd6d":"markdown"},"source":{"32118515":"import os\nimport time\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nfrom IPython import display\n\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.autograd import Variable\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim","502ab297":"path = '\/kaggle\/input\/digit-recognizer\/'\nos.listdir(path)","6a380496":"train_data = pd.read_csv(path+'train.csv')\ntest_data = pd.read_csv(path+'test.csv')\nsamp_subm = pd.read_csv(path+'sample_submission.csv')","4ebebd5f":"fig, axs = plt.subplots(2, 5, figsize=(15, 6))\nfig.subplots_adjust(hspace = .5, wspace=.5)\naxs = axs.ravel()\nfor i in range(10):\n    idx = train_data[train_data['label']==i].index[0]\n    X_train = train_data.loc[idx, train_data.columns[1:]].values.reshape(28, 28, 1)\n    axs[i].imshow(X_train, cmap='gray')\n    axs[i].set_title(train_data.loc[idx, 'label'])\n    axs[i].set_xticklabels([])\n    axs[i].set_yticklabels([])","239633ba":"def fit(model, optimizer, loss_func, train_loader, val_loader, epochs):\n    \"\"\" Fit the model \"\"\"\n    \n    # Store the training performance\n    train_loss = np.zeros(epochs)\n    train_acc = np.zeros(epochs)\n    valid_loss = np.zeros(epochs)\n    valid_acc = np.zeros(epochs)\n    \n    for epoch in range(epochs):\n        start = time.time()\n        print('Epoch:', epoch+1)\n        \n        # Training\n        train_correct = 0\n        train_examples = 0\n        model.train()\n        for batch in train_loader:\n            optimizer.zero_grad()\n            inputs, targets = batch\n            output = model(inputs)\n            loss = loss_func(output, targets)\n            loss.backward()\n            optimizer.step()\n            train_loss[epoch] += loss.data.item()*inputs.size(0)\n            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets)\n            train_correct += torch.sum(correct).item()\n            train_examples += correct.shape[0]\n        train_loss[epoch] \/= len(train_loader.dataset)\n        train_acc[epoch] = train_correct\/train_examples\n        \n        # Validation\n        valid_correct = 0\n        valid_examples = 0\n        model.eval()\n        for batch in val_loader:\n            inputs, targets = batch\n            output = model(inputs)\n            loss = loss_func(output, targets)\n            valid_loss[epoch] += loss.data.item()*inputs.size(0)\n            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets)\n            valid_correct += torch.sum(correct).item()\n            valid_examples += correct.shape[0]\n        valid_loss[epoch] \/= len(val_loader.dataset)\n        valid_acc[epoch] = valid_correct\/valid_examples\n        \n        # Write Output\n        end = time.time()\n        print('\\t Time: {:.2f} sec' .format(end - start))\n        print('\\t Train Loss: {:.3f}, Acc: {:.2f}' .format(train_loss[epoch], train_acc[epoch]))\n        print('\\t Valid Loss: {:.3f}, Acc: {:.2f}' .format(valid_loss[epoch], valid_acc[epoch]))\n        \n        # Write the training perfomance values into a dictionary\n        history = {'train_loss': train_loss, 'train_acc': train_acc, 'valid_loss': valid_loss, 'valid_acc': valid_acc}\n    return history\n\n\ndef prediction(model, test_loader):\n    \"\"\" Predict the test data \"\"\"\n    \n    model.eval()\n    y_test = torch.LongTensor()\n    for i, data in enumerate(test_loader):\n        data = Variable(data[0])\n        output = model(data)\n        pred = output.data.max(1)[1]\n        y_test = torch.cat((y_test, pred), dim=0)\n    return y_test","d1db51a5":"X = train_data[train_data.columns[1:]]\ny = train_data['label']","85e6a326":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state=2021)","997a26c4":"X_train.index = range(len(X_train))\ny_train.index = range(len(y_train))\n\nX_val.index = range(len(X_val))\ny_val.index = range(len(y_val))","89f5c7ad":"X_test = test_data\ny_test = np.zeros(len(X_test))","7e06ddc6":"class DataGeneratorFCNN(Dataset):\n    def __init__(self, data, label):\n        self.data = data\n        self.label = label\n        self.lenght = len(data.index)\n    \n    def __getitem__(self, index):\n        data_tensor = torch.Tensor(self.data.iloc[index].values)\n        label = self.label[index]\n        return (data_tensor, label)\n    \n    def __len__(self):\n        return self.lenght\n        ","0d174f91":"data_train = DataGeneratorFCNN(X_train, y_train)\ndata_val = DataGeneratorFCNN(X_val, y_val)\ndata_test = DataGeneratorFCNN(X_test, y_test)","4c89fe05":"print('Train samples:', data_train.__len__())\nprint('Val samples:', data_val.__len__())\nprint('Test samples:', data_test.__len__())","98748a7f":"X, y = data_train[0]\nprint('Shape:', X.shape)\nprint('Data:', X[:3])\nprint('Label:',y)","be04198e":"batch_size = 32","05a20e79":"train_loader = DataLoader(data_train, batch_size=batch_size, shuffle=False)\nval_loader = DataLoader(data_val, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(data_test, batch_size=batch_size, shuffle=False)","87cf2be5":"train_loader.dataset[0][1]","4ee6f25e":"class SimpleFCNN(nn.Module):\n    def __init__(self):\n        super(SimpleFCNN, self).__init__()\n        self.fc1 = nn.Linear(28*28, 200)\n        self.fc2 = nn.Linear(200, 100)\n        self.fc3 = nn.Linear(100, 10)\n        \n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.log_softmax(self.fc3(x), dim=1)\n        return x\n    \n    def set_weight(self, tensor):\n        \"\"\"Update the weights of the model\"\"\"\n        with torch.no_grad():\n            self.weight.copy_(tensor)","189a82b9":"modelFCNN = SimpleFCNN()\nmodelFCNN","1e399516":"modelFCNN.fc1.weight","5018caff":"optimizer = optim.Adam(modelFCNN.parameters())\nloss_func = nn.CrossEntropyLoss()","daa36b92":"history = fit(modelFCNN, optimizer, loss_func, train_loader, val_loader, epochs=10)","03b3b20a":"history","073bed23":"fig, axs = plt.subplots(1, 2, figsize=(20, 6))\nfig.subplots_adjust(hspace = .2, wspace=.2)\naxs = axs.ravel()\nloss = history['train_loss']\nloss_val = history['valid_loss']\nepochs = range(1, len(loss)+1)\naxs[0].plot(epochs, loss, 'bo', label='loss_train')\naxs[0].plot(epochs, loss_val, 'ro', label='loss_val')\naxs[0].set_title('Value of the loss function')\naxs[0].set_xlabel('epochs')\naxs[0].set_ylabel('value of the loss function')\naxs[0].legend()\naxs[0].grid()\n\nacc = history['train_acc']\nacc_val = history['valid_acc']\naxs[1].plot(epochs, acc, 'bo', label='accuracy_train')\naxs[1].plot(epochs, acc_val, 'ro', label='accuracy_val')\naxs[1].set_title('Accuracy')\naxs[1].set_xlabel('Epochs')\naxs[1].set_ylabel('Value of accuracy')\naxs[1].legend()\naxs[1].grid()\nplt.show()","df687cff":"modelFCNN.fc1.weight","9746db10":"for name, param in modelFCNN.named_parameters():\n    print(name)","fb897ac4":"y_test = prediction(modelFCNN, test_loader)\nsamp_subm['Label'] = y_test.numpy()","20195102":"samp_subm.to_csv('FCNN_submission.csv', index=False)","1b94d711":"class DataGeneratorCNN(Dataset):\n    def __init__(self, data, label):\n        self.data = data\n        self.label = label\n        self.lenght = len(data.index)\n    \n    def __getitem__(self, index):\n        data_tensor = torch.Tensor(self.data.iloc[index].values.reshape(1, 28, 28))\n        label = self.label[index]\n        return (data_tensor, label)\n    \n    def __len__(self):\n        return self.lenght","5f8edcea":"data_train = DataGeneratorCNN(X_train, y_train)\ndata_val = DataGeneratorCNN(X_val, y_val)\ndata_test = DataGeneratorCNN(X_test, y_test)","4a63b52b":"print('Train samples:', data_train.__len__())\nprint('Val samples:', data_val.__len__())\nprint('Test samples:', data_test.__len__())","c6f4dd5a":"X, y = data_train[0]\nprint('Shape:', X.shape)\nprint('Label:',y)","2e6e5943":"batch_size = 32","6c421e7e":"train_loader = DataLoader(data_train, batch_size=batch_size, shuffle=False)\nval_loader = DataLoader(data_val, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(data_test, batch_size=batch_size, shuffle=False)","a6a31a51":"train_loader.dataset[0][1]","acb42ce0":"class SimpleCNN(nn.Module):\n    def __init__(self, num_classes=10):\n        super(SimpleCNN, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(1, 32, kernel_size=5, stride=1),\n            nn.ReLU(),\n            nn.Conv2d(32, 32, kernel_size=5, stride=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n            nn.Conv2d(32, 64, kernel_size=3, stride=1),\n            nn.ReLU(),\n            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n            \n        )\n        self.classifier = nn.Sequential(\n            nn.Dropout(),\n            nn.Linear(576, 256),\n            nn.Linear(256, num_classes)\n        )\n    def forward(self, x):\n        x = self.features(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        x = F.log_softmax(x, dim=1)\n        return x\n    \n    def set_weight(self, tensor):\n        \"\"\"Update the weights of the model\"\"\"\n        with torch.no_grad():\n            self.weight.copy_(tensor)","d13bf3ad":"modelCNN = SimpleCNN()\nmodelCNN","a65616d5":"optimizer = optim.RMSprop(modelCNN.parameters(), lr=0.001)\nloss_func = nn.CrossEntropyLoss()","25d5ba21":"history = fit(modelCNN, optimizer, loss_func, train_loader, val_loader, epochs=10)","6a4ea633":"for name, param in modelCNN.named_parameters():\n    print(name, param.shape)","c632dc54":"modelCNN.features[0].weight.shape","88e2d348":"fig, axs = plt.subplots(1, 2, figsize=(20, 6))\nfig.subplots_adjust(hspace = .2, wspace=.2)\naxs = axs.ravel()\nloss = history['train_loss']\nloss_val = history['valid_loss']\nepochs = range(1, len(loss)+1)\naxs[0].plot(epochs, loss, 'bo', label='loss_train')\naxs[0].plot(epochs, loss_val, 'ro', label='loss_val')\naxs[0].set_title('Value of the loss function')\naxs[0].set_xlabel('epochs')\naxs[0].set_ylabel('value of the loss function')\naxs[0].legend()\naxs[0].grid()\n\nacc = history['train_acc']\nacc_val = history['valid_acc']\naxs[1].plot(epochs, acc, 'bo', label='accuracy_train')\naxs[1].plot(epochs, acc_val, 'ro', label='accuracy_val')\naxs[1].set_title('Accuracy')\naxs[1].set_xlabel('Epochs')\naxs[1].set_ylabel('Value of accuracy')\naxs[1].legend()\naxs[1].grid()\nplt.show()","61dfcab4":"y_test = prediction(modelCNN, test_loader)\nsamp_subm['Label'] = y_test.numpy()","8f7ffcd2":"samp_subm.to_csv('CNN_submission.csv', index=False)","07772936":"# Path","e06a2e86":"## Predict Test Data","cdc2a8e1":"Define the model and take a look on the structure:","e386fc9a":"## Model","14bc727f":"## Export","16859f67":"## Data Generator","5ba978f1":"# Intro\nWelcome To The famous [MINST](https:\/\/www.kaggle.com\/c\/digit-recognizer) Competition\n\n![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/3004\/logos\/header.png)\n\nThis notebook compares a Fully Connected Neural Network (FCNN) with a Convolutory Neural Network (CNN) in a pytorch formulation.\n\n**Table of content:**\n\n1. [Plot Examples](#PlotExamples)\n2. [Fit And Prediction Functions](#FitAndPredictionFunctions)\n3. [Prepare Data](#PrepareData)\n4. [Fully Connected Neural Network (FCNN)](#FCNN)\n5. [Convolutional Neural Network (CNN)](#CNN)\n\n\n<font size=\"4\"><span style=\"color: royalblue;\">Please vote the notebook up if it helps you. Feel free to leave a comment above the notebook. Thank you. <\/span><\/font>\n","95c09c62":"# Fully Connected Neural Network (FCNN) <a name=\"FCNN\"><\/a>\nWe define a simple Fully Connected Neural Network.","fb59b47f":"## Predict Test Data","a35a9f9f":"## Data Loader Object","f8095c27":"## Data Loader Object","aaf8f465":"# Convolutional Neural Network (CNN) <a name=\"CNN\"><\/a>\nWe define a simple Convolutional Neural Network.","e0f82083":"# Prepare Data <a name=\"PrepareData\"><\/a>\nWe define the training, validation and test data.","0c30f799":"Define optimizer and loss function:","fac0e4dc":"## Analyse Results\nThe fit function returns the history dictionary with the loss and accurancy values of the train and validation data.","0a902f33":"# Plot Examples  <a name=\"PlotExamples\"><\/a>\nWe plot some examples to get famiiliar with the data.","19631e60":"# Libraries","2587634c":"Initial weights of the fc1 layer:","f0fc56ce":"## Model","0a818fdf":"## Export","92748cbc":"# Load Data","ab3bf05a":"Define the model and take a look on the structure:","22b41cdf":"## Data Generator","3edd79dd":"## Analyse Results","9cc9cd6d":"# Fit And Prediction Functions  <a name=\"FitAndPredictionFunctions\"><\/a>\nWe define a fit and prediction method independet of the model. Consequently we can use both functions for the Fully Conncted and Convolutional Neural Network."}}