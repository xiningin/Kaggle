{"cell_type":{"190a32bb":"code","9444d479":"code","a4fd3fbf":"code","de17c307":"code","aae788bb":"code","3160fcb1":"code","ed422426":"code","ae572a46":"code","fdab779d":"code","ad152374":"code","196e1d23":"code","4e7b58f0":"code","b5c6222a":"code","49474ec6":"code","583cc308":"code","3637b3b8":"code","562560f2":"code","6f624082":"code","1d9b6500":"code","40d391ff":"code","50a5c960":"code","bf867755":"code","fae906ec":"code","3d6ca7a2":"code","20e71e99":"code","740144ee":"code","c84e27a1":"code","c6a97f15":"code","d644e6b7":"code","5512d5ff":"code","6954f295":"code","4cfe09af":"markdown","8b79921c":"markdown","94e4affd":"markdown","7a9f2270":"markdown","b0e1734c":"markdown","247e8cdc":"markdown","c049c634":"markdown"},"source":{"190a32bb":"# matplotlib\u3067\u65e5\u672c\u8a9e\u3092\u6271\u3048\u308b\u3088\u3046\u306b\n!pip install japanize_matplotlib -Uq\n\n# RainCloud Plot(\u6563\u5e03\u56f3\uff0bBoxPlot\uff0bViolin\u3092\u4e00\u3064\u3067\u8868\u793a)\n!pip install ptitprince -Uq\n\n# \u6b20\u640d\u5024\u3092\u53ef\u8996\u5316\n!pip install missingno -Uq\n\n# \u30d9\u30f3\u56f3\u3092\u4f5c\u6210\n!pip install matplotlib-venn -Uq\n\n!pip install pytorch-tabnet -Uq","9444d479":"import warnings\nwarnings.simplefilter('ignore')\n\nimport os\nimport gc\ngc.enable()\nimport sys\nimport glob\nimport math\nimport time\nimport random\nimport string\nimport psutil\nimport pathlib\nfrom pathlib import Path\nfrom contextlib import contextmanager\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport japanize_matplotlib\nfrom ptitprince import RainCloud\nfrom matplotlib_venn import venn2\n\n\nfrom tqdm.auto import tqdm as tqdmp\nfrom tqdm.autonotebook import tqdm as tqdm\ntqdmp.pandas()\n\n## Model\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\nimport lightgbm as lgb\n\nfrom PIL import Image\nimport cv2\n\nfrom pytorch_tabnet.pretraining import TabNetPretrainer","a4fd3fbf":"# \u5b9f\u9a13\u3067\u4f7f\u3046\u30d1\u30e9\u30e1\u30fc\u30bf\u306fConfig\u3067\u7ba1\u7406\u3057\u3066\u3044\u307e\u3059\u3002\n# \u3053\u306e\u5b9f\u9a13\u4f55\u3084\u3063\u305f\u304b\u306a\u3068\u5f8c\u3067\u632f\u308a\u8fd4\u308a\u3084\u3059\u3044\u3088\u3046\u306b\u3001\u306a\u308b\u3079\u304fConfig\u3060\u3051\u898b\u308c\u3070\u308f\u304b\u308b\u3088\u3046\u306b\u3057\u3066\u3044\u307e\u3059\n\nclass CFG:\n    \n    def __init__(self):\n        \n        self.debug=True\n        self.seed=42\n        self.n_fold = 5\n        self.environment='Kaggle'  # 'AWS' or 'Kaggle' or 'Colab'\n        self.project='Shiggle_1st',\n        self.exp_name = '009_tabnet_BASE'\n        self.objective = 'rmse'\n        self.metric = 'rmse'\n        self.learning_rate = 0.1\n        self.num_boost_round = 1000\n        self.early_stopping_rounds = 30\n        self.num_leaves = 32\n        \nCONFIG = CFG()","de17c307":"## \u518d\u73fe\u6027\u78ba\u4fdd\u306e\u305f\u3081\u306eSeed\u56fa\u5b9a\ndef seed_everything(seed:int==42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n\nseed_everything(CONFIG.seed)","aae788bb":"## \u51e6\u7406\u306b\u304b\u304b\u3063\u305f\u6642\u9593\u3068\u4f7f\u7528\u3057\u305f\u30e1\u30e2\u30ea\u3092\u8a08\u6e2c\n@contextmanager\ndef timer(name:str, slack:bool=False):\n    t0 = time.time()\n    p = psutil.Process(os.getpid())\n    m0 = p.memory_info()[0] \/ 2. ** 30\n    print(f'<< {name} >> Start')\n    yield\n    \n    m1 = p.memory_info()[0] \/ 2. ** 30\n    delta = m1 - m0\n    sign = '+' if delta >= 0 else '-'\n    delta = math.fabs(delta)\n    \n    print(f\"<< {name} >> {m1:.1f}GB({sign}{delta:.1f}GB):{time.time() - t0:.1f}sec\", file=sys.stderr)","3160fcb1":"def display_image(url_images):\n    plt.figure(figsize=(15, 20))\n    for i, url_image in enumerate(url_images):\n        try:\n            im = Image.open(str(INPUT_DIR) + f\"\/pokemon_images\/{url_image}\")\n            im_list = np.asarray(im)\n            plt.subplot(10, 5, i + 1)\n            plt.imshow(im_list)\n        except:\n            pass\n        if i == 49:\n            break\n    plt.show()","ed422426":"# \u500b\u4eba\u7684\u306bAWS\u3084Kaggle\u74b0\u5883\u3084Google Colab\u3092\u884c\u3063\u305f\u308a\u6765\u305f\u308a\u3057\u3066\u3044\u308b\u306e\u3067\u307e\u3068\u3081\u3066\u3044\u307e\u3059\nif CONFIG.environment == 'AWS':\n    INPUT_DIR = Path('\/mnt\/work\/data\/kaggle\/shiggle_1st\/')\n    MODEL_DIR = Path(f'..\/models\/{CONFIG.exp_name}\/')\n    OUTPUT_DIR = Path(f'..\/data\/interim\/{CONFIG.exp_name}\/')\n    \n    os.makedirs(MODEL_DIR, exist_ok=True)\n    os.makedirs(OUTPUT_DIR, exist_ok=True)\n    \n    print(f\"Your environment is 'AWS'.\\nINPUT_DIR is {INPUT_DIR}\\nMODEL_DIR is {MODEL_DIR}\\nOUTPUT_DIR is {OUTPUT_DIR}\")\n    \n    \nelif CONFIG.environment == 'Kaggle':\n    INPUT_DIR = Path('..\/input\/shigglecup-1st\/DATA\/')\n    MODEL_DIR = Path('.\/')\n    OUTPUT_DIR = Path('.\/')\n    print(f\"Your environment is 'Kaggle'.\\nINPUT_DIR is {INPUT_DIR}\\nMODEL_DIR is {MODEL_DIR}\\nOUTPUT_DIR is {OUTPUT_DIR}\")\n\n    \nelif CONFIG.environment == 'Colab':\n    INPUT_DIR = Path('\/content\/drive\/MyDrive\/kaggle\/Shiggle_1st\/data\/raw')\n    BASE_DIR = Path(\"\/content\/drive\/MyDrive\/kaggle\/Shiggle_1st\/data\/\")\n\n    MODEL_DIR = BASE_DIR \/ f'{CONFIG.exp_name}'\n    OUTPUT_DIR = BASE_DIR \/ f'{CONFIG.exp_name}\/'\n\n    os.makedirs(MODEL_DIR, exist_ok=True)\n    os.makedirs(OUTPUT_DIR, exist_ok=True)\n    \n    if not os.path.exists(INPUT_DIR):\n        print('Please Mount your Google Drive.')\n    else:\n        print(f\"Your environment is 'Colab'.\\nINPUT_DIR is {INPUT_DIR}\\nMODEL_DIR is {MODEL_DIR}\\nOUTPUT_DIR is {OUTPUT_DIR}\")\n        \nelse:\n    print(\"Please choose 'AWS' or 'Kaggle' or 'Colab'.\\nINPUT_DIR is not found.\")","ae572a46":"with timer('Data Load'):\n    train_df = pd.read_csv(INPUT_DIR \/ 'train.csv')\n    test_df = pd.read_csv(INPUT_DIR \/ 'test.csv')\n    sub_df = pd.read_csv(INPUT_DIR \/ 'sample_submission.csv')\n    \n    print(f'Train: {train_df.shape} | Test: {test_df.shape}')\n    \n## Train\u3068Test\u3092\u7d50\u5408\u3057\u307e\u3059\n## \u3042\u3068\u3067\u5206\u3051\u3089\u308c\u308b\u3088\u3046\u306bflag\u3092\u4ed8\u4e0e\u3057\u307e\u3059\ntrain_df['flag'] = 0\ntest_df['flag'] = 1\n\nwith timer('train test concat'):\n    whole_df = pd.concat([train_df, test_df], axis=0).reset_index(drop=True)\n    \n# \u30ed\u30b0\u3068\u308b\nwith timer('log transform w\/ target'):\n    whole_df['target'] = whole_df['target'].progress_apply(lambda x: np.log1p(x))\n","fdab779d":"# \u8eab\u9577\u3001\u4f53\u91cd\nfrom sklearn.preprocessing import StandardScaler\n\nwhole_df['height'] = whole_df['height'].progress_apply(lambda x: np.log1p(x))\nwhole_df['weight'] = whole_df['weight'].progress_apply(lambda x: np.log1p(x))","ad152374":"# \u9032\u5316\u6570\u306e\u6700\u5927\u5024\u3092\u8a08\u7b97(\u30c7\u30fc\u30bf\u304c\u6b20\u640d\uff08\u4f1d\u8aac\u7cfb\uff09\u306e\u5834\u5408\u306f\u30010\u3092\u683c\u7d0d)\ndef agg_func(x):\n    return x.nunique() + 1\ntmp = whole_df.groupby('evolution_chain_id').agg({'evolves_from_species_id':agg_func}).rename(columns = {'evolves_from_species_id':'evolves_max'})\nwhole_df = pd.merge(whole_df, tmp, on='evolution_chain_id', how='left')\nwhole_df.evolves_max = whole_df.evolves_max.fillna(0)\n\n# \u500b\u4f53\u304c\u4f55\u6bb5\u968e\u76ee\u306e\u9032\u5316\u72b6\u614b\u304b\u7b97\u51fa\ndef count_evol_sub(species_id):\n    tmp_list = []\n    while 1:\n        tmp_list.append(species_id)\n        tmp = whole_df.query('evolves_from_species_id in @species_id').species_id.to_list()\n        if len(tmp)==0:\n            break\n        else:\n            species_id = tmp\n    return tmp_list\n\norigin_species_id =  whole_df[pd.isnull(whole_df.evolves_from_species_id)].species_id.to_list()\nresults = []\nfor species_id in origin_species_id:\n    results.append(count_evol_sub([species_id]))\n    \nwhole_df['evolves_num'] = np.nan\nfor species_id_list in results:\n    count = 0\n    for species_ids in species_id_list:\n        count += 1\n        for species_id in species_ids:\n            whole_df.loc[whole_df.query('species_id == @species_id').index, 'evolves_num'] = count\n\n# \u500b\u4f53\u304c\u5168\u9032\u5316\u6bb5\u968e\u4e2d\u3001\u4f55\u6bb5\u968e\u76ee\u306e\u9032\u5316\u72b6\u614b\u304b\u7b97\u51fa\nwhole_df['evolves_cat'] = whole_df.evolves_num.astype('int').astype('str') + '_' + whole_df.evolves_max.astype('int').astype('str')","196e1d23":"# \u5916\u308c\u5024\u3092\u9664\u53bb\u3057\u3001\u5b66\u7fd2\nrm_pokemon = ['audino', 'blissey', 'happiny']\nwhole_df = whole_df.query('pokemon not in @rm_pokemon')","4e7b58f0":"# \u30bf\u30a4\u30d7\u6570\u306e\u30ab\u30a6\u30f3\u30c8\ndef count_type(df:pd.DataFrame) -> pd.DataFrame:\n    \n    _df = df.copy()\n    # type_2\u304cnan\u3067\u3042\u308c\u3070\u3001\u30bf\u30a4\u30d7\u6570\u306f1\u3068\u3059\u308b\n    _df['num_type'] = _df['type_2'].progress_apply(lambda x: 1 if x is np.nan else 2)\n\n    return _df\n\nwith timer('\u30bf\u30a4\u30d7\u6570\u3092\u30ab\u30a6\u30f3\u30c8'):\n    whole_df = count_type(whole_df)","b5c6222a":"# \u7a2e\u65cf\u5024\u5408\u8a08\nwith timer('\u7a2e\u65cf\u5024\u8a08\u7b97'):\n    whole_df['Base_stats'] = whole_df[['hp', 'attack', 'defense', 'special_attack', 'special_defense', 'speed']].sum(axis=1)\n    whole_df['defence_all'] = whole_df[['defense', 'special_defense']].sum(axis=1)\n    whole_df['attack_all'] = whole_df[['attack', 'special_attack']].sum(axis=1)\n    whole_df['attack_defence_all'] = whole_df[['defence_all', 'attack_all']].sum(axis=1)","49474ec6":"# ability\u6570\u3092\u30ab\u30a6\u30f3\u30c8\ndef count_ability(df:pd.DataFrame) -> pd.DataFrame:\n    \n    _df = df.copy()\n    # type_2\u304cnan\u3067\u3042\u308c\u3070\u3001\u30bf\u30a4\u30d7\u6570\u306f1\u3068\u3059\u308b\n    _df['num_ability'] = _df['ability_2'].progress_apply(lambda x: 1 if x is np.nan else 2)\n\n    return _df\n\nwith timer('ability\u6570\u3092\u30ab\u30a6\u30f3\u30c8'):\n    whole_df = count_ability(whole_df)","583cc308":"# ability_hidden\u306e\u6b20\u640d\u72b6\u6cc1\u3092\u8ffd\u52a0\ndef count_ability_hidden(df:pd.DataFrame) -> pd.DataFrame:\n    \n    _df = df.copy()\n    # type_2\u304cnan\u3067\u3042\u308c\u3070\u3001\u30bf\u30a4\u30d7\u6570\u306f1\u3068\u3059\u308b\n    _df['ability_hidden_flag'] = _df['ability_hidden'].progress_apply(lambda x: 0 if pd.isnull(x) else 1)\n\n    return _df\n\nwith timer('ability\u6570\u3092\u30ab\u30a6\u30f3\u30c8'):\n    whole_df = count_ability_hidden(whole_df)","3637b3b8":"def count_egg_group(df:pd.DataFrame) -> pd.DataFrame:\n    \n    _df = df.copy()\n    # type_2\u304cnan\u3067\u3042\u308c\u3070\u3001\u30bf\u30a4\u30d7\u6570\u306f1\u3068\u3059\u308b\n    _df['num_egg_group'] = _df['egg_group_2'].progress_apply(lambda x: 1 if x is np.nan else 2)\n\n    return _df\nwith timer('egg_group\u6570\u3092\u30ab\u30a6\u30f3\u30c8'):\n    whole_df = count_egg_group(whole_df)","562560f2":"# generation_id\u306e\u6b20\u640d\u72b6\u6cc1\u3092\u8ffd\u52a0\ndef count_generation_id(df:pd.DataFrame) -> pd.DataFrame:\n    \n    _df = df.copy()\n    # type_2\u304cnan\u3067\u3042\u308c\u3070\u3001\u30bf\u30a4\u30d7\u6570\u306f1\u3068\u3059\u308b\n    _df['generation_id_flag'] = _df['generation_id'].progress_apply(lambda x: 0 if pd.isnull(x) else 1)\n\n    return _df\n\nwith timer('generation_id\u306e\u6b20\u640d\u72b6\u6cc1\u3092\u8ffd\u52a0'):\n    whole_df = count_generation_id(whole_df)","6f624082":"# evolves_from_species_id\u306e\u6b20\u640d\u72b6\u6cc1\u3092\u8ffd\u52a0\ndef count_evolves_from_species_id(df:pd.DataFrame) -> pd.DataFrame:\n    \n    _df = df.copy()\n    # type_2\u304cnan\u3067\u3042\u308c\u3070\u3001\u30bf\u30a4\u30d7\u6570\u306f1\u3068\u3059\u308b\n    _df['evolves_from_species_id_flag'] = _df['evolves_from_species_id'].progress_apply(lambda x: 0 if pd.isnull(x) else 1)\n    print(_df['evolves_from_species_id_flag'].sum())\n    return _df\n\nwith timer('evolves_from_species_id\u306e\u6b20\u640d\u72b6\u6cc1\u3092\u8ffd\u52a0'):\n    whole_df = count_evolves_from_species_id(whole_df)","1d9b6500":"with timer('drop color'):\n    whole_df = whole_df.drop(['color_1', 'color_2', 'color_f'], axis=1)\nwith timer('drop image'):\n    whole_df = whole_df.drop('url_image', axis=1)\nwith timer('drop shape'):\n    whole_df = whole_df.drop('shape', axis=1)","40d391ff":"nunique = whole_df.nunique()\ntypes = whole_df.dtypes\n\ncategorical_columns = []\ncategorical_dims =  {}\nfor col in whole_df.columns:\n    if types[col] == 'object': #  or nunique[col] < 200\n        print(col, whole_df[col].nunique())\n        categorical_columns.append(col)\n        categorical_dims[col] = whole_df[col].nunique()\n    else:\n        whole_df.fillna(whole_df.loc[:, col].mean(), inplace=True)\n        \ncategorical_dims['type_1'] = pd.concat([whole_df['type_1'], whole_df['type_2']]).nunique(dropna = False)\ncategorical_dims['type_2'] = pd.concat([whole_df['type_1'], whole_df['type_2']]).nunique(dropna = False)\ncategorical_dims['ability_1'] = pd.concat([whole_df['ability_1'], whole_df['ability_2']]).nunique(dropna = False)\ncategorical_dims['ability_2'] = pd.concat([whole_df['ability_1'], whole_df['ability_2']]).nunique(dropna = False)\ncategorical_dims['egg_group_1'] = pd.concat([whole_df['egg_group_1'], whole_df['egg_group_2']]).nunique(dropna = False)\ncategorical_dims['egg_group_2'] = pd.concat([whole_df['egg_group_1'], whole_df['egg_group_2']]).nunique(dropna = False)","50a5c960":"## evolves_cat\u3000Label Encoding\nwith timer('label encoding w\/ evolves_cat'):\n    labels, uniques = whole_df['evolves_cat'].factorize()\n    whole_df['evolves_cat'] = labels\n    \n## egg_group_2\u3000Label Encoding\nwith timer('label encoding w\/ egg_group_2'):\n    labels, uniques = pd.concat([whole_df['egg_group_1'], whole_df['egg_group_2']], axis=0).factorize()\n    whole_df['egg_group_1'] = labels[:len(whole_df)]\n    whole_df['egg_group_2'] = labels[len(whole_df):]\n    \n## ability_hidden\u3000Label Encoding\nwith timer('label encoding w\/ ability_hidden'):\n    labels, uniques = whole_df['ability_hidden'].factorize()\n    whole_df['ability_hidden'] = labels\n    \n## ability\u3000Label Encoding\nwith timer('label encoding w\/ ability'):\n    labels, uniques = pd.concat([whole_df['ability_1'], whole_df['ability_2']], axis=0).factorize()\n    whole_df['ability_1'] = labels[:len(whole_df)]\n    whole_df['ability_2'] = labels[len(whole_df):]\n\n## Label Encoding\u306fpandas\u306efactorize\u3092\u4f7f\u3046\u3068\u4fbf\u5229\u3067\u3059\nwith timer('label encoding w\/ type'):\n    labels, uniques = pd.concat([whole_df['type_1'], whole_df['type_2']], axis=0).factorize()\n    whole_df['type_1'] = labels[:len(whole_df)]\n    whole_df['type_2'] = labels[len(whole_df):]","bf867755":"## Data Split\nwith timer('Data Split'):\n    train_df = whole_df[whole_df['flag'] == 0].reset_index(drop=True)\n    test_df = whole_df[whole_df['flag'] == 1].reset_index(drop=True)\n    \n    print(f'Train: {train_df.shape} | Test: {test_df.shape}')","fae906ec":"# target encoding\nfrom sklearn.model_selection import KFold\nnum_splits = 8\n\ncat_cols = ['type_1', 'type_2', 'egg_group_1', 'egg_group_2', 'shape_id', 'generation_id', 'evolves_cat', 'evolves_num', 'evolves_max']\nfor c in cat_cols:\n    data_tmp = pd.DataFrame({c: train_df[c], 'target': train_df['target']})\n    target_mean = data_tmp.groupby(c)['target'].mean()\n    test_df[c+'_target_enc'] = test_df[c].map(target_mean)\n\n    tmp = np.repeat(np.nan, train_df.shape[0])\n    kf = KFold(n_splits=num_splits, shuffle=True, random_state=CONFIG.seed)\n    for idx_1, idx_2 in kf.split(train_df):\n        target_mean = data_tmp.iloc[idx_1].groupby(c)['target'].mean()\n        tmp[idx_2] = train_df[c].iloc[idx_2].map(target_mean)\n    train_df[c+'_target_enc'] = tmp","3d6ca7a2":"train_df = train_df.replace([np.inf, -np.inf], np.nan)\ntest_df = test_df.replace([np.inf, -np.inf], np.nan)\ntrain_df = train_df.fillna(0)\ntest_df = test_df.fillna(0)","20e71e99":"## Non Training Columns\ndrop_cols = [\"id\", \"pokemon\", \"species_id\", \"target\", 'image_exist', 'flag']","740144ee":"features = [ col for col in train_df.columns if col not in drop_cols] \ncat_idxs = [ i for i, f in enumerate(features) if f in categorical_columns]\ncat_dims = [ categorical_dims[f] for i, f in enumerate(features) if f in categorical_columns]","c84e27a1":"from pytorch_tabnet.pretraining import TabNetPretrainer\nfrom pytorch_tabnet.tab_model import TabNetRegressor\nimport torch\n\n# TabNetPretrainer\nunsupervised_model = TabNetPretrainer(\n    n_d = 32,\n    n_a = 32,\n    n_steps = 3,\n    cat_idxs=cat_idxs,\n    cat_dims=cat_dims,\n    cat_emb_dim=3,\n    optimizer_fn=torch.optim.Adam,\n    optimizer_params=dict(lr=2e-2),\n    mask_type='entmax', # \"sparsemax\", 'entmax'\n#     scheduler_params=dict(mode=\"min\", patience=5, min_lr=1e-5, factor=0.9,),\n#     scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n    verbose=10\n)\n\n\nmax_epochs = 1000 if not os.getenv(\"CI\", False) else 2\nunsupervised_model.fit(\n    X_train=train_df.loc[:,features].values,\n    eval_set=[train_df.loc[:,features].values],\n    max_epochs=max_epochs , patience=5,\n    batch_size=128, virtual_batch_size=16,\n    num_workers=0,\n    drop_last=False,\n    pretraining_ratio=0.8,\n)","c6a97f15":"oof = np.zeros(len(train_df))\npred = np.zeros(len(test_df))\n\n\nCV = KFold(n_splits=CONFIG.n_fold, shuffle=True, random_state=CONFIG.seed)\nfor fold, (tr_idx, va_idx) in enumerate(CV.split(train_df, train_df['target'])):\n    \n    ## \u5b66\u7fd2\u7528\u30c7\u30fc\u30bf\u3068\u8a55\u4fa1\u7528\u30c7\u30fc\u30bf\u306b\u5206\u96e2\n    X_train = train_df.loc[tr_idx, features].values\n    X_valid = train_df.loc[va_idx, features].values\n    y_train = train_df.loc[tr_idx, 'target'].values.reshape(-1, 1)\n    y_valid = train_df.loc[va_idx, 'target'].values.reshape(-1, 1)\n\n    clf = TabNetRegressor(cat_dims=cat_dims, cat_emb_dim=3, cat_idxs=cat_idxs, \n                          optimizer_fn=torch.optim.Adam, mask_type=\"entmax\",\n                          optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n#                           scheduler_params=dict(max_lr=0.05, steps_per_epoch=int(X_train.shape[0] \/ 256), epochs=10000, is_batch_level=True),\n#                           scheduler_fn=torch.optim.lr_scheduler.OneCycleLR,\n                          verbose=10,\n                         )\n    clf.fit(\n        X_train=X_train, y_train=y_train,\n        eval_set=[(X_train, y_train), (X_valid, y_valid)],\n        eval_name=['train', 'valid'],\n        eval_metric=['rmse'],\n        max_epochs=max_epochs,\n        patience=50,\n        batch_size=128, virtual_batch_size=16,\n        num_workers=0,\n        drop_last=False,\n        from_unsupervised=unsupervised_model,\n    )\n    \n    ## valid\u306e\u4e88\u6e2c\u5024\u3092\u683c\u7d0d\n    oof[va_idx] = clf.predict(X_valid).reshape(-1)\n    \n    ## test\u30c7\u30fc\u30bf\u306e\u4e88\u6e2c\u5024\u3092\u683c\u7d0d\n    tabnet_pred = clf.predict(test_df.loc[:, features].values)\n    \n    ## \u4e88\u6e2c\u5024\u306f\u5404Fold\u306e\u5e73\u5747\n    pred += tabnet_pred.reshape(-1)\/CONFIG.n_fold\n    ","d644e6b7":"total_score = mean_squared_error(train_df.target, oof) ** .5\nprint(total_score)","5512d5ff":"plt.figure(figsize=(16, 5),tight_layout=True)\nsns.distplot(train_df['target'], label='train')\nsns.distplot(oof, label='oof')\nsns.distplot(pred, label='pred')\nplt.legend()\nplt.show()","6954f295":"## sample_submission.csv\u306etarget\u3092pred\u3067\u7f6e\u304d\u63db\u3048\u3066\u3001csv\u3067\u4fdd\u5b58\u3002\n## pred\u306flog\u5909\u63db\u3057\u3066\u3044\u308b\u306e\u3067\u3001expm1\u3067\u5143\u306b\u623b\u3059\u3053\u3068\u3092\u5fd8\u308c\u306a\u3044\u3088\u3046\u306b\u3057\u307e\u3057\u3087\u3046\u3002\n## submissin\u30d5\u30a1\u30a4\u30eb\u306e\u540d\u524d\u3092\u898b\u308c\u3070\u3001CVscore\u3082\u308f\u304b\u308b\u3088\u3046\u306b\u3001\u30d5\u30a1\u30a4\u30eb\u540d\u306bCV\u5024\u3082\u5165\u308c\u3066\u3057\u307e\u3046\u3053\u3068\u304c\u50d5\u306f\u591a\u3044\u3067\u3059\u3002\n\nsub_df['target'] = np.expm1(pred)\nsub_df.to_csv(f'.\/{CONFIG.exp_name}_CV{total_score:.6f}_submision.csv', index=False)","4cfe09af":"### \u753b\u50cf\u53ef\u8996\u5316","8b79921c":"# Submit","94e4affd":"### \u7279\u5fb4\u91cf\u751f\u6210","7a9f2270":"# Data Load","b0e1734c":"# Tabnet","247e8cdc":"# Settings","c049c634":"## \u4e88\u6e2c\u5024\u306e\u5206\u5e03\u3092\u78ba\u8a8d"}}