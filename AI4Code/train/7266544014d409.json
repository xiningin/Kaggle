{"cell_type":{"8ff3048e":"code","8ba51741":"code","80756564":"code","be7948dc":"code","cf136c1c":"code","b2dffc9b":"code","a4121bfb":"code","29402e26":"code","55468241":"code","1db807e3":"code","2f55c77d":"code","f8f712a0":"code","56c29c93":"markdown"},"source":{"8ff3048e":"import os\nimport sys\nsys.path.append('..\/input\/timm-pytorch-image-models\/pytorch-image-models-master')\n\nfrom sklearn import metrics\nimport numpy as np\nimport pandas as pd\nimport random\nimport math\n\n\nimport cv2\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\n\nimport timm\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset,DataLoader,random_split","8ba51741":"def dataframe(df, istrain=True):\n    if istrain:\n        mode = 'train'\n    else:\n        mode = 'test'\n    df['filepath'] = df.id.apply(lambda x: '..\/input\/seti-breakthrough-listen\/'+ f'{mode}\/'+str(x[0])+f'\/{x}.npy')\n    return df\ntest_df = pd.read_csv('..\/input\/seti-breakthrough-listen\/sample_submission.csv')\ntest_df = dataframe(test_df, istrain=False)\ntest_df['target'] = 0\ntrain_df = pd.read_csv('..\/input\/seti-breakthrough-listen\/train_labels.csv')\ntrain_df = dataframe(train_df)\ntrain_df.head(2)","80756564":"class setiDataset(Dataset):\n    def __init__(self, df, transform = None): \n        self.df = df\n        self.transform = transform\n    \n    def fileinfo(self, idx):\n        return self.df.filepath.iloc[idx], self.df.target.iloc[idx]\n    \n    def loadfile(self, filepath):\n        image = np.load(filepath).astype('float32')\n        return image\n    \n    def __getitem__(self, idx):\n        filepath, target = self.fileinfo(idx)\n        image = self.loadfile(filepath)\n        return  torch.tensor(image, dtype=torch.float), torch.tensor(target, dtype=torch.long)\n    \n    def __len__(self):\n        return len(self.df)","be7948dc":"# Encoder\nclass ConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size):\n        super().__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, padding = 1 if kernel_size == 3 else 0, bias=False)\n        self.bn = nn.BatchNorm2d(out_channels)\n        self.vals = nn.Parameter(torch.zeros(out_channels)) \n        nn.init.kaiming_normal_(self.conv.weight, mode='fan_in', nonlinearity='leaky_relu')\n        \n    def forward(self, x):\n        x = self.conv(x)\n        x = F.leaky_relu(x, 0.1)\n        x = self.bn(x)\n        x += self.vals.view(1, self.bn.num_features, 1, 1).expand_as(x)\n        x = x * torch.tanh(F.softplus(x))\n        return x\n\nclass ResBlock(nn.Module):\n    def __init__(self, in_channels: int, out_channels: int):\n        super().__init__()\n        self.conv1 = ConvBlock(in_channels, out_channels, 3)\n        self.conv2 = ConvBlock(out_channels, out_channels, 3)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = x * torch.tanh(F.softplus(x))\n        return x\n    \nclass Encoder(nn.Module):\n    def __init__(self, in_channels = 2, res_level = 4):\n        super(Encoder,self).__init__()\n        self.res_layer = nn.Sequential(\n            *[ResBlock(in_channels, in_channels) for _ in range(res_level)]\n        )\n    \n    def forward(self, x):\n        x1 = x[:,:2,...]\n        x2 = x[:,2:4,...]\n        x3 = x[:,4:,...]\n        \n        x1 = self.res_layer(x1)\n        x2 = self.res_layer(x2)\n        x3 = self.res_layer(x3)\n        #maybe it would be effective using channelwise \n        \n        x = torch.cat([x1,x2,x3], dim = 1)\n        return x    ","cf136c1c":"class effModel(nn.Module):\n    def __init__(self, in_chans = 6, num_classes = 1, pretrained=True):\n        super(effModel,self).__init__()\n        \n        self.model = timm.create_model('efficientnet_b0', \n                                       in_chans=in_chans, \n                                       num_classes=num_classes,\n                                       pretrained=pretrained)\n    \n    def forward(self, x):\n        x = self.model(x)\n        return x","b2dffc9b":"def train(data_loader, encoder, model, optimizer, device):\n    model.train()\n    encoder.train()\n    for data in tqdm(data_loader, position=0, leave=True, desc='Training'):\n        images, targets = data\n        images = images.to(device, dtype=torch.float)\n        targets = targets.to(device, dtype=torch.float)\n        def closure():\n            optimizer.zero_grad()\n            encode = encoder(images)\n            output = model(encode)\n            loss = nn.BCEWithLogitsLoss()(output, targets.view(-1,1))\n            loss += 0.15*nn.L1Loss()(encode,images)\n            loss.backward()\n            return loss\n        optimizer.step(closure)","a4121bfb":"def evaluate(data_loader, encoder, model, device):\n    model.eval()\n    encoder.eval()\n    \n    final_targets = []\n    final_outputs = []\n    validate_losses = 0\n    with torch.no_grad():\n        \n        for data in tqdm(data_loader, position=0, leave=True, desc='Evaluating'):\n            images, targets = data\n\n            images = images.to(device, dtype=torch.float)\n            targets = targets.to(device, dtype=torch.float)\n            \n            output = encoder(images)\n            output = model(output)\n            loss = nn.BCEWithLogitsLoss()(output, targets.view(-1, 1))\n            validate_losses += loss.item()\n\n\n            targets = targets.detach().cpu().numpy().tolist()\n            output = output.detach().cpu().numpy().tolist()\n            \n            final_targets.extend(targets)\n            final_outputs.extend(output)\n    return final_outputs, final_targets, validate_losses\/len(data_loader)","29402e26":"def submission(data_loader, encoder, model, device):\n    model.eval()\n    encoder.eval()\n    \n    final_outputs = []\n    with torch.no_grad():\n        \n        for data in tqdm(data_loader, position=0, leave=True, desc='Evaluating'):\n            images, targets = data\n\n            images = images.to(device, dtype=torch.float)\n            \n            output = encoder(images)\n            output = model(output)\n            output = output.detach().cpu().numpy().tolist()\n            final_outputs.extend(output)\n    return final_outputs","55468241":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(\"GPU is available\")\nelse:\n    device = torch.device('cpu')\n    print(\"GPU not available, CPU used\")","1db807e3":"Batch_Size = 16\ninit_dataset = setiDataset(train_df)\nlengths = [int(len(init_dataset)*0.8), int(len(init_dataset)*0.2)]\n\ntrain_dataset, valid_dataset = random_split(init_dataset, lengths)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=Batch_Size, shuffle=True)\nvalid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=Batch_Size, shuffle=False)\n\nencoder = Encoder()\nencoder.to(device)\nmodel = effModel()\nmodel.to(device)\n\nparams = list(model.parameters()) + list(encoder.parameters())\noptimizer=  torch.optim.Adam(params, lr=1e-4, eps=1e-5)\n\nfor epoch in range(10):\n    print(epoch)\n    train(train_loader, encoder, model, optimizer, device)\n    valid_pred, target, valid_loss = evaluate(valid_loader, encoder, model, device)\n    roc_auc = metrics.roc_auc_score(target, valid_pred)\n    print(f\"Epoch={epoch}, Valid Loss={valid_loss}, Valid ROC AUC={roc_auc}\")","2f55c77d":"image, target = setiDataset(train_df[train_df.target==1].reset_index(drop=True))[1028]\n\nplt.figure(figsize=(16,8))\nplt.subplot(2,3,1)\nplt.imshow(image[0], aspect='auto')\nplt.subplot(2,3,2)\nplt.imshow(image[2], aspect='auto')\nplt.subplot(2,3,3)\nplt.imshow(image[4], aspect='auto')\nplt.show()\nprint('original, target:1')\n\nimage = image.unsqueeze(dim=0).to(device)\nimage = encoder(image)\nimage = image.to('cpu').view(6,273,256)\nimage = image.detach().numpy()\nplt.figure(figsize=(16,8))\nplt.subplot(2,3,1)\nplt.imshow(image[0], aspect='auto')\nplt.subplot(2,3,2)\nplt.imshow(image[2], aspect='auto')\nplt.subplot(2,3,3)\nplt.imshow(image[4], aspect='auto')\nplt.show()\nprint('encoder, target:1')\n\nimage, target = setiDataset(train_df[train_df.target==1].reset_index(drop=True))[512]\n\nplt.figure(figsize=(16,8))\nplt.subplot(2,3,1)\nplt.imshow(image[0], aspect='auto')\nplt.subplot(2,3,2)\nplt.imshow(image[2], aspect='auto')\nplt.subplot(2,3,3)\nplt.imshow(image[4], aspect='auto')\nplt.show()\nprint('original, target:1')\n\nimage = image.unsqueeze(dim=0).to(device)\nimage = encoder(image)\nimage = image.to('cpu').view(6,273,256)\nimage = image.detach().numpy()\nplt.figure(figsize=(16,8))\nplt.subplot(2,3,1)\nplt.imshow(image[0], aspect='auto')\nplt.subplot(2,3,2)\nplt.imshow(image[2], aspect='auto')\nplt.subplot(2,3,3)\nplt.imshow(image[4], aspect='auto')\nplt.show()\nprint('encoder, target:1')","f8f712a0":"def sigmoid(x):\n    return 1\/(1+np.exp(-x))\n\ntest_dataset = setiDataset(test_df)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=Batch_Size, shuffle=False)\npred = submission(test_loader, encoder, model, device)\nsub = test_df[['id']].copy()\nsub['target'] = sigmoid(np.array(pred).flatten())\nsub.to_csv('submission.csv', index=None)\n","56c29c93":"continued the SETI-test1.\n\nI thought it would more nice modify residual layer to auto-encoder layer.\n\npair (0,1), (2,3), (4,5) 2 images as one set in Encoder."}}