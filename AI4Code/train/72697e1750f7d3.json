{"cell_type":{"a01e85a0":"code","a7aab4af":"code","683b9d7c":"code","e3796d21":"code","33b05c2f":"code","87fb723c":"code","807abbf8":"code","aac43bec":"code","69aaed51":"code","8c0b4248":"code","7985b47c":"code","1c4b9c62":"code","0c004b34":"code","7058af55":"code","6b858af5":"code","0fc2ba03":"markdown","fe621d78":"markdown","d66f243c":"markdown"},"source":{"a01e85a0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n#  Classification Project on Pima Indains Diabetes dataset using Decission Tree and Random Forests\nObjective \n# Understanding the structure of the datsets and then Building a Model classification using Decision Tree and Random Forest\n","a7aab4af":"# Reading the Csv file  and  Viewing the structure of the datsets\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\ndiabets =pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv')\n\n# Viewing the Pima Indians Diabets datasets\ndiabets.head(5)\n","683b9d7c":"# Dividing the COlumns into target varaible and d=feature variables\n\nY = diabets.iloc[:,8]\nX = diabets.iloc[:,:8]\n\nX.head(5)","e3796d21":"# Sklearn Packages\nimport sklearn \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score , confusion_matrix","33b05c2f":"# Dividing the datsets into Training and Test set (70:30)\n\nX_train, X_test, y_train, y_test =train_test_split(X, Y, test_size =0.3 ,  random_state = 0)","87fb723c":"# building the Model\nDT = DecisionTreeClassifier()\nDT.fit(X_train, y_train)","807abbf8":"y_pred =DT.predict(X_test)\ny_pred","aac43bec":"# checking the performance of the Decission Tree model \n\nconfusion_matrix(y_test, y_pred)","69aaed51":"# Calculating the Accuracy \naccuracy_score(y_test, y_pred)","8c0b4248":"# Using the Decission Classification tree, we got an accuracy of 74 %","7985b47c":"#  Packages\nfrom sklearn.ensemble import RandomForestClassifier","1c4b9c62":"# building the Model\nRF = RandomForestClassifier()\nRF.fit(X_train, y_train)","0c004b34":"y_pred =RF.predict(X_test)\ny_pred","7058af55":"# checking the performance of the Decission Tree model \n\nconfusion_matrix(y_test, y_pred)","6b858af5":"# Calculating the Accuracy \naccuracy_score(y_test, y_pred)","0fc2ba03":"# Building Model Using Decision Tree","fe621d78":"# Using the RandomForset Classification , we got an accuracy of 77 %\n# So we Conculuded that the RandomForset  is better than Decission Tree","d66f243c":"# Model Building Using Random Forests"}}