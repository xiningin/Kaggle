{"cell_type":{"7d60d772":"code","9597698b":"code","bb585788":"code","c43651fc":"code","05409cf6":"code","fc66f8bc":"code","36ad2dce":"code","6e42f2fb":"code","19570877":"code","c81632cf":"code","85b2b1f5":"code","cfec6158":"code","36809826":"code","1911c205":"code","b62561d2":"code","6485f7c1":"code","71782250":"code","be495740":"code","b56637a1":"code","fe1a66e1":"markdown","8c4bafeb":"markdown","fc1d7308":"markdown","f1fdcce8":"markdown","ebe793c4":"markdown","a9a7581e":"markdown"},"source":{"7d60d772":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9597698b":"import pandas as pd\nimport numpy as np\nimport os\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport seaborn as sns\n\nfrom nltk.corpus import stopwords\nfrom nltk.util import ngrams\n\nfrom wordcloud import WordCloud\n\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA, TruncatedSVD\nfrom sklearn.metrics import classification_report,confusion_matrix\n\nfrom collections import defaultdict\nfrom collections import Counter\nplt.style.use('ggplot')\nstop=set(stopwords.words('english'))\n\nimport re\nfrom nltk.tokenize import word_tokenize\nimport gensim\nimport string\n\nfrom tqdm import tqdm\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Embedding, LSTM,Dense, SpatialDropout1D, Dropout\nfrom keras.initializers import Constant\nfrom keras.optimizers import Adam\n\nimport torch\n\nimport warnings\nwarnings.simplefilter('ignore')","bb585788":"train_tweet= pd.read_csv('..\/input\/nlp-getting-started\/train.csv')\ntest_tweet=pd.read_csv('..\/input\/nlp-getting-started\/test.csv')","c43651fc":"print('There are {} rows and {} columns in train'.format(train_tweet.shape[0],train_tweet.shape[1]))\nprint('There are {} rows and {} columns in test'.format(test_tweet.shape[0],test_tweet.shape[1]))","05409cf6":"train_tweet.head(10)","fc66f8bc":"# extracting the number of examples of each class\nReal_len = train_tweet[train_tweet['target'] == 1].shape[0]\nNot_len = train_tweet[train_tweet['target'] == 0].shape[0]","36ad2dce":"# bar plot of the 2 classes\nplt.rcParams['figure.figsize'] = (7, 5)\nplt.bar(10,Real_len,3, label=\"Real\", color='blue')\nplt.bar(15,Not_len,3, label=\"Not\", color='red')\nplt.legend()\nplt.ylabel('Number of examples')\nplt.title('Propertion of examples')\nplt.show()","6e42f2fb":"def length(text):    \n    '''a function which returns the length of text'''\n    return len(text)","19570877":"train_tweet['length'] = train_tweet['text'].apply(length)","c81632cf":"plt.rcParams['figure.figsize'] = (18.0, 6.0)\nbins = 150\nplt.hist(train_tweet[train_tweet['target'] == 0]['length'], alpha = 0.6, bins=bins, label='Not')\nplt.hist(train_tweet[train_tweet['target'] == 1]['length'], alpha = 0.8, bins=bins, label='Real')\nplt.xlabel('length')\nplt.ylabel('numbers')\nplt.legend(loc='upper right')\nplt.xlim(0,150)\nplt.grid()\nplt.show()","85b2b1f5":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\ntweet_len=train_tweet[train_tweet['target']==1]['text'].str.len()\nax1.hist(tweet_len,color='blue')\nax1.set_title('disaster tweets')\ntweet_len=train_tweet[train_tweet['target']==0]['text'].str.len()\nax2.hist(tweet_len,color='red')\nax2.set_title('Not disaster tweets')\nfig.suptitle('Characters in tweets')\nplt.show()\n\n","cfec6158":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\ntweet_len=train_tweet[train_tweet['target']==1]['text'].str.split().map(lambda x: len(x))\nax1.hist(tweet_len,color='blue')\nax1.set_title('disaster tweets')\ntweet_len=train_tweet[train_tweet['target']==0]['text'].str.split().map(lambda x: len(x))\nax2.hist(tweet_len,color='red')\nax2.set_title('Not disaster tweets')\nfig.suptitle('Words in a tweet')\nplt.show()","36809826":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\nword=train_tweet[train_tweet['target']==1]['text'].str.split().apply(lambda x : [len(i) for i in x])\nsns.distplot(word.map(lambda x: np.mean(x)),ax=ax1,color='blue')\nax1.set_title('disaster')\nword=train_tweet[train_tweet['target']==0]['text'].str.split().apply(lambda x : [len(i) for i in x])\nsns.distplot(word.map(lambda x: np.mean(x)),ax=ax2,color='red')\nax2.set_title('Not disaster')\nfig.suptitle('Average word length in each tweet')","1911c205":"def create_corpus(target):\n    corpus=[]\n    \n    for x in train_tweet[train_tweet['target']==target]['text'].str.split():\n        for i in x:\n            corpus.append(i)\n    return corpus","b62561d2":"def create_corpus_df(tweet, target):\n    corpus=[]\n    \n    for x in train_tweet[train_tweet['target']==target]['text'].str.split():\n        for i in x:\n            corpus.append(i)\n    return corpus","6485f7c1":"corpus=create_corpus(0)\n\ndic=defaultdict(int)\nfor word in corpus:\n    if word in stop:\n        dic[word]+=1\n        \ntop=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:10]","71782250":"# displaying the stopwords\nnp.array(stop)","be495740":"plt.rcParams['figure.figsize'] = (18.0, 6.0)\nx,y=zip(*top)\nplt.bar(x,y)","b56637a1":"corpus=create_corpus(1)\n\ndic=defaultdict(int)\nfor word in corpus:\n    if word in stop:\n        dic[word]+=1\n\ntop=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:10] \n    \n\nplt.rcParams['figure.figsize'] = (18.0, 6.0)\nx,y=zip(*top)\nplt.bar(x,y)","fe1a66e1":"**Class distribution**","8c4bafeb":"**Number of characters in tweets**","fc1d7308":"**Number of words in a tweet**","f1fdcce8":"**Average word length in a tweet**","ebe793c4":"**Common stopwords in tweets**","a9a7581e":"# Exploratory data analysis"}}