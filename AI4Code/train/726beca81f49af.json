{"cell_type":{"d7e8d3dc":"code","7560d25d":"code","bd5e462c":"code","b4f712ac":"code","df8d3540":"code","5d1d8077":"code","eb2a0393":"code","9c834f78":"code","4bbad250":"code","dc6eba4b":"code","88054e21":"code","6cd96b00":"code","d36b09c2":"code","f52521dc":"code","78339c03":"code","edfea369":"code","66a11a68":"code","382b09a6":"code","c71634d2":"code","0862eb6f":"code","a0c9e270":"code","1b9438fd":"code","63cf65f3":"code","1cd4dcd4":"code","6b5141ee":"code","0d459517":"code","a3e5ae50":"markdown","a9d7d2be":"markdown","0b305864":"markdown","377e6bff":"markdown","48e5fe21":"markdown","cc13cea8":"markdown","9681c756":"markdown","04a0fe62":"markdown","080e69c8":"markdown","68ed4051":"markdown","869aef83":"markdown","f50466b0":"markdown","025b518e":"markdown","f1952b61":"markdown","316b4b5f":"markdown","303c8a4a":"markdown","3977a8dc":"markdown","44a0f92e":"markdown","465977ca":"markdown","84c1cf45":"markdown","8bd74f8c":"markdown","aaa5e123":"markdown","282657e2":"markdown","507bed04":"markdown","b9e37991":"markdown","e7f9f013":"markdown","86559cce":"markdown","bfd4b67c":"markdown"},"source":{"d7e8d3dc":"!pip install kneed\n!pip install raceplotly","7560d25d":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport colorama\nfrom colorama import Fore as F\nfrom time import sleep\nfrom nlp_package_pv import *\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom sklearn.preprocessing import normalize\nfrom sklearn.cluster import MiniBatchKMeans\nfrom sklearn.cluster import KMeans\nfrom warnings import filterwarnings\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nimport matplotlib.cm as cm\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import silhouette_samples, silhouette_score\nfrom kneed import KneeLocator\nfrom brown_clustering_yangyuan import *\nfrom sklearn.cluster import Birch\nfrom sklearn.cluster import *\nfrom sklearn.decomposition import TruncatedSVD\nimport plotly.express as px\nfrom nltk.tokenize import RegexpTokenizer\nimport umap\nimport plotly\nfrom raceplotly.plots import barplot\nplotly.offline.init_notebook_mode (connected = True)\nfilterwarnings(\"ignore\")","bd5e462c":"print(F.YELLOW+'Importing Data ....')\nsleep(2)\ndata=pd.read_csv('..\/input\/reddit-vaccine-myths\/reddit_vm.csv')\nprint(F.YELLOW+'Imported Data Successfully !!!!')","b4f712ac":"# Checking for NAN values\ndata.isna().sum()","df8d3540":"# Removing URLand ID columns and removing nan values after that\ndata.drop(columns=['url','id'],axis=1,inplace=True)\ndata.dropna(inplace=True)\n\n# Changing the timestamp to datetime format\ndata['timestamp']=pd.to_datetime(data['timestamp'])\ndata.head()","5d1d8077":"# Preprocessing the data\n\ntitle=data['title'].values.copy()\n\n# Removing the word comment from the title columns since this seems to be the default value which is not needed\n\ndata['title'].replace({'Comment':''},inplace=True)\n\n# Joining both the title and the body together\n\ndata['text']=data[['title', 'body']].agg(' '.join, axis=1)\n\n# Adding the data for the title columns back to it\n\ndata['title']=title\n\n# Deleting the title variable \n\ndel title\n\n# Removing Links from the data\n\ndata['text']=data['text'].apply(lambda x:re.sub(r\"http\\S+\", \"\", x))\n\n# Code to remove the Special characters from the text \n\ndata['text']=data['text'].apply(lambda x:' '.join(re.findall(r'\\w+', x)))\n\n# Removing the stopwords and tokenizing the data\n\nrem_stopwords_tokenize(data,'text')\n\n# Lemmatizing the sentences\n\nlemmatize_all(data,'text')\n\n# Making all the tokens back to sentences\n\nmake_sentences(data,'text')\n\n\n# Having a look at the data\n\ndata.head()","eb2a0393":"# What is the length of the data we got here ??\nprint (F.YELLOW + \"The length of the dataframe is :\" , F.CYAN + str(len(data)))","9c834f78":"sample_data = data.text.astype('str').tolist()\n\n# toeknize\ntokenizer = RegexpTokenizer(r'\\w+')\nsample_data_tokenized = [w.lower() for w in sample_data]\nsample_data_tokenized = [tokenizer.tokenize(i) for i in sample_data_tokenized]\ncorpus = Corpus(sample_data_tokenized, 0.001)\nclustering = BrownClustering(corpus, 6)\nclustering.train()\n","4bbad250":"clustering.get_similar('vaccine')","dc6eba4b":"# Let's use both kmeans and brown clustering together :)\nfor i,j in enumerate(sample_data_tokenized) :\n    for n,m in enumerate(j):\n        sample_data_tokenized[i][n]=clustering.vocabulary[m]\n        \n# Padding the sequences\npadded_sequence=pad_sequences(sample_data_tokenized,maxlen=20,padding='post')\n\nprint(F.YELLOW+\"The vocabulary of the data is \" +F.CYAN + str(len(corpus.vocabulary))+F.YELLOW+' words long :)')","88054e21":"# Function to get the best k for the image\ndef get_k(X,print_plot=False):\n    arr=X\n    wcss=[]\n    for i in range(1,11):\n        kmeans = KMeans(n_clusters= i, init='k-means++', random_state=0)\n        kmeans.fit(arr)\n        wcss.append(kmeans.inertia_)\n    x=[i for i in range(1,11)]\n    kn = KneeLocator(x, wcss, curve='convex', direction='decreasing')\n    if print_plot==True:\n        plt.xlabel('number of clusters k')\n        plt.ylabel('Sum of squared distances')\n        plt.plot(x, wcss, 'rx-')\n        plt.vlines(kn.knee, plt.ylim()[0], plt.ylim()[1], linestyles='dashed')\n        plt.show()\n        print('The elbow is formed at :',kn.knee)\n    else:\n        return kn.knee","6cd96b00":"get_k(padded_sequence,print_plot=True)","d36b09c2":"clusters=KMeans(n_clusters=6,random_state=20).fit_predict(padded_sequence)","f52521dc":"def plot_tsne_pca(data, labels):\n    max_label = max(labels)+1\n    max_items = np.random.choice(range(data.shape[0]), size=1000, replace=False)\n    \n    pca = PCA(n_components=2).fit_transform(data[max_items,:])\n    tsne = TSNE().fit_transform(PCA(n_components=10).fit_transform(data[max_items,:]))\n    \n    \n    idx = np.random.choice(range(pca.shape[0]), size=320, replace=False)\n    label_subset = labels[max_items]\n    label_subset = [cm.hsv(i\/max_label) for i in label_subset[idx]]\n    \n    f, ax = plt.subplots(1, 2, figsize=(14, 6))\n    \n    ax[0].scatter(pca[idx, 0], pca[idx, 1], c=label_subset)\n    ax[0].set_title('PCA Cluster Plot')\n    \n    ax[1].scatter(tsne[idx, 0], tsne[idx, 1], c=label_subset)\n    ax[1].set_title('TSNE Cluster Plot')\n    \nplot_tsne_pca(padded_sequence, clusters)","78339c03":"data['Kmeans clusters']=clusters","edfea369":"data[data['Kmeans clusters']==2].head()","66a11a68":"data[data['Kmeans clusters']==5].head()","382b09a6":" def get_me_topics(cluster_id=1):\n    # Let's work on Cluster 1 and find topics for it :)\n    vectorizer = TfidfVectorizer()\n    X = vectorizer.fit_transform(data[data['Kmeans clusters']==cluster_id]['text'])\n    # SVD represent documents and terms in vectors \n    svd_model = TruncatedSVD(n_components=4, algorithm='randomized', n_iter=100, random_state=122)\n\n    svd_model.fit(X)\n    terms = vectorizer.get_feature_names()\n    for i, comp in enumerate(svd_model.components_):\n        terms_comp = zip(terms, comp)\n        sorted_terms = sorted(terms_comp, key= lambda x:x[1], reverse=True)[:7]\n        print()\n        print(\"Topic \"+str(i)+\": \")\n        for t in sorted_terms:\n            print(t[0],end=' ')\n            print(\" \",end=' ')","c71634d2":"get_me_topics(cluster_id=1)","0862eb6f":"vectorizer = TfidfVectorizer()\nX = vectorizer.fit_transform(data['text'])\nsvd_model = TruncatedSVD(n_components=4, algorithm='randomized', n_iter=100, random_state=122)\nX_topics = svd_model.fit_transform(X)\nembedding = umap.UMAP(n_neighbors=150, min_dist=0.5, random_state=12).fit_transform(X_topics)\n\nplt.figure(figsize=(7,5))\nplt.scatter(embedding[:, 0], embedding[:, 1], \nc = data['Kmeans clusters'],\ns = 10, # size\nedgecolor='none'\n)\nplt.show()","a0c9e270":"def make_topic_plot(cluster=1,topics=1,n=20) :\n    vectorizer = TfidfVectorizer()\n    X = vectorizer.fit_transform(data[data['Kmeans clusters']==cluster]['text'])\n    svd_model = TruncatedSVD(n_components=topics, algorithm='randomized', n_iter=100, random_state=122)\n    svd_model.fit(X)\n    comp=svd_model.components_\n    terms=vectorizer.get_feature_names()\n    plot_frame=pd.DataFrame(columns=['x','y','text','score','topic'])\n    for i in range(topics):\n        x=np.random.randint(10,200,n)\n        y=np.random.randint(10,200,n)\n        score=comp[i]\n        terms_comp = zip(terms, score)\n        sorted_terms = sorted(terms_comp, key= lambda x:x[1], reverse=True)[:n]\n        sorted_terms=np.array(sorted_terms)\n        sorted_terms=np.array(sorted_terms)\n        dn=pd.DataFrame()\n        dn['x']=x\n        dn['y']=y\n        dn['text']=sorted_terms[:,0]\n        dn['score']=sorted_terms[:,1].astype('float32')\n        dn['topic']=[i+1]*n\n        plot_frame=plot_frame.append(dn,ignore_index=True)\n    titl='Topic Plot For Cluster'+str(cluster)\n    fig=px.scatter(plot_frame,x='x',y='y',text='text',size='score',size_max=40,color='score',\n               color_continuous_scale='sunset',labels={'x':'','y':''},title=titl,animation_frame='topic')\n    fig.update_xaxes(showgrid=False)\n    fig.update_yaxes(showgrid=False)\n    fig.show()\n","1b9438fd":"make_topic_plot(cluster=1,topics=4)","63cf65f3":"# Important Topics in a cluster changing by time \ndef make_race_plot(cluster=1,top_n=4):\n    data_time=pd.DataFrame(columns=['text','score','time'])\n    for i in data[data['Kmeans clusters']==cluster].sort_values('timestamp')['timestamp'].values[4:] :\n            vectorizer = TfidfVectorizer()\n            X = vectorizer.fit_transform((data[(data['Kmeans clusters']==cluster) & (data['timestamp']<=i)].sort_values('timestamp')['text']))\n            svd_model = TruncatedSVD(n_components=1, algorithm='randomized', n_iter=100, random_state=122)\n            svd_model.fit(X)\n            comp=svd_model.components_[0]\n            terms=vectorizer.get_feature_names()\n            terms_comp = zip(terms, comp)\n            sorted_terms = sorted(terms_comp, key= lambda x:x[1], reverse=True)[:top_n]\n            sorted_terms=np.array(sorted_terms)\n            dn=pd.DataFrame()\n            dn['text']=sorted_terms[:,0]\n            dn['score']=sorted_terms[:,1].astype('float32')\n            dn['time']=[i]*top_n\n            data_time=data_time.append(dn)\n\n\n    my_raceplot = barplot(data_time,\n                          item_column='text',\n                          value_column='score',\n                          time_column='time')\n\n    fig=my_raceplot.plot(title = 'Change in most common word for a cluster over time',\n                     item_label = 'Text',\n                     value_label = 'Score',\n                     time_label='Creation Time :',\n                     frame_duration = 1600)\n    fig.show()","1cd4dcd4":"make_race_plot(cluster=2)","6b5141ee":"# Cluster vs Score\ngrouped=data.groupby('Kmeans clusters').mean()\npx.bar(grouped,x=grouped.index+1,y='comms_num',labels={'x':'Cluster'},color=(grouped.index+1).astype(str))","0d459517":"# Cluster vs Score\ngrouped=data.groupby('Kmeans clusters').mean()\npx.bar(grouped,x=grouped.index+1,y='score',labels={'x':'Cluster'},color=(grouped.index+1).astype(str))","a3e5ae50":"<p style = \"font-family:courier,arial,helvetica;font-size:300%;\">\n More Detailed Plot For Topics<\/p>\n","a9d7d2be":"<p style = \"font-family:courier,arial,helvetica;font-size:300%;\">\nHaving a look at cluster 2 <\/p>","0b305864":"<p style = \"font-family:courier,arial,helvetica;font-size:350%;\">\nReddit Vaccine Myths Analysis<\/p>","377e6bff":"<p style = \"font-family:courier,arial,helvetica;font-size:300%;\">\nPreprocessing The Data<\/p>","48e5fe21":"<p style = \"font-family:'Brush Script MT', cursive;font-size:200%;\">\nWe have succesfully preprocessed the data<\/p>","cc13cea8":"<p style = \"font-family:courier,arial,helvetica;font-size:300%;\">\nApplying K Means <\/p>","9681c756":"<p style = \"font-family:courier,arial,helvetica;font-size:300%;\">\nClosest Word Clusters To the word Vaccine<\/p>","04a0fe62":"<p style = \"font-family:courier,arial,helvetica;font-size:300%;\">\n A breif Look at Cluster 5<\/p>\n","080e69c8":"<p style = \"font-family:courier,arial,helvetica;font-size:300%;\">\nwhat is the length of the data ??<\/p>","68ed4051":"<p style = \"font-family:courier,arial,helvetica;font-size:200%;\">\nThis cluster is more about the people telling about the experience before or after the vaccine shot<\/p>\n\n","869aef83":"<p style = \"font-family:courier,arial,helvetica;font-size:300%;\">\n Using LSA for topic modelling<\/p>\n","f50466b0":"<p style = \"font-family:courier,arial,helvetica;font-size:300%;\">\nApplying Brown Clustering On The Data<\/p>","025b518e":"<p style = \"font-family:courier,arial,helvetica;font-size:300%;\">\n How Topics Change Over Time For Different Clusters<\/p>\n","f1952b61":"<p style = \"font-family:courier,arial,helvetica;font-size:200%;\">We can clearly see that the maximum amount of people have commented on the cluster 1 which shows how controversial that cluster may be unlike cluster 3 which seems to have the least mean amount of comments on it<\/p>\n\n","316b4b5f":"![](https:\/\/www.icegif.com\/wp-content\/uploads\/thank-you-icegif-10.gif)","303c8a4a":"<p style = \"font-family:courier,arial,helvetica;font-size:300%;\">\nPlotting The Clusters<\/p>\n","3977a8dc":"<p style = \"font-family:courier,arial,helvetica;font-size:300%;\">\nTokenizing and Padding the data <\/p>","44a0f92e":"<p style = \"font-family:courier,arial,helvetica;font-size:300%;\">\nImporting Data<\/p>","465977ca":"![](https:\/\/media0.giphy.com\/media\/iFgzUCWgxj7B22ik2K\/giphy.gif)","84c1cf45":"<p style = \"font-family:courier,arial,helvetica;font-size:200%;\">\nThese looks like questions about the vaccine and kind of shows some worries and myths in the minds of the people<\/p>\n","8bd74f8c":"<p style = \"font-family:courier,arial,helvetica;font-size:300%;\">\nImporting Packages<\/p>","aaa5e123":"<p style = \"font-family:courier,arial,helvetica;font-size:200%;\">There seems to be not much relation between clusters and the score .<\/p>\n\n\n","282657e2":"<p style = \"font-family:courier,arial,helvetica;font-size:200%;\">\nBrown clustering is used for word clustering but we need to cluster the sentences \ud83e\udd14\ud83e\udd14\ud83e\udd14\ud83e\udd14\n    <br> We can just use kmeans clustering on the score we got using the brown clustering to perform the sentence clustering\n<\/p>","507bed04":"<p style = \"font-family:courier,arial,helvetica;font-size:300%;\">\n Hoping you liked it :) <br> Would really like to know your feedback :) <br>\nWill try to explore this data more :) <\/p>\n","b9e37991":"<p style = \"font-family:courier,arial,helvetica;font-size:200%;\">As you can see above, the result is quite beautiful. Each dot represents a document and the colours represent the clusters. Our LSA model seems to have done a good job.<\/p>\n","e7f9f013":"<p style = \"font-family:courier,arial,helvetica;font-size:300%;\">\n Relation btw clusters and score<\/p>\n","86559cce":"<p style = \"font-family:courier,arial,helvetica;font-size:300%;\">\n Relation btw clusters and number of comments<\/p>\n","bfd4b67c":"![](https:\/\/img.etimg.com\/thumb\/width-1200,height-900,imgsize-261105,resizemode-1,msid-79592510\/prime\/pharma-and-healthcare\/2021-is-all-about-vaccine-transportation-piramal-schott-kaisha-are-ready-with-sturdy-vials.jpg)"}}