{"cell_type":{"3fc939e5":"code","96948b5b":"code","2085b4c7":"code","8d930cca":"code","258ee69e":"code","234f0d14":"code","d543dc4f":"code","25614d17":"code","bee514bd":"code","b5c5dcb8":"code","bde5e469":"code","4c4155f1":"code","a87f6091":"code","ea4e764e":"code","40997535":"code","21be82e6":"code","d20d0b60":"code","88a44b83":"code","7b3202a1":"code","c6d921c2":"code","232f5207":"code","a4d111db":"code","2c98fe45":"code","3ba78962":"code","997e3f27":"code","102e5707":"code","77ac7383":"code","731010d6":"code","668a9eba":"code","12b1717c":"code","45686d7b":"code","a400b247":"code","a0dafc4e":"code","692463a9":"code","9a57c677":"code","2edc89ae":"code","e9d21cc1":"code","997984d7":"code","46b0b312":"code","3c458053":"code","3e948a5b":"code","45b64f71":"code","c506a5a7":"code","0553bf53":"code","dad7188f":"code","527dae56":"code","6d19e12d":"code","62ac7d04":"code","e79060e6":"code","84f409f5":"code","a9fa52f3":"code","285d97a4":"code","47b55f5a":"code","1024d184":"code","056d9c8f":"code","49a7492d":"code","ced9d287":"code","e2886566":"code","15f08613":"code","67a6bd35":"code","561f3a20":"code","c8964827":"code","06ef9875":"code","0de3f840":"code","c759f38a":"code","a3b4ded9":"code","dd04c1d5":"code","5f87ad5a":"code","45e32ec4":"code","8d3a4fa7":"code","0c239184":"code","38770aa4":"code","e9ee6a8c":"code","bc854c75":"code","781c0074":"code","a6fac12a":"code","d9a1f8b5":"markdown","6342d7dc":"markdown","7215aaf6":"markdown","b6dcc82d":"markdown","59daa7f3":"markdown","1d8b3dae":"markdown","3d2c6cea":"markdown","96622cc7":"markdown","c49d4ab7":"markdown","c37a9f76":"markdown","85117512":"markdown","8393d5ca":"markdown","bfa608e8":"markdown","e9b61a94":"markdown","6d09d78e":"markdown","0c4c386f":"markdown","9474af82":"markdown","5840bc2c":"markdown","42bbe8d2":"markdown","7a9360c0":"markdown","5aa6ab3b":"markdown","65554444":"markdown","5f17236f":"markdown","9de9f9dd":"markdown","dcde0ce2":"markdown","e2566a73":"markdown","bf90b593":"markdown","183e917f":"markdown","9e2a376f":"markdown","fc493841":"markdown","c5b0f86e":"markdown","f43fb148":"markdown","45038ebc":"markdown","31003885":"markdown","f13e8fae":"markdown","27d4f537":"markdown","33afe0c6":"markdown","c05253fd":"markdown","e2c85749":"markdown","1dc508d1":"markdown","496d8b71":"markdown","7c1f9075":"markdown","de3b804c":"markdown","267fb5d4":"markdown","54ae2d13":"markdown","2d3c8d2f":"markdown"},"source":{"3fc939e5":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np","96948b5b":"weather = pd.read_csv('..\/input\/weather-dataset-rattle-package\/weatherAUS.csv')\nweather.head()","2085b4c7":"weather.info()","8d930cca":"weather.select_dtypes('object').columns","258ee69e":"weather.select_dtypes('float64').columns","234f0d14":"print(len(weather.select_dtypes('object').columns))\nprint(len(weather.select_dtypes('float64').columns))","d543dc4f":"weather = weather.drop(columns='RISK_MM')","25614d17":"weather.describe()","bee514bd":"weather.hist(bins=50, figsize=(20,15));","b5c5dcb8":"cat_attribs = weather.select_dtypes('object')\ncat_attribs = cat_attribs.drop(columns='Date')\nfor i in cat_attribs:\n    print(cat_attribs[i].value_counts())\n    if i != 'RainTomorrow':\n        print('\\n')","bde5e469":"len(cat_attribs['Location'].value_counts())","4c4155f1":"fig, axarr = plt.subplots(3, 2, figsize=(12,10))\ncat_attribs['WindGustDir'].value_counts(ascending=True).plot.barh(ax=axarr[0,0], title='WindGustDir')\ncat_attribs['WindDir9am'].value_counts(ascending=True).plot.barh(ax=axarr[1,0], title='WindDir9am')\ncat_attribs['WindDir3pm'].value_counts(ascending=True).plot.barh(ax=axarr[2,0], title='WindDir3pm')\ncat_attribs['RainToday'].value_counts(ascending=True).plot.barh(ax=axarr[0,1], title='RainToday')\ncat_attribs['RainTomorrow'].value_counts(ascending=True).plot.barh(ax=axarr[1,1], title='RainTomorrow')\ncat_attribs['RainTomorrow'].value_counts(ascending=True).plot.barh(ax=axarr[1,1], title='RainTomorrow')\nfig.delaxes(axarr[2,1]) # deletes empty plot\nplt.tight_layout();","a87f6091":"print('Total number of missing values: ')\nprint(weather.isnull().sum().sort_values(ascending=False))","ea4e764e":"print('Percentage of missing values: ')\nprint((weather.isnull().sum().sort_values(ascending=False) \/ len(weather)) * 100)","40997535":"missing_counts = weather.isnull().sum().sort_values(ascending=True)\nmissing_counts.plot.barh(figsize=(10,8), title = 'Total number of missing values by attribute');","21be82e6":"# Random sampling method\nfrom sklearn.model_selection import train_test_split\ntrain_set, test_set = train_test_split(weather, test_size=0.2, random_state=42)","d20d0b60":"(test_set['RainToday'].value_counts() \/ len(test_set)) * 100","88a44b83":"(weather['RainToday'].value_counts() \/ len(weather)) * 100","7b3202a1":"weather = train_set.copy()","c6d921c2":"corr_matrix = weather.corr()\ncorr_matrix","232f5207":"temp = weather[['MinTemp', 'MaxTemp', 'Temp9am', 'Temp3pm']]\ntemp.corr()","a4d111db":"from pandas.plotting import scatter_matrix\nscatter_matrix(temp, figsize=(15,12), alpha=0.05, s=5);","2c98fe45":"wind = weather[['WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm']]\nwind.corr()","3ba78962":"scatter_matrix(wind, figsize=(15,10), alpha=0.1);","997e3f27":"humidity = weather[['Humidity9am', 'Humidity3pm']]\nhumidity.corr()","102e5707":"scatter_matrix(humidity, figsize=(12,8), alpha=0.02);","77ac7383":"weather['RainTomorrow'].value_counts()","731010d6":"# RainTomorrow and RainToday values must be transformed from text (Yes, No) to numbers (0, 1) before correlations can be computed\nmake_binary = {'RainTomorrow': {'No': 0, 'Yes': 1},\n               'RainToday': {'No': 0, 'Yes': 1}\n              }\nweather.replace(make_binary, inplace=True)","668a9eba":"corr_matrix = weather.corr()\ncorr_matrix['RainTomorrow'].sort_values(ascending=False)","12b1717c":"weather = train_set.drop('RainTomorrow', axis=1)\nweather_labels = train_set['RainTomorrow'].copy()","45686d7b":"# Transformation pipeline for numerical attributes\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import MinMaxScaler\n\nnum_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='median')), # impute missing values with median\n    ('minmax_scaler', MinMaxScaler()),             # scale features\n])","a400b247":"# Transformation pipeline for categorical attributes\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\n\ncat_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent')), # impute missing values with mode\n    ('cat_encoder', OneHotEncoder())                      # convert text to numbers\n])","a0dafc4e":"# Apply transformations\nfrom sklearn.compose import ColumnTransformer\n\nnum_attribs = weather.select_dtypes('float64').columns\ncat_attribs = weather.select_dtypes('object').columns\n\nfull_pipeline = ColumnTransformer([\n        (\"num\", num_pipeline, num_attribs),\n        (\"cat\", cat_pipeline, cat_attribs),\n    ])\n\ntrain_set_prepared = full_pipeline.fit_transform(weather)","692463a9":"train_set_prepared","9a57c677":"from sklearn.linear_model import SGDClassifier\nsgd_clf = SGDClassifier(random_state=42)\nsgd_clf.fit(train_set_prepared, weather_labels) # fit model to transformed training set","2edc89ae":"some_data = weather.iloc[:5] # training set without the labels\nsome_labels = weather_labels.iloc[:5] # training set with labels only\nsome_data_prepared = full_pipeline.transform(some_data) # transform first five instances","e9d21cc1":"print(\"Predictions:\", sgd_clf.predict(some_data_prepared)) # predictions made by model\nprint(\"Labels:\", list(some_labels)) # labels from training set","997984d7":"sgd_clf.predict(train_set_prepared)","46b0b312":"len(sgd_clf.predict(train_set_prepared))","3c458053":"from sklearn.model_selection import cross_val_score\ncross_val_score(sgd_clf, train_set_prepared, weather_labels, cv=3, scoring='accuracy')","3e948a5b":"from sklearn.model_selection import cross_val_predict\nweather_labels_pred = cross_val_predict(sgd_clf, train_set_prepared, weather_labels, cv=3)","45b64f71":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(weather_labels, weather_labels_pred)","c506a5a7":"# precision = TP \/ (TP + FP) (the accuracy of positive predictions)\n# TP is the number of true positives, and FP is the number of false positives\nfrom sklearn.metrics import precision_score, recall_score\nprecision_score(weather_labels, weather_labels_pred, average='binary', pos_label='Yes') # == 11967 \/ (11967 + 3425)","0553bf53":"# recall = TP \/ (TP + FN)\nrecall_score(weather_labels, weather_labels_pred, average='binary', pos_label='Yes') # == 11967 \/ (11967 + 13569)","dad7188f":"from sklearn.metrics import f1_score\nf1_score(weather_labels, weather_labels_pred, average='binary', pos_label='Yes')","527dae56":"weather_labels_scores = cross_val_predict(sgd_clf, train_set_prepared, weather_labels, cv=3,\n                                          method='decision_function') # returns decision scores instead of predictions","6d19e12d":"from sklearn.metrics import precision_recall_curve\nprecisions, recalls, thresholds = precision_recall_curve(weather_labels, weather_labels_scores,\n                                                         pos_label='Yes')","62ac7d04":"def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n    plt.title('Precision and recall by the decision threshold')\n    plt.legend()\n    plt.xlabel(\"Threshold\")\n    plt.ylabel(\"Proportion\")\n    plt.axis([-4, 3, 0, 1])\n    \nplt.figure(figsize=(8,6))\nplot_precision_recall_vs_threshold(precisions, recalls, thresholds);","e79060e6":"def plot_precision_vs_recall(precisions, recalls):\n    plt.plot(recalls, precisions, \"b-\")\n    plt.title('Precision by recall')\n    plt.xlabel(\"Recall\")\n    plt.ylabel(\"Precision\")\n    plt.axis([0, 1, 0, 1])\n    plt.grid(True)\n\nplt.figure(figsize=(8,6))\nplot_precision_vs_recall(precisions, recalls)\nplt.plot([0.8, 0.8], [0., 0.525], \"r:\")\nplt.plot([0.0, 0.8], [0.525, 0.525], \"r:\")\nplt.plot([0.8], [0.525], \"ro\");","84f409f5":"threshold_80_recall = thresholds[np.argmin(recalls >= 0.80)]\nthreshold_80_recall","a9fa52f3":"weather_labels_pred_80 = (weather_labels_scores >= threshold_80_recall)\nweather_labels_pred_80","285d97a4":"# New predictions using threshold of -1.06 are boolean (False = No; True = Yes)\n# Convert labels on training set to boolean to allow for calculation of precision and recall\nweather_labels_arr = weather_labels.to_numpy()\nweather_labels_bool = weather_labels_arr == 'Yes'","47b55f5a":"precision_score(weather_labels_bool, weather_labels_pred_80)","1024d184":"recall_score(weather_labels_bool, weather_labels_pred_80)","056d9c8f":"from sklearn.metrics import roc_curve\nfpr, tpr, thresholds = roc_curve(weather_labels, weather_labels_scores, pos_label='Yes')","49a7492d":"def plot_roc_curve(fpr, tpr, label=None):\n    plt.plot(fpr, tpr, linewidth=2, label=label)\n    plt.plot([0, 1], [0, 1], 'k--') # Dashed diagonal\u201d\n    plt.axis([0, 1, 0, 1])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate (Recall)')\n    plt.grid(True)\n\nplt.figure(figsize=(8,6))\nplot_roc_curve(fpr, tpr);","ced9d287":"from sklearn.metrics import roc_auc_score\nroc_auc_score(weather_labels, weather_labels_scores)","e2886566":"from sklearn.ensemble import RandomForestClassifier\n\nforest_clf = RandomForestClassifier(random_state=42)\ny_probas_forest = cross_val_predict(forest_clf, train_set_prepared, weather_labels, cv=3, \n                                    method=\"predict_proba\")","15f08613":"y_scores_forest = y_probas_forest[:, 1]   # score = proba of positive class\nfpr_forest, tpr_forest, thresholds_forest = roc_curve(weather_labels, y_scores_forest, pos_label='Yes')","67a6bd35":"plt.figure(figsize=(8,6))\nplt.plot(fpr, tpr, \"b:\", label=\"SGD\")\nplot_roc_curve(fpr_forest, tpr_forest, \"Random Forest\")\nplt.legend(loc=\"lower right\")\nplt.show();","561f3a20":"roc_auc_score(weather_labels, y_scores_forest)","c8964827":"# Need predictions for calculating precision and recall\ny_train_pred_forest = cross_val_predict(forest_clf, train_set_prepared, weather_labels, cv=3)","06ef9875":"precision_score(weather_labels, y_train_pred_forest, pos_label='Yes')","0de3f840":"recall_score(weather_labels, y_train_pred_forest, pos_label='Yes')","c759f38a":"precisions_forest, recalls_forest, thresholds_forest = precision_recall_curve(weather_labels, y_scores_forest,\n                                                                              pos_label='Yes')","a3b4ded9":"plt.figure(figsize=(8,6))\nplot_precision_vs_recall(precisions_forest, recalls_forest)\nplt.plot([0.8, 0.8], [0., 0.54], \"r:\")\nplt.plot([0.0, 0.8], [0.54, 0.54], \"r:\")\nplt.plot([0.8], [0.54], \"ro\");","dd04c1d5":"threshold_80_recall = thresholds_forest[np.argmin(recalls_forest >= 0.80)]\nthreshold_80_recall","5f87ad5a":"y_scores_forest_pred_80 = (y_scores_forest >= threshold_80_recall)\nprecision_score(weather_labels_bool, y_scores_forest_pred_80)","45e32ec4":"recall_score(weather_labels_bool, y_scores_forest_pred_80)","8d3a4fa7":"cross_val_score(forest_clf, train_set_prepared, weather_labels, cv=3, scoring='accuracy')","0c239184":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n    {'alpha': [0.0001, 0.001, 0.01], 'verbose': [0, 1, 10, 100], 'shuffle': [True, False]} \n]\n\nsgd_clf = SGDClassifier(random_state=42)\n\ngrid_search = GridSearchCV(sgd_clf, param_grid, cv=3, scoring='accuracy', return_train_score=True)\n\ngrid_search.fit(train_set_prepared, weather_labels)","38770aa4":"grid_search.best_params_","e9ee6a8c":"cvres = grid_search.cv_results_\ncvres","bc854c75":"cvres['mean_test_score']","781c0074":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n    {'n_estimators': [3, 10, 30, 100], 'max_features': [2, 4, 6, 8]},\n    {'bootstrap': [True, False], 'n_estimators': [3, 10, 100], 'max_features': [2, 3, 4]} \n]\n\nforest_clf = RandomForestClassifier(random_state=42)\n\ngrid_search = GridSearchCV(forest_clf, param_grid, cv=3, scoring='accuracy', return_train_score=True)\n\ngrid_search.fit(train_set_prepared, weather_labels)","a6fac12a":"grid_search.best_params_","d9a1f8b5":"* There are 49 different locations.\n* `WindGustDir`, `WindDir9am`, and `WindDir3pm` are nominal attributes. Therefore, they should be converted to numbers using one-hot encoding.\n* `RainToday` should be converted to binary (`0`, `1`).\n* `RainTomorrow` is the target attribute.","6342d7dc":"The defaults values for the hyperparameters are satisfactory.","7215aaf6":"Before proceeding further, the dataset description advises to drop `RISK_MM` as it contains the amount of rainfall for the next day. This would leak future information to the model if used for training, resulting in an inflated accuracy rate when evaluating the model.","b6dcc82d":"There are 142,193 instances in the dataset. Some attributes, such as `Sunshine` and `Evaporation`, have a high proportion of missing values. In fact, most attributes appear to have at least some missing values.\n\nIn total, there are 24 attributes. 7 of these have the `object` type, while the remaining 17 are `float64`. The `object`s appear to be categorical attributes (`Date` can be treated as numerical or categorical depending on the analysis at hand).","59daa7f3":"These are the default values for these parameters.","1d8b3dae":"### Take a Quick Look at the Data Structure","3d2c6cea":"## Get the Data","96622cc7":"Separate the predictors and the label:","c49d4ab7":"### Confusion Matrix\n\nA confusion matrix is a better way to evaluate the performance of a classifier.","c37a9f76":"In this context, it is more important to predict days it is going to rain rather than days it *isn't* going to rain. So, I don't mind sacrificing precision in order to increase recall (I want to correctly detect more instances in the training set where `RainTomorrow` is equal to `Yes`).","85117512":"* There are a large number of missing values, particularly for `Sunshine`, `Evaporation`, `Cloud3pm`, and `Cloud9am` (missingness ranges from 37.7%\u201347.7%).\n* I will need to set these values to something else (e.g., zero, the mean, the median).\n* The target attribute `RainTomorrow` has no missing values.","8393d5ca":"As predicted, using a new threshold, the model correctly detects instances in the training set where `RainTomorrow` is equal to `Yes` 80% of the time. Therefore, 20% of the time the model predicts `No` when `RainTomorrow` is `Yes`. Additionally, because the threshold has been adjusted, when the model predicts rain the following day, it is now correct only 52% of the time. So, it is more cautious than the first model.","bfa608e8":"### Correlations","e9b61a94":"## Introduction\n\nI will use historic daily weather observations from numerous Australian weather stations to predict whether or not it will rain tomorrow. This data was sourced from the [Bureau of Meteorology](http:\/\/www.bom.gov.au\/climate\/data\/).\n\nA binary classification model will be trained on the target attribute `RainTomorrow` (Did it rain the next day? Yes or no).\n\nThis is a typical supervised learning task, as we are given *labelled* training examples (`RainTomorrow`). It is also a classification task as the target attribute `RainTomorrow` is binary with two possible values `Yes` or `No`. Additionally, this is a univariate problem because I have only one outcome of interest.","6d09d78e":"## Evaluate\n\n### Performance Measures\n\nEvaluating a classifier is often trickier than evaluating a regressor. Here are some options for evaluating the performance of my binary classifier:\n1. Cross-validation\n1. Confusion matrix\n1. Precision and recall\n1. The ROC curve","0c4c386f":"Accuracy is 85% (ratio of correct predictions) on all cross-validation folds. In comparison to the SGD classifier, it is about .001% better.","9474af82":"Create the transformation pipeline and and apply it to each attribute:","5840bc2c":"Accuracy is 85% (ratio of correct predictions) on all cross-validation folds.\n\nHow does this compare to a dumb classifier that predicts no rain every day? It rains about 22% of the time, so if I always guessed no rain, I would be correct approximately 78% of the time.","42bbe8d2":"I think `RainToday` will be an important attribute to predict `RainTomorrow`. I want to make sure the test set is representative of `RainToday` in the whole dataset.","7a9360c0":"The first row in the output considers instances in the training set where `RainTomorrow` is equal to `No`:\n* 84,793 instances were correctly classfied as `No`.\n* 3,425 instances were wrongly classified as `Yes`.\n\nOf the instances where `RainTomorrow` is equal to `Yes` (the second row):\n* 13,569 were wrongly classified as `No`.\n* 11,967 were correctly classified as `Yes`.","5aa6ab3b":"#### Random Forest Classifier","65554444":"* Each pairwise correlation of `MinTemp`, `MaxTemp`, `Temp9am`, and `Temp3pm` has a moderate (0.5 < r < 0.75) to strong (r > 0.75) relationship.\n* The strongest association is between `MaxTemp` and `Temp3pm` (r = 0.98) followed by `MinTemp` and `Temp9am` (r = 0.90).\n* `WindGustSpeed`, `WindSpeed9am`, `WindSpeed3pm` are moderately associated with each other (0.5 < r < 0.75).\n* There is a moderate relationship between `Humidity9am` and `Humidity3pm` (0.5 < r < 0.75).\n* The relationship between `Humidity9am` and `Humidity3pm` is not strictly linear.","5f17236f":"### Missing values","9de9f9dd":"* Many of these attributes, such as `MinTemp`, `MaxTemp`, `Pressure9am`, and `Pressure3pm`, have bell-shaped distributions.\n* `Rainfall` and `Evaporation` are heavily skewed to the right. How likely is 371 mm of rainfall in a day?\n* `WindGustSpeed`, `WindSpeed9am`, and `WindSpeed3pm` are also skewed to the right, but less so than `Rainfall` and `Evaporation`.\n* `Humidity9am` and `Humidity3pm` are slightly skewed to the left.\n* These attributes have very different scales. For example, compare `MinTemp` and `Pressure9am`.\n* `Cloud9am` and `Cloud3pm` are discrete attributes (cloud cover is measured in [oktas](https:\/\/en.wikipedia.org\/wiki\/Okta)).\n* The mode for `Sunshine` is 0. `Sunshine` is described as the \"number of hours of bright sunshine in the day\". It seems unlikely there would be so many days without any sunshine, but it depends on what \"bright\" means. Maybe during the winter months there are very few days with \"bright\" sunshine.\n* The mode for `Humidity9am` is 100%. Also, `Humidity3pm` has an usually high number of 100% days given the bell-shaped distribution.\n\nThe above highlights the need for feature scaling and the transformation of attributes so they approximate a normal distribution. Additionally, extreme values for `Rainfall`, `Evaporation`, `Sunshine`, `Humidity9am`, and `Humidity3pm` can be investigated.","dcde0ce2":"### Create a Test Set\n\nBefore exploring the data further, I will create a test set.","e2566a73":"I will use a stochastic gradient descent (SGD) classifier first, followed by a random forest classifier. After evaluating the performance of the SGD classifier using a confusion matrix and precision and recall, I will compare the performance of the two classifiers using a ROC curve.","bf90b593":"The random forest classifier performs slightly better than the SGD classifier. If I wanted a similar precision and recall as the SGD classifier, I would have to adjust the threshold.","183e917f":"### Numerical Attributes","9e2a376f":"### The ROC Curve","fc493841":"Each instance represents weather information from a weather station on a particular day.","c5b0f86e":"## Explore the Data","f43fb148":"### Cross-Validation","45038ebc":"## SGD Classifier","31003885":"### Categorical Attributes","f13e8fae":"### Precision and Recall","27d4f537":"Precision starts to fall sharply around 80% recall. This is where I will set the threshold.","33afe0c6":"## Prepare the Data","c05253fd":"The F\u2081 score is the harmonic mean of precision and recall and can be used to compare two classifiers. An F\u2081 score is only high when both precision *and* recall are high, which we don't always want.","e2c85749":"Based on this, if recall is 80%, the false positive rate is just over 20% (the ratio of `No`s that are incorrectly classified as `Yes`). I'm satisfied with this.","1dc508d1":"## Summary and Key Findings\n\n* I wanted to predict whether or not it will rain tomorrow.\n* I performed an EDA on weather data from 49 different weather stations across Australia for the past 10 years.\n* I selected and trained two models: an SGD classifier and a random forest classifier.\n* Both models had an accuracy of about 85% on all cross-validation folds of the training set.\n* I adjusted recall to 80%, which resulted in a precision of 54% for the random forest classifier.\n* I tried different combinations of hyperparameters for both models but the best combinations were the default values.\n* After further experimentation with feature engineering, I will be ready to measure performance on the test set to estimate the generalisation error.","496d8b71":"## Random Forest Classifier","7c1f9075":"A more concise metric than a confusion matrix is precision and recall.","de3b804c":"## Fine-Tune the Model\n\nI will use `GridSearchCV` to experiment with different combinations of hyperparameters.\n\n### Grid Search\n\n#### SGD Classifier","267fb5d4":"When the model predicts it will rain tomorrow, it is correct about 78% of the time. Moreover, it correctly classifies 47% of instances in the training set where `RainTomorrow` is equal to `Yes` (i.e., by predicting `Yes`). Or, stated alternatively, 53% of the time the model predicts `No` for `RainTomorrow` when it should be `Yes`.\n\nThese numbers may seem disappointing, but at least the model is correctly predicting nearly 50% of `Yes` instances. Recall the dumb classifier predicts `No`\u00a0for `RainTomorrow` for *all* instances. This means it correctly identifies 0% of days where it rains the following day in the training set. In comparison to this, the numbers above don't seem so bad!","54ae2d13":"Precision and recall are similar when compared to the SGD classifier (with the adjusted threshold). However, at about the same percentage of recall, precision is 2% greater with the random forest classifier.","2d3c8d2f":"The most promising attribute to predict whether or not it will rain tomorrow is `Sunshine`, followed by `Humidity3pm` and `Cloud3pm`. Interestingly, `MinTemp` and `Temp9am` have almost no linear relationship with `RainTomorrow`, and `RainToday` had a weaker association than I expected."}}