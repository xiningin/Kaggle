{"cell_type":{"66ad21fc":"code","6fb14d20":"code","b131b0ac":"code","eb764f36":"code","9b275427":"code","0e2c448f":"code","f62d8331":"code","71c0f1bb":"code","939e5ae4":"code","8304bb99":"code","3d864ebe":"code","417122c2":"code","5d3e3309":"code","dda73ff5":"code","0d4c00e2":"markdown","7242c748":"markdown","58b40fa4":"markdown","527d75ba":"markdown","19270c16":"markdown","ca9cfa00":"markdown","6bef1948":"markdown","e13f55c7":"markdown"},"source":{"66ad21fc":"import pandas as pd\nimport numpy as np\nimport zipfile\nimport os\nfrom matplotlib import pyplot as plt\nfrom sklearn.linear_model import LogisticRegression,LinearRegression\nfrom sklearn.model_selection import train_test_split,StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom scipy import fftpack\nimport xgboost\nimport warnings\nfrom sklearn.model_selection import cross_val_predict, cross_validate\nimport seaborn as sns; sns.set()\nfrom collections import Counter\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom keras.layers import LSTM,Input,Dense,Flatten,SpatialDropout1D,Dropout,CuDNNLSTM,Reshape,Concatenate\nfrom keras.layers import Lambda,concatenate,BatchNormalization\nfrom keras.models import Model\nfrom keras.utils import to_categorical\nfrom keras.optimizers import Adam\nfrom keras import backend as K \nfrom sklearn.preprocessing import LabelEncoder","6fb14d20":"directory = \"..\/input\/\"\nX_test_path = os.path.join(directory,\"X_test.csv\")\nX_train_path = os.path.join(directory,\"X_train.csv\")\nX_test_data = pd.read_csv(X_test_path)\nX_train_data = pd.read_csv(X_train_path)\ny_train_data = pd.read_csv(os.path.join(directory,\"y_train.csv\"))\nsample_submission = pd.read_csv(os.path.join(directory,\"sample_submission.csv\"))","b131b0ac":"le = LabelEncoder()\nle.fit(list(y_train_data[\"surface\"]))\ny_train_dataset_for_nn = to_categorical(le.transform(list(y_train_data[\"surface\"])))","eb764f36":"def dataset_for_nn(X_dataset):\n    num_samples = X_dataset.shape[0]\/\/128\n    X_dataset_for_nn = np.zeros((num_samples,128,10))\n    for i in range(num_samples):\n        subset = np.array(X_dataset.iloc[i*128:(i+1)*128,3:])\n        X_dataset_for_nn[i,:,:] = subset\n    return X_dataset_for_nn","9b275427":"X_train_for_nn = dataset_for_nn(X_train_data)\nX_test_for_nn = dataset_for_nn(X_test_data)","0e2c448f":"def freqs(dataset,width):\n    X = np.abs(fftpack.fft(dataset))\n    squeezed_dataset = []\n    for i in range(64\/\/width):\n        squeezed_dataset.append(np.mean(X[i*width:(i+1)*width]))\n    return squeezed_dataset","f62d8331":"def X_features(X_dataset,width=3):\n    num_samples = len(list(set(X_dataset[\"series_id\"])))\n    num_cols = 64\/\/width\n    features = np.zeros((num_samples,40+10*num_cols))\n    for i in range(num_samples):\n        X_train_subset = np.array(X_dataset.iloc[i*128:(i+1)*128,3:])\n        features[i,:10] = np.mean(X_train_subset,axis=0)\n        features[i,10:20] = np.std(X_train_subset,axis=0)\n        features[i,20:30] = np.max(X_train_subset,axis=0)-np.min(X_train_subset,axis=0)\n        features[i,30:40] = X_train_subset[-1,:]-X_train_subset[0,:]\n        for j in range(X_train_subset.shape[1]):\n            features[i,40+j*num_cols:40+(j+1)*num_cols] = freqs(X_train_subset[:,j],width)\n    return features","71c0f1bb":"X_train_features = X_features(X_train_data)\nX_test_features = X_features(X_test_data)","939e5ae4":"def LSTM_NN(drop):\n    inp = Input(shape=(128,10))\n    x = SpatialDropout1D(0.1)(inp)\n    inp_2 = Input(shape=(250,))\n    x_2 = Dense(250, input_shape=(250,), activation=\"sigmoid\")(inp_2)\n    x_2 = Dropout(drop)(x_2)\n    x_2 = Dense(120, activation=\"sigmoid\")(x_2)\n    x_2 = Dropout(drop)(x_2)\n    x_2 = Dense(60, activation=\"sigmoid\")(x_2)\n    x_2 = Dropout(drop)(x_2)\n    x_2 = BatchNormalization()(x_2)\n    x = CuDNNLSTM(units=200, return_sequences=True, return_state=False, go_backwards=False)(x)\n    x = Dropout(drop)(x)\n    x = CuDNNLSTM(units=100, return_sequences=False, return_state=False, go_backwards=False)(x)\n    x = concatenate([x,x_2])\n    x = Dropout(drop)(x)\n    outp = Dense(9, activation=\"sigmoid\")(x)\n    model = Model(inputs=[inp,inp_2], outputs=outp)\n    model.compile(loss='categorical_crossentropy', optimizer=Adam())\n    return model","8304bb99":"%%time\nn_splits=5\nkfold = StratifiedKFold(n_splits=n_splits, random_state=10, shuffle=True)\ny_test = np.zeros((X_test_for_nn.shape[0],9*n_splits))\ntrain_preds = np.zeros((X_train_for_nn.shape[0],9))\nX = X_train_for_nn\nX_test = X_test_for_nn\nY = np.array(list(y_train_data[\"surface\"]))\nfor i, (train_index, valid_index) in enumerate(kfold.split(X, Y)):\n    X_train, X_val =  X[list(train_index),:,:],X[list(valid_index),:,:]\n    X_train_feat, X_val_feat = X_train_features[list(train_index),:],X_train_features[list(valid_index),:]\n    Y_train, Y_val = Y[list(train_index)], Y[list(valid_index)]\n    Y_train = to_categorical(le.transform(Y_train))\n    Y_val = to_categorical(le.transform(Y_val))\n    model = LSTM_NN(0.15)\n    model.fit([X_train,X_train_feat], Y_train, epochs=120, validation_data=([X_val,X_val_feat], Y_val), verbose=2) \n    y_pred = model.predict([X_val,X_val_feat], verbose=2)\n    y_test[:,i*9:(i+1)*9] = model.predict([X_test,X_test_features])\n    train_preds[list(valid_index),:] = np.squeeze(y_pred)","3d864ebe":"res_train = np.argmax(train_preds,axis=1)\nans_train = np.argmax(to_categorical(le.transform(Y)),axis=1)\nprint (\"CV score\",round(accuracy_score(res_train,ans_train),4))","417122c2":"def most_frequent(List): \n    occurence_count = Counter(List) \n    return occurence_count.most_common(1)[0][0]\n\nres_test_inter = np.zeros((y_test.shape[0],n_splits))\nres_test=[]\nfor i in range(n_splits):\n    inter_arr = y_test[:,i*9:(i+1)*9]\n    res_test_inter[:,i] = np.argmax(inter_arr,axis=1)\nfor j in range(y_test.shape[0]):\n    res_test.append(int(most_frequent(res_test_inter[j,:])))","5d3e3309":"test_for_sub=le.inverse_transform(res_test)\nprint (test_for_sub[:5])\ntest_size = len(list(set(X_test_data[\"series_id\"])))\nY_test_pred_array = np.zeros((test_size,2))\nY_test_for_submission = pd.DataFrame(Y_test_pred_array,columns = [\"series_id\",\"surface\"])\nY_test_for_submission.iloc[:,0] = list(range(test_size))\nY_test_for_submission.iloc[:,1] = test_for_sub\nY_test_for_submission.to_csv(\"submission.csv\",index=None)","dda73ff5":"from IPython.display import FileLink\nFileLink('submission.csv')","0d4c00e2":"**Creating features**","7242c748":"**Training model and prediction**","58b40fa4":"**Exctracting test prediction (most frequent)**","527d75ba":"**Converting class labels to binary matrix representation**","19270c16":"**Function for extracting Fourier transform with averaging**","ca9cfa00":"**CV score**","6bef1948":"**Neural network architecture**","e13f55c7":"**Creating X-datasets for LSTM - shape = (num_samples,128,10)**"}}