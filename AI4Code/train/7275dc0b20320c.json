{"cell_type":{"42b696df":"code","1f32669e":"code","6b516f35":"code","8cbab71d":"code","f2c51b94":"code","989156b9":"code","4a2a857a":"code","69ab2a43":"code","eeefd057":"code","b38762e0":"code","07c7941e":"code","d323aeec":"code","72350ba9":"code","35309fb3":"code","793b5972":"code","61dc0606":"code","0bf0789b":"markdown","fda6ab8d":"markdown"},"source":{"42b696df":"import gc,uuid\nimport pandas as pd\nimport numpy as np\nimport pyarrow as pa\nimport tensorflow as tf\nfrom pyarrow import parquet as pq\nfrom collections import defaultdict\nfrom sklearn.preprocessing import LabelEncoder","1f32669e":"CATEGORICAL_DIM = ['item_id','dept_id','cat_id','store_id','state_id']\nwindowSize = 7\ntest_range = windowSize + 10","6b516f35":"df = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/sales_train_validation.csv')\ndf.index = df.id\ndf = df.drop('id',axis = 1)","8cbab71d":"testDate = list(map(lambda x: 'd_'+str(x),list(range(1913-test_range,1914))))\ntest = df[CATEGORICAL_DIM+testDate]\ntrain = df.drop(testDate,axis = 1)","f2c51b94":"# To-Do\n# 1. Calendar event generator corresponding to certain date\n# 2. Sell Price generator corresponding to certain date\n# 3. Make tensorflow dataset\n# 4. Make multi-step service\n\nclass feature_engineering(object):\n    \n    def __init__ (self,df,dimList,encoder = LabelEncoder,encodeDict = None):\n        super().__init__()\n        self._df = df\n        self._dimList = dimList\n        self.arr = df.drop(dimList,axis =1).values\n        self.indexList = df.index.tolist()\n        self._encoder = encoder\n        self.labelDict,self.encodeDict = self._pandas_to_categorical_encode(encodeDict)\n\n\n    def _rolling_window(self,a, window):\n        shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n        strides = a.strides + (a.strides[-1],)\n        return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\n\n    def _get_time_tensor(self,arr,window_size):\n        tmp = self._rolling_window(arr,window_size+1)\n        Xtensor = tmp[:,:-1].reshape(-1,window_size,1)\n        Ytensor = tmp[:,-1].reshape(-1,1)\n        return (Xtensor,Ytensor)\n\n    def _tensor_factory(self,arr,window_size,categoryIx):\n        X,Ytensor = self._get_time_tensor(arr,window_size)\n        Xtensor = {}\n        for i in self.labelDict:\n            label = self.labelDict[i][categoryIx]\n            Xtensor[i] = self._label_shape_transform(label,Ytensor.shape)\n        Xtensor['sells'] = X\n        return (Xtensor,Ytensor)\n\n    def np_to_time_tensor_generator(self,windowSize):\n        if np.ndim(self.arr) > 1:\n            for ix,v in enumerate(self.arr):\n                yield self._tensor_factory(v,windowSize,ix)\n        else:\n            yield self._tensor_factory(self.arr,windowSize,0) \n\n    def _label_encode(self,arr,encoder):\n        if encoder is None:\n            encoder = self._encoder()\n            enc_arr = encoder.fit_transform(arr)\n        else:\n            enc_arr = encoder.transform(arr)\n        return enc_arr,encoder\n\n    def _pandas_to_categorical_encode(self,encodeDict):\n        if encodeDict is None:\n            encodeDict = {}\n        labelDict = {}\n        for i in self._dimList:\n            if i in encodeDict:\n                enc_arr,encoder = self._label_encode(self._df[i],encodeDict[i])\n            else:\n                enc_arr,encoder = self._label_encode(self._df[i],None)\n            encodeDict[i] = encoder\n            labelDict[i] = enc_arr\n        return labelDict,encodeDict\n\n    def _label_shape_transform(self,label,shape):\n        tmp = np.zeros(shape)\n        tmp += label\n        return tmp\n\n    def get_encoder_class(self,label):\n        return len(self.encodeDict[label].classes_)\n    \n    def _get_tf_output_type(self):\n        dct = {}\n        for i in self.encodeDict:\n            dct[i] = tf.int16\n        dct['sells'] = tf.float32\n        return (dct,tf.float32)\n    \n    def _get_tf_output_shape(self,window_size):\n        dct = {}\n        for i in self.encodeDict:\n            dct[i] = tf.TensorShape([None,1])\n        dct['sells'] = tf.TensorShape([None,window_size,1])\n        return (dct,tf.TensorShape([None,1]))\n    \n    def get_tf_dataset(self,window_size):\n        return tf.data.Dataset.from_generator(\n                    self.np_to_time_tensor_generator,\n                    self._get_tf_output_type(),\n                    output_shapes = self._get_tf_output_shape(window_size),\n                    args = [window_size]\n        ), len(list(self.np_to_time_tensor_generator(window_size)))","989156b9":"fe = feature_engineering(train,['item_id','dept_id','cat_id','store_id','state_id'])\ndept_id_class_num = fe.get_encoder_class('dept_id')\nstate_id_class_num = fe.get_encoder_class('state_id')\nstore_id_class_num = fe.get_encoder_class('store_id')\ncat_id_class_num = fe.get_encoder_class('cat_id')\n\ntrain_univariate,train_step = fe.get_tf_dataset(windowSize)\ntrain_univariate = train_univariate.prefetch(tf.data.experimental.AUTOTUNE).repeat()","4a2a857a":"ge = feature_engineering(test,['item_id','dept_id','cat_id','store_id','state_id'],encodeDict= fe.encodeDict)\n\ncacheFile = str(uuid.uuid4())\nval_univariate,val_step = ge.get_tf_dataset(windowSize)\nvals_univariate = val_univariate.prefetch(tf.data.experimental.AUTOTUNE).repeat()","69ab2a43":"sells_input = tf.keras.layers.Input(shape=(windowSize,1),name = 'sells')\ncat_id_input= tf.keras.layers.Input(shape=1,name = 'cat_id')\nstore_id_input= tf.keras.layers.Input(shape=1,name = 'store_id')\ndept_id_input = tf.keras.layers.Input(shape=1,name = 'dept_id')\nstate_id_input = tf.keras.layers.Input(shape=1,name = 'state_id')\n\n\ndept_id = tf.keras.layers.Embedding(dept_id_class_num,1)(dept_id_input)\ndept_id =tf.keras.layers.Flatten()(dept_id)\n\nstate_id = tf.keras.layers.Embedding(dept_id_class_num,1)(state_id_input)\nstate_id =tf.keras.layers.Flatten()(state_id)\n\ncat_id = tf.keras.layers.Embedding(cat_id_class_num,1)(cat_id_input)\ncat_id =tf.keras.layers.Flatten()(cat_id)\n\nstore_id = tf.keras.layers.Embedding(store_id_class_num,1)(store_id_input)\nstore_id =tf.keras.layers.Flatten()(store_id)\n\nlstm = tf.keras.layers.LSTM(3)(sells_input)\nlstm = tf.keras.layers.Dense(20,'relu')(lstm)\n\ndense = tf.keras.layers.Concatenate()([lstm,cat_id,store_id,dept_id,state_id])\ndense = tf.keras.layers.Dense(40,'relu')(dense)\ndense = tf.keras.layers.Dropout(0.2)(dense)\ndense = tf.keras.layers.Dense(15,'relu')(dense)\ndense = tf.keras.layers.Dense(1,'relu')(dense)\nsimple_lstm_model = tf.keras.models.Model({\n    'sells':sells_input,\n    'cat_id':cat_id_input,\n    'dept_id':dept_id_input,\n    'state_id':state_id_input,\n    'store_id':store_id_input\n},dense)\nsimple_lstm_model.compile(optimizer='adam', loss='mse',metrics = ['mae','mse'])","eeefd057":"tf.keras.utils.plot_model(simple_lstm_model,show_shapes=True)","b38762e0":"EVALUATION_INTERVAL = len(list(fe.np_to_time_tensor_generator(windowSize)))\nvalidation_steps = len(list(ge.np_to_time_tensor_generator(windowSize)))\nEPOCHS = 10","07c7941e":"simple_lstm_model.fit(\n    train_univariate,\n    epochs=EPOCHS,\n    steps_per_epoch= EVALUATION_INTERVAL,\n    validation_data=vals_univariate, \n    validation_steps=validation_steps\n    )","d323aeec":"gen = ge.np_to_time_tensor_generator(windowSize)\nfor ix,v in enumerate(gen):\n    if ix == 0:\n        dct = v[0]\n        continue\n    for i in v[0]:\n        dct[i] = np.concatenate((dct[i],v[0][i]))\nprd = simple_lstm_model.predict(dct, verbose =1)\nprd = prd.reshape(-1,11)","72350ba9":"for i in range(20):\n    prdDf = pd.DataFrame(prd[i].reshape((1,-1)),columns = testDate[-11:])\n    prdDf.append(test[prdDf.columns].head(i+1).tail(1)).transpose().plot()","35309fb3":"prd","793b5972":"prdDate = list(map(lambda x: 'd_'+str(x),list(range(1914-windowSize,1914))))\nprdDf = df[CATEGORICAL_DIM+prdDate]","61dc0606":"for i in range(28):\n    print(i)\n    dtList = prdDf.columns.tolist()\n    [dtList.remove(i) for i in CATEGORICAL_DIM]\n    dtList = dtList[-windowSize:]\n    prdDf = prdDf[CATEGORICAL_DIM+dtList]\n\n    prdDf['d_'+ str(int(prdDf.columns.tolist()[-1].split('_')[-1])+1)] = -1\n    pe = feature_engineering(prdDf,['item_id','dept_id','cat_id','store_id','state_id'],encodeDict= fe.encodeDict)\n    gen = pe.np_to_time_tensor_generator(windowSize)\n    prd = simple_lstm_model.predict_generator(gen,use_multiprocessing = True, verbose =1)\n    prdDf[prdDf.columns[-1]] = list(map(lambda x: float(x[0]) ,prd))","0bf0789b":"# Submission","fda6ab8d":"# Model Training"}}