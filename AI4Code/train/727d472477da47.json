{"cell_type":{"a100ba14":"code","087b4e02":"code","84421222":"code","03b4f83a":"code","b41c6125":"code","4da41465":"code","c4d97f6f":"code","005b0b85":"code","83f8b3c5":"code","f2457818":"code","ea456e8b":"code","fc1ea2d7":"code","24ea27f5":"code","09f9cfaa":"code","34db3802":"code","cb661fe7":"code","72d1663d":"code","8f59951c":"code","70ecec74":"code","501aeb15":"code","64a21972":"code","afeb9e18":"code","51e05274":"code","2033116b":"code","6dd0ebec":"code","ac48b9e8":"code","41c7e697":"code","a86a7003":"code","dd0b14fa":"code","d16527a9":"code","68a5d0a1":"code","ee153483":"code","5d3464e9":"code","ee7f31c4":"code","be6482b6":"code","bb5e3f7b":"code","a877b0ff":"code","faf6d591":"code","32b3dc1a":"code","1740b04b":"code","5ed35039":"code","00984eac":"code","73ae2edd":"code","99a871f2":"code","ec9a1563":"code","0aa02fa4":"code","1a5d0d96":"code","e6d12777":"code","4aeb3c27":"code","903bca99":"code","e4b6c6d5":"markdown","6fd4acdd":"markdown","176e1e0b":"markdown","32939ba8":"markdown","f8eb7cf5":"markdown","5b616db4":"markdown"},"source":{"a100ba14":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom numpy import loadtxt\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nimport keras\nimport pandas as pd\nimport numpy as np\nimport riiideducation\nimport matplotlib.pyplot as plt\nfrom keras.callbacks import EarlyStopping","087b4e02":"#%%time\n#col_list = [\"user_id\", \"content_id\",\"answered_correctly\"]\ntrain = pd.read_feather('..\/input\/user-id-content-id-answered-correctly\/user_id_content_id_answered_correctly.feather')\nquestions = pd.read_feather('..\/input\/riiid-feather-dataset\/questions.feather')\nlectures = pd.read_feather('..\/input\/riiid-feather-dataset\/lectures.feather')\nexample_test = pd.read_feather('..\/input\/riiid-feather-dataset\/example_test.feather')\nexample_sample_submission = pd.read_feather('..\/input\/riiid-feather-dataset\/example_sample_submission.feather')","84421222":"\ntrain = train.sample(frac=0.10)\n","03b4f83a":"train","b41c6125":"questions.columns","4da41465":"questions.tags.value_counts()","c4d97f6f":"questions.part.value_counts()","005b0b85":"train.columns","83f8b3c5":"#df = train[\"user_id\",\"content_id\",\"answered_correctly\"]\n\n# ERFAN: Try to use\/make different features user_id and content_id are probably not super informative to models.\n#df = train[['user_id','content_id','answered_correctly']]\n","f2457818":"def prepare_features(col_name):\n    #df = train[train.content_type_id==0][[col_name,'answered_correctly']].groupby(col_name).agg(['count','sum'])\n    df = train[[col_name,'answered_correctly']].groupby(col_name).agg(['count','sum'])\n    #print(df)\n    if col_name == 'content_id':\n        col_name = 'question'\n        #TODO: Add question_entropy\n        # try decomposition methods?\n        \n    elif col_name == 'user_id':\n        col_name = 'student'\n        # TODO: user choice entropy\n        \n    df.columns=[col_name + '_total', col_name + '_correct']\n    df = df.astype('uint64')\n    df[col_name +'_incorrect'] = df[col_name + '_total'] - df[ col_name + '_correct']\n    df[col_name +'_correct_ratio'] = df[ col_name + '_correct']\/df[col_name + '_total']\n    return df\n    ","ea456e8b":"questions_dataframe = prepare_features('content_id')\nquestions_dataframe['content_id'] = list(questions_dataframe.index)\nquestions_dataframe = questions_dataframe.rename_axis(\"question_index\")\nquestions_dataframe","fc1ea2d7":"#import matplotlib.pyplot as plt\n#fig = plt.figure()\n#ax = fig.add_axes([0,0,1,1])\n#langs = ['Answered Correctly', 'Answered Incorrectly']\n#results = [sum(questions_dataframe['question_correct']),sum(questions_dataframe['question_incorrect'])]\n#ax.bar(langs,results)\n#plt.show()","24ea27f5":"#import matplotlib.pyplot as plt\n\n# Pie chart, where the slices will be ordered and plotted counter-clockwise:\n#labels = 'Answered Correctly', 'Answered Incorrectly'\n#sizes = [sum(questions_dataframe['question_correct']), sum(questions_dataframe['question_incorrect'])]\n#explode = (0, 0.1)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n\n#fig1, ax1 = plt.subplots()\n#ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n       # shadow=True, startangle=90)\n#ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\n#plt.show()","09f9cfaa":"users_dataframe = prepare_features('user_id')\nusers_dataframe['user_id'] = list(users_dataframe.index)\nusers_dataframe = users_dataframe.rename_axis(\"user_index\")\nusers_dataframe","34db3802":"df = pd.merge(train,users_dataframe,how = 'inner',on = 'user_id')\ndf = pd.merge(df,questions_dataframe,how = 'inner',on = 'content_id')\ndf","cb661fe7":"df = df[df['answered_correctly'] != -1]","72d1663d":"df.shape\n","8f59951c":"#df['prior_question_elapsed_time'].fillna(-1,inplace = True)\n#df['prior_question_had_explanation'].fillna(-1,inplace = True)","70ecec74":"#df['prior_question_had_explanation'] *= 1 # convert from boolean to numbers","501aeb15":"#use this in presentation\n\ncols = list(df.columns.values) #Make a list of all of the columns in the df\ncols.pop(cols.index('answered_correctly')) #Remove b from list\ndf = df[cols+['answered_correctly']] #Create new dataframe with columns in the order you want\nf = plt.figure(figsize=(19, 15))\nplt.matshow(df.corr(), fignum=f.number)\nplt.xticks(range(df.shape[1]), df.columns, fontsize=14, rotation=45)\nplt.yticks(range(df.shape[1]), df.columns, fontsize=14)\ncb = plt.colorbar()\ncb.ax.tick_params(labelsize=14)\n# TODO FIX GRAPH ","64a21972":"df.corr()['answered_correctly']","afeb9e18":"#df['prior_question_elapsed_time'].value_counts()","51e05274":"#df['prior_question_had_explanation'].value_counts()","2033116b":"df['answered_correctly'].value_counts()","6dd0ebec":"from sklearn.decomposition import PCA\npca = PCA(n_components=5, svd_solver='full')\npca.fit(df[[i for i in df.columns if i!= 'answered_correctly']])\nprint(pca.explained_variance_ratio_)\npca_featurelist = pca.transform(df[[i for i in df.columns if i!= 'answered_correctly']])\npca_featurelist","ac48b9e8":"pca_featurelist.shape","41c7e697":"import scipy.stats\nscipy.stats.spearmanr(pca_featurelist[:,0], df['answered_correctly'])\n","a86a7003":"#feature_list = ['content_id','prior_question_elapsed_time','prior_question_had_explanation', 'question_correct_ratio','student_correct_ratio']\nfeature_list = ['content_id','question_correct_ratio','student_correct_ratio']\nX = df[feature_list].to_numpy()\n\ny = df['answered_correctly'].to_numpy()","dd0b14fa":"X = X.astype(float)\n","d16527a9":"X","68a5d0a1":"y = y.astype(float)","ee153483":"y","5d3464e9":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 0)\n","ee7f31c4":"X_train","be6482b6":"# ERFAN: This structure needs revision - I dont think it's super good for this task.\nmodel = Sequential()\nmodel.add(Dense(12, input_dim=len(feature_list), activation='relu'))\nmodel.add(Dense(8, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))","bb5e3f7b":"optimizer = keras.optimizers.Adam(lr=0.001)\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=9)\nmodel.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[tf.keras.metrics.AUC(),'accuracy']) #ERFAN: added auc since that's what we are optimizing for - loss seems static.","a877b0ff":"model.fit(X_train, y_train, epochs=30, batch_size=50,validation_data=(X_test, y_test),verbose=1, callbacks=[es]) ","faf6d591":"predictions = model.predict(X_test)","32b3dc1a":"nnpredictions = model.predict_classes(X_test)","1740b04b":"X_test","5ed35039":"y_test","00984eac":"predictions","73ae2edd":"nnpredictions","99a871f2":"flatten_p = [ item for elem in predictions for item in elem]\n","ec9a1563":"flatten_p","0aa02fa4":"ptf = pd.DataFrame({'y_test':y_test, 'pred':flatten_p})","1a5d0d96":"ptf","e6d12777":"def prepare_test_features(df,test_df,feature_list):\n    #['content_id','prior_question_elapsed_time','prior_question_had_explanation', 'question_correct_ratio','student_correct_ratio']\n    \n        \n    test_df = pd.merge(test_df,questions_dataframe[['content_id', 'question_correct_ratio']],how='left',on='content_id')\n    test_df = pd.merge(test_df,users_dataframe[['user_id','student_correct_ratio']],how='left',on='user_id')\n    #test_df['prior_question_elapsed_time'].fillna(-1,inplace = True)\n    #test_df['prior_question_had_explanation'] *= 1 # convert from boolean to numbers\n    #test_df['prior_question_had_explanation'].fillna(-1,inplace = True)\n    #test_df.fillna(-1,inplace = True)\n    return test_df[feature_list].to_numpy().astype(float)","4aeb3c27":"env = riiideducation.make_env()\niter_test = env.iter_test()","903bca99":"for (test_df, sample_prediction_df) in iter_test:\n    test_questions = test_df['content_id'].to_numpy()\n    test_users = test_df['user_id'].to_numpy()\n    test_set = prepare_test_features(df,test_df,feature_list)\n    answered_correctly = model.predict_classes(test_set)\n    #answered_correctly = clf.predict(test_set)\n    test_df['answered_correctly'] = answered_correctly\n    env.predict(test_df.loc[test_df['content_type_id']==0,['row_id','answered_correctly']])","e4b6c6d5":"# Riiid classification using NN & Random Forest","6fd4acdd":"# Replace Null values","176e1e0b":"## Read the data\n<p>I read the data in feather format from this notebook https:\/\/www.kaggle.com\/aralai\/riiid-feather-dataset. It's much faster! \nIf you don't want to use feather, you can just replace the following lines with the csv format reading.","32939ba8":"For each batch in <code>test_df<\/code>, we will predict the probability of answering correctly (<code>nb.predict<\/code>) and then we will send the resulting data back to the environment. This last part is done in <code>env.predict<\/code>. Notice that we must not create any <code>submission.csv<\/code> file, this is done automatically by <code>env.predict<\/code>.","f8eb7cf5":"## Submission<p>\n<code>example_test<\/code> contains just a few dummy rows that can be used for development. The real submission must be made by using <code>riiideducation<\/code> package. To do that, we must create an environment and then loop through all the batches provided by <code>iter_test<\/code>.","5b616db4":"The initial purpose of this notebook was to make a very simple baseline for my own usage to better understand the data and the submission process. As I got a fairly decent score (given the simplicity of the model) I decided to share the notebook in case it can be helpful to someone else. This model could be improved by adding more features."}}