{"cell_type":{"95ea1c24":"code","18549a77":"code","a4ba9395":"code","1d7ac6dc":"code","79181293":"code","0cbcc5aa":"code","5cff0b7c":"code","49cc4942":"code","0d1da1bd":"code","036daf87":"code","3834b9f3":"code","23c0a76b":"code","f7860840":"code","43a2e96f":"code","bf1c8bc9":"code","a3455f4a":"code","274e1f24":"code","764d1a09":"code","aa30551e":"code","21f2e6dc":"code","8b9088ec":"code","ced6fdb5":"code","79760aa9":"code","798b6b00":"code","f3be8afe":"code","a2917cac":"code","d23103cc":"code","96edf7da":"code","00aa72c6":"code","239acba2":"code","a7e15f0d":"code","8a4a2428":"code","a45992de":"code","4088d749":"code","be5fbed0":"code","e63c7715":"code","cf80908c":"code","48ccf8d8":"code","c69ac9fb":"code","5ffb5edd":"code","396db3e2":"code","70eaea69":"code","35b6364c":"code","f9a85a12":"code","bc4aa411":"code","c02e261a":"code","4129f0e0":"code","4ce8b28c":"code","85d50b24":"code","2a0a2ce8":"code","0decaf1c":"code","563e1782":"code","638afcde":"code","8dcf51ac":"code","ec19de72":"code","39ad0d55":"code","be36887e":"code","8de9c669":"code","08ff41be":"code","aba420fe":"code","da8fa1cd":"code","7ce74894":"code","7bf4c898":"code","86166b5a":"code","733d784b":"code","84d90f4a":"code","ce422561":"code","e7d705e6":"code","9f246c14":"code","82990402":"markdown","a9b02608":"markdown","4277b130":"markdown","be62b8c9":"markdown","f3915046":"markdown","8deba42e":"markdown","f9f2f100":"markdown","a5c064aa":"markdown","c1e31835":"markdown","343d88fd":"markdown","199f63a7":"markdown","bd43a4d4":"markdown","537026fe":"markdown","14eb5926":"markdown","d061d6e0":"markdown","506f4a12":"markdown","219d1529":"markdown","c9fc27ad":"markdown","74aa195a":"markdown","445c9f17":"markdown","79c0d737":"markdown","d7023345":"markdown","fbb36c3a":"markdown","81997bfb":"markdown","b8f7b171":"markdown","7799aeb8":"markdown","c3909eb2":"markdown","4afa6b04":"markdown","9afefa69":"markdown","cebdd9f2":"markdown","d07d406a":"markdown","48b803a5":"markdown","4c8b5b1d":"markdown","977918ea":"markdown","228f9885":"markdown","72262aee":"markdown","44ee40b0":"markdown","dc3d6a6b":"markdown","ee57744c":"markdown","a8b8f54d":"markdown","231d7404":"markdown","46b4ad2b":"markdown","ffac50aa":"markdown","5e314868":"markdown","0a810d04":"markdown","013ecee7":"markdown","8c88d355":"markdown","4f85998a":"markdown","bb3a17a0":"markdown","1a0341b0":"markdown","2412cc9b":"markdown","eea0d2b8":"markdown","ac49f4dd":"markdown","70a27495":"markdown","acd7352b":"markdown","44e4aa36":"markdown","1257418a":"markdown","687258ab":"markdown","fbef803e":"markdown","34082f0a":"markdown","e1f159bc":"markdown","0beb8bd1":"markdown","43e06893":"markdown","c34b465e":"markdown","182f34ce":"markdown","cc378c29":"markdown","71ac3fea":"markdown","23861954":"markdown","37dda42d":"markdown","b1ca83ea":"markdown","dabd76f8":"markdown","2a60b959":"markdown","382498d8":"markdown","92c5b063":"markdown","e874c484":"markdown","d049f5ac":"markdown","2f7bc348":"markdown","90413efc":"markdown","ceeb30bd":"markdown","2621af8c":"markdown","e227ea78":"markdown","9e5f1a35":"markdown","9c6fffb6":"markdown"},"source":{"95ea1c24":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #visualization\nimport seaborn as sns #visualization\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","18549a77":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")","a4ba9395":"test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","1d7ac6dc":"train.head()","79181293":"train.info()","0cbcc5aa":"train['PassengerId'].count()","5cff0b7c":"sns.set_style('whitegrid') #setting style of charts \nsns.countplot(x='Survived',data=train).set(title='Survival')\nplt.show()","49cc4942":"#how many values of 0 and 1 were in Survived column\ntrain['Survived'].value_counts()","0d1da1bd":"#what are the percentages?\nround(train['Sex'].value_counts()\/891,2)*100","036daf87":"sns.histplot(data=train, x=\"Age\")\nplt.show()","3834b9f3":"bins= [0,18,60,90]\nlabels = ['Kid','Adult', 'Senior']\nage_group = pd.cut(train['Age'], bins=bins, labels=labels, right=False)\nprint(age_group.value_counts())","23c0a76b":"#what are the percentages?\nround(age_group.value_counts()\/891,2)*100","f7860840":"sns.histplot(data=train, x=\"Age\", hue='Sex')\nplt.show()","43a2e96f":"sns.histplot(data=train, x=\"Age\", hue='Pclass')\nplt.show()","bf1c8bc9":"train['Embarked'].value_counts()","a3455f4a":"sns.barplot(y='Fare',x='Embarked',data=train,palette='rainbow')\nplt.show()","274e1f24":"sns.countplot(x='Survived',hue='Sex',data=train).set(title='Survival by sex')\nplt.show()","764d1a09":"train_without_na = train.dropna() #Additional DataFrame for visualization\nsns.histplot(data=train_without_na, x=\"Age\", hue='Survived')\nplt.show()","aa30551e":"sns.countplot(x='Survived',hue='Pclass',data=train,palette='rainbow')\nplt.show()","21f2e6dc":"sns.barplot(y='Fare',x='Pclass',data=train,palette='rainbow')\nplt.show()","8b9088ec":"sns.barplot(y='Fare',x='Survived',data=train,palette='rainbow')\nplt.show()","ced6fdb5":"sns.boxplot(x='Pclass',y='Fare',hue='Survived',data=train,palette='rainbow')\nplt.show()","79760aa9":"pass_class = train.groupby(['Pclass'])\nround(pass_class['Fare'].describe(),2)","798b6b00":"train[train.Fare > 250].sort_values('Ticket')","f3be8afe":"sns.countplot(x='Survived',hue='Embarked',data=train,palette='rainbow')\nplt.show()","a2917cac":"sns.countplot(x='Survived',hue='SibSp',data=train,palette='rainbow')\nplt.legend(loc='upper right',title='SibSp')","d23103cc":"sns.countplot(x='Survived',hue='Parch',data=train,palette='rainbow')\nplt.legend(loc='upper right',title='Parch')","96edf7da":"train.info()","00aa72c6":"train['Pclass'] = train['Pclass'].astype(\"category\")\ntrain['Sex'] = train['Sex'].astype(\"category\")\ntrain['SibSp'] = train['SibSp'].astype(\"category\")\ntrain['Parch'] = train['Parch'].astype(\"category\")\ntrain['Embarked'] = train['Embarked'].astype(\"category\")\ntrain.info()","239acba2":"sns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='viridis')","a7e15f0d":"plt.figure(figsize=(12, 7))\nsns.boxplot(x='Pclass',y='Age',data=train,palette='winter')","8a4a2428":"grouped_df = train.groupby(train.columns[2])\nmean_train = grouped_df.mean()\nround(mean_train['Age'],0)","a45992de":"def impute_age(cols):\n  Age = cols[0]\n  Pclass = cols[1]\n    \n  if pd.isnull(Age):\n\n    if Pclass == 1:\n      return 38\n    elif Pclass == 2:\n      return 30\n    else:\n      return 25\n  else:\n    return Age","4088d749":"train['Age'] = train[['Age','Pclass']].apply(impute_age,axis=1)","be5fbed0":"sns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='viridis')","e63c7715":"train.drop('Cabin',axis=1,inplace=True)","cf80908c":"train.head()","48ccf8d8":"sns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='viridis')","c69ac9fb":"train[train.isnull().any(axis=1)]","5ffb5edd":"train.dropna(inplace=True)","396db3e2":"train[train.isnull().any(axis=1)]","70eaea69":"test['Pclass'] = test['Pclass'].astype(\"category\")\ntest['Sex'] = test['Sex'].astype(\"category\")\ntest['SibSp'] = test['SibSp'].astype(\"category\")\ntest['Parch'] = test['Parch'].astype(\"category\")\ntest['Embarked'] = test['Embarked'].astype(\"category\")\ntest.info()","35b6364c":"sns.heatmap(test.isnull(),yticklabels=False,cbar=False,cmap='viridis')","f9a85a12":"grouped_df = test.groupby('Pclass')\nmean_test = grouped_df.mean()\nround(mean_test['Age'],0)","bc4aa411":"def impute_age_test(cols):\n  Age = cols[0]\n  Pclass = cols[1]\n  if pd.isnull(Age):\n\n    if Pclass == 1:\n      return 41\n    elif Pclass == 2:\n      return 29\n    else:\n      return 24\n  else:\n    return Age","c02e261a":"test['Age'] = test[['Age','Pclass']].apply(impute_age_test,axis=1)","4129f0e0":"sns.heatmap(test.isnull(),yticklabels=False,cbar=False,cmap='viridis')","4ce8b28c":"test.drop('Cabin',axis=1,inplace=True)","85d50b24":"sns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='viridis')","2a0a2ce8":"test[test.isnull().any(axis=1)]","0decaf1c":"test['Fare'].fillna(test['Fare'].mean(), inplace = True)","563e1782":"test[test.isnull().any(axis=1)]","638afcde":"train.head()","8dcf51ac":"train.drop(['PassengerId','SibSp','Parch','Name','Ticket','Embarked'],axis=1,inplace=True)","ec19de72":"train.head()","39ad0d55":"train.info()","be36887e":"features = [\"Sex\",\"Pclass\"]\n#For each binary variable, the process looks like this\n#1) we create new binary variables\nX_dummy = pd.get_dummies(train[features], drop_first=True)\n#2) we add to our set X\nX_train = pd.concat([train,X_dummy],axis=1)\n#3) we remove the variables on the basis of which the dummy variables were created\nX_train.drop(['Sex','Pclass'],axis=1,inplace=True)","8de9c669":"X_train.head()","08ff41be":"y_train = train[\"Survived\"]\nX_train.drop(['Survived'], axis=1,inplace=True)","aba420fe":"passanger_id_test = test.copy()","da8fa1cd":"test.head()","7ce74894":"test.drop(['PassengerId','SibSp','Parch','Name','Ticket','Embarked'],axis=1,inplace=True)","7bf4c898":"test.head()","86166b5a":"features = [\"Sex\",\"Pclass\"]\n#For each binary variable, the process looks like this\n#1) we create new binary variables\nX_test_dummy = pd.get_dummies(test[features], drop_first=True)\n#2) we add to our set X\nX_test = pd.concat([test,X_test_dummy],axis=1)\n#3) we remove the variables on the basis of which the dummy variables were created\nX_test.drop(['Sex','Pclass'],axis=1,inplace=True)","733d784b":"X_test.head()","84d90f4a":"from sklearn.linear_model import LogisticRegression\n#we build a model \nlogmodel = LogisticRegression(random_state=42) #if you want to get exactly the same results set random state on the same value\n#train the model on the traing set \nlogmodel.fit(X_train,y_train)","ce422561":"#prediction \npredictions_log = logmodel.predict(X_test)","e7d705e6":"output = pd.DataFrame({'PassengerId': passanger_id_test.PassengerId, 'Survived': predictions_log})\noutput.to_csv('my_submission_log.csv', index=False)\nprint(\"Your submission was successfully saved!\")","9f246c14":"print('Acurracy score for logistic regression model: 0.75598')","82990402":"#### -> class","a9b02608":"You can see from the graph that the passengers were of different ages. Among the passengers were children, the main group was working age people and some seniors. \nIn order to get more detailed information I create three age groups:\n- 0-18 child\n- 18-60 adult \n- 60 + senior\n\n*This is my choice of groups, you can create more groups all depends on the purpose of analysis. One could go further and, in order to obtain even more detailed information, adjust the intervals to the era, e.g. taking into account that people lived shorter in those times. assume to get general information about passengers.*","4277b130":"#### -> Age \nFor the age column we will use imputations we will fill in the NA vaules with the average age in each class. ","be62b8c9":"#### How many passengers were on the ship (in the training set)? How many passengers do we have information about? ","f3915046":"> 35% of passengers were women, the rest 65% were men","8deba42e":"We have a model, so now we forecast.","f9f2f100":"> 644 of passengers embarked in Southampton\n\n> 168 passengers embarked in Cherbourg\n\n> 77 passengers embarked in Queenstown","a5c064aa":"## EDA\n<a id=\"EDA\"><\/a>\nLet's explore data.\n\n*The first step should be to read [Data](https:\/\/www.kaggle.com\/c\/titanic\/data) tab in competition overview*\n\nTo recap there are 12 features:\n- `PassengerId`\n- **`Survived` - target variable | 0 = No, 1 = Yes**\n- `Pclass` - Ticket class | 1 = 1st, 2 = 2nd, 3 = 3rd\n- `Name`\n- `Sex` \n- `Age`\n- `SibSp` - # of siblings \/ spouses aboard the Titanic\n- `Parch` - # of parents \/ children aboard the Titanic\n- `Ticket` - Ticket number\n- `Fare` - Passenger fare\n- `Cabin` - Cabin number\n- `Embarked` Port of Embarkation | C = Cherbourg, Q = Queenstown, S = Southampton","c1e31835":"# Overview\nHi, I would like to share my work on Logistic regression model which was my first attempt to this competition. \nThe objective of this notebook is to show the process of data analysis. I'm aware that other type of model like Random Forest would give higher accuracy score. Regardless I think it would be useful for beginners to see the whole process of analysis using one type of model.\nFor beginers I also recommend [Titanic Tutorial](\/https:\/\/www.kaggle.com\/alexisbcook\/titanic-tutorial).\n","343d88fd":"> 342 passengers were rescued;\n> the remaining 549 died","199f63a7":"Let's see the effect ","bd43a4d4":"<a id=\"model\"><\/a>\n## Model","537026fe":"Do you remember the types of these variables?","14eb5926":"It's better now, let's move on to missing values, we will check if there are any.\n<a id=\"Na\"><\/a>","d061d6e0":"> Now we have accurate passenger (in training set) numbers for each group and can assess the percentage of participation of each group: \n> - adults of working age 65% (the biggest age group)\n> - children were 13% of passengers \n> - seniors 3%","506f4a12":"> Three tickets were purchased for more than 250 if we analyze the most expensive ticket it comes out that it was purchased for three people in first class. It was probably a suite, so we assume that this value is probable. \n\n> By the way, we discover another problem with the data: different values for `Cabin` for passengers on the same `Ticket`. These three people have different last names so we can assume they are acquaintances and were given separate rooms however with the Fortune family we see the same ticket name and the same 3 cabins. Let's keep this in mind as we continue our analysis.","219d1529":"Another importat factor was **class**. \n- More people with first class ticket survive the disaster \n- 3rd class ticket significantly increased risk of death\n\nA factor related to ticket class appears to be the price of the ticket, so intuitively the price of the ticket affects the chance of surviving. Let's verify this statement based on data.","c9fc27ad":"<a id=\"Cleaning\"><\/a>\n## Data preparation and cleaning\nNow you need to prepare the data, i.e. check for missing data, outliners, perform scaling if needed. \n\nNow our data types look like this","74aa195a":"After deleting, again we check if there are any missing values left","445c9f17":"> Let's check the stats for fare in each class","79c0d737":"##### Deleting Cabin column","d7023345":"*We create a copy of the test set to later assign the passenger id to the prediction (needed to send the submission).*","fbb36c3a":"Now let's assign our target variable to *y_train* and from *X_train* we will remove the explained variable `Survived`","81997bfb":"##### How does age compare by gender?","b8f7b171":"Finally our data sets are clean, but are they ready to build a model? \n\nNo, this is not the end of data preparation. \n\nLet's see our data","7799aeb8":"Let's build a logistic regression model.","c3909eb2":"A more **expensive ticket** offered a better chance of survival ","4afa6b04":"The exact average values are","9afefa69":"##### Other missing data ","cebdd9f2":"> Observation of the graph shows: \n> - First class consisted mainly of older, wealthier people\n> - Second class is made up of people of different ages, but rather young, we can describe them as middle class\n> - Third class consisted of young people, mostly the poorer ones, and the ship's workers","d07d406a":"Now, using a simple function, let's fill the missing values with the calculated age","48b803a5":"As we know our model should include variables that give information important to the purpose of building the model. \nOur goal is to predict whether the passenger survived, from previous EDA analysis we know two variables were significant `Sex`,`Age`,`Pclass` and `Fare`. \n\nWe leave only these 4 variables with the target variable and remove all other variables because we assume we don't need them.","4c8b5b1d":"> The age distribution by age was fairly similar for males and females, however, large differences can be seen in ages 18-40. There were more males in this range. This is due to the fact that males made up the majority of the crew. ","977918ea":"### Logistic Regression \nLogistic regression is a model for classification problems, you can read more about it in [this article](https:\/\/towardsdatascience.com\/logistic-regression-fa1a86270eb).\n\nAs in the [Titanic Tutorial](https:\/\/www.kaggle.com\/alexisbcook\/titanic-tutorial) we will use the sklearn library, so model building and prediction will be familiar to you. First we build the model on the training set, then we use the model on the test set to predict whether the passenger survived or not. Finally we check the quality by submitting the list of our predictions in the competition.","228f9885":"<a id=\"library\"><\/a>\n## Importing libraries\nFirst step is to import libraries to be able to do actuall work.","72262aee":"#### -> Cabin","44ee40b0":"#### Did the port affect the price of the ticket purchased?","dc3d6a6b":"Empty, uff. We have finished preparing the training set!\n\nNow it's time to prepare the test set. We will do exactly the same steps. ","ee57744c":"The chart suggests that now the data is fine, but let's still see the table with the missing values ","a8b8f54d":"##### Age imputation\nWe do exactly the same as for the training set, calculate the average age across classes, and then using a simple function to fill in the missing values","231d7404":"Let's see the average age in classes ","46b4ad2b":"Now our set is just five variables ","ffac50aa":"The number of relatives on board didn't matter either","5e314868":"Let's see the effect of our action.","0a810d04":"The `Cabin` column is gone, again are there any missing values left?","013ecee7":"Note: In order to avoid redundancy, we are removing one dummy column. \n> Example \nvariable `Sex` has two values: *male* or *famle*. After creating the dummy, we have two columns *sex_famale* and *sex_male* which complement each other, that is, when the passenger was a woman, sex_famale takes the value 1 and sex_male 0. So to get all the information we need only one column. \n\nThat is why instead of two columns of categorical variables, we have 3: \n- `Sex_male` from `Sex` - the Sex_female column has been removed\n- `Pclass_2` and `Pclass_2` from `Pclass` - the Pclass_2 column has been removed\n\n","8c88d355":"First, let's take care of data type cleanliness, we know that several variables are categorical variables so let's tell Pandas about it.","4f85998a":"##### What class did passengers of different ages travel in?","bb3a17a0":"#### What percentage of passengers were women?","1a0341b0":"We save the values predicted by our model to a csv file according to the competition formula so that we can make a submission.","2412cc9b":"There is one observation with a missing `Fare` value in the test set. We will fill it in with the average Fare value of the entire set. \n\n*You can try using the mean in the third class if you want to find an even more accurate value.*","eea0d2b8":"### Training set\n","ac49f4dd":"#### -> gender and age","70a27495":"We do not know the location of the embarked two female passengers. It's only two people so we can remove these observations, the alternative is to replace these values with the most common location Southampton (S). ","acd7352b":"> As we can see in the training set there are data about 891 passengers.","44e4aa36":"> Let's see the passengers who paid more than 250 for a ticket. As we guessed, they will be first class passengers, rather traveling with families. ","1257418a":"#### -> fare","687258ab":"> *With the boxplot, we discover some outliers. Is it possible that the passenger paid more than 500? This should be checked.*","fbef803e":"Remember we already talked about this column, we observed some inconsistency in this column (for the same ticket different cabins were granted for some passengers). Now we see that there are very many values missing in this column. \nWe could try to sort out this problem, but in this case there are so many missing values that we decide to remove this column. ","34082f0a":"> The plot shows where passengers boarded according to their Fare:\n> - the richest people got in Cherbourg (C)\n> - people who bought the cheapest ticket embarked in Queenstown (Q)","e1f159bc":"Our theory was correct. A more expensive ticket links to a higher class of ticket.\n\nThis theory also has a historical foundation in the early 20th century, class divisions regarding social status and wealth were important in Europe. \nWhen it came to travel, higher class meant more comfort, but as we know a more expensive ticket.","0beb8bd1":"It seems that the embarked location was irrelevant to the survival of the passenger.","43e06893":"We discovered main factors that increase the chance of survival:\n- `Sex` \n- `Age`\n- `Pclass`\n- `Fare`\n\nThis is important for our model because we want it to predict whether the passenger survived or not.","c34b465e":"<a id=\"data\"><\/a>\n## Importing data\nAs we know form competition decription we import two set of data:\n- train.csv wll be used to train model\n- test.csv will be used to quality of model and in the case of competition to crate submittion with our model predicted output","182f34ce":"X_train looks the same as X_test that's what we meant, now it's time for a model!","cc378c29":"<a id=\"one-hot\"><\/a>\n#### One-hot encoding \nIf you have never heard of this term read [this article ](https:\/\/towardsdatascience.com\/what-is-one-hot-encoding-and-how-to-use-pandas-get-dummies-function-922eb9bd4970)\nIn short, the idea is to convert categorical variables into binary variables so that the model can handle them.","71ac3fea":"Let's see the age distribution of passengers divided into survivors and non-survivors. We create an additional Data Frame with deleted observations containing missing data, we need to do this to improve the visualization. ","23861954":"<a id=\"Dataexploring\"><\/a>\n### Data exploring* \nWe start exploring the data by asking simple questions, then we will discover factors affecting chance of survivle.\n\n**In this section, we only analyze the training set*","37dda42d":"We got a pretty good result. However, our goal was to learn more about the data analysis process and the data itself. \n\nI hope you found my notebook useful and if you have any comments please write.","b1ca83ea":"<a id=\"Factors\"><\/a>\n### Factors affecting chances of survival\n*What factors increased the passenger's chance of survival?*","dabd76f8":"Mission accomplished. Let's move on to the second column `Cabin`","2a60b959":"#### Where did the passengers embark?","382498d8":"Important factor increasing chance of survival was female **gender**. Observing the age distribution, we notice that a large group of young people did not survive, now we know that they were men aged 18-50 and that they were a large group of passengers. It was normal practice to start evacuation from woman and children. That is the reason why more women survive this catastrophe.","92c5b063":"Let's see if it worked ","e874c484":"#### Test set preparation","d049f5ac":"#### Test set preparation","2f7bc348":"We have prepared the variables from the training set, we have a set of explanatory variables *X_train* and the dependent variable *y_train*. Now the same has to be done in the test set.","90413efc":"We can see quite a bit NA values in the `Age` column and very much in the `Cabin` column. Let's try to fix this.","ceeb30bd":"#### How old were the passengers? Which age group dominated?","2621af8c":"So we have:\n- binary target variable: `Survived`\n- quantitative: `Age`, `Fare`\n- categorical data: `Pclass`,`Sex`,`SibSp`,`Parch`,`Embarked`\n- unique passenger details (strings and int): `Name`, `Ticket`, `Cabin`,`PassengerId`\n\n*If you want to read more about types of variables read ['Understanding types of variables'](https:\/\/www.scribbr.com\/methodology\/types-of-variables\/)*","e227ea78":"#### How many passengers survived?","9e5f1a35":"So we have\n- binary target variable: `Survived`\n- quantitative: `Age`, `Fare`\n- categorical data: `Pclass`,`Sex`\n\nCategorical variables are not interpreted correctly by the model so we need a trick to fix this.","9c6fffb6":"## Table of content\n* [Importing libraries](#library)\n* [Importing data](#data)\n* [EDA](#EDA)\n    - [Data exploring](#Dataexploring)\n    - [Factors affecting chances of survival](#factors)\n* [Data preparation and cleaning](#Cleaning)\n    - [Missing values](#Na)\n    - [One-hot encoding](#one-hot)\n* [Logistic Regression model](#model)    "}}