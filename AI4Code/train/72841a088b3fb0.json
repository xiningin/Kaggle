{"cell_type":{"c28dd4d4":"code","d6484fba":"code","a18aaafb":"code","b0c5c7b0":"code","493f07bb":"code","2bf7d5a7":"code","52e06af1":"code","1e5b90ab":"code","93290dbd":"code","87738e4a":"code","a59ed150":"code","c401740d":"code","b8f0ff68":"code","394f8a03":"code","0cddb83e":"code","91b525ed":"code","a9c86d94":"code","20d23a18":"code","98ef38c0":"code","aa76b7ff":"code","cf278df3":"code","24e88917":"code","20075cc6":"code","7f7265ae":"markdown","58908026":"markdown","fac54857":"markdown","07d3acbc":"markdown","81790ee9":"markdown","bd1a553c":"markdown","520d1cd0":"markdown","5ef40557":"markdown","44ae2488":"markdown"},"source":{"c28dd4d4":"# Import pandas and numpy\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\n\n#Import scikit-learn metrics module for accuracy calculation\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import confusion_matrix,accuracy_score\nfrom sklearn.model_selection import train_test_split\nresults = []","d6484fba":"def death_ratio(y, predict_y):\n    tn, fp, fn, tp = confusion_matrix(y, predict_y).ravel()\n    return fn\/y.size\n\n\ndef plot_confusion_matrix(y, predict_y, name):\n    # Confusion Matrix\n    \n    confusion_matrix_ = confusion_matrix(y, predict_y)\n    \n\n    # Ploting heatmap of confusion matrix\n    # https:\/\/stackoverflow.com\/questions\/19233771\/sklearn-plot-confusion-matrix-with-labels\n    class_names = ['edible','poisonous']\n    confusion_matrix_ = pd.DataFrame(confusion_matrix_,index=class_names, columns=class_names)\n    heatmap = sns.heatmap(confusion_matrix_, annot=True, fmt='g')\n\n    plt.xlabel('Predicted Class',size=14)\n    plt.ylabel('Actual Class',size=14)\n    plt.title(f\"{name} Confusion Matrix\\n\",size=24)\n    plt.show()","a18aaafb":"df = pd.read_csv(\"\/kaggle\/input\/mushroom-classification\/mushrooms.csv\")\ndesc = df.describe()\n# sns.set(rc={'figure.figsize':(20,20)})\n# plot = sns.heatmap(df.isnull())\n# plt.show(plot)","b0c5c7b0":"desc","493f07bb":"sum(desc.loc['unique'])","2bf7d5a7":"msno.bar(df)","52e06af1":"df = df.apply(lambda col: pd.factorize(col, sort=True)[0]) ### poisonous -> 1; edible -> 0;\n\ny = df['class']\ndf_ = df.drop(['class', 'veil-type'], axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(df_, y, test_size=0.2)","1e5b90ab":"df.describe()\n","93290dbd":"from sklearn.preprocessing import OneHotEncoder\n\n# Create the encoder.\nencoder = OneHotEncoder(handle_unknown=\"ignore\")\nencoder.fit(X_train)    # Assume for simplicity all features are categorical.\n\n# Apply the encoder.\nX_train = encoder.transform(X_train)\nX_test = encoder.transform(X_test)","87738e4a":"# requires graphviz and python-graphviz conda packages\nimport graphviz\n\nxgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42, eval_metric=\"auc\")\n\nxgb_model.fit(X_train, y_train, early_stopping_rounds=10, eval_set=[(X_test, y_test)], verbose=False)\n\nxgb.plot_importance(xgb_model)\n\n# plot the output tree via matplotlib, specifying the ordinal number of the target tree\n# xgb.plot_tree(xgb_model, num_trees=xgb_model.best_iteration)\n\n# converts the target tree to a graphviz instance\nxgb.to_graphviz(xgb_model, num_trees=xgb_model.best_iteration)","a59ed150":"import xgboost as xgb\nimport time\nstart_time = time.time()\nclf = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\ntrain, test = X_train, X_test\n\nclf.fit(train, y_train)\n\ntest_predict_y = clf.predict(test)\ntrain_predict_y = clf.predict(train)\nelapsed_time = (time.time() - start_time)\nprint(\"--- %s seconds ---\" % elapsed_time)\nacc_test = accuracy_score(y_test, test_predict_y)\nacc_train = accuracy_score(y_train, train_predict_y)\nintoxication_ratio = death_ratio(y_train, train_predict_y)\nresults.append({'name': 'XGBoost', 'Accuracy (test)': acc_test, 'Accuracy (train)': acc_train, \n'intoxication':intoxication_ratio, 'Elapsed Time': elapsed_time})\nprint(\"Accuracy (test):\", acc_test)\nprint(\"Accuracy (train):\", acc_train)\nprint(\"Death ratio:\", intoxication_ratio)","c401740d":"import time\nstart_time = time.time()\n\nfrom sklearn.linear_model import LogisticRegression\n# Defining the LR model and performing the hyper parameter tuning using gridsearch\n#weights = np.linspace(0.05, 0.95, 20)\n%time\nparams = {'C' : [\n                10**-4,10**-3,10**-2,10**-1,1,10**1,10**2,10**3],\n          'penalty': ['l1', 'l2']#,'class_weight': [{0: x, 1: 1.0-x} for x in weights]\n         }\nclf = LogisticRegression(n_jobs= -1,random_state=42)\nclf.fit(X_train,y_train)\nmodel = GridSearchCV(estimator=clf,cv = 2,n_jobs= -1,param_grid=params,scoring='f1',verbose= 2,)\nmodel.fit(X_train,y_train)\nelapsed_time = (time.time() - start_time)\nprint(\"--- %s seconds ---\" % elapsed_time)\n\nprint(\"Best estimator is\", model.best_params_)","b8f0ff68":"import time\nstart_time = time.time()\n\n# model fitting using the best parameter.\n%time\nfrom sklearn.linear_model import LogisticRegression\nclf = LogisticRegression(n_jobs= -1,random_state=42,C= 10,penalty= 'l1')\ntrain, test = X_train, X_test\nclf.fit(train,y_train)\ntest_predict_y = clf.predict(test)\ntrain_predict_y = clf.predict(train)\nelapsed_time = (time.time() - start_time)\nprint(\"--- %s seconds ---\" % elapsed_time)\nacc_test = accuracy_score(y_test, test_predict_y)\nacc_train = accuracy_score(y_train, train_predict_y)\nintoxication_ratio = death_ratio(y_train, train_predict_y)\nresults.append({'name': 'Logistic Regression', 'Accuracy (test)': acc_test, 'Accuracy (train)': acc_train, \n'intoxication':intoxication_ratio, 'Elapsed Time': elapsed_time})\nprint(\"Accuracy (test):\", acc_test)\nprint(\"Accuracy (train):\", acc_train)\nprint(\"Death ratio:\", intoxication_ratio)","394f8a03":"plot_confusion_matrix(**{'name': \"Mushroom classification\",\n                       'y': y_train,\n                       'predict_y': train_predict_y,})","0cddb83e":"import time\nstart_time = time.time()\n\nfrom sklearn import preprocessing\nfrom sklearn.naive_bayes import BernoulliNB\n\n# Creating labelEncoder\nle = preprocessing.LabelEncoder()\nX_train\n# Encoding target data\ny_train = le.fit_transform(y_train)\ny_test = le.fit_transform(y_test)\n\n#Create a Gaussian Classifier\nmodel = BernoulliNB()\n\n# Train the model using the training sets\nmodel.fit(X_train, y_train)\n\n#Predict the response for test dataset\ntest_predict_y = model.predict(X_test)\ntrain_predict_y = model.predict(X_train)\n\nelapsed_time = (time.time() - start_time)\nprint(\"--- %s seconds ---\" % elapsed_time)\nacc_test = accuracy_score(y_test, test_predict_y)\nacc_train = accuracy_score(y_train, train_predict_y)\nintoxication_ratio = death_ratio(y_train, train_predict_y)\nresults.append({'name': 'Naive Bayes', 'Accuracy (test)': acc_test, 'Accuracy (train)': acc_train, \n'intoxication':intoxication_ratio, 'Elapsed Time': elapsed_time})\nprint(\"Accuracy (test):\", acc_test)\nprint(\"Accuracy (train):\", acc_train)\nprint(\"Death ratio:\", intoxication_ratio)","91b525ed":"import time\nstart_time = time.time()\n\n# Import MLP Classifier\n\nfrom sklearn.neural_network import MLPClassifier\n\n# TODO: Create a MLP Classifier \nmlp = MLPClassifier(hidden_layer_sizes=(21))\n\n#Train the model using the training sets \nmlp.fit(X_train, y_train)\n\n#Predict the response for test dataset\ntest_predict_y = mlp.predict(X_test)\ntrain_predict_y = mlp.predict(X_train)\n\n# Model Accuracy: how often is the classifier correct?\nelapsed_time = (time.time() - start_time)\nprint(\"--- %s seconds ---\" % elapsed_time)\nacc_test = accuracy_score(y_test, test_predict_y)\nacc_train = accuracy_score(y_train, train_predict_y)\nintoxication_ratio = death_ratio(y_train, train_predict_y)\nresults.append({'name': 'MLP (layers=1, n=21)', 'Accuracy (test)': acc_test, 'Accuracy (train)': acc_train, \n'intoxication':intoxication_ratio, 'Elapsed Time': elapsed_time})\nprint(\"Accuracy (test):\", acc_test)\nprint(\"Accuracy (train):\", acc_train)\nprint(\"Death ratio:\", intoxication_ratio)","a9c86d94":"# X_train.todense()[0].size","20d23a18":"import time\nstart_time = time.time()\n\n# Import MLP Classifier\n\nfrom sklearn.neural_network import MLPClassifier\n\n# TODO: Create a MLP Classifier \nmlp = MLPClassifier(hidden_layer_sizes=(1,))\n\n#Train the model using the training sets \nmlp.fit(X_train, y_train)\n\n#Predict the response for test dataset\ntest_predict_y = mlp.predict(X_test)\ntrain_predict_y = mlp.predict(X_train)\n\n# Model Accuracy: how often is the classifier correct?\nelapsed_time = (time.time() - start_time)\nprint(\"--- %s seconds ---\" % elapsed_time)\nacc_test = accuracy_score(y_test, test_predict_y)\nacc_train = accuracy_score(y_train, train_predict_y)\nintoxication_ratio = death_ratio(y_train, train_predict_y)\nresults.append({'name': 'MLP (layers=1, n=1)', 'Accuracy (test)': acc_test, 'Accuracy (train)': acc_train, \n'intoxication':intoxication_ratio, 'Elapsed Time': elapsed_time})\nprint(\"Accuracy (test):\", acc_test)\nprint(\"Accuracy (train):\", acc_train)\nprint(\"Death ratio:\", intoxication_ratio)","98ef38c0":"import time\nstart_time = time.time()\n\n# Import KNN Classifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Import LabelEncoder\nfrom sklearn import preprocessing\n\n# Creating labelEncoder\nle = preprocessing.LabelEncoder()\n\n# Encoding target data\ny_train = le.fit_transform(y_train)\ny_test = le.fit_transform(y_test)\n\n# Create a KNN Classifier\nmodel = KNeighborsClassifier(n_neighbors=3)\n\n#Train the model using the training sets \nmodel.fit(X_train, y_train)\n\n#Predict the response for test dataset\ntest_predict_y = model.predict(X_test)\ntrain_predict_y = model.predict(X_train)\n# Model Accuracy: how often is the classifier correct?\nelapsed_time = (time.time() - start_time)\nprint(\"--- %s seconds ---\" % elapsed_time)\nacc_test = accuracy_score(y_test, test_predict_y)\nacc_train = accuracy_score(y_train, train_predict_y)\nintoxication_ratio = death_ratio(y_train, train_predict_y)\nresults.append({'name': 'KNN', 'Accuracy (test)': acc_test, 'Accuracy (train)': acc_train, \n'intoxication':intoxication_ratio, 'Elapsed Time': elapsed_time})\nprint(\"Accuracy (test):\", acc_test)\nprint(\"Accuracy (train):\", acc_train)\nprint(\"Death ratio:\", intoxication_ratio)","aa76b7ff":"import time\nstart_time = time.time()\n\n# Import SVM model\nfrom sklearn import svm\n\n#Create a SVM Classifier\nclf = svm.SVC(kernel='poly', degree=10, gamma='auto')\n\n#Train the model using the training sets\nclf.fit(X_train, y_train)\n\n#Predict the response for test dataset\ntest_predict_y = clf.predict(X_test)\ntrain_predict_y = clf.predict(X_train)\n\n# Model Accuracy: how often is the classifier correct?\nelapsed_time = (time.time() - start_time)\nprint(\"--- %s seconds ---\" % elapsed_time)\nacc_test = accuracy_score(y_test, test_predict_y)\nacc_train = accuracy_score(y_train, train_predict_y)\nintoxication_ratio = death_ratio(y_train, train_predict_y)\nresults.append({'name': 'SVM', 'Accuracy (test)': acc_test, 'Accuracy (train)': acc_train, \n'intoxication':intoxication_ratio, 'Elapsed Time': elapsed_time})\nprint(\"Accuracy (test):\", acc_test)\nprint(\"Accuracy (train):\", acc_train)\nprint(\"Death ratio:\", intoxication_ratio)","cf278df3":"import time\nstart_time = time.time()\n\n# Import DecisionTreeClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Create Decision Tree classifer object\nclf = DecisionTreeClassifier()\n\n# Train Decision Tree Classifer\nclf = clf.fit(X_train, y_train)\n\n#Predict the response for test dataset\ntest_predict_y = clf.predict(X_test)\ntrain_predict_y = clf.predict(X_train)\n\n# Model Accuracy: how often is the classifier correct?\nelapsed_time = (time.time() - start_time)\nprint(\"--- %s seconds ---\" % elapsed_time)\nacc_test = accuracy_score(y_test, test_predict_y)\nacc_train = accuracy_score(y_train, train_predict_y)\nintoxication_ratio = death_ratio(y_train, train_predict_y)\nresults.append({'name': 'Decision tree', 'Accuracy (test)': acc_test, 'Accuracy (train)': acc_train, \n'intoxication':intoxication_ratio, 'Elapsed Time': elapsed_time})\nprint(\"Accuracy (test):\", acc_test)\nprint(\"Accuracy (train):\", acc_train)\nprint(\"Death ratio:\", intoxication_ratio)","24e88917":"import time\nstart_time = time.time()\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import make_classification\nclf = RandomForestClassifier(n_estimators=100, max_depth=2,\n                              random_state=0)\nclf.fit(X_train, y_train)  \n\nimportances = clf.feature_importances_\n\ntest_predict_y = clf.predict(X_test)\ntrain_predict_y = clf.predict(X_train)\n\nelapsed_time = (time.time() - start_time)\nprint(\"--- %s seconds ---\" % elapsed_time)\nacc_test = accuracy_score(y_test, test_predict_y)\nacc_train = accuracy_score(y_train, train_predict_y)\nintoxication_ratio = death_ratio(y_train, train_predict_y)\nresults.append({'name': 'Random forest', 'Accuracy (test)': acc_test, 'Accuracy (train)': acc_train, \n'intoxication':intoxication_ratio, 'Elapsed Time': elapsed_time})\nprint(\"Accuracy (test):\", acc_test)\nprint(\"Accuracy (train):\", acc_train)\nprint(\"Death ratio:\", intoxication_ratio)","20075cc6":"print(pd.DataFrame(results).to_latex(index=False))","7f7265ae":"# SVM (better without onehotencoding)","58908026":"# KNN Classifier","fac54857":"# Decision Tree","07d3acbc":"# XGBoost","81790ee9":"# Importance","bd1a553c":"# Multilayer perceptron (1 layer, n=21)","520d1cd0":"# Logistic Regression","5ef40557":"# Naive Bayes","44ae2488":"# Random forest"}}