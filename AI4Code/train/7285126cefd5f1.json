{"cell_type":{"8f161b04":"code","23c2e44a":"code","913d3770":"code","2bbb707e":"code","1e19d51c":"code","ded11841":"code","d3105f3e":"code","ee132a85":"code","c06c50c8":"code","b5151942":"code","30de3f41":"code","fb63af3d":"code","b61adf2a":"code","2e240e30":"code","e9cfeeae":"code","dcdf80de":"code","2e7de1fe":"code","26561c8c":"code","201874a4":"code","73dc4d5e":"code","3f4e69c4":"code","31832382":"code","b8b727e0":"code","97e75c6f":"code","42d248e5":"code","2e0ab529":"code","71def57e":"code","5afb6016":"code","189edfdc":"code","a617ec16":"code","c5dab725":"code","f568201f":"markdown","c0dbe7cf":"markdown","2ddacf00":"markdown","61f13b67":"markdown"},"source":{"8f161b04":"from torch.utils.data import Dataset, DataLoader","23c2e44a":"# !unzip ..\/input\/diabetic-retinopathy-detection\/sample.zip\n# !unzip ..\/input\/diabetic-retinopathy-detection\/sampleSubmission.csv.zip","913d3770":"# ! dir sample","2bbb707e":"# !unzip ..\/input\/diabetic-retinopathy-detection\/trainLabels.csv.zip","1e19d51c":"# from PIL import Image\n\n# img = Image.open(\".\/sample\/16_right.jpeg\")\n\n# import matplotlib.pyplot as plt\n\n# plt.imshow(img)","ded11841":"# import pandas as pd\n\n# pd.read_csv(\".\/trainLabels.csv\")","d3105f3e":"#!mv ..\/input\/diabetic-retinopathy-detection\/train.zip.001 .\/train1.zip","ee132a85":"# !unzip train1.zip\n\n# I guess we need to find something else altogether","c06c50c8":"pd.read_csv(\"..\/input\/diabetic-retinopathy-resized\/trainLabels.csv\")['level'].unique()\n\n# classes","b5151942":"import os\ncropped = pd.read_csv(\"..\/input\/diabetic-retinopathy-resized\/trainLabels_cropped.csv\")[:5000]","30de3f41":"cropped.iloc[0]","fb63af3d":"image_names = os.listdir(\"..\/input\/diabetic-retinopathy-resized\/resized_train_cropped\/resized_train_cropped\/\")\nimage_names.sort()\nimage_names[:5]","b61adf2a":"images_path = \"..\/input\/diabetic-retinopathy-resized\/resized_train_cropped\/resized_train_cropped\"\nimg_path = os.path.join(images_path, cropped.iloc[3500].image+\".jpeg\")\nimg_path","2e240e30":"img = Image.open(img_path)\n\nplt.imshow(img)\n\nimg.size","e9cfeeae":"import torchvision.transforms as transforms\nmy_transform = transforms.Compose([\n    transforms.Resize((299,299)),\n    transforms.ToTensor(),\n#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])","dcdf80de":"import torch\n\nclass retinaDataset(Dataset):\n    def __init__(self, imagepath=\"..\/input\/diabetic-retinopathy-resized\/resized_train_cropped\/resized_train_cropped\", total=None,transform=my_transform):\n        self.df = pd.read_csv(\"..\/input\/diabetic-retinopathy-resized\/trainLabels_cropped.csv\")\n        \n        if (total is not None):\n            self.df = self.df[:total]\n        \n        self.transform = transform\n        \n        self.imagepath = imagepath\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        img_path = os.path.join(self.imagepath, self.df.iloc[index].image +\".jpeg\")\n        img = Image.open(img_path)\n        \n        if(self.transform):\n            img = self.transform(img)\n        \n        return img, torch.tensor(self.df.iloc[index].level)\n","2e7de1fe":"train_dataset = retinaDataset(total=5000)","26561c8c":"img, label = train_dataset[0]\n\nplt.imshow(img.permute(1,2,0))\nimg.shape, label, train_dataset.__len__()","201874a4":"num_classes = 5\nlearning_rate = 1e-4\nnum_epochs = 1\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","73dc4d5e":"from torchvision.models import inception_v3\n\nmodel = inception_v3(pretrained=True)\n\nfor param in model.parameters():\n    param.requires_grad = False\n    \nmodel.fc","3f4e69c4":"model.fc = torch.nn.Linear(in_features=2048, out_features=5, bias=True)","31832382":"model.aux_logits = False","b8b727e0":"model = model.to(device=device)","97e75c6f":"model","42d248e5":"optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\nloss_criterion = torch.nn.CrossEntropyLoss()","2e0ab529":"batch_size = 32","71def57e":"train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)","5afb6016":"from tqdm import tqdm\n\nfor epoch in range(num_epochs):\n    for data, target in tqdm(train_dataloader):\n        data = data.to(device=device)\n        target = target.to(device=device)\n        \n        score = model(data)\n        optimizer.zero_grad()\n        \n        loss = loss_criterion(score, target)\n        loss.backward()\n        \n        optimizer.step()\n    \n    print(f\"for epoch {epoch}, loss : {loss}\")\n    ","189edfdc":"def check_accuracy(model, loader):\n    model.eval()\n    \n    correct_output = 0\n    total_output = 0\n    \n    with torch.no_grad():\n        for x, y in tqdm(loader):\n            x = x.to(device=device)\n            y = y.to(device=device)\n            \n            score = model(x)\n            _,predictions = score.max(1)\n            \n            correct_output += (y==predictions).sum()\n            total_output += predictions.shape[0]\n    model.train()\n    print(f\"out of {total_output} , total correct: {correct_output} with an accuracy of {float(correct_output\/total_output)*100}\")","a617ec16":"check_accuracy(model, train_dataloader)","c5dab725":"image = Image.open(\"..\/input\/diabetic-retinopathy-resized\/resized_train_cropped\/resized_train_cropped\/10007_right.jpeg\")\n\nimg = my_transform(image).unsqueeze(0)\n\nscore = model(img)\n\n_, predictions = score.max(1)\n\nplt.imshow(image)\n\nprint(\"predicted: \", predictions)\n\ndf = pd.read_csv(\"..\/input\/diabetic-retinopathy-resized\/trainLabels_cropped.csv\")\n\n# print(df[image][:5])\n# print(df.loc[df[image]==\"10_left\"].level)\nprint(\"actual: \", df.loc[df['image'].isin(['10007_right'])].level)\n","f568201f":"Lets work with sample data.","c0dbe7cf":"# New dataset , diabetic-retinopathy-resized","2ddacf00":"Lets get the first train file","61f13b67":"But there are no labels!"}}