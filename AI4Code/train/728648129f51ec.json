{"cell_type":{"1e9f3f50":"code","332ebdd6":"code","fda8a233":"code","edcf1e5e":"code","ddb44019":"code","5b1aa39b":"code","93ad93b4":"code","9d955ae0":"code","1331967a":"code","7b4048b9":"markdown","7a952066":"markdown","e6ffc2be":"markdown","707a80eb":"markdown","43a6e3ae":"markdown","f7eb60be":"markdown"},"source":{"1e9f3f50":"# TensorFlow Libraries\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\n# For downloading the image.\nimport matplotlib.pyplot as plt\nimport tempfile\nfrom six.moves.urllib.request import urlopen\nfrom six import BytesIO\n\n# For drawing onto the image.\nimport numpy as np\nfrom PIL import Image\nfrom PIL import ImageColor\nfrom PIL import ImageDraw\nfrom PIL import ImageFont\nfrom PIL import ImageOps\n\n# For measuring the inference time.\nimport time\n\n# Generic\nimport os\nimport random","332ebdd6":"# Random Images Directory Path\nrandom_images = '..\/input\/object-detection-sample-images\/'","fda8a233":"# Function to Display Image\ndef display_image(image,file):\n    fig = plt.figure(figsize=(15, 10))\n    plt.grid(False)\n    plt.imshow(image)\n    plt.title(file, fontsize=20)\n\n    \n# Function to Resize Image\ndef resize_image(img, new_width=300, new_height=300,display=False):\n    img_path = os.path.join(random_images,img)\n    pil_image = Image.open(img_path)\n    pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n    pil_image_rgb = pil_image.convert(\"RGB\")\n    if display:\n        display_image(pil_image, img)","edcf1e5e":"# Applying the Function \nresize_image(random.choice(os.listdir(random_images)),600,400,True)","ddb44019":"# Function to Draw Bounding Boxes on Image\ndef draw_bounding_box_on_image(image,ymin,xmin,ymax,xmax,color,font,thickness=4,display_str_list=()):\n       \n    # Adds a bounding box to an image.\n    draw = ImageDraw.Draw(image)\n    im_width, im_height = image.size\n    (left, right, top, bottom) = (xmin * im_width, xmax * im_width,ymin * im_height, ymax * im_height)\n    draw.line([(left, top), (left, bottom), (right, bottom), (right, top),(left, top)],width=thickness,fill=color)\n    \n    # If the total height of the display strings added to the top of the bounding\n    # box exceeds the top of the image, stack the strings below the bounding box\n    # instead of above.\n    display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n    \n    # Each display_str has a top and bottom margin of 0.05x.\n    total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n    \n    if top > total_display_str_height:\n        text_bottom = top\n    else:\n        text_bottom = top + total_display_str_height\n        \n    # Reverse list and print from bottom to top.\n    for display_str in display_str_list[::-1]:\n        text_width, text_height = font.getsize(display_str)\n        margin = np.ceil(0.05 * text_height)\n        draw.rectangle([(left, text_bottom - text_height - 2 * margin),(left + text_width, text_bottom)],fill=color)\n        draw.text((left + margin, text_bottom - text_height - margin),display_str, fill=\"black\", font=font)\n        text_bottom -= text_height - 2 * margin\n        \n\n# Function to Draw Boxes       \ndef draw_boxes(image, boxes, class_names, scores, max_boxes=3, min_score=0.1):\n    \n    # Overlay labeled boxes on an image with formatted scores and label names.\n    colors = list(ImageColor.colormap.values())\n    font = ImageFont.load_default()\n    \n    for i in range(min(boxes.shape[0], max_boxes)):\n        if scores[i] >= min_score:\n            ymin, xmin, ymax, xmax = tuple(boxes[i])\n            display_str = \"{}: {}%\".format(class_names[i].decode(\"ascii\"),int(100 * scores[i]))\n            color = colors[hash(class_names[i]) % len(colors)]\n            image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n            \n            draw_bounding_box_on_image(image_pil,ymin,xmin,ymax,xmax,color,font,display_str_list=[display_str])\n            np.copyto(image, np.array(image_pil))\n    return image","5b1aa39b":"# FasterRCNN + InceptionResNet v2 Path\nmodel_path = \"https:\/\/tfhub.dev\/google\/faster_rcnn\/openimages_v4\/inception_resnet_v2\/1\"\n\n# Define Model\nPreTrained_Model = hub.load(model_path).signatures['default']","93ad93b4":"# Function to Load Image from Random Image Folder using TensorFlow\ndef load_img(img_file):\n    path = os.path.join(random_images,img_file)\n    img = tf.io.read_file(path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    return img","9d955ae0":"# Function to Detect Object using TensorFlow's Pretrained Model\ndef detect(model, img_file):\n    \n    img = load_img(img_file)\n    \n    converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n    \n    start_time = time.time()   # Start Timer\n    \n    result = model(converted_img)   # Detection Using Pretrained Model downloaded above\n    \n    end_time = time.time()    # End Timer\n    \n    result = {key:value.numpy() for key,value in result.items()}\n    \n    print(\"Found %d objects.\" % len(result[\"detection_scores\"]))\n    print(\"Inference time (secs): \",'{:.2}'.format(end_time-start_time))\n    \n    image_with_boxes = draw_boxes(img.numpy(), result[\"detection_boxes\"],result[\"detection_class_entities\"], result[\"detection_scores\"])\n    \n    display_image(image_with_boxes,img_file)\n    ","1331967a":"# Running the Detect Function\ndetect(PreTrained_Model, random.choice(os.listdir(random_images)))","7b4048b9":"# Object Detection with Pretrained TensorFlow Model - Tutorial\n\nIn this notebook, we'll learn about using a Pretrained Model from TensorFlow's Model Zoo to perform an Object Detection on a random Image. I have kept this notebook fairly organized and well-commented for easy reading. This notebook is specifically designed as a starter-code so that anyone who is interested in using Pretrained Model for Object Detection can simply fork it and start using it. \n\nI hope this notebook is helpful & if it is then please do consider it to UPVOTE :-).","7a952066":"## Libraries","e6ffc2be":"## Utility Functions - Bounding Boxes","707a80eb":"## Pretrained Models\n\nTensorFlow's Model Zoo has a couple of pretrained Models for Object Detection that are trained on COCO, KITTI & Open Images dataset. These Models can be used for inference if we're interested in categories from these datasets.\n\nHowever, these pretrained Models are also useful for training on new datasets. The various architectures used in the pretrained model are described below:\n\n* FasterRCNN + InceptionResNet v2 - Trained on Open Images dataset. It is slow but has high accuracy\n* SSD + Mobilenet v2 - Trained on COCO dataset. It is small and quick\n\nFor this tutorial we shall be using using **FasterRCNN + InceptionResNet v2**","43a6e3ae":"## Utility Functions - Display Image","f7eb60be":"## Utility Functions - Object Detection"}}