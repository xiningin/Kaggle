{"cell_type":{"63c6f891":"code","16db96c6":"code","78f424c3":"code","99b6d467":"code","2afbab86":"code","11b66865":"code","18e7d857":"code","5441b8ca":"code","65b6690d":"code","7a4d6f77":"code","8bfdc705":"code","a64fc9af":"code","2e432842":"code","6c27d6e2":"code","b3170bc6":"code","83fe58d9":"code","9a6d53e2":"code","10d75f4f":"code","364cf8f4":"code","092aa728":"code","7e3064d8":"code","917d130b":"code","d98875d2":"markdown","bf5a1c23":"markdown","1aa9ddb4":"markdown","3829f79f":"markdown","27f64cb0":"markdown","cb822942":"markdown","d98bd0d5":"markdown","8cc66ba5":"markdown","01b240b6":"markdown","2428ebd5":"markdown","6ef66cef":"markdown"},"source":{"63c6f891":"#for efficientnet\nBATCH_SIZE = 1\nimage_size = 512\nenet_type = ['tf_efficientnet_b4_ns'] * 5\nmodel_path = ['..\/input\/moa-b4-baseline\/baseline_cld_fold0_epoch8_tf_efficientnet_b4_ns_512.pth',\n              '..\/input\/moa-b4-baseline\/baseline_cld_fold1_epoch9_tf_efficientnet_b4_ns_512.pth', \n              '..\/input\/moa-b4-baseline\/baseline_cld_fold2_epoch9_tf_efficientnet_b4_ns_512.pth',\n              '..\/input\/moa-b4-baseline\/baseline_cld_fold3_epoch5_tf_efficientnet_b4_ns_512.pth',\n              '..\/input\/moa-b4-baseline\/baseline_cld_fold4_epoch11_tf_efficientnet_b4_ns_512.pth']","16db96c6":"# ====================================================\n# Library\n# ====================================================\nimport sys\nsys.path.append('..\/input\/pytorch-image-models\/pytorch-image-models-master')\n\nimport os\nimport math\nimport time\nimport random\nimport shutil\nimport albumentations\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\n\nimport scipy as sp\nfrom scipy.special import softmax\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport cv2\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport timm\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","78f424c3":"#Transform for efficientnet\ntransforms_valid = albumentations.Compose([\n    albumentations.CenterCrop(image_size, image_size, p=1),\n    albumentations.Resize(image_size, image_size),\n    albumentations.Normalize()\n])","99b6d467":"# ====================================================\n# Directory settings for Resnext\n# ====================================================\nimport os\n\nOUTPUT_DIR = '.\/'\n#MODEL_DIR = '..\/input\/cassava-resnext50-32x4d-starter-training\/'\nMODEL_DIR = '..\/input\/cassava-resnext50-32x4d-weights\/'\nMODEL_DIR2 = '..\/input\/resnext50-cassava-384size\/'\n\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n    \nTRAIN_PATH = '..\/input\/cassava-leaf-disease-classification\/train_images'\nTEST_PATH = '..\/input\/cassava-leaf-disease-classification\/test_images'","2afbab86":"# ====================================================\n# CFG for Resnext\n# ====================================================\nclass CFG:\n    debug=False\n    num_workers=8\n    model_name='resnext50_32x4d'\n    size=512\n    batch_size=32\n    seed=2020\n    target_size=5\n    target_col='label'\n    n_fold=5\n    trn_fold=[0, 1, 2, 3, 4]\n    inference=True","11b66865":"class CFG2:\n    debug=False\n    num_workers=8\n    model_name='resnext50_32x4d'\n    size=384\n    batch_size=32\n    seed=2020\n    target_size=5\n    target_col='label'\n    n_fold=5\n    trn_fold=[0, 1, 2, 3, 4]\n    inference=True","18e7d857":"# ====================================================\n# Utils for Resnext\n# ====================================================\ndef get_score(y_true, y_pred):\n    return accuracy_score(y_true, y_pred)\n\n\n@contextmanager\ndef timer(name):\n    t0 = time.time()\n    LOGGER.info(f'[{name}] start')\n    yield\n    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n\n\ndef init_logger(log_file=OUTPUT_DIR+'inference.log'):\n    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\n#LOGGER = init_logger()\n\ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=CFG.seed)","5441b8ca":"test = pd.read_csv('..\/input\/cassava-leaf-disease-classification\/sample_submission.csv')\ntest['filepath'] = test.image_id.apply(lambda x: os.path.join('..\/input\/cassava-leaf-disease-classification\/test_images', f'{x}'))\n#test.head()","65b6690d":"# ====================================================\n# Dataset for Resnext\n# ====================================================\nclass TestDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df['image_id'].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_name = self.file_names[idx]\n        file_path = f'{TEST_PATH}\/{file_name}'\n        image = cv2.imread(file_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        return image","7a4d6f77":"# ====================================================\n# Dataset for efficientnet\n# ====================================================\nclass CLDDataset(Dataset):\n    def __init__(self, df, mode, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.mode = mode\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        row = self.df.loc[index]\n        image = cv2.imread(row.filepath)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.transform is not None:\n            res = self.transform(image=image)\n            image = res['image']\n        \n        image = image.astype(np.float32)\n        image = image.transpose(2,0,1)\n        if self.mode == 'test':\n            return torch.tensor(image).float()\n        else:\n            return torch.tensor(image).float(), torch.tensor(row.label).float()\n\n#test = pd.read_csv('..\/input\/cassava-leaf-disease-classification\/sample_submission.csv')\n#test_dataset = CLDDataset(test, 'test', transform=transforms_valid)\n#test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False,  num_workers=4)","8bfdc705":"#for efficientnet\ntest_dataset_efficient = CLDDataset(test, 'test', transform=transforms_valid)\ntest_loader_efficient = torch.utils.data.DataLoader(test_dataset_efficient, batch_size=BATCH_SIZE, shuffle=False,  num_workers=4)","a64fc9af":"# ====================================================\n# Transforms for Resnext 512\n# ====================================================\ndef get_transforms(*, data):\n    if data == 'valid':\n        return A.Compose([\n            A.Resize(CFG.size, CFG.size),\n            A.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])\n    \n# ====================================================\n# Transforms for Resnext 384\n# ====================================================\ndef get_transforms2(*, data):\n    if data == 'valid':\n        return A.Compose([\n            A.Resize(CFG2.size, CFG2.size),\n            A.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])","2e432842":"# ====================================================\n# ResNext Model\n# ====================================================\nclass CustomResNext(nn.Module):\n    def __init__(self, model_name='resnext50_32x4d', pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        n_features = self.model.fc.in_features\n        self.model.fc = nn.Linear(n_features, CFG.target_size)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x","6c27d6e2":"# ====================================================\n# EfficientNet Model\n# ====================================================\nclass enet_v2(nn.Module):\n\n    def __init__(self, backbone, out_dim, pretrained=False):\n        super(enet_v2, self).__init__()\n        self.enet = timm.create_model(backbone, pretrained=pretrained)\n        in_ch = self.enet.classifier.in_features\n        self.myfc = nn.Linear(in_ch, out_dim)\n        self.enet.classifier = nn.Identity()\n\n    def forward(self, x):\n        x = self.enet(x)\n        x = self.myfc(x)\n        return x","b3170bc6":"# ====================================================\n# Helper functions for Resnext\n# ====================================================\ndef load_state(model_path):\n    model = CustomResNext(CFG.model_name, pretrained=False)\n    try:  # single GPU model_file\n        model.load_state_dict(torch.load(model_path)['model'], strict=True)\n        state_dict = torch.load(model_path)['model']\n    except:  # multi GPU model_file\n        state_dict = torch.load(model_path)['model']\n        state_dict = {k[7:] if k.startswith('module.') else k: state_dict[k] for k in state_dict.keys()}\n\n    return state_dict\n\n\ndef inference(model, states, test_loader, device):\n    model.to(device)\n    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n    probs = []\n    for i, (images) in tk0:\n        images = images.to(device)\n        avg_preds = []\n        for state in states:\n            model.load_state_dict(state)\n            model.eval()\n            with torch.no_grad():\n                y_preds = model(images)\n            avg_preds.append(y_preds.softmax(1).to('cpu').numpy())\n        avg_preds = np.mean(avg_preds, axis=0)\n        probs.append(avg_preds)\n    probs = np.concatenate(probs)\n    return probs","83fe58d9":"# ====================================================\n# Helper functions for efficientnet\n# ====================================================\ndef inference_func(test_loader):\n    model.eval()\n    bar = tqdm(test_loader)\n\n    LOGITS = []\n    PREDS = []\n    \n    with torch.no_grad():\n        for batch_idx, images in enumerate(bar):\n            x = images.to(device)\n            logits = model(x)\n            LOGITS.append(logits.cpu())\n            PREDS += [torch.softmax(logits, 1).detach().cpu()]\n        PREDS = torch.cat(PREDS).cpu().numpy()\n        LOGITS = torch.cat(LOGITS).cpu().numpy()\n    return PREDS\n\ndef tta_inference_func(test_loader):\n    model.eval()\n    bar = tqdm(test_loader)\n    PREDS = []\n    LOGITS = []\n\n    with torch.no_grad():\n        for batch_idx, images in enumerate(bar):\n            x = images.to(device)\n            x = torch.stack([x,x.flip(-1),x.flip(-2),x.flip(-1,-2),\n            x.transpose(-1,-2),x.transpose(-1,-2).flip(-1),\n            x.transpose(-1,-2).flip(-2),x.transpose(-1,-2).flip(-1,-2)],0)\n            x = x.view(-1, 3, image_size, image_size)\n            logits = model(x)\n            logits = logits.view(BATCH_SIZE, 8, -1).mean(1)\n            PREDS += [torch.softmax(logits, 1).detach().cpu()]\n            LOGITS.append(logits.cpu())\n\n        PREDS = torch.cat(PREDS).cpu().numpy()\n        \n    return PREDS","9a6d53e2":"# ====================================================\n# inference\n# ====================================================\n\n#for Resnext 512\nmodel = CustomResNext(CFG.model_name, pretrained=False)\n#model = enet_v2(enet_type[i], out_dim=5)\n#states = [load_state(MODEL_DIR+f'{CFG.model_name}_fold{fold}_best.pth') for fold in CFG.trn_fold]\nstates = [load_state(MODEL_DIR+f'{CFG.model_name}_fold{fold}.pth') for fold in CFG.trn_fold]\n\ntest_dataset = TestDataset(test, transform=get_transforms(data='valid'))\ntest_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                         num_workers=CFG.num_workers, pin_memory=True)\npredictions = inference(model, states, test_loader, device)\n\n#for Efficientnet\ntest_preds = []\nfor i in range(len(enet_type)):\n    model = enet_v2(enet_type[i], out_dim=5)\n    model = model.to(device)\n    model.load_state_dict(torch.load(model_path[i]))\n    test_preds += [tta_inference_func(test_loader_efficient)]","10d75f4f":"#for Resnext 384\nmodel = CustomResNext(CFG2.model_name, pretrained=False)\n#model = enet_v2(enet_type[i], out_dim=5)\n#states = [load_state(MODEL_DIR2+f'{CFG2.model_name}_fold{fold}_best.pth') for fold in CFG2.trn_fold]\nstates = [load_state(MODEL_DIR2+f'{CFG2.model_name}_fold{fold}_best.pth') for fold in CFG2.trn_fold]\n\ntest_dataset2 = TestDataset(test, transform=get_transforms2(data='valid'))\ntest_loader2 = DataLoader(test_dataset2, batch_size=CFG2.batch_size, shuffle=False, \n                         num_workers=CFG2.num_workers, pin_memory=True)\npredictions2 = inference(model, states, test_loader2, device)","364cf8f4":"# resnext 512\npredictions","092aa728":"# resnext 384\npredictions2","7e3064d8":"# efficientNet_b4\ntest_preds","917d130b":"# submission\n# resnext 512 + efficient_b4 + resnext 384\npred = 0.35*predictions + 0.35*np.mean(test_preds, axis=0) + 0.3*predictions2\n# pred = np.mean(test_preds, axis=0)\n\ntest['label'] = softmax(pred).argmax(1)\ntest[['image_id', 'label']].to_csv(OUTPUT_DIR+'submission.csv', index=False)\ntest.head()","d98875d2":"# Utils","bf5a1c23":"# Dataset","1aa9ddb4":"# Directory settings","3829f79f":"# CFG","27f64cb0":"# inference and Submit","cb822942":"# Data Loading","d98bd0d5":"# MODELS","8cc66ba5":"# Helper functions","01b240b6":"# About\n* In this notebook, we try to improve the score by ensemble.\n* I made datasets private.\n\n# Source Kernels\n* This notebook was written by refering these great kernels below, so please don't forget to check and upvote them.\n* [[No TTA] Cassava Resnext50_32x4d Inference lb0.903](https:\/\/www.kaggle.com\/piantic\/no-tta-cassava-resnext50-32x4d-inference-lb0-903\/output)\n* [Clean_Inference_Kernel_8xTTA_LB902](https:\/\/www.kaggle.com\/underwearfitting\/clean-inference-kernel-8xtta-lb902\/data)\n* [Cassava-ensemble-(efnetb3-resnet50)](https:\/\/www.kaggle.com\/shubham108\/cassava-ensemble-efnetb3-resnet50)","2428ebd5":"### 2model\n- 0.48 * resnext512 + 0.52 * efficientNet = 0.902\n- 0.5 * resnext512 + 0.5 * efficientNet = 0.903\n- 0.52 * resnext512 + 0.48 * efficientNet = 0.902\n- 0.51 * resnext512 + 0.49 * efficientNet = 0.902\n\n#############\n\n- 0.5 * resnext384 + 0.5 * efficientNet = 0.900","6ef66cef":"### 3model\n- 0.35 * resnext512 + 0.3 * efficientNet + 0.35 * resnext384 = 0.900\n- 0.4 * resnext512 + 0.2 * efficientNet + 0.4 * resnext384 = 0.899\n- 0.4 * resnext512 + 0.4 * efficientNet + 0.2 * resnext384 = 0.900\n- 0.2 * resnext512 + 0.4 * efficientNet + 0.4 * resnext384 = 0.899\n- 0.33 * resnext512 + 0.34 * efficientNet + 0.33 * resnext384 = 0.899\n- 0.45 * resnext512 + 0.45 * efficientNet + 0.1 * resnext384 = 0.901"}}