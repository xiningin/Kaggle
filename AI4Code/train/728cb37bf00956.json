{"cell_type":{"8ffdf3cc":"code","0cd01364":"code","fb495ab6":"code","6ff518c6":"code","33ad6aa9":"code","146dffff":"code","032c5371":"code","2df928c8":"code","99ed98e8":"code","b2dd1bac":"code","399b9f6c":"code","92807bd6":"code","023cc459":"code","bb67d4c7":"code","64f32db9":"code","0686486c":"code","a5d77e48":"code","955773ad":"code","3a96cbce":"code","2f680bbe":"code","21afdcf5":"code","1457457e":"code","9ecc3df5":"code","01beb3eb":"code","61ff7ff0":"code","238138ba":"code","2e19fc3a":"code","2c17f622":"code","dec0f026":"code","9a297706":"markdown","5d05103f":"markdown","826f567b":"markdown","a1829b37":"markdown","b3ce4f5d":"markdown","325f3492":"markdown","4d03e9a8":"markdown","4bbfd712":"markdown","e7eaf173":"markdown"},"source":{"8ffdf3cc":"import pandas as pd\nimport io\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n!pip install lightgbm\nfrom scipy import stats\nimport scipy.stats as ss\nfrom lightgbm import LGBMRegressor,LGBMClassifier\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings(\"ignore\")","0cd01364":"data = pd.read_csv(\"..\/input\/wine-reviews\/winemag-data_first150k.csv\")","fb495ab6":"data.head()","6ff518c6":"data.info()","33ad6aa9":"data.hist();","146dffff":"sns.scatterplot(x=\"price\",y=\"region_2\",data=data);","032c5371":"sns.kdeplot(data.price,shade=True);","2df928c8":"sns.barplot(x=\"points\",y=\"price\",data=data);","99ed98e8":"sparse_columns=[]\nfor col in [\"points\",\"price\"]:\n  if (data[col].mode()[0]==data[col].quantile(0.01)==data[col].quantile(0.25) or (data[col].mode()[0]==data[col].quantile(0.99)==data[col].quantile(0.75))):\n    sparse_columns.append(col)\nsparse_columns","b2dd1bac":"def boxplot_for_outlier(df,columns):\n  for col in columns:\n    fig, ax =plt.subplots(figsize=(7,5))\n    sns.boxplot(x = df[col], palette=\"Set2\")\nboxplot_for_outlier(data,[\"points\",\"price\"])","399b9f6c":"def outliers_detection(df,columns):\n  for col in columns:\n    q1=df[col].describe()[4]\n    q3=df[col].describe()[6]\n    iqr=q3-q1\n    lowerbound = q1 - (1.5 * iqr)\n    upperbound = q3 + (1.5 * iqr)\n    number_of_outlier = df.loc[(df.loc[:,col]<lowerbound)| (df.loc[:,col]>upperbound)].shape[0]\n    if(number_of_outlier>0):\n      print(number_of_outlier,\" outlier values cleared in\" ,col)\n      df.loc[(df.loc[:,col]<lowerbound),col] =  lowerbound*0.75\n      df.loc[(df.loc[:,col]>upperbound),col] =  upperbound*1.25","92807bd6":"data_outliers=data.copy()\noutliers_detection(data_outliers,[\"points\",\"price\"])","023cc459":"boxplot_for_outlier(data_outliers,[\"points\",\"price\"])","bb67d4c7":"def Missing_Values(data):\n    variable_name=[]\n    total_value=[]\n    total_missing_value=[]\n    missing_value_rate=[]\n    unique_value_list=[]\n    total_unique_value=[]\n    data_type=[]\n    for col in data.columns:\n        variable_name.append(col)\n        data_type.append(data[col].dtype)\n        total_value.append(data[col].shape[0])\n        total_missing_value.append(data[col].isnull().sum())\n        missing_value_rate.append(round(data[col].isnull().sum()\/data[col].shape[0],5))\n        unique_value_list.append(data[col].unique())\n        total_unique_value.append(len(data[col].unique()))\n    missing_data=pd.DataFrame({\"Variable\":variable_name,\"Total_Value\":total_value,\\\n                             \"Total_Missing_Value\":total_missing_value,\"Missing_Value_Rate\":missing_value_rate,\n                             \"Data_Type\":data_type,\"Unique_Value\":unique_value_list,\\\n                               \"Total_Unique_Value\":total_unique_value})\n    \n    return missing_data.sort_values(\"Missing_Value_Rate\",ascending=False)","64f32db9":"data_info=Missing_Values(data_outliers)\ndata_info = data_info.set_index(\"Variable\")\ndata_info","0686486c":"categorical_columns=data_info[data_info[\"Data_Type\"]==\"object\"].index\nnumerical_columns=data_info[(data_info[\"Data_Type\"]==\"float64\") | (data_info[\"Data_Type\"]==\"int64\")].index\nlen(categorical_columns),len(numerical_columns)","a5d77e48":"import missingno as msno\nmsno.bar(data);","955773ad":"msno.matrix(data);","3a96cbce":"msno.heatmap(data);","2f680bbe":"def simple_imputer(df,columns):\n  for col in columns:\n    total_nan=int(df[col].isnull().sum())\n    if(col in categorical_columns):\n  \n      most_frequent_value=str(stats.mode(df[col])[0][0])\n\n      df[col]=df[col].fillna(most_frequent_value)\n      print(\"Total imputed in {} : {} \".format(col,total_nan))\n    else:\n      \n      mean=df[col].mean()\n      std=df[col].std()\n      random_normal=np.random.normal(loc=mean,scale=std,size=total_nan) \n      df[col][df[col].isnull()]=random_normal\n      print(\"Total imputed in {} : {} \".format(col,total_nan))\n  return df","21afdcf5":"data_simple_imp=data_outliers.copy()\ncolumns=list(data_info[(data_info[\"Missing_Value_Rate\"]>0 )& (data_info[\"Missing_Value_Rate\"]<0.1 ) ].index)\ncolumns.append(\"designation\")\ndata_simpe_imp=simple_imputer(data_simple_imp,columns)","1457457e":"Missing_Values(data_simple_imp)","9ecc3df5":"from sklearn_pandas import CategoricalImputer\nlst=list(data_info[(data_info[\"Missing_Value_Rate\"]>0.1 )].index)\nlst.remove(\"designation\")\ndata_c_imputer=data_simple_imp.copy()\nfor col in lst:\n\n  imputer = CategoricalImputer()\n  data_c_imputer[col]=imputer.fit_transform(data_c_imputer[col])","01beb3eb":"Missing_Values(data_c_imputer)","61ff7ff0":"\"\"\"lgbm_imputer = LGBMClassifier()\nlst=list(data_info[(data_info[\"Missing_Value_Rate\"]>0.1 )].index)\nlst.remove(\"designation\")\ndf_mbi = data_simpe_imp.copy()\n\nimport re\ndf_mbi = df_mbi.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n\nfor c in df_mbi.columns:\n    col_type= df_mbi[c].dtype\n    if col_type == \"object\" or col_type.name==\"category\":\n        df_mbi[c] = df_mbi[c].astype(\"category\")\n\nfor col in lst:\n    y_col_nan_train = df_mbi.loc[df_mbi.loc[:,col].isnull(),col]\n    y_col_train = df_mbi.loc[df_mbi.loc[:,col].notnull(),col]  \n    X_col_nan_train = df_mbi.drop(columns=col,axis=1).loc[y_col_nan_train.index,:]\n    X_col_train = df_mbi.drop(columns=col,axis=1).loc[y_col_train.index,:]\n    print(col)\n    lgbm_imputer.fit(X_col_train,y_col_train)\n    y_col_pred_train = lgbm_imputer.predict(X_col_nan_train)\n\n    df_mbi.loc[y_col_nan_train.index,col] = y_col_pred_train\n\n\n    print(col,\" null sayisi:\",df_mbi[col].isnull().sum())\"\"\"\n","238138ba":"#from scipy import stats\n#import scipy.stats as ss","2e19fc3a":"\"\"\"def cramers_v(columns,df):\n    chi2_df=pd.DataFrame(columns=columns)\n    for col in columns:\n        lst=[]\n        print(col)\n        for col2 in columns:\n\n            confusion_matrix = pd.crosstab(df[col],df[col2])\n            chi2 = ss.chi2_contingency(confusion_matrix)[0]\n            n = confusion_matrix.sum().sum()\n            phi2 = chi2\/n\n            r,k = confusion_matrix.shape\n            phi2corr = max(0, phi2-((k-1)*(r-1))\/(n-1))\n            rcorr = r-((r-1)**2)\/(n-1)\n            kcorr = k-((k-1)**2)\/(n-1)\n            lst.append(np.sqrt(phi2corr\/min((kcorr-1),(rcorr-1))))\n\n        chi2_df.loc[col]=lst\n    return chi2_df\ncategorical_columns=list(data.select_dtypes(include=['object']).columns)\ncategorical_columns.remove(\"description\")\ncategorical_columns.remove(\"title\")\nchi2_rate =cramers_v(categorical_columns.copy(),data.copy())\"\"\"","2c17f622":"#Missing_Values(data)","dec0f026":"#f, ax = plt.subplots(figsize=(20, 30))\n#sns.heatmap(chi2_rate, annot=True,fmt=\".1f\")\n#plt.show()","9a297706":"# Missing Values Detection","5d05103f":"# Visualization","826f567b":"# Visualization Before Cleaning Outlier.","a1829b37":"# Missing Value Imputation For Categoricals Columns with LGBM","b3ce4f5d":"# Missing Values Visualizaton","325f3492":"# Missing Value Imputation For Categoricals Columns with CategoricalImputer","4d03e9a8":"# Visualization After cleaning outlier.","4bbfd712":"# Cleaning Outlier.","e7eaf173":"# Simple Imputation"}}