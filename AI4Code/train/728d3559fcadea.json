{"cell_type":{"0b2f24d3":"code","6eeeff22":"code","8639dde8":"code","9a911f89":"code","e7aa83e2":"code","c2e7fd81":"code","4111202f":"code","3867f81e":"code","2fb0a780":"code","04667fda":"code","d4d5078f":"code","92f9af0a":"code","ad136a91":"code","494cecfe":"code","1ec2e2c7":"code","18fcdeb9":"code","6b355124":"code","454966a7":"code","0a04039c":"code","1517d319":"code","03102946":"code","cc1b0284":"code","45022214":"code","54db8e23":"code","844e0452":"code","022fa9e3":"code","0ae66a07":"code","cd85ea56":"code","00d1fa97":"code","fc979c10":"markdown","4b66fb91":"markdown","02e39f6c":"markdown","1ed79262":"markdown","ff139665":"markdown","c8a3032e":"markdown","697a975e":"markdown","e2a9f0b2":"markdown","c84d4a3d":"markdown","49f87657":"markdown","7bf585cd":"markdown","b9c0d34b":"markdown","71fef954":"markdown","38520708":"markdown","76aae37c":"markdown","ee59c3fa":"markdown","d9ac9371":"markdown","9f1e809e":"markdown","b0c41f62":"markdown","0163e6bf":"markdown","e1b277ef":"markdown","a9ca51af":"markdown","0c16c1a8":"markdown","f2a811a2":"markdown","17c9e31d":"markdown"},"source":{"0b2f24d3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6eeeff22":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import linear_model\nimport math","8639dde8":"dirty_train=pd.read_csv('..\/input\/random-linear-regression\/train.csv')\ndirty_test=pd.read_csv('..\/input\/random-linear-regression\/test.csv')","9a911f89":"display(dirty_train.duplicated().sum())\ndisplay(dirty_test.duplicated().sum())","e7aa83e2":"display(dirty_train.isna().sum())\ndisplay(dirty_test.isna().sum())","c2e7fd81":"#...but clean the data by dropping an dodgy data\ntraining_set = dirty_train.dropna() \ntest_set = dirty_test.dropna() ","4111202f":"x_training_set = training_set['x']\ndisplay(x_training_set.loc[:5])","3867f81e":"y_training_set = training_set.y\ndisplay(y_training_set.loc[:5])","2fb0a780":"x_test_set = test_set['x']\ny_test_set = test_set['y']","04667fda":"# Review some of the statistics to check whether the data is skewed\nprint (\"Mean of X Training set: \", np.mean(x_training_set), \"\\n\")\nprint (\"Median of X Training set: \", np.median(x_training_set), \"\\n\")\nprint (\"Mean of Y Training set: \", np.mean(y_training_set), \"\\n\")\nprint (\"Median of Y Training set: \", np.median(y_training_set), \"\\n\")\nprint (\"Std Dev of X Training set: \", np.std(x_training_set), \"\\n\")\nprint (\"Std Dev of Y Training set: \", np.std(y_training_set), \"\\n\")","d4d5078f":"plt.figure(figsize=(16,6))\nplt.style.use(\"seaborn\")\nplt.title('Relationship between X and Y', fontsize=20, y=1.02)\nplt.scatter(x=x_training_set,y=y_training_set,  color='black')\nplt.yticks(fontsize =16)\nplt.xticks(fontsize =16)\nplt.show()","92f9af0a":"display(x_training_set.shape)\ndisplay(y_training_set.shape)","ad136a91":"x_training_set=np.array(x_training_set).reshape(-1,1)\nx_training_set.shape","494cecfe":"x_test_set=np.array(x_test_set).reshape(-1,1)\nx_test_set.shape","1ec2e2c7":"lm=linear_model.LinearRegression()\nlm.fit(x_training_set,y_training_set)","18fcdeb9":"m=lm.coef_ #y=mx+b\nprint(\"Coefficient for X \", m)","6b355124":"b=lm.intercept_ #y=mx+b\nprint('Intercept: ', b)","454966a7":"# So let's run the model against the test data\ny_predicted = lm.predict(x_test_set)","0a04039c":"plt.title('Comparison of Y values in test and the Predicted values',fontsize=24,y=1.08)\nplt.ylabel('Test Set')\nplt.xlabel('Predicted values')\nplt.scatter(y_test_set, y_predicted,  color='DarkBlue')\nplt.show()","1517d319":"# Have a look at R sq to give an idea of the fit \nprint('R sq: ',lm.score(x_training_set,y_training_set))\n\n# and so the correlation is..\nprint('Correlation: ', math.sqrt(lm.score(x_training_set,y_training_set)))","03102946":"import pickle","cc1b0284":"with open('model_pickle','wb') as f:\n    pickle.dump(lm,f)\nprint('Model dump in pickle file successfully')    ","45022214":"with open('model_pickle','rb') as f:\n    model=pickle.load(f)\nprint('Model File Loaded successfully')    ","54db8e23":"plt.title('Comparison of Y and Predicted Y in test dataset Using Model Pickle',fontsize=24,y=1.08)\nplt.scatter(x_test_set,y_test_set,color='g')\nplt.ylabel('y_test_set',fontsize=24)\nplt.xlabel('x_test_set',fontsize=24)\nplt.plot(x_test_set, model.predict(x_test_set),color='k')\nplt.show()","844e0452":"# from sklearn.externals import joblib\nimport joblib","022fa9e3":"joblib.dump(lm,'model_joblib.pkl')\nprint('Model dump in Joblib pickle file successfully')    ","0ae66a07":"model1=joblib.load('model_joblib.pkl')\nprint('Joblib Model File Loaded successfully')","cd85ea56":"model1.coef_","00d1fa97":"model1.intercept_","fc979c10":"# Review some of the statistics to check whether the data is skewed","4b66fb91":"# Linear_model","02e39f6c":"# View Model from Joblib pickle file","1ed79262":"# LinearRegression Score","ff139665":"# Load","c8a3032e":"# 2 .Import Joblib -sklearn - More Efficient","697a975e":"# View Predict from model pickle file - plt.scatter","e2a9f0b2":"# Prepare train and test","c84d4a3d":"https:\/\/www.machinecurve.com\/index.php\/question\/how-to-fix-valueerror-expected-2d-array-got-1d-array-instead-in-scikit-learn\/","49f87657":"# load","7bf585cd":"https:\/\/www.kaggle.com\/ariadne\/simple-one-feature-linear-regression","b9c0d34b":"# Dump\/Write Model into Pickle","71fef954":"# LinearRegression - Predicting y-test using x-test","38520708":"# Clean","76aae37c":"# 1. Import pickle","ee59c3fa":"# Reshape - x Train and Test","d9ac9371":"The positive correlation shows that as Y increases so does X.","9f1e809e":"# Import","b0c41f62":"# Dump ","0163e6bf":"Median and mean are similar so the training set isn't skewed by any outliers that might cause leverage when doing the linear regression","e1b277ef":"# Relationship between X and Y","a9ca51af":"# LinearRegression - fit x_training_set  && y_training_set","0c16c1a8":"# Save Model Using Joblib And Pickle","f2a811a2":"# Reference","17c9e31d":"# Load Model Pickle File"}}