{"cell_type":{"b75251c1":"code","9625bcf8":"code","967cd66b":"code","8485f6cd":"code","6cc40d76":"code","92faa2dd":"code","de00f751":"code","ac7fd9f8":"code","cfaed315":"code","ad9782ee":"code","dc635da1":"code","89ca96b1":"code","a500633e":"code","93824905":"code","dcec832f":"code","b1d6eb49":"code","57c36667":"code","81b738eb":"code","10d79639":"code","b2d282c1":"code","ceb6e833":"code","8a50dc92":"code","bf77ec80":"code","7832e258":"code","246204e1":"code","84a9e8e8":"markdown","ff5b6844":"markdown","a535a3f9":"markdown"},"source":{"b75251c1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport plotly.graph_objs as go\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9625bcf8":"data = pd.read_csv(\"..\/input\/covid19-in-turkey\/covid_19_data_tr.csv\")\ndata.head()","967cd66b":"# Province\/State column is null\n# We work on Turkey data. We do not need Country column\ndata = data.drop([\"Province\/State\",\"Country\/Region\"],axis=1)\ndata.head()","8485f6cd":"# confirmed_data = pd.read_csv(\"..\/input\/covid19-in-turkey\/time_series_covid_19_confirmed_tr.csv\")\n# confirmed_data = confirmed_data.drop([\"Province\/State\", \"Country\/Region\", \"Lat\", \"Long\"],axis=1)\n# confirmed_data = confirmed_data.transpose()\n# confirmed_data.head()\nconfirmed_data = data['Confirmed']\nconfirmed_data.head()","6cc40d76":"# total test numbers\ntested_data = pd.read_csv(\"..\/input\/covid19-in-turkey\/time_series_covid_19_tested_tr.csv\")\ntested_data = tested_data.drop([\"Province\/State\", \"Country\/Region\", \"Lat\", \"Long\"],axis=1)\ntested_data = tested_data.transpose()\ntested_data.head()","92faa2dd":"recovered_data = data['Recovered']\nrecovered_data.head()","de00f751":"deaths_data = data['Deaths']\ndeaths_data.head()","ac7fd9f8":"intubated_data = pd.read_csv(\"..\/input\/covid19-in-turkey\/time_series_covid_19_intubated_tr.csv\")\nintubated_data = intubated_data.drop([\"Province\/State\", \"Country\/Region\", \"Lat\", \"Long\"],axis=1)\nintubated_data = intubated_data.transpose()\nintubated_data.head()","cfaed315":"data.info()","ad9782ee":"dates_data = data['Last_Update']\ndates_data.head()","dc635da1":"# death plot\nplt.plot(dates_data, deaths_data)\nplt.rcParams[\"figure.figsize\"] = [10,5]\nplt.xlabel(\"Date\")\nplt.ylabel(\"Deaths\",rotation=90)\nplt.xticks(rotation=90)\nplt.show()","89ca96b1":"# confirmed patient\nplt.plot(dates_data, confirmed_data)\nplt.rcParams[\"figure.figsize\"] = [15,5]\nplt.xlabel(\"Date\")\nplt.ylabel(\"Confirmed\")\nplt.xticks(rotation=90)\nplt.show()","a500633e":"from plotly.offline import init_notebook_mode, iplot, plot\nconfirmed_scatter = go.Scatter(\n    x = dates_data,\n    y = confirmed_data,\n    mode = \"lines+markers\",\n    name = \"Confirmed\",\n    marker = dict(color = 'rgba(16, 112, 2, 0.8)'),\n    text= 'Confirmed'\n)\n\ndeath_scatter = go.Scatter(\n    x = dates_data,\n    y = deaths_data,\n    mode = \"lines+markers\",\n    name = \"Deaths\",\n    marker = dict(color = 'rgba(0, 255, 200, 0.8)'),\n    text = 'Deaths'\n)\n\ntest_scatter = go.Scatter(\n    x = dates_data,\n    y = recovered_data,\n    mode = \"lines+markers\",\n    name = \"Recovered\",\n    marker = dict(color = 'rgba(255, 128, 2, 0.8)'),\n    text = 'Recovered'\n)\n\nlayout = dict(title = 'Deaths & Confirmed & Recovered',\n              xaxis= dict(title= 'Dates',ticklen= 5,zeroline= True)\n             )\n\ndata_scatter = [confirmed_scatter, death_scatter, test_scatter]\nfig = dict(data = data_scatter, layout = layout)\niplot(fig)","93824905":"import math\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error","dcec832f":"dates_data = dates_data.values.reshape(-1,1)\nrecovered_data = recovered_data.values.reshape(-1,1)\ndeaths_data = deaths_data.values.reshape(-1,1)\nconfirmed_data = confirmed_data.values.reshape(-1,1)","b1d6eb49":"# scale deaths\nscaler_dead = MinMaxScaler(feature_range=(0, 1))\ndeaths_data_sc = scaler_dead.fit_transform(deaths_data)\n\n# scale recovered\nscaler_rec = MinMaxScaler(feature_range=(0, 1))\nrecovered_data_sc = scaler_rec.fit_transform(recovered_data)\n\n# scale confirmed\nscaler_con = MinMaxScaler(feature_range=(0, 1))\nconfirmed_data_sc = scaler_con.fit_transform(confirmed_data)","57c36667":"train_dead_data_size = int(len(deaths_data_sc) * 0.55)\ntest_dead_data_size = len(deaths_data_sc) - train_dead_data_size\ntrain_dead_data = deaths_data_sc[0:train_dead_data_size,:]\ntest_dead_data = deaths_data_sc[train_dead_data_size:len(deaths_data_sc),:]\nprint(\"Dead Train data size\", len(train_dead_data) , \"Dead Test data size\", len(test_dead_data))","81b738eb":"train_recovered_data_size = int(len(recovered_data_sc) * 0.55)\ntest_recovered_data_size = len(recovered_data_sc) - train_recovered_data_size\ntrain_recovered_data = recovered_data_sc[0:train_recovered_data_size,:]\ntest_recovered_data = recovered_data_sc[train_recovered_data_size:len(recovered_data_sc),:]\nprint(\"Recovered Train data size\", len(train_recovered_data) , \"Recovered Test data size\", len(test_recovered_data))","10d79639":"train_confirmed_data_size = int(len(confirmed_data_sc) * 0.55)\ntest_confirmed_data_size = len(confirmed_data_sc) - train_confirmed_data_size\ntrain_confirmed_data = confirmed_data_sc[0:train_confirmed_data_size,:]\ntest_confirmed_data = confirmed_data_sc[train_confirmed_data_size:len(confirmed_data_sc),:]\nprint(\"Confirmed Train data size\", len(train_confirmed_data) , \"Confirmed Test data size\", len(test_confirmed_data))","b2d282c1":"time_stemp = 4\ndatax_date = []\ndatay_deaths = []\ndatay_confirmed = []\ndatay_recovered = []\n\nfor i in range(len(train_dead_data)-time_stemp-1):\n    a = train_dead_data[i:(i+time_stemp), 0]\n    datax_date.append(a)\n    datay_deaths.append(train_dead_data[i + time_stemp, 0])\ntrainX_deaths = np.array(datax_date)\ntrainY_deaths = np.array(datay_deaths)  \n","ceb6e833":"datax_date = []\ndatay_deaths = []\n\nfor i in range(len(test_dead_data)-time_stemp-1):\n    a = test_dead_data[i:(i+time_stemp), 0]\n    datax_date.append(a)\n    datay_deaths.append(test_dead_data[i + time_stemp, 0])\ntestX_deaths = np.array(datax_date)\ntestY_deaths = np.array(datay_deaths)  ","8a50dc92":"trainX_deaths = np.reshape(trainX_deaths, (trainX_deaths.shape[0], 1, trainX_deaths.shape[1]))\ntestX_deaths = np.reshape(testX_deaths, (testX_deaths.shape[0], 1, testX_deaths.shape[1]))","bf77ec80":"lstm_model = Sequential()\nlstm_model.add(LSTM(10, input_shape=(1, time_stemp)))\nlstm_model.add(Dense(1))\nlstm_model.compile(loss='mean_squared_error', optimizer='adam')\nlstm_model.fit(trainX_deaths, trainY_deaths, epochs=50, batch_size=1)","7832e258":"trainPredict = lstm_model.predict(trainX_deaths)\ntestPredict = lstm_model.predict(testX_deaths)\n\ntrainPredict = scaler_dead.inverse_transform(trainPredict)\ntrainY = scaler_dead.inverse_transform([trainY_deaths])\ntestPredict = scaler_dead.inverse_transform(testPredict)\ntestY = scaler_dead.inverse_transform([testY_deaths])\n# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\nprint('Test Score: %.2f RMSE' % (testScore))","246204e1":"\ntrainPredictPlot = np.empty_like(deaths_data_sc)\ntrainPredictPlot[:, :] = np.nan\ntrainPredictPlot[time_stemp:len(trainPredict)+time_stemp, :] = trainPredict\n\ntestPredictPlot = np.empty_like(deaths_data_sc)\ntestPredictPlot[:, :] = np.nan\ntestPredictPlot[len(trainPredict)+(time_stemp*2)+1:len(deaths_data_sc)-1, :] = testPredict\n\nplt.plot(scaler_dead.inverse_transform(deaths_data_sc))\nplt.plot(trainPredictPlot)\nplt.plot(testPredictPlot)\nplt.legend()\nplt.show()","84a9e8e8":"# LSTM Model","ff5b6844":"I will 2 more lstm models for confirmed and recovered datas.\nThank you","a535a3f9":"We crate 3 different model. recovered, confirmed , deaths"}}