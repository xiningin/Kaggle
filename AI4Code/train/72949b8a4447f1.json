{"cell_type":{"7ad6e187":"code","54d258f7":"code","0170a07c":"code","997530f2":"code","ebdd377c":"code","0e0d82a8":"code","c448448e":"code","767f09bd":"code","0f7838f4":"code","db5c0ee3":"code","c505f024":"code","c7afbaf8":"markdown","e40ce230":"markdown","3bc51222":"markdown","ddac29e7":"markdown"},"source":{"7ad6e187":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras import models, layers\nimport tqdm\nfrom PIL import Image\n\nimport os","54d258f7":"PATH = \"\/kaggle\/input\/challenges-in-representation-learning-facial-expression-recognition-challenge\"\n\ndata = pd.read_csv(os.path.join(PATH, \"icml_face_data.csv\"))\n\nemotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}","0170a07c":"print(data)","997530f2":"# Function to parse data into right format\n# Output: Image in right shaped and normalized + labels\ndef parse_data(data):\n    image_array = np.zeros(shape=(len(data), 48, 48, 1))\n    image_label = np.array(list(map(int, data['emotion'])))\n    \n    for i, row in enumerate(data.index):\n        image = np.fromstring(data.loc[row, ' pixels'], dtype=int, sep=' ')\n        image = np.reshape(image, (48, 48, 1))\n        image_array[i] = image\n        \n    return image_array, image_label\n\n# Splitting the data into train, validation and testing set thanks to Usage column\ntrain_imgs, train_lbls = parse_data(data[data[\" Usage\"] == \"Training\"])\nval_imgs, val_lbls = parse_data(data[data[\" Usage\"] == \"PrivateTest\"])\ntest_imgs, test_lbls = parse_data(data[data[\" Usage\"] == \"PublicTest\"])","ebdd377c":"print(\"train shape\", np.shape(train_imgs))\nprint(\"validation shape\", np.shape(val_imgs))\nprint(\"validatio shape\", np.shape(val_imgs))","0e0d82a8":"print(train_imgs)","c448448e":"import os, shutil \nos.mkdir(\"\/kaggle\/working\/imgs\")\ndata = np.array(train_imgs[:5])\ni = 0\nfor px_map in data:\n    i = i + 1\n    px_map = np.reshape(px_map, (48, 48))\n    image = Image.fromarray(px_map)\n    image = image.convert('RGB')\n    image.save('\/kaggle\/working\/imgs\/'+str(i)+'.bmp')","767f09bd":"# Building a MLP model based on LeNet architecture \n\nmodel_mlp = keras.Sequential()\n\nmodel_mlp.add(layers.Flatten(input_shape=(48, 48, 1)))\n\nmodel_mlp.add(layers.Dense(units=120, activation='relu'))\n\nmodel_mlp.add(layers.Dense(units=84, activation='relu'))\n\nmodel_mlp.add(layers.Dense(units=7, activation = 'softmax'))\n\nmodel_mlp.compile(loss=keras.losses.SparseCategoricalCrossentropy(), optimizer=keras.optimizers.Adam(lr=1e-3), metrics=['accuracy'])\n\nmodel_mlp.summary()","0f7838f4":"# Training the model, and validating\nmodel_mlp.fit(train_imgs, train_lbls, \n          epochs=5, batch_size=32, \n          validation_data=(val_imgs, val_lbls), verbose=1)","db5c0ee3":"model_cnn = keras.Sequential()\n\nmodel_cnn.add(layers.Conv2D())\n\nmodel_cnn.add(layers.MaxPooling())\n\nmodel_cnn.add(layers.Flatten())\n\nmodel_cnn.add(layers.Dense(units=84, activation='relu'))\n\nmodel_cnn.add(layers.Dense(units=7, activation = 'softmax'))\n\nmodel_cnn.compile(loss=keras.losses.SparseCategoricalCrossentropy(), optimizer=keras.optimizers.Adam(lr=1e-3), metrics=['accuracy'])\n\nmodel_cnn.summary()","c505f024":"model_cnn.fit()","c7afbaf8":"CNN model","e40ce230":"Image files generation","3bc51222":"https:\/\/scikit-learn.org\/stable\/modules\/cross_validation.html","ddac29e7":"MLP model"}}