{"cell_type":{"61ba9993":"code","ca40680a":"code","60fdffcb":"code","a306af39":"code","88aa70e5":"code","58cd7225":"code","aff8518f":"code","454b1c2d":"code","da8b5e7c":"code","ea6d148f":"code","5b149ab1":"code","02942a8e":"code","fc352a2e":"code","8eca2cda":"code","556a5221":"code","f40563e0":"code","ddae0091":"code","4ee76355":"code","a0632f68":"code","adcc0af5":"markdown","b8bb469a":"markdown","c62ad2c1":"markdown","d3d21400":"markdown","de1fe0ce":"markdown","b16b902a":"markdown","507fef72":"markdown","21272be0":"markdown","94ab55cb":"markdown","f1420d9e":"markdown"},"source":{"61ba9993":"import torch\nimport torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\nimport torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\nimport torchvision.transforms as transforms  # Transformations we can perform on our dataset\nimport torchvision\nimport os\nimport pandas as pd\nfrom tqdm import tqdm\nfrom skimage import io\nfrom skimage.transform import rescale, resize, downscale_local_mean\nfrom torch.utils.data import (\n    Dataset,\n    DataLoader,\n)  # Gives easier dataset managment and creates mini batches","ca40680a":"!pip install torch-summary\n!pip install tqdm","60fdffcb":"class ImagesDataProcess(Dataset):\n    def __init__(self,csv_file,root_dir,tranform=None):\n        self.annotation=pd.read_csv(csv_file)\n        self.root_dir=root_dir\n        self.tranform=tranform\n        \n    def __len__(self):\n        return len(self.annotation)\n    \n    def __getitem__(self,index):\n        img_path=os.path.join(self.root_dir,self.annotation.iloc[index,0])\n        image=io.imread(img_path)\n        y_label=torch.tensor(int(self.annotation.iloc[index,1]))\n        \n        if self.tranform:\n            image=self.tranform(image)\n        return (image,y_label)\n","a306af39":"# Hyperparameters\nin_channel = 3\nnum_classes = 2\nlearning_rate = 1e-3\nbatch_size = 32\nnum_epochs = 10\nroot_dir_path='..\/input\/cat-dog-images-for-classification\/cat_dog'\ncsv_file_path='..\/input\/cat-dog-images-for-classification\/cat_dog.csv'","88aa70e5":"my_transform=transforms.Compose(\n    [\n        transforms.ToPILImage(),\n        transforms.Resize((224,224)),\n#         transforms.ColorJitter(brightness=0,contrast=0,saturation=0,hue=0),\n        transforms.RandomRotation(degrees=45),\n        transforms.RandomHorizontalFlip(p=0.3),\n        transforms.RandomVerticalFlip(p=0.05),\n        transforms.RandomGrayscale(p=0.1),\n        transforms.RandomCrop((224,224)),\n        transforms.ToTensor(),\n        # transforms.Normalize(mean=[0.5,0.5,0.5],std=[1.0,1.0,1.0])\n    ]\n)   ","58cd7225":"dataset=ImagesDataProcess(\n    csv_file=csv_file_path,\n    root_dir=root_dir_path,\n    tranform=my_transform\n)","aff8518f":"len(dataset)\n","454b1c2d":"train_set, test_set = torch.utils.data.random_split(dataset, [20000, 5000])\ntrain_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True)","da8b5e7c":"VGG = {\n    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n}","ea6d148f":"class VGG_net(nn.Module):\n    def __init__(self,in_ch=3,num_classes=10,arcitecture=None):\n        super(VGG_net,self).__init__()\n        self.arcitecture=arcitecture\n        self.in_ch=in_ch\n        self.out_ch=num_classes\n        self.conv_layers=self.create_conv_layers(self.arcitecture)\n        self.fc=nn.Sequential(\n            nn.Linear(7*7*512,4096),\n            nn.ReLU(),\n            # nn.Dropout(p=0.5),\n            nn.Linear(4096,4096),\n            nn.ReLU(),\n            # nn.Dropout(p=0.5),\n            nn.Linear(4096,num_classes)\n        )\n            \n        \n    def forward(self,x):\n        x=self.conv_layers(x)\n        x=x.view(x.shape[0],-1)\n        x=self.fc(x)\n        return x\n    \n    def create_conv_layers(self,model_arcitecture):\n        in_ch=self.in_ch\n        model=[]\n        for i in model_arcitecture:\n            if type(i)==int:\n                out_ch=i\n                model+=[nn.Conv2d(in_channels=in_ch,\n                                 out_channels=out_ch,\n                                 kernel_size=3,\n                                 stride=1,\n                                 padding=1),\n                        nn.BatchNorm2d(i),\n                        nn.ReLU()]\n                in_ch=i\n            elif i=='M':\n                model+=[nn.MaxPool2d(kernel_size=2,stride=2)]\n        return nn.Sequential(*model)","5b149ab1":"model=VGG_net(in_ch=3,num_classes=10,arcitecture=VGG['VGG16'])","02942a8e":"from torchsummary import summary\n\nprint(summary(model, (3, 224, 224),verbose=0))","fc352a2e":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","8eca2cda":"device=get_default_device()\ndevice","556a5221":"train_loader = DeviceDataLoader(train_loader, device)\ntest_loader = DeviceDataLoader(test_loader, device)\nto_device(model, device);","f40563e0":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)","ddae0091":"for epoch in range(num_epochs):\n    losses = []\n\n    for batch_idx, (data, targets) in tqdm(enumerate(train_loader)):\n        # Get data to cuda if possible\n        data = data\n        targets = targets\n        # forward\n        scores = model(data)\n        loss = criterion(scores, targets)\n\n        losses.append(loss.item())\n\n        # backward\n        optimizer.zero_grad()\n        loss.backward()\n\n        # gradient descent or adam step\n        optimizer.step()\n\n    print(f\"Cost at epoch {epoch} is {sum(losses)\/len(losses)}\")","4ee76355":"%time\ndef check_accuracy(loader, model):\n    num_correct = 0\n    num_samples = 0\n    model.eval()\n\n    with torch.no_grad():\n        for x, y in tqdm(loader):\n            x = x\n            y = y\n            scores = model(x)\n            _, predictions = scores.max(1)\n            num_correct += (predictions == y).sum()\n            num_samples += predictions.size(0)\n\n        print(\n            f\"Got {num_correct} \/ {num_samples} with accuracy {float(num_correct)\/float(num_samples)*100:.2f}\"\n        )\n\n    model.train()","a0632f68":"print(\"Checking accuracy on Training Set\")\ncheck_accuracy(train_loader, model)\n\nprint(\"Checking accuracy on Test Set\")\ncheck_accuracy(test_loader, model)","adcc0af5":"# Imports\n","b8bb469a":"# Loss and optimizer\n","c62ad2c1":"# Image Augmentation","d3d21400":"## Create Model","de1fe0ce":"# Move model & data to GPU","b16b902a":"# Check accuracy on training to see how good our model is\n","507fef72":"# Creating VGG arcitecture","21272be0":"# Train Network\n","94ab55cb":"# Creating Dataloader Class","f1420d9e":"# Load Dataset"}}