{"cell_type":{"821df1f0":"code","47850480":"code","9561c7fb":"code","8746b58e":"code","17bf304d":"code","e17b5e2d":"code","b951ff7d":"code","539e03a1":"code","81866890":"code","dcc0d406":"code","838e288c":"code","6e645cb6":"code","822a9014":"code","7db59ff3":"code","6dac8b67":"code","50575cf3":"code","610ebeb3":"code","8c2c9c39":"code","5fe70ed2":"code","54f5a53e":"code","aefc190b":"code","f9ccb90b":"code","d995b76f":"code","ecef17f4":"code","d41afe20":"code","babd8d8e":"code","8a7d8bec":"code","1e5fd0bc":"code","ca931243":"code","e13ff1ee":"code","ef0b7d05":"code","1ebe9ae6":"code","cf0fa8be":"code","c8674c85":"code","df0584fd":"code","840b1021":"code","a34a4488":"code","6cf37fdf":"code","1e258230":"code","1ba2ed2b":"code","5a51f80e":"code","e1cfad68":"code","6b8aef1c":"code","8954c86e":"code","dbc412c3":"markdown","d9843592":"markdown","556f8a01":"markdown","da499bd0":"markdown","82c0a023":"markdown","973afc8a":"markdown","81b387df":"markdown","8036308d":"markdown","2adf55df":"markdown","6fbb8836":"markdown","d25a2c6f":"markdown","18747143":"markdown","75eb6fcf":"markdown","21a895a4":"markdown","df0ea0ec":"markdown","1a06d705":"markdown","21c88e38":"markdown","188974be":"markdown"},"source":{"821df1f0":"import re\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom kaggle_datasets import KaggleDatasets\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import layers, models, optimizers\nfrom tensorflow.keras.layers import Dropout\nfrom keras.applications.vgg16 import VGG16\nimport matplotlib.cm as cm\nfrom sklearn.model_selection import train_test_split\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)\n    \nprint(tf.__version__)","47850480":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nGCS_PATH = KaggleDatasets().get_gcs_path(\"covid19-radiography-database\")\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nIMAGE_SIZE = [180, 180]","9561c7fb":"filenames = tf.io.gfile.glob(str(GCS_PATH + '\/COVID-19 Radiography Database\/COVID-19\/*'))\nfilenames.extend(tf.io.gfile.glob(str(GCS_PATH + '\/COVID-19 Radiography Database\/NORMAL\/*')))\nfilenames.extend(tf.io.gfile.glob(str(GCS_PATH + '\/COVID-19 Radiography Database\/Viral Pneumonia\/*')))\n\nrandom.seed(1337)\ntf.random.set_seed(1337)\nrandom.shuffle(filenames)","8746b58e":"COUNT_NORMAL = len([filename for filename in filenames if \"NORMAL\" in filename])\nprint(\"Normal images count : \" + str(COUNT_NORMAL))\n\nCOUNT_COVID = len([filename for filename in filenames if \"\/COVID-19\/\" in filename])\nprint(\"COVID-19 images count : \" + str(COUNT_COVID))\n\nCOUNT_PNEUMONIA = len([filename for filename in filenames if \"Viral\" in filename])\nprint(\"Pneumonia images count : \" + str(COUNT_PNEUMONIA))","17bf304d":"import seaborn as sns\n# intialise data of lists.\ndata = {'Cases':['0', '1', '2'],\n        'Cases_count':[COUNT_NORMAL, COUNT_COVID, COUNT_PNEUMONIA]\n       }\n \n# Create DataFrame\ndf = pd.DataFrame(data)\n\n# Get the counts for each class in the data\n\nplt.figure(figsize=(10,8))\nsns.barplot(x=df.index, y= df['Cases_count'].values)\nplt.title('Number of All the Data', fontsize=14)\nplt.xlabel('Case type', fontsize=12)\nplt.ylabel('Count', fontsize=12)\nplt.xticks(range(len(df.index)), ['Normal(0)', 'Covid19(1)', 'Pneumonia(2)'])\nplt.show()\n \n# Print the output.\nprint(df)","e17b5e2d":"train_filenames, test_filenames = train_test_split(filenames, test_size=0.1)\ntrain_filenames, val_filenames = train_test_split(train_filenames, test_size=0.1)","b951ff7d":"COUNT_NORMAL_TRAINING = len([filename for filename in train_filenames if \"NORMAL\" in filename])\nprint(\"Normal images count in training set: \" + str(COUNT_NORMAL_TRAINING))\n\nCOUNT_COVID_TRAINING = len([filename for filename in train_filenames if \"\/COVID-19\/\" in filename])\nprint(\"COVID-19 images count in training set: \" + str(COUNT_COVID_TRAINING))\n\nCOUNT_PNEUMONIA_TRAINING = len([filename for filename in train_filenames if \"Viral\" in filename])\nprint(\"Pneumonia images count in training set: \" + str(COUNT_PNEUMONIA_TRAINING))","539e03a1":"import seaborn as sns\n# intialise data of lists.\ndata = {'Cases':['0', '1', '2'],\n        'Cases_count':[COUNT_NORMAL_TRAINING, COUNT_COVID_TRAINING, COUNT_PNEUMONIA_TRAINING]}\n \n# Create DataFrame\ndf = pd.DataFrame(data)\n\n# Get the counts for each class in training data\n\nplt.figure(figsize=(10,8))\nsns.barplot(x=df.index, y= df['Cases_count'].values)\nplt.title('Number of Training cases', fontsize=14)\nplt.xlabel('Case type', fontsize=12)\nplt.ylabel('Count', fontsize=12)\nplt.xticks(range(len(df.index)), ['Normal(0)', 'Covid19(1)', 'Pneumonia(2)'])\nplt.show()\n \n# Print the output.\nprint(df)","81866890":"COUNT_NORMAL_VALODATION = len([filename for filename in val_filenames if \"NORMAL\" in filename])\nprint(\"Normal images count in validation set: \" + str(COUNT_NORMAL_VALODATION))\n\nCOUNT_COVID_VALODATION = len([filename for filename in val_filenames if \"\/COVID-19\/\" in filename])\nprint(\"COVID-19 images count in validation set: \" + str(COUNT_COVID_VALODATION))\n\nCOUNT_PNEUMONIA_VALODATION = len([filename for filename in val_filenames if \"Viral\" in filename])\nprint(\"Pneumonia images count in validation set: \" + str(COUNT_PNEUMONIA_VALODATION))","dcc0d406":"import seaborn as sns\n# intialise data of lists.\ndata = {'Cases':['0', '1', '2'],\n        'Cases_count':[COUNT_NORMAL_VALODATION, COUNT_COVID_VALODATION, COUNT_PNEUMONIA_VALODATION]}\n \n# Create DataFrame\ndf = pd.DataFrame(data)\n\n# Get the counts for each class in validation data\n\nplt.figure(figsize=(10,8))\nsns.barplot(x=df.index, y= df['Cases_count'].values)\nplt.title('Number of Validation cases', fontsize=14)\nplt.xlabel('Case type', fontsize=12)\nplt.ylabel('Count', fontsize=12)\nplt.xticks(range(len(df.index)), ['Normal(0)', 'Covid19(1)', 'Pneumonia(2)'])\nplt.show()\n \n# Print the output.\nprint(df)","838e288c":"COUNT_NORMAL_TEST = len([filename for filename in test_filenames if \"NORMAL\" in filename])\nprint(\"Normal images count in test set: \" + str(COUNT_NORMAL_TEST))\n\nCOUNT_COVID_TEST = len([filename for filename in test_filenames if \"\/COVID-19\/\" in filename])\nprint(\"COVID-19 images count in test set: \" + str(COUNT_COVID_TEST))\n\nCOUNT_PNEUMONIA_TEST = len([filename for filename in test_filenames if \"Viral\" in filename])\nprint(\"Pneumonia images count in test set: \" + str(COUNT_PNEUMONIA_TEST))","6e645cb6":"import seaborn as sns\n# intialise data of lists.\ndata = {'Cases':['0', '1', '2'],\n        'Cases_count':[COUNT_NORMAL_TEST, COUNT_COVID_TEST, COUNT_PNEUMONIA_TEST]}\n \n# Create DataFrame\ndf = pd.DataFrame(data)\n\n# Get the counts for each class in test data\n\nplt.figure(figsize=(10,8))\nsns.barplot(x=df.index, y= df['Cases_count'].values)\nplt.title('Number of test cases', fontsize=14)\nplt.xlabel('Case type', fontsize=12)\nplt.ylabel('Count', fontsize=12)\nplt.xticks(range(len(df.index)), ['Normal(0)', 'Covid19(1)', 'Pneumonia(2)'])\nplt.show()\n \n# Print the output.\nprint(df)","822a9014":"train_list_ds = tf.data.Dataset.from_tensor_slices(train_filenames)\nval_list_ds = tf.data.Dataset.from_tensor_slices(val_filenames)\ntest_list_ds = tf.data.Dataset.from_tensor_slices(test_filenames)","7db59ff3":"TRAIN_IMG_COUNT = tf.data.experimental.cardinality(train_list_ds).numpy()\nprint(\"Training images count: \" + str(TRAIN_IMG_COUNT))\n\nVAL_IMG_COUNT = tf.data.experimental.cardinality(val_list_ds).numpy()\nprint(\"Validating images count: \" + str(VAL_IMG_COUNT))\n\nTest_IMG_COUNT = tf.data.experimental.cardinality(test_list_ds).numpy()\nprint(\"Testing images count: \" + str(Test_IMG_COUNT))","6dac8b67":"CLASSES = ['NORMAL', 'COVID-19', 'Viral Pneumonia']","50575cf3":"def get_label(file_path):\n    # convert the path to a list of path components\n    parts = tf.strings.split(file_path, os.path.sep)\n    # The second to last is the class-directory\n    return parts[-2] == CLASSES","610ebeb3":"def decode_img(img):\n  # convert the compressed string to a 3D uint8 tensor\n  img = tf.image.decode_png(img, channels=3)\n  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n  img = tf.image.convert_image_dtype(img, tf.float32)\n  # resize the image to the desired size.\n  return tf.image.resize(img, IMAGE_SIZE)","8c2c9c39":"def process_path(file_path):\n    label = get_label(file_path)\n    # load the raw data from the file as a string\n    img = tf.io.read_file(file_path)\n    img = decode_img(img)\n    return img, label","5fe70ed2":"train_ds = train_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\nval_ds = val_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\ntest_ds = test_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)","54f5a53e":"def prepare_for_training(ds, cache=True):\n    # This is a small dataset, only load it once, and keep it in memory.\n    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n    # fit in memory.\n    if cache:\n        if isinstance(cache, str):\n            ds = ds.cache(cache)\n        else:\n            ds = ds.cache()\n\n    ds = ds.shuffle(buffer_size=1000)\n    ds = ds.batch(BATCH_SIZE)\n\n    if cache:\n        ds = ds.prefetch(buffer_size=AUTOTUNE)\n\n    return ds","aefc190b":"train_ds = prepare_for_training(train_ds)\nval_ds = prepare_for_training(val_ds)\ntest_ds = prepare_for_training(test_ds, False)","f9ccb90b":"def show_batch(image_batch, label_batch):\n    plt.figure(figsize=(10,10))\n    for n in range(15):\n        ax = plt.subplot(5,5,n+1)\n        plt.imshow(image_batch[n])\n        plt.title(CLASSES[np.argmax(label_batch[n])])\n        plt.axis(\"off\")","d995b76f":"image_batch, label_batch = next(iter(train_ds))\nshow_batch(image_batch.numpy(), label_batch.numpy())","ecef17f4":"early_stopping_cb = keras.callbacks.EarlyStopping(patience=5,\n                                                  restore_best_weights=True)","d41afe20":"with strategy.scope():\n    reconstructed_model = keras.models.load_model(\"..\/input\/pneumonetbest-model\/PneomoNetBest.h5\")\n    reconstructed_model.pop()\n    reconstructed_model.add(layers.Dense(512, activation='relu'))\n#     reconstructed_model.add(layers.Dense(128, activation='relu'))\n#     reconstructed_model.add(layers.Dense(64, activation='relu'))\n    reconstructed_model.add(keras.layers.Dense(3, activation='softmax'))\n    \n    METRICS = [\n        'accuracy',\n        keras.metrics.Precision(name=\"precision\"),\n        keras.metrics.Recall(name=\"recall\")\n    ]\n    \n    reconstructed_model.compile(\n        optimizer=\"adam\",\n        loss=\"categorical_crossentropy\",\n        metrics=METRICS,\n    )","babd8d8e":"history = reconstructed_model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=30,\n    callbacks=[early_stopping_cb]\n)","8a7d8bec":"fig, ax = plt.subplots(2, 2, figsize=(15, 10))\nax = ax.ravel()\n\nfor i, met in enumerate(['precision', 'recall', 'accuracy', 'loss']):\n    ax[i].plot(history.history[met])\n    ax[i].plot(history.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])\n    ","1e5fd0bc":"history_dict2 = history.history\nacc_values2 = history_dict2['accuracy']\nval_acc_values2 = history_dict2['val_accuracy']\n\nepochs = range(1, 21 + 1)\nplt.plot(epochs, acc_values2, 'b-', label='training Accuracy')\nplt.plot(epochs, val_acc_values2, 'r-', label='validation Accuracy')\nplt.title('trainin\/validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.rcParams['axes.facecolor'] = 'white'\nplt.rcParams['axes.edgecolor'] = 'white'\nplt.rcParams['axes.grid'] = True\nplt.rcParams['grid.alpha'] = 1\nplt.rcParams['grid.color'] = \"#cccccc\"\nplt.show()","ca931243":"history_dict2 = history.history\nloss_values2 = history_dict2['loss']\nval_loss_values2 = history_dict2['val_loss']\n\nepochs = range(1, 21 + 1)\nplt.plot(epochs, loss_values2, 'b-', label='training loos')\nplt.plot(epochs, val_loss_values2, 'r-', label='validation loss')\nplt.title('trainin\/validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.rcParams['axes.facecolor'] = 'white'\nplt.rcParams['axes.edgecolor'] = 'white'\nplt.rcParams['axes.grid'] = False\nplt.rcParams['grid.alpha'] = 1\nplt.rcParams['grid.color'] = \"#cccccc\"\nplt.show()","e13ff1ee":"reconstructed_model.evaluate(test_ds, return_dict=True)","ef0b7d05":"# reconstructed_model.save('PneumoCovid_Model.h5')","1ebe9ae6":"image_batch, label_batch = next(iter(train_ds))\n\npred = reconstructed_model.predict(image_batch)\npred","cf0fa8be":"saved_Model = keras.models.load_model('..\/input\/best-model\/PneumoCovid_Model.h5')\nsaved_Model2 = keras.models.load_model('..\/input\/best-model-v2\/PneumoCovid_Model V2.h5')","c8674c85":"saved_Model.evaluate(test_ds, return_dict=True)","df0584fd":"saved_Model2.evaluate(test_ds, return_dict=True)","840b1021":"def get_intermediate_Activation(model, imge_path):\n    \n\n    img_path = imge_path\n    from keras.preprocessing import image\n    import numpy as np\n    img = image.load_img(img_path, target_size=(180, 180))\n    img_tensor = image.img_to_array(img)\n    img_tensor = np.expand_dims(img_tensor, axis=0)\n    img_tensor \/= 255.\n    import tensorflow as tf\n    from tensorflow.keras import models\n    layer_outputs = [layer.output for layer in model.layers[:5]]\n    activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n    activations = activation_model.predict(img_tensor)\n\n    layer_names = []\n    for layer in model.layers[:5]:\n        layer_names.append(layer.name)\n    images_per_row = 5\n    for layer_name, layer_activation in zip(layer_names, activations):\n        n_features = layer_activation.shape[-1]\n        size = layer_activation.shape[1]\n        n_cols = n_features \/\/ images_per_row\n        display_grid = np.zeros((size * n_cols, images_per_row * size))\n        for col in range(n_cols):\n            for row in range(images_per_row):\n                channel_image = layer_activation[0,\n                                         :, :,\n                                         col * images_per_row + row]\n                channel_image -= channel_image.mean()\n                channel_image \/= channel_image.std()\n                channel_image *= 64\n                channel_image += 128\n                channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n                display_grid[col * size : (col + 1) * size,\n                      row * size : (row + 1) * size] = channel_image\n        scale = 1. \/ size\n        plt.figure(figsize=(scale * display_grid.shape[1],\n        scale * display_grid.shape[0]))\n        plt.title(layer_name)\n        plt.grid(False)\n        plt.imshow(display_grid, aspect='auto', cmap='viridis')\n        \nget_intermediate_Activation(saved_Model, '..\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/COVID-19\/COVID-19 (1).png')","a34a4488":"saved_Model.summary()","6cf37fdf":"# ploting the NeumoNet2 architecture\nfrom keras.utils import plot_model\nplot_model(saved_Model, to_file='PneumoCovidNet.png', show_shapes=True)","1e258230":"# last convolution block of the model\nsaved_Model.layers[7].layers","1ba2ed2b":"def get_img_array(img_path, size=IMAGE_SIZE):\n    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n    # `array` is a float32 NumPy array\n    array = keras.preprocessing.image.img_to_array(img)\n    # We add a dimension to transform our array into a \"batch\"\n    # of size (1, 180, 180, 3)\n    array = np.expand_dims(array, axis=0) \/ 255.0\n    return array","5a51f80e":"def make_gradcam_heatmap(img_array, model):\n    # First, we create a model that maps the input image to the activations\n    # of the last conv layer\n    last_conv_layer = model.layers[7]\n    last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)\n    \n    # Mark the classifying layers\n    classifier_layers = model.layers[-6:]\n\n    # Second, we create a model that maps the activations of the last conv\n    # layer to the final class predictions\n    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n    x = classifier_input\n    for classifier_layer in classifier_layers:\n        x = classifier_layer(x)\n    classifier_model = keras.Model(classifier_input, x)\n\n    # Then, we compute the gradient of the top predicted class for our input image\n    # with respect to the activations of the last conv layer\n    with tf.GradientTape() as tape:\n        # Compute activations of the last conv layer and make the tape watch it\n        last_conv_layer_output = last_conv_layer_model(img_array)\n        tape.watch(last_conv_layer_output)\n        # Compute class predictions\n        preds = classifier_model(last_conv_layer_output)\n        top_pred_index = tf.argmax(preds[0])\n        top_class_channel = preds[:, top_pred_index]\n\n    # This is the gradient of the top predicted class with regard to\n    # the output feature map of the last conv layer\n    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n\n    # This is a vector where each entry is the mean intensity of the gradient\n    # over a specific feature map channel\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    # We multiply each channel in the feature map array\n    # by \"how important this channel is\" with regard to the top predicted class\n    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n    pooled_grads = pooled_grads.numpy()\n    for i in range(pooled_grads.shape[-1]):\n        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n\n    # The channel-wise mean of the resulting feature map\n    # is our heatmap of class activation\n    heatmap = np.mean(last_conv_layer_output, axis=-1)\n\n    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n    heatmap = np.maximum(heatmap, 0) \/ np.max(heatmap)\n    return heatmap","e1cfad68":"def superimposed_cam(file_path):\n    # Prepare image\n    img_array = get_img_array(file_path)\n\n    # Generate class activation heatmap\n    heatmap = make_gradcam_heatmap(\n        img_array, saved_Model\n    )\n\n    # Rescale the original image\n    img = img_array * 255\n\n    # We rescale heatmap to a range 0-255\n    heatmap = np.uint8(255 * heatmap)\n\n    # We use jet colormap to colorize heatmap\n    jet = cm.get_cmap(\"jet\")\n\n    # We use RGB values of the colormap\n    jet_colors = jet(np.arange(256))[:, :3]\n    jet_heatmap = jet_colors[heatmap]\n\n    # We create an image with RGB colorized heatmap\n    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n\n    # Superimpose the heatmap on original image\n    superimposed_img = jet_heatmap * 0.4 + img\n    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img[0])\n    \n    return superimposed_img, CLASSES[np.argmax(saved_Model.predict(img_array))]","6b8aef1c":"covid_filenames = tf.io.gfile.glob('..\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/COVID-19\/*')\npneumonia_filenames = tf.io.gfile.glob('..\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/Viral Pneumonia\/*')","8954c86e":"plt.figure(figsize=(20,20))\nfor n in range(10):\n    ax = plt.subplot(5,5,n+1)\n    img, pred = superimposed_cam(covid_filenames[n])\n    plt.imshow(img)\n    plt.title(pred)\n    plt.axis(\"off\")\nfor n in range(10, 20):\n    ax = plt.subplot(5,5,n+1)\n    img, pred = superimposed_cam(pneumonia_filenames[n])\n    plt.imshow(img)\n    plt.title(pred)\n    plt.axis(\"off\")","dbc412c3":"Divide the set into training, validation, and testing sets.","d9843592":"# **Ploting Activation Map**","556f8a01":"# **MODEL TRAINING**","da499bd0":"# Make grad-CAM heatmap\n\nLet's define our grad-CAM function. We need to identify our last convolution layer. For our model, this would be the convolution layer within our `sequential_3` model in our summary above. Since we only need the outputs of the layer and not the actual layer itself, we can specify `sequential_3`, our 7th layer in oour model, as the last convolution layer.\n\nWe also need to specifiy our classifying layers. The flatten layer and the layers that follow it does the classifying for us so we'll label `layers[-5:]` as our classifying layers.","82c0a023":"Our original model from the pneumonia notebook was used as a binary classifier, but our dataset has three classes. Therefore, before we train our model, we have to pop our top level classifying layer and replace it with a 3-node dense layer. Thankfully, Keras API makes this change simple.","973afc8a":"# Liberaries\n\n","81b387df":"The top two rows are COVID-19 images and the botton two rows are Pneumonia images. Parts of the image that are redder on the rainbow spectrum are the more \"important\" parts of the image, as defined by the CNN, and purple parts of the image are less important.\n","8036308d":"# Load the images","2adf55df":"# Define superimposing function\n\nLet's superimpose the heatmap on the original image to visualize what the CNN marks as important and is used to classify the image.","6fbb8836":"# Grad-CAM Setup\n\nCheck out Keras IO [Grad-CAM Code Example](https:\/\/keras.io\/examples\/vision\/grad_cam\/) for the original source code.\n\nTo start, let's first look at the structure of our model.","d25a2c6f":"# Visualize our images","18747143":"Define the function to get a NumPy repressentation of our image.","75eb6fcf":"We correctly classify all of our testing images as well! Even though we had a very limited number of images, we could build a great model by loading in a pre-trained model.","21a895a4":"The following functions will help us format our dataset into the necessary (image, label) tuple for easy training. We also one-hot encode our labels (i.e. [1 0 0] means NORMAL).","df0ea0ec":"We need to get the output of the last convolution layer. Because I used Sequential instead of Functional API for my pneumonia model in my other notebook, the blocks that I used show us as nested Sequential models instead of as individual layers. That's not a problem because we can look at the structures of internal models as well.","1a06d705":"# Load in our saved model\n\nKeras has an easy API to just load in previously trained models. The weights of the model will be preserved as well. First, let's define an early stopping callback.","21c88e38":"# Evaluate our model","188974be":"# Visualize class activation mapping\n\nLet's compare what the model uses to classify COVID-19 X-rays versus Pneumonia X-rays."}}