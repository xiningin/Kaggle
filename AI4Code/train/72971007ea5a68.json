{"cell_type":{"2ebefe2a":"code","0e286002":"code","9db52a48":"code","65949cc9":"code","b93e01a6":"code","748b68a5":"code","028d2118":"markdown","fd35a935":"markdown","aad166ec":"markdown","237d8f20":"markdown","482caf5d":"markdown"},"source":{"2ebefe2a":"#### paths\nx_train_path='..\/input\/numpy-for-rsna-compet-flair\/x_train_dataset.npy'\ny_train_path='..\/input\/numpy-for-rsna-compet-flair\/y_train_dataset.npy'\nx_val_path='..\/input\/numpy-for-rsna-compet-flair\/x_val_dataset.npy'\ny_val_path='..\/input\/numpy-for-rsna-compet-flair\/y_val_dataset.npy'","0e286002":"import numpy as np\nx_train = np.load(x_train_path)\ny_train = np.load(y_train_path)\nx_val = np.load(x_val_path)\ny_val = np.load(y_val_path)","9db52a48":"import random\nimport tensorflow as tf\n\nfrom scipy import ndimage\n\n@tf.function\ndef rotate(volume):\n    \"\"\"Rotate the volume by a few degrees\"\"\"\n\n    def scipy_rotate(volume):\n        # define some rotation angles\n        angles = [-5, 5]\n        # pick angles at random\n        angle = random.choice(angles)\n        # rotate volume\n        volume = ndimage.rotate(volume, angle, reshape=False)\n        volume[volume < 0] = 0\n        volume[volume > 1] = 1\n        return volume\n\n    augmented_volume = tf.numpy_function(scipy_rotate, [volume], tf.float32)\n    return augmented_volume\n\n\ndef train_preprocessing(volume, label):\n    \"\"\"Process training data by rotating and adding a channel.\"\"\"\n    # Rotate volume\n    volume = rotate(volume)\n    volume = tf.expand_dims(volume, axis=3)\n    return volume, label\n\n\ndef validation_preprocessing(volume, label):\n    \"\"\"Process validation data by only adding a channel.\"\"\"\n    volume = tf.expand_dims(volume, axis=3)\n    return volume, label","65949cc9":"# Define data loaders.\ntrain_loader = tf.data.Dataset.from_tensor_slices((x_train, y_train))\nvalidation_loader = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n\nbatch_size = 2\n# Augment the on the fly during training.\ntrain_dataset = (\n    train_loader.shuffle(len(x_train))\n    .map(train_preprocessing)\n    .batch(batch_size)\n    .prefetch(2)\n)\n# Only rescale.\nvalidation_dataset = (\n    validation_loader.shuffle(len(x_val))\n    .map(validation_preprocessing)\n    .batch(batch_size)\n    .prefetch(2)\n)","b93e01a6":"from tensorflow import keras\nfrom tensorflow.keras import layers\n\ndef get_model(width=128, height=128, depth=64):\n    \"\"\"Build a 3D convolutional neural network model.\"\"\"\n\n    inputs = keras.Input((width, height, depth, 1))\n\n    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n\n    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n\n    x = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n\n    x = layers.Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n\n    x = layers.GlobalAveragePooling3D()(x)\n    x = layers.Dense(units=512, activation=\"relu\")(x)\n    x = layers.Dropout(0.3)(x)\n\n    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n\n    # Define the model.\n    model = keras.Model(inputs, outputs, name=\"3dcnn\")\n    return model\n\n\n# Build model.\nmodel = get_model(width=128, height=128, depth=64)","748b68a5":"# Compile model.\ninitial_learning_rate = 0.0001\nlr_schedule = keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n)\nmodel.compile(\n    loss=\"binary_crossentropy\",\n    optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n    metrics=[\"acc\"],\n)\n\n# Define callbacks.\ncheckpoint_cb = keras.callbacks.ModelCheckpoint(\n    \"3d_image_classification.h5\", save_best_only=True\n)\nearly_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_acc\", patience=30)\n\n# Train the model, doing validation at the end of each epoch\nepochs = 5\nmodel.fit(\n    train_dataset,\n    validation_data=validation_dataset,\n    epochs=epochs,\n    shuffle=True,\n    verbose=2,\n    callbacks=[checkpoint_cb, early_stopping_cb],\n)","028d2118":"# Applying data augmentation","fd35a935":"# Building the CNN","aad166ec":"Here we load the data to tf.data to facilitate the processing by the CNN","237d8f20":"# Training","482caf5d":"# Loading the dataset"}}