{"cell_type":{"e5d49a59":"code","ab39eb5c":"code","f991745d":"code","24b25954":"code","739ce2e6":"code","16e5c68e":"code","3f584159":"code","363453da":"code","9eaaba8c":"code","20acf7dd":"code","36f9c05f":"code","17f9e5e7":"code","552cee6f":"code","4f7e8bdd":"code","218567db":"markdown","053c142c":"markdown","2a2229db":"markdown","fdf9eaee":"markdown","42cfe081":"markdown","8c9013b4":"markdown","0e4577dd":"markdown","f95ffe4b":"markdown","bbd7a1e8":"markdown","c826ba69":"markdown","2e6b34ef":"markdown","05bc0480":"markdown","82e22ea4":"markdown","41c93d5b":"markdown","5724a401":"markdown","83d5cc6b":"markdown","4618dd90":"markdown","48951078":"markdown"},"source":{"e5d49a59":"# Datum: 14.11.2020","ab39eb5c":"import pandas as pd\n##  allows to prepocess the data and create matrix of features and the dependable variable vector\n\nimport numpy as np\n## allows working with arrays\n\nimport matplotlib.pyplot as plt\n## allow plotting charts","f991745d":"dataset=pd.read_csv(\"Data.csv\")\ndataset","24b25954":"x=dataset.iloc[:,:-1].values \ny= dataset.iloc[:, -1].values\n\n## [ROWS: All, COLUMNS everything: except the last columns for x, AND The last Column for Y]\n## values - alloes to take all values in all the rows and columns without the header","739ce2e6":"from sklearn.impute import SimpleImputer  ## SimpleImputer class\nimputer=SimpleImputer(missing_values=np.nan, strategy='mean') ##  mean is by default\n\n## So here is pretty simple: you say how your missing values look like:NAN--> np.nan\n## and then you specify how you want it to get replaced --> by mean values\n\nx[:,1:3]=imputer.fit_transform(x[:,1:3]) # Then you Fit the imputer  and Apply on X.\nprint(x)\n","16e5c68e":"from sklearn.compose import ColumnTransformer \n## Applies transformers to columns of an array or pandas DataFrame.\n\n\n\nfrom sklearn.preprocessing import OneHotEncoder\n## Encode categorical features as a one-hot numeric array.","3f584159":"ct=ColumnTransformer(\n    transformers=[(\n        \"encoder\",\n        OneHotEncoder(),\n        [0])], \n        remainder=\"passthrough\")\n\n## Okay, that part was the trickiest\n## Column Transformer allows to transform columns\n#if you look at the documentation of One Hot Encoder, it says it is encodes categories of data, which is perfect\n# So in nutshell, we ask to transform the column of the country with a particular encoder class (OneHotEncoder)\n# we give it a name (\"encoder\"), I tested, you can write whatever you want\n# Then you specify the column of the categorical data\n\n#Be careful with parenthesis. It shall be like a list of tupels \n# I still miss a parenthesis or a bracket.\n\n# And very important to specify the remainder, so it can passthrough all other columns while the transformation","363453da":"x=np.array(ct.fit_transform(x)) #force to be an NP array\n\n# I don't know why, but at the course, they said it is importnant for the future model to have an np_array","9eaaba8c":"from sklearn.preprocessing import LabelEncoder\n\n# Holds the label for each class.","20acf7dd":"le=LabelEncoder()\ny=le.fit_transform(y) ## no need for np_array\ny","36f9c05f":"from sklearn.model_selection import train_test_split\n##Create 4 different sets (matrix for train and test sex)","17f9e5e7":"x_train, x_test, y_train, y_test=train_test_split(x,y,test_size=0.2, random_state=1)\n# Test Size: 0.2 --> 20% goes to test\n# Random State -- Any number can be there, to make sure that once the random data has been selected, \n# it stays the same for the next time we run the code\n# Apparently it takes random values from dataset everytime we run (correct me if I am wrong)\n\n\n#From Documentation: \n\n## Controls the shuffling applied to the data before applying the split. \n# Pass an int for reproducible output across multiple function calls","552cee6f":"from sklearn.preprocessing import StandardScaler\nsc=StandardScaler() ## it will automatically standartdize\nx_train[:,3:4]=sc.fit_transform(x_train[:,3:4])\n","4f7e8bdd":"x_test[:,3:4]=sc.transform(x_test[:,3:4]) ## need to be scaled by the same scaler\n# So no Fit function for the Test set","218567db":"before we were preparing the data, now we need to divide the data for Train Set and Test Set\n\nSo far as I understood, \n- the Train set is where we are going to train the model on existing data\n-  Test Set - to evaluate the performance of the model on the future-like data","053c142c":"https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.StandardScaler.html","2a2229db":"**That's so far I get on the pre-processing data, if you have some recommendations, what are better ways to prepare data for pre-processing, just let me know.\n**","fdf9eaee":"Next step is removing missing values. As for normal exploratory analysis missing values do mess up with the graphs and it is always better to get rid of them. The same story is for machine learning. In the dataset there are missing values in the column Age and Salary, which is better to get rid of. I guess you can remove of the missing values just using Pandas, but you can also use sklearn package, to clean your dataset, by either deleting values if the dataset is large, or replace them with mean or median, frequent met values, depend on what you think is the best for the data analysis :)","42cfe081":"Scaling all your features to make sure they all take values in the same scale to prevent the dominations\n- Scaling shall be done after the spliting the test to prevent taking the Test Set ( which is playing the role here of the future-like observation) \n- Standartization and Normalization of the data \n    - Standardisation (x-mean(X)\/standard deviation) puts the data in the range of -3 and +3\n    - Normalisation (x-min(x)\/(max(x)-min(x))) puts the data in the range between 0 and 1\n","8c9013b4":"https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.train_test_split.html","0e4577dd":"For machine learning we need to have two important parts of the dataset,matrix of features and dependable variable vector. Matrix of features is the features that are located on the first columns (Country, Age, Salary) and they are independent variables that will influence the outcome, the last column (Purchases). \n\n\n- Independable Features Matrix (\"Country\", \"Age\", \"Salary\") =X\n- Dependable Variable (\"Purchased\") =Y","f95ffe4b":"The most surprising moment in the machine learning was the encoding the categorical data. We had three countries in the column \"Countries\", so I did not expect that we needed to encode. As I understood, if you replace each country by particular number, the program might think that there is an order for this dataset, which will definitely mess up with the dataset. So the teacher recommended OneHotEncoder (which sounds pretty fun actually)","bbd7a1e8":"You can do separately Fit to X and then to Transform, but this class has fit_transform, so you can use that too","c826ba69":"https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.impute.SimpleImputer.html","2e6b34ef":"##  Feature Scaling","05bc0480":"We need to create 4 different sets (matrix for train and test set)\n\nWhy 4? Well, we need to divide the dataset: 80% of data goes to Train and 20% goes to test\nand we need to divide the independent and dependant variables","82e22ea4":"## Splitting the dataset into the Training set and Test set","41c93d5b":" For a Yes and No data, we have just used a SimpleEncoder, that replaces Yes for 1 and No for 0\n ","5724a401":"I am a beginner at machine learning and it took me awhile to understand the lecture on Udemy about pre-processing data with sklearn for machine learning.\n- I tried to recreate the code 3 times to understand the code and process\n- Here I want to write the code again with explanation of the particular points of the code for my own understanding and maybe if someone is learning machine learning, it will be also helpful. ","83d5cc6b":"https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.LabelEncoder.html","4618dd90":"https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.OneHotEncoder.html\nhttps:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.compose.ColumnTransformer.html","48951078":"When you apply the StandardSaler,you need to apply only to your non-binary code, otherwise you will mess up with one hot encoded categorial data and you will have no idea, what are results for."}}