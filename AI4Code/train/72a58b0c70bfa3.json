{"cell_type":{"138eb71b":"code","c6ec56b0":"code","b15a2405":"code","487d975f":"code","4fff048a":"code","3277c28c":"code","a99c447a":"code","41f0d76b":"code","e0d93824":"code","4734c586":"code","7993c43c":"code","9b263be9":"code","a0975e92":"code","5071fd78":"code","f8d1df89":"code","12070585":"code","981b728b":"code","0522c101":"code","a08bba5e":"code","7aba8c33":"code","de047d4a":"code","269a6e64":"code","f859cf14":"code","0b44bbb6":"code","57367858":"code","16e25b2e":"code","821052bd":"code","d5770d5e":"code","5d2aa7fc":"code","d184518d":"code","53f86680":"code","94238ecf":"code","cc2ccd2d":"code","810bcf64":"code","30c82281":"markdown","91a83106":"markdown"},"source":{"138eb71b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c6ec56b0":"import matplotlib.pyplot as plt \nimport seaborn as sns \nimport spacy \nfrom tqdm import tqdm\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation,  PCA, NMF\nimport random ","b15a2405":"df = pd.read_csv('\/kaggle\/input\/covid19-public-media-dataset\/covid19_articles_20200512.csv',index_col='Unnamed: 0')\n\ndf2 = pd.read_csv('\/kaggle\/input\/covid19-public-media-dataset\/covid19_articles_20200526.csv',index_col='Unnamed: 0')\ndf2.head()\n\ndf3 = pd.read_csv('\/kaggle\/input\/covid19-public-media-dataset\/covid19_articles_20200504.csv',index_col='Unnamed: 0')\ndf3.head()\n\n# concatenating sources \ndf = pd.concat([df,df2,df3],ignore_index=True)\ndf.head()","487d975f":"# visualize sources and their counts \norder_by = df['domain'].value_counts().index\nsns.catplot(data=df,x='domain',kind='count',aspect=3,order=order_by)\nplt.xticks(rotation=90)\nplt.show()","4fff048a":"# topic areas\n# here we can see 7 topic_areas, where general category is in majority \norder_by = df['topic_area'].value_counts().index\nsns.catplot(kind='count',x='topic_area',aspect=3,data=df,order=order_by)\nplt.show()","3277c28c":"# dates aggregation \ndf.date.value_counts().sort_index().plot()\nplt.xticks(rotation=90)\nplt.show()","a99c447a":"nlp = spacy.load('en_core_web_sm',disable=['parser','ner','tokenizer'])","41f0d76b":"# from https:\/\/www.kaggle.com\/jannalipenkova\/covid-19-media-overview\nRELEVANT_POS_TAGS = [\"PROPN\", \"VERB\", \"NOUN\", \"ADJ\"]\n\nCUSTOM_STOPWORDS = [\"say\", \"%\", \"will\", \"new\", \"would\", \"could\", \"other\", \n                    \"tell\", \"see\", \"make\", \"-\", \"go\", \"come\", \"can\", \"do\", \n                    \"such\", \"give\", \"should\", \"must\", \"use\"]\n","e0d93824":"# Data Preprocessing \ndef preprocess(txt):\n  '''\n  Take text pass through spacy's pipeline \n  Normalize text using remove stopwords from CUSTOM_STOPWORDS, take words which are RELEVENT_POS_TAGS and\n  take lemma and use that in smaller version of alphabet\n  '''\n  doc = nlp(txt)\n  rel_tokens = \" \".join([tok.lemma_.lower() for tok in doc if tok.pos_ in RELEVANT_POS_TAGS and tok.lemma_.lower() not in CUSTOM_STOPWORDS])\n  return rel_tokens","4734c586":"tqdm.pandas()\nprocessed_content = df[\"content\"].progress_apply(preprocess)\ndf[\"processed_content\"] = processed_content","7993c43c":"cv = CountVectorizer(max_features=2**11,min_df=10,stop_words='english') # count vectorizer","9b263be9":"dtm = cv.fit_transform(df['processed_content'])","a0975e92":"LDA = LatentDirichletAllocation(n_components=7,random_state=42,n_jobs=-1) # LDA topic Modeling Technique","5071fd78":"LDA.fit(dtm)","f8d1df89":"# get the vocabulary length of words \nlen(cv.get_feature_names())","12070585":"# get some random words \nrandom_word_id = random.randint(0,2048)\ncv.get_feature_names()[10]","981b728b":"# get the topics \nLDA.components_","0522c101":"LDA.components_.shape","a08bba5e":"single_topic = LDA.components_[0]","7aba8c33":"# get the last 10 values which has high prob\ntop_ten_words = single_topic.argsort()[-10:]","de047d4a":"# from here we can see, that words like \"Pay, company, coronavirus, worker \" are related to business \nfor index in top_ten_words:\n    print(cv.get_feature_names()[index])","269a6e64":"# get the highest probability words per topic \nfor i,topic in enumerate(LDA.components_):\n    print(f'The top 25 words for topic #{i}')\n    print([cv.get_feature_names()[index] for index in topic.argsort()[-25:]])\n    print('\\n\\n')\n\n# Here we can check topic#1 related to financial, topic # 3 relates to tech, ","f859cf14":"topic_results = LDA.transform(dtm)","0b44bbb6":"df['Topic'] = topic_results.argmax(axis=1)","57367858":"tfidf = TfidfVectorizer(max_features=2**11,min_df=10, stop_words='english')","16e25b2e":"dtm = tfidf.fit_transform(df['processed_content'])","821052bd":"nmf_model  = NMF(n_components=7,random_state=42)","d5770d5e":"nmf_model.fit(dtm)","5d2aa7fc":"tfidf.get_feature_names()[1480]","d184518d":"for i,topic in enumerate(nmf_model.components_):\n    print(f'The top 25 words for topic #{i}')\n    print([tfidf.get_feature_names()[index] for index in topic.argsort()[-25:]])","53f86680":"#  Here we can see that \n# nmfNumeric_to_topic = {0:'',1:'finance',2:'',3:'business',4:'healthcare',5:'',6:''}\n#it depends on how we infer topics","94238ecf":"topic_results = nmf_model.transform(dtm)","cc2ccd2d":"df['NMF_Topic'] = topic_results.argmax(axis=-1)","810bcf64":"df.head()","30c82281":"# Non-Negative Matrix Factorization\nNMF with clustering also performs dimensionality reduction","91a83106":"# Latent Dirichlet Allocation\nLDA performs clustering inside, and is topic modeling technique.\nIt assumes that similar topics shares similar group of words or vocab."}}