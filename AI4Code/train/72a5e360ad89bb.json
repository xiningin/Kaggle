{"cell_type":{"644b41db":"code","b7257351":"code","60c31ca4":"code","4a9a788f":"code","a49ef183":"code","59a2b538":"code","39af54e6":"code","5871e7f2":"code","6e499825":"code","1e04dadc":"code","e8319715":"code","4cc3923f":"code","3b1362ed":"code","ed16e8e4":"code","bf81d64e":"code","abd3802c":"code","631f01d8":"code","38bbc93a":"code","d7af82f7":"code","0fbbfe6f":"code","1933cd8c":"code","b3dc8212":"code","489a44b2":"code","f6848928":"code","f50d4e25":"code","e34b2598":"code","72328f5c":"code","2257cdea":"code","a7a7ddfa":"code","45e557a5":"code","bbbde854":"code","fbd8e03b":"code","aadb94f9":"code","8b5df772":"code","280a5519":"code","18932436":"code","d8b5d079":"code","2c7a536f":"code","b1d0514a":"code","65132022":"code","8c6a7cc8":"code","8d461ba9":"code","53f1c6b9":"code","b7c6f40f":"code","8dbc9427":"code","e72a991b":"code","3b830074":"code","aa7802dd":"code","8a566e30":"code","abf8d5ce":"code","e141b391":"code","d7f520e7":"code","4159dd62":"code","a80f5782":"code","236ec694":"code","0f4aeb8b":"code","7669a2d8":"code","413529dc":"code","20311c96":"code","d7e63c2c":"code","66f0b8dd":"code","24064b06":"code","6a8c08b2":"code","629317a4":"code","e88f2531":"code","b2db9a89":"code","03fd66a2":"code","a9889ae5":"markdown","90e90f61":"markdown","3dc2151e":"markdown","d935ed9c":"markdown","ea6aa89b":"markdown","b86646e7":"markdown","47ff1a0c":"markdown","a0a4c197":"markdown","02ce0421":"markdown","7feddf56":"markdown","57cfae96":"markdown","b828c089":"markdown","ec51c7ac":"markdown"},"source":{"644b41db":"import pandas as pd\nimport numpy as np","b7257351":"df=pd.read_csv(r\"..\/input\/phishing-website-detector\/phishing.csv\")","60c31ca4":"df.head()","4a9a788f":"df.columns","a49ef183":"df.head()","59a2b538":"df.shape","39af54e6":"df.isnull().sum()","5871e7f2":"from sklearn.model_selection import train_test_split,cross_val_score","6e499825":"X= df.drop(columns='class')\nX.head()","1e04dadc":"Y=df['class']\nY=pd.DataFrame(Y)\nY.head()","e8319715":"train_X,test_X,train_Y,test_Y=train_test_split(X,Y,test_size=0.3,random_state=2)","4cc3923f":"print(train_X.shape)\nprint(test_X.shape)\nprint(train_Y.shape)\nprint(test_Y.shape)","3b1362ed":"from sklearn.linear_model import LogisticRegression\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report","ed16e8e4":"logreg=LogisticRegression()\nmodel_1=logreg.fit(train_X,train_Y)","bf81d64e":"logreg_predict= model_1.predict(test_X)","abd3802c":"accuracy_score(logreg_predict,test_Y)","631f01d8":"print(classification_report(logreg_predict,test_Y))","38bbc93a":"def plot_confusion_matrix(test_Y, predict_y):\n C = confusion_matrix(test_Y, predict_y)\n A =(((C.T)\/(C.sum(axis=1))).T)\n B =(C\/C.sum(axis=0))\n plt.figure(figsize=(20,4))\n labels = [1,2]\n cmap=sns.light_palette(\"blue\")\n plt.subplot(1, 3, 1)\n sns.heatmap(C, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n plt.xlabel('Predicted Class')\n plt.ylabel('Original Class')\n plt.title(\"Confusion matrix\")\n plt.subplot(1, 3, 2)\n sns.heatmap(B, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n plt.xlabel('Predicted Class')\n plt.ylabel('Original Class')\n plt.title(\"Precision matrix\")\n plt.subplot(1, 3, 3)\n sns.heatmap(A, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n plt.xlabel('Predicted Class')\n plt.ylabel('Original Class')\n plt.title(\"Recall matrix\")\n plt.show()","d7af82f7":"plot_confusion_matrix(test_Y, logreg_predict)","0fbbfe6f":"from sklearn.neighbors import KNeighborsClassifier","1933cd8c":"knn=KNeighborsClassifier(n_neighbors=3)\nmodel_2= knn.fit(train_X,train_Y)","b3dc8212":"knn_predict=model_2.predict(test_X)","489a44b2":"accuracy_score(knn_predict,test_Y)","f6848928":"print(classification_report(test_Y,knn_predict))","f50d4e25":"plot_confusion_matrix(test_Y, knn_predict)","e34b2598":"from sklearn.tree import DecisionTreeClassifier","72328f5c":"dtree=DecisionTreeClassifier()\nmodel_3=dtree.fit(train_X,train_Y)","2257cdea":"dtree_predict=model_3.predict(test_X)","a7a7ddfa":"accuracy_score(dtree_predict,test_Y)","45e557a5":"print(classification_report(dtree_predict,test_Y))","bbbde854":"plot_confusion_matrix(test_Y, dtree_predict)","fbd8e03b":"from sklearn.ensemble import RandomForestClassifier","aadb94f9":"rfc=RandomForestClassifier()\nmodel_4=rfc.fit(train_X,train_Y)","8b5df772":"rfc_predict=model_4.predict(test_X)","280a5519":"accuracy_score(rfc_predict,test_Y)","18932436":"print(classification_report(rfc_predict,test_Y))","d8b5d079":"plot_confusion_matrix(test_Y, rfc_predict)","2c7a536f":"from sklearn.svm import SVC","b1d0514a":"svc=SVC()\nmodel_5=svc.fit(train_X,train_Y)","65132022":"svm_predict=model_5.predict(test_X)","8c6a7cc8":"accuracy_score(svm_predict,test_Y)","8d461ba9":"print(classification_report(svm_predict,test_Y))","53f1c6b9":"plot_confusion_matrix(test_Y, svm_predict)","b7c6f40f":"from sklearn.ensemble import AdaBoostClassifier","8dbc9427":"adc=AdaBoostClassifier(n_estimators=5,learning_rate=1)\nmodel_6=adc.fit(train_X,train_Y)","e72a991b":"adc_predict=model_6.predict(test_X)","3b830074":"accuracy_score(adc_predict,test_Y)","aa7802dd":"print(classification_report(adc_predict,test_Y))","8a566e30":"plot_confusion_matrix(test_Y, adc_predict)","abf8d5ce":"from xgboost import XGBClassifier","e141b391":"xgb=XGBClassifier()\nmodel_7=xgb.fit(train_X,train_Y)","d7f520e7":"xgb_predict=model_7.predict(test_X)","4159dd62":"accuracy_score(xgb_predict,test_Y)","a80f5782":"plot_confusion_matrix(test_Y, xgb_predict)","236ec694":"print('Logistic Regression Accuracy:',accuracy_score(logreg_predict,test_Y))\nprint('K-Nearest Neighbour Accuracy:',accuracy_score(knn_predict,test_Y))\nprint('Decision Tree Classifier Accuracy:',accuracy_score(dtree_predict,test_Y))\nprint('Random Forest Classifier Accuracy:',accuracy_score(rfc_predict,test_Y))\nprint('support Vector Machine Accuracy:',accuracy_score(svm_predict,test_Y))\nprint('Adaboost Classifier Accuracy:',accuracy_score(adc_predict,test_Y))\nprint('XGBoost Accuracy:',accuracy_score(xgb_predict,test_Y))","0f4aeb8b":"df.columns","7669a2d8":"X=df[['PrefixSuffix-','AnchorURL']]\nX.head()","413529dc":"train_X,test_X,train_Y,test_Y=train_test_split(X,Y,test_size=0.3,random_state=2)","20311c96":"print(train_X.shape)\nprint(test_X.shape)\nprint(train_Y.shape)\nprint(test_Y.shape)","d7e63c2c":"model_8=logreg.fit(train_X,train_Y)","66f0b8dd":"logreg_predict=model_8.predict(test_X)","24064b06":"accuracy_score(test_Y,logreg_predict)","6a8c08b2":"logreg.classes_","629317a4":"x = np.array(X)\nx","e88f2531":"X = X.to_numpy()\ny = df['class']\ny= y.to_numpy()","b2db9a89":"from mlxtend.plotting import plot_decision_regions","03fd66a2":"plot_decision_regions(x, y, clf=model_1, legend=2)\n\n# Adding axes annotations\nplt.xlabel('features')\nplt.ylabel('class')\nplt.title('Logistic regression')\nplt.show()","a9889ae5":"From all the models we developed , Random forest accuracy has highest accuracy and followed by decision tree and XGBoost. Lowest accuracy model is SVM. ","90e90f61":"**Lets apply Decision Tree Classifier and check its classifier **","3dc2151e":"**Lets Apply SVM and check its accuracy**","d935ed9c":" **TO BE CONTINUED**","ea6aa89b":"**Lets apply K-Nearest Neighbors Classifier and check its accuracy**","b86646e7":"**Lets apply Random Forest Classifier and check its accuracy**","47ff1a0c":"Now lets apply logistic Regression for this new model which is having only two features","a0a4c197":"Now lets consider only two imporatant features Prefix_Suffix and URL_of_Anchor.","02ce0421":"**Lets apply Logistic Regression and check its accuracy**","7feddf56":"**Lets apply AdaBoost Classifier and check its accuracy **","57cfae96":"Lets apply XGBoost Classifier and check its accuracy","b828c089":"Plot for only Logistic regression is made \nPlots for remaining model will be made soon ","ec51c7ac":"Now lets plot the decision boundary "}}