{"cell_type":{"d0b1f477":"code","3ac4c7d2":"code","1614aae6":"code","354602a4":"code","35785ae4":"code","d99236f4":"code","db2ab351":"code","b61c5e8c":"code","4c67eb7e":"code","c993d804":"code","a43ec755":"code","867bef58":"code","c03fa2e8":"code","755fc826":"code","43df3ba9":"code","5ea7abab":"code","84215c03":"code","aa8604f6":"code","f8515a24":"code","e1ba1914":"code","309ee106":"code","2c76a440":"code","47559f16":"code","75aa1aa3":"code","40532593":"code","3580d4b3":"code","2dba5ab7":"code","1564e507":"code","30477271":"code","297f6a99":"code","5a9e7f69":"code","cf789e24":"code","5d30957d":"code","04f76ef2":"code","00438c95":"code","335d1a8d":"code","d147818d":"code","8cadb419":"code","ff41b275":"code","900d71f6":"code","1c34e162":"markdown","3dc2b001":"markdown","d6484a30":"markdown","cb0873c4":"markdown","478d750e":"markdown","fbbc5d50":"markdown","30b8ded2":"markdown","3061146f":"markdown","90fe767c":"markdown","f3b0966b":"markdown","1e40c361":"markdown","674ea690":"markdown","3ce14340":"markdown","e72486f2":"markdown","f427828b":"markdown","30987a05":"markdown","f57064cb":"markdown","44e87c4d":"markdown","403685bc":"markdown","a6a53652":"markdown","180a01ae":"markdown"},"source":{"d0b1f477":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3ac4c7d2":"import matplotlib.pyplot as plt\nimport seaborn as sns","1614aae6":"from sklearn.model_selection import KFold\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import f1_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import VotingClassifier\nimport pickle\nimport joblib\nimport gc","354602a4":"train = pd.read_csv('\/kaggle\/input\/kakr-4th-competition\/train.csv', index_col = \"id\")\ntest = pd.read_csv('\/kaggle\/input\/kakr-4th-competition\/test.csv', index_col = \"id\")","35785ae4":"y = train['income'] == '>50K'\nX = train.drop(['income'], axis=1)","d99236f4":"'''import category_encoders as ce\n\nohe = ce.OneHotEncoder(use_cat_names = True)\nohe.fit(X)\nX = ohe.transform(X)\ntest_X = ohe.transform(test)'''","db2ab351":"from category_encoders.ordinal import OrdinalEncoder\nle = OrdinalEncoder(list(X.columns))\n\nX = le.fit_transform(X, y)\ntest_X = le.transform(test)","b61c5e8c":"X.head()","4c67eb7e":"X.shape","c993d804":"test_X.shape","a43ec755":"NFOLDS = 5\nfolds = KFold(n_splits = NFOLDS)\n\ncolumns = X.columns\nsplits = folds.split(X, y)\nlgbm_preds = np.zeros(test_X.shape[0])","867bef58":"lgbm = LGBMClassifier(objective='binary', verbose = 1, random_state = 17,\n                     boosting_type = 'gbdt', learning_rate = 0.1)\n\n\nfor fold_n, (train_index, valid_index) in enumerate(splits):\n    print('Fold: ', fold_n+1)\n    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n\n    evals = [(X_train, y_train), (X_valid, y_valid)]\n    lgbm.fit(X_train, y_train, eval_metric='f1', eval_set=evals, verbose=True)\n        \n    lgbm_preds += lgbm.predict(test_X).astype(int) \/ NFOLDS\n    \n    del X_train, X_valid, y_train, y_valid\n    gc.collect()","c03fa2e8":"def make_sub(predicts, filename):\n    sample_submission = pd.read_csv('\/kaggle\/input\/kakr-4th-competition\/sample_submission.csv')\n    sample_submission['prediction'] = predicts\n\n    for ix, row in sample_submission.iterrows():\n        if row['prediction'] > 0.5:\n            sample_submission.loc[ix, 'prediction'] = 1\n        else:\n            sample_submission.loc[ix, 'prediction'] = 0\n\n    sample_submission = sample_submission.astype({\"prediction\": int})\n    sample_submission.to_csv(path_or_buf = filename, index=False)","755fc826":"make_sub(lgbm_preds, \"LGBMsubmissions.csv\")","43df3ba9":"XGB = XGBClassifier(gamma = 0.01, learning_rate = 0.1,\n                    max_depth = 7, min_child_weight = 3, random_state = 17)","5ea7abab":"NFOLDS = 5\nfolds = KFold(n_splits = NFOLDS)\n\ncolumns = X.columns\nsplits = folds.split(X, y)\nXGB_preds = np.zeros(test_X.shape[0])","84215c03":"def f1_eval(y_pred, dtrain):\n    y_true = dtrain.get_label()\n    err = 1-f1_score(y_true, np.round(y_pred), average = \"micro\")\n    return 'f1_err', err","aa8604f6":"for fold_n, (train_index, valid_index) in enumerate(splits):\n    print('Fold: ', fold_n+1)\n    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n\n    evals = [(X_train, y_train), (X_valid, y_valid)]\n    XGB.fit(X_train, y_train, eval_metric=f1_eval, eval_set=evals, verbose=True)\n        \n    XGB_preds += XGB.predict_proba(test_X)[:, 1] \/ NFOLDS\n    \n    del X_train, X_valid, y_train, y_valid\n    gc.collect()","f8515a24":"make_sub(predicts = XGB_preds, filename = \"XGBsubmissions.csv\")","e1ba1914":"rf = RandomForestClassifier(max_features = 3, min_samples_split = 8,\n                           n_estimators = 100, criterion = \"entropy\",\n                           bootstrap = True)","309ee106":"rf.fit(X, y)","2c76a440":"RF_preds = rf.predict_proba(test_X)[:, 1]","47559f16":"make_sub(RF_preds, \"rf.csv\")","75aa1aa3":"ensemble_arith_1 = (XGB_preds + lgbm_preds + RF_preds) \/ 3","40532593":"make_sub(predicts = ensemble_arith_1, filename = \"Ensemble_arith_1.csv\")","3580d4b3":"ensemble_arith_2 = (XGB_preds + lgbm_preds) \/ 2","2dba5ab7":"make_sub(predicts = ensemble_arith_2, filename = \"Ensemble_arith_2.csv\")","1564e507":"ensemble_geo_1 = (XGB_preds * lgbm_preds * RF_preds) ** (1\/ 3)","30477271":"ensemble_geo_2 = (XGB_preds * lgbm_preds) ** (1\/ 2)","297f6a99":"make_sub(predicts = ensemble_geo_1, filename = \"Ensemble_geo_1.csv\")\nmake_sub(predicts = ensemble_geo_2, filename = \"Ensemble_geo_2.csv\")","5a9e7f69":"voting_hard = VotingClassifier(estimators = [(\"lgbm\", lgbm), (\"xgb\", XGB), (\"rf\", rf)],\n                         voting = \"hard\")","cf789e24":"voting_hard = voting_hard.fit(X, y)","5d30957d":"hard_preds = voting_hard.predict(test_X)","04f76ef2":"make_sub(hard_preds, \"voting_hard_1.csv\")","00438c95":"voting_hard = VotingClassifier(estimators = [(\"lgbm\", lgbm), (\"xgb\", XGB)],\n                         voting = \"hard\")\nvoting_hard = voting_hard.fit(X, y)\nhard_preds = voting_hard.predict(test_X)\nmake_sub(hard_preds, \"voting_hard_2.csv\")","335d1a8d":"voting_soft = VotingClassifier(estimators = [(\"lgbm\", lgbm), (\"xgb\", XGB), (\"rf\", rf)],\n                         voting = \"soft\")","d147818d":"voting_soft = voting_soft.fit(X, y)","8cadb419":"soft_preds = voting_soft.predict(test_X)","ff41b275":"make_sub(soft_preds, \"voting_soft_1.csv\")","900d71f6":"voting_soft = VotingClassifier(estimators = [(\"lgbm\", lgbm), (\"xgb\", XGB), (\"rf\", rf)],\n                         voting = \"soft\")\nvoting_soft = voting_soft.fit(X, y)\nsoft_preds = voting_soft.predict(test_X)\nmake_sub(soft_preds, \"voting_soft_2.csv\")","1c34e162":"### Soft","3dc2b001":"## \uc0b0\uc220\ud3c9\uade0","d6484a30":"# RF","cb0873c4":"# LGBM","478d750e":"### Hard Voting","fbbc5d50":"gridsearch\ub85c \ucc3e\uc740 \ud558\uc774\ud37c \ud30c\ub77c\ubbf8\ud130 \ub123\uc5b4\uc90c","30b8ded2":"https:\/\/www.kaggle.com\/werooring\/basic-eda-lgbm-modeling-public-score-0-87714","3061146f":"## \uae30\ud558\ud3c9\uade0","90fe767c":"prediction : [\uc18c\ub4dd\uc774 50,000$\uc744 \ub118\ub294\ub2e4\uba74 1, \uc544\ub2c8\ub77c\uba74 0] <br>\n\ud0c0\uac9f\uc744 T&F \ud615\ud0dc\ub85c","f3b0966b":"## OneHot Encoding","1e40c361":"\ud655\ub960\uc5d0\uc11c \uc608\uce21 \uacb0\uacfc\ub97c \ub9cc\ub4e4\uc5b4\uc8fc\ub294 \ud568\uc218","674ea690":"## Label Encoding","3ce14340":"\uae30\ud558\ud3c9\uade0\uc744 \ube44\uc728\uc5d0 \uc4f4\ub2e4\uace0 \ubc30\uc6cc\uc11c \ud655\ub960\uc5d0\ub3c4 \uc54c\ub9de\uc9c0 \uc54a\uc744\uae4c \uc2f6\uc5b4\uc11c \ud55c \ubc88 \ud574\ubd24\uc2b5\ub2c8\ub2e4.","e72486f2":"\uc6d0\ud56b\uc778\ucf54\ub529 \uc2dc \uc2a4\ucf54\uc5b4\uac00 \ub354 \ub5a8\uc5b4\uc838\uc11c \ub77c\ubca8\ub85c \ub2e4\uc2dc \ub3cc\uc544\uc654\uc2b5\ub2c8\ub2e4.","f427828b":"# Ensemble","30987a05":"gridsearch\ub85c \ucc3e\uc544\ub0b8 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130","f57064cb":"## voting classifier","44e87c4d":"voting\uc740 fold\ud558\uc9c0 \uc54a\uc544\uc11c \ud3c9\uade0\uc744 \ub0b4\ub294 \uac83\ubcf4\ub2e4 \uc624\ud788\ub824 \ub354 \ub5a8\uc5b4\uc9c4 \uac83 \uac19\ub2e4.<br>\n\uae30\ud558\ud3c9\uade0\uc774 \ub354 \ubbfc\uac10\ud55c \ub4ef \ud558\ub2e4.<br>\n\uc608\uce21\ub825\uc774 \ub0ae\uc740 \ub79c\ub364\ud3ec\ub808\uc2a4\ud2b8\ub294 \uc81c\uac70\ud558\ub294 \ucabd\uc774 \ub354 \ub098\uc740 \uac83 \uac19\ub2e4.<br>\n\ub2e4\uc74c\uc5d0\ub294 catboost\ub97c \ud55c \ubc88 \uc2dc\ub3c4\ud574\ubcf4\uc790","403685bc":"**\ucc38\uace0**<br>\nhttps:\/\/www.kaggle.com\/subinium\/kakr-eda\nhttps:\/\/www.kaggle.com\/werooring\/basic-eda-lgbm-modeling-public-score-0-87714\nhttps:\/\/www.kaggle.com\/werooring\/4th-place-solution-simple-lgbm\nhttps:\/\/www.kaggle.com\/c\/kakr-4th-competition\/discussion\/196061","a6a53652":"# XGB","180a01ae":"id\ub97c \ud589\uc774\ub984\uc73c\ub85c \uc0ac\uc6a9"}}