{"cell_type":{"6dc61f30":"code","007489c1":"code","9c07045c":"code","3d993228":"code","69573fe6":"code","24c4af77":"code","e7441926":"code","96dc963d":"code","684ed267":"code","01db08f2":"code","e48d66b9":"code","c1adf87a":"code","7a7b801d":"code","3d0997ad":"code","580f10ab":"code","cc0f4722":"code","988e311b":"code","64f172ae":"code","e390ee1d":"markdown","428b3a4a":"markdown","bf7ce9ec":"markdown","739afca5":"markdown","6ae11b2c":"markdown","ca7bc085":"markdown","1b6cdd2f":"markdown","616e456c":"markdown","aa58bd33":"markdown","8f803563":"markdown","0d908477":"markdown","1bc450a6":"markdown","b636dd5c":"markdown"},"source":{"6dc61f30":"\nimport numpy as np # linear algebra\nimport matplotlib.pyplot as plt\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns \nfrom matplotlib.colors import ListedColormap\nfrom matplotlib import figure\nfrom cycler import cycler\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","007489c1":"df = pd.read_csv('..\/input\/federal-disasters\/database.csv')\ndf_time = (df[['County','Disaster Type','Start Date', 'End Date']][0: :])\n\n\n","9c07045c":"#Number of NaN values          \ndf_nan = df[['County','Disaster Type','Start Date', 'End Date']].isna().sum()\n\ndf_nan.head(4)","3d993228":"len(df_time.index)","69573fe6":"\n#NaN values as a percentage as total \nprint([(df_nan.sum(axis=0)), str((((539\/46185)*100))) +'%'])\n\ndf_time.head(10)\n","24c4af77":"#Remove NaN values\ndf_time.dropna(subset = [\"County\", 'End Date'], inplace=True)\ndf_time.reset_index(0).head(20)","e7441926":"#Set Date Format\ndf_time['Start_Date_A'] = pd.to_datetime(df['Start Date'], format='%m\/%d\/%Y')\ndf_time['End_Date_A'] = pd.to_datetime(df['End Date'], format='%m\/%d\/%Y')\n\ndf_time.head(5)","96dc963d":"#Create new column == Disaster Length\ndf_time['Disaster_Length'] = (df_time.Start_Date_A - df_time.End_Date_A).dt.days\n\n#Create new column == start year\ndf_time['Start_year'] = df_time['Start_Date_A'].dt.year\n\n#Replace 0 day values with 1 to indicate a Disaster length of 1 Day\ndf_time['Disaster_Length'] = df_time['Disaster_Length'].replace({0:1})\n\n#Replace all values with absolute values so all days are represented as positive numeric values\ndf_time['Disaster_Length'] = df_time['Disaster_Length'].abs()\n\ndf_time.head(10)","684ed267":"# Locating man-made and non 'natural' disasters, sorting Disaster types, and analyzing value counts\n\ndf_time = df_time.rename(columns={'Disaster Type': 'Disaster_Type'})\n\ndf_DTypes= df_time['Disaster_Type'].values\n\ndf_DTypes=pd.DataFrame(df_DTypes)\n\ndf_DType_VCounts=(df_DTypes.value_counts()).sort_values(ascending=True)\n\ndf_DType_VCounts.head(20)\n\n\n\n","01db08f2":"#List of all 'Natural' Disasters\ndf_DType_Natural=(df_DType_VCounts.drop(['Human Cause', 'Chemical', 'Dam\/Levee Break', 'Terrorism','Other'],axis=0)).sort_values(ascending=True)\n\n\n#Removing non-natural disasters from main df_time\ndf_time = df_time[(df_time.Disaster_Type != 'Human Cause') & (df_time.Disaster_Type != 'Chemical') & (df_time.Disaster_Type != 'Dam\/Levee Break') & (df_time.Disaster_Type != 'Terrorism') & (df_time.Disaster_Type != 'Other') ]\n\n\n","e48d66b9":"#Number of disasters declared per year\nyearly_dcount = df_time.groupby(['Start_year']).size()\n\nyearly_dcount=pd.DataFrame(yearly_dcount)\nyearly_dcount.columns=['Number_of_Disasters']\n\n\n#Visualizing change in total number of disasters over time \nplt.style.use('dark_background')\n\nyearly_dcount.reset_index().plot('Start_year','Number_of_Disasters', title='Number of Disasters Declared 1958-2017', xlabel='', figsize=(13, 8))\n\n","c1adf87a":"#Number of disasters declared per year\nyearly_dcount = df_time.groupby(['Start_year']).size()\n\nyearly_dcount=pd.DataFrame(yearly_dcount)\nyearly_dcount.columns=['Number_of_Disasters']\n\nyearly_dcount= yearly_dcount.reset_index()\n\n#Data distribution\nplt.hist(yearly_dcount, bins=20, rwidth=.7)\nplt.show()\n\n#Removing Outliers\n\nyearly_dcount['zscore'] = (yearly_dcount.Number_of_Disasters - yearly_dcount.Number_of_Disasters.mean() )\/yearly_dcount.Number_of_Disasters.std()\ndf_deviations=yearly_dcount[yearly_dcount['zscore']>2]\ndf_lreg = (yearly_dcount[yearly_dcount['zscore']<2])\n\n           \n#Visualizing change in total number of disasters over time \nX2 = df_lreg.iloc[:, :1].values\ny2 = df_lreg.iloc[:, 1:2].values\n\n\nfrom sklearn.model_selection import train_test_split\nX2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size = 1\/3, random_state = 0)\n\n\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X2_train, y2_train)\n\n\n# Predicting the Test set results\ny_pred = regressor.predict(X2_test)\n\n# Visualising the Training set results\nplt.scatter(X2_train, y2_train, color = '#FE7D74')\nplt.plot(X2_train, regressor.predict(X2_train), color = '#5DA0FC')\nplt.title('Number of Disasters per Year (Training set)')\nplt.xlabel('Year')\nplt.ylabel('Number of Disasters per year')\nplt.show()\n\n\n# Visualising the Test set results\nplt.scatter(X2_test, y2_test, color = '#FE7D74')\nplt.plot(X2_train, regressor.predict(X2_train), color = '#5DA0FC')\nplt.title('Number of Disasters per Year (Test set)')\nplt.xlabel('Year')\nplt.ylabel('Number of Disasters per year')\nplt.show()\n","7a7b801d":"#Dataframe with mean disaster length for each year\ndf_yearly_mean_len = df_time.groupby(['Start_year']).mean()\ndf_yearly_mean_len.reset_index().plot('Start_year','Disaster_Length', title='Change in Average Length of Disasters Declared 1958-2017', xlabel='', figsize=(13, 8))","3d0997ad":"#Preprocessing to analyze the change in the number of each type of environmental weather emergency \n\ndf_yearly_tcount = df_time.groupby(['Start_year', 'Disaster_Type']).size()\nyearly_tcount=pd.DataFrame(df_yearly_tcount)\nyearly_tcount=yearly_tcount.reset_index()\nyearly_tcount = yearly_tcount.drop(labels = [0, 1], axis=0 )\nyearly_tcount.columns = ['Start_year', 'Disaster_Type','Event_Count']\n\n#Visualization\nfig, ax = plt.subplots(figsize=(18,14))\n\n\ncolors = [\n    '#1f77b4', '#aec7e8', '#ff7f0e', '#ffbb78', '#2ca02c', '#98df8a',\n    '#d62728', '#ff9896', '#9467bd', '#c5b0d5', '#8c564b', '#c49c94',\n    '#e377c2', '#f7b6d2', '#7f7f7f']\n\ncmap = ListedColormap(colors, name=\"custom\")\n\nyearly_tcount.pivot(index='Start_year', columns = 'Disaster_Type', values='Event_Count' ).plot.bar(stacked=True, ax=ax, zorder=3,cmap=cmap)\nax.legend(ncol=3, edgecolor='w', prop={'size': 16})\n[ax.spines[s].set_visible(False) for s in ['top','right', 'left']]\nax.tick_params(axis='both', left=False, bottom=False)\nplt.title(label='Type of Weather Events Occurring each Year from 1965-2017', size=25)\n\nax.grid(axis='y', dashes=(8,3), color='grey', alpha=0.3)\nplt.xlabel(xlabel='')\nfig.savefig('Change_in_Type_of_Weather_Events')\n\n\n\n\n","580f10ab":"#Have have the type of winter storms changed since 1965?\ndf_winter = df_time[(df_time['Disaster_Type'] == 'Winter') | (df_time['Disaster_Type'] == 'Snow') | (df_time['Disaster_Type'] == 'Ice')]\n\ndf_winter.drop(columns=['Start_Date_A', 'End_Date_A'], axis=1, inplace=True)\n\ndf_winter.drop_duplicates(keep='first')\n\n#How many of each type of winter storm happened each year? \ndf_winter_tcount= df_winter.groupby(['Start_year', 'Disaster_Type']).size()\n\ndf_winter_tcount=pd.DataFrame(df_winter_tcount)\n\ndf_winter_tcount = df_winter_tcount.reset_index()\n\ndf_winter_tcount.columns=['Start_Year','Disaster_Type','Event_Count']\n\nfig, ax = plt.subplots(figsize=(16,12))\n\ndf_winter_tcount.pivot(index='Start_Year', columns = 'Disaster_Type', values='Event_Count').plot.bar(stacked=True, ax=ax, zorder=3)\nax.legend(ncol=3, edgecolor='w')\n[ax.spines[s].set_visible(False) for s in ['top','right', 'left']]\nax.tick_params(axis='both', left=False, bottom=False)\nplt.title('Type of Winter Storms Occurring each Year (1965-2017)', size=25, pad=2)\nplt.xlabel(xlabel='')\nax.grid(axis='y', dashes=(8,3), color='grey', alpha=0.3)\n\n\n\n\n\n\n","cc0f4722":"df_winter_length = df_winter.drop(columns=['County','Disaster_Type'])\n\n\ndf_winter_length = df_winter_length.groupby(['Start_year']).mean()\n\n\nfig, ax = plt.subplots(figsize=(16,12))\ndf_winter_length.plot.bar(ax=ax, zorder=3)\n\nax.legend(ncol=3, edgecolor='w')\n[ax.spines[s].set_visible(False) for s in ['top','right', 'left']]\nax.tick_params(axis='both', left=False, bottom=False)\nplt.title('Average Length of Winter Storms 1965-2017 (Days)', size=25)\nax.grid(axis='y', dashes=(8,3), color='grey', alpha=0.3)\nplt.xlabel(xlabel='')\nfig.savefig('Change_in_Average Length_of_Winter_Events')\n","988e311b":"df_winter = df_time[(df_time['Disaster_Type'] == 'Winter') | (df_time['Disaster_Type'] == 'Snow') | (df_time['Disaster_Type'] == 'Ice')]\n\ndf_winter.drop_duplicates(keep='first')\n\ndf_winter = df_winter.reset_index(drop=True, inplace=False)\n\n#Change in Length of Winter Weather Events from 1965 - 2017\n\ndf_winter['day'] = df_winter['Start_Date_A'].dt.day\ndf_winter['month'] = df_winter['Start_Date_A'].dt.month\ndf_winter['year'] = df_winter['Start_Date_A'].dt.year\n\n\ndf_winter_start = df_winter.drop(columns=['County', 'Start_Date_A','End_Date_A', 'Start_year', 'Disaster_Length',])\n\ndf_winter_plot = df_winter_start.pivot_table(index='month', columns='Disaster_Type', values='day', aggfunc='count')\n\n\nfig, ax = plt.subplots(figsize=(12,8))\n\ncolors = [\n'#1f77b4','#ff7f0e', '#FF665A', '#2ca02c', '#28a2a6',\n    '#ff9896', '#9467bd', '#c5b0d5', '#8c564b', '#c49c94',\n    '#e377c2', '#FFF447']\n\ncmap = ListedColormap(colors, name=\"custom\")\n\ndf_winter_plot.plot.bar(stacked=True, ax=ax, zorder=3, cmap=cmap, rot=0)\n\nax.legend(ncol=3, edgecolor='w', prop={'size': 16})\n[ax.spines[s].set_visible(False) for s in ['top','right', 'left']]\nax.tick_params(axis='both', left=False, bottom=False)\nplt.title(label='Monthly Winter Storm Count & Distribution (1965-2017)', size=22)\nplt.xlabel(xlabel=\"\")\nax.grid(axis='y', dashes=(8,3), color='grey', alpha=0.3)\n\n\n\n","64f172ae":"\ndf_winter_start = df_winter.drop(columns=['County', 'Start_Date_A','End_Date_A', 'Start_year', 'Disaster_Length',])\ndf_winter_plot2 = df_winter_start.pivot_table(index='year', columns='month', values='day', aggfunc='count')\n\n\nfig, ax = plt.subplots(figsize=(18,14))\n\n\ncolors = [\n    '#1f77b4','#ff7f0e', '#FF665A', '#2ca02c', '#28a2a6',\n    '#ff9896', '#9467bd', '#c5b0d5', '#8c564b', '#c49c94',\n    '#e377c2', '#FFF447']\n\ncmap = ListedColormap(colors, name=\"custom\")\n\ndf_winter_plot2.plot.bar(stacked=True, ax=ax, zorder=3, cmap=cmap, rot=0)\nax.legend(ncol=3, edgecolor='w', prop={'size': 20})\n[ax.spines[s].set_visible(False) for s in ['top','right', 'left']]\nax.tick_params(axis='both', left=False, bottom=False)\nfor i, t in enumerate(ax.get_xticklabels()):\n    if (i % 5) != 0:\n        t.set_visible(False)\n        \nplt.title(label='Monthly Winter Storm Counts from 1965-2017', size=20)\nplt.xlabel(xlabel=\"\")\nax.grid(axis='y', dashes=(8,3), color='grey', alpha=0.3)","e390ee1d":"#Preprocessing\nIn order to prepare the data for analysis, I've dropped the NaN values, along with other unnecessary columns, and done a little organizing. ","428b3a4a":"As shown in the 2 figures above, the average length of weather emergencies has stayed relatively consistent throughout the data period, while the number of weather emergencies being declared appears to be increasing.\n\nThe key question at hand is, as to what extent is the difference between the increase in emergencies, and the increase in declarations.\n\nAs previously mentioned, since this is the reported number of emergencies, and not the number of weather events that occurred, a variety of other factors are involved, especially as multiple counties can report the same disaster. Accordingly, from another perspective, the increased reporting by a higher number of counties, could be due to changes in population, weather reporting technology\/protocol, or, that the storms are potentially becoming larger in geographical area and therefore, affecting a greater number of counties. \n\nSubsequently, in order to get a little more out of this data set, let's look at the types of emergencies being reported.\n\nLastly, it is important to note that from 1960 - 1980, all storms were reported as 1 day events, making that section untelling and insignificant. If we were to continue analyzing that section, we would remove that period from the dataframe. ","bf7ce9ec":"Althought the data doesn't represent a significant time period, especially as there seems to be a change in terms of the reporting that happened before and after roughly 1990, lets train and test a simple linear regression model to more clearly illustrate changes over time and see how accurate the predictions are.","739afca5":"We can see there are a number of emergencies that are not directly environmentally related (althought some may be debatable depending on your perspective). However, they are not relevant for answering the research questions. ","6ae11b2c":"While 2005 clearly represents hurricane Katrina, it is interesting to see the number of hurricanes and 'storms' being declared as an emergency increasing. With the number of hurricanes incresaing, it is likely that 'storm', while being ambiguous, could illustrate Tropical Storms, and also be a sign of a rising intensity of weather events, that previously, had a weaker impact on counties and were therefore not declared as emergencies. \n\nBeginning in 1999 the number of fire related emergencies increases while the number of floods decreases. In turn, it would be interesting to contrast this analysis with data on rising temperatures and rainfall changes.\n\n\n","ca7bc085":"Therefore, while some of data NaN values may be in the same row, as a county and end date could both not have values,\neven if all NaN represented seperate rows, this would still only equal 1.18%. In turn, I removed all rows with a NaN value, as they don't represent a significant value that could influence results. ","1b6cdd2f":"We can see a total of 539 NaN values out of 46185 rows.","616e456c":"#Analysis\n\nStarting with some more general visualizations, I plotted the number of weather emergencies declared per year, and the average length of such, to see if any particular patterns emerged. \n\n","aa58bd33":"While it is not surprising that Dec (1) and Jan (2), had the most winter emergencies, when looking at the second illustration that depicts how many emergencies were declared each month, in a given year, it is difficult to contend that the shift I hypothesized has fully formed. However, it should be noted that in the past 10 years, the December (12), weather emergencies has declined while February emergencies have increased, a longer time frame would is need to confirm that a seasonal shift is taking place. ","8f803563":"When looking specifically at Winter storms, it appears that the types of storms has shifted, with more ice related emergencies being declared. Secondly, the data illustrates a decrease in the average length of winter emergencies in the last 30 years.\n\nMoreover, while the visualizations above allowed for the analysis of the length and types of winter emergencies, I was also curious if a shift in seasons had been occurring, with winter possibly starting later in Winter and pushing further into Spring. \n\nIn turn, I first took a look at which months had the most winter storms, and how the types were distributed. \n\nSecondly, I zoomed out for a longtitudal approach to see if the months with the most winter weather events being declared changed between 1965 and 2017. \n\n(1-12 represent the months of the year for both graphs) \n","0d908477":"#Conclusion\n\nWhile a longer timeframe data set would indeed provide more insights and depth to the observations, even throughout the past 60 years, a change in the emergencies being declared is present.\n\nThe question remains as to the variety of influencing variables and their weights, especially in this case, in terms of the declaration protocols and technological changes. \n\nStay tuned for upcoming projects on on water conservation and forest fires. ","1bc450a6":"Next, I converted all dates to the proper pd date format so the lengths of emergencies could be caluculated, organized the df, and created a new column with the length of disaster days. Also, since all emergencies reported to start and end on the same day would give a 0 in terms of length, I converted all 0 entries to represent 1, to represent 1 day.  ","b636dd5c":"Considering the rising intensity and quantity of weather events in recent years, caused by a variety of factors, most notably, the affects of increasing GHG emissions, it is important to understand not only the intensity, but also shifts in the type and length of weather events. \n\nHowever, it is important to note a few things about the data set before proceeding. \n\nFirstly, 60 years worth of data, when referring to weather, is insufficient when attempting to investigate changes which occur over much longer cycles. \n\nSecondly, although the results show signs of an increasing number of weather related emergencies being declared, this is also only in terms of 'declared' emergencies, as in accordance with the US FEMA guidelines. Therefore, it must be taken into account how the quantity of declarations may also have changed\/increased over time due to improved technology, alterations in reporting standards, increased populations and more. \n    \n  \nResearch Questions: \n1. Have the types of storms which occur each year changed since 1965? \n2. Has the average length of storms which occur each year changed since 1965?\n3. Has the type and duration of winter weather events changed since 1965? \n\n    \nWhy is this important? \nUnderstanding the way in which the types of weather events are changing, and more specifically, shifts in intensity or occurrence of particular storms, allows us to prepare, adapt and ensure resilience during times of change and uncertainty. This becomes especially prudent for instance, when addressing rising temperatures and sea levels, or increasingly intense weather events. "}}