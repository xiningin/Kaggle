{"cell_type":{"edbdfd84":"code","ace223f4":"code","bf9a6dac":"code","c35d85ba":"code","5ffde569":"code","3704df61":"code","a7f2ff5b":"code","9d681fdc":"code","c486fe3a":"code","f3411c91":"code","65d0d7fc":"code","762737d0":"code","9411066e":"markdown","eaa27030":"markdown","cffdaf47":"markdown","60d61315":"markdown","379c9166":"markdown","32792011":"markdown","605aab23":"markdown","ca2b72e3":"markdown","4d7fc82c":"markdown","6d9effb1":"markdown","ceefc107":"markdown","c440c48b":"markdown","8574bb14":"markdown"},"source":{"edbdfd84":"%%sh\n#!\/bin\/sh\n\n# Script to set up a GCS project for this application.\n\nset -eu\n\nDATE=$(date '+%Y%m%d_%H%M%S')\nPREFIX=\"project\"\nCREDENTIAL_PATH=\"$(pwd)\"\nREGION=\"us-central1\"\n\n# Parse command line arguments\nwhile [[ $# -gt 0 ]]; do\n    case $1 in\n        --prefix)\n            PREFIX=$2\n            shift\n            ;;\n        --billing_acct)\n            BILLING_ACCT=$2\n            shift\n            ;;\n        --credential_path)\n            CREDENTIAL_PATH=$2\n            shift\n            ;;\n        --region)\n            REGION=$2\n            shift\n            ;;\n    esac\n    shift\ndone\n\nPROJECT_NAME=\"${PREFIX}${DATE}\"\nSA_NAME=\"${PREFIX}-sa${DATE}\"\nGOOGLE_APPLICATION_CREDENTIALS=\"${CREDENTIAL_PATH}\/${SA_NAME}.json\"\nBUCKET_NAME=\"${PREFIX}-gs${DATE}\"\n\n\necho \"Initializing project ${PROJECT_NAME}.\"\n\necho \"Creating project ${PROJECT_NAME}.\"\ngcloud projects create $PROJECT_NAME --set-as-default\n\necho \"Linking billing account.\"\ngcloud beta billing projects link \\\n       $PROJECT_NAME \\\n       --billing-account=$BILLING_ACCT\n\necho \"Enabling services.\"\ngcloud services enable \\\n       aiplatform.googleapis.com \\\n       storage.googleapis.com\n\necho \"Creating service account ${SA_NAME}.\"\ngcloud iam service-accounts create $SA_NAME\n\necho \"Adding IAM owner role to service account.\"\ngcloud projects add-iam-policy-binding \\\n       $PROJECT_NAME \\\n       --member=\"serviceAccount:$SA_NAME@$PROJECT_NAME.iam.gserviceaccount.com\" \\\n       --role=\"roles\/owner\"\n\necho \"Creating key file at ${GOOGLE_APPLICATION_CREDENTIALS}.\"\ngcloud iam service-accounts keys create \\\n       $GOOGLE_APPLICATION_CREDENTIALS \\\n       --iam-account=\"$SA_NAME@$PROJECT_NAME.iam.gserviceaccount.com\"\n\necho \"Authorizing service account.\"\ngcloud auth activate-service-account \\\n       --key-file=$GOOGLE_APPLICATION_CREDENTIALS\n\nexport $GOOGLE_APPLICATION_CREDENTIALS\n\necho \"Creating storage bucket ${BUCKET_NAME} in region ${REGION}.\"\ngsutil mb -l $REGION gs:\/\/$BUCKET_NAME\n\necho \"Initialization complete.\"\n\necho \"When you've finished with this project, delete it by running\\n gcloud projects delete ${PROJECT_NAME}\"","ace223f4":"# See https:\/\/cloud.google.com\/ai-platform-unified\/docs\/training\/create-custom-job\nimport google.cloud.aiplatform.gapic as aip\nfrom typing import List, Dict, Any\n\n\ndef create_custom_job(\n        job_client,\n        project: str,\n        display_name: str,\n        executor_image_uri: str,\n        package_uris: List[str],\n        args: List[str],  # arguments to trainer.task\n        python_module: str = \"trainer.task\",\n        location: str = \"us-central1\",\n):\n    custom_job = {\n        \"display_name\": display_name,\n        \"job_spec\": {\n            \"worker_pool_specs\": [\n                {\n                    \"machine_spec\": {\n                        \"machine_type\": \"n1-standard-8\",\n                        \"accelerator_type\": aip.AcceleratorType.NVIDIA_TESLA_T4,\n                        \"accelerator_count\": 1,\n                    },\n                    \"replica_count\": 1,\n                    \"python_package_spec\": {\n                        \"executor_image_uri\": executor_image_uri,\n                        \"package_uris\": package_uris,\n                        \"args\": args,\n                        \"python_module\": python_module,\n                    }\n                }\n            ]\n        },\n    }\n    parent = f\"projects\/{project}\/locations\/{location}\"\n    response = job_client.create_custom_job(parent=parent, custom_job=custom_job)\n    return response.name\n\n\ndef upload_model(\n        model_client,\n        project: str,\n        display_name: str,\n        image_uri: str,\n        artifact_uri: str,\n        location: str = \"us-central1\",\n        timeout: int = 1800,\n):\n    model = {\n        \"display_name\": display_name,\n        \"metadata_schema_uri\": \"\",\n        \"artifact_uri\": artifact_uri,\n        \"container_spec\": {\n            \"image_uri\": image_uri,\n            \"command\": [],\n            \"args\": [],\n            \"env\": [],\n            \"ports\": [],\n            \"predict_route\": \"\",\n            \"health_route\": \"\",\n        },\n    }\n    parent = f\"projects\/{project}\/locations\/{location}\"\n    response = model_client.upload_model(parent=parent, model=model)\n    upload_model_response = response.result(timeout=timeout)\n    return upload_model_response.model\n\n\ndef create_endpoint(\n        endpoint_client,\n        project: str,\n        display_name: str,\n        location: str = \"us-central1\",\n        timeout: int = 300,\n):\n    endpoint = {\"display_name\": display_name}\n    parent = f\"projects\/{project}\/locations\/{location}\"\n    response = endpoint_client.create_endpoint(parent=parent, endpoint=endpoint)\n    create_endpoint_response = response.result(timeout=timeout)\n    return create_endpoint_response.name  # endpoint_id\n\n\ndef deploy_model(\n        endpoint_client,\n        endpoint_id,\n        project: str,\n        model_name: str,\n        deployed_model_display_name: str,\n        location: str = \"us-central1\",\n        timeout: int = 7200,\n):\n    deployed_model = {\n        \"model\": model_name,\n        \"display_name\": deployed_model_display_name,\n        \"dedicated_resources\": {\n            \"min_replica_count\": 1,\n            \"machine_spec\": {\n                \"machine_type\": \"n1-standard-2\",\n            },\n        },\n    }\n    traffic_split = {\"0\": 100}\n    response = endpoint_client.deploy_model(\n        endpoint=endpoint_id, deployed_model=deployed_model, traffic_split=traffic_split,\n    )\n    deploy_model_response = response.result(timeout=timeout)\n    return deploy_model_response.deployed_model\n\n\ndef get_predictions(\n        prediction_client,\n        images,\n        endpoint,\n        input_name,\n        parameters=None,\n):\n    import base64\n    from google.protobuf.json_format import ParseDict, MessageToDict\n    from google.protobuf.struct_pb2 import Value\n    \n    instances = []\n    for img in images:\n        img = base64.b64encode(img).decode('utf-8')\n        img = {input_name: {'b64': img}}\n        instances.append(ParseDict(img, Value()))\n\n    response = prediction_client.predict(\n        endpoint=endpoint, instances=instances, parameters=parameters,\n    )\n    return MessageToDict(response)\n","bf9a6dac":"from google.cloud.aiplatform import gapic as aip\n\n# You might need to set the path to your credential file if the\n# environment variable isn't around anymore.\n#\n# import os\n# os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '\/path\/to\/credentials.json'\n\n# Set these to match what you defined in the script above\nPROJECT = 'project20210402'\nLOCATION = 'us-central1'\nBUCKET = 'gs:\/\/project-gs20210402'\n\nAPI_ENDPOINT = f\"{LOCATION}-aiplatform.googleapis.com\"\nclient_options = {\"api_endpoint\": API_ENDPOINT}\nclients = {\n    'job': aip.JobServiceClient(client_options=client_options),\n    'model': aip.ModelServiceClient(client_options=client_options),\n    'endpoint': aip.EndpointServiceClient(client_options=client_options),\n    'prediction': aip.PredictionServiceClient(client_options=client_options),\n}","c35d85ba":"from pathlib import Path\n\nPACKAGE_DIR = Path(\"\/kaggle\/working\/custom\")\nPath(PACKAGE_DIR, \"trainer\").mkdir(parents=True, exist_ok=True)\nPath(PACKAGE_DIR, \"trainer\/__init__.py\").touch()","5ffde569":"%%writefile \/kaggle\/working\/custom\/setup.py\n\nfrom setuptools import find_packages\nfrom setuptools import setup\n\nsetup(\n    name='trainer',\n    version='0.1',\n    install_requires=['tensorflow_datasets>=4.0.0'],\n    packages=find_packages(),\n    include_package_data=True,\n    description='Localizer trainer.'\n)","3704df61":"%%writefile \/kaggle\/working\/custom\/trainer\/task.py\n\nimport argparse\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow_datasets as tfds\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--data_dir',\n                    default=None,\n                    type=str)\nparser.add_argument('--model_dir',\n                    type=str)\nparser.add_argument('--serving_model_dir',\n                    type=str)\nparser.add_argument('--learning_rate',\n                    default=0.01,\n                    type=float)\nparser.add_argument('--epochs',\n                    default=10,\n                    type=int)\nparser.add_argument('--batch_size',\n                    default=16,\n                    type=int)\nparser.add_argument('--img_size',\n                    default=256,\n                    type=int)\nargs = parser.parse_args()\n\n# Data\nAUTO = tf.data.AUTOTUNE\nBUFFER_SIZE = 10000\n\n(ds_train, ds_valid), ds_info = tfds.load(\n    \"cars196\", split=[\"train\", \"test\"], with_info=True,\n)\n\n\ndef preprocess(image, bbox):\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    image = tf.image.resize(image, size=[args.img_size, args.img_size])\n    return image, bbox\n\n\nds_train = (\n    ds_train\n    .map(lambda ex: (ex[\"image\"], ex[\"bbox\"]), num_parallel_calls=AUTO)\n    .map(preprocess, AUTO)\n    .cache()\n    .shuffle(BUFFER_SIZE)\n    .batch(args.batch_size)\n    .prefetch(AUTO)\n)\nds_train.options().experimental_deterministic = False\n\nds_valid = (\n    ds_valid\n    .map(lambda ex: (ex[\"image\"], ex[\"bbox\"]), AUTO)\n    .map(preprocess, AUTO)\n    .batch(args.batch_size)\n    .cache()\n    .prefetch(AUTO)\n)\nds_valid.options().experimental_deterministic = False\n\n\n# Model\n\npretrained = keras.applications.Xception(include_top=False)\n\nmodel = keras.Sequential([\n    pretrained,\n    layers.GlobalAvgPool2D(),\n    layers.Dropout(0.1),\n    layers.Dense(4, activation=\"sigmoid\")\n])\nmodel.compile(\n    loss=\"mse\",\n    optimizer=keras.optimizers.Adam(learning_rate=args.learning_rate),\n)\nearly_stopping = keras.callbacks.EarlyStopping(restore_best_weights=True)\nmodel.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=args.epochs,\n    callbacks=[early_stopping],\n)\n\nmodel.save(args.model_dir)\n\n\n# Serving Model #\n#\n# We need a model that can take b64-encoded images as input. We'll\n# subclass `keras.Model` to make a wrapper for our trained model.\n#\n# The `input_signature` specification to `call` is needed for\n# TensorFlow to be able to compile this model for serving.\nclass ServingModel(keras.Model):\n    def __init__(self, model, img_size):\n        super().__init__(self)\n        self.model = model\n        self.img_size = img_size\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\n            \"model\": self.model,\n            \"img_size\": self.img_size,\n        })\n        return config\n\n    def _preprocess(self, bytes_input):\n        image = tf.io.decode_jpeg(bytes_input, channels=3),\n        image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n        image = tf.image.resize(image, size=self.img_size)\n        return image[0]\n\n    def preprocess_fn(self, bytes_inputs):\n        images = tf.map_fn(self._preprocess, bytes_inputs, dtype=tf.float32)\n        return images\n\n    @tf.function(input_signature=[tf.TensorSpec([None], tf.string)])\n    def call(self, bytes_inputs):\n        images = self.preprocess_fn(bytes_inputs)\n        return {\"bbox\": self.model(images)}\n\n\nserving_model = ServingModel(model, [args.img_size, args.img_size])\nserving_model.build(input_shape=())\nserving_model.save(\n    args.serving_model_dir,\n    signatures={\"serving_default\": serving_model.call},\n)","a7f2ff5b":"import os\n\nos.chdir(PACKAGE_DIR)\n!python setup.py sdist --formats=gztar\n!gsutil cp dist\/trainer-0.1.tar.gz $BUCKET\/trainer.tar.gz","9d681fdc":"from uuid import uuid4\n\nJOB_NAME = f\"cropper_{uuid4()}\"  # make a unique job name\nEPOCHS = 5\nLEARNING_RATE = 0.001\n\nmodel_dir = os.path.join(BUCKET, JOB_NAME, \"train\")\nserving_model_dir = os.path.join(BUCKET, JOB_NAME, \"serve\")\njob_spec = {\n    'job_client': clients['job'],\n    'project': PROJECT,\n    'display_name': JOB_NAME,\n    'executor_image_uri': 'us-docker.pkg.dev\/cloud-aiplatform\/training\/tf-gpu.2-4:latest',\n    'package_uris': [os.path.join(BUCKET, \"trainer.tar.gz\")],\n    'args': [\n        f\"--serving_model_dir={serving_model_dir}\",\n        f\"--model_dir={model_dir}\",\n        f\"--learning_rate={LEARNING_RATE}\",\n        f\"--epochs={EPOCHS}\",\n    ],\n}\njob_response = create_custom_job(**job_spec)","c486fe3a":"MODEL_DISPLAY_NAME = 'cropper'\n\nmodel_spec = {\n    'model_client': clients['model'],\n    'project': PROJECT,\n    'display_name': MODEL_DISPLAY_NAME,\n    'image_uri': 'us-docker.pkg.dev\/cloud-aiplatform\/prediction\/tf2-cpu.2-3:latest',\n    'artifact_uri': serving_model_dir,\n}\nmodel_id = upload_model(**model_spec)","f3411c91":"ENDPOINT_DISPLAY_NAME = 'cropper_serving'\n\nendpoint_spec = {\n    'endpoint_client': clients['endpoint'],\n    'project': PROJECT,\n    'display_name': ENDPOINT_DISPLAY_NAME,\n}\nendpoint_id = create_endpoint(**endpoint_spec)","65d0d7fc":"deploy_spec = {\n    'endpoint_client': clients['endpoint'],\n    'endpoint_id': endpoint_id,\n    'project': PROJECT,\n    'model_name': model_id,\n    'deployed_model_display_name': 'cropper_server',\n}\ndeployed_id = deploy_model(**deploy_spec)","762737d0":"import numpy as np\nimport tensorflow as tf\n\n# Random image\ntmp = tf.image.encode_jpeg(np.random.random(size=[16, 16, 3]) * 255).numpy()\n\nprediction_spec = {\n    'prediction_client': clients['prediction'],\n    'images': [tmp],\n    'endpoint': endpoint_id,\n    'input_name': 'bytes_inputs',\n}\nprediction = get_predictions(**prediction_spec)","9411066e":"- Create training module.","eaa27030":"# Deploying a TensorFlow AutoCropper #\n\nIn this tutorial, we'll create a TensorFlow model using Google's AI Platform (Unified) that will learn to crop images of cars and deploy it to an online endpoint. This would be a great setup if you wanted to let users upload images through an app, say, and return a cropped image.\n\nBe aware that you'll be charged for some of the resources used in this tutorial. To ensure you won't incur any unnecessary charges, create a new project just for this tutorial (using the script below) and then delete it when you're finished.\n\n# Setup GCS Project #\n\nHere's a script you can run at the command line to set up this project. Find your billing account number (`BILLING_ACCT`), decide where you'd like to store the key file for the service account (`CREDENTIAL_PATH`), and choose some project name (`PREFIX`). Save this script to your computer and then run something like:\n\n```\nchmod a+x setup-gcs.sh\n.\/setup-gcs.sh \\\n    --prefix=\"project\" \\\n    --billing_acct=\"xxxxxxx\" \\\n    --credential_path=\"\/home\/myname\"\n```\n\nOpen this cell to see the script. You'll need to download the `gcloud` command line utility and create a billing account if you haven't done so already.","cffdaf47":"- Train model.","60d61315":"# Make Predictions #\n\nLet's test it by making a prediction.\n\nThe `input_name` will be the same as the argument name used in the `call` function we defined for the serving model -- in our case, `'bytes_inputs'`.","379c9166":"# Deploy Model to Endpoint #\n\nAnd now we'll deploy the model to the endpoint.","32792011":"# Upload Serving Model #\n\nNow that we've trained our model, we're ready to deploy it for making predictions. This involves three steps:\n1. Upload the model to the model server.\n2. Create a API endpoint for prediction requests.\n3. Attach the model to the endpoint.\n\nHere's how we upload the model:","605aab23":"- Create package.","ca2b72e3":"# GCS Functions #\n\nThe following defines a few helper functions. The first creates a trained model:\n- `create_custom_job` - train the model\n\nWhile the next three deploy it to a prediction server with a defined API endpoint.\n- `upload_model` - upload to model server\n- `create_endpoint` - create API endpoint for predictions\n- `deploy_model` - attach model to endpoint\n\nThe last function sends data to the endpoint and retrieves the corresponding predictions.\n- `get_predictions` - send instances and get corresponding predictions","4d7fc82c":"# Create Endpoint #\n\nNow we'll create our prediction endpoint.","6d9effb1":"# Define Training Package #\n\nOur cropping model is a variation of a an *object localizer*. The model we train is simply a pretrained convolutional base with a regression head with four outputs to predict bounding boxes. The model we deploy for serving has a couple of extra functions attached for processing inputs and outputs. Attaching these functions to the network means that TensorFlow can compile a complete computational graph for deployment.\n\nTo train a model with AI Platform Custom Training, we upload a Python package containing the training code to the training server. We defined the kind of machine we want to use in the `create_custom_job` function earlier: a standard 8-core machine with a T4 NVIDIA GPU accelerator. For larger jobs, you could easily scale this to a machine with multiple GPUs or even a cluster of machines by adding more workers to the job specification and wrapping model definition in a distribution strategy -- see [this tutorial](https:\/\/www.tensorflow.org\/tutorials\/distribute\/keras) for more.\n\nHere are the steps:\n\n- Create package structure.","ceefc107":"- Create package config.","c440c48b":"# Create GCS Clients #\n\nTo create this project, we'll interact with the AI Platform API. We need an API client for each of the steps above.","8574bb14":"Here's what a request and response looks like:\n\n``` json\n{\"instances\": \n  [{\"bytes_inputs\": \n    {\"b64\": \"\/9j\/4AAQSkZJRgABAQEBLAEsAAD\/2wBDAAIBAQEBAQIBAQECAgICAgQDAgICAgUEBAMEBgUGBgYFBgYGBwkIBgcJBwYGCAsICQoKCgoKBggLDAsKDAkKCgr\/2wBDAQICAgICAgUDAwUKBwYHCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgr\/wAARCAAQABADASIAAhEBAxEB\/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL\/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6\/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL\/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6\/9oADAMBAAIRAxEAPwDU8U+LfEfw+sdM+GHg\/wAW6z4c0fTr2GfQ4tI0VdU1s615Vg6WLCe3tn1EvJGdRiuGVJrlrkpHGYrVyvMfAfQvFPhfxHobaRb\/AG3wr4rFppyar8QvGklo+gwTpeXtu10olu7VtQjs\/tYVpRPIIJbb5IhJKq+g+Gdb1\/X9A1TwrY\/F670SePxJo2van4dh1u40bUWu557iS5uJLCS5aSNPkgCwSO6ztFPMEjjeJzyvgnxhb6be+GrDxzF\/Z3jHwx4w0x\/hxYad4Whe8WKE6jA+nvPbQzw2s9z5lsm51jfUFjhiE04aK5h83EVKEcvrzxdBuf7qLSg6c6ko+zUptRbnCMZ1o80pKp9ubjL34EYetRy7D1o06sJUouVKnTcV7SpBqMnP21KmnJcnNC6dPkap6uDhCX\/\/2Q==\"\n    }\n  }]\n}\n\n{\n \"predictions\": [\n   [\n     0.598633349,\n     0.285437942,\n     0.844543397,\n     0.692057133\n   ]\n ],\n \"deployedModelId\": \"0123456789012345678\"\n}\n```"}}