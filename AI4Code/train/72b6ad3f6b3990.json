{"cell_type":{"2f0fe7a0":"code","e3f6af19":"code","2fd63448":"code","0f7edeb9":"code","bfc4db0e":"code","229245c2":"code","f267d6ae":"code","206907fc":"code","b0fa4e63":"code","7a5d2bbe":"code","e10429fd":"code","46c9ff06":"code","325ddb52":"code","329a318c":"code","111b7719":"code","eaedd649":"code","00f654a7":"code","a8d4480c":"code","82b6705f":"code","63ae40e1":"code","f7c550a2":"code","39a01f1e":"code","8bba2455":"code","d857f856":"code","3aefe800":"code","bcd9e798":"code","1c12f1d5":"code","01689bfa":"code","096eef31":"code","c15bd896":"code","112e2037":"code","aaac0712":"markdown","06ee4755":"markdown","31354e66":"markdown","8d290548":"markdown","1b472e92":"markdown","03c0c933":"markdown","099e653d":"markdown","6be1a061":"markdown","8637be0f":"markdown","c3297675":"markdown","e9e628b3":"markdown","99ae7da7":"markdown","111e01e7":"markdown","0f7ec5a6":"markdown","469730ab":"markdown","c296ce99":"markdown","179324d0":"markdown","997d7648":"markdown","a56be2dc":"markdown","847f694f":"markdown","02245cf7":"markdown","15ecbcd2":"markdown","fe7d518d":"markdown","dfb06ec1":"markdown","5a58610d":"markdown","b0f2c2e3":"markdown","4e5b3ccb":"markdown","04386f94":"markdown","e499d82b":"markdown","3c874290":"markdown","034044a1":"markdown","6b264acc":"markdown","9ef615e0":"markdown","a8ba09a7":"markdown","a98ace1a":"markdown","2a0a5837":"markdown"},"source":{"2f0fe7a0":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport cv2 as cv\nimport pickle\nimport warnings\nfrom itertools import product, repeat, permutations, combinations_with_replacement, chain\nfrom math import floor, ceil\n\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline","e3f6af19":"data = np.load('\/kaggle\/input\/reading-captcha-dataset-part-1\/preprocessed-data.npz')\nX, y_labels, y = data['X'], data['y_labels'], data['y']","2fd63448":"n = X.shape[0]\nimg = (X[np.random.randint(n)] * 255)[:, :, 0].astype(np.uint8)","0f7edeb9":"plt.imshow(img, cmap='gray');","bfc4db0e":"inverted = 255 - img\nplt.imshow(inverted, cmap='gray');","229245c2":"ret, thresholded = cv.threshold(inverted, 140, 255, cv.THRESH_BINARY)\nplt.imshow(thresholded, cmap='gray');","f267d6ae":"blurred = cv.medianBlur(thresholded, 3)\nplt.imshow(blurred, cmap='gray');","206907fc":"    kernel = np.array([\n        [0, 0, 1, 0, 0],\n        [0, 0, 1, 0, 0],\n        [0, 0, 1, 0, 0],\n        [0, 0, 1, 0, 0],\n        [0, 0, 1, 0, 0],\n    ]).astype(np.uint8)\n    \n    ex = cv.morphologyEx(blurred, cv.MORPH_OPEN, kernel)\n    plt.imshow(ex, cmap='gray');","b0fa4e63":"kernel2 = np.array([\n    [0, 0, 0, 0, 0],\n    [0, 0, 0, 0, 0],\n    [0, 0, 0, 0, 0],\n    [1, 1, 1, 1, 1],\n    [0, 0, 0, 0, 0],\n    [0, 0, 0, 0, 0],\n    [0, 0, 0, 0, 0]\n]).astype(np.uint8)\nex2 = cv.morphologyEx(ex, cv.MORPH_DILATE, kernel2)\nplt.imshow(ex2, cmap='gray');","7a5d2bbe":"mask = ex2\nprocessed = cv.bitwise_and(mask, blurred)\nplt.imshow(processed, cmap='gray');","e10429fd":"contours, hierachy = cv.findContours(processed, cv.RETR_CCOMP, cv.CHAIN_APPROX_SIMPLE)\ncontours = [contours[k] for k in range(0, len(contours)) if hierachy[0, k, 3] == -1]\ncontours.sort(key=lambda cnt: cv.boundingRect(cnt)[0])","46c9ff06":"len(contours)","325ddb52":"plt.imshow(cv.drawContours(cv.cvtColor(img, cv.COLOR_GRAY2RGB), contours, -1, (255, 0, 0), 1, cv.LINE_4));","329a318c":"contour_bboxes = [cv.boundingRect(contour) for contour in contours]\nimg_bboxes = cv.cvtColor(img, cv.COLOR_GRAY2RGB)\nfor bbox in contour_bboxes:\n    left, top, width, height = bbox\n    img_bboxes = cv.rectangle(img_bboxes,\n                              (left, top), (left+width, top+height),\n                              (0, 255, 0), 1)\nplt.imshow(img_bboxes, cmap='gray');","111b7719":"\nwith open('\/kaggle\/input\/captchadlutils\/repository\/Vykstorm-CaptchaDL-utils-a8458b5\/contour-classifier', 'rb') as file:\n    contour_classifier = pickle.load(file)","eaedd649":"contour_classifier","00f654a7":"contours_features = pd.DataFrame.from_dict({\n    'bbox_width': [bbox[2] for bbox in contour_bboxes],\n    'bbox_height': [bbox[3] for bbox in contour_bboxes],\n    'area': [cv.contourArea(cnt) for cnt in contours],\n    'extent': [cv.contourArea(cnt) \/ (bbox[2] * bbox[3]) for cnt, bbox in zip(contours, contour_bboxes)],\n    'perimeter': [cv.arcLength(cnt, True) for cnt in contours]\n})\ncontours_features","a8d4480c":"\nwith open('\/kaggle\/input\/captchadlutils\/repository\/Vykstorm-CaptchaDL-utils-a8458b5\/contour-classifier-preprocessor', 'rb') as file:\n    contour_features_scaler = pickle.load(file)","82b6705f":"contour_features = contour_features_scaler.transform(contours_features[['bbox_width', 'bbox_height', 'area', 'extent', 'perimeter']])\ncontour_features","63ae40e1":"contour_num_chars = contour_classifier.predict(contour_features)\ncontour_num_chars","f7c550a2":"n = len(contours)\ncols = 2\nrows = n \/\/ cols\nif n % cols > 0:\n    rows += 1\nrows = max(rows, 2)\n\nfig, ax = plt.subplots(rows, cols, figsize=(15, 2.5*rows))\nfor i, j in product(range(0,rows), range(0,cols)):\n    k = i * cols + j\n    if k < n:\n        left, top, width, height = contour_bboxes[k]\n        img_bbox = cv.rectangle(cv.cvtColor(img, cv.COLOR_GRAY2RGB),\n                                (left, top), (left+width, top+height), (0, 255, 0), 1)\n        \n        plt.sca(ax[i,j])\n        plt.title('Contour {}, Number of chars: {}'.format(k, contour_num_chars[k]))\n        plt.imshow(img_bbox, cmap='gray')\n        plt.xticks([])\n        plt.yticks([])\n    else:\n        ax[i,j].set_visible(False)\n\nplt.tight_layout()","39a01f1e":"print('Total number of predicted characters in the image: {}'.format(contour_num_chars.sum()))","8bba2455":"P = contour_classifier.predict_proba(contour_features)\nnp.round(P, 2)","d857f856":"configs = filter(lambda x: np.sum(x) == 5, combinations_with_replacement(range(0, 6), n))\nconfigs = list(frozenset(chain.from_iterable(map(lambda config: permutations(config, n), configs))))\nconfigs = np.array(configs, dtype=np.uint8)\nlen(configs)","3aefe800":"scores = np.zeros([len(configs)]).astype(np.float32)\nfor i in range(0, len(configs)):\n    scores[i] = np.prod(P[np.arange(0, n), configs[i]])","bcd9e798":"best_config = configs[scores.argmax()]\nbest_config","1c12f1d5":"frames = []\nfor i in range(0, n):\n    if best_config[i] > 0:\n        left, top, width, height = contour_bboxes[i]\n        right, bottom = left+width, top+height\n        frame = img[top:bottom, left:right]\n        frames.append(frame)\nframe_num_chars = best_config[np.nonzero(best_config)[0]]\nnum_frames = len(frames)\n\ncols = 3\nrows = num_frames \/\/ cols\nif num_frames % cols > 0:\n    rows += 1\nrows = max(rows,2)\nfig, ax = plt.subplots(rows, cols, figsize=(15, 2.5*rows))\nfor i, j in product(range(0,rows), range(0,cols)):\n    k = i * cols + j\n    if k < num_frames:\n        plt.sca(ax[i,j])\n        plt.imshow(frames[k], cmap='gray')\n        plt.title('Frame {}. Num chars: {}'.format(k, frame_num_chars[k]))\n        plt.xticks([])\n        plt.yticks([])\n    else:\n        ax[i,j].set_visible(False)","01689bfa":"frame = [frames[i] for i in range(0, num_frames) if frame_num_chars[i] > 1][-1]\nnum_chars = frame_num_chars[frames.index(frame)]\nplt.imshow(frame, cmap='gray');\nseparators = np.linspace(0, frame.shape[1], num_chars+1)[1:-1]\nplt.vlines(separators, ymin=0, ymax=frame.shape[0]-1, color='red');","096eef31":"def split_array(a, separators, axis=1):\n    # This is a helper function to split a numpy array along the given axis using the separators\n    # specified\n    seperators = sorted(separators)\n    n_sep = len(separators)\n    if n_sep == 1:\n        sep = separators[0]\n        a = a.swapaxes(0, axis)\n        return [a[0:sep].swapaxes(0, axis), a[sep:].swapaxes(0, axis)]\n\n    head, body = split_array(a, [separators[0]], axis)\n    splits = split_array(body, np.array(separators[1:]) - separators[0], axis)\n    return [head] + splits\n\ndef find_separators(frame, n):\n    # This method returns n-1 vertical lines equally spaced to split the frame indicated\n    return np.floor(np.linspace(0, frame.shape[1], n+1)[1:-1]).astype(np.uint16)\n\n\nchars = []\nfor frame, num_chars in zip(frames, frame_num_chars):\n    if num_chars == 1:\n        # No need to split frames with only 1 char\n        chars.append(frame)\n    else:\n        # Divide the frame into num_chars splits\n        splits = split_array(frame, find_separators(frame, num_chars), axis=1)\n        chars.extend(splits)\n        \n\nfig, ax = plt.subplots(1, 5, figsize=(13, 3))\nfor i in range(0, 5):\n    plt.sca(ax[i])\n    plt.imshow(chars[i], cmap='gray')\n    plt.xticks([])\n    plt.yticks([])\n    plt.title('Char {}, shape: {}'.format(i+1, chars[i].shape))\n\nplt.tight_layout()","c15bd896":"chars_processed = np.zeros([5, 40, 40, 1]).astype(np.float32)\nfor i, char in zip(range(0, 5), chars):\n    img = char\n    inverted = 255 - img\n    ret, thresholded = cv.threshold(inverted, 70, 255, cv.THRESH_BINARY)\n    img = 255 - np.multiply((thresholded > 0), inverted)\n    \n    dh, dw = 40, 40\n    h, w = img.shape\n    if w < dw:\n        left = floor((dw - w) \/ 2)\n        right = dw - w - left\n        img = cv.copyMakeBorder(img, 0, 0, left, right, cv.BORDER_CONSTANT, value=(255, 255, 255))\n    elif w > dw:\n        left = floor((w - dw) \/ 2)\n        img = img[:, left:left+dw]\n\n    if h < dh:\n        top = floor((dh - h) \/ 2)\n        bottom = dh - h - top\n        img = cv.copyMakeBorder(img, top, bottom, 0, 0, cv.BORDER_CONSTANT, value=(255, 255, 255))\n    elif h > dh:\n        top = floor((h - dh) \/ 2)\n        img = img[top:top+dh, :]\n    \n    chars_processed[i, :, :, 0] = img.astype(np.float32) \/ 255","112e2037":"fig, ax = plt.subplots(1, 5, figsize=(13, 3))\nfor i in range(0, 5):\n    plt.sca(ax[i])\n    plt.imshow(chars_processed[i, :, :, 0], cmap='gray')\n    plt.xticks([])\n    plt.yticks([])\n    plt.title('Char {}'.format(i+1))\n\nplt.tight_layout()","aaac0712":"This notebook shows how to extract char's from the captcha dataset images <br\/>\nAdditional code and notebooks are avaliable on my repository: https:\/\/github.com\/Vykstorm\/CaptchaDL","06ee4755":"For each contour we extract the next features:\n* Bounding box width (Width of the bounding box that encloses the contour)\n* Bounding box height (Height of the bbox)\n* Area (Area of the contour)\n* Extent (Ratio between the area of the contour and its bounding box)\n* Perimeter (Perimiter of the contour)\n<br\/>\nhttps:\/\/docs.opencv.org\/3.1.0\/dd\/d49\/tutorial_py_contour_features.html","31354e66":"## Contour classification","8d290548":"We can plot the contours","1b472e92":"We invert the image so that the background is black and foreground white","03c0c933":"Finally we classify each contour","099e653d":"Get the best configuration","6be1a061":"Apply a bitwise AND operation between the last image and the blurred image (the last one is used as a \"mask\")","8637be0f":"In this section we need to guess the number of chars inside each contour. <br\/>\nTo do so, we need to classify each contour in 6 classes (from 0 to 5) <br\/>\nA contour of class k is one that contains k characters","c3297675":"For each contour, we calculate its rectangle bounding box and draw them","e9e628b3":"Our goal is: <br>\nFind a configuration $\\alpha$ such that $\\sum_{i=1}^{n} \\alpha_i = 5$ that maximize the next function: <br\/>\n$$ score(\\alpha) = \\prod_{i=0}^{n} p_{i}^{\\alpha_i} $$","99ae7da7":"## Finding contours","111e01e7":"On the frames with more than 1 char, we need to split them so that we can get the pixels of each char individually","0f7ec5a6":"Now we scale the features. <br\/>\nYou can download https:\/\/github.com\/Vykstorm\/CaptchaDL\/blob\/master\/models\/.contour-classifier-preprocessor\nwhich is an instance of sklearn.preprocessing.StdScaler already fit with the data","469730ab":"Apply morphological transformations to eliminate tiny objects & horizontal lines","c296ce99":"Reduce the noise with a filter","179324d0":"We are also going to define $\\alpha$ as 1D vector with n (number of contours) elements:\n$\\begin{bmatrix}\n\\alpha_0 & \\alpha_1 & ... & \\alpha_n\n\\end{bmatrix}$ <br\/>\n$\\alpha_i$ will be the number of characters that we predict are inside the ith contour","997d7648":"Our final step is to resize each char image so that all has the same fixed shape (40, 40) <br\/>\nIf the image is smaller than (40, 40), white borders will be added on each side to fill the gaps <br\/>\nIf its greater, its cropped about the center <br\/>\nPixels with intensities higher than ~70 are set to 255 to remove color differences between the generated borders and\nthe background","a56be2dc":"Compute $score(\\alpha)$ for each possible configuration","847f694f":"## Word pixels extraction","02245cf7":"A decent approximation (far from perfect) to divide the frame is to draw n-1 vertical lines equally spaced (where n is the number of chars inside the frame)","15ecbcd2":"## Image preprocessing","fe7d518d":"## Import statements","dfb06ec1":"As we can see in the image, sometimes one contour can hold more than one character. <br\/>\nWe need to figure out how many chars are inside each one to split the image correctly <br\/>\nAlso, there are unwanted small contours that we need to remove","5a58610d":"Load the captcha images and their labels (check the part 1 notebook)","b0f2c2e3":"# Extract chars from the captcha","4e5b3ccb":"The code below creates a list of all possible valid configurations for $\\alpha$[](http:\/\/)","04386f94":"I created a Support vector machine (SVM) to do this task. It uses different contour properties as features such as bounding box width & height, perimeter, area, ... <br\/>\nYou can download the pre-trained SVM here: https:\/\/github.com\/Vykstorm\/CaptchaDL\/blob\/master\/models\/.contour-classifier","e499d82b":"This is our final result...","3c874290":"The next step is finding contours in the image. We can use the OpenCV api method findContours()","034044a1":"Now we are going to take a random image from the dataset and show how to extract each char's pixels.","6b264acc":"Now we can extract the pixels inside the contours in which we predict the chars are in","9ef615e0":"To solve this problem, im going to define the next matrix of size num.contours (n) x 6:\n<p>\n$P = \n\\begin{bmatrix}\np_0^0 & p_0^1 & ... & p_0^6 \\\\\n& & ... & & \\\\\np_n^0 & p_n^1 & ... & p_n^6\n\\end{bmatrix}$\n<\/p>\nWhere $p_i^j$ is the probability of the ith contour of having j characters inside","a8ba09a7":"But there is a problem: what if the total number of predicted chars in the image is not 5? <br\/>\nFor example, we can predict that a contour holds 2 chars but in reality it has 3","a98ace1a":"# Load dataset","2a0a5837":"Now apply binary thresholding."}}