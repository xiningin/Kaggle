{"cell_type":{"44f6639f":"code","74e024c9":"code","47997050":"code","d22ee174":"code","0df24251":"code","2006c651":"code","4fc97078":"code","1f44330f":"code","c79318da":"code","6d98257d":"code","4d777d51":"code","092cde20":"code","e5e260d2":"code","03c2a8c4":"code","aaa94faf":"code","22b7f822":"code","99aa5c45":"code","fad891a0":"code","89f35689":"code","e485506d":"code","51385500":"markdown","cee8e68d":"markdown","0c8966c4":"markdown","44797084":"markdown","3549e90d":"markdown","f8788ef7":"markdown","20b89c3d":"markdown","bc5637e2":"markdown","c47ab7ca":"markdown","34c8acd4":"markdown","27014d0b":"markdown","ac38f8f1":"markdown","9117e54c":"markdown","27faf8e6":"markdown"},"source":{"44f6639f":"#importing libraries\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.cluster import KMeans\n\nimport warnings\nwarnings.filterwarnings('ignore')","74e024c9":"# loading data\ntry:\n    iris_data = pd.read_csv('..\/input\/iris-dataset\/Iris.csv')\n    print(\"Data loaded Successfully!!\\n\")\n    iris_data.info()\nexcept:\n    print(\"Can't Load data\")","47997050":"# check the data by printing first 5 lines\niris_data.head()","d22ee174":"iris_data['Species'].value_counts()","0df24251":"iris_data['Species']","2006c651":"# Let's first see the features\niris_data.describe()","4fc97078":"plt.figure(figsize=(10,6))\nax = sns.boxplot(data=iris_data.drop('Id',axis=1), orient=\"h\", palette=\"Set2\")","1f44330f":"# let's chechk correlation between numeric columns\ncorr = iris_data.drop('Id',axis=1).corr()\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\nheatmap = sns.heatmap(corr, mask=mask, vmin=-1, vmax=1, annot=True)\nheatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12);","c79318da":"# Correlation of Sepal Length-Width\nplt.figure(figsize=(12,8))\nsns.scatterplot(x='SepalLengthCm',y='SepalWidthCm',hue='Species',data=iris_data)","6d98257d":"# Correlation of Petal Length-Width\nplt.figure(figsize=(12,8))\nsns.scatterplot(x='PetalLengthCm',y='PetalWidthCm',hue='Species',data=iris_data)","4d777d51":"# Let's bivariate relation between each pair of features by Ploting the PairPlot\nsns.pairplot(iris_data, hue=\"Species\", size=3.2)","092cde20":"def ViolinPlot(X,Y1,Y2,data):\n  plt.figure(figsize=(15,10))\n  plt.subplot(1,2,1)\n  sns.violinplot(x=X,y=Y1,data=iris_data)\n  plt.title(Y1)\n  plt.subplot(1,2,2)\n  sns.violinplot(x=X,y=Y2,data=iris_data)\n  plt.title(Y2)","e5e260d2":"ViolinPlot(\"Species\",\"PetalLengthCm\",\"PetalWidthCm\",iris_data)\nViolinPlot(\"Species\",\"SepalLengthCm\",\"SepalWidthCm\",iris_data)","03c2a8c4":"plt.figure(figsize=(15,10))\nplt.subplot(2,2,1)\nsns.boxplot(x='Species',y='PetalLengthCm',data=iris_data)\nplt.subplot(2,2,2)\nsns.boxplot(x='Species',y='PetalWidthCm',data=iris_data)\nplt.subplot(2,2,3)\nsns.boxplot(x='Species',y='SepalLengthCm',data=iris_data)\nplt.subplot(2,2,4)\nsns.boxplot(x='Species',y='SepalWidthCm',data=iris_data)","aaa94faf":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\niris_data['Species'] = le.fit_transform(iris_data['Species'])\niris_data['Species']","22b7f822":"# As given problem is of classification problem, we can use K-Means Algorithm for finding the Optimal k value\n\nfrom sklearn.cluster import KMeans\n\nx = iris_data.iloc[:, [0, 1, 2, 3, 4]].values\nwcss = []\n\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\n    kmeans.fit(x)\n    wcss.append(kmeans.inertia_)\n\nplt.figure(figsize=(13,8))\nplt.plot(range(1, 11), wcss,marker='o')\nplt.title('The elbow method',size=15)\nplt.xlabel('Number of clusters',size=12)\nplt.ylabel('WCSS',size=12) #within cluster sum of squares\nplt.show()\n","99aa5c45":"# Predicting the values using Kmeans Algorithm\nkmeans = KMeans(n_clusters = 3, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\npredictions = kmeans.fit_predict(x)","fad891a0":"#Predicted Values\npredictions","89f35689":"#centroids\nkmeans.cluster_centers_","e485506d":"#visualising the predicted clusters on basic all 4 features\nFeatures = ['Sepal Length','Sepal Width','Petal Length','Petal Width']\nplt.figure(figsize=(18,14))\nfor i in range(1,5):\n    plt.subplot(2,2,i)\n    plt.scatter(x[predictions == 0,0], x[predictions == 0,i], s=50, c = '#c718f2', label = 'Iris-setosa' )\n    plt.scatter(x[predictions == 1,0], x[predictions == 1,i], s=50, c = '#2140ed', label = 'Iris-vergiscolor' )\n    plt.scatter(x[predictions == 2,0], x[predictions == 2,i], s=50, c = '#2cb510', label = 'Iris-virginica' )\n    #centroids of the clusters\n    plt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,i], s = 120, c = 'red', label = 'Centroids')\n    plt.title(Features[i-1],size=16)\n    plt.xlabel('Id',size=12)\n    plt.ylabel(iris_data.columns[i],size=12)\n    plt.legend()\nplt.suptitle('Clusters w.r.t Features',fontsize=20)","51385500":"Some Violin Plot is long, there might be outlier. <br>\nLet's check Box plot","cee8e68d":"#### Label Encoding of Target Variable","0c8966c4":">From K= 1 to K= 2, there is large drop<br>\n>From K= 2 to K= 3, there is slight drop<br>\n> After K= 3, slop is almost constant\n\nHence, value of **`K=3`**  implies an Optimal Value of K-Clusters","44797084":"We can conclude from above information:\n1.   All Columns are Filled i.e. There is no Null value present\n2.   Iris Data contains 6 columns out of which :<br>\n  **`Id`** column is unique.<br>\n  **`Species`** is the Target<br>\n  **`SepalLengthCm`, `SepalWidthCm`, `PetalLengthCm`, `PetalWidthCm`** are Features<br>","3549e90d":"From above Two graphs, we can see that\n* Sepal Length and Width have low correlation   \n* Petal Length and Width have high correlation\n","f8788ef7":"### Importing libraries and Data set","20b89c3d":">From the pairplot, we can see that the `Iris-setosa` species is separataed from the other two across all feature combinations","bc5637e2":"### Exploratory Analysis","c47ab7ca":"> The Sepal Width and Length are not correlated The Petal Width and Length are highly correlated","34c8acd4":"> We can see some Outliers","27014d0b":"## Task 2 : Prediction using Unsupervised ML\n\n* From the given \u2018Iris\u2019 dataset, predict the optimum number of clusters and represent it visually.<br>\n\n> ##### **By:** Rutuja Vaidya\n> ##### **Technique used:** UnSupervised ML: K-Means\n> ##### **Language used:** Python","ac38f8f1":"### Predicting Optimal Values for K","9117e54c":"#### From above graphs and Elbow Curve, we can see at `K = 3`, we get Optimal Clusters. ","27faf8e6":"> Target **`Species`** has categorical values\n\nLet's check its unique values"}}