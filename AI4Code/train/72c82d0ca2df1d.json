{"cell_type":{"b830fbe9":"code","0f306c24":"code","5678a3d7":"code","9a69e803":"code","de48ae9b":"code","71e3eb66":"code","6e648cc9":"code","1b64c2f0":"code","bd68bbea":"code","b61f2059":"code","940a65b0":"code","eda9a56e":"code","8abf8be9":"code","9fdae579":"code","891ac51e":"code","e9b1e7cb":"code","c8f459dc":"code","3cc73962":"code","9c7f6c69":"code","ec69b791":"code","304a8bbc":"code","a3d3bbe6":"code","c96d1a9c":"code","dd13fd8e":"code","f3987c27":"code","d305e733":"code","39af0158":"code","f3c17ca4":"code","42cad666":"code","81cd4057":"code","868faf0b":"code","db04d18b":"code","7c7982d3":"code","7e1d76c9":"code","3c208af8":"code","d1ba4863":"code","4f8853a7":"code","f6cea70b":"code","4b5df7fd":"code","4fedac67":"code","8a474699":"code","ed87752b":"code","df8cabfc":"markdown","9ecfc7af":"markdown","8c605b0d":"markdown","3d258a04":"markdown","ab7cb062":"markdown","5b236b80":"markdown","1a28cac8":"markdown","435d7b80":"markdown","61be3a26":"markdown","6c617913":"markdown","607fc7e8":"markdown","0691b768":"markdown","6029ed42":"markdown","764ac6a5":"markdown","61c79891":"markdown","a3c1e949":"markdown","111720ba":"markdown","5a4548c2":"markdown","3725c98d":"markdown","05d08eef":"markdown","6237be1c":"markdown","b67062eb":"markdown","72d0bd76":"markdown","88d3d96b":"markdown","233567da":"markdown","7b2ae687":"markdown","8b78244c":"markdown","4e83390b":"markdown","703575d5":"markdown","45640e9d":"markdown"},"source":{"b830fbe9":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport cv2\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom numpy import expand_dims\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom sklearn.model_selection import train_test_split\nimport gc\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom sklearn.metrics import auc\nfrom sklearn.metrics import roc_curve\nfrom IPython.display import clear_output\nprint('Importing process completed')","0f306c24":"os.listdir('\/kaggle\/input\/covid19-radiography-database\/COVID-19 Radiography Database')","5678a3d7":"#Exploring the dataset directory in more depth\n#Run just in case you want to know the images are segmented in each folder\n\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))","9a69e803":"normal_quantity = 0\nvpneumonia_quantity = 0\ncovid_quantity = 0\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        if filename.endswith('.png'):\n            if 'NORMAL' in filename:\n                normal_quantity += 1\n            if 'Viral' in filename:\n                vpneumonia_quantity += 1\n            if 'COVID' in filename:\n                covid_quantity += 1\n\nprint('Normal category quantity: ',normal_quantity)\nprint('Viral Pneumonia category quantity: ',vpneumonia_quantity)\nprint('COVID category quantity: ',covid_quantity)","de48ae9b":"%matplotlib inline\n\nplt.figure(figsize=(30,20))\n\nax1 = plt.subplot(131)\nplt.imshow(mpimg.imread('\/kaggle\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/COVID\/COVID (4).png'))\n\nax2 = plt.subplot(132)\nplt.imshow(mpimg.imread('\/kaggle\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/COVID\/COVID (27).png'))\n\nax3 = plt.subplot(133)\nplt.imshow(mpimg.imread('\/kaggle\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/COVID\/COVID (30).png'))\n\nplt.show()","71e3eb66":"%matplotlib inline\n\nplt.figure(figsize=(30,20))\n\nax1 = plt.subplot(131)\nplt.imshow(mpimg.imread('\/kaggle\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/Viral Pneumonia\/Viral Pneumonia (49).png'))\n\nax2 = plt.subplot(132)\nplt.imshow(mpimg.imread('\/kaggle\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/Viral Pneumonia\/Viral Pneumonia (82).png'))\n\nax3 = plt.subplot(133)\nplt.imshow(mpimg.imread('\/kaggle\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/Viral Pneumonia\/Viral Pneumonia (1114).png'))\n\nplt.show()","6e648cc9":"#Let's plot some normal images randomly to know how they look like, so we can determine important factors as color.\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nplt.figure(figsize=(30,20))\n\nax1 = plt.subplot(131)\n#cv2.imread('data\/src\/lena.jpg')\nplt.imshow(mpimg.imread('\/kaggle\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/NORMAL\/NORMAL (764).png'))\n\nax2 = plt.subplot(132)\nplt.imshow(mpimg.imread('\/kaggle\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/NORMAL\/NORMAL (277).png'))\n\nax3 = plt.subplot(133)\nplt.imshow(mpimg.imread('\/kaggle\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/NORMAL\/NORMAL (121).png'))\n\nplt.show()","1b64c2f0":"#Let's test this hypothesis:\nprint('Shape of image array using cv2.imread: ',cv2.imread('\/kaggle\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/NORMAL\/NORMAL (764).png').shape)\nprint('Shape of image array using mpimg.imread: ',mpimg.imread('\/kaggle\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/NORMAL\/NORMAL (764).png').shape)","bd68bbea":"normal_shape = []\nvpneumonia_shape = []\ncovid_shape = []\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        if filename.endswith('.png'):\n            if 'NORMAL' in filename:\n                normal_shape.append(cv2.imread(os.path.join(dirname, filename)).shape)\n            if 'Viral' in filename:\n                vpneumonia_shape.append(cv2.imread(os.path.join(dirname, filename)).shape)\n            if 'COVID' in filename:\n                covid_shape.append(cv2.imread(os.path.join(dirname, filename)).shape)\nprint('Unique shapes at Normal images set: ',set(normal_shape))\nprint('Unique shapes at Viral Pneumonia images set: ',set(vpneumonia_shape))\nprint('Unique shapes at COVID images set: ',set(covid_shape))","b61f2059":"%matplotlib inline\nplt.figure()\nimage = cv2.imread('\/kaggle\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/NORMAL\/NORMAL (121).png')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nimage = cv2.resize(image, (128, 128))\n#image = image.astype('float32')\n#image \/= 255.0\nplt.imshow(image)\nplt.show()      ","940a65b0":"def data_augmentation(dirname,filename):\n    \n    \"\"\"\n    This function will perform data augmentation: \n    for each one of the images, will create shifted, expanded\/reduced, darker\/lighter, rotated images. 9 for every modification type. \n    In total, we will create 36 extra images for every one in the original dataset.\n    \"\"\"\n    \n    image_data = []\n    #reading the image\n    image = cv2.imread(os.path.join(dirname, filename))\n    #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, (128, 128))\n    #image = image.astype('float32')\n    #image \/= 255.0\n    #expanding the image dimension to one sample\n    samples = expand_dims(image, 0)\n    # creating the image data augmentation generators\n    datagen1 = ImageDataGenerator(width_shift_range=[-20,20])\n    datagen2 = ImageDataGenerator(zoom_range=[0.8,1.0])\n    datagen3 = ImageDataGenerator(brightness_range=[0.5,1.0])\n    datagen4 = ImageDataGenerator(rotation_range=20)\n      \n    # preparing iterators\n    it1 = datagen1.flow(samples, batch_size=1)\n    it2 = datagen2.flow(samples, batch_size=1)\n    it3 = datagen3.flow(samples, batch_size=1)\n    it4 = datagen4.flow(samples, batch_size=1)\n    image_data.append(image)\n    for i in range(9):\n        # generating batch of images\n        batch1 = it1.next()\n        batch2 = it2.next()\n        batch3 = it3.next()\n        batch4 = it4.next()\n        # convert to unsigned integers\n        image1 = batch1[0].astype('uint8')\n        image2 = batch2[0].astype('uint8')\n        image3 = batch3[0].astype('uint8')\n        image4 = batch4[0].astype('uint8')\n        #appending to the list of images\n        image_data.append(image1)\n        image_data.append(image2)\n        image_data.append(image3)\n        image_data.append(image4)\n        \n    return image_data","eda9a56e":"#Let's test our function.\nresult = data_augmentation('\/kaggle\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/NORMAL','NORMAL (121).png')","8abf8be9":"#Let's plot an image\n%matplotlib inline\nplt.figure()\nimage = result[5]\nplt.imshow(image)\nplt.show()  ","9fdae579":"def data_transformation(keyword):\n    \n    \"\"\"\n    This function receives a keyword as parameter to determine the kind of set it's going to process.\n    It uses data_augmentation function to expand the image quantity, then resizes the images and finally returns a list containing the images already processed.\n    IMPORTANT: Maybe you'll notice we don't use any Keras method which could make easier the image processing. Instead, we decided to process the images using our own functions.\n    \"\"\"\n    \n    images = []\n    counter = 0\n    \n    if keyword == 'NORMAL':\n        for dirname, _, filenames in os.walk('\/kaggle\/input'):\n            for filename in filenames:\n                if (filename.endswith('.png')) and ('NORMAL' in filename):\n                    image = cv2.imread(os.path.join(dirname, filename))\n                    #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                    image = cv2.resize(image, (128, 128))\n                    #image = image.astype('float32')\n                    #image \/= 255.0\n                    images.append(image)\n                    counter += 1\n        for dirname, _, filenames in os.walk('\/kaggle\/input'):\n            for filename in filenames:\n                if (filename.endswith('.png')) and ('NORMAL' in filename):\n                    result = data_augmentation(dirname,filename)\n                    for i in range(len(result)):\n                        if i==0:\n                            continue\n                        else:\n                            images.append(result[i])\n                            counter += 1\n                if counter >= 8000:\n                    break\n            if counter >= 8000:\n                break\n                \n    if keyword == 'Viral':\n        for dirname, _, filenames in os.walk('\/kaggle\/input'):\n            for filename in filenames:\n                if (filename.endswith('.png')) and ('Viral' in filename):\n                    image = cv2.imread(os.path.join(dirname, filename))\n                    image = cv2.resize(image, (128, 128))\n                    #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                    #image = image.astype('float32')\n                    #image \/= 255.0\n                    images.append(image)\n                    counter += 1\n        for dirname, _, filenames in os.walk('\/kaggle\/input'):\n            for filename in filenames:\n                if (filename.endswith('.png')) and ('Viral' in filename):\n                    result = data_augmentation(dirname,filename)\n                    for i in range(len(result)):\n                        if i==0:\n                            continue\n                        else:\n                            images.append(result[i])\n                            counter += 1\n                if counter >= 8000:\n                    break\n            if counter >= 8000:\n                break\n                            \n    if keyword == 'COVID':\n        for dirname, _, filenames in os.walk('\/kaggle\/input'):\n            for filename in filenames:\n                if (filename.endswith('.png')) and ('COVID' in filename):\n                    image = cv2.imread(os.path.join(dirname, filename))\n                    #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                    image = cv2.resize(image, (128, 128))\n                    #image = image.astype('float32')\n                    #image \/= 255.0\n                    images.append(image)\n                    counter += 1\n        for dirname, _, filenames in os.walk('\/kaggle\/input'):\n            for filename in filenames:\n                if (filename.endswith('.png')) and ('COVID' in filename):\n                    result = data_augmentation(dirname,filename)\n                    for i in range(len(result)):\n                        if i==0:\n                            continue\n                        else:\n                            images.append(result[i])\n                            counter += 1\n                if counter >= 8000:\n                    break\n            if counter >= 8000:\n                break\n    return images","891ac51e":"normal = data_transformation('NORMAL')[:5000]\nviral_pneumonia = data_transformation('Viral')[:5000]\ncovid = data_transformation('COVID')[:5000]\ngc.collect()","e9b1e7cb":"#Let's plot an image\n%matplotlib inline\nplt.figure()\nimage = normal[2]\nplt.imshow(image)\nplt.show()","c8f459dc":"!mkdir normal_images\n!mkdir covid_images\n!mkdir viral_images","3cc73962":"def array_to_disk(path,array):\n    for i in range(len(array)):\n        image = array[i]\n        plt.imsave(os.path.join(path,str(i)+'.png'),image)\n        clear_output(wait=True)\n        print(\"Saving to disk. Progress: \"+str(i+1)+\"\/\"+str(len(array)))","9c7f6c69":"array_to_disk('.\/normal_images',normal)","ec69b791":"array_to_disk('.\/covid_images',covid)","304a8bbc":"array_to_disk('.\/viral_images',viral_pneumonia)","a3d3bbe6":"#Class combination\nX = normal + viral_pneumonia + covid\nlen(X)","c96d1a9c":"#Transforming from list to numpy array.\nX = np.array(X)\nX.shape","dd13fd8e":"from keras.preprocessing.image import save_img\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import array_to_img","f3987c27":"!zip -r \/kaggle\/working\/output.zip \/kaggle\/working\/","d305e733":"class_names = ['Normal','Viral Pneumonia','COVID-19']","39af0158":"#Creating labels.\ny = []\nfor i in range(5000):\n    y.append(0)\nfor i in range(5000):\n    y.append(1)\nfor i in range(5000):\n    y.append(2)\ny = np.array(y)\nlen(y)","f3c17ca4":"#from keras.utils import to_categorical\n#y = to_categorical(y)","42cad666":"X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=0,shuffle=True)","81cd4057":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","868faf0b":"#del normal_shape\n#del vpneumonia_shape\n#del covid_shape\ndel X\n#del image\ndel y\ndel normal\ndel viral_pneumonia\ndel covid\ngc.collect()","db04d18b":"#X_train, X_test = X_train \/ 255.0, X_test \/ 255.0","7c7982d3":"input_img = layers.Input(shape=(128, 128, 3))\nx = keras.layers.Conv2D(128,(3, 3), activation='relu')(input_img)\nx = keras.layers.MaxPooling2D((2, 2))(x)\nx = keras.layers.Conv2D(256, (3, 3), activation='relu')(x)\nx = keras.layers.MaxPooling2D((2, 2))(x)\nx = keras.layers.Conv2D(512, (3, 3), activation='relu')(x)\nx = keras.layers.SpatialDropout2D(0.2)(x)\nx = keras.layers.Flatten()(x)\nx = keras.layers.Dense(512)(x)\nx = keras.layers.Dense(3)(x)\n\nmodel = keras.Model(input_img, x,name=\"CNN_COVID\")","7e1d76c9":"model.summary()","3c208af8":"model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])","d1ba4863":"checkpoint = ModelCheckpoint(\"\/kaggle\/working\/best_model.hdf5\", monitor='val_loss', verbose=1,save_best_only=True, mode='auto', period=1)\nhistory = model.fit(X_train, y_train, epochs=15,validation_data=(X_test, y_test),callbacks=[checkpoint])","4f8853a7":"from tensorflow.keras.models import load_model\nmodel = load_model(\"\/kaggle\/working\/best_model.hdf5\")\nmodel.evaluate(X_test, y_test)","f6cea70b":"y_pred = model.predict(X_test)","4b5df7fd":"class_names[np.argmax(y_pred[1])]","4fedac67":"class_names[y_test[1]]","8a474699":"from sklearn.metrics import confusion_matrix\nmatrix = confusion_matrix(y_test, y_pred.argmax(axis=1))","ed87752b":"import seaborn as sns\nconf_matrix = pd.DataFrame(matrix, index = ['Normal','Viral Pneumonia','COVID-19'],columns = ['Normal','Viral Pneumonia','COVID-19'])\n#Normalizing\nconf_matrix = conf_matrix.astype('float') \/ conf_matrix.sum(axis=1)[:, np.newaxis]\nplt.figure(figsize = (15,15))\nsns.heatmap(conf_matrix, annot=True, annot_kws={\"size\": 15})","df8cabfc":"## **Data augmentation & transformation**\n\nAs you noticed before, we've got just a few images for each category which will make completely impossible to train an accurate model. In this section, we'll walk you through the process of extracting more images from the current dataset implementing data augmentation techniques. Also, we will resize the images making sure they don't miss quality. At the end of this stage, we'll transform the resulting lists to numpy arrays which will be the ones that feed the model.","9ecfc7af":"As you could notice, the model is very simple but reaches very good accuracy (about 95% before final commit). We could implement more layers to make it more complex or use a pre-trained model which will deliver much better results. It's depending on the project needs and because this is a medical application, the accuracy should be much higher but like this is just a demonstration, we'll keep this model.","8c605b0d":"## Imports","3d258a04":"## Model training\n\nWe'll implement 6 epochs only as it reaches a very good accuracy number. In the other hand, we want to keep the model to generalize well.","ab7cb062":"## Model evaluation","5b236b80":"### Data splitting and shuffling\nWe'll split the data using the sklearn method to do so, dividing it into train and test subsets.","1a28cac8":"## Confusion Matrix\n\nLet's try to understand how well the predictions were achieved.","435d7b80":"# Exploration of dataset's directory","61be3a26":"# Conclusions\n\nAs we mentioned earlier, we wanted to walk you through all the issues we've encountered in this journey. \nWe showed you how to determine some important factors about images before their pre-processing. Also showed you a few kind of blocks you can find when you're dealing with image classification.\nFinally, we reached a very good accuracy implementing a very simple CNN model - If you want to achieve better results, try checking other models like MobileNetV2  and its convolutional base. \n\nFeel free to comment this post :)","6c617913":"We were right. We would need to switch and use cv2.imread instead. Let's see this time.","607fc7e8":"Download the output.zip file here -> <a href=\".\/output.zip\">output.zip <\/a><br>\nDownload the best model file here -> <a href=\".\/best_model.hdf5\">best_model.hdf5 <\/a>","0691b768":"If you're curious and want to deep dive into, inspect the model summary. It's a very simple model however.","6029ed42":"After several RAM limitations due to a huge dataset processing we've determined that we can take only 5000 images of each category, otherwise we'll be running out of memory. Our resulting dataset could be bigger if we reduce the images' size but we would lose quality, so we preferred to keep them 128x128 pixels and sacrify datase size.","764ac6a5":"Let's study the predictions deeply, though.\n\nWhat prediction do we get for y_pred[1] ?","61c79891":"## Plotting sample images\n\nEssentially we're going to plot random selected images to determine how they look like. Are they in grayscale? How good is their quality?","a3c1e949":"# Model creation, training and evaluation\n\nAs you may know, if the goal is to achieve a very good image classifier it must be Neural Network. We're not stating you can't train a classic ML model to perform this task, obviously you can, but if you want to get high performance classifer, you should consider a Neural Network model.\n\nIn this case we will create our own Convolutional Neural Network and will keep it as simpler as possible, with some help of TensorFlow.","111720ba":"As you may see above, looks like our method (mpimg.imread()) is not taking the image array dimensions properly. To discard it's an issue with the method and not the images we're going to test with other method from the cv2 library.","5a4548c2":"### COVID RX images","3725c98d":"As you could read before, we've been dealing with some RAM issues as per this notebook only has 16 GBs. This is the reason why we have to free some memory along this notebook.","05d08eef":"### Label encoding:\n\n* Normal: 0\n* Viral Pneumonia: 1\n* COVID-19: 2","6237be1c":"# **Project Description**\n\nIn this opportunity we're going to explore the COVID-19 Radiography dataset available at https:\/\/www.kaggle.com\/tawsifurrahman\/covid19-radiography-database - such recopilation has been created by a team of researchers from Qatar, Bangladesh and some collaborators from Pakistan and Malaysia. Essentially it contains several chest X-ray images for COVID-19 positive cases along with Normal and Viral Pneumonia images.\n\nIn the dataset there are 219 COVID-19 positive images, 1341 normal images and 1345 viral pneumonia images.\n\nThis notebook will go through all the steps for data preprocessing, all the issues encountered about it, a model creation and finally some testing predictions to determine how accurate our model is.","b67062eb":"We will use cv2.imread from now on. Let's see if this method allows us to render the images properly now.","72d0bd76":"## CNN architecture and model explanation\n\nA very common architecture for a CNN is a stack of Conv2D and MaxPooling layers followed by a few densily connected layers.\nThe core idea is that the stack of Convolutional and MaxPooling layers extract the features from the image, then these features are flattened and feed to densily connected layers that determine the class of an image based on the presence of features.\n\n* Layer 1: Our images are 128x128 pixels of dimension; in addition, our input layer will contain 128 filters of size 3x3. In other words, we will detect 128 patterns and our response map will have dimension 126x126 (3x42 = 126) and depth of 128.\n\n* Layer 2: The idea behind a pooling layer is to downsample our feature maps and reduce our dimensions. In this case the window will be a 2x2 frame with stride of 2 (default).\n\n* Other layers: The next ones do very similar things but take as input the feature map from the previous layer. They increase the frequency of the filters (because previous layers shrink spacial dimensions) in order to gain more depth.","88d3d96b":"# Data Preprocessing\n\nDuring this section we'll go through taking the dataset and preparing it to then feed a CNN model. We've encountered some challenges you must be aware of before continuing the reading.","233567da":"### Normal RX images","7b2ae687":"What is the actual class?","8b78244c":"# Image exploration\nIn this section we're going to explore some important factors such as size, what color format they do have, do they really have the quantity expected? ","4e83390b":"## Model creation","703575d5":"The line below is VERY important. In order to train the model easier and faster we need to normalize the dataset. We'll keep it the way it is due to RAM capacity issues.","45640e9d":"### Viral Pneumonia RX images"}}