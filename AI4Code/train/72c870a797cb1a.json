{"cell_type":{"3f186982":"code","129fb82a":"code","e8f2ffd0":"code","4606948d":"code","41e4b074":"code","19d93508":"code","eb7547d9":"code","ad713034":"code","93a7bbda":"code","54c45970":"code","6328635b":"code","b31f281c":"code","1cfeedaf":"code","4357a2ba":"code","f5c25857":"code","ece1a087":"code","7d0112a4":"code","378fee42":"code","3602eec7":"code","94ee27e9":"code","5b581db8":"markdown","f143ba46":"markdown","3b1d4a11":"markdown","ab3c66f9":"markdown","4d044a8c":"markdown","3e9ccba3":"markdown","3ccec8c1":"markdown","b6a1cd10":"markdown","bd4513e5":"markdown","42b770d3":"markdown","134175db":"markdown","6bc4f77d":"markdown","d8880083":"markdown","d164e25d":"markdown","905dd52d":"markdown","531bb728":"markdown","e594a186":"markdown","f2a525a6":"markdown","827f1b2c":"markdown"},"source":{"3f186982":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport math\nfrom sklearn.model_selection import train_test_split\nimport itertools\nfrom itertools import chain, combinations\nimport scipy.special\n\nimport plotly\nfrom plotly.graph_objs import Scatter, Layout, Heatmap, Bar, Scene, XAxis, YAxis, ZAxis\nimport plotly.figure_factory as ff\nimport plotly.graph_objs as go\nfrom plotly import tools\n   \nimport shap    \n\nimport warnings  \nwarnings.filterwarnings('ignore')\n\nnp.random.seed(10)\n\nplotly.offline.init_notebook_mode(connected=True)","129fb82a":"dt = pd.read_csv('..\/input\/heart.csv')\ndt.head()","e8f2ffd0":"class ModelUCI1:\n    def __init__(self, data):\n        self.data = data\n        self.X_oryg = self.data[[x for x in dt.columns if x != 'target']].values\n        #normalized input, no-one-hot version\n        self.X = np.apply_along_axis(lambda x: (x-x.min())\/(x.max()-x.min()), 0, self.X_oryg)\n        self.y = self.data.target.values\n        self.X_train, self.X_test, self.y_train, self.y_test, self.X_train_oryg, self.X_test_oryg \\\n            = train_test_split(self.X, self.y, self.X_oryg, test_size=0.2, random_state=42)\n        self.build_model()\n    \n    def __del__(self):\n        try:\n            self.sess.close()\n        except:\n            pass\n\n    def build_model(self):\n        def dense(input_layer, units, name):\n            return tf.layers.dense(input_layer, units=units, activation='relu', name=name, \n                                   kernel_initializer=tf.initializers.random_normal(), \n                                   kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=0.1))\n    \n        self.graph = tf.Graph()\n        with self.graph.as_default():\n            tf.set_random_seed(10)\n            \n            self.x_input = tf.placeholder(tf.float32, shape=[None, self.X_train.shape[1]], name='x_input')\n            self.dense_1 = dense(self.x_input, 64, 'dense_1')\n            self.dense_2 = dense(self.dense_1, 32, 'dense_2')\n            self.dense_3 = dense(self.dense_2, 16, 'dense_3')\n            self.output = tf.layers.dense(self.dense_3, units=2, activation=None, name='output') \n            \n            self.y_target = tf.placeholder(tf.int64, shape=[None], name='target') \n            self.learning_rate = 0.01            \n            self.loss_fn = tf.reduce_mean(\n                tf.nn.sparse_softmax_cross_entropy_with_logits(logits=self.output, labels=self.y_target))\n            self.train_op = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss_fn) \n            \n    def train(self):\n        n_samples = self.X_train.shape[0]\n        n_epochs = 200\n        batch_size = 16\n        n_batches = math.ceil(n_samples\/batch_size)\n\n        with self.graph.as_default():\n            dataset = tf.data.Dataset.from_tensor_slices({'X':self.X_train,'y': self.y_train})\n            dataset = dataset.shuffle(300).batch(batch_size).repeat(n_epochs)\n            iter = dataset.make_one_shot_iterator()\n            next_elem = iter.get_next() \n            init_op = tf.global_variables_initializer()\n            self.sess = tf.Session()\n            self.sess.run(init_op)\n            for epoch in range(n_epochs):\n                for i in range(n_batches):\n                    batch = self.sess.run(next_elem)\n                    feed_dict = {self.x_input: batch['X'], self.y_target: batch['y']}\n                    loss, _ = self.sess.run([self.loss_fn, self.train_op], feed_dict)\n\n    def predict(self, X_test):\n        with model.graph.as_default():\n            predictions = self.sess.run(tf.argmax(tf.nn.softmax(self.output), axis=1), {self.x_input: X_test})\n            return predictions\n        \n    def acc(self, y_pred, y_true):\n        return len([x for x in abs(y_true - y_pred) if x == 0])\/len(y_pred)","4606948d":"model = ModelUCI1(dt)\nmodel.train()","41e4b074":"X_test_preds = model.predict(model.X_test)\nprint('test accuracy: ', model.acc(X_test_preds, model.y_test))","19d93508":"e_kernel = shap.KernelExplainer(model.predict, model.X_train, link='identity')\nshap_values_kernel = e_kernel.shap_values(model.X_test)","eb7547d9":"#Expected value is based on the class distribution in the background dataset\nprint('Kernel SHAP expected value:', e_kernel.expected_value)\nprint('Class distribution (positive to all ratio) in the background set (X_train):', \n      len([x for x in model.y_train if x==1])\/len(model.y_train))\nprint('Kernel SHAP shape:', shap_values_kernel.shape, ': No of features:', model.X_test.shape[1],\n      ' for each test sample:', model.X_test.shape[0])","ad713034":"round(max(abs(np.sum(shap_values_kernel, axis=1) + e_kernel.expected_value - X_test_preds)),6)","93a7bbda":"class SimpleExplainer:\n    '''   \n    Feature values are treated as players forming coalitions and a reference value \n    is used in place of a missing player. Model's prediction is used as score function. \n    \n    https:\/\/en.wikipedia.org\/wiki\/Shapley_value\n    '''\n    def __init__(self, reference_set=model.X_train, model_fun=model.predict):        \n        self.reference_set = reference_set\n        self.N = reference_set.shape[-1]\n        self.model_fun = model_fun\n        self.all_subsets = [self.tpl2indx(xx, self.N-1) for xx in self.powerset(range(self.N))]\n        #reference values (here: mean value for each column)        \n        self.reference = np.apply_along_axis(lambda x: x.mean(), 0, self.reference_set)\n        #expected value: model output for the empty (reference) subset\n        self.expected_value = self.model_fun([self.reference])\n        self.x_samples = None\n        self.shap_values = np.empty\n        \n    def powerset(self, range_s):\n        return chain.from_iterable(combinations(range_s, r) for r in range(len(range_s)+1))   \n\n    def tpl2indx(self, tpl, max_len):\n        return tuple(1 if i in tpl else 0 for i in range(max_len+1)) \n\n    def subset2args(self, x, reference, subset):     \n        return [ref if pres==0 else xx for xx, ref, pres in \n                [(xx,ref,pres) for xx,ref,pres in zip(x, reference, subset)]]            \n\n    def calculateSHAP(self, x_samples):\n        self.shap_values = np.asarray([self.calculateSHAP_one(x_samples[i:(i+1),:]) \n                                       for i in range(x_samples.shape[0])])\n    \n    def calculateSHAP_one(self, x_sample):\n        #calculate model output for all subsets\n        def calc_model_output4subsets(x_sample):\n            model_input_all_subsets = [self.subset2args(x_sample[0], self.reference, s) for s in self.all_subsets]\n            return dict(zip(self.all_subsets, self.model_fun(model_input_all_subsets)))\n    \n        model_output4subsets = calc_model_output4subsets(x_sample)\n        N = x_sample.shape[1]\n        binomS = dict(zip(range(N+1), [int(scipy.special.binom(N-1,s)) for s in range(N+1)]))\n        s = range(N)\n        sw = [0]*N \n        subsetsI_g = list(filter(lambda x: sum(xx == 0 for xx in x)>=1, list(model_output4subsets.keys())))\n\n        for s in subsetsI_g:\n            not_in_set = list([(i,x) for i,x in enumerate(s) if x == 0])\n            group2update = []\n            indx_not_in_set = tuple(zip(*not_in_set))[0]\n            group2update = [x[0] for x in itertools.combinations(indx_not_in_set, 1)]\n            model_output_s = model_output4subsets[s] \n            for g in group2update:\n                s_ij = tuple(1 if i in {g} else x for i,x in enumerate(s))\n                model_output_sij = model_output4subsets[s_ij]\n                sLen = len([x for x in s if x == 1])\n                sw[g] =  sw[g] + (model_output_sij-model_output_s)\/binomS[sLen]  \n        return [x\/N for x in sw]      ","54c45970":"simpleExplainer = SimpleExplainer()\nsimpleExplainer.calculateSHAP(model.X_test)\nshap_values_simple = simpleExplainer.shap_values\nprint(shap_values_simple.shape)","6328635b":"round(max(abs(np.sum(shap_values_simple, axis=1) + simpleExplainer.expected_value - X_test_preds)),6)","b31f281c":"#Glove game score function:\ndef score4Glove_game_fun(x):\n    return [1*(any(xx==1 for xx in row[0:2]) and row[2]==1) for row in x]","1cfeedaf":"simpleExplainer_glove = SimpleExplainer(reference_set=np.asarray([[0,0,0]]), model_fun=score4Glove_game_fun)        \nsimpleExplainer_glove.calculateSHAP(np.asarray([[1,1,1]]))\n{i: simpleExplainer_glove.shap_values[0][i] for i in range(3)}","4357a2ba":"def plot1(data_shap, data_features, preds, columns):\n    def x_title(feature_indx):\n        return 'SHAP value for feature: ' + columns[feature_indx]\n\n    def y_title(feature_indx):\n        return 'Feature value for: ' + columns[feature_indx]\n\n    def plot_title(feature_indx):\n        return 'SHAP value vs feature value for: ' + columns[feature_indx]\n\n    def get_plot_data(feature_indx):\n        f = data_shap.swapaxes(0,1)[feature_indx]\n        v = data_features.swapaxes(0,1)[feature_indx]\n        return {'x1': [x for x,y in zip(f, preds) if y == 1],\n                'y1': [x for x,y in zip(v, preds) if y == 1],\n                'x0': [x for x,y in zip(f, preds) if y == 0],\n                'y0': [x for x,y in zip(v, preds) if y == 0]}    \n    \n    feature_indx_default = 0\n    d0 = get_plot_data(feature_indx_default)\n    traces = [go.Scatter(x = d0['x0'], y = d0['y0'], mode='markers', name='negative'),\n              go.Scatter(x = d0['x1'], y = d0['y1'], mode='markers', name='positive')]\n    \n    options = []\n    feature_cnt = len(columns)\n    for feature_indx in range(feature_cnt):\n        feature_name = model.data.columns[feature_indx]\n        options.append(\n            dict(label = feature_name,\n                method = 'update',\n                args = [{'x': \\\n                         [get_plot_data(feature_indx)['x0'],\n                          get_plot_data(feature_indx)['x1']],\n                         'y': \\\n                         [get_plot_data(feature_indx)['y0'],\n                          get_plot_data(feature_indx)['y1']]},\n                        {'title': plot_title(feature_indx), 'xaxis': {'title': x_title(feature_indx)}, \n                        'yaxis': {'title':y_title(feature_indx)}}]))\n    return {'traces': traces, 'options': options, 'plot_title': plot_title(feature_indx_default),\n            'xtitle': x_title(feature_indx_default), 'ytitle': y_title(feature_indx_default)}   \n\nplot = plot1(shap_values_kernel, model.X_test_oryg, X_test_preds, model.data.columns[:-1])\n\nupdatemenus = list([\n    dict(active=0,\n         buttons=plot['options'],\n         y=1.4\n    )\n])\n\nlayout = Layout(title = plot['plot_title'], xaxis = {'title': plot['xtitle']}, yaxis = {'title': plot['ytitle']},\n               updatemenus=updatemenus)\n\nplotly.offline.iplot({'data': plot['traces'], 'layout': layout})","f5c25857":"shap.summary_plot(shap_values_kernel, pd.DataFrame(model.X_test_oryg, \n    columns=[x for x in model.data.columns if x != 'target']))","ece1a087":"f1 = 0\nf2 = 1\nf3 = 2\ndata4f = shap_values_kernel.swapaxes(0,1)\nfeature_cnt = len(model.data.columns[:-1])\n\ndef get_data4feature(feature_indx):\n    return data4f[feature_indx]\n\ndef get_data4axis(axis):\n    options = []\n    for feature_indx in range(feature_cnt):\n        feature_name = model.data.columns[feature_indx]\n        options.append(dict(args = [{axis: [get_data4feature(feature_indx)]}],\n                label = feature_name,\n                method = 'update' ))\n    return list(options)    \n\nupdatemenus=list([\n    dict( \n        active = f1,\n        buttons = get_data4axis('x'),\n        x = 0.1,\n        y = 1.2\n    ),\n    dict(\n        active = f2,\n        buttons = get_data4axis('y'),\n        x = 0.3,\n        y = 1.2\n    ),   \n    dict(\n        active = f3,\n        buttons = get_data4axis('z'),\n        x = 0.5,\n        y = 1.2\n    )    \n])\n\ncols = ['green' if x == 0 else 'orange' for x in X_test_preds]\ndata = [go.Scatter3d(\n    x = get_data4feature(f1),\n    y = get_data4feature(f2),\n    z = get_data4feature(f3),\n    mode = 'markers',\n    marker = dict(color = cols))]\n\nannotations = list([\n    dict(text='X-axis', x=-0.05, y=1.27, yref='paper', align='left', showarrow=False ),\n    dict(text='Y-axis', x=0.15, y=1.27, yref='paper', showarrow=False ),\n    dict(text='Z-axis', x=0.38, y=1.27, yref='paper', showarrow=False),\n    dict(text='Negative', x=1, y=1, bgcolor='green', align='left', showarrow=False),\n    dict(text='Positive', x=1, y=0.9, bgcolor='orange', align='left', showarrow=False)\n])\n\nlayout = Layout(updatemenus = updatemenus, annotations = annotations, \n                title = {'text': 'SHAP values for features', 'y': 0},\n                scene=Scene(aspectratio=dict(x = 1, y = 1, z = 1)))\n\nplotly.offline.iplot({'data': data, 'layout': layout})","7d0112a4":"def plot_violin(data_shap, data_features, preds, columns):\n    traces = []\n    data_shap_f = data_shap.swapaxes(0,1)\n    data_features_f = data_features.swapaxes(0,1)\n    for feature_indx in range(len(columns)):\n        f = data_shap_f[feature_indx]\n        v = data_features_f[feature_indx]\n        feature_name = columns[feature_indx]\n        traces.append({'meanline': {'visible': True},\n                'name': feature_name, 'type': 'violin', \n                 'x': pd.Series([feature_name]*len(v)), \n                 'y': pd.Series(f)})\n    return traces\n     \nplotly.offline.iplot({'data': plot_violin(shap_values_kernel, model.X_test_oryg, X_test_preds, model.data.columns[:-1]),\n                    'layout': Layout(title = 'SHAP values for features')})","378fee42":"data_shap_0 = [x for x,y in zip(shap_values_kernel, X_test_preds) if y == 0]\ndata_shap_1 = [x for x,y in zip(shap_values_kernel, X_test_preds) if y == 1]\n\ny0 = [xx for x in data_shap_0 for xx in x]    \ny1 = [xx for x in data_shap_1 for xx in x]\nx0 = list(model.data.columns[:-1])*len([x for x,y in zip(shap_values_kernel, X_test_preds) if y == 0])\nx1 = list(model.data.columns[:-1])*len([x for x,y in zip(shap_values_kernel, X_test_preds) if y == 1])\n\ndef data_violin(x, y, caption, side, color):\n    return  {\"type\": 'violin', \"x\": x, \"y\": y, \"legendgroup\": caption, \"scalegroup\": caption,\n            \"name\": caption, \"side\": side, \"meanline\": {\"visible\": True},\n            \"line\": {\"color\": color}}  \n\nfig = {\n    \"data\": [data_violin(x0, y0, 'Negative', 'negative', 'green'), data_violin(x1, y1, 'Positive', 'positive', 'blue')],\n    \"layout\" : {\n        \"yaxis\": {\"zeroline\": True,},\n        \"violingap\": 0,\n        \"violinmode\": \"overlay\",\n        \"title\": \"Split violin plot for positive and negative outputs\"\n    }\n}\n\nplotly.offline.iplot(fig)","3602eec7":"def plot_rank_all():\n    shap4features = shap_values_kernel.swapaxes(0,1)    \n    values4features = model.X_test_oryg.swapaxes(0,1)\n    traces = []\n    for feature_indx in range(len(model.data.columns[:-1])):\n        feature_name = model.data.columns[feature_indx]\n        f = shap4features[feature_indx]\n        v = values4features[feature_indx]\n        #rank vector of the value list\n        v_rank = [sorted(v).index(x) for x in v]\n        f_sorted_by_v = [y for x,y in sorted(zip(v_rank, f))]\n        traces.append(go.Scatter(y = f_sorted_by_v,\n            mode='lines+markers', name = feature_name ) )       \n    return traces\n\nlayout = Layout(title = 'SHAP value for feature rank', \n                xaxis = {'title': 'Feature rank'}, \n                yaxis = {'title': 'SHAP value'})\n\nplotly.offline.iplot({'data': plot_rank_all(), 'layout': layout})","94ee27e9":"shap4features = shap_values_kernel.swapaxes(0,1)    \nvalues4features = model.X_test_oryg.swapaxes(0,1)\n\ndef plot_lines_get_data(feature_indx):\n    traces = []\n    f = shap4features[feature_indx]\n    v = values4features[feature_indx]\n    feature_name = model.data.columns[feature_indx]\n    v_rank = [sorted(v).index(x) for x in v]\n    f_sorted_by_v = [y for x,y in sorted(zip(v_rank, f))]\n    return {'y': f_sorted_by_v, \n            'title': feature_name + \": SHAP value vs rank\", \n            'xtitle': 'Feature rank for ' + feature_name, \n            'ytitle': 'SHAP value for ' + feature_name}\n\ndef plot_lines_get_menus():\n    options = []\n    for feature_indx in range(len(model.data.columns[:-1])):\n        feature_name = model.data.columns[feature_indx]\n        d = plot_lines_get_data(feature_indx)\n        options.append(\n                  dict(label = feature_name,\n                      method = 'update',\n                      args = [{'y': [d['y']]},\n                              {'title': d['title'], 'xaxis': {'title': d['xtitle']}, \n                              'yaxis': {'title': d['ytitle']}}]\n                      ))\n    return options\n\nfeature_indx_default = 0\nplot_data = plot_lines_get_data(feature_indx_default)\ndata = [go.Scatter(y = plot_data['y'], mode='lines+markers')]\n\nupdatemenus=list([dict(active = feature_indx_default, y = 1.2, buttons = plot_lines_get_menus())])   \n\nlayout = Layout(updatemenus = updatemenus, title = plot_data['title'],\n               xaxis = {'title': plot_data['xtitle']}, yaxis = {'title': plot_data['ytitle']})\n\nplotly.offline.iplot({'data': data, 'layout': layout})","5b581db8":"# 4.5.2 By feature\nThe plot shows SHAP values against ordered values of the respective feature.","f143ba46":"In the Wiki example:\n\n$\\varphi _{1}(v)=\\!\\left({\\frac {1}{6}}\\right)(1)={\\frac {1}{6}}$\n\n$ \\varphi _{2}(v)=\\varphi _{1}(v)={\\frac {1}{6}}$\n\n$\\varphi _{3}(v)={\\frac {4}{6}}={\\frac {2}{3}}$","3b1d4a11":"# 4. Interactive plots\n# 4.1 Scatter plot","ab3c66f9":"# 3.2.2 Simple example: SHAP for the Glove game\nThe Wikipedia article on Shapley value uses an example of the __[Glove game](https:\/\/en.wikipedia.org\/wiki\/Shapley_value#Glove_game)__.\nSimple implementation of SHAP can be used to calculate the contribution of individual players to the result of the game.","4d044a8c":"# 4.3 Scatter3d SHAP","3e9ccba3":"For each sample, the model's expected value and shap values sum up to the model's prediction:\n","3ccec8c1":"# 4.4.2 Features and output - split violin","b6a1cd10":"# 3.2.1 SHAP values for the UCI heart disease data set","bd4513e5":"# 3.2 Toy implementation of SHAP values\nKernel SHAP is model-agnostic and only requires a function returning the score for a given sample.\nThis is a naive straightforward implementation of the Shapley Value algorithm for one-actor coalitions.\n\n__[Wiki Shapley value](https:\/\/en.wikipedia.org\/wiki\/Shapley_value)__\n\n<center>\n$\\varphi _{i}(v)={\\frac {1}{N}}\\sum _{S\\subseteq N\\setminus \\{i\\}}{\\binom {N-1}{|S|}}^{-1}(v(S\\cup \\{i\\})-v(S))$\n<\/center>","42b770d3":"# Content\n1. Calculation of SHAP values for a Tensorflow model with:\n    - KernelExplainer from the SHAP package \n    - Toy implementation of the Shapley Value algorithm\n2. Interactive visualization with Plotly library \n\n**Reference:** For information on interpreting models and Plotly visualization, you can refer to the documentation of the [SHAP package](https:\/\/github.com\/slundberg\/shap) and [Plotly](https:\/\/plot.ly\/python\/) library, the [Interpretable Machine Learning](https:\/\/christophm.github.io\/interpretable-ml-book\/) website or check out kernels: [Intermediate visualization tutorial using Plotly ](https:\/\/www.kaggle.com\/thebrownviking20\/intermediate-visualization-tutorial-using-plotly) and \n[What Causes Heart Disease? Explaining the Model](https:\/\/www.kaggle.com\/tentotheminus9\/what-causes-heart-disease-explaining-the-model).","134175db":"# 2.2 Train and predict ","6bc4f77d":"# 1. Data","d8880083":"For each sample, the model's expected value and shap values add up to the model's prediction:","d164e25d":"# 4.2 Summary plot from the SHAP library\nSummary plot from the shap library for comparison","905dd52d":"**Kernel SHAP values with Plotly interactive visualization for the UCI Heart Disease data set**","531bb728":"# 4.4 Violin plot\n# 4.4.1 Features","e594a186":"# 4.5 Line scatter plot \n# 4.5.1 All features\nThe plot shows SHAP values against ordered values of the respective feature.","f2a525a6":"# 2. Tensorflow model\n# 2.1 Build model","827f1b2c":"# 3. SHAP values\n# 3.1 KernelExplainer from the SHAP package\nModel's prediction is being treated like a black-box function."}}