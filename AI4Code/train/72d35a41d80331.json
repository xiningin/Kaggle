{"cell_type":{"518d4ae4":"code","3adda3c2":"code","cf7339e0":"code","4cab0322":"code","0877f458":"code","1650c713":"code","900dd2da":"code","2a3fa60d":"code","d82e9984":"code","b8a7f141":"code","7840982c":"code","78f04484":"code","37d328ae":"code","3f4879f5":"code","a2a50551":"code","27d5bf1b":"code","a3f8de95":"markdown","60872af8":"markdown","60d553aa":"markdown","e47ee85e":"markdown","b430f9a9":"markdown","6e5cb95a":"markdown","d5e9dd59":"markdown","aea8ffa2":"markdown","689e40f9":"markdown","387bf914":"markdown","7a2c4428":"markdown","98c64b6b":"markdown"},"source":{"518d4ae4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3adda3c2":"# importing important libraries\n%matplotlib inline\n\nimport numpy as np\nimport torch\nimport matplotlib.pyplot as plt","cf7339e0":"from torchvision import datasets\nimport torchvision.transforms as transforms\n\n# number of subprocesses to use for data loading\nnum_workers = 0\n# how many samples per batch to load\nbatch_size = 64\n\n# convert data to torch.FloatTensor\ntransform = transforms.ToTensor()\n\n# get the training datasets\ntrain_data = datasets.MNIST(root='data', train=True,\n                                   download=True, transform=transform)\n\n# prepare data loader\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n                                           num_workers=num_workers)","4cab0322":"# obtain one batch of training images\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\nimages = images.numpy()\n\n# get one image from the batch\nimg = np.squeeze(images[0])\n\nfig = plt.figure(figsize = (3,3)) \nax = fig.add_subplot(111)\nax.imshow(img, cmap='gray')","0877f458":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Discriminator(nn.Module):\n\n    def __init__(self, input_size, hidden_dim, output_size):\n        super(Discriminator, self).__init__()\n        \n        # define hidden linear layers\n        self.fc1 = nn.Linear(input_size, hidden_dim*4)\n        self.fc2 = nn.Linear(hidden_dim*4, hidden_dim*2)\n        self.fc3 = nn.Linear(hidden_dim*2, hidden_dim)\n        \n        # final fully-connected layer\n        self.fc4 = nn.Linear(hidden_dim, output_size)\n        \n        # dropout layer \n        self.dropout = nn.Dropout(0.3)\n        \n        \n    def forward(self, x):\n        \n        # flatten image\n        x = x.view(-1, 28*28)\n        \n        # all hidden layers\n        x = F.leaky_relu(self.fc1(x), 0.2) # (input, negative_slope=0.2)\n        x = self.dropout(x)\n        x = F.leaky_relu(self.fc2(x), 0.2)\n        x = self.dropout(x)\n        x = F.leaky_relu(self.fc3(x), 0.2)\n        x = self.dropout(x)\n        \n        # final layer\n        out = self.fc4(x)\n\n        return out","1650c713":"class Generator(nn.Module):\n\n    def __init__(self, input_size, hidden_dim, output_size):\n        super(Generator, self).__init__()\n        \n        # define hidden linear layers\n        self.fc1 = nn.Linear(input_size, hidden_dim)\n        self.fc2 = nn.Linear(hidden_dim, hidden_dim*2)\n        self.fc3 = nn.Linear(hidden_dim*2, hidden_dim*4)\n        \n        # final fully-connected layer\n        self.fc4 = nn.Linear(hidden_dim*4, output_size)\n        \n        # dropout layer \n        self.dropout = nn.Dropout(0.3)\n\n    def forward(self, x):\n        \n        # all hidden layers\n        x = F.leaky_relu(self.fc1(x), 0.2) # (input, negative_slope=0.2)\n        x = self.dropout(x)\n        x = F.leaky_relu(self.fc2(x), 0.2)\n        x = self.dropout(x)\n        x = F.leaky_relu(self.fc3(x), 0.2)\n        x = self.dropout(x)\n        \n        # final layer with tanh applied\n        out = F.tanh(self.fc4(x))\n\n        return out","900dd2da":"# Discriminator hyperparams\n\n# Size of input image to discriminator (28*28)\ninput_size = 784\n# Size of discriminator output (real or fake)\nd_output_size = 1\n# Size of last hidden layer in the discriminator\nd_hidden_size = 32\n\n# Generator hyperparams\n\n# Size of latent vector to give to generator\nz_size = 100\n# Size of discriminator output (generated image)\ng_output_size = 784\n# Size of first hidden layer in the generator\ng_hidden_size = 32","2a3fa60d":"# instantiate discriminator and generator\nD = Discriminator(input_size, d_hidden_size, d_output_size)\nG = Generator(z_size, g_hidden_size, g_output_size)","d82e9984":"# Calculate losses\n\ndef real_loss(D_out, smooth=False):\n    batch_size = D_out.size(0)\n    \n    # label smoothing\n    if smooth:\n        # smooth, real labels = 0.9\n        labels = torch.ones(batch_size)*0.9\n    else:\n        labels = torch.ones(batch_size) # real labels = 1\n        \n    # numerically stable loss\n    criterion = nn.BCEWithLogitsLoss()\n    \n    # calculate loss\n    loss = criterion(D_out.squeeze(), labels)\n    return loss\n\n\ndef fake_loss(D_out):\n    batch_size = D_out.size(0)\n    \n    labels = torch.zeros(batch_size) # fake labels = 0\n    criterion = nn.BCEWithLogitsLoss()\n    \n    # calculate loss\n    loss = criterion(D_out.squeeze(), labels)\n    return loss","b8a7f141":"import torch.optim as optim\n\n# Optimizers\nlr = 0.002\n\n# Create optimizers for the discriminator and generator\nd_optimizer = optim.Adam(D.parameters(), lr)\ng_optimizer = optim.Adam(G.parameters(), lr)","7840982c":"import pickle as pkl\n\n# training hyperparams\nnum_epochs = 100\n\n# keep track of loss and generated, \"fake\" samples\nsamples = []\nlosses = []\n\nprint_every = 400\n\n# Get some fixed data for sampling. These are images that are held\n# constant throughout training, and allow us to inspect the model's performance\nsample_size=16\nfixed_z = np.random.uniform(-1, 1, size=(sample_size, z_size))\nfixed_z = torch.from_numpy(fixed_z).float()\n\n# train the network\nD.train()\nG.train()\nfor epoch in range(num_epochs):\n    \n    for batch_i, (real_images, _) in enumerate(train_loader):\n                \n        batch_size = real_images.size(0)\n        \n        ## Important rescaling step ## \n        real_images = real_images*2 - 1  # rescale input images from [0,1) to [-1, 1)\n        \n        # ============================================\n        #            TRAIN THE DISCRIMINATOR\n        # ============================================\n        \n        d_optimizer.zero_grad()\n        \n        # 1. Train with real images\n\n        # Compute the discriminator losses on real images \n        # smooth the real labels\n        D_real = D(real_images)\n        d_real_loss = real_loss(D_real, smooth=True)\n        \n        # 2. Train with fake images\n        \n        # Generate fake images\n        z = np.random.uniform(-1, 1, size=(batch_size, z_size))\n        z = torch.from_numpy(z).float()\n        fake_images = G(z)\n        \n        # Compute the discriminator losses on fake images        \n        D_fake = D(fake_images)\n        d_fake_loss = fake_loss(D_fake)\n        \n        # add up loss and perform backprop\n        d_loss = d_real_loss + d_fake_loss\n        d_loss.backward()\n        d_optimizer.step()\n        \n        \n        # =========================================\n        #            TRAIN THE GENERATOR\n        # =========================================\n        g_optimizer.zero_grad()\n        \n        # 1. Train with fake images and flipped labels\n        \n        # Generate fake images\n        z = np.random.uniform(-1, 1, size=(batch_size, z_size))\n        z = torch.from_numpy(z).float()\n        fake_images = G(z)\n        \n        # Compute the discriminator losses on fake images \n        # using flipped labels!\n        D_fake = D(fake_images)\n        g_loss = real_loss(D_fake) # use real loss to flip labels\n        \n        # perform backprop\n        g_loss.backward()\n        g_optimizer.step()\n\n        # Print some loss stats\n        if batch_i % print_every == 0:\n            # print discriminator and generator loss\n            print('Epoch [{:5d}\/{:5d}] | d_loss: {:6.4f} | g_loss: {:6.4f}'.format(\n                    epoch+1, num_epochs, d_loss.item(), g_loss.item()))\n\n    \n    ## AFTER EACH EPOCH##\n    # append discriminator loss and generator loss\n    losses.append((d_loss.item(), g_loss.item()))\n    \n    # generate and save sample, fake images\n    G.eval() # eval mode for generating samples\n    samples_z = G(fixed_z)\n    samples.append(samples_z)\n    G.train() # back to train mode\n\n\n# Save training generator samples\nwith open('train_samples.pkl', 'wb') as f:\n    pkl.dump(samples, f)","78f04484":"fig, ax = plt.subplots()\nlosses = np.array(losses)\nplt.plot(losses.T[0], label='Discriminator')\nplt.plot(losses.T[1], label='Generator')\nplt.title(\"Training Losses\")\nplt.legend()","37d328ae":"# helper function for viewing a list of passed in sample images\ndef view_samples(epoch, samples):\n    fig, axes = plt.subplots(figsize=(7,7), nrows=4, ncols=4, sharey=True, sharex=True)\n    for ax, img in zip(axes.flatten(), samples[epoch]):\n        img = img.detach()\n        ax.xaxis.set_visible(False)\n        ax.yaxis.set_visible(False)\n        im = ax.imshow(img.reshape((28,28)), cmap='Greys_r')","3f4879f5":"# Load samples from generator, taken while training\nwith open('train_samples.pkl', 'rb') as f:\n    samples = pkl.load(f)","a2a50551":"# -1 indicates final epoch's samples (the last in the list)\nview_samples(-1, samples)","27d5bf1b":"rows = 10 # split epochs into 10, so 100\/10 = every 10 epochs\ncols = 6\nfig, axes = plt.subplots(figsize=(7,12), nrows=rows, ncols=cols, sharex=True, sharey=True)\n\nfor sample, ax_row in zip(samples[::int(len(samples)\/rows)], axes):\n    for img, ax in zip(sample[::int(len(sample)\/cols)], ax_row):\n        img = img.detach()\n        ax.imshow(img.reshape((28,28)), cmap='Greys_r')\n        ax.xaxis.set_visible(False)\n        ax.yaxis.set_visible(False)","a3f8de95":"## Define the model\nA GAN is comprised of two adversarial networks, a discriminator and a generator.\n\n### Discriminator\nThe discriminator network is going to be a pretty typical linear classifier. To make this network a universal function approximator, we'll need at least one hidden layer, and these hidden layers should have one key attribute:\n\n- All hidden layers will have a [Leaky ReLu](https:\/\/pytorch.org\/docs\/stable\/nn.html#torch.nn.LeakyReLU) activation function applied to their outputs.\n\n<img src='https:\/\/raw.githubusercontent.com\/ArpitFalcon\/DeepLearning101\/master\/05%20-%20Generative%20Adverserial%20Networks\/Lesson%2001%20-%20Intro%20to%20GAN\/assets\/gan_network.png' width=70% \/>\n\n#### Leaky ReLu\nWe should use a leaky ReLU to allow gradients to flow backwards through the layer unimpeded. A leaky ReLU is like a normal ReLU, except that there is a small non-zero output for negative input values.\n<img src='https:\/\/raw.githubusercontent.com\/ArpitFalcon\/DeepLearning101\/master\/05%20-%20Generative%20Adverserial%20Networks\/Lesson%2001%20-%20Intro%20to%20GAN\/assets\/leaky_relu.png' width=40% \/>\n\n#### Sigmoid Output\nWe'll also take the approach of using a more numerically stable loss function on the outputs. Recall that we want the discriminator to output a value 0-1 indicating whether an image is real or fake.\n\n#### BCEwithLogitsLoss\nWe will ultimately use [BCEWithLogitsLoss](https:\/\/pytorch.org\/docs\/stable\/nn.html#bcewithlogitsloss), which combines a sigmoid activation function and binary cross entropy loss in one function. So our final output should not have any activation function.\n","60872af8":"## Build Complete Network\nNow we're instantiating the discriminator and generator from the classes defined above.","60d553aa":"### Generator samples from training\nHere we can view samples of images from the generator. First we'll look at the images we saved during training","e47ee85e":"### Discriminator and Generator Losses\nNow we need to calculate the losses.\n\n\n#### Discriminator Losses\nFor the discriminator, the total loss is the sum of the losses for real and fake images, d_loss = d_real_loss + d_fake_loss.\n\n\n#### Generator Losses\nThe generator loss will look similar only with flipped labels. The generator's goal is to get D(fake_images) = 1. In this case, the labels are flipped to represent that the generator is trying to fool the discriminator into thinking that the images it generates (fakes) are real!","b430f9a9":"\nIt starts out as all noise. Then it learns to make only the center white and the rest black. You can start to see some number like structures appear out of the noise like 1s and 9s.","6e5cb95a":"### Training\nTraining will involve alternating between training the discriminator and the generator. We'll use our functions real_loss and fake_loss to help us calculate the discriminator losses in all of the following cases.\n\n#### Discriminator training\n- Compute the discriminator loss on real, training images\n- Generate fake images\n- Compute the discriminator loss on fake, generated images\n- Add up real and fake loss\n- Perform backpropagation + an optimization step to update the discriminator's weights\n\n\n#### Generator training\n- Generate fake images\n- Compute the discriminator loss on fake images, using flipped labels!\n- Perform backpropagation + an optimization step to update the generator's weights\n\n\n##### Saving Samples\nAs we train, we'll also print out some loss statistics and save some generated \"fake\" samples.","d5e9dd59":"## Model Hyperparameters","aea8ffa2":"# Generative Adversarial Network\n\nIn this notebook, we'll be building a generative adversarial network (GAN) trained on the MNIST dataset. From this, we'll be able to generate new handwritten digits!\n\nThe idea behind GANs is that you have two networks, a generator $G$ and a discriminator $D$, competing against each other. The generator makes \"fake\" data to pass to the discriminator. The discriminator also sees real training data and predicts if the data it's received is real or fake.\n\n- The generator is trained to fool the discriminator, it wants to output data that looks as close as possible to real, training data.\n- The discriminator is a classifier that is trained to figure out which data is real and which is fake.\n\nWhat ends up happening is that the generator learns to make data that is indistinguishable from real data to the discriminator.\n\n<img src='https:\/\/raw.githubusercontent.com\/ArpitFalcon\/DeepLearning101\/master\/05%20-%20Generative%20Adverserial%20Networks\/Lesson%2001%20-%20Intro%20to%20GAN\/assets\/gan_pipeline.png' width=70% \/>\n\nThe general structure of a GAN is shown in the diagram above, using MNIST images as data. The latent sample is a random vector that the generator uses to construct its fake images. This is often called a latent vector and that vector space is called latent space. As the generator trains, it figures out how to map latent vectors to recognizable images that can fool the discriminator.\n\nIf you're interested in generating only new images, you can throw out the discriminator after training. In this notebook, I'll show you how to define and train these adversarial networks in PyTorch and generate new images!","689e40f9":"### Optimizers\nWe want to update the generator and discriminator variables separately. So, we'll define two separate Adam optimizers.","387bf914":"### Training loss\nHere we'll plot the training losses for the generator and discriminator, recorded after each epoch.","7a2c4428":"### Generator\nThe generator network will be almost exactly the same as the discriminator network, except that we're applying a [tanh](https:\/\/pytorch.org\/docs\/stable\/nn.html#tanh) activation function to our output layer.\n\n#### tanh Output\nThe generator has been found to perform the best with $tanh$ for the generator output, which scales the output to be between -1 and 1, instead of 0 and 1.\n<img src='https:\/\/raw.githubusercontent.com\/ArpitFalcon\/DeepLearning101\/master\/05%20-%20Generative%20Adverserial%20Networks\/Lesson%2001%20-%20Intro%20to%20GAN\/assets\/tanh_fn.png' width=40% \/>\n\n","98c64b6b":"### Generated Image for every 10 epochs"}}