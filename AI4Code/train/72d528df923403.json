{"cell_type":{"a66359f5":"code","642b7f04":"code","c5062063":"code","eafd6526":"code","398c2624":"code","9e29d879":"code","d73f17d6":"code","a575f684":"code","5922326d":"code","876b147e":"code","dbbdaddb":"code","44806ba5":"code","7c9c033d":"code","bf0c69e6":"code","08875c12":"code","1f14cc03":"code","3bfef752":"code","4cca9979":"code","4da10c4d":"code","a66b6c4f":"code","18790bd3":"code","d001ebe7":"code","43bfbd50":"code","ffd616f2":"code","2bcf1faa":"code","c81590d8":"code","8991d05d":"code","3a552a04":"markdown","9dec0afd":"markdown","3030e509":"markdown","d8bb09c5":"markdown","cde87b8c":"markdown","8fd3ab63":"markdown","8070ca2b":"markdown","ab85913b":"markdown","d2702c54":"markdown","d88c9a0e":"markdown","be7c2224":"markdown","f4c702ed":"markdown","364d137f":"markdown","c9abe32d":"markdown","b0d16ab8":"markdown","bedf5d95":"markdown","231eed60":"markdown","c735a9f0":"markdown","3c61b17e":"markdown"},"source":{"a66359f5":"# Data Analysis\nimport pandas as pd\nimport numpy as np\n\n# Data Visualization\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.io as pio\nimport plotly.offline as py\n\npy.init_notebook_mode(connected=True)\n\n# Data analysis custom settings\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","642b7f04":"base_layout = dict(\n    colorway = ['#ff5200', '#6f0000', '#00263b'] +\n    [ '#ffa41b', '#000839', '#005082', '#00a8cc']+\n    ['#000839', '#00a8cc']\n    + ['#eb4559', '#f78259', '#522d5b'],\n)\nbase_fig = go.Figure(\n    layout = base_layout\n)\ntemplate_fig = pio.to_templated(base_fig)\npio.templates['m5'] = template_fig.layout.template\npio.templates.default = 'm5'\npio.renderers.default = 'kaggle'","c5062063":"os.getcwd()","eafd6526":"sales = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/sales_train_validation.csv')\ncalendar = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/calendar.csv')\nprices = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/sell_prices.csv')\n\nfor d in np.arange(1914, 1970):\n    col = 'd_'+str(d)\n    sales[col] = 0\n    sales[col] = sales[col].astype(np.int16)","398c2624":"# Downcasting\n\ndef downcast(df):\n    dtypes = df.dtypes\n    cols = dtypes.index.tolist()\n    types = dtypes.values.tolist()\n    \n    for col, typ in zip(cols, types):\n        \n        if 'int' in str(typ):\n            if df[col].min() > np.iinfo(np.int8).min and \\\n                df[col].max() < np.iinfo(np.int8).max:\n                df[col] = df[col].astype(np.int8)\n            \n            elif df[col].min() > np.iinfo(np.int16).min and \\\n                df[col].max() < np.iinfo(np.int16).max:\n                df[col] = df[col].astype(np.int16)\n                \n            elif df[col].min() > np.iinfo(np.int32).min and \\\n                df[col].max() < np.iinfo(np.int32).max:\n                df[col] = df[col].astype(np.int32)\n                \n            else:\n                df[col] = df[col].astype(np.int64)\n                \n        elif 'float' in str(typ):\n            if df[col].min() > np.finfo(np.float16).min and \\\n                df[col].max() < np.finfo(np.float16).max:\n                df[col] = df[col].astype(np.float16)\n                \n            elif df[col].min() > np.finfo(np.float32).min and \\\n                df[col].max() < np.finfo(np.float32).max:\n                df[col] = df[col].astype(np.float32)\n                \n            else:\n                df[col] = df[col].astype(np.float64)\n                \n        elif typ == np.object:\n            if col == 'date':\n                df[col] = pd.to_datetime(df[col], format='%Y-%m-%d')\n                \n            else:\n                df[col] = df[col].astype('category')\n    \n    return df","9e29d879":"sales = downcast(sales)\ncalendar = downcast(calendar)\nprices = downcast(prices)","d73f17d6":"df = pd.melt(\n    sales,\n    id_vars=[\n        'id',\n        'item_id',\n        'dept_id',\n        'cat_id',\n        'store_id',\n        'state_id'\n    ],\n    var_name='d',\n    value_name='sold'\n).dropna()\n\ndf = pd.merge(df, calendar, on='d', how='left')\n\ndf = pd.merge(\n    df,\n    prices,\n    on=['store_id','item_id','wm_yr_wk'],\n    how='left') ","a575f684":"day = [\n    'Monday',\n    'Tuesday',\n    'Thursday',\n    'Wednesday',\n    'Friday',\n    'Saturday',\n    'Sunday'\n]\n\ndf['weekday'] = pd.Categorical(\n    df['weekday'],\n    categories=day,\n    ordered=True\n)\ndf['revenue'] = df.sold*df.sell_price","5922326d":"categories = pd.DataFrame(\n    df.cat_id.unique(),\n    columns=['cat_id']\n)\ncategories['color'] = ['#ff5200', '#6f0000', '#00263b']\ncategories.set_index('cat_id', inplace=True)\n\nevent_t1_df = pd.DataFrame(\n    calendar.event_type_1.dropna().unique(),\n    columns=['event_type_1']\n)\nevent_t1_df['color'] = [\n    '#ffa41b',\n    '#000839',\n    '#005082',\n    '#00a8cc'\n]\nevent_t1_df.set_index('event_type_1', inplace=True)\n\nevent_t2_df = pd.DataFrame(\n    calendar.event_type_2.dropna().unique(),\n    columns=['event_type_2']\n)\nevent_t2_df['color'] = ['#000839', '#00a8cc']\nevent_t2_df.set_index('event_type_2', inplace=True)\n\n\nstates = pd.DataFrame(\n    df.state_id.unique(),\n    columns=['state_id']\n)\nstates['color'] = ['#eb4559', '#f78259', '#522d5b']\nstates.set_index('state_id', inplace=True)","876b147e":"bar_data = df.groupby(\n    ['cat_id', 'dept_id']\n)['sold'].sum().dropna()\n\nfig = go.Figure()\n\nfor cat in [ 'HOBBIES','HOUSEHOLD','FOODS']:\n    \n    bar_data_fil = bar_data.loc[(cat, )].sort_values()\n    trace = go.Bar(\n        y = bar_data_fil.index.get_level_values(0),\n        x = bar_data_fil.values,\n        marker_color=categories.loc[(cat), 'color'],\n        orientation='h',\n        name = cat,\n        texttemplate = '<b>%{x}<\/b>',\n        textposition='inside',\n    )\n    fig.add_trace(trace)\nfig.update_layout(\n    title = dict(text = 'UNITS SOLD BY DEPTARTMENT'),\n    legend = dict(x=0.85, y=0.1),\n)\nfig.show()","dbbdaddb":"bar_data = df.groupby(\n    ['state_id', 'store_id']\n)['sold'].sum().dropna()\n\nfig = go.Figure()\n\nfor state in list(bar_data.index.levels[0])[::-1]:\n    \n    bar_data_fil = bar_data.loc[(state, )].sort_values()\n    trace = go.Bar(\n        y = bar_data_fil.index.get_level_values(0),\n        x = bar_data_fil.values,\n        marker_color=states.loc[(state), 'color'],\n        orientation='h',\n        name = state,\n        texttemplate = '<b>%{x}<\/b>',\n        textposition='inside',\n    )\n    fig.add_trace(trace)\nfig.update_layout(\n    title = dict(text = 'UNITS SOLD BY STORE'),\n    legend = dict(x=0.9, y=0.1),\n)\nfig.show()","44806ba5":"data = df.groupby(\n    ['state_id', 'store_id', 'cat_id', 'dept_id']\n)['sold'].sum()\n\ndata = data.unstack(level=[-2,-1])\\\n        .dropna(axis=1, how='all')\\\n        .dropna(axis=0, how='all')\n\nfig = go.Figure()\ntrace = go.Heatmap(\n    y = [\n        data.index.get_level_values(0),\n        data.index.get_level_values(1)\n    ],\n    x = [\n        data.columns.get_level_values(0),\n        data.columns.get_level_values(1)\n    ],\n    z = data.values,\n    coloraxis = 'coloraxis'\n    \n)\nfig.add_trace(trace)\nfig.update_layout(\n    title = dict(\n        text = 'UNITS SOLD BY STORE AND DEPARTMENT'\n    ),\n    coloraxis = dict(colorscale = 'Cividis')\n)\nfig.show()","7c9c033d":"data = df.groupby(['cat_id', 'dept_id', pd.Grouper(key='date', freq='M')])['sold'].sum()\ndata = data[data>0]\nfig = px.line(\n    data_frame=data.reset_index(),\n    x = 'date',\n    y = 'sold',\n    color = 'dept_id',\n    facet_col='cat_id'\n)\nfig.update_xaxes(nticks=7)\nfig.update_layout(\n    title = dict(text = 'UNITS SOLD BY MONTH-YEAR')\n)\nfig.show()","bf0c69e6":"data = df.loc[df.sold>0].groupby(['cat_id', 'dept_id', 'weekday'])['sold'].mean().reset_index()\nfig = px.line(\n    data_frame=data,\n    x = 'weekday',\n    y = 'sold',\n    color = 'dept_id',\n    facet_col = 'cat_id',\n)\nfig.update_layout(\n    title = dict(text='AVERAGE UNITS SOLD BY DEPARTMENT')\n)\n\nfig.show()","08875c12":"data = df.loc[df.sold>0].groupby(\n    ['cat_id', 'dept_id', pd.Grouper(key='date', freq='M')]\n)['sold'].mean()\n\nfig = px.line(\n    data_frame=data.reset_index(),\n    x = 'date',\n    y = 'sold',\n    color = 'dept_id',\n    facet_col = 'cat_id',\n    render_mode='svg'\n)\n\nfig.update_xaxes(nticks=7)\nfig.update_layout(\n    title = dict(text = 'AVERAGE UNITS SOLD BY MONTH-YEAR')\n)\nfig.show()","1f14cc03":"selling_days = df.loc[df.sold>0].groupby(['cat_id', 'dept_id', pd.Grouper(key='date', freq='M')]).size()\nactive_days = df.groupby(['cat_id', 'dept_id', pd.Grouper(key='date', freq='M')]).size()\ndata = active_days.div(selling_days).reset_index()\ndata.rename(columns={0:'sold'}, inplace = True)\n\nfig = px.line(\n    data_frame=data,\n    x = 'date',\n    y = 'sold',\n    color = 'dept_id',\n    facet_col = 'cat_id',\n    render_mode='svg'\n)\nfig.update_xaxes(nticks=7)\nfig.update_layout(\n    title = dict(text = 'AVERAGE FREQUENCY ASSISTANCE BY YEAR-MONTH')\n)\nfig.show()","3bfef752":"data = df.groupby(['state_id', 'store_id', pd.Grouper(key='date', freq='M')])['sold'].sum()\ndata = data[data>0]\n\nmetadata = dict()\nmetadata['traces'] = []\nmetadata['rows'] = []\nmetadata['cols'] = []\nmetadata['titles'] = []\n\nnrows = 1\nncols = 3\n\nfor idx, cat in enumerate(data.index.levels[0]): \n    row = (idx\/\/ncols)+ 1\n    col = (idx%ncols)+ 1\n    fil_stores = data.loc[(cat, )]\n    \n    for store in fil_stores.index.remove_unused_levels().levels[0]:\n        fil_data = fil_stores.loc[(store, )]\n        trace = go.Scatter(\n            x = fil_data.index,\n            y = fil_data.values,\n            name = store,\n            showlegend=False,\n            hovertemplate= f'<b>Store:<\/b> {store}<br>' +\n                            '<b>Units Sold:<\/b> %{y}<br>' +\n                            '<b>Date:<\/b> %{x}'\n        )\n        metadata['traces'].append(trace)\n        metadata['rows'].append(row)\n        metadata['cols'].append(col)\n    metadata['titles'].append(cat)\n        \nfig = make_subplots(rows = nrows, cols=ncols, subplot_titles=metadata['titles'], shared_yaxes=True)\nfig.add_traces(data = metadata['traces'], rows=metadata['rows'], cols = metadata['cols'])\nfig.update_layout(\n    title = dict(text = 'UNITS SOLD BY STORE')\n)\nfig.show()","4cca9979":"# Data \ndata = df.groupby(\n    ['cat_id', 'date']\n)['sold'].sum().reset_index()\n\ndata['year'] = data.date.dt.year\ndata['month'] = pd.Categorical(\n    data.date.dt.month_name().str.slice(stop=3), \n                               categories = [\n                                   'Jan',\n                                   'Feb',\n                                   'Mar',\n                                   'Apr',\n                                   'May',\n                                   'Jun',\n                                   'Jul',\n                                   'Aug',\n                                   'Sep',\n                                   'Oct',\n                                   'Nov',\n                                   'Dec'\n                               ],\n                               ordered = True\n)\n\ndata['weekday'] = pd.Categorical(\n    data.date.dt.day_name(),\n    categories=day,\n    ordered=True\n)\n\n# subplots info\nmetadata = dict()\nmetadata['traces'] = []\nmetadata['rows'] = []\nmetadata['cols'] = []\nmetadata['titles'] = []\n\nnrows = 6\nncols = 1\n\nfor idx, year in enumerate(data.year.unique()):\n    \n    row_mask = data.year==year\n    col_mask = ['month', 'weekday', 'sold']\n    fil_data = data.loc[row_mask, col_mask]\\\n                        .pivot_table(columns='month', index='weekday')\\\n                        .sort_index(ascending=False)\n    trace = go.Heatmap(\n        x = fil_data.columns.get_level_values(1),\n        y = fil_data.index,\n        z = fil_data.values,\n        coloraxis = 'coloraxis',\n        name=''\n    )\n    fig.add_trace(trace)\n    \n    #updating subplots info\n    metadata['traces'].append(trace)\n    metadata['rows'].append(idx+1)\n    metadata['cols'].append(1)\n    metadata['titles'].append(str(year))\n    \nfig = make_subplots(\n    rows = nrows,\n    cols = ncols,\n    subplot_titles=metadata['titles'],\n    shared_xaxes=True,\n    shared_yaxes=True,\n)\n\nfig.add_traces(\n    data = metadata['traces'],\n    rows = metadata['rows'],\n    cols = metadata['cols'],\n)\n\nfig.update_layout(\n    title = 'UNITS SOLD BY DAY OF WEEK',\n    height=900,\n    coloraxis=dict(colorscale='Cividis'), showlegend=False\n)\n\nfig.show()","4da10c4d":"data = df.groupby(['date', 'cat_id'])['sold'].sum().reset_index()\ndata1 = df.groupby(['date', 'cat_id'])['sold'].sum().rolling(14).mean().reset_index()\ndata = data.merge(data1, how='outer', on=['date', 'cat_id'])\ndata.columns = ['date', 'cat_id', 'sold', 'sold_ma']\nevent_cols = list(calendar.columns[calendar.columns.str.contains('event|snap')]) + ['date']\ndata = data.merge(calendar[event_cols], how='outer', on='date')\ndel(data1)\n\nmetadata = dict()\nmetadata['traces'] = []\nmetadata['rows'] = []\nmetadata['cols'] = []\nmetadata['titles'] = []\n\nnrows = 4\nncols = 1\nfor idx, event in enumerate(data.event_type_1.unique().dropna()):\n    for cat in data.cat_id.unique():\n        mask = (data.cat_id == cat)\n        mask1 = (data.event_type_1 == event)\n        fil_data = data.loc[mask]\n        fil_data2 = data.loc[mask&mask1]\n        if idx == 0:\n            showlegend = True\n        else:\n            showlegend = False\n        trace = go.Scatter(\n            x = fil_data.date,\n            y = fil_data.sold,\n            marker_color = categories.loc[(cat), 'color'],\n            legendgroup = f'Items sold MA - {cat}',\n            showlegend=showlegend,\n            name = f'Items sold - {cat}',\n            mode = 'lines',\n            hovertemplate = f'<b>Category: <\/b>{cat}<br>'+\n                            '<b>Sold Units: <\/b>%{y}<br>'+\n                            '<b>Date:<\/b>%{x}<br>'\n        )\n        metadata['traces'].append(trace)\n        metadata['rows'].append(idx+1)\n        metadata['cols'].append(1)\n        \n        trace2 = go.Scatter(\n            x = fil_data2.date,\n            y = fil_data2.sold,\n            marker_color = 'gold',\n            name = f'Items sold MA - {cat}',\n            legendgroup = f'Items sold MA - {cat}',\n            showlegend=False,\n            mode = 'markers',\n            text = fil_data2.event_name_1,\n            hovertemplate = '<b>Event Name:<\/b>%{text}',\n            texttemplate = '<b>%{text}'\n        )\n        metadata['traces'].append(trace2)\n        metadata['rows'].append(idx+1)\n        metadata['cols'].append(1)\n    metadata['titles'].append(f'Event type = {event}')\n    \nfig = make_subplots(\n    rows=nrows,\n    cols=ncols,\n    subplot_titles=metadata['titles'],\n    shared_xaxes=True,\n    shared_yaxes=True,\n)\nfig.add_traces(\n    data = metadata['traces'],\n    rows = metadata['rows'],\n    cols = metadata['cols'],\n)\nfig.update_layout(\n    height=900,\n    legend = dict(x=0.5, y=1.07, orientation='h'),\n    title = dict(text='IMPACT OF EVENT TYPES ON SOLD UNITS')\n)\nfig.show()        ","a66b6c4f":"def describe_moments(df):\n    my_aggs = dict(\n        sold = ['mean', 'median','std','skew', pd.DataFrame.kurt, 'sum', 'size'],\n        sell_price = ['mean', 'median','std','skew', pd.DataFrame.kurt],\n        revenue = ['mean', 'sum']\n    )\n    moments = df.groupby('item_id').agg(my_aggs)\n    moments.columns = moments.columns.get_level_values(0)+ '_' + moments.columns.get_level_values(1)\n    \n    moment_label = ['mean', 'median', 'std', 'skew', 'kurt']\n    for moment in moment_label:\n        col_min = moments[f'sold_{moment}'].min()\n        col_max = moments[f'sold_{moment}'].max()\n        print(f'{moment} {col_min}, {col_max}')\n    return moments","18790bd3":"non_cero_moments = describe_moments(df[df.sold>0])\nnon_cero_moments['cat_id'] = np.array(non_cero_moments.index.str.extract('([A-Z]+)')[0])\nnon_cero_moments['dept_id'] = np.array(non_cero_moments.index.str.extract('([A-Z]+_\\d)')[0])\n\nselling_days = df[df.sold>0].groupby(['item_id'])['date'].size()\nactivity_horizon = df.groupby(['item_id'])['date'].size().div(selling_days)\nnon_cero_moments['avg_sold_days'] = non_cero_moments.index.map(activity_horizon)\n\nnon_cero_moments.head()","d001ebe7":"fig=go.Figure()\nfor cat in non_cero_moments.cat_id.unique():\n    fil_data = non_cero_moments.loc[non_cero_moments.cat_id == cat]\n    trace = go.Box(\n        y = fil_data.dept_id,\n        x = fil_data.sold_mean,\n        marker_color = categories.loc[(cat), 'color'],\n        orientation = 'h',\n        name = cat,\n        hovertext = fil_data.index,\n        hovertemplate='<b>Item: <\/b>%{hovertext}<br>'+\n                        '<b>Department: <\/b>%{y}<br>'+\n                        '<b>Avg Sold Units: <\/b>%{x}<br>'\n    )\n    fig.add_trace(trace)\n\nfig.show()","43bfbd50":"sold_cols = non_cero_moments.columns[non_cero_moments.columns.str.contains('sold')]\n\nmetadata = dict()\nmetadata['traces'] = []\nmetadata['rows'] = []\nmetadata['cols'] = []\nmetadata['titles'] = []\n\nnrows = 2\nncols = 4\n\nfor cat in non_cero_moments.cat_id.unique():\n    fil_cat_df = non_cero_moments.loc[non_cero_moments.cat_id == cat]\n\n    for idx, stat in enumerate(sold_cols):\n        row = (idx\/\/ncols) + 1\n        col = (idx%ncols) + 1\n        color = categories.loc[cat, 'color'] \n        \n        if row ==1 and col==1:\n            showlegend = True\n        else:\n            showlegend = False\n            \n        trace = go.Histogram(\n            x = fil_cat_df[stat],\n            marker_color = color,\n            showlegend = showlegend,\n            legendgroup=cat,\n            opacity=0.4,\n            cumulative_enabled = True,\n            histnorm = 'probability',\n            name = cat\n        )\n        metadata['traces'].append(trace)\n        metadata['rows'].append(row)\n        metadata['cols'].append(col)\n        metadata['titles'].append(stat)\n    \nfig = make_subplots(rows=nrows, cols=ncols, subplot_titles = metadata['titles'])\nfig.add_traces(data=metadata['traces'], rows = metadata['rows'],\n               cols = metadata['cols'])\nfig.update_layout(\n    title = dict(text='DISTRIBUTIONS BY ITEM BEHAVIOR'),\n    xaxis_zeroline=False,\n    barmode='overlay'\n)\n# fig.update_yaxes(showticklabels=False)\nfig.show()","ffd616f2":"fig = px.scatter(\n    data_frame = non_cero_moments.reset_index(),\n    x = 'sold_mean',\n    y = 'sold_std',\n    color = 'sold_kurt',\n    size = 'sold_skew',\n    facet_col='cat_id',\n    render_mode='svg'\n)\n\nfig.update_layout(\n#     title = 'UNITS SOLD BY DAY OF WEEK',\n    coloraxis=dict(colorscale='Cividis'), showlegend=False\n)\n\nfig.update_traces(\n    text = non_cero_moments.reset_index().item_id,\n    hovertemplate = '<b>Item: <\/b>%{text}<br>'+\n                    '<b>Sold Mean: <\/b>%{x:.2f}<br>'+\n                    '<b>Sold Std: <\/b>%{y:.2f}<br>'+\n                    '<b>Sold Skew: <\/b>%{marker.size:.2f}<br>'+\n                    '<b>Sold kurtosis: <\/b>%{marker.color:.2f}'\n)\n\nfig.update_layout(\n    title = dict(text='ITEMS BEHAVIOR BY CATEGORY')\n)\nfig.show()","2bcf1faa":"\nfig = px.scatter(\n    data_frame = non_cero_moments.reset_index(),\n    x = 'sold_mean',\n    y = 'sold_std',\n    size = 'revenue_sum',\n    color = 'sold_sum',\n    facet_col='cat_id',\n    render_mode='svg'\n)\nfig.update_layout(\n#     title = 'UNITS SOLD BY DAY OF WEEK',\n    coloraxis=dict(colorscale='Cividis'), showlegend=False\n)\nfig.update_traces(\n    text = non_cero_moments.reset_index().item_id,\n    hovertemplate = '<b>Item: <\/b>%{text}<br>'+\n                    '<b>Sold Mean: <\/b>%{x:.2f}<br>'+\n                    '<b>Sold Std: <\/b>%{y:.2f}<br>'+\n                    '<b>Total Revenue: <\/b>%{marker.size:,.0f}<br>'+\n                    '<b>Sold Units: <\/b>%{marker.color:,}'\n)\n\nfig.update_layout(\n    title = dict(text='ITEMS BEHAVIOR BY CATEGORY')\n)\nfig.show()","c81590d8":"top5_items = non_cero_moments.sold_sum.nlargest(5).index\n\ndef top5_plot(variable):\n    mycolors = ['#4d3e3e', '#bb3b0e', '#dd7631', '#708160', '#d8c593']\n    fig = make_subplots(rows = 2, cols = 1, subplot_titles=[f'Top 5 Items {variable} by Date', f'Top Items 5 {variable} Cumulative Distributions'])\n    for color, top in zip(mycolors, top5_items):\n        fil_df = df.loc[df.item_id == top].sort_values('date')\n\n        trace = go.Scatter(\n            x = fil_df.date,\n            y = fil_df[variable],\n            opacity=0.6,\n            marker_color = color,\n            legendgroup=top,\n            showlegend=False,\n            name = top,\n        )\n\n        fig.add_trace(trace, row=1, col=1)\n        trace1 = go.Histogram(\n            x = fil_df[variable],\n            opacity=0.6,\n            cumulative_enabled = True,\n            histnorm='probability',\n            marker_color = color,\n            legendgroup=top,\n            name = top,\n        )\n        fig.add_trace(trace1, row=2, col=1)\n    fig.update_layout(title = dict(text = f'Top 5 {variable}'), barmode='overlay')\n    fig.show()","8991d05d":"top5_plot('sold')","3a552a04":"- In all the departments the quantity of items sold is higher on the weekend, except in HOBBIES_2, which keeps the slope flat.","9dec0afd":"Some quick observations:\n- 95% of the items are sold in batches of up to 10 units per assistance.\n- the FOODS category has more some more extreme products, even so they only represent 5% of the total items.\n- The mean and median of the quantities have a certain difference and this is due to the degree of asymmetry involved.\n- 95% of the items have a standard deviation of 8 units per transaction.\n- Most of the items have positive skewness, which justifies the superior performance of some products.","3030e509":"# Stores and departments behavior\n- CA_3 is the best seller in FOODS_3 department, beating second place CA_1 by more than 1 million.\n- CA_3 is the best seller in HOUSEHOLD_1.\n","d8bb09c5":"# Introduction\n\nIn this Notebook we are going to understand everything related to M5 Forecasting - Accuracy competition data. \nThe dataset involves the unit sales of 3,049 products, classified in 3 product categories (Hobbies, Foods, and Household) and 7 product departments, in which the above-mentioned categories are disaggregated.  The products are sold across ten stores, located in three States (CA, TX, and WI).","cde87b8c":"To do:\n- Price analysis.\n- Revenue analysis.\n- Seasonality and stacionarity analysis.\n\nIf you find it useful, please upvote. ","8fd3ab63":"- The days that occur before a purchase have gradually decreased. Which means that the average quantity of consumption has decreased, but people come more often to make their purchases.","8070ca2b":"- It seems that HOUSEHOLD_1 has a growing demand tendency.\n- FOODS_3 seems to have its peaks in the mid-year.\n- Demand on FOODS_2 is growing in the last periods.","ab85913b":"Lest's obseve to top five items sold","d2702c54":"- More units are sold on the weekend, especially on weekends in August and September. Although in 2016 the weekends of February and March have exceeded the sales of past years during the same period.","d88c9a0e":"Let's review the influence of different types of events on the quantity of items sold.","be7c2224":"## Categories and department behavior\n- FOODS category is the most sold.\n- Most of the items sold are in the FOODS_3 department, second place HOUSEHOLD_1 and third FOODS_2. \n- Each department has a product that sells a lot more than the rest. These are FOODS_3, HOUSEHOLD_1 and HOBBIES_1","f4c702ed":"- Over time, the average number of units sold in each department has gradually decreased.","364d137f":"### Setting colors coherently\nthis is important to keep track easily to each variable. \n","c9abe32d":"# Downcasting\n\nDowncasting is pretty importat for optimizing memory usage. I take an reference from https:\/\/www.kaggle.com\/anshuls235\/m5-forecasting-eda-feature-engineering. Please check that notebook for more details.","b0d16ab8":"# states and stores behavior\n- CA is the top item seller.\n- CA_3, TX_2, WI_2 are top item sellers of their respective states.","bedf5d95":"- In the middle of the year between June and August the number of units sold is higher and at the end of the year until the beginning of the next, sales reach their lowest peak, in all departments.\n- The is more distance at the highest and lowest peaks of CA_3.\n- Since 2015 CA_2 has started to rise in terms of quantity sold.\n- TX_3 outnumbered units sold to TX_1 since 2014.\n- Since July 2013 WI_2 is the store that sells the most units in the state of WI.\n- WI_3 units sold have declined from 2012 through 2014, where they reached their lowest peak. After that sales gradually increased again.\n- While WI_2 sales decreased, W_1 and W_3 sales increased considerably in 2012.","231eed60":"In the next graph we can observe a positive relationship between units sold mean and units sold standar deviation which involves that items with most sold items have bigger fluctuations.","c735a9f0":"Let's analyze the global performance of each product:\n- We can notice that each department has a few items with higher performance than the rest.","3c61b17e":"# Exploratory data analysis"}}