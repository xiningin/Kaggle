{"cell_type":{"1e7e4e3c":"code","20ac766a":"code","e3eb5fd9":"code","28f394e0":"code","8ff99ccb":"code","c4b37f51":"code","f3d0e286":"code","d2d2eb81":"code","7099249e":"code","130135b8":"code","6c3d7097":"code","e9ebb8de":"code","333af088":"code","50c5da59":"code","46543f46":"code","d614b1b3":"code","bca2cb7f":"code","3a84e20b":"markdown","36b0478d":"markdown","ad29bf91":"markdown","ff29080e":"markdown","c73f200c":"markdown","bb647c1b":"markdown","9b6fa922":"markdown","b84f10d0":"markdown","e6126fe4":"markdown","ebc66b3e":"markdown","7182623c":"markdown","080dd2a6":"markdown"},"source":{"1e7e4e3c":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, Dropout, Lambda, Flatten, Conv2D, MaxPooling2D, Activation, MaxPool2D\nfrom keras.optimizers import SGD\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split","20ac766a":"# load training & test datasets\ntrain = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","e3eb5fd9":"# pandas to numpy\ny_train = train[\"label\"]\nX_train = train.drop(labels=[\"label\"], axis=1)","28f394e0":"# normalize\nX_train = np.array(X_train\/255.0)\ntest = np.array(test\/255.0)","8ff99ccb":"X_train_view = X_train.reshape(X_train.shape[0], 28, 28)\nfor i in range(10, 14):\n    plt.subplot(330 + (i+1))\n    plt.imshow(X_train_view[i], cmap=plt.get_cmap('gray'))\n    plt.title(y_train[i]);","c4b37f51":"X_train = X_train.reshape(-1,28,28,1)\ntest = test.reshape(-1,28,28,1)\n\n# one-hot vector as a label (binarize the label)\ny_train = to_categorical(y_train, num_classes=10)","f3d0e286":"model = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(10, activation = \"softmax\"))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","d2d2eb81":"# check input and output shapes\nprint(\"input shape: \", model.input_shape)\nprint(\"output shape: \", model.output_shape)\nprint(\"X_train shape: \", X_train.shape)\nprint(\"test shape: \", test.shape)","7099249e":"# cross validation\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.10, random_state=1)","130135b8":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.10, # Randomly zoom image \n        width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ndatagen.fit(X_train)","6c3d7097":"# epochs = 20\nepochs=1\nbatch_size = 512","e9ebb8de":"history = model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),\n                    steps_per_epoch=len(X_train) \/\/ batch_size, epochs=epochs,\n                    validation_data = (X_val,y_val) )","333af088":"model.load_weights('..\/input\/digits-weights\/digits2_weights.h5')","50c5da59":"loss, accuracy = model.evaluate(X_val, y_val)\nprint (\"\\nAccuracy: \", accuracy)","46543f46":"# model prediction on test data\npredictions = model.predict_classes(test, verbose=0)\n\n# submission\nsubmissions = pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n    \"Label\": predictions})\nsubmissions.to_csv(\"DR.csv\", index=False, header=True)","d614b1b3":"from sklearn.metrics import confusion_matrix\nimport itertools\n\ndef plot_confusion_matrix(cm, classes,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    plt.figure()\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(10)) ","bca2cb7f":"errors = (Y_pred_classes - Y_true != 0)\n\nY_pred_classes_errors = Y_pred_classes[errors]\nY_pred_errors = Y_pred[errors]\nY_true_errors = Y_true[errors]\nX_val_errors = X_val[errors]\n\ndef display_errors(errors_index,img_errors,pred_errors, obs_errors):\n    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n    n = 0\n    nrows = 2\n    ncols = 3\n    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n    for row in range(nrows):\n        for col in range(ncols):\n            error = errors_index[n]\n            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n            n += 1\n\n# Probabilities of the wrong predicted numbers\nY_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n\n# Predicted probabilities of the true values in the error set\ntrue_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n\n# Difference between the probability of the predicted label and the true label\ndelta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n\n# Sorted list of the delta prob errors\nsorted_dela_errors = np.argsort(delta_pred_true_errors)\n\n# Top 6 errors \nmost_important_errors = sorted_dela_errors[-6:]\n\n# Show the top 6 errors\ndisplay_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)","3a84e20b":"I present you my solution using Convolutional Neural Network with keras with which I get a good result.\n","36b0478d":"Submission","ad29bf91":"**Display some error results**\n\nErrors are the difference between predicted and true labels","ff29080e":"The numbers are not well defined. Maybe a human would have also committed these errors.","c73f200c":"**Confusion Matrix**","bb647c1b":"Let's have a look at some images","9b6fa922":"To simplify the calculation, this kernel has been done with 1 iterations. I'm going to load a file with the weights of this same neural network with 20 interactions","b84f10d0":"The Architecture is:\n\nConv (32) x 2 > Pool(2x2) > Dropout(0.25) > Conv (64) x 2 > Pool (2x2) > Dropout (0.25) > FC (256) > Dropout(0.25) > Softmax(10)","e6126fe4":"With data augmentation, we increase the data sample of interweaving with the rotated and scaled images, which reduces the overfitting and increases the accuracy","ebc66b3e":"I got a score of **0,99514** with de test set in the competition","7182623c":"**Accuracy**","080dd2a6":"**Fine tune with batch_size:**\n\nChanging only the batch_size parameter, I obtain the folowing results:\n\n64    Accuracy:  0.987857142857\n\n128   Accuracy:  0.991904761905\n\n256   Accuracy:  0.992142857143\n\n**512   Accuracy:  0.992857142857**\n\n1024  Accuracy:  0.992380952381\n\nTherefore I choose the 512 for Batch_size"}}