{"cell_type":{"db0c3d59":"code","aba14abf":"code","ecb6e900":"code","eb7f287e":"code","2e9e20cf":"code","495ef999":"code","fbf0d4f5":"code","5d6d88d5":"code","a7079731":"code","96a1a70f":"code","4896e17d":"code","bf3bad09":"code","7b4f851e":"code","ef871b54":"code","90322fc9":"code","53c84f05":"code","9426221c":"code","7d7def7e":"code","45ab0c94":"code","e35c8797":"code","07b02869":"code","2dd359a1":"code","816d44e9":"code","d798a713":"code","13c75251":"code","005b9822":"code","5e649302":"code","96f016d2":"code","f6508cd3":"code","fea95104":"code","b07b5609":"code","226dbd30":"code","c8f069d0":"code","37123396":"code","b2bc4588":"code","018e0285":"code","a1f2239c":"code","f40dff58":"code","5bdb8c5e":"code","938bf541":"code","e1470cc2":"markdown","83d31995":"markdown","efed27d6":"markdown","c22bb28d":"markdown","72da3f99":"markdown","00fb2454":"markdown","75d3f563":"markdown","4d837bad":"markdown","e524ee7f":"markdown","ed27d316":"markdown","642516d0":"markdown","3b64cd8a":"markdown","2a36c314":"markdown","9c27bb93":"markdown","a5d78191":"markdown","c32a6726":"markdown","1c1ea7db":"markdown","c8303815":"markdown","01ee8eea":"markdown","759dc82f":"markdown","d1f1cd3e":"markdown","d57c1931":"markdown","09122a84":"markdown","3a1a9535":"markdown","4b043667":"markdown"},"source":{"db0c3d59":"\nimport math\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\npd.options.mode.chained_assignment = None  # default='warn'\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","aba14abf":"data_train = pd.read_csv('..\/input\/titanic\/train.csv')\ndata_test = pd.read_csv('..\/input\/titanic\/test.csv')","ecb6e900":"data_train.head(10)","eb7f287e":"data_train.info()","2e9e20cf":"Na_percent = []\nUniques = []\nfor feature in list(data_train.columns):\n    Na_count = len(data_train[feature][data_train[feature].isna() == True])\n    Na_percent.append(Na_count \/ len(data_train))\n    Uniques.append(data_train[feature].nunique())\n    \npd.DataFrame({'Feature' : list(data_train.columns), 'Na_rate' : Na_percent, 'Uniques' : Uniques})","495ef999":"data_train = data_train.drop(['PassengerId', 'Ticket', 'Cabin'], axis = 1)\npass_id = data_test.PassengerId\ndata_test = data_test.drop(['PassengerId', 'Ticket', 'Cabin'], axis = 1)","fbf0d4f5":"#extracting and applying titles\ndata_train['Title'] = data_train['Name'].str.split(\", \", expand = True)[1].str.split(\".\", expand = True)[0]\ndata_test['Title'] = data_test['Name'].str.split(\", \", expand = True)[1].str.split(\".\", expand = True)[0]\n\ntitles = (data_train.Title.value_counts() > 10)\ntitles = list(titles[titles == True].index)\n\ndata_train['Title'] = data_train.Title.apply(lambda x: x if x in titles else 'other')\ndata_test['Title'] = data_test.Title.apply(lambda x: x if x in titles else 'other')","5d6d88d5":"#dropping Name column\ndata_train = data_train.drop('Name', axis = 1)\ndata_test = data_test.drop('Name', axis = 1)","a7079731":"data_train.Embarked = data_train.Embarked.fillna('S')\ndata_test.Fare = data_test.Fare.fillna(data_test.Fare.mean())","96a1a70f":"plt.figure()\nsns.boxplot(data = data_train, x = 'Pclass', y = 'Age')\nplt.title('Age distribution depending on Pclass')","4896e17d":"import scipy.stats as stats\n\nalpha = 0.05\n\nclass_1 = data_train.Age[(data_train.Pclass == 1) & (data_train.Age.isna() == False)]\nclass_2 = data_train.Age[(data_train.Pclass == 2) & (data_train.Age.isna() == False)]\nclass_3 = data_train.Age[(data_train.Pclass == 3) & (data_train.Age.isna() == False)]\n\n#checking normality\nprint('class 1 p_value =', stats.shapiro(class_1)[1])\nprint('class 2 p_value =', stats.shapiro(class_2)[1])\nprint('class 3 p_value =', stats.shapiro(class_3)[1])\n\np_val = stats.f_oneway(class_1, class_2, class_3)[1]\n\nprint('\\nANOVA TEST p_value =', stats.f_oneway(class_1, class_2, class_3)[1])\nprint('KRUSKAL TEST p_value =', stats.kruskal(class_1, class_2, class_3)[1])    \n\nif p_val < alpha:\n    print('\\nRejecting the null hypothesis, means are not equal')","bf3bad09":"plt.figure()\nsns.boxplot(data = data_train, x = 'Title', y = 'Age')\nplt.title('Age distribution depending on Title')","7b4f851e":"def age_connect(row):\n    if math.isnan(row['Age']) == True:\n        row['Age'] = list(mean_ages[mean_ages.connect == row.connect].Mean_age)[0]\n    return row\n\n\nmean_ages = data_train.groupby(['Title','Pclass']).Age.mean().reset_index()\nmean_ages['connect'] = mean_ages.Title + '_' + mean_ages.Pclass.astype(str)\n\nother_3 = pd.DataFrame({'Mean_age' : [35], 'connect': ['other_3']})\n\nmean_ages = mean_ages.drop(['Title', 'Pclass'], axis = 1).rename(columns = {'Age' : 'Mean_age'}).append(other_3)\n\ndata_train['connect'] = data_train.Title + '_' + data_train.Pclass.astype(str)\ndata_test['connect'] = data_test.Title + '_' + data_test.Pclass.astype(str)\n\ndata_train = data_train.apply(age_connect, axis = 'columns').drop('connect', axis = 1)\ndata_test = data_test.apply(age_connect, axis = 'columns').drop('connect', axis = 1)","ef871b54":"# P-class vs Survived\nplt.figure()\nsns.barplot(data = data_train, x = 'Pclass', y = 'Survived', hue = 'Sex',palette = sns.color_palette('Set2'))\nplt.ylabel('Survival Rate')\nplt.title('Survival Rate by Passenger Class')\n\ndata_train.groupby(['Pclass', 'Sex']).Survived.agg({'mean'}).reset_index()","90322fc9":"# Survival vs Sex\nplt.figure()\nsns.barplot(x = data_train['Sex'], y = data_train['Survived'])\nplt.ylabel('Survival Rate')\nplt.title('Survival Rate by Passenger Sex')\ndata_train.groupby(['Sex']).Survived.agg({'mean'}).reset_index()","53c84f05":"plt.figure()\nsns.barplot(data = data_train, x = 'Embarked', y = 'Survived', hue = 'Sex')\nplt.ylabel('Survival Rate')\nplt.title('Survival Rate by Embarked')\n\ndata_train.groupby(['Embarked', 'Sex']).Survived.agg({'mean'}).reset_index()","9426221c":"plt.figure()\nsns.barplot(data = data_train, x = 'Title', y = 'Survived')\nplt.ylabel('Survival Rate')\nplt.title('Survival Rate by Title')\n\ndata_train.groupby(['Title']).Survived.agg({'mean'}).reset_index()","7d7def7e":"plt.figure()\nsns.histplot(data = data_train, x = 'Age', hue = 'Survived')\nplt.ylabel('Age')\nplt.title('Survival Rate by Embarked')","45ab0c94":"plt.figure()\nsns.barplot(data = data_train, x = 'Embarked', y = 'Survived')\nplt.ylabel('Survival Rate')\nplt.title('Survival Rate by Embarked')","e35c8797":"plt.figure()\nplt.hist(data_train['Fare'])\nplt.title('Fare distribution')\n\nplt.figure()\nsns.scatterplot(x = data_train['Age'], y = data_train['Fare'], hue = data_train['Sex'])\nplt.ylabel('Fare')\nplt.title('Age')","07b02869":"data_train = data_train[data_train.Fare < 400]","2dd359a1":"plt.figure(figsize = (10, 6))\n# using .heatmap() of seaborn to understand better relationship of variables \nsns.heatmap(data_train.corr(), annot=True)\nplt.title('Corelation Matrix');","816d44e9":"y = data_train.Survived\ndata_train = data_train.drop('Survived',axis=1)\n","d798a713":"#getting dummies\nsex_dummies_train = pd.get_dummies(data_train.Sex,drop_first=True)\nsex_dummies_test = pd.get_dummies(data_test.Sex,drop_first=True)\n\nclass_dummies_train = pd.get_dummies(data_train.Pclass,prefix='Pclass')\nclass_dummies_test = pd.get_dummies(data_test.Pclass,prefix='Pclass')\n\nemb_dummies_train = pd.get_dummies(data_train.Embarked,prefix='Embarked')\nemb_dummies_test = pd.get_dummies(data_test.Embarked,prefix='Embarked')\n\ntitle_dummies_train = pd.get_dummies(data_train.Title,prefix='Title')\ntitle_dummies_test = pd.get_dummies(data_test.Title,prefix='Title')\n\ndata_train=pd.concat([data_train, sex_dummies_train, class_dummies_train, emb_dummies_train, title_dummies_train],axis=1)\\\n    .drop(['Sex','Pclass','Embarked','Title'],axis=1)\ndata_test=pd.concat([data_test, sex_dummies_test, class_dummies_test, emb_dummies_test, title_dummies_test],axis=1)\\\n    .drop(['Sex','Pclass','Embarked','Title'],axis=1)\n","13c75251":"data_test","005b9822":"X=data_train\nX_test=data_test\n","5e649302":"#splitting the train set\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_holdout, y_train, y_holdout = train_test_split(X, y, test_size=0.3, random_state=17)","96f016d2":"#importing classifiers\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier","f6508cd3":"logreg = LogisticRegression()\n\nlogreg.fit(X_train,y_train)\nprint('LOGREG Score on train set:',logreg.score(X_train,y_train))\nprint('LOGREG Score on test set:',logreg.score(X_holdout,y_holdout))\n\ntree_clf = DecisionTreeClassifier()\n\ntree_clf.fit(X_train, y_train)\nprint('TREE Score on train set:',tree_clf.score(X_train, y_train))\nprint('TREE Score on test set:',tree_clf.score(X_holdout, y_holdout))\n\nrf_clf = RandomForestClassifier(max_features='sqrt', n_estimators=1000, max_depth=10, min_samples_split=9)\n\nrf_clf.fit(X_train, y_train)\nprint('RF Score on train set:',rf_clf.score(X_train, y_train))\nprint('RF Score on test set:',rf_clf.score(X_holdout, y_holdout))\n\nxgb_clf = GradientBoostingClassifier(max_depth = 10, n_estimators = 500, min_samples_split = 6)\n\nxgb_clf.fit(X_train, y_train)\nprint('GB Score on train set:',xgb_clf.score(X_train, y_train))\nprint('GB Score on test set:',xgb_clf.score(X_holdout, y_holdout))","fea95104":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score\ncv = KFold(n_splits = 5, random_state = 1, shuffle = True)\n\nrfscore = cross_val_score(rf_clf, X_holdout, y_holdout, scoring = 'accuracy', cv = cv, n_jobs = -1)\nrfscore = np.mean(rfscore)\nprint(rfscore)","b07b5609":"from sklearn.model_selection import GridSearchCV","226dbd30":"param_grid = { \n    'n_estimators': [500],\n    'max_features': ['auto', 'sqrt'],\n    'max_depth' : [8, 10],\n    'min_samples_leaf' : [2, 4, 6, 8],\n    'criterion' :['entropy']\n}\nbest_clf_rf = GridSearchCV(rf_clf, param_grid = param_grid, cv = cv, scoring = 'accuracy')\n\nbest_clf_rf.fit(X_train,y_train)\n\nprint(best_clf_rf.score(X_holdout,y_holdout))\nbest_clf_rf.best_params_\n","c8f069d0":"accuracy_score(best_clf_rf.best_estimator_.predict(X_holdout), y_holdout)","37123396":"importances = pd.DataFrame({'feature' : list(data_train.columns), 'importance' : best_clf_rf.best_estimator_.feature_importances_})\\\n    .sort_values(by = 'importance', ascending = False)\nimportances","b2bc4588":"data_train_scaled = data_train\ndata_test_scaled = data_test\n\ndata_train_scaled.Age = (data_train_scaled.Age - data_train_scaled.Age.mean()) \/ data_train_scaled.Age.std()\ndata_test_scaled.Age = (data_test_scaled.Age - data_train_scaled.Age.mean()) \/ data_train_scaled.Age.std()\n\ndata_train_scaled.Fare = (data_train_scaled.Fare - data_train_scaled.Fare.mean()) \/ data_train_scaled.Fare.std()\ndata_test_scaled.Fare = (data_test_scaled.Fare - data_train_scaled.Fare.mean()) \/ data_train_scaled.Fare.std()\n\nX_train, X_holdout, y_train, y_holdout = train_test_split(data_train_scaled, y, test_size=0.3, random_state=17)","018e0285":"rf_clf = RandomForestClassifier(max_features='sqrt', n_estimators=1000, max_depth=12, min_samples_split=9, random_state = 17)\n\nrf_clf.fit(X_train, y_train)\nprint('RF Score on train set:',rf_clf.score(X_train, y_train))\nprint('RF Score on test set:',rf_clf.score(X_holdout, y_holdout))","a1f2239c":"param_grid = { \n    'n_estimators': [500],\n    'max_features': ['auto', 'sqrt'],\n    'max_depth' : [8, 11, 12],\n    'min_samples_split' : [4, 6, 8, 10],\n    'criterion' :['entropy']\n}\nbest_clf_rf = GridSearchCV(rf_clf, param_grid = param_grid, cv = cv, scoring = 'accuracy', n_jobs = -1)\n\nbest_clf_rf.fit(X_train,y_train)\n\nprint(best_clf_rf.score(X_holdout,y_holdout))\nbest_clf_rf.best_params_","f40dff58":"#calculating feature importance\nimportances = pd.DataFrame({'feature' : list(data_train.columns), 'importance' : best_clf_rf.best_estimator_.feature_importances_})\\\n    .sort_values(by = 'importance', ascending = False)\nimportances","5bdb8c5e":"result=pd.DataFrame({'PassengerId':pass_id,'Survived':best_clf_rf.best_estimator_.predict(X_test)})\nresult.sum()\n","938bf541":"from IPython.display import HTML\nresult.to_csv('predictions_RF.csv',index=False)\n\ndef create_download_link(title = \"Download CSV file\", filename = \"data.csv\"):  \n    html = '<a href={filename}>{title}<\/a>'\n    html = html.format(title=title,filename=filename)\n    return HTML(html)\n\n# create a link to download the dataframe which was saved with .to_csv method\ncreate_download_link(filename='predictions_RF.csv')","e1470cc2":"# Tuning features\n\nThe next idea is to apply Z-transformation to Age and Fare\n\n$$Z=\\frac{X-\\mathrm{E}(X)}{\\sigma}$$","83d31995":"# Importing the Data","efed27d6":"* Survival rate hardly depends on Sex","c22bb28d":"# Working with Name feature\nAs we can see, the Name feture cannot be deleted. One of the approaches is to extract titles as Mr, Mrs... as a new feature","72da3f99":"Ok. There it is obvious. Time to fill in the age. The function below calculates median ages and maps them to the missing values","00fb2454":"# Tuning models using GridSearch","75d3f563":"Seems that we have to drop Cabin, becase Na rate is too high\nWe should also drop Ticket, because there is no way to convert it to something useful","4d837bad":"# Data preprocessing","e524ee7f":"* This graph correlates with previous showing Survival rate depending on Sex. But it can tell us, that people with Master title (which corresponds to kids) have more chances to survive. The following graph will show it.","ed27d316":"# Training different models","642516d0":"RF performs wery well","3b64cd8a":" * Survival rate depends on Pclass for both males and females","2a36c314":"# Titanic Project Classification\n\n\n## Overview \n### 1) Import and clean the data (Shape , missing values , data types , ...)\n\n### 2) EDA \n\n### 3) Data Preprocessing and Feature Engineering\n\n### 4) Model Building \n\n### 5) Model Tuning","9c27bb93":"# Dealing with Na in Age\n**Now we have to fill in Na values in age.**\n\nI am going to fill in missing values according to median age grouped by Title and Pclass. I also checked the hypothesis about median ages in Pclass","a5d78191":"First of all we have to dig into the data","c32a6726":"### Creating dummies for Sex, Class, Embarked and Title\n\nIn order to have te better result we should create dummies instead of replacing categorical columns with numbers (0,1..)","1c1ea7db":"From the graph above we can see that age seem to depend on the class. We'll check the equality of means to answer this. \n\n### ANOVA Hypotheses\n\nNull hypothesis: Groups means are equal (no variation in means of groups) \nH0: $$\\mu_1=\\mu_2=...=\\mu_p$$\nAlternative hypothesis H1: At least, one group mean is different from other groups \n ","c8303815":"Now we have to deal with Na values\n\nIt will be interesting to calculate the percentage of Na in each column","01ee8eea":"# Libraries used in the project\n\n- [seaborn](https:\/\/seaborn.pydata.org\/)\n- [matplotlib](https:\/\/matplotlib.org\/)\n- [numpy](https:\/\/numpy.org\/)\n- [pandas](https:\/\/pandas.pydata.org\/)\n\n- [sklearn](https:\/\/scikit-learn.org\/stable\/)\n- math","759dc82f":"It is not enough, maybe some actions with data should improve the score","d1f1cd3e":"* It seems strange, but Survival also depends on Embarked","d57c1931":"# EDA\n\nHere I have to understand the data and visualize it","09122a84":"There are no strongly correlating features that have to be merged","3a1a9535":"Try untuned classifiers first","4b043667":"Seems that there are two outliers that can be deleted"}}