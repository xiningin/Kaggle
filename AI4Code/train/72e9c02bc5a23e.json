{"cell_type":{"4c616d53":"code","5b03a0c1":"code","a1c2c10f":"code","184f2ee3":"code","ac2177d0":"code","77a846cf":"code","3cd98c5b":"code","d3bdb92c":"code","d9b509d6":"code","41b876b8":"code","6e39caa5":"code","a4021569":"code","077f94a7":"code","2990ed01":"code","8590e40e":"code","58616b5f":"code","1bba962a":"code","b0602312":"code","ad9a4f00":"code","65365928":"code","b99d2359":"code","83926efb":"code","4b8299e9":"code","7c65e553":"code","1fe9d45e":"code","e29e7fa8":"code","5b0764fe":"code","af63ab1b":"code","7083842a":"code","d7bbf122":"code","ef0d3815":"code","16dd4e02":"code","e92576a3":"code","39368ab5":"code","37174380":"code","90e5e69e":"markdown","87e70772":"markdown","856cd6c9":"markdown","9c94daaa":"markdown","ee8bfec8":"markdown","eb5ebdc5":"markdown","1a49b778":"markdown","eaaef529":"markdown","db1c1dd8":"markdown","04c37bb5":"markdown","3e70802e":"markdown","d2f8ba59":"markdown","a7a29e1f":"markdown","ccfe2660":"markdown","a1526389":"markdown","b2f80906":"markdown","c48761a2":"markdown","9e585276":"markdown","d6551f65":"markdown","ed9856ac":"markdown"},"source":{"4c616d53":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5b03a0c1":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n%matplotlib inline","a1c2c10f":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntrain.head()","184f2ee3":"plt.figure(figsize = (12,6))\nsns.heatmap(train.isnull(), yticklabels = False, cbar = False, cmap = 'inferno')","ac2177d0":"columns = ['PassengerId','Name','Ticket','Cabin']\ntrain.drop(columns, axis=1, inplace = True)","77a846cf":"train.head()","3cd98c5b":"plt.figure(figsize = (12,6))\nsns.heatmap(train.isnull(), yticklabels = False, cbar = False, cmap = 'inferno')","d3bdb92c":"sns.boxplot('Pclass','Age',data = train, palette = 'inferno')","d9b509d6":"def Class_Mean_Age(column):\n    age = column[0]\n    Class = column[1]\n    \n    if pd.isnull(age):\n        if Class ==1:\n            return 37\n        elif Class == 2:\n            return 29\n        else:\n            return 24\n    else:\n        return age","41b876b8":"train['Age'] = train[['Age','Pclass']].apply(Class_Mean_Age, axis=1)","6e39caa5":"train.dropna(inplace = True)","a4021569":"plt.figure(figsize = (12,6))\nsns.heatmap(train.isnull(), yticklabels = False, cbar = False, cmap = 'inferno')","077f94a7":"sns.countplot('Survived', data = train, hue = 'Sex', palette = 'magma')\n\n# Count of survivers by sex","2990ed01":"sns.countplot('Pclass', data = train, hue = 'Survived', palette = 'inferno')\n\n# Count of Survived by Passenger Class","8590e40e":"Sex = pd.get_dummies(train['Sex'], drop_first = True) \nEmbarked = pd.get_dummies(train['Embarked'], drop_first = True)","58616b5f":"train.drop(['Sex','Embarked'], axis = 1, inplace = True)","1bba962a":"train = pd.concat([train, Sex, Embarked], axis = 1)\ntrain.head()","b0602312":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(train.drop('Survived', axis = 1), train['Survived'], test_size = 0.3)","ad9a4f00":"from sklearn.linear_model import LogisticRegression\nlogmodel =  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=1000, multi_class='auto',\n          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n          tol=0.0001, verbose=0, warm_start=False)\nlogmodel.fit(X_train,y_train)","65365928":"predictions = logmodel.predict(X_test)","b99d2359":"print(classification_report(y_test,predictions))","83926efb":"test = pd.read_csv('..\/input\/titanic\/test.csv')\ntest.head()","4b8299e9":"columns = ['PassengerId','Name','Ticket','Cabin']\ntest.drop(columns, axis=1, inplace = True)","7c65e553":"test['Age'] = test[['Age','Pclass']].apply(Class_Mean_Age, axis=1)","1fe9d45e":"plt.figure(figsize = (12,6))\nsns.heatmap(test.isnull(), yticklabels = False, cbar = False, cmap = 'inferno')","e29e7fa8":"group = test.groupby('Pclass')\ngroup.Fare.mean()","5b0764fe":"def meanFareClass(column):\n    fare = column[0]\n    Class = column[1]\n    \n    if pd.isnull(fare):\n        if Class==1:\n            return 94.28\n        elif Class==2:\n            return 22.2\n        else:\n            return 12.46\n    else:\n        return fare","af63ab1b":"test['Fare'] = test[['Fare','Pclass']].apply(meanFareClass, axis=1)","7083842a":"plt.figure(figsize = (12,6))\nsns.heatmap(test.isnull(), yticklabels = False, cbar = False, cmap = 'inferno')","d7bbf122":"Sex = pd.get_dummies(test['Sex'], drop_first = True) \nEmbarked = pd.get_dummies(test['Embarked'], drop_first = True)\ntest.drop(['Sex','Embarked'], axis = 1, inplace = True)","ef0d3815":"test = pd.concat([test, Sex, Embarked], axis = 1)\ntest.head()","16dd4e02":"predictions = logmodel.predict(test)","e92576a3":"Id = pd.read_csv('..\/input\/titanic\/test.csv')\nId = Id.PassengerId","39368ab5":"submission = pd.DataFrame({\"PassengerId\": Id,\"Survived\": predictions})\nsubmission.head()","37174380":"submission.to_csv('submission.csv',index=False)","90e5e69e":"## **Let's look again the heatmap of null\/missing values**","87e70772":"# Now we can make the predictions","856cd6c9":"# Splitting the data into train and test","9c94daaa":"## Finishing, let's concating the new columns Sex and Embarked to our dataset Train","ee8bfec8":"## Let's drop the columns with a high number of missing values and the columns with no relevant information","eb5ebdc5":"# Creating the submission file to kaggle","1a49b778":"## Let's use get_dummies to transform the categorical data","eaaef529":"## Now We can drop the original columns Sex and Embarked","db1c1dd8":"## To finish, let's drop the line with the last missing value in the Embarked column","04c37bb5":"## We can see a high number of missing values in the column AGE\n\n**We can fill those missing informations with the mean of each class**","3e70802e":"# Creating a model\n\n**Let's create a linear model and fit it with the train splitted data**","d2f8ba59":"## The first step is look in the data to find null\/missing values","a7a29e1f":"# Dataset clean, is time to change or categorical parameters","ccfe2660":"## On this test dataset We have a missing value in the column Fare. \n## Exclude this line is not the best solution, for this, I'll fill this value with the Fare mean of the class","a1526389":"## Let's create a function to extract the age according the class of each passenger","b2f80906":"## Creating a prediction","c48761a2":"# Now We can repeat the process to test dataset","9e585276":"## Comparing the results","d6551f65":"# With a clean dataset, We can explore some relations with our target column","ed9856ac":"## The model had accuracy of 80% to predict non survivors and 75% to predict survivors"}}