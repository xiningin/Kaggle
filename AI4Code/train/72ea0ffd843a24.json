{"cell_type":{"f17fbdaf":"code","c00c2817":"code","55f766af":"code","e4b7a165":"code","23d9c276":"code","9112e265":"code","9cea4047":"code","c76446a3":"code","78a7b9d4":"code","a372e151":"code","82fe3427":"markdown","fe772487":"markdown","b612eeb6":"markdown","411bbf13":"markdown"},"source":{"f17fbdaf":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport glob\nimport gc\nfrom tqdm import tqdm","c00c2817":"#read each stock id pq file and store as dataframe  \ndef read_data(path):\n    trade = pd.read_parquet(path)\n    return trade\n\ndef RMSPE(y_true, y_pred):\n    loss = np.sqrt(np.mean(np.square(((y_true - y_pred) \/ y_true)), axis=0))\n    return loss\n\ndef WAP1(df):\n    WAP = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * \n           df['bid_size1'])\/(df['bid_size1'] + df['ask_size1'])\n    return WAP\n\ndef WAP2(df):\n    wap = (df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * \n           df['bid_size2'])\/(df['bid_size2'] + df['ask_size2'])\n    return wap\n\ndef log_return(WAP):\n    return np.log(WAP).diff() \n\ndef realized_volatility(log_r):\n    return np.sqrt((log_r**2).sum())\n\ndef consol_book_df(path):\n\n    #read stock pq file\n    df = read_data(path)\n    \n    #add stock-id column\n    df['stock_id'] = int(path.split(\"=\")[1]) #extract stock id by removing directory\n    \n    #WAP\n    df['WAP1'] = WAP1(df)\n    df['WAP2'] = WAP2(df)\n    \n    #log return\n    df['book_log_ret1'] = df.groupby('time_id')['WAP1'].apply(log_return).fillna(0)\n    df['book_log_ret2'] = df.groupby('time_id')['WAP2'].apply(log_return).fillna(0)\n    \n    #Book features\n    final_book = df.groupby(['stock_id', 'time_id']).agg(\n                                              real_vol_1 =('book_log_ret1', realized_volatility),\n                                              real_vol_2 = ('book_log_ret2', realized_volatility),\n                                              ).reset_index()\n    return final_book\n\ndef consol_trade_df(path):\n    \n    #read stock pq file\n    df = read_data(path)\n    \n    #add stock-id column\n    df['stock_id'] = int(path.split(\"=\")[1])  #extract stock id by removing directory\n    \n    #trade log return\n    df['trade_log_ret'] = df.groupby('time_id')['price'].apply(log_return).fillna(0)\n    \n    #Trade features\n    final_trade = df.groupby(['time_id', 'stock_id']).agg(\n                                                     real_vol_trade=('trade_log_ret', realized_volatility)).reset_index()\n\n    return final_trade\n\n","55f766af":"def create_dataSet(df, book_paths, trade_paths):\n    final_df = pd.DataFrame()\n    for book_path, trade_path in tqdm(zip(book_paths, trade_paths)):\n        book = consol_book_df(book_path)\n        trade = consol_trade_df(trade_path)\n        merged_df = (pd.merge(book, trade, on=['stock_id', 'time_id'], how='left')\n                     .merge(df, on=['stock_id', 'time_id'], how='left'))\n        final_df = pd.concat([final_df, merged_df])\n        gc.collect()\n    return final_df ","e4b7a165":"order_book_training = glob.glob('\/kaggle\/input\/optiver-realized-volatility-prediction\/book_train.parquet\/*')\ntrade_training = glob.glob('\/kaggle\/input\/optiver-realized-volatility-prediction\/trade_train.parquet\/*')\ntrain_df = pd.read_csv('..\/input\/optiver-realized-volatility-prediction\/train.csv')\n\ntrain_set = create_dataSet(train_df, order_book_training, trade_training)","23d9c276":"order_book_test = glob.glob('\/kaggle\/input\/optiver-realized-volatility-prediction\/book_test.parquet\/*')\ntrade_test = glob.glob('\/kaggle\/input\/optiver-realized-volatility-prediction\/trade_test.parquet\/*')\ntest_df = pd.read_csv('..\/input\/optiver-realized-volatility-prediction\/test.csv')\n\ntest_set = create_dataSet(test_df, order_book_test, trade_test)","9112e265":"import xgboost\nfrom sklearn.model_selection import train_test_split\n\nX = train_set.drop(columns = ['target'], axis = 1)\ny = train_set.target.values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)","9cea4047":"reg = xgboost.XGBRegressor(n_estimator=150)\nreg.fit(X_train, y_train)","c76446a3":"reg.score(X_test, y_test)","78a7b9d4":"test = test_set.drop(columns = ['row_id'], axis = 1)\nfinal_pred = reg.predict(test)\n\n#final_pred = test_set.real_vol_trade + 0.001211","a372e151":"submission = pd.DataFrame({\"row_id\" : test_set['row_id'], \"target\": final_pred})  \nsubmission.to_csv('submission.csv',index = False)","82fe3427":"# Import Libraries","fe772487":"# Key functions and Features","b612eeb6":"## Prepare test set\n\nNew consol functions are written due to different length of the directory string for test files","411bbf13":"# Joint Dataset\nCreate a aggregate dataset which contains both the book and trade features for modelling"}}