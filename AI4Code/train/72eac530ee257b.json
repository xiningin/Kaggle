{"cell_type":{"39f9f003":"code","9e637b0c":"code","3a96e8c5":"code","1b434902":"code","a3b0ef4d":"code","ffd630dd":"code","efad2bee":"code","9f31f435":"code","de7f14d1":"code","20fe0470":"code","92b268ba":"code","6830760c":"code","5e448649":"code","1402a3af":"code","90e3ecca":"code","0d2d8769":"code","2d89b2f0":"code","374cafc9":"code","8357d85c":"code","bc0bcb90":"code","0e8c35fa":"code","2a20aee7":"code","3d8ef070":"code","7be1ea42":"code","1f9369f6":"code","31a0ec3f":"code","3b8718aa":"code","572d2472":"code","96aa7d43":"code","9a8d4b8f":"code","f48fc039":"code","873696f6":"code","63b32b94":"code","15677c8c":"code","0ad8f70f":"markdown","41080ede":"markdown","a381a7ae":"markdown","b7a40cb7":"markdown","d4128e26":"markdown","6ac54f8b":"markdown","5577cde4":"markdown","2785e1cf":"markdown","6bdcf0eb":"markdown","0b1caa28":"markdown"},"source":{"39f9f003":"# Common lib\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\n\n# Utils\nfrom tqdm import tqdm\nimport datetime\n\n# Sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_recall_curve, confusion_matrix, auc\n\n# Tensorflow\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Add, MaxPooling2D, Flatten, GlobalAveragePooling2D, Dense, Dropout\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\nfrom tensorflow.keras.metrics import AUC, TruePositives, TrueNegatives, FalsePositives, FalseNegatives\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\nfrom tensorflow.keras.layers.experimental.preprocessing import Resizing, Rescaling\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.regularizers import l2\n\nprint(\"Import successfully\")","9e637b0c":"# Init variables\ninput_folder = '..\/input\/coronahack-chest-xraydataset'\ntest_img_folder = os.path.join(input_folder, 'Coronahack-Chest-XRay-Dataset', 'Coronahack-Chest-XRay-Dataset', 'test')\ntrain_img_folder = os.path.join(input_folder, 'Coronahack-Chest-XRay-Dataset', 'Coronahack-Chest-XRay-Dataset', 'train')\nmetadata_df = pd.read_csv(os.path.join(input_folder, 'Chest_xray_Corona_Metadata.csv'), index_col=0)","3a96e8c5":"# Split to train & test set\ntrain_df = metadata_df[metadata_df.Dataset_type == 'TRAIN'].reset_index(drop=True)\ntest_df = metadata_df[metadata_df.Dataset_type == 'TEST'].reset_index(drop=True)\n\n# Check train_df size + test_df size == metadata_df size\nassert train_df.size + test_df.size == metadata_df.size\n\nprint(f'Shape of train data: { train_df.shape }')\nprint(f'Shape of test data: { test_df.shape }')","1b434902":"# fill na\ntrain_df.fillna('unknow', inplace=True)\ntest_df.fillna('unknow', inplace=True)","a3b0ef4d":"# Image augmentation\ntrain_datagen = ImageDataGenerator(rotation_range=10,\n                              brightness_range=(0.8, 1.2),\n                              zoom_range=[0.75, 1],\n                              horizontal_flip=True)\ntest_datagen = ImageDataGenerator()","ffd630dd":"train_df, valid_df = train_test_split(train_df, test_size=0.2, shuffle=True, random_state=42)","efad2bee":"train_batches = train_datagen.flow_from_dataframe(train_df,\n                                             directory=train_img_folder,\n                                             x_col='X_ray_image_name',\n                                             y_col='Label',\n                                             class_mode='binary',\n                                             batch_size=128)\n\nvalid_batches = test_datagen.flow_from_dataframe(valid_df,\n                                             directory=train_img_folder,\n                                             x_col='X_ray_image_name',\n                                             y_col='Label',\n                                             class_mode='binary',\n                                             batch_size=128)\n\ntest_batches = test_datagen.flow_from_dataframe(test_df,\n                                            directory=test_img_folder,\n                                            x_col='X_ray_image_name',\n                                            y_col='Label',\n                                            class_mode='binary',\n                                            batch_size=8,\n                                            shuffle=False)","9f31f435":"print(f'Label encode: { valid_batches.class_indices }')","de7f14d1":"train_batches_series = pd.Series(train_batches.classes)\nvalid_batches_series = pd.Series(valid_batches.classes)\n\nprint(f'Value count in train_batches: \\n{ train_batches_series.value_counts() }')\nprint(f'Value count in valid_batches: \\n{ valid_batches_series.value_counts() }')","20fe0470":"def create_dir(dir_path):\n    if not os.path.exists(dir_path):\n        os.mkdir(dir_path)\n        \ncreate_dir('models')","92b268ba":"resize_and_rescale = Sequential([\n    Resizing(224, 224),\n    Rescaling(1.\/255)\n])","6830760c":"metrics = [TruePositives(name='TP'),\n           TrueNegatives(name='TN'),\n           FalsePositives(name='FP'),\n           FalseNegatives(name='FN'),\n           AUC(curve='PR', name='AUC')]","5e448649":"!pip install git+https:\/\/github.com\/qubvel\/classification_models.git","1402a3af":"from classification_models.keras import Classifiers","90e3ecca":"ResNet18, preprocess_input = Classifiers.get('resnet18')\nbase_model = ResNet18((224, 224, 3), weights='imagenet', include_top=False)","0d2d8769":"# Preprocess layer\nft_resnet18 = Sequential([resize_and_rescale]) \n# Feature extractor\nft_resnet18.add(base_model)\n# Classifier\nft_resnet18.add(GlobalAveragePooling2D())\nft_resnet18.add(Dense(1, activation='sigmoid'))","2d89b2f0":"# Freeze\n#for layer in ft_resnet34.layers[1].layers[:50]:\n#    layer.trainable = False","374cafc9":"resnet18_dir = 'models\/resnet18'\nresnet18_file = 'best_resnet18.hdf5'\n\ncreate_dir(resnet18_dir)\n\ncheckpoint = ModelCheckpoint(os.path.join(resnet18_dir, resnet18_file),\n                             monitor='val_loss',\n                             verbose=1,\n                             save_best_only=True,\n                             save_weights_only=False)\n\nearly_stopping = EarlyStopping(monitor='val_loss',\n                               patience=30,\n                               verbose=1,\n                               restore_best_weights=True)","8357d85c":"# Initialize TensorBoard\nlog_dir = 'models\/resnet18\/logs'\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)","bc0bcb90":"epochs = 200\nlr = 1e-4\n\nft_resnet18.compile(optimizer=Adam(lr=lr), loss='binary_crossentropy', metrics=metrics)\n\ntraining_time_start = datetime.datetime.now()\n\nresnet18_history = ft_resnet18.fit(train_batches,\n                                epochs=epochs,\n                                verbose=2,\n                                callbacks=[checkpoint, early_stopping],\n                                validation_data=valid_batches,\n                                steps_per_epoch=len(train_batches),\n                                validation_steps=len(valid_batches))\n\ntraining_time_end = datetime.datetime.now()","0e8c35fa":"total_training_seconds = (training_time_end - training_time_start).seconds\nprint('Total training time: ', str(datetime.timedelta(seconds=total_training_seconds)))","2a20aee7":"resnet18_hist_df = pd.DataFrame(resnet18_history.history)","3d8ef070":"resnet18_hist_df.loc[:, ['loss', 'val_loss']].plot()\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.show()","7be1ea42":"resnet18_hist_df.loc[:, ['AUC', 'val_AUC']].plot()\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.show()","1f9369f6":"num_of_epochs = resnet18_hist_df.shape[0]\nhalf_epoch = int(num_of_epochs \/ 2)\n\nfirst_half_resnet18_hist = resnet18_hist_df.loc[:half_epoch]\nfirst_title = f'Loss value at epoch 0 - { half_epoch }'\n\nlast_half_resnet18_hist = resnet18_hist_df.loc[half_epoch:len(resnet18_hist_df)]\nlast_title = f'Loss value at epoch { half_epoch } - { len(resnet18_hist_df) }'\n\nhists = [first_half_resnet18_hist, last_half_resnet18_hist]\ntitles = [first_title, last_title]\n\nfor i in range(2):\n    ax = hists[i][['loss', 'val_loss']].plot()\n    ax.set_xlabel('Epoch')\n    ax.set_ylabel('Loss value')\n    ax.set_title(titles[i])\nplt.show()","31a0ec3f":"first_title = f'AUC value at epoch 0 - { half_epoch }'\nlast_title = f'AUC value at epoch { half_epoch } - { len(resnet18_hist_df) }'\n\ntitles = [first_title, last_title]\n\nfor i in range(2):\n    ax = hists[i][['AUC', 'val_AUC']].plot()\n    ax.set_xlabel('Epoch')\n    ax.set_ylabel('AUC value')\n    ax.set_title(titles[i])\nplt.show()","3b8718aa":"evaluate_resnet18 = ft_resnet18.evaluate(test_batches, verbose=1)","572d2472":"loss, tp, tn, fp, fn, auc = evaluate_resnet18[0], evaluate_resnet18[1], evaluate_resnet18[2], evaluate_resnet18[3], evaluate_resnet18[4], evaluate_resnet18[5]\nprint(f'Test loss: { loss }')\nprint(f'True positive: { tp }')\nprint(f'True negative: { tn }')\nprint(f'False positive: { fp }')\nprint(f'False negative: { fn }')\nprint('AUC: %.2f' % auc)","96aa7d43":"def find_optimal_threshold(precision, recall, threshold):\n    f1_score = (2 * precision * recall) \/ (precision + recall)\n    best_idx = np.argmax(f1_score)\n    best_threshold = threshold[best_idx]\n    return best_threshold, best_idx","9a8d4b8f":"y_true = test_batches.classes\ny_predict = ft_resnet18.predict(test_batches)\nprecision, recall, threshold = precision_recall_curve(y_true, y_predict)\nbest_threshold, best_idx = find_optimal_threshold(precision, recall, threshold)\nprint('Best threshold: {}'.format(best_threshold))","f48fc039":"plt.figure(figsize=(7, 5))\nauc_score = auc(recall, precision)\nplt.plot([1, 0], [0, 1], linestyle='--', color='black', label='No skill')\nplt.plot(recall, precision, linewidth=3, label='ResNet18')\nplt.plot(recall[best_idx], precision[best_idx], \n         marker='o', color='black', \n         label='Best_theshold', linestyle='', markersize='7')\nplt.xlabel('Recall', size=13)\nplt.ylabel('Precision', size=13)\nplt.title('Precision-Recall curve (AUC - {:.4f})'.format(auc_score), size=15)\nplt.legend()\nplt.show()","873696f6":"y_predict = (y_predict >= best_threshold).astype('int')\ny_predict = np.reshape(y_predict, -1)","63b32b94":"cfs_matrix = confusion_matrix(y_true, y_predict)","15677c8c":"label = ['Normal', 'Pneumonia']\n\nplt.figure(figsize=(6, 5))\nplt.imshow(cfs_matrix, cmap=plt.cm.Reds)\nplt.colorbar()\nfor i in range(len(label)):\n    for j in range(len(label)):\n        plt.text(j, i, cfs_matrix[i, j],\n                 horizontalalignment='center', verticalalignment='center', size=14)\nplt.xticks(np.arange(len(label)), label)\nplt.yticks(np.arange(len(label)), label)\nplt.xlabel('Predicted label', size=13)\nplt.ylabel('True label', size=13)\nplt.title('Confusion matrix of ResNet18', size=15)\nplt.show()","0ad8f70f":"## Note\nIn this notebook, i just prepare the data then fine tuning VGG16 to diagnosis pneumonia. If you wanna see insight the dataset, please visit this notebook:\n\n-> https:\/\/www.kaggle.com\/luukhang\/build-alexnet-to-classifies-pneumonia.\n\nComparing the performance of pretrained of VGG16 and ResNet18, plese visit this notebook:\n\n-> https:\/\/www.kaggle.com\/luukhang\/transfer-learning-vgg16-to-classifies-pneumonia","41080ede":"**Find the best threshold**","a381a7ae":"# 3. Fine tuning","b7a40cb7":"# 5. Plot PR curve and find optimal threshold","d4128e26":"# 1. Import libs","6ac54f8b":"# 4. Evaluate","5577cde4":"# 6. Predict and plot confusion matrix","2785e1cf":"**Plot ROC curve**","6bdcf0eb":"**Preprocessing layer**","0b1caa28":"# 2. Prepare data"}}