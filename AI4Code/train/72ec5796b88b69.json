{"cell_type":{"c6c86132":"code","25535bd8":"code","46a9a415":"code","5f5df5f8":"code","4bdb6747":"code","1638779c":"code","facc6c41":"code","cdfd83ab":"markdown","5cbf5d85":"markdown","375e7ad8":"markdown","24361095":"markdown","5ad63da2":"markdown","710d6762":"markdown","4845df0d":"markdown"},"source":{"c6c86132":"# Set up code checking\nimport os\nif not os.path.exists(\"..\/input\/train.csv\"):\n    os.symlink(\"..\/input\/home-data-for-ml-course\/train.csv\", \"..\/input\/train.csv\")  \n    os.symlink(\"..\/input\/home-data-for-ml-course\/test.csv\", \"..\/input\/test.csv\") ","25535bd8":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Read the data\nX_full = pd.read_csv('..\/input\/train.csv', index_col='Id')\nX_test_full = pd.read_csv('..\/input\/test.csv', index_col='Id')\n\n# Remove rows with missing target, separate target from predictors\nX_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\ny = X_full.SalePrice\nX_full.drop(['SalePrice'], axis=1, inplace=True)\n\n# Break off validation set from training data\nX_train_full, X_valid_full, y_train, y_valid = train_test_split(X_full, y, \n                                                                train_size=0.8, test_size=0.2,\n                                                                random_state=0)\n\n# \"Cardinality\" means the number of unique values in a column\n# Select categorical columns with relatively low cardinality (convenient but arbitrary)\ncategorical_cols = [cname for cname in X_train_full.columns if # X_train_full[cname].nunique() < 10 and \n                    X_train_full[cname].dtype == \"object\"]\n\n# Select numerical columns\nnumerical_cols = [cname for cname in X_train_full.columns if \n                X_train_full[cname].dtype in ['int64', 'float64']]\n\n# Keep selected columns only\nmy_cols = categorical_cols + numerical_cols\nX_train = X_train_full[my_cols].copy()\nX_valid = X_valid_full[my_cols].copy()\nX_test = X_test_full[my_cols].copy()","46a9a415":"X_train.head()","5f5df5f8":"from sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_absolute_error\nfrom xgboost import XGBRegressor\n\n# Preprocessing for numerical data\n#numerical_transformer = IterativeImputer() # Your code here\nnumerical_transformer = Pipeline(steps=[\n    ('num_imputer', IterativeImputer(max_iter=40)),\n    ('scaler', StandardScaler()),\n])\n\n# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[\n    #('imputer', IterativeImputer(initial_strategy=\"most_frequent\")),\n    ('imputer', SimpleImputer(strategy=\"most_frequent\")),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n]) # Your code here\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])\n\n# Define model\n#model = RandomForestRegressor(n_estimators=100,random_state=1)\nmodel = GradientBoostingRegressor(n_estimators=500,random_state=1)\n\n# Bundle preprocessing and modeling code in a pipeline\nmy_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', model)\n                             ])\n\n# Preprocessing of training data, fit model \nmy_pipeline.fit(X_train, y_train)\n\n# Preprocessing of validation data, get predictions\npreds = my_pipeline.predict(X_valid)\n\n# Evaluate the model\nscore = mean_absolute_error(y_valid, preds)\nprint('MAE:', score)","4bdb6747":"# Use the entire data for testing\nmy_pipeline.fit(pd.concat([X_train,X_valid]), pd.concat([y_train,y_valid]))\n\n","1638779c":"# Preprocessing of test data, fit model\npreds_test = my_pipeline.predict(X_test) \n","facc6c41":"# Save test predictions to file\noutput = pd.DataFrame({'Id': X_test.index,\n                       'SalePrice': preds_test})\noutput.to_csv('submission.csv', index=False)","cdfd83ab":"**This notebook is an exercise in the [Intermediate Machine Learning](https:\/\/www.kaggle.com\/learn\/intermediate-machine-learning) course.  You can reference the tutorial at [this link](https:\/\/www.kaggle.com\/alexisbcook\/pipelines).**\n\n---\n","5cbf5d85":"Run the next code cell without changes to save your results to a CSV file that can be submitted directly to the competition.","375e7ad8":"# Step 2: Generate test predictions\n\nNow, you'll use your trained model to generate predictions with the test data.","24361095":"# Submit your results\n\nOnce you have successfully completed Step 2, you're ready to submit your results to the leaderboard!  If you choose to do so, make sure that you have already joined the competition by clicking on the **Join Competition** button at [this link](https:\/\/www.kaggle.com\/c\/home-data-for-ml-course).  \n1. Begin by clicking on the blue **Save Version** button in the top right corner of the window.  This will generate a pop-up window.  \n2. Ensure that the **Save and Run All** option is selected, and then click on the blue **Save** button.\n3. This generates a window in the bottom left corner of the notebook.  After it has finished running, click on the number to the right of the **Save Version** button.  This pulls up a list of versions on the right of the screen.  Click on the ellipsis **(...)** to the right of the most recent version, and select **Open in Viewer**.  This brings you into view mode of the same page. You will need to scroll down to get back to these instructions.\n4. Click on the **Output** tab on the right of the screen.  Then, click on the file you would like to submit, and click on the blue **Submit** button to submit your results to the leaderboard.\n\nYou have now successfully submitted to the competition!\n\nIf you want to keep working to improve your performance, select the blue **Edit** button in the top right of the screen. Then you can change your code and repeat the process. There's a lot of room to improve, and you will climb up the leaderboard as you work.\n\n\n# Keep going\n\nMove on to learn about [**cross-validation**](https:\/\/www.kaggle.com\/alexisbcook\/cross-validation), a technique you can use to obtain more accurate estimates of model performance!","5ad63da2":"The next code cell uses code from the tutorial to preprocess the data and train a model.  Run this code without changes.","710d6762":"---\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https:\/\/www.kaggle.com\/learn-forum\/161289) to chat with other Learners.*","4845df0d":"You will work with data from the [Housing Prices Competition for Kaggle Learn Users](https:\/\/www.kaggle.com\/c\/home-data-for-ml-course). \n\n![Ames Housing dataset image](https:\/\/i.imgur.com\/lTJVG4e.png)\n\nRun the next code cell without changes to load the training and validation sets in `X_train`, `X_valid`, `y_train`, and `y_valid`.  The test set is loaded in `X_test`."}}