{"cell_type":{"7cb98dbe":"code","e4cc3016":"code","3c150f03":"code","d48db3f1":"code","e1643930":"code","60f0276f":"code","0b2c2aed":"code","a2002344":"code","aea52401":"code","4a9f5002":"code","6e7820b9":"code","39b7e6c5":"code","35529a48":"markdown"},"source":{"7cb98dbe":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e4cc3016":"import cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport keras\nfrom keras.preprocessing.image import *\nfrom keras.layers import *\nfrom keras.models import Sequential\nfrom keras.callbacks import *","3c150f03":"face_mask_detection_dir = '..\/input\/face-mask-detection\/images'\n\nwith_without_mask_train = '..\/input\/withwithout-mask\/maskdata\/maskdata\/train'\nwith_without_mask_test = '..\/input\/withwithout-mask\/maskdata\/maskdata\/test'\n\nwith_mask_train_dir = os.path.join(with_without_mask_train, 'with_mask')\nwithout_mask_train_dir = os.path.join(with_without_mask_train, 'without_mask')\n\nwith_mask_test_dir = os.path.join(with_without_mask_test, 'with_mask')\nwithout_mask_test_dir = os.path.join(with_without_mask_test, 'without_mask')","d48db3f1":"categories=os.listdir(with_without_mask_train)\n\nlabels=[i for i in range(len(categories))]\n\nlabel_dict=dict(zip(categories,labels)) #empty dictionary\n\nprint(label_dict)\nprint(categories)\nprint(labels)","e1643930":"img_size=100\ndata=[]\ntarget=[]\n\n\nfor category in categories:\n    folder_path=os.path.join(with_without_mask_train,category)\n    img_names=os.listdir(folder_path)\n        \n    for img_name in img_names:\n        img_path=os.path.join(folder_path,img_name)\n        img=cv2.imread(img_path)\n\n        try:\n            gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)           \n            \n            resized=cv2.resize(gray,(img_size,img_size))\n           \n            data.append(resized)\n            target.append(label_dict[category])\n            \n        except Exception as e:\n            print('Exception:',e)","60f0276f":"\ndata=np.array(data)\/255.0\ndata=np.reshape(data,(data.shape[0],img_size,img_size,1))\ntarget=np.array(target)\n\nfrom keras.utils import np_utils\n\nnew_target=np_utils.to_categorical(target)\n\nnp.save('data',data)\nnp.save('target',new_target)\n","0b2c2aed":"data=np.load('data.npy')\ntarget=np.load('target.npy')\n","a2002344":"from keras.models import Sequential\nfrom keras.layers import Dense,Activation,Flatten,Dropout\nfrom keras.layers import Conv2D,MaxPooling2D\nfrom keras.callbacks import ModelCheckpoint\n\nmodel=Sequential()\n\nmodel.add(Conv2D(200,(3,3),input_shape=data.shape[1:]))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n#The first CNN layer followed by Relu and MaxPooling layers\n\nmodel.add(Conv2D(100,(3,3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n#The second convolution layer followed by Relu and MaxPooling layers\n\nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\n#Flatten layer to stack the output convolutions from second convolution layer\nmodel.add(Dense(50,activation='relu'))\n#Dense layer of 64 neurons\nmodel.add(Dense(2,activation='softmax'))\n#The Final layer with two outputs for two categories\n\nmodel.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])","aea52401":"checkpoint = ModelCheckpoint('model-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')\nhistory=model.fit(data,target,epochs=20,callbacks=[checkpoint],validation_split=0.2)","4a9f5002":"plt.plot(history.history['accuracy'],'r',label='training accuracy')\nplt.plot(history.history['val_accuracy'],label='validation accuracy')\nplt.xlabel('# epochs')\nplt.ylabel('loss')\nplt.legend()\nplt.show()","6e7820b9":"categories=os.listdir(with_without_mask_test)\n\nlabels=[i for i in range(len(categories))]\n\nlabel_dict=dict(zip(categories,labels)) #empty dictionary\n\nprint(label_dict)\nprint(categories)\nprint(labels)\n\nimg_size=100\ndata_test=[]\ntarget_test=[]\n\n\nfor category in categories:\n    folder_path=os.path.join(with_without_mask_test,category)\n    img_names=os.listdir(folder_path)\n        \n    for img_name in img_names:\n        img_path=os.path.join(folder_path,img_name)\n        img=cv2.imread(img_path)\n\n        try:\n            gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)           \n            \n            resized=cv2.resize(gray,(img_size,img_size))\n           \n            data_test.append(resized)\n            target_test.append(label_dict[category])\n            \n        except Exception as e:\n            print('Exception:',e)\n            \n            \ndata_test=np.array(data_test)\/255.0\ndata_test=np.reshape(data_test,(data_test.shape[0],img_size,img_size,1))\ntarget_test=np.array(target_test)\n\nfrom keras.utils import np_utils\n\nnew_target_test=np_utils.to_categorical(target_test)\n\nnp.save('data_test',data_test)\nnp.save('target_test',new_target_test)\n            ","39b7e6c5":"data_test=np.load('data.npy')\ntarget_test=np.load('target.npy')\nprint(model.evaluate(data_test,target_test))","35529a48":"As you can see the model has approximately 97% accuracy!"}}