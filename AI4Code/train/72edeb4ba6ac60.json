{"cell_type":{"f5139c18":"code","78e8a905":"code","1e581394":"code","a8b0c546":"code","60101c79":"code","a090e9b5":"code","46dcc02f":"code","138eabe7":"code","1b784276":"code","6a3a872c":"code","fffb185d":"code","faeb3be2":"code","b963ab35":"code","7b489ee3":"code","3d5ff01f":"code","990b2759":"code","74fd62ee":"code","9d414b43":"code","a0243158":"code","102a6da9":"code","2872506b":"code","e2baf93b":"code","95abcfb7":"code","d7721227":"code","8ab4cc2f":"code","6d5b7b26":"code","f2477721":"code","7e2f01d7":"code","d5e998aa":"code","23013a69":"code","57bf84c3":"code","452de623":"code","8b0bd3fc":"code","fb5b5629":"code","3f592ac9":"code","6a6e52fa":"code","715e93c4":"code","00a71dbf":"code","053f70ac":"code","f243b3bd":"code","420d0cb9":"code","515e05fd":"code","18e5625a":"code","957466b6":"code","2140a67d":"code","62cb42cd":"code","9eb9f4ee":"code","74c3d4a5":"code","5eae5cbd":"code","b64e3295":"code","4bcefde3":"code","527f4195":"code","cfa1c3ac":"code","882a99c2":"code","10bdf488":"code","17b247a1":"code","d1351f2c":"code","7ed1ae9d":"code","b102856f":"code","0f33ed56":"code","cdff3d26":"code","1a7d8684":"code","4f12276a":"code","f27091cd":"code","c4af0696":"code","91a1c9b4":"code","d1b54178":"code","e3040134":"code","11d5f3af":"code","d17a3c9a":"code","2e5d9659":"code","5c64576f":"code","e12fed9b":"code","288aabe9":"code","8b4dcce5":"code","21c21d66":"code","82c21521":"code","af563e9b":"code","e9cf3851":"code","58dcab77":"code","ec5c0cf2":"code","262a0d07":"code","c0e48c2d":"code","6534ede3":"code","2cfab8da":"code","583ab5b8":"code","59b02400":"code","1fa4555f":"code","f02d56a6":"code","46232498":"code","03b06b69":"code","4b1d9384":"code","e4eb6010":"code","cfb16a40":"code","6713cbd9":"code","37033581":"code","e3b81035":"code","0ea16f8a":"code","4590c961":"markdown","47af8610":"markdown","7852d2ca":"markdown","affc3736":"markdown","782d33ac":"markdown","785c3264":"markdown","2edc13d8":"markdown","3f97be84":"markdown","43c3647e":"markdown","5f640de9":"markdown","bd6a4a60":"markdown","a363dd39":"markdown","47b885f4":"markdown","a14fea97":"markdown","279a94f0":"markdown","1c112c5e":"markdown","7e9d22eb":"markdown","2b4c2c50":"markdown","5df7ac4c":"markdown","3e5f4b5c":"markdown","5771214c":"markdown","0eaa4baf":"markdown","3307b5c6":"markdown","dccb83e5":"markdown","5647a735":"markdown","f84eeb2f":"markdown","24eee282":"markdown","0a11b7cb":"markdown","6983f5ba":"markdown","e566dc5f":"markdown","c50f38f5":"markdown","54402f6b":"markdown","1d9feb4a":"markdown","8993a44b":"markdown","5377bb09":"markdown","c95d9361":"markdown","9ef4e8a4":"markdown","c137226d":"markdown","ffab39f9":"markdown","7a287785":"markdown","040d4217":"markdown","d533584d":"markdown","108e0622":"markdown","786bfbfd":"markdown","f5680a8e":"markdown","ae435b55":"markdown","09b44b96":"markdown","8485d365":"markdown","6948bb0b":"markdown","39a9d26d":"markdown","df753b45":"markdown","e081bd0a":"markdown","eff982b5":"markdown","0c85404e":"markdown","d4cfcf8a":"markdown"},"source":{"f5139c18":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import chisquare, ttest_ind, zscore\n\n%matplotlib inline\n\n#Supresses scientific notation\npd.set_option('display.float_format', lambda x: '%.2f' % x)\n\nimport warnings\nwarnings.filterwarnings('ignore')","78e8a905":"#There are a lot of issues with the 'position_two' column, so I left it out.\n#Furthermore, the 'position_again' column is much more consistent and has all relevant win\/place information  \n\nfields = [\"position_again\",\"bf_odds\",\"venue_name\",\"date\",\"market_name\",\"condition\",\n          \"barrier\",\"handicap_weight\",\"last_twenty_starts\",\"prize_money\",\"sex\",\n          \"age\",\"jockey_sex\",\"days_since_last_run\",\"overall_starts\",\"overall_wins\",\n          \"overall_places\",\"track_starts\",\"track_wins\",\"track_places\",\"firm_starts\",\n          \"firm_wins\",\"firm_places\",\"good_starts\",\"good_wins\",\"good_places\",\n          \"slow_starts\",\"slow_wins\",\"slow_places\",\"soft_starts\",\"soft_wins\",\n          \"soft_places\",\"heavy_starts\",\"heavy_wins\",\"heavy_places\",\"distance_starts\",\n          \"distance_wins\",\"distance_places\"]\n\ndf = pd.read_csv('..\/input\/horses 2.csv', usecols=fields, skipinitialspace=True, low_memory=False)\n\ndf.head()","1e581394":"df.date = pd.to_datetime(df.date, format='%Y'+'-'+'%m'+'-'+'%d')\n\n#removes numbers from end of 'condition' strings\ndf.condition = df.condition.str.replace('\\d+', '')\n\n#renaming condition values so that they're uniform\ndf.condition = df.condition.replace(['HVY','AWT'], ['HEAVY','GOOD']) \n#AWT equates to a Good surface under some weather conditions\n\n#reverses 'last_five_starts' (originally written right-to-left) \n#so that it's easier to read in the future\ndf.last_twenty_starts = df.last_twenty_starts.str[::-1]","a8b0c546":"def column_cleaner(cleaned_df, grouped_df, column_name):\n    non_null_indices = grouped_df[column_name].apply(lambda x: all(x.notnull()))\n    \n    non_null_df = cleaned_df[non_null_indices]\n    \n    non_null_grouped = non_null_df.groupby(['date','venue_name','market_name'])\n    \n    clean_indices = non_null_grouped[column_name].value_counts(normalize=True,dropna=False).\\\n        where(lambda x:x != 1).dropna().index.droplevel(column_name)\n    \n    new_cleaned_df = non_null_df.loc[clean_indices].drop_duplicates()\n    return new_cleaned_df\n\ndef cleaned_win_df(cleaned_df):\n    win_indices = cleaned_df.position_again.apply(lambda x:x == 1)\n    \n    df_cleaned_win = cleaned_df[win_indices]\n    return df_cleaned_win","60101c79":"new = df.market_name.str.split(expand=True)\n\ndf['distance'] = new[1].str.rstrip('m')\n\ndf.distance = df.distance.astype(np.int64)\n\ndf.distance.head()","a090e9b5":"#creates overall, track, and distance win_percent and place_percent columns\n#and drops existing wins and places columns\n\ncolumns_list = [\"overall\",\"track\",\"distance\"]\n\nfor x in columns_list:\n    df[x+\"_win_percent\"] = df[x+\"_wins\"]\/df[x+\"_starts\"]\n    \n    df[x+\"_place_percent\"] = df[x+\"_places\"]\/df[x+\"_starts\"]\n\n    # dropping various columns, though 'starts' columns will be used later\n    df.drop([x+'_wins', x+'_places'], axis=1, inplace=True)","46dcc02f":"#creates a condition_starts ,condition_win_percent, and condition_place_percent column\n#for each horse according to the condition of the track for that race\n\ndf.loc[df.condition.isna(), \"condition_win_percent\"] = np.nan\n\ncondition_list = [\"firm\",\"good\",\"slow\",\"soft\",\"heavy\"]\n\nfor x in condition_list: \n    df.loc[df.condition.str.lower() == x, \"condition_starts\"] = df[x+\"_starts\"]\n    \n    df.loc[df.condition.str.lower() == x, \"condition_win_percent\"] = df[x+\"_wins\"]\/df[x+\"_starts\"]\n    \n    df.loc[df.condition.str.lower() == x, \"condition_place_percent\"] = df[x+\"_places\"]\/df[x+\"_starts\"]\n    \n    df.drop([x+'_starts', x+'_wins', x+'_places'], axis=1, inplace=True)\n\n# Replaces infinity (zero division) with NaN\ndf.replace([np.inf, -np.inf], np.nan, inplace=True)","138eabe7":"df.isnull().sum()\n#The position_again is primarily nan values because it only shows first and place\n#However, track_starts is primarily zeros, so the track_win\/place_percent columns are nan","1b784276":"df.drop(['track_win_percent','track_place_percent'],axis=1,inplace=True)","6a3a872c":"#position_again unique values\ndf.position_again.unique()","fffb185d":"new = pd.DataFrame()\n\nfor i in range(20):\n    new[i] = df.last_twenty_starts.str[i:i+1]\n\nfor i in range(20):\n    df['last_start'+str(i+1)] = new[i].replace(['0','','x','f'],['ten+','none','scratch','fell'])    \n\ndf.drop('last_twenty_starts',axis=1,inplace=True)","faeb3be2":"#Used groupby to create indices by which to sort the re-indexed dataframes below, like df_indexed and df_cleaned\ndf_grouped = df.groupby(['date','venue_name','market_name'])\n\n#Drops all groups\/races in 'position_again' column where sum of values [1st, 2nd, 3rd] don't add to 3 or 6\n#i.e. 1+2 and 1+2+3\nindex_list1 = df_grouped.position_again.sum(dropna=False).where(lambda x:(x == 3) | (x == 6)).dropna().index\n\ndf_indexed = df.set_index(['date','venue_name','market_name'])\n\ndf_cleaned = df_indexed.loc[index_list1].drop_duplicates()\n\ndf_grouped = df_cleaned.groupby(['date','venue_name','market_name'])\n\n#Eliminates remaining errors in 'position_again' column by making sure that there isn't a single 3rd-place finish\nindex_list2 = df_grouped.position_again.value_counts(normalize=True,dropna=False)\\\n    .where(lambda x:x != 1).dropna().index.droplevel('position_again')\n\ndf_cleaned = df_cleaned.loc[index_list2].drop_duplicates()\n\ndf_grouped = df_cleaned.groupby(['date','venue_name','market_name'])","b963ab35":"df_cleaned['weight_z'] = df_grouped['handicap_weight'].transform(lambda x: zscore(x,ddof=1))\n\ndf_cleaned.drop('handicap_weight',axis=1,inplace=True)\n\ndf_grouped = df_cleaned.groupby(['date','venue_name','market_name'])","7b489ee3":"#creates prize_money_per_start column\ndf_cleaned['prize_money_per_start'] = df_cleaned.prize_money\/df_cleaned.overall_starts\n\ndf_cleaned['prize_money_per_start_z'] = df_grouped['prize_money_per_start']\\\n    .transform(lambda x: zscore(x,ddof=1))\n\ndf_cleaned.drop(['prize_money','prize_money_per_start'],axis=1,inplace=True)\n\ndf_grouped = df_cleaned.groupby(['date','venue_name','market_name'])","3d5ff01f":"df_cleaned['age_z'] = df_grouped['age'].transform(lambda x: zscore(x,ddof=1))\n\ndf_cleaned.drop('age',axis=1,inplace=True)\n\ndf_grouped = df_cleaned.groupby(['date','venue_name','market_name'])","990b2759":"z_score_cols = ['days_since_last_run','overall_win_percent','overall_place_percent',\n                'distance_win_percent','distance_place_percent','condition_win_percent',\n                'condition_place_percent','overall_starts','distance_starts','condition_starts',\n                'track_starts']\n\nfor col in z_score_cols:\n    df_cleaned[col+'_z'] = df_grouped[col].transform(lambda x: zscore(x,ddof=1))","74fd62ee":"#Replaces infinity (zero division) with NaN\ndf_cleaned.replace([np.inf, -np.inf], np.nan, inplace=True)\n\ndf_grouped = df_cleaned.groupby(['date','venue_name','market_name'])\n\ndf_cleaned.head()","9d414b43":"df_cleaned.shape","a0243158":"len(df_grouped) #Number of remaining races","102a6da9":"#Removes races where only one horse gender is represented\nsex_pop_cleaned = column_cleaner(df_cleaned, df_grouped, 'sex')\n\nsex_pop_cleaned_win = cleaned_win_df(sex_pop_cleaned)","2872506b":"#General percentage of horse genders for races where multiple genders are represented  \nsex_pop_cleaned.sex.value_counts(dropna=False,normalize=True).sort_values(ascending=False)\\\n    .drop('Unknown')","e2baf93b":"sex_pop_cleaned_win.sex.value_counts(dropna=False,normalize=True).sort_values(ascending=False)\\\n    .drop('Unknown')","95abcfb7":"horse_sex_pop = sex_pop_cleaned.sex.value_counts(dropna=False,normalize=True)\\\n    .sort_values(ascending=False).drop('Unknown')\n\nhorse_sex_win = sex_pop_cleaned_win.sex.value_counts(dropna=False,normalize=True)\\\n    .sort_values(ascending=False).drop('Unknown')\n\nhorse_sex_percent_difference = (horse_sex_win - horse_sex_pop)\/horse_sex_pop\n\nhorse_sex_percent_difference","d7721227":"index1 = ['Gelding', 'Mare', 'Filly','Colt', 'Horse']\n\ndf1 = pd.DataFrame({'Total Proportion': horse_sex_pop,'Win Proportion': horse_sex_win ,\n                    'Percent Difference': horse_sex_percent_difference}, index=index1)\n\nax = df1.plot.bar(rot=0,title='The Significance of Horse Gender')","8ab4cc2f":"observed1 = sex_pop_cleaned_win.sex.value_counts().sort_values(ascending=False)\\\n    .drop('Unknown').values\n\nexpected_percentages1 = horse_sex_pop.values\nexpected1 = [x*observed1.sum() for x in expected_percentages1]\n\ntest_stat1, p_value1 = chisquare(observed1, expected1)\n\ntest_stat1, p_value1","6d5b7b26":"#Removing races where there is only one age\nage_pop_cleaned = column_cleaner(df_cleaned, df_grouped, 'age_z')\n\nage_pop_cleaned_win = cleaned_win_df(age_pop_cleaned)","f2477721":"age_pop_cleaned.age_z.describe()","7e2f01d7":"age_pop_cleaned_win.age_z.describe()","d5e998aa":"data2a = age_pop_cleaned.age_z.dropna().values\ndata2b = age_pop_cleaned_win.age_z.dropna().values\n\nplt.title(\"Winner and Race Distributions of Age Z-scores\", fontsize=15)\n\nplt.hist(data2a, density=True, bins=24, range=(-3,3), label='Race Average', \n         color='b', alpha=.5, edgecolor='k')\n\nplt.hist(data2b, density=True, bins=24, range=(-3,3), label='Winner Average',\n         color='r', alpha=.5, edgecolor='k')\n\nplt.legend(loc='upper right')\nplt.xlabel('Age Z-scores')\nplt.ylabel('Probability');","23013a69":"test_stat2, p_value2 = ttest_ind(data2a, data2b)\n\ntest_stat2, p_value2","57bf84c3":"condit_age_pop = age_pop_cleaned[age_pop_cleaned.condition == 'HEAVY']","452de623":"condit_age_pop_win = cleaned_win_df(condit_age_pop)","8b0bd3fc":"data2c = condit_age_pop.age_z.dropna().values\ndata2d = condit_age_pop_win.age_z.dropna().values\n\nplt.title(\"Winner and Race Distributions of Age Z-scores \\n (Condition Specific)\", fontsize=15)\n\nplt.hist(data2c, density=True, bins=24, range=(-3,3), label='Race Average', \n         color='b', alpha=.5, edgecolor='k')\n\nplt.hist(data2d, density=True, bins=24, range=(-3,3), label='Winner Average',\n         color='r', alpha=.5, edgecolor='k')\n\nplt.legend(loc='upper right')\nplt.xlabel('Age Z-scores')\nplt.ylabel('Probability');","fb5b5629":"test_stat2, p_value2 = ttest_ind(data2c, data2d)\n\ntest_stat2, p_value2","3f592ac9":"#Removing races where there is only one age\nweight_pop_cleaned = column_cleaner(df_cleaned, df_grouped, 'weight_z')\n\nweight_pop_cleaned_win = cleaned_win_df(weight_pop_cleaned)","6a6e52fa":"weight_pop_cleaned.weight_z.describe()","715e93c4":"weight_pop_cleaned_win.weight_z.describe()","00a71dbf":"data3a = weight_pop_cleaned.weight_z.dropna().values\ndata3b = weight_pop_cleaned_win.weight_z.dropna().values\n\nplt.title(\"Winner and Race Distributions of Weight Z-scores\", fontsize=15)\n\nplt.hist(data3a, density=True, bins=24, range=(-3,3), label='Race Average', \n         color='b', alpha=.5, edgecolor='k')\n\nplt.hist(data3b, density=True, bins=24, range=(-3,3), label='Winner Average',\n         color='r', alpha=.5, edgecolor='k')\n\nplt.legend(loc='upper right')\nplt.xlabel('Weight Z-scores')\nplt.ylabel('Probability');","053f70ac":"test_stat3, p_value3 = ttest_ind(data3a, data3b)\n\ntest_stat3, p_value3","f243b3bd":"money_pop_cleaned = column_cleaner(df_cleaned, df_grouped, 'prize_money_per_start_z')\n\nmoney_pop_cleaned_win = cleaned_win_df(weight_pop_cleaned)","420d0cb9":"money_pop_cleaned.prize_money_per_start_z.describe()","515e05fd":"#Winner prize money \nmoney_pop_cleaned_win.prize_money_per_start_z.describe()","18e5625a":"data4a = money_pop_cleaned.prize_money_per_start_z.dropna().values\ndata4b = money_pop_cleaned_win.prize_money_per_start_z.dropna().values\n\nplt.title(\"Winner and Race Distributions of Prize Money per Start Z-scores\",\n          fontsize=15)\n\nplt.hist(data4a, density=True, bins=24, range=(-3,3), label='Race Average',\n         color='b', alpha=.6, edgecolor='k')\n\nplt.hist(data4b, density=True, bins=24, range=(-3,3), label='Winner Average',\n         color='r', alpha=.5, edgecolor='k')\n\nplt.legend(loc='upper right')\nplt.xlabel('Prize Money per Start Z-scores')\nplt.ylabel('Probability');","957466b6":"test_stat4, p_value4 = ttest_ind(data4a, data4b)\n\ntest_stat4, p_value4","2140a67d":"overall_win_pop_cleaned = column_cleaner(df_cleaned, df_grouped, 'overall_win_percent_z')\n\noverall_win_pop_cleaned_win = cleaned_win_df(overall_win_pop_cleaned)","62cb42cd":"overall_win_pop_cleaned.overall_win_percent_z.describe()","9eb9f4ee":"overall_win_pop_cleaned_win.overall_win_percent_z.describe()","74c3d4a5":"data5a = overall_win_pop_cleaned.overall_win_percent_z.dropna().values\ndata5b = overall_win_pop_cleaned_win.overall_win_percent_z.dropna().values\n\nplt.title(\"Winner and Race Distributions of Overall Win Percent Z-scores\",\n          fontsize=15)\n\nplt.hist(data5a, density=True, bins=24, range=(-3,3), label='Race Average',\n         color='b', alpha=.6, edgecolor='k')\n\nplt.hist(data5b, density=True, bins=24, range=(-3,3), label='Winner Average',\n         color='r', alpha=.5, edgecolor='k')\n\nplt.legend(loc='upper right')\nplt.xlabel('Overall Win Percent Z-scores')\nplt.ylabel('Probability');","5eae5cbd":"test_stat5, p_value5 = ttest_ind(data5a, data5b)\n\ntest_stat5, p_value5","b64e3295":"overall_win_pop_grouped = overall_win_pop_cleaned.groupby(['date','venue_name',\n                                                           'market_name'])\n\noverall_starts_indices = overall_win_pop_grouped.overall_starts.agg('min')\\\n    .where(lambda x:x >= 5).dropna().index\n\noverall_starts_cleaned = overall_win_pop_cleaned.loc[overall_starts_indices].drop_duplicates()\n\noverall_starts_cleaned_win = cleaned_win_df(overall_starts_cleaned)","4bcefde3":"overall_starts_cleaned.overall_win_percent_z.describe()","527f4195":"overall_starts_cleaned_win.overall_win_percent_z.describe()","cfa1c3ac":"data6a = overall_starts_cleaned.overall_win_percent_z.dropna().values\ndata6b = overall_starts_cleaned_win.overall_win_percent_z.dropna().values\n\nplt.title(\"Winner and Race Distributions of Overall Win Percent Z-scores \\n (with horses over 5 total races)\",\n          fontsize=15)\n\nplt.hist(data6a, density=True, bins=24, range=(-3,3), label='Race Average',\n         color='b', alpha=.6, edgecolor='k')\n\nplt.hist(data6b, density=True, bins=24, range=(-3,3), label='Winner Average',\n         color='r', alpha=.5, edgecolor='k')\n\nplt.legend(loc='upper right')\nplt.xlabel('Overall Win Percent Z-scores \\n (with horses over 5 total races)')\nplt.ylabel('Probability');","882a99c2":"test_stat6, p_value6 = ttest_ind(data6a, data6b)\n\ntest_stat6, p_value6","10bdf488":"barrier_pop_cleaned = column_cleaner(df_cleaned, df_grouped, 'barrier')\n\nbarrier_grouped = barrier_pop_cleaned.groupby(['date','venue_name','market_name'])\n\nbarrier_indices = barrier_grouped.barrier.value_counts().where(lambda x:x == 1)\\\n    .dropna().index.droplevel('barrier')\n\nbarrier_pop_cleaned = barrier_pop_cleaned.loc[barrier_indices]\n\nbarrier_pop_cleaned_win = cleaned_win_df(barrier_pop_cleaned)","17b247a1":"barrier_pop = barrier_pop_cleaned.barrier.value_counts(normalize=True).sort_index()\\\n    .drop([18.00,19.00,20.00])\n\nbarrier_win = barrier_pop_cleaned_win.barrier.value_counts(normalize=True).sort_index()\\\n    .drop(18.00)\n\nbarrier_percent_difference = (barrier_win - barrier_pop)\/barrier_pop\n\nbarrier_percent_difference","d1351f2c":"index7 = barrier_percent_difference.index\n\ndf7 = pd.DataFrame({'Total Proportion': barrier_pop,'Win Proportion': barrier_win,\n                    'Percent Difference': barrier_percent_difference}, index=index7)\n\nax = df7.plot.bar(rot=0, title='The Significance of Barrier')","7ed1ae9d":"observed7 = barrier_pop_cleaned_win.barrier.value_counts().sort_index().drop(18.00).values\nexpected_percentages7 = barrier_pop.values\nexpected7 = [x*observed7.sum() for x in expected_percentages7]\n\ntest_stat7, p_value7 = chisquare(observed7, expected7)\n\ntest_stat7, p_value7","b102856f":"barr_dist_indices = barrier_pop_cleaned.distance.where(lambda x:x>=1800).dropna().index\n\nbarr_dist_cleaned = barrier_pop_cleaned.loc[barr_dist_indices]\n\nbarr_dist_cleaned_win = cleaned_win_df(barr_dist_cleaned)","0f33ed56":"barr_dist_pop = barr_dist_cleaned.barrier.value_counts(normalize=True).sort_index()\\\n    .drop(18.00)\n\nbarr_dist_win = barr_dist_cleaned_win.barrier.value_counts(normalize=True).sort_index()\\\n    .drop(18.00)\n\nbarr_dist_percent_difference = (barr_dist_win - barr_dist_pop)\/barr_dist_pop\n\nbarr_dist_percent_difference","cdff3d26":"index7a = barr_dist_percent_difference.index\n\ndf7a = pd.DataFrame({'Total Proportion': barr_dist_pop,'Win Proportion': barr_dist_win,\n                    'Percent Difference': barr_dist_percent_difference}, index=index7a)\n\nax = df7a.plot.bar(rot=0, title='The Significance of Barrier for Races Longer than 1800m')","1a7d8684":"#Drops races where there is only one jockey gender, meaning that the other gender can't win\njockey_sex_cleaned = column_cleaner(df_cleaned, df_grouped, 'jockey_sex')\n\njockey_sex_cleaned_win = cleaned_win_df(jockey_sex_cleaned)","4f12276a":"jockey_sex_cleaned.jockey_sex.value_counts(normalize=True)\n#This amount is the sum of all 'male' and 'female' jockeys added together and THEN 'normalized'","f27091cd":"#Isolates wins in races with both jockey genders represented\njockey_sex_cleaned_win.jockey_sex.value_counts(normalize=True, dropna=False)","c4af0696":"#Finding the percent difference between win and total\njockey_sex_pop = jockey_sex_cleaned.jockey_sex.value_counts(normalize=True,\n                                                            dropna=False).values\n\njockey_sex_win = jockey_sex_cleaned_win.jockey_sex.value_counts(normalize=True,\n                                                                dropna=False).values\n\njockey_sex_percent_difference = (jockey_sex_win - jockey_sex_pop)\/jockey_sex_pop","91a1c9b4":"index8 = ['Men','Women']\n\ndf8 = pd.DataFrame({'Total Proportion': jockey_sex_pop,'Win Proportion': jockey_sex_win ,\n                    'Percent Difference': jockey_sex_percent_difference}, index=index8)\n\nax = df8.plot.bar(rot=0, title='The Significance of Jockey Gender')","d1b54178":"last_start_pop_cleaned = column_cleaner(df_cleaned, df_grouped, 'last_start1')\n\nlast_start_pop_cleaned_win = cleaned_win_df(last_start_pop_cleaned)","e3040134":"#Finding the percent difference between win and total\nlast_start_pop = last_start_pop_cleaned.last_start1.value_counts(normalize=True,\n                                                                 dropna=False)\n\nlast_start_win = last_start_pop_cleaned_win.last_start1.value_counts(normalize=True,\n                                                                     dropna=False)\n\nlast_start_percent_difference = (last_start_win - last_start_pop)\/last_start_pop\n\nlast_start_percent_difference","11d5f3af":"index9 = ['1','2','3','4','5','6','7','8','9','ten+','scratch','fell','none']\n\ndf9 = pd.DataFrame({'Total Proportion': last_start_pop,'Win Proportion': last_start_win,\n                    'Percent Difference': last_start_percent_difference}, index=index9)","d17a3c9a":"last_start_pop_cleaned = column_cleaner(df_cleaned, df_grouped, 'last_start5')\n\nlast_start_pop_cleaned_win = cleaned_win_df(last_start_pop_cleaned)","2e5d9659":"#Finding the percent difference between win and total\nlast_start_pop = last_start_pop_cleaned.last_start5.value_counts(normalize=True,\n                                                                 dropna=False)\n\nlast_start_win = last_start_pop_cleaned_win.last_start5.value_counts(normalize=True,\n                                                                     dropna=False)\n\nlast_start_percent_difference = (last_start_win - last_start_pop)\/last_start_pop","5c64576f":"index10 = ['1','2','3','4','5','6','7','8','9','ten+','scratch','fell','none']\n\ndf10 = pd.DataFrame({'Total Proportion': last_start_pop,'Win Proportion': last_start_win,\n                    'Percent Difference': last_start_percent_difference}, index=index10)","e12fed9b":"last_start_pop_cleaned = column_cleaner(df_cleaned, df_grouped, 'last_start10')\n\nlast_start_pop_cleaned_win = cleaned_win_df(last_start_pop_cleaned)","288aabe9":"#Finding the percent difference between win and total\nlast_start_pop = last_start_pop_cleaned.last_start10.value_counts(normalize=True,\n                                                                 dropna=False)\n\nlast_start_win = last_start_pop_cleaned_win.last_start10.value_counts(normalize=True,\n                                                                     dropna=False)\n\nlast_start_percent_difference = (last_start_win - last_start_pop)\/last_start_pop","8b4dcce5":"index11 = ['1','2','3','4','5','6','7','8','9','ten+','scratch','fell','none']\n\ndf11 = pd.DataFrame({'Total Proportion': last_start_pop,'Win Proportion': last_start_win,\n                    'Percent Difference': last_start_percent_difference}, index=index11)","21c21d66":"last_start_pop_cleaned = column_cleaner(df_cleaned, df_grouped, 'last_start13')\n\nlast_start_pop_cleaned_win = cleaned_win_df(last_start_pop_cleaned)","82c21521":"#Finding the percent difference between win and total\nlast_start_pop = last_start_pop_cleaned.last_start13.value_counts(normalize=True,\n                                                                 dropna=False)\n\nlast_start_win = last_start_pop_cleaned_win.last_start13.value_counts(normalize=True,\n                                                                     dropna=False)\n\nlast_start_percent_difference = (last_start_win - last_start_pop)\/last_start_pop\n\nlast_start_percent_difference","af563e9b":"index12 = ['1','2','3','4','5','6','7','8','9','ten+','scratch','fell','none']\n\ndf12 = pd.DataFrame({'Total Proportion': last_start_pop,'Win Proportion': last_start_win,\n                    'Percent Difference': last_start_percent_difference}, index=index12)","e9cf3851":"fig,ax1 = plt.subplots(2, 2)\n\ndf9.plot.bar(ax=ax1[0,0],figsize=(20, 10)).set_title('The Significance of Previous Result')\ndf10.plot.bar(ax=ax1[0,1],figsize=(20, 10)).set_title('The Significance of 5 Results Ago')\ndf11.plot.bar(ax=ax1[1,0],figsize=(20, 10)).set_title('The Significance of 10 Results Ago')\ndf12.plot.bar(ax=ax1[1,1],figsize=(20, 10)).set_title('The Significance of 13 Results Ago')","58dcab77":"odds_cleaned = column_cleaner(df_cleaned, df_grouped, 'bf_odds')","ec5c0cf2":"#creates dataframe with a unique index\nodds_cleaned['uniq_idx'] = range(len(odds_cleaned))\nodds_cleaned_uniq_idx = odds_cleaned.set_index('uniq_idx',append=True)\nuniq_idx_grouped = odds_cleaned_uniq_idx.groupby(['date','venue_name',\n                                                  'market_name'])\n\nodds_cleaned_uniq_idx.head()","262a0d07":"bf_min_indices = uniq_idx_grouped.bf_odds.idxmin\n    \nmin_odds_cleaned = odds_cleaned_uniq_idx.loc[bf_min_indices].drop_duplicates()\n\nmin_odds_win = cleaned_win_df(min_odds_cleaned)\n\nodds_pop = len(min_odds_cleaned)\nodds_win = len(min_odds_win)\n\naverage = min_odds_win.bf_odds.agg('min').mean()\n\n#Printing total number of favorite horses (equal to the number of races) and the number of times those horses win:\nprint(len(min_odds_cleaned))\nprint(len(min_odds_win))","c0e48c2d":"odds_win\/odds_pop","6534ede3":"-1*(1-odds_win\/odds_pop) + average*odds_win\/odds_pop","2cfab8da":"df_cleaned.drop(['condition_place_percent_z','condition_win_percent_z',\n                 'distance_place_percent_z','distance_win_percent_z'],\n                axis=1,inplace=True)\n\n#drops last_start 11 through 20 to match information provided on racing websites\nfor i in range(10,20):\n    df_cleaned.drop('last_start'+str(i+1),axis=1,inplace=True)","583ab5b8":"df_cleaned_test = df_cleaned.copy()\n\ndf_cleaned_test.reset_index(drop=True,inplace=True)","59b02400":"#Modifying categorical groups\ndf_cleaned_test.position_again = df_cleaned_test.position_again.replace([2,3,np.nan],\n                                                                        [0,0,0])\n\ncategorical_list = ['sex','jockey_sex','condition','barrier']\nfor i in range(10):\n    categorical_list.append('last_start'+str(i+1)) \n\ndf_cleaned_test = pd.get_dummies(df_cleaned_test,columns=categorical_list,drop_first=True,dummy_na=1)\n\nnan_list1 = ['days_since_last_run_z','overall_starts','prize_money_per_start_z',\n             'overall_starts_z','overall_win_percent_z','overall_place_percent_z',\n             'condition_starts_z','distance_starts_z',\"track_starts_z\",\"track_starts\",\n             \"distance_starts\",\"condition_starts\",'weight_z','age_z','days_since_last_run',\n             'overall_win_percent','overall_place_percent','distance_win_percent',\n             'distance_place_percent','condition_win_percent','condition_place_percent']                            \n\nfor column1 in nan_list1:\n    df_cleaned_test[str(column1)].fillna(-99, inplace=True)\n\ndf_cleaned_test = df_cleaned_test.convert_objects(convert_numeric=True)","1fa4555f":"df_cleaned_test.head()","f02d56a6":"df_cleaned_test.isnull().sum()","46232498":"X = df_cleaned_test.drop(['position_again','bf_odds'],axis=1)\ny = df_cleaned_test['position_again']","03b06b69":"#classifiers\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.tree import DecisionTreeClassifier\n\nimport xgboost as xgb\n\n#for function below\nfrom sklearn.model_selection import StratifiedKFold\nfrom time import time\nfrom sklearn.metrics import make_scorer,confusion_matrix,accuracy_score,\\\n    precision_score,recall_score,f1_score,roc_auc_score,matthews_corrcoef","4b1d9384":"#for xgboost scale_pos_weight\nnegative = len(df_cleaned_test[df_cleaned_test.position_again ==0])\npositive = len(df_cleaned_test[df_cleaned_test.position_again ==1])\nxgb_weight = negative\/positive\n\nxgb_weight","e4eb6010":"clf_B = LogisticRegression(random_state=0,class_weight='balanced')\n\nclf_D = RandomForestClassifier(random_state=0,max_depth=15,class_weight='balanced')\n\nclf_F = DecisionTreeClassifier(random_state=0,max_depth=5,class_weight='balanced')\n\nclf_J = xgb.XGBClassifier(random_state=0,scale_pos_weight=xgb_weight)","cfb16a40":"def metrics_function(target,pred):\n    return accuracy_score(target, pred),precision_score(target, pred),\\\n        recall_score(target, pred),f1_score(target, pred),\\\n        roc_auc_score(target, pred),matthews_corrcoef(target, pred)\n\ndef FOLD_TEST(clf,X_all,y_all,folds_num,row_factor):\n    start=time()\n    \n    KFLD=StratifiedKFold(n_splits=folds_num,random_state=0,shuffle=True)\n    print ('{}:'.format(clf.__class__.__name__),'\\n')\n    \n    acc_list_train=[]\n    acc_list_test=[]\n    prc_list_train=[]\n    prc_list_test=[]\n    rcal_list_train=[]\n    rcal_list_test=[]\n    f1_list_train=[]\n    f1_list_test=[]\n    matt_list_train=[]\n    matt_list_test=[]\n    AUC_list_train=[]\n    AUC_list_test=[]\n    \n    samp_size=X_all.shape[0]\/\/row_factor\n    \n    true_values = []\n    predict_values =[]\n    \n    for fold,(train_index,target_index) in enumerate(KFLD.split(X_all[:samp_size],\n                                                                y_all[:samp_size])):\n        X_train=X_all.iloc[train_index].values\n        y_train=y_all.iloc[train_index].values\n\n        X_test=X_all.iloc[target_index].values\n        y_test=y_all.iloc[target_index].values\n        \n        clf.fit(X_train,y_train)\n        y_pred1=clf.predict(X_train)\n        y_pred2=clf.predict(X_test)\n\n        train_acc,train_prc,train_rcal,train_f1,train_auc,train_matt=metrics_function(y_train,y_pred1)\n        \n        test_acc,test_prc,test_rcal,test_f1,test_auc,test_matt=metrics_function(y_test,y_pred2)\n        \n        acc_list_train.append(train_acc)\n        acc_list_test.append(test_acc)\n        prc_list_train.append(train_prc)\n        prc_list_test.append(test_prc)\n        rcal_list_train.append(train_rcal)\n        rcal_list_test.append(test_rcal)\n        \n        f1_list_train.append(train_f1)\n        f1_list_test.append(test_f1)\n        matt_list_train.append(train_matt)\n        matt_list_test.append(test_matt)\n        AUC_list_train.append(train_auc)\n        AUC_list_test.append(test_auc)\n        \n        true_values = true_values + list(zip(target_index,y_test))\n        predict_values = predict_values + list(zip(target_index,y_pred2))\n        \n    print(\"Averages:\"'\\n')\n    \n    print(\"Train acc: {}, Test acc: {}\".format(np.mean(acc_list_train),\n                                               np.mean(acc_list_test)))\n    print(\"Train prc: {}, Test prc: {}\".format(np.mean(prc_list_train),\n                                               np.mean(prc_list_test)))\n    print(\"Train recall: {}, Test recall: {}\".format(np.mean(rcal_list_train),\n                                                     np.mean(rcal_list_test)),'\\n')\n    \n    print(\"Train f1: {}, Test f1: {}\".format(np.mean(f1_list_train),\n                                             np.mean(f1_list_test)))\n    print(\"Train MattCC: {}, Test MattCC: {}\".format(np.mean(matt_list_train),\n                                                     np.mean(matt_list_test)))\n    print(\"Train AUC: {}, Test AUC: {}\".format(np.mean(AUC_list_train),\n                                               np.mean(AUC_list_test)),'\\n'*2)\n        \n    print(\"Sample Size: {}, Folds Num: {}, Time: {}\".format(samp_size,folds_num,\n                                                            time()-start),'\\n'*2)\n    \n    total_picks = []\n    correct_idx = []\n\n    for ((a,b),(c,d)) in list(zip(true_values,predict_values)):\n        if (b==1)&(d==1):\n            correct_idx.append(a)\n        if d==1:\n            total_picks.append(c)\n\n    win_odds_list=[]\n\n    for a in correct_idx:\n        win_odds_list.append(df_cleaned_test.bf_odds.iloc[a])\n\n    average_win=np.mean(win_odds_list)\n    \n    print(\"Total Picks:\",len(total_picks),\"Average Win Odds:\", average_win)\n    print(\"Total Return:\",average_win*len(correct_idx)-len(total_picks))\n    print(\"Average Expected Return:\",(average_win*len(correct_idx)-len(total_picks))\/len(total_picks))","6713cbd9":"FOLD_TEST(clf_B, X, y, 5, 2)","37033581":"FOLD_TEST(clf_D, X, y, 5, 2)","e3b81035":"FOLD_TEST(clf_F, X, y, 5, 2)","0ea16f8a":"FOLD_TEST(clf_J, X, y, 5, 2)","4590c961":"## For overall wins:","47af8610":"## Creating a horse age_z column:","7852d2ca":"# Normalizing each group (race) using z-scores is a good and straightforward way to compare horses across races.\n\n## Here, I am creating several normalized columns in this way.","affc3736":"## Creating general and track, distance, condition-specific 'win_percent' and 'place_percent' columns:","782d33ac":"### Using a 2-sample T-test, I find that Overall Win Percent Z-scores (with horses over 5 total races) is significant:","785c3264":"### The expected return if betting 1 dollar on favorite every race:","2edc13d8":"### Does condition affect the win distribution of age? Specifically, do older horses perform worse in bad conditions?","3f97be84":"# <center> Analyzing the \"Horses for Courses\" Horse Racing Dataset from Kaggle <\/center>","43c3647e":"### It appears as though bad track conditions actually level out the age discrepancies, maybe because they have more experience with those bad conditions.","5f640de9":"# Testing and graphing the significance of certain features:","bd6a4a60":"#### Overall percentage of men and women in races where both are represented:","a363dd39":"### How often the favorite wins:","47b885f4":"## Shuffling and splitting the grouped data:","a14fea97":"# Beginning the Machine Learning Process:","279a94f0":"### After 13 starts:","1c112c5e":"## I decided not to use any man-made metrics (e.g. odds, field strength, etc.) because these are relative and subject to change.\n\n## Also, jockey and trainer win percentages are not included with this dataset.\n\n## Fixing the format of some features:","7e9d22eb":"### After 10 starts:","2b4c2c50":"## For horse age_z (z-scores):","5df7ac4c":"## Find and drop features that are primarily NaN:","3e5f4b5c":"## For Barrier:","5771214c":"### The dataset is imbalanced and this needs to be accounted for.","0eaa4baf":"# How often would you win and what would be your expected return if you always bet on the favorite?","3307b5c6":"### Using a 2-sample T-test, again I find that Weight Z-scores is significant:","dccb83e5":"#### Win percentage of those races:","5647a735":"### Creates a function to split data and fit, predict, and score models:","f84eeb2f":"## Creating a prize_money_per_start_z column:\n\n### This may be one of the best indicators, as prize money is also an indicator of the difficulty of past races. Therefore, the value (meaningfulness) of past wins is taken into consideration.","24eee282":"#### Finding the total a different way:","0a11b7cb":"# Creating new features and dropping others in order to relate horses in each race to one another while allowing the general input of the dataset into a machine learning model:","6983f5ba":"### Using a 2-sample T-test, I find that Prize Money per Start Z-scores is significant:\n","e566dc5f":"### It appears that there may be an even bigger distinction with barrier 1 with longer race distances. However, the other barriers seem to even out.","c50f38f5":"### Condition depended T-test for Age Z-scores: ","54402f6b":"## For horse handicap weight_z (z-scores):","1d9feb4a":"## Creating a distance column from market_name:","8993a44b":"## Cleaned Dataframe Details:","5377bb09":"### Using a 2-sample T-test, I find that Age Z-scores is significant:","c95d9361":"### Does the length of a race negate or alter the effect of starting barrier?","9ef4e8a4":"## Dropping null-majority features, creating dummy variables, and replacing null values:","c137226d":"## For horse gender:","ffab39f9":"## Splits last_twenty_starts column into 20 separate columns, replaces values, then drops last_twenty_starts:","7a287785":"### Using a 2-sample T-test, I find that Overall Win Percent Z-scores is significant:","040d4217":"## Creating race-relative z-scores for the remaining continuous features:","d533584d":"## Cleaning data by removing races with missing win and\/or place values in 'position_again' column:","108e0622":"## How far back does form (previous finishes) become irrelevant?\n\n### The distribution after 1 start:","786bfbfd":"## Creating a weight_z column:","f5680a8e":"## Useful Cleaning Functions:","ae435b55":"## The meaningful values here are:\n### Test prc (precision), Sample Size, Total Picks, Average Win Odds, Total Return, and Average Expected Return.","09b44b96":"### Using a 2-proportion z-test, I find that jockey gender is significant with a p-value of 2.3E-30\n#### (There is currently a bug with the statsmodels library concering compatibility with scipy, so I used a scientific calculator)","8485d365":"### Using the Pearson's chi-squared, I find horse gender is significant:","6948bb0b":"### Why is barrier 1 so overrepresented? Is there a problem with the data? There doesn't appear to be.\n\n### Using the Pearson's chi-squared test, I find that barrier is significant:","39a9d26d":"## For prize money, using prize_money_per_start_z (z-scores):","df753b45":"## For jockey gender: ","e081bd0a":"### After 5 starts:","eff982b5":"## I decided to keep the original \"overall_starts,\" \"distance_starts,\" \"condition_starts,\" and \"track_starts\" columns because they may have a meaning irrespective of other races (unnormalized).","0c85404e":"### Graphing form data:","d4cfcf8a":"### There is high variance in the 100% column (aka beginner's luck). How many races before the 100% column is properly represented? That is, how many races is considered statistically significant?\n\n### It seems that a minimum of 5 races for all horses in the race gives the percent difference bar graph an exponential appearance."}}