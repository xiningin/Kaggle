{"cell_type":{"96efbbd8":"code","7604e46b":"code","be4e3226":"code","3e84b1a4":"code","d02b00d0":"code","8d7cee8d":"code","e33a1cbe":"code","8a022449":"code","20c32123":"code","ffa0c2a6":"code","73b81667":"code","4596d801":"code","d1653016":"code","c8c4f5ed":"code","20f21a52":"code","a0efe248":"code","aeebb1b3":"code","cce83d2f":"code","842ae571":"code","e664a6d4":"code","68212cbe":"markdown","8e7a4fd8":"markdown","a9ab2c2f":"markdown","4e49275e":"markdown","10b0b65a":"markdown","17749672":"markdown","cc484307":"markdown","6471f3c6":"markdown","e786e62d":"markdown"},"source":{"96efbbd8":"# Importing necessary libraries for preprocessing & EDA\nimport numpy as np \nimport pandas as pd \nfrom plotly import graph_objs as go\n\n# Ignore  the warnings\nimport warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')\n\ndf = pd.read_csv('..\/input\/womens-ecommerce-clothing-reviews\/Womens Clothing E-Commerce Reviews.csv')\ndf.head()","7604e46b":"# Remove columns\ndel df['Unnamed: 0']\n\n# How many reviews do we have?\nprint('There are', df.shape[0], 'reviews in this dataset')\n\n# Do we have duplicates?\nprint('Number of Duplicates:', len(df[df.duplicated()]))\n\n# Do we have missing values?\nprint('Number of Missing Values:', df.isnull().sum().sum())","be4e3226":"print('Number of Missing Values per column:')\ndf.isnull().sum().sort_values(ascending=False)","3e84b1a4":"# Remove rows with nulls in specific columns\ndf = df.dropna(subset = ['Review Text', 'Division Name', 'Department Name', 'Class Name'])","d02b00d0":"recommended = (\n    df['Recommended IND']\n    .value_counts()\n    .to_frame()\n    .reset_index()\n    .rename(columns={'index':'Recommended', 'Recommended IND':'Count'})\n    .sort_values(by=['Recommended'], ascending=True)\n    .replace([0, 1], ['No', 'Yes'])   \n          )  \n\ncolors = ['#f6b220','#0E2F44']\n\nfig = go.Figure(data=[go.Pie(labels=recommended['Recommended'], \n                             values=recommended['Count'])])\n\nfig.update_traces(hoverinfo='percent', \n                  textinfo='label', \n                  textfont_size=20,\n                  marker=dict(colors=colors, \n                              line=dict(color='white', width=1)))\n\nfig.update_layout(showlegend=False, \n                  title_text=\"<b>Recommended<\/b> Distribution\",\n                  title_x=0.5,\n                  font=dict(family=\"Rockwell, sans-serif\", size=25, color='#000000'))\n\nfig.show()","8d7cee8d":"classes = (\n    df\n    .groupby(['Recommended IND', 'Class Name'])\n    .size()\n    .to_frame()\n    .rename(columns={0:'Count'})\n    .reset_index()\n          )  \n\n# get proportions in each class\na = classes.groupby('Class Name')['Count'].transform('sum')\n\nclasses['Count'] = classes['Count'].div(a)\n\n# pivot table\nclasses = classes.pivot(index='Class Name', columns='Recommended IND')  \n\nfig = go.Figure()\nfig.add_trace(go.Bar(\n    y=classes.index,\n    x=classes.iloc[:,0],\n    name='Not Recommended',\n    orientation='h',\n    marker=dict(\n        color='#f6b220')\n    ))\n\nfig.add_trace(go.Bar(\n    y=classes.index,\n    x=classes.iloc[:,1],\n    name='Recommended',\n    orientation='h',\n    marker=dict(\n        color='#0E2F44')\n    ))\n\nfig.update_layout(barmode='stack')\n\nfig.update_layout(\n                title = 'Distribution of <b>Product Class<\/b> by Recommendation ',\n                barmode='stack', \n                autosize=False,\n                width=680,\n                height=800,\n                font=dict(family=\"Rockwell, sans-serif\", size=18, color='#000000'),\n                margin=dict(\n                  l=150,\n                  r=100,\n                   b=30,\n                   t=100,\n                   pad=4\n                          ))\nfig.layout.xaxis.tickformat = ',.0%'\n\nfig.show()","e33a1cbe":"rating = (\n    df['Rating']\n    .value_counts()\n    .to_frame()\n    .reset_index()\n    .rename(columns={'index':'Rating', 'Rating':'Count'})\n    .sort_values(by=['Rating'], ascending=True)   \n          ) \n\nrating['percent'] = ((rating['Count'] \/ rating['Count'].sum())*100).round(2).astype(str) + '%'\n\ncolors = ['#0E2F44',] * 5\ncolors[4] = '#f6b220'\n\nfig = go.Figure(go.Bar(\n            y=rating['Count'],\n            x=rating['Rating'],\n            marker_color=colors,\n            text=rating['percent']\n                        ))\n\nfig.update_traces(texttemplate='%{text}', \n                  textposition='outside',\n                  cliponaxis = False,\n                  hovertemplate='<b>Rating<\/b>: %{x}<br><extra><\/extra>'+  # <extra><\/extra> removes trance 0\n                                '<b>Count<\/b>: %{y}',\n                  textfont_size=18)\n                  \nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\n \nfig.update_layout(coloraxis=dict(colorscale='Teal'),\n                  showlegend=False, \n                  plot_bgcolor='#F7F7F7', \n                  margin=dict(pad=20),\n                  paper_bgcolor='#F7F7F7',\n                  height=500,\n                  yaxis={'showticklabels': False},\n                  yaxis_title=None,\n                  xaxis_title=None,\n                  title_text=\"<b>Rating<\/b> Distribution\",\n                  title_x=0.5,\n                  font=dict(family=\"Rockwell, sans-serif\", size=22, color='#000000'),\n                  title_font_size=35)\n\n\nfig.show()","8a022449":"# Necessary libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\nimport re\nimport string\n\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing import sequence\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Embedding\nfrom tensorflow.keras.layers import SimpleRNN, LSTM\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","20c32123":"# Let's just work with the reviews and recommendations\ndata = df[['Review Text', 'Recommended IND']]","ffa0c2a6":"# Cleaning the text\ndef clean_text(text):\n    '''Make text lowercase, remove text in square brackets, \n    remove links, remove punctuation\n    and remove words containing numbers.'''\n    text = str(text).lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?:\/\/\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text","73b81667":"data['Review Text'] = data['Review Text'].apply(lambda x:clean_text(x))","4596d801":"# Setting up the evaluation metrics\ndef roc_auc(predictions,target):\n    \n    fpr, tpr, thresholds = metrics.roc_curve(target, predictions)\n    roc_auc = metrics.auc(fpr, tpr)\n    return roc_auc","d1653016":"# Split target & features\nX = data.drop('Recommended IND', axis=1)\ny = data['Recommended IND']\n\n# Spliting train & test\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    stratify=y,\n                                                    test_size=0.2, \n                                                    random_state=42,\n                                                    shuffle=True)","c8c4f5ed":"# Keras takenization text data prep\n\nnum_words = None   # the most X frequent words is returned\n\n# Tokenize data\ntokenizer = Tokenizer(num_words=num_words)\ntokenizer.fit_on_texts(X_train['Review Text'].tolist() + X_test['Review Text'].tolist())   # introduce text in list\n\n# Get data word index\nword_index = tokenizer.word_index\n\n# Encode training\/test data sentences into sequences\nX_train_seq = tokenizer.texts_to_sequences(X_train['Review Text'].tolist())\nX_test_seq = tokenizer.texts_to_sequences(X_test['Review Text'].tolist())\n\n# Get max training sequence length\nmax_len = max([len(x) for x in X_train_seq])\n\n# Pad the training\/test sequences\nX_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\nX_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n\n# Output some results \nprint(\"\\nPadded training shape:\", X_train_pad.shape)\nprint(\"\\nPadded test shape:\", X_test_pad.shape)","20f21a52":"# Basic RNN \nmodel = Sequential()\nmodel.add(Embedding(len(word_index) + 1,\n                    50,     # embeds it in a 50-dimensional vector\n                    input_length=max_len))\nmodel.add(SimpleRNN(100))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nmodel.summary()","a0efe248":"batch_size = 512\n\nmodel.fit(X_train_pad, y_train, epochs=5, batch_size=batch_size)","aeebb1b3":"scores = model.predict(X_test_pad)\nprint(\"AUC: %.2f%%\" % (roc_auc(scores,y_test)))","cce83d2f":"model = Sequential()\nmodel.add(Embedding(len(word_index) + 1,\n                    50,     # embeds it in a 50-dimensional vector\n                    input_length=max_len))\n\nmodel.add(LSTM(100, dropout=0.3, recurrent_dropout=0.3))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n    \nmodel.summary()","842ae571":"batch_size = 512\n\nmodel.fit(X_train_pad, y_train, epochs=5, batch_size=batch_size)","e664a6d4":"scores = model.predict(X_test_pad)\nprint(\"AUC: %.2f%%\" % (roc_auc(scores,y_test)))","68212cbe":"# Introduction\n\nThis notebook will demonstrate how to perform a sentimental analysis using different Deep Learning techniques. As a beginner with Deep Learning Techniques for NLP, I won't use the most sophisticated techniques available out there. However, I'll explain the basics needed to face an NLP project. \n\nThe data that I will be working with in this notebook will be from a Women's Clothing E-Commerce store revolving around the reviews written by customers on their different products. If you want to know more about it, you can click here.\n\n## Acknowledgment \n\nI want to recognize MR_KNOWNOTHING for his fantastic contribution to NLP's topic in Kaggle's community. Here are a couple of his kernels that I recommend to everyone to check out:\n\n* https:\/\/www.kaggle.com\/tanulsingh077\/deep-learning-for-nlp-zero-to-transformers-bert\n\n* https:\/\/www.kaggle.com\/tanulsingh077\/twitter-sentiment-extaction-analysis-eda-and-model\n\n## About this notebook\n\nFor this project, I'll show the performance of the Recurrent Neural Networks (RNN) and Long Short Term Memory networks (LSTM's) techniques for NPL. Previous to that, I'll display a simple EDA to understand the basics of the dataset and preprocess it for the models.","8e7a4fd8":"\"Trend\" is the class with the most \"Not Recommended\" responses.","a9ab2c2f":"# EDA","4e49275e":"# LSTM's","10b0b65a":"I'll remove the rows with nulls of every column except the <code>Title<\/code> feature.","17749672":"# Tokenization\n\nTokenization is an essencial step on a NLP process. Tokenization is essentially splitting a phrase, sentence, paragraph, or an entire text document into smaller units, such as individual words or terms. Each of these smaller units are called tokens. Check out the below image to visualize this definition:\n\n<center><img src='https:\/\/freecontent.manning.com\/wp-content\/uploads\/Chollet_DLfT_01.png'><\/center>\n\nI recommend checking these 2 articles: \n\n* https:\/\/www.analyticsvidhya.com\/blog\/2019\/07\/how-get-started-nlp-6-unique-ways-perform-tokenization\/\n\n* https:\/\/www.kdnuggets.com\/2020\/03\/tensorflow-keras-tokenization-text-data-prep.html","cc484307":"# NLP\n\nFor the following models, I'll just be focusing on the review text and recommendation columns to determine if, based on the text, the user will recommend the product to other customers (i.e. if they like it enough to recommend it to some else). This way it will reduce the complexity of the model and make it a classification binary model.","6471f3c6":"The majority of the reviews are positive and recommend the product they purchase.","e786e62d":"# RNN"}}