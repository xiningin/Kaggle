{"cell_type":{"d27502cb":"code","7e3e7075":"code","df90d487":"code","bfa54fd6":"code","22101b67":"markdown"},"source":{"d27502cb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n\n# Any results you write to the current directory are saved as output.","7e3e7075":"# This tells matplotlib not to try opening a new window for each plot.\n%matplotlib inline\n\n# Import a bunch of libraries.\nimport time\nimport os\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.naive_bayes import GaussianNB\nfrom numpy import math\n\n# Set the randomizer seed so results are the same each time.\nnp.random.seed(0)\n\n# Prepare Dataset\n# load data\ntrain = pd.read_csv(r\"..\/input\/train.csv\",dtype = np.float32)\n\n# split data into features(pixels) and labels(numbers from 0 to 9)\ntargets_numpy = train.label.values\nfeatures_numpy = train.loc[:,train.columns != \"label\"].values\/255 # normalization\n\n# train test split. Size of train data is 80% and size of test data is 20%. \ntrain_data, test_data, train_labels, test_labels = train_test_split(features_numpy,\n                                                                             targets_numpy,\n                                                                             test_size = 0.2,\n                                                                             random_state = 42)","df90d487":"def imperfect_numbers(num_examples=10):\n    \n    #Look for examples of each digit\n    from itertools import chain\n\n    zero = list(np.where(train_labels==0)[0][:num_examples])\n    one = list(np.where(train_labels==1)[0][:num_examples])\n    two = list(np.where(train_labels==2)[0][:num_examples])\n    three = list(np.where(train_labels==3)[0][:num_examples])\n    four = list(np.where(train_labels==4)[0][:num_examples])\n    five = list(np.where(train_labels==5)[0][:num_examples])\n    six = list(np.where(train_labels==6)[0][:num_examples])\n    seven = list(np.where(train_labels==7)[0][:num_examples])\n    eight = list(np.where(train_labels==8)[0][:num_examples])\n    nine = list(np.where(train_labels==9)[0][:num_examples])\n    \n    #Store them together in one list and reshape them\n    all=list(chain(zero, one, two, three, four, five, six, seven, eight, nine))\n    xgrid=train_data[all]\n    xgrid=list(xgrid)\n    xgrid=[x.reshape(28,28) for x in xgrid]\n    \n    #Create a grid subplot \n    plt.figure(figsize=(28,28))\n    for i in range(0,10*num_examples):\n        plt.subplot(10,num_examples,i+1)\n        plt.imshow(xgrid[i],cmap=plt.get_cmap('gray_r'))\n        plt.tick_params(left='off', bottom='off', right='off', top='off', labelleft='off', labelbottom='off')\n\nimperfect_numbers(10)","bfa54fd6":"def perfect_numbers():\n    \n    naive_binom = BernoulliNB(binarize = 0.5)\n    naive_binom.fit(train_data,train_labels)\n    prob = (np.exp(naive_binom.feature_log_prob_))\n    \n    generate = list()\n    for i in range(1,101):\n        generate.append((prob[math.ceil((i\/10)-1)])*(np.random.rand(784,)))\n        i=i+1\n    generate = [x.reshape(28,28) for x in generate]\n    \n    plt.figure(figsize=(28,28))\n    for i in range(0,100):\n        plt.subplot(10,10,i+1)\n        plt.imshow(generate[i],cmap=plt.get_cmap('gray_r'))\n        plt.tick_params(left='off', bottom='off', right='off', top='off', labelleft='off', labelbottom='off')\n\nperfect_numbers()","22101b67":"># Imperfect and Perfect Digits\n\nThis notebook is an MNIST digit recognizer implemented with numpy and scikit-learn. Its objective is show what an average digit looks like, based on the probability of an active pixel using the BernoulliNB classifier.\n\nThis is a simple demonstration mainly for pedagogical purposes, which shows the basic workflow of a machine learning algorithm using a simple off-the-rack classifiers from the scikit-learn library."}}