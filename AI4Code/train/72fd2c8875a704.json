{"cell_type":{"2655a71b":"code","4cd942a2":"code","8cb12636":"code","6e5a6907":"code","21ec3250":"code","6b801b91":"code","62e420d8":"code","3c19574b":"code","03f51c49":"code","b786a89d":"code","062c8090":"code","0c4e9b52":"code","f71ca044":"code","17a997bc":"code","02574258":"code","85a7469f":"code","d72740fa":"code","955e0458":"code","b8c1e38b":"code","4fb36030":"code","7afda3f9":"code","49e1b6c9":"code","dc573772":"code","16d54d43":"code","0dfed62a":"code","8f5745eb":"markdown","aebeaede":"markdown","448aba78":"markdown","4d5f049c":"markdown","5693ab88":"markdown","efc6dce7":"markdown","f256160d":"markdown","0ba13866":"markdown","35c9cb1d":"markdown","ce5ef68a":"markdown","16383d91":"markdown"},"source":{"2655a71b":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing  import StandardScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.model_selection import cross_val_score","4cd942a2":"train = pd.read_csv(r'\/kaggle\/input\/titanic\/train.csv')\ntrain.Age.fillna(train.Age.median(), inplace=True)\ntrain = train.drop(['Cabin', 'Ticket', 'Name', 'PassengerId'], axis=1)\n","8cb12636":"#test data\ncontrol = pd.read_csv(r'\/kaggle\/input\/titanic\/test.csv')\nX_control = control[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\nclass_le = LabelEncoder()\nX_control['Sex'] = class_le.fit_transform(X_control['Sex'].values)\nX_control['Embarked'] = class_le.fit_transform(X_control['Embarked'].values)\nX_control.Age.fillna(X_control.Age.median(), inplace=True)\nX_control.loc[X_control['Fare'].isna(),'Fare'] = X_control['Fare'].mode()[0]","6e5a6907":"class_le = LabelEncoder ()\ntrain['Sex'] = class_le.fit_transform(train['Sex'].values)\ntrain['Embarked'] = class_le.fit_transform(train['Embarked'].values)","21ec3250":"y = train.Survived\nX = train.drop('Survived', axis = 1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=0, stratify=y) ","6b801b91":"len(X_train)","62e420d8":"svc_pipe = Pipeline([['st', StandardScaler()],['svc', SVC(random_state=1)]]) \n\nparam_range = [0.0001, 0.001, 0.01, 0.1, 1, 2, 5]\nbool = [True, False]\nparam_grid = [{'svc__C' : param_range,\n               'svc__probability' : bool,\n               'svc__kernel': ['linear']},\n               {'svc__C': param_range,\n                'svc__probability' : bool,\n               'svc__gamma': param_range,\n               'svc__kernel' : [ 'rbf' ]}]\n\ngs_svc = GridSearchCV(estimator=svc_pipe, param_grid = param_grid, scoring='accuracy', refit=True, cv=4)\ngs_svc = gs_svc.fit(X_train, y_train)\ngs_svc.best_params_","3c19574b":"gs_svc.best_score_","03f51c49":"svc_pipe = Pipeline([['st', StandardScaler()],\n                ['svc', SVC(random_state=1, C = 1, gamma = 0.1, kernel = 'rbf', probability = True)]]) ","b786a89d":"bag_svc = BaggingClassifier(base_estimator=svc_pipe, n_estimators=50, random_state=0).fit(X_train, y_train)","062c8090":"pipe_knn = Pipeline([['st', StandardScaler()],\n                    ['knn', KNeighborsClassifier(weights = 'distance', metric = 'minkowski')]])\nparam_grid_knn = [{'knn__n_neighbors' :  [1,2,3,4,5,6,7,8,9],\n                   'knn__p' : [1,2,3]}]\ngrid_knn = GridSearchCV(estimator = pipe_knn, param_grid = param_grid_knn, scoring = 'accuracy',\n                        refit=True, cv=4)\ngs_knn = grid_knn.fit(X_train, y_train)\n","0c4e9b52":"gs_knn.best_params_","f71ca044":"gs_knn.best_score_","17a997bc":"pipe_knn = Pipeline([['st', StandardScaler()],\n                    ['knn', KNeighborsClassifier(weights = 'distance', p = 1, n_neighbors = 4, \n                                                 metric = 'minkowski')]])","02574258":"bag_knn = BaggingClassifier(base_estimator=pipe_knn, n_estimators=50, random_state=0).fit(X_train, y_train)","85a7469f":"pipe_forest = Pipeline([('forest', RandomForestClassifier( bootstrap = True,random_state=1, n_jobs=2))])\n\nparam_grid_forest = [{'forest__criterion' : ['gini', 'entropy'],\n                      'forest__max_depth' :  [5, 6, 7, 8],\n                      'forest__max_features' : [3,4,5, 6],\n                      'forest__max_samples' : [210, 230, 250, 270, 300],\n                      'forest__n_estimators' : [25, 30, 35, 40]}]\n\ngrid_forest = GridSearchCV(estimator = pipe_forest, param_grid = param_grid_forest, \n                           scoring = 'accuracy',refit=True, cv=4)\ngs_forest = grid_forest.fit(X_train, y_train)\ngs_forest.best_score_ ","d72740fa":"gs_forest.best_params_","955e0458":"pipe_forest = Pipeline([('forest', RandomForestClassifier(criterion='gini', max_depth = 8, \n                                                          max_features = 3,  max_samples = 270,\n                                                          bootstrap = True, n_estimators=35, \n                                                          random_state=1,  n_jobs=2))])","b8c1e38b":"lr_pipe = Pipeline([['sd', StandardScaler()],\n                    ['lr', LogisticRegression(random_state=0, solver = 'lbfgs', C = 0.01,\n                                              penalty = 'l2')]])\n\nparam_grid_lr = [{'lr__penalty' : ['l1', 'l2'],\n                 'lr__C' : [0.001, 0.01, 0.1, 1, 2],\n                 'lr__solver' : ['liblinear']},\n                 {'lr__penalty' : ['l2'],\n                 'lr__C' : [0.001,0.01, 0.1, 1, 2],\n                 'lr__solver' : ['lbfgs']}]\nlr_grid =  GridSearchCV(estimator = lr_pipe, param_grid = param_grid_lr, \n                        scoring = 'accuracy',refit=True, cv=4)\nlr_grid = lr_grid.fit(X_train, y_train)\nlr_grid.best_score_","4fb36030":"lr_grid.best_params_","7afda3f9":"lr_pipe = Pipeline([['sd', StandardScaler()],\n                    ['lr', LogisticRegression(random_state=0, solver = 'liblinear', \n                                              C = 2, penalty = 'l2')]])","49e1b6c9":"bag_lr = BaggingClassifier(base_estimator=lr_pipe, n_estimators=50, random_state=0).fit(X_train, y_train)","dc573772":"ens1 = VotingClassifier(estimators=[('svc', bag_svc), ('knn', bag_knn), ('forest', pipe_forest),\n                                    ('lr', bag_lr)], voting='hard')\nens1 = ens1.fit(X_train, y_train)","16d54d43":"print('Cross-validation on 5 blocks: \\n')\nfor model, label in zip([bag_svc, bag_knn, pipe_forest, bag_lr, ens1], ['SVC', 'KNN','RandomForest', \n                                                                        'LogisticRegression', 'Ensemble']):\n    scores = cross_val_score(estimator=model,  X=X_train, y=y_train, cv=5, scoring='accuracy')\n    print(\"Accuracy on train data set: %f (+\/- %f) [%s]\" % (scores.mean(), scores.std(), label))","0dfed62a":"y_pred = ens1.predict(X_control)\nsubmission = pd.DataFrame({'PassengerId' : control.PassengerId,'Survived' : y_pred})\nsubmission.to_csv(path_or_buf = 'titanic_submission.csv', index=False)","8f5745eb":"## Bagging for LogisticRegression","aebeaede":"## Load the data and drop a few columns","448aba78":"## Support Vector Classification with GridSearch","4d5f049c":"## Bagging for SVC model","5693ab88":"### By now we have four models: Support Vector Classification, K-nearest neighbors, Random forest, Logistic regression. All models are based on bagging. Now lets make an ensemble of majority votes.","efc6dce7":"## K-nearest weighted neighbors with GridSearch","f256160d":"## Encode strings   ","0ba13866":"## Make 85% training set and 15% test set","35c9cb1d":"## Bagging for KNN","ce5ef68a":"## RandomForestClassifier with GridSearch","16383d91":"## LogisticRegression with GridSearch"}}