{"cell_type":{"433e2479":"code","35dd9f45":"code","2349a5d0":"code","a380dd0e":"code","f4246f73":"code","4a740c51":"code","d74211ee":"code","5f1e35d4":"code","9bb76ca2":"code","0794c135":"code","26888a3e":"code","db065076":"code","52bdcd9b":"code","152d4eb1":"code","77bc3f64":"markdown","cf9d9ea6":"markdown","89ce18b3":"markdown"},"source":{"433e2479":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport tensorflow.keras.layers as Layers\nimport tensorflow.keras.activations as Actications\nimport tensorflow.keras.models as Models\nimport tensorflow.keras.optimizers as Optimizer\nimport tensorflow.keras.metrics as Metrics\nimport tensorflow.keras.utils as Utils\nfrom keras.utils.vis_utils import model_to_dot\nimport os\nimport matplotlib.pyplot as plot\nimport cv2\nimport numpy as np\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import confusion_matrix as CM\nfrom random import randint\nfrom IPython.display import SVG\nimport matplotlib.gridspec as gridspec\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","35dd9f45":"def get_images(directory):\n    Images = []\n    Labels = []  # 0 for Building , 1 for forest, 2 for glacier, 3 for mountain, 4 for Sea , 5 for Street\n    label = 0\n    \n   # The \"listdir()\" function of the os module allows us to list files and folders within a directory\n\n   # If we want to list the contents of a different directory, it will be enough to write the name of that directory as the parameter. \"os.listdir ('\/ var \/ www')\"\n    for labels in os.listdir(directory): #Main Directory where each class label is present as folder name.\n        if labels == 'buildings':\n            label = 0\n        elif labels == 'forest':\n            label = 1\n        elif labels == 'glacier': #Folder contain Glacier Images get the '2' class label.\n            label = 2\n        elif labels == 'mountain':\n            label = 3\n        elif labels == 'sea':\n            label = 4\n        elif labels == 'street':\n            label = 5\n            \n        \n       # Here with for loop, we go into each file and make the size of the pictures there as 150x150.\n        for image_file in os.listdir(directory+labels): #Extracting the file name of the image from Class Label folder\n\n            image = cv2.imread(directory+labels+r'\/'+image_file) #Reading the image (OpenCV)\n            image = cv2.resize(image,(150,150)) #Resize the image, Some images are different sizes. (Resizing is very Important)\n            Images.append(image)\n            Labels.append(label)\n            \n            \n    return shuffle(Images,Labels,random_state=817328462) #Shuffle the dataset you just prepared.\n\n\ndef get_classlabel(class_code):\n    labels = {2:'glacier', 4:'sea', 0:'buildings', 1:'forest', 5:'street', 3:'mountain'}\n    \n    return labels[class_code]\n    ","2349a5d0":"Images, Labels = get_images('\/kaggle\/input\/intel-image-classification\/seg_train\/seg_train\/') #Extract the training images from the folders.\n\nImages = np.array(Images) #converting the list of images to numpy array.\nLabels = np.array(Labels)","a380dd0e":"# shape of Training data set\nprint(\"Shape of Images:\",Images.shape)\nprint(\"Shape of Labels:\",Labels.shape)","f4246f73":"# Lets plot some of training images\nf,ax = plot.subplots(5,5) \nf.subplots_adjust(0,0,3,3) # adjust the spaces between images\nfor i in range(0,5,1):\n    for j in range(0,5,1):\n        rnd_number = randint(0,len(Images))\n        ax[i,j].imshow(Images[rnd_number])\n        ax[i,j].set_title(get_classlabel(Labels[rnd_number]))\n        ax[i,j].axis('off')","4a740c51":"model = Models.Sequential()\n\nmodel.add(Layers.Conv2D(200,kernel_size=(3,3),activation='relu',input_shape=(150,150,3)))\nmodel.add(Layers.Conv2D(180,kernel_size=(3,3),activation='relu'))\nmodel.add(Layers.MaxPool2D(5,5))\nmodel.add(Layers.Conv2D(180,kernel_size=(3,3),activation='relu'))\nmodel.add(Layers.Conv2D(140,kernel_size=(3,3),activation='relu'))\nmodel.add(Layers.Conv2D(100,kernel_size=(3,3),activation='relu'))\nmodel.add(Layers.Conv2D(50,kernel_size=(3,3),activation='relu'))\nmodel.add(Layers.MaxPool2D(5,5))\nmodel.add(Layers.Flatten())\nmodel.add(Layers.Dense(180,activation='relu'))\nmodel.add(Layers.Dense(100,activation='relu'))\nmodel.add(Layers.Dense(50,activation='relu'))\nmodel.add(Layers.Dropout(rate=0.5))\nmodel.add(Layers.Dense(6,activation='softmax'))\n\nmodel.compile(optimizer=Optimizer.Adam(lr=0.0001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n\nmodel.summary()\n\n\n","d74211ee":"# Dot representation of the model\nSVG(model_to_dot(model).create(prog='dot', format='svg'))\nUtils.plot_model(model,to_file='model.png',show_shapes=True)","5f1e35d4":"# Fitting the model    \/  Splitting model as %70 train and 30% validation set\ntrained = model.fit(Images,Labels,epochs=10,validation_split=0.30)","9bb76ca2":"# Plotting accuracy values of the train and validation sets\nplot.plot(trained.history['accuracy'])\nplot.plot(trained.history['val_accuracy'])\nplot.title('Model accuracy')\nplot.ylabel('Accuracy')\nplot.xlabel('Epoch')\nplot.legend(['Train', 'Test'], loc='upper left')\nplot.show()\n\n# Plotting loss values of the train and validation sets\nplot.plot(trained.history['loss'])\nplot.plot(trained.history['val_loss'])\nplot.title('Model loss')\nplot.ylabel('Loss')\nplot.xlabel('Epoch')\nplot.legend(['Train', 'Test'], loc='upper left')\nplot.show()","0794c135":"# Extract the Test images from folder\ntest_images,test_labels = get_images('\/kaggle\/input\/intel-image-classification\/seg_test\/seg_test\/') #Extract the training images from the folders.')\ntest_images = np.array(test_images)\ntest_labels = np.array(test_labels)","26888a3e":"# Evaluation of the test set\nmodel.evaluate(test_images,test_labels, verbose=1)","db065076":"# Plot confusion matrix \nimport matplotlib.pyplot as plt\n# Note: This code snippet for confusion-matrix is taken directly from the SKLEARN website.\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=30)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('Actual class')\n    plt.xlabel('Predicted class')","52bdcd9b":"import sklearn.metrics as metrics\nfrom collections import Counter\nimport itertools\n\nY_pred = model.predict(test_images)\nY_pred_classes = np.argmax(Y_pred, axis = 1) \n\nconfusion_matrix = metrics.confusion_matrix(y_true=test_labels, y_pred=Y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_matrix, classes = range(6))","152d4eb1":"# Plotting some images and their predicted values.\nfig = plot.figure(figsize=(30, 30))\nouter = gridspec.GridSpec(5, 5, wspace=0.2, hspace=0.2)\n\nfor i in range(25):\n    inner = gridspec.GridSpecFromSubplotSpec(2, 1,subplot_spec=outer[i], wspace=0.1, hspace=0.1)\n    rnd_number = randint(0,len(test_images))\n    pred_image = np.array([test_images[rnd_number]])\n    pred_class = get_classlabel(model.predict_classes(pred_image)[0])\n    pred_prob = model.predict(pred_image).reshape(6)\n    for j in range(2):\n        # It creates grid and set the image on the grid\n        if (j%2) == 0:\n            ax = plot.Subplot(fig, inner[j])\n            ax.imshow(pred_image[0])\n            ax.set_title(pred_class)\n            ax.set_xticks([])\n            ax.set_yticks([])\n            fig.add_subplot(ax)\n        # It shows the pred_prob's values on the bar plot below the related image    \n        else:\n            ax = plot.Subplot(fig, inner[j])\n            ax.bar([0,1,2,3,4,5],pred_prob)\n            fig.add_subplot(ax)\n\n\nfig.show()","77bc3f64":"# Extract the training images from folder","cf9d9ea6":"# CNN Model","89ce18b3":"# Evaluation of the Test Images\n"}}