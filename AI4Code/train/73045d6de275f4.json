{"cell_type":{"d7f609fd":"code","e97abb34":"code","2d61cc18":"code","744f8ffd":"code","503a9165":"code","5205e410":"code","c42e7d43":"code","c494b556":"code","ac181aa5":"code","31d110f2":"code","5d00399b":"code","9bf235f3":"code","e2ed3fba":"code","70f77678":"code","c65c7f75":"code","65b626a3":"code","13283c41":"code","781d00dc":"code","04800cbe":"code","242955f8":"code","bd0b7916":"code","0fe45647":"code","eac645ed":"code","e9aef670":"code","b859eced":"code","e954601a":"code","ec057f65":"code","c3bd320d":"code","8fd29f8f":"code","4a7fb27b":"code","bc23e519":"code","4cf6ddad":"code","54803fb2":"code","35fd516a":"code","f594af9b":"code","57734789":"code","089b39f5":"code","7875162d":"code","8d30fbb4":"code","7516e034":"code","06200899":"code","522a7aff":"code","eb7eacd6":"code","aa2a7580":"code","98c762c4":"code","e327b3e9":"code","acc938fa":"code","b087f0c1":"code","f58fd77b":"code","f20fcbc5":"code","f21134e5":"markdown","87db15b8":"markdown","3007f330":"markdown","2416570c":"markdown"},"source":{"d7f609fd":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")","e97abb34":"train = pd.read_csv('..\/input\/covid19-global-forecasting-week-2\/train.csv')\ntrain.info()","2d61cc18":"train.head()","744f8ffd":"train.tail()","503a9165":"train.describe()","5205e410":"train.corr()","c42e7d43":"train.isnull().sum()","c494b556":"test = pd.read_csv('..\/input\/covid19-global-forecasting-week-2\/test.csv')\ntest.info()","ac181aa5":"test.head()","31d110f2":"test.tail()","5d00399b":"test.describe()","9bf235f3":"test.isnull().sum()","e2ed3fba":"#Changing dtype for dates from object to datetime\ntrain['Date'] = pd.to_datetime(train['Date'])\ntest['Date'] = pd.to_datetime(test['Date'])","70f77678":"train[train['Province_State'].isnull()]['Country_Region'].unique()","c65c7f75":"train[train['Province_State'].notnull()]['Country_Region'].unique()","65b626a3":"train['Province_State'] = np.where(train['Province_State'].isnull(), train['Country_Region'], train['Province_State'])\ntest['Province_State'] = np.where(test['Province_State'].isnull(), test['Country_Region'], test['Province_State'])","13283c41":"train[train['Province_State'] == 'Diamond Princess']","781d00dc":"train[train['Province_State'] == 'Diamond Princess']['Country_Region'].unique()","04800cbe":"df = train.append(test)","242955f8":"group = df.groupby(['Province_State', 'Country_Region'])['Date'].count().reset_index()\ngroup","bd0b7916":"group[group['Province_State'].duplicated()]","0fe45647":"df[df['Province_State'] == 'Georgia']['Country_Region'].unique()","eac645ed":"#Distinguishing Province\/State Georgia according to Country\/Region\ndf['Province_State'] = np.where((df['Country_Region'] == 'Georgia') & (df['Province_State'] == 'Georgia'), \n                                'Country Georgia', df['Province_State'])","e9aef670":"#Viewing the total number of confirmeed cases and fatalities worldwide\nworld = train.groupby('Date')['ConfirmedCases', 'Fatalities'].sum().reset_index()\n\nplt.plot(world['Date'], world['ConfirmedCases'], label = 'Confirmed Cases')\nplt.plot(world['Date'], world['Fatalities'], label = 'Fatalities')\nplt.legend()\nplt.title('Total number of Confirmed Cases and Fatalities Worldwide')\nplt.xticks(rotation = 30)\nplt.show();","b859eced":"#Plotting the number of confirmed cases and fatalities for each country\ncountry = train.groupby('Country_Region')['ConfirmedCases', 'Fatalities'].sum().reset_index()\n\nfig = plt.figure(figsize = (15, 25))\nax = fig.add_subplot(111)\nax.barh(country['Country_Region'], country['ConfirmedCases'],label = 'Confirmed Cases')\nax.barh(country['Country_Region'], country['Fatalities'],label = 'Fatalities')\nax.legend()\nax.set_title('Total Confirmed Cases and Fatalities by Country');","e954601a":"#Viewing the top 15 countries with the most confirmed cases\nranked = country.sort_values(by = 'ConfirmedCases', ascending = False)[:15]\nranked","ec057f65":"#Plotting confirmed cases and fatalities for the 15 countries with the most cases\ncountries = ['China', 'Italy', 'US', \n             'Spain', 'Germany', 'Iran', \n             'France', 'Korea, South', 'United Kingdom', \n             'Switzerland', 'Netherlands', 'Belgium', \n             'Austria', 'Turkey', 'Canada']\n\nfor c in countries:\n    group = train[train['Country_Region'] == c].groupby('Date')['ConfirmedCases', 'Fatalities'].sum().reset_index()\n    group['ConfirmedCases'].plot(label = 'Confirmed Cases')\n    group['Fatalities'].plot(label = 'Fatalities')\n    plt.legend()\n    plt.title(c)\n    plt.show();","c3bd320d":"from statsmodels.tsa.seasonal import seasonal_decompose\n\ndef trends(country, case):\n    group = train[train['Country_Region'] == country].groupby('Date')['ConfirmedCases', 'Fatalities'].sum().reset_index()\n    decomposition = seasonal_decompose(group[case], freq = 3)\n    trend = decomposition.trend\n    seasonal = decomposition.seasonal\n    residual = decomposition.resid\n    \n    plt.subplot(411)\n    plt.plot(group[case], label= case)\n    plt.legend(loc='best')\n    plt.title('Original')\n    plt.subplot(412)\n    plt.plot(trend, label=case)\n    plt.legend(loc='best')\n    plt.title('Trend')\n    plt.subplot(413)\n    plt.plot(seasonal,label=case)\n    plt.legend(loc='best')\n    plt.title('Seasonality')\n    plt.subplot(414)\n    plt.plot(residual, label=case)\n    plt.legend(loc='best')\n    plt.title('Residual')\n    plt.tight_layout();","8fd29f8f":"trends('China', 'ConfirmedCases')","4a7fb27b":"trends('China', 'Fatalities')","bc23e519":"trends('Italy', 'ConfirmedCases')","4cf6ddad":"trends('Italy', 'Fatalities')","54803fb2":"trends('US', 'ConfirmedCases')","35fd516a":"trends('US', 'Fatalities')","f594af9b":"from statsmodels.tsa.stattools import adfuller\ndef stationarity_test(country, case):\n    timeseries = train[train['Country_Region'] == country].groupby('Date')['ConfirmedCases', 'Fatalities'].sum().reset_index()\n    #Perform Dickey-Fuller test:\n    print('Results of Dickey-Fuller Test:')\n    dftest = adfuller(timeseries[case], autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value',\n                                             '#Lags Used',\n                                             'Number of Observations Used'])\n    for key,value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key] = value\n    print (dfoutput)","57734789":"stationarity_test('US', 'ConfirmedCases')","089b39f5":"from statsmodels.tsa.arima_model import ARIMA\nfrom sklearn.metrics import mean_squared_error","7875162d":"def comb_p_d_q(pVals,dVals,qVals):\n    return [(p,d,q) for p in pVals for d in dVals for q in qVals]","8d30fbb4":"#List of combinations for pdq \npdq_results = comb_p_d_q([0,1,2],[0,1,2],[0,1,2])\npdq_results","7516e034":"df.drop_duplicates(subset = ['Date', 'Province_State'], keep = 'last', inplace = True)","06200899":"#Finding the best pdq combination using aic\ndef aic_finder(province, case):\n    train_df = df[df['Province_State'] == province][:70]\n    a = 9999\n    \n    for pdq in pdq_results:\n        try:\n            model = ARIMA(train_df[case], order = pdq, dates = train_df['Date'], freq = 'D')\n            model_fit = model.fit()\n            aicval = model_fit.aic\n            \n            if aicval < a:\n                a = aicval\n                param = pdq\n                print(param, a)\n        except:\n            pass","522a7aff":"aic_finder('Switzerland', 'ConfirmedCases')","eb7eacd6":"from statsmodels.tsa.arima_model import ARIMA","aa2a7580":"def model_eval(case):\n    state = ['Italy']\n    for s in state:\n        train_ts = train[train['Province_State'] == s][:50]\n        test_ts = train[train['Province_State'] == s][50:]\n        a = 9999\n        \n        for pdq in pdq_results:\n            try:\n                model = ARIMA(train_ts[case], order = pdq, dates = train_ts['Date'], freq = 'D')\n                model_fit = model.fit()\n                aicval = model_fit.aic\n            \n                if aicval < a:\n                    a = aicval\n                    param = pdq\n            except:\n                pass\n        \n        model = ARIMA(train_ts[case], order = param, dates = train_ts['Date'], freq = 'D')\n        model_fit = model.fit()\n        model_fit.plot_predict(start = int(len(train_ts) * 0.3), end = int(len(train_ts) * 1.4))\n        pred = model_fit.forecast(steps = int(len(test_ts)))[0]\n            \n        ","98c762c4":"model_eval('ConfirmedCases')","e327b3e9":"model_eval('Fatalities')","acc938fa":"def model(case):\n    state = df['Province_State'].unique()\n    confirmed = []\n    for s in state:\n        train_ts = df[df['Province_State'] == s][:57]\n        pred_ts = df[df['Province_State'] == s][57:]\n        a = 9999\n        \n        for pdq in pdq_results:\n            try:\n                model = ARIMA(train_ts[case], order = pdq, dates = train_ts['Date'], freq = 'D')\n                model_fit = model.fit()\n                aicval = model_fit.aic\n            \n                if aicval < a:\n                    a = aicval\n                    param = pdq\n            except:\n                pass\n        \n        try:\n            model = ARIMA(train_ts[case], order = param, dates = train_ts['Date'], freq = 'D')\n            model_fit = model.fit()\n            pred = model_fit.forecast(steps = int(len(pred_ts)))[0]\n            confirmed = np.append(confirmed, pred.tolist())\n        except:\n            confirmed = np.append(confirmed, np.repeat(0, 43))\n            continue\n            \n    test[case] = confirmed","b087f0c1":"model('ConfirmedCases')","f58fd77b":"model('Fatalities')","f20fcbc5":"results = test[['ForecastId', 'ConfirmedCases', 'Fatalities']]\nresults.to_csv('submission.csv', index = False)","f21134e5":"### Importing training data","87db15b8":"### Importing test data","3007f330":"### Data exploration","2416570c":"# COVID-19 Global Forecasting Week 2"}}