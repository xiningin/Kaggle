{"cell_type":{"a2cfce71":"code","82a457ea":"code","af6263f8":"code","7c7c140a":"code","07917cc5":"code","087d086b":"code","036777ff":"code","07f53c94":"code","31473aac":"code","9043df76":"code","f3e7a670":"code","426d9a8d":"code","84907964":"code","9205847a":"code","b993f8cc":"code","bc766d1b":"code","7e892117":"code","b78d8bc8":"code","2fbc509e":"code","57f5dac8":"code","95f00a11":"code","641af570":"code","6b6d72b2":"code","292245db":"code","f2f84e23":"code","ade058f3":"code","c9f513b3":"code","887c74b1":"code","19abcb28":"code","ccf5d165":"code","d66d8d60":"code","ff99acac":"code","af33f2b7":"markdown","d28aef7b":"markdown","4a8fe0d5":"markdown","07e08cb4":"markdown","96e59678":"markdown","6cdc96cd":"markdown","45e5285a":"markdown","e8547851":"markdown","53cc84ed":"markdown","f537cbef":"markdown","1bd71062":"markdown","36844081":"markdown","ce7adacf":"markdown","ecba0178":"markdown","46cc871a":"markdown","dca7ae0c":"markdown","adb099e1":"markdown","cd0d8e2a":"markdown","a75b4e94":"markdown","571ac702":"markdown","880c748f":"markdown","4a34fc6e":"markdown","7ebfcc0f":"markdown","49a75887":"markdown","7dd39532":"markdown","194bc2e4":"markdown","60fceed9":"markdown","092e7ba0":"markdown"},"source":{"a2cfce71":"!pip install opencv-contrib-python\nimport cv2\n!pip install imutils\nimport imutils\nimport math\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\nimport os","82a457ea":"lena = r\"\/kaggle\/input\/opencv-samples-images\/data\/lena.jpg\"\nchessboard = r\"\/kaggle\/input\/opencv-samples-images\/data\/chessboard.png\"\nminnions = r\"\/kaggle\/input\/opencv-samples-images\/minions.jpg\"\ntempl = r\"\/kaggle\/input\/opencv-samples-images\/data\/templ.png\"\nblob= r\"\/kaggle\/input\/opencv-samples-images\/data\/detect_blob.png\"\nbasketball = r\"\/kaggle\/input\/opencv-samples-images\/data\/basketball2.png\"\ncoffee = r\"\/kaggle\/input\/operations-with-opencv\/coffee.jpg\"\nfruits = r\"\/kaggle\/input\/opencv-samples-images\/data\/fruits.jpg\"\nmotion= r\"\/kaggle\/input\/opencv-samples-images\/data\/text_motion.jpg\"\ncoridor = r\"\/kaggle\/input\/computer-vision-course\/imagenes\/corridor.jpg\"\nmit2 =  r\"\/kaggle\/input\/computer-vision-course\/imagenes\/car.jpg\"\nhand = r\"\/kaggle\/input\/opencv-samples-images\/hand.jpg\"","af6263f8":"contour_image = cv2.imread(templ )\ncontour_image = cv2.cvtColor(contour_image, cv2.COLOR_BGR2GRAY)\nfigure(figsize=(18,16), dpi=30)\nplt.imshow(contour_image,cmap=\"gray\")","7c7c140a":"canny = cv2.Canny(contour_image , 120, 255)        \ncontours, hier = cv2.findContours(canny, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\ncenter_moments= cv2.moments(contours[0])\nprint(center_moments)","07917cc5":"x_centroid = int(center_moments[\"m10\"]\/center_moments[\"m00\"])\ny_centroid = int(center_moments[\"m01\"]\/center_moments[\"m00\"])\nprint( \"x coordinate of the centroid is {}, and y coordinate of the centroid is {}\".format(x_centroid, y_centroid))\ncv2.circle( contour_image, (x_centroid, y_centroid), 5, (255,0,0), -1 )\nfigure(figsize=(18,16), dpi=30)\nplt.imshow(contour_image,cmap=\"gray\")","087d086b":"image1 = cv2.imread(blob)\nimage1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\nimage2=cv2.imread(blob)\nimage2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\nim1=cv2.imread(blob)\nim1 = cv2.cvtColor(im1, cv2.COLOR_BGR2RGB)\n\n\nprint(\"shape is: {}\".format(image1.shape))\nim = image1 #back-up \nw,h,c = image1.shape #shape of the numpy array \nfigure(figsize=(18,16), dpi=30)\nplt.imshow(image1)","036777ff":"black = np.zeros((w,h,c)) #Creating a black image in the shape of original input image for the masking issues\nimage1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)","07f53c94":"blur = cv2.medianBlur(image1,5)\nedged = cv2.Canny(blur,10, 150)\n\nfigure(figsize=(18,16), dpi=30)\nplt.imshow(edged,cmap=\"gray\")","31473aac":"contours, hier= cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL,  cv2.CHAIN_APPROX_SIMPLE)\nprint(\"{} contours have been detected\".format(len(contours)))\n\nfigure(figsize=(18,16), dpi=30)\ncv2.drawContours(black,contours,-1, (255,0,0),3 )\nplt.imshow(black,cmap=\"gray\")\nprint(\"Number of detected contours :\",len(contours))","9043df76":"contours, hier= cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL,  cv2.CHAIN_APPROX_SIMPLE)\nprint(\"{} contours have been detected\".format(len(contours)))\n\nfigure(figsize=(18,16), dpi=30)\ncv2.drawContours(im,contours,-1, (255,0,0),3)\nplt.imshow(im, cmap=\"gray\")","f3e7a670":"def contour_areas(contours): #Function calculates contour areas and creates a list of the areas with respect to the contours.\n    area =[]\n    for _ in contours:\n        area.append( cv2.contourArea(_) )    \n    return area   \n\nareas = contour_areas(contours)\nprint(\"The areas are {} pixel square\".format(areas))","426d9a8d":"img = im1 #duplicate the GRAY SCALE image\nsorted_areas = sorted ( contours ,key=contour_areas, reverse = True ) #From largest to smallest","84907964":"figure(figsize=(18,16), dpi=30)\ncv2.drawContours(img,[sorted_areas[0]] ,-1, (255,0,0),3)\nprint(\"The Largest Area Has been Drown\")\nplt.imshow(img)","9205847a":"img2 = image2.copy()\n#We will get X coordinates by this function\ndef sort_loc2(contours):\n\n    center_moments = cv2.moments(contours)\n        \n    return ( int(center_moments[\"m10\"]\/center_moments[\"m00\"]) )\n","b993f8cc":"#We will find the centroid of the contour by this function\n\ndef centroid_loc(img , centroid):\n    center_moments = cv2.moments(centroid)\n    \n    x_centroid = int(center_moments[\"m10\"]\/center_moments[\"m00\"])\n    y_centroid = int(center_moments[\"m01\"]\/center_moments[\"m00\"])\n    \n    cv2.circle( img, (x_centroid, y_centroid), 10, (255,0,0), -1 )\n    \n    return img","bc766d1b":"spatial_sort = sorted( contours, key=sort_loc2, reverse = False  )\n\nfor (i,j) in enumerate(spatial_sort):\n    centre = centroid_loc(img , j)\n\nfigure(figsize=(18,16), dpi=30)\nplt.imshow(img)","7e892117":"for (i,j) in enumerate(spatial_sort):\n    cv2.drawContours(image2, [j] , -1, (255,0,0), 3)\n    center_moments = cv2.moments(j)\n    x_centroid = int(center_moments[\"m10\"]\/center_moments[\"m00\"])\n    y_centroid = int(center_moments[\"m01\"]\/center_moments[\"m00\"])\n    num = str ( i+1 )\n    cv2.putText(image2, num, (x_centroid, y_centroid), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,255) ,2)\n    \n\nfigure(figsize=(18,16), dpi=30)\nplt.imshow(image2)    ","b78d8bc8":"contour = cv2.imread(templ)\ncontour= cv2.cvtColor(contour, cv2.COLOR_BGR2GRAY)\n\ncanny = cv2.Canny(contour , 120, 255)        \ncontours, hier = cv2.findContours(canny, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)","2fbc509e":"#You Can Draw a Rectangular over the Contour by:\n(x,y,w,h)= cv2.boundingRect(contours[0])\ncv2.rectangle( contour, (x,y), (x+w, y+h), (0,220,225),2)\nfigure(figsize=(18,16), dpi=30)\nplt.imshow(contour,cmap=\"gray\")    ","57f5dac8":"contour = cv2.imread(hand)\ncontour= cv2.cvtColor(contour, cv2.COLOR_BGR2GRAY)\n\n_,thresh = cv2.threshold(contour , 233, 255,cv2.THRESH_BINARY_INV)   \n\ncontours, hier = cv2.findContours(thresh , cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)","95f00a11":"w,h=contour.shape\nblack1 = np.zeros((w,h)) \nfigure(figsize=(18,16), dpi=30)\ncv2.drawContours(black1,contours,-1, (255,0,0),3 )\nplt.imshow(black1,cmap=\"gray\")\nprint(\"Number of detected contours :\",len(contours))","641af570":"chull = cv2.imread(hand)\nchull= cv2.cvtColor(chull, cv2.COLOR_BGR2GRAY)\n\n_,thresh = cv2.threshold(chull , 230, 255,cv2.THRESH_BINARY_INV)        \ncontours, hier = cv2.findContours(thresh , cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n\nhull = cv2.convexHull( contours[0])","6b6d72b2":"w,h=contour.shape\nblack2 =black1.copy()\nfigure(figsize=(18,16), dpi=30)\ncv2.drawContours(black2,[hull],0, (255,0,0),3 )\nplt.imshow(black2,cmap=\"gray\")\nprint(\"Number of detected contours :\",len(contours))","292245db":"imdic = [ black1, black2]\ntitles = [ \"contour\", \"hull\"]\nfigure(figsize=(18,16), dpi=40)\n\nfor i in range(2):\n    plt.subplot(1,2,i+1), plt.imshow(imdic[i], \"gray\")\n    plt.title(titles[i])\n    plt.xticks([]), plt.yticks([])\nplt.show()","f2f84e23":"hand_raw = cv2.imread(hand)\nhand_raw = cv2.cvtColor(hand_raw, cv2.COLOR_BGR2GRAY)\nh,w=hand_raw.shape\nprint(hand_raw.shape)\nplt.imshow(hand_raw,cmap=\"gray\")","ade058f3":"_,thresh = cv2.threshold(hand_raw  , 230, 255,cv2.THRESH_BINARY_INV)    \ncontours, _ = cv2.findContours(thresh , cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\nblack3= np.zeros((w+150,h+150)) \nhand_manup = cv2.drawContours(black3,[contours[0]],0, (255,255,255),3 )\nhand_manup=hand_manup.astype(np.uint8)\nplt.imshow(hand_manup,cmap=\"gray\")","c9f513b3":"hand_scaled = cv2.resize(hand_manup , (int(h\/2),int(w\/2)), interpolation = cv2.INTER_AREA)\n_,hand_scaled = cv2.threshold(hand_scaled , 130, 255, cv2.THRESH_BINARY) \nhand_scaled=hand_scaled.astype(np.uint8)\n\nhand_translation = cv2.warpAffine(hand_manup  , np.float32([[1,0,100],[0,1,50]]), (w*2,h*2))\n_,hand_translation  = cv2.threshold(hand_translation  , 130, 255, cv2.THRESH_BINARY) \nhand_translation=hand_translation.astype(np.uint8)\n\nhand_rotated = imutils.rotate_bound(hand_manup , -33)\n_,hand_rotated = cv2.threshold(hand_rotated , 130, 255, cv2.THRESH_BINARY) \nhand_rotated=hand_rotated.astype(np.uint8)\n\nimdic = [ hand_manup, hand_scaled,hand_translation,hand_rotated ]\ntitles = [ \"original\",\"Scaled\",\"Scaled & Translation\", \"Scaled & Rotated\"]\nfigure(figsize=(18,16), dpi=50)\n\nfor i in range(4):\n    plt.subplot(2,2,i+1), plt.imshow(imdic[i], \"gray\")\n    plt.title(titles[i])\n    plt.xticks([]), plt.yticks([])\nplt.show()\n","887c74b1":"print(np.unique(hand_manup),\n      np.unique(hand_scaled),\n      np.unique(hand_translation),\n      np.unique(hand_rotated))\n\nprint((hand_manup.shape),\n      (hand_scaled.shape),\n      (hand_translation.shape),\n      (hand_rotated.shape))","19abcb28":"AR= []\nfor img in imdic:\n    (x,y,w,h)= cv2.boundingRect(img)\n    aspect_ratio = float ( w \/ h)\n    AR.append(aspect_ratio)\n\nprint(\"Aspect Ratio of Original Shape is {}\".format(AR[0]))\nprint(\"Aspect Ratio of Scaled is {}\".format(AR[1]))\nprint(\"Aspect Ratio of Scaled & Translation Shape is {}\".format(AR[2]))\nprint(\"Aspect Ratio of Scaled & Rotated Shape is {}\".format(AR[3]))","ccf5d165":"center_moments= cv2.moments(hand_raw)\nhu_mom = cv2.HuMoments(center_moments)\nprint(hu_mom)","d66d8d60":"Hu_mom= []\nfor img in imdic:    \n    cm = cv2.moments(img)\n    hum = cv2.HuMoments(cm)\n    Hu_mom.append(hum)\n","ff99acac":"imdic = [ hand_manup, hand_scaled,hand_translation,hand_rotated ]\nL2_1 = cv2.matchShapes(hand_manup,hand_scaled,cv2.CONTOURS_MATCH_I2,0)\nL2_2 = cv2.matchShapes(hand_manup,hand_translation,cv2.CONTOURS_MATCH_I2,0)\nL2_3 = cv2.matchShapes(hand_manup,hand_rotated,cv2.CONTOURS_MATCH_I2,0)\nprint(\"the distance of scaling:\",L2_1 )\nprint(\"the distance of scaling and translation:\",L2_2)\nprint(\"the distance of scaling and rotation:\",L2_3)","af33f2b7":"Even the length or area will certainly change due to translation, rotation and scaling, the aspect ratio which is nothing but thre ratio of the width to height of the object will remain same under the curcumcitations that object would not tilted from the centroid. (Valid for only 2D movement)","d28aef7b":"Hull means the exterior or the shape of the object.The Convex Hull of a shape or a group of points is a tight fitting convex boundary around blob.\n\n","4a8fe0d5":"## ****$\\color{orange}{\\text{Section 4.1 Aspect Ratio }}$**** <a class=\"anchor\"  id=\"section4_1\"><\/a>\n","07e08cb4":"# Chapter 1. Image Moments <a class=\"anchor\" id=\"chapter1\"><\/a>","96e59678":"### ****$\\color{orange}{\\text{If You want to be an AI Expert, Knowing Deep learning is never enough alone!}}$****\n\n### $\\color{Pink}{\\text{Table of Contents  }}$\n\n* [Chapter 1. Image Moments](#chapter1)     \n* [Chapter 2. Sorting the Contours](#chapter2)\n    * [Section 2.1 Sorting by Area ](#section2_1)\n    * [Section 2.2 Sorting by Location ](#section2_2)\n* [Chapter 3. Drawing a Rectangle & Convex Hull over the Contour](#chapter3)\n    * [Section 3.1 Drawing a Rectangle ](#section3_1)\n    * [Section 3.2 Drawing a Convex Hull ](#section3_2)\n* [Chapter 4. Invariant Contour Propoerties](#chapter4)\n    * [Section 4.1 Aspect Ratio ](#section4_1)\n    * [Section 4.2 Hu Moments ](#section4_2)\n\n\n   \n    \n\n****$\\color{pink}{\\text{If You like my work, Please upvote  }}$****\n","6cdc96cd":"Now we have 4 different pics, lets see if some properties remain same after those operations","45e5285a":"When we think of certain shape the objects, most of the properties will be change when the object is rotated, shifted or scaled which means the 3D movement (x,y,z) of the object in real life. This movements will change the properties of area, moments etc. However, there are some properties which are totally invariant of 3D movement!! This will help us to find the objects in real life scenerios.","e8547851":"We have studied cv2.findContours() function in part 2. It finds the contours according to the parameters that we state. Another topic we may interest is sorting the contours after finding it. In some applications such object detection, face detection or measurement, finding the related contours is a need. Soo that, sorting is an important issue to dive deeply.\n\nWe can sort the contours by two ways:\n\n* Sorting by area\n* Sorting by location\n\nSorting by area is useful when you are interested in medium-large parts you want to extract from the image or small contours to noise elimination. Sorting by spatial poision helps us to sort the contours left to right or top to bottom.","53cc84ed":"The centroid of an shape is basically the weighted center of the shape blob in the image. Mathamatically speaking, it is the arithmetic mean of the pixels in the shape.\n\n![centroid.png](attachment:f99c67b9-2184-4fa4-81ae-cf2a84eb4bcc.png)\n\nImage Moment is a particular weighted average of image pixel values. By the help of using first moments ratios we can find the x and y coordinate of the centroid. By following formulas:\n\nThe centroid is given by the formula:\n\n![cx.png](attachment:d9003542-4b0c-4771-b406-c39dd6707cf8.png)\n\n![cy.png](attachment:14ef3b00-57f3-4f7a-934a-4b27b8e60be5.png)\n\nFinding the centroid and the coordinates of the shapes helps us to sort the images by their centroid's coordinates. For clean iamges, it helps a lot to gather the desired feature for problem solving reasons.","f537cbef":"****$\\color{pink}{\\text{Conclusion of Invariant Features}}$****\n\nAs you can see, the hu moments of the original image and the manupulated images are really close to each others. The shape matching algorithm is also gives a L2 ( squared root distance ) of the similarities to each other. That means ** hu moments** are scale-translation-rotation invariant properties. So we can use it for searching a common objecte that we know hu moments in object detection\n\n![humoments.PNG](attachment:9bd45761-792f-4df2-958d-def00deb97cf.PNG)","1bd71062":"## ****$\\color{orange}{\\text{Section 2.1 Sorting Contours by the Area}}$**** <a class=\"anchor\"  id=\"section2_1\"><\/a>\n\n\n\nFinding the area in a binary image is just counting the non zero pixels!! Below function calculates the area of the contours.\n\n>cv2.contourArea( contours ) ","36844081":"sorted_areas[0] means the contour which has the largest area.","ce7adacf":"****$\\color{pink}{\\text{Conclusion of Convex Hull}}$****\n\nHull is an exterior boundry over a contour. Sometimes the contour is not an enough feature for classification or detection. Plus, unlikely to contours, Hull gives a known geometric shape enclose the object or contour.","ecba0178":"![3.png](attachment:8f822733-fae6-4062-8499-49d511d4e961.png)","46cc871a":"# Chapter 3. Drawing a Rectangle & Convex Hull over the Contour <a class=\"anchor\" id=\"chapter3\"><\/a>","dca7ae0c":"\n## ****$\\color{orange}{\\text{Section 3.1 Drawing a Rectangle Box over the Contour}}$**** <a class=\"anchor\"  id=\"section3_1\"><\/a>","adb099e1":"# Chapter 4. Invariant Contour Properties <a class=\"anchor\" id=\"chapter3\"><\/a>","cd0d8e2a":"# Introduction\n\nHi everyone! We continue to deep dive to image processing with OpenCV for Computer Vision, it is a long notebook so keep in tune. If you missed the first two parts, you are welcome to reach from here :\n\n* Lesson 1: [OpenCV for Computer Vision 1 - Beginner](https:\/\/www.kaggle.com\/volkandl\/opencv-for-computer-vision-1-beginner)\n* Lesson 2: [OpenCV for Computer Vision 2 - intermediate](https:\/\/www.kaggle.com\/volkandl\/opencv-for-computer-vision-2-intermediate)\n\n\nLast time we found contours of the blobs in an image by using below mentioned opencv function and check the internal and external contours.\n\n>contours, hier = cv2.findContours(canny, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n\nIn this notebook we will continue with the contours since they are one of the basic features for image processing. I will briefly summarize how we can sort the contours and how to detect the objects by invariant contour properties. Give an upvote if you enjoy! ","a75b4e94":"OpenCV function helps us to find moments:\n>cv2.moments(contour)\n\n","571ac702":"We can gather the coordinates and draw a bounding box over the contour we find. Below we will find the  contour and draw a rectangle over it.","880c748f":"\n\n## ****$\\color{orange}{\\text{Section 2.2 Sorting Contours by the Location}}$**** <a class=\"anchor\"  id=\"section2_2\"><\/a>\n\nWe will sort the contours according to spatial locations. We will use the help of moments function.\n>cv2.moments ( contours ) ","4a34fc6e":"OpenCV provides an easy to use a utility function called matchShapes that takes in two images ( or contours ) and finds the distance between them using Hu Moments. If the result is close to 0, then the two images or contours are matched. The function is using L2 distance to decide the similarity with using HU moments.\n\n>cv2.matchShapes(image1, image2, cv2.CONTOURS_MATHC_I2,0)","7ebfcc0f":"# Chapter 2. Sorting the Contours <a class=\"anchor\" id=\"chapter2\"><\/a>","49a75887":"As you can see, cv2.moments() function returns a dictionary increase lots of values starting \n\n* Spatial moments m00, m01, m10 as first order moments and m11, m20,m02 and the rest as higher order moments.\n* Central moments mu20, mu11, mu02 and higher orders moments\n* central normalized moments nu20, nu11, nu02 and higher order moments\n\nAll moments are calculated with Green's theorem. It states the integral form of finding areas. For further read : https:\/\/en.wikipedia.org\/wiki\/Green%27s_theorem","7dd39532":"****$\\color{pink}{\\text{Contour Sorting}}$****\n\nContours are the basic features of the objects. As the very early step of object detection in computer vision history starts with contour finding and its specialities. By finding its area or spatial position we can detect or divide them in an image.","194bc2e4":"****$\\color{pink}{\\text{Moments}}$****\n\nMoments help us to find specific points of a blob in an image such as centroid location. The math behind it is simple and very similar to physics. As you can see , we find the centroid of an contour and put a circle to that point.","60fceed9":"## ****$\\color{orange}{\\text{Section 4.2 Hu Moments}}$**** <a class=\"anchor\"  id=\"section4_2\"><\/a>\n\nHu moments are 7 different moments which are derived six absolute orthogonal invariants and one skew orthogonal invariant based upon algebraic invariants,Hu moments are invariant to rotation, translation and scaling! However,hu moments are not enough for shape matching.\n\n*[1] Zhihu Huang, ; Jinsong Leng, (2010). [IEEE 2010 2nd International Conference on Computer Engineering and Technology - Chengdu, China (2010.04.16-2010.04.18)] 2010 2nd International Conference on Computer Engineering and Technology - Analysis of Hu's moment invariants on image scaling and rotation. , (), V7-476\u2013V7-480. doi:10.1109\/iccet.2010.5485542 *\n\n\n*[2] image is taken from:  https:\/\/learnopencv.com\/shape-matching-using-hu-moments-c-python\/*\n\n","092e7ba0":"## ****$\\color{orange}{\\text{Section 3.2 Drawing a Convex Hull over the Contour}}$**** <a class=\"anchor\"  id=\"section3_2\"><\/a>"}}