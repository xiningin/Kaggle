{"cell_type":{"91b7f9ea":"code","0970cdbf":"code","3f09bc88":"code","1303d431":"code","7b183877":"code","43278425":"code","9a7f9ba6":"code","84a730f9":"code","b1e527a5":"code","13cc95d9":"code","2f223af2":"code","ba320046":"code","fa75a2f3":"markdown","059e8944":"markdown"},"source":{"91b7f9ea":"# Read in the document-term matrix\nimport pandas as pd\n\ndata = pd.read_pickle('dtm.pkl')\ndata = data.transpose()\ndata.head()","0970cdbf":"# Find the top 30 words said by each politician\ntop_dict = {}\nfor p in data.columns:\n    top = data[p].sort_values(ascending=False).head(30)\n    top_dict[p]= list(zip(top.index, top.values))\n\ntop_dict","3f09bc88":"# Print the top 15 words said by each politician\nfor politician, top_words in top_dict.items():\n    print(politician)\n    print(', '.join([word for word, count in top_words[0:14]]))\n    print('---')","1303d431":"# Look at the most common top words --> add them to the stop word list\nfrom collections import Counter\n\n# Let's first pull out the top 30 words for each comedian\nwords = []\nfor politician in data.columns:\n    top = [word for (word, count) in top_dict[politician]]\n    for t in top:\n        words.append(t)\n        \nwords","7b183877":"# Let's aggregate this list and identify the most common words along with how many routines they occur in\nCounter(words).most_common()","43278425":"# If more than half of the politicians have it as a top word, exclude it from the list\nadd_stop_words = [word for word, count in Counter(words).most_common() if count > 4]\nadd_stop_words","9a7f9ba6":"# Let's update our document-term matrix with the new list of stop words\nfrom sklearn.feature_extraction import text \nfrom sklearn.feature_extraction.text import CountVectorizer\n\n# Read in cleaned data\ndata_clean = pd.read_pickle('data_clean.pkl')\n\n# Add new stop words\nstop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)\n\n# Recreate document-term matrix\ncv = CountVectorizer(stop_words=stop_words)\ndata_cv = cv.fit_transform(data_clean.speeches)\ndata_stop = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\ndata_stop.index = data_clean.index\n\n# Pickle it for later use\nimport pickle\npickle.dump(cv, open(\"cv_stop.pkl\", \"wb\"))\ndata_stop.to_pickle(\"dtm_stop.pkl\")","84a730f9":"# Let's make some word clouds!\nfrom wordcloud import WordCloud\n\nwc = WordCloud(stopwords=stop_words, background_color=\"white\", colormap=\"Dark2\",\n               max_font_size=150, random_state=42)","b1e527a5":"# Reset the output dimensions\nimport matplotlib.pyplot as plt\n\nplt.rcParams['figure.figsize'] = [16, 6]\n\nfull_names= ['Al Gore Jr','Bill Clinton','Michael Bloomberg','George W Bush','Susan Collins', 'Rudy Giuliani','Hilary Clinton', 'Barack Obama','Condolezza Rice','Mitt Romney']\n\n\n# Create subplots for each comedian\nfor index, politician in enumerate(data.columns):\n    wc.generate(data_clean.speeches[politician])\n    \n    plt.subplot(3, 4, index+1)\n    plt.imshow(wc, interpolation=\"bilinear\")\n    plt.axis(\"off\")\n    plt.title(full_names[index])\n    \nplt.show()","13cc95d9":"# Find the number of unique words that each politician uses\n\n# Identify the non-zero items in the document-term matrix, meaning that the word occurs at least once\nunique_list = []\nfor politician in data.columns:\n    uniques = data[politician].to_numpy().nonzero()[0].size\n    unique_list.append(uniques)\n\n# Create a new dataframe that contains this unique word count\ndata_words = pd.DataFrame(list(zip(full_names, unique_list)), columns=['politician', 'unique_words'])\ndata_unique_sort = data_words.sort_values(by='unique_words')\ndata_unique_sort","2f223af2":"# Find the total number of words that a politician uses\ntotal_list = []\nfor politician in data.columns:\n    totals = sum(data[politician])\n    total_list.append(totals)\n    \n\n# Let's add some columns to our dataframe\ndata_words['total_words'] = total_list\n\ndata_wpm_sort = data_words.sort_values(by='unique_words')\ndata_wpm_sort\n\n","ba320046":"# Let's plot our findings\nimport numpy as np\n\ny_pos = np.arange(len(data_words))\n\nplt.subplot(1, 2, 1)\nplt.barh(y_pos, data_unique_sort.unique_words, align='center')\nplt.yticks(y_pos, data_unique_sort.politician)\nplt.title('Number of Unique Words', fontsize=20)\n\n\nplt.tight_layout()\nplt.show()","fa75a2f3":"## Most Common Words","059e8944":"# Number of Words"}}