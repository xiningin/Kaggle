{"cell_type":{"9d9724e7":"code","5b87bf62":"code","b8a56299":"code","1b49272a":"code","5d686b9a":"code","85cdfdc5":"code","c9f026bc":"code","c591e2d0":"code","d69b1bed":"code","0f0d1f4a":"code","024b957b":"code","495d357b":"code","81412610":"code","d6537fc6":"code","5c847851":"code","d2e4589e":"code","e106f450":"code","25dccff7":"code","f8903e40":"code","65d29dea":"code","dbd914ae":"code","39ed129f":"code","5db9d051":"code","0917d06c":"code","98577f31":"code","4ac82ad6":"code","6ab059a1":"code","c27c9214":"code","6e57882b":"code","bd827ae2":"code","75703d20":"markdown","ef057ac8":"markdown","5f046bcb":"markdown","aa0847eb":"markdown","77258004":"markdown","17d7da01":"markdown","9660e912":"markdown","60753298":"markdown","f4ea3af8":"markdown","7dd9d81b":"markdown","c626d687":"markdown","29925b80":"markdown","2180bd71":"markdown","1bf06444":"markdown","3a8c6d8c":"markdown","864c930f":"markdown","d8d006c3":"markdown","cbec8e72":"markdown","356a49bc":"markdown"},"source":{"9d9724e7":"# Packages I'm always using \nimport numpy as np \nimport pandas as pd \nimport glob \nimport matplotlib.pyplot as plt \nimport matplotlib.image as img \nimport time\n\n# sklearn tools \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.experimental import enable_hist_gradient_boosting\n\n# function\ndef rms(y1, y2):\n    return np.sqrt(np.sum( (y1-y2)**2)\/len(y1))\n\n\n### Plot style   (you can use seaborn  or some other plotting tool)\ndef plotstyle():\n    plt.xlabel('xlabel',  fontsize = 20)\n    plt.ylabel('ylabel',  fontsize = 20)\n\n    plt.xticks(size=18)\n    plt.yticks(size=18)\n    \n    \ndef axstyle(ax):\n    ax.set_xlabel('xlabel',  fontsize = 20)\n    ax.set_ylabel('ylabel',  fontsize = 20)\n\n    ax.tick_params(axis='x', labelsize=20)\n    ax.tick_params(axis='y', labelsize=20)","5b87bf62":"# Take a look \npath = '\/kaggle\/input\/petfinder-pawpularity-score\/'\ntrain_dat = pd.read_csv(path+'train.csv')\ntest_dat = pd.read_csv(path+'test.csv')\n\nprint(f\" training data size =  {len(train_dat)}\" )\n\ntrain_dat.head(3) ","b8a56299":"test_dat.head(3) ","1b49272a":"## Getting the image using matplotlib.image.imread \nt1 = path + 'train\/' + train_dat.Id[0] +'*'\nf1 = glob.glob(t1)[0]\nim1 = img.imread(f1) \n\nt2 = path + 'test\/' + test_dat.Id[0] +'*'\nf2 = glob.glob(t2)[0]\nim2 = img.imread(f2) \n\n## plot the figure \nfig = plt.figure( figsize = (15, 6))\nax1 = fig.add_subplot(121)\nax2 = fig.add_subplot(122)\n\nax1.imshow(im1)\nax2.imshow(im2)\ntitle1 = f'score = {train_dat.Pawpularity[0]}'\ntitle2 = f'test image'\nax1.set_title(title1, fontsize=15)\nax2.set_title(title2, fontsize=15)\n\nplt.show()","5d686b9a":"# histogram of the score:\nscore = train_dat.Pawpularity\n\nprint(f\" std of the score = {np.std(score)} \\n median of the score = {np.median(score)}\")\n\nplt.figure(figsize = (6, 4))\nplt.title(r'Histogram', fontsize=20)\nplt.hist(score, bins = np.linspace(0, 100, 20), rwidth=0.7 )\nplotstyle()\nplt.xlabel('score')\nplt.ylabel('Num')\nplt.show()\n\n\nplt.figure(figsize = (6, 4))\nplt.title(r'1 vs 0', fontsize=20)\n\nfor i, feature in enumerate(train_dat.columns[1:-1]): \n    group0 = train_dat[train_dat[feature] == 0]\n    group1 = train_dat[train_dat[feature] == 1]\n    \n    m0 = np.median(group0.Pawpularity)\n    s0 = np.std(group0.Pawpularity)\n    m1 = np.median(group1.Pawpularity)\n    s1 = np.std(group1.Pawpularity)\n    \n    plt.plot((i, i), (m0-s0, m0+s0), 'b-', alpha=0.5)\n    plt.plot((i+0.3, i+0.3), (m1-s1, m1+s1), 'r-', alpha=0.5)\n    \n    plt.scatter(i, m0, s=30, color='b', marker='x')\n    plt.scatter(i+0.3, m1, s=30, color='r', marker='x')\nplotstyle()    \nplt.xlabel('features')\nplt.ylabel('score')\nplt.ylim(0, 100)\nplt.show()","85cdfdc5":"# Set up the data : \ny = train_dat['Pawpularity']\nX = train_dat.drop(['Id','Pawpularity'],axis=1)\n\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1234)\n\n\n## Random Forest \n#create the Random Forest ensemble\nRF_reg = RandomForestRegressor(n_estimators=200, max_depth=8)\n#train the model\nstart = time.time()\nRF_reg.fit(x_train, y_train)\nstop = time.time()\n#predict the response for the test data\ny_RF = RF_reg.predict(x_test)\n#print the rms\nprint(f'Training time: {round((stop - start),3)} seconds')\nrms_RF = rms(y_test, y_RF)\nprint(f'RF_reg_RMSE: {round(rms_RF,3)}')\n\n\n## Boost Decision Tree\nBD_reg = GradientBoostingRegressor( max_depth=10, n_estimators=20, learning_rate=0.01)\nBD_reg.fit(x_train, y_train)\ny_BDT = BD_reg.predict(x_test)\nrms_BDT = rms(y_test, y_BDT)\nprint(f'BD_reg_RMSE: {rms_BDT:.3f}')\n\nplt.hist(y_train, bins = np.linspace(0, 100, 20), rwidth=0.8, label='Data' , alpha=0.5 )\nplt.hist(y_RF, bins = np.linspace(0, 100, 20), rwidth=0.8, label='Random Forest' , alpha=0.7 )\nplt.hist(y_BDT, bins = np.linspace(0, 100, 20), rwidth=0.5, label='BDT' , alpha=0.7 )\nplt.legend(fontsize=15)\nplt.show()","c9f026bc":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torchvision\nimport pytorch_lightning as pl\nimport matplotlib.pyplot as plt\n\nfrom typing import Optional\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torch import nn, optim\nfrom torchvision.io import read_image\nfrom torchvision.transforms import Compose, ConvertImageDtype, Resize, Normalize\nfrom pytorch_lightning.callbacks import ModelCheckpoint\n\npd.set_option(\"display.max_rows\", None)\nplt.style.use('ggplot')\n\nfrom functools import partial\nfrom dataclasses import dataclass\nfrom collections import OrderedDict\n\n!pip install torchsummary\nfrom torchsummary import summary","c591e2d0":"class PetfinderDataset(Dataset):\n    \"\"\"Training\/Testing dataset of Petfinder profiles.\"\"\"\n    \n    def __init__(self, train=True,img_transform=None, meta_transform=None, score_transform=None):\n        \"\"\"\n        Arguments\n        ---------\n            train (bool): Whether the training dataset or the testing dataset\n            img_transform: Transformation of images\n            meta_transform: Transformation of metadata\n            socre_transform: Transformation of pawpularity scores\n        \n        Note\n        ----\n        `score_transform` is not supported if `train` is `False`.\n        \"\"\"\n        self.dirpath = '..\/input\/petfinder-pawpularity-score'\n        self.img_dir = 'train' if train else 'test'\n        self.meta = pd.read_csv( os.path.join(self.dirpath, 'train.csv' if train else 'test.csv') )\n        self.metacols = self.meta.columns.drop( ['Id', 'Pawpularity'] if train else 'Id')\n        self.train = train\n        self.img_transform = img_transform\n        self.meta_transform = meta_transform\n        self.score_transform = score_transform\n    \n    def __len__(self):\n        return len(self.meta.index)\n    \n    def __getitem__(self, idx):\n        \"\"\"\n        Return the image, metadata and score given the index of a sample.\n        \n        Note\n        ----\n        If `self.train` is `False`, the returned score will be -1.\n        \"\"\"\n        # Obtain image, metadata and score\n        ind = self.meta.index[idx]  # index in metadata\n        img_path = os.path.join( self.dirpath, self.img_dir, f\"{self.meta.loc[ind, 'Id']}.jpg\")\n        img = read_image(img_path)\n        meta = self.meta.loc[ind, self.metacols]\n        meta = meta.values.astype(np.float32)  # convert data type\n        score = self.meta.loc[ind, 'Pawpularity'] if self.train else -1.0\n        score = np.float32(score)  # convert data type\n        # Apply transformations\n        if self.img_transform is not None:\n            img = self.img_transform(img)\n        if self.meta_transform is not None:\n            meta = self.meta_transform(meta)\n        if self.train and self.score_transform is not None:\n            score = self.score_transform(score)\n        return img, meta, score","d69b1bed":"class PetfinderDataModule(pl.LightningDataModule):\n    \"\"\"Data module of Petfinder profiles.\"\"\"\n    \n    def __init__(self,image_size: int = 224, batch_size: int = 64, num_validation: int = 128):\n        \"\"\"\n        Arguments\n        ---------\n            image_size: Size of square images after transformations\n            batch_size: Batch size loading training\/validation dataset\n            num_validataion: Number of observations in validataion dataset\n        \"\"\"\n        super().__init__()\n        self.image_size = image_size\n        self.batch_size = batch_size\n        self.num_validation = num_validation\n    \n    def setup(self, stage: Optional[str] = None):\n        # Transformations\n        transforms = {'img_transform': Compose([\n                ConvertImageDtype(torch.float32),\n                Resize((self.image_size, self.image_size)),\n                Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n                ])}\n        # Split training set and validation set\n        if stage in (None, 'fit'):\n            self.dataset = PetfinderDataset(train=True, **transforms)\n            self.trainset, self.valset = random_split(\n                self.dataset, [len(self.dataset)-self.num_validation, self.num_validation])\n        # Load dataset for prediction\n        if stage == 'predict':\n            self.predictset = PetfinderDataset(train=False, **transforms)\n    \n    def train_dataloader(self):\n        return DataLoader(self.trainset, batch_size=BATCH_SIZE, shuffle=True)\n    \n    def val_dataloader(self):\n        return DataLoader(self.valset, batch_size=BATCH_SIZE)\n    \n    def predict_dataloader(self):\n        return DataLoader(self.predictset, batch_size=len(self.predictset))\n    \n    def num_meta(self):\n        \"\"\"\n        Return number of features in the metadata.\n        \n        Note\n        ----\n        Must be called after running self.setup().\n        \"\"\"\n        return len(self.dataset.metacols)\n    \n    def meta_odds(self):\n        \"\"\"\n        Return the odds against features in the metadata.\n        \n        Note\n        ----\n        Must be called after running self.setup().\n        \"\"\"\n        pos_rate = self.dataset.meta.loc[:, self.dataset.metacols].mean()\n        pos_rate = torch.from_numpy(pos_rate.values).float()\n        return (1 - pos_rate) \/ pos_rate","0f0d1f4a":"### Following this nicely written explanation about ResNet \n### https:\/\/github.com\/FrancescoSaverioZuppichini\/ResNet\n\n## Basic Block\nclass Conv2dAuto(nn.Conv2d):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.padding =  (self.kernel_size[0] \/\/ 2, self.kernel_size[1] \/\/ 2) # dynamic add padding based on the kernel_size\n        \nconv3x3 = partial(Conv2dAuto, kernel_size=3, bias=False)    \n\n## Residul Block\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.in_channels, self.out_channels =  in_channels, out_channels\n        self.blocks = nn.Identity()\n        self.shortcut = nn.Identity()   \n    \n    def forward(self, x):\n        residual = x\n        if self.should_apply_shortcut: residual = self.shortcut(x)\n        x = self.blocks(x)\n        x += residual\n        return x\n    \n    @property\n    def should_apply_shortcut(self):\n        return self.in_channels != self.out_channels\n\n## Extend the ResidualBlock \nclass ResNetResidualBlock(ResidualBlock):\n    def __init__(self, in_channels, out_channels, expansion=1, downsampling=1, conv=conv3x3, *args, **kwargs):\n        super().__init__(in_channels, out_channels)\n        self.expansion, self.downsampling, self.conv = expansion, downsampling, conv\n        self.shortcut = nn.Sequential(OrderedDict(\n        {\n            'conv' : nn.Conv2d(self.in_channels, self.expanded_channels, kernel_size=1,\n                      stride=self.downsampling, bias=False),\n            'bn' : nn.BatchNorm2d(self.expanded_channels)\n            \n        })) if self.should_apply_shortcut else None\n        \n        \n    @property\n    def expanded_channels(self):\n        return self.out_channels * self.expansion\n    \n    @property\n    def should_apply_shortcut(self):\n        return self.in_channels != self.expanded_channels\n","024b957b":"def conv_bn(in_channels, out_channels, conv, *args, **kwargs):\n    return nn.Sequential(OrderedDict({'conv': conv(in_channels, out_channels, *args, **kwargs), \n                          'bn': nn.BatchNorm2d(out_channels) }))\n## Basic Block\nclass ResNetBasicBlock(ResNetResidualBlock):\n    expansion = 1\n    def __init__(self, in_channels, out_channels, activation=nn.ReLU, *args, **kwargs):\n        super().__init__(in_channels, out_channels, *args, **kwargs)\n        self.blocks = nn.Sequential(\n            conv_bn(self.in_channels, self.out_channels, conv=self.conv, bias=False, stride=self.downsampling),\n            activation(),\n            conv_bn(self.out_channels, self.expanded_channels, conv=self.conv, bias=False),\n        )\n        \n## Bottle Neck        \nclass ResNetBottleNeckBlock(ResNetResidualBlock):\n    expansion = 4\n    def __init__(self, in_channels, out_channels, activation=nn.ReLU, *args, **kwargs):\n        super().__init__(in_channels, out_channels, expansion=4, *args, **kwargs)\n        self.blocks = nn.Sequential(\n           conv_bn(self.in_channels, self.out_channels, self.conv, kernel_size=1),\n             activation(),\n             conv_bn(self.out_channels, self.out_channels, self.conv, kernel_size=3, stride=self.downsampling),\n             activation(),\n             conv_bn(self.out_channels, self.expanded_channels, self.conv, kernel_size=1),\n        )\n        \nclass ResNetLayer(nn.Module):\n    def __init__(self, in_channels, out_channels, block=ResNetBasicBlock, n=1, *args, **kwargs):\n        super().__init__()\n        # 'We perform downsampling directly by convolutional layers that have a stride of 2.'\n        downsampling = 2 if in_channels != out_channels else 1\n        \n        self.blocks = nn.Sequential(\n            block(in_channels , out_channels, *args, **kwargs, downsampling=downsampling),\n            *[block(out_channels * block.expansion, \n                    out_channels, downsampling=1, *args, **kwargs) for _ in range(n - 1)]\n        )\n\n    def forward(self, x):\n        x = self.blocks(x)\n        return x\n    \n","495d357b":"## Encoder\nclass ResNetEncoder(nn.Module):\n    \"\"\"\n    ResNet encoder composed by increasing different layers with increasing features.\n    \"\"\"\n    def __init__(self, in_channels=3, blocks_sizes=[64, 128, 256, 512], deepths=[2,2,2,2], \n                 activation=nn.ReLU, block=ResNetBasicBlock, *args,**kwargs):\n        super().__init__()\n        \n        self.blocks_sizes = blocks_sizes\n        \n        self.gate = nn.Sequential(\n            nn.Conv2d(in_channels, self.blocks_sizes[0], kernel_size=7, stride=2, padding=3, bias=False),\n            nn.BatchNorm2d(self.blocks_sizes[0]),\n            activation(),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n        \n        self.in_out_block_sizes = list(zip(blocks_sizes, blocks_sizes[1:]))\n        self.blocks = nn.ModuleList([ \n            ResNetLayer(blocks_sizes[0], blocks_sizes[0], n=deepths[0], activation=activation, \n                        block=block,  *args, **kwargs),\n            *[ResNetLayer(in_channels * block.expansion, \n                          out_channels, n=n, activation=activation, \n                          block=block, *args, **kwargs) \n              for (in_channels, out_channels), n in zip(self.in_out_block_sizes, deepths[1:])]       \n        ])\n        \n        \n    def forward(self, x):\n        x = self.gate(x)\n        for block in self.blocks:\n            x = block(x)\n        return x\n\n## Decoder\nclass ResnetDecoder(nn.Module):\n    \"\"\"\n    This class represents the tail of ResNet. It performs a global pooling and maps the output to the\n    correct class by using a fully connected layer.\n    \"\"\"\n    def __init__(self, in_features, n_classes):\n        super().__init__()\n        self.avg = nn.AdaptiveAvgPool2d((1, 1))\n        self.decoder = nn.Linear(in_features, n_classes)\n\n    def forward(self, x):\n        x = self.avg(x)\n        x = torch.flatten(x, 1)  #x = x.view(x.size(0), -1)\n        x = self.decoder(x)\n        return x\n    \n## Combine everything \n    \nclass ResNet(nn.Module):\n    \n    def __init__(self, in_channels, n_classes, *args, **kwargs):\n        super().__init__()\n        self.out_features = n_classes\n        self.encoder = ResNetEncoder(in_channels, *args, **kwargs)\n        self.decoder = ResnetDecoder(self.encoder.blocks[-1].blocks[-1].expanded_channels, n_classes)\n        \n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x","81412610":"def resnet18(in_channels, n_classes):\n    return ResNet(in_channels, n_classes, block=ResNetBasicBlock, deepths=[2, 2, 2, 2])\n\ndef resnet_small(in_channels, n_classes):\n    return ResNet(in_channels, n_classes, blocks_sizes=[16, 32, 64, 128], block=ResNetBasicBlock, deepths=[2, 2, 2, 2])\n\nMy_model = resnet_small(3, 87)\nsummary(My_model.cuda(), (3, 224, 224))\n","d6537fc6":"class PawpularityPredictor(pl.LightningModule):\n    \"\"\"Transfer learning model with two-stage finetuning.\"\"\"\n    \n    def __init__(\n        self,\n        backbone: str ='resnet_18',\n        training_phase: str = 'regression',\n        num_meta: int = 12,\n        pos_weight: torch.Tensor = torch.ones(12),\n        classification_threshold: float = 0.5\n    ):\n        \"\"\"\n        Arguments\n        ---------\n            backbone: Backbone model to fine tune\n            training_phase: Indicator of classification or regression\n            num_meta: Number of features in metadata\n            pos_weight: Weight of positive samples passed to classification loss\n            classification_threshold: Threshold for binary classification\n        \"\"\"\n        super().__init__()\n        if training_phase not in ('classification', 'regression'):\n            raise ValueError('phase must be either classification or regression')\n        if backbone == 'resnet_18':\n            self.backbone = torchvision.models.resnet18(pretrained=True)\n            num_feats = self.backbone.fc.in_features\n            self.backbone.fc = nn.Identity()  \n        if backbone == 'try':\n            self.backbone = My_model\n            num_feats = self.backbone.out_features\n            \n        else:\n            raise ValueError('backbone model not supported')\n        # classifier\n        self.classifier = nn.Linear(num_feats, num_meta)\n        \n        # regressor \n        self.regressor =nn.Linear(num_feats, 1) \n        \n        \n        self.lossfn_classification = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n        self.lossfn_regression = nn.MSELoss()\n        self.classification_threshold = classification_threshold\n        self.training_phase = training_phase\n        self.freeze_part_by_training_phase()\n    \n    def freeze_part_by_training_phase(self):\n        \"\"\"Freeze part of model according to the internal training phase.\"\"\"\n        if self.training_phase == 'classification':\n            self.classifier.requires_grad_(True)\n            self.regressor.requires_grad_(False)  # freeze regressor\n        else:\n            self.regressor.requires_grad_(True)\n            self.classifier.requires_grad_(False)  # freeze classifier\n    \n    def forward(self, imgs):\n        x = self.backbone(imgs)\n        x = torch.sigmoid(self.regressor(x))\n        x = 100*x\n        #return self.regressor(self.backbone(imgs))\n        return x\n    \n    def class_forward(self, imgs):\n        x = self.backbone(imgs)\n        x = self.classifier(x)\n        return x\n        \n    \n    def training_step(self, batch, batch_idx):\n        imgs, meta, scores = batch\n        if self.training_phase == 'classification':\n            logits = self.class_forward(imgs)#self.classifier(self.backbone(imgs))\n            loss = self.lossfn_classification(logits, meta)\n            self.log('Loss:classification\/train', loss)\n            preds = torch.sigmoid(logits) > self.classification_threshold\n            acc = (preds == meta).float().mean().item()  # batch accuracy\n            self.log('Accuracy\/train', acc)\n        else:\n            preds = self.forward(imgs) #self.regressor(self.backbone(imgs))\n            loss = self.lossfn_regression(preds, scores.unsqueeze(-1))\n            self.log('Loss:regression\/train', loss)\n            rmse = torch.sqrt(loss)\n            self.log('RMSE\/train', rmse)\n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        imgs, meta, scores = batch\n        if self.training_phase == 'classification':\n            logits = self.class_forward(imgs) #self.classifier(self.backbone(imgs))\n            loss = self.lossfn_classification(logits, meta)\n            self.log('Loss:classification\/validation', loss)\n            preds = torch.sigmoid(logits) > self.classification_threshold\n            acc = (preds == meta).float().mean().item()  # batch accuracy\n            self.log('Accuracy\/validation', acc)\n        else:\n            preds = self.forward(imgs) #self.regressor(self.backbone(imgs))\n            loss = self.lossfn_regression(preds, scores.unsqueeze(-1))\n            self.log('Loss:regression\/validation', loss)\n            rmse = torch.sqrt(loss)\n            self.log('RMSE\/validation', rmse)\n    \n    def configure_optimizers(self):\n        if self.training_phase == 'classification':\n            optimizer = optim.AdamW(self.parameters(), lr=1e-3)\n            return optimizer\n        else:\n            optimizer = optim.AdamW(self.parameters(), lr=1e-3)\n            return optimizer\n    \n    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n        imgs, _, _ = batch\n        return self(imgs)","5c847851":"IMAGE_SIZE = 224\nBATCH_SIZE = 64\nNUM_VALIDATION = 128\nCLASSIFICATION_THRESHOLD = 0.5\nNUM_EPOCHS_CLASSIFICATION = 10\nNUM_EPOCHS_REGRESSION = 20","d2e4589e":"datamodule = PetfinderDataModule( image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n                                 num_validation=NUM_VALIDATION  )\ndatamodule.setup()","e106f450":"# skip the classifier (if the regressor field again,  we come back to train this, \n# so that I know at least the network works on the classifier )\nmodel_class = PawpularityPredictor( backbone = 'try',  training_phase='classification' )\n\ncheckpoint_callback = ModelCheckpoint(\n    monitor='Accuracy\/validation',\n    mode='max',\n    filename='classifier-{epoch}-{step}'\n)\n\nlogger = pl.loggers.CSVLogger('.\/logs_classification')\n\ntrainer = pl.Trainer( gpus=1,\n                      max_epochs=NUM_EPOCHS_CLASSIFICATION,\n                      callbacks=[checkpoint_callback],\n                      logger=logger )\n\n","25dccff7":"trainer.fit(model_class, datamodule=datamodule)","f8903e40":"classifier_path = checkpoint_callback.best_model_path\nclassifier_path","65d29dea":"log = pd.read_csv(os.path.join(logger.log_dir, 'metrics.csv'))\nlog","dbd914ae":"\nmodel = PawpularityPredictor.load_from_checkpoint(\n    checkpoint_callback.best_model_path,\n    training_phase='regression'\n)\n'''\nmodel = PawpularityPredictor(\n    training_phase='regression'\n)\n'''\ncheckpoint_callback = ModelCheckpoint(\n    monitor='RMSE\/validation',\n    mode='min',\n    filename='regressor-{epoch}-{step}'\n)\nlogger = pl.loggers.CSVLogger('.\/logs_regression')\ntrainer = pl.Trainer(\n    gpus=1,\n    max_epochs=NUM_EPOCHS_REGRESSION,\n    callbacks=[checkpoint_callback],\n    logger=logger\n)\n\n#trainer.fit(model, datamodule=datamodule)","39ed129f":"#checkpoint_callback.best_model_path","5db9d051":"#log = pd.read_csv(os.path.join(logger.log_dir, 'metrics.csv'))\n#log","0917d06c":"def diagnose_predictions(model, datamodule, num_epochs):\n    \"\"\"Output a scatter plot of the actual\/predicted Pawpularity scores.\"\"\"\n    # Setup figure\n    fig, axes = plt.subplots(ncols=2, figsize=(12,6))\n    lims = (-2, 102)\n    for ax in axes:\n        ax.set_xlabel('Actual Pawpularity Score')\n        ax.set_ylabel('Predicted Pawpularity Score')\n        ax.set_xlim(*lims)\n        ax.set_ylim(*lims)\n    axes[0].set_title('Training Samples')\n    axes[1].set_title('Validation Set')\n    fig.suptitle(f'Regressor Trained after {num_epochs} Epochs', fontsize=16)\n    \n    # Plot diagonal line\n    for ax in axes:\n        ax.plot(lims, lims, color='C3')\n    \n    # Visualize training\/validation set\n    dataloaders = (\n        DataLoader(datamodule.trainset, batch_size=NUM_VALIDATION, shuffle=True),\n        DataLoader(datamodule.valset, batch_size=NUM_VALIDATION)\n    )\n    for ax, dataloader in zip(axes, dataloaders):\n        # Plot actual\/predicted scores\n        imgs, _, scores = next(iter(dataloader))\n        with torch.no_grad():\n            preds = model(imgs)\n            \n        x = scores.cpu().numpy()\n        y = preds.squeeze().cpu().numpy()\n        #print(np.shape(x), np.shape(y))\n        ax.scatter(scores.cpu().numpy(), preds.squeeze().cpu().numpy(), c='C1')\n        # Add text of RMSE\n        rmse = torch.sqrt(model.lossfn_regression(preds, scores.unsqueeze(-1))).item()\n        textstr = f'RMSE = {rmse:.2f}'\n        props = dict(boxstyle='round', facecolor='C4', alpha=0.5)\n        ax.text(0.05, 0.95, textstr, transform=ax.transAxes, verticalalignment='top', bbox=props)\n    \n    # Output\n    os.makedirs('.\/diagnostics', exist_ok=True)\n    fig.savefig(f'.\/diagnostics\/regressor_{num_epochs}_epochs.png')\n    plt.show(fig)","98577f31":"# Before training regressor\ndiagnose_predictions(model, datamodule, 0)","4ac82ad6":"# After NUM epochs\ntrainer.fit(model, datamodule=datamodule)\ndiagnose_predictions(model, datamodule, 1 * NUM_EPOCHS_REGRESSION)","6ab059a1":"# After 2*NUM epochs\n#trainer.fit(model, datamodule=datamodule)\n#diagnose_predictions(model, datamodule, 2 * NUM_EPOCHS_REGRESSION)","c27c9214":"preds, = trainer.predict(datamodule=datamodule)","6e57882b":"# Output predictions\npredictions = pd.DataFrame({\n    'Id': datamodule.predictset.meta['Id'],\n    'Pawpularity': preds.squeeze().cpu().numpy()\n})\npredictions.to_csv('.\/submission.csv', index=False)","bd827ae2":"predictions","75703d20":"### Some ML method: \n\nLet's try if the combination of the catalog features can make good prediction to the score.  We will use several ML tools in sklearn to build our model. ","ef057ac8":"### Building a network smaller than ResNet18\n### Following this nicely written explanation about ResNet \n### https:\/\/github.com\/FrancescoSaverioZuppichini\/ResNet","5f046bcb":"# 1. Explore the metadata \n","aa0847eb":"# Inference","77258004":"# Model & Training\/Validation Step","17d7da01":"# Two Step Model \n\nNext we try to use a pretrain ResNet18 network as a regressor.  \nWe have tried the follwoing: \n\n### 1. A two-step fine tuning model:  First train the network to predict the MetaData  (The classifier), then transfer the best performing model to train the Pawpularity (The regressor).   We also try adding a few hidden layer as the decoder. \n\nThe result of the classifier works pretty good in less than 10 epoch if we preserve the pretrain weight. However, even though the regressor can successfully predict the Pawpularity of the training data, it return only the value of the mean (~38) for the validation data.  First we assume it was a result of overtrain. \n\n### 2. Build a network smaller than ResNet18. \n\nI assume the reason of overtraining is there are too many parameters in ResNet18 (11M parameters).  So I build a residual-net will less layer and lower dimension.  The result is similar to the previous method: works for classifier, and return the mean for the validation data.  Only this time,  with the same number of epoch,  the scattering of the training data is larger than using the pretrained ResNet18, and still returning somewhat a value close to mean at the validation set.  \n\n\n### We will put our thoughts at the end of the notebook: ","9660e912":"## PawpularityPredictor","60753298":"## Data Augmentation (TODO) \nYes,  but actually, no","f4ea3af8":"# Discussion \n\n### About the two-step procedure:  \nSo we already see other ML models failed to predict the Pawpularity using the Metadata along.  You might also see (or do it as a practice) the model of DNN network with the 12 MetaData features as input failed to predict the score.  Basically I believe if the input have no statistic significant to the output, any model would have failed to predict with the input.  \nThe two step model first try to train a network that recognize the MetaData, which has no correlation to the Pawpularity.  \nHowever there are 512 output features in ResNet18. One of the problem we have is that we only have < 10k training data.  By training to match the 12 MetaData features, we are more certain that these 512 features capture the information about the images, and these 512 features should be helpful on prediction.  Except that they don't. \n\n\n\n\n### Some other discussion: \nAs in this discussion, (https:\/\/www.kaggle.com\/c\/petfinder-pawpularity-score\/discussion\/285140) \nsome point out that there are similar images getting distinct Pawpularity, or duplicate images. \nThere are notebook working on identifing similar images (e.g. https:\/\/www.kaggle.com\/schulta\/petfinder-identify-duplicates-and-share-findings, https:\/\/www.kaggle.com\/burakbekci\/petfinder-finding-duplicates-with-cnn), basically alinging the features from Metadata or from the network.   \nThe similar images\/ duplicate images are not too many (<300 images? That's 3% ) and can be remove or treat as noise (see the discussion link for more detail).  We have tried remove the duplicate images (keep the higher score) and train it again, but not getting imporving (as expect).  The similar featured images inspire us to view the Paupularity as a score of **aesthetics**, rather than base on identity features.  How good the photo looks in the thumbnail, are people related to the photos, who posted the photos, etc.  \n\nNow I do have concern about whether we are given all the necessary data to predict this Pawpularity score.  Some common questions are like whether the score is more relevant to where\/who\/when the photos were posted, even though the competition explained that these have been normalized.  Personally, I think we do what we can do.  Analyze the data.  \n\nSo that's my thought about this project.  I have a lot of fun and gain experience.  To dig deeper on aesthetics rating is beyong my goal (but check this out: http:\/\/infolab.stanford.edu\/~wangz\/project\/imsearch\/Aesthetics\/TMM15\/lu.pdf).  \n\nChills, \n","7dd9d81b":"## Finetune Backbone & Classifier","c626d687":"# Introduction \n\n### The goal of the project is predicting the image score \"Pawpularity\" from the data including the feature catalog (metadata) and the image itself.  The followings are what we'll do: \n\n### 1. Explore the metadata : \n(1) read the csv table   \n(2) take a look at the images  \n(3) try several ML methods using the table along\n\n### 2. A two-stage fine tuning regressor using pretrained model (ResNet-18) \n(1) Training the image feature in the MetaData using ResNet18 \n\n(2) Transfer the above network to train as a regressor for Pawpularity \n\n### 3. Discussion \n(1) Thoughts about our model  \n(2) What else can we do ","29925b80":"# Training with Two-stage Finetuning","2180bd71":"### Chatting \nThis is my first project on Kaggle, working with some of my friends who are also interested in Deep Learning.  I want to record problems, thoughts, and what I've learned from this project in this notebook.  Now I'm writing the notebook I realize it takes affort to have a good notebook presentation.  \n\nAnyway, hope you have fun on this project as well!   ","1bf06444":"### hmm \n\nSo I accually tried more than two methods, but none of them works well.  As you can see above, both method predict the mean value as the safest strategy.  Note that these method are not bad, the reason way we are not prediction the result can be: (1) There's a much hidden and complicate rule between the score and the features  (2) MetaData is irrelevant to the score (3) The score is irrelevant to the data.  \n\nFor (1) and (2),  our plan is to get into the image,  extract features with some CNN, and hope for the best.   (But if it's that simple,  why couldn't BDT make a good prediction? just saying)\n\n(3) is the worst case which basically means we give up. But in the research field where I am at (Astronomy),  often time data are messy and confusing.  Finding out something is irrelevant can be a contribution.  \n\nI recommend you to read this discussion about other's thoughts and ideas about this dataset: \n\nhttps:\/\/www.kaggle.com\/c\/petfinder-pawpularity-score\/discussion\/285140\n\n","3a8c6d8c":"# Dataset & Datamodule","864c930f":"### Let's take a look at the images \n\nAs you can see,  the training data is pictures of dogs (or cats), and testing data is some kind of noise.  That's not a problem as long as our model works for the training data that has the real meaning.   \n\nYou can briefly go through a few more images to see how accurate the metadata catalog describe the corresponding images.  I'd say they look fine.   ","d8d006c3":"### Back to the catalog\n\nLet's make a few plots, counts, statistics.  \n\nThe first plot is the histogram\/distribution of the score  (Looks like a Poisson distribution, no?).  Most of the scores are distributed at the median ~ 33.  The standard deviation is around 21.  You can see a peak at around 100 point, presumming that the the intrinsic distribution is ($-\\infty$, $\\infty$), and set all negative to 0 and all above 100 to 100, or something like that. \n\nThe next plot is separating the training data by a single feature ( 0 as blue and 1 as red ), to see if there is a single dominating feature that can give you a brief pridection to the score.  Unfortunately I would say there is no dominating features. The features are binary numbers, at the end of the day. ","cbec8e72":"### There are ~9900 rows in the training data catalog.  In each row, we have 12 boolean  features ( 1 or 0), and a the score from 0 to 100. \n\n### In the testing data we have the features. ","356a49bc":"## Finetune Backbone & Regressor (**also some Diagnostics**)"}}