{"cell_type":{"ab8071b9":"code","76b12593":"code","87ae1c08":"code","1730757a":"code","1847701c":"code","af0f240d":"code","f70c6e45":"code","531c59d9":"code","7a2e13dd":"code","54554dcf":"code","358edc32":"code","e6e08055":"code","ca4d5996":"code","4fa3c66d":"code","777a869b":"code","1f4c5d59":"code","14dd6251":"code","7c53bf94":"code","5932dfa7":"code","d46e0b15":"code","bcddec2b":"code","81e343ed":"code","a494505d":"code","09fe2fcd":"code","611cc859":"code","56d07d85":"code","47ff3706":"code","b3a56a46":"code","df7296aa":"code","a2d46ec2":"code","dc275772":"code","b9c3fdd4":"code","02d86603":"code","76d8c127":"code","6dd70921":"code","715f0583":"code","4ace2b4e":"code","1ad7899a":"code","384f00a8":"code","0d4b16ad":"code","9a65e65b":"code","14a3e5ec":"code","81507b68":"code","bd2bd1d2":"code","4c1e1f7d":"code","39734f48":"code","6aeef3e2":"code","586cb4c4":"code","eff0b380":"code","4f1dc193":"code","1d1a31ee":"code","9a2009c7":"code","3e36d550":"markdown","7cb9f286":"markdown","c62ef4b4":"markdown","a0296926":"markdown","9337e206":"markdown","3a57cf72":"markdown","74071190":"markdown","07255914":"markdown","06c1b2e0":"markdown","f992342b":"markdown","d8606e49":"markdown","50f670cf":"markdown","582b9743":"markdown","e1885aad":"markdown","2ae65467":"markdown","b698791a":"markdown"},"source":{"ab8071b9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","76b12593":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom ast import literal_eval\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel, cosine_similarity\nfrom nltk.stem.snowball import SnowballStemmer\nfrom nltk.stem.wordnet import WordNetLemmatizer\nfrom nltk.corpus import wordnet\nfrom surprise import Reader, Dataset, SVD, evaluate\n\nimport warnings; warnings.simplefilter('ignore')","87ae1c08":"metadata = pd.read_csv('..\/input\/movies_metadata.csv')\nmetadata.head()","1730757a":"metadata['genres'] = metadata['genres'].fillna('[]').apply(literal_eval).apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])","1847701c":"vote_counts = metadata[metadata['vote_count'].notnull()]['vote_count'].astype('int')\nvote_averages = metadata[metadata['vote_average'].notnull()]['vote_average'].astype('int')\nC = vote_averages.mean()\nC","af0f240d":"# Assumption:\n# Top 5% vote counts are reliable, others are very small to analyse\nm = vote_counts.quantile(0.95)\nm","f70c6e45":"metadata['year'] = pd.to_datetime(metadata['release_date'], errors='coerce').apply(lambda x: str(x).split('-')[0] if x != np.nan else np.nan)","531c59d9":"qualified = metadata[(metadata['vote_count'] >= m) & (metadata['vote_count'].notnull()) & (metadata['vote_average'].notnull())]\nqualified = qualified[['title', 'year', 'vote_count', 'vote_average', 'popularity', 'genres']]\nqualified['vote_count'] = qualified['vote_count'].astype('int')\nqualified['vote_average'] = qualified['vote_average'].astype('int')\nqualified.shape","7a2e13dd":"def weighted_rating(x):\n    v = x['vote_count']\n    R = x['vote_average']\n    return (v\/(v+m) * R) + (m\/(m+v) * C)","54554dcf":"qualified['wr'] = qualified.apply(weighted_rating, axis=1)","358edc32":"qualified = qualified.sort_values('wr', ascending=False).head(250)","e6e08055":"qualified.head(15)","ca4d5996":"s = metadata.apply(lambda x: pd.Series(x['genres']) , axis=1).stack().reset_index(level=1, drop=True)\ns.name = 'genre'\ngen_md = metadata.drop('genres', axis=1).join(s)","4fa3c66d":"def build_chart(genre, percentile=0.85):\n    df = gen_md[gen_md['genre'] == genre]\n    vote_count = df[df['vote_count'].notnull()]['vote_count'].astype('int')\n    vote_averages = df[df['vote_average'].notnull()]['vote_average'].astype('int')\n    C = vote_averages.mean()\n    m = vote_count.quantile(percentile)\n    \n    qualified = df[(df['vote_count'] >= m) \n                   & (df['vote_count'].notnull()) \n                   & (df['vote_average'].notnull())][[\n        'title', 'year', 'vote_count', 'vote_average', 'popularity'\n    ]]\n    qualified['vote_count'] = qualified['vote_count'].astype('int')\n    qualified['vote_average'] = qualified['vote_average'].astype('int')\n    qualified['wr'] = qualified.apply(\n        lambda x: x['vote_count']\/(x['vote_count'] + m) * x['vote_average'] \n        + (m\/(m+x['vote_count']) * C), axis=1)\n    qualified = qualified.sort_values('wr', ascending=False).head(250)\n    return qualified","777a869b":"build_chart('Horror').head(15)","1f4c5d59":"links_small = pd.read_csv('..\/input\/links_small.csv')\nlinks_small = links_small[links_small['tmdbId'].notnull()]['tmdbId'].astype('int')","14dd6251":"metadata = metadata.drop([19730, 29503, 35587])\n# Droping these rows because ids are not parcable as int\n# The data is not clean\nmetadata['id'] = metadata['id'].astype('int')","7c53bf94":"smd = metadata[metadata['id'].isin(links_small)]\nsmd.shape","5932dfa7":"smd['tagline'] = smd['tagline'].fillna('')\nsmd['description'] = smd['overview'] + smd['tagline']\nsmd['description'] = smd['description'].fillna('')","d46e0b15":"tf = TfidfVectorizer(analyzer='word', ngram_range=(1,2), min_df=0, stop_words='english')\ntfidf_matrix = tf.fit_transform(smd['description'])\ntfidf_matrix.shape","bcddec2b":"cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\ncosine_sim[0]","81e343ed":"smd = smd.reset_index()\ntitles = smd['title']\nindices = pd.Series(smd.index, index=smd['title'])","a494505d":"def get_recommendations(title):\n    idx = indices[title]\n    sim_scores = list(enumerate(cosine_sim[idx]))\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    movie_indices = [i[0] for i in sim_scores]\n    return titles.iloc[movie_indices]","09fe2fcd":"get_recommendations('The Dark Knight Rises').head(25)","611cc859":"credits = pd.read_csv('..\/input\/credits.csv')\nkeywords = pd.read_csv('..\/input\/keywords.csv')","56d07d85":"keywords['id'] = keywords['id'].astype('int')\ncredits['id'] = credits['id'].astype('int')\nmetadata['id'] = metadata['id'].astype('int')","47ff3706":"metadata.shape","b3a56a46":"metadata = metadata.merge(credits, on='id')\nmetadata = metadata.merge(keywords, on='id')","df7296aa":"smd = metadata[metadata['id'].isin(links_small)]\nsmd.shape","a2d46ec2":"smd['cast'] = smd['cast'].apply(literal_eval)\nsmd['crew'] = smd['crew'].apply(literal_eval)\nsmd['keywords'] = smd['keywords'].apply(literal_eval)\nsmd['cast_size'] = smd['cast'].apply(lambda x: len(x))\nsmd['crew_size'] = smd['crew'].apply(lambda x: len(x))","dc275772":"def get_director(x):\n    for i in x:\n        if i['job'].lower() == 'director':\n            return i['name']\n        return np.nan","b9c3fdd4":"smd['director'] = smd['crew'].apply(get_director)","02d86603":"smd['cast'] = smd['cast'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\nsmd['cast'] = smd['cast'].apply(lambda x: x[:3] if len(x) >= 3 else x)","76d8c127":"smd['keywords'] = smd['keywords'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])","6dd70921":"smd['cast'] = smd['cast'].apply(lambda x: [i.lower().replace(\" \", \"\") for i in x])","715f0583":"smd['director'] = smd['director'].astype('str').apply(lambda x: str.lower(x.replace(\" \", \"\")))\nsmd['director'] = smd['director'].apply(lambda x: [x, x, x])","4ace2b4e":"s = smd.apply(lambda x: pd.Series(x['keywords']),axis=1).stack().reset_index(level=1, drop=True)\ns.name = 'keyword'","1ad7899a":"s = s.value_counts()\ns[:10]","384f00a8":"s = s[s > 1]","0d4b16ad":"stemmer = SnowballStemmer('english')\nstemmer.stem('Dogs')","9a65e65b":"def filter_keywords(keywords):\n    filtered_keywords = []\n    for word in keywords:\n        if word in s:\n            filtered_keywords.append(word)\n    return filtered_keywords","14a3e5ec":"smd['keywords'] = smd['keywords'].apply(filter_keywords) ","81507b68":"smd['keywords'] = smd['keywords'].apply(lambda x: [stemmer.stem(i) for i in x])\nsmd['keywords'] = smd['keywords'].apply(lambda x: [str.lower(i.replace(\" \", \"\")) for i in x])\nsmd['keywords'].head()","bd2bd1d2":"smd['soup'] = smd['keywords'] + smd['cast'] + smd['director'] + smd['genres']\nsmd['soup'].head()","4c1e1f7d":"smd['soup'] = smd['soup'].apply(lambda x: ' '.join(x))","39734f48":"count = CountVectorizer(analyzer='word', ngram_range=(1, 2), min_df=0, stop_words='english')\ncount_matrix = count.fit_transform(smd['soup'])","6aeef3e2":"cosine_sim = cosine_similarity(count_matrix, count_matrix)","586cb4c4":"smd = smd.reset_index()\ntitles = smd['title']\nindices = pd.Series(smd.index, index=smd['title'])","eff0b380":"get_recommendations('The Dark Knight').head(10)","4f1dc193":"get_recommendations('Thursday').head(10)","1d1a31ee":"def improved_reco(title, percentile=0.60, num_recommendations=10):\n    idx = indices[title]\n    if type(idx) == pd.Series:\n        sim_scores = []\n        for i in idx:\n            sim_scores = sim_scores + list(enumerate(cosine_sim[i]))\n    else:\n        sim_scores = list(enumerate(cosine_sim[idx]))\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    sim_scores = sim_scores[1:26]\n    movie_indices = [i[0] for i in sim_scores]\n    movies = smd.iloc[movie_indices][['title', 'vote_count', 'vote_average', 'popularity', 'year']]\n    \n    vote_count = movies[movies['vote_count'].notnull()]['vote_count'].astype('int')\n    vote_averages = movies[movies['vote_average'].notnull()]['vote_average'].astype('int')\n    m  = vote_count.mean()\n    C = vote_averages.quantile(percentile)\n    qualified = movies[(movies['vote_count'].notnull()) \n                       & (movies['vote_average'].notnull()) \n                       & (movies['vote_count'] >= m)]\n    qualified['vote_count'] = qualified['vote_count'].astype('int')\n    qualified['vote_average'] = qualified['vote_average'].astype('int')\n    qualified['wr'] = qualified.apply(weighted_rating, axis=1)\n    qualified = qualified.sort_values('wr', ascending=False).head(num_recommendations)\n    return qualified","9a2009c7":"improved_reco('Kahaani')","3e36d550":"**Movie Description Based Recommender**\n\nLet us first try to build a recommender using movie descriptions and taglines. We do not have a quantitative metric to judge our machine's performance so this will have to be done qualitatively.","7cb9f286":"Keywords occur in frequencies ranging from 1 to 610. We do not have any use for keywords that occur only once. \n\nTherefore, these can be safely removed. Finally, we will convert every word to its stem so that words such as Dogs and Dog are considered the same.","c62ef4b4":"**Simple Recommender System**\n\nThis model will recommend movies to users without any prior knowledge about the user\nThis moodel works purely on rating of the movies and returns highest rated ones.\nIt also returns movies of highest rating in a perticular genre.","a0296926":"We now have a pairwise cosine similarity matrix for all the movies in our dataset. The next step is to write a function that returns the 30 most similar movies based on the cosine similarity score.","9337e206":"**Metadata Based Recommender**\n\nTo build our standard metadata based content recommender, we will need to merge our current dataset with the crew and the keyword datasets. Let us prepare this data as our first step.","3a57cf72":"**Content Based Recommender**\n\nThe recommender we built in the previous section suffers some severe limitations. For one, it gives the same recommendation to everyone, regardless of the user's personal taste. If a person who loves romantic movies (and hates action) were to look at our Top 15 Chart, s\/he wouldn't probably like most of the movies. If s\/he were to go one step further and look at our charts by genre, s\/he wouldn't still be getting the best recommendations.\n\nFor instance, consider a person who loves Dilwale Dulhania Le Jayenge, My Name is Khan and Kabhi Khushi Kabhi Gham. One inference we can obtain is that the person loves the actor Shahrukh Khan and the director Karan Johar. Even if s\/he were to access the romance chart, s\/he wouldn't find these as the top recommendations.\n\nTo personalise our recommendations more, I am going to build an engine that computes similarity between movies based on certain metrics and suggests movies that are most similar to a particular movie that a user liked. Since we will be using movie metadata (or content) to build this engine, this also known as **Content Based Filtering.**\n\nI will build two Content Based Recommenders based on:\n\n* Movie Overviews and Taglines\n* Movie Cast, Crew, Keywords and Genre","74071190":"My approach to building the recommender is going to be extremely hacky. What I plan on doing is creating a metadata dump for every movie which consists of genres, director, main actors and keywords. I then use a Count Vectorizer to create our count matrix as we did in the Description Recommender. The remaining steps are similar to what we did earlier: we calculate the cosine similarities and return movies that are most similar.\n\nThese are steps I follow in the preparation of my genres and credits data:\n\n1. Strip Spaces and Convert to Lowercase from all our features. This way, our engine will not confuse between Johnny Depp and Johnny Galecki.\n2. Mention Director 3 times to give it more weight relative to the entire cast.","07255914":"We see that three Christopher Nolan Films, **Inception, The Dark Knight and Interstellar** occur at the very top of our chart. The chart also indicates a strong bias of TMDB Users towards particular genres and directors.\n\nLet us now construct our function that builds charts for particular genres. For this, we will use relax our default conditions to the **85th** percentile instead of 95.","06c1b2e0":"Therefore, to qualify to be considered for the chart, a movie has to have at least **434 votes** on TMDB. We also see that the average rating for a movie on TMDB is **5.244** on a scale of 10. **2274 Movies** qualify to be on our chart.","f992342b":"**Keywords**\n\nWe will do a small amount of pre-processing of our keywords before putting them to any use. As a first step, we calculate the frequenct counts of every keyword that appears in the dataset.","d8606e49":"We now have our cast, crew, genres and credits, all in one dataframe. Let us wrangle this a little more using the following intuitions:\n\n1. **Crew**: From the crew, we will only pick the director as our feature since the others don't contribute that much to the feel of the movie.\n\n2. **Cast**: Choosing Cast is a little more tricky. Lesser known actors and minor roles do not really affect people's opinion of a movie. Therefore, we must only select the major characters and their respective actors. Arbitrarily we will choose the top 3 actors that appear in the credits list.","50f670cf":"We have **9099** movies avaiable in our small movies metadata dataset which is 5 times smaller than our original dataset of 45000 movies.","582b9743":"I use the TMDB Ratings to come up with our Top Movies Chart. I will use IMDB's weighted rating formula to construct my chart. Mathematically, it is represented as follows:\n\nWeighted Rating (WR) =  (v\/(v+m) * R)+(m\/(v+m) * C) \nwhere,\n\nv is the number of votes for the movie\nm is the minimum votes required to be listed in the chart\nR is the average rating of the movie\nC is the mean vote across the whole report\n\nThe next step is to determine an appropriate value for m, the minimum votes required to be listed in the chart. We will use 95th percentile as our cutoff. In other words, for a movie to feature in the charts, it must have more votes than at least 95% of the movies in the list.\n\nI will build our overall Top 250 Chart and will define a function to build charts for a particular genre. Let's begin!","e1885aad":"Cosine Similarity\n\nI will be using the Cosine Similarity to calculate a numeric quantity that denotes the similarity between two movies. Mathematically, it is defined as follows:\n\ncosine(x,y) = x.y\u22ba \/ (||x||.||y||) \n\nSince we have used the TF-IDF Vectorizer, calculating the Dot Product will directly give us the Cosine Similarity Score. Therefore, we will use sklearn's **linear_kernel** instead of cosine_similarities since it is much faster.","2ae65467":"Popularity and Ratings\n\nOne thing that we notice about our recommendation system is that it recommends movies regardless of ratings and popularity. It is true that Batman and Robin has a lot of similar characters as compared to The Dark Knight but it was a terrible movie that shouldn't be recommended to anyone.\n\nTherefore, we will add a mechanism to remove bad movies and return movies which are popular and have had a good critical response.\n\nI will take the top 25 movies based on similarity scores and calculate the vote of the 60th percentile movie. Then, using this as the value of  m , we will calculate the weighted rating of each movie using IMDB's formula like we did in the Simple Recommender section.","b698791a":"We will reuse the get_recommendations function that we had written earlier. Since our cosine similarity scores have changed, we expect it to give us different (and probably better) results. Let us check for The Dark Knight again and see what recommendations I get this time around."}}