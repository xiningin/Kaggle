{"cell_type":{"09dc610d":"code","8c28ce30":"code","144e1026":"code","6a40c7ec":"code","69c22cf5":"code","21757fc1":"code","2d945572":"code","992af5ba":"code","6d2e3009":"code","192e894f":"code","0312006a":"markdown"},"source":{"09dc610d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport seaborn as sns\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","8c28ce30":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LogisticRegression\nimport scipy.spatial.distance as spdist\nfrom sklearn.pipeline import Pipeline","144e1026":"fresh_data = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/train.csv')\nfresh_data_test = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/test.csv')\nfresh_data.head(10)","6a40c7ec":"train_data = fresh_data.dropna()\ntest_data = fresh_data_test.dropna()\n\ndel fresh_data, fresh_data_test","69c22cf5":"vect = TfidfVectorizer()\nvect.fit(list(pd.DataFrame(train_data.text).append(pd.DataFrame(test_data.text), ignore_index=True).text))\ntransformer_smaller = PCA(n_components=100)\ntransformer_smaller.fit(vect.transform(list(pd.DataFrame(train_data.text).append(pd.DataFrame(test_data.text), ignore_index=True).text)[:100]).toarray())","21757fc1":"def my_transform(x):\n    try:\n        return transformer_smaller.transform(vect.transform([x]).toarray())\n    except:\n        return transformer_smaller.transform(vect.transform(x).toarray())","2d945572":"model = LogisticRegression() #\u0445\u0435\u0445, \u043e\u0431\u0443\u0447\u0438\u043b\nmodel.fit(my_transform(train_data.selected_text[:10000]), train_data.sentiment.values[:10000])","992af5ba":"def my_predict(x):\n    words = x.text.split()\n    type_of = x.sentiment\n    min_r = np.inf\n    best_word = x.text\n    for i in words:\n        if (spdist.cosine(my_transform(i)[0], my_transform(words)[0]) < min_r) and (model.predict(my_transform(i)) == type_of):\n            best_word = i\n            min_r = spdist.euclidean(my_transform(i)[0], my_transform(words)[0])\n    return best_word\n    ","6d2e3009":"res = pd.DataFrame()\nid_arr = list(test_data.textID)\nansw = []\nfor i in tqdm(range(len(id_arr))):\n    answ.append(my_predict(test_data.iloc[i]))\nres['textID'] = id_arr\nres['selected_text'] = answ","192e894f":"res.to_csv('submission.csv', index=False)","0312006a":"\u043d\u0443\u0436\u043d\u043e \u0447\u0442\u043e\u0431\u044b \u0440\u0430\u0441\u0441\u0442\u043e\u044f\u043d\u0438\u0435 \u043c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 + \u043f\u043e \u0441\u043c\u044b\u0441\u043b\u0443 \u043e\u0442\u043d\u043e\u0441\u0438\u043b\u043e \u043a \u0442\u043e\u043c\u0443 \u0438\u043b\u0438 \u0438\u043d\u043e\u043c\u0443 (negative, positive, neutral). \u041c\u043e\u0436\u0435\u0442 \u043f\u0435\u0440\u0435\u0431\u043e\u0440 \u0441\u0440\u0430\u0431\u043e\u0442\u0430\u0435\u0442. \u041f\u043e\u043f\u0440\u043e\u0431\u0443\u044e \u0442\u043e\u043b\u044c\u043a\u043e \u043e\u0434\u043d\u043e \u0441\u043b\u043e\u0432\u043e \u0431\u0440\u0430\u0442\u044c!!!"}}