{"cell_type":{"5ef0ad06":"code","14c2cca6":"code","e76c76b3":"code","afd4398a":"code","7085a687":"code","eaa062b5":"code","611add39":"markdown"},"source":{"5ef0ad06":"import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom keras import models\nfrom keras.layers  import Dense, Conv1D, Reshape, Flatten, Lambda\nfrom keras.optimizers import Adam\nfrom keras import backend as K","14c2cca6":"class Data:\n    def __init__(self, mu, sigma, ni_D):\n        self.real_sample = lambda n_batch : np.random.normal(mu, sigma, (n_batch, ni_D))\n        self.in_sample = lambda n_batch : np.random.rand(n_batch, ni_D)","e76c76b3":"class Machine:\n    def __init__(self, n_batch=10, ni_D=100):\n        data_mean = 4\n        data_stddev = 1.25\n        \n        self.data = Data(data_mean, data_stddev, ni_D)\n        self.gan = GAN(ni_D = ni_D, nh_D =50, nh_G=50)\n        self.n_batch = n_batch\n        self.n_iter_D = 1\n        self.n_iter_G = 5\n        \n    def run(self, n_repeat=30000\/\/200, n_show=200, n_test=100):\n        for ii in range(n_repeat):\n            print('Stage',ii,'(Epoch: {})'.format(ii*n_show))\n            self.run_epochs(n_show, n_test)\n            plt.show()\n            \n    def run_epochs(self, epochs, n_test):\n        self.train(epochs)\n        self.test_and_show(n_test)\n        \n    def train(self, epochs):\n        for epochs in range(epochs):\n            self.train_each()\n    \n    def train_each(self):\n        for it in range(self.n_iter_D):\n            self.train_D()\n        for it in range(self.n_iter_G):\n            self.train_GD()\n    \n    def train_D(self):\n        gan = self.gan\n        n_batch = self.n_batch\n        data =self.data\n        Real = data.real_sample(n_batch)\n        Z = data.in_sample(n_batch)\n        Gen = gan.G.predict(Z)\n        gan.D.trainable = True\n        gan.D_train_on_batch(Real, Gen)\n        \n    def train_GD(self):\n        gan =self.gan\n        n_batch = self.n_batch\n        data =self.data\n        Z = data.in_sample(n_batch)\n        \n        gan.D.trainable = False\n        gan.GD_train_on_batch(Z)\n        \n    \n    def test(self, n_test):\n        gan =self.gan\n        data =self.data\n        Z = data.in_sample(n_test)\n        Gen = gan.G.predict(Z)\n        return Gen, Z\n    \n    def show_hist(self, Real, Gen, Z):\n        plt.hist(Real.reshape(-1), histtype ='step', label = 'Real')\n        plt.hist(Gen.reshape(-1), histtype ='step', label = 'Generated')    \n        plt.hist(Z.reshape(-1), histtype ='step', label = 'Input')\n        plt.legend(loc=0)\n        \n    def test_and_show(self, n_test):\n        data =self.data\n        Gen, Z = self.test(n_test)\n        Real= data.real_sample(n_test)\n        self.show_hist(Real, Gen, Z)\n        Machine.print_stat(Real, Gen)\n        \n    def print_stat(Real, Gen):\n        def stat(d):\n            return (np.mean(d), np.std(d))\n        \n        print('Mean and Std of Real', stat(Real))\n        print('Mean and Std of Gen', stat(Gen))","afd4398a":"def add_decorate(x):\n    m = K.mean(x, axis=-1, keepdims=True)\n    d = K.square(x - m)\n    return K.concatenate([x,d],axis=-1)\n\ndef add_decorate_shape(input_shape):\n    shape = list(input_shape)\n    assert len(shape) == 2\n    shape[i] *= 2\n    return tuple(shape)\n\nlr = 2e-4\nadam =Adam(lr = lr, beta_1 = 0.9, beta_2 = 0.999)\n\ndef model_compile(model):\n    return model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])","7085a687":"class GAN:\n    def __init__(self, ni_D, nh_D, nh_G):\n        self.ni_D = ni_D\n        self.nh_D = nh_D\n        self.nh_G = nh_G\n        \n        self.D = self.gen_D()\n        self.G = self.gen_G()\n        self.GD = self.make_GD()\n        \n    def gen_D(self):\n        ni_D = self.ni_D\n        nh_D = self.nh_D\n        D = models.Sequential()\n        D.add(Lambda(add_decorate, output_shape =add_decorate_shape, input_shape=(ni_D,)))\n        D.add(Dense(nh_D, activation = 'relu'))\n        D.add(Dense(nh_D, activation = 'relu'))        \n        D.add(Dense(1, activation = 'sigmoid'))\n        \n        model_compile(D)\n        return D\n    \n    def gen_G(self):\n        ni_D = self.ni_D\n        nh_G = self.nh_D\n        \n        G = models.Sequential()\n        G.add(Reshape((ni_D,1), input_shape =(ni_D,)))\n        G.add(Conv1D(nh_G, 1, activation='relu'))\n        G.add(Conv1D(nh_G, 1, activation='sigmoid'))\n        G.add(Conv1D(1,1))\n        G.add(Flatten())\n        \n        model_compile(G)\n        return G\n     \n    def make_GD(self):\n        G, D =self.G, self.D\n        GD = models.Sequential()\n        GD.add(G)\n        GD.add(D)\n        D.trainable =False\n        model_compile(GD)\n        D.trainable =True\n        return GD\n    \n    def D_train_on_batch(self, Real, Gen):\n        D = self.D\n        X = np.concatenate([Real, Gen], axis=0)\n        y = np.array([1]*Real.shape[0]+[0]*Gen.shape[0])\n        D.train_on_batch(X,y)\n        \n    def GD_train_on_batch(self, Z):\n        GD = self.GD\n        y = np.array([1] *Z.shape[0])\n        GD.train_on_batch(Z,y)","eaa062b5":"machine = Machine(n_batch=1, ni_D=100)\nmachine.run(n_repeat = 100, n_show =200, n_test=100)","611add39":"# GAN_practice\n### I refer [jskDR's code](https:\/\/github.com\/jskDr\/keraspp)"}}