{"cell_type":{"a671c4f2":"code","32a584a1":"code","04e28345":"code","e1e0b474":"code","02390cd0":"code","00b29834":"code","551e9c6f":"code","a47fc822":"code","d8154cef":"code","c927b1ec":"code","05e125d3":"code","81722edf":"code","b9a067a0":"code","38b6657e":"code","8d9d0151":"code","5260e3b8":"code","acfcbe68":"code","fd9e7938":"code","3ab24d2d":"code","d4bd425f":"code","136635d4":"code","048d54bb":"code","24ca7096":"code","3ca80e81":"code","d0215ad2":"code","39f54ef6":"code","c5de48d5":"code","76be10ab":"code","ca82a75a":"code","0a964d92":"code","88e731b7":"code","e0d62d14":"code","5d5c2067":"code","c58ef53c":"code","31b044f3":"code","1a78a998":"code","145d182a":"code","edc3fbfa":"code","f662ebca":"code","3d31777c":"code","8720cc24":"code","d1f6ce6c":"code","29d2412b":"code","22c94473":"code","b965cea2":"code","55d1e074":"code","18e561df":"code","4ff2b964":"code","1da1af1f":"code","1d13a708":"code","49e28f35":"code","3175725b":"code","101eb718":"code","c2aabd74":"code","223fbbbe":"code","0616743d":"code","d12bb363":"code","de3ebb29":"code","7d19d339":"code","812c771f":"code","6756a767":"code","d256a46d":"code","2d6f6ba7":"code","86913840":"code","88d93af5":"code","b6a9b74c":"code","24ba27f9":"code","38da2330":"code","98612f86":"markdown","cf20272f":"markdown","58541ba4":"markdown","3fdeeac8":"markdown","09f428af":"markdown","0462fb5a":"markdown","5283872c":"markdown","697695ea":"markdown","b0fdcaa4":"markdown","e3a6a6b3":"markdown","3cad3018":"markdown","25b5791a":"markdown","1abbca4b":"markdown","3faa74e5":"markdown","739a11f7":"markdown","7b3eef4f":"markdown","9cc29730":"markdown","880416d7":"markdown","78849123":"markdown","7afd09ac":"markdown","ef0dce37":"markdown","d0060f16":"markdown","b8516c2f":"markdown"},"source":{"a671c4f2":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport datetime\nimport math\nimport calendar\n\n# Thanks for providing this in the forum\ndef ToWeight(y):\n    w = np.zeros(y.shape, dtype=float)\n    ind = y != 0\n    w[ind] = 1.\/(y[ind]**2)\n    return w\n\ndef rmspe(yhat, y):\n    w = ToWeight(y)\n    rmspe = np.sqrt(np.mean( w * (y - yhat)**2 ))\n    return rmspe\n\ndef rmspe_xg(yhat, y):\n    y = y.get_label()\n    y = np.exp(y) - 1\n    yhat = np.exp(yhat) - 1\n    w = ToWeight(y)\n    rmspe = np.sqrt(np.mean(w * (y - yhat)**2))\n    return \"rmspe\", rmspe","32a584a1":"train = pd.read_csv('\/kaggle\/input\/rossmann-store-sales\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/rossmann-store-sales\/test.csv')\nstore = pd.read_csv('\/kaggle\/input\/rossmann-store-sales\/store.csv')\n\ntrain.shape, test.shape, store.shape","04e28345":"train.Store.nunique() == store.Store.nunique()","e1e0b474":"df = train.merge(store, how='left', left_on=train.Store, right_on=store.Store)\ndf.drop(['key_0', 'Store_y'], axis=1, inplace=True)\ndf = df.rename(columns={'Store_x':'Store'})\ndf.shape","02390cd0":"round(df.describe().T,2)","00b29834":"train.duplicated().sum(), test.duplicated().sum()","551e9c6f":"train.isnull().sum().sum(), test.isnull().sum().sum()","a47fc822":"print(\"Training data starts from: {}\".format(train.Date.min()))\nprint(\"Training data end on: {}\".format(train.Date.max()))\nprint()\nprint(\"Testing data starts from: {}\".format(test.Date.min()))\nprint(\"Testing data end on: {}\".format(test.Date.max()))","d8154cef":"df.Date = pd.to_datetime(df.Date)\ndf['Day'] = df.Date.dt.day\ndf['Month'] = df.Date.dt.month\ndf['Year'] = df.Date.dt.year","c927b1ec":"plt.figure(figsize=(18,8))\nplt.plot(df.groupby(df.Day).sum().Sales)\nplt.title(\"Sale vs Day\")\nplt.xlabel('Day')\nplt.ylabel('Sales')\nplt.show()","05e125d3":"plt.figure(figsize=(18,8))\nplt.plot(df.groupby(df.DayOfWeek).sum().Sales)\nplt.title(\"Sale vs Month\")\nplt.xlabel('Month')\nplt.ylabel('Sales')\nplt.show()","81722edf":"plt.figure(figsize=(18,8))\nplt.plot(df.groupby(df.Month).sum().Sales)\nplt.title(\"Sale vs Month\")\nplt.xlabel('Month')\nplt.ylabel('Sales')\nplt.show()","b9a067a0":"fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18,8))\nsns.boxplot(train.Sales, ax=ax1)\nsns.kdeplot(train.Sales, ax=ax2)\nplt.show()","38b6657e":"df[df.Open==0].Sales.value_counts()","8d9d0151":"fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18,8))\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\ncorr = train.corr()\nmask = np.triu(np.ones_like(corr, dtype=bool))\nsns.heatmap(train.corr(), mask=mask, cmap=cmap, annot=True, ax=ax1)\nax1.set_title('Train')\ncorr = test.corr()\nmask = np.triu(np.ones_like(corr, dtype=bool))\nsns.heatmap(test.corr(), mask=mask, cmap=cmap, annot=True, ax=ax2)\nax2.set_title('Test')\nplt.show()","5260e3b8":"plt.figure(figsize=(18,8))\ntemp_df = df.sample(100000)\nsns.scatterplot(temp_df.Sales, temp_df.Customers, hue=df.Year)\nplt.title(\"Sales Vs Customers\")\nplt.show()","acfcbe68":"plt.figure(figsize=(18,8))\ntemp_df = df.groupby(df.Year).sum()\nsns.barplot(temp_df.index, temp_df.Sales, palette='Blues')\nplt.title(\"Total SALE in Each Year\")\nplt.xlabel('Year')\nplt.ylabel('Sales')\nplt.show()","fd9e7938":"fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18,8))\ntemp_df = df.sample(100000)\nsns.scatterplot(temp_df.Sales, temp_df.Customers, hue=df.Promo, ax=ax1)\nsns.scatterplot(temp_df.Sales, temp_df.Customers, hue=df.Promo2, ax=ax2)\nplt.show()","3ab24d2d":"df.groupby(df.Promo).Sales.mean()[1] > df.groupby(df.Promo2).Sales.mean()[1] #1 means store participated","d4bd425f":"plt.figure(figsize=(18,8))\ntemp_df = df.groupby(df.StoreType).sum()\nsns.barplot(temp_df.index, temp_df.Sales, palette='Blues')\nplt.title(\"Store Type vs Sales\")\nplt.xlabel('Store Type')\nplt.ylabel('Sales')\nplt.show()","136635d4":"fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18,8))\ntemp_df = df.groupby(df.StoreType).count()\nsns.barplot(temp_df.index, temp_df['Promo'], ax=ax1, palette='Blues')\ntemp_df = df.groupby(df.StoreType).mean()\nsns.barplot(temp_df.index, temp_df['CompetitionDistance'], ax=ax2, palette='Blues')\nplt.show()","048d54bb":"from statsmodels.tsa.seasonal import seasonal_decompose\ntemp_df = train.copy()\ntemp_df.Date = pd.to_datetime(temp_df.Date)\ntemp_df.index = temp_df.Date\ntemp_df.Sales = temp_df.Sales.apply(lambda x: None if x == 0 else x)\ntemp_df.Sales = temp_df.Sales.fillna(method='ffill').fillna(method='bfill')\ntemp_df = temp_df[['Sales']]\ntemp_df = temp_df.groupby(temp_df.index).sum()\nresult = seasonal_decompose(temp_df, model='additive', freq=52)\n\nfig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(18,8))\nax1.plot(result.trend)\nax1.axhline(y = temp_df.Sales.mean(), color = 'r', linestyle = '-', label='Sales Mean')\nax1.set_title(\"Trend\")\nax2.plot(result.resid)\nax2.set_title(\"Error\")\nax1.legend()\nplt.show()","24ca7096":"temp_df = df.copy()\ntemp_df.index = temp_df.Date\ntemp_df.Sales = temp_df.Sales.apply(lambda x: None if x == 0 else x)\ntemp_df.Sales = temp_df.Sales.fillna(method='ffill').fillna(method='bfill')\ntemp_df = temp_df.groupby(temp_df.index).mean()\n\nfig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18,8))\nax1.plot(temp_df.CompetitionDistance, '.')\nax1.set_title(\"Date vs CompetitonDistance (on average)\")\nax2.plot(temp_df.CompetitionOpenSinceMonth, '.')\nax2.set_title(\"Date vs CompetitionOpenSinceMonth (on average)\")\nplt.show()","3ca80e81":"plt.figure(figsize=(18,8))\ntemp_df = df.copy()\ntemp_df.index = temp_df.Date\ntemp_df = temp_df[temp_df.Year==2014]\ntemp_df = temp_df.groupby(temp_df.Month).sum()\ntemp_df.Sales = temp_df.Sales.apply(lambda x: None if x == 0 else x)\ntemp_df.Sales = temp_df.Sales.fillna(method='ffill').fillna(method='bfill')\n\nplt.title('Total Promos done in YEAR 2014')\nsns.lineplot(temp_df.index, temp_df.Promo, palette='Blues', label='Promo1')\nsns.lineplot(temp_df.index, temp_df.Promo2, palette='Blues', label='Promo2')\nplt.legend()\nplt.show()","d0215ad2":"features_x = ['Store', 'Date', 'DayOfWeek', 'Open', 'Promo', 'SchoolHoliday', 'StateHoliday']\nfeatures_y = ['SalesLog']","39f54ef6":"train['is_train'] = 1\ntest['is_train'] = 0\ndf = pd.concat([train, test])","c5de48d5":"df.Date = pd.to_datetime(df.Date) #Converting date to required format","76be10ab":"df = df.loc[~((df['Open'] == 1) & (df['Sales'] == 0))] #Removing rows with Sales 0","ca82a75a":"df.StateHoliday = df.StateHoliday.map({0:'0', 'a':'a', 'b':'b', 'c':'c', '0':'0'}) #mixed data types\ndf.StateHoliday = LabelEncoder().fit_transform(df.StateHoliday) #Encoding for XG Boost","0a964d92":"var_name = 'Date'\n\ndf[var_name + 'Day'] = df[var_name].dt.day #addding day\ndf[var_name + 'Week'] = df[var_name].dt.week #adding week\ndf[var_name + 'Month'] = df[var_name].dt.month #adding month\ndf[var_name + 'Year'] = df[var_name].dt.year #adding year\ndf[var_name + 'DayOfYear'] = df[var_name].dt.dayofyear #adding dayofyear\n\nfeatures_x.remove(var_name) #removing Date\nfeatures_x.append(var_name + 'Day')\nfeatures_x.append(var_name + 'Week')\nfeatures_x.append(var_name + 'Month')\nfeatures_x.append(var_name + 'Year')\nfeatures_x.append(var_name + 'DayOfYear')","88e731b7":"store.StoreType = LabelEncoder().fit_transform(store.StoreType) #encoding StoreType\nstore.Assortment = LabelEncoder().fit_transform(store.Assortment) #encoding Assortment","e0d62d14":"join_with = store['PromoInterval'].str.split(',').apply(pd.Series)\njoin_with.columns = join_with.columns.map(lambda x: str(x) + '_PromoInterval')\nstore = store.join(join_with) #joining splits","5d5c2067":"def monthToNum(value):\n    if(value=='Sept'):\n        value='Sep'\n    return list(calendar.month_abbr).index(value)\n#mapping month abbr to month number\nstore['0_PromoInterval'] = store['0_PromoInterval'].map(lambda x: monthToNum(x) if str(x) != 'nan' else np.nan)\nstore['1_PromoInterval'] = store['1_PromoInterval'].map(lambda x: monthToNum(x) if str(x) != 'nan' else np.nan)\nstore['2_PromoInterval'] = store['2_PromoInterval'].map(lambda x: monthToNum(x) if str(x) != 'nan' else np.nan)\nstore['3_PromoInterval'] = store['3_PromoInterval'].map(lambda x: monthToNum(x) if str(x) != 'nan' else np.nan)","c58ef53c":"competition_open = []\nfor index, value in store[['CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear']].iterrows():\n    try:\n        year, month = int(value['CompetitionOpenSinceYear']), int(value['CompetitionOpenSinceMonth'])\n        date = pd.to_datetime(\"{}-{}-01\".format(year, month), format='%Y-%m')\n        competition_open.append(date)\n    except:\n        competition_open.append(np.nan)\ncompetition_open = pd.Series(competition_open)\ncompetition_open.shape","31b044f3":"store['CompetitionOpen'] = competition_open #converted int to datetime\nstore['CompetitionOpen'] = store.CompetitionOpen.dt.strftime('%Y%m%d')","1a78a998":"promo = []\nfor index, value in store[['Promo2SinceWeek', 'Promo2SinceYear']].iterrows():\n    try:\n        year, week = int(value['Promo2SinceYear']), int(value['Promo2SinceWeek'])\n        date = pd.to_datetime(\"{}-{}-01\".format(year, week), format='%Y%W')\n        promo.append(date)\n    except:\n        promo.append(np.nan)\npromo = pd.to_datetime(pd.Series(competition_open))\npromo.shape","145d182a":"store['PromoSince'] = promo #converted int to datetime\nstore['PromoSince'] = store.PromoSince.dt.strftime('%Y%m%d')","edc3fbfa":"store_features = ['Store', 'StoreType', 'Assortment', 'CompetitionDistance', 'CompetitionOpen', \n                  'PromoSince', '0_PromoInterval']\n#1_PromoInterval, 2_PromoInterval, 3_PromoInterval irrelevent","f662ebca":"df = pd.merge(df, store[store_features], how='left', on=['Store'])","3d31777c":"features_x = list(set(features_x + store_features))","8720cc24":"for feature in features_x:\n    df[feature] = df[feature].fillna(-999) #out of range value for model","d1f6ce6c":"df['DateInt'] = df.Date.dt.strftime('%Y%m%d').map(int) #mapping to Int\ndf['CompetitionOpen'] = df.CompetitionOpen.map(int)\ndf['PromoSince'] = df.PromoSince.map(int)","29d2412b":"df['Zscore'] = (df.Sales - df.Sales.mean())\/df.Sales.std()","22c94473":"thresh=4.0\ndef check_outlier(value):\n    if(value>=thresh):\n        return True\n    else:\n        return False\n\ndf['Outlier'] = df.Zscore.apply(check_outlier)","b965cea2":"store_data_sales = df.groupby([df['Store']])['Sales'].sum()\nstore_data_customers = df.groupby([df['Store']])['Customers'].sum()\nstore_data_open = df.groupby([df['Store']])['Open'].count()\n\nstore_data_sales_per_day = store_data_sales \/ store_data_open\nstore_data_customers_per_day = store_data_customers \/ store_data_open\nstore_data_sales_per_customer_per_day = store_data_sales_per_day \/ store_data_customers_per_day\n\ndf_store = pd.merge(store, store_data_sales_per_day.reset_index(name='SalesPerDay'), how='left', on=['Store'])\ndf_store = pd.merge(df_store, store_data_customers_per_day.reset_index(name='CustomersPerDay'), how='left', on=['Store'])\ndf_store = pd.merge(df_store, store_data_sales_per_customer_per_day.reset_index(name='SalesPerCustomersPerDay'), how='left', on=['Store'])","55d1e074":"store_features = ['Store', 'SalesPerDay', 'CustomersPerDay', 'SalesPerCustomersPerDay']\n\nfeatures_x = list(set(features_x + store_features))\ndf = pd.merge(df, df_store[store_features], how='left', on=['Store'])","18e561df":"holidays_each_day_of_week = df.groupby(df.DayOfWeek).sum().StateHoliday\ndf = pd.merge(df, holidays_each_day_of_week.reset_index(name='HolidaysPerDayOfWeek'), on=['DayOfWeek'])","4ff2b964":"school_holidays_each_day_of_week = df.groupby(df.DayOfWeek).sum().SchoolHoliday\ndf = pd.merge(df, school_holidays_each_day_of_week.reset_index(name='SchoolHolidaysPerDayOfWeek'), on=['DayOfWeek'])","1da1af1f":"promo_each_day_of_week = df.groupby(df.DayOfWeek).sum().Promo\ndf = pd.merge(df, promo_each_day_of_week.reset_index(name='PromoPerDayOfWeek'), on=['DayOfWeek'])","1d13a708":"holidays_next_week=[]\nholidays_next_week_index=[]\nfor index, value in df.groupby(df.Date).sum().iterrows():\n    start_range = index + datetime.timedelta(days=7)\n    end_range = index + datetime.timedelta(days=15)\n    school_holidays = sum((df.groupby(df.Date).sum()[start_range:end_range]).SchoolHoliday)\n    state_holidays = sum((df.groupby(df.Date).sum()[start_range:end_range]).StateHoliday)\n    holidays_next_week.append(school_holidays+state_holidays)\n    holidays_next_week_index.append(index)\n    \nholidays_next_week = pd.Series(holidays_next_week)\nholidays_next_week.shape","49e28f35":"holidays_this_week=[]\nindex_list = []\nfor index, value in df.groupby(df.Date).sum().iterrows():\n    start_range = index \n    end_range = index + datetime.timedelta(days=7)\n    school_holidays = sum((df.groupby(df.Date).sum()[start_range:end_range]).SchoolHoliday)\n    state_holidays = sum((df.groupby(df.Date).sum()[start_range:end_range]).StateHoliday)\n    holidays_this_week.append(school_holidays+state_holidays)\n    index_list.append(index)\n    \nholidays_this_week = pd.Series(holidays_this_week)\nholidays_this_week.shape","3175725b":"holidays_last_week=[]\nholidays_last_week_index=[]\nfor index, value in df.groupby(df.Date).sum().iterrows():\n    start_range = index - datetime.timedelta(days=7)\n    end_range = index + datetime.timedelta(days=1)\n    school_holidays = sum((df.groupby(df.Date).sum()[start_range:end_range]).SchoolHoliday)\n    state_holidays = sum((df.groupby(df.Date).sum()[start_range:end_range]).StateHoliday)\n    holidays_last_week.append(school_holidays+state_holidays)\n    holidays_last_week_index.append(index)\n    \nholidays_last_week = pd.Series(holidays_next_week)\nholidays_last_week.shape","101eb718":"temp_df = pd.DataFrame({'HolidaysNextWeek':holidays_next_week, 'Date': holidays_next_week_index})\ndf = pd.merge(df, temp_df, on=['Date'])","c2aabd74":"temp_df = pd.DataFrame({'HolidaysThisWeek':holidays_this_week, 'Date': index_list})\ndf = pd.merge(df, temp_df, on=['Date'])","223fbbbe":"temp_df = pd.DataFrame({'HolidaysLastWeek':holidays_last_week, 'Date': holidays_last_week_index})\ndf = pd.merge(df, temp_df, on=['Date'])","0616743d":"holidays_features = ['HolidaysPerDayOfWeek', 'SchoolHolidaysPerDayOfWeek', 'PromoPerDayOfWeek', \n                     'HolidaysNextWeek', 'HolidaysThisWeek', 'HolidaysLastWeek']\n\nfeatures_x = list(set(features_x + holidays_features))","d12bb363":"#Most Promos are done on DayofWeek 4\ndf['DaysTillMaxPromo'] = df.DayOfWeek.apply(lambda x: 4-x)","de3ebb29":"df['PromoTomorrow'] = df.Promo.shift(-1)\ndf['PromoYesterday'] = df.Promo.shift(1)","7d19d339":"promo_features = ['DaysTillMaxPromo', 'PromoTomorrow', 'PromoYesterday']\n\nfeatures_x = list(set(features_x + promo_features))","812c771f":"df.Sales = df.Sales.apply(lambda x: np.nan if x == 0 else x) #Convert 0 to NaNs","6756a767":"df.loc[df['is_train'] == 1, 'SalesLog'] = np.log(1+df.loc[df['is_train'] == 1]['Sales']) #Transforming Sales to 1+log","d256a46d":"len(features_x)","2d6f6ba7":"df.shape","86913840":"df.isnull().sum().sum()","88d93af5":"import xgboost as xgb","b6a9b74c":"data = df.loc[(df['is_train'] == 1) & (df['Open'] == 1) & (df['Outlier'] == False)]\nx_train, x_test, y_train, y_test = train_test_split(data[features_x], \n                                                    data[features_y], \n                                                    test_size=0.1, \n                                                    random_state=42)\nprint(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n\ndtrain = xgb.DMatrix(x_train, y_train)\ndtest = xgb.DMatrix(x_test, y_test)\n\nnum_round = 20000\nevallist = [(dtrain, 'train'), (dtest, 'test')]\n\nparam = {'max_depth': 9,\n         'eta': 0.01,\n         'subsample': 0.75,\n         'colsample_bytree': 0.6, \n         'objective': 'reg:squarederror',}\n\nplst = list(param.items())\n\nmodel = xgb.train(plst, dtrain, num_round, evallist, \n                  feval=rmspe_xg, verbose_eval=250, early_stopping_rounds=250)","24ba27f9":"#Print Feature Importance\nplt.figure(figsize=(18,8))\nfrom xgboost import plot_importance\nplot_importance(model)\nplt.show()","38da2330":"submit = df.loc[df['is_train'] == 0]\ndsubmit = xgb.DMatrix(submit[features_x])\npredictions = model.predict(dsubmit)\n\ndf_predictions = submit['Id'].reset_index()\ndf_predictions['Id'] = df_predictions['Id'].astype('int')\ndf_predictions['Sales'] = (np.exp(predictions) - 1) * 0.985 #Scale Back\n\ndf_predictions.sort_values('Id', inplace=True)\ndf_predictions[['Id', 'Sales']].to_csv('solution.csv', index=False)","98612f86":"There are in total 1115 stores with sales feature having 3849.93 volatility and feature customers having 464.41 volatility with a mean of 57773.82 and 633.15 respectively.","cf20272f":"# Hi!\n\nSales forecasting plays an integral role in setting expectations and making plans for your business. It\u2019s your best shot at predicting the future. Rossmann operates over 3,000 drug stores in 7 European countries. Currently, Rossmann store managers are tasked with predicting their daily sales for up to six weeks in advance. You are provided with historical sales data for 1,115 Rossmann stores. The task is to forecast the \"Sales\" column for the test set. \n\nI will be performing an exhaustive analysis in order to gain insights and engineer features with an interactive exploratory analysis and finally will use XGB to predict. \n\n<b> Please upvote if you like my work! It means a lot!<\/b>","58541ba4":"Store A did the most Promo'1's inspite of being on average top second in comparison to other stores with regard to Competition Distance (distance in meters to the nearest competitor store). Hence, I think it is fair to say promos are a big deal. Other factors could be seasonality, trend etc. Lets see about trend!","3fdeeac8":"Most Sales are done in the beginning of the month with end of the month being the lowest. ","09f428af":"Seems like I was right! 172817 values are filled with 0. I will fill these values with np.NaN as some models like XGBoost can handle missing values and it might benifit from it. ","0462fb5a":"Seems like there was a new competitor near the end of 2014 and since the distance also relatively increased it could be maybe change of location but these are just assumptions. It could be useful for the model to interpret such behaviour in the future for the stores. \n\nI wonder if the stores had done less promos when the trend was going down. Lets see!","5283872c":"I wish to explore seasonality and trend in the dataset and somehow engineer and pre-process features with the analysis I perform.","697695ea":"Why does Store A outperform all other stores?","b0fdcaa4":"Seems like Promo1 was more successful for the stores! Lets check the Sales for each promo on average. ","e3a6a6b3":"### Feature Engineering and Preprocessing","3cad3018":"2015 has been a good year as the trend line is above the average line by the end of 2014. Beginning of 2014 is a huge peak, I wonder what drived that?","25b5791a":"### Understanding the Data","1abbca4b":"There are no duplicates and Testing dataset has 11 null values.","3faa74e5":"Sales are 0 on a huge amount of days which could mean this is either imputed to fill gaps as it doesn't make sense for sale of a day to be 0. It could mean the store was closed, maybe there was a holiday. Lets see if this stands. ","739a11f7":"### Importing Dependencies","7b3eef4f":"Lets see if the type of store is a significant feature! Intuitively, stores inventory and ambience should be a huge factor. ","9cc29730":"Sales are relatively are lower by the end of year. ","880416d7":"# Modelling","78849123":"Sales are more in the beginning of the week than the end. ","7afd09ac":"### Joining","ef0dce37":"### Importing Data","d0060f16":"Sales are highly correlated with feature Customers and feature Open and moderately correlated with Promo. Lets see some more plots about this!","b8516c2f":"### Exploratory Data Analysis"}}