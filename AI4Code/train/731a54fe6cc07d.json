{"cell_type":{"311b6b65":"code","10830658":"code","353ebebc":"code","0ef13969":"code","0c60ccb9":"code","f07d077b":"code","492fc8b0":"code","5d6e34c1":"markdown","e822b99b":"markdown","8258f560":"markdown","9b697cb0":"markdown","64c66559":"markdown","25b57807":"markdown","e692b50b":"markdown","454c474e":"markdown","b2c8d6ce":"markdown","e32dda9d":"markdown"},"source":{"311b6b65":"# Installs\nprint(\"\\n... PIP\/APT INSTALLS STARTING ...\\n\")\n!pip install -q pandarallel\n!pip install -q tensorflow_model_optimization\n!pip install -q --upgrade tensorflow_datasets\n!pip install -q neural-structured-learning\nprint(\"... PIP\/APT INSTALLS COMPLETE ...\\n\")\n\nprint(\"\\n... IMPORTS STARTING ...\\n\")\nprint(\"\\n\\tVERSION INFORMATION\")\n# Machine Learning and Data Science Imports\nimport tensorflow as tf; print(f\"\\t\\t\u2013 TENSORFLOW VERSION: {tf.__version__}\");\nimport tensorflow_addons as tfa; print(f\"\\t\\t\u2013 TENSORFLOW ADDONS VERSION: {tfa.__version__}\");\nimport pandas as pd; pd.options.mode.chained_assignment = None;\nimport numpy as np; print(f\"\\t\\t\u2013 NUMPY VERSION: {np.__version__}\");\n\n# Built In Imports\nfrom kaggle_datasets import KaggleDatasets\nfrom collections import Counter\nfrom datetime import datetime\nfrom glob import glob\nimport warnings\nimport requests\nimport imageio\nimport IPython\nimport urllib\nimport zipfile\nimport pickle\nimport random\nimport shutil\nimport string\nimport math\nimport time\nimport gzip\nimport ast\nimport sys\nimport io\nimport os\nimport gc\nimport re\n\n# Visualization Imports\nfrom matplotlib.colors import ListedColormap\nimport matplotlib.patches as patches\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm; tqdm.pandas();\nimport plotly.express as px\nimport seaborn as sns\nfrom PIL import Image\nimport matplotlib; print(f\"\\t\\t\u2013 MATPLOTLIB VERSION: {matplotlib.__version__}\");\nimport plotly\nimport PIL\nimport cv2\n    \nprint(\"\\n\\n... IMPORTS COMPLETE ...\\n\")\n\nprint(\"\\n... EFFICIENTDET SETUP STARTING ...\")\n\n# SET LIBRARY DIRECTORY\nLIB_DIR = \"\/kaggle\/input\/google-automl-efficientdetefficientnet-oct-2021\"\n\n# To give access to automl files\nsys.path.insert(0, LIB_DIR)\nsys.path.insert(0, os.path.join(LIB_DIR, \"automl-master\"))\nsys.path.insert(0, os.path.join(LIB_DIR, \"automl-master\", \"efficientnetv2\"))\n    \n# EfficientDET Module Imports\nimport cflags\nimport datasets\nimport effnetv2_configs\nimport preprocessing\nimport effnetv2_model\nimport hparams\nimport utils\nfrom main_tf2 import TrainableModel\nprint(\"... EFFICIENTDET SETUP COMPLETE ...\\n\")","10830658":"# See EfficientNetV2 Base Config\nfor k,v in  hparams.base_config.items(): print(k,v)","353ebebc":"def download_weights(model_name):\n    \"\"\" Download the model checkpoints \"\"\"\n    if not os.path.isdir(f\"\/kaggle\/working\/{model_name}\"):\n        !wget https:\/\/storage.googleapis.com\/cloud-tpu-checkpoints\/efficientnet\/v2\/{model_name}.tgz\n        !tar -xvzf .\/{model_name}.tgz\n        !rm -rf .\/{model_name}.tgz\n    return f\"\/kaggle\/working\/{model_name}\"\n\ndef download_label_map_file(return_map=True, output_txtfile_name=\"\/kaggle\/working\/labels_map.txt\"):\n    \"\"\" Download label map and parse \"\"\"\n    if not os.path.isfile(output_txtfile_name):\n        !wget https:\/\/storage.googleapis.com\/cloud-tpu-checkpoints\/efficientnet\/eval_data\/labels_map.txt -O {output_txtfile_name}\n    if return_map:\n        return ast.literal_eval(open(output_txtfile_name, \"r\").read())\n\ndef download_test_images(test_1_path=\"\/kaggle\/working\/test_1.jpg\", test_2_path=\"\/kaggle\/working\/test_2.jpg\"):\n    \"\"\" Download some test images and return paths \"\"\"\n    if not os.path.isfile(test_1_path):\n        !wget https:\/\/upload.wikimedia.org\/wikipedia\/commons\/f\/fe\/Giant_Panda_in_Beijing_Zoo_1.JPG -O {test_1_path}\n    if not os.path.isfile(test_2_path):\n        !wget https:\/\/cdn.britannica.com\/22\/206222-131-E921E1FB\/Domestic-feline-tabby-cat.jpg -O {test_2_path}\n    return test_1_path, test_2_path\n        \n    \n# Define which model and get the required helpers\nmodel_name = \"efficientnetv2-b0\"\nmodel_wt_path = download_weights(model_name)\nlbl_map = download_label_map_file(); _small_lbl_map = {k:v for k,v in lbl_map.items() if k<10}\nimg_path_1, img_path_2 = download_test_images()\nprint(f\"\\n... MODEL NAME: {model_name} ...\")\nprint(f\"... MODEL WEIGHT PATH: {model_wt_path} ...\\n\")\n\nprint(f\"\\n... TESTING IMAGE PATH 1: {img_path_1} ...\")\nprint(f\"... TESTING IMAGE PATH 2: {img_path_2} ...\\n\")\n\nprint(f\"\\n... LBL MAP (FIRST TEN LABELS):\\n\\n{_small_lbl_map} ...\\n\")","0ef13969":"def ev2_load_and_preprocess(img_path, size=224):\n    \"\"\" Load and preprocess an image given a path \"\"\"\n    return preprocessing.preprocess_image(tf.io.read_file(img_path), size, is_training=False)\n\nprint(\"\\n... DEFINE IMAGE SIZE AND LOAD DEMO IMAGES AND PLOT ...\\n\")\nIMG_SIZE = (224,224,3)\ntest_img_1 = ev2_load_and_preprocess(img_path_1)\ntest_img_2 = ev2_load_and_preprocess(img_path_2)\n\nplt.figure(figsize=(20,10))\n\nplt.subplot(1,4,1)\nplt.imshow(cv2.imread(img_path_1)[..., ::-1])\nplt.title(\"Original Test Image 1\", fontweight=\"bold\")\nplt.axis(False)\n\nplt.subplot(1,4,2)\nplt.imshow(test_img_1)\nplt.title(f\"Preprocessed Test Image 1 - (SHAPE={IMG_SIZE})\", fontweight=\"bold\")\nplt.axis(False)\n\nplt.subplot(1,4,3)\nplt.imshow(cv2.imread(img_path_2)[..., ::-1])\nplt.title(\"Original Test Image 2\", fontweight=\"bold\")\nplt.axis(False)\n\nplt.subplot(1,4,4)\nplt.imshow(test_img_2)\nplt.title(f\"Preprocessed Test Image 2 - (SHAPE={IMG_SIZE})\", fontweight=\"bold\")\nplt.axis(False)\n\nplt.tight_layout()\nplt.show()\n\n\n# For some reason this is required or else you will get an AssertionError on weight loading\nprint(\"\\n\\n\\n... CLEAR THE BACKEND KERAS SESSION ...\\n\")\ntf.keras.backend.clear_session()\n\n# Load the model\nprint(\"\\n... LOAD THE MODEL ...\\n\")\nev2 = effnetv2_model.EffNetV2Model(model_name=model_name, name=model_name)\n\n# Build the model with a dummy call (ensure batch size is inline with what you intend to use)\nprint(\"\\n... BUILD THE MODEL ...\\n\")\nev2(tf.ones((1,*IMG_SIZE)), training=False)\n\n# Get the latest checkpoint from path and load into the model\nprint(\"\\n... LOAD PRETRAINED WEIGHTS INTO THE MODEL ...\\n\")\nckpt = tf.train.latest_checkpoint(model_wt_path)\nev2.load_weights(ckpt)\n\n\n# perform inference and take the output layer (index to 0)\nprint(\"\\n... PERFORM INFERENCE W\/ THE MODEL ...\\n\")\npreds_1 = ev2(tf.expand_dims(test_img_1, axis=0), training=False)\npreds_2 = ev2(tf.expand_dims(test_img_2, axis=0), training=False)\n\n# Convert raw predictions into understandable information\ntop_k=3\nprint(\"\\n... CONVERT PREDICTIONS INTO UNDERSTANDABLE INFORMATION ...\\n\")\nprint(\"\\t--> TEST IMAGE 1 - TOP 10 PREDICTIONS\")\nfor x in [f\"\\t\\t#{i+1} MOST CONFIDENT\\n\\t\\t\\t----> LABEL={x[1]}\\n\\t\\t\\t----> SCORE={x[2]:.4f}\" for i, x in enumerate(tf.keras.applications.efficientnet.decode_predictions(preds_1.numpy(), top=top_k)[0])]: print(x)\nprint(\"\\n\\t--> TEST IMAGE 2 - TOP 10 PREDICTIONS\")\nfor x in [f\"\\t\\t#{i+1} MOST CONFIDENT\\n\\t\\t\\t----> LABEL={x[1]}\\n\\t\\t\\t----> SCORE={x[2]:.4f}\" for i, x in enumerate(tf.keras.applications.efficientnet.decode_predictions(preds_2.numpy(), top=top_k)[0])]: print(x)\n\nprint(\"\\n\\n\\n... PLOT THE TOP PREDICTION AS THE TITLE TO THE ORIGINAL IMAGE PLOT ...\\n\\n\")\nplt.figure(figsize=(20,10))\n\nplt.subplot(1,2,1)\nplt.imshow(cv2.imread(img_path_1)[..., ::-1])\nplt.title(f\"Original Test Image 1 - LABEL={lbl_map[tf.argmax(preds_1, axis=-1)[0].numpy()]}\", fontweight=\"bold\")\nplt.axis(False)\n\nplt.subplot(1,2,2)\nplt.imshow(cv2.imread(img_path_2)[..., ::-1])\nplt.title(f\"Original Test Image 2 - LABEL={lbl_map[tf.argmax(preds_2, axis=-1)[0].numpy()]}\", fontweight=\"bold\")\nplt.axis(False)\n\nplt.tight_layout()\nplt.show()","0c60ccb9":"# Load the dataframe\ntrain_df = pd.read_csv(\"..\/input\/petfinder-pawpularity-score\/train.csv\")\n\n# Discard all columns except Id and Pawpularity and rename to id and pawpularity\ntrain_df = train_df[[\"Id\", \"Pawpularity\"]]\ntrain_df.columns = [\"id\", \"pawpularity\"]\ntrain_df[\"pawpularity\"] = train_df[\"pawpularity\"]-1 # zero index\n\n# Create a column containing path information for each id\nTRAIN_IMG_DIR = \"\/kaggle\/input\/petfinder-pawpularity-score\/train\"\ntrain_df[\"img_path\"] = train_df[\"id\"].apply(lambda x: os.path.join(TRAIN_IMG_DIR, x+\".jpg\"))\n\n# Show demo plot\nplt.figure(figsize=(8,8))\nplt.imshow(ev2_load_and_preprocess(train_df.iloc[0].img_path))\nplt.axis(False)\nplt.title(f\"Demo Image With First Row and Load Fn - Image Size={IMG_SIZE}\", fontweight=\"bold\")\nplt.show()\n\nN_VAL = int(len(train_df)\/10)\nval_df = train_df[:N_VAL]\ntrain_df = train_df[N_VAL:]\nN_TRAIN = len(train_df)\nCLASSES = train_df[\"pawpularity\"].unique()\nN_CLASSES = len(CLASSES)\n\nBATCH_SIZE=8\ntrain_x = tf.data.Dataset.from_tensor_slices(train_df.img_path.values)\ntrain_x = train_x.map(lambda x: ev2_load_and_preprocess(x, IMG_SIZE[0]), num_parallel_calls=tf.data.AUTOTUNE)\ntrain_y = tf.data.Dataset.from_tensor_slices(train_df.pawpularity.values.astype(np.uint8))\ntrain_ds = tf.data.Dataset.zip((train_x,train_y)).shuffle(BATCH_SIZE*8).batch(BATCH_SIZE,drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n\nval_x = tf.data.Dataset.from_tensor_slices(val_df.img_path.values)\nval_x = val_x.map(lambda x: ev2_load_and_preprocess(x, IMG_SIZE[0]), num_parallel_calls=tf.data.AUTOTUNE)\nval_y = tf.data.Dataset.from_tensor_slices(val_df.pawpularity.values.astype(np.uint8))\nval_ds = tf.data.Dataset.zip((val_x,val_y)).shuffle(BATCH_SIZE*8).batch(BATCH_SIZE,drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n\nprint(f\"\\n... TRAIN DATASET OBJECT: {train_ds} ...\")\nprint(f\"... VAL   DATASET OBJECT: {val_ds} ...\\n\")","f07d077b":"def get_paw_model(bb_trainable=False, model_name=model_name, dropout=0.2, weights=\"imagenet21k-ft1k\"):\n    \"\"\"\"\"\"\n    tf.keras.backend.clear_session(); gc.collect();\n    _inputs = tf.keras.layers.Input(shape=IMG_SIZE)\n    bb = effnetv2_model.get_model(model_name, include_top=False, weights=weights)\n    \n    if not bb_trainable:\n        bb.trainable=False\n        \n    x = bb(_inputs)\n    x = tf.keras.layers.Dropout(dropout)(x)\n    _outputs = tf.keras.layers.Dense(1, activation=\"relu\")(x)\n    \n    _model = tf.keras.Model(inputs=_inputs, outputs=_outputs)\n    print(_model.summary())\n    return _model\n    \nmodel = get_paw_model()\nmodel.compile(optimizer=\"adam\", loss=tf.keras.losses.MeanSquaredError(), metrics=tf.keras.metrics.RootMeanSquaredError())","492fc8b0":"model.fit(train_ds, validation_data=val_ds, epochs=5)","5d6e34c1":"## <center>LEARN HOW TO LOAD A PRETRAINED EFFICIENTNETV2 MODEL<br><br>AND FINETUNE IT!!<\/center>","e822b99b":"#### Update The Ev2 Model To Allow For Finetuning on A New Task (Regression)\n","8258f560":"### **LOAD A PRETRAINED MODEL AND INFER**","9b697cb0":"#### Finetune the Model\n","64c66559":"#### Create A `tf.data.Dataset` Object For Training and Validation","25b57807":"### **IMPORTS**","e692b50b":"### **EXPLORE THE CONFIG**","454c474e":"#### Build The Model and Infer","b2c8d6ce":"### **FINETUNE THE MODEL FOR A SPECIFIC TASK**\n\n**We will use two tasks and two datasets**\n\n1. Petfinder Pawpularity Score","e32dda9d":"#### Download the Weights, Label File, and A Couple Test Images"}}