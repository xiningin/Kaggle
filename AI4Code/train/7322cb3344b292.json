{"cell_type":{"97ab1c3c":"code","9e3fbb81":"code","156f9477":"code","77a9b8b4":"code","d1c92edb":"code","6ab8dc05":"code","95a9fe63":"code","30bcb59d":"code","1fb6b9a4":"code","d3ab20a6":"code","c9bdf5d4":"markdown","2a8bcda9":"markdown","0616d0dc":"markdown","caf239b4":"markdown","d581fcff":"markdown","9360a30f":"markdown"},"source":{"97ab1c3c":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split # train_test\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression,PassiveAggressiveClassifier,RidgeClassifier,SGDClassifier\nfrom sklearn.neighbors import KNeighborsClassifier,RadiusNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\nfrom sklearn.svm import LinearSVC, SVC,NuSVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_validate\nfrom time import perf_counter\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import Markdown, display\n\ndef printmd(string):\n    # Print with Markdowns    \n    display(Markdown(string))\n\nimport warnings\nwarnings.filterwarnings(action='ignore')","9e3fbb81":"df = pd.read_csv(\"..\/input\/mushroom-classification\/mushrooms.csv\")\n\n# Change the names of the class to be more explicit\n# with \"edible\" and \"poisonous\"\ndf['class'] = df['class'].map({\"e\": \"edible\", \"p\": \"poisonous\"})\ndf.iloc[:5,:8]","156f9477":"df['class'].value_counts().plot.bar(figsize = (10,5), color = ['grey','red'])\nplt.xticks(rotation=0)\nplt.title('Quantity of each class in the dataset', fontsize = 15)\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.show()\n","77a9b8b4":"from sklearn.preprocessing import LabelEncoder\n\nX = df.drop(\"class\", axis = 1).copy()\ny = df['class'].copy()\n\nlabel_encoder_data = X.copy()\nlabel_encoder = LabelEncoder()\nfor col in X.columns:\n    label_encoder_data[col] = label_encoder.fit_transform(label_encoder_data[col])\n    \nX = label_encoder_data\n","d1c92edb":"# Split the dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)","6ab8dc05":"# Create a dictionary with the model which will be tested\nmodels = {\n    \"GaussianNB\":{\"model\":GaussianNB()},\n    \"PassiveAggressiveClassifier\":{\"model\":PassiveAggressiveClassifier() },\n    \"RidgeClassifier\":{\"model\":RidgeClassifier() },\n    \"SGDClassifier\":{\"model\":SGDClassifier() },\n    \"KNeighborsClassifier\":{\"model\":KNeighborsClassifier() },\n    \"DecisionTreeClassifier\":{\"model\":DecisionTreeClassifier() },\n    \"ExtraTreeClassifier\":{\"model\":ExtraTreeClassifier() },\n    \"LinearSVC\":{\"model\":LinearSVC() },\n    \"SVC\":{\"model\":SVC() },\n    \"NuSVC\":{\"model\":NuSVC() },\n    \"MLPClassifier\":{\"model\":MLPClassifier() },\n    \"RandomForestClassifier\":{\"model\":RandomForestClassifier() },\n    \"GradientBoostingClassifier\":{\"model\":GradientBoostingClassifier() },\n    \"AdaBoostClassifier\":{\"model\":AdaBoostClassifier() }\n}\n# Use the 10-fold cross validation for each model\n# to get the mean validation accuracy and the mean training time\nfor name, m in models.items():\n    # Cross validation of the model\n    model = m['model']\n    result = cross_validate(model, X_train,y_train,cv = 10)\n    \n    # Mean accuracy and mean training time\n    mean_val_accuracy = round( sum(result['test_score']) \/ len(result['test_score']), 4)\n    mean_fit_time = round( sum(result['fit_time']) \/ len(result['fit_time']), 4)\n    \n    # Add the result to the dictionary witht he models\n    m['val_accuracy'] = mean_val_accuracy\n    m['Training time (sec)'] = mean_fit_time\n    \n    # Display the result\n    print(f\"{name:27} mean accuracy using 10-fold cross validation: {mean_val_accuracy*100:.2f}% - mean training time {mean_fit_time} sec\")","95a9fe63":"# Create a DataFrame with the results\nmodels_result = []\n\nfor name, v in models.items():\n    lst = [name, v['val_accuracy'],v['Training time (sec)']]\n    models_result.append(lst)\n\ndf_results = pd.DataFrame(models_result, \n                          columns = ['model','val_accuracy','Training time (sec)'])\ndf_results.sort_values(by='val_accuracy', ascending=False, inplace=True)\ndf_results.reset_index(inplace=True,drop=True)\ndf_results","30bcb59d":"plt.figure(figsize = (15,5))\nsns.barplot(x = 'model', y = 'val_accuracy', data = df_results)\nplt.title('Mean Validation Accuracy for each Model\\ny-axis between 0.8 and 1.0', fontsize = 15)\nplt.ylim(0.8,1.005)\nplt.xlabel('Model', fontsize=15)\nplt.ylabel('Accuracy',fontsize=15)\nplt.xticks(rotation=90, fontsize=12)\nplt.show()","1fb6b9a4":"plt.figure(figsize = (15,5))\nsns.barplot(x = 'model', y = 'Training time (sec)', data = df_results)\nplt.title('Training time for each Model in sec', fontsize = 15)\nplt.xticks(rotation=90, fontsize=12)\nplt.xlabel('Model', fontsize=15)\nplt.ylabel('Training time (sec)',fontsize=15)\nplt.show()","d3ab20a6":"# Get the model with the highest mean validation accuracy\nbest_model = df_results.iloc[0]\n\n# Fit the model\nmodel = models[best_model[0]]['model']\nmodel.fit(X_train,y_train)\n\n# Predict the labels with the data set\npred = model.predict(X_test)\n\n# Display the results\nprintmd(f'## Best Model: {best_model[0]} with {best_model[1]*100}% accuracy on the test set')\nprintmd(f'## Trained in: {best_model[2]} sec')\n\n# Display a confusion matrix\nfrom sklearn.metrics import confusion_matrix\ncf_matrix = confusion_matrix(y_test, pred, normalize='true')\nplt.figure(figsize = (10,7))\nsns.heatmap(cf_matrix, annot=True, xticklabels = sorted(set(y_test)), yticklabels = sorted(set(y_test)),cbar=False)\nplt.title('Normalized Confusion Matrix', fontsize = 23)\nplt.xticks(fontsize=20)\nplt.yticks(fontsize=20)\nplt.show()","c9bdf5d4":"# 4. Prediction metrics of the best model using the test set<a class=\"anchor\" id=\"4\"><\/a><a class=\"anchor\" id=\"1\"><\/a>","2a8bcda9":"# 1. Data Description & Visualization<a class=\"anchor\" id=\"1\"><\/a><a class=\"anchor\" id=\"1\"><\/a>","0616d0dc":"# 2. Data Preprocessing<a class=\"anchor\" id=\"2\"><\/a><a class=\"anchor\" id=\"1\"><\/a>","caf239b4":"## Load the libraries:","d581fcff":"# Compare 14 Algorithms for Mushroom classification\n## *Using Cross validation*\n\n![mushrooms](https:\/\/i.imgur.com\/JZuP141.png)\n\n# Table of contents\n\n[<h3>1. Data Description & Visualization<\/h3>](#1)\n\n[<h3>2. Data Preprocessing<\/h3>](#2)\n\n[<h3>3. Model comparison using cross validation<\/h3>](#3)\n\n[<h3>4. Prediction metrics of the best model using the test set<\/h3>](#4)\n\n## Context\nAlthough this dataset was originally contributed to the UCI Machine Learning repository nearly 30 years ago, mushroom hunting (otherwise known as \"shrooming\") is enjoying new peaks in popularity. Learn which features spell certain death and which are most palatable in this dataset of mushroom characteristics. And how certain can your model be?\n\n## Content\nThis dataset includes descriptions of hypothetical samples corresponding to 23 species of gilled mushrooms in the Agaricus and Lepiota Family Mushroom drawn from The Audubon Society Field Guide to North American Mushrooms (1981). Each species is identified as definitely edible, definitely poisonous, or of unknown edibility and not recommended. This latter class was combined with the poisonous one. The Guide clearly states that there is no simple rule for determining the edibility of a mushroom; no rule like \"leaflets three, let it be'' for Poisonous Oak and Ivy.\n\nTime period: Donated to UCI ML 27 April 1987\n\n## Inspiration\n- What types of machine learning models perform best on this dataset?\n- Which features are most indicative of a poisonous mushroom?\n\n## Acknowledgements\nThis dataset was originally donated to the UCI Machine Learning repository.\n\n## Attribute Information: \n(classes: edible=e, poisonous=p)\n\n- cap-shape: bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s\n- cap-surface: fibrous=f,grooves=g,scaly=y,smooth=s\n- cap-color: brown=n,buff=b,cinnamon=c,gray=g,green=r,pink=p,purple=u,red=e,white=w,yellow=y\n- bruises: bruises=t,no=f\n- odor: almond=a,anise=l,creosote=c,fishy=y,foul=f,musty=m,none=n,pungent=p,spicy=s\n- gill-attachment: attached=a,descending=d,free=f,notched=n\n- gill-spacing: close=c,crowded=w,distant=d\n- gill-size: broad=b,narrow=n\n- gill-color: black=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e,white=w,yellow=y\n- stalk-shape: enlarging=e,tapering=t\n- stalk-root: bulbous=b,club=c,cup=u,equal=e,rhizomorphs=z,rooted=r,missing=?\n- stalk-surface-above-ring: fibrous=f,scaly=y,silky=k,smooth=s\n- stalk-surface-below-ring: fibrous=f,scaly=y,silky=k,smooth=s\n- stalk-color-above-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y\n- stalk-color-below-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y\n- veil-type: partial=p,universal=u\n- veil-color: brown=n,orange=o,white=w,yellow=y\n- ring-number: none=n,one=o,two=t\n- ring-type: cobwebby=c,evanescent=e,flaring=f,large=l,none=n,pendant=p,sheathing=s,zone=z\n- spore-print-color: black=k,brown=n,buff=b,chocolate=h,green=r,orange=o,purple=u,white=w,yellow=y\n- population: abundant=a,clustered=c,numerous=n,scattered=s,several=v,solitary=y\n- habitat: grasses=g,leaves=l,meadows=m,paths=p,urban=u,waste=w,woods=d\n\n\n","9360a30f":"# 3. Model comparison using cross validation<a class=\"anchor\" id=\"3\"><\/a><a class=\"anchor\" id=\"3\"><\/a>"}}