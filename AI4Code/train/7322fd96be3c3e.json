{"cell_type":{"b74b3d85":"code","1b42f3f4":"code","0e345dc6":"code","11a5a6d0":"code","3ebaee01":"code","e917b5d0":"code","d1450c14":"code","649d9451":"code","47f9adb0":"code","f1d8c8ad":"code","e0f911db":"code","de1d7b84":"code","bc76676a":"code","f0aa30e9":"code","f3c9d207":"code","0e5db0b0":"markdown","90431cf3":"markdown","7ffe78e9":"markdown","4a497147":"markdown","749ad93e":"markdown","765d510d":"markdown","bf3aced5":"markdown","69e24bda":"markdown","9e787e7e":"markdown"},"source":{"b74b3d85":"!pip install visualkeras","1b42f3f4":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport visualkeras\n\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\n\nfrom sklearn import model_selection\nfrom sklearn import metrics\ndf = pd.read_csv('..\/input\/facial-keypoints-detection\/training.zip', compression='zip', header=0, sep=',', quotechar='\"')\n","0e345dc6":"all_features=df.columns\nprint('---------No. of columns------------\\n')\nprint(list(all_features))\nprint('-------------DataFrame-------------\\n')\nprint(df.iloc[0])","11a5a6d0":"# determine the threshold for missing values\ndef percent_missing(df):\n    data = pd.DataFrame(df)\n    df_cols = list(pd.DataFrame(data))\n    dict_x = {}\n    for i in range(0, len(df_cols)):\n        dict_x.update({df_cols[i]: round(data[df_cols[i]].isnull().mean()*100,2)})\n    \n    return dict_x\n\nmissing = percent_missing(df)\ndf_miss = sorted(missing.items(), key=lambda x: x[1], reverse=True)\nprint('Percent of missing data')\ndf_miss[0:10]","3ebaee01":"print('-----------DataFrame shape--------')\nprint(df.shape[0])\nprint('-----------DataFrame shape after dropping all NA values--------')\nprint(df.dropna().shape[0])","e917b5d0":"df.fillna(method = 'ffill',inplace = True)","d1450c14":"#Helper function\ndef preprocessing_Images(data):\n    data=data.apply(lambda x:np.fromstring(x,dtype=int,sep=' ').reshape(96,96))\n    \n    #Normalize the image\n    data=data\/255\n    \n    # empty array to feed the model of shape(96,96,1)\n    temp= np.empty((len(data),96,96,1))\n\n    #expanding dimensions to (96,96,1)\n    for i in range(len(data)):\n        temp[i,]=np.expand_dims(data[i],axis=2)\n    return temp\n\ndef images_vis(x,y,loc,y_pred,point_show=True):\n    plt.imshow(x[loc], cmap = 'gray')\n    if point_show==True:\n        for j in range(0, 28, 2):\n            plt.plot(y.iloc[loc][j], y.iloc[loc][j+1], 'bo',label='Actual values')\n            plt.plot(y_pred[loc][j], y_pred[loc][j+1], 'rx',label='Predicted values')\n            \ndef images_vis_train(x,y,loc,point_show=True):\n    plt.imshow(x[loc], cmap = 'gray')\n    if point_show==True:\n        for j in range(0, 28, 2):\n            plt.plot(y.iloc[loc][j], y.iloc[loc][j+1], 'bo',label='Actual values')","649d9451":"X=preprocessing_Images(df.Image)\n\ntargets=list(df.columns)\ntargets.remove(\"Image\")\n\ny= df[targets]\n# Split the data into 95 : 05 ratio\nx_train,x_test, y_train, y_test=model_selection.train_test_split(X,y,test_size=0.05,random_state=42)","47f9adb0":"n_rows=2\nn_cols=5\nfig = plt.figure(figsize=(24,6.6), dpi=100)\nfor i, idx in enumerate(np.random.randint(0, len(y_train), n_rows*n_cols)):\n    axis = fig.add_subplot(n_rows, n_cols, i+1, xticks=[], yticks=[])\n    images_vis_train(x=x_train,y=y_train,loc=idx,point_show=True)\n    axis.set_title(f'Sample #{idx}')","f1d8c8ad":"model = Sequential([\n  layers.Conv2D(16, 3, padding='same', activation='relu',input_shape=(96,96,1)),\n  layers.MaxPooling2D(),\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(64, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Flatten(),\n  layers.Dense(64, activation='relu'),\n  layers.Dense(30)\n])\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae', 'acc'])\n\n\nvisualkeras.layered_view(model)","e0f911db":"# Train the model\nhistory = model.fit(x_train, y_train, epochs=15, batch_size=32,validation_split=0.2)","de1d7b84":"history_frame = pd.DataFrame(history.history)\nhistory_frame.loc[:, ['loss', 'val_loss']].plot(title='Loss vs Epochs')\nhistory_frame.loc[:, ['acc', 'val_acc']].plot(title='Accuary vs Epochs');\nhistory_frame.loc[:, ['mae', 'val_mae']].plot(title='MAE vs Epochs');","bc76676a":"test_preds = model.predict(x_test)\nprint(np.sqrt(metrics.mean_squared_error(y_test,test_preds)))","f0aa30e9":"i=4\nplt.figure(figsize=(6,6))\nplt.imshow(x_test[i], cmap = 'gray')\nfor j in range(0, 28, 2):\n    plt.plot(test_preds[i][j], test_preds[i][j+1], 'rx',label='Predicted values')\n    plt.plot(y_test.iloc[i][j], y_test.iloc[i][j+1], 'bo',label='Actual Values')\n    \n# Function add a legend   \nplt.legend([\"Predicted values\", \"Actual Values\"], loc =\"best\") \n  \n# function to show the plot \nplt.show() ","f3c9d207":"n_rows=2\nn_cols=5\nfig = plt.figure(figsize=(24,6.5), dpi=100)\nfor i, idx in enumerate(np.random.randint(0, len(y_test), n_rows*n_cols)):\n    axis = fig.add_subplot(n_rows, n_cols, i+1, xticks=[], yticks=[])\n    images_vis(x=x_test,y=y_test,loc=idx,y_pred=test_preds,point_show=True)\n    axis.set_title(f'Sample #{idx}')\n# Function add a legend   \nplt.legend([\"Predicted values\", \"Actual Values\"], loc =\"best\") \n  \n# function to show the plot \nplt.show() ","0e5db0b0":"# Import all essential libraries and read the data","90431cf3":"Clearly we cannot drop the row with NA vlaues as we will loos the 3000 rows.\n\nWe impute the data with forward fill method","7ffe78e9":"# Predict the data","4a497147":"## Accuracy Graphs","749ad93e":"Sample Images","765d510d":"# Sample Predictions","bf3aced5":"### [Facial Keypoints Detection](https:\/\/www.kaggle.com\/c\/facial-keypoints-detection)\n\n**The objective of this task is to predict keypoint positions on face images.**\n\nSo our input is image of person and goals is here to predict the 30 keypoints on the images","69e24bda":"# Model Building","9e787e7e":"Percent of missing data"}}