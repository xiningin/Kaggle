{"cell_type":{"3279262d":"code","1f6817fe":"markdown"},"source":{"3279262d":"from sklearn import tree\nfrom sklearn import model_selection\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.datasets import load_digits\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndigits = load_digits()\nX, y = digits.data, digits.target\nAlgo = [['DecisionTreeClassifier', tree.DecisionTreeClassifier(),  # algorithm\n             'max_depth', [1, 2, 4, 6, 8, 10, 12, 14, 18, 20, 22, 24, 26, 28, 30],  # Parameter1\n             'max_features', ['sqrt', 'log2', None],  # Parameter2\n                 'criterion', ['gini', 'entropy']]]  # Parameter3\n\n\ndef plot_grid_search(cv_results, grid_param_1, grid_param_2, name_param_1, name_param_2, title):\n    # Get Test Scores Mean and std for each grid search\n\n    grid_param_1 = list(str(e) for e in grid_param_1)\n    grid_param_2 = list(str(e) for e in grid_param_2)\n    scores_mean = cv_results['mean_test_score']\n    scores_std = cv_results['std_test_score']\n    params_set = cv_results['params']\n\n    scores_organized = {}\n    std_organized = {}\n    std_upper = {}\n    std_lower = {}\n    for p2 in grid_param_2:\n        scores_organized[p2] = []\n        std_organized[p2] = []\n        std_upper[p2] = []\n        std_lower[p2] = []\n        for p1 in grid_param_1:\n            for i in range(len(params_set)):\n                if str(params_set[i][name_param_1]) == str(p1) and str(params_set[i][name_param_2]) == str(p2):\n                    mean = scores_mean[i]\n                    std = scores_std[i]\n                    scores_organized[p2].append(mean)\n                    std_organized[p2].append(std)\n                    std_upper[p2].append(mean + std)\n                    std_lower[p2].append(mean - std)\n\n    _, ax = plt.subplots(1, 1)\n\n    # Param1 is the X-axis, Param 2 is represented as a different curve (color line)\n    # plot means\n    for key in scores_organized.keys():\n        ax.plot(grid_param_1, scores_organized[key], '-o', label= name_param_2 + ': ' + str(key))\n        ax.fill_between(grid_param_1, std_lower[key], std_upper[key], alpha=0.1)\n\n    ax.set_title(title)\n    ax.set_xlabel(name_param_1)\n    ax.set_ylabel('CV Average Score')\n    ax.legend(loc=\"best\")\n    ax.grid('on')\n    plt.show()\n\ndataset = 'Digits'\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\ncv_split = model_selection.KFold(n_splits=10, random_state=2)\n\nfor i in range(len(Algo)):\n\n    name = Algo[0][0]\n    alg = Algo[0][1]\n    param_1_name = Algo[0][2]\n    param_1_range = Algo[0][3]\n    param_2_name = Algo[0][4]\n    param_2_range = Algo[0][5]\n    param_3_name = Algo[0][6]\n    param_3_range = Algo[0][7]\n\n    for p in param_3_range:\n        # grid search\n        param = {\n            param_1_name: param_1_range,\n            param_2_name: param_2_range,\n            param_3_name: [p]\n        }\n        grid_test = GridSearchCV(alg, param_grid=param, scoring='accuracy', cv=cv_split)\n        grid_test.fit(X_train, y_train)\n        plot_grid_search(grid_test.cv_results_, param[param_1_name], param[param_2_name], param_1_name, param_2_name, dataset + ' GridSearch Scores: ' + name + ', ' + param_3_name + '=' + str(p))\n\n    param = {\n        param_1_name: param_1_range,\n        param_2_name: param_2_range,\n        param_3_name: param_3_range\n    }\n    grid_final = GridSearchCV(alg, param_grid=param, scoring='accuracy', cv=cv_split)\n    grid_final.fit(X_train, y_train)\n    best_params = grid_final.best_params_\n    alg.set_params(**best_params)\n    print('best_params:', best_params)\n","1f6817fe":"Here's fully working code that will produce a plot showing Parameter1 (x-axis) vs. CrossValidaton Mean Score (y-axis) per Parameter2 (new line for each new Parameter2 value, and showing a legend), per each Parameter3 you have (multiple extra charts will pop up). For each line there is also charted a standard deviation of what you can expect the CV Mean Score to do based on the multiple CV's you're running. Enjoy!"}}