{"cell_type":{"3eb58539":"code","2c5d9ed9":"code","0104548d":"code","c4040313":"code","bc92008c":"code","6f514d44":"code","f8ea0911":"code","2c8ad4d4":"code","8947bfc5":"code","7e9f5bb8":"code","596ac184":"code","f85ccd29":"markdown","2a10ecdf":"markdown","209c17ff":"markdown","06d495ee":"markdown","0cd3e2f4":"markdown","8af5a05d":"markdown"},"source":{"3eb58539":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport torch\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torchvision.models as models\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\ndata_dir = \"\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\"\n\nrandom_seed = 1\ntorch.manual_seed(random_seed)\n","2c5d9ed9":"transformations = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], \n                             [0.229, 0.224, 0.225])\n    ])\n\ntrain_set = datasets.ImageFolder(data_dir + \"\/train\", transform = transformations)\nval_set = datasets.ImageFolder(data_dir + \"\/val\", transform = transformations)\ntest_set = datasets.ImageFolder(data_dir + \"\/test\", transform = transformations)\n\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\nval_loader = torch.utils.data.DataLoader(val_set, batch_size=32, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=True)\n\nclasses = train_set.classes\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available()\n                               else \"cpu\")","0104548d":"model = models.resnet50(pretrained=True, progress=True)","c4040313":"num_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 2)\n\nmodel = model.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)","bc92008c":"for epoch in range(5):\n    running_loss = 0.0\n    counter = 0\n    for i, data in enumerate(train_loader, 0):\n        inputs, labels = data\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        \n        optimizer.zero_grad()\n        \n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        \n        counter += 1\n        if counter % 10 == 0 or counter == len(train_loader):\n            print(counter, \"\/\", len(train_loader))\n        \n    print(running_loss)\nprint('Finished Training')","6f514d44":"class_correct = [0, 0]\nclass_total = [0, 0]\nwith torch.no_grad():\n    for i, data in enumerate(val_loader, 0):\n            inputs, labels = data\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            c = (predicted == labels).squeeze()\n            print(\"Validation Set Size: \", len(labels))\n            for i in range(len(labels)):\n                label = labels[i]\n                class_correct[label] += c[i].item()\n                class_total[label] += 1\nfor i in range(2):\n    print('Accuracy of %5s : %2d %%' % (\n        classes[i], 100 * class_correct[i] \/ class_total[i]))","f8ea0911":"def process_image(image_path):\n    size = 256\n    \n    # Load Image\n    img = Image.open(image_path).convert('RGB')\n    \n    # Get the dimensions of the image\n    width, height = img.size\n    \n    # Resize by keeping the aspect ratio, but changing the dimension\n    img = img.resize((size, int(size*(height\/width))) if width < height else (int(size*(width\/height)), size))\n    \n    # Get the dimensions of the new image size\n    width, height = img.size\n    \n    # Set the coordinates to do a center crop of 224 x 224\n    left = (width - 224)\/2\n    top = (height - 224)\/2\n    right = (width + 224)\/2\n    bottom = (height + 224)\/2\n    img = img.crop((left, top, right, bottom))\n    \n    # Turn image into numpy array\n    img = np.array(img)\n    \n    # Make the color channel dimension first instead of last\n    img = img.transpose((2, 0, 1))\n    \n    # Make all values between 0 and 1\n    img = img\/size\n    \n    # Normalize based on the preset mean and standard deviation\n    img[0] = (img[0] - 0.485)\/0.229\n    img[1] = (img[1] - 0.456)\/0.224\n    img[2] = (img[2] - 0.406)\/0.225\n    \n    # Add a fourth dimension to the beginning to indicate batch size\n    img = img[np.newaxis,:]\n    \n    # Turn into a torch tensor\n    image = torch.from_numpy(img)\n    image = image.float()\n    image = image.to(device)\n    \n    return image","2c8ad4d4":"# Using model to predict label\ndef predict(image, model):\n    # Pass the image through model\n    output = model.forward(image)\n    \n    # Reverse the log function in output\n    output = torch.exp(output)\n    \n    # Get the top predicted class, and the output percentage for\n    # that class\n    probs, classes = output.topk(1, dim=1)\n    return probs.item(), classes.item()","8947bfc5":"# Show Image\ndef show_image(image):\n    # Convert image to numpy\n    image = image.cpu().numpy()\n    \n    # Un-normalize the image\n    image[0] = image[0] * 0.226 + 0.445\n    \n    # Print the image\n    fig = plt.figure(figsize=(25, 4))\n    plt.imshow(np.transpose(image[0], (1, 2, 0)))","7e9f5bb8":"import os\n\naccurate = 0\nfalse_neg = 0\ntrue_neg = 0\nfalse_pos = 0\ntrue_pos = 0\ntotal = 0\n\nclasses = [\"NORMAL\", \"PNEUMONIA\"]\n\nnormal_total = 0\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/test\/NORMAL'):\n    for filename in filenames:\n        # Process Example Image\n        image = process_image(dirname + \"\/\" + filename)\n        # Give image to model to predict output\n        top_prob, top_class = predict(image, model)\n        \n        if top_class == 0:\n            accurate += 1 \n            true_neg += 1\n        else:\n            false_pos += 1\n        normal_total += 1\n        \n        # Print the results\n        # print(\"The model is \", top_prob*100, \"% certain that the image has a predicted class of \", classes[top_class]  )\ntotal += normal_total\n\npneumonia_total = 0\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/test\/PNEUMONIA'):\n    for filename in filenames:\n        # Process Example Image\n        image = process_image(dirname + \"\/\" + filename)\n        # Give image to model to predict output\n        top_prob, top_class = predict(image, model)\n            \n        if top_class == 1:\n            accurate += 1\n            true_pos += 1\n        else:\n            false_neg += 1\n        pneumonia_total += 1\n    \n        # Print the results\n        # print(\"The model is \", top_prob*100, \"% certain that the image \" + filename + \" has a predicted class of \", classes[top_class]  )\ntotal += pneumonia_total\n\nprecision = true_pos * 1.0 \/ (true_pos + false_pos)\nprint(\"Precision (PPV): \" + str(true_pos) + \" \/ \" + str(true_pos + false_pos) + \" = \" +  str(precision))\n\nsensitivity = true_pos * 1.0 \/ (true_pos + false_neg)\nprint(\"Sensitivity (Recall): \" + str(true_pos) +  \" \/ \" + str(true_pos + false_neg) + \" = \" + str(sensitivity))\n\nspecificity = true_neg * 1.0 \/ (true_neg + false_pos)\nprint(\"Specificity: \" + str(true_neg) + \" \/ \" + str(true_neg + false_pos) + \" = \" + str(specificity))\n\nnpv = true_neg * 1.0 \/ (true_neg + false_neg) if true_neg + false_neg != 0 else 0\nprint(\"NPV: \" + str(true_neg) + \" \/ \" + str(true_neg + false_neg) + \" = \" + str(npv))\n\naccuracy = accurate * 1.0 \/ total\nprint(\"Accuracy: \" + str(accurate) + \" \/ \" + str(total) + \" = \" + str(accuracy))\n\nf1 = (2 * precision * sensitivity) \/ (precision + sensitivity)\nprint(\"F-1 Score: \" + str(f1))","596ac184":"examples = enumerate(test_loader)\nbatch_idx, (example_data, example_targets) = next(examples)\n\nexample_data = example_data.to(device)\n\nwith torch.no_grad():\n  output = model(example_data)\n\nfig = plt.figure(figsize=(6,6))\nfor i in range(4):\n  plt.subplot(2,2,i+1)\n  plt.tight_layout()\n  plt.imshow(np.transpose(example_data[i].cpu(), (1, 2, 0)))\n  plt.title(\"Prediction: {}\\nActual: {}\".format(\n    classes[output.data.max(1, keepdim=True)[1][i].item()], classes[example_targets[i]]))","f85ccd29":"## Load Data","2a10ecdf":"## Create Model","209c17ff":"## Check Performance on Test Data","06d495ee":"## Imports","0cd3e2f4":"## Train Model","8af5a05d":"## Validate Model"}}