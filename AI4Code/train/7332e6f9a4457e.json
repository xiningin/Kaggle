{"cell_type":{"3328b34a":"code","308f02f6":"code","2705c0a4":"code","9d2961d0":"code","9ae221c9":"code","ca54b027":"code","77a8c585":"code","58ae0953":"code","d22e7ad6":"code","d49325fd":"code","94d66b9f":"code","07ec2b94":"code","f500efe8":"code","af19a307":"code","68de0f3f":"code","b13ab459":"code","6f687cf6":"code","ecaa31c5":"markdown","ca713145":"markdown","bc06b0e0":"markdown","2baf20b3":"markdown","9d68f87c":"markdown","a3cb9ed4":"markdown","233729b7":"markdown","1963922f":"markdown","36ab49f2":"markdown","db42af2e":"markdown","6df49e96":"markdown","265352aa":"markdown","15900581":"markdown","16a05e7f":"markdown"},"source":{"3328b34a":"import pandas as pd # to read dataframe\nimport numpy as np  # to do array computation \nfrom sklearn.datasets import make_classification # dataste\nfrom sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_val_score, GridSearchCV\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis # the model\n","308f02f6":"data=make_classification()","2705c0a4":"X, y=make_classification(n_samples=1000,n_features=10, n_informative=10, n_redundant=0, random_state=0)\n","9d2961d0":"cv=RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)","9ae221c9":"model=LinearDiscriminantAnalysis()","ca54b027":"score=cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=1)","77a8c585":"np.mean(score), np.std(score)","58ae0953":"model.fit(X, y)","d22e7ad6":"y_pred=model.predict(X)","d49325fd":"row = [0.12777556,-3.64400522,-2.23268854,-1.82114386,1.75466361,0.1243966,1.03397657,2.35822076,1.01001752,0.56768485]\n","94d66b9f":"y_pred=model.predict([row])","07ec2b94":"y_pred","f500efe8":"grid=dict()\ngrid['solver']=['svd', 'lsqr', 'eigen']","af19a307":"search=GridSearchCV(model, grid, scoring='accuracy', cv=cv, n_jobs=-1 )","68de0f3f":"result=search.fit(X,y)","b13ab459":"result.best_score_","6f687cf6":"result.best_params_","ecaa31c5":"# Importing the library","ca713145":"# Best_score \n* It is calssification matrics\n* It brings the best score of he model\n","bc06b0e0":"# Linear Discriminant Analysis\n* a classification machine learning algorithm.\n* works by calculating summary statistics for the input features by class label, such as the mean and standard deviation.\n*  linear algebra operations are used to calculate the required quantities efficiently via matrix decomposition\n*  Predictions are made by estimating the probability that a new example belongs to each class label based on the values of each input feature. \n* The class that results in the largest probability is then assigned to the example\n*  As such, LDA may be considered a simple application of Bayes Theorem for classification\n* LDA assumes that the input variables are numeric and normally distributed and that they have the same variance (spread)\n* standardize or normalize the data prior to modeling.\n# Assumption \n* It also assumes that the input variables are not correlated; \n* Data are assumned to be normally distributed\n","2baf20b3":"# Conclusion \n* The Linear Discriminant Analysis is a simple linear machine learning algorithm for classification.\n* How to fit, evaluate, and make predictions with the Linear Discriminant Analysis model with Scikit-Learn.\n* How to tune the hyperparameters of the Linear Discriminant Analysis algorithm on a given dataset.\n>https:\/\/machinelearningmastery.com\/linear-discriminant-analysis-with-python\/","9d68f87c":"# Follow the procedure as below","a3cb9ed4":"# Use of LDA\n* LDA model is naturally multi-class\n* his means that it supports two-class classification problems and extends to more than two classes\n","233729b7":"# LDA Hyperparameters\n* The hyperparameters for the Linear Discriminant Analysis method must be configured for your specific dataset.\n* An important hyperparameter is the solver, which defaults to \u2018svd\u2018 but can also be set to other values for solvers that support the shrinkage capability.\n# GridsearCV\n* Exhaustive search over specified parameter values for an estimator.\n* used to calculate the best hyperparameters of the models","1963922f":"# The Prediction Metrics ","36ab49f2":"# Make_claasification - \n* Generate a random n-class classification problem.\n* This initially creates clusters of points normally distributed (std=1) about vertices of an n_informative-dimensional hypercube with sides of length 2*class_sep and assigns an equal number of clusters to each class. It introduces interdependence between these features and adds various types of further noise to the data","db42af2e":"# Mean and Std","6df49e96":"# Fitting the model","265352aa":"# again Fitting the model","15900581":"# Prearing to calculate the model score\n* in  LDA model , we compute mean and standard deviation ","16a05e7f":"# Best_parameters\n* It is classification Metrics\n* Used to calculate the best Hyperparamters"}}