{"cell_type":{"03c346de":"code","50e8a1bd":"code","d295e8b0":"code","1fdd84e3":"code","22c18ed1":"code","62338c2a":"code","1f45dd19":"code","da83c29c":"code","23716a23":"code","ab283654":"code","39e30450":"code","d333c9f2":"code","5213e764":"code","262f2f69":"markdown","e9fd6c79":"markdown","dd51aeb2":"markdown","7737a965":"markdown","8233496b":"markdown","ac93968c":"markdown","f2507d10":"markdown","317b876c":"markdown","afc28e30":"markdown","672cc30c":"markdown","eafbb550":"markdown","0355a42b":"markdown","26da43ab":"markdown","1c0a71b8":"markdown","ec7fb8cf":"markdown","4df75d0d":"markdown","70252423":"markdown","9f168e9b":"markdown","264e3978":"markdown","e20b738a":"markdown","aa274143":"markdown","9df0119b":"markdown","f271c045":"markdown","b10a8f67":"markdown","7556f213":"markdown","15312586":"markdown"},"source":{"03c346de":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","50e8a1bd":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\nplt.style.use('fivethirtyeight')","d295e8b0":"df=pd.read_csv('..\/input\/us-accidents\/US_Accidents_Dec20.csv')\ndf.head(2)","1fdd84e3":"print('Rows     :',df.shape[0])\nprint('Columns  :',df.shape[1])\nprint('\\nFeatures :\\n     :',df.columns.tolist())\nprint('\\nMissing values    :',df.isnull().values.sum())\nprint('\\nUnique values :  \\n',df.nunique())","22c18ed1":"df.select_dtypes(exclude=['int','float']).columns","62338c2a":"df['Description'].head()","1f45dd19":"print(df['Source'].unique())\nprint(df['Description'].unique())\nprint(df['Timezone'].unique())\nprint(df['Amenity'].unique())","da83c29c":"total = df.isnull().sum().sort_values(ascending=False)\npercent = ((df.isnull().sum())*100)\/df.isnull().count().sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total','Percent'], sort=False).sort_values('Total', ascending=False)\nmissing_data.head(40)\n","23716a23":"import warnings\nimport warnings\nwarnings.filterwarnings('ignore')\nmissing_df = df.isnull().sum(axis=0).reset_index()\nmissing_df.columns = ['column_name','missing_count']\nmissing_df = missing_df.loc[missing_df['missing_count']>0]\nmissing_df = missing_df.sort_values(by='missing_count')\n\nind = np.arange(missing_df.shape[0])\nwidth = 0.5\nfig,ax = plt.subplots(figsize=(12,18))\nrects = ax.barh(ind,missing_df.missing_count.values,color='blue')\nax.set_yticks(ind)\nax.set_yticklabels(missing_df.column_name.values, rotation='horizontal')\nax.set_xlabel(\"Count of missing values\")\nax.set_title(\"Number of missing values in each column\")\nplt.show()","ab283654":"fig=sns.heatmap(df[['TMC','Severity','Start_Lat','End_Lat','Distance(mi)','Temperature(F)','Wind_Chill(F)','Humidity(%)','Pressure(in)','Visibility(mi)','Wind_Speed(mph)']].corr(),annot=True,cmap='RdYlGn',linewidths=0.2,annot_kws={'size':15})\nfig=plt.gcf()\nfig.set_size_inches(15,7)\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.show()","39e30450":"f,ax=plt.subplots(1,2,figsize=(18,8))\ndf['Source'].value_counts().plot.pie(explode=[0,0.1,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)\nax[0].set_title('Share of Sources')\nax[0].set_ylabel('Count')\nsns.countplot('Source',data=df,ax=ax[1],order=df['Source'].value_counts().index)\nax[1].set_title('Count of Source')\nplt.show()","d333c9f2":"f,ax=plt.subplots(1,3,figsize=(15,5))\ndf['Severity'].value_counts().plot.pie(explode=[0,0.1,0.1,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)\nax[0].set_title('Percentage Severity Distribution')\n#ax[0].set_ylabel('Count')\nsns.countplot('Severity',data=df,ax=ax[1],order=df['Severity'].value_counts().index)\nax[1].set_title('Count of Severity')\ndf.Severity.value_counts(normalize=True).sort_index().plot.bar(ax=ax[2])\nax[2].set_title('Severity Percentage')\nax[2].set_xlabel('Severity')\nax[2].set_ylabel('Percentage')\n#plt.grid()\n#plt.title('Severity')\n#plt.xlabel('Severity')\n#plt.ylabel('Fraction');\nplt.tight_layout()\nplt.show()","5213e764":"fig,ax=plt.subplots(1,2,figsize=(15,8))\nclr = (\"blue\", \"forestgreen\", \"gold\", \"red\", \"purple\",'cadetblue','hotpink','orange','darksalmon','brown')\ndf.State.value_counts().sort_values(ascending=False)[:10].sort_values().plot(kind='barh',color=clr,ax=ax[0])\nax[0].set_title(\"Top 10 Acciedent Prone States\",size=20)\nax[0].set_xlabel('States',size=18)\n\n\ncount=df['State'].value_counts()\ngroups=list(df['State'].value_counts().index)[:10]\ncounts=list(count[:10])\ncounts.append(count.agg(sum)-count[:10].agg('sum'))\ngroups.append('Other')\ntype_dict=pd.DataFrame({\"group\":groups,\"counts\":counts})\nclr1=('brown','darksalmon','orange','hotpink','cadetblue','purple','red','gold','forestgreen','blue','plum')\nqx = type_dict.plot(kind='pie', y='counts', labels=groups,colors=clr1,autopct='%1.1f%%', pctdistance=0.9, radius=1.2,ax=ax[1])\nplt.legend(loc=0, bbox_to_anchor=(1.15,0.4)) \nplt.subplots_adjust(wspace =0.5, hspace =0)\nplt.ioff()\nplt.ylabel('')\npass","262f2f69":"### State ","e9fd6c79":"## Source","dd51aeb2":"### Heat Map","7737a965":"### Displaying Data in Description Column","8233496b":"bove method can be used to display the lables in the categorical feature.","ac93968c":"To can refer to my other notebooks from https:\/\/www.kaggle.com\/binuthomasphilip\/code","f2507d10":"### Finding out columns with Catogerical Values","317b876c":"Some features like location,number,preciptation and windchill have very high number of missing values.","afc28e30":"This is a countrywide traffic accident dataset, which covers 49 states of the United States. The data is continuously being collected from February 2016, using several data providers, including two APIs which provide streaming traffic event data. These APIs broadcast traffic events captured by a variety of entities, such as the US and state departments of transportation, law enforcement agencies, traffic cameras, and traffic sensors within the road-networks. Currently, there are about 2.25 million accident records in this dataset.In this Kernel we will be covering following topic.\n\n1.Data Preprocessing\n\n2.Data Exploration and Vizualization\n\n3.Conclusion\n\nTo can refer to my other notebooks from https:\/\/www.kaggle.com\/binuthomasphilip\/code","672cc30c":"We can see that more accidents are happening in state of California(CA), Texas(TX) and Florida(FL)","eafbb550":"### Summary of Data","0355a42b":"### Count Pie and Bar Plot","26da43ab":"## Severity\n\nIt shows the severity of the accident, a number between 1 and 4, where 1 indicates the least impact on traffic (i.e., short delay as a result of the accident) and 4 indicates a significant impact on traffic (i.e., long delay).","1c0a71b8":"### Importing the dataset","ec7fb8cf":"We can see a very high correlation between the wind_chill and temperature.So when we are using this feature to predict severity than we can drop either wind_chill or the temperare column.","4df75d0d":"The above mentioned columns which have catogerical values","70252423":"Recently I published a self help book titled Inspiration: Thoughts on Spirituality, Technology, Wealth, Leadership and Motivation. The preview of the book can be read from the Amazon link https:\/\/lnkd.in\/gj7bMQA","9f168e9b":"# TO BE CONTINUED","264e3978":"### Missing Values Bar Plot","e20b738a":"### Missing Value Count and Percentage","aa274143":"### Importing modules","9df0119b":"### Displaying Catogerical values","f271c045":"67.5 % Accidents fall in the Severity class 2 followed by Severity class 3,4 and 1.","b10a8f67":"# 1.Data Import Preprocessing","7556f213":"# 2.Data Visulaziation ","15312586":"This is quite a huge dataset with 49 features and more than 35 lac row of data."}}