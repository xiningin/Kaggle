{"cell_type":{"4cd058d1":"code","a17cce21":"code","5f5cb8c2":"code","dba5742e":"code","21613150":"code","052b0586":"code","f0d46b36":"code","11331a4c":"code","7c1de229":"code","9c6abbdf":"code","50bb4092":"code","5455d06b":"code","08deca8b":"markdown","e43e4466":"markdown","7a98e5d1":"markdown"},"source":{"4cd058d1":"# What this is doing? please refer to my above linked kernel\n!pip install ..\/input\/pretrainedmodels\/pretrainedmodels-0.7.4\/pretrainedmodels-0.7.4\/ > \/dev\/null\npackage_path = '..\/input\/unetmodelscript'\nimport sys\nsys.path.append(package_path)","a17cce21":"import pdb\nimport os\nimport cv2\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport torch.backends.cudnn as cudnn\nfrom torch.utils.data import DataLoader, Dataset\nfrom albumentations import (Normalize, Compose)\nfrom albumentations.torch import ToTensor\nimport torch.utils.data as data\nfrom model import Unet","5f5cb8c2":"#https:\/\/www.kaggle.com\/paulorzp\/rle-functions-run-lenght-encode-decode\ndef mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","dba5742e":"class TestDataset(Dataset):\n    '''Dataset for test prediction'''\n    def __init__(self, root, df, mean, std):\n        self.root = root\n        df['ImageId'] = df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n        self.fnames = df['ImageId'].unique().tolist()\n        self.num_samples = len(self.fnames)\n        self.transform = Compose(\n            [\n                Normalize(mean=mean, std=std, p=1),\n                ToTensor(),\n            ]\n        )\n\n    def __getitem__(self, idx):\n        fname = self.fnames[idx]\n        path = os.path.join(self.root, fname)\n        image = cv2.imread(path)\n        images = self.transform(image=image)[\"image\"]\n        return fname, images\n\n    def __len__(self):\n        return self.num_samples","21613150":"def post_process(probability, threshold, min_size):\n    '''Post processing of each predicted mask, components with lesser number of pixels\n    than `min_size` are ignored'''\n    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]\n    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n    predictions = np.zeros((256, 1600), np.float32)\n    num = 0\n    for c in range(1, num_component):\n        p = (component == c)\n        if p.sum() > min_size:\n            predictions[p] = 1\n            num += 1\n    return predictions, num","052b0586":"!ls ..\/input\/unetstartermodelfile\/","f0d46b36":"sample_submission_path = '..\/input\/severstal-steel-defect-detection\/sample_submission.csv'\ntest_data_folder = \"..\/input\/severstal-steel-defect-detection\/test_images\"","11331a4c":"# initialize test dataloader\nbest_threshold = 0.5\nnum_workers = 2\nbatch_size = 4\nprint('best_threshold', best_threshold)\nmin_size = 3500\nmean = (0.485, 0.456, 0.406)\nstd = (0.229, 0.224, 0.225)\ndf = pd.read_csv(sample_submission_path)\ntestset = DataLoader(\n    TestDataset(test_data_folder, df, mean, std),\n    batch_size=batch_size,\n    shuffle=False,\n    num_workers=num_workers,\n    pin_memory=True\n)","7c1de229":"os.listdir(\"..\/input\/\")","9c6abbdf":"# Initialize mode and load trained weights\nckpt_path = \"..\/input\/unet-starter-kernel-pytorch-lb-0-88\/model.pth\"\ndevice = torch.device(\"cuda\")\nmodel = Unet(\"resnet18\", encoder_weights=None, classes=4, activation=None)\nmodel.to(device)\nmodel.eval()\nstate = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\nmodel.load_state_dict(state[\"state_dict\"])","50bb4092":"# start prediction\npredictions = []\nfor i, batch in enumerate(tqdm(testset)):\n    fnames, images = batch\n    batch_preds = torch.sigmoid(model(images.to(device)))\n    batch_preds = batch_preds.detach().cpu().numpy()\n    for fname, preds in zip(fnames, batch_preds):\n        for cls, pred in enumerate(preds):\n            pred, num = post_process(pred, best_threshold, min_size)\n            rle = mask2rle(pred)\n            name = fname + f\"_{cls+1}\"\n            predictions.append([name, rle])\n\n# save predictions to submission.csv\ndf = pd.DataFrame(predictions, columns=['ImageId_ClassId', 'EncodedPixels'])\ndf.to_csv(\"submission.csv\", index=False)","5455d06b":"df.head()","08deca8b":"Do upvote if you liked my kernel :)","e43e4466":"### Refrences:\n\nFew kernels from which I've borrowed some code:\n\n* https:\/\/www.kaggle.com\/amanooo\/defect-detection-starter-u-net\n* https:\/\/www.kaggle.com\/go1dfish\/clear-mask-visualization-and-simple-eda\n\nA big thank you to all those who share their code on Kaggle, I'm nobody without you guys. I've learnt a lot from fellow kagglers, special shout-out to [@Abhishek](https:\/\/www.kaggle.com\/abhishek), [@Yury](https:\/\/www.kaggle.com\/deyury), [@Heng](https:\/\/www.kaggle.com\/hengck23), [@Ekhtiar](https:\/\/www.kaggle.com\/ekhtiar), [@lafoss](https:\/\/www.kaggle.com\/iafoss), [@Siddhartha](https:\/\/www.kaggle.com\/meaninglesslives), [@xhulu](https:\/\/www.kaggle.com\/xhlulu), and the list goes on..","7a98e5d1":"> ### UNet Inference kernel\n\nThis kernel is an inference kernel of my [UNet + RAdam kernel](https:\/\/www.kaggle.com\/asimandia\/unet-radam-kernel-pytorch-lb-0-88). \nIt shows the power of new Sota optimizer.\nDon't forget to add the `model.pth` file generated from the starter kernel as dataset to predict on the test set."}}