{"cell_type":{"8bedeec2":"code","bc4e5d25":"code","d4652159":"code","97d667a5":"code","ffe005f2":"code","d9215bd4":"code","c3ecbbc7":"code","1e7efdba":"code","6c815384":"code","b32374db":"code","7c7fad70":"code","ba678420":"code","4871483d":"code","cab09f37":"code","f8162316":"code","c1550544":"code","929567e2":"code","5549721c":"code","35f954c5":"code","bd0bdc24":"code","1f84b3ff":"code","4e26a780":"code","fa152261":"markdown","caab3365":"markdown","488fa4d0":"markdown","9760c732":"markdown","21ffa780":"markdown","ab7a3cd4":"markdown","45759443":"markdown","61cc95c2":"markdown","53a69702":"markdown","febf9671":"markdown","bfd1ffc9":"markdown","df43ed6e":"markdown","7e0b671f":"markdown","217df94d":"markdown","4fe0d848":"markdown","591c2abf":"markdown","9a24fe72":"markdown","40d4ca51":"markdown"},"source":{"8bedeec2":"%%time\n!pip install '\/kaggle\/input\/pretrainedmodels\/pretrainedmodels-0.7.4\/pretrainedmodels-0.7.4'","bc4e5d25":"from __future__ import print_function, division\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.optim import lr_scheduler\nimport torchvision\nfrom torch.autograd import Variable\nfrom torchvision import datasets, models, transforms\nimport os\nimport numpy as np\nfrom torch import nn\n\nimport time\nimport os\nimport copy\nimport pretrainedmodels\nimport pretrainedmodels.utils as utils\nfrom shutil import copyfile\nos.environ['TORCH_HOME'] = '\/kaggle\/working\/pretrained-model-weights-pytorch'\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","d4652159":"device","97d667a5":"data_dir = \"\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/\"\n\ntrain_transforms= transforms.Compose([transforms.RandomRotation(30),\n                                transforms.RandomHorizontalFlip(),\n                                transforms.Resize((280,280)),\n                                transforms.ToTensor(),\n                                transforms.Normalize([0.5, 0.5, 0.5],\n                                [0.5, 0.5, 0.5])])\n\n\ntest_transforms = transforms.Compose([\n                                transforms.Resize((280,280)),\n                                transforms.ToTensor(),\n                                transforms.Normalize([0.5, 0.5, 0.5],\n                                [0.5, 0.5, 0.5])])\n\ntrain_data=datasets.ImageFolder(data_dir+ 'train',transform=train_transforms)\ntest_data=datasets.ImageFolder(data_dir+ 'validation',transform=test_transforms)","ffe005f2":"for image,label in train_data:\n    print(image.shape)\n    break","d9215bd4":"trainloader=torch.utils.data.DataLoader(dataset=train_data,batch_size=64,shuffle=True)\ntestloader=torch.utils.data.DataLoader(dataset=test_data,batch_size=64,shuffle=True)","c3ecbbc7":"def copy_weights(model_name):\n    found = False\n    for dirname, _, filenames in os.walk('\/kaggle\/input\/pretrained-model-weights-pytorch'):\n        for filename in filenames:\n            full_path = os.path.join(dirname, filename)\n            if filename.startswith(model_name):\n                found = True\n                break\n        if found:\n            break\n            \n    base_dir = \"\/kaggle\/working\/pretrained-model-weights-pytorch\/checkpoints\"\n    os.makedirs(base_dir, exist_ok=True)\n    filename = os.path.basename(full_path)\n    copyfile(full_path, os.path.join(base_dir, filename))","1e7efdba":"print(pretrainedmodels.model_names)","6c815384":"copy_weights('resnet50')\nmodel_name = 'resnet50' # could be fbresnet152 or inceptionresnetv2\nmodel = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\nmodel.eval()\ntf_img = utils.TransformImage(model)","b32374db":"model","7c7fad70":"model =  model.to(device)\nmodel","ba678420":"class attaching_model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear1=nn.Linear(2048,512)\n        self.linear2=nn.Linear(512,256)\n        self.linear3=nn.Linear(256,64)\n        self.linear4=nn.Linear(64,16)\n        self.linear5=nn.Linear(16,2)\n    \n    def forward(self,x):\n        x = F.relu(self.linear1(x))\n        x = F.relu(self.linear2(x))\n        x = F.relu(self.linear3(x))\n        x = F.relu(self.linear4(x))\n        x = self.linear5(x)\n        return x","4871483d":"model_ = attaching_model().to(device)\nmodel_","cab09f37":"model.last_linear=model_\nprint(model)","f8162316":"model.to(device)","c1550544":"for param in model.parameters():\n        param.requires_grad = False\nfor param in model.last_linear.parameters():\n        param.requires_grad = True","929567e2":"criterion = nn.CrossEntropyLoss().to(device)\noptimizer = optim.RMSprop(model.parameters(),lr=0.001)","5549721c":"train_loss = []\nval_loss = []\n\nepochs = 5\n\nfor epoch in range(epochs):\n      print(\"epoch {}\/{}\".format(epoch+1,epochs))\n      running_loss = 0.0\n      running_score = 0.0\n#       model.train()\n      for image,label in trainloader:\n          image = image.to(device)\n          label = label.to(device)\n          optimizer.zero_grad()\n          y_pred = model.forward(image)\n          loss = criterion(y_pred,label)         \n          loss.backward() #calculate derivatives \n          optimizer.step() # update parameters\n          val, index_ = torch.max(y_pred,axis=1)\n          running_score += torch.sum(index_ == label.data).item()\n          running_loss += loss.item()\n      \n      epoch_score = running_score\/len(trainloader.dataset)\n      epoch_loss = running_loss\/len(trainloader.dataset)\n      train_loss.append(epoch_loss)\n      print(\"Training loss: {}, accuracy: {}\".format(epoch_loss,epoch_score))\n      \n      with torch.no_grad():\n          model.eval()\n          running_loss = 0.0\n          running_score = 0.0\n          for image,label in testloader:\n                image = image.to(device)\n                label = label.to(device)\n                optimizer.zero_grad()\n                y_pred = model.forward(image)\n                loss = criterion(y_pred,label)\n                running_loss += loss.item()\n\n                val, index_ = torch.max(y_pred,axis=1)\n                running_score += torch.sum(index_ == label.data).item()\n          \n          epoch_score = running_score\/len(testloader.dataset)\n          epoch_loss = running_loss\/len(testloader.dataset)\n          val_loss.append(epoch_loss)\n          print(\"Validation loss: {}, accuracy: {}\".format(epoch_loss,epoch_score))","35f954c5":"import matplotlib.pyplot as plt\nplt.plot(train_loss,label='train loss')\nplt.plot(val_loss,label='test loss')\nplt.legend()\nplt.show()","bd0bdc24":"class_names = train_data.classes\nclass_names","1f84b3ff":"def imshow(inp, model=model, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    inp = model.std * inp + model.mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001) \n\ndef visualize_model(model, num_images=6):\n    was_training = model.training\n    model.eval()\n    images_so_far = 0\n    fig = plt.figure()\n\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(testloader):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n\n            for j in range(inputs.size()[0]):\n                images_so_far += 1\n                ax = plt.subplot(num_images\/\/2, 2, images_so_far)\n                ax.axis('off')\n                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n                imshow(inputs.cpu().data[j])\n\n                if images_so_far == num_images:\n                    model.train(mode=was_training)\n                    return\n        model.train(mode=was_training)","4e26a780":"visualize_model(model)","fa152261":"## Visualising loss over the epochs.","caab3365":"####  We are going to use Resnet-50 in this kernel,but you can use anyone you want by forking this kernel","488fa4d0":"### checking whether gpu is connected or not..","9760c732":"# Fine Tuning the Last Layer.","21ffa780":"### Well our model performs pretty good,considering this is a beginner dataset and we have a really powerful pretrained model on it.","ab7a3cd4":"# Training Model.","45759443":"# Creating a function to copy weights from the data for torch model.","61cc95c2":"<font color='red'> **  Do Upvote the Kernel and Comment your views in the comment section below . **  <\/font> ","53a69702":"### Visualizing the Final Fine tuned model ready to use.","febf9671":"![image.png](attachment:image.png)","bfd1ffc9":"## The following is a list of pretrained models that we can use.","df43ed6e":"# Importing The Libraries ","7e0b671f":"### Loading the Dataset along with transformations performed on it.","217df94d":"transfering model to gpu(Cuda).","4fe0d848":"## Defining Criterion and Optimizer.","591c2abf":"## Visualizing the model predictions\nGeneric function to display predictions for a few images.","9a24fe72":"Printing model.","40d4ca51":"# Thankyou For Reading,Do upvote the Kernel!!!"}}