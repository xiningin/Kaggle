{"cell_type":{"28f3f8e8":"code","3de181c6":"code","050d1eab":"code","25d0bfeb":"code","8653b2d8":"code","bff48566":"code","9e970c96":"code","bb0484d7":"code","a97b68ec":"code","77508f0e":"code","4e47a087":"code","29d6d890":"code","d0f5506f":"code","0440636f":"code","f0cf4b27":"code","7f0c5a2b":"code","f77b8d24":"code","a48573c0":"code","9cce05a9":"code","4ec16188":"code","826c39de":"code","341a41e7":"markdown","896d0c5d":"markdown","78941476":"markdown","facd5fa9":"markdown","c8684dfd":"markdown","2dcbd8f9":"markdown","5cb7e49b":"markdown","7f15848e":"markdown","81205173":"markdown"},"source":{"28f3f8e8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3de181c6":"import pandas as pd\nimport numpy as np\nimport seaborn as sbn","050d1eab":"df = pd.read_csv(\"\/kaggle\/input\/fish-market\/Fish.csv\")","25d0bfeb":"df.head()","8653b2d8":"df.describe()","bff48566":"df.isnull().sum()","9e970c96":"sbn.distplot(df[\"Weight\"])","bb0484d7":"len(df) * 0.01\ndf = df.sort_values(\"Weight\", ascending=False).iloc[1:]","a97b68ec":"sbn.distplot(df[\"Weight\"])","77508f0e":"y = df[\"Weight\"].values\nx = df.drop([\"Weight\",\"Species\"],axis=1).values","4e47a087":"from sklearn.model_selection import train_test_split","29d6d890":"x_train, x_test, y_train, y_test = train_test_split(x,y,random_state=5,test_size=0.3)","d0f5506f":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()","0440636f":"x_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)","f0cf4b27":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense","7f0c5a2b":"model = Sequential()\n\nmodel.add(Dense(12, activation=\"relu\"))\nmodel.add(Dense(16, activation=\"relu\"))\nmodel.add(Dense(16, activation=\"relu\"))\nmodel.add(Dense(16, activation=\"relu\"))\nmodel.add(Dense(12, activation=\"relu\"))\nmodel.add(Dense(6, activation=\"relu\"))\n\nmodel.add(Dense(1))\n\nmodel.compile(optimizer=\"adam\", loss=\"mse\")","f77b8d24":"model.fit(x=x_train, y=y_train, validation_data=(x_test,y_test), epochs=750)","a48573c0":"lossData = pd.DataFrame(model.history.history)","9cce05a9":"lossData.plot()","4ec16188":"from sklearn.metrics import mean_absolute_error\npredictData = model.predict(x_test)\nmean_absolute_error(y_test, predictData)","826c39de":"df.describe()","341a41e7":"When we look at data. We can see weight's mean, min and max value. And we can examine values.","896d0c5d":"**Reading file**","78941476":"**Looking First 5 Row in Data**","facd5fa9":"Data have not any null values. So we can use easily.","c8684dfd":"**Describe Data**","2dcbd8f9":"Data are normally distributed. But the line is going paralell at Weight axis. So I want to look max Weight rows. I want to use 99 percent of data. So I'm looking at how many data I can extract. Then I remove the row with the highest weight value.","5cb7e49b":"I used a neural network.","7f15848e":"So data are ready for split to test and train.","81205173":"## Import Libraries"}}