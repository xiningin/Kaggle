{"cell_type":{"74dbdd65":"code","53007d54":"code","fb384497":"code","91db6202":"code","0d6c7105":"code","fb242573":"code","93b4045c":"code","43f73016":"code","d3e2d529":"code","c61674f8":"code","03175c43":"code","6fa079da":"code","fd13210a":"code","5683c31a":"code","de660287":"code","8cae4e44":"code","783b0647":"code","ab90eeed":"code","f367fdd4":"code","3dfeb16d":"code","2b480b6f":"code","0741501d":"code","f47e8eb0":"code","59a11bb3":"code","1b0997d2":"code","aaa2f99c":"code","80e3d199":"code","e46ffaf5":"code","2d5fb95f":"code","ed65f74e":"code","1806bc59":"markdown","800c4aa2":"markdown","06af7892":"markdown","3bb7bc1c":"markdown","34982958":"markdown","2e7fe240":"markdown","1eee9d6a":"markdown","bf8bcc3b":"markdown","580e49a9":"markdown","91338d90":"markdown","7a44e3ca":"markdown","bb2dcc8e":"markdown","602c6432":"markdown","0bf324b3":"markdown","a8bec7f8":"markdown","b783ab27":"markdown","d658d56c":"markdown","afa1892a":"markdown","f01aedc3":"markdown"},"source":{"74dbdd65":"# Importar las librer\u00edas necesarias\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split # Para separar Train y Test\nfrom sklearn import metrics # Para medir la efectividad de los modelos\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nimport matplotlib.pyplot as plt \nfrom IPython.display import Image\nimport pydotplus # Si no lo tienen instalado: conda install -c conda-forge pydotplus","53007d54":"data = pd.read_csv('..\/input\/WA_Fn-UseC_-Telco-Customer-Churn.csv')","fb384497":"#Imputamos los nulos que figuran como \"vacios\"\ndata['TotalCharges'] = data['TotalCharges'].replace(' ',-1).astype(float)","91db6202":"# Seleccionamos las variables categ\u00f3ricas\ncat_vars = ['gender', 'Partner', 'Dependents', 'PhoneService','MultipleLines', 'InternetService',\n           'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n           'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n           'PaymentMethod']","0d6c7105":"# Iteramos sobre cada variable creando su dummie         \nfor var in cat_vars:\n    cat_list='var'+'_'+var\n    cat_list = pd.get_dummies(data[var], prefix=var)\n    data1=data.join(cat_list)\n    data=data1","fb242573":"# Descartamos las variables originales\ndata = data.drop(cat_vars, axis = 1)","93b4045c":"# El target tambi\u00e9n los convertimos en una variable num\u00e9rica dummie\ndata['target'] = np.where(data.Churn == 'Yes',1,0)","43f73016":"# Eliminamos la variable Target y el ID de cliente que no arroja informaci\u00f3n (realmente no tiene informaci\u00f3n?)\ndata = data.drop(['Churn', 'customerID'], axis = 1)","d3e2d529":"data.head()","c61674f8":"# Separamos la base en las columnas Independientes y la Dependiente (X e Y)\nX, y = data.drop(data.columns[-1], axis=1), data.iloc[:,-1]","03175c43":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)","6fa079da":"print(\"Tama\u00f1o de Base:\", data.shape)\nprint(\"Tama\u00f1o de Muestra de Entrenamiento:\", X_train.shape)\nprint(\"Tama\u00f1o de Muestra de Testeo\", X_test.shape)\nprint(\"Tama\u00f1o del Target de Entrenamiento:\", y_train.shape)\nprint(\"Tama\u00f1o del Target de Testeo\", y_test.shape)","fd13210a":"#Guardo un objeto con las metricas de mis modelos\nmetricas = {}","5683c31a":"# Entreno un Arbol de Decision\ndtree= DecisionTreeClassifier(max_depth = 3)\ndtree.fit(X_train,y_train)","de660287":"# Predigo sobre la base de Validaci\u00f3n\ny_pred = dtree.predict(X_test)\n\n# Me guardo las Metricas que necesito para graficar\nauc = metrics.roc_auc_score(np.asarray(y_test), y_pred)\nfpr, tpr, thresholds = metrics.roc_curve(np.asarray(y_test), y_pred)\nmetricas ['decisionTree'] = {'fpr': fpr, 'tpr': tpr, 'auc': auc}","8cae4e44":"# Graficamos el Arbol para entenderlo\ndot_data = tree.export_graphviz(dtree, out_file=None, \n                                feature_names= X.columns,\n                                 class_names= ['No','Si'])\n\ngraph = pydotplus.graph_from_dot_data(dot_data)  \nImage(graph.create_png())","783b0647":"# Realizamos una tabla cruzada para ver la efectividad del resultado\npd.crosstab(np.asarray(y_test), y_pred)","ab90eeed":"#Entreno una Regresi\u00f3n Logistica\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)","f367fdd4":"# Predigo sobre la base de Validaci\u00f3n\ny_pred = logreg.predict(X_test)\n\n# Me guardo las Metricas que necesito para graficar\nauc = metrics.roc_auc_score(np.asarray(y_test), y_pred)\nfpr, tpr, thresholds = metrics.roc_curve(np.asarray(y_test), y_pred)\nmetricas['logisticRegresion'] = {'fpr': fpr, 'tpr': tpr, 'auc': auc}","3dfeb16d":"# Realizamos una tabla cruzada para ver la efectividad del resultado\npd.crosstab(np.asarray(y_test), y_pred)","2b480b6f":"# Calculo el Accuracy \n# \u00bfQu\u00e9 porcentaje de predicciones fue correcta? \n# (0 & 0) + (1 & 1) \/ Total = \nmetrics.accuracy_score(np.asarray(y_test), y_pred)","0741501d":"# Calculo el Error Medio Absoluto \n# \u00bfQu\u00e9 porcentaje de predicciones fue incorrecta?\n# (0 & 1) + (1 & 0) \/ Total = \nmetrics.mean_absolute_error(np.asarray(y_test), y_pred)","f47e8eb0":"# Calculo el Recall \n# \u00bfQu\u00e9 porcentaje de casos positivos fueron capturados? \n# (1 & 1) \/ (1 & 0) + (1 & 1) = \nmetrics.recall_score(np.asarray(y_test), y_pred)","59a11bb3":"# Calculo de la Precisi\u00f3n\n# \u00bfQu\u00e9 porcentaje de predicciones positivos fueron correctas? \n# (1 & 1) \/ (0 & 1) + (1 & 1) = \nmetrics.precision_score(np.asarray(y_test), y_pred)","1b0997d2":"#Entreno un Random Forest\nRF = RandomForestClassifier()\nRF.fit(X_train, y_train)","aaa2f99c":"# Predigo sobre la base de Validaci\u00f3n\ny_pred = RF.predict(X_test)\n\n# Me guardo las Metricas que necesito para graficar\nauc = metrics.roc_auc_score(np.asarray(y_test), y_pred)\nfpr, tpr, thresholds = metrics.roc_curve(np.asarray(y_test), y_pred)\nmetricas['RandomForest'] = {'fpr': fpr, 'tpr': tpr, 'auc': auc}","80e3d199":"# Entreno un Modelo de AdaBoost\nAdaB = AdaBoostClassifier()\nAdaB.fit(X_train,y_train)","e46ffaf5":"# Predigo sobre la base de Validaci\u00f3n\ny_pred = AdaB.predict(X_test)\n\n# Me guardo las Metricas que necesito para graficar\nauc = metrics.roc_auc_score(np.asarray(y_test), y_pred)\nfpr, tpr, thresholds = metrics.roc_curve(np.asarray(y_test), y_pred)\nmetricas ['AdaBoost'] = {'fpr': fpr, 'tpr': tpr, 'auc': auc}","2d5fb95f":"# Entreno un Modelo de Gradient Boosting\nGBM = GradientBoostingClassifier()\nGBM.fit(X_train,y_train)\n\n# Me guardo las Metricas que necesito para graficar\ny_pred = GBM.predict(X_test)\nauc = metrics.roc_auc_score(np.asarray(y_test), y_pred)\nfpr, tpr, thresholds = metrics.roc_curve(np.asarray(y_test), y_pred)\nmetricas ['GradientBoosting'] = {'fpr': fpr, 'tpr': tpr, 'auc': auc}","ed65f74e":"# Grafico la Curva ROC con los valores de mis modelos\nfor modelName in metricas:\n    label = 'ROC curve for {0}:'.format(modelName)\n    plt.plot(metricas[modelName]['fpr'], metricas[modelName]['tpr'], label=label+'AUC={0:0.2f}'.format(metricas[modelName]['auc']))\n    plt.xlabel('1-Specificity')\n    plt.ylabel('Sensitivity')\n    plt.ylim([0.0, 1.0])\n    plt.xlim([0.0, 1.0])\n    plt.plot([0, 1], [0, 1], 'k--')\n\nplt.grid(True)\nplt.title('ROC')\nplt.legend(loc=\"lower left\")\nplt.show()\n","1806bc59":"### Importamos los datos","800c4aa2":"### \u00bfQu\u00e9 pasar\u00eda si optimizo los par\u00e1metros con Greedy Search o Random Search?","06af7892":"Cambiar los par\u00e1metros -> Guardar las nuevas m\u00e9tricas -> Volver a graficar las Curvas ROC","3bb7bc1c":"### \u00bfQu\u00e9 pasar\u00eda si comienzo a modificar los par\u00e1metros de estos modelos nuevos?","34982958":"### Entreno los modelos \"Simples\"","2e7fe240":"Los datos fueron descargados de: https:\/\/www.kaggle.com\/blastchar\/telco-customer-churn","1eee9d6a":"### Separamos las bases en Entrenamiento y Testeo","bf8bcc3b":"### Entreno modelos de Baging y Boosting","580e49a9":"Optimizar por Greedy\/Random Search -> Guardar las nuevas m\u00e9tricas -> Volver a graficar las Curvas ROC","91338d90":"#### AdaBoost","7a44e3ca":"#### Regresi\u00f3n Logistica","bb2dcc8e":"### Creamos un objeto Metricas para guardar los resultados","602c6432":"### Importamos las librer\u00edas necesarias","0bf324b3":"# Ejemplo de Modelos Superviados","a8bec7f8":"### Grafico las curvas ROC de los modelos para Compararlos","b783ab27":"#### Arbol de Decision","d658d56c":"### Convertirmos las variables categ\u00f3ricas a Dummies","afa1892a":"#### Random Forest","f01aedc3":"#### Gradient Boosting"}}