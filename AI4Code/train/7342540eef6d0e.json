{"cell_type":{"9216071f":"code","0cb3a55a":"code","34ceb3a4":"code","665bc39c":"code","aff6eba9":"code","1c4686ef":"code","174a2140":"code","28bad612":"code","ac2bd749":"code","5cfad11b":"code","3bc5c4b4":"markdown","ef7c53dc":"markdown","eac28dcb":"markdown","c4efddb7":"markdown","c536736c":"markdown","1d5b0cdb":"markdown","25bde85b":"markdown"},"source":{"9216071f":"import os\nfor dirname, _, filenames in os.walk(\"\/kaggle\/input\"):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport pandas as pd\ndf = pd.read_csv(\"\/kaggle\/input\/clash-royale-battles-upper-ladder-december-2021\/data_ord.csv\").iloc[:,1:]\ndf","0cb3a55a":"# Add constant value to second player's deck so player 2's deck will use the next 106 columns after player 1\nfor c in range(1, 9):\n    df[\"p2card{}\".format(c)] = df[\"p2card{}\".format(c)] + 106","34ceb3a4":"# Generate Columns\ncardlist = pd.read_csv(\"\/kaggle\/input\/clash-royale-battles-upper-ladder-december-2021\/cardlist.csv\").iloc[:,1:]\ncards = cardlist[\"card\"]\ncolumns = []\nfor i in range(1, 3):\n    for card in cards:\n        columns.append(card + str(i))\n        \ncolumns.append(\"trophies1\")\ncolumns.append(\"trophies2\")\ncolumns.append(\"outcome\")\n        \nlen(columns) # Should equal 215: 106*2 cards, 2 trophy values, 1 outcome value","665bc39c":"def enc_row(row_ord=tuple):\n    row_enc = [0] * 215 \n    for c in range(1, 17):\n        if row_ord[c] > 211: print(row_ord[c])\n        row_enc[row_ord[c]] = 1\n    row_enc[212] = row_ord[17] # p2trophies\n    row_enc[213] = row_ord[18] # p1trophies\n    row_enc[214] = row_ord[19] # outcome\n    \n    return row_enc","aff6eba9":"# make the encoded dataframe\n\nrows = []\nfor row in df.itertuples():\n    rows.append(enc_row(row))\n    \ndf_enc = pd.DataFrame(data=rows, columns=columns)\ndf_enc","1c4686ef":"# Split data + Preprocessing\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\n\nX = df_enc.iloc[:,0:214]\ny = df_enc.iloc[:,214]\n\nscaler = MinMaxScaler()\nX = scaler.fit_transform(X)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","174a2140":"# Create Network\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.regularizers import L1\nfrom tensorflow.keras.optimizers import Adam\nimport os\n\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\n\nmodel = Sequential()\nmodel.add(Dense(144, input_dim=214, activation=\"relu\", kernel_regularizer=L1(0.0001), kernel_initializer=\"he_uniform\"))\nmodel.add(Dense(72, activation=\"relu\", kernel_regularizer=L1(0.0001), kernel_initializer=\"he_uniform\"))\nmodel.add(Dense(36, activation=\"relu\", kernel_regularizer=L1(0.0001), kernel_initializer=\"he_uniform\"))\nmodel.add(Dense(36, activation=\"relu\", kernel_regularizer=L1(0.0001), kernel_initializer=\"he_uniform\"))\nmodel.add(Dense(36, activation=\"relu\", kernel_regularizer=L1(0.0001), kernel_initializer=\"he_uniform\"))\nmodel.add(Dense(36, activation=\"relu\", kernel_regularizer=L1(0.0001), kernel_initializer=\"he_uniform\"))\nmodel.add(Dense(1, activation=\"sigmoid\", kernel_regularizer=L1(0.0001)))\nmodel.summary()\n\nmodel.compile(\n    optimizer=Adam(learning_rate=0.00025),\n    loss=\"binary_crossentropy\",\n    metrics=[\"accuracy\"]\n)","28bad612":"# Training\n\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tqdm.keras import TqdmCallback\n\nepochs_hist = model.fit(\n    X_train,\n    y_train,\n    shuffle=True,\n    epochs=128,\n    batch_size=196,\n    verbose=0,\n    validation_split=0.2,\n    callbacks=[TqdmCallback(), EarlyStopping(monitor=\"val_loss\", patience=10)]\n)","ac2bd749":"# Plot loss\n\nfrom matplotlib import pyplot as plt\n\nplt.figure(dpi=100)\nplt.plot(epochs_hist.history['loss'], label=\"Training Loss\")\nplt.plot(epochs_hist.history['val_loss'], label=\"Validation Loss\")","5cfad11b":"# Confusion Matrix on novel data\n\nfrom sklearn.metrics import confusion_matrix\n\ny_pred = model.predict(X_test) \ny_pred = [1 if x >= 0.5 else 0 for x in y_pred]\n\ntn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\nprint(\"True Negative:\", tn)\nprint(\"False Positive:\", fp)\nprint(\"False Negative:\", fn)\nprint(\"True Positive:\", tp)\nprint(\"Final Accuracy:\", (tp+tn)\/(tp+tn+fp+fn))","3bc5c4b4":"## Encoding\nPlayer decks are:\n* unordered\n* distinct; no duplicates\n* a set of 8 cards, selected from a pool of 106 cards\n\nThe current encoding of the dataset **wrongly assumes** player decks and cards are:\n* ordered (False)\n* might not be distinct (False)\n* numerically related (False)\n\nAs a result, the data must be encoded in a better way.\n\nThe best way to do this is through One-Hot Encoding. A deck can be fully described with 106 columns, 1 column per card in the game. In these columns, exactly 8 (1 column per card in the deck) will have a value of `1`, signifying the usage of that card, and the rest will have a value of `0`. **This method of encoding preserves the unordered nature of a deck, as well as how individual cards are not numerically related.** In order to describe the two decks in each sample, `106*2=212` columns will be used.","ef7c53dc":"## Training Results","eac28dcb":"## Neural Network\nAfter fiddling around with various layer sizes, I decided to go with a \"funnel\" shaped network with L1 regularization. This makes the network learn to reduce dimensionality, allowing it to find more abstract relationships, as well as filter out less important features through the more aggresive L1 regularization.","c4efddb7":"# Predicting Clash Royale Battles\nClash Royale is a game of fast paced 1v1 battles. By training on dataset of a player's pre-battle information, including deck configuration and trophy count, can the final outcome of a battle be predicted before it happens? \n\n[Dataset collected by me.](https:\/\/www.kaggle.com\/nonrice\/clash-royale-battles-upper-ladder-december-2021)","c536736c":"## Conclusions\nThis is was one of my first few projects in the world of machine learning. Despite that, scraping my own data and developing a complex model was still a magical experience. Granted that yes, the predictive accuracy I achieved is nothing to gape at, I don't take it heavily, because so many factors in the world of gaming are not, and could not, be reflected in my dataset. However, that is all speculation. Maybe one day, a few years in the future, I will look back at this early project and think *wow... I could have done so much better.*","1d5b0cdb":"## Load Dataset","25bde85b":"## Preprocessing\n"}}