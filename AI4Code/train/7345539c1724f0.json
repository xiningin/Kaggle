{"cell_type":{"abf42aa6":"code","a18a2ce1":"code","5238bf29":"code","bcb6e1c5":"code","96d9fce6":"code","764b4a6c":"code","ab2d4659":"code","61dc09d7":"code","533f96f5":"code","053fb745":"code","f222e0be":"code","38092f5a":"code","0c5bc52f":"code","56b2248e":"code","016a3e01":"code","726eb590":"code","c1f61208":"code","bfe6f2f9":"markdown","2e6cc2ee":"markdown","99b21f0b":"markdown","10846bea":"markdown","35d40595":"markdown","fb8122d0":"markdown","ef3b0465":"markdown","b3520412":"markdown","b4728607":"markdown","d663d887":"markdown","70394f87":"markdown","8c103654":"markdown"},"source":{"abf42aa6":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport spacy\nimport string\nimport re\nfrom wordcloud import WordCloud\nimport os","a18a2ce1":"df = pd.read_csv('\/kaggle\/input\/feedback-prize-2021\/train.csv')\ndf = df[['discourse_start','discourse_end','discourse_text','discourse_type']]\ndf.head()","5238bf29":"df.shape","bcb6e1c5":"df.discourse_type.unique().tolist()","96d9fce6":"sns.set_theme(style=\"whitegrid\")\nplt.figure(figsize=(8,6))\nsns.barplot(y=df['discourse_type'].unique(),\n            x=df['discourse_type'].value_counts())\nplt.xlabel('Count of Discourse Type')\nplt.title('Discourse Type Distribution')\nplt.show()\n","764b4a6c":"fig = px.box(df, y='discourse_type', x='discourse_start',\n            title='Where Each Type Element Starts')\nfig.show()","ab2d4659":"fig = px.box(df, y='discourse_type', x='discourse_end',\n            title='Where Each Type Element Ends')\nfig.show()","61dc09d7":"fig = px.scatter(df.sample(frac=0.01, random_state=20), x='discourse_start', y='discourse_end',\n            title='Correlation between Discourse Start and End',\n            opacity = 0.3,\n            color = 'discourse_type')\nfig.show()","533f96f5":"df['txt_len'] = df['discourse_text'].apply(lambda x: len(x.split()))","053fb745":"fig = px.box(df, y='discourse_type', x='txt_len',\n            title='Length of Each Type of Element')\nfig.show()","f222e0be":"nlp = spacy.load('en_core_web_sm')\nstopwords = nlp.Defaults.stop_words\nprint(f'There are {len(stopwords)} default stop-words before customization.')","38092f5a":"customized_stopwords = ['student', 'people', 'make', 'school', 'teacher', 'be', 'electoral', 'college', 'think']\n\nfor token in customized_stopwords:\n    stopwords.add(token)\n    nlp.vocab[token].is_stop = True\n    \nprint(f'There are {len(stopwords)} stop-words after customization.')","0c5bc52f":"# Create tokenzer function from a given sentence\ndef clean_text(sentence):\n    # Remove nan, @username, punctuation, URL, or any non alpanumeric characters and seperate word using a single space.\n    sentence = sentence.lower()\n    sentence = ' '.join(re.sub(\"(nan)|(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\\/\\\/\\S+)\",\" \", sentence).split())\n    # Removing stop words and obtain the lemma\n    text = [ word.lemma_ for word in nlp(sentence) if not word.text in stopwords]\n    return ' '.join(text).strip()","56b2248e":"# Apply clean_text function to the column.\ndf['text_cleaned'] = df['discourse_text'].map(clean_text)\n\ndf.head()","016a3e01":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n# Define a function returning the top words\ndef get_top_tf_idf_words(df = df, col = \"text\", use_idf = True, ngram_range =(1, 1), top_n= 10):\n    \n    tf_idf = TfidfVectorizer(#stop_words='english',\n        ngram_range = ngram_range, use_idf = use_idf)\n    \n    # Fit and transform the corpus\n    X_sparse_matrix = tf_idf.fit_transform(df[col])\n    feature_names = np.array(tf_idf.get_feature_names())\n    \n    # Generate the tf-idf matrix\n    tf_idf_sparse_matrix = tf_idf.transform(df[col])\n    \n    # Rank the matrix by tf-idf values and return the indices of the top_n values\n    sorted_idx = np.argsort(tf_idf_sparse_matrix.data)[:-(top_n+1):-1]\n    \n    # Return the feature names and corresponding tf_idf values in a df\n    return pd.DataFrame(\n    {'feature': feature_names[tf_idf_sparse_matrix.indices[sorted_idx]],\n     'tf_idf': tf_idf_sparse_matrix.data[sorted_idx],\n    })\n\nTOP_N = 10\ndf_text_lead = get_top_tf_idf_words(df = df[df['discourse_type']=='Lead'], col = \"discourse_text\", top_n= TOP_N)\ndf_text_posi = get_top_tf_idf_words(df = df[df['discourse_type']=='Position'], col = \"discourse_text\", top_n= TOP_N)\ndf_text_evid = get_top_tf_idf_words(df = df[df['discourse_type']=='Evidence'], col = \"discourse_text\", top_n= TOP_N)\ndf_text_clai = get_top_tf_idf_words(df = df[df['discourse_type']=='Claim'], col = \"discourse_text\", top_n= TOP_N)\ndf_text_cclu = get_top_tf_idf_words(df = df[df['discourse_type']=='Concluding Statement'], col = \"discourse_text\", top_n= TOP_N)\ndf_text_cntr = get_top_tf_idf_words(df = df[df['discourse_type']=='Counterclaim'], col = \"discourse_text\", top_n= TOP_N)\ndf_text_rebt = get_top_tf_idf_words(df = df[df['discourse_type']=='Rebuttal'], col = \"discourse_text\", top_n= TOP_N)\n\nx=range(0, TOP_N)\n\nfig, ax = plt.subplots(7, 1, figsize = (10, 25))\nfig.suptitle('Top 10 Bigrams of the TF-IDF', fontsize= 18)\n\nax[0].plot(x, df_text_lead.tf_idf, 'bo')\nax[0].set_title('Lead', fontsize= 14)\nax[0].set_xticks(x)\nax[0].set_xticklabels(df_text_lead.feature, rotation='vertical', fontsize=10)\n\nax[1].plot(x, df_text_posi.tf_idf, 'bo')\nax[1].set_title('Position', fontsize= 14)\nax[1].set_xticks(x)\nax[1].set_xticklabels(df_text_posi.feature, rotation='vertical', fontsize=10)\n\nax[2].plot(x, df_text_evid.tf_idf, 'bo')\nax[2].set_title('Evidence', fontsize= 14)\nax[2].set_xticks(x)\nax[2].set_xticklabels(df_text_evid.feature, rotation='vertical', fontsize=10)\n\nax[3].plot(x, df_text_clai.tf_idf, 'bo')\nax[3].set_title('Claim', fontsize= 14)\nax[3].set_xticks(x)\nax[3].set_xticklabels(df_text_clai.feature, rotation='vertical', fontsize=10)\n\nax[4].plot(x, df_text_cclu.tf_idf, 'bo')\nax[4].set_title('Concluding Statement', fontsize= 14)\nax[4].set_xticks(x)\nax[4].set_xticklabels(df_text_cclu.feature, rotation='vertical', fontsize=10)\n\nax[5].plot(x, df_text_cntr.tf_idf, 'bo')\nax[5].set_title('Counterclaim', fontsize= 14)\nax[5].set_xticks(x)\nax[5].set_xticklabels(df_text_cntr.feature, rotation='vertical', fontsize=10)\n\nax[6].plot(x, df_text_rebt.tf_idf, 'bo')\nax[6].set_title('Rebuttal', fontsize= 14)\nax[6].set_xticks(x)\nax[6].set_xticklabels(df_text_rebt.feature, rotation='vertical', fontsize=10)\n\nfig.subplots_adjust(hspace=1.5)\nplt.show()","726eb590":"elem = df.discourse_type.unique().tolist()\n\nplt.figure(figsize=(15,10))\nfor i in range(1,8):\n    plt.subplot(4, 2, i)\n    plt.imshow(WordCloud().generate(' '.join(df[df.discourse_type == elem[i-1]].discourse_text.apply(lambda x: x.lower()))),\n               interpolation='bilinear')\n    plt.title(elem[i-1])\n    plt.axis('off')\nplt.suptitle('Wordcloud for Each Category before Clean')\nplt.tight_layout()","c1f61208":"plt.figure(figsize=(15,10))\nfor i in range(1,8):\n    plt.subplot(4, 2, i)\n    plt.imshow(WordCloud().generate(' '.join(df[df.discourse_type == elem[i-1]].text_cleaned)),\n               interpolation='bilinear')\n    plt.title(elem[i-1])\n    plt.axis('off')\nplt.suptitle('Wordcloud for Each Category After Clean')\nplt.tight_layout()","bfe6f2f9":"## Remove Stopwords, Tokenization and Lemmatization\n\nFirst, add a few customized stopwords:","2e6cc2ee":"Wordcloud after clean the text:","99b21f0b":"Unique target values:","10846bea":"In conclusion, we can all agree that lead statement start usually at the beginning of an article, where as concluding statement usually is at the very end of an article.\n\nUsually, when a sentence start early, it will end early. So I am not suprised that there is an obvious linear correlation between start and end point for each types. However, there \"Evidence\" seems scattered more and 'Lead' usually is very short.","35d40595":"## Word Clouds for each Type\nWordcloud before clean the text:","fb8122d0":"## Top 10 Uni-grams of the tf-idf of the Text","ef3b0465":"## Position of Each Target Variables\n\nWhere does each element target start at the student's article? Where do they end? In this section, we will plot each element's position in an article.","b3520412":"## Look at the train.csv Data Frame","b4728607":"## What does the Target Variables Mean?\nBasically, there are 7 types of discourse:\n- **Lead**: intro part to hook readers' attention; \n- **Position**: demonstrate you understand the other side's viewpoint, but you explain your own stance; \n- **Evidence**: provide the readers with facts\/data to prove the argument is strong;\n- **Claim**: explain the overall thesis on the subject. The main argument is made in this part;\n- **Concluding Statement**: draw conclusion;\n- **Counterclaim**: the opposite perspective;\n- **Rebuttal**: evidence that disagrees with the counterclaim.\n\nAccording to [Purdue owl writing lab](https:\/\/owl.purdue.edu\/owl\/general_writing\/academic_writing\/establishing_arguments\/organizing_your_argument.html).","d663d887":"## Target Variables Distribution","70394f87":"## How Long Are Each Type of Elements?","8c103654":"Shape of the Data Frame:"}}