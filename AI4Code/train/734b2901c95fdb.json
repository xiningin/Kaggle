{"cell_type":{"93bbd3da":"code","53dfe9dc":"code","5cdeb691":"code","d05150e4":"code","bcefd535":"code","a663ca04":"code","dbde10aa":"code","50dfb698":"code","0fb9def3":"code","9cf9ab69":"code","52d572cd":"code","6157139b":"code","5bcae413":"code","6884e6a8":"code","9089bc3e":"code","c5248bab":"code","9fbbdc9e":"code","fa0c0d22":"code","5658f86a":"code","0feb6eb3":"markdown","0b174674":"markdown","f327037a":"markdown","53c4662e":"markdown","17d93e8c":"markdown","82e67047":"markdown","a513bb73":"markdown","1dd10b89":"markdown","cc2ee3fe":"markdown"},"source":{"93bbd3da":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","53dfe9dc":"import numpy as np \nimport pandas as pd\nimport os\nimport glob\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","5cdeb691":"# Load the dataet along with some other information (training split, width and height of the samples).\ndataset_dir = '\/kaggle\/input\/utkface-new\/UTKFace\/'\n\nTRAIN_TEST_SPLIT = 0.7\nIM_WIDTH = IM_HEIGHT = 198\n","d05150e4":"\n# Creating our dictionary to help us on parsing the information from the dataset\n\n\n\ndataset_dict = {\n    'race_id': {\n        0: 'white', \n        1: 'black', \n        2: 'asian', \n        3: 'indian', \n        4: 'others'\n    },\n    'gender_id': {\n        0: 'male',\n        1: 'female'\n    }\n}\n\ndataset_dict['gender_alias'] = dict((g, i) for i, g in dataset_dict['gender_id'].items())\ndataset_dict['race_alias'] = dict((r, i) for i, r in dataset_dict['race_id'].items())\n","bcefd535":"\n\n\ndef parse_dataset(dataset_path, ext='jpg'):\n    \n    def parse_info_from_file(path):\n        \"\"\"\n        Parse information from a single file\n        \"\"\"\n        try:\n            filename = os.path.split(path)[1]\n            filename = os.path.splitext(filename)[0]\n            age, gender, race, _ = filename.split('_')\n\n            return int(age), dataset_dict['gender_id'][int(gender)], dataset_dict['race_id'][int(race)]\n        except Exception as ex:\n            return None, None, None\n        \n    files = glob.glob(os.path.join(dataset_path, \"*.%s\" % ext))\n    \n    records = []\n    for file in files:\n        info = parse_info_from_file(file)\n        records.append(info)\n        \n    df = pd.DataFrame(records)\n    df['file'] = files\n    df.columns = ['age', 'gender', 'race', 'file']\n    df = df.dropna()\n    \n    return df","a663ca04":"\ndata = parse_dataset(dataset_dir)\ndata.head()","dbde10aa":"\n# specifies the parameters of our graphs\nfig = plt.figure(figsize=(18,6), dpi=1600) \nalpha=alpha_scatterplot = 0.2 \nalpha_bar_chart = 0.55\n\n# lets us plot many diffrent shaped graphs together \nax1 = plt.subplot2grid((2,3),(0,0))\n               \ndata.gender.value_counts().plot(kind='bar', alpha=alpha_bar_chart)\n# this nicely sets the margins in matplotlib to deal with a recent bug 1.3.1\nax1.set_xlim(-1, 2)\n# puts a title on our graph\nplt.title(\"Distribution of gender, (1 = male)\")    \n\nax3 = plt.subplot2grid((2,3),(0,2))\ndata.race.value_counts().plot(kind=\"barh\", alpha=alpha_bar_chart)\nax3.set_ylim(-1, len(data.race.value_counts()))\nplt.title(\"Race Distribution\")","50dfb698":"fig, ax = plt.subplots()\nnum_bins = 50\n\n# the histogram of the data\nn, bins, patches = ax.hist(data.age, num_bins, density=True)\n\n# add a 'best fit' line\ny = data.age.value_counts()\nax.set_xlabel('Age')\nax.set_ylabel('Count')\nax.set_title('Distribution by Age')\nplt.show()","0fb9def3":"\nimport tensorflow as tf\nfrom tensorflow.keras.utils import to_categorical\nfrom PIL import Image\nclass UtkFaceDataGenerator():\n    \"\"\"\n    Data generator for the UTKFace dataset. This class should be used when training our Keras multi-output model.\n    \"\"\"\n    def __init__(self, data):\n        self.data = data\n        \n    def generate_split_indexes(self):\n        p = np.random.permutation(len(self.data))\n        train_up_to = int(len(self.data) * TRAIN_TEST_SPLIT)\n        train_idx = p[:train_up_to]\n        test_idx = p[train_up_to:]\n\n        train_up_to = int(train_up_to * TRAIN_TEST_SPLIT)\n        train_idx, valid_idx = train_idx[:train_up_to], train_idx[train_up_to:]\n        \n        # converts alias to id\n        self.data['gender_id'] = self.data['gender'].map(lambda gender: dataset_dict['gender_alias'][gender])\n        self.data['race_id'] = self.data['race'].map(lambda race: dataset_dict['race_alias'][race])\n\n        self.max_age = self.data['age'].max()\n        \n        return train_idx, valid_idx, test_idx\n    \n    def preprocess_image(self, img_path):\n        \"\"\"\n        Used to perform some minor preprocessing on the image before inputting into the network.\n        \"\"\"\n        im = Image.open(img_path)\n        im = im.resize((IM_WIDTH, IM_HEIGHT))\n        im = np.array(im) \/ 255.0\n        \n        return im\n    \n    def generate_images(self, image_idx, is_training, batch_size=16):\n        \"\"\"\n        Used to generate a batch with images when training\/testing\/validating our Keras model.\n        \"\"\"\n        \n        # arrays to store our batched data\n        images, ages, races, genders = [], [], [], []\n        while True:\n            for idx in image_idx:\n                person = self.data.iloc[idx]\n                \n                age = person['age']\n                race = person['race_id']\n                gender = person['gender_id']\n                file = person['file']\n                \n                im = self.preprocess_image(file)\n                \n                ages.append(age \/ self.max_age)\n                races.append(to_categorical(race, len(dataset_dict['race_id'])))\n                genders.append(to_categorical(gender, len(dataset_dict['gender_id'])))\n                images.append(im)\n                \n                # yielding condition\n                if len(images) >= batch_size:\n                    yield np.array(images), [np.array(ages), np.array(races), np.array(genders)]\n                    images, ages, races, genders = [], [], [], []\n                    \n            if not is_training:\n                break\n                \ndata_generator = UtkFaceDataGenerator(data)\ntrain_idx, valid_idx, test_idx = data_generator.generate_split_indexes()","9cf9ab69":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Activation, Dropout, Lambda, Dense, Flatten, Input\n\n\nclass UtkMultiOutputModel():\n    \"\"\"\n    Used to generate our multi-output model. This CNN contains three branches, one for age, other for \n    sex and another for race. Each branch contains a sequence of Convolutional Layers that is defined\n    on the make_default_hidden_layers method.\n    \"\"\"\n    def make_default_hidden_layers(self, inputs):\n        \"\"\"\n        Used to generate a default set of hidden layers. The structure used in this network is defined as:\n        \n        Conv2D -> BatchNormalization -> Pooling -> Dropout\n        \"\"\"\n        x = Conv2D(16, (3, 3), padding=\"same\")(inputs)\n        x = Activation(\"relu\")(x)\n        x = BatchNormalization(axis=-1)(x)\n        x = MaxPooling2D(pool_size=(3, 3))(x)\n        x = Dropout(0.25)(x)\n\n        x = Conv2D(32, (3, 3), padding=\"same\")(x)\n        x = Activation(\"relu\")(x)\n        x = BatchNormalization(axis=-1)(x)\n        x = MaxPooling2D(pool_size=(2, 2))(x)\n        x = Dropout(0.25)(x)\n\n        x = Conv2D(32, (3, 3), padding=\"same\")(x)\n        x = Activation(\"relu\")(x)\n        x = BatchNormalization(axis=-1)(x)\n        x = MaxPooling2D(pool_size=(2, 2))(x)\n        x = Dropout(0.25)(x)\n\n        return x\n    \n    def build_race_branch(self, inputs, num_races):\n        \"\"\"\n        Used to build the race branch of our face recognition network.\n        This branch is composed of three Conv -> BN -> Pool -> Dropout blocks, \n        followed by the Dense output layer.\n        \"\"\"\n        x = self.make_default_hidden_layers(inputs)\n\n        x = Flatten()(x)\n        x = Dense(128)(x)\n        x = Activation(\"relu\")(x)\n        x = BatchNormalization()(x)\n        x = Dropout(0.5)(x)\n        x = Dense(num_races)(x)\n        x = Activation(\"softmax\", name=\"race_output\")(x)\n\n        return x\n    \n    def build_gender_branch(self, inputs, num_genders=2):\n        \"\"\"\n        Used to build the gender branch of our face recognition network.\n        This branch is composed of three Conv -> BN -> Pool -> Dropout blocks, \n        followed by the Dense output layer.\n        \"\"\"\n        x = Lambda(lambda c: tf.image.rgb_to_grayscale(c))(inputs)\n\n        x = self.make_default_hidden_layers(inputs)\n\n        x = Flatten()(x)\n        x = Dense(128)(x)\n        x = Activation(\"relu\")(x)\n        x = BatchNormalization()(x)\n        x = Dropout(0.5)(x)\n        x = Dense(num_genders)(x)\n        x = Activation(\"sigmoid\", name=\"gender_output\")(x)\n\n        return x\n\n    def build_age_branch(self, inputs):   \n        \"\"\"\n        Used to build the age branch of our face recognition network.\n        This branch is composed of three Conv -> BN -> Pool -> Dropout blocks, \n        followed by the Dense output layer.\n\n        \"\"\"\n        x = self.make_default_hidden_layers(inputs)\n\n        x = Flatten()(x)\n        x = Dense(128)(x)\n        x = Activation(\"relu\")(x)\n        x = BatchNormalization()(x)\n        x = Dropout(0.5)(x)\n        x = Dense(1)(x)\n        x = Activation(\"linear\", name=\"age_output\")(x)\n\n        return x\n    \n    def assemble_full_model(self, width, height, num_races):\n        \"\"\"\n        Used to assemble our multi-output model CNN.\n        \"\"\"\n        input_shape = (height, width, 3)\n\n        inputs = Input(shape=input_shape)\n\n        age_branch = self.build_age_branch(inputs)\n        race_branch = self.build_race_branch(inputs, num_races)\n        gender_branch = self.build_gender_branch(inputs)\n\n        model = Model(inputs=inputs,\n                     outputs = [age_branch, race_branch, gender_branch],\n                     name=\"face_net\")\n\n        return model\n    \nmodel = UtkMultiOutputModel().assemble_full_model(IM_WIDTH, IM_HEIGHT, num_races=len(dataset_dict['race_alias']))\n","52d572cd":"from tensorflow.keras.optimizers import Adam\n\ninit_lr = 1e-4\nepochs = 25\n\nopt = Adam(lr=init_lr, decay=init_lr \/ epochs)\n\nmodel.compile(optimizer=opt, \n              loss={\n                  'age_output': 'mse', \n                  'race_output': 'categorical_crossentropy', \n                  'gender_output': 'binary_crossentropy'},\n              loss_weights={\n                  'age_output': 4., \n                  'race_output': 1.5, \n                  'gender_output': 0.1},\n              metrics={\n                  'age_output': 'mae', \n                  'race_output': 'accuracy',\n                  'gender_output': 'accuracy'})\n\n","6157139b":"from tensorflow.keras.callbacks import ModelCheckpoint\n\nbatch_size = 40\nvalid_batch_size = 40\ntrain_gen = data_generator.generate_images(train_idx, is_training=True, batch_size=batch_size)\nvalid_gen = data_generator.generate_images(valid_idx, is_training=True, batch_size=valid_batch_size)\n\ncallbacks = [\n    ModelCheckpoint(\".\/model_checkpoint\", monitor='val_loss')\n]\n\nhistory = model.fit_generator(train_gen,\n                    steps_per_epoch=len(train_idx)\/\/batch_size,\n                    epochs=epochs,\n                    callbacks=callbacks,\n                    validation_data=valid_gen,\n                               \n                    validation_steps=len(valid_idx)\/\/valid_batch_size)","5bcae413":"test_batch_size = 128\ntest_generator = data_generator.generate_images(test_idx, is_training=False, batch_size=test_batch_size)\nage_pred, race_pred, gender_pred = model.predict_generator(test_generator, \n                                                           steps=len(test_idx)\/\/test_batch_size)\n","6884e6a8":"test_generator = data_generator.generate_images(test_idx, is_training=False, batch_size=test_batch_size)\nsamples = 0\nimages, age_true, race_true, gender_true = [], [], [], []\nfor test_batch in test_generator:\n    image = test_batch[0]\n    labels = test_batch[1]\n    \n    images.extend(image)\n    age_true.extend(labels[0])\n    race_true.extend(labels[1])\n    gender_true.extend(labels[2])\n    \nage_true = np.array(age_true)\nrace_true = np.array(race_true)\ngender_true = np.array(gender_true)\n\nrace_true, gender_true = race_true.argmax(axis=-1), gender_true.argmax(axis=-1)\nrace_pred, gender_pred = race_pred.argmax(axis=-1), gender_pred.argmax(axis=-1)\n\nage_true = age_true * data_generator.max_age\nage_pred = age_pred * data_generator.max_age\n\n","9089bc3e":"from sklearn.metrics import classification_report\n\ncr_race = classification_report(race_true, race_pred, target_names=dataset_dict['race_alias'].keys())\nprint(cr_race)","c5248bab":"cr_gender = classification_report(gender_true, gender_pred, target_names=dataset_dict['gender_alias'].keys())\nprint(cr_gender)","9fbbdc9e":"cr_gender = classification_report(gender_true, gender_pred, target_names=dataset_dict['gender_alias'].keys())\nprint(cr_gender)","fa0c0d22":"import math\nn = 40\nrandom_indices = np.random.permutation(n)\nn_cols = 4\nn_rows = math.ceil(n \/ n_cols)\nfig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 17))\nfor i, img_idx in enumerate(random_indices):\n    ax = axes.flat[i]\n    ax.imshow(images[img_idx])\n    \n    cur_age_pred = age_pred[img_idx]\n    cur_age_true = age_true[img_idx]\n    \n    cur_gender_pred = gender_pred[img_idx]\n    cur_gender_true = gender_true[img_idx]\n    \n    cur_race_pred = race_pred[img_idx]\n    cur_race_true = race_true[img_idx]\n    \n    age_threshold = 10\n    if cur_gender_pred == cur_gender_true and cur_race_pred == cur_race_true and abs(cur_age_pred - cur_age_true) <= age_threshold:\n        ax.xaxis.label.set_color('green')\n    elif cur_gender_pred != cur_gender_true and cur_race_pred != cur_race_true and abs(cur_age_pred - cur_age_true) > age_threshold:\n        ax.xaxis.label.set_color('red')\n    \n    ax.set_xlabel('a: {}, g: {}, r: {}'.format(int(age_pred[img_idx]),\n                            dataset_dict['gender_id'][gender_pred[img_idx]],\n                               dataset_dict['race_id'][race_pred[img_idx]]))\n    \n    ax.set_title('a: {}, g: {}, r: {}'.format(int(age_true[img_idx]),\n                            dataset_dict['gender_id'][gender_true[img_idx]],\n                               dataset_dict['race_id'][race_true[img_idx]]))\n    ax.set_xticks([])\n    ax.set_yticks([])\n    \nplt.tight_layout()\nplt.savefig('preds.png')\n","5658f86a":"# Save the model\n\nmodel.save_weights('full_model_weights.h5')\nmodel.save('model.h5')\n","0feb6eb3":"#Lets define a function for extracting the data from our dataset. This function will be used to iterate over each file of the UTK dataset and return a Pandas Dataframe containing all the fields (age, gender and sex) of our records.\n","0b174674":"###  In the plot it is clearly seen that almost half of the samples are from the White race, so we can expect this group to have a great accuracy and races such as Black, Indian and Asian also show a good number of samples, probably leading us to good accuracy numbers as well. but others races such as hispanics, latinos, etc., as small accuracy\n# \n#### In the gender distribution plot we should have a great accuracy for both classes when using our model.\n\n# Age distribution\n*> Let's also plot how our age feature is distributed over the dataset by using a simple histogram with 50 bins.\n*\n","f327037a":"# Output Images\n","53c4662e":"# Finally, let's print the classification reports for each feature on the test set.","17d93e8c":"# Evaluating our model on the test set","82e67047":"# Data visualization\n \n* > Generate plots based on a given Pandas series:*","a513bb73":"# Lets build our model","1dd10b89":"# Train Model","cc2ee3fe":"### It is clearly seen that our dataset is mostly composed of individuals which age varies between 20 and 30 years, followed by individuals ranging from 30-40 years and then 40-60 years old. These groups represent around 70% of our dataset, so we can believe that we are going to have a good accuracy on predicting individuals in these ranges.\n\n# Data Generator\n*> In order to input our data to our Keras multi-output model, we will create a helper object to work as a data generator for our dataset. This will be done by generating batches of data, which will be used to feed our multi-output model with both the images and their labels.*"}}