{"cell_type":{"12af71c1":"code","7c0db9a2":"code","254bbafd":"code","a0ce5743":"code","ccec5bd6":"code","85d082a3":"code","1de12bd7":"code","7366ec2d":"code","bf8055cb":"code","5348b7b1":"code","9393f4ed":"code","dbd04fd1":"code","d1ecd438":"code","7ef2e88a":"code","3fa86027":"code","7eee34b6":"code","5a5cbab7":"code","faf42101":"code","81f0d382":"code","671a8c8c":"code","eb3c8017":"code","b1c7eccc":"code","eb1256b4":"code","dc5203f5":"code","bedfde94":"code","9e2827d1":"code","f7669754":"code","9764b5b4":"code","3f258209":"code","0b7bb0e8":"code","9c2bc267":"code","6c488580":"code","a0a36d87":"code","7b8eb2c6":"code","8864304b":"code","752f10be":"code","97e55db4":"code","479177f0":"code","3f123240":"markdown","8b72a831":"markdown","d470c3d0":"markdown","8acf5ec4":"markdown","f63d6633":"markdown","ed74f6e0":"markdown","4dc45812":"markdown","08291333":"markdown","101b315a":"markdown","d35b954d":"markdown","b0df9a37":"markdown","19b97a39":"markdown","a9d3e863":"markdown","fc5fba94":"markdown","9e1606b7":"markdown","a9206848":"markdown","50d5711e":"markdown","5f6ee44d":"markdown","2157e574":"markdown","9bfa0946":"markdown"},"source":{"12af71c1":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\n#warnings.filterwarnings('ignore')","7c0db9a2":"train_data = pd.read_csv('..\/input\/train.csv')\ntrain_data.head()","254bbafd":"train_data.columns","a0ce5743":"train_data.describe()","ccec5bd6":"train_data.info()","85d082a3":"train_data.count()","1de12bd7":"train_data.isnull().sum().sort_values(ascending=False)","7366ec2d":"train_data[['Survived','Embarked']].groupby(['Embarked'],as_index=False).count() #to check which port has highest intake","bf8055cb":"train_data['Embarked'] = train_data['Embarked'].fillna('S'); # fillna returns value ","5348b7b1":"train_data[['Survived','Embarked']].groupby(['Embarked'],as_index=False).count() #after filling the blank 2 with S","9393f4ed":"train_data['Family'] = train_data['SibSp']+train_data['Parch'] +1\ntrain_data['Isalone'] = (train_data['Family'] == 1)*1","dbd04fd1":"f,ax = plt.subplots(2,4,figsize=(20,16))\nsns.countplot('Sex',data =train_data,ax = ax[0][0])\nsns.countplot('Pclass',data = train_data,ax = ax[0][1])\nsns.countplot('Family',data=train_data,ax = ax[0][2])\nsns.countplot('Embarked',data=train_data,ax = ax[0][3] )\nsns.countplot(\"Sex\",hue = 'Survived',data = train_data, ax = ax[1][0])\nsns.countplot(\"Pclass\",hue = 'Survived',data = train_data, ax = ax[1][1])\nsns.countplot(\"Family\",hue = 'Survived',data = train_data, ax = ax[1][2])\nsns.countplot(\"Embarked\",hue = 'Survived',data = train_data, ax = ax[1][3])\nplt.show()","d1ecd438":"train_data[['Family','Survived']].groupby(['Family'],as_index = False).mean().sort_values(by = 'Survived',ascending = False)","7ef2e88a":"train_data['Title'] = train_data['Name'].str.extract('([A-Za-z]+)\\.',expand = False) \ntrain_data['Title'].unique()","3fa86027":"train_data['Title'].value_counts() # value_cout works only in series not in Dataframe","7eee34b6":"print(pd.crosstab(train_data['Title'], train_data['Sex'])) #crosstab breaks 2nd argument into its unique values and give results","5a5cbab7":"train_data['Title'] = train_data['Title'].replace(['Don', 'Rev', 'Dr', 'Mme', 'Ms',\n       'Major', 'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'Countess',\n       'Jonkheer'],'Few')","faf42101":"fig,(axis1,axis2) = plt.subplots(1,2,figsize=(20,8))\nsns.barplot(x=\"Embarked\", y=\"Survived\", hue=\"Sex\", data=train_data,ax = axis1)\nsns.distplot(train_data[train_data['Survived']==0]['Age'].dropna(),ax=axis2,kde=False,color='r',bins=15) \nsns.distplot(train_data[train_data['Survived']==1]['Age'].dropna(),ax=axis2,kde=False,color='g',bins=15)\nplt.show()","81f0d382":"import random\nage_mean = train_data['Age'].mean()\nage_sd = train_data['Age'].std()\nage_random_list = np.random.randint(age_mean-age_sd, age_mean+age_sd, train_data['Age'].isnull().sum() )\ntrain_data['Age'][np.isnan(train_data['Age'])] = age_random_list\ntrain_data['Age'] = train_data['Age'].astype(int)","671a8c8c":"train_data.loc[train_data['Age'] <16 ,'Age'] = 0\ntrain_data.loc[(train_data['Age']>=16) & (train_data['Age']<32),'Age'] = 1\ntrain_data.loc[(train_data['Age']>=32) & (train_data['Age']<45),'Age'] = 2\ntrain_data.loc[(train_data['Age']>=45) & (train_data['Age']<55),'Age'] = 3\ntrain_data.loc[(train_data['Age']>55),'Age'] = 4","eb3c8017":"fig, ax = plt.subplots(figsize=(20,6))\nsns.distplot(train_data[train_data['Survived']==0]['Fare'],kde=False,color='r', ax = ax )\nsns.distplot(train_data[train_data['Survived']==1]['Fare'],kde=False,color='b',ax = ax)\nplt.show()","b1c7eccc":"train_data['CategoricalFare'] = pd.qcut(train_data['Fare'], 3)","eb1256b4":"train_data['CategoricalFare'].value_counts()","dc5203f5":"train_data.loc[(train_data['Fare'])<= 8.662, 'Fare'] = 0\ntrain_data.loc[(train_data['Fare']>8.662) & (train_data['Fare']<= 26), 'Fare'] = 1\ntrain_data.loc[(train_data['Fare']>26), 'Fare']  =2\ntrain_data['Fare'] = train_data['Fare'].astype(int)","bedfde94":"gender = {'male':0, 'female' : 1}\ntitle_dict = {'Mr' : 0, 'Mrs':1,'Miss':2,'Master':3, 'Few':4 }\nemb = {'S':0,'C':1,'Q':2}\ntrain_data['Title']= train_data['Title'].map(title_dict).astype(int)\ntrain_data['Embarked'] = train_data['Embarked'].map(emb).astype(int)\ntrain_data['Sex'] = train_data['Sex'].map(gender).astype(int)","9e2827d1":"train_data = train_data.drop(['PassengerId','Name','Cabin','CategoricalFare','Ticket'],axis = 1)","f7669754":"train_data.sample(10)","9764b5b4":"X_train = train_data.drop(\"Survived\", axis=1)\nY_train = train_data[\"Survived\"]\nX_train.shape, Y_train.shape\n\n#X_test = test.copy()","3f258209":"import sklearn         # Collection of machine learning algorithms\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n                              GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier)\nfrom sklearn.cross_validation import KFold\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\nwarnings.filterwarnings('ignore')","0b7bb0e8":"logistic_regression = LogisticRegression()\nlogistic_regression.fit(X_train,Y_train)\nacc_log = round(logistic_regression.score(X_train, Y_train) * 100, 2)\nacc_log","9c2bc267":"svc=SVC()\nsvc.fit(X_train, Y_train)\n#Y_pred = svc.predict(X_test)\nacc_svc = round(svc.score(X_train, Y_train) * 100, 2)\nacc_svc","6c488580":"gaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\n#Y_pred = gaussian.predict(test)\nacc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\nacc_gaussian","a0a36d87":"perceptron = Perceptron()\nperceptron.fit(X_train, Y_train)\n#Y_pred = perceptron.predict(test)\nacc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\nacc_perceptron","7b8eb2c6":"linear_svc = LinearSVC()\nlinear_svc.fit(X_train, Y_train)\n#Y_pred = linear_svc.predict(test)\nacc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)\nacc_linear_svc","8864304b":"sgd = SGDClassifier()\nsgd.fit(X_train, Y_train)\n#Y_pred = sgd.predict(test)\nacc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\nacc_sgd","752f10be":"decision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\n#Y_pred = decision_tree.predict(test)\nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\nacc_decision_tree","97e55db4":"random_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\n#random_forest_predictions = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest","479177f0":"knn = KNeighborsClassifier(algorithm='auto', leaf_size=26, metric='minkowski', \n                           metric_params=None, n_jobs=1, n_neighbors=6, p=2, \n                           weights='uniform')\nknn.fit(X_train, Y_train)\n#knn_predictions = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, Y_train) * 100, 2)\nacc_knn","3f123240":"# Importing Libraries","8b72a831":"## Guassian ","d470c3d0":"## Linear SVC","8acf5ec4":"# Loading Dataset","f63d6633":"## Decision Tree Classifier","ed74f6e0":"## Data Type of each feature","4dc45812":"# Predictive Modelling and Analysis","08291333":"# Basic Visualization of data","101b315a":"## Filling missing value from age column ","d35b954d":"## Categorizing Fare","b0df9a37":"## How many null data are present column-Wise","19b97a39":"## Categorizing age","a9d3e863":"## Categorizing Gender, Title and Location of Embarkement","fc5fba94":"## K Neighbour Classifier","9e1606b7":"## Final datatable for Model","a9206848":"## Logistic Regression","50d5711e":"## Perceptron","5f6ee44d":"## SGD(Stochastic Gradient Descent)","2157e574":"## Random Forest Classifier","9bfa0946":"## Support Vector Mechanics"}}