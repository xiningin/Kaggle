{"cell_type":{"eef2afc7":"code","d095996b":"code","b57da7a8":"code","fd5ec490":"code","2ffde9de":"code","5f4944cc":"code","6362f2dc":"code","6cb473c0":"code","6ed4950f":"code","1c914d9f":"code","5f6e5add":"code","4242a4c8":"code","aa92fc3c":"code","96c3010c":"markdown","879522d0":"markdown","551333c8":"markdown","f57b9ed7":"markdown","6df4c775":"markdown","5641000e":"markdown","08af6e4a":"markdown","8a1f07f9":"markdown","2eea49fe":"markdown","40c8944d":"markdown","870da399":"markdown","36e6d05e":"markdown","1a015829":"markdown","636a624c":"markdown"},"source":{"eef2afc7":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os","d095996b":"np.set_printoptions(precision = 4)\nds_dir = '..\/input\/drone-osddvr-num-dataset\/OSD_NUM_DATASET'\ntrain_dir = ds_dir + '\/train\/*\/*'\ntest_dir =  ds_dir + '\/test\/*\/*'\nCLASS_NAMES = np.array(['0','1', '2','3','4','5','6', '7','8','9','J'])\nIMG_HEIGHT = 25\nIMG_WIDTH = 20\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nBATCH_SIZE = 1177","b57da7a8":"traindata = tf.data.Dataset.list_files(train_dir)\ntestdata = tf.data.Dataset.list_files(test_dir)","fd5ec490":"def get_label(file_path):\n    parts = tf.strings.split(file_path, os.path.sep)\n    return parts[-2] == CLASS_NAMES","2ffde9de":"def decode_img(img):\n    img = tf.image.decode_jpeg(img, channels = 3)\n    img = tf.image.convert_image_dtype(img, tf.float32)\n    return img\n","5f4944cc":"def process_path(file_path):\n    label = get_label(file_path)\n    img = tf.io.read_file(file_path)\n    img = decode_img(img)\n    return img, label","6362f2dc":"def prepare_for_training(ds, cache = True, shuffle_buffer_size = 1000):\n    if cache:\n        if isinstance(cache, str):\n            ds = ds.cache(cache)\n        else:\n            ds = ds.cache()\n    ds = ds.shuffle(buffer_size = shuffle_buffer_size)\n    ds = ds.repeat()\n    ds = ds.batch(BATCH_SIZE)\n    ds = ds.prefetch(buffer_size = AUTOTUNE)\n    return ds","6cb473c0":"train_DS = traindata.map(process_path, num_parallel_calls=AUTOTUNE)\ntest_DS = testdata.map(process_path, num_parallel_calls=AUTOTUNE)","6ed4950f":"train_DS = prepare_for_training(train_DS)\ntest_DS = prepare_for_training(test_DS)","1c914d9f":"def show_batch(image_batch, label_batch):\n  plt.figure(figsize=(10,10))\n  for n in range(25):\n      ax = plt.subplot(5,5,n+1)\n      plt.imshow(image_batch[n])\n      plt.title(CLASS_NAMES[label_batch[n]==1])\n      plt.axis('off')\n  plt.show()\n\nimage_batch, label_batch = next(iter(train_DS))\nshow_batch(image_batch.numpy(), label_batch.numpy())","5f6e5add":"model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', input_shape=(25,20,3)),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Conv2D(128, (3,3), activation = 'relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Dense(11, activation = tf.nn.softmax)\n])","4242a4c8":"model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics = ['acc'])\nhis = model.fit(train_DS, steps_per_epoch = 10, epochs = 10, validation_data=test_DS, validation_steps = 1, shuffle=False, verbose=1)","aa92fc3c":"acc=his.history['acc']\nval_acc=his.history['val_acc']\nloss=his.history['loss']\nval_loss=his.history['val_loss']\nepochs=range(len(acc)) # Get number of epochs\n\nplt.plot(epochs, acc, 'r', label = \"Training Accuracy\")\nplt.plot(epochs, val_acc, 'b',label = \"Validation Accuracy\")\nplt.title('Training and validation accuracy')\nplt.show()\n\nplt.plot(epochs, loss, 'r', label = \"Training Loss\")\nplt.plot(epochs, val_loss, 'b', label = \"Validation Loss\")\nplt.title('Training and validation loss')\nplt.show()","96c3010c":"Create a model","879522d0":"Set the attributes","551333c8":"Create the datasets using the file datasets and the process_path function","f57b9ed7":"Use the last two functions to create a label and an image from a file path","6df4c775":"Compile and train the model","5641000e":"### A simple digit recognizer\nA very simple example. I chose not to do any augmentation as the orientation, size and position of the digits are constant. The model gets around 98% accuracy, but when i tested it out on a timer it only got one of 1500 frames wrong.\nImport tensorflow, numpy, os and plt","08af6e4a":"Convert the compressed string to a 3D uint8 tensor. Then change the dtype to float","8a1f07f9":"The model is now trained and ready to read OSD values such as power, voltage, amps or GPS coordinates","2eea49fe":"Plot the loss and accuracy. ","40c8944d":"Create a dataset of the files","870da399":"Prepare the datasets for training by setting its attributes","36e6d05e":"Setting static variables","1a015829":"View some of the training data and their lables","636a624c":"A simple labeling function that gets the label from the directory"}}