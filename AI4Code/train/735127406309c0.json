{"cell_type":{"bc0fcee8":"code","83c51d34":"code","e9fde2cf":"code","0cecc648":"code","f219e313":"code","9cca21ca":"code","39c8fcf3":"code","a22dbd1d":"code","a9f0a37e":"code","aab4b8e9":"code","15c7de3d":"code","37259264":"code","ceb1ff30":"code","26a0f7e1":"code","9e8ef166":"code","ab90c384":"code","45df916c":"code","27b24c1a":"code","817936b4":"code","92d42674":"code","a69f1158":"code","eae92bfa":"code","74d004e1":"code","f0087dfc":"code","64bbeccf":"code","ec592f46":"code","8a9dc490":"markdown","268616cb":"markdown","3b031cf7":"markdown","2cbdd371":"markdown"},"source":{"bc0fcee8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objs as go\nimport plotly.offline as py\nimport plotly.express as px\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","83c51d34":"df = pd.read_csv('..\/input\/customer-base-global-retail-bank\/cube.csv', encoding='utf8')\ndf.tail(2)","e9fde2cf":"!pip install pandas_flavor","0cecc648":"#Code by IM_AMS  https:\/\/www.kaggle.com\/imams2000\/fraud-detection-under-oversample-87-recall\n\nfrom pandas_flavor import register_dataframe_method,register_series_method\nfrom IPython.core.display import display, HTML\n\n@register_dataframe_method\ndef get_missing(df):        \n    tmp =  sorted(\n                [(col , str(df[col].dtypes) ,df[col].isna().sum(), np.round( df[col].isna().sum() \/ len(df) * 100,2) ) for col in df.columns if df[col].isna().sum() !=0 ],\n                key = lambda x: x[2], reverse=True)\n    \n    return pd.DataFrame(tmp).rename({0:\"Feature\", 1:\"dtype\", 2:\"count\", 3:\"percent\"},axis=1)  \n\n@register_dataframe_method\ndef get_numeric_df(df):\n    return df.select_dtypes(np.number)\n\n@register_dataframe_method\ndef get_numeric_cols(df):\n    return list(df.select_dtypes(np.number).columns)\n\n@register_dataframe_method\ndef get_object_cols(df):\n    return list(df.select_dtypes(exclude = np.number).columns)\n\n@register_dataframe_method\ndef get_object_df(df):\n    return df.select_dtypes(exclude = np.number)\n\n@register_dataframe_method\ndef get_discrete_cols(df,thresold):\n#     thresold in number of unique values\n    return [feature for feature in df.columns if len(df[feature].unique()) < thresold]\n\n@register_dataframe_method\ndef get_discrete_df(df,thresold):\n#     thresold in number of unique values\n    return df[ get_discrete_cols(df=df,thresold=thresold) ]\n\n@register_dataframe_method\ndef describe_discrete_cols(df,thresold, ascending=True):\n    \n    values = pd.DataFrame()\n    \n    for col in df.get_discrete_cols(thresold=thresold):\n        values[col] = [df[col].unique(), df[col].nunique()]\n        \n    return values.transpose().sort_values(by = 1,ascending=ascending).rename({0:\"Values\",1:\"cardinality\"},axis=1)\n\n@register_dataframe_method\ndef get_continuous_cols(df,thresold):\n    #     thresold in number of unique values\n    return [feature for feature in df.columns if len(df[feature].unique()) >= thresold]\n\n@register_dataframe_method\ndef get_continuous_df(df,thresold):\n    #     thresold in number of unique values\n    return df[ get_continuous_cols(df=df,thresold=thresold) ]\n\n\n@register_dataframe_method\ndef describe_continuous_cols(df,thresold, ascending=True):\n    return df[df.get_continuous_cols(thresold=thresold)].describe().T\n\n@register_dataframe_method\ndef dtypes_of_cols(df):\n    return pd.DataFrame(df.dtypes).reset_index().rename(columns={'index':\"Columns\",0: \"dtype\"})\n\n\n@register_series_method\ndef IQR_range(df):\n    if isinstance(df, pd.Series):\n        Q3 = np.quantile(df, 0.75)\n        Q1 = np.quantile(df, 0.25)\n        IQR = Q3 - Q1\n\n        lower_range = Q1 - 1.5 * IQR\n        upper_range = Q3 + 1.5 * IQR\n\n        return (lower_range,upper_range)\n    else:\n        assert False, \"df must be of type pandas.Series\"\n        \n@register_dataframe_method\ndef IQR_range(df):\n    if isinstance(df, pd.DataFrame):\n        cols = df.get_numeric_cols()\n        features = {}\n        for i in cols:\n            Q3 = np.quantile(df[i], 0.75)\n            Q1 = np.quantile(df[i], 0.25)\n            IQR = Q3 - Q1\n\n            lower_range = Q1 - 1.5 * IQR\n            upper_range = Q3 + 1.5 * IQR\n\n\n            features[i] = (lower_range,upper_range)\n            \n        return pd.DataFrame.from_dict(features,orient='index').rename({0: 'IQR_Low',1: 'IQR_High'}, axis=1)\n    else:\n        assert False, \"df must be of type pandas.DataFrame\"\n        \n@register_series_method\ndef IQR_percent(df):\n    if isinstance(df, pd.Series):\n        \n        lower_range, upper_range = df.IQR_range()\n\n        length = len(df)\n        return np.round((length - df.between(lower_range,upper_range).sum())\/length * 100, 2)\n    else:\n        assert False, \"df must be of type pandas.Series\"\n\n@register_dataframe_method\ndef IQR_percent(df):\n    if isinstance(df, pd.DataFrame):\n        cols = df.get_numeric_cols()\n        features = {}\n        for i in cols:\n            lower_range, upper_range = df[i].IQR_range()\n#             length - Number of NON outliers\n            length = len(df[i])\n            outlier_count = length - df[i].between(lower_range,upper_range).sum()\n            \n            percent = np.round( outlier_count \/length * 100, 2)\n            if outlier_count != 0:\n                features[i] = [percent, outlier_count]\n#             features[i] = IQR_percent(df[i])\n            \n        return pd.DataFrame.from_dict(features,orient='index').rename({0: 'Outlier percent', 1:\"Count\"}, axis=1)\n    else:\n        assert False, \"df must be of type pandas.DataFrame\"\n\n@register_dataframe_method\ndef get_outlier_cols(df):\n    return df.IQR_percent().reset_index()[\"index\"].to_list()\n        \n@register_dataframe_method\ndef drop_row_outlier(df, cols, inplace=False):\n#     init empty index\n    indices = pd.Series(np.zeros(len(df), dtype=bool), index=df.index)\n\n    for col in cols:\n        low, top = df[col].IQR_range()\n        indices |= (df[col] > top) | (df[col] < low)\n        \n    \n    return df.drop(df[ indices ].index, inplace=inplace)\n\n@register_series_method\ndef drop_row_outlier(df, inplace=False):\n#     init empty index\n\n    low, top = df.IQR_range()\n    indices = (df > top) | (df < low)\n        \n    \n    return df.drop(df[ indices ].index, inplace=inplace)\n        \n@register_dataframe_method\ndef compare_cols(df,l_feat,r_feat, percent=False, percent_of_total=False):\n    \n#     [L_feat] {R_feat1: agg1, R_feat2: agg2}\n\n    \n    if percent or percent_of_total:\n        \n        comp = []\n        for key, val in zip(r_feat,r_feat.values()):\n            tmp = pd.DataFrame()\n            tmp[key + \" \" + val] =  df.groupby(l_feat,sort=True).agg({key: val})\n            \n            if percent: tmp[key +\" %\"] = tmp.groupby(level=0).apply(lambda x: np.round(100 * x \/ float(x.sum()),2))\n\n            if percent_of_total: tmp[key+\" % of total\"] = np.round(tmp[key + \" \" + val] \/ tmp[key + \" \" + val].sum() * 100 , 2)\n            \n            comp.append(tmp)\n            \n        return comp\n    \n    else:\n        comp = []\n        for key, val in zip(r_feat,r_feat.values()):\n            tmp = pd.DataFrame()\n            tmp[key + \" \" + val] =  df.groupby(l_feat,sort=True).agg({key: val})           \n            comp.append(tmp)\n            \n        return comp  \n    \n    \n\n@register_dataframe_method\ndef count_dtypes(df, ascending=False):\n    return pd.DataFrame(df.dtypes.value_counts(ascending=ascending)).rename({0:\"Count\"},axis=1)\n\n@register_dataframe_method\ndef about(df):\n\n    display(HTML('<h1 style=\"color:green\"> <b> Shape of data <\/b> <\/h1>'))\n    print(df.shape)    \n\n    display(HTML('<h1 style=\"color:green\"> <b> Datatypes in data <\/b> <\/h1> '))\n    display(pd.DataFrame(df.dtypes.value_counts(ascending=False) ).rename({0:\"count\"},axis=1))\n\n    display(HTML('<h1 style=\"color:green\"> <b> dtypes of columns <\/b> <\/h1> '))\n    display(df.dtypes_of_cols())\n\n    display(HTML('<h1 style=\"color:green\"> <b> Percentage of missing values <\/b> <\/h1> '))\n    tmp = get_missing(df)\n    display(tmp) if len(tmp) != 0 else display(HTML(\"<h2> <b> None <b> <\/h2>\"))\n\n    display(HTML('<h1 style=\"color:green\"> <b> Data description <\/b> <\/h1> '))\n    display(df.describe().T)\n    \n    display(HTML('<h1 style=\"color:green\"> <b> Outlier Percentage(IQR) <\/b> <\/h1> '))\n    tmp = df.IQR_percent()\n    display(tmp) if len(tmp) != 0 else display(HTML(\"<h2> <b> None <b> <\/h2>\"))\n\n    display(HTML('<h1 style=\"color:green\"> <b> Example of data <\/b> <\/h1> '))\n    display(df.head())\n    \n    \nimport itertools\ndef display_multiple_tables(table_list):\n    table_list = list(itertools.chain(*table_list) )\n    return HTML(\n        '<table><tr style=\"background-color:white;\">' + \n        ''.join(['<td>' + table._repr_html_() + '<\/td>' for table in table_list]) +\n        '<\/tr><\/table>')","f219e313":"df.about()","9cca21ca":"df[\"Digital\"].value_counts()","39c8fcf3":"#Code by Lucas Abrah\u00e3o https:\/\/www.kaggle.com\/lucasabrahao\/trabalho-manufatura-an-lise-de-dados-no-brasil\n\ndf[\"Proposition\"].value_counts().plot.barh(color=['#D2B48C', '#808080', '#B8860B'], title='Proposition',);","a22dbd1d":"#Code by Lucas Abrah\u00e3o https:\/\/www.kaggle.com\/lucasabrahao\/trabalho-manufatura-an-lise-de-dados-no-brasil\n\ndf[\"Primary\"].value_counts().plot.barh(color=['blue', '#f5005a'], title='Primary',);","a9f0a37e":"#Code by Lucas Abrah\u00e3o https:\/\/www.kaggle.com\/lucasabrahao\/trabalho-manufatura-an-lise-de-dados-no-brasil\n\ndf[\"International\"].value_counts().plot.barh(color=['purple', 'green'], title='International',);","aab4b8e9":"#Code by Lucas Abrah\u00e3o https:\/\/www.kaggle.com\/lucasabrahao\/trabalho-manufatura-an-lise-de-dados-no-brasil\n\ndf[\"Tenure\"].value_counts().plot.barh(color=['blue', 'red','lime','purple'], title='Tenure',);","15c7de3d":"#Code by Lucas Abrah\u00e3o https:\/\/www.kaggle.com\/lucasabrahao\/trabalho-manufatura-an-lise-de-dados-no-brasil\n\ndf[\"Age\"].value_counts().plot.barh(color=['blue', 'red','lime','purple','teal','cyan'], title='Age');","37259264":"#Code by Lucas Abrah\u00e3o https:\/\/www.kaggle.com\/lucasabrahao\/trabalho-manufatura-an-lise-de-dados-no-brasil\n\ndf[\"Mortgage\"].value_counts().plot.bar(color=['green', '#f5005a'], title='Mortgage');","ceb1ff30":"cols_to_drop=['Unnamed: 23','Unnamed: 24', 'Unnamed: 25', '2']\ndf=df.drop(cols_to_drop,axis=1)\ndf.columns","26a0f7e1":"corr = df.corr(method='pearson')\nsns.heatmap(corr);\n\nplt.figure(figsize=(16,6))\n\nsns.scatterplot( data=df, x=\"Proposition\", y=\"Mort_holders\", hue=\"Mortgage\")\nplt.xticks(rotation=45)\nplt.title('Proposition by Mortgage Holders');","9e8ef166":"plt.figure(figsize=(16,6))\n\nsns.scatterplot( data=df, x=\"Proposition\", y=\"Inv_holders\", hue=\"Investment\")\nplt.xticks(rotation=45)\nplt.title('Proposition by Investment Holders');","ab90c384":"plt.figure(figsize=(25,6))\nplt.title('Proposition vs Mortgage Holders')\nplt.xticks(rotation=70)\nsns.barplot(x=df['Proposition'], y='Mort_holders', data=df);","45df916c":"#Code by Puru Behl https:\/\/www.kaggle.com\/accountstatus\/mt-cars-data-analysis\n\nsns.distplot(df['Mort_holders'])\nplt.axvline(df['Mort_holders'].values.mean(), color='red', linestyle='dashed', linewidth=1)\nplt.title('Mortgage Holders');","27b24c1a":"#Code by Puru Behl https:\/\/www.kaggle.com\/accountstatus\/mt-cars-data-analysis\n\nsns.distplot(df['Inv_holders'], color='r')\nplt.axvline(df['Inv_holders'].values.mean(), color='red', linestyle='dashed', linewidth=1)\nplt.title('Investment Holders');","817936b4":"#Code by Puru Behl https:\/\/www.kaggle.com\/accountstatus\/mt-cars-data-analysis\n\nsns.distplot(df['Digital_cust'], color='purple')\nplt.axvline(df['Digital_cust'].values.mean(), color='red', linestyle='dashed', linewidth=1)\nplt.title('Active Digital Customers');","92d42674":"fig = px.histogram(df, x=\"Proposition\", y=\"Inv_holders\", color= 'Investment',\n                   hover_data=df.columns)\nfig.show()","a69f1158":"#https:\/\/seaborn.pydata.org\/generated\/seaborn.lineplot.html\n\nsns.lineplot(data=df,x='Digital_cust', y=\"Age\")\nplt.title ('Active Digital Customers by Age');\n#plt.xticks(rotation=45);","eae92bfa":"fig = px.histogram(df, x=\"Age\", y=\"Digital_cust\", color= 'Revenue',\n                   hover_data=df.columns)\nfig.show()\n","74d004e1":"#Code by Beyza T. https:\/\/www.kaggle.com\/beyzat\/first-notebook-da\n\nx = np.linspace(1,100, 100)  # creating an array by numpy for x-axis values\n\nplt.plot(x, x**2)  # y = x^2\nplt.xlabel(\"Proposition\")  # naming x axis\nplt.ylabel(\"Revenue\")  # naming y axis\nplt.show()","f0087dfc":"fig = px.histogram(df, x=\"Proposition\", y=\"Revenue\", color=\"Digital_cust\", pattern_shape=\"Mortgage\",\n                  title=\"Proposition by Revenue\",color_discrete_sequence=px.colors.qualitative.Safe)\nfig.show()","64bbeccf":"# making a lineplot to check the relation between customer care calls, customer ratings and gender\n\nplt.figure(figsize = (18, 9))\nsns.lineplot(x = 'Proposition', y = 'Digital_cust', hue = 'Digital', data = df,\n             palette = 'rocket', ci = 0)\nplt.title('Proposition by Active Digital Customers',\n          fontsize = 15)\nplt.show()","ec592f46":"#word cloud\nfrom wordcloud import WordCloud, ImageColorGenerator\ntext = \" \".join(str(each) for each in df.NPS)\n# Create and generate a word cloud image:\nwordcloud = WordCloud(max_words=200,colormap='Set3', background_color=\"black\").generate(text)\nplt.figure(figsize=(10,6))\nplt.figure(figsize=(15,10))\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='Bilinear')\nplt.axis(\"off\")\nplt.figure(1,figsize=(12, 12))\nplt.show()","8a9dc490":"#Net Promoter Score (NPS)\n\nNPS WordCloud below.Customers receive scores too.","268616cb":"#Dropping empty columns","3b031cf7":"That's all for now.","2cbdd371":"![](https:\/\/community.tibco.com\/sites\/default\/files\/customer_journey.jpg)community.tibco.com"}}