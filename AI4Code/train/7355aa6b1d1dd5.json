{"cell_type":{"73847f66":"code","56113934":"code","1c8bb794":"code","9dfe27d4":"code","659e057a":"code","a9b065b6":"code","e6d1339e":"code","c6fd9774":"code","15b4c461":"markdown","b511ae23":"markdown","5d08cfae":"markdown","30b14835":"markdown","70b570ef":"markdown","cb44857d":"markdown","8aa9240b":"markdown"},"source":{"73847f66":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","56113934":"import numpy as np\nimport pandas as pd\nfrom catboost import CatBoostClassifier\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split","1c8bb794":"train_df = pd.read_csv('\/kaggle\/input\/mf-accelerator\/contest_train.csv')","9dfe27d4":"blok_list = ['TARGET', 'ID']\ntrain = [data for data in train_df.columns if data not in blok_list ]\nnan_cols = []\ntrain_cleared = [data for data in train if data not in nan_cols ]\ncorr_m=train_df[train_cleared].corr()\ndict_corr = {}\ncorr_counter = {}\n\n\n\nfor f1 in train_cleared:\n    hi_cor_list = list(corr_m[f1][(abs(corr_m[f1]) >0.5) & (abs(corr_m[f1]) <1)].index)\n    if len(hi_cor_list) > 0:\n        dict_corr[f1] = hi_cor_list\n        for feat in hi_cor_list:\n            if feat in corr_counter.keys():\n                corr_counter[feat] += 1\n            else:\n                corr_counter[feat] = 1\n\n                \ncorr_counter = {k: v for k, v in sorted(corr_counter.items(), key=lambda item: item[1], reverse = True)}\nfor key_counter in list(corr_counter.keys()):\n    if key_counter in dict_corr.keys():\n        for key in dict_corr[key_counter]:\n            dict_corr.pop(key, None) \n\nindex_new_feat = 0 \ntrain_copy = train_df[train_cleared].copy()\nfor feat in train_copy.columns:\n    if feat in dict_corr.keys():\n        train_copy.drop(dict_corr[feat], axis=1, inplace = True, errors = 'ignore')  \n\nX = train_copy\ny = train_df['TARGET']","659e057a":"cat_list = ['FEATURE_1','FEATURE_2','FEATURE_5','FEATURE_6',\n            'FEATURE_10','FEATURE_13','FEATURE_14','FEATURE_15',\n            'FEATURE_16','FEATURE_17','FEATURE_18','FEATURE_19',\n            'FEATURE_27', 'FEATURE_74', 'FEATURE_75', 'FEATURE_118',\n            'FEATURE_123','FEATURE_133', 'FEATURE_142', \n            'FEATURE_144','FEATURE_145', 'FEATURE_146', 'FEATURE_150',\n            'FEATURE_151', 'FEATURE_155', 'FEATURE_156',\n            'FEATURE_157', 'FEATURE_159', 'FEATURE_172', \n            'FEATURE_175','FEATURE_176', 'FEATURE_178', 'FEATURE_197',\n            'FEATURE_199', 'FEATURE_201', 'FEATURE_202', 'FEATURE_206', \n            'FEATURE_213','FEATURE_224', 'FEATURE_246','FEATURE_249',\n            'FEATURE_257', 'FEATURE_258','FEATURE_259'\n           ]\nX[cat_list] = X[cat_list].astype(str)","a9b065b6":"ignored_feat2 =  [ 'FEATURE_10', 'FEATURE_257', 'FEATURE_245', 'FEATURE_201',\n                  'FEATURE_246', 'FEATURE_247', 'FEATURE_145', 'FEATURE_202',\n                  'FEATURE_27','FEATURE_157', 'FEATURE_146', 'FEATURE_156',\n                  'FEATURE_234', 'FEATURE_242', 'FEATURE_75', 'FEATURE_231',\n                  'FEATURE_29', 'FEATURE_2', 'FEATURE_3', 'FEATURE_5', 'FEATURE_6',\n                  'FEATURE_15', 'FEATURE_16', 'FEATURE_17', 'FEATURE_18', 'FEATURE_19',\n                  'FEATURE_20', 'FEATURE_22', 'FEATURE_25', 'FEATURE_28', 'FEATURE_39',\n                   'FEATURE_40', 'FEATURE_41', 'FEATURE_139', 'FEATURE_141',\n                  'FEATURE_144', 'FEATURE_159', 'FEATURE_229', 'FEATURE_249','FEATURE_256'\n                 ]","e6d1339e":"it = 200\ndepth_t = 10\nl2_reg = 9\nlr = 0.15\nweight_class = 'Balanced'\n\n\nsubm_name = f'.\/subm_f{X.shape[1]}_it{it}_depth{depth_t}_l2_{l2_reg}_lr{lr}_{weight_class}_ignefat_traincleared.csv '\n\nmodel_train = CatBoostClassifier(\n    iterations= it,\n    custom_loss=['TotalF1'],\n    loss_function = 'MultiClass',\n    random_seed=42,\n    task_type=\"GPU\",\n    cat_features = cat_list,\n    ignored_features = ignored_feat2[-31:],\n    depth = depth_t,\n    l2_leaf_reg = l2_reg,\n    learning_rate = lr,\n    auto_class_weights = weight_class,\n    logging_level='Silent'\n)\n\n\nmodel_train.fit(\n    X, \n    y,\n    plot=True\n)","c6fd9774":"subm_df = pd.read_csv('\/kaggle\/input\/mf-accelerator\/sample_subm.csv')\n\n\ntest_df = pd.read_csv('\/kaggle\/input\/mf-accelerator\/contest_test.csv')\n# test_df\nlist_columns = list(train_copy.columns) \n\n# test_df = test_df[list_columns]\ntest_df[cat_list] = test_df[cat_list].astype(str)\n\n\npredictions = model_train.predict(test_df[list_columns])\n# predictions = model_train.predict(test_df[train_cleared])\n\ntest_df['TARGET'] = predictions\nsubm_df.loc[subm_df.ID.isin(test_df.ID),'Predicted'] = test_df['TARGET']\n\nsubm_df.to_csv(subm_name, index=False)","15b4c461":"## \u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 (\u043e\u0442\u0431\u043e\u0440 \u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u043b\u0441\u044f \u0432\u0440\u0443\u0447\u043d\u0443\u044e - \u0434\u0430\u043d\u043d\u044b\u0439 \u0434\u0430\u0442\u0430\u0441\u0435\u0442 \u0438\u043c\u0435\u0435\u0442 \u043d\u0435 \u043e\u0447\u0435\u043d\u044c \u0431\u043e\u043b\u044c\u0448\u0443\u044e \u0440\u0430\u0437\u043c\u0435\u0440\u043d\u043e\u0441\u0442\u044c \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u0430 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 - \u043c\u043e\u0436\u043d\u043e \u0441\u043f\u043e\u043a\u043e\u0439\u043d\u043e \u043e\u0442\u0441\u043c\u043e\u0442\u0440\u0435\u0442\u044c \u043a\u0430\u0436\u0434\u044b\u0439 \u043d\u0430 \u044d\u0442\u0430\u043f\u0435 EDA)","b511ae23":"Private Score 0.53961\n\nPublic Score 0.54087\n\n\u041c\u043e\u0434\u0435\u043b\u044c  \u043f\u043e\u043b\u0443\u0447\u0438\u043b\u0430\u0441\u044c \u0434\u043e\u0432\u043e\u043b\u044c\u043d\u043e \u0443\u0441\u0442\u043e\u0439\u0447\u0438\u0432\u043e\u0439.","5d08cfae":"## \u0422\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043a\u0430 \u043c\u043e\u0434\u0435\u043b\u0438","30b14835":"## \u041f\u0440\u043e\u0433\u043d\u043e\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0438 \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0432\u044b\u0433\u0440\u0443\u0437\u043a\u0438 \u0434\u043b\u044f \u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0438","70b570ef":"## \u0414\u0430\u043d\u043d\u0430\u044f \u0440\u0430\u0431\u043e\u0442\u0430  \u043d\u0435 \u0441\u043e\u0434\u0435\u0440\u0436\u0438\u0442 EDA \u0438 \u043f\u043e\u043b\u043d\u044b\u0439 \u0432\u044b\u0432\u043e\u0434 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432. \u0413\u043b\u0430\u0432\u043d\u0430\u044f \u0437\u0430\u0434\u0430\u0447\u0430 - \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u044c \u0432\u043e\u0441\u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u043c\u043e\u0441\u0442\u044c \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u0430 \u0438 \u043a\u0440\u0430\u0442\u043a\u043e \u043e\u043f\u0438\u0441\u0430\u0442\u044c \u043f\u0440\u0438\u043d\u044f\u0442\u044b\u0435 \u0440\u0435\u0448\u0435\u043d\u0438\u044f","cb44857d":"## \u0424\u0438\u043b\u044c\u0442\u0440\u0430\u0446\u0438\u044f \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u043d\u0430\u0431\u043b\u044e\u0434\u0435\u043d\u0438\u0439 \u043f\u043e \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u0438 (\u043a\u0430\u043d\u0434\u0438\u0434\u0430\u0442\u0430\u043c\u0438 \u043d\u0430 \u043e\u0442\u0441\u0435\u0432 \u0440\u0430\u0441\u0441\u043c\u0430\u0442\u0440\u0438\u0432\u0430\u043b\u0438\u0441\u044c \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u0441 \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u0435\u0439 (0.5;1)). ","8aa9240b":"## \u0418\u0433\u043d\u043e\u0440\u0438\u0440\u0443\u0435\u043c\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 (\u043e\u0442\u043e\u0431\u0440\u0430\u043d\u044b \u043f\u043e model_train.get_feature_importance() \u043d\u0430 \u043e\u0434\u043d\u043e\u043c \u0438\u0437 \u044d\u0442\u0430\u043f\u043e\u0432 \u043c\u043e\u0434\u0435\u043b\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f). \u041a\u043e\u043d\u0435\u0447\u043d\u043e\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e (31 \u043f\u043e\u0441\u043b\u0435\u043d\u0438\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u0432 \u0441\u043f\u0438\u043a\u0435) \u0431\u044b\u043b\u043e \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u043e \u043d\u0430\u0445\u043e\u0436\u0434\u0435\u043d\u0438\u0435\u043c f1 \u043d\u0430 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435 (\u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0438\u0439 \u0434\u0430\u0442\u0430\u0441\u0435\u0442 \u0434\u0435\u043b\u0438\u043b\u0441\u044f \u043d\u0430 train\/val) \u043f\u043e\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u044b\u043c \u043e\u0442\u0431\u0440\u043e\u0441\u043e\u043c \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 (\u043d\u0430\u0447\u0438\u043d\u0430\u044f \u0441 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0433\u043e \u0432 \u0441\u043f\u0438\u0441\u043a\u0435)."}}