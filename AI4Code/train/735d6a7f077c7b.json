{"cell_type":{"2f59075e":"code","7d74c804":"code","b3174c84":"code","7c76d127":"code","5cc0b297":"code","e657a877":"code","ac5df2e0":"code","314f40a6":"code","a72dcb10":"code","835bb14b":"code","43e60825":"code","2f1fa22e":"code","3eff1286":"code","303c66ac":"code","0aeb254b":"code","ed74dd48":"code","41f5228b":"code","951e39da":"code","fbcdb926":"code","86dba1ba":"code","57ebaa02":"markdown","eca09a01":"markdown","754f3194":"markdown","3c1e687d":"markdown","e38991bf":"markdown","ed4aa816":"markdown","5b0e1605":"markdown","ec5ab471":"markdown","04a8a787":"markdown","9c12701d":"markdown","84daa3ef":"markdown","449248b8":"markdown","588a8971":"markdown","1cb6a2a1":"markdown","e86d3a67":"markdown","772781da":"markdown","b442798d":"markdown","fcec250c":"markdown","9eea38ef":"markdown","ed78e232":"markdown","c9cd4d77":"markdown","efde805a":"markdown"},"source":{"2f59075e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7d74c804":"#Import required libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats","b3174c84":"#Dataset\n\n#x - Annual Salary in USD'000\nx = [20,22,25,28,34,40,45,51,58,62,65,70,74,78,82,85,89,92,95,99,102,104,110,112,117,123,126,130,134,140,144,148,150]\n\n#y - Price of the car bought in USD'000\ny = [35,41,35,24,32,36,50,59,63,50,36,84,80,88,94,64,80,98,68,88,80,72,95,96,104,120,105,118,110,130,125,118,135]","7c76d127":"# <img src=\"img\/hypothesis.png\" \/>","5cc0b297":"#Create a class for Linear Regression\nclass LinearRegression:\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n        \n        #Number of iterations of the Gradient Descent Algorithm\n        self.max_iter = 1000000\n        \n        self.eps=1e-9\n        \n        #Learning Rate\n        self.alpha = 0.0001\n        \n        #Loss arr\n        self.loss_arr = []\n        \n        \n    def stochasticGradientDescent(self):\n        \n        \n        #Initialize w and b with random value\n        w = 0.25\n        b = 0.3\n        alpha = 0.00001\n        \n        check = True\n        iter = 0\n        self.loss_arr = []\n        while check:\n            for j in range(len(self.x)):\n                prev_w = w\n                prev_b = b\n                \n                #Calculate y_pred\n                y_pred = w * self.x[j] + b\n                \n                #Update slope\n                w = w - alpha * (y_pred - self.y[j]) * self.x[j]\n                \n                #Update intercept\n                b = b - alpha * (y_pred - self.y[j]) * 1\n                \n                self.loss_arr.append((y_pred - self.y[j])**2)\n                \n                iter += 1\n                \n                if (np.abs(w-prev_w) < self.eps and np.abs(b-prev_b) < self.eps) or iter == self.max_iter:\n                    check = False\n        \n        print(\"Stochastic Gradient Descent algorithm took {} iters to converge\".format(iter))\n                \n        return w,b\n    \n    def batchGradientDescent(self):\n        \n        #Initialize w and b with a random value\n        w=0.25\n        b=0.3\n        \n        check = True\n        iter = 0\n        n = len(self.x)\n        self.loss_arr = []\n        \n        while check:\n            \n            cost_intercept = 0\n            cost_slope = 0\n            \n            prev_w = w\n            prev_b = b\n            \n            \n            for j in range(len(self.x)):\n                \n                #Calculate y_pred\n                y_pred = w * self.x[j] + b\n                \n                #Calculate loss for the entire batch\n                cost_intercept +=  (y_pred - self.y[j])*1 \n                \n                cost_slope +=  (y_pred - self.y[j])*self.x[j]\n            \n            #Update slope\n            w = w - self.alpha * cost_slope \/ n\n                \n            #Update intercept\n            b = b - self.alpha * cost_intercept \/ n\n            \n            iter += 1\n                \n            if (np.abs(w-prev_w) < self.eps and np.abs(b-prev_b) < self.eps) or iter == self.max_iter:\n                check = False \n                \n        print(\"Batch Gradient Descent algorithm took {} iters to converge\".format(iter))\n                \n        return w,b\n    \n    \n    def normalEquation(self):\n        \n        #Initialize w and b with random value\n        w = 0.25\n        b = 0.3\n        \n        #Create arrays for vectorized calculations using Numpy\n        x_arr = np.array(self.x)\n        y_arr = np.array(self.y)\n        \n        \n        num = np.mean(x_arr*y_arr) - np.mean(x_arr)*np.mean(y_arr)\n        den = np.mean(np.square(x_arr)) - np.square(np.mean(x_arr))\n        w = num\/den\n        \n        b = np.mean(y_arr) - w*np.mean(x_arr)\n        \n        return w,b\n    \n    \n    def newtonMethod(self):\n        #Create arrays for vectorized calculations using Numpy\n        x_arr = np.array(self.x)\n        y_arr = np.array(self.y)\n        \n        \n        #Reshape x_arr and y_arr for matrix operations\n        x_arr = x_arr.reshape(x_arr.shape[0], 1)\n        y_arr = y_arr.reshape(y_arr.shape[0], 1)\n        \n        #Modify x_arr to 2-D, x[0] = 1\n        x_arr = np.insert(x_arr, 0, 1, axis=1)\n        \n        #Initialize w_arr\n        w_arr = np.ones((2, 1))\n        \n        #Source for Gradient and Hessian Equations\n        #https:\/\/www.cs.ubc.ca\/~schmidtm\/Courses\/Notes\/linearQuadraticGradients.pdf\n        \n        \n        check = True\n        iter = 0\n        while check and iter < self.max_iter:\n            \n            old_w_arr = w_arr\n            \n            #Calculate the gradient\n            gradientLoss = np.matmul(np.dot(x_arr.T,x_arr),w_arr) - np.matmul(x_arr.T,y_arr)\n        \n            #Calculate the hessian\n            hessianLoss = np.dot(x_arr.T,x_arr)\n\n            #Calculate the hessian inverse\n            hessianLossInv = np.linalg.inv(hessianLoss)\n            \n            #Use Newton's method to update w_arr\n            w_arr = old_w_arr - np.matmul(hessianLossInv,gradientLoss)\n            \n            \n            #Difference between new and old theta\n            diff = np.linalg.norm(w_arr - old_w_arr)\n            \n            #Check if the difference is less than the eps specified\n            if abs(diff) < self.eps:\n                print(\"Linear Regression Algorithm converged\")\n                check = False\n            \n            print(\"This is iter: \", iter)\n            print(\"This is w after Newton Method: \", w_arr)\n            print(\"*\"*10)\n            iter += 1\n        \n        # return slope, intercept\n        return w_arr[1,0], w_arr[0,0]\n                \n        \n\n    \n    def fit(self):\n        #Fit the model\n        return np.multiply(self.slope,self.x) + self.intercept\n    \n    \n    def drawPlot(self):\n        #Plot the dataset and model\n        plt.scatter(self.x, self.y)\n        plt.title(\"Simple Linear Regression\")\n        plt.xlabel(\"Salary in USD'000\")\n        plt.ylabel(\"Money spent on car purchase in USD'000\")\n        plt.plot(self.x, self.myModel)\n        plt.show()   ","e657a877":"#Dataset\n\n#x - Annual Salary in USD'000\nx = [20,22,25,28,34,40,45,51,58,62,65,70,74,78,82,85,89,92,95,99,102,104,110,112,117,123,126,130,134,140,144,148,150]\n\n#y - Price of the car bought in USD'000\ny = [35,41,35,24,32,36,50,59,63,50,36,84,80,88,94,64,80,98,68,88,80,72,95,96,104,120,105,118,110,130,125,118,135]","ac5df2e0":"#Create an object of the class\nmyLinearReg = LinearRegression(x,y)","314f40a6":"#Execute the Stochastic Gradient Descent()\nmyLinearReg.slope, myLinearReg.intercept = myLinearReg.stochasticGradientDescent()\nprint(\"This is slope: \", myLinearReg.slope)\nprint(\"This is intercept: \", myLinearReg.intercept)","a72dcb10":"myLinearReg.myModel = myLinearReg.fit()\nmyLinearReg.drawPlot()","835bb14b":"print(\"This is the length of loss_arr: \", len(myLinearReg.loss_arr))","43e60825":"iter_arr = [x for x in range(len(myLinearReg.loss_arr))]","2f1fa22e":"plt.plot(iter_arr, myLinearReg.loss_arr)\nplt.show()   ","3eff1286":"#Execute the Batch Gradient Descent()\nmyLinearReg.slope, myLinearReg.intercept = myLinearReg.batchGradientDescent()\nprint(\"This is slope: \", myLinearReg.slope)\nprint(\"This is intercept: \", myLinearReg.intercept)","303c66ac":"myLinearReg.myModel = myLinearReg.fit()\nmyLinearReg.drawPlot()","0aeb254b":"myLinearReg.slope, myLinearReg.intercept = myLinearReg.normalEquation()\nprint(\"This is slope: \", myLinearReg.slope)\nprint(\"This is intercept: \", myLinearReg.intercept)","ed74dd48":"myLinearReg.myModel = myLinearReg.fit()\nmyLinearReg.drawPlot()","41f5228b":"myLinearReg.slope, myLinearReg.intercept = myLinearReg.newtonMethod()\nprint(\"This is slope: \", myLinearReg.slope)\nprint(\"This is intercept: \", myLinearReg.intercept)\n","951e39da":"myLinearReg.drawPlot()","fbcdb926":"slope, intercept, r, p, std_err = stats.linregress(myLinearReg.x, myLinearReg.y)\nprint(\"This is slope: \", slope)\nprint(\"This is intercept: \", intercept)\n\n","86dba1ba":"def myfunc(x):\n  return slope * x + intercept\n\nmymodel = list(map(myfunc, x))\n\nplt.scatter(x, y)\nplt.title(\"Simple Linear Regression\")\nplt.xlabel(\"Salary in USD'000\")\nplt.ylabel(\"Money spent on car purchase in USD'000\")\nplt.plot(x, mymodel)\nplt.show()","57ebaa02":"--------\n\n### Project Name: Mathematics of Linear Regression | Linear Regression model implemented from scratch in Python\n\n### Author: Ankur Dhamija\n\n### Connect on Linkedin: https:\/\/www.linkedin.com\/in\/ankurdhamija\/\n\n-------","eca09a01":"### Deriving the Newton Raphson Method\n\nFind the tangent line to $f(x)$ at point $(x_n,y_n)$\n\n$y=f\u2032(x_n)(x\u2212x_n)+f(x_n)$\n\nFind the x-intercept of the tangent line, $x_n+1$\n\n$0=f\u2032(x_n)(x_n+1\u2212x_n)+f(x_n)$\n\n$\u2212f(x_n)=f\u2032(x_n)(x_{n+1}\u2212x_n)$\n\n$x_{n+1}=x_n\u2212f(x_n)f\u2032(x_n)$\n\nFind the y value at the x-intercept.\n\n$y_{n+1}=f(x_{n+1})$\n\nIf $y_{n+1}\u2212y_n\u22480$:\n\nreturn $y_{n+1}$ because we\u2019ve converged!\n\nElse update point $(x_n,y_n)$, and iterate\n\n$x=x_{n+1},y=y_{n+1},$ goto (1).\n\n\n********\n\nIn our case, since we are minimizing the derivative of the Loss function, Newton Method equation can be re-written as\n$\\theta_{n+1} = \\theta + H^{-1}_{l(\\theta)} \\nabla{l(\\theta)}$","754f3194":"# Understanding the mathematics behind Linear Regression Model","3c1e687d":"# What are we trying to predict?\n\nGiven data like this, how can we learn to predict the price of the car the person will buy as a function of their annual salary?","e38991bf":"# LMS Algorithm\n\n**5.1 Gradient Descent Algorithm**<br>\nWe want to choose $\\theta$ so as to minimize $J(\\theta)$. To do so, let\u2019s use a search algorithm that starts with some `initial guess` for $\\theta$, and that repeatedly changes $\\theta$ to make $J(\\theta)$ smaller, until hopefully we converge to a value of $\\theta$ that minimizes $J(\\theta)$. \n\nSpecifically, let\u2019s consider the `gradient descent algorithm`, which starts with some initial $\\theta$, and repeatedly performs the update:\n\n<h2><center>$ \\theta_j := \\theta_j - \\alpha \\frac{\\partial}{\\partial \\theta_j} J(\\theta)$<\/center><\/h2>\n\nHere, $\\alpha$ is the learning rate.\n\n---\n","ed4aa816":"# LR Model from scratch in Python","5b0e1605":"# Normal Equation","ec5ab471":"# Business problem\n\nSuppose, we have a `dataset of annual salaries` (in USD'000) and `price of the car` bought (in USD'000) by 30 people. Our aim is to build a `predictive model` for the above dataset. The model should predict as follows\n\n**Given the value of an annual salary of a person, the model should output the expected price of the car that person will buy.**\n\n---","04a8a787":"# Gradient Descent","9c12701d":"**3.1 First we define the Hypothesis function**\n\n<h3><center>$h_{\\theta}x = \\theta_0 + \\theta_1*x_1 $.<\/center><\/h3>\n\n---","84daa3ef":"# Calculation of weights using Scipy","449248b8":"### Deriving the parameters of the Normal Equation\n\nWe first define our general cost function: $J(\\theta) = (1\/2n)\\sum_{i=1}^{n} (h_{\\theta}x^{(i)}-y^{(i)})^2 $\n\nTaking the cost function for Simple Linear Regression\n\n$J = (1\/2n)((b+wx)-y)^2 $\n\n$J = (1\/2n)((b+wx)^2+y^2-2(b+wx)y) $\n\n$J = (1\/2n)(b^2+w^2x^2 + 2bwx+y^2-2by-2wxy) $\n\n*********\n\n#### Taking the partial derivative wrt b\n\n$\\frac{\\partial J}{\\partial b} = (1\/2n) * (2b + 2wx - 2y)$\n\nTaking the parameters out that are independent of n\n\n$\\frac{\\partial J}{\\partial b} = (1\/2) * (2b) + (1\/2n) * (2wx - 2y) $\n\nTo find the value of b that minimizes the loss function, we equate $\\frac{\\partial J}{\\partial b} = 0$\n\n$(1\/2) * (2b) + (1\/2n) * (2wx - 2y) = 0 $\n\n$ b = (y - wx)\/n $\n\n$ b = (\\bar{y} - w\\bar{x}) $\n\n*********\n\n#### Taking the partial derivative wrt w\n\n$\\frac{\\partial J}{\\partial b} = (1\/2n) * (2wx^2 + 2bx - 2xy)$\n\n$\\frac{\\partial J}{\\partial b} = (1\/2n) * (2wx^2 + 2x(b - y))$\n\nSubstituting the value of b from earlier derivation and solving the equation algebraically, we get\n\n$ w = \\frac{1\/N(\\sum_{n=1}^{N} x_n t_n) - \\bar t \\bar x}{1\/N(\\sum_{n=1}^{N} x^2) - \\bar x \\bar x} $\n","588a8971":"**3.2 Simplifying the hypothesis function**\n\nHere, $\\theta_i$ are the parameters (also called weights) parameterizing the space of linear functions mapping from $X$ to $Y$. \n\nTo simplify our notation, we also introduce the convention of letting $x_0 = 1$ (this is the intercept term), so that ->\n\n<h3><center>$h(x) = \\sum_{i=0}^{n} \\theta_i x_i = \\theta^Tx$<\/center><\/h3>\n\n---\n","1cb6a2a1":"**5.3 Gradient Descent Update rule**<br>\n\nFor a single training example, the Gradient Descent update rule is\n<h3><center>$ \\theta_j := \\theta_j - \\alpha (h_{\\theta}x-y)*x_j$<\/center><\/h3>\n\nThe rule is called the LMS update rule (LMS stands for `least mean squares`), and is also known as the Widrow-Hoff learning rule. ","e86d3a67":"# Hypothesis function\n","772781da":"**5.2 Taking the partial derivative**<br>\nIn order to implement the `gradient descent algorithm`, we have to work out what is the `partial derivative` term on the right hand side. Let\u2019s first work it out for the case of if we have only one training example (x,y), so that we can neglect the sum in the definition of J.\n\nCalculating the Partial Derivative of $J(\\theta)$\n\n$\\frac{\\partial}{\\partial \\theta_j}J(\\theta) = \\frac{\\partial}{\\partial \\theta_j} \\frac{1}{2}(h_{\\theta}x-y)^2$\n\n$= 2*\\frac{1}{2}*(h_{\\theta}x-y)*\\frac{\\partial}{\\partial \\theta_j}(h_{\\theta}x-y)$\n\n$= 2*\\frac{1}{2}*(h_{\\theta}x-y)*\\frac{\\partial}{\\partial \\theta_j}\\sum_{i=0}^{d} (\\theta_{i} x_{i}-y)$\n\n$= (h_{\\theta}x-y)*x_j$\n\n---","b442798d":"# Cost function\n\nNow, given a training set, how do we pick, or learn, the parameters $\\theta$? \n\nOne reasonable method seems to be to make $h(x)$ close to $y$, at least for the training examples we have. To formalize this, we will define a function that measures, for each value of the $\\theta$, how close the $h(x_i)$ are to the corresponding $y_i$. We define the cost function:\n\n<h3><center> $J(\\theta) = (1\/2n)\\sum_{i=1}^{n} (h_{\\theta}x^{(i)}-y^{(i)})^2 $<\/center><\/h3>\n    \nIf you have seen linear regression before, you may recognize this as the familiar `least-squares cost function` that gives rise to the `ordinary least squares regression model`.\n\n----\n","fcec250c":"# Multiple approaches of executing the Linear Regression Algorithm","9eea38ef":"# Notation\n - We\u2019ll use $x^{(i)}$ to denote the `\u201cinput\u201d variables` (annual salaries in this example), also called input features,\n - $y^{(i)}$ to denote the `\u201coutput\u201d` or target variable that we are trying to predict (price of the car). \n - A pair $(x^{(i)},y^{(i)})$ is called a `training example`, and the dataset that we\u2019ll be using to learn\u2014a list of m training examples ${(x(i),y(i));i = 1, . . . , m}$\u2014is called a `training set`. Note that the superscript $\u201c(i)\u201d$ in the notation is simply an index into the training set, and has nothing to do with exponentiation. \n - We will also use $X$ denote the space of input values, and $Y$ the space of output values.\n\nTo describe the supervised learning problem slightly more formally, our goal is, \n- Given a training set, to learn a function $h: X->Y$ so that $h(x)$ is a \u201cgood\u201d predictor for the corresponding value of $y$. \n- For historical reasons, this function $h$ is called a `hypothesis`. \n\nSeen pictorially, the process is therefore like this:","ed78e232":"# End of Sheet","c9cd4d77":"## Mathematics behind Gradient Descent\n\nFirst we define the Hypothesis function - $h_{\\theta}x = \\theta_0 + \\theta_1*x_1 $\n\nThen, we define our cost function - $J(\\theta) = (1\/2n)\\sum_{i=1}^{n} (h_{\\theta}x^{(i)}-y^{(i)})^2 $\n\nNext, we define the Gradient Descent update rule - $ \\theta_j := \\theta_j - \\alpha \\frac{\\partial}{\\partial \\theta_j} J(\\theta)$\n\nHere, $\\alpha$ is the learning rate.\n\nCalculating the Partial Derivative of $J(\\theta)$\n\n$\\frac{\\partial}{\\partial \\theta_j}J(\\theta) = \\frac{\\partial}{\\partial \\theta_j} \\frac{1}{2}(h_{\\theta}x-y)^2$\n\n$= 2*\\frac{1}{2}*(h_{\\theta}x-y)*\\frac{\\partial}{\\partial \\theta_j}(h_{\\theta}x-y)$\n\n$= 2*\\frac{1}{2}*(h_{\\theta}x-y)*\\frac{\\partial}{\\partial \\theta_j}\\sum_{i=0}^{d} (\\theta_{i} x_{i}-y)$\n\n$= (h_{\\theta}x-y)*x_j$\n\nFor a single training example, the Gradient Descent update rule is\n$ \\theta_j := \\theta_j - \\alpha (h_{\\theta}x-y)*x_j$\n\nThe rule is called the LMS update rule (LMS stands for \u201cleast mean squares\u201d), and is also known as the Widrow-Hoff learning rule. ","efde805a":"# Newton Raphson method"}}