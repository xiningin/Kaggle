{"cell_type":{"5a58e89d":"code","3f892050":"code","39b4a3a9":"code","17029077":"code","d1b45915":"code","185c5e80":"code","cd14279f":"code","f3c3add6":"code","b78d2a46":"code","49907f04":"code","554303b6":"code","9203e265":"code","f0d78455":"code","d4251185":"code","c70d203e":"code","26c5fb5d":"code","7f99f9a0":"code","45c52fd2":"markdown","6bcda162":"markdown"},"source":{"5a58e89d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))   \n\n# Any results you write to the current directory are saved as output.","3f892050":"train = pd.read_csv('..\/input\/learn-together\/train.csv')  ## Load the Training Data set\ntest = pd.read_csv('..\/input\/learn-together\/test.csv')","39b4a3a9":"sample_submission = pd.read_csv('..\/input\/learn-together\/sample_submission.csv')\nsample_submission.head()","17029077":"train.head()  ## We find that there are numerous features\/columns in the data set that has zero values. This could be a good example for reducing the dimension of zero categoricals.","d1b45915":"train.info()  # Analyzing the Train data set indicates that there are no missing values and we have to only deal with categoricals that are zero.","185c5e80":"from sklearn.tree import DecisionTreeClassifier","cd14279f":"classifier = DecisionTreeClassifier(random_state=0)","f3c3add6":"X = train.drop(['Cover_Type'], axis=1)\ny = train['Cover_Type']","b78d2a46":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)","49907f04":"classifier.fit(X_train, y_train)","554303b6":"# test_pred = knn.predict(test)\n# test_pred","9203e265":"# \u7cbe\u5ea6\u3092\u8a08\u7b97\u3059\u308bmetrics\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u30a4\u30f3\u30dd\u30fc\u30c8\u3057\u307e\u3059\nfrom sklearn import metrics\n\n# # \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3092\u4e88\u6e2c\u3057\u307e\u3059\ny_pred = classifier.predict(X_test)\n\n# # \u7cbe\u5ea6\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\u7b97\u51fa\u306b\u306f metrics.accuracy_score\u3092\u4f7f\u7528\u3057\u307e\u3059\u3002\nprint(metrics.accuracy_score(y_test, y_pred))","f0d78455":"feature = X_train.columns\nimportances = classifier.feature_importances_\nindices = np.argsort(importances)\n\nplt.figure(figsize=(10,15))\nplt.bar(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), feature[indices])\nplt.show()","d4251185":"test_pred = classifier.predict(test)","c70d203e":"sample_submission['Cover_Type'] = test_pred\nsample_submission.to_csv('submission.csv', index=False)","26c5fb5d":"sample_submission","7f99f9a0":"!ls","45c52fd2":"** Load the Train and Test data sets into Pandas dataframes","6bcda162":"Initial Kaggle competition to predict forest type "}}