{"cell_type":{"239af3e4":"code","c00c69a2":"code","f0f72b98":"code","1dac67e5":"code","989e7a01":"code","6fe3116c":"code","bff92f44":"code","579c8974":"code","0edd8652":"code","e0742076":"code","a1acc2ab":"code","1deb14c4":"code","7669b35b":"code","5ef11801":"code","4ec89071":"code","d00e59cc":"code","56c926b9":"code","e50c10ff":"code","aff201f4":"code","9c31ee3f":"code","f2a3b974":"code","fcd4b107":"code","0c73fba6":"code","d04ece1e":"code","8cf76ef9":"code","47c60c54":"code","ee19db58":"code","ae276e97":"code","88cd27e1":"code","668f60b5":"code","17451c85":"code","aa424e30":"code","41942f20":"code","dda077c1":"code","21970df9":"code","7caac678":"code","a7bd0371":"code","c57263ac":"code","e7602764":"code","e046fa83":"code","98349cbc":"code","1224013b":"code","6ad88bb5":"code","7313a2d1":"code","cda9fc29":"code","9969e9a3":"code","acf08b5c":"code","cbe9948c":"code","b29d7239":"code","e95408cc":"code","0e8a55e4":"code","c2b3616f":"code","68fd3163":"code","70a57fb1":"code","cbefaf7b":"code","c908c8d5":"code","f14be7bd":"code","861f63cf":"code","6221319b":"code","64fad243":"code","d731f01c":"code","d4dcd24c":"code","0b0a910a":"code","cffde2d2":"code","0b10b7d8":"code","7f4faa41":"code","514b6137":"code","697205ed":"code","0c8ad3c4":"code","f1ef8567":"code","88474706":"code","86995231":"code","ebcd7fec":"code","98b97436":"code","9593bb92":"code","70a4ea7a":"code","16d7ff37":"code","872cc443":"code","446e476c":"code","b9193f91":"code","6138871a":"code","406ebb08":"code","ab809d85":"code","174213b0":"code","b81bb1c7":"code","7649098d":"code","01d998ec":"code","05e574e2":"code","508732af":"code","2f5515d5":"code","5bc4324a":"code","9a250133":"code","aed201ab":"code","4d6081ae":"code","920f73c8":"code","81db189e":"code","ca4ef83e":"code","c2baf1f8":"code","204991f0":"code","bfbcad3c":"code","8b4cbad4":"code","42ff8696":"code","925d79cb":"code","882f20d8":"code","283efa9e":"markdown","15007f29":"markdown","010b2555":"markdown","a5e27e49":"markdown","03f49d44":"markdown","d5e1d531":"markdown","c4ea2e3e":"markdown","3ca5dfe6":"markdown","16cdf823":"markdown","7d8dacd7":"markdown","dba15eba":"markdown","c72ea53a":"markdown","20f1e672":"markdown","f81e1bd5":"markdown","68b882e7":"markdown","af5324d6":"markdown","49e4ca52":"markdown","b9d2c56b":"markdown","5273da95":"markdown","088a2077":"markdown","051bf49a":"markdown","0e204c7c":"markdown","c3464333":"markdown","ef9d60b9":"markdown","d2c2eac8":"markdown"},"source":{"239af3e4":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier\nimport lightgbm\nfrom lightgbm import LGBMClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import roc_auc_score, accuracy_score\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.calibration import CalibratedClassifierCV\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport optuna\n\nimport random\n\nimport warnings\n\nwarnings.filterwarnings('ignore')","c00c69a2":"train1=pd.read_csv('..\/input\/training-apr\/train.csv')\ntest1=pd.read_csv('..\/input\/training-apr\/test.csv')\n\ntrain2=train1.copy()\ntest2=test1.copy()\n\ntrain1.drop(columns=['PassengerId','Name','Cabin','Ticket','SibSp','Parch','Age_log','Fare','Fare_cat','SibSp_log','Parch_log','related','related_cat'], inplace=True)\ntest1.drop(columns=['PassengerId','Name','Cabin','Ticket','SibSp','Parch','Age_log','Fare','Fare_cat','SibSp_log','Parch_log','related','related_cat'], inplace=True)\n\ntrain2.drop(columns=['PassengerId','Name','Cabin','Ticket','SibSp','Parch','Age_log','Fare','Fare_cat','SibSp_log','Parch_log','related','related_log'], inplace=True)\ntest2.drop(columns=['PassengerId','Name','Cabin','Ticket','SibSp','Parch','Age_log','Fare','Fare_cat','SibSp_log','Parch_log','related','related_log'], inplace=True)\n\nprint(\"set 1:\", train1.columns, test1.columns)\nprint(\"set 2:\", train2.columns, test2.columns)","f0f72b98":"print(\"is finite set1 Train:{} Test:{}\".format(np.isfinite(train1[['Age','Fare_log','related_log']]).any()[0],np.isfinite(test1[['Age','Fare_log','related_log']]).any()[0]))\nprint(\"is finite set2 Train:{} Test:{}\".format(np.isfinite(train2[['Age','Fare_log']]).any()[0],np.isfinite(test2[['Age','Fare_log']]).any()[0]))\n\nprint(\"is nan set1 Train:{} Test:{}\".format(sum(train1.isnull().sum()),sum(test1.isnull().sum())))\nprint(\"is nan set2 Train:{} Test:{}\".format(sum(train2.isnull().sum()),sum(train2.isnull().sum())))","1dac67e5":"score_train=pd.DataFrame(columns=['xg','rf','lg','cb']) # train data\nscore_test=pd.DataFrame(columns=['xg','rf','lg','cb']) # leadeboard data","989e7a01":"ohe=OneHotEncoder()\ncol=['Sex','Embarked']\nohe.fit(train1[col])\nprint(ohe.get_feature_names(col))\ndf1=pd.DataFrame(columns=ohe.get_feature_names(col),data=ohe.transform(train1[col]).toarray())\ndf2=pd.DataFrame(columns=ohe.get_feature_names(col),data=ohe.transform(test1[col]).toarray())\n\ntrain1=train1.join(df1)\ntest1=test1.join(df2)\n\ntrain1.drop(columns=['Sex','Embarked'], inplace=True)\ntest1.drop(columns=['Sex','Embarked'], inplace=True)","6fe3116c":"train1.head()","bff92f44":"test1.head()","579c8974":"folds=5\nSEED=random.randint(937,8641)\n\nkf=StratifiedKFold(n_splits=folds, random_state=SEED, shuffle=True)\n\nfeatures=train1.columns[1:]\nX = train1[features]\ny = train1['Survived']\n\n\nimbalanced_ratio=(train1[train1['Survived']==0]['Survived'].count()\/train1[train1['Survived']==1]['Survived'].count()).round(2)\nprint(\"Imbalnce ratio: {:}\".format(imbalanced_ratio))\n# x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=SEED)\n\n# print(\"Distribution of train and test:\", len(x_train), len(y_train), len(x_test), len(x_test))","0edd8652":"Trial=0\ndef objective(trial, x=x_train, y=y_train):\n    global Trial\n    \n    para={\n        'verbosity': 1,\n        'objective': 'binary:logistic',\n        'random_state': SEED,\n        'seed': SEED,\n        'tree_method':'hist',\n        'scale_pos_weight': imbalanced_ratio,\n        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1),\n        'subsample': trial.suggest_float('subsample', 0.1, 1),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1),\n        'n_estimators': trial.suggest_int('n_estimators',500, 20000),\n        'max_depth': trial.suggest_int('max_depth', 1, 31),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 1000)\n    }\n    \n    print(\"--------------------> Trial {} <--------------------\".format(Trial))\n    Trial=Trial + 1\n    xgboost_train_preds = np.zeros(len(y),)\n    for fold, (train_ind, val_ind) in enumerate(kf.split(x, y)):\n        print(\"--> Fold {}\".format(fold + 1))\n        xtrain, xval = x.iloc[train_ind], x.iloc[val_ind]\n        ytrain, yval = y.iloc[train_ind], y.iloc[val_ind]\n        xgboost = XGBClassifier(**para)\n        \n        model =  xgboost.fit(xtrain, ytrain, eval_set=[(xtrain,ytrain), (xval,yval)], \n                             eval_metric=[\"error\", \"logloss\"],verbose=0, early_stopping_rounds=50)\n        pred_train = model.predict(xtrain)\n        pred_val = model.predict(xval)\n        xgboost_train_preds[val_ind]=pred_val\n        score1 = accuracy_score(ytrain, pred_train)\n        score2 = accuracy_score(yval, pred_val)\n        print('Fold {} ACCURACY Train: {} Validation: {}'.format(fold+1, score1, score2))\n        \n        results = model.evals_result()\n        df=pd.DataFrame({\n                        \"validation_train_ll\":results[\"validation_0\"][\"logloss\"],\n                        \"validation_test_ll\":results[\"validation_1\"][\"logloss\"],\n                        \"validation_train_acc\":results[\"validation_0\"][\"error\"],\n                        \"validation_test_acc\":results[\"validation_1\"][\"error\"],\n                        \n        })\n        df['validation_train_acc']=(1-df['validation_train_acc'])*100.0\n        df['validation_test_acc']=(1-df['validation_test_acc'])*100.0\n#         print(df.head())\n        \n        fig, ax = plt.subplots(ncols=2, figsize=(12,6))\n        sns.lineplot(data=df, x=df.index, y=\"validation_train_ll\", ax=ax[0], label=\"Train loss\")\n        sns.lineplot(data=df, x=df.index, y=\"validation_test_ll\", ax=ax[0], label=\"Test loss\")\n        sns.lineplot(data=df, x=df.index, y=\"validation_train_acc\", ax=ax[1], label=\"Train acc.\")\n        sns.lineplot(data=df, x=df.index, y=\"validation_test_acc\", ax=ax[1], label=\"Test acc.\")\n        ax[0].set_title(\"Loss curve\")\n        ax[1].set_title(\"Accuracy curve\")\n        ax[0].set_ylabel(\"Loss\")\n        ax[0].set_xlabel(\"Itertation\")\n        ax[1].set_ylabel(\"Accuracy\")\n        ax[1].set_xlabel(\"Itertation\")\n        fig.suptitle(\"XGBoost Loss\/Accuracy.\")\n        plt.show()\n    acc=accuracy_score(y, xgboost_train_preds)\n    print('OOF ACCURACY: {}'.format(acc))\n    return acc","e0742076":"study=optuna.create_study(study_name=\"XGBoost set 1 Optimization\", direction='maximize')\nstudy.optimize(objective, n_trials=25)\n\ntrial = study.best_trial\nprint('Accuracy: {}'.format(trial.value))\n\nprint(\"Best hyperparameters: {}\".format(trial.params))","a1acc2ab":"#Tuning keeping the N-estimator same as the above best parameter\nTrial=0\ndef objective(trial, x=x_train, y=y_train):\n    global Trial\n    \n    para={\n        'verbosity': 1,\n        'objective': 'binary:logistic',\n        'random_state': SEED,\n        'seed': SEED,\n        'tree_method':'hist',\n        'scale_pos_weight': imbalanced_ratio,\n        'n_estimators': 7657,\n        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1),\n        'subsample': trial.suggest_float('subsample', 0.1, 1),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 1, 31),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 1000)\n    }\n    \n    print(\"--------------------> Trial {} <--------------------\".format(Trial))\n    Trial=Trial + 1\n    xgboost_train_preds = np.zeros(len(y),)\n    for fold, (train_ind, val_ind) in enumerate(kf.split(x, y)):\n        print(\"--> Fold {}\".format(fold + 1))\n        xtrain, xval = x.iloc[train_ind], x.iloc[val_ind]\n        ytrain, yval = y.iloc[train_ind], y.iloc[val_ind]\n        xgboost = XGBClassifier(**para)\n        \n        model =  xgboost.fit(xtrain, ytrain, eval_set=[(xtrain,ytrain), (xval,yval)], \n                             eval_metric=[\"error\", \"logloss\"],verbose=0, early_stopping_rounds=50)\n        pred_train = model.predict(xtrain)\n        pred_val = model.predict(xval)\n        xgboost_train_preds[val_ind]=pred_val\n        score1 = accuracy_score(ytrain, pred_train)\n        score2 = accuracy_score(yval, pred_val)\n        print('Fold {} ACCURACY Train: {} Validation: {}'.format(fold+1, score1, score2))\n        \n        results = model.evals_result()\n        df=pd.DataFrame({\n                        \"validation_train_ll\":results[\"validation_0\"][\"logloss\"],\n                        \"validation_test_ll\":results[\"validation_1\"][\"logloss\"],\n                        \"validation_train_acc\":results[\"validation_0\"][\"error\"],\n                        \"validation_test_acc\":results[\"validation_1\"][\"error\"],\n                        \n        })\n        df['validation_train_acc']=(1-df['validation_train_acc'])*100.0\n        df['validation_test_acc']=(1-df['validation_test_acc'])*100.0\n#         print(df.head())\n        \n        fig, ax = plt.subplots(ncols=2, figsize=(12,6))\n        sns.lineplot(data=df, x=df.index, y=\"validation_train_ll\", ax=ax[0], label=\"Train loss\")\n        sns.lineplot(data=df, x=df.index, y=\"validation_test_ll\", ax=ax[0], label=\"Test loss\")\n        sns.lineplot(data=df, x=df.index, y=\"validation_train_acc\", ax=ax[1], label=\"Train acc.\")\n        sns.lineplot(data=df, x=df.index, y=\"validation_test_acc\", ax=ax[1], label=\"Test acc.\")\n        ax[0].set_title(\"Loss curve\")\n        ax[1].set_title(\"Accuracy curve\")\n        ax[0].set_ylabel(\"Loss\")\n        ax[0].set_xlabel(\"Itertation\")\n        ax[1].set_ylabel(\"Accuracy\")\n        ax[1].set_xlabel(\"Itertation\")\n        fig.suptitle(\"XGBoost Loss\/Accuracy.\")\n        plt.show()\n    acc=accuracy_score(y, xgboost_train_preds)\n    print('OOF ACCURACY: {}'.format(acc))\n    return acc","1deb14c4":"study=optuna.create_study(study_name=\"XGBoost Optimization\", direction='maximize')\nstudy.optimize(objective, n_trials=15)\n\ntrial = study.best_trial\nprint('Accuracy: {}'.format(trial.value))\n\nprint(\"Best hyperparameters: {}\".format(trial.params))","7669b35b":"para = {\n        'verbosity': 1,\n        'objective': 'binary:logistic',\n        'random_state': SEED,\n        'seed': SEED,\n        'tree_method':'hist',\n        'scale_pos_weight': imbalanced_ratio,\n        'lambda': 0.040336438299178316, \n        'alpha': 1.6115451006296893, \n        'colsample_bytree': 0.6421153349186888, \n        'subsample': 0.9948174596370332, \n        'learning_rate': 0.08617507766633564, \n        'n_estimators': 7657, \n        'max_depth': 18, \n        'min_child_weight': 114\n      }","5ef11801":"xg_train_preds = np.zeros(len(y),)\nxg_test = np.zeros(len(test1),)\nfor fold, (train_ind, val_ind) in enumerate(kf.split(X, y)):\n    print(\"--> Fold {}\".format(fold + 1))\n    \n    xtrain, xval = X.iloc[train_ind], X.iloc[val_ind]\n    ytrain, yval = y.iloc[train_ind], y.iloc[val_ind]\n    \n    xgboost = XGBClassifier(**para)\n\n    model = xgboost.fit(xtrain, ytrain, eval_set=[(xtrain,ytrain), (xval,yval)], \n                         eval_metric=[\"error\", \"logloss\"], verbose=0, early_stopping_rounds=50)\n    pred_train = model.predict_proba(xtrain)[:,1]\n    pred_val = model.predict_proba(xval)[:,1]\n    xg_train_preds[val_ind] = pred_val\n#     xg_test_preds += (model.predict_proba(x_test)[:,1])\/folds\n    xg_test += (model.predict_proba(test1)[:,1])\/folds\n    score1 = accuracy_score(ytrain, np.where(pred_train<=0.5, 0, 1))\n    score2 = accuracy_score(yval, np.where(pred_val<=0.5, 0, 1))\n    print('Fold {} ACCURACY Train: {} Validation: {}'.format(fold+1, score1, score2))\n\n    results = model.evals_result()\n    df=pd.DataFrame({\n                    \"validation_train_ll\":results[\"validation_0\"][\"logloss\"],\n                    \"validation_test_ll\":results[\"validation_1\"][\"logloss\"],\n                    \"validation_train_acc\":results[\"validation_0\"][\"error\"],\n                    \"validation_test_acc\":results[\"validation_1\"][\"error\"],\n\n    })\n    df['validation_train_acc']=(1-df['validation_train_acc'])*100.0\n    df['validation_test_acc']=(1-df['validation_test_acc'])*100.0\n    #         print(df.head())\n\n    fig, ax = plt.subplots(ncols=2, figsize=(12,6))\n    sns.lineplot(data=df, x=df.index, y=\"validation_train_ll\", ax=ax[0], label=\"Train loss\")\n    sns.lineplot(data=df, x=df.index, y=\"validation_test_ll\", ax=ax[0], label=\"Test loss\")\n    sns.lineplot(data=df, x=df.index, y=\"validation_train_acc\", ax=ax[1], label=\"Train acc.\")\n    sns.lineplot(data=df, x=df.index, y=\"validation_test_acc\", ax=ax[1], label=\"Test acc.\")\n    ax[0].set_title(\"Loss curve\")\n    ax[1].set_title(\"Accuracy curve\")\n    ax[0].set_ylabel(\"Loss\")\n    ax[0].set_xlabel(\"Itertation\")\n    ax[1].set_ylabel(\"Accuracy\")\n    ax[1].set_xlabel(\"Itertation\")\n    fig.suptitle(\"XGBoost Loss\/Accuracy.\")\n    plt.show()\n    \nacc1 = accuracy_score(y, np.where(xg_train_preds<=0.5, 0, 1))\n# acc2 = accuracy_score(y_test, np.where(xg_test_preds<=0.5, 0, 1))\nprint('OOF ACCURACY Train: {}'.format(acc1))\n\nscore_train['xg'] = xg_train_preds\nscore_test['xg'] = xg_test","4ec89071":"score_train.head()","d00e59cc":"score_test.head()","56c926b9":"score_train.to_csv('.\/score_train.csv',index=False)\nscore_test.to_csv('.\/score_test.csv',index=False)","e50c10ff":"test_=pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/test.csv')\ndf=pd.DataFrame()\ndf['PassengerId']=test_['PassengerId'].values\ndf['Survived']=score_test['xg']\ndf['Survived']=df['Survived'].apply(lambda x:0 if x<=0.5 else 1)\ndf.to_csv('.\/xg_tuned.csv',index=False)","aff201f4":"ohe=OneHotEncoder()\ncol=['Sex','Embarked']\nohe.fit(train2[col])\nprint(ohe.get_feature_names(col))\ndf1=pd.DataFrame(columns=ohe.get_feature_names(col),data=ohe.transform(train2[col]).toarray())\ndf2=pd.DataFrame(columns=ohe.get_feature_names(col),data=ohe.transform(test2[col]).toarray())\n\ntrain2=train2.join(df1)\ntest2=test2.join(df2)\n\ntrain2['related_cat'] = train2['related_cat'].apply(lambda x:1 if x in ['low'] else 2)\ntest2['related_cat'] = test2['related_cat'].apply(lambda x:1 if x in ['low'] else 2)\n\ntrain2.drop(columns=['Sex','Embarked'], inplace=True)\ntest2.drop(columns=['Sex','Embarked'], inplace=True)","9c31ee3f":"train2.head()","f2a3b974":"test2.head()","fcd4b107":"folds=5\nSEED=random.randint(937,8641)\n\nkf=StratifiedKFold(n_splits=folds, random_state=SEED, shuffle=True)\n\nfeatures=train2.columns[1:]\nX = train2[features]\ny = train2['Survived']\n\n\nimbalanced_ratio=(train2[train2['Survived']==0]['Survived'].count()\/train2[train2['Survived']==1]['Survived'].count()).round(2)\nprint(\"Imbalnce ratio: {:}\".format(imbalanced_ratio))\n\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=SEED)\nprint(\"Distribution of train and test:\", len(x_train), len(y_train), len(x_test), len(x_test))","0c73fba6":"Trial=0\ndef objective(trial, x=x_train, y=y_train):\n    global Trial\n    \n    para={\n        'verbosity': 1,\n        'objective': 'binary:logistic',\n        'random_state': SEED,\n        'seed': SEED,\n        'tree_method':'hist',\n        'scale_pos_weight': imbalanced_ratio,\n        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1),\n        'subsample': trial.suggest_float('subsample', 0.1, 1),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1),\n        'n_estimators': trial.suggest_int('n_estimators',500, 20000),\n        'max_depth': trial.suggest_int('max_depth', 1, 31),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 1000)\n    }\n    \n    print(\"--------------------> Trial {} <--------------------\".format(Trial))\n    Trial=Trial + 1\n    xgboost_train_preds = np.zeros(len(y),)\n    for fold, (train_ind, val_ind) in enumerate(kf.split(x, y)):\n        callbacks=[early_stopping_round]\n        print(\"--> Fold {}\".format(fold + 1))\n        xtrain, xval = x.iloc[train_ind], x.iloc[val_ind]\n        ytrain, yval = y.iloc[train_ind], y.iloc[val_ind]\n        xgboost = XGBClassifier(**para)\n        \n        model =  xgboost.fit(xtrain, ytrain, eval_set=[(xtrain,ytrain), (xval,yval)], \n                             eval_metric=[\"error\", \"logloss\"],verbose=0,callbacks=[early_stopping_round])\n        pred_train = model.predict(xtrain)\n        pred_val = model.predict(xval)\n        xgboost_train_preds[val_ind]=pred_val\n        score1 = accuracy_score(ytrain, pred_train)\n        score2 = accuracy_score(yval, pred_val)\n        print('Fold {} ACCURACY Train: {} Validation: {}'.format(fold+1, score1, score2))\n        \n        results = model.evals_result()\n        df=pd.DataFrame({\n                        \"validation_train_ll\":results[\"validation_0\"][\"logloss\"],\n                        \"validation_test_ll\":results[\"validation_1\"][\"logloss\"],\n                        \"validation_train_acc\":results[\"validation_0\"][\"error\"],\n                        \"validation_test_acc\":results[\"validation_1\"][\"error\"],\n                        \n        })\n        df['validation_train_acc']=(1-df['validation_train_acc'])*100.0\n        df['validation_test_acc']=(1-df['validation_test_acc'])*100.0\n#         print(df.head())\n        \n        fig, ax = plt.subplots(ncols=2, figsize=(12,6))\n        sns.lineplot(data=df, x=df.index, y=\"validation_train_ll\", ax=ax[0], label=\"Train loss\")\n        sns.lineplot(data=df, x=df.index, y=\"validation_test_ll\", ax=ax[0], label=\"Test loss\")\n        sns.lineplot(data=df, x=df.index, y=\"validation_train_acc\", ax=ax[1], label=\"Train acc.\")\n        sns.lineplot(data=df, x=df.index, y=\"validation_test_acc\", ax=ax[1], label=\"Test acc.\")\n        ax[0].set_title(\"Loss curve\")\n        ax[1].set_title(\"Accuracy curve\")\n        ax[0].set_ylabel(\"Loss\")\n        ax[0].set_xlabel(\"Itertation\")\n        ax[1].set_ylabel(\"Accuracy\")\n        ax[1].set_xlabel(\"Itertation\")\n        fig.suptitle(\"XGBoost Loss\/Accuracy.\")\n        plt.show()\n    acc=accuracy_score(y, xgboost_train_preds)\n    print('OOF ACCURACY: {}'.format(acc))\n    return acc","d04ece1e":"study=optuna.create_study(study_name=\"XGBoost set 2 Optimization\", direction='maximize')\nstudy.optimize(objective, n_trials=50)\n\ntrial = study.best_trial\nprint('Accuracy: {}'.format(trial.value))\n\nprint(\"Best hyperparameters: {}\".format(trial.params))","8cf76ef9":"para = {\n        'verbosity': 1,\n        'objective': 'binary:logistic',\n        'random_state': SEED,\n        'seed': SEED,\n        'tree_method':'hist',\n        'scale_pos_weight': imbalanced_ratio,\n        'lambda': 0.23870865587316725, \n        'alpha': 0.05851635206035666, \n        'colsample_bytree': 0.1050482977664344, \n        'subsample': 0.9719852687976757, \n        'learning_rate': 0.06744568400126143, \n        'n_estimators': 19537, 'max_depth': 3, \n        'min_child_weight': 498\n       }","47c60c54":"xg_train_preds = np.zeros(len(y_train),)\nxg_test_preds = np.zeros(len(y_test),)\nxg_test = np.zeros(len(test2),)\nfor fold, (train_ind, val_ind) in enumerate(kf.split(x_train, y_train)):\n    print(\"--> Fold {}\".format(fold + 1))\n    \n    xtrain, xval = x_train.iloc[train_ind], x_train.iloc[val_ind]\n    ytrain, yval = y_train.iloc[train_ind], y_train.iloc[val_ind]\n    \n    xgboost = XGBClassifier(**para)\n\n    model = xgboost.fit(xtrain, ytrain, eval_set=[(xtrain,ytrain), (xval,yval)], \n                         eval_metric=[\"error\", \"logloss\"], verbose=0, early_stopping_rounds=50)\n    pred_train = model.predict_proba(xtrain)[:,1]\n    pred_val = model.predict_proba(xval)[:,1]\n    xg_train_preds[val_ind] = pred_val\n    xg_test_preds += (model.predict_proba(x_test)[:,1])\/folds\n    xg_test += (model.predict_proba(test2)[:,1])\/folds\n    score1 = accuracy_score(ytrain, np.where(pred_train<=0.5, 0, 1))\n    score2 = accuracy_score(yval, np.where(pred_val<=0.5, 0, 1))\n    print('Fold {} ACCURACY Train: {} Validation: {}'.format(fold+1, score1, score2))\n\n    results = model.evals_result()\n    df=pd.DataFrame({\n                    \"validation_train_ll\":results[\"validation_0\"][\"logloss\"],\n                    \"validation_test_ll\":results[\"validation_1\"][\"logloss\"],\n                    \"validation_train_acc\":results[\"validation_0\"][\"error\"],\n                    \"validation_test_acc\":results[\"validation_1\"][\"error\"],\n\n    })\n    df['validation_train_acc']=(1-df['validation_train_acc'])*100.0\n    df['validation_test_acc']=(1-df['validation_test_acc'])*100.0\n    #         print(df.head())\n\n    fig, ax = plt.subplots(ncols=2, figsize=(12,6))\n    sns.lineplot(data=df, x=df.index, y=\"validation_train_ll\", ax=ax[0], label=\"Train loss\")\n    sns.lineplot(data=df, x=df.index, y=\"validation_test_ll\", ax=ax[0], label=\"Test loss\")\n    sns.lineplot(data=df, x=df.index, y=\"validation_train_acc\", ax=ax[1], label=\"Train acc.\")\n    sns.lineplot(data=df, x=df.index, y=\"validation_test_acc\", ax=ax[1], label=\"Test acc.\")\n    ax[0].set_title(\"Loss curve\")\n    ax[1].set_title(\"Accuracy curve\")\n    ax[0].set_ylabel(\"Loss\")\n    ax[0].set_xlabel(\"Itertation\")\n    ax[1].set_ylabel(\"Accuracy\")\n    ax[1].set_xlabel(\"Itertation\")\n    fig.suptitle(\"XGBoost Loss\/Accuracy.\")\n    plt.show()\n    \nacc1 = accuracy_score(y_train, np.where(xg_train_preds<=0.5, 0, 1))\nacc2 = accuracy_score(y_test, np.where(xg_test_preds<=0.5, 0, 1))\nprint('OOF ACCURACY Train: {} Test: {}'.format(acc1, acc2))\n\n# score_train['xg']=np.concatenate([xg_train_preds,xg_test_preds])\n# score_test['xg']=xg_test","ee19db58":"test_=pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/test.csv')\ndf=pd.DataFrame()\ndf['PassengerId']=test_['PassengerId'].values\ndf['Survived']=xg_test\ndf['Survived']=df['Survived'].apply(lambda x:0 if x<=0.5 else 1)\ndf.to_csv('.\/xg_tuned_set2.csv',index=False)","ae276e97":"train1=pd.read_csv('..\/input\/training-apr\/train.csv')\ntest1=pd.read_csv('..\/input\/training-apr\/test.csv')\n\ntrain2=train1.copy()\ntest2=test1.copy()\n\ntrain1.drop(columns=['PassengerId','Name','Cabin','Ticket','SibSp','Parch','Age_log','Fare','Fare_cat','SibSp_log','Parch_log','related','related_cat'], inplace=True)\ntest1.drop(columns=['PassengerId','Name','Cabin','Ticket','SibSp','Parch','Age_log','Fare','Fare_cat','SibSp_log','Parch_log','related','related_cat'], inplace=True)\n\ntrain2.drop(columns=['PassengerId','Name','Cabin','Ticket','SibSp','Parch','Age_log','Fare','Fare_cat','SibSp_log','Parch_log','related','related_log'], inplace=True)\ntest2.drop(columns=['PassengerId','Name','Cabin','Ticket','SibSp','Parch','Age_log','Fare','Fare_cat','SibSp_log','Parch_log','related','related_log'], inplace=True)\n\nprint(\"set 1:\", train1.columns, test1.columns)\nprint(\"set 2:\", train2.columns, test2.columns)","88cd27e1":"ohe=OneHotEncoder()\ncol=['Sex','Embarked']\nohe.fit(train1[col])\nprint(ohe.get_feature_names(col))\ndf1=pd.DataFrame(columns=ohe.get_feature_names(col),data=ohe.transform(train1[col]).toarray())\ndf2=pd.DataFrame(columns=ohe.get_feature_names(col),data=ohe.transform(test1[col]).toarray())\n\ntrain1=train1.join(df1)\ntest1=test1.join(df2)\n\ntrain1.drop(columns=['Sex','Embarked'], inplace=True)\ntest1.drop(columns=['Sex','Embarked'], inplace=True)","668f60b5":"train1.head()","17451c85":"test1.head()","aa424e30":"folds=5\nSEED=random.randint(937,8641)\n\nkf=StratifiedKFold(n_splits=folds, random_state=SEED, shuffle=True)\n\nfeatures=train1.columns[1:]\nX = train1[features]\ny = train1['Survived']\n\n\nimbalanced_ratio=(train1[train1['Survived']==0]['Survived'].count()\/train1[train1['Survived']==1]['Survived'].count()).round(2)\nprint(\"Imbalnce ratio: {:}\".format(imbalanced_ratio))\n# x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=SEED)\n\n# print(\"Distribution of train and test:\", len(x_train), len(y_train), len(x_test), len(x_test))","41942f20":"Trial=0\n\ndef objective(trial, x=x_train, y=y_train):\n    global Trial\n    \n    para = {\n              'verbosity': 1,\n              'random_state': SEED,\n              'n_jobs': -1,\n              'is_unbalance': True,\n              'bagging_seed': SEED,\n              'feature_fraction_seed': SEED,\n              'objective': 'binary', \n              'boosting': trial.suggest_categorical('boosting', ['gbdt','rf']),\n              'n_estimators': trial.suggest_int('n_estimators',500, 20000),\n              'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1),\n              'max_depth': trial.suggest_int('max_depth', 6, 127),\n              'num_leaves': trial.suggest_int('num_leaves', 31, 128),\n              'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 10.0),\n              'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 10.0),\n              'feature_fraction': trial.suggest_float('feature_fraction', 0.2, 0.9),\n              'min_child_samples': trial.suggest_int('min_child_samples', 1, 300),\n              'bagging_freq': trial.suggest_int('bagging_freq', 50, 15000),\n              'bagging_fraction': trial.suggest_float('bagging_fraction', 0, 0.9),\n              'max_bin': trial.suggest_int('max_bin', 128, 1024)\n            }\n    \n    print(\"--------------------> Trial {} <--------------------\".format(Trial))\n    Trial=Trial + 1\n    lgbm_train_preds = np.zeros(len(y),)\n    \n    for fold, (train_ind, val_ind) in enumerate(kf.split(x, y)):\n        print(\"--> Fold {}\".format(fold + 1))\n        xtrain, xval = x.iloc[train_ind], x.iloc[val_ind]\n        ytrain, yval = y.iloc[train_ind], y.iloc[val_ind]\n        \n        lgbm = LGBMClassifier(**para)\n        \n        early_stopping = lightgbm.early_stopping(25, first_metric_only=True, verbose=True)\n        \n        model =  lgbm.fit(xtrain, ytrain, eval_set=[(xtrain,ytrain), (xval,yval)], categorical_feature=None,\n                          eval_metric = ['binary_logloss', 'binary_error'], verbose=100, callbacks=[early_stopping])\n        \n        pred_train = model.predict(xtrain, num_iteration=model.best_iteration_)\n        pred_val = model.predict(xval, num_iteration=model.best_iteration_)\n        lgbm_train_preds[val_ind]=pred_val\n        score1 = accuracy_score(ytrain, pred_train)\n        score2 = accuracy_score(yval, pred_val)\n        print('Fold {} ACCURACY Train: {} Validation: {}'.format(fold+1, score1, score2))\n        \n        results = model.evals_result_\n        df=pd.DataFrame({\n                        \"train_ll\":results[\"training\"][\"binary_logloss\"],\n                        \"validation_ll\":results[\"valid_1\"][\"binary_logloss\"],\n                        \"train_acc\":results[\"training\"][\"binary_error\"],\n                        \"test_acc\":results[\"valid_1\"][\"binary_error\"],\n        })\n        df['train_acc']=(1-df['train_acc'])*100.0\n        df['test_acc']=(1-df['test_acc'])*100.0\n#         print(df.head())\n        \n        fig, ax = plt.subplots(ncols=2, figsize=(12,6))\n        sns.lineplot(data=df, x=df.index, y=\"train_ll\", ax=ax[0], label=\"Train loss\")\n        sns.lineplot(data=df, x=df.index, y=\"validation_ll\", ax=ax[0], label=\"Validation loss\")\n        sns.lineplot(data=df, x=df.index, y=\"train_acc\", ax=ax[1], label=\"Train acc.\")\n        sns.lineplot(data=df, x=df.index, y=\"test_acc\", ax=ax[1], label=\"Validation acc.\")\n        ax[0].set_title(\"Loss curve\")\n        ax[1].set_title(\"Accuracy curve\")\n        ax[0].set_ylabel(\"Loss\")\n        ax[0].set_xlabel(\"Itertation\")\n        ax[1].set_ylabel(\"Accuracy\")\n        ax[1].set_xlabel(\"Itertation\")\n        fig.suptitle(\"LightGBM Loss\/Accuracy.\")\n        plt.show()\n    acc=accuracy_score(y, lgbm_train_preds)\n    print('OOF ACCURACY: {}'.format(acc))\n    return acc","dda077c1":"study=optuna.create_study(study_name=\"LightGBM set 1 Optimization\", direction='maximize')\nstudy.optimize(objective, n_trials=25)\n\ntrial = study.best_trial\nprint('Accuracy: {}'.format(trial.value))\n\nprint(\"Best hyperparameters: {}\".format(trial.params))","21970df9":"para = {\n        'verbosity': 1,\n        'random_state': SEED,\n        'n_jobs': -1,\n        'is_unbalance': True,\n        'bagging_seed': SEED,\n        'feature_fraction_seed': SEED,\n        'objective': 'binary',\n        'boosting': 'gbdt', \n        'n_estimators': 12792, \n        'learning_rate': 0.0998109583959103, \n        'max_depth': 67, \n        'num_leaves': 81, \n        'reg_alpha': 8.95628715211493, \n        'reg_lambda': 2.5201711907717668, \n        'feature_fraction': 0.591553893731912, \n        'min_child_samples': 206, \n        'bagging_freq': 2628, \n        'bagging_fraction': 0.661876388933661, \n        'max_bin': 230\n       }","7caac678":"lg_train_preds = np.zeros(len(y),)\nlg_test = np.zeros(len(test1),)\nfor fold, (train_ind, val_ind) in enumerate(kf.split(X, y)):\n    print(\"--> Fold {}\".format(fold + 1))\n    \n    xtrain, xval = X.iloc[train_ind], X.iloc[val_ind]\n    ytrain, yval = y.iloc[train_ind], y.iloc[val_ind]\n    \n    early_stopping_round = lightgbm.early_stopping(25, first_metric_only=True, verbose=True)\n    \n    lgbm = LGBMClassifier(**para)\n        \n    model =  lgbm.fit(xtrain, ytrain, eval_set=[(xtrain,ytrain), (xval,yval)], categorical_feature=None,\n                      eval_metric = ['binary_logloss', 'binary_error'], verbose=100, callbacks=[early_stopping_round])\n    pred_train = model.predict_proba(xtrain, num_iteration=model.best_iteration_)[:,1]\n    pred_val = model.predict_proba(xval, num_iteration=model.best_iteration_)[:,1]\n    lg_train_preds[val_ind] = pred_val\n    lg_test += (model.predict_proba(test1, num_iteration=model.best_iteration_)[:,1])\/folds\n    score1 = accuracy_score(ytrain, np.where(pred_train<=0.5, 0, 1))\n    score2 = accuracy_score(yval, np.where(pred_val<=0.5, 0, 1))\n    print('Fold {} ACCURACY Train: {} Validation: {}'.format(fold+1, score1, score2))\n\n    results = model.evals_result_\n    df=pd.DataFrame({\n                    \"train_ll\":results[\"training\"][\"binary_logloss\"],\n                    \"validation_ll\":results[\"valid_1\"][\"binary_logloss\"],\n                    \"train_acc\":results[\"training\"][\"binary_error\"],\n                    \"test_acc\":results[\"valid_1\"][\"binary_error\"],\n\n    })\n    df['train_acc']=(1-df['train_acc'])*100.0\n    df['test_acc']=(1-df['test_acc'])*100.0\n#         print(df.head())\n\n    fig, ax = plt.subplots(ncols=2, figsize=(12,6))\n    sns.lineplot(data=df, x=df.index, y=\"train_ll\", ax=ax[0], label=\"Train loss\")\n    sns.lineplot(data=df, x=df.index, y=\"validation_ll\", ax=ax[0], label=\"Validation loss\")\n    sns.lineplot(data=df, x=df.index, y=\"train_acc\", ax=ax[1], label=\"Train acc.\")\n    sns.lineplot(data=df, x=df.index, y=\"test_acc\", ax=ax[1], label=\"Validation acc.\")\n    ax[0].set_title(\"Loss curve\")\n    ax[1].set_title(\"Accuracy curve\")\n    ax[0].set_ylabel(\"Loss\")\n    ax[0].set_xlabel(\"Itertation\")\n    ax[1].set_ylabel(\"Accuracy\")\n    ax[1].set_xlabel(\"Itertation\")\n    fig.suptitle(\"LightGBM Loss\/Accuracy.\")\n    plt.show()\n    \nacc1 = accuracy_score(y, np.where(lg_train_preds<=0.5, 0, 1))\n# acc2 = accuracy_score(y_test, np.where(lg_test_preds<=0.5, 0, 1))\n\nprint('OOF ACCURACY Train: {}'.format(acc1))\n\n# score_train=pd.read_csv('..\/input\/score-tab-apr21\/score_train.csv')\n# score_test=pd.read_csv('..\/input\/score-tab-apr21\/score_test.csv')\n\nscore_train['lg']=lg_train_preds\nscore_test['lg']=lg_test","a7bd0371":"score_train.head()","c57263ac":"score_test.head()","e7602764":"score_train.to_csv('.\/score_train.csv',index=False)\nscore_test.to_csv('.\/score_test.csv',index=False)","e046fa83":"test_=pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/test.csv')\ndf=pd.DataFrame()\ndf['PassengerId']=test_['PassengerId'].values\ndf['Survived']=lg_test\ndf['Survived']=df['Survived'].apply(lambda x:0 if x<=0.5 else 1)\ndf.to_csv('.\/lg_tuned.csv',index=False)","98349cbc":"ohe=OneHotEncoder()\ncol=['Sex','Embarked']\nohe.fit(train2[col])\nprint(ohe.get_feature_names(col))\ndf1=pd.DataFrame(columns=ohe.get_feature_names(col),data=ohe.transform(train2[col]).toarray())\ndf2=pd.DataFrame(columns=ohe.get_feature_names(col),data=ohe.transform(test2[col]).toarray())\n\ntrain2=train2.join(df1)\ntest2=test2.join(df2)\n\ntrain2['related_cat'] = train2['related_cat'].apply(lambda x:1 if x in ['low'] else 2)\ntest2['related_cat'] = test2['related_cat'].apply(lambda x:1 if x in ['low'] else 2)\n\ntrain2.drop(columns=['Sex','Embarked'], inplace=True)\ntest2.drop(columns=['Sex','Embarked'], inplace=True)","1224013b":"train2.head()","6ad88bb5":"test2.head()","7313a2d1":"folds=5\nSEED=random.randint(937,8641)\n\nkf=StratifiedKFold(n_splits=folds, random_state=SEED, shuffle=True)\n\nfeatures=train2.columns[1:]\nX = train2[features]\ny = train2['Survived']\n\n\nimbalanced_ratio=(train2[train2['Survived']==0]['Survived'].count()\/train2[train2['Survived']==1]['Survived'].count()).round(2)\nprint(\"Imbalnce ratio: {:}\".format(imbalanced_ratio))\n\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=SEED)\nprint(\"Distribution of train and test:\", len(x_train), len(y_train), len(x_test), len(x_test))","cda9fc29":"Trial=0\n\n\ndef objective(trial, x=x_train, y=y_train):\n    global Trial\n    \n    para = {\n              'verbosity': 1,\n              'random_state': SEED,\n              'n_jobs': -1,\n              'is_unbalance': True,\n              'bagging_seed': SEED,\n              'feature_fraction_seed': SEED,\n              'objective': 'binary',\n              'boosting': trial.suggest_categorical('boosting', ['gbdt','rf']),\n              'n_estimators': trial.suggest_int('n_estimators',500, 20000),\n              'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1),\n              'max_depth': trial.suggest_int('max_depth', 6, 127),\n              'num_leaves': trial.suggest_int('num_leaves', 31, 128),\n              'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 10.0),\n              'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 10.0),\n              'feature_fraction': trial.suggest_float('feature_fraction', 0.2, 0.9),\n              'min_child_samples': trial.suggest_int('min_child_samples', 1, 300),\n              'bagging_freq': trial.suggest_int('bagging_freq', 50, 15000),\n              'bagging_fraction': trial.suggest_float('bagging_fraction', 0, 0.9),\n              'max_bin': trial.suggest_int('max_bin', 128, 1024)\n            }\n    \n    print(\"--------------------> Trial {} <--------------------\".format(Trial))\n    Trial=Trial + 1\n    lgbm_train_preds = np.zeros(len(y),)\n    for fold, (train_ind, val_ind) in enumerate(kf.split(x, y)):\n        print(\"--> Fold {}\".format(fold + 1))\n        xtrain, xval = x.iloc[train_ind], x.iloc[val_ind]\n        ytrain, yval = y.iloc[train_ind], y.iloc[val_ind]\n        lgbm = LGBMClassifier(**para)\n        \n        early_stopping_round = lightgbm.early_stopping(25, first_metric_only=True, verbose=True)\n        model =  lgbm.fit(xtrain, ytrain, eval_set=[(xtrain,ytrain), (xval,yval)], categorical_feature=None,\n                             eval_metric = ['binary_logloss', 'binary_error'], verbose=100, callbacks=[early_stopping_round])\n        \n        pred_train = model.predict(xtrain, num_iteration=model.best_iteration_)\n        pred_val = model.predict(xval, num_iteration=model.best_iteration_)\n        lgbm_train_preds[val_ind]=pred_val\n        score1 = accuracy_score(ytrain, pred_train)\n        score2 = accuracy_score(yval, pred_val)\n        print('Fold {} ACCURACY Train: {} Validation: {}'.format(fold+1, score1, score2))\n        \n        results = model.evals_result_\n        df=pd.DataFrame({\n                        \"train_ll\":results[\"training\"][\"binary_logloss\"],\n                        \"validation_ll\":results[\"valid_1\"][\"binary_logloss\"],\n                        \"train_acc\":results[\"training\"][\"binary_error\"],\n                        \"test_acc\":results[\"valid_1\"][\"binary_error\"],\n                        \n        })\n        df['train_acc']=(1-df['train_acc'])*100.0\n        df['test_acc']=(1-df['test_acc'])*100.0\n#         print(df.head())\n        \n        fig, ax = plt.subplots(ncols=2, figsize=(12,6))\n        sns.lineplot(data=df, x=df.index, y=\"train_ll\", ax=ax[0], label=\"Train loss\")\n        sns.lineplot(data=df, x=df.index, y=\"validation_ll\", ax=ax[0], label=\"Validation loss\")\n        sns.lineplot(data=df, x=df.index, y=\"train_acc\", ax=ax[1], label=\"Train acc.\")\n        sns.lineplot(data=df, x=df.index, y=\"test_acc\", ax=ax[1], label=\"Validation acc.\")\n        ax[0].set_title(\"Loss curve\")\n        ax[1].set_title(\"Accuracy curve\")\n        ax[0].set_ylabel(\"Loss\")\n        ax[0].set_xlabel(\"Itertation\")\n        ax[1].set_ylabel(\"Accuracy\")\n        ax[1].set_xlabel(\"Itertation\")\n        fig.suptitle(\"LightGBM Loss\/Accuracy.\")\n        plt.show()\n    acc=accuracy_score(y, lgbm_train_preds)\n    print('OOF ACCURACY: {}'.format(acc))\n    return acc","9969e9a3":"study=optuna.create_study(study_name=\"LightGBM set 2 Optimization\", direction='maximize')\nstudy.optimize(objective, n_trials=25)\n\ntrial = study.best_trial\nprint('Accuracy: {}'.format(trial.value))\n\nprint(\"Best hyperparameters: {}\".format(trial.params))","acf08b5c":"para = {\n        'verbosity': 1,\n        'random_state': SEED,\n        'n_jobs': -1,\n        'is_unbalance': True,\n        'bagging_seed': SEED,\n        'feature_fraction_seed': SEED,\n        'objective': 'binary',\n        'boosting': 'gbdt', \n        'n_estimators': 10701, \n        'learning_rate': 0.06955447670117614, \n        'max_depth': 65, 'num_leaves': 110, \n        'reg_alpha': 8.557750007560998, \n        'reg_lambda': 0.016304042294640997, \n        'feature_fraction': 0.2779304475599476, \n        'min_child_samples': 233, \n        'bagging_freq': 14930, \n        'bagging_fraction': 0.8838910149186466, \n        'max_bin': 370\n       }","cbe9948c":"lg_train_preds = np.zeros(len(y_train),)\nlg_test_preds = np.zeros(len(y_test),)\nlg_test = np.zeros(len(test2),)\nfor fold, (train_ind, val_ind) in enumerate(kf.split(x_train, y_train)):\n    print(\"--> Fold {}\".format(fold + 1))\n    \n    xtrain, xval = x_train.iloc[train_ind], x_train.iloc[val_ind]\n    ytrain, yval = y_train.iloc[train_ind], y_train.iloc[val_ind]\n    \n    early_stopping_round = lightgbm.early_stopping(25, first_metric_only=True, verbose=True)\n    \n    lgbm = LGBMClassifier(**para)\n        \n    model =  lgbm.fit(xtrain, ytrain, eval_set=[(xtrain,ytrain), (xval,yval)], categorical_feature=None,\n                      eval_metric = ['binary_logloss', 'binary_error'], verbose=100, callbacks=[early_stopping_round])\n    pred_train = model.predict_proba(xtrain, num_iteration=model.best_iteration_)[:,1]\n    pred_val = model.predict_proba(xval, num_iteration=model.best_iteration_)[:,1]\n    lg_train_preds[val_ind] = pred_val\n    lg_test_preds += (model.predict_proba(x_test, num_iteration=model.best_iteration_)[:,1])\/folds\n    lg_test += (model.predict_proba(test2, num_iteration=model.best_iteration_)[:,1])\/folds\n    score1 = accuracy_score(ytrain, np.where(pred_train<=0.5, 0, 1))\n    score2 = accuracy_score(yval, np.where(pred_val<=0.5, 0, 1))\n    print('Fold {} ACCURACY Train: {} Validation: {}'.format(fold+1, score1, score2))\n\n    results = model.evals_result_\n    df=pd.DataFrame({\n                    \"train_ll\":results[\"training\"][\"binary_logloss\"],\n                    \"validation_ll\":results[\"valid_1\"][\"binary_logloss\"],\n                    \"train_acc\":results[\"training\"][\"binary_error\"],\n                    \"test_acc\":results[\"valid_1\"][\"binary_error\"],\n\n    })\n    df['train_acc']=(1-df['train_acc'])*100.0\n    df['test_acc']=(1-df['test_acc'])*100.0\n#         print(df.head())\n\n    fig, ax = plt.subplots(ncols=2, figsize=(12,6))\n    sns.lineplot(data=df, x=df.index, y=\"train_ll\", ax=ax[0], label=\"Train loss\")\n    sns.lineplot(data=df, x=df.index, y=\"validation_ll\", ax=ax[0], label=\"Validation loss\")\n    sns.lineplot(data=df, x=df.index, y=\"train_acc\", ax=ax[1], label=\"Train acc.\")\n    sns.lineplot(data=df, x=df.index, y=\"test_acc\", ax=ax[1], label=\"Validation acc.\")\n    ax[0].set_title(\"Loss curve\")\n    ax[1].set_title(\"Accuracy curve\")\n    ax[0].set_ylabel(\"Loss\")\n    ax[0].set_xlabel(\"Itertation\")\n    ax[1].set_ylabel(\"Accuracy\")\n    ax[1].set_xlabel(\"Itertation\")\n    fig.suptitle(\"LightGBM Loss\/Accuracy.\")\n    plt.show()\n    \nacc1 = accuracy_score(y_train, np.where(lg_train_preds<=0.5, 0, 1))\nacc2 = accuracy_score(y_test, np.where(lg_test_preds<=0.5, 0, 1))\n\nprint('OOF ACCURACY Train: {} Test: {}'.format(acc1, acc2))\n\n# score_train=pd.read_csv('..\/input\/score-apr21\/score_train.csv')\n# score_test=pd.read_csv('..\/input\/score-apr21\/score_test.csv')\n\n# score_train['lg']=np.concatenate([lg_train_preds,lg_test_preds])\n# score_test['lg']=lg_test","b29d7239":"test_=pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/test.csv')\ndf=pd.DataFrame()\ndf['PassengerId']=test_['PassengerId'].values\ndf['Survived']=lg_test\ndf['Survived']=df['Survived'].apply(lambda x:0 if x<=0.5 else 1)\ndf.to_csv('.\/lg_tuned_set2.csv',index=False)","e95408cc":"train1=pd.read_csv('..\/input\/training-apr\/train.csv')\ntest1=pd.read_csv('..\/input\/training-apr\/test.csv')\n\ntrain2=train1.copy()\ntest2=test1.copy()\n\ntrain1.drop(columns=['PassengerId','Name','Cabin','Ticket','SibSp','Parch','Age_log','Fare','Fare_cat','SibSp_log','Parch_log','related','related_cat'], inplace=True)\ntest1.drop(columns=['PassengerId','Name','Cabin','Ticket','SibSp','Parch','Age_log','Fare','Fare_cat','SibSp_log','Parch_log','related','related_cat'], inplace=True)\n\ntrain2.drop(columns=['PassengerId','Name','Cabin','Ticket','SibSp','Parch','Age_log','Fare','Fare_cat','SibSp_log','Parch_log','related','related_log'], inplace=True)\ntest2.drop(columns=['PassengerId','Name','Cabin','Ticket','SibSp','Parch','Age_log','Fare','Fare_cat','SibSp_log','Parch_log','related','related_log'], inplace=True)\n\nprint(\"set 1:\", train1.columns, test1.columns)\nprint(\"set 2:\", train2.columns, test2.columns)","0e8a55e4":"ohe=OneHotEncoder()\ncol=['Sex','Embarked']\nohe.fit(train1[col])\nprint(ohe.get_feature_names(col))\ndf1=pd.DataFrame(columns=ohe.get_feature_names(col),data=ohe.transform(train1[col]).toarray())\ndf2=pd.DataFrame(columns=ohe.get_feature_names(col),data=ohe.transform(test1[col]).toarray())\n\ntrain1=train1.join(df1)\ntest1=test1.join(df2)\n\ntrain1.drop(columns=['Sex','Embarked'], inplace=True)\ntest1.drop(columns=['Sex','Embarked'], inplace=True)","c2b3616f":"train1.head()","68fd3163":"test1.head()","70a57fb1":"folds=5\nSEED=random.randint(937,8641)\n\nkf=StratifiedKFold(n_splits=folds, random_state=SEED, shuffle=True)\n\nfeatures=train1.columns[1:]\nX = train1[features]\ny = train1['Survived']\n\n\nimbalanced_ratio=(train1[train1['Survived']==0]['Survived'].count()\/train1[train1['Survived']==1]['Survived'].count()).round(2)\nprint(\"Imbalnce ratio: {:}\".format(imbalanced_ratio))\n# x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=SEED)\n\n# print(\"Distribution of train and test:\", len(x_train), len(y_train), len(x_test), len(x_test))","cbefaf7b":"Trial=0\ndef objective(trial, x=x_train, y=y_train):\n    global Trial\n    \n    para={\n        'bootstrap': True,\n        'n_jobs': -1,\n        'verbose': 0,\n        'random_state': SEED,\n        'criterion': 'entropy',\n        'n_estimators': trial.suggest_int('n_estimators',10, 1000),\n        'max_depth': trial.suggest_int('max_depth', 3, 2000),\n        'min_samples_split': trial.suggest_float('min_samples_split', 1e-4, 1e-1),\n        'min_samples_leaf': trial.suggest_float('min_samples_leaf', 1e-4, 1e-1),\n        'max_features': trial.suggest_categorical(\"max_features\", ['sqrt', 'log2']),\n        'max_leaf_nodes': trial.suggest_int('max_leaf_nodes', 500, 100000),\n        'warm_start': trial.suggest_categorical('warm_start', [True, False]),\n        'min_impurity_decrease': trial.suggest_float('min_impurity_decrease', 0.0, 0.2),\n        'class_weight':trial.suggest_categorical(\"class_weight\", ['balanced', 'balanced_subsample']),\n        'max_samples': trial.suggest_float('max_samples', 0.5, 0.8)\n    }\n    \n    print(\"--------------------> Trial {} <--------------------\".format(Trial))\n    Trial=Trial + 1\n    rf_train_preds = np.zeros(len(y),)\n    for fold, (train_ind, val_ind) in enumerate(kf.split(x, y)):\n        print(\"--> Fold {}\".format(fold + 1))\n        xtrain, xval = x.iloc[train_ind], x.iloc[val_ind]\n        ytrain, yval = y.iloc[train_ind], y.iloc[val_ind]\n        \n        rf = RandomForestClassifier(**para)\n\n        model =  rf.fit(xtrain, ytrain)\n        \n        pred_train = model.predict(xtrain)\n        pred_val = model.predict(xval)\n        rf_train_preds[val_ind]=pred_val\n        score1 = accuracy_score(ytrain, pred_train)\n        score2 = accuracy_score(yval, pred_val)\n        print('Fold {} AUC Train: {} Validation: {}'.format(fold+1, score1, score2))\n    \n    acc=accuracy_score(y, rf_train_preds)\n    print('OOF ACCURACY: {}'.format(acc))\n    return acc","c908c8d5":"study=optuna.create_study(study_name=\"Random Forest set 1 Optimization\", direction='maximize')\nstudy.optimize(objective, n_trials=25)\n\ntrial = study.best_trial\nprint('Accuracy: {}'.format(trial.value))\n\nprint(\"Best hyperparameters: {}\".format(trial.params))","f14be7bd":"Trial=0\ndef objective(trial, x=x_train, y=y_train):\n    global Trial\n    \n    para={\n        'bootstrap': True,\n        'n_jobs': -1,\n        'verbose': 0,\n        'random_state': SEED,\n        'criterion': 'entropy',\n        'n_estimators': 330, \n        'max_depth': 1417, \n        'min_samples_split': 0.010377003772355852, \n        'min_samples_leaf': 0.01865186498148891, \n        'max_features': 'log2', \n        'max_leaf_nodes': 87127, \n        'warm_start': False, \n        'min_impurity_decrease': 0.01122129357981094, \n        'class_weight': 'balanced_subsample', \n        'max_samples': 0.5985586520207642,\n        'ccp_alpha': trial.suggest_float('ccp_alpha', 0.0, 2e-1)\n    }\n    \n    print(\"--------------------> Trial {} <--------------------\".format(Trial))\n    Trial=Trial + 1\n    rf_train_preds = np.zeros(len(y),)\n    for fold, (train_ind, val_ind) in enumerate(kf.split(x, y)):\n        print(\"--> Fold {}\".format(fold + 1))\n        xtrain, xval = x.iloc[train_ind], x.iloc[val_ind]\n        ytrain, yval = y.iloc[train_ind], y.iloc[val_ind]\n        \n        rf = RandomForestClassifier(**para)\n\n        model =  rf.fit(xtrain, ytrain)\n        \n        pred_train = model.predict(xtrain)\n        pred_val = model.predict(xval)\n        rf_train_preds[val_ind]=pred_val\n        score1 = accuracy_score(ytrain, pred_train)\n        score2 = accuracy_score(yval, pred_val)\n        print('Fold {} AUC Train: {} Validation: {}'.format(fold+1, score1, score2))\n    \n    acc=accuracy_score(y, rf_train_preds)\n    print('OOF ACCURACY: {}'.format(acc))\n    return acc","861f63cf":"study=optuna.create_study(study_name=\"Random Forest set 1 Pruning\", direction='maximize')\nstudy.optimize(objective, n_trials=25)\n\ntrial = study.best_trial\nprint('Accuracy: {}'.format(trial.value))\n\nprint(\"Best hyperparameters: {}\".format(trial.params))","6221319b":"para={\n      'n_estimators': 898,\n      'criterion': 'entropy',\n      'max_depth': 8, \n      'max_leaf_nodes': 9058,\n      'min_samples_split': 0.0671810090247945, \n      'min_samples_leaf': 0.04742472303688006, \n      'max_features': 'sqrt', \n      'min_impurity_decrease': 0.00010583321874846287,\n      'bootstrap': True,\n      'n_jobs': -1,\n      'verbose': 0, \n      'class_weight': 'balanced_subsample', \n      'max_samples': 0.8634669615516827,\n      'random_state': SEED\n}","64fad243":"rf_train_preds = np.zeros(len(y),)\nrf_test = np.zeros(len(test1),)\nfor fold, (train_ind, val_ind) in enumerate(kf.split(X, y)):\n    print(\"--> Fold {}\".format(fold + 1))\n    \n    xtrain, xval = X.iloc[train_ind], X.iloc[val_ind]\n    ytrain, yval = y.iloc[train_ind], y.iloc[val_ind]\n    \n    rf = RandomForestClassifier(**para)\n\n    model =  rf.fit(xtrain, ytrain)\n    \n    pred_train = model.predict_proba(xtrain)[:,1]\n    pred_val = model.predict_proba(xval)[:,1]\n    rf_train_preds[val_ind] = pred_val\n    rf_test += (model.predict_proba(test1)[:,1])\/folds\n    score1 = accuracy_score(ytrain, np.where(pred_train<=0.5, 0, 1))\n    score2 = accuracy_score(yval, np.where(pred_val<=0.5, 0, 1))\n    print('Fold {} ACCURACY Train: {} Validation: {}'.format(fold+1, score1, score2))\n    \nacc1 = accuracy_score(y, np.where(rf_train_preds<=0.5, 0, 1))\n# acc2 = accuracy_score(y_test, np.where(rf_test_preds<=0.5, 0, 1))\n\nprint('OOF ACCURACY Train: {}'.format(acc1))\n\n# score_train=pd.read_csv('..\/input\/score-tab-apr21\/score_train.csv')\n# score_test=pd.read_csv('..\/input\/score-tab-apr21\/score_test.csv')\n\nscore_train['rf']=rf_train_preds\nscore_test['rf']=rf_test","d731f01c":"score_train.head()","d4dcd24c":"score_test.head()","0b0a910a":"score_train.to_csv('.\/score_train.csv',index=False)\nscore_test.to_csv('.\/score_test.csv',index=False)","cffde2d2":"test_=pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/test.csv')\ndf=pd.DataFrame()\ndf['PassengerId']=test_['PassengerId'].values\ndf['Survived']=rf_test\ndf['Survived']=df['Survived'].apply(lambda x:0 if x<=0.5 else 1)\ndf.to_csv('.\/rf_tuned.csv',index=False)","0b10b7d8":"ohe=OneHotEncoder()\ncol=['Sex','Embarked']\nohe.fit(train2[col])\nprint(ohe.get_feature_names(col))\ndf1=pd.DataFrame(columns=ohe.get_feature_names(col),data=ohe.transform(train2[col]).toarray())\ndf2=pd.DataFrame(columns=ohe.get_feature_names(col),data=ohe.transform(test2[col]).toarray())\n\ntrain2=train2.join(df1)\ntest2=test2.join(df2)\n\ntrain2['related_cat'] = train2['related_cat'].apply(lambda x:1 if x in ['low'] else 2)\ntest2['related_cat'] = test2['related_cat'].apply(lambda x:1 if x in ['low'] else 2)\n\ntrain2.drop(columns=['Sex','Embarked'], inplace=True)\ntest2.drop(columns=['Sex','Embarked'], inplace=True)","7f4faa41":"train2.head()","514b6137":"test2.head()","697205ed":"folds=5\nSEED=random.randint(937,8641)\n\nkf=StratifiedKFold(n_splits=folds, random_state=SEED, shuffle=True)\n\nfeatures=train2.columns[1:]\nX = train2[features]\ny = train2['Survived']\n\n\nimbalanced_ratio=(train2[train2['Survived']==0]['Survived'].count()\/train2[train2['Survived']==1]['Survived'].count()).round(2)\nprint(\"Imbalnce ratio: {:}\".format(imbalanced_ratio))\n\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=SEED)\nprint(\"Distribution of train and test:\", len(x_train), len(y_train), len(x_test), len(x_test))","0c8ad3c4":"Trial=0\ndef objective(trial, x=x_train, y=y_train):\n    global Trial\n    \n    para={\n        'bootstrap': True,\n        'n_jobs': -1,\n        'verbose': 0,\n        'random_state': SEED,\n        'criterion': 'entropy',\n        'n_estimators': trial.suggest_int('n_estimators',10, 1000),\n        'max_depth': trial.suggest_int('max_depth', 3, 2000),\n        'min_samples_split': trial.suggest_float('min_samples_split', 1e-4, 1e-1),\n        'min_samples_leaf': trial.suggest_float('min_samples_leaf', 1e-4, 1e-1),\n        'max_features': trial.suggest_categorical(\"max_features\", ['sqrt', 'log2']),\n        'max_leaf_nodes': trial.suggest_int('max_leaf_nodes', 500, 100000),\n        'warm_start': trial.suggest_categorical('warm_start', [True, False]),\n        'min_impurity_decrease': trial.suggest_float('min_impurity_decrease', 0.0, 0.2),\n        'class_weight':trial.suggest_categorical(\"class_weight\", ['balanced', 'balanced_subsample']),\n        'max_samples': trial.suggest_float('max_samples', 0.5, 0.8)\n    }\n    \n    print(\"--------------------> Trial {} <--------------------\".format(Trial))\n    Trial=Trial + 1\n    rf_train_preds = np.zeros(len(y),)\n    for fold, (train_ind, val_ind) in enumerate(kf.split(x, y)):\n        print(\"--> Fold {}\".format(fold + 1))\n        xtrain, xval = x.iloc[train_ind], x.iloc[val_ind]\n        ytrain, yval = y.iloc[train_ind], y.iloc[val_ind]\n        \n        rf = RandomForestClassifier(**para)\n\n        model =  rf.fit(xtrain, ytrain)\n        \n        pred_train = model.predict(xtrain)\n        pred_val = model.predict(xval)\n        rf_train_preds[val_ind]=pred_val\n        score1 = accuracy_score(ytrain, pred_train)\n        score2 = accuracy_score(yval, pred_val)\n        print('Fold {} AUC Train: {} Validation: {}'.format(fold+1, score1, score2))\n    \n    acc=accuracy_score(y, rf_train_preds)\n    print('OOF ACCURACY: {}'.format(acc))\n    return acc","f1ef8567":"study=optuna.create_study(study_name=\"Random Forest set 2 Optimization\", direction='maximize')\nstudy.optimize(objective, n_trials=25)\n\ntrial = study.best_trial\nprint('Accuracy: {}'.format(trial.value))\n\nprint(\"Best hyperparameters: {}\".format(trial.params))","88474706":"para = {\n        'bootstrap': True,\n        'n_jobs': -1,\n        'verbose': 0,\n        'random_state': SEED,\n        'criterion': 'entropy',\n        'n_estimators': 137, \n        'max_depth': 1852, \n        'min_samples_split': 0.0852885149102395, \n        'min_samples_leaf': 0.04145631437008027, \n        'max_features': 'sqrt', \n        'max_leaf_nodes': 85221, \n        'warm_start': False, \n        'min_impurity_decrease': 0.004519625185607378, \n        'class_weight': 'balanced', \n        'max_samples': 0.63249673484119\n       }","86995231":"rf_train_preds = np.zeros(len(y_train),)\nrf_test_preds = np.zeros(len(y_test),)\nrf_test = np.zeros(len(test2),)\nfor fold, (train_ind, val_ind) in enumerate(kf.split(x_train, y_train)):\n    print(\"--> Fold {}\".format(fold + 1))\n    \n    xtrain, xval = x_train.iloc[train_ind], x_train.iloc[val_ind]\n    ytrain, yval = y_train.iloc[train_ind], y_train.iloc[val_ind]\n    \n    rf = RandomForestClassifier(**para)\n\n    model =  rf.fit(xtrain, ytrain)\n    \n    pred_train = model.predict_proba(xtrain)[:,1]\n    pred_val = model.predict_proba(xval)[:,1]\n    rf_train_preds[val_ind] = pred_val\n    rf_test_preds += (model.predict_proba(x_test)[:,1])\/folds\n    rf_test += (model.predict_proba(test2)[:,1])\/folds\n    score1 = accuracy_score(ytrain, np.where(pred_train<=0.5, 0, 1))\n    score2 = accuracy_score(yval, np.where(pred_val<=0.5, 0, 1))\n    print('Fold {} ACCURACY Train: {} Validation: {}'.format(fold+1, score1, score2))\n    \nacc1 = accuracy_score(y_train, np.where(rf_train_preds<=0.5, 0, 1))\nacc2 = accuracy_score(y_test, np.where(rf_test_preds<=0.5, 0, 1))\n\nprint('OOF ACCURACY Train: {} Test: {}'.format(acc1, acc2))\n\n# score_train=pd.read_csv('..\/input\/score-tab-apr21\/score_train.csv')\n# score_test=pd.read_csv('..\/input\/score-tab-apr21\/score_test.csv')\n\n# score_train['rf']=np.concatenate([rf_train_preds,rf_test_preds])\n# score_test['rf']=rf_test","ebcd7fec":"test_=pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/test.csv')\ndf=pd.DataFrame()\ndf['PassengerId']=test_['PassengerId'].values\ndf['Survived']=rf_test\ndf['Survived']=df['Survived'].apply(lambda x:0 if x<=0.5 else 1)\ndf.to_csv('.\/rf_tuned_set2.csv',index=False)","98b97436":"train1=pd.read_csv('..\/input\/training-apr\/train.csv')\ntest1=pd.read_csv('..\/input\/training-apr\/test.csv')\n\ntrain2=train1.copy()\ntest2=test1.copy()\n\ntrain1.drop(columns=['PassengerId','Name','Cabin','Ticket','SibSp','Parch','Age_log','Fare','Fare_cat','SibSp_log','Parch_log','related','related_cat'], inplace=True)\ntest1.drop(columns=['PassengerId','Name','Cabin','Ticket','SibSp','Parch','Age_log','Fare','Fare_cat','SibSp_log','Parch_log','related','related_cat'], inplace=True)\n\ntrain2.drop(columns=['PassengerId','Name','Cabin','Ticket','SibSp','Parch','Age_log','Fare','Fare_cat','SibSp_log','Parch_log','related','related_log'], inplace=True)\ntest2.drop(columns=['PassengerId','Name','Cabin','Ticket','SibSp','Parch','Age_log','Fare','Fare_cat','SibSp_log','Parch_log','related','related_log'], inplace=True)\n\nprint(\"set 1:\", train1.columns, test1.columns)\nprint(\"set 2:\", train2.columns, test2.columns)","9593bb92":"ohe=OneHotEncoder()\ncol=['Sex','Embarked']\nohe.fit(train1[col])\nprint(ohe.get_feature_names(col))\ndf1=pd.DataFrame(columns=ohe.get_feature_names(col),data=ohe.transform(train1[col]).toarray())\ndf2=pd.DataFrame(columns=ohe.get_feature_names(col),data=ohe.transform(test1[col]).toarray())\n\ntrain1=train1.join(df1)\ntest1=test1.join(df2)\n\ntrain1.drop(columns=['Sex','Embarked'], inplace=True)\ntest1.drop(columns=['Sex','Embarked'], inplace=True)","70a4ea7a":"train1.head()","16d7ff37":"test1.head()","872cc443":"folds=5\nSEED=random.randint(937,8641)\n\nkf=StratifiedKFold(n_splits=folds, random_state=SEED, shuffle=True)\n\nfeatures=train1.columns[1:]\nX = train1[features]\ny = train1['Survived']\n\n\nimbalanced_ratio=(train1[train1['Survived']==0]['Survived'].count()\/train1[train1['Survived']==1]['Survived'].count()).round(2)\nprint(\"Imbalnce ratio: {:}\".format(imbalanced_ratio))\n# x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=SEED)\n\n# print(\"Distribution of train and test:\", len(x_train), len(y_train), len(x_test), len(x_test))","446e476c":"Trial=0\n\ndef objective(trial, x=x_train, y=y_train):\n    global Trial\n    \n    para = {\n            'random_seed': SEED,\n            'loss_function': 'Logloss',\n            'class_weights':[1,1.34],\n            'task_type': 'GPU', \n            'custom_metric': ['Logloss','Accuracy'],\n            'use_best_model': True,\n            'od_pval': 1e-4,\n            'verbose': True,\n            'max_bin': 128,\n            'bootstrap_type': trial.suggest_categorical('bootstrap_type',['Bernoulli','Poisson']),\n            'max_depth': trial.suggest_int('max_depth', 1, 16),\n            'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1),\n            'n_estimators': trial.suggest_int('n_estimators',500, 20000),\n            'grow_policy': trial.suggest_categorical('grow_policy', ['SymmetricTree','Depthwise','Lossguide']),\n            'random_strength': trial.suggest_int('random_strength', 1, 10),\n            'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 10000),\n            'score_function': trial.suggest_categorical('score_function', ['Cosine','L2','NewtonCosine','NewtonL2']),\n            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-3, 10.0),\n            'subsample': trial.suggest_float('subsample', 0.5, 0.85)\n            }\n    \n    print(\"--------------------> Trial {} <--------------------\".format(Trial))\n    Trial=Trial + 1\n    cb_train_preds = np.zeros(len(y),)\n    \n    for fold, (train_ind, val_ind) in enumerate(kf.split(x, y)):\n        print(\"--> Fold {}\".format(fold + 1))\n        xtrain, xval = x.iloc[train_ind], x.iloc[val_ind]\n        ytrain, yval = y.iloc[train_ind], y.iloc[val_ind]\n        \n        cb = CatBoostClassifier(**para)\n        \n        model =  cb.fit(xtrain, ytrain, eval_set=[(xval,yval)], cat_features=None, verbose=100, early_stopping_rounds=50)\n        \n        pred_train = model.predict(xtrain)\n        pred_val = model.predict(xval)\n        cb_train_preds[val_ind]=pred_val\n        score1 = accuracy_score(ytrain, pred_train)\n        score2 = accuracy_score(yval, pred_val)\n        print('Fold {} ACCURACY Train: {} Validation: {}'.format(fold+1, score1, score2))\n        \n        results = model.evals_result_\n#         print(results)\n        df=pd.DataFrame({\n                        \"train_ll\":results['learn'][\"Logloss:use_weights=true\"],\n                        \"validation_ll\":results[\"validation\"][\"Logloss:use_weights=true\"],\n                        \"train_acc\":results['learn']['Accuracy:use_weights=true'],\n                        \"test_acc\":results[\"validation\"]['Accuracy:use_weights=true'],\n        })\n#         print(df.head())\n        \n        fig, ax = plt.subplots(ncols=2, figsize=(12,6))\n        sns.lineplot(data=df, x=df.index, y=\"train_ll\", ax=ax[0], label=\"Train loss\")\n        sns.lineplot(data=df, x=df.index, y=\"validation_ll\", ax=ax[0], label=\"Validation loss\")\n        sns.lineplot(data=df, x=df.index, y=\"train_acc\", ax=ax[1], label=\"Train acc.\")\n        sns.lineplot(data=df, x=df.index, y=\"test_acc\", ax=ax[1], label=\"Validation acc.\")\n        ax[0].set_title(\"Loss curve\")\n        ax[1].set_title(\"Accuracy curve\")\n        ax[0].set_ylabel(\"Loss\")\n        ax[0].set_xlabel(\"Itertation\")\n        ax[1].set_ylabel(\"Accuracy\")\n        ax[1].set_xlabel(\"Itertation\")\n        fig.suptitle(\"CatBoost Loss\/Accuracy.\")\n        plt.show()\n    acc=accuracy_score(y, cb_train_preds)\n    print('OOF ACCURACY: {}'.format(acc))\n    return acc","b9193f91":"study=optuna.create_study(study_name=\"CatBoost set 1 Optimization\", direction='maximize')\nstudy.optimize(objective, n_trials=30)\n\ntrial = study.best_trial\nprint('Accuracy: {}'.format(trial.value))\n\nprint(\"Best hyperparameters: {}\".format(trial.params))","6138871a":"para = {  \n        'random_seed': SEED,\n        'loss_function': 'Logloss',\n        'class_weights':[1,1.34],\n        'task_type': 'GPU', \n        'custom_metric': ['Logloss','Accuracy'],\n        'use_best_model': True,\n        'od_type': \"Iter\",\n        'od_wait': 20,\n        'verbose': True,\n        'max_bin': 128,  \n        'bootstrap_type': 'Poisson', \n        'max_depth': 1, \n        'learning_rate': 0.0921929936216536, \n        'n_estimators': 879, \n        'grow_policy': 'Depthwise', \n        'mvs_reg': 45.53846095760124, \n        'random_strength': 10, \n        'min_data_in_leaf': 6644, \n        'score_function': 'NewtonL2', \n        'l2_leaf_reg': 9.586306645407689, \n        'subsample': 0.5043977454997433\n      }","406ebb08":"cb_train_preds = np.zeros(len(y),)\ncb_test = np.zeros(len(test1),)\nfor fold, (train_ind, val_ind) in enumerate(kf.split(X, y)):\n    print(\"--> Fold {}\".format(fold + 1))\n    \n    xtrain, xval = X.iloc[train_ind], X.iloc[val_ind]\n    ytrain, yval = y.iloc[train_ind], y.iloc[val_ind]\n    \n    cb = CatBoostClassifier(**para)\n        \n    model =  cb.fit(xtrain, ytrain, eval_set=[(xval,yval)], cat_features=None, verbose=100, early_stopping_rounds=50)\n    \n    pred_train = model.predict_proba(xtrain)[:,1]\n    pred_val = model.predict_proba(xval)[:,1]\n    cb_train_preds[val_ind] = pred_val\n    cb_test += (model.predict_proba(test1)[:,1])\/folds\n    score1 = accuracy_score(ytrain, np.where(pred_train<=0.5, 0, 1))\n    score2 = accuracy_score(yval, np.where(pred_val<=0.5, 0, 1))\n    print('Fold {} ACCURACY Train: {} Validation: {}'.format(fold+1, score1, score2))\n\n    results = model.evals_result_\n#     print(results)\n    df=pd.DataFrame({\n                    \"train_ll\":results['learn'][\"Logloss:use_weights=true\"],\n                    \"validation_ll\":results[\"validation\"][\"Logloss:use_weights=true\"],\n                    \"train_acc\":results['learn']['Accuracy:use_weights=true'],\n                    \"test_acc\":results[\"validation\"]['Accuracy:use_weights=true'],\n    })\n#         print(df.head())\n\n    fig, ax = plt.subplots(ncols=2, figsize=(12,6))\n    sns.lineplot(data=df, x=df.index, y=\"train_ll\", ax=ax[0], label=\"Train loss\")\n    sns.lineplot(data=df, x=df.index, y=\"validation_ll\", ax=ax[0], label=\"Validation loss\")\n    sns.lineplot(data=df, x=df.index, y=\"train_acc\", ax=ax[1], label=\"Train acc.\")\n    sns.lineplot(data=df, x=df.index, y=\"test_acc\", ax=ax[1], label=\"Validation acc.\")\n    ax[0].set_title(\"Loss curve\")\n    ax[1].set_title(\"Accuracy curve\")\n    ax[0].set_ylabel(\"Loss\")\n    ax[0].set_xlabel(\"Itertation\")\n    ax[1].set_ylabel(\"Accuracy\")\n    ax[1].set_xlabel(\"Itertation\")\n    fig.suptitle(\"CatBoost Loss\/Accuracy.\")\n    plt.show()\n    \nacc1 = accuracy_score(y, np.where(cb_train_preds<=0.5, 0, 1))\n# acc2 = accuracy_score(y_test, np.where(cb_test_preds<=0.5, 0, 1))\n\nprint('OOF ACCURACY Train: {} '.format(acc1))\n\nscore_train=pd.read_csv('..\/input\/score-tab-apr21\/score_train.csv')\nscore_test=pd.read_csv('..\/input\/score-tab-apr21\/score_test.csv')\n\nscore_train['cb'] = cb_train_preds\nscore_test['cb'] = cb_test","ab809d85":"score_train.head()","174213b0":"score_test.head()","b81bb1c7":"score_train.to_csv('.\/score_train.csv',index=False)\nscore_test.to_csv('.\/score_test.csv',index=False)","7649098d":"test_=pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/test.csv')\ndf=pd.DataFrame()\ndf['PassengerId']=test_['PassengerId'].values\ndf['Survived']=cb_test\ndf['Survived']=df['Survived'].apply(lambda x:0 if x<=0.5 else 1)\ndf.to_csv('.\/cb_tuned.csv',index=False)","01d998ec":"ohe=OneHotEncoder()\ncol=['Sex','Embarked']\nohe.fit(train2[col])\nprint(ohe.get_feature_names(col))\ndf1=pd.DataFrame(columns=ohe.get_feature_names(col),data=ohe.transform(train2[col]).toarray())\ndf2=pd.DataFrame(columns=ohe.get_feature_names(col),data=ohe.transform(test2[col]).toarray())\n\ntrain2=train2.join(df1)\ntest2=test2.join(df2)\n\ntrain2['related_cat'] = train2['related_cat'].apply(lambda x:1 if x in ['low'] else 2)\ntest2['related_cat'] = test2['related_cat'].apply(lambda x:1 if x in ['low'] else 2)\n\ntrain2.drop(columns=['Sex','Embarked'], inplace=True)\ntest2.drop(columns=['Sex','Embarked'], inplace=True)","05e574e2":"train2.head()","508732af":"test2.head()","2f5515d5":"folds=5\nSEED=random.randint(937,8641)\n\nkf=StratifiedKFold(n_splits=folds, random_state=SEED, shuffle=True)\n\nfeatures=train2.columns[1:]\nX = train2[features]\ny = train2['Survived']\n\n\nimbalanced_ratio=(train2[train2['Survived']==0]['Survived'].count()\/train2[train2['Survived']==1]['Survived'].count()).round(2)\nprint(\"Imbalnce ratio: {:}\".format(imbalanced_ratio))\n\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=SEED)\nprint(\"Distribution of train and test:\", len(x_train), len(y_train), len(x_test), len(x_test))","5bc4324a":"Trial=0\n\ndef objective(trial, x=x_train, y=y_train):\n    global Trial\n    \n    para = {\n            'random_seed': SEED,\n            'loss_function': 'Logloss',\n            'class_weights':[1,1.34],\n            'task_type': 'GPU', \n            'custom_metric': ['Logloss','Accuracy'],\n            'use_best_model': True,\n            'verbose': True,\n            'max_bin': 128,\n            'bootstrap_type': trial.suggest_categorical('bootstrap_type',['Bernoulli','Poisson']),\n            'max_depth': trial.suggest_int('max_depth', 1, 16),\n            'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1),\n            'n_estimators': trial.suggest_int('n_estimators',500, 20000),\n            'grow_policy': trial.suggest_categorical('grow_policy', ['SymmetricTree','Depthwise','Lossguide']),\n            'random_strength': trial.suggest_int('random_strength', 1, 10),\n            'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 10000),\n            'score_function': trial.suggest_categorical('score_function', ['Cosine','L2','NewtonCosine','NewtonL2']),\n            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-3, 10.0),\n            'subsample': trial.suggest_float('subsample', 0.5, 0.85)\n            }\n    \n    print(\"--------------------> Trial {} <--------------------\".format(Trial))\n    Trial=Trial + 1\n    cb_train_preds = np.zeros(len(y),)\n    \n    for fold, (train_ind, val_ind) in enumerate(kf.split(x, y)):\n        print(\"--> Fold {}\".format(fold + 1))\n        xtrain, xval = x.iloc[train_ind], x.iloc[val_ind]\n        ytrain, yval = y.iloc[train_ind], y.iloc[val_ind]\n        \n        cb = CatBoostClassifier(**para)\n        \n        model =  cb.fit(xtrain, ytrain, eval_set=[(xval,yval)], cat_features=None, verbose=100, early_stopping_rounds=50)\n        \n        pred_train = model.predict(xtrain)\n        pred_val = model.predict(xval)\n        cb_train_preds[val_ind]=pred_val\n        score1 = accuracy_score(ytrain, pred_train)\n        score2 = accuracy_score(yval, pred_val)\n        print('Fold {} ACCURACY Train: {} Validation: {}'.format(fold+1, score1, score2))\n        \n        results = model.evals_result_\n#         print(results)\n        df=pd.DataFrame({\n                        \"train_ll\":results['learn'][\"Logloss:use_weights=true\"],\n                        \"validation_ll\":results[\"validation\"][\"Logloss:use_weights=true\"],\n                        \"train_acc\":results['learn']['Accuracy:use_weights=true'],\n                        \"test_acc\":results[\"validation\"]['Accuracy:use_weights=true'],\n        })\n#         print(df.head())\n        \n        fig, ax = plt.subplots(ncols=2, figsize=(12,6))\n        sns.lineplot(data=df, x=df.index, y=\"train_ll\", ax=ax[0], label=\"Train loss\")\n        sns.lineplot(data=df, x=df.index, y=\"validation_ll\", ax=ax[0], label=\"Validation loss\")\n        sns.lineplot(data=df, x=df.index, y=\"train_acc\", ax=ax[1], label=\"Train acc.\")\n        sns.lineplot(data=df, x=df.index, y=\"test_acc\", ax=ax[1], label=\"Validation acc.\")\n        ax[0].set_title(\"Loss curve\")\n        ax[1].set_title(\"Accuracy curve\")\n        ax[0].set_ylabel(\"Loss\")\n        ax[0].set_xlabel(\"Itertation\")\n        ax[1].set_ylabel(\"Accuracy\")\n        ax[1].set_xlabel(\"Itertation\")\n        fig.suptitle(\"CatBoost Loss\/Accuracy.\")\n        plt.show()\n    acc=accuracy_score(y, cb_train_preds)\n    print('OOF ACCURACY: {}'.format(acc))\n    return acc","9a250133":"study=optuna.create_study(study_name=\"CatBoost set 2 Optimization\", direction='maximize')\nstudy.optimize(objective, n_trials=25)\n\ntrial = study.best_trial\nprint('Accuracy: {}'.format(trial.value))\n\nprint(\"Best hyperparameters: {}\".format(trial.params))","aed201ab":"score_train=pd.read_csv('..\/input\/score-tab-apr21\/score_train.csv')\nscore_test=pd.read_csv('..\/input\/score-tab-apr21\/score_test.csv')","4d6081ae":"score_train.head()","920f73c8":"score_test.head()","81db189e":"test_ = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/test.csv')\ndf = pd.DataFrame()\ndf['PassengerId'] = test_['PassengerId'].values\ndf['Survived'] = 0.2*score_test['xg']+0.2*score_test['rf']+0.4*score_test['lg']+0.2*score_test['cb']\ndf['Survived'] = df['Survived'].apply(lambda x:0 if x<=0.5 else 1)\ndf.to_csv('.\/ensembled_model.csv',index=False)","ca4ef83e":"train=pd.read_csv('..\/input\/score-tab-apr21\/score_train.csv')\ntest=pd.read_csv('..\/input\/score-tab-apr21\/score_test.csv')\ntrain1=pd.read_csv('..\/input\/training-apr\/train.csv')","c2baf1f8":"train.head()","204991f0":"test.head()","bfbcad3c":"folds=5\nSEED=random.randint(937,8641)\n\nkf=StratifiedKFold(n_splits=folds, random_state=SEED, shuffle=True)\n\nfeatures=train.columns\nX = train[features]\ny = train1['Survived']\n\n# x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=SEED)\n\n# print(\"Distribution of train and test:\", len(x_train), len(y_train), len(x_test), len(x_test))","8b4cbad4":"X.head()","42ff8696":"y.head()","925d79cb":"lvl2_train_preds = np.zeros(len(y),)\nlvl2_test = np.zeros(len(test),)\nfor fold, (train_ind, val_ind) in enumerate(kf.split(X, y)):\n    print(\"--> Fold {}\".format(fold + 1))\n    \n    xtrain, xval = X.iloc[train_ind], X.iloc[val_ind]\n    ytrain, yval = y.iloc[train_ind], y.iloc[val_ind]\n    \n    rc = CalibratedClassifierCV(\n                                RidgeClassifier(random_state=SEED, \n                                                class_weight=\"balanced\"),\n                                cv=3\n                                )\n        \n    model =  rc.fit(xtrain, ytrain)\n    \n    pred_train = model.predict_proba(xtrain)[:,1]\n    pred_val = model.predict_proba(xval)[:,1]\n    lvl2_train_preds[val_ind] = pred_val\n    lvl2_test += (model.predict_proba(test)[:,1])\/folds\n    score1 = accuracy_score(ytrain, np.where(pred_train<=0.5, 0, 1))\n    score2 = accuracy_score(yval, np.where(pred_val<=0.5, 0, 1))\n    print('Fold {} ACCURACY Train: {} Validation: {}'.format(fold+1, score1, score2))\n\nacc1 = accuracy_score(y, np.where(lvl2_train_preds<=0.5, 0, 1))\n# acc2 = accuracy_score(y_test, np.where(lvl2_test_preds<=0.5, 0, 1))\n\nprint('OOF ACCURACY Train: {}'.format(acc1))","882f20d8":"test_ = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/test.csv')\ndf = pd.DataFrame()\ndf['PassengerId'] = test_['PassengerId'].values\ndf['Survived'] = lvl2_test\ndf['Survived'] = df['Survived'].apply(lambda x:0 if x<=0.5 else 1)\ndf.to_csv('.\/level2_model.csv',index=False)","283efa9e":"<h2 style=\"background-color:azure; text-align:center; font-size:200%\">LightGBM set2 tuned model<\/h2>","15007f29":"<h2 style=\"background-color:azure; text-align:center; font-size:200%\">XGBOOST set2<\/h2>","010b2555":"<h2 style=\"background-color:azure; text-align:center; font-size:200%\">Random Forest<\/h2>","a5e27e49":"<h2 style=\"background-color:azure; text-align:center; font-size:200%\">XGBOOST set1<\/h2>","03f49d44":"<h2 style=\"background-color:azure; text-align:center; font-size:300%\">Level1 Classification<\/h2>","d5e1d531":"<h2 style=\"background-color:azure; text-align:center; font-size:200%\">LightGBM set2<\/h2>","c4ea2e3e":"<h2 style=\"background-color:azure; text-align:center; font-size:200%\">LightGBM<\/h2>","3ca5dfe6":"<h2 style=\"background-color:azure; text-align:center; font-size:200%\">Ensemble model<\/h2>","16cdf823":"<span style=\"background-color:orange; font-size:150%\">**Observation**<\/span>\n* For LightGBM train set 1 gave better results in public leaderboard compared to train set 2.","7d8dacd7":"<h2 style=\"background-color:azure; text-align:center; font-size:200%\">XGBOOST tuned model set1<\/h2>","dba15eba":"<h2 style=\"background-color:azure; text-align:center; font-size:200%\">CatBoost<\/h2>","c72ea53a":"<h2 style=\"background-color:azure; text-align:center; font-size:200%\">CatBoost set1<\/h2>","20f1e672":"<h2 style=\"background-color:azure; text-align:center; font-size:200%\">XGBOOST set2 tuned model<\/h2>","f81e1bd5":"<h2 style=\"background-color:azure; text-align:center; font-size:200%\">CatBoost set2<\/h2>","68b882e7":"<h2 style=\"background-color:azure; text-align:center; font-size:200%\">XGBOOST<\/h2>","af5324d6":"<h2 style=\"background-color:azure; text-align:center; font-size:200%\">Random Forest set1<\/h2>","49e4ca52":"<h2 style=\"background-color:azure; text-align:center; font-size:200%\">LightGBM set1 tuned model<\/h2>","b9d2c56b":"<h2 style=\"background-color:azure; text-align:center; font-size:200%\">CatBoost tuned set1 model<\/h2>","5273da95":"<h2 style=\"background-color:azure; text-align:center; font-size:200%\">Random Forest set1 tuned model<\/h2>","088a2077":"<h2 style=\"background-color:azure; text-align:center; font-size:200%\">LightGBM set1<\/h2>","051bf49a":"<h2 style=\"background-color:azure; text-align:center; font-size:200%\">Random Forest set2 tuned model<\/h2>","0e204c7c":"<h2 style=\"background-color:azure; text-align:center; font-size:200%\">Random Forest set2<\/h2>","c3464333":"<span style=\"background-color:orange; font-size:150%\">**Observation**<\/span>\n* For XGBOOST train set 1 gave better results in public leaderboard compared to train set 2.  ","ef9d60b9":"<span style=\"background-color:orange; font-size:150%\">**Important Point**<\/span>\n* The cat features of lightgbm should only be used when you have high cardinality in categorical features. \n* It is common to represent categorical features with one-hot encoding, but this approach is suboptimal for tree learners. Particularly for high-cardinality categorical features, a tree built on one-hot features tends to be unbalanced and needs to grow very deep to achieve good accuracy.Instead of one-hot encoding, the optimal solution is to split on a categorical feature by partitioning its categories into 2 subsets. If the feature has k categories, there are 2^(k-1) - 1 possible partitions. But there is an efficient solution for regression trees. It needs about O(k * log(k)) to find the optimal partition.","d2c2eac8":"<h2 style=\"background-color:azure; text-align:center; font-size:300%\">Level2 Classification<\/h2>"}}