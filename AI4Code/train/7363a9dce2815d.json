{"cell_type":{"ebe2eb31":"code","83393e60":"code","c7907fc3":"code","1593e217":"code","993573d4":"code","0ce4c19b":"code","111937db":"code","b530fbb5":"code","5fe3abf3":"code","7c810458":"code","b85042ff":"code","9d278fd1":"code","2f988669":"code","c15aaa38":"code","17259e17":"code","158bde88":"code","a61d05d8":"code","57f73d24":"code","ab587c55":"code","eaacbaf6":"code","ab98371e":"code","d50b4e60":"code","286dafc7":"code","91fde516":"code","2f3c2a47":"code","80befa86":"code","f90fc975":"code","bb6fea62":"markdown","481d6a49":"markdown","6362a2bd":"markdown","617c4d5c":"markdown","3f957328":"markdown","0397909a":"markdown","17cc6d23":"markdown","50558a87":"markdown","42d144cc":"markdown","98f6d255":"markdown","e75f31c1":"markdown","5f35b87e":"markdown","787b3dbc":"markdown"},"source":{"ebe2eb31":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\n# To create temporary directory, type in following in the Console\n# os.chdir(\"\/kaggle\/\")\n# !mkdir temp\n# os.listdir()\n\n# Any results we write to the current directory are saved as output in '\/kaggle\/working\/' directory\nprint()\nprint(os.listdir('..'))\nprint(os.listdir('\/kaggle\/input'))\nprint(os.listdir('\/kaggle\/working\/'))\n# print(os.listdir('\/kaggle\/temp\/'))\n","83393e60":"# Importing needed libraries\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport h5py\nimport cv2\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\nfrom keras.utils import plot_model\nfrom keras.callbacks import LearningRateScheduler, ModelCheckpoint\n\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n\nfrom timeit import default_timer as timer\n\n# Check point\nprint('Libraries are imported successfully')\n","c7907fc3":"# Building model for RGB datasets\n# RGB --> {128C5-P2-D30} --> {256C5-P2-D30} --> {512C5-P2-D30} --> {1024C3-P2-D30} --> 2048-D30 --> 43\n\n# Initializing model to be as linear stack of layers\nmodel = Sequential()\n\n# Adding first convolutional-pooling pair\nmodel.add(Conv2D(128, kernel_size=5, padding='same', activation='relu', input_shape=(48, 48, 3),\n                 kernel_initializer='random_normal',\n                 bias_initializer='zeros'))\nmodel.add(MaxPool2D())\nmodel.add(Dropout(0.3))\n\n# Adding second convolutional-pooling pair\nmodel.add(Conv2D(256, kernel_size=5, padding='same', activation='relu',\n                 kernel_initializer='random_normal',\n                 bias_initializer='zeros'))\nmodel.add(MaxPool2D())\nmodel.add(Dropout(0.3))\n\n# Adding third convolutional-pooling pair\nmodel.add(Conv2D(512, kernel_size=5, padding='same', activation='relu',\n                 kernel_initializer='random_normal',\n                 bias_initializer='zeros'))\nmodel.add(MaxPool2D())\nmodel.add(Dropout(0.3))\n\n# Adding fourth convolutional-pooling pair\nmodel.add(Conv2D(1024, kernel_size=3, padding='same', activation='relu',\n                 kernel_initializer='random_normal',\n                 bias_initializer='zeros'))\nmodel.add(MaxPool2D())\nmodel.add(Dropout(0.3))\n\n# Adding fully connected layers\nmodel.add(Flatten())\nmodel.add(Dense(2048, activation='relu',\n                kernel_initializer='random_normal',\n                bias_initializer='zeros'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(43, activation='softmax'))\n\n# Compiling created model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Saving model for RGB datasets\nmodel.save('model_ts_rgb_light.h5')\n\n\n\n\n# Building model for GRAY datasets\n# GRAY --> {128C5-P2-D30} --> {256C5-P2-D30} --> {512C5-P2-D30} --> {1024C3-P2-D30} --> 2048-D30 --> 43\n\n# Initializing model to be as linear stack of layers\nmodel = Sequential()\n\n# Adding first convolutional-pooling pair\nmodel.add(Conv2D(128, kernel_size=5, padding='same', activation='relu', input_shape=(48, 48, 1),\n                 kernel_initializer='random_normal',\n                 bias_initializer='zeros'))\nmodel.add(MaxPool2D())\nmodel.add(Dropout(0.3))\n\n# Adding second convolutional-pooling pair\nmodel.add(Conv2D(256, kernel_size=5, padding='same', activation='relu',\n                 kernel_initializer='random_normal',\n                 bias_initializer='zeros'))\nmodel.add(MaxPool2D())\nmodel.add(Dropout(0.3))\n\n# Adding third convolutional-pooling pair\nmodel.add(Conv2D(512, kernel_size=5, padding='same', activation='relu',\n                 kernel_initializer='random_normal',\n                 bias_initializer='zeros'))\nmodel.add(MaxPool2D())\nmodel.add(Dropout(0.3))\n\n# Adding fourth convolutional-pooling pair\nmodel.add(Conv2D(1024, kernel_size=3, padding='same', activation='relu',\n                 kernel_initializer='random_normal',\n                 bias_initializer='zeros'))\nmodel.add(MaxPool2D())\nmodel.add(Dropout(0.3))\n\n# Adding fully connected layers\nmodel.add(Flatten())\nmodel.add(Dense(2048, activation='relu',\n                kernel_initializer='random_normal',\n                bias_initializer='zeros'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(43, activation='softmax'))\n\n# Compiling created model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Saving 1st model for GRAY datasets\nmodel.save('model_ts_gray_light.h5')\n\n\n# Check point\nprint('2 models are saved successfully')\n","1593e217":"# Loading model\nmodel_rgb = load_model('\/kaggle\/working\/model_ts_rgb_light.h5')\nmodel_gray = load_model('\/kaggle\/working\/model_ts_gray_light.h5')\n\n# Check point\nprint('2 models are loaded successfully')\n","993573d4":"# Showing model's summary in form of table\nmodel_rgb.summary()\nprint()\nmodel_gray.summary()\n","0ce4c19b":"# Showing dropout rate\nprint(model_rgb.layers[2].rate)\nprint(model_gray.layers[2].rate)\n\n# Showing strides for the 1st layer (convolutional)\nprint(model_rgb.layers[0].strides)\nprint(model_gray.layers[0].strides)\n\n# Showing strides for the 2nd layer (max pooling)\nprint(model_rgb.layers[1].strides)\nprint(model_gray.layers[1].strides)\n","111937db":"# Defining lists to collect models in\nmodel_rgb = []\nmodel_gray = []\n\n\n# Loading models and appending them into lists\nfor i in range(2):\n    model_rgb.append(load_model('\/kaggle\/working\/model_ts_rgb_light.h5'))\n    \n    model_gray.append(load_model('\/kaggle\/working\/model_ts_gray_light.h5'))\n\n\n# Check point\nprint('4 separate models are successfully loaded')\n","b530fbb5":"# Showing models' input shapes\nprint(model_rgb[0].layers[0].input_shape)\nprint()\nprint(model_gray[0].layers[0].input_shape)\n","5fe3abf3":"# Defining number of epochs\nepochs = 10\n\n\n# Defining schedule to update learning rate\nlearning_rate = LearningRateScheduler(lambda x: 1e-2 * 0.95 ** (x + 50), verbose=1)\n\n\n# Check point\nprint('Number of epochs and schedule for learning rate are set successfully')\n","7c810458":"# Preparing list with datasets' names\ndatasets = ['dataset_ts_rgb_255_mean_light.hdf5',\n            'dataset_ts_rgb_255_mean_std_light.hdf5',\n            'dataset_ts_gray_255_mean_light.hdf5',\n            'dataset_ts_gray_255_mean_std_light.hdf5']\n\n\n# Defining list to collect results in\nh = []\n\n\n# Training model with all Traffic Signs datasets in a loop\nfor i in range(4):\n    # Opening saved Traffic Signs dataset from HDF5 binary file\n    # Initiating File object\n    # Opening file in reading mode by 'r'\n    with h5py.File('\/kaggle\/input\/preprocessed-light-version-of-traffic-signs\/' + datasets[i], 'r') as f:\n        # Extracting saved arrays for training by appropriate keys\n        # Saving them into new variables\n        x_train = f['x_train']  # HDF5 dataset\n        y_train = f['y_train']  # HDF5 dataset\n        # Converting them into Numpy arrays\n        x_train = np.array(x_train)  # Numpy arrays\n        y_train = np.array(y_train)  # Numpy arrays\n\n        # Extracting saved arrays for validation by appropriate keys\n        # Saving them into new variables\n        x_validation = f['x_validation']  # HDF5 dataset\n        y_validation = f['y_validation']  # HDF5 dataset\n        # Converting them into Numpy arrays\n        x_validation = np.array(x_validation)  # Numpy arrays\n        y_validation = np.array(y_validation)  # Numpy arrays\n    \n    \n    # Check point\n    print('Following dataset is successfully opened:        ', datasets[i])\n    \n    \n    # Preparing classes to be passed into the model\n    # Transforming them from vectors to binary matrices\n    # It is needed to set relationship between classes to be understood by the algorithm\n    # Such format is commonly used in training and predicting\n    y_train = to_categorical(y_train, num_classes = 43)\n    y_validation = to_categorical(y_validation, num_classes = 43)\n    \n    \n    # Check point\n    print('Binary matrices are successfully created:        ', datasets[i])\n \n\n    # Preparing filepath to save best weights\n    best_weights_filepath = 'w' + datasets[i][7:-5] + '.h5'\n       \n    # Defining schedule to save best weights\n    best_weights = ModelCheckpoint(filepath=best_weights_filepath,\n                                   save_weights_only=True,                                   \n                                   monitor='val_accuracy',\n                                   mode='max',\n                                   save_best_only=True,\n                                   period=1,\n                                   verbose=1)\n    \n    \n    # Check point\n    print('Schedule to save best weights is created:        ', datasets[i])\n\n    \n    # Checking if RGB dataset is opened\n    if i <= 1:\n        # Training RGB model with current dataset\n        temp = model_rgb[i].fit(x_train, y_train,\n                                batch_size=50,\n                                epochs=epochs,\n                                validation_data=(x_validation, y_validation),\n                                callbacks=[learning_rate, best_weights],\n                                verbose=1)\n\n        \n        # Adding results of model for current RGB dataset in the list\n        h.append(temp)\n        \n        \n        # Check points\n        print('Model for RGB is successfully trained on:        ', datasets[i])\n        print('Trained weights for RGB are saved successfully:  ', 'w' + datasets[i][7:-5] + '.h5')\n        print()\n    \n    # Checking if GRAY dataset is opened\n    elif i >= 2:\n        # Training GRAY model with current dataset\n        temp = model_gray[i-2].fit(x_train, y_train,\n                                   batch_size=50,\n                                   epochs=epochs,\n                                   validation_data=(x_validation, y_validation),\n                                   callbacks=[learning_rate, best_weights],\n                                   verbose=1)\n\n        \n        # Adding results of 1st model for current GRAY dataset in the list\n        h.append(temp)\n        \n        \n        # Check points\n        print('Model for GRAY is successfully trained on:       ', datasets[i])\n        print('Trained weights for GRAY are saved successfully: ', 'w' + datasets[i][7:-5] + '.h5')\n        print()\n","b85042ff":"# Resulted accuracies of all pre-processed Traffic Signs datasets\nfor i in range(4):\n    print('T: {0:.5f},  V: {1:.5f},  D: {2}'.format(max(h[i].history['accuracy']),\n                                                    max(h[i].history['val_accuracy']),\n                                                    datasets[i][8:-5]))\n    ","9d278fd1":"# Showing other parameters that history holds\nprint(h[0].params)\n","2f988669":"# Magic function that renders the figure in a jupyter notebook\n# instead of displaying a figure object\n%matplotlib inline\n\n\n# Setting default size of the plot\nplt.rcParams['figure.figsize'] = (12.0, 6.0)\nplt.rcParams['font.family'] = 'Times New Roman'\n\n\n# Plotting accuracies of all Traffic Signs datasets for 1st model\nplt.plot(h[0].history['val_accuracy'], '-o')\nplt.plot(h[1].history['val_accuracy'], '-o')\nplt.plot(h[2].history['val_accuracy'], '-o')\nplt.plot(h[3].history['val_accuracy'], '-o')\n\n\n# Showing legend\nplt.legend(['rgb_255_mean', 'rgb_255_mean_std',\n            'gray_255_mean', 'gray_255_mean_std'],\n           loc='lower right',\n           fontsize='xx-large')\n\n\n# Giving name to axes\nplt.xlabel('Epoch', fontsize=16)\nplt.ylabel('Accuracy', fontsize=16)\n\n\n# Setting limit along Y axis\nplt.ylim(0.88, 0.9992)\n\n\n# Giving name to the plot\nplt.title('Validation accuracies', fontsize=16)\n\n\n# Saving plot\nplt.savefig('validation_model_ts_dataset_light.png', dpi=500)\n\n\n# Showing the plot\nplt.show()\n","c15aaa38":"# Magic function that renders the figure in a jupyter notebook\n# instead of displaying a figure object\n%matplotlib inline\n\n\n# Setting default size of the plot\nplt.rcParams['figure.figsize'] = (12.0, 6.0)\nplt.rcParams['font.family'] = 'Times New Roman'\n\n\n# Plotting training and validation losses of all Traffic Signs datasets for 1st model\nplt.plot(h[0].history['loss'], '-ob')\nplt.plot(h[1].history['loss'], '-og')\nplt.plot(h[2].history['loss'], '-or')\nplt.plot(h[3].history['loss'], '-oc')\n\nplt.plot(h[0].history['val_loss'], '-ob')\nplt.plot(h[1].history['val_loss'], '-og')\nplt.plot(h[2].history['val_loss'], '-or')\nplt.plot(h[3].history['val_loss'], '-oc')\n\n\n# Showing legend\nplt.legend(['rgb_255_mean', 'rgb_255_mean_std',\n            'gray_255_mean', 'gray_255_mean_std'],\n           loc='center right',\n           fontsize='large')\n\n\n# Giving name to axes\nplt.xlabel('Epoch', fontsize=16)\nplt.ylabel('Loss', fontsize=16)\n\n\n# Giving name to the plot\nplt.title('Losses', fontsize=16)\n\n\n# Saving plot\nplt.savefig('losses_model_ts_dataset_light.png', dpi=500)\n\n\n# Showing the plot\nplt.show()\n","17259e17":"# Defining lists to collect models in\nmodel_rgb = []\nmodel_gray = []\n\n\n# Loading 1st model for Traffic Signs dataset\nfor i in range(2):\n    model_rgb.append(load_model('\/kaggle\/working\/model_ts_rgb_light.h5'))\n    model_gray.append(load_model('\/kaggle\/working\/model_ts_gray_light.h5'))\n\n\n# Check point\nprint('4 separate models are successfully loaded')\n","158bde88":"# Showing models' input shapes\nprint(model_rgb[0].layers[0].input_shape)\nprint()\nprint(model_gray[0].layers[0].input_shape)\n","a61d05d8":"# Preparing list with weights' names\nweights = ['w_ts_rgb_255_mean_light.h5',\n           'w_ts_rgb_255_mean_std_light.h5',\n           'w_ts_gray_255_mean_light.h5',\n           'w_ts_gray_255_mean_std_light.h5']\n\n\n# Loading best weights for 1st model\nfor i in range(4):    \n    # Checking if it is RGB model\n    if i <= 1:\n        # loading and assigning best weights\n        model_rgb[i].load_weights('\/kaggle\/working\/' + weights[i])\n        \n        \n        # Check point\n        print('Best weights for RGB model are loaded and assigned  : ', weights[i])\n    \n    # Checking if it is GRAY model\n    elif i >= 2:\n        # loading and assigning best weights\n        model_gray[i-2].load_weights('\/kaggle\/working\/' + weights[i])\n        \n        \n        # Check point\n        print('Best weights for GRAY model are loaded and assigned : ', weights[i])\n","57f73d24":"# Preparing list with datasets' names\ndatasets = ['dataset_ts_rgb_255_mean_light.hdf5',\n            'dataset_ts_rgb_255_mean_std_light.hdf5',\n            'dataset_ts_gray_255_mean_light.hdf5',\n            'dataset_ts_gray_255_mean_std_light.hdf5']\n\n\n# Defining variable to identify the best model\naccuracy_best = 0\n\n\n# Testing 1st model with all Traffic Signs datasets in a loop\nfor i in range(4):    \n    # Opening saved Traffic Signs dataset from HDF5 binary file\n    # Initiating File object\n    # Opening file in reading mode by 'r'\n    with h5py.File('\/kaggle\/input\/preprocessed-light-version-of-traffic-signs\/' + datasets[i], 'r') as f:\n        # Extracting saved arrays for testing by appropriate keys\n        # Saving them into new variables\n        x_test = f['x_test']  # HDF5 dataset\n        y_test = f['y_test']  # HDF5 dataset\n        # Converting them into Numpy arrays\n        x_test = np.array(x_test)  # Numpy arrays\n        y_test = np.array(y_test)  # Numpy arrays\n    \n    \n    # Check point\n    print('Dataset is opened :', datasets[i])\n    \n    \n    # Check point\n    # Showing shapes of loaded arrays\n    if i == 0:\n        print('x_test shape      :', x_test.shape)\n        print('y_test shape      :', y_test.shape)\n    \n    \n    # Checking if RGB dataset is opened\n    if i <= 1:\n        # Testing RGB model with current dataset\n        temp = model_rgb[i].predict(x_test)\n        \n        \n        # Check point\n        # Showing prediction shape and scores\n        if i == 0:\n            print('prediction shape  :', temp.shape)  # (3111, 43)\n            print('prediction scores :', temp[0, 0:5])  # 5 score numbers\n      \n    \n        # Getting indexes of maximum values along specified axis\n        temp = np.argmax(temp, axis=1)\n        \n        \n        # Check point\n        # Showing prediction shape after convertion\n        # Showing predicted and correct indexes of classes\n        if i == 0:\n            print('prediction shape  :', temp.shape)  # (3111,)\n            print('predicted indexes :', temp[0:10])\n            print('correct indexes   :', y_test[:10])\n        \n        \n        # Calculating accuracy\n        # We compare predicted class with correct class for all input images\n        # By saying 'temp == y_test' we create Numpy array with True and False values\n        # By function 'np.mean' we calculate mean value:\n        # all_True \/ (all_True + all_False)\n        accuracy = np.mean(temp == y_test)\n        \n        \n        # Check point\n        # Showing True and False matrix\n        if i == 0:\n            print('T and F matrix    :', (temp == y_test)[0:10])\n        \n        \n        # Check point\n        # Showing calculated accuracy\n        print('Testing accuracy  : {0:.5f}'.format(accuracy))\n        print()\n    \n    # Checking if GRAY dataset is opened\n    elif i >= 2:\n        # Testing GRAY model with current dataset\n        temp = model_gray[i-2].predict(x_test)\n        \n        \n        # Getting indexes of maximum values along specified axis\n        temp = np.argmax(temp, axis=1)\n        \n        \n        # Calculating accuracy\n        # We compare predicted class with correct class for all input images\n        # By saying 'temp == y_test' we create Numpy array with True and False values\n        # By function 'np.mean' we calculate mean value:\n        # all_True \/ (all_True + all_False)\n        accuracy = np.mean(temp == y_test)\n        \n        \n        # Check point\n        # Showing calculated accuracy\n        print('Testing accuracy  : {0:.5f}'.format(accuracy))\n        print()\n    \n    \n    # Identifying the best model\n    # Saving predicted indexes of the best model\n    if accuracy > accuracy_best:\n        # Updating value of the best accuracy\n        accuracy_best = accuracy\n        \n        # Saving predicted indexes of the best model into array\n        # Updating array with predicted indexes of the best model\n        y_predicted_best = temp\n    ","ab587c55":"# Showing the main classification metrics of the best model\nprint(classification_report(y_test, y_predicted_best))\n","eaacbaf6":"# Confusion matrix is a two dimensional matrix that visualizes the performance,\n# and makes it easy to see confusion between classes,\n# by providing a picture of interrelation\n\n# Each row represents a number of actual class  \n# Each column represents a number of predicted class  \n\n\n# Computing confusion matrix to evaluate accuracy of classification\nc_m = confusion_matrix(y_test, y_predicted_best)\n\n# Showing confusion matrix in form of Numpy array\nprint(c_m)\n","ab98371e":"# Magic function that renders the figure in a jupyter notebook\n# instead of displaying a figure object\n%matplotlib inline\n\n\n# Setting default size of the plot\n# Setting default fontsize used in the plot\nplt.rcParams['figure.figsize'] = (14.0, 14.0)\nplt.rcParams['font.size'] = 12\n\n\n# Implementing visualization of confusion matrix\ndisplay_c_m = ConfusionMatrixDisplay(c_m)\n\n\n# Plotting confusion matrix\n# Setting colour map to be used\ndisplay_c_m.plot(cmap='PuRd')\n# Other possible options for colour map are:\n# 'OrRd', 'autumn_r', 'Blues', 'cool', 'Greens', 'Greys', 'copper_r'\n\n\n# Setting fontsize for xticks and yticks\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\n\n# Setting fontsize for xlabels and ylabels\nplt.xlabel('Predicted label', fontsize=18)\nplt.ylabel('True label', fontsize=18)\n\n\n# Giving name to the plot\nplt.title('Confusion Matrix: Traffic Signs Dataset', fontsize=18)\n\n\n# Saving plot\nplt.savefig('confusion_matrix_ts_model.png', transparent=True, dpi=500)\n\n\n# Showing the plot\nplt.show()\n","d50b4e60":"# Preparing list with datasets' names\ndatasets = ['dataset_ts_rgb_255_mean_light.hdf5',\n            'dataset_ts_rgb_255_mean_std_light.hdf5',\n            'dataset_ts_gray_255_mean_light.hdf5',\n            'dataset_ts_gray_255_mean_std_light.hdf5']\n\n\n# Opening saved Traffic Signs dataset from HDF5 binary file\n# Initiating File object\n# Opening file in reading mode by 'r'\nwith h5py.File('\/kaggle\/input\/preprocessed-light-version-of-traffic-signs\/' + datasets[0], 'r') as f:\n    # Extracting saved arrays for testing by appropriate keys\n    # Saving them into new variables\n    x_test_rgb_255_mean_light = f['x_test']  # HDF5 dataset\n    # Converting them into Numpy arrays\n    x_test_rgb_255_mean_light = np.array(x_test_rgb_255_mean_light)  # Numpy arrays\n\n\n# Opening saved Traffic Signs dataset from HDF5 binary file\n# Initiating File object\n# Opening file in reading mode by 'r'\nwith h5py.File('\/kaggle\/input\/preprocessed-light-version-of-traffic-signs\/' + datasets[1], 'r') as f:\n    # Extracting saved arrays for testing by appropriate keys\n    # Saving them into new variables\n    x_test_rgb_255_mean_std_light = f['x_test']  # HDF5 dataset\n    # Converting them into Numpy arrays\n    x_test_rgb_255_mean_std_light = np.array(x_test_rgb_255_mean_std_light)  # Numpy arrays\n\n# Opening saved Traffic Signs dataset from HDF5 binary file\n# Initiating File object\n# Opening file in reading mode by 'r'\nwith h5py.File('\/kaggle\/input\/preprocessed-light-version-of-traffic-signs\/' + datasets[2], 'r') as f:\n    # Extracting saved arrays for testing by appropriate keys\n    # Saving them into new variables\n    x_test_gray_255_mean_light = f['x_test']  # HDF5 dataset\n    # Converting them into Numpy arrays\n    x_test_gray_255_mean_light = np.array(x_test_gray_255_mean_light)  # Numpy arrays\n\n\n# Opening saved Traffic Signs dataset from HDF5 binary file\n# Initiating File object\n# Opening file in reading mode by 'r'\nwith h5py.File('\/kaggle\/input\/preprocessed-light-version-of-traffic-signs\/' + datasets[3], 'r') as f:\n    # Extracting saved arrays for testing by appropriate keys\n    # Saving them into new variables\n    x_test_gray_255_mean_std_light = f['x_test']  # HDF5 dataset\n    # Converting them into Numpy arrays\n    x_test_gray_255_mean_std_light = np.array(x_test_gray_255_mean_std_light)  # Numpy arrays\n\n\n# Check points\n# Showing shapes of loaded Numpy arrays\nprint('RGB Mean                :', x_test_rgb_255_mean_light.shape)\nprint('RGB Standard Deviation  :', x_test_rgb_255_mean_std_light.shape)\nprint('GRAY Mean               :', x_test_gray_255_mean_light.shape)\nprint('GRAY Standard Deviation :', x_test_gray_255_mean_std_light.shape)\n","286dafc7":"# Magic function that renders the figure in a jupyter notebook\n# instead of displaying a figure object\n%matplotlib inline\n\n# Setting default size of the plot\nplt.rcParams['figure.figsize'] = (2.5, 2.5)\n\n\n# Check point\n# Showing RGB image\nplt.imshow(x_test_rgb_255_mean_light[0])\nplt.show()\n\n\n# Check point\n# Showing GRAY image\nplt.imshow(x_test_gray_255_mean_light[0], cmap=plt.get_cmap('gray'))\nplt.show()\n","91fde516":"# Extending dimension from (height, width, channels) to (1, height, width, channels)\nimage_ts_rgb_255_mean = x_test_rgb_255_mean_light[0][np.newaxis, :, :, :]\nimage_ts_rgb_255_mean_std = x_test_rgb_255_mean_std_light[0][np.newaxis, :, :, :]\n\nimage_ts_gray_255_mean = x_test_gray_255_mean_light[0][np.newaxis, :, :, :]\nimage_ts_gray_255_mean_std = x_test_gray_255_mean_std_light[0][np.newaxis, :, :, :]\n\n# Check points\n# Showing shapes of extended Numpy arrays\nprint('RGB \/255.0 => mean         :', image_ts_rgb_255_mean.shape)\nprint('RGB \/255.0 => mean => std  :', image_ts_rgb_255_mean_std.shape)\nprint()\nprint('GRAY \/255.0 => mean        :', image_ts_gray_255_mean.shape)\nprint('GRAY \/255.0 => mean => std :', image_ts_gray_255_mean_std.shape)","2f3c2a47":"# Defining function to plot bar chart with scores values\ndef bar_chart(scores, bar_title, show_xticks=True, labels=None):\n    # Arranging X axis\n    x_positions = np.arange(scores.size)\n\n    # Creating bar chart\n    barlist = plt.bar(x_positions, scores, align='center', alpha=0.6)\n\n    # Highlighting the highest bar\n    barlist[np.argmax(scores)].set_color('red')\n\n    # Giving labels to bars along X axis\n    if show_xticks:\n        plt.xticks(x_positions, labels, rotation=20, fontsize=15)\n\n    # Giving name to axes\n    plt.xlabel('Class', fontsize=20)\n    plt.ylabel('Value', fontsize=20)\n\n    # Giving name to bar chart\n    plt.title('Classification: ' + bar_title, fontsize=20)\n\n    # Showing bar chart\n    plt.show()\n\n\n# Check point\nprint('Function to plot Bar Chart is successfully defined')\n","80befa86":"# Preparing labels for Traffic Signs dataset\n# Getting Pandas dataFrame with labels\n# (!) On Windows, it might need to change\n# this: + '\/' +\n# to this: + '\\' +\n# or to this: + '\\\\' +\nlabels_ts = pd.read_csv('\/kaggle\/input\/traffic-signs-preprocessed' + '\/' + 'label_names.csv', sep=',')\n\n\n# Check point\n# Showing first 5 elements of the dataFrame\nprint(labels_ts.head())\nprint()\n\n\n# Showing class's name of the 1st element\nprint(labels_ts.loc[0, 'SignName'])\nprint()\n\n\n# Converting into Numpy array\nlabels_ts = np.array(labels_ts.loc[:, 'SignName']).flatten()\n\n\n# Check points\n# Showing size of Numpy array\n# Showing all elements of Numpy array\nprint('Total number of labels:', labels_ts.size)\nprint()\nprint(labels_ts)\n","f90fc975":"# Magic function that renders the figure in a jupyter notebook\n# instead of displaying a figure object\n%matplotlib inline\n\n# Setting default size of the plot\nplt.rcParams['figure.figsize'] = (12, 7)\n\n\n\n# Testing RGB model trained on dataset: dataset_ts_rgb_255_mean.hdf5\n# Input image is preprocessed in the same way\n# Measuring classification time\nstart = timer()\nscores = model_rgb[0].predict(image_ts_rgb_255_mean)\nend = timer()\n\n# Scores are given as 43 numbers of predictions for each class\n# Getting only one class with maximum value\nprediction = np.argmax(scores)\n\n# Check points\n# Showing scores shape and values\n# Printing class index, label and time\nprint()\nprint('Scores shape        :', scores.shape)\nprint('Scores values       :', scores[0, 10:15])\nprint('Scores sum          :', scores[0].sum())\nprint('Score of prediction : {0:.5f}'.format(scores[0][prediction]))\nprint('Class index         :', prediction)\nprint('Label               :', labels_ts[prediction])\nprint('Time                : {0:.5f}'.format(end - start))\n\n# Plotting bar chart with scores values\nbar_chart(scores[0],\n          bar_title='1st RGB model, ts_rgb_255_mean',\n          show_xticks=False)\n\n\n\n# Testing RGB model trained on dataset: dataset_ts_rgb_255_mean_std.hdf5\n# Input image is preprocessed in the same way\n# Measuring classification time\nstart = timer()\nscores = model_rgb[1].predict(image_ts_rgb_255_mean_std)\nend = timer()\n\n# Scores are given as 43 numbers of predictions for each class\n# Getting only one class with maximum value\nprediction = np.argmax(scores)\n\n# Check points\n# Showing scores shape and values\n# Printing class index, label and time\nprint()\nprint('Scores shape        :', scores.shape)\nprint('Scores values       :', scores[0, 10:15])\nprint('Scores sum          :', scores[0].sum())\nprint('Score of prediction : {0:.5f}'.format(scores[0][prediction]))\nprint('Class index         :', prediction)\nprint('Label               :', labels_ts[prediction])\nprint('Time                : {0:.5f}'.format(end - start))\n\n# Plotting bar chart with scores values\nbar_chart(scores[0],\n          bar_title='1st RGB model, ts_rgb_255_mean_std',\n          show_xticks=False)\n\n\n\n# Testing GRAY model trained on dataset: dataset_ts_gray_255_mean.hdf5\n# Input image is preprocessed in the same way\n# Measuring classification time\nstart = timer()\nscores = model_gray[0].predict(image_ts_gray_255_mean)\nend = timer()\n\n# Scores are given as 43 numbers of predictions for each class\n# Getting only one class with maximum value\nprediction = np.argmax(scores)\n\n# Check points\n# Showing scores shape and values\n# Printing class index, label and time\nprint()\nprint('Scores shape        :', scores.shape)\nprint('Scores values       :', scores[0, 10:15])\nprint('Scores sum          :', scores[0].sum())\nprint('Score of prediction : {0:.5f}'.format(scores[0][prediction]))\nprint('Class index         :', prediction)\nprint('Label               :', labels_ts[prediction])\nprint('Time                : {0:.5f}'.format(end - start))\n\n# Plotting bar chart with scores values\nbar_chart(scores[0],\n          bar_title='1st GRAY model, ts_gray_255_mean',\n          show_xticks=False)\n\n\n\n# Testing GRAY model trained on dataset: dataset_ts_gray_255_mean_std.hdf5\n# Input image is preprocessed in the same way\n# Measuring classification time\nstart = timer()\nscores = model_gray[1].predict(image_ts_gray_255_mean_std)\nend = timer()\n\n# Scores are given as 43 numbers of predictions for each class\n# Getting only one class with maximum value\nprediction = np.argmax(scores)\n\n# Check points\n# Showing scores shape and values\n# Printing class index, label and time\nprint()\nprint('Scores shape        :', scores.shape)\nprint('Scores values       :', scores[0, 10:15])\nprint('Scores sum          :', scores[0].sum())\nprint('Score of prediction : {0:.5f}'.format(scores[0][prediction]))\nprint('Class index         :', prediction)\nprint('Label               :', labels_ts[prediction])\nprint('Time                : {0:.5f}'.format(end - start))\n\n# Plotting bar chart with scores values\nbar_chart(scores[0],\n          bar_title='1st GRAY model, ts_gray_255_mean_std',\n          show_xticks=False)\n","bb6fea62":"# \u27bf Training separately defined models","481d6a49":"# \ud83e\uddee Calculating testing accuracies","6362a2bd":"# \u2714\ufe0f Confusion matrix","617c4d5c":"# \u2728 Classification report","3f957328":"# \u27b0 Designing and Saving Deep CNN model","0397909a":"* **Training** deep CNN on **\"light\"** version of TS for classification\n* Dataset with **\"original\"**, **\"light\"** & **\"hard\"** versions: [https:\/\/www.kaggle.com\/valentynsichkar\/traffic-signs-1-million-images-for-classification](https:\/\/www.kaggle.com\/valentynsichkar\/traffic-signs-1-million-images-for-classification)\n* Dataset with preprocessed **\"light\"** version: [https:\/\/www.kaggle.com\/valentynsichkar\/preprocessed-light-version-of-traffic-signs](https:\/\/www.kaggle.com\/valentynsichkar\/preprocessed-light-version-of-traffic-signs)","17cc6d23":"**Design**, **Train** & **Test** deep CNN for Image Classification.\n\n**Join** the course & enjoy new opportunities to get deep learning skills:\n\n\n[https:\/\/www.udemy.com\/course\/convolutional-neural-networks-for-image-classification\/](https:\/\/www.udemy.com\/course\/convolutional-neural-networks-for-image-classification\/?referralCode=12EE0D74A405BF4DDE9B)\n\n\n![](https:\/\/github.com\/sichkar-valentyn\/1-million-images-for-Traffic-Signs-Classification-tasks\/blob\/main\/images\/slideshow_classification.gif?raw=true)","50558a87":"# \ud83d\udcc2 Defining separate 4 models for training","42d144cc":"# \ud83c\udf93 Related course for classification tasks","98f6d255":"# \ud83d\udce5 Importing needed libraries","e75f31c1":"# \u26d4\ufe0f CNN trained on \"light\" version of TS","5f35b87e":"# \ud83d\uddbc\ufe0f Testing on one image","787b3dbc":"# \ud83d\udce5 Loading and Verifying model"}}