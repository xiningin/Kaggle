{"cell_type":{"2e6b186f":"code","e84d0ebc":"code","e3dbd515":"code","e21982be":"code","74eaab63":"code","93c6f2f2":"code","dacfb79f":"code","ac8d5b50":"code","8f199fb2":"code","a195a090":"code","c048069a":"code","f55d3e74":"code","e1bba8ae":"code","eaabc73d":"code","3b677a9a":"code","c073989b":"code","2bcb9d3b":"code","93cc4a16":"code","dd354262":"code","6038cda3":"code","f713f7fa":"code","9801d1bc":"code","8ae15e69":"code","309627ca":"code","10ac8daf":"code","cbf8bd0d":"code","e2c5a126":"code","317a61a0":"code","19f5cd2d":"code","50311d77":"code","751d529b":"code","1d40bbc5":"code","0a7922d6":"code","375f1113":"code","5ac069d7":"code","000afa86":"code","3759c70d":"code","553fe8f3":"code","132b24ae":"code","0a172036":"code","de678522":"code","f50b06dd":"code","3b0dd395":"code","7f9b70b4":"code","c11d81ff":"code","9e00d698":"code","1829f7cc":"code","1179749b":"code","5296b8a6":"code","46e1eb9e":"code","fde414b9":"code","47ff682b":"markdown","9695f001":"markdown","7318e223":"markdown","0530d9d8":"markdown","59fe5dbb":"markdown","05eba458":"markdown","dbbfe614":"markdown","58a9579c":"markdown"},"source":{"2e6b186f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","e84d0ebc":"import glob","e3dbd515":"print(os.listdir(\"..\/input\/shanghaitech_with_people_density_map\/ShanghaiTech\/part_A\/train_data\"))","e21982be":"DATA_PATH = \"..\/input\/shanghaitech_with_people_density_map\/ShanghaiTech\/part_A\/train_data\"\nTEST_PATH = \"..\/input\/shanghaitech_with_people_density_map\/ShanghaiTech\/part_A\/test_data\"\nMODEL_PATH = \"csrnet_shanghaitechA_task1.model\"\nMODEL_JSON_PATH = \"csrnet_shanghaitechA_task1.json\"","74eaab63":"import os\nfrom tqdm import tqdm\nimport glob\nfrom sklearn.model_selection import train_test_split\nimport json\n\"\"\"\ncreate a list of file (full directory)\n\"\"\"\n\n\n\n\ndef create_training_image_list(data_path):\n    \"\"\"\n    create a list of absolutely path of jpg file\n    :param data_path: must contain subfolder \"images\" with *.jpg  (example ShanghaiTech\/part_A\/train_data\/)\n    :return:\n    \"\"\"\n    DATA_PATH = data_path\n    image_path_list = glob.glob(os.path.join(DATA_PATH, \"images\", \"*.jpg\"))\n    return image_path_list\n\n\ndef get_train_val_list(data_path):\n    DATA_PATH = data_path\n    image_path_list = glob.glob(os.path.join(DATA_PATH, \"images\", \"*.jpg\"))\n    train, val = train_test_split(image_path_list, test_size=0.1)\n\n    print(\"train size \", len(train))\n    print(\"val size \", len(val))\n    return train, val\n\ndef get_test_list(data_path):\n    DATA_PATH = data_path\n    image_path_list = glob.glob(os.path.join(DATA_PATH, \"images\", \"*.jpg\"))\n    \n    print(\"test size \", len(image_path_list))\n    return image_path_list\n\ndef create_density_path_list(image_path_list):\n    gt_paths = []\n    for img_path in image_path_list:\n        gt_path = img_path.replace('.jpg','.h5').replace('images','ground-truth-h5')\n        gt_paths.append(gt_path)\n    return gt_paths","93c6f2f2":"# train_img_path, val_img_path = get_train_val_list(DATA_PATH)\n# train_density_path = create_density_path_list(train_img_path)\n# val_density_path = create_density_path_list(val_img_path)","dacfb79f":"# DATA_PATH = \"..\/input\/ucfcrowdcountingdataset_cvpr13_with_people_density_map\/UCF_CC_50\/\"\n# MODEL_PATH = \"single_image_random_crop_experiment_model_1.model\"\n# image_list = glob.glob(DATA_PATH+\"*.jpg\")\n# density_list = list(map(lambda s: s.replace(\".jpg\", \".h5\"), image_list))","ac8d5b50":"from tensorflow.python.keras import backend as K\ndef mae_metric(y_true, y_pred):\n    return K.abs(K.sum(y_true) - K.sum(y_pred))","8f199fb2":"from tensorflow.python.keras import backend as K\ndef euclidean_distance_loss(y_true, y_pred):\n    \"\"\"\n    # Euclidean distance as a measure of loss (Loss function) \n    copy from https:\/\/github.com\/Neerajj9\/CSRNet-keras\/blob\/master\/Model.ipynb\n    \"\"\"\n    return K.sqrt(K.sum(K.sum(K.sum(K.square(y_pred - y_true), axis=3), axis=2), axis=1))\n#     x = K.square(y_pred - y_true)\n#     batch_size, w, h, channel_size = x.shape\n#     x = K.reshape(x, (batch_size, w*h*channel_size))\n#     return K.sqrt(K.sum(x, axis=-1))","a195a090":"# from tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.python.keras.models import load_model, model_from_json\nfrom tensorflow.python.keras.applications.vgg16 import VGG16, preprocess_input\n# from tensorflow.keras.models import Model\n# from tensorflow.keras.layers import Conv2D, UpSampling2D\nfrom tensorflow.python.keras.losses import mean_squared_error\n\n\nfrom tensorflow.python.keras.models import Model\nfrom tensorflow.python.keras.layers import Conv2D, UpSampling2D, BatchNormalization, Activation\n\nfrom tensorflow.python.keras.initializers import RandomNormal \nimport numpy as np\n\nfrom tensorflow.python.keras.optimizers import SGD, Adam\n# from keras import optimizers\n\n\ndef build_model():\n    sgd = SGD(lr=1e-7, decay=5*1e-4, momentum=0.95)\n    adam = Adam()\n    vgg16_model = VGG16(weights='imagenet', include_top=False)\n    # model = Model(inputs=base_model.input, outputs=base_model.get_layer('block4_pool').output)\n    x = vgg16_model.get_layer('block4_conv3').output\n    x = BatchNormalization()(x)\n#     x = UpSampling2D(size=(8, 8))(x)\n    x = Conv2D(filters=512, kernel_size=(3, 3), dilation_rate=2, padding='same', use_bias=False, kernel_initializer=RandomNormal(stddev=0.01))(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Conv2D(filters=512, kernel_size=(3, 3), dilation_rate=2, padding='same', use_bias=False, kernel_initializer=RandomNormal(stddev=0.01))(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Conv2D(filters=512, kernel_size=(3, 3), dilation_rate=2, padding='same', use_bias=False, kernel_initializer=RandomNormal(stddev=0.01))(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Conv2D(filters=256, kernel_size=(3, 3), dilation_rate=2, padding='same', use_bias=False, kernel_initializer=RandomNormal(stddev=0.01))(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Conv2D(filters=128, kernel_size=(3, 3), dilation_rate=2, padding='same', use_bias=False, kernel_initializer=RandomNormal(stddev=0.01))(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Conv2D(filters=64, kernel_size=(3, 3), dilation_rate=2, padding='same', use_bias=False, kernel_initializer=RandomNormal(stddev=0.01))(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Conv2D(filters=1, kernel_size=(1, 1), dilation_rate=1, padding='same', use_bias=True, kernel_initializer=RandomNormal(stddev=0.01))(x)\n#     x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    model = Model(inputs=vgg16_model.input, outputs=x)\n    model.compile(optimizer=adam,\n                  loss=mean_squared_error, metrics=[mae_metric])\n    return model","c048069a":"def save_model(model , weight_path , json_path):\n    \"\"\"\n    save model and json file\n    source = https:\/\/github.com\/Neerajj9\/CSRNet-keras\/blob\/master\/Model.ipynb\n    \"\"\"\n    model.save_weights(weight_path)\n    \n    model_json = model.to_json()\n    \n    with open(json_path, \"w\") as json_file:\n        json_file.write(model_json)","f55d3e74":"def load_json_model(weight_path, json_path):\n    \"\"\"\n    load model and json file\n    source = https:\/\/github.com\/Neerajj9\/CSRNet-keras\/blob\/master\/Model.ipynb\n    \"\"\"\n    # Function to load and return neural network model \n    json_file = open(json_path, 'r')\n    loaded_model_json = json_file.read()\n    json_file.close()\n    loaded_model = model_from_json(loaded_model_json)\n    loaded_model.load_weights(weight_path)\n    return loaded_model","e1bba8ae":"model = build_model()\n# model.save(MODEL_PATH)","eaabc73d":"x = np.random.rand(1, 224, 224, 3)\npred = model.predict(x)\nprint(pred.shape)","3b677a9a":"import cv2","c073989b":"# # TODO: write keras.utils.Sequence() to load image\n# from tensorflow.python.keras.utils import Sequence\n\n# import numpy as np\n# import h5py\n# import PIL.Image as Image\n\n\n# def load_density(file_path):\n#     gt_file = h5py.File(file_path, 'r')\n#     groundtruth = np.asarray(gt_file['density'])\n#     return groundtruth\n\n\n# def random_crop(img, density_map, random_crop_size):\n#     \"\"\"\n#     adapt from https:\/\/jkjung-avt.github.io\/keras-image-cropping\/\n#     :param img: image matrix (h, w, channel)\n#     :param density_map: (h, w, channel)\n#     :param random_crop_size: h_crop, w_crop\n#     :return:\n#     \"\"\"\n#     # Note: image_data_format is 'channel_last'\n#     assert img.shape[2] == 3\n#     height, width = img.shape[0], img.shape[1]\n#     dy, dx = random_crop_size\n#     x = np.random.randint(0, width - dx + 1)\n#     y = np.random.randint(0, height - dy + 1)\n\n#     return img[y:(y+dy), x:(x+dx), :], density_map[y:(y+dy), x:(x+dx), :]\n\n\n# TODO: write keras.utils.Sequence() to load image\nfrom tensorflow.python.keras.utils import Sequence\n\nimport numpy as np\nimport h5py\nimport PIL.Image as Image\n\n\ndef load_density(file_path):\n    gt_file = h5py.File(file_path, 'r')\n    groundtruth = np.asarray(gt_file['density'])\n    return groundtruth\n\ndef downsample_density_map(density):\n    density2 = density.squeeze(3).squeeze(0)\n    density3 = cv2.resize(density2,(int(density2.shape[1]\/8), int(density2.shape[0]\/8)),interpolation = cv2.INTER_CUBIC)*64\n    density4 = np.expand_dims(density3, axis=0)\n    density5 = np.expand_dims(density4, axis=3)\n    return density5\n    \n\ndef random_crop(img, density_map, random_crop_size):\n    \"\"\"\n    adapt from https:\/\/jkjung-avt.github.io\/keras-image-cropping\/\n    :param img: image matrix (h, w, channel)\n    :param density_map: (h, w, channel)\n    :param random_crop_size: h_crop, w_crop\n    :return:\n    \"\"\"\n    # Note: image_data_format is 'channel_last'\n    assert img.shape[2] == 3\n    height, width = img.shape[0], img.shape[1]\n    dy, dx = random_crop_size\n    x = np.random.randint(0, width - dx + 1)\n    y = np.random.randint(0, height - dy + 1)\n    # print(\"x shape \", x.shape)\n    # print(\"img shape \", img.shape)\n    # print(\"density shape \", density_map.shape)\n    return img[y:(y+dy), x:(x+dx), :], density_map[y:(y+dy), x:(x+dx), :]\n\n\nclass DatasetSequence(Sequence):\n\n    def __init__(self, image_path_list, density_path_list, random_crop_size=None, same_size_density=True):\n        self.image_path_list = image_path_list\n        self.density_path_list = density_path_list\n        self.random_crop_size = random_crop_size\n        self.batch_size = 1\n        self.same_size_density = same_size_density\n        \n    def __len__(self):\n        return len(self.image_path_list)\n\n    def __getitem__(self, idx):\n        try:\n            image_path = self.image_path_list[idx]\n            density_path = self.density_path_list[idx]\n\n            density = load_density(density_path)\n            image = np.array(Image.open(image_path, \"r\").convert(\"RGB\"))\n            density = np.expand_dims(density, axis=3)  # add channel dim\n\n            if self.random_crop_size is not None:\n                # print(\"crop \", self.random_crop_size)\n                image, density = random_crop(image, density, self.random_crop_size)        \n    \n            # preprocess vgg16 input\n            im = image\n            im = im\/255.0\n            im[:,:,0]=(im[:,:,0]-0.485)\/0.229\n            im[:,:,1]=(im[:,:,1]-0.456)\/0.224\n            im[:,:,2]=(im[:,:,2]-0.406)\/0.225\n            image = im\n\n            # density = np.expand_dims(density, axis=3)  # add channel dim\n            image = np.expand_dims(image, axis=0) # add batch dim\n            density = np.expand_dims(density, axis=0) # add batch dim\n            \n            if not self.same_size_density:\n                density = downsample_density_map(density)\n\n            return image, density\n        except:\n            pass\n        \n    def get_non_preprocess(self, idx):\n        try:\n            image_path = self.image_path_list[idx]\n            density_path = self.density_path_list[idx]\n\n            density = load_density(density_path)\n            image = np.array(Image.open(image_path, \"r\").convert(\"RGB\"))\n            density = np.expand_dims(density, axis=3)  # add channel dim\n                \n            # density = np.expand_dims(density, axis=3)  # add channel dim\n            image = np.expand_dims(image, axis=0) # add batch dim\n            density = np.expand_dims(density, axis=0) # add batch dim\n\n            return image, density\n        except:\n            pass\n\n    def get_random_crop_image(self, idx):\n#         try:\n        image_path = self.image_path_list[idx]\n        density_path = self.density_path_list[idx]\n\n        density = load_density(density_path)\n        image = np.array(Image.open(image_path, \"r\").convert(\"RGB\"))\n        density = np.expand_dims(density, axis=3)  # add channel dim\n\n        if self.random_crop_size is not None:\n            # print(\"crop \", self.random_crop_size)\n            image, density = random_crop(image, density, self.random_crop_size)\n            \n        # preprocess vgg16 input\n        im = image\n        im = im\/255.0\n        im[:,:,0]=(im[:,:,0]-0.485)\/0.229\n        im[:,:,1]=(im[:,:,1]-0.456)\/0.224\n        im[:,:,2]=(im[:,:,2]-0.406)\/0.225\n        image = im\n\n        image = np.expand_dims(image, axis=0)  # add batch dim\n        density = np.expand_dims(density, axis=0)  # add batch dim\n#         except:\n#             print(\"get_random_crop_image \", idx)\n#             print(\"img path = \", image_path)\n#             print(\"img shape \", image.shape)\n#             print(\"density shape \", density.shape)\n        return image, density\n\n    def get_random_crop_image_batch(self, idx, batch_size):\n        image_batch = []\n        density_batch = []\n        \n        for i in range(batch_size):\n            image, density = self.get_random_crop_image(idx)\n            image_batch.append(image)\n            density_batch.append(density)\n\n        images = np.concatenate(image_batch, axis=0)\n        densities = np.concatenate(density_batch, axis=0)\n        return images, densities\n    \n    def get_all(self, crop_per_img):\n        image_list = []\n        density_list = []\n        for i in tqdm(range(len(self.image_path_list))):\n            try:\n                image, density = self.get_random_crop_image_batch(i, crop_per_img)\n                image_list.append(image)\n                density_list.append(density)\n            except:\n                print(\"exception at image \", i)\n        image_mat = np.concatenate(image_list, axis = 0)\n        density_mat = np.concatenate(density_list, axis = 0)\n        return image_mat, density_mat\n\n","2bcb9d3b":"train_img_path, val_img_path = get_train_val_list(DATA_PATH)\ntrain_density_path = create_density_path_list(train_img_path)\nval_density_path = create_density_path_list(val_img_path)","93cc4a16":"train_dataset = DatasetSequence(train_img_path, train_density_path, random_crop_size=(224, 224), same_size_density=False)","dd354262":"img, density = train_dataset[0]","6038cda3":"density.shape","f713f7fa":"density2 = density.squeeze(3).squeeze(0)\ndensity3 = cv2.resize(density2,(int(density2.shape[1]\/8), int(density2.shape[0]\/8)),interpolation = cv2.INTER_CUBIC)*64\ndensity4 = np.expand_dims(density3, axis=0)\ndensity5 = np.expand_dims(density4, axis=3)\nprint(density3.shape)\nprint(density2.shape)\nprint(density5.shape)","9801d1bc":"# density2 = cv2.resize(density,(1, int(density.shape[1]\/8), int(density.shape[2]\/8), 1),interpolation = cv2.INTER_CUBIC)*64\n","8ae15e69":"# # generate dataset\n# img_mat, density_mat = train_dataset.get_all(9)\n# # img_mat = preprocess_input(img_mat)\n# print(img_mat.shape)\n# print(density_mat.shape)","309627ca":"# a = img_mat[1:3]\n# b = density_mat[1:3]\n# print(b.shape)\n# print(a.shape)","10ac8daf":"# bb = model.predict(a)\n# print(bb.shape)","cbf8bd0d":"# eu_loss = euclidean_distance_loss(b, bb)\n# print(eu_loss.shape)\n# mse_loss = mean_squared_error(b, bb)\n# print(mse_loss)","e2c5a126":"# density_mat.dtype","317a61a0":"# train_dataset_nocrop = DatasetSequence(train_img_path, train_density_path)\n# image, density = train_dataset_nocrop[0]\n# print(image.shape)\n# print(density.shape)","19f5cd2d":"# def image_generator():\n#     train_dataset_nocrop = DatasetSequence(train_img_path, train_density_path)\n#     for image, density in train_dataset_nocrop:\n#         yield image, density","50311d77":"# print(img_mat.shape)\n# print(density_mat.shape)","751d529b":"from tensorflow.python.keras.preprocessing.image import ImageDataGenerator","1d40bbc5":"# # we create two instances with the same arguments\n# data_gen_args = dict(rotation_range=90,\n#                      width_shift_range=0.1,\n#                      height_shift_range=0.1,\n#                      zoom_range=0.2)\n# image_datagen = ImageDataGenerator(**data_gen_args)\n# mask_datagen = ImageDataGenerator(**data_gen_args)\n\n# # Provide the same seed and keyword arguments to the fit and flow methods\n# seed = 1\n# image_datagen.fit(img_mat, augment=True, seed=seed)\n# mask_datagen.fit(density_mat, augment=True, seed=seed)\n\n# image_datagen.flow()\n\n# # image_generator = image_datagen.flow_from_directory(\n# #     'data\/images',\n# #     class_mode=None,\n# #     seed=seed)\n\n# # mask_generator = mask_datagen.flow_from_directory(\n# #     'data\/masks',\n# #     class_mode=None,\n# #     seed=seed)\n\n# # combine generators into one which yields image and masks\n# train_generator = zip(image_generator, mask_generator)","0a7922d6":"# dataset = DatasetSequence(image_list, density_list, random_crop_size=(224, 224))\nmodel = build_model()\n\n# for image, density in dataset:\n#     model.fit(image, density)\nepoch = 400\n# n_sample = len(dataset)\nprint(\"total epoch \", epoch)\n# print(\"sample \", n_sample)\n# img_train, density_train = dataset.get_all(10)\nmodel.fit_generator(train_dataset, shuffle=True, epochs = epoch)\nsave_model(model, MODEL_PATH, MODEL_JSON_PATH)\nimport sys\nsys.stdout.flush()","375f1113":"# for img, density in train_dataset:\n#     print(img.shape)\n#     print(density.shape)\n#     print(\"-----------------\")","5ac069d7":"loaded_model = load_json_model(MODEL_PATH, MODEL_JSON_PATH)","000afa86":"print(\"meow\")","3759c70d":"\nimport glob\nimport PIL.Image as Image\nfrom matplotlib import pyplot as plt\nfrom matplotlib import cm as CM\nimport os\nimport numpy as np\n\n\ndef save_density_map(density_map, name):\n    plt.figure(dpi=600)\n    plt.axis('off')\n    plt.margins(0, 0)\n    plt.imshow(density_map, cmap=CM.jet)\n    plt.savefig(name, dpi=600, bbox_inches='tight', pad_inches=0)\n","553fe8f3":"# train_dataset\nimg_train, density_train = train_dataset.get_non_preprocess(0)\npil_img = Image.fromarray(img_train[0])\n\nmodel = load_json_model(MODEL_PATH, MODEL_JSON_PATH)\n\nprint(\"label \", density_train.sum())\n\n# img_train = preprocess_input(img_train)\npred = model.predict(img_train)\n# pred = loaded_model.predict(img_train)\n\nprint(\"predict \", np.squeeze(pred[0], axis=2).shape, np.squeeze(pred[0], axis=2).sum())\n\nprint(\"------------\")","132b24ae":"pil_img.save(\"train.png\")\nfrom matplotlib import pyplot as plt\n\n\nplt.figure(dpi=600)\nplt.axis('off')\nplt.margins(0,0)\nplt.imshow(Image.open(\"train.png\"))","0a172036":"save_density_map(np.squeeze(density_train[0], axis=2), \"label.png\")","de678522":"np.squeeze(pred[0], axis=2)","f50b06dd":"save_density_map(np.squeeze(pred[0], axis=2), \"predict.png\")","3b0dd395":"pred[0].shape","7f9b70b4":"np.savetxt(\"pred_np.txt\",np.squeeze(density_train[0], axis=2))","c11d81ff":"val_dataset = DatasetSequence(val_img_path, val_density_path, same_size_density=False)","9e00d698":"n = 0\nmae = 0\nmse = 0\nfor i in tqdm(range(len(val_dataset))):\n    img, density = val_dataset[i]\n    # img = preprocess_input(img)\n    pred = model.predict(img)\n    pred_values = pred.sum()\n    truth = density.sum()\n    mae = mae + abs(truth - pred_values)\n    n += 1\n    mse = mse + (truth - pred_values) * (truth - pred_values)\n\nval_result_mae = mae \/ n\nval_result_mse = np.sqrt(mse\/n)\nprint('val mae ', val_result_mae)\nprint('val mse ', val_result_mse)","1829f7cc":"test_img_path = get_test_list(TEST_PATH)\ntest_density_path = create_density_path_list(test_img_path)","1179749b":"test_dataset = DatasetSequence(test_img_path, test_density_path, same_size_density=False)\n# model = load_model(MODEL_PATH)","5296b8a6":"n = 0\nmae = 0\nmse = 0\nfor i in tqdm(range(len(test_dataset))):\n    img, density = test_dataset[i]\n    # img = preprocess_input(img)\n    pred = model.predict(img)\n    pred_values = pred.sum()\n    truth = density.sum()\n    mae = mae + abs(truth - pred_values)\n    n += 1\n    mse += (truth - pred_values) * (truth - pred_values)\nmae = mae \/ n\nmse = np.sqrt(mse \/ n)\nprint(mae)\nprint(mse)","46e1eb9e":"# mae = mae \/ n\n# mse = np.sqrt(mse \/ n)","fde414b9":"\n# print(mae)\n# print(mse)","47ff682b":"## data loader","9695f001":"# Training","7318e223":"# Evaluate","0530d9d8":"# Let's import thing first","59fe5dbb":"# TEST DATA","05eba458":"### Changelog v5\n- use batch normalization, no bias at conv <br>\n- use preprocess_input\n(from tensorflow.python.keras.applications.vgg16 import VGG16, preprocess_input )\n- output layer no batch norm\n- use default mse again \n- change loss function\n- improve data prerpocess\n- from keras.initializers import RandomNormal \n### Changelog v8\n- use adam\n\n### Changelog v9\n- reduce output density map by 1\/8 ","dbbfe614":"## Single Image data generator","58a9579c":"# Validate data"}}