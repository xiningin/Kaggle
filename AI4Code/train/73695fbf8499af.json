{"cell_type":{"f3809aa8":"code","df1bf210":"code","04b5f436":"code","a234bb8b":"code","6b89f9e5":"code","7b0e8a13":"code","17eba183":"code","8a1e6cf6":"code","894c202c":"code","56fd673b":"code","6d602903":"code","29129716":"code","044a0820":"code","6b901ea9":"code","4730d469":"code","016b649d":"code","ecac7e8d":"code","a36aaced":"code","b9769277":"code","47d87faf":"code","a6cc41d9":"code","aa81ea57":"code","a8a7d476":"code","1b25e60f":"code","97c0278e":"code","fb41bc18":"code","545223cf":"code","7b0e7ce0":"code","58e28fde":"code","9fe70e53":"code","0e5461e5":"code","1468871a":"code","646e8447":"code","fd6ee2e7":"code","2e259ac4":"code","4076dec6":"code","afc1c1bd":"markdown"},"source":{"f3809aa8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","df1bf210":"import torch\nfrom torch.utils.data import DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,f1_score\nimport torch.nn as nn\nimport matplotlib.pyplot as plt \nimport seaborn as sns","04b5f436":"df= pd.read_csv('\/kaggle\/input\/weather-dataset-rattle-package\/weatherAUS.csv')\ndf.head()","a234bb8b":"time_series_data= df[['Date','Humidity3pm']]\nregression_data= df.iloc[:,1:]","6b89f9e5":"time_series_data","7b0e8a13":"regression_data","17eba183":"regression_data.isna().count()","8a1e6cf6":"from sklearn.preprocessing import RobustScaler\nfrom sklearn.impute import SimpleImputer\nsi= SimpleImputer(strategy='median')\nrs=RobustScaler()\n","894c202c":"char_clmns = regression_data.dtypes[regression_data.dtypes == \"object\"].index \nchar_clmns","56fd673b":"num_clmns = regression_data.dtypes[regression_data.dtypes != \"object\"].index \nnum_clmns","6d602903":"charer= regression_data[char_clmns]\ncharer=charer.fillna('UNK')\ncharer","29129716":"regression_data=regression_data.drop(charer.columns,axis=1,inplace=False)    ","044a0820":"regression_data","6b901ea9":"charer_corrected=pd.get_dummies(charer,drop_first=True)","4730d469":"charer_corrected=pd.DataFrame(charer_corrected)","016b649d":"regression_data = pd.concat([regression_data,charer_corrected],ignore_index=True,axis=1)\nregression_data","ecac7e8d":"regression_data=regression_data.fillna(0)","a36aaced":"regression_data","b9769277":"regression_data.columns=[str(i) for i in range(116)]\nregression_data.to_csv('new_file.csv',index=False)","47d87faf":"import torch\nfrom torch.utils.data import DataLoader,Dataset\nfrom sklearn.model_selection import train_test_split\nimport torch.nn as nn\nfrom sklearn.metrics import f1_score\nfrom sklearn.preprocessing import RobustScaler","a6cc41d9":"\n\ndf= pd.read_csv('.\/new_file.csv')\ndf.describe()\n\n","aa81ea57":"df['115'].nunique()","a8a7d476":"\n\nX=df.iloc[:,:-1]\ny=df.iloc[:,-1]\nX_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.2,shuffle=True,stratify=df['115'])\n\n        \n\n","1b25e60f":"rs=RobustScaler()\nX_train=rs.fit_transform(X_train)\nX_test=rs.fit_transform(X_test)","97c0278e":"class Attributes:\n    EPOCHS=100\n    BATCH_SIZE=32\n    LR=1e-3","fb41bc18":"class CustomDataset(Dataset):\n    def __init__(self,X_data,y_data):\n        self.X=X_data\n        self.y=y_data\n    def __len__(self):\n        return len(self.X)\n    def __getitem__(self,idx):\n        return self.X[idx],self.y[idx]\ntrain_data= CustomDataset(torch.FloatTensor(X_train),torch.FloatTensor(y_train.values))\ntest_data= CustomDataset(torch.FloatTensor(X_test),torch.FloatTensor(y_test.values))","545223cf":"train_loader=DataLoader(train_data,batch_size=Attributes.BATCH_SIZE,shuffle=True)\ntest_loader=DataLoader(test_data,batch_size=1)","7b0e7ce0":"class NeuralNet(nn.Module):\n    def __init__(self):\n        super(NeuralNet,self).__init__()\n        self.li1=nn.Linear(115,64)\n        self.li2=nn.Linear(64,64)\n        self.li3=nn.Linear(64,1)\n        \n        self.relu=nn.ReLU()\n        self.dropout=nn.Dropout(p=0.1)\n        self.batchnorm=nn.BatchNorm1d(64)\n        \n    def forward(self,x):\n        x= self.relu(self.li1(x))\n        x= self.batchnorm(x)\n        x=self.relu(self.li2(x))\n        x=self.batchnorm(x)\n        x=self.dropout(x)\n        x=self.li3(x)\n        return x","58e28fde":"\n\ndevice=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)\n\n","9fe70e53":"\n\nmodel=NeuralNet()\nmodel\n\n","0e5461e5":"model.to(device)\noptimizer=torch.optim.RMSprop(model.parameters(),lr=Attributes.LR)\nloss_fn=nn.BCEWithLogitsLoss()","1468871a":"def binary_acc(y_pred, y_test):\n    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n\n    correct_results_sum = (y_pred_tag == y_test).sum().float()\n    acc = correct_results_sum\/y_test.shape[0]\n    acc = torch.round(acc * 100)\n    \n    return acc","646e8447":"model.train()\nfor e in range(1, Attributes.EPOCHS+1):\n    epoch_loss = 0\n    epoch_acc = 0\n    for X_batch, y_batch in train_loader:\n        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n        optimizer.zero_grad()\n        \n        y_pred = model(X_batch)\n        \n        loss = loss_fn(y_pred, y_batch.unsqueeze(1))\n        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n        \n        loss.backward()\n        optimizer.step()\n        \n        epoch_loss += loss.item()\n        epoch_acc += acc.item()\n        \n\n    print(f'Epoch {e+0:03}: | Loss: {epoch_loss\/len(train_loader):.5f} | Acc: {epoch_acc\/len(train_loader):.3f}')","fd6ee2e7":"y_pred_list = []\nmodel.eval()\nwith torch.no_grad():\n    for X_batch,_ in test_loader:\n        X_batch = X_batch.to(device)\n        y_test_pred = model(X_batch)\n        y_test_pred = torch.sigmoid(y_test_pred)\n        y_pred_tag = torch.round(y_test_pred)\n        y_pred_list.append(y_pred_tag.cpu().numpy())\ny_pred_list = [a.squeeze().tolist() for a in y_pred_list]","2e259ac4":"f1_score(y_test,y_pred_list)","4076dec6":"\n\nimport sklearn.metrics as sm\nprint(sm.classification_report(y_test,y_pred_list))\n\n","afc1c1bd":"## Classification Data"}}