{"cell_type":{"83db78fa":"code","cc359835":"code","63107f0d":"code","6217cf54":"code","f1e3407f":"code","149ba3ee":"code","b487dd27":"code","d3035117":"code","27a4fa47":"code","3a677e8d":"code","8e200d2b":"code","95409eba":"code","e8e996af":"markdown","5ee1fa73":"markdown","69748e14":"markdown","a9507f6d":"markdown","2ffc215b":"markdown","768b2e21":"markdown","06d02469":"markdown"},"source":{"83db78fa":"import string\n\ndef transliterate_hindi(st):\n    HINDI_MAP = { '\u0950' : 'o\u1e41', '\u0900' : '\u1e41', '\u0901' : '\u1e43', '\u0902' : '\u1e43', '\u0903' : '\u1e25', '\u0905' : 'a', '\u0906' : '\u0101', '\u0907' : 'i', '\u0908' : '\u012b', '\u0909' : 'u', '\u090a' : '\u016b', '\u090b' : 'r\u0325', '\u0960' : ' r\u0325\u0304', '\u090c' : 'l\u0325', '\u0961' : ' l\u0325\u0304', '\u090d' : '\u00ea', '\u090e' : 'e', '\u090f' : 'e', '\u0910' : 'ai', '\u0911' : '\u00f4', '\u0912' : 'o', '\u0913' : 'o', '\u0914' : 'au', '\u093e' : '\u0101', '\u093f' : 'i', '\u0940' : '\u012b', '\u0941' : 'u', '\u0942' : '\u016b', '\u0943' : 'r\u0325', '\u0944' : ' r\u0325\u0304', '\u0962' : 'l\u0325', '\u0963' : ' l\u0325\u0304', '\u0945' : '\u00ea', '\u0947' : 'e', '\u0948' : 'ai', '\u0949' : '\u00f4', '\u094b' : 'o', '\u094c' : 'au', '\u0915\u093c' : 'q', '\u0915' : 'k', '\u0916\u093c' : 'x', '\u0916' : 'kh', '\u0917\u093c' : '\u0121', '\u0917' : 'g', '\u097b' : 'g', '\u0918' : 'gh', '\u0919' : '\u1e45', '\u091a' : 'c', '\u091b' : 'ch', '\u091c\u093c' : 'z', '\u091c' : 'j', '\u097c' : 'j', '\u091d' : 'jh', '\u091e' : '\u00f1', '\u091f' : '\u1e6d', '\u0920' : '\u1e6dh', '\u0921\u093c' : '\u1e5b', '\u0921' : '\u1e0d', '\u0978' : '\u1e0d', '\u097e' : 'd', '\u0922\u093c' : '\u1e5bh', '\u0922' : '\u1e0dh', '\u0923' : '\u1e47', '\u0924' : 't', '\u0925' : 'th', '\u0926' : 'd', '\u0927' : 'dh', '\u0928' : 'n', '\u092a' : 'p', '\u092b\u093c' : 'f', '\u092b' : 'ph', '\u092c' : 'b', '\u097f' : 'b', '\u092d' : 'bh', '\u092e' : 'm', '\u092f' : 'y', '\u0930' : 'r', '\u0932' : 'l', '\u0933' : '\u1e37', '\u0935' : 'v', '\u0936' : '\u015b', '\u0937' : '\u1e63', '\u0938' : 's', '\u0939' : 'h', '\u093d' : '\\'', '\u094d' : '', '\u093c' : '', '\u0966' : '0', '\u0967' : '1', '\u0968' : '2', '\u0969' : '3', '\u096a' : '4', '\u096b' : '5', '\u096c' : '6', '\u096d' : '7', '\u096e' : '8', '\u096f' : '9', '\ua8f3' : '\u1e41', '\u0964' : '.', '\u0965' : '..', ' ' : ' '}\n    return ''.join(HINDI_MAP.get(c, c)  for c in st)\n\ndef transliterate_tamil(st):\n    text = \"\"\"\u0b85 a \u0b8e e \u0b86 \u0101 \u0b8f \u0113 \u0b87 i \u0b90 ai \u0b88 \u012b \u0b92 o \u0b89 u \u0b93 \u014d \u0b8a \u016b \u0b94 au \u0b83 ka \u0bae ma \u0b95 ka \u0baf ya \u0b99 \u1e45a \u0bb0 ra \u0b9a ca \u0bb2 la \u0b9e \u00f1a \u0bb5 va \u0b9f \u1e6da \u0bb4 la \u0ba3 \u1e47a \u0bb3 \u1e37a \u0ba4 ta \u0bb1 ra\u0ba8 na \u0ba9 na \u0baa pa \u0b9c ja \u0bb8 sa \u0bb6 \u015ba \u0bb9 ha \u0bb7 \u1e63a\"\"\".split()\n    TAMIL_MAP = dict(zip(text[0::2], text[1::2]))\n    TAMIL_MAP.update({t: t for t in ' ?.1234567890'+string.ascii_lowercase})\n    return ''.join(TAMIL_MAP.get(c.lower(), '') for c in st)\n\ndef transliterate(df_in, columns=['question', 'context', 'answer_text']):\n    df = df_in.copy()\n    for c in columns:\n        df.loc[df['language'] == 'hindi', c] = df.loc[df['language'] == 'hindi', c].apply(transliterate_hindi)\n        df.loc[df['language'] == 'tamil', c] = df.loc[df['language'] == 'tamil', c].apply(transliterate_tamil)        \n    return df","cc359835":"import pandas as pd\n\ndf_train = pd.read_csv(\"..\/input\/chaii-hindi-and-tamil-question-answering\/train.csv\")\ndf_trans = transliterate(df_train)","63107f0d":"df_train.head()","6217cf54":"df_trans.head()","f1e3407f":"df_train[df_train['language'] == 'hindi'].head(5)","149ba3ee":"df_trans[df_trans['language'] == 'hindi'].head(5)","b487dd27":"# This is a name. Adolph Meyr or something\ndf_trans[df_trans['language'] == 'hindi']['answer_text'].iloc[0]","d3035117":"df_train[df_train['language'] == 'hindi']['answer_text'].iloc[0]","27a4fa47":"df_train.iloc[1112]['answer_text']","3a677e8d":"df_trans.iloc[1112]['answer_text']","8e200d2b":"df_train[df_train['language'] == 'hindi'].iloc[0]['context']","95409eba":"df_trans[df_trans['language'] == 'hindi'].iloc[0]['context']","e8e996af":"## Hindi","5ee1fa73":"# Example usage:","69748e14":"And this is a date (October 27, 1605):","a9507f6d":"## Tamil","2ffc215b":"<img src=\"https:\/\/i.imgur.com\/RFR6UZX.jpg\" width=\"100%\"\/>\n\n# Quick and dirty Transliteration Tables\n\nThis notebook provides a simple, short, and easy to *copy and paste* set of three functions to transliterate (in a very quick-and-dirty fashion) from `Hindi` and `Tamil` to `Latin` alphabet (in 16 lines of code).\n\n# What is transliteration?  `\u0905\u0915\u094d\u0924\u0942\u092c\u0930` -> `akt\u016bbr` (October)\n\nTransliteration is the action of phonetically mapping one alphabet with another. It allows or improves phonetic readability and, sometimes, interpretability too.\n\nSee this example:\n\nThis is how you write `police` in Russian: `\u043f\u043e\u043b\u0438\u0446\u0438\u044f`.\n\nAnd this is how it looks when you transliterate Cyrillic to Latin: `politsiya`\n\nIt's still Russian, but much more familiar, isn't it?\nThe transliteration is a simple phonetic mapping from one alphabet to another. Here, the mapping was:\n```python\n{'\u043f': 'p', '\u043e': 'o', '\u043b': 'l', '\u0438': 't', '\u0446': 's', '\u0438': 'i', '\u044f': 'ya'}\n```\n\n\n# Origin of the tables\n\nI couldn't find well-established python packaged for that, at least fast. But I did find the following tables:\n\nFor Hindi:\n* https:\/\/pandey.github.io\/posts\/transliterate-devanagari-to-latin.html\n\nFor Tamil:\n* https:\/\/www.loc.gov\/catdir\/cpso\/romanization\/tamil.pdf\n\n\nNote that few characters are dropped (this is actually quick and dirty)\n\n\n# Usage\n\nThe usage is quite straightforward. See examples below for some good surprises!\n```python\ndf_trans = transliterate(df_train)\n```","768b2e21":"It increases a little the readability. See for example:","06d02469":"### New to Question Answering? \nJoin me in my `Quick overview for QA noobs` series, where I'm jumping into this competition from zero. Current notebooks are:\n\n1. [The competition [QA for QA noobs]](https:\/\/www.kaggle.com\/julian3833\/1-the-competition-qa-for-qa-noobs)\n2. [The dataset [QA for QA noobs]](https:\/\/www.kaggle.com\/julian3833\/2-the-dataset-qa-for-qa-noobs)\n3. [The metric (Jaccard) [QA for QA noobs]](https:\/\/www.kaggle.com\/julian3833\/3-the-metric-jaccard-qa-for-qa-noobs)\n4. [Exploring Public Models [QA for QA noobs]](https:\/\/www.kaggle.com\/julian3833\/4-exploring-public-models-qa-for-qa-noobs\/)\n5. [XLM-Roberta + Torch's extra data [LB: 0.749]](https:\/\/www.kaggle.com\/julian3833\/5-xlm-roberta-torch-s-extra-data-lb-0-749)\n\n&nbsp;\n&nbsp;\n&nbsp;\n&nbsp;\n&nbsp;\n\n## Remember to upvote the notebook if you found it useful! \ud83e\udd17"}}