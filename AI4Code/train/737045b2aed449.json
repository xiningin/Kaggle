{"cell_type":{"f3084e49":"code","6634e757":"code","52ebf6c9":"code","c2be37d1":"code","2e949130":"code","1bc4e5ab":"code","b5494b72":"code","adc298e1":"code","e8575a43":"code","4f5694b8":"code","4ff1bffe":"code","6d4036a4":"code","3f0e83c5":"code","c483fdc6":"code","1c4c49cd":"code","390d1e18":"code","9242c9ec":"code","c9538f7b":"code","a535504a":"code","45594849":"code","e5f2e3ed":"code","00729109":"code","a13635a6":"code","b5fb935f":"code","d5d00498":"code","19d5c748":"code","5ea64af4":"code","32697381":"code","d11376b4":"code","79340f2d":"code","f97b28ca":"code","8b1ac57b":"code","b610c091":"code","26383a92":"code","1f4a8dd0":"code","88e79df6":"code","d36d57eb":"code","0e7ccde2":"code","c48d6c3d":"code","f95154e6":"code","a9b8201d":"code","35183747":"code","5c710685":"code","66fa5980":"code","008186a7":"code","71aaa021":"code","1eddefae":"code","4f2cedaf":"code","6b8d4598":"code","73c1b759":"markdown","d79c257b":"markdown","50fc123f":"markdown","2927d0bf":"markdown"},"source":{"f3084e49":"import numpy as np\nimport pandas as pd\nimport tensorflow as tensor\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","6634e757":"df = pd.read_csv('train.csv')","52ebf6c9":"df['Review']=df['Review'].fillna(\"\")\ndf['Review_Title']=df['Review_Title'].fillna(\"\")","c2be37d1":"import html\ndf=df.copy()\ndf['Review'] = html.unescape(df['Review'])\ndf['Review_Title'] = html.unescape(df['Review_Title'])","2e949130":"pattern = r\"\\&\\#[0-9]+\\;\"\n\ndf['Review'] = df['Review'].str.replace(pat=pattern, repl=\"\", regex=True)\ndf['Review_Title'] = df['Review_Title'].str.replace(pat=pattern, repl=\"\", regex=True)","1bc4e5ab":"pattern = r\"[^\\w\\s]\"\n\ndf[\"Review\"] = df[\"Review\"].str.replace(pat=pattern, repl=\" \", regex=True)\ndf[\"Review_Title\"] = df[\"Review_Title\"].str.replace(pat=pattern, repl=\" \", regex=True)","b5494b72":"df[\"Review\"] = df[\"Review\"].str.lower()\ndf[\"Review_Title\"] = df[\"Review_Title\"].str.lower()","adc298e1":"pattern = r\"[\\s]+\"\n\ndf[\"Review\"] = df[\"Review\"].str.replace(pat=pattern, repl=\" \", regex=True)\ndf[\"Review_Title\"] = df[\"Review_Title\"].str.replace(pat=pattern, repl=\" \", regex=True)","e8575a43":"err1 = df['Review'].str.extractall(\"(&amp)\")\nerr2 = df['Review'].str.extractall(\"(\\xa0)\")\n","4f5694b8":"print('with &amp',len(err1[~err1.isna()]))\nprint('with (\\xa0)',len(err2[~err2.isna()]))","4ff1bffe":"df['Review'] = df['Review'].str.replace('(&amp)','')\ndf['Review']= df['Review'].str.replace('(\\xa0)','')","6d4036a4":"df.index = np.arange(len(df))","3f0e83c5":"import nltk\nimport re\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\ncorpus=[]\n# x_change = df[['Review']]\nfor i in range(len(df)):\n    review = re.sub('[^a-zA-z]',' ',df['Review'][i])\n    review = review.split()\n    ps = PorterStemmer()\n    review =[ps.stem(i) for i in review if not i in set(stopwords.words('english'))]\n    review =' '.join(review)\n    corpus.append(review)","c483fdc6":"titl=[]\nfor i in range(len(df)):\n    revi = re.sub('[^a-zA-z]',' ',df['Review_Title'][i])\n    revi = revi.split()\n    ps = PorterStemmer()\n    revi =[ps.stem(i) for i in revi if not i in set(stopwords.words('english'))]\n    revi =' '.join(revi)\n    titl.append(revi)","1c4c49cd":"df['Review']=corpus\ndf['Review_Title']=titl","390d1e18":"from sklearn.model_selection import train_test_split\nX = df[['Age','Review','Review_Title','Pos_Feedback_Cnt','Division','Department','Product_Category']]\ny = df[['Rating','Recommended']]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y)","9242c9ec":"num_words = 10000 \nnum_departments = 5 \n\ntitle_input = keras.Input(\n    shape=(None,), name=\"title\")  \nbody_input = keras.Input(shape=(None,), name=\"body\")  \ncategorical_input = keras.Input(\n    shape=(3,), name=\"tags\")\nnumeric_inputs = keras.Input(\n    shape=(2,), name=\"numeric\")\n\ntitle_features = layers.Embedding(num_words, 32)(title_input)\nbody_features = layers.Embedding(num_words, 32)(body_input)\n\ncat_features = layers.Dense(16, activation='relu')(categorical_input)\nnum_features = layers.Dense(16, activation='relu')(numeric_inputs)\n\ntitle_features =  tensor.keras.layers.GRU(32)(title_features)\nbody_features =  tensor.keras.layers.GRU(128)(body_features)\n\nbody_features = layers.Dropout(.6)(body_features)\nbody_features = layers.Dense(16, activation='relu')(body_features)\n\ntitle_features=layers.Dense(16, activation='relu')(title_features)\n\nx = layers.concatenate([body_features,title_features,cat_features,num_features])\n\nrecommended_pred = layers.Dense(1,activation='sigmoid', name=\"recommended\")(x)\nrating_pred = layers.Dense(num_departments,activation='softmax', name=\"rating\")(x)\n\nmodel = keras.Model(\n    inputs=[body_input,title_input,categorical_input,numeric_inputs],\n    outputs=[recommended_pred, rating_pred]\n\n)","c9538f7b":"model.compile(\n    optimizer='Adam',\n    loss={\n        \"recommended\": keras.losses.BinaryCrossentropy(),\n        \"rating\": keras.losses.SparseCategoricalCrossentropy(),\n    },\n    metrics = ['accuracy'],\n)","a535504a":"from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nimport numpy as np\nfrom sklearn import preprocessing\nlabel_encoder = preprocessing.LabelEncoder()\n\nimputer = SimpleImputer(strategy='most_frequent')\nx1=imputer.fit_transform(X_train[['Division']]).ravel()\nx2=imputer.fit_transform(X_train[['Department']]).ravel()\nx3=imputer.fit_transform(X_train[['Product_Category']]).ravel()\n\ny1=label_encoder.fit_transform(x1).ravel()\ny2=label_encoder.fit_transform(x2).ravel()\ny3=label_encoder.fit_transform(x3).ravel()\ncategory=np.column_stack((y1,y2,y3))\ncategory.shape","45594849":"num_data =  np.vstack((X_train['Age'],X_train['Pos_Feedback_Cnt']))\nnum_data=num_data.transpose()\nnum_data.shape","e5f2e3ed":"from sklearn.feature_extraction.text import CountVectorizer\ntext_body = X_train[\"Review\"]\ntext_title=X_train[\"Review_Title\"]\n\nvectorizer = CountVectorizer(ngram_range=(1,1))\nvectorizer.fit(text_body)\n\nvector = vectorizer.transform(text_body)\ncount_body = vector.toarray()\ncount_title=vectorizer.transform(text_title).toarray()","00729109":"VOCAB_SIZE = 10000\ntitle_data = X_train['Review_Title'].values\nbody_data = X_train['Review'].values\ntitle_data = np.asarray(title_data).astype('str')\nbody_data = np.asarray(body_data).astype('str')\nencoder = tensor.keras.layers.experimental.preprocessing.TextVectorization(max_tokens=VOCAB_SIZE,ngrams=1)\n\nencoder.adapt(X_train['Review'].values)\n#a-X_traindeki review-in, b review_title-in reqemle ifadesi ucun variablerdi\nbody_data=encoder(body_data).numpy()\ntitle_data=encoder(title_data).numpy()\n\nrecommended_targets = y_train['Recommended'].values\nrat_targets = y_train['Rating']-1","a13635a6":"model.fit(    \n     {\"body\": body_data,\"title\":title_data, \"tags\": category,\"numeric\":num_data},\n    {\"recommended\": recommended_targets, \"rating\": rat_targets},\n    validation_split=0.3,\n    epochs=5,\n    batch_size=32,\n)","b5fb935f":"# Appending prediction for recommendation. \nrecom_list=[]\nfor i in model.predict([body_data,title_data,category,num_data])[0]:\n    if i>0.5:\n        recom_list.append(1)\n    else:\n        recom_list.append(0)\n\n# Appending prediction for rating.         \ncateg=[]\nfor i in model.predict([body_data,title_data,category,num_data])[1]:\n    index = np. argmax(i)\n    categ.append(index+1)","d5d00498":"from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nimport numpy as np\n\nimputer = SimpleImputer(strategy='most_frequent')\ns1=imputer.fit_transform(X_test[['Division']]).ravel()\ns2=imputer.fit_transform(X_test[['Department']]).ravel()\ns3=imputer.fit_transform(X_test[['Product_Category']]).ravel()\n\n\n\nz1=label_encoder.fit_transform(s1).ravel()\nz2=label_encoder.fit_transform(s2).ravel()\nz3=label_encoder.fit_transform(s3).ravel()\ncat=np.column_stack((z1,z2,z3))","19d5c748":"num =  np.vstack((X_test['Age'],X_test['Pos_Feedback_Cnt']))\nnum=num.transpose()\nnum.shape","5ea64af4":"titl = X_test['Review_Title'].values\nbody = X_test['Review'].values\ntitl = np.asarray(titl).astype('str')\nbody = np.asarray(body).astype('str')\n\nbody_test=encoder(body).numpy()\ntitle_test=encoder(titl).numpy()","32697381":"rec_list=[]\nfor i in model.predict([body_test,title_test,cat,num])[0]:    \n    if i>0.5:\n        rec_list.append(1)\n    else:\n        rec_list.append(0)\n        \ncati=[]\nfor i in model.predict([body_test,title_test,cat,num])[1]:\n    index = np. argmax(i)\n    cati.append(index+1)","d11376b4":"from collections import Counter\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\n\n\nprint('Training set performance for recommended :', accuracy_score(y_train['Recommended'].values, recom_list))\nprint('Training set performance for rating:', accuracy_score(y_train['Rating'].values, categ))\n\nprint()\nprint('Test set performance for recommended :', accuracy_score(y_test['Recommended'].values, rec_list))\nprint('Test set performance for Rating :', accuracy_score(y_test['Rating'].values, cati))\nprint(classification_report(y_train['Rating'].values, categ))\nprint()\nprint('Test Classification report')\nprint(classification_report(y_test['Rating'].values, cati))\nprint()\n\nprint(f\"Real training Rating values: {Counter(y_train['Rating'])}\")\nprint(f\"Predicted training Rating values: {Counter(categ)}\")\nprint()\nprint(f\"Real test Rating values: {Counter(y_test['Rating'])}\")\nprint(f\"Predicted test Rating values: {Counter(cati)}\")","79340f2d":"df_t = pd.read_csv('test.csv')","f97b28ca":"df_t['Review']=df_t['Review'].fillna(\"is the\")\ndf_t['Review_Title']=df_t['Review_Title'].fillna(\"is the\")","8b1ac57b":"df_t['Review']=df_t['Review'].astype(\"string\")","b610c091":"import html\ndf_t=test_df.copy()\ndf_t['Review'] = html.unescape(df_t['Review'])\ndf_t['Review_Title'] = html.unescape(df_t['Review_Title'])","26383a92":"pattern = r\"\\&\\#[0-9]+\\;\"\n\ndf_t['Review'] = df_t['Review'].str.replace(pat=pattern, repl=\"\")\ndf_t['Review_Title'] = df_t['Review_Title'].str.replace(pat=pattern, repl=\"\",)","1f4a8dd0":"patte = r\"[^\\w\\s]\"\n\ndf_t[\"Review\"] = df_t[\"Review\"].str.replace(pat=patte, repl=\" \", regex=True)\ndf_t[\"Review_Title\"] = df_t[\"Review_Title\"].str.replace(pat=patte, repl=\" \", regex=True)","88e79df6":"df_t[\"Review\"] = df_t[\"Review\"].str.lower()\ndf_t[\"Review_Title\"] = df_t[\"Review_Title\"].str.lower()","d36d57eb":"df_t['Review'] = df_t['Review'].str.replace('(&amp)','')\ndf_t['Review']= df_t['Review'].str.replace('(\\xa0)','')","0e7ccde2":"patr = r\"[\\s]+\"\n\ndf_t[\"Review\"] = df_t[\"Review\"].str.replace(pat=patr, repl=\" \", regex=True)\ndf_t[\"Review_Title\"] = df_t[\"Review_Title\"].str.replace(pat=patr, repl=\" \", regex=True)","c48d6c3d":"test_df.index = np.arange(len(df_t))","f95154e6":"l1=[]\nfor i in range(len(df_t)):\n    revi = re.sub('[^a-zA-z]',' ',df_t['Review'][i])\n    revi = revi.lower()\n    revi = revi.split()\n    ps = PorterStemmer()\n    revi =[ps.stem(i) for i in revi if not i in set(stopwords.words('english'))]\n    revi =' '.join(revi)\n    l1.append(revi)","a9b8201d":"df_t['Review']=l1\ndf_t['Review'][1]","35183747":"m1=[]\nfor i in range(len(test_df)):\n    revi = re.sub('[^a-zA-z]',' ',df_t['Review_Title'][i])\n    revi = revi.split()\n    ps = PorterStemmer()\n    revi =[ps.stem(i) for i in revi if not i in set(stopwords.words('english'))]\n    revi =' '.join(revi)\n    m1.append(revi)","5c710685":"df_t['Review_Title']=m1\ndf_t['Review_Title'][1]","66fa5980":"from sklearn.preprocessing import OneHotEncoder\nimport numpy as np\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy='most_frequent')\ndiv=imputer.fit_transform(df_t[['Division']]).ravel()\ndep=imputer.fit_transform(df_t[['Department']]).ravel()\nprod=imputer.fit_transform(df_t[['Product_Category']]).ravel()\n\ndiv_l=label_encoder.fit_transform(div).ravel()\ndep_l=label_encoder.fit_transform(dep).ravel()\nprod_l=label_encoder.fit_transform(prod).ravel()\ncat_test=np.column_stack((div_l,dep_l,prod_l))\ncat_test.shape","008186a7":"numer =  np.vstack((df_t['Age'],df_t['Pos_Feedback_Cnt']))\nnumer=numer.transpose()\nnumer.shape","71aaa021":"rev_titl = df_t['Review_Title'].values\nrev_body = df_t['Review'].values\nrev_titl = np.asarray(rev_titl).astype('str')\nrev_body = np.asarray(rev_body).astype('str')\n\nrev_titl=encoder(rev_titl).numpy()\nrev_body=encoder(rev_body).numpy()","1eddefae":"pred_rec=[]\nfor i in model.predict([rev_titl,rev_body,cat_test,numi])[0]:\n    \n    if i>0.5:\n        pred_rec.append(1)\n    else:\n        pred_rec.append(0)\n\npred_rat=[]\nfor i in model.predict([rev_titl,rev_body,cat_test,numi])[1]:    \n    index = np. argmax(i)\n    pred_rat.append(index+1)\n  ","4f2cedaf":"output = pd.DataFrame({'Id':df_t['Id'],'Rating':pred_rat,'Recommended':pred_rec})","6b8d4598":"filename = '.csv'\noutput.to_csv(filename,index=False)","73c1b759":"I have used PorterStemmer to stemm all the words because of using the encoder which is called \"TextVectorization\" therefore we need to have the words in same form. I have removed stopwords from the text to use only important words.","d79c257b":"# Using the TextVectorization to encoding the each words independently","50fc123f":"# Bag-of-words model for encoding the Review and Review_Title columns","2927d0bf":"Replacing NaN values with empty string. Here I have used preprocessing tools to remove numbers and extra symbols."}}