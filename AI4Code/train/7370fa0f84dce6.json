{"cell_type":{"58bdcfee":"code","1300ede2":"code","f2554449":"code","856bcdcd":"code","175bb028":"code","955a49b2":"code","dc534b21":"code","7515ba20":"code","56d39fb6":"code","4d1d13fe":"code","ff9a2938":"code","ca503b1d":"code","0505f761":"code","bceb57e5":"code","8d0716a6":"code","3455281d":"code","ff698a35":"code","57b5d7dd":"code","256798b7":"code","a3bb12f0":"code","6c0e9f32":"code","7a0d815a":"code","f33bfdba":"code","cefb1397":"code","c6914a32":"code","5877613f":"code","3107026e":"code","1c05a852":"markdown","2875c7a8":"markdown","78132d75":"markdown","69c0b8d0":"markdown","d8bcd25f":"markdown","6c23ce19":"markdown","a7de257f":"markdown","3f14e97e":"markdown","4b2a7be1":"markdown","a7fb66d1":"markdown","486714fd":"markdown","955b0c20":"markdown","33a9f602":"markdown","58796b04":"markdown","b503a7cc":"markdown","e03cb6d5":"markdown","73a22fbf":"markdown"},"source":{"58bdcfee":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nplt.rcParams['figure.figsize'] = [9, 12]\n\nimport warnings\nwarnings.simplefilter('ignore')","1300ede2":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import cross_val_score, train_test_split, KFold, StratifiedKFold","f2554449":"# Classification\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n\nimport lightgbm as lgb\nimport xgboost as xgb","856bcdcd":"train = pd.read_csv(\"\/kaggle\/input\/whoisafriend\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/whoisafriend\/test.csv\")\nsub = pd.read_csv(\"\/kaggle\/input\/whoisafriend\/sample_submission.csv\")\n\ntrain.shape, test.shape, sub.shape","175bb028":"train.head()","955a49b2":"test.head()","dc534b21":"# First of all are the persons in Person_A and Person_B from same set or are they from the different set.\ntrain[['Person A', 'Person B']].describe()","7515ba20":"len(set(train['Person A'].unique()) - set(train['Person B'].unique()))","56d39fb6":"len(set(train['Person B'].unique()) - set(train['Person A'].unique()))","4d1d13fe":"train_persons_list = train['Person A'].unique().tolist() + train['Person B'].unique().tolist()\ntest_persons_list = test['Person A'].unique().tolist() + test['Person B'].unique().tolist()","ff9a2938":"len(set(train_persons_list) - set(test_persons_list)), len(set(test_persons_list) - set(train_persons_list))","ca503b1d":"train['Persons_Name_combined'] = train['Person A'] + train['Person B']\ntest['Persons_Name_combined'] = test['Person A'] + test['Person B']","0505f761":"plt.figure(figsize=(15, 4))\nsns.countplot(train['Moon Phase During Interaction'], hue=train['Friends'])\nplt.show()","bceb57e5":"sns.lmplot('Years of Knowing', 'Interaction Duration', data=train, hue='Friends', size=15)","8d0716a6":"train['mult_years_dur'] = train['Years of Knowing'] + train['Interaction Duration']\ntest['mult_years_dur'] = test['Years of Knowing'] + test['Interaction Duration']","3455281d":"def missing_values(df):\n    mis_val = df.isnull().sum()\n    mis_val_percent = 100 * df.isnull().sum() \/ len(df)\n    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n    mis_val_table_ren_columns = mis_val_table.rename(\n        columns={0: 'Missing Values', 1: '% of Total Values'})\n    mis_val_table_ren_columns = mis_val_table_ren_columns[\n        mis_val_table_ren_columns.iloc[:, 1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n    print(\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"\n                                                              \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n          \" columns that have missing values.\")\n\n    return mis_val_table_ren_columns","ff698a35":"miss_train, miss_test = missing_values(train), missing_values(test)","57b5d7dd":"cat_cols = ['Person A', 'Person B', 'Interaction Type', 'Moon Phase During Interaction', 'Persons_Name_combined']\ntarget = 'Friends'","256798b7":"# Making a dictionary to store all the labelencoders for categroical columns to transform them later.\nle_dict = {}\n\nfor col in cat_cols:\n    le = LabelEncoder()\n    le.fit(train[col].unique().tolist() + test[col].unique().tolist())\n    train[col] = le.transform(train[[col]])\n    test[col] = le.transform(test[[col]])\n    \n    le_dict[col] = le","a3bb12f0":"def baseliner(train, features, target, cv=3, metric='accuracy'):\n    \"\"\"\n    Function for baselining Models which return CV Score, Train Score, Valid Score\n    \"\"\"\n    print(\"Baseliner Models\\n\")\n    eval_dict = {}\n    models = [lgb.LGBMClassifier(), xgb.XGBClassifier(), GradientBoostingClassifier(), LogisticRegression(), \n              RandomForestClassifier(), DecisionTreeClassifier(), AdaBoostClassifier()\n             ]\n    print(\"Model Name \\t |   CV\") #    | \\t TRN   | \\t  VAL\n    print(\"--\" * 50)\n\n    for index, model in enumerate(models, 0):\n        model_name = str(model).split(\"(\")[0]\n        eval_dict[model_name] = {}\n\n        results = cross_val_score(model, train[features], train[target], cv=cv, scoring=metric)\n        eval_dict[model_name]['cv'] = results.mean()\n\n        print(\"%s \\t | %.4f \\t\" % (\n            model_name[:12], eval_dict[model_name]['cv']))","6c0e9f32":"target = 'Friends'\nid_col = 'ID'\n\nfeat = train.columns.tolist()\nfeat.remove(target)\nfeat.remove(id_col)\n\nprint(\"Length of Features : {}\".format(len(feat)))","7a0d815a":"baseliner(train, feat, target)","f33bfdba":"def splitter(train, features, target, ts=False):\n    if ts:\n        trainX, validX, trainY, validY = train_test_split(train[features],\n                                                          train[target], test_size=0.2,\n                                                          random_state=13, shuffle=False)\n    else:\n        trainX, validX, trainY, validY = train_test_split(train[features],\n                                                      train[target], test_size=0.2,\n                                                      random_state=13)\n    return trainX, validX, trainY, validY\n\ndef lgb_model(train, test, features, target, ts=False):\n    evals_result = {}\n    trainX, validX, trainY, validY = splitter(train, features, target, ts=ts)\n    print(\"LGB Model\")\n    lgb_train_set = lgb.Dataset(trainX, label=trainY)\n    lgb_valid_set = lgb.Dataset(validX, label=validY)\n\n    MAX_ROUNDS = 2000\n    lgb_params = {\n        \"boosting\": 'gbdt',  # \"dart\",\n        \"learning_rate\": 0.01,\n        \"nthread\": -1,\n        \"seed\": 13,\n        \"num_boost_round\": MAX_ROUNDS,\n        \"objective\": \"binary\",\n        \"metric\": \"binary_error\",\n    }\n\n    lgb_model = lgb.train(\n        lgb_params,\n        train_set=lgb_train_set,\n        valid_sets=[lgb_train_set, lgb_valid_set],\n        early_stopping_rounds=50,\n        verbose_eval=100,\n        evals_result=evals_result,\n    )\n\n    lgb.plot_importance(lgb_model, figsize=(24, 24))\n    lgb.plot_metric(evals_result, metric='binary_error')\n    \n    preds = lgb_model.predict(test[feat])\n    return lgb_model, preds","cefb1397":"lgbM, lgb_preds = lgb_model(train, test, feat, target, ts=False)","c6914a32":"threshold = 0.5\nlgb_preds[lgb_preds < threshold] = 0\nlgb_preds[lgb_preds >= threshold] = 1\n\nsub['lgb'] = lgb_preds\nsub['lgb'] = sub['lgb'].astype(np.int)\nsub.head()","5877613f":"plt.figure(figsize=(12, 5))\nsns.distplot(lgb_preds)\nplt.title(\"Distritbution of predictions\")\nplt.show()","3107026e":"sub[['ID', 'lgb']].rename({\n    \"lgb\": \"Friends\"\n}, axis=1).to_csv(\"lgb_submission.csv\", index=False)","1c05a852":"### Understanding the data and Making Hypothesis : \n\n- H1. Is there a relation between persons in Train and Test?\n- H2. Does Moon Phase matter \/ important in being a friend? \n- H3. Distribution of Years of Knowing and Interaction Duration between friends and non-friends.","2875c7a8":"### H1 :  Is there a relation between persons in Train and Test?","78132d75":"#### Oh look what we have here. It seems there is a good relationship between \"Years_Known\" and \"Interaction_Duration\" for being Friends.\n#### The two lines represent the fitted regression line. Seaborn does is defaultly in ScatterPlots. They also state they have a good relationship and might prove good features.","69c0b8d0":"#### No Intersection, that means no persons are common in train and test sets.\n\nSo is the feature Person A and Person B not important? Absolutely not. They might be not that important indiviudually but think if we combine both these features so this feature now implies a combination of persons and consider if a model predicts at one record that these two are friends so they musnt be.","d8bcd25f":"### Data Preprocessing","6c23ce19":"#### Missing Values","a7de257f":"#### So that clarifies that they both are from different sets. But how about difference between train and test.","3f14e97e":"### H2.  Does Moon Phase matter \/ important in being a friend? ","4b2a7be1":"### Saving the submission","a7fb66d1":"### Baselining Models","486714fd":"#### Label Encoding ","955b0c20":"### Basic LightGBM Modelling","33a9f602":"### Distribution of the prediction probabilities","58796b04":"### Importing Data","b503a7cc":"#### It seems there are 100 unique names both in Person A and Person B. \n#### Now let's check whether they are same or different.\n\n#### Lets check the count of Person B who are not in Person A list. \n#### If this is equal to 100 then it says that there is no interaction between both the sets.","e03cb6d5":"### H3. Distribution of Years of Knowing and Interaction Duration between friends and non-friends.","73a22fbf":"#### By seeing this plot it doesn't seem Moon Phase seriously affects the Friendship, but let the model verify it."}}