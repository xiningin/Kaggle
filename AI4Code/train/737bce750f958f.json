{"cell_type":{"d24c1a18":"code","12b32522":"code","23d4def3":"code","39ec07ed":"code","e0124496":"code","50426d04":"code","7e29b413":"code","123e2fdd":"code","2e317ad6":"code","5a38d4de":"code","ed126aea":"code","249b242c":"code","506e8af7":"code","361050a4":"code","c9ddc65e":"code","941555fe":"code","95bd8642":"code","02daf98c":"code","0e52f959":"code","dc9b6298":"code","3781bfb9":"code","b25cc9a6":"code","1f438cb3":"code","5b4b5e46":"code","e05cf5c3":"code","778489c7":"code","9e0dad04":"code","f7eb19a0":"markdown","e1e13fdf":"markdown","47a3310f":"markdown","d3b1eb86":"markdown","a63ae346":"markdown","e58fac75":"markdown","0663b139":"markdown","2f21046e":"markdown","180b3cb1":"markdown","e1dde954":"markdown"},"source":{"d24c1a18":"import numpy as np\nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\nimport scipy.stats as stats\nfrom sklearn.preprocessing import PowerTransformer, QuantileTransformer, RobustScaler\nfrom sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.decomposition import PCA, KernelPCA\nfrom sklearn.manifold import TSNE\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, mean_squared_log_error\nfrom sklearn.model_selection import train_test_split, cross_val_score, ShuffleSplit, StratifiedShuffleSplit","12b32522":"def rmse(true, pred):\n    return np.sqrt(mean_squared_error(true, pred))\n\ndef rmsle(true, pred):\n    return np.sqrt(mean_squared_log_error(true, pred))\n\nfrom sklearn.metrics import make_scorer\n\nscore_rmse = make_scorer(rmse, greater_is_better=False)","23d4def3":"train = pd.read_csv('\/kaggle\/input\/youtube-likes-prediction-av-hacklive\/train.csv', parse_dates=['publish_date'])\ntest = pd.read_csv('\/kaggle\/input\/youtube-likes-prediction-av-hacklive\/test.csv', parse_dates=['publish_date'])\nsample = pd.read_csv('\/kaggle\/input\/youtube-likes-prediction-av-hacklive\/sample_submission_cxCGjdN.csv')\nprint(train.shape, test.shape)","39ec07ed":"train.info()","e0124496":"train.isna().sum()","50426d04":"test.isna().sum()","7e29b413":"train.skew()","123e2fdd":"train.head()","2e317ad6":"train.category_id = train.category_id.astype('int')\ntest.category_id = test.category_id.astype('int')","5a38d4de":"pt = PowerTransformer(method='yeo-johnson')\nskew = ['views','dislikes','comment_count','likes']","ed126aea":"i = 0\nfig, ax = plt.subplots(2, 4, figsize=(12, 5))\nax = ax.flatten()\nfor col in skew:    \n    sns.distplot(train[col], fit=stats.norm, ax=ax[i], label='Before Transformation')\n    sns.distplot(pt.fit_transform(train[col][:,None]), fit=stats.norm, ax=ax[i+1], label='After Transformation')\n    ax[i].legend(loc='best')\n    ax[i+1].legend(loc='best')\n    i+=2\nplt.tight_layout()\nplt.show()","249b242c":"sns.jointplot(x='views', y='likes', data=train, kind='scatter')\nplt.show()","506e8af7":"def date_features(data):\n    data['day'] = data.publish_date.dt.day\n    data['weekday'] = data.publish_date.dt.dayofweek\n    data['month'] = data.publish_date.dt.month\n    data['year'] = data.publish_date.dt.year\n    data['is_weekend'] = np.where((data.weekday==5)|(data.weekday==6), 1, 0)\n    data['week_year'] = data.publish_date.dt.weekofyear\n    data['day_year'] = data.publish_date.dt.dayofyear\n    data['quarter'] = data.publish_date.dt.quarter\n    return data\n\ntrain = date_features(train)\ntest = date_features(test)","361050a4":"train['title_len'] = train['title'].apply(lambda x: len(x))\ntrain['description_len'] = train['description'].apply(lambda x: len(x))\ntrain['tags_len'] = train['tags'].apply(lambda x: len(x))\ntrain['channel_title_len'] = train['channel_title'].apply(lambda x: len(x))\ntrain['publish_date_days_since_start'] = (train['publish_date'] - train['publish_date'].min()).dt.days\ntrain['channel_title_num_videos'] = train['channel_title'].map(train['channel_title'].value_counts())\ntrain['publish_date_num_videos'] = train['publish_date'].map(train['publish_date'].value_counts())\n\ntest['title_len'] = test['title'].apply(lambda x: len(x))\ntest['description_len'] = test['description'].apply(lambda x: len(x))\ntest['tags_len'] = test['tags'].apply(lambda x: len(x))\ntest['channel_title_len'] = test['channel_title'].apply(lambda x: len(x))\ntest['publish_date_days_since_start'] = (test['publish_date'] - test['publish_date'].min()).dt.days\ntest['channel_title_num_videos'] = test['channel_title'].map(test['channel_title'].value_counts())\ntest['publish_date_num_videos'] = test['publish_date'].map(test['publish_date'].value_counts())","c9ddc65e":"train.head(3)","941555fe":"X = train.drop(['likes'], axis=1)\nY = train['likes']","95bd8642":"pt_likes = PowerTransformer(method='yeo-johnson')\n\nx_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.8, random_state=1, stratify=X['country_code'])\ny_train = pt_likes.fit_transform(y_train[:,None])\ny_test = pt_likes.transform(y_test[:,None])\nprint(f'Train : {x_train.shape} Test : {x_test.shape}')","02daf98c":"def score_metrics(model, train, train_a, test=None, test_a=None):\n    trainpred = model.predict(train)\n    print('Train R2 score : %.4f'%r2_score(train_a, trainpred))\n    print('Train RMSE score : %.4f'%rmse(train_a, trainpred))\n    if test is not None:\n        testpred = model.predict(test)\n        print('Test R2 score : %.4f'%r2_score(test_a, testpred))\n        print('Test RMSE score : %.4f'%rmse(test_a, testpred))\n        \ndef submission(model, name, test=test):\n    pred = model.predict(test)\n    sample['likes'] = pt_likes.inverse_transform(np.array(pred).reshape(-1,1))\n    sample.to_csv(name+'.csv', index=False)","0e52f959":"skew = ['views','dislikes','comment_count']\ndummy = ['category_id','country_code']\ndrop = ['video_id','publish_date','title','channel_title','tags','description']\npassthru = set(x_train.columns).difference(drop+dummy+skew)\nscaler = StandardScaler()\nlabel = OneHotEncoder(handle_unknown='ignore')\n#label = OrdinalEncoder()\n\npt = PowerTransformer(method='yeo-johnson')\n\ntransformer = [('skew', pt, skew),\n               ('onehot',label, dummy),\n               ('pass','drop',drop)]\n\nct_skew = ColumnTransformer(transformers=transformer)\n\nmodel_lr = LinearRegression(n_jobs=4)\nmodel_lasso = Lasso(random_state=1, alpha=0.003)","dc9b6298":"pipe_lr = Pipeline([('skew_treat', ct_skew),\n                    ('scaler', scaler),\n                    ('model', model_lasso)], verbose=1)\n\npipe_lr.fit(x_train, y_train)\nscore_metrics(pipe_lr, x_train, y_train, x_test, y_test)","3781bfb9":"submission(pipe_lr, 'model_lr')","b25cc9a6":"model_cat = CatBoostRegressor(random_state=1, verbose=0)\nmodel_lgbm = LGBMRegressor(n_jobs=4, random_state=1)\nmodel_xgb = XGBRegressor(n_jobs=4, random_state=1)\n\nmodels = []\nmodels.append(('LGBM', model_lgbm))\nmodels.append(('XGB', model_xgb))\nmodels.append(('CAT', model_cat))","1f438cb3":"for name, model in models:\n    pipe = Pipeline([('skew_treat', ct_skew),\n                     (name, model)], verbose=1)\n    pipe.fit(x_train, y_train)\n    score_metrics(pipe, x_train, y_train, x_test, y_test)","5b4b5e46":"cat_feature = ['category_id','country_code']\nignored = ['video_id','title','channel_title','publish_date','tags','description']\nmodel_cat = CatBoostRegressor(random_state=1, cat_features = cat_feature, verbose=0, one_hot_max_size=255,\n                             max_depth=10, learning_rate=0.08, n_estimators=1000 )\n\nmodel_cat.fit(x_train.drop(ignored, axis=1), y_train, plot=True, eval_set=(x_test.drop(ignored, axis=1), y_test))\n\nscore_metrics(model_cat, x_train.drop(ignored, axis=1), y_train, x_test.drop(ignored, axis=1), y_test)","e05cf5c3":"submission(model_cat, 'model_cat',\n           test=test.drop(columns=['video_id','title','channel_title','publish_date','tags','description']))","778489c7":"plt.figure(figsize=(16,5))\nplt.bar(model_cat.feature_names_, model_cat.feature_importances_)\nplt.xticks(rotation=90)\nplt.show()","9e0dad04":"from IPython.display import FileLink, FileLinks\nFileLink('.\/model_cat.csv')","f7eb19a0":"### How transforming the variables can have a huge impact on the model building","e1e13fdf":"## Utility Functions","47a3310f":"## Creating the model pipelines","d3b1eb86":"## Catboost seems to give us the best performance. Hence creating a submission using the default model","a63ae346":"## Performing 80\/20 split on the data","e58fac75":"## checking how the Linear Model performs to establish a Baseline","0663b139":"### Scatter plot Views vs Likes","2f21046e":"## This is only a starter version of my work on this dataset. Will keep on updating the notebook.\n### And dont forget to upvote my work if you like it. Check Here for more updates.","180b3cb1":"## Separating the X and Y","e1dde954":"## Trying out the Non-Linear Models"}}