{"cell_type":{"648e4f7b":"code","e0936909":"code","12d8cacd":"code","42e7b01f":"code","006469c2":"code","3493a3c2":"code","4d1c1570":"code","35124424":"code","3f2eb8ab":"code","1ab2ea66":"code","0691db77":"code","9e74da39":"code","c9850bfc":"code","04f0dc7a":"code","f2e9292d":"code","d6351e62":"code","75377f06":"code","90a1f1c8":"code","7e03210f":"code","875b8be3":"code","66dff0a2":"code","0a5df6cc":"code","0459d00c":"code","c6039cbd":"code","fe56385e":"code","580e2eaf":"code","f1702391":"code","df6c3522":"code","084e3dbf":"code","d4d40203":"code","bd307de3":"code","84c07dbc":"code","d2fe4277":"code","80abcc3d":"code","b0968916":"code","e4ef1967":"code","b7837d58":"markdown","02cfdbc3":"markdown","f6cda100":"markdown","87212dd4":"markdown","73167605":"markdown","aefc47bd":"markdown","2c495e86":"markdown","14ae36ab":"markdown","b4fdac40":"markdown","b0087218":"markdown","d7775dd9":"markdown","25f39810":"markdown","58bdfc50":"markdown","9d47adc9":"markdown","c4aa5ea7":"markdown","5c9eb05f":"markdown","34732812":"markdown","b90160e8":"markdown","05c49c46":"markdown","25008806":"markdown","9b955339":"markdown","9a24e44c":"markdown","4091f9c5":"markdown","dc14f7d2":"markdown","789df4d0":"markdown","18b2b0a4":"markdown","3e0fb15f":"markdown","2156dca1":"markdown","cdb5e59a":"markdown","340926ef":"markdown","ee2eed85":"markdown","5759e871":"markdown","042a596f":"markdown","9c917e8e":"markdown","05b3a8bd":"markdown","eb21b8fd":"markdown","d98e90d4":"markdown","72257a05":"markdown","5fd31f6c":"markdown","353ed609":"markdown","4a8cd38f":"markdown","78c5c5e0":"markdown"},"source":{"648e4f7b":"import pandas as pd\n\ndf = pd.read_csv('..\/input\/The_top-5000_frequent_Spanish_words_in_Twitter_for_331_cities_in_the_Spanish-speaking_world.csv')","e0936909":"df.head()","12d8cacd":"df.shape","42e7b01f":"df = pd.read_csv('..\/input\/The_top-5000_frequent_Spanish_words_in_Twitter_for_331_cities_in_the_Spanish-speaking_world_2.csv')","006469c2":"df.head()","3493a3c2":"from collections import Counter\n\ncnt = Counter()\n\nfor country in df['Country'].tolist():\n     cnt[country] += 1\n\nprint(cnt)","4d1c1570":"for item in list(zip(df['Country'],df['city_ascii'])):\n    print (item[0]+', '+item[1])","35124424":"import folium\n\nm = folium.Map(tiles= 'cartodbpositron')  \nm","3f2eb8ab":"cities = list(zip(df['city_ascii'],df['lat'],df['lng']))","1ab2ea66":"cities[0]","0691db77":"for city in cities:\n    folium.Marker(\n    popup=city[0],\n    location=[city[1],city[2]]\n    ).add_to(m)\nm","9e74da39":"df['lines']","c9850bfc":"from gensim import corpora\ndf['tokens'] = df['lines'].str.split(',')","04f0dc7a":"df['tokens']","f2e9292d":"dictionary = corpora.Dictionary(df['tokens'])","d6351e62":"print(dictionary)","75377f06":"df['bow'] = df['tokens'].apply(lambda x: dictionary.doc2bow(x))","90a1f1c8":"df['bow']","7e03210f":"from gensim import models\ntfidf = models.TfidfModel(df['bow']) ","875b8be3":"df['tfidf'] = df['bow'].apply(lambda x: tfidf[x]) ","66dff0a2":"df['tfidf']","0a5df6cc":"def get_top_tfidf(line,dictionary):\n    line = [(dictionary[a],b) for (a,b) in line]\n    line = [(float(b),a) for (a,b) in line]\n    line = list(sorted(line,reverse=True))[:10] \n    line = [b for (a,b) in line]\n    return line","0459d00c":"df['top_tfidf'] = df['tfidf'].apply(lambda line: get_top_tfidf(line,dictionary))","c6039cbd":"import random\nfor i in random.sample((list(zip(df['Country'],df['city_ascii'],df['top_tfidf']))),10):\n    print(i)","fe56385e":"lsi = models.LsiModel(df['tfidf'],num_topics=200)","580e2eaf":"from gensim import similarities\nindex = similarities.MatrixSimilarity(lsi[df['tfidf']]) ","f1702391":"query = 'Somos pac\u00edfico, estamos unidos Nos une la regi\u00f3n La pinta, la raza y el don del sabor Somos pac\u00edfico, estamos unidos Nos une la regi\u00f3n La pinta, la raza y el don del sabor  Ok! si por si acaso usted no conoce En el pac\u00edfico hay de todo para que goce Cantadores, colores, buenos sabores Y muchos santos para que adores Es toda una conexi\u00f3n Con un corrillo choc\u00f3, valle, cauca Y mis paisanos de nari\u00f1o Todo este repertorio me produce orgullo Y si somos tantos Porque estamos tan al cucho (en la esquina) Bueno, dejemos ese punto a un lado Hay gente trabajando pero son contados All\u00e1 rastrillan, hablan jerguiados Te preguntan si no has janguiado (hanging out) Si estas queda\u2019o Si lo has copiado, lo has vacilado Si dejaste al que est\u00e1 malo o te lo has rumbeado Hay mucha calentura en buenaventura Y si sos chocoano sos arrecho por cultura, ey!  Somos pac\u00edfico, estamos unidos Nos une la regi\u00f3n La pinta, la raza y el don del sabor Somos pac\u00edfico, estamos unidos Nos une la regi\u00f3n La pinta, la raza y el don del sabor Unidos por siempre, por la sangre, el color Y hasta por la tierra No hay quien se me pierda Con un v\u00ednculo familiar que aterra Caracter\u00edstico en muchos de nosotros Que nos reconozcan por la mam\u00e1 Y hasta por los rostros \u00c9tnicos, estilos que entre todos se ven La forma de caminar  El cabello y hasta por la piel Y dime qui\u00e9n me va a decir que no Escucho hablar de san pacho Mi patrono all\u00e1 en quibdo, ey! Donde se ven un pico y juran que fue un beso Donde el manjar al desayuno es el pl\u00e1tano con queso Y eso que no te he hablado de buenaventura Donde se baila el currulao, salsa poco pega\u2019o Puerto fiel al pescado Negras grandes con gran tumba\u2019o Donde se baila aguabajo y pasillo  En el lado del r\u00edo (ritmo folcl\u00f3rico) Con mis prietillos Somos pac\u00edfico, estamos unidos Nos une la regi\u00f3n La pinta, la raza y el don del sabor Somos pac\u00edfico, estamos unidos Nos une la regi\u00f3n La pinta, la raza y el don del sabor Es del pac\u00edfico, guapi, timbiqu\u00ed, tumaco El bordo cauca Seguimos aqu\u00ed con la herencia africana M\u00e1s fuerte que antes Llevando el legado a todas partes De forma constante Expres\u00e1ndonos a trav\u00e9s de lo cultural M\u00fasica, artes pl\u00e1stica, danza en general Acento golpia\u2019o al hablar El 1, 2,3 al bailar Despu\u00e9s de eso seguro hay much\u00edsimo m\u00e1s Este es pac\u00edfico colombiano Una raza un sector Lleno de hermanas y hermanos Con nuestra b\u00e1mbara y con el cach\u00e9 (bendici\u00f3n, buen esp\u00edritu) Venga y lo ve usted mismo Pa v\u00e9 como es, y eh! Piense en lo que se puede perder, y eh! Pura calentura y yenyer\u00e9, y eh!'.split()","df6c3522":"query_bow = dictionary.doc2bow(query)","084e3dbf":"query_bow","d4d40203":"query_lsi = lsi[query_bow] ","bd307de3":"sim_scores = index[query_lsi]","84c07dbc":"df['sim_score'] = sim_scores","d2fe4277":"df = df.dropna()","80abcc3d":"df = df.sort_values(by=['sim_score'], ascending=False)[:10]","b0968916":"similar_cities = list(zip(df['Country'],df['city_ascii'],df['lat'],df['lng'],df['sim_score']))\nfor city in similar_cities:\n    print(city)","e4ef1967":"m = folium.Map(tiles= 'cartodbpositron')  \n\nfor city in similar_cities:\n    folium.Marker(\n    popup=city[0],\n    location=[city[2],city[3]]\n    ).add_to(m)\n\nm.fit_bounds(m.get_bounds())\n\nm","b7837d58":"Let's see all the cities included in the data set","02cfdbc3":"By calling \"print\" on the dictionary, we see that we have 62314 unique tokens:","f6cda100":"If you have inspected the data set, you see that we have all the country words in one column, joined by a comma (,). Let's create a new column and split this \"lines\" into tokens.","87212dd4":"Let's apply this transformation to our bag of words column and create a new tfidf column","73167605":"We need to convert our query to the same vector space of our indexed corpus. First, let's transform it to bag of words:","aefc47bd":"# Let's dive into text processing","2c495e86":"Let's create a dictionary, with all the *unique* tokens. ","14ae36ab":"Now, let's transform it to lsi:","b4fdac40":"Let's finally see which cities are the most similar to our query!","b0087218":"Let's see the first element:","d7775dd9":"Great! We have 19 countries and we can see how many cities are included for each country. Mexico has the greater number of cities in this dataset, with 74 cities, while Cuba has just one city. Let's keep this in mind and let's go on.","25f39810":"By querying the shape, we see that the data set has 5000 rows and 585 columns. ","58bdfc50":"Now, our goal is to find more relationships between words, to find the most typical words of each city and to find similarities between them. In order to accomplish that, we need to transform our Bag of Words into a different representation.","9d47adc9":"Let's sort our dataframe by similarity score and keep the top 10 cities","c4aa5ea7":"The dataset is a .csv file. We are going to read it using [Pandas](https:\/\/pandas.pydata.org\/), a great Python library for data analysis. ","5c9eb05f":"Here, we see that the columns correspond to the cities: we have one column for the words and one column for the word frequency of each city's words. \n\n","34732812":"Let's add information to our map. We are going to zip 3 columns from our dataframe: `city_ascii`, (the city name), `lat` and `lng` (the latitude and longitude of each city)","b90160e8":"How many countries and cities are included in the dataset? Let's find out:","05c49c46":"Although this is a dataset about cities, it does not contain geographical information, such as the location of the cities. \n\nBy consulting other datasets and also by looking up manually the latitude and longitude of the cities, I enhanced the dataset with geographical information. You can download the enhanced dataset [here](https:\/\/drive.google.com\/file\/d\/1gHd6N12E1YqS4GMG8HbLFYQsUfGVVXpq\/view?usp=sharing). ","25008806":"This is nice! Our similarity model detected correctly that our query (a rap song from Colombia) is indeed from Colombia! We got a list with the most similar cities and their similarity scores","9b955339":"Nice! We get a glance at all the cities included in our dataset! Click on the markers to see the city's name. \n\nSpain and its islands are included and allmost all of the Latinamerican countries. We have even Spanish speaking cities from the United States. The dataset does not include information about Venezuela and Uruguay, though. ","9a24e44c":"In this notebook, we are going to explore a Spanish language dataset and do many interesting things with it. \n\nWhen [Google Dataset Search](https:\/\/toolbox.google.com\/datasetsearch\/search?query=spanish%20twitter&docid=KjIKji0L9hTF2vQAAAAAAA%3D%3D) came out, I started looking for datasets in Spanish, to practice programming and data analysis. I found a Twitter dataset and started working with it. \n\nThis dataset is great. It contains the top 5000 frequent Spanish words in Twitter for hundreds of cities in the Spanish-speaking world! \n\nIt was created by the [Instituto Caro y Cuervo](https:\/\/www.caroycuervo.gov.co\/), (a linguistics Institute from Colombia) and made available at the [Open Data Website](https:\/\/www.datos.gov.co\/) of the Colombian Government.\n\nAccording to them, \n\n> More than *250 million tweets* in Spanish from 331 Spanish-speaking cities in Latin America, Spain and the United States were compiled from Twitter. The reported data correspond to the years 2009 to 2016.\n\n","4091f9c5":"In order to analyze the words, we need to convert them to vectors. ","dc14f7d2":"Let's use the lyrics of a Colombian rap group as a query example:","789df4d0":"At this point, we could also visualize the cities in the dataset on a map. We will use [Folium](https:\/\/github.com\/python-visualization\/folium), a flexible Python library that allows us to make maps easily.","18b2b0a4":"Ok, let's get to work. First, let's download the dataset at https:\/\/www.datos.gov.co\/Ciencia-Tecnolog-a-e-Innovaci-n\/The-top-5000-frequent-Spanish-words-in-Twitter-for\/nmid-inr9. ","3e0fb15f":"# Query","2156dca1":"> From now on, tfidf is treated as a read-only object that can be used to convert any vector from the old representation (bag-of-words integer counts) to the new representation (TfIdf real-valued weights):","cdb5e59a":"Now, we can add all the cities to our map. We pass the latitude and longitude (`city[1]` and `city[2]` to `location`. We also pass the city name (`city[0]`) to the `popup`, to display the city's name on the Marker. ","340926ef":"One of the first things we can do is call `head()` to see the first rows. Let's inspect the dataset.","ee2eed85":"To prepare for similarity queries, we need to enter all documents which we want to compare against subsequent queries:","5759e871":"Finally, let's see the results on our map:","042a596f":"# BOW \n(Bag of words)\n\n![alt text](https:\/\/cdn-images-1.medium.com\/max\/800\/0*JpqZhCNsQ_OGaRkB.jpg \"Bag of words\")\n\n\nLet's follow Gensim's first tutorial, \"Corpora and Vector Spaces\":\n\n> To convert documents to vectors, we\u2019ll use a document representation called bag-of-words. In this representation, each document is represented by one vector\n\nLet's take the word \"caf\u00e9\". Let\u00b4s assign it the id number 0 and let's say it appears 2 times. \n\nThe resulting vector will look like this: `(0, 2)`","9c917e8e":"# LOGEO ","05b3a8bd":"Latent Semantic Indexing, LSI (or sometimes LSA) transforms documents from either bag-of-words or (preferrably) TfIdf-weighted space into a latent space of a lower dimensionality. Let's transform our tf-idf vectors into LSI vectors:","eb21b8fd":"Now, let's convert all our tokens to vectors, with the function `doc2bow`:","d98e90d4":"#  Similarity\nA common reason for this transformations is to determine similarity between pairs of documents, or the similarity between a specific document and a set of other documents (such as a user query vs. indexed documents).","72257a05":"Let's find out the similarity scores of this query against all our cities in the corpus:","5fd31f6c":"Let's put aside the map for now and let's analyze the words. We are going to use [Gensim](https:\/\/radimrehurek.com\/gensim\/), a Python library for Natural Language Processing.","353ed609":"If you want to try your own query, you can do it at LOGEO's website www.moorelanguage.com Try it out and share your results!","4a8cd38f":"# TF\/IDF\n\nWhat is tf\/idf? \n\n> TF = term frequency. IDF = inverse document frequency. Numerical statistic that reflects how important a word is to a document in a collection or corpus. We can calculate this value by dividing the number of times a term occurs in a document by the number of documents in which the word appears.\n\n>The tf\u2013idf value increases proportionally to the number of times a word appears in the document and is offset by the number of documents in the corpus that contain the word, which helps to adjust for the fact that some words appear more frequently in general. \n","78c5c5e0":"### Exploring the top 5,000 words from hundreds of Spanish speaking cities"}}