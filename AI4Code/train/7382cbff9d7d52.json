{"cell_type":{"243e3c75":"code","def4129f":"code","fec11d10":"code","8153cbfc":"code","2adab658":"code","490aa37b":"code","dad331aa":"code","224ac67f":"code","1187eae2":"code","5c60bc3e":"code","9aaa95d1":"code","09b1279c":"code","927646a3":"code","b3b51a95":"code","923b291b":"code","04c8148b":"code","1c5706d7":"code","7f5a9db0":"code","542578da":"code","37f34d7c":"code","73076a9f":"code","a7eeb6cb":"markdown","bfec770f":"markdown","d7849285":"markdown","0ec2efaa":"markdown","cb70d9b3":"markdown","5981df2d":"markdown","0995c464":"markdown","45c2e14a":"markdown","6adefeb2":"markdown","f70f50a7":"markdown"},"source":{"243e3c75":"import re\nimport numpy as np \nimport pandas as pd\nimport random\nimport math\nimport cv2 \nimport seaborn as sns\nfrom glob import glob\nimport os\nimport itertools\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D,MaxPool2D ,UpSampling2D, Flatten, Input,LeakyReLU,BatchNormalization,Dropout\nfrom tensorflow.nn import atrous_conv2d\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint, ReduceLROnPlateau, CSVLogger\nimport matplotlib.pyplot as plt\nfrom skimage.util import random_noise\nfrom skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim,mean_squared_error as mse\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\nplt.rcParams['image.interpolation'] = 'nearest'\nplt.rcParams['image.cmap'] = 'gray'","def4129f":"path = '..\/input\/breast-ultrasound-images-dataset\/Dataset_BUSI_with_GT\/*\/*.png' \nimages = glob(path)\nimages.sort()","fec11d10":"#creating dictionary of images and masks\nimage = []\nmask = []\ncount = 1\ni= 0\nnum = len(images)\nimages_per_class = {}\nwhile i < num-1:\n    print(str(count) + \"\/\" + str(num), end=\"\\r\")\n    img = images[i]\n    label = img.split('\/')[-2] #get label from image name\n    image_name = img.split('\/')[-1].split(')')[0] #get image name\n    if label not in images_per_class.keys():\n        images_per_class[label] = {'image':[],'mask':[]} #make nested dictionory for each label\n    \n    \n    if img.split('\/')[-1][-5] == ')': #get the image\n        image = cv2.resize(cv2.imread(img,cv2.IMREAD_GRAYSCALE),(128,128)) #read image\n        images_per_class[label]['image'].append(image)\n        mylist = images[i:]\n        r = re.compile(r\".*\"+re.escape(image_name)+r\"\\)_mask*.\") #look for mask\n        masklist = list(filter(r.match, mylist))\n        if len(masklist) == 1:\n            mask = cv2.resize(cv2.imread(masklist[0]),(128,128))            \n            images_per_class[label]['mask'].append(mask)\n        else:  #there are two masks\n            mask_1 = cv2.imread(masklist[0])\n            mask_2 = cv2.imread(masklist[1])\n            mask = cv2.resize(cv2.bitwise_or(mask_1,mask_2),(128,128))            \n            images_per_class[label]['mask'].append(mask)      \n        \n    i+=1 \n    \n    count += 1","8153cbfc":"#Number of images per class\nlabels = []\nfor key,value in images_per_class.items():\n    for k,v in value.items():\n        labels.extend([k]*len(v))\n        print(\"{0} : {1} : {2} \".format(key,k, len(v)))","2adab658":"fig,ax = plt.subplots(1,2)\nax[0].imshow(images_per_class['benign']['image'][100])\nax[0].set_title('Image')\nax[1].imshow(images_per_class['benign']['mask'][100])\nax[1].set_title('Mask')","490aa37b":"#dataset for denoising consists of only images\ndataset = images_per_class['benign']['image'] + images_per_class['malignant']['image'] + images_per_class['normal']['image']","dad331aa":"#normalizing pixel values in the dataset\ndataset = [img\/255 for img in dataset] #for faster computation\nrandom.shuffle(dataset)","224ac67f":"#Plotting set of images\ndef plot_images(dataset):\n  fig,ax=plt.subplots(1,5)\n  fig.set_size_inches(40,20)\n  for i in range(5,10):\n    ax[i-5].imshow(dataset[i], cmap='gray')\n  plt.show()","1187eae2":"noised_dataset=[]\nfor img in dataset:\n  noisy=random_noise(img,mode = 'speckle') #introducing speckle noise\n  noised_dataset.append(noisy)\n\nnoised_dataset=np.array(noised_dataset)","5c60bc3e":"plot_images(dataset)","9aaa95d1":"plot_images(noised_dataset)","09b1279c":"#Splitting dataset for training and testing\nx_train = noised_dataset[:500]\nx_train_clean = dataset[:500]\nx_test=noised_dataset[500:]\nx_test_clean = dataset[500:]","927646a3":"def denoising_autoencoder():\n    i=Input(shape=(128,128,1))\n    #encoder \n    x = Conv2D(128, (3,3), activation='relu', padding='same')(i)\n    x = MaxPooling2D((2,2), padding='same')(x)\n    x = Conv2D(128, (3,3), activation='relu', padding='same')(x)\n    x = MaxPooling2D((2,2), padding='same')(x)\n    x = Conv2D(128, (3,3), activation='relu', padding='same')(x)\n    x = Conv2D(128, (3,3), activation='relu', padding='same')(x)\n\n    #decoder\n    x = Conv2D(128, (3,3), activation='relu', padding='same')(x)\n    x = Conv2D(128, (3,3), activation='relu', padding='same')(x)\n    x = UpSampling2D((2,2))(x)\n    x = Conv2D(128, (3,3), activation='relu', padding='same')(x)\n    x = UpSampling2D((2,2))(x)\n    x = Conv2D(1, (3,3), activation='sigmoid', padding='same')(x)\n\n    #model\n    autoencoder = Model(inputs=i, outputs=x)\n    autoencoder.compile(optimizer='Adam', loss='mse')\n    autoencoder.summary()\n\n    return autoencoder\n","b3b51a95":"autoencoder = denoising_autoencoder()","923b291b":"epochnum = 300\nbatchnum = 64\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n                                            patience=8, \n                                            verbose=1, \n                                            factor=0.8, \n                                            min_lr=1e-10)\nr = autoencoder.fit(x_train, x_train,\n                epochs=epochnum,\n                batch_size=batchnum,\n                shuffle=True,\n                validation_data=(x_test, x_test),\n                callbacks=[learning_rate_reduction],verbose=0)\n#model evaluation\nprint(\"Train score:\", autoencoder.evaluate(x_train,x_train))\nprint(\"Test score:\", autoencoder.evaluate(x_test,x_test))","04c8148b":"pred= autoencoder.predict(x_test[:5])","1c5706d7":"image_dict = {0 :x_test_clean,1:x_test,2:pred}\ntitle = ['Original images','Images corrupted with speckle noise','Denoised images using autoencoder']\n\nfig, axs = plt.subplots(nrows=3, ncols=1, figsize = (25,15),constrained_layout=True)\nfig.suptitle('Noisy vs Denoised Images',fontsize = 20)\n\n# clear subplots\nfor ax in axs:\n    ax.remove()\n\n# add subfigure per subplot\ngridspec = axs[0].get_subplotspec().get_gridspec()\nsubfigs = [fig.add_subfigure(gs) for gs in gridspec]\n\nfor row, subfig in enumerate(subfigs):\n    subfig.suptitle(title[row],fontsize=15)\n\n    # create 1x3 subplots per subfig\n    axs = subfig.subplots(nrows=1, ncols=5)\n    for col, ax in enumerate(axs):\n        ax.imshow(image_dict[row][col], aspect='auto', cmap='gray')","7f5a9db0":"median_blur = cv2.medianBlur(np.float32(x_test[0]), (5))\ngaussian_blur=cv2.GaussianBlur(x_test[0],(5,5),0)\naverage_blur=cv2.blur(x_test[0],(5,5))\nbilateral_filter=cv2.bilateralFilter(np.float32(x_test[0]),9,75,75)\nf,ax=plt.subplots(1,5)\nf.set_size_inches(40,20)\nax[0].imshow(pred[0], cmap='gray')\nax[0].set_title('Autoencoder Image',fontsize = 15)\nax[1].imshow(median_blur,cmap='gray')\nax[1].set_title('Median Filter',fontsize = 15)\nax[2].imshow(gaussian_blur,cmap='gray')\nax[2].set_title('Gaussian Filter')\nax[3].imshow(average_blur,cmap='gray')\nax[3].set_title('Average Filter',fontsize = 15)\nax[4].imshow(bilateral_filter,cmap='gray')\nax[4].set_title('Bilateral Filter',fontsize = 15)\nplt.show()","542578da":"def plotLearningCurve(history,epochnum,batchnum):\n  epochRange = range(1,epochnum+1)\n  plt.figure(figsize = (5,5))\n  plt.plot(epochRange,history.history['loss'],'b',label = 'Training Loss')\n  plt.plot(epochRange,history.history['val_loss'],'r',label = 'Validation Loss')\n  plt.xlabel('Epoch', fontsize = 15)\n  plt.ylabel('Loss', fontsize = 15)\n  plt.grid(color='gray', linestyle='--')\n  plt.legend()\n  plt.title('LOSS, Epochs={}, Batch={}'.format(epochnum, batchnum))\n  plt.show()","37f34d7c":"plotLearningCurve(r,epochnum,batchnum)","73076a9f":"value1 = psnr(x_test[0], pred[0].reshape(x_test_clean[0].shape[0],-1))\nvalue2 = psnr(x_test[0], median_blur)\nvalue3 = psnr(x_test[0], gaussian_blur)\nvalue4 = psnr(x_test[0], average_blur)\nvalue5 = psnr(x_test[0], bilateral_filter)\nmetric = pd.DataFrame({'Autoencoder':value1,'Median Blur':value2,'Gaussian Blur':value3,'Average Blur':value4,'Bilateral Filter':value5},index = ['PSNR'])\nvalue1 = mse(x_test[0], pred[0].reshape(x_test_clean[0].shape[0],-1))\nvalue2 = mse(x_test[0], median_blur)\nvalue3 = mse(x_test[0], gaussian_blur)\nvalue4 = mse(x_test[0], average_blur)\nvalue5 = mse(x_test[0], bilateral_filter)\nmetric.loc['MSE'] = [value1,value2,value3,value4,value5]\nvalue1 = ssim(x_test[0], pred[0].reshape(x_test_clean[0].shape[0],-1))\nvalue2 = ssim(x_test[0], median_blur)\nvalue3 = ssim(x_test[0], gaussian_blur)\nvalue4 = ssim(x_test[0], average_blur)\nvalue5 = ssim(x_test[0], bilateral_filter)\nmetric.loc['SSIM'] = [value1,value2,value3,value4,value5]\nmetric\n","a7eeb6cb":"**Comment** <br> \nNumber of images for image and its masks are different for benign and malignant images. Some images have two masks.","bfec770f":"### Creating dataset","d7849285":"# **2. Importing and preprocessing dataset**","0ec2efaa":"# **1. Importing Libraries**","cb70d9b3":"### Building model architecture","5981df2d":"### Training the  model","0995c464":"# **3. Denoising Ultrasound Images**","45c2e14a":"### Metric Evaluation","6adefeb2":"### Get prediction","f70f50a7":"### Dataset Description\nBreast cancer is one of the most common causes of death among women worldwide. Early detection helps in reducing the number of early deaths. The data reviews the medical images of breast cancer using ultrasound scan. Breast Ultrasound Dataset is categorized into three classes: normal, benign, and malignant images. Breast ultrasound images can produce great results in classification, detection, and segmentation of breast cancer when combined with machine learning.\n\nThe data collected at baseline include breast ultrasound images among women in ages between 25 and 75 years old. This data was collected in 2018. The number of patients is 600 female patients. The dataset consists of 780 images with an average image size of 500*500 pixels. The images are in PNG format. The ground truth images are presented with original images. The images are categorized into three classes, which are normal, benign, and malignant.\n\n### Project overview\nSpeckle noise is a multiplicative noise that degrades the visual quality of ultrasound images and affects the clinical assessment. Denoising speckle is a very fundamental challenge in the field of Ultrasound imaging as it affects the clinical assessment. In this project, convolutional autoencoders are used to denoise speckle from breast ultrasound images. The results show that the under proper hyperparameter optimization implemented autoencoder performs significantly better than other traditional filters used for denoising.\n"}}