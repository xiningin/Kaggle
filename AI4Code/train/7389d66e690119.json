{"cell_type":{"92852d22":"code","2501ec59":"code","e17c71e9":"code","fabf64d0":"code","6c1dab05":"code","7c7a27ec":"code","d128e700":"code","0d3a204a":"code","1cb42ec6":"code","b6d4438c":"code","006ab95d":"code","65c40fa0":"code","94ceb897":"code","1215eeb1":"code","67d2ed30":"code","eee34f7d":"code","0a987c58":"code","42c5ecd4":"code","24313b2a":"code","bb595c81":"code","f7840c0d":"code","717f501b":"code","0b1dc3a3":"code","6960f2d6":"code","637d3d38":"code","a04e3b48":"code","3d454ba0":"code","0fea55a8":"code","5d51df01":"code","762b4e28":"code","18083d82":"code","56dacb06":"code","8b9b08e5":"code","2db952ed":"code","b1466fe3":"code","c441fcd3":"code","2d0918cf":"code","fb716fd3":"code","160d3b9f":"code","39290a09":"code","3298477c":"code","1e7060d3":"code","e433e31c":"code","d576bf64":"code","dd4c0e8e":"code","d8a01543":"code","7b6bec5d":"markdown","2a603ac3":"markdown","27ad2b40":"markdown","1bbeeb63":"markdown","1ec0fcad":"markdown","07257a44":"markdown","a697c214":"markdown","53e8e6a5":"markdown","606bc987":"markdown","ee3e0948":"markdown","e8f71378":"markdown","49aec09c":"markdown","fa2d4fc6":"markdown","7aa0cd57":"markdown","04d0f727":"markdown","f68c2359":"markdown","d1bee65b":"markdown","c9a92756":"markdown","24d15910":"markdown","bf676427":"markdown","7404a500":"markdown","bb015152":"markdown"},"source":{"92852d22":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","2501ec59":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom warnings import filterwarnings\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.impute import SimpleImputer\nfrom scipy.stats import norm\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nimport lightgbm as lgb","e17c71e9":"pd.options.mode.chained_assignment = None ","fabf64d0":"train_df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\nX_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","6c1dab05":"train_df.head()","7c7a27ec":"train_df.info()","d128e700":"# includes creating a new feature \"family size\" and dropping useless columns\n\ndef preprocessor(df):\n    df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n    df['Family size'] = df['SibSp']+df['Parch']+1\n    df.drop(['Parch', 'SibSp'], axis=1, inplace=True)\n\n    return df","0d3a204a":"preprocessor(train_df)","1cb42ec6":"# some barplots to see how the dataset looks like\n\ndef bar_visualizer(df):\n    plot = sns.barplot(x=df[df.columns[0]],\n                       y=df[df.columns[1]], palette='muted')\n    for bar in plot.patches:\n        plot.annotate(format(bar.get_height(), 'g'),\n                      (bar.get_x() + bar.get_width() \/ 2,\n                       bar.get_height()), ha='center', va='center',\n                      size=12, xytext=(0, 4),\n                      textcoords='offset points')","b6d4438c":"temp = train_df[['Sex', 'Survived']].groupby(\n    'Sex', as_index=False)['Survived'].sum()","006ab95d":"bar_visualizer(temp)","65c40fa0":"temp = train_df[['Pclass', 'Survived']].groupby(\n    'Pclass', as_index=False)['Survived'].sum()\ntemp","94ceb897":"bar_visualizer(temp)","1215eeb1":"temp = train_df[['Embarked', 'Survived']].groupby(\n    'Embarked', as_index=False)['Survived'].sum()","67d2ed30":"bar_visualizer(temp)","eee34f7d":"temp = train_df[['Survived', 'Family size']].groupby(\n    'Family size', as_index=False)['Survived'].sum()","0a987c58":"bar_visualizer(temp)","42c5ecd4":"temp = train_df[['Survived', 'Age']].groupby(\n    'Survived', as_index=False)['Age'].mean()\ntemp","24313b2a":"bar_visualizer(temp)","bb595c81":"train_df.isna().sum()","f7840c0d":"# there are just two of missing values in this column, we can easily drop them.\n\ntrain_df.dropna(subset=['Embarked'], inplace=True)","717f501b":"le = LabelEncoder()\nfor col in ['Embarked', 'Sex']:\n    train_df[col] = le.fit_transform(train_df[col])","0b1dc3a3":"sns.heatmap(train_df.corr(), cmap='Greys', annot=True)","6960f2d6":"X = train_df.drop('Survived', axis=1)\ny = train_df['Survived']\nX","637d3d38":"X_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.2, random_state=42)","a04e3b48":"X_train","3d454ba0":"# replacing NaNs in age column by mean value of this column\n\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nX_train[['Age']] = imputer.fit(X_train[['Age']]).transform(X_train[['Age']])","0fea55a8":"# replacing NaNs in age column by mean value of this column\n\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nX_val[['Age']] = imputer.fit(X_val[['Age']]).transform(X_val[['Age']])","5d51df01":"classifier = DecisionTreeClassifier(random_state=42)\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_val)","762b4e28":"print(accuracy_score(y_val, y_pred))","18083d82":"classifier = RandomForestClassifier(random_state=42)\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_val)","56dacb06":"print(accuracy_score(y_pred, y_val))","8b9b08e5":"classifier = KNeighborsClassifier(n_neighbors=7)\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_val)","2db952ed":"print(accuracy_score(y_val, y_pred))","b1466fe3":"classifier = SVC()\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_val)","c441fcd3":"print(accuracy_score(y_val, y_pred))","2d0918cf":"classifier = LogisticRegression()\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_val)","fb716fd3":"print(accuracy_score(y_val, y_pred))","160d3b9f":"# classification report of logistic regression model\n\nprint(classification_report(y_val, y_pred))","39290a09":"cm = confusion_matrix(y_val, y_pred)\ncm","3298477c":"X_test = preprocessor(X_test)","1e7060d3":"le = LabelEncoder()\nfor col in ['Embarked', 'Sex']:\n    X_test[col] = le.fit_transform(X_test[col])","e433e31c":"X_test.isna().sum()","d576bf64":"X_test[['Age']] = imputer.fit(X_test[['Age']]).transform(X_test[['Age']])\nX_test[['Fare']] = imputer.fit(X_test[['Fare']]).transform(X_test[['Fare']])","dd4c0e8e":"y_pred = classifier.predict(X_test)","d8a01543":"y_pred","7b6bec5d":"## Confusion matrix","2a603ac3":"## Checking missing values","27ad2b40":"## Predicting results for the test set","1bbeeb63":"## Train and Validation split","1ec0fcad":"### Train set","07257a44":"### KNN","a697c214":"### Data correlation","53e8e6a5":"### Logistic Regression","606bc987":"## Taking care of missing values","ee3e0948":"## Loading datasets","e8f71378":"Sex: 1 male, 0 female <br>\nEmbarked: 2 S, 0 C, 1 Q","49aec09c":"### Logistic Regression","fa2d4fc6":"### SVM","7aa0cd57":"### Decision Tree","04d0f727":"## Training a model","f68c2359":"### Random Forest","d1bee65b":"## Some info about the dataset","c9a92756":"## Classification report","24d15910":"### Label encoder","bf676427":"## Preparing the test set","7404a500":"### Label encoder","bb015152":"### Validation set"}}