{"cell_type":{"fd0f0991":"code","be9bc5cd":"code","cea35bbd":"code","6428d1b0":"code","160b7541":"code","838bc91c":"code","8246c873":"code","3c3b193f":"code","dbda2a10":"code","e5d6d413":"code","d8d50706":"code","117aa63e":"code","f0a57bec":"code","791224b2":"code","2fe181d6":"code","46399df8":"code","fa77a66b":"code","657072ff":"code","ae7fdc4d":"code","50bbafea":"code","149432d8":"code","cd2f3739":"code","681af6bf":"code","9eae40c2":"code","34615088":"code","699d07db":"markdown","14fb3c2a":"markdown","4795ed29":"markdown","eeaee3be":"markdown"},"source":{"fd0f0991":"# Reading the cleaned numeric car prices data\nimport pandas as pd\nimport numpy as np\n\n# To remove the scientific notation from numpy arrays\nnp.set_printoptions(suppress=True)\n\nTitanicSurvivalDataNumeric=pd.read_pickle('..\/input\/titanic-survival-ann\/TitanicSurvivalDataNumeric.pkl')\nTitanicSurvivalDataNumeric.head()","be9bc5cd":"TitanicSurvivalDataNumeric.columns","cea35bbd":"# After Standardization of data\n# Separate Target Variable and Predictor Variables\nTargetVariable=['Survived']\nPredictors=['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n       'Embarked_C', 'Embarked_Q', 'Embarked_S']\n\nX=TitanicSurvivalDataNumeric[Predictors].values\ny=TitanicSurvivalDataNumeric[TargetVariable].values\n\n\n### Sandardization of data ###\n### We does not standardize the Target variable for classification\nfrom sklearn.preprocessing import StandardScaler\nPredictorScaler=StandardScaler()\n\n# Storing the fit object for later reference\nPredictorScalerFit=PredictorScaler.fit(X)\n\n# Generating the standardized values of X and y\nX=PredictorScalerFit.transform(X)\n\n# Split the data into training and testing set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","6428d1b0":"# Quick sanity check with the shapes of Training and testing datasets\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","160b7541":"# Standardized predictors\nX[0:3]","838bc91c":"# Inverse transform will take the data back to original form\nPredictorScalerFit.inverse_transform(X)[0:3]","8246c873":"y[0:5]","3c3b193f":"from keras.models import Sequential\nfrom keras.layers import Dense","dbda2a10":"classifier = Sequential()\n# Defining the Input layer and FIRST hidden layer\n# relu means Rectifier linear unit function\nclassifier.add(Dense(units=10, input_dim=9, kernel_initializer='uniform', activation='relu'))\n\n#Defining the SECOND hidden layer, here we have not defined input because it is\n# second layer and it will get input as the output of first hidden layer\nclassifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu'))\n\n# Defining the Output layer\n# sigmoid means sigmoid activation function\n# for Multiclass classification the activation ='softmax'\n# And output_dim will be equal to the number of factor levels\nclassifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n\n# Optimizer== the algorithm of SGG to keep updating weights\n# loss== the loss function to measure the accuracy\n# metrics== the way we will compare the accuracy after each step of SGD\nclassifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","e5d6d413":"# fitting the Neural Network on the training data\nsurvivalANN_Model=classifier.fit(X_train,y_train, batch_size=10 , epochs=10, verbose=1)","d8d50706":"# Training data Accuracy of the model is the the accuracy achieved in the last epoch\nsurvivalANN_Model.history['accuracy'][-1]","117aa63e":"def FunctionFindBestParams(X_train, y_train):\n    \n    \n    # Defining the list of hyper parameters to try\n    TrialNumber=0\n    batch_size_list=[5, 10, 15, 20]\n    epoch_list  =   [5, 10, 50 ,100]\n    \n    import pandas as pd\n    SearchResultsData=pd.DataFrame(columns=['TrialNumber', 'Parameters', 'Accuracy'])\n    \n    for batch_size_trial in batch_size_list:\n        for epochs_trial in epoch_list:\n            TrialNumber+=1\n            \n            # Creating the classifier ANN model\n            classifier = Sequential()\n            classifier.add(Dense(units=10, input_dim=9, kernel_initializer='uniform', activation='relu'))\n            classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu'))\n            classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n            classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n            \n            survivalANN_Model=classifier.fit(X_train,y_train, batch_size=batch_size_trial , epochs=epochs_trial, verbose=0)\n            Accuracy = survivalANN_Model.history['accuracy'][-1]\n            \n            # printing the results of the current iteration\n            print(TrialNumber, 'Parameters:','batch_size:', batch_size_trial,'-', 'epochs:',epochs_trial, 'Accuracy:', Accuracy)\n            \n            SearchResultsData=SearchResultsData.append(pd.DataFrame(data=[[TrialNumber,\n                            'batch_size'+str(batch_size_trial)+'-'+'epoch'+str(epochs_trial), Accuracy]],\n                                                                    columns=['TrialNumber', 'Parameters', 'Accuracy'] ))\n    return(SearchResultsData)","f0a57bec":"# Calling the function\nResultsData=FunctionFindBestParams(X_train, y_train)","791224b2":"%matplotlib inline\nResultsData.plot(x='Parameters', y='Accuracy', figsize=(15,4), kind='line', rot=20)","2fe181d6":"# Printing the best parameter\nResultsData.sort_values(by='Accuracy', ascending=False).head(1)","46399df8":"classifier.fit(X_train,y_train, batch_size=10 , epochs=100, verbose=1)","fa77a66b":"# Predictions on testing data\nPredictions=classifier.predict(X_test)\n\n# Scaling the test data back to original scale\nTest_Data=PredictorScalerFit.inverse_transform(X_test)\n\n# Generating a data frame for analyzing the test data\nTestingData=pd.DataFrame(data=Test_Data, columns=Predictors)\nTestingData['Survival']=y_test\nTestingData['PredictedSurvivalProb']=Predictions\n\ndef probThreshold(inpProb):\n    if inpProb>0.3:\n        return(1)\n    else:\n        return(0)\n\nTestingData['PredictedSurvival']=TestingData['PredictedSurvivalProb'].apply(probThreshold)\nTestingData.head()","657072ff":"# Comparing a sample row from original data to confirm if the reverse transform has happend correctly\nTitanicSurvivalDataNumeric[(TitanicSurvivalDataNumeric['Fare']==11.2417) & (TitanicSurvivalDataNumeric['Age']==14)]","ae7fdc4d":"from sklearn import metrics\nprint(metrics.classification_report(TestingData['Survival'], TestingData['PredictedSurvival']))\nprint(metrics.confusion_matrix(TestingData['Survival'], TestingData['PredictedSurvival']))","50bbafea":"# Function to generate Deep ANN model \ndef make_classification_ann(Optimizer_Trial, Neurons_Trial):\n    from keras.models import Sequential\n    from keras.layers import Dense\n    \n    # Creating the classifier ANN model\n    classifier = Sequential()\n    classifier.add(Dense(units=Neurons_Trial, input_dim=9, kernel_initializer='uniform', activation='relu'))\n    classifier.add(Dense(units=Neurons_Trial, kernel_initializer='uniform', activation='relu'))\n    classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n    classifier.compile(optimizer=Optimizer_Trial, loss='binary_crossentropy', metrics=['accuracy'])\n            \n    return classifier","149432d8":"from sklearn.model_selection import GridSearchCV\nfrom keras.wrappers.scikit_learn import KerasClassifier\n\n\nParameter_Trials={'batch_size':[10,20,30],\n                      'epochs':[10,20],\n                    'Optimizer_Trial':['adam', 'rmsprop'],\n                  'Neurons_Trial': [5,10]\n                 }\n\n\nclassifierModel=KerasClassifier(make_classification_ann, verbose=0)","cd2f3739":"# Creating the Grid search space\n# See different scoring methods by using sklearn.metrics.SCORERS.keys()\ngrid_search=GridSearchCV(estimator=classifierModel, param_grid=Parameter_Trials, scoring='f1', cv=5)","681af6bf":"# Measuring how much time it took to find the best params\nimport time\nStartTime=time.time()\n\n# Running Grid Search for different paramenters\ngrid_search.fit(X_train,y_train, verbose=1)\n\nEndTime=time.time()\nprint(\"############### Total Time Taken: \", round((EndTime-StartTime)\/60), 'Minutes #############')","9eae40c2":"grid_search.best_params_","34615088":"grid_search.best_score_","699d07db":"# Finding best set of parameters using grid search","14fb3c2a":"# Training the model using best parameters","4795ed29":"# Classification using Deep Learning- Artificial Neural Networks(ANN)","eeaee3be":"# Sklearn GridSearchCV"}}