{"cell_type":{"033a2203":"code","93e34f92":"code","6217a40c":"code","692068f4":"code","7dfdb953":"code","c8aa80cd":"code","f27fc4e3":"code","7d6c1626":"code","88763a6f":"code","1a2bbdd2":"code","3823ec8a":"code","d900a352":"code","28f475c0":"code","64f4b2ed":"code","bb5b37f0":"code","f48c640d":"code","521d15d6":"code","065c2373":"code","322e4126":"code","49ff8680":"code","606a28f0":"code","ee5f5313":"code","aa011ee7":"code","4449be83":"code","948daf64":"code","d7a1cdb6":"code","71aa0a33":"code","c30cfbbb":"code","523506ed":"code","032469a8":"code","ca972ce7":"code","5b636538":"code","6ebafeed":"code","e08b4978":"code","54f66ab0":"code","ffb17eb3":"code","95f65d3c":"code","b217ea08":"code","0eea0ed2":"code","07525856":"code","3d69f867":"code","7089c360":"code","c5ac97d5":"code","34043f48":"code","7cf4d6fb":"code","51c7cdd9":"code","ba40cf2f":"code","fc998c0b":"code","cfa49bc0":"code","38befb32":"code","a624b6aa":"code","4ef68ead":"code","7b87669e":"code","89b6164f":"code","462512fc":"markdown","b8c86688":"markdown","5681d86b":"markdown","7e54186c":"markdown","83c4d833":"markdown","8a94f5a7":"markdown","c4c73057":"markdown","c1408c2e":"markdown","c27e5947":"markdown","c047c8a2":"markdown","3a0ff0ad":"markdown","f3286cec":"markdown","1aad4804":"markdown","3f16ce6d":"markdown","2380d0ec":"markdown","4ebf112e":"markdown","aa8572dc":"markdown","b5ae93c9":"markdown","e9909b7a":"markdown","509d3d9d":"markdown","c1a94f4b":"markdown","248f2d01":"markdown","9cf57be1":"markdown","c8b1ccc2":"markdown"},"source":{"033a2203":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom tqdm.auto import tqdm\ntqdm.pandas()\n\nimport matplotlib.pyplot as plt\nimport os\n\n#i added the original titanic dataset also here, just to compare a bit\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","93e34f92":"%%time\ndf_train_orig = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ndf_train_orig.head()","6217a40c":"df_train = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-apr-2021\/train.csv\")\ndf_train.head()","692068f4":"df_test = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-apr-2021\/test.csv\")\ndf_test.head()","7dfdb953":"df_train[\"train\"] = 1\ndf_test[\"train\"] = 0\ndf_all = pd.concat([df_train, df_test], sort=False)\ndf_all.head()","c8aa80cd":"def parse_cabin_type(x):\n    if pd.isnull(x):\n        return None\n    cab_id = x[0]\n    return cab_id","f27fc4e3":"def parse_cabin_num(x):\n    if pd.isnull(x):\n        return -1\n    cab_num = x[1:]\n    return cab_num","7d6c1626":"cabin_type = df_all[\"Cabin\"].apply(lambda x: parse_cabin_type(x))\n","88763a6f":"cabin_type","1a2bbdd2":"cabin_num = df_all[\"Cabin\"].apply(lambda x: parse_cabin_num(x))\ncabin_num","3823ec8a":"cabin_num.unique()","d900a352":"def parse_cabin_count(x):\n    if pd.isnull(x):\n        return np.nan\n    #a typical passenger has a single cabin but some had multiple. in that case they are space separated\n    cabs = x.split()\n    return len(cabs)\n","28f475c0":"df_all[\"cabin_type\"] = df_all[\"Cabin\"].apply(lambda x: parse_cabin_type(x))\ndf_all[\"cabin_num\"] = df_all[\"Cabin\"].apply(lambda x: parse_cabin_num(x))\n#no multiple cabins in this set\n#df_all[\"cabin_count\"] = df_all[\"Cabin\"].apply(lambda x: parse_cabin_count(x))\ndf_all[\"cabin_num\"] = df_all[\"cabin_num\"].astype(int)\ndf_all.head()","64f4b2ed":"df_all[\"family_size\"] = df_all[\"SibSp\"] + df_all[\"Parch\"] + 1","bb5b37f0":"#there are no titles in this dataset\n\n#df_all['Title'] = df_all['Name'].str.extract('([A-Za-z]+)\\.', expand=True)\n#df_all.head()\n","f48c640d":"df_train_orig['Title'] = df_train_orig['Name'].str.extract('([A-Za-z]+)\\.', expand=True)\ndf_train_orig.head()\n","521d15d6":"df_all['Age'].isnull().sum()","065c2373":"df_all[\"Age\"].value_counts().count()","322e4126":"df_all[\"Age\"].unique()\n","49ff8680":"df_all[df_all[\"Fare\"].isnull()]","606a28f0":"df_all.groupby('Pclass').agg({'Fare': lambda x: x.isnull().sum()})","ee5f5313":"df_all.groupby('Pclass')[\"Fare\"].nunique()","aa011ee7":"p3_median_fare = df_all[df_all[\"Pclass\"] == 2][\"Fare\"].median()\np3_median_fare","4449be83":"df_all[df_all[\"Pclass\"] == 3].hist(column=\"Fare\", bins=100)","948daf64":"df_all[df_all[\"Pclass\"] == 3][\"Fare\"].value_counts()","d7a1cdb6":"df_all['Fare'] = df_all['Fare'].fillna(df_all.groupby('Pclass')['Fare'].transform('median'))","71aa0a33":"df_all[\"Fare\"].isnull().sum()","c30cfbbb":"df_all.head()","523506ed":"#pd.Int64Dtype seems to be some kind of int that takes NaN also. \n#however, using it here causes unknown label type for LGBM, so have stick with float\n#df_all[\"Survived\"] = df_all[\"Survived\"].astype(pd.Int64Dtype())\ndf_all[\"Sex\"] = df_all[\"Sex\"].astype('category')\ndf_all[\"Embarked\"] = df_all[\"Embarked\"].astype('category')\ndf_all[\"cabin_type\"] = df_all[\"cabin_type\"].astype('category')","032469a8":"#passenger id got ranked high at some point in feature importance.. \n#no idea why. better to remove it anyway\n#although i guess it could indicate the order in which people boarded\ndf_all = df_all.drop([\"Cabin\", \"Name\", \"Ticket\", \"PassengerId\"], axis=1)\ndf_all.head()","ca972ce7":"df_all.dtypes","5b636538":"df_train = df_all[df_all[\"train\"] == 1]\ndf_train.head()","6ebafeed":"df_test = df_all[df_all[\"train\"] == 0]\ndf_test = df_test.drop([\"Survived\", \"train\"], axis=1)\ndf_test.head()\n","e08b4978":"y = df_train[\"Survived\"]\nX = df_train.drop([\"Survived\", \"train\"], axis=1)","54f66ab0":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=314, stratify=y)","ffb17eb3":"%%time\nimport lightgbm as lgbm\n","95f65d3c":"df_train.dtypes","b217ea08":"cat_cols = df_train.select_dtypes(include=['category']).columns\ncat_cols","0eea0ed2":"fit_params = {\"eval_metric\": [\"binary_logloss\", \"auc\"]}\n#fit_params[\"n_estimators\"] = [2000, 5000, 10000, 15000]\nfit_params[\"early_stopping_rounds\"] = 50\nfit_params[\"eval_set\"] = [(X_test,y_test)]\nfit_params['verbose'] = 100 #this results in printing info every 100th round\nfit_params['categorical_feature'] = 'auto'\n#fit_params['categorical_feature'] = cat_cols\n\n    ","07525856":"from scipy.stats import randint as sp_randint\n\nfrozen = sp_randint(6, 50)\nfrozen_results = frozen.rvs(size=1000)\n","3d69f867":"plt.hist(frozen_results)","7089c360":"%%time\nfrom scipy.stats import randint as sp_randint\nfrom scipy.stats import uniform as sp_uniform\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n\nparam_space={'num_leaves': sp_randint(6, 100), \n             'min_child_samples': sp_randint(100, 500), \n             'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n             'subsample': sp_uniform(loc=0.2, scale=0.8), \n             'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n             'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n             'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}\n\nclf = lgbm.LGBMClassifier(max_depth=-1, random_state=314, \n                         silent=True, metric='None', \n                         n_jobs=4, n_estimators=5000)\n\ngs = RandomizedSearchCV(\n    estimator=clf, param_distributions=param_space, \n    n_iter=100,\n    scoring='roc_auc',\n    cv=3,\n    refit=True,\n    random_state=314,\n    verbose=True)","c5ac97d5":"%%time\ngs.fit(X_train, y_train, **fit_params)\n","34043f48":"print(f'Best score reached: {gs.best_score_} with params: {gs.best_params_} ')","7cf4d6fb":"clf = lgbm.LGBMClassifier(max_depth=-1, random_state=314, \n                         silent=True, metric='None', \n                         n_jobs=4, n_estimators=5000, **gs.best_params_)","51c7cdd9":"clf.fit(X_train, y_train, **fit_params)\n","ba40cf2f":"importances = clf.feature_importances_\nfeatures = X.columns\nfeat_importances = pd.Series(importances, index=features)\nfeat_importances.nlargest(30).sort_values().plot(kind='barh', color='#86bf91', figsize=(10, 8))\nplt.show()","fc998c0b":"predictions = clf.predict(df_test)","cfa49bc0":"predictions","38befb32":"sub_df = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-apr-2021\/test.csv\")\nsub_df = sub_df[[\"PassengerId\"]]\nsub_df[\"Survived\"] = predictions\nsub_df[\"Survived\"] = sub_df[\"Survived\"].astype(int)","a624b6aa":"sub_df.to_csv(\"sub.csv\", index=False)","4ef68ead":"sub_df.head()","7b87669e":"!head sub.csv","89b6164f":"!tail sub.csv","462512fc":"There seems to be the difference, that the synthetic data in this dataset has no titles for people. Thus the title as a feature is not useful in this case.","b8c86688":"Do a randomized search over the search space:","5681d86b":"Set the parameters to use for LGBM fit() function:","7e54186c":"Now that the data is all processed and features added, split it back to the original train\/test set:","83c4d833":"Make the predictions for submission:","8a94f5a7":"There are some missing values. Age is one, so need to imputate that. Meaning, fill in the blanks..","c4c73057":"There are 175 different age values, so the age must be reported in fractions of a year. The following confirms this:","c1408c2e":"Now run the search that was just configured above.\n\nUnfortunately the following will also print excessive error messages about overriding some categorical value. Quick search turned no solution, so just leaving it here.","c27e5947":"Also, the original dataset had people who were marked as having multiple cabins. This synthetic dataset does not have that.","c047c8a2":"Just for interest, plot the highest ranked features:","3a0ff0ad":"This fills the missing fares by the passengers class medium. So passenger in class 1 with a missing fare gets a new fare value that is the median of all reported fares in class 1:","f3286cec":"Take the best parameters that the above search found, and re-train the LGBM with those.","1aad4804":"The number of missing fares by passenger group (Pclass):","3f16ce6d":"This is a method to define a range of values to explore for the Random Search algorithm:","2380d0ec":"So the above shows the titles in the original dataset, extracted to the \"Title\" column. The new synthetic one gives nothing if you run that on int.","4ebf112e":"And save them. The Kaggle system does not seem to like floats for 1\/0 survived here, so have to convert them to ints.","aa8572dc":"Change all categorical columns to pandas categorical data type to make use of LGBM's built-in categorical data handling. Thus no need for one-hot encoding:","b5ae93c9":"I added the original dataset, just so I can do a bit of comparison. Because I tried copying features from my earlier Titanic notebooks and some did not work.","e9909b7a":"Strangely, the fare seems also to vary quite a lot inside each passenger class as well. The following shows over 20k different values for class 1 alone:","509d3d9d":"Just to see what types of data the above generated:","c1a94f4b":"The values are largely collected on the bottom part, with the above median of 21.7:","248f2d01":"Check our categorical columns are still correct:","9cf57be1":"Combine train and test data to build some common features.","c8b1ccc2":"See how the fares are quite changing within the class, and the diffs are mostly not too big:"}}