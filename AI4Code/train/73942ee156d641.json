{"cell_type":{"cc536319":"code","18b4d83e":"code","ac356ab1":"code","994ecb1f":"code","b638a140":"code","0a999bc9":"code","d28fa848":"code","a9f993ad":"code","adc2d280":"code","a1cda918":"code","78ee3b72":"code","875adf30":"code","ecdc98be":"code","94349407":"code","5c975f96":"code","4ca5ff1e":"code","b95fe4c0":"code","64082865":"code","765a3ddb":"code","56ccdfc0":"code","e8267d28":"code","8bd85711":"code","3601270c":"code","ed2d7ad8":"code","a9e85d26":"code","b8e51f8e":"code","ef40cbba":"code","327db1fa":"code","bd002a1b":"code","fbee86fa":"code","ff1cb7d5":"code","92630e42":"code","645b4508":"code","2137fe67":"code","a795a1b7":"code","0dfd312d":"code","acad5078":"code","570d2529":"code","7898c60c":"code","883bda7b":"code","76e7eff7":"code","68cc22e1":"code","a5f1db36":"code","7748c713":"code","f78d2459":"code","b584aa46":"code","d91de752":"code","169192aa":"code","cc23a1c4":"code","483b2c6e":"code","765312ed":"code","49adfa65":"code","54d82972":"code","1aa8eb12":"code","26eaa27b":"code","9e4a030d":"code","e4995555":"code","ae664f9d":"code","40b63c43":"code","3ad79466":"code","20e75035":"code","5a6a8e53":"code","7d45ba3d":"code","34196298":"code","c7d39763":"code","c5aa1ade":"code","e82764de":"code","ad3e67c9":"code","2b76801e":"code","1deaad1a":"code","f223ea1f":"code","5e091809":"code","b2fa6b93":"code","22e2ce63":"code","86038eeb":"code","efa90efb":"code","946d881c":"code","ad3bfcfd":"code","d8a9983f":"code","f9154fba":"code","61fb693b":"code","70623f01":"code","0597e6b9":"code","db562121":"code","6009b2f6":"code","6066881a":"code","8e6d738f":"code","3b11892d":"code","8546a84e":"code","baa5542f":"code","5194189b":"code","571e8133":"code","4027fd9f":"code","addad591":"code","054ec2be":"code","73196454":"code","465bd287":"code","8febe6c4":"code","3f67fec4":"code","71d5741c":"code","3ab3622e":"code","539aa82e":"code","f7d7029c":"code","bb4e9382":"code","45344d40":"code","ac95f4f7":"code","608eaf4c":"code","ebf3a23d":"code","125996fe":"code","f0600644":"code","0665e585":"code","863339ce":"code","03346137":"code","d01942d3":"code","00fc37af":"code","6241ca12":"markdown","254677fe":"markdown","a9713e49":"markdown","81714611":"markdown","e2aea26f":"markdown","3ac201d4":"markdown","5b8e6797":"markdown","12120813":"markdown","94525c47":"markdown","4dd0aaa9":"markdown","b071a22a":"markdown","d0928411":"markdown"},"source":{"cc536319":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")","18b4d83e":"pd.set_option(\"display.max_columns\",999)","ac356ab1":"pd.set_option(\"display.max_rows\",85)","994ecb1f":"df_train = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ndf_test = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")","b638a140":"df_train.head()","0a999bc9":"df_test.head()","d28fa848":"df_train.shape","a9f993ad":"df_test.shape","adc2d280":"### checking columns with null values\nnull_df = round((df_train.isnull().sum() *100 \/ df_train.shape[0]),2).sort_values(ascending=False)\nnull_df[null_df > 0]","a1cda918":"### droppping columns from both train and set having more than 40% null value\ndf_train.drop(columns=null_df[null_df > 40].index , inplace=True)\ndf_test.drop(columns=null_df[null_df > 40].index , inplace=True)\nprint(df_train.shape)\nprint(\"\\n\" , df_test.shape)","78ee3b72":"### checking LotFrontage column for data imputation\nsns.boxplot(df_train.LotFrontage)\nplt.show()","875adf30":"sns.displot(df_train.LotFrontage)","ecdc98be":"### best to impute LotFrontage with median values\ndf_train.LotFrontage.fillna(df_train.LotFrontage.median() , inplace=True)\ndf_train.LotFrontage.isnull().sum()","94349407":"### checking GarageYrBlt column for data imputation\nsns.histplot(df_train.GarageYrBlt)\nplt.show()","5c975f96":"### best to impute GarageYrBlt with mode values\ndf_train.GarageYrBlt.fillna(df_train.GarageYrBlt.mode()[0] , inplace=True)\ndf_train.GarageYrBlt.isnull().sum()","4ca5ff1e":"### checking GarageCond column for data imputation\nsns.countplot(df_train.GarageCond)","b95fe4c0":"### best to impute GarageCond with mode values\ndf_train.GarageCond.fillna(df_train.GarageCond.mode()[0] , inplace=True)\ndf_train.GarageCond.isnull().sum()","64082865":"### merging non-TA values as others in both Train and Test set\ndf_train.GarageCond = df_train.GarageCond.apply(lambda x: \"Others\" if x != 'TA' else x)\ndf_train.GarageCond.value_counts(dropna=False)","765a3ddb":"df_test.GarageCond = df_test.GarageCond.apply(lambda x: \"Others\" if x != 'TA' else x)\ndf_test.GarageCond.value_counts(dropna=False)","56ccdfc0":"### checking GarageType column for data imputation\nsns.countplot(df_train.GarageType)","e8267d28":"### best to impute GarageType with mode values\ndf_train.GarageType.fillna(df_train.GarageType.mode()[0] , inplace=True)\ndf_train.GarageType.isnull().sum()","8bd85711":"### merging non-Attchd and non-Detchd values as others in both Train and Test set\ndf_train.GarageType = df_train.GarageType.apply(lambda x: \"Others\" if (x != 'Attchd' and x != 'Detchd') else x)\ndf_train.GarageType.value_counts(dropna=False)","3601270c":"df_test.GarageType = df_test.GarageType.apply(lambda x: \"Others\" if (x != 'Attchd' and x != 'Detchd') else x)\ndf_test.GarageType.value_counts(dropna=False)","ed2d7ad8":"### checking GarageFinish column for data imputation\nsns.countplot(df_train.GarageFinish)","a9e85d26":"### best to impute GarageFinish with mode values\ndf_train.GarageFinish.fillna(df_train.GarageFinish.mode()[0] , inplace=True)\ndf_train.GarageFinish.isnull().sum()","b8e51f8e":"### checking GarageQual column for data imputation\nsns.countplot(df_train.GarageQual)","ef40cbba":"### best to impute GarageCond with mode values\ndf_train.GarageQual.fillna(df_train.GarageQual.mode()[0] , inplace=True)\ndf_train.GarageQual.isnull().sum()","327db1fa":"### merging non-TA values as others in both Train and Test set\ndf_train.GarageQual = df_train.GarageQual.apply(lambda x: \"Others\" if x != 'TA' else x)\ndf_train.GarageQual.value_counts(dropna=False)","bd002a1b":"df_test.GarageQual = df_test.GarageQual.apply(lambda x: \"Others\" if x != 'TA' else x)\ndf_test.GarageQual.value_counts(dropna=False)","fbee86fa":"### checking BsmtFinType2 column for data imputation\nsns.countplot(df_train.BsmtFinType2)","ff1cb7d5":"### best to impute BsmtFinType2 with mode values\ndf_train.BsmtFinType2.fillna(df_train.BsmtFinType2.mode()[0] , inplace=True)\ndf_train.BsmtFinType2.isnull().sum()","92630e42":"### merging non-Unf values as others in both Train and Test set\ndf_train.BsmtFinType2 = df_train.BsmtFinType2.apply(lambda x: \"Others\" if x != 'Unf' else x)\ndf_train.BsmtFinType2.value_counts(dropna=False)","645b4508":"df_test.BsmtFinType2 = df_test.BsmtFinType2.apply(lambda x: \"Others\" if x != 'Unf' else x)\ndf_test.BsmtFinType2.value_counts(dropna=False)","2137fe67":"### checking BsmtExposure column for data imputation\nsns.countplot(df_train.BsmtExposure)","a795a1b7":"### best to impute BsmtExposure with mode values\ndf_train.BsmtExposure.fillna(df_train.BsmtExposure.mode()[0] , inplace=True)\ndf_train.BsmtExposure.isnull().sum()","0dfd312d":"df_test.BsmtExposure.fillna(df_test.BsmtExposure.mode()[0] , inplace=True)\ndf_test.BsmtExposure.isnull().sum()","acad5078":"### merging non-NO values as others in both Train and Test set\ndf_train.BsmtExposure = df_train.BsmtExposure.apply(lambda x: \"Others\" if x != 'No' else x)\ndf_train.BsmtExposure.value_counts(dropna=False)","570d2529":"df_test.BsmtExposure = df_test.BsmtExposure.apply(lambda x: \"Others\" if x != 'No' else x)\ndf_test.BsmtExposure.value_counts(dropna=False)","7898c60c":"### checking BsmtQual column for data imputation\nsns.countplot(df_train.BsmtQual)","883bda7b":"### best to impute BsmtQual with mode values\ndf_train.BsmtQual.fillna(df_train.BsmtQual.mode()[0] , inplace=True)\ndf_train.BsmtQual.isnull().sum()","76e7eff7":"df_test.BsmtQual.fillna(df_test.BsmtQual.mode()[0] , inplace=True)\ndf_test.BsmtQual.isnull().sum()","68cc22e1":"### merging Ex & Fa values as others in both Train and Test set\ndf_train.BsmtQual = df_train.BsmtQual.apply(lambda x: \"Others\" if (x == 'Ex' or x == 'Fa') else x)\ndf_train.BsmtQual.value_counts(dropna=False)","a5f1db36":"df_test.BsmtQual = df_test.BsmtQual.apply(lambda x: \"Others\" if (x == 'Ex' or x == 'Fa') else x)\ndf_test.BsmtQual.value_counts(dropna=False)","7748c713":"### checking BsmtCond column for data imputation\nsns.countplot(df_train.BsmtCond)","f78d2459":"### best to impute BsmtQual with mode values\ndf_train.BsmtCond.fillna(df_train.BsmtCond.mode()[0] , inplace=True)\ndf_train.BsmtCond.isnull().sum()","b584aa46":"df_test.BsmtCond.fillna(df_test.BsmtCond.mode()[0] , inplace=True)\ndf_test.BsmtCond.isnull().sum()","d91de752":"### merging non-TA values as others in both Train and Test set\ndf_train.BsmtCond = df_train.BsmtCond.apply(lambda x: \"Others\" if x != 'TA' else x)\ndf_train.BsmtCond.value_counts(dropna=False)","169192aa":"df_test.BsmtCond = df_test.BsmtCond.apply(lambda x: \"Others\" if x != 'TA' else x)\ndf_test.BsmtCond.value_counts(dropna=False)","cc23a1c4":"### checking BsmtFinType1 column for data imputation\nsns.countplot(df_train.BsmtFinType1)","483b2c6e":"### best to impute BsmtFinType1 with mode values\ndf_train.BsmtFinType1.fillna(df_train.BsmtFinType1.mode()[0] , inplace=True)\ndf_train.BsmtFinType1.isnull().sum()","765312ed":"df_test.BsmtFinType1.fillna(df_test.BsmtFinType1.mode()[0] , inplace=True)\ndf_test.BsmtFinType1.isnull().sum()","49adfa65":"### checking MasVnrArea column for data imputation\nsns.distplot(df_train.MasVnrArea)","54d82972":"sns.boxplot(df_train.MasVnrArea)","1aa8eb12":"### best to impute MasVnrArea with median values\ndf_train.MasVnrArea.fillna(df_train.MasVnrArea.median() , inplace=True)\ndf_train.MasVnrArea.isnull().sum()","26eaa27b":"df_test.MasVnrArea.fillna(df_test.MasVnrArea.median() , inplace=True)\ndf_test.MasVnrArea.isnull().sum()","9e4a030d":"### checking MasVnrType column for data imputation\nsns.countplot(df_train.MasVnrType)","e4995555":"### best to impute MasVnrType with mode values\ndf_train.MasVnrType.fillna(df_train.MasVnrType.mode()[0] , inplace=True)\ndf_train.MasVnrType.isnull().sum()","ae664f9d":"df_test.MasVnrType.fillna(df_test.MasVnrType.mode()[0] , inplace=True)\ndf_test.MasVnrType.isnull().sum()","40b63c43":"### merging Stone & BrkCmn values as others in both Train and Test set\ndf_train.MasVnrType = df_train.MasVnrType.apply(lambda x: \"Others\" if (x == 'Stone' or x == 'BrkCmn') else x)\ndf_train.MasVnrType.value_counts(dropna=False)","3ad79466":"df_test.MasVnrType = df_test.MasVnrType.apply(lambda x: \"Others\" if (x == 'Stone' or x == 'BrkCmn') else x)\ndf_test.MasVnrType.value_counts(dropna=False)","20e75035":"### checking Electrical column for data imputation\nsns.countplot(df_train.Electrical)","5a6a8e53":"### best to impute Electrical with mode values\ndf_train.Electrical.fillna(df_train.Electrical.mode()[0] , inplace=True)\ndf_train.Electrical.isnull().sum()","7d45ba3d":"df_test.Electrical.fillna(df_test.Electrical.mode()[0] , inplace=True)\ndf_test.Electrical.isnull().sum()","34196298":"### merging non-SBrkr values as others in both Train and Test set\ndf_train.Electrical = df_train.Electrical.apply(lambda x: \"Others\" if x != 'SBrkr' else x)\ndf_train.Electrical.value_counts(dropna=False)","c7d39763":"df_test.Electrical = df_test.Electrical.apply(lambda x: \"Others\" if x != 'SBrkr' else x)\ndf_test.Electrical.value_counts(dropna=False)","c5aa1ade":"### Final check of columns after\nnull_df = round((df_train.isnull().sum() *100 \/ df_train.shape[0]),2).sort_values(ascending=False)\nnull_df[null_df > 0]","e82764de":"## converting YearBuilt columns into buckets\nbuckets = [-np.inf , 1900,1950,2000,np.inf]\nlabels = [\"1800-1900\",\"1900-1950\",\"1950-2000\",\"2000-2020\"]\ndf_train[\"YearBuilt_Bucket\"] = pd.cut(df_train[\"YearBuilt\"] , buckets ,labels =labels)\ndf_test[\"YearBuilt_Bucket\"] = pd.cut(df_test[\"YearBuilt\"] , buckets ,labels =labels)","ad3e67c9":"df_train.drop(columns=\"YearBuilt\" , inplace=True)\ndf_test.drop(columns=\"YearBuilt\" , inplace=True)","2b76801e":"## converting YearRemodAdd columns into buckets\nbuckets = [1950,1975,2000,np.inf]\nlabels = [\"1950-1975\",\"1975-2000\",\"2000-2020\"]\ndf_train[\"YearRemodAdd_Bucket\"] = pd.cut(df_train[\"YearRemodAdd\"] , buckets ,labels =labels)\ndf_test[\"YearRemodAdd_Bucket\"] = pd.cut(df_test[\"YearRemodAdd\"] , buckets ,labels =labels)","1deaad1a":"df_train.drop(columns=\"YearRemodAdd\" , inplace=True)\ndf_test.drop(columns=\"YearRemodAdd\" , inplace=True)","f223ea1f":"## converting GarageYrBlt columns into buckets\nbuckets = [-np.inf,1950,1975,2000,np.inf]\nlabels = [\"Before-1950\",\"1950-1975\",\"1975-2000\",\"2000-2020\"]\ndf_train[\"GarageYrBlt_Bucket\"] = pd.cut(df_train[\"GarageYrBlt\"] , buckets ,labels =labels)\ndf_test[\"GarageYrBlt_Bucket\"] = pd.cut(df_test[\"GarageYrBlt\"] , buckets ,labels =labels)","5e091809":"df_train.drop(columns=\"GarageYrBlt\" , inplace=True)\ndf_test.drop(columns=\"GarageYrBlt\" , inplace=True)","b2fa6b93":"### converting yr columns to objects as they must be treated a categorical\ndf_train[[\"YearBuilt_Bucket\",\"YrSold\",\"YearRemodAdd_Bucket\",\"GarageYrBlt_Bucket\"]] = df_train[[\"YearBuilt_Bucket\",\"YrSold\",\"YearRemodAdd_Bucket\",\"GarageYrBlt_Bucket\"]].astype(\"object\")\ndf_test[[\"YearBuilt_Bucket\",\"YrSold\",\"YearRemodAdd_Bucket\",\"GarageYrBlt_Bucket\"]] = df_test[[\"YearBuilt_Bucket\",\"YrSold\",\"YearRemodAdd_Bucket\",\"GarageYrBlt_Bucket\"]].astype(\"object\")","22e2ce63":"### converting CentralAir \"Y\" to 1 and \"N\" to 0\ndf_train[\"CentralAir\"] = df_train[\"CentralAir\"].apply(lambda x: 1 if x==\"Y\" else 0)\ndf_test[\"CentralAir\"] = df_test[\"CentralAir\"].apply(lambda x: 1 if x==\"Y\" else 0)","86038eeb":"### converting other columns to objects as they must be treated a categorical\ncolumn_to_object = [\"Fireplaces\",\"TotRmsAbvGrd\",\"OverallQual\",\"OverallCond\",\"CentralAir\",\"MoSold\",\"GarageCars\",\"MSSubClass\",\"BsmtFullBath\",\"BsmtHalfBath\",\"FullBath\",\"HalfBath\",\"BedroomAbvGr\",\"KitchenAbvGr\"]\ndf_train[column_to_object] = df_train[column_to_object].astype(\"object\")\ndf_test[column_to_object] = df_test[column_to_object].astype(\"object\")","efa90efb":"### dropping the ID column\ndf_train.drop(columns=\"Id\" , inplace=True)","946d881c":"from sklearn.preprocessing import MinMaxScaler","ad3bfcfd":"scaler = MinMaxScaler()","d8a9983f":"### getting list of numerical columns\ncolumns_to_scale = df_train.select_dtypes([\"int64\",\"float64\"]).columns\ncolumns_to_scale","f9154fba":"### excluding the target column\ncolumns_to_scale = columns_to_scale[:-1]","61fb693b":"df_train[columns_to_scale] = scaler.fit_transform(df_train[columns_to_scale])\ndf_test[columns_to_scale] = scaler.transform(df_test[columns_to_scale])","70623f01":"### creating X & Y train\ny_train = df_train.pop(\"SalePrice\")\nx_train = df_train","0597e6b9":"### getting list of categorical columns\ncolumns_to_dummy = df_train.select_dtypes([\"object\"]).columns\ncolumns_to_dummy","db562121":"### create dummy for both test and train\ndummy = pd.get_dummies(x_train[columns_to_dummy] , drop_first=True)\nx_train.drop(columns=columns_to_dummy , inplace=True)\nx_train = pd.concat([x_train,dummy] , axis=1)\n\ndummy = pd.get_dummies(df_test[columns_to_dummy] , drop_first=True)\ndf_test.drop(columns=columns_to_dummy , inplace=True)\ndf_test = pd.concat([df_test,dummy] , axis=1)\n","6009b2f6":"x_train.shape","6066881a":"x_train.head()","8e6d738f":"from sklearn.linear_model import LinearRegression\nfrom sklearn.feature_selection import RFECV\nfrom sklearn import metrics\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.feature_selection import RFE\nimport statsmodels.api as sm\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor","3b11892d":"folds = StratifiedKFold(n_splits=5 , random_state=42 , shuffle=True)","8546a84e":"lm = LinearRegression()","baa5542f":"rfecv =RFECV(estimator=lm , cv=folds , scoring=\"r2\" , n_jobs=-1)\nrfecv.fit(x_train,y_train)","5194189b":"rfecv.n_features_","571e8133":"rfe = RFE(lm , rfecv.n_features_)\nrfe = rfe.fit(x_train,y_train)","4027fd9f":"best_features = list(x_train.columns[rfe.support_])\nbest_features","addad591":"plt.figure(figsize=(18,12))\nsns.heatmap(x_train[best_features].corr(),annot=True)\nplt.show()","054ec2be":"### creating function to create model and display stats\ndef build_OLS_model(x_train , y_train , features):\n    x_train_rfe = x_train[features]\n    x_train_rfe = sm.add_constant(x_train_rfe)\n    ols = sm.OLS(y_train, x_train_rfe)\n    ols_model = ols.fit()\n    print(ols_model.summary())\n    print(\"\\n\")\n    vif= pd.DataFrame()\n    vif[\"Features\"] = x_train_rfe.columns\n    vif[\"VIF\"] = [variance_inflation_factor(x_train_rfe.values , i) for i in range(x_train_rfe.shape[1])]\n    vif[\"VIF\"] = round(vif[\"VIF\"] , 2)\n    vif = vif.sort_values(by=\"VIF\" , ascending=False)\n    print(vif)","73196454":"### Model-1\nbuild_OLS_model(x_train,y_train,best_features)","465bd287":"### removing column with high VIF : 2ndFlrSF\nbest_features.remove(\"2ndFlrSF\")\n### Model-2\nbuild_OLS_model(x_train,y_train,best_features)","8febe6c4":"### removing column with high VIF : RoofMatl_WdShake\nbest_features.remove(\"RoofMatl_WdShake\")\n### Model-3\nbuild_OLS_model(x_train,y_train,best_features)","3f67fec4":"### removing column with high p-value : OverallCond_8\nbest_features.remove(\"OverallCond_8\")\n### Model-4\nbuild_OLS_model(x_train,y_train,best_features)","71d5741c":"### removing column with high p-value : OverallCond_9 \nbest_features.remove(\"OverallCond_9\")\n### Model-5\nbuild_OLS_model(x_train,y_train,best_features)","3ab3622e":"### here is the final list of features having low VIF and P-Value\nbest_features","539aa82e":"### checking the best_features in test set and dropping if not present\ncols_remove = []\nfor col in  best_features:\n    if col not in df_test.columns:\n        print(\"\\n Removed:\",col)\n        cols_remove.append(col)\n        \nfor col in cols_remove:\n    best_features.remove(col)\n\nbest_features","f7d7029c":"### checking the best_features in test set and dropping if not present\ncols_consider = []\nfor col in  x_train.columns:\n    if col in df_test.columns:\n        cols_consider.append(col)\n","bb4e9382":"### creating the final OLS model\nx_train_final = sm.add_constant(x_train[best_features])\nols = sm.OLS(y_train,x_train_final)\nols_model_best = ols.fit()\n","45344d40":"from sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import metrics\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RandomizedSearchCV","ac95f4f7":"### checking with KNN\nr2_scores =[]\nfor n in range(1,10):\n    knn = KNeighborsRegressor(n_neighbors=n)\n    r2_scores.append(cross_val_score(knn,x_train[cols_consider] , y_train,n_jobs=-1, cv=folds, scoring=\"r2\").mean())\n    \nplt.plot(range(1,10) , r2_scores)    \nplt.show()","608eaf4c":"### best to keep K=3\nknn_best = KNeighborsRegressor(n_neighbors=3)\nknn_best.fit(x_train[cols_consider] , y_train)","ebf3a23d":"### checking with Random forest\nrf = RandomForestRegressor(random_state=42 , n_jobs=-1)\nparams = {\n    \"n_estimators\": range(10,200,5),\n    \"max_depth\": range(3,15),\n    \"min_samples_split\" : range(3,10),\n    \"min_samples_leaf\" :range(2,15),\n    \"max_features\": range(5,150,5)\n}\n\nrsCV = RandomizedSearchCV(estimator=rf , random_state=42  , param_distributions= params , n_jobs=-1 , cv=folds , n_iter= 400)\nrsCV.fit(x_train[cols_consider] , y_train)","125996fe":"rf_best = rsCV.best_estimator_","f0600644":"### best r2 score from Random Forest\nrsCV.best_score_","0665e585":"def estimate(x_test, best_features,cols_consider):\n    x_test_sm = sm.add_constant(x_test[best_features])\n    final_estimate = pd.DataFrame({\"OLS\":ols_model_best.predict(x_test_sm) , \"KNN\" : knn_best.predict(x_test[cols_consider]) , \"RF\" : rf_best.predict(x_test[cols_consider]) })\n    return final_estimate","863339ce":"### handling null values in test set\nnull_df = round((df_test.isnull().sum() *100 \/ df_test.shape[0]),2).sort_values(ascending=False)\nnull_df[null_df > 0]","03346137":"### imputing all with median values\ndf_test[\"TotalBsmtSF\"] = df_test[\"TotalBsmtSF\"].fillna(df_test[\"TotalBsmtSF\"].median())\ndf_test[\"GarageArea\"] = df_test[\"GarageArea\"].fillna(df_test[\"GarageArea\"].median())\ndf_test[\"BsmtFinSF1\"] = df_test[\"BsmtFinSF1\"].fillna(df_test[\"BsmtFinSF1\"].median())\ndf_test[\"LotFrontage\"] = df_test[\"LotFrontage\"].fillna(df_test[\"LotFrontage\"].median())\ndf_test[\"BsmtFinSF2\"] = df_test[\"BsmtFinSF2\"].fillna(df_test[\"BsmtFinSF2\"].median())\ndf_test[\"BsmtUnfSF\"] = df_test[\"BsmtUnfSF\"].fillna(df_test[\"BsmtUnfSF\"].median())","d01942d3":"### show multi estimator values\ny_test_predicted = estimate(df_test,best_features,cols_consider)\ny_test_predicted[\"Avg_Predict\"] = y_test_predicted.mean(axis=1)\ndf_test[\"SalePrice\"] = y_test_predicted[\"Avg_Predict\"]\ny_test_predicted.head()","00fc37af":"### final data to submit\ndf_test[[\"Id\",\"SalePrice\"]].to_csv(\"submission.csv\")","6241ca12":"<br>\n<br>","254677fe":"### Importing Packages","a9713e49":"### Data Understanding & Cleaning","81714611":"### Importing Data","e2aea26f":"<br>","3ac201d4":"### Data Standardisation & Dummy column ","5b8e6797":"### Creating non-liner model","12120813":"<rb>","94525c47":"### Model Creation","4dd0aaa9":"<br>\n<br>","b071a22a":"<br>\n<br>","d0928411":"### Creating Multi Estimator"}}