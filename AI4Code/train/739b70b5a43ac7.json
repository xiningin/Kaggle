{"cell_type":{"9fb7aa98":"code","3b855155":"code","016ad870":"code","f751e481":"code","eed6084f":"code","d1522ccd":"code","fafc6b3e":"code","718dc35a":"code","5ef80a68":"code","1f8305e2":"code","1ad7151a":"code","5b713b83":"code","790e5abc":"code","3fc36e84":"code","15e40ca4":"code","b3798ebc":"code","9a4270c4":"code","35d73bd5":"code","b9bee42a":"code","56b00e4e":"code","3ab94b4f":"code","31053ac0":"code","6ccde651":"code","26c4c7f7":"code","a97e6d05":"code","b085e594":"code","424dc9ea":"code","35bba7c7":"code","3561b4cb":"code","9cd6c072":"code","c7e351e8":"code","af1ab26a":"code","3bc1467e":"code","157f03f0":"code","65b36313":"code","fe19fd42":"markdown","f1fe8577":"markdown","291f68b7":"markdown","68709660":"markdown","bdf07a7a":"markdown","6628c503":"markdown","54998936":"markdown","7b39d91d":"markdown","af1a1c3e":"markdown","38bda10a":"markdown","3e075be4":"markdown","2e258662":"markdown","2a1773d9":"markdown","a10b9220":"markdown","916445e1":"markdown","fd5cd33d":"markdown","f6c506d3":"markdown","6dd50a6f":"markdown","c52f1d67":"markdown","2bc4c98c":"markdown","3ddea3ff":"markdown","0a0d0fc3":"markdown","45f04666":"markdown","fcfbb42e":"markdown","37aba29d":"markdown","3032a648":"markdown","2065bf42":"markdown","8dbbda9b":"markdown","b7333857":"markdown","312bcfbb":"markdown","3bc483ca":"markdown","82f3314f":"markdown","8838bc99":"markdown"},"source":{"9fb7aa98":"COMPUTE_CV = False\nEDA_DEMO = True\nALL_BLENDED = False\nBASELINE_HELPING = False\nMATCH_ONLY = False\nMLM_ONLY = False\nKEN_MATCHING = True\nBS_CLEANING = False\nTHEO_MERGE = False\nSEED = 42","3b855155":"!pip install datasets --no-index --find-links=file:\/\/\/kaggle\/input\/coleridge-packages\/packages\/datasets\n!pip install ..\/input\/coleridge-packages\/seqeval-1.2.2-py3-none-any.whl\n!pip install ..\/input\/coleridge-packages\/tokenizers-0.10.1-cp37-cp37m-manylinux1_x86_64.whl\n!pip install ..\/input\/coleridge-packages\/transformers-4.5.0.dev0-py3-none-any.whl\n\nfrom IPython.display import clear_output\nclear_output()","016ad870":"import os\nimport re\nimport json\nimport time\nimport random\nimport glob\nimport importlib\n\nimport numpy as np\nimport pandas as pd\n\nfrom tqdm.autonotebook import tqdm\n\nimport torch\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, DataCollatorForLanguageModeling, \\\nAutoModelForMaskedLM, Trainer, TrainingArguments, pipeline\n\nfrom typing import List\nimport string\nfrom functools import partial\nimport warnings\nwarnings.filterwarnings(\"ignore\", 'This pattern has match groups')\n\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\nsample_submission = pd.read_csv('..\/input\/coleridgeinitiative-show-us-the-data\/sample_submission.csv')\nif len(sample_submission) > 4: COMPUTE_CV = False\nif COMPUTE_CV: \n    print('this submission notebook will compute CV score but commit notebook will not')\nelse:\n    print('this submission notebook will only be used to submit result')","f751e481":"train_path = '..\/input\/coleridgeinitiative-show-us-the-data\/train.csv'\ntrain_files_path = '..\/input\/coleridgeinitiative-show-us-the-data\/train'\ntrain = pd.read_csv(train_path)\n\nif COMPUTE_CV: \n    sample_submission = train\n    paper_test_folder = '..\/input\/coleridgeinitiative-show-us-the-data\/train'\n    test_files_path = paper_test_folder\nelse:\n    sample_submission = pd.read_csv('..\/input\/coleridgeinitiative-show-us-the-data\/sample_submission.csv')\n    paper_test_folder = '..\/input\/coleridgeinitiative-show-us-the-data\/test'\n    test_files_path = paper_test_folder\n    \nadnl_govt_labels_path = '..\/input\/coleridge-additional-gov-datasets-22000popular\/data_set_800_with2000popular.csv'","eed6084f":"train","d1522ccd":"for col in train.columns:\n    print(col + \":\" + str(len(train[col].unique())))\n\nprint(\"all rows = \" + str(len(train)))","fafc6b3e":"papers = {}\nfor paper_id in tqdm(sample_submission['Id']):\n    with open(f'{paper_test_folder}\/{paper_id}.json', 'r') as f:\n        paper = json.load(f)\n        papers[paper_id] = paper","718dc35a":"paper[0]","5ef80a68":"if EDA_DEMO:\n    df_input = pd.DataFrame(columns=['id','section_title','text','data_label'])\n    for id in tqdm(train['Id'].values):\n        df=pd.read_json('..\/input\/coleridgeinitiative-show-us-the-data\/train\/{}.json'.format(id))    \n        for data_label in train[train['Id']==id]['dataset_label'].values:        \n            new_df=df[df['text'].str.contains(data_label)].copy(deep=True)\n            new_df.loc[:,['data_label']] = data_label\n            new_df.loc[:,['id']] = id\n            new_df.reset_index(inplace=True,drop=True)\n            df_input=pd.concat([df_input, new_df], ignore_index=True)\n            df_input.reset_index(inplace=True,drop=True)\nelse: df_input = None\n\ndf_input","1f8305e2":"if EDA_DEMO: df_input = df_input[ df_input['section_title'] != '' ]\n\ndf_input","1ad7151a":"all_labels = set()\n\nfor label_1, label_2, label_3 in train[['dataset_title', 'dataset_label', 'cleaned_label']].itertuples(index=False):\n    all_labels.add(str(label_1).lower())\n    all_labels.add(str(label_2).lower())\n    all_labels.add(str(label_3).lower())\n    \nprint(f'No. different labels: {len(all_labels)}')","5b713b83":"adnl_govt_labels = pd.read_csv(adnl_govt_labels_path)\n\nfor l in adnl_govt_labels.title:\n    all_labels.add(l)\n    \nall_labels = set(all_labels)\nprint(f'No. different labels: {len(all_labels)}')","790e5abc":"l","3fc36e84":"def clean_text(txt):\n    return re.sub('[^A-Za-z0-9]+', ' ', str(txt).lower()).strip()\n\n\ndef totally_clean_text(txt):\n    txt = clean_text(txt)\n    txt = re.sub(' +', ' ', txt)\n    return txt\n\nif not BS_CLEANING:\n    def text_cleaning(text):\n        '''\n       \u3059\u3079\u3066\u306e\u30c6\u30ad\u30b9\u30c8\u3092\u5c0f\u6587\u5b57\u306b\u5909\u63db\u3057\u3001\u7279\u6b8a\u6587\u5b57\u3001\u7d75\u6587\u5b57\u3001\u8907\u6570\u306e\u30b9\u30da\u30fc\u30b9\u3092\u524a\u9664\u3057\u307e\u3059\u3002\u30c6\u30ad\u30b9\u30c8 - \u30af\u30ea\u30fc\u30f3\u30a2\u30c3\u30d7\u304c\u5fc5\u8981\u306a\u6587\n        '''\n        text = re.sub('[^A-Za-z0-9]+', ' ', str(text).lower()).strip()\n        text = re.sub(' +', ' ', text)\n        emoji_pattern = re.compile(\"[\"\n                                   u\"\\U0001F600-\\U0001F64F\"  # \u9854\u6587\u5b57\n                                   u\"\\U0001F300-\\U0001F5FF\"  # \u8a18\u53f7\u3068\u7d75\u6587\u5b57\n                                   u\"\\U0001F680-\\U0001F6FF\"  # \u4ea4\u901a\u53ca\u3073\u5730\u56f3\u8a18\u53f7\n                                   u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                                   \"]+\", flags=re.UNICODE)\n        text = emoji_pattern.sub(r'', text)\n        return text\nelse:\n    def text_cleaning(text):\n        '''\n        \u3059\u3079\u3066\u306e\u30c6\u30ad\u30b9\u30c8\u3092\u5c0f\u6587\u5b57\u306b\u5909\u63db\u3057\u3001\u7279\u6b8a\u6587\u5b57\u3001\u7d75\u6587\u5b57\u3001\u8907\u6570\u306e\u30b9\u30da\u30fc\u30b9\u3092\u524a\u9664\u3057\u307e\u3059\u3002\u30c6\u30ad\u30b9\u30c8 - \u30af\u30ea\u30fc\u30f3\u30a2\u30c3\u30d7\u304c\u5fc5\u8981\u306a\u6587\n        '''\n        text = ''.join([k for k in text if k not in string.punctuation])\n        text = re.sub('[^A-Za-z0-9]+', ' ', str(text).lower()).strip()\n        # text = re.sub(\"\/'+\/g\", ' ', text)\n        return text\n\n\ndef read_json_pub(filename, train_data_path=train_files_path, output='text'):\n    json_path = os.path.join(train_data_path, (filename+'.json'))\n    headings = []\n    contents = []\n    combined = []\n    with open(json_path, 'r') as f:\n        json_decode = json.load(f)\n        for data in json_decode:\n            headings.append(data.get('section_title'))\n            contents.append(data.get('text'))\n            combined.append(data.get('section_title'))\n            combined.append(data.get('text'))\n    \n    all_headings = ' '.join(headings)\n    all_contents = ' '.join(contents)\n    all_data = '. '.join(combined)\n    \n    if output == 'text':\n        return all_contents\n    elif output == 'head':\n        return all_headings\n    else:\n        return all_data","15e40ca4":"if not KEN_MATCHING and not MLM_ONLY:\n    literal_preds = []\n    for paper_id in tqdm(sample_submission['Id']):\n        paper = papers[paper_id]\n        text_1 = '. '.join(section['text'] for section in paper).lower()\n        text_2 = totally_clean_text(text_1)\n\n        labels = set()\n        for label in all_labels:\n            if label in text_1 or label in text_2:\n                labels.add(clean_text(label))\n\n        literal_preds.append('|'.join(labels))\n    literal_preds[:5]","b3798ebc":"literal_preds = []\n\nif KEN_MATCHING and not MLM_ONLY:\n    literal_preds = []\n    to_append = []\n    for index, row in tqdm(sample_submission.iterrows()):\n        to_append = [row['Id'],'']\n        large_string = str(read_json_pub(row['Id'], test_files_path))\n        clean_string = text_cleaning(large_string)\n        for index, row2 in adnl_govt_labels.iterrows():\n            query_string = str(row2['title'])\n            if query_string in clean_string:\n                if to_append[1] != '' and clean_text(query_string) not in to_append[1]:\n                    to_append[1] = to_append[1] + '|' + clean_text(query_string)\n                if to_append[1] == '':\n                    to_append[1] = clean_text(query_string)\n        literal_preds.append(*to_append[1:])\n\nelif MLM_ONLY:\n    print('This kernel will only use MLM model to predict.')","9a4270c4":"literal_preds","35d73bd5":"if not MATCH_ONLY:\n    PRETRAINED_PATH = '..\/input\/coleridge-mlm-model\/mlm-model'\n    TOKENIZER_PATH = '..\/input\/coleridge-mlm-model\/model_tokenizer'\n\n    MAX_LENGTH = 64\n    OVERLAP = 20\n\n    PREDICT_BATCH = 32 # a higher value requires higher GPU memory usage\n\n    DATASET_SYMBOL = '$' # this symbol represents a dataset name\n    NONDATA_SYMBOL = '#' # this symbol represents a non-dataset name","b9bee42a":"if not MATCH_ONLY:\n    tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH, use_fast=True)\n    model = AutoModelForMaskedLM.from_pretrained(PRETRAINED_PATH)\n\n    mlm = pipeline(\n        'fill-mask', \n        model=model,\n        tokenizer=tokenizer,\n        device=0 if torch.cuda.is_available() else -1\n    )","56b00e4e":"def jaccard_similarity(s1, s2): #\u7a7a\u767d\u3067split\n    l1 = s1.split(\" \")\n    l2 = s2.split(\" \")    \n    intersection = len(list(set(l1).intersection(l2)))\n    union = (len(l1) + len(l2)) - intersection\n    return float(intersection) \/ union\n\ndef clean_paper_sentence(s): #\u6570\u5b57\u3001\u82f1\u5b57\u3092\u7a7a\u767d\u306b\u5909\u63db\u3002+\u3082\u7a7a\u767d\u306b\u5909\u63db\u3002\n    \"\"\"\n    \u3053\u306e\u95a2\u6570\u306f\u3001\u57fa\u672c\u7684\u306b\u5c0f\u6587\u5b57\u306e\u306a\u3044 clean_text \u3067\u3059\u3002\n    \"\"\"\n    s = re.sub('[^A-Za-z0-9]+', ' ', str(s)).strip()\n    s = re.sub(' +', ' ', s)\n    return s\n\ndef shorten_sentences(sentences):\n    \"\"\"\n    MAX_LENGTH\u5358\u8a9e\u4ee5\u4e0a\u306e\u6587\u306f\u5206\u5272\u3055\u308c\u307e\u3059\n     \u91cd\u8907\u3057\u3066\u8907\u6570\u306e\u6587\u306b\u3002\n    \"\"\"\n    short_sentences = []\n    for sentence in sentences:\n        words = sentence.split()\n        if len(words) > MAX_LENGTH:\n            for p in range(0, len(words), MAX_LENGTH - OVERLAP):\n                short_sentences.append(' '.join(words[p:p+MAX_LENGTH]))\n        else:\n            short_sentences.append(sentence)\n    return short_sentences\n\nconnection_tokens = {'s', 'of', 'and', 'in', 'on', 'for', 'data', 'dataset'}\ndef find_mask_candidates(sentence):\n    \"\"\"\n    \u6307\u5b9a\u3055\u308c\u305f $sentence \u304b\u3089 Masked Dataset Modeling \u306e\u30de\u30b9\u30ad\u30f3\u30b0\u5019\u88dc\u3092\u62bd\u51fa\u3057\u307e\u3059\u3002\n     \u5019\u88dc\u306f\u5c11\u306a\u304f\u3068\u3082 2 \u5358\u8a9e\u306e\u9023\u7d9a\u3057\u305f\u30b7\u30fc\u30b1\u30f3\u30b9\u3067\u306a\u3051\u308c\u3070\u306a\u308a\u307e\u305b\u3093\u3002\n     \u3053\u308c\u3089\u306e\u5404\u5358\u8a9e\u306f\u3001\u6700\u521d\u306e\u6587\u5b57\u304c\u5927\u6587\u5b57\u304b\u3001\u6b21\u306e\u3044\u305a\u308c\u304b\u3067\u3059\u3002\n     \u63a5\u7d9a\u30ef\u30fc\u30c9 ($connection_tokens)\u3002 \u3055\u3089\u306b\u3001\u63a5\u7d9a\u306f\n     \u30c8\u30fc\u30af\u30f3\u306e\u6700\u521d\u3068\u6700\u5f8c\u306b\u51fa\u73fe\u3059\u308b\u3053\u3068\u306f\u8a31\u53ef\u3055\u308c\u3066\u3044\u307e\u305b\u3093\u3002\n     \u30b7\u30fc\u30b1\u30f3\u30b9\u3002\n    \"\"\"\n    def candidate_qualified(words):\n        while len(words) and words[0].lower() in connection_tokens:\n            words = words[1:]\n        while len(words) and words[-1].lower() in connection_tokens:\n            words = words[:-1]\n        \n        return len(words) >= 2\n    \n    candidates = []\n    \n    phrase_start, phrase_end = -1, -1\n    for id in range(1, len(sentence)):\n        word = sentence[id]\n        if word[0].isupper() or word in connection_tokens:\n            if phrase_start == -1:\n                phrase_start = phrase_end = id\n            else:\n                phrase_end = id\n        else:\n            if phrase_start != -1:\n                if candidate_qualified(sentence[phrase_start:phrase_end+1]):\n                    candidates.append((phrase_start, phrase_end))\n                phrase_start = phrase_end = -1\n    \n    if phrase_start != -1:\n        if candidate_qualified(sentence[phrase_start:phrase_end+1]):\n            candidates.append((phrase_start, phrase_end))\n    \n    return candidates","3ab94b4f":"if not MATCH_ONLY:\n    mask = mlm.tokenizer.mask_token\n    all_test_data = []\n    \n    for paper_id in tqdm(sample_submission['Id']):\n        # load paper\n        paper = papers[paper_id]\n\n        # extract sentences\n        sentences = set([clean_paper_sentence(sentence) for section in paper \n                         for sentence in section['text'].split('.')\n                        ])\n        sentences = shorten_sentences(sentences) # make sentences short\n        sentences = [sentence for sentence in sentences if len(sentence) > 1] # only accept sentences with length > 1 chars\n        sentences = [sentence for sentence in sentences if any(word in sentence.lower() for word in ['data', 'study'])]\n        sentences = [sentence.split() for sentence in sentences] # sentence = list of words\n\n        # mask\n        test_data = []\n        for sentence in sentences:\n            for phrase_start, phrase_end in find_mask_candidates(sentence):\n                dt_point = sentence[:phrase_start] + [mask] + sentence[phrase_end+1:]\n                test_data.append((' '.join(dt_point), ' '.join(sentence[phrase_start:phrase_end+1]))) # (masked text, phrase)\n\n        all_test_data.append(test_data)","31053ac0":"sample_submission['Id']","6ccde651":"papers['2100032a-7c33-4bff-97ef-690822c43466'][0]","26c4c7f7":"sentence","a97e6d05":"all_test_data[0]","b085e594":"if not MATCH_ONLY:\n    pred_mlm_labels = []\n\n    for test_data in tqdm(all_test_data):\n        pred_bag = set()\n\n        if len(test_data):\n            texts, phrases = list(zip(*test_data))\n            mlm_pred = []\n            for p_id in range(0, len(texts), PREDICT_BATCH):\n                batch_texts = texts[p_id:p_id+PREDICT_BATCH]\n                batch_pred = mlm(list(batch_texts), targets=[f' {DATASET_SYMBOL}', f' {NONDATA_SYMBOL}'])\n\n                if len(batch_texts) == 1:\n                    batch_pred = [batch_pred]\n\n                mlm_pred.extend(batch_pred)\n\n            for (result1, result2), phrase in zip(mlm_pred, phrases):\n                if (result1['score'] > result2['score']*2 and result1['token_str'] == DATASET_SYMBOL) or\\\n                   (result2['score'] > result1['score']*2 and result2['token_str'] == NONDATA_SYMBOL):\n                    pred_bag.add(clean_text(phrase))\n\n        # filter labels by jaccard score \n        filtered_labels = []\n\n        for label in sorted(pred_bag, key=len, reverse=True):\n            if len(filtered_labels) == 0 or all(jaccard_similarity(label, got_label) < 0.75 for got_label in filtered_labels):\n                filtered_labels.append(label)\n\n        pred_mlm_labels.append('|'.join(filtered_labels))\n    \n    pred_mlm_labels[:5]","424dc9ea":"def read_append_return(filename, train_files_path=train_files_path, output='text'):\n    \"\"\"\n    json \u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u53d6\u308a\u3001\u305d\u3053\u304b\u3089\u30c6\u30ad\u30b9\u30c8 \u30c7\u30fc\u30bf\u3092\u8fd4\u3057\u3001\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u306b\u8ffd\u52a0\u3059\u308b\u95a2\u6570\n    \"\"\"\n    json_path = os.path.join(train_files_path, (filename+'.json'))\n    headings = []\n    contents = []\n    combined = []\n    with open(json_path, 'r') as f:\n        json_decode = json.load(f)\n        for data in json_decode:\n            headings.append(data.get('section_title'))\n            contents.append(data.get('text'))\n            combined.append(data.get('section_title'))\n            combined.append(data.get('text'))\n    \n    all_headings = ' '.join(headings)\n    all_contents = ' '.join(contents)\n    all_data = '. '.join(combined)\n    \n    if output == 'text':\n        return all_contents\n    elif output == 'head':\n        return all_headings\n    else:\n        return all_data\n    \n    \ndef text_cleaning(text):\n    '''\n    \u3059\u3079\u3066\u306e\u30c6\u30ad\u30b9\u30c8\u3092\u5c0f\u6587\u5b57\u306b\u5909\u63db\u3057\u3001\u7279\u6b8a\u6587\u5b57\u3001\u7d75\u6587\u5b57\u3001\u8907\u6570\u306e\u30b9\u30da\u30fc\u30b9\u3092\u524a\u9664\u3057\u307e\u3059\u3002\u30c6\u30ad\u30b9\u30c8 - \u30af\u30ea\u30fc\u30f3\u30a2\u30c3\u30d7\u304c\u5fc5\u8981\u306a\u6587\n    '''\n    text = ''.join([k for k in text if k not in string.punctuation])\n    text = re.sub('[^A-Za-z0-9]+', ' ', str(text).lower()).strip()\n    # text = re.sub(\"\/'+\/g\", ' ', text)\n    return text","35bba7c7":"if BASELINE_HELPING or ALL_BLENDED:\n    tqdm.pandas()\n\n    train['text'] = train['Id'].progress_apply(read_append_return)\n\n    if not COMPUTE_CV:\n        sample_submission['text'] = sample_submission['Id'].progress_apply(partial(read_append_return, train_files_path=test_files_path))\n\n    train.head()","3561b4cb":"if BASELINE_HELPING or ALL_BLENDED:\n    tqdm.pandas()\n    \n    train['text'] = train['text'].progress_apply(text_cleaning)","9cd6c072":"if BASELINE_HELPING or ALL_BLENDED:\n    temp_1 = [x.lower() for x in train['dataset_label'].unique()]\n    temp_2 = [x.lower() for x in train['dataset_title'].unique()]\n    temp_3 = [x.lower() for x in train['cleaned_label'].unique()]\n\n    existing_labels = set(temp_1 + temp_2 + temp_3)\n\n    print(f'len(temp_1) = {len(temp_1)}')\n    print(f'len(temp_2) = {len(temp_2)}')\n    print(f'len(temp_3) = {len(temp_3)}')\n    print(f'len(existing_labels) = {len(existing_labels)}')\n\n    id_list = []\n    lables_list = []\n    for index, row in tqdm(sample_submission.iterrows()):\n        sample_text = row['text']\n        row_id = row['Id']\n        temp_df = train[train['text'] == text_cleaning(sample_text)]\n        cleaned_labels = temp_df['cleaned_label'].to_list()\n\n        for known_label in existing_labels:\n            if known_label in sample_text.lower():\n                cleaned_labels.append(clean_text(known_label))\n\n        cleaned_labels = [clean_text(x) for x in cleaned_labels]\n        cleaned_labels = set(cleaned_labels)\n        lables_list.append('|'.join(cleaned_labels))\n        id_list.append(row_id)","c7e351e8":"pred_mlm_labels","af1ab26a":"final_predictions = []\n\nif ALL_BLENDED:\n    for literal_match, mlm_pred, lables_match in zip(literal_preds, pred_mlm_labels, lables_list):\n        temp = [literal_match, mlm_pred, lables_match]\n        temp = [pred for pred in temp if pred]\n        temp = ('|').join(temp)\n        final_predictions.append(temp)\n        \nelif BASELINE_HELPING:\n    for literal_match, mlm_pred, lables_match in zip(literal_preds, pred_mlm_labels, lables_list):\n        if literal_match:\n            final_predictions.append(literal_match)\n        elif lables_match:\n            final_predictions.append(lables_match)\n        else:\n            final_predictions.append(mlm_pred)\n\nelif MATCH_ONLY:\n    final_predictions = literal_preds\n\nelif MLM_ONLY:\n    final_predictions = pred_mlm_labels\n\nelif THEO_MERGE:\n    for i in range(len(literal_preds)):\n        pred_naive = literal_preds[i].split('|')\n        pred_model = pred_mlm_labels[i].split('|')\n        pred_model_kept = []\n        for pred_m in pred_model:\n            kept = True\n            for pred_n in pred_naive:\n                if pred_m in pred_n or pred_n in pred_m:\n                    kept = False\n            if kept:\n                pred_model_kept.append(pred_m)\n        final_predictions.append(\"|\".join(pred_naive + pred_model_kept))\n\nelse:\n    for literal_match, mlm_pred in zip(literal_preds, pred_mlm_labels):\n        if literal_match:\n            final_predictions.append(literal_match)\n        else:\n            final_predictions.append(mlm_pred)\n\nsample_submission['PredictionString'] = final_predictions","3bc1467e":"sample_submission['PredictionString'] = final_predictions\nsample_submission[['Id', 'PredictionString']].to_csv('submission.csv', index=False)\n\nsample_submission.head()","157f03f0":"# https:\/\/www.kaggle.com\/c\/coleridgeinitiative-show-us-the-data\/discussion\/230091\ndef compute_fbeta(y_true: List[List[str]],\n                  y_pred: List[List[str]],\n                  beta: float = 0.5) -> float:\n    \"\"\"Compute the Jaccard-based micro FBeta score.\n\n    References\n    ----------\n    - https:\/\/www.kaggle.com\/c\/coleridgeinitiative-show-us-the-data\/overview\/evaluation\n    \"\"\"\n\n    def _jaccard_similarity(str1: str, str2: str) -> float:\n        a = set(str1.split()) \n        b = set(str2.split())\n        c = a.intersection(b)\n        return float(len(c)) \/ (len(a) + len(b) - len(c))\n\n    tp = 0  # true positive\n    fp = 0  # false positive\n    fn = 0  # false negative\n    for ground_truth_list, predicted_string_list in zip(y_true, y_pred):\n        predicted_string_list_sorted = sorted(predicted_string_list)\n        for ground_truth in sorted(ground_truth_list):            \n            if len(predicted_string_list_sorted) == 0:\n                fn += 1\n            else:\n                similarity_scores = [\n                    _jaccard_similarity(ground_truth, predicted_string)\n                    for predicted_string in predicted_string_list_sorted\n                ]\n                matched_idx = np.argmax(similarity_scores)\n                if similarity_scores[matched_idx] >= 0.5:\n                    predicted_string_list_sorted.pop(matched_idx)\n                    tp += 1\n                else:\n                    fn += 1\n        fp += len(predicted_string_list_sorted)\n\n    tp *= (1 + beta ** 2)\n    fn *= beta ** 2\n    fbeta_score = tp \/ (tp + fp + fn)\n    return fbeta_score","65b36313":"if COMPUTE_CV:\n    COMPUTE_CV_SCORE = compute_fbeta(sample_submission['cleaned_label'].apply(lambda x: [x]),\\\n                  sample_submission['PredictionString'].apply(lambda x: x.split('|')))\n    print('COMPUTE_CV_SCORE =', COMPUTE_CV_SCORE)\nelse:\n    print(f'COMPUTE_CV = {COMPUTE_CV}')\n    \nprint(f'EDA_DEMO = {EDA_DEMO}')\nprint(f'ALL_BLENDED = {ALL_BLENDED}')\nprint(f'BASELINE_HELPING = {BASELINE_HELPING}')\nprint(f'MATCH_ONLY = {MATCH_ONLY}')\nprint(f'MLM_ONLY = {MLM_ONLY}')\nprint(f'KEN_MATCHING = {KEN_MATCHING}')\nprint(f'BS_CLEANING = {BS_CLEANING}')\nprint(f'THEO_MERGE = {THEO_MERGE}')\nprint(f'SEED = {SEED}')","fe19fd42":"\ud83c\udf89\u30a8\u30f3\u30b3\u30fc\u30c0\u30fc\u306fAutoTokenizer.from_pretrained()\u3067\u547c\u3073\u51fa\u305b\u307e\u3059\u3002bert-base-japanese\u306fWikipedia\u306e\u65e5\u672c\u8a9e\u7248\u3067\u4e8b\u524d\u5b66\u7fd2\u6e08\u307f\u306e\u30b5\u30d6\u30ef\u30fc\u30c9\u8f9e\u66f8\u3068\u306a\u308a\u307e\u3059\u3002\u4eca\u56de\u306f\u3001\u65e5\u672c\u8a9e\u306f\u4f7f\u3044\u307e\u305b\u3093\u306e\u3067\u3001'..\/input\/coleridge-mlm-model\/model_tokenizer'\u3092\u4f7f\u3063\u3066\u3044\u307e\u3059\u3002","f1fe8577":"# About\n\n\u3053\u306e\u30b3\u30f3\u30da\u30c6\u30a3\u30b7\u30e7\u30f3\u306f\u3001\u30c7\u30fc\u30bf \u30b5\u30a4\u30a8\u30f3\u30c6\u30a3\u30b9\u30c8\u306b\u3001\u516c\u7684\u8cc7\u91d1\u306b\u3088\u308b\u30c7\u30fc\u30bf\u304c\u79d1\u5b66\u3068\u793e\u4f1a\u306b\u3069\u306e\u3088\u3046\u306b\u4f7f\u7528\u3055\u308c\u3066\u3044\u308b\u304b\u3092\u793a\u3059\u3053\u3068\u3092\u6c42\u3081\u3066\u3044\u307e\u3059\u3002\u653f\u5e9c\u304c\u793e\u4f1a\u304c\u76f4\u9762\u3057\u3066\u3044\u308b\u591a\u304f\u306e\u8105\u5a01\u306b\u5bfe\u51e6\u3059\u308b\u305f\u3081\u306b\u306f\u3001\u30c7\u30fc\u30bf\u306b\u3088\u308b\u8a3c\u62e0\u304c\u91cd\u8981\u3067\u3059\u3002\u30d1\u30f3\u30c7\u30df\u30c3\u30af\u3001\u6c17\u5019\u5909\u52d5\u3001\u30a2\u30eb\u30c4\u30cf\u30a4\u30de\u30fc\u75c5\u3001\u5b50\u4f9b\u306e\u98e2\u9913\u3001\u98df\u7ce7\u751f\u7523\u306e\u5897\u52a0\u3001\u751f\u7269\u591a\u69d8\u6027\u306e\u7dad\u6301\u3001\u305d\u306e\u4ed6\u591a\u304f\u306e\u8ab2\u984c\u3078\u306e\u53d6\u308a\u7d44\u307f\u3002\u3057\u304b\u3057\u3001\u8a3c\u62e0\u3084\u79d1\u5b66\u306b\u60c5\u5831\u3092\u63d0\u4f9b\u3059\u308b\u305f\u3081\u306b\u5fc5\u8981\u306a\u30c7\u30fc\u30bf\u306b\u95a2\u3059\u308b\u60c5\u5831\u306e\u591a\u304f\u306f\u3001\u51fa\u7248\u7269\u306e\u4e2d\u306b\u9589\u3058\u8fbc\u3081\u3089\u308c\u3066\u3044\u307e\u3059\u3002\n\n\u81ea\u7136\u8a00\u8a9e\u51e6\u7406\u306f\u3001\u76ee\u306b\u898b\u3048\u306a\u3044\u30c7\u30fc\u30bf\u306e\u5f15\u7528\u3092\u898b\u3064\u3051\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u304b?\u6a5f\u68b0\u5b66\u7fd2\u306f\u3001\u7814\u7a76\u8a18\u4e8b\u3067\u4f7f\u7528\u3055\u308c\u3066\u3044\u308b\u5358\u8a9e\u3068\u8a18\u4e8b\u3067\u53c2\u7167\u3055\u308c\u3066\u3044\u308b\u30c7\u30fc\u30bf\u3068\u306e\u9593\u306e\u30ea\u30f3\u30af\u3092\u898b\u3064\u3051\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u304b?\n\n\u4eca\u3053\u305d\u3001\u30c7\u30fc\u30bf \u30b5\u30a4\u30a8\u30f3\u30c6\u30a3\u30b9\u30c8\u304c\u30c7\u30fc\u30bf\u3068\u8a3c\u62e0\u3078\u306e\u4fe1\u983c\u3092\u56de\u5fa9\u3059\u308b\u624b\u52a9\u3051\u3092\u3059\u308b\u3068\u304d\u3067\u3059\u3002\u7c73\u56fd\u3067\u306f\u3001\u9023\u90a6\u6a5f\u95a2\u306f\u73fe\u5728\u3001\u30c7\u30fc\u30bf\u304c\u3069\u306e\u3088\u3046\u306b\u4f7f\u7528\u3055\u308c\u3066\u3044\u308b\u304b\u3092\u793a\u3059\u3053\u3068\u304c\u7fa9\u52d9\u4ed8\u3051\u3089\u308c\u3066\u3044\u307e\u3059\u3002\u65b0\u3057\u3044\u6839\u62e0\u306b\u57fa\u3065\u304f\u653f\u7b56\u7acb\u6848\u6cd5\u3067\u306f\u3001\u653f\u5e9c\u6a5f\u95a2\u306f\u30c7\u30fc\u30bf\u7ba1\u7406\u3092\u6700\u65b0\u5316\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\u65b0\u3057\u3044\u5927\u7d71\u9818\u4ee4\u306b\u3088\u308a\u3001\u653f\u5e9c\u6a5f\u95a2\u306f\u3001\u5165\u624b\u53ef\u80fd\u306a\u6700\u826f\u306e\u30c7\u30fc\u30bf\u3068\u79d1\u5b66\u306b\u57fa\u3065\u3044\u3066\u8a3c\u62e0\u306b\u57fa\u3065\u3044\u305f\u6c7a\u5b9a\u3092\u884c\u3046\u3088\u3046\u6c42\u3081\u3089\u308c\u3066\u3044\u307e\u3059\u3002\u305d\u3057\u3066\u653f\u5e9c\u306f\u3001\u30aa\u30fc\u30d7\u30f3\u3067\u900f\u660e\u306a\u65b9\u6cd5\u3067\u5bfe\u5fdc\u3059\u308b\u305f\u3081\u306b\u53d6\u308a\u7d44\u3093\u3067\u3044\u307e\u3059\u3002\n\n\u3053\u306e\u30b3\u30f3\u30c6\u30b9\u30c8\u306f\u3001\u307e\u3055\u306b\u305d\u306e\u3088\u3046\u306a\u30aa\u30fc\u30d7\u30f3\u3067\u900f\u660e\u306a\u30a2\u30d7\u30ed\u30fc\u30c1\u3092\u69cb\u7bc9\u3057\u307e\u3059\u3002\u7d50\u679c\u306f\u3001\u516c\u7684\u30c7\u30fc\u30bf\u304c\u79d1\u5b66\u3067\u3069\u306e\u3088\u3046\u306b\u4f7f\u7528\u3055\u308c\u3066\u3044\u308b\u304b\u3092\u793a\u3057\u3001\u653f\u5e9c\u304c\u3088\u308a\u8ce2\u660e\u3067\u900f\u660e\u6027\u306e\u9ad8\u3044\u516c\u5171\u6295\u8cc7\u3092\u884c\u3046\u306e\u306b\u5f79\u7acb\u3061\u307e\u3059\u3002\u3053\u308c\u306b\u3088\u308a\u3001\u7814\u7a76\u8005\u3084\u653f\u5e9c\u306f\u3001\u30a2\u30c9\u30db\u30c3\u30af\u306a\u65b9\u6cd5\u3092\u4f7f\u7528\u3059\u308b\u3053\u3068\u304b\u3089\u3001\u554f\u984c\u3092\u89e3\u6c7a\u3059\u308b\u305f\u3081\u306b\u4f7f\u7528\u3055\u308c\u3066\u3044\u308b\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3001\u751f\u6210\u3055\u308c\u3066\u3044\u308b\u5bfe\u7b56\u3001\u304a\u3088\u3073\u3069\u306e\u7814\u7a76\u8005\u304c\u5c02\u9580\u5bb6\u3067\u3042\u308b\u304b\u3092\u898b\u3064\u3051\u308b\u81ea\u52d5\u5316\u3055\u308c\u305f\u65b9\u6cd5\u306b\u79fb\u884c\u3059\u308b\u306e\u306b\u5f79\u7acb\u3061\u307e\u3059\u3002\u904e\u53bb\u306e\u30b3\u30f3\u30c6\u30b9\u30c8\u3067\u306f\u3001\u30c7\u30fc\u30bf\u3078\u306e\u53c2\u7167\u306e\u691c\u7d22\u3068\u767a\u898b\u3092\u81ea\u52d5\u5316\u3059\u308b\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u958b\u767a\u3067\u304d\u308b\u3053\u3068\u304c\u793a\u3055\u308c\u3066\u3044\u307e\u3059\u3002\u73fe\u5728\u3001\u79c1\u305f\u3061\u306f Kaggle \u30b3\u30df\u30e5\u30cb\u30c6\u30a3\u304c\u79d1\u5b66\u51fa\u7248\u7269\u3067\u4f7f\u7528\u3055\u308c\u308b\u91cd\u8981\u306a\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u7279\u5b9a\u3059\u308b\u305f\u3081\u306e\u6700\u826f\u306e\u30a2\u30d7\u30ed\u30fc\u30c1\u3092\u958b\u767a\u3059\u308b\u3053\u3068\u3092\u671b\u3093\u3067\u3044\u307e\u3059\u3002\n\n\u3053\u306e\u30b3\u30f3\u30c6\u30b9\u30c8\u3067\u306f\u3001\u81ea\u7136\u8a00\u8a9e\u51e6\u7406 (NLP) \u3092\u4f7f\u7528\u3057\u3066\u3001\u79d1\u5b66\u30c7\u30fc\u30bf\u304c\u51fa\u7248\u7269\u3067\u3069\u306e\u3088\u3046\u306b\u53c2\u7167\u3055\u308c\u3066\u3044\u308b\u304b\u306e\u767a\u898b\u3092\u81ea\u52d5\u5316\u3057\u307e\u3059\u3002 CHORUS \u306e\u51fa\u7248\u793e\u306e\u30e1\u30f3\u30d0\u30fc\u3084\u305d\u306e\u4ed6\u306e\u60c5\u5831\u6e90\u304b\u3089\u96c6\u3081\u3089\u308c\u305f\u6570\u591a\u304f\u306e\u7814\u7a76\u5206\u91ce\u304b\u3089\u306e\u79d1\u5b66\u51fa\u7248\u7269\u306e\u5168\u6587\u3092\u5229\u7528\u3057\u3066\u3001\u51fa\u7248\u7269\u306e\u8457\u8005\u304c\u7814\u7a76\u3067\u4f7f\u7528\u3057\u305f\u30c7\u30fc\u30bf \u30bb\u30c3\u30c8\u3092\u7279\u5b9a\u3057\u307e\u3059\u3002\n\n\u6210\u529f\u3057\u305f\u5834\u5408\u306f\u3001\u653f\u5e9c\u30c7\u30fc\u30bf\u306e\u8a3c\u62e0\u3092\u30b5\u30dd\u30fc\u30c8\u3059\u308b\u306e\u306b\u5f79\u7acb\u3061\u307e\u3059\u3002\u81ea\u52d5\u5316\u3055\u308c\u305f NLP \u30a2\u30d7\u30ed\u30fc\u30c1\u306b\u3088\u308a\u3001\u653f\u5e9c\u6a5f\u95a2\u3084\u7814\u7a76\u8005\u306f\u5fc5\u8981\u306a\u60c5\u5831\u3092\u3059\u3070\u3084\u304f\u898b\u3064\u3051\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\u3053\u306e\u30a2\u30d7\u30ed\u30fc\u30c1\u306f\u3001\u30c7\u30fc\u30bf\u4f7f\u7528\u30b9\u30b3\u30a2\u30ab\u30fc\u30c9\u3092\u958b\u767a\u3059\u308b\u305f\u3081\u306b\u4f7f\u7528\u3055\u308c\u3001\u653f\u5e9c\u6a5f\u95a2\u304c\u30c7\u30fc\u30bf\u304c\u3069\u306e\u3088\u3046\u306b\u4f7f\u7528\u3055\u308c\u3066\u3044\u308b\u304b\u3092\u3088\u308a\u3088\u304f\u793a\u3057\u3001\u516c\u958b\u30c7\u30fc\u30bf\u3078\u306e\u30a2\u30af\u30bb\u30b9\u3068\u4f7f\u7528\u306b\u5bfe\u3059\u308b\u91cd\u5927\u306a\u969c\u58c1\u3092\u53d6\u308a\u9664\u304f\u305f\u3081\u306b\u4f7f\u7528\u3055\u308c\u307e\u3059\u3002\n\n\u30b3\u30fc\u30eb\u30ea\u30c3\u30b8 \u30a4\u30cb\u30b7\u30a2\u30c1\u30d6\u306f\u3001\u793e\u4f1a\u7684\u5229\u76ca\u306e\u305f\u3081\u306b\u30c7\u30fc\u30bf\u3092\u4f7f\u7528\u3059\u308b\u305f\u3081\u306b\u8a2d\u7acb\u3055\u308c\u305f\u975e\u55b6\u5229\u56e3\u4f53\u3067\u3059\u3002\u7d44\u7e54\u304c\u3053\u308c\u3092\u884c\u3046 1 \u3064\u306e\u65b9\u6cd5\u306f\u3001\u516c\u7684\u306b\u5229\u7528\u53ef\u80fd\u306a\u7814\u7a76\u3092\u901a\u3058\u3066\u79d1\u5b66\u3092\u63a8\u9032\u3059\u308b\u3053\u3068\u3067\u3059\u3002\n","291f68b7":"\ud83c\udf89BASELINE_HELPING or ALL_BLENDED:\u306e\u610f\u5473\u304c\u3088\u304f\u308f\u304b\u3089\u306a\u3044","68709660":"# Baseline Model","bdf07a7a":"|   | CV | LB |\n| --- | --- | --- |\n| s57 adnl_govt_labels |   | 0.573 |\n| 42 w\/ adnl_govt_labels |   | 0.557 |\n| adnl_govt_labels_26897 | 0.136 |   |\n| adnl_govt_labels |   | 0.556 |\n| adnl_govt_labels KEN |   |   |\n| 42 w\/ adnl_govt_labels KEN |   | 0.557 |\n| **RKM adnl_govt_labels w\/ 42** | **0.514** | **0.574** |\n| 42 only |   | 0.154 |\n| RKM adnl_govt_labels BS_CLEANING w\/ 42 |   | 0.568 |\n| RKM adnl_govt_labels_26897 |   | 0.244 |\n| RKM adnl_govt_labels w\/ 42_48 |   | 0.574 |\n| **RKM adnl_govt_labels w\/ 42_36** |   | **0.574** |\n| RKM adnl_govt_labels w\/ 42_60 |   | 0.574 |\n| RKM adnl_govt_labels w\/ 42_24 |   | 0.573 |\n| RKM adnl_govt_labels w\/ 42_60 |   | 0.573 |\n| RKM adnl_govt_labels w\/ 42_60 TM |   | 0.553 |","6628c503":"\ud83c\udf89\u5909\u6570\u306e\u4e2d\u8eab\u3092\u898b\u3066\u307f\u308b\u3002","54998936":"### Matching on test data","7b39d91d":"### Load model and tokenizer","af1a1c3e":"# Install packages","38bda10a":"# \u8a55\u4fa1\u6307\u6a19","3e075be4":"### Transform","2e258662":"\u30d5\u30a1\u30a4\u30eb\ntrain - \u30c8\u30ec\u30fc\u30cb\u30f3\u30b0 \u30bb\u30c3\u30c8\u306e\u51fa\u7248\u7269\u306e JSON \u5f62\u5f0f\u306e\u5168\u6587\u3001\u30bb\u30af\u30b7\u30e7\u30f3 \u30bf\u30a4\u30c8\u30eb\u306e\u3042\u308b\u30bb\u30af\u30b7\u30e7\u30f3\u306b\u5206\u5272\ntest - \u30c6\u30b9\u30c8 \u30bb\u30c3\u30c8\u306e\u767a\u884c\u7269\u306e\u5168\u6587 (JSON \u5f62\u5f0f)\u3001\u30bb\u30af\u30b7\u30e7\u30f3 \u30bf\u30a4\u30c8\u30eb\u4ed8\u304d\u306e\u30bb\u30af\u30b7\u30e7\u30f3\u306b\u5206\u5272\ntrain.csv - \u30c8\u30ec\u30fc\u30cb\u30f3\u30b0 \u30bb\u30c3\u30c8\u306e\u30e9\u30d9\u30eb\u3068\u30e1\u30bf\u30c7\u30fc\u30bf\nsample_submission.csv - \u6b63\u3057\u3044\u5f62\u5f0f\u306e\u30b5\u30f3\u30d7\u30eb\u63d0\u51fa\u30d5\u30a1\u30a4\u30eb\n\ncolumns\nid - \u30d1\u30d6\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3 ID - \u4e00\u90e8\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0 \u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306b\u306f\u8907\u6570\u306e\u884c\u304c\u3042\u308a\u3001\u8907\u6570\u306e\u8a00\u53ca\u3055\u308c\u305f\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u793a\u3057\u3066\u3044\u308b\u3053\u3068\u306b\u6ce8\u610f\u3057\u3066\u304f\u3060\u3055\u3044\npub_title - \u51fa\u7248\u7269\u306e\u30bf\u30a4\u30c8\u30eb (\u540c\u3058\u30bf\u30a4\u30c8\u30eb\u306e\u51fa\u7248\u7269\u304c\u5c11\u6570\u3042\u308a\u307e\u3059)\ndataset_title - \u51fa\u7248\u7269\u5185\u3067\u8a00\u53ca\u3055\u308c\u3066\u3044\u308b\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u30bf\u30a4\u30c8\u30eb\ndataset_label - \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u793a\u3059\u30c6\u30ad\u30b9\u30c8\u306e\u4e00\u90e8\nclean_label - \u8a55\u4fa1\u30da\u30fc\u30b8\u304b\u3089 clean_text \u95a2\u6570\u3092\u4ecb\u3057\u3066\u6e21\u3055\u308c\u308b\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8 \u30e9\u30d9\u30eb ","2a1773d9":"![image.png](attachment:c8cbc8d2-9f78-4f2c-b3ee-72701bc284ad.png)","a10b9220":"\ud83c\udf89\u30c6\u30b9\u30c8\u30d5\u30a9\u30eb\u30c0\u30fc\u304b\u3089json\u30d5\u30a1\u30a4\u30eb\u3092paper\u3068\u3057\u3066\u62fe\u3063\u3066\u3001papers\u3067\u3064\u306a\u3052\u3066\u3044\u308b\u3002","916445e1":"### Predict","fd5cd33d":"#  ****section_title\u304c''\u306e\u3082\u306e\u3092\u9664\u304f\u3002****","f6c506d3":"#### Ken Matching=true MLM_ONLY=False ","6dd50a6f":"\ud83c\udf89\u5909\u6570\u306e\u4e2d\u8eab\u3092\u898b\u3066\u307f\u308b\u3002","c52f1d67":"## submission file","2bc4c98c":"##  \ud83d\uddc3EDA\n![image.png](attachment:f24f1373-f548-4de5-9f19-08c4df93b829.png)","3ddea3ff":"# \u30ca\u30ec\u30c3\u30b8 \u30d0\u30f3\u30af\u3092\u4f5c\u6210\u3059\u308b","0a0d0fc3":"### \u30d1\u30b9\u3068\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf","45f04666":"# \u30de\u30b9\u30af\u3055\u308c\u305f\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8 \u30e2\u30c7\u30ea\u30f3\u30b0\n![image.png](attachment:14b431ff-cca0-4d91-b496-8b0d5fe4cc38.png)","fcfbb42e":"# \u8ffd\u52a0\u306e\u653f\u5e9c\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\n![image.png](attachment:a352b81e-6892-4692-88eb-8b3b6d828a0f.png)","37aba29d":"# Import","3032a648":"\ud83c\udf89train[id]\u3092\u30ad\u30fc\u306b\u3057\u3066\u3001json\u30d5\u30a1\u30a4\u30eb\u3068\u7d71\u5408\u3057\u3066\u3044\u308b\u3002section_title\u304c''\u306e\u3082\u306e\u304c\u3042\u308b\u3002","2065bf42":"# Setting","8dbbda9b":"# Load data","b7333857":"\ud83c\udf89Bert\u30d1\u30c3\u30b1\u30fc\u30b8\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3002\u6587\u7ae0\u7cfb\u306e\u554f\u984c\u306f\u3059\u3054\u3044\u96e3\u3057\u3044\u3093\u3067\u3059\u3088\u306d\u3002","312bcfbb":"\u30b3\u30f3\u30c6\u30b9\u30c8\u306e\u76ee\u7684\u306f\u3001\u79d1\u5b66\u51fa\u7248\u7269\u5185\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3078\u306e\u8a00\u53ca\u3092\u7279\u5b9a\u3059\u308b\u3053\u3068\u3067\u3059\u3002\u3042\u306a\u305f\u306e\u4e88\u6e2c\u306f\u3001\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u6ce8\u76ee\u3057\u3066\u3044\u308b\u3088\u3046\u306b\u898b\u3048\u308b\u51fa\u7248\u7269\u304b\u3089\u306e\u77ed\u3044\u629c\u7c8b\u3067\u3059\u3002\u51fa\u7248\u7269\u5185\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u8b58\u5225\u3059\u308b\u305f\u3081\u306b\u4f7f\u7528\u3055\u308c\u305f\u6b63\u78ba\u306a\u5358\u8a9e\u3068\u3088\u308a\u6b63\u78ba\u306b\u4e00\u81f4\u3059\u308b\u4e88\u6e2c\u306f\u3001\u3088\u308a\u9ad8\u3044\u30b9\u30b3\u30a2\u306b\u306a\u308a\u307e\u3059\u3002\u4e88\u6e2c\u306f\u3001\u9069\u5207\u306a\u4e00\u81f4\u3092\u78ba\u5b9f\u306b\u3059\u308b\u305f\u3081\u306b\u3001\u8a55\u4fa1\u30da\u30fc\u30b8\u306e clean_text \u95a2\u6570\u3092\u4f7f\u7528\u3057\u3066\u30af\u30ea\u30fc\u30f3\u30a2\u30c3\u30d7\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n\n\u51fa\u7248\u7269\u306f JSON \u5f62\u5f0f\u3067\u63d0\u4f9b\u3055\u308c\u3001\u30bb\u30af\u30b7\u30e7\u30f3 \u30bf\u30a4\u30c8\u30eb\u306e\u4ed8\u3044\u305f\u30bb\u30af\u30b7\u30e7\u30f3\u306b\u5206\u5272\u3055\u308c\u307e\u3059\u3002\n\n\u3053\u306e\u30b3\u30f3\u30c6\u30b9\u30c8\u306e\u76ee\u6a19\u306f\u3001\u65e2\u77e5\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u6587\u5b57\u5217\u3092\u4e00\u81f4\u3055\u305b\u308b\u3060\u3051\u3067\u306a\u304f\u3001***NLP \u3068\u7d71\u8a08\u7684\u624b\u6cd5\u3092\u4f7f\u7528\u3057\u3066\u3001\u3053\u308c\u307e\u3067\u898b\u305f\u3053\u3068\u306e\u306a\u3044\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u4e00\u822c\u5316\u3059\u308b\u3053\u3068\u3067\u3059***\u3002\u516c\u958b\u30c6\u30b9\u30c8 \u30bb\u30c3\u30c8\u306e\u516c\u958b\u306e\u30d1\u30fc\u30bb\u30f3\u30c6\u30fc\u30b8\u306f\u3001\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0 \u30bb\u30c3\u30c8\u304b\u3089\u53d6\u5f97\u3055\u308c\u307e\u3059\u3002\u3059\u3079\u3066\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u304c\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3067\u8b58\u5225\u3055\u308c\u305f\u308f\u3051\u3067\u306f\u306a\u3044\u305f\u3081\u3001\u3053\u308c\u3089\u306e\u672a\u78ba\u8a8d\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306f\u3001\u516c\u958b\u30c6\u30b9\u30c8 \u30e9\u30d9\u30eb\u306e\u4e00\u90e8\u3068\u3057\u3066\u4f7f\u7528\u3055\u308c\u3066\u3044\u307e\u3059\u3002\u3053\u308c\u3089\u306f\u3001\u30d7\u30e9\u30a4\u30d9\u30fc\u30c8 \u30c6\u30b9\u30c8 \u30bb\u30c3\u30c8\u306b\u30e9\u30d9\u30eb\u3092\u4ed8\u3051\u308b\u3068\u3044\u3046\u96e3\u3057\u3044\u30bf\u30b9\u30af\u306e\u30ac\u30a4\u30c9\u3068\u3057\u3066\u5f79\u7acb\u3064\u306f\u305a\u3067\u3059\u3002\n\n![image.png](attachment:ddfd8297-1b00-49e3-8a7d-2824401e367a.png)","3bc483ca":"### \u88dc\u52a9\u6a5f\u80fd","82f3314f":"# <br>![image.png](attachment:5517f791-0d14-4c18-9823-8c86c45bd46a.png)\n\nId\u300014316\u500b : \u5b66\u8853\u8ad6\u6587\u306eid\u3067\u3059\u3002train\u30d5\u30a9\u30eb\u30c0\u306b\u306f\u3001\u3053\u306eid + \".json\" \u30d5\u30a1\u30a4\u30eb\u304c\u3042\u308a\u307e\u3059\u3002\u3053\u306ejson\u30d5\u30a1\u30a4\u30eb\u304c\u8ad6\u6587\u306e\u5168\u6587\u7ae0\u306b\u306a\u308a\u307e\u3059\u3002<br>\npub_title 14271\u500b : \u5b66\u8853\u8ad6\u6587\u306e\u51fa\u7248\u7269\u306e\u30bf\u30a4\u30c8\u30eb\u3067\u3059\u3002<br>\ndataset_title 45\u500b : \u30d1\u30d6\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u5185\u3067\u8a00\u53ca\u3055\u308c\u3066\u3044\u308b\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u30bf\u30a4\u30c8\u30eb\u3002(\u203b\u3000\u88fd\u4f5c\u8005\u304c\u547d\u540d\u3057\u305f\u3082\u306e\u3089\u3057\u3044\u3067\u3059\u3002)<br>\ndataset_label 130\u500b : \u3053\u308c\u3092\u4e88\u6e2c\u3057\u307e\u3059\u3002\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u793a\u3059\u30c6\u30ad\u30b9\u30c8\u306e\u4e00\u90e8\u3002\uff08\u203b\u3000\u8ad6\u6587\u7b46\u8005\u304c\u4f7f\u3063\u3066\u3044\u308b\u540d\u524d\u3002\u7701\u7565\u306a\u3069\u3042\u308b\u305f\u3081\u3001dataset_title\u3088\u308a\u6570\u304c\u591a\u3044\u3089\u3057\u3044\u3067\u3059\u3002)<br>\ncleaned_label 130\u500b : evaluation\u9805\u76ee\u306b\u3042\u308b\u3088\u3046\u306b\u3001dataset_label\u3092\u5c0f\u6587\u5b57\u3068\u304b\u304d\u308c\u3044\u306b\u6574\u5f62\u3057\u305f\u3082\u306e\u3067\u3059\u3002submission\u306f\u3053\u306e\u5f62\u306b\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059(\u95a2\u6570\u901a\u3059\u3060\u3051\u3067\u3059)<br>\n\u5168\u90e8\u306e\u884c\u306f19661\u500b\u3042\u308b\u306e\u306b\u3001\u305f\u3044\u3057\u3066\u305d\u308c\u305e\u308c\u91cd\u8907\u3057\u3066\u3044\u308b\u3082\u306e\u304c\u3042\u308b\u3002\n","8838bc99":"#\u30c7\u30fc\u30bf\u3092 MLM \u5f62\u5f0f\u306b\u5909\u63db\u3059\u308b"}}