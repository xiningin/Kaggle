{"cell_type":{"ec013ef0":"code","0a6dc836":"code","610e9166":"code","757aadda":"code","2fb3c94a":"code","6710e16a":"code","2d168c94":"code","145b1ed9":"code","1ea00beb":"code","86b0c4ad":"code","e2f06db2":"code","cb0c834f":"code","3e5d78d3":"code","86b49fd4":"code","38f6a461":"code","d9990e48":"code","6baaa3dc":"markdown","8e97af15":"markdown","667a0ec6":"markdown","83d73541":"markdown","6d388ccb":"markdown","d398002a":"markdown","f4588c45":"markdown","aafbc454":"markdown","c6f40dfe":"markdown","f1490432":"markdown"},"source":{"ec013ef0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0a6dc836":"DF_GP_OD2 = pd.read_csv(\"..\/input\/gufhtugu-publications-dataset-challenge\/GP Orders - 2.csv\",encoding=\"unicode_escape\", delimiter=',')\nDF_GP_OD4 = pd.read_csv(\"..\/input\/gufhtugu-publications-dataset-challenge\/GP Orders - 4.csv\",encoding=\"unicode_escape\", delimiter=',')","610e9166":"#TO KNOW OVERALL RECORDS IN DATAFRAME\nDF_GP_OD2.shape","757aadda":"#TO GET FIRST FIVE RECORDS\nDF_GP_OD2.head()","2fb3c94a":"DF_GP_OD2 = DF_GP_OD2.rename(columns={'Order Number': 'Order_No',\"Order Status\":\"Order_Status\", \"Book Name\":\"Book_Name\",\"Order Date\":\"Order_Date\",\"City (Billing)\":\"Billing_City\"})\nDF_GP_OD2.head()","6710e16a":"#TO KNOW OVERALL DATA STATS: It will only show numerical column stats i.e, order number\nDF_GP_OD2.describe()","2d168c94":"# get the number of missing data points per column\nmissing_values_count = DF_GP_OD2.isnull().sum()\nmissing_values_count","145b1ed9":"# filling a null values using fillna()  \nDF_GP_OD2[\"Book_Name\"].fillna(\"NAN\", inplace = True) \nDF_GP_OD2[\"Billing_City\"].fillna(\"NAN\", inplace = True) ","1ea00beb":"# check order date format and type\nprint(DF_GP_OD2['Order_Date'].head())","86b0c4ad":"# create a new column, date_parsed, with the parsed dates\nDF_GP_OD2['Order_date_parsed'] = pd.to_datetime(DF_GP_OD2['Order_Date'], format=\"%m\/%d\/%Y %H:%M\")\n#DF_GP_OD2['Order_date_parsed'] = pd.to_datetime(DF_GP_OD2['Order_Date'], infer_datetime_format=True)\nDF_GP_OD2['Order_date_parsed'].head()","e2f06db2":"# try to get the day of the month from the date column\nday_of_month_orders = DF_GP_OD2['Order_date_parsed'].dt.day\n# plot the day of the month\nsns.distplot(day_of_month_orders, kde=False, bins=31)","cb0c834f":"# to get stats based on different features available\n\nDF_GP_OD2.Order_No.describe()\nDF_GP_OD2.Billing_City.describe()\nDF_GP_OD2.Book_Name.describe()","3e5d78d3":"# to get unique values based on different features available\nDF_GP_OD2.Billing_City.unique()\nDF_GP_OD2.Book_Name.unique()","86b49fd4":"# to group data\nDF_GP_OD2.Book_Name.value_counts()\nDF_GP_OD2.groupby('Book_Name').Book_Name.count()\n\n\nDF_GP_OD2.Billing_City.value_counts()\nDF_GP_OD2.groupby('Billing_City').Billing_City.count()\n\n\nDF_BOOKPERCITY = DF_GP_OD2.groupby(['Book_Name', 'Billing_City']).apply(lambda df: DF_GP_OD2.loc[DF_GP_OD2.Order_No.idxmax()])\n","38f6a461":"# most purchased book in any city\nbook_orders_per_city = DF_GP_OD2.groupby(['Book_Name', 'Billing_City']).Book_Name.agg([len])\nbook_orders_per_city.sort_values(by='len', ascending=False)","d9990e48":"# most purchased book at any date\nbook_orders_at_date = DF_GP_OD2.groupby(['Book_Name', 'Order_date_parsed']).Book_Name.agg([len])\nbook_orders_at_date.sort_values(by='len', ascending=False)","6baaa3dc":"Shape() will show the overall rows and columns available in databaset.","8e97af15":"Describe() will show overall statistics against numerical columns only","667a0ec6":"To check overall missing values in dataset.","83d73541":"Next Phase:\n* To scale and normalize the features\n* To add feature visalization ","6d388ccb":"Rename() is used to apply proper columns names.","d398002a":"Please Upvote if you find the notebook interesting.\nThis notebook is under MIT License Feel free to copy and edit it.\n\n[Follow me](https:\/\/www.kaggle.com\/kk2033\/)\n\nThank you.","f4588c45":"Data is grouped based on different features.","aafbc454":"This will parse the order date feature to make date consistent.","c6f40dfe":"Head() will show the frist 5 records","f1490432":"Based on the missing values (missing_values_count), fillna() is used to fill missing values in book name and billing city feature."}}