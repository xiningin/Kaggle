{"cell_type":{"48026c47":"code","97e0bed4":"code","c4a2c596":"code","f1266e4b":"code","727ebdfe":"code","cac63729":"code","d210ddc8":"code","c21d53d5":"code","d6a3c0a6":"code","2dd6aeb3":"code","d5dbc10d":"code","cd9f5c76":"code","1ff7cb6f":"code","a57d74dd":"code","6d9a1c88":"code","74f5941a":"code","35fe2489":"code","79aff501":"code","6afce243":"code","4675a684":"code","977ac6de":"code","9f7208ee":"code","fd97d28c":"code","9b99750a":"code","f7ef1310":"code","c02a1ef7":"code","4c4b8a39":"code","53dd900e":"code","13ab7848":"code","26c4f138":"code","6f75952a":"code","14ccf618":"code","f9410c0b":"code","1ff6da9f":"code","4f5037e7":"code","9be96bc1":"code","2a9d7e04":"code","a1f4bea3":"code","fb7ea442":"code","603abf09":"code","1336cddc":"code","4006ef71":"code","81998557":"code","716e2581":"code","fa3b99e7":"code","5019097c":"code","68af5228":"code","c5d09815":"code","c412b2d2":"code","6e61b94c":"code","050827b6":"code","13388a91":"code","7f58331d":"code","9e9a0627":"code","70a3be6a":"code","e7e8d00b":"code","6d8af26e":"code","59edb409":"code","99a73b1f":"code","b2a1cf40":"code","b3cd75cd":"code","ad09d3d5":"code","8f227544":"code","9e6805da":"code","a04095a2":"markdown","8ca33f05":"markdown","4eabf54b":"markdown","731d4162":"markdown","7424f054":"markdown","23c1c508":"markdown","a1ef372b":"markdown","06367a6d":"markdown","1c698243":"markdown","fefc7e71":"markdown","72a3ebab":"markdown","3f28cf1e":"markdown","cb116773":"markdown","40a657f9":"markdown","3b777263":"markdown","b581f119":"markdown","e0b3162a":"markdown","ae45ff8b":"markdown","4b417c9f":"markdown","0bd957e0":"markdown","b3e74bb8":"markdown","9e7d9ec7":"markdown","6557f002":"markdown","91885b67":"markdown","964389d5":"markdown","876fd2fb":"markdown","4581a3d3":"markdown","cd9ddaab":"markdown","b670e2b4":"markdown","fa88e143":"markdown","882eaf10":"markdown","a750db6a":"markdown","027df8fd":"markdown","a8413df8":"markdown","6ca89ab9":"markdown","254a5264":"markdown","aef49198":"markdown","63d6ab48":"markdown","6a1b4072":"markdown","0c145738":"markdown"},"source":{"48026c47":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","97e0bed4":"import tensorflow as tf\nimport tensorflow_hub as hub\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image\nimport matplotlib.pyplot as plt\nprint('TensorFlow Version :', tf.__version__)\nprint('TensorFlow_Hub Version :', hub.__version__)\n\n# Check if we're using GPU\nprint('GPU','Available!!, Noice' if tf.config.list_logical_devices('GPU') else 'Not Available')","c4a2c596":"labels_csv = pd.read_csv('..\/input\/dog-breed-identification\/labels.csv')","f1266e4b":"labels_csv[70:80]","727ebdfe":"labels_csv.describe()","cac63729":"print(labels_csv['breed'].value_counts()[:10])\nlabels_csv['breed'].value_counts()[:20].plot.bar(figsize=(20,10))","d210ddc8":"labels_csv['breed'].value_counts(normalize=True).plot.bar(logx=False, figsize=(20,10))\nprint(labels_csv['breed'].value_counts().median())","c21d53d5":"Image('..\/input\/dog-breed-identification\/train\/0042188c895a2f14ef64a918ed9c7b64.jpg')","d6a3c0a6":"Image('..\/input\/dog-breed-identification\/train\/01e787576c003930f96c966f9c3e1d44.jpg')","2dd6aeb3":"# Create pathnames from image ID's\nfilenames = []","d5dbc10d":"filenames = []\nfor filename in labels_csv['id']:\n    filenames.append('..\/input\/dog-breed-identification\/train\/' + filename + '.jpg')\nfilenames[:10]","cd9f5c76":"# Check if number of filenames are equal to number of actual image files.\nimport os\nif len(os.listdir('..\/input\/dog-breed-identification\/train\/')) == len(filenames):\n    print('Yes ! they match')\nelse:\n    print('No, they don\\'t')","1ff7cb6f":"print(labels_csv['breed'][9000])\nImage(filenames[9000])","a57d74dd":"labels = labels_csv['breed']\nlabels = np.array(labels)\nlabels\n\n# Or we can ,\n# labels = labels_csv['breed'].to_numpy()","6d9a1c88":"len(labels)","74f5941a":"# Check if number of labels are equal to number of filenames.\nimport os\nif len(filenames) == len(labels):\n    print('Yessssss ! no missing values ;-)')\nelse:\n    print('Nooooo ! Look\\'s like we have missing values to deal with')","35fe2489":"# Let's find unique label values.\nunique_breeds = np.unique(labels)\nunique_breeds\n","79aff501":"len(unique_breeds)","6afce243":"print(labels[0])\nlabels[0] == unique_breeds","4675a684":"boolean_labels = [label == unique_breeds for label in labels]\nboolean_labels[:2]","977ac6de":"from sklearn.model_selection import train_test_split\nX = filenames\ny = boolean_labels","9f7208ee":"# Splitting into train and validation set.\nX_train, X_valid, y_train, y_valid = train_test_split(X[:1000], y[:1000], test_size = 0.2, random_state = 42)\n\n# Checking the dimensions of train and validation set\nlen(X_train), len(X_valid), len(y_train), len(y_valid)","fd97d28c":"# Let's look if everything is fine.\nX_train[:1], y_train[:1]","9b99750a":"from matplotlib.pyplot import imread\nimage = imread(filenames[30])\nimage.shape","f7ef1310":"image.max(), image.min()","c02a1ef7":"tf.constant(image)","4c4b8a39":"# Define image size\n#IMG_SIZE = 224\n\n# Create a function that preprocessess images\ndef image_process(image_path):\n    '''\n    Takes an image filepath and converts image into a tensor\n    '''\n    # Read image file\n    image = tf.io.read_file(image_path)\n    \n    # Turn the jpg image into numerical tensor with 3 colour channels (red, green, blue)\n    image = tf.image.decode_jpeg(image, channels = 3)\n    \n    # Convert the colour channel values from 0-255 to 0-1 values\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    \n    # Resize the image (224,224)\n    image = tf.image.resize(image, size = [224,224])\n    \n    return image","53dd900e":"# Creating a function that return a tuple of image and tensor [(image, tensor)]\ndef get_image_label(image_path, label):\n    '''\n    Takes an image filepath name and the associated label,\n    processes the image and returns a tuple of (image, label)\n    '''\n    image = image_process(image_path)\n    return image, label","13ab7848":"# Creating a function to turn data into batches.\ndef data_batcher(X, y=None, batch_size = 32, valid_data = False, test_data = False):\n    '''\n    Creates batches of data out of image (X) and label (y) pairs.\n    It shuffles if it's training data, but won't if it's validation data.\n    Also accepts test data as input (it doesn't have labels).\n    '''\n    \n    # If the data is test data, we won't have labels\n    if test_data:\n        print('Creating test data batches...')\n    \n        # Only filepaths, not labels\n        data = tf.data.Dataset.from_tensor_slices((tf.constant(X)))\n        data_batch = data.map(image_process).batch(32)\n        return data_batch\n\n    # If the data is valid dataset, we don't shuffle it.\n    elif valid_data:\n        print('Creating validation data batches...')\n        data = tf.data.Dataset.from_tensor_slices((tf.constant(X), # filepaths\n                                                   tf.constant(y)))# labels\n        data_batch = data.map(get_image_label).batch(32) \n        return data_batch\n    # If the data is training data set\n    else:\n        print('Creating training data batches...')\n        # Turn filepaths and labels into tensors\n        data = tf.data.Dataset.from_tensor_slices((tf.constant(X), # filepaths\n                                                   tf.constant(y))) # labels\n        \n        # Shuffle the pathnames and labels before mapping image processor function\n        # ... is faster than shuffling images\n        data = data.shuffle(buffer_size = len(X))\n        \n        # Create a image, label tuple and turns the image path into a preprocessed image\n        data = data.map(get_image_label)\n        \n        # Turning the training data into batches.\n        data_batch = data.batch(32) \n    return data_batch","26c4f138":"# Create training and validation data batches.\ntrain_data = data_batcher(X_train, y_train)\nval_data = data_batcher(X_valid, y_valid, valid_data = True)","6f75952a":"# Check different attributes of our data batches.\ntrain_data.element_spec, val_data.element_spec","14ccf618":"# Creating a function to view images in a data batch\ndef show_lim_images(images,labels):\n    '''\n    Displays a plot of given number of images and their labels from a data batch.\n    '''\n    # Setting up the fig\n    plt.figure(figsize=(10,10))\n    # Loop through 25 for displaying 25 images\n    for i in range(25):\n        #create subplots (5 rows, 5 columns)\n        ax = plt.subplot(5,5,i+1)\n        # Display an image\n        plt.imshow(images[i])\n        # Add the image lable as title.\n        plt.title(unique_breeds[labels[i].argmax()])\n        # Turn the gridlines off\n        plt.axis('off')","f9410c0b":"train_images, train_labels = next(train_data.as_numpy_iterator()) \nshow_lim_images(train_images, train_labels)","1ff6da9f":"valid_images, valid_labels = next(val_data.as_numpy_iterator()) \nshow_lim_images(valid_images, valid_labels)","4f5037e7":"# Setup input shape to the model.\nINPUT_SHAPE = [None, 224, 224,3] #batch, height, width, colour channels.\n# Setup the output shape of the model.\nOUTPUT_SHAPE = len(unique_breeds)\n# Setup model URL from tensorflow hub.\nMODEL_URL = 'https:\/\/tfhub.dev\/google\/imagenet\/mobilenet_v2_130_224\/classification\/4'","9be96bc1":"def create_model(input_shape = INPUT_SHAPE, output_shape = OUTPUT_SHAPE, model_url = MODEL_URL):\n    print('Building model with : ', MODEL_URL, '...')\n    \n    #Setting up the model layers\n    model = tf.keras.Sequential([\n        hub.KerasLayer(MODEL_URL), #1st layer\/input layer\n        tf.keras.layers.Dense(units = OUTPUT_SHAPE,\n                              activation='softmax')])#2nd\/output layer\n    \n    # Compiling the model\n    model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n                  optimizer=tf.keras.optimizers.Adam(),\n                  metrics=['accuracy'])\n        \n    # Building the model\n    model.build(INPUT_SHAPE)\n    \n    return model    ","2a9d7e04":"model = create_model()\nmodel.summary()","a1f4bea3":"# Create early stopping \nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n                                                  patience=3) ","fb7ea442":"# Build a function to train and return a trained model (100 epochs)\ndef train_model():    \n    \"\"\"\n    Trains a given model and returns the trained version.\n    \"\"\"\n    # Create a model\n    model = create_model()\n    \n    # Create new TensorBoard session everytime we train a model\n    #tensorboard = create_tf_callback()\n\n    # Fit the model to the data passing it the callbacks we created\n    model.fit(x=train_data,\n          epochs=100,\n          validation_data=val_data,\n          validation_freq=1, # check validation metrics every epoch\n          callbacks=[early_stopping])\n  \n    # Return the fitted model.\n    return model","603abf09":"# Fit the model to the data\nmodel = train_model()","1336cddc":"# Make predictions on the validation data (not used to train on)\npredictions = model.predict(val_data, verbose=1)\npredictions[0] # Predictions of one image","4006ef71":"def pred(index):\n    '''\n    Takes index value from the predictions and returns \n    highest confidence level index of the highest confidence value\n    and dog breed.\n    '''\n    max_value = np.max(predictions[index])\n    max_value_index = predictions[index].argmax()\n    breed_at_that_index = unique_breeds[max_value_index]\n    print(f\"Confidence Level for first image : {max_value}\")\n    print(f\"Index for the Max Value : {max_value_index}\")\n    print(f\"Breed at that Index :  {breed_at_that_index}\")","81998557":"pred(0)","716e2581":"# Turn prediction probabilities into their respective label (easier to understand)\ndef get_pred_label(prediction_probabilities):\n  \"\"\"\n  Turns an array of prediction probabilities into a label.\n  \"\"\"\n  return unique_breeds[np.argmax(prediction_probabilities)]\n\n# Get a predicted label based on an array of prediction probabilities\npred_label = get_pred_label(predictions[0])","fa3b99e7":"# Create a function to unbatch.\ndef unbatch(data):\n    '''\n    Takes a dataset(which is in batches), and unbatches it. \n    '''\n    images = []\n    labels = []\n    for image, label in data.unbatch().as_numpy_iterator():\n        images.append(image)\n        labels.append(unique_breeds[np.argmax(label)])\n    return images, labels","5019097c":"val_images, val_labels = unbatch(val_data)\nval_images[0], val_labels[0]","68af5228":"def plot(pred_probs, labels, images, n=1):\n    '''\n    View prediction, actual truth, and image for sample n\n    '''\n    pred_prob, true_label, image = pred_probs[n], labels[n], images[n]\n    \n    #Getting pred \n    pred_label = get_pred_label(pred_prob)\n    \n    # Plot image & remove ticks\n    plt.imshow(image)\n    plt.xticks([])\n    plt.yticks([])\n    \n    # Changing colour, depending upon whether the prediction is right or wrong.\n    if pred_label == true_label:\n        color='green'\n    else:\n        color='red'\n    \n    \n    # Change plot title\n    plt.title('{} - {:2.0f}%\\n{}'.format(pred_label, \n                                   np.max(pred_prob)*100,\n                                   true_label),\n                                   color=color)","c5d09815":"plot(predictions, val_labels, val_images,73)","c412b2d2":"def plot_pred_conf(prediction_probabilities, labels, n=1):\n  \"\"\"\n  Plots the top 10 highest prediction confidences along with\n  the truth label for sample n.\n  \"\"\"\n  pred_prob, true_label = prediction_probabilities[n], labels[n]\n\n  # Get the predicted label\n  pred_label = get_pred_label(pred_prob)\n\n  # Find the top 10 prediction confidence indexes\n  top_10_pred_indexes = pred_prob.argsort()[-10:][::-1]\n  # Find the top 10 prediction confidence values\n  top_10_pred_values = pred_prob[top_10_pred_indexes]\n  # Find the top 10 prediction labels\n  top_10_pred_labels = unique_breeds[top_10_pred_indexes]\n\n  # Setup plot\n  top_plot = plt.bar(np.arange(len(top_10_pred_labels)), \n                     top_10_pred_values, \n                     color=\"black\")\n  plt.xticks(np.arange(len(top_10_pred_labels)),\n             labels=top_10_pred_labels,\n             rotation=\"vertical\")\n\n  # Change color of true label\n  if np.isin(true_label, top_10_pred_labels):\n    top_plot[np.argmax(top_10_pred_labels == true_label)].set_color(\"red\")\n  else:\n    pass","6e61b94c":"plot_pred_conf(prediction_probabilities=predictions,\n               labels=val_labels,\n               n=20)","050827b6":"# Let's check a few predictions and their different values\ni_multiplier = 0\nnum_rows = 3\nnum_cols = 2\nnum_images = num_rows*num_cols\nplt.figure(figsize=(5*2*num_cols, 5*num_rows))\nfor i in range(num_images):\n  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n  plot(pred_probs=predictions,\n            labels=val_labels,\n            images=val_images,\n            n=i+i_multiplier)\n  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n  plot_pred_conf(prediction_probabilities=predictions,\n                labels=val_labels,\n                n=i+i_multiplier)\nplt.tight_layout(h_pad=1.0)\nplt.show()","13388a91":"from datetime import datetime\ndef save_model(model, suffix=None):\n  \"\"\"\n  Saves a given model in a models directory and appends a suffix (str)\n  for clarity and reuse.\n  \"\"\"\n  # Create model directory with current time\n  modeldir = os.path.join(\"\",\n                          datetime.now().strftime(\"%Y%m%d-%H%M%s\"))\n  model_path = modeldir + \"-\" + suffix + \".h5\" # save format of model\n  print(f\"Saving model to: {model_path}...\")\n  model.save(model_path)\n  return model_path","7f58331d":"def load_model(model_path):\n  \"\"\"\n  Loads a saved model from a specified path.\n  \"\"\"\n  print(f\"Loading saved model from: {model_path}\")\n  model = tf.keras.models.load_model(model_path,\n                                     custom_objects={\"KerasLayer\":hub.KerasLayer})\n  return model","9e9a0627":"# Save our model trained on 1000 images\nsave_model(model, suffix=\"1000-images-Adam\")","70a3be6a":"# Turn full training data in a data batch\nfull_data = data_batcher(X, y)","e7e8d00b":"# Instantiate a new model for training on the full dataset\nfull_model = create_model()","6d8af26e":"# Create full model callbacks\nfull_model_early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\",\n                                                             patience=3)","59edb409":"# Fit the full model to the full training data\nfull_model.fit(x=full_data,\n               epochs=5,\n               callbacks=[full_model_early_stopping])","99a73b1f":"save_model(full_model, suffix=\"all-images-Adam\")","b2a1cf40":"# Load test image filenames (since we're using os.listdir(), these already have .jpg)\ntest = \"\/kaggle\/input\/dog-breed-identification\/test\/\"\ntest_filenames = [test + fname for fname in os.listdir(test_path)]\n\ntest_filenames[:10]","b3cd75cd":"# Create test data batch\ntest_data = data_batcher(test_filenames, test_data=True)","ad09d3d5":"# Make predictions on test data batch using the loaded full model\ntest_preds = full_model.predict(test_data,\n                                             verbose=1)","8f227544":"# Creating pandas DataFrame with empty columns\nsubm_df = pd.DataFrame(columns=[\"id\"] + list(unique_breeds))\n# Append test image ID's to predictions DataFrame\ntest = \"\/kaggle\/input\/dog-breed-identification\/test\/\"\nsubm_df[\"id\"] = [os.path.splitext(path)[0] for path in os.listdir(test)]\n# Add the prediction probabilities to each dog breed column\nsubm_df[list(unique_breeds)] = test_predictions\nsubm_df.head()","9e6805da":"# Taking a .csv output for submission\nsubm_df.to_csv(\"Submissions.csv\",\n                 index=False)","a04095a2":"Since we've a list of training image filepaths, it's time to prepare our labels.","8ca33f05":"WOAHHH ! What a beast, looks like a lion.","4eabf54b":"Looking at the accuracy and difference between accuracy and val_accuracy, it seems that the model is overfitting.\n\nWhile it is doing exceptionally good on training data, it's not doing that good on validation data.","731d4162":"Let's save this model.","7424f054":"Lets make some callbacks too.","23c1c508":"We can almost convert anything into a tensor using `tf.constant()`","a1ef372b":"Awesome ! Since we had 120 breed of dogs.\n\nNow let's turn labels into boolean array.","06367a6d":"## Saving a model","1c698243":"## Callbacks\n\nCallbacks are like checkpoints that we have in games, it checks progress or stop training if there's no significant improvement in model.\n\nSo now we create a callback, \n* To stop the model early, if it's training for too long, because that'll lead to overfitting.\n\n\n### Stopping Callback\n\nSometimes the model keeps on training evem though there is no improvement, which will cause overfitting. At times like that we use a callback to stop the model to train.","fefc7e71":"We should know that for model training purposes, it's recommended that we use about 100 annotations per label, with minumum of 10 annotations.\n\nWhat it means is, if we had atleast 100 values\/images per each breed, our model would learn really good. \n\nBut that's not the case here. We have roughly 82 images per breed.\n\nAnyway, let's continue.\n\nLet's try and view an image.\n\nSince `scottish_deerhound` is the most common breed, let's take a look at it.","72a3ebab":"Now that we've our inputs, outputs and model all set up, let's use `Keras` api from `TensorFlow` for creating deep learning model.\n\nLet's create a function which:\n1. Takes input, output shape along with model we've chosen.\n2. Defines layers in the `Keras` model(Sequential fashion).\n3. Compiles the model.\n4. Builds the model.\n5. Returns the model.\n\nSource : https:\/\/www.tensorflow.org\/guide\/keras\/overview","3f28cf1e":"## Preprocessing the images.\n\nIt's time to convert images into tensors :\n1. Take an image filepath as input\n2. Use tensorflow to read the file and save it to a variable, `image`.\n3. Turn `image` ('.jpg') into tensor\n4. Normalize image (convert colour channels from 0-255 to 0-1\n5. Resize `image` to a shape of (224, 224)\n6. Return the modified `image`.\n\nNow before that, let's import an image","cb116773":"Now that we've converted our data into tuple of tensors `(image, label)`, let's turn all of our data(`X & y`) into batches.","40a657f9":"Fitting the model on full data.","3b777263":"## Predictions\n\nMaking predictions with our model returns an array with a different value for each label.\n\nIn this case, making predictions on the validation data (200 images) returns an array (predictions) of arrays, each containing 120 different values (one for each unique dog breed).\n\nThese different values are the probabilities or the likelihood the model has predicted a certain image being a certain breed of dog. The higher the value, the more likely the model thinks a given image is a specific breed of dog.","b581f119":"Now that we've visualized the model's predictions, let's look at the top 10 predictions.","e0b3162a":"# Training a model in full dataset","ae45ff8b":"Let's look at another image,","4b417c9f":"## Importing the necessary libraries","0bd957e0":"Now let's take our `val_data`(which is in batches) and get a list of it, or basically unbatch it.","b3e74bb8":"Let's first train on 1000 images.","9e7d9ec7":"# End to End Multi-class Dog Breed Classification\n\nThis notebook builds an end-to-end multi-class image classifier using TensorFlow 2.0 and TensorFlow Hub\n\n## 1. Problem\nIdentifying the breed of a dog, given the image of a dog.\n\n## 2. Data\nData is available in this competition\n\n## 3. Evaluation\nThe evaluation is a file with prediction probabilities for each dog breed of each test image.\n\n## Features\nThis is unstructured data, since we're dealing with images here, so it is a deep learning problem. ","6557f002":"* Let's take a look at most common dog breed.\n* Also this helps us figure out number of images for each breed.","91885b67":"### EDA","964389d5":"Now in case we had structured data, in order to find the missing values, we had `df.isnull().sum()`.\n\nBut since we're dealing with unstructured data, we have to check for missing values by comparing length of `filenames` and `labels`.","876fd2fb":"Now as humans, we can identify some patterns\/features of this breed. \n\nLet's look at some of the features of this breed :\n\n1. It looks like a large greyhound cloaked in a wiry coat. \n2. This breed has long, slender legs, like a greyhound.\n3. It has relatively narrow body, deep chest, tucked abdomen, arched loin      and long tail.\n4. It is Dolichocephalic (long face).\n\nNow let's see if our model can similarly figure out different features from this data.","4581a3d3":"## Turning data into batches (default=32)\n\nIf you're trying to process 10222 images in one go, they won't fit into the memory.\n\nHence process 32 images at a time.\n\nIn order to use tensorflow effectively, our data has to be in the form of tensor tuples, like this :\n`(image, label)`","cd9ddaab":"## Building the model\n\nBefore building a model, let's define a few things\n1. The input shape(our images in tensors) to our model.\n2. The output shape(image labels, in tensors) of our model.\n3. URL of the model we want to use : https:\/\/tfhub.dev\/google\/imagenet\/mobilenet_v2_130_224\/classification\/4","b670e2b4":"Now let's visualize it.","fa88e143":"* Overall frequency of `breed` column","882eaf10":"## Let's visualize the predictions.\n\nNow we've got ways to get:\n1. Prediction labels\n2. Validation labels(truth labels)\n3. Validation images\n\nLets visualize it with a function.","a750db6a":"Awesome, number of filenames are equal to number of image files.\n\nLet's make one last check.","027df8fd":"## Training\n\nNow we won't train on all of our data, just 1000 images (800-training, 200-validation), As this will save us time.\n\nThe final parameter we'll define before training is NUM_EPOCHS (also known as number of epochs).\n\nNUM_EPOCHS defines number of passes of the data we'd like our model to do.","a8413df8":"## Creating a validation set","6ca89ab9":"Hmmm, lets see according to the model, it's highly probable that the dog in the first image is a `cairn`, with a confidence of 45.13%.  Now this is variable, because we've shuffled the training data.","254a5264":"Hmmm, looks like these are the top 5 most common dog breeds in this data :\n\n\n `scottish_deerhound      126\n maltese_dog             117\n afghan_hound            116\n entlebucher             115\n bernese_mountain_dog    114`","aef49198":"Beautiful, looks like we don't have any missing data.","63d6ab48":"## Visualizing Data Batches\n\nAlthough our data is now in batches, it can be hard to understand.\n\nSo let's visualize it.","6a1b4072":"Now let's map `images` and their `labels` ","0c145738":"## Getting our data(images) ready, by converting it into tensors.\n\nLet's take a look at our labels."}}