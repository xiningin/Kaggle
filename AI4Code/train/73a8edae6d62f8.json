{"cell_type":{"654cca69":"code","ad7115e9":"code","6477cf15":"code","7181b2d8":"code","6b1ecc5d":"code","e6bdf5e7":"code","4d8f9691":"code","6c1e819e":"code","24621ffe":"code","da69c6b7":"code","30f18684":"code","21fcefa9":"code","06067aad":"code","c3776a62":"code","5bd64925":"code","b12d432e":"code","8e41ad49":"code","3b8e4abd":"code","71e4f8b0":"code","cd8fb252":"code","8e5d6726":"code","c6112a04":"code","d35b0de8":"code","438f2e86":"code","9c5a3bb3":"code","64041886":"markdown","3580f2de":"markdown","30ed5532":"markdown","666057f3":"markdown","bedcbc3f":"markdown","c084a3d4":"markdown","1f7a8889":"markdown","56691a0d":"markdown","2fa9a9fc":"markdown","f377626f":"markdown","8721b7aa":"markdown","1e846302":"markdown","c49b1b97":"markdown","3153454c":"markdown","a642b084":"markdown"},"source":{"654cca69":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\n\n\nfrom sklearn.impute import SimpleImputer , KNNImputer\n\nfrom sklearn.preprocessing import StandardScaler ,OneHotEncoder\nfrom sklearn.metrics import mean_squared_error,auc\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,accuracy_score,recall_score,precision_score\nfrom matplotlib.colors import ListedColormap\n\n#os.path.join(path, filename)\n\npd.set_option('display.max_columns', 80)\npd.set_option(\"max_r\", 80)\npd.set_option('display.max_rows', 80)","ad7115e9":"#data = pd.read_csv(os.path.join('..\/input\/neolen-house-price-prediction\/', 'train.csv')\n#test =  pd.read_csv(os.path.join('..\/input\/neolen-house-price-prediction\/', 'test.csv')\ndata = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\nprint(data.shape)\nprint(test.shape)\ndata.head(5)","6477cf15":"data.drop(['Name','PassengerId'],axis = 1 ,inplace=  True)\ntest.drop(['Name'],axis = 1 ,inplace=  True)\nprint(data.info())\nprint(test.info())\ndisplay(data.describe())\ndata['Male'] = pd.get_dummies(data['Sex'],drop_first =True)\ntest['Male'] = pd.get_dummies(test['Sex'],drop_first =True)","7181b2d8":"sns.pairplot(data,hue=\"Survived\", corner=True)\nsns.pairplot(data,hue=\"Male\", corner=True)\nplt.show()","6b1ecc5d":"display(data.loc[ :,['Embarked']].apply(pd.value_counts,axis=0).T)\ndisplay(data.loc[ :,[\"Cabin\"]].apply(pd.value_counts,axis=0).T)\ndisplay(data.loc[ :,['Ticket']].apply(pd.value_counts,axis=0).T)","e6bdf5e7":"\ndisplay(data.loc[:,[\"Embarked\",\"Survived\",'Fare']].groupby([\"Embarked\",\"Survived\"]).agg(count = ('Fare','size')))\n# emparked in c has more chance to servive\n\ndisplay(data.loc[:,[\"Cabin\",\"Survived\",'Fare']].groupby([\"Cabin\",\"Survived\"]).agg(count = ('Fare','size')).T)\n#capin each level can use the latters only not the digits\n\ndisplay(data.loc[:,[\"Ticket\",\"Survived\",'Fare']].groupby([\"Ticket\",\"Survived\"]).agg( count = ('Fare','size')).T)\n# discared the digits on ticket\ndisplay(data.loc[:,[\"Male\",\"Survived\",'Fare']].groupby([\"Male\",\"Survived\"]).agg( count = ('Fare','size')))\n\n\n#display(data.loc[:,[\"Age\",\"Male\",\"Survived\",'Fare']].groupby([\"Age\",\"Male\",\"Survived\"]).agg( count = ('Fare','size')).T)\n\n","4d8f9691":"data[\"AgeGroup\"] =data[\"Age\"].div(10).round(0).add(1).mul(10)\ntest[\"AgeGroup\"] =test[\"Age\"].div(10).round(0).add(1).mul(10)\n\ntrain ,val = train_test_split(data.values.reshape(-1,data.shape[1]),\n                                          test_size=.20, random_state=96, shuffle=True,stratify=data[\"Survived\"])\n\n\ntrain = pd.DataFrame(train,columns= data.columns).astype(data.dtypes.to_dict())\nval =pd.DataFrame(val,columns= data.columns).astype(data.dtypes.to_dict())\ndel(data)\nprint(train.shape)\nprint(val.shape)","6c1e819e":"display(pd.DataFrame(train.isnull().sum()).loc[train.isnull().sum()>0])\ndisplay(pd.DataFrame(val.isnull().sum()).loc[val.isnull().sum()>0])\ndisplay(pd.DataFrame(test.isnull().sum()).loc[test.isnull().sum()>0])","24621ffe":"train[\"CabinGroup\"] =train[\"Cabin\"].fillna('Unkown').str[0]\ndisplay(train.loc[:,[\"CabinGroup\",\"Survived\",'Fare']].groupby([\"CabinGroup\",\"Survived\"]).agg( count = ('Fare','size')).T)\n\nval[\"CabinGroup\"] =val[\"Cabin\"].fillna('Unkown').str[0]\ndisplay(val.loc[:,[\"CabinGroup\",'Fare']].groupby([\"CabinGroup\"]).agg( count = ('Fare','size')).T)\n\ntest[\"CabinGroup\"] =test[\"Cabin\"].fillna('Unkown').str[0]\ndisplay(test.loc[:,[\"CabinGroup\",'Fare']].groupby([\"CabinGroup\"]).agg( count = ('Fare','size')).T)\n\ntrain.drop([\"Cabin\"],axis = 1,inplace =True)\ntest.drop([\"Cabin\"],axis = 1,inplace =True)\nval.drop([\"Cabin\"],axis = 1,inplace =True)","da69c6b7":"hue_order = ['00', '01', '10','11']\n\ng=sns.displot(train.loc[~np.isnan(train[\"Age\"]),[\"AgeGroup\",\"Male\",\"Survived\"]] ,kind=\"kde\",\n            x = \"AgeGroup\",hue= train[\"Survived\"].astype('str') + train[\"Male\"].astype('str') ,hue_order=hue_order)\n\nplt.legend(title='Survived AgeGroup ', loc='upper right', labels=['Not Survived F ', 'Not Survived M', 'Survived F','Survived M '])\nplt.show(g)\n\ntrain[\"AgeGroup\"] =train[\"AgeGroup\"].fillna(\n    train[[\"AgeGroup\",\"Male\",\"Survived\"]].groupby([\"Male\",\"Survived\"])['AgeGroup'].transform(np.median)\n                            )\n\ntrain[\"Age\"] =train[\"Age\"].fillna(\n    train[[\"Age\",\"Male\",\"Survived\"]].groupby([\"Male\",\"Survived\"])['Age'].transform(np.median)\n                            )\n\nval[\"AgeGroup\"] =val[\"AgeGroup\"].fillna(\n    train[[\"AgeGroup\",\"Male\",\"Survived\"]].groupby([\"Male\",\"Survived\"])['AgeGroup'].transform(np.median)\n                            )\nval[\"Age\"] =val[\"Age\"].fillna(\n    train[[\"Age\",\"Male\",\"Survived\"]].groupby([\"Male\",\"Survived\"])['Age'].transform(np.median)\n                            )\n\ntest[\"AgeGroup\"] =test[\"AgeGroup\"].fillna(\n    train[[\"AgeGroup\",\"Male\",\"Survived\"]].groupby([\"Male\",\"Survived\"])['AgeGroup'].transform(np.median)\n                            )\ntest[\"Age\"] =test[\"Age\"].fillna(\n    train[[\"Age\",\"Male\",\"Survived\"]].groupby([\"Male\",\"Survived\"])['Age'].transform(np.median)\n                            )\n\nprint(train[\"AgeGroup\"].isnull().sum(),val[\"AgeGroup\"].isnull().sum(),test[\"AgeGroup\"].isnull().sum())","30f18684":"test['Fare'].fillna(np.median(train['Fare']),inplace=True)\ntrain['Embarked'].fillna(train['Embarked'].mode()[0],inplace=True)\nval['Embarked'].fillna(train['Embarked'].mode()[0],inplace=True)\n","21fcefa9":"train[\"TicketGroup\"] =train[\"Ticket\"].str.replace('\\d+', 'N', regex=True).str[0]\nval[\"TicketGroup\"] =val[\"Ticket\"].str.replace('\\d+', 'N', regex=True).str[0]\ntest[\"TicketGroup\"] =test[\"Ticket\"].str.replace('\\d+', 'N', regex=True).str[0]\n\n#data[\"Ticketa\"] =data[\"Ticketa\"].str.replace(\"[^a-zA-Z]+\",'',regex=True)\ndisplay(train.loc[:,[\"TicketGroup\",\"Survived\",'Fare']].groupby([\"TicketGroup\",\"Survived\"]).agg( count = ('Fare','size')).T)\n","06067aad":"display(pd.DataFrame(train.dtypes[train.dtypes == \"object\"]).T)\ntrain.drop([\"Sex\",\"Ticket\"],axis = 1,inplace =True)\ntest.drop([\"Sex\",\"Ticket\"],axis = 1,inplace =True)\nval.drop([\"Sex\",\"Ticket\"],axis = 1,inplace =True)","c3776a62":"ddictt = train.loc[train[\"Survived\"].values.astype('bool'),[\"Embarked\"]].groupby('Embarked').size()\/(train[\"Survived\"].sum())\ndisplay(ddictt)\n\ntrain[\"EmbarkedProb\"] =train[\"Embarked\"].map(ddictt)\nval[\"EmbarkedProb\"] =val[\"Embarked\"].map(ddictt)\ntest[\"EmbarkedProb\"] =test[\"Embarked\"].map(ddictt)","5bd64925":"ddictt = train.loc[train[\"Survived\"].values.astype('bool'),[\"TicketGroup\"]].groupby('TicketGroup').size()\/(train[\"Survived\"].sum())\ndisplay(ddictt)\n\ntrain[\"TicketProb\"] =train[\"TicketGroup\"].map(ddictt)\nval[\"TicketProb\"] =val[\"TicketGroup\"].map(ddictt)\ntest[\"TicketProb\"] =test[\"TicketGroup\"].map(ddictt)\n","b12d432e":"ddictt = train.loc[train[\"Survived\"].values.astype('bool'),[\"CabinGroup\"]].groupby('CabinGroup').size()\/(train[\"Survived\"].sum())\ndisplay(ddictt)\n\ntrain[\"CabinProb\"] =train[\"CabinGroup\"].map(ddictt)\nval[\"CabinProb\"] =val[\"CabinGroup\"].map(ddictt)\ntest[\"CabinProb\"] =test[\"CabinGroup\"].map(ddictt)\n\n","8e41ad49":"train.fillna(0,inplace =True)\ntest.fillna(0,inplace =True)\nval.fillna(0,inplace =True)\n\n\ntrain","3b8e4abd":"x_trian = train.drop(['Embarked','CabinGroup','TicketGroup'],axis = 1).iloc[:,1:].to_numpy()\ny_train =train[\"Survived\"].to_numpy()\nx_val =val.drop(['Embarked','CabinGroup','TicketGroup'],axis = 1).iloc[:,1:].to_numpy()\ny_val =val[\"Survived\"].to_numpy()\nx_test =test.drop(['Embarked','CabinGroup','TicketGroup'],axis = 1).iloc[:,1:].to_numpy()\nprint(\"train shapes:\" ,x_trian.shape , y_train.shape)\nprint(\"val shapes:\" ,x_val.shape , y_val.shape)\nprint(\"test shapes:\" ,x_test.shape)\n#sc = StandardScaler()\n#xtrain = sc.fit_transform(xtrain)\n#xvalid = sc.transform(xvalid)","71e4f8b0":"x_trian[0,:]","cd8fb252":"Embarkedohe = OneHotEncoder(handle_unknown='ignore')\n\nx_trian= np.hstack(( x_trian,  Embarkedohe.fit_transform(train['Embarked'].values.reshape(-1, 1)).toarray() ))\nx_val =np.hstack(( x_val,  Embarkedohe.transform(val['Embarked'].values.reshape(-1, 1)).toarray() ))\nx_test = np.hstack(( x_test,  Embarkedohe.transform(test['Embarked'].values.reshape(-1, 1)).toarray() ))\n\n\nCabindohe = OneHotEncoder(handle_unknown='ignore')\n\nx_trian=np.hstack(( x_trian,  Cabindohe.fit_transform(train['CabinGroup'].values.reshape(-1, 1)).toarray()))\nx_val =np.hstack(( x_val,  Cabindohe.transform(val['CabinGroup'].values.reshape(-1, 1)).toarray()))\nx_test = np.hstack(( x_test,  Cabindohe.transform(test['CabinGroup'].values.reshape(-1, 1)).toarray()))\n\nprint(\"train shapes:\" ,x_trian.shape , y_train.shape)\nprint(\"val shapes:\" ,x_val.shape , y_val.shape)\nprint(\"test shapes:\" ,x_test.shape)\n","8e5d6726":"display(pd.DataFrame(train.dtypes[train.dtypes == \"object\"]).T)\ndisplay(pd.DataFrame(train.isnull().sum()).loc[train.isnull().sum()>0])\ndisplay(pd.DataFrame(val.isnull().sum()).loc[val.isnull().sum()>0])\ndisplay(pd.DataFrame(test.isnull().sum()).loc[test.isnull().sum()>0])","c6112a04":"# Fitting Logistic Regression to the Training set\nLogistic_Regression = LogisticRegression(random_state = 1,\n                                solver='newton-cg',\n                                C=1.5,\n                                max_iter=1000,\n                                verbose=0)\n#solver{\u2018newton-cg\u2019, \u2018lbfgs\u2019, \u2018liblinear\u2019, \u2018sag\u2019, \u2018saga\u2019}\nLogistic_Regression.fit(x_trian, y_train)\n\nypredtrain = Logistic_Regression.predict(x_trian)\n# Predicting the Test set results\nypredval = Logistic_Regression.predict(x_val)\n# Making the Confusion Matrix\ncmt = confusion_matrix(y_train, ypredtrain)\ncmv = confusion_matrix(y_val, ypredval)\n\nprint('\\nTrain Aaccuracy =',accuracy_score(y_train, ypredtrain) ,' \\nValidation Aaccuracy =',accuracy_score(y_val, ypredval))\n\nprint('Confusion matrix train: \\n',cmt)\nprint('Confusion matrix train: \\n',cmv)","d35b0de8":"from sklearn.neighbors import KNeighborsClassifier\nKNeighbors = KNeighborsClassifier(n_neighbors =20, metric = 'minkowski', p = 1)\nKNeighbors.fit(x_trian, y_train)\n\nypredtrain = KNeighbors.predict(x_trian)\n# Predicting the Test set results\nypredval = KNeighbors.predict(x_val)\n# Making the Confusion Matrix\ncmt = confusion_matrix(y_train, ypredtrain)\ncmv = confusion_matrix(y_val, ypredval)\n\nprint('\\nTrain Aaccuracy =',accuracy_score(y_train, ypredtrain) ,' \\nValidation Aaccuracy =',accuracy_score(y_val, ypredval))\n\nprint('Confusion matrix train: \\n',cmt)\nprint('Confusion matrix train: \\n',cmv)","438f2e86":"from sklearn.svm import SVC\nSVCclassifier = SVC(kernel = 'linear',C = .25 ,random_state = 0)\nSVCclassifier.fit(x_trian, y_train)\n\n\nypredtrain = SVCclassifier.predict(x_trian)\n# Predicting the Test set results\nypredval = SVCclassifier.predict(x_val)\n# Making the Confusion Matrix\ncmt = confusion_matrix(y_train, ypredtrain)\ncmv = confusion_matrix(y_val, ypredval)\n\nprint('\\nTrain Aaccuracy =',accuracy_score(y_train, ypredtrain) ,' \\nValidation Aaccuracy =',accuracy_score(y_val, ypredval))\n\nprint('Confusion matrix train: \\n',cmt)\nprint('Confusion matrix train: \\n',cmv)","9c5a3bb3":"#os.path.join('kaggle\/input\/neolen-house-price-prediction', filename)\nypred= Logistic_Regression.predict(x_test)\nsample_submission= pd.DataFrame({'PassengerId':test['PassengerId'].to_numpy(), 'Survived':ypred })\nsample_submission.to_csv(os.path.join('.\/',\"submission.csv\"), index=False)","64041886":"# split the Data","3580f2de":"## Age Impute","30ed5532":"## Cabin Impute","666057f3":"# Category Encoding","bedcbc3f":"## Embarked probabilistic Encoding","c084a3d4":"## TicketGroup probabilistic Encoding ","1f7a8889":"## Embarked dummie varibles","56691a0d":"## CabinGroup probabilistic Encoding ","2fa9a9fc":"## impute Fare ,Embarked ","f377626f":"# Train Model","8721b7aa":"# impute Missing  Values","1e846302":"# EDA","c49b1b97":"# Load  The Data","3153454c":"<h1>Table of Contents<span class=\"tocSkip\"><\/span><\/h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;<\/span>Imports<\/a><\/span><\/li><li><span><a href=\"#Load--The-Data\" data-toc-modified-id=\"Load--The-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;<\/span>Load  The Data<\/a><\/span><\/li><li><span><a href=\"#EDA\" data-toc-modified-id=\"EDA-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;<\/span>EDA<\/a><\/span><\/li><li><span><a href=\"#split-the-Data\" data-toc-modified-id=\"split-the-Data-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;<\/span>split the Data<\/a><\/span><\/li><li><span><a href=\"#impute-Missing--Values\" data-toc-modified-id=\"impute-Missing--Values-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;<\/span>impute Missing  Values<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Cabin-Impute\" data-toc-modified-id=\"Cabin-Impute-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;<\/span>Cabin Impute<\/a><\/span><\/li><li><span><a href=\"#Age-Impute\" data-toc-modified-id=\"Age-Impute-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;<\/span>Age Impute<\/a><\/span><\/li><li><span><a href=\"#impute-Fare-,Embarked\" data-toc-modified-id=\"impute-Fare-,Embarked-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;<\/span>impute Fare ,Embarked<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Category-Encoding\" data-toc-modified-id=\"Category-Encoding-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;<\/span>Category Encoding<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Embarked-probabilistic-Encoding\" data-toc-modified-id=\"Embarked-probabilistic-Encoding-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;<\/span>Embarked probabilistic Encoding<\/a><\/span><\/li><li><span><a href=\"#TicketGroup-probabilistic-Encoding\" data-toc-modified-id=\"TicketGroup-probabilistic-Encoding-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;<\/span>TicketGroup probabilistic Encoding<\/a><\/span><\/li><li><span><a href=\"#CabinGroup-probabilistic-Encoding\" data-toc-modified-id=\"CabinGroup-probabilistic-Encoding-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;<\/span>CabinGroup probabilistic Encoding<\/a><\/span><\/li><li><span><a href=\"#Embarked-dummie-varibles\" data-toc-modified-id=\"Embarked-dummie-varibles-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;<\/span>Embarked dummie varibles<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Train-Model\" data-toc-modified-id=\"Train-Model-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;<\/span>Train Model<\/a><\/span><\/li><\/ul><\/div>","a642b084":"# Imports"}}