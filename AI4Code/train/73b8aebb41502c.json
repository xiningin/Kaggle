{"cell_type":{"1e976b08":"code","fded6d51":"code","98ef7270":"code","1058294c":"code","8eecdf0a":"code","ed8dd9e2":"code","bb07dcc4":"code","f5202aad":"code","60eff938":"code","159e5037":"code","0b46af18":"code","16ac8cf4":"code","f0a3bcfe":"code","367074f1":"code","c51a37c1":"code","ed05f65b":"code","e1f8ebb1":"code","def1c99f":"code","6d72addd":"code","aef0833c":"code","5a0d4d65":"code","13ba035c":"code","70e4e21b":"code","a453780d":"code","9252ca95":"code","e7962b16":"code","e539162f":"code","cc433577":"code","77d0b0ed":"code","ea43782d":"code","b463570e":"code","3decd0d9":"code","b6dfcd49":"code","b69a3aa4":"code","63b419ad":"code","6db78f28":"code","b78f8b07":"code","ea0303ec":"code","42bb7e4d":"code","5ca60630":"code","8aef35b3":"code","35fc725a":"code","42eb9dc8":"code","d3013bfd":"code","b71036b8":"code","c39ed87d":"code","1246b20e":"code","bf62b0c7":"code","ef41036b":"code","7406605c":"code","95044394":"markdown","970d94c5":"markdown","0e73e8b8":"markdown","17d514eb":"markdown","494f86bd":"markdown","c50b2878":"markdown","fb6efa98":"markdown","d4bd409e":"markdown","a8110351":"markdown"},"source":{"1e976b08":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\nfrom keras.layers import Input, Dense\n\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\n\nimport tensorflow\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, RepeatVector, TimeDistributed\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, Flatten, Input, Reshape, Flatten, MaxPooling2D, UpSampling2D\nfrom tensorflow.keras.layers import BatchNormalization, Flatten\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras import regularizers\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport keras\nfrom keras import layers\n\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt","fded6d51":"df = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ndf.head()","98ef7270":"df1  = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\ndf1.head()","1058294c":"x_train = df.drop(['label'], axis=1).values\ntrain_y = df['label'].values\nx_test = df1.values\n\nprint(\"X_train shape\", x_train.shape)\nprint(\"y_test shape\", train_y.shape)\nprint(\"X_test shape\", x_test.shape)","8eecdf0a":"IMG_SIZE = 32","ed8dd9e2":"import cv2\n\ndef resize(img_array):\n    tmp = np.empty((img_array.shape[0], IMG_SIZE, IMG_SIZE))\n\n    for i in range(len(img_array)):\n        img = img_array[i].reshape(28, 28).astype('uint8')\n        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n        img = img.astype('float32')\/255\n        tmp[i] = img\n        \n    return tmp\n\nx_train = resize(x_train)\nx_test = resize(x_test)","bb07dcc4":"X_train_final = np.stack((x_train,)*3, axis=-1)\nX_test_final = np.stack((x_test,)*3, axis=-1)\nprint(X_train_final.shape)\nprint(X_test_final.shape)","f5202aad":"y_train_final = to_categorical(train_y, num_classes=10)\nprint(y_train_final.shape)","60eff938":"X_train, X_test, y_train, y_test = train_test_split(X_train_final, y_train_final, test_size=0.2, random_state=2021)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","159e5037":"# plot first few images\nimport matplotlib.pyplot as plt\nfor i in range(9):\n    plt.subplot(330 + 1 + i)\n    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\n# show the figure\nplt.show()","0b46af18":"def plot_history(history):\n    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n    \n    if len(loss_list) == 0:\n        print('Loss is missing in history')\n        return \n    \n    ## As loss always exists\n    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n    \n    ## Loss\n    plt.figure(1)\n    plt.figsize=(10, 10)\n    for l in loss_list:\n        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n    for l in val_loss_list:\n        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n    \n    plt.title('Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    ## Accuracy\n    plt.figure(2)\n    plt.figsize=(10, 10)\n    for l in acc_list:\n        plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n    for l in val_acc_list:    \n        plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n\n    plt.title('Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.show()","16ac8cf4":"model1 = Sequential()\nmodel1.add(Conv2D(IMG_SIZE, (3, 3), activation='relu', padding='valid'))\nmodel1.add(MaxPooling2D(pool_size=(2, 2)))\nmodel1.add(Flatten())\nmodel1.add(Dense(512, activation='relu'))\nmodel1.add(Dropout(0.1))\nmodel1.add(Dense(10, activation='softmax'))\nmodel1.compile(loss='categorical_crossentropy',\n              optimizer=\"adam\", metrics=['accuracy'])","f0a3bcfe":"es = EarlyStopping(monitor='val_accuracy', verbose=1, patience=5)\nmc = ModelCheckpoint(filepath='CNN.h5', verbose=1, monitor='val_acc')\ncb = [es, mc]","367074f1":"history1 = model1.fit(X_train, y_train, \n                    epochs=50, \n                    batch_size=128, \n                    validation_data=(X_test, y_test),\n                    callbacks=cb)","c51a37c1":"plot_history(history1)","ed05f65b":"score1 = model1.evaluate(X_test, y_test, verbose=0)\nprint('Test accuracy CNN%:', (score1[1]*100))","e1f8ebb1":"pred_1=model1.predict(X_test, batch_size=128)\ny_pred_1= pred_1.argmax(axis=-1)\n\ny_true_onehot = y_test\ny_true_label = np.argmax(y_true_onehot, axis=1)\ny_true = y_true_label\ny_pred1 = y_pred_1\nprint(y_pred1[0:10])","def1c99f":"cm = confusion_matrix(y_true, y_pred1)\nprint(cm)","6d72addd":"plt.figure(figsize=(9,9))\nplt.imshow(cm, interpolation='nearest', cmap='Pastel1')\nplt.title('Confusion matrix', size = 15)\nplt.colorbar()\ntick_marks = np.arange(10)\nplt.xticks(tick_marks, [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], rotation=45, size = 10)\nplt.yticks(tick_marks, [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], size = 10)\nplt.tight_layout()\nplt.ylabel('Actual label', size = 15)\nplt.xlabel('Predicted label', size = 15)\nwidth, height = cm.shape\n\nfor x in range(width):\n    for y in range(height):\n        plt.annotate(str(cm[x][y]), xy=(y, x), \n                    horizontalalignment='center',\n                    verticalalignment='center')\nplt.savefig('CNN.png')\n","aef0833c":"input_signal = Input(shape=(32, 32, 3))\n\n#ENCODER\n \ne = Conv2D(filters = 512, kernel_size = (3, 3), activation='relu', padding='same',  kernel_initializer='he_uniform')(input_signal)\ne = MaxPooling2D(pool_size = (2, 2), padding='same')(e)\ne = Dropout(0.1)(e)\n\n\ne = Conv2D(filters = 256, kernel_size = (3, 3), activation='relu', padding='same',  kernel_initializer='he_uniform')(e)\ne = MaxPooling2D(pool_size = (2, 2), padding='same')(e)\ne = Dropout(0.1)(e)\n\ne = Conv2D(filters = 256, kernel_size = (3, 3), activation='relu', padding='same',  kernel_initializer='he_uniform')(e)\ne = MaxPooling2D(pool_size = (2, 2), padding='same')(e)\ne = Dropout(0.1)(e)\n\n##DECODER\nd = Conv2D(256, (3, 3), activation='relu', padding='same',  kernel_initializer='he_uniform')(e)\nd = MaxPooling2D(pool_size = (2, 2), padding='same')(d)\nd = Dropout(0.1)(d)\n\nd = Conv2D(256, (3, 3), activation='relu', padding='same',  kernel_initializer='he_uniform')(d)\nd = MaxPooling2D(pool_size = (2, 2), padding='same')(d)\nd = Dropout(0.1)(d)\n\nd = Conv2D(512, (3, 3), activation='relu', padding='same',  kernel_initializer='he_uniform')(d)\nd = MaxPooling2D(pool_size = (2, 2), padding='same')(d)\nd = Dropout(0.1)(d)\n\nd = Flatten()(d)\ndecoded = Dense(10, activation=\"softmax\")(d)\n\n\nmodel2 = Model(inputs=input_signal, outputs=decoded)\nmodel2.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\nmodel2.summary()","5a0d4d65":"es = EarlyStopping(monitor='val_accuracy', verbose=1, patience=5)\nmc = ModelCheckpoint(filepath='CNN-AutoEncoder.h5', verbose=1, monitor='val_acc')\ncb = [es, mc]","13ba035c":"history2 = model2.fit(X_train, y_train, \n                    epochs=50, \n                    batch_size=128, \n                    validation_data=(X_test, y_test),\n                    callbacks=cb)\nscores = model2.evaluate(X_test, y_test, verbose=0)","70e4e21b":"plot_history(history2)","a453780d":"score2 = model2.evaluate(X_test, y_test, verbose=0)\nprint('Test accuracy CNN AutoEncoder%:', (score2[1]*100))","9252ca95":"pred_2=model2.predict(X_test, batch_size=128)\ny_pred_2= pred_2.argmax(axis=-1)\n\ny_true_onehot = y_test\ny_true_label = np.argmax(y_true_onehot, axis=1)\ny_true = y_true_label\ny_pred2 = y_pred_2\nprint(y_pred2[0:10])","e7962b16":"cm = confusion_matrix(y_true, y_pred2)\nprint(cm)","e539162f":"plt.figure(figsize=(9,9))\nplt.imshow(cm, interpolation='nearest', cmap='Pastel2')\nplt.title('Confusion matrix', size = 15)\nplt.colorbar()\ntick_marks = np.arange(10)\nplt.xticks(tick_marks, [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], rotation=45, size = 10)\nplt.yticks(tick_marks, [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], size = 10)\nplt.tight_layout()\nplt.ylabel('Actual label', size = 15)\nplt.xlabel('Predicted label', size = 15)\nwidth, height = cm.shape\n\nfor x in range(width):\n    for y in range(height):\n        plt.annotate(str(cm[x][y]), xy=(y, x), \n                    horizontalalignment='center',\n                    verticalalignment='center')\nplt.savefig('CNN-AutoEncoder.png')","cc433577":"from tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.applications.vgg16 import preprocess_input","77d0b0ed":"VGG = VGG16(input_shape=(32, 32, 3), include_top=False, weights='imagenet')\nVGG.trainable = False\n\nmodel3 = Sequential([\n    VGG,\n    Flatten(),\n    Dense(units=512, activation=\"relu\"),\n    Dropout(0.1),\n    Dense(units=256, activation=\"relu\"),\n    Dropout(0.1),\n    Dense(units=10, activation=\"softmax\")\n    \n])\n\nmodel3.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\nmodel3.summary()","ea43782d":"es = EarlyStopping(monitor='val_accuracy', verbose=1, patience=5)\nmc = ModelCheckpoint(filepath='CNN-VGG16.h5', verbose=1, monitor='val_acc')\ncb = [es, mc]","b463570e":"history3 = model3.fit(X_train, y_train, \n                    epochs=50, \n                    batch_size=128, \n                    validation_data=(X_test, y_test),\n                    callbacks=cb)","3decd0d9":"plot_history(history3)","b6dfcd49":"score3 = model3.evaluate(X_test, y_test, verbose=0)\nprint('Test accuracy CNN VGG-16%:', (score3[1]*100))","b69a3aa4":"pred_3=model3.predict(X_test, batch_size=128)\ny_pred_3= pred_3.argmax(axis=-1)\n\ny_true_onehot = y_test\ny_true_label = np.argmax(y_true_onehot, axis=1)\ny_true = y_true_label\ny_pred3 = y_pred_3\nprint(y_pred3[0:10])","63b419ad":"cm = confusion_matrix(y_true, y_pred3)\nprint(cm)","6db78f28":"plt.figure(figsize=(9,9))\nplt.imshow(cm, interpolation='nearest', cmap='Paired')\nplt.title('Confusion matrix', size = 15)\nplt.colorbar()\ntick_marks = np.arange(10)\nplt.xticks(tick_marks, [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], rotation=45, size = 10)\nplt.yticks(tick_marks, [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], size = 10)\nplt.tight_layout()\nplt.ylabel('Actual label', size = 15)\nplt.xlabel('Predicted label', size = 15)\nwidth, height = cm.shape\n\nfor x in range(width):\n    for y in range(height):\n        plt.annotate(str(cm[x][y]), xy=(y, x), \n                    horizontalalignment='center',\n                    verticalalignment='center')\nplt.savefig('CNN-VGG-16.png')","b78f8b07":"from tensorflow.keras.applications import VGG19\nfrom tensorflow.keras.applications.vgg19 import preprocess_input","ea0303ec":"VGG = VGG19(input_shape=(32, 32, 3), include_top=False, weights='imagenet')\nVGG.trainable = False\n\nmodel4 = Sequential([\n    VGG,\n    Flatten(),\n    Dense(units=512, activation=\"relu\"),\n    Dropout(0.1),\n    Dense(units=256, activation=\"relu\"),\n    Dropout(0.1),\n    Dense(units=10, activation=\"softmax\")\n    \n])\n\nmodel4.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n\nmodel4.summary()","42bb7e4d":"es = EarlyStopping(monitor='val_accuracy', verbose=1, patience=5)\nmc = ModelCheckpoint(filepath='CNN-VGG19.h5', verbose=1, monitor='val_acc')\ncb = [es, mc]","5ca60630":"history4 = model4.fit(X_train, y_train, \n                    epochs=50, \n                    batch_size=128, \n                    validation_data=(X_test, y_test),\n                    callbacks=cb)\nscores = model4.evaluate(X_test, y_test, verbose=0)\nprint('Test accuracy CNN-VGG19-Model%:', (scores[1]*100))","8aef35b3":"plot_history(history4)","35fc725a":"score4 = model4.evaluate(X_test, y_test, verbose=0)\nprint('Test accuracy CNN VGG-19%:', (score4[1]*100))","42eb9dc8":"pred_4=model4.predict(X_test, batch_size=128)\ny_pred_4= pred_4.argmax(axis=-1)\n\ny_true_onehot = y_test\ny_true_label = np.argmax(y_true_onehot, axis=1)\ny_true = y_true_label\ny_pred4 = y_pred_4\nprint(y_pred4[0:10])","d3013bfd":"cm = confusion_matrix(y_true, y_pred4)\nprint(cm)","b71036b8":"plt.figure(figsize=(9,9))\nplt.imshow(cm, interpolation='nearest', cmap='Accent')\nplt.title('Confusion matrix', size = 15)\nplt.colorbar()\ntick_marks = np.arange(10)\nplt.xticks(tick_marks, [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], rotation=45, size = 10)\nplt.yticks(tick_marks, [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], size = 10)\nplt.tight_layout()\nplt.ylabel('Actual label', size = 15)\nplt.xlabel('Predicted label', size = 15)\nwidth, height = cm.shape\n\nfor x in range(width):\n    for y in range(height):\n        plt.annotate(str(cm[x][y]), xy=(y, x), \n                    horizontalalignment='center',\n                    verticalalignment='center')\nplt.savefig('CNN-VGG-19.png')","c39ed87d":"from tensorflow.keras.models import load_model\n\nmodel = load_model('CNN-AutoEncoder.h5')\nprediction = model.predict([X_test_final])","1246b20e":"print(np.argmax(prediction[0]))","bf62b0c7":"plt.imshow(X_test_final[0])\nplt.show","ef41036b":"label = [np.argmax(x) for x in prediction]\nImageId = [x+1 for x in range(len(prediction))]\n\nsubmission = pd.DataFrame({'ImageId': ImageId,\n                          'Label' : label}, index = None)\nsubmission","7406605c":"submission.to_csv('MySubmission.csv', index=False)","95044394":"### VGG-19 Transfer Learning","970d94c5":"#### Splitting and Reshaping the dataset","0e73e8b8":"### Convolution Neural Network (CNN)","17d514eb":"### VGG-16 Transfer-Learning","494f86bd":"## Comparitive-Models","c50b2878":"### Evaluating and SUBMISSION\n\nAs it is observed that CNN Autoencoder is giving the Highest Test Accuracy of 99.01%\n\nWe will be submtting that model","fb6efa98":"#### Code which helps to plot the Accuracy and Loss Curve","d4bd409e":"### Convolution Neural Network with AutoEncoder","a8110351":"### Importing Libraries"}}