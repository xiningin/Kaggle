{"cell_type":{"ecceb849":"code","74c051de":"code","cfab6c7d":"code","1c73fdfd":"code","8f6bf447":"code","8a3f258b":"code","864e5995":"code","58d1ce89":"code","0ebd2d66":"code","6c795a0e":"code","7a638777":"code","6fafcc04":"code","3d0b1edb":"code","28599a3b":"code","f2f2c1f2":"code","2be4abc4":"code","a3cfbfb2":"code","d1282ab7":"code","91dfac52":"code","5c509a2e":"code","d8962fcf":"code","904a9ef7":"code","97312d66":"code","198e24c1":"code","7c4ef0a0":"code","89cb9b52":"code","18e57613":"code","75fd90f3":"code","37a4dc1e":"code","a01c0d4e":"code","dd673120":"code","de53b0a8":"code","f771918b":"code","1d9627f2":"code","1b996433":"code","5168f084":"code","ea023f0d":"code","3755057f":"code","0f7bb5b8":"code","0d65bfe2":"code","c51b10a6":"code","5a147773":"code","a81cb00f":"code","d0b48a94":"code","318affef":"code","ef622717":"code","55991b5d":"code","f5ef3e3e":"code","15cd7c1f":"code","c87b9174":"code","4079b5f6":"code","9bf4b37f":"code","d4b50a13":"code","8c87145e":"code","d1a8faed":"code","e2ca7073":"code","d4ca9cf1":"code","b7640194":"code","a27134f6":"code","731107a0":"code","62b2891b":"code","d1f251ce":"code","3b2e2da0":"code","cd500458":"code","0c5bb9dd":"code","2854e69d":"code","a61054d7":"code","11799efa":"code","90a5e386":"code","563ac190":"code","cf0f5e46":"code","6c3d93b7":"code","576ebdfa":"code","9ae6b0b0":"code","8cdfe33b":"code","bed3cfb4":"code","17131c79":"code","f1a6a180":"code","798528bf":"code","1e68b8d0":"code","ea6b123e":"markdown","83296152":"markdown","f3379c48":"markdown","26402cf9":"markdown","812bdea0":"markdown","c9d3c0d6":"markdown","945336c5":"markdown","1b964d8a":"markdown","bee194f8":"markdown","2f8d2621":"markdown","2ad39b14":"markdown","57c766bf":"markdown","580dbdad":"markdown","8ee77914":"markdown","f43ca456":"markdown","1dc4bb45":"markdown","ea0b4569":"markdown","14f54998":"markdown","68acab18":"markdown","55242bdd":"markdown","20d34d7f":"markdown","3ba93b0d":"markdown","1b92586e":"markdown","c181e88c":"markdown"},"source":{"ecceb849":"imp_feature = ['uid3_count_dist', 'feat1', 'TransactionAmt', 'feat2', 'card1_count_dist', 'card2_count_dist', 'addr1_count_dist', 'uid_count_dist', 'uid2_count_dist', 'Transaction_hour', 'uid1_count_dist', 'P_emaildomain_count_dist', 'M_na', 'M_na_count_dist', 'D15_count_dist', 'Transaction_day_of_week', 'D1', 'card5_count_dist', 'dist1_count_dist', 'C13', 'D10_count_dist', 'id_20_count_dist', 'D4_count_dist', 'id_19_count_dist', 'C13_count_dist', 'D2_count_dist', 'id_31_count_dist', 'D1_count_dist', 'DeviceInfo_count_dist', 'R_emaildomain_count_dist', 'C1', 'uid4_count_dist', 'id_33_count_dist', 'V310_count_dist', 'C2', 'C1_count_dist', 'V307_count_dist', 'C14', 'C6', 'C2_count_dist', 'C14_count_dist', 'C6_count_dist', 'id_30_count_dist', 'D3_count_dist', 'V313_count_dist', 'D11_count_dist', 'D5_count_dist', 'id_05_count_dist', 'D9_count_dist', 'C11', 'dist2_count_dist', 'C9', 'V315_count_dist', 'id_13_count_dist', 'C9_count_dist', 'id_01_count_dist', 'V130_count_dist', 'M4_count_dist', 'C11_count_dist', 'V314_count_dist', 'M6_count_dist', 'M5_count_dist', 'card4_count_dist', 'V127_count_dist', 'V312_count_dist', 'D14_count_dist', 'V308_count_dist', 'C5', 'V283_count_dist', 'id_14_count_dist', 'V83_count_dist', 'M3_count_dist', 'C5_count_dist', 'V62_count_dist', 'id_18_count_dist', 'ProductCD_count_dist', 'V87_count_dist', 'V282_count_dist', 'V317_count_dist', 'D6_count_dist', 'card6_count_dist', 'V285_count_dist', 'V76_count_dist', 'card3_count_dist', 'id_02_count_dist', 'V45_count_dist', 'V143_count_dist', 'V38_count_dist', 'V131_count_dist', 'C10']\n","74c051de":"import pandas as pd\nimport numpy as np\nimport multiprocessing\nimport warnings\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport lightgbm as lgb\nimport gc\nfrom time import time\nimport datetime\nfrom tqdm import tqdm_notebook\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold, TimeSeriesSplit\nfrom sklearn.metrics import roc_auc_score\nwarnings.simplefilter('ignore')\nsns.set()\n%matplotlib inline","cfab6c7d":"sub = pd.read_csv(\"..\/input\/ieee-fraud-detection\/sample_submission.csv\")","1c73fdfd":"sub.shape","8f6bf447":"train_id = pd.read_csv(\"..\/input\/ieee-fraud-detection\/train_identity.csv\")\ntrain_tr = pd.read_csv(\"..\/input\/ieee-fraud-detection\/train_transaction.csv\")","8a3f258b":"pd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)","864e5995":"train_id.head(5)","58d1ce89":"train_tr.head(5)","0ebd2d66":"train_id.shape, train_tr.shape","6c795a0e":"test_id = pd.read_csv(\"..\/input\/ieee-fraud-detection\/test_identity.csv\")\ntest_tr = pd.read_csv(\"..\/input\/ieee-fraud-detection\/test_transaction.csv\")","7a638777":"test_id.shape, test_tr.shape","6fafcc04":"train = pd.merge(train_tr, train_id, on='TransactionID', how='left')\ntest = pd.merge(test_tr, test_id, on='TransactionID', how='left')\n\ndel test_id, test_tr\ndel train_id, train_tr\ngc.collect()","3d0b1edb":"train.head(5)","28599a3b":"# Negative downsampling\ntrain_pos = train[train['isFraud']==1]\ntrain_neg = train[train['isFraud']==0]\n\ntrain_neg = train_neg.sample(2*int(train_pos.shape[0] ), random_state=42)\ntrain = pd.concat([train_pos,train_neg]).sort_index()","f2f2c1f2":"train_pos.shape, train_neg.shape","2be4abc4":"l = 3*int(train_pos.shape[0])","a3cfbfb2":"train.shape","d1282ab7":"#train.head(2)","91dfac52":"del train_pos\ndel train_neg","5c509a2e":"train.isna().sum()","d8962fcf":"train = train.sort_values('TransactionDT')","904a9ef7":"train.shape","97312d66":"train.drop_duplicates(inplace=True)","198e24c1":"train.shape","7c4ef0a0":"#","89cb9b52":"#corr = train.corr()\n#corr.head(403)\n#Correlation with output variable\n#cor_target = abs(corr[\"isFraud\"])\n#Selecting highly correlated features\n#relevant_features = cor_target[cor_target>0.05]\n#relevant_features","18e57613":"target = train[\"isFraud\"]\ntrain.drop([\"isFraud\"], axis=1, inplace=True)","75fd90f3":"useful_features = [col for col in train.columns]","37a4dc1e":"len(useful_features)","a01c0d4e":"train.shape","dd673120":"train.isna().sum()","de53b0a8":"pd.set_option('display.max_columns', None)","f771918b":"train.shape, test.shape","1d9627f2":"train.head(10)","1b996433":"#target = train[\"isFraud\"]\n#train.drop([\"isFraud\"], axis=1, inplace=True)","5168f084":"train = train.iloc[:, 1:31]\ntest = test.iloc[:, 1:31]","ea023f0d":"train.head()","3755057f":"train['Transaction_day_of_week'] = np.floor((train['TransactionDT'] \/ (3600 * 24) - 1) % 7)\ntest['Transaction_day_of_week'] = np.floor((test['TransactionDT'] \/ (3600 * 24) - 1) % 7)\ntrain['Transaction_hour'] = np.floor(train['TransactionDT'] \/ 3600) % 24\ntest['Transaction_hour'] = np.floor(test['TransactionDT'] \/ 3600) % 24\n","0f7bb5b8":"train['uid'] = train['card1'].astype(str)+'_'+train['card2'].astype(str)\ntest['uid'] = test['card1'].astype(str)+'_'+test['card2'].astype(str)\n\ntrain['uid1'] = train['uid'].astype(str)+'_'+train['card3'].astype(str)\ntest['uid1'] = test['uid'].astype(str)+'_'+test['card3'].astype(str)\n\n\ntrain['uid2'] = train['uid'].astype(str)+'_'+train['card3'].astype(str)+'_'+train['card5'].astype(str)\ntest['uid2'] = test['uid'].astype(str)+'_'+test['card3'].astype(str)+'_'+test['card5'].astype(str)\n\ntrain['uid3'] = train['uid2'].astype(str)+'_'+train['addr1'].astype(str)+'_'+train['addr2'].astype(str)\ntest['uid3'] = test['uid2'].astype(str)+'_'+test['addr1'].astype(str)+'_'+test['addr2'].astype(str)\n\ntrain['uid4'] = train['card4'].astype(str)+'_'+train['card6'].astype(str)\ntest['uid4'] = test['card4'].astype(str)+'_'+test['card6'].astype(str)\n\ntrain['TransactionAmt_check'] = np.where(train['TransactionAmt'].isin(test['TransactionAmt']), 1, 0)\ntest['TransactionAmt_check']  = np.where(test['TransactionAmt'].isin(train['TransactionAmt']), 1, 0)\n","0d65bfe2":"train = pd.concat([train, test])","c51b10a6":"#neglect = [\"TransactionAmt\", 'Transaction_day_of_week', 'Transaction_hour']","5a147773":"#useful_features = [col for col in train.columns if col not in neglect]","a81cb00f":"train['M_na'] = abs(train.isna().sum(axis=1).astype(np.int8))","d0b48a94":"#non_nan = [\"C1\", \"C2\", \"C3\", \"C4\", \"C5\", \"C6\", \"C7\", \"C8\", \"C9\", \"C10\", \"C11\", \"C12\", \"C13\", \"C14\",\\\n #         \"D1\", \"M_na\"]","318affef":"#\"V96\", \"V97\", \"V98\", \"V99\", \"V100\", \"V101\", \"V102\", \"V103\", \"V104\", \"V105\", \"V106\",\\\n#          \"V107\", \"V108\", \"V109\", \"V110\", \"V111\", \"V112\", \"V113\", \"V114\", \"V115\", \"V116\", \"V117\",\"V118\",\\\n #         \"V119\", \"V120\", \"V121\",\"V122\",\"V123\", \"V124\", \"V125\", \"V126\", \"V127\", \"V128\", \"V129\", \"V130\",\\\n  #        \"V131\", \"V132\", \"V133\", \"V134\", \"V135\", \"V136\", \"V137\", \"V297\", \"V298\", \"V299\", \"V300\",\\\n   #       \"V301\", \"V301\", \"V302\", \"V303\", \"V304\", \"V305\", \"V306\", \"V307\", \"V308\", \"V309\", \"V310\",\\\n    #      \"V311\", \"V312\", \"V313\", \"V314\", \"V315\", \"V316\", \"V317\", \"V318\", \"V319\", \"V320\", \"V321\",\\\n     #     \"V279\", \"V280\", \"V281\", \"V282\", \"V283\", \"V284\", \"V285\", \"V286\", \"V287\", \"V288\", \"V289\", \"V290\",\\\n      #    \"V291\", \"V292\", \"V293\", \"V294\", \"V295\", \"V296\"]","ef622717":"def id_split(dataframe):\n    dataframe['device_name'] = dataframe['DeviceInfo'].str.split('\/', expand=True)[0]\n    dataframe['device_version'] = dataframe['DeviceInfo'].str.split('\/', expand=True)[1]\n\n    dataframe['OS_id_30'] = dataframe['id_30'].str.split(' ', expand=True)[0]\n    dataframe['version_id_30'] = dataframe['id_30'].str.split(' ', expand=True)[1]\n\n    dataframe['browser_id_31'] = dataframe['id_31'].str.split(' ', expand=True)[0]\n    dataframe['version_id_31'] = dataframe['id_31'].str.split(' ', expand=True)[1]\n\n    dataframe['screen_width'] = dataframe['id_33'].str.split('x', expand=True)[0]\n    dataframe['screen_height'] = dataframe['id_33'].str.split('x', expand=True)[1]\n\n    dataframe['id_34'] = dataframe['id_34'].str.split(':', expand=True)[1]\n    dataframe['id_23'] = dataframe['id_23'].str.split(':', expand=True)[1]\n\n    dataframe.loc[dataframe['device_name'].str.contains('SM', na=False), 'device_name'] = 'Samsung'\n    dataframe.loc[dataframe['device_name'].str.contains('SAMSUNG', na=False), 'device_name'] = 'Samsung'\n    dataframe.loc[dataframe['device_name'].str.contains('GT-', na=False), 'device_name'] = 'Samsung'\n    dataframe.loc[dataframe['device_name'].str.contains('Moto G', na=False), 'device_name'] = 'Motorola'\n    dataframe.loc[dataframe['device_name'].str.contains('Moto', na=False), 'device_name'] = 'Motorola'\n    dataframe.loc[dataframe['device_name'].str.contains('moto', na=False), 'device_name'] = 'Motorola'\n    dataframe.loc[dataframe['device_name'].str.contains('LG-', na=False), 'device_name'] = 'LG'\n    dataframe.loc[dataframe['device_name'].str.contains('rv:', na=False), 'device_name'] = 'RV'\n    dataframe.loc[dataframe['device_name'].str.contains('HUAWEI', na=False), 'device_name'] = 'Huawei'\n    dataframe.loc[dataframe['device_name'].str.contains('ALE-', na=False), 'device_name'] = 'Huawei'\n    dataframe.loc[dataframe['device_name'].str.contains('-L', na=False), 'device_name'] = 'Huawei'\n    dataframe.loc[dataframe['device_name'].str.contains('Blade', na=False), 'device_name'] = 'ZTE'\n    dataframe.loc[dataframe['device_name'].str.contains('BLADE', na=False), 'device_name'] = 'ZTE'\n    dataframe.loc[dataframe['device_name'].str.contains('Linux', na=False), 'device_name'] = 'Linux'\n    dataframe.loc[dataframe['device_name'].str.contains('XT', na=False), 'device_name'] = 'Sony'\n    dataframe.loc[dataframe['device_name'].str.contains('HTC', na=False), 'device_name'] = 'HTC'\n    dataframe.loc[dataframe['device_name'].str.contains('ASUS', na=False), 'device_name'] = 'Asus'\n    \n    dataframe.loc[dataframe.device_name.isin(dataframe.device_name.value_counts()[dataframe.device_name.value_counts() < 200].index), 'device_name'] = 'Others'\n    gc.collect()\n    return dataframe","55991b5d":"#train = id_split(train)","f5ef3e3e":"#train['TransactionAmt_Log'] = np.log(train['TransactionAmt'])\ntrain['TransactionAmt_decimal'] = ((train['TransactionAmt'] - train['TransactionAmt'].astype(int)) * 1000).astype(int)","15cd7c1f":"neglect = [\"TransactionAmt\", 'Transaction_day_of_week', 'Transaction_hour', \"TransactionAmt_Log\", 'TransactionAmt_decimal']","c87b9174":"emails = {'gmail': 'google', 'att.net': 'att', 'twc.com': 'spectrum', 'scranton.edu': 'other', \n          'optonline.net': 'other', 'hotmail.co.uk': 'microsoft', 'comcast.net': 'other', \n          'yahoo.com.mx': 'yahoo', 'yahoo.fr': 'yahoo', 'yahoo.es': 'yahoo', \n          'charter.net': 'spectrum', 'live.com': 'microsoft', 'aim.com': 'aol', \n          'hotmail.de': 'microsoft', 'centurylink.net': 'centurylink', 'gmail.com': 'google', \n          'me.com': 'apple', 'earthlink.net': 'other', 'gmx.de': 'other', 'web.de': 'other', \n          'cfl.rr.com': 'other', 'hotmail.com': 'microsoft', 'protonmail.com': 'other', \n          'hotmail.fr': 'microsoft', 'windstream.net': 'other', 'outlook.es': 'microsoft', \n          'yahoo.co.jp': 'yahoo', 'yahoo.de': 'yahoo', 'servicios-ta.com': 'other', \n          'netzero.net': 'other', 'suddenlink.net': 'other', 'roadrunner.com': 'other', \n          'sc.rr.com': 'other', 'live.fr': 'microsoft', 'verizon.net': 'yahoo', \n          'msn.com': 'microsoft', 'q.com': 'centurylink', 'prodigy.net.mx': 'att', \n          'frontier.com': 'yahoo', 'anonymous.com': 'other', 'rocketmail.com': 'yahoo', \n          'sbcglobal.net': 'att', 'frontiernet.net': 'yahoo', 'ymail.com': 'yahoo', \n          'outlook.com': 'microsoft', 'mail.com': 'other', 'bellsouth.net': 'other', \n          'embarqmail.com': 'centurylink', 'cableone.net': 'other', 'hotmail.es': 'microsoft', \n          'mac.com': 'apple', 'yahoo.co.uk': 'yahoo', 'netzero.com': 'other', \n          'yahoo.com': 'yahoo', 'live.com.mx': 'microsoft', 'ptd.net': 'other', \n          'cox.net': 'other', 'aol.com': 'aol', 'juno.com': 'other', 'icloud.com': 'apple'}\nus_emails = ['gmail', 'net', 'edu']","4079b5f6":"for c in ['P_emaildomain', 'R_emaildomain']:\n    train[c + '_bin'] = train[c].map(emails)\n    \n    train[c + '_suffix'] = train[c].map(lambda x: str(x).split('.')[-1])\n    \n    train[c + '_suffix'] = train[c + '_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')","9bf4b37f":"useful_features = [col for col in train.columns if col not in neglect]","d4b50a13":"#i=0        \n#for feature in useful_features:\n    \n        # Count encoded separately for train and test\n #   train[feature + '_count_dist'] = train[feature].map(train[feature].value_counts(dropna=False))\n    #if feature not in non_nan:\n     #   train.drop([feature], axis=1,inplace=True)\n  #  print(\"Done\" + str(i))\n   # i+=1\n        ","8c87145e":"dropping =[\"D8_count_dist\", \"V138_count_dist\", \"V139_count_dist\", \"V140_count_dist\", \"V141_count_dist\",\\\n           \"V146_count_dist\", \"V147_count_dist\", \"V148_count_dist\", \"V149_count_dist\", \"V144_count_dist\",\\\n           \"V145_count_dist\", \"V150_count_dist\", \"V151_count_dist\", \"V152_count_dist\", \"V153_count_dist\",\\\n           \"V154_count_dist\", \"V155_count_dist\", \"V156_count_dist\", \"V157_count_dist\", \"V158_count_dist\",\\\n           \"V159_count_dist\", \"V160_count_dist\", \"V161_count_dist\", \"V162_count_dist\", \"V163_count_dist\",\\\n           \"V164_count_dist\", \"V165_count_dist\", \"V166_count_dist\", \"V168_count_dist\", \"V170_count_dist\",\\\n           \"V171_count_dist\", \"V172_count_dist\", \"V173_count_dist\", \"V174_count_dist\", \"V175_count_dist\",\\\n           \"V176_count_dist\", \"V177_count_dist\", \"V178_count_dist\", \"V179_count_dist\", \"V180_count_dist\",\\\n           \"V181_count_dist\", \"V182_count_dist\", \"V183_count_dist\", \"V184_count_dist\", \"V185_count_dist\",\\\n           \"V186_count_dist\", \"V187_count_dist\", \"V188_count_dist\", \"V189_count_dist\", \"V190_count_dist\",\\\n           \"V191_count_dist\", \"V192_count_dist\", \"V193_count_dist\", \"V194_count_dist\", \"V195_count_dist\",\\\n           \"V196_count_dist\", \"V197_count_dist\", \"V198_count_dist\", \"V199_count_dist\", \"V200_count_dist\",\\\n           \"V201_count_dist\", \"V202_count_dist\", \"V203_count_dist\", \"V204_count_dist\", \"V205_count_dist\",\\\n           \"V206_count_dist\", \"V207_count_dist\", \"V208_count_dist\", \"V209_count_dist\", \"V210_count_dist\",\\\n           \"V211_count_dist\", \"V212_count_dist\", \"V213_count_dist\", \"V214_count_dist\", \"V215_count_dist\",\\\n           \"V216_count_dist\", \"V218_count_dist\", \"V219_count_dist\", \"V221_count_dist\", \"V222_count_dist\",\\\n           \"V223_count_dist\", \"V224_count_dist\", \"V225_count_dist\", \"V226_count_dist\", \"V227_count_dist\",\\\n           \"V228_count_dist\", \"V229_count_dist\", \"V230_count_dist\", \"V231_count_dist\", \"V232_count_dist\",\\\n           \"V233_count_dist\", \"V234_count_dist\", \"V235_count_dist\", \"V236_count_dist\", \"V237_count_dist\",\\\n           \"V205_count_dist\", \"V205_count_dist\", \"V205_count_dist\", \"V205_count_dist\", \"V205_count_dist\",\\\n           \"V238_count_dist\", \"V239_count_dist\", \"V240_count_dist\", \"V241_count_dist\", \"V242_count_dist\",\\\n           \"V243_count_dist\", \"V244_count_dist\", \"V245_count_dist\",\"V246_count_dist\", \"V247_count_dist\",\\\n           \"V248_count_dist\", \"V249_count_dist\", \"V250_count_dist\", \"V251_count_dist\", \"V252_count_dist\",\\\n           \"V253_count_dist\", \"V254_count_dist\", \"V255_count_dist\", \"V256_count_dist\", \"V257_count_dist\",\\\n           \"V258_count_dist\", \"V259_count_dist\", \"V260_count_dist\", \"V261_count_dist\", \"V262_count_dist\",\\\n           \"V263_count_dist\", \"V264_count_dist\", \"V265_count_dist\", \"V266_count_dist\", \"V267_count_dist\",\\\n           \"V268_count_dist\", \"V269_count_dist\", \"V270_count_dist\", \"V271_count_dist\", \"V272_count_dist\",\\\n           \"V273_count_dist\", \"V274_count_dist\", \"V275_count_dist\", \"V276_count_dist\", \"V277_count_dist\",\\\n           \"V278_count_dist\", \"V323_count_dist\", \"V324_count_dist\", \"V325_count_dist\", \"V326_count_dist\",\\\n           \"V327_count_dist\", \"V328_count_dist\", \"V329_count_dist\", \"V330_count_dist\", \"V331_count_dist\",\\\n           \"V332_count_dist\", \"V333_count_dist\", \"V334_count_dist\", \"V335_count_dist\", \"V336_count_dist\",\\\n           \"V237_count_dist\", \"V238_count_dist\", \"V239_count_dist\", \"id_04_count_dist\", \"id_06_count_dist\",\\\n           \"id_08_count_dist\", \"id_10_count_dist\", \"id_22_count_dist\", \"id_27_count_dist\", \"id_29_count_dist\",\\\n           \"id_36_count_dist\", \"id_37_count_dist\", \"id_38_count_dist\"]\n","d1a8faed":"#train = train.drop(dropping, axis=1)","e2ca7073":"#len(dropping)","d4ca9cf1":"#train['feat1'] = (train[\"TransactionAmt\"]\/train['uid_count_dist'])*100\n#train['feat2'] = (train[\"TransactionAmt\"]\/train['uid3_count_dist'])*100\n#train['feat3'] = (train[\"TransactionAmt\"]\/train['card1_count_dist'])*100\n","b7640194":"#useful_features = [col for col in train.columns]\n#for feature in useful_features:\n    \n        # Count encoded separately for train and test\n#    train[feature] = np.log(train[feature])\n    \n    \n    ","a27134f6":"train.head(4)","731107a0":"train.shape","62b2891b":"#X = train.sort_values('TransactionDT').drop(['isFraud', 'TransactionDT', 'TransactionID'], axis=1)#\n#y = train.sort_values('TransactionDT')['isFraud']\n#test = test.sort_values('TransactionDT').drop(['TransactionDT', 'TransactionID'], axis=1)","d1f251ce":"train.isna().sum()","3b2e2da0":"train.fillna(-333, inplace=True)","cd500458":"#del train\n#gc.collect()","0c5bb9dd":"X = train.iloc[:l, :]\ntest = train.iloc[l:, :]","2854e69d":"from sklearn import preprocessing\nfor f in X.columns:\n    if X[f].dtype.name =='object' or test[f].dtype.name =='object': \n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(X[f].values) + list(test[f].values))\n        X[f] = lbl.transform(list(X[f].values))\n        test[f] = lbl.transform(list(test[f].values))","a61054d7":"#X = train","11799efa":"y=target","90a5e386":"X.head()","563ac190":"# Training and Validation Set\n#from sklearn.model_selection import train_test_split\n#X_train, X_valid, y_train, y_valid = train_test_split(train, target, test_size=0.20, random_state=23)","cf0f5e46":"from catboost import CatBoostClassifier\ncategorical_var = np.where(train.dtypes != np.float)[0]\nprint('\\nCategorical Variables indices : ',categorical_var)","6c3d93b7":"del train","576ebdfa":"#X['feat3'] = (X[\"TransactionAmt\"]\/X['card1_count_dist'])*100\n#X['feat2'] = (X[\"TransactionAmt\"]\/X['uid3_count_dist'])*100\n\n","9ae6b0b0":"params = {'num_leaves': 491,\n          'min_child_weight': 0.03454472573214212,\n          'feature_fraction': 0.3797454081646243,\n          'bagging_fraction': 0.4181193142567742,\n          'min_data_in_leaf': 106,\n          'objective': 'binary',\n          'max_depth': -1,\n          'learning_rate': 0.006883242363721497,\n          \"boosting_type\": \"gbdt\",\n          \"bagging_seed\": 11,\n          \"metric\": 'auc',\n          \"verbosity\": -1,\n          'reg_alpha': 0.3899927210061127,\n          'reg_lambda': 0.6485237330340494,\n          'random_state': 47,\n          \"n_jobs\" : -1\n         }","8cdfe33b":"folds = TimeSeriesSplit(n_splits=5)\n\naucs = list()\nfeature_importances = pd.DataFrame()\nfeature_importances['feature'] = X.columns\n\ntraining_start_time = time()\nfor fold, (trn_idx, test_idx) in enumerate(folds.split(X, y)):\n    start_time = time()\n    print('Training on fold {}'.format(fold + 1))\n    \n    trn_data = lgb.Dataset(X.iloc[trn_idx], label=y.iloc[trn_idx])\n    val_data = lgb.Dataset(X.iloc[test_idx], label=y.iloc[test_idx])\n    clf = lgb.train(params, trn_data, 10000, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds=500)\n    \n    feature_importances['fold_{}'.format(fold + 1)] = clf.feature_importance()\n    aucs.append(clf.best_score['valid_1']['auc'])\n    \n    print('Fold {} finished in {}'.format(fold + 1, str(datetime.timedelta(seconds=time() - start_time))))\nprint('-' * 30)\nprint('Training has finished.')\nprint('Total training time is {}'.format(str(datetime.timedelta(seconds=time() - training_start_time))))\nprint('Mean AUC:', np.mean(aucs))\nprint('-' * 30)","bed3cfb4":"feature_importances['average'] = feature_importances[['fold_{}'.format(fold + 1) for fold in range(folds.n_splits)]].mean(axis=1)\nfeature_importances.to_csv('feature_importances.csv')\n\nplt.figure(figsize=(16, 16))\nsns.barplot(data=feature_importances.sort_values(by='average', ascending=False).head(50), x='average', y='feature');\nplt.title('50 TOP feature importance over {} folds average'.format(folds.n_splits));","17131c79":"# clf right now is the last model, trained with 80% of data and validated with 20%\nbest_iter = clf.best_iteration","f1a6a180":"clf = lgb.LGBMClassifier(**params, num_boost_round=best_iter)\nclf.fit(X, y)","798528bf":"sub['isFraud'] = clf.predict_proba(test)[:, 1]","1e68b8d0":"sub.to_csv('ieee_cis_fraud_detection_new.csv', index=False)","ea6b123e":"**Negative Downsampling**","83296152":"**This block of code count every features and drop original features**","f3379c48":"> Below we can see that all I am left with is count","26402cf9":"**Card feature**","812bdea0":"**Adding few more features**","c9d3c0d6":"**Taking all features**\n> Initially I will start with all the features and then will drop most of the features on the basis of count","945336c5":"**Train test and split**","1b964d8a":"> Sorting features on basis of TransactionDT","bee194f8":"> Please give your feedback","2f8d2621":"**Merging transaction and Identity **","2ad39b14":"**Importing necessary library**","57c766bf":"Reference: https:\/\/www.kaggle.com\/nroman\/lgb-single-model-lb-0-9419\n> https:\/\/www.kaggle.com\/roydatascience\/light-gbm-with-complete-eda\n* https:\/\/www.kaggle.com\/ragnar123\/e-d-a-and-baseline-mix-lgbm","580dbdad":"**Id Feaures**","8ee77914":"**Importing datasets**","f43ca456":"**Log**","1dc4bb45":"**Dropping below features as these seems to be repeating**","ea0b4569":"> thank you all please let me know where did I go wrong.\n> Thankyou","14f54998":"**Concatinating train and test as one dataframe**","68acab18":"> **Lightgbm**","55242bdd":"> From below we can see that length of features is 434","20d34d7f":"> From below we can see that there are a lot of features with almost 99% nan values","3ba93b0d":"**Displaying all the columns**","1b92586e":"**Submission**","c181e88c":"**Again seperating data into train and test**"}}