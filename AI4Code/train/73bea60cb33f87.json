{"cell_type":{"21894649":"code","c0a3caf8":"code","0b0ddacc":"code","ff26c1fb":"code","ac1e2a3d":"code","ae094ba3":"code","95768fa3":"code","4d6bb43a":"code","242c9e05":"code","cc483eea":"code","bed517fb":"code","9a3f34d5":"code","79baf9f6":"code","62b24413":"code","e5f6d80b":"code","34159e5a":"code","86127048":"code","e1c2a8ec":"code","59cf6e3c":"code","086691e8":"code","73d5016b":"code","9b91e75b":"code","0f394dfa":"code","4c268a15":"code","d090c226":"markdown","b5117cc8":"markdown","67268a0f":"markdown"},"source":{"21894649":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport tensorflow as tf\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Activation,Dropout","c0a3caf8":"#Loading the data\nDATAPATH = \"\/kaggle\/input\/wind-turbine-scada-dataset\/T1.csv\"\ndata = pd.read_csv(DATAPATH, index_col = ['Date\/Time'])\n\n#Parsing data dates\ndata['Date'] = pd.to_datetime(data.index, format=\"%d %m %Y %H:%M\")\ndata.set_index('Date',inplace=True)\n\n#Renaming columns\ndata = data.rename(columns={'LV ActivePower (kW)': 'Active_power','Wind Speed (m\/s)':'Wind_speed','Theoretical_Power_Curve (KWh)': 'Theoretical_power','Wind Direction (\u00b0)':'Wind_direction'})\ndata = data.dropna()","0b0ddacc":"data.info()","ff26c1fb":"data['Gust'] = np.array([0] + list(data['Wind_speed'][1:].values - data['Wind_speed'][:-1].values))","ac1e2a3d":"data","ae094ba3":"datax = np.asarray(data.copy().drop(['Active_power','Theoretical_power'],axis=1).values)\ndatay = data.copy()['Active_power'].values\nth_power = data['Theoretical_power'].values\n#datax = datax.reshape(datax.shape[0],datax.shape[1],1)\n#datay = datay.reshape(datay.shape[0],1)\n#th_power = th_power.reshape(th_power.shape[0],1)","95768fa3":"data_samples = datax.shape[0]\nx_train = datax[:int(0.7 * data_samples)]\nx_val = datax[int(0.7 * data_samples) : int(0.85 * data_samples)]\nx_test = datax[int(0.85 * data_samples) :]\n\ny_train = datay[:int(0.7 * data_samples)]\ny_val = datay[int(0.7 * data_samples) : int(0.85 * data_samples)]\ny_test = datay[int(0.85 * data_samples) :]","4d6bb43a":"print(\"Training examples: \" + str(x_train.shape[0]))\nprint(\"Validation examples: \" + str(x_val.shape[0]))\nprint(\"Test examples: \" + str(x_test.shape[0]))","242c9e05":"fig = plt.figure(figsize = (15,15))\n\nsns.heatmap(data.corr(), vmax = .8, square = True)\nplt.show()","cc483eea":"model = Sequential([\n    Dense(10,kernel_initializer = 'normal',input_shape = (3,),activation = 'relu'),\n    Dense(25,kernel_initializer = 'normal',activation = 'relu'),\n    Dense(25,kernel_initializer = 'normal',activation = 'relu'),\n    Dense(10,kernel_initializer = 'normal',activation = 'relu'),\n    Dense(1,kernel_initializer = 'normal',activation = 'linear')\n])\n\nmodel.compile(\n    loss = 'mean_absolute_error',optimizer='adam',metrics=['mean_absolute_error'])","bed517fb":"model.summary()","9a3f34d5":"from keras.callbacks import ModelCheckpoint","79baf9f6":"def display_training_curves(training,validation,title,subplot):\n    if subplot%10 == 1:\n        plt.subplots(figsize = (10,10),facecolor='#F0F0F0')\n        plt.tight_layout()\n    ax = plt.subplot(subplot)\n    ax.set_facecolor('#F8F8F8')\n    ax.plot(training)\n    ax.plot(validation)\n    ax.set_title('model '+ title)\n    ax.set_ylabel(title)\n    ax.set_xlabel('epoch')\n    ax.legend(['train', 'valid.'])","62b24413":"display_training_curves(fit.history['loss'], fit.history['val_loss'], 'loss', 211) ","e5f6d80b":"from keras.models import load_model\nmodel = load_model(\"\/kaggle\/input\/wind-neural-net\/my_model.hdf5\")","34159e5a":"model.summary()","86127048":"import types\nimport tempfile\nimport keras.models\n\ndef make_keras_picklable():\n    def __getstate__(self):\n        model_str = \"\"\n        with tempfile.NamedTemporaryFile(suffix='.hdf5', delete=True) as fd:\n            keras.models.save_model(self, fd.name, overwrite=True)\n            model_str = fd.read()\n        d = { 'model_str': model_str }\n        return d\n\n    def __setstate__(self, state):\n        with tempfile.NamedTemporaryFile(suffix='.hdf5', delete=True) as fd:\n            fd.write(state['model_str'])\n            fd.flush()\n            model = keras.models.load_model(fd.name)\n        self.__dict__ = model.__dict__\n\n\n    cls = keras.models.Model\n    cls.__getstate__ = __getstate__\n    cls.__setstate__ = __setstate__\n    \nmake_keras_picklable()","e1c2a8ec":"# Import pickle Package\n\nimport pickle\n# Save the Modle to file in the current working directory\n\nPkl_Filename = \"pickle_model.pkl\"  \n\nwith open(Pkl_Filename, 'wb') as file:  \n    pickle.dump(model, file)","59cf6e3c":"y_pred = model.predict(x_test)","086691e8":"y_pred[y_pred<0] = 0","73d5016b":"nik =   [ 8.51521484e+02,  1.01623571e+03,  1.19089645e+03,  1.10533343e+03,\n        1.42126503e+03,  1.39092575e+03,  1.41171925e+03,  1.82458728e+03,\n        1.85975805e+03,  1.67113438e+03,  1.81877738e+03,  1.93867418e+03,\n        2.34995526e+03,  2.44985588e+03,  2.01707775e+03,  3.24057570e+03,\n        2.86248240e+03,  3.17835318e+03,  3.22255214e+03,  3.09699840e+03,\n        3.49890318e+03,  3.12445214e+03,  3.18895054e+03,  3.08471571e+03,\n        3.26691114e+03,  1.82171707e+03,  1.91544339e+03,  1.44944391e+03,\n        1.54458367e+03,  1.82310455e+03,  1.46501644e+03,  1.69375105e+03,\n        1.52780627e+03,  1.32659679e+03,  1.38886342e+03,  1.40053397e+03,\n        1.87686883e+03,  1.53326245e+03,  1.42362900e+03,  1.02583679e+03,\n        4.58639510e+02,  1.95637024e+02,  2.44516846e+02,  8.30089462e+02,\n        9.79176848e+02,  9.41398620e+02,  8.09213764e+02,  1.99804222e+03,\n        1.98620114e+03,  2.06384231e+03,  1.59407199e+03,  1.26586770e+03,\n        8.76922306e+02,  1.24389006e+03,  7.50481531e+02,  6.98305033e+02,\n        5.24714408e+02,  8.30321045e+01,  8.94052562e+01,  1.67664450e+02,\n        4.33144801e+02, -2.47997683e+02,  2.16719896e+02,  2.88409002e+02,\n       -1.07121132e+02, -2.49083081e+02, -7.96218860e+01, -2.10658983e+02,\n        1.02015809e+02,  3.63323177e+02,  4.17509602e+02,  1.50050933e+02,\n        2.11442759e+02, -1.63285010e+02, -4.06918452e+02, -3.79267873e+02,\n       -1.03101782e+01, -5.89267347e+01, -3.68568317e+02, -3.05789541e+02,\n       -3.86028263e+02,  3.82210325e+02,  2.51759418e+01, -1.06567418e+02,\n       -3.80354949e+02, -2.92466634e+02, -2.71878321e+02,  6.86941191e+01,\n       -1.03984169e+02,  3.56347937e+02,  2.57185535e+02,  5.38580362e+02,\n        8.74398340e+02,  1.62759751e+03,  1.13121751e+03,  1.18955572e+03,\n        1.21611999e+03,  1.37472170e+03,  1.37715886e+03,  1.42569937e+03,\n        1.00776499e+03,  1.30461818e+03,  1.70371210e+03,  2.30239452e+03,\n        2.32295385e+03,  2.74813330e+03,  2.78814670e+03,  2.38518276e+03,\n        3.35873994e+03,  3.13122743e+03,  2.60118205e+03,  3.10602928e+03,\n        3.16470123e+03,  2.76378542e+03,  2.76054005e+03,  2.74330241e+03,\n        2.08901218e+03,  2.30237835e+03,  2.00655424e+03,  2.28623093e+03,\n        2.32853974e+03,  1.86848595e+03,  1.66337034e+03,  1.54578593e+03,\n        1.58895388e+03,  1.51492254e+03,  1.55838695e+03,  1.68895846e+03,\n        1.54354346e+03,  1.22693357e+03,  1.10181194e+03,  1.00793420e+03,\n        1.13239431e+03,  9.22975240e+02,  9.60059393e+02,  8.57524313e+02,\n        9.26119227e+02,  8.08307941e+02,  1.06247241e+03,  9.32240919e+02,\n        9.38194435e+02,  8.01207399e+02,  4.42662162e+02,  7.41969921e+01,\n        1.27983205e+02,  4.83270241e+02,  5.04443264e+02,  6.67900312e+02,\n        4.71723794e+02,  9.38194184e+02,  9.55824388e+02,  6.98600269e+02,\n        2.06911348e+02,  5.78985687e+02, -1.72951145e+01,  4.33062038e+01,\n        3.63866031e+02,  1.24061177e+02,  1.70151415e+02,  2.06254429e+02,\n        3.00178896e+02,  4.03852646e+02,  3.30182953e+02,  1.26384730e+03,\n       -1.99561652e+02, -1.48569702e+02,  3.59390232e+02,  6.11908042e+02,\n        8.36419805e+02,  6.82489734e+02,  9.87034454e+02,  1.54904624e+03,\n        1.55684058e+03,  7.55191836e+02,  1.36046778e+03,  1.64210252e+03,\n        1.12227941e+03,  1.47522436e+03,  1.14164933e+03,  1.92266273e+03,\n        1.30719009e+03,  1.44668277e+03,  2.15878830e+03,  1.97587614e+03,\n        2.42199325e+03,  1.98940977e+03,  2.40846796e+03,  2.39761384e+03,\n        2.51182015e+03,  2.32958413e+03,  2.66558333e+03,  2.29025056e+03,\n        1.86765778e+03,  2.44742757e+03,  1.53849161e+03,  2.29843416e+03,\n        2.22039106e+03,  2.76569998e+03,  2.68102327e+03,  2.64286281e+03,\n        2.50058146e+03,  2.44778308e+03,  2.27505711e+03,  2.04347937e+03,\n        2.16780014e+03,  2.54164189e+03,  2.65522627e+03,  2.61686600e+03,\n        2.72346776e+03,  2.58030136e+03,  2.76729915e+03,  2.73418637e+03,\n        2.72546543e+03,  2.58771867e+03,  2.35382768e+03,  2.03750691e+03,\n        1.83985326e+03,  1.64838525e+03,  1.68508791e+03,  1.19513160e+03,\n        1.69611728e+03,  2.02019172e+03,  1.25849269e+03,  1.62446472e+03,\n        1.40366416e+03,  1.59177103e+03,  1.63028711e+03,  1.33288228e+03,\n        1.10425744e+03,  9.83493526e+02,  9.46631049e+02,  1.16862614e+03,\n        1.17677933e+03,  1.62978971e+03,  1.57202558e+03,  2.27421715e+03,\n        2.25042913e+03,  3.41993428e+03,  3.65552558e+03,  3.38302847e+03,\n        3.62129487e+03,  3.41909439e+03,  3.58667261e+03,  3.40415902e+03,\n        4.20051722e+03,  4.20873206e+03,  4.37067194e+03,  4.55051574e+03,\n        4.80788750e+03,  4.88616800e+03,  4.85157008e+03,  4.37706484e+03,\n        3.99217682e+03,  3.96496857e+03,  3.26873625e+03,  2.18683745e+03,\n        1.50026085e+03,  2.30167846e+03,  1.55981550e+03,  1.14248964e+03,\n        2.06204507e+03,  1.68078370e+03,  1.86655747e+03,  1.77710059e+03,\n        1.81385164e+03,  1.88589382e+03,  1.86817029e+03,  1.85686882e+03,\n        1.82958581e+03,  1.77357430e+03,  1.76344603e+03,  2.04094265e+03,\n        2.13016265e+03,  1.43835981e+03,  1.85547694e+03,  1.73458580e+03,\n        1.75489293e+03,  1.69784543e+03,  2.23088999e+03,  1.82793575e+03,\n        1.74234232e+03,  1.77183870e+03,  1.91201296e+03,  8.30838475e+02,\n        1.19634886e+03,  9.33444208e+02,  9.35616904e+02,  1.43166615e+03,\n        1.04570419e+03,  9.53554065e+02,  5.69438657e+02,  3.22069609e+02,\n        9.70517531e+02,  4.93357401e+02,  4.66630225e+02,  5.69213298e+02,\n        1.62113121e+02,  4.76129982e+02,  1.10759022e+02,  1.89148625e+01,\n        4.58126108e+02,  1.57970933e+02,  7.54565814e+01,  2.94177894e+02,\n        5.03899099e+02,  3.24763090e+02,  2.63366369e+01,  4.82054364e+02,\n       -2.31515372e+02,  3.05829551e+02,  2.38352933e+02,  4.45735949e+02,\n        2.94194470e+02,  3.33328909e+02,  1.91263596e+02,  9.99865895e+02,\n        1.23415155e+03,  4.38083456e+02,  2.71174173e+02,  7.21448310e+02,\n        5.01557076e+02,  3.41581053e+02,  1.07629964e+02,  1.55365981e+02,\n        2.26440258e+01,  7.07974418e+01,  3.65146674e+02,  2.50183599e+02,\n        1.69713267e+02,  1.91605759e+02,  2.16755738e+02,  2.14906525e+02,\n        2.66815280e+02,  2.17965333e+02,  3.75335675e+02, -1.60995244e+02,\n       -2.14698767e+02, -1.04760109e+02, -1.68449905e+02, -2.19145201e+02,\n        1.12729000e+02,  3.68275957e+02,  5.83343644e+02,  9.31368552e+02,\n        1.00182005e+03,  1.21546124e+03,  1.23092434e+03,  5.59600503e+02,\n        6.55130193e+02,  7.73164068e+02,  8.87526181e+02,  9.75655261e+02,\n        1.07593240e+03,  8.21135809e+02,  5.17212873e+02,  8.59357235e+02,\n        7.21844702e+02,  1.18969258e+03,  1.38266660e+03,  1.26101321e+03,\n        1.28439888e+03,  1.38932503e+03,  1.05467945e+03,  1.07286627e+03,\n        6.80593604e+02,  4.89291783e+02,  2.48779036e+02,  3.56540367e+02,\n        2.91870617e+02,  6.03955663e+02,  1.48236745e+03,  1.72274836e+03,\n        1.16489353e+03,  1.06792792e+03,  1.23943228e+03,  1.03961320e+03,\n        8.21326269e+02,  6.42312704e+02,  3.30650561e+02,  1.60095360e+02,\n        1.32697952e+02, -2.81844145e+02,  1.95158667e+00,  1.19512335e+00,\n        1.58879468e+02, -1.88845264e+02, -2.82409889e+02, -4.35130282e+02,\n        1.61193943e+02, -1.07704884e+02,  3.70392471e+00,  8.34111657e+01,\n        6.32761513e+01,  1.36570105e+02, -9.24061441e+01, -1.26863290e+02,\n       -1.90574335e+02, -3.84971008e+02, -4.45835741e+02,  1.33243730e+02,\n        1.45803784e+02, -2.97753211e+01, -3.18130568e+02, -3.08814111e+01,\n       -4.18074762e+02, -4.86910824e+02, -3.24349350e+02, -3.44428847e+02,\n        9.30608120e+01, -1.81537074e+02,  1.65755110e+02,  1.50283674e+02,\n        4.97699635e+02,  8.81159344e+02,  1.32012942e+03,  6.57431647e+02,\n        5.66315669e+02,  7.70975979e+02,  1.65560430e+03,  1.94039070e+03,\n        2.09389839e+03,  2.62702796e+03]","9b91e75b":"plt.figure(figsize=(12,7))\nplt.plot(y_pred[-1000:],'r',label='Neural Net')\nplt.plot(y_test[-1000:],'b',label='Real Values')\n#plt.plot(nik,'g',label='Time series')\nplt.legend()\nplt.show()","0f394dfa":"y_pred","4c268a15":"y_test","d090c226":"filepath = \"my_model.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')","b5117cc8":"data = data.asfreq('h')\ndata = data.dropna()","67268a0f":"callbacks_list = [checkpoint]\n\nfit = model.fit(x_train,y_train,validation_data=(x_val,y_val),epochs=200,verbose=1,callbacks= callbacks_list)"}}