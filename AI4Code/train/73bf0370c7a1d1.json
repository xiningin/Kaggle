{"cell_type":{"d6884132":"code","42d558f9":"code","df698ae9":"code","0289941b":"code","127522b8":"code","5597a5f6":"code","42c67312":"code","52a5e1bb":"code","12451349":"code","1aa3c58a":"code","dd70497c":"code","51f84a88":"code","e833d85c":"code","675c0f34":"code","59ee1ddc":"code","d21f284f":"code","9d230190":"code","09bc4f83":"code","8a6c9872":"code","0b57f894":"code","910e0e6d":"code","28af9871":"code","6cfeb9d4":"code","2d0a7602":"code","ad31c4d2":"code","af07e3c7":"code","375a45be":"code","96e46d44":"code","33796025":"code","78d77c6b":"markdown","20791d71":"markdown","ec2ba41d":"markdown","852481b7":"markdown","5eafb5f5":"markdown"},"source":{"d6884132":"import tensorflow_hub as th,tensorflow as tf\nimport os,numpy as np,pandas as pd,pylab as pl\nfrom tensorflow.keras.datasets import mnist\nimport tensorflow.keras.layers as tkl\nimport tensorflow.keras.callbacks as tkc\nfrom tensorflow.keras.preprocessing.image \\\nimport ImageDataGenerator","42d558f9":"df_train=pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ndf_test=pd.read_csv('..\/input\/digit-recognizer\/test.csv')\nprint([df_train.shape,df_test.shape])\nprint(df_train.iloc[265,1:].values.reshape(28,28)[:,10])","df698ae9":"images=['%s%s'%('pixel',pixel_no) for pixel_no in range(0,784)]\nx_train=df_train[images].values\/255.\nx_train=x_train.reshape(-1,28,28,1)\ny_train=df_train['label'].values\nx_test_out=df_test[images].values\/255.\nx_test_out=x_test_out.reshape(-1,28,28,1)","0289941b":"num_classes=10; img_size,img_size2=28,96\nN=df_train.shape[0]; n=int(.1*N)\nshuffle_ids=np.arange(N)\nnp.random.RandomState(123).shuffle(shuffle_ids)\nx_train=x_train[shuffle_ids]; y_train=y_train[shuffle_ids]\nx_test,x_valid,x_train=\\\nx_train[:n],x_train[n:2*n],x_train[2*n:]\ny_test,y_valid,y_train=\\\ny_train[:n],y_train[n:2*n],y_train[2*n:]\ndf=pd.DataFrame(\n    [[x_train.shape,x_valid.shape,x_test.shape],\n     [x_train.dtype,x_valid.dtype,x_test.dtype],\n     [y_train.shape,y_valid.shape,y_test.shape],\n     [y_train.dtype,y_valid.dtype,y_test.dtype]],\n    columns=['train','valid','test'],\n    index=['image shape','image type','label shape','label type'])\ndf","127522b8":"fig,ax=pl.subplots(\n    figsize=(10,2),nrows=1,\n    ncols=5,sharex=True,sharey=True)\nax=ax.flatten()\nfor i in range(5):\n    image=x_train[i].reshape(28,28)\n    ax[i].imshow(image,cmap=pl.cm.bone)\nax[0].set_xticks([]); ax[0].set_yticks([])\npl.tight_layout(); pl.gcf()\nax[2].set_title(\n    'Examples of the 784-dimensional digits',fontsize=25);","5597a5f6":"def model():\n    model=tf.keras.Sequential()\n    model.add(tkl.Input(shape=(28,28,1)))\n    model.add(tkl.BatchNormalization())  \n    model.add(tkl.Conv2D(28,(5,5),padding='same'))\n    model.add(tkl.LeakyReLU(alpha=.02))\n    model.add(tkl.MaxPooling2D(pool_size=(2,2)))\n    model.add(tkl.Dropout(.2))   \n    model.add(tkl.Conv2D(96,(5,5),padding='same'))\n    model.add(tkl.LeakyReLU(alpha=.02))\n    model.add(tkl.MaxPooling2D(strides=(2,2)))\n    model.add(tkl.Dropout(.2))\n    model.add(tkl.Conv2D(128,(5,5)))\n    model.add(tkl.LeakyReLU(alpha=.02))\n    model.add(tkl.MaxPooling2D(strides=(2,2)))\n    model.add(tkl.Dropout(.2)) \n    model.add(tkl.GlobalMaxPooling2D())\n    model.add(tkl.Dense(1024))\n    model.add(tkl.LeakyReLU(alpha=.02))\n    model.add(tkl.Dropout(.5))  \n    model.add(tkl.Dense(num_classes,activation='softmax'))        \n    model.compile(loss='sparse_categorical_crossentropy',\n                  optimizer='nadam',\n                  metrics=['sparse_categorical_accuracy'])\n    return model","42c67312":"cnn_model=model()\ncheckpointer=tkc.ModelCheckpoint(\n    filepath='\/tmp\/checkpoint',verbose=2,save_weights_only=True,\n    monitor='val_sparse_categorical_accuracy',mode='max',save_best_only=True)\nlr_reduction=tkc.ReduceLROnPlateau(\n    monitor='val_loss',patience=15,verbose=2,factor=.8)\nearly_stopping=tkc.EarlyStopping(\n    monitor='val_loss',patience=75,verbose=2)\nhistory=cnn_model.fit(\n    x_train,y_train,epochs=120,batch_size=128,\n    verbose=2,validation_data=(x_valid,y_valid),\n    callbacks=[checkpointer,lr_reduction,early_stopping])","52a5e1bb":"def history_plot(history):\n    pl.figure(figsize=(12,5))\n    pl.plot(history.history['sparse_categorical_accuracy'][3:],\n            '-o',label='train')\n    pl.plot(history.history['val_sparse_categorical_accuracy'][3:],\n            '-o',label='valid')\n    pl.legend(); pl.title('CNN Accuracy'); pl.show()","12451349":"cnn_model.load_weights('\/tmp\/checkpoint')\nscores=cnn_model.evaluate(x_test,y_test,verbose=0)","1aa3c58a":"history_plot(history)\nprint('CNN Scores: ',(scores))\nprint('CNN Error: %.2f%%'%(100-scores[1]*100))","dd70497c":"steps,epochs=int(len(x_train)\/128),10\ndatagen=ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    zoom_range=.2,shear_range=.2,rotation_range=30,\n    height_shift_range=.2,width_shift_range=.2)\ndatagen.fit(x_train)\nhistory=cnn_model.\\\nfit(datagen.flow(x_train,y_train,batch_size=128),\n    steps_per_epoch=steps,epochs=epochs,verbose=2,\n    validation_data=datagen.flow(x_valid,y_valid,batch_size=16), \n    callbacks=[checkpointer,lr_reduction,early_stopping])","51f84a88":"cnn_model.load_weights('\/tmp\/checkpoint')\nscores=cnn_model.evaluate(x_test,y_test,verbose=0)","e833d85c":"history_plot(history)\nprint('CNN Scores: ',(scores))\nprint('CNN Error: %.2f%%'%(100-scores[1]*100))","675c0f34":"y_test_predictions=\\\ncnn_model.predict(x_test).argmax(axis=-1)\npl.figure(figsize=(12,5))\npl.scatter(range(150),y_test[:150],s=100)\npl.scatter(range(150),y_test_predictions[:150],s=25);","59ee1ddc":"predict_y_test_out=cnn_model.predict(x_test_out)\npredict_y_test_out=predict_y_test_out.argmax(axis=-1)","d21f284f":"submission=pd.DataFrame(\n    {'ImageId':range(1,len(predict_y_test_out)+1), \n     'Label':predict_y_test_out})\nprint(submission[0:15].T)\nsubmission.to_csv('kaggle_digits_cnn.csv',index=False)","9d230190":"fig,ax=pl.subplots(figsize=(12,6),nrows=3,ncols=5,sharex=True,sharey=True)\nax=ax.flatten()\nfor i in range(15):\n    image=x_test_out[i].reshape(28,28)\n    ax[i].imshow(image,cmap=pl.cm.bone)\nax[0].set_xticks([]); ax[0].set_yticks([])\nax[2].set_title('Examples of digits. Test datapoints',fontsize=25)\npl.tight_layout(); pl.gcf(); pl.show()","09bc4f83":"os.environ['TFHUB_MODEL_LOAD_FORMAT']='COMPRESSED'\nmodel=th.load('https:\/\/tfhub.dev\/captain-pool\/esrgan-tf2\/1')\nfunc=model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\nfunc.inputs[0].set_shape([1,img_size2\/\/4,img_size2\/\/4,3])\nconverter=tf.lite.TFLiteConverter.from_concrete_functions([func])\nconverter.optimizations=[tf.lite.Optimize.DEFAULT]\ntflite_model=converter.convert()\nwith tf.io.gfile.GFile('ESRGAN.tflite','wb') as f:\n     f.write(tflite_model)\nesrgan_model_path='.\/ESRGAN.tflite'","8a6c9872":"N3=10000; n3=int(.1*N3)\nx_train3=x_train[:N3]; y_train3=y_train[:N3]\nx_valid3=x_valid[:n3]; y_valid3=y_valid[:n3]\nx_test3=x_test[:n3]; y_test3=y_test[:n3]\nx_train3=tf.repeat(x_train3,3,axis=3).numpy()\nx_valid3=tf.repeat(x_valid3,3,axis=3).numpy()\nx_test3=tf.repeat(x_test3,3,axis=3).numpy()\nx_test3.shape,x_test3.mean()","0b57f894":"def bicubic_resize(imgs,img_size=img_size2):\n    bicubic=tf.image.resize(\n        imgs*255,[img_size,img_size],tf.image.ResizeMethod.BICUBIC)\n    bicubic_contrast=tf.image.adjust_contrast(bicubic,.8)\n    bicubic_contrast=tf.cast(bicubic_contrast,tf.uint8)\n    return bicubic_contrast.numpy()\/255","910e0e6d":"x_train3=bicubic_resize(x_train3)\nx_valid3=bicubic_resize(x_valid3)\nx_test3=bicubic_resize(x_test3)\nx_test3.shape,x_test3.mean()","28af9871":"fig,ax=pl.subplots(\n    figsize=(10,2),nrows=1,\n    ncols=5,sharex=True,sharey=True)\nax=ax.flatten()\nfor i in range(5):\n    ax[i].imshow(x_train3[i])\nax[0].set_xticks([]); ax[0].set_yticks([])\npl.tight_layout(); pl.gcf()\nax[2].set_title(\n    f'Examples of the {img_size2}*{img_size2}*3-dimensional digits',\n    fontsize=25);","6cfeb9d4":"def esrgantf2_superresolution(\n    img,super_size=img_size2,model_path=esrgan_model_path):\n    if img.mean()<1.: img=img*255.\n    lr=tf.image.resize(img,[super_size\/\/4,super_size\/\/4])\n    lr=tf.expand_dims(lr.numpy()[:,:,:3],axis=0)\n    lr=tf.cast(lr,tf.float32)\n    interpreter=tf.lite.Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n    input_details=interpreter.get_input_details()\n    output_details=interpreter.get_output_details()\n    interpreter.set_tensor(input_details[0]['index'],lr)\n    interpreter.invoke()\n    output_data=interpreter.get_tensor(output_details[0]['index'])\n    sr=tf.squeeze(output_data,axis=0)\n    sr=tf.clip_by_value(sr,0,255)\n    sr=tf.round(sr); sr=tf.cast(sr,tf.uint8)\n    lr=tf.cast(tf.squeeze(lr,axis=0),tf.uint8)\n    return lr,sr","2d0a7602":"def low2superbicubic_imgs(img,lr,sr,img_size=img_size2):\n    pl.figure(figsize=(10,3))\n    pl.subplot(1,4,1); pl.title('HR'); pl.imshow(img)\n    pl.subplot(1,4,2); pl.title('LR'); pl.imshow(lr.numpy())\n    pl.subplot(1,4,3); pl.title(f'ESRGAN x4'); pl.imshow(sr.numpy())\n    bicubic=tf.image.resize(\n        lr,[img_size2,img_size2],tf.image.ResizeMethod.BICUBIC)\n    bicubic_contrast=tf.image.adjust_contrast(bicubic,.8)\n    bicubic_contrast=tf.cast(bicubic_contrast,tf.uint8)\n    pl.subplot(1,4,4); pl.title('Bicubic & Contrast')\n    pl.imshow(bicubic_contrast.numpy())\n    pl.tight_layout(); pl.show()","ad31c4d2":"for i in range(5):\n    lr,sr=esrgantf2_superresolution(\n        tf.repeat(x_train[i],3,axis=2).numpy())\n    low2superbicubic_imgs(\n        tf.repeat(x_train[i],3,axis=2).numpy(),lr,sr)","af07e3c7":"def premodel(pix,den,mh,lbl,activ,loss):\n    model=tf.keras.Sequential([\n        tkl.Input((pix,pix,3),name='input'),\n        th.KerasLayer(mh,trainable=True),\n        tkl.Flatten(),\n        tkl.Dense(den,activation='relu'),\n        tkl.Dropout(rate=.5),\n        tkl.Dense(lbl,activation=activ)])\n    model.compile(optimizer='nadam',loss=loss,\n                  metrics=['sparse_categorical_accuracy'])\n    return model\ndef cb(fw):\n    early_stopping=tkc.EarlyStopping(\n        monitor='val_loss',patience=10,verbose=2)\n    checkpointer=tkc.ModelCheckpoint(\n        filepath=fw,verbose=2,save_weights_only=True,\n        monitor='val_sparse_categorical_accuracy',\n        mode='max',save_best_only=True)\n    lr_reduction=tkc.ReduceLROnPlateau(\n        monitor='val_loss',verbose=2,patience=5,factor=.8)\n    return [checkpointer,early_stopping,lr_reduction]","375a45be":"fw='\/tmp\/checkpoint'\nhandle_base='mobilenet_v2_100_%d'%img_size2\nmhandle='https:\/\/tfhub.dev\/google\/imagenet\/{}\/classification\/4'\\\n.format(handle_base)\nhub_model=premodel(img_size2,1024,mhandle,num_classes,\n                  'softmax','sparse_categorical_crossentropy')\nhistory=hub_model.fit(x=x_train3,y=y_train3,batch_size=128,\n                      epochs=20,callbacks=cb(fw),verbose=0,\n                      validation_data=(x_valid3,y_valid3))","96e46d44":"hub_model.load_weights('\/tmp\/checkpoint')\nhub_model.evaluate(x_test3,y_test3,verbose=0)","33796025":"y_test_predictions3=\\\nhub_model.predict(x_test3).argmax(axis=-1)\npl.figure(figsize=(10,5))\npl.scatter(range(200),y_test3[:200],s=100)\npl.scatter(range(200),y_test_predictions3[:200],s=25);","78d77c6b":"## CNN Like Models","20791d71":"## Code Modules","ec2ba41d":"## Data Transforming","852481b7":"## Data Loading","5eafb5f5":"## Hub Classifiers"}}