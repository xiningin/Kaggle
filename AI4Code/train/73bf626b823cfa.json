{"cell_type":{"a07274e4":"code","9b3a0dd6":"code","bf67dc07":"code","61825849":"code","8d542315":"code","408ce4ca":"code","5300d2f7":"code","16396c30":"code","95020d9d":"code","0572d700":"code","020fe26f":"code","b720ef35":"code","cec0134a":"code","d83f7b03":"code","8facb28b":"code","5c1d8d96":"code","41a18421":"code","2d3565f0":"code","61b7a827":"code","774dc465":"code","e7055107":"code","4f088897":"code","c5776ac3":"code","4dc8eeda":"code","7bb2969f":"code","b299089b":"code","9539981d":"code","41c67692":"code","f0fa1cc5":"code","d1471640":"code","e15fd1c7":"code","5759a818":"code","68706434":"code","a585cad9":"code","55a9a832":"code","0014b970":"code","92e50340":"code","54b8085b":"code","b37f3411":"code","955a5afb":"code","dd44e328":"code","06b77707":"code","51e862bb":"code","6513b382":"code","e392ff8b":"code","a5de5c7b":"code","321cfb59":"code","1f9c5bdb":"markdown","f3b021fd":"markdown","3a33a22f":"markdown","fed8dd1c":"markdown","629562dc":"markdown","4a72b17e":"markdown","fa281a9b":"markdown","7228588f":"markdown","1c1de4f0":"markdown","9bc84578":"markdown","92ec69d4":"markdown"},"source":{"a07274e4":"## Importing the required libraries\n###################################\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport plotly \nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.offline as py\nfrom plotly.offline import iplot\nfrom plotly.subplots import make_subplots\nimport plotly.figure_factory as ff\n\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler","9b3a0dd6":"## Read and Examine the Dataset\n###################################\n\ndf = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ndf.head()","bf67dc07":"df.columns","61825849":"df.columns = [col.upper() for col in df.columns]","8d542315":"print(df.columns.values)","408ce4ca":"df.shape","5300d2f7":"## Getting information about the missing values and data types in the dateset\n###############################################################################\n\ndf.info()","16396c30":"sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap=\"viridis\")","95020d9d":"df.sample(10)","0572d700":"#############################################\n## Arrange the columns in the dataset according to the information given in the dictionary of the dataset\n#############################################\n\n    \n# Cabin bool\ndf[\"NEW_CABIN_BOOL\"] = df[\"CABIN\"].notnull().astype('int')\n# Name count\ndf[\"NEW_NAME_COUNT\"] = df[\"NAME\"].str.len()\n# name word count\ndf[\"NEW_NAME_WORD_COUNT\"] = df[\"NAME\"].apply(lambda x: len(str(x).split(\" \")))\n# name dr with .\ndf[\"NEW_NAME_DR\"] = df[\"NAME\"].apply(lambda x: len([x for x in x.split() if x.startswith(\"Dr.\")]))\n# name title\ndf['NEW_TITLE'] = df.NAME.str.extract(' ([A-Za-z]+)\\.', expand=False)\n# family size\ndf[\"NEW_FAMILY_SIZE\"] = df[\"SIBSP\"] + df[\"PARCH\"] + 1\n# age_pclass\ndf[\"NEW_AGE_PCLASS\"] = df[\"AGE\"] * df[\"PCLASS\"]\n# is alone\ndf.loc[((df['SIBSP'] + df['PARCH']) > 0), \"NEW_IS_ALONE\"] = \"NO\"\ndf.loc[((df['SIBSP'] + df['PARCH']) == 0), \"NEW_IS_ALONE\"] = \"YES\"\n# age level\ndf.loc[(df['AGE'] < 18), 'NEW_AGE_CAT'] = 'young'\ndf.loc[(df['AGE'] >= 18) & (df['AGE'] < 56), 'NEW_AGE_CAT'] = 'mature'\ndf.loc[(df['AGE'] >= 56), 'NEW_AGE_CAT'] = 'senior'\n# sex x age\ndf.loc[(df['SEX'] == 'male') & (df['AGE'] <= 21), 'NEW_SEX_CAT'] = 'youngmale'\ndf.loc[(df['SEX'] == 'male') & ((df['AGE'] > 21) & (df['AGE']) <= 50), 'NEW_SEX_CAT'] = 'maturemale'\ndf.loc[(df['SEX'] == 'male') & (df['AGE'] > 50), 'NEW_SEX_CAT'] = 'seniormale'\ndf.loc[(df['SEX'] == 'female') & (df['AGE'] <= 21), 'NEW_SEX_CAT'] = 'youngfemale'\ndf.loc[(df['SEX'] == 'female') & ((df['AGE'] > 21) & (df['AGE']) <= 50), 'NEW_SEX_CAT'] = 'maturefemale'\ndf.loc[(df['SEX'] == 'female') & (df['AGE'] > 50), 'NEW_SEX_CAT'] = 'seniorfemale'\n","020fe26f":"df.head()","b720ef35":"df.info()","cec0134a":"def overview_dataset(dataframe, cat_th=10, car_th=20):\n    \n    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n\n    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n                   dataframe[col].dtypes != \"O\"]\n\n    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n                   dataframe[col].dtypes == \"O\"]\n\n    cat_cols = cat_cols + num_but_cat\n    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n\n    \n    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n    num_cols = [col for col in num_cols if col not in num_but_cat]\n\n    print(f\"Observations: {dataframe.shape[0]}\")\n    print(f\"Variables: {dataframe.shape[1]}\")\n    print(f'cat_cols: {len(cat_cols)}')\n    print(f'num_cols: {len(num_cols)}')\n    print(f'cat_but_car: {len(cat_but_car)}')\n    print(f'num_but_cat: {len(num_but_cat)}')\n\n    return cat_cols, num_cols, cat_but_car","d83f7b03":"cat_cols, num_cols, cat_but_car = overview_dataset(df)\nnum_cols = [col for col in num_cols if \"PASSENGERID\" not in col]","8facb28b":"sns.boxplot(x='EMBARKED', y='FARE', data=df)\nplt.title(\"Fare distribution as function of Embarked Port\")\nplt.show()","5c1d8d96":"def outlier_winsorize(df, col):\n    Q1 = df[col].quantile(0.25)\n    Q3 = df[col].quantile(0.75)\n    IQR = Q3 - Q1\n    upper = Q3 + 1.5 * IQR\n    lower = Q1 - 1.5 * IQR\n    df.loc[(df[col] < lower), col] = lower\n    df.loc[(df[col] > upper), col] = upper\n   ","41a18421":"num_cols","2d3565f0":"for col in num_cols:\n    outlier_winsorize(df,col)","61b7a827":"sns.boxplot(y='FARE', data=df)\nplt.title(\"Age distribution as function of Embarked Port\")\nplt.show()","774dc465":"## Drop the missing values in the \"CABIN\" column\n\ndf.drop(\"CABIN\", inplace=True, axis=1)","e7055107":"remove_cols = [\"TICKET\", \"NAME\"]\ndf.drop(remove_cols, inplace=True, axis=1)","4f088897":"df[\"NEW_TITLE\"].value_counts()","c5776ac3":"\ndf[\"AGE\"] = df[\"AGE\"].fillna(df.groupby(\"NEW_TITLE\")[\"AGE\"].transform(\"median\"))\n\n\ndf[\"NEW_AGE_PCLASS\"] = df[\"AGE\"] * df[\"PCLASS\"]\ndf.loc[(df['AGE'] < 18), 'NEW_AGE_CAT'] = 'young'\ndf.loc[(df['AGE'] >= 18) & (df['AGE'] < 56), 'NEW_AGE_CAT'] = 'mature'\ndf.loc[(df['AGE'] >= 56), 'NEW_AGE_CAT'] = 'senior'\n\ndf.loc[(df['SEX'] == 'male') & (df['AGE'] <= 21), 'NEW_SEX_CAT'] = 'youngmale'\ndf.loc[(df['SEX'] == 'male') & ((df['AGE'] > 21) & (df['AGE']) <= 50), 'NEW_SEX_CAT'] = 'maturemale'\ndf.loc[(df['SEX'] == 'male') & (df['AGE'] > 50), 'NEW_SEX_CAT'] = 'seniormale'\ndf.loc[(df['SEX'] == 'female') & (df['AGE'] <= 21), 'NEW_SEX_CAT'] = 'youngfemale'\ndf.loc[(df['SEX'] == 'female') & ((df['AGE'] > 21) & (df['AGE']) <= 50), 'NEW_SEX_CAT'] = 'maturefemale'\ndf.loc[(df['SEX'] == 'female') & (df['AGE'] > 50), 'NEW_SEX_CAT'] = 'seniorfemale'\n\ndf = df.apply(lambda x: x.fillna(x.mode()[0]) if (x.dtype == \"O\" and len(x.unique()) <= 10) else x, axis=0)","4dc8eeda":"pd.isnull(df).sum()","7bb2969f":"sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap=\"viridis\")","b299089b":"def label_encoder(df, binary_col):\n    labelencoder = LabelEncoder()\n    df[binary_col] = labelencoder.fit_transform(df[binary_col])\n    return df","9539981d":"binary_cols = [col for col in df.columns if df[col].dtype not in [int, float] and df[col].nunique() == 2]\n\nfor col in binary_cols:\n    df = label_encoder(df, col)","41c67692":"def rare_encoder(df, rare_perc):\n    temp_df = df.copy()\n\n    rare_columns = [col for col in temp_df.columns if temp_df[col].dtypes == 'O'\n                    and (temp_df[col].value_counts() \/ len(temp_df) < rare_perc).any(axis=None)]\n\n    for var in rare_columns:\n        tmp = temp_df[var].value_counts() \/ len(temp_df)\n        rare_labels = tmp[tmp < rare_perc].index\n        temp_df[var] = np.where(temp_df[var].isin(rare_labels), 'Rare', temp_df[var])\n\n    return temp_df","f0fa1cc5":"df = rare_encoder(df, 0.01)","d1471640":"def one_hot_encoder(df, categorical_cols, drop_first=False):\n    df = pd.get_dummies(df, columns=categorical_cols, drop_first=drop_first)\n    return df","e15fd1c7":"oneHotEncoder_cols = [col for col in df.columns if 10 >= df[col].nunique() > 2]\n\n#get dummies\ndf = one_hot_encoder(df, oneHotEncoder_cols)\n","5759a818":"cat_cols, num_cols, cat_but_car = overview_dataset(df)\nnum_cols = [col for col in num_cols if \"PASSENGERID\" not in col]\n","68706434":"useless_cols = [col for col in df.columns if df[col].nunique() == 2 and (df[col].value_counts() \/ len(df) < 0.01).any(axis=None)]\n\ndf.drop(useless_cols, axis=1, inplace=True)","a585cad9":"df.shape","55a9a832":"df.head(30)","0014b970":"scaler = StandardScaler()\ndf[num_cols] = scaler.fit_transform(df[num_cols])","92e50340":"df.head()","54b8085b":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, \\\n    roc_auc_score, confusion_matrix, classification_report, plot_roc_curve\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ny = df[\"SURVIVED\"]\nX = df.drop([\"SURVIVED\", \"PASSENGERID\"], axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n\nlog_model = LogisticRegression().fit(X_train, y_train)\nlog_model.intercept_\nlog_model.coef_","b37f3411":"\ny_pred = log_model.predict(X_test)\ny_pred[0:10]\ny_test[0:10].to_list()\n\n# prediction\nlog_model.predict_proba(X_test)[0:10]\n\n# The probabilities of belonging to the 1st class:\ny_prob = log_model.predict_proba(X_test)[:, 1]\n\n##########################\n# Evaluation\n##########################\n# AUC Score for y_prob\ny_prob = log_model.predict_proba(X_test)[:, 1]\n\n# Other metrics for y_pred\ny_pred = log_model.predict(X_test)\n\n\n# CONFUSION MATRIX\ndef plot_confusion_matrix(y, y_pred):\n    acc = round(accuracy_score(y, y_pred), 2)\n    cm = confusion_matrix(y, y_pred)\n    sns.heatmap(cm, annot=True, fmt=\".0f\")\n    plt.xlabel('y_pred')\n    plt.ylabel('y')\n    plt.title('Accuracy Score: {0}'.format(acc), size=10)\n    plt.show()\n\nplot_confusion_matrix(y_test, y_pred)\n","955a5afb":"# ACCURACY\naccuracy_score(y_test, y_pred)","dd44e328":"# PRECISION\nprecision_score(y_test, y_pred)","06b77707":"# RECALL\nrecall_score(y_test, y_pred)","51e862bb":"# F1\nf1_score(y_test, y_pred)","6513b382":"# AUC\nroc_auc_score(y_test, y_prob)","e392ff8b":"# ROC CURVE\nplot_roc_curve(log_model, X_test, y_test)\nplt.title('ROC Curve')\nplt.plot([0, 1], [0, 1], 'r--')\nplt.show()\n\n# Classification report\nprint(classification_report(y_test, y_pred))","a5de5c7b":"women = df.loc[df.SEX == 0][\"SURVIVED\"]\nrate_women = sum(women)\/len(women) if len(women) != 0 else 0\n\nprint(\"% of women who survived:\", rate_women)","321cfb59":"men = df.loc[df.SEX == 1][\"SURVIVED\"]\nrate_men = sum(men)\/len(men)\n\nprint(\"% of men who survived:\", rate_men)","1f9c5bdb":"## Introduction","f3b021fd":"## PREDICTION","3a33a22f":"** The dataset contains information about the people involved in the Titanic shipwreck.\n\n** It consists of 891 observations and 12 variables.\n\n** The target variable is specified as \"Survived\"; 1 indicates the survival of the person and 0 indicates the death of the person.","fed8dd1c":"![7-15-2021%202-04-39%20PM.jpg](attachment:7-15-2021%202-04-39%20PM.jpg)","629562dc":"### Applying Standart Scaler","4a72b17e":"##### As you can see, there are some variables in the NEW_TITLE colon. \nThese values were grouped in their own, and their medians were taken, and the missing values were filled with these values.","fa281a9b":"#### Rare Variable Analysis. \nIn the \"NEW_TITLE\" column, there are many values such as dr., col, capt, which are rarely mentioned. We will rare encode this variable.","7228588f":"## 1.Step Exploratory Data Analysis (EDA)","1c1de4f0":"## MODEL","9bc84578":"# Titanic: Machine Learning from Disaster","92ec69d4":"THANKS!"}}