{"cell_type":{"ade11c8d":"code","c5166c66":"code","946664ab":"code","b27116da":"code","5a367ded":"code","33c2eab5":"code","588471b9":"code","2782ecd3":"code","c8377f01":"code","76198207":"code","620ef220":"code","6520e112":"code","72e6c19f":"code","4b73c2d6":"code","f788dc9d":"code","e02288f5":"code","ae619488":"code","cfac1c4e":"code","e8b23aa6":"code","52712631":"code","a8a43fbc":"code","1baa0e61":"code","921d01f9":"code","57b4658d":"code","cf880fcf":"code","d802a0a3":"markdown","0d0cc370":"markdown","caac25f7":"markdown","a644257c":"markdown","cc1792ef":"markdown","020b01d0":"markdown","86f0bcf9":"markdown","cc14f47c":"markdown","99acf09e":"markdown","d897c5a6":"markdown","75071663":"markdown"},"source":{"ade11c8d":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport numpy as np\nimport pandas as pd\nfrom bs4 import BeautifulSoup\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\nfrom nltk.tokenize import TweetTokenizer\n\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\nfrom sklearn.pipeline import make_pipeline, Pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import make_scorer, accuracy_score, f1_score\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import confusion_matrix, roc_auc_score, recall_score, precision_score","c5166c66":"data = pd.read_csv(\"..\/input\/twitter-airline-sentiment\/Tweets.csv\")","946664ab":"data_clean = data.copy()\ndata_clean = data_clean[data_clean['airline_sentiment_confidence'] > 0.65]\ndata_clean['sentiment'] = data_clean['airline_sentiment'].\\\n    apply(lambda x: 1 if x=='negative' else 0)\n\ndata_clean['text_clean'] = data_clean['text'].apply(lambda x: BeautifulSoup(x, \"lxml\").text)","b27116da":"data_clean['sentiment'] = data_clean['airline_sentiment'].apply(lambda x: 1 if x=='negative' else 0)","5a367ded":"data_clean = data_clean.loc[:, ['text_clean', 'sentiment']]","33c2eab5":"data_clean.head()","588471b9":"train, test = train_test_split(data_clean, test_size=0.2, random_state=1)\nX_train = train['text_clean'].values\nX_test = test['text_clean'].values\ny_train = train['sentiment']\ny_test = test['sentiment']","2782ecd3":"def tokenize(text): \n    tknzr = TweetTokenizer()\n    return tknzr.tokenize(text)\n\ndef stem(doc):\n    return (stemmer.stem(w) for w in analyzer(doc))\n\nen_stopwords = set(stopwords.words(\"english\")) \n\nvectorizer = CountVectorizer(\n    analyzer = 'word',\n    tokenizer = tokenize,\n    lowercase = True,\n    ngram_range=(1, 1),\n    stop_words = en_stopwords)","c8377f01":"kfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)","76198207":"np.random.seed(1)\n\npipeline_svm = make_pipeline(vectorizer, \n                            SVC(probability=True, kernel=\"linear\", class_weight=\"balanced\"))\n\ngrid_svm = GridSearchCV(pipeline_svm,\n                    param_grid = {'svc__C': [0.01, 0.1, 1]}, \n                    cv = kfolds,\n                    scoring=\"roc_auc\",\n                    verbose=1,   \n                    n_jobs=-1) \n\ngrid_svm.fit(X_train, y_train)\ngrid_svm.score(X_test, y_test)","620ef220":"grid_svm.best_params_","6520e112":"grid_svm.best_score_","72e6c19f":"def report_results(model, X, y):\n    pred_proba = model.predict_proba(X)[:, 1]\n    pred = model.predict(X)        \n\n    auc = roc_auc_score(y, pred_proba)\n    acc = accuracy_score(y, pred)\n    f1 = f1_score(y, pred)\n    prec = precision_score(y, pred)\n    rec = recall_score(y, pred)\n    result = {'auc': auc, 'f1': f1, 'acc': acc, 'precision': prec, 'recall': rec}\n    return result","4b73c2d6":"report_results(grid_svm.best_estimator_, X_test, y_test)","f788dc9d":"def get_roc_curve(model, X, y):\n    pred_proba = model.predict_proba(X)[:, 1]\n    fpr, tpr, _ = roc_curve(y, pred_proba)\n    return fpr, tpr","e02288f5":"roc_svm = get_roc_curve(grid_svm.best_estimator_, X_test, y_test)","ae619488":"fpr, tpr = roc_svm\nplt.figure(figsize=(14,8))\nplt.plot(fpr, tpr, color=\"red\")\nplt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Roc curve')\nplt.show()","cfac1c4e":"from sklearn.model_selection import learning_curve\n\ntrain_sizes, train_scores, test_scores = \\\n    learning_curve(grid_svm.best_estimator_, X_train, y_train, cv=5, n_jobs=-1, \n                   scoring=\"roc_auc\", train_sizes=np.linspace(.1, 1.0, 10), random_state=1)","e8b23aa6":"def plot_learning_curve(X, y, train_sizes, train_scores, test_scores, title='', ylim=None, figsize=(14,8)):\n\n    plt.figure(figsize=figsize)\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n\n    plt.legend(loc=\"lower right\")\n    return plt","52712631":"plot_learning_curve(X_train, y_train, train_sizes, \n                    train_scores, test_scores, ylim=(0.7, 1.01), figsize=(14,6))\nplt.show()","a8a43fbc":"grid_svm.predict([\"flying with @united is always a great experience\"])","1baa0e61":"grid_svm.predict([\"flying with @united is always a great experience. If you don't lose your luggage\"])","921d01f9":"grid_svm.predict([\"I love @united. Sorry, just kidding!\"])","57b4658d":"grid_svm.predict([\"@united very bad experience!\"])","cf880fcf":"grid_svm.predict([\"@united very bad experience!\"])","d802a0a3":"## Examples\n\nWe are going to apply the obtained machine learning model to some example text. If the output is **1** it means that the text has a negative sentiment associated:","0d0cc370":"Let's see how the model (with the best hyperparameters) works on the test data:","caac25f7":"We are going to distinguish two cases: tweets with negative sentiment and tweets with non-negative sentiment","a644257c":"## Summary\n\nWe face the problem of predicting tweets sentiment. \nWe have coded the text as Bag of Words and applied an SVM model. We have built a pipeline to check different hyperparameters using cross-validation. At the end, we have obtained a good model which achieve an AUC of **0.92** ","cc1792ef":"It looks like there isn't a big bias or variance problem, but it is clear that our model would work better with more data:. if we can get more labeled data the model performance will increase.","020b01d0":"## Data loading and cleaning","86f0bcf9":"## Machine Learning Model","cc14f47c":"Let's see if our model has some bias or variance problem ploting its learning curve:","99acf09e":"We are going to use cross validation and grid search to find good hyperparameters for our SVM model. We need to build a pipeline to don't get features from the validation folds when building each training model.","d897c5a6":"We take only the tweets we are very confident with. We use the BeautifulSoup library to process html encoding present in some tweets because scrapping.","75071663":"We split the data into training and testing set:"}}