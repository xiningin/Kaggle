{"cell_type":{"5696e9e9":"code","2c8af374":"code","fb13a3cb":"code","5552ba21":"code","3de398e2":"code","2672c9b4":"code","2832ad46":"code","74a73c54":"code","92f5b834":"code","280931a5":"code","d5302fd2":"code","1d28b08b":"code","5e820389":"code","4e1a1a71":"code","b036df85":"code","bc99f842":"code","7f97c1f8":"code","b1d4e0f0":"code","46a4567f":"code","f4206a79":"code","9aa5e6bc":"code","4e9d343c":"code","e197dc55":"code","6ec5d6c3":"code","86a938af":"code","827d964f":"code","966f07e9":"code","f2baeeb0":"code","3a4f7262":"code","0d2d9cd6":"code","a253edf6":"code","b2111b62":"code","74846fb1":"code","95b29fd4":"code","c645c975":"code","08c8501b":"code","96911b57":"code","0d026f7a":"code","ea034d12":"code","81e2cf8d":"code","dca58e41":"code","c284f4e5":"code","ba67c7a9":"code","11ddc4d3":"code","7a49f5a2":"code","64598e12":"code","3e699d78":"code","88a52fa5":"code","55d6abac":"code","e4ff3dff":"code","ab4cf2ae":"code","1e24d889":"code","c950169e":"code","961d5212":"code","beb2ce2b":"code","f25486e8":"code","b532abcf":"code","7acd0afc":"code","e5f2c9e0":"code","c1339bea":"code","6a8f6eb3":"code","89907404":"code","3810fff7":"code","751b3ee5":"code","f5e2a7cf":"code","5abf07d2":"code","533c5c82":"code","5e253c36":"code","fd0de72f":"code","df225be3":"code","0a03e98d":"code","0ab712c1":"code","70bd8898":"code","2fd7e1eb":"code","e49a26be":"code","930ed3de":"code","fdb5bbc8":"code","004c91e5":"code","344f01d8":"code","eaa0edb5":"code","2c4880ab":"code","c988c42f":"code","ee4949b4":"code","ae9e20a9":"code","6726ec3a":"code","b3a31af6":"code","6e911052":"code","842b9750":"code","3bc468cc":"code","b0ac29a8":"code","b03b2e25":"code","d00c9b5d":"code","b6fb8e09":"code","7e189b85":"code","44bac81b":"code","90588865":"code","dff9e4ef":"code","216b6b18":"code","825e0fef":"code","c8d70e87":"code","4043c82a":"markdown","38709a58":"markdown","e4ca71a2":"markdown"},"source":{"5696e9e9":"# importing the libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OrdinalEncoder,OneHotEncoder,LabelEncoder,MinMaxScaler\nfrom imblearn.over_sampling import BorderlineSMOTE\nfrom sklearn.feature_selection import SelectKBest,chi2\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import RandomizedSearchCV,GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n","2c8af374":"#loading the datset\ntrain=pd.read_csv('..\/input\/predict-the-genetic-disorders-datasetof-genomes\/train_genetic_disorders.csv')\ntest=pd.read_csv('..\/input\/predict-the-genetic-disorders-datasetof-genomes\/test_genetic_disorders.csv')\ndata_train=train.copy()\ndata_test=test.copy()","fb13a3cb":"#check all null rows\ndata_train[data_train.isnull().all(1)].shape\nprint(\"Null rows_train:\",data_train[data_train.isnull().all(1)].shape[0])","5552ba21":"#check all null rows\ndata_test[data_test.isnull().all(1)].shape\nprint(\"Null rows_test:\",data_test[data_test.isnull().all(1)].shape[0])","3de398e2":"#subset where no all rows being null\ndata_fea_train=data_train[data_train.isnull().all(1)!=True]","2672c9b4":"#shape of train after removing null rows\ndata_fea_train.shape","2832ad46":"#subset where no all rows being null\ndata_fea_test=data_test[data_test.isnull().all(1)!=True]","74a73c54":"# Dropping the features\ndata_fea_train=data_fea_train.drop(columns=['Patient Id','Patient First Name','Family Name','Father\\'s name','Institute Name','Location of Institute','Test 1','Test 2','Test 3','Test 4',\n'Test 5','Parental consent'])\ndata_fea_test=data_fea_test.drop(columns=['Patient Id','Patient First Name','Family Name','Father\\'s name','Institute Name','Location of Institute','Test 1','Test 2','Test 3','Test 4',\n'Test 5','Parental consent'])","92f5b834":"print(data_fea_train.shape,data_fea_test.shape)","280931a5":"# renaming the columns\ndata_fea_train=data_fea_train.rename(columns={\"Genes in mother's side\":'defective_mother',\n                    'Inherited from father':'defective_father',\n                    'Maternal gene':'maternal_gene','Paternal gene':'paternal_gene',\n                    'Respiratory Rate (breaths\/min)':'respiratory_rate','Heart Rate (rates\/min':'heart_rate',\n                    'Parental consent':'parental_consent','Follow-up':'follow_up','Birth asphyxia':'birth_asphyxia',\n                    'Autopsy shows birth defect (if applicable)':'birth_defect_autopsy','Place of birth':'birth_place',\n                    'Folic acid details (peri-conceptional)':'folic_acid_periconceptional',\n                    'H\/O serious maternal illness':'maternal_illness','H\/O radiation exposure (x-ray)':'radiation_exposure',\n                    'H\/O substance abuse':'substance_abuse','Assisted conception IVF\/ART':'assisted_conception',\n                    'History of anomalies in previous pregnancies':'previous_pregnancy_anomalies',\n                    'Birth defects':'birth_defects','Blood test result':'blood_test_result','Genetic Disorder':'genetic_disorder',\n                    'Disorder Subclass':'disorder_subclass','Patient Age':'patient_age','Blood cell count (mcL)':'blood_cell_count',\n                    \"Mother's age\":'mother_age',\"Father's age\":'father_age','No. of previous abortion':'num_previous_abortion',\n                    'White Blood cell count (thousand per microliter)':'WBC_count'})","d5302fd2":"data_fea_test=data_fea_test.rename(columns={\"Genes in mother's side\":'defective_mother',\n                    'Inherited from father':'defective_father',\n                    'Maternal gene':'maternal_gene','Paternal gene':'paternal_gene',\n                    'Respiratory Rate (breaths\/min)':'respiratory_rate','Heart Rate (rates\/min':'heart_rate',\n                    'Parental consent':'parental_consent','Follow-up':'follow_up','Birth asphyxia':'birth_asphyxia',\n                    'Autopsy shows birth defect (if applicable)':'birth_defect_autopsy','Place of birth':'birth_place',\n                    'Folic acid details (peri-conceptional)':'folic_acid_periconceptional',\n                    'H\/O serious maternal illness':'maternal_illness','H\/O radiation exposure (x-ray)':'radiation_exposure',\n                    'H\/O substance abuse':'substance_abuse','Assisted conception IVF\/ART':'assisted_conception',\n                    'History of anomalies in previous pregnancies':'previous_pregnancy_anomalies',\n                    'Birth defects':'birth_defects','Blood test result':'blood_test_result','Genetic Disorder':'genetic_disorder',\n                    'Disorder Subclass':'disorder_subclass','Patient Age':'patient_age','Blood cell count (mcL)':'blood_cell_count',\n                    \"Mother's age\":'mother_age',\"Father's age\":'father_age','No. of previous abortion':'num_previous_abortion',\n                    'White Blood cell count (thousand per microliter)':'WBC_count'})","1d28b08b":"# missing target variables\ndata_fea_train.iloc[:,-2].isnull().sum(),data_fea_train.iloc[:,-1].isnull().sum()","5e820389":"# removing rows of missing target variables\ndata_fea_train=data_fea_train[(data_fea_train['genetic_disorder'].isnull()!=True)&(data_fea_train['disorder_subclass'].isnull()!=True)]","4e1a1a71":"data_fea_train.shape","b036df85":"#Subsetting\nX=data_fea_train.iloc[:,:-2]\ny1=data_fea_train.iloc[:,-2]\ny2=data_fea_train.iloc[:,-1]","bc99f842":"# shape of features,target variables\nX.shape,y1.shape,y2.shape","7f97c1f8":"# test data\nX_test=data_fea_test","b1d4e0f0":"#converting dissimilar datatype to one\nfor i in X_test.columns:\n    if X_test[i].dtype!=X[i].dtype:\n        X_test[i]=X_test[i].astype(X[i].dtype.name)","46a4567f":"# Data Cleaning\nX_test=X_test.replace('-99',np.nan)\n# Cleaning_data\n# replace '-' with other values\nX['radiation_exposure']=X['radiation_exposure'].replace('-','others')\nX['substance_abuse']=X['substance_abuse'].replace('-','others')\n# Cleaning_data\nX_test['radiation_exposure']=X_test['radiation_exposure'].replace('-','others')\nX_test['substance_abuse']=X_test['substance_abuse'].replace('-','others')","f4206a79":"# Data Cleaning\nX_test['WBC_count']=X_test['WBC_count'].mask(X_test['WBC_count']<0,np.nan)\nX_test['num_previous_abortion']=X_test['num_previous_abortion'].mask(X_test['num_previous_abortion']<0,np.nan)","9aa5e6bc":"#Splitting the data\nX_train1,X_val1,y_train1,y_val1= train_test_split(X,y1,stratify=y1,test_size=0.20)\nX_train2,X_val2,y_train2,y_val2= train_test_split(X,y2,stratify=y2,test_size=0.20)","4e9d343c":"# shape of train,validation set\nprint(X_train1.shape,X_val1.shape,y_train1.shape,y_val1.shape)\nprint(X_train2.shape,X_val2.shape,y_train2.shape,y_val2.shape)","e197dc55":"# Missing value imputation\nfrom sklearn.impute import SimpleImputer\nimp_mode=SimpleImputer(strategy='most_frequent')\nimp_mode_num=SimpleImputer(strategy='most_frequent')\nimp_median=SimpleImputer(strategy='median')","6ec5d6c3":"pd.options.mode.chained_assignment = None  ","86a938af":"# missing value imputation\nfor i in X.columns:\n    if (X[i].dtype.name!='object')&(X[i].nunique()<=3):\n        imp_mode_num.fit(np.array(X_train1[i]).reshape(-1,1))\n        X_train1[i]=imp_mode_num.transform(np.array(X_train1[i]).reshape(-1,1))\n        X_val1[i]=imp_mode_num.transform(np.array(X_val1[i]).reshape(-1,1))\n        X_test[i]=imp_mode_num.transform(np.array(X_test[i]).reshape(-1,1))\n    elif (X[i].dtype.name!='object')&(X[i].nunique()>3):\n        imp_median.fit(np.array(X_train1[i]).reshape(-1,1))\n        X_train1[i]=imp_median.transform(np.array(X_train1[i]).reshape(-1,1))\n        X_val1[i]=imp_median.transform(np.array(X_val1[i]).reshape(-1,1))\n        X_test[i]=imp_median.transform(np.array(X_test[i]).reshape(-1,1))\n    else:\n        imp_mode.fit(np.array(X_train1[i]).reshape(-1,1))\n        X_train1[i]=imp_mode.transform(np.array(X_train1[i]).reshape(-1,1))\n        X_val1[i]=imp_mode.transform(np.array(X_val1[i]).reshape(-1,1))\n        X_test[i]=imp_mode.transform(np.array(X_test[i]).reshape(-1,1))","827d964f":"# checking null values\nX_train1.isnull().sum()","966f07e9":"X_val1.isnull().sum()","f2baeeb0":"X_test.isnull().sum()","3a4f7262":"from sklearn.preprocessing import OrdinalEncoder,OneHotEncoder,LabelEncoder,MinMaxScaler\nord_enc=OrdinalEncoder()\nohe_enc=OneHotEncoder()\nmin_max=MinMaxScaler()","0d2d9cd6":"# reset index\nX_train1.reset_index(inplace=True)\nX_val1.reset_index(inplace=True)","a253edf6":"# encoding the features\nfor i in X.columns:\n    if (X[i].dtype.name=='object'):\n        if i in X and X[i].nunique()<=2:\n            ord_enc.fit(np.array(X_train1[i]).reshape(-1,1))\n            X_train1.loc[:,i]=ord_enc.transform(np.array(X_train1[i]).reshape(-1,1))\n            X_val1.loc[:,i]=ord_enc.transform(np.array(X_val1[i]).reshape(-1,1))\n            X_test.loc[:,i]=ord_enc.transform(np.array(X_test[i]).reshape(-1,1))\n        else:\n            ohe_enc.fit(np.array(X_train1[i]).reshape(-1,1))\n            X_encode_tr1=pd.DataFrame(ohe_enc.transform(np.array(X_train1[i]).reshape(-1,1)).toarray(),columns=ohe_enc.get_feature_names([i]))\n            X_encode_va1=pd.DataFrame(ohe_enc.transform(np.array(X_val1[i]).reshape(-1,1)).toarray(),columns=ohe_enc.get_feature_names([i]))\n            X_encode1=pd.DataFrame(ohe_enc.transform(np.array(X_test[i]).reshape(-1,1)).toarray(),columns=ohe_enc.get_feature_names([i]))\n            X_train1=pd.concat([X_train1,X_encode_tr1],axis=1)\n            X_val1=pd.concat([X_val1,X_encode_va1],axis=1)\n            X_test=pd.concat([X_test,X_encode1],axis=1)\n            X_train1.drop(columns=[i],inplace=True)\n            X_val1.drop(columns=[i],inplace=True)\n            X_test.drop(columns=[i],inplace=True)","b2111b62":"# shape of the train,test,val\nX_train1.shape,X_val1.shape,X_test.shape","74846fb1":"X_train1.drop(columns='index',inplace=True)\nX_val1.drop(columns='index',inplace=True)","95b29fd4":"from sklearn.preprocessing import MinMaxScaler\nmin_max=MinMaxScaler()\nX2=min_max.fit_transform(X_train1)","c645c975":"# normalised minmax\nX2=pd.DataFrame(X2,columns=X_train1.columns)","08c8501b":"#normalised val1\nX2_val=min_max.transform(X_val1)\nX2_val=pd.DataFrame(X2_val,columns=X_val1.columns)","96911b57":"#normalised test\nX2_test=min_max.transform(X_test)\nX2_test=pd.DataFrame(X2_test,columns=X_test.columns)","0d026f7a":"# enoding the target variables1\nlab_enc1=LabelEncoder()\ny1_en=lab_enc1.fit_transform(y_train1)\ny1_en_val=lab_enc1.transform(y_val1)","ea034d12":"# printing encoded targets\nnp.unique(y1_en),np.unique(y1_en_val)","81e2cf8d":"# enoding the target variables2\nlab_enc2=LabelEncoder()\ny2_en=lab_enc2.fit_transform(y_train2)\ny2_en_val=lab_enc2.transform(y_val2)","dca58e41":"# printing encoded targets\nnp.unique(y2_en),np.unique(y2_en_val)","c284f4e5":"from imblearn.over_sampling import BorderlineSMOTE\nsm = BorderlineSMOTE(random_state=42)\nX_sm, y_sm = sm.fit_resample(X2, pd.DataFrame(y1_en))\nprint(f'''shape of X before SMOTE: {X2.shape} \nshape of X after SMOTE: {X_sm.shape}''')\nprint('balanced class (%):')\ny_sm.value_counts(normalize=True) * 100","ba67c7a9":"X_sm.head(2)","11ddc4d3":"y1_enco=np.array(y_sm).ravel()","7a49f5a2":"from sklearn.feature_selection import SelectKBest,chi2","64598e12":"sel1=SelectKBest(chi2, k=25).fit(X_sm,y1_enco)","3e699d78":"cols=sel1.get_support(indices=True)\nprint(X_sm.iloc[:,cols].shape)\nresult_kbest_20=X_sm.iloc[:,cols]","88a52fa5":"sele_fea= X2.columns[(sel1.get_support())]\nprint(sele_fea)","55d6abac":"print(X2_val.iloc[:,cols].shape)\nresult_kbest_val=X2_val.iloc[:,cols]","e4ff3dff":"print(X2_test.iloc[:,cols].shape)\nresult_kbest_test20=X2_test.iloc[:,cols]","ab4cf2ae":"from sklearn.metrics import f1_score","1e24d889":"nn=[x for x in range(1, 15, 2)]\ncv_f1_macro=[]\nfor i in nn:\n    knn=KNeighborsClassifier(n_neighbors=i,n_jobs=-1)\n    knn.fit(result_kbest_20,y1_enco)\n    predict_y=knn.predict(result_kbest_val)\n    cv_f1_macro.append(f1_score(y1_en_val, predict_y,average='macro'))\nfor i in range(len(cv_f1_macro)):\n    print ('f1_macro for k = ',nn[i],'is',cv_f1_macro[i])\nbest_nn = np.argmax(cv_f1_macro)\nknn=KNeighborsClassifier(n_neighbors=nn[best_nn])\nknn.fit(result_kbest_20,y1_enco)\npredict_y=knn.predict(result_kbest_20)\nprint ('For values of best nn = ', nn[best_nn], \"The train f1_macro is:\",f1_score(y1_enco, predict_y,average='macro'))\npredict_y=knn.predict(result_kbest_val)\nprint('For values of best nn = ', nn[best_nn], \"The cross validation f1_macro is:\",f1_score(y1_en_val, predict_y,average='macro'))","c950169e":"C1= [10 ** x for x in range(-5, 4)]\ncv_f1_macro=[]\nfor i in C1:\n    logisticR=LogisticRegression(penalty='l2',C=i,class_weight='balanced')\n    logisticR.fit(result_kbest_20,y1_enco)\n    predict_y=logisticR.predict(result_kbest_val)\n    cv_f1_macro.append(f1_score(y1_en_val, predict_y,average='macro'))\nfor i in range(len(cv_f1_macro)):\n    print ('f1_macro for C1 = ',C1[i],'is',cv_f1_macro[i])\nbest_C1 = np.argmax(cv_f1_macro)\nlogisticR=LogisticRegression(penalty='l2',C=C1[best_C1],class_weight='balanced')\nlogisticR.fit(result_kbest_20,y1_enco)\npredict_y=logisticR.predict(result_kbest_20)\nprint ('For values of best C = ',C1[best_C1], \"The train f1_macro is:\",f1_score(y1_enco, predict_y,average='macro'))\npredict_y=logisticR.predict(result_kbest_val)\nprint('For values of best C = ',C1[best_C1], \"The cross validation f1_macro is:\",f1_score(y1_en_val, predict_y,average='macro'))","961d5212":"DT = DecisionTreeClassifier(random_state=42)\nparams = {\n    'max_depth': [2, 3, 5, 10, 20],\n    'min_samples_leaf': [5, 10, 20, 50, 100],\n    'criterion': [\"gini\", \"entropy\"]\n}\nrandom_dt=RandomizedSearchCV(DT,param_distributions=params,verbose=10,n_jobs=-1,random_state=42)\nrandom_dt.fit(result_kbest_20,y1_enco)","beb2ce2b":"print(random_dt.best_estimator_)","f25486e8":"print(random_dt.best_score_)","b532abcf":"DT = DecisionTreeClassifier(max_depth=10,min_samples_leaf=20,random_state=42)\nDT.fit(result_kbest_20,y1_enco)\npredict_y =DT.predict(result_kbest_20)\nprint ('The train f1_macro is:',f1_score(y1_enco, predict_y,average='macro'))\npredict_y =DT.predict(result_kbest_val)\nprint('The cross validation f1_macro is:',f1_score(y1_en_val, predict_y,average='macro'))","7acd0afc":"from sklearn.ensemble import RandomForestClassifier","e5f2c9e0":"rfc=RandomForestClassifier(random_state=42)\nparams1={'bootstrap': [True, False],\n 'max_depth': [10, 20, 30, 40, 50, 60],\n 'max_features': ['auto', 'sqrt'],\n 'min_samples_leaf': [1, 2, 4],\n 'min_samples_split': [2, 5, 10],\n 'n_estimators': [600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\nrandom_rfc=RandomizedSearchCV(rfc,param_distributions=params1,n_jobs=-1,random_state=42)\nrandom_rfc.fit(result_kbest_20,y1_enco)","c1339bea":"print(random_rfc.best_estimator_)","6a8f6eb3":"print(random_rfc.best_score_)","89907404":"rfc = RandomForestClassifier(n_estimators=1800,max_depth=20,max_features='sqrt',bootstrap=False, min_samples_leaf=2, min_samples_split=5,random_state=42)\nrfc.fit(result_kbest_20,y1_enco)\npredict_y =rfc.predict(result_kbest_20)\nprint ('The train f1_macro is:',f1_score(y1_enco, predict_y,average='macro'))\npredict_y =rfc.predict(result_kbest_val)\nprint('The cross validation f1_macro is:',f1_score(y1_en_val, predict_y,average='macro'))","3810fff7":"from lightgbm import LGBMClassifier","751b3ee5":"lgb=LGBMClassifier(random_state=42)\nparams_lgb= {'num_leaves':[20,40,60,80],'min_child_samples':[5,10,15,25],'max_depth':[1,5,10,20],\n             'learning_rate':[0.05,0.1,0.2],'reg_alpha':[0.01,0.03,1, 2, 5, 7, 10]}\nrandom_lgb=RandomizedSearchCV(lgb,param_distributions=params_lgb,verbose=10,n_jobs=-1,random_state=42)\nrandom_lgb.fit(result_kbest_20,y1_enco)","f5e2a7cf":"print (random_lgb.best_params_)","5abf07d2":"print(random_lgb.best_score_)","533c5c82":"lgb=LGBMClassifier(num_leaves=80,min_child_samples=25,max_depth=10,learning_rate=0.05,reg_alpha=0.03,random_state=42)\nlgb.fit(result_kbest_20,y1_enco)\npredict_y =lgb.predict(result_kbest_20)\nprint ('The train f1_macro is:',f1_score(y1_enco, predict_y,average='macro'))\npredict_y = lgb.predict(result_kbest_val)\nprint('The cross validation f1_macro is:',f1_score(y1_en_val, predict_y,average='macro'))","5e253c36":"from imblearn.over_sampling import BorderlineSMOTE","fd0de72f":"smd=BorderlineSMOTE(random_state=42)\nX_smd, y_smd = smd.fit_resample(X2, pd.DataFrame(y2_en))\nprint(f'''shape of X before SMOTE: {X2.shape} \nshape of X after SMOTE: {X_smd.shape}''')\nprint('balanced class (%):')\ny_smd.value_counts(normalize=True) * 100","df225be3":"X_smd.head(2)","0a03e98d":"y2_enco=np.array(y_smd).ravel()","0ab712c1":"from sklearn.feature_selection import SelectKBest,chi2","70bd8898":"# feature selection \nsel2=SelectKBest(chi2, k=25).fit(X_smd,y2_enco)","2fd7e1eb":"cols=sel2.get_support(indices=True)\nprint(X_smd.iloc[:,cols].shape)\nresult_kbest_20d=X_smd.iloc[:,cols]","e49a26be":"sele_fead= X2.columns[(sel2.get_support())]\nprint(sele_fead)","930ed3de":"print(X2_val.iloc[:,cols].shape)\nresult_kbest_vald=X2_val.iloc[:,cols]","fdb5bbc8":"print(X2_test.iloc[:,cols].shape)\nresult_kbest_test20d=X2_test.iloc[:,cols]","004c91e5":"nn=[x for x in range(1, 15, 2)]\ncv_f1_macro=[]\nfor i in nn:\n    knn=KNeighborsClassifier(n_neighbors=i,n_jobs=-1)\n    knn.fit(result_kbest_20d,y2_enco)\n    predict_y=knn.predict(result_kbest_vald)\n    cv_f1_macro.append(f1_score(y2_en_val, predict_y,average='macro'))\nfor i in range(len(cv_f1_macro)):\n    print ('f1_macro for k = ',nn[i],'is',cv_f1_macro[i])\nbest_nn = np.argmax(cv_f1_macro)\nknn=KNeighborsClassifier(n_neighbors=nn[best_nn])\nknn.fit(result_kbest_20d,y2_enco)\npredict_y=knn.predict(result_kbest_20d)\nprint ('For values of best nn = ', nn[best_nn], \"The train f1_macro is:\",f1_score(y2_enco, predict_y,average='macro'))\npredict_y=knn.predict(result_kbest_vald)\nprint('For values of best nn = ', nn[best_nn], \"The cross validation f1_macro is:\",f1_score(y2_en_val, predict_y,average='macro'))","344f01d8":"C1= [10 ** x for x in range(-5, 4)]\ncv_f1_macro=[]\nfor i in C1:\n    logisticR=LogisticRegression(penalty='l2',C=i,class_weight='balanced')\n    logisticR.fit(result_kbest_20d,y2_enco)\n    predict_y=logisticR.predict(result_kbest_vald)\n    cv_f1_macro.append(f1_score(y2_en_val, predict_y,average='macro'))\nfor i in range(len(cv_f1_macro)):\n    print ('f1_macro for C1 = ',C1[i],'is',cv_f1_macro[i])\nbest_C1 = np.argmax(cv_f1_macro)\nlogisticR=LogisticRegression(penalty='l2',C=C1[best_C1],class_weight='balanced')\nlogisticR.fit(result_kbest_20d,y2_enco)\npredict_y=logisticR.predict(result_kbest_20d)\nprint ('For values of best C = ',C1[best_C1], \"The train f1_macro is:\",f1_score(y2_enco, predict_y,average='macro'))\npredict_y=logisticR.predict(result_kbest_vald)\nprint('For values of best C = ',C1[best_C1], \"The cross validation f1_macro is:\",f1_score(y2_en_val, predict_y,average='macro'))","eaa0edb5":"DT = DecisionTreeClassifier(random_state=42)\nparams = {\n    'max_depth': [2, 3, 5, 10, 20],\n    'min_samples_leaf': [10, 20, 50, 100],\n    'criterion': [\"gini\", \"entropy\"]\n}\nrandom_dt=RandomizedSearchCV(DT,param_distributions=params,n_jobs=-1,random_state=42)\nrandom_dt.fit(result_kbest_20d,y2_enco)","2c4880ab":"print(random_dt.best_estimator_)","c988c42f":"print(random_dt.best_score_)","ee4949b4":"DT = DecisionTreeClassifier(max_depth=20,min_samples_leaf=10,random_state=42)\nDT.fit(result_kbest_20d,y2_enco)\npredict_y =DT.predict(result_kbest_20d)\nprint ('The train f1_macro is:',f1_score(y2_enco, predict_y,average='macro'))\npredict_y = DT.predict(result_kbest_vald)\nprint('The cross validation f1_macro is:',f1_score(y2_en_val, predict_y,average='macro'))","ae9e20a9":"rfc1=r_cfl=RandomForestClassifier(random_state=42)\nparams1={'bootstrap': [True, False],\n 'max_depth': [10, 20, 30, 40, 50, 60],\n 'max_features': ['auto', 'sqrt'],\n 'min_samples_leaf': [1, 2, 4],\n 'min_samples_split': [2, 5, 10,15],\n 'n_estimators': [200, 400, 500, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\nrandom_rfc1=RandomizedSearchCV(rfc1,param_distributions=params1,n_jobs=-1,random_state=42)\nrandom_rfc1.fit(result_kbest_20d,y2_enco)","6726ec3a":"print(random_rfc1.best_estimator_)","b3a31af6":"print(random_rfc1.best_score_)","6e911052":"rfc1= RandomForestClassifier(n_estimators=500,max_depth=30,min_samples_leaf=2,min_samples_split=5,bootstrap=False,random_state=42)\nrfc1.fit(result_kbest_20d,y2_enco)\npredict_y =rfc1.predict(result_kbest_20d)\nprint ('The train f1_macro is:',f1_score(y2_enco, predict_y,average='macro'))\npredict_y =rfc1.predict(result_kbest_vald)\nprint('The cross validation f1_macro is:',f1_score(y2_en_val, predict_y,average='macro'))","842b9750":"lgbd=LGBMClassifier(random_state=42)\nparams_lgbd= {'num_leaves':[20,40,60,80],'min_child_samples':[5,10,15,25],'max_depth':[1,5,10,20],\n             'learning_rate':[0.05,0.1,0.2],'reg_alpha':[0.01,0.03,1, 2, 5, 7, 10]}\nrandom_lgbd=RandomizedSearchCV(lgbd,param_distributions=params_lgbd,n_jobs=-1,random_state=42)\nrandom_lgbd.fit(result_kbest_20d,y2_enco)","3bc468cc":"print (random_lgbd.best_params_)","b0ac29a8":"print(random_lgbd.best_score_)","b03b2e25":"lgbd=LGBMClassifier(num_leaves=40,min_child_samples=5,max_depth=10,learning_rate=0.2,reg_alpha=2,random_state=42)\nlgbd.fit(result_kbest_20d,y2_enco)\n    \npredict_y = lgbd.predict(result_kbest_20d)\nprint ('The train f1_macro is:',f1_score(y2_enco, predict_y,average='macro'))\npredict_y = lgbd.predict(result_kbest_vald)\nprint('The cross validation f1_macro is:',f1_score(y2_en_val, predict_y,average='macro'))","d00c9b5d":"from prettytable import PrettyTable","b6fb8e09":"Pred_gene = PrettyTable([\"Model\", \"Average_F1_Score\"])\nPred_gene.add_row(['KNN','28.50'])\nPred_gene.add_row(['Logistic_Regression','25.80'])\nPred_gene.add_row(['Decision_Tree','32.69'])\nPred_gene.add_row(['RFC','31.49'])\nPred_gene.add_row(['LGBM','31.49'])","7e189b85":"print(Pred_gene)","44bac81b":"DT = DecisionTreeClassifier(max_depth=10,min_samples_leaf=20,random_state=42)\nDT.fit(result_kbest_20,y1_enco)\npredict_y =DT.predict(result_kbest_20)\nprint ('The train f1_macro is:',f1_score(y1_enco, predict_y,average='macro'))\npredict_y =DT.predict(result_kbest_test20)","90588865":"Genetic_disorder=lab_enc1.inverse_transform(predict_y)","dff9e4ef":"DT = DecisionTreeClassifier(max_depth=20,min_samples_leaf=10,random_state=42)\nDT.fit(result_kbest_20d,y2_enco)\npredict_y =DT.predict(result_kbest_20d)\nprint ('The train f1_macro is:',f1_score(y2_enco, predict_y,average='macro'))\npredict_yd =DT.predict(result_kbest_test20)","216b6b18":"Disorder_Subclass=lab_enc2.inverse_transform(predict_yd)","825e0fef":"data_fea_test1=data_test[data_test.isnull().all(1)!=True]","c8d70e87":"ids=data_fea_test1['Patient Id']\noutput=pd.DataFrame({'Patient Id': ids,'Genetic_Disorder':Genetic_disorder,'Disorder_Subclass':Disorder_Subclass})\noutput.to_csv('submission.csv',index=False)","4043c82a":"#### Final Model","38709a58":"#### Disorder_subclass","e4ca71a2":"### genetic_disorder"}}