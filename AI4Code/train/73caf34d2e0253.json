{"cell_type":{"53a119f2":"code","d735a0fc":"code","4f90b1d9":"code","dff6cb85":"code","19acb3fa":"code","d4c26d3a":"code","3516af25":"code","07330fc0":"code","72f2d49e":"code","a0b06c6e":"code","225b28ee":"code","5a17c89a":"code","a68c00b7":"code","c6d99194":"code","ba3da72c":"markdown","e590cd5e":"markdown","71ffa80a":"markdown","aa283771":"markdown","a4cdc82d":"markdown","3c84899f":"markdown","8b772f25":"markdown","bf3c4464":"markdown","1beae1d9":"markdown","423d45b9":"markdown","6b10a0de":"markdown","8ddc0e08":"markdown"},"source":{"53a119f2":"!pip install transformers","d735a0fc":"from transformers import pipeline","4f90b1d9":"nlp = pipeline('sentiment-analysis')\nnlp('We are very happy to include pipeline into the transformers repository.')","dff6cb85":"nlp = pipeline('question-answering')\nnlp({\n    'question': 'What is my name ?',\n    'context': 'My name is Ahmed, I am working with HuggingFace'\n})","19acb3fa":"nlp = pipeline('fill-mask')\nnlp('I hope you <mask> this video')","d4c26d3a":"nlp = pipeline('ner')\nnlp('It is me, Ahmed, I am working with HuggingFace')","3516af25":"import torch\nfrom transformers import GPT2Tokenizer, GPT2LMHeadModel","07330fc0":"tokeniser = GPT2Tokenizer.from_pretrained('gpt2')\nmodel = GPT2LMHeadModel.from_pretrained('gpt2')","72f2d49e":"device = \"cuda\"\n\ntext = \"let us see how this turns\"\nindexed_tokens = tokeniser.encode(text)\ntokens_tensor = torch.tensor([indexed_tokens])\nmodel.eval()\ntokens_tensor = tokens_tensor.to(device)\nmodel.to(device)","a0b06c6e":"with torch.no_grad():\n  outputs = model(tokens_tensor)\n  predictions = outputs[0]\n\nprint(outputs[0].shape)\n\npredicted_index = torch.argmax(predictions[0, -1, :]).item()\npredicted_text = tokeniser.decode(indexed_tokens + [predicted_index])\n\nprint(predicted_text)","225b28ee":"chars = 0\ntext = \"i am very exited to present to you this\"\nwhile chars<50:\n  chars += 1\n  indexed_tokens = tokeniser.encode(text)\n  tokens_tensors = torch.tensor([indexed_tokens])\n  tokens_tensors = tokens_tensors.to(device)\n  with torch.no_grad():\n    outputs = model(tokens_tensors)\n    predictions = outputs[0]\n  predicted_index = torch.argmax(predictions[0,-1,:]).item()\n  text = tokeniser.decode(indexed_tokens + [predicted_index])\n\nprint(text)","5a17c89a":"text = 'Shakespeare occupies a position unique in world literature. Other poets, such as Homer and Dante, and novelists, such as Leo Tolstoy and Charles Dickens, have transcended national barriers, but no writer\u2019s living reputation can compare to that of Shakespeare, whose plays, written in the late 16th and early 17th centuries for a small repertory theatre, are now performed and read more often and in more countries than ever before. The prophecy of his great contemporary, the poet and dramatist Ben Jonson, that Shakespeare \u201cwas not of an age, but for all time,\u201d has been fulfilled. It may be audacious even to attempt a definition of his greatness, but it is not so difficult to describe the gifts that enabled him to create imaginative visions of pathos and mirth that, whether read or witnessed in the theatre, fill the mind and linger there. He is a writer of great intellectual rapidity, perceptiveness, and poetic power. Other writers have had these qualities, but with Shakespeare the keenness of mind was applied not to abstruse or remote subjects but to human beings and their complete range of emotions and conflicts. Other writers have applied their keenness of mind in this way, but Shakespeare is astonishingly clever with words and images, so that his mental energy, when applied to intelligible human situations, finds full and memorable expression, convincing and imaginatively stimulating. As if this were not enough, the art form into which his creative energies went was not remote and bookish but involved the vivid stage impersonation of human beings, commanding sympathy and inviting vicarious participation. Thus, Shakespeare\u2019s merits can survive translation into other languages and into cultures remote from that of Elizabethan England.'","a68c00b7":"from transformers import BartTokenizer, BartForConditionalGeneration, BartConfig\n\nmodel = BartForConditionalGeneration.from_pretrained('facebook\/bart-large-cnn')\ntokenizer = BartTokenizer.from_pretrained('facebook\/bart-large-cnn')","c6d99194":"inputs = tokenizer.batch_encode_plus([text], max_length=1024, return_tensors='pt')\n\nsummary_ids = model.generate(inputs['input_ids'], num_beams=4, max_length=100, early_stopping=False)\n\nfor ids in summary_ids:\n    short = tokenizer.decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n\n    print(len(text), len(short))\n    print(short)","ba3da72c":"# Using HuggingFace\n\nIn this tutorial, we will learn how to use the various functionalities offered by [HuggingFace](https:\/\/huggingface.co\/).\n\n## About Hugging Face\n\n- HuggingFace is 'On a mission to solve NLP, One commit at a time', as per their tagline. \n\n- The HuggingFace Transformer library is closing on 26K Stars on GitHub now and provides state-of-the-art Transformer Based Models, their pretrained weights and a lots more (as we will see today)\n\n- They recently released their Tokenisers library\n\n\nThey have originally used Rust, so that's an added advantage.","e590cd5e":"## Question Answering","71ffa80a":"# Pipeline\n\nhttps:\/\/github.com\/huggingface\/transformers#quick-tour-of-pipelines","aa283771":"## Sentiment Analysis","a4cdc82d":"## Looping for multi-word","3c84899f":"![Hugging Face](https:\/\/miro.medium.com\/max\/2000\/1*Z4mGaMsu34LfyE76QAi9qA.png)\n","8b772f25":"# Text Generation","bf3c4464":"## Single Word Prediction","1beae1d9":"## Predicting Masks","423d45b9":"## NER","6b10a0de":"HuggingFace Tranformers: https:\/\/github.com\/huggingface\/transformers\n\nBART: https:\/\/arxiv.org\/abs\/1910.13461\n\nCurious Case of Neural Text Degeneration: https:\/\/arxiv.org\/abs\/1904.09751","8ddc0e08":"# Summarising text using HuggingFace"}}