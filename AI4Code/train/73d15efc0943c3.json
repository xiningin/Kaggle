{"cell_type":{"db5d5955":"code","9a179bbb":"code","6c2e61ac":"code","e53f1885":"code","b47e45ca":"code","52b5de50":"code","284010e7":"code","085b2cee":"code","e93df256":"code","66c8ca1c":"code","425ea1f9":"code","ae1559d1":"code","6611681a":"code","5591e8f0":"code","3bb8cd08":"code","980a6409":"code","e996f98f":"code","0e6fe494":"code","39423d1e":"code","879e371a":"code","3c32e9f4":"code","76c31993":"code","c9e81ac0":"code","87c8645b":"code","3e40dc30":"code","7a4aa575":"code","15d66ac9":"code","d741ba3e":"markdown","2d3d98dc":"markdown","55d76757":"markdown","3fb427fe":"markdown"},"source":{"db5d5955":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9a179bbb":"# Import Libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\nfrom xgboost import XGBClassifier, plot_tree\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import roc_auc_score\nimport warnings\nwarnings.filterwarnings('ignore')","6c2e61ac":"# Load the data\ntrain = pd.read_csv(\"..\/input\/tabular-playground-series-nov-2021\/train.csv\")\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-nov-2021\/test.csv\")","e53f1885":"train.head()","b47e45ca":"# Extract the sample\ntrain_sample = train.sample(frac = 0.1, random_state=42)\nvalidation_sample = train.sample(frac = 0.05, random_state=50)\ntest_sample = train.sample(frac = 0.05, random_state=60)","52b5de50":"train_sample['id'].value_counts()","284010e7":"# drop the id column\ntrain_sample.drop('id', axis=1, inplace=True)","085b2cee":"train_sample.head()","e93df256":"plt.figure(figsize=(25, 25))\nfeatures = train_sample.drop('target', axis=1).columns\nfor i, feature in enumerate(features):\n    plt.subplot(10, 10, i+1)\n    sns.distplot(train_sample[feature][train_sample['target'] == 0], color='red', label = 'class 0')\n    sns.distplot(train_sample[feature][train_sample['target'] == 1], color='green', label = 'class 1')\n    plt.legend()\nplt.show()","66c8ca1c":"# Scale the data\nss = StandardScaler()\n\nX_train = train_sample.drop('target', axis=1)\ny_train = train_sample['target']\n\nX_val = validation_sample.drop(['id','target'], axis=1)\ny_val = validation_sample['target']\n\nX_test = test_sample.drop(['id','target'], axis=1)\ny_test = test_sample['target']\n\n\nss = StandardScaler()\nX_train_scaled = ss.fit_transform(X_train)\nX_val_scaled = ss.transform(X_val)\nX_test_scaled = ss.transform(X_test)","425ea1f9":"rfe = RFE(estimator=XGBClassifier(), verbose=5)\nrfe.fit(X_train_scaled, y_train)","ae1559d1":"rfe.get_support()","6611681a":"selected_features = X_train.columns[rfe.get_support()]\nprint(selected_features)","5591e8f0":"print(\"Total number of features selected are\", len(selected_features))","3bb8cd08":"# Prepare the final dataset\n\ntrain_final = X_train[selected_features]\nval_final = X_val[selected_features]\ntest_final = X_test[selected_features]\n\n# Scale the data\nss = StandardScaler()\n\ntrain_final = ss.fit_transform(train_final)\nval_final = ss.transform(val_final)\ntest_final = ss.transform(test_final)","980a6409":"# Build a linear model\nlr = LogisticRegression(solver='liblinear')\nlr.fit(train_final, y_train)","e996f98f":"# Validation results\nval_predictions = lr.predict_proba(val_final)\nval_auc_score = roc_auc_score(y_val, val_predictions[ : , 1])\nprint(\"Validation AUC score {}\".format(val_auc_score))","0e6fe494":"# Test Results\ntest_predictions = lr.predict_proba(test_final)\ntest_auc_score = roc_auc_score(y_test, test_predictions[ : , 1])\nprint(\"Testing AUC score {}\".format(test_auc_score))","39423d1e":"# Building a Bagging Model\next = ExtraTreesClassifier()\next.fit(train_final, y_train)","879e371a":"# Validation results\nval_predictions = ext.predict_proba(val_final)\nval_auc_score = roc_auc_score(y_val, val_predictions[ : , 1])\nprint(\"Validation AUC score {}\".format(val_auc_score))","3c32e9f4":"# Test Results\n\ntest_predictions = ext.predict_proba(test_final)\ntest_auc_score = roc_auc_score(y_test, test_predictions[ : , 1])\nprint(\"Testing AUC score {}\".format(test_auc_score))","76c31993":"# Building a Boosting Model\nxgb = XGBClassifier()\nxgb.fit(train_final, y_train)","c9e81ac0":"# Validation results\nval_predictions = xgb.predict_proba(val_final)\nval_auc_score = roc_auc_score(y_val, val_predictions[ : , 1])\nprint(\"Validation AUC score {}\".format(val_auc_score))","87c8645b":"# Test Results\ntest_predictions = xgb.predict_proba(test_final)\ntest_auc_score = roc_auc_score(y_test, test_predictions[ : , 1])\nprint(\"Testing AUC score {}\".format(test_auc_score))","3e40dc30":"# Train the model\nfinal_data = ss.transform(train[selected_features])\ntarget = train['target']\next.fit(final_data, target)","7a4aa575":"# Make Predictions\ntest_final = ss.transform(test[selected_features])\ntest_id = test['id']\n\next_preds = ext.predict_proba(test_final)\nsubmission_arr = np.concatenate((test_id.values.reshape(-1,1), ext_preds[ : ,1].reshape(-1,1)), axis=1)\nsubmission_df = pd.DataFrame(submission_arr, columns=['id', 'target'])\nsubmission_df['id'] = submission_df['id'].astype('int')\n# cnvt to csv\nsubmission_df.to_csv('.\/ext_submissions.csv', index=False)","15d66ac9":"submission_df.head()","d741ba3e":"**We are able to select top 50 features using RFE**","2d3d98dc":"# Train on the entire data and Making Submissions","55d76757":"**Bagging Model seems to perform best**","3fb427fe":"**id column is a unique identifier, it is better to drop it.**"}}