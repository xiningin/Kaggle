{"cell_type":{"918db5db":"code","eeffefa4":"code","e2a7d4bc":"code","ab7bce4f":"code","99d0e61c":"code","4ed161cf":"code","207142ed":"code","e22ba9d8":"code","1a61352e":"code","f25ad248":"code","8aa20331":"code","c4ad7475":"code","a756d06d":"code","7572c1a2":"code","307d0cdd":"code","76a73717":"code","bfb884d4":"code","c6e1ccc7":"code","b46b8bc0":"code","5cd93339":"markdown","a070cc26":"markdown","dd94bf2a":"markdown","c17446db":"markdown","5861d312":"markdown","dc9ddf29":"markdown","408253d1":"markdown","71722086":"markdown"},"source":{"918db5db":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom pathlib import Path\n\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix","eeffefa4":"base_path = Path('\/kaggle\/input\/wild-animals\/Animals\/')\npaths = list(base_path.glob(r'*\/*')) \n","e2a7d4bc":"# paths\npaths[0]","ab7bce4f":"FilePath = pd.Series(paths, name=\"FilePath\").astype(str)\nlabel = pd.Series([path.split(\"\/\")[5] for path in FilePath], name=\"Label\").astype(str)\n","99d0e61c":"FilePath","4ed161cf":"df = pd.concat([FilePath, label], axis=1)","207142ed":"fig, ax = plt.subplots(4,4, figsize=(20,15))\nfor idx, axis in enumerate(ax.flat):\n    _ = axis.imshow(plt.imread(df.FilePath[idx]))\n    _ = axis.set_title(df.Label[idx])","e22ba9d8":"train_df, test_df = train_test_split(df, test_size=0.2, random_state=0, shuffle=True)","1a61352e":"print(len(train_df))\nprint(len(test_df))","f25ad248":"train_generator = ImageDataGenerator(validation_split=0.2, rescale = 1.\/255 ) # Rescaling the data and splitting the training data in validation data as well\ntest_generator = ImageDataGenerator(rescale = 1.\/255) # Rescaling the data","8aa20331":"train_imgs = train_generator.flow_from_dataframe(\n    dataframe = train_df,\n    x_col = \"FilePath\",\n    y_col = \"Label\",\n    target_size = (224, 224),\n    color_mode = \"rgb\",\n    class_mode = \"categorical\",\n    batch_size = 32,\n    shuffle = True,\n    subset = \"training\"\n)\nval_imgs = train_generator.flow_from_dataframe(\n    dataframe = train_df,\n    x_col = \"FilePath\",\n    y_col = \"Label\",\n    target_size = (224, 224),\n    color_mode = \"rgb\",\n    class_mode = \"categorical\",\n    batch_size = 32,\n    shuffle = True,\n    subset = \"validation\"\n)\n\ntest_imgs = test_generator.flow_from_dataframe(\n    dataframe = test_df,\n    x_col = \"FilePath\",\n    y_col = \"Label\",\n    target_size = (224, 224),\n    color_mode = \"rgb\",\n    class_mode = \"categorical\",\n    batch_size = 32,\n    shuffle = False\n)","c4ad7475":"\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3,3), padding=\"Same\", activation=\"relu\", input_shape=(224, 224, 3)),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Conv2D(64, (3, 3), padding=\"Same\", activation='relu'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Conv2D(64, (3, 3), padding=\"Same\", activation='relu'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Conv2D(128, (3, 3), padding=\"Same\", activation='relu'),\n\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(5, activation='softmax'),\n])\nmodel.compile(\n    optimizer='rmsprop',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nmodel.summary()","a756d06d":"history = model.fit(train_imgs, batch_size = 32, validation_data=val_imgs, epochs=5)","7572c1a2":"train_accuracy =  history.history['accuracy']\ntrain_loss =  history.history['loss']\n\nval_accuracy =  history.history['val_accuracy']\nval_loss =  history.history['val_loss']\nepochs = range(1, len(train_accuracy) + 1)\n\nfigure, axis = plt.subplots(1, 2, figsize=(20, 10))\naxis[0].plot(epochs, train_accuracy, label=\"train\")\naxis[0].plot(epochs, val_accuracy, label=\"validation\")\naxis[0].set_title('Accuracy')\naxis[0].legend()\naxis[1].plot(epochs, train_loss, label=\"train\")\naxis[1].plot(epochs, val_loss, label=\"validation\")\naxis[1].set_title('Loss')\naxis[1].legend()\n\nplt.show()","307d0cdd":"pred = model.predict(test_imgs)","76a73717":"output = np.argmax(pred, axis=1)","bfb884d4":"labels = test_imgs.class_indices # Will get the indices of the classes in integer","c6e1ccc7":"y_vals = []\npred_labels = dict((v, k) for k, v in labels.items()) # mapping the classes with the indices\n\nfor i in range(0, len(output)):\n    y_vals.append(pred_labels[output[i]])","b46b8bc0":"print(classification_report(test_df.Label, y_vals))\nprint(confusion_matrix(test_df.Label, y_vals))","5cd93339":"We could see that for Lion and for Leopard, it is not able to recognise!","a070cc26":"Okie Dokie, ImageDataGenerator have successfully recognised the classes and yes there are total of 5 classes.","dd94bf2a":"### Generating the Data","c17446db":"It looks good. We can see that we do not have enough data so probably the model will overfit but let's look at how it performs.","5861d312":"### Get the data","dc9ddf29":"### Splitting the Data","408253d1":"### Model Creation","71722086":"Oh, we could see Cheetas, Jaguars and it looks good. Plotting the image always kind me gives us a sense of feeling that its real that we are going to do the classification, Yayy!"}}