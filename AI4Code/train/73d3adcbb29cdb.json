{"cell_type":{"d73b9bd8":"code","23d17c1d":"code","a3eb9ffd":"code","19ac5892":"code","978a2ce2":"code","3a5eca31":"code","0cf31c88":"code","fb3c742b":"markdown","82da1aee":"markdown","e25444f9":"markdown","12b1d8cd":"markdown","628e5ce9":"markdown","ddae0918":"markdown","94629066":"markdown","21be25b7":"markdown"},"source":{"d73b9bd8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.metrics.pairwise import cosine_similarity # Calculate distance between movies\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","23d17c1d":"df = pd.read_csv('..\/input\/movies-datasets-2021\/movies_metadata.csv', low_memory=False)  # DtypeWarning close\ndf.head()","a3eb9ffd":"df[\"overview\"].head()","19ac5892":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ndef calculate_cosine_sim(dataframe):\n    tfidf = TfidfVectorizer(stop_words='english')\n    dataframe['overview'] = dataframe['overview'].fillna('')\n    tfidf_matrix = tfidf.fit_transform(dataframe['overview'])\n    tfidf_matrix = tfidf_matrix.astype(np.float32)\n    tfidf_matrix.shape\n    # prevent allocate error\n    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n    return cosine_sim","978a2ce2":"def content_based_recommender(title, cosine_sim, dataframe):\n    \"\"\"\n         Provides content-based advice\n\n         Parameters\n         ----------\n         title: str\n             We get the information of the watched movie from outside and\n             we will adjust the same contents accordingly.\n         cosine_sim: Series\n             It is the calculated version of the similarity scores of the films.\n         dataframe: dataframe\n             is the dataset that holds all the movies\n\n         Returns\n         -------\n             Returns recommended movies\n    \"\"\"\n    # creating indexes\n    indices = pd.Series(dataframe.index, index=dataframe['title'])\n    indices = indices[~indices.index.duplicated(keep='last')]\n\n    # capturing title's index\n    movie_index = indices[title]\n\n    # Calculating similarity scores by title\n    similarity_scores = pd.DataFrame(cosine_sim[movie_index], columns=[\"score\"])\n\n    # bring the top 10 movies excluding itself\n    movie_indices = similarity_scores.sort_values(\"score\", ascending=False)[1:11].index\n    return dataframe['title'].iloc[movie_indices]","3a5eca31":"cosine_sim = calculate_cosine_sim(df)","0cf31c88":"content_based_recommender(\"Sherlock Holmes\", cosine_sim, df)","fb3c742b":"# CONTENT BASED RECOMMENDATION\n\n![Content Based Recommendation](https:\/\/miro.medium.com\/max\/1400\/1*Lr6qL0YjY_WqVK5u-AYHAQ.png)\n\nThe work to be done in the Content Based recommendation is quite simple.\n\nWherever you want to apply a movie or article. The one that is similar in content is taken as the basis and the most similar product is shown to the user.\n* The key is to calculate similarity. How Does? let's find out \ud83d\ude80","82da1aee":"* 34737    \u041f\u0440\u0438\u043a\u043b\u044e\u0447\u0435\u043d\u0438\u044f \u0428\u0435\u0440\u043b\u043e\u043a\u0430 \u0425\u043e\u043b\u043c\u0441\u0430 \u0438 \u0434\u043e\u043a\u0442\u043e\u0440\u0430 \u0412\u0430\u0442\u0441\u043e\u043d\u0430: ...\n* 14821                                    The Royal Scandal\n* 34750    The Adventures of Sherlock Holmes and Doctor W...\n* 9743                           The Seven-Per-Cent Solution\n* 4434                                        Without a Clue\n* 29706                       How Sherlock Changed the World\n* 18258                   Sherlock Holmes: A Game of Shadows\n* 24665     The Sign of Four: Sherlock Holmes' Greatest Case\n* 6432                   The Private Life of Sherlock Holmes\n* 29154                          Sherlock Holmes in New York\n\nThus, we have brought the 10 most similar films to Sherlock Holmesa.\nBy the way, Sherlock Holmes comes first and is written in Cyrillic alphabet :)\n\n# let data be your best friend :) \ud83d\ude80","e25444f9":"* all movies have 75827 tokens and there are 45466 movies","12b1d8cd":"# How do we calculate similarity\n\nI calculated the similarity of the films based on the short description of the films, that is, the overview variable.","628e5ce9":"# Creating the Cosine Similarity Matrix","ddae0918":"# As a method, I will use the tf-idf method because of the bias caused by the same word frequency.\n\nTF-IDF = TF(t) * IDF(t)\n\nSTEP 1: TF(t) = (Frequency of occurrence of a t term in the relevant document) \/ (Total number of terms in the document) (term frequency)\n\nSTEP 2: IDF(t) = 1 + log_e((Total number of documents + 1) \/ (Number of documents with t term + 1) (inverse document frequency)\n\nSTEP 3: TF-IDF = TF(t) * IDF(t)\n\nSTEP 4: L2 normalization to TF-IDF Values.","94629066":"!!! In cosine similarity, kaggle is not enough for calculation, but you can run it on your personal computer without any problems.","21be25b7":"# Top 10 recommended movies list"}}