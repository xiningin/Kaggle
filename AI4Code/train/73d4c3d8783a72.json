{"cell_type":{"efe52926":"code","06b61d3b":"code","ee391d6d":"code","6b35e943":"code","51508453":"code","c3bcb191":"code","cd5f13a5":"code","f2c8f817":"code","e416dc45":"code","3a283b16":"code","af5d71c6":"code","abd90bce":"code","cdc4f08d":"code","1bbc0ccb":"code","e0bdeaee":"code","e85ef198":"code","c726aa3a":"code","89e4d374":"code","137dd286":"code","f378ac65":"code","d22c0792":"code","79131cae":"code","1b4fca57":"code","b7e1bc0f":"code","290dcf7e":"code","0aa472d1":"code","28d007be":"code","0217777d":"code","2da0663a":"code","d14c1ba9":"code","54387ccf":"code","09b2c55c":"code","e2ee3184":"code","bb224d8b":"code","a4117895":"code","d11225ed":"code","422f17d2":"code","fff2eb09":"code","732a74c4":"code","bb0e94a3":"code","acf592ac":"code","b56c2a82":"code","640de8be":"code","c8db8c27":"code","7e122dad":"code","4869afcf":"code","8d6ef195":"code","e9be3c74":"code","afb5d38e":"code","3d1632a6":"code","25961d8f":"code","1d22dc65":"code","c3a9ead7":"code","4b3de127":"code","14cbecf4":"code","cd443ed3":"code","1b31ac8f":"code","dcba7890":"code","0c845b97":"code","98a951bd":"code","581c93e4":"code","bce6d161":"code","714bbf61":"code","4e3de498":"code","e008d7fe":"markdown","a2d20c28":"markdown","14ef09a6":"markdown","a2c56382":"markdown","45a7901e":"markdown","124fb790":"markdown","959d8d79":"markdown","c5b79e06":"markdown","b1910655":"markdown","1df3e244":"markdown","614c4b0a":"markdown","c0d378d3":"markdown","d78c2c4d":"markdown","e43a9d2d":"markdown","e1648df7":"markdown","8c514953":"markdown","e2abb115":"markdown","5ea229b1":"markdown","b568b90f":"markdown","d96c99bd":"markdown","e73a0858":"markdown","ee141b16":"markdown","ddcbbe98":"markdown","a9172b5a":"markdown","fbf06322":"markdown"},"source":{"efe52926":"import sklearn\nimport skimage\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom glob import glob\nimport os.path\nfrom skimage import data, io\nfrom matplotlib import pyplot as plt\n\nprint('loaded modules')\n%matplotlib inline","06b61d3b":"! ls \/kaggle\/input\/\n!pwd","ee391d6d":"!ls \/kaggle\/input\/daan-kreuz-kreis-plus\/","6b35e943":"!pwd","51508453":"!tar -xvf \/kaggle\/input\/daan-kreuz-kreis-plus\/train.tar.gz # Trainingsbilder\n!tar -xvf \/kaggle\/input\/daan-kreuz-kreis-plus\/data.tar.gz #Testbilder","c3bcb191":"!ls Bilder","cd5f13a5":"%mkdir -p ..\/output\n!ls \/kaggle\/working\/Bilder\/","f2c8f817":"path = '\/kaggle\/working\/Bilder'\ntrainpath= os.path.join(path,'train')\ntestpath= os.path.join(path,'test')\n\noutputpath = '..\/output'","e416dc45":"y_train = pd.read_csv(os.path.join(path,'target_info_train.txt'),index_col='id')","3a283b16":"#teste imread\n\nim = skimage.io.imread(os.path.join(trainpath,r'0001-u010.png'))\n#im = skimage.io.imread('Bilder\/test\/0887-u026.png')\nim.shape","af5d71c6":"# target_info_train.txt enth\u00e4lt label-Werte 0,1,2\nglob(os.path.join(trainpath,'*.png'))[:10]\nwith open(os.path.join(path,'target_info_train.txt'),'r') as fh:\n    for i in range(10):\n        line = fh.readline()\n        print(line.strip())","abd90bce":"plt.imshow(im[:,:],cmap='gray')\nplt.title('Offenbar haben die Bilder Graustufen und Farbkan\u00e4le')\nplt.colorbar();","cdc4f08d":"mins = []\nmaxes=[]\nimdict = dict()\n#for fn in glob('Bilder\/train\/*.png')+glob('Bilder\/test\/*.png'):\nfor fn in glob(os.path.join(trainpath,'*'))+glob(os.path.join(testpath,'*')):\n    im = skimage.io.imread(fn)\n    imdict[fn]=im\nlen(imdict)","1bbc0ccb":"list(imdict.keys())[:5]","e0bdeaee":"shapes = []\nfor fn,im in imdict.items():\n    shapes.append(im.shape)\npd.Series(shapes).unique()[:10] #zeige nur die ersten 10 unterschiedlichen shapes.","e85ef198":"seen4=0\nfor fn,im in imdict.items():\n    if len(im.shape)>2:\n        if im.shape[2]==4:\n            seen4+=1\n            if seen4==5: #5. Bild mit 4 Ebenen\n                plt.subplot(2,2,1)\n                plt.imshow(im[:,:,0])\n                plt.subplot(2,2,2)\n                plt.imshow(im[:,:,1])\n                plt.subplot(2,2,3)\n                plt.imshow(im[:,:,2])\n                plt.subplot(2,2,4)\n                plt.imshow(im[:,:,3])\n                plt.suptitle(fn)\nprint('done.')","c726aa3a":"im.shape","89e4d374":"grayimdict = dict()\n\nfor fn,im in imdict.items():\n    if len(im.shape)!=2:\n        assert len(im.shape)<=3,'unerwarteter Fall'\n        im=np.mean(im,axis=2)\n    grayimdict[fn]=im","137dd286":"plt.imshow(grayimdict['\/kaggle\/working\/Bilder\/train\/0507-u029.png'],cmap='gray')\nplt.colorbar()","f378ac65":"plt.imshow(grayimdict['\/kaggle\/working\/Bilder\/train\/0446-u032.png'],cmap='gray')\nplt.colorbar();","d22c0792":"for fn,im in grayimdict.items():\n    mins.append(np.min(im))\n    maxes.append(np.max(im))","79131cae":"ax1 = plt.subplot(1,2,1)\nplt.hist(mins,bins=[0,256,1000,10000,100000]);plt.title('pixel minima')\nax1.set_xscale(\"log\", nonposx='clip')\nax2 = plt.subplot(1,2,2)\nplt.hist(maxes,bins=[0,256,1000,10000,100000]);plt.title('pixel maxima')\nax2.set_xscale(\"log\", nonposx='clip')\n#ax2.set_yscale(\"log\", nonposy='clip')","1b4fca57":"scaledimdict = {}\nfor fn,im in grayimdict.items():\n    imscaled = (im - np.min(im))\/(np.max(im)-np.min(im))\n    scaledimdict[fn]=imscaled","b7e1bc0f":"list(scaledimdict.keys())[:5]","290dcf7e":"from skimage import data, io\nfrom matplotlib import pyplot as plt\n\nio.imshow(scaledimdict['\/kaggle\/working\/Bilder\/train\/0129-u021.png'])\nplt.show()","0aa472d1":"scaledimdictflipped = scaledimdict.copy()\nperc_list = []\nfor fn,im in scaledimdict.items():\n    curr_perc = np.percentile(im.ravel(),50)\n    if curr_perc > 0.5: #Falls die Mehrheit der Pixel hell ist, flippe schwarz <-> weiss       \n        scaledimdictflipped[fn] = 1-im\n        new_perc = np.percentile(scaledimdictflipped[fn].ravel(),50)\n    perc_list.append(curr_perc)","28d007be":"plt.hist(perc_list);","0217777d":"import skimage.transform\nresizedimdict=dict()\nfor fn,im in scaledimdictflipped.items():\n    im = skimage.transform.resize(im,(15,15),\n              #Diese zwei Optionen sind n\u00f6tig, um keine Warung mehr zu erhalten:\n              anti_aliasing=True, \n              mode='reflect')\n    resizedimdict[fn]=im","2da0663a":"plt.imshow(im,cmap='gray')\nplt.colorbar();","d14c1ba9":"pixelList = []\nfnamelist = []\nfor fn,im in resizedimdict.items():\n    pixelList.append(im.ravel().tolist())\n    fnamelist.append(fn)\npixelArr = np.array(pixelList)\nplt.imshow(pixelArr)\nplt.gca().set_aspect('auto');plt.xlabel('Pixelindex');plt.ylabel('Bildindex')\n\npixelArr.shape #Anz. Bilder x Anz Pixel (15x15)","54387ccf":"#Verteilung aller Pixelwerte: \nplt.hist(pixelArr.ravel(),bins=50);","09b2c55c":"import pandas as pd\ncols = ['pix'+str(i) for i in range(15**2)]\ndf = pd.DataFrame(pixelArr,columns=cols,index=fnamelist)\ndf.shape","e2ee3184":"AnzProblemPixel = ((df>0.05) & (df < 0.1)).sum(axis=1)\nAnzProblemPixel.hist(bins=20),plt.title('Verteilung der Anzahl \"Problempixel\"');","bb224d8b":"problemBilder = df[AnzProblemPixel>20]","a4117895":"#z.B. \ntestbild = problemBilder.sample()\nplt.imshow(resizedimdict[testbild.index[0]],cmap='gray');","d11225ed":"#Wende den Schwellwert an: \ndfbin = df.copy()\ndfbin[df>0.1]=1\ndfbin[df<=0.1]=0\ndfbin = dfbin.astype('int')","422f17d2":"#\u00dcberpr\u00fcfe qualitativ, indem wir alle Bilder in einem zusammenfassen. Oder auch einfach, weil's h\u00fcbsch aussieht...\nplt.imshow(dfbin,cmap='gray')\nplt.gca().set_aspect('auto');plt.xlabel('Pixelindex');plt.ylabel('Bildindex')","fff2eb09":"im1 = dfbin.sample(1).values.reshape(15,15);plt.subplot(1,3,1);plt.imshow(im1);\nim2 = dfbin.sample(1).values.reshape(15,15);plt.subplot(1,3,2);plt.imshow(im2);\nim3 = dfbin.sample(1).values.reshape(15,15);plt.subplot(1,3,3);plt.imshow(im3);","732a74c4":"def ticksoff():\n    plt.xticks([]),plt.yticks([])\nplt.figure(1,figsize=(15,10))\nim1 = dfbin.iloc[1].values.reshape(15,15);plt.subplot(1,3,2);plt.imshow(im1);ticksoff()\nim2 = dfbin.iloc[2].values.reshape(15,15);plt.subplot(1,3,1);plt.imshow(im2);ticksoff()\nim3 = dfbin.iloc[4].values.reshape(15,15);plt.subplot(1,3,3);plt.imshow(im3);ticksoff()","bb0e94a3":"dfy = pd.read_csv('\/kaggle\/working\/Bilder\/target_info_train.txt',index_col='id')\ndfy.sort_index(inplace=True) #wohl nicht n\u00f6tig...\n\ndfy.tail()","acf592ac":"#dfbin beginnt mit training-Bildern, dann Testbildern\ndisplay(dfbin.head())\ndisplay(dfbin.tail())","b56c2a82":"#extrahiere den Dateinamen aus dem Index:\nimage_index = dfbin.index\nfrom os.path import basename\nimport re\n#re.sub?\ndfbin2 = dfbin.reset_index(inplace=False);\n\nbasenames = pd.Series([os.path.basename(fn) for fn in image_index])\ndfbin2['basename'] = basenames\nimage_index = basenames.replace(to_replace='-u\\d*.png',value='',regex=True).map(lambda x:int(x))\nimage_index[:5]","640de8be":"dfbin2.rename(columns={'index':'Dateiname'},inplace=True)\ndfbin2['image_index']=image_index\ndfbin2 = dfbin2.set_index('image_index',inplace=False).sort_index()\ndfbin2.head()","c8db8c27":"np.all(dfbin2.index==np.arange(1430)), np.all(dfy.index==np.arange(715))","7e122dad":"dfy.index","4869afcf":"dfbin2.tail(2)","8d6ef195":"#inner join:\ndf_train = pd.merge(dfbin2, dfy, left_index=True, right_index=True)\ndisplay(df_train.head(2))\ndf_train.tail(2)","e9be3c74":"dftemp = dfbin2.join(dfy)\ndf_test = dftemp[dftemp.target.isnull()]\ndisplay(df_test.head(2))\ndf_test.tail(2)","afb5d38e":"df_train.target.unique()","3d1632a6":"#Check! nehme 5 zuf\u00e4llige Bilder: stimmen die Label mit den Bildern \u00fcberein?\nsample = df_train.sample(5)\nsample.index","25961d8f":"sample = df_train.sample(5)\nd={0:'Kreuz',1:'Kreis',2:'Plus'}\nfor iframe,index in enumerate(sample.index):\n    plt.subplot(1,5,iframe+1)\n    im = sample.loc[index].iloc[1:-2].values.reshape(15,15).astype('int')\n    target = sample.loc[index].target\n    plt.imshow(im)\n    plt.title('{0}'.format(d[target]))","1d22dc65":"if 'Dateiname' in df_train.columns: del df_train['Dateiname']\nif 'Dateiname' in df_test.columns: del df_test['Dateiname']\nfor coln in df_test.columns:print(coln)","c3a9ead7":"df_train.set_index('basename',inplace=True)\ndf_train.head(5)","4b3de127":"del df_test['target']","14cbecf4":"df_test.set_index('basename',inplace=True)\ndf_test.head()","cd443ed3":"if 'target' in df_test.columns:\n    del df_test['target']\n\ndf_train.to_csv('KreuzKreisPlus_train.csv',index=False)\ndf_test.to_csv('KreuzKreisPlus_test.csv',index=False)","1b31ac8f":"!ls .\n!pwd","dcba7890":"#funktioniert bei mir nicht\nfrom IPython.display import FileLink,FileLinks\n#FileLink('\/kaggle\/output\/KreuzKreisPlus_train.csv')\nFileLinks('\/kaggle\/output\/')\n#!head {outputpath}\/*","0c845b97":"from IPython.display import Javascript\ndef download_file(fn):\n    js_download = \"\"\"\n    var csv = '%s';\n\n    var filename = '{fn}';\n    var blob = new Blob([csv], { type: 'text\/csv;charset=utf-8;' });\n    if (navigator.msSaveBlob) { \/\/ IE 10+\n    navigator.msSaveBlob(blob, filename);\n    } else {\n    var link = document.createElement(\"a\");\n    if (link.download !== undefined) { \/\/ feature detection\n    \/\/ Browsers that support HTML5 download attribute\n    var url = URL.createObjectURL(blob);\n    link.setAttribute(\"href\", url);\n    link.setAttribute(\"download\", filename);\n    link.style.visibility = 'hidden';\n    document.body.appendChild(link);\n    link.click();\n    document.body.removeChild(link);\n    }\n    }\n    \"\"\"\n    return Javascript(js_download)\n#download_file('KreuzKreisPlus_train.csv')\n#download_file('KreuzKreisPlus_test.csv')","98a951bd":"!ls {outputpath}\n!ls \/kaggle\/output","581c93e4":"Xtrain = df_train.values[:,:-1]","bce6d161":"from sklearn.decomposition import PCA\nXtrain","714bbf61":"clf = PCA(n_components=5)\nclf.fit_transform(Xtrain,None)","4e3de498":"plt.figure(1,figsize=(15,20))\nplt.subplot(2,3,1),plt.imshow(clf.components_[0].reshape(-1,15));\nplt.subplot(2,3,2),plt.imshow(clf.components_[1].reshape(-1,15));\nplt.subplot(2,3,3),plt.imshow(clf.components_[2].reshape(-1,15));\nplt.subplot(2,3,4),plt.imshow(clf.components_[3].reshape(-1,15));\nplt.subplot(2,3,5),plt.imshow(clf.components_[4].reshape(-1,15));","e008d7fe":"Mache aus jedem 15x15-Bild eine Zeile mit 225 Werten. Erstelle eine Matrix mit einer Zeile pro Bild.","a2d20c28":"## Daten laden\nZun\u00e4chst laden wir die Bilder in einen Dictionary:","14ef09a6":"# Download ab Kaggle Kernel?\nRecht schwierig ist es, die erstellten Dateien runterzuladen. Am Einfachsten wird das Notebook committed, und unter den output die erzeugten Files heruntergeladen. \nHier einige Ans\u00e4tze dazu, direkt im Kernel auf die Datei zuzugreifen:","a2c56382":"## Zielvariable dazuladen\nDie Zielvariable zu laden ist tricky! \nWie stellen wir sicher, dass das richtige Target-label zur richtigen Datei zugeordnet wird? Dazu m\u00fcssen wir aus dem Dateinamen den Index (als Zahl) extrahieren.\n\nWir holen den Bildindex aus dem Dateinamen, und f\u00fchren es mit dem richtigen Label aus der Zielvariablen-Datei zusammen. Die Datei ist zwar schnell geladen:","45a7901e":"### Wertebereich der Pixel\nWelche Wertebereiche haben die Pixel? Wir m\u00f6chten diese auf den Bereich 0 (Schwarz) bis 1 (Weiss) einschr\u00e4nken.","124fb790":"# PCA","959d8d79":"## Farbbild nach Graustufenbild\nWelche shapes gibt's denn so?","c5b79e06":"## Aufl\u00f6sung der Bilder reduzieren\"\n   \nWir skalieren nun die Bilder drastisch runter- eine Unterscheidung von \\\"x,o,+\\\" sollte auch mit 15x15-Bildern gut m\u00f6glich sein.\"","b1910655":"# Binarisierung\nWie k\u00f6nnen wir diese Daten binarisieren? Wenn wir alle Pixelwerte gr\u00f6sser als ein Schwellwert auf Eins und darunter auf Null setzen: Wo w\u00e4hlen wir den Schwellwert?  \nWenn wir einen Wert zwischen 0.05 und 0.1 w\u00e4hlen, erhalten wir Probleme mit folgenden Bildern:","1df3e244":"Setze nun den neuen Bildindex als DataFrame Index","614c4b0a":"Die Testbilder haben nat\u00fcrlich kein Label! Es gibt folgende Varianten von joins: \n - inner join: es verfallen alle Zeilen, welche es nicht in beiden Teildatens\u00e4tzen gibt.\n - left join: Alle spalten des \"linken\" Datensatzes werden behalten. Wo keine Werte vorhanden sind, wird NaN eingef\u00fcgt.","c0d378d3":"# Speichern der Datens\u00e4tze als .csv-Dateien","d78c2c4d":"Hier benutzen wir eine Regex `Bilder\\\\\/(train|test)\\\\\/(?P<imgind>\\\\d+)-u\\\\d+.png`, umd die 4 Ziffern nach \"Bilder\/train\/\" oder \"Bilder\/test\/\" zu extrahieren. Sie werden in der Gruppe \"imgind\" abgelegt, und von dort wieder geholt:","e43a9d2d":"Wir extrahieren also aus dddd-uddd.png die ersten vier Ziffern- die sind der Index des Bildes.","e1648df7":"Die Pixel haben entweder den Wertebereich [0,255] oder [0,2^16-1]\n   \nWir normieren also mal Pixel-Wertebereich:","8c514953":"Offensichtlich sind einige Zeichen \"weiss\", andere \"schwarz\".","e2abb115":"Die Meisten bilder haben weniger als 20 Problempixel (auf 225)","5ea229b1":"Erinnern wir uns:\n - Klasse 0: Kreuz\n - Klasse 1: Kreis  \n - Klasse 2: Plus","b568b90f":"Tats\u00e4chlich sollten die meisten dieser Bilder kein grosses Problem darstellen f\u00fcr die Klassifikation. Sie haben eine klare Form, und die Pixel mit Werten zwischen 0.05 und 0.1 sollten nicht entscheidend sein.","d96c99bd":"Das ist erstaunlich eindeutig- es gibt klar zwei Gruppen, eine mit kleinem und eine mit grossem Median. Da die meisten Pixel Hintergrundpixel sein sollen, erwarten wir, dass das 50%-Quantil die Hintergrundfarbe angibt.\n   ","e73a0858":"Die folgenden 2 Features produzieren ann\u00e4hernd gleich gute Klassifikationsergebnisse als die 15*15 Pixelfeatures. PCA-Komponenten auf Bildern werden auch Eigenfaces genannt.","ee141b16":"Die Arrays, haben 1 oder 4 Ebenen. 1 Ebene entspricht einem einfachen Graustufenkanal, 4 Ebenen einem RGBA-Bild (mit Alpha-Kanal). Wir erstellen uns Graustufenbilder, indem wir einfach \u00fcber die Farbkan\u00e4le mitteln:   ","ddcbbe98":"# Struktur des Datensatzes\nEigentlich w\u00fcrden wir ja gerne den Datensatz einfach laden. Allerdings haben nur schon die geladenen Bilder ganz unterschiedliches Format:[](http:\/\/)","a9172b5a":"Das war's! Damit haben wir einen Datensatz in einer Form, mit der wir Machine Learning betreiben k\u00f6nnen.  \nGratulation! Einfach war das nicht! Die Dateien lagen in vielen unterschiedlichen Formaten vor. Ihr Zeitaufwand, um es bis hierhin zu schaffen, war gewiss betr\u00e4chtlich. Das \\\"putzen\\\", also das standardisieren der Daten ist ein wichtiger Teil der Arbeit eines Data Scientists. Denken Sie auch daran, dass Sie gewisse Entscheidungen getroffen haben (z.B. die Aufl\u00f6sung, oder die Binarisierung und deren Schwellwerte), welche Sie sp\u00e4ter ev. revidieren wollen. Es lohnt sich daher der Reproduzierbarkeit des soeben erstellten Datensatzes einen gewissen Effort zu widmen.  \n\nAls n\u00e4chstes k\u00f6nnten wir einen Klassifikator nehmen und schauen, wie gut wir diesen Datensatz erkennen. Aber dass das Feature Engineering bei diesem Problem wichtig ist, ist wohl auch klar. \"","fbf06322":"Ist kompliziert! Die Bilder haben unterschiedlich viele Farbkan\u00e4le- entweder keinen (Graustufenbild) oder 4 (rgb-alpha) "}}