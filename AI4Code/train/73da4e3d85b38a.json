{"cell_type":{"3d3cacec":"code","c6c51093":"code","f400f377":"code","4e7cec60":"code","b32e947d":"code","c5b1c0c0":"code","922d2399":"code","1b5e1ec9":"code","1324a1b5":"code","3235f9ec":"code","27d3b74b":"code","313f3854":"code","a2a9ff99":"code","b6e8a9c0":"code","58b37758":"code","d890a285":"code","59993db3":"code","4f5be02f":"code","263c4823":"code","4c5f7c2c":"code","77cdb234":"code","71d2e10a":"code","dae6fd93":"code","390cb9b2":"code","69f7fbe8":"code","099c074a":"code","9e6933b1":"code","3bd39e0a":"code","8296419f":"code","15dac688":"code","1f014da2":"code","9d986c6f":"code","bae3bf8f":"code","ffcdfd1b":"code","7e6f47c6":"code","4f8478a7":"code","5b0f40a3":"code","a723cd67":"code","453882cd":"code","dec56a56":"code","0366ad12":"code","eab20e90":"code","e85053c0":"code","6e5eb2b4":"code","fb26b95f":"code","3c8c12ca":"code","eb7c5968":"markdown","d0c84eae":"markdown","2b011bec":"markdown","6b98456a":"markdown","ca7cb7e1":"markdown","202ac712":"markdown","491bb429":"markdown","9027b53a":"markdown","c0373096":"markdown","c1bed942":"markdown","7b20c72a":"markdown","a77b5f36":"markdown","0659faa4":"markdown","17b24900":"markdown","f312b2f6":"markdown"},"source":{"3d3cacec":"import numpy as np\nimport pandas as pd\nfrom shutil import copyfile\nimport os\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom skimage.io import imread\nimport keras\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, Model,load_model\nfrom keras.layers import Dense , Dropout , Lambda, Flatten, Conv2D, MaxPool2D,GlobalAveragePooling2D\nfrom keras.optimizers import Adam, RMSprop, SGD\nfrom keras.models import load_model\nfrom sklearn.datasets import load_files \nfrom keras.utils import np_utils\nfrom keras.applications.imagenet_utils import decode_predictions\nfrom keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint\nfrom keras import applications\nfrom keras.metrics import FalseNegatives, FalsePositives\nfrom skimage.segmentation import mark_boundaries","c6c51093":"!pip install progressbar2==2.6.0","f400f377":"image_size = 128","4e7cec60":"train_datagen = ImageDataGenerator(rescale=1.\/255, \n                                   rotation_range=90,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True,\n                                   vertical_flip=True,\n                                   fill_mode='nearest')\nval_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_datagen = ImageDataGenerator(rescale=1.\/255)","b32e947d":"train_generator = train_datagen.flow_from_directory(\n    directory=r\"\/kaggle\/input\/tick-and-mosq\/data\/train\/\",\n    target_size=(image_size, image_size),\n    color_mode=\"rgb\",\n    batch_size=10,\n    class_mode=\"categorical\",\n    shuffle=True,\n    seed=42\n)","c5b1c0c0":"val_generator = val_datagen.flow_from_directory(\n    directory=r\"\/kaggle\/input\/tick-and-mosq\/data\/validation\/\",\n    target_size=(image_size, image_size),\n    color_mode=\"rgb\",\n    batch_size=1,\n    class_mode=\"categorical\",\n    shuffle=True,\n    seed=42\n)","922d2399":"test_generator = test_datagen.flow_from_directory(\n    directory=r\"\/kaggle\/input\/tick-and-mosq\/data\/test\/\",\n    target_size=(image_size, image_size),\n    color_mode=\"rgb\",\n    batch_size=1,\n    class_mode=\"categorical\",\n    shuffle=True,\n    seed=42\n)","1b5e1ec9":"base_model = applications.resnet50.ResNet50(weights= \"imagenet\", include_top=False, input_shape= (image_size,image_size,3))","1324a1b5":"num_classes=2","3235f9ec":"x = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dropout(0.5)(x)\npredictions = Dense(num_classes, activation= 'softmax')(x)\nmodel = Model(inputs = base_model.input, outputs = predictions)","27d3b74b":"epoch_mod = 1000","313f3854":"filepath=\"\/kaggle\/working\/weights_best.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='min')","a2a9ff99":"from keras import losses","b6e8a9c0":"#model.compile(optimizer=SGD(lr=0.0001),\nmodel.compile(optimizer=SGD(),\nloss=\"categorical_crossentropy\",\nmetrics=['acc'])","58b37758":"import tensorflow as tf\ninit_lr = 1e-3\ndecay_steps = epoch_mod\nalpha = 0\nbeta = 1e-3\nnum_periods=4\nlin_cos_dec1 = tf.keras.experimental.LinearCosineDecay(init_lr,\n                                                       decay_steps,\n                                                       num_periods=num_periods, alpha=alpha,\n                                                       beta=beta, name='LinCosDec 1')","d890a285":"lr_schedule = tf.keras.callbacks.LearningRateScheduler(lin_cos_dec1, verbose=0)","59993db3":"STEP_SIZE_TRAIN=train_generator.n\/\/train_generator.batch_size\nSTEP_SIZE_VALID=val_generator.n\/\/val_generator.batch_size\nhistory = model.fit_generator(generator=train_generator,\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n                    validation_data=val_generator,\n                    validation_steps=STEP_SIZE_VALID,\n                    epochs=epoch_mod, callbacks=[checkpoint,lr_schedule], verbose=0)","4f5be02f":"import matplotlib.pyplot as plt\nX_train_data=next(train_generator)[0]\nX_train_data[0].shape\nX_train_data = X_train_data[0].reshape( image_size, image_size, 3)\nplt.imshow(X_train_data)","263c4823":"model.save('ResNet50_ECG_model_new.h5')","4c5f7c2c":"print(\"Loss , Accuracy\")\nmodel.evaluate_generator(generator=val_generator,\nsteps=STEP_SIZE_VALID)","77cdb234":"STEP_SIZE_TEST=test_generator.n\/\/test_generator.batch_size\ntest_generator.reset()\npred=model.predict_generator(test_generator,\nsteps=STEP_SIZE_TEST,\nverbose=1)","71d2e10a":"predicted_class_indices=np.argmax(pred,axis=1)","dae6fd93":"labels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npredictions = [labels[k] for k in predicted_class_indices]","390cb9b2":"import plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots","69f7fbe8":"def display_training_curves(training, validation, yaxis):\n    if yaxis == \"loss\":\n        ylabel = \"Loss\"\n        title = \"Loss vs. Epochs\"\n    else:\n        ylabel = \"Accuracy\"\n        title = \"Accuracy vs. Epochs\"\n        \n    fig = go.Figure()\n        \n    fig.add_trace(\n        go.Scatter(x=np.arange(1, epoch_mod+1), mode='lines+markers', y=training, marker=dict(color=\"dodgerblue\"),\n               name=\"Train\"))\n    \n    fig.add_trace(\n        go.Scatter(x=np.arange(1, epoch_mod+1), mode='lines+markers', y=validation, marker=dict(color=\"darkorange\"),\n               name=\"Val\"))\n    \n    fig.update_layout(title_text=title, yaxis_title=ylabel, xaxis_title=\"Epochs\", template=\"plotly_white\")\n\n    fig.show()","099c074a":"display_training_curves(\n    history.history['acc'], \n    history.history['val_acc'], \n    'Accuracy')","9e6933b1":"display_training_curves(\n    history.history['loss'], \n    history.history['val_loss'], \n    'loss')","3bd39e0a":"filenames=test_generator.filenames\nresults=pd.DataFrame({\"Filename\":filenames,\n                      \"Predictions\":predictions})\nresults.to_csv(\"results.csv\",index=False)","8296419f":"results","15dac688":"!pip install lime --upgrade","1f014da2":"import lime\nfrom lime import lime_image\n\nexplainer = lime_image.LimeImageExplainer()","9d986c6f":"X_exp = []\nfor i in range(4):\n    temp_exp = next(test_generator)[0]\n    X_exp.append(temp_exp)","bae3bf8f":"X_exp = np.asarray(X_exp)","ffcdfd1b":"X_exp = X_exp.reshape(4,image_size, image_size, 3)","7e6f47c6":"model.predict(X_exp[0].reshape(1,image_size, image_size, 3))","4f8478a7":"plt.imshow(X_exp[0].reshape(image_size, image_size, 3))\nplt.savefig(\"image1\")","5b0f40a3":"explanation = explainer.explain_instance(X_exp[0].reshape(image_size, image_size, 3), model.predict, top_labels=5, hide_color=0, num_samples=1000)\n\ntemp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=True)\nplt.imshow(mark_boundaries(temp \/ 2 + 0.5, mask))\nplt.savefig(\"image1_exp\")","a723cd67":"model.predict(X_exp[1].reshape(1,image_size, image_size, 3))","453882cd":"plt.imshow(X_exp[1].reshape(image_size, image_size, 3))\nplt.savefig(\"image2\")","dec56a56":"explanation = explainer.explain_instance(X_exp[1].reshape(image_size, image_size, 3), model.predict, top_labels=5, hide_color=0, num_samples=1000)\n\ntemp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=True)\nplt.imshow(mark_boundaries(temp \/ 2 + 0.5, mask))\nplt.savefig(\"image2_exp\")","0366ad12":"model.predict(X_exp[2].reshape(1,image_size, image_size, 3))","eab20e90":"plt.imshow(X_exp[2].reshape(image_size, image_size, 3))\nplt.savefig(\"image3\")","e85053c0":"explanation = explainer.explain_instance(X_exp[2].reshape(image_size, image_size, 3), model.predict, top_labels=5, hide_color=0, num_samples=1000)\n\ntemp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=True)\nplt.imshow(mark_boundaries(temp \/ 2 + 0.5, mask))\nplt.savefig(\"image3_exp\")","6e5eb2b4":"model.predict(X_exp[3].reshape(1,image_size, image_size, 3))","fb26b95f":"plt.imshow(X_exp[3].reshape(image_size, image_size, 3))\nplt.savefig(\"image4\")","3c8c12ca":"explanation = explainer.explain_instance(X_exp[3].reshape(image_size, image_size, 3), model.predict, top_labels=5, hide_color=0, num_samples=1000)\n\ntemp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=True)\nplt.imshow(mark_boundaries(temp \/ 2 + 0.5, mask))\nplt.savefig(\"image4_exp\")","eb7c5968":"# <center> Can we distingiuish between marks from tick bites and mosquito bites using Residual Neural Networks? <\/center>","d0c84eae":"# Start the training!","2b011bec":"This notebook is inspired by this [medium article](https:\/\/medium.com\/@vijayabhaskar96\/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720). A big thanks to [Vijayabhaskar J](https:\/\/www.kaggle.com\/vijayabhaskar96) for making this tutorial. \n\nYou can read more of his articles [here](https:\/\/medium.com\/@vijayabhaskar96)","6b98456a":"## Explain image 4","ca7cb7e1":"# LIME explaination","202ac712":"# Set dataflow from directory\n### Now we want to start train our model, but first we need to make a Image Data Generator that will get batches of data from our directory. We need to make one generator each for the train, test and validation directories. Keras will find all the categories that we have in the subdirectories (in this case mosquitos and ticks).","491bb429":"# Save the model\n### Before doing anything else we want to save our model","9027b53a":"# Historical training data\n### We can also have a look at how the accuracy and loss imporved during the training","c0373096":"## Explain image 1","c1bed942":"# Make directories\n### We want to structure the data in different subdirectories to make it more easy to train the model later on\n\n![](https:\/\/miro.medium.com\/max\/1262\/1*HpvpA9pBJXKxaPCl5tKnLg.jpeg)\n***Figure 1:*** *To be able to use the Keras method; flow_from_directory(), we need to create some new directories.*\n*This illustration is taken from this [medium article](https:\/\/medium.com\/@vijayabhaskar96\/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720), Author:[Vijayabhaskar J](https:\/\/www.kaggle.com\/vijayabhaskar96), which is recommended reading if you consider doing something similar to this*","7b20c72a":"## Explain image 2","a77b5f36":"## Explain image 3","0659faa4":"# Making the model\n### Finally we are ready to make the model. Or, what we actually are going to do is to get the ResNet50 with pretrained weights from image net and retrain it for our purpose.","17b24900":"# Evaluation and predictions\n### Now, lets see how our model performs!\n","f312b2f6":"# Lets save our prediction to a file"}}