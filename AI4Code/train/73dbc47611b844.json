{"cell_type":{"df3b42e1":"code","8820e2eb":"code","f2079d7e":"code","75926d45":"code","b9da34a3":"code","5a536b6d":"code","1007a9b2":"code","8db0eb1d":"code","b534d6b8":"code","6a4d963c":"code","3cb008c1":"code","c5a5bd12":"code","26b445f7":"code","b0491fd6":"code","0ca609a7":"code","67f8e032":"code","f360e9eb":"code","84448366":"code","15d0a206":"markdown","feefa9c3":"markdown","8317965e":"markdown","240f2116":"markdown","cff89498":"markdown"},"source":{"df3b42e1":"#Importing the necessary libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom itertools import permutations\nfrom mlxtend.preprocessing import TransactionEncoder\nfrom mlxtend.frequent_patterns import apriori, association_rules\n\nplt.style.use('seaborn-pastel')","8820e2eb":"#Reading the csv file\ngro = pd.read_csv('..\/input\/groceries-dataset\/Groceries_dataset.csv', index_col='Date', parse_dates=True)","f2079d7e":"#Taking a look at the data shape and sorting by date\nprint(gro.shape)\ngro.sort_index(inplace=True)\ngro.head()","75926d45":"#Number of unique Costumers and Items\nprint(gro.Member_number.nunique())\nprint(gro.itemDescription.nunique())","b9da34a3":"#Creating new columns based on the date column\ngro['year'] = gro.index.year\ngro['month'] = gro.index.month\ngro['day'] = gro.index.day\ngro['weekday'] = gro.index.strftime('%A')\ngro['monthName'] = gro.index.strftime('%B')\ngro.head()","5a536b6d":"#Chart 1 - Most purchased items\ngro['itemDescription'].value_counts().head(20).plot.bar(figsize=(8, 6), alpha=0.8, color='violet')\nplt.title('20 most purchased items', size=15)\nplt.ylabel('Quantity')","1007a9b2":"#Chart 2 - Least purchased items\ngro['itemDescription'].value_counts().tail(20).plot.bar(figsize=(8, 6), alpha=0.8, color='lightseagreen')\nplt.title('20 least purchased items', size=15)\nplt.ylabel('Quantity')","8db0eb1d":"#Chart 3 - Total items sold per month each year\nplt.figure(figsize=(8,6))\nax = sns.countplot(x='monthName', hue='year', palette='GnBu', data=gro)\nax.set_xticklabels(ax.get_xticklabels(), rotation=45)\nplt.title('Total items sold per month each year', size=15)\nplt.xlabel('Month')\nplt.ylabel('Quantity')","b534d6b8":"#Chart 4 - Total items sold per day each year\nplt.figure(figsize=(15,8))\nax = sns.countplot(x='day', hue='year', palette='YlOrBr', data=gro)\nax.set_xticklabels(ax.get_xticklabels(), rotation=45)\nplt.title('Total items sold per day each year', size=15)\nplt.xlabel('Day')\nplt.ylabel('Quantity')","6a4d963c":"#Chart 5 - Total items sold per weekday each year  \nplt.figure(figsize=(8,6))\nax = sns.countplot(x='weekday', hue='year', palette='RdPu', data=gro)\nax.set_xticklabels(ax.get_xticklabels(), rotation=45)\nplt.title('Total items sold per weekday each year', size=15)\nplt.xlabel('Weekday')\nplt.ylabel('Quantity')","3cb008c1":"#Chart 6 - Top Costumers\nplt.figure(figsize=(8,6))\nax = sns.countplot(x='Member_number', palette='winter', data=gro, alpha=0.6, order=gro.Member_number.value_counts().iloc[:20].index)\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)\nplt.title('Top Costumers', size=15)\nplt.xlabel('Costumer')\nplt.ylabel('Quantity Purchased')","c5a5bd12":"#Grouping by Costumers and date to create transactions\ntransactions = gro.groupby(['Member_number', 'Date'])['itemDescription'].unique().reset_index()","26b445f7":"#Taking a look at the number of transactions\nprint(transactions.shape)\ntransactions.head()","b0491fd6":"#Separating the transactions as a list of lists and taking a look\ntrsct = list(list(i) for i in transactions.itemDescription.values)\ntrsct","0ca609a7":"#one hot encoding and creating the encoded Dataframe\nencoder = TransactionEncoder().fit(trsct)\nonehot = encoder.transform(trsct)\ndfonehot = pd.DataFrame(onehot, columns=encoder.columns_)\ndfonehot.head()","67f8e032":"#Applying the apriori algorithm with a min_support of 0.002\nfrequent_itemsets = apriori(dfonehot, min_support=0.002, use_colnames=True)\nprint(len(frequent_itemsets))","f360e9eb":"#Compute association rules with a lift threshold of 1\nrules = association_rules(frequent_itemsets, metric='lift', min_threshold=1)","84448366":"#Printing our final rules\nrules","15d0a206":"## Market Basket Analysis with Apriori\n\nWell hello there! \ud83d\ude43 In this notebook I'll try to explore the groceries dataset and apply market basket analysis to identify products that are frequently purchased together and construct association rules. But first, it is always a good practice to do some Exploratory Data Analysis.\n\n![supermarket](https:\/\/www.savethestudent.org\/uploads\/Supermarket-Savings-1.jpg)","feefa9c3":"### Importing the data & first look \n\nHere we are just importing the necessary libraries, loading the data and taking a first look at its contents. ","8317965e":"### The Apriori algorithm\n\nApriori proceeds by identifying the frequent individual items in the data and extending them to larger and larger itemsets as long as those itemsets appear sufficiently often in the data. It prunes itemsets not known to be frequent.\n\n### Metrics \n\nA metric is a measure of performance for rules. We'll work with the **support metric**, **confidence metric** and **lift metric**. \n\n**support:** Measures the share of transactions that contain an item. We can calculate it as followed:\n\nsupport = number of transactions with item \/ total transactions\n\n**confidence:** Says how likely item Y is purchased when item X is purchased. We can calculate it as followed:\n\nconfidence{X->Y} = support{X,Y} \/ support{X}\n\n**lift:** Says how likely item Y is purchased when item X is purchased while controlling for how popular item Y is.\n\nlift{X->Y} = support{X,Y} \/ support{X} * support{Y}\n\n### Association Rules\n\nAssociation rules are rules that try to satisfy connections between items with a specified minimum support and a specified minimum confidence at the same time.\n\nIt contains antecedent(s) and consequent(s).\n\ne.g. {milk} --> {coffee}\n\n**Multi-antecedent rule**\ne.g. {apple, banana} --> {orange}\n\n**Multi-consequent rule**\ne.g {bread} --> {peanut butter, jam}","240f2116":"### Data Preparation and Visualization\n\nNow, let's prepare the data to create some visualizations. We'll generate the following plots:\n\n* Most purchased items \n* Least purchased items\n* Total count of items sold per month each year\n* Total count of items sold per day each year\n* Total count of items sold per weekday each year\n* Top costumers (Costumers who bought the most)","cff89498":"### Data modelling for Association Rules and Apriori\n\nHere we'll prepare the data to a suitable form for the apriori algorithm. The first step is to generate the transactions, the items bought by a unique costumer each day. Then, we'll perform one hot encoding to treat these categorical features as values."}}