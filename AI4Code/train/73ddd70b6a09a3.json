{"cell_type":{"7a176f1f":"code","a461d88a":"code","ac56d9ba":"code","8a8f9759":"code","94be23b2":"code","ab77ad82":"code","2e707922":"code","248fc0a9":"code","c67cdc6f":"code","0b14496b":"code","6b371a6a":"code","fbc29f6f":"code","15ac8335":"code","d2289cd8":"code","bee29384":"code","ec224ccc":"code","3920c1bd":"code","fd793d06":"code","fa5dbcca":"code","e1667527":"code","9207ef99":"code","efc1a426":"code","5b919840":"code","e0bd4c3c":"code","73d6cfc7":"code","ea826db6":"code","ed2d0e4a":"code","ee3917d7":"code","e16c4308":"code","9fd6f4f2":"code","d82da96a":"code","56bb3a1c":"code","b4da50aa":"code","4fa2b546":"code","0be7ce56":"code","955607b3":"code","3d198092":"code","92b0657a":"code","3651fa0f":"code","d0728b84":"code","3cf3fefa":"code","2b5bac1e":"code","0a657ff5":"code","6f12af7c":"code","a775c748":"code","0bf7a205":"code","176e86a3":"code","d6837449":"code","d2402c5b":"code","f9a53fd0":"code","4b3a118d":"code","29676fc3":"code","605c5834":"code","82b9bfb1":"code","03e67e38":"code","99635f24":"code","8c646bc6":"code","01a1a3ba":"code","a706c230":"code","e5d84ee0":"code","68c168b1":"code","6abdde16":"code","b8900c5a":"code","a976ed46":"code","8b5eb45c":"code","19fe7db4":"code","c26e0660":"code","f5fb8867":"code","01e2743c":"code","f579c2de":"code","40a4f079":"code","70652246":"code","7c659dfa":"code","0aa49872":"code","6bf232ef":"code","848b38ae":"code","1f5e836f":"code","19226e1c":"code","a2ffdac8":"code","951e96ff":"code","3865ac12":"code","136eba95":"code","d2cfb3f8":"code","0ad14b92":"code","b83d825e":"code","2d5cf701":"code","59fa0838":"code","32b6122e":"code","926d1032":"code","6f049c0c":"code","e6d17157":"code","e887cdae":"code","98814fd7":"code","833633dd":"code","a070bb4e":"code","a1a0bdcb":"code","859fd596":"code","e5e5fa22":"code","0545705c":"code","744c7f60":"code","e86b8779":"code","260de02a":"code","da2292d5":"code","d37edbda":"code","3833779c":"code","1bbb7b95":"code","7f702158":"code","355182cb":"code","898bcd93":"code","2c57ccf5":"code","2afe5201":"code","e3bfc133":"code","7f2077b5":"code","be2313f1":"code","f9a2fc53":"code","1b6611f3":"code","caffc4c9":"code","b0179188":"code","77ab665e":"code","fdd473af":"code","2ac5ad12":"code","9a69f2be":"code","b3f4b885":"code","ae0fda99":"code","4df7f543":"code","5fa30861":"code","cf9cbd3e":"code","660630b9":"code","a85c844a":"code","9d3639f1":"code","4fd10281":"code","92a11fb9":"markdown","713be1d8":"markdown","085d4c59":"markdown","bb607504":"markdown","c425d045":"markdown","02aded65":"markdown","c1b9d40e":"markdown","75ee5c87":"markdown","fa4ddd4b":"markdown","c13a0ca7":"markdown","6ca92e6a":"markdown","f2b084a5":"markdown","b0273be6":"markdown","5eaaf595":"markdown","80fb540c":"markdown","6e0d0528":"markdown","eb2dd401":"markdown","35cfd31b":"markdown","53dca7d6":"markdown","647354d7":"markdown","551a0cff":"markdown","daefc121":"markdown","37c039a6":"markdown","f05f377c":"markdown","17fdaeba":"markdown","def2abb4":"markdown","4d987a69":"markdown","e2af6d3d":"markdown","d22e0d6d":"markdown","5ac3b807":"markdown","e91976a2":"markdown","900ad129":"markdown","1d9d5114":"markdown","45c74bc6":"markdown","818d2d60":"markdown","0b879cc9":"markdown","ef5c88fd":"markdown","78692167":"markdown","30b69663":"markdown","e00d227d":"markdown","3324db4d":"markdown","10412d23":"markdown","e67652a5":"markdown","193d85c4":"markdown","3fb70a23":"markdown","28f513fb":"markdown","c817a7ac":"markdown","fbd5b46b":"markdown","b40cc5cc":"markdown","c260c5b6":"markdown","84dd2f60":"markdown","90e9102d":"markdown","5ffa4677":"markdown","5deba1fb":"markdown","0a288cef":"markdown","cbcec857":"markdown","b9c48c76":"markdown","a0121f11":"markdown","44fba10a":"markdown","8874503b":"markdown","6d9ef5ff":"markdown","0d7402e3":"markdown","dc2e8b49":"markdown","b379d082":"markdown","20b594f3":"markdown","9b49c8c5":"markdown","fb73d50c":"markdown","041a6ac4":"markdown","dea2a1a7":"markdown","b3f4bb7f":"markdown","73ca9c86":"markdown","12ceb563":"markdown","3b2ee236":"markdown","251b0547":"markdown","108f0e62":"markdown"},"source":{"7a176f1f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a461d88a":"import numpy as np\nimport pandas as pd\npd.options.display.max_columns = 200\n\nimport lightgbm as lgb\nfrom lightgbm import LGBMRegressor\nimport xgboost as xgb\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import HistGradientBoostingRegressor\nfrom sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nfrom sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\nfrom sklearn.svm import SVR, LinearSVR\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\n\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error, mean_squared_log_error\n\nfrom tqdm import tqdm_notebook as tqdm\nfrom geopy.distance import great_circle\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import PowerTransformer\nfrom scipy.stats import norm, skew\nfrom scipy import stats\n\nfrom sklearn.inspection import permutation_importance\nimport matplotlib.pyplot as pyplot\nfrom sklearn.metrics.pairwise import euclidean_distances\n\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone","ac56d9ba":"# \u8ddd\u96e2\u8a08\u7b97\u3092\u884c\u3046\u95a2\u6570\u3092\u5b9a\u7fa9\u3057\u3066\u304a\u304d\u307e\u3059\u3002\ndef calc_distance(df, dist):\n    return great_circle((df.Latitude, df.Longitude), dist).meters\n\ndf_train = pd.read_csv('..\/input\/machine-learning-homework\/train.csv', index_col=0)\ndf_test = pd.read_csv('..\/input\/machine-learning-homework\/test.csv', index_col=0)\ndf_station = pd.read_csv('..\/input\/machine-learning-homework\/station_info.csv')\ndf_city = pd.read_csv('..\/input\/machine-learning-homework\/city_info.csv')\n\nindex_train = df_train.index\nindex_test = df_test.index","8a8f9759":"df_all = pd.concat([df_train, df_test], axis = 0)\ndf_all.head()","94be23b2":"df_all.info()","ab77ad82":"# Missing Data_all\ndf_all_na = (df_all.isnull().sum() \/ len(df_all)) * 100\ndf_all_na = df_all_na.drop(df_all_na[df_all_na == 0].index).sort_values(ascending=False)[:30]\nmissing_data_all = pd.DataFrame({'Missing Ratio_all' :df_all_na})\n\n# Missing Data_train\ndf_train_na = (df_train.isnull().sum() \/ len(df_train)) * 100\ndf_train_na = df_train_na.drop(df_train_na[df_train_na == 0].index).sort_values(ascending=False)[:30]\nmissing_data_train = pd.DataFrame({'Missing Ratio_train' :df_train_na})\n\n# Missing Data_test\ndf_test_na = (df_test.isnull().sum() \/ len(df_test)) * 100\ndf_test_na = df_test_na.drop(df_test_na[df_test_na == 0].index).sort_values(ascending=False)[:30]\nmissing_data_test = pd.DataFrame({'Missing Ratio_test' :df_test_na})\n\nmissing_data = pd.concat([missing_data_all, missing_data_train, missing_data_test], axis=1)\nmissing_data","2e707922":"na_col_list = df_all.isnull().sum()[df_all.isnull().sum()>0].index.tolist()\ndf_all[na_col_list].dtypes.sort_values()","248fc0a9":"df_all[\"Year\"] = df_all[\"Year\"].astype(\"str\")\ndf_all[\"Quarter_str\"] = df_all[\"Quarter\"].astype(\"str\")\ndf_all[\"Quarter_str\"] = df_all[\"Quarter_str\"].str.replace('1','.0').str.replace('2','.25').str.replace('3','.5').str.replace('4','.75')\ndf_all[\"Transaction\"] = df_all[\"Year\"] + df_all[\"Quarter_str\"]\ndf_all[\"Year\"] = df_all[\"Year\"].astype(\"int\")\ndf_all = df_all.drop([\"Quarter_str\"], axis = 1)\ndf_all[\"Transaction\"] = df_all[\"Transaction\"].astype(\"float\")\n\ndf_all = df_all.drop([\"Year\", \"Quarter\"], axis=1)\n\ndf_all.head()","c67cdc6f":"#Correlation map to see how features are correlated with TradePrice\ncorrmat = df_all.corr()\nplt.subplots(figsize=(12,9))\nsns.heatmap(corrmat, vmax=0.9, vmin=-0.9, square=True, cmap=\"bwr\")","0b14496b":"df_all_float = df_all.loc[:, [\"MinTimeToNearestStation\", \"MaxTimeToNearestStation\", \"Area\", \"Frontage\", \"TotalFloorArea\", \"BuildingYear\", \n                              \"PrewarBuilding\", \"Breadth\", \"CoverageRatio\", \"FloorAreaRatio\", \"Transaction\", \"TradePrice\"]]\n\ndf_all_float.head()","6b371a6a":"sns.scatterplot(data=df_train, x=\"Breadth\", y=\"TradePrice\")","fbc29f6f":"# Breadth\u306etrain\u3068test\u306e\u5206\u5e03\u3092\u78ba\u8a8d\nfig = plt.figure()\nax = fig.add_subplot(1, 1, 1)\nax.hist(df_train[\"Breadth\"], bins=50, alpha=0.6)\nax.hist(df_test[\"Breadth\"], bins=50, alpha=0.6)\nax.set_xlabel('Breadth')\nplt.show()","15ac8335":"grouped_Classification_Breadth = df_all.groupby('Classification')['Breadth'].mean() \ngrouped_Classification_Breadth.sort_values()","d2289cd8":"df_all[\"Classification\"].value_counts()","bee29384":"#df_all.Classification.replace([\"Kyoto\/ Osaka Prefectural Road\", \"Hokkaido Prefectural Road\"], np.nan, inplace=True)\ndf_all[\"Classification\"] = df_all[\"Classification\"].fillna(\"NaN\")\n\ngrouped_Classification_Breadth = df_all.groupby('Classification')['Breadth'].mean() \ngrouped_Classification_Breadth.sort_values()","ec224ccc":"dict_Breadth = grouped_Classification_Breadth.to_dict()\ndict_Breadth","3920c1bd":"# Breadth\u304c\u7a7a\u6b04\u306e\u5834\u5408\u306f\u3001Classification\u306e\u5024\u3092\u5165\u529b\ndf_all['Breadth'] = df_all['Breadth'].fillna(df_all['Classification'])\n\ndf_all.Breadth.replace(dict_Breadth,inplace=True)\ndf_all.head()","fd793d06":"df_all.Breadth.isnull().sum()","fa5dbcca":"df_train[\"CityPlanning\"] = df_train[\"CityPlanning\"].fillna(\"NaN\")\ngrouped_CityPlanning_TradePrice_train = df_train.groupby('CityPlanning')['TradePrice'].mean() \ngrouped_CityPlanning_TradePrice_train.sort_values()","e1667527":"df_test[\"CityPlanning\"] = df_test[\"CityPlanning\"].fillna(\"NaN\")\n\nCityPlanning_value_counts = pd.concat([grouped_CityPlanning_TradePrice_train.sort_values(ascending=False), df_train.CityPlanning.value_counts(), df_test.CityPlanning.value_counts()], axis=1)\nCityPlanning_value_counts.columns = [\"train_CityPlanning_TradePrice_mean\", \"train_CityPlanning_values_counts\", \"test_CityPlanning_values_counts\"]\nCityPlanning_value_counts[\"teat\/train\"] = CityPlanning_value_counts[\"test_CityPlanning_values_counts\"] \/ CityPlanning_value_counts[\"train_CityPlanning_values_counts\"]\nCityPlanning_value_counts","9207ef99":"sns.scatterplot(data=df_all, x=\"Area\", y=\"CityPlanning\")","efc1a426":"df_all[\"CityPlanning\"] = df_all[\"CityPlanning\"].fillna(\"NaN\")\ngrouped_CityPlanning_Area_all = df_all.groupby('CityPlanning')['Area'].mean() \ngrouped_CityPlanning_Area_all.sort_values()","5b919840":"# CityPlanning \u3092 Area\u306e\u5e73\u5747\u5024\u3067TargetEncoding\ndf_all['CityPlanning'] = df_all.CityPlanning.map(grouped_CityPlanning_Area_all)\ndf_all","e0bd4c3c":"df_train[\"Renovation\"] = df_train[\"Renovation\"].fillna(\"NaN\")\ndf_test[\"Renovation\"] = df_test[\"Renovation\"].fillna(\"NaN\")\n\ngrouped_Renovation_TradePrice_train = df_train.groupby('Renovation')['TradePrice'].mean() \n\nRenovation_value_counts = pd.concat([grouped_Renovation_TradePrice_train.sort_values(ascending=False), df_train.Renovation.value_counts(), df_test.Renovation.value_counts()], axis=1)\nRenovation_value_counts.columns = [\"train_Renovation_TradePrice_mean\", \"train_Renovation_values_counts\", \"test_Renovation_values_counts\"]\nRenovation_value_counts[\"teat\/train\"] = Renovation_value_counts[\"test_Renovation_values_counts\"] \/ Renovation_value_counts[\"train_Renovation_values_counts\"]\nRenovation_value_counts","73d6cfc7":"# Renovation\u30d5\u30e9\u30b0\u306e\u7279\u5fb4\u91cf\u8ffd\u52a0\uff1aDone=1, Not yet=0, NAN=0\ndf_all[\"RenovationFlag\"] = df_all['Renovation'].apply(lambda x: 1 if x == \"Done\" else 0)","ea826db6":"sns.scatterplot(data=df_all, x=\"Area\", y=\"Renovation\")","ed2d0e4a":"df_train[\"Classification\"] = df_train[\"Classification\"].fillna(\"NaN\")\ndf_test[\"Classification\"] = df_test[\"Classification\"].fillna(\"NaN\")\n\ngrouped_Category_TradePrice_train = df_train.groupby(\"Classification\")['TradePrice'].mean() \n\nCategory_value_counts = pd.concat([grouped_Category_TradePrice_train.sort_values(ascending=False), df_train.Classification.value_counts(), df_test.Classification.value_counts()], axis=1)\nCategory_value_counts.columns = [\"train_Category_TradePrice_mean\", \"train_Category_values_counts\", \"test_Category_values_counts\"]\nCategory_value_counts[\"teat\/train\"] = Category_value_counts[\"test_Category_values_counts\"] \/ Category_value_counts[\"train_Category_values_counts\"]\nCategory_value_counts","ee3917d7":"sns.scatterplot(data=df_all, x=\"Area\", y=\"Classification\")","e16c4308":"df_all[\"Classification\"] = df_all[\"Classification\"].fillna(\"NaN\")\ngrouped_Classification_Area_all = df_all.groupby('Classification')['Area'].mean() \ngrouped_Classification_Area_all.sort_values()","9fd6f4f2":"# Classification \u3092 Area\u306e\u5e73\u5747\u5024\u3067TargetEncoding\ndf_all['Classification'] = df_all.Classification.map(grouped_Classification_Area_all)\ndf_all","d82da96a":"df_train[\"Purpose\"] = df_train[\"Purpose\"].fillna(\"NaN\")\ndf_test[\"Purpose\"] = df_test[\"Purpose\"].fillna(\"NaN\")\n\ngrouped_Category_TradePrice_train = df_train.groupby(\"Purpose\")['TradePrice'].mean() \n\nCategory_value_counts = pd.concat([grouped_Category_TradePrice_train.sort_values(ascending=False), df_train.Purpose.value_counts(), df_test.Purpose.value_counts()], axis=1)\nCategory_value_counts.columns = [\"train_Category_TradePrice_mean\", \"train_Category_values_counts\", \"test_Category_values_counts\"]\nCategory_value_counts[\"teat\/train\"] = Category_value_counts[\"test_Category_values_counts\"] \/ Category_value_counts[\"train_Category_values_counts\"]\nCategory_value_counts","56bb3a1c":"sns.scatterplot(data=df_all, x=\"Area\", y=\"Purpose\")","b4da50aa":"df_all[\"Purpose\"] = df_all[\"Purpose\"].fillna(\"NaN\")\ngrouped_Purpose_Area_all = df_all.groupby('Purpose')['Area'].mean() \ngrouped_Purpose_Area_all.sort_values()","4fa2b546":"# Purpose \u3092 Area\u306e\u5e73\u5747\u5024\u3067TargetEncoding\ndf_all['Purpose'] = df_all.Purpose.map(grouped_Purpose_Area_all)\ndf_all","0be7ce56":"df_train[\"Direction\"] = df_train[\"Direction\"].fillna(\"NaN\")\ndf_test[\"Direction\"] = df_test[\"Direction\"].fillna(\"NaN\")\n\ngrouped_Category_TradePrice_train = df_train.groupby(\"Direction\")['TradePrice'].mean() \n\nCategory_value_counts = pd.concat([grouped_Category_TradePrice_train.sort_values(ascending=False), df_train.Direction.value_counts(), df_test.Direction.value_counts()], axis=1)\nCategory_value_counts.columns = [\"train_Category_TradePrice_mean\", \"train_Category_values_counts\", \"test_Category_values_counts\"]\nCategory_value_counts[\"teat\/train\"] = Category_value_counts[\"test_Category_values_counts\"] \/ Category_value_counts[\"train_Category_values_counts\"]\nCategory_value_counts","955607b3":"sns.scatterplot(data=df_all, x=\"Area\", y=\"Direction\")","3d198092":"df_all[\"Direction\"] = df_all[\"Direction\"].fillna(\"NaN\")\ngrouped_Direction_Area_all = df_all.groupby('Direction')['Area'].mean() \ngrouped_Direction_Area_all.sort_values()","92b0657a":"# Direction\u30d5\u30e9\u30b0\u306e\u7279\u5fb4\u91cf\u8ffd\u52a0\uff1aNo facing road=1, others=0\n# df_all[\"DirectionFlag2\"] = df_all['Renovation'].apply(lambda x: 1 if x == \"No facing road\" else 0)","3651fa0f":"df_train[\"Use\"] = df_train[\"Use\"].fillna(\"NaN\")\ndf_test[\"Use\"] = df_test[\"Use\"].fillna(\"NaN\")\n\ngrouped_Category_TradePrice_train = df_train.groupby(\"Use\")['TradePrice'].mean() \n\nCategory_value_counts = pd.concat([grouped_Category_TradePrice_train.sort_values(ascending=False), df_train.Use.value_counts(), df_test.Use.value_counts()], axis=1)\nCategory_value_counts.columns = [\"train_Category_TradePrice_mean\", \"train_Category_values_counts\", \"test_Category_values_counts\"]\nCategory_value_counts[\"teat\/train\"] = Category_value_counts[\"test_Category_values_counts\"] \/ Category_value_counts[\"train_Category_values_counts\"]\nCategory_value_counts","d0728b84":"sns.scatterplot(data=df_all, x=\"Area\", y=\"Use\")","3cf3fefa":"df_all[\"Use\"] = df_all[\"Use\"].fillna(\"NaN\")\ngrouped_Use_Area_all = df_all.groupby('Use')['Area'].mean() \ngrouped_Use_Area_all.sort_values()","2b5bac1e":"# UseFlag\u3068\u3057\u3066 \u3092 Area\u306e\u5e73\u5747\u5024\u3092\u53d6\u308b\n# df_all['UseFlag2'] = df_all[\"Use\"]\n# df_all[\"UseFlag2\"] = df_all.Use.map(grouped_Use_Area_all)\n# df_all","0a657ff5":"df_train[\"LandShape\"] = df_train[\"LandShape\"].fillna(\"NaN\")\ndf_test[\"LandShape\"] = df_test[\"LandShape\"].fillna(\"NaN\")\n\ngrouped_Category_TradePrice_train = df_train.groupby(\"LandShape\")['TradePrice'].mean() \n\nCategory_value_counts = pd.concat([grouped_Category_TradePrice_train.sort_values(ascending=False), df_train.LandShape.value_counts(), df_test.LandShape.value_counts()], axis=1)\nCategory_value_counts.columns = [\"train_Category_TradePrice_mean\", \"train_Category_values_counts\", \"test_Category_values_counts\"]\nCategory_value_counts[\"teat\/train\"] = Category_value_counts[\"test_Category_values_counts\"] \/ Category_value_counts[\"train_Category_values_counts\"]\nCategory_value_counts","6f12af7c":"sns.scatterplot(data=df_all, x=\"Area\", y=\"LandShape\")","a775c748":"df_all[\"LandShape\"] = df_all[\"LandShape\"].fillna(\"NaN\")\ngrouped_LandShape_Area_all = df_all.groupby('LandShape')['Area'].mean() \ngrouped_LandShape_Area_all.sort_values()","0bf7a205":"# LandShape \u3092 Area\u306e\u5e73\u5747\u5024\u3067TargetEncoding\ndf_all['LandShape'] = df_all.LandShape.map(grouped_LandShape_Area_all)\ndf_all","176e86a3":"df_train[\"FloorPlan\"] = df_train[\"FloorPlan\"].fillna(\"NaN\")\ndf_test[\"FloorPlan\"] = df_test[\"FloorPlan\"].fillna(\"NaN\")\n\ngrouped_Category_TradePrice_train = df_train.groupby(\"FloorPlan\")['TradePrice'].mean() \n\nCategory_value_counts = pd.concat([grouped_Category_TradePrice_train.sort_values(ascending=False), df_train.FloorPlan.value_counts(), df_test.FloorPlan.value_counts()], axis=1)\nCategory_value_counts.columns = [\"train_Category_TradePrice_mean\", \"train_Category_values_counts\", \"test_Category_values_counts\"]\nCategory_value_counts[\"teat\/train\"] = Category_value_counts[\"test_Category_values_counts\"] \/ Category_value_counts[\"train_Category_values_counts\"]\nCategory_value_counts","d6837449":"sns.scatterplot(data=df_all, x=\"Area\", y=\"FloorPlan\")","d2402c5b":"df_all[\"FloorPlan\"] = df_all[\"FloorPlan\"].fillna(\"NaN\")\ngrouped_FloorPlan_Area_all = df_all.groupby('FloorPlan')['Area'].mean() \ngrouped_FloorPlan_Area_all.sort_values()","f9a53fd0":"# FloorPlan \u3092 Area\u306e\u5e73\u5747\u5024\u3067TargetEncoding\ndf_all['FloorPlan'] = df_all.FloorPlan.map(grouped_FloorPlan_Area_all)\ndf_all","4b3a118d":"df_train[\"Structure\"] = df_train[\"Structure\"].fillna(\"NaN\")\ndf_test[\"Structure\"] = df_test[\"Structure\"].fillna(\"NaN\")\n\ngrouped_Category_TradePrice_train = df_train.groupby(\"Structure\")['TradePrice'].mean() \n\nCategory_value_counts = pd.concat([grouped_Category_TradePrice_train.sort_values(ascending=False), df_train.Structure.value_counts(), df_test.Structure.value_counts()], axis=1)\nCategory_value_counts.columns = [\"train_Category_TradePrice_mean\", \"train_Category_values_counts\", \"test_Category_values_counts\"]\nCategory_value_counts[\"teat\/train\"] = Category_value_counts[\"test_Category_values_counts\"] \/ Category_value_counts[\"train_Category_values_counts\"]\nCategory_value_counts","29676fc3":"df_all[\"Structure\"] = df_all[\"Structure\"].fillna(\"NaN\")\ngrouped_Structure_Area_all = df_all.groupby('Structure')['Area'].mean() \ngrouped_Structure_Area_all.sort_values()","605c5834":"# Structure \u3092 Area\u306e\u5e73\u5747\u5024\u3067TargetEncoding\ndf_all['Structure'] = df_all.Structure.map(grouped_Structure_Area_all)\ndf_all","82b9bfb1":"df_train[\"Region\"] = df_train[\"Region\"].fillna(\"NaN\")\ndf_test[\"Region\"] = df_test[\"Region\"].fillna(\"NaN\")\n\ngrouped_Category_TradePrice_train = df_train.groupby(\"Region\")['TradePrice'].mean() \n\nCategory_value_counts = pd.concat([grouped_Category_TradePrice_train.sort_values(ascending=False), df_train.Region.value_counts(), df_test.Region.value_counts()], axis=1)\nCategory_value_counts.columns = [\"train_Category_TradePrice_mean\", \"train_Category_values_counts\", \"test_Category_values_counts\"]\nCategory_value_counts[\"teat\/train\"] = Category_value_counts[\"test_Category_values_counts\"] \/ Category_value_counts[\"train_Category_values_counts\"]\nCategory_value_counts","03e67e38":"df_all[\"Region\"] = df_all[\"Region\"].fillna(\"NaN\")\ngrouped_Region_Area_all = df_all.groupby('Region')['Area'].mean() \ngrouped_Region_Area_all.sort_values()","99635f24":"# Region \u3092 Area\u306e\u5e73\u5747\u5024\u3067TargetEncoding\ndf_all['Region'] = df_all.Region.map(grouped_Region_Area_all)\ndf_all","8c646bc6":"# \u6700\u5bc4\u308a\u99c5\u307e\u3067\u306e\u6240\u8981\u6642\u9593\u304c\u30ab\u30c6\u30b4\u30ea\u306b\u306a\u3063\u3066\u3044\u308b\u306e\u3067\u3001\u6570\u5024\u306b\u5909\u63db\u3002\nreplace_dict = {\n    '30-60minutes':45, '1H-1H30':75, '2H-':120, '1H30-2H':105}\ndf_all.TimeToNearestStation.replace(replace_dict, inplace=True)\ndf_all.TimeToNearestStation = df_all.TimeToNearestStation.astype(float)","01a1a3ba":"# \u6b20\u640d\u5024\uff1aMaxTimeToNearestStation > MinTimeToNearestStation\n# MaxTimeToNearestStation\u304c\u7a7a\u6b04\u306e\u5834\u5408\u306fMinTimeToNearestStation\u306e\u5024\u3092\u5165\u529b\n\nnull_ix = df_all[df_all.MaxTimeToNearestStation.isnull()==True].index\n# \u6b20\u640d\u90e8\u5206\u306b\u96c6\u8a08\u7d50\u679c\u3092\u4ee3\u5165\u3059\u308b\ndf_all.loc[null_ix, 'MaxTimeToNearestStation'] = df_all.MaxTimeToNearestStation.fillna(df_all.MinTimeToNearestStation)\n\ndf_all.loc[null_ix]\n","a706c230":"df_all = df_all.merge(df_station, left_on='NearestStation', right_on='Station', how='left')\n\n# \u6700\u5bc4\u99c5\u304b\u3089\u6771\u4eac\u306e\u3068\u3042\u308b\u99c5\u307e\u3067\u306e\u8ddd\u96e2\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\nstation = 'Tokyo'\nlat_dist = df_station[df_station.Station==station].Latitude.values[0]\nlon_dist = df_station[df_station.Station==station].Longitude.values[0]\n\ndf_all.loc[df_all.Latitude.isnull()==False, 'distance_%s'%station] = \\\ndf_all[df_all.Latitude.isnull()==False].apply(calc_distance, dist=(lat_dist, lon_dist), axis=1)\n\ndf_all[\"Latitude_Station\"] = df_all[\"Latitude\"]\ndf_all[\"Longitude_Station\"] = df_all[\"Longitude\"]\n\ndf_all = df_all.drop([\"Latitude\", \"Longitude\", \"Station\"], axis =1 )\n","e5d84ee0":"df_all_Ward = df_all[df_all[\"Municipality\"].str.contains(\"Ward\")]\ndf_all_Ward = df_all_Ward[df_all_Ward[\"Prefecture\"].str.contains(\"Tokyo\")]\ndf_all_Ward.Municipality.value_counts()","68c168b1":"# \u90fd\u5e02\u306b\u3064\u3044\u3066\u3082\u6700\u5bc4\u308a\u99c5\u3068\u540c\u3058\u64cd\u4f5c\n# \u6771\u4eac23\u533a\u306e\u4e2d\u3067\u51fa\u73fe\u56de\u6570\u304c\u4e00\u756a\u591a\u3044Setagaya Ward\u3092\u57fa\u6e96\ndf_all = df_all.merge(df_city, left_on='Municipality', right_on='Municipality', how='left')\n\nMunicipality_all = 'Setagaya Ward'\nlat_dist = df_city[df_city.Municipality==Municipality_all].Latitude.values[0]\nlon_dist = df_city[df_city.Municipality==Municipality_all].Longitude.values[0]\ndf_all.loc[df_all.Latitude.isnull()==False, 'distance_%s'%Municipality_all] = \\\ndf_all[df_all.Latitude.isnull()==False].apply(calc_distance, dist=(lat_dist, lon_dist), axis=1)\n\n\n# \u5f8c\u8ff0\u306edf_all_high\u306e\u4e2d\u3067\u51fa\u73fe\u56de\u6570\u304c\u4e00\u756a\u591a\u3044Minato Ward\u304b\u3089\u306e\u8ddd\u96e2\u3082\u8ffd\u52a0\nMunicipality_high = 'Minato Ward'\nlat_dist = df_city[df_city.Municipality==Municipality_high].Latitude.values[0]\nlon_dist = df_city[df_city.Municipality==Municipality_high].Longitude.values[0]\ndf_all.loc[df_all.Latitude.isnull()==False, 'distance_%s'%Municipality_high] = \\\ndf_all[df_all.Latitude.isnull()==False].apply(calc_distance, dist=(lat_dist, lon_dist), axis=1)\n\n\n# \u5f8c\u8ff0\u306edf_all_high\u306e\u4e2d\u3067\u51fa\u73fe\u56de\u6570\u304c2\u756a\u76ee\u306b\u591a\u3044Shibuya Ward\u304b\u3089\u306e\u8ddd\u96e2\u3082\u8ffd\u52a0\nMunicipality_low = 'Shibuya Ward'\nlat_dist = df_city[df_city.Municipality==Municipality_low].Latitude.values[0]\nlon_dist = df_city[df_city.Municipality==Municipality_low].Longitude.values[0]\ndf_all.loc[df_all.Latitude.isnull()==False, 'distance_%s'%Municipality_low] = \\\ndf_all[df_all.Latitude.isnull()==False].apply(calc_distance, dist=(lat_dist, lon_dist), axis=1)\n\n# \u5f8c\u8ff0\u306edf_all_high\u306e\u4e2d\u3067\u51fa\u73fe\u56de\u6570\u304c3\u756a\u76ee\u306b\u591a\u3044Chuo Ward\u304b\u3089\u306e\u8ddd\u96e2\u3082\u8ffd\u52a0\nMunicipality_low = 'Chuo Ward'\nlat_dist = df_city[df_city.Municipality==Municipality_low].Latitude.values[0]\nlon_dist = df_city[df_city.Municipality==Municipality_low].Longitude.values[0]\ndf_all.loc[df_all.Latitude.isnull()==False, 'distance_%s'%Municipality_low] = \\\ndf_all[df_all.Latitude.isnull()==False].apply(calc_distance, dist=(lat_dist, lon_dist), axis=1)\n\n# \u5f8c\u8ff0\u306edf_all_low\u306e\u4e2d\u3067\u51fa\u73fe\u56de\u6570\u304c\u4e00\u756a\u591a\u3044Minato Ward\u304b\u3089\u306e\u8ddd\u96e2\u3082\u8ffd\u52a0\nMunicipality_low = 'Nasu Town,Nasu County'\nlat_dist = df_city[df_city.Municipality==Municipality_low].Latitude.values[0]\nlon_dist = df_city[df_city.Municipality==Municipality_low].Longitude.values[0]\ndf_all.loc[df_all.Latitude.isnull()==False, 'distance_%s'%Municipality_low] = \\\ndf_all[df_all.Latitude.isnull()==False].apply(calc_distance, dist=(lat_dist, lon_dist), axis=1)\n\n# \u5f8c\u8ff0\u306edf_all_low\u306e\u4e2d\u3067\u51fa\u73fe\u56de\u6570\u304c2\u756a\u76ee\u306b\u591a\u3044Tsumagoi Village,Agatsuma County\u304b\u3089\u306e\u8ddd\u96e2\u3082\u8ffd\u52a0\nMunicipality_low = 'Tsumagoi Village,Agatsuma County'\nlat_dist = df_city[df_city.Municipality==Municipality_low].Latitude.values[0]\nlon_dist = df_city[df_city.Municipality==Municipality_low].Longitude.values[0]\ndf_all.loc[df_all.Latitude.isnull()==False, 'distance_%s'%Municipality_low] = \\\ndf_all[df_all.Latitude.isnull()==False].apply(calc_distance, dist=(lat_dist, lon_dist), axis=1)\n\n# \u5f8c\u8ff0\u306edf_all_low\u306e\u4e2d\u3067\u51fa\u73fe\u56de\u6570\u304c3\u756a\u76ee\u306b\u591a\u3044Kimitsu City\u304b\u3089\u306e\u8ddd\u96e2\u3082\u8ffd\u52a0\nMunicipality_low = 'Kimitsu City'\nlat_dist = df_city[df_city.Municipality==Municipality_low].Latitude.values[0]\nlon_dist = df_city[df_city.Municipality==Municipality_low].Longitude.values[0]\ndf_all.loc[df_all.Latitude.isnull()==False, 'distance_%s'%Municipality_low] = \\\ndf_all[df_all.Latitude.isnull()==False].apply(calc_distance, dist=(lat_dist, lon_dist), axis=1)\n\ndf_all[\"Latitude_City\"] = df_all[\"Latitude\"]\ndf_all[\"Longitude_City\"] = df_all[\"Longitude\"]\ndf_all[\"Prefecture\"] = df_all[\"Prefecture_x\"]\n\ndf_all = df_all.drop([\"Latitude\", \"Longitude\", \"Prefecture_y\", \"Prefecture_x\"], axis =1 )\n\ndf_all = df_all.rename(columns={'distance_Nasu Town,Nasu County': 'distance_Nasu'})\ndf_all.head()","6abdde16":"# \"TimeToNearestStation\"\u306e\u6b20\u640d\u5024\u306b\u3001NearestStation\u3054\u3068\u306e\u5e73\u5747\u5024\u3092\u5165\u529b\ndf_all[df_all.TimeToNearestStation.isnull()==True]","b8900c5a":"# \u308f\u304b\u308a\u3084\u3059\u304f\u3059\u308b\u305f\u3081\u3001\u4e0a\u8a18\u306e\u6b20\u640d\u884c\u306e\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u3092\u63a7\u3048\u3066\u304a\u304f\nnull_ix = df_all[df_all.TimeToNearestStation.isnull()==True].index","a976ed46":"summary = df_all.groupby(['NearestStation'])['TimeToNearestStation'].mean()\nsummary","8b5eb45c":"# \u6b20\u640d\u90e8\u5206\u306b\u96c6\u8a08\u7d50\u679c\u3092\u4ee3\u5165\u3059\u308b\ndf_all.loc[null_ix, 'TimeToNearestStation'] = df_all.NearestStation.map(summary)\n\ndf_all.loc[null_ix]","19fe7db4":"# MinTimeToNearestStation\u304c\u7a7a\u6b04\u306e\u5834\u5408\u306fTimeToNearestStation\u306e\u5024\u3092\u5165\u529b\nnull_ix = df_all[df_all.MinTimeToNearestStation.isnull()==True].index\n# \u6b20\u640d\u90e8\u5206\u306b\u96c6\u8a08\u7d50\u679c\u3092\u4ee3\u5165\u3059\u308b\ndf_all.loc[null_ix, 'MinTimeToNearestStation'] = df_all.MinTimeToNearestStation.fillna(df_all.TimeToNearestStation)\n\n\n# \u6b20\u640d\u5024\uff1aMaxTimeToNearestStation > MinTimeToNearestStation\n# MaxTimeToNearestStation\u304c\u7a7a\u6b04\u306e\u5834\u5408\u306fMinTimeToNearestStation\u306e\u5024\u3092\u5165\u529b\n\nnull_ix = df_all[df_all.MaxTimeToNearestStation.isnull()==True].index\n# \u6b20\u640d\u90e8\u5206\u306b\u96c6\u8a08\u7d50\u679c\u3092\u4ee3\u5165\u3059\u308b\ndf_all.loc[null_ix, 'MaxTimeToNearestStation'] = df_all.MaxTimeToNearestStation.fillna(df_all.MinTimeToNearestStation)\n\ndf_all.loc[null_ix]","c26e0660":"df_all.info()","f5fb8867":"# \u6700\u5bc4\u308a\u99c5\u3068\u6240\u5728\u90fd\u5e02\u306e\u8ddd\u96e2\u3092\u65b0\u305f\u306a\u7279\u5fb4\u91cf\u306b\u8a2d\u5b9a\ndf_all[\"distance_bet_station_city\"] = np.sqrt((df_all[\"Latitude_Station\"]-df_all[\"Latitude_City\"])**2 + (df_all[\"Longitude_Station\"]-df_all[\"Longitude_City\"])**2)\n\n# \u8ddd\u96e2\u306e\u6bd4\ndf_all[\"distance_Ward\/Station\"] = df_all[\"distance_Setagaya Ward\"]\/df_all['distance_%s'%station]\n\n# \u8ddd\u96e2\u306e\u9006\u6bd4\n# df_all[\"distance_Ward-Station\"] = df_all[\"distance_Setagaya Ward\"] - df_all[\"distance_Tokyo\"]\n\ndf_all.describe()","01e2743c":"df_all_high = df_all[df_all[\"TradePrice\"] > 400000000]\ndf_all_high.info()","f579c2de":"# Missing Data\ndf_all_high_na = (df_all_high.isnull().sum() \/ len(df_all_high)) * 100\ndf_all_high_na = df_all_high_na.drop(df_all_high_na[df_all_high_na == 0].index).sort_values(ascending=False)[:30]\nmissing_data_high = pd.DataFrame({'Missing Ratio_high' :df_all_high_na})\nmissing_data_high","40a4f079":"#Correlation map to see how features are correlated with TradePrice\ncorrmat = df_all_high.corr()\nplt.subplots(figsize=(12,9))\nsns.heatmap(corrmat, vmin = -1, vmax = 1, square=True, cmap=\"bwr\")","70652246":"df_all_high.dtypes","7c659dfa":"df_all_high.Municipality.value_counts()","0aa49872":"grouped_high_City = df_all_high.groupby('Municipality')['TradePrice'].mean() \ngrouped_high_City.sort_values()","6bf232ef":"print(df_all_high.Type.value_counts()), df_all.Type.value_counts()","848b38ae":"print(df_all_high.Region.value_counts()), df_all.Region.value_counts()","1f5e836f":"# TradePrice\u304c\u9ad8\u3044\u30c7\u30fc\u30bf\u306fCommercial Area\u306e\u5272\u5408\u304c\u9ad8\u3044\n# RegionFlag\u3092\u8a2d\u5b9a\u30021=Commercial Area, 0=others\ndf_all[\"RegionFlag\"] = df_all['Region'].apply(lambda x: 1 if x == \"Commercial Area\" else 0)","19226e1c":"print(df_all_high.FloorPlan.value_counts()), df_all.FloorPlan.value_counts()","a2ffdac8":"# \u9ad8\u4fa1\u683c\u5e2f\u306eFloorPlan\u306f\u307b\u307cNaN\u3002NaN\u304b\u3069\u3046\u304b\u306e\u30d5\u30e9\u30b0\u8a2d\u5b9a\ndf_all[\"FloorPlanFlag\"] = df_all['FloorPlan'].apply(lambda x: 1 if x == \"NaN\" else 0)","951e96ff":"print(df_all_high.LandShape.value_counts()), df_all.LandShape.value_counts()","3865ac12":"print(df_all_high.Structure.value_counts()), df_all.Structure.value_counts()","136eba95":"print(df_all_high.Use.value_counts()), df_all.Use.value_counts()","d2cfb3f8":"# \u9ad8\u4fa1\u683c\u5e2f\u306eUse\u306bHouse\u306e\u5272\u5408\u5c11\u306a\u3044\u3002House\u304b\u3069\u3046\u304b\u306e\u30d5\u30e9\u30b0\u8a2d\u5b9a\ndf_all[\"UseFlag\"] = df_all['Use'].apply(lambda x: 1 if x == \"House\" else 0)","0ad14b92":"print(df_all_high.Purpose.value_counts()), df_all.Purpose.value_counts()","b83d825e":"print(df_all_high.Direction.value_counts()), df_all.Direction.value_counts()","2d5cf701":"print(df_all_high.Classification.value_counts()), df_all.Classification.value_counts()","59fa0838":"print(df_all_high.CityPlanning.value_counts()), df_all.CityPlanning.value_counts()","32b6122e":"# \u9ad8\u4fa1\u683c\u5e2f\u306eCityPlanning\u306fCommercial Zone\u306e\u5272\u5408\u3084\u3084\u591a\u3044\u3002Commercial Zone\u304b\u3069\u3046\u304b\u306e\u30d5\u30e9\u30b0\u8a2d\u5b9a\ndf_all[\"CityPlanningFlag\"] = df_all['CityPlanning'].apply(lambda x: 1 if x == \"Commercial Zone\" else 0)","926d1032":"print(df_all_high.Renovation.value_counts()), df_all.Renovation.value_counts()","6f049c0c":"print(df_all_high.Prefecture.value_counts()), df_all.Prefecture.value_counts()","e6d17157":"# \u9ad8\u4fa1\u683c\u5e2f\u306ePrefecture\u306fTokyo\u306e\u5272\u5408\u3084\u3084\u591a\u3044\u3002Tokyo\u304b\u3069\u3046\u304b\u306e\u30d5\u30e9\u30b0\u8a2d\u5b9a\ndf_all[\"PrefectureFlag\"] = df_all['Prefecture'].apply(lambda x: 1 if x == \"Tokyo\" else 0)\ndf_all[\"PrefectureFlag\"].dtypes","e887cdae":"print(df_all_high.Municipality.value_counts()), df_all.Municipality.value_counts()","98814fd7":"print(df_all_high.DistrictName.value_counts()), df_all.DistrictName.value_counts()","833633dd":"df_all_low = df_all[df_all[\"TradePrice\"] < 100000]\ndf_all_low.info()","a070bb4e":"# Missing Data\ndf_all_low_na = (df_all_low.isnull().sum() \/ len(df_all_low)) * 100\ndf_all_low_na = df_all_low_na.drop(df_all_low_na[df_all_low_na == 0].index).sort_values(ascending=False)[:30]\nmissing_data_low = pd.DataFrame({'Missing Ratio_low' :df_all_low_na})\nmissing_data_low","a1a0bdcb":"missing_data = pd.concat([missing_data_all, missing_data_train, missing_data_test, missing_data_high, missing_data_low], axis=1)\nmissing_data","859fd596":"#Correlation map to see how features are correlated with TradePrice\ncorrmat = df_all_low.corr()\nplt.subplots(figsize=(12,9))\nsns.heatmap(corrmat, square=True, cmap=\"bwr\", vmin = -1, vmax = 1)","e5e5fa22":"df_all[\"PurposeFlag\"] = df_all['Purpose'].fillna(\"NaN\").apply(lambda x: 1 if x == \"NaN\" else 0)\ndf_all[\"StructureFlag\"] = df_all['Structure'].fillna(\"NaN\").apply(lambda x: 1 if x == \"NaN\" else 0)\ndf_all[\"FrontageFlag\"] = df_all['Frontage'].fillna(-99999).apply(lambda x: 1 if x == -99999 else 0)\ndf_all[\"BreadthFlag\"] = df_all['Breadth'].fillna(-99999).apply(lambda x: 1 if x == -99999 else 0)\n#df_all[\"CoverageRatioFlag\"] = df_all['CoverageRatio'].fillna(-99999).apply(lambda x: 1 if x == -99999 else 0)\n#df_all[\"FloorAreaRatioFlag\"] = df_all['FloorAreaRatio'].fillna(-99999).apply(lambda x: 1 if x == -99999 else 0)\n#df_all[\"TimeToNearestStationFlag\"] = df_all['TimeToNearestStation'].fillna(-99999).apply(lambda x: 1 if x == -99999 else 0)\n#df_all[\"TotalFloorAreaFlag\"] = df_all['TotalFloorArea'].fillna(-99999).apply(lambda x: 1 if x == -99999 else 0)\ndf_all[\"BuildingYearFlag\"] = df_all['BuildingYear'].fillna(-99999).apply(lambda x: 1 if x == -99999 else 0)\n#df_all[\"NearestStationFlag\"] = df_all['NearestStation'].fillna(\"NaN\").apply(lambda x: 1 if x == \"NaN\" else 0)","0545705c":"df_all_low.Municipality.value_counts()","744c7f60":"df_all_low.CityPlanning.value_counts(), df_all_high.CityPlanning.value_counts(), df_all.CityPlanning.value_counts()","e86b8779":"# \u9ad8\u4fa1\u683c\u5e2f\u306eCityPlanning\u306fNaN\u306e\u5272\u5408\u3084\u3084\u591a\u3044\u3002NaN\u304b\u3069\u3046\u304b\u306e\u30d5\u30e9\u30b0\u8a2d\u5b9a\n# df_all[\"CityPlanningNaNFlag\"] = df_all['CityPlanning'].apply(lambda x: 1 if x == \"NaN\" else 0)","260de02a":"df_all_low.LandShape.value_counts(), df_all_high.LandShape.value_counts(), df_all.LandShape.value_counts()","da2292d5":"# \u4f4e\u3044\u4fa1\u683c\u5e2f\u306eLandShape\u306fNaN\u306e\u5272\u5408\u3084\u3084\u591a\u3044\u3002NaN\u304b\u3069\u3046\u304b\u306e\u30d5\u30e9\u30b0\u8a2d\u5b9a\n# df_all[\"LandShapeFlag\"] = df_all['LandShape'].apply(lambda x: 1 if x == \"NaN\" else 0)","d37edbda":"df_all_low.Direction.value_counts(), df_all_high.Direction.value_counts(), df_all.Direction.value_counts()","3833779c":"# \u4f4e\u3044\u4fa1\u683c\u5e2f\u306eDirection\u306fNaN\u306e\u5272\u5408\u3084\u3084\u591a\u3044\u3002NaN\u304b\u3069\u3046\u304b\u306e\u30d5\u30e9\u30b0\u8a2d\u5b9a\ndf_all[\"DirectionFlag\"] = df_all['Direction'].apply(lambda x: 1 if x == \"NaN\" else 0)","1bbb7b95":"df_all_low.Classification.value_counts(), df_all_high.Classification.value_counts(), df_all.Classification.value_counts()","7f702158":"# \u4f4e\u3044\u4fa1\u683c\u5e2f\u306eClassification\u306fNaN\u306e\u5272\u5408\u3084\u3084\u591a\u3044\u3002NaN\u304b\u3069\u3046\u304b\u306e\u30d5\u30e9\u30b0\u8a2d\u5b9a\ndf_all[\"ClassificationFlag\"] = df_all['Classification'].apply(lambda x: 1 if x == \"NaN\" else 0)","355182cb":"# \u65b0\u3057\u3044\u7279\u5fb4\u91cf\u3092\u8ffd\u52a0\ndf_all[\"CoverageRatio\/FloorAreaRatio\"] = df_all[\"CoverageRatio\"]\/df_all[\"FloorAreaRatio\"]\ndf_all['Area_x_CoverageRatio_x_FloorAreaRatio'] = df_all['Area'] * df_all['CoverageRatio'] * df_all['FloorAreaRatio']","898bcd93":"corrmat = df_all.corr()\nplt.subplots(figsize=(15,15))\nsns.heatmap(corrmat, vmax=0.9, square=True, cmap=\"bwr\")","2c57ccf5":"# TotalFloorArea\u306e\u6b20\u640d\u5024\u304c\u591a\u3044\u305f\u3081\u3001\u4ed6\u304b\u3089\u4e88\u6e2c\u3067\u304d\u306a\u3044\u304b\uff1f\ndf_all.TotalFloorArea.plot(kind=\"hist\")","2afe5201":"df_Area = df_all[[\"Area\", \"TotalFloorArea\", \"AreaIsGreaterFlag\", \"TotalFloorAreaIsGreaterFlag\", \"CoverageRatio\", \"FloorAreaRatio\", \"CoverageRatio\/FloorAreaRatio\", \"Area_x_CoverageRatio_x_FloorAreaRatio\"]]\ndf_Area = df_Area.fillna(-99999)\ndf_Area\n\ndf_Area_test = df_Area[df_Area[\"TotalFloorArea\"] == -99999]\ndf_Area_train = df_Area[(df_Area[\"TotalFloorArea\"] != -99999) & (df_Area[\"TotalFloorArea\"] != 2000)]\ndf_Area_2000 = df_Area[(df_Area[\"TotalFloorArea\"] == 2000)]\n\ny_Area_train = df_Area_train.TotalFloorArea\nX_Area_train = df_Area_train.drop([\"TotalFloorArea\"], axis=1)\ny_Area_test = df_Area_test.TotalFloorArea\nX_Area_test = df_Area_test.drop([\"TotalFloorArea\"], axis=1)\n\ndf_Area_test.shape, df_Area_train.shape, df_Area_2000.shape","e3bfc133":"y_Area_train.shape, X_Area_train.shape, y_Area_test.shape, X_Area_test.shape","7f2077b5":"index_df_Area_test = df_Area_test.index\nn_fold = 5\ncv = KFold(n_splits=n_fold)\n\ny_Area_pred_train = np.zeros(len(X_Area_train))\ny_Area_pred_test = np.zeros(len(X_Area_test))\nscores = []\n\nfor i, (train_index, val_index) in enumerate(cv.split(X_Area_train, y_Area_train)):\n    X_Area_train_, y_Area_train_ = X_Area_train.iloc[train_index], y_Area_train.iloc[train_index]\n    X_Area_val, y_Area_val = X_Area_train.iloc[val_index], y_Area_train.iloc[val_index]\n    \n    model = lgb.LGBMRegressor(learning_rate=0.05, \n                              n_estimators=150, random_state=71,\n                              num_leaves = 20,)\n    model.fit(X_Area_train_, np.log1p(y_Area_train_))\n    y_Area_pred_val = np.expm1(model.predict(X_Area_val))\n    y_Area_pred_test += np.expm1(model.predict(X_Area_test))\/n_fold\n    \n    y_Area_pred_train[val_index] = y_Area_pred_val\n    score = mean_squared_log_error(y_Area_val, y_Area_pred_val)**0.5\n    scores.append(score)\n    \n    print(\"Fold%d RMSLE: %f\"%(i, score))\n    \nprint(\"Overall RMSLE: %f\u00b1%f\"%(np.mean(scores), np.std(scores)))","be2313f1":"plt.scatter(y_Area_train, y_Area_pred_train)\nmax_y = np.max(np.array([np.array(y_Area_train), y_Area_pred_train]))\nmin_y = np.min(np.array([np.array(y_Area_train), y_Area_pred_train]))\nplt.plot([min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y)],\n         [min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y)], 'k-')\nplt.ylim(min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y))\nplt.xlim(min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y))\nplt.xlabel('y_Area_train')\nplt.ylabel('y_Area_pred_train')\n\nplt.show()","f9a2fc53":"df_Area_test.TotalFloorArea = y_Area_pred_test\ndf_Area = pd.concat([df_Area_test, df_Area_train, df_Area_2000])\ndf_Area[\"index\"] = df_Area.index\ndf_Area = df_Area.sort_values(\"index\")\ndf_Area","1b6611f3":"df_all[\"pred_TotalFloorArea\"] = df_all[\"TotalFloorArea\"].fillna(df_Area[\"TotalFloorArea\"])\ndf_all.shape","caffc4c9":"df_all.info()","b0179188":"# dtype\u304cobject\u306e\u3082\u306e\u3092\u96d1\u306bLabelEncoding\u3057\u3066\u304a\u304f\u3002\u540c\u6642\u306b\u6b20\u640d\u3092\u57cb\u3081\u3066\u304a\u304f\u3002\nfor col in df_all.columns:\n    if (df_all[col].dtype == 'object'):\n        le = LabelEncoder()\n        df_all[col] = le.fit_transform(df_all[col].fillna('NaN')) # \u30ab\u30c6\u30b4\u30ea\u306e\u6b20\u640d\u3092NaN\u3068\u3044\u3046\u5024\u3067\u57cb\u3081\u3066\u304a\u304f\n        \ndf_all = df_all.fillna(-99999) # \u6570\u5024\u306e\u6b20\u640d\u3092-99999\u3067\u57cb\u3081\u3066\u304a\u304f","77ab665e":"\n\n#\u4e0d\u8981\u306a\u30ab\u30e9\u30e0\u306e\u524a\u9664\ndf_all = df_all.drop(['Prefecture', \"NearestStation\", \"DistrictName\", \"Municipality\"], axis=1)\n\n#df_all = df_all.drop([\"ClassificationFlag\"], axis=1)\n#df_all = df_all.drop([\"StructureFlag\"], axis=1)\n#df_all = df_all.drop([\"CityPlanningFlag\"], axis=1)\n#df_all = df_all.drop([\"PurposeFlag\"], axis=1)\n#df_all = df_all.drop([\"FloorPlanFlag\"], axis=1)\n#df_all = df_all.drop([\"RegionFlag\"], axis=1)\n\ndf_all = df_all.drop([\"TotalFloorArea\"], axis=1)\n\ndf_all = df_all.drop([\"MinTimeToNearestStation\"], axis=1)\n#df_all = df_all.drop([\"MaxTimeToNearestStation\"], axis=1)\n#df_all = df_all.drop([\"calcTotalFloorArea\"], axis=1)\n","fdd473af":"y_train = df_all.loc[index_train].TradePrice\nX_all = df_all.drop([\"TradePrice\"], axis = 1)\n\nX_test = X_all.loc[index_test]\nX_train = X_all.loc[index_train]","2ac5ad12":"X_train.shape, y_train.shape","9a69f2be":"too_high = 11000000000\n\ndf_train_too_high = df_train[df_train[\"TradePrice\"] > too_high]\ndf_train_too_high[\"Prefecture\"].value_counts()","b3f4b885":"# y_train\u304c\u5927\u304d\u3044\u9818\u57df\u306e\u4e88\u6e2c\u304c\u60aa\u3044\n# y_train\u304c\u3042\u308b\u5024\u3088\u308a\u5927\u304d\u3044\u30c7\u30fc\u30bf\u3092\u524a\u9664\u3057\u3066\u4e88\u6e2c\u7cbe\u5ea6\u3092\u78ba\u8a8d\n\ndf_train_too_high = pd.concat([X_train, y_train], axis = 1)\ndf_train_too_high = df_train_too_high[df_train_too_high[\"TradePrice\"] < too_high]\n\ny_train = df_train_too_high.TradePrice\nX_train = df_train_too_high.drop([\"TradePrice\"], axis = 1)\n\nX_train.shape, y_train.shape","ae0fda99":"too_low = 1100\n\ndf_train_too_low = df_train[df_train[\"TradePrice\"] < too_low]\n\ndf_train_too_low[\"Prefecture\"].value_counts()","4df7f543":"# y_train\u304c\u5c0f\u3055\u3044\u9818\u57df\u306e\u4e88\u6e2c\u3082\u60aa\u3044\n# y_train\u304c\u3042\u308b\u5024\u3088\u308a\u5c0f\u3055\u3044\u30c7\u30fc\u30bf\u3092\u524a\u9664\u3057\u3066\u4e88\u6e2c\u7cbe\u5ea6\u3092\u78ba\u8a8d\n\ndf_train_too_low = pd.concat([X_train, y_train], axis = 1)\ndf_train_too_low = df_train_too_low[df_train_too_low[\"TradePrice\"] > too_low]\n\ny_train = df_train_too_low.TradePrice\nX_train = df_train_too_low.drop([\"TradePrice\"], axis = 1)\n\nX_train.shape, y_train.shape","5fa30861":"# \u5c0f\u7b20\u539f\u8af8\u5cf6\u306f\u30c7\u30fc\u30bf\u304b\u3089\u9664\u5916\ndf_train_Ogasawara = pd.concat([X_train, y_train], axis = 1)\ndf_train_Ogasawara = df_train_Ogasawara[df_train_Ogasawara[\"Longitude_City\"] < 141]\n\ny_train = df_train_Ogasawara.TradePrice\nX_train = df_train_Ogasawara.drop([\"TradePrice\"], axis = 1)\n\nX_train.shape, y_train.shape","cf9cbd3e":"corrmat = df_all.corr()\nplt.subplots(figsize=(15,15))\nsns.heatmap(corrmat, vmax=0.9, square=True, cmap=\"bwr\")","660630b9":"X_train = X_train.rename(columns={'distance_Tsumagoi Village,Agatsuma County': 'distance_Tsumagoi'})\nX_test = X_test.rename(columns={'distance_Tsumagoi Village,Agatsuma County': 'distance_Tsumagoi'})","a85c844a":"plt.figure(figsize=(10, 17))\nbar = sns.barplot(x=\"importance\", y=\"feature\", data=feature)\nbar.axes.set_xlim(-0.0000000001,0.0000000035)\nbar","9d3639f1":"from sklearn.ensemble import VotingRegressor\n\nn_fold = 7\ncv = KFold(n_splits=n_fold)\n\ny_pred_train = np.zeros(len(X_train))\ny_pred_test = np.zeros(len(X_test))\nscores = []\n\nfor i, (train_index, val_index) in enumerate(cv.split(X_train, y_train)):\n    X_train_, y_train_ = X_train.iloc[train_index], y_train.iloc[train_index]\n    X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]\n    \n    # random seed average\n    model1 = lgb.LGBMRegressor(n_estimators=300, max_depth=6, random_state=1, subsample=0.8, colsample_bytree=0.8, min_child_weight=1)\n    model2 = lgb.LGBMRegressor(n_estimators=300, max_depth=6, random_state=71, subsample=0.8, colsample_bytree=0.8, min_child_weight=1)\n    model3 = lgb.LGBMRegressor(n_estimators=300, max_depth=6, random_state=141, subsample=0.8, colsample_bytree=0.8, min_child_weight=1)\n    model4 = lgb.LGBMRegressor(n_estimators=300, max_depth=6, random_state=211, subsample=0.8, colsample_bytree=0.8, min_child_weight=1)\n    ereg = VotingRegressor(estimators=[('m1', model1), ('m2', model2), ('m3', model3), ('m4', model4)])\n    ereg.fit(X_train_, np.log1p(y_train_))\n    y_pred_val = np.expm1(ereg.predict(X_val))\n    y_pred_test += np.expm1(ereg.predict(X_test))\/n_fold\n    \n    y_pred_train[val_index] = y_pred_val\n    score = mean_squared_log_error(y_val, y_pred_val)**0.5\n    scores.append(score)\n    \n    print(\"Fold%d RMSLE: %f\"%(i, score))\n    \nprint(\"Overall RMSLE: %f\u00b1%f\"%(np.mean(scores), np.std(scores)))","4fd10281":"df_sub = pd.read_csv('..\/input\/machine-learning-homework\/sample_submission.csv', index_col=0)\ndf_sub.TradePrice = y_pred_test\ndf_sub.to_csv('submission.csv')","92a11fb9":"plt.scatter(y_train, y_pred_train)\nmax_y = np.max(np.array([np.array(y_train), y_pred_train]))\nmin_y = np.min(np.array([np.array(y_train), y_pred_train]))\nplt.plot([min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y)],\n         [min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y)], 'k-')\nplt.ylim(min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y))\nplt.xlim(min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y))\nplt.xlabel('y_train')\nplt.ylabel('y_pred_train')\nfigsize=(10, 20)\nplt.show()","713be1d8":"# Time of transaction year\/Quarter \u3092\u7d50\u5408","085d4c59":"import optuna.integration.lightgbm as lgb_o\nfrom sklearn.model_selection import train_test_split\n\nX_train_op, X_val_op, y_train_op, y_val_op = train_test_split(X_Area_train, y_Area_train, test_size=0.2,random_state=0)\n\n\n# LightGBM\u7528\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u5909\u63db\ntrain = lgb_o.Dataset(X_train_op, np.log1p(y_train_op))\nval = lgb_o.Dataset(X_val_op, np.log1p(y_val_op))\n\n# \u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u30b5\u30fc\u30c1&\u30e2\u30c7\u30eb\u69cb\u7bc9\nparams = {'objective': 'regression',\n          'metric': 'rmse',\n          'random_seed':0} \n\ngbm_o = lgb_o.train(params,\n                    train,\n                    valid_sets=val,\n                    early_stopping_rounds=100,\n                    verbose_eval=200,)\n\n# \u30d9\u30b9\u30c8\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u53d6\u5f97\ngbm_o.params","bb607504":"# UMAP","c425d045":"plt.scatter(y_train, y_pred_train)\nmax_y = np.max(np.array([np.array(y_train), y_pred_train]))\nmin_y = np.min(np.array([np.array(y_train), y_pred_train]))\nplt.plot([min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y)],\n         [min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y)], 'k-')\nplt.ylim(min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y))\nplt.xlim(min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y))\nplt.xlabel('y_train')\nplt.ylabel('y_pred_train')\n\nplt.show()","02aded65":"result = permutation_importance(model, X_train, y_train, n_repeats=1, random_state=71)\n\nfeature = pd.DataFrame(result.importances.T[0])\nfeature_index = pd.DataFrame(X_train.columns)\nfeature = pd.concat([feature_index, feature], axis=1)\nfeature.columns = [\"feature\", \"importance\"]\nfeature = feature.sort_values(\"importance\")\npd.options.display.precision = 2\nfeature","c1b9d40e":"from sklearn.linear_model import LinearRegression\n# \u30b9\u30bf\u30c3\u30ad\u30f3\u30b0\u306b\u3088\u308b\u4e88\u6e2c\n\n# \u7b2c1\u6bb5\u968e\u306e\u4e88\u6e2c\u5024(\u3053\u306e\u5f8c\u3001\u30e1\u30bf\u30e2\u30c7\u30eb\u306e\u5165\u529b\u306b\u4f7f\u7528)\nfirst_pred_1 = np.expm1(first_model_1.predict(X_valid))\nfirst_pred_2 = np.expm1(first_model_2.predict(X_valid))\nfirst_pred_3 = np.expm1(first_model_3.predict(X_valid))\n\n#\u7b2c1\u6bb5\u968e\u306e\u4e88\u6e2c\u5024\u3092\u7a4d\u307f\u91cd\u306d\u308b\nstack_pred = np.column_stack((first_pred_1, first_pred_2, first_pred_3))\n\n# \u30e1\u30bf\u30e2\u30c7\u30eb\u306e\u5b66\u7fd2 \nmeta_model = PLSRegression(n_components=2)\nmeta_model.fit(stack_pred, y_valid)\n\n# \u5404\u30e2\u30c7\u30eb\u306e\u691c\u8a3c\u30c7\u30fc\u30bf\u3092\u7a4d\u307f\u91cd\u306d\u308b\nstack_test_pred = np.column_stack((test_pred_1, test_pred_2, test_pred_3))\n\n# \u30b9\u30bf\u30c3\u30ad\u30f3\u30b0\u306e\u691c\u8a3c\nmeta_test_pred = meta_model.predict(stack_test_pred)\nprint (\"\u30e1\u30bf\u30e2\u30c7\u30eb\u306eRMSE: {:.4f}\".format(mean_squared_log_error(y_test_, meta_test_pred)**0.5))","75ee5c87":"# TradePrice\u304c\u9ad8\u3044\u9818\u57df\u306e\u7279\u5fb4\u91cf\u306e\u78ba\u8a8d","fa4ddd4b":"import optuna.integration.lightgbm as lgb_o\nfrom sklearn.model_selection import train_test_split\n\nX_train_op, X_val_op, y_train_op, y_val_op = train_test_split(X_train, y_train, test_size=0.2,random_state=0)\n\n\n# LightGBM\u7528\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u5909\u63db\ntrain = lgb_o.Dataset(X_train_op, np.log1p(y_train_op))\nval = lgb_o.Dataset(X_val_op, np.log1p(y_val_op))\n\n# \u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u30b5\u30fc\u30c1&\u30e2\u30c7\u30eb\u69cb\u7bc9\nparams = {'objective': 'regression',\n          'metric': 'rmse',\n          'random_seed':0} \n\ngbm_o = lgb_o.train(params,\n                    train,\n                    valid_sets=val,\n                    early_stopping_rounds=100,\n                    verbose_eval=200,)\n\n# \u8abf\u6574\u5f8c\u30e2\u30c7\u30eb\u3067\u4e88\u6e2c\u306e\u5b9f\u884c\ny_train_pred = np.expm1(gbm_o.predict(X_train,num_iteration=gbm_o.best_iteration))\ny_test_pred = np.expm1(gbm_o.predict(X_test,num_iteration=gbm_o.best_iteration))\n\n# \u30d9\u30b9\u30c8\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u53d6\u5f97\ngbm_o.params","c13a0ca7":"# Area\u306b\u95a2\u3059\u308b\u7279\u5fb4\u91cf\u306e\u78ba\u8a8d","6ca92e6a":"from sklearn.model_selection import train_test_split\nX_train_valid, X_test_, y_train_valid, y_test_ = train_test_split(X_train, y_train, test_size=0.2, random_state=100)\nX_train, X_valid, y_train, y_valid = train_test_split(X_train_valid, y_train_valid, test_size=0.2, random_state=100)","f2b084a5":"# 3)Classification","b0273be6":"## ToDo\nPCA\u4f7f\u3048\u306a\u3044\uff1f\u7def\u5ea6\u3068\u7d4c\u5ea6\n\u30e6\u30fc\u30b0\u30ea\u30c3\u30c9\u8ddd\u96e2\\","5eaaf595":"df_all_Saitama.Municipality.value_counts()","80fb540c":"# \u5b66\u7fd2-LightGBM","6e0d0528":"# 4) Purpose","eb2dd401":"# 8) FloorPlan","35cfd31b":"# \u8ddd\u96e2\u95a2\u4fc2\u306e\u7279\u5fb4\u91cf","53dca7d6":"plt.scatter(np.log1p(y_train), np.log1p(y_pred_train))\nmax_y = np.max(np.array([np.array(np.log1p(y_train)), np.log1p(y_pred_train)]))\nmin_y = np.min(np.array([np.array(np.log1p(y_train)), np.log1p(y_pred_train)]))\nplt.plot([min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y)],\n         [min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y)], 'k-')\nplt.ylim(min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y))\nplt.xlim(min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y))\nplt.xlabel('log(y_train+1)')\nplt.ylabel('log(y_pred_train+1)')\nfigsize=(10, 20)\nplt.show()","647354d7":"from sklearn.cross_decomposition import PLSRegression\nfrom catboost import CatBoostRegressor, FeaturesData, Pool\n# \u7b2c1\u6bb5\u968e\u306e\u30e2\u30c7\u30eb\u4f5c\u6210\n\nfirst_model_1 = model_2\nfirst_model_2 = model_2\nfirst_model_3 = model_2\n\nfirst_model_1.fit(X_train, np.log1p(y_train))\nfirst_model_2.fit(X_train_high, np.log1p(y_train_high))\nfirst_model_3.fit(X_train_low, np.log1p(y_train_low))\n\n# \u7d50\u679c\u306e\u691c\u8a3c \ntest_pred_1 = np.expm1(first_model_1.predict(X_test_))\ntest_pred_2 = np.expm1(first_model_2.predict(X_test_))\ntest_pred_3 = np.expm1(first_model_3.predict(X_test_))\n\n#\u3000\u5404\u30e2\u30c7\u30eb\u500b\u5225\u306e\u4e88\u6e2c\u7cbe\u5ea6\u3092\u5e73\u5747\u4e8c\u4e57\u8aa4\u5dee\u3067\u78ba\u8a8d\nprint (\"\u30e2\u30c7\u30eb1\u306eRMSLE: {:.4f}\".format(mean_squared_log_error(y_test_, test_pred_1)**0.5))\nprint (\"\u30e2\u30c7\u30eb2\u306eRMSLE: {:.4f}\".format(mean_squared_log_error(y_test_, test_pred_2)**0.5))\nprint (\"\u30e2\u30c7\u30eb3\u306eRMSLE: {:.4f}\".format(mean_squared_log_error(y_test_, test_pred_3)**0.5))","551a0cff":"# \u30ab\u30c6\u30b4\u30ea\u2015\u5909\u6570\u304b\u3089\u65b0\u3057\u3044\u7279\u5fb4\u91cf","daefc121":"too_high = 10000000\n\ndf_train_too_high = pd.concat([X_train, y_train], axis = 1)\ndf_train_too_high = df_train_too_high[df_train_too_high[\"TradePrice\"] > too_high]\n\nhigh_index = df_train_too_high.index\n\nX_train.shape, df_train_too_high.shape","37c039a6":"too_low = 1000000\n\ndf_train_too_low = pd.concat([X_train, y_train], axis = 1)\ndf_train_too_low = df_train_too_low[df_train_too_low[\"TradePrice\"] < too_low]\n\nX_train.shape, df_train_too_low.shape","f05f377c":"# Chiyoda Ward :\nLatitude_City_Tokyo = 35.694031\nLongitude_City_Tokyo = 139.753772\n# Naka Ward,Yokohama City : \nLatitude_City_Kanagawa = 35.432255\nLongitude_City_Kanagawa = 139.660515\n# Chuo Ward,Chiba City : \nLatitude_City_Chiba = 35.583071\nLongitude_City_Chiba = 140.131802\n# Mito City : \nLatitude_City_Ibaraki = 36.365876\nLongitude_City_Ibaraki = 140.471372\n# Utsunomiya City : \nLatitude_City_Tochigi = 36.555074\nLongitude_City_Tochigi = 139.882621\n# Maebashi City : \nLatitude_City_Gunma = 36.389467\nLongitude_City_Gunma = 139.063413\n# Urawa Ward,Saitama City : \nLatitude_City_Saitama = 35.875254\nLongitude_City_Saitama = 139.655412","17fdaeba":"# \u5b66\u7fd2-Stacking\u7528-high price\u9818\u57df\u306e\u307f\u306e\u30e2\u30c7\u30eb","def2abb4":"result = permutation_importance(model_2, X_train, y_train, n_repeats=1, random_state=71)\nfeature = pd.DataFrame(result.importances.T[0])\nfeature_index = pd.DataFrame(X_train.columns)\nfeature = pd.concat([feature_index, feature], axis=1)\nfeature.columns = [\"feature\", \"importance\"]\nfeature = feature.sort_values(\"importance\")\nfeature","4d987a69":"# \u6570\u5024\u30ab\u30e9\u30e0\u306e\u76f8\u95a2","e2af6d3d":"# \u6b20\u640d\u5024\u51e6\u7406","d22e0d6d":"# \u5916\u308c\u5024\u51e6\u7406","5ac3b807":"plt.scatter(np.log1p(y_train_high), np.log1p(y_pred_train_high))\nmax_y = np.max(np.array([np.array(np.log1p(y_train_high)), np.log1p(y_pred_train_high)]))\nmin_y = np.min(np.array([np.array(np.log1p(y_train_high)), np.log1p(y_pred_train_high)]))\nplt.plot([min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y)],\n         [min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y)], 'k-')\nplt.ylim(min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y))\nplt.xlim(min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y))\nplt.xlabel('log(y_train_high+1)')\nplt.ylabel('log(y_pred_train_high+1)')\nplt.show()","e91976a2":"y_train_high = df_train_too_high.TradePrice\nX_train_high = df_train_too_high.drop([\"TradePrice\"], axis = 1)\n\ndf_train_too_high.shape, X_train_high.shape, y_train_high.shape","900ad129":"# Breadth\u304c\u91cd\u8981\u5ea6\u306e\u9ad8\u3044\u5909\u6570\u3060\u3063\u305f\u306e\u3067\u3001\u6b20\u640d\u5024\u88dc\u586b","1d9d5114":"# 9) Structure","45c74bc6":"# \u5b66\u7fd2-LightGBM-random seed average","818d2d60":"## Done\n1.GroupKFold + HistGradientBoostingRegressor(0.818)\\\n4.StratifiedKFold + HistGradientBoostingRegressor --- (0.528)\\\n8.\u6700\u5bc4\u308a\u99c5\u307e\u3067\u306e\u6240\u8981\u6642\u9593\u3092\u5e73\u5747\u5024\u306b\u5909\u63db\u3057\u30664\u3092\u5b9f\u884c\uff080.528)\\\n9.df_city\u8ffd\u52a0\u3001\u5343\u4ee3\u7530\u533a\uff0823\u533a\u306e\u4e2d\u3067\u5e73\u5747Tradeplace\u304c\u6700\u5927\uff09\u304b\u3089\u306e\\\u8ddd\u96e2\u3082\u5909\u6570\u8ffd\u52a0\u30674\u3092\u5b9f\u65bd\uff080.5185\uff09\\\n10.9\u306e\u5343\u4ee3\u7530\u533a\u3092\u845b\u98fe\u533a\uff0823\u533a\u306e\u4e2d\u3067\u5e73\u5747Tradeplace\u304c\u6700\u5c0f\uff09\u304b\u3089\u306e\u8ddd\u96e2\u3082\u5909\u6570\u8ffd\u52a0\u30674\u3092\u5b9f\u65bd\uff080.518\uff09\\\n11.9\u306e\u4e16\u7530\u8c37\u533a\u3092\u845b\u98fe\u533a\uff0823\u533a\u306e\u4e2d\u3067\u5e73\u5747Tradeplace\u304c\u4e2d\u592e\u304f\u3089\u3044\uff09\u304b\u3089\u306e\u8ddd\u96e2\u3082\u5909\u6570\u8ffd\u52a0\u30674\u3092\u5b9f\u65bd\uff080.5175\uff09\\\n12.11\u304b\u3089Area\u3068\u4e16\u7530\u8c37\u533a\u304b\u3089\u306e\u8ddd\u96e2\u3092\u5bfe\u6570\u5909\u63db\u3057\u30664\u3092\u5b9f\u65bd\uff080.5175\uff09\\\n13.11\u304b\u3089\u6b6a\u5ea60.5\u4ee5\u4e0a\u306e\u5909\u6570\u3092Yao-Johnson\u5909\u63db\u3057\u30664\u3092\u5b9f\u65bd\uff080.5175\uff09\\\n14.11\u306bCoverageRatio\/FloorAreaRatio\u3092\u8ffd\u52a0\uff080.5170\uff09\\\n15.14\u306bRenovationFlag\u3092\u8ffd\u52a0\uff080.5170\uff09\\\n16.15\u306bArea\/TotalFloorArea \u3068 AveTimeToNearestStation \u3092\u8ffd\u52a0\uff080.5173\uff09\\\n17.16\u304b\u3089Area\/TotalFloorArea\u524a\u9664\uff080.5170\uff09\\\n18.17\u3067y_train\u304c\u5927\u304d\u3044\u9818\u57df\u306e\u4e88\u6e2c\u304c\u60aa\u3044\u305f\u3081\u3001y_train\u304c1500000000\u3088\u308a\u5927\u304d\u3044\u30c7\u30fc\u30bf\u3092\u524a\u9664\uff080.5155\uff09\\\n19.18\u3067y_train\u304c2000000000\u3088\u308a\u5927\u304d\u3044\u30c7\u30fc\u30bf\u3092\u524a\u9664\uff080.5160\uff09\\\n20.18\u3067y_train\u304c1000000000\u3088\u308a\u5927\u304d\u3044\u30c7\u30fc\u30bf\u3092\u524a\u9664\uff080.51498\uff09\\\n21.20\u304b\u3089\u3001Area=5000\u306a\u306e\u306bPrice\u304c10000\u4ee5\u4e0b\u306e\uff12\u3064\u306e\u30c7\u30fc\u30bf\u3092\u524a\u9664 \uff080.51448\uff09\\\n22.21\u306ePrice\u95be\u5024\u309250000\u306b\u5909\u66f4\uff080.51414\uff09\\\n23.22\u3067submit\u3057\u305f\u3089\u7d50\u679c\u60aa\u5316\u306b\u3064\u304d\u300120\u306b\u623b\u308b\u3002\u305d\u3057\u3066\u3001TotalFloorArea\u304cNaN\u306e\u5834\u5408\u306f\u3001Area\u306e\u5024\u3092\u5165\u529b\u3059\u308b\uff080.5186\uff09\\\n24.20\u306en_fold\u30925\u219210\u306b\u5909\u66f4\uff080.51401\uff09\\\n26.24\u306b\u623b\u308b\u3002Clasification\u306e\u660e\u3089\u304b\u306b\u304a\u304b\u3057\u3044Road\u3092NaN\u306b\u3059\u308b\u3002MaxTimeToNearestStation\u304c\u7a7a\u6b04\u306e\u5834\u5408\u306fMinTimeToNearestStation\u306e\u5024\u3092\u4ee3\u5165\uff080.51352\uff09\\\n27.26\u306en_fold\u309210\u21925\u306b\uff080.51467\uff09\\\n28.26\u3067Area vs TradePrice\u306e\u5916\u308c\u5024\u30923\u70b9\u524a\u9664(0.51399)\\\n29.27\u308228\u308220\u306b\u52a3\u308b\u3002\u5916\u308c\u5024\u524a\u9664\u3092\u53d6\u308a\u6d88\u3057\u3002TradePrice\u5927\u304d\u3044\u30c7\u30fc\u30bf\u306e\u524a\u9664\u3082\u53d6\u308a\u6d88\u3057\uff080.51700\uff09\u3002\\\n30.29\u304b\u3089y_train\u304c11000000000\u3088\u308a\u5927\u304d\u3044\u30c7\u30fc\u30bf\u3092\u524a\u9664\uff080.51668\uff09\\\n31.30\u306bTradePrice\u304c400000000\u4ee5\u4e0a\u306e\u30c7\u30fc\u30bf\u3067\u5272\u5408\u306b\u504f\u308a\u306e\u3042\u308b\u5909\u6570\u306b\u95a2\u3057\u3001\u30d5\u30e9\u30b0\u3092\u8a2d\u5b9a\uff080.51668\uff09\\\n32.31\u306ey_train\u524a\u9664\u306e\u95be\u5024\u309220\u306b\u5408\u308f\u305b\u30661000000000\u306b\u3059\u308b\uff080.51437\uff09\\\n33.31\u304b\u308915000000000\u4ee5\u4e0a\u306ey_train\u524a\u9664\u3067\u3001CV\u3092GroupKFold\u306b\u3057\u3066\u3001Municipality\u3054\u3068\u306b\u30b0\u30eb\u30fc\u30d7\u5206\u3051\uff080.57438\uff09\\\n34.33\u306e\u30b0\u30eb\u30fc\u30d7\u5206\u3051\u3092DistrictName\u3054\u3068\u306b\u5909\u66f4\uff080.52758\uff09\\\n35.33\u306eTotalFloorArea\u3092Area\u95a2\u4fc2\u306e\u5909\u6570\u304b\u3089lightgbm\u3067\u4e88\u6e2c\u3057\u3001\u4e88\u6e2c\u5024\u3067\u57cb\u3081\u308b\uff080.52889\uff09\\\n36.35\u3067CV\u3092n=5\u304b\u3089n=10\u306b\uff080.52671\uff09 ### sub=0.56796\\\n37.36\u3067CV\u3092n=5\u306b\u623b\u3057\u3001Area_x_CoverageRatio_x_FloorAreaRatio\u3092\u7279\u5fb4\u91cf\u306b\u8ffd\u52a0\uff080.52898\uff09\\\n38.","0b879cc9":"from sklearn.model_selection import train_test_split\nX_train_valid, X_test_, y_train_valid, y_test_ = train_test_split(X_train, y_train, test_size=0.2, random_state=100)\nX_train, X_valid, y_train, y_valid = train_test_split(X_train_valid, y_train_valid, test_size=0.2, random_state=100)","ef5c88fd":"# Municipality\u3068\u770c\u5e81\u6240\u5728\u5730\u306e\u8ddd\u96e2\u3092\u8ffd\u52a0\ndf_all_Tokyo = df_all[df_all[\"Prefecture\"] == \"Tokyo\"]\ndf_all_Kanagawa = df_all[df_all[\"Prefecture\"] == \"Kanagawa Prefecture\"]\ndf_all_Chiba = df_all[df_all[\"Prefecture\"] == \"Chiba Prefecture\"]\ndf_all_Ibaraki = df_all[df_all[\"Prefecture\"] == \"Ibaraki Prefecture\"]\ndf_all_Tochigi = df_all[df_all[\"Prefecture\"] == \"Tochigi Prefecture\"]\ndf_all_Gunma = df_all[df_all[\"Prefecture\"] == \"Gunma Prefecture\"]\ndf_all_Saitama = df_all[df_all[\"Prefecture\"] == \"Saitama Prefecture\"]\n\n#\u770c\u5e81\u6240\u5728\u5730\u306e\u7def\u5ea6\u7d4c\u5ea6\u3092\u8868\u793a\ndf_all_Saitama[df_all_Saitama[\"Municipality\"]==\"Urawa Ward,Saitama City\"].head(2)","78692167":"# 10) Region","30b69663":"# \u30b9\u30bf\u30c3\u30ad\u30f3\u30b0-all + highprice + lowprice","e00d227d":"# LightGBM-\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u8abf\u6574","3324db4d":"from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\nX_all = pd.concat([X_train, X_test], axis=0)\n\n# distance_Ward\/Station \u306finf\u3092\u542b\u3080\u305f\u3081\u3001NMF\u7528\u306b\u306f\u524a\u9664\nX_all = X_all.drop([\"distance_Ward\/Station\"], axis=1)\n\nsc = StandardScaler()\nX_all_sc = sc.fit_transform(X_all)\n\npca = PCA()\nfeature = pca.fit(X_all_sc)\n# \u30c7\u30fc\u30bf\u3092\u4e3b\u6210\u5206\u7a7a\u9593\u306b\u5199\u50cf\nfeature = pca.transform(X_all_sc)\n\n# \u4e3b\u6210\u5206\u5f97\u70b9\npd.DataFrame(feature)\n\n#\u4e3b\u6210\u5206\u5f97\u70b9\u306b\u5217\u540d\u3092\u4ed8\u4e0e\nX_all_PC = pd.DataFrame(feature, columns=[\"PC{}\".format(x + 1) for x in range(len(pd.DataFrame(feature).columns))])\nX_all_PC","10412d23":"# 7) LandShape","e67652a5":"# \u5b66\u7fd2-HistGradientBoostingRegressor","193d85c4":"# \u5efa\u307a\u3044\u7387\u3001\u5bb9\u7a4d\u7387\u306e\u95a2\u4fc2\u304b\u3089\u3001TotalFloorArea\u3092\u8a08\u7b97\ndf_all[\"calcTotalFloorArea\"] = df_all['TotalFloorArea'].fillna(df_all['FloorAreaRatio'] \/ df_all['CoverageRatio'] * df_all['Area'])\n\n# TotalFloorArea\u304c\u7a7a\u6b04\u306e\u5834\u5408\u306f\u3001Area\u306e\u5024\u3092\u5165\u529b\ndf_all[\"replacedTotalFloorArea\"] = df_all['TotalFloorArea'].fillna(df_all['Area'])\n\n# \u4ee3\u66ffTotalFloorArea\u3068Area\u306e\u5dee\n#df_all[\"replacedTotalFloorArea-Area\"] = df_all[\"replacedTotalFloorArea\"] - df_all[\"Area\"]\n\n# \u4ee3\u66ffTotalFloorArea\u3068Area\u306e\u6bd4\n#df_all[\"replacedTotalFloorArea\/Area\"] = df_all[\"replacedTotalFloorArea\"] \/ df_all[\"Area\"]\n\n# \u4e88\u6e2cTotalFloorArea\u3068Area\u306e\u5dee\ndf_all[\"pred_TotalFloorArea-Area\"] = df_all[\"pred_TotalFloorArea\"] - df_all[\"Area\"]\n\n# \u4e88\u6e2cTotalFloorArea\u3068Area\u306e\u6bd4\ndf_all[\"pred_TotalFloorArea\/Area\"] = df_all[\"pred_TotalFloorArea\"] \/ df_all[\"Area\"]\n\n# TotalFloorArea\u306e\u7a7a\u6b04\u90e8\u306bFlag\n#df_all[\"TotalFloorAreaFlag\"] = df_all['TotalFloorArea'].apply(lambda x: 1 if x == \"NaN\" else 0)\n\n# Area \/ Frontage\ndf_all[\"Area\/Frontage\"] = df_all[\"Area\"] \/ df_all[\"Frontage\"]","3fb70a23":"# 6) Use","28f513fb":"n_fold = 5\ncv = KFold(n_splits=n_fold)\n\ny_pred_train = np.zeros(len(X_train))\ny_pred_test = np.zeros(len(X_test))\nscores = []\n\nfor i, (train_index, val_index) in enumerate(cv.split(X_train, y_train)):\n    X_train_, y_train_ = X_train.iloc[train_index], y_train.iloc[train_index]\n    X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]\n    \n    model_2 = lgb.LGBMRegressor(feature_pre_filter = False,\n                                lambda_l1 = 0.005928667844410908,\n                                lambda_l2 = 4.613191133280647e-05,\n                                num_leaves = 88,\n                                feature_fraction = 0.652,\n                                bagging_fraction = 1.0,\n                                bagging_freq = 0,\n                                min_child_samples =50)\n    model_2.fit(X_train_, np.log1p(y_train_))\n    y_pred_val = np.expm1(model_2.predict(X_val))\n    y_pred_test += np.expm1(model_2.predict(X_test))\/n_fold\n    \n    y_pred_train[val_index] = y_pred_val\n    score = mean_squared_log_error(y_val, y_pred_val)**0.5\n    scores.append(score)\n    \n    print(\"Fold%d RMSLE: %f\"%(i, score))\n    \nprint(\"Overall RMSLE: %f\u00b1%f\"%(np.mean(scores), np.std(scores)))","c817a7ac":"y_train_low = df_train_too_low.TradePrice\nX_train_low = df_train_too_low.drop([\"TradePrice\"], axis = 1)\n\ndf_train_too_low.shape, X_train_low.shape, y_train_low.shape","fbd5b46b":"# Kyoto\/ Osaka Prefectural Road, Hokkaido Prefectural Road \u306f\u95a2\u6771\u306b\u306f\u306a\u3044\u306e\u3067NaN\u306b\n\ndf_all.Classification.replace([\"Kyoto\/ Osaka Prefectural Road\", \"Hokkaido Prefectural Road\"], np.nan, inplace=True)\ngrouped_Classification = df_all.groupby('Classification')['TradePrice'].mean() \ngrouped_Classification.sort_values()","b40cc5cc":"df_all[\"Renovation\"] = df_all[\"Renovation\"].fillna(\"NaN\")\ngrouped_Renovation_Area_all = df_all.groupby('Renovation')['Area'].mean() \n\n# Renovation \u3092 Area\u306e\u5e73\u5747\u5024\u3067TargetEncoding\ndf_all['Renovation'] = df_all.Renovation.map(grouped_Renovation_Area_all)\ndf_all","c260c5b6":"# \u7d2f\u7a4d\u5bc4\u4e0e\u7387\u3092\u56f3\u793a\u3059\u308b\nimport matplotlib.ticker as ticker\nplt.gca().get_xaxis().set_major_locator(ticker.MaxNLocator(integer=True))\nplt.plot([0] + list( np.cumsum(pca.explained_variance_ratio_)), \"-o\")\nplt.xlabel(\"Number of principal components\")\nplt.ylabel(\"Cumulative contribution rate\")\nplt.grid()\nplt.show()","84dd2f60":"from sklearn.linear_model import LinearRegression\n# \u30b9\u30bf\u30c3\u30ad\u30f3\u30b0\u306b\u3088\u308b\u4e88\u6e2c\n\n# \u7b2c1\u6bb5\u968e\u306e\u4e88\u6e2c\u5024(\u3053\u306e\u5f8c\u3001\u30e1\u30bf\u30e2\u30c7\u30eb\u306e\u5165\u529b\u306b\u4f7f\u7528)\nfirst_pred_1 = np.expm1(first_model_1.predict(X_valid))\nfirst_pred_2 = np.expm1(first_model_2.predict(X_valid))\nfirst_pred_3 = np.expm1(first_model_3.predict(X_valid))\n\n#\u7b2c1\u6bb5\u968e\u306e\u4e88\u6e2c\u5024\u3092\u7a4d\u307f\u91cd\u306d\u308b\nstack_pred = np.column_stack((first_pred_1, first_pred_2, first_pred_3))\n\n# \u30e1\u30bf\u30e2\u30c7\u30eb\u306e\u5b66\u7fd2 \nmeta_model = PLSRegression(n_components=2)\nmeta_model.fit(stack_pred, y_valid)\n\n# \u5404\u30e2\u30c7\u30eb\u306e\u691c\u8a3c\u30c7\u30fc\u30bf\u3092\u7a4d\u307f\u91cd\u306d\u308b\nstack_test_pred = np.column_stack((test_pred_1, test_pred_2, test_pred_3))\n\n# \u30b9\u30bf\u30c3\u30ad\u30f3\u30b0\u306e\u691c\u8a3c\nmeta_test_pred = meta_model.predict(stack_test_pred)\nprint (\"\u30e1\u30bf\u30e2\u30c7\u30eb\u306eRMSE: {:.4f}\".format(mean_squared_log_error(y_test_, meta_test_pred)**0.5))","90e9102d":"# \u30b9\u30bf\u30c3\u30ad\u30f3\u30b0-LightGBM + HistGradient + catboost","5ffa4677":"# 5) Direction","5deba1fb":"# LightGBM\u30cf\u30a4\u30d1\u30e9\u8abf\u6574\uff0brandom seed average","0a288cef":"plt.scatter(y_train_low, y_pred_train_low)\nmax_y = np.max(np.array([np.array(y_train_low), y_pred_train_low]))\nmin_y = np.min(np.array([np.array(y_train_low), y_pred_train_low]))\nplt.plot([min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y)],\n         [min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y)], 'k-')\nplt.ylim(min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y))\nplt.xlim(min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y))\nplt.xlabel('y_train_low')\nplt.ylabel('y_pred_train_low')\n\nplt.show()","cbcec857":"# \u30ab\u30c6\u30b4\u30ea\u30fc\u5909\u6570\u304b\u3064\u6b20\u640d\u5024\u304c\u3042\u308b\u7279\u5fb4\u91cf\u3092\u78ba\u8a8d\n# 1)CityPlanning","b9c48c76":"df_all_Tokyo[\"distance_Maincity_Municipality\"] = np.sqrt((df_all_Tokyo[\"Latitude_Station\"]-Latitude_City_Tokyo)**2 + (df_all[\"Longitude_Station\"]-Longitude_City_Tokyo)**2)\ndf_all_Kanagawa[\"distance_Maincity_Municipality\"] = np.sqrt((df_all_Kanagawa[\"Latitude_Station\"]-Latitude_City_Kanagawa)**2 + (df_all_Kanagawa[\"Longitude_Station\"]-Longitude_City_Kanagawa)**2)\ndf_all_Chiba[\"distance_Maincity_Municipality\"] = np.sqrt((df_all_Chiba[\"Latitude_Station\"]-Latitude_City_Chiba)**2 + (df_all_Chiba[\"Longitude_Station\"]-Longitude_City_Chiba)**2)\ndf_all_Ibaraki[\"distance_Maincity_Municipality\"] = np.sqrt((df_all_Ibaraki[\"Latitude_Station\"]-Latitude_City_Ibaraki)**2 + (df_all_Ibaraki[\"Longitude_Station\"]-Longitude_City_Ibaraki)**2)\ndf_all_Tochigi[\"distance_Maincity_Municipality\"] = np.sqrt((df_all_Tochigi[\"Latitude_Station\"]-Latitude_City_Tochigi)**2 + (df_all_Tochigi[\"Longitude_Station\"]-Longitude_City_Tochigi)**2)\ndf_all_Gunma[\"distance_Maincity_Municipality\"] = np.sqrt((df_all_Gunma[\"Latitude_Station\"]-Latitude_City_Gunma)**2 + (df_all_Gunma[\"Longitude_Station\"]-Longitude_City_Gunma)**2)\ndf_all_Saitama[\"distance_Maincity_Municipality\"] = np.sqrt((df_all_Saitama[\"Latitude_Station\"]-Latitude_City_Saitama)**2 + (df_all_Saitama[\"Longitude_Station\"]-Longitude_City_Saitama)**2)\n\ndf_all = pd.concat([df_all_Tokyo, df_all_Kanagawa, df_all_Chiba, df_all_Ibaraki, df_all_Tochigi, df_all_Gunma, df_all_Saitama], axis = 0)\ndf_all.sort_index()\n\ndf_all","a0121f11":"# \u5b66\u7fd2-Stacking\u7528-low price\u9818\u57df\u306e\u307f\u306e\u30e2\u30c7\u30eb","44fba10a":"# 2) Renovation","8874503b":"df_all_Tokyo.NearestStation.value_counts().head()","6d9ef5ff":"X_all_PC_80 = X_all_PC.iloc[:, :6]\n\nindex_trrain = X_train.index\nindex_test = X_test.index\n\nX_all = pd.concat([X_all, X_all_PC_80], axis = 1)\n\nX_all = X_all.drop([\"PC1\", \"PC2\", \"PC3\", \"PC5\", \"PC6\"], axis=1)\n\nX_test = X_all.loc[index_test]\nX_train = X_all.loc[index_train]\n\nX_train","0d7402e3":"n_fold = 5\ncv = KFold(n_splits=n_fold)\n\ny_pred_train_low = np.zeros(len(X_train_low))\ny_pred_test_low = np.zeros(len(X_test))\nscores = []\n\nfor i, (train_index, val_index) in enumerate(cv.split(X_train_low, y_train_low)):\n    X_train_, y_train_ = X_train_low.iloc[train_index], y_train_low.iloc[train_index]\n    X_val, y_val = X_train_low.iloc[val_index], y_train_low.iloc[val_index]\n    \n    model_low = lgb.LGBMRegressor(n_estimators=300, \n                                max_depth=6, \n                                random_state=71, \n                                subsample=0.8, \n                                colsample_bytree=0.8, \n                                min_child_weight=1,\n                                )\n    model_low.fit(X_train_, y_train_)\n    y_pred_val = model_low.predict(X_val)\n    y_pred_test += model_low.predict(X_test)\/n_fold\n    \n    y_pred_train_low[val_index] = y_pred_val\n    score = mean_squared_log_error(y_val, y_pred_val)**0.5\n    scores.append(score)\n    \n    print(\"Fold%d RMSLE: %f\"%(i, score))\n    \nprint(\"Overall RMSLE: %f\u00b1%f\"%(np.mean(scores), np.std(scores)))","dc2e8b49":"n_fold = 5\ncv = KFold(n_splits=n_fold)\n\ny_pred_train = np.zeros(len(X_train))\ny_pred_test = np.zeros(len(X_test))\nscores = []\n\nfor i, (train_index, val_index) in enumerate(cv.split(X_train, y_train)):\n    X_train_, y_train_ = X_train.iloc[train_index], y_train.iloc[train_index]\n    X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]\n    \n    model = HistGradientBoostingRegressor(learning_rate=0.05, random_state=71, max_iter=500)\n    model.fit(X_train_, np.log1p(y_train_))\n    y_pred_val = np.expm1(model.predict(X_val))\n    y_pred_test += np.expm1(model.predict(X_test))\/n_fold\n    \n    y_pred_train[val_index] = y_pred_val\n    score = mean_squared_log_error(y_val, y_pred_val)**0.5\n    scores.append(score)\n    \n    print(\"Fold%d RMSLE: %f\"%(i, score))\n    \nprint(\"Overall RMSLE: %f\u00b1%f\"%(np.mean(scores), np.std(scores)))","b379d082":"plt.scatter(y_train_high, y_pred_train_high)\nmax_y = np.max(np.array([np.array(y_train_high), y_pred_train_high]))\nmin_y = np.min(np.array([np.array(y_train_high), y_pred_train_high]))\nplt.plot([min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y)],\n         [min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y)], 'k-')\nplt.ylim(min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y))\nplt.xlim(min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y))\nplt.xlabel('y_train_high')\nplt.ylabel('y_pred_train_high')\n\nplt.show()","20b594f3":"from sklearn.cross_decomposition import PLSRegression\nfrom catboost import CatBoostRegressor, FeaturesData, Pool\n# \u7b2c1\u6bb5\u968e\u306e\u30e2\u30c7\u30eb\u4f5c\u6210\n\nfirst_model_1 = model_2\nfirst_model_2 = HistGradientBoostingRegressor(learning_rate=0.05, random_state=71, max_iter=500)\nfirst_model_3 = CatBoostRegressor(iterations=2000, learning_rate=0.05, depth=5)\n\nfirst_model_1.fit(X_train, np.log1p(y_train))\nfirst_model_2.fit(X_train, np.log1p(y_train))\nfirst_model_3.fit(X_train, np.log1p(y_train))\n\n# \u7d50\u679c\u306e\u691c\u8a3c \ntest_pred_1 = np.expm1(first_model_1.predict(X_test_))\ntest_pred_2 = np.expm1(first_model_2.predict(X_test_))\ntest_pred_3 = np.expm1(first_model_3.predict(X_test_))\n\n#\u3000\u5404\u30e2\u30c7\u30eb\u500b\u5225\u306e\u4e88\u6e2c\u7cbe\u5ea6\u3092\u5e73\u5747\u4e8c\u4e57\u8aa4\u5dee\u3067\u78ba\u8a8d\nprint (\"\u30e2\u30c7\u30eb1\u306eRMSLE: {:.4f}\".format(mean_squared_log_error(y_test_, test_pred_1)**0.5))\nprint (\"\u30e2\u30c7\u30eb2\u306eRMSLE: {:.4f}\".format(mean_squared_log_error(y_test_, test_pred_2)**0.5))\nprint (\"\u30e2\u30c7\u30eb3\u306eRMSLE: {:.4f}\".format(mean_squared_log_error(y_test_, test_pred_3)**0.5))","9b49c8c5":"# PCA\u306e\u4e3b\u6210\u5206\u3092\u7279\u5fb4\u91cf\u306b","fb73d50c":"df_all[\"CityPlanning_x_Region\"] = df_all[\"CityPlanning\"] * df_all[\"Region\"]\ndf_all[\"CityPlanning_x_Classification\"] = df_all[\"CityPlanning\"] * df_all[\"Classification\"]\n#df_all[\"Classification_x_Region\"] = df_all[\"Classification\"] * df_all[\"Region\"]\n#df_all[\"Purpose_x_Region\"] = df_all[\"Purpose\"] * df_all[\"Region\"]\ndf_all[\"CityPlanning_x_Purpose\"] = df_all[\"CityPlanning\"] * df_all[\"Purpose\"]\n#df_all[\"Classification_x_Purpose\"] = df_all[\"Classification\"] * df_all[\"Purpose\"]\n\ndf_all.head()","041a6ac4":"n_fold = 5\ncv = KFold(n_splits=n_fold)\n\ny_pred_train = np.zeros(len(X_train))\ny_pred_test = np.zeros(len(X_test))\nscores = []\n\nfor i, (train_index, val_index) in enumerate(cv.split(X_train, y_train)):\n    X_train_, y_train_ = X_train.iloc[train_index], y_train.iloc[train_index]\n    X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]\n    \n    model_2 = lgb.LGBMRegressor(n_estimators=300,#300 \n                                max_depth=6, #6\n                                random_state=71, \n                                subsample=0.8,#0.8 \n                                colsample_bytree=0.8, #0.8 \n                                min_child_weight=1,\n                                )\n    model_2.fit(X_train_, np.log1p(y_train_))\n    y_pred_val = np.expm1(model_2.predict(X_val))\n    y_pred_test += np.expm1(model_2.predict(X_test))\/n_fold\n    \n    y_pred_train[val_index] = y_pred_val\n    score = mean_squared_log_error(y_val, y_pred_val)**0.5\n    scores.append(score)\n    \n    print(\"Fold%d RMSLE: %f\"%(i, score))\n    \nprint(\"Overall RMSLE: %f\u00b1%f\"%(np.mean(scores), np.std(scores)))","dea2a1a7":"n_fold = 5\ncv = KFold(n_splits=n_fold)\n\ny_pred_train_high = np.zeros(len(X_train_high))\ny_pred_test_high = np.zeros(len(X_test))\nscores = []\n\nfor i, (train_index, val_index) in enumerate(cv.split(X_train_high, y_train_high)):\n    X_train_, y_train_ = X_train_high.iloc[train_index], y_train_high.iloc[train_index]\n    X_val, y_val = X_train_high.iloc[val_index], y_train_high.iloc[val_index]\n    \n    model_high = lgb.LGBMRegressor(n_estimators=300, \n                                max_depth=6, \n                                random_state=71, \n                                subsample=0.8, \n                                colsample_bytree=0.8, \n                                min_child_weight=1,\n                                )\n    model_high.fit(X_train_, np.log1p(y_train_))\n    y_pred_val = np.expm1(model_high.predict(X_val))\n    y_pred_test += np.expm1(model_high.predict(X_test))\/n_fold\n    \n    y_pred_train_high[val_index] = y_pred_val\n    score = mean_squared_log_error(y_val, y_pred_val)**0.5\n    scores.append(score)\n    \n    print(\"Fold%d RMSLE: %f\"%(i, score))\n    \nprint(\"Overall RMSLE: %f\u00b1%f\"%(np.mean(scores), np.std(scores)))","b3f4bb7f":"plt.scatter(np.log1p(y_train_low), np.log1p(y_pred_train_low))\nmax_y = np.max(np.array([np.array(np.log1p(y_train_low)), np.log1p(y_pred_train_low)]))\nmin_y = np.min(np.array([np.array(np.log1p(y_train_low)), np.log1p(y_pred_train_low)]))\nplt.plot([min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y)],\n         [min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y)], 'k-')\nplt.ylim(min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y))\nplt.xlim(min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y))\nplt.xlabel('log(y_train_low+1)')\nplt.ylabel('log(y_pred_train_low+1)')\nplt.show()","73ca9c86":"from sklearn.ensemble import VotingRegressor\n\nn_fold = 5\ncv = KFold(n_splits=n_fold)\n\ny_pred_train = np.zeros(len(X_train))\ny_pred_test = np.zeros(len(X_test))\nscores = []\n\nfor i, (train_index, val_index) in enumerate(cv.split(X_train, y_train)):\n    X_train_, y_train_ = X_train.iloc[train_index], y_train.iloc[train_index]\n    X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]\n    \n    # random seed average\n    model1 = lgb.LGBMRegressor(n_estimators=300, \n                                max_depth=6, \n                                random_state=1, \n                                subsample=0.8, \n                                colsample_bytree=0.8, \n                                min_child_weight=1,\n                                feature_pre_filter = False,\n                                lambda_l1 = 7.317782441373365,\n                                lambda_l2 = 5.676015378886587e-06,\n                                num_leaves = 111,\n                                feature_fraction = 0.6,\n                                bagging_fraction = 1.0,\n                                bagging_freq = 0,\n                                min_child_samples =20)\n    model2 = lgb.LGBMRegressor(n_estimators=300, \n                                max_depth=6, \n                                random_state=71, \n                                subsample=0.8, \n                                colsample_bytree=0.8, \n                                min_child_weight=1,\n                                feature_pre_filter = False,\n                                lambda_l1 = 7.317782441373365,\n                                lambda_l2 = 5.676015378886587e-06,\n                                num_leaves = 111,\n                                feature_fraction = 0.6,\n                                bagging_fraction = 1.0,\n                                bagging_freq = 0,\n                                min_child_samples =20)\n    model3 = lgb.LGBMRegressor(n_estimators=300, \n                                max_depth=6, \n                                random_state=141, \n                                subsample=0.8, \n                                colsample_bytree=0.8, \n                                min_child_weight=1,\n                                feature_pre_filter = False,\n                                lambda_l1 = 7.317782441373365,\n                                lambda_l2 = 5.676015378886587e-06,\n                                num_leaves = 111,\n                                feature_fraction = 0.6,\n                                bagging_fraction = 1.0,\n                                bagging_freq = 0,\n                                min_child_samples =20)\n    model4 = lgb.LGBMRegressor(n_estimators=300, \n                                max_depth=6, \n                                random_state=211, \n                                subsample=0.8, \n                                colsample_bytree=0.8, \n                                min_child_weight=1,\n                                feature_pre_filter = False,\n                                lambda_l1 = 7.317782441373365,\n                                lambda_l2 = 5.676015378886587e-06,\n                                num_leaves = 111,\n                                feature_fraction = 0.6,\n                                bagging_fraction = 1.0,\n                                bagging_freq = 0,\n                                min_child_samples =20)\n    ereg = VotingRegressor(estimators=[('m1', model1), ('m2', model2), ('m3', model3), ('m4', model4)])\n    ereg.fit(X_train_, np.log1p(y_train_))\n    y_pred_val = np.expm1(ereg.predict(X_val))\n    y_pred_test += np.expm1(ereg.predict(X_test))\/n_fold\n    \n    y_pred_train[val_index] = y_pred_val\n    score = mean_squared_log_error(y_val, y_pred_val)**0.5\n    scores.append(score)\n    \n    print(\"Fold%d RMSLE: %f\"%(i, score))\n    \nprint(\"Overall RMSLE: %f\u00b1%f\"%(np.mean(scores), np.std(scores)))","12ceb563":"plt.figure(figsize=(10, 17))\nbar = sns.barplot(x=\"importance\", y=\"feature\", data=feature)\nbar.axes.set_xlim(-0.00000000015,0.0000000018)\nbar","3b2ee236":"# **TradePrice\u304c\u4f4e\u3044\u9818\u57df\u306e\u7279\u5fb4\u91cf\u306e\u78ba\u8a8d**","251b0547":"# train\u3068test\u306b\u5206\u5272","108f0e62":"plt.scatter(np.log1p(y_train), np.log1p(y_pred_train))\nmax_y = np.max(np.array([np.array(np.log1p(y_train)), np.log1p(y_pred_train)]))\nmin_y = np.min(np.array([np.array(np.log1p(y_train)), np.log1p(y_pred_train)]))\nplt.plot([min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y)],\n         [min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y)], 'k-')\nplt.ylim(min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y))\nplt.xlim(min_y - 0.05 * (max_y - min_y), max_y + 0.05 * (max_y - min_y))\nplt.xlabel('log(y_train+1)')\nplt.ylabel('log(y_pred_train+1)')\nplt.show()"}}