{"cell_type":{"55b465e7":"code","a2e5a2e8":"code","0bbede98":"code","04d59ae7":"code","c2e7ea6c":"code","12fc675d":"code","0abb1629":"code","df6c4ee6":"code","577b0566":"code","3c5644f3":"code","a8e968c0":"code","839ae139":"code","822b2eca":"code","e6aac424":"code","6389188b":"code","f545b49a":"code","bfeec98d":"code","ba5cbdc1":"code","3a8ad79c":"code","f195e2f7":"code","230b9ca6":"code","b38f1cda":"code","5eec15e2":"code","7e4e312b":"code","37324a44":"code","2458612f":"code","04f43f4b":"code","50ca347a":"code","56e7faeb":"code","9389cda1":"code","7fdd881c":"code","08636f6b":"code","15e9a664":"code","a5c022a3":"code","c04fa496":"code","b68aab88":"code","5a2d72a0":"code","f0e9869f":"code","5a035db6":"code","415de6e9":"markdown","bad0e5be":"markdown","4cc67c35":"markdown","ac259ebc":"markdown","e69542c0":"markdown","3c9a8f7a":"markdown","057cd98f":"markdown","e4920bbb":"markdown","10816d87":"markdown","3cdb11b3":"markdown","55ac9e64":"markdown","0801d588":"markdown","59149474":"markdown","7549de42":"markdown","5b200d12":"markdown","7cb15403":"markdown","67e2cfca":"markdown"},"source":{"55b465e7":"!pip install colorednoise > \/dev\/null","a2e5a2e8":"import librosa\nimport librosa.display\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom pathlib import Path\nfrom IPython.display import Audio","0bbede98":"DATA_DIR = Path(\"..\/input\/rfcx-species-audio-detection\/train\")","04d59ae7":"flacfiles = list(DATA_DIR.glob(\"*.flac\"))\ny, sr = librosa.load(flacfiles[0], duration=10)\ny, sr","c2e7ea6c":"Audio(y, rate=sr)","12fc675d":"librosa.display.waveplot(y, sr=sr);","0abb1629":"melspec = librosa.power_to_db(librosa.feature.melspectrogram(y, sr=sr, n_mels=128))\nlibrosa.display.specshow(melspec, sr=sr, x_axis=\"time\", y_axis=\"mel\")\nplt.colorbar();","df6c4ee6":"class AudioTransform:\n    def __init__(self, always_apply=False, p=0.5):\n        self.always_apply = always_apply\n        self.p = p\n\n    def __call__(self, y: np.ndarray):\n        if self.always_apply:\n            return self.apply(y)\n        else:\n            if np.random.rand() < self.p:\n                return self.apply(y)\n            else:\n                return y\n\n    def apply(self, y: np.ndarray):\n        raise NotImplementedError\n\n\nclass Compose:\n    def __init__(self, transforms: list):\n        self.transforms = transforms\n\n    def __call__(self, y: np.ndarray):\n        for trns in self.transforms:\n            y = trns(y)\n        return y\n\n\nclass OneOf:\n    def __init__(self, transforms: list):\n        self.transforms = transforms\n\n    def __call__(self, y: np.ndarray):\n        n_trns = len(self.transforms)\n        trns_idx = np.random.choice(n_trns)\n        trns = self.transforms[trns_idx]\n        return trns(y)","577b0566":"class AddGaussianNoise(AudioTransform):\n    def __init__(self, always_apply=False, p=0.5, max_noise_amplitude=0.5, **kwargs):\n        super().__init__(always_apply, p)\n\n        self.noise_amplitude = (0.0, max_noise_amplitude)\n\n    def apply(self, y: np.ndarray, **params):\n        noise_amplitude = np.random.uniform(*self.noise_amplitude)\n        noise = np.random.randn(len(y))\n        augmented = (y + noise * noise_amplitude).astype(y.dtype)\n        return augmented","3c5644f3":"transform = AddGaussianNoise(always_apply=True, max_noise_amplitude=0.05)\ny_gaussian_added = transform(y)\nAudio(y_gaussian_added, rate=sr)","a8e968c0":"librosa.display.waveplot(y_gaussian_added, sr=sr);","839ae139":"melspec = librosa.power_to_db(librosa.feature.melspectrogram(y_gaussian_added, sr=sr, n_mels=128))\nlibrosa.display.specshow(melspec, sr=sr, x_axis=\"time\", y_axis=\"mel\")\nplt.colorbar();","822b2eca":"class GaussianNoiseSNR(AudioTransform):\n    def __init__(self, always_apply=False, p=0.5, min_snr=5.0, max_snr=20.0, **kwargs):\n        super().__init__(always_apply, p)\n\n        self.min_snr = min_snr\n        self.max_snr = max_snr\n\n    def apply(self, y: np.ndarray, **params):\n        snr = np.random.uniform(self.min_snr, self.max_snr)\n        a_signal = np.sqrt(y ** 2).max()\n        a_noise = a_signal \/ (10 ** (snr \/ 20))\n\n        white_noise = np.random.randn(len(y))\n        a_white = np.sqrt(white_noise ** 2).max()\n        augmented = (y + white_noise * 1 \/ a_white * a_noise).astype(y.dtype)\n        return augmented","e6aac424":"transform = GaussianNoiseSNR(always_apply=True, min_snr=5, max_snr=20)\ny_gaussian_snr = transform(y)\nAudio(y_gaussian_snr, rate=sr)","6389188b":"librosa.display.waveplot(y_gaussian_snr, sr=sr);","f545b49a":"melspec = librosa.power_to_db(librosa.feature.melspectrogram(y_gaussian_snr, sr=sr, n_mels=128))\nlibrosa.display.specshow(melspec, sr=sr, x_axis=\"time\", y_axis=\"mel\")\nplt.colorbar();","bfeec98d":"import colorednoise as cn\n\n\nclass PinkNoiseSNR(AudioTransform):\n    def __init__(self, always_apply=False, p=0.5, min_snr=5.0, max_snr=20.0, **kwargs):\n        super().__init__(always_apply, p)\n\n        self.min_snr = min_snr\n        self.max_snr = max_snr\n\n    def apply(self, y: np.ndarray, **params):\n        snr = np.random.uniform(self.min_snr, self.max_snr)\n        a_signal = np.sqrt(y ** 2).max()\n        a_noise = a_signal \/ (10 ** (snr \/ 20))\n\n        pink_noise = cn.powerlaw_psd_gaussian(1, len(y))\n        a_pink = np.sqrt(pink_noise ** 2).max()\n        augmented = (y + pink_noise * 1 \/ a_pink * a_noise).astype(y.dtype)\n        return augmented","ba5cbdc1":"transform = PinkNoiseSNR(always_apply=True, min_snr=5.0, max_snr=20.0)\ny_pink_noise = transform(y)\nAudio(y_pink_noise, rate=sr)","3a8ad79c":"librosa.display.waveplot(y_pink_noise, sr=sr);","f195e2f7":"melspec = librosa.power_to_db(librosa.feature.melspectrogram(y_pink_noise, sr=sr, n_mels=128))\nlibrosa.display.specshow(melspec, sr=sr, x_axis=\"time\", y_axis=\"mel\")\nplt.colorbar();","230b9ca6":"class PitchShift(AudioTransform):\n    def __init__(self, always_apply=False, p=0.5, max_steps=5, sr=32000):\n        super().__init__(always_apply, p)\n\n        self.max_steps = max_steps\n        self.sr = sr\n\n    def apply(self, y: np.ndarray, **params):\n        n_steps = np.random.randint(-self.max_steps, self.max_steps)\n        augmented = librosa.effects.pitch_shift(y, sr=self.sr, n_steps=n_steps)\n        return augmented","b38f1cda":"transform = PitchShift(always_apply=True, max_steps=5, sr=sr)\ny_pitch_shift = transform(y)\nAudio(y_pitch_shift, rate=sr)","5eec15e2":"librosa.display.waveplot(y_pitch_shift, sr=sr);","7e4e312b":"melspec = librosa.power_to_db(librosa.feature.melspectrogram(y_pitch_shift, sr=sr, n_mels=128))\nlibrosa.display.specshow(melspec, sr=sr, x_axis=\"time\", y_axis=\"mel\")\nplt.colorbar();","37324a44":"class TimeStretch(AudioTransform):\n    def __init__(self, always_apply=False, p=0.5, max_rate=1.2):\n        super().__init__(always_apply, p)\n\n        self.max_rate = max_rate\n\n    def apply(self, y: np.ndarray, **params):\n        rate = np.random.uniform(0, self.max_rate)\n        augmented = librosa.effects.time_stretch(y, rate)\n        return augmented","2458612f":"transform = TimeStretch(always_apply=True, max_rate=2.0)\ny_time_stretch = transform(y)\nAudio(y_time_stretch, rate=sr)","04f43f4b":"librosa.display.waveplot(y_time_stretch, sr=sr);","50ca347a":"melspec = librosa.power_to_db(librosa.feature.melspectrogram(y_time_stretch, sr=sr, n_mels=128))\nlibrosa.display.specshow(melspec, sr=sr, x_axis=\"time\", y_axis=\"mel\")\nplt.colorbar();","56e7faeb":"class TimeShift(AudioTransform):\n    def __init__(self, always_apply=False, p=0.5, max_shift_second=2, sr=32000, padding_mode=\"replace\"):\n        super().__init__(always_apply, p)\n    \n        assert padding_mode in [\"replace\", \"zero\"], \"`padding_mode` must be either 'replace' or 'zero'\"\n        self.max_shift_second = max_shift_second\n        self.sr = sr\n        self.padding_mode = padding_mode\n\n    def apply(self, y: np.ndarray, **params):\n        shift = np.random.randint(-self.sr * self.max_shift_second, self.sr * self.max_shift_second)\n        augmented = np.roll(y, shift)\n        if self.padding_mode == \"zero\":\n            if shift > 0:\n                augmented[:shift] = 0\n            else:\n                augmented[shift:] = 0\n        return augmented","9389cda1":"transform = TimeShift(always_apply=True, max_shift_second=4, sr=sr)\ny_time_shifted = transform(y)\nAudio(y_time_shifted, rate=sr)","7fdd881c":"librosa.display.waveplot(y_time_shifted, sr=sr);","08636f6b":"melspec = librosa.power_to_db(librosa.feature.melspectrogram(y_time_shifted, sr=sr, n_mels=128))\nlibrosa.display.specshow(melspec, sr=sr, x_axis=\"time\", y_axis=\"mel\")\nplt.colorbar();","15e9a664":"class VolumeControl(AudioTransform):\n    def __init__(self, always_apply=False, p=0.5, db_limit=10, mode=\"uniform\"):\n        super().__init__(always_apply, p)\n\n        assert mode in [\"uniform\", \"fade\", \"fade\", \"cosine\", \"sine\"], \\\n            \"`mode` must be one of 'uniform', 'fade', 'cosine', 'sine'\"\n\n        self.db_limit= db_limit\n        self.mode = mode\n\n    def apply(self, y: np.ndarray, **params):\n        db = np.random.uniform(-self.db_limit, self.db_limit)\n        if self.mode == \"uniform\":\n            db_translated = 10 ** (db \/ 20)\n        elif self.mode == \"fade\":\n            lin = np.arange(len(y))[::-1] \/ (len(y) - 1)\n            db_translated = 10 ** (db * lin \/ 20)\n        elif self.mode == \"cosine\":\n            cosine = np.cos(np.arange(len(y)) \/ len(y) * np.pi * 2)\n            db_translated = 10 ** (db * cosine \/ 20)\n        else:\n            sine = np.sin(np.arange(len(y)) \/ len(y) * np.pi * 2)\n            db_translated = 10 ** (db * sine \/ 20)\n        augmented = y * db_translated\n        return augmented","a5c022a3":"transform = VolumeControl(always_apply=True, mode=\"sine\")\ny_volume_controlled = transform(y)\nAudio(y_volume_controlled, rate=sr)","c04fa496":"librosa.display.waveplot(y_volume_controlled, sr=sr);","b68aab88":"melspec = librosa.power_to_db(librosa.feature.melspectrogram(y_volume_controlled, sr=sr, n_mels=128))\nlibrosa.display.specshow(melspec, sr=sr, x_axis=\"time\", y_axis=\"mel\")\nplt.colorbar();","5a2d72a0":"transform = Compose([\n  OneOf([\n    GaussianNoiseSNR(min_snr=10),\n    PinkNoiseSNR(min_snr=10)\n  ]),\n  PitchShift(max_steps=2, sr=sr),\n  TimeStretch(),\n  TimeShift(sr=sr),\n  VolumeControl(mode=\"sine\")\n])\ny_composed = transform(y)\nAudio(y_composed, rate=sr)","f0e9869f":"librosa.display.waveplot(y_composed, sr=sr);","5a035db6":"melspec = librosa.power_to_db(librosa.feature.melspectrogram(y_composed, sr=sr, n_mels=128))\nlibrosa.display.specshow(melspec, sr=sr, x_axis=\"time\", y_axis=\"mel\")\nplt.colorbar();","415de6e9":"## More to come. Stay tuned!","bad0e5be":"\u30b9\u30da\u30af\u30c8\u30ed\u30b0\u30e9\u30e0\u3092\u898b\u308b\u3068\u308f\u304b\u308a\u3084\u3059\u3044\u306e\u3067\u3059\u304c\u3001\u5168\u4f53\u306b\u6563\u3089\u3057\u305f\u3088\u3046\u306b\u30ce\u30a4\u30ba\u304c\u52a0\u308f\u3063\u3066\u3044\u308b\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3059\u3002Gaussian Noise\u3092\u52a0\u3048\u308b\u3053\u3068\u3067\u30ce\u30a4\u30ba\u304c\u6bd4\u8f03\u7684\u5c11\u306a\u3044\u30c7\u30fc\u30bf\u3067\u5b66\u7fd2\u3057\u3066\u3001\u30ce\u30a4\u30ba\u304c\u591a\u3044\u74b0\u5883\u306e\u97f3\u3092\u51e6\u7406\u3057\u306a\u3051\u308c\u3070\u3044\u3051\u306a\u3044\u5834\u5408\u306a\u3069\u306b\u6c4e\u5316\u6027\u80fd\u3092\u3042\u3052\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002","4cc67c35":"### PitchShift\n\nPitchShift\u306f\u97f3\u306e\u30d4\u30c3\u30c1(\u9ad8\u4f4e)\u306b\u95a2\u3059\u308b\u8abf\u6574\u3092\u65bd\u3059Data Augmentation\u3067\u3001\u52b9\u679c\u3068\u3057\u3066\u805e\u3053\u3048\u308b\u97f3\u304c\u9ad8\u304f\/\u4f4e\u304f\u306a\u308a\u307e\u3059\u3002\u30e1\u30eb\u30b9\u30da\u30af\u30c8\u30ed\u30b0\u30e9\u30e0\u4e0a\u3067\u306f\u3001\u30d1\u30bf\u30fc\u30f3\u306e\u3042\u308b\u5468\u6ce2\u6570\u5e2f\u304c\u4e0a\u307e\u305f\u306f\u4e0b\u306b\u30ba\u30ec\u307e\u3059\u3002\n\nPitchShift\u306f\u30ea\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3092\u884c\u3046\u305f\u3081\u4eca\u307e\u3067\u7d39\u4ecb\u3057\u305fData Augmentation\u3068\u6bd4\u3079\u308b\u3068\u6642\u9593\u304c\u304b\u304b\u308b\u307b\u304b\u3001\u30d4\u30c3\u30c1\u3092\u5909\u3048\u3059\u304e\u308b\u3068\u97f3\u5272\u308c\u3092\u8d77\u3053\u3057\u3066\u3057\u307e\u3046\u3053\u3068\u3082\u3042\u308b\u305f\u3081\u6ce8\u610f\u304c\u5fc5\u8981\u3067\u3059\u3002\n\n\u53c2\u8003\u30fb\u51fa\u5178: [librosa.effects.pitch_shift](http:\/\/man.hubwiz.com\/docset\/LibROSA.docset\/Contents\/Resources\/Documents\/generated\/librosa.effects.pitch_shift.html)\n\nPitchShift is a data augmentation that adjusts the pitch of the sound (high and low), making the sound heard as an effect higher\/lower. On the Meru spectrogram, certain frequency bands in the pattern will be shifted up or down.\n\nPitchShift takes more time than the previously introduced Data Augmentation because of resampling, and you should be careful not to change the pitch too much because it may cause the sound to crack.\n\nReference: [librosa.effects.pitch_shift](http:\/\/man.hubwiz.com\/docset\/LibROSA.docset\/Contents\/Resources\/Documents\/generated\/librosa.effects.pitch_shift.html)","ac259ebc":"### TimeStretch\n\nTimeStretch\u306f\u5143\u306e\u97f3\u3092\u6642\u9593\u7684\u306b\u5f15\u304d\u5ef6\u3070\u3057\u305f\u308a\u5727\u7e2e\u3057\u305f\u308a\u3057\u307e\u3059\u3002\u7d50\u679c\u3068\u3057\u3066\u97f3\u306e\u30b9\u30d4\u30fc\u30c9\u304c\u901f\u304f\u306a\u3063\u305f\u308a\u9045\u304f\u306a\u3063\u305f\u308a\u3057\u307e\u3059\u3002\n\nTimeStretch\u3082\u6642\u9593\u304c\u304b\u304b\u308bData Augmentation\u3067\u3059\u3002\n\n\u53c2\u8003\u30fb\u51fa\u5178: [librosa.effects.time_stretch](http:\/\/man.hubwiz.com\/docset\/LibROSA.docset\/Contents\/Resources\/Documents\/generated\/librosa.effects.time_stretch.html)\n\nTimeStretch stretches and compresses the original sound in time. As a result, the speed of the sound may be increased or decreased.\n\nTimeStretch is another time-consuming form of data augmentation.\n\nReference: [librosa.effects.time_stretch](http:\/\/man.hubwiz.com\/docset\/LibROSA.docset\/Contents\/Resources\/Documents\/generated\/librosa.effects.time_stretch.html)","e69542c0":"Data Augmentations for audio is quite different from those for images. There are two types of augmentations:\n\n1. Augmentations for waveform\n2. Augmentations for spectrogram\/melspectrogram\n\nAugmentation for waveform is applied to raw 1D signal, and changes how it sounds like, so we can check how it alters the signal by listening it.\nOn the other hand, augmentation for spectrogram is something similar to image augmentation. However, spectrogram has some big differences from natural image.\nOne of the biggest difference is that it has axis - time axis and frequency axis. Applying augmentations that ignores this axis (Flip, Rotation, etc...) is nonsense.","3c9a8f7a":"\u97f3\u306e\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u3080\u3053\u3068\u304c\u3067\u304d\u307e\u3057\u305f\u3002\u4eca\u56de\u306f\u3053\u306e\u30c7\u30fc\u30bf\u306b\u69d8\u3005\u306aData Augmentation\u3092\u304b\u3051\u3066\u305d\u306e\u7d50\u679c\u3092\u5b9f\u969b\u306b\u805e\u3044\u305f\u308a\u898b\u305f\u308a\u3057\u306a\u304c\u3089\u5404Data Augmentation\u306e\u52b9\u679c\u3092\u78ba\u8a8d\u3057\u3066\u3044\u304d\u307e\u3059\u3002\n\n\u307e\u305a\u306f\u5143\u306e\u97f3\u30c7\u30fc\u30bf\u3092\u78ba\u8a8d\u3057\u3066\u307f\u307e\u3057\u3087\u3046\u3002\n\nNow we've loaded audio data. In this notebook, we'll apply several Data Augmentations and check the result by listening or visually watching it.","057cd98f":"## [WIP] \u30b9\u30da\u30af\u30c8\u30ed\u30b0\u30e9\u30e0\/\u30e1\u30eb\u30b9\u30da\u30af\u30c8\u30ed\u30b0\u30e9\u30e0\u306b\u5bfe\u3059\u308bData Augmentation(Data Augmentation for waveform)\n\nWork in progress...","e4920bbb":"### AddGaussianNoise\n\n\u6b63\u898f\u5206\u5e03\u306b\u5f93\u3046\u30ce\u30a4\u30ba\u3001\u3044\u308f\u3086\u308b\u30db\u30ef\u30a4\u30c8\u30ce\u30a4\u30ba\u3092\u97f3\u306b\u52a0\u3048\u307e\u3059\u3002\u30ce\u30a4\u30ba\u306e\u632f\u5e45\u306f\u30e9\u30f3\u30c0\u30e0\u3067\u3059\u3002\n\n\u53c2\u8003\u30fb\u51fa\u5178: [Data Augmentation for Audio](https:\/\/medium.com\/@makcedward\/data-augmentation-for-audio-76912b01fdf6)\u306e`NoiseInjection`\u3088\u308a\n\nAdd noise that follows normal distribution (a.k.a whitenoise). The amplitude of noise is randomly decided.\n\nReference: [Data Augmentation for Audio](https:\/\/medium.com\/@makcedward\/data-augmentation-for-audio-76912b01fdf6)","10816d87":"## Data Loading\n\n\n","3cdb11b3":"### \u7d44\u307f\u5408\u308f\u305b\u3066\u4f7f\u3046 (Combination)","55ac9e64":"### VolumeControl\n\nVolumeControl\u306f\u97f3\u91cf\u3092\u8abf\u7bc0\u3057\u307e\u3059\u3002\u97f3\u306e\u8a8d\u8b58\u306b\u306f\u97f3\u91cf\u305d\u306e\u3082\u306e\u3088\u308aSNR\u304c\u5f71\u97ff\u3059\u308b\u3068\u3044\u3046\u8a71\u3092\u4ee5\u524d\u7d39\u4ecb\u3057\u305f\u304b\u3068\u601d\u3044\u307e\u3059\u304c\u3001\u97f3\u91cf\u3092\u8abf\u7bc0\u3059\u308b\u3053\u3068\u3067\u30e1\u30eb\u30b9\u30da\u30af\u30c8\u30ed\u30b0\u30e9\u30e0\u306b\u306f\u3054\u304f\u50c5\u304b\u306a\u5909\u5316\u304c\u751f\u3058\u307e\u3059\u3002\u307e\u305f\u3001\u97f3\u91cf\u3092\u30b5\u30a4\u30f3\u66f2\u7dda\u3001\u30b3\u30b5\u30a4\u30f3\u66f2\u7dda\u306a\u3069\u306b\u5408\u308f\u305b\u3066\u8abf\u7bc0\u3059\u308b\u3001\u306a\u3069\u306f\u30e1\u30eb\u30b9\u30da\u30af\u30c8\u30ed\u30b0\u30e9\u30e0\u306b\u306f\u5927\u304d\u306a\u5909\u5316\u3092\u3082\u305f\u3089\u3059\u305f\u3081\u6709\u7528\u3067\u3059\u3002\n\nVolumeControl controls the volume. I think I mentioned before that the SNR has more influence on sound perception than the volume itself, but adjusting the volume causes a very small change in the mel spectrogram. Adjusting the volume according to a sine curve, cosine curve, etc. is also useful because it causes a big change in the mel spectrogram.","0801d588":"## \u97f3\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308bData Augmentation (Data Augmentation for waveform)\n\n\u307e\u305a\u306f\u3001\u97f3\u306e\u4e00\u6b21\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308bData Augmentation\u3092\u7d39\u4ecb\u3057\u307e\u3059\u3002\u3053\u3053\u3067\u306f\u5b9f\u969b\u306b\u5b9f\u88c5\u3057\u306a\u304c\u3089\u4ee5\u4e0b\u306eaugmentation\u3092\u7d39\u4ecb\u3057\u307e\u3059\u3002\n\n1. AddGaussianNoise\n2. GaussianNoiseSNR\n3. PinkNoiseSNR\n4. PitchShift\n5. TimeStretch\n6. TimeShift\n7. VolumeControl\n\n\u306a\u304a\u3001\u5b9f\u88c5\u306f[albumentations](https:\/\/github.com\/albumentations-team\/albumentations)\u3092\u53c2\u8003\u306b\u3057\u3066\u3044\u307e\u3059\u3002albumentations\u306e\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u3092\u7d99\u627f\u3057\u3066\u4f5c\u6210\u3092\u3059\u308b\u3053\u3068\u3082\u3067\u304d\u308b\u306e\u3067\u3059\u304c\u82e5\u5e72\u624b\u9593\u304c\u591a\u3044\u305f\u3081\u81ea\u524d\u5b9f\u88c5\u3067\u6e08\u307e\u305b\u307e\u3059\u3002\n\nHere, I'll introduce some Data Augmentation methods for raw waveform.\n\n1. AddGaussianNoise\n2. GaussianNoiseSNR\n3. PinkNoiseSNR\n4. PitchShift\n5. TimeStretch\n6. TimeShift\n7. VolumeControl\n\nI imitated the implementation of [albumentations](https:\/\/github.com\/albumentations-team\/albumentations).","59149474":"### TimeShift\n\nTimeShift\u306f\u6642\u9593\u7684\u306b\u97f3\u30a4\u30d9\u30f3\u30c8\u3092\u305a\u3089\u3059\u3088\u3046\u306a\u64cd\u4f5c\u3067\u3059\u3002\u30ba\u30e9\u3057\u305f\u7d50\u679c\u3001\u5143\u306e\u97f3\u30af\u30ea\u30c3\u30d7\u306e\u9577\u3055\u304b\u3089\u306f\u307f\u51fa\u3057\u305f\u90e8\u5206\u306e\u6271\u3044\u306b\u95a2\u3057\u3066\u306f\u3001\u524d(\u307e\u305f\u306f\u5f8c\u308d)\u306b\u6301\u3063\u3066\u3044\u3063\u3066\u304f\u3063\u3064\u3051\u308b\u3001\u7121\u8996\u3057\u3066\u6368\u3066\u3066\u3057\u307e\u3046\u3001\u306a\u3069\u306e\u3084\u308a\u65b9\u304c\u3042\u308a\u307e\u3059\u3002\n\n\u53c2\u8003\u30fb\u51fa\u5178: [Data Augmentation for Audio](https:\/\/medium.com\/@makcedward\/data-augmentation-for-audio-76912b01fdf6)\n\nTimeShift is such an operation that shifts a sound event in time. As for dealing with the part of the sound clip that goes out of the original length as a result of shifting, you can bring it forward (or backward) and stick it to the front (or backward), or ignore it and throw it away.\n\nReference: [Data Augmentation for Audio](https:\/\/medium.com\/@makcedward\/data-augmentation-for-audio-76912b01fdf6)","7549de42":"\u97f3\u306e\u30c7\u30fc\u30bf\u306b\u9069\u7528\u3067\u304d\u308bData Augmentation\u306f\u753b\u50cf\u306e\u3082\u306e\u3068\u306f\u5927\u304d\u304f\u7570\u306a\u308a\u307e\u3059\u3002\u97f3\u306e\u30c7\u30fc\u30bf\u306b\u306f\u5927\u304d\u304f\u5206\u3051\u3066\u4ee5\u4e0b\u306e\u4e8c\u7a2e\u985e\u306eData Augmentation\u304c\u5b58\u5728\u3057\u307e\u3059\u3002\n\n1. \u5143\u306e\u97f3\u30c7\u30fc\u30bf(1\u6b21\u5143\u306e\u72b6\u614b)\u306b\u5bfe\u3057\u3066\u9069\u7528\u3055\u308c\u308bData Augmentaion (Data Augmentation for waveform)\n2. \u30b9\u30da\u30af\u30c8\u30ed\u30b0\u30e9\u30e0\u3084\u30e1\u30eb\u30b9\u30da\u30af\u30c8\u30ed\u30b0\u30e9\u30e0\u306b\u5bfe\u3057\u3066\u9069\u7528\u3055\u308c\u308bData Augmentation (Data Augmentation for spectrogram)\n\n\u5143\u306e\u97f3\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u9069\u7528\u3055\u308c\u308bData Augmentation\u306f\u97f3\u306e\u805e\u3053\u3048\u65b9\u81ea\u4f53\u3092\u5909\u5316\u3055\u305b\u308b\u3082\u306e\u304c\u591a\u304f\u753b\u50cf\u306e\u3082\u306e\u3068\u306f\u5927\u304d\u304f\u7570\u306a\u308a\u307e\u3059\u3002\n\n\u4e00\u65b9\u30b9\u30da\u30af\u30c8\u30ed\u30b0\u30e9\u30e0\u306b\u5bfe\u3057\u3066\u9069\u7528\u3055\u308c\u308b\u3082\u306e\u306f\u753b\u50cf\u306b\u5bfe\u3059\u308bData Augmentation\u306b\u4f3c\u3066\u3044\u307e\u3059\u304c\u3001\u4e00\u3064\u5927\u304d\u304f\u7570\u306a\u308b\u70b9\u3068\u3057\u3066\u3001\u30b9\u30da\u30af\u30c8\u30ed\u30b0\u30e9\u30e0\u306b\u306f\u660e\u78ba\u306b\u8ef8\u304c\u3042\u308b\u3068\u3044\u3046\u70b9\u3092\u7121\u8996\u3057\u3066Data Augmentation\u3092\u304b\u3051\u308b\u3053\u3068\u306b\u306f\u610f\u5473\u304c\u3042\u308a\u307e\u305b\u3093\u3002\u8ef8\u3068\u3044\u3046\u306e\u306f\u3001\u30b9\u30da\u30af\u30c8\u30ed\u30b0\u30e9\u30e0\u306ex\u8ef8\u306f\u6642\u9593\u3001y\u8ef8\u306f\u5468\u6ce2\u6570\u306e\u8ef8\u3067\u3042\u308b\u3068\u3044\u3046\u3053\u3068\u3067\u3053\u3053\u306f\u660e\u78ba\u306b\u81ea\u7136\u753b\u50cf\u3068\u306f\u7570\u306a\u308a\u307e\u3059\u3002\u5f93\u3063\u3066\u5358\u7d14\u306bFlip\u3057\u305f\u308a\u56de\u8ee2\u3092\u304b\u3051\u308b\u3053\u3068\u306f\u610f\u5473\u304c\u306a\u3044\u3069\u3053\u308d\u304b\u6709\u5bb3\u3067\u3059\u3002","5b200d12":"### PinkNoiseSNR\n\nGaussian Noise\u306f\u3044\u308f\u3086\u308b\u767d\u8272\u96d1\u97f3(white noise)\u3067\u5168\u5468\u6ce2\u6570\u5e2f\u306b\u30ce\u30a4\u30ba\u3092\u304b\u3051\u308b\u3082\u306e\u3067\u3057\u305f\u3002\u3053\u3053\u3067\u7d39\u4ecb\u3059\u308bPink Noise\u306f\u4f4e\u5468\u6ce2\u6570\u5e2f\u304b\u3089\u4f4e\u5468\u6ce2\u6570\u5e2f\u306b\u304b\u3051\u3066\u5f90\u3005\u306b\u30ce\u30a4\u30ba\u306e\u5f37\u3055\u304c\u6e1b\u5c11\u3059\u308b\u3088\u3046\u306a\u30ce\u30a4\u30ba\u306e\u3053\u3068\u3092\u3055\u3057\u307e\u3059\u3002\u81ea\u7136\u754c\u306b\u5b58\u5728\u3059\u308b\u30ce\u30a4\u30ba\u306f\u3053\u306e\u3088\u3046\u306a\u30ce\u30a4\u30ba\u3067\u3042\u308b\u3068\u3055\u308c\u307e\u3059\u3002\n\n\u306a\u304a\u3001\u767d\u8272\u96d1\u97f3\u4ee5\u5916\u306e\u30ce\u30a4\u30ba\u306fcolored noise\u3068\u547c\u3070\u308c\u3001\u4ed6\u306b\u306f\u30d6\u30e9\u30a6\u30f3\u30ce\u30a4\u30ba\u3001\u30d6\u30eb\u30fc\u30ce\u30a4\u30ba\u306a\u3069\u69d8\u3005\u306a\u30ce\u30a4\u30ba\u304c\u63d0\u6848\u3055\u308c\u3066\u3044\u307e\u3059\u3002\n\nPink Noise\u3092\u767a\u751f\u3055\u305b\u308b\u305f\u3081\u306b`colorednoise`\u3068\u3044\u3046\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u7528\u3044\u308b\u306e\u3067\u3059\u304c\u305d\u306e\u540d\u524d\u306e\u7531\u6765\u306f\u4e0a\u8a18\u306e\u3088\u3046\u306a\u3082\u306e\u306b\u306a\u308a\u307e\u3059\u3002\n\n\u306a\u304a\u3001\u767d\u8272\u96d1\u97f3\u306e\u6642\u306f\u6700\u521d\u306b\u5f37\u3055\u3092\u76f4\u63a5\u6307\u5b9a\u3059\u308b\u3088\u3046\u306a\u5b9f\u88c5\u3092\u7d39\u4ecb\u3057\u307e\u3057\u305f\u304c\u3001\u4eca\u56de\u306f\u3044\u304d\u306a\u308a\u5f37\u3055\u3092SNR\u30d9\u30fc\u30b9\u3067\u9069\u5fdc\u7684\u306b\u6c7a\u5b9a\u3067\u304d\u308b\u5b9f\u88c5\u3092\u7d39\u4ecb\u3057\u307e\u3059\u3002\n\n\u53c2\u8003\u30fb\u51fa\u5178: [Wikipedia \u30ab\u30e9\u30fc\u30c9\u30ce\u30a4\u30ba](https:\/\/ja.wikipedia.org\/wiki\/%E3%82%AB%E3%83%A9%E3%83%BC%E3%83%89%E3%83%8E%E3%82%A4%E3%82%BA#:~:text=%E3%82%AB%E3%83%A9%E3%83%BC%E3%83%89%E3%83%8E%E3%82%A4%E3%82%BA%EF%BC%88%E8%8B%B1%3A%20colors%20of,%E3%81%9D%E3%81%AE%E7%89%B9%E6%80%A7%E3%82%82%E5%A4%A7%E3%81%8D%E3%81%8F%E7%95%B0%E3%81%AA%E3%82%8B%E3%80%82), [`colorednoise`](https:\/\/github.com\/felixpatzelt\/colorednoise)\n\nGaussian Noise is a so-called white noise, which is a noise over the whole frequency range. Pink noise, which we introduce here, is noise with a gradual decrease in noise intensity from low frequency to low frequency bands. The noise in the natural world is said to be such noise.\n\nThe noise other than white noise is called \"colored noise\", and various noises such as brown noise and blue noise have been proposed.\n\nThe `colorednoise` library is used to generate pink noise, and its name comes from the above.\n\nIn the previous article, we introduced an implementation of white noise that directly specifies the intensity of the noise.\n\nReference: [Wikipedia Colors of noise](https:\/\/en.wikipedia.org\/wiki\/Colors_of_noise), [`colorednoise`](https:\/\/github.com\/felixpatzelt\/colorednoise)","7cb15403":"### GaussianNoiseSNR\n\n\u4e0a\u3067\u7d39\u4ecb\u3057\u305fData Augmentation\u306e\u554f\u984c\u70b9\u306f\u30ce\u30a4\u30ba\u306e\u5f37\u3055(amplitude)\u3092\u6307\u5b9a\u3057\u3066\u3057\u307e\u3046\u3068\u3001\u5143\u306e\u4fe1\u53f7\u304c\u5fae\u5f31\u306a\u3068\u304d\u306b\u96d1\u97f3\u306b\u8986\u3044\u96a0\u3055\u308c\u3066\u3057\u307e\u3046\u3053\u3068\u304c\u3042\u308a\u3046\u308b\u70b9\u3067\u3059\u3002\n\n\u3053\u308c\u3092\u9632\u3050\u305f\u3081\u306b\u5143\u306e\u97f3\u306e\u4e2d\u306e\u4fe1\u53f7\u306e\u632f\u5e45\u3092\u5143\u306b\u9069\u5207\u306a\u96d1\u97f3\u30ec\u30d9\u30eb\u3092\u9069\u5fdc\u7684\u306b\u8a2d\u5b9a\u3067\u304d\u308b\u3088\u3046\u306b\u3057\u305f\u307b\u3046\u304c\u4f7f\u3044\u3084\u3059\u3044\u3067\u3059\u3002\n\n\u4fe1\u53f7\u306e\u5927\u304d\u3055\u3068\u96d1\u97f3\u306e\u5927\u304d\u3055\u306e\u6bd4\u3092\u8868\u3057\u305f\u3082\u306e\u3092Signal-to-Noise Ratio(SNR)\u3068\u547c\u3073\u307e\u3059\u3002\u4fe1\u53f7\u306e\u5927\u304d\u3055\u3001\u3068\u3044\u3063\u305f\u5834\u5408\u306b\u306f\u632f\u5e45\u306e\u3053\u3068\u3092\u3055\u3059\u3053\u3068\u304c\u591a\u3044\u306e\u3067\u3059\u304c\u591a\u304f\u306e\u5834\u5408SNR\u306f\u5b9f\u969b\u306e\u632f\u5e45\u306e\u6bd4\u306b\u5bfe\u6570\u3092\u53d6\u3063\u305f\u3082\u306e\u3068\u3057\u3066\u8868\u73fe\u3055\u308c\u3001\u4ee5\u4e0b\u306e\u5f0f\u3067\u8a08\u7b97\u3055\u308c\u307e\u3059\u3002\n\n$$\nSNR = 20\\log_{10}\\frac{A_{signal}}{A_{noise}}\n$$\n\n\u3053\u306e\u91cf\u306f\u5927\u304d\u3051\u308c\u3070\u5927\u304d\u3044\u307b\u3069\u4fe1\u53f7\u304c\u5f37\u3044\u3001\u3059\u306a\u308f\u3061\u97f3\u304c\u805e\u3053\u3048\u3084\u3059\u3044\u3053\u3068\u3092\u8868\u3059\u91cf\u3067\u5358\u4f4d\u306fdB(\u30c7\u30b7\u30d9\u30eb)\u3067\u8868\u73fe\u3055\u308c\u307e\u3059\u30020dB\u3067\u4fe1\u53f7\u306e\u5f37\u3055\u3068\u96d1\u97f3\u306e\u5f37\u3055\u304c\u91e3\u308a\u5408\u3063\u3066\u3044\u308b\u72b6\u614b\u3067\u3001\u8ca0\u306e\u5834\u5408\u306b\u306f\u96d1\u97f3\u306e\u65b9\u304c\u5f37\u3044\u72b6\u614b\u3001\u6b63\u306e\u5834\u5408\u306b\u306f\u4fe1\u53f7\u306e\u65b9\u304c\u5f37\u3044\u72b6\u614b\u3067\u3059\u3002\n\n\u307e\u305f\u3001\u4fe1\u53f7\u97f3\u306e\u5f37\u3055\u306e\u63a8\u5b9a\u6cd5\u306f\u3044\u304f\u3064\u304b\u3042\u308b\u304b\u3068\u601d\u3044\u307e\u3059\u304c\u3001\u4eca\u56de\u306f\u30af\u30ea\u30c3\u30d7\u5185\u306e\u632f\u5e45\u306e\u7d76\u5bfe\u5024\u306e\u6700\u5927\u5024\u3092\u4fe1\u53f7\u306e\u632f\u5e45\u3068\u3057\u3066\u6271\u3044\u307e\u3059\u3002\n\n\u53c2\u8003\u30fb\u51fa\u5178: [\u4efb\u610f\u306eSignal-to-Noise\u6bd4\u306e\u97f3\u58f0\u6ce2\u5f62\u3092Python\u3067\u4f5c\u308d\u3046\uff01](https:\/\/engineering.linecorp.com\/ja\/blog\/voice-waveform-arbitrary-signal-to-noise-ratio-python\/)\u3088\u308a\n\nThe problem with Data Augmentation introduced above is that if you specify an amplitude of noise, it can be masked by noise when the original signal is weak.\n\nTo prevent this, it is easier to adaptively set an appropriate noise level based on the amplitude of the signal in the original sound.\n\nThe ratio of the signal-to-noise level is called Signal-to-Noise Ratio (SNR). The signal-to-noise ratio (SNR) is expressed as the ratio of the actual amplitude to the logarithm of the signal's amplitude and is calculated by the following formula.\n\n$$\nSNR = 20\\log_{10}\\frac{A_{signal}}{A_{noise}}\n$$\n\nThe larger this amount is, the stronger the signal, or the more audible the sound is, and it is expressed in dB (decibel), where 0dB means that the strength of the signal is balanced with the strength of the noise, when it is negative, the noise is stronger, and when it is positive, the signal is stronger.\n\nThere may be several ways to estimate the strength of the signal sound, but in this case we will treat the absolute maximum of the amplitude in the clip as the amplitude of the signal.\n\nReference: [\u4efb\u610f\u306eSignal-to-Noise\u6bd4\u306e\u97f3\u58f0\u6ce2\u5f62\u3092Python\u3067\u4f5c\u308d\u3046\uff01](https:\/\/engineering.linecorp.com\/ja\/blog\/voice-waveform-arbitrary-signal-to-noise-ratio-python\/) (Japanese)","67e2cfca":"## About\n\n\u3053\u306e\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u3067\u306f\u97f3\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308bData Augmentation\u3092\u7d39\u4ecb\u3057\u307e\u3059\u3002\u753b\u50cf\u540c\u69d8\u3001\u97f3\u306e\u30c7\u30fc\u30bf\u3082Data Augmentation\u306f\u6c4e\u5316\u6027\u80fd\u3092\u62c5\u4fdd\u3059\u308b\u4e0a\u3067\u5927\u304d\u306a\u5f79\u5272\u3092\u679c\u305f\u3057\u3066\u3044\u307e\u3059\u3002\n\nIn this notebook, I will introduce some basic Data Augmentation methods for audio. Similar in computer vision, Data Augmentation is quite effective for audio as well to make generalized model.\n\nMaybe you'll find some odd translation since I translated this from Japanese and in some part I just used the result of deepL..."}}