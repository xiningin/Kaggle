{"cell_type":{"1d7d5b5d":"code","6e8d8e01":"code","bd2d2e32":"code","e7dbf51f":"code","d9e08e49":"code","751b57c6":"code","2b634e66":"code","b50ba90d":"code","0be4b340":"code","0c6b2fe9":"code","5efd5690":"code","fe425f9c":"code","07838bc4":"code","e663fcb9":"code","5eda9539":"markdown","9ae12403":"markdown","0e262091":"markdown","c695e969":"markdown","c0dd913c":"markdown","853278a4":"markdown","45c6b643":"markdown","661d86e9":"markdown"},"source":{"1d7d5b5d":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport glob\nimport numpy as np # linear algebra\nimport pandas as pd \n\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport os\n\nfrom tensorflow.keras import preprocessing\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D,Dropout,Dense,Flatten,Conv2DTranspose,BatchNormalization,LeakyReLU,Reshape\n\nimport tensorflow as tf\nfrom tensorflow.keras.utils import plot_model","6e8d8e01":"# First I am creating an array containing all the full path names for each of the .jpg file\n# The purpose to crete this array is to be able to select only limited number of training_images to train from this array\n\nall_image_path = []\n\nfull_image_train_path = '..\/input\/celeba-dataset\/img_align_celeba\/img_align_celeba'\n# When running in Kaggle\n\n# full_image_train_path = \"..\/input\/img_align_celeba\/img_align_celeba\/\"\n# When running in Local Machine  \n\n# full_image_train_path = \"\/content\/gdrive\/MyDrive\/celeba-dataset\/img_align_celeba\/img_align_celeba\"  \n# When running in Colab with data in G-Drive\n\n# full_image_train_path =  \"\/content\/img_align_celeba\/img_align_celeba\/\"\n# For reading from Colab sesstion storage as g-drive is failing for large 200k files of CelebA\n\n# Now from this array \nfor path in os.listdir(full_image_train_path):\n  if '.jpg' in path:\n    all_image_path.append(os.path.join(full_image_train_path, path))\n    \nimage_path_50k = all_image_path[0:500]\n\nprint(len(image_path_50k))\n# print(image_path_50k)","bd2d2e32":"# Model Constants\nPLOTS_DPI = 150","e7dbf51f":"# Alternative way to build the numpy array for all the training images\n# For getting the list of training_images - I COULD REPLACE THE ABOVE os.listdir() with glob like below\n\n# full_image_train_path = \"..\/input\/img_align_celeba\/img_align_celeba\/*.*\"  \n\n# # But even the above got timed-out when connecting Colab with Google Drive by pulling the data residing in GDrive\n# # https:\/\/research.google.com\/colaboratory\/faq.html#drive-timeout\n\n# img_list = glob.glob(full_image_train_path)\n\n# # image_path_50k = all_image_path[0:500]\n# image_path_50k = img_list[0:500]\n\n# print(len(image_path_50k))","d9e08e49":"%%time\n\n''' croping size for the image to have only the face at centre is obtained \n\nImage.crop(box=None)\n\nReturns a rectangular region from this image. The box is a 4-tuple defining the left, upper, right, and lower pixel coordinate\n\n'''\n\n# For the Image.crop function argument box \u2013\n# which is the crop rectangle, as a (left, upper, right, lower)-tuple.\n# The crop method from the Image module takes four coordinates as input.\n# The right can also be represented as (left+width)\n# and lower can be represented as (upper+height).\ncropping_box = (30, 55, 150, 175) \n\n# To load an image from a file, we use the open() function in the Image module, passing it the path to the image.\ntraining_images = [np.array((Image.open(path).crop(cropping_box)).resize((64,64))) for path in image_path_50k]\n# print(training_images)\n\n''' [[[ 10,  10,  10],\n      [ 15,  15,  17],\n      ...\n      [187, 233, 233],\n      [188, 233, 234]]\n        \n'''\n\n\n'''\nNormalizing images to range in 0-1\n\nNeural networks process inputs, using small weight values, and inputs with large integer values can disrupt or slow down the learning process. As such it is good practice to normalize the pixel values so that each pixel value has a value between 0 and 1.\n\nA pixel value can change between 0-255; if an image is fully red, then the RGB value is (255,0,0), where red is denoted by 255 and green and blue are 0.\n\nnormalized = (x-min(x))\/(max(x)-min(x))\n\nAnd in this case the largest pixel value is 255.\n\nSo if the intensity of RGB is (0,0,0) then it will be a dark or black image, and again if the intensity of RGB is (255,255,255), the image will be white. \n'''\nfor i in range(len(training_images)):\n    training_images[i] = ((training_images[i] - training_images[i].min())\/(255 - training_images[i].min()))\n    \ntraining_images = np.array(training_images) \n# training_images is a 4-D array\n\n# print(training_images)\n''' [[[0.03921569 0.03921569 0.03921569]\n   [0.05882353 0.05882353 0.06666667]\n   ...\n   ...\n    [0.59349593 0.4796748  0.41463415]\n   [0.6504065  0.54471545 0.48780488]]]]\n'''\n\nprint(training_images.shape) # (500, 64, 64, 3)\n\n# print(np.min(training_images, axis=0))\n# print(np.max(training_images, axis=0))","751b57c6":"len(full_image_train_path)\n\nprint(training_images.shape)  ","2b634e66":"plt.figure(figsize=(10,10))\nfig,ax=plt.subplots(2,5)\nfig.suptitle(\"Real Images\")\nidx=8\n\nfor i in range(2):\n    for j in range(5):\n            ax[i,j].imshow(training_images[idx].reshape(64,64,3))            \n            idx+=6\n            \nplt.tight_layout()\nplt.show()","b50ba90d":"noise_shape = 100\n\n#  Generator will upsample our seed using convolutional transpose layers (upsampling layers)\ndef generator_model():\n  generator=Sequential()\n  \n  # Random noise to 4x4x512 image\n  generator.add(Dense(4*4*512, input_shape=[noise_shape]))\n  \n  #  Next, add a reshape layer to the network to reshape the tensor from the \n  # last layer to a tensor of a shape of (4, 4, 512):\n  generator.add(Reshape([4,4,512]))\n  generator.add(Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"))\n  # BatchNormalization is added to the model after the hidden layer, but before the activation, such as LeakyReLU.\n  generator.add(BatchNormalization())\n  generator.add(LeakyReLU(alpha=0.2))\n  \n  generator.add(Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"))\n  generator.add(LeakyReLU(alpha=0.2))\n  \n  generator.add(BatchNormalization())\n  generator.add(Conv2DTranspose(64, kernel_size=4, strides=2, padding=\"same\"))\n  generator.add(LeakyReLU(alpha=0.2))\n  generator.add(BatchNormalization())\n  generator.add(Conv2DTranspose(3, kernel_size=4, strides=2, padding=\"same\",\n                                  activation='sigmoid'))\n  return generator\n\ngenerator = generator_model()\ngenerator.summary()","0be4b340":"# First create a random noise \nnoise = tf.random.normal([1,100])\ngenerated_image = generator(noise, training=False)\n# print(generated_image)\nplt.imshow(generated_image[0, :, :, 0])\n\n# It is just plain noise. But, the fact that it can create an image from a random noise array proves the model's power.\n","0c6b2fe9":"def discriminator_model():\n  discriminator = Sequential()\n  discriminator.add(Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=[64,64, 3]))\n  discriminator.add(LeakyReLU(alpha=0.2))\n  discriminator.add(Dropout(0.4))\n  discriminator.add(Conv2D(64, (3,3), strides=(2, 2), padding='same'))\n  discriminator.add(BatchNormalization())\n  discriminator.add(LeakyReLU(alpha=0.2))  \n  discriminator.add(Dropout(0.4))\n  discriminator.add(Flatten())\n  discriminator.add(Dense(1, activation='sigmoid'))\n  return discriminator\n\ndiscriminator = discriminator_model()\n\ndiscriminator.summary()","5efd5690":"GAN =Sequential([generator,discriminator])\n\ndiscriminator.compile(optimizer='adam',loss='binary_crossentropy')\n\n# When we train this network, we don't want to train the discriminator network, \n# so make it non-trainable before we add it to the adversarial model.\ndiscriminator.trainable = False\n\nGAN.compile(optimizer='adam',loss='binary_crossentropy')\n\nGAN.layers\n\nGAN.summary()","fe425f9c":"training_images.shape[0]\/\/100","07838bc4":"epochs = 1\nbatch_size = 64\n\nloss_from_discriminator_model=[] # Array to collect loss for the discriminator model\n\nloss_from_generator_model=[] # Array to collect loss for generator model\n\nwith tf.device('\/gpu:0'):\n for epoch in range(epochs):\n    print(f\"Currently training on Epoch {epoch+1}\")\n    \n    # Loop over each batch in the dataset\n    for i in range(training_images.shape[0]\/\/batch_size):\n    # Benefits of Double Division Operator over Single Division Operator in Python\n    # The Double Division operator in Python returns the floor value for both integer and floating-point arguments after division.\n        \n        if (i)%100 == 0:\n            print(f\"\\tCurrently training on batch number {i} of {len(training_images)\/\/batch_size}\")\n        \n        #  Start by sampling a batch of noise vectors from a uniform distribution\n        # generator receives a random seed as input which is used to produce an image.\n        noise=np.random.uniform(-1,1,size=[batch_size, noise_shape])\n        \n        ''' Generate a batch of fake images using the generator network\n        \n        The difference between predict() and predict_on_batch() - lies in when you pass as x data that is larger than one batch.\n\n        predict() -  will go through all the data, batch by batch, predicting labels. It thus internally does the splitting in batches and feeding one batch at a time.\n\n        predict_on_batch() - on the other hand, assumes that the data you pass in is exactly one batch and thus feeds it to the network. It will not try to split it\n        \n        In summary, predict method has extra operations to ensure a collection of batches are processed right, whereas, predict_on_batch is a lightweight alternative to predict that should be used on a single batch.\n        '''\n        gen_image = generator.predict_on_batch(noise)\n        # We do this by first sampling some random noise from a random uniform distribution, \n        # then getting the generator\u2019s predictions on the noise. \n        # The noise variable is the code equivalent of the variable z, which we discussed earlier.\n        \n        # Now I am taking real x_train data\n        # by sampling a batch of real images from the set of all image\n        train_dataset = training_images[i*batch_size:(i+1)*batch_size]\n        \n        # Create Labels\n        # First training on real image\n        train_labels_real=np.ones(shape=(batch_size,1))\n        \n        discriminator.trainable = True\n        \n        #  Next, train the discriminator network on real images and real labels:\n        d_loss_real = discriminator.train_on_batch(train_dataset,train_labels_real)\n        \n        #Now training on fake image\n        train_labels_fake=np.zeros(shape=(batch_size,1))\n        \n        d_loss_fake = discriminator.train_on_batch(gen_image,train_labels_fake)\n        \n        # Creating variables to make ready the whole adversarial network\n        noise=np.random.uniform(-1,1,size=[batch_size,noise_shape])\n        \n        # Image Label vector that has all the values equal to 1\n        # To fool the Discriminator Network\n        train_label_fake_for_gen_training =np.ones(shape=(batch_size,1))\n        \n        discriminator.trainable = False\n        \n        ''' Now train the generator\n        To train the generator network, we have to train the adversarial model.\n        When we train the adversarial model, it trains the generator network only\n        but freezes the discriminator network. We won't train the discriminator\n        network, as we have already trained it.\n        '''\n        g_loss = GAN.train_on_batch(noise, train_label_fake_for_gen_training)\n        \n        ''' So what I am doing above in short is,\n        I train the adversarial model on the batch of noise vectors and real\n        labels. Here, real labels is a vector with all values equal to 1. \n        \n        I am also training the generator to fool the discriminator network. To do\n        this, I provide it with a vector that has all the values equal to 1. \n        \n        In this step, the generator will receive feedback from the generator\n        network and improve itself accordingly.\n        '''\n        \n        loss_from_discriminator_model.append(d_loss_real+d_loss_fake)\n        \n        loss_from_generator_model.append(g_loss)\n        \n    ''' There is a passive method to evaluate the training process. After every 50\n    epochs, generate fake images and manually check the quality of the images:\n    These images will help you to decide whether to continue the training or to\n    stop it early. Stop the training if quality of the generated high-resolution\n    images is good. Or continue the training until your model becomes good.\n\n    '''\n    if epoch % 50 == 0:\n        samples = 10\n        x_fake = generator.predict(np.random.normal(loc=0, scale=1, size=(samples,100)))\n\n        for k in range(samples):\n            plt.subplot(2, 5, k+1)\n            plt.imshow(x_fake[k].reshape(64,64,3))\n            plt.xticks([])\n            plt.yticks([])\n\n        \n        plt.tight_layout()\n        plt.show()\n    print('Epoch: %d,  Loss: D_real = %.3f, D_fake = %.3f,  G = %.3f' %   (epoch+1, d_loss_real, d_loss_fake, g_loss))        \n\nprint('Training completed with all epochs')","e663fcb9":"for i in range(5):\n  plt.figure(figsize=(7,7))   \nfor k in range(20):\n          noise=np.random.uniform(-1,1,size=[100,noise_shape])\n          im=generator.predict(noise) \n          plt.subplot(5, 4, k+1)\n          plt.imshow(im[k].reshape(64,64,3))\n          plt.xticks([])\n          plt.yticks([])\n \nplt.tight_layout()\nplt.show()","5eda9539":"# Final DCGAN Training\n\nTraining GANs is an art form itself, as incorrect hyperparameter settings lead to mode collapse. So play with different hyperparameters to obtain better results.\n\n### Final Training Architecture of a DCGAN\n\n1. Initially, both of the networks are naive and have random weights.\n\n2. The standard process to train a DCGAN network is to first train the discriminator on the batch of samples.\n\n3. To do this, we need fake samples as well as real samples. We already have the real samples, so we now\nneed to generate the fake samples.\n\n4. To generate fake samples, create a latent vector of a shape of (100,) over a uniform distribution. Feed\nthis latent vector to the untrained generator network. The generator network will generate fake samples\nthat we use to train our discriminator network. So the training loop begins with generator receiving a random seed as input. That seed is used to produce an image. \n\n5. Concatenate the real images and the fake images to create a new set of sample images. We also need to\ncreate an array of labels: label 1 for real images and label 0 for fake images.\n\n6. The discriminator is then used to classify real images (drawn from the training set) and fakes images (produced by the generator). \n\n7. The loss is calculated for each of these models\nIn the process defined below I am training the generator and discriminator simultaneously.\n\n## DCGAN is super sensitive\n\nHere, even when we only train a GAN to manipulate 1D data, we have to use multiple\ntechniques to ensure a stable training. A lot of things could go wrong in the training of\nGANs. For example, either a generator or a discriminator could overfit if one or the other\ndoes not converge. Sometimes, the generator only generates a handful of sample varieties.\nThis is called mode collapse. \n\nIt's important that the generator and discriminator do not overpower each other (e.g., that they train at a similar rate).\n\nAt the beginning of the training, the generated images will look like random noise. As training progresses, the generated images will look increasingly real just like original celeb-a images. After about 300 epochs, they resemble almost the original.\n\n### Since we are training two models at once, the discriminator and the generator, we can\u2019t rely on Keras\u2019 .fit function. Instead, we have to manually loop through each epoch and fit the models on batches.","9ae12403":"### Lets see how our generator is creating images from noise. Lets generate a sample image with the below code.","0e262091":"### Scaling images \n\nit is also recommended that real images used to train the discriminator are scaled so that their pixel values are in the range [-1,1]. This is so that the discriminator will always receive images as input, real and fake, that have pixel values in the same range.\n\nTypically, image data is loaded as a NumPy array such that pixel values are 8-bit unsigned integer (uint8) values in the range [0, 255].","c695e969":"# Transposed Convolutions\n\n![Imgur](https:\/\/imgur.com\/55ldJ7M.png)\n\nThe 2\u00d72 kernel produces a 2\u00d72 output when convolving over a 3\u00d73 image.\n\nBut I want to work in the opposite direction, i.e., to use a smaller input and to learn its larger representation, being the following:\n\n![Imgur](https:\/\/imgur.com\/er12xAe.png)\n\nThats where the Transposed convolutions in the Keras API comes to help.\n\nThe Conv2DTranspose layer learns a number of filters, similar to the regular Conv2D layer.\n\nRemember that the transpose layer simply swaps the backwards and forward pass, keeping the rest of the operations the same!\n\nAs the transposed convolution will also slide over the input, we must specify a kernel_size, as with the normal convolution. Similarly we got to specify strides, output_padding \n\n#  UpSampling2D vs Conv2DTranspose in Keras\n\nUpSampling2D is just a simple scaling up of the image by using nearest neighbour or bilinear upsampling, so nothing smart. Advantage is it's cheap.\n\nConv2DTranspose is a convolution operation whose kernel is learnt (just like normal conv2d operation) while training your model. Using Conv2DTranspose will also upsample its input but the key difference is the model should learn what is the best upsampling for the job.\n\n# Generator\n\n#### I use Leaky relu activations in the hidden layer neurons, and sigmoids for the output layers. Originally, ReLU was recommend for use in the generator model and LeakyReLU was recommended for use in the discriminator model, although more recently, the LeakyReLU is recommended in both models.\n\nThe generator consists of convolutional-transpose layers, batch normalization layers, and ReLU activations. The output will be a 3x64x64 RGB image.\n\n\n## Use of Batch Normalization\n\nBatch normalization standardizes the activations from a prior layer to have a zero mean and unit variance. This has the effect of stabilizing the training process.\n\nBatch normalization limits the amount by which updating the\nparameters in the previous layers can affect the distribution of\ninputs received by the current layer. This decreases any\nunwanted interdependence between parameters across layers,\nwhich helps speed up the network training process and\nincrease its robustness, especially when it comes to network\nparameter initialization.\n\n\nBatch normalization is used after the activation of convolution in the discriminator model\n\nand after transpose convolutional layers in generator model.\n\nIt is added to the model after the hidden layer, but before the activation, such as LeakyReLU.\n\n### For understanding parameters look at this blog\n\nhttps:\/\/towardsdatascience.com\/understand-transposed-convolutions-and-build-your-own-transposed-convolution-layer-from-scratch-4f5d97b2967\n","c0dd913c":"# DCGAN - Combining Generator and Discriminator\n\nThe combined model is stacked generator and discriminator\n\n## Setting discriminator.trainable to False.\n\nWhy would we want to do this?\n\nWell, we aren\u2019t going to be training the generator model directly \u2014 we are going to be combining the generator and discriminator into a single model, then training that. This allows the generator to understand the discriminator so it can update itself more effectively.\n\nSetting discriminator.trainable to False will only affect the copy of the discriminator in the combined model. This is good! If the copy of the discriminator in the combined model were trainable, it would update itself to be worse at classifying images.\n\nTo combine the generator and discriminator, we will be calling the discriminator on the output of the generator.\n\n","853278a4":"\n### Special Note - Due to Out-of-memory limits in Kaggle, I could NOT run this Notebook inside Kaggle with any larger dataset than 1000 images. Hence the resultant fake images generated at the end will almost be like noise. But this Notebook is mostly written as a Tutorial to show the flow of DCGAN.\n\n---\n\n## [Link to my Youtube Video Explaining this whole Notebook](https:\/\/youtu.be\/csQj1e6Oj38)\n\n[![Imgur](https:\/\/imgur.com\/8ogHDeZ.png)](https:\/\/youtu.be\/csQj1e6Oj38)\n\n# Facial Attribute prediction\n\nFacial Attribute prediction is a Computer Vision (CV) task about deducing the set of attributes belonging to a face. Example attributes are the color of hair, hairstyle, age, gender, etc.\n\nFacial attribute analysis has received considerable attention when deep learning techniques made\nremarkable breakthroughs in this field over the past few\nyears.\n\nDeep learning based facial attribute analysis consists of two basic sub-issues:\n\nfacial attribute estimation (FAE), which recognizes whether facial attributes are present in given images, and\n\nfacial attribute manipulation (FAM), which synthesizes or removes desired facial attributes.\n\n---\n\n### Getting to know CELEB-A Dataset\n\n202,599 number of face images of various celebrities\n10,177 unique identities, but names of identities are not given\n40 binary attribute annotations per image\n5 landmark locations\n\n#### Data Files\n\n- <b>img_align_celeba.zip<\/b>: All the face images, cropped and aligned\n- <b>list_eval_partition.csv<\/b>: Recommended partitioning of images into training, validation, testing sets. Images 1-162770 are training, 162771-182637 are validation, 182638-202599 are testing\n- <b>list_bbox_celeba.csv<\/b>: Bounding box information for each image. \"x_1\" and \"y_1\" represent the upper left point coordinate of bounding box. \"width\" and \"height\" represent the width and height of bounding box\n- <b>list_landmarks_align_celeba.csv<\/b>: Image landmarks and their respective coordinates. There are 5 landmarks: left eye, right eye, nose, left mouth, right mouth\n- <b>list_attr_celeba.csv<\/b>: Attribute labels for each image. There are 40 attributes. \"1\" represents positive while \"-1\" represents negative\n\n## The Facial Attributes of CELEB-A Dataset\n\n![Imgur](https:\/\/imgur.com\/reRs5Jk.png)\n\nThe Dataset is considerably large to manage with even Google Colab's Pro version. I got out-of-memory quite a few times. Could not work at all with the full set of 200k images.\n\n### A quick tip in this regard if you are using local-machine to handle this dataset-challenge.\n\nIf you have a Solid-State Drive (SSD) with enough space plugged in your\nmachine, I highly recommend you move all of your training samples to\nthe SSD, especially when you have a powerful graphics card. Because\nwhen you are training neural networks on a very large dataset, which\ncannot fit in the GPU memory, the reading speed from physical drives\ncould be the bottleneck of your training performance. Sometimes, the\nspeed-up of SSD (reading samples at 50 MB\/s) over the traditional hard\ndrive (5 MB\/s) can save you a big chunk of training time.\n\n---\n\n# Fundamental way GAN Works\n\n\nGAN contains two networks which has two competing objectives:\n\nGenerator: the generator generates new data instances that are \"similar\" to the training data, in our case celebA images. Generator takes random latent vector and output a \"fake\" image of the same size as our reshaped celebA image.\n\nDiscriminator: the discriminator evaluate the authenticity of provided images; it classifies the images from the generator and the original image. Discriminator takes true of fake images and output the probability estimate ranging between 0 and 1.\n\n![Imgur](https:\/\/imgur.com\/pLJdmxs.png)\n\n\n### The basic objective function of a vanilla GAN model is the following:\n\n![Imgur](https:\/\/imgur.com\/LMjhfKk.png)\n\nHere, D refers to the discriminator network, while G obviously refers to the generator.\n\nAs the formula shows, the generator optimizes for maximally confusing the discriminator, by trying to make it output high probabilities for fake data samples.\n\nOn the contrary, the discriminator tries to become better at distinguishing samples coming from G from samples coming from the real distribution.\n\nThe GAN training process consists of a two-player minimax game in which D is adapted to minimize the discrimination error between real and generated samples, and G is adapted to maximize the probability of D making a mistake. When G does a good enough job to fool D, the output probability should be close to 1.\n\n---\n\n# Regular Neural Network vs CNN\n\n\nUnlike a regular feed-forward neural network whose neurons\nare arranged in flat, fully connected layers, layers in a\nConvNet are arranged in three dimensions (width \u00d7 height \u00d7\ndepth).\n\nConvolutions are performed by sliding one or more filters (the smaller Matrix which is the Kernel of the Current Layer) over the input layer. Each filter has a relatively small receptive field (width \u00d7 height) but always extends through the\nentire depth of the input volume.\n\nAt every step as it slides across the input, each filter outputs a single activation value: the dot product between the input values and the filter entries.\n\nConvolutional Neural Networks (CNNs) are neural networks with architectural constraints to reduce computational complexity and ensure translational invariance (the network interprets input patterns the same regardless of translation\u2014 in terms of image recognition: a banana is a banana regardless of where it is in the image). \n\n#### Convolutional Neural Networks have three important architectural features.\n\n**Local Connectivity**: Neurons in one layer are only connected to neurons in the next layer that are spatially close to them. This design trims the vast majority of connections between consecutive layers, but keeps the ones that carry the most useful information. The assumption made here is that the input data has spatial significance, or in the example of computer vision, the relationship between two distant pixels is probably less significant than two close neighbors.\n\n**Shared Weights**: This is the concept that makes CNNs \"convolutional.\" By forcing the neurons of one layer to share weights, the forward pass (feeding data through the network) becomes the equivalent of convolving a filter over the image to produce a new image. The training of CNNs then becomes the task of learning filters (deciding what features you should look for in the data.)\n\n**Pooling and ReLU**: CNNs have two non-linearities: pooling layers and ReLU functions. Pooling layers consider a block of input data and simply pass on the maximum value. Doing this reduces the size of the output and requires no added parameters to learn, so pooling layers are often used to regulate the size of the network and keep the system below a computational limit. The ReLU function takes one input, x, and returns the maximum of {0, x}. ReLU(x) = argmax(x, 0). This introduces a similar effect to tanh(x) or sigmoid(x) as non-linearities to increase the model's expressive power.\n\n---\n\n\n# Deep Convolutional GANs (DCGANs)\n\nDeep Convolutional GANs (DCGANs) introduced convolutions to the generator and discriminator networks.\n\nHowever, this was not simply a matter of adding convolutional layers to the model, since training became even more unstable.\n\n---\n\n## Generator Architecture\n\n![Imgur](https:\/\/imgur.com\/bHX4suR.png)\n\nThe generator network of a DCGAN contains 4 hidden layers (we treat the input layer as\nthe 1st hidden layer for simplicity) and 1 output layer. Transposed convolution layers are\nused in hidden layers, which are followed by batch normalization layers and ReLU\nactivation functions. The output layer is also a transposed convolution layer and Tanh is\nused as the activation function.\n\nThe 2nd, 3rd, and 4th hidden layers and the output layer have a stride value of 2. The 1st layer\nhas a padding value of 0 and the other layers have a padding value of 1. As the\nimage (feature map) sizes increase by two in deeper layers, the numbers of channels are\ndecreasing by half. This is a common convention in the architecture design of neural\nnetworks. All kernel sizes of transposed convolution layers are set to 4 x 4. The output\nchannel can be either 1 or 3, depending on whether you want to generate grayscale images\nor color images.\n\n## The architecture of a discriminator\n\n![Imgur](https:\/\/imgur.com\/HQWoKrF.png)\n\nThe discriminator network of a DCGAN consists of 4 hidden layers (again, we treat the\ninput layer as the 1st hidden layer) and 1 output layer. Convolution layers are used in all\nlayers, which are followed by batch normalization layers except that the first layer does not\nhave batch normalization. LeakyReLU activation functions are used in the hidden layers\nand Sigmoid is used for the output layer. The architecture of the discriminator is shown in\nthe following:\n\nThe input channel can be either 1 or 3, depending on whether you are dealing with\ngrayscale images or color images. All hidden layers have a stride value of 2 and a padding\nvalue of 1 so that their output image sizes will be half the input images. As image sizes\nincrease in deeper layers, the numbers of channels are increasing by twice. All kernels in\nconvolution layers are of a size of 4 x 4. The output layer has a stride value of 1 and a\npadding value of 0. It maps 4 x 4 feature maps to single values so that the Sigmoid function\ncan transform the value into prediction confidence.\n\n---\n\n\n### Several tricks had to be applied to make DCGANs stable and useful:\n\nBatch normalization was applied to both the generator and the discriminator network\nDropout is used as a regularization technique\nThe generator needed a way to upsample the random input vector to an output image. Transposing convolutional layers is employed here\nLeakyRelu and TanH activations are used throughout both networks\n\n------------------------------------------------------------------------------\n\n# How Reverse ConvNets works in DCGAN\n\nConvNets have traditionally been used for image classification\ntasks, in which the network takes in an image with the\ndimensions height \u00d7 width \u00d7 number of color channels as\ninput and\u2014through a series of convolutional layers\u2014outputs a\nsingle vector of class scores, with the dimensions 1 \u00d7 n, where\nn is the number of class labels.\n\nIn DCGAN, under the Generator part, to generate an image by using the ConvNet architecture, we reverse the process: instead of taking an image and processing it into a vector, we take a\nvector and up-size it to an image.\n\nSo, overall, the core to the DCGAN architecture uses a standard CNN architecture on the discriminative model.\n\nBut for the generator, convolutions are replaced with up-convolutions, so the representation at each layer of the generator is actually successively larger, as it maps from a low-dimensional latent vector onto a high-dimensional image.","45c6b643":"crop = (30, 55, 150, 175) #croping size for the image so that only the face at centre is obtained\n\ntraining_images = [np.array((Image.open(path).crop(crop)).resize((64,64))) for path in image_path_50k]\n\nfor i in range(len(training_images)):\n    training_images[i] = ((training_images[i] - training_images[i].min())\/(255 - training_images[i].min()))\n    #training_images[i] = training_images[i]*2-1  #uncomment this if activation is tanh for generator last layer\n    \ntraining_images = np.array(training_images) ","661d86e9":"# Discriminator\n\nHere I am creating a Sequential model incrementally via the add() method:"}}