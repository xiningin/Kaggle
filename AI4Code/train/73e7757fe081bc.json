{"cell_type":{"9b82b886":"code","f74c770d":"code","58de9707":"code","3106a6d3":"code","9b4c940b":"code","90964b81":"code","cc6b48ee":"code","ac857bc3":"code","aa76f091":"code","2f37aea0":"code","e6c31513":"code","51003723":"code","50468d59":"code","a38044ed":"code","ef84387f":"code","ce47ec10":"code","060b73b2":"code","e1acfa1d":"code","239ada54":"code","be2c40db":"code","96e09de0":"code","fa803cd3":"code","1ee67847":"code","c02884ae":"code","eaa27cd5":"code","75db863a":"code","4306812c":"code","52dc6c90":"code","4b86e2e0":"code","edec44e4":"code","65908110":"code","2a336fe7":"code","156b0e54":"code","1cd90ba1":"code","c714cfff":"code","297a94f3":"code","9b0eaf05":"code","3e241016":"code","3d5c48a2":"code","03e3c9ba":"code","9d7c4c61":"code","a3c8c7cb":"markdown","2d3947f6":"markdown","188bf47a":"markdown","71b584a1":"markdown","ae898aff":"markdown","356122f6":"markdown","58fa2676":"markdown","c727233e":"markdown","c6448113":"markdown","004e7108":"markdown","c1750491":"markdown","29d2ef31":"markdown","496b21aa":"markdown","51abd177":"markdown","b40cd375":"markdown","d8041aed":"markdown","137acfc2":"markdown","9853f0e3":"markdown","4c090383":"markdown","dd5165a3":"markdown","4e548948":"markdown","d6db7b80":"markdown","613753a2":"markdown","6c3b3230":"markdown"},"source":{"9b82b886":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f74c770d":"import pandas as pd\nmb_file2_path=\"\/kaggle\/input\/titanic\/train.csv\"\ndata=pd.read_csv(mb_file2_path)\ndata.head()","58de9707":"print('The number of missing values is= ',data.isnull().sum().sum())\nprint('The shape of the dataFrame is= ',data.shape)","3106a6d3":"data.isnull().sum()","9b4c940b":"X=data.drop('Survived', axis=1)\ny=data.Survived\nuniq_values_in_cols_10= {i:X[i].unique()[:9] for i in X.columns}\nuniq_values_in_cols_10 #Just to see how many the unique values are for each column","90964b81":"X_first_mod= X.copy()\nX_first_mod['age_group']=pd.cut(X_first_mod['Age'],bins=[-float('inf'),12,19,61,90,float(\"inf\")], labels=[1,2,3,4,5])\nX_first_mod.head()","cc6b48ee":"col_wit_misn_values=[col for col in X_first_mod.columns if X_first_mod[col].isnull().any()]\ncol_wit_misn_values #the columns with missing values","ac857bc3":"no_of_misn_values_in_cols= {i:X_first_mod[i].isnull().sum() for i in X_first_mod.columns}\nno_of_misn_values_in_cols #number of missing values besides its column as the key in the dictionary","aa76f091":"print('The number of missing values in the cabin column is ',X_first_mod['Cabin'].isnull().sum())\nprint('The percentage of missing values in the cabin column is ',X_first_mod['Cabin'].isnull().sum()\/len(X_first_mod.index)*100)","2f37aea0":"X_sec_mod=X_first_mod.drop(['Age','Cabin'], axis=1)\nX_sec_mod.head()","e6c31513":"X_sec_mod['age_group'].isnull().sum()\/len(X_sec_mod.index)*100","51003723":"X_sec_mod['Title']=X_sec_mod['Name'].str.split(',').str[1].str.split('.').str[0].str.strip()\nX_3rd_mod=X_sec_mod.copy()\nX_3rd_mod.head()","50468d59":"X_3rd_mod[~X_3rd_mod['Title'].str.contains('Mr|Mrs|Miss|Master')]","a38044ed":"miss_master_pd=(X_3rd_mod['Title']=='Miss') | (X_3rd_mod['Title']=='Master')\nmiss_pd=(X_3rd_mod['Title']=='Miss') #only miss\nnot_miss_master_pd=~miss_master_pd #pd of title as miss or master and not\nmrs_pd=(X_3rd_mod['Title']=='Mrs') #only mrs","ef84387f":"not_miss_master_age_2=X_3rd_mod.loc[(X_3rd_mod['age_group']==2) & not_miss_master_pd]\nnot_miss_master_age_2.shape[0]\/X_3rd_mod.shape[0]*100 ","ce47ec10":"not_miss_master_age_3=X_3rd_mod.loc[(X_3rd_mod['age_group']==3) & not_miss_master_pd]\nnot_miss_master_age_3.shape[0]\/X_3rd_mod.shape[0]*100","060b73b2":"miss_master_age_2= X_3rd_mod.loc[(X_3rd_mod['age_group']==2) & miss_master_pd]\nmiss_master_age_2.shape[0]\/X_3rd_mod.shape[0]*100 ","e1acfa1d":"miss_master_age_3=X_3rd_mod.loc[(X_3rd_mod['age_group']==3) & miss_master_pd]\nmiss_master_age_3.shape[0]\/X_3rd_mod.shape[0]*100 ","239ada54":"only_mrs_age_2=X_3rd_mod.loc[(X_3rd_mod['age_group']==3) & mrs_pd]\nonly_mrs_age_2.shape[0]\/not_miss_master_age_3.shape[0]*100 ","be2c40db":"only_miss_age_2=X_3rd_mod.loc[(X_3rd_mod['age_group']==3) & miss_pd]\nonly_miss_age_2.shape[0]\/miss_master_age_3.shape[0]*100 ","96e09de0":"X_3rd_mod[X_3rd_mod['age_group'].isnull()].shape[0]\/X_3rd_mod.shape[0]*100 ","fa803cd3":"cond=X_3rd_mod['Title']=='Master'\nX_3rd_mod['age_group']=X_3rd_mod['age_group'].fillna(cond.map({True:2, False:3}))\nX_4th_mod=X_3rd_mod.copy()\nX_4th_mod['age_group'].isnull().sum()","1ee67847":"X_4th_mod.isnull().any()","c02884ae":"print('null sum- ',X_4th_mod.Embarked.isnull().sum())\nprint('') \nprint('value-counts- ',X_4th_mod.Embarked.value_counts())","eaa27cd5":"X_4th_mod['Embarked'].fillna(X_4th_mod['Embarked'].value_counts().index[0],inplace=True)\nX_5th_mod=X_4th_mod.copy()\nX_5th_mod.isnull().any()","75db863a":"every_uniq_val_col=[col for col in X_5th_mod.columns if X_5th_mod[col].nunique()==len(X_5th_mod)]\nX_6th_mod=X_5th_mod.drop(every_uniq_val_col,axis=1)","4306812c":"from sklearn.preprocessing import OrdinalEncoder\n#now to encode categorical values\ncate_cols=[cols for cols in X_6th_mod.columns if X_6th_mod[cols].nunique()>1 and X_6th_mod[cols].dtype=='object']\nX_7th_mod=X_6th_mod.copy()\nordinal_encoder= OrdinalEncoder()\nX_7th_mod[cate_cols]=ordinal_encoder.fit_transform(X_7th_mod[cate_cols])\nX_7th_mod.head()","52dc6c90":"from sklearn.model_selection import train_test_split as tts\nfrom sklearn.ensemble import RandomForestClassifier as rfc\nfrom sklearn.metrics import confusion_matrix\nX_train, X_test, y_train, y_test=tts(X_7th_mod,y,random_state=2)\nmodelrfr= rfc(random_state=2, n_estimators=10)\nmodelrfr.fit(X_train, y_train)\npred_v=modelrfr.predict(X_test)\nconf_val=confusion_matrix(y_test,pred_v)\nconf_val","4b86e2e0":"a=112+64\nprint('This model made a '+str(a\/(a+28+19))+' accuracy')","edec44e4":"from sklearn.metrics import classification_report as cr\nprint(cr(y_test, pred_v))","65908110":"mb_file3_path='\/kaggle\/input\/titanic\/test.csv'\ndata_test=pd.read_csv(mb_file3_path)\ndata_test.head()","2a336fe7":"test_first_mod=data_test.copy()\ntest_first_mod['age_group']=pd.cut(data_test['Age'],bins=[-float('inf'),12,19,61,90,float(\"inf\")], labels=[1,2,3,4,5])\ntest_first_mod.head()","156b0e54":"test_first_mod.isnull().any()","1cd90ba1":"test_sec_mod=test_first_mod.drop(['Age','Cabin'], axis=1)\ntest_sec_mod['Title']=test_sec_mod['Name'].str.split(',').str[1].str.split('.').str[0].str.strip()\ntest_3rd_mod=test_sec_mod.copy()\ntest_3rd_mod.head()","c714cfff":"cond=test_3rd_mod['Title']=='Master'\ntest_3rd_mod['age_group'].fillna(cond.map({True:2, False:3}), inplace=True)\ntest_4th_mod=test_3rd_mod.copy()\ntest_4th_mod.head()","297a94f3":"test_4th_mod['Fare'].isnull().sum()","9b0eaf05":"test_4th_mod['Fare'].fillna(method='ffill',inplace=True)","3e241016":"test_4th_mod.isnull().any()","3d5c48a2":"every_uniq_val_col=[col for col in test_4th_mod.columns if test_4th_mod[col].nunique()==len(test_4th_mod)]\ntest_5th_mod=test_4th_mod.drop(every_uniq_val_col,axis=1)\ncate_cols=[cols for cols in test_5th_mod.columns if test_5th_mod[cols].nunique()>1 and test_5th_mod[cols].dtype=='object']\ntest_6th_mod=test_5th_mod.copy()\nordinal_encoder= OrdinalEncoder()\ntest_6th_mod[cate_cols]=ordinal_encoder.fit_transform(test_6th_mod[cate_cols])","03e3c9ba":"pred_test_v=modelrfr.predict(test_6th_mod)","9d7c4c61":"submission=pd.DataFrame({\n    \"PassengerId\": test_first_mod['PassengerId'], \n    \"Survived\":pred_test_v\n})\nsubmission.to_csv(\"submission.csv\", index=False)","a3c8c7cb":"*getting the basic analysis more like an overview*","2d3947f6":"*All of miss rows satisfy the 8% rows of either miss or master and age=3 that means no master was registered as an adult(excluding the missing columns)*","188bf47a":"*Next missing value is the age_group column. 19% null column is not enough to be dropped as it may have a major impact on the target value so it needs to be filled up. I came up with this logic that since the name entry has characters that contain a title(Mr., Mrs, Miss....), i should come up with another column called 'Title' which would be the title subcopy of the corresponding name entries. like Ogbonna,Mr. GreyHaired wouldsliced to Mr so as to give a better categorical column. \nX_3rd_mod takes over for holding the predictor data.*","71b584a1":"*19% of the age_group entries are null*","ae898aff":"*Now to use ordinal encoder to encode categorical values. \nX_7th_mod takes over for holding the predictor data.*","356122f6":"*21% of mrs rows satisfy the 50% rows of not miss n master and age=3*","58fa2676":"*importing pandas and reading your csv file*","c727233e":"*6.8% rows satisfy title of neither miss nor master and age_group==2*","c6448113":"*50% rows satisfy title of neither miss nor master and age_group==3*","004e7108":"*For some reason, based on my analysis above, i feel like the logical thing to do is to split the age_group. \nfill 2 for the master, then 3 for those that are not. Fill the agegroup missing values with the Title value based on a condition.\nX_4th_mod takes over for holding the predictor data*","c1750491":"*Now time to drop unnecessary columns, like the columns that every entry is a unique one. \nX_6th_mod takes over for holding the predictor data.*","29d2ef31":"*getting the first ten unique values of each column*","496b21aa":"*All done for the missing values remaining the 'Embarked' column*","51abd177":"*4% rows satisfy title of either miss or master and age_group==2*","b40cd375":"*Just only 2 null entries for the embarked column. so i just filled it with the most frequent. \nX_5th_mod takes over for holding the predictor data.*","d8041aed":"*Now lets fill inn the missing ages with the title column. For missing age_group rows with its corresponding title rows.\nComparing the title and age_group, I found out there are more titles than just Mr, Master, Miss and \nMr.*","137acfc2":"*Analyzing the mising data in the 'cabin' column*","9853f0e3":"*Submitting Tasks*","4c090383":"*Getting the columns with missing values and the number of missing values in them*","dd5165a3":"*9% rows satisfy title of either miss or master and age_group==3*","4e548948":"*Now to split and train the model using random forest classifier. Then check the performance using confusion matrix*","d6db7b80":"*77 percent of the rows are missing in the cabin column. given that is a huge percentage of missing entries for a column it has to be dropped. Plus i would be dropping the cabin alongside the age column as the age_group would be of better representation to the age entry too. X_sec_mod takes over for holding the predictor data.*","613753a2":"#### PS- There was no graphical representational analysis done on this notebook,nevertheless I used my wholesome skills in pandas to pinpoint and document the necessary analysis alongside detailed comments. I would appreciate feedbacks, comments and if you find the work worthful, please upvote, I would deeply appreciate.","6c3b3230":"*I grouped the age column containing various ages of each passenger row according to ranges with the pd.cut function then \ninserting age_group containing the encoded version of the grouped ages. X_first_mod takes over for holding the predictor data.*"}}