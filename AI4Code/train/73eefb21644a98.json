{"cell_type":{"f9376e2a":"code","49c3e579":"code","1f6e5573":"code","ff504725":"code","595f2371":"code","963345da":"code","5bea5430":"code","776bbb70":"code","5099c558":"code","9734b243":"code","c64af292":"code","fe03a3b8":"code","8f60918e":"code","aa859801":"code","95f12a5a":"code","cda7cd3e":"code","f5006d44":"code","23bf73ee":"markdown","07afca0c":"markdown"},"source":{"f9376e2a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","49c3e579":"# import necessary package\nimport tensorflow as tf\nfrom tensorflow import keras\n\nimport sklearn\nfrom sklearn import preprocessing\n\n# \u756b\u5716\u8868\u7528\nimport matplotlib.pyplot as plt","1f6e5573":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()","ff504725":"# \u5206\u6790name\u662f\u5426\u53ef\u4ee5\u4f5c\u70bafeature\u4f7f\u7528\n# \u89c0\u5bdf\u8cc7\u6599\u5167\u5bb9\ntrain_data[[\"Survived\", \"Name\"]]","595f2371":"# \u540d\u7a31\u4e2d\u7528\u65bc\u7a31\u547c\u7684\u8a5e\u53ef\u4ee5\u505a\u4f86\u5206\u985e(Mr. Mrs. Miss Rev.\u7b49\u7b49)\ntrain_data[\"Title\"] = train_data[\"Name\"].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n\ntrain_data[\"Title\"].value_counts()","963345da":"# \u89c0\u5bdf\u8cc7\u6599\ntrain_data[[\"Survived\",\"Title\"]].value_counts()","5bea5430":"# \u5f9e\u4e0a\u9762\u53ef\u4ee5\u767c\u73fe\u57fa\u672c\u7684\u7a31\u547c\u4f54\u5927\u591a\u6578(Mr Miss Mrs)\n# \u4e0b\u9762\u6211\u5011\u5c07\u5e38\u898b\u7684\u7a31\u547c\u6b78\u70ba\u4e00\u985e\uff0c\u4e0d\u5e38\u898b\u7684\u6b78\u70ba\u4e00\u985e\n# \u4ee5\u4e0b\u5206\u6210\u56db\u985e1.Mr 2.Miss\/Mrs\/Ms 3.Master 4.\u5176\u4ed6\n\n# Don\u662f\u897f\u73ed\u7259\u6587\u7684\u7537\u6027\u7a31\u547c\ntrain_data[\"Title\"] = train_data[\"Title\"].replace([\"Mr\", \"Don\"], \"Man\") \n# Dona\u662f\u897f\u73ed\u7259\u6587\u7684\u5973\u6027\u7a31\u547c, Mlle(\u672a\u5a5a)\u53caMme\u662f\u6cd5\u6587\u7684\u5973\u6027\u7a31\u547c\ntrain_data[\"Title\"] = train_data[\"Title\"].replace([\"Miss\", \"Mrs\", \"Ms\", \"Mlle\", \"Lady\", \"Mme\", \"Dona\"], \"Woman\") \n# \u5176\u4ed6\u8f03\u9ad8\u7d1a\u7684\u982d\u929c\ntrain_data[\"Title\"] = train_data[\"Title\"].replace([\"Dr\", \"Rev\", \"Major\", \"Col\", \"Capt\", \"Jonkheer\", \"Sir\", \"the Countess\"], \"Other\")\n\ntrain_data[[\"Survived\",\"Title\"]].value_counts()","776bbb70":"titleEncode = pd.get_dummies(train_data[\"Title\"], prefix=\"Title\")\ntrain_data = train_data.join(titleEncode)\n\ntrain_data.head()","5099c558":"# feature\u4e2d\u6709\u8a31\u591a\u9700\u8981encode\u7684\u90e8\u5206\n# Pclass, embark\n\n# Pclass encoding (One Hot Encoding)\npclassEncode = pd.get_dummies(train_data[\"Pclass\"], prefix=\"Pclass\")\ntrain_data = train_data.join(pclassEncode)\n\n# Embarked encoding (One Hot Encoding)\nembarkedEncode = pd.get_dummies(train_data[\"Embarked\"], prefix=\"Embarked\")\ntrain_data = train_data.join(embarkedEncode)\n\ntrain_data.head()","9734b243":"# \u53bb\u9664\u6c92Age\u8cc7\u6599\u7684row\n# train_data = train_data.drop(train_data[pd.isna(train_data.Age)].index)\n\n# Age\u6709\u7f3a\u8cc7\u6599\uff0c\u4e4b\u5f8c\u518d\u8003\u616e\u52a0\u5165(\u4f46\u662f\u5f88\u91cd\u8981\u7684\u90e8\u5206\uff0c\u611f\u89ba\u5f71\u97ff\u6e96\u78ba\u7387\u5f88\u591a)\nfeature_name = [\"Pclass_1\", \"Pclass_2\", \"Pclass_3\", \"SibSp\", \"Parch\", \"Title_Man\", \"Title_Woman\", \"Title_Other\", \"Title_Master\"]\n\ntrain_x = train_data[feature_name]\ntrain_y = train_data[\"Survived\"]","c64af292":"scaler = preprocessing.MinMaxScaler()\nscaler.fit(train_x)\n\ntrain_x = scaler.transform(train_x)\n\ntrain_x = pd.DataFrame(train_x, columns=feature_name)\n\ntrain_x.head()\n","fe03a3b8":"model = keras.models.Sequential([\n    keras.layers.Input(shape=(9, )),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dense(16, activation=\"relu\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dense(32, activation=\"relu\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dense(16, activation=\"relu\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dense(1, activation=\"sigmoid\")\n])\n\noptimizer = keras.optimizers.Adam(lr=0.001)\n\nmodel.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=[\"accuracy\"])","8f60918e":"model.summary()","aa859801":"early_stopping =  keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n\nmodel_result = model.fit(train_x, train_y, batch_size=32, epochs=200, validation_split=0.2, shuffle=True, callbacks=[early_stopping])","95f12a5a":"plt.figure(figsize=(30, 10))\n\nplt.subplot(1, 2, 1)\nplt.plot(model_result.history[\"loss\"], label=\"training\")\nplt.plot(model_result.history[\"val_loss\"], label=\"validation\")\nplt.axhline(0.55, c=\"red\", linestyle=\"--\")\nplt.axhline(0.35, c=\"yellow\", linestyle=\"--\")\nplt.axhline(0.15, c=\"green\", linestyle=\"--\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(model_result.history[\"accuracy\"], label=\"training\")\nplt.plot(model_result.history[\"val_accuracy\"], label=\"validation\")\nplt.axhline(0.75, c=\"red\", linestyle=\"--\")\nplt.axhline(0.80, c=\"green\", linestyle=\"--\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\n\nplt.show()","cda7cd3e":"# \u5c0dtest\u8cc7\u6599\u505a\u4e00\u6a23\u7684\u8655\u7406\u4f86\u505apredict\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n\n# Name\u8655\u7406\ntest_data[\"Title\"] = test_data[\"Name\"].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n\n# Don\u662f\u897f\u73ed\u7259\u6587\u7684\u7537\u6027\u7a31\u547c\ntest_data[\"Title\"] = test_data[\"Title\"].replace([\"Mr\", \"Don\"], \"Man\") \n# Dona\u662f\u897f\u73ed\u7259\u6587\u7684\u5973\u6027\u7a31\u547c, Mlle(\u672a\u5a5a)\u53caMme\u662f\u6cd5\u6587\u7684\u5973\u6027\u7a31\u547c\ntest_data[\"Title\"] = test_data[\"Title\"].replace([\"Miss\", \"Mrs\", \"Ms\", \"Mlle\", \"Lady\", \"Mme\", \"Dona\"], \"Woman\") \n# \u5176\u4ed6\u8f03\u9ad8\u7d1a\u7684\u982d\u929c\ntest_data[\"Title\"] = test_data[\"Title\"].replace([\"Dr\", \"Rev\", \"Major\", \"Col\", \"Capt\", \"Jonkheer\", \"Sir\", \"the Countess\"], \"Other\")\n\ntitleEncode = pd.get_dummies(test_data[\"Title\"], prefix=\"Title\")\ntest_data = test_data.join(titleEncode)\n\n# Pclass encoding (One Hot Encoding)\npclassEncode = pd.get_dummies(test_data[\"Pclass\"], prefix=\"Pclass\")\ntest_data = test_data.join(pclassEncode)\n\n# Embarked encoding (One Hot Encoding)\nembarkedEncode = pd.get_dummies(test_data[\"Embarked\"], prefix=\"Embarked\")\ntest_data = test_data.join(embarkedEncode)\n\ntest_x = test_data[feature_name]\n\nscaler = preprocessing.MinMaxScaler()\nscaler.fit(test_x)\n\ntest_x = scaler.transform(test_x)\n\ntest_x = pd.DataFrame(test_x, columns=feature_name)\n\ntest_x.head()","f5006d44":"prediction = model.predict_classes(test_x)\n\nsubmission = pd.DataFrame()\nsubmission[\"PassengerId\"] = test_data.PassengerId\nsubmission[\"Survived\"] = prediction\n\nsubmission.to_csv('submission.csv', index=False)","23bf73ee":"**Predict Result**","07afca0c":"* \u4e00\u822c\u7537\u6027\u5b58\u6d3b\u7387 (81\/437+81) = 15.6%\n* \u4e00\u822c\u5973\u6027\u5b58\u6d3b\u7387 (231\/231+81) = 74%\n* Master\u5b58\u6d3b\u7387 (23\/17+23) = 57.5%\n* \u982d\u929c\u64c1\u6709\u8005\u5b58\u6d3b\u7387 (7\/14+7) = 33.3%\n\n\u4ee5\u4e00\u822c\u7537\u6027\u5b58\u6d3b\u7387\u4f5c\u70ba\u6a19\u6e96\uff0c\u5176\u4ed6\u4e09\u985e\u5747\u6709\u660e\u986f\u8f03\u9ad8\u7684\u5b58\u6d3b\u7387"}}