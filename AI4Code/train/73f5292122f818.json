{"cell_type":{"8718b8cd":"code","f1ab429a":"code","67870a30":"code","ff0070ea":"code","e8e21493":"code","738f8d44":"code","7f218e86":"code","c8ca3f7d":"code","07407c23":"code","3d9d18ba":"code","1b994d6e":"code","3d32d55a":"code","6cbf4215":"code","3226a356":"code","99a8ea46":"code","4db1fa6a":"code","844811a0":"code","7a7b016f":"code","65148312":"code","e358d42d":"markdown","c0befed6":"markdown","2de21796":"markdown","2841ab59":"markdown","2ba7d943":"markdown","7551f8bf":"markdown","44321295":"markdown","2e39e745":"markdown","857b4fd0":"markdown","e75abeea":"markdown","b908636a":"markdown","70b06671":"markdown","817d44db":"markdown"},"source":{"8718b8cd":"import numpy as np\nimport matplotlib.pylab as plt\nimport pandas as pd\nimport torch \nfrom torch import nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import Dataset, DataLoader\nimport random\nfrom keras.preprocessing.text import one_hot\nfrom keras.preprocessing.sequence import pad_sequences\nfrom sklearn.preprocessing import OneHotEncoder\n!pip install torchsummaryX  --quiet\nfrom torchsummaryX import summary","f1ab429a":"# Sample Document # Recreated from the tom and jerry cartoon\n        \ndocs = [\"cat and mice are buddies\",\n        'mice lives in hole',\n        'cat lives in house',\n        'cat chases mice',\n        'cat catches mice',\n        'cat eats mice',\n        'mice runs into hole',\n        'cat says bad words',\n        'cat and mice are pals',\n        'cat and mice are chums',\n        'mice stores food in hole',\n        'cat stores food in house',\n        'mice sleeps in hole',\n        'cat sleeps in house']","67870a30":"idx_2_word = {}\nword_2_idx = {}\ntemp = []\ni = 1\nfor doc in docs:\n    for word in doc.split():\n        if word not in temp:\n            temp.append(word)\n            idx_2_word[i] = word\n            word_2_idx[word] = i\n            i += 1\n\nprint(idx_2_word)\nprint(word_2_idx)","ff0070ea":"vocab_size = 25\n\ndef one_hot_map(doc):\n    x = []\n    for word in doc.split():\n        x.append(word_2_idx[word])\n    return x\n  \nencoded_docs = [one_hot_map(d) for d in docs]\nencoded_docs","e8e21493":"max_len = 10\npadded_docs = pad_sequences(encoded_docs, maxlen=max_len, padding='post')\npadded_docs","738f8d44":"training_data = np.empty((0,2))\n\nwindow = 2\nfor sentence in padded_docs:\n    sent_len = len(sentence)\n    \n    for i, word in enumerate(sentence):\n        w_context = []\n        if sentence[i] != 0:\n            w_target = sentence[i]\n            for j in range(i-window, i + window + 1):\n                if j != i and j <= sent_len -1 and j >=0 and sentence[j]!=0:\n                    w_context = sentence[j]\n                    training_data = np.append(training_data, [[w_target, w_context]], axis=0)\n\nprint(len(training_data))\nprint(training_data.shape)\ntraining_data","7f218e86":"enc = OneHotEncoder()\nenc.fit(np.array(range(30)).reshape(-1,1))\nonehot_label_x = enc.transform(training_data[:,0].reshape(-1,1)).toarray()\nonehot_label_x","c8ca3f7d":"enc = OneHotEncoder()\nenc.fit(np.array(range(30)).reshape(-1,1))\nonehot_label_y = enc.transform(training_data[:,1].reshape(-1,1)).toarray()\nonehot_label_y","07407c23":"print(onehot_label_x[0])\nprint(onehot_label_y[0])\n\n# From Numpy to Torch\n\nonehot_label_x = torch.from_numpy(onehot_label_x)\nonehot_label_y = torch.from_numpy(onehot_label_y)\nprint(onehot_label_x.shape, onehot_label_y.shape)","3d9d18ba":"class WEMB(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super(WEMB, self).__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.softmax = nn.Softmax(dim=1)\n    \n        self.l1 = nn.Linear(self.input_size, self.hidden_size, bias=False)\n        self.l2 = nn.Linear(self.hidden_size, self.input_size, bias=False)\n   \n    def forward(self, x):\n        out_bn = self.l1(x) # bn - bottle_neck\n        out = self.l2(out_bn)\n        out = self.softmax(out)\n        return out, out_bn\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","1b994d6e":"'''\nm = nn.Softmax() #nn.Sigmoid()\nloss = nn.BCELoss()\ninput = torch.tensor([0.9,0.0,0.0]) #torch.randn(3, requires_grad=True)\ntarget = torch.tensor([1.0,0.0,0.0])\noutput = loss(m(input), target)\nprint(input, m(input), target) tensor([0.9000, 0.0000, 0.0000]) tensor([0.5515, 0.2242, 0.2242]) tensor([1., 0., 0.])\noutput -> 0.36\n'''\n\n'''\nm = nn.Sigmoid()\nloss = nn.BCELoss()\ninput = torch.tensor([0.9,0.0,0.0])\ntarget = torch.tensor([1.0,0.0,0.0])\noutput = loss(m(input), target)\nprint(input, m(input), target) tensor([0.9000, 0.0000, 0.0000]) tensor([0.7109, 0.5000, 0.5000]) tensor([1., 0., 0.])\noutput -> 0.5758\n'''","3d32d55a":"input_size = 30\nhidden_size = 2\nlearning_rate = 0.01\nnum_epochs = 5000\n\nuntrained_model = WEMB(input_size, hidden_size).to(device)\nmodel = WEMB(input_size, hidden_size).to(device)\nmodel.train(True)\nprint(model)\nprint()\n\n# Loss and optimizer\ncriterion = nn.BCELoss()\n#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0, dampening=0, weight_decay=0, nesterov=False)\nsummary(model, torch.ones((1,30)).to(device)) ","6cbf4215":"loss_val = []\nonehot_label_x = onehot_label_x.to(device)\nonehot_label_y = onehot_label_y.to(device)\n\nfor epoch in range(num_epochs):\n    for i in range(onehot_label_y.shape[0]):\n        inputs = onehot_label_x[i].float()\n        labels = onehot_label_y[i].float()\n        inputs = inputs.unsqueeze(0)\n        labels = labels.unsqueeze(0)\n\n      # Forward pass\n        output, wemb = model(inputs)\n        loss = criterion(output, labels)\n\n      # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    loss_val.append(loss.item())\n\n    if (epoch+1) % 100 == 0:\n        print (f'Epoch [{epoch+1}\/{num_epochs}], Loss: {loss.item():.4f}')\n\nplt.plot(loss_val)","3226a356":"docs = ['cat and mice are buddies hole lives in house chases catches runs into says bad words pals chums stores sleeps']\nencoded_docs = [one_hot_map(d) for d in docs]\n\ntest_arr = np.array([[ 1.,  2., 3., 4., 5., 8., 6., 7., 9., 10., 11., 13., 14., 15., 16., 17., 18., 19., 20., 22.]])\ntest = enc.transform(test_arr.reshape(-1,1)).toarray()\n\noutput = []\nfor i in range(test.shape[0]):\n    _, wemb2 = model(torch.from_numpy(test[i]).unsqueeze(0).float().to(device))\n    wemb2 = wemb2[0].detach().cpu().numpy()\n    output.append(wemb2)\nprint(len(output))\nprint(output)","99a8ea46":"docs = ['cat', 'and', 'mice', 'are', 'buddies', 'hole', 'lives', 'in', 'house', 'chases', 'catches', 'runs', 'into', 'says', 'bad', 'words', 'pals', 'chums', 'stores', 'sleeps']\nfor i in range(0, len(docs)):\n    print(\"Word - {} - It's Word Embeddings : {:.3} & {:.3} -\".format(docs[i], output[i][0], output[i][0]))","4db1fa6a":"xs = []\nys = []\nfor i in range(len(output)):\n    xs.append(output[i][0])\n    ys.append(output[i][1])\nprint(xs, ys)\n\ndocs = ['cat', 'and', 'mice', 'are', 'buddies', 'hole', 'lives', 'in', 'house', 'chases', 'catches', 'runs', 'into', 'says', 'bad', 'words', 'pals', \\\n        'chums', 'stores', 'sleeps']\n\nplt.clf()\nplt.figure(figsize=(12,12))\nplt.scatter(xs,ys)\nlabel = docs\n\nfor i,(x,y) in enumerate(zip(xs,ys)):\n    plt.annotate(label[i], (x,y), textcoords=\"offset points\", xytext=(0,10), fontsize=20, ha = random.choice(['left', 'right']))\n    plt.title(\"Trained Model\")\nplt.show()","844811a0":"import plotly\nimport plotly.express as px\n\nimport plotly.express as px\nfig = px.scatter(x=xs, y=ys, text=docs, size_max=100)\nfig.update_traces(textposition= random.choice(['top center', 'bottom center','bottom left']))\nfig.update_layout(height=800,title_text='Custom Word Embeddings')\nfig.show()","7a7b016f":"output = []\nfor i in range(test.shape[0]):\n    _, wemb2 = untrained_model(torch.from_numpy(test[i]).unsqueeze(0).float().to(device)) # Here I am loading the untrained model\n    wemb2 = wemb2[0].detach().cpu().numpy()\n    output.append(wemb2)\nprint(len(output))\nprint(output)\n\nxs = []\nys = []\nfor i in range(len(output)):\n    xs.append(output[i][0])\n    ys.append(output[i][1])\nprint(xs, ys)\n\ndocs = ['cat', 'and', 'mice', 'are', 'buddies', 'hole', 'lives', 'in', 'house', 'chases', 'catches', 'runs', 'into', 'says', 'bad', 'words', 'pals', \\\n        'chums', 'stores', 'sleeps']\n\nplt.clf()\nplt.figure(figsize=(12,12))\nplt.scatter(xs,ys)\nlabel = docs\n\nfor i,(x,y) in enumerate(zip(xs,ys)):\n    plt.annotate(label[i], (x,y), textcoords=\"offset points\", xytext=(0,10), fontsize=20, ha = random.choice(['left', 'right']))\n    plt.title(\"Un-Trained Model\")\nplt.show()","65148312":"import plotly\nimport plotly.express as px\n\nimport plotly.express as px\nfig = px.scatter(x=xs, y=ys, text=docs, size_max=100)\nfig.update_traces(textposition= random.choice(['top center', 'bottom center','bottom left']))\nfig.update_layout(height=800,title_text='Custom Word Embeddings')\nfig.show()","e358d42d":"# Data - Preprocessing - Steps : Visualization","c0befed6":"<img src=\"https:\/\/cdn-images-1.medium.com\/max\/1200\/1*r_9zfDywyD1TbVpxKENHjw.png\">","2de21796":"# Padding","2841ab59":"# Words to numbers","2ba7d943":"# Dataset Source\n<img src=\"https:\/\/github.com\/bala-codes\/Mini_Word_Embeddings\/blob\/master\/codes\/Capture.PNG?raw=true\">\n","7551f8bf":"# This notebook has been written in accordance to my blog post on medium, feel free to read in this [Link](https:\/\/medium.com\/towards-artificial-intelligence\/create-your-own-mini-word-embedding-from-scratch-c7b32bd84f8e) to get the complete essence of it.","44321295":"<img src=\"https:\/\/cdn-images-1.medium.com\/max\/1200\/0*dEB7_sqWOHhV82EI.png\">","2e39e745":"# Creating dataset tuples for training","857b4fd0":"<img src=\"https:\/\/cdn-images-1.medium.com\/max\/800\/1*SANI-0E8qSTHzGHg4HHtNA.png\">\n","e75abeea":"# How Untrained Model behaves with our data","b908636a":"<img src=\"https:\/\/cdn-images-1.medium.com\/max\/800\/1*pDeswCr7eBhEDtiywMkAqQ.png\">\n","70b06671":"![image.png](https:\/\/github.com\/bala-codes\/Mini_Word_Embeddings\/blob\/master\/codes\/untrained%20to%20trained.PNG?raw=true)","817d44db":"<img src=\"https:\/\/cdn-images-1.medium.com\/max\/800\/1*rb9i3dT_rH3DB31atto_Ag.png\">"}}