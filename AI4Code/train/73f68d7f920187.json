{"cell_type":{"eef7faaf":"code","f51bbc79":"code","22130e6e":"code","aa1107ae":"code","1f9cc3dc":"code","50dd3720":"code","e7744fad":"code","f7ad9529":"code","944b8eab":"code","eb0fd23f":"code","ff4a3a09":"code","6f73fb69":"code","abd6e094":"code","232f7f32":"code","42ab2f78":"code","4f8b29b2":"markdown","b1e79982":"markdown","8ce92466":"markdown","b5c32a2e":"markdown","43b833e4":"markdown","75f5dfb7":"markdown","61d70df4":"markdown"},"source":{"eef7faaf":"import os,re,zipfile\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport itertools\nplt.style.use('seaborn')","f51bbc79":"train = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/test.csv')\ntrain[:3]","22130e6e":"train.target.value_counts().plot.bar(rot=0);","aa1107ae":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import ensemble, linear_model\nimport lightgbm as lgbm\nfrom nltk.corpus import stopwords","1f9cc3dc":"stop = stopwords.words('english')\nstop += ['http','https', 'u_','co', '70', 'years', 'via']\nstop += ['news', 'california', 'amp', 'train','like','two', 'get', 'people']\n\ntfidf = TfidfVectorizer(\n    ngram_range=(1,4), \n    stop_words=stop,\n    max_df=0.95,\n    min_df=3,\n    max_features=700,\n    strip_accents='unicode',\n    token_pattern=r'\\w+'\n)\ntfidf.fit(pd.concat([ train['text'], test['text'] ], ignore_index=True).values)\n\ntfidf_features = tfidf.get_feature_names()\n\ntrain_vects = tfidf.transform(train['text'])\ntest_vects = tfidf.transform(test['text'])","50dd3720":"tmp = pd.DataFrame.sparse.from_spmatrix(train_vects, columns=tfidf_features)\ntmp['target'] = train.target.values\ntmp = tmp.groupby('target')[tfidf_features].mean().T.sort_values(by=[1,0],ascending=False)\ntmp","e7744fad":"SEED = 42","f7ad9529":"train_X,test_X, train_y, test_y = train_test_split(train_vects,train.target, test_size=0.33,random_state=SEED,stratify=train.target)","944b8eab":"model = lgbm.LGBMClassifier(random_state=SEED,n_estimators=1000, n_jobs=-1, class_weight='balanced')\n# model = linear_model.LogisticRegressionCV(n_jobs=-1, cv=3)\n# model = ensemble.RandomForestClassifier(n_jobs=-1, random_state=SEED)","eb0fd23f":"%%time\nmodel.fit(train_X,train_y)","ff4a3a09":"y_pred = model.predict(test_X)\ny_pred_proba = model.predict_proba(test_X)[:,1] \nsns.heatmap(metrics.confusion_matrix(test_y, y_pred),annot=True,fmt='d');\nprint(metrics.classification_report(test_y, y_pred))","6f73fb69":"from sklearn.model_selection import GridSearchCV","abd6e094":"%%time\nmodel.fit(train_vects,train.target, eval_set=[(train_vects,train.target)], eval_metric='logloss', early_stopping_rounds=25, verbose=50)","232f7f32":"%%time\nresults_full = test.copy()\nresults_full['target'] = model.predict(test_vects)","42ab2f78":"results_full[['id','target']].to_csv('submissionv.csv',index=False)\nresults_full[['id','target']]","4f8b29b2":"## Data","b1e79982":"**Retrain on Full Data**","8ce92466":"## Imports","b5c32a2e":"# Real or Not? NLP with Disaster Tweets","43b833e4":"**Number of samples by target**","75f5dfb7":"## Pre-Processing","61d70df4":"## Modelling"}}