{"cell_type":{"41b71f2f":"code","e9b7de4c":"code","b7f4b161":"code","f5aab338":"code","6b9449af":"code","df1cea28":"code","267efb37":"code","afaaecdb":"code","87221ebb":"code","c2c743c4":"code","f8b7a10e":"code","65eadaa6":"code","82d00335":"code","696fd75b":"code","e387f106":"code","fd509ba6":"code","b4385189":"code","ef4bf828":"code","9a935a8c":"code","8327e010":"code","cd4c98f2":"code","dbc7eb36":"code","109dfaf2":"code","f4abaa6f":"code","fc1a276e":"code","0d7d2bc2":"code","9742f8f2":"code","e35d9668":"code","49cfafc8":"code","41557216":"code","4ec349a5":"code","26818c5f":"code","f371b62c":"code","80a4f58c":"code","dfcc4395":"code","3af2c547":"code","61679c4e":"code","6766eac6":"code","ca3cbfce":"code","0e44f4a0":"code","86e1c2fd":"code","5be0da1a":"code","d28392cc":"code","1eea2a18":"code","9b33e9ce":"code","2af4b32c":"code","04b1cd0f":"code","0fb9c0af":"code","520a0c50":"code","bce02c85":"code","46398dd4":"code","bf1c0699":"code","3b9fca23":"code","10602469":"code","866646e5":"code","f0297592":"code","ee119016":"code","210561cb":"code","e664e6a4":"code","64d50080":"code","2343aaf9":"code","e3815523":"code","eb5bad72":"code","8144414a":"code","d6679967":"code","02019b4a":"code","fb15e383":"code","0954038b":"code","f475efdd":"markdown","d98484a9":"markdown","73335b66":"markdown","0d289d07":"markdown","634cfb74":"markdown","1b8dee97":"markdown","8273e4ca":"markdown","fd71aae5":"markdown","93afb311":"markdown","9e45f905":"markdown","ae4a342e":"markdown"},"source":{"41b71f2f":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom catboost import CatBoostRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom xgboost import XGBRegressor\n\npd.set_option('display.max_columns', None)\npd.set_option('display.float_format', lambda x: '%.5f' % x)","e9b7de4c":"train = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntest = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")\ndf = train.append(test).reset_index(drop=True)\ndf.head()","b7f4b161":"def check_df(dataframe, head=5):\n    print(\"##################### Shape #####################\")\n    print(dataframe.shape)\n    print(\"##################### Types #####################\")\n    print(dataframe.dtypes)\n    print(\"##################### Head #####################\")\n    print(dataframe.head(head))\n    print(\"##################### Tail #####################\")\n    print(dataframe.tail(head))\n    print(\"##################### NA #####################\")\n    print(dataframe.isnull().sum())\n    print(\"##################### Quantiles #####################\")\n    print(dataframe.quantile([0, 0.05, 0.50, 0.95, 0.99, 1]).T)","f5aab338":"check_df(df)","6b9449af":"df.shape","df1cea28":"def grab_col_names(dataframe, cat_th=10, car_th=20):\n    # cat_cols, cat_but_car\n    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n                   dataframe[col].dtypes != \"O\"]\n    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n                   dataframe[col].dtypes == \"O\"]\n    cat_cols = cat_cols + num_but_cat\n    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n\n    # num_cols\n    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n    num_cols = [col for col in num_cols if col not in num_but_cat]\n\n    print(f\"Observations: {dataframe.shape[0]}\")\n    print(f\"Variables: {dataframe.shape[1]}\")\n    print(f'cat_cols: {len(cat_cols)}')\n    print(f'num_cols: {len(num_cols)}')\n    print(f'cat_but_car: {len(cat_but_car)}')\n    print(f'num_but_cat: {len(num_but_cat)}')\n    return cat_cols, num_cols, cat_but_car\n","267efb37":"cat_cols, num_cols, cat_but_car = grab_col_names(df)","afaaecdb":"\ndef cat_summary(dataframe, col_name, plot=False):\n    print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),\n                        \"Ratio\": 100 * dataframe[col_name].value_counts() \/ len(dataframe)}))\n    print(\"##########################################\")\n    if plot:\n        sns.countplot(x=dataframe[col_name], data=dataframe)\n        plt.show()","87221ebb":"for col in cat_cols:\n    cat_summary(df, col)","c2c743c4":"for col in cat_but_car:\n    cat_summary(df, col)","f8b7a10e":"def num_summary(dataframe, numerical_col, plot=False):\n    quantiles = [0.05, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 0.95, 0.99]\n    print(dataframe[numerical_col].describe(quantiles).T)\n\n    if plot:\n        dataframe[numerical_col].hist(bins=20)\n        plt.xlabel(numerical_col)\n        plt.title(numerical_col)\n        plt.show()\n","65eadaa6":"df[num_cols].describe().T\n\nfor col in num_cols:\n    num_summary(df, col, plot=True)","82d00335":"def missing_values_table(dataframe, na_name=False):\n    na_columns = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]\n    n_miss = dataframe[na_columns].isnull().sum().sort_values(ascending=False)\n    ratio = (dataframe[na_columns].isnull().sum() \/ dataframe.shape[0] * 100).sort_values(ascending=False)\n    missing_df = pd.concat([n_miss, np.round(ratio, 2)], axis=1, keys=['n_miss', 'ratio'])\n    print(missing_df, end=\"\\n\")\n    if na_name:\n        return na_columns\n\n\ndef missing_vs_target(dataframe, target, na_columns):\n    temp_df = dataframe.copy()\n    for col in na_columns:\n        temp_df[col + '_NA_FLAG'] = np.where(temp_df[col].isnull(), 1, 0)\n    na_flags = temp_df.loc[:, temp_df.columns.str.contains(\"_NA_\")].columns\n    for col in na_flags:\n        print(pd.DataFrame({\"TARGET_MEAN\": temp_df.groupby(col)[target].mean(),\n                            \"Count\": temp_df.groupby(col)[target].count()}), end=\"\\n\\n\\n\")\n","696fd75b":"missing_vs_target(df, \"SalePrice\", missing_values_table(df, na_name=True))\nmissing_values_table(df)","e387f106":"none_cols = ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'BsmtQual', 'BsmtCond',\n             'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'MasVnrType']\nzero_cols = ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'GarageYrBlt',\n             'GarageArea', 'GarageCars', 'MasVnrArea']\nfreq_cols = ['Exterior1st', 'Exterior2nd', 'KitchenQual', 'Electrical']\n\nfor col in zero_cols:\n    df[col].replace(np.nan, 0, inplace=True)\nfor col in none_cols:\n    df[col].replace(np.nan, \"None\", inplace=True)\nfor col in freq_cols:\n    df[col].replace(np.nan, df[col].mode()[0], inplace=True)","fd509ba6":"df[\"Alley\"] = df[\"Alley\"].fillna(\"None\")\ndf[\"PoolQC\"] = df[\"PoolQC\"].fillna(\"None\")\ndf[\"MiscFeature\"] = df[\"MiscFeature\"].fillna(\"None\")\ndf[\"Fence\"] = df[\"Fence\"].fillna(\"None\")\ndf[\"FireplaceQu\"] = df[\"FireplaceQu\"].fillna(\"None\")\ndf[\"LotFrontage\"] = df.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\n\n\ndf[\"GarageCars\"] = df[\"GarageCars\"].fillna(0)","b4385189":"df.drop(['GarageArea'], axis=1, inplace=True)\ndf.drop(['GarageYrBlt'], axis=1, inplace=True)\n","ef4bf828":"df.drop(['Utilities'], axis=1, inplace=True)","9a935a8c":"df['MSZoning'] = df.groupby('MSSubClass')['MSZoning'].apply(lambda x: x.fillna(x.mode()[0]))\n\ndf[\"Functional\"] = df[\"Functional\"].fillna(\"Typ\")\n\ndf['SaleType'] = df['SaleType'].fillna(df['SaleType'].mode()[0])\n\ndf['YrSold'] = df['YrSold'].astype(str)","8327e010":"df[\"SalePrice\"].describe([0.05, 0.10, 0.25, 0.50, 0.75, 0.80, 0.90, 0.95, 0.99])\n\ndef target_correlation_matrix(dataframe, corr_th=0.5, target=\"SalePrice\"):\n    corr = dataframe.corr()\n    corr_th = corr_th\n\n    try:\n        filter = np.abs(corr[target]) > corr_th\n        corr_features = corr.columns[filter].tolist()\n        sns.clustermap(dataframe[corr_features].corr(), annot=True, fmt=\".2f\")\n        plt.show()\n        return corr_features\n    except:\n        print(\"Y\u00fcksek threshold de\u011feri, corr_th de\u011ferinizi d\u00fc\u015f\u00fcr\u00fcn!\")\n\ntarget_correlation_matrix(df, corr_th=0.5, target=\"SalePrice\")\n","cd4c98f2":"def rare_analyser(dataframe, target, cat_cols):\n    for col in cat_cols:\n        print(col, \":\", len(dataframe[col].value_counts()))\n        print(pd.DataFrame({\"COUNT\": dataframe[col].value_counts(),\n                            \"RATIO\": dataframe[col].value_counts() \/ len(dataframe),\n                            \"TARGET_MEAN\": dataframe.groupby(col)[target].mean()}), end=\"\\n\\n\\n\")\n","dbc7eb36":"df.groupby(\"Neighborhood\").agg({\"SalePrice\": \"mean\"}).sort_values(by=\"SalePrice\", ascending=False)  ","109dfaf2":"nhood_map = {'MeadowV': 1, 'IDOTRR': 1, 'BrDale': 1,'BrkSide': 2, 'Edwards': 2, 'OldTown': 2,'Sawyer': 3, 'Blueste': 3,'SWISU': 4, 'NPkVill': 4, 'NAmes': 4, 'Mitchel': 4,'SawyerW': 5, 'NWAmes': 5,'Gilbert': 6, 'Blmngtn': 6, 'CollgCr': 6,'Crawfor': 7, 'ClearCr': 7,'Somerst': 8, 'Veenker': 8, 'Timber': 8,'StoneBr': 9, 'NridgHt': 9,'NoRidge': 10}\n\ndf['Neighborhood'] = df['Neighborhood'].map(nhood_map).astype('int')","f4abaa6f":"df= df.replace({\"MSSubClass\": {20: \"SC20\", 30: \"SC30\", 40: \"SC40\", 45: \"SC45\", \\\n50: \"SC50\", 60: \"SC60\", 70: \"SC70\", 75: \"SC75\", \\\n80: \"SC80\", 85: \"SC85\", 90: \"SC90\", 120: \"SC120\", \\\n150: \"SC150\", 160: \"SC160\", 180: \"SC180\", 190: \"SC190\"},\n\"MoSold\": {1: \"Jan\", 2: \"Feb\", 3: \"Mar\", 4: \"Apr\", 5: \"May\", 6: \"Jun\", \\\n7: \"Jul\", 8: \"Aug\", 9: \"Sep\", 10: \"Oct\", 11: \"Nov\", 12: \"Dec\"}})","fc1a276e":"func = {\"Sal\": 0, \"Sev\": 1, \"Maj2\": 2, \"Maj1\": 3, \"Mod\": 4, \"Min2\": 5, \"Min1\": 6, \"Typ\": 7}\ndf[\"Functional\"] = df[\"Functional\"].map(func).astype(\"int\")\ndf.groupby(\"Functional\").agg({\"SalePrice\": \"mean\"})","0d7d2bc2":"# MSZoning\ndf.loc[(df[\"MSZoning\"] == \"C (all)\"), \"MSZoning\"] = 1\ndf.loc[(df[\"MSZoning\"] == \"RM\"), \"MSZoning\"] = 2\ndf.loc[(df[\"MSZoning\"] == \"RH\"), \"MSZoning\"] = 2\ndf.loc[(df[\"MSZoning\"] == \"RL\"), \"MSZoning\"] = 3\ndf.loc[(df[\"MSZoning\"] == \"FV\"), \"MSZoning\"] = 3","9742f8f2":"# LotShape\ndf.groupby(\"LotShape\").agg({\"SalePrice\": \"mean\"}).sort_values(by=\"SalePrice\", ascending=False)\nshape_map = {\"Reg\": 1, \"IR1\": 2, \"IR3\": 3, \"IR2\": 4}\ndf['LotShape'] = df['LotShape'].map(shape_map).astype('int')","e35d9668":"# LandContour\ndf.groupby(\"LandContour\").agg({\"SalePrice\": \"mean\"}).sort_values(by=\"SalePrice\", ascending=False)\ncontour_map = {\"Bnk\": 1, \"Lvl\": 2, \"Low\": 3, \"HLS\": 4}\ndf['LandContour'] = df['LandContour'].map(contour_map).astype('int')","49cfafc8":"cat_cols, num_cols, cat_but_car = grab_col_names(df)\nrare_analyser(df, \"SalePrice\", cat_cols)","41557216":"# LotConfig\ndf.loc[(df[\"LotConfig\"] == \"Inside\"), \"LotConfig\"] = 1\ndf.loc[(df[\"LotConfig\"] == \"FR2\"), \"LotConfig\"] = 1\ndf.loc[(df[\"LotConfig\"] == \"Corner\"), \"LotConfig\"] = 1\ndf.loc[(df[\"LotConfig\"] == \"FR3\"), \"LotConfig\"] = 2\ndf.loc[(df[\"LotConfig\"] == \"CulDSac\"), \"LotConfig\"] = 2","4ec349a5":"# Condition1\ncond1_map = {\"Artery\": 1, \"RRAe\": 1, \"Feedr\": 1,\"Norm\": 2, \"RRAn\": 2, \"RRNe\": 2,\"PosN\": 3, \"RRNn\": 3, \"PosA\": 3}\ndf['Condition1'] = df['Condition1'].map(cond1_map).astype('int')\n","26818c5f":"# BldgType\ndf.loc[(df[\"BldgType\"] == \"2fmCon\"), \"BldgType\"] = 1\ndf.loc[(df[\"BldgType\"] == \"Duplex\"), \"BldgType\"] = 1\ndf.loc[(df[\"BldgType\"] == \"Twnhs\"), \"BldgType\"] = 1\ndf.loc[(df[\"BldgType\"] == \"1Fam\"), \"BldgType\"] = 2\ndf.loc[(df[\"BldgType\"] == \"TwnhsE\"), \"BldgType\"] = 2\n\n# RoofStyle\ndf.groupby(\"RoofStyle\").agg({\"SalePrice\": \"mean\"}).sort_values(by=\"SalePrice\", ascending=False)\ndf.loc[(df[\"RoofStyle\"] == \"Gambrel\"), \"RoofStyle\"] = 1\ndf.loc[(df[\"RoofStyle\"] == \"Gablee\"), \"RoofStyle\"] = 2\ndf.loc[(df[\"RoofStyle\"] == \"Mansard\"), \"RoofStyle\"] = 3\ndf.loc[(df[\"RoofStyle\"] == \"Flat\"), \"RoofStyle\"] = 4\ndf.loc[(df[\"RoofStyle\"] == \"Hip\"), \"RoofStyle\"] = 5\ndf.loc[(df[\"RoofStyle\"] == \"Shed\"), \"RoofStyle\"] = 6\n\n# RoofMatl\ndf.groupby(\"RoofMatl\").agg({\"SalePrice\": \"mean\"}).sort_values(by=\"SalePrice\", ascending=False)\ndf.loc[(df[\"RoofMatl\"] == \"Roll\"), \"RoofMatl\"] = 1\ndf.loc[(df[\"RoofMatl\"] == \"ClyTile\"), \"RoofMatl\"] = 2\ndf.loc[(df[\"RoofMatl\"] == \"CompShg\"), \"RoofMatl\"] = 3\ndf.loc[(df[\"RoofMatl\"] == \"Metal\"), \"RoofMatl\"] = 3\ndf.loc[(df[\"RoofMatl\"] == \"Tar&Grv\"), \"RoofMatl\"] = 3\ndf.loc[(df[\"RoofMatl\"] == \"WdShake\"), \"RoofMatl\"] = 4\ndf.loc[(df[\"RoofMatl\"] == \"Membran\"), \"RoofMatl\"] = 4\ndf.loc[(df[\"RoofMatl\"] == \"WdShngl\"), \"RoofMatl\"] = 5","f371b62c":"cat_cols, num_cols, cat_but_car = grab_col_names(df)\nrare_analyser(df, \"SalePrice\", cat_cols)","80a4f58c":"# ExterQual\ndf.groupby(\"ExterQual\").agg({\"SalePrice\": \"mean\"}).sort_values(by=\"SalePrice\", ascending=False)\next_map = {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\ndf['ExterQual'] = df['ExterQual'].map(ext_map).astype('int')\n\n# ExterCond\next_map = {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\ndf['ExterCond'] = df['ExterCond'].map(ext_map).astype('int')\n\n# BsmtQual\nbsm_map = {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\ndf['BsmtQual'] = df['BsmtQual'].map(bsm_map).astype('int')\n\n# BsmtCond\nbsm_map = {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\ndf['BsmtCond'] = df['BsmtCond'].map(bsm_map).astype('int')","dfcc4395":"cat_cols, num_cols, cat_but_car = grab_col_names(df)\nrare_analyser(df, \"SalePrice\", cat_cols)","3af2c547":"# BsmtFinType1\nbsm_map = {'None': 0, 'Rec': 1, 'BLQ': 1, 'LwQ': 2, 'ALQ': 3, 'Unf': 3, 'GLQ': 4}\ndf['BsmtFinType1'] = df['BsmtFinType1'].map(bsm_map).astype('int')\n\n# BsmtFinType2\nbsm_map = {'None': 0, 'BLQ': 1, 'Rec': 2, 'LwQ': 2, 'Unf': 3, 'GLQ': 3, 'ALQ': 4}\ndf['BsmtFinType2'] = df['BsmtFinType2'].map(bsm_map).astype('int')\n\n# BsmtExposure\nbsm_map = {'None': 0, 'No': 1, 'Mn': 2, 'Av': 3, 'Gd': 4}\ndf['BsmtExposure'] =df['BsmtExposure'].map(bsm_map).astype('int')\n\n# Heating\nheat_map = {'Floor': 1, 'Grav': 1, 'Wall': 2, 'OthW': 3, 'GasW': 4, 'GasA': 5}\ndf['Heating'] = df['Heating'].map(heat_map).astype('int')\n\n# HeatingQC\nheat_map = {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\ndf['HeatingQC'] = df['HeatingQC'].map(heat_map).astype('int')\n\n# KitchenQual\nkitch_map = {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\ndf['KitchenQual'] = df['KitchenQual'].map(heat_map).astype('int')\n\n# FireplaceQu\nfire_map = {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\ndf['FireplaceQu'] = df['FireplaceQu'].map(fire_map).astype('int')\n\n# GarageCond\ngarage_map = {'None': 1, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\ndf['GarageCond'] = df['GarageCond'].map(garage_map).astype('int')\n\n# GarageQual\ngarage_map = {'None': 1, 'Po': 1, 'Fa': 2, 'TA': 3, 'Ex': 4, 'Gd': 5}\ndf['GarageQual'] = df['GarageQual'].map(garage_map).astype('int')\n\n# PavedDrive\npaved_map = {'N': 1, 'P': 2, 'Y': 3}\ndf['PavedDrive'] = df['PavedDrive'].map(paved_map).astype('int')\n\n# CentralAir\ncent = {\"N\": 0, \"Y\": 1}\ndf[\"CentralAir\"] = df[\"CentralAir\"].map(cent).astype(\"int\")\ndf.groupby(\"CentralAir\").agg({\"SalePrice\": \"mean\"})\n\n# LandSlope\ndf.loc[df[\"LandSlope\"] == \"Gtl\", \"LandSlope\"] = 1\ndf.loc[df[\"LandSlope\"] == \"Sev\", \"LandSlope\"] = 2\ndf.loc[df[\"LandSlope\"] == \"Mod\", \"LandSlope\"] = 2\ndf[\"LandSlope\"] = df[\"LandSlope\"].astype(\"int\")\n\n# OverallQual\ndf.loc[df[\"OverallQual\"] == 1, \"OverallQual\"] = 1\ndf.loc[df[\"OverallQual\"] == 2, \"OverallQual\"] = 1\ndf.loc[df[\"OverallQual\"] == 3, \"OverallQual\"] = 1\ndf.loc[df[\"OverallQual\"] == 4, \"OverallQual\"] = 2\ndf.loc[df[\"OverallQual\"] == 5, \"OverallQual\"] = 3\ndf.loc[df[\"OverallQual\"] == 6, \"OverallQual\"] = 4\ndf.loc[df[\"OverallQual\"] == 7, \"OverallQual\"] = 5\ndf.loc[df[\"OverallQual\"] == 8, \"OverallQual\"] = 6\ndf.loc[df[\"OverallQual\"] == 9, \"OverallQual\"] = 7\ndf.loc[df[\"OverallQual\"] == 10, \"OverallQual\"] = 8","61679c4e":"cat_cols, num_cols, cat_but_car = grab_col_names(df)\nrare_analyser(df, \"SalePrice\", cat_cols)","6766eac6":"df[\"NEW\"] = df[\"GarageCars\"] * df[\"OverallQual\"]\ndf[\"NEW3\"] = df[\"TotalBsmtSF\"] * df[\"1stFlrSF\"]\ndf[\"NEW4\"] = df[\"TotRmsAbvGrd\"] * df[\"GrLivArea\"]\ndf[\"NEW5\"] = df[\"FullBath\"] * df[\"GrLivArea\"]\ndf[\"NEW6\"] = df[\"YearBuilt\"] * df[\"YearRemodAdd\"]\ndf[\"NEW7\"] = df[\"OverallQual\"] * df[\"YearBuilt\"]\ndf[\"NEW8\"] = df[\"OverallQual\"] * df[\"RoofMatl\"]\ndf[\"NEW9\"] = df[\"PoolQC\"] * df[\"OverallCond\"]\ndf[\"NEW10\"] = df[\"OverallCond\"] * df[\"MasVnrArea\"]\ndf[\"NEW11\"]  = df[\"LotArea\"] * df[\"GrLivArea\"]\ndf[\"NEW12\"] = df[\"FullBath\"] * df[\"GrLivArea\"]\ndf[\"NEW13\"] = df[\"FullBath\"] * df[\"TotRmsAbvGrd\"]\ndf[\"NEW14\"] = df[\"1stFlrSF\"] *df[\"TotalBsmtSF\"]\ndf[\"New_Home_Quality\"] =  df[\"OverallCond\"] \/ df[\"OverallQual\"]\ndf['POOL'] = df['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\ndf['HAS2NDFLOOR'] = df['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\ndf[\"LUXURY\"] = df[\"1stFlrSF\"] + df[\"2ndFlrSF\"]\ndf[\"New_TotalBsmtSFRate\"] = df[\"TotalBsmtSF\"] \/ df[\"LotArea\"]\ndf['TotalPorchArea'] = df['WoodDeckSF'] + df['OpenPorchSF'] + df['EnclosedPorch'] + df['3SsnPorch'] + df['ScreenPorch']\ndf['IsNew'] = df.YearBuilt.apply(lambda x: 1 if x > 2000 else 0)\ndf['IsOld'] = df.YearBuilt.apply(lambda x: 1 if x < 1946 else 0)\n","ca3cbfce":"def rare_encoder(dataframe, rare_perc, cat_cols):\n    temp_df = dataframe.copy()\n\n    rare_columns = [col for col in dataframe.columns if (dataframe[col].value_counts() \/ len(dataframe) < 0.01).sum()>1]\n\n    for var in rare_columns:\n        tmp = dataframe[col].value_counts() \/ len(dataframe)\n        rare_labels = tmp[tmp < rare_perc].index\n        dataframe[col] = np.where(dataframe[col].isin(rare_labels), 'Rare', dataframe[col])\n\n    return temp_df","0e44f4a0":"rare_analyser(df, \"SalePrice\", cat_cols)\n\ndf = rare_encoder(df, 0.01, cat_cols)\n\nrare_analyser(df, \"SalePrice\", cat_cols)","86e1c2fd":"useless_cols = [col for col in cat_cols if df[col].nunique() == 1 or\n                (df[col].nunique() == 2 and (df[col].value_counts() \/ len(df) <= 0.02).any(axis=None))]\n\n\nuseless_cols","5be0da1a":"cat_cols = [col for col in cat_cols if col not in useless_cols]\ndf.shape","d28392cc":"for col in useless_cols:\n    df.drop(col, axis=1, inplace=True)\ndf.shape","1eea2a18":"rare_analyser(df, \"SalePrice\", cat_cols)","9b33e9ce":"def label_encoder(dataframe, binary_col):\n    labelencoder = LabelEncoder()\n    dataframe[binary_col] = labelencoder.fit_transform(dataframe[binary_col])\n    return dataframe\n\n\n\ndef one_hot_encoder(dataframe, categorical_cols, drop_first=False):\n    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)\n    return dataframe","2af4b32c":"df = one_hot_encoder(df, cat_cols, drop_first=True)\ndf.shape","04b1cd0f":"cat_cols, num_cols, cat_but_car = grab_col_names(df)","0fb9c0af":"rare_analyser(df, \"SalePrice\", cat_cols)","520a0c50":"useless_cols_new = [col for col in cat_cols if (df[col].value_counts() \/ len(df) <= 0.01).any(axis=None)]\nuseless_cols_new","bce02c85":"for col in useless_cols_new:\n    df.drop(col, axis=1, inplace=True)\ndf.shape","46398dd4":"missing_values_table(df)\n\ntest.shape\n\nmissing_values_table(train)\n\n\nna_cols = [col for col in df.columns if df[col].isnull().sum() > 0 and \"SalePrice\" not in col]\n\ndf[na_cols] = df[na_cols].apply(lambda x: x.fillna(x.median()), axis=0)","bf1c0699":"def outlier_thresholds(dataframe, col_name, q1=0.10, q3=0.90):\n    quartile1 = dataframe[col_name].quantile(q1)\n    quartile3 = dataframe[col_name].quantile(q3)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit\n\ndef replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n\n\ndef check_outlier(dataframe, col_name):\n    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n        return True\n    else:\n        return False","3b9fca23":"cat_cols, num_cols, cat_but_car = grab_col_names(df)\n\nfor col in num_cols:\n    print(col, check_outlier(df, col))\n\nfor col in num_cols:\n    replace_with_thresholds(df, col)","10602469":"for col in num_cols:\n    print(col, check_outlier(df, col))","866646e5":"train_df = df[df['SalePrice'].notnull()]\ntest_df = df[df['SalePrice'].isnull()].drop(\"SalePrice\", axis=1)\n\n\ny = np.log1p(train_df['SalePrice'])\nX = train_df.drop([\"Id\", \"SalePrice\"], axis=1)","f0297592":"models = [('LR', LinearRegression()),\n          (\"Ridge\", Ridge()),\n          (\"Lasso\", Lasso()),\n          (\"ElasticNet\", ElasticNet()),\n          ('KNN', KNeighborsRegressor()),\n          ('CART', DecisionTreeRegressor()),\n          ('RF', RandomForestRegressor()),\n          ('SVR', SVR()),\n          ('GBM', GradientBoostingRegressor()),\n          (\"XGBoost\", XGBRegressor(objective='reg:squarederror')),\n          (\"LightGBM\", LGBMRegressor()),\n          (\"CatBoost\", CatBoostRegressor(verbose=False))]","ee119016":"for name, regressor in models:\n    rmse = np.mean(np.sqrt(-cross_val_score(regressor, X, y, cv=5, scoring=\"neg_mean_squared_error\")))\n    print(f\"RMSE: {round(rmse, 4)} ({name}) \")","210561cb":"lgbm_model = LGBMRegressor(random_state=46)\n\n# modelleme \u00f6ncesi hata:\nrmse = np.mean(np.sqrt(-cross_val_score(lgbm_model,\n                                        X, y, cv=10, scoring=\"neg_mean_squared_error\")))\n","e664e6a4":"lgbm_params = {\"learning_rate\": [0.01, 0.1, 0.03, 0.2, 0.5],\n               \"n_estimators\": [100, 200, 250, 500, 1500],\n               \"colsample_bytree\": [0.3,0.4, 0.5, 0.7, 1]}","64d50080":"lgbm_gs_best = GridSearchCV(lgbm_model,\n                            lgbm_params,\n                            cv=3,\n                            n_jobs=-1,\n                            verbose=True).fit(X, y)","2343aaf9":"final_model_lgbm = lgbm_model.set_params(**lgbm_gs_best.best_params_).fit(X, y)\nrmse = np.mean(np.sqrt(-cross_val_score(final_model_lgbm, X, y, cv=10, scoring=\"neg_mean_squared_error\")))","e3815523":"rmse","eb5bad72":"# CatBoost\n\ncatboost_model = CatBoostRegressor(random_state = 46)\n\ncatboost_params = {\"iterations\": [200, 250, 300, 500],\n                   \"learning_rate\": [0.01, 0.1, 0.2, 0.5],\n                   \"depth\": [3, 6]}\n\nrmse = np.mean(np.sqrt(-cross_val_score(catboost_model,\n                                        X, y, cv=5, scoring=\"neg_mean_squared_error\")))","8144414a":"cat_gs_best = GridSearchCV(catboost_model,\ncatboost_params,cv=3,n_jobs=-1,verbose=False).fit(X, y)\n\nfinal_model_cat = catboost_model.set_params(**cat_gs_best.best_params_).fit(X, y)\n\nrmse = np.mean(np.sqrt(-cross_val_score(final_model_cat, X, y, cv=10, scoring=\"neg_mean_squared_error\")))","d6679967":"rmse","02019b4a":"# GBM\n\ngbm_model = GradientBoostingRegressor(random_state=46)\n\nrmse = np.mean(np.sqrt(-cross_val_score(gbm_model,\n                                        X, y, cv=5, scoring=\"neg_mean_squared_error\")))\n\ngbm_params = {\"learning_rate\": [0.01,0.05,0.1],\"max_depth\": [3,5,8],\"n_estimators\": [500,1000,1500],\"subsample\": [1, 0.5, 0.7]}","fb15e383":"gbm_gs_best = GridSearchCV(gbm_model,gbm_params,cv=5,n_jobs=-1,verbose=True).fit(X, y)\n\nfinal_model_gbm = gbm_model.set_params(**gbm_gs_best.best_params_).fit(X, y)\n\nrmse = np.mean(np.sqrt(-cross_val_score(final_model_gbm, X, y, cv=10, scoring=\"neg_mean_squared_error\")))","0954038b":"rmse","f475efdd":"**Data Preprocessing & Feature Engineering**","d98484a9":"**Numerical Features Analysis**","73335b66":"**Hyperparameter Optimization**","0d289d07":"**Label Encoding & One-Hot Encoding**","634cfb74":"**Target Analysis**","1b8dee97":"**Base Models**","8273e4ca":"**EDA**","fd71aae5":"**Missing Values Analysis**","93afb311":"**MODELING**","9e45f905":"**Categorical Features Analysis**","ae4a342e":"**Check Outliers**"}}