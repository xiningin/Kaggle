{"cell_type":{"0b0dc176":"code","677a63d8":"code","7cb69f40":"code","dc619da2":"code","7c80148d":"code","041b9748":"code","eaab0a59":"code","2a8a68c5":"code","9c4eb4eb":"code","f4a6fb20":"code","9cc784cb":"code","26be372f":"code","021da7db":"code","640bb9eb":"code","47bb16ed":"code","d587f0c3":"code","d44eb3a5":"code","1f07d98d":"code","7660b34a":"code","79cd11a6":"code","322ebd49":"code","8c36b77b":"code","853054f7":"code","b2c1bc82":"code","1fabce0f":"code","0bccf222":"code","3d8df333":"code","88ff3071":"code","98ff3e3b":"code","ef59c8c5":"code","1dfb492e":"code","9090be53":"code","69c3c829":"code","1eacb090":"code","82a67dc1":"code","febaea96":"code","f5fc6a5c":"code","473f1926":"code","cea6adc8":"markdown","1201c23a":"markdown","9c3abebf":"markdown","d63154d6":"markdown","90252abd":"markdown","eaec2ef1":"markdown","f31a098d":"markdown","4d576be1":"markdown","7794f63f":"markdown","21d654c1":"markdown","d2783ac4":"markdown","f1064cf9":"markdown","8cd68765":"markdown","de39929b":"markdown","69cb1a55":"markdown","37328b50":"markdown","b7e30c07":"markdown","a3db5fa1":"markdown"},"source":{"0b0dc176":"#importing required libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport datetime as dt\nimport sklearn\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import learning_curve\nfrom sklearn import datasets\n%matplotlib inline","677a63d8":"df= pd.read_csv('winequality_white.csv', delimiter = ',')","7cb69f40":"df.head()","dc619da2":"df[\"quality\"].unique()\nquality_count_per_class = df[\"quality\"].value_counts()\nprint(\"Number of data points per class:\\n\", quality_count_per_class)\n","7c80148d":"df.shape[0]","041b9748":"df.count()","eaab0a59":"df.head()","2a8a68c5":"df.describe()","9c4eb4eb":"random_state=sklearn.utils.shuffle(df)","f4a6fb20":"random_state.head(200)","9cc784cb":"plt.scatter(df.pH, df.quality)\nplt.xlabel(\"pH\"), plt.ylabel(\"quality\")\nplt.show()","26be372f":"Y=df.pH\nX=df.drop('pH',axis=1)","021da7db":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)","640bb9eb":"np.mean(X)","47bb16ed":"np.std(X)","d587f0c3":"sc = StandardScaler()\npca = PCA(n_components=2)\nX_train = pca.fit_transform(X_train)\nX_test = pca.transform(X_test)","d44eb3a5":"data1 = pd.DataFrame(data = X_train\n             , columns = ['PC1', 'PC2'])","1f07d98d":"data1.tail()","7660b34a":"Y=data1.PC1\nX=data1.drop('PC1',axis=1)","79cd11a6":"plt.scatter(data1.PC1, data1.PC2, s=20, c=data1.PC1, cmap='cool')\nplt.xlabel(\"PC1\"), plt.ylabel(\"PC2\")\nplt.grid(True)\nplt.colorbar()\nplt.show()","322ebd49":"explained_variance=pca.explained_variance_ratio_\nexplained_variance","8c36b77b":"pca.get_covariance()","853054f7":"\nX_train = df[1000:4898]","b2c1bc82":"X_train.shape","1fabce0f":"df.tail()","0bccf222":"X_test = df[0:1000]","3d8df333":"X_test.shape","88ff3071":"X_test.head()","98ff3e3b":"validation = df[0:1000]","ef59c8c5":"validation.shape","1dfb492e":"validation.head()","9090be53":"def plot_learning_curve(pH, title, X, y, ylim=None, cv=None,\n                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n    \"\"\"\n    \n    \"\"\"","69c3c829":"train_sizes = [0.1, 0.2, 0.3, 0.4, 0.5,0.6, 0.7, 0.8, 0.9, 1.0]","1eacb090":"df.head()","82a67dc1":"ff = ['chlorides', 'density', 'pH', 'sulphates']\ntarget = 'quality'","febaea96":"train_sizes, train_scores, validation_scores = learning_curve(\n                                                   estimator = LinearRegression(), X = df[ff],\n                                                   y = df[target], train_sizes =np.linspace(0.1, 1, 10), cv = 5,\n                                                   scoring = 'neg_mean_squared_error')","f5fc6a5c":"train_mean = np.mean(validation_scores, axis=1)\ntrain_std = np.std(validation_scores, axis=1)\ntest_mean = np.mean(validation_scores, axis=1)\ntest_std = np.std(validation_scores, axis=1)","473f1926":"plt.grid()\nplt.plot(train_sizes, train_mean,'o-',color='r',  label=\"Training score\")\nplt.plot(train_sizes, test_mean,color='g', label=\"Cross-validation score\")\nplt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std)\nplt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std)\nplt.title(\"My Class Learning Curve\")\nplt.xlabel(\"Training Set\"), plt.ylabel(\"Perfromance Measurment\"), plt.legend(loc=\"best\")\nplt.tight_layout()\nplt.show()","cea6adc8":"# a. Summarize your findings for each task.","1201c23a":"#There is no problem with experimental design. Results shows that the performance measure increases with the number of rows (the size of the dataset) involved in the processing (training set). The training set is part of the process used in the training of the algorithm.","9c3abebf":"# a. Produce a learning curve of the size of training set against the performance measurements","d63154d6":"# Task 2: PCA Analysis on the white-wine dataset Using Scikit-Learn","90252abd":"# Training set section","eaec2ef1":"# Validation set section","f31a098d":"learning purpose only\n","4d576be1":"# Task 3: Divide the white_wine dataset into a training set, a validation set, and a test set.","7794f63f":"# Test set section","21d654c1":"# Task 4: Investigate how the size of the training dataset affects the model performance on the test set.","d2783ac4":"# Task 5: Critical Discussion","f1064cf9":"# c. Report the performance on the test set obtained using the model trained from the best size. ","8cd68765":"# b. Report what the best training data size you would like to use for this work is and explain why you choose it?","de39929b":"# b. For Task 4, discuss whether there is any problem with that experimental design. If there is, what is it? How may you further improve it so that the experimental results are more reliable?","69cb1a55":"#Increase in the number of training set from 500 to maximum of 4000 have a slight increase on performance measure. Notably, the last sets of training set have reached the maximum performnace measure. Towards the last set of 4000 training set,the curve remains almost flat. ","37328b50":"#The best data set I would like to use is 10% of the data. The reason is due to its optimal size to manipulate and train for ease of learning. ","b7e30c07":"#The line test_size=0.2 set above suggests that the test data should be 20% of the dataset and the rest should be train data. ","a3db5fa1":"#The dataset has 4898 number of rows.\nThe quality of wine has been found to remain constant despite increase in pH value of the wine content.  \nThe variance of the data is 0.08333333 as detailed from the PCA data projection. Both validation and test sets are saved at first 1000 rows of the dataset. The training set of the dataset has been set on the rest of the dataset rows, which represents rows above 1000. \nIn the training of the data, 10% of the dataset would be the best one for ease of training the algorithm.  "}}