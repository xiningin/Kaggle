{"cell_type":{"5a8f41b8":"code","4321a6d8":"code","6835ddf0":"code","c00b2fa9":"code","4f0c02b6":"code","7b9fb69e":"code","50ad0547":"code","f755e1d3":"code","c8a14444":"code","418b8765":"code","20c99bae":"code","0bde4767":"code","d7535ae2":"code","0e6461a7":"code","1446dd4f":"code","68306a19":"code","8d2b1894":"code","929084bc":"markdown","daaa6d65":"markdown","d26d38b8":"markdown","3b9a0e90":"markdown","e6fa71c9":"markdown","28b032b1":"markdown","2e0f56de":"markdown","cecc21d1":"markdown","047166ed":"markdown","cc7cbfd1":"markdown","5e4d86e2":"markdown","cf01066d":"markdown","fa51b55b":"markdown","f0547385":"markdown"},"source":{"5a8f41b8":"# Import the libraries\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\nsns.set()\n%matplotlib inline","4321a6d8":"raw_data = pd.read_csv('..\/input\/dataset\/titanic.csv')\nraw_data.head()","6835ddf0":"# Overview of the data\nraw_data.describe(include='all')","c00b2fa9":"# Drop the unnecessary columns\ndata = raw_data.drop(['PassengerId','Name','SibSp','Parch','Ticket','Cabin','Embarked'], axis='columns')\ndata.head()","4f0c02b6":"# Dealing with missing values\nmv = data.isnull().sum()\nmv","7b9fb69e":"# Remove all the data that has missing values\ndata_no_mv = data.dropna(axis=0)\ndata_no_mv.describe(include='all')","50ad0547":"data_with_dummies = pd.get_dummies(data_no_mv, drop_first=True)\ndata_with_dummies.head()","f755e1d3":"corr_matrix = data_with_dummies.corr().round(2)  # Round to 2 decimal places\nsns.heatmap(data=corr_matrix, annot=True)  # Set annot = True to print the values inside the squares\nplt.show()","c8a14444":"# Drop the 'Fare' column\ndata_no_multicollinearity = data_with_dummies.drop('Fare', axis=1)\ndata_no_multicollinearity.head()","418b8765":"# Plot the distribution of 'Age'\nsns.distplot(data_no_multicollinearity['Age'])\nplt.show()","20c99bae":"# Declaring the features and the label\nfeatures = data_no_multicollinearity.drop('Survived', axis=1)\nlabel = data_no_multicollinearity['Survived']","0bde4767":"# Split the data into training and test sets, in a 80:20 ratio\nX_train, X_test, y_train, y_test = train_test_split(features, label, test_size=0.2, random_state=1)","d7535ae2":"# Build and fit the model\nclf = GaussianNB()\nclf.fit(X_train, y_train)","0e6461a7":"# Making predictions\npred = clf.predict(X_test)","1446dd4f":"# Measuring the accuracy of the model\nacc = accuracy_score(y_test, pred)\nacc","68306a19":"# Create a Confusion Matrix\nmatrix = pd.DataFrame(\n        confusion_matrix(y_test, pred),\n        columns=['Predicted 0', 'Predicted 1'],\n        index=['Actual 0', 'Actual 1'])\nmatrix","8d2b1894":"# Create a classification report\nprint(classification_report(y_test,pred))","929084bc":"# Gaussian Naive Bayes Classifier on Titanic Dataset\nThis project is one of my Machine Learning mini projects. For this project, we have a [Titanic](https:\/\/github.com\/richardcsuwandi\/datasets\/blob\/master\/titanic.csv) dataset that contains the the passengers information like name, age, gender, socio-economic class, etc. The dataset can be found on Kaggle: https:\/\/www.kaggle.com\/c\/titanic\/data\n\nThe goal of this project is to create a Gaussian Naive Bayes Classifier model to classify whether the passenger survived the Titanic shipwreck or not.","daaa6d65":"## Exploratory Data Analysis (EDA)\nBefore we begin fitting a Gaussian Naive Bayes Classifier model on the data, let's try and eyeball it first. Here, we will make some explorations and visualizations to understand the relationship of the target variable with other features.","d26d38b8":"### Cleaning The Data\nDropping unnecessary columns and clearing the missing values","3b9a0e90":"### Creating Dummy Variables\nConverts categorical values in the 'Sex' column into numerical values.","e6fa71c9":"## Building the Model\nFinally, we can build our Gaussian Naive Bayes Classifier model from the Titanic dataset.","28b032b1":"## Predictions and Evaluations","2e0f56de":"From the plot above, it seems that 'Age' has a distribution that is close enough to Gaussian. So, applying the Gaussian Naive Bayes model on the data might be a good idea.","cecc21d1":"Notice that we drop the 'Sex_female' column because according to the Dummy Variable Trap theory, one column is enough to represent male or female.","047166ed":"From the correlation matrix above, we can observe that 'Pclass' and 'Fare' have a correlation of -0.55. This suggests that these feature pairs are strongly correlated to each other. Considering multicollinearity, let's drop the 'Fare' column since it has lower correlation with 'Survived' compared to 'Pclass'.","cc7cbfd1":"### Creating a correlation matrix\nThe correlation matrix is used to measure the linear relationships between the variables.","5e4d86e2":"## Loading the Data","cf01066d":"## Preprocessing the Data","fa51b55b":"### Plotting the distribution\nSince our 'Age' column has continuous numeric values, we can plot its distribution.","f0547385":"As we can see above, some columns might not be useful and our data seems to have some missing values. So, we have to clean our data first"}}