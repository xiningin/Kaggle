{"cell_type":{"f7a2ac08":"code","d8c1fe9f":"code","4b19699c":"code","984efc09":"code","72c7474c":"code","57caaf5b":"code","ad1bc23b":"code","b30de91c":"code","e6fcf3c6":"code","835f559d":"code","4b4ec509":"code","a6a4f1f7":"code","1828498a":"code","5a358463":"code","ada1d300":"code","81970288":"code","4cfc0bcc":"code","16398229":"code","75988e1a":"code","9e151c55":"code","235f2225":"code","fe2b7f4d":"code","41af42dd":"code","9a1e4def":"markdown","05d038e5":"markdown","a627066b":"markdown","f6e22f65":"markdown","11d17b7e":"markdown","600855b0":"markdown","f68e889a":"markdown","bc5d8cd4":"markdown","2365ca76":"markdown"},"source":{"f7a2ac08":"import os\nimport glob\n\nimport numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport matplotlib.image as mpimg\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout","d8c1fe9f":"! ls ..\/input\/siim-isic-melanoma-classification","4b19699c":"train = pd.read_csv('..\/input\/siim-isic-melanoma-classification\/train.csv')\ntrain.head()","984efc09":"test = pd.read_csv('..\/input\/siim-isic-melanoma-classification\/test.csv')\ntest.head()","72c7474c":"sample_submission = pd.read_csv('..\/input\/siim-isic-melanoma-classification\/sample_submission.csv')\nsample_submission.head()","57caaf5b":"print('No. of images in the train dataset :', train.shape[0])\nprint('No. of unique patients in train dataset :', train['patient_id'].nunique())","ad1bc23b":"print('No. of images in the test dataset :', test.shape[0])\nprint('No. of unique patients in test dataset :', test['patient_id'].nunique())","b30de91c":"def count_hbar(col, title, pal='Dark2'):\n    df = pd.DataFrame(train[col].value_counts()).reset_index()\n    \n    sns.set_style('whitegrid')\n\n    sns.barplot(data=df, x=col, y='index', palette=pal)\n    \n    for ind, row in df.iterrows():\n        plt.text(row[col]+500, ind, row[col])\n        \n    \n    sns.despine(bottom=True)\n    plt.title(title)\n    plt.xlabel('')\n    plt.ylabel('')\n    plt.show()","e6fcf3c6":"count_hbar('sex', 'Gender', ['royalblue', 'deeppink'])","835f559d":"count_hbar('anatom_site_general_challenge', 'Anatomy site of the mole')","4b4ec509":"count_hbar('diagnosis', 'Diagnosis  of the mole')","a6a4f1f7":"count_hbar('benign_malignant', 'Benign or Malignant', ['dimgray', 'orangered'])","1828498a":"temp = train.groupby('patient_id').agg({'sex':max, 'age_approx':np.mean}).reset_index()\n\nplt.figure(figsize=(12, 5))\nsns.kdeplot(temp[temp['sex']=='male']['age_approx'], label='Male', shade=True, color='royalblue')\nsns.kdeplot(temp[temp['sex']=='female']['age_approx'], label='Female', shade=True, color='deeppink')\nplt.title('Age distribution Male and Female patients', \n          loc='left', fontsize=16)\nplt.show()","5a358463":"df = pd.DataFrame(train.groupby(['anatom_site_general_challenge'])['target'].mean()) \\\n        .sort_values('target', ascending=False) \\\n        .reset_index() \ndf['target'] = round(df['target'], 4)\n\nplt.figure(figsize=(12, 5))\nsns.set_style('darkgrid')\n\nsns.barplot(data=df, x='target', y='anatom_site_general_challenge', palette='Set2')\n\nfor ind, row in df.iterrows():\n    plt.text(row['target']+0.0001, ind+0.1, row['target'])\n\nsns.despine(bottom=True)\nplt.title('Probability of mole being a Malignant one wrt to it\\'s possition on the human body', \n          loc='left', fontsize=16)\nplt.xlabel('')\nplt.ylabel('')\nplt.show()","ada1d300":"def plot_images(diagnosis, title, n):\n    temp = train[train['diagnosis']==diagnosis]\n    img_ids = ['..\/input\/siim-isic-melanoma-classification\/jpeg\/train\/'+i+'.jpg' for i in temp['image_name'].sample(n)]\n\n    fig, ax = plt.subplots(figsize=(24, 5))\n    fig.suptitle(title, fontsize=24)\n    for ind, img in enumerate(img_ids[:n]):\n        plt.subplot(1, 5, ind+1)\n        image = plt.imread(img) # read image\n        plt.axis('off')\n        plt.imshow(image)","81970288":"def plot_image(diagnosis, title):\n    temp = train[train['diagnosis']==diagnosis]\n    img_ids = ['..\/input\/siim-isic-melanoma-classification\/jpeg\/train\/'+i+'.jpg' for i in temp['image_name']]\n    \n    plt.figure(figsize = (4, 4))\n    image = plt.imread(img_ids[0])\n    plt.axis('off')\n    plt.title(title, fontsize=16)\n    plt.imshow(image)\n    plt.show()","4cfc0bcc":"plot_images('melanoma', 'Melanoma', 5)","16398229":"plot_images('seborrheic keratosis', 'Seborrheic Keratosis', 5)","75988e1a":"plot_images('lichenoid keratosis', 'Lichenoid Keratosis', 5)","9e151c55":"plot_images('lentigo NOS', 'Lentigo NOS', 5)","235f2225":"plot_images('solar lentigo', 'Solar Lentigo', 5)","fe2b7f4d":"plot_image('cafe-au-lait macule', 'Cafe-au-lait Macule')","41af42dd":"plot_image('atypical melanocytic proliferation', 'Atypical Melanocytic Proliferation')","9a1e4def":"## Images","05d038e5":"### Value counts","a627066b":"### Read dataset","f6e22f65":"## Context    \n> * Skin cancer is the most prevalent type of cancer.    \n> * Melanoma, specifically, is responsible for 75% of skin cancer deaths, despite being the least common skin cancer.    \n> * The American Cancer Society estimates over 100,000 new melanoma cases will be diagnosed in 2020.    \n> * It's also expected that almost 7,000 people will die from the disease.    \n> * As with other cancers, early and accurate detection\u2014potentially aided by data science\u2014can make treatment more effective. \n   \n## Task    \n> * In this competition, you\u2019ll identify melanoma in images of skin lesions.    \n> * In particular, you\u2019ll use images within the same patient and determine which are likely to represent a melanoma.    \n> * Using patient-level contextual information may help the development of image analysis tools, which could better support clinical dermatologists.    \n   \n## What should I expect the data format to be?    \n> * The images are provided in DICOM format.    \n> * This can be accessed using commonly-available libraries like pydicom, and contains both image and metadata.    \n> * It is a commonly used medical imaging data format.    \n   \n   \n> * Images are also provided in JPEG and TFRecord format (in the jpeg and tfrecords directories, respectively).    \n> * Images in TFRecord format have been resized to a uniform 1024x1024.    \n   \n   \n> * Metadata is also provided outside of the DICOM format, in CSV files.    \n> * See the Columns section for a description. \n   \n## What am I predicting?    \n> * You are predicting a binary target for each image.    \n> * Your model should predict the probability (floating point) between 0.0 and 1.0 that the lesion in the image is malignant (the target).    \n> * In the training data, train.csv, the value 0 denotes benign, and 1 indicates malignant.    ","11d17b7e":"## Data","600855b0":"### EDA","f68e889a":"### Explore datasets","bc5d8cd4":"### Files    \n> * train.csv - the training set    \n> * test.csv - the test set    \n> * sample_submission.csv - a sample submission file in the correct format \n   \n### Columns    \n> * **image_name** - unique identifier, points to filename of related DICOM image    \n> * **patient_id** - unique patient identifier    \n> * **sex** - the sex of the patient (when unknown, will be blank)    \n> * **age_approx** - approximate patient age at time of imaging    \n> * **anatom_site_general_challenge** - location of imaged site    \n> * **diagnosis** - detailed diagnosis information (train only)    \n> * **benign_malignant** - indicator of malignancy of imaged lesion    \n> * **target** - binarized version of the target variable    ","2365ca76":"## Libraries"}}