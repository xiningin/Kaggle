{"cell_type":{"aebf112c":"code","548f48f5":"code","b7bdb74d":"code","eeadc88f":"code","2bdcdc52":"code","4694addf":"code","56bda749":"code","f1fc7d39":"code","acfcbc42":"code","6b467902":"code","5333eb7a":"code","1762f12d":"code","194d98d0":"code","3d1f0dea":"code","f1cdab17":"code","e7196778":"code","747a9ba1":"code","e95e86bd":"code","80d4ecd2":"code","80ad471c":"code","969b2ba9":"code","2c0756b4":"code","5d18a094":"code","524bc951":"code","54bcc764":"code","8fd0ecbc":"code","5248b11f":"code","4aa30d86":"code","c0137521":"markdown","6a6ebd89":"markdown","0a74e574":"markdown","228b4071":"markdown","e7d787d0":"markdown","fe02dcda":"markdown","f6086a34":"markdown","b60c7426":"markdown","adaf949e":"markdown","194e5091":"markdown","5ac8e003":"markdown","f6e98408":"markdown","a0079cc7":"markdown","74c2d1e4":"markdown","7e5ffe19":"markdown","4e39fd62":"markdown","740452de":"markdown","f4b187c1":"markdown","13f8c0bc":"markdown","d90307c5":"markdown"},"source":{"aebf112c":"import numpy as np\nimport pandas as pd","548f48f5":"import warnings\nwarnings.filterwarnings('ignore') #Ignore warnings.","b7bdb74d":"from keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Dropout ,Activation","eeadc88f":"import matplotlib.pyplot as plt","2bdcdc52":"sales=pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sales_train.csv',parse_dates=['date']) #The data column is automatically parsed and converted into a date format.\ntest=pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/test.csv') \nshops=pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/shops.csv') \nitem_cat=pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/item_categories.csv') \nsub=pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv') \nitem=pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/items.csv') ","4694addf":"def basic_information(df):\n    print('----------------The first 5 rows of data----------------')\n    print(df.head())\n    print('----------------Brief summary----------------')\n    print(df.info())\n    print('----------------Data set size----------------')\n    print(df.shape)\n    print('----------------Column name----------------')\n    print(df.columns)\n    print('----------------Numerical features----------------')\n    print(df.describe())\n    print('----------------Missing data----------------')\n    print(df.isnull().sum())","56bda749":"basic_information(sales)","f1fc7d39":"basic_information(test)","acfcbc42":"basic_information(shops)","6b467902":"basic_information(item_cat)","5333eb7a":"basic_information(sub)","1762f12d":"basic_information(item)","194d98d0":"dataset = sales.pivot_table(index = ['shop_id','item_id'],values = ['item_cnt_day'],columns = ['date_block_num'],\n                            fill_value = 0,aggfunc=[np.sum])\ndataset.head() #Observe the front data.","3d1f0dea":"dataset.reset_index(inplace = True)\ndataset.head() #Observe the front data.","f1cdab17":"dataset.drop(['shop_id','item_id'],inplace = True, axis = 1)\ndataset.head()","e7196778":"dataset.shape","747a9ba1":"X_train = np.expand_dims(dataset.values[:,:-1],axis = 2) #Set all columns's data except the last column as training values.\ny_train = dataset.values[:,-1:] #Set the last column as label.\nX_test = np.expand_dims(dataset.values[:,1:],axis = 2) ##Set all columns except the first column as predicted values.\nprint(X_train.shape,y_train.shape) #View the shape of the training data set to make sure that the corresponding shapes of each data set are the same.","e95e86bd":"model_LSTM = Sequential()\nmodel_LSTM.add(LSTM(units = 64,input_shape = (33,1)))\n#model_LSTM.add(LSTM(units =70,input_shape = (X_train.shape[1], X_train.shape[2]))) #units\uff1aOutput dimension\uff1binput_shape\uff1aInput dimension.\nmodel_LSTM.add(Dropout(0.2)) #Represent the proportion of missing input.\n\n#model_LSTM.add(LSTM(units=50, return_sequences=False))\n#model_LSTM.add(Dropout(0.2))\n\nmodel_LSTM.add(Dense(1)) #Output dimension.\nmodel_LSTM.add(Activation('relu'))\nmodel_LSTM.compile(loss = 'mse',optimizer = 'adam', metrics = ['accuracy']) \n\nmodel_LSTM.summary()","80d4ecd2":"#history_lstm = model_LSTM.fit(X_train,y_train,batch_size = 4000,epochs = 12)\n#history_lstm = model_LSTM.fit(X_train,y_train,batch_size = 4096,epochs = 10)\nhistory_lstm = model_LSTM.fit(X_train,y_train,batch_size = 4096,epochs = 20)","80ad471c":"plt.plot(history_lstm.history['loss'])","969b2ba9":"plt.plot(history_lstm.history['accuracy'])","2c0756b4":"print(model_LSTM.predict(X_test))","5d18a094":"data_1=model_LSTM.predict(X_test).tolist()\ndata_1=[i[0] for i in data_1]","524bc951":"data_2=y_train.tolist()\ndata_2=[i[0] for i in data_2]","54bcc764":"plt.rcParams['figure.figsize'] = 11.7,8.27\nplt.scatter(x=range(len(data_1)),y=data_1,s=1)\nplt.scatter(x=range(len(data_2)),y=data_2,s=1)","8fd0ecbc":"abs(len(data_2)-len(data_1))","5248b11f":"sum1 = 1\nfor i in range(len(data_2)):\n    if abs(data_2[i]-data_1[i]) == 0:\n        sum1 += 1\nprint(sum1)","4aa30d86":"sum1\/len(data_1)*100","c0137521":"### Define a function.","6a6ebd89":"### (3). Train the model.","0a74e574":"# 1. Import related modules","228b4071":"### Meaning of each data set  \n1. **sales_train.csv**: Training set. Daily historical data from Jan 2013 to Oct 2015.  \n2. **test.csv**: Test set. It is necessary to predict the sales of these stores and products in Nov 2015.  \n3. **shops.csv**: Supplementary information about the store.  \n4. **item_categories.csv**: Supplementary information about item categories.  \n5. **sample_submission.csv**: Sample submission documents in the correct format.  \n6. **items.csv**: Supplementary information about items.","e7d787d0":"**reset_index**\uff1aReset the pivot table index. Among them, '**inplace = True**' means to modify the original variable without creating a new variable.","fe02dcda":"### (4). Draw loss and score curves during model training.","f6086a34":"expand_dims\uff1aExpand the array shape.","b60c7426":"### (1). Divide training set and test set.","adaf949e":"### Meaning of each variable\n1. **ID**: The ID of the (shop, product) tuple in the test set.  \n2. **shop_id**: The unique identifier of the store. \n3. **item_id**: The unique identifier of the product.  \n4. **item_category_id**: The unique identifier of the product category.\n5. **item_cnt_day**: The number of sold products.  \n6. **item_price**: The current price of the item.  \n7. **date**: The date format is yyyy-mm-dd.  \n8. **date_block_num**: Consecutive month numbers For convenience, 0 is Jan 2013, 1 is Feb 2013, ..., and 33 is Oct 2015.\n9. **item_name**: The product name.  \n10. **shop_name**: The store name.  \n11. **item_category_name**: The product category name.","194e5091":"**drop**\uff1aDelete some data. Here delete the '**shop_id**' and '**item_id**' columns' data , because in the data training, these data are irrelevant data and are only defined and established when the data set is created.  \n**axis=1**\uff1aDelete the column.","5ac8e003":"# 2. Import and clean the data set.","f6e98408":"It can be seen that the prediction rate of this model training is around 85%.","a0079cc7":"# 3. Recurrent neural network-LSTM ","74c2d1e4":"### (2). Build the model.","7e5ffe19":"## Processing the 'sales_train' data set","4e39fd62":"Add layers to the model.  \n**compile**\uff1aWhen configuring the training method, set the optimizer, loss function, and accuracy evaluation standard used during training.  \n1. The loss function is the mean square error.  \n2. The optimizer is Adaptive Moment Estimation, which is a variant of the gradient descent algorithm. However, the learning rate of each iteration parameter has a certain range, and the learning rate (step size) will not become too large because of the large gradient, and the value of the parameter is relatively stable.  \n3. The accuracy rate evaluation standard is the accuracy rate.","740452de":"**pivot_table**:  \n1. **index**: index. There are two levels of index here, and the order is the index order. The first level is the store code (shop_id), and the second level is the product code (item_id).  \n2. **values**: The row grouping key, the column name or other grouping key used for grouping, is used as the row index of the result DataFrame to filter out the required data. The number of products to be sold(item_cnt_day).  \n3. **columns**: The column grouping key, the column name or other grouping key used for grouping, as the column index of the result DataFrame. Here is a breakdown of the number of products sold under each consecutive month number.  \n4. **fill_value**: Set the null value to 0.  \n5. **aggfunc**: Set the function operation when aggregating data. The default is averaging. Use np.sum to sum up.","f4b187c1":"* **Sequential**\uff1aSequential model. It is the simplest linear, it is a linear stack of multiple network layers.  \n* **LSTM**\uff1aRecurrent neural network layer.  \n* **Dense**\uff1aFully connected layer.  \n* **Dropout**\uff1aDelete some neurons to prevent overfitting.  \n* **Activation**\uff1aActivation function, it will modify the result of the previous layer through functions such as 'Relu' and 'Softmax'.","13f8c0bc":"## View information of each data set.","d90307c5":"Import the ploting module."}}