{"cell_type":{"9d4cdbcf":"code","ff688a75":"code","e4638ac3":"code","9d5943b5":"code","931137d2":"code","d0a6be2d":"code","903a17e9":"code","5958e24e":"code","887306a4":"code","5e9c9dea":"code","0b7214d1":"code","f3404360":"code","6e670937":"code","0c8a1721":"code","b4919ac8":"code","c156366b":"code","c42dc193":"code","c2505703":"code","d49b635d":"code","2e0c149f":"code","f51f4590":"code","89f892ba":"code","21544e2c":"code","81307d94":"code","c0554e9c":"code","b2c8f270":"code","dad0429c":"code","31a3439e":"code","44f14aef":"code","d0361a6e":"code","b2f1636f":"code","84317afb":"code","1625b138":"code","77ae2ea1":"code","18399afc":"markdown","ecc368c5":"markdown","4b42fb1d":"markdown","77fb04bf":"markdown","db57860b":"markdown","35e9813e":"markdown","010619db":"markdown","732dae5b":"markdown","1c103aa8":"markdown","bea8fe57":"markdown","55a1af4f":"markdown","b264fdd1":"markdown","9a5c1a65":"markdown","f2e34c0d":"markdown","214389ca":"markdown","4c858a51":"markdown","4388bcf9":"markdown","26d8404e":"markdown","ae384e2d":"markdown","f8cd80c7":"markdown","bd83fc8c":"markdown","f99f37cd":"markdown","1fabd503":"markdown","36230bee":"markdown"},"source":{"9d4cdbcf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ff688a75":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nfrom tensorflow import keras\nfrom tensorflow import data","e4638ac3":"!pip install git+https:\/\/github.com\/keras-team\/keras-tuner.git -q","9d5943b5":"# set image size and batch size\nIMAGE_SIZE = (150,150)\nBATCH_SIZE = 16\n\n# set the size of the training and validation datasets\nVALIDATION_SHARE = 0.1\nTRAINING_SHARE = 0.4\n\n# use a fixed number of epochs for fine tuning\nFINE_TUNE_EPOCHS = 10\n\n","931137d2":"train_validate_directory = '\/kaggle\/input\/fork-of-cats-vs-dogs-train-val-test-data\/train_validate\/'\n\ntraining_ds = keras.preprocessing.image_dataset_from_directory(\n    train_validate_directory, \n    labels='inferred', \n    label_mode='binary', \n    class_names = [\"cats\",\"dogs\"], \n    color_mode='rgb',\n    batch_size=BATCH_SIZE, \n    image_size=IMAGE_SIZE, \n    shuffle=True,\n    seed=1,\n    validation_split = 1 - TRAINING_SHARE,\n    subset=\"training\",\n)","d0a6be2d":"plt.figure(figsize=(10, 10))\nfor images, labels in training_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(int(labels[i]))\n        plt.axis(\"off\")","903a17e9":"train_validate_directory = '\/kaggle\/input\/fork-of-cats-vs-dogs-train-val-test-data\/train_validate\/'\n\nvalidation_ds = keras.preprocessing.image_dataset_from_directory(\n    train_validate_directory, \n    labels='inferred', \n    label_mode='binary', \n    class_names = [\"cats\",\"dogs\"], \n    color_mode='rgb', \n    batch_size=BATCH_SIZE, \n    image_size=IMAGE_SIZE,\n    shuffle=True,\n    seed = 1,\n    validation_split = VALIDATION_SHARE,\n    subset=\"validation\"\n)","5958e24e":"#plt.figure(figsize=(10, 10))\n#for images, labels in validation_ds.take(1):\n#    for i in range(9):\n#        ax = plt.subplot(3, 3, i + 1)\n#        plt.imshow(images[i].numpy().astype(\"uint8\"))\n#        plt.title(int(labels[i]))\n#        plt.axis(\"off\")","887306a4":"from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\n\nfrom tensorflow.python.data.ops import dataset_ops\nfrom tensorflow.python.keras.layers.preprocessing import image_preprocessing\nfrom tensorflow.python.keras.preprocessing import dataset_utils\nfrom tensorflow.python.ops import image_ops\nfrom tensorflow.python.ops import io_ops\nfrom tensorflow.python.util.tf_export import keras_export\n\nWHITELIST_FORMATS = ('.bmp', '.gif', '.jpeg', '.jpg', '.png')\n\n## Tensorflow override method to return fname as list as well as dataset\n\ndef my_image_dataset_from_directory(directory,\n                                 labels='inferred',\n                                 label_mode='int',\n                                 class_names=None,\n                                 color_mode='rgb',\n                                 batch_size=BATCH_SIZE,\n                                 image_size=(IMAGE_SIZE[0], IMAGE_SIZE[1]),\n                                 shuffle=True,\n                                 seed=None,\n                                 validation_split=None,\n                                 subset=None,\n                                 interpolation='bilinear',\n                                 follow_links=False):\n  \n  if labels != 'inferred':\n    if not isinstance(labels, (list, tuple)):\n      raise ValueError(\n          '`labels` argument should be a list\/tuple of integer labels, of '\n          'the same size as the number of image files in the target '\n          'directory. If you wish to infer the labels from the subdirectory '\n          'names in the target directory, pass `labels=\"inferred\"`. '\n          'If you wish to get a dataset that only contains images '\n          '(no labels), pass `label_mode=None`.')\n    if class_names:\n      raise ValueError('You can only pass `class_names` if the labels are '\n                       'inferred from the subdirectory names in the target '\n                       'directory (`labels=\"inferred\"`).')\n  if label_mode not in {'int', 'categorical', 'binary', None}:\n    raise ValueError(\n        '`label_mode` argument must be one of \"int\", \"categorical\", \"binary\", '\n        'or None. Received: %s' % (label_mode,))\n  if color_mode == 'rgb':\n    num_channels = 3\n  elif color_mode == 'rgba':\n    num_channels = 4\n  elif color_mode == 'grayscale':\n    num_channels = 1\n  else:\n    raise ValueError(\n        '`color_mode` must be one of {\"rbg\", \"rgba\", \"grayscale\"}. '\n        'Received: %s' % (color_mode,))\n  interpolation = image_preprocessing.get_interpolation(interpolation)\n  dataset_utils.check_validation_split_arg(\n      validation_split, subset, shuffle, seed)\n\n  if seed is None:\n    seed = np.random.randint(1e6)\n  image_paths, labels, class_names = dataset_utils.index_directory(\n      directory,\n      labels,\n      formats=WHITELIST_FORMATS,\n      class_names=class_names,\n      shuffle=shuffle,\n      seed=seed,\n      follow_links=follow_links)\n\n  if label_mode == 'binary' and len(class_names) != 2:\n    raise ValueError(\n        'When passing `label_mode=\"binary\", there must exactly 2 classes. '\n        'Found the following classes: %s' % (class_names,))\n\n  image_paths, labels = dataset_utils.get_training_or_validation_split(\n      image_paths, labels, validation_split, subset)\n\n  dataset = paths_and_labels_to_dataset(\n      image_paths=image_paths,\n      image_size=image_size,\n      num_channels=num_channels,\n      labels=labels,\n      label_mode=label_mode,\n      num_classes=len(class_names),\n      interpolation=interpolation)\n  if shuffle:\n    # Shuffle locally at each iteration\n    dataset = dataset.shuffle(buffer_size=BATCH_SIZE * 8, seed=seed)\n  dataset = dataset.batch(BATCH_SIZE)\n  # Users may need to reference `class_names`.\n  dataset.class_names = class_names\n  return dataset, image_paths\n\ndef paths_and_labels_to_dataset(image_paths,\n                                image_size,\n                                num_channels,\n                                labels,\n                                label_mode,\n                                num_classes,\n                                interpolation):\n  \"\"\"Constructs a dataset of images and labels.\"\"\"\n  # TODO(fchollet): consider making num_parallel_calls settable\n  path_ds = dataset_ops.Dataset.from_tensor_slices(image_paths)\n  img_ds = path_ds.map(\n      lambda x: path_to_image(x, image_size, num_channels, interpolation))\n  if label_mode:\n    label_ds = dataset_utils.labels_to_dataset(labels, label_mode, num_classes)\n    img_ds = dataset_ops.Dataset.zip((img_ds, label_ds))\n  return img_ds\n\n\ndef path_to_image(path, image_size, num_channels, interpolation):\n  img = io_ops.read_file(path)\n  img = image_ops.decode_image(\n      img, channels=num_channels, expand_animations=False)\n  img = image_ops.resize_images_v2(img, image_size, method=interpolation)\n  img.set_shape((image_size[0], image_size[1], num_channels))\n  return img","5e9c9dea":"testing_directory = '\/kaggle\/input\/fork-of-cats-vs-dogs-train-val-test-data\/test_dir\/'\n\n#testing_ds = keras.preprocessing.image_dataset_from_directory(\ntesting_ds, testing_paths = my_image_dataset_from_directory(\n    testing_directory, \n    label_mode=None, \n    color_mode='rgb', \n    batch_size=12500,\n    image_size=IMAGE_SIZE, \n    shuffle=False,\n    seed = 1\n)","0b7214d1":"print(\"Number of training batches: %d\" % data.experimental.cardinality(training_ds))\nprint(\"Number of validation batches: %d\" % data.experimental.cardinality(validation_ds))\nprint(\"Number of test batches: %d\" % data.experimental.cardinality(testing_ds))","f3404360":"training_ds = training_ds.cache().prefetch(data.experimental.AUTOTUNE)\nvalidation_ds = validation_ds.cache().prefetch(data.experimental.AUTOTUNE)\ntesting_ds = testing_ds.cache().prefetch(data.experimental.AUTOTUNE)","6e670937":"base_model = keras.applications.VGG16(\n    weights=\"imagenet\",\n    input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3),\n    include_top=False,\n)\n\nbase_model.trainable = False\n\n# Let's take a look at the base model architecture\nbase_model.summary()","0c8a1721":"from kerastuner import HyperModel\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport numpy as np\n\ndef data_augmentation(x, hp):\n\n    x = layers.experimental.preprocessing.RandomRotation(\n        factor = hp.Float('random_rotation', min_value=0.05, max_value=0.2, step = 0.05)\n    )(x)\n\n    x = layers.experimental.preprocessing.RandomZoom(\n        height_factor = hp.Float('random_zoom', min_value=0.05, max_value=0.2, step = 0.05)\n    )(x)\n\n    x = layers.experimental.preprocessing.RandomWidth(\n        factor = hp.Float(\"random_width\", min_value = 0.05, max_value = 0.2, step = 0.05)\n    )(x)\n\n    x = layers.experimental.preprocessing.RandomHeight(\n        factor = hp.Float(\"random_height\", min_value = 0.05, max_value = 0.2, step = 0.05)\n    )(x)\n\n    x = layers.experimental.preprocessing.RandomTranslation(\n        height_factor = hp.Float(\"rand_trans_h\", min_value = 0.05, max_value = 0.2, step = 0.05),\n        width_factor = hp.Float(\"rand_trans_w\", min_value = 0.05, max_value = 0.2, step = 0.05)\n    )(x)\n\n    x = layers.experimental.preprocessing.RandomFlip(\n        mode = hp.Choice('random_flip', ['horizontal', 'vertical'])\n    )(x)\n    return x\n\ndef build_model(hp):\n    \n    # create an input mode\n    inputs = keras.Input(shape=(150,150,3))\n\n    # data augmentation\n    x = data_augmentation(inputs, hp)\n    \n    # data standardization\n    # omit rescaling as it will apparently be done as part of preprocessing\n    x = layers.experimental.preprocessing.Resizing(150,150, interpolation='bilinear')(x)\n    \n    # preprocess  before parsing to the base model\n    x = keras.applications.vgg16.preprocess_input(x)\n\n    # feed the processed data into the frozen base model\n    x = base_model(x, training=False)\n    \n    # add fully connected layers on top of the base model\n    #\n    # add a Flatten or a GlobalAveragePooling layer\n    reduction_type = hp.Choice('reduction_type', ['flatten', 'avg'])\n    if reduction_type == 'flatten':\n        x = layers.Flatten()(x)\n    else:\n        x = layers.GlobalAveragePooling2D()(x)\n    #\n    # add a Dense layer\n    x = layers.Dense(\n        units=hp.Int('num_dense_units', min_value=128, max_value=1024, step=32),\n        activation='relu'\n    )(x)\n    #\n    # add a Dropout layer\n    x = layers.Dropout(\n        hp.Float('dense_dropout', min_value=0.0, max_value=0.9)\n    )(x)\n    #\n    # add the final layer\n    outputs = layers.Dense(1)(x)\n    #\n    # build the model\n    model = keras.Model(inputs, outputs)\n    #\n    # let the learning rate vary\n    learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2)\n    #\n    # compile the model\n    model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=True),\n                  optimizer=keras.optimizers.Adam(learning_rate=0.001),\n                  metrics=[keras.metrics.BinaryAccuracy()])\n    #\n    # print the summary\n    model.summary()\n\n\n    return model","b4919ac8":"import kerastuner as kt\n\n\ntuner = kt.tuners.RandomSearch(\n    build_model,\n    objective='val_loss',\n    max_trials=100,\n    overwrite=True)\n\ncallbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', \n                                         mode='min', \n                                         patience=3, \n                                         restore_best_weights=True)]\n\ntuner.search(training_ds,\n             validation_data=validation_ds,\n             callbacks=callbacks, \n             verbose=1, \n             epochs=100)\n\ntuner.results_summary()","c156366b":"# extract the best hyperparameters\nbest_hp = tuner.get_best_hyperparameters()[0]\n\n# build the model using the best hyperparameters\nmodel = build_model(best_hp)\n\n# callbacks to use early stopping\ncallbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', \n                                         mode='min', \n                                         patience=4, \n                                         restore_best_weights=True)]\n# train the model\nhistory = model.fit(training_ds, \n                    epochs = 100, \n                    validation_data=validation_ds,\n                    callbacks=callbacks,\n                    verbose = 1)\n\n# get the best # of epochs\nval_loss_per_epoch = history.history['val_loss']\nbest_epoch = val_loss_per_epoch.index(min(val_loss_per_epoch)) + 1\nprint('Best epoch: %d' % (best_epoch,))\n\n# rebuild the model\nmodel = build_model(best_hp)","c42dc193":"# train with the best number of epochs\nhistory = model.fit(training_ds,\n          validation_data=validation_ds,\n          epochs=best_epoch,\n          verbose = 1)\n\nmodel.save('cats-vs-dogs-vgg16-tuner-production.h5')","c2505703":"acc = history.history['binary_accuracy']\nval_acc = history.history['val_binary_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='best')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.ylim([0,1.0])\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","d49b635d":"# Unfreeze the base_model. Note that it keeps running in inference mode\n# since we passed `training=False` when calling it. This means that\n# the batchnorm layers will not update their batch statistics.\n# This prevents the batchnorm layers from undoing all the training\n# we've done so far.\nbase_model.trainable = True","2e0c149f":"# Let's take a look to see how many layers are in the base model\nprint(\"Number of layers in the base model: \", len(base_model.layers))","f51f4590":"\n# Fine-tune from this layer onwards - 16,17,18 (the first layer is 0)\nfine_tune_at = 16\n\n# Freeze all the layers before the `fine_tune_at` layer\nfor layer in base_model.layers[:fine_tune_at]:\n    layer.trainable =  False","89f892ba":"best_hp[\"learning_rate\"]","21544e2c":"model.summary()","81307d94":"model.compile(\n    optimizer = keras.optimizers.Adam(lr=best_hp[\"learning_rate\"]\/10),\n    loss=keras.losses.BinaryCrossentropy(from_logits = True),\n    metrics=[keras.metrics.BinaryAccuracy()],\n)","c0554e9c":"fine_tune_epochs = FINE_TUNE_EPOCHS\n\ntotal_epochs =  best_epoch + fine_tune_epochs\n\nhistory_fine = model.fit(training_ds,\n                         epochs=total_epochs,\n                         initial_epoch=best_epoch,\n                         validation_data=validation_ds,\n                         callbacks=callbacks)","b2c8f270":"model.save('cats-vs-dogs-vgg16-tuner-finetuned.h5')","dad0429c":"acc += history_fine.history['binary_accuracy']\nval_acc += history_fine.history['val_binary_accuracy']\n\nloss += history_fine.history['loss']\nval_loss += history_fine.history['val_loss']","31a3439e":"plt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.ylim([0.8, 1])\nplt.plot([best_epoch-1,best_epoch-1],\n          plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.ylim([0, 1.0])\nplt.plot([best_epoch-1,best_epoch-1],\n         plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","44f14aef":"predictions = model.predict(testing_ds, verbose=1, steps = 12500)","d0361a6e":"predicted_label = []\npredicted_label = [int(round(probability[0])) for probability in predictions]","b2f1636f":"import numpy as np\nid = []\nfor testing_path in testing_paths:\n    id.append(testing_path.split('.')[0].split('\/')[-1])","84317afb":"import pandas as pd\nsubmission_df = pd.DataFrame({'id':id, 'label':predicted_label})\nsubmission_df = submission_df.sort_values(by=['id'])","1625b138":"submission_df.to_csv(\"submission.csv\", index=False)","77ae2ea1":"from IPython.display import FileLink\nFileLink(r'submission.csv')","18399afc":"# Directory structure","ecc368c5":"# Load images\n\n\nIn ```image_dataset_from_directory```, set\n\n* ```validation_split = validation_share```  for validation dataset and ```validation_split = 1 - training_share``` for training dataset \n* the directory where the data are located\n* ```labels = \"inferred\"``` to generate labels from the directory structure\n* ```label_mode = 'binary'``` to encode the labels as scalars with values 0 and 1\n* the explicit class names (which must match the names of the directories) to control the order of classes: ```class_names = [\"cats\", \"dogs\"]```\n* ```color_mode = \"rgb\"```\n* the batch size is ```batch_size``` for training and validation\n* the batch size for testing is ```batch_size_testing```\n* the size to resize the images after they read from disk, all images must have the same size\n* ```shuffle = True``` for training and validation to shuffle the data and provide the ```seed``` argument to make sure there is no overlap between the training and validation datasets\n* ```shuffle = False``` for testing data because we want to keep the datasets and their labels (filenames) ordered\n* ```subset = \"training\"``` for training dataset and ```subset = \"validation\"``` for validation dataset\n* ```label_mode = \"binary\"```  for training and validation\n* ```label_mode = None``` for testing","4b42fb1d":"# Train the production model","77fb04bf":"**To return test images *along with their corresponding paths*, I use an overriden IMAGE_DATASET_FROM_DIRECTORY function from here** https:\/\/github.com\/tensorflow\/tensorflow\/blob\/v2.3.0\/tensorflow\/python\/keras\/preprocessing\/image_dataset.py#L34-L206","db57860b":"* train for a **fixed** number of epochs","35e9813e":"## Full model\n\n* The model is built using the Keras functional API. \n\n* From Keras documentation: \"The Keras functional API is a way to create models that are more flexible than the tf.keras.Sequential API. The functional API can handle models with non-linear topology, shared layers, and even multiple inputs or outputs. The main idea is that a deep learning model is usually a directed acyclic graph (DAG) of layers. So the functional API is a way to build graphs of layers.\"\n\n* The first step is to create an input node\n\n* This is followed by data augmentation (using a custom function called on the ```inputs``` object).\n\n* Keras tuner is used to find optimal augmentation hyperparameters\n\n* The images are resized as part of the model using \n\n```\ntf.keras.layers.experimental.preprocessing.Resizing\n```\n\n\n* The pixel values are rescaled as part of the model too using\n\n```\nx = keras.applications.vgg16.preprocess_input(x)\n```\n\n\n* The base model is called on the processed data \n\n* **Make sure to pass ```training=False``` when calling the base model!**\n\n```\nx = base_model(x, training = False)\n```\n\n* This ensures the model runs in inference mode, so that batchnorm statistics is not updated even after we unfreeze the base model for fine tuning.  \n\n\n* Upon parsing the processed data into the base model, add fully connected layers\n\n* Keras tuner is used to find their optimal hyperparameters\n\n* Use Adam optimizer and tune its learning rate with the Keras tuner\n\n* Use ```keras.losses.BinaryCrossentropy()``` loss because there are only two classes and set ```from_logits=True``` as the model itself does not implement a sigmoid activation of the last layer.\n\n","010619db":"# Fine-tuning","732dae5b":"# Run hyperparameter search","1c103aa8":"# Binary classification on a cats vs. dogs dataset\n\n**Based on**:\n - tensorflow's transfer learning and early stopping guides https:\/\/www.tensorflow.org\/guide\/keras\/transfer_learning\n https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/callbacks\/EarlyStopping\n - keras + kerastuner best practices notebook https:\/\/www.kaggle.com\/fchollet\/moa-keras-kerastuner-best-practices    \n - tensorflow's blog and github resources on keras tuner\nhttps:\/\/blog.tensorflow.org\/2020\/01\/hyperparameter-tuning-with-keras-tuner.html\nhttps:\/\/keras-team.github.io\/keras-tuner\/\n\n\n\n* 50% of the dataset used\n* Keras tuner to find optimal hyperparameters\n* Data augmentation (using keras tuner)\n* Transfer learning (VGG16 network)\n* Fine-tuning (no keras tuner yet)\n\n\n**Updates in this version**:\n\n* Now using early stopping whilst training the model.\n \n**Note: in a similar notebook, https:\/\/www.kaggle.com\/fchollet\/keras-kerastuner-best-practices, the model is trained without early stopping! By calling** \n\n```history = model.fit(x_train, y_train, validation_split=0.2, epochs=50)```. \n\n**The correct approach would be to do it as here https:\/\/www.kaggle.com\/fchollet\/moa-keras-kerastuner-best-practices by using early stopping:**\n \n ``` callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=4)]\n    history = model.fit(train_ds, validation_data=val_ds, epochs=100, callbacks=callbacks) ```","bea8fe57":"# Make predictions","55a1af4f":"Make sure you have the following directory structure under \/kaggle\/input\/:\n\n* ...\/train_validate (a directory with images for training and validation)\n    * ...\/cats (a sub-directory with 12500 cats images)\n    * ...\/dogs (a sub-directory with 12500 dogs images)\n* ...\/test_dir\/test (a directory with 12500 unlabelled images for testing)\n\n**It is important the test_dir fodler contains a single \"unlabelled\" folder with all the test images in it. This is because ```image_dataset_from_directory``` expects at least a single directory under the specified path.**\n\n\nTo obtain the directory structure as above, you can use the output of my notebook \"cats-vs-dogs-train-val-test-data\"","b264fdd1":"Use the complete set of the original test data (12500 images) for testing.\n\n* set ```image_size=IMAGE_SIZE```,```label_mode=None``` and ```batch_size=12500```","9a5c1a65":"Set a few parameters used in the model:\n\n* image_size to resize the images after they are read from disk, all images must have the same size\n* the recommended size of the images for the currently used network is   ...  pixels. \n* batch_size to set the batch size\n* validation_share = 0.2 and training_share = 0.8 to use 20% of the original train-validate data for training and 80% for validation, for example, any other numbers like 0.1 and 0.4 are possible\n* set base learning rate\n","f2e34c0d":"# Build a model\n\n## Base model\n\n* Use a pre-trained model as a base model\n* Set weights to ```imagenet```\n* Do not include the fully-connected layer at the top of the network\n* Freeze the model\n\n*From tensorflow documentation:*\n\n*The very last classification layer (on \"top\", as most diagrams of machine learning models go from bottom to top) is not very useful. Instead, you will follow the common practice to depend on the very last layer before the flatten operation. This layer is called the \"bottleneck layer\". The bottleneck layer features retain more generality as compared to the final\/top layer.*","214389ca":"Sometimes, the validation accuracy is higher than the training accuracy.\n\nFrom TF documentation:\n\nNote: If you are wondering why the validation metrics are clearly better than the training metrics, the main factor is because layers like tf.keras.layers.BatchNormalization and tf.keras.layers.Dropout affect accuracy during training. They are turned off when calculating validation loss.","4c858a51":"* Recompile the model\n* From TF documentation: As you are training a much larger model (on a data set that is rather small) and want to readapt the pretrained weights, it is important to use a lower learning rate at this stage. Otherwise, your model could overfit very quickly.","4388bcf9":"* set 10x lower learning rate for fine-tuning","26d8404e":"# Set image and model parameters","ae384e2d":"# **Cache and prefetch the data to optimize loading speed**\n\nFrom the tensorflow documentation:\n\n* Caching saves some operations (like file opening and data reading) from being executed during each epoch.\n\n* Prefetching overlaps the preprocessing and model execution of a training step. While the model is executing training step s, the input pipeline is reading the data for step s+1. Doing so reduces the step time to the maximum (as opposed to the sum) of the training and the time it takes to extract the data.\n\n* Most dataset input pipelines should end with a call to prefetch. This allows later elements to be prepared while the current element is being processed. This often improves latency and throughput, at the cost of using additional memory to store prefetched elements.\n\n* The number of elements to prefetch should be equal to (or possibly greater than) the number of batches consumed by a single training step. You could either manually tune this value, or set it to tf.data.experimental.AUTOTUNE which will prompt the tf.data runtime to tune the value dynamically at runtime.\n\n* Note: Like other Dataset methods, prefetch operates on the elements of the input dataset. It has no concept of examples vs. batches. examples.prefetch(2) will prefetch two elements (2 examples), while examples.batch(20).prefetch(2) will prefetch 2 elements (2 batches, of 20 examples each).","f8cd80c7":"# Data pre-processing\n\n* Data pre-processing consists of data augmentation and data standardization (resizing and intensity normalization).\n\n* To benefit from the GPU acceleration, make it part of the model. \n\n* From Tensorflow documentation: \"When data preprocessing is part of the model, other people can load and use your model without having to be aware of how each feature is expected to be encoded and normalized. \"\n","bd83fc8c":"* All you need to do is unfreeze the base_model and set the bottom layers to be un-trainable. Then, you should recompile the model (necessary for these changes to take effect), and resume training.","f99f37cd":"# Find the best epoch value","1fabd503":"Print the number of batches","36230bee":"Install keras tuner"}}