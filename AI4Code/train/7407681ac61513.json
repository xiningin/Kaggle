{"cell_type":{"78c4e3c3":"code","13886365":"code","e8634cc5":"code","9babce02":"code","e534fbe1":"code","e0e75a5a":"code","b2664711":"code","9c76d7d7":"code","4bfbd364":"code","71be7474":"code","9d8dfac8":"code","cede15f0":"code","c34b8269":"markdown","d693e5dc":"markdown","14872d27":"markdown","98409f2a":"markdown","8878c7c9":"markdown","e8db373d":"markdown","4e09c196":"markdown","2cece0a1":"markdown","d2bdce14":"markdown","293ca9e3":"markdown","2fb2c9ac":"markdown","9c3dfeba":"markdown","768ed6d1":"markdown","9f9eea01":"markdown","a5fad70e":"markdown","1b5bcfc8":"markdown","18fc563a":"markdown","de539ae6":"markdown","5b7a7eef":"markdown","238b2541":"markdown","d251a30b":"markdown","4e3b3680":"markdown","d0680a0d":"markdown"},"source":{"78c4e3c3":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","13886365":"data = pd.read_csv('..\/input\/predictingese\/AttendanceMarksSA.csv')\ndata.head()\n","e8634cc5":"X= data['MSE']\nY=data['ESE']\nsns.scatterplot(X,Y)","9babce02":"theta0 = 0\ntheta1 = 0\nalpha = 0.01\ncount = 10000\nm = len(X) # m is number of examples i.e number of students here.","e534fbe1":"for i in range(count): \n    Y_hat = theta1*X + theta0  \n    theta0 = theta0 - (alpha\/m)*sum(Y_hat-Y)\n    theta1 = theta1 - (alpha\/m)*sum(X*(Y_hat-Y))\n    \n    \nprint(theta0,theta1)","e0e75a5a":"Y_hat = theta1*X + theta0\n\nplt.scatter(X, Y) \nplt.plot([min(X), max(X)], [min(Y_hat), max(Y_hat)], color='red')  # regression line\nplt.show()","b2664711":"import math\ndef RSE(y_true, y_predicted):\n   \n    y_true = np.array(y_true)\n    y_predicted = np.array(y_predicted)\n    RSS = np.sum(np.square(y_true - y_predicted))\n\n    rse = math.sqrt(RSS \/ (len(y_true) - 2))\n    return rse\n\n\nrse= RSE(data['ESE'],Y_hat)\nprint(rse)","9c76d7d7":"\nfrom sklearn.linear_model import LinearRegression","4bfbd364":"X = np.array(data['MSE']).reshape(-1,1)\ny = np.array(data['ESE']).reshape(-1,1)\n \n\nmodel = LinearRegression()\nmodel.fit(X,y)\n\n\nprint(model.coef_)\nprint(model.intercept_)\n\ny_predict = model.predict(X)\n\n","71be7474":"rse = RSE(y,y_predict)\n\nprint(rse)","9d8dfac8":"marks = [17]\nresult = model.predict([marks])","cede15f0":"print(result)","c34b8269":"### Importing Libraries","d693e5dc":"### Loading data","14872d27":"### Implementing Gradient Descent","98409f2a":"### Calculating Residual Standard Error","8878c7c9":"![gradient_descent.png](attachment:gradient_descent.png)","e8db373d":"### Predicting score","4e09c196":"![grad_desc.png](attachment:grad_desc.png)","2cece0a1":"### Importing Library","d2bdce14":"## 2. Using Scikit-Learn","293ca9e3":"### Implementation","2fb2c9ac":"### Ploting data","9c3dfeba":"## 1.Gradient Descent","768ed6d1":"In this notebook , I predicted End Semester Examination performance by using two methods. \n1. Gradient Descent (Without Scikit-learn)\n2. using Scikit-learn","9f9eea01":"### Calculating Residual Standard Error","a5fad70e":"### Initializing parameters and hyper-parameters","1b5bcfc8":"![RSS.png](attachment:RSS.png)","18fc563a":"By visualizing data , we can get idea about dataset.","de539ae6":"Here is formula for **gradient descent**.\n\nIn gradient descent we are updating parameters ***theta0*** and ***theta1*** until **Convergence**","5b7a7eef":"If my marks are 17 in Mid Semester Examination my score for End Semester Examination would be 58","238b2541":"**Parameters** - theta0 , theta1\n\n**Hyper-parameters** - alpha , count","d251a30b":"# Simple Linear Regression with Gradient Descent and Scikit-learn","4e3b3680":"### Gradient Descent","d0680a0d":"### Ploting regression line"}}