{"cell_type":{"425a436c":"code","bfdc2f91":"code","66839af3":"code","ebea6e40":"code","dd5c18f3":"code","3f0a74fc":"code","64b9ab29":"code","38a969c8":"code","3b225482":"code","d4153512":"code","bd988df1":"code","6cbdb8e9":"code","a5520774":"code","ea1a414f":"code","0ec47346":"code","ea378122":"code","94efbbb8":"code","b4d81bb7":"code","8f05f7bd":"code","bdb70c58":"code","dba2d4ed":"code","0c2df9c7":"code","3ff7b359":"code","8b9365e4":"code","054c3252":"code","25560621":"code","39a7e9e8":"code","4c08ade5":"code","f919491b":"code","f2218d0f":"code","3a0e7590":"code","082b723f":"code","8d3ef001":"markdown","b115b6e5":"markdown","97dc243c":"markdown","ba0fd762":"markdown","5701c058":"markdown","7fa9ca0b":"markdown"},"source":{"425a436c":"import os\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n!pip install keras\nfrom tensorflow import keras\n#from keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout","bfdc2f91":"train_dir = '..\/input\/asl-alphabet\/asl_alphabet_train\/asl_alphabet_train'","66839af3":"## Data Directory description   ###################################\n#\n#\n#   29 folders in test are -> A, B, C, D, E, F, G ,H, I ,J ,K, L, M, N, O, P, Q, R, S, T, U, V, W, X, Y, Z, DEL, SPACE, NOTHING\n#\n#\n#\n#                             -> asl_alphabet_train ->  asl_alphabet_train -> 29 folder, each folder has 3000 images\n#                           \/\n# input ->  asl-alphabet ->  \n#                          \\ \n#                           -> asl_alphabet_test ->  asl_alphabet_test -> 28 test images\n#\n","ebea6e40":"categories = os.listdir(train_dir)\nlen(categories)","dd5c18f3":"categories","3f0a74fc":"count = 0\ntrain_images_names_and_paths = {}\n\nfor i in categories:\n    train_images_names_and_paths[i] = os.listdir(train_dir + '\/' + i)\n    count += len(os.listdir(train_dir + '\/' + i))\n    \nprint('total count of train images is:', count)","64b9ab29":"train_dir + '\/' + list(train_images_names_and_paths.keys())[0] + '\/' + list(train_images_names_and_paths.values())[0][0]","38a969c8":"img = plt.imread(train_dir + '\/' + list(train_images_names_and_paths.keys())[0] + '\/' + list(train_images_names_and_paths.values())[0][0])\nimg","3b225482":"plt.imshow(img)","d4153512":"img.shape","bd988df1":"#The ImageDataGenerator class has three methods \n#flow(), flow_from_directory() and flow_from_dataframe() \n#to read the images from a big numpy array and folders containing images.","6cbdb8e9":"#data_generator = ImageDataGenerator(rescale = 1\/255)\n\ndata_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1\/255)\n\ntrain_generated = data_generator.flow_from_directory(train_dir,                       # path of images\n                                                     target_size = (200,200),         # size of image\n                                                     class_mode = 'categorical',\n                                                     color_mode = 'rgb',\n                                                     shuffle = True,\n                                                     batch_size = 32                  # hyperparameter that defines the number of samples\n                                                                                      #to work through before updating the internal model parameters\n                                                    )\n","a5520774":"train_generated","ea1a414f":"train_generated.class_indices","0ec47346":"img = plt.imread(train_dir + '\/' + list(train_images_names_and_paths.keys())[1] + '\/' + list(train_images_names_and_paths.values())[1][0])\nplt.imshow(img)\n\nprint(\"Following is picture of 'R'\")","ea378122":"def get_model():\n    \n    # Create a simple CNN model\n\n    model = keras.models.Sequential([\n            keras.layers.Conv2D( 32, kernel_size = 3, input_shape = (200,200,3), activation = 'relu'),\n            keras.layers.MaxPool2D(pool_size = (2,2)),\n\n            keras.layers.Conv2D( 64, kernel_size = 3, activation = 'relu'),\n            keras.layers.MaxPool2D(pool_size = (3,3)),\n\n            keras.layers.Conv2D( 128, kernel_size = 3, activation = 'relu'),\n            keras.layers.MaxPool2D(pool_size = (3,3)),\n\n            keras.layers.Conv2D( 256, kernel_size = 3, activation = 'relu'),\n            keras.layers.MaxPool2D(pool_size = (4,4)),\n\n            keras.layers.Flatten(),\n            keras.layers.Dense(1024, activation = 'relu'),\n            keras.layers.Dropout(0.2),\n            keras.layers.Dense(512, activation = 'relu'),\n            keras.layers.Dropout(0.4),\n            keras.layers.Dense(256, activation = 'relu'),\n            keras.layers.Dropout(0.6),\n            keras.layers.Dense(29, activation = 'softmax')   \n            ]) \n    model.compile(\n    optimizer = 'adam',\n    loss = 'categorical_crossentropy',\n    )\n    #model.summary()\n    \n    return model","94efbbb8":"model = get_model()\n\n# Train the model.\nmodel.fit(train_generated, epochs = 5)\n\n# Calling `save('KC_ASL_model')` creates a SavedModel folder `KC_ASL_model`.\nmodel.save(\"KC_ASL_model\")\n\n# It can be used to reconstruct the model identically.\nreconstructed_model = keras.models.load_model(\"KC_ASL_model\")","b4d81bb7":"test_dir = '..\/input\/asl-alphabet\/asl_alphabet_test'","8f05f7bd":"test_categories = os.listdir(test_dir)\nlen(test_categories)","bdb70c58":"count1 = 0\ntest_images_names_and_paths = {}\n\nfor i in test_categories:\n    test_images_names_and_paths[i] = os.listdir(test_dir + '\/' + i)\n    count1 += len(os.listdir(test_dir + '\/' + i))\n    \nprint('total count of test images is:', count1)\n","dba2d4ed":"test_dir + '\/' + list(test_images_names_and_paths.keys())[0] + '\/' + list(test_images_names_and_paths.values())[0][0]","0c2df9c7":"img1 = plt.imread(test_dir + '\/' + list(test_images_names_and_paths.keys())[0] + '\/' + list(test_images_names_and_paths.values())[0][0])\nimg1","3ff7b359":"plt.imshow(img1)","8b9365e4":"#data_generator = ImageDataGenerator(rescale = 1\/255)\n\ndata_generator1 = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1\/255)\n\ntest_generated = data_generator1.flow_from_directory(test_dir,                       # path of images\n                                                     target_size = (200,200),         # size of image\n                                                     class_mode = 'categorical',\n                                                     color_mode = 'rgb',\n                                                     shuffle = True,\n                                                     batch_size = 32                  # hyperparameter that defines the number of samples\n                                                                                      #to work through before updating the internal model parameters\n                                                    )","054c3252":"test_generated","25560621":"test_generated.class_indices","39a7e9e8":"img2 = plt.imread(test_dir + '\/' + list(test_images_names_and_paths.keys())[0] + '\/' + list(test_images_names_and_paths.values())[0][27])\nimg2\nplt.imshow(img2)","4c08ade5":"print(\"Evaluate on test data\")\nresults = model.evaluate(test_generated)\nprint(\"test loss, test acc:\", results)","f919491b":"test_predictions = reconstructed_model.predict(test_generated)\nprint(test_predictions[:3])","f2218d0f":"print(\"predictions shape:\", test_predictions.shape)","3a0e7590":"plt.imshow(test_predictions)","082b723f":"'''# Let's check:\nnp.testing.assert_allclose(\n    model.predict(test_generated), reconstructed_model.predict(test_generated)\n)\n\n# The reconstructed model is already compiled and has retained the optimizer\n# state, so training can resume:\n#reconstructed_model.fit(test_input, test_target)'''","8d3ef001":"# Code below is for evaluation and prediction on the Test Images","b115b6e5":"# Importing libraries","97dc243c":"# Create a CNN MODEL","ba0fd762":"# Data Preprocessing","5701c058":"## Data Description","7fa9ca0b":"# Train the Model"}}