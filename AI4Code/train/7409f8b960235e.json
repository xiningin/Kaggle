{"cell_type":{"70a53c72":"code","131cc90d":"code","100e8700":"code","3a09af74":"code","ec3949ae":"code","5d1213a2":"code","1f2695ec":"code","22f9b5a6":"code","9a5189db":"code","6603e6e5":"code","00d33c9d":"code","95e54a63":"code","aa994990":"code","27ce229e":"code","88457f8e":"code","92f2d663":"code","0f7d0a89":"code","f4c026d5":"code","b7c1e928":"code","5fe03537":"code","e09e596d":"code","063c8ee4":"code","43d91e2b":"code","a1430bb6":"code","421bbddb":"code","c4ffe5a8":"code","07a8a66b":"code","1a16cd31":"code","b64d3356":"markdown","3869f8aa":"markdown","ea1b77bb":"markdown","69d86bf1":"markdown","c3fa380b":"markdown","907b3324":"markdown","79982d3e":"markdown","7b45a4ea":"markdown","71c3e03e":"markdown","f6283423":"markdown"},"source":{"70a53c72":"%config Completer.use_jedi = False\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom PIL import Image\nimport seaborn as sns\nimport cv2\nimport random\nimport os\nimport imageio\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\nfrom collections import Counter\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, classification_report, confusion_matrix, plot_confusion_matrix\nfrom sklearn.model_selection import RandomizedSearchCV, cross_val_score, RepeatedStratifiedKFold\nfrom imblearn.over_sampling import SMOTE\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\nfrom keras.applications import resnet\nfrom tensorflow.keras.applications import EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3, EfficientNetB4, EfficientNetB5, EfficientNetB6, EfficientNetB7\nfrom keras.applications.resnet import ResNet50\nfrom keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img","131cc90d":"directory = r'..\/input\/iqothnccd-lung-cancer-dataset\/The IQ-OTHNCCD lung cancer dataset'\n\ncategories = ['Bengin cases', 'Malignant cases', 'Normal cases']","100e8700":"size_data = {}\nfor i in categories:\n    path = os.path.join(directory, i)\n    class_num = categories.index(i)\n    temp_dict = {}\n    for file in os.listdir(path):\n        filepath = os.path.join(path, file)\n        height, width, channels = imageio.imread(filepath).shape\n        if str(height) + ' x ' + str(width) in temp_dict:\n            temp_dict[str(height) + ' x ' + str(width)] += 1 \n        else:\n            temp_dict[str(height) + ' x ' + str(width)] = 1\n    \n    size_data[i] = temp_dict\n        \nsize_data","3a09af74":"for i in categories:\n    path = os.path.join(directory, i)\n    class_num = categories.index(i)\n    for file in os.listdir(path):\n        filepath = os.path.join(path, file)\n        print(i)\n        img = cv2.imread(filepath, 0)\n        plt.imshow(img)\n        plt.show()\n        break","ec3949ae":"img_size = 256\nfor i in categories:\n    cnt, samples = 0, 3\n    fig, ax = plt.subplots(samples, 3, figsize=(15, 15))\n    fig.suptitle(i)\n    \n    path = os.path.join(directory, i)\n    class_num = categories.index(i)\n    for curr_cnt, file in enumerate(os.listdir(path)):\n        filepath = os.path.join(path, file)\n        img = cv2.imread(filepath, 0)\n        \n        img0 = cv2.resize(img, (img_size, img_size))\n        \n        img1 = cv2.GaussianBlur(img0, (5, 5), 0)\n        \n        ax[cnt, 0].imshow(img)\n        ax[cnt, 1].imshow(img0)\n        ax[cnt, 2].imshow(img1)\n        cnt += 1\n        if cnt == samples:\n            break\n        \nplt.show()","5d1213a2":"data = []\nimg_size = 256\n\nfor i in categories:\n    path = os.path.join(directory, i)\n    class_num = categories.index(i)\n    for file in os.listdir(path):\n        filepath = os.path.join(path, file)\n        img = cv2.imread(filepath, 0)\n        # preprocess here\n        img = cv2.resize(img, (img_size, img_size))\n        data.append([img, class_num])\n        \nrandom.shuffle(data)\n\nX, y = [], []\nfor feature, label in data:\n    X.append(feature)\n    y.append(label)\n    \nprint('X length:', len(X))\nprint('y counts:', Counter(y))\n\n# normalize\nX = np.array(X).reshape(-1, img_size, img_size, 1)\nX = X \/ 255.0\ny = np.array(y)","1f2695ec":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=10, stratify=y)\n\nprint(len(X_train), X_train.shape)\nprint(len(X_valid), X_valid.shape)","22f9b5a6":"print(Counter(y_train), Counter(y_valid))","9a5189db":"print(len(X_train), X_train.shape)\n\nX_train = X_train.reshape(X_train.shape[0], img_size*img_size*1)\n\nprint(len(X_train), X_train.shape)","6603e6e5":"print('Before SMOTE:', Counter(y_train))\nsmote = SMOTE()\nX_train_sampled, y_train_sampled = smote.fit_resample(X_train, y_train)\nprint('After SMOTE:', Counter(y_train_sampled))","00d33c9d":"X_train = X_train.reshape(X_train.shape[0], img_size, img_size, 1)\nX_train_sampled = X_train_sampled.reshape(X_train_sampled.shape[0], img_size, img_size, 1)\n\nprint(len(X_train), X_train.shape)\nprint(len(X_train_sampled), X_train_sampled.shape)","95e54a63":"model1 = Sequential()\n\nmodel1.add(Conv2D(64, (3, 3), input_shape=X_train.shape[1:]))\nmodel1.add(Activation('relu'))\nmodel1.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel1.add(Conv2D(64, (3, 3), activation='relu'))\nmodel1.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel1.add(Flatten())\nmodel1.add(Dense(16))\nmodel1.add(Dense(3, activation='softmax'))\n\nmodel1.summary()","aa994990":"model1.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","27ce229e":"history = model1.fit(X_train_sampled, y_train_sampled, batch_size=8, epochs=10, validation_data=(X_valid, y_valid))","88457f8e":"y_pred = model1.predict(X_valid, verbose=1)\ny_pred_bool = np.argmax(y_pred, axis=1)\n\nprint(classification_report(y_valid, y_pred_bool))\n\nprint(confusion_matrix(y_true=y_valid, y_pred=y_pred_bool))","92f2d663":"plt.plot(history.history['accuracy'], label='Train')\nplt.plot(history.history['val_accuracy'], label='Validation')\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\nplt.show()\n\nplt.plot(history.history['loss'], label='Train')\nplt.plot(history.history['val_loss'], label='Validation')\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend()\nplt.show()","0f7d0a89":"model2 = Sequential()\n\nmodel2.add(Conv2D(64, (3, 3), input_shape=X_train.shape[1:]))\nmodel2.add(Activation('relu'))\nmodel2.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel2.add(Conv2D(64, (3, 3), activation='relu'))\nmodel2.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel2.add(Flatten())\nmodel2.add(Dense(16))\nmodel2.add(Dense(3, activation='softmax'))\n\nmodel2.summary()","f4c026d5":"model2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","b7c1e928":"new_weights = {\n    0: X_train.shape[0]\/(3*Counter(y_train)[0]),\n    1: X_train.shape[0]\/(3*Counter(y_train)[1]),\n    2: X_train.shape[0]\/(3*Counter(y_train)[2]),\n}\n\n# new_weights[0] = 0.5\n# new_weights[1] = 20\n\nnew_weights","5fe03537":"history = model2.fit(X_train, y_train, batch_size=8, epochs=10, validation_data=(X_valid, y_valid), class_weight=new_weights)","e09e596d":"y_pred = model2.predict(X_valid, verbose=1)\ny_pred_bool = np.argmax(y_pred, axis=1)\n\nprint(classification_report(y_valid, y_pred_bool))\n\nprint(confusion_matrix(y_true=y_valid, y_pred=y_pred_bool))","063c8ee4":"plt.plot(history.history['accuracy'], label='Train')\nplt.plot(history.history['val_accuracy'], label='Validation')\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\nplt.show()\n\nplt.plot(history.history['loss'], label='Train')\nplt.plot(history.history['val_loss'], label='Validation')\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend()\nplt.show()","43d91e2b":"train_datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True) \nval_datagen = ImageDataGenerator()","a1430bb6":"train_generator = train_datagen.flow(X_train, y_train, batch_size=8) \nval_generator = val_datagen.flow(X_valid, y_valid, batch_size=8)","421bbddb":"model3 = Sequential()\n\nmodel3.add(Conv2D(64, (3, 3), input_shape=X_train.shape[1:]))\nmodel3.add(Activation('relu'))\nmodel3.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel3.add(Conv2D(64, (3, 3), activation='relu'))\nmodel3.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel3.add(Flatten())\nmodel3.add(Dense(16))\nmodel3.add(Dense(3, activation='softmax'))\n\nmodel3.summary()","c4ffe5a8":"model3.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","07a8a66b":"history = model3.fit_generator(train_generator, epochs=5, validation_data=val_generator, class_weight=new_weights)","1a16cd31":"y_pred = model3.predict(X_valid, verbose=1)\ny_pred_bool = np.argmax(y_pred, axis=1)\n\nprint(classification_report(y_valid, y_pred_bool))\n\nprint(confusion_matrix(y_true=y_valid, y_pred=y_pred_bool))","b64d3356":"# Results","3869f8aa":"# Model Building with SMOTE data","ea1b77bb":"# Applying SMOTE to oversample the data","69d86bf1":"# Image Size Variations","c3fa380b":"# Preparing Data","907b3324":"# Data Augmentation","79982d3e":"# Model Building with Class Weighted Approach","7b45a4ea":"# Import Packages","71c3e03e":"# Image Preprocessing and Testing","f6283423":"# Results"}}