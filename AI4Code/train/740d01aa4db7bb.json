{"cell_type":{"0843991f":"code","edbec55b":"code","2c8519a4":"code","054acbbc":"code","bd01e2b3":"code","c6f1e8fd":"code","cad1f3a2":"code","4c659d35":"code","538372e0":"code","c6e2a47a":"code","5be88866":"code","b4df4746":"code","d4bb43fe":"code","1e5ad116":"code","c96f9c69":"code","275b11ca":"code","6f9dd7b9":"code","22f97996":"code","f0bf4ee6":"code","224b9694":"code","e49fe402":"code","05f46e60":"code","92c344aa":"code","120ee466":"code","46b643ae":"code","410041f3":"code","0344ce28":"markdown"},"source":{"0843991f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","edbec55b":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport nltk\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelBinarizer\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom wordcloud import WordCloud,STOPWORDS\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize,sent_tokenize\nfrom bs4 import BeautifulSoup\nimport re,string,unicodedata\nfrom nltk.tokenize.toktok import ToktokTokenizer\nfrom nltk.stem import PorterStemmer,WordNetLemmatizer\nfrom sklearn.linear_model import LogisticRegression,SGDClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom string import punctuation\nfrom nltk import pos_tag\nfrom nltk.corpus import wordnet\nimport keras\nfrom keras.models import Sequential","2c8519a4":"news = pd.read_csv(\"..\/input\/cbc-news-coronavirus-articles-march-26\/news.csv\")","054acbbc":"news.head()","bd01e2b3":"news.authors.unique()","c6f1e8fd":"news.authors.replace(\"[]\" , \"Unknown\"  ,inplace = True)","cad1f3a2":"authors = news.authors.value_counts().index.values[:5]\nfreq = news.authors.value_counts().values[:5]\nauthors_pd = pd.DataFrame(columns = ['authors' , 'freq'])\nauthors_pd['authors'] = authors\nauthors_pd['freq'] = freq","4c659d35":"f, ax = plt.subplots(figsize=(10, 10))\nsns.barplot(x = \"freq\" , y = \"authors\" , data = authors_pd , label = 'Total')\nsns.set_color_codes(\"muted\")\nax.legend(ncol=2, loc=\"lower right\", frameon=True)\nax.set(ylabel=\"\",xlabel=\"Maximum Number of Articles Written by Top 5 Authors\")","538372e0":"news['Unnamed: 0'].count()","c6e2a47a":"def sort_text(texts):\n    des_text = news[news.text == texts].description.values[0]\n    if(des_text.split()[:5] == texts.split()[:5]):\n        return texts\n    else:\n        return texts +  ' ' + des_text\nnews.text = news.text.apply(sort_text)    ","5be88866":"stop = set(stopwords.words('english'))\npunctuation = list(string.punctuation)\nstop.update(punctuation)","b4df4746":"def get_simple_pos(tag):\n    if tag.startswith('J'):\n        return wordnet.ADJ\n    elif tag.startswith('V'):\n        return wordnet.VERB\n    elif tag.startswith('N'):\n        return wordnet.NOUN\n    elif tag.startswith('R'):\n        return wordnet.ADV\n    else:\n        return wordnet.NOUN","d4bb43fe":"lemmatizer = WordNetLemmatizer()\ndef lemmatize_words(text):\n    final_text = []\n    for i in text.split():\n        if i.strip().lower() not in stop:\n            pos = pos_tag([i.strip()])\n            word = lemmatizer.lemmatize(i.strip(),get_simple_pos(pos[0][1]))\n            if(word.lower().isalpha()):\n                final_text.append(word.lower())\n    return \" \".join(final_text)","1e5ad116":"news.text = news.text.apply(lemmatize_words)","c96f9c69":"plt.figure(figsize = (20,20))\nwc = WordCloud(max_words = 3000 , width = 1600 , height = 800).generate(\" \".join(news.text))\nplt.imshow(wc , interpolation = 'bilinear')","275b11ca":"cv=CountVectorizer(min_df=0,max_df=1,ngram_range=(1,3))\ncv_reviews=cv.fit_transform(news.text)","6f9dd7b9":"cv_reviews","22f97996":"cv.vocabulary_","f0bf4ee6":"len(cv.vocabulary_)","224b9694":"d = cv.vocabulary_\ngram = {}\nbigram = {}\ntrigram = {}\nfor i in d.keys():\n    x = i.split()\n    if(len(x) == 1):\n        gram[i] = gram.get(i,0) + d[i]\n    elif(len(x) == 2):\n        bigram[i] = bigram.get(i,0) + d[i]\n    elif(len(x) == 3):\n        trigram[i] = trigram.get(i,0) + d[i]     ","e49fe402":"# Sorting dictionaries based on values\ngram = sorted(gram.items(),key = lambda kv:(kv[1], kv[0]))\nbigram = sorted(bigram.items(),key = lambda kv:(kv[1], kv[0]))\ntrigram = sorted(trigram.items(),key = lambda kv:(kv[1], kv[0]))","05f46e60":"gram_words = list(dict(gram).keys())[-20:]\ngram_freq =  list(dict(gram).values())[-20:]\n\nbigram_words = list(dict(bigram).keys())[-20:]\nbigram_freq =  list(dict(bigram).values())[-20:]\n\ntrigram_words = list(dict(trigram).keys())[-20:]\ntrigram_freq =  list(dict(trigram).values())[-20:]","92c344aa":"gram_freq_new = [i\/\/100000 for i in gram_freq]\nbigram_freq_new = [i\/\/100000 for i in bigram_freq]\ntrigram_freq_new = [i\/\/100000 for i in trigram_freq]","120ee466":"gram_df = pd.DataFrame(columns = ['words' , 'freq'])\ngram_df['words'] = gram_words\ngram_df['freq'] = gram_freq_new\nf, ax = plt.subplots(figsize=(20, 20))\nsns.barplot(x = \"freq\" , y = \"words\" , data = gram_df , label = 'Total')\nsns.set_color_codes(\"muted\")\nax.legend(ncol=1, loc=\"upper right\", frameon=True)\nax.set(ylabel=\"\",xlabel=\"Top 20 Grams used in Text in Lakhs\")","46b643ae":"bigram_df = pd.DataFrame(columns = ['words' , 'freq'])\nbigram_df['words'] = bigram_words\nbigram_df['freq'] = bigram_freq_new\nf, ax = plt.subplots(figsize=(20, 20))\nsns.barplot(x = \"freq\" , y = \"words\" , data = bigram_df , label = 'Total')\nsns.set_color_codes(\"muted\")\nax.legend(ncol=1, loc=\"upper right\", frameon=True)\nax.set(ylabel=\"\",xlabel=\"Top 20 BiGrams used in Text in Millions\")","410041f3":"trigram_df = pd.DataFrame(columns = ['words' , 'freq'])\ntrigram_df['words'] = trigram_words\ntrigram_df['freq'] = trigram_freq\nf, ax = plt.subplots(figsize=(20, 20))\nsns.barplot(x = \"freq\" , y = \"words\" , data = trigram_df , label = 'Total')\nsns.set_color_codes(\"muted\")\nax.legend(ncol=1, loc=\"upper right\", frameon=True)\nax.set(ylabel=\"\",xlabel=\"Top 20 TriGrams used in Text in Millions\")","0344ce28":"**In many rows , the text in 'description' column is exactly same\/ or a subset of the column 'text' **"}}