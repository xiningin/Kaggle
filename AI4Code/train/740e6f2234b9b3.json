{"cell_type":{"ff0e0219":"code","4d99abce":"code","ec05cbe9":"code","16773f32":"code","deb47b45":"code","5dd24d96":"code","c79b4399":"code","337aeaf2":"code","0d2f9f10":"code","bb083b0d":"code","aca36ac1":"code","2b0322a8":"code","af3770d8":"code","99b06ad3":"code","dbc7b083":"code","3dca3a07":"code","0b6e1d15":"code","841285fb":"code","8bd42977":"code","e3a42f3c":"markdown","26387a5a":"markdown","74b2c4e0":"markdown","b54c0833":"markdown","210a3dc6":"markdown","c26674c2":"markdown","0eb15970":"markdown","8c0796b8":"markdown","5afb4e08":"markdown","7fe71288":"markdown","aa2818e3":"markdown","fcebc82b":"markdown","6b7304d3":"markdown"},"source":{"ff0e0219":"from fastai.vision.all import *","4d99abce":"def is_cat(x): return x[0].isupper()\n\npath = untar_data(URLs.PETS)\/'images'\n\ndls = ImageDataLoaders.from_name_func(\n    path, get_image_files(path), valid_pct=0.2, seed=42,\n    label_func=is_cat, item_tfms=Resize(224))","ec05cbe9":"print(f'N\u00famero de imagens: {dls.n}')","16773f32":"dls.show_batch()","deb47b45":"learn1 = cnn_learner(dls, resnet34, metrics=error_rate)\nlearn1.fine_tune(5)","5dd24d96":"img = PILImage.create('..\/input\/boshchewie\/IMG-20200623-WA0028.jpg')\nimg2 = PILImage.create('..\/input\/boshchewie\/IMG-20200715-WA0005.jpg')\n\ndisplay(img.to_thumb(192))\ndisplay(img2.to_thumb(192))","c79b4399":"is_cat,_,probs = learn1.predict(img)\n\nprint(f\"\u00c9 um gato? {is_cat}.\")\nprint(f\"Probabilidade de ser um gato : {probs[1].item():.6f}\")","337aeaf2":"from fastai.text.all import *","0d2f9f10":"dls = TextDataLoaders.from_folder(untar_data(URLs.IMDB), valid='test')","bb083b0d":"print(f'N\u00famero de reviews: {dls.n}')","aca36ac1":"dls.show_batch()","2b0322a8":"learn2 = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=accuracy)\nlearn2.fine_tune(3, 1e-2)","af3770d8":"sentiment,_,probs = learn2.predict(\"I really liked that movie!\")\n\nprint(f\"Qual o sentimento? {sentiment}.\")\nprint(f\"Probabilidades : {probs[1].item():.6f}\")","99b06ad3":"from fastai.tabular.all import *","dbc7b083":"path = untar_data(URLs.ADULT_SAMPLE)\n\ndls = TabularDataLoaders.from_csv(path\/'adult.csv', path=path, y_names=\"salary\",\n    cat_names = ['workclass', 'education', 'marital-status', 'occupation',\n                 'relationship', 'race'],\n    cont_names = ['age', 'fnlwgt', 'education-num'],\n    procs = [Categorify, FillMissing, Normalize])","3dca3a07":"print(f'N\u00famero de linhas: {dls.n}')","0b6e1d15":"dls.show_batch()","841285fb":"learn3 = tabular_learner(dls, metrics=accuracy)\nlearn3.fine_tune(5)","8bd42977":"learn3.show_results()","e3a42f3c":"### Dados\n\nUm conjunto de dados \"tradicional\", contendo valores categ\u00f3ricos e num\u00e9ricos - al\u00e9m da classe a ser predita (sal\u00e1rio).","26387a5a":"### Aprendizado\n\nTreinamento e avalia\u00e7\u00e3o do modelo.","74b2c4e0":"-----\n\n<a id=\"classification\"><\/a>\n# Classifica\u00e7\u00e3o de Images\n\nClassifica\u00e7\u00e3o utilizando a [ResNet34](https:\/\/www.kaggle.com\/pytorch\/resnet34) (da Microsoft) para identificar cachorros e gatos a partir de fotos. [Hist\u00f3ria](https:\/\/towardsdatascience.com\/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8) - A ResNet foi vencedora do ILSVRC 2015 em classifica\u00e7\u00e3o, detec\u00e7\u00e3o e localiza\u00e7\u00e3o de imagens, bem como Vencedor do MS COCO 2015, em detec\u00e7\u00e3o e segmenta\u00e7\u00e3o de imagens. O [artigo](https:\/\/www.cv-foundation.org\/openaccess\/content_cvpr_2016\/papers\/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) da ResNet, publicado na CVPR em 2016, possui mais de 19.000 cita\u00e7\u00f5es.\n\nNesta se\u00e7\u00e3o, utilizamos a rede ResNet34 treinada na ImageNet, um dataset de mais de 15 mil\u00f5es de imagens de alta-resolu\u00e7\u00e3o rotuladas em aproximadamente 22,000 classes. Esta rede ser\u00e1 adaptada para o nosso problema, ou seja, ser\u00e1 realizado um [transfer learning](https:\/\/en.wikipedia.org\/wiki\/Transfer_learning) - para que a rede aprenda sobre o nosso problema em quest\u00e3o.\n\n[Voltar para o Topo](#top)","b54c0833":"# Deep Learning - Fast AI\n\nEste notebook apresenta um conjunto de demonstra\u00e7\u00f5es de Deep Learning utilizando o pacote `fastai`, um pacote constru\u00eddo em cima do `pytorch`. O pacote [fast.ai](https:\/\/course.fast.ai\/) \u00e9 utilizado em cursos, pesquisas e no mercado de trabalho - al\u00e9m disso, ele mant\u00e9m os principais pacotes de Aprendizado Profundo ( _i.e.,_ Deep Learning) e Aprendizado de M\u00e1quina ( _i.e.,_ Machine Learning) utilizados atualmente. Neste notebook vamos ver como (1) classificar imagens utilizando a [ResNet34](https:\/\/www.kaggle.com\/pytorch\/resnet34) (da Microsoft) para identificar cachorros e gatos a partir de fotos; (2) utilizar a [AWD-LSTM](https:\/\/arxiv.org\/abs\/1803.08240) (do Salesforce) para an\u00e1lise de sentimento por meio de textos; e, por fim (3) uma classifica\u00e7\u00e3o de sal\u00e1rio de pessoas utilizando uma rede neural profunda, criada do zero.\n\n> Conte\u00fado voltado para n\u00edvel intermedi\u00e1rio de Aprendizado de M\u00e1quina e Ci\u00eancia de Dados!\n\n<a id=\"top\"><\/a>\n## Conte\u00fado\n\n> **Nota.** Alguns c\u00f3digos foram ocultados a fim de facilitar a leitura e dar destaque para os conte\u00fados mais importantes.\n\nO notebook est\u00e1 organizado como segue:\n\n- [Classifica\u00e7\u00e3o de Images](#classification) - Classificar fotos de gatos e cachorros.\n- [An\u00e1lise de Sentimento](#sentiment_analysis) - An\u00e1lise de texto, indicando positividade ou negatividade.\n- [Classifica\u00e7\u00e3o de Sal\u00e1rio](#classification2) - Predizer o sal\u00e1rio de acordo com as caracter\u00edsticas da pessoa.","210a3dc6":"-----\n\n<a id=\"sentiment_analysis\"><\/a>\n# An\u00e1lise de Sentimento\n\nNesta tarefa utilizaremos a red [AWD-LSTM](https:\/\/arxiv.org\/abs\/1803.08240) (do Salesforce) para an\u00e1lise de sentimento por meio de textos. AWD-LSTM  \u00e9 uma adapta\u00e7\u00e3o recente do [LSTM](https:\/\/en.wikipedia.org\/wiki\/Long_short-term_memory) que mostra melhorias substanciais no estado da arte para modelagem de linguagem, usando t\u00e9cnicas muito \u00fateis em uma s\u00e9rie de problemas de [NLP](https:\/\/en.wikipedia.org\/wiki\/Natural_language_processing).\n\n[Voltar para o Topo](#top)","c26674c2":"### Teste\n\nTestando empiricamente a classifica\u00e7\u00e3o de uma foto.","0eb15970":"### Dados\n\nFotos dos gatos e cachorros, bem como uma fun\u00e7\u00e3o para identificar suas respectivas classes.","8c0796b8":"### Teste\n\nTestando empiricamente a an\u00e1lise de sentimento de um texto.","5afb4e08":"### Aprendizado\n\nTreinamento e avalia\u00e7\u00e3o do modelo.   \nNeste exemplo, durante o aprendizado j\u00e1 \u00e9 nos retornado a m\u00e9trica de desempenho.","7fe71288":"### Aprendizado\n\nTreinamento e avalia\u00e7\u00e3o do modelo.","aa2818e3":"### Teste\n\nApresentando os resultados de algumas classifica\u00e7\u00f5es.","fcebc82b":"-----\n\n<a id=\"classification2\"><\/a>\n# Classifica\u00e7\u00e3o de Sal\u00e1rio\n\nNesta tarefa vamos trabalhar com dados tabulares, contendo valores num\u00e9ricos e categ\u00f3ricos. Al\u00e9m disso, vamos criar nossa pr\u00f3pria rede neural e treina-la a partir dos dados. Utilizaremos a rede neural \"padr\u00e3o\" sugerida para trabalhar com dados tabulares `tabular_learner`, com duas camadas escondidades de, respectivamente, \\[200,100\\] n\u00f3s.\n\n[Voltar para o Topo](#top)","6b7304d3":"### Dados\n\nCarregando um conjunto de avalia\u00e7\u00f5es do IMDb, e seus sentimentos."}}