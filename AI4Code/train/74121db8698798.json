{"cell_type":{"af0f7a68":"code","bdb75f9d":"code","0cb39a8a":"code","486a475c":"code","0c5b4e24":"code","0c334e38":"code","00b9011f":"code","ee629325":"code","76466e8e":"code","dfadfb9c":"code","1929794e":"code","947f2023":"code","ba887027":"code","57fbbeac":"code","7012b91f":"code","17ea7f2a":"code","a2401c57":"code","1d30cbc7":"code","72839796":"code","a52b7693":"code","1b6687ed":"code","8e919e27":"code","cf122267":"code","f83047fa":"code","3531bc1b":"markdown","225d7dd6":"markdown","43452b33":"markdown","658c3503":"markdown","e10ca5a9":"markdown","45e1c5b6":"markdown","1345af85":"markdown","7d17ec7d":"markdown","51c4d0d8":"markdown","23fbac08":"markdown","10342210":"markdown","0993dedd":"markdown","4839ea98":"markdown","aae0844d":"markdown","2de10392":"markdown","0019ed66":"markdown","9710936e":"markdown","5b408bcb":"markdown"},"source":{"af0f7a68":"#importing required libraries\nimport numpy as np\nimport pandas as pd\n\n#reading the file from input path\ndataset = pd.read_csv('..\/input\/datascience-survey-on-kaggle\/kagglesurvey.csv')\n\n#first glance at the data\ndataset.head()","bdb75f9d":"#dataset before dropping missing values\nprint(\"Dataset Before:\")\ndataset.info()\n\ndataset = dataset.dropna()\n\n#dataset after dropping values\nprint(\"Dataset After:\")\ndataset.info()","0cb39a8a":"\"\"\" \nThis method takes the column as parameter and returns the string containing all the\nvalues that were separated by ',' and it also concats the strings like\n'Amazon Web Services' to 'AmazonWebServices' to avoid any ambiguity\n\"\"\"\ndef combineText(Column):\n    text = []\n    result = \"\"\n    for entry in Column:\n        text.append(str(entry).split(','))\n    \n    for item in text:\n        for skill in item:\n            skill = skill.replace(\" \",\"\")\n            result += skill\n            result += \" \"\n            \n    return result","486a475c":"from wordcloud import WordCloud\n#from PIL import Image\nimport matplotlib.pyplot as plt\n\ntools=combineText(dataset[\"WorkToolsSelect\"])\n\nwordcloud = WordCloud(width = 1000, height = 800,\n                     background_color =\"white\",\n                     min_font_size = 15).generate(tools)\n\n#plotting the pie chart for tools used\nplt.figure(figsize = [10, 10])\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis(\"off\")\nplt.show()","0c5b4e24":"\"\"\"\nThis method takes string as input and returns dictonary in sorted order by keys.\ninput- \"Python Python R Python\"\noutput-{'Python':3, 'R':1}\n\"\"\"\ndef countFrequency(text):\n    frequency = {}\n    text_list = text.split()\n\n    for item in text_list:\n        if item in frequency:\n            frequency[item] += 1\n        else:\n            frequency[item] = 1\n\n    sorted_dict = {}\n    sorted_keys = sorted(frequency, key = frequency.get, reverse = True)\n\n    for w in sorted_keys:\n        sorted_dict[w] = frequency[w]\n\n    return(sorted_dict)","0c334e38":"\"\"\" \nTakes sorted dictionary as input and returns the list of respective keys and values as list of list\ninput-{'Python':3, 'R':1}\noutput-[['Python','R'],[3,1]]\n\"\"\"\ndef CreateListForPlotting(sorted_dict):\n    count = []\n    skill = []\n    for key, value in sorted_dict.items():\n        skill.append(key)\n        count.append(value)\n\n    return [count,skill]  ","00b9011f":"#counting the frequency of values and getting the values in dictionary\nfrequency_dict = countFrequency(tools)\n\n#getting separate list of keys and values for above dictionary so that we can plot it\nresult_list = CreateListForPlotting(frequency_dict)\n\nfrequency = result_list[0]\nskills = result_list[1]\n","ee629325":"#getting top 20 tools used by the respondents\ny = np.array(frequency[:20])\nmylabels = skills[:20]\n\n#creating pie chart with final lists\nplt.figure(figsize = [10, 10])\nplt.pie(y, labels = mylabels,autopct='%1.1f%%',labeldistance=1.07)\nplt.show() ","76466e8e":"#quick look on the most used language\nprint(dataset[\"LanguageRecommendationSelect\"].value_counts())","dfadfb9c":"#getting value and its frequency in list to create pie chart\nlanguage = dataset['LanguageRecommendationSelect'].value_counts().keys().tolist()\ncounts = dataset['LanguageRecommendationSelect'].value_counts().tolist()\n\n#top 10 languages\ny = np.array(counts[:10])\nmylabels = language[:10]\n\n#plots pie chart for the 'LanguageRecommendationSelect' column\nplt.figure(figsize=[10, 10])\nplt.pie(y, labels = mylabels,autopct='%1.1f%%',labeldistance=1.07)\nplt.show() ","1929794e":"#first glance at the industries\nprint(dataset[\"EmployerIndustry\"].value_counts())","947f2023":"#separating keys and values from value_counts\nIndustry = dataset['EmployerIndustry'].value_counts().keys().tolist()\nIndustry_count = dataset['EmployerIndustry'].value_counts().tolist()\n\n#creating pie chart for the above lists\ny = np.array(Industry_count)\nmylabels = Industry\nplt.figure(figsize=[10, 10])\nplt.pie(y, labels = mylabels,autopct='%1.1f%%',labeldistance=1.07)\nplt.show() ","ba887027":"#filtering the columns\ntechnology= dataset[\"LanguageRecommendationSelect\"][dataset[\"EmployerIndustry\"]==\"Technology\"]\nprint(technology.head())","57fbbeac":"#language count for technology domain\nprint(technology.value_counts())","7012b91f":"#extracting result of value_counts in list for plotting\nLanguageUsed = technology.value_counts().keys().tolist()\nLanguage_count = technology.value_counts().tolist()\n\n#top 10 languages\ny = np.array(Language_count[:10])\nmylabels = LanguageUsed[:10]\n\n#pie chart for the above data\nplt.figure(figsize=[10, 10])\nplt.pie(y, labels = mylabels,autopct='%1.1f%%',labeldistance=1.07)\nplt.show() ","17ea7f2a":"#filtering the column for academic industry\nacademics= dataset[\"LanguageRecommendationSelect\"][dataset[\"EmployerIndustry\"]==\"Academic\"]\nprint(academics.head())","a2401c57":"#language and its frequency\nprint(academics.value_counts())","1d30cbc7":"##extracting result of value_counts in list for plotting\nLanguageUsed = academics.value_counts().keys().tolist()\nLanguage_count = academics.value_counts().tolist()\n\n#top 10 languages for academic domain\ny = np.array(Language_count[:10])\nmylabels = LanguageUsed[:10]\n\n#creating pie chart for languages used\nplt.figure(figsize=[10, 10])\nplt.pie(y, labels = mylabels,autopct='%1.1f%%',labeldistance=1.07)\nplt.show()","72839796":"#creating a new column by concatinating the columns 'LanguageRecommendationSelect' and 'EmployerIndustry' \ndataset[\"IndustryLanguage\"]=dataset[\"LanguageRecommendationSelect\"]+ \"-\" +dataset[\"EmployerIndustry\"]\nprint(dataset[\"IndustryLanguage\"].head())","a52b7693":"#frequency of languages used in different domains\nprint(dataset[\"IndustryLanguage\"].value_counts())","1b6687ed":"#creating list of value_counts() values\nIndustryLanguage = dataset['IndustryLanguage'].value_counts().keys().tolist()\nIndustryLanguage_count = dataset['IndustryLanguage'].value_counts().tolist()\n\n#selecting top 20 rows\ny = np.array(IndustryLanguage_count[:20])\nmylabels = IndustryLanguage[:20]\n\n#creating pie chart for the values obtained\nplt.figure(figsize=[10, 10])\nplt.pie(y, labels = mylabels,autopct='%1.1f%%',labeldistance=1.07)\nplt.show() ","8e919e27":"algorithms = combineText(dataset[\"WorkAlgorithmsSelect\"])\n\n#creating wordcloud for the algorithms string we got from above method\nwordcloud = WordCloud(width = 1000, height = 800,\n                     background_color = \"white\",\n                     min_font_size = 15).generate(algorithms)\n\nplt.figure(figsize=[10, 10])\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","cf122267":"#getting list of values and their frequency\nalgorithms_dict = countFrequency(algorithms)\nresult_list = CreateListForPlotting(algorithms_dict)\nalgorithmsFrequency = result_list[0]\nalgorithms = result_list[1]","f83047fa":"y = np.array(algorithmsFrequency)\nmylabels = algorithms\n\n#pie chart for most helpful algorithms\nplt.figure(figsize=[10, 10])\nplt.pie(y, labels = mylabels)\nplt.show()","3531bc1b":"**1.2** From the above plot we can clearly see programming languages used majorly with\n    1. Python - 15.5%\n    2. R - 12.1%\n    3. SQL - 10.7%\n\nFollowed by other tools that are being used by the respondents.","225d7dd6":"**1. Let's take a quick look at the most used tools**","43452b33":"The dataset we are using consists of string values so for missing columns we can't use imputing that we could have used with numericals values. So, its better to drop such rows.","658c3503":"**This is my first notebook. Let me know if you like it and also I am open for suggestions.**\n\n**Happy Kaggling!**","e10ca5a9":"**3. As we now know about the tools and languages, let's see on what industry these skills are mostly used**","45e1c5b6":"**Here also Python is leading with 58.5% followed by R which is at 27.8%. We can see that R in academics is used more than technology because the students are more inclined to learn new languages due to which we see a bump in it.**","1345af85":"It can be seen that the skills are widely used in technological fields such as to extract meaningful information and to predict future patterns and behavior.\n\nWhile we can also see that Academics is also not far behind technology because major number of the respondents are students who are practising the skills to get better at it.","7d17ec7d":"**2.1 From the above plot we can see that Python covers over almost 62.5% of total languages used**\n\nThe remaining top languages are:\n    1. R - 26.1%\n    2. SQL - 3.7%","51c4d0d8":"**Python is capturing a major 71.6% of the technology industry followed by R at 18.2%**","23fbac08":"**6. Next up is the algorithms respondents used widely.** \n\nThe measure does not emphasize on the eficiency of the algorithms but it indicates the algos that helped respondent in completing their task.","10342210":"# Overview\nAs the number of people who likes to play with data is increasing, the analysis of skillset and techniques that are being used by the professionals will help the beginners to get the idea of what will be helpful for them to keep in their toolkit.\n\nThe below notebook does the analysis of data that was accumulated by the survey happened on kaggle where the users have entered the skills and language they used the most for their tasks.\n\n# About Data\nThe data consists of four colums as below:\n\n1. WorkToolSelect - Tools used for analysis and processing\n2. LanguageRecommendationSelect - Language that the respondentis using\n3. EmployerIndustry - Industry\/Domain where respondent is working\n4. WorkAlgorithmSelect - Algorithms that are widely used","0993dedd":"**7. Outcome**\n\n7.1 We got the basic idea of technical skills required to do data analysis and apply models on it. Some of the tools are:\n1. JupyterNotebook\n2. Tensorflow\n3. Unix\/awk\n4. Amazon Web Services\n5. Tableau\n\n7.2 While talking about languages we have \n1. Python\n2. R\n3. SQL\n\nIn most of the cases Python outruns other languages in terms of usage, but its good to have variety in your arsenal so give a try to R as well. SQL will come into place when you have to deal with relational databases.\n\n7.3 Algorithms mostly used\n1. Regression\/Logistic Regression\n2. Decision Trees\n3. Random Forest\n4. Neural Networks\n5. Bayesian Techniques\n6. Ensemble Methods\n7. SVM\n\nHowever, the efficiency of algorithms depends on the quality and type of data. The above list gives only an idea of widely used algorithms.\n\n\n","4839ea98":"1.1 For better look of the tools used let's plot a pie chart for the column values","aae0844d":"**2. Speaking about language, let's plot for the recommended language that respondent entered.**","2de10392":"**5. Languages that are used in Academics**","0019ed66":"**5. Let's see the languages most used in each domain**","9710936e":"**5.1 Python is dominating other languages as it is used in-**\n    1. Technology\n    2. Academics\n    3. Financial","5b408bcb":"**4. Languages that are used in Technology**"}}