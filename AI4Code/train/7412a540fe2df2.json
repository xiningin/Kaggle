{"cell_type":{"93d36509":"code","14ecb229":"code","55e72020":"code","86e5e633":"code","51902b9b":"code","9085f603":"code","3cbf70be":"code","28c1586c":"code","fe5678ce":"code","db4936ca":"code","ffe43a57":"code","0110a94d":"code","707407ea":"code","69cf8cbf":"code","90e13d67":"code","ee535fde":"code","23e23e37":"code","8c93fc7f":"code","41e7e488":"code","b955f726":"code","a14123dd":"code","68aa32f8":"code","29efcf60":"code","1240c3f9":"code","ed734299":"code","3311dade":"code","bbbaf630":"code","068eea3e":"code","725af20f":"code","9eef8cb5":"code","a218be50":"markdown","2a7ac9de":"markdown","64b8f2cf":"markdown","34ee148d":"markdown"},"source":{"93d36509":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","14ecb229":"clothes = pd.read_csv('\/kaggle\/input\/clothessizeprediction\/final_test.csv')","55e72020":"clothes.head()","86e5e633":"# Let check the basic info about the dataset\nclothes.describe()","51902b9b":"clothes.info()","9085f603":"# Let's check the number of null values present in the data\nclothes.isnull().sum()","3cbf70be":"# since it is a fairly large dataset with 119734 rows,dropping these null values will have\n# very minimum effect on the model \nclothes.dropna(inplace=True)","28c1586c":"# Let's check if the value of age,weight or height is 0\nprint(f\"There are {len(clothes[clothes['age']==0])} rows with value of age as 0\")\nprint(f\"There are {len(clothes[clothes['weight']==0])} rows with values of weight as 0\")\nprint(f\"There are {len(clothes[clothes['height']==0])} rows with values of height as 0\")","fe5678ce":"# Let's remove the 18 rows as a customer can not have age as 0\nage_is_0 = clothes[clothes['age']==0]\nclothes.drop(age_is_0.index,inplace=True)","db4936ca":"# importing the libraries for visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt","ffe43a57":"# Let's check what are the different size of clothes present and how many cutomers are wearing them\nclothes['size'].unique()","0110a94d":"order = ['XXS','S','M','L','XL','XXL','XXXL']\nsns.set_style('darkgrid')\nsns.countplot(x='size',data=clothes,palette='Spectral',order=order)","707407ea":"# Let's see the relation between age,weight and height of customers and size of their clothes\n# Size vs Age\nsns.boxplot(x='size',y='age',data=clothes,order=order)","69cf8cbf":"# Size vs Weight\nsns.boxplot(x='size',y='weight',data = clothes,order=order)","90e13d67":"# Size vs Height\nsns.boxplot(x='size',y='height',data= clothes,order=order)","ee535fde":"# Let's check the correlation between the columns: weight,age,height\nclothes_corr = clothes.corr()\nsns.heatmap(clothes_corr,annot=True,cmap='YlOrBr')","23e23e37":"# Next step would be to divide the data into X which will be used as input values\n# and y which will be used as output value\nX = clothes.drop('size',axis=1).values\ny = clothes['size'].values","8c93fc7f":"# Lets check what type of values are present in y\ny","41e7e488":"# datatype of y is object which ML model will not be able to understand and process.\n# We will use LabelEncoder and to_categorical methods of sklearn and keras respectively to\n# do one hot encoding\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.utils import to_categorical","b955f726":"encoder = LabelEncoder()\ny_encoded = encoder.fit_transform(y)\ny_encoded = to_categorical(y_encoded)\ny_encoded","a14123dd":"# Let's split the data into train set and test set with 25% of data as test_set\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y_encoded,test_size=0.25,random_state = 42)","68aa32f8":"# Next task would be to do feature scaling on X_train and X_test data\n# will use MinMaxScaler method of sklearn module for feature scaling\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\n\n# will only perform fit method to X_train and not to X_test to avoid data leakage\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)","29efcf60":"# ANN model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.callbacks import EarlyStopping","1240c3f9":"# creating the model with 2 hidden layer and 7 nodes in each layers\nmodel = Sequential()\n\n# 1st hidden layer\nmodel.add(Dense(7,activation='relu',input_shape=[3]))\n\n# 2nd hidden layer\nmodel.add(Dense(7,activation='relu'))\n\n# output layer will have 7 nodes as there are 7 different sizes present\nmodel.add(Dense(7,activation='softmax'))\n\n# compiling the model\nmodel.compile(loss='categorical_crossentropy',optimizer='adam',metrics='accuracy')\n\n# model summary\nmodel.summary()","ed734299":"# earlystop is used to avoid overfitting of the model on training data.It is used to monitor\n# the performence of the model during training.It allows us to choose the large number of epochs \n# and stop training once the model performence stop improving on the validation data\nearly_stop = EarlyStopping(monitor='val_loss',mode='min',verbose = 1, patience=20)","3311dade":"# fitting the model to training data\nmodel.fit(X_train_scaled,y_train,validation_data=(X_test_scaled,y_test),epochs=300,callbacks=[early_stop])","bbbaf630":"metrics = pd.DataFrame(model.history.history)\nmetrics.head()","068eea3e":"# loss vs val_loss\nmetrics[['loss','val_loss']].plot()","725af20f":"# accuracy vs val_accuracy\nmetrics[['accuracy','val_accuracy']].plot()","9eef8cb5":"# Lets check the accuracy for X_test\nmodel.evaluate(X_test_scaled,y_test)","a218be50":"**Model Evaluation**","2a7ac9de":"Weight has the most impact on the size of clothes. With increase in weight, size of the clothes increased.","64b8f2cf":"There are very few cutomers who wear XXL size clothes","34ee148d":"**Accuracy of the model is 52.22%**"}}