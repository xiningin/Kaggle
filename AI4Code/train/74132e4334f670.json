{"cell_type":{"913ef40e":"code","9c7911f6":"code","dfd580c1":"code","d51e5575":"code","691d4989":"code","db1e176d":"code","e8845f94":"code","ef55ded2":"code","b5ab3179":"code","eb3d75b0":"code","c9fc53e8":"code","b4e38a08":"code","3109b7d1":"code","fea15cff":"code","99899496":"code","e2915635":"code","e6ced052":"code","f443d18f":"code","7261fe13":"code","34ffd9a1":"code","2151ad41":"code","d2298fc6":"code","50c035af":"code","6ada53b2":"code","8857a2eb":"code","8f3746f1":"code","3a885d94":"code","e4ec6688":"code","67d8f605":"markdown","8a0cdb2d":"markdown","90633daa":"markdown","2608e568":"markdown","3141c73e":"markdown","dcabe7ac":"markdown","ef77dd53":"markdown","4b898633":"markdown","35a267e7":"markdown","fbcbdc40":"markdown","72a9d8b2":"markdown","99202db4":"markdown"},"source":{"913ef40e":"import matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nimport time\nimport random\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom hyperopt import hp, fmin, tpe, rand, STATUS_OK, Trials\n\nSEED = 42\n\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)","9c7911f6":"def pred(model, x_test):\n    pred_prob = model.predict(x_test)\n    pred = np.argmax(pred_prob, axis = 1)\n    return pred\n\n\ndef plot_confusion_mtx(model, x_test, y_test, plot_tittle):\n    pred_prob = model.predict(x_test)\n    pred = np.argmax(pred_prob, axis = 1)\n\n    CM = confusion_matrix(y_test, pred)\n\n    plot_confusion_matrix(conf_mat = CM, figsize = (16, 8))\n    plt.title(plot_tittle)\n    plt.xticks(range(10), [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n    plt.yticks(range(10), [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n    plt.show()\n    \ndef plot_confusion_mtx2(model, x_test, y_test, plot_tittle):\n    pred= model.predict(x_test)\n\n    CM = confusion_matrix(y_test, pred)\n\n    plot_confusion_matrix(conf_mat = CM, figsize = (16, 8))\n    plt.title(plot_tittle)\n    plt.xticks(range(10), [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n    plt.yticks(range(10), [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n    plt.show()","dfd580c1":"(trainX, trainy), (testX, testy) = mnist.load_data()\nreshaped_trainX_unscaled = trainX.reshape([trainX.shape[0], -1]).astype('float32')\nreshaped_testX_unscaled = testX.reshape([testX.shape[0], -1]).astype('float32')\n\nscaler = MinMaxScaler()\n\nreshaped_trainX = scaler.fit_transform(reshaped_trainX_unscaled)\nreshaped_testX = scaler.fit_transform(reshaped_testX_unscaled)\n\nencoded_trainy = to_categorical(trainy)\nencoded_testy = to_categorical(testy)\n\nprint('\\nFormato train dataset:\\t%s\\nTrain dataset reshaped:\\t%s\\nFormato labels dataset:\\t%s' % (trainX.shape, reshaped_trainX.shape, trainy.shape))\nprint('\\nFormato test dataset:\\t%s\\nTest dataset reshaped:\\t%s\\nFormato labels dataset:\\t%s' % (testX.shape, reshaped_testX.shape, testy.shape))","d51e5575":"plt.rcParams.update({'font.size': 16})\n\nfig = plt.figure(figsize = (6, 6))\ncolumns = 4\nrows = 3\n\nfor i in range(1, columns * rows + 1):\n    rnd = np.random.randint(0, len(trainX))\n    img = trainX[rnd]  \n    fig.add_subplot(rows, columns, i)\n    plt.title(trainy[rnd])\n    plt.axis('off')\n    plt.imshow(img, cmap='gray')\n\nplt.show()","691d4989":"NN = Sequential(name = 'Simple_NN')\nNN.add(Dense(512, input_dim=784, activation='relu', name='input_layer'))\nNN.add(Dense(10, activation='softmax', name='output_layer'))\n\nprint(\"input shape \",NN.input_shape)\nprint(\"output shape \",NN.output_shape)","db1e176d":"NN.compile(loss=tf.keras.losses.categorical_crossentropy, \n           optimizer=tf.keras.optimizers.Adam(), \n           metrics=['accuracy'])\n\nNN.summary()","e8845f94":"start = time.time()\nhistory = NN.fit(reshaped_trainX, encoded_trainy, epochs=50, batch_size=64, verbose=0)\n\npredicted = pred(NN, reshaped_testX)\n\nelapsed_time = time.time() - start\n\nNN_acc = accuracy_score(testy, predicted)\nNN_time = elapsed_time\n\nprint(\"O treinamento levou %.0f segundos.\\nAcur\u00e1cia: %.4f\" % (elapsed_time, NN_acc))","ef55ded2":"print (\"Reporte de classifica\u00e7\u00e3o:\\n\")\nprint(classification_report(testy, predicted))","b5ab3179":"plot_confusion_mtx(NN, reshaped_testX, testy, 'Rede Neural Simples')","eb3d75b0":"start = time.time()\nhistory = NN.fit(reshaped_trainX_unscaled, encoded_trainy, epochs=50, batch_size=64, verbose=0)\n\npredicted = pred(NN, reshaped_testX_unscaled)\n\nelapsed_time = time.time() - start\n\nNN_acc_ns = accuracy_score(testy, predicted)\nNN_time_ns = elapsed_time\n\nprint(\"O treinamento levou %.0f segundos.\\nAcur\u00e1cia: %.4f\" % (elapsed_time, NN_acc_ns))","c9fc53e8":"print (\"Reporte de classifica\u00e7\u00e3o:\\n\")\nprint(classification_report(testy, predicted))","b4e38a08":"plot_confusion_mtx(NN, reshaped_testX, testy, 'Rede Neural Simples (Dados N\u00e3o-Normalizados)')","3109b7d1":"DNN = Sequential(name = 'Deep_NN')\nDNN.add(Dense(512, input_dim=784, activation='relu', name='input_layer'))\nDNN.add(Dense(256, activation='relu', name='hidden_layer1'))\nDNN.add(Dense(128, activation='relu', name='hidden_layer2'))\nDNN.add(Dense(64, activation='relu', name='hidden_layer3'))\nDNN.add(Dense(32, activation='relu', name='hidden_layer4'))\nDNN.add(Dense(10, activation='softmax', name='output_layer'))\n\nprint(\"input shape \",DNN.input_shape)\nprint(\"output shape \",DNN.output_shape)","fea15cff":"DNN.compile(loss=tf.keras.losses.categorical_crossentropy, \n            optimizer=tf.keras.optimizers.Adam(), \n            metrics=['accuracy'])\n\nDNN.summary()","99899496":"start = time.time()\nhistory = DNN.fit(reshaped_trainX, encoded_trainy, epochs=50, batch_size=64, verbose=0)\n\npredicted = pred(DNN, reshaped_testX)\n\nelapsed_time = time.time() - start\n\nDNN_acc = accuracy_score(testy, predicted)\nDNN_time = elapsed_time\n\nprint(\"O treinamento levou %.0f segundos.\\nAcur\u00e1cia: %.4f\" % (elapsed_time, DNN_acc))","e2915635":"print (\"Reporte de classifica\u00e7\u00e3o:\\n\")\nprint(classification_report(testy, predicted))","e6ced052":"plot_confusion_mtx(DNN, reshaped_testX, testy, 'Rede Neural Profunda')","f443d18f":"rf = RandomForestClassifier(max_depth = 5,\n                            max_features = 5,\n                            n_estimators = 50,\n                            criterion = \"entropy\",\n                            random_state = SEED, \n                            n_jobs=-1)\n\nstart = time.time()\nrf.fit(reshaped_trainX, trainy)\n\npredicted = rf.predict(reshaped_testX)\nelapsed_time = time.time() - start\n\nrf_acc = accuracy_score(testy, predicted)\nrf_time = elapsed_time\n\nprint(\"O treinamento levou %.0f segundos para os par\u00e2metros padr\u00e3o.\\nAcur\u00e1cia: %.4f\" % (elapsed_time, rf_acc))","7261fe13":"print (\"Reporte de classifica\u00e7\u00e3o:\\n\")\nprint(classification_report(testy, predicted))","34ffd9a1":"plot_confusion_mtx2(rf, reshaped_testX, testy, 'Random Forest Basal')","2151ad41":"space = {'max_depth': hp.quniform('max_depth', 1, 100, 1),\n         'max_features': hp.quniform('max_features', 1, 50, 1),\n         'n_estimators': hp.quniform('n_estimators', 25, 500, 5),\n         'criterion': hp.choice('criterion', [\"gini\", \"entropy\"])}","d2298fc6":"def rf_tuning(space):\n    \n    global best_score, best_rf_model\n    \n    clf = RandomForestClassifier(max_depth = int(space['max_depth']),\n                                 max_features = int(space['max_features']),\n                                 n_estimators = int(space['n_estimators']), \n                                 criterion = space['criterion'], n_jobs=-1, random_state = SEED)\n    \n    clf.fit(reshaped_trainX, trainy)\n\n    pred = clf.predict(reshaped_testX)\n    accuracy = 1-accuracy_score(testy, pred)\n    \n    if (accuracy < best_score):\n        best_score = accuracy\n        best_rf_model = clf\n    \n    return {'loss': accuracy, 'status': STATUS_OK }","50c035af":"trials = Trials()\nstart = time.time()\nneval = 50\nbest_score = 1.0\nbest_rf_model = []\n\nbest = fmin(fn = rf_tuning,\n            space = space,\n            algo = tpe.suggest,\n            max_evals = neval,\n            trials = trials,\n            rstate = np.random.RandomState(SEED))\n\nelapsed_time = time.time() - start\n\nrf_optim_acc = (1-best_score)\nrf_optim_time = elapsed_time","6ada53b2":"print(\"A otimiza\u00e7\u00e3o de par\u00e2metros levou %.0f segundos para %d rodadas.\\nAcur\u00e1cia: %.4f\\n\\nPar\u00e2metros \u00f3timos encontrado:\\n%s\" % (elapsed_time, neval, rf_optim_acc, best))","8857a2eb":"predicted = best_rf_model.predict(reshaped_testX)","8f3746f1":"print (\"Reporte de classifica\u00e7\u00e3o:\\n\")\nprint(classification_report(testy, predicted))","3a885d94":"plot_confusion_mtx2(best_rf_model, reshaped_testX, testy, 'Random Forest Otimizado')","e4ec6688":"print(\"Compara\u00e7\u00e3o das acur\u00e1cias\\n\\nRede Neural Simples:\\t\\t\\t%.2f%%\\nRede Neural Simples (n\u00e3o norm.):\\t%.2f%%\\nRede Neural Profunda:\\t\\t\\t%.2f%%\\nRandom Forest Basal:\\t\\t\\t%.2f%%\\nRandom Forest Otimizado:\\t\\t%.2f%%\" % (NN_acc*100, NN_acc_ns*100, DNN_acc*100, rf_acc*100, rf_optim_acc*100))\nprint(\"\\nCompara\u00e7\u00e3o dos tempos\\n\\nRede Neural Simples:\\t\\t\\t%.0f s\\nRede Neural Simples (n\u00e3o norm.):\\t%.0f s\\nRede Neural Profunda:\\t\\t\\t%.0f s\\nRandom Forest Basal:\\t\\t\\t%.0f s\\nRandom Forest Otimizado:\\t\\t%.0f s\" % (NN_time, NN_time_ns, DNN_time, rf_time, rf_optim_time))","67d8f605":"### Rede Neural Profunda com dados normalizados ","8a0cdb2d":"# Random Forest\n### Classificador Random Forest com par\u00e2metros basais","90633daa":"### Carregar fun\u00e7\u00f5es customizadas","2608e568":"### Explorar conte\u00fado","3141c73e":"# Redes Neurais\n### Rede Neural Simples com dados normalizados","dcabe7ac":"### Carregar e fazer o *reshape* do *dataset*","ef77dd53":"### Rede Neural Simples com dados n\u00e3o-normalizados","4b898633":"# An\u00e1lise Preditiva Avan\u00e7ada\n\n## Trabalho Individual\n- **Curso:** FGV MBA - Business Analytics e Big Data\n- **Disciplina:** An\u00e1lise Preditiva Avan\u00e7ada\n- **Professor:** Hitoshi Nagano e Gustavo Mirapalheta\n- **Tarefa:** Trabalho Substitutivo de Prova\n- **Link para este notebook:** [Kaggle](https:\/\/www.kaggle.com\/danielferrazcampos\/mnist-using-neural-network-random-forest-pt-br)\n\n## Aluno\n|Github|Kaggle|Nome\n|---|---|---|---|---|\n|<a href=\"https:\/\/github.com\/DanielFCampos\"><img src=\"https:\/\/avatars2.githubusercontent.com\/u\/31582602?s=460&v=4\" title=\"DanielFCampos\" width=\"40\" height=\"40\"><\/a>|<a href=\"https:\/\/www.kaggle.com\/danielferrazcampos\"><img src=\"https:\/\/storage.googleapis.com\/kaggle-avatars\/images\/3508055-kg.png\" title=\"DanielFCampos\" width=\"40\" height=\"40\"><\/a>|Daniel Campos|\n\n# Enunciado\n\n- **Instru\u00e7\u00f5es** <br>\nTurma: MSP 11924-TBABD-T1\nDisciplina: An\u00e1lise Preditiva Avan\u00e7ada (Professores Mirapalheta e Hitoshi)<\/br>\n\n- **Quest\u00e3o 1:** <br>\nTomando por base o conjunto de dados MNIST, padr\u00e3o do pacote Keras, defina e elabore uma rede neural sequencial, apresentando os formatos dos tensores de entrada e sa\u00edda, bem como os tensores intermedi\u00e1rios na rede. Treine e teste o modelo de rede neural sequencial desenvolvido, de forma que ele consiga atingir uma precis\u00e3o de pelo menos 97% no teste, no reconhecimento das imagens de n\u00fameros escritos \u00e0 m\u00e3o livre. Compare o desempenho da rede neural no treino utilizando dados normalizados e n\u00e3o normalizados ap\u00f3s 50 \u00e9pocas de treino. Aumente o n\u00famero de camadas internas da rede neural e determine se isto melhora ou n\u00e3o a qualidade dos resultados no teste. Qual o n\u00famero de camadas que voc\u00ea consideraria ideal?<\/br>\n\n- **Quest\u00e3o 2:** <br>\nResolva o mesmo problema da Quest\u00e3o 1 utilizando o algoritmo Random Forests. Tentem trabalhar a hiperparametriza\u00e7\u00e3o para aumento do desempenho. Compare o seu melhor resultado com o resultado obtido na Quest\u00e3o 1 e comente.<\/br>\n\n- **Data de Entrega** <br>\n8 de junho de 2020 23:59<\/br>","35a267e7":"### Classificador Random Forest com par\u00e2metros otimizados","fbcbdc40":"# Conclus\u00e3o","72a9d8b2":"# Resolu\u00e7\u00e3o\n### Carregar bibliotecas necess\u00e1rias","99202db4":"- **Respostas a Quest\u00e3o 1:** <br>\n    * Tomando por base o conjunto de dados MNIST, padr\u00e3o do pacote Keras, defina e elabore uma rede neural sequencial, apresentando os formatos dos tensores de entrada e sa\u00edda, bem como os tensores intermedi\u00e1rios na rede. <span style=\"color:red\">Esta quest\u00e3o foi respondida com o uso dos comandos *input_shape*, *output_shape* e *summary* na grande se\u00e7\u00e3o **Redes Neurais**. Em todas as redes neurais criadas usamos um vetor unidimensional de 784 posi\u00e7\u00f5es (correspondente ao n\u00fameros de pixels das imagens: 28x28) como entrada e 10 vetores de sa\u00edda para a classifica\u00e7\u00e3o *multi-label* do problema (n\u00fameros de 0 a 9). O comando *summary* mostra todas as camadas ocultas usadas (Rede Neural Simples com uma \u00fanica camada com 512 neur\u00f4nios + camadas de input\/output e Rede Neural Profunda com 6 camadas com 512, 256, 128, 64, 32 e 16 neur\u00f4nios cada + camadas de input\/output).\n    * Treine e teste o modelo de rede neural sequencial desenvolvido, de forma que ele consiga atingir uma precis\u00e3o de pelo menos 97% no teste, no reconhecimento das imagens de n\u00fameros escritos \u00e0 m\u00e3o livre. Compare o desempenho da rede neural no treino utilizando dados normalizados e n\u00e3o normalizados ap\u00f3s 50 \u00e9pocas de treino. <span style=\"color:red\">Os dados normalizados n\u00e3o apresentaram ganho\/perda expressiva ao modelo apesar de esperarmos que houvesse uma melhora. Entretando, vale ressaltar que temos os dados todos em mesma escala (0 a 255) e o o maior preju\u00edzo acontece quando temos *features* do modelo com m\u00ednimos e m\u00e1ximos muito diferentes entre si (fato tal que n\u00e3o acontece nesse exemplo).\n    * Aumente o n\u00famero de camadas internas da rede neural e determine se isto melhora ou n\u00e3o a qualidade dos resultados no teste. <span style=\"color:red\">O n\u00famero de camadas aumenta marginalmente a precis\u00e3o do modelo com um custo computacional bastante maior (+35-40% no tempo de processamento para o nosso caso).\n    * Qual o n\u00famero de camadas que voc\u00ea consideraria ideal? <span style=\"color:red\">Pensando em redes neurais n\u00e3o convolucionais, acredito que uma \u00fanica camada resolve o problema com uma acur\u00e1cia bastante satisfat\u00f3ria e com um tempo de processamento reduzido. Entretanto, \u00e9 sabido que a adi\u00e7\u00e3o de camadas convolucionais melhora bastante o resultado de redes neurais aplicadas a imagens, portanto, se f\u00f4ssemos adicionar camadas, o ideal seria adicionar camadas convolucionais antes das camadas sequenciais n\u00e3o-convolucionadas.\n<br><br>\n- **Respostas a Quest\u00e3o 2:** <br>\n    * Resolva o mesmo problema da Quest\u00e3o 1 utilizando o algoritmo Random Forests. Tentem trabalhar a hiperparametriza\u00e7\u00e3o para aumento do desempenho. <span style=\"color:red\">O modelo de Random Forest foi trabalhado de duas maneiras: par\u00e2metros escolhidos manualmente e fazendo uma otimiza\u00e7\u00e3o Bayesiana dos par\u00e2metros com o pacote hyperopt.\n    * Compare o seu melhor resultado com o resultado obtido na Quest\u00e3o 1 e comente. <span style=\"color:red\">Mesmo com os par\u00e2metros \u00f3timos obtidos pelo hyperopt, o modelo Random Forest n\u00e3o foi capaz de superar os modelos de redes neurais. Al\u00e9m disso, o tempo para a otimiza\u00e7\u00e3o foi muito maior do que o tempo de treinamento das redes neurais profundas deste exemplo. Entretanto, a simplicidade do modelo nos traz bons resultados com par\u00e2metros bastante simples e tempo de treino curto, sendo uma alternativa vi\u00e1vel para uma primeira abordagem ao problema."}}