{"cell_type":{"b43d82a5":"code","bf1ec2bc":"code","2505c0ac":"code","dedb4eeb":"code","1c5a3429":"code","f1da4c15":"code","6cb1a142":"code","25fb97c2":"code","1a66e612":"code","73c398ab":"code","8f969f3c":"code","9d16b66e":"code","ce9398a9":"code","6bf9235e":"code","a515a41b":"code","4ac2003e":"code","04a4cf84":"code","f540c0f3":"markdown","00ede436":"markdown","7c07409a":"markdown","94248544":"markdown","da7ee292":"markdown","2ccf6f4a":"markdown","98d082cf":"markdown","930828b4":"markdown","1eeeb921":"markdown","fed66150":"markdown"},"source":{"b43d82a5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bf1ec2bc":"#importing Libraries \nimport numpy as np \nimport pandas as pd\nimport seaborn as sns \nimport matplotlib.pyplot as plt\nfrom glob import glob\n\n#Important keras libraries\nimport keras\nfrom keras.models import Sequential\nfrom keras.models import Model\nfrom keras.layers import Input, Lambda, Dense, Flatten, Dropout\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\n","2505c0ac":"#saving the image directory paths\ntraining_dir = '\/kaggle\/input\/cat-and-dog\/training_set\/training_set'\ntesting_dir = '\/kaggle\/input\/cat-and-dog\/test_set\/test_set'","dedb4eeb":"#Vgg model images is train on 224x224 shape\nimage_size = [224,224] ","1c5a3429":"#creating vgg object\nvgg = VGG16(include_top=False,\n    weights=\"imagenet\",\n    input_shape = image_size + [3],\n    )","f1da4c15":"#as we are using pretrained model we should NOT train the weights\nfor layers in vgg.layers:\n  layers.trainable = False ","6cb1a142":"# build a model based on the VGG16\n# add 2 hidden dense layers with RELU activation and He_Normal initializer\n# add 20% dropout rate\n\nx = Flatten()(vgg.output) \nx = Dense(units = 128, kernel_initializer = 'he_normal',activation = 'relu')(x)\nx = x = Dense(units = 64, kernel_initializer = 'he_normal',activation = 'relu')(x)\nx = Dropout(0.2)(x)\noutput_layer = Dense(units = 1,activation = 'sigmoid')(x)\n\nmodel = Model(inputs=vgg.input, outputs=output_layer)\n\nmodel.summary()","25fb97c2":"#compiling model \nmodel.compile(optimizer = 'adam', loss='binary_crossentropy', metrics=['accuracy'])\n","1a66e612":"# callback function, stop training if there is no improvement after 2 epochs \n\nearly_stopping = keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)","73c398ab":"# image generator with data augmentation to increase the size of training set\n\ntrain_datagen = ImageDataGenerator(rescale=1.0\/255.0,\n                                  rotation_range=40,\n                                  width_shift_range=0.2,\n                                  height_shift_range=0.2,\n                                  zoom_range=0.2,\n                                  horizontal_flip=True,\n                                  fill_mode=\"nearest\")\n\ntrain_generator = train_datagen.flow_from_directory(training_dir,\n                                                   target_size=(224,224),\n                                                   batch_size=64,\n                                                   class_mode=\"binary\")\n\nvalidation_datagen = ImageDataGenerator(rescale=1.0\/255.0)\n\nvalidation_generator = validation_datagen.flow_from_directory(testing_dir,\n                                                 target_size=(224,224),\n                                                 batch_size=32,\n                                                 class_mode=\"binary\")","8f969f3c":"classes = ['Cat','Dog']\ntrain_generator.class_indices\n","9d16b66e":"#Vi\nX, y = validation_generator[15]\n\nfig, ax = plt.subplots(3, 5, figsize=(20, 18))\n\nfor i, axis in enumerate(ax.flat):\n    axis.imshow(X[i])\n    label = classes[int(y[i])]\n    axis.set(title=label)","ce9398a9":"#now we will fit the model\n#fit_generator is used as we are using an augmented image data set \nprediction = model.fit_generator(train_generator, \n                                 epochs=3, \n                                 validation_data = validation_generator,\n                                 )","6bf9235e":"#Plotting train, test accuracy and loss. \nplt.plot(prediction.history['accuracy'], color = 'b')\nplt.plot(prediction.history['val_accuracy'], color = 'r')\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='lower right')\nplt.figure()\n\nplt.plot(prediction.history['loss'], color = 'b')\nplt.plot(prediction.history['val_loss'], color = 'r')\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='lower right')\nplt.show()","a515a41b":"#predicting out results for 15 instances \ny_pred = model.predict(validation_generator)","4ac2003e":"y_instant = np.round(y_pred[:6])\nX, y = validation_generator[6]\n\nfig, ax = plt.subplots(2, 3, figsize=(20, 18))\n\nfor i, axis in enumerate(ax.flat):\n    axis.imshow(X[i])\n    label = y_instant[i]\n    axis.set(title=label)","04a4cf84":"from sklearn.metrics import confusion_matrix\n\ny = model.predict(validation_generator)\ny = np.reshape(predictions, 2023)\ny = np.round(y)\ncm = confusion_matrix(y_true=validation_generator.classes, y_pred=y)\ncm_plot_labels = ['cat','dog']\nsns.heatmap(cm, cmap=plt.cm.Blues,annot=True,fmt=\"d\",\n            linewidths=.5)","f540c0f3":"## Fitting our Model: ","00ede436":"## Visualizing the Data","7c07409a":"For making use of this pretrained model we will first create a VGG object. In the object we will do the following:\n\n* Incude_top will be made False . This is done to specify that we are creating our own head.\n\n* Weights will be set to 'imagenet'. This is done to specify that ImageNet weights are being used for our base.\n\n* Finally we will set the shape for our input i-e 224x224x3 where 3 shows the number of channel.\n\n","94248544":"# The Convolutional Classifier\n\nA convnet used for image classification consists of two parts: a convolutional base and a dense head.\n\nThe base is used to extract the features from an image. It is formed primarily of layers performing the convolution operation, but often includes other kinds of layers as well. (You'll learn about these in the next lesson.)\n\nThe head is used to determine the class of the image. It is formed primarily of dense layers, but might include other layers like dropout.\n","da7ee292":"## Checking Accuracy though plots and Confusion Matrix","2ccf6f4a":"## Modeling:","98d082cf":"# Data loading and Augmentation\n","930828b4":"The basic advantage of transfer learning is that it is useful when you have insufficient data for a new domain you want handled by a neural network and there is a big pre-existing data pool that can be transferred to your problem. And as VGG16 is already trained on such a large pool of data we will make use of the weights that it have obtained after training.","1eeeb921":"**The Result:**\n\nAfter training my new model with VGG16 layers with much fewer epochs, I was able to get considerably higher accuracy for both training and validation set.","fed66150":"# Defining Pretrained Base\n\nThe most commonly used dataset for pretraining is ImageNet, a large dataset of many kind of natural images. Keras includes a variety models pretrained on ImageNet in its applications module. The pretrained model we'll use is called VGG16.\n\nVGG model is usually trained on target image size of 224 x 224."}}