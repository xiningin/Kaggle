{"cell_type":{"d53a001d":"code","3901b576":"code","f48176c7":"code","673a33cb":"code","c54df6a5":"code","bf4c4dfd":"code","555430ba":"code","f476b46a":"code","55423847":"code","405c61c8":"code","fa6a9a88":"code","c48b0243":"code","5a5d9999":"code","9c1cc3f1":"code","860dd55e":"code","40c01779":"code","5b498382":"code","f8ec7e26":"code","f7579fce":"code","32947170":"code","0502fcb5":"code","3304ede8":"code","92b912b6":"code","858e8022":"code","dff772c2":"code","97937375":"code","79f1fcab":"code","42b03a6d":"code","ff4a0527":"code","6973bbd7":"code","8392d3a1":"code","b23d04ee":"code","9e59b325":"code","517e11a7":"code","e3348928":"code","42476988":"code","a70ac651":"code","0e951206":"code","1bb3dfb6":"code","43ccc5ac":"code","600091a7":"code","d5fed611":"code","1e169743":"code","f744864d":"code","e848307b":"code","c150b60c":"code","76d97a93":"code","361a396f":"code","fb3d2196":"code","c9e18bc8":"code","94f7e3d5":"code","87b36200":"code","b17815ae":"code","c058aead":"code","5a1d1bdf":"code","7df6f69a":"code","8c1f8e6e":"code","49863a4e":"code","40a1b384":"code","ce362b63":"code","895193ba":"code","86bf1549":"code","b1c30b3c":"code","3b8d2bf3":"code","27e0334a":"code","e80005a2":"code","a3b42357":"code","d885a01c":"code","65d06497":"code","541e8b6d":"code","e05e8c0a":"code","db9a0422":"code","545ebcfc":"code","78e30cf3":"code","dcc8f28e":"code","d78713e0":"code","45fe2cb6":"code","f3707207":"code","54a90745":"code","99e1cdc9":"code","85ff9383":"code","a2d3c615":"code","e5a41519":"code","2be87343":"markdown","ad9a6e96":"markdown"},"source":{"d53a001d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3901b576":"dftrain = pd.read_csv(\"\/kaggle\/input\/lish-moa\/train_features.csv\")\ndftest = pd.read_csv(\"\/kaggle\/input\/lish-moa\/test_features.csv\")\ndf = pd.concat([dftrain,dftest])\ndf.head()","f48176c7":"df.shape","673a33cb":"sns.countplot(dftrain['cp_type']) \n# TREATMENT STATUS - trt_cp -> Treated & ctl_vehicle -> control","c54df6a5":"sns.countplot(dftrain['cp_dose'])","bf4c4dfd":"sns.countplot(dftrain['cp_time']) # TREATMENT TIME","555430ba":"df.isnull().sum()","f476b46a":"df.info()","55423847":"df.columns","405c61c8":"train_target = pd.read_csv(\"..\/input\/lish-moa\/train_targets_scored.csv\")\ntrain_target.head()","fa6a9a88":"x = train_target.drop(['sig_id'],axis=1).sum(axis=0).sort_values(ascending=False).reset_index()\nx.columns = ['Protein\/Enzyme','non-zero-records']\nx.head()","c48b0243":"top = x.head(20)\nplt.figure(figsize=(20,8))\nplt.title(\"Top 20 Protein\/Enzyme Entries\")\nsns.barplot(top['Protein\/Enzyme'],top['non-zero-records'])\nplt.xticks(rotation=45)\nplt.show()","5a5d9999":"bot = x.tail(20)\nplt.figure(figsize=(20,8))\nplt.title(\"Bottom 20 Protein\/Enzyme Entries\")\nsns.barplot(bot['Protein\/Enzyme'],bot['non-zero-records'])\nplt.xticks(rotation=45)\nplt.show()","9c1cc3f1":"x = train_target.drop(['sig_id'],axis=1).sum(axis=0).sort_values(ascending=False).reset_index()\nx.columns = ['Protein\/Enzyme','non-zero-records']\nx['count'] = x['non-zero-records'] * 100 \/ len(train_target)\nx.head()","860dd55e":"top = x.head(40)\nplt.figure(figsize=(20,8))\nplt.title(\"Top 40 Protein\/Enzyme Entries by Overall percentage\")\nsns.barplot(top['Protein\/Enzyme'],top['count'])\nplt.xticks(rotation=45)\nplt.show()","40c01779":"bot = x.tail(20)\nplt.figure(figsize=(20,8))\nplt.title(\"Bottom 20 Protein\/Enzyme Entries by Overall percentage\")\nsns.barplot(bot['Protein\/Enzyme'],bot['count'])\nplt.xticks(rotation=45)\nplt.show()","5b498382":"x = train_target.drop(['sig_id'],axis=1).astype(bool).sum(axis=1).reset_index()\nx.columns = ['row','count']\nx = x.groupby(['count'])['row'].count().reset_index()\nx.head()","f8ec7e26":"sns.barplot(x['count'],x['row'])","f7579fce":"px.pie(x,values=100 * x['row']\/len(train_target),names='count',\n      title='Number of activations in targets for every sample (Percent)')","32947170":"train_target.describe()","0502fcb5":"train_columns = dftrain.columns.to_list()\ng_list = [i for i in train_columns if i.startswith('g-')]\nc_list = [i for i in train_columns if i.startswith('c-')]","3304ede8":"columns = g_list + c_list\nimport random\nforcorr = [columns[random.randint(0,len(columns)-1)] for i in range(30)]","92b912b6":"forcorr","858e8022":"corrdata = df[forcorr]","dff772c2":"plt.figure(figsize=(24,14))\nplt.title(\"Correlation Matrix for Randomly selected 30 Features\")\nsns.heatmap(corrdata.corr(),annot=True)\nplt.show()","97937375":"import time\n\nstart = time.time()\ncols = ['cp_time'] + columns\nall_columns = []\nfor i in range(0, len(cols)):\n    for j in range(i+1, len(cols)):\n        if abs(dftrain[cols[i]].corr(dftrain[cols[j]])) > 0.9:\n            all_columns.append(cols[i])\n            all_columns.append(cols[j])\n\nprint(time.time()-start)\n            ","79f1fcab":"highcorrdata = df[all_columns]","42b03a6d":"plt.figure(figsize=(24,14))\nplt.title(\"Correlation Matrix for Highly Correlated features\")\nsns.heatmap(highcorrdata.corr())\nplt.show()","ff4a0527":"target_columns = train_target.columns.tolist()\ntarget_columns.remove('sig_id')","6973bbd7":"correlation_matrix = pd.DataFrame()\nfor t_col in train_target.columns:\n    corr_list = list()\n    if t_col == 'sig_id':\n        continue\n    for col in columns:\n        res = dftrain[col].corr(train_target[t_col])\n        corr_list.append(res)\n    correlation_matrix[t_col] = corr_list","8392d3a1":"correlation_matrix['train_features'] = columns\ncorrelation_matrix = correlation_matrix.set_index('train_features')\ncorrelation_matrix","b23d04ee":"targetcols = train_target.columns.tolist()\n# target_columns.remove('sig_id')\nforanalysis = [target_columns[random.randint(0,len(target_columns)-1)] for m in range(5)]","9e59b325":"foranalysis","517e11a7":"currentcols = correlation_matrix[foranalysis]","e3348928":"currentcols","42476988":"coldf = pd.DataFrame()\ntr_first_cols = list()\ntr_second_cols = list()\ntarcols = list()\nfor col in currentcols.columns:\n    tarcols.append(col)\n    tr_first_cols.append(currentcols[col].abs().sort_values(ascending=False).reset_index()['train_features'].head(2).values[0])\n    tr_second_cols.append(currentcols[col].abs().sort_values(ascending=False).reset_index()['train_features'].head(2).values[1])","a70ac651":"coldf['column'] = tarcols\ncoldf['train_1_column'] = tr_first_cols\ncoldf['train_2_column'] = tr_second_cols\ncoldf","0e951206":"def scatterplot(coldf,index):\n    analysis = pd.DataFrame()\n    analysis['color'] = train_target[coldf.iloc[index]['column']]\n    analysis['x'] = dftrain[coldf.iloc[index]['train_1_column']]\n    analysis['y'] = dftrain[coldf.iloc[index]['train_2_column']]\n    analysis.columns = ['color',coldf.iloc[index]['train_1_column'],coldf.iloc[index]['train_2_column']]\n    analysis['size'] = 1\n    analysis.loc[analysis['color'] == 1, 'size'] = 10\n    fig = px.scatter(\n        analysis, \n        x=coldf.iloc[index]['train_1_column'], \n        y=coldf.iloc[index]['train_2_column'], \n        color=\"color\", \n        size='size', \n        height=800,\n        title='Scatter plot for ' + coldf.iloc[index]['column']\n    )\n    fig.show()","1bb3dfb6":"scatterplot(coldf, 0)","43ccc5ac":"scatterplot(coldf, 1)","600091a7":"scatterplot(coldf, 2)","d5fed611":"scatterplot(coldf,3)","1e169743":"scatterplot(coldf, 4)","f744864d":"train_targets_scored = pd.read_csv(\"\/kaggle\/input\/lish-moa\/train_targets_scored.csv\")\ntrain_targets_nonscored = pd.read_csv(\"\/kaggle\/input\/lish-moa\/train_targets_nonscored.csv\")\ntrain_features = pd.read_csv(\"\/kaggle\/input\/lish-moa\/train_features.csv\")\ntest_features = pd.read_csv(\"\/kaggle\/input\/lish-moa\/test_features.csv\")\nsample_submission = pd.read_csv(\"\/kaggle\/input\/lish-moa\/sample_submission.csv\")","e848307b":"import torch\nimport torch.nn as nn","c150b60c":"sample_submission.head()","76d97a93":"train_targets_scored.head()","361a396f":"train_features.head()","fb3d2196":"test_features.head()","c9e18bc8":"train_features[:1][[col for col in train_features.columns if 'g-' in col]].values","94f7e3d5":"gs = train_features[:1][[col for col in train_features.columns if 'g-' in col]].values.reshape(-1,1)\ngs","87b36200":"plt.plot(gs)","b17815ae":"sns.distplot(train_features['g-0'],color='red')","c058aead":"# train_features.loc[:,\"kfold\"] = -1","5a1d1bdf":"train_features.head(2)","7df6f69a":"train_features = pd.concat([train_features,pd.get_dummies(train_features['cp_time'],prefix = 'cp_time')],axis=1)\ntrain_features = pd.concat([train_features,pd.get_dummies(train_features['cp_type'],prefix = 'cp_type')],axis=1)\ntrain_features = pd.concat([train_features,pd.get_dummies(train_features['cp_dose'],prefix = 'cp_dose')],axis=1)\ntrain_features = train_features.drop(columns=['cp_time','cp_type','cp_dose'],axis=1)\n","8c1f8e6e":"train_features.head(3)","49863a4e":"       \nclass MoADataset:\n    def __init__(self, dataset, targets):\n        self.dataset = dataset\n        self.targets = targets\n\n    def __len__(self):\n        return self.dataset.shape[0]\n\n    def __getitem__(self, item):\n        return {\n            \"x\": torch.tensor(self.dataset[item, :], dtype=torch.float),\n            \"y\": torch.tensor(self.targets[item, :], dtype=torch.float),\n        }\n        \n        ","40a1b384":"    \nclass Model(nn.Module):\n    def __init__(self, num_features, num_targets):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Linear(num_features, 1024),\n            nn.BatchNorm1d(1024),\n            nn.Dropout(0.3),\n            nn.PReLU(),\n            nn.Linear(1024, 1024),\n            nn.BatchNorm1d(1024),\n            nn.Dropout(0.4),\n            nn.PReLU(),\n            nn.Linear(1024, 1024),\n            nn.BatchNorm1d(1024),\n            nn.Dropout(0.4),\n            nn.PReLU(),\n            nn.Linear(1024, num_targets),\n        )\n\n    def forward(self, x):\n        x = self.model(x)\n        return x","ce362b63":"!pip install pytorch-lightning","895193ba":"import pytorch_lightning as pl","86bf1549":"from sklearn.model_selection import train_test_split","b1c30b3c":"    \nclass MoADataModule(pl.LightningDataModule):\n    def __init__(self, hparams, data, targets):\n        super().__init__()\n        self.hparams = hparams\n        self.data = data\n        self.targets = targets\n\n    def prepare_data(self):\n        pass\n\n    def setup(self, stage=None):\n\n        train_data, valid_data, train_targets, valid_targets = train_test_split(self.data, self.targets,\n                                                                                test_size=0.2, random_state=42)\n        self.train_dataset = MoADataset(dataset=train_data.iloc[:, 1:].values,\n                                         targets=train_targets.iloc[:, 1:].values)\n        self.valid_dataset = MoADataset(dataset=valid_data.iloc[:, 1:].values,\n                                         targets=valid_targets.iloc[:, 1:].values)\n    \n    def train_dataloader(self):\n        train_loader = torch.utils.data.DataLoader(\n            self.train_dataset,\n            batch_size=1024,\n            num_workers=0,\n            shuffle=True,\n        )\n        return train_loader\n\n    def val_dataloader(self):\n        valid_loader = torch.utils.data.DataLoader(\n            self.valid_dataset,\n            batch_size=1024,\n            num_workers=0,\n            shuffle=False,\n        )\n\n        return valid_loader\n\n    def test_dataloader(self):\n        return None\n    ","3b8d2bf3":"class LitMoA(pl.LightningModule):\n    def __init__(self, hparams, model):\n        super(LitMoA, self).__init__()\n        self.hparams = hparams\n        self.model = model\n        self.criterion = nn.BCEWithLogitsLoss()\n                \n    def forward(self, x):\n        return self.model(x)\n        \n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n                                                               patience=3, threshold=0.00001, mode=\"min\", verbose=True)\n        return ([optimizer],\n                [{'scheduler': scheduler, 'interval': 'epoch', 'monitor': 'valid_loss'}])\n        \n\n    def training_step(self, batch, batch_idx):\n        data = batch['x']\n        target = batch['y']\n        out = self(data)\n        loss = self.criterion(out, target)\n        logs = {'train_loss': loss}        \n        return {'loss': loss, 'log': logs, 'progress_bar': logs}\n    \n    def training_epoch_end(self, outputs):\n        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n        logs = {'train_loss': avg_loss}\n        return {'log': logs, 'progress_bar': logs}\n    \n    def validation_step(self, batch, batch_idx):\n        data = batch['x']\n        target = batch['y']\n        out = self(data)\n        loss = self.criterion(out, target)\n        \n        logs = {'valid_loss': loss}\n        \n        return {'loss': loss, 'log': logs, 'progress_bar': logs}\n    \n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n        logs = {'valid_loss': avg_loss}\n        return {'log': logs, 'progress_bar': logs}\n    \n        \n        ","27e0334a":"trainer = pl.Trainer(gpus=1,max_epochs=50,weights_summary='full')\n","e80005a2":"train_features.head()","a3b42357":"train_targets_scored.head()","d885a01c":"net = Model(879, 206) # number of features, number of targets\nmodel = LitMoA(hparams={}, model=net)\ndm = MoADataModule(hparams={}, data=train_features, targets=train_targets_scored)","65d06497":"trainer.fit(model,dm)","541e8b6d":"test_features = pd.concat([test_features, pd.get_dummies(test_features['cp_time'], prefix='cp_time')], axis=1)\ntest_features = pd.concat([test_features, pd.get_dummies(test_features['cp_dose'], prefix='cp_dose')], axis=1)\ntest_features = pd.concat([test_features, pd.get_dummies(test_features['cp_type'], prefix='cp_type')], axis=1)\ntest_features = test_features.drop(['cp_type', 'cp_time', 'cp_dose'], axis=1)","e05e8c0a":"class TestMoADataset:\n    def __init__(self, dataset):\n        self.dataset = dataset\n\n    def __len__(self):\n        return self.dataset.shape[0]\n\n    def __getitem__(self, item):\n        return {\n            \"x\": torch.tensor(self.dataset[item, :], dtype=torch.float),\n        }","db9a0422":"test_dataset = TestMoADataset(dataset=test_features.iloc[:, 1:].values)","545ebcfc":"test_loader = torch.utils.data.DataLoader(\n            test_dataset,\n            batch_size=1024,\n            num_workers=0,\n            shuffle=False,\n        )","78e30cf3":"predictions = np.zeros((test_features.shape[0], 206))\ninference_model = model.model\ninference_model.eval()\nfor ind, batch in enumerate(test_loader):\n    p = inference_model(batch['x'])[0].detach().cpu().numpy()\n    predictions[ind * 1024:(ind + 1) * 1024] = p","dcc8f28e":"test_features1 = pd.read_csv('\/kaggle\/input\/lish-moa\/test_features.csv')\ns = pd.DataFrame({'sig_id': test_features1['sig_id'].values})","d78713e0":"s","45fe2cb6":"for col in train_targets_scored.columns[1:].tolist():\n    s[col] = 0","f3707207":"s.loc[:, train_targets_scored.columns[1:]] = predictions","54a90745":"s.head()","99e1cdc9":"test_features1.loc[test_features1['cp_type'] =='ctl_vehicle', 'sig_id']","85ff9383":"s.loc[s['sig_id'].isin(test_features1.loc[test_features1['cp_type'] =='ctl_vehicle', 'sig_id']), train_targets_scored.columns[1:]] = 0","a2d3c615":"s.to_csv('submission.csv', index=False)","e5a41519":"torch.save(model.model.state_dict(), 'model.pt')","2be87343":"# EDA","ad9a6e96":"# MODELLING\n\nI have followed this video by Abhishek Thakur for the code given below !\nIts an amazing approach i got to learn a lot :D\nhttps:\/\/www.youtube.com\/watch?v=VRVit0-0AXE"}}