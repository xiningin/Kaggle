{"cell_type":{"eb84d366":"code","9f5c9f8a":"code","ee879da7":"code","86a139a1":"code","0e7036e5":"code","8a7a7d3b":"code","3eea0992":"code","30f9c0c3":"markdown","1cea3be6":"markdown","adced576":"markdown","b1875566":"markdown","fc53c387":"markdown","b7b7d5f5":"markdown"},"source":{"eb84d366":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","9f5c9f8a":"from sklearn import preprocessing\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\n#url = 'http:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/wine-quality\/winequality-red.csv'\ndata = pd.read_csv('..\/input\/winequality-red.csv')\n\ndata.head()","ee879da7":"# X = data[[data.columns]]\nX = data.drop('quality',axis=1)\ny = data.quality\nX.head()","86a139a1":"X = preprocessing.StandardScaler().fit(X).transform(X)","0e7036e5":"model = PCA()\nresults = model.fit(X)\nplt.plot(results.explained_variance_)\nplt.show()","8a7a7d3b":"from sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import confusion_matrix\n\ngnb = GaussianNB()\nfit = gnb.fit(X,y)\npred = fit.predict(X)\nprint (confusion_matrix(pred,y))\nprint(\"accuracy: \")\nprint(confusion_matrix(pred,y).trace()*100\/confusion_matrix(pred,y).sum())","3eea0992":"predicted_correct = []\nfor i in range(1,10):\n    model = PCA(n_components = i)\n    results = model.fit(X)\n    Z = results.transform(X)\n    fit = gnb.fit(Z,y)\n    pred = fit.predict(Z)\n    predicted_correct.append(confusion_matrix(pred,y).trace())\nplt.plot(predicted_correct)\nplt.show()","30f9c0c3":"Importing our dataset:","1cea3be6":"Now,  let's see how much the accuracy get's affected with different number of variables:","adced576":"In this mini tutorial I show the process of picking the best number of variables for predictions using a method called Principal Components Analysis (PCA) ;)","b1875566":"When standardizing data, the following formula is applied to every data point:\n\nZ = (Sample - Mean)\/(Stan.Dev)\n\nIn other words, we are calculating z-scores, centering the samples by the mean and th standard deviation.","fc53c387":"As we can see, the more variables we add the more of the information we represent.\n\ni would say that 5 varaibles is a good meausure.","b7b7d5f5":"The plot shows that with only 3  variables. \nalso adding more variables beyond 5 doesn't add much predictive power as the first 5."}}