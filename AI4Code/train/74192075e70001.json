{"cell_type":{"14e5cd3e":"code","36c59dcc":"code","e49775c2":"code","beea0910":"code","3f098c0e":"code","a66860e5":"code","fcdde984":"code","b39612d0":"code","1cab66c2":"code","78356728":"code","757c2b0d":"code","ad864f73":"code","cb38b978":"code","d76b5c5d":"code","e539433e":"code","ac9257a3":"code","daab4c78":"code","1e3911e9":"code","77e76539":"code","41044136":"code","2b018bc8":"code","7f054d30":"code","134029c0":"code","2b4e5453":"code","affbcc65":"code","4cc1a819":"code","ed2f49dc":"markdown","b2995d03":"markdown","d0bfcad3":"markdown","cca2541d":"markdown","27a3575a":"markdown","1a0b178b":"markdown","6dbf8543":"markdown","3a964b5b":"markdown","a6c5f3c8":"markdown","a53f0f43":"markdown","aedc5b9b":"markdown","ac414a49":"markdown","7a549393":"markdown","4042ad4e":"markdown","16b2a16c":"markdown","5f935925":"markdown"},"source":{"14e5cd3e":"import pandas as pd\nimport numpy as np\nimport  seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split #for spliting the data \nfrom sklearn.preprocessing import MaxAbsScaler,QuantileTransformer # for scaling the data\nfrom imblearn.over_sampling import RandomOverSampler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.tree import DecisionTreeClassifier\nimport xgboost as xgb\nfrom sklearn.metrics import classification_report,plot_confusion_matrix\nfrom IPython.display import HTML\nHTML(\"\"\"\n<style>\nh1,h2,h3 {\n\tmargin: 1em 0 0.5em 0;\n\tfont-weight: 600;\n\tfont-family: 'Titillium Web', sans-serif;\n\tposition: relative;  \n\tfont-size: 36px;\n\tline-height: 40px;\n\tpadding: 15px 15px 15px 2.5%;\n\tcolor: #13003A;\n\tbox-shadow: \n\t\tinset 0 0 0 1px rgba(53,86,129, 1), \n\t\tinset 0 0 5px rgba(53,86,129, 1),\n\t\tinset -285px 0 35px white;\n\tborder-radius: 0 10px 0 15px;\n\tbackground: #fff\n    \n}\n<\/style>\n\"\"\")","36c59dcc":"data = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')\ndata.head()","e49775c2":"print('Number of rows are :',data.shape[0], ',and number of columns are :',data.shape[1])","beea0910":"data.tail()","3f098c0e":"data.shape","a66860e5":"data.describe().T.style.bar(subset=[\"mean\"],color=\"#606ff2\").background_gradient(\nsubset=[\"std\"],cmap=\"PuBu\").background_gradient(subset=[\"50%\"],cmap=\"PuBu\")","fcdde984":"data.isnull().sum()","b39612d0":"data['Class'].value_counts()","1cab66c2":"col=data.columns.to_list()\ncol","78356728":"data.duplicated().sum()\n","757c2b0d":"data.drop_duplicates(inplace=True)\nprint(\"Shape of data frame : \",data.shape)","ad864f73":"sns.scatterplot(x='Time',y='Amount',hue='Class',data=data)","cb38b978":"import warnings as wr\nwr.filterwarnings(\"ignore\")\nplt.figure(figsize=(12,6))\nax=plt.axes()\nax.set_facecolor(\"black\")\nsns.countplot(data[\"Class\"])","d76b5c5d":"num_col=['V1','V2','V3','V4','V5','V6','V7','V8','V9','V10','V11','V12','V13','V14','V15',\n         'V16','V17','V18','V19','V20','V21','V22','V23','V24','V25','V26','V27','V28','Amount','Class']","e539433e":"i = 1\nplt.figure()\nfig, ax = plt.subplots(15, 2,figsize=(24, 28))\nfor feature in num_col:\n    plt.subplot(15, 2,i)\n    sns.histplot(data[feature],color=\"aqua\", kde=True,bins=100, label='data')\n    plt.xlabel(feature, fontsize=9); plt.legend()\n    i += 1\nplt.show()","ac9257a3":"i = 1\nplt.figure()\nfig, ax = plt.subplots(15, 2,figsize=(26, 32))\nfor feature in num_col:\n    plt.subplot(15, 2,i)\n    sns.scatterplot(x=feature, \n                    y=data['Class'], \n                    data=data, \n                    palette='muted')\n    #sns.scatterplot(data[feature],color=\"blue\", palette='muted', label='data')\n    plt.xlabel(feature, fontsize=9); plt.legend()\n    i += 1\nplt.show()","daab4c78":"plt.figure(figsize=(35,20))\nsns.heatmap(data.corr(),annot=True,cmap=\"tab20c\")\nplt.show()","1e3911e9":"\nX = data.drop('Class', axis = 1)\ny = data['Class']","77e76539":"#finding correlation\nvar = data[data.columns[1:]].corr()['Class'][:]\nvar.sort_values(ascending=False)","41044136":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, \n                                                    random_state = 1, stratify = y)","2b018bc8":"X_train.shape, X_test.shape","7f054d30":"X_train,y_train = RandomOverSampler(random_state=63).fit_resample(X_train, y_train)","134029c0":"# Build Model here\nLR = make_pipeline(MaxAbsScaler(),QuantileTransformer(),xgb.XGBClassifier())\nLR.fit(X_train, y_train)","2b4e5453":"print(\"Accuracy score {:.2f} %\\n\".format(LR.score(X_test,y_test)*100))","affbcc65":"plot_confusion_matrix(LR,X_test,y_test,cmap=plt.cm.Blues)","4cc1a819":"print(classification_report(y_test,LR.predict(X_test)))","ed2f49dc":"### Checking null values","b2995d03":"## Correlation Matrix","d0bfcad3":"<center><h1    <b style=\"color:red;\">Credit Card Fraud Detection using Pipeline<\/b><\/h1><\/center>","cca2541d":"* The heatmap clearly shows which all varible are multicollinear in nature and which variable have high collinearity with the target variable.","27a3575a":"# Model Building","1a0b178b":"**There is 1081 duplicate row. let's drop it**","6dbf8543":"### features distribution ","3a964b5b":"## Duplicate Check","a6c5f3c8":"\n### Confusion Matrix\nA confusion matrix is utilized to understand the performance of the classification model or algorithm in machine learning for a given test set where results are known.\n\n","a53f0f43":"**here 0 is non fraud and 1 is fraud** \n\n","aedc5b9b":"### Handling Target Imbalance\nThe challenge of working with imbalanced datasets is that most machine learning techniques will ignore, and in turn have poor performance on, the minority class, although typically it is performance on the minority class that is most important.\n\nOne approach to addressing imbalanced datasets is to oversample the minority class. The simplest approach involves duplicating examples in the minority class.We will perform overspampling using imblearn library.\n\n","ac414a49":"**spliting the data in training set and testing set**","7a549393":"## class is outcome feture need to predict","4042ad4e":"### Feature Transformation\n#### PowerTransformer\n\nPowerTransformer applies a power transform featurewise to make data more Gaussian-like.\n\nPower transforms are a family of parametric, monotonic transformations that are applied to make data more Gaussian-like. This is useful for modeling issues related to heteroscedasticity (non-constant variance), or other situations where normality is desired.","16b2a16c":"# Please do a upvote if you like it.","5f935925":"### Classification Report\nA Classification report is used to measure the quality of predictions from a classification algorithm. How many predictions are True, how many are False.\n\n**where:**\n\n* Precision:- Accuracy of positive predictions.\n* Recall:- Fraction of positives that were correctly identified.\n* f1-score:- percent of positive predictions were correct\n* support:- Support is the number of actual occurrences of the class in the specified dataset."}}