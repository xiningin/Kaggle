{"cell_type":{"d5b09987":"code","e7937717":"code","a17ed416":"code","49baf656":"code","d6c4b5f9":"code","99f311cd":"code","553f0b5d":"code","e84f0583":"code","d2355e62":"code","15fd386f":"code","99639442":"code","d34e060d":"code","ce1089f5":"code","098a6482":"code","6954c8e4":"code","424f9321":"markdown","da04a3ac":"markdown","1f1ac36c":"markdown","7c45b6e1":"markdown","e3143cca":"markdown","b04397cb":"markdown","51180276":"markdown","c4dcce24":"markdown","8b50b198":"markdown","67e1d6f0":"markdown","06f3c065":"markdown","df1999c0":"markdown","fdc42f13":"markdown"},"source":{"d5b09987":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e7937717":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Supress Warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# To impute missing Values\nfrom sklearn.impute import SimpleImputer","a17ed416":"df = pd.read_csv('..\/input\/tabular-playground-series-oct-2021\/train.csv')\ndf_test = pd.read_csv('..\/input\/tabular-playground-series-oct-2021\/test.csv')\nsubmission_sample = pd.read_csv('..\/input\/tabular-playground-series-oct-2021\/sample_submission.csv')","49baf656":"df.head(5)","d6c4b5f9":"df.isnull().sum().sum()","99f311cd":"df_test.isnull().sum().sum()","553f0b5d":"df.describe().style.background_gradient(cmap='bone_r')","e84f0583":"df.drop('id', axis=1, inplace=True)","d2355e62":"df.dtypes.unique()","15fd386f":"df.corr()[['target']].T.style.background_gradient('copper_r')","99639442":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ndf_scaled = scaler.fit_transform(df)\ndf_test_scaled = scaler.transform(df_test)","d34e060d":"df_scal = pd.DataFrame(df_scaled, columns=df.columns)","ce1089f5":"df_scal.head()","098a6482":"fig, ax = plt.subplots(8, 1, figsize = (25,25))\nsns.boxplot(data = df_scal.iloc[:, 1:30], ax = ax[0])\nsns.boxplot(data = df_scal.iloc[:, 30:60], ax = ax[1])\nsns.boxplot(data = df_scal.iloc[:, 60:90], ax = ax[2])\nsns.boxplot(data = df_scal.iloc[:, 90:120], ax = ax[3])\nsns.boxplot(data = df_scal.iloc[:, 120:150], ax = ax[4])\nsns.boxplot(data = df_scal.iloc[:, 150:180], ax = ax[5])\nsns.boxplot(data = df_scal.iloc[:, 180:210], ax = ax[6])\nsns.boxplot(data = df_scal.iloc[:, 210:285], ax = ax[7])","6954c8e4":"nrows = 57\nncols = 5\ni = 0\n\nfig, ax = plt.subplots(nrows, ncols, figsize = (25,75))\n\nfor row in range(nrows):\n    for col in range(ncols):\n        sns.histplot(data = df.iloc[:, i], bins = 50, ax = ax[row, col], palette  = 'bone_r').set(ylabel = '')\n        i += 1","424f9321":"# Droping ID column","da04a3ac":"# Checking Null values","1f1ac36c":"# Normalizing the data","7c45b6e1":"# Thank you!\n# If you like it please upvote it. If you have suggestion please leave it in comment.\n# Even I am beginner looking forward to learn something new. So let me know how can I improve this","e3143cca":"Many of the features dont have normal distribution. Some features are with 0\/1 values. In that case also there are imbalances. \nOne of the ways to treat this is to use some transformations(log, sqrt etc) to get normal distribution from the skewed distribution.","b04397cb":"# Distribution of variables","51180276":"# Importing Libraries","c4dcce24":"# Describing data","8b50b198":"There are lot of outliers in many features. This must be taken care.","67e1d6f0":"## No missing data in both test and train data","06f3c065":"# Correlation checking","df1999c0":"# Reading data","fdc42f13":"# Outlier checking"}}