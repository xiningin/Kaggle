{"cell_type":{"eb687058":"code","4f66b9c1":"code","6606e58b":"code","0dc508b5":"code","193787f9":"code","947b368d":"code","03a1b566":"code","f81cf37c":"code","e31902b1":"code","b3aea472":"code","6abf43fb":"code","80462bc4":"code","f1e73280":"code","fe346422":"code","30a59723":"code","cb3ef805":"code","84b4e50e":"code","1eea35fa":"code","e5052b65":"code","2a55e77a":"code","80dbf0d2":"code","98ed1ef7":"code","fcfdcb29":"code","08c4abcf":"code","e3e39a46":"code","7ae64379":"code","19b15249":"code","2095c012":"code","f7f304aa":"code","000aa837":"code","a949beef":"code","21d8a22a":"code","a4a004ae":"code","54384300":"code","8ea94533":"code","dc31bebe":"code","d65c6b77":"code","fd8fa026":"code","ea7955cc":"code","2870f924":"code","7be88222":"code","f804007a":"code","b0e5e98b":"markdown","5178a60e":"markdown","6dd64a13":"markdown","07829b88":"markdown","435799c4":"markdown","5fd93ed1":"markdown","b24fa63b":"markdown","7f37e93d":"markdown","0cd02f25":"markdown","a0c8de9f":"markdown","92a73dc0":"markdown","817381a4":"markdown","d4343e6f":"markdown","90c10a36":"markdown","896dc07f":"markdown"},"source":{"eb687058":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","4f66b9c1":"import numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nsns.set_style('darkgrid')\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier","6606e58b":"heart = pd.read_csv(\"\/kaggle\/input\/heart-disease-uci\/heart.csv\")","0dc508b5":"heart.head(3)","193787f9":"# GENDER\n\n# female = 0\n# male = 1\n\nfemale = len(heart[heart['sex'] ==0])\nmale = len(heart[heart['sex'] ==1])\n\nprint('Percentage of female: {:.2f} %' .format(female\/len(heart['sex'])*100))\nprint('Percentage of male: {:.2f} %' .format(male\/len(heart['sex'])*100))","947b368d":"plt.figure(figsize=(15,8))\ncbar_kws = { 'ticks' : [-1, -0.5, 0, 0.5, 1], 'orientation': 'horizontal'}\nsns.heatmap(heart.corr(), cmap='PuBu', linewidths=0.1, annot=True, vmax=1, vmin=-1, cbar_kws=cbar_kws)","03a1b566":"plt.figure(figsize=(15,8))\nsns.distplot(heart['age'], hist=True, bins=30, color='grey')\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.title('Distribution of age', fontsize=15)","f81cf37c":"heart['sex'].value_counts","e31902b1":"plt.figure(figsize=(15,8))\nsns.countplot(heart['sex'], palette='PuBu')\nplt.xlabel('Gender')\nplt.ylabel('Count')\nplt.title('Gender', fontsize=15)","b3aea472":"plt.figure(figsize=(15,8))\nsns.countplot(heart['age'], hue=heart['sex'], palette='PuBu', saturation=0.8)\nplt.xlabel('Age')\nplt.ylabel('Count')\nplt.title('Gender count', fontsize=15)\nplt.legend(loc='upper right', fontsize=15, labels=['Female', 'Male'])","6abf43fb":"plt.figure(figsize=(15,8))\nsns.countplot(heart['target'], palette='PuBu')\nplt.xlabel('Target')\nplt.ylabel('Count')\nplt.title('Target count', fontsize=15)","80462bc4":"plt.figure(figsize=(15,8))\nsns.countplot(heart['age'], hue=heart['target'], palette='PuBu', saturation=0.8)\nplt.xlabel('Age')\nplt.ylabel('Count')\nplt.title('Target count', fontsize=15)\nplt.legend(loc='upper right', fontsize=15, labels=['No disease', 'Disease'])","f1e73280":"countNoDisease = len(heart[heart.target == 0])\ncountHaveDisease = len(heart[heart.target == 1])\nprint(\"Percentage of Patients without Heart Disease: {:.2f}%\".format((countNoDisease \/ (len(heart.target))*100)))\nprint(\"Percentage of Patients with Heart Disease: {:.2f}%\".format((countHaveDisease \/ (len(heart.target))*100)))","fe346422":"pd.crosstab(heart.sex,heart.target).plot(kind=\"bar\",figsize=(15,6),color=['#1CA53B','#AA1111' ])\nplt.title('Heart Disease Frequency for Sex')\nplt.xlabel('Sex (0 = Female, 1 = Male)')\nplt.xticks(rotation=0)\nplt.legend([\"No Disease\", \"Disease\"])\nplt.ylabel('Frequency')\nplt.show()","30a59723":"pd.crosstab(heart.fbs,heart.target).plot(kind=\"bar\",figsize=(15,6),color=['#1CA53B','#AA1111' ])\nplt.title('Heart Disease Frequency Fasting Blood Sugar')\nplt.xlabel('FBS - (Fasting Blood Sugar > 120 mg\/dl) (1 = true; 0 = false)')\nplt.xticks(rotation=0)\nplt.legend([\"No Disease\", \"Disease\"])\nplt.ylabel('Frequency')\nplt.show()","cb3ef805":"pd.crosstab(heart.cp,heart.target).plot(kind=\"bar\",figsize=(15,6),color=['g','m'])\nplt.title('Heart Disease Frequency Chest Pain')\nplt.xlabel('Chest Pain Type')\nplt.xticks(rotation=0)\nplt.legend([\"No Disease\", \"Disease\"])\nplt.ylabel('Frequency')\nplt.show()","84b4e50e":"plt.scatter(x=heart.age[heart.target==1], y=heart.thalach[(heart.target==1)], c=\"violet\")\nplt.scatter(x=heart.age[heart.target==0], y=heart.thalach[(heart.target==0)])\nplt.legend([\"Disease\", \"Not Disease\"])\nplt.xlabel(\"Age\")\nplt.ylabel(\"Maximum Heart Rate\")\nplt.show()","1eea35fa":"pd.crosstab(heart.slope,heart.target).plot(kind=\"bar\",figsize=(15,6),color=['r','b'])\nplt.title('Heart Disease Frequency for Slope')\nplt.xlabel('The Slope of The Peak Exercise ST Segment ')\nplt.xticks(rotation = 0)\nplt.ylabel('Frequency')\nplt.show()","e5052b65":"heart.head(2)","2a55e77a":"a = pd.get_dummies(heart['cp'], prefix = \"cp\")\nb = pd.get_dummies(heart['thal'], prefix = \"thal\")\nc = pd.get_dummies(heart['slope'], prefix = \"slope\")","80dbf0d2":"frames = [heart, a, b, c]\nheart = pd.concat(frames, axis = 1)\nheart.head()","98ed1ef7":"heart = heart.drop(columns = ['cp', 'thal', 'slope'])\nheart.head()","fcfdcb29":"y = heart.target.values\nx_data = heart.drop(['target'], axis = 1)","08c4abcf":"# Normalize\nx = (x_data - np.min(x_data)) \/ (np.max(x_data) - np.min(x_data)).values","e3e39a46":"x","7ae64379":"x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2, random_state=0 )","19b15249":"accuracies = {}\n\nlr = LogisticRegression()\nlr.fit(x_train,y_train)\nacc = lr.score(x_test,y_test)*100\n\naccuracies['Logistic Regression'] = acc\nprint(\"Test Accuracy {:.2f}%\".format(acc))","2095c012":"from sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(x_train, y_train)\n\nacc = nb.score(x_test,y_test)*100\naccuracies['Naive Bayes'] = acc\nprint(\"Accuracy of Naive Bayes: {:.2f}%\".format(acc))","f7f304aa":"svm = SVC(random_state = 1)\nsvm.fit(x_train, y_train)\n\nacc = svm.score(x_test,y_test)*100\naccuracies['SVM'] = acc\nprint(\"Test Accuracy of SVM Algorithm: {:.2f}%\".format(acc))","000aa837":"from sklearn.tree import DecisionTreeClassifier\ndtc = DecisionTreeClassifier()\ndtc.fit(x_train, y_train)\n\nacc = dtc.score(x_test, y_test)*100\naccuracies['Decision Tree'] = acc\nprint(\"Decision Tree Test Accuracy {:.2f}%\".format(acc))","a949beef":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators = 1000, random_state = 1)\nrf.fit(x_train, y_train)\n\nacc = rf.score(x_test,y_test)*100\naccuracies['Random Forest'] = acc\nprint(\"Random Forest Algorithm Accuracy Score : {:.2f}%\".format(acc))","21d8a22a":"colors = [\"purple\", \"green\", \"orange\", \"magenta\",\"#CFC60E\",\"#0FBBAE\"]\n\nsns.set_style(\"whitegrid\")\nplt.figure(figsize=(16,5))\nplt.yticks(np.arange(0,100,10))\nplt.ylabel(\"Accuracy %\")\nplt.xlabel(\"Algorithms\")\nsns.barplot(x=list(accuracies.keys()), y=list(accuracies.values()), palette=colors)\nplt.show()","a4a004ae":"rf = RandomForestClassifier()","54384300":"from sklearn.model_selection import GridSearchCV","8ea94533":"#Using grid search to get best params for Randomforest\nparams = {\n    'n_estimators':[10,50,100,150,200,250],\n    'random_state': [10,5,15,20,50]\n         }\ngs = GridSearchCV(rf, param_grid=params, cv=5, n_jobs=-1)\ngs.fit(x_train,y_train)","dc31bebe":"# Grid Search Score with test Data\nprint(\"Grid search score with random forest classifier = \",gs.score(x_test,y_test)*100)","d65c6b77":"#Best Params\ngs.best_params_","fd8fa026":"# Creating the Confusion matrix\npred = gs.predict(x_test)\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(y_pred=pred, y_true=y_test)","ea7955cc":"from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier","2870f924":"ab = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(),n_estimators=1000)\nab.fit(x_train,y_train)\nprint('AdaBoost Accuracy with Decision Tree = ',(ab.score(x_test,y_test)*100))","7be88222":"ab = AdaBoostClassifier(base_estimator=LogisticRegression(max_iter=1000,solver = 'lbfgs'),n_estimators=1000)\nab.fit(x_train,y_train)\nprint('AdaBoost Accuracy with Logistic Reg = ',(ab.score(x_test,y_test)*100))","f804007a":"ab = AdaBoostClassifier(algorithm='SAMME',base_estimator=SVC(kernel='linear',C = 1000, gamma=1),n_estimators=1000)\nab.fit(x_train,y_train)\nprint('AdaBoost Accuracy with SVC = ',(ab.score(x_test,y_test)*100))","b0e5e98b":"# Male and Female - Heart Disease Frequency","5178a60e":"# Grid Search CV","6dd64a13":"# Target at different ages","07829b88":"# Distribution-Age","435799c4":"# HEAT-MAP for Heart Patients","5fd93ed1":"# Count-Sex","b24fa63b":"# MIN MAX SCALING - NORMALIZATION","7f37e93d":"# Target Count","0cd02f25":"# Attribute Information:\n1. age\n2. sex\n3. chest pain type (4 values)\n4. resting blood pressure\n5. serum cholestoral in mg\/dl\n6. fasting blood sugar > 120 mg\/dl\n7. resting electrocardiographic results (values 0,1,2)\n8. maximum heart rate achieved\n9. exercise induced angina\n10. oldpeak = ST depression induced by exercise relative to rest\n11. the slope of the peak exercise ST segment\n12. number of major vessels (0-3) colored by flourosopy\n13. thal: 3 = normal; 6 = fixed defect; 7 = reversable defect","a0c8de9f":"[Heart-diseases.jpg](attachment:Heart-diseases.jpg)","92a73dc0":"# Gender Count at different ages","817381a4":"# DUMMY VARIABLES FOR CATEGORICAL VARIABLES - chest pain type, thal type and slope type","d4343e6f":"# Percentage of Target","90c10a36":"# Conclusion\n# This dataset is very small but helped us to create a simple model and machine learning techniques. Cholesterol and age would be major factors in the model. I have learnt basically about a heart disease.\n\n# ML technologies have become increasingly important and has a greater role in medical devices and Pharma Industry","896dc07f":"# Logistic Regression"}}