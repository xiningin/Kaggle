{"cell_type":{"37fd265a":"code","d8d5878f":"code","bb438675":"code","859a6057":"code","014f9282":"code","4acb6fc1":"code","6be4b875":"code","5c36bcea":"code","c2dc8964":"code","92083cb5":"code","60d391b0":"code","046889d0":"code","e554d136":"code","c11e032d":"code","9b44d7fe":"code","d5dd0550":"code","7da80ea5":"code","f05f12b1":"code","7273ef2a":"code","524bc8a8":"code","8a7b4abc":"code","15cda6e2":"code","681b9744":"code","193da8d0":"code","12ac056f":"code","b462d28b":"code","0d576b9c":"code","4c9ec617":"code","5fdc126f":"code","f622a142":"code","9ebae3ae":"markdown","82e1c3be":"markdown","f7a54ff5":"markdown","8bfad22b":"markdown","354ff580":"markdown","643113d7":"markdown","99dad749":"markdown","40ca7131":"markdown","283bcec7":"markdown","628dbf82":"markdown","3ddc450a":"markdown","ded6f358":"markdown","c1cfacad":"markdown","afc4113f":"markdown","9391a180":"markdown","124ed42b":"markdown","b1240c13":"markdown","644c1195":"markdown","38ec7c06":"markdown","00876544":"markdown","a4b5c820":"markdown","5a1837a0":"markdown","57c692dd":"markdown","33a34d73":"markdown","615dd1ab":"markdown","4e932d9c":"markdown","9147ba5a":"markdown","492cf5e1":"markdown","90002446":"markdown","3dcb8738":"markdown"},"source":{"37fd265a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","d8d5878f":"train_X = pd.read_csv('..\/input\/X_train.csv')\ncolumns = train_X.columns\ntrain_X = train_X.iloc[:,3:].values.reshape(-1,128,10)\ntest_X  = pd.read_csv('..\/input\/X_test.csv' ).iloc[:,3:].values.reshape(-1,128,10)\nprint('train_X shape:', train_X.shape, ', test_X shape:', test_X.shape)","bb438675":"df_train_y = pd.read_csv('..\/input\/y_train.csv')\n\n# build a dict to convert surface names into numbers\nsurface_names = df_train_y['surface'].unique()\nnum_surfaces = len(surface_names)\nsurface_to_numeric = dict(zip(surface_names, range(num_surfaces)))\nprint('Convert to numbers: ', surface_to_numeric)\n\n# y and group data as numeric values:\ntrain_y = df_train_y['surface'].replace(surface_to_numeric).values\ntrain_group = df_train_y['group_id'].values","859a6057":"fig, axes = plt.subplots(1,4)\nfig.set_size_inches(20,3)\n\nfor i in range(4):\n    axes[i].plot(train_X[train_group == 17][:,:,i].reshape(-1))\n    axes[i].grid(True)","014f9282":"def sq_dist(a,b):\n    ''' the squared euclidean distance between two samples '''\n    \n    return np.sum((a-b)**2, axis=1)\n\n\ndef find_run_edges(data, edge):\n    ''' examine links between samples. left\/right run edges are those samples which do not have a link on that side. '''\n\n    if edge == 'left':\n        border1 = 0\n        border2 = -1\n    elif edge == 'right':\n        border1 = -1\n        border2 = 0\n    else:\n        return False\n    \n    edge_list = []\n    linked_list = []\n    \n    for i in range(len(data)):\n        dist_list = sq_dist(data[i, border1, :4], data[:, border2, :4]) # distances to rest of samples\n        min_dist = np.min(dist_list)\n        closest_i   = np.argmin(dist_list) # this is i's closest neighbor\n        if closest_i == i: # this might happen and it's definitely wrong\n            print('Sample', i, 'linked with itself. Next closest sample used instead.')\n            closest_i = np.argsort(dist_list)[1]\n        dist_list = sq_dist(data[closest_i, border2, :4], data[:, border1, :4]) # now find closest_i's closest neighbor\n        rev_dist = np.min(dist_list)\n        closest_rev = np.argmin(dist_list) # here it is\n        if closest_rev == closest_i: # again a check\n            print('Sample', i, '(back-)linked with itself. Next closest sample used instead.')\n            closest_rev = np.argsort(dist_list)[1]\n        if (i != closest_rev): # we found an edge\n            edge_list.append(i)\n        else:\n            linked_list.append([i, closest_i, min_dist])\n            \n    return edge_list, linked_list\n\n\ndef find_runs(data, left_edges, right_edges):\n    ''' go through the list of samples & link the closest neighbors into a single run '''\n    \n    data_runs = []\n\n    for start_point in left_edges:\n        i = start_point\n        run_list = [i]\n        while i not in right_edges:\n            tmp = np.argmin(sq_dist(data[i, -1, :4], data[:, 0, :4]))\n            if tmp == i: # self-linked sample\n                tmp = np.argsort(sq_dist(data[i, -1, :4], data[:, 0, :4]))[1]\n            i = tmp\n            run_list.append(i)\n        data_runs.append(np.array(run_list))\n    \n    return data_runs","4acb6fc1":"train_left_edges, train_left_linked  = find_run_edges(train_X, edge='left')\ntrain_right_edges, train_right_linked = find_run_edges(train_X, edge='right')\nprint('Found', len(train_left_edges), 'left edges and', len(train_right_edges), 'right edges.')","6be4b875":"train_runs = find_runs(train_X, train_left_edges, train_right_edges)","5c36bcea":"flat_list = [series_id for run in train_runs for series_id in run]\nprint(len(flat_list), len(np.unique(flat_list)))","c2dc8964":"print([ len(np.unique(train_y[run])) for run in train_runs ])","92083cb5":"print([ len(np.unique(train_group[run])) for run in train_runs ])","60d391b0":"fig, axes = plt.subplots(10,1, sharex=True)\nfig.set_size_inches(20,15)\nfig.subplots_adjust(hspace=0)\n\nfor i in range(10):\n    axes[i].plot(train_X[train_runs[0]][:,:,i].reshape(-1))\n    axes[i].grid(True)","046889d0":"df_train_y['run_id'] = 0\ndf_train_y['run_pos'] = 0\n\nfor run_id in range(len(train_runs)):\n    for run_pos in range(len(train_runs[run_id])):\n        series_id = train_runs[run_id][run_pos]\n        df_train_y.at[ series_id, 'run_id'  ] = run_id\n        df_train_y.at[ series_id, 'run_pos' ] = run_pos\n\ndf_train_y.to_csv('y_train_with_runs.csv', index=False)\ndf_train_y.tail()","e554d136":"test_left_edges, test_left_linked  = find_run_edges(test_X, edge='left')\ntest_right_edges, test_right_linked = find_run_edges(test_X, edge='right')\nprint('Found', len(test_left_edges), 'left edges and', len(test_right_edges), 'right edges.')","c11e032d":"test_runs = find_runs(test_X, test_left_edges, test_right_edges)","9b44d7fe":"flat_list = [series_id for run in test_runs for series_id in run]\nprint(len(flat_list), len(np.unique(flat_list)))","d5dd0550":"lost_samples = np.array([ i for i in range(len(test_X)) if i not in np.concatenate(test_runs) ])\nprint(lost_samples)\nprint(len(lost_samples))","7da80ea5":"find_run_edges(test_X[lost_samples], edge='left')[1][0]","f05f12b1":"lost_run = np.array(lost_samples[find_runs(test_X[lost_samples], [0], [5])[0]])\ntest_runs.append(lost_run)","7273ef2a":"fig, axes = plt.subplots(10,1, sharex=True)\nfig.set_size_inches(20,15)\nfig.subplots_adjust(hspace=0)\n\nfor i in range(10):\n    axes[i].plot(test_X[test_runs[1]][:,:,i].reshape(-1))\n    axes[i].grid(True)","524bc8a8":"print(f\"There is {len(test_runs)} runs of series containing one or several groups of surfaces\")","8a7b4abc":"import scaleogram as scg\nperiods         = np.logspace(np.log10(1), np.log10(1024), 50)\nwavelet_scales  = scg.periods2scales( periods )\n\ndef plot_cwt_run(id_run):\n    id_series = train_runs[id_run]\n    surfaces = df_train_y[df_train_y.series_id.isin(id_series)].surface.values\n    print(f\"surfaces in run={id_run}: \", surfaces)\n    (fig1, axes1) = plt.subplots(6, 1, figsize=(10,4))\n    (fig2, axes2) = plt.subplots(6, 1, figsize=(11,9))\n    for i in range(4,10):\n        title   = f'surface={surfaces[0]} movement sensors train_grp={id_run} '\n        signal = train_X[id_series][:,:,i].ravel()[0:1024*4]\n        signal -= signal.mean()\n        axes1[i-4].plot(signal)\n        axes1[i-4].set_xlim(0,1024*4)\n        plt.xlim(0, len(signal))\n        scg.cws(signal, scales=wavelet_scales, ax=axes2[i-4], yscale='log',\n               title=\"\", clim=(0, 0.2) if i < 7 else (0, 4), \n               xlim=(0, 1024*4))\n    axes1[0].set_title(title)\n    axes2[0].set_title(title)\n    fig1.subplots_adjust(hspace=0)\n    fig2.subplots_adjust(hspace=0)\n    #fig2.tight_layout()\n        \n","15cda6e2":"for (irun, run) in enumerate(train_runs):\n    surface = df_train_y[df_train_y.series_id==run[0]].surface.values[0]\n    print(f\"run={irun} surface={surface}\")","681b9744":"plot_cwt_run(2)","193da8d0":"plot_cwt_run(10)","12ac056f":"plot_cwt_run(27)","b462d28b":"plot_cwt_run(51)","0d576b9c":"plot_cwt_run(23)","4c9ec617":"plot_cwt_run(0)","5fdc126f":"plot_cwt_run(26)","f622a142":"plot_cwt_run(3)","9ebae3ae":"# Wavelet transforms","82e1c3be":"# Cnaining of series","f7a54ff5":"...and y \/ group data:","8bfad22b":"This kernel is a fork of Markus [Missing Link](https:\/\/www.kaggle.com\/friedchips\/the-missing-link) that chaines series.\n\nThe continuous wavelet transform of chained series for each surface are shown bellow as scaleograms. These views allow to see both frequency related and time related features. Interresting patterns shows up at scales larger than 128 samples.","354ff580":"# Hard tiles","643113d7":"...But wait. Might this also work with the test data?","99dad749":"Scaleo","40ca7131":"I'll leave you with a caution and an exercise:\nFirst, there are certainly some errors in the test runs. Two runs with different surfaces might have been stitched into one (as happened 4 times with the train data) by chance.\nSecond, might it even be possible to link *across train and test*? Well, see for yourself...","283bcec7":"Let's add our new knowledge to train_y. Now you can use this info to train your models to even greater perfection. Enjoy!","628dbf82":"Now for the real test. How many different surfaces are in each run? *Only 4 runs have more than one surface* (and if you look at them, you can easily split them by hand). This actually works!","3ddc450a":"# Soft PVC","ded6f358":"Perfect. Now we also have test runs. A nice plot to prove it:","c1cfacad":"# Soft tiles","afc4113f":"Let's plot the 4 orientation channels of a random group in series:","9391a180":"First, let's get our raw data:","124ed42b":"Well, that certainly looks promising. Found 76 runs, similar number than the number of groups. Build the runs:","b1240c13":"[](http:\/\/) 3816 - 3790 = 26 series are not in any run and aren't edges. They must form a closed ring -> another run. find it:","644c1195":"# Concrete","38ec7c06":"Let's go:","00876544":"Oh yeah!","a4b5c820":"# Wood","5a1837a0":"Well, that certainly looks like a jigsaw puzzle to me. And that leads to an idea: the euclidean distance in the 4-dimensional \"orientation space\" between, for example, the right edge of one sample and the left edge of its true neighbor should be a minimum, *ideally even among all samples*, not only the samples in its group. Same for left\/right. This should enable us to stitch the runs together again. All we have to do is link samples together which are *each other's* closest neighbors. Let's code:","57c692dd":"Have we found all samples? Have we used any sample twice? The answer is yes, and no. Perfect.","33a34d73":"Let's plot all 10 channels for one run.  Beautiful.","615dd1ab":"# Hard tiles large space","4e932d9c":"# Fine concrete\n","9147ba5a":"# Tiled","492cf5e1":"Interesting. Some runs contain  2, 3 and even 4 groups. So several groups were cut from one run:","90002446":"Again no samples are used twice, but we have lost some.","3dcb8738":"# Surfaces by run group\n\nnote: a run group is the series_id which are grouped together\n"}}