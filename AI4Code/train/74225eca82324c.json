{"cell_type":{"7f825d10":"code","82390460":"code","7a3de5d3":"code","81a0266f":"code","97ceaad1":"code","37dcfa4e":"code","1bcaa38d":"code","e0cb950d":"code","0469a308":"code","251f7635":"code","6882f52b":"code","4a35c23b":"code","c3a36280":"code","a5e8d2d8":"code","124638b7":"code","493b77f2":"code","f46c8050":"code","78672dc8":"code","fc174f9c":"code","5bb1c2bb":"code","dcf5f58c":"code","299d1bc3":"code","e1303b45":"code","ce2a35db":"code","dab09ed2":"code","169331e4":"code","34957b0c":"code","6bd89799":"code","0605fdd0":"code","0a5c4a80":"code","3ae0cb40":"code","ac708e24":"code","504681c4":"code","63a9c6ca":"code","fa6fd7ab":"code","c9784956":"code","d701aa67":"code","1969ce45":"code","2e329b9d":"code","cb9525f9":"code","427d228d":"code","9581bd1a":"code","840a5d52":"code","1b0ff99b":"code","9d26c9ea":"code","8bcbde87":"code","9f880e5e":"code","8a2a2ac8":"code","20d2d10e":"code","2a57e744":"code","ffe378c7":"code","1640d77b":"code","5d9098f3":"code","eb1f8442":"code","0b66dc21":"code","dc6ca069":"code","aa40124b":"code","3a3872b3":"code","d0680023":"code","45e86d66":"code","312b3c7a":"code","125084c6":"code","b275315d":"code","69c0277f":"code","c52420cd":"code","2b12c49b":"code","1162463b":"code","088b1c5a":"code","b1fa5441":"code","939037fc":"code","824e3765":"code","d7ca1f5c":"code","573147a5":"code","870e23b4":"code","cfe77759":"code","7668ca01":"code","b4a9b64d":"code","f2e30e22":"code","cb0ec2a4":"markdown","e7a1330b":"markdown"},"source":{"7f825d10":"# Importing Modules\n\nimport pandas as pd\nimport numpy as np\nimport json\nimport os\n\nfrom PIL import Image,ImageFont\n%pylab inline\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline\nimport seaborn as sns\n\nimport os\nimport sys\nimport random\nimport math\nimport numpy as np\nimport skimage.io\nfrom skimage.color import rgb2gray\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport cv2\nfrom scipy import ndimage\n\n# Root directory of the project\nROOT_DIR = os.path.abspath(\"..\/\")\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","82390460":"root_path = '\/kaggle\/input\/imaterialist-fashion-2019-FGVC6\/'\n#reading train csv file\ntrain_df = pd.read_csv(os.path.join(root_path, 'train.csv'))\ntrain_df.shape","7a3de5d3":"train_df.head(5)","81a0266f":"train_df.info()","97ceaad1":"num_test_images = len(os.listdir(os.path.join(root_path,'test')))\nnum_train_images = len(os.listdir(os.path.join(root_path,'train')))\nprint(\"Number of images in test set: {}\".format(num_test_images))\nprint(\"Number of images in train set: {}\".format(num_train_images))","37dcfa4e":"avg_class_per_image = np.round(train_df.shape[0]\/num_train_images, 2)\nprint(\"Average number of classes per image: {}\".format(avg_class_per_image))\nassert len(train_df[\"ImageId\"].value_counts()) == num_train_images\nprint(\"Every image has at least 1 class\")","1bcaa38d":"#reading categories\nwith open(os.path.join(root_path, 'label_descriptions.json')) as f:\n    labels_data=json.load(f)\nlabels_data","e0cb950d":"#separating the categories and attributes\ncategories = pd.DataFrame(labels_data['categories'])\nattributes = pd.DataFrame(labels_data['attributes'])\nprint(\"There are descriptions for\", categories.shape[0],\"categories and\", attributes.shape[0], \"attributes\")","0469a308":"categories.head()","251f7635":"attributes.head()","6882f52b":"categories['supercategory'].unique()","4a35c23b":"attributes['supercategory'].unique()","c3a36280":"#separating categories and attributes in train data\ntrain_df['hasAttributes'] = train_df.ClassId.apply(lambda x: x.find(\"_\") > 0)\ntrain_df['CategoryId'] = train_df.ClassId.apply(lambda x: x.split(\"_\")[0]).astype(int)\ntrain_df = train_df.merge(categories, left_on=\"CategoryId\", right_on=\"id\")\ntrain_df.head()","a5e8d2d8":"fine_grained_obj_perc = np.round(train_df[\"hasAttributes\"].mean()*100, 1)\nprint(\"{}% of the objects are fine-grained.\".format(fine_grained_obj_perc))\nfine_grained_img_perc = np.round((train_df.groupby(\"ImageId\")[\"hasAttributes\"].sum() > 0).mean()*100, 1)\nprint(\"{}% of the images have at least one fine-grained object.\".format(fine_grained_img_perc))\nclass_df = train_df.groupby(\"CategoryId\").agg({\"ImageId\": \"count\"}).reset_index()\nclass_df = class_df.rename(columns={\"ImageId\": \"img_count\"})\nprint(\"Number of classes: {}\".format(class_df.shape[0]))\nprint(\"{} of the classes are fine-grained.\".format(train_df[train_df[\"hasAttributes\"] == True].CategoryId.nunique()))\nclass_df.head()","124638b7":"#eda\ndef plot_function_for_supercategories(subset,title):\n    supercategory_names = np.unique(subset.supercategory)\n    plt.figure(figsize=(10, 6))\n    g = sns.countplot(x = 'supercategory', data=subset, order=supercategory_names)\n    ax = g.axes\n    tl = [x.get_text() for x in ax.get_xticklabels()]    \n    ax.set_xticklabels(tl, rotation=45)\n    for p, label in zip(ax.patches, supercategory_names):\n        c = subset[(subset['supercategory'] == label)].shape[0]\n        ax.annotate(str(c), (p.get_x()+0.3, p.get_height() + 50))\n    plt.title(title)\n    plt.show()","493b77f2":"plot_function_for_supercategories(train_df[train_df.hasAttributes],'Supercategories with any attributes')","f46c8050":"plot_function_for_supercategories(train_df[~train_df.hasAttributes],'Supercategories with no attributes')","78672dc8":"super_cat = list(train_df['supercategory'].unique())\nfig, axes = plt.subplots(6, 2, figsize=(25, 20))\nz=0\nfor i in range(0, 6):\n    for j in range(0, 2):\n        sns.countplot(y=\"name\", data=train_df[train_df.supercategory.isin([super_cat[z]])],ax = axes[i, j]).set(title = (super_cat[z]))\n        fig.tight_layout()\n        z=z+1","fc174f9c":"# reading sample images from training data\nfor i in range(6):\n    id_image=train_df['ImageId'].iloc[np.random.randint(0,train_df.shape[0])]\n    print('Image ID:',id_image)\n    image = plt.imread(os.path.join(root_path,'train\/',id_image))\n    plt.imshow(image)\n    plt.show()","5bb1c2bb":"image = plt.imread(os.path.join(root_path,'train\/','b98f08f330c23af5db1c62c2412592b4.jpg'))\ngray = rgb2gray(image)\nplt.imshow(gray, cmap='gray')","dcf5f58c":"gray_r = gray.reshape(gray.shape[0]*gray.shape[1])\nan_array = np.where(gray_r > gray_r.mean(), 0, 3)\ngray = an_array.reshape(gray.shape[0],gray.shape[1])\nplt.imshow(gray, cmap='binary_r')","299d1bc3":"# execution_path = '..\/input\/imageai\/resnet50_coco_best_v2.0.1.h5'\n# detector = ObjectDetection()\n# detector.setModelTypeAsRetinaNet()\n# detector.setModelPath( os.path.join(execution_path , \"resnet50_coco_best_v2.0.1.h5\"))\n# detector.loadModel()\n# detections = detector.detectObjectsFromImage(input_image=os.path.join(root_path,'train\/','b98f08f330c23af5db1c62c2412592b4.jpg'), output_image_path=os.path.join(root_path,'b98f08f330c23af5db1c62c2412592b4_detection.jpg'))\n# pic = plt.imread(os.path.join(root_path,'b98f08f330c23af5db1c62c2412592b4_detection.jpg'))\n# plt.imshow(pic)","e1303b45":"# !git clone https:\/\/www.github.com\/matterport\/Mask_RCNN.git\n# os.chdir('Mask_RCNN')\n# !rm -rf .git # to prevent an error when the kernel is committed\n# !rm -rf images assets # to prevent displaying images at the bottom of a kernel\n\n# # Root directory of the project\n# ROOT_DIR = os.path.abspath(\"..\/\")\n\n# import warnings\n# warnings.filterwarnings(\"ignore\")\n\n# # Import Mask RCNN\n# sys.path.append(ROOT_DIR)  # To find local version of the library\n# from mrcnn import utils\n# import mrcnn.model as modellib\n# from mrcnn import visualize\n# # Import COCO config\n# sys.path.append(os.path.join(ROOT_DIR, \"samples\/coco\/\"))  # To find local version\n# import coco\n\n# # Directory to save logs and trained model\n# MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n\n# # Local path to trained weights file\n# COCO_MODEL_PATH = os.path.join('', \"mask_rcnn_coco.h5\")\n\n# # Download COCO trained weights from Releases if needed\n# if not os.path.exists(COCO_MODEL_PATH):\n#     utils.download_trained_weights(COCO_MODEL_PATH)\n\n# # Directory of images to run detection on\n# IMAGE_DIR = os.path.join(ROOT_DIR, \"trump.jpg\")\n\n\n","ce2a35db":"!pip install ProgressBar\n# import required packages\nfrom pathlib import Path\nfrom fastai.vision import *\nfrom fastai.callbacks.hooks import *\nfrom fastai.utils.mem import *\nfrom progressbar import ProgressBar\n","dab09ed2":"# create a folder for the mask images\nif  not os.path.isdir('..\/labels'):\n    os.makedirs('..\/labels')","169331e4":"train_df.columns","34957b0c":"# path = Path(\"..\/input\/imaterialist-fashion-2019-FGVC6\")\n# path_img = path+'\/train'\n# path_lbl = root_path+Path(\"..\/labels\")\n# only the 27 apparel items, plus 1 for background\n# model image size 224x224\ncategory_num = 27 + 1\nsize = 224\n# get and show categories\n# with open(os.path.join(root_path,\"label_descriptions.json\")) as f:\n#     label_descriptions = json.load(f)\n# label_names = [x['name'] for x in label_descriptions['categories']]\n# print(label_names)\n# train dataframe\ndf = train_df[['ImageId', 'EncodedPixels', 'Height', 'Width','ClassId']]","6bd89799":"# training image path and images\nfnames = get_image_files(os.path.join(root_path,'train'))\nprint(fnames[0])","0605fdd0":"# need a function to turn the run encoded pixels from train.csv into an image mask\n# there are multiple rows per image for different apparel items, this groups them into one mask\ndef make_mask_img(segment_df):\n    seg_width = segment_df.at[0, \"Width\"]\n    seg_height = segment_df.at[0, \"Height\"]\n    seg_img = np.full(seg_width*seg_height, category_num-1, dtype=np.int32)\n    for encoded_pixels, class_id in zip(segment_df[\"EncodedPixels\"].values, segment_df[\"ClassId\"].values):\n        pixel_list = list(map(int, encoded_pixels.split(\" \")))\n        for i in range(0, len(pixel_list), 2):\n            start_index = pixel_list[i] - 1\n            index_len = pixel_list[i+1] - 1\n            if int(class_id.split(\"_\")[0]) < category_num - 1:\n                seg_img[start_index:start_index+index_len] = int(class_id.split(\"_\")[0])\n    seg_img = seg_img.reshape((seg_height, seg_width), order='F')\n    return seg_img","0a5c4a80":"# we can look at an image to see how the processing works\n# the original image\nimg_file = fnames[500]\nimg = open_image(img_file)\nimg.show(figsize=(5,5))","3ae0cb40":"# convert rows for this image into a numpy array mask\nimg_name = os.path.basename(img_file)\nimg_df = df[df.ImageId == img_name].reset_index()\n#img_df = img_df.iloc[0:1]\n#img_df = img_df[img_df.ClassId.astype(int) < category_num - 1].reset_index()\nimg_mask = make_mask_img(img_df)\nplt.imshow(img_mask)","ac708e24":"# convert the numpy array into a three channel png that can be used in the standard SegmentationItemList\n# then write into the labels folder as png and show the image\n# all pixels have the category numbers, so it looks like a dark greyscale image\nimg_mask_3_chn = np.dstack((img_mask, img_mask, img_mask))\ncv2.imwrite('..\/labels\/' + os.path.splitext(img_name)[0] + '_P.png', img_mask_3_chn)\npng = open_image('..\/labels\/' + os.path.splitext(img_name)[0] + '_P.png')\npng.show(figsize=(5,5))","504681c4":"# use fastai's open_mask for an easier-to-view image (and check it works...)\nmask = open_mask('..\/labels\/' + os.path.splitext(img_name)[0] + '_P.png')\nmask.show(figsize=(5,5), alpha=1)\nprint(mask.data)","63a9c6ca":"# run the same procedure for a sample of first 5000 images in dataset\nimages = df.ImageId.unique()[:5000]","fa6fd7ab":"pbar = ProgressBar()\nfor img in pbar(images):\n    img_df = df[df.ImageId == img].reset_index()\n    img_mask = make_mask_img(img_df)\n    img_mask_3_chn = np.dstack((img_mask, img_mask, img_mask))\n    cv2.imwrite('..\/labels\/' + os.path.splitext(img)[0] + '_P.png', img_mask_3_chn)","c9784956":"# before creating the databunch we need a function to find the mask images\n# also set the batch size, categories and wd\nget_y_fn = lambda x: Path(\"..\/labels\")\/f'{Path(x).stem}_P.png'\nbs = 32\n#classes = label_names\ncodes = list(range(category_num))\nwd = 1e-2","d701aa67":"# create the databunch\nimages_df = pd.DataFrame(images)\nsrc = (SegmentationItemList.from_df(images_df, os.path.join(root_path,'train'))\n       .split_by_rand_pct()\n       .label_from_func(get_y_fn, classes=codes))\n\ndata = (src.transform(get_transforms(), size=size, tfm_y=True)\n       .databunch(bs=bs)\n       .normalize(imagenet_stats))","1969ce45":"# look at a batch\ndata.show_batch(3, figsize=(10,10))","2e329b9d":"# I create an accuracy metric which excludes the background pixels\ndef acc_fashion(input, target):\n    target = target.squeeze(1)\n    mask = target != category_num - 1\n    return (input.argmax(dim=1)==target).float().mean()","cb9525f9":"# learner, include where to save pre-trained weights (default is in non-write directory)\nlearn = unet_learner(data, models.resnet34, metrics=acc_fashion, wd=wd, model_dir=\"\/kaggle\/working\/models\")","427d228d":"# run learning rate finder\nlr_find(learn)\nlearn.recorder.plot()","9581bd1a":"# set learning rate based on roughly the steepest part of the curve\nlr=1e-3","840a5d52":"# train for 10 cycles frozen\nlearn.fit_one_cycle(10, slice(lr), pct_start=0.9)","1b0ff99b":"# take a look at some results\nlearn.show_results()","9d26c9ea":"# unfreeze earlier weights\nlearn.unfreeze()","8bcbde87":"# decrease the learning rate\nlrs = slice(lr\/400,lr\/4)","9f880e5e":"# train for 10 more cycles unfrozen\nlearn.fit_one_cycle(10, lrs, pct_start=0.8)","8a2a2ac8":"# more results\nlearn.show_results()","20d2d10e":"test_path = '..\/input\/imaterialist-fashion-2019-FGVC6\/test\/0046f98599f05fd7233973e430d6d04d.jpg'\nimg = open_image(test_path)\nx = learn.predict(img)\nimg.show()","2a57e744":"fig, axes = plt.subplots(9, 3, figsize=(25, 20))\nz=0\nfor i in range(9):\n    for j in range(3):\n        axes[i,j].imshow(x[2][z])\n#         plt.imshow(x[2][z])\n        z=z+1","ffe378c7":"print(learn.data.classes)","1640d77b":"categories","5d9098f3":"test_path = '..\/input\/imaterialist-fashion-2019-FGVC6\/test\/0146a53e12d690914995248fb6872121.jpg'\nimg = open_image(test_path)\nx = learn.predict(img)\nimg.show()","eb1f8442":"fig, axes = plt.subplots(9, 3, figsize=(25, 20))\nz=0\nfor i in range(9):\n    for j in range(3):\n        axes[i,j].imshow(x[2][z])\n#         plt.imshow(x[2][z])\n        z=z+1","0b66dc21":"plt.imshow(x[2][27])","dc6ca069":"test_path = '..\/input\/personal-testing\/1.jpeg'\nimg = open_image(test_path)\nx = learn.predict(img)\nimg.show()","aa40124b":"fig, axes = plt.subplots(9, 3, figsize=(25, 20))\nz=0\nfor i in range(9):\n    for j in range(3):\n        axes[i,j].imshow(x[2][z])\n#         plt.imshow(x[2][z])\n        z=z+1","3a3872b3":"test_path = '..\/input\/personal-group-1\/_G2A0656.JPG'\nimg = open_image(test_path)\nx = learn.predict(img)\nimg.show()","d0680023":"fig, axes = plt.subplots(9, 3, figsize=(25, 20))\nz=0\nfor i in range(9):\n    for j in range(3):\n        axes[i,j].imshow(x[2][z])\n#         plt.imshow(x[2][z])\n        z=z+1","45e86d66":"test_path = '..\/input\/personal-2\/MicrosoftTeams-image (6).png'\nimg = open_image(test_path)\nx = learn.predict(img)\nimg.show()\n","312b3c7a":"fig, axes = plt.subplots(9, 3, figsize=(25, 20))\nz=0\nfor i in range(9):\n    for j in range(3):\n        axes[i,j].imshow(x[2][z])\n#         plt.imshow(x[2][z])\n        z=z+1","125084c6":"test_path = '..\/input\/personal-2\/MicrosoftTeams-image (7).png'\nimg = open_image(test_path)\nx = learn.predict(img)\nimg.show()\n","b275315d":"fig, axes = plt.subplots(9, 3, figsize=(25, 20))\nz=0\nfor i in range(9):\n    for j in range(3):\n        axes[i,j].imshow(x[2][z])\n#         plt.imshow(x[2][z])\n        z=z+1","69c0277f":"plt.imshow(x[2][27])","c52420cd":"gnames = get_image_files('..\/input\/personal-girl-power')\n","2b12c49b":"gnames","1162463b":"test_path = gnames[0]\nimg = open_image(test_path)\nx = learn.predict(img)\nimg.show()\n","088b1c5a":"fig, axes = plt.subplots(9, 3, figsize=(25, 20))\nz=0\nfor i in range(9):\n    for j in range(3):\n        axes[i,j].imshow(x[2][z])\n#         plt.imshow(x[2][z])\n        z=z+1","b1fa5441":"test_path = gnames[1]\nimg = open_image(test_path)\nx = learn.predict(img)\nimg.show()\n","939037fc":"fig, axes = plt.subplots(9, 3, figsize=(25, 20))\nz=0\nfor i in range(9):\n    for j in range(3):\n        axes[i,j].imshow(x[2][z])\n#         plt.imshow(x[2][z])\n        z=z+1","824e3765":"test_path = gnames[2]\nimg = open_image(test_path)\nx = learn.predict(img)\nimg.show()\n","d7ca1f5c":"fig, axes = plt.subplots(9, 3, figsize=(25, 20))\nz=0\nfor i in range(9):\n    for j in range(3):\n        axes[i,j].imshow(x[2][z])\n#         plt.imshow(x[2][z])\n        z=z+1","573147a5":"test_path = gnames[3]\nimg = open_image(test_path)\nx = learn.predict(img)\nimg.show()\n","870e23b4":"fig, axes = plt.subplots(9, 3, figsize=(25, 20))\nz=0\nfor i in range(9):\n    for j in range(3):\n        axes[i,j].imshow(x[2][z])\n#         plt.imshow(x[2][z])\n        z=z+1","cfe77759":"test_path = gnames[4]\nimg = open_image(test_path)\nx = learn.predict(img)\nimg.show()\n","7668ca01":"fig, axes = plt.subplots(9, 3, figsize=(25, 20))\nz=0\nfor i in range(9):\n    for j in range(3):\n        axes[i,j].imshow(x[2][z])\n#         plt.imshow(x[2][z])\n        z=z+1","b4a9b64d":"test_path = gnames[5]\nimg = open_image(test_path)\nx = learn.predict(img)\nimg.show()\n","f2e30e22":"fig, axes = plt.subplots(9, 3, figsize=(25, 20))\nz=0\nfor i in range(9):\n    for j in range(3):\n        axes[i,j].imshow(x[2][z])\n#         plt.imshow(x[2][z])\n        z=z+1","cb0ec2a4":"no null values","e7a1330b":"## understanding and reading few images from train data"}}