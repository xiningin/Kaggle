{"cell_type":{"ae95b0ef":"code","29f1c0b3":"code","c1ce6ba0":"code","57a2aa01":"code","18851bf4":"code","c32bc742":"code","415e5c6f":"code","326c0688":"code","d7d52293":"code","4688135b":"code","43cdfce5":"code","227e7dcf":"markdown","6bdfd708":"markdown","640063ed":"markdown","0318b8eb":"markdown","5f195f50":"markdown","f0844f87":"markdown","4e40939e":"markdown","e0a338d1":"markdown","d840a0ec":"markdown","02ff9d17":"markdown"},"source":{"ae95b0ef":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport random as rnd\nfrom random import randint\n\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","29f1c0b3":"dss = pd.read_csv(\"..\/input\/derm.csv\")\ndss.describe()","c1ce6ba0":"dss.drop(['age'], axis=1, inplace=True)","57a2aa01":"last_col = dss.columns[len(dss.columns)-1]\nclasses = list(dss[last_col].unique())\nlen_cols = len(dss.columns) - 1","18851bf4":"# One Hot Codification\n# Coding using zeros' array and 1 to each class\ndef one_hot_encoding(classes):\n    cl_onehot = np.zeros((len(classes),len(classes)),dtype=int)\n    np.fill_diagonal(cl_onehot,1)\n    r = [(classes[i], cl) for i, cl in enumerate(cl_onehot)]\n    return r\n\n# Encode the expected classes\ndef encode_expected(expected, encoded_class):\n    return np.array([ list(filter(lambda e: e[0] == x, encoded_class))[0][1] for x in expected ])\n\n# Encode all the dataset classes\ndef encode_class(ds):\n    return one_hot_encoding(pd.unique(ds.iloc[:,-1:].values.flatten()))\n\n# Decode the result\ndef decode_result(encoded_class, value):\n    if sum(value) != 1:\n        value = list(encoded_class[randint(0,len(encoded_class)-1)][1])\n    return list(filter(lambda x: list(x[1]) == value,encoded_class))[0][0]","c32bc742":"# Class to represent the hidden layer\nclass NeuronLayer():\n    def __init__(self, number_of_neurons, number_of_inputs_per_neuron):\n        self.synaptic_weights = 2 * np.random.random((number_of_inputs_per_neuron, number_of_neurons)) - 1","415e5c6f":"# Classe to represent the neural network (by default, it was made with two layers)\n\nclass NeuralNetwork():\n    \n    # Construct method\n    def __init__(self, layer1, layer2):\n        self.layer1 = layer1\n        self.layer2 = layer2\n        \n    # Sigmoid function\n    def __sigmoid(self, x):\n        return 1 \/ (1 + np.exp(-x))\n\n    # sigmoid's derivative\n    def __sigmoid_derivative(self, x):\n        return x * (1 - x)\n    \n    # Add bias\n    def __add_bias(self, inputs_training):\n        return np.array([ np.append(i,-1) for i in inputs_training])\n    \n    # Train network - Used: Delta Rule\n    def train(self, inputs_training, outputs_training, num_interation, rate):\n        \n        inputs_training = self.__add_bias(inputs_training)\n        \n        for interate in range(0,num_interation):\n            # Calcule the result of neuron\n            output_layer1, output_layer2 = self.__think(inputs_training)\n            \n            # Calcule the layer 2 error\n            layer2_error = outputs_training - output_layer2\n            layer2_delta = layer2_error * self.__sigmoid_derivative(output_layer2)\n            \n            # Calcule layer 1 error\n            layer1_error = layer2_delta.dot(self.layer2.synaptic_weights.T)\n            layer1_delta = layer1_error * self.__sigmoid_derivative(output_layer1)\n            \n            # How much adjustment it will take in synaptic weights\n            layer1_adjustment = inputs_training.T.dot(layer1_delta) * rate\n            layer2_adjustment = output_layer1.T.dot(layer2_delta) * rate\n            \n            #Adjust synaptic weights\n            self.layer1.synaptic_weights += layer1_adjustment\n            self.layer2.synaptic_weights += layer2_adjustment\n            \n    # Return the output of neuron layer\n    def __think(self, input_training):\n        output_layer1 = self.__sigmoid(np.dot(input_training, self.layer1.synaptic_weights))\n        output_layer2 = self.__sigmoid(np.dot(output_layer1, self.layer2.synaptic_weights))\n        \n        return output_layer1, output_layer2\n    \n    # Predict passing the datas\n    def predict(self, input_):\n        input_ = input_ + [-1] \n        h, out = self.__think(input_)\n        result = [1 if o >= 0.5 else 0 for o in out]\n        return result\n        \n    # Print weights\n    def print_weights(self):\n        \n        print('Layer 1:')\n        print(self.layer1.synaptic_weights)\n        print('Layer 2:')\n        print(self.layer2.synaptic_weights)","326c0688":"def train(dataset_train, dataset_test):\n    count_correct = 0\n    count_incorrect = 0\n    \n    count_by_classes_correct = [0 for i in range(0,len(classes))]\n    count_by_classes_incorrect = [0 for i in range(0,len(classes))]\n    \n    # Encode the classes of dataset\n    encoded_class = encode_class(dataset_train)\n    \n    # Neural network with 2 layers, One with 16 neurons and other with 6 neurons.\n    \n    # Layer 1: Make 16 neurons com 33 inputs (quantity of input from dataset)\n    l1 = NeuronLayer(32,len_cols + 1)\n    # Layer 2: Make 12 nerons with 16 input from the other neuron layers (output layer)\n    l2 = NeuronLayer(len(classes), 32)\n    \n    neural_network = NeuralNetwork(l1, l2)\n    \n    inputs = dataset_train.iloc[:,:-1].values\n    outputs = dataset_train.iloc[:,-1:].values\n    \n    outputs_encoded = encode_expected(outputs,encoded_class)\n    \n    neural_network.train(inputs, outputs_encoded, 10000, 0.01)\n    \n    for index, row in dataset_test.iterrows():\n        \n        tuple_t = list(row)\n        tuple_t.pop()\n        \n        r = neural_network.predict(tuple_t) # Performs the result by the value of the network\n        \n        result = decode_result(encoded_class, r)\n        \n        #Result\n        if result == row[last_col]:\n            count_correct += 1\n            count_by_classes_correct[classes.index(result)] += 1\n        else:\n            count_incorrect += 1\n            count_by_classes_incorrect[classes.index(result)] += 1\n        \n    return count_correct, count_incorrect, count_by_classes_correct, count_by_classes_incorrect","d7d52293":"def seperate_ds_by_class(dataset, percentage):\n    rds_train = pd.DataFrame()\n    rds_test = pd.DataFrame()\n    \n    for c in classes:\n        nds = dataset[dataset[last_col]==c]\n        \n        ds_train = nds.sample(frac=percentage, random_state=randint(0,15100))\n        ds_test = nds.drop(ds_train.index) \n        \n        rds_train = rds_train.append(ds_train)\n        rds_test = rds_test.append(ds_test)\n        \n    rds_train = rds_train.reset_index()\n    rds_test = rds_test.reset_index() \n\n    rds_train.drop('index',1,inplace=True) \n    rds_test.drop('index',1,inplace=True) \n    \n    return (rds_train, rds_test)","4688135b":"def run_nth(ds,percentage, number):\n    percentages_correct = list()\n    prob_correct_by_class = []\n    \n    for i in range(0,number):\n        ds_train, ds_test = seperate_ds_by_class(ds,percentage)\n        correct, incorrect, count_by_classes_correct, count_by_classes_incorrect = train(ds_train, ds_test)\n\n        by_class = []\n        for count_correct, count_incorrect in zip(count_by_classes_correct, count_by_classes_incorrect):\n            if count_correct+count_incorrect != 0:\n                by_class.append(count_correct\/(count_correct+count_incorrect))\n            else:\n                by_class.append(0)\n                \n        prob_correct_by_class.append(by_class)\n        percentages_correct.append(correct\/(correct+incorrect))\n        \n    return (percentages_correct, prob_correct_by_class)","43cdfce5":"percents, prob_by_class = run_nth(dss,0.8,1)\n\ntaxa_acerto_min=np.min(percents)\ntaxa_acerto_max=np.max(percents)\ntaxa_acerto_med=np.mean(percents)\n\nprint('Rate')\nprint('--------------')\nprint('Min: ' + str(taxa_acerto_min))\nprint('Max: ' + str(taxa_acerto_max))\nprint('Mean: '+str(taxa_acerto_med))\n\nprint('-------------------------------')\nprint('Mean rate by class')\nprint('-------------------------------')\n\nar_value = [ np.mean(m) for m in np.array(prob_by_class).transpose() ]\n\nfor i, _class in enumerate(ar_value):\n    print('Class \\'' +  str(classes[i]) +'\\' : ' + str(_class))","227e7dcf":"### Separate dataset by class\nThis function return the dataset separate by classes<br>\nIt's similar function **sklearn.model_selection.train_test_split**","6bdfd708":"### Basic variable","640063ed":"### Implementation of One Hot Encoder\/Decoder","0318b8eb":"### Import dataset and get the information","5f195f50":"### Create a main class to neural network","f0844f87":"### Execute","4e40939e":"### Prepare the dataset\nI should remove the \"age\" column because the column, there is empty data on some line.","e0a338d1":"## Implementation of Multilayer Perceptron\nImplementation without to use library, i just used basic libraries.\n\n**Dataset**: Dermatology\n\n**PS:** Neural Network with 2 layers.","d840a0ec":"### Create Layer Class","02ff9d17":"### Train and count results of training"}}