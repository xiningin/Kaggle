{"cell_type":{"c1024c7d":"code","bab2a073":"code","7aaa610c":"code","9622b670":"code","cd0e7508":"code","f715672b":"code","7ee5a580":"code","3f5978df":"code","c127af88":"code","45ef3943":"code","4d2153f6":"code","c48d9ca6":"code","9a99c6fb":"code","b472c74f":"code","93b23cdf":"code","4e0042c1":"code","8440addd":"markdown","c0ebd326":"markdown","38914642":"markdown","eed75b4e":"markdown","5799e2b6":"markdown","f88ddd79":"markdown","097a191e":"markdown","8daffafe":"markdown","e56eb602":"markdown","10fd18dc":"markdown"},"source":{"c1024c7d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bab2a073":"data = pd.read_csv('..\/input\/divorce-prediction\/divorce_data.csv', sep=';')","7aaa610c":"X = data.drop('Divorce', axis=1)\ny = data.loc[:, 'Divorce']","9622b670":"data.info()","cd0e7508":"data.describe().T","f715672b":"hist = data.hist(figsize=(40, 30))","7ee5a580":"data.corr()['Divorce'].drop('Divorce').sort_values(ascending=False)","3f5978df":"from sklearn.model_selection import train_test_split\nXtrain, Xvalid, ytrain, yvalid = train_test_split(X, y, test_size=.3, random_state=777)","c127af88":"from xgboost import XGBClassifier\nmodel = XGBClassifier(n_estimators=2500)\nmodel.fit(Xtrain, ytrain.values.flatten())\nypred = model.predict(Xvalid)","45ef3943":"from sklearn.metrics import accuracy_score, confusion_matrix\naccuracy_score(yvalid, ypred), confusion_matrix(yvalid, ypred)","4d2153f6":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(1, 3))\ncolumns = X.columns\nX = pd.DataFrame(scaler.fit_transform(X), columns=columns)","c48d9ca6":"info = data.corr()['Divorce'].drop('Divorce').sort_values(ascending=False)\nupper_columns = list(info[:5].index)\n\ncolumns = list(X.columns)\nfrom sklearn.preprocessing import MinMaxScaler\nX = pd.DataFrame(MinMaxScaler(feature_range=(1, 3)).fit_transform(X), columns=columns)\n\nnew_arrays = np.zeros([X.shape[0], 1])\nfor i in upper_columns:\n    new_arrays = np.concatenate([new_arrays, (X[i] ** 2).values.reshape(-1, 1)], axis=1)\nfor i in upper_columns:\n    for j in upper_columns:\n        if i != j:\n            new_arrays = np.concatenate([new_arrays, (X[i] * X[j]).values.reshape(-1, 1)], axis=1)\n\nnew_arrays = new_arrays[:, 1:]\nX = pd.concat([pd.DataFrame(X), pd.DataFrame(new_arrays)], axis=1)","9a99c6fb":"components = round(X.shape[1] \/ 4)\nfrom sklearn.decomposition import KernelPCA\nkpca = KernelPCA(kernel='rbf', n_components=components)\nkpca.fit(X)\nX = kpca.transform(X)","b472c74f":"Xtrain, Xvalid, ytrain, yvalid = train_test_split(X, y, test_size=.3, random_state=777)\n\nmodel = XGBClassifier(n_estimators=2500)\nmodel.fit(Xtrain, ytrain.values.flatten())\nypred = model.predict(Xvalid)\n\naccuracy_score(yvalid, ypred), confusion_matrix(yvalid, ypred)","93b23cdf":"from sklearn.model_selection import cross_val_score\nkfold_results = cross_val_score(estimator=XGBClassifier(n_estimators=2500), X=X, y=y, scoring='accuracy', cv=5, n_jobs=-1)","4e0042c1":"kfold_results.mean()","8440addd":"and let's reduct the dimension to avoid overfit by using KernelPCA","c0ebd326":"there no need to cut any value because none of them seem higher or lower than others","38914642":"---","eed75b4e":"there is no column that affects our target column too low, they all feed our target goodly (the lowest term is 0.42 which means exactly perfect)","5799e2b6":"---","f88ddd79":"let's add some new features","097a191e":"let's create our train and see whether we can earn a good score without any kind of preprocess","8daffafe":"there no need to encode since there is no columns based on object type && also no need to filling nan values since all the columns non-null","e56eb602":"there is no need to scale any of columns since they all between 0 and 4, and also has standard deviation smaller than 2","10fd18dc":"now we've earnt a good value of accuracy. now let's test it in kfolds"}}