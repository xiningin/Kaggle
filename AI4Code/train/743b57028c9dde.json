{"cell_type":{"897f0fd4":"code","cd10cf65":"code","8d831199":"code","b82c514d":"code","7545bedf":"code","436c054c":"code","82813a07":"code","697812e5":"code","7f928bad":"code","560912b6":"code","e1a0f0a7":"code","a156a373":"code","81b0d9ba":"code","caac11e5":"code","e00f4728":"markdown","afffc0b0":"markdown","934856aa":"markdown","73732ad1":"markdown","7c1e729a":"markdown","c434ddbf":"markdown","273f21de":"markdown","77662fac":"markdown","5d776d12":"markdown","3dbbe135":"markdown"},"source":{"897f0fd4":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n\npd.options.display.float_format = '{:20,.2f}'.format\n\n\n!jupyter nbextension enable --py --sys-prefix widgetsnbextension\nimport os\nfrom ipywidgets import interact\nfrom ipywidgets import interact\nimport ipywidgets as widgets\nimport pandas as pd\nfrom IPython.display import display\nfrom subprocess import check_output\nfrom wordcloud import WordCloud, STOPWORDS\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n%matplotlib inline\ndef world_cloud(wc,species='species'):\n    mpl.rcParams['figure.figsize']=(12.0,18.0)    #(6.0,4.0)\n    mpl.rcParams['font.size']=16                #10 \n    mpl.rcParams['savefig.dpi']=100            #72 \n    mpl.rcParams['figure.subplot.bottom']=.1 \n\n\n    stopwords = set(STOPWORDS)\n\n\n    wordcloud = WordCloud(\n                              background_color='red',\n\n                              max_words=100,\n                              max_font_size=50, \n                              random_state=0\n                             ).generate(str(wc))\n\n    print(wordcloud)\n    fig = plt.figure(1)\n    plt.imshow(wordcloud)\n    plt.title(species)\n    plt.axis('off')\n    plt.show()\n    ","cd10cf65":"os.listdir('\/kaggle\/input\/')","8d831199":"def extract_response(response):\n    all_wrds=[]\n    try:\n        for annotation in response[\"annotations\"]:\n            if annotation[\"cosine\"]>0.1:\n                #print(\"%s (%s) %s\" % (annotation[\"title\"], annotation[\"url\"], annotation[\"dbPediaTypes\"]))\n                all_wrds.append((annotation[\"title\"],annotation[\"dbPediaTypes\"]))\n    except:\n        1==1\n    return all_wrds  \n\ndef function_join_title(response):\n    title=''\n    for k in range(len(response['words'])):\n        title=title+response[\"spaces\"][k]+response[\"words\"][k]\n    return title","b82c514d":"read_data=pd.read_pickle('\/kaggle\/input\/wiki-covid-map\/abstract_res_all.pkl')","7545bedf":"read_data_All=pd.read_pickle('\/kaggle\/input\/covid-all-wiki-columns-data\/ALL_study_with_wiki_columns.pkl')\nread_data_All['unique_id']=range(len(read_data))\nread_data_All_p=read_data_All[['unique_id','all_txt_resp']]\n\nread_data_All_p['words_wiki']=read_data_All_p['all_txt_resp'].apply(lambda x: extract_response(x))\nlst_col='words_wiki'\nread_data_All_p=read_data_All_p.explode(lst_col)","436c054c":"read_data_All_p=pd.concat([read_data_All_p,pd.DataFrame(read_data_All_p[lst_col].tolist(), index=read_data_All_p.index , columns=['keywords','wikitype']  )],axis=1)\nread_data_All_p=read_data_All_p.explode('wikitype')\nread_data_All_p=read_data_All_p.drop(['all_txt_resp','words_wiki'],axis=1)\nmetadata_limit1=pd.DataFrame()\nmetadata_limit1['wiki_article_resp']=np.array(read_data)\nmetadata_limit1['words']=metadata_limit1['wiki_article_resp'].apply(lambda x: extract_response(x))\nmetadata_limit1['title']=metadata_limit1['wiki_article_resp'].apply(lambda x : function_join_title(x))\nmetadata_limit=read_data_All.merge(metadata_limit1,on='title',how='inner')\nlst_col='words'\ndf=metadata_limit\n\ndf=df.explode(lst_col)\ndf=pd.concat([df,pd.DataFrame(df[lst_col].tolist(), index=df.index , columns=['keywords','wikitype']  )],axis=1)\ndf.groupby('keywords').count()['words'].reset_index().sort_values('words',ascending=False)\ndf=df.explode('wikitype')\n\ntop_wikitype=(df.groupby(['wikitype'])['unique_id'].nunique().reset_index().sort_values('unique_id',ascending=False))\n#df.groupby(['wikitype',])['keywords'].nunique().reset_index().sort_values('keywords',ascending=False)[:20]","82813a07":"top_keywrd=df.groupby('keywords')['unique_id'].nunique().reset_index().sort_values('unique_id',ascending=False)\n\n\nimport plotly.express as px\ntop_wikitype_1 = top_wikitype[:100].copy()\ntop_wikitype_1.columns=['Cat_type','# docs']\nfig = px.bar(top_wikitype_1, x='Cat_type', y='# docs')\nfig.show()\n\ntop_keywrd_1 = top_keywrd[:100].copy()\ntop_keywrd_1.columns=['keywords','# docs']\nfig = px.bar(top_keywrd_1, x='keywords', y='# docs')\n\nfig.show()\n\n","697812e5":"\ntop_wikitype_all=(read_data_All_p.groupby(['wikitype'])['unique_id'].nunique().reset_index().sort_values('unique_id',ascending=False))\ntop_keywrd_all=read_data_All_p.groupby('keywords')['unique_id'].nunique().reset_index().sort_values('unique_id',ascending=False)\n\n\nimport plotly.express as px\ntop_wikitype_all_1 = top_wikitype_all[:100].copy()\ntop_wikitype_all_1.columns=['Cat_type','# docs']\nfig = px.bar(top_wikitype_1, x='Cat_type', y='# docs')\nfig.show()\n\ntop_keywrd_all_1 = top_keywrd_all[:100].copy()\ntop_keywrd_all_1.columns=['keywords','# docs']\nfig = px.bar(top_keywrd_1, x='keywords', y='# docs')\n\nfig.show()\n\n","7f928bad":"def show_task(keywords='ALL',Cat_type='ALL',license='ALL'):\n    df1=df\n    if keywords!='ALL' :\n        df1=df1[(df1.keywords == keywords) ]\n    if Cat_type!='ALL' :\n        df1=df1[(df1.wikitype == Cat_type) ]\n    if license!='ALL' :\n        df1=df1[(df1.license == license) ]\n    search_results= df1[['all_txt','source_x','license']].drop_duplicates().head(10)\n\n    return search_results\nlt=top_wikitype[['wikitype']].wikitype.to_list()\nlt.sort() \njn=df[['license']].fillna('NA').drop_duplicates().license.tolist()\njn.sort()\nkw=['ALL']+top_keywrd[['keywords']].keywords.to_list()[:80]\nkw.sort()\ndisplay(interact(show_task, keywords = ['ALL']+kw,\\\n         Cat_type = ['ALL']+lt,\\\n        license=['ALL']+jn))","560912b6":"import pprint\nfor k in top_wikitype[['wikitype']].wikitype.to_list()[:5]:\n    pprint.pprint(\" Top Match for category in title \" + str(k),depth=4, width=60) \n    pprint.pprint(show_task(Cat_type=k))\n    pprint.pprint('-'*20+'end'+'-'*20)\n    print('\\n')","e1a0f0a7":"import pprint\nfor k in top_keywrd[['keywords']].keywords.to_list()[:5]:\n    pprint.pprint(\" Top Match for category in title \" + str(k),depth=4, width=60) \n    pprint.pprint(show_task(keywords=k))\n    pprint.pprint('-'*20+'end'+'-'*20)\n    print('\\n')","a156a373":"df1=df[['wikitype','keywords','unique_id']].drop_duplicates().fillna('')\ndef show_wrd_cld(n_type):\n    for k in top_wikitype.wikitype.values[:n_type]:\n    #for k in ['Protein']:    \n        wc=df1[df1['wikitype']==k]\n        wc=wc['keywords']\n        wc=\" \".join(wc)\n        world_cloud(wc,species=k)\ninteract(show_wrd_cld,n_type=range(3,30,1))","81b0d9ba":"df1=df[['wikitype','keywords','unique_id']].drop_duplicates().fillna('')\ndef show_wrd_cld_cat(Cat_type):\n    if Cat_type=='ALL':\n        wc1=df1\n    else:    \n        wc1=df1[df1['wikitype']==Cat_type]\n    wc1=wc1['keywords']\n    wc1=\" \".join(wc1)\n    world_cloud(wc1,species=Cat_type)\nlt=top_wikitype[['wikitype']].wikitype.to_list()\nlt.sort()\ninteract(show_wrd_cld_cat,Cat_type = ['ALL']+lt)","caac11e5":"df.to_pickle('all_title_pickle.pkl')\nread_data_All_p.to_pickle('all_title_abs_text_pickle.pkl')","e00f4728":"# Printing results for top 5 keywords in title ","afffc0b0":"# Printing results for top 5 category in title ","934856aa":"# Reading data for all text ","73732ad1":"# Top Category mentioned in title of articles ","7c1e729a":"# Interact to see word cloud for specific category. \nNot able to make it work in publish area","c434ddbf":"# Keywords in top category articles \n# Interact to see word cloud for specific numbers. \nNot able to make it work in publish area","273f21de":"# Extracting keywords and category from wikifier \n## http:\/\/www.wikifier.org\/\n\nI have extracted major topics and keywords from the wikifier to have specific match \n\n[old version to extract title](https:\/\/www.kaggle.com\/yatinece\/wiki-data?scriptVersionId=30676608) ( I will need to run this in other notebook)\n[Version to extract all data ](https:\/\/www.kaggle.com\/yatinece\/wiki-data)\n\n### Data sources are attached in the notebook.\n\nMost of the cells are hidden. Please fork the notebook to develop ","77662fac":"# Top mention category and keywords in articles complete","5d776d12":"# Reading data for title only extract","3dbbe135":"# Search for article from various publications "}}