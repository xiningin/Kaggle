{"cell_type":{"f4ebb1c9":"code","2cda98be":"code","fa78502b":"code","ebbdacb0":"code","27afbea6":"code","097acd34":"code","626b3ce3":"code","b4305421":"code","0b331e72":"code","e6f0203c":"code","0ef6ea1c":"code","5de35135":"code","d8a0e664":"code","5d3c0a5e":"code","9666497d":"code","175e4afd":"code","a745c456":"code","261a15ad":"code","6b39d0cb":"code","8b8b20dc":"code","f4407506":"code","54f4a92d":"code","2abdfab4":"code","bb87af4b":"code","92500e2d":"code","bfe52383":"code","e285f34a":"code","d2ea9efc":"code","3deb1b5b":"code","4261c093":"code","4233d1ca":"code","a635d6ba":"code","69fd32b3":"code","99df7349":"code","07693f4c":"code","964732b6":"code","8201a0a4":"code","57fd79c8":"code","acca8129":"code","1a8c3c4b":"markdown","4cd5b377":"markdown"},"source":{"f4ebb1c9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2cda98be":"train_file = '..\/input\/titanic\/train.csv'\ntrain_data = pd.read_csv(train_file)\ntest_file = '..\/input\/titanic\/test.csv'\ntest_data = pd.read_csv(test_file)","fa78502b":"train_data.head()","ebbdacb0":"test_data.head()","27afbea6":"train_data.info()","097acd34":"test_data.info()","626b3ce3":"#number of missing values in columns\ntrain_data.isna().sum()","b4305421":"test_data.isna().sum()","0b331e72":"combined = pd.concat([train_data, test_data], sort=False)\ncombined.info()","e6f0203c":"combined.Name","0ef6ea1c":"combined.drop(columns=['Ticket', 'Name'], inplace=True)\ncombined.head()","5de35135":"#embarked\nimport seaborn as sns\nprint('EMBARKED')\nprint(f'Unique enteries: {combined.Embarked.unique()}')\nprint(f'Null count: {combined.Embarked.isnull().sum():.0f}')\nsns.catplot(x='Embarked', kind='count', data = combined)","d8a0e664":"#Fill missing values\ncombined['Embarked'].fillna(value='S',inplace =True)\nmode_age = combined.Age.mode()[0]\ncombined.Age.fillna(mode_age, inplace=True)\n# combined.Fare.fillna(inplace=True)","5d3c0a5e":"sns.barplot(x='Survived', y='Fare', data=combined)","9666497d":"sns.countplot(x='Pclass', hue='Survived', data=combined)","175e4afd":"avg_fare_survived = combined.loc[combined.Survived==1].Fare.mean()\navg_fare_died = combined.loc[combined.Survived==0].Fare.mean()\nprint(f'Average fare of those who died: {avg_fare_died:0.2f}\\nAverage fare of those who survived: {avg_fare_survived:0.2f}')","a745c456":"pc_1_s = combined.loc[(combined.Survived==1) & (combined.Pclass==1)].shape[0]\npc_2_s = combined.loc[(combined.Survived==1) & (combined.Pclass==2)].shape[0]\npc_3_s = combined.loc[(combined.Survived==1) & (combined.Pclass==3)].shape[0]\n\npc_1_d = combined.loc[(combined.Survived==0) & (combined.Pclass==1)].shape[0]\npc_2_d = combined.loc[(combined.Survived==0) & (combined.Pclass==2)].shape[0]\npc_3_d = combined.loc[(combined.Survived==0) & (combined.Pclass==3)].shape[0]\n\npClassAnalysis = pd.DataFrame({'Pclass': [1,2,3], 'Survived':[pc_1_s, pc_2_s, pc_3_s], 'Died':[pc_1_d,pc_2_d,pc_3_d]})\n# pClassAnalysis.set_index('Pclass', inplace=True)\npClassAnalysis","261a15ad":"pclass_3_mean_fare = combined[combined.Pclass==3].Fare.mean()\ncombined.Fare.fillna(pclass_3_mean_fare, inplace=True)","6b39d0cb":"combined.Age.value_counts()","8b8b20dc":"#FARE\ndef normalizeFare(fare):\n    m = combined.Fare.mean()\n    s = combined.Fare.std()\n    return (fare-m)\/s\n\ncombined.Fare = combined.Fare.map(lambda fare : normalizeFare(fare))\n\n# AGE\ndef normalizeAge(age):\n    m = combined.Age.mean()\n    s = combined.Age.std()\n    return (age-m)\/s\ncombined['Age'] = combined['Age'].map(lambda age : normalizeAge(age))","f4407506":"#Encoding Cabin\ncombined.Cabin = combined.Cabin.map(lambda l : str(l)[0])","54f4a92d":"#Checking if any NaN left\ncombined.info()","2abdfab4":"cat_cols = ['Sex', 'Cabin', 'Embarked']\ndummies = pd.get_dummies(combined, cat_cols, drop_first=True)\ndummies.dtypes","bb87af4b":"combined.isna().sum()","92500e2d":"dummies.PassengerId","bfe52383":"X=dummies[:len(train_data)].drop(columns=['Survived'])\ny=train_data.Survived","e285f34a":"print(X.shape)\nprint(y.shape)","d2ea9efc":"X","3deb1b5b":"y","4261c093":"test_X = dummies[len(train_data):]\ntest_X.drop(columns=['Survived'], inplace=True)","4233d1ca":"from xgboost import XGBRegressor as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=0, stratify = y)","a635d6ba":"X_train.shape","69fd32b3":"X_train.columns == test_X.columns","99df7349":"X_valid.shape","07693f4c":"X_valid.columns","964732b6":"model = xgb(n_estimators=1000, learning_rate=0.05, random_state=0)\nmodel.fit(X_train, y_train, early_stopping_rounds=5, eval_set=[(X_valid, y_valid)], verbose=False)\npredictions = model.predict(test_X)","8201a0a4":"test_data.PassengerId","57fd79c8":"predictions = [0 if pred<0.5 else 1 for pred in predictions]","acca8129":"# prediction here \nsub = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived' : predictions})\nsub.to_csv(\"titanic-ml.csv\", index=False)","1a8c3c4b":"Since the people died were mostly from Pclass 3, assuming the missing Fare entry is from Pclass 3 as well.","4cd5b377":"Average fare of survivors is doubled of those who could'nt make it. Coincidence?"}}