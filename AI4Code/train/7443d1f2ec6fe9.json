{"cell_type":{"43987a8b":"code","cf170016":"code","e71d78a9":"code","ff55d86e":"code","549edd40":"code","95abcafd":"code","fd13bc31":"code","09daafa3":"code","ab21b703":"code","0067eb06":"code","1cf2f496":"code","c46b27c6":"code","949764c0":"code","22d202f7":"code","b686d6d0":"code","3798a4c9":"code","8decdba4":"code","74addbba":"code","52199f88":"code","6562149e":"code","98bc7a58":"code","26cf4410":"code","fde09eb3":"code","fba0691c":"markdown","7718094d":"markdown"},"source":{"43987a8b":"import os\nimport re\nimport random\nimport numpy as np\nimport pandas as pd\nimport librosa\nimport librosa.display\nimport cv2\nimport matplotlib.pyplot as plt\nimport IPython.display as ipd\n\n\nfrom tqdm import tqdm\nfrom pydub import AudioSegment\n\nimport albumentations\nfrom albumentations.core.transforms_interface import DualTransform, BasicTransform\n\nimport warnings\nwarnings.filterwarnings('ignore')","cf170016":"path = f\"..\/input\/birdsong-resampled-train-audio-03\/norhar2\/XC143657.wav\"\nsample_rate = 16000\nsound = AudioSegment.from_wav(path)\nsound = sound.set_frame_rate(sample_rate)\n\ndata = np.array(sound.get_array_of_samples(), dtype=np.float32), sample_rate","e71d78a9":"class AudioTransform(BasicTransform):\n    \"\"\"Transform for Audio task\"\"\"\n\n    @property\n    def targets(self):\n        return {\"data\": self.apply}\n    \n    def update_params(self, params, **kwargs):\n        if hasattr(self, \"interpolation\"):\n            params[\"interpolation\"] = self.interpolation\n        if hasattr(self, \"fill_value\"):\n            params[\"fill_value\"] = self.fill_value\n        return params","ff55d86e":"    \"\"\"It simply add some random value into data by using numpy\"\"\"\n    def __init__(self, always_apply=False, p=0.5):\n        super(NoiseInjection, self).__init__(always_apply, p)\n    \n    def apply(self, data, noise_levels=(0, 0.5), **params):\n        sound, sr = data\n        noise_level = np.random.uniform(*noise_levels)\n        noise = np.random.randn(len(sound))\n        augmented_sound = sound + noise_level * noise\n        # Cast back to same data type\n        augmented_sound = augmented_sound.astype(type(sound[0]))\n\n        return augmented_sound, sr","549edd40":"class NoiseInjection(AudioTransform):\n    \"\"\"It simply add some random value into data by using numpy\"\"\"\n    def __init__(self, always_apply=False, p=0.5):\n        super(NoiseInjection, self).__init__(always_apply, p)\n    \n    def apply(self, data, noise_levels=(0, 0.5), **params):\n        sound, sr = data\n        noise_level = np.random.uniform(*noise_levels)\n        noise = np.random.randn(len(sound))\n        augmented_sound = sound + noise_level * noise\n        # Cast back to same data type\n        augmented_sound = augmented_sound.astype(type(sound[0]))\n\n        return augmented_sound, sr","95abcafd":"transform = NoiseInjection(p=1.0)\nsound_aug, sr = transform(data=data)['data']\n\nplt.plot(data[0])\nplt.plot(sound_aug)\nplt.show()\n\ndisplay(ipd.Audio(data[0], rate=sr))\ndisplay(ipd.Audio(sound_aug, rate=sr))","fd13bc31":"class ShiftingTime(AudioTransform):\n    \"\"\"Shifting time axis\"\"\"\n    def __init__(self, always_apply=False, p=0.5):\n        super(ShiftingTime, self).__init__(always_apply, p)\n    \n    def apply(self, data, **params):\n        sound, sr = data\n\n        shift_max = np.random.randint((len(sound)\/sr)\/2)\n        shift = np.random.randint(sr * shift_max)\n        direction = np.random.randint(0,2)\n        if direction == 1:\n            shift = -shift\n\n        augmented_sound = np.roll(sound, shift)\n        # Set to silence for heading\/ tailing\n        if shift > 0:\n            augmented_sound[:shift] = 0\n        else:\n            augmented_sound[shift:] = 0\n\n        return augmented_sound, sr\n\n    \ntransform = ShiftingTime(p=1.0)\nsound_aug, sr = transform(data=data)['data']\n\nplt.plot(data[0])\nplt.plot(sound_aug)\nplt.show()\n\ndisplay(ipd.Audio(data[0], rate=sr))\ndisplay(ipd.Audio(sound_aug, rate=sr))","09daafa3":"class PitchShift(AudioTransform):\n    \"\"\"Shifting time axis\"\"\"\n    def __init__(self, always_apply=False, p=0.5):\n        super(PitchShift, self).__init__(always_apply, p)\n    \n    def apply(self, data, **params):\n        sound, sr = data\n\n        n_steps = np.random.randint(-10, 10)\n        augmented_sound = librosa.effects.pitch_shift(sound, sr, n_steps)\n\n        return augmented_sound, sr\n    \ntransform = PitchShift(p=1.0)\nsound_aug, sr = transform(data=data)['data']\n\nplt.plot(data[0])\nplt.plot(sound_aug)\nplt.show()\n\ndisplay(ipd.Audio(data[0], rate=sr))\ndisplay(ipd.Audio(sound_aug, rate=sr))","ab21b703":"class TimeStretch(AudioTransform):\n    \"\"\"Shifting time axis\"\"\"\n    def __init__(self, always_apply=False, p=0.5):\n        super(TimeStretch, self).__init__(always_apply, p)\n    \n    def apply(self, data, **params):\n        sound, sr = data\n\n        rate = np.random.uniform(0, 2)\n        augmented_sound = librosa.effects.time_stretch(sound, rate)\n\n        return augmented_sound, sr\n\ntransform = TimeStretch(p=1.0)\nsound_aug, sr = transform(data=data)['data']\n\nplt.plot(data[0])\nplt.plot(sound_aug)\nplt.show()\n\ndisplay(ipd.Audio(data[0], rate=sr))\ndisplay(ipd.Audio(sound_aug, rate=sr))","0067eb06":"class MelSpectrogram(AudioTransform):\n    \"\"\"Shifting time axis\"\"\"\n    def __init__(self, parameters, always_apply=False, p=0.5):\n        super(MelSpectrogram, self).__init__(always_apply, p)\n\n        self.parameters = parameters\n    \n    def apply(self, data, **params):\n        sound, sr = data\n\n        melspec = librosa.feature.melspectrogram(sound, sr=sr, **self.parameters)\n        melspec = librosa.power_to_db(melspec)\n        melspec = melspec.astype(np.float32)\n\n        return melspec, sr\n    \n    \n    \nmelspectrogram_parameters = {\n        \"n_mels\": 128,\n        \"fmin\": 20,\n        \"fmax\": 16000\n    }\n\ntransform = MelSpectrogram(parameters=melspectrogram_parameters, p=1.0)\n\nmelspec, sr = transform(data=data)['data']\n\nplt.figure(figsize=(20,10))\nplt.imshow(melspec)\nplt.show()","1cf2f496":"class SpecAugment(AudioTransform):\n    \"\"\"Shifting time axis\"\"\"\n    def __init__(self, num_mask=2, freq_masking=0.15, time_masking=0.20, always_apply=False, p=0.5):\n        super(SpecAugment, self).__init__(always_apply, p)\n\n        self.num_mask = num_mask\n        self.freq_masking = freq_masking\n        self.time_masking = time_masking\n    \n    def apply(self, data, **params):\n        melspec, sr = data\n\n        spec_aug = self.spec_augment(melspec, \n                                     self.num_mask,\n                                     self.freq_masking,\n                                     self.time_masking,\n                                     melspec.min())\n        \n\n\n        return spec_aug, sr\n    \n\n    def spec_augment(self, \n                    spec: np.ndarray,\n                    num_mask=2,\n                    freq_masking=0.15,\n                    time_masking=0.20,\n                    value=0):\n        spec = spec.copy()\n        num_mask = random.randint(1, num_mask)\n        for i in range(num_mask):\n            all_freqs_num, all_frames_num  = spec.shape\n            freq_percentage = random.uniform(0.0, freq_masking)\n\n            num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n            f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n            f0 = int(f0)\n            spec[f0:f0 + num_freqs_to_mask, :] = value\n\n            time_percentage = random.uniform(0.0, time_masking)\n\n            num_frames_to_mask = int(time_percentage * all_frames_num)\n            t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n            t0 = int(t0)\n            spec[:, t0:t0 + num_frames_to_mask] = value\n\n        return spec\n    \n    \n    \ntransform = SpecAugment(p=1.0)\ndata = melspec, sr\n\nspecAug, sr = transform(data=data)['data']\n\nplt.figure(figsize=(20,10))\nplt.imshow(specAug)\nplt.show()","c46b27c6":"class SpectToImage(AudioTransform):\n\n    def __init__(self, always_apply=False, p=0.5):\n        super(SpectToImage, self).__init__(always_apply, p)\n    \n    def apply(self, data, **params):\n        image, sr = data\n        delta = librosa.feature.delta(image)\n        accelerate = librosa.feature.delta(image, order=2)\n        image = np.stack([image, delta, accelerate], axis=-1)\n        image = image.astype(np.float32) \/ 100.0\n\n        return image\n    \n    \ntransform = SpectToImage(p=1.0)\ndata = specAug, sr\n\nimage = transform(data=data)['data']\n\nplt.figure(figsize=(20,10))\nplt.imshow(image)\nplt.show()","949764c0":"# audio_augmentation = albumentations.Compose([\n#      RandomAudio(always_apply=True),\n#      NoiseInjection(p=1),\n#      MelSpectrogram(parameters=melspectrogram_parameters,always_apply=True),\n#      SpecAugment(p=1),\n#      SpectToImage(always_apply=True)\n# ])\n\n# data = np.array(sound.get_array_of_samples(), dtype=np.float32), sample_rate\n# image = audio_augmentation(data=data)['data']\n\n# plt.imshow(image)\n# plt.show()","22d202f7":"class CutOut(AudioTransform):\n    def __init__(self, always_apply=False, p=0.5 ):\n        super(CutOut, self).__init__(always_apply, p)\n        \n    def apply(self,data,**params):\n        '''\n        data : ndarray of audio timeseries\n        '''\n        start_ = np.random.randint(0,len(data))\n        end_ = np.random.randint(start_,len(data))\n        \n        data[start_:end_] = 0\n        \n        return data\n    \n\n\ny,sr = librosa.load(path,sr=16000)\n\nprint('Audio Intially')\nipd.Audio(y, rate=sr)","b686d6d0":"transform = CutOut(p=1.0)\n\nprint('audio after transform')\nipd.Audio(transform(data=y)['data'],rate=sr)","3798a4c9":"def openAudioFile(path, sample_rate=16000, as_mono=True, mean_substract=False):\n    \n    # Open file with librosa (uses ffmpeg or libav)\n    sig, rate = librosa.load(path, sr=sample_rate, mono=as_mono)\n\n    # Noise reduction?\n    if mean_substract:\n        sig -= sig.mean()\n\n    return sig, rate","8decdba4":"def splitSignal(sig, rate, seconds, overlap, minlen):\n\n    # Split signal with overlap\n    sig_splits = []\n    for i in range(0, len(sig), int((seconds - overlap) * rate)):\n        split = sig[i:i + int(seconds * rate)]\n\n        # End of signal?\n        if len(split) < int(minlen * rate):\n            break\n        \n        # Signal chunk too short?\n        if len(split) < int(rate * seconds):\n            split = np.hstack((split, np.zeros((int(rate * seconds) - len(split),))))\n        \n        sig_splits.append(split)\n\n    return sig_splits","74addbba":"def melspec(sig, rate, shape=(128, 256), fmin=20, fmax=16000, normalize=True, preemphasis=0.95):\n\n    # shape = (height, width) in pixels\n\n    # Mel-Spec parameters\n    SAMPLE_RATE = rate\n    N_FFT = shape[0] * 8 # = window length\n    N_MELS = shape[0]\n    HOP_LEN = len(sig) \/\/ (shape[1] - 1)    \n    FMAX = fmax\n    FMIN = fmin\n\n    # Preemphasis as in python_speech_features by James Lyons\n    if preemphasis:\n        sig = np.append(sig[0], sig[1:] - preemphasis * sig[:-1])\n\n    # Librosa mel-spectrum\n    melspec = librosa.feature.melspectrogram(y=sig, sr=SAMPLE_RATE, hop_length=HOP_LEN, n_fft=N_FFT, n_mels=N_MELS, fmax=FMAX, fmin=FMIN, power=1.0)\n    \n    # Convert power spec to dB scale (compute dB relative to peak power)\n    melspec = librosa.amplitude_to_db(melspec, ref=np.max, top_db=80)\n\n    # Flip spectrum vertically (only for better visialization, low freq. at bottom)\n    melspec = melspec[::-1, ...]\n\n    # Trim to desired shape if too large\n    melspec = melspec[:shape[0], :shape[1]]\n\n    # Normalize values between 0 and 1\n    if normalize:\n        melspec -= melspec.min()\n        if not melspec.max() == 0:\n            melspec \/= melspec.max()\n        else:\n            mlspec = np.clip(melspec, 0, 1)\n\n    return melspec.astype('float32')","52199f88":"def stft(sig, rate, shape=(128, 256), fmin=20, fmax=16000, normalize=True):\n\n    # shape = (height, width) in pixels\n\n    # STFT-Spec parameters\n    N_FFT = int((rate * shape[0] * 2) \/ abs(fmax - fmin)) + 1\n    P_MIN = int(float(N_FFT \/ 2) \/ rate * fmin) + 1\n    P_MAX = int(float(N_FFT \/ 2) \/ rate * fmax) + 1    \n    HOP_LEN = len(sig) \/\/ (shape[1] - 1)\n\n    # Librosa stft-spectrum\n    spec = librosa.core.stft(sig, hop_length=HOP_LEN, n_fft=N_FFT, window='hamm')\n\n    # Convert power spec to dB scale (compute dB relative to peak power)\n    spec = librosa.amplitude_to_db(librosa.core.magphase(spec)[0], ref=np.max, top_db=80)\n\n    # Trim to desired shape using cutoff frequencies\n    spec = spec[P_MIN:P_MAX, :shape[1]]\n\n    # Flip spectrum vertically (only for better visialization, low freq. at bottom)\n    spec = spec[::-1, ...]    \n\n    # Normalize values between 0 and 1\n    if normalize:\n        spec -= spec.min()\n        if not spec.max() == 0:\n            spec \/= spec.max()\n        else:\n            spec = np.clip(spec, 0, 1)    \n    \n    return spec.astype('float32')","6562149e":"def get_spec(sig, rate, shape, spec_type='linear', **kwargs):\n\n    if spec_type.lower()== 'melspec':\n        return melspec(sig, rate, shape, **kwargs)\n    else:\n        return stft(sig, rate, shape, **kwargs)","98bc7a58":"def signal2noise(spec):\n\n    # Get working copy\n    spec = spec.copy()\n\n    # Calculate median for columns and rows\n    col_median = np.median(spec, axis=0, keepdims=True)\n    row_median = np.median(spec, axis=1, keepdims=True)\n\n    # Binary threshold\n    spec[spec < row_median * 1.25] = 0.0\n    spec[spec < col_median * 1.15] = 0.0\n    spec[spec > 0] = 1.0\n\n    # Median blur\n    spec = cv2.medianBlur(spec, 3)\n\n    # Morphology\n    spec = cv2.morphologyEx(spec, cv2.MORPH_CLOSE, np.ones((3, 3), np.float32))\n\n    # Sum of all values\n    spec_sum = spec.sum()\n\n    # Signal to noise ratio (higher is better)\n    try:\n        s2n = spec_sum \/ (spec.shape[0] * spec.shape[1] * spec.shape[2])\n    except:\n        s2n = spec_sum \/ (spec.shape[0] * spec.shape[1])\n\n    return s2n","26cf4410":"def specsFromSignal(sig, rate, shape, seconds, overlap, minlen, **kwargs):\n\n    # Split signal in consecutive chunks with overlap\n    sig_splits = splitSignal(sig, rate, seconds, overlap, minlen)\n\n    # Extract specs for every sig split\n    for sig in sig_splits:\n\n        # Get spec for signal chunk\n        spec = get_spec(sig, rate, shape, **kwargs)\n\n        yield spec","fde09eb3":"def specsFromFile(path, rate, seconds, overlap, minlen, shape, start=-1, end=-1, **kwargs):\n\n    # Open file\n    sig, rate = openAudioFile(path, rate)\n\n    # Trim signal?\n    if start > -1 and end > -1:\n        sig = sig[int(start * rate):int(end * rate)]\n        minlen = 0\n\n    # Yield all specs for file\n    for spec in specsFromSignal(sig, rate, shape, seconds, overlap, minlen, **kwargs):\n        yield spec\n    \nif __name__ == '__main__':\n\n    \n    for spec in specsFromFile('..\/input\/birdsong-resampled-train-audio-03\/norwat\/XC120655.wav',\n                              rate=44000,\n                              seconds=1,\n                              overlap=0,\n                              minlen=1,\n                              shape=(128, 256),\n                              fmin=20,\n                              fmax=16000,\n                              spec_type='melspec'):\n\n        # Calculate and show noise measure\n        noise = signal2noise(spec)\n        print (noise)\n\n        # Show spec and wait for enter key\n        cv2.imshow('SPEC', spec)\n        cv2.waitKey(-1)","fba0691c":"Show All","7718094d":"# Spectrogram Extraction\n\nhttps:\/\/github.com\/kahst\/BirdCLEF-Baseline\/blob\/master\/utils\/"}}