{"cell_type":{"32948069":"code","0450dfe4":"code","a9ea9d09":"code","be401f5e":"code","1205b739":"code","de966ac3":"code","6d53054a":"code","c3d193ac":"code","d5ad4f34":"code","6a0e7e41":"code","5f419821":"code","9de0d132":"code","20978d9e":"code","b8a9a065":"markdown","955534c8":"markdown","7f12c051":"markdown","65bf6f2c":"markdown","4e86d90f":"markdown","4d6532f3":"markdown","87ce311e":"markdown","f5934877":"markdown","6537e4ad":"markdown","969802e9":"markdown","86ed50a4":"markdown","19f04171":"markdown","b23892cd":"markdown"},"source":{"32948069":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0450dfe4":"\nfrom operator import index\nfrom pyexpat.errors import XML_ERROR_TEXT_DECL\nfrom turtle import home\nfrom unicodedata import category\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy import rand\nimport seaborn as sns\n\nfrom sklearn.metrics import mean_squared_error\n\nSeed = 42\nnp.random.seed(Seed)","a9ea9d09":"# Build Funcitons\n\ndef save_csv(y_pred, file_name):\n    submit = pd.read_csv(path + 'sample_submission.csv')\n    submit['item_cnt_month'] = y_pred\n    submit.to_csv(file_name, index = False)","be401f5e":"# Load the datasets\npath = '\/kaggle\/input\/competitive-data-science-predict-future-sales\/'\n\ntrain = pd.read_csv(path + '.\/sales_train.csv')\n\nshops = pd.read_csv(path + 'shops.csv')\nitems = pd.read_csv(path + 'items.csv')\nitem_categories = pd.read_csv(path + 'item_categories.csv')","1205b739":"# merge categories_id in train set\ntrain = train.merge(right=items, how='inner', on='item_id')\n\n# drop string feature from dataset\ntrain.drop(labels=['item_name'], axis = 1, inplace=True)\n\n# change negative values in item_cnt_day feature\ntrain['item_cnt_day'] = np.abs(train['item_cnt_day'])\n\ngrouped_train = train.groupby(by=['date_block_num', 'shop_id', 'item_category_id', 'item_id'], ).agg({'item_cnt_day':sum}).reset_index()\n","de966ac3":"# Shffle the dataframe first to random the rows\ngrouped_train = grouped_train.sample(frac=1, random_state=Seed)\n\n# split target from train 'item_cnt_day'\ntarget  = grouped_train['item_cnt_day']\n\n# drop item_cnt_day and date_block_num features\ngrouped_train.drop(labels=['item_cnt_day', 'date_block_num'], axis =1, inplace=True)\n","6d53054a":"grouped_train.describe()\n\nsns.heatmap(grouped_train.corr())\n","c3d193ac":"# Split Train and valid data\nfrom sklearn.model_selection import train_test_split\nx_train, x_valid, y_train, y_valid = train_test_split(grouped_train, target, test_size=10_000)\n\nx_train.shape, x_valid.shape, y_train.shape, y_valid.shape","d5ad4f34":"# Prepare test data\ntest = pd.read_csv(path + 'test.csv')\n\ntest = test.merge(right=items, how='inner', on='item_id')\nx_test = test.drop(labels=['item_name', 'ID'], axis=1)\n\n# change the order of features ['shop_id', 'item_id', 'item_category_id'] to ['shop_id', 'item_category_id', 'item_id']\nx_test = x_test[['shop_id', 'item_category_id', 'item_id']]\n","6a0e7e41":"# Scale the data using StandardScaler\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_valid = sc.transform(x_valid)\nx_test = sc.transform(x_test)\n","5f419821":"''' 1- Random Forest Model'''\nfrom sklearn.ensemble import RandomForestRegressor\nrnd_reg = RandomForestRegressor(n_estimators=150, max_depth=20, random_state=Seed, \n    n_jobs=-1, criterion='mse')\n\nprint('Training the data....')\nrnd_reg.fit(x_train, y_train)\n\n# Score the model\nprint('Model Accuracy...')\nscore = rnd_reg.score(x_valid, y_valid)\nprint(score)\n\n# Model RMSE\nprint('Model RMSE...')\ny_pred_valid_rnd = rnd_reg.predict(x_valid)\nrmse_rnd = mean_squared_error(y_valid, y_pred_valid_rnd, squared=False)\nprint(rmse_rnd)\n\n# predict the test set\nprint('Predict the test data...')\ny_pred_rnd = rnd_reg.predict(x_test)\ny_pred_rnd = np.round(y_pred_rnd).astype(np.int64)\nprint(y_pred_rnd)\n\n# Save the result\nprint('Save the prediction in submission file')\nsave_csv(y_pred_rnd, file_name = 'submission_solution_rnd_reg.csv')\n","9de0d132":"# ''' 2- Suppor Vector Machine '''\n\n# from sklearn.svm import SVR\n# svr_reg = SVR()\n\n# print('Training the data....')\n# svr_reg.fit(x_train, y_train)\n\n# # Score the model\n# print('Model Accuracy...')\n# score = svr_reg.score(x_valid, y_valid)\n# print(score)\n\n# # Model RMSE\n# print('Model RMSE...')\n# y_pred_valid_svr = svr_reg.predict(x_valid)\n# rmse_svr = mean_squared_error(y_valid, y_pred_valid_svr, squared=False)\n# print(rmse_svr)\n\n# # predict the test set\n# print('Predict the test data...')\n# y_pred_svr = svr_reg.predict(x_test)\n# y_pred_svr = np.round(y_pred_svr).astype(np.int64)\n# print(y_pred_svr)\n\n# # Save the result\n# print('Save the prediction in submission file')\n# save_csv(y_pred_svr, file_name = 'submission_solution_svr_reg.csv')\n","20978d9e":"'''3- XGBoost'''\n\nimport xgboost as xg\nxg_reg = xg.XGBRegressor(n_estimators =120, learning_rate = .01, random_state = Seed, n_jobs = -1,)\n\n\nprint('Training the data....')\nxg_reg.fit(x_train, y_train)\n\n# Score the model\nprint('Model Accuracy...')\nscore = xg_reg.score(x_valid, y_valid)\nprint(score)\n\n# Model RMSE\nprint('Model RMSE...')\ny_pred_valid_xgb = xg_reg.predict(x_valid)\nrmse_xgb = mean_squared_error(y_valid, y_pred_valid_xgb, squared=False)\nprint(rmse_xgb)\n\n# predict the test set\nprint('Predicting the test data...')\ny_pred_xgb = xg_reg.predict(x_test)\ny_pred_xgb = np.round(y_pred_xgb).astype(np.int64)\nprint(y_pred_xgb)\n\n# Save the result\nprint('Saving the prediction in submission file')\nsave_csv(y_pred_xgb, file_name = 'submission_solution_xg_reg.csv')","b8a9a065":"##### 3- XGBRegressor","955534c8":"### Load the datasets","7f12c051":"### Build Funcitons\n","65bf6f2c":"### Import Libraries","4e86d90f":"#### Build the Models","4d6532f3":"##### 1 - RandomForest Algorithm","87ce311e":"#### Split Train and valid data","f5934877":"#### show the correlation between features","6537e4ad":"#### Shffle the dataframe first to random the rows\n* split target from train 'item_cnt_day'\n* drop item_cnt_day and date_block_num features","969802e9":"##### 2- Suppor Vector Machine","86ed50a4":"#### merge categories_id in train set\n- merge categories_id in train set\n* drop string feature from dataset\n* change negative values in item_cnt_day feature","19f04171":"#### Prepare test data","b23892cd":"#### Scale the features"}}