{"cell_type":{"0d3a3630":"code","3ffa776b":"code","277c1e7f":"code","2088b71a":"code","769a5a82":"code","f485d9b2":"code","a732b4ac":"code","5d5db167":"code","ff144138":"code","fda04337":"code","e95b1300":"code","87ff32c1":"code","3fedb868":"code","2a27c615":"code","41d2998d":"code","0f273dea":"code","cbcef7cc":"code","b299adbc":"code","44770a53":"code","7b5bb500":"code","cb22adc2":"code","6d31800c":"code","f0581437":"code","63c37246":"code","6a727fe9":"code","f3dc4941":"code","a0c47445":"code","97a89885":"code","e269ceac":"code","248c0446":"code","87d77eb2":"code","795efada":"code","1c8fed16":"code","be037e2a":"code","6b893dde":"code","0947c92d":"code","e8ced0d4":"code","38fdd0dd":"code","a3186790":"code","997b945c":"code","46c064d1":"code","4c230040":"code","4c17b40b":"markdown","0c4b741b":"markdown","c8bda69d":"markdown","702f06f4":"markdown","9198cf96":"markdown","eb7dade5":"markdown","24294a61":"markdown","8e54e114":"markdown","80be21e8":"markdown","d1833faa":"markdown","0a50a7d4":"markdown"},"source":{"0d3a3630":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3ffa776b":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport cv2\nimport os\nimport random\nimport tensorflow as tf\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Conv2D, MaxPool2D, BatchNormalization\nfrom keras.layers import Flatten, Dropout, MaxPooling2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom keras import applications\nsns.set_style('dark')","277c1e7f":"# Current working dictionary\n!pwd","2088b71a":"path = '..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/'","769a5a82":"!ls '..\/input\/cell-images-for-detecting-malaria\/cell_images'","f485d9b2":"parasitized_img = os.listdir(path+'Parasitized\/')\nuninfected_img = os.listdir(path+'Uninfected\/')\nprint(\"Number of parasitized Image:\",len(parasitized_img))\nprint(\"Number of uninfected Image:\", len(uninfected_img))","a732b4ac":"labels = ['Parasitized','Uninfected']\nimg_size = 224","5d5db167":"fig = plt.figure(figsize=(8,6))\nfor i in range(6):\n    idx = random.randint(0, len(parasitized_img))\n    plt.subplot(2, 3, i+1)\n    img = cv2.imread(path+'Parasitized\/'+parasitized_img[idx])\n    plt.imshow(img)","ff144138":"par_img = plt.imread(path+'Parasitized\/'+parasitized_img[0])\nprint(\"Image Shape: \",par_img.shape)","fda04337":"par_img","e95b1300":"par_img.max()","87ff32c1":"par_img.min()","3fedb868":"fig = plt.figure(figsize=(8,6))\nfor i in range(6):\n    idx = random.randint(0, len(uninfected_img))\n    plt.subplot(2, 3, i+1)\n    img = cv2.imread(path+'Uninfected\/'+uninfected_img[idx])\n    plt.imshow(img)","2a27c615":"Un_img = plt.imread(path+'Uninfected\/'+uninfected_img[0])\nprint(\"Image Shape: \",Un_img.shape)","41d2998d":"Un_img","0f273dea":"Un_img.max()","cbcef7cc":"Un_img.min()","b299adbc":"def Image_2_array(data_dir):\n    data = []\n    per1,per2 = [], []\n    un1, un2 = [], []\n    for label in labels: \n        path = os.path.join(data_dir, label)\n        class_num = labels.index(label)\n        for img in (os.listdir(path)):\n            try:\n                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n                d1, d2, _ = img_arr.shape\n                if(class_num==0):\n                    per1.append(d1)\n                    per2.append(d2)\n                if(class_num==1):\n                    un1.append(d1)\n                    un2.append(d2)\n                resized_arr = cv2.resize(img_arr, (img_size, img_size))\n                # Reshaping images to preferred size\n                data.append([resized_arr, class_num])\n            except Exception as e:\n                print(e)\n    return np.array(data), [per1, per2], [un1, un2]","44770a53":"data, per, un = Image_2_array(\"\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\")","7b5bb500":"sns.jointplot(x=per[0] , y=per[1])","cb22adc2":"sns.jointplot(x=un[0] , y=un[1])","6d31800c":"l = []\nfor i in data:\n    l.append(labels[i[1]])","f0581437":"l","63c37246":"fig,ax=plt.subplots(5,2)\nfig.set_size_inches(15,15)\nfor i in range(5):\n    for j in range (2):\n        l=random.randint(0,len(data))\n        ax[i,j].imshow(data[l][0])\n        ax[i,j].set_title('disease: '+labels[data[l][1]])\nplt.tight_layout()","6a727fe9":"datagen = ImageDataGenerator(rescale=1.\/255,\n                             rotation_range=30,\n                             horizontal_flip=True,\n                             vertical_flip=True,\n                             shear_range=0.1,\n                             zoom_range=0.1,\n                             width_shift_range=0.2,\n                             height_shift_range=0.2,\n                             validation_split=0.2,\n                             fill_mode='nearest')\n\ntrain_data = datagen.flow_from_directory(path,\n                                         shuffle=True,\n                                         seed=42,\n                                         target_size=(128,128),\n                                         batch_size=64,\n                                         class_mode = 'binary',\n                                         subset = 'training')\n\nvalidation_data = datagen.flow_from_directory(path,\n                                              shuffle=False,\n                                              seed=42,\n                                              target_size=(128,128),\n                                              batch_size=64,\n                                              class_mode = 'binary',\n                                              subset = 'validation')","f3dc4941":"model=tf.keras.Sequential([\n    tf.keras.layers.Conv2D(16,(3,3),input_shape=(128,128,3),activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.2),\n    \n    tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.25),\n    \n    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.3),\n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(64,activation='relu'),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Dense(1,activation='sigmoid')])","a0c47445":"model.summary()","97a89885":"model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),loss='binary_crossentropy',metrics=['acc'])","e269ceac":"early_stop = EarlyStopping(monitor='val_loss',patience=2)","248c0446":"history = model.fit(train_data,\n                    validation_data=validation_data,\n                    epochs = 10,\n                    callbacks=[early_stop])","87d77eb2":"pred_probabilities = model.predict(validation_data)\npredictions = pred_probabilities > 0.5","795efada":"print(classification_report(validation_data.classes, predictions))","1c8fed16":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(acc))","be037e2a":"plt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.figure()","6b893dde":"plt.plot(epochs, loss, 'r', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend(loc=0)\nplt.figure()","0947c92d":"from tensorflow.keras.applications.resnet50 import ResNet50\nconv_base = ResNet50(weights='imagenet',include_top=False,input_shape=(128,128,3))","e8ced0d4":"def classifier():\n    model = Sequential()\n    model.add(conv_base)\n    model.add(Flatten())\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.25))\n    model.add(Dense(1, activation='sigmoid'))\n    model.summary()\n    \n    model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),loss='binary_crossentropy',metrics=['acc'])    \n    return model","38fdd0dd":"from keras.callbacks import  ReduceLROnPlateau\nfrom keras.utils import to_categorical\nmodel1 = classifier()\nhistory_vgg = model1.fit(train_data,\n                              validation_data=validation_data,\n                              epochs = 10,\n                              callbacks=[early_stop])","a3186790":"acc = history_vgg.history['acc']\nval_acc = history_vgg.history['val_acc']\nloss = history_vgg.history['loss']\nval_loss = history_vgg.history['val_loss']\nepochs = range(len(acc))","997b945c":"plt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.figure()","46c064d1":"plt.plot(epochs, loss, 'r', label='Training los')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend(loc=0)\nplt.figure()","4c230040":"pred_probabilities = model1.predict(validation_data)\npredictions = pred_probabilities > 0.5\nprint(classification_report(validation_data.classes, predictions))","4c17b40b":"## Image 2 Array Conversion","0c4b741b":"### Parasitized images shape distribution","c8bda69d":"# Import necessary libraries","702f06f4":"# CNN Model","9198cf96":"# Thank you","eb7dade5":"### Uninfected Image images shape distribution","24294a61":"# Transfer Learning","8e54e114":"## Data preprosessing","80be21e8":"## Parasitized images","d1833faa":"## Dataset Path","0a50a7d4":"## Uninfected Image"}}