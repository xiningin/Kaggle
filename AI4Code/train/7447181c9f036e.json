{"cell_type":{"6c5c6604":"code","3b199b17":"code","49d5db94":"code","62aea40d":"code","cd86d582":"code","97c8471d":"code","eb5eab4a":"code","9051d15d":"code","8103ce0a":"code","744ccb13":"code","3978680c":"code","35b0c40d":"code","1fcb85ad":"code","ab1c573f":"code","8772ee0b":"code","65d9e1fd":"code","e4365589":"code","7b014c16":"code","00209a4d":"code","6e7bcf77":"code","9ab472a1":"code","892e78ac":"code","3ad8d283":"markdown","f0a1dfd5":"markdown","cabe5896":"markdown","44091bc9":"markdown","68249adb":"markdown","d085fb14":"markdown","d1a93c78":"markdown","9b6df70d":"markdown","e167cb7a":"markdown","98b4fe16":"markdown","dca04afc":"markdown","6079bac6":"markdown","fb4218ef":"markdown","2a1191c7":"markdown","e9035508":"markdown","8f0b750d":"markdown","2dfae2b3":"markdown","8a0bd869":"markdown","94e693ca":"markdown","c10a278f":"markdown","c734110a":"markdown","05159abd":"markdown","73691c6f":"markdown"},"source":{"6c5c6604":"import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport PIL\nimport tensorflow as tf\nimport pathlib\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential","3b199b17":"print(tf.__version__)","49d5db94":"dataset_url = \"https:\/\/storage.googleapis.com\/download.tensorflow.org\/example_images\/flower_photos.tgz\"\ndata_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)\ndata_dir = pathlib.Path(data_dir)","62aea40d":"folder = list(data_dir.glob('*'))\nimages = list(data_dir.glob('*\/*.jpg')) #list of all images (full path)\nprint('Folder Structure:')\nfor f in folder:\n    print(f)\nprint('\\nNumber of images: ', len(images))","cd86d582":"fig = plt.figure(figsize=(10, 10))\nfor i in range(9):\n    plt.subplot(3, 3, i + 1)\n    plt.title(str(images[i]).split('\/')[-1], fontsize=10) #get the file name and disply as title\n    plt.imshow(PIL.Image.open(images[i]))\n    ax = plt.axis(\"off\")","97c8471d":"batch_size = 32\nimg_height = 180\nimg_width = 180","eb5eab4a":"train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    data_dir,\n    validation_split=0.8, #80% training\n    subset=\"training\",\n    seed=123,\n    image_size=(img_height, img_width),\n    batch_size=batch_size)","9051d15d":"val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    data_dir,\n    validation_split=0.2, #20% training\n    subset=\"validation\",\n    seed=123,\n    image_size=(img_height, img_width),\n    batch_size=batch_size)","8103ce0a":"class_names = train_ds.class_names\nprint('The name of the classes are: ', class_names)","744ccb13":"fig = plt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n    for i in range(9):\n        plt.subplot(3, 3, i + 1)\n        plt.title(class_names[labels[i]], fontsize=10)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        ax = plt.axis(\"off\")","3978680c":"AUTOTUNE = tf.data.AUTOTUNE\n\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)","35b0c40d":"normalization_layer = layers.experimental.preprocessing.Rescaling(1.\/255)","1fcb85ad":"normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y)) #lambda\nimage_batch, labels_batch = next(iter(normalized_ds))\n\nfirst_image = image_batch[0]\n\nprint(np.min(first_image), np.max(first_image)) #pixels values are now in [0,1].","ab1c573f":"data_augmentation = keras.Sequential(\n    [\n        layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n                                                 input_shape=(img_height, \n                                                              img_width,\n                                                              3)),\n        layers.experimental.preprocessing.RandomRotation(0.1),\n        layers.experimental.preprocessing.RandomZoom(0.1),\n    ]\n)","8772ee0b":"plt.figure(figsize=(10, 10))\nfor images, _ in train_ds.take(1):\n    for i in range(9):\n        augmented_images = data_augmentation(images)\n        plt.subplot(3, 3, i + 1)\n        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n        ax = plt.axis(\"off\")","65d9e1fd":"model = Sequential([\n    data_augmentation, #Agumented Data\n    layers.experimental.preprocessing.Rescaling(1.\/255),\n    layers.Conv2D(16, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(32, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(64, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Dropout(0.2), #Dropout\n    layers.Flatten(),\n    layers.Dense(128, activation='relu'),\n    layers.Dense(5)\n])","e4365589":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","7b014c16":"model.summary()","00209a4d":"epochs = 15 #the cycle\nactivity = model.fit(train_ds, validation_data=val_ds, epochs=epochs)","6e7bcf77":"acc = activity.history['accuracy']\nval_acc = activity.history['val_accuracy']\n\nloss = activity.history['loss']\nval_loss = activity.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(16, 8))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\nplt.grid()\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.grid()\n\nplt.show()","9ab472a1":"file_url = \"https:\/\/img.etimg.com\/thumb\/msid-50991600,width-1200,height-900,imgsize-87025,overlay-etpanache\/photo.jpg\"\n\nfile_path = tf.keras.utils.get_file('new_downloaded_file', origin=file_url)\nimg = keras.preprocessing.image.load_img(file_path, target_size=(img_height, img_width))\nimg_array = keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0) #in the format it should be to perform prediction\n\npredictions = model.predict(img_array)\nscore = tf.nn.softmax(predictions[0])","892e78ac":"plt.figure(figsize=(10, 10))\nplt.title(\"This is a image of {} ({:.2f}% confidence).\".format(class_names[np.argmax(score)], 100 * np.max(score)), fontsize=12)\nplt.imshow(PIL.Image.open(file_path))\nax = plt.axis(\"off\")","3ad8d283":"Compiling the model, and display the summary.","f0a1dfd5":"## 2. Data\nIn our case we will be using a sample data of flowers","cabe5896":"### 2 B. Explore\nLet's see what is the structure of the files and folder, so that it will be easy to read image files.","44091bc9":"Ahaa! now let's see the output","68249adb":"Verify the version of TensorFlow:","d085fb14":"> NOTE: We are going to use GPU Accelerator for fast output while using image processing. If you like you can just turn it off or on from the `More` option in the tool bar.","d1a93c78":"## 5. Modeling\nThis is all about to create a model, we need to define the number of class as the density. We are now using `dropout` technique to reduce overfitting, which make our model more accurate for our data.","9b6df70d":"## Table of Content\n1. [The Import and Library](#1.-The-Import-and-Library)\n2. [Data](#2.-Data)\n    2. A. [Download](#2.-A.-Download)\n    2. B. [Explore](#2.-B.-Explore)\n3. [Dataset Creation](#3.-Dataset-Creation)\n4. [Dataset Configuration](#4.-Dataset-Configuration)\n    4. A. [Auto Tune](#4.-A.-Auto-Tune)\n    4. B. [Standardizing](#4.-B.-Standardizing)\n    4. C. [Augmentation](#4.-C.-Augmentation)\n5. [Modeling](#5.-Modeling)\n6. [Training](#6.-Training)\n7. [Prediction](#7.-Prediction)\n8. [Conclusion](#8.-Conclusion)","e167cb7a":"## 1. The Import and Library\nWhen we start any notebook we should have to import few libraries which makes our work more easy, we are using following libraries\n* Pyplot: for ploting and graphs\n* Numpy: to work with multi-dimensional arrays and matrices\n* os: to read files\n* PIL: fork of Pillow, to work with images\n* tensorflow: for machine learning\n* pathlib: to working with path","98b4fe16":"So, we have the photos inside of each diffrent folders. Let's preview of some photos that we have.","dca04afc":"## 3. Dataset Creation\nWe need to create a dataset based on the data we have, so here we are going to use 80% of the images for training, and 20% for validation. Batch size and image height-width.","6079bac6":"### 4. C. Augmentation\nThis step is required to make the model more accurate by training with same images but with applying rotation, zoom and flip into diffrent angle and sides.","fb4218ef":"## 4. Dataset Configuration\nFor better Performance we need to configure the dataset properly. Here we the shuffle and prefetch buffer size will be configured.","2a1191c7":"### 4. A. Auto Tune","e9035508":"### 4. B. Standardizing","8f0b750d":"## 8. Conclusion\nThere are basic few steps that we need to cover in order to build a Model to perform image classification from ground up. Many activity you may not understand now, for which I always like to prefer the bigger version of this Notebook which is available here in Google Colab ([Image Classification](https:\/\/colab.research.google.com\/github\/tensorflow\/docs\/blob\/master\/site\/en\/tutorials\/images\/classification.ipynb#scrollTo=N1loMlbYHeiJ)).","2dfae2b3":"### 2. A. Download\nHere we are going to download a .TGZ (a compressed file, like .ZIP) file from Google, and then export\/unzip files in a specific folder.","8a0bd869":"## 7. Prediction\nLet's download some other image data and run the prediction","94e693ca":"Let's see few augmented examples after applying data augmentation to the same image several times.","c10a278f":"Visualizing the activity to check how good our training was.","c734110a":"Now we are going to preview some the data with classification:","05159abd":"## 6. Training\nSet the Epochs value as 15 which is number of full cycle of model training.\n\n>NOTE: Here we are going to use the GPU Acceleration in order to save a lot of time. If you are not using GPU Acceleration, then this training will take approximately to 10 to 15 min in Kaggle.","73691c6f":"# TensorFlow Image Classification Basic\nIn this notebook we are going to follow the basic process guided by Google to use TensorFlow."}}