{"cell_type":{"718808c8":"code","908fe7fa":"code","a585c3ab":"code","51b9f698":"code","fe76d01f":"code","54c7af6d":"code","d8a63d43":"code","12ebb27f":"code","103cbf09":"code","9505582a":"code","a07b9082":"code","6ac48c23":"code","20208adb":"code","3bc64bb4":"code","2f16c951":"code","b1594af2":"code","58e4d254":"code","a948f66c":"code","5d5da654":"code","5bab0193":"code","f0b74b8a":"code","486bd36f":"code","fa3c2614":"code","f60ddf1b":"code","dc607f31":"code","8db236e3":"code","da202b24":"code","c68d5a53":"code","1efd711a":"code","eb96202d":"code","32f860ff":"code","4a615237":"code","edddacf1":"code","339c6aa4":"code","fe8c49a6":"code","b76821aa":"code","d19b82bc":"code","d7440057":"code","ebf8f523":"code","627562a3":"code","2a2163d5":"code","0b15cd9e":"code","13f22669":"code","9aa07d09":"code","cb7e3433":"code","3145c224":"code","a3dad60e":"code","326eb8bc":"code","a95541f1":"code","1ae3cce8":"code","941160e8":"code","0b9169ee":"code","9ee89d4c":"code","96b5bbce":"code","eff139f0":"code","92879ba9":"code","4c05e981":"code","864b071f":"code","77ab0487":"code","ac014ee8":"code","1e131124":"code","34b4c24e":"code","e4069722":"code","c5c37602":"code","faca595e":"markdown","7328817f":"markdown"},"source":{"718808c8":"!wget https:\/\/github.com\/mohith01\/datasets\/raw\/main\/dataset.tar.xz","908fe7fa":"!tar -xvf dataset.tar.xz","a585c3ab":"import pandas as pd\nimport numpy as np\n\ndf = pd.read_csv(\"train.csv\")","51b9f698":"df.head()","fe76d01f":"X = df.iloc[:,0:-1]\ny = df.iloc[:,-1]","54c7af6d":"X","d8a63d43":"X.head()","12ebb27f":"X[\"type\"].unique()","103cbf09":"X = X.drop(labels=[\"type\"],axis=1)\nX.head()","9505582a":"list(df[\"title\"].unique())","a07b9082":"for i in list(X[\"title\"].unique())[1:]:\n  print(str(len(X[X[\"title\"]==i]))+ \" : \"+ i  ) ","6ac48c23":"X[\"title\"] = X[\"title\"].fillna(\"Other\")\n\n##Note 50% of data is however trash\n","20208adb":"from sklearn import preprocessing\n\nle_titles = preprocessing.LabelEncoder()\nle_titles.fit(X.title)\n","3bc64bb4":"print(set(le_titles.transform(X.title)))","2f16c951":"X[\"title\"] = le_titles.transform(X.title)","b1594af2":"labels = preprocessing.LabelEncoder()\nlabels.fit(y)\n\nlabels.transform(y)","58e4d254":"y = labels.transform(y)","a948f66c":"X.head()","5d5da654":"##Handling missing data now","5bab0193":"print(pd.DataFrame(X).isnull().sum())","f0b74b8a":"print(pd.DataFrame(X).isna().sum())","486bd36f":"X[[\"Rhythm\",\"vibrance\",\"acoustics\",\"Beats_Speed\"]]","fa3c2614":"#All four are pretty much continuous\n\nX['Rhythm'].fillna(X['Rhythm'].mean(),inplace=True)\nX['vibrance'].fillna(X['vibrance'].mean(),inplace=True)\nX['acoustics'].fillna(X['acoustics'].mean(),inplace=True)\nX['Beats_Speed'].fillna(X['Beats_Speed'].mean(),inplace=True)\n\n","f60ddf1b":"print(pd.DataFrame(X).isnull().sum())","dc607f31":"X[\"TimeLength\"] = X[\"TimeLength\"]\/(60*100)","8db236e3":"X.head()","da202b24":"correl = X.corr()","c68d5a53":"import plotly.express as px\nimport plotly.io as pio\nimport plotly.graph_objects as go\n\npio.templates.default = \"plotly_white\"\ncorr_map = go.Heatmap(z=correl,x=correl.columns,y=correl.columns,colorscale=px.colors.diverging.RdBu)\n\n","1efd711a":"fig=go.Figure(data=[corr_map])\nfig.show()","eb96202d":"#From the graph, we can see that hyperactivaty and valence are very closely correlated, So I am removing Hyperactivity.KLet's check once again\n\nfig = px.histogram(X,x=\"Hyperactivity\")\nfig.show()","32f860ff":"fig = px.histogram(X,x=\"valence\")\nfig.show()","4a615237":"X = X.drop(labels=[\"valence\",\"mode\",\"key\"],axis=1)","edddacf1":"X.head()","339c6aa4":"from sklearn.model_selection import train_test_split\n\nX_train,X_val, y_train, y_val = train_test_split(X,y,test_size=0.33, random_state=42)","fe8c49a6":"import xgboost as xgb\n\nxgb_model = xgb.XGBClassifier(objective=\"multi:softprob\",random_state=42)\nxgb_model.fit(X_train,y_train)","b76821aa":"y_pred = xgb_model.predict(X_val)\nfrom sklearn.metrics import confusion_matrix,accuracy_score\n\nprint(confusion_matrix(y_pred,y_val))","d19b82bc":"accuracy_score(y_pred,y_val)","d7440057":"!pip install optuna","ebf8f523":"# import optuna\n\n# from sklearn.preprocessing import StandardScaler\n# from sklearn.pipeline import Pipeline\n\n# def score_dataset(X_train, y_train, X_val, y_val, xgb_model):\n#     model = xgb_model\n#     my_pipeline = Pipeline(steps=[('scale',StandardScaler()),\n#                               ('model', model)\n#                              ])\n#     my_pipeline.fit(X_train, y_train)\n#     preds = my_pipeline.predict(X_val)\n#     score = accuracy_score(y_val, preds)\n#     return score\n\n\n\n# def objective(trial):\n#     xgb_params = dict(\n#         max_depth=trial.suggest_int(\"max_depth\", 2, 10),\n#         learning_rate=trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True),\n#         n_estimators=trial.suggest_int(\"n_estimators\", 10, 2000),\n#         min_child_weight=trial.suggest_int(\"min_child_weight\", 1, 10),\n#         colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n#         subsample=trial.suggest_float(\"subsample\", 0.2, 1.0),\n#         reg_alpha=trial.suggest_float(\"reg_alpha\", 1e-4, 1e2, log=True),\n#         reg_lambda=trial.suggest_float(\"reg_lambda\", 1e-4, 1e2, log=True),\n#     )\n#     xgb_model = xgb.XGBClassifier(**xgb_params)\n#     return score_dataset(X_train, y_train, X_val, y_val, xgb_model)\n\n# study = optuna.create_study(direction=\"maximize\")\n# study.optimize(objective, n_trials=15)\n# xgb_params = study.best_params\n","627562a3":"xgb_params","2a2163d5":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n#Saving state of final params\nxgb_params = {'max_depth': 8,\n 'learning_rate': 0.0025402642751198175,\n 'n_estimators': 1906,\n 'min_child_weight': 1,\n 'colsample_bytree': 0.7517645868254619,\n 'subsample': 0.7528644089365699,\n 'reg_alpha': 0.0021115571147040275,\n 'reg_lambda': 1.0511255276800122}","0b15cd9e":"model = xgb.XGBClassifier(**xgb_params)\nmy_pipeline = Pipeline(steps=[('scale',StandardScaler()),\n                              ('model', model)\n                             ])\nmy_pipeline.fit(X_train, y_train)","13f22669":"y_pred = my_pipeline.predict(X_val)\n\n","9aa07d09":"accuracy_score(y_pred,y_val)","cb7e3433":"test = pd.read_csv(\"test_x.csv\")","3145c224":"test.head()","a3dad60e":"#drop type first\ntest = test.drop(labels=[\"type\"],axis=1)\n#Change title Nan label\ntest[\"title\"] = test[\"title\"].fillna(\"Other\")\n#categorise title\ntest[\"title\"] = le_titles.transform(test.title)\n#convert time to seconds\ntest[\"TimeLength\"] = test[\"TimeLength\"]\/(60*100)\n# Drop valence due to heavily correlated\ntest = test.drop(labels=[\"valence\",\"mode\",\"key\"],axis=1)\n#","326eb8bc":"print(pd.DataFrame(test).isna().sum())","a95541f1":"\n##Check for na and replace if na there \ntest['Rhythm'].fillna(test['Rhythm'].mean(),inplace=True)\ntest['vibrance'].fillna(test['vibrance'].mean(),inplace=True)\ntest['acoustics'].fillna(test['acoustics'].mean(),inplace=True)\ntest['Beats_Speed'].fillna(test['Beats_Speed'].mean(),inplace=True)","1ae3cce8":"#Check for Null again\nprint(pd.DataFrame(test).isna().sum())","941160e8":"test.head()","0b9169ee":"#Remove the Usage column and take out the id column\ntest = test.drop(labels=[\"Usage\"],axis=1)\n","9ee89d4c":"test.head()","96b5bbce":"test.iloc[:,1:-1]","eff139f0":"test_id = test.iloc[:,0]\ntest_X = test.iloc[:,1:]","92879ba9":"X_val.columns","4c05e981":"test_X.columns","864b071f":"test_pred = my_pipeline.predict(test_X)","77ab0487":"test_pred","ac014ee8":"genre_labels = labels.inverse_transform(test_pred)","1e131124":"test_id.values","34b4c24e":"test_submission = pd.DataFrame(data={\"id\":test_id.values,\"genre\": genre_labels})","e4069722":"test_submission.head()","c5c37602":"test_submission.to_csv(\"submission.csv\",index=False)","faca595e":"Since audio features has one value, it has like no use to the dataset","7328817f":"###Features of X\n\n**Rhythm** : This describes the tune of the music and its danceability. (float)\n\n**Vibrance** : This field refers to how energetic the music is. (float)\n\n**Key** : The key of a music is the group of pitches, or scale, that forms the basis of a music composition in classical, Western art, and Western pop music. (int)\n\n**Decibel_Levels** : This field indicates how loud the music is. For instance metal trap may be louder as compared  to trance. (float)\n\n**Mode** : Mode is used as a type of musical scale on the basis of a set of characteristic melodic and harmonic behaviours of the music. (numerical)\n\n**Lyrics_amount** : This field determines how much part of the music consists of the lyrics as compared to its pure instrumental track. Rap music may have a higher lyric_amount than Drums & Bass. (float)\n\n**Acoustics** : Acoustic music solely or primarily uses instruments that produce sound through acoustic means, as opposed to electric or electronic means. Eg: \u00a0string instruments, wind instruments, percussion, other instruments. This field describes how much part of the music involves acoustic instruments. (float)\n\n**Instruments** : This field is the opposite of Lyrics_amount and helps us understand how much part of the music involves instrumental tracks. (float)\n\n**Bounce** : This describes how lively the music is. (float)\n\n**Valence** : A measure\u00a0from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry). (float)\n\n**Beats_Speed** : Tempo describes\u00a0the tempo at which a piece of music should be played.\u00a0(float)\n\n**TimeLength** : The duration of the music measured in milliseconds (double)\n\n\n**Title** : Title classifies the song briefly into a subcategory. Please note that this is quite different as compared to the \u201cGenres\u201d attribute which is to be predicted. (Removed) \n\n**Hyperactivity** : This can be understood as a combination of \u201cBeats_speed\u201d and \u201cvalence\u201d (float)\n\n**MusicEraRating** : Based on the rating of the music provided by audiences of different generations.  (int)\n"}}