{"cell_type":{"c5d156d6":"code","b4be7589":"code","3828eca6":"code","56b8e93a":"code","20ad65f5":"code","bdd61ffa":"code","757ad1be":"code","63927a6c":"code","21a5bf87":"code","bde6676a":"code","009974ac":"code","dbbdd989":"code","b7ce5303":"markdown","71706890":"markdown","004ae124":"markdown","bc684ad1":"markdown","35535a03":"markdown","2cb47a65":"markdown","1e4bcb98":"markdown","a7c96811":"markdown","e81bbf35":"markdown","2f8b1a5a":"markdown","4ba01395":"markdown","263b0c0f":"markdown","e2951144":"markdown"},"source":{"c5d156d6":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","b4be7589":"import pandas as pd","3828eca6":"daily_df = pd.read_csv(\"\/kaggle\/input\/euro-exchange-rates\/ert_bil_eur_d.tsv\", sep='\\t')","56b8e93a":"print(f\"Data columns: {len(list(daily_df.columns))}\")\nprint(f\"Data columns (first 10): {list(daily_df.columns)[0:10]}\")\nprint(f\"Data columns (last 10): {list(daily_df.columns)[-10:]}\")","20ad65f5":"pivot_data_col = daily_df.columns[0]\ntime_columns = daily_df.columns[1:]","bdd61ffa":"daily_df['statinfo'] = daily_df[pivot_data_col].apply(lambda x: x.split(\",\")[0])\ndaily_df['unit']     = daily_df[pivot_data_col].apply(lambda x: x.split(\",\")[1])\ndaily_df['currency'] = daily_df[pivot_data_col].apply(lambda x: x.split(\",\")[2])","757ad1be":"selected_columns = list(['statinfo', 'unit', 'currency']) +  list(time_columns)\ndaily_df = daily_df[selected_columns]","63927a6c":"daily_tr_df = daily_df.melt(id_vars=['statinfo', 'unit', 'currency'], \n        var_name=\"date\", \n        value_name=\"value\")\ndaily_tr_df['value'] = daily_tr_df['value'].apply(lambda x: str(x).replace(\": \", \"NAN\"))\ndaily_tr_df['value'] = daily_tr_df['value'].apply(lambda x: str(x).replace(\"z\", \"\"))\ndaily_tr_df['value'] = daily_tr_df['value'].apply(lambda x: float(x))","21a5bf87":"from datetime import datetime\ndef strip_date(date_string, test=False):\n    year, month, day = int(date_string[0:4]), int(date_string[5:7]), int(date_string[8:10])\n    if test:\n        print(f\"From: {date_string} -> Year: {year}, Month: {month}, Day: {day}\")\n    try:\n        d = datetime(year, month, day)\n        return d\n    except Exception as ex:\n        print(\"Error, wrong data: \", year, month, day)\n        return None\n    \n\nprint(f\"Tests:\") \nstrip_date('2021M06D25 ', test=True)\nstrip_date('2019M13D03 ', test=True)\nstrip_date('1971M01D16 ', test=True)\n\nprint(f\"\\nFull data processing...\\n\")\ndaily_tr_df['date'] = daily_tr_df['date'].apply(lambda x: strip_date(x))\nprint(\"done.\")","bde6676a":"print(f\"Transformed data shape: {daily_tr_df.shape} (rows\/columns)\")\ndaily_tr_df.head()","009974ac":"daily_tr_df.tail()","dbbdd989":"import pandas_profiling\npandas_profiling.ProfileReport(daily_tr_df)","b7ce5303":"# Introduction\n\nWe show in this Kernel how we can process the **daily data** to prepare it for easier processing. \n\n**Note**: This data is changing frequently. Due to the fact that for each day we have an additional column, being able to dynamically process these data is important. This Kernel will show you how to pivot automatically the time column data, without hardcoding the columns names.\n\nLet's start by checking the data files.","71706890":"Let's glimpse the data columns.","004ae124":"Then, we split from `pivot_data_col` the 3 separate fields:\n* statinfo (AVG\/END);\n* unit (NAC only);\n* currency (this would be each currency for which we provide the Euro conversion).","bc684ad1":"We then transform `date` to an actual date.","35535a03":"We have daily, monthly, quartery and annual data. We will select the daily data and demonstrate how to prepare this data for further easy analysis.","2cb47a65":"Next, we pivot the time columns using `melt` operation in pandas.  \nWe set `value` to be a float, after we replace \": \" (for N\/A) with `NAN`.","1e4bcb98":"# Data pre-processing\n\nWe start by defining two working lists.","a7c96811":"The first column is a composed one, containing 3 different information (the type of statistical info, the unit and the currency).  \nThe next columns are the year\/month\/day values, from last (current year\/month\/day) to first (first year\/month\/day).","e81bbf35":"# A very preliminary exploratory data analysis\n\nThis would be a very short exploratory data analysis. The role of this Kernel is just to show how we can prepare the daily data for analysis and we already did this.\n\nWe are using Pandas profiling package for automatic EDA.","2f8b1a5a":"Let's inspect the result.","4ba01395":"## Load the data\n\nThe datafiles are in TSV format. We will read the files using pandas, just include in the function call the `sep` (tab separator data).\nWe demonstrate first how to read and process the Daily data.","263b0c0f":"# Analysis preparation\n\n## Load packages","e2951144":"We select now only the new columns resulted from splitting the `pivot_data_col` and the time columns."}}