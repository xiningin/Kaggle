{"cell_type":{"4e438b1c":"code","e3e8bbea":"code","c34e31ba":"code","e70ec175":"code","842bc851":"code","2d5e3dc9":"code","9d9f68a9":"code","ecaa6fdb":"code","d0bc4082":"code","e644d541":"code","a10e9d77":"code","b713501a":"code","a812d2ae":"code","8fab8f89":"code","4fb05bbd":"code","36c458b7":"code","00645114":"code","9ade0915":"code","da39ba03":"code","dab0bf35":"code","a429e77d":"code","37ba349d":"code","5d2b878d":"code","2aebe1aa":"code","0ca93df4":"code","43f3d7ed":"code","8bc7d6c1":"code","a8e1e7e6":"code","efeea524":"code","42a57205":"code","e1ba8917":"code","4b29fddd":"code","8ae2ea4f":"code","875f7a4f":"code","1615be6c":"code","e0e0ffb5":"code","94673be6":"code","a52a55cd":"code","2c94639c":"code","47810e10":"code","e9163ede":"code","c299d56f":"code","b2e9d2b0":"code","bff52d73":"code","9b372c66":"code","03bce839":"code","63a2c182":"code","1eacfe2b":"code","7830a15f":"code","f4ba5551":"code","b2fa6eba":"code","ce5e6f81":"code","eb62fa03":"code","3aaacc6f":"code","65affe70":"code","4f62d656":"code","60cabd89":"code","d7119cfc":"code","add46028":"code","0552d36a":"code","102a109e":"code","a44b4847":"code","74c4655e":"code","232a2ad6":"code","ebcc68bf":"code","4c3b69b7":"code","39018bb5":"code","7f21e17d":"code","8feaf8c4":"code","f153b031":"code","abdd8fac":"code","53621152":"code","ebbcbeff":"code","b7677679":"code","481db7d0":"code","245ce879":"code","1e2c15e4":"code","ddaf30ee":"code","ac329352":"code","72229a4e":"code","4a55f349":"code","6e78ea09":"code","7bc29681":"code","9b481e01":"code","e7759992":"code","51000a67":"code","73374a1a":"code","1970b2a5":"code","e0bfed22":"code","5873eef0":"code","24c94787":"code","d001e98d":"markdown","b0d58c6c":"markdown","1f48dd65":"markdown","8a4e3ab5":"markdown","6936be28":"markdown","50d03cad":"markdown","466eb82b":"markdown","b6d938f9":"markdown","6809d622":"markdown","bb479651":"markdown","17651995":"markdown","82aa8453":"markdown","de0cef35":"markdown","002b8884":"markdown","10c39ff5":"markdown","d84c9fe2":"markdown","bfab62f7":"markdown","c7067bc8":"markdown","02af9bd8":"markdown","e48e8bf6":"markdown","0c2882a6":"markdown","cd501025":"markdown","1a0dc7e5":"markdown","759fee6c":"markdown","4c9e2125":"markdown","b49464da":"markdown","7de4673e":"markdown","38507736":"markdown","c9a7dd01":"markdown","4780b4dc":"markdown","03f8baef":"markdown","ef81783b":"markdown","5cf4185c":"markdown","d2fef182":"markdown","42c348de":"markdown","9e886206":"markdown","764dbbea":"markdown","694daa29":"markdown","1e9334fa":"markdown","73a3929b":"markdown","d45d08cf":"markdown","4b31445e":"markdown","8ada1029":"markdown","a9cce881":"markdown","66b6a734":"markdown","4dcabb46":"markdown","dd862a6f":"markdown","31db3291":"markdown","b4f24351":"markdown","2703a9f3":"markdown","bbb12d8d":"markdown","97d55965":"markdown","a287ce8f":"markdown","92cdd853":"markdown","f22d8284":"markdown","01e742f6":"markdown"},"source":{"4e438b1c":"#from functions import *\n#from labels import *\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, roc_curve, precision_recall_curve, f1_score, roc_auc_score, mean_squared_error\nimport tensorflow as tf\nfrom tensorflow.python.client import device_lib\nimport keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, MaxPool2D, BatchNormalization\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.datasets import cifar100","e3e8bbea":"def plot_model(model): \n    \n    fig, axs = plt.subplots(1,2,figsize=(15,5)) \n    \n    axs[0].plot(model.history['accuracy']) \n    axs[0].plot(model.history['val_accuracy']) \n    axs[0].set_title('Model Accuracy')\n    axs[0].set_ylabel('Accuracy') \n    axs[0].set_xlabel('Epoch')\n    axs[0].legend(['train', 'validate'], loc='upper left')\n    \n    axs[1].plot(model.history['loss']) \n    axs[1].plot(model.history['val_loss']) \n    axs[1].set_title('Model Loss')\n    axs[1].set_ylabel('Loss') \n    axs[1].set_xlabel('Epoch')\n    axs[1].legend(['train', 'validate'], loc='upper left')\n    \n    plt.show()","c34e31ba":"def heatmap(data, row_labels, col_labels, ax=None, cbar_kw={}, cbarlabel=\"\", **kwargs):\n    \"\"\"\n    Create a heatmap from a numpy array and two lists of labels.\n    \"\"\"\n    if not ax:\n        ax = plt.gca()\n\n    im = ax.imshow(data, **kwargs)\n\n    cbar = ax.figure.colorbar(im, ax=ax, **cbar_kw)\n    cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n\n    ax.tick_params(top=True, bottom=False, labeltop=True, labelbottom=False)\n\n    ax.set_xticks(np.arange(data.shape[1]))\n    ax.set_yticks(np.arange(data.shape[0]))\n\n    ax.set_xticklabels(col_labels)\n    ax.set_yticklabels(row_labels)\n    \n    ax.set_xlabel('Predicted Label') \n    ax.set_ylabel('True Label')\n    \n    return im, cbar\n\ndef annotate_heatmap(im, data=None, fmt=\"d\", threshold=None):\n\n    texts = []\n    for i in range(data.shape[0]):\n        for j in range(data.shape[1]):\n            text = im.axes.text(j, i, format(data[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if data[i, j] > thresh else \"black\")\n            texts.append(text)\n\n    return texts","e70ec175":"tf.__version__","842bc851":"keras.__version__","2d5e3dc9":"print(device_lib.list_local_devices())","9d9f68a9":"print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))","ecaa6fdb":"# The data, shuffled and split between train and test sets:\n(X_train, y_train), (X_test, y_test) = cifar100.load_data()","d0bc4082":"X_train.shape","e644d541":"y_train.shape","a10e9d77":"labels_dictionary = {0: 'apple',\n 1: 'aquarium_fish',\n 2: 'baby',\n 3: 'bear',\n 4: 'beaver',\n 5: 'bed',\n 6: 'bee',\n 7: 'beetle',\n 8: 'bicycle',\n 9: 'bottle',\n 10: 'bowl',\n 11: 'boy',\n 12: 'bridge',\n 13: 'bus',\n 14: 'butterfly',\n 15: 'camel',\n 16: 'can',\n 17: 'castle',\n 18: 'caterpillar',\n 19: 'cattle',\n 20: 'chair',\n 21: 'chimpanzee',\n 22: 'clock',\n 23: 'cloud',\n 24: 'cockroach',\n 25: 'couch',\n 26: 'crab',\n 27: 'crocodile',\n 28: 'cup',\n 29: 'dinosaur',\n 30: 'dolphin',\n 31: 'elephant',\n 32: 'flatfish',\n 33: 'forest',\n 34: 'fox',\n 35: 'girl',\n 36: 'hamster',\n 37: 'house',\n 38: 'kangaroo',\n 39: 'computer_keyboard',\n 40: 'lamp',\n 41: 'lawn_mower',\n 42: 'leopard',\n 43: 'lion',\n 44: 'lizard',\n 45: 'lobster',\n 46: 'man',\n 47: 'maple_tree',\n 48: 'motorcycle',\n 49: 'mountain',\n 50: 'mouse',\n 51: 'mushroom',\n 52: 'oak_tree',\n 53: 'orange',\n 54: 'orchid',\n 55: 'otter',\n 56: 'palm_tree',\n 57: 'pear',\n 58: 'pickup_truck',\n 59: 'pine_tree',\n 60: 'plain',\n 61: 'plate',\n 62: 'poppy',\n 63: 'porcupine',\n 64: 'possum',\n 65: 'rabbit',\n 66: 'raccoon',\n 67: 'ray',\n 68: 'road',\n 69: 'rocket',\n 70: 'rose',\n 71: 'sea',\n 72: 'seal',\n 73: 'shark',\n 74: 'shrew',\n 75: 'skunk',\n 76: 'skyscraper',\n 77: 'snail',\n 78: 'snake',\n 79: 'spider',\n 80: 'squirrel',\n 81: 'streetcar',\n 82: 'sunflower',\n 83: 'sweet_pepper',\n 84: 'table',\n 85: 'tank',\n 86: 'telephone',\n 87: 'television',\n 88: 'tiger',\n 89: 'tractor',\n 90: 'train',\n 91: 'trout',\n 92: 'tulip',\n 93: 'turtle',\n 94: 'wardrobe',\n 95: 'whale',\n 96: 'willow_tree',\n 97: 'wolf',\n 98: 'woman',\n 99: 'worm'}","b713501a":"labels_dictionary[0]","a812d2ae":"labels_dictionary = pd.DataFrame.from_dict(labels_dictionary, orient=\"index\")\nlabels_dictionary","8fab8f89":"X_train.shape","4fb05bbd":"X_train[0].shape","36c458b7":"plt.imshow(X_train[0])","00645114":"X_train[-1].shape","9ade0915":"plt.imshow(X_train[-1])","da39ba03":"images_to_show = []\nfor i, image in enumerate(X_train):\n    if (i + 1) % 1000 == 0:\n        images_to_show.append(i)","dab0bf35":"plt.figure(figsize=(30,15))\ncolumns = 5\nfor i, image in enumerate(X_train[images_to_show]):\n    plt.subplot(len(images_to_show) \/ columns + 1, columns, i + 1)\n    plt.imshow(image)","a429e77d":"labels_to_concat = []\nfor i in range(len(y_train)):\n    if (i + 1) % 1000 == 0:\n        #print(y_train[i])\n        labels_to_concat.append(y_train[i])","37ba349d":"labels_to_concat = pd.DataFrame(labels_to_concat, columns=[\"idx\"])\nlabels_to_concat = labels_to_concat.set_index(\"idx\")","5d2b878d":"pd.concat([labels_to_concat, labels_dictionary], axis=1, join=\"inner\")","2aebe1aa":"X_test.shape","0ca93df4":"X_test[0].shape","43f3d7ed":"plt.imshow(X_test[0])","8bc7d6c1":"X_test[-1].shape","a8e1e7e6":"plt.imshow(X_test[-1])","efeea524":"images_to_show = []\nfor i, image in enumerate(X_test):\n    if (i + 1) % 1000 == 0:\n        images_to_show.append(i)","42a57205":"plt.figure(figsize=(30,15))\ncolumns = 5\nfor i, image in enumerate(X_test[images_to_show]):\n    plt.subplot(len(images_to_show) \/ columns + 1, columns, i + 1)\n    plt.imshow(image)","e1ba8917":"labels_to_concat = []\nfor i in range(len(y_test)):\n    if (i + 1) % 1000 == 0:\n        #print(y_train[i])\n        labels_to_concat.append(y_test[i])","4b29fddd":"labels_to_concat = pd.DataFrame(labels_to_concat, columns=[\"idx\"])\nlabels_to_concat = labels_to_concat.set_index(\"idx\")","8ae2ea4f":"pd.concat([labels_to_concat, labels_dictionary], axis=1, join=\"inner\")","875f7a4f":"num_classes = 100\n\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)","1615be6c":"y_train[0]","e0e0ffb5":"X_train.max()","94673be6":"X_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\nX_train \/= 255\nX_test \/= 255","a52a55cd":"model1 = Sequential()\n\nmodel1.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\nmodel1.add(BatchNormalization())\nmodel1.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel1.add(BatchNormalization())\n# model1.add(MaxPool2D((2, 2)))\nmodel1.add(Dropout(0.1))\n\nmodel1.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel1.add(BatchNormalization())\nmodel1.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel1.add(BatchNormalization())\n# model1.add(MaxPool2D((2, 2)))\nmodel1.add(Dropout(0.2))\n\nmodel1.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel1.add(BatchNormalization())\nmodel1.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel1.add(BatchNormalization())\n# model1.add(MaxPool2D((2, 2)))\nmodel1.add(Dropout(0.3))\n\nmodel1.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel1.add(BatchNormalization())\nmodel1.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel1.add(BatchNormalization())\n# model1.add(MaxPool2D((2, 2)))\nmodel1.add(Dropout(0.4))\n\nmodel1.add(Flatten())\nmodel1.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\nmodel1.add(BatchNormalization())\nmodel1.add(Dropout(0.5))\nmodel1.add(Dense(100, activation='softmax'))","2c94639c":"model1.summary()","47810e10":"batch_size = 30\nepochs=2000","e9163ede":"optimizer_1 = keras.optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name=\"Nadam\")","c299d56f":"model1.compile(loss=\"categorical_crossentropy\", optimizer=optimizer_1, metrics=[\"accuracy\"])","b2e9d2b0":"es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\nmc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)","bff52d73":"model1history = model1.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test), shuffle=True, verbose=1, callbacks=[es, mc])","9b372c66":"accuracy_score(np.argmax(y_test, axis=1), model1.predict_classes(X_test))","03bce839":"plot_model(model1history)","63a2c182":"labels = labels_dictionary[0]\nlabels","1eacfe2b":"pred = model1.predict(X_test)","7830a15f":"y_pred_classes = np.argmax(pred, axis=1)\ny_true = np.argmax(y_test, axis=1)\nerrors = (y_pred_classes - y_true != 0)\n\ny_pred_classes_errors = y_pred_classes[errors]\ny_pred_errors = pred[errors]\ny_true_errors = y_true[errors]\nX_test_errors = X_test[errors]\n\ncm = confusion_matrix(y_true, y_pred_classes) \nthresh = cm.max() \/ 2.\n\nfig, ax = plt.subplots(figsize=(32,32))\nim, cbar = heatmap(cm, labels, labels, ax=ax, cmap=plt.cm.Blues, cbarlabel=\"count of predictions\")\ntexts = annotate_heatmap(im, data=cm, threshold=thresh)\n\nfig.tight_layout()\nplt.show()","f4ba5551":"print(classification_report(y_true, y_pred_classes))","b2fa6eba":"labels = labels_dictionary[0]\nlabels","ce5e6f81":"row = 5\ncolumn = 5\nfig, axes = plt.subplots(row, column, figsize=(22,12))\naxes = axes.ravel()\n\nclassified_idx = np.where(y_pred_classes == y_true)[0]\nfor i in np.arange(0, row*column):\n    axes[i].imshow(X_test[classified_idx[i]])\n    axes[i].set_title(\"True: %s \\nPredicted: %s\" % (labels[y_true[classified_idx[i]]], \n                                                  labels[y_pred_classes[classified_idx[i]]]))\n    axes[i].axis('off')\n    plt.subplots_adjust(wspace=1)","eb62fa03":"row = 5\ncolumn = 5\nfig, axes = plt.subplots(row, column, figsize=(22,12))\naxes = axes.ravel()\n\nmisclassified_idx = np.where(y_pred_classes != y_true)[0]\nfor i in np.arange(0, row*column):\n    axes[i].imshow(X_test[misclassified_idx[i]])\n    axes[i].set_title(\"True: %s \\nPredicted: %s\" % (labels[y_true[misclassified_idx[i]]], \n                                                  labels[y_pred_classes[misclassified_idx[i]]]))\n    axes[i].axis('off')\n    plt.subplots_adjust(wspace=1)","3aaacc6f":"model2 = Sequential()\n\nmodel2.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\nmodel2.add(BatchNormalization())\nmodel2.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel2.add(BatchNormalization())\nmodel2.add(MaxPool2D((2, 2)))\nmodel2.add(Dropout(0.1))\n\nmodel2.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel2.add(BatchNormalization())\nmodel2.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel2.add(BatchNormalization())\nmodel2.add(MaxPool2D((2, 2)))\nmodel2.add(Dropout(0.2))\n\nmodel2.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel2.add(BatchNormalization())\nmodel2.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel2.add(BatchNormalization())\nmodel2.add(MaxPool2D((2, 2)))\nmodel2.add(Dropout(0.3))\n\nmodel2.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel2.add(BatchNormalization())\nmodel2.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel2.add(BatchNormalization())\nmodel2.add(MaxPool2D((2, 2)))\nmodel2.add(Dropout(0.4))\n\nmodel2.add(Flatten())\nmodel2.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\nmodel2.add(BatchNormalization())\nmodel2.add(Dropout(0.5))\nmodel2.add(Dense(100, activation='softmax'))","65affe70":"model2.summary()","4f62d656":"batch_size = 30\nepochs=2000","60cabd89":"optimizer_2 = keras.optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name=\"Nadam\")","d7119cfc":"model2.compile(loss=\"categorical_crossentropy\", optimizer=optimizer_2, metrics=[\"accuracy\"])","add46028":"es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\nmc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)","0552d36a":"model2history = model2.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test), shuffle=True, verbose=1, callbacks=[es, mc])","102a109e":"accuracy_score(np.argmax(y_test, axis=1), model2.predict_classes(X_test))","a44b4847":"plot_model(model2history)","74c4655e":"labels = labels_dictionary[0]\nlabels","232a2ad6":"pred = model2.predict(X_test)","ebcc68bf":"#labels = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n\n# Convert predictions classes to one hot vectors \ny_pred_classes = np.argmax(pred, axis=1) \n# Convert validation observations to one hot vectors\ny_true = np.argmax(y_test, axis=1)\n# Errors are difference between predicted labels and true labels\nerrors = (y_pred_classes - y_true != 0)\n\ny_pred_classes_errors = y_pred_classes[errors]\ny_pred_errors = pred[errors]\ny_true_errors = y_true[errors]\nX_test_errors = X_test[errors]\n\ncm = confusion_matrix(y_true, y_pred_classes) \nthresh = cm.max() \/ 2.\n\nfig, ax = plt.subplots(figsize=(32,32))\nim, cbar = heatmap(cm, labels, labels, ax=ax,\n                   cmap=plt.cm.Blues, cbarlabel=\"count of predictions\")\ntexts = annotate_heatmap(im, data=cm, threshold=thresh)\n\nfig.tight_layout()\nplt.show()","4c3b69b7":"labels = labels_dictionary[0]\nlabels","39018bb5":"print(classification_report(y_true, y_pred_classes))","7f21e17d":"labels = labels_dictionary[0]\nlabels","8feaf8c4":"row = 5\ncolumn = 5\nfig, axes = plt.subplots(row, column, figsize=(22,12))\naxes = axes.ravel()\n\nclassified_idx = np.where(y_pred_classes == y_true)[0]\nfor i in np.arange(0, row*column):\n    axes[i].imshow(X_test[classified_idx[i]])\n    axes[i].set_title(\"True: %s \\nPredicted: %s\" % (labels[y_true[classified_idx[i]]], \n                                                  labels[y_pred_classes[classified_idx[i]]]))\n    axes[i].axis('off')\n    plt.subplots_adjust(wspace=1)","f153b031":"row = 5\ncolumn = 5\nfig, axes = plt.subplots(row, column, figsize=(22,12))\naxes = axes.ravel()\n\nmisclassified_idx = np.where(y_pred_classes != y_true)[0]\nfor i in np.arange(0, row*column):\n    axes[i].imshow(X_test[misclassified_idx[i]])\n    axes[i].set_title(\"True: %s \\nPredicted: %s\" % (labels[y_true[misclassified_idx[i]]], \n                                                  labels[y_pred_classes[misclassified_idx[i]]]))\n    axes[i].axis('off')\n    plt.subplots_adjust(wspace=1)","abdd8fac":"model3 = Sequential()\n\nmodel3.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\nmodel3.add(BatchNormalization())\nmodel3.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel3.add(BatchNormalization())\n# model3.add(MaxPool2D((2, 2)))\nmodel3.add(Dropout(0.1))\n\nmodel3.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel3.add(BatchNormalization())\nmodel3.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel3.add(BatchNormalization())\n# model3.add(MaxPool2D((2, 2)))\nmodel3.add(Dropout(0.2))\n\nmodel3.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel3.add(BatchNormalization())\nmodel3.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel3.add(BatchNormalization())\n# model3.add(MaxPool2D((2, 2)))\nmodel3.add(Dropout(0.3))\n\nmodel3.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel3.add(BatchNormalization())\nmodel3.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel3.add(BatchNormalization())\n# model3.add(MaxPool2D((2, 2)))\nmodel3.add(Dropout(0.4))\n\nmodel3.add(Flatten())\nmodel3.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\nmodel3.add(BatchNormalization())\nmodel3.add(Dropout(0.5))\nmodel3.add(Dense(100, activation='softmax'))","53621152":"# Image Data Generator , we are shifting image accross width and height also we are flipping the image horizantally.\ndatagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True,rotation_range=10)\nit_train = datagen.flow(X_train, y_train)\nsteps = int(X_train.shape[0] \/ 64)","ebbcbeff":"batch_size = 30\nepochs=2000","b7677679":"optimizer_2 = keras.optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name=\"Nadam\")","481db7d0":"model3.compile(loss=\"categorical_crossentropy\", optimizer=optimizer_2, metrics=[\"accuracy\"])","245ce879":"es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\nmc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)","1e2c15e4":"model3history = model3.fit_generator(it_train, epochs=epochs, steps_per_epoch=steps, validation_data=(X_test,y_test), shuffle=True, verbose=1, callbacks=[es, mc])","ddaf30ee":"plot_model(model3history)","ac329352":"labels = labels_dictionary[0]\nlabels","72229a4e":"pred = model3.predict(X_test)","4a55f349":"#labels = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n\n# Convert predictions classes to one hot vectors \ny_pred_classes = np.argmax(pred, axis=1) \n# Convert validation observations to one hot vectors\ny_true = np.argmax(y_test, axis=1)\n# Errors are difference between predicted labels and true labels\nerrors = (y_pred_classes - y_true != 0)\n\ny_pred_classes_errors = y_pred_classes[errors]\ny_pred_errors = pred[errors]\ny_true_errors = y_true[errors]\nX_test_errors = X_test[errors]\n\ncm = confusion_matrix(y_true, y_pred_classes) \nthresh = cm.max() \/ 2.\n\nfig, ax = plt.subplots(figsize=(32,32))\nim, cbar = heatmap(cm, labels, labels, ax=ax,\n                   cmap=plt.cm.Blues, cbarlabel=\"count of predictions\")\ntexts = annotate_heatmap(im, data=cm, threshold=thresh)\n\nfig.tight_layout()\nplt.show()","6e78ea09":"labels = labels_dictionary[0]\nlabels","7bc29681":"print(classification_report(y_true, y_pred_classes))","9b481e01":"labels = labels_dictionary[0]\nlabels","e7759992":"row = 5\ncolumn = 5\nfig, axes = plt.subplots(row, column, figsize=(22,12))\naxes = axes.ravel()\n\nclassified_idx = np.where(y_pred_classes == y_true)[0]\nfor i in np.arange(0, row*column):\n    axes[i].imshow(X_test[classified_idx[i]])\n    axes[i].set_title(\"True: %s \\nPredicted: %s\" % (labels[y_true[classified_idx[i]]], \n                                                  labels[y_pred_classes[classified_idx[i]]]))\n    axes[i].axis('off')\n    plt.subplots_adjust(wspace=1)","51000a67":"row = 5\ncolumn = 5\nfig, axes = plt.subplots(row, column, figsize=(22,12))\naxes = axes.ravel()\n\nmisclassified_idx = np.where(y_pred_classes != y_true)[0]\nfor i in np.arange(0, row*column):\n    axes[i].imshow(X_test[misclassified_idx[i]])\n    axes[i].set_title(\"True: %s \\nPredicted: %s\" % (labels[y_true[misclassified_idx[i]]], \n                                                  labels[y_pred_classes[misclassified_idx[i]]]))\n    axes[i].axis('off')\n    plt.subplots_adjust(wspace=1)","73374a1a":"images_to_show = []\nfor i, image in enumerate(X_train):\n    if (i + 1) % 1000 == 0:\n        images_to_show.append(i)","1970b2a5":"plt.figure(figsize=(30,15))\ncolumns = 5\nfor i, image in enumerate(X_train[images_to_show]):\n    plt.subplot(len(images_to_show) \/ columns + 1, columns, i + 1)\n    plt.imshow(image)","e0bfed22":"#labels = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n\n# Convert predictions classes to one hot vectors \ny_pred_classes = np.argmax(pred, axis=1) \n# Convert validation observations to one hot vectors\ny_true = np.argmax(y_test, axis=1)\n# Errors are difference between predicted labels and true labels\nerrors = (y_pred_classes - y_true != 0)\n\ny_pred_classes_errors = y_pred_classes[errors]\ny_pred_errors = pred[errors]\ny_true_errors = y_true[errors]\nX_test_errors = X_test[errors]\n\ncm = confusion_matrix(y_true, y_pred_classes) \nthresh = cm.max() \/ 2.\n\nfig, ax = plt.subplots(figsize=(32,32))\nim, cbar = heatmap(cm, labels, labels, ax=ax,\n                   cmap=plt.cm.Blues, cbarlabel=\"count of predictions\")\ntexts = annotate_heatmap(im, data=cm, threshold=thresh)\n\nfig.tight_layout()\nplt.show()","5873eef0":"row = 5\ncolumn = 5\nfig, axes = plt.subplots(row, column, figsize=(22,12))\naxes = axes.ravel()\n\nclassified_idx = np.where(y_pred_classes == y_true)[0]\nfor i in np.arange(0, row*column):\n    axes[i].imshow(X_test[classified_idx[i]])\n    axes[i].set_title(\"True: %s \\nPredicted: %s\" % (labels[y_true[classified_idx[i]]], \n                                                  labels[y_pred_classes[classified_idx[i]]]))\n    axes[i].axis('off')\n    plt.subplots_adjust(wspace=1)","24c94787":"row = 5\ncolumn = 5\nfig, axes = plt.subplots(row, column, figsize=(22,12))\naxes = axes.ravel()\n\nmisclassified_idx = np.where(y_pred_classes != y_true)[0]\nfor i in np.arange(0, row*column):\n    axes[i].imshow(X_test[misclassified_idx[i]])\n    axes[i].set_title(\"True: %s \\nPredicted: %s\" % (labels[y_true[misclassified_idx[i]]], \n                                                  labels[y_pred_classes[misclassified_idx[i]]]))\n    axes[i].axis('off')\n    plt.subplots_adjust(wspace=1)","d001e98d":"# 3. Test set","b0d58c6c":"### Classification report","1f48dd65":"### Correct classifications","8a4e3ab5":"* There is still a space for more experiments and exploration with available Image Augmentation methods.  \n* Moving from Keras which is indeed high level library to more sophisticated one like TensorFlow might prove beneficial as well.","6936be28":"### Last image","50d03cad":"All train models were trained on more-less similar initial architecture. Nonetheless they were slightly diffrent in few aspects.  \n* Model 1 was trained without Pooling.\n   - in a comparison to Model 2 significant drop of accuracy was noted  \n   - removing Pooling increased significantly overall time needed for processing of each Epoch  \n* Model 2 was trained with same architecture as Model 1 but with an addition of Pooling\n   - adding Pooling lowered time needed for processing of each Epoch\n   - the accuracy increased from 0.47920 to 0.62780\n* Model 3 was trained with same architecture as Model 2 but with an addition of Image Augmentation  \n   - the accuracy increased from 0.62780 to 0.67630","466eb82b":"### First image","b6d938f9":"### Missclassifications","6809d622":"### Missclassifications","bb479651":"* Model 1 scored: 0.4682\n* Model 2 scored: 0.6203\n* Model 3 scored: 0.6763","17651995":"# Report","82aa8453":"### Correct classifications","de0cef35":"# 4. Baseline model","002b8884":"# 1. Main objective of the analysis that also specifies whether your model will be focused on a specific type of Deep Learning or Reinforcement Learning algorithm and the benefits that your analysis brings to the business or stakeholders of this data.  ","10c39ff5":"##### Accuracy report for Model 2:\n              precision    recall  f1-score   support\n\n           0       0.73      0.87      0.79       100\n           1       0.66      0.72      0.69       100\n           2       0.52      0.49      0.50       100\n           3       0.31      0.38      0.34       100\n           4       0.30      0.54      0.39       100\n           5       0.58      0.59      0.59       100\n           6       0.69      0.74      0.71       100\n           7       0.66      0.55      0.60       100\n           8       0.80      0.82      0.81       100\n           9       0.80      0.70      0.74       100\n          10       0.54      0.48      0.51       100\n          11       0.42      0.40      0.41       100\n          12       0.64      0.69      0.67       100\n          13       0.84      0.56      0.67       100\n          14       0.72      0.46      0.56       100\n          15       0.68      0.63      0.66       100\n          16       0.71      0.62      0.66       100\n          17       0.80      0.78      0.79       100\n          18       0.60      0.44      0.51       100\n          19       0.59      0.50      0.54       100\n          20       0.89      0.79      0.84       100\n          21       0.64      0.84      0.73       100\n          22       0.61      0.60      0.60       100\n          23       0.69      0.86      0.76       100\n          24       0.71      0.77      0.74       100\n          25       0.53      0.55      0.54       100\n          26       0.57      0.56      0.57       100\n          27       0.34      0.57      0.43       100\n          28       0.87      0.76      0.81       100\n          29       0.72      0.54      0.62       100\n          30       0.48      0.65      0.55       100\n          31       0.66      0.61      0.64       100\n          32       0.58      0.59      0.58       100\n          33       0.64      0.59      0.61       100\n          34       0.67      0.63      0.65       100\n          35       0.42      0.33      0.37       100\n          36       0.72      0.56      0.63       100\n          37       0.62      0.65      0.64       100\n          38       0.58      0.45      0.51       100\n          39       0.84      0.76      0.80       100\n          40       0.64      0.47      0.54       100\n          41       0.84      0.79      0.81       100\n          42       0.63      0.66      0.64       100\n          43       0.65      0.71      0.68       100\n          44       0.33      0.41      0.36       100\n          45       0.43      0.62      0.51       100\n          46       0.43      0.47      0.45       100\n          47       0.66      0.57      0.61       100\n          48       0.83      0.86      0.85       100\n          49       0.73      0.85      0.79       100\n          50       0.33      0.34      0.34       100\n          51       0.72      0.59      0.65       100\n          52       0.54      0.80      0.65       100\n          53       0.70      0.85      0.77       100\n          54       0.62      0.74      0.68       100\n          55       0.25      0.22      0.23       100\n          56       0.89      0.81      0.85       100\n          57       0.77      0.66      0.71       100\n          58       0.75      0.79      0.77       100\n          59       0.69      0.49      0.57       100\n          60       0.89      0.72      0.80       100\n          61       0.73      0.70      0.71       100\n          62       0.69      0.66      0.68       100\n          63       0.70      0.50      0.58       100\n          64       0.38      0.43      0.41       100\n          65       0.55      0.41      0.47       100\n          66       0.72      0.58      0.64       100\n          67       0.45      0.53      0.48       100\n          68       0.87      0.91      0.89       100\n          69       0.78      0.76      0.77       100\n          70       0.69      0.64      0.66       100\n          71       0.70      0.81      0.75       100\n          72       0.23      0.41      0.29       100\n          73       0.40      0.43      0.41       100\n          74       0.42      0.45      0.44       100\n          75       0.92      0.80      0.86       100\n          76       0.85      0.79      0.82       100\n          77       0.64      0.53      0.58       100\n          78       0.49      0.48      0.49       100\n          79       0.72      0.57      0.64       100\n          80       0.34      0.38      0.36       100\n          81       0.66      0.73      0.70       100\n          82       0.93      0.84      0.88       100\n          83       0.70      0.50      0.58       100\n          84       0.60      0.57      0.58       100\n          85       0.68      0.83      0.75       100\n          86       0.71      0.67      0.69       100\n          87       0.70      0.71      0.71       100\n          88       0.82      0.58      0.68       100\n          89       0.76      0.71      0.73       100\n          90       0.65      0.80      0.72       100\n          91       0.74      0.69      0.72       100\n          92       0.55      0.62      0.58       100\n          93       0.43      0.46      0.45       100\n          94       0.87      0.87      0.87       100\n          95       0.61      0.54      0.57       100\n          96       0.53      0.54      0.54       100\n          97       0.67      0.62      0.64       100\n          98       0.40      0.36      0.38       100\n          99       0.67      0.62      0.64       100\n\n    accuracy                           0.62     10000","d84c9fe2":"# 4.1 Model 1 - no Pooling","bfab62f7":"# 1. Labels","c7067bc8":"Examples of misclassifications from Model 3.:","02af9bd8":"### Setting number of classes","e48e8bf6":"# 4 Summary of training at least three variations of the Deep Learning model you selected. For example, you can use different clustering techniques or different hyperparameters.  ","0c2882a6":"### First image","cd501025":"# 2. Brief description of the data set you chose, a summary of its attributes, and an outline of what you are trying to accomplish with this analysis.  ","1a0dc7e5":"# 3 Brief summary of data exploration and actions taken for data cleaning or feature engineering.  ","759fee6c":"# 2. Training set","4c9e2125":"* Main objective of the analysis that also specifies whether your model will be focused on a specific type of Deep Learning or Reinforcement Learning algorithm and the benefits that your analysis brings to the business or stakeholders of this data.  \n* Brief description of the data set you chose, a summary of its attributes, and an outline of what you are trying to accomplish with this analysis.  \n* Brief summary of data exploration and actions taken for data cleaning or feature engineering.  \n* Summary of training at least three variations of the Deep Learning model you selected. For example, you can use different clustering techniques or different hyperparameters.  \n* A paragraph explaining which of your Deep Learning models you recommend as a final model that best fits your needs in terms of accuracy or explainability.  \n* Summary Key Findings and Insights, which walks your reader through the main findings of your modeling exercise.  \n* Suggestions for next steps in analyzing this data, which may include suggesting revisiting this model or adding specific data features to achieve a better model.  ","b49464da":"# cifar100 dataset - image classification of 100 categories","7de4673e":"labels_dictionary =\\\n{0: 'apple',\n 1: 'aquarium_fish',\n 2: 'baby',\n 3: 'bear',\n 4: 'beaver',\n 5: 'bed',\n 6: 'bee',\n 7: 'beetle',\n 8: 'bicycle',\n 9: 'bottle',\n 10: 'bowl',\n 11: 'boy',\n 12: 'bridge',\n 13: 'bus',\n 14: 'butterfly',\n 15: 'camel',\n 16: 'can',\n 17: 'castle',\n 18: 'caterpillar',\n 19: 'cattle',\n 20: 'chair',\n 21: 'chimpanzee',\n 22: 'clock',\n 23: 'cloud',\n 24: 'cockroach',\n 25: 'couch',\n 26: 'crab',\n 27: 'crocodile',\n 28: 'cup',\n 29: 'dinosaur',\n 30: 'dolphin',\n 31: 'elephant',\n 32: 'flatfish',\n 33: 'forest',\n 34: 'fox',\n 35: 'girl',\n 36: 'hamster',\n 37: 'house',\n 38: 'kangaroo',\n 39: 'computer_keyboard',\n 40: 'lamp',\n 41: 'lawn_mower',\n 42: 'leopard',\n 43: 'lion',\n 44: 'lizard',\n 45: 'lobster',\n 46: 'man',\n 47: 'maple_tree',\n 48: 'motorcycle',\n 49: 'mountain',\n 50: 'mouse',\n 51: 'mushroom',\n 52: 'oak_tree',\n 53: 'orange',\n 54: 'orchid',\n 55: 'otter',\n 56: 'palm_tree',\n 57: 'pear',\n 58: 'pickup_truck',\n 59: 'pine_tree',\n 60: 'plain',\n 61: 'plate',\n 62: 'poppy',\n 63: 'porcupine',\n 64: 'possum',\n 65: 'rabbit',\n 66: 'raccoon',\n 67: 'ray',\n 68: 'road',\n 69: 'rocket',\n 70: 'rose',\n 71: 'sea',\n 72: 'seal',\n 73: 'shark',\n 74: 'shrew',\n 75: 'skunk',\n 76: 'skyscraper',\n 77: 'snail',\n 78: 'snake',\n 79: 'spider',\n 80: 'squirrel',\n 81: 'streetcar',\n 82: 'sunflower',\n 83: 'sweet_pepper',\n 84: 'table',\n 85: 'tank',\n 86: 'telephone',\n 87: 'television',\n 88: 'tiger',\n 89: 'tractor',\n 90: 'train',\n 91: 'trout',\n 92: 'tulip',\n 93: 'turtle',\n 94: 'wardrobe',\n 95: 'whale',\n 96: 'willow_tree',\n 97: 'wolf',\n 98: 'woman',\n 99: 'worm'}","38507736":"Due to characteristics of the problem I value accuracy more than explainability.  \nThe model I recommend as a final one is the model with highest accuracy on a validation data set.  \nModel 3. with some Image Augmentation methods proved to be the best one.  ","c9a7dd01":"# 5 A paragraph explaining which of your Deep Learning models you recommend as a final model that best fits your needs in terms of accuracy or explainability.","4780b4dc":"Examples of correct classifications from Model 3.:","03f8baef":"# 4.3 Model 3 - same architecture but with Pooling and Image Augmentation","ef81783b":"### Being a member of a class is now vectiorized","5cf4185c":"### Classification report","d2fef182":"https:\/\/www.cs.toronto.edu\/~kriz\/cifar.html","42c348de":"### Every 10.000th image of Traing set","9e886206":"https:\/\/www.kaggle.com\/konutech\/cifar100-image-classification-to-1-of-100-classes","764dbbea":"# 4.2 Model 2 - same architecture but with Pooling","694daa29":"# 7 Suggestions for next steps in analyzing this data, which may include suggesting revisiting this model or adding specific data features to achieve a better model.  ","1e9334fa":"### Converting all values to floats","73a3929b":"### Missclassifications","d45d08cf":"### Every 10 000th image","4b31445e":"### Confusion matrix","8ada1029":"##### Accuracy report for Model 3:  \n            precision    recall  f1-score   support\n\n           0       0.89      0.88      0.88       100\n           1       0.87      0.76      0.81       100\n           2       0.67      0.60      0.63       100\n           3       0.59      0.41      0.49       100\n           4       0.47      0.48      0.47       100\n           5       0.56      0.74      0.64       100\n           6       0.69      0.79      0.73       100\n           7       0.77      0.63      0.69       100\n           8       0.75      0.83      0.79       100\n           9       0.84      0.82      0.83       100\n          10       0.47      0.50      0.49       100\n          11       0.50      0.51      0.51       100\n          12       0.71      0.78      0.74       100\n          13       0.75      0.65      0.70       100\n          14       0.53      0.73      0.62       100\n          15       0.69      0.65      0.67       100\n          16       0.74      0.73      0.73       100\n          17       0.76      0.81      0.79       100\n          18       0.62      0.64      0.63       100\n          19       0.68      0.62      0.65       100\n          20       0.88      0.85      0.86       100\n          21       0.88      0.76      0.82       100\n          22       0.59      0.73      0.65       100\n          23       0.81      0.76      0.78       100\n          24       0.87      0.76      0.81       100\n          25       0.59      0.54      0.57       100\n          26       0.51      0.79      0.62       100\n          27       0.47      0.54      0.50       100\n          28       0.76      0.79      0.77       100\n          29       0.60      0.66      0.63       100\n          30       0.68      0.58      0.63       100\n          31       0.81      0.55      0.65       100\n          32       0.80      0.52      0.63       100\n          33       0.59      0.71      0.64       100\n          34       0.77      0.76      0.76       100\n          35       0.43      0.49      0.46       100\n          36       0.87      0.74      0.80       100\n          37       0.77      0.69      0.73       100\n          38       0.69      0.46      0.55       100\n          39       0.56      0.86      0.68       100\n          40       0.87      0.58      0.69       100\n          41       0.86      0.79      0.82       100\n          42       0.39      0.83      0.53       100\n          43       0.80      0.72      0.76       100\n          44       0.34      0.38      0.36       100\n          45       0.49      0.64      0.56       100\n          46       0.51      0.51      0.51       100\n          47       0.49      0.74      0.59       100\n          48       0.80      0.94      0.86       100\n          49       0.74      0.84      0.79       100\n          50       0.55      0.43      0.48       100\n          51       0.77      0.68      0.72       100\n          52       0.67      0.48      0.56       100\n          53       0.75      0.95      0.84       100\n          54       0.85      0.76      0.80       100\n          55       0.47      0.24      0.32       100\n          56       0.93      0.85      0.89       100\n          57       0.74      0.78      0.76       100\n          58       0.82      0.88      0.85       100\n          59       0.63      0.68      0.65       100\n          60       0.75      0.88      0.81       100\n          61       0.59      0.78      0.67       100\n          62       0.88      0.63      0.73       100\n          63       0.38      0.67      0.49       100\n          64       0.63      0.51      0.56       100\n          65       0.63      0.49      0.55       100\n          66       0.71      0.79      0.75       100\n          67       0.61      0.48      0.54       100\n          68       0.89      0.93      0.91       100\n          69       0.84      0.81      0.83       100\n          70       0.77      0.75      0.76       100\n          71       0.83      0.63      0.72       100\n          72       0.44      0.35      0.39       100\n          73       0.59      0.50      0.54       100\n          74       0.39      0.51      0.44       100\n          75       0.90      0.77      0.83       100\n          76       0.92      0.82      0.87       100\n          77       0.59      0.62      0.60       100\n          78       0.41      0.67      0.51       100\n          79       0.63      0.71      0.67       100\n          80       0.66      0.42      0.51       100\n          81       0.67      0.72      0.69       100\n          82       0.92      0.88      0.90       100\n          83       0.85      0.52      0.65       100\n          84       0.80      0.63      0.70       100\n          85       0.87      0.80      0.83       100\n          86       0.65      0.73      0.69       100\n          87       0.71      0.77      0.74       100\n          88       0.57      0.86      0.69       100\n          89       0.74      0.78      0.76       100\n          90       0.82      0.77      0.79       100\n          91       0.84      0.72      0.77       100\n          92       0.78      0.58      0.67       100\n          93       0.53      0.49      0.51       100\n          94       0.90      0.87      0.88       100\n          95       0.68      0.69      0.69       100\n          96       0.65      0.37      0.47       100\n          97       0.81      0.61      0.70       100\n          98       0.57      0.41      0.48       100\n          99       0.74      0.57      0.64       100\n\n    accuracy                           0.67     10000","a9cce881":"images_to_show = []\nfor i, image in enumerate(X_train):\n    if (i + 1) % 1000 == 0:\n        images_to_show.append(i)","66b6a734":"The data I used comes from https:\/\/www.cs.toronto.edu\/~kriz\/cifar.html  \nIn contrary to the data set used during the course which was grouped by 10 classes, and for the sake of studying deep learning methods, I decided to increase the challenge of classification to 100 groups.  \nThe dimensions of training set are (50000, 32, 32, 3) so in other words:    \n* the model was trained using 50.000 classified images  \n* the images are in RBS scale and each one has 32*32 pixels  \n\nTest set consists of 10.000 images.  \n\nThe labels are:  ","4dcabb46":"### Last image","dd862a6f":"### Every 1000th image","31db3291":"https:\/\/machinelearningmastery.com\/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping\/","b4f24351":"### Correct classifications","2703a9f3":"##### Accuracy report for Model 1: 0.4711\n              precision    recall  f1-score   support\n\n           0       0.73      0.70      0.71       100\n           1       0.56      0.65      0.60       100\n           2       0.34      0.23      0.28       100\n           3       0.20      0.17      0.18       100\n           4       0.31      0.20      0.24       100\n           5       0.37      0.46      0.41       100\n           6       0.46      0.50      0.48       100\n           7       0.64      0.48      0.55       100\n           8       0.71      0.55      0.62       100\n           9       0.56      0.68      0.61       100\n          10       0.49      0.33      0.40       100\n          11       0.33      0.30      0.32       100\n          12       0.50      0.52      0.51       100\n          13       0.39      0.48      0.43       100\n          14       0.44      0.43      0.44       100\n          15       0.42      0.39      0.41       100\n          16       0.62      0.44      0.51       100\n          17       0.50      0.65      0.57       100\n          18       0.36      0.38      0.37       100\n          19       0.38      0.37      0.38       100\n          20       0.68      0.77      0.72       100\n          21       0.44      0.64      0.52       100\n          22       0.49      0.45      0.47       100\n          23       0.70      0.61      0.65       100\n          24       0.72      0.62      0.67       100\n          25       0.36      0.38      0.37       100\n          26       0.48      0.30      0.37       100\n          27       0.29      0.25      0.27       100\n          28       0.74      0.70      0.72       100\n          29       0.45      0.47      0.46       100\n          30       0.46      0.43      0.45       100\n          31       0.39      0.43      0.41       100\n          32       0.39      0.28      0.33       100\n          33       0.51      0.43      0.47       100\n          34       0.44      0.43      0.44       100\n          35       0.27      0.32      0.29       100\n          36       0.46      0.47      0.47       100\n          37       0.48      0.51      0.50       100\n          38       0.28      0.30      0.29       100\n          39       0.59      0.55      0.57       100\n          40       0.40      0.42      0.41       100\n          41       0.68      0.69      0.69       100\n          42       0.49      0.49      0.49       100\n          43       0.61      0.49      0.54       100\n          44       0.17      0.14      0.15       100\n          45       0.38      0.34      0.36       100\n          46       0.26      0.36      0.30       100\n          47       0.58      0.57      0.58       100\n          48       0.63      0.85      0.72       100\n          49       0.59      0.50      0.54       100\n          50       0.31      0.26      0.28       100\n          51       0.34      0.39      0.36       100\n          52       0.54      0.72      0.62       100\n          53       0.55      0.77      0.64       100\n          54       0.48      0.65      0.55       100\n          55       0.20      0.16      0.18       100\n          56       0.62      0.65      0.63       100\n          57       0.57      0.54      0.55       100\n          58       0.63      0.64      0.64       100\n          59       0.53      0.37      0.44       100\n          60       0.63      0.79      0.70       100\n          61       0.50      0.52      0.51       100\n          62       0.51      0.62      0.56       100\n          63       0.51      0.44      0.47       100\n          64       0.31      0.31      0.31       100\n          65       0.23      0.28      0.25       100\n          66       0.41      0.37      0.39       100\n          67       0.44      0.23      0.30       100\n          68       0.75      0.86      0.80       100\n          69       0.50      0.66      0.57       100\n          70       0.45      0.50      0.47       100\n          71       0.64      0.43      0.51       100\n          72       0.20      0.16      0.18       100\n          73       0.38      0.43      0.40       100\n          74       0.39      0.20      0.26       100\n          75       0.61      0.70      0.65       100\n          76       0.55      0.80      0.65       100\n          77       0.32      0.24      0.27       100\n          78       0.30      0.29      0.29       100\n          79       0.49      0.43      0.46       100\n          80       0.33      0.22      0.26       100\n          81       0.60      0.47      0.53       100\n          82       0.61      0.76      0.68       100\n          83       0.41      0.38      0.40       100\n          84       0.42      0.32      0.36       100\n          85       0.60      0.58      0.59       100\n          86       0.39      0.61      0.47       100\n          87       0.47      0.60      0.52       100\n          88       0.57      0.52      0.54       100\n          89       0.56      0.44      0.49       100\n          90       0.41      0.48      0.44       100\n          91       0.64      0.56      0.60       100\n          92       0.31      0.47      0.38       100\n          93       0.30      0.19      0.23       100\n          94       0.74      0.84      0.79       100\n          95       0.49      0.55      0.52       100\n          96       0.48      0.35      0.40       100\n          97       0.36      0.53      0.43       100\n          98       0.22      0.22      0.22       100\n          99       0.47      0.51      0.49       100  \n  \n    accuracy                           0.47     10000  ","bbb12d8d":"# 6 Summary Key Findings and Insights, which walks your reader through the main findings of your modeling exercise.  ","97d55965":"You can run my notebook on Kaggle. GPU recommended:","a287ce8f":"The data set provided did not needed any actions related to data cleaning.  \nIn case of \"feature engindeering\" some action were taken known as Image Augmentation.  \nBasically Image Augmentation provides solutions to increase the size of training set (provides new sample of images) due to simple changes in atrtibutes of images.  \nThe simplest examples of Image Augmentation are:\n* vertical copies of images  \n* shifts in orientation of images  \n* rotations of images by some degrees","92cdd853":"### Classification report","f22d8284":"# Image augmentation settings","01e742f6":"The main objective of the analysis was to classify images with highest possible accuracy.  \nHere, in my project images could have been classified by 100 classes, e.g. \"mountain\", \"road\".\nDue to characteristics of the challenge I have used few variations of Convolutional Neural Networks (or CNN).  \n\nSimplest benefit from implementation of image classification automation for a business area might be a case when a user is expected to upload a particular picture but instead he uses a random one.  \nLet's imagine that insurence company expects to upload an image of a car but receives a picture of a horse.  "}}