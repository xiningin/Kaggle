{"cell_type":{"6a315976":"code","bcb62480":"code","6fe621ef":"code","a6e01042":"code","080a69ea":"code","71b67c1f":"code","a371dab2":"code","0df52a1a":"code","278bde49":"code","a9a78d13":"code","7f753c0d":"code","c711c30f":"code","792bd75c":"code","b66737a9":"code","5855b52d":"markdown","01a53697":"markdown","6bdd149c":"markdown","10df2dca":"markdown","34843941":"markdown","ab8b0277":"markdown","97ccba81":"markdown","aa601905":"markdown","f79daedf":"markdown","9f651628":"markdown","64adac50":"markdown"},"source":{"6a315976":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","bcb62480":"df_cal = pd.read_csv('..\/input\/m5-forecasting-accuracy\/calendar.csv')\ndf_sales = pd.read_csv('..\/input\/m5-forecasting-accuracy\/sales_train_validation.csv')\ndf_price = pd.read_csv('..\/input\/m5-forecasting-accuracy\/sell_prices.csv')","6fe621ef":"# Check for missing entries\ndf_cal['date'] = pd.to_datetime(df_cal['date'])\n\nassert (df_cal['date'].max() - df_cal['date'].min()).days + 1 == df_cal.shape[0], 'Missing Dates in the data'","a6e01042":"df_cal['weekday'] = pd.Categorical(df_cal['weekday'], \n                                   categories=['Saturday', 'Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday','Friday'], \n                                   ordered=True)","080a69ea":"df_event_types = pd.wide_to_long(df_cal[['event_name_1','event_type_1','event_name_2','event_type_2']].reset_index(), \n                stubnames=['event_name_','event_type_'],\n                i='index',j='num')\\\n    .dropna()\\\n    .reset_index(level=-1)\\\n    .groupby(['event_type_','event_name_'], as_index=False)\\\n    .count()\\\n    .rename(columns={'event_type_':'Event Type','event_name_':'Event Name', 'num':'Counts'})","71b67c1f":"fig, ax = plt.subplots(1,1,figsize=(10,12))\nax = sns.barplot(x='Counts', y='Event Name', hue='Event Type', data=df_event_types, orient='h', dodge=False)\nax.set_title('Total No. of Events (By type and name)')\nax.legend(loc='center left', bbox_to_anchor=(1.01,0.5))\nplt.show()","a371dab2":"df_cal[['year','weekday','snap_CA','snap_TX','snap_WI']]\\\n    .groupby(['year','weekday'])\\\n    .sum()\\\n    .plot(kind='bar', \n          stacked=True, \n          figsize=(20,6), \n          title='SNAP Purchases (Year and Days)')","0df52a1a":"snap_by_month = df_cal[['date','snap_CA','snap_TX','snap_WI']]\\\n    .resample(rule='M',on='date')\\\n    .sum()\n\nsnap_by_month.index = snap_by_month.index.strftime('%b-%Y')\n\nfig, ax = plt.subplots(1,1,figsize=(20,6))\nsnap_by_month.plot(kind='bar', stacked=True, title='SNAP Purchases Across Months', ax=ax)\n\nax.legend(loc='center left', bbox_to_anchor=(1.01,0.5))\n\nplt.show()","278bde49":"df_cat_dept = df_sales[['dept_id','cat_id','id']].groupby(['cat_id','dept_id']).count().reset_index()\n\ndf_cat_dept.rename(columns={'id':'Count of Unique IDs'}, inplace=True)\n\nfig, ax = plt.subplots(1,1,figsize=(12,8))\n\nsns.barplot(data=df_cat_dept, x='Count of Unique IDs', y='dept_id', hue='cat_id', orient='h', dodge=False, ax=ax)\nax.set_title('Total No. of Unique IDs (By Department and Category)')\nax.legend(loc='center left', bbox_to_anchor=(1.01,0.5), title='cat_id')\nplt.show()","a9a78d13":"df_sales['Total_sales'] = df_sales.iloc[:, 6:].sum(axis=1)\n\ndf_total_item_sales = df_sales[['cat_id','dept_id','Total_sales']].groupby(['cat_id','dept_id'], as_index=False).sum()\n\nfig, ax = plt.subplots(1,1,figsize=(12,8))\n\nsns.barplot(data=df_total_item_sales, x='Total_sales', y='dept_id', hue='cat_id', orient='h', dodge=False, ax=ax)\nax.set_title('Total Items Sales (By Department and Category)')\nax.legend(loc='center left', bbox_to_anchor=(1.01,0.5), title='cat_id')\nplt.show()","7f753c0d":"fig, ax = plt.subplots(1,1, figsize=(12,6))\n\ndf_item_by_store = df_sales[['state_id','store_id','item_id']]\\\n    .groupby(['state_id','store_id']).count()\\\n    .reset_index()\\\n    .rename(columns={'item_id':'Unique Items'})\n    \nsns.barplot(data=df_item_by_store, x='store_id', y='Unique Items', hue='state_id', dodge=False, ax=ax)\n \nax.set_title('Count of Unique Items across Stores')    \nax.set_ylabel('Count of Unique Items')\nax.legend(loc='center left', bbox_to_anchor=(1.01,0.5), title='state_id')\nplt.show()","c711c30f":"df_total_store_sales = df_sales[['state_id','store_id','Total_sales']].groupby(['state_id','store_id'], as_index=False).sum()\n\nfig, ax = plt.subplots(1,1,figsize=(12,6))\n\nsns.barplot(data=df_total_store_sales, x='store_id', y='Total_sales', hue='state_id', dodge=False, ax=ax)\nax.set_title('Total Sales Volume (By Store)')\nax.legend(loc='center left', bbox_to_anchor=(1.01,0.5), title='state_id')\nplt.show()","792bd75c":"d_cols = list(df_sales.columns[df_sales.columns.str.startswith('d_')])\n\ndf_days_long = df_sales[['item_id','store_id'] + d_cols].set_index(['item_id','store_id'])\\\n    .stack()\\\n    .rename('sale_unit')\\\n    .reset_index(-1)\\\n    .query('sale_unit > 0')\n\nd_to_wmyrwk_mapping = df_cal[['wm_yr_wk','d']].set_index('d').to_dict()['wm_yr_wk']\n\ndf_days_long['wm_yr_wk'] = df_days_long['level_2'].map(d_to_wmyrwk_mapping)\ndf_days_long = df_days_long.set_index('wm_yr_wk', append=True).groupby(level=[0,1,2])['sale_unit'].sum().to_frame()\n\ndf_merged = df_days_long.merge(df_price.set_index(['item_id','store_id','wm_yr_wk']), left_index=True, right_index=True, how='left')\ndf_merged['sale_value'] = df_merged['sale_unit'] * df_merged['sell_price']","b66737a9":"df_sales_value_by_store = (df_merged['sale_value'].groupby(level=[1]).sum() \/ 1_000_000)\\\n    .round(1).rename('Sales Value ($ millions)')\\\n    .to_frame()\\\n    .reset_index()\n\ndf_sales_value_by_store['state_id'] = df_sales_value_by_store['store_id'].str[:2]\n\nfig, ax = plt.subplots(1,1,figsize=(12,6))\n\nsns.barplot(data=df_sales_value_by_store, x='store_id', y='Sales Value ($ millions)', hue='state_id', dodge=False, ax=ax)\nax.set_title('Total Sales Value (By Store)')\nax.legend(loc='center left', bbox_to_anchor=(1.01,0.5), title='state_id')\nplt.show()","5855b52d":"### Event Type and Name\n\nLets explore the events type and name given alongside the dates. As these events happen at National level, annual occurence is guaranteed. \n\nAs our data only spans about 5.4 years, certain annual event has yet to happen for the 6th time.","01a53697":"## Total Sales Value By Store\n\n- More or less the same proportions as total sales volume.","6bdd149c":"## Total Sales by Category of Items (Across 5.4 years)\n\n- People tend to buy more food items, followed by household items and hobby items. (much like Maslow's Hierarchy of Needs)","10df2dca":"##  Supplement Nutrition Assistance Program (SNAP)\n\n> *The United States federal government provides a nutrition assistance benefit called the Supplement Nutrition\nAssistance Program (SNAP). SNAP provides low income families and individuals with an Electronic Benefits Transfer\ndebit card to purchase food products. In many states, the monetary benefits are dispersed to people across 10 days\nof the month and on each of these days 1\/10 of the people will receive the benefit on their card.*\n\nThe columns `snap_CA`, `snap_TX` and `snap_WI` indicates whether the stores of CA, TX or WI allow **SNAP** purchases on the examined \ndate. 1 indicates that SNAP purchases are allowed.\n\nWe can see below that the dispersal of SNAP benefits is consistent over the years, but they can happen over the strecth of any 10 days.","34843941":"# 2. Sales & Prices","ab8b0277":"## Categories of Items\n\n- 3 categories of items in total, namely, Food, Hobbies and Household items.\n- We have more unique food items compared to the rest","97ccba81":"## Number of Stores and Unique Items Sold at Each Store\n\nWe have 10 stores in total, 4 in CA, 3 in TX and WI. All the products are available in every store.","aa601905":"# 1. Calendar","f79daedf":"## Data Period\n\nCalendar details are available from 29 Jan 2011 to 19 Jun 2016 (no missing entries).","9f651628":"That's all for now!","64adac50":"## Total Sales Volume by Store\n\n- CA_3 seems to be the most popular store among all, with a significantly higher sales volume than the others.\n- Other stores registered similar sales volume."}}