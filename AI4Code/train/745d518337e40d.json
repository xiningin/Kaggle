{"cell_type":{"7ce5acc7":"code","97c5fa8c":"code","2a326477":"code","893d600a":"code","f4ca5d8b":"code","ae0c4108":"code","633b20c0":"code","28ebeb74":"code","1b73fd1f":"code","30414433":"code","58b212ae":"code","272177b2":"code","ffaef6f8":"code","fc14dd4b":"code","3e6bec5c":"code","c878b619":"code","e1414e24":"code","c99171d9":"code","11e0220a":"code","2f39652d":"code","09f3b706":"code","e6a75bba":"code","9b1aa5f8":"code","9132c472":"code","711fcc30":"code","ba1b2fdd":"code","9bf6e5ec":"code","7c25cac3":"code","746b7d1a":"code","54aab013":"code","0d266a94":"code","3d9bc3f8":"code","511e9658":"code","5b687423":"code","23798daf":"code","cf3c93d1":"code","33da512d":"code","9e007b3d":"code","b85b8011":"code","28404c42":"code","6593a899":"code","c4fd93de":"code","543540fb":"code","c413fa5c":"code","0058ef3d":"code","99f37ba3":"code","7bf98bac":"code","741b38da":"code","68b08c97":"code","82e90f5d":"code","b48955ef":"code","6b472700":"code","65a6ac70":"code","1cf58e7a":"code","5d6c5e84":"code","d44d60c9":"code","d2c6e100":"code","d9fb5da7":"markdown","cd9a7470":"markdown","af2ee213":"markdown","a2401c2f":"markdown","9157c93a":"markdown","e102f0d9":"markdown","0d6befa0":"markdown","0421ddb2":"markdown","60fd94e6":"markdown","f772d74f":"markdown","7a2b4780":"markdown","75c6708d":"markdown","d1f90771":"markdown","539c08f9":"markdown","eb7a1fa2":"markdown","cabd77e5":"markdown","734d564d":"markdown","a321ad7c":"markdown","674a1923":"markdown","5d985946":"markdown","21d2a60b":"markdown","4620793e":"markdown","6c29ae49":"markdown","c4ea4d6c":"markdown","9d410b44":"markdown","597f6d0b":"markdown","26d832d2":"markdown","0c914178":"markdown","2bbe16b5":"markdown","c0a81139":"markdown","e4331044":"markdown","3fd8dfa2":"markdown","c5bf50b3":"markdown","ed4ad6f0":"markdown","30626117":"markdown","55ec1acf":"markdown","afc1da60":"markdown","21606e8a":"markdown","de3ff60e":"markdown","286d4de1":"markdown","99832967":"markdown","02ff1d06":"markdown","f42b6e7e":"markdown","d3aa25a5":"markdown","132ceafa":"markdown","27e83f0a":"markdown","5da9609b":"markdown","b0d1f6c4":"markdown","223a3e89":"markdown","8b0b9749":"markdown","d191b602":"markdown","1b0a8497":"markdown","57eb2a73":"markdown","2f977001":"markdown","e7a2261b":"markdown","2a1a608b":"markdown","ffff458b":"markdown","1b000dd9":"markdown","91dc5f10":"markdown","c1181dec":"markdown","d40233aa":"markdown","58f30d75":"markdown","41c9551a":"markdown","c9b5fb14":"markdown","be56e169":"markdown","eada948d":"markdown","b0793041":"markdown","6f391f3d":"markdown","b9d17525":"markdown","03fd7577":"markdown","88afacd1":"markdown","df62825e":"markdown","46907ca5":"markdown","f248b379":"markdown","14d8e593":"markdown"},"source":{"7ce5acc7":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt","97c5fa8c":"# Create a Series\nlist_a = [1, 2, 3, 4, 5, 6, 7]\n# series_a = pd.Series(None)\n# series_a","2a326477":"list_b = ['a', 'b', 'c', 'd', 'e', 'f', 'g']\n# series_b = pd.Series(None)\n# series_b","893d600a":"list_c = [1, 'bjdas', [8,9], {1,'s', 'e', 't'}, dict, print, float(22*0.14)]\n# series_c = pd.Series(None)\n# series_c","f4ca5d8b":"#\u00a0Access the first element in the series\n# series_a.iloc[None]","ae0c4108":"# Access the last element in the series\n# series_a.iloc[None]","633b20c0":"# Access the third to fifth elements in the series\n# series_a.iloc[None]","28ebeb74":"series_d = pd.Series(list_a, index=list_b)\nseries_d","1b73fd1f":"# series_d.loc[None]","30414433":"selected_index = ['a', 'd', 'g']\n# series_d.loc[None]","58b212ae":"d = {'col1': [1, 2, 3, 4], 'col2': [3, 4, 10, 'a']}\n#\u00a0df = pd.DataFrame(None)","272177b2":"# df.iloc[None]","ffaef6f8":"# df[None]","fc14dd4b":"path = \"..\/input\/load_data\/see_ess_vee.csv\"\ndf = pd.read_csv(path)\n\n# We can view the first 5 rows using df.head()\n\ndf.head()","3e6bec5c":"df = pd.read_csv('..\/input\/parks-data\/parks.csv', index_col=['Park Code'])\ndf.head()","c878b619":"parks = ['HALE', 'HAVO', 'HOSP', 'ISRO', 'JOTR', 'KATM', 'KEFJ', 'KOVA', 'LACL','YOSE']\nselected_df = df.loc[parks]\nselected_df","e1414e24":"selected_df['State']","c99171d9":"mask = selected_df['State']=='HI'\nselected_df[mask]","11e0220a":"# selected_df[(selected_df['State']==None) &\n#             (selected_df['Acres']>None)]","2f39652d":"missing_data = {'col1': [1, 2, None, 4], 'col2': [None, 4, 10, 'a']}\nmissing_df = pd.DataFrame(missing_data)\nmissing_df","09f3b706":"missing_df[missing_df['col1'].isnull()]","e6a75bba":"missing_df[~missing_df['col1'].isnull()]","9b1aa5f8":"# missing_df.rename(columns={None:None}, inplace=True)\n# missing_df","9132c472":"# missing_df.drop(None, axis=1, inplace=True)\n# missing_df","711fcc30":"# missing_df.drop(None, axis=0, inplace=True)\n# missing_df","ba1b2fdd":"d = {'col1': [1, 2, 3, 4], 'col2': [3, 4, 10, 1]}\ndf = pd.DataFrame(d)\ndf['minus'] = d['col1']-df['col2']\ndf","9bf6e5ec":"df['divide'] = d['col1']\/df['col2']\ndf","7c25cac3":"df = pd.read_csv('..\/input\/parks-data\/parks.csv', index_col=['Park Code'])\ndf.sort_values(by='State', ascending=False, inplace=True)\ndf.head(10)","746b7d1a":"# Which state has the most national parks?","54aab013":"df.describe()","0d266a94":"# df.groupby(None).agg(None)[None]","3d9bc3f8":"df = pd.DataFrame(data={'preds': [1, 0, 0, 0, 1, 0, 1, 1, 1],\n                        'ground_truth': [1, 0, 1, 0, 1, 0, 0, 1, 1]})\n\nconfusion_matrix =pd.crosstab(df['ground_truth'], df['preds'], rownames=['ground_truth'], colnames=['Preds'])\nprint (confusion_matrix)","511e9658":"path = \"..\/input\/load_data\/see_ess_vee.csv\"\ndf = pd.read_csv(path)","5b687423":"# df.plot(x=None, y=None,kind=None)","23798daf":"df.plot(x='a', y='b',kind='scatter', color='k', title='Random Scatter')","cf3c93d1":"datetime_example = pd.to_datetime('2019-08-01 12:40')\ndatetime_example","33da512d":"# We can extract hour\/week\/day from these timestamps using the following\nprint(datetime_example.hour)\nprint(datetime_example.weekday())\nprint(datetime_example.weekday_name)","9e007b3d":"df = pd.read_csv('..\/input\/stock-time-series-20050101-to-20171231\/all_stocks_2017-01-01_to_2018-01-01.csv')","b85b8011":"df['Date'] = pd.to_datetime(df['Date'])","28404c42":"df['Date'].iloc[420]","6593a899":"# x is the row (Think of it as the 'i' in --- for i in iterable_object)\ndf['weekday_day'] = df['Date'].apply(lambda x: x.weekday_name) ","c4fd93de":"df.head()","543540fb":"# Function takes the value of that row and returns a value after processing\ndef part_of_week(row_entry):\n    day_of_week = row_entry.weekday()\n    if day_of_week in [0,1]:\n        return 'early week'\n    elif day_of_week == 2:\n        return 'hump day'\n    if day_of_week in [3,4]:\n        return 'late week'\n\n# Apply to the column you wishh to process and access each row using `x`\n#\u00a0Think of this technique as a for loop going over each row in a column\ndf['part_of_week'] = df['Date'].apply(lambda x: part_of_week(x))\n        ","c413fa5c":"df.head()","0058ef3d":"d1 = {'Customer_id':pd.Series([1,2,3,4,5,6]),\n  'Product':pd.Series(['Oven','Oven','Oven','Television','Television','Television'])}\ndf1 = pd.DataFrame(d1)\n \nd2 = {'Customer_id':pd.Series([2,4,6]),\n    'State':pd.Series(['California','California','Texas'])}\ndf2 = pd.DataFrame(d2)","99f37ba3":"df1","7bf98bac":"df2","741b38da":"df3 = pd.merge(df1, df2, on='Customer_id', how='left')\ndf3","68b08c97":"df1 = pd.DataFrame([[1, 2], [3, 4]], columns=list('AB'))\ndf1","82e90f5d":"df2 = pd.DataFrame([[5, 6], [7, 8]], columns=list('AB'))\ndf1.append(df2)","b48955ef":"df_concat = pd.concat([df1, df2], axis=0)\ndf_concat","6b472700":"df_concat.loc[1]","65a6ac70":"df_concat = pd.concat([df1, df2], axis=0, ignore_index=True)\ndf_concat","1cf58e7a":"data = {'animal': ['cat', 'cat', 'snake', 'dog', 'dog', 'cat', 'snake', 'cat', 'dog', 'dog'],\n        'age': [2.5, 3, 0.5, np.nan, 5, 2, 4.5, np.nan, 7, 3],\n        'visits': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n        'priority': ['yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no']}\n\nlabels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']","5d6c5e84":"df = pd.DataFrame({'From_To': ['LoNDon_paris', 'MAdrid_miLAN', 'londON_StockhOlm', \n                               'Budapest_PaRis', 'Brussels_londOn'],\n              'FlightNumber': [10045, np.nan, 10065, np.nan, 10085],\n              'RecentDelays': [[23, 47], [], [24, 43, 87], [13], [67, 32]],\n                   'Airline': ['KLM(!)', '<Air France> (12)', '(British Airways. )', \n                               '12. Air France', '\"Swiss Air\"']})\ndf","d44d60c9":"df = pd.DataFrame({'A': [1, 2, 2, 3, 4, 5, 5, 5, 6, 7, 7]})\n\n","d2c6e100":"df = pd.DataFrame({'a': [None, None, None, 2, 3, 5],\n                   'b': [1, 2 ,3, None, None, None]})","d9fb5da7":"#\u00a0Exploring\nWe can let columns interact with each othher very easily in pandas. \n\nUse simple math symbols to combine columns and then add them to Dataframe\n","cd9a7470":"** Select the data in rows [3, 4, 8] and in columns ['animal', 'age'].**","af2ee213":"# Hello! \ud83d\udc4b\ud83d\udc4b\ud83d\udc4b \n\nWelcome to the the latest Meetup from Central London Data Science! \n\nThis month we'll be giving you a walkthrough in how to navigate, manipulate and analyse data using the popular data science package- `pandas` \ud83d\udc3c\n\nThe first half of this notebook will give you the essentials in working with pandas, while the second half will be leaving you to your own devices with some puzzles and challenges \n","a2401c2f":"# Cleaning data\n\nEven if we don't love it, we still gotta do it. Cleaning and data preprocessing is a massive part of a data scientists day. Here's a few exercises to help tidy up your data.","9157c93a":"Just like in a Series we can access full rows using indexing.\n\nTry and access the row with index label `2`...","e102f0d9":"Let's plot a simple scatter plot...","0d6befa0":"We can check basic stats as well using `df.describe()`","0421ddb2":"**Change the age in row 'f' to 1.5.**","60fd94e6":"**In the RecentDelays column, the values have been entered into the DataFrame as a list. We would like each first value in its own column, each second value in its own column, and so on. If there isn't an Nth value, the value should be NaN.\nExpand the Series of lists into a DataFrame named delays, rename the columns delay_1, delay_2, etc. and replace the unwanted RecentDelays column in df with delays.**","f772d74f":"We can do as may conditional comparisons as we want, we've just got to wrap them in `()` and chain them with `&`.\n\nLet's find out how many parks in Alaska are over 1760000 arces.\n\n\n","7a2b4780":"**A DataFrame has a column of groups 'grps' and and column of numbers 'vals'. For example:**\n```\ndf = pd.DataFrame({'grps': list('aaabbcaabcccbbc'),\n                    'vals': [12,345,3,1,45,14,4,52,54,23,235,21,57,3,87]})\n```\n                   \n                   \n**For each group, find the sum of the three greatest values.**","75c6708d":"# OK... That's the basics of pandas\n\nIf you feel comfortable with what we've shown you tonight have a crack at these challenges. They'll range in difficulty and you might need to think outside the box for a few. But the majority of the techniques covered so far will help you out.","d1f90771":"**Select just the 'animal' and 'age' columns from the DataFrame df.**","539c08f9":"We can also stick DataFrames together using `concat`, depending on the axis used we can combine DataFrames vertically (adding new rows) or horizontally (adding new columns). \n\nThe syntax is a bit different, we pass the function a list of DataFrames\/Series and tell it to concatenate along a specific axis. \n\nCheck it out [here](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.concat.html)\n","eb7a1fa2":"**Notice how the capitalisation of the city names is all mixed up in this temporary DataFrame. Standardise the strings so that only the first letter is uppercase (e.g. \"londON\" should become \"London\".)**","cabd77e5":"**Select the rows the age is between 2 and 4 (inclusive).**\n","734d564d":"We can also stick new rows in to DataFrames using the `append` method. ","a321ad7c":"We can get round this by passing `ignore_index=True`","674a1923":"** Count the number of each type of animal in df.**","5d985946":"# Anddddd that's a wrap \ud83c\udf2f\ud83c\udf2f\ud83c\udf2f\n\nHopefully you've learnt a few tips and tecniques to help with your day to day data preprocessing and analysis.\n\nJust a shout out to this [repo](https:\/\/github.com\/ajcr\/100-pandas-puzzles) for some of the challenges used tonight. They were a great help!\n\n\nAlso as you've probably noticed pandas as sooooo may methods and functions. The documentation has still quite a lot of catching up to do. So if you feel like giving back to the open source community have a think about going to this [meetup](https:\/\/www.meetup.com\/Python-Sprints\/)\n\nIf you want to find out more about improving the documentation check out this [blog](https:\/\/towardsdatascience.com\/get-stuck-in-with-contributing-to-pandas-fea87d2ac99)\n\nThanks for coming\u270c\ufe0f \n","21d2a60b":"# Time series\nJust like visualization, we should really have a dedicated meetup to discuss time series data. But this crash course will have to do...\n\npandas leans heavily on `numpy`'s `datetime64` and `timedelta64` dtypes. \n\nLets start by looking at a pandas timestamp object...","4620793e":"Another useful feature when dealing with missing values is to replace them with another value. Try replacing all the `None` values in the `missing_df` using the `replace()` method. \n\nHere's the [documentation](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.replace.html)","6c29ae49":"We can navigate and select items in a series using indexing.\n\nThere are 3 different ways to select items:\n\n* `iloc`- Gets row\/s at particular positions in the index- only takes integers.\n* `loc`- Gets a with particular labels from the index.\n* `ix`- behaves like `loc` but if it cannot find a matching label it reverts to `iloc`.\n\n** Try to avoid `ix` as it can be a bit of a gamble if a label doesn't exist. (It's also deprecated)**\n\nLet's start by accessing elements from our original `series_a`\n","c4ea4d6c":"You can identify missing data by using the `.isnull()` method. This will return `True` if any cell within the DataFrame is empty.","9d410b44":"**Suppose you have DataFrame with 10 columns of real numbers, for example:**\n\n`df = pd.DataFrame(np.random.random(size=(5, 10)), columns=list('abcdefghij'))`\n\n**Which column of numbers has the smallest sum? (Find that column's label.)**","597f6d0b":"We'll select the 10 rows based on the `Park Code` and store them in a **separate** dataframe.\n","26d832d2":"#\u00a0DataFrames\nDataFrames are essentially just tables, similar to that seen in Excel. They are (normally) two dimensional, with rows (horizontal entries) and columns (vertical entries). Each column is made of a `Series`.\n\nHere's a diagram to map out:\n\n<img src=\"https:\/\/media.geeksforgeeks.org\/wp-content\/uploads\/finallpandas.png\">\n\n","0c914178":"Or even filter **out** rows from certain columns based on missing data. or do **any** inverse conditional with the `~` \n\n","2bbe16b5":"** The 'priority' column contains the values 'yes' and 'no'. Replace this column with a column of boolean values: 'yes' should be True and 'no' should be False.**\n\n**Tip** We can use our `apply\/lambda` technique here, or we could use the `map` method. Check it out [here](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.Series.map.html) and try both\n","c0a81139":"We can also rename and drop columns using the following methods\n* `df.rename(columns={'old_column_name': 'new_column_name'}, inplace=True)`\n* `df.drop('column to drop', axis=1, inplace=True)`\n* `df.drop('row to drop', axis=0, inplace=True)`","e4331044":"Now we'll take advantage of the custom labels\/indexes.\n\nWe will give `series_a` new indexing, based on `list_b`. This means instead of indexes = `0, 1, 2, 3, 4, 5, 6` . We'll use `'a', 'b', 'c', 'd', 'e', 'f' 'g'`.","3fd8dfa2":"Let's combine the timestamp objects with a very useful data processing technique- `apply` and `lambda`. These functions allow us to apply a function to each row or column in the dataframe. The function can be anything you like. Just follow this template and you'll be grand.\n\n\nWe'll start by extracting the weekday from the timestamps\n\n","c5bf50b3":"# More difficult problems","ed4ad6f0":"Being able to calculate aggregates from data is essential as well.\n\nWe can groupby a certain column and then perfrom aggregates using the `.agg()` method.\n\nTry and find the total amount of acres for national parks across each state","30626117":"# Creating structured data \n\n* Pandas comprises of two main components, Series and DataFrames.\n* Throughout this meetup we will learn how to how to navigate, manipulate and analyse data using these two components.\n* Let's start with the most simple building block in pandas a Series.\n\n```\n0    a\n1    b\n2    c\n3    d\n4    e\n5    f\n6    g\n```\n\nA series is a one-dimensional array. (Think of it as a vertical python list). Our first exercise will be to simply create a `Series` from a `list`. We do this by using `pd.Series(data=None)`. \n\nReplace `None` with the following lists\n\n\nOne of the cool things about Series is the indexing. (How to select each element in the Series).","55ec1acf":"Try and experiment with the other parameters...","afc1da60":"**Sort df first by the values in the 'age' in decending order, then by the value in the 'visit' column in ascending order.**","21606e8a":"We can filter rows using python conditional statements ie `==` or `!=`. \nSay we wanted to filter our `selected_df` so that it only included Hawaiian parks (`HI`) \n\nWe would start by returning a boolean dataframe\/series based on this conditional statement\n\n\n`selected_df['State']=='HI`\n\nThis would be returned\n\n```\nPark Code\nHALE     True\nHAVO     True\nHOSP    False\nISRO    False\nJOTR    False\nKATM    False\nKEFJ    False\nKOVA    False\nLACL    False\nYOSE    False\nName: State, dtype: bool\n```\n\n\nWe would then use this as a **mask** and apply this to our original `selected_df`\n\nWhich would return this\n\n","de3ff60e":"**Note:** We dont have to create a mask variable to get the filtering working, but it makes it look a bit nicer","286d4de1":"Now let's use `loc` to access the elemets\n","99832967":"# Filtering data\n\nNow that we know how to navigate Series and DataFrames, we can search of specific data within these object. We do that by filtering using comparisions.\n\nWe'll load in a USA National Parks dataset and start selecting data.","02ff1d06":"In order to make a DataFrame, we'll use `pd.DataFrame`. Normally, we can just pass this function a dictionary of data. With the key, values representing the column name and data respectively.\n\nUse this dictionary to create a DataFrame:\n\n```\nd = {'col1': [1, 2], 'col2': [3, 4]}\n\n```","f42b6e7e":"**You have a DataFrame df with a column 'A' of integers. For example:**\n\n`df = pd.DataFrame({'A': [1, 2, 2, 3, 4, 5, 5, 5, 6, 7, 7]})`\n\n\n**How do you filter out rows which contain the same integer as the row immediately above?**","d3aa25a5":"**For each calendar month in s, find the mean of values**","132ceafa":"Now, most of the time you will be reading data in from a different source, typically a `.csv` file.\n\nPandas makes this really easy using the `pd.read_csv()` function.\n\nGive it a path to the data source and it will read your data into memory.\n\nLet's give it a go....","27e83f0a":"# Time Series exercises\n**Create a DatetimeIndex that contains each business day of 2015 and use it to index a Series of random numbers. Let's call this Series s.******","5da9609b":"**Select the rows where the animal is a cat and the age is less than 3**","b0d1f6c4":"# Combining DataFrames\nThe joins in pandas are basically the same as SQL joins. \n<img src=\"http:\/\/www.datasciencemadesimple.com\/wp-content\/uploads\/2017\/09\/join-or-merge-in-python-pandas-1.png\">","223a3e89":"We can sort based on max\/min or alphabeta as well...\n","8b0b9749":"**Display a summary of the basic information about this DataFrame and its data.**","d191b602":"# Visulizations\nThis could and will be a meetup onto itself. `pandas` has built in plotting features based on the popular visualization package `matplotlib`.\nAll the documentataion can be found [here](https:\/\/matplotlib.org\/users\/index.html)\n\nBut in essence these are the basic parameters you'll need to get up and running:\n\n* `kind` \u2014 \u2018bar\u2019,\u2019barh\u2019,\u2019pie\u2019,\u2019scatter\u2019,\u2019kde\u2019 etc\n* `color` \u2014 Hex codes corresponding colour variants.\n* `linestyle` \u2014 \u2018solid\u2019, \u2018dotted\u2019, \u2018dashed\u2019\n* `xlim`, `ylim` \u2014 Tuple representing the lower limit and upper limit of axes\n* `legend`\u2014 Displays legend\n* `labels` \u2014  Descriptive names for the legend\n* `title` \u2014 Title of the plot","1b0a8497":"**Calculate the sum of all visits (the total number of visits).**","57eb2a73":"Another useful tool is finding the occurances of values within a column.\n* `df['colum_of_interest'].value_counts()`","2f977001":"**For each group of four consecutive calendar months in s, find the date on which the highest value occurred**\n\nThis one blew my mind- check out the `TimeGrouper` function","e7a2261b":"* **Note** Notice the indexing here? It's kept the same indexing from each of the DataFrames... This can be dangerous. Select the row with an index of `1` and see what we mean?","2a1a608b":"So we can now select rows from certain columns based on missing data....\n","ffff458b":"Let's only look at the States from this subset...","1b000dd9":"**Return the first 3 rows of the DataFrame df.**","91dc5f10":"And we can access columns similarly to that of a dictionary\n\n`DataFrame['column name']`\n\nTry and access `col2`...","c1181dec":"**Select the rows where the age is missing, i.e. is NaN.**","d40233aa":"**Append a new row 'k' to df with your choice of values for each column. Then delete that row to return the original DataFrame.**","58f30d75":"**Find the sum of the values in s for every Wednesday**","41c9551a":"Just like lists we can store anything we want in a Series Check out list_c.\n\nIt has integers, strings, lists, sets, classes, functions and floats stored in a single Series","c9b5fb14":"Data can be an absolute nightmare to load in. Here are a few parameters we can use to make data loading that bit easier.\n* If your data is separated using something thats not a `,` use the `sep` param.  eg `sep='|'`\n* If you want to skip rows use `skiprows=n`\n* If the datasets columns are super messy try `error_bad_lines=False`\n\nThese are just a few that I used in work today... but there are many many more.\n\nCheck out the [documentation](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.read_csv.html) for more.","be56e169":"**The From_To column would be better as two separate columns! Split each string on the underscore delimiter _ to give a new temporary DataFrame with the correct values. Assign the correct column names to this temporary DataFrame.**","eada948d":"**Create a DataFrame df from this dictionary data which has the index labels.**","b0793041":"# Filtering","6f391f3d":"## Cleaning Data\n\n### Making a DataFrame easier to work with\n\nTake this monstrosity as the DataFrame to use in the following puzzles:","b9d17525":"Use the `merge()` function and experiment with the `on` and `how` parameters. ","03fd7577":"pandas `crosstab` allows us to create cross-tabulation tables that can show the frequency with which certain groups of data appear. Perfect for classification model evaluations","88afacd1":"**How do you count how many unique rows a DataFrame has (i.e. ignore all rows that are duplicates)?**","df62825e":"Chances are when you load in a dataset the datetime column will be in a `str` format. We can convert them to the correct type using `pd.to_datetime`.","46907ca5":"**You have a DataFrame that consists of 2 columns of floating--point numbers. Suppose that exactly 3 entries in each row are NaN values. For each row of the DataFrame, find the column which contains the third NaN value.**\n\nMy favourite one of the night","f248b379":"** Some values in the the FlightNumber column are missing. These numbers are meant to increase by 10 with each row so 10055 and 10075 need to be put in place. Fill in these missing numbers and make the column an integer column (instead of a float column).**","14d8e593":"We'll build a custom function that we can apply to each row in a column. Like we said, it can be anything you like, just use this template"}}