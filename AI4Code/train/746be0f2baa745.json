{"cell_type":{"ec95c40d":"code","050e8570":"code","4ca78c9f":"code","d0c747c0":"code","54c4882c":"code","a22f4ed9":"code","1938249f":"code","a58953f2":"code","df32df95":"code","8c874d9e":"code","cab9c174":"code","149dcce3":"code","2eec1f85":"code","eb58977f":"code","31720053":"code","500801c1":"code","a73e6380":"code","020cbe2b":"code","dcfbf05e":"code","2993d5d2":"code","04359c1e":"code","c9d83144":"code","453ca48c":"code","fa36ed6f":"code","52318716":"code","027b69d4":"code","cbf8a48d":"code","79b2c6a3":"code","b9c979fa":"code","e98b82ef":"code","175f6289":"code","d5b56c8e":"code","6510a13e":"code","eb1db68b":"code","b9fea198":"code","8ea3c2e6":"code","6bc4c160":"code","8b75d260":"code","db2e004b":"code","dc460055":"code","53a832ee":"code","5fd9e812":"code","51f76af1":"code","0eef6bd0":"code","6dc99837":"code","99944b9b":"code","e462357c":"code","17eac4e8":"code","96a568f6":"code","0f8aef33":"code","c00b7edb":"code","38832a83":"markdown"},"source":{"ec95c40d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns \nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report\n%matplotlib inline\nimport IPython.display as display\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","050e8570":"train_data = pd.read_csv ( \"..\/input\/widsdatathon2021\/TrainingWiDS2021.csv\")\ntest_data = pd.read_csv(\"..\/input\/widsdatathon2021\/UnlabeledWiDS2021.csv\")\nUnlabeledWiDS2021 = \"..\/input\/widsdatathon2021\/UnlabeledWiDS2021.csv\"","4ca78c9f":"print(train_data.shape)","d0c747c0":"train_data.head(5)","54c4882c":"train_data=train_data.drop(['Unnamed: 0'],axis=1)","a22f4ed9":"y_train=train_data['diabetes_mellitus']","1938249f":"train_data=train_data.drop(['diabetes_mellitus'],axis=1)","a58953f2":"train_data.dtypes","df32df95":"train_data=train_data.drop(['encounter_id','hospital_id'],axis=1)","8c874d9e":"categorical_features=[]\nfor features in train_data.columns:\n    if (train_data[features]).dtype=='O':\n        categorical_features.append(features)","cab9c174":"numerical_features=[]\nfor features in train_data.columns:\n    if (train_data[features]).dtype=='int' or (train_data[features]).dtype=='float':\n        numerical_features.append(features)","149dcce3":"len(numerical_features)","2eec1f85":"def missing_count(df):\n    missing_count = df.isna().sum()\n    missing_df = (pd.concat([missing_count.rename('Missing count'),\n                     missing_count.div(len(df))\n                          .rename('Missing ratio')],axis = 1)\n             .loc[missing_count.ne(0)])\n    return missing_df.sort_values(by=\"Missing ratio\")","eb58977f":"missing_df = missing_count(train_data)\n\n\ndisplay.display(missing_df)\n","31720053":"column_nan_miss = missing_df[missing_df[\"Missing ratio\"]>.3].index.to_list()\ntrain_data.drop(columns=column_nan_miss, inplace = True)\ntest_data.drop(columns=column_nan_miss, inplace = True)","500801c1":"column_nan_miss","a73e6380":"test_data=test_data.drop(['Unnamed: 0','encounter_id','hospital_id'],axis=1)","020cbe2b":"count_values = train_data.dropna().nunique().reset_index()\nonly_one = count_values[count_values[0]<2][\"index\"].to_list()\n\ntrain_data.drop(columns=only_one, inplace = True)\ntest_data.drop(columns=only_one, inplace = True)","dcfbf05e":"only_one","2993d5d2":"print(train_data.shape,test_data.shape)","04359c1e":"from sklearn.ensemble import RandomForestClassifier ","c9d83144":"df=pd.get_dummies(train_data[categorical_features])","453ca48c":"train_data=pd.concat([train_data,df],axis=1)","fa36ed6f":"train_data=train_data.drop(labels=categorical_features,axis=1)","52318716":"test_data","027b69d4":"df2=pd.get_dummies(test_data[categorical_features])","cbf8a48d":"test_data=pd.concat([test_data,df2],axis=1)","79b2c6a3":"test_data=test_data.drop(labels=categorical_features,axis=1)","b9c979fa":"train_data.shape","e98b82ef":"test_data.shape","175f6289":"test_data.columns","d5b56c8e":"col=[]\nfor i in train_data.columns:\n    if i not in test_data.columns:\n        col.append(i)","6510a13e":"train_data=train_data.drop(labels=col,axis=1)","eb1db68b":"train_data.shape","b9fea198":"for i in train_data.columns:\n    if (train_data[i]).dtype=='int32' or(train_data[i]).dtype=='float64' :\n        train_data[i] =train_data[i].fillna(train_data[i].mean())\n        test_data[i]=test_data[i].fillna(train_data[i].mean())","8ea3c2e6":"clf=RandomForestClassifier(n_estimators=200,random_state=42)","6bc4c160":"train_data.isnull().sum()","8b75d260":"clf.fit(train_data,y_train)","db2e004b":"feature_importances={}\nfor i,j in zip(train_data.columns,clf.feature_importances_):\n    feature_importances[i]=(j*100)\n\n    ","dc460055":"feature_imp=pd.DataFrame.from_dict(feature_importances, orient='index')","53a832ee":"x=feature_imp.sort_values(by=0,ascending=False)[0:7]\n\n","5fd9e812":"x.columns=['Significance value']\nx","51f76af1":"most_imp_features=x.index","0eef6bd0":"most_imp_features","6dc99837":"final_trainset=train_data[most_imp_features]\nfinal_testset=test_data[most_imp_features]","99944b9b":"print(final_trainset.shape,final_testset.shape)","e462357c":"from sklearn.ensemble import GradientBoostingClassifier\n","17eac4e8":"final_clf=GradientBoostingClassifier(n_estimators=400,max_depth=None,random_state=42, max_features='log2')","96a568f6":"final_clf.fit(final_trainset,y_train)","0f8aef33":"y_pred     = final_clf.predict_proba(final_testset)\n\nencounter_IDs = pd.read_csv(UnlabeledWiDS2021)[[\"encounter_id\"]].values\ndf_sub = {'encounter_id': encounter_IDs[:,0], 'diabetes_mellitus': y_pred[:,1]}\ndf_predictions = pd.DataFrame.from_dict(df_sub).set_index(['encounter_id'])\ndf_predictions.to_csv('submission.csv')\n\n","c00b7edb":"df_predictions.shape","38832a83":"**Beginner**"}}