{"cell_type":{"e762ba9e":"code","5ac540df":"code","ee0724ff":"code","eb089102":"code","a3328379":"code","53346596":"code","c17215d4":"code","a0d37af1":"code","2592344d":"code","f6d9444e":"code","923a4187":"code","a63ebff6":"code","ccf2c679":"code","a7ffc77e":"code","5f0cf016":"code","18d83282":"code","b4d9394b":"code","481a293d":"code","bf668884":"code","7edfabf0":"code","b0e8f2d7":"code","de869534":"code","aab45382":"code","e816ef43":"code","b1af1c7f":"code","a594f02e":"code","c35de10b":"code","74d010aa":"code","e8d690af":"code","3ba9f537":"code","e72e90da":"code","6b842dcf":"code","6f61936c":"code","27008fd5":"code","25da4d39":"code","0333eaca":"code","5a25c622":"code","1c8fd726":"code","23eb5226":"code","21031154":"code","37a3b358":"code","74ebbd3a":"code","d4e24a30":"code","6651f472":"code","3fdb7a3c":"code","5ffabd0c":"code","31cd3a97":"code","6d79e638":"code","4ccd0949":"code","a2bfc0e2":"code","e4a29e32":"code","eff14eeb":"code","62cdd03a":"code","440c402a":"code","b0330720":"code","a2267744":"code","bf3b274e":"code","dbb6212b":"code","e920995b":"code","b87071cc":"code","18dd84e5":"code","9dfc7c72":"code","65593e06":"code","6f69025e":"code","6ee36033":"code","dc203af1":"code","4580879b":"code","e122008f":"code","47676c39":"code","5378a385":"code","5af1a9c2":"code","c060af7b":"code","178c48a1":"code","f77f8327":"code","bc24cd97":"code","a922b828":"code","0f0aae9a":"code","f17ede33":"code","e48877a0":"code","954eb748":"code","a45765dc":"code","b56a5b6b":"code","78ff58b7":"code","7fcd7b9b":"code","56f9ad9c":"code","9cea22ea":"code","ac15bf0d":"code","53d4cef9":"code","8d8c53dd":"code","cb7cfa52":"markdown","81980839":"markdown","b7d92b3c":"markdown","24f97597":"markdown","93beb172":"markdown","38263a67":"markdown","ff7211b9":"markdown","fb92de56":"markdown","f22c279d":"markdown","5feaa769":"markdown","781051f8":"markdown","dc7d0ec5":"markdown","a003ffef":"markdown","e3b87f7c":"markdown","1f51fd98":"markdown","79705747":"markdown","2a5f679d":"markdown","5a4714d0":"markdown","61d12fb7":"markdown","4796f297":"markdown"},"source":{"e762ba9e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5ac540df":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import datasets, metrics, model_selection, svm\nimport missingno as msno\n\nimport numpy as np\nimport pandas as pd \nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nimport seaborn as sns\nfrom sklearn.preprocessing import scale \nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.metrics import roc_auc_score,roc_curve\nimport statsmodels.formula.api as smf\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import tree\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')\n\npd.set_option('display.max_columns', None)","ee0724ff":"!pip install ycimpute","eb089102":"from ycimpute.imputer import iterforest,EM\nfrom fancyimpute import KNN\nfrom sklearn.preprocessing import OrdinalEncoder","a3328379":"encoder=OrdinalEncoder()\nimputer=KNN()\n\ndef encode(data):\n    '''function to encode non-null data and replace it in the original data'''\n    #retains only non-null values\n    nonulls = np.array(data.dropna())\n    #reshapes the data for encoding\n    impute_reshape = nonulls.reshape(-1,1)\n    #encode date\n    impute_ordinal = encoder.fit_transform(impute_reshape)\n    #Assign back encoded values to non-null values\n    data.loc[data.notnull()] = np.squeeze(impute_ordinal)\n    return data","53346596":"#Ktest_identity = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/test_identity.csv')\nKtest_transaction = pd.read_csv(\"\/kaggle\/input\/ieee-fraud-detection\/test_transaction.csv\")\n#Ktrain_identity = pd.read_csv(\"\/kaggle\/input\/ieee-fraud-detection\/train_identity.csv\")\nKtrain_transaction = pd.read_csv(\"\/kaggle\/input\/ieee-fraud-detection\/train_transaction.csv\")","c17215d4":"df = Ktrain_transaction.copy()\ndf2=Ktest_transaction.copy()\ndel Ktrain_transaction\ndel Ktest_transaction","a0d37af1":"\"\"\"\n# nulls smaller than 60%\nprint(\n    pd.DataFrame(df.isnull().sum()\/len(df)>.7)\n    .loc[pd.DataFrame(df.isnull().sum()\/len(df)>.7)[0]==True].count())\n\nprint(\n    pd.DataFrame(df2.isnull().sum()\/len(df2)>.7)\n    .loc[pd.DataFrame(df2.isnull().sum()\/len(df2)>.7)[0]==True].count())\n\"\"\"","2592344d":"\"\"\"\ndf_to_revome_cols=(\n    pd.DataFrame(df.isnull().sum()\/len(df)>.7)\n    .loc[pd.DataFrame(df.isnull().sum()\/len(df)>.7)[0]==True].T).columns\n\ndf= df.drop(df_to_revome_cols, axis=1)\ndf.shape\n\"\"\"","f6d9444e":"print( df.loc[:,\"addr1\":\"dist2\"].isnull().sum()\/len(df.loc[:,\"addr1\":\"dist2\"]))\nprint('---------------------')\nprint(df2.loc[:,\"addr1\":\"dist2\"].isnull().sum()\/len(df2.loc[:,\"addr1\":\"dist2\"]))","923a4187":"df=df.drop(['dist2'], axis=1)\ndf2=df2.drop(['dist2'], axis=1)","a63ebff6":"addr= df.loc[:,\"addr1\":\"dist1\"]\naddr= pd.DataFrame(EM().complete(np.array(addr)), columns=addr.columns)\naddr2=df2.loc[:,\"addr1\":\"dist1\"]\naddr2= pd.DataFrame(EM().complete(np.array(addr2)), columns=addr2.columns)\n\n# no nulls for C series in df\nc_series2= df2.loc[:,'C1':'C14']\nc_series2= pd.DataFrame(EM().complete(np.array(c_series2)),columns= c_series2.columns)","ccf2c679":"# This is to check missing data greater than 60%\n\nx= pd.DataFrame(df.loc[:,\"D1\":\"D15\"].isnull().sum()\/len(df.loc[:,\"D1\":\"D15\"])>0.6)\nx=x.loc[x[0]==True]\nx_col=x.T.columns\nprint('---------------------')\nx2= pd.DataFrame(df2.loc[:,\"D1\":\"D15\"].isnull().sum()\/len(df2.loc[:,\"D1\":\"D15\"])>0.6)\nx2= x2.loc[x2[0]==True]\nx2_col=x.T.columns\n\nprint(x_col)\nprint(x2_col)","a7ffc77e":"df= df.drop(x_col, axis=1)\ndf2=df2.drop(x2_col, axis=1)","5f0cf016":"d_series= df.loc[:,'D1':'D15']\nd_series= pd.DataFrame(EM().complete(np.array(d_series)),columns= d_series.columns)\n\nd_series2= df2.loc[:,'D1':'D15']\nd_series2= pd.DataFrame(EM().complete(np.array(d_series2)),columns= d_series2.columns)","18d83282":"# cards have some are categorical data\ncard1card6= df.loc[:,'card1':'card6']\nfor i in card1card6:\n    encode(card1card6[i])\n    \ncard1card6_2= df2.loc[:,'card1':'card6']\nfor i in card1card6_2:\n    encode(card1card6_2[i])\n    \ncard1card6= pd.DataFrame(EM().complete(np.array(card1card6)), columns=card1card6.columns) \ncard1card6_2= pd.DataFrame(EM().complete(np.array(card1card6_2)), columns=card1card6_2.columns)","b4d9394b":"# This is to check missing data greater than 60%\n\nx= pd.DataFrame(df.loc[:,'TransactionID':'R_emaildomain'].isnull().sum()\/len(df.loc[:,'TransactionID':'R_emaildomain'])>0.6)\nx=x.loc[x[0]==True]\nx_col=x.T.columns\nprint('---------------------')\nx2= pd.DataFrame(df2.loc[:,'TransactionID':'R_emaildomain'].isnull().sum()\/len(df2.loc[:,'TransactionID':'R_emaildomain'])>0.6)\nx2= x2.loc[x2[0]==True]\nx2_col=x.T.columns\n\nprint(x_col)\nprint(x2_col)","481a293d":"# we will delete R_emaildomain after filled b\/c encode defdoesn't work in series\n\ndomain= df.loc[:,'P_emaildomain':'R_emaildomain']\ndomain2=df2.loc[:,'P_emaildomain':'R_emaildomain']\n\nfor i in domain:\n    encode(domain[i])\n    \nfor i in domain2:\n    encode(domain2[i])\n    \ndomain= pd.DataFrame(EM().complete(np.array(domain)), columns=domain.columns)\ndomain2= pd.DataFrame(EM().complete(np.array(domain2)), columns=domain2.columns)","bf668884":"df= df.drop(x_col, axis=1)\ndf2=df2.drop(x2_col, axis=1)","7edfabf0":"# m_ series\n# This is to check missing data greater than 60%\n\nx= pd.DataFrame(df.loc[:,'M1':'M9'].isnull().sum()\/len(df.loc[:,'M1':'M9'])>0.6)\nx=x.loc[x[0]==True]\nx_col=x.T.columns\nprint('---------------------')\nx2= pd.DataFrame(df2.loc[:,'M1':'M9'].isnull().sum()\/len(df2.loc[:,'M1':'M9'])>0.6)\nx2= x2.loc[x2[0]==True]\nx2_col=x.T.columns\n\nprint(x_col)\nprint(x2_col)","b0e8f2d7":"# m series\nm_series = df.loc[:,'M1':'M9']\n\nfor i in m_series:\n    encode(m_series[i])\n    \nm_series= pd.DataFrame(EM().complete(np.array(m_series)), columns= m_series.columns)\n# ----------\n\nm_series2 = df2.loc[:,'M1':'M9']\nfor i in m_series2:\n    encode(m_series2[i])\n    \nm_series2= pd.DataFrame(EM().complete(np.array(m_series2)), columns= m_series2.columns)","de869534":"\n# This is to check missing data greater than 60%\n\nx= pd.DataFrame(df.loc[:,'V1':'V11'].isnull().sum()\/len(df.loc[:,'V1':'V11'])>0.6)\nx=x.loc[x[0]==True]\nx_col=x.T.columns\nprint('---------------------')\nx2= pd.DataFrame(df2.loc[:,'V1':'V11'].isnull().sum()\/len(df2.loc[:,'V1':'V11'])>0.6)\nx2= x2.loc[x2[0]==True]\nx2_col=x.T.columns\n\nprint(x_col)\nprint(x2_col)","aab45382":"# v series\nv1v11= df.loc[:,'V1':'V11']\nv1v11= pd.DataFrame(EM().complete(np.array(v1v11)), columns= v1v11.columns)\n\nv12v34= df.loc[:,'V12':'V34']\nv12v34= pd.DataFrame(EM().complete(np.array(v12v34)), columns= v12v34.columns)\n\nv35v52= df.loc[:,\"V35\":\"V52\"]\nv35v52= pd.DataFrame(EM().complete(np.array(v35v52)), columns=v35v52.columns)\n\nv53v74= df.loc[:,'V53':'V74']\nv53v74= pd.DataFrame(EM().complete(np.array(v53v74)), columns=v53v74.columns)","e816ef43":"v1v11_2= df2.loc[:,'V1':'V11']\nv1v11_2= pd.DataFrame(EM().complete(np.array(v1v11_2)), columns= v1v11_2.columns)\n\nv12v34_2= df2.loc[:,'V12':'V34']\nv12v34_2= pd.DataFrame(EM().complete(np.array(v12v34_2)), columns= v12v34_2.columns)\nv35v52_2= df2.loc[:,\"V35\":\"V52\"]\nv35v52_2= pd.DataFrame(EM().complete(np.array(v35v52_2)), columns=v35v52_2.columns)\nv53v74_2= df2.loc[:,'V53':'V74']\nv53v74_2= pd.DataFrame(EM().complete(np.array(v53v74_2)), columns=v53v74_2.columns)","b1af1c7f":"# This is to check missing data greater than 60%\n\nx= pd.DataFrame(df.loc[:,\"V138\":\"V166\"].isnull().sum()\/len(df.loc[:,\"V138\":\"V166\"])>0.6)\nx=x.loc[x[0]==True]\nx_col=x.T.columns\n\n#'---------------------')\n\nx2= pd.DataFrame(df2.loc[:,\"V138\":\"V166\"].isnull().sum()\/len(df2.loc[:,\"V138\":\"V166\"])>0.6)\nx2= x2.loc[x2[0]==True]\nx2_col=x.T.columns\n\nprint(x_col)\nprint('---------------------')\nprint(x2_col)","a594f02e":"v75v94= df.loc[:,\"V75\":\"V94\"]\nv75v94= pd.DataFrame(EM().complete(np.array(v75v94)), columns=v75v94.columns)\nv95v137= df.loc[:,\"V95\":\"V137\"]\nv95v137= pd.DataFrame(EM().complete(np.array(v95v137)), columns=v95v137.columns)\n#v138-v166 dropped\n#v167-v278 dropped\nv279v321 = df.loc[:,\"V279\":\"V321\"]\nv279v321= pd.DataFrame(EM().complete(np.array(v279v321)), columns=v279v321.columns)","c35de10b":"v75v94_2= df2.loc[:,\"V75\":\"V94\"]\nv75v94_2= pd.DataFrame(EM().complete(np.array(v75v94_2)), columns=v75v94_2.columns)\nv95v137_2= df.loc[:,\"V95\":\"V137\"]\nv95v137_2= pd.DataFrame(EM().complete(np.array(v95v137_2)), columns=v95v137_2.columns)\n#v138-v166 dropped\n#v167-v278 dropped\nv279v321_2 = df.loc[:,\"V279\":\"V321\"]\nv279v321_2= pd.DataFrame(EM().complete(np.array(v279v321_2)), columns=v279v321_2.columns)","74d010aa":"dms= pd.get_dummies(df['ProductCD'])\ndms.columns = ['ProductCD_C', 'ProductCD_H', 'ProductCD_R', 'ProductCD_S','ProductCD_W|']\n\ndms2= pd.get_dummies(df2['ProductCD'])\ndms2.columns = ['ProductCD_C', 'ProductCD_H', 'ProductCD_R', 'ProductCD_S','ProductCD_W|']\ndms2.head()","e8d690af":"domain=domain.drop([\"R_emaildomain\"], axis=1)\ndomain2=domain2.drop([\"R_emaildomain\"], axis=1)","3ba9f537":"df_ = df.loc[:,\"TransactionID\":\"TransactionAmt\"]\ndf2_= df2.loc[:,\"TransactionID\":\"TransactionAmt\"]","e72e90da":"print(df_.shape)\nprint(df2_.shape)","6b842dcf":"'''\nvars_to_removed=(card1card6.columns,\n                 addr.columns,\n                 d_series.columns,\n                 domain.columns,\n                 m_series.columns,\n                 v1v11.columns,\n                 v12v34.columns,\n                 v35v52.columns,\n                 v53v74.columns,\n                 v75v94.columns,\n                 v95v137.columns,\n                 v279v321.columns)\n\nfor i in vars_to_removed:\n    df_=df.drop(i, axis=1)\n\ndf_=df.drop([\"ProductCD\"], axis=1)\ndf_.shape\n'''","6f61936c":"'''\nvars_to_removed=(card1card6_2.columns,\n                 addr2.columns,\n                 d_series2.columns,\n                 domain2.columns,\n                 m_series2.columns,\n                 v1v11_2.columns,\n                 v12v34_2.columns,\n                 v35v52_2.columns,\n                 v53v74_2.columns,\n                 v75v94_2.columns,\n                 v95v137_2.columns,\n                 v279v321_2.columns)\n\nfor i in vars_to_removed:\n    df2=df2.drop(i, axis=1)\n\ndf2=df2.drop([\"ProductCD\"], axis=1)\ndf.shape\n'''","27008fd5":"\nvars_to_reload=(card1card6,\n                 addr,\n                 d_series,\n                 domain,\n                 m_series,\n                 v1v11,\n                 v12v34,\n                 v35v52,\n                 v53v74,\n                 v75v94,\n                 v95v137,\n                 v279v321,\n                 dms)\n\nfor i in vars_to_reload:\n    df_=pd.concat([df_,i], axis=1)\ndf_.shape","25da4d39":"df_.head()","0333eaca":"vars_to_repload=(card1card6_2,\n                 addr2,\n                 d_series2,\n                 domain2,\n                 m_series2,\n                 v1v11_2,\n                 v12v34_2,\n                 v35v52_2,\n                 v53v74_2,\n                 v75v94_2,\n                 v95v137_2,\n                 v279v321_2,\n                 dms2)\n\nfor i in vars_to_reload:\n    df2_=pd.concat([df2_,i], axis=1)\ndf2_.head()","5a25c622":"print(df_.shape)\nprint(df2_.shape)","1c8fd726":"import gc\ndelete = (card1card6,\n          addr,\n          d_series,\n          domain,\n          m_series,\n          v1v11,\n          v12v34,\n          v35v52,\n          v53v74,\n          v75v94,\n          v95v137,\n          v279v321,\n          card1card6_2,\n          addr2,\n          d_series2,\n          domain2,\n          m_series2,\n          v1v11_2,\n          v12v34_2,\n          v35v52_2,\n          v53v74_2,\n          v75v94_2,\n          v95v137_2,\n          v279v321_2)\nfor i in delete:\n    del i\n    gc.collect()","23eb5226":"del delete\ngc.collect()","21031154":"Ktrain_identity = pd.read_csv(\"\/kaggle\/input\/ieee-fraud-detection\/train_identity.csv\")\ndf1= Ktrain_identity\n\ndf1_col= pd.DataFrame(df1.isnull().sum()\/len(df1)>.6).loc[(df1.isnull().sum()\/len(df1)>.6)==True].T.columns\ndf1=df1.drop(df1_col, axis=1)\nprint(df1.shape)\ndf1.info()","37a3b358":"df1_cat = df1.select_dtypes(include='object')\ndf1_cat.nunique()","74ebbd3a":"df1_cat.isnull().sum()\/len(df1_cat)","d4e24a30":"# crowded cat data\ndf1_cat1=df1_cat.drop([\"id_30\",\"id_31\",\"id_33\",\"DeviceInfo\"], axis=1)","6651f472":"df1_cat1.shape","3fdb7a3c":"for i in df1_cat1:\n    encode(df1_cat1[i])\ndf1_cat1.head()","5ffabd0c":"df1_cat1= pd.DataFrame(EM().complete(np.array(df1_cat1)), columns=df1_cat1.columns)\ndf1_cat1.isnull().sum().any()","31cd3a97":"df1_cat1","6d79e638":"df1_cat2=pd.concat([df1['id_30'],df1['id_31'],df1['id_33'],df1['DeviceInfo']], axis=1)\ndf1_cat2.head()","4ccd0949":"df1_cat2[\"id_30\"].value_counts(dropna=False).count()","a2bfc0e2":"df1_cat2['id_30a']=df1_cat2['id_30'].str.slice(0,3)\ndf1_cat2['id_30a']=df1_cat2['id_30a'].str.lower()\ndf1_cat2['id_30a'].value_counts(dropna=False).count()","e4a29e32":"df1_cat2['id_31'].nunique()","eff14eeb":"df1_cat2['id_31a']=df1_cat2['id_31'].str.lower()\ndf1_cat2['id_31a']=df1_cat2['id_31a'].str.slice(0,3)\ndf1_cat2['id_31a'].nunique()","62cdd03a":"df1_cat2['DeviceInfo'].nunique()","440c402a":"df1_cat2['DeviceInfo_a']= df1['DeviceInfo'].str.slice(0,2)\ndf1_cat2['DeviceInfo_a']=df1_cat2['DeviceInfo_a'].str.lower()\ndf1_cat2['DeviceInfo_a'].nunique()","b0330720":"df1_cat2.head()","a2267744":"df1_cat2= df1_cat2.drop(['id_30','id_31','DeviceInfo'], axis=1)","bf3b274e":"df1_cat2","dbb6212b":"for i in df1_cat2:\n    encode(df1_cat2[i])\ndf1_cat2.head()\n\ndf1_cat2= pd.DataFrame(EM().complete(np.array(df1_cat2)), columns=df1_cat2.columns)","e920995b":"df1_cat2","b87071cc":"#df1_=df1.drop(df1_cat1.columns, axis=1)\n#df1_=df1_.drop(['id_30','id_31','id_33','DeviceInfo'],axis=1)\ndf1_cat= pd.concat([df1_cat1,df1_cat2], axis=1)","18dd84e5":"df1_cat","9dfc7c72":"df1.info()","65593e06":"df1_cont = df1.select_dtypes(include='float64')\ndf1_cont.nunique()","6f69025e":"df1_cont.isnull().sum()\/len(df1_cont)","6ee36033":"df1_cont=pd.DataFrame(EM().complete(np.array(df1_cont)), columns=df1_cont.columns)\ndf1_cont.isnull().sum().any()","dc203af1":"df1_=pd.concat([df1[\"TransactionID\"],df1_cont,df1_cat], axis=1 )","4580879b":"df1_","e122008f":"del Ktrain_identity\ndel df1_cat\ndel df1_cat1\ndel df1_cat2\ndel df1_cont\ngc.collect()","47676c39":"Ktest_identity = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/test_identity.csv')\ndf3= Ktest_identity\ndel Ktest_identity\ndf3_col= pd.DataFrame(df3.isnull().sum()\/len(df3)>.6).loc[(df3.isnull().sum()\/len(df3)>.6)==True].T.columns\ndf3=df3.drop(df3_col, axis=1)\ndf3_cat = df3.select_dtypes(include='object')\nprint(df3.shape)\ndf3_cat.nunique()","5378a385":"df3_cat.isnull().sum()\/len(df3_cat)","5af1a9c2":"# crowded cat data\ndf3_cat1=df3_cat.drop([\"id-30\",\"id-31\",\"id-33\",\"DeviceInfo\"], axis=1)\n\nfor i in df3_cat1:\n    encode(df3_cat1[i])\ndf3_cat1.head()\n\ndf3_cat1= pd.DataFrame(EM().complete(np.array(df3_cat1)), columns=df3_cat1.columns)\ndf3_cat1","c060af7b":"df3_cat2=pd.concat([df3['id-30'],df3['id-31'],df3['id-33'],df3['DeviceInfo']], axis=1)\ndf3_cat2.shape","178c48a1":"# make these cat. data larger groups\n\ndf3_cat2['id-30a']=df3_cat2['id-30'].str.slice(0,3)\ndf3_cat2['id-30a']=df3_cat2['id-30a'].str.lower()\n\ndf3_cat2['id-31a']=df3_cat2['id-31'].str.lower()\ndf3_cat2['id-31a']=df3_cat2['id-31a'].str.slice(0,3)\n\ndf3_cat2['DeviceInfo_a']= df3['DeviceInfo'].str.slice(0,2)\ndf3_cat2['DeviceInfo_a']=df3_cat2['DeviceInfo_a'].str.lower()\n\ndf3_cat2=df3_cat2.drop([\"id-30\", \"id-31\", \"DeviceInfo\"], axis=1)\n\ndf3_cat2.head()","f77f8327":"# covert to numbers \/ fill nulls\nfor i in df3_cat2:\n    encode(df3_cat2[i])\n\ndf3_cat2= pd.DataFrame(EM().complete(np.array(df3_cat2)), columns=df3_cat2.columns)","bc24cd97":"df3_cat2","a922b828":"df3_cat = pd.concat([df3_cat1, df3_cat2], axis=1)\ndf3_cat","0f0aae9a":"df3_cont=df3.select_dtypes(include='float64')\ndf3_cont=pd.DataFrame(EM().complete(np.array(df3_cont)), columns=df3_cont.columns)\ndf3_=pd.concat([df3[\"TransactionID\"],df3_cont,df3_cat], axis=1 )\nprint(df3_.shape)\ndf3_","f17ede33":"print(df1_.shape, df3_.shape)","e48877a0":"\nprint(df_.shape, df1.shape)\nprint(df2_.shape, df3.shape)","954eb748":"Ktrain= pd.merge(df_,df1_, on='TransactionID', how='left')\nKtest= pd.merge(df2_,df3_, on='TransactionID', how='left')","a45765dc":"print(Ktrain.shape)\nprint(Ktest.shape)","b56a5b6b":"%%time\n# From kernel https:\/\/www.kaggle.com\/gemartin\/load-data-reduce-memory-usage\n# WARNING! THIS CAN DAMAGE THE DATA \ndef reduce_mem_usage2(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df","78ff58b7":"%%time\nKtest = reduce_mem_usage2(Ktest)\nKtrain = reduce_mem_usage2(Ktrain)","7fcd7b9b":"print(Ktrain.shape)\nKtrain.head()","56f9ad9c":"print(Ktest.shape)\nKtest.head()","9cea22ea":"id=Ktrain['TransactionID']\ny= Ktrain['isFraud']\nX=Ktrain.drop(['isFraud','TransactionID'], axis=1).astype('float64')\nX_train,X_test,y_train,y_test= train_test_split(X,y, test_size=0.25, random_state=40)","ac15bf0d":"lgb_model=LGBMClassifier().fit(X_train,y_train)\ny_pred= lgb_model.predict(X_test)\nnp.sqrt(accuracy_score(y_test, y_pred))","53d4cef9":"Ktest_id=(Ktest[\"TransactionID\"])\n# Ktest_id= Ktest_id.astype(\"int64\")\nX_Ktest= Ktest.drop(['TransactionID'], axis=1).astype(\"float64\")\nKtest_pred= lgb_model.predict(X_Ktest)","8d8c53dd":"predictions=lgb_model.predict_proba(X_Ktest)[:,1]\noutput=pd.DataFrame({'TransactionID':Ktest_id, 'isFraud':predictions })\noutput=output.loc[pd.DataFrame(output[\"TransactionID\"].isnull())[\"TransactionID\"]==False]\noutput[\"TransactionID\"]= output[\"TransactionID\"].astype('int64')\noutput.to_csv('submission_lgbm.csv', index=False)","cb7cfa52":"# ML Algorithm","81980839":"make these cat. data larger groups","b7d92b3c":"drop old columns\/ covert to numbers \/ fill nulls","24f97597":"# df3= test_indentity------------------------------\n\n* same as train_identity","93beb172":"### Encoding","38263a67":"### df3_cat2","ff7211b9":"### df3_cat1","fb92de56":"## Merge train tables","f22c279d":"### fill nulls by EM Algorithm","5feaa769":"### df1_cat2","781051f8":"### replace with corrected cat. data","dc7d0ec5":"* train_transaction, train_identity tables are ready!","a003ffef":"### Numeric Data manipulation","e3b87f7c":"### remove old data to be replaced","1f51fd98":"### categorical data \/ filling nulls","79705747":"### df3_cont","2a5f679d":" # df1= Ktrain_indentity -----------------------------------","5a4714d0":"### remove columns nulls of which are greater than 60%","61d12fb7":"### concatenate corrected data with df","4796f297":"# df = Ktrain_transaction \/ df2= Ktest_transaction------------------------------"}}