{"cell_type":{"7501dd8f":"code","b0a18106":"code","20098410":"code","261ef72c":"code","bdc5a60a":"code","c31b1f15":"code","24389c3b":"code","db4330dd":"code","281c15a1":"code","93461d74":"code","c43fe7c4":"code","ec0d43c5":"code","25d55f0e":"code","0c29cfc7":"code","59232d28":"code","e74247ca":"code","d8329a4f":"code","b11ae183":"code","72848a66":"code","a813eb4c":"code","a15381b8":"code","7fd53a3b":"code","8b5552f7":"code","455eee7b":"code","a9e83fdb":"code","ab9ae8c0":"code","f1e06c93":"code","348dc351":"code","95ea61e9":"code","1817c17d":"code","3fa129be":"code","f6379ccd":"code","48794222":"code","6f8445b0":"code","5854be3a":"code","17004918":"code","759cd19a":"code","c9a35279":"code","216fb18f":"code","30d957a1":"code","5ec40dad":"code","389f5fbe":"code","5573b225":"code","ef70da7d":"code","9cc0ae59":"code","7da6147f":"code","a3b9aa41":"code","df36ae85":"code","7d974e14":"code","31fc8563":"code","d3a4fca0":"code","55f6a605":"code","fea4487d":"code","fc437004":"code","1686df46":"code","6cff871f":"code","28f578f1":"code","cbbfc9c8":"code","35841b96":"code","8d397f6c":"code","11312208":"code","3f226712":"code","9384cf9b":"code","3f89d3fc":"code","1bba859e":"code","ffa95906":"code","f1f6af82":"code","e141a812":"markdown","fefc849a":"markdown","d2d8a0e8":"markdown","a8c1cc26":"markdown","1be6f9af":"markdown","f8a7f68b":"markdown","f6c94c74":"markdown"},"source":{"7501dd8f":"#importing necessary packages\nimport pandas as pd\nimport numpy as np \nimport matplotlib\n%matplotlib inline\nfrom matplotlib import pyplot as plt\nimport seaborn as sb","b0a18106":"train= pd.read_csv(\"..\/input\/titanic\/train.csv\")","20098410":"train.head()","261ef72c":"train.isnull().sum()","bdc5a60a":"train.columns","c31b1f15":"train = train.drop(train.columns[[0,3,6,7,8,10,11]], axis = 1)","24389c3b":"train.head()\n#train.dtypes","db4330dd":"train[\"Sex\"]= train[\"Sex\"].astype(\"category\")","281c15a1":"def sex(x):\n    if x ==\"male\":\n        return 1\n    else:\n        return 0","93461d74":"train[\"Sex\"] = train[\"Sex\"].apply(sex)","c43fe7c4":"train.select_dtypes(include=(\"int64\",\"float64\")).describe()\n#we do have missing value for Age her will be handdle befor regression","ec0d43c5":"train[[\"Survived\",\"Sex\"]].describe()","25d55f0e":"#Crossing Freatures : pivot tables\npd.pivot_table(train, \"Survived\", index=\"Pclass\", columns=\"Sex\", aggfunc=np.mean, margins=True,margins_name=\"PropTotal\")","0c29cfc7":"pd.pivot_table(train, \"Age\", index=\"Pclass\", columns=\"Sex\", aggfunc=np.mean, margins=True,margins_name=\"PropTotal\")\n#We notice here that survied man are 3 year old than survived women. Also The survived pepople age decrease as\n#Pclass went from 1 to 3. That me show that people in class 1 have best conditions than the remain. This\n#sound normal as theh best the class is the cheaper the Fare class is(take a look on it down) ","59232d28":"pd.pivot_table(train,\"Fare\" ,[\"Pclass\"], aggfunc=np.mean)\n#we can notice that class 1 fare is 84\/13 times cheaper than class 3 fare","e74247ca":"#looking at the survied dist by Pcal or sex\nimport plotly.express as px\nfig = px.box(train, x=\"Survived\", y=\"Age\", color=\"Sex\",facet_col=\"Pclass\")\nfig.update_layout(autosize=True)\nfig.show()","d8329a4f":"#As the Pclass is function of the fare i decide to only keep Pclass in ma modelisation\n#Choosing features for model","b11ae183":"df = train.drop(train.columns[4], axis = 1)","72848a66":"df.head()","a813eb4c":"df.describe()","a15381b8":"#How missing value  in Age\nage_null = df[df['Age'].isnull()]\n#so we have among 891 records thsi is more than 10%\nage_null.shape[0]","7fd53a3b":"df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].mean(skipna=True))#fil na with mean(Age)","8b5552f7":"df.describe()","455eee7b":"#creating the target and de labels\ndf_labels = df.drop(df.columns[0], axis = 1)","a9e83fdb":"df_labels.head()","ab9ae8c0":"df_target = df.iloc[:,0]","f1e06c93":"df_target.head()","348dc351":"#We first logisticRegression from Sklearn to build and fit the model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LogisticRegressionCV","95ea61e9":"model1 = LogisticRegression()","1817c17d":"model1.fit(df_labels,df_target)","3fa129be":"#our model is build and we can how test it performance and predict values of test dataset","f6379ccd":"#First of all we have to select out labels on test dataset","48794222":"test= pd.read_csv(\"..\/input\/titanic\/test.csv\")","6f8445b0":"test.head()","5854be3a":"test.describe()","17004918":"test[\"Age\"] = test[\"Age\"].fillna(test[\"Age\"].mean(skipna=True))#fil na with mean(Age)","759cd19a":"x_test = test.iloc[:,[0,1,3,4]]","c9a35279":"x_test.head()","216fb18f":"x_test[\"Sex\"] = x_test[\"Sex\"].apply(sex)","30d957a1":"x_test.head()","5ec40dad":"x_for_pred = x_test.iloc[:,[0,1,2,3]]","389f5fbe":"x_for_pred.head()","5573b225":"target_predic = model1.predict(x_for_pred.iloc[:,[1,2,3]])","ef70da7d":"target_predic","9cc0ae59":"full_pred_data = x_for_pred\nfull_pred_data[\"survived\"] = target_predic","7da6147f":"full_pred_data.head()","a3b9aa41":"#Description of my prediction\npd.pivot_table(full_pred_data, \"survived\", [\"Pclass\"], aggfunc=np.mean)","df36ae85":"pd.pivot_table(full_pred_data, \"survived\", [\"Sex\"], aggfunc=np.mean)","7d974e14":"prediction = full_pred_data.iloc[:,[0,4]]","31fc8563":"prediction.head()\nprediction.set_index(\"PassengerId\")","d3a4fca0":"model1.score(df_labels,df_target)","55f6a605":"from sklearn.model_selection import GridSearchCV\nfrom sklearn import linear_model\nlog = linear_model.LogisticRegression(penalty ='l2',solver = 'newton-cg',\n                                      max_iter = 1000,l1_ratio=None,\n                                      multi_class ='ovr')","fea4487d":"hyperparameters = dict(C=np.logspace(0, 4, 10))","fc437004":"clf = GridSearchCV(log, hyperparameters,cv = 5, verbose=0)\n","1686df46":"clf.fit(df_labels,df_target)","6cff871f":"clf.estimator","28f578f1":"target_predic2 =clf.predict(x_for_pred.iloc[:,1:])","cbbfc9c8":"# Create regularization penalty space\npenalty = ['l1', 'l2',\"elasticnet\",\"none\"]\n\n# Create regularization hyperparameter space\nC = np.logspace(0, 4, 10)\n\n#choosen solver\nsolver = ['newton-cg', 'lbfgs', 'liblinear', 'saga']\n# Create hyperparameter options\nhyperparameters = dict(cv = 5,C=np.logspace(0, 4, 10), penalty=['l1', 'l2'])","35841b96":"log2 = LogisticRegressionCV(Cs=10, fit_intercept=True, cv=5, dual=False, penalty=[\"l1\",\"l2\",\"elasticnet\",\"none\"], scoring='f1', \n                     solver=['liblinear','newton-cg', 'lbfgs', 'sag', 'saga'],\n                     tol=0.0001, max_iter=1000, class_weight=None, n_jobs=None, verbose=0, \n                     refit=True, intercept_scaling=1.0, multi_class='auto', random_state=True, l1_ratios=None)","8d397f6c":"log2 = LogisticRegressionCV()","11312208":"target_predic3 = log2.fit(df_labels,df_target)","3f226712":"#first prediction count\nprediction[\"survived\"].value_counts()","9384cf9b":"target_predic3 = log2.predict(x_for_pred.iloc[:,1:])\n","3f89d3fc":"full_pred_data2 = x_for_pred\nfull_pred_data2[\"survived\"] = target_predic2","1bba859e":"prediction2 = full_pred_data2.iloc[:,[0,4]]","ffa95906":"prediction2.head()","f1f6af82":"prediction2[\"survived\"].value_counts()","e141a812":"* Here our pr\u00e9diction is like 94% of woman will survive when only 3.3% of men will","fefc849a":"* The class with high rate of survived still Pclass1 and the last still the Pclass3","d2d8a0e8":"Trying to predict titanic catastroph result. Thsi work is still bettering \n* I first use normal LogisticRegression\n* I know use LogisticRegressionCv to have the best estimator parameters (section :\"LogisticRegressionCv\")","a8c1cc26":"### LogisticRegression with hyper parameter add gridcv","1be6f9af":"## Model score and prediction","f8a7f68b":"Those results show us claerly that women had had more chance to survied that man. In fact : \n* only 18.89% of man has survied, where almost 75% of women did\n* The probability of dying increase as the Pclass went from 1 to 3.\n* So class 1 people has more chance to survive","f6c94c74":"Adding hyper parameter to Logistic regression"}}