{"cell_type":{"38a4ac4c":"code","d3331026":"code","a7286893":"code","be9b5f82":"code","63b738fd":"code","42069e55":"code","1fba6ed2":"code","6451978a":"code","d6cc5567":"code","4e47912d":"code","55397926":"code","b3d2dc80":"code","11f462ce":"code","770168e5":"code","79ba7de3":"code","08717a1d":"code","6c08b82f":"code","67fc92ba":"markdown","d3a4799e":"markdown","756eb743":"markdown","7079f9ae":"markdown","33996b52":"markdown","28ca3515":"markdown","473b7509":"markdown"},"source":{"38a4ac4c":"#All imports\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf","d3331026":"#set seed value for reproducibility\nseed_val=42\n\ntf.random.set_seed(seed_val)\nnp.random.seed(seed_val)","a7286893":"#Read data\ntrain_df = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\ntrain_df.head()","be9b5f82":"train_df.info()","63b738fd":"#Check if any null pixel value\nnull_count = train_df.isnull().sum()\nnull_count[null_count.values > 0].index","42069e55":"#check distribution of samples for each label(i.e digit 0-9)\nsns.countplot(train_df['label'])\nplt.show()","1fba6ed2":"#display few images from train dataset\nfig, ax = plt.subplots(1,5, sharey=True, figsize=(10,6))\n\nfor i in range(5):  \n  img = np.array(train_df.iloc[i, 1:])\n  ax[i].imshow(img.reshape(28,28))","6451978a":"IMG_SHAPE =28\nBATCH_SZ=64","d6cc5567":"X = train_df.iloc[:,1:]\ny = train_df.iloc[:,0]\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8, random_state=100)","4e47912d":"#reshape the images\ndef preprocess_img(img):\n  img = np.array(img, dtype=np.float32)\n  img = img.reshape(IMG_SHAPE, IMG_SHAPE) \n  img = img[:,:,np.newaxis]\n  return img","55397926":"#Convert datasets to rank 4 dimension(#ofsamples, height, width, depth)\nX_train = X_train.apply(lambda x:preprocess_img(x), axis=1)\nX_val = X_val.apply(lambda x:preprocess_img(x), axis=1)\n\nX_train = np.stack(X_train)\nX_val = np.stack(X_val)\n\ny_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\ny_val = tf.keras.utils.to_categorical(y_val, num_classes=10)","b3d2dc80":"data_gen = tf.keras.preprocessing.image.ImageDataGenerator(featurewise_center=True,\n                                                           featurewise_std_normalization=True\n                                                           )\n\n#compute statistics to perform standardization\ndata_gen.fit(X_train)\n\n#perform standardization on validation data\ndata_gen.standardize(X_val)","11f462ce":"#Define CNN\nmodel = tf.keras.models.Sequential([\n          tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_SHAPE,IMG_SHAPE, 1)),\n          tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n          \n          tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n          tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n          \n          tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n          tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n          \n          tf.keras.layers.Dropout(0.2),\n          \n          tf.keras.layers.Flatten(),    \n\n          tf.keras.layers.Dense(512, activation='relu'),\n          tf.keras.layers.Dropout(0.2),\n          tf.keras.layers.Dense(10, activation='softmax')\n        ])\n\nmodel.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])","770168e5":"#stop iterations if model does not show any improvement for 50 consecutive epochs\nmodel_checkpoint = tf.keras.callbacks.ModelCheckpoint('best_model.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',patience=50, mode='max')\n\nmodel.fit(data_gen.flow(X_train,y_train,batch_size=BATCH_SZ),\n          steps_per_epoch=np.ceil(len(X_train)\/BATCH_SZ),\n          epochs=100,\n          validation_data=(X_val, y_val),\n          validation_steps = np.ceil(len(X_val)\/BATCH_SZ),\n          callbacks = [model_checkpoint, early_stopping]          \n          )","79ba7de3":"final_model = tf.keras.models.load_model('.\/best_model.h5')","08717a1d":"#reshape the data\nX_test = test_df.apply(lambda x:preprocess_img(x), axis=1)\nX_test = np.stack(X_test)\n\n#perform standardization based on statistics of training data\ndata_gen.standardize(X_test)\n\npredictions = final_model.predict(X_test, batch_size=BATCH_SZ)\ntest_predictions = np.argmax(predictions, axis=1)","6c08b82f":"submission = pd.DataFrame({'ImageId':test_df.index.values+1, 'Label':test_predictions})\nsubmission.to_csv('.\/submission.csv', index=False)","67fc92ba":"**Prediction on test set**","d3a4799e":"**Fetch the saved best model**","756eb743":"**Number of samples for each digit are close in count**","7079f9ae":"**Data Reading and Understanding**","33996b52":"**Data Preprocessing**","28ca3515":"**Modelling**","473b7509":"**Image Data Generator to perform featurewise center and standardization**"}}