{"cell_type":{"80dc9f26":"code","b31649e8":"code","99f3ebcd":"code","46be35bf":"code","e4bacaf3":"code","342deab4":"code","7ab2e238":"code","907b753a":"code","65b44a79":"code","7043a613":"code","5632a0a9":"code","6f3e0ab0":"code","d859d7ab":"code","88422fa3":"code","cbeb834b":"code","257e1e70":"code","e09523f7":"code","2eb80e5b":"code","bc1d1a63":"code","5e1df385":"code","7d41f0bb":"code","c4c64e9a":"code","a0706e93":"code","977c9a91":"code","3fe27f92":"code","8502e509":"code","0b5dfe67":"code","f63ae336":"code","e43b6e58":"code","cb96430a":"code","7cab8eb7":"code","c8158936":"markdown","ac72331e":"markdown"},"source":{"80dc9f26":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.metrics import roc_curve,auc\nfrom sklearn.metrics import f1_score\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.metrics import confusion_matrix\n\n# Any results you write to the current directory are saved as output.\n","b31649e8":"# pd.read_json('..\/input\/Sarcasm_Headlines_Dataset.json', lines = True)","99f3ebcd":"def parseJson(fname):\n    for line in open(fname,'r'):\n        yield eval(line)","46be35bf":"file_name = '..\/input\/Sarcasm_Headlines_Dataset.json'\ndata = list(parseJson(file_name))","e4bacaf3":"df = pd.DataFrame(data)\ndf.head()","342deab4":"df = df.drop('article_link', axis= 1)\ndf.head()","7ab2e238":"df['len'] = df['headline'].apply(lambda x: len(x.split(\" \")))\ndf.head()","907b753a":"df_length = df['len'].value_counts().reset_index()\ndf_length.rename(columns={'index': 'length_word', 'len':'frequency'}, inplace = True)\ndf_length.head()","65b44a79":"import matplotlib.pyplot as plt\nplt.bar(df_length['length_word'], df_length['frequency'])","7043a613":"# removing those headline whose length is greather than 19\nprint('shape before preprocessing ',df.shape)\ndf = df[df['len'] < 19]\nprint('shape after preprocessing ',df.shape)\ndf.head()","5632a0a9":"sns.countplot(df['is_sarcastic'])","6f3e0ab0":"tf = TfidfVectorizer(analyzer='word', ngram_range=(1,3), max_features= 5000)\nX = tf.fit_transform(df['headline'])\ny = df['is_sarcastic']\n","d859d7ab":"print(X)","88422fa3":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3)","cbeb834b":"nb = BernoulliNB()\nnb.fit(X_train, y_train)\ny_pred = nb.predict(X_test)\nconfusion_matrix(y_pred, y_test)","257e1e70":"# Reciever opereating charactaristics (ROC)\nproba = nb.predict_proba(X_test)[:,1]\nfpr, tpr, threshold = roc_curve(y_test, proba)\n\nauc_val = auc(fpr,tpr)\nplt.plot(fpr, tpr)","e09523f7":"f1_score(y_pred, y_test)","2eb80e5b":"## xgboost classifier\nfrom xgboost import XGBClassifier\nfor i in range(10, 12):\n    model = XGBClassifier(max_depth = i, n_jobs=4 )\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    print(f1_score(y_pred, y_test))","bc1d1a63":"# data cleaning\n\n\nimport string\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\n\nwordnet_lemmatizer = WordNetLemmatizer()\nstop_words = stopwords.words('english')\n# print (\"punctuations that gonna be removed, : \",string.punctuation)\n# print(stop_words)\n\ndef process(x):\n    token_list = x.split()\n#     print(token_list)\n    new_list = [w.lower() for w in token_list if w not in string.punctuation]\n    new_list = [w for w in new_list if w not in stop_words]\n    new_list = [wordnet_lemmatizer.lemmatize(w) for w in new_list]\n    return \" \".join(new_list)\n\ndf['headline'] = df['headline'].apply(process)","5e1df385":"# XGB after cleaning\ntf = TfidfVectorizer(analyzer='word', ngram_range=(1,3), max_features= 5000, token_pattern=\"[a-zA-Z]{2,}\", norm='l1')\nX = tf.fit_transform(df['headline'])\ny = df['is_sarcastic']\ndf.drop('len', axis = 1)\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3)\n\nfor i in range(15, 20):\n    model = XGBClassifier(max_depth = i, n_jobs = 8)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    print(f1_score(y_pred, y_test))","7d41f0bb":"tf.get_feature_names()[:10]","c4c64e9a":"#naive bayes after cleaning\nnb = BernoulliNB(alpha=1)\nnb.fit(X_train, y_train)\ny_pred = nb.predict(X_test)\nf1_score(y_pred, y_test)","a0706e93":"from sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\nmodel.fit(X_train,y_train)\ny_pred = model.predict(X_test)\nf1_score(y_pred, y_test)","977c9a91":"vec = CountVectorizer(ngram_range=(1,2), max_features=5000,  token_pattern=\"[a-zA-Z]{2,}\")\nX = vec.fit_transform(df['headline'])\ny = df['is_sarcastic']\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3)","3fe27f92":"nb = BernoulliNB(alpha=1)\nnb.fit(X_train, y_train)\ny_pred = nb.predict(X_test)\nf1_score(y_pred, y_test)","8502e509":"from sklearn.linear_model import SGDClassifier","0b5dfe67":"model = SGDClassifier()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nf1_score(y_pred, y_test)","f63ae336":"from sklearn.svm import LinearSVC","e43b6e58":"model = LinearSVC()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nf1_score(y_pred, y_test)","cb96430a":"from sklearn.ensemble import RandomForestClassifier","7cab8eb7":"model = RandomForestClassifier()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nf1_score(y_pred, y_test)","c8158936":"** Training model after removing noise using CountVectorizer**","ac72331e":"   **Training model after removing noise  using Tfidvectorizer** "}}