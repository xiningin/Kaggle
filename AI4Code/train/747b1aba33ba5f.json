{"cell_type":{"71bb2be4":"code","bb939c3f":"code","7f25c888":"code","fcb6184d":"code","2ddc4f29":"code","c2431b3a":"code","f904c799":"code","d82901a6":"code","5f01ade9":"code","3fa6420b":"code","58b81af5":"code","fc273ceb":"code","de87391e":"code","0271cb0d":"code","8f24b01c":"code","1f91c88d":"code","51482735":"code","d49dad3d":"code","7f1030b3":"code","d58a5076":"markdown","fd59ca04":"markdown","8dabb13c":"markdown","77965f94":"markdown","bc277433":"markdown","b4600404":"markdown"},"source":{"71bb2be4":"import pandas as pd\nimport numpy as np","bb939c3f":"data = pd.read_csv('..\/input\/bank-marketing-dataset\/bank.csv')","7f25c888":"data.shape","fcb6184d":"data.head()","2ddc4f29":"df_pivot = pd.DataFrame({'types': data.dtypes,\n                         'nulls': data.isna().sum(),\n                          '% nulls': data.isna().sum() \/ data.shape[0],\n                          'size': data.shape[0],\n                          'uniques': data.nunique()})\ndf_pivot","c2431b3a":"import category_encoders as ce\nencoder = ce.BinaryEncoder()\ndf_binary = encoder.fit_transform(data.loc[:,['job','marital', 'education',\n                                              'default', 'housing', 'loan',\n                                              'contact','month','poutcome']])\ndf_binary.head()","f904c799":"int_columns = data.select_dtypes(include=['int'])\nint_columns = int_columns.columns.values\ncolumns = np.append(int_columns, 'deposit')\ncolumns","d82901a6":"data = pd.concat([df_binary, data.loc[:,columns]], axis=1)\ndata.head()","5f01ade9":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(data.loc[:,'job_0':'previous'], \n                                                    data.loc[:,'deposit'], test_size=0.2)","3fa6420b":"from sklearn import preprocessing\npreprocessParams = preprocessing.StandardScaler().fit(x_train)","58b81af5":"X_train_normalized = preprocessParams.transform(x_train)\nX_test_normalized = preprocessParams.transform(x_test)","fc273ceb":"from keras import Sequential\nfrom keras.layers import Dense","de87391e":"RN = Sequential()\nRN.add(Dense(22,input_shape = X_train_normalized.shape[1:], activation = 'sigmoid'))\nRN.add(Dense(10, activation = 'sigmoid'))\nRN.add(Dense(2,activation = 'sigmoid'))\nRN.summary()","0271cb0d":"# Dummy Transformation\nfrom sklearn.preprocessing import OneHotEncoder\nencoder = OneHotEncoder(handle_unknown = 'ignore')\nencoder.fit(pd.DataFrame(y_train))\n\ny_train = encoder.transform(pd.DataFrame(y_train)).toarray()\ny_test = encoder.transform(pd.DataFrame(y_test)).toarray()\ny_train","8f24b01c":"RN.compile(optimizer = 'sgd', loss = 'mean_squared_error', metrics = ['accuracy'])\nhistory = RN.fit(X_train_normalized,y_train, epochs = 125, validation_split=0.2) ","1f91c88d":"score = RN.evaluate(X_test_normalized, y_test, verbose = 0)\nprint('Test score:', score[0])\nprint('Test accuracy:', score[1])","51482735":"# Graph training: cost train and validation\nimport matplotlib.pyplot as plt\nplt.plot(history.history['loss'], label='train')\nplt.plot(history.history['val_loss'], label='validation')\nplt.title('Loss train and validation')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend();","d49dad3d":"from sklearn.metrics import confusion_matrix\ny_test_predicted = RN.predict(X_test_normalized)\ny_test_predicted_indexes = np.argmax(y_test_predicted,axis=1)\ny_test_indexes = np.argmax(y_test, axis=1)","7f1030b3":"#Confusion Matrix\nconfMatrix = pd.DataFrame(confusion_matrix(y_test_predicted_indexes, y_test_indexes),\n                           index=['0 - No','1 - Yes'],columns=['0 - No','1 - Yes'])\n\nconfMatrix.index.name = 'Actual'\nconfMatrix.columns.name= 'Predicted'\nprint(confMatrix)","d58a5076":"### Converting categorical to numerical features","fd59ca04":"### Split Train & Test","8dabb13c":"### Training Neural Network","77965f94":"### Confusion Matrix","bc277433":"### Normalization","b4600404":"### Loading Dataset"}}