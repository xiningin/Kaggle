{"cell_type":{"5a57bf3e":"code","6462b225":"code","3ee30642":"code","e908ddb0":"code","1b1307b7":"code","9073de70":"code","078c7a6f":"code","0e73873f":"code","f820e0b5":"code","f3d24b48":"code","2ac77bdc":"code","36e66108":"code","8055da50":"code","7f03de38":"code","6c86e207":"code","7d61e6a2":"code","d37d60de":"code","34254cc4":"code","d925af62":"code","c78076ec":"code","5bb40993":"code","a6e53816":"code","da35e591":"code","c52b4b75":"code","29505d58":"code","aaa3ef50":"code","2bbe30b2":"code","2c4be2d9":"code","96e75912":"markdown","bdd0850b":"markdown","02f4f485":"markdown","724e0bc2":"markdown","23a04e23":"markdown","a484961e":"markdown","4bf80f4d":"markdown","1e681314":"markdown","ef07f152":"markdown","69dc848c":"markdown","f4d634fc":"markdown","58039261":"markdown","27fe827e":"markdown"},"source":{"5a57bf3e":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd \nimport h5py\nimport os\nimport glob\nimport cv2 # for porcess the image\nfrom keras.utils import to_categorical  # to transfrom integer value to catagorial value\nimport matplotlib.pyplot as plt # For creating plot\nfrom scipy.misc.pilutil import Image #Convert Image to grayscale\nfrom skimage.feature import canny #Transfrom The image in black and white\nimport scipy.misc   # Convert it to the numpy array\nimport keras \nfrom keras.models import Model, load_model\nfrom keras.layers import Dense, Input, Conv2D, Flatten,Activation,ZeroPadding2D,MaxPool2D,Dropout\nfrom keras.layers.normalization import BatchNormalization\nfrom keras import backend as K\nfrom keras import optimizers as opt #ReSet the adam optimizer\nfrom sklearn.cross_validation import train_test_split\nfrom keras.models import Sequential\nfrom keras import applications\nfrom IPython.display import HTML #For Download CSV File \nimport base64 # For Download CSV File","6462b225":"data_dir = os.path.join('..','input')\npaths_train_a=glob.glob(os.path.join(data_dir,'training-a','*.png'))\npaths_train_b=glob.glob(os.path.join(data_dir,'training-b','*.png'))\npaths_train_e=glob.glob(os.path.join(data_dir,'training-e','*.png'))\npaths_train_c=glob.glob(os.path.join(data_dir,'training-c','*.png'))\npaths_train_d=glob.glob(os.path.join(data_dir,'training-d','*.png'))","3ee30642":"print(os.listdir(\"..\/input\"))","e908ddb0":"path_label_train_a=os.path.join(data_dir,'training-a.csv')\npath_label_train_b=os.path.join(data_dir,'training-b.csv')\npath_label_train_e=os.path.join(data_dir,'training-e.csv')\npath_label_train_c=os.path.join(data_dir,'training-c.csv')\npath_label_train_d=os.path.join(data_dir,'training-d.csv')","1b1307b7":"paths_test_a=glob.glob(os.path.join(data_dir,'testing-a','*.png'))\npaths_test_b=glob.glob(os.path.join(data_dir,'testing-b','*.png'))\npaths_test_e=glob.glob(os.path.join(data_dir,'testing-e','*.png'))\npaths_test_c=glob.glob(os.path.join(data_dir,'testing-c','*.png'))\npaths_test_d=glob.glob(os.path.join(data_dir,'testing-d','*.png'))\npaths_test_f=glob.glob(os.path.join(data_dir,'testing-f','*.png'))+glob.glob(os.path.join(data_dir,'testing-f','*.JPG'))\npaths_test_auga=glob.glob(os.path.join(data_dir,'testing-auga','*.png'))\npaths_test_augc=glob.glob(os.path.join(data_dir,'testing-augc','*.png'))\n","9073de70":"def get_key(path):\n    # seperates the key of an image from the filepath\n    key=path.split(sep=os.sep)[-1]\n    return key","078c7a6f":"def get_data(paths_img,path_label=None,resize_dim=None):\n    '''reads images from the filepaths, resizes them (if given), and returns them in a numpy array\n    Args:\n        paths_img: image filepaths\n        path_label: pass image label filepaths while processing training data, defaults to None while processing testing data\n        resize_dim: if given, the image is resized to resize_dim x resize_dim (optional)\n    Returns:\n        X: group of images\n        y: categorical true labels\n    '''\n    X=[]\n    for i,path in enumerate(paths_img):\n        img = Image.open(path).convert('L') # Convert to the grayscale \n        img = np.asarray(img) # Convert to the numpy\n        if resize_dim is not None:\n            img=cv2.resize(img,(resize_dim,resize_dim),interpolation=cv2.INTER_AREA) #Create 32*32 image\n        X.append(img) # expand image to 32x32 and append to the list\n        if i==len(paths_img)-1:\n            end='\\n'\n        else: end='\\r'\n        print('processed {}\/{}'.format(i+1,len(paths_img)),end=end)\n        \n    #X=np.array(X)\n    X = np.array(X).astype('float32') # tranform list to numpy array\n    if  path_label is None:\n        return X\n    else:\n        df = pd.read_csv(path_label) # read labels\n        df=df.set_index('filename') \n        y_label=[df.loc[get_key(path)]['digit'] for path in  paths_img] # get the labels corresponding to the images\n        y=to_categorical(y_label,10) # transfrom integer value to categorical variable\n        return X, y\n","0e73873f":"PIC_SIZE = 28\nX_train_a,y_train_a=get_data(paths_train_a,path_label_train_a,resize_dim=PIC_SIZE)\nX_train_b,y_train_b=get_data(paths_train_b,path_label_train_b,resize_dim=PIC_SIZE)\nX_train_c,y_train_c=get_data(paths_train_c,path_label_train_c,resize_dim=PIC_SIZE)\nX_train_d,y_train_d=get_data(paths_train_d,path_label_train_d,resize_dim=PIC_SIZE)\nX_train_e,y_train_e=get_data(paths_train_e,path_label_train_e,resize_dim=PIC_SIZE)","f820e0b5":"X_train_all=np.concatenate((X_train_a,X_train_b,X_train_c,X_train_d,X_train_e),axis=0)\ny_train_all=np.concatenate((y_train_a,y_train_b,y_train_c,y_train_d,y_train_e),axis=0)","f3d24b48":"X_train = X_train_all[:,:,:,np.newaxis]\ny_train= y_train_all\nprint(X_train.shape)\nprint(y_train.shape)","2ac77bdc":"Image_Size = 28\nX_test_a=get_data(paths_test_a,resize_dim=Image_Size)\nX_test_b=get_data(paths_test_b,resize_dim=Image_Size)\nX_test_c=get_data(paths_test_c,resize_dim=Image_Size)\nX_test_d=get_data(paths_test_d,resize_dim=Image_Size)\nX_test_e=get_data(paths_test_e,resize_dim=Image_Size)\nX_test_f=get_data(paths_test_f,resize_dim=Image_Size)\nX_test_auga=get_data(paths_test_auga,resize_dim=Image_Size)\nX_test_augc=get_data(paths_test_augc,resize_dim=Image_Size)","36e66108":"X_test_all=np.concatenate((X_test_a,X_test_b,X_test_c,X_test_d,X_test_e,X_test_f,X_test_auga,X_test_augc))\nX_test = X_test_all[:,:,:,np.newaxis]","8055da50":"plt.figure(figsize = (10, 8))\na, b = 9, 3\nfor i in range(27):\n    plt.subplot(b, a, i+1)\n    plt.imshow(X_train_all[i])\nplt.show()","7f03de38":"X_train = X_train\/255.0\nX_Test = X_test\/255.0","6c86e207":"#model.summary()","7d61e6a2":"nets = 1\nmodel = [0] *nets\nfor j in range(nets):\n    model[j] = Sequential()\n\n    model[j].add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',kernel_initializer='he_normal', \n                 activation ='relu', input_shape = (28,28,1)))\n    model[j].add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', kernel_initializer='he_normal', \n                 activation ='relu'))\n    model[j].add(MaxPool2D(pool_size=(2,2)))\n    model[j].add(Dropout(0.20))\n\n\n    model[j].add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', kernel_initializer='he_normal', \n                 activation ='relu'))\n    model[j].add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', kernel_initializer='he_normal',\n                 activation ='relu'))\n    model[j].add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n    model[j].add(Dropout(0.25))\n    \n    \n    model[j].add(Conv2D(128, (3, 3), activation='relu',padding='same',kernel_initializer='he_normal'))\n    model[j].add(Dropout(0.25))\n\n\n    model[j].add(Flatten())\n    model[j].add(Dense(128, activation = \"relu\"))\n    model[j].add(BatchNormalization())\n    model[j].add(Dense(10, activation = \"softmax\"))\n    \n    # COMPILE WITH RMSprop OPTIMIZER AND CROSS ENTROPY COST\n    opt = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n    model[j].compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    \n    ","d37d60de":"datagen = keras.preprocessing.image.ImageDataGenerator(\n                              featurewise_center=False,  # set input mean to 0 over the dataset\n                              samplewise_center=False,  # set each sample mean to 0\n                              featurewise_std_normalization=False,  # divide inputs by std of the dataset\n                              samplewise_std_normalization=False,  # divide each input by its std\n                              zca_whitening=False,  # apply ZCA whitening\n                              rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n                              zoom_range = 0.1, # Randomly zoom image \n                              width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n                              height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n                              horizontal_flip=False,  # randomly flip images\n                              vertical_flip=False)  # randomly flip images\n                              ","34254cc4":"annealer = keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)\n# TRAIN NETWORKS\nhistory = [0] * nets\nepochs = 45\nfor j in range(nets):\n    X_train2, X_val2, Y_train2, Y_val2 = train_test_split(X_train, y_train, test_size = 0.1)\n    history[j] = model[j].fit_generator(datagen.flow(X_train2,Y_train2, batch_size=64),\n        epochs = epochs, steps_per_epoch = X_train2.shape[0]\/\/64,  \n        validation_data = (X_val2,Y_val2), callbacks=[annealer], verbose=0)\n    print(\"CNN {0:d}: Epochs={1:d}, Train accuracy={2:.5f}, Validation accuracy={3:.5f}\".format(\n        j+1,epochs,max(history[j].history['acc']),max(history[j].history['val_acc']) ))","d925af62":"predictions_prob = np.zeros( (X_test.shape[0],10) ) \nfor j in range(nets):\n    predictions_prob = predictions_prob + model[j].predict(X_test)\n#results = np.argmax(results,axis = 1)","c78076ec":"predictions_prob=model.predict(X_test)\ntype(predictions_prob)","5bb40993":"n_sample=200\nnp.random.seed(42)\nind=np.random.randint(0,len(X_test_all), size=n_sample)","a6e53816":"FIG_WIDTH=20 # Width of figure\nROW_HEIGHT=3 \ndef imshow_group(X,y=None,y_pred=None,n_per_row=10):\n    '''helper function to visualize a group of images along with their categorical true labels (y) and prediction probabilities.\n    Args:\n        X: images\n        y: categorical true labels\n        y_pred: predicted class probabilities\n        n_per_row: number of images per row to be plotted\n    '''\n    n_sample=len(X)\n    img_dim=X.shape[1]\n    j=np.ceil(n_sample\/n_per_row)\n    fig=plt.figure(figsize=(FIG_WIDTH,ROW_HEIGHT*j))\n    for i,img in enumerate(X):\n        plt.subplot(j,n_per_row,i+1)\n        plt.imshow(img)\n        if y is not None:\n                plt.title('true label: {}'.format(np.argmax(y[i])))\n        if y_pred is not None:\n            top_n=3 # top 3 predictions with highest probabilities\n            ind_sorted=np.argsort(y_pred[i])[::-1]\n            h=img_dim+4\n            for k in range(top_n):\n                string='pred: {} ({:.0f}%)\\n'.format(ind_sorted[k],y_pred[i,ind_sorted[k]]*100)\n                plt.text(img_dim\/2, h, string, horizontalalignment='center',verticalalignment='center')\n                h+=4\n        plt.axis('off')\n    plt.show()\ndef create_submission(predictions,keys):\n    result = pd.DataFrame(\n        predictions,\n        columns=['label'],\n        index=keys\n        )\n    result.index.name='key'\n    return result\n    #result.to_csv(path, index=True)","da35e591":"imshow_group(X=X_test_all[ind],y=None,y_pred=predictions_prob[ind])","c52b4b75":"labels=[np.argmax(pred) for pred in predictions_prob]","29505d58":"paths_test_all=paths_test_a+paths_test_b+paths_test_c+paths_test_d+paths_test_e+paths_test_f+paths_test_auga+paths_test_augc\nkeys=[get_key(path) for path in paths_test_all]","aaa3ef50":"result = create_submission(predictions=labels,keys=keys)","2bbe30b2":"def create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n    csv = df.to_csv()\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text\/csv;base64,{payload}\" target=\"_blank\">{title}<\/a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)","2c4be2d9":"create_download_link(result)","96e75912":"# Normalize. Transfrom image from 0....255 to 0...1","bdd0850b":"K.tensorflow_backend.clear_session()\n#model=get_model() # create the model\n#K.set_value(model.optimizer.lr, 1e-4)\n\n\nmodel.fit(datagen.flow(X_train,y_train, batch_size=64), \n            epochs=40, \n            verbose=1, \n            validation_data=(X_val,y_val),\n            shuffle=True\n            )","02f4f485":"# Setup all training image path","724e0bc2":"##  To understand (cv2.INTER_AREA) function cheak [here](http:\/\/https:\/\/medium.com\/@wenrudong\/what-is-opencvs-inter-area-actually-doing-282a626a09b3)","23a04e23":"# Not Work Very Well \n!git clone https:\/\/github.com\/titu1994\/DenseNet.git ","a484961e":"base_model = DenseNet121(input_shape=(28, 28, 1),\n                                     weights='resnet34',\n                                     include_top=False,\n                                     pooling='max')","4bf80f4d":"model = get_model()\nmodel.summary()","1e681314":"# Using DenseNet cause overfitting\nimport DenseNet","ef07f152":"# Build a keras CNN model.\n\ninspiration for the model is taken from here, [here](http:\/\/https:\/\/github.com\/kurapan\/CNN-MNIST\/blob\/master\/src\/mnist_keras.py)","69dc848c":"cd .\/DenseNet","f4d634fc":"# Setup all training label path","58039261":"# Define all the libary","27fe827e":"#from DenseNet import tensorflow_backend\n\nimport densenet\n\nimage_dim = (28,28,1)\n#model = densenet.DenseNet(classes=10, input_shape=image_dim, depth=40, growth_rate=12,bottleneck=True, reduction=0.5)"}}