{"cell_type":{"8e45974b":"code","d00774d5":"code","010b20dd":"code","2766bc4e":"code","b9979a71":"code","cea04cc4":"code","f09ad33a":"code","baf57a57":"code","cde6a62e":"code","01faf002":"code","b9304129":"code","60fa3081":"code","85f17e50":"code","f83efe4a":"code","76757127":"code","232fb818":"code","f8edc758":"code","715935dc":"code","0c3143fd":"code","3a70977f":"code","e8762398":"code","83539582":"code","18140a84":"code","0e776d51":"code","04789754":"code","3c17acb1":"code","85b2f5d7":"code","dd4b80d4":"code","cbc059fc":"code","0b21393a":"code","c5d8b34d":"code","9eed4e5f":"code","7ed94a15":"code","391417c5":"code","329eb815":"code","070604e8":"code","f7e5ecd4":"code","5a87cf87":"code","1217f3e0":"code","f2648d49":"code","9079029c":"code","102084ce":"code","e6ae84ff":"code","4c91bbd5":"code","0b30fc40":"code","fb411d34":"code","85d54fb9":"code","f45ad20e":"code","cb8e4870":"code","181c0857":"code","5e6ebe72":"code","b7df5d7e":"code","e5467efc":"code","479e2e0a":"code","a0946465":"code","29931b30":"code","a480255c":"code","002fa1b8":"code","10315460":"code","77b17400":"code","8f463998":"code","7e81738d":"code","5a6a64c7":"code","997c13f1":"code","624566cd":"code","1c53c643":"code","48f5aaeb":"code","56d64b90":"code","b6196a57":"code","92bdaf09":"code","6dd96a69":"code","fbb1d27d":"code","c9b9731a":"code","185ffe28":"code","9adb2d1c":"code","93b54050":"code","8d849675":"code","8ee2d2c2":"code","a05d6cd5":"code","57deda9a":"code","ba94cd31":"code","d5beba0f":"code","945ceee4":"code","cac49f32":"code","2a6ece13":"code","b4a9ec93":"code","a448a026":"code","9c42fdbf":"code","ce5325b9":"code","d3ee28db":"code","d845c6b0":"code","eb943f81":"code","cf4d0cff":"code","e629609b":"code","c9308718":"code","a214b67e":"code","5ceb7b22":"code","6acd86a9":"code","7a804354":"code","9b22017f":"code","6f44bbcb":"code","f602987a":"code","8e0fa6ca":"code","6a0cedff":"code","eb6591f8":"code","c6d2ec04":"code","cce69ff3":"code","bd705555":"code","742f0edf":"code","b3e23057":"code","c0bfdfa9":"code","70e6b5a5":"code","9926c235":"code","8a425790":"code","477b7495":"code","353a7357":"code","2d9ba827":"code","8455267f":"code","8c50dab7":"code","63807b41":"markdown","6b55837b":"markdown","9a67f273":"markdown","52e23537":"markdown","f2393cb3":"markdown","7e206933":"markdown","e14d6d0b":"markdown","716c7cf2":"markdown","0d7a751f":"markdown","54c2876f":"markdown","355cad3a":"markdown","eef0898d":"markdown","54982199":"markdown","544de35c":"markdown","51476f93":"markdown","bb8fd0e2":"markdown","70a4caa5":"markdown","8264aa98":"markdown","023c6a99":"markdown","9dc6846a":"markdown","c9a257cc":"markdown","481fd5c2":"markdown","bf37b39e":"markdown","bc6c32cc":"markdown","682b5cc3":"markdown","920ac3ae":"markdown","58188b69":"markdown","08e02d5d":"markdown","d769726c":"markdown","cb8518f6":"markdown","86c22428":"markdown","6eaf360c":"markdown","b0f1e57c":"markdown","f36a3188":"markdown","ba6dcfe3":"markdown","e5eb080d":"markdown","9e284c85":"markdown","5986cc58":"markdown","595f1ff3":"markdown","fac04c6a":"markdown","cdd3bd96":"markdown","e8a09f21":"markdown","f0931990":"markdown","b65ce7b4":"markdown","3c0ba977":"markdown","935b6033":"markdown","8e77f4a5":"markdown","2064bbd4":"markdown","f4d5fcd1":"markdown","33ab8b29":"markdown","f286ebae":"markdown","0d61aaea":"markdown"},"source":{"8e45974b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Data Visualization\nimport matplotlib.pyplot as plt\nimport pydot\nimport statsmodels.api as sn\nfrom mpl_toolkits.mplot3d import axes3d\nimport seaborn as sns\nfrom wordcloud import WordCloud\nfrom collections import Counter\nfrom datetime import datetime\nfrom tqdm import tqdm\n\n# Sklearn\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.tree import export_graphviz\nfrom tensorflow import keras\n\n# Modeling\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nimport lightgbm as lgb\nfrom sklearn.preprocessing import normalize\nfrom sklearn.model_selection import train_test_split\nfrom keras import layers\nfrom keras import models\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras import regularizers\nfrom keras.metrics import mean_squared_logarithmic_error\nfrom sklearn.model_selection import KFold\n\n#Miscellaneous\nfrom tqdm import tqdm_notebook\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory \nfrom wordcloud import WordCloud\nfrom collections import Counter\nfrom sklearn import preprocessing\nfrom datetime import datetime\nimport ast\nfrom sklearn.preprocessing import normalize\nfrom sklearn.model_selection import train_test_split\nfrom keras import layers\nfrom keras import models\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras import regularizers\nfrom keras.metrics import mean_squared_logarithmic_error\nfrom sklearn.model_selection import KFold\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nrandom_seed = 2019\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d00774d5":"%%time\n\ntrain = pd.read_csv('\/kaggle\/input\/tmdb-box-office-prediction\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tmdb-box-office-prediction\/test.csv')","010b20dd":"train.head()","2766bc4e":"print(train.shape)\nprint(test.shape)","b9979a71":"train.columns","cea04cc4":"test.columns","f09ad33a":"train.describe()","baf57a57":"train.info()","cde6a62e":"sns.heatmap(train.isna(), yticklabels=False, cmap=\"viridis\")","01faf002":"import ast\n\ndict_columns = ['belongs_to_collection', 'genres', 'production_companies',\n                'production_countries', 'spoken_languages', 'Keywords', 'cast', 'crew']\n\ndef text_to_dict(df):\n    for column in dict_columns:\n        train[column] = df[column].apply(lambda x: {} if pd.isna(x) else ast.literal_eval(x) )\n    return df\n        \ndfx = text_to_dict(train)\nfor col in dict_columns:\n       train[col]=dfx[col]","b9304129":"train['belongs_to_collection'].apply(lambda x:len(x) if x!= {} else 0).value_counts()","60fa3081":"collections=train['belongs_to_collection'].apply(lambda x : x[0]['name'] if x!= {} else '?').value_counts()[1:15]\nsns.barplot(collections,collections.index)\nplt.show()","85f17e50":"train['tagline'].apply(lambda x:1 if x is not np.nan else 0).value_counts()","f83efe4a":"plt.figure(figsize=(10,10))\ntaglines=' '.join(train['tagline'].apply(lambda x:x if x is not np.nan else ''))\n\nwordcloud = WordCloud(max_font_size=None, background_color='white', collocations=False,\n                      width=1200, height=1000).generate(taglines)\nplt.imshow(wordcloud)\nplt.title('Taglines')\nplt.axis(\"off\")\nplt.show()","76757127":"keywords=train['Keywords'].apply(lambda x: ' '.join(i['name'] for i in x) if x != {} else '')\nplt.figure(figsize=(10,10))\ndata=' '.join(words for words in keywords)\nwordcloud = WordCloud(max_font_size=None, background_color='white', collocations=False,\n                      width=1200, height=1000).generate(data)\nplt.imshow(wordcloud)\nplt.title('Taglines')\nplt.axis(\"off\")\nplt.show()","232fb818":"x=train['production_companies'].apply(lambda x : [x[i]['name'] for i in range(len(x))] if x != {} else []).values\nCounter([i for j in x for i in j]).most_common(30)","f8edc758":"countries=train['production_countries'].apply(lambda x: [i['name'] for i in x] if x!={} else []).values\ncount=Counter([j for i in countries for j in i]).most_common(20)\nsns.barplot([val[1] for val in count],[val[0] for val in count])","715935dc":"train['spoken_languages'].apply(lambda x:len(x) if x !={} else 0).value_counts()\nlang=train['spoken_languages'].apply(lambda x: [i['name'] for i in x] if x != {} else [])\ncount=Counter([i for j in lang for i in j]).most_common(5)\nsns.barplot([val[1] for val in count],[val[0] for val in count])","0c3143fd":"genre=train['genres'].apply(lambda x: [i['name'] for i in x] if x != {} else [])\ncount=Counter([i for j in genre for i in j]).most_common(10)\nsns.barplot([val[1] for val in count],[val[0] for val in count])","3a70977f":"dfx = text_to_dict(test)\nfor col in dict_columns:\n       test[col]=dfx[col]","e8762398":"plt.figure(figsize=(10,5))\nplt.subplot(1,2,1)\nplt.title('skewed data')\nsns.distplot(train['revenue'])\nplt.subplot(1,2,2)\nplt.title('log transformation')\nsns.distplot(np.log(train['revenue']))\nplt.show()","83539582":"train['revenue'].describe()","18140a84":"plt.subplots(figsize=(10,5))\nplt.subplot(1,2,1)\nplt.hist(train['budget']+1,bins=10,color='g')\nplt.title('skewed data')\nplt.subplot(1,2,2)\nplt.hist(np.log(train['budget']+1),bins=10,color='g')\nplt.title('log transformation')\nplt.show()","0e776d51":"plt.figure(figsize=(10,5))\nplt.subplot(1,2,1)\nsns.scatterplot(train['budget'],train['revenue'])\nplt.subplot(1,2,2)\nsns.scatterplot(np.log1p(train['budget']),np.log1p(train['revenue']))\nplt.show()","04789754":"sns.set()\nx = np.array(train[\"budget\"])\ny = np.array(train[\"revenue\"])\nfig = plt.figure(1, figsize=(10, 8))\nsns.regplot(x, y)\nplt.xlabel(\"Budget\", fontsize=10)  \nplt.ylabel(\"Revenue\", fontsize=10)\nplt.title(\"Link between revenue and budget\", fontsize=10)","3c17acb1":"%%time\n\nsns.pairplot(train)","85b2f5d7":"plt.hist(train['popularity'],bins=30,color='violet')\nplt.show()","dd4b80d4":"sns.scatterplot(train['popularity'],train['revenue'],color='violet')\nplt.show()","cbc059fc":"train.loc[train['id'] == 16,'revenue'] = 192864         \ntrain.loc[train['id'] == 90,'budget'] = 30000000                  \ntrain.loc[train['id'] == 118,'budget'] = 60000000       \ntrain.loc[train['id'] == 149,'budget'] = 18000000       \ntrain.loc[train['id'] == 313,'revenue'] = 12000000       \ntrain.loc[train['id'] == 451,'revenue'] = 12000000      \ntrain.loc[train['id'] == 464,'budget'] = 20000000       \ntrain.loc[train['id'] == 470,'budget'] = 13000000       \ntrain.loc[train['id'] == 513,'budget'] = 930000         \ntrain.loc[train['id'] == 797,'budget'] = 8000000        \ntrain.loc[train['id'] == 819,'budget'] = 90000000       \ntrain.loc[train['id'] == 850,'budget'] = 90000000       \ntrain.loc[train['id'] == 1007,'budget'] = 2              \ntrain.loc[train['id'] == 1112,'budget'] = 7500000       \ntrain.loc[train['id'] == 1131,'budget'] = 4300000        \ntrain.loc[train['id'] == 1359,'budget'] = 10000000       \ntrain.loc[train['id'] == 1542,'budget'] = 1             \ntrain.loc[train['id'] == 1570,'budget'] = 15800000       \ntrain.loc[train['id'] == 1571,'budget'] = 4000000        \ntrain.loc[train['id'] == 1714,'budget'] = 46000000       \ntrain.loc[train['id'] == 1721,'budget'] = 17500000       \ntrain.loc[train['id'] == 1865,'revenue'] = 25000000      \ntrain.loc[train['id'] == 1885,'budget'] = 12             \ntrain.loc[train['id'] == 2091,'budget'] = 10             \ntrain.loc[train['id'] == 2268,'budget'] = 17500000       \ntrain.loc[train['id'] == 2491,'budget'] = 6              \ntrain.loc[train['id'] == 2602,'budget'] = 31000000       \ntrain.loc[train['id'] == 2612,'budget'] = 15000000       \ntrain.loc[train['id'] == 2696,'budget'] = 10000000      \ntrain.loc[train['id'] == 2801,'budget'] = 10000000       \ntrain.loc[train['id'] == 335,'budget'] = 2 \ntrain.loc[train['id'] == 348,'budget'] = 12\ntrain.loc[train['id'] == 470,'budget'] = 13000000 \ntrain.loc[train['id'] == 513,'budget'] = 1100000\ntrain.loc[train['id'] == 640,'budget'] = 6 \ntrain.loc[train['id'] == 696,'budget'] = 1\ntrain.loc[train['id'] == 797,'budget'] = 8000000 \ntrain.loc[train['id'] == 850,'budget'] = 1500000\ntrain.loc[train['id'] == 1199,'budget'] = 5 \ntrain.loc[train['id'] == 1282,'budget'] = 9              \ntrain.loc[train['id'] == 1347,'budget'] = 1\ntrain.loc[train['id'] == 1755,'budget'] = 2\ntrain.loc[train['id'] == 1801,'budget'] = 5\ntrain.loc[train['id'] == 1918,'budget'] = 592 \ntrain.loc[train['id'] == 2033,'budget'] = 4\ntrain.loc[train['id'] == 2118,'budget'] = 344 \ntrain.loc[train['id'] == 2252,'budget'] = 130\ntrain.loc[train['id'] == 2256,'budget'] = 1 \ntrain.loc[train['id'] == 2696,'budget'] = 10000000","0b21393a":"test.loc[test['id'] == 3033,'budget'] = 250 \ntest.loc[test['id'] == 3051,'budget'] = 50\ntest.loc[test['id'] == 3084,'budget'] = 337\ntest.loc[test['id'] == 3224,'budget'] = 4  \ntest.loc[test['id'] == 3594,'budget'] = 25  \ntest.loc[test['id'] == 3619,'budget'] = 500  \ntest.loc[test['id'] == 3831,'budget'] = 3  \ntest.loc[test['id'] == 3935,'budget'] = 500  \ntest.loc[test['id'] == 4049,'budget'] = 995946 \ntest.loc[test['id'] == 4424,'budget'] = 3  \ntest.loc[test['id'] == 4460,'budget'] = 8  \ntest.loc[test['id'] == 4555,'budget'] = 1200000 \ntest.loc[test['id'] == 4624,'budget'] = 30 \ntest.loc[test['id'] == 4645,'budget'] = 500 \ntest.loc[test['id'] == 4709,'budget'] = 450 \ntest.loc[test['id'] == 4839,'budget'] = 7\ntest.loc[test['id'] == 3125,'budget'] = 25 \ntest.loc[test['id'] == 3142,'budget'] = 1\ntest.loc[test['id'] == 3201,'budget'] = 450\ntest.loc[test['id'] == 3222,'budget'] = 6\ntest.loc[test['id'] == 3545,'budget'] = 38\ntest.loc[test['id'] == 3670,'budget'] = 18\ntest.loc[test['id'] == 3792,'budget'] = 19\ntest.loc[test['id'] == 3881,'budget'] = 7\ntest.loc[test['id'] == 3969,'budget'] = 400\ntest.loc[test['id'] == 4196,'budget'] = 6\ntest.loc[test['id'] == 4221,'budget'] = 11\ntest.loc[test['id'] == 4222,'budget'] = 500\ntest.loc[test['id'] == 4285,'budget'] = 11\ntest.loc[test['id'] == 4319,'budget'] = 1\ntest.loc[test['id'] == 4639,'budget'] = 10\ntest.loc[test['id'] == 4719,'budget'] = 45\ntest.loc[test['id'] == 4822,'budget'] = 22\ntest.loc[test['id'] == 4829,'budget'] = 20\ntest.loc[test['id'] == 4969,'budget'] = 20\ntest.loc[test['id'] == 5021,'budget'] = 40 \ntest.loc[test['id'] == 5035,'budget'] = 1 \ntest.loc[test['id'] == 5063,'budget'] = 14 \ntest.loc[test['id'] == 5119,'budget'] = 2 \ntest.loc[test['id'] == 5214,'budget'] = 30 \ntest.loc[test['id'] == 5221,'budget'] = 50 \ntest.loc[test['id'] == 4903,'budget'] = 15\ntest.loc[test['id'] == 4983,'budget'] = 3\ntest.loc[test['id'] == 5102,'budget'] = 28\ntest.loc[test['id'] == 5217,'budget'] = 75\ntest.loc[test['id'] == 5224,'budget'] = 3 \ntest.loc[test['id'] == 5469,'budget'] = 20 \ntest.loc[test['id'] == 5840,'budget'] = 1 \ntest.loc[test['id'] == 5960,'budget'] = 30\ntest.loc[test['id'] == 6506,'budget'] = 11 \ntest.loc[test['id'] == 6553,'budget'] = 280\ntest.loc[test['id'] == 6561,'budget'] = 7\ntest.loc[test['id'] == 6582,'budget'] = 218\ntest.loc[test['id'] == 6638,'budget'] = 5\ntest.loc[test['id'] == 6749,'budget'] = 8 \ntest.loc[test['id'] == 6759,'budget'] = 50 \ntest.loc[test['id'] == 6856,'budget'] = 10\ntest.loc[test['id'] == 6858,'budget'] =  100\ntest.loc[test['id'] == 6876,'budget'] =  250\ntest.loc[test['id'] == 6972,'budget'] = 1\ntest.loc[test['id'] == 7079,'budget'] = 8000000\ntest.loc[test['id'] == 7150,'budget'] = 118\ntest.loc[test['id'] == 6506,'budget'] = 118\ntest.loc[test['id'] == 7225,'budget'] = 6\ntest.loc[test['id'] == 7231,'budget'] = 85\ntest.loc[test['id'] == 5222,'budget'] = 5\ntest.loc[test['id'] == 5322,'budget'] = 90\ntest.loc[test['id'] == 5350,'budget'] = 70\ntest.loc[test['id'] == 5378,'budget'] = 10\ntest.loc[test['id'] == 5545,'budget'] = 80\ntest.loc[test['id'] == 5810,'budget'] = 8\ntest.loc[test['id'] == 5926,'budget'] = 300\ntest.loc[test['id'] == 5927,'budget'] = 4\ntest.loc[test['id'] == 5986,'budget'] = 1\ntest.loc[test['id'] == 6053,'budget'] = 20\ntest.loc[test['id'] == 6104,'budget'] = 1\ntest.loc[test['id'] == 6130,'budget'] = 30\ntest.loc[test['id'] == 6301,'budget'] = 150\ntest.loc[test['id'] == 6276,'budget'] = 100\ntest.loc[test['id'] == 6473,'budget'] = 100\ntest.loc[test['id'] == 6842,'budget'] = 30","c5d8b34d":"release_dates = pd.read_csv('..\/input\/externaldata\/release_dates_per_country2.csv')\nrelease_dates['id'] = range(1,7399)\ntrain = pd.merge(train, release_dates, how='left', on=['id'])\ntest = pd.merge(test, release_dates, how='left', on=['id'])","9eed4e5f":"train.columns","7ed94a15":"test.columns","391417c5":"corr_mat = train.corr()\ncorr_mat.revenue.sort_values(ascending=False)","329eb815":"train['revenue'].describe()","070604e8":"train.head()","f7e5ecd4":"sns.distplot(train['revenue'])","5a87cf87":"max_revenue= train[train['revenue']== max(train['revenue'])]\nmax_revenue.head()","1217f3e0":"Train = train.copy()\nTrain.sort_values('revenue',ascending=False,inplace=True)\nTrain =Train.head(15)\nTrain[['title', 'original_language','popularity','budget','genres','revenue','release_date','production_companies']]","f2648d49":"min_revenue = train[train['revenue']== min(train['revenue'])]\nmin_revenue.sample()","9079029c":"cols =['revenue','budget','popularity','theatrical','runtime','release_year']\nsns.heatmap(train[cols].corr())\nplt.show()","102084ce":"%%time\n\nsns.set()\nx = np.array(train[\"budget\"])\ny = np.array(train[\"revenue\"])\nfig = plt.figure(1, figsize=(10, 8))\nsns.regplot(x, y)\nplt.xlabel(\"Budget\", fontsize=10)  \nplt.ylabel(\"Revenue\", fontsize=10)\nplt.title(\"Link between revenue and budget\", fontsize=10)","e6ae84ff":"%%time\n\nsns.set()\nx=train['revenue']\ny=train['popularity']\nplt.figure(figsize=(12,6))\nsns.regplot(x,y)\nplt.xlabel('popularity')\nplt.ylabel('revenue')\nplt.title('Relationship between popularity and revenue of a movie')","4c91bbd5":"%%time\n\nplt.figure(figsize=(15,12)) \na1 = sns.swarmplot(x='original_language', y='revenue', \n                   data=train[(train['original_language'].isin((train['original_language'].value_counts()[:10].index.values)))])\na1.set_title(\"Plot revenue by original language in the movie\", fontsize=20) \na1.set_xticklabels(a1.get_xticklabels(),rotation=45) \na1.set_xlabel('Original language', fontsize=18)\na1.set_ylabel('revenue', fontsize=18) \n\nplt.show()","0b30fc40":"%%time\n\nplt.figure(figsize=(15,8))\nsns.countplot(train.release_year)\nplt.xticks(rotation=90)\nplt.xlabel('Years')\nplt.title('Number of movies launched every year')","fb411d34":"train['revenue'] = np.log1p(train['revenue'])","85d54fb9":"x = train.budget.values.reshape(-1,1)\ny = train.revenue\nreg = LinearRegression().fit(x, y)","f45ad20e":"print(f'Regression Score: {reg.score(x, y)}')\nprint(f'Regression Coefficient: {reg.coef_[0]}')\nprint(f'Regression Intercept: {reg.intercept_}')","cb8e4870":"predictions = reg.predict(test['budget'].values.reshape(-1,1))","181c0857":"idm = test['id'] \narrid = np.array(idm) ","5e6ebe72":"Submission = pd.DataFrame({\"id\" : arrid, \"revenue\" : predictions}).to_csv(\"submission.csv\", index=False)","b7df5d7e":"submission = pd.read_csv('submission.csv', index_col=0)\nsubmission.head(15)","e5467efc":"df_train = pd.read_csv('..\/input\/tmdb-box-office-prediction\/train.csv')\ndf_test = pd.read_csv('..\/input\/tmdb-box-office-prediction\/test.csv')\nsam_sub = pd.read_csv('..\/input\/tmdb-box-office-prediction\/sample_submission.csv')\nprint( \"train dataset:\", df_train.shape,\"\\n\",\"test dataset: \",df_test.shape,\"\\n\",\"sample_submission dataset:\", sam_sub .shape)","479e2e0a":"df_train.info()","a0946465":"df_train.head(5)","29931b30":"df_train.describe(include='all')","a480255c":"df_train.isna().sum().sort_values(ascending=False)","002fa1b8":"missing=df_train.isna().sum().sort_values(ascending=False)\nsns.barplot(missing[:8],missing[:8].index)\nplt.show()","10315460":"plt.style.use('seaborn')","77b17400":"import ast\ndict_columns = ['belongs_to_collection', 'genres', 'production_companies',\n                'production_countries', 'spoken_languages', 'Keywords', 'cast', 'crew']\n\ndef text_to_dict(df):\n    for column in dict_columns:\n        df[column] = df[column].apply(lambda x: {} if pd.isna(x) else ast.literal_eval(x) )\n    return df\n        \ndfx = text_to_dict(df_train)\nfor col in dict_columns:\n       df_train[col]=dfx[col]","8f463998":"df_train['belongs_to_collection'].apply(lambda x:len(x) if x!= {} else 0).value_counts()","7e81738d":"collections=df_train['belongs_to_collection'].apply(lambda x : x[0]['name'] if x!= {} else '?').value_counts()[1:15]\nsns.barplot(collections,collections.index)\nplt.show()","5a6a64c7":"df_train['tagline'].apply(lambda x:1 if x is not np.nan else 0).value_counts()","997c13f1":"plt.figure(figsize=(10,10))\ntaglines=' '.join(df_train['tagline'].apply(lambda x:x if x is not np.nan else ''))\n\nwordcloud = WordCloud(max_font_size=None, background_color='white', collocations=False,\n                      width=1200, height=1000).generate(taglines)\nplt.imshow(wordcloud)\nplt.title('Taglines')\nplt.axis(\"off\")\nplt.show()","624566cd":"keywords=df_train['Keywords'].apply(lambda x: ' '.join(i['name'] for i in x) if x != {} else '')\nplt.figure(figsize=(10,10))\ndata=' '.join(words for words in keywords)\nwordcloud = WordCloud(max_font_size=None, background_color='white', collocations=False,\n                      width=1200, height=1000).generate(data)\nplt.imshow(wordcloud)\nplt.title('Taglines')\nplt.axis(\"off\")\nplt.show()","1c53c643":"x=df_train['production_companies'].apply(lambda x : [x[i]['name'] for i in range(len(x))] if x != {} else []).values\nCounter([i for j in x for i in j]).most_common(20)","48f5aaeb":"countries=df_train['production_countries'].apply(lambda x: [i['name'] for i in x] if x!={} else []).values\ncount=Counter([j for i in countries for j in i]).most_common(10)\nsns.barplot([val[1] for val in count],[val[0] for val in count])","56d64b90":"df_train['spoken_languages'].apply(lambda x:len(x) if x !={} else 0).value_counts()","b6196a57":"lang=df_train['spoken_languages'].apply(lambda x: [i['name'] for i in x] if x != {} else [])\ncount=Counter([i for j in lang for i in j]).most_common(5)\nsns.barplot([val[1] for val in count],[val[0] for val in count])","92bdaf09":"genre=df_train['genres'].apply(lambda x: [i['name'] for i in x] if x != {} else [])\ncount=Counter([i for j in genre for i in j]).most_common(10)\nsns.barplot([val[1] for val in count],[val[0] for val in count])","6dd96a69":"dfx = text_to_dict(df_test)\nfor col in dict_columns:\n       df_test[col]=dfx[col]","fbb1d27d":"plt.figure(figsize=(10,5))\nplt.subplot(1,2,1)\nplt.title('skewed data')\nsns.distplot(df_train['revenue'])\nplt.subplot(1,2,2)\nplt.title('log transformation')\nsns.distplot(np.log(df_train['revenue']))\nplt.show()","c9b9731a":"df_train['log_revenue']=np.log1p(df_train['revenue'])","185ffe28":"plt.subplots(figsize=(10,5))\nplt.subplot(1,2,1)\nplt.hist(df_train['revenue'],bins=10,color='g')\nplt.title('skewed data')\nplt.subplot(1,2,2)\nplt.hist(np.log(df_train['revenue']),bins=10,color='g')\nplt.title('log transformation')\nplt.show()","9adb2d1c":"df_train['revenue'].describe()","93b54050":"plt.subplots(figsize=(10,5))\nplt.subplot(1,2,1)\nplt.hist(df_train['budget']+1,bins=10,color='g')\nplt.title('skewed data')\nplt.subplot(1,2,2)\nplt.hist(np.log(df_train['budget']+1),bins=10,color='g')\nplt.title('log transformation')\nplt.show()","8d849675":"plt.figure(figsize=(10,5))\nplt.subplot(1,2,1)\nsns.scatterplot(df_train['budget'],df_train['revenue'])\nplt.subplot(1,2,2)\nsns.scatterplot(np.log1p(df_train['budget']),np.log1p(df_train['revenue']))\nplt.show()","8ee2d2c2":"df_train['log_budget']=np.log1p(df_train['budget'])\ndf_test['log_budget']=np.log1p(df_train['budget'])","a05d6cd5":"plt.hist(df_train['popularity'],bins=30,color='violet')\nplt.show()","57deda9a":"sns.scatterplot(df_train['popularity'],df_train['revenue'],color='violet')\nplt.show()","ba94cd31":"def date(x):\n    x=str(x)\n    year=x.split('\/')[2]\n    if int(year)<19:\n        return x[:-2]+'20'+year\n    else:\n        return x[:-2]+'19'+year\ndf_train['release_date']=df_train['release_date'].fillna('1\/1\/90').apply(lambda x: date(x))\ndf_test['release_date']=df_test['release_date'].fillna('1\/1\/90').apply(lambda x: date(x))","d5beba0f":"#from datetime import datetime\ndf_train['release_date']=df_train['release_date'].apply(lambda x: datetime.strptime(x,'%m\/%d\/%Y'))\ndf_test['release_date']=df_test['release_date'].apply(lambda x: datetime.strptime(x,'%m\/%d\/%Y'))","945ceee4":"df_train['release_day']=df_train['release_date'].apply(lambda x:x.weekday())\ndf_train['release_month']=df_train['release_date'].apply(lambda x:x.month)\ndf_train['release_year']=df_train['release_date'].apply(lambda x:x.year)","cac49f32":"df_test['release_day']=df_test['release_date'].apply(lambda x:x.weekday())\ndf_test['release_month']=df_test['release_date'].apply(lambda x:x.month)\ndf_test['release_year']=df_test['release_date'].apply(lambda x:x.year)","2a6ece13":"day=df_train['release_day'].value_counts().sort_index()\nsns.barplot(day.index,day)\nplt.gca().set_xticklabels([\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"],rotation='45')\nplt.ylabel('No of releases')","b4a9ec93":"sns.catplot(x='release_day',y='revenue',data=df_train)\nplt.gca().set_xticklabels([\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"],rotation='90')\nplt.show()","a448a026":"sns.catplot(x='release_day',y='runtime',data=df_train)\nplt.gca().set_xticklabels([\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"],rotation='90')\nplt.show()","9c42fdbf":"plt.figure(figsize=(10,15))\nsns.catplot(x='release_month',y='revenue',data=df_train)\nmonth_lst = ['January', 'February', 'March', 'April', 'May', 'June', 'July','August', 'September', 'October', 'November', 'December']\nplt.gca().set_xticklabels(month_lst,rotation='90')\nplt.show()","ce5325b9":"plt.figure(figsize=(15,8))\nyearly=df_train.groupby(df_train['release_year'])['revenue'].agg('mean')\nplt.plot(yearly.index,yearly)\nplt.xlabel('year')\nplt.ylabel(\"Revenue\")\nplt.savefig('fig')","d3ee28db":"plt.figure(figsize=(10,5))\n\nplt.subplot(1,2,1)\nsns.distplot(np.log1p(df_train['runtime'].fillna(0)))\n\nplt.subplot(1,2,2)\nsns.scatterplot(np.log1p(df_train['runtime'].fillna(0)),np.log1p(df_train['revenue']))","d845c6b0":"df_train['homepage'].value_counts().sort_values(ascending=False)[:10]","eb943f81":"genres=df_train.loc[df_train['genres'].str.len()==1][['genres','revenue','budget','popularity','runtime']].reset_index(drop=True)\ngenres['genres']=genres.genres.apply(lambda x :x[0]['name'])","cf4d0cff":"genres=genres.groupby(genres.genres).agg('mean')","e629609b":"plt.figure(figsize=(15,10))\nplt.subplot(2,2,1)\nsns.barplot(genres['revenue'],genres.index)\n\nplt.subplot(2,2,2)\nsns.barplot(genres['budget'],genres.index)\n\nplt.subplot(2,2,3)\nsns.barplot(genres['popularity'],genres.index)\n\nplt.subplot(2,2,4)\nsns.barplot(genres['runtime'],genres.index)","c9308718":"crew=df_train['crew'].apply(lambda x:[i['name'] for i in x] if x != {} else [])\nCounter([i for j in crew for i in j]).most_common(20)","a214b67e":"cast=df_train['cast'].apply(lambda x:[i['name'] for i in x] if x != {} else [])\nCounter([i for j in cast for i in j]).most_common(20)","5ceb7b22":"def  prepare_data(df):\n    df['_budget_runtime_ratio'] = (df['budget']\/df['runtime']).replace([np.inf,-np.inf,np.nan],0)\n    df['_budget_popularity_ratio'] = df['budget']\/df['popularity']\n    df['_budget_year_ratio'] = df['budget'].fillna(0)\/(df['release_year']*df['release_year'])\n    df['_releaseYear_popularity_ratio'] = df['release_year']\/df['popularity']\n    df['_releaseYear_popularity_ratio2'] = df['popularity']\/df['release_year']\n    df['budget']=np.log1p(df['budget'])\n    \n    df['collection_name']=df['belongs_to_collection'].apply(lambda x: x[0]['name'] if x != {} else 0)\n    df['has_homepage']=0\n    df.loc[(pd.isnull(df['homepage'])),'has_homepage']=1\n    \n    le=LabelEncoder()\n    le.fit(list(df['collection_name'].fillna('')))\n    df['collection_name']=le.transform(df['collection_name'].fillna('').astype(str))\n    \n    le=LabelEncoder()\n    le.fit(list(df['original_language'].fillna('')))\n    df['original_language']=le.transform(df['original_language'].fillna('').astype(str))\n    \n    df['_num_Keywords'] = df['Keywords'].apply(lambda x: len(x) if x != {} else 0)\n    df['_num_cast'] = df['cast'].apply(lambda x: len(x) if x != {} else 0)\n    \n    df['isbelongto_coll']=0\n    df.loc[pd.isna(df['belongs_to_collection']),'isbelongto_coll']=1\n    \n    df['isTaglineNA'] = 0\n    df.loc[df['tagline'] == 0 ,\"isTaglineNA\"] = 1 \n\n    df['isOriginalLanguageEng'] = 0 \n    df.loc[ df['original_language'].astype(str) == \"en\" ,\"isOriginalLanguageEng\"] = 1\n    \n    df['ismovie_released']=1\n    df.loc[(df['status']!='Released'),'ismovie_released']=0\n    \n    df['no_spoken_languages']=df['spoken_languages'].apply(lambda x: len(x))\n    df['original_title_letter_count'] = df['original_title'].str.len() \n    df['original_title_word_count'] = df['original_title'].str.split().str.len() \n\n\n    df['title_word_count'] = df['title'].str.split().str.len()\n    df['overview_word_count'] = df['overview'].str.split().str.len()\n    df['tagline_word_count'] = df['tagline'].str.split().str.len()\n    \n    \n    df['collection_id'] = df['belongs_to_collection'].apply(lambda x : np.nan if len(x)==0 else x[0]['id'])\n    df['production_countries_count'] = df['production_countries'].apply(lambda x : len(x))\n    df['production_companies_count'] = df['production_companies'].apply(lambda x : len(x))\n    df['cast_count'] = df['cast'].apply(lambda x : len(x))\n    df['crew_count'] = df['crew'].apply(lambda x : len(x))\n\n    df['genders_0_crew'] = df['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\n    df['genders_1_crew'] = df['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\n    df['genders_2_crew'] = df['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))\n\n    for col in  ['genres', 'production_countries', 'spoken_languages', 'production_companies'] :\n        df[col] = df[col].map(lambda x: sorted(list(set([n if n in train_dict[col] else col+'_etc' for n in [d['name'] for d in x]])))).map(lambda x: ','.join(map(str, x)))\n        temp = df[col].str.get_dummies(sep=',')\n        df = pd.concat([df, temp], axis=1, sort=False)\n    df.drop(['genres_etc'], axis = 1, inplace = True)\n    \n    cols_to_normalize=['runtime','popularity','budget','_budget_runtime_ratio','_budget_year_ratio','_budget_popularity_ratio','_releaseYear_popularity_ratio',\n    '_releaseYear_popularity_ratio2','_num_Keywords','_num_cast','no_spoken_languages','original_title_letter_count','original_title_word_count',\n    'title_word_count','overview_word_count','tagline_word_count','production_countries_count','production_companies_count','cast_count','crew_count',\n    'genders_0_crew','genders_1_crew','genders_2_crew']\n    for col in cols_to_normalize:\n        print(col)\n        x_array=[]\n        x_array=np.array(df[col].fillna(0))\n        X_norm=normalize([x_array])[0]\n        df[col]=X_norm\n    \n    df = df.drop(['belongs_to_collection','genres','homepage','imdb_id','overview','id'\n    ,'poster_path','production_companies','production_countries','release_date','spoken_languages'\n    ,'status','title','Keywords','cast','crew','original_language','original_title','tagline', 'collection_id'\n    ],axis=1)\n    \n    df.fillna(value=0.0, inplace = True) \n\n    return df","6acd86a9":"def get_json(df):\n    global dict_columns\n    result=dict()\n    for col in dict_columns:\n        d=dict()\n        rows=df[col].values\n        for row in rows:\n            if row is None: continue\n            for i in row:\n                if i['name'] not in d:\n                    d[i['name']]=0\n                else:\n                    d[i['name']]+=1\n            result[col]=d\n    return result\n    \n    \n\n    \ntrain_dict=get_json(df_train)\ntest_dict=get_json(df_test)","7a804354":"df_train.shape","9b22017f":"df_test.shape","6f44bbcb":"for col in dict_columns :\n    \n    remove = []\n    train_id = set(list(train_dict[col].keys()))\n    test_id = set(list(test_dict[col].keys()))   \n    \n    remove += list(train_id - test_id) + list(test_id - train_id)\n    for i in train_id.union(test_id) - set(remove) :\n        if train_dict[col][i] < 10 or i == '' :\n            remove += [i]\n    for i in remove :\n        if i in train_dict[col] :\n            del train_dict[col][i]\n        if i in test_dict[col] :\n            del test_dict[col][i]","f602987a":"df_test['revenue']=np.nan\nall_data=prepare_data((pd.concat([df_train,df_test]))).reset_index(drop=True)\ntrain=all_data.loc[:df_train.shape[0]-1,:]\ntest=all_data.loc[df_train.shape[0]:,:]\nprint(train.shape)","8e0fa6ca":"all_data.head()","6a0cedff":"train.drop('revenue',axis=1,inplace=True)","eb6591f8":"y=train['log_revenue']\nX=train.drop(['log_revenue'],axis=1)","c6d2ec04":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.1)\nkfold=KFold(n_splits=3,random_state=42,shuffle=True)","cce69ff3":"X.columns","bd705555":"from keras import optimizers\n\n    \nmodel=models.Sequential()\nmodel.add(layers.Dense(356,activation='relu',kernel_regularizer=regularizers.l1(.001),input_shape=(X.shape[1],)))\nmodel.add(layers.Dense(256,kernel_regularizer=regularizers.l1(.001),activation='relu'))\nmodel.add(layers.Dense(1))\nmodel.compile(optimizer=optimizers.rmsprop(lr=.001),loss='mse',metrics=['mean_squared_logarithmic_error'])","742f0edf":"model.summary()","b3e23057":"keras.utils.plot_model(model)","c0bfdfa9":"epochs=50","70e6b5a5":"hist=model.fit(X_train,y_train,epochs=50,verbose=0,validation_data=(X_test,y_test))","9926c235":"hist.params","8a425790":"pd.DataFrame(hist.history).plot(figsize=(8,5))\nplt.grid(True)\nplt.gca().set_ylim(0,1)\nplt.show()","477b7495":"mae=hist.history['mean_squared_logarithmic_error']\nplt.plot(range(1,epochs),mae[1:],label='mae')\nplt.xlabel('epochs')\nplt.ylabel('mean_abs_error')\nmae=hist.history['val_mean_squared_logarithmic_error']\nplt.plot(range(1,epochs),mae[1:],label='val_mae')\nplt.legend()","353a7357":"mae=hist.history['loss']\nplt.plot(range(1,epochs),mae[1:],label='trraining loss')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nmae=hist.history['val_loss']\nplt.plot(range(1,epochs),mae[1:],label='val_loss')\nplt.legend()","2d9ba827":"test.drop(['revenue','log_revenue'],axis=1,inplace=True)","8455267f":"y=np.expm1(model.predict(test))\ndf_test['revenue']=y\ndf_test[['id','revenue']].to_csv('submission2.csv',index=False)","8c50dab7":"submission = pd.read_csv('submission2.csv', index_col=0)\nsubmission.head(15)","63807b41":"4.9. Budget","6b55837b":"4.7. Genre","9a67f273":"The movie Avengers got the max revenue..","52e23537":"4.5. Production countries","f2393cb3":"belongs to collection","7e206933":"Tagline","e14d6d0b":"Budget","716c7cf2":"Popularity vs revenue","0d7a751f":"Observations :\n    1. Missing values in :\n    belongs_to_collection,\n    homepage, \n    production_companies, \n    production_countries, \n    tagline, \n    Keywords,\n    spoken_languages,\n    crew,\n    cast,\n    overview,\n    genres,\n    runtime,\n    poster_path ","54c2876f":"Lets see which movie got the min revenue","355cad3a":"Spoken languages","eef0898d":"Production companies","54982199":"Release day of week","544de35c":"4.4. Production companies","51476f93":"# 4. Simple Linear Regression","bb8fd0e2":"Missing values","70a4caa5":"# 2. Describe the Data","8264aa98":"4.8. Revenue","023c6a99":"Popularity vs revenue","9dc6846a":"Extracting date features","c9a257cc":"4.2. Tagline","481fd5c2":"Keywords","bf37b39e":"The 15 Top Movie have English as Original Language ","bc6c32cc":"Feature Engineering","682b5cc3":"4.6. Spoken languages","920ac3ae":"Cast","58188b69":"# 3. Feature Exploration","08e02d5d":"# 1. Loading the Data","d769726c":"Production countries","cb8518f6":"The budget has a great impact in movie revenue, so let predicte the reveveu with a Simple Linear Regression","86c22428":"Revenue vs budget","6eaf360c":"# 5. Keras model","b0f1e57c":"External Data (release dates , popularity and votes )\n\nContains releases dates for every country.","f36a3188":"Year vs revenue","ba6dcfe3":"Popularity","e5eb080d":"Missing values","9e284c85":"4.1. belongs to collection","5986cc58":"Crew","595f1ff3":"Relation between popularity and revenue","fac04c6a":"Popularity","cdd3bd96":"Revenue","e8a09f21":"Splitting train and test","f0931990":"Runtime","b65ce7b4":"Lets see which movie got the max revenue","3c0ba977":"We need some cleaning i'll take in this case the cleaning of another KERNEL from https:\/\/www.kaggle.com\/zero92","935b6033":"Homepage","8e77f4a5":"Revenue vs budget","2064bbd4":"In reference with kernel by B.H","f4d5fcd1":"4.3. Keywords","33ab8b29":"A big budget can guarantee a good revenue.","f286ebae":"Genre","0d61aaea":"Let's take a peak on the top 15 movies !"}}