{"cell_type":{"26c61023":"code","390b8318":"code","52a08ded":"code","e3c4ef41":"code","706ae24b":"code","af8b0fbc":"code","fbc5b1ab":"code","e1036b8c":"code","870a33a8":"code","dd398962":"code","613bcdf9":"code","d325e8f6":"code","1235d91d":"code","4535c99e":"markdown","9f92b3b8":"markdown","7b4c6315":"markdown","8472a7e4":"markdown","7630a607":"markdown"},"source":{"26c61023":"# Import libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.layers import *\nfrom keras.models import *\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nimport os, shutil\nimport warnings\nwarnings.filterwarnings('ignore')","390b8318":"# Let's plot a few images\ntrain_path = \"..\/input\/vegetable-image-dataset\/Vegetable Images\/train\"\nvalidation_path = \"..\/input\/vegetable-image-dataset\/Vegetable Images\/validation\"\ntest_path = \"..\/input\/vegetable-image-dataset\/Vegetable Images\/test\"\n\nimage_categories = os.listdir('..\/input\/vegetable-image-dataset\/Vegetable Images\/train')\n\ndef plot_images(image_categories):\n    \n    # Create a figure\n    plt.figure(figsize=(12, 12))\n    for i, cat in enumerate(image_categories):\n        \n        # Load images for the ith category\n        image_path = train_path + '\/' + cat\n        images_in_folder = os.listdir(image_path)\n        first_image_of_folder = images_in_folder[0]\n        first_image_path = image_path + '\/' + first_image_of_folder\n        img = image.load_img(first_image_path)\n        img_arr = image.img_to_array(img)\/255.0\n        \n        \n        # Create Subplot and plot the images\n        plt.subplot(4, 4, i+1)\n        plt.imshow(img_arr)\n        plt.title(cat)\n        plt.axis('off')\n        \n    plt.show()\n\n# Call the function\nplot_images(image_categories)\n        ","52a08ded":"# Creating Image Data Generator for train, validation and test set\n\n# 1. Train Set\ntrain_gen = ImageDataGenerator(rescale = 1.0\/255.0) # Normalise the data\ntrain_image_generator = train_gen.flow_from_directory(\n                                            train_path,\n                                            target_size=(150, 150),\n                                            batch_size=32,\n                                            class_mode='categorical')\n\n# 2. Validation Set\nval_gen = ImageDataGenerator(rescale = 1.0\/255.0) # Normalise the data\nval_image_generator = train_gen.flow_from_directory(\n                                            validation_path,\n                                            target_size=(150, 150),\n                                            batch_size=32,\n                                            class_mode='categorical')\n\n# 3. Test Set\ntest_gen = ImageDataGenerator(rescale = 1.0\/255.0) # Normalise the data\ntest_image_generator = train_gen.flow_from_directory(\n                                            test_path,\n                                            target_size=(150, 150),\n                                            batch_size=32,\n                                            class_mode='categorical')","e3c4ef41":"# Print the class encodings done by the generators\nclass_map = dict([(v, k) for k, v in train_image_generator.class_indices.items()])\nprint(class_map)","706ae24b":"# Build a custom sequential CNN model\n\nmodel = Sequential() # model object\n\n# Add Layers\nmodel.add(Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=[150, 150, 3]))\nmodel.add(MaxPooling2D(2, ))\nmodel.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'))\nmodel.add(MaxPooling2D(2))\n\n# Flatten the feature map\nmodel.add(Flatten())\n\n# Add the fully connected layers\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(15, activation='softmax'))\n\n# print the model summary\nmodel.summary()","af8b0fbc":"# Compile and fit the model\nearly_stopping = keras.callbacks.EarlyStopping(patience=5) # Set up callbacks\nmodel.compile(optimizer='Adam', loss='categorical_crossentropy', metrics='accuracy')\nhist = model.fit(train_image_generator, \n                 epochs=100, \n                 verbose=1, \n                 validation_data=val_image_generator, \n                 steps_per_epoch = 15000\/\/32, \n                 validation_steps = 3000\/\/32, \n                 callbacks=early_stopping)","fbc5b1ab":"# Plot the error and accuracy\nh = hist.history\nplt.style.use('ggplot')\nplt.figure(figsize=(10, 5))\nplt.plot(h['loss'], c='red', label='Training Loss')\nplt.plot(h['val_loss'], c='red', linestyle='--', label='Validation Loss')\nplt.plot(h['accuracy'], c='blue', label='Training Accuracy')\nplt.plot(h['val_accuracy'], c='blue', linestyle='--', label='Validation Accuracy')\nplt.xlabel(\"Number of Epochs\")\nplt.legend(loc='best')\nplt.show()","e1036b8c":"# Predict the accuracy for the test set\nmodel.evaluate(test_image_generator)","870a33a8":"# Testing the Model\ntest_image_path = '..\/input\/vegetable-image-dataset\/Vegetable Images\/test\/Broccoli\/1011.jpg'\n\ndef generate_predictions(test_image_path, actual_label):\n    \n    # 1. Load and preprocess the image\n    test_img = image.load_img(test_image_path, target_size=(150, 150))\n    test_img_arr = image.img_to_array(test_img)\/255.0\n    test_img_input = test_img_arr.reshape((1, test_img_arr.shape[0], test_img_arr.shape[1], test_img_arr.shape[2]))\n\n    # 2. Make Predictions\n    predicted_label = np.argmax(model.predict(test_img_input))\n    predicted_vegetable = class_map[predicted_label]\n    plt.figure(figsize=(4, 4))\n    plt.imshow(test_img_arr)\n    plt.title(\"Predicted Label: {}, Actual Label: {}\".format(predicted_vegetable, actual_label))\n    plt.grid()\n    plt.axis('off')\n    plt.show()\n\n# call the function\ngenerate_predictions(test_image_path, actual_label='Brocoli')","dd398962":"# Let's test the model on an image from an external source\n!wget \"https:\/\/www.dropbox.com\/s\/i020rz847u8bq09\/beans.jpg?dl=0\"","613bcdf9":"!wget \"https:\/\/www.dropbox.com\/s\/lge1plvr4mg5w7y\/potato_2.jpg?dl=0\"","d325e8f6":"# Generate predictions for external images\nexternal_image_path_1 = \".\/beans.jpg?dl=0\"\ngenerate_predictions(external_image_path_1, actual_label='Bean')","1235d91d":"# Generate predictions for external image\nexternal_image_path_2 = \".\/potato_2.jpg?dl=0\"\ngenerate_predictions(external_image_path_2, actual_label='Potato')","4535c99e":"# Prepare the Dataset","9f92b3b8":"**Model trained for 15 Epochs**","7b4c6315":"> ## T*he model performs well on both internal as well as external test images. In the upcoming notebook edits, I will implement various concepts like Data Augmentation and Transfer Learning and prepare a comparison between all these models. I hope you find the notebook informative. Please do share your feedback in the comment section and please do upvote it, if you found it helpful. Thanks and Happy Learning :)*","8472a7e4":"# Building a CNN model","7630a607":"# Visualise the Images"}}