{"cell_type":{"6fe7f530":"code","3a985463":"code","ec96a06f":"code","b3a89cf6":"code","7496c854":"code","3340a892":"code","de261a00":"code","f764b015":"code","567538f2":"code","03789a25":"code","9d3872db":"markdown","1dfa7056":"markdown","a551972a":"markdown","a8c0e1a5":"markdown","279eafa7":"markdown","8ec705cb":"markdown"},"source":{"6fe7f530":"#Import Statements\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.models import  Sequential\nfrom tensorflow.keras import layers \nfrom keras.utils.np_utils import to_categorical\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom keras.callbacks import ReduceLROnPlateau\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\n\nimport seaborn as sns","3a985463":"#Importing data\ntrain = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\n\ntrain.shape, test.shape","ec96a06f":"#Creating Train and Test arays\ny = train.iloc[:,0].values.astype('int32') #Extracting values in order to store data as array\nX = train.iloc[:,1:].values.astype('float32')\nX_test = test.values.astype('float32')","b3a89cf6":"#Constraining data between 0 and 1\nX = X \/ 255.0\nX_test = X_test \/ 255.0\n\n#Reshaping data in the form (example, width, height, channel)\nX = X.reshape(-1,28,28,1)\nX_test = X_test.reshape(-1,28,28,1)\n\n#Converting y using onehot encoding\ny = to_categorical(y)\ny","7496c854":"#Split data into train and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n\n#Instantiate generator and data augmentation\ngenerator = ImageDataGenerator(rotation_range=8, \n                               width_shift_range=0.08, \n                               shear_range=0.3,\n                               height_shift_range=0.08, \n                               zoom_range=0.08\n                              )\n\n#Create batch generators for train and validation sets\ntrain_batches = generator.flow(X_train, y_train, \n                               batch_size = 64)\n\nval_batches = generator.flow(X_val, y_val, \n                             batch_size = 64)","3340a892":"#Callbacks\n#Early Stopping \nearly_stopping = EarlyStopping(min_delta=0.001, \n                               patience=10, \n                               restore_best_weights=True) #Use this if you don't have a GPU\n\n#Learning Rate Reduction\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\n","de261a00":"#Model Creation\n#Model Architecture can be found here: https:\/\/www.kaggle.com\/sajaldeb25\/kaggle-digit-recognizer-my-best-model-cnn-999. \n#All credits for architecture to the author. A lot of time and effort went into optimization of the model and all the hyperparameters. \n\nmodel2 = Sequential([\n    layers.Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (28,28,1)),\n    layers.BatchNormalization(),\n    layers.Conv2D(filters = 64, kernel_size = (5,5), padding = 'Same', activation = 'relu'),\n    layers.BatchNormalization(),\n    layers.MaxPool2D(pool_size = (2,2)),\n    layers.Dropout(0.25),\n    \n    layers.Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation = 'relu'),\n    layers.BatchNormalization(),\n    layers.Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation = 'relu'),\n    layers.BatchNormalization(),\n    layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n    layers.Dropout(0.25),\n    \n    layers.Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation = 'relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.25),\n    \n    layers.Flatten(),\n    layers.Dense(256, activation = 'relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.25),\n    \n    layers.Dense(10, activation = 'softmax')\n])\n\n#Define Optimizer\noptimizer = tf.keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n\n\n#Compile Model\nmodel2.compile(optimizer = optimizer,\n             loss = 'categorical_crossentropy',\n             metrics = ['accuracy'])\n\n#Fit Model\nhistory = model2.fit_generator(\n    generator=train_batches, \n    steps_per_epoch=525,\n    epochs=50,  \n    validation_data=val_batches, \n    validation_steps=100,\n    callbacks = [learning_rate_reduction]\n)","f764b015":"#Plotting the results\n\nplt.figure(figsize = (15,5))\n\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label='val_accuracy')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend(loc='lower right')\n# plt.yticks(np.linspace(0.96,0.995))\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='loss')\nplt.plot(history.history['val_loss'], label='val_loss')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend(loc='lower left')\n\n\nplt.tight_layout()\nplt.show()","567538f2":"#Making Predictions for test set\npredictions = model2.predict_classes(X_test)","03789a25":"#Creating dataframe and saving it as a .csv file to submit\nsubmission_data = pd.DataFrame({'ImageId': range(1,28001), 'Label': predictions})\nsubmission_data.to_csv(\"Submission_Digit_Recognition_model2.csv\", index=False, header=True)","9d3872db":"## Model Creation\n\n---\nTHe model we are going to use is an optimized CNN along with learning rate decay and early stopping. The architecture of the model can be found on this notebook: https:\/\/www.kaggle.com\/sajaldeb25\/kaggle-digit-recognizer-my-best-model-cnn-999. All credits to the author of that notebook for figuring out optimal parameters. \n\nNote to beginners:    \nI was confused at first between the difference between using .fit and .fit_generator. The difference is that the latter is used when the dataset is extremely large. It divides the dataset into batches to be used by the model and only stores the data being used by the current batch to memory. This enables us to work with extremely large datasets with limited amounts of memory. \n\n---","1dfa7056":"## Creating Submission File","a551972a":"## Data Prep\n\n---\n\nAfter extracting the data and storing them as arrays, we need to reshape the data so that it can be fed into a CNN. \n\nWe reshape the data in the form (example_number, height, width, channel)\n\nHeight and width can be derived by taking the square root of the number of columns in the dataset. That is to say, that since each row in the dataset contains data for a single image, then the number of columns is the total number of pixels in the image. In our example, we have 784 columns in each row, i.e. 784 pixels per image. In a square format (which is the format the images are in) this comes to images of the size 28x28 (sqrt(784) == 28).\n\nAdditionally, for X_train and X_test, we divide the data by 255 in order to constain it between 0 and 1. We choose 255 because in an image, this number represents the maximum value for a pixel's intensity. 0 represents a white pixel and 1 represents a black one. Numbers in between represent various shades of grey. \n\nFor y_train, we onehot encode the data using the handy 'to_categorical' function from keras.utils.np_utils.\n\n---","a8c0e1a5":"## Conclusion\n\nThe model above got me an accuracy of 0.99503.\n\nMethods to improve upon this model:\n- Use an ensemble of CNNs\n- Use data augmentation.\n- A useful tutorial for doing the above can be found here: https:\/\/www.kaggle.com\/cdeotte\/25-million-images-0-99757-mnist\n\nNotebooks referred to:    \nhttps:\/\/www.kaggle.com\/poonaml\/deep-neural-network-keras-way    \nhttps:\/\/www.kaggle.com\/abhiram8\/mnist-digit-classification-cnn-beginner-s-guide    \nhttps:\/\/www.kaggle.com\/sajaldeb25\/kaggle-digit-recognizer-my-best-model-cnn-999    \nhttps:\/\/www.kaggle.com\/c\/digit-recognizer\/discussion\/61480    \n\nI hope this notebook was helpful to you. Please comment if there are any questions or if I can help you in any way.\n\nThank you for reading!","279eafa7":"---\nAfter restructuring the data, we now split our data into train and test sets. Upon doing so, we can then construct a generator for both the training and testing data that feeds our model with batches of our data for training. \n\nAdditionally, we'll augment the data using ImageDataGenerator.\n\n---","8ec705cb":"# MINST Digit Classification\n---\n\nRohit Baney    \n7th June 2021\n\n---\n\nThe MINST dataset is known as the 'hello world' of computer vision datasets. \n\nThe following Deep Neural Network is my attempt at Digit Classification using a Convolutional Neural Network (CNN).\n\nThe goal of this project is to successfully classify images of handwritten digits using a neural network. \n\nMore information about the dataset can be found here: https:\/\/www.kaggle.com\/scolianni\/mnistasjpg\n\n---"}}