{"cell_type":{"84b4c6ee":"code","f6a400e7":"code","2b6d89ef":"code","4b765fbf":"code","1fde80d8":"code","48c10e60":"code","7da497ff":"code","8b7dda23":"code","8b5f042a":"code","2afd2f75":"code","1d3c7b53":"code","4fd921bf":"code","289d7673":"code","c86846cd":"code","902d50d2":"code","1d5143c5":"code","d6373fe3":"code","93241b61":"code","5192041a":"code","8d0a274b":"code","041c1122":"code","5dbb4c3f":"code","b3783ab7":"code","1cc3fd97":"code","f8e4ca70":"code","b5bd8c2f":"code","8c271351":"code","1ee97775":"code","aed2c058":"code","e2670bdc":"code","ed51199f":"code","65a2b0d8":"code","1e1fad39":"code","debd4f35":"code","2bb8c837":"code","c95fa85e":"code","b540ece5":"markdown","92d199f5":"markdown","9c9aa56d":"markdown","516ec59d":"markdown","2955f537":"markdown","c2843712":"markdown","8e0c8e85":"markdown","450d069f":"markdown","3add2052":"markdown","cd85b48e":"markdown","f345dfd1":"markdown","a2230ff2":"markdown","82b31ec7":"markdown","9a8687a0":"markdown","da57c73d":"markdown","92dc25e8":"markdown","942c3904":"markdown","27257776":"markdown","918db942":"markdown","8a71a40e":"markdown","14a43292":"markdown","79db0d22":"markdown","3ba805e1":"markdown","bfde3e6a":"markdown","4acb0c26":"markdown","f7b641a7":"markdown","db50e882":"markdown","a13c9b22":"markdown","5ed67ded":"markdown","1aa98a3e":"markdown","2cdd8247":"markdown","a81adec2":"markdown","2521fd12":"markdown","2a956721":"markdown","f6ed56dd":"markdown","b1fa4279":"markdown","cec29d0c":"markdown","98c95b9b":"markdown","08f90734":"markdown","e1bb5225":"markdown","e7ed3558":"markdown","5da14bdd":"markdown","a2d8c6f3":"markdown","b043f11a":"markdown","28cb0983":"markdown","0afde743":"markdown","bba1fcf5":"markdown","094ed032":"markdown","74d5cdfd":"markdown","a57fb9b5":"markdown","1b983d3d":"markdown"},"source":{"84b4c6ee":"import pandas as pd\nimport numpy as np \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","f6a400e7":"Loan_data=pd.read_csv('..\/input\/loan-prediction-problem-dataset\/train_u6lujuX_CVtuZ9i.csv')\nLoan_data.head()","2b6d89ef":"Loan_data.shape ","4b765fbf":"Loan_data.info()","1fde80d8":"Loan_data.isnull().sum().sort_values(ascending=False)","48c10e60":"Loan_data.drop(\"Loan_ID\",axis=1,inplace=True)","7da497ff":"Loan_data.describe(include=\"all\")","8b7dda23":"Loan_data.columns","8b5f042a":"Loan_data['Credit_History']=Loan_data[\"Credit_History\"].astype(\"object\")","2afd2f75":"Loan_data.duplicated().any()","1d3c7b53":"#Loan Status.\nfigsize=(7,5)\nsns.countplot(Loan_data[\"Loan_Status\"])","4fd921bf":"#Credit_History\ngrid=sns.FacetGrid(Loan_data,col=\"Loan_Status\",size=3.5)\ngrid.map(sns.countplot,\"Credit_History\")","289d7673":"#Gender\ngrid=sns.FacetGrid(Loan_data,col=\"Loan_Status\",size=3.5)\ngrid.map(sns.countplot,\"Gender\")","c86846cd":"#Marriage\ngrid=sns.FacetGrid(Loan_data,col=\"Loan_Status\",size=3.5)\ngrid.map(sns.countplot,\"Married\")","902d50d2":"#dependents \nplt.figure(figsize=(8,5))\nsns.countplot(x=\"Dependents\",hue=\"Loan_Status\",data=Loan_data,saturation=5)","1d5143c5":"#Education\nplt.figure(figsize=(7,6))\nsns.countplot(x=\"Education\",hue=\"Loan_Status\",data=Loan_data,saturation=5)","d6373fe3":"#Self employed\nplt.figure(figsize=(8,5))\nsns.countplot(x=\"Self_Employed\",hue=\"Loan_Status\",data=Loan_data,saturation=5)","93241b61":"#property area \nplt.figure(figsize=(7,5))\nsns.countplot(x=\"Property_Area\",hue=\"Loan_Status\",data=Loan_data,saturation=5)","5192041a":"Loan_mean_amount = Loan_data.groupby(['Property_Area','Education'])['LoanAmount'].mean().reset_index()\n\nplt.figure(figsize=(9,6))\nsns.barplot(x='Property_Area',y='LoanAmount',hue='Education',data=Loan_data)\nplt.xlabel(\"Property Area of Education\")\nplt.ylabel(\"Average loan amount\")\nplt.show()","8d0a274b":"cateagorical_data=[]\nNumerical_data=[]\n\nfor i,c in enumerate(Loan_data.dtypes):\n  if c==object:\n    cateagorical_data.append(Loan_data.iloc[:,i])\n  else:\n      Numerical_data.append(Loan_data.iloc[:,i])","041c1122":"cateagorical_data=pd.DataFrame(cateagorical_data).transpose()\nNumerical_data=pd.DataFrame(Numerical_data).transpose()","5dbb4c3f":"cateagorical_data.head()","b3783ab7":"Numerical_data.head()","1cc3fd97":"cateagorical_data=cateagorical_data.apply(lambda x:x.fillna(x.value_counts().index[0]))\ncateagorical_data.isnull().sum().any()","f8e4ca70":"Numerical_data=Numerical_data.apply(lambda x:x.fillna(x.mean()))\nNumerical_data.isnull().sum().any()","b5bd8c2f":"from sklearn.preprocessing import LabelEncoder\nLE=LabelEncoder()\n\nLabel_value={\"Y\":0,\"N\":1}\nLabel=cateagorical_data[\"Loan_Status\"]\ncateagorical_data.drop(\"Loan_Status\",axis=1,inplace=True)\nLabel=Label.map(Label_value)","8c271351":"for i in cateagorical_data:\n  cateagorical_data[i]=LE.fit_transform(cateagorical_data[i])","1ee97775":"cateagorical_data.head()","aed2c058":"Label","e2670bdc":"Loan_data=pd.concat([cateagorical_data,Numerical_data,Label],axis=1)","ed51199f":"plt.figure(figsize=(10,7))\nplt.title(\"Correlation Matrix\")\nsns.heatmap(Loan_data.corr(),annot=True,)","65a2b0d8":"from sklearn.model_selection import train_test_split\nX=pd.concat([cateagorical_data,Numerical_data],axis=1)\nY=Label","1e1fad39":"x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.3,random_state=28)","debd4f35":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\n\nmodels={\"LogisticRegression\":LogisticRegression(random_state=28),\n        \"KNeighborsClassifier\":KNeighborsClassifier(),\n        \"DecisionTreeClassifier\":DecisionTreeClassifier(max_depth=1,random_state=28),\n        \"RandomForestClassifier\":RandomForestClassifier(n_estimators=400,oob_score=True,random_state=28,n_jobs=-1),\n        \"AdaBoostClassifier\":AdaBoostClassifier(random_state=28)\n        }","2bb8c837":"from sklearn.metrics import precision_score,accuracy_score\n\ndef loss(y_true,y_pred,retu=False):\n  pre=precision_score(y_true,y_pred)\n  acc=accuracy_score(y_true,y_pred)\n\n\n  if retu:\n    return pre,acc\n  else:\n      print(' pre: %.3f\\n  acc: %.3f\\n '%(pre,acc))","c95fa85e":"def train_pred_score(models,x,y):\n  for name,model in models.items():\n    print(name,\" :\")\n    model.fit(x,y)\n    loss(y,model.predict(x))\n    print(\"-\"*30)\n\ntrain_pred_score(models,x_train,y_train)","b540ece5":"Here I am defining a Business problem as without a problem there is no solution, banks want to simplify the loan process and make it more smooth and want to classify people to whom to lend and whom not to.","92d199f5":"this countplot of property area with loan status shows that:\n\n* most of the people who got the loan lives in semi urban area.","9c9aa56d":"**Why there is a need to create a loan prediction model??**","516ec59d":"**Plotting and finding Insights.**","2955f537":"**Importing The Library And Data**","c2843712":"this is the countplot of the gender with their loan Status.\n\n* Most of the people who got the loan are Male,Female stays low in both the case.\n","8e0c8e85":"**Business Problem**","450d069f":"this is the countplot of the dependents with their loan Status.\n\n* Most of the poeple who got the loan has 0 dependents.","3add2052":"Now lets take a look in Numerical Data we have.","cd85b48e":"Now models have been built we,will like to see how well they perform for that we are suing the 2 score.\n\n* precision_score\n\n* accuracy_score","f345dfd1":"now lets check how many null values are present in our data.","a2230ff2":"this countplot of self employed with their loan status shows that:\n\n* most of the peopel who got the loan is  not self employed.","82b31ec7":"\nNow,here we want to fill our Null values in the Cateagorical Data by the most number of repeated values in that Feature Column.","9a8687a0":"Now we will import our LabelEncoder so that we can encode our Cateagorical Data into the o and 1 so that further it will be easy to know the correlation among them with the help of correlation matrix.","da57c73d":"I believe that when a bank lends a loan to a customer there are many factors which a bank see in order to be sure that will the customer will be able to pay the loan back or not.its easy for a bank if there are less number of people applying for the loan but as we know this is the 20th-century everyday bank will be receiving hundreds of loan request and to make the process easy we can apply Data Science in order for much smoother and Data drove decisions which can increase the chances of the bank to know whom to lend the loan and who are volatile not to lend.","92dc25e8":"Now lets see how our Cateagorical Data looks like.","942c3904":"At last we will print the accucracy of all the models.","27257776":"Now,in Case of our Numerical Data we will will the Null values with the Help of Mean of that Feature\/variable Column because an average explains the Data more precisely.","918db942":"lets work on the cateagorical data and numerical data seperately now .","8a71a40e":"Notice that we have kept the random see to 28 so that every time we run it, selects the same randomness and we get the same output.","14a43292":"#There is a short way to EDA the data its given below if you like you can use it as it will do all the EDA for you and will give you a output in the HTML format.\n\n\n'''pip install pandas-profiling\nfrom pandas_profiling import ProfileReport\nprof = ProfileReport(Loan_data)\nprof.to_file(output_file='output.html')'''","79db0d22":"As,we can see we have a Loan_ID as a variable it does not provide any insight about the Data ,so we will remove it.","3ba805e1":"**Data Source**","bfde3e6a":"The Data have been taken from Kaggle ,the kingdom of Data people.\n\nWhat we will be doing though this Model Building.\n\n1. We will first analyse the Data and try to understand the Features\/variables.\n2. We will then Visualize the Data for better understanding.\n3. We will then use the Machine Learning methods to Train and predict.\n4. At last we will define at what accuracy we can classify correctly.","4acb0c26":"Hello Data People i have tried to keep the Kernel as informative as possible ,if you like it leave a upvote ,it really motivates.","f7b641a7":"As,we know the credit History Variable is object type lets convert it into object.","db50e882":"Now ,we would like to the the statistics like Count,mean,mode,stf,quantiles..etc. of all our our Features\/Variables.","a13c9b22":"Now we will import the libraries each one has a specific role to play.\n\n**Pandas:** pandas is a library written for the Python programming language for data manipulation and analysis.\n\n**Numpy:** NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays\n\n**Seaborn:** Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics.\n\n**Matplotlib:** Matplotlib is a plotting library for the Python programming language and its numerical mathematics extension NumPy.","5ed67ded":"this countplot of Education with there loan Status show that:\n\n* most of the people who got the loan is Graduate.","1aa98a3e":"Now we will read the data with the help of pandas.","2cdd8247":"Lets,see what are the name of the columns of our Data Frame.","a81adec2":"Now we wil import the models we want to use:\n\n* LogisticRegression\n\n* KNeighborsClassifier\n\n* DecisionTreeClassifier\n\n* RandomForestClassifier\n\n* AdaBoostClassifier","2521fd12":"The Below plot is a countplot of Loan_status.\n\n* Here we can see there are more cases of rejecting a loan and less case of actually acepting a loan.\n\n* Approximately loan accept is less then 50% of the loan rejected in the Bank.","2a956721":"**Exploratory Data Analysis**","f6ed56dd":"Now,lets see how our Cateagorical Data looks like.","b1fa4279":"Now,we will coccat all the Cateagorical data,Numerical Data and label to form a single Data frame named Loan Data.","cec29d0c":"**Loan Prediction Model**","98c95b9b":"**Form the various model we have plot here we can see that AdaBoostClassifier is performing the best as ,it is classifying all the Data points which were not classified in the first stumps and so on.**\n\n\nWe could do a ensemble modelling to (votting) but as our model reached 91% it not recommended to do ensemble,you can try in will enventually will decrease the accuracy.","08f90734":"in this barplot we cab see it is grouped by property area and then by education ,which is the plotted by average loan amount on y axis.\n\n* it gives out the insight that:\n\n* Graduate people in all the property area are taking off a high amount of average loan amount. ","e1bb5225":"This is the countplot(frequency of Data) of Credit History with Loan Status devided in the Facetgrid.\n\n* The people who have a credit score 1 have a better chance to get a loan.","e7ed3558":"Now let us plot the correlation matrix.\n\n* We have seen no feature pose a high correlation with any other feature so there is no need to club or remove any feature.\n\n* Though loan amount and application income have a good correation.","5da14bdd":"This is the countplot of marriage with their loan status.\n\n* Most of the people who got the loan is Married.","a2d8c6f3":"Here we can see that we have done the 70% train and 30% split.","b043f11a":"Lets first through some light on what a loan is actually.\n1. A loan is when money is given to another party in exchange for repayment of the loan principal amount plus interest.\n2. Loan terms are agreed to by each party before any money is advanced.\n3. A loan may be secured by collateral such as a mortgage or it may be unsecured such as a credit card.\n4. Revolving loans or lines can be spent, repaid, and spent again, while term loans are fixed-rate, fixed-payment loans.","28cb0983":"Here,using the fit_transform we are applying the Label_encoding in one go with fitting and transforming.","0afde743":"**Modelling**","bba1fcf5":"Checking if there are any dublicates.","094ed032":"Now first check the size of the Data.","74d5cdfd":"Checking the Labels,which is our dependent variables.","a57fb9b5":"For the process of modelling we have to first split the data into Train and Test data .","1b983d3d":"Now the best step is to look out what is the data types of the features ,if there is some missing values,how much values are there in the feature\/variable."}}