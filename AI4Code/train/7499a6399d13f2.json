{"cell_type":{"e4ead218":"code","34daa28a":"code","e73911ff":"code","d8c6a779":"code","677cdd3b":"code","7efd7990":"code","9e4873db":"code","05cc17a2":"code","38476789":"code","6b2ad3e7":"code","198d17c2":"code","718be4de":"code","49e4babb":"code","6304f000":"code","7992b99e":"code","5acae795":"code","bb6a9fef":"code","ed62dd22":"code","2547c6ed":"code","aac93ac0":"code","bd4ec2a8":"code","038eec61":"code","3882b1b8":"code","4f9f3b82":"code","f7fbe38c":"code","b8bdd803":"code","1ca86e25":"code","126722ff":"code","f3613b1c":"code","96f7e946":"code","bc0d5db2":"markdown","0dcb5618":"markdown","720eb12f":"markdown","6f88ab18":"markdown","e086c0d9":"markdown","2888aac7":"markdown","fa8ca669":"markdown","79e28331":"markdown","873ea9de":"markdown","870ebbdc":"markdown","2a9c9d92":"markdown","5719d13b":"markdown","8e43de28":"markdown","dca68b90":"markdown","db2411ac":"markdown","258c10a8":"markdown","d60fae78":"markdown","0f89761c":"markdown"},"source":{"e4ead218":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","34daa28a":"#Importing required libraries for visualization\nimport warnings\nwarnings.filterwarnings('ignore')\nimport matplotlib.pyplot as plt\nimport seaborn as sns","e73911ff":"#Reading the data set\ndf = pd.read_csv('\/kaggle\/input\/heart-disease-prediction-using-logistic-regression\/framingham.csv')","d8c6a779":"#Sneak Peek over the dataset \ndf.head()","677cdd3b":"df.shape","7efd7990":"df.info()","9e4873db":"df.isnull().sum()","05cc17a2":"df['education'].fillna(1,inplace=True)\ndf['cigsPerDay'].fillna(df['cigsPerDay'].median(),inplace=True)\ndf['BPMeds'].fillna(0,inplace=True)\ndf['totChol'].fillna(df['totChol'].mean(),inplace=True)\ndf['BMI'].fillna(df['BMI'].mean(),inplace=True)\ndf['heartRate'].fillna(df['heartRate'].mean(),inplace=True)\ndf['glucose'].fillna(df['glucose'].mean(),inplace=True)","38476789":"df.isnull().sum()","6b2ad3e7":"plt.figure(figsize=(10,7))\nsns.boxplot(data=df,x='heartRate',whis=3)\nplt.show()","198d17c2":"#Removing the outliers\ndf[df['heartRate']>125]","718be4de":"df.drop([339,358,3142],inplace=True)","49e4babb":"#Splitting categorical and numerical data\ndf_num = df[['age', 'cigsPerDay', 'totChol', 'sysBP', 'diaBP', 'BMI', 'heartRate', 'glucose']]\ndf_cat = df[['male', 'education', 'currentSmoker', 'BPMeds', 'prevalentStroke', 'prevalentHyp', 'diabetes','TenYearCHD']]","6304f000":"from scipy.stats import skew\nfor col in df_num:\n  try:\n    print(col,\"=\",skew(df_num[col]))\n    sns.distplot(df_num[col])\n    plt.show()\n  except:\n    pass\n  finally:\n    print(\"**********************************************\")","7992b99e":"df_num['cigsPerDay'] = np.sqrt(df_num['cigsPerDay'])\ndf_num['totChol'] = np.sqrt(df_num['totChol'])\ndf_num['sysBP'] = np.log(df_num['sysBP'])\ndf_num['diaBP'] = np.sqrt(df_num['diaBP'])\ndf_num['BMI'] = np.sqrt(df_num['BMI'])","5acae795":"df_num.drop('glucose',axis=1,inplace=True)","bb6a9fef":"df_new = pd.concat([df_num,df_cat],axis=1)","ed62dd22":"#Dataset before performing scaling \ndf_new.head()","2547c6ed":"from sklearn.preprocessing import MinMaxScaler\nfor col in df_new:\n  mm = MinMaxScaler()\n  df_new[col] = mm.fit_transform(df_new[[col]])\ndf_new.head()","aac93ac0":"#Dividing the dataset into train and test data\nfrom sklearn.model_selection import train_test_split\n\nx = df_new.drop('TenYearCHD',axis=1)\ny = df_new['TenYearCHD']\n\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3)","bd4ec2a8":"from sklearn.linear_model import LogisticRegression\n\nlogr = LogisticRegression()\nlogr.fit(x_train,y_train)\n\ny_hat = logr.predict(x_test)","038eec61":"#Importing few metrics to check model performace\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import(accuracy_score, recall_score, precision_score, f1_score)\ncm = confusion_matrix(y_test,y_hat)","3882b1b8":"#Confusion matrix \nprint(cm)","4f9f3b82":"print(\"Accuracy Score: \",accuracy_score(y_test, y_hat))\nprint(\"Recall Score: \",recall_score(y_test, y_hat))\nprint(\"Precision Score: \",precision_score(y_test, y_hat))\nprint(\"F1 Score: \",f1_score(y_test, y_hat))","f7fbe38c":"from sklearn.metrics import roc_auc_score\nprint(roc_auc_score(y_test,y_hat))","b8bdd803":"from sklearn.metrics import roc_curve\nfpr, tpr, threshold = roc_curve(y_test,y_hat)\nplt.plot(fpr,tpr,'r-',label=\"Logistic Model\")\nplt.xlabel(\"False positive rate\")\nplt.ylabel(\"True positive rate\")\nplt.legend()\nplt.show()","1ca86e25":"from sklearn.tree import DecisionTreeClassifier\n\ndt = DecisionTreeClassifier()\ndt.fit(x_train,y_train)\ndt.score(x_test,y_test)","126722ff":"from sklearn.feature_selection import f_regression\nfrom sklearn.feature_selection import SelectKBest\nannova = SelectKBest(score_func=f_regression,k=10)\nannova.fit(x_train,y_train)\nx_train_annova = annova.transform(x_train)\nx_test_annova = annova.transform(x_test)\n\nfrom sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression()\nlr.fit(x_train_annova, y_train)\ny_hat_annova = lr.predict(x_test_annova)\nprint(\"Bias = \",lr.score(x_train_annova,y_train))\nprint(\"Variance = \",lr.score(x_test_annova,y_test))\n","f3613b1c":"cm = confusion_matrix(y_test,y_hat_annova)","96f7e946":"print(cm)","bc0d5db2":"Plotting ROC-AUC Curve","0dcb5618":"Our dataset has 4238 number of rows and 16 columns","720eb12f":"Step 2: Handling Outliers","6f88ab18":"Performing feature selection using ANNOVA Test","e086c0d9":"Checking the performance using Decision Tree Classifier","2888aac7":"Concatenating both categorical and numerical dataset","fa8ca669":"ROC-AUC score for Logistic regression is pretty low ","79e28331":"Handling the missing values by filling their respective mean \/ median \/ mode values.","873ea9de":"Column glucose has highly skewed data. As it has a higher correlation with diabetes, considering diabetes feature for model prediction and hence excluding glucose from dataset.","870ebbdc":"Performing scaling over the dataset using Min-Max Scaler","2a9c9d92":"Step 1: Handling missing values","5719d13b":"Column education, currentSmoker, cigsPerDay, BPMeds, totChol, BMI, heartRate, glucose has missing values which has to be handled. Below output shows how much of the individual columns has missing data","8e43de28":"Modelling and Feature Selection","dca68b90":"As all the column has positive skewness, with least correlation with the Target Variable\nNone of the columns have negative values, hence handling skewness for all the columns","db2411ac":"Performing Logistic Regression on the dataset","258c10a8":"All the missing values has been handled ","d60fae78":"Step 3: Handling Skewness","0f89761c":"Performing EDA"}}