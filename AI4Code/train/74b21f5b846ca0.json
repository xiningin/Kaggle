{"cell_type":{"8845a329":"code","7c9b3ff5":"code","08fc96ea":"code","7243e0ee":"code","201dcc0d":"code","0733a304":"code","feef7154":"code","1b2fab01":"code","b6b764e4":"code","2d295024":"code","27ae5234":"code","441bac68":"code","1544fb09":"code","74a1206c":"code","fff28133":"code","a324b818":"code","22f8448b":"code","09e3ff35":"code","91ac989d":"code","84f284db":"code","80462145":"code","38b32fd3":"code","0c4511b5":"code","92e9f7a9":"code","0fdd5616":"code","2e7682e9":"code","9b41ed3f":"code","1a01774a":"code","104a98ec":"code","fba65bc4":"code","33930653":"code","474c1144":"code","186e788b":"code","2b6cd9c4":"code","48d69d03":"code","77220c4f":"code","906d685c":"code","b3fb7a34":"code","5578d5e2":"code","1835fa7b":"code","e50d8f01":"code","310e6c10":"code","24f17cc8":"code","c9f192a1":"code","567c7c33":"code","e2658c00":"code","c335e113":"code","86d5e4c8":"code","c0e12174":"code","cc3159fa":"code","992dc209":"code","8c76eea2":"code","f7b0239c":"code","bafc7bc4":"code","67e55346":"code","bb52d95d":"code","f27e152a":"code","2eeef227":"code","48e6b819":"code","2d70fc82":"code","ca2c3b4d":"code","c2d27d32":"code","f0e1ec4d":"code","db2f2436":"markdown","5f678bce":"markdown","b3febac0":"markdown","ecea2b56":"markdown","aae4a19c":"markdown","b0973dc7":"markdown","f213970a":"markdown","78121374":"markdown","1cf49b43":"markdown","b47987cc":"markdown","85686f69":"markdown","0d0126be":"markdown","231153b4":"markdown","7e7d27e6":"markdown","c92752a7":"markdown","3c0569cf":"markdown","9dce2606":"markdown","f94212b4":"markdown","c49a3c8b":"markdown","af516697":"markdown","8279f2d1":"markdown","e4d84aeb":"markdown","645ed17e":"markdown","c25a065f":"markdown","fbc15f99":"markdown","19f2bd6c":"markdown","21e8989d":"markdown","2fe23b28":"markdown","8ad909c5":"markdown","d30babec":"markdown","d572a062":"markdown"},"source":{"8845a329":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7c9b3ff5":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n#style\nplt.style.use(\"fivethirtyeight\")\nsns.set_style(\"darkgrid\")\nimport warnings\nwarnings.filterwarnings(\"ignore\")","08fc96ea":"df = pd.read_csv(\"..\/input\/iris\/Iris.csv\")","7243e0ee":"display(df.head())\ndisplay(df.tail())","201dcc0d":"#Display number of rows randomly\ndf.sample(10)","0733a304":"df.shape","feef7154":"#check dataframe structure, like columns and its counts, datatypes and null values\ndisplay(df.info())","1b2fab01":"df.columns.tolist()","b6b764e4":"df.describe()","2d295024":"print('Iris-setosa')\nsetosa = df['Species'] == 'Iris-setosa'\nprint(df[setosa].describe())\n\nprint('\\nIris-versicolor')\nversicolor = df['Species'] == 'Iris-versicolor'\nprint(df[versicolor].describe())\n\nprint('\\nIris-virginica')\nvirginica = df['Species'] == 'Iris-virginica'\nprint(df[virginica].describe())","27ae5234":"df['SepalLengthCm'].nunique()","441bac68":"plt.figure(figsize = (25, 15))\nsns.countplot(df['SepalLengthCm'])\nplt.xlabel('SepalLengthCm', fontsize = 25, fontweight = 'bold')\nplt.ylabel('Count', fontsize = 25, fontweight = 'bold')\nplt.title('SepalLengthCm Vs Count', fontsize = 30, fontweight = 'bold')\nplt.xticks(fontsize = 20)\nplt.yticks(fontsize = 20)\nplt.show()\nprint(df['SepalLengthCm'].value_counts())","1544fb09":"df['SepalLengthCm'].nunique()","74a1206c":"plt.figure(figsize = (10, 8))\nprint(df['SepalWidthCm'].value_counts())\ndf['SepalWidthCm'].value_counts().plot.bar()\n#sns.countplot(df['SepalWidthCm'])","fff28133":"df['PetalLengthCm'].nunique()","a324b818":"plt.figure(figsize=(13,10))\nprint(df['PetalLengthCm'].value_counts())\ndf['PetalLengthCm'].value_counts().plot.bar()","22f8448b":"df['PetalWidthCm'].nunique()","09e3ff35":"plt.figure(figsize=(13,10))\nprint(df['PetalWidthCm'].value_counts())\ndf['PetalWidthCm'].value_counts().plot.bar()","91ac989d":"df['Species'].nunique()","84f284db":"plt.figure(figsize=(20, 6))\n\ncols = ['yellowgreen', 'lightcoral','gold']\nplt.subplot(1,2,1)\nsns.countplot('Species',data=df, palette='Set1')\nplt.title('Iris Species Count',fontweight=\"bold\", size=20)\nplt.xticks(fontweight=\"bold\")\n\nplt.subplot(1,2,2)\ndf['Species'].value_counts().plot.pie(explode=[0.05,0.05,0.1],autopct='%1.1f%%',shadow=True, colors=cols)\nplt.title('Iris Species Count',fontweight=\"bold\", size=20)\nplt.xticks(fontweight=\"bold\")\n\nplt.show()","80462145":"df.drop(\"Id\", axis=1, inplace=True)","38b32fd3":"df.isnull().sum()","0c4511b5":"df[df.duplicated()]","92e9f7a9":"df.duplicated().value_counts()","0fdd5616":"df.drop_duplicates(inplace=True)\ndf.shape","2e7682e9":"df.duplicated().any()","9b41ed3f":"df.corr()['SepalLengthCm']","1a01774a":"plt.figure(figsize = (10, 6))\nsns.heatmap(df.corr(), annot = True, linecolor = 'white', linewidths = 1, cmap = \"YlGnBu\")\nplt.show()","104a98ec":"sns.distplot(df.SepalWidthCm, color = 'red')\nplt.show()","fba65bc4":"plt.figure(figsize = (15,10))\nfeature = df.columns[0:4]\nfor i in enumerate(feature):\n    plt.subplot(2,2, i[0]+1)\n    sns.distplot(df[i[1]], color='crimson')","33930653":"plt.figure(figsize = (13, 9)) \ndf.boxplot()\nplt.show()","474c1144":"# Setting color palette\ncolors = ['#D32F2F','#1976D2','#689F38']\nsns.palplot(sns.color_palette(colors))","186e788b":"plt.figure(figsize=(12,10))\nsns.scatterplot(x=\"SepalLengthCm\", y=\"SepalWidthCm\", hue=\"Species\", data=df, palette=colors, marker=\"X\")\nplt.show()","2b6cd9c4":"plt.figure(figsize=(9,7))\nsns.boxplot(data=df, x='Species', y='SepalLengthCm')\nplt.show()","48d69d03":"plt.figure(figsize=(12,5))\nsns.barplot(x=df['Species'],y=df['SepalLengthCm'],data=df)\nplt.show()","77220c4f":"plt.figure(figsize=(12,5))\nsns.barplot(x=df['Species'],y=df['SepalWidthCm'],data=df)\nplt.show()","906d685c":"plt.figure(figsize=(12,5))\nsns.barplot(x=df['Species'],y=df['PetalLengthCm'],data=df)\nplt.show()","b3fb7a34":"plt.figure(figsize=(12,5))\nsns.barplot(x=df['Species'],y=df['PetalWidthCm'],data=df)\nplt.show()","5578d5e2":"# Boxplot    \nplt.figure(figsize=(15,10))    \nplt.subplot(2,2,1)    \nsns.boxplot(x='Species', y='SepalLengthCm', data=df)    \nplt.subplot(2,2,2)    \nsns.boxplot(x='Species', y='SepalWidthCm', data=df)    \nplt.subplot(2,2,3)    \nsns.boxplot(x='Species', y='PetalLengthCm', data=df)    \nplt.subplot(2,2,4)    \nsns.boxplot(x='Species', y='PetalWidthCm', data=df)\nplt.show()","1835fa7b":"# Pairplot\nsns.pairplot(df, hue='Species')\nplt.show()","e50d8f01":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndf['Species'] = le.fit_transform(df['Species'])","310e6c10":"# independent variable\nx=df.drop(['Species'],axis=1)\n\n# dependent variable\ny=df['Species']","24f17cc8":"# split the data into train and test data\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,random_state=0,test_size=0.2)","c9f192a1":"print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)","567c7c33":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nlist_1=[]\nfor i in range(1,21):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(x_train,y_train)\n    preds = knn.predict(x_test)\n    scores = accuracy_score(y_test,preds)\n    list_1.append(scores)","e2658c00":"# lets plot the decisoin boundary for the kneighbors classifier\n\nfrom mlxtend.plotting import plot_decision_regions\nfrom sklearn.decomposition import PCA\n\nknn = KNeighborsClassifier(n_neighbors=3)\npca = PCA(n_components = 2)\nX_train2 = pca.fit_transform(x_train)\n\nknn.fit(X_train2, y_train)\n\nplt.figure(figsize=(12,5))\nplot_decision_regions(X_train2, y_train.values, clf=knn, legend=2)\n\nplt.xlabel(df.columns[0], size=14)\nplt.ylabel(df.columns[1], size=14)\nplt.title('k neighbors decision boundary', size=16)\n\nplt.show()","c335e113":"# Creates a confusion matrix\ncm = confusion_matrix(y_test, preds)\n\ncm_df = pd.DataFrame(cm,\n                     index = ['setosa','versicolor','virginica'], \n                     columns = ['setosa','versicolor','virginica'])\n\nplt.figure(figsize=(8,6))\nsns.heatmap(cm_df, annot=True)\nplt.title('KNN \\nAccuracy:{0:.3f}'.format(accuracy_score(y_test, preds)))\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.show()","86d5e4c8":"print(accuracy_score(y_test, preds))\nprint(confusion_matrix(y_test, preds))\nprint(classification_report(y_test, preds))","c0e12174":"from sklearn import svm\nsvn = svm.SVC()    \nsvn.fit(x_train, y_train)    \npredictions = svn.predict(x_test)    \nprint(accuracy_score(y_test, predictions))    \nprint(confusion_matrix(y_test, predictions))    \nprint(classification_report(y_test, predictions)) ","cc3159fa":"# Creates a confusion matrix\ncm = confusion_matrix(y_test, predictions)\n\ncm_df = pd.DataFrame(cm,\n                     index = ['setosa','versicolor','virginica'], \n                     columns = ['setosa','versicolor','virginica'])\n\nplt.figure(figsize=(8,6))\nsns.heatmap(cm_df, annot=True)\nplt.title('SVM Linear Kernel \\nAccuracy:{0:.3f}'.format(accuracy_score(y_test, preds)))\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.show()","992dc209":"from sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression(solver = 'liblinear')\nlogreg.fit(x_train, y_train)\ny_pred = logreg.predict(x_test)\nprint('Test Accuracy for Scikit-Learn model:', accuracy_score(y_test, y_pred)* 100,'%')","8c76eea2":"print(accuracy_score(y_test, y_pred))    \nprint(confusion_matrix(y_test, y_pred))    \nprint(classification_report(y_test, y_pred))","f7b0239c":"# Creates a confusion matrix\ncm = confusion_matrix(y_test, y_pred)\n\ncm_df = pd.DataFrame(cm,\n                     index = ['setosa','versicolor','virginica'], \n                     columns = ['setosa','versicolor','virginica'])\n\nplt.figure(figsize=(8,6))\nsns.heatmap(cm_df, annot=True)\nplt.title('SVM Linear Kernel \\nAccuracy:{0:.3f}'.format(accuracy_score(y_test, y_pred)))\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.show()","bafc7bc4":"# import\nfrom sklearn.ensemble import RandomForestClassifier\n\n# initialize\nclf = RandomForestClassifier()\n\n# train the classifier using the training data\nclf.fit(x_train, y_train)","67e55346":"y_pred = clf.predict(x_test)","bb52d95d":"print(accuracy_score(y_test, y_pred))    \nprint(confusion_matrix(y_test, y_pred))    \nprint(classification_report(y_test, y_pred))","f27e152a":"# Creates a confusion matrix\ncm = confusion_matrix(y_test, y_pred)\n\ncm_df = pd.DataFrame(cm,\n                     index = ['setosa','versicolor','virginica'], \n                     columns = ['setosa','versicolor','virginica'])\n\nplt.figure(figsize=(8,6))\nsns.heatmap(cm_df, annot=True)\nplt.title('SVM Linear Kernel \\nAccuracy:{0:.3f}'.format(accuracy_score(y_test, y_pred)))\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.show()","2eeef227":"# Defining the decision tree algorithm\nfrom sklearn.tree import DecisionTreeClassifier\nDCT = DecisionTreeClassifier(criterion='gini', max_depth=3)\nDCT.fit(x_train, y_train)\n\ny_pred_DCT = DCT.predict(x_test)\n\nprint('Test Accuracy for DCT model:', accuracy_score(y_test, y_pred_DCT)* 100,'%')","48e6b819":"DCT.classes_","2d70fc82":"DCT.feature_importances_","ca2c3b4d":"plt.tight_layout()\nplt.title(\"Feature importances\")\nplt.barh(x.columns, DCT.feature_importances_, 1)","c2d27d32":"pip install pydotplus","f0e1ec4d":"# Import necessary libraries for graph viz\nfrom six import StringIO  \nfrom IPython.display import Image  \nfrom sklearn.tree import export_graphviz\nimport pydotplus\nimport graphviz\n\n# Visualize the graph\ndot_data = StringIO()\nexport_graphviz(DCT, out_file=dot_data, feature_names=x.columns,  \n                filled=True, rounded=True,\n                special_characters=True)\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \nImage(graph.create_png())","db2f2436":"### 1. KNN","5f678bce":"### c. Analysis of Relationship between variables","b3febac0":"### 5. Decision Tree Classifier","ecea2b56":"- setosa has the longer Sepalwidth and Versicolor has shorter Sepalwidth","aae4a19c":"#### 3. Identify Duplicate Values","b0973dc7":"### i) SepalLengthCm","f213970a":"### 2. SVM","78121374":"#### e. Multivariate Analysis","1cf49b43":"- In this case we are plotting the frequency of the three species in the Iris Dataset\n\n- We can see that there are 50 samples each of all the Iris Species in the data set.","b47987cc":"## 3. Modeling","85686f69":"- We can see that Sepal Length and Sepal Width columns are normally distributed. And Petal Length and Petal Width columns have skewness in the data.\n\n- We will use Petal_length and petal_width for cluster profiling.","0d0126be":"- setosa has the shorter Petalwidth and Virginica has longer Petalwidth","231153b4":"### iv) PetalWidthCm","7e7d27e6":"#### d. Bivariate Analysis","c92752a7":"#### 1. Drop unwanted features","3c0569cf":"### ii) SepalWidthCm","9dce2606":"## Loading Data","f94212b4":"#### c. Univariate Analysis","c49a3c8b":"- from above figure setosa has the shorter sepal lenght and virginica has longer","af516697":"### iii) PetalLengthCm","8279f2d1":"### 3. Logistic Regression","e4d84aeb":"#### a. Correlation with the variable of interest","645ed17e":"#### b. Heatmap","c25a065f":"### b. Clean the data","fbc15f99":"### 4. Random Forest Classifier","19f2bd6c":"- After graphing the features in a pair plot, it is clear that the relationship between pairs of features of a iris-setosa (in blue) is distinctly different from those of the other two species.\n\n- There is some overlap in the pairwise relationships of the other two species, iris-versicolor (brown) and iris-virginica (green).","21e8989d":"#### 2. Missing Values","2fe23b28":"- setosa has the shorter Petallength and Virginica has longer Petallength","8ad909c5":"### a.Understand the data","d30babec":"### v) Species","d572a062":"## EDA(Exploratory Data Analysis)"}}