{"cell_type":{"a25cc320":"code","3837db74":"code","9de195f7":"code","db28f2a2":"code","403e0ecd":"code","42fee61a":"code","1d2f5c37":"code","2b456cea":"code","c8232b53":"code","852028a1":"code","ef6662f9":"code","c96f4d7d":"code","6b3bf925":"code","9c40283e":"code","44795244":"code","28722e85":"code","f908bc76":"code","dd797f0b":"code","186eb38d":"code","12e7dd76":"code","6ca0c2a5":"code","9177b95d":"code","4a533d47":"code","a49cdb9c":"markdown","d75bfbaf":"markdown","f84de338":"markdown","f919899e":"markdown","db998346":"markdown","3ea59d90":"markdown","1a04cb46":"markdown","901f596c":"markdown","bd0b091b":"markdown","9c43f18f":"markdown","a32af761":"markdown","e55b0416":"markdown","a91fea38":"markdown","6090d123":"markdown","0a06bfdf":"markdown","8c73be98":"markdown","6e0e88d2":"markdown","0b2ce728":"markdown","2c83acde":"markdown","605fa3cf":"markdown","06fbcda0":"markdown","975bc36d":"markdown","c96df086":"markdown","0a672d9e":"markdown","336a8b71":"markdown"},"source":{"a25cc320":"from IPython.display import Image\nImage(\"..\/input\/cifar10\/Cifar10 1.png\")","3837db74":"Image(\"..\/input\/cifar10\/CiFAR10 Examples.png\")","9de195f7":"# importing tensorflow and keras\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.keras.utils import to_categorical, plot_model","db28f2a2":"# Printing version of the TensorFlow\n\nprint(tf.__version__)","403e0ecd":"# Loading the dataset\n\nCifar10=keras.datasets.cifar10 # Loading the dataset\n\n(xtrain,ytrain),(xtest,ytest)= Cifar10.load_data()\n\nprint(xtrain.shape)\nprint(ytrain.shape)\nprint(xtest.shape)\nprint(ytest.shape)\nprint(ytrain)\n\n# see the size of the dataset\n# print(\"Train Images Shape: %s \\nTrain Labels: %s \\nTest Images Shape: %s \\nTest Labels: %s\"  % (xtrain.shape, xtrain,xtest.shape,ytest))\n","42fee61a":"# Defining array. Each item of array represent integer value of labels. 10 clothing item for 10 integer label.\n\nclass_names =['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\nprint(class_names)","1d2f5c37":"# inspect the data in the array\n\nindex=0 # change this number \nplt.imshow(xtrain[index], cmap=plt.cm.binary) # printing 10th image. You may use cmap='gray'\nplt.colorbar() # shows the bar on the right side of the image\nplt.grid(True) # will shot the grid\nplt.show()\nprint(\"Class ID: %s and Class name: %s\" % (ytrain[index], class_names[ytrain[index][0]]))","2b456cea":"# display the first 25 images from traing set\n\nplt.figure(figsize=(10,10))\nfor i in range(25): # 25 images\n  plt.subplot(5,5,i+1) # matrix of 5 X 5 array\n  plt.xticks([])\n  plt.yticks([])\n  plt.grid(False)\n  plt.imshow(xtrain[i], cmap=plt.cm.binary) # printing binary\/black and white image\n    # The CIFAR labels happen to be arrays, \n    # which is why you need the extra index\n  plt.xlabel(\"%s %s\" % (ytrain[i], class_names[ytrain[i][0]])) # Assigning name to each image\nplt.show()","c8232b53":"# Pixel value of the image falls between 0 to 255.\n\nxtrain = xtrain\/255 # So, we are scale the value between 0 to 1 before by deviding each value by 255\nprint(xtrain.shape)\n\nxtest = xtest\/255 # So, we are scale the value between 0 to 1 before by deviding each value by 255\nprint(xtest.shape)","852028a1":"# One hot encoding of the labels.\n#(generally we do one hot encoding of the features in EDA but in this case we are doing it for labels)\n\n# Before one hot encoding\nprint(\"ytrain Shape: %s and value: %s\" % (ytrain.shape, ytrain))\nprint(\"ytest Shape: %s and value: %s\" % (ytest.shape, ytest))\n\nytrain=to_categorical(ytrain)\nytest=to_categorical(ytest)\n\n# After one hot encoding\nprint(\"ytrain Shape: %s and value: %s\" % (ytrain.shape, ytrain[0]))\nprint(\"ytest Shape: %s and value: %s\" % (ytest.shape, ytest[1]))","ef6662f9":"from IPython.display import Image\nImage(\"..\/input\/lecunimage\/Lecun.png\")","c96f4d7d":"# Modelling - Model on CNN\n\nfrom tensorflow.keras import models, layers\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten , Dense, Activation,Dropout\n\n# create a sequential model i.e. empty neural network which has no layers in it.\nmodel=models.Sequential()\n\n#==================== Feature Detection \/ extraction Block ====================#\n\n# Add first convolutional block - To deal with images we use Conv2D and for colour images and shape use Conv3D\n#model.add(layers.Conv2D(filters=6, kernal_size(3,3), input_shape=(32,32,1), activation='relu'))\n# in the first block we need to mention input_shape\nmodel.add(layers.Conv2D(64,(3,3),input_shape=(32,32,3),activation='relu'))\nmodel.add(layers.Conv2D(64,(3,3),input_shape=(32,32,3),activation='relu'))\n# Add the max pooling layer\nmodel.add(layers.MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n# Add Second convolutional block\n#model.add(layers.Conv2D(filters=6, kernal_size(3,3), activation='relu'))\nmodel.add(layers.Conv2D(128,(3,3),activation='relu'))\nmodel.add(layers.Conv2D(128,(3,3),activation='relu'))\n# Add the max pooling layer\nmodel.add(layers.MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n# Add Third convolutional block\n#model.add(layers.Conv2D(filters=6, kernal_size(3,3), activation='relu'))\nmodel.add(layers.Conv2D(256,(3,3),activation='relu'))\n# model.add(layers.Conv2D(256,(3,3),activation='relu'))\n# Add the max pooling layer\nmodel.add(layers.MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\n#==================== Transition Block (from feature detection to classification) ====================#\n\n# Add Flatten layer. Flatten simply converts matrics to array\nmodel.add(layers.Flatten(input_shape=(32,32))) # this will flatten the image and after this Classification happens\n\n#==================== Classification Block ====================#\n\n# Classification segment - fully connected network\n# The Dence layer does classification and is deep neural network. Dense layer always accept the array.\nmodel.add(layers.Dense(128, activation='relu')) # as C5 layer in above image. \nmodel.add(layers.Dense(100, activation='relu')) # as C5 layer in above image. \nmodel.add(layers.Dense(80, activation='relu')) # as C5 layer in above image. \n# model.add(layers.Dense(60, activation='relu')) # as C5 layer in above image\n# model.add(layers.Dense(40, activation='relu')) # as C5 layer in above image\n# this 120 is hyper parameter whcih is number of neuron \n#model.add(layers.Dense(84, activation='relu'))# as F6 layer in aboave image\n\n# Add the output layer\nmodel.add(layers.Dense(10, activation='softmax')) # as Output layer in above image. The output layer normally have softmax activation\n\n# Ploting the Model\nplot_model(model)","6b3bf925":"# Compile the model\n\n# if we use softmax activation in output layer then best fit optimizer is categorical_crossentropy\n# for sigmoid activation in output layer then loss will be binary_crossentropy\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) \n# if we do not go for One Hot Encoding then use loss='sparse_categorical_crossentropy'\n\nmodel.summary()","9c40283e":"# Train the model \n# Using GPU really speeds up this code\nxtrain2=xtrain.reshape(50000,32,32,3)\nxtest2=xtest.reshape(10000,32,32,3)\n\nprint(xtrain.shape)\nprint(xtest.shape)\nprint(ytrain.shape)\nprint(ytest.shape)\n\nmodel.fit(xtrain2,ytrain,epochs=40,batch_size=56,verbose=True,validation_data=(xtest2,ytest))","44795244":"# evaluate accuracy of the model\n\ntest_loss, test_acc = model.evaluate(xtest2, ytest)\nprint(\"accuracy:\", test_acc)","28722e85":"# predicting lable for test_images\n\npredictions=model.predict(xtest2)\n\n# Prediction of the 1st result. It will show the 10 predictions of labels for test image\nprint(\"1. Prediction array: %s\" % (predictions[0]))\n\n# we will verify that which result for label has highest confidence\nprint(\"2. Label number having highest confidence in prediction array: %s\" % (np.argmax(predictions[0])))\n\n# let us verify what is the label in test_labels.\nprint(\"3. Actual label in dataset: %s\" % (ytest[0]))","f908bc76":"# creating a funtion which will help to verify the prediction is true of not\n\ndef plot_image(i, predictions_array, true_label, img): # taking index and 3 arrays viz. prediction array, true label array and image array\n  \n  predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n  plt.grid(False)\n  plt.xticks([])\n  plt.yticks([])\n  \n  plt.imshow(img, cmap=plt.cm.binary) # showing b\/w image\n\n  predicted_label=np.argmax(predictions_array)\n  true_label=np.argmax(true_label)\n\n  # print(predicted_label)\n  # print(true_label)\n  \n  if predicted_label == true_label: #setting up label color\n    color='blue' # correct then blue colour\n    \n  else:\n    color='red' # wrong then red colour\n\n  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n                                       100*np.max(predictions_array),\n                                       class_names[true_label]),\n             color=color)\n  \n# function to display bar chart showing whether image prediction is how much correct  \ndef plot_value_array(i, predictions_array, true_label): # taking index along with predictions and true label array\n  predictions_array, true_label = predictions_array[i], true_label[i]\n  plt.grid(False)\n  plt.xticks([])\n  plt.yticks([])\n  thisplot=plt.bar(range(10), predictions_array, color='gray')\n  plt.ylim([0,1])\n  predicted_label=np.argmax(predictions_array)\n  true_label=np.argmax(true_label)\n\n  thisplot[predicted_label].set_color('red')\n  thisplot[true_label].set_color('green')","dd797f0b":"# call the function\n\n# defining parameters to pass to function\ni=12 # image number 56. You may change value of i for play around\nplt.figure(figsize=(6,3))\nplt.subplot(1,2,1)\n\nplot_image(i, predictions, ytest, xtest)\nplt.subplot(1,2,2)\nplot_value_array(i, predictions, ytest)\nplt.show()","186eb38d":"# call the function\n\n# defining parameters to pass to function\ni=7 # image number 5. You may change value of i for play around\nplt.figure(figsize=(6,3))\nplt.subplot(1,2,1)\nplot_image(i, predictions, ytest, xtest)\nplt.subplot(1,2,2)\nplot_value_array(i, predictions, ytest)\nplt.show()","12e7dd76":"# call the function\n\n# defining parameters to pass to function\ni=18 # image number 12. You may change value of i for play around\nplt.figure(figsize=(6,3))\nplt.subplot(1,2,1)\nplot_image(i, predictions, ytest, xtest)\nplt.subplot(1,2,2)\nplot_value_array(i, predictions, ytest)\nplt.show()","6ca0c2a5":"# verification our prediction on single image\n\ni=4 # image number 0. You may change value of i for play around\nimg = xtest2[i]\nprint(img.shape)\n\nimg=(np.expand_dims(img,0))\nprint(img.shape)\n\npredictions_single = model.predict(img)\nprint(predictions_single)\n\nplot_value_array(i, predictions,ytest)\n_ = plt.xticks(range(10), class_names,rotation=45)\n\nnp.argmax(predictions_single[0])","9177b95d":"# verification of several images\n\nnum_rows=6\nnum_cols=5\nnum_images=num_rows*num_cols\n\nplt.figure(figsize=(2*2*num_cols,2*num_rows))\nfor i in range(num_images):\n  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n  plot_image(i,predictions, ytest, xtest)\n  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n  plot_value_array(i, predictions, ytest)\nplt.show()","4a533d47":"print(\"Notebook completed!\")","a49cdb9c":"## One hot encoding of the labels\n- This is NOT required in two-class classification problem\n- This is REQUIRED in multi-class classification problem\n- This is 10 class classification problem so after one hot encoding it will generate 10 columns i.e. 10 output nurons for each label","d75bfbaf":"# Testing the model on data","f84de338":"## Evaluating model accuracy","f919899e":"Observations:\n* There are 60,000 images. We assigned 10,000 to test dataset\n* Images are black and white and is of 32 x 32 pixels\n* Train Images: Array of 60,000 images in 32 X 32 pixel\n* Train Labels: Integer array of 60,000 labels, value between 0 to 9\n* Test Images: Array of 10,000 images in 32 X 32 pixel\n* Test Labels: Integer array of 10,000 labels, value between 0 to 9\n* Each image mapped to a single label\n* Each integer value in label array represent clothing item","db998346":"# Evaluation of the data","3ea59d90":"## Train the model","1a04cb46":"## Scaling the image values","901f596c":"Reading the summary:\n- There are 5 computational layers i.e. all the layers where param value is non-zero that is why it is called LeNet-5.\n- Params are weights and bias\n- the value 60 = 6 filters X  kernal size 9 i.e.(3 X 3) = 54 + 6 bias (equal to number of filters) = 60\n- the value 550 = 10 filters X  kernal size 9 i.e.(3 X 3) = 90 X 6 filters of earliar layer = 540 + 10 bias (equal to number of filters) = 550\n- In case of Dense layer 30120 = 250 X 120 = 30,000 + 120 bias\n- In case of Dense layer 10164 = 120 X 84 = 10080 + 84 bias","bd0b091b":"## Creating a function to verify prediction is True or False","9c43f18f":"## Building model","a32af761":"## Compile the model","e55b0416":"# Computer Vision: Image Classification of CIFAR-10 dataset using TensorFlow\n\n**Domain:**Image Identification \/ Classification\n\n**About:**\nThe CIFAR-10 dataset (Canadian Institute For Advanced Research) is a collection of images that are commonly used to train machine learning and computer vision algorithms. It is one of the most widely used datasets for machine learning research.The CIFAR-10 dataset contains 60,000 32x32 color images in 10 different classes. The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. There are 6,000 images of each class.\n\nComputer algorithms for recognizing objects in photos often learn by example. CIFAR-10 is a set of images that can be used to teach a computer how to recognize objects. Since the images in CIFAR-10 are low-resolution (32x32), this dataset can allow researchers to quickly try different algorithms to see what works. Various kinds of convolutional neural networks tend to be the best at recognizing the images in CIFAR-10.\n\nCIFAR-10 is a labeled subset of the 80 million tiny images dataset. When the dataset was created, students were paid to label all of the images.\n\n[Information source: https:\/\/en.wikipedia.org\/wiki\/CIFAR-10]\n[Image Source: https:\/\/www.cs.toronto.edu\/~kriz\/cifar.html]\n\n**Problem Statement:** To predict correct label for each image given in test dataset.\n\n**We will use GPU for this notebook to speed up process.**\n","a91fea38":"## Predicting label","6090d123":"Observation:\n* This means model shows most confidence about 1st test_image is 'Ankle boot' ('T-shirt\/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'])\n* test_labels[0] also gives result as 9 (i.e. 'Ankle boot'). So, the prediction is correct. The data is one hot encoded so there is 1 at the last\n","0a06bfdf":"# Loading the Dataset","8c73be98":"## Test for single image","6e0e88d2":"# Data Preparation","0b2ce728":"# Evaluation of the model","2c83acde":"## Verifying several images","605fa3cf":"# Importing packages","06fbcda0":"Observation:\n* there is a very little gap between accracy of train and test model i.e. 0.9881 and 0.9826 that means model is almost perfect... very little overfitting.","975bc36d":"# Modelling - Model on CNN\n- There are 2 ways to program CNN with keras:\n  - Sequential approach: Here, we generally add layers in sequence.\n  - Modular approach: This is more important. This more dynamic, cusotmized, moulded and easy to explore. We generally use this.\n\nEffectiveness in both the approach will remain same.\n\nWe are creating this model based on lecun-99\nSource: http:\/\/yann.lecun.com\/exdb\/publis\/pdf\/lecun-99.pdf\n\n","c96df086":"## Test for single image","0a672d9e":"## Test for single image","336a8b71":"# Conclusions\n\n* With a complex sequential model with multiple convolution layers and 40 epochs for the training, we obtained an accuracy 0.85 for test prediction. \n* After investigating the validation accuracy and loss, we understood that the model is little overfitting.\n* Model may be retrained with Dropout layers to reduce overfitting.\n* Most of the images can be identified except in few cases for Deer and Automobile. Model is poor at identifying Deer."}}