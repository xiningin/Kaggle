{"cell_type":{"6599e0cb":"code","d7ce4da8":"code","90d72595":"code","e332f1e3":"code","11d86d95":"code","74c6a1f8":"code","ae952c92":"code","470447b0":"code","bff2fee8":"code","664bea78":"code","e94aaaa2":"code","449c36da":"code","e6e78c07":"code","9a40a42e":"code","f5b7a4c4":"code","fb2c3ef7":"code","6214983c":"code","c9065600":"code","affcc9bc":"code","8b2bc603":"code","8fc209a0":"code","60a2080a":"code","34aed8ee":"code","822dd5d9":"code","623ca552":"code","63739268":"code","7246e916":"code","b09150e0":"code","04afbd1f":"code","d56192d3":"code","ff42a830":"code","3a278f37":"code","a9c2eb9e":"code","259fa2e1":"markdown","b9c66dc9":"markdown","4c906e7d":"markdown","a5b7c1b8":"markdown","e3cd3cfc":"markdown","74728460":"markdown","a8f2d010":"markdown","84b48670":"markdown","e87e1738":"markdown","d4e6b389":"markdown","856871ac":"markdown"},"source":{"6599e0cb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d7ce4da8":"# Ignoring the warnings\nimport warnings\nwarnings.filterwarnings('ignore')","90d72595":"# Importing Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline","e332f1e3":"# Loading the Dataset\ndata = pd.read_csv(\"\/kaggle\/input\/pima-indians-diabetes-database\/diabetes.csv\")\ndata.head()  #display first 5 rows of dataset","11d86d95":"data.tail() #display last 5 rows of dataset","74c6a1f8":"# Column names and its datatypes\ndata.info(),\ndata.shape","ae952c92":"# Discription of Dataset\ndata.describe()","470447b0":"data.value_counts()","bff2fee8":"# Checking Missing Values\ndata.isna().sum()","664bea78":"# Check the columns that has '0' values in them\n\ncols = (data.columns == 0).sum()\nprint(cols)","e94aaaa2":"# See the distribution of the outcome variable\ndata.groupby('Outcome').size()","449c36da":"# Check Percentage of Healthy and Diabetic women\nimport matplotlib.style as style\n\nstyle.use('seaborn-pastel')\nlabels = [\"Healthy\", \"Diabetic\"]\ndata['Outcome'].value_counts().plot(kind='pie',labels=labels, subplots=True,autopct='%1.0f%%', figsize=(5,5));","e6e78c07":"## See the variables with respect to outcome variable\n\ndata.groupby('Outcome').hist(figsize=(20,5),layout=(2,8),histtype='barstacked')\nplt.show()","9a40a42e":"# Plotting Correlation Matrix using Heatmap\n\nplt.figure(figsize = (10,8))\nsns.heatmap(data.corr(), annot =True);","f5b7a4c4":"# Checkong Correlation between Outcome and Age\n\nsns.distplot(data.loc[data['Outcome']==0, 'Age'],label='Healthy')\nsns.distplot(data.loc[data['Outcome']==1, 'Age'], hist_kws=dict(alpha=0.4), label='Diabetic')\nplt.legend(prop={'size': 12})\nplt.title('Correlation between Outcome and Age')\nplt.xlabel('Age')\nplt.ylabel('Count')  \nsns.set(rc={'figure.figsize':(8,4)})","fb2c3ef7":"data.hist(figsize=(15,10))\nplt.show()","6214983c":"sns.distplot(data['Pregnancies'],bins=10);","c9065600":"sns.distplot(data['Age'],bins=10)","affcc9bc":"sns.distplot(data['DiabetesPedigreeFunction'],bins=10)","8b2bc603":"plt.figure(figsize=(14,10))\nsns.set_style(style='darkgrid')\nplt.subplot(2,3,1)\nsns.boxplot(data['Glucose'])\nplt.subplot(2,3,2)\nsns.boxplot(data['BloodPressure'])\nplt.subplot(2,3,3)\nsns.boxplot(data['Insulin'])\nplt.subplot(2,3,4)\nsns.boxplot(data['BMI'])\nplt.subplot(2,3,5)\nsns.boxplot(data['Age'])\nplt.subplot(2,3,6)\nsns.boxplot(data['SkinThickness'])","8fc209a0":"# Find the Glucose level in group of pregnant women who had diabetes.\nsns.boxplot(x=data['Pregnancies'],y=data['Glucose'],hue=data['Outcome'])","60a2080a":"# How many pregnant women had BP?\ndata.groupby(['Outcome','BloodPressure']).Pregnancies.count().hist()\nplt.show()","34aed8ee":"sns.pairplot(data,hue='Outcome',palette=\"husl\")","822dd5d9":"# Split the dataset\n\nx = data.drop(\"Outcome\", axis=1)\ny = data.Outcome","623ca552":"# Split the data into training and testing data\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=1)\n\nx_train.shape, x_test.shape, y_train.shape, y_test.shape","63739268":"# Import all 7 the models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import AdaBoostClassifier","7246e916":"# Put models in a dictionary\nmodels = {\"Logistic Regression\": LogisticRegression(solver='liblinear'),\n          \"Random Forest\": RandomForestClassifier(),\n          \"Decision Tree\": DecisionTreeClassifier(max_depth=6, random_state=123,criterion='entropy'),\n          \"KNN\": KNeighborsClassifier(n_neighbors=7),\n          \"SVC\": SVC(),\n          \"GaussianNB\" : GaussianNB(),\n          \"AdaBoost\" : AdaBoostClassifier(base_estimator = None)}","b09150e0":"# Create a function to fit and score models\ndef fit_and_score(models, x_train, x_test, y_train, y_test):\n    \"\"\"\n    Fits and evaluates given machine learning models.\n    models : a dict of different Scikit-Learn machine learning models\n    x_train : training data (no labels)\n    x_test : testing data (no labels)\n    y_train : training labels\n    y_test : test labels\n    \"\"\"\n    # Set random seed\n    np.random.seed(42)\n    # Make a dictionary to keep model scores\n    model_scores = {}\n    # Loop through models\n    for name, model in models.items():\n        # Fit the model to the data\n        model.fit(x_train, y_train)\n        # Evaluate the model and append its score to model_scores\n        model_scores[name] = model.score(x_test, y_test)\n    return model_scores","04afbd1f":"# Call the function\nmodel_scores = fit_and_score(models=models,\n                             x_train=x_train,\n                             x_test=x_test,\n                             y_train=y_train,\n                             y_test=y_test)\n\nmodel_scores","d56192d3":"# First import metrics\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import mean_squared_error\n","ff42a830":"for name, model in models.items():\n    # Fit the model to the data\n    model.fit(x_train, y_train)\n    y_preds = model.predict(x_test)\n    print(f\"Classification Report of {name} is:\\n {classification_report(y_test,y_preds)}\")\n\n    print(f\"Confusion Matrix of {name} is:\\n {confusion_matrix(y_test,y_preds)}\\n\")\n\n    print(f\"Mean Squared Error of {name} is: {mean_squared_error(y_test,y_preds)}\\n\")\n\n    print(f\"R2 score is of {name} is: {r2_score(y_test,y_preds)}\\n\")\n\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_preds)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    print(f\"ROC_AUC Curve for {name} is:\\n {roc_auc}\")\n    print(\"==================================================================================================\\n\\n\")","3a278f37":"model_scores","a9c2eb9e":"model_compare = pd.DataFrame(model_scores, index=[\"accuracy\"])\nmodel_compare.T.plot.bar();","259fa2e1":"# Exploratory Data Analysis","b9c66dc9":"**Now we've got our data split into training and test sets, it's time to build a machine learning model.**","4c906e7d":"#### Lets print Metrics","a5b7c1b8":"There are 9 columns and 768 rows in dataset","e3cd3cfc":"### Model Comparison","74728460":"# Pima Indians Diabetes Database\nPredict the onset of diabetes based on diagnostic measures\n\n**Problem Definition**\n\n\n```\nPredict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset.\n```\n**Features**\n* Pregnancies: Number of times pregnant.\n\n* Glucose: Plasma glucose concentration over 2 hours in an oral glucose tolerance test.\n\n* BloodPressure: Diastolic blood pressure (mm Hg).\n\n* SkinThickness: Triceps skin fold thickness (mm).\n\n* Insulin: 2-Hour serum insulin (mu U\/ml).\n\n* BMI: Body mass index (weight in kg\/(height in m)2).\n\n* DiabetesPedigreeFunction: iabetes pedigree function (a function which scores likelihood of diabetes based on family history).\n\n* Age: No explanation needed.\n\n","a8f2d010":"There are 500 non diabetics and 268 diabetics pregnant women. There is imbalance in the data.","84b48670":"There is no missing values","e87e1738":"# Models:\nWe're going to try 7 different machine learning models:\n```\n1. Logistic Regression\n2. RandomForestClassifier\n3. DECISION TREE CLASSIFIER\n4. KNeighborsClassifier\n5. Support Vector Classification (SVC)\n6. Naive Bayes (GaussianNB)\n7. AdaBoostClassifier\n```\n\n\n\n\n\n","d4e6b389":"# Training and Testing Data","856871ac":"**The distribution of data shows us that the data is mostly right skewed.**"}}