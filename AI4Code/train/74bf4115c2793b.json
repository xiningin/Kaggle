{"cell_type":{"921f2b29":"code","6ba1595e":"code","4735b605":"code","98e289f5":"code","b520ca5c":"code","5c40f427":"code","11f092ab":"code","618e7f74":"code","70400924":"code","784abf31":"code","56911d3c":"code","df73c1f5":"code","748f3733":"code","9f54e13a":"code","ae154a48":"code","528e7018":"code","68496ac6":"code","b509ee47":"code","115f0dde":"code","349d2d5d":"code","557c3eac":"code","e6d97386":"code","108eda4e":"code","56ffec4f":"code","6add1922":"code","ed4f6cfd":"code","e4b67070":"code","f235d51b":"code","ce0ca17c":"code","631c79ae":"code","a72bb787":"code","23feae8c":"code","e1c37e2d":"code","ee130ace":"markdown","bb501ac3":"markdown","590a414e":"markdown","8e26df1f":"markdown","cf4e4941":"markdown","24f8f25d":"markdown","8d0a2a0b":"markdown","b7c2e3f1":"markdown","9017d926":"markdown","d4e75b5a":"markdown","9bb75f6b":"markdown","4d288495":"markdown"},"source":{"921f2b29":"import os\nimport random\nimport numpy as np\nimport shutil\n\nimport torch.nn as nn\nimport torchvision\nfrom torchvision import transforms\nfrom torchvision.transforms import ToTensor\n\nfrom kaggle_secrets import UserSecretsClient\n\nfrom PIL import Image\nimport torchvision.transforms.functional as TF\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\n\nmpl.rcParams['figure.dpi']= 100\nmpl.rcParams[\"savefig.dpi\"] = 300","6ba1595e":"%%capture\n!pip install pynvml\nimport pynvml\nfrom pynvml.smi import nvidia_smi\npynvml.nvmlInit()","4735b605":"deviceCount = pynvml.nvmlDeviceGetCount()\nfor i in range(deviceCount):\n    handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n    print(f\"Device {i} {pynvml.nvmlDeviceGetName(handle).decode()}\")\nprint(f\"Free GPU memory - {nvidia_smi.getInstance().DeviceQuery('memory.total')}\")","98e289f5":"random.seed(42)\nage_limits = [10,20,30,40,50,60,70,80,100,120]\ntest_split = 0.1\nvalid_split = 0.1\n\nEPOCHS = 40\nBATCH_SIZE = 20\nLEARNING_RATE = 2e-5\n\nfreezed = True","b520ca5c":"os.mkdir(\"\/kaggle\/utkface\/\")\nos.mkdir(\"\/kaggle\/utkface\/train\/\")\nos.mkdir(\"\/kaggle\/utkface\/test\/\")\nos.mkdir(\"\/kaggle\/utkface\/valid\/\")\nos.mkdir(\"\/kaggle\/workdir\/\")","5c40f427":"all_classes = []\nl = 0\nfor x in range(len(age_limits)):\n    class_name = str(l)+\"-\"+str(age_limits[x]-1)\n    l=str(age_limits[x])\n    all_classes.append(class_name)\n    os.mkdir(\"\/kaggle\/utkface\/train\/\"+class_name+\"\/\")\n    os.mkdir(\"\/kaggle\/utkface\/test\/\"+class_name+\"\/\")\n    os.mkdir(\"\/kaggle\/utkface\/valid\/\"+class_name+\"\/\")","11f092ab":"path = \"..\/input\/utkface-new\/UTKFace\/\"\n\nfor filename in os.listdir(path):\n    age = int(filename.split(\"_\")[0])\n    bin_index = np.digitize(age, bins=age_limits)\n\n\n    class_name = all_classes[bin_index]\n\n    #copy files in correct folder\n    shutil.copy2(path+filename, \"\/kaggle\/utkface\/train\/\"+class_name+\"\/\"+filename)","618e7f74":"for class_filename in os.listdir(\"\/kaggle\/utkface\/train\"):\n    number_images = len(next(os.walk(\"\/kaggle\/utkface\/train\/\"+class_filename))[2])\n\n  \n    number_test_images = int(test_split * number_images)\n    number_valid_images = int(valid_split * number_images)\n\n    all_images_filenames = next(os.walk(\"\/kaggle\/utkface\/train\/\"+class_filename))[2]\n\n    #select random test images from all images\n    test_images_filenames = random.sample(all_images_filenames, number_test_images)\n    #remove test images from all images\n\n    all_images_filenames = [ img for img in all_images_filenames if img not in test_images_filenames]\n    #select random valid images from all images\n    valid_images_filenames = random.sample(all_images_filenames, number_valid_images)\n\n\n    for x in test_images_filenames:\n        shutil.move(\"\/kaggle\/utkface\/train\/\"+class_filename+\"\/\"+x, \"\/kaggle\/utkface\/test\/\"+class_filename+\"\/\"+x)\n\n    for x in valid_images_filenames:\n        shutil.move(\"\/kaggle\/utkface\/train\/\"+class_filename+\"\/\"+x, \"\/kaggle\/utkface\/valid\/\"+class_filename+\"\/\"+x)\n","70400924":"augmention_transforms = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(degrees=(-30, 30)),\n    transforms.RandomGrayscale(),\n    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n    transforms.ToTensor()\n])","784abf31":"train_ds = torchvision.datasets.ImageFolder('\/kaggle\/utkface\/train\/', transform=ToTensor())\nvalid_ds = torchvision.datasets.ImageFolder('\/kaggle\/utkface\/valid\/', transform=ToTensor())\ntest_ds = torchvision.datasets.ImageFolder('\/kaggle\/utkface\/test\/', transform=ToTensor())","56911d3c":"%%capture\n!pip install transformers","df73c1f5":"from transformers import ViTForImageClassification","748f3733":"model = ViTForImageClassification.from_pretrained('google\/vit-base-patch16-224')\nclasses = len(train_ds.classes)\nmodel.classifier = nn.Linear(768, classes)","9f54e13a":"pytorch_total_params = sum(p.numel() for p in model.parameters())\nprint(\"Model: {} Parameter\".format(pytorch_total_params))","ae154a48":"if freezed:\n    for param in model.parameters():\n        param.requires_grad = False\n\n    for param in model.classifier.parameters():\n        param.requires_grad = True","528e7018":"%%capture\n!pip install transformers datasets","68496ac6":"import torch.utils.data as data\nfrom transformers import ViTFeatureExtractor\nfrom transformers import AdamW\nfrom transformers import get_scheduler\nfrom datasets import load_metric\nimport torch\nfrom tqdm.auto import tqdm\nfrom torch.autograd import Variable","b509ee47":"feature_extractor = ViTFeatureExtractor.from_pretrained('google\/vit-base-patch16-224-in21k')","115f0dde":"train_dataloader = data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2)\ntest_dataloader  = data.DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\nvalid_dataloader = data.DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2)","349d2d5d":"optimizer = AdamW(model.parameters(), lr=5e-5)\nloss_func = nn.CrossEntropyLoss()\nmetric = load_metric(\"accuracy\")\ntrain_metric = load_metric(\"accuracy\")\n\nnum_training_steps = EPOCHS * len(train_dataloader)\nlr_scheduler = get_scheduler(\n    \"linear\",\n    optimizer=optimizer,\n    num_warmup_steps=3,\n    num_training_steps=num_training_steps\n)","557c3eac":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \nif torch.cuda.is_available():\n    model.cuda() ","e6d97386":"val_acc, train_acc, train_loss = [], [], []","108eda4e":"model.train()\nfor epoch in range(EPOCHS):\n    for (x, y) in train_dataloader:\n        x = np.split(np.squeeze(np.array(x)), np.array(x).shape[0])\n        for index, array in enumerate(x):\n            x[index] = np.squeeze(array)\n        x = torch.tensor(np.stack(feature_extractor(x, image_mean=[0.5964, 0.4567, 0.3910], image_std=[0.1257, 0.1144, 0.1206])['pixel_values'], axis=0))\n        x, y  = x.to(device), y.to(device)\n        b_x = Variable(x)\n        b_y = Variable(y)\n\n        optimizer.zero_grad()\n        #genereate predicitons\n        output = model(b_x, None)\n        train_metric.add_batch(predictions=torch.argmax(output.logits, dim=-1), references=b_y)\n        #compute loss\n        loss = loss_func(output.logits, b_y)  \n        \n        #back propagate and optimize\n        loss.backward()\n        optimizer.step()\n        lr_scheduler.step()\n        \n    #testing accuracy\n    for (x, y) in test_dataloader:\n        #prepare data\n        x = np.split(np.squeeze(np.array(x)), np.array(x).shape[0])\n        for index, array in enumerate(x):\n            x[index] = np.squeeze(array)\n        x = torch.tensor(np.stack(feature_extractor(x, image_mean=[0.5964, 0.4567, 0.3910], image_std=[0.1257, 0.1144, 0.1206])['pixel_values'], axis=0))\n        x, y  = x.to(device), y.to(device)\n\n        #get output without gradients\n        with torch.no_grad():\n            outputs = model(x, None)\n\n        #compare results\n        logits = outputs.logits\n        predictions = torch.argmax(logits, dim=-1)\n        metric.add_batch(predictions=predictions, references=y)\n    \n    history = metric.compute()\n    train_history = train_metric.compute()\n    print(\"epoch:\", epoch)\n    print(\"accuracy: {:6.4f}\".format(history[\"accuracy\"]))\n    print(\"loss: {:6.4f}\".format(loss.data))\n    \n    val_acc.append(history[\"accuracy\"])\n    train_acc.append(train_history[\"accuracy\"])\n    train_loss.append(loss.data)","56ffec4f":"torch.save(model.state_dict(), \"\/kaggle\/working\/model.pth\")","6add1922":"eps = range(0, EPOCHS)\n\nplt.plot(eps, val_acc, 'g', label='Validation Accuracy')\nplt.plot(eps, train_acc, 'b', label='Training Accuracy')\nplt.title('Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","ed4f6cfd":"plt.plot(eps, train_loss, 'b', label='Loss')\nplt.title('Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","e4b67070":"from sklearn.metrics import confusion_matrix\nimport seaborn as sn\nimport pandas as pd\nimport matplotlib.pyplot as plt ","f235d51b":"y_true = []\ny_pred = []\nmodel.eval()\nfor (x, y) in valid_dataloader:\n    x = np.split(np.squeeze(np.array(x)), np.array(x).shape[0])\n    for index, array in enumerate(x):\n        x[index] = np.squeeze(array)\n    x = torch.tensor(np.stack(feature_extractor(x, image_mean=[0.5964, 0.4567, 0.3910], image_std=[0.1257, 0.1144, 0.1206])['pixel_values'], axis=0))\n    x, y  = x.to(device), y.to(device)\n\n    #get output without gradients\n    with torch.no_grad():\n        outputs = model(x, None)\n\n    #compare results\n    logits = outputs.logits\n    predictions = torch.argmax(logits, dim=-1)\n    metric.add_batch(predictions=predictions, references=y)\n    \n    y_true.append(y)\n    y_pred.append(predictions)\n    \nhistory = metric.compute()\nout = \"accuracy: {:6.2f}\".format(history[\"accuracy\"])\nprint(out)","ce0ca17c":"# send to cpu if needed and construct one tensor out of list of tensors\ny_pred = torch.cat(y_pred).cpu()\ny_true = torch.cat(y_true).cpu()","631c79ae":"# Build confusion matrix\ncf_matrix = confusion_matrix(y_true, y_pred)\ndf_cm = pd.DataFrame(cf_matrix, index = [i for i in all_classes],columns = [i for i in all_classes])\nplt.figure(figsize = (12,7))\nsn.heatmap(df_cm, annot=True, fmt='g')\nplt.title(\"Confusion Matrix\")\nplt.savefig('\/kaggle\/working\/confusionMatrix.png')","a72bb787":"def test_image(paths, number_columns=5):\n    \n    number_images = len(paths)    \n    a = int(np.ceil(number_images \/ number_columns))\n    \n    fig = plt.figure(figsize=(3*number_columns,a*3))\n\n    for i in range(number_images):\n        plt.subplot(a, number_columns, i+1)\n        plt.xlabel(i)\n        \n        \n        #prediciton\n        image = Image.open(paths[i])\n        x = TF.to_tensor(image)\n        x = torch.tensor(np.stack(feature_extractor(x, image_mean=[0.5964, 0.4567, 0.3910], image_std=[0.1257, 0.1144, 0.1206])['pixel_values'], axis=0))\n        x = x.to(device)\n        with torch.no_grad():\n            outputs = model(x, None)\n        logits = outputs.logits\n        predictions = torch.argmax(logits, dim=-1)\n        #send to cpu\n        predictions = predictions.cpu()\n        predicted_class = all_classes[predictions]\n        \n        #get real label\n        label = paths[i].split(\"\/\")[-1].split(\"_\")[0]\n        #set title\n        title = f\"predicted: {predicted_class}  real age:{label}\"\n        plt.title(title, fontsize= 8)\n        imgplot = plt.imshow(image)        \n        plt.axis('off')\n        \n    plt.show()","23feae8c":"#count is number of images per class\ndef get_random_images(count=2):\n    paths = []\n    for folder in os.listdir(\"\/kaggle\/utkface\/valid\/\"):\n        filenames = os.listdir(f\"\/kaggle\/utkface\/valid\/{folder}\/\")\n        filenames = [f\"\/kaggle\/utkface\/valid\/{folder}\/\"+x for x in filenames]\n        paths.extend(random.sample(filenames, count))\n    return paths","e1c37e2d":"images = get_random_images(3)\ntest_image(images,6)","ee130ace":"# training","bb501ac3":"use GPU if possible","590a414e":"freeze params","8e26df1f":"# Initialise Parameters","cf4e4941":"training loop","24f8f25d":"# ViT installation","8d0a2a0b":"get some informations about the GPU","b7c2e3f1":"# Validation","9017d926":"# show some test results","d4e75b5a":"# folders","9bb75f6b":"# imports","4d288495":"test random images from valid folder"}}