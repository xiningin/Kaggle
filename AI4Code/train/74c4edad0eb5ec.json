{"cell_type":{"f7052bb3":"code","cd1eaf07":"code","76f6f0ae":"code","a7d79263":"code","aebe2b3d":"code","3d6eb171":"code","64e23d0a":"code","ed2733e0":"code","17ede41f":"markdown","f2ff7ee0":"markdown","a312de66":"markdown","a6223e5e":"markdown","5e7da2c3":"markdown","05e9ca90":"markdown","8233ec09":"markdown"},"source":{"f7052bb3":"#Code help taken from: https:\/\/www.back-prop.com\/deep_learning\/knn\/mnist\/2019\/05\/16\/knn_classifier\/\nimport mnist #Dataset\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt #Graph\nfrom keras.utils import to_categorical\n\nfrom sklearn.metrics import confusion_matrix \nfrom sklearn.metrics import accuracy_score \nfrom sklearn.metrics import classification_report \nfrom sklearn.datasets import load_digits\nfrom IPython.display import display, HTML\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split","cd1eaf07":"train_images = mnist.train_images() #training data images\ntrain_labels = mnist.train_labels() #training data labels\ntest_images = mnist.test_images() #testing data images\ntest_labels = mnist.test_labels() #testing data labels\n\n#validation dataset\ntrain_images,val_images,train_labels,val_labels = train_test_split(train_images,\n                                                                   train_labels,\n                                                                   test_size=0.1,#10% validation data\n                                                                   random_state=84)\nprint(\"training data points: {}\".format(len(train_labels)))\nprint(\"validation data points: {}\".format(len(val_labels)))\nprint(\"testing data points: {}\".format(len(test_labels)))","76f6f0ae":"\ntrain_images = train_images \/ 255\ntest_images = test_images \/ 255\nval_images = val_images \/ 255\n\n\ntrain_images = train_images.reshape((-1, 784))\ntest_images = test_images.reshape((-1, 784))\nval_images = val_images.reshape((-1, 784))\n\n\nprint(test_images.shape) \nprint(train_images.shape)\nprint(val_images.shape) ","a7d79263":"kVals = np.arange(1,30,2)\n\nfor k in kVals:\n    \n    model = KNeighborsClassifier(n_neighbors=k)\n    model.fit(train_images,train_labels)\n    \n    # evaluate the model and update the accuracies list\n    score = model.score(val_images, val_labels)\n    print(\"k=%d, accuracy=%.2f%%\" % (k, score * 100))","aebe2b3d":"#For best value of accuracy, k turned out to be 3\nmodel = KNeighborsClassifier(n_neighbors = 3)\nmodel.fit(train_images, train_labels)\npredictions = model.predict(test_images)\n\nprint(classification_report(test_labels, predictions))\n","3d6eb171":"#predict on the first five test images\npredictions = model.predict(test_images[:6])\nprint('labels: ' , test_labels[:6])\nprint('predictions by our model: ' , predictions)","64e23d0a":"#ref https:\/\/www.kaggle.com\/grfiv4\/plot-a-confusion-matrix\ndef plot_confusion_matrix(cm,\n                          target_names,\n                          title='Confusion matrix',\n                          cmap=None,\n                          normalize=True):\n    \"\"\"\n    given a sklearn confusion matrix (cm), make a nice plot\n\n    Arguments\n    ---------\n    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n\n    target_names: given classification classes such as [0, 1, 2]\n                  the class names, for example: ['high', 'medium', 'low']\n\n    title:        the text to display at the top of the matrix\n\n    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n                  see http:\/\/matplotlib.org\/examples\/color\/colormaps_reference.html\n                  plt.get_cmap('jet') or plt.cm.Blues\n\n    normalize:    If False, plot the raw numbers\n                  If True, plot the proportions\n\n    Usage\n    -----\n    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n                                                              # sklearn.metrics.confusion_matrix\n                          normalize    = True,                # show proportions\n                          target_names = y_labels_vals,       # list of names of the classes\n                          title        = best_estimator_name) # title of graph\n\n    Citiation\n    ---------\n    http:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_confusion_matrix.html\n\n    \"\"\"\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import itertools\n\n    accuracy = np.trace(cm) \/ float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(10, 10))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n\n    thresh = cm.max() \/ 1.5 if normalize else cm.max() \/ 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n    plt.show()\n\npredictions = model.predict(test_images)\nplot_confusion_matrix(confusion_matrix(test_labels, predictions), \n                      normalize    = True,\n                      target_names = ['0', '1', '2',  '3',  '4', '5',  '6', '7',  '8', '9'],\n                      title        = \"Confusion Matrix, Normalized\")\n\n","ed2733e0":"sub = pd.DataFrame(predictions)\nsub.index.name = 'ImageId'\nsub.index += 1\nsub.columns = ['Label']\nsub.to_csv('submission_kNN.csv', header = True)","17ede41f":"# Training and testing\nkNN classifier is trained on value of k = 3 which came out to be best value due to its accuracy on validation data. ","f2ff7ee0":"# Seperating training, testing and validation data\n* training data is used to train model.\n* testing data is used for testing model function,\n* Validation data is used to tune up hyperparameters.","a312de66":"# Confusion matrix\nConfusion matrix shows relationship between actual labels and labels predicted by the model.","a6223e5e":"# Normalization of data\nNormalizing pixels from the range (0, 255) to (0, 1) to train our network easily.\n# Flattening of images\nFlatten the image from 28 x 28 to 1-d array of size 784 to pass it to the neural network.","5e7da2c3":"# Importing libraries \n\nfor dataset, image processing, scikit machine learning libraries","05e9ca90":"# Predict labels of sample test images","8233ec09":"# Tuning of hyperparameter\nkNN is an unsupervised machine learning algorithm. It has a hyperparameter k, which specifies the number of nearest neighbours in classification. Here, k hyperparameter is tuned by training model on training data and checking accuracies on validation dataset."}}