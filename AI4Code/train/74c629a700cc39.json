{"cell_type":{"131dc009":"code","6aa37610":"code","9ed7e8d8":"code","effb159d":"code","2c28f51e":"code","79c8ac27":"code","0bd0ad2b":"code","a0d189ba":"code","bab67eab":"code","64389915":"code","588fc60b":"code","d8f8099d":"code","5438e453":"code","b2d336f6":"code","33dc4ebf":"code","f9a9baf7":"code","8cb309d6":"code","fb5241ae":"code","6af45892":"code","6b45970b":"code","de0be1b3":"code","135ef74a":"code","dbe9bc06":"code","b56dc17b":"code","bb87001d":"code","5ca7cb4a":"code","6da97e0f":"code","b4c626f1":"code","f16e6755":"code","33111e72":"code","3a784d56":"code","89cc1570":"code","048d1379":"code","0991aeef":"code","449323cf":"code","8d72bc14":"code","def5d253":"code","21239bf7":"code","bb9c1c58":"code","7625a56c":"code","a5eb9c74":"code","f241152c":"code","ed1650bf":"code","ed318e4b":"code","6a05a963":"code","34be0b8b":"code","ff5b2e6e":"code","0945cb49":"code","1e995847":"code","fa26737b":"markdown","8fa34e20":"markdown","252b9e29":"markdown","3dca47d2":"markdown","2ec417f1":"markdown","96a7d636":"markdown","36e79702":"markdown","dbfc59af":"markdown","f92d8f95":"markdown","0021fcef":"markdown","0b1a1c1e":"markdown"},"source":{"131dc009":"#http:\/\/www.nltk.org\/book\/\n#Import nltk packages\nimport nltk\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.tokenize import PunktSentenceTokenizer\nimport matplotlib.pyplot as plt","6aa37610":"#Define the text string\ndata = \"All work and no play makes jack dull boy. This video is about NLTK programming.\"\ndata","9ed7e8d8":"#Convert the given text into sentences\nsentences = sent_tokenize(data)\nprint(sentences)","effb159d":"#Convert the given text into words\nwords = word_tokenize(data)\nprint(words)","2c28f51e":"stopWords = set(stopwords.words('english'))\nstopWords","79c8ac27":"wordsFiltered = []\nfor w in words:\n    if w not in stopWords:\n        wordsFiltered.append(w)\n\nprint(\"\\nExtracted words ==>\",words)\nprint(\"\\nWords after removing the stop words ==>\",wordsFiltered)\n#print(\"\\nList of stop words ==>\",stopWords)","0bd0ad2b":"ps = PorterStemmer()\nsentence = \"gaming, the gamers play games\"\nwords = word_tokenize(sentence)\nfor word in words:\n    print(word + \":\" + ps.stem(word))","a0d189ba":"text = 'She sells, sea shells on the sea shore'\nsentences = nltk.sent_tokenize(text)\nfor sent in sentences:\n    print(nltk.pos_tag(nltk.word_tokenize(sent)))","bab67eab":"#Import books from nltk corpora\nfrom nltk.book import *","64389915":"#Display the tile of 1st book (Moby Dick by Herman Melville 1851)\ntext1","588fc60b":"#Display the tile of 2nd book (#Display the tile of 2nd book)\ntext2","d8f8099d":"#Searching text\ntext1.concordance(\"monstrous\")","5438e453":"#What other words appear in a similar range of contexts\ntext1.similar(\"monstrous\")","b2d336f6":"#What other words appear in a similar range of contexts\ntext2.similar(\"monstrous\")","33dc4ebf":"#Plot the word location of the given words in the book\ntext4.dispersion_plot([\"citizens\", \"democracy\", \"freedom\", \"duties\", \"America\"])","f9a9baf7":"#Find the count of words in the 3rd book (The Book of Genesis)\nlen(text3)","8cb309d6":"#Find the unique words in the given book (The Book of Genesis)\nuniq_words = list(set(text3))\ntype(uniq_words)\nsorted(uniq_words[:10])","fb5241ae":"#Count the number of unique words in the given book\nlen(set(text3))","6af45892":"#Find the Lexical Richness of the given book\nlen(set(text3)) \/ len(text3)","6b45970b":"#Find frequency distribution of the words in book1\nfdist1 = FreqDist(text1) \nprint(fdist1)","de0be1b3":"#Find most common used words along with its word count\nfdist1.most_common(10)","135ef74a":"#Find count of word whale\nfdist1['whale']","dbe9bc06":"#Plot frequency distribution of most common used words\nfdist1.plot(20)\nfdist1.plot(20, cumulative=True)","b56dc17b":"fdist1.plot(20, cumulative=True)","bb87001d":"#The Brown Corpus was the first million-word electronic corpus of English, created in 1961 at Brown University. \nfrom nltk.corpus import brown\nbrown.categories()","5ca7cb4a":"#Find words in the category \"news\" in Brown Corpus\nbrown.sents(categories='news')","6da97e0f":"#Find words in the category \"news\" in Brown Corpus\nbrown.words(categories='news')","b4c626f1":"from nltk.corpus import brown\nnews_text = brown.words(categories='news')\nfdist = nltk.FreqDist(w.lower() for w in news_text)\nfdist","f16e6755":"#The Brown Corpus is a convenient resource for studying systematic differences between genres, a kind of linguistic inquiry known as stylistics. \n#Let's compare genres in their usage of modal verbs. The first step is to produce the counts for a particular genre.\nmodals = ['can', 'could', 'may', 'might', 'must', 'will']\nfor m in modals:\n    print(m + ':', fdist[m], end=' ')","33111e72":"#Inaugural Address Corpus\n#the corpus is actually a collection of 55 texts, one for each presidential address. An interesting property of this collection is its time dimension:\nfrom nltk.corpus import inaugural\ninaugural.fileids()[50:]","3a784d56":"[fileid[:4] for fileid in inaugural.fileids()][:5]","89cc1570":"#Let's look at how the words America and citizen are used over time. \nplt.figure(figsize=(20,10)) \ncfd = nltk.ConditionalFreqDist((target, fileid[:4])\n                               for fileid in inaugural.fileids()\n                               for w in inaugural.words(fileid)\n                               for target in ['america', 'citizen']\n                               if w.lower().startswith(target))\ncfd.plot()","048d1379":"#Corpora in Other Languages (hindi)\nnltk.corpus.indian.words('hindi.pos')","0991aeef":"#Gender Prediction using Naive Bayes Classifer\nimport nltk.classify.util\nfrom nltk.classify import NaiveBayesClassifier\nfrom nltk.corpus import names\n\ndef gender_features(word): \n    return {'last_letter': word[-1]} \n \n# Load data and training \nnames = ([(name, 'male') for name in names.words('male.txt')] + \n  [(name, 'female') for name in names.words('female.txt')])\n \nfeaturesets = [(gender_features(n), g) for (n,g) in names] \ntrain_set = featuresets\nclassifier = nltk.NaiveBayesClassifier.train(train_set) \n \n# Predict\nprint(classifier.classify(gender_features('Jonas')))","449323cf":"from nltk.corpus import wordnet as wn","8d72bc14":"#Synsets = Synonym sets.  Find all the synonmyms of 'dog'\nwn.synsets('cat')","def5d253":"#Synsets = Synonym sets.  Find all the VERB synonmyms of 'dog'\nwn.synsets('dog', pos=wn.VERB)","21239bf7":"#Select the synset\nwn.synset('dog.n.01')","bb9c1c58":"#Find the Definition of the given synset\nprint(wn.synset('chase.v.01').definition())","7625a56c":"#Find the Examples of the given synset\nprint(wn.synset('chase.v.01').examples())","a5eb9c74":"#Lemmas = Collection of synonym words \nwn.synset('dog.n.01').lemmas()","f241152c":"#Find the upper entity in hierarchy\ndog = wn.synset('dog.n.01')\ndog.hypernyms()","ed1650bf":"dog.hypernyms()","ed318e4b":"#Find the below entity in hierarchy\ndog.hyponyms()","6a05a963":"good = wn.synset('good.a.01')\ngood.lemmas()","34be0b8b":"good.lemmas()[0].name()","ff5b2e6e":"good.lemmas()[0].antonyms()[0].name()","0945cb49":"from nltk.corpus import wordnet\nword1 = \"weapon\"\nsynArray = wordnet.synsets(word1)\nsynArray\nwoi =  synArray[0]\nprint(\"Word ==>\",word1)\nprint(\"Word Synset==>\",woi)\nprint(\"Word Definition ==>\",woi.definition())\nprint(\"Word Name ==>\",woi.name())\nprint(\"Word Parts of Speech ==>\",woi.pos())\nprint(\"Word Hypernym ==>\",woi.hypernyms())\nprint(\"Word Hyponym ==>\",woi.hyponyms())\nprint(\"Word Hyponym ==>\",woi.hyponyms()[1])\n#print(woi2 = woi.hyponyms()[1])","1e995847":"#For Chatbot please refer to YouTube video\n#https:\/\/www.youtube.com\/watch?v=EMDKOk5FeCA&","fa26737b":"# Frequency distribution of words","8fa34e20":"# Import python packages","252b9e29":"# Count of words, unique words, Lexical Richness","3dca47d2":"# Importing Brown corpus, sentences, words and Frequency Distribution","2ec417f1":"# Find the key word","96a7d636":"# Remove stop words","36e79702":"# Text --> Sentences --> words","dbfc59af":"# Parts of Speech (POS) tag","f92d8f95":"# Import NLTK corpora","0021fcef":"# Word location plot","0b1a1c1e":"POS stands for.\n\nCC coordinating conjunction\nCD cardinal digit\nDT determiner\nEX existential there (like: \u201cthere is\u201d \u2026 think of it like \u201cthere exists\u201d)\nFW foreign word\nIN preposition\/subordinating conjunction\nJJ adjective \u2018big\u2019\nJJR adjective, comparative \u2018bigger\u2019\nJJS adjective, superlative \u2018biggest\u2019\nLS list marker 1)\nMD modal could, will\nNN noun, singular \u2018desk\u2019\nNNS noun plural \u2018desks\u2019\nNNP proper noun, singular \u2018Harrison\u2019\nNNPS proper noun, plural \u2018Americans\u2019\nPDT predeterminer \u2018all the kids\u2019\nPOS possessive ending parent\u2019s\nPRP personal pronoun I, he, she\nPRP$ possessive pronoun my, his, hers\nRB adverb very, silently,\nRBR adverb, comparative better\nRBS adverb, superlative best\nRP particle give up\nTO, to go \u2018to\u2019 the store.\nUH interjection, errrrrrrrm\nVB verb, base form take\nVBD verb, past tense took\nVBG verb, gerund\/present participle taking\nVBN verb, past participle taken\nVBP verb, sing. present, non-3d take\nVBZ verb, 3rd person sing. present takes\nWDT wh-determiner which\nWP wh-pronoun who, what\nWP$ possessive wh-pronoun whose\nWRB wh-abverb where, when"}}