{"cell_type":{"fec609f6":"code","237e4051":"code","bbcfbcbb":"code","f1600552":"code","a1a650e7":"code","36bb60fa":"code","649cee7d":"code","4300504b":"code","2f9f845f":"code","d7e0b396":"code","a3910a21":"code","c4222307":"code","bf782f8b":"code","d1783d81":"code","1b9f3246":"code","61d6d486":"code","b30ba078":"code","ca14cfe3":"code","8a68877f":"code","580c1488":"code","6b181983":"markdown","1b4b697a":"markdown","a330225f":"markdown","94392e4a":"markdown","3742cdbe":"markdown","4efbfa87":"markdown","630ce0fd":"markdown","75ce7591":"markdown","f8f7e26f":"markdown","8cd3dc3c":"markdown","9b86af97":"markdown","b012bc86":"markdown"},"source":{"fec609f6":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","237e4051":"train_df = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-sep-2021\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-sep-2021\/test.csv\")\nsub = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-sep-2021\/sample_solution.csv\")","bbcfbcbb":"train_df.head(10)","f1600552":"Summary = pd.DataFrame(train_df.dtypes, columns=['Dtype'])\nSummary[\"max\"] = train_df.max()\nSummary[\"min\"] = train_df.min()\nSummary[\"Null\"] = train_df.isnull().sum() # to get null values\nSummary[\"First\"] = train_df.iloc[0] # to get first value\nSummary[\"Second\"] = train_df.iloc[1] # to get second value\nSummary","a1a650e7":"y = train_df[\"claim\"]\ntrain_df = train_df.drop([\"id\"], axis=1)\ntrain_df = train_df.drop([\"claim\"], axis=1)","36bb60fa":"test_df = test_df.drop([\"id\"], axis=1)","649cee7d":"train_df[\"max_value\"] = train_df.max(axis = 1)\ntrain_df[\"min_value\"] = train_df.min(axis = 1 )\ntrain_df['num_missing_std'] = train_df.isna().std(axis=1).astype('float') \ntrain_df[\"mean\"] = train_df.mean(axis = 1)\ntrain_df[\"median\"] = train_df.median(axis = 1)\ntrain_df[\"std\"] = train_df.std(axis = 1)\ntrain_df['mad'] = train_df.mad(axis=1) \ntrain_df[\"skew\"] = train_df.skew(axis = 1)\ntrain_df[\"null_value\"] = train_df.isnull().sum(axis = 1)","4300504b":"\ntest_df[\"max_value\"] = test_df.max(axis = 1)\ntest_df[\"min_value\"] = test_df.min(axis = 1 )\ntest_df['num_missing_std'] = test_df.isna().std(axis=1).astype('float') \ntest_df[\"mean\"] = test_df.mean(axis = 1)\ntest_df[\"median\"] = test_df.median(axis = 1)\ntest_df[\"std\"] = test_df.std(axis = 1)\ntest_df['mad'] = test_df.mad(axis=1) \ntest_df[\"skew\"] = test_df.skew(axis = 1)\ntest_df[\"null_value\"] = test_df.isnull().sum(axis = 1)","2f9f845f":"# test_df.isnull().sum()\ny.value_counts() #kool","d7e0b396":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\n\nX_train, X_test, y_train, y_test = train_test_split(train_df, y, stratify = y, random_state = 123, test_size = 0.1)","a3910a21":"from sklearn.impute import SimpleImputer\n\nnumerical_transformer = SimpleImputer(strategy='constant', fill_value=0)\n# numerical_transformer = SimpleImputer(strategy='mean') # above one worked better rather than this one\n\nimputed_train = pd.DataFrame(numerical_transformer.fit_transform(X_train))\nimputed_test = pd.DataFrame(numerical_transformer.transform(X_test))\nimputed_train.columns = train_df.columns # Columns are not preserved when imputing\nimputed_test.columns = train_df.columns","c4222307":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train = scaler.fit_transform(imputed_train)\nX_test = scaler.transform(imputed_test)","bf782f8b":"lr = LogisticRegression(random_state=123, C = 0.01, penalty = 'l2')\nlr.fit(X_train, y_train)","d1783d81":"y_pred = lr.predict_proba(X_test)","1b9f3246":"y_pred = y_pred[:, 1]","61d6d486":"from sklearn.metrics import roc_curve, auc\n\nfpr, tpr, thresholds = roc_curve(y_test, y_pred)\nprint(auc(fpr, tpr))\n\n# Never mnind this stuff written below, its just the progress!\n# this is the score: 0.5254161343242256\n# this is the score with logisticR: 0.530162419244593\n# score with logistic regression: 0.5410502320900562\n#  score with logistic regression with mean: Nevermind\n# score with zero imputation: 0.5818869874137387\n# score improved without removing extra features that I added 0.5895987572971035\n# score improved without removing extra features and adding extra features 0.7981633906567501\n# score with unique value feature added did not hep 0.7907597973759513\n# score now is 0.798165516631935\n# score now is 0.7982741998661137\n# score now is 0.803559088213053 with constant imputation and with extra features","b30ba078":"\nimputed_test_df = pd.DataFrame(numerical_transformer.transform(test_df))\nimputed_test_df.columns = imputed_test_df.columns # Columns are not preserved when imputing","ca14cfe3":"test_df = scaler.transform(imputed_test_df)","8a68877f":"y_val = lr.predict_proba(test_df)\ny_val = y_val[:, 1]","580c1488":"sub = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-sep-2021\/sample_solution.csv\")\nsub[\"claim\"] = y_val\nsub.to_csv(\"lr.csv\", index=False)\nsub.head(10)","6b181983":"Nothing fancy going on in here, just trying to get the info of the training data \ud83d\ude0e","1b4b697a":"### Reading the Data","a330225f":"### Getting rid of the target variable and ID","94392e4a":"### Model","3742cdbe":"### Feature Engineering stuff","4efbfa87":"### Submission","630ce0fd":"### Summary of the data","75ce7591":"### Splitting the Data","f8f7e26f":"### Do give an upvote if you think it is easy to understand for yall and help me by commenting your suggestions of what I could try more.\n### Happy Kaggling!","8cd3dc3c":"### Data transformation","9b86af97":"### Performance","b012bc86":"Okay, target variable is pretty balanced!"}}