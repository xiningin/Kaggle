{"cell_type":{"573dffc2":"code","d84b77de":"code","cdcebd63":"code","1da6b230":"code","04b51985":"code","cbe9677e":"code","6110d511":"code","e02fd6f8":"code","f8102200":"code","932277b6":"code","aa2f8b06":"code","c5d97c1f":"code","7c60fd02":"code","62b417bb":"code","7ea14a3d":"code","cd9f2cfd":"markdown","f2d766ef":"markdown","c8dad805":"markdown","ba4e74d8":"markdown","e4d965d8":"markdown","5f095d9c":"markdown","18e5e0a9":"markdown","14a47d63":"markdown","6aca5108":"markdown"},"source":{"573dffc2":"%%capture\n!pip install pytorch-tabnet","d84b77de":"import torch\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom pytorch_tabnet.tab_model import TabNetClassifier\nfrom pytorch_tabnet.pretraining import TabNetPretrainer\n\ntrain = pd.read_csv(\"..\/input\/tabular-playground-series-jun-2021\/train.csv\")","cdcebd63":"# Normalization\nfor i in range(75):\n    mean, std = train[f'feature_{i}'].mean(), train[f'feature_{i}'].std()\n    train[f'feature_{i}'] = train[f'feature_{i}'].apply(lambda x : (x-mean)\/std)","1da6b230":"# Train, Test, Validation Split\ntarget = 'target'\nif \"Set\" not in train.columns:\n    train[\"Set\"] = np.random.choice([\"train\", \"valid\", \"test\"], p =[.8, .1, .1], size=(train.shape[0],))\n\ntrain_indices = train[train.Set==\"train\"].index\nvalid_indices = train[train.Set==\"valid\"].index\ntest_indices = train[train.Set==\"test\"].index","04b51985":"nunique = train.nunique()\ntypes = train.dtypes\n\ncategorical_columns = []\ncategorical_dims =  {}\nfor col in train.columns:\n    if types[col] == 'object':\n        print(col, train[col].nunique())\n        l_enc = LabelEncoder()\n        train[col] = l_enc.fit_transform(train[col].values)\n        categorical_columns.append(col)\n        categorical_dims[col] = len(l_enc.classes_)\n    else:\n        train.fillna(train.loc[train_indices, col].mean(), inplace=True)","cbe9677e":"# Columns not to use\nunused_feat = ['Set']\n\n# Features to Use\nfeatures = [ col for col in train.columns if col not in unused_feat+[target]] \n\nX_train = train[features].values[train_indices]\ny_train = train[target].values[train_indices]\n\nX_valid = train[features].values[valid_indices]\ny_valid = train[target].values[valid_indices]\n\nX_test = train[features].values[test_indices]\ny_test = train[target].values[test_indices]","6110d511":"# Basic model parameters\nmax_epochs = 30\nbatch_size = 1024\nopt = torch.optim.Adam # Optimizer\nopt_params = dict(lr=1e-3)\nsch = torch.optim.lr_scheduler.StepLR # LR Scheduler\nsch_params = {\"step_size\":10, \"gamma\":0.9}\nmask = 'entmax'\nworkers = 2 # For torch DataLoader\nsample_type = 1 # For automated sampling with inverse class occurrences \nvirtual_batch = 128 # Size of the mini batches used for \"Ghost Batch Normalization\"","e02fd6f8":"unsupervised_model = TabNetPretrainer(\n    optimizer_fn = opt,\n    optimizer_params = opt_params,\n    mask_type = mask)","f8102200":"clf = TabNetClassifier(gamma = 1.5,\n                       lambda_sparse = 1e-4,\n                       optimizer_fn = opt,\n                       optimizer_params = opt_params,\n                       scheduler_fn = sch,\n                       scheduler_params = sch_params,\n                       mask_type = mask)","932277b6":"unsupervised_model.fit(\n    X_train=X_train,\n    eval_set=[X_valid],\n    pretraining_ratio=0.8)","aa2f8b06":"clf.fit(X_train=X_train, \n    y_train=y_train,\n    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n    eval_name=['train', 'val'],\n    eval_metric=[\"logloss\", 'balanced_accuracy'],\n    max_epochs=max_epochs , patience=15,\n    batch_size=batch_size,\n    virtual_batch_size=virtual_batch,\n    num_workers=workers,\n    weights=sample_type,\n    drop_last=False,\n    from_unsupervised=unsupervised_model)","c5d97c1f":"# plot losses\nplt.plot(clf.history['loss'])","7c60fd02":"# plot auc\nplt.plot(clf.history['train_logloss'])\nplt.plot(clf.history['val_logloss'])","62b417bb":"test = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/test.csv')\ntest_indices = test.index\ntest_ds = test[features].values[test_indices]\n\nsample_submission = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/sample_submission.csv')\nsample_submission[['Class_1','Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6', 'Class_7', 'Class_8', 'Class_9']] = clf.predict_proba(test_ds)\nsample_submission.to_csv('tabnet_submission.csv',index = False)","7ea14a3d":"sample_submission.head()","cd9f2cfd":"<a id = 'process'><\/a>\n# Pre-Processing \ud83d\udc4e\ud83c\udffb -> \ud83d\udc4d","f2d766ef":"<a id = 'train'><\/a>\n# Training \ud83d\udcaa\ud83c\udffb","c8dad805":"# Submission","ba4e74d8":"We'll split the dataset into a **80-10-10 split** for training, validation and test respectively.","e4d965d8":"<a id = 'basic'> <\/a>\n# Packages \ud83d\udce6 and Basic Setup\n\nInitially introduced in the paper titled [**\"TabNet: Attentive Interpretable Tabular Learning\"**](https:\/\/arxiv.org\/pdf\/1908.07442.pdf), TabNet is a novel high-performance and interpretable canonical deep tabular data learning architecture. It uses sequential attention to choose which features to reason from at each decision step, enabling interpretability and more efficient learning as the learning capacity is used for the most salient features.\n\n![](https:\/\/github.com\/SauravMaheshkar\/Tabular-Playground-Series-May-2021\/blob\/main\/assets\/tabnet.png?raw=true)\n\nA Pytorch Implementation of Tabnet has been made available by the team at [**dreamquark-ai**](https:\/\/github.com\/dreamquark-ai\/tabnet). We can simply install the package using `pip`.\n```\npip install pytorch-tabnet\n```\n\nThis kernel aims to be a starter notebook for you to add your own pre-processing \/ parameters.","5f095d9c":"The paper highlights a semi-supervised pre-training method which is available via the **`TabNetPretrainer`** class. We'll use this pretrain this model and use it to boost the tabnet model performance as a unsupervised prior.","18e5e0a9":"![](https:\/\/github.com\/SauravMaheshkar\/Tabular-Playground-Series-June-2021\/blob\/main\/assets\/TPS%20June%202021.png?raw=true)\n\n# Table of Contents\n\n1. [**Packages \ud83d\udce6 and Basic Setup**](#basic)\n2. [**Pre-Processing \ud83d\udc4e\ud83c\udffb -> \ud83d\udc4d**](#process)\n3. [**The Model \ud83d\udc77\u200d\u2640\ufe0f**](#model)\n4. [**Training \ud83d\udcaa\ud83c\udffb**](#train)","14a47d63":"Fill NaN values + **optional** script for object columns","6aca5108":"<a id = 'model'><\/a>\n# The Model \ud83d\udc77\u200d\u2640\ufe0f"}}