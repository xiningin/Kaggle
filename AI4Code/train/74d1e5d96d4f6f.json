{"cell_type":{"0fafc58f":"code","4aa8142f":"code","4043cfdc":"code","2dbc8b86":"code","9a85d62b":"code","a7562b56":"code","d971a20c":"code","8c11b5a6":"code","e4735f2e":"markdown"},"source":{"0fafc58f":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom sklearn.metrics import roc_auc_score\nfrom keras.layers import Dropout, BatchNormalization\nfrom keras.layers.advanced_activations import PReLU, LeakyReLU\nfrom keras.optimizers import Adam\nfrom sklearn.model_selection import KFold\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.models import load_model\n\nimport gc\nimport os\nprint(os.listdir(\"..\/input\"))\nprint(os.listdir(\"..\/input\/save-dromosys-features\"))\n","4aa8142f":"df = pd.read_pickle('..\/input\/save-dromosys-features\/df.pkl.gz')\nprint(\"Raw shape: \", df.shape)\n\ndf.set_index('SK_ID_CURR', inplace=True)\n\ny = df['TARGET'].copy()\nfeats = [f for f in df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n\ndf.drop(['index', 'TARGET'], axis=1, inplace=True)\n\nprint(\"X shape: \", df.shape, \"    y shape:\", y.shape)\n\nprint(\"\\nPreparing data...\")\nfor feat in feats:\n    df[feat] = df[feat].fillna(df[feat].mean())","4043cfdc":"# i must congrats someone that did this, but i read it on internet, please if it's you, congrats, and explain your code :)\ndef rank_gauss(x):\n    from scipy.special import erfinv\n    N = x.shape[0]\n    temp = x.argsort()\n    rank_x = temp.argsort() \/ N\n    rank_x -= rank_x.mean()\n    rank_x *= 2\n    efi_x = erfinv(rank_x)\n    efi_x -= efi_x.mean()\n    return efi_x","2dbc8b86":"for i in df.columns:\n    #print('Categorical: ',i)\n    df[i] = rank_gauss(df[i].values)","9a85d62b":"training = y.notnull()\ntesting = y.isnull()\nX_train = df[training].values\nX_test = df[testing].values\ny_train = np.array(y[training])\nprint( X_train.shape, X_test.shape, y_train.shape )\ngc.collect()","a7562b56":"import tensorflow as tf\nfrom keras.callbacks import Callback\nimport logging\nclass IntervalEvaluation(Callback):\n    def __init__(self, validation_data=(), interval=10):\n        super(Callback, self).__init__()\n\n        self.interval = interval\n        self.X_val, self.y_val = validation_data\n\n    def on_epoch_end(self, epoch, logs={}):\n        y_pred = self.model.predict_proba(self.X_val, verbose=0)\n        score = roc_auc_score(self.y_val, y_pred)\n        \n        logging.info(\"interval evaluation - epoch: {:d} - score: {:.6f}\".format(epoch, score))\n        print(\"interval evaluation - epoch: {:d} - score: {:.6f}\".format(epoch, score))\n        logs['val_auc'] = score\n","d971a20c":"n_folds = 10\nfolds = KFold(n_splits=n_folds, shuffle=True, random_state=42)\nsub_preds = np.zeros(X_test.shape[0])\noof_preds = np.zeros(X_train.shape[0])\n\nfor n_fold, (trn_idx, val_idx) in enumerate(folds.split(X_train)):\n    trn_x, trn_y = X_train[trn_idx], y_train[trn_idx]\n    val_x, val_y = X_train[val_idx], y_train[val_idx]\n    earlystop = EarlyStopping(monitor='val_auc', min_delta=0, patience=3, verbose=0, mode='max')\n    file_path = \"fold \" + str(n_fold+1) + \" best_model.hdf5\"\n    check_point = ModelCheckpoint(file_path, monitor = \"val_auc\", verbose = 1, save_best_only = True, mode = \"max\")\n    \n    print( 'Setting up neural network...' )\n    nn = Sequential()\n    nn.add(Dense(units = 400 , kernel_initializer = 'normal', input_dim = df.shape[1]))\n    nn.add(PReLU())\n    nn.add(Dropout(.3))\n    nn.add(Dense(units = 160 , kernel_initializer = 'normal'))\n    nn.add(PReLU())\n    nn.add(BatchNormalization())\n    nn.add(Dropout(.3))\n    nn.add(Dense(units = 64 , kernel_initializer = 'normal'))\n    nn.add(PReLU())\n    nn.add(BatchNormalization())\n    nn.add(Dropout(.3))\n    nn.add(Dense(units = 26, kernel_initializer = 'normal'))\n    nn.add(PReLU())\n    nn.add(BatchNormalization())\n    nn.add(Dropout(.3))\n    nn.add(Dense(units = 12, kernel_initializer = 'normal'))\n    nn.add(PReLU())\n    nn.add(BatchNormalization())\n    nn.add(Dropout(.3))\n    nn.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n    nn.compile(loss='binary_crossentropy', optimizer='adam')\n    \n    print( 'Fitting neural network...' )\n    ival = IntervalEvaluation(validation_data=(val_x, val_y), interval=10)\n    nn.fit(trn_x, trn_y, validation_data = (val_x, val_y), epochs=20, verbose=0, callbacks=[ival, earlystop, check_point], batch_size=128)\n    \n    best_model = load_model(file_path)\n    \n    oof_preds[val_idx] = best_model.predict(val_x).flatten()\n    \n    print(roc_auc_score(val_y, oof_preds[val_idx]))\n    \n    \n    print( 'Predicting...' )\n    sub_preds += best_model.predict(X_test).flatten().clip(0,1) \/ folds.n_splits\n    \n    gc.collect()\nprint('FULL AUC: {}'.format(roc_auc_score(y_train, oof_preds)))","8c11b5a6":"print( 'Saving results...' )\nsub = pd.DataFrame()\nsub_train = pd.DataFrame()\nsub['SK_ID_CURR'] = df[testing].index\nsub['TARGET'] = sub_preds\nsub[['SK_ID_CURR', 'TARGET']].to_csv('sub_nn.csv', index= False)\n\nprint( sub.head() )","e4735f2e":"This kernel is forked from Takumi Ihara's kernel \"10-fold-simple-FFNN-with-rank-gauss\" \nwhich is forked from Andy Harless's kernel \"Simple FFNN from Dromosys Features\".  \nOriginal kernel has no early stopping.  "}}