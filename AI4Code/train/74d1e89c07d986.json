{"cell_type":{"4f67bcfd":"code","2826689c":"code","e3cece42":"code","6c5595f0":"code","3a01c8ad":"code","b09205a5":"code","94f18183":"code","1771de5e":"code","78e07011":"code","1ad1be43":"code","d7ddeb65":"code","a4b8a3c4":"code","988f3b43":"code","03c571ac":"code","12485f10":"code","5f2cdddc":"code","8e8271f8":"code","7915fad0":"code","191429f5":"code","9fc2cf47":"code","d8b016f8":"code","61aaf734":"code","29643a05":"code","8abfd6b5":"code","d239664e":"code","a927f866":"code","fb8f2d2a":"code","29ba7292":"code","ba5eeb72":"code","fc235dbd":"code","49266e06":"code","0ed349a7":"code","9334d6f0":"code","da55edf8":"code","c69ecc2c":"code","22ab39bf":"code","288bbfe7":"code","b29c6d79":"code","bf2354e4":"code","9ada2c79":"markdown","69ecd51f":"markdown","c78d061e":"markdown","c0125df9":"markdown","b10b4d41":"markdown","50c30bd1":"markdown","31d95926":"markdown","42d0cf04":"markdown","473a9871":"markdown","72a8dc4d":"markdown","6c8a3d68":"markdown","d6f7adf5":"markdown","c13e5c4f":"markdown","6d334b25":"markdown","f9817b09":"markdown","4a5a6aa7":"markdown","07a4185c":"markdown","5084647f":"markdown","e8f0b994":"markdown"},"source":{"4f67bcfd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2826689c":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","e3cece42":"admission = pd.read_csv(\"\/kaggle\/input\/graduate-admissions\/Admission_Predict.csv\")\nadmission_new = pd.read_csv(\"\/kaggle\/input\/graduate-admissions\/Admission_Predict_Ver1.1.csv\")","6c5595f0":"print(admission.shape,admission_new.shape)","3a01c8ad":"admission.head()","b09205a5":"admission_new.head()","94f18183":"'''Normaizing columns name as there are unnnecessary spaces at the end and we will also reove spaces between two words. It will help us while\naccessing columns'''\nadmission.columns = [\"_\".join(i.strip().split()) for i in admission.columns]\nadmission_new.columns = [\"_\".join(i.strip().split()) for i in admission_new.columns]","1771de5e":"\nadmission.drop(['Serial_No.'],axis=1,inplace=True)\nadmission.info()","78e07011":"admission.describe()","1ad1be43":"if admission.drop_duplicates(subset=admission.drop(['Chance_of_Admit'],axis=1).columns).shape[0] == admission.shape[0]:\n    print(\"No duplicate entry!!\")\nelse:\n    print(\"Yes there are duplicacies in data!!\")","d7ddeb65":"sns.pairplot(admission.drop(['Chance_of_Admit'],axis=1),diag_kind='kde')\nplt.show()","a4b8a3c4":"fig,ax = plt.subplots(4,1,figsize=(14,20))\nfor i,j in enumerate(['University_Rating','SOP','LOR','Research']):\n    admission[j].value_counts().plot.bar(ax=ax[i-1],title=j)\nfig.tight_layout()","988f3b43":"plt.figure(figsize=(14,8))\nsns.scatterplot(data=admission,x='CGPA',y='Chance_of_Admit',hue='University_Rating',legend='full')\nplt.show()","03c571ac":"plt.figure(figsize=(14,8))\nsns.scatterplot(data=admission,x='GRE_Score',y='Chance_of_Admit',hue='University_Rating',legend='full')\nplt.show()","12485f10":"plt.figure(figsize=(14,8))\nsns.scatterplot(data=admission,x='TOEFL_Score',y='Chance_of_Admit',hue='University_Rating',legend='full')\nplt.show()","5f2cdddc":"plt.figure(figsize=(14,8))\nsns.scatterplot(data=admission,x='CGPA',y='TOEFL_Score',hue='Chance_of_Admit',legend='brief')\nplt.show()","8e8271f8":"sns.pairplot(admission,hue='Chance_of_Admit',diag_kws={'bw': 0.2,'legend':'brief'})\nplt.show()","7915fad0":"plt.figure(figsize=(14,8))\nsns.heatmap(admission.corr()[['Chance_of_Admit']],annot=True)\nplt.show()","191429f5":"plt.figure(figsize=(12,6))\nsns.heatmap(admission[['CGPA','TOEFL_Score','GRE_Score']].corr(),annot=True)\nplt.show()","9fc2cf47":"admission['GRE_TOEFL_CGPA_Combined'] = (admission.TOEFL_Score\/120) + (admission.GRE_Score\/340) + (admission.CGPA\/10)","d8b016f8":"admission.GRE_TOEFL_CGPA_Combined.corr(admission.Chance_of_Admit) #Correlation of combined variable with target varible","61aaf734":"validation = admission_new.iloc[-100:,1:] #Serial_No is not in admission dataframe.","29643a05":"validation['GRE_TOEFL_CGPA_Combined'] = (validation.TOEFL_Score\/120)+(validation.GRE_Score\/340)+(validation.CGPA\/10)","8abfd6b5":"validation.shape","d239664e":"validation.tail()","a927f866":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.svm import SVR\nfrom xgboost import XGBRegressor","fb8f2d2a":"lr = LinearRegression()\nlr.fit(admission.drop(['GRE_TOEFL_CGPA_Combined','Chance_of_Admit'],axis=1),admission.Chance_of_Admit)\nprint(\"Last 100 observations RMSE :\",np.sqrt(mean_squared_error(validation.Chance_of_Admit,lr.predict(validation.drop(['GRE_TOEFL_CGPA_Combined','Chance_of_Admit'],axis=1)))))","29ba7292":"lr = LinearRegression()\nlr.fit(admission.drop(['GRE_Score','CGPA','TOEFL_Score','Chance_of_Admit'],axis=1),admission.Chance_of_Admit)\nprint(\"Last 100 observations RMSE :\",np.sqrt(mean_squared_error(validation.Chance_of_Admit,lr.predict(validation.drop(['GRE_Score','CGPA','TOEFL_Score','Chance_of_Admit'],axis=1)))))","ba5eeb72":"master = pd.read_csv(\"\/kaggle\/input\/graduate-admissions\/Admission_Predict_Ver1.1.csv\")\nprint(master.shape)\nmaster.head()","fc235dbd":"train = master.iloc[:400,:]\ntest = master.iloc[400:,:]","49266e06":"import h2o\nfrom h2o import H2OFrame\nfrom h2o.automl import H2OAutoML\nfrom sklearn.metrics import mean_squared_error","0ed349a7":"# Initialize H2O Instance\n\nh2o.init()","9334d6f0":"#Create H2O frame\ntrain_h2o = h2o.H2OFrame(train)\ntest_h2o = h2o.H2OFrame(test)","da55edf8":"#Explanatory and Response Variable\n\nfeatures = train.drop(['Chance of Admit '],axis=1).columns\ntarget = 'Chance of Admit '","c69ecc2c":"?H2OAutoML","22ab39bf":"model = H2OAutoML(max_models = 30, max_runtime_secs=300, seed = 1) #Ther are many parameter which you can tune as per your requirements.\nmodel.train(list(features),target,training_frame=train_h2o) #train H2O model","288bbfe7":"model.leaderboard","b29c6d79":"#Model Validation\n\npredict = h2o.as_list(model.predict(test_h2o),use_pandas=True) #Making Prediction and Changing Into Pandas DataFrame\npredict","bf2354e4":"# Calculate RMSE on test data\nnp.sqrt(mean_squared_error(test['Chance of Admit '],predict['predict']))","9ada2c79":"# Linear Regression Model excluding All 3 Multicollinear Features And Including Combined `GRE_TOEFL_CGPA_Combined` variable","69ecd51f":"<h3> `admission` dataframe is our training data.<\/h3>\n\n<h1 style=\"text-align:center;\">While<\/h1>\n\n<h3>Last 100 observations of `admission_new` dataframe will be for validation purpose.<\/h3>","c78d061e":"<h1 style=\"color:blue;text-align:center;font-size:50px;\">Manual Machine Learning<h1>","c0125df9":"# Multivariate Analysis","b10b4d41":"# Linear Regression Model Having All Three Multicollinear Features","50c30bd1":"# Check Distribution of All Explanatory Variable and Correlation B\/W Them","31d95926":"<h3>From above graph it is clear that if someone want good university with less CGPA then his\/her chances of admission will be less. Although there are some exceptions.<\/h3>","42d0cf04":"# Model Building","473a9871":"# Creating Multivarite plots using pairplot","72a8dc4d":"<h1 style=\"color:red;text-align:center;font-size:50px;\">Auto Machine Learning(AutoML)<h1>\n    \n    \n**We will use `h2o anutML`**\n    \n<h3>The Automatic Machine Learning (AutoML) function automates the supervised machine learning model training process.<\/h3>\n\n**The current version of AutoML trains and cross-validates**\n    \n--->a Random Forest (DRF), \n\n--->an Extremely-Randomized Forest (DRF\/XRT),\n\n--->a random grid of Generalized Linear Models (GLM)\n\n--->a random grid of XGBoost (XGBoost),\n\n--->a random grid of Gradient Boosting Machines (GBM), \n\n--->a random grid of Deep Neural Nets (DeepLearning),and 2 Stacked Ensembles, one of all the models, and one of only the best models of each kind.","6c8a3d68":"# As we can see that explanatory variables are highly correlated with target variable, So we can use linear regression easily. But there is multicollinearty among some explanatory variables. So we need to handle this case also. We will create both type of model by including all three multicollinear variable and by creating a single variable of all these three variable. In below cell we created a combine `GRE_TOEFL_CGPA_Combined` variable.","d6f7adf5":"# Checking Correlation Between Three Continuous features","c13e5c4f":"# Conclusion\n\n**We can see that AutoML is performing good and giving much better result than one of our Manual Machine Learning model.**","6d334b25":"# Checking Correlation of explanatory variables with target variable(Chance_of_Admit)","f9817b09":"<h3>There are three continuous explanatory variable(CGPA,GRE and TOEFL) and four discrete explanatory variables. We can cleary see that continuous variables are cleary correlated while discrete variables are not. Distributions are approximate normal.<\/h3>","4a5a6aa7":"# Visualizing Discrete Variables","07a4185c":"# Let's Do Some EDA","5084647f":"# Any Duplicates?","e8f0b994":"# Meaning Of Each Column\n\n**GRE Scores ( out of 340 )**\n\n**TOEFL Scores ( out of 120 )**\n\n**University Rating ( out of 5 )**\n\n**Statement of Purpose and Letter of Recommendation Strength ( out of 5 )**\n\n**Undergraduate GPA ( out of 10 )**\n\n**Research Experience ( either 0 or 1 )**\n\n**Chance of Admit ( ranging from 0 to 1 )**"}}