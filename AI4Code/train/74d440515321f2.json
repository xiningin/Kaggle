{"cell_type":{"bcad4cea":"code","4e239877":"code","7ac677d3":"code","3b3042e4":"code","cbf25d37":"code","5a9fe698":"code","6c3dae32":"code","eacd85c2":"code","4a625f51":"code","10a16de1":"code","2abcd811":"code","33464f5b":"code","1aa8b890":"code","cbb106d1":"code","dfbd4a74":"code","7beda06c":"code","298670e0":"code","3caa057c":"code","2259b4d0":"code","f2269181":"code","cc08eaa6":"code","84151bdb":"code","c9b1b527":"code","a982977f":"code","5df65cc4":"code","fc0dd824":"code","5fb24059":"code","6307cf37":"markdown","d72867fa":"markdown","3abc3d54":"markdown","c49f75fc":"markdown","b37a53ea":"markdown","cf27c2dc":"markdown","52632735":"markdown"},"source":{"bcad4cea":"from IPython.display import Image\nimport os\n#!ls ..\/input\/\nImage(\"..\/input\/transferlearning\/TL Main.PNG\")","4e239877":"import numpy as np\nfrom keras.datasets import cifar10\n\n#Load the dataset:\n(X_train, y_train), (X_test, y_test) = cifar10.load_data()","7ac677d3":"print(\"There are {} train images and {} test images.\".format(X_train.shape[0], X_test.shape[0]))\nprint('There are {} unique classes to predict.'.format(np.unique(y_train).shape[0]))","3b3042e4":"#One-hot encoding the labels\nnum_classes = 10\nfrom keras.utils import np_utils\ny_train = np_utils.to_categorical(y_train, num_classes)\ny_test = np_utils.to_categorical(y_test, num_classes)","cbf25d37":"y_train.shape,y_test.shape","5a9fe698":"from matplotlib import pyplot as plt\nfig = plt.figure(figsize=(10, 10))\n\nfor i in range(1, 9):\n    img = X_train[i-1]\n    fig.add_subplot(2, 4, i)\n    plt.imshow(img)\n\nprint(\"Shape of each image in the training data: \", X_train.shape[1:])","6c3dae32":"#Importing the necessary libraries \nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, MaxPooling2D\nfrom keras.layers import Dropout, Flatten, GlobalAveragePooling2D\n\n#Building up a Sequential model\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu',input_shape = X_train.shape[1:]))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(32, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dense(10, activation='softmax'))\nmodel.summary()","eacd85c2":"# model compile\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","4a625f51":"# Scaling\nX_train_scratch = X_train\/255.\nX_test_scratch = X_test\/255.","10a16de1":"#Creating a checkpointer \nfrom keras.callbacks import ModelCheckpoint\ncheckpointer = ModelCheckpoint(filepath='scratchmodel.best.hdf5',verbose=1,save_best_only=True)","2abcd811":"#Fitting the model on the train data and labels.\nmodel.fit(X_train_scratch, y_train, batch_size=32, epochs=10,verbose=1, callbacks=[checkpointer], validation_split=0.2, shuffle=True)","33464f5b":"#Evaluate the model on the test data\nscore = model.evaluate(X_test_scratch, y_test)\n\n#Accuracy on test data\nprint('Accuracy on the Test Images: ', score[1])","1aa8b890":"from IPython.display import Image\nimport os\n#!ls ..\/input\/\nImage(\"..\/input\/transferlearning\/TL 1.PNG\")\n","cbb106d1":"from IPython.display import Image\nimport os\n#!ls ..\/input\/\nImage(\"..\/input\/transferlearning\/TL 2.PNG\")","dfbd4a74":"from IPython.display import Image\nimport os\n#!ls ..\/input\/\nImage(\"..\/input\/transferlearning\/TL 3.PNG\")","7beda06c":"from IPython.display import Image\nimport os\n#!ls ..\/input\/\nImage(\"..\/input\/transferlearning\/TL 4.PNG\")","298670e0":"from IPython.display import Image\nimport os\n#!ls ..\/input\/\nImage(\"..\/input\/transferlearning\/TL 5.PNG\")","3caa057c":"from IPython.display import Image\nimport os\n#!ls ..\/input\/\nImage(\"..\/input\/transferlearning\/TL 6.PNG\")","2259b4d0":"from IPython.display import Image\nimport os\n#!ls ..\/input\/\nImage(\"..\/input\/transferlearning\/TL 7.PNG\")","f2269181":"#Keras library for CIFAR dataset\nfrom keras.datasets import cifar10\n(x_train,y_train),(x_test,y_test)=cifar10.load_data()\n\nW_grid=5\nL_grid=5\nfig,axes = plt.subplots(L_grid,W_grid,figsize=(10,10))\naxes=axes.ravel()\nn_training=len(x_train)\nfor i in np.arange(0,L_grid * W_grid):\n    index=np.random.randint(0,n_training) #Pick a random number \n    axes[i].imshow(x_train[index])\n    axes[i].set_title(y_train[index]) #Prints labels on top of the picture\n    axes[i].axis('off')\nplt.subplots_adjust(hspace=0.4)","cc08eaa6":"from sklearn.model_selection import train_test_split\n#Split\nx_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=.3)\n\n#Dimension of the CIFAR10 dataset\nprint((x_train.shape,y_train.shape))\nprint((x_val.shape,y_val.shape))\nprint((x_test.shape,y_test.shape))","84151bdb":"import keras\nimport keras.utils\nfrom keras import utils as np_utils\nfrom keras.utils import to_categorical\n#Onehot Encoding the labels.\n#Since we have 10 classes we should expect the shape[1] of y_train,y_val and y_test to change from 1 to 10\ny_train=to_categorical(y_train)\ny_val=to_categorical(y_val)\ny_test=to_categorical(y_test)\n\n#Verifying the dimension after onehot encoding\nprint((x_train.shape,y_train.shape))\nprint((x_val.shape,y_val.shape))\nprint((x_test.shape,y_test.shape))","c9b1b527":"import matplotlib\nmatplotlib.use(\"Agg\")\n# import the necessary packages\n#from sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n#from sklearn.metrics import classification_report\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n#from tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.utils import to_categorical\nimport matplotlib.pyplot as plt\n#import numpy as np\n#import argparse\n#import cv2\n#import os\nfrom keras.callbacks import ReduceLROnPlateau\n#Image Data Augmentation\ntrain_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True, zoom_range=.1 )\nval_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True,zoom_range=.1)\ntest_generator = ImageDataGenerator(rotation_range=2,  horizontal_flip= True, zoom_range=.1) \n\n#Fitting the augmentation defined above to the data\ntrain_generator.fit(x_train)\nval_generator.fit(x_val)\ntest_generator.fit(x_test)\n\n#Learning Rate Annealer\nlrr= ReduceLROnPlateau(monitor='val_accuracy', factor=.01,  patience=3, min_lr=1e-5) ","a982977f":"# Transfer Learning by using Resnet50 model\nfrom keras.applications.resnet50 import ResNet50\n#Instantiating ResNet50\nbase_model_resnet = ResNet50(include_top=False,weights='imagenet',input_shape=(32,32,3),classes=y_train.shape[1])\n\n#Defining and Adding layers\nmodel_resnet=Sequential()\n#Add the Dense layers along with activation and batch normalization\nmodel_resnet.add(base_model_resnet)\nmodel_resnet.add(Flatten())\n\n#Add the Dense layers along with activation and batch normalization\nmodel_resnet.add(Dense(1024,activation=('relu'),input_dim=512))\nmodel_resnet.add(Dense(512,activation=('relu'))) \nmodel_resnet.add(Dropout(.4))\nmodel_resnet.add(Dense(256,activation=('relu'))) \nmodel_resnet.add(Dropout(.3))#Adding a dropout layer that will randomly drop 30% of the weights\nmodel_resnet.add(Dense(128,activation=('relu')))\nmodel_resnet.add(Dropout(.2))\nmodel_resnet.add(Dense(10,activation=('softmax'))) #This is the classification layer\n\n#Model summary\nmodel_resnet.summary()","5df65cc4":"x_train.shape,y_train.shape,x_test.shape,y_test.shape","fc0dd824":" from keras.optimizers import SGD\n#Defining the parameters\nbatch_size= 100\nepochs=30\nlearn_rate=.001\n\nsgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\n\n#Compile\nmodel_resnet.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n\n#Training\nmodel_resnet.fit_generator(train_generator.flow(x_train,y_train,batch_size=batch_size), epochs=epochs, steps_per_epoch=x_train.shape[0]\/\/batch_size, validation_data=val_generator.flow(x_val,y_val,batch_size=batch_size),validation_steps=250,callbacks=[lrr],verbose=1)\n","5fb24059":"#Making prediction\ny_pred3=model_resnet.predict_classes(x_test)\ny_true=np.argmax(y_test,axis=1)\nfrom sklearn.metrics import accuracy_score\nresnet_acc = accuracy_score(y_true, y_pred3)\nprint('Accuracy Score of ResNet50 = ', resnet_acc)","6307cf37":"<a id=\"Tableofcontents\"><\/a>\n# Table of Contents\n\n* [Introduction](#Introduction)\n* [PlainVanilaNeuralNetworkModel](#PlainVanilaNeuralNetworkModel)\n* [TransferLearningModel](#TransferLearningModel)\n* [References](#References)","d72867fa":"* [Table of Contents](#Tableofcontents)\n<a id=\"References\"><\/a>\n# References","3abc3d54":"1. https:\/\/www.hackerearth.com\/practice\/machine-learning\/transfer-learning\/transfer-learning-intro\/tutorial\/\n1. https:\/\/towardsdatascience.com\/transfer-learning-in-nlp-fecc59f546e4\n1. https:\/\/medium.com\/modern-nlp\/transfer-learning-in-nlp-f5035cc3f62f\n1. https:\/\/blog.insightdatascience.com\/using-transfer-learning-for-nlp-with-small-data-71e10baf99a6\n1. https:\/\/www.pyimagesearch.com\/2020\/04\/27\/fine-tuning-resnet-with-keras-tensorflow-and-deep-learning\/\n1. https:\/\/www.tensorflow.org\/tutorials\/images\/transfer_learning\n1. https:\/\/stackoverflow.com\/questions\/52134926\/reducelronplateau-gives-error-with-adam-optimizer\n1. https:\/\/www.programcreek.com\/python\/example\/101526\/keras.utils.to_categorical\n1. https:\/\/www.youtube.com\/watch?v=lSvo9mRrTHY\n\n","c49f75fc":"* [Table of Contents](#Tableofcontents)\n<a id=\"PlainVanilaNeuralNetworkModel\"><\/a>\n# Plain Vanila Neural Network Model","b37a53ea":"* [Table of Contents](#Tableofcontents)\n<a id=\"TransferLearningModel\"><\/a>\n# Transfer Learning Model","cf27c2dc":"# Objective: To demonstrate image classification model building using plain vanila Neural Network and Pre-Defined ResNet Model (Transfer Learning) \n\n# Plain Vanila NeuralNetwork Vs TransferLearning\n","52632735":"* [Table of Contents](#Tableofcontents)\n<a id=\"Introduction\"><\/a>\n# Introduction\n\n#### The CIFAR-10 dataset (Canadian Institute For Advanced Research) is a collection of images that are commonly used to train machine learning and computer vision algorithms. It is one of the most widely used datasets for machine learning research.The CIFAR-10 dataset contains 60,000 32x32 color images in 10 different classes.The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. There are 6,000 images of each class.\n\n#### Computer algorithms for recognizing objects in photos often learn by example. CIFAR-10 is a set of images that can be used to teach a computer how to recognize objects. Since the images in CIFAR-10 are low-resolution (32x32), this dataset can allow researchers to quickly try different algorithms to see what works. Various kinds of convolutional neural networks tend to be the best at recognizing the images in CIFAR-10. \n\n#### CIFAR -10 here, 10 represents this dataset contains 10 image classifications."}}