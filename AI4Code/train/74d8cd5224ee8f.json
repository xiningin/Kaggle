{"cell_type":{"671932d0":"code","84013542":"code","4a5bc729":"code","54758bd7":"code","d5d40d6b":"code","11e03fa1":"code","91cd16da":"code","1ae0f6ff":"code","581b22ab":"code","a7c9fa3d":"code","1a0ffa51":"code","61d547ad":"code","023dbd5a":"code","47a2585c":"code","634495fd":"code","c2912691":"markdown","f927eac3":"markdown","f7871acf":"markdown","d3412fb6":"markdown"},"source":{"671932d0":"# !pip install -U tensorflow==2.1.0rc0\n# !pip uninstall -y keras","84013542":"import tensorflow as tf\n\nprint(tf.__version__)","4a5bc729":"def get_Xy(in_path):\n    X = HDF5Matrix(in_path, 'strokes')[:]\n    y = to_categorical(word_encoder.transform(HDF5Matrix(in_path, 'word')[:]))\n    return X, y","54758bd7":"import h5py\nimport numpy as np\nimport os\nfrom tensorflow.keras.utils import HDF5Matrix\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelEncoder\n\nbase_dir = os.path.join('..\/input\/quickdraw-overview')\ntrain_path = os.path.join(base_dir, 'quickdraw_train.h5')\nvalid_path = os.path.join(base_dir, 'quickdraw_valid.h5')\n# test_path = os.path.join(base_dir, 'quickdraw_test.h5')\n\nwords = HDF5Matrix(train_path, 'word')[:]\nword_encoder = LabelEncoder()\nword_encoder.fit(words)","d5d40d6b":"X_train, y_train = get_Xy(train_path)\nX_val, y_val = get_Xy(valid_path)\n# X_test, y_test = get_Xy(test_path)\nprint(X_train.shape)\nprint(y_train.shape)","11e03fa1":"import matplotlib.pyplot as plt\n\nfig, m_axs = plt.subplots(3,3, figsize = (16, 16))\nrand_idxs = range(9)# np.random.choice(range(X_train.shape[0]), size = 9)\n\nfor c_id, c_ax in zip(rand_idxs, m_axs.flatten()):\n    test_arr = X_train[c_id]\n    test_arr = test_arr[test_arr[:,2]>0, :] # only keep valid points    \n    lab_idx = np.cumsum(test_arr[:,2]-1)\n                        \n    for i in np.unique(lab_idx):\n        c_ax.plot(test_arr[lab_idx==i,0], \n                test_arr[lab_idx==i,1], '.-')\n    c_ax.axis('off')\n    c_ax.set_title(word_encoder.classes_[np.argmax(y_train[c_id])].decode())\n","91cd16da":"from tensorflow.keras.metrics import top_k_categorical_accuracy\ndef top_5_accuracy(x,y): return top_k_categorical_accuracy(x,y, 5)","1ae0f6ff":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import BatchNormalization, Conv1D, Dense, Dropout, GlobalAveragePooling1D\nmlp_stroke_model = Sequential()\nmlp_stroke_model.add(BatchNormalization(input_shape = (None,)+X_train.shape[2:]))\n# filter count and length are taken from the script https:\/\/github.com\/tensorflow\/models\/blob\/master\/tutorials\/rnn\/quickdraw\/train_model.py\nmlp_stroke_model.add(Conv1D(48, (5,)))\nmlp_stroke_model.add(Dropout(0.3))\nmlp_stroke_model.add(Conv1D(64, (5,)))\nmlp_stroke_model.add(Dropout(0.3))\nmlp_stroke_model.add(Conv1D(128, (3,)))\nmlp_stroke_model.add(Dropout(0.3))\nmlp_stroke_model.add(GlobalAveragePooling1D())\nmlp_stroke_model.add(Dropout(0.3))\nmlp_stroke_model.add(Dense(256))\nmlp_stroke_model.add(Dense(len(word_encoder.classes_), activation = 'softmax'))\nmlp_stroke_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['categorical_accuracy', top_5_accuracy])\nmlp_stroke_model.summary()","581b22ab":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, Conv1D, Dense, Dropout, GlobalMaxPool1D, Concatenate\nfrom tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau, EarlyStopping\nimport datetime\nimport os\nfrom os import path\n\nweight_path=\"{}_weights.best.hdf5\".format('stroke_mlp_model')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\n\n\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=10, verbose=1, mode='auto', epsilon=0.0001, cooldown=5, min_lr=0.0001)\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=5) # probably needs to be more patient, but kaggle time is limited\ncallbacks_list = [checkpoint, early, reduceLROnPlat]","a7c9fa3d":"mlp_stroke_model.fit(X_train, y_train,\n                      validation_data = (X_val, y_val), \n                      batch_size = 1024,\n                      epochs = 30,\n                      shuffle = 'batch',\n                      callbacks = callbacks_list)","1a0ffa51":"mlp_stroke_model.load_weights(weight_path)\nmlp_stroke_results = mlp_stroke_model.evaluate(test_X, test_y, batch_size = 2048)\nprint('Accuracy: %2.1f%%, Top 2 Accuracy %2.1f%%' % (100*mlp_stroke_results[1], 100*mlp_stroke_results[2]))","61d547ad":"from keras.models import Sequential\nfrom keras.layers import BatchNormalization, Conv1D, LSTM, Dense, Dropout\n# if len(get_available_gpus())>0:\n    # https:\/\/twitter.com\/fchollet\/status\/918170264608817152?lang=en\n#     from keras.layers import CuDNNLSTM as LSTM # this one is about 3x faster on GPU instances\nstroke_read_model = Sequential()\nstroke_read_model.add(BatchNormalization(input_shape = (None,)+train_X.shape[2:]))\n# filter count and length are taken from the script https:\/\/github.com\/tensorflow\/models\/blob\/master\/tutorials\/rnn\/quickdraw\/train_model.py\nstroke_read_model.add(Conv1D(48, (5,)))\nstroke_read_model.add(Dropout(0.3))\nstroke_read_model.add(Conv1D(64, (5,)))\nstroke_read_model.add(Dropout(0.3))\nstroke_read_model.add(Conv1D(96, (3,)))\nstroke_read_model.add(Dropout(0.3))\nstroke_read_model.add(LSTM(128, return_sequences = True))\nstroke_read_model.add(Dropout(0.3))\nstroke_read_model.add(LSTM(128, return_sequences = False))\nstroke_read_model.add(Dropout(0.3))\nstroke_read_model.add(Dense(256))\nstroke_read_model.add(Dense(len(word_encoder.classes_), activation = 'softmax'))\nstroke_read_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['categorical_accuracy', top_5_accuracy])\nstroke_read_model.summary()\n\ntf.keras.backend.set_learning_phase(1)","023dbd5a":"weight_path=\"{}_weights.best.hdf5\".format('stroke_lstm_model')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\n\n\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=10, verbose=1, mode='auto', epsilon=0.0001, cooldown=5, min_lr=0.0001)\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=5) # probably needs to be more patient, but kaggle time is limited\ncallbacks_list = [checkpoint, early, reduceLROnPlat]","47a2585c":"stroke_read_model.fit(train_X, train_y,\n                      validation_data = (valid_X, valid_y), \n                      batch_size = 1024,\n                      epochs = 30,\n                      shuffle = 'batch',\n                      callbacks = callbacks_list)","634495fd":"stroke_read_model.load_weights(weight_path)\nlstm_results = stroke_read_model.evaluate(test_X, test_y, batch_size = 2048)\nprint('Accuracy: %2.1f%%, Top 2 Accuracy %2.1f%%' % (100*lstm_results[1], 100*lstm_results[2]))","c2912691":"# Overview\nThe notebook takes the preprocessed data from the QuickDraw step (thumbnails and strokes) and trains 4 different models on the data to see which gets the best performance. The outcome variable (y) is always the same (category). The input for the first two models is the thumbnail and for the last is the stroke data.\n## Classification Models\nThe first is a basic multi-layer perceptron as a sort of baseline. It takes the flattened image vector and with 2 dense or fully-connected layers produces an outcome. \n\nTHe second model is a basic convolutional model similar to AlexNet. The model uses convolutions with max pooling rather than fully-connected layers to allow for some degree of spatial invariance.\n\nThe third model uses the stroke data instead of the image data and has a series of 1D convolutions and Global Average Pooling layers to 'process' but not 'read' the stroke sequences.\n\nThe last model is the stroke-based LSTM. The model takes the stroke data and 'preprocesses' it a bit using 1D convolutions and then uses two stacked LSTMs followed by two dense layers to make the classification. The model can be thought to 'read' the drawing stroke by stroke.\n\n","f927eac3":"# LSTM to Parse Strokes\nThe model suggeted from the tutorial is\n\n![Suggested Model](https:\/\/www.tensorflow.org\/versions\/master\/images\/quickdraw_model.png)","f7871acf":"# Stroke-based Classification\nHere we use the stroke information to train a model and see if the strokes give us a better idea of what the shape could be. ","d3412fb6":"# Stroke baseline Model\nWe can make a baseline stroke model by copying the general structure from the MLP we made before. The model here captures in a sense the sort of information in the strokes themselves without 'reading them'. The convolutions serve to preprocess and then a global average pooling layer to summarize the information in a single vector that can then be processed using standard fully-connected layers.\n"}}