{"cell_type":{"0adea81b":"code","2b069711":"code","88c38b0f":"code","0e084003":"code","bc8e2ab2":"code","427a2221":"code","86f4cd13":"code","a04299e6":"code","7bff2ee2":"code","203e75d0":"code","d1acf13a":"code","87952a7a":"code","ace3f85c":"code","58563c2a":"code","5ea64cd6":"code","d77898e6":"code","7bf9ddf3":"code","e988a065":"code","170d1b0c":"code","395a95a7":"code","95b0f9ee":"code","d7a20b39":"code","c77fd2ff":"code","3ca5d6b8":"code","4d1b16af":"code","4711c7f9":"code","187b99bb":"code","dc6dc8bd":"code","4ed29381":"code","ed8792d5":"code","90a2a136":"code","24712519":"code","f510b8ec":"code","816a56d4":"code","aca5cb00":"code","6de15aab":"code","229a931d":"code","77b9cb32":"code","3579848d":"code","beb6f48a":"markdown","e7b9c676":"markdown","3e26df69":"markdown","24134347":"markdown","6c4714b3":"markdown","bf4aa843":"markdown","c5fc35a0":"markdown","270040c8":"markdown","72c65f80":"markdown","7924993b":"markdown","12694325":"markdown","05bef59d":"markdown","eb44c146":"markdown","2f96853d":"markdown","18d71d74":"markdown","9a3cc46a":"markdown","72b8971f":"markdown","90c6b606":"markdown","449f2461":"markdown","53775caf":"markdown","180f1617":"markdown","a0787e17":"markdown","9eb99413":"markdown","632cf922":"markdown","2456cbf4":"markdown","640e2106":"markdown"},"source":{"0adea81b":"import sys\nprint('\\nRunning on %s' % sys.platform)\nprint('Python Version', sys.version)","2b069711":"from datetime import datetime\nfrom dateutil.relativedelta import *\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport sklearn\nassert sklearn.__version__ >= '0.20'\nimport math\nimport os\nimport sys\nimport matplotlib.pyplot as plt\nimport yellowbrick\nimport statsmodels\nimport tensorflow as tf\nimport skimage.io as io\n\nimport warnings\nwarnings.filterwarnings('ignore')","88c38b0f":"from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, mean_squared_log_error\nfrom sklearn.decomposition import PCA\nfrom sklearn.feature_selection import RFE\nfrom sklearn.tree import DecisionTreeRegressor, plot_tree\nfrom sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\nfrom xgboost import XGBRegressor","0e084003":"color = ['#dc2624', '#2b4750', '#45a0a2', '#e87a59','#7dcaa9', '#649E7D', '#dc8018', '#C89F91', '#6c6d6c', '#4f6268', '#c7cccf']\nsns.set_palette(color)\nsns.set_style('darkgrid',{'axes.facecolor':'#F5F5F5'});","bc8e2ab2":"import math\ndef rmsle(y, y_pred):\n    assert len(y) == len(y_pred)\n    terms_to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n    return (sum(terms_to_sum) * (1.0\/len(y))) ** 0.5","427a2221":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","86f4cd13":"train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","a04299e6":"train.head()","7bff2ee2":"train.info()","203e75d0":"train.drop(['Id'], axis=1).describe()","d1acf13a":"nullsum = pd.DataFrame()\nx = []\ny = []\nfor colname in train.columns:\n    x.append(colname)\n    y.append(train[colname].isnull().sum())\n\nnullsum['columns'] = x\nnullsum['nullvalue'] = y\n\nnullsum[nullsum['nullvalue']>0]","87952a7a":"nullsum.sort_values('nullvalue',inplace=True,ascending=False)\nfig,ax = plt.subplots(figsize=(20,7))\nsns.barplot(x='columns',y='nullvalue',data=nullsum)\nax.set_xticklabels(ax.get_xticklabels(),rotation=90);","ace3f85c":"nullsum_test = pd.DataFrame()\nx = []\ny = []\nfor colname in test.columns:\n    x.append(colname)\n    y.append(test[colname].isnull().sum())\n\nnullsum_test['columns'] = x\nnullsum_test['nullvalue'] = y\n\nnullsum_test[nullsum_test['nullvalue']>0]","58563c2a":"corrmatrix = train.corr();\nfig, ax = plt.subplots(figsize=(25, 15));\nsns.heatmap(corrmatrix, square=True);","5ea64cd6":"corrmatrix.loc['SalePrice'].sort_values(ascending=False)[:10]","d77898e6":"sns.distplot(train['SalePrice']);","7bf9ddf3":"sns.distplot( np.log(train['SalePrice'].to_numpy()) );","e988a065":"def box(columnname):\n    fig,ax = plt.subplots(figsize=(8,5))\n    sns.boxplot(ax=ax, x=columnname, y='SalePrice', data=train, order=train.groupby(columnname)['SalePrice'].mean().sort_values(ascending=False).index)\n    ax.axis(ymin=0, ymax=800000);\n    ax.set_xticklabels(ax.get_xticklabels(),rotation=90);\n\ndef scatter(columnname):\n    fig,ax = plt.subplots(figsize=(8,5))\n    sns.scatterplot(ax=ax, x=columnname, y='SalePrice', data=train)\n    ax.axis(ymin=0, ymax=800000);","170d1b0c":"box('MSZoning')","395a95a7":"fig,ax = plt.subplots(figsize=(20,7))\nsns.boxplot(ax=ax, x='Neighborhood', y='SalePrice', data=train)\nax.axis(ymin=0, ymax=800000);\nax.set_xticklabels(ax.get_xticklabels(),rotation=90);","95b0f9ee":"fig,ax = plt.subplots(figsize=(20,7))\nsns.boxplot(ax=ax, x='YearBuilt', y='SalePrice', data=train)\nax.axis(ymin=0, ymax=800000);\nax.set_xticklabels(ax.get_xticklabels(),rotation=90);","d7a20b39":"scatter('GrLivArea')","c77fd2ff":"scatter('1stFlrSF')","3ca5d6b8":"out = train[(train['GrLivArea']>4000) & (train['SalePrice']<200000)].index\ntrain.drop(out, inplace=True)","4d1b16af":"def cleanfeature(data):\n    #\u88dc\u7f3a\u5931\u503c\n    for i in ['BsmtExposure','BsmtFinType1','BsmtFinType2','FireplaceQu','GarageType','GarageFinish','BsmtQual','BsmtCond','MasVnrType']:\n        data[i].fillna('NoData', inplace=True)\n  \n    data['PoolQC'].replace({'Ex':1,'Fa':0,'Gd':0,np.nan:0},inplace=True)\n    \n    #\u88dc\u773e\u6578\n    #'BsmtFullBath','BsmtHalfBath','Utilities'\n    #'Electrical'\n    for i in ['MSZoning','Functional','KitchenQual','SaleType']:\n        data[i].fillna(data[i].mode(), inplace=True)\n  \n    #\u88dc\u5e73\u5747\u503c\n        data['LotFrontage'].fillna(data['LotFrontage'].mean(), inplace=True)\n\n    #\u7f3a\u5931\u503c\u88dc0\n    for i in ['MasVnrArea','GarageCars','GarageArea','TotalBsmtSF','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','HalfBath']:\n        data[i].fillna(0, inplace=True)\n\n  \n    #\u53d6log\n    tmp = []\n    for i in data.index:\n        if data.loc[i,'LotFrontage']>0:\n            tmp.append(np.log(data.loc[i,'LotFrontage']))\n        else:\n            tmp.append(0)\n    data['LotFrontage_log'] = tmp\n\n    tmp = []\n    for i in data.index:\n        if data.loc[i,'1stFlrSF']>0:\n            tmp.append(np.log(data.loc[i,'1stFlrSF']))\n        else:\n            tmp.append(0)\n    data['1stFlrSF_log'] = tmp\n\n    tmp = []\n    for i in data.index:\n        if data.loc[i,'TotalBsmtSF']>0:\n            tmp.append(np.log(data.loc[i,'TotalBsmtSF']))\n        else:\n            tmp.append(0)\n    data['TotalBsmtSF_log'] = tmp\n\n      #\u65b0\u6b04\u4f4d\n    data['CarArea'] = data['GarageCars']\/data['GarageArea']\n    data['RoomArea'] = data['GrLivArea']\/data['TotRmsAbvGrd']\n    data['TotalHouse'] = data['TotalBsmtSF']+data['1stFlrSF']+data['2ndFlrSF']\n    data['TotalArea'] = data['TotalHouse']+data['GarageArea']\n    data['PorchArea'] = data['OpenPorchSF']+data['EnclosedPorch']+data['3SsnPorch']+data['ScreenPorch']\n    data['TotalPlace'] = data['TotalHouse']+data['GarageArea']+data['PorchArea']\n    data['House_and_LotArea'] = data['TotalHouse']+data['LotArea']\n    data['Bsmt'] = data['BsmtFinSF1']+data['BsmtFinSF2']+data['BsmtUnfSF']\n    data['AllRooms'] = data['FullBath']+(0.5*data['HalfBath'])+data['TotRmsAbvGrd']\n    for i in ['CarArea','RoomArea','TotalHouse','TotalArea','PorchArea','TotalPlace','House_and_LotArea','Bsmt','AllRooms']:\n        data[i].fillna(0, inplace=True)\n\n    #\u6578\u503c\u8f49\u985e\u5225\n    data['OverallCond'].replace({1:'one',2:'two',3:'three',4:'four',5:'five',6:'six',7:'seven',8:'eight',9:'nine',10:'ten'},inplace=True)\n    #train\u8cc7\u6599\u6c92\u6709150\u9019\u985e\uff0c\u770b\u985e\u5225\u89ba\u5f97150\u548c75\u883b\u63a5\u8fd1\u7684\uff0c\u5148\u628a\u5b83\u548c75\u653e\u540c\u4e00\u985e\n    data['MSSubClass'].replace({20:'one',30:'two',40:'three',45:'four',50:'five',60:'six',70:'seven',75:'eight',80:'nine',85:'ten',90:'eleven',120:'twelve',150:'eight',160:'fourteen',180:'fifteen',190:'sixteen'},inplace=True)\n\n    #\u6311\u51fa\u6b04\u4f4d\n    choose = ['BsmtExposure','BsmtFinType1','BsmtFinType2','FireplaceQu','GarageType','GarageFinish','PoolQC','BsmtQual','BsmtCond','MasVnrType',\\\n                'MSZoning','Functional','KitchenQual','SaleType',\\\n                'MasVnrArea',\\\n                'LotFrontage_log','1stFlrSF_log','TotalBsmtSF_log',\\\n                'CarArea','RoomArea',\\\n                'TotalHouse','TotalArea','PorchArea','TotalPlace','House_and_LotArea','Bsmt','AllRooms',\\\n                'OverallCond','MSSubClass',\\\n                'YearRemodAdd','FullBath','Neighborhood','OverallQual','HeatingQC','CentralAir','2ndFlrSF','YearBuilt',\\\n                'LandSlope','Fireplaces','PavedDrive','LandContour','RoofStyle','Foundation','SaleCondition']\n\n    newdata = data.loc[:,choose]\n    newdata = pd.get_dummies(newdata,drop_first=False)\n    return newdata","4711c7f9":"train2 = cleanfeature(train)\ntrain2['SalePrice_log'] = np.log(train['SalePrice'])\nprint(train2.isnull().sum()[train2.isnull().sum()!=0])\ntrain2.head()","187b99bb":"X_realtest = cleanfeature(test)\nprint(X_realtest.isnull().sum()[X_realtest.isnull().sum()!=0])\nX_realtest.head()","dc6dc8bd":"X = train2.drop('SalePrice_log', axis = 1).values\ny = train2['SalePrice_log'].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)","4ed29381":"N = len(train2.columns)-1 #\u539f\u59cb\u6210\u5206\u6578\u91cf\nprint(N)\nscores_train = np.zeros(N)\nscores_test = np.zeros(N)\n\nfor i in np.arange(N,2,-1): #\u5f9eN\u905e\u6e1b\u52302\n    model = make_pipeline(\n      RobustScaler(),\n      PCA(n_components=i),\n      Ridge(alpha=1.5) )\n    model.fit(X_train,y_train)\n    scores_train[i-1] = model.score(X_train,y_train)\n    scores_test[i-1] = model.score(X_test,y_test)\n\ndef start_plot(figsize=(10, 8), style = 'whitegrid'):\n    fig = plt.figure(figsize=figsize)\n    gs = fig.add_gridspec(1,1)\n    plt.tight_layout()\n    ax = fig.add_subplot(gs[0,0])\n    return ax\n\nxdomain = np.arange(2,N,1)\nax=start_plot(figsize=(20,8));\nax.plot(xdomain,scores_train[2:],color='darkorange',label='Training Scores');\nax.plot(xdomain,scores_test[2:],color='navy',label='Test Scores');\nax.legend(loc='lower center',frameon=True,fontsize=13);","ed8792d5":"X = train2.drop('SalePrice_log', axis = 1).values\ny = train2['SalePrice_log'].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n\nrmsle_score=[]\ncomponents=[i for i in range(130,150)]\n\nfor n in components:\n    model = make_pipeline( RobustScaler(),PCA(n_components=n),Ridge(alpha=0.75) )\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    rmsle_score.append(rmsle(y_test, y_pred))\n\n\nprint(rmsle_score)\nfig,ax = plt.subplots(figsize=(15,7));\nplt.scatter(components, rmsle_score);","90a2a136":"rmsle_score=[]\nalpha=[0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2, 2.25, 2.5, 2.75, 3,\n        3.25, 3.5, 3.75, 4, 5]\n\nfor a in alpha:\n    model = make_pipeline( RobustScaler(),PCA(n_components=145),Ridge(alpha=a) )\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    rmsle_score.append(rmsle(y_test, y_pred))\n\n\nprint(rmsle_score)\nfig,ax = plt.subplots(figsize=(15,7));\nplt.scatter(alpha, rmsle_score);","24712519":"X = train2.drop('SalePrice_log', axis = 1).values\ny = train2['SalePrice_log'].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n\nmodel = make_pipeline( RobustScaler(),PCA(n_components=145),Ridge(alpha=0.75) )\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n\nprint('R-squared:',model.score(X_test, y_test))\nprint('Root Mean Squared Logarithmic Error:', rmsle(y_test, y_pred))\nprint(' ')\ncv_results = cross_val_score(model, X, y, cv=5) #5fold-CV\uff0cscore\u662f\u56de\u50b3R-square\nprint('5fold-CV R-squared:',cv_results)\nprint('5fold-CV R-squared Avg:',np.average(cv_results))\nprint('5fold-CV R-squared Std:',np.std(cv_results))","f510b8ec":"X = train2.drop('SalePrice_log', axis = 1).values\ny = train2['SalePrice_log'].values\n\nmodel = make_pipeline( RobustScaler(),PCA(n_components=145),Ridge(alpha=0.75) )\nmodel.fit(X, y)\ny_pred = model.predict(X_realtest)\ny_pred = np.exp(y_pred)\n\nsubmit = pd.DataFrame()\nsubmit['Id'] = test['Id']\nsubmit['SalePrice'] = y_pred\nsubmit.head()","816a56d4":"X = train2.drop('SalePrice_log', axis = 1).values\ny = train2['SalePrice_log'].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n\nscaler = RobustScaler()\nscaler.fit_transform(X_train)\nscaler.transform(X_train)","aca5cb00":"from sklearn.feature_selection import RFE\nrmsle_score=[]\nalpha=[0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2, 2.25, 2.5, 2.75, 3,\n    3.25, 3.5, 3.75, 4, 5]\n\nfor a in alpha:\n    selector = RFE(Ridge(alpha=a))\n    selector.fit(X_train, y_train)\n    y_pred = selector.predict(X_test)\n    rmsle_score.append(rmsle(y_test, y_pred))\n\nprint(rmsle_score)\nfig,ax = plt.subplots(figsize=(15,7));\nplt.scatter(alpha, rmsle_score);","6de15aab":"X = train2.drop('SalePrice_log', axis = 1).values\ny = train2['SalePrice_log'].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n\nscaler = RobustScaler()\nscaler.fit_transform(X_train)\nscaler.transform(X_train)\n\nselector = RFE(Ridge(alpha=1))\nselector.fit(X_train, y_train)\ny_pred = selector.predict(X_test)\n\nprint('\u9078\u4e86%d\u500b\u7279\u5fb5' % selector.support_.sum())\nprint(' ')\nprint('R-squared:',selector.score(X_test, y_test))\nprint('Root Mean Squared Logarithmic Error:', rmsle(y_test, y_pred))\nprint(' ')\ncv_results = cross_val_score(selector, X, y, cv=5) #5fold-CV\uff0cscore\u662f\u56de\u50b3R-square\nprint('5fold-CV R-squared:',cv_results)\nprint('5fold-CV R-squared Avg:',np.average(cv_results))\nprint('5fold-CV R-squared Std:',np.std(cv_results))","229a931d":"model_1 = make_pipeline( RobustScaler(),PCA(n_components=145),Ridge(alpha=0.75) )\nmodel_2 = make_pipeline( RobustScaler(),PCA(n_components=145),Lasso() )\nmodel_3 = make_pipeline( RobustScaler(),PCA(n_components=145),ElasticNet() )\nmodel_4 = make_pipeline( RobustScaler(),DecisionTreeRegressor() )\nmodel_5 = make_pipeline( RobustScaler(),PCA(n_components=145),DecisionTreeRegressor() )\nmodel_6 = make_pipeline( RobustScaler(),RandomForestRegressor() )\nmodel_7 = make_pipeline( RobustScaler(),PCA(n_components=145),RandomForestRegressor() )\nmodel_8 = make_pipeline( RobustScaler(),AdaBoostRegressor() )\nmodel_9 = make_pipeline( RobustScaler(),PCA(n_components=145),AdaBoostRegressor() )\nmodel_10 = make_pipeline( RobustScaler(),GradientBoostingRegressor() )\nmodel_11 = make_pipeline( RobustScaler(),PCA(n_components=145),GradientBoostingRegressor() )\nmodel_12 = make_pipeline( RobustScaler(),XGBRegressor(objective='reg:squarederror') )\nmodel_13 = make_pipeline( RobustScaler(),PCA(n_components=145),XGBRegressor(objective='reg:squarederror') )\n\n\nmodels = [model_1, model_2, model_3, model_4, model_5, model_6, model_7, model_8,\n          model_9, model_10, model_11, model_12, model_13]\ntitles = ['PCA and Ridge', 'PCA and Lasso', 'PCA and ElasticNet',\n          'DecisionTree', 'PCA and DecisionTree',\n          'RandomForest', 'PCA and RandomForest',\n          'AdaBoost', 'PCA and AdaBoost',\n          'GradientBoost', 'PCA and GradientBoost',\n          'XGBOOST', 'PCA and XGBOOST']\n\nmodel_comp = pd.DataFrame()\ncv = StratifiedKFold(n_splits=5)\n\nfor i, model in enumerate(models):\n    model_comp[titles[i]] = cross_val_score(model, X_train, y_train, cv=5)\n\nfig, ax = plt.subplots(figsize=(25,6));\nsns.boxplot(data=model_comp, ax=ax);","77b9cb32":"%%time\nfrom sklearn.ensemble import VotingRegressor\n\nXGBoost = XGBRegressor( objective='reg:squarederror',\n            n_estimators = 2500,\n            learning_rate= 0.008,\n            max_depth = 3,\n            min_child_weight = 3,\n            gamma = 0,\n            subsample = 0.5,\n            colsample_bytree = 0.8,\n            reg_lambda= 0.75,\n            reg_alpha= 0.1 \n            )\n\nGBoost = GradientBoostingRegressor( n_estimators = 1500,\n                    learning_rate = 0.015,\n                    max_depth = 5,\n                    min_samples_leaf = 9,\n                    min_samples_split = 360,\n                    subsample = 1,\n                    max_features = 119)\n\nmodel_1 = make_pipeline( RobustScaler(),PCA(n_components=145),Ridge(alpha=0.75) )\nmodel_2 = make_pipeline( RobustScaler(), XGBoost )\nmodel_3 = make_pipeline( RobustScaler(), GBoost )\n\nensemblemodel = VotingRegressor( estimators = [ ('Ridge', model_1),\n                            ('XGBoost', model_2),\n                            ('GB', model_3)])\nensemblemodel.fit(X_train, y_train)\ny_pred = ensemblemodel.predict(X_test)\n\nprint('R-squared:',ensemblemodel.score(X_test, y_test))\nprint('Root Mean Squared Logarithmic Error:', rmsle(y_test, y_pred))\nprint(' ')\ncv_results = cross_val_score(ensemblemodel, X, y, cv=5)\nprint('5fold-CV R-squared:',cv_results)\nprint('5fold-CV R-squared Avg:',np.average(cv_results))\nprint('5fold-CV R-squared Std:',np.std(cv_results))","3579848d":"X = train2.drop('SalePrice_log', axis = 1).values\ny = train2['SalePrice_log'].values\n\nXGBoost = XGBRegressor( objective='reg:squarederror',\n            n_estimators = 2500,\n            learning_rate= 0.008,\n            max_depth = 3,\n            min_child_weight = 3,\n            gamma = 0,\n            subsample = 0.5,\n            colsample_bytree = 0.8,\n            reg_lambda= 0.75,\n            reg_alpha= 0.1 \n            )\n\nGBoost = GradientBoostingRegressor( n_estimators = 1500,\n                    learning_rate = 0.015,\n                    max_depth = 5,\n                    min_samples_leaf = 9,\n                    min_samples_split = 360,\n                    subsample = 1,\n                    max_features = 119)\n\nmodel_1 = make_pipeline( RobustScaler(),PCA(n_components=145),Ridge(alpha=0.75) )\nmodel_2 = make_pipeline(RobustScaler(), XGBoost )\nmodel_3 = make_pipeline(RobustScaler(), GBoost )\n\nensemblemodel = VotingRegressor( estimators = [ ('Ridge', model_1),\n                            ('XGBoost', model_2),\n                            ('GB', model_3)])\n\nensemblemodel.fit(X, y)\ny_pred = ensemblemodel.predict(X_realtest)\ny_pred = np.exp(y_pred)\n\nsubmit = pd.DataFrame()\nsubmit['Id'] = test['Id']\nsubmit['SalePrice'] = y_pred\nsubmit.head()","beb6f48a":"### 0.2.2 Test","e7b9c676":"\u63d0\u4ea4\u9810\u6e2c\u7d50\u679c\uff0c\u76ee\u524d\u70baTop36%\u3002\n![image.png](attachment:image.png)","3e26df69":"# 2 \u5efa\u6a21","24134347":"![image.png](attachment:image.png)","6c4714b3":"\u6839\u64da\u6a21\u578b\u6bd4\u8f03\u7d50\u679c\uff0c\u4ee5PCA+Ridge\u3001Gradient Boost\u3001XGBoost\u6700\u4f73\uff0c\u6545\u63a5\u7e8c\u9032\u884cGradient Boost\u3001XGBoost\u7684\u8abf\u53c3\u5f8c\uff0c\u7d44\u6210Ensemble\u6a21\u578b\u3002\\\n\u5728\u9019\u9805\u6bd4\u8f03\u7d50\u679c\u4e2d\uff0c\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u6a39\u6a21\u578b\u548c\u96c6\u6210\u6a21\u578b\u8207PCA\u7d50\u5408\u5f8c\u901a\u5e38\u6c92\u80fd\u7372\u5f97\u66f4\u4f73\u7684\u8868\u73fe\uff0c\u9019\u9ede\u503c\u5f97\u5f8c\u7e8c\u518d\u9032\u884c\u7814\u7a76\u63a2\u8a0e\u3002","bf4aa843":"## 0.2 \u7f3a\u5931\u503c\n\u9996\u5148\u89c0\u5bdfTrain\u3001Test\u5169\u8cc7\u6599\u53ca\u5305\u542b\u7f3a\u5931\u503c\u7684\u7279\u5fb5\uff0c\u518d\u6839\u64da\u5176\u5f62\u614b\u6c7a\u5b9a\u5982\u4f55\u88dc\u7f3a\u5931\u503c\u3002\\\nTrain\u8cc7\u6599\u96c6\u4e2d\u670919\u9805\u7279\u5fb5\u5305\u542b\u7f3a\u5931\u503c\uff0cTest\u8cc7\u6599\u96c6\u5247\u670933\u9805\u7279\u5fb5\u5177\u6709\u7f3a\u5931\u503c\uff0c\u8f03Train\u8cc7\u6599\u96c6\u591a\u51fa14\u9805\uff0c\u5f8c\u7e8c\u9032\u884c\u7f3a\u5931\u503c\u586b\u88dc\u3001\u7279\u5fb5\u5de5\u7a0b\u6642\u9808\u6ce8\u610f\u3002\n### 0.2.1 Train","c5fc35a0":"## 1.2 \u7279\u5fb5\u5de5\u7a0b\n\u7d9c\u5408\u524d\u8ff0\u5c0d\u7279\u5fb5\u7684\u89c0\u5bdf\uff0c\u6311\u9078\u51fa\u5408\u9069\u7684\u7279\u5fb5\uff0c\u9032\u884c\u7f3a\u5931\u503c\u8655\u7406\u3001\u5275\u9020\u65b0\u7279\u5fb5\u3001\u6578\u503c\u8207\u985e\u5225\u8b8a\u6578\u8f49\u63db\u7b49\u5de5\u4f5c\uff0c\u6700\u7d42\u5b9a\u7fa9\u51fa\u4ee5\u4e0b\u7684 cleanfeature\u3002","270040c8":"## 2.2 \u78ba\u8a8d\u53c3\u6578\uff0c\u5efa\u6a21","72c65f80":"# 3 \u5f8c\u7e8c\u5617\u8a66\n## 3.1 RFE\n\u7d93\u53c3\u6578\u8abf\u6574\u5f8c\uff0cRidge\u6a21\u578b\u9078\u64c7alpha=1\u3002\n\u63a1\u7528RFE\u7684\u7d50\u679c\u8207PCA\u76f8\u6bd4\uff0c\u4ecd\u662fPCA\u8868\u73fe\u8f03\u4f73\u3002","7924993b":"\u672c\u7bc7\u6bd4\u8f03\u4e86\u5169\u7a2e\u7279\u5fb5\u9078\u64c7\u8fa6\u6cd5(PCA\u3001RFE)\u3001\u4e09\u7a2e\u8ff4\u6b78\u6a21\u578b(Lasso\u3001Ridge\u3001Elastic Net)\u53ca\u96c6\u6210\u65b9\u6cd5\uff0c\u76ee\u524d\u4ee5PCA+Ridge\u3001Gradient Boost\u3001XGBoost\u4e09\u500b\u6a21\u578b\u5efa\u7acbEnsemble Model\u4e26\u63d0\u4ea4\u9810\u6e2c\u7d50\u679c\uff0c\u6210\u7e3e\u70baTop 29%\u3002","12694325":"\u672c\u7bc7\u76ee\u524d\u5df2\u6700\u55ae\u7d14\u7684VotingRegressor\u5c07\u4e09\u7a2e\u6a21\u578b\u7d44\u6210Ensemble Model\u5f8c\u63d0\u4ea4\u9810\u6e2c\u7d50\u679c\uff0c\u76ee\u524d\u7d50\u679c\u70baTop 29%\u3002","05bef59d":"### 0.3.2 \u6aa2\u67e5SalePrice\n\u7531\u65bcSalePrice\u6709\u660e\u986f\u504f\u614b\uff0c\u5c07\u5176\u53d6Log\u4ee5\u5229\u5f8c\u7e8c\u9810\u6e2c\u4f5c\u696d\u3002","eb44c146":"# 1 \u8b80\u53d6\u8cc7\u6599","2f96853d":"\u8cc7\u6599\u5171\u670981\u500b\u6b04\u4f4d\uff0c\u9664\u4e86Id\u53ca\u9810\u6e2c\u76ee\u6a19SalePrice\u5916\uff0c\u5171\u670979\u500b\u7279\u5fb5\uff0c\u5305\u542b\u96e2\u6563\u578b\u3001\u9023\u7e8c\u578b\u7279\u5fb5\uff0c\u4e26\u6709\u5927\u91cf\u7f3a\u5931\u503c\u9700\u8655\u7406\u3002","18d71d74":"## 2.3 \u9810\u6e2cTest\u8cc7\u6599\u96c6","9a3cc46a":"## 2.1 \u53c3\u6578\u8abf\u6574\n### 2.1.1 PCA","72b8971f":"### 2.1.2 Ridge","90c6b606":"## 3.2 Ensemble Model\n\u5305\u542b\u524d\u8ff0\u5efa\u69cb\u7684PCA+Ridge\u6a21\u578b\u5728\u5167\uff0c\u6bd4\u8f0313\u7a2e\u6a21\u578b\uff0c\u4e26\u5f9e\u4e2d\u6311\u9078\u8868\u73fe\u8f03\u4f73\u7684\u6a21\u578b\u3002","449f2461":"\u7d93\u89c0\u5bdf\uff0c\u6c7a\u5b9a\u5177\u7f3a\u5931\u503c\u7684\u6b04\u4f4d\u53ef\u4f9d\u4e0b\u5217\u65b9\u5f0f\u586b\u88dc\uff1a\n1. \u6b64\u985e\u8cc7\u6599\u82e5\u70ba\u7f3a\u5931\u503c\u5c31\u662f\u6c92\u6709\u8a72\u8a2d\u5099\uff0c\u586b\u5165'NoData'\\\n'MiscFeature','Fence','GarageCond','GarageYrBlt', 'BsmtQual','MasVnrType', 'Alley','FireplaceQu','GarageQual'\n\n2. \u88dc\u773e\u6578\\\n'BsmtFullBath','BsmtHalfBath','Utilities', 'Electrical'\n\n3. \u88dc\u5e73\u5747\u503c\\\n'LotFrontage'\n\n4. \u88dc0\\\n'MasVnrArea','GarageCars','GarageArea','TotalBsmtSF','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','HalfBath'","53775caf":"# 1 \u7279\u5fb5\u9078\u64c7\n## 1.1 \u522a\u9664\u96e2\u7fa4\u503c","180f1617":"\u5206\u5225\u5c0dTrain\u3001Test\u8cc7\u6599\u53ca\u5957\u7528\u6b64\u7279\u5fb5\u5de5\u7a0b","a0787e17":"## 0.1 \u8cc7\u6599\u6982\u6cc1","9eb99413":"### 0.3.3 \u7279\u5fb5\u5206\u4f48\n1. \u985e\u5225\u7279\u5fb5","632cf922":"2. \u6578\u503c\u7279\u5fb5\n","2456cbf4":"## 0.3 \u89c0\u5bdf\u7279\u5fb5\n### 0.3.1 \u76f8\u95dc\u6027\n\u767c\u73fe'GrLivArea'\u8207'TotRmsAbvGrd'\u3001'GarageArea'\u8207'GarageCars'\u7684\u76f8\u95dc\u6027\u504f\u9ad8\uff0c\u6545\u5c07\u5176\u8f49\u5316\u70ba\u65b0\u6b04\u4f4d\uff1a\n>   data['CarArea'] = data['GarageCars']\/data['GarageArea']\\\n>  data['RoomArea'] = data['GrLivArea']\/data['TotRmsAbvGrd']","640e2106":"# 0 \u524d\u7f6e\u4f5c\u696d"}}