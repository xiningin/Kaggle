{"cell_type":{"4a671d32":"code","bee2d77f":"code","d05e2089":"code","c4f281e4":"code","06492726":"code","5e5f3a00":"code","693c3497":"code","643b8aa3":"code","70338859":"code","bbfd1016":"code","ea73212c":"code","b5f80b36":"code","48a9e977":"code","843f00b8":"code","57485667":"code","d22e6289":"code","893e45d7":"code","5ae0cf96":"code","b9e8d376":"code","9a0fa121":"code","174eaa64":"code","717f2b43":"code","3440d320":"code","c6e9f427":"code","ef93f6dd":"code","db1897c0":"code","5c743c28":"code","223778a0":"code","6b98415b":"code","bd7b4e36":"code","2d07ee71":"code","8de52349":"code","57609fb7":"code","e49664f1":"code","a76d65cb":"code","ac1f280b":"code","e13f0701":"code","e2b19500":"code","24fe61e0":"code","4160f99e":"code","6c20a4cd":"markdown","c8140afe":"markdown","337d97c6":"markdown","7775d973":"markdown","9e7581fc":"markdown","1b352f42":"markdown","cb4fab40":"markdown","dc492df9":"markdown","fcdffa48":"markdown","21a46a19":"markdown"},"source":{"4a671d32":"!git clone https:\/\/github.com\/ultralytics\/yolov5  # clone\n!pip install -qr yolov5\/requirements.txt  # install","bee2d77f":"import pandas as pd\nimport numpy as np\nimport os\nimport glob\nfrom datetime import datetime\nimport xml.etree.ElementTree as ET \nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","d05e2089":"path_an = \"..\/input\/face-mask-detection\/annotations\"","c4f281e4":"dataset = {\n            \"file\":[],\n            \"name\":[],    \n            \"width\":[],\n            \"height\":[],\n            \"xmin\":[],\n            \"ymin\":[],   \n            \"xmax\":[],\n            \"ymax\":[],\n           }","06492726":"for anno in glob.glob(path_an+\"\/*.xml\"):\n    tree = ET.parse(anno)\n    \n    for elem in tree.iter():\n        if 'size' in elem.tag:\n            for attr in list(elem):\n                if 'width' in attr.tag: \n                    width = int(round(float(attr.text)))\n                if 'height' in attr.tag:\n                    height = int(round(float(attr.text)))    \n\n        if 'object' in elem.tag:\n            for attr in list(elem):\n                \n                if 'name' in attr.tag:\n                    name = attr.text                 \n                    dataset['name']+=[name]\n                    dataset['width']+=[width]\n                    dataset['height']+=[height] \n                    dataset['file']+=[anno.split('\/')[-1][0:-4]] \n                            \n                if 'bndbox' in attr.tag:\n                    for dim in list(attr):\n                        if 'xmin' in dim.tag:\n                            xmin = int(round(float(dim.text)))\n                            dataset['xmin']+=[xmin]\n                        if 'ymin' in dim.tag:\n                            ymin = int(round(float(dim.text)))\n                            dataset['ymin']+=[ymin]                                \n                        if 'xmax' in dim.tag:\n                            xmax = int(round(float(dim.text)))\n                            dataset['xmax']+=[xmax]                                \n                        if 'ymax' in dim.tag:\n                            ymax = int(round(float(dim.text)))\n                            dataset['ymax']+=[ymax]","5e5f3a00":"df=pd.DataFrame(dataset)\ndf.head()","693c3497":"name_dict = {\n    'with_mask': 0,\n    'mask_weared_incorrect': 1,\n    'without_mask': 2 \n}","643b8aa3":"df['class'] = df['name'].map(name_dict)","70338859":"df.info()","bbfd1016":"np.sort(df.name.unique())","ea73212c":"fileNames = [*os.listdir(\"..\/input\/face-mask-detection\/images\")]\nlen(fileNames)","b5f80b36":"from sklearn.model_selection import train_test_split\ntrain, test = train_test_split(fileNames, test_size=0.1, random_state=22)\ntest, val = train_test_split(test, test_size=0.7, random_state=22)\nprint(\"Length of Train =\",len(train))\nprint(\"=\"*30)\nprint(\"Length of Valid =\",len(val))\nprint(\"=\"*30)\nprint(\"Length of test =\", len(test))","48a9e977":"os.mkdir('.\/yolov5\/data\/train')\nos.mkdir('.\/yolov5\/data\/val')\nos.mkdir('.\/yolov5\/data\/test')\nos.mkdir('.\/yolov5\/data\/train\/images')\nos.mkdir('.\/yolov5\/data\/train\/labels')\nos.mkdir('.\/yolov5\/data\/test\/images')\nos.mkdir('.\/yolov5\/data\/test\/labels')\nos.mkdir('.\/yolov5\/data\/val\/images')\nos.mkdir('.\/yolov5\/data\/val\/labels')","843f00b8":"from PIL import Image\n\ndef copyImages(imageList, folder_Name):\n    for image in imageList:\n        img = Image.open(\"..\/input\/face-mask-detection\/images\/\"+image)\n        img1 = img.resize((640, 480))\n        _ = img1.save(\".\/yolov5\/data\/\"+folder_Name+\"\/images\/\"+image)\n        ","57485667":"copyImages(train, \"train\")\ncopyImages(val, \"val\")\ncopyImages(test, \"test\")","d22e6289":"df.head()","893e45d7":"df['xmax'] = (640\/df['width'])*df['xmax']\ndf['ymax'] = (480\/df['height'])*df['ymax']\ndf['xmin'] = (640\/df['width'])*df['xmin']\ndf['ymin'] = (480\/df['height'])*df['ymin']","5ae0cf96":"df[['xmax', 'ymax', 'xmin', 'ymin']] = df[['xmax', 'ymax', 'xmin', 'ymin']].astype('int64')","b9e8d376":"df['x_center'] = (df['xmax']+df['xmin'])\/(2*640)\ndf['y_center'] = (df['ymax']+df['ymin'])\/(2*480)\ndf['box_height'] = (df['xmax']-df['xmin'])\/(640)\ndf['box_width'] = (df['ymax']-df['ymin'])\/(480)","9a0fa121":"df.head()","174eaa64":"df['xbbox'] = df['xmax']-df['xmin']\ndf['ybbox'] = df['ymax']-df['ymin']\n\nsns.set()\nsns.scatterplot(x='xbbox',  y='ybbox', data=df)\nplt.show()","717f2b43":"df = df.astype('string')","3440d320":"def create_labels(image_list, data_name):\n    fileNames = [x.split(\".\")[0] for x in image_list]\n\n    for name in fileNames:\n        data = df[df.file==name]\n        box_list = []\n        \n        for index in range(len(data)):\n            row = data.iloc[index]\n            box_list.append(row['class']+\" \"+row[\"x_center\"]+\" \"+row[\"y_center\"]\\\n                        +\" \"+row[\"box_height\"]+\" \"+row[\"box_width\"])\n            \n        text = \"\\n\".join(box_list)\n        with open(\".\/yolov5\/data\/\"+data_name+\"\/labels\/\"+name+\".txt\", \"w\") as file:\n            file.write(text)        ","c6e9f427":"create_labels(train, \"train\")\ncreate_labels(val, \"val\")\ncreate_labels(test, \"test\")","ef93f6dd":"%cd yolov5","db1897c0":"from IPython.display import Image, Video, clear_output  # to display images\nimport torch\nfrom yolov5 import utils\ndisplay = utils.notebook_init()","5c743c28":"yaml_text = \"\"\"train: data\/train\/images\nval: data\/train\/images\n\nnc: 3\nnames: ['with_mask', 'mask_weared_incorrect', 'without_mask']\"\"\"","223778a0":"with open(\"data\/data.yaml\", 'w') as file:\n    file.write(yaml_text)","6b98415b":"%cat data\/data.yaml","bd7b4e36":"#customize iPython writefile so we can write variables\nfrom IPython.core.magic import register_line_cell_magic\n\n@register_line_cell_magic\ndef writetemplate(line, cell):\n    with open(line, 'w') as f:\n        f.write(cell.format(**globals()))","2d07ee71":"%%writetemplate models\/custom_yolov5s.yaml\n\n# parameters\nnc: 3  # number of classes\ndepth_multiple: 0.33  # model depth multiple\nwidth_multiple: 0.50  # layer channel multiple\n\n# anchors\nanchors:\n    - [10,13, 16,30, 33,23]  # P3\/8\n    - [30,61, 62,45, 59,119]  # P4\/16\n    - [116,90, 156,198, 373,326]  # P5\/32\n\n# YOLOv5 backbone\nbackbone:\n  # [from, number, module, args]\n  [[-1, 1, Focus, [64, 3]],  # 0-P1\/2\n   [-1, 1, Conv, [128, 3, 2]],  # 1-P2\/4\n   [-1, 3, BottleneckCSP, [128]],\n   [-1, 1, Conv, [256, 3, 2]],  # 3-P3\/8\n   [-1, 9, BottleneckCSP, [256]],\n   [-1, 1, Conv, [512, 3, 2]],  # 5-P4\/16\n   [-1, 9, BottleneckCSP, [512]],\n   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5\/32\n   [-1, 1, SPP, [1024, [5, 9, 13]]],\n   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n  ]\n\n# YOLOv5 head\nhead:\n    [[-1, 1, Conv, [512, 1, 1]],\n    [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n    [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n    [-1, 3, BottleneckCSP, [512, False]],  # 13\n\n    [-1, 1, Conv, [256, 1, 1]],\n    [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n    [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n    [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3\/8-small)\n\n    [-1, 1, Conv, [256, 3, 2]],\n    [[-1, 14], 1, Concat, [1]],  # cat head P4\n    [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4\/16-medium)\n\n    [-1, 1, Conv, [512, 3, 2]],\n    [[-1, 10], 1, Concat, [1]],  # cat head P5\n    [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5\/32-large)\n\n    [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n    ]","8de52349":"# train yolov5s on custom data for 100 epochs\n# time its performance\n\nstart = datetime.now()\n!python train.py --img 640 --batch 32 --epochs 100 --data data\/data.yaml --cfg models\/custom_yolov5s.yaml --weights '' --name yolov5s_results  --cache\nend = datetime.now()","57609fb7":"print(\"Runtime =\",end-start)","e49664f1":"img = plt.imread('runs\/train\/yolov5s_results\/train_batch0.jpg')\nplt.figure(figsize=(20,15))\nplt.imshow(img)\nplt.axis('off')\nplt.show()","a76d65cb":"!python detect.py --source data\/test\/images\/ --weight runs\/train\/yolov5s_results\/weights\/best.pt --name expTestImage --conf 0.4","ac1f280b":"color_dict = {\n    'with_mask': (0, 255, 0),\n    'mask_weared_incorrect':  (0, 0, 255),\n    'without_mask': (255, 0, 0) \n}","e13f0701":"def show_image(img_id):\n    df_image = df[df.file==img_id]\n    df_image[['xmin', 'ymin', 'xmax', 'ymax']] = df_image[['xmin', 'ymin', 'xmax', 'ymax']].astype('int64')\n    path = 'data\/test\/images\/'+img_id+'.png'\n    img = plt.imread(path)\n\n    imge = img.copy()\n\n    for index in range(len(df_image)):\n        row = df_image.iloc[index]\n        cv2.rectangle(imge, \n                      (row['xmin'], row['ymin']),\n                      (row['xmax'], row['ymax']),\n                      color=color_dict[row['name']],\n                      thickness=2)\n\n    img_pred = plt.imread('runs\/detect\/expTestImage\/'+img_id+\".png\")\n    # ===================================\n    plt.figure(figsize=(14,17))\n\n    plt.subplot(1,2,1)\n    plt.imshow(imge)\n    plt.axis('off')\n    plt.title('Image with Truth Box')\n\n    plt.subplot(1,2,2)\n    plt.imshow(img_pred)\n    plt.axis('off')\n    plt.title('Image with Predicted Box')\n","e2b19500":"show_image(\"maksssksksss466\") \nshow_image(\"maksssksksss164\") \nplt.show()","24fe61e0":"%cd ..\/","4160f99e":"!python yolov5\/detect.py --source ..\/input\/facemaskdetectionvideo\/Wear-Mask.mp4 --weight yolov5\/runs\/train\/yolov5s_results\/weights\/best.pt --name video --conf 0.4","6c20a4cd":"## Split Data to Train, Validation, and Test.","c8140afe":"## Train Model","337d97c6":"** This is Notebook Use YOLO V5 to Detect Mask & No Mask Faces:\n\n- Download YOLO Algrithm Files.\n- Anotation Read and Handling.\n- Split Data to Train, Validation, and Test.\n- Configuration Model.\n- Train Model.\n- Evaluation Model","7775d973":"### Mask & No Mask Face Detection ","9e7581fc":"## Download YOLO Algrithm Files.","1b352f42":"## Configuration Model.","cb4fab40":"### End :)","dc492df9":"## Evaluation Model","fcdffa48":"## Anotation Read and Handling.","21a46a19":"<a href=\"yolov5\/runs\/detect\/video\/Wear-Mask.mp4\">Download Test Video<\/a>"}}