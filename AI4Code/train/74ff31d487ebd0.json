{"cell_type":{"4ce123e8":"code","b5169c81":"code","09aa6476":"code","01e64e6a":"code","c3ab7eee":"code","ea87e8de":"code","2eb30147":"code","ed973cd9":"code","cf4cd86d":"code","dfb98dbd":"code","1fda23fa":"code","5019b4c4":"code","717c750b":"code","e4f90594":"code","43e3253e":"code","5dfb27a7":"code","170a1f33":"code","3d76eab5":"code","a1b9d04b":"code","b798b7b5":"code","5ed89dd0":"code","8d2f33ce":"code","0e16ac68":"code","83204143":"code","03f1f8ec":"code","49ce50b6":"code","f2a14b75":"code","a8abc479":"code","920ef7aa":"code","8a9cb093":"code","5e7fdc63":"code","d123162c":"code","58fbd5f3":"code","886cfa3e":"code","c8d853c9":"markdown"},"source":{"4ce123e8":"import glob\nfrom keras.preprocessing import image as kImage\nimport os\nimport numpy as np\nfrom tensorflow import keras\nimport cv2\nfrom matplotlib import pyplot as plt\nfrom IPython.display import Image, display\nfrom tensorflow.keras.preprocessing.image import load_img\nimport PIL\nfrom PIL import ImageOps\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input, Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications import VGG16\nimport tensorflow as tf\nfrom keras import backend as K\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\n\nfrom PIL import Image\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nscaler = MinMaxScaler()","b5169c81":"!pip install patchify","09aa6476":"from patchify import patchify","01e64e6a":"#################################################\nCLASSIFICATION\n################################################","c3ab7eee":"os.makedirs('\/kaggle\/working\/alldataset')\nos.makedirs('\/kaggle\/working\/alldataset\/all_dataset\/')\nos.makedirs('\/kaggle\/working\/alldataset\/all_dataset\/seg_x')","ea87e8de":"path_to_original_images = '\/kaggle\/input\/alldataset\/all_dataset\/x\/'\npath_to_masks = '\/kaggle\/input\/alldataset\/all_dataset\/y\/'\npath_to_segmented_images = '\/kaggle\/working\/alldataset\/all_dataset\/seg_x\/'\n\ndef segment_images(path_img, path_maks, target_path):\n    for filename in os.listdir(path_img):\n        \n        img = cv2.imread(path_img + filename)\n        img = np.array(img)\n\n        mask = cv2.imread(path_maks + filename, cv2.IMREAD_GRAYSCALE)\n        mask = np.array(mask)\n        mask = np.expand_dims(mask, axis=2)\n       \n        N = mask.shape[0] * mask.shape[1] \n        \n        if (mask == 1).sum() \/ N > 0.1:\n            img_seg_1 = img.copy()\n            img_seg_1[(mask != 1).all(axis = 2)] = [255,255,255]\n            cv2.imwrite(target_path + \"1\" + '_' + filename, img_seg_1 )\n          \n        if (mask == 2).sum() \/ N > 0.1:\n            img_seg_2 = img.copy()\n            img_seg_2[(mask != 2).all(axis = 2)] =  [255,255,255]\n            cv2.imwrite(target_path + \"2\" + '_' + filename, img_seg_2 )\n            \n        if (mask == 3).sum() \/ N > 0.1:\n            img_seg_3 = img.copy()\n            img_seg_3[(mask != 3).all(axis = 2)] = [255,255,255]\n            cv2.imwrite(target_path + \"3\" + '_' + filename, img_seg_3 )\n            \n            \n\nsegment_images(path_to_original_images, path_to_masks, path_to_segmented_images)","2eb30147":"\nimport matplotlib.pyplot as plt\nimport random\nfrom matplotlib import cm\nplt.rcParams['figure.figsize'] = (12.0, 12.0)\n\n\nplt.figure(figsize=(18, 18))\nplt.subplot(151)\nplt.imshow(cv2.imread('\/kaggle\/input\/alldataset\/all_dataset\/x\/' + 'TCGA-EW-A1PB-DX1_xmin57214_ymin25940_MPP-0.2500.png' ))\nplt.title('original image')\nplt.subplot(152)\nplt.imshow(cv2.imread('\/kaggle\/working\/alldataset\/all_dataset\/seg_x\/' + '1_' + 'TCGA-EW-A1PB-DX1_xmin57214_ymin25940_MPP-0.2500.png' ))\nplt.title('segmented class 1 image ')\nplt.subplot(153)\nplt.imshow(cv2.imread('\/kaggle\/working\/alldataset\/all_dataset\/seg_x\/' + '2_' + 'TCGA-EW-A1PB-DX1_xmin57214_ymin25940_MPP-0.2500.png' ))\nplt.title('segmented class 2 image ')\nplt.subplot(154)\nplt.imshow(cv2.imread('\/kaggle\/working\/alldataset\/all_dataset\/seg_x\/' + '3_' + 'TCGA-EW-A1PB-DX1_xmin57214_ymin25940_MPP-0.2500.png' ))\nplt.title('segmented class 3 image ')\nplt.subplot(155)\nplt.imshow(cv2.imread('\/kaggle\/input\/alldataset\/all_dataset\/y\/' + 'TCGA-EW-A1PB-DX1_xmin57214_ymin25940_MPP-0.2500.png', cv2.IMREAD_GRAYSCALE ))\nplt.title('original mask')\nplt.show()","ed973cd9":"base_size = 224\nmultiplier = 4\nclasses= 3\ntarget_path='\/kaggle\/working\/alldataset\/all_dataset\/patches_classifier\/'\n\npatch_size = base_size * multiplier\n\ndef preprocess(dataset_dir, mask_dir):\n    \n    X_list= sorted(glob.glob(os.path.join(dataset_dir, 'seg_x','*.png')))\n    Y_list = sorted(glob.glob(os.path.join(mask_dir, 'y' ,'*.png')))\n    \n    X= []\n    Y= []\n    \n    for f in range(len(Y_list)):\n        \n        for seg in range (3):\n            \n            # Load input image\n            id_class = seg + 1\n            \n            if(os.path.isfile(dataset_dir + 'seg_x\/' + str(id_class) + '_' + os.path.basename(Y_list[f]))):\n                \n                x = cv2.imread(dataset_dir + 'seg_x\/' + str(id_class) + '_' + os.path.basename(Y_list[f])) \n                \n                new_h = (x.shape[1]\/\/patch_size)*patch_size #Nearest size divisible by base_size\n                new_w = (x.shape[0]\/\/patch_size)*patch_size \n                x = Image.fromarray(x)\n                x = x.crop((0 ,0, new_h, new_w))\n                x = np.array(x)  \n\n                patches_img = patchify(x, (patch_size, patch_size, 3), step=patch_size)  #No overlapping\n                min_multi = new_h \/ patch_size\n                if new_w \/ patch_size < min_multi:\n                    min_multi = new_w \/ patch_size\n                n_patch = 0\n                for i in range(patches_img.shape[0]):\n                    for j in range(patches_img.shape[1]):\n                        single_patch_img = patches_img[i,j,:,:]\n                        single_patch_img = single_patch_img[0] \n\n                        if( i <= min_multi-1 and j <= min_multi-1):\n                            n_patch = n_patch +1\n                            single_patch_img = single_patch_img[::-1]\n                            \n                            N = single_patch_img.shape[0] * single_patch_img.shape[1] \n                            white_pixels = (single_patch_img == [255,255,255]).sum()\n                            if white_pixels \/ N > 0.9:\n                                single_patch_img = cv2.resize(single_patch_img, (base_size, base_size))\n                                single_patch_img = scaler.fit_transform(single_patch_img.reshape(-1, single_patch_img.shape[-1])).reshape(single_patch_img.shape)\n                                X.append(single_patch_img)   \n                                Y.append([seg])\n                \n\n                \n                    \n    X = np.asarray(X)\n    Y = np.asarray(Y)\n    return X, Y","cf4cd86d":"X, Y = preprocess('\/kaggle\/working\/alldataset\/all_dataset\/','\/kaggle\/input\/alldataset\/all_dataset')","dfb98dbd":"\nprint(X.shape)\nprint(Y.shape)","1fda23fa":"import matplotlib.pyplot as plt\nimport random\nfrom matplotlib import cm\nplt.rcParams['figure.figsize'] = (8.0, 6.0)\n\nidx = random.randint(0, len(X)-1)\n#idx=9\nplt.figure(figsize=(12, 6))\nplt.subplot(121)\nplt.imshow(np.reshape(X[idx], (base_size, base_size, 3)))\nplt.show()\n\n\n\nprint(Y[idx])","5019b4c4":"X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1, stratify=Y)\n","717c750b":"del X, Y","e4f90594":"import gc\ngc.collect()","43e3253e":"\n\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1, stratify=y_train)\n\nprint(X_train.shape, y_train.shape)\nprint(X_val.shape, y_val.shape)\nprint(X_test.shape, y_test.shape)","5dfb27a7":"def pixels_per_class(y):\n    shp = y.shape\n    print(shp)\n    print(\"Pixels values: \", np.unique(y))\n\n    N = shp[0] * shp[1] \n    print('Number of pixel in dataset',N)\n\n\n    for i in range(classes):\n        Nc = (y == i ).sum()\n        print('num pixels with value {}', i , Nc)\n\n        \npixels_per_class(y_train)\npixels_per_class(y_val)\npixels_per_class(y_test)","170a1f33":"from sklearn.preprocessing import LabelBinarizer\n\nclasses = 3\n\nencoder = LabelBinarizer()\nencoder.fit(y_train)\ny_train = encoder.transform(y_train)\ny_val = encoder.transform(y_val)","3d76eab5":"datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True)","a1b9d04b":"print(\"Pixels values: \", np.unique(y_train))\nprint(\"Pixels values: \", np.unique(y_val))\nprint(\"Pixels values: \", np.unique(y_test))\nprint(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)\nprint(X_val.shape, y_val.shape)","b798b7b5":"from keras.applications.vgg16 import VGG16\nfrom keras.preprocessing import image\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.layers import Input, Flatten, Dense\nfrom keras.models import Model\nimport numpy as np\n\n#Get back the convolutional part of a VGG network trained on ImageNet\npretrainedVgg16 = VGG16(weights='imagenet', input_shape=(224,224,3))\npretrainedVgg16.summary()","5ed89dd0":"classes = 3\nfor layer in pretrainedVgg16.layers:\n    layer.trainable = False\n    \n\n#Add a layer where input is the output of the  second last layer \nx = Dense(128, activation='relu', name='my_fc1')(pretrainedVgg16.layers[-4].output)\nx = Dense(128, activation='relu', name='my_fc2')(x)\nx = Dense(classes, activation='softmax', name='my_predictions')(x)\n\n#Then create the corresponding model \nmy_model = Model(pretrainedVgg16.input, x)\nmy_model.summary()","8d2f33ce":"gc.collect()","0e16ac68":"from sklearn.utils import class_weight\ny_train_argmax = np.argmax(y_train, axis =1)\nclass_weight = class_weight.compute_class_weight('balanced' ,np.unique(y_train_argmax) ,y_train_argmax)\n\nclass_weight = {i : class_weight[i] for i in range(3)}\n\nprint(class_weight)","83204143":"del y_train_argmax","03f1f8ec":"from keras import optimizers\n\nbatch_size = 32\n\nmy_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel_checkpoint = ModelCheckpoint('best_multi_clasi_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n\n\nmy_model_hist = my_model.fit(datagen.flow(X_train, y_train, batch_size=batch_size),\n                  validation_data=(X_val, y_val),\n                  steps_per_epoch=len(X_train) \/\/ batch_size,\n                  epochs=50,verbose=2,\n                  class_weight=class_weight,\n                  callbacks=[model_checkpoint])","49ce50b6":"my_model.save('last_epoch_multi_model.h5')","f2a14b75":"gc.collect()","a8abc479":"pred = my_model.predict(X_test, verbose=1, batch_size=16)","920ef7aa":"import random\nidx = random.randint(0, len(X_test)-1)\n\n\npred_argmax = np.argmax(pred,axis=1)\n\nprint('real labels', y_test[idx])\nprint('predicted labels', pred_argmax[idx])\n\n","8a9cb093":"y_test_cat = encoder.transform(y_test)\n_, acc = my_model.evaluate(X_test, y_test_cat)\nprint(\"Accuracy = \", (acc * 100.0), \"%\")","5e7fdc63":"print('predicted values', np.unique(pred_argmax))","d123162c":"loss = my_model_hist.history['loss']\nval_loss = my_model_hist.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss, 'y', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\n\nacc = my_model_hist.history['accuracy']\nval_acc = my_model_hist.history['val_accuracy']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'y', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('acuracy')\nplt.legend()\nplt.show()","58fbd5f3":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\ncm = confusion_matrix(y_test, pred_argmax, labels=[0,1,2])\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['tumor','stroma','inflammatory infiltration'])\ndisp.plot()\n\nplt.show()","886cfa3e":"from sklearn.metrics import classification_report\nclassification_report(\n    y_test,\n    pred_argmax,\n    output_dict=False,\n    target_names=['tumor', 'stroma', 'inflammatory infiltration']\n)","c8d853c9":"\n                                     precision    recall  f1-score   support\n       tumor                         0.76      0.92      0.83       312\n       stroma                        0.93      0.81      0.87       297\n       inflammatory infiltration     0.82      0.58      0.68        93\n       \n       accuracy                                          0.83       702\n       macro avg                     0.84      0.77      0.79       702\n       weighted avg                  0.84      0.83      0.83       702\n       "}}