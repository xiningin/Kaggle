{"cell_type":{"977d4fee":"code","7843ddee":"code","04295946":"code","d80f65df":"code","20264554":"code","d567d2d6":"code","8a5babaf":"code","4fbbad67":"code","c76b0782":"code","2df31dd7":"code","4d9fa3ae":"markdown","e51c5f6b":"markdown","60deeaa3":"markdown","d4746e62":"markdown","bb095690":"markdown","67676bab":"markdown","67c6114f":"markdown","17498ca5":"markdown","2f696432":"markdown"},"source":{"977d4fee":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn import metrics\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix","7843ddee":"dataset = pd.read_csv(\"\/kaggle\/input\/shill-bidding-dataset\/Shill Bidding Dataset.csv\", delimiter=\",\")","04295946":"X = dataset[['Bidder_Tendency', 'Bidding_Ratio', 'Successive_Outbidding', 'Last_Bidding', 'Auction_Bids', 'Starting_Price_Average', 'Early_Bidding', 'Winning_Ratio', 'Auction_Duration']].values\ny = dataset['Class']","d80f65df":"X_trainset, X_testset, y_trainset, y_testset = train_test_split(X, y, test_size=0.3, random_state=3)","20264554":"def SBDecisionTreeClassifier(heuristic=\"gini\", tree_depth = None):\n    decision_tree_clfr = DecisionTreeClassifier(criterion = heuristic, max_depth = tree_depth)\n    decision_tree_clfr.fit(X_trainset, y_trainset)\n    return decision_tree_clfr\n\ndecision_tree = SBDecisionTreeClassifier()","d567d2d6":"predTree = decision_tree.predict(X_testset)","8a5babaf":"def evaluate_model(decision_tree, predTree):\n    print(\"Decision Trees's Accuracy: \", metrics.accuracy_score(y_testset, predTree))\n    print(\"Depth of Decision Tree: \", decision_tree.tree_.max_depth)\n    \nevaluate_model(decision_tree, predTree)","4fbbad67":"print(\"USING GINI\")\nheuristic = \"gini\"\ndecision_tree_gini = SBDecisionTreeClassifier(heuristic)\npredTree_gini = decision_tree_gini.predict(X_testset)\nevaluate_model(decision_tree_gini, predTree_gini)\n\nprint(\"USING ENTROPY\")\nheuristic = \"entropy\"\ndecision_tree_entropy = SBDecisionTreeClassifier(heuristic)\npredTree_entropy = decision_tree_entropy.predict(X_testset)\nevaluate_model(decision_tree_entropy, predTree_entropy)","c76b0782":"!conda install -c conda-forge pydotplus -y\n!conda install -c conda-forge python-graphviz -y","2df31dd7":"import matplotlib.pyplot as plt\nfrom six import StringIO\nimport pydotplus\nimport matplotlib.image as mpimg\nfrom sklearn import tree\nimport numpy as np\n\nfileName_g = \"decision-tree.png\"\ndot_data = StringIO()\nfeatureNames = dataset.columns[3:12]\nlabedNames = dataset[\"Class\"].unique().tolist()\n    \n# export_graphviz will convert decision tree classifier into dot file\ntree.export_graphviz(decision_tree_gini,feature_names = featureNames, out_file = dot_data, class_names = str(np.unique(y_trainset)), filled = True,  special_characters = True, rotate = False) \n    \n# Convert dot file int pgn using pydotplus\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n    \n#write pgn into file\ngraph.write_png(fileName_g)\n\n#display tree image\nimg_g = mpimg.imread(fileName_g)\nplt.figure(figsize=(100, 200))\nplt.imshow(img_g, interpolation='nearest')","4d9fa3ae":"## Evaluating Model","e51c5f6b":"## Visualization","60deeaa3":"## Splitting Data","d4746e62":"## Loading Data","bb095690":"## Testing The Model","67676bab":"Let us now evaluate the different heuristic options.","67c6114f":"# Decision Trees\n\nDecision Trees (DTs) are machine learning algorithms that recursively divide the dataset into smaller groups based on a given feature until all the samples are classified.\n\nAt each step in recursion, the DT tries to pick the next best feature to split the dataset. It does this by evaluating the *splitting criterion*. This notebook will investigate the **Gini Impurity** and **Entropy (Information Gain)** splitting criterion.\n\n# Approach\n\n1. Loading Data\n2. Feature Selection\n3. Splitting Data\n4. Building and Training a DT Model\n5. Testing the Model\n6. Evaluating Model\n7. Visualizing the DT\n\nMost of the steps above can be done simply by calling a function.\n\n# Dataset\n\n## What is Shill Bidding?\n\nShill bidding is when a seller uses a fraudulent account, to bid on their auction to artificially raise the price of the auction. Here we work with the Shill Bidding Dataset to learn a decision tree that classifies auctioners into normal or suspicious behavior.\n\n![about-dataset](https:\/\/github.com\/gsethi2409\/first-order-model\/blob\/master\/Screenshot%20from%202021-01-03%2009-48-18.png?raw=true)\n\n## Features\n\n* Record ID\n* Auction ID\n* Bidder ID\n* Bidder Tendency\n* Bidding Ratio\n* Successive Outbidding\n* Last Bidding\n* Auction Bids\n* Auction Starting Price\n* Early Bidding\n* Winning Ratio\n* Auction Duration\n\nFor classification, we use all features except the first three IDs.\n\nWe will use the following libraries.\n* scikit-learn\n* numpy\n* pandas\n* matplotlib","17498ca5":"## Building and Training a DT Model","2f696432":"## Feature Selection"}}