{"cell_type":{"0fa25663":"code","dc86b152":"code","fc2b1771":"code","4655aad0":"code","696c995e":"code","9b728260":"code","cbd67c73":"code","58716285":"code","e7c9531b":"code","0761895c":"code","fa2ef4aa":"code","9ba0c6cf":"code","77a9cc20":"code","011c5c3b":"code","a415a092":"markdown","19f58acd":"markdown","aa412d90":"markdown","f1931743":"markdown","c33f0cf3":"markdown","14977fe6":"markdown","f2dcbce1":"markdown","043ae506":"markdown","fecd54e9":"markdown","eee1ba4c":"markdown","61f0a448":"markdown"},"source":{"0fa25663":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dc86b152":"import numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","fc2b1771":"from sklearn.datasets import load_boston\nboston = load_boston()","4655aad0":"! pip install optuna","696c995e":"import optuna","9b728260":"from sklearn.model_selection import KFold\nkf = KFold(n_splits=5, random_state=12345678, shuffle=True)","cbd67c73":"from sklearn.svm import SVR\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import Ridge\n\nfrom sklearn.model_selection import cross_validate\n#\ndef evaluate(clf):\n    #\n    scores = cross_validate(clf, X_train, y_train ,cv=kf, scoring='neg_mean_squared_error')\n    #\n    # Optuna\u3067\u306f\u30b9\u30b3\u30a2\u306f\u6700\u5c0f\u5316\n    # neg_mean_squared_error\u306e\u5834\u5408\u306f\u30de\u30a4\u30ca\u30b9\u3067\u6700\u5c0f\u5316\n    return -1*np.mean( scores['test_score'] )\n\ndef objective_lasso(trial):\n    # alpha\n    alpha   = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n    clf = Lasso(alpha=alpha)\n    #\n    return evaluate(clf)\n\ndef objective_ridge(trial):\n    # alpha\n    alpha   = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n    clf = Ridge(alpha=alpha)\n    #\n    return evaluate(clf)\n\ndef objective_svr(trial):\n    # C\n    svr_c   = trial.suggest_loguniform('svr_c', 1e0, 1e2)\n    # epsilon\n    epsilon = trial.suggest_loguniform('epsilon', 1e-1, 1e1)\n    # SVR\n    clf = SVR(C=svr_c, epsilon=epsilon)\n    #\n    return evaluate(clf)","58716285":"import sklearn.metrics\nsklearn.metrics.SCORERS.keys()","e7c9531b":"y = boston.target\nX = boston.data\n#\nsns.displot(y)\nplt.show()","0761895c":"from sklearn.preprocessing import StandardScaler, PowerTransformer\n#\nX_train, y_train = X, y\n#\n# \u6a19\u6e96\u5316\n#scaler_x = StandardScaler()\nscaler_x = PowerTransformer()\nX_train = scaler_x.fit_transform(X_train)\n#\nscaler_y = PowerTransformer()\ny_train  = scaler_y.fit_transform(y_train.reshape(-1,1)).flatten() \n#\nsns.displot( y_train )\nplt.show()","fa2ef4aa":"studys    = []\nmodelname = ['Lasso','Ridge','SVR']\nmodels    = [objective_lasso,objective_ridge,objective_svr,]\nn_trials  = [100,100,300]\n#\nfor i, model in enumerate(models):  \n    #\n    # optuna\n    study = optuna.create_study()\n    #\n    study.optimize(model, n_trials=n_trials[i])\n    #\n    studys.append(study)","9ba0c6cf":"# \u6700\u9069\u89e3\nfor i, study in enumerate(studys):\n    print(modelname[i])\n    print(study.best_params)\n    print(study.best_value)\n    print(study.best_trial)","77a9cc20":"for i, study in enumerate(studys):\n    print(modelname[i], study.best_value)","011c5c3b":"from sklearn.metrics import r2_score\n#\nclfs = [ Lasso(alpha=studys[0].best_params['alpha']),\n         Ridge(alpha=studys[1].best_params['alpha']),\n         SVR(C=studys[2].best_params['svr_c'], epsilon=studys[2].best_params['epsilon']) ]\n#\nfor i, clf in enumerate(clfs):\n    #\n    print(modelname[i])\n    plt.figure(figsize=(4, 4))\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_train)\n    # ypred\u306e\u5024\u3092\u3082\u3068\u306b\u623b\u3059\n    y_pred = scaler_y.inverse_transform(y_pred.reshape(-1,1)).flatten()\n    #\n    min = np.min( np.array( np.min(y), np.min(y_pred) ) )\n    max = np.max( np.array( np.max(y), np.max(y_pred) ) )\n    #\n    plt.plot(y,y_pred,'o')\n    plt.plot( [0.9*min,1.1*max],[0.9*min,1.1*max], 'k-' )\n    plt.xlabel('Actual')\n    plt.ylabel('Estimated')\n    print(r2_score(y,y_pred))\n    #\n    plt.show()","a415a092":"cross_validate\u306escoring\u306e\u4e00\u89a7\u3092\u78ba\u8a8d\u3067\u304d\u307e\u3059\u3002","19f58acd":"Optuna\u306e\u7d50\u679c\u306e\u3046\u3061\u3001\u30b9\u30b3\u30a2\u306e\u307f\u3092\u78ba\u8a8d","aa412d90":"\u4ea4\u5dee\u691c\u8a3c\u3092\u5b9f\u65bd\u3002shuffle\u3092True\u306b\u3057\u306a\u3044\u3068\u504f\u308a\u306e\u3042\u308b\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u304c\u884c\u308f\u308c\u307e\u3059\u3002StratifiledKFold\u3082\u9078\u629e\u80a2\u3068\u3057\u3066\u3042\u308a\u3002\n\nhttps:\/\/blog.amedama.jp\/entry\/2018\/06\/21\/235951\n\nhttps:\/\/qiita.com\/tomov3\/items\/039d4271ed30490edf7b","f1931743":"\u30dc\u30b9\u30c8\u30f3\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u8aad\u307f\u8fbc\u307f\u307e\u3059","c33f0cf3":"\u30dc\u30b9\u30c8\u30f3\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u78ba\u8a8d\u3002y\u306e\u5206\u5e03\u3092\u78ba\u8a8d\u3057\u307e\u3059\u3002","14977fe6":"\u6700\u9069\u5316\u3059\u308b\u30e2\u30c7\u30eb\u3092\u8a2d\u5b9a\u3057\u307e\u3059\u3002SVR,Lasso,Ridge\u3067\u30c8\u30e9\u30a4\u3057\u3066\u3044\u307e\u3059\u3002Optuna\u306e\u6a19\u6e96\u7684\u306a\u4f7f\u7528\u65b9\u6cd5\u306b\u6e96\u62e0\u3002cross_validate\u3067\u306fmse\u3067\u8a55\u4fa1\u3057\u307e\u3059\u3002\n\nhttps:\/\/www.haya-programming.com\/entry\/2018\/03\/31\/184557\n\nhttps:\/\/qiita.com\/Mukomiz\/items\/fcdf1f6c2bc1e89bbc8b","f2dcbce1":"\u6700\u9069\u5316\u306e\u7d50\u679c\u3092\u30b0\u30e9\u30d5\u3067\u8868\u793a\u3057\u307e\u3059\u3002\u5168\u30c7\u30fc\u30bf\u306ex-y\u30d7\u30ed\u30c3\u30c8\u3068\u3001r2\u5024\u306b\u3088\u308b\u30b9\u30b3\u30a2\u3092\u8868\u793a\u3002","043ae506":"Optuna\u306e\u7d50\u679c\u3092\u78ba\u8a8d\u3057\u307e\u3059\u3002","fecd54e9":"optuna\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\n\nOptuna\u306b\u3064\u3044\u3066\u306e\u8a18\u4e8b\u306f\u4ee5\u4e0b\u3002\n\nhttps:\/\/optuna.readthedocs.io\/en\/stable\/index.html\n\nhttps:\/\/qiita.com\/studio_haneya\/items\/2dc3ba9d7cafa36ddffa\n\nhttps:\/\/qiita.com\/koshian2\/items\/1c0f781d244a6046b83e\n\nhttps:\/\/qiita.com\/hideki\/items\/c09242639fd74abe73a0\n\nhttps:\/\/www.inoue-kobo.com\/ai_ml\/xgboost-with-optuna\/index.html\n\nhttps:\/\/qiita.com\/DS27\/items\/ec6a747977e57bb1837e\n\nhttps:\/\/kiseno-log.com\/2019\/11\/17\/optunasklearn%E3%82%92%E7%94%A8%E3%81%84%E3%81%9Fk%E5%88%86%E5%89%B2%E4%BA%A4%E5%B7%AE%E6%A4%9C%E8%A8%BC%E3%81%A7%E3%80%81lightgbm%E3%81%AE%E3%83%8F%E3%82%A4%E3%83%91%E3%83%BC%E3%83%91%E3%83%A9\/","eee1ba4c":"\u5404\u30e2\u30c7\u30eb\u3067Optuna\u306e\u6700\u9069\u5316\u3092\u884c\u3044\u307e\u3059\u3002\u6700\u9069\u5316\u6642\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u30b9\u30bf\u30c7\u30a3\u306e\u56de\u6570\u3092n_trial\u3067\u8a2d\u5b9a\u3057\u307e\u3059\u3002","61f0a448":"\u30c7\u30fc\u30bf\u3092\u6a19\u6e96\u5316\u3067\u304d\u308b\u3088\u3046\u306b\u3057\u307e\u3059\u3002\u4eca\u56de\u306fPowerTransformer\u3092\u9078\u629e\u3002\n\nhttps:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.PowerTransformer.html"}}