{"cell_type":{"8b29d6c1":"code","a5203365":"code","2961943e":"code","612284fb":"code","5366730e":"code","41777f72":"code","73972647":"code","e4977ae9":"code","3e311245":"code","069341d9":"code","aae7972b":"code","99e8f02b":"code","65d42138":"code","5d4ff44c":"code","5010f2c0":"code","f86b0525":"code","9475ecbe":"code","12c8006e":"code","eb348482":"code","3d6a8319":"code","9cc58bfe":"code","c46e891b":"code","ce1b2c0f":"code","3cb9361f":"code","0d9c1048":"code","78d605a8":"code","4f464812":"code","4d057b0c":"code","9b501178":"markdown","34a76385":"markdown","067a4884":"markdown","278cf241":"markdown","daf26f0c":"markdown","39e21f70":"markdown","a7c23482":"markdown","1240c7d7":"markdown","18659d91":"markdown","ca6fb15b":"markdown","7e9de49e":"markdown","88eb879e":"markdown","0e49c6e5":"markdown","a69d0e60":"markdown","9272610f":"markdown","352515e8":"markdown","d2a48fa4":"markdown","d93adb5d":"markdown","223f5298":"markdown","74d10476":"markdown"},"source":{"8b29d6c1":"import pandas as pd\nimport math\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.mlab as mlab\nimport seaborn as sn\nfrom pandas.plotting import scatter_matrix\nimport plotly.offline as py\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport plotly.figure_factory as ff\n%matplotlib inline\n## denote the working directory","a5203365":"def in_range (lowerlimit, upperlimit, value):\n    return lowerlimit <= value <= upperlimit\n\ndef calculate_scores(h1max,h1min,d1max,d1min,value_ranges):\n    max_score=0\n    min_score=0\n    hd_value=pd.Series([h1max,h1min,d1max,d1min]).dropna()\n    if hd_value.empty:\n        return np.nan\n    else:\n        max_value=max(hd_value)\n        min_value=min(hd_value)\n        for value_range in value_ranges:\n            if in_range(value_range[0], value_range[1], max_value):\n                max_score=int(value_range[2])\n                break\n        for value_range in value_ranges: \n            if in_range(value_range[0],value_range[1], min_value):\n                min_score=int(value_range[2])\n                break\n        if max_score>=min_score:\n            return max_score\n        else:\n            return min_score \n\ndef calculate_value(h1max,h1min,d1max,d1min,value_ranges):\n    max_score=0\n    min_score=0\n    hd_value=pd.Series([h1max,h1min,d1max,d1min]).dropna()\n    if hd_value.empty:\n        return np.nan\n    else:\n        max_value=max(hd_value)\n        min_value=min(hd_value)\n        for value_range in value_ranges:\n            if in_range(value_range[0], value_range[1], max_value):\n                max_score=int(value_range[2])\n                break\n        for value_range in value_ranges: \n            if in_range(value_range[0],value_range[1], min_value):\n                min_score=int(value_range[2])\n                break\n        if max_score>=min_score:\n            return max_value\n        else:\n            return min_value \n\napache_range={'temp':([41,50,4],[39,40.9,3],[38.5,38.9,1],[36,38.4,0],[34,35.9,1],[32,33.9,2],[30,31.9,3],[19,29.9,4]),\n             'heartrate':([180,300,4],[140,179,3],[110,139,2],[70,109,0],[55,69,2],[40,54,3],[0,39,4]),\n             'sodium':([180,300,4],[160,179,3],[155,159,2],[150,154,1],[130,149,0],[120,129,2],[111,119,3],[50,110,4]),\n             'potassium':([7,9,4],[6,6.9,3],[5.5,5.9,1],[3.5,5.4,0],[3,3.4,1],[2.5,2.9,2],[2.5,2,4]),\n             'creatinine':([3.5,30,4],[2,3.4,3],[1.5,1.9,2],[0.6,1.4,0],[0,0.6,2]),\n             'hematocrit':([60,100,4],[50,59.9,2],[46,49.9,1],[30,45.9,0],[20,29.9,2],[0,20,4]),\n             'wbc':([40,100,4],[20,39.9,2],[15,19.9,1],[3,14.9,0],[1,2.9,2],[0,1,4]),\n             'ph':([7.7,9.0,4],[7.6,7.69,3],[7.5,7.59,1],[7.33,7.49,0],[7.25,7.32,2],[7.15,7.24,3],[5,7.15,4]),\n             'resprate':([50,100,4],[35,49,3],[25,34,2],[12,24,0],[10,11,1],[6,9,2],[0,5,4])}","2961943e":"df=pd.read_csv('\/kaggle\/input\/widsdatathon2020\/training_v2.csv')\nTest_df=pd.read_csv('\/kaggle\/input\/widsdatathon2020\/unlabeled.csv')\nAll_df=df.append(Test_df)\nAll_y=All_df['hospital_death']#get y","612284fb":"import plotly.express as px\nfig = px.histogram(df[['age','gender','hospital_death','bmi']].dropna(), x=\"age\", y=\"hospital_death\", color=\"gender\",\n                   marginal=\"box\", # or violin, rug\n                   hover_data=df[['age','gender','hospital_death','bmi']].columns)\nfig.show()","5366730e":"age_death_F=df[df['gender']=='F'][['age','hospital_death']].groupby('age').mean().reset_index()\nage_death_M=df[df['gender']=='M'][['age','hospital_death']].groupby('age').mean().reset_index()\nfrom plotly.subplots import make_subplots\nfig = make_subplots()\nfig.add_trace(\n    go.Scatter(x=age_death_F['age'], y=age_death_F['hospital_death'], name=\"Female patients\"))\nfig.add_trace(\n    go.Scatter(x=age_death_M['age'], y=age_death_M['hospital_death'],name=\"Male patients\"))\nfig.update_layout(\n    title_text=\"<b>Average hospital death probability of patients<b>\")\nfig.update_xaxes(title_text=\"<b>patient age<b>\")\nfig.update_yaxes(title_text=\"<b>Average Hospital Death<\/b>\", secondary_y=False)\nfig.show()","41777f72":"weight_df=df[['weight','hospital_death','bmi']]\nweight_df['weight']=weight_df['weight'].round(0)\nweight_df['bmi']=weight_df['bmi'].round(0)\nweight_death=weight_df[['weight','hospital_death']].groupby('weight').mean().reset_index()\nbmi_death=weight_df[['bmi','hospital_death']].groupby('bmi').mean().reset_index()\nfig = make_subplots(rows=1, cols=2, shared_yaxes=True)\nfig.add_trace(\n    go.Scatter(x=weight_death['weight'], y=weight_death['hospital_death'], name=\"Weight\"),\n   row=1, col=1\n)\nfig.add_trace(\n    go.Scatter(x=bmi_death['bmi'], y=bmi_death['hospital_death'], name=\"BMI\"),\n    row=1, col=2\n)\nfig.update_layout(\n    title_text=\"<b>impacts of BMI and weight over patients<b>\"\n)\nfig.update_yaxes(title_text=\"<b>Average Hospital Death\")\nfig.show()","73972647":"ICU_type=df[['icu_type','age','hospital_death']]\nICU_type['icu_type']=ICU_type['icu_type'].replace({'CTICU':'CCU-CTICU',\n                                              'Cardiac ICU':'CCT-CTICU',\n                                              'CTICU':'CCT-CTICU',\n                                              'CSICU':'SICU'})\n#ICU_type['pre_icu_los_days']=ICU_type['pre_icu_los_days'].round(0)\nICU_df=ICU_type.groupby(['icu_type','age']).mean().reset_index()\nICU_df['count']=ICU_type.groupby(['icu_type','age']).count().reset_index()['hospital_death']\n\nfig = px.scatter(ICU_df, x=\"age\", y=\"hospital_death\", size=\"count\", color=\"icu_type\",\n           hover_name=\"icu_type\", log_x=False, size_max=60,)\nfig.update_layout(\n    title_text=\"<b>Survival rate at different types of ICU<b>\"\n)\nfig.update_yaxes(title_text=\"<b>Average Hospital Death<b>\")\nfig.update_xaxes(title_text=\"<b>Age<b>\")\nfig.show()","e4977ae9":"ICU_day=df[df['pre_icu_los_days']>=0][['icu_type','pre_icu_los_days','hospital_death']]\nICU_day['icu_type']=ICU_type['icu_type'].replace({'CTICU':'CCU-CTICU',\n                                              'Cardiac ICU':'CCT-CTICU',\n                                              'CTICU':'CCT-CTICU',\n                                              'CSICU':'SICU'})\nICU_day['pre_icu_los_days']=ICU_day['pre_icu_los_days'].round(0)\nICU_df=ICU_day.groupby(['icu_type','pre_icu_los_days']).mean().reset_index()\nICU_df['count']=ICU_day.groupby(['icu_type','pre_icu_los_days']).sum().reset_index()['hospital_death']\n\nfig = px.scatter(ICU_df, x=\"pre_icu_los_days\", y=\"hospital_death\", size=\"count\", color=\"icu_type\",\n           hover_name=\"icu_type\", log_x=True, size_max=200,)\nfig.update_layout(\n    title_text=\"<b>Survival rate at different length of stay before ICU admission<b>\"\n)\nfig.update_yaxes(title_text=\"<b>Average Hospital Death<b>\")\nfig.update_xaxes(title_text=\"<b>The length of stay of the patient between hospital admission and unit admission <b>\")\nfig.show()","3e311245":"apache3=df[['age','apache_3j_bodysystem','hospital_death']]\napache3=apache3.groupby(['apache_3j_bodysystem','age']).agg(['size','mean']).reset_index()\n\napache3['size']=apache3['hospital_death']['size']\napache3['mean']=apache3['hospital_death']['mean']\n\napache3.drop('hospital_death',axis=1,inplace=True)\n\nsystems =list(apache3['apache_3j_bodysystem'].unique())\ndata = []\nlist_updatemenus = []\nfor n, s in enumerate(systems):\n    visible = [False] * len(systems)\n    visible[n] = True\n    temp_dict = dict(label = str(s),\n                 method = 'update',\n                 args = [{'visible': visible},\n                         {'title': '<b>'+s+'<b>'}])\n    list_updatemenus.append(temp_dict)\n    \n\nfor s in systems:\n    mask = (apache3['apache_3j_bodysystem'].values == s) \n    trace = (dict(visible = False,     \n        x = apache3.loc[mask, 'age'],\n        y = apache3.loc[mask, 'mean'],\n        mode = 'markers',\n        marker = {'size':apache3.loc[mask, 'size']\/apache3.loc[mask,'size'].sum()*1000,\n                 'color':apache3.loc[mask, 'mean'],\n                 'showscale': True})\n                   )\n    data.append(trace)\n\ndata[0]['visible'] = True    \n    \nlayout = dict(updatemenus=list([dict(buttons= list_updatemenus)]),\n              xaxis=dict(title = '<b>Age<b>', range=[min(apache3.loc[:, 'age'])-10, max(apache3.loc[:, 'age']) + 10]),\n              yaxis=dict(title = '<b>Average Hospital Death<b>', range=[min(apache3.loc[:, 'mean'])-0.1, max(apache3.loc[:, 'mean'])+0.1]),\n              title='<b>Survival Rate<b>' )\nfig = dict(data=data, layout=layout)\npy.iplot(fig, filename='update_dropdown')","069341d9":"All_df['icu_type']=All_df['icu_type'].replace({'CTICU':'CCU-CTICU',\n                                              'Cardiac ICU':'CCT-CTICU',\n                                              'CTICU':'CCT-CTICU',\n                                              'CSICU':'SICU'})\n\nAll_df['hospital_admit_source']=All_df['hospital_admit_source'].replace({\n                                        'Other ICU':\"ICU\",'ICU to SDU':\"SDU\",\n                                       'Step-Down Unit (SDU)':\"SDU\",\n                                      'Acute Care\/Floor':\"Floor\",\n                                      'Other Hospital':\"Other\"})\n\nAll_df.drop(['encounter_id','patient_id','readmission_status','hospital_death','hospital_id','icu_id','apache_2_bodysystem','apache_3j_bodysystem'],axis=1,inplace=True)\n\nAll_df['bmi']=All_df['weight']*10000\/(All_df['height']*All_df['height'])\nAll_df.loc[All_df['bmi']>df['bmi'].max(),'bmi']=df['bmi'].max()\nAll_df.loc[All_df['bmi']<df['bmi'].min(),'bmi']=df['bmi'].min()\n\nbinary=[col for col in All_df.columns if All_df[col].nunique() == 2 and All_df[col].dtypes !='object']\ncategorical = [col for col in All_df.columns if All_df[col].dtypes == 'object']\nAll_df['apache_3j_diagnosis']=All_df['apache_3j_diagnosis'].fillna(0).astype(np.int16)\nAll_df['apache_2_diagnosis']=All_df['apache_2_diagnosis'].fillna(0).astype(np.int16)\ncategorical.append('apache_2_diagnosis')\ncategorical.append('apache_3j_diagnosis')\n\n#Binary:we will labelencode Missing as 0, No as 1, Yes as 2 \nfor col in binary:\n    All_df[col]=All_df[col]+1\n    All_df[col].fillna(0,inplace=True)\n    All_df[col]=All_df[col].astype(np.int8).astype('category')\n\n#STR type Categorical:label encode category\nfrom sklearn import preprocessing\nfor col in categorical:\n    All_df[col] = All_df[col].astype('str')  \n    le = preprocessing.LabelEncoder().fit(\n            np.unique(All_df[col].unique().tolist()))\n    All_df[col] = le.transform(All_df[col])+1\n    All_df[col] = All_df[col].replace(np.nan, 0).astype(np.int16).astype('category')\n\ncategory=categorical+binary","aae7972b":"for c in ['resprate','heartrate','sodium']:\n    All_df['d1_'+c+'_min']=All_df['d1_'+c+'_min'].round(0)\n    All_df['d1_'+c+'_max']=All_df['d1_'+c+'_max'].round(0)\nfor c in ['temp','potassium','creatinine','hematocrit','wbc']:\n    All_df['d1_'+c+'_min']=All_df['d1_'+c+'_min'].round(1)\n    All_df['d1_'+c+'_max']=All_df['d1_'+c+'_max'].round(1)\nAll_df['d1_arterial_ph_min']=All_df['d1_arterial_ph_min'].round(2)\nAll_df['d1_arterial_ph_max']=All_df['d1_arterial_ph_max'].round(2)\napache=pd.DataFrame()\nfor c in apache_range.keys():\n    if c !='ph':\n        apache[c+'_apache']=All_df.apply(lambda row: calculate_value(row['h1_'+c+'_max'],row['h1_'+c+'_min'],row['d1_'+c+'_max'],row['d1_'+c+'_min'],apache_range[c]),axis=1)\n    else:\n        apache[c+'_apache']=All_df.apply(lambda row:calculate_value(row['h1_arterial_ph_max'],row['h1_arterial_ph_min'],row['d1_arterial_ph_max'],row['d1_arterial_ph_min'],apache_range['ph']),axis=1)\napache_original=set([c for c in All_df.columns.tolist() if '_apache' in c]).intersection(set(apache.columns.tolist()))\nother_apache=set(apache.columns.tolist())-apache_original\nfor c in list(apache_original):\n    All_df[c].fillna(apache[c],inplace=True)\nfor c in list(other_apache):\n    if c!='heartrate_apache':\n        All_df[c]=apache[c]\n    else:\n        All_df['heart_rate_apache'].fillna(apache[c],inplace=True)","99e8f02b":"All_df['hco3pco2_ratio']=All_df['d1_hco3_min']\/All_df['d1_arterial_pco2_max']\nAll_df['map_apache'].fillna((2*All_df['d1_diasbp_min']+All_df['d1_sysbp_max']),inplace=True)","65d42138":"All_df['gcs_sum']=All_df['gcs_eyes_apache']+All_df['gcs_motor_apache']+All_df['gcs_verbal_apache']","5d4ff44c":"invasive_col=[s for s in All_df.columns.tolist() if \"invasive\" in s]\nAll_df.drop(invasive_col,axis=1,inplace=True)","5010f2c0":"feature_dict=pd.read_csv('\/kaggle\/input\/widsdatathon2020\/WiDS Datathon 2020 Dictionary.csv')\nlab_feature=feature_dict[feature_dict['Category']=='labs']['Variable Name'].tolist()\nlab_feature=list(set(lab_feature)-set(invasive_col))\nvital_feature=feature_dict[feature_dict['Category']=='vitals']['Variable Name'].tolist()\nvital_feature=list(set(vital_feature)-set(invasive_col))\nLBG_feature=feature_dict[feature_dict['Category']=='labs blood gas']['Variable Name'].tolist()\nLBG_feature=list(set(LBG_feature)-set(invasive_col))\napache_feature=feature_dict[feature_dict['Category']=='APACHE covariate']['Variable Name'].tolist()\ncol=All_df.columns.tolist()\nh1_col=[s for s in col if \"h1_\" in s]\nd1_col=[s for s in col if \"d1_\" in s]\nAll_df['null_sum']=All_df.transpose().isnull().sum()\nAll_df['h1_null_sum']=All_df[h1_col].transpose().isnull().sum()\nAll_df['d1_null_sum']=All_df[d1_col].transpose().isnull().sum()\nAll_df['lab_null_sum']=All_df[lab_feature].transpose().isnull().sum()\nAll_df['vital_null_sum']=All_df[vital_feature].transpose().isnull().sum()\nAll_df['LBG_null_sum']=All_df[LBG_feature].transpose().isnull().sum()\nAll_df['apache_null_sum']=All_df[apache_feature].transpose().isnull().sum()","f86b0525":"h1_col=[s for s in col if \"h1_\" in s]\nd1_col=[s for s in col if \"d1_\" in s]\nh1d1=list(pd.Series(h1_col).str.replace(\"h1_\",\"\"))\nfor c in h1d1:\n    All_df['diff_'+c]=All_df['d1_'+c]-All_df['h1_'+c]","9475ecbe":"#RTS = 0.9368 GCS + 0.7326 SBP + 0.2908 RR\nRTS_range={'gcs':([13,15,4],[9,12,3],[6,8,2],[4,5,1],[0,3,0]),\n           'sysbp':([90,300,4],[76,89,3],[50,75,2],[1,49,1],[0,0,0]),\n           'resprate':([10,29,4],[30,150,3],[6,9,2],[1,5,1],[0,0,0])}\nRTS=list(RTS_range.keys())\nRTS_df=pd.DataFrame()\nfor c in RTS:\n    if c !='gcs':\n        RTS_df[c+'_RTS_score']=All_df.apply(lambda row: calculate_scores(row['h1_'+c+'_max'],row['h1_'+c+'_min'],row['d1_'+c+'_max'],row['d1_'+c+'_min'],RTS_range[c]),axis=1)\n    else:\n        RTS_df['gcs_RTS_score']=All_df.apply(lambda row: calculate_scores(row['gcs_sum'],row['gcs_sum'],row['gcs_sum'],row['gcs_sum'],RTS_range[c]),axis=1)\nAll_df['RTS_score']=0.9358*RTS_df['gcs_RTS_score']+0.7326*RTS_df['sysbp_RTS_score']+0.2908*RTS_df['resprate_RTS_score']","12c8006e":"from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score, train_test_split\nfrom sklearn.metrics import precision_score, roc_auc_score, recall_score, confusion_matrix, roc_curve, precision_recall_curve, accuracy_score,explained_variance_score\n\nimport lightgbm as lgbm\n\nfrom scipy.stats import randint as sp_randint\nfrom scipy.stats import uniform as sp_uniform\nimport warnings\n\n\nwarnings.filterwarnings('ignore')","eb348482":"All_impute=All_df.dropna(subset=['apache_4a_icu_death_prob'])\nAll_impute.drop(All_impute[All_impute['apache_4a_icu_death_prob']<0].index,inplace=True)#incorrect value\nAll_y_impute=All_impute['apache_4a_icu_death_prob']#get y\nAll_df_impute=All_impute.drop('apache_4a_icu_death_prob',axis=1)\n\ndata_impute=All_df_impute.copy()\ny_impute = np.array(All_y_impute.tolist())\nrandom_state = 23\n\nX_train, X_test, y_train, y_test = train_test_split(data_impute, y_impute, test_size = 0.2, random_state = random_state)#stratify = y_impute)\nX_train=pd.DataFrame(X_train,columns=data_impute.columns)\nX_test=pd.DataFrame(X_test,columns=data_impute.columns)\nlgbm_reg = lgbm.LGBMRegressor(n_estimators=300, random_state = 23,categorical_feature=category)\nlgbm_reg.fit(X_train, y_train)\ny_pred = lgbm_reg.predict(X_test)\nacc_lgbm_reg = explained_variance_score(y_test,y_pred)\nprint('The accuracy of imputing apache_4a_icu_death_prob in all data is:  '+str(acc_lgbm_reg))\n\nlgbm_reg.fit(data_impute,y_impute)\nAll_df_X=All_df.drop('apache_4a_icu_death_prob',axis=1)\nAll_df_icu=lgbm_reg.predict(All_df_X)\n\nAll_df_icu=np.reshape(All_df_icu,(131021,1))\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nAll_df_icu=scaler.fit_transform(All_df_icu)\n\nAll_df.loc[All_df['apache_4a_icu_death_prob']<0,'apache_4a_icu_death_prob']=np.nan\nAll_df['apache_4a_icu_death_prob'].fillna(pd.Series(np.reshape(All_df_icu,(131021,))),inplace=True)\n\nAll_impute=All_df.dropna(subset=['apache_4a_hospital_death_prob'])\nAll_impute.drop(All_impute[All_impute['apache_4a_hospital_death_prob']<0].index,inplace=True)#incorrect value\nAll_y_impute=All_impute['apache_4a_hospital_death_prob']#get y\nAll_df_impute=All_impute.drop('apache_4a_hospital_death_prob',axis=1)\n\ndata_impute=All_df_impute.copy()\ny_impute = np.array(All_y_impute.tolist())\nrandom_state = 23\n\nX_train, X_test, y_train, y_test = train_test_split(data_impute, y_impute, test_size = 0.2, random_state = random_state)#stratify = y_impute)\nX_train=pd.DataFrame(X_train,columns=data_impute.columns)\nX_test=pd.DataFrame(X_test,columns=data_impute.columns)\nlgbm_reg = lgbm.LGBMRegressor(n_estimators=300, random_state = 23,categorical_feature=category)\nlgbm_reg.fit(X_train, y_train)\ny_pred = lgbm_reg.predict(X_test)\nacc_lgbm_reg = explained_variance_score(y_test,y_pred)\n\nprint('The accuracy of imputing apache_4a_hospital_death_prob in all data is:  '+str(acc_lgbm_reg))\nlgbm_reg.fit(data_impute,y_impute)\nAll_df_X=All_df.drop('apache_4a_hospital_death_prob',axis=1)\nAll_df_hos=lgbm_reg.predict(All_df_X)\nAll_df_hos=np.reshape(All_df_hos,(131021,1))\nscaler = MinMaxScaler()\nAll_df_hos=scaler.fit_transform(All_df_hos)\n\nAll_df.loc[All_df['apache_4a_hospital_death_prob']<0,'apache_4a_hospital_death_prob']=np.nan\nAll_df['apache_4a_hospital_death_prob'].fillna(pd.Series(np.reshape(All_df_hos,(131021,))),inplace=True)","3d6a8319":"def model_performance(model) : \n    #Conf matrix\n    conf_matrix = confusion_matrix(y_test, y_pred)\n    trace1 = go.Heatmap(z = conf_matrix  ,x = [\"0 (pred)\",\"1 (pred)\"],\n                        y = [\"0 (true)\",\"1 (true)\"],xgap = 2, ygap = 2, \n                        colorscale = 'Viridis', showscale  = False)\n\n    #Show metrics\n    tp = conf_matrix[1,1]\n    fn = conf_matrix[1,0]\n    fp = conf_matrix[0,1]\n    tn = conf_matrix[0,0]\n    Accuracy  =  ((tp+tn)\/(tp+tn+fp+fn))\n    Precision =  (tp\/(tp+fp))\n    Recall    =  (tp\/(tp+fn))\n    F1_score  =  (2*(((tp\/(tp+fp))*(tp\/(tp+fn)))\/((tp\/(tp+fp))+(tp\/(tp+fn)))))\n\n    show_metrics = pd.DataFrame(data=[[Accuracy , Precision, Recall, F1_score]])\n    show_metrics = show_metrics.T\n\n    colors = ['gold', 'lightgreen', 'lightcoral', 'lightskyblue']\n    trace2 = go.Bar(x = (show_metrics[0].values), \n                   y = ['Accuracy', 'Precision', 'Recall', 'F1_score'], text = np.round_(show_metrics[0].values,4),\n                    textposition = 'auto',\n                   orientation = 'h', opacity = 0.8,marker=dict(\n            color=colors,\n            line=dict(color='#000000',width=1.5)))\n    \n    #Roc curve\n    model_roc_auc = round(roc_auc_score(y_test, y_score) , 3)\n    fpr, tpr, t = roc_curve(y_test, y_score)\n    trace3 = go.Scatter(x = fpr,y = tpr,\n                        name = \"Roc : \" + str(model_roc_auc),\n                        line = dict(color = ('rgb(22, 96, 167)'),width = 2), fill='tozeroy')\n    trace4 = go.Scatter(x = [0,1],y = [0,1],\n                        line = dict(color = ('black'),width = 1.5,\n                        dash = 'dot'))\n    \n    # Precision-recall curve\n    precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n    trace5 = go.Scatter(x = recall, y = precision,\n                        name = \"Precision\" + str(precision),\n                        line = dict(color = ('lightcoral'),width = 2), fill='tozeroy')\n    \n    #Feature importance\n    coefficients  = pd.DataFrame(eval(model).feature_importances_)\n    column_data   = pd.DataFrame(list(data))\n    coef_sumry    = (pd.merge(coefficients,column_data,left_index= True,\n                              right_index= True, how = \"left\"))\n    coef_sumry.columns = [\"coefficients\",\"features\"]\n    coef_sumry    = coef_sumry.sort_values(by = \"coefficients\",ascending = False)\n    coef_sumry = coef_sumry[coef_sumry[\"coefficients\"] !=0]\n    trace6 = go.Bar(x = coef_sumry[\"features\"],y = coef_sumry[\"coefficients\"],\n                    name = \"coefficients\",\n                    marker = dict(color = coef_sumry[\"coefficients\"],\n                                  colorscale = \"Viridis\",\n                                  line = dict(width = .6,color = \"black\")))\n    \n    #Cumulative gain\n    pos = pd.get_dummies(y_test).as_matrix()\n    pos = pos[:,1] \n    npos = np.sum(pos)\n    index = np.argsort(y_score) \n    index = index[::-1] \n    sort_pos = pos[index]\n    #cumulative sum\n    cpos = np.cumsum(sort_pos) \n    #recall\n    recall = cpos\/npos \n    #size obs test\n    n = y_test.shape[0] \n    size = np.arange(start=1,stop=369,step=1) \n    #proportion\n    size = size \/ n \n    #plots\n    model = model\n    trace7 = go.Scatter(x = size,y = recall,\n                        name = \"Lift curve\",\n                        line = dict(color = ('gold'),width = 2), fill='tozeroy') \n    \n    #Subplots\n    fig = tls.make_subplots(rows=4, cols=2, print_grid=False, \n                          specs=[[{}, {}], \n                                 [{}, {}],\n                                 [{'colspan': 2}, None],\n                                 [{'colspan': 2}, None]],\n                          subplot_titles=('Confusion Matrix',\n                                        'Metrics',\n                                        'ROC curve'+\" \"+ '('+ str(model_roc_auc)+')',\n                                        'Precision - Recall curve',\n                                        'Cumulative gains curve',\n                                        'Feature importance',\n                                        ))\n    \n    fig.append_trace(trace1,1,1)\n    fig.append_trace(trace2,1,2)\n    fig.append_trace(trace3,2,1)\n    fig.append_trace(trace4,2,1)\n    fig.append_trace(trace5,2,2)\n    fig.append_trace(trace6,4,1)\n    fig.append_trace(trace7,3,1)\n    \n    fig['layout'].update(showlegend = False, title = '<b>Model performance report<\/b><br>'+str(model),\n                        autosize = False, height = 1500,width = 830,\n                        plot_bgcolor = 'rgba(240,240,240, 0.95)',\n                        paper_bgcolor = 'rgba(240,240,240, 0.95)',\n                        margin = dict(b = 195))\n    fig[\"layout\"][\"xaxis2\"].update((dict(range=[0, 1])))\n    fig[\"layout\"][\"xaxis3\"].update(dict(title = \"false positive rate\"))\n    fig[\"layout\"][\"yaxis3\"].update(dict(title = \"true positive rate\"))\n    fig[\"layout\"][\"xaxis4\"].update(dict(title = \"recall\"), range = [0,1.05])\n    fig[\"layout\"][\"yaxis4\"].update(dict(title = \"precision\"), range = [0,1.05])\n    fig[\"layout\"][\"xaxis5\"].update(dict(title = \"Percentage contacted\"))\n    fig[\"layout\"][\"yaxis5\"].update(dict(title = \"Percentage positive targeted\"))\n    fig.layout.titlefont.size = 14\n    \n    py.iplot(fig)","9cc58bfe":"data=All_df[0:91713]\nTest_data=All_df[91713:131021]\ny = np.array(All_y[0:91713].tolist())\nrandom_state = 23\nX_train, X_test, y_train, y_test = train_test_split(data, y, test_size = 0.2, random_state = random_state, stratify = y)\nX_train=pd.DataFrame(X_train,columns=data.columns)\nX_test=pd.DataFrame(X_test,columns=data.columns)","c46e891b":"%%time\nlgbm_clf = lgbm.LGBMClassifier(boosting_type='dart',n_estimators=1000,random_state = 23,categorical_feature=category,metric='auc')\nlgbm_clf.fit(X_train, y_train)\ny_pred = lgbm_clf.predict(X_test)\ny_score = lgbm_clf.predict_proba(X_test)[:,1]","ce1b2c0f":"model_performance('lgbm_clf')","3cb9361f":"Best_params={'bagging_fraction': 0.8823860189717492, 'feature_fraction': 0.5012324406004431, 'lambda_l1': 2.6520965471163143, 'lambda_l2': 5.309685230258841, 'learning_rate': 0.09506145340497216, 'max_bin': 61, 'max_depth': 14, 'min_split_gain': 0.846642883905048, 'num_leaves':10}","0d9c1048":"lgbm_clf_rd = lgbm.LGBMClassifier(early_stopping_round=50,boosting_type='dart',objective='binary',random_state=23, silent=True, metric='auc', num_iterations=1000,categorical_feature=category,**Best_params,random_seed=23)","78d605a8":"lgbm_clf_rd.fit(X_train, y_train)\ny_pred = lgbm_clf_rd.predict(X_test)\ny_score = lgbm_clf_rd.predict_proba(X_test)[:,1]","4f464812":"model_performance('lgbm_clf_rd')","4d057b0c":"#model output\nlgbm_clf_rd = lgbm.LGBMClassifier(early_stopping_round=50,boosting_type='dart',objective='binary',num_iterations=1500,random_state=23, silent=True, metric='auc', categorical_feature=category,**Best_params,random_seed=23)\nlgbm_clf_rd.fit(data, y)\ny1_pred = lgbm_clf_rd.predict_proba(Test_data)\nsub_df=pd.read_csv('\/kaggle\/input\/widsdatathon2020\/solution_template.csv')\noutput=pd.DataFrame()\noutput['encounter_id']=sub_df['encounter_id']\noutput['hospital_death']=y1_pred[:,1]\noutput.reset_index(drop=True,inplace=True)\noutput.to_csv('submission.csv',index=False)","9b501178":"# Data processing\nHere, we will merge some categories, and fill in some missing value with what we know from the data.\nSuch as BMI (KG\/m^2)= Weight \/ (Height * Height)","34a76385":"We also want to capture how the patient's records change during the first hour and first day.  \n**Difference varialbes** were created to describe the difference beween maximum and minimum value.","067a4884":"### Age distribution of male and female patients.","278cf241":"### How do ICU-types and the days in hospital before the patients' ICU admissions look like?","daf26f0c":"# Bayesian Optimization Result\nI have skipped the hyperparameter tuning process as it could be found in many kernels. Let's look at the result!","39e21f70":"I hope you enjoy this notebook. This is my first Kaggle competition. I'm grateful for all those discussions and kernels posted. Hope this may inspire you a bit as well! Happy Learning!","a7c23482":"We will also add one feature: **Hco3\/PCo2** is a metric that can be used in some ICU  \nAnd fill out another feature with estiamtion: **Mean Arterial Pressure**","1240c7d7":"### What's the relationship between apache bodyststem categorization and hospital death?\nlet's choose one bodyststem category from the dropdown list.","18659d91":"**Revised Trauma Score** is another score that is used to describe the severity of patient condition.  \nRTS = 0.9368 GCS + 0.7326 SBP + 0.2908 RR","ca6fb15b":"# Lightgbm Model\nFinally, we get to build our model!","7e9de49e":"# Imputation\nWe still have a lot of missing value, so we will use lightgbm regressor to impute two important features: **apache_4a_icu_death_prob and apache_4a_hospital_death_prob**","88eb879e":"** Here is a base model without parameter tuning..**","0e49c6e5":"# Exploratory Data Analysis","a69d0e60":"![1](https:\/\/images.theconversation.com\/files\/117015\/original\/image-20160331-28462-qliwnl.jpg?ixlib=rb-1.1.0&q=45&auto=format&w=926&fit=clip)\n\nHello World! Have you ever think about how can data science predict our life, or even, health? This WiDS Datathon definitely inspired me on its power. How can we use patient data to understand inviidual health condition, and predict hospital death? \nLet's look at the data first!","9272610f":"Since **'Invasive\/Non-invasive'** columns are redundant and contain less information, we can drop them","352515e8":"Sum up the three component of GCS score as **'gcs_sum'**","d2a48fa4":"The dataset contains a dictionary where we get to know various kinds of features, we create a set of **\"null_sum\"** variables to describe the **completeness of each patient's data**","d93adb5d":"# What is this notebook about?","223f5298":"### Impact of bmi over old and young patients?","74d10476":"We will also fill in some 'xxx_apache' columns as those were the worst value within 24 hours of the ICU admission"}}