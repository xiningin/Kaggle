{"cell_type":{"c8ee57ab":"code","06e7592c":"code","53cbb589":"code","8617b8a6":"code","8ce61334":"markdown","7ecc164d":"markdown","06cf6143":"markdown","4330e349":"markdown"},"source":{"c8ee57ab":"import tensorflow as tf\nmnist = tf.keras.datasets.fashion_mnist\n(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\ntraining_images=training_images \/ 255.0\ntest_images=test_images \/ 255.0\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n])\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.fit(training_images, training_labels, epochs=5)\n\ntest_loss = model.evaluate(test_images, test_labels)","06e7592c":"import tensorflow as tf\nprint(tf.__version__)\nmnist = tf.keras.datasets.fashion_mnist\n(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\ntraining_images=training_images.reshape(60000, 28, 28, 1)\ntraining_images=training_images \/ 255.0\ntest_images = test_images.reshape(10000, 28, 28, 1)\ntest_images=test_images\/255.0\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n  tf.keras.layers.MaxPooling2D(2, 2),\n  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n  tf.keras.layers.MaxPooling2D(2,2),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dense(10, activation='softmax')\n])\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()\nmodel.fit(training_images, training_labels, epochs=5)\ntest_loss = model.evaluate(test_images, test_labels)","53cbb589":"import matplotlib.pyplot as plt\nf, axarr = plt.subplots(3,4)\nFIRST_IMAGE=0\nSECOND_IMAGE=7\nTHIRD_IMAGE=26\nCONVOLUTION_NUMBER = 1\nfrom tensorflow.keras import models\nlayer_outputs = [layer.output for layer in model.layers]\nactivation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\nfor x in range(0,4):\n  f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]\n  axarr[0,x].imshow(f1[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n  axarr[0,x].grid(False)\n  f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]\n  axarr[1,x].imshow(f2[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n  axarr[1,x].grid(False)\n  f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n  axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n  axarr[2,x].grid(False)","8617b8a6":"import tensorflow as tf\nprint(tf.__version__)\nmnist = tf.keras.datasets.mnist\n(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\ntraining_images=training_images.reshape(60000, 28, 28, 1)\ntraining_images=training_images \/ 255.0\ntest_images = test_images.reshape(10000, 28, 28, 1)\ntest_images=test_images\/255.0\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n  tf.keras.layers.MaxPooling2D(2, 2),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dense(10, activation='softmax')\n])\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.fit(training_images, training_labels, epochs=10)\ntest_loss, test_acc = model.evaluate(test_images, test_labels)\nprint(test_acc)","8ce61334":"## Simple NN on Fashion MNIST dataset","7ecc164d":"# Visualizing the Convolutions and Pooling\nThis code will show us the convolutions graphically. The print (test_labels[;100]) shows us the first 100 labels in the test set, and you can see that the ones at index 0, index 23 and index 28 are all the same value (9). They're all shoes. Let's take a look at the result of running the convolution on each, and you'll begin to see common features between them emerge. Now, when the DNN is training on that data, it's working with a lot less, and it's perhaps finding a commonality between shoes based on this convolution\/pooling combination.","06cf6143":"## Lets improve accuracy using CNN","4330e349":"# EXERCISES\n\nTry editing the convolutions. Change the 32s to either 16 or 64. What impact will this have on accuracy and\/or training time.\n\nRemove the final Convolution. What impact will this have on accuracy or training time?\n\nHow about adding more Convolutions? What impact do you think this will have? Experiment with it.\n\nRemove all Convolutions but the first. What impact do you think this will have? Experiment with it.\n\nIn the previous lesson you implemented a callback to check on the loss function and to cancel training once it hit a certain amount. See if you can implement that here!"}}