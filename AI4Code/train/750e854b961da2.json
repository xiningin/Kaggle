{"cell_type":{"07ff1f5e":"code","98dc7836":"code","82cf5697":"code","9199fb0f":"markdown","1cf97199":"markdown","c72d81a6":"markdown"},"source":{"07ff1f5e":"# basic\nimport numpy as np \nimport pandas as pd\nimport scipy as sp\nimport sys,os,math,time,random,shutil\n\n# split \nfrom sklearn.model_selection import train_test_split\n\n# model\nimport lightgbm as lgb\nimport optuna \nimport optuna.integration.lightgbm as lgbo\n\n# oof\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom scipy import stats\n\n# data path \nTRAIN_PATH = \"..\/input\/tabular-playground-series-aug-2021\/train.csv\"\nTEST_PATH = \"..\/input\/tabular-playground-series-aug-2021\/test.csv\"\nSAMPLE_SUBMISSION_PATH = \"..\/input\/tabular-playground-series-aug-2021\/sample_submission.csv\"\nSUBMISSION_PATH = \"submission.csv\"\n\n# main columns\nID  =\"id\"\nTARGET = \"loss\"\n\n#seed \nSEED = 2022\ndef seed_everything(seed=SEED):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\nseed_everything()\n\n# model\nNFOLD = 5\nTEST_SIZE = 0.25\nOBJECTIVE = 'mean_squared_error'\nMETRICS = 'rmse'\nNBR = 10\nVERBOSE_EVAL = 100","98dc7836":"# load\ntrain = pd.read_csv(TRAIN_PATH)\n\n# split (input & target)\ny= train[TARGET]\nX = train.drop([ID,TARGET],axis=1)\n\n#split (train & validation)\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=TEST_SIZE, random_state=SEED)\n\n# search best param (optuna)\nparams = { 'objective':OBJECTIVE, 'metric':METRICS }\n\nlgb_train = lgb.Dataset(X_train, y_train)\nlgb_valid = lgb.Dataset(X_val, y_val)\nmodel = lgbo.train(params, lgb_train, valid_sets=[lgb_valid], verbose_eval=False, num_boost_round=NBR) \nprint(model.params)\n\n# oof prediction\ntest = pd.read_csv(TEST_PATH)\nX_test = test.drop([ID],axis=1)\n\nkf = KFold(n_splits=NFOLD, random_state=SEED, shuffle=True)\npred_test_list =[]\nfor fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n    print(\"Fold :\", fold+1)\n    \n    X_train, y_train = X.loc[train_idx], y.loc[train_idx]\n    X_val,  y_val = X.loc[val_idx], y.loc[val_idx]\n \n    D_train = lgb.Dataset(X_train, y_train)\n    D_valid = lgb.Dataset(X_val, y_val)\n \n    model = lgb.train(model.params,D_train, valid_sets=[D_valid], verbose_eval=VERBOSE_EVAL)\n    pred_val = model.predict(X_val)\n\n    pred_test = model.predict(X_test)\n    pred_test_list.append(pred_test.tolist())\n    \n    print('#### fold #########',np.sqrt(mean_squared_error(y_val, pred_val)),mean_squared_error(y_val, pred_val))","82cf5697":"modeResult = stats.mode(pred_test_list, axis=0)\nfinal_test_pred = modeResult.mode\n\nsub = pd.read_csv(SAMPLE_SUBMISSION_PATH)\nsub[TARGET] = final_test_pred[0]\nsub.to_csv(SUBMISSION_PATH,index=False)\nsub.head()","9199fb0f":"# mak submission csv  ","1cf97199":"# build & predict ","c72d81a6":"# imports & variables"}}