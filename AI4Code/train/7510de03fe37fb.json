{"cell_type":{"3cacb44d":"code","a30e3ac1":"code","55130a87":"code","24ae6bf1":"code","b5e48f3e":"code","5d8e25a0":"code","2ab23dee":"code","aabc8076":"code","285205d8":"code","9aa5fc78":"code","2144e190":"code","a583f95f":"code","3921f849":"code","f17c383f":"code","4a9d2fc7":"code","a22da21e":"code","b46905f1":"code","f69e08e5":"code","4b94fb9b":"code","9538a132":"code","a2952cc0":"code","6212d1f5":"code","81065593":"code","e7fed978":"code","a20c08da":"code","c0c1a072":"code","94a0e131":"code","fb48ccd7":"code","0f6e7c5f":"code","22b51f64":"code","e6b93d4c":"code","26ac8966":"code","f3f2566f":"code","680e7222":"code","97967cb1":"code","34ff8087":"code","01f1b8a8":"code","15976b86":"code","d1d38d07":"code","19d753ef":"code","dde0a54d":"code","0bcf659b":"code","b6c43cca":"code","884bb406":"code","0bae7603":"code","22d71222":"code","5388100e":"code","cb1a5aac":"code","270548c0":"code","687d066c":"code","ed0d1ba7":"code","9c7c91bf":"code","c4b2ac52":"markdown","7f767bf3":"markdown","12065594":"markdown","7c932e68":"markdown","5faa96ff":"markdown","02f2743a":"markdown","8edb1283":"markdown","c61236a6":"markdown","0657c4dd":"markdown","af7edd2f":"markdown","ead184f7":"markdown","195af2ed":"markdown","eda47c74":"markdown"},"source":{"3cacb44d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a30e3ac1":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler","55130a87":"data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")# <\u0417\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u0434\u0430\u0442\u0430\u0441\u0435\u0442 \u0432 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u0443\u044e\ndata.head()","24ae6bf1":"data.info()","b5e48f3e":"data.describe()","5d8e25a0":"dataCopy = data.drop(['PassengerId', 'Cabin', 'Name'], axis=1) #\u0414\u0440\u043e\u043f\u0430\u0435\u043c ","2ab23dee":"dataCopy['Ticket'] = dataCopy.Ticket.str.split().apply(lambda x : 0 if x[-1] == 'LINE' else x[-1])# \u0423\u0434\u0430\u043b\u044f\u0435\u043c \u0432\u0441\u0435 \u0441\u0438\u043c\u0432\u043e\u043b\u044b \u0441 \u0431\u0438\u043b\u0435\u0442\u043e\u0432. \u041e\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u043c \u0442\u043e\u043b\u044c\u043a\u043e \u0446\u0438\u0444\u0440\u044b \u0431\u0438\u043b\u0435\u0442\u043e\u0432 \u0438 \u043f\u0440\u0435\u0432\u0440\u044f\u0449\u0430\u0435\u043c \u0432 INT64 \u0430 Line \u0432 0\ndataCopy.Ticket = dataCopy.Ticket.values.astype('int64')","aabc8076":"a = pd.cut(dataCopy['Fare'],5) # \u0420\u0430\u0437\u0431\u0438\u0432\u043a\u0430 \u043d\u0430 \u0434\u0438\u0430\u043f\u0430\u0437\u043e\u043d\u044b\ndataCopy['Fare'] = LabelEncoder().fit_transform(a) ","285205d8":"dataCopy = dataCopy.replace(to_replace={'Sex' : { 'male' : 1, 'female' : 0}, 'Embarked' : { 'C' : 0, 'Q' : 1, 'S' : 2}})\ndataCopy.head()","9aa5fc78":"embarked_mode = dataCopy['Embarked'].mode()[0] \ndataCopy['Embarked'] = dataCopy['Embarked'].fillna(embarked_mode)","2144e190":"dataCopy['Relatives'] = dataCopy['SibSp'] + dataCopy['Parch'] \ndataCopy = dataCopy.drop(['SibSp','Parch'], axis=1)","a583f95f":"dataCopy.info()","3921f849":"plt.figure(figsize=(10,8))\nsns.heatmap(dataCopy.corr(), annot=True, cmap=\"YlGnBu\", cbar=False);","f17c383f":"dataCopy.groupby(['Pclass','Sex','Relatives'])['Age'].mean()","4a9d2fc7":"dataCopy[\"Age\"].fillna(dataCopy.groupby(['Pclass','Sex','Relatives'])['Age'].transform(\"mean\"), inplace=True)","a22da21e":"dataCopy.info()","b46905f1":"dataCopy.groupby(['Pclass','Sex'])['Age'].mean()","f69e08e5":"dataCopy[\"Age\"].fillna(dataCopy.groupby(['Pclass','Sex'])['Age'].transform(\"mean\"), inplace=True)","4b94fb9b":"split = [0,12,24,45,60,dataCopy.Age.max()]\na = pd.cut(dataCopy['Age'], split)\n\nfig, axs = plt.subplots(figsize=(15, 5))\nsns.countplot(x=a, hue='Survived', data=dataCopy)\nsns.despine()","9538a132":"dataCopy['Age'] = LabelEncoder().fit_transform(a) ","a2952cc0":"sns.factorplot('Relatives','Survived',data=dataCopy, aspect = 2.5);","6212d1f5":"split = [-1,0,3,6]\na = pd.cut(dataCopy['Relatives'], split)\n\ndataCopy['Relatives'] = LabelEncoder().fit_transform(a) \n\ndataCopy['Relatives'].value_counts()","81065593":"fig, axs = plt.subplots(figsize=(15, 5))\nsns.countplot(x='Relatives', hue='Survived', data=dataCopy)\nsns.despine()","e7fed978":"dataCopy.head()","a20c08da":"plt.figure(figsize=(10,8))\nsns.heatmap(dataCopy.corr(), annot=True, cmap=\"YlGnBu\", cbar=False);","c0c1a072":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier","94a0e131":"new_target = dataCopy['Survived']\ndataCopy = dataCopy.drop(['Survived'], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(\n                                                    dataCopy,\n                                                    new_target.ravel(),\n                                                    test_size=0.2,\n                                                    random_state=42,\n                                                    stratify=new_target)","fb48ccd7":"sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","0f6e7c5f":"logmodel = LogisticRegression(max_iter=200)\nlogmodel.fit(X_train, y_train)\nprediction1 = logmodel.predict(X_test)","22b51f64":"print('Confusion Matrix:\\n', confusion_matrix(y_test, prediction1))\nprint('\\n')\nprint('Classification Report:\\n', classification_report(y_test, prediction1))","e6b93d4c":"logmodel2 = LogisticRegression(C= 0.09858667904100823,\n max_iter= 200,\n penalty= 'l2',\n solver= 'liblinear')","26ac8966":"logmodel2.fit(X_train, y_train)","f3f2566f":"log_grid_preds = logmodel2.predict(X_test)","680e7222":"print('Confusion Matrix:\\n', confusion_matrix(y_test, log_grid_preds))\nprint('\\n')\nprint('Classification Report:\\n', classification_report(y_test, log_grid_preds))","97967cb1":"knn = KNeighborsClassifier(n_neighbors=1)\nknn.fit(X_train, y_train)\nprediction2 = knn.predict(X_test)","34ff8087":"print('Confusion Matrix:\\n', confusion_matrix(y_test, prediction2))\nprint('\\n')\nprint('Classification Report:\\n', classification_report(y_test, prediction2))","01f1b8a8":"error_rate = []\n\nfor i in range(1,40):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train, y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))","15976b86":"plt.figure(figsize=(10,6))\nplt.plot(range(1,40), error_rate, color='blue', linestyle='--', marker='o', markerfacecolor='red', markersize=10)\nplt.title('Error Rate vs K value')\nplt.xlabel = ('K')\nplt.ylabel = ('Error Rate')","d1d38d07":"knn = KNeighborsClassifier(n_neighbors=8)\nknn.fit(X_train, y_train)\nprediction2 = knn.predict(X_test)","19d753ef":"print('Confusion Matrix:\\n', confusion_matrix(y_test, prediction2))\nprint('\\n')\nprint('Classification Report:\\n', classification_report(y_test, prediction2))","dde0a54d":"model = RandomForestClassifier(criterion ='entropy',\n                               max_depth = 4,\n                               min_samples_leaf = 1,\n                               min_samples_split = 4, \n                               n_estimators = 110)","0bcf659b":"model.fit(X_train, y_train) # \u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u041c\u043e\u0434\u0435\u043b\u0438","b6c43cca":"rfc_acc= model.score(X_test, y_test)","884bb406":"model.fit(dataCopy, new_target)","0bae7603":"lr_acc = accuracy_score(y_test, prediction1)\nknn_acc = accuracy_score(y_test, prediction2)\n","22d71222":"model1 = ['Logistic Regression', 'K Nearest Neighbors','Random Forest']\nscore = [lr_acc, knn_acc, rfc_acc]","5388100e":"plt.figure(figsize = (15, 10))\nsns.barplot(x = score, y = model1)\nplt.show()","cb1a5aac":"testData = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntestDataCopy = testData.drop(['PassengerId', 'Cabin', 'Name'], axis=1)\n\ntestDataCopy['Fare'] = testDataCopy['Fare'].interpolate()[:418]\na = pd.cut(testDataCopy['Fare'],5)\ntestDataCopy['Fare'] = LabelEncoder().fit_transform(a) \n\ntestDataCopy['Ticket'] = testDataCopy.Ticket.str.split().apply(lambda x : 0 if x[-1] == 'LINE' else x[-1])\ntestDataCopy.Ticket = testDataCopy.Ticket.values.astype('int64')\n\ntestDataCopy = testDataCopy.replace(to_replace={'Sex' : { 'male' : 1, 'female' : 0}, 'Embarked' : { 'C' : 0, 'Q' : 1, 'S' : 2}})\n\nembarked_mode = testDataCopy['Embarked'].mode()[0]\ntestDataCopy['Embarked'] = testDataCopy['Embarked'].fillna(embarked_mode)[:418]\n\ntestDataCopy['Relatives'] = testDataCopy['SibSp'] + testDataCopy['Parch'] \ntestDataCopy = testDataCopy.drop(['SibSp','Parch'], axis=1)\n\ntestDataCopy[\"Age\"].fillna(testDataCopy.groupby(['Pclass','Sex','Relatives'])['Age'].transform(\"mean\"), inplace=True)\ntestDataCopy[\"Age\"].fillna(testDataCopy.groupby(['Pclass','Sex'])['Age'].transform(\"mean\"), inplace=True)\nsplit = [0,12,24,45,60,testDataCopy.Age.max()]\na = pd.cut(testDataCopy['Age'], split)\ntestDataCopy['Age'] = LabelEncoder().fit_transform(a) \n\nsplit = [-1,0,3,6]\na = pd.cut(testDataCopy['Relatives'], split)\ntestDataCopy['Relatives'] = LabelEncoder().fit_transform(a)    \n\ntestDataCopy.info()","270548c0":"rusultPredict = model.predict(testDataCopy)","687d066c":"gender_submission = pd.read_csv(\"\/kaggle\/input\/titanic\/gender_submission.csv\")","ed0d1ba7":"gender_submission.Survived = rusultPredict","9c7c91bf":"gender_submission.to_csv('.\/gender_submission.csv', index=False)","c4b2ac52":"# 3. **\u0420\u0430\u0437\u0431\u0438\u0432\u0430\u0435\u043c \u043d\u0430 \u0433\u0440\u0443\u043f\u043f\u044b \u043b\u044e\u0434\u0435\u0439 \u0432 \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u0438 \u043e\u0442 \u0447\u0438\u0441\u043b\u0430 \u0440\u043e\u0434\u0441\u0442\u0432\u0435\u043d\u043d\u0438\u043a\u043e\u0432 \u043d\u0430 \u043a\u043e\u0440\u0430\u0431\u043b\u0435**","7f767bf3":"# **KNN**","12065594":"# 1.  **\u041e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 \u0438 \u0437\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432**","7c932e68":"\u041e\u0446\u0435\u043d\u043a\u0430 \u043d\u0430 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445:","5faa96ff":"# **Random Forest Classifier**","02f2743a":"\u0412\u0438\u0434\u043d\u043e \u0447\u0442\u043e \u0447\u0438\u0441\u043b\u043e \u0440\u043e\u0434\u0441\u0442\u0432\u0435\u043d\u043d\u0438\u043a\u043e\u0432 \u043d\u0430 \u043a\u043e\u0440\u0430\u0431\u043b\u0435 \u0434\u0435\u043b\u0438\u0442\u0441\u044f \u043d\u0430 4 \u0433\u0440\u0443\u043f\u043f\u044b: 1)\u0431\u0435\u0437 \u0440\u043e\u0434\u0441\u0442\u0432\u0435\u043d\u043d\u0438\u043a\u043e\u0432 2)\u043d\u0435\u0431\u043e\u043b\u044c\u0448\u0430\u044f \u0441\u0435\u043c\u044c\u044f(1-3 \u0440\u043e\u0434\u0441\u0442\u0432\u0435\u043d\u043d\u0438\u043a\u043e\u0432) 3)\u0441\u0440\u0435\u0434\u043d\u044f\u044f \u0441\u0435\u043c\u044c\u044f(4-6) 4)\u0431\u043e\u043b\u044c\u0448\u0430\u044f \u0441\u0435\u043c\u044c\u044f(6 \u0438 \u0431\u043e\u043b\u0435\u0435)","8edb1283":"\u041d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0430 \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u0434\u043b\u044f \u043b\u043e\u0433\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u043e\u0439 \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438","c61236a6":"# 2. **\u0412\u043e\u0441\u0442\u0430\u043d\u0430\u0432\u043b\u0438\u0432\u0430\u0435\u043c \u0432\u043e\u0437\u0440\u0430\u0441\u0442 \u0438 \u0440\u0430\u0437\u0431\u0438\u0432\u0430\u0435\u043c \u043f\u043e \u0433\u0440\u0443\u043f\u043f\u0430\u043c**","0657c4dd":"\u041a\u0430\u043a \u0432\u044b \u043c\u043e\u0436\u0435\u0442\u0435 \u0432\u0438\u0434\u0435\u0442\u044c, \u043e\u0441\u0442\u0440\u043e\u0442\u0430 \u043d\u0435 \u0442\u0430\u043a \u0443\u0436 \u0445\u043e\u0440\u043e\u0448\u0430. \u041f\u043e\u044d\u0442\u043e\u043c\u0443 \u044f \u043f\u043e\u0441\u0442\u0440\u043e\u044e \u0433\u0440\u0430\u0444\u0438\u043a \u043c\u0435\u0436\u0434\u0443 \u0447\u0430\u0441\u0442\u043e\u0442\u043e\u0439 \u043e\u0448\u0438\u0431\u043e\u043a \u0438 n_neighbors \u0438 \u043f\u043e\u043b\u0443\u0447\u0443 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0434\u043b\u044f n_neighbors, \u0433\u0434\u0435 \u0447\u0430\u0441\u0442\u043e\u0442\u0430 \u043e\u0448\u0438\u0431\u043e\u043a \u0441\u0430\u043c\u0430\u044f \u043d\u0438\u0437\u043a\u0430\u044f!","af7edd2f":"# \u0417\u0430\u043f\u043e\u043b\u043d\u044f\u0435\u043c \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u0438 \u0432 Embarked","ead184f7":"# 4. **\u041c\u043e\u0434\u0435\u043b\u044c**","195af2ed":"# 5.  \u0422\u0435\u0441\u0442\u043e\u0432\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435 \u043c\u0435\u043d\u044f\u0435\u043c \u0442\u043e\u0447\u043d\u043e \u0442\u0430\u043a \u0436\u0435 \u043a\u0430\u043a \u0438 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u044b\u0435","eda47c74":"# **Logic Regression**"}}