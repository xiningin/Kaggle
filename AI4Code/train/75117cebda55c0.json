{"cell_type":{"7a2035aa":"code","f4781567":"code","5c056d84":"code","02da4ded":"code","684a78d3":"code","6b4b55c5":"code","a2ca9d1f":"code","841847c3":"code","8e63e5cd":"code","3b6b9b09":"code","3a2470c2":"code","bfe976aa":"code","ce62c857":"code","f6e05ddd":"code","7702b1f3":"code","e0a2be65":"code","8b291a35":"code","84af67db":"code","f63883dc":"code","fa7ddc57":"markdown","5d08960c":"markdown","d6b7efbe":"markdown","fe69e650":"markdown","21a52a52":"markdown","bb4f2f45":"markdown","e1af1b78":"markdown","870b7867":"markdown","3c5a7d50":"markdown","bcbc7bb1":"markdown","578d9329":"markdown","e8433d76":"markdown","0e32d067":"markdown","675ca232":"markdown","41d1597b":"markdown"},"source":{"7a2035aa":"#importing libraries\nimport numpy as np\nimport pandas as pd\nimport seaborn  as sns\nimport matplotlib.pyplot as plt\nimport torch","f4781567":"#getting dataset with details\ncols = ['UserId','MovieId','Rating','TimeStamp']\nds = pd.read_csv('..\/input\/movielens-100k-dataset\/ml-100k\/u.data',sep = '\\t',header = None,names = cols)\nds.head()","5c056d84":"#getting dataset with movies\nname = cols = ['MovieId','Names']\nmovies = pd.read_csv('..\/input\/movielens-100k-dataset\/ml-100k\/u.item',sep = '\\|',header = None,engine = 'python',usecols=[0,1],names = name)\nmovies.head()","02da4ded":"#merging both sets for visualization\ndata = pd.merge(ds,movies,on = 'MovieId')\ndata.head()","684a78d3":"#top 5 most watched movies\ndata.groupby('Names')['Rating'].count().sort_values(ascending = False).head()","6b4b55c5":"#getting mean of movie ratings\nratings = pd.DataFrame(data.groupby('Names')['Rating'].mean())\nratings.head()","a2ca9d1f":"#getting number of ratings for each movie\nratings['No of ratings'] = data.groupby('Names')['Rating'].count()\nratings.head()","841847c3":"plt.figure(figsize = (8,6))  \nsns.set_style('white')\nratings['Rating'].hist(bins = 70)","8e63e5cd":"plt.figure(figsize = (8,6))  \nratings['No of ratings'].hist(bins = 70)","3b6b9b09":"sns.jointplot(x = 'Rating', y = 'No of ratings' , data = ratings, alpha = 0.3)","3a2470c2":"#importing training set\ntraining_set = pd.read_csv('..\/input\/movielens-100k-dataset\/ml-100k\/u1.base',sep = '\\t',header = None)\n\n#we need set in an numpy array\ntraining_set = np.array(training_set)\ntraining_set","bfe976aa":"#importing test set\ntest_set = pd.read_csv('..\/input\/movielens-100k-dataset\/ml-100k\/u1.test',sep = '\\t',header = None)\ntest_set = np.array(test_set)\ntest_set","ce62c857":"#getting total number of movies and total users\ntot_movies = max(max(training_set[:,1]),max(test_set[:,1]))\ntot_users = max(max(training_set[:,0]),max(test_set[:,0]))\nprint('Total users : {} , Total movies : {}'.format(tot_users,tot_movies))","f6e05ddd":"#converting our array into a 2D matrix where rows are number of users and columns are ratings of movies \ndef convert(arr):\n    new_arr = []\n    for user_id in range(1,tot_users + 1):\n        rating_id = arr[:,2][arr[:,0] == user_id]\n        movie_id = arr[:,1][arr[:,0] == user_id]\n        temp = np.zeros(tot_movies)\n        temp[movie_id - 1] = rating_id\n        new_arr.append(list(temp))\n    return new_arr\n\ntraining_set = convert(training_set)\ntest_set = convert(test_set)","7702b1f3":"#converting our matrices into torch Tensors\ntraining_set = torch.FloatTensor(training_set)\ntest_set = torch.FloatTensor(test_set)","e0a2be65":"#for training set\ntraining_set[training_set == 0] = -1\ntraining_set[training_set == 1] = 0\ntraining_set[training_set == 2] = 0\ntraining_set[training_set >= 3] = 1\n\n#for test set\ntest_set[test_set == 0] = -1\ntest_set[test_set == 1] = 0\ntest_set[test_set == 2] = 0\ntest_set[test_set >= 3] = 1","8b291a35":"#creating a class for Restricted Boltzmann Machine\nclass RBM:\n    \n    #randomly intializing weights and biases\n    def __init__(self,nv,nh):\n        self.W = torch.randn(nh,nv)\n        self.a = torch.randn(1,nh)\n        self.b = torch.randn(1,nv)\n    \n    #probability that hidden node will be 1 given the visible node(x is visble node vector)\n    def sample_h(self,x):\n        wx = torch.mm(x,self.W.t())\n        act = wx + self.a.expand_as(wx)\n        p_h_given_v = torch.sigmoid(act)\n        return p_h_given_v, torch.bernoulli(p_h_given_v)\n    \n    #probability that visible node will be 1 given the hidden node(y is hidden node vector()\n    def sample_v(self,y):\n        wy = torch.mm(y,self.W)\n        act = wy + self.b.expand_as(wy)\n        p_v_given_h = torch.sigmoid(act)\n        return p_v_given_h, torch.bernoulli(p_v_given_h)\n    \n    #updatting weights and biases to minimize energy (less the energy better the model)\n    #Function to perform Contrastive Divergence(Gibbs Sampling)\n    def train(self,v0,vk,ph0,phk):\n        self.W += (torch.mm(v0.t(),ph0) - torch.mm(vk.t(),phk)).t()\n        self.a += torch.sum((ph0-phk),0)\n        self.b += torch.sum((v0-vk),0)\n\n#visible nodes (nv) will be equal to input nodes (i.e movie ratings)        \nnv = len(training_set[0])\n\n#taking hidden nodes and batch_size as 100)\nnh = 100\nbatch_size = 100\n\n#creating object of our class\nrbm = RBM(nv,nh)","84af67db":"#training the model\nepochs = 10\ntrain_loss = 0\nn = 0.\n\n#for loop for epochs\nfor epo in range(1, epochs + 1):\n    \n    #for loop to iterate users\n    for i in range(0, tot_users - batch_size, batch_size):\n        \n        #note that at staring v0 and vk are equal\n        v0 = training_set[i : i + batch_size]\n        vk = training_set[i : i + batch_size]\n        ph0,_ = rbm.sample_h(v0)\n        \n        #for loop for Contrastive Divergence\n        for k in range(10):\n            _,hk = rbm.sample_h(vk)\n            _,vk = rbm.sample_v(hk)\n            vk[v0 < 0] = v0[v0 < 0] #to ignore values less than 0 (that are unrated movies with value -1)\n        phk,_ = rbm.sample_h(vk)\n        rbm.train(v0,vk,ph0,phk) #performing CD\n        \n        #calculating loss\n        train_loss += torch.mean(torch.abs(v0[v0 >= 0] - vk[v0 >= 0]))\n        n += 1.\n    \n    #here loss is divided by n to normalize it.\n    print('epoch : ' + str(epo) + ' train loss : ' + str(train_loss\/n))","f63883dc":"#testing\ntest_loss = 0\nn = 0.\nfor i in range(tot_users):\n    v = training_set[i : i + 1]\n    vt = test_set[i : i + 1]\n    if len(vt[vt >= 0]) > 0:\n        _,h = rbm.sample_h(v)\n        _,v = rbm.sample_v(h)\n        test_loss += torch.mean(torch.abs(v[vt >= 0] - vt[vt >= 0]))\n        n += 1.\nprint('test loss : ' + str(test_loss\/n))","fa7ddc57":"**NOTE:** \n* In (func. init ): weights(W) and biases(a,b) are initialized using Random Normal Distribution.\n* In (func. sample_h ): activation function is created using sigmoid activation to get p_h_given_v(prob. that hidden node is 1 given the visible node) \n* In (func. sample_v ): activation function is created using sigmoid activation to get p_v_given_h(prob. that visible node is 1 given the hidden node) \n* In (func. train ): Weights and biases are updated to minimize the energy(it's an Energy Based Model)\n\n**where,** \n* a = bias for probabilty of hidden node given the visible node\n* b = bias for probabilty of visible node given the hidden node\n* torch.bernoulli(p_h_given_v) = bernoulli distribution of p_h_given_v (vector of 0s and 1s)\n* v0 = Visible node or Input vector\n* vk = Visible node after k Contrastive Divergence\n* ph0 = probabilty of hidden node given the visible node (at starting)\n* phk = probabilty of hidden node given the visible node (after k Contrastive Divergence)","5d08960c":"**OBSERVATION :**\nMean of around 3.0 has maximum density and it makes sense because people usually watch movies with more ratings.\n","d6b7efbe":"# An Energy-Based Model\n\nEnergy is a term that may not be associated with deep learning in the first place. Rather is energy a quantitative property of physics. E.g. gravitational energy describes the potential energy a body with mass has in relation to another massive objected due to gravity. Yet some deep learning architectures use the idea of energy as a metric for the measurement of the model\u2019s quality.\n\n**NOTE : Purpose of a modes is to encode dependencies between variables. The capturing of dependencies happens through associating of scalar energy to each configuration of the variables, which serves as a measure of compatibility. High energy means bad compatibility. An energy-based model tries always to minimize a predefined energy function.**","fe69e650":"**OBSERVATION :** As the number of ratings increase, Mean of ratings also increase.","21a52a52":"**NOTE: Make sure to take v as training_set because we want to activate our nodes through training set and use those nodes in our testing set (vt)**","bb4f2f45":"**Making a RECOMMENDER SYSTEM that predicts whether a user will like a particular movie or not (Binary Classification) using Restricted Boltzmann Machine from scratch.**","e1af1b78":"# What is Boltzmann Machine?\n* Boltzmann Machine is a generative unsupervised model, which involves learning a probability distribution from an original dataset and using it to make inferences about never before seen data.\n* Boltzmann Machine has an input layer (also referred to as the visible layer) and one or several hidden layers (also referred to as the hidden layer).\n\n![](https:\/\/miro.medium.com\/max\/805\/1*YTZo3rydalAJmXuDY4B4ug.png)\n* Boltzmann Machine uses neural networks with neurons that are connected not only to other neurons in other layers but also to neurons within the same layer.\n* Everything is connected to everything. Connections are bidirectional, visible neurons connected to each other and hidden neurons also connected to each other\n* Boltzmann Machine doesn\u2019t expect input data, it generates data. Neurons generate information regardless they are hidden or visible.\n* For Boltzmann Machine all neurons are the same, it doesn\u2019t discriminate between hidden and visible neurons. For Boltzmann Machine whole things are system and its generating state of the system.\n\n**IN A NUTSHELL : Boltzmann Machine consists of a neural network with an input layer and one or several hidden layers. The neurons in the neural network make stochastic decisions about whether to turn on or off based on the data we feed during training and the cost function the Boltzmann Machine is trying to minimize.\nBy doing so, the Boltzmann Machine discovers interesting features about the data, which help model the complex underlying relationships and patterns present in the data.**","870b7867":"# Restricted Boltzmann Machine\n\nWhat makes RBMs different from Boltzmann machines is that visible node isn\u2019t connected to each other, and hidden nodes aren\u2019t connected with each other. Other than that, RBMs are exactly the same as Boltzmann machines.\n\n![](https:\/\/miro.medium.com\/max\/405\/1*qP7zFsyjb1sCVpV6IBIqOw.png)\n\n**POINTS TO REMEMBER :**\n* RBM is the neural network that belongs to the energy-based model\n* It is a probabilistic, unsupervised, generative deep machine learning algorithm.\n* RBM\u2019s objective is to find the joint probability distribution that maximizes the log-likelihood function.\n* RBM is undirected and has only two layers, Input layer, and hidden layer.\n\n**REFERENCE PAPER :** https:\/\/medium.com\/machine-learning-researcher\/boltzmann-machine-c2ce76d94da5","3c5a7d50":"**NOTE:**\n* An array of zeros was made and updated that such that with rated movies(i.e taking zero for the movies that aren't rated by user)\n* Done to make all columns equal (equal to number of movies  = 1682 )\n* Number of rows will be equal to number of users (943)\n","bcbc7bb1":"**OBSERVATION :** Most movies have ratings 0 and 1 and very less movies have high number of ratings.","578d9329":"**5 Movies with most ratings**","e8433d76":"* HERE WE COMPARED V0 AND VK (WE WANT THESE VALUES TO BE AS CLOSE AS POSSIBLE)\n* ALL CHANGES ARE MADE TO VK BECAUSE WE WANT V0 IN ORIGINAL FORM SO THAT WE CAN COMPARE IT LATER.","0e32d067":"**Rather than Movie names, Movie codes are given.**","675ca232":"* Objective of this model is to predict whether a user will like a movie or not (0,1), therefore converting ratings (1-5) to binary ratings\n* Taking 0 as -1 (These are nor rated movies)\n* Taking (1,2) as 0 (Not Liked)\n* Taking (3,4,5) as 1 (Liked)","41d1597b":"**Each movie has a unique code**"}}