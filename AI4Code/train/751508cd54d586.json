{"cell_type":{"1a29a2a5":"code","d1d6f6c3":"code","ec03a0d0":"code","17519b7b":"code","a3945991":"code","0f9b9993":"code","d2349e3b":"code","f50eb570":"code","bd6c048c":"code","118906da":"code","7ebbd835":"code","e262ac55":"code","dd452f7a":"code","141a41ea":"code","67c6338d":"code","51bb184e":"code","d3b5d5a7":"code","77514232":"code","d8732c77":"code","43d5cf53":"code","5b9cd4c5":"code","c9e48b1b":"code","1becf7db":"code","27521ef5":"code","3a33f67b":"code","dad7789c":"code","05fed07f":"code","f70c818b":"code","3a7aa16a":"code","b7021df1":"code","50c1f6ee":"code","81206bc9":"code","e64265ee":"code","a70e89a3":"code","9c5e31da":"code","760390b0":"code","3e8c83ef":"code","483c84a9":"code","48d353a7":"code","3f004eab":"code","af470f08":"code","e5a60622":"code","a32b308f":"code","33ca0d31":"code","5514c3fc":"code","e0810bd7":"code","2e2d1c50":"code","735c0492":"code","6dfa6926":"code","40e3dbdd":"code","c94c7bcd":"code","3d8c56ac":"code","9d7d5520":"code","1caa3354":"code","8944747a":"code","e19ffe73":"code","e65f6011":"code","597a6d62":"code","2404e13f":"code","12f963fe":"code","9d5f1879":"code","2815094f":"code","9cc983ab":"code","5d3c340d":"code","5b0aafec":"code","21b15549":"code","aeb6e776":"code","e8f787d0":"code","229e058e":"code","5f110b88":"code","05ab0f9c":"code","5d849a8c":"code","f357e04e":"code","ff51926f":"code","a1d1a86d":"markdown","cfafba42":"markdown","61ddabf4":"markdown","00ac783d":"markdown","4f7496ba":"markdown","7e9f91fd":"markdown","47aae40a":"markdown","f463be39":"markdown","5e931aa8":"markdown","4188c9d2":"markdown","8d28ace2":"markdown","b2184a0e":"markdown","c6b18870":"markdown","b91fc228":"markdown","d1155297":"markdown","af48b83c":"markdown","aea852fb":"markdown","8d1af306":"markdown","9b7b6db7":"markdown","14995a19":"markdown","8d619160":"markdown","1e1640a0":"markdown","fa0cf1a7":"markdown","cf96cce0":"markdown","9116099a":"markdown","90e9bb51":"markdown","d7ccb443":"markdown","a888af16":"markdown","1d73e956":"markdown","7138cc9d":"markdown","81bf8ade":"markdown","78194c0b":"markdown","d5a69757":"markdown","3de99e7b":"markdown","288a2c26":"markdown","2f298902":"markdown","4a1b462e":"markdown","06e5d5cd":"markdown","a0e33c03":"markdown","459dce0b":"markdown","80d02f71":"markdown","cb5adb10":"markdown"},"source":{"1a29a2a5":"from datetime import datetime\nimport numpy as np             #for numerical computations like log,exp,sqrt etc\nimport pandas as pd            #for reading & storing data, pre-processing\nimport matplotlib.pylab as plt #for visualization\n#for making sure matplotlib plots are generated in Jupyter notebook itself\n%matplotlib inline             \nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.stattools import acf, pacf\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nimport statsmodels.api as sm\nimport itertools\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom matplotlib.pylab import rcParams\nrcParams['figure.figsize'] = 10, 6\nimport seaborn as sns\n","d1d6f6c3":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ec03a0d0":"df=pd.read_excel(\"\/kaggle\/input\/nhsadmissions-and-gp-referrals\/NHS-Admissions.xls\")","17519b7b":"df.head()","a3945991":"df['date'] = pd.to_datetime(df[['Year', 'Month', 'Day']], errors = 'coerce')\ndf.head()","0f9b9993":"df=df.sort_values(by = 'date', ascending = True)","d2349e3b":"df.shape","f50eb570":"#df.info","bd6c048c":"#df.describe","118906da":"df.dtypes","7ebbd835":"df.isnull().sum()","e262ac55":"(df == 0).sum()","dd452f7a":"dt= df.drop(['Patients Suspended ','Deferred admissions'], axis = 1)  #Caere of the secret space after Suspender! ","141a41ea":"(dt == 0).sum()","67c6338d":"df['Admissions'].describe()","51bb184e":"df['Admissions'].plot(kind='box', vert=False, figsize=(14,6))","d3b5d5a7":"df['Admissions'].plot(kind='density', figsize=(14,6))","77514232":"df.head()","d8732c77":"plt.plot(df[\"date\"], df[\"Decisions to Admit\"], label=\"Decisions to Admit\")\nplt.plot(df[\"date\"], df[\"Admissions\"], label=\"Admissions\")\nplt.plot(df[\"date\"], df[\"Failed to Attend\"], label=\"Failed to Attend\")\nplt.plot(df[\"date\"], df[\"Removals\"], label=\"Removals\")\nplt.title(\" Inpatient activity over Years\")\nplt.xlabel(\"Year\")\nplt.ylabel(\" Inpatient activity\")\nplt.legend()\n\nplt.show()","43d5cf53":"plt.plot(df[\"date\"], df[\"Subsequent Attendances Seen\"], label=\"Subsequent Attendances Seen\")\nplt.plot(df[\"date\"], df[\"First Attendances Seen\"], label=\"First Attendances Seen\")\nplt.plot(df[\"date\"], df[\"GP Referrals Made\"], label=\"GP Referrals Made\")\nplt.plot(df[\"date\"], df[\"Other Referrals Made\"], label=\"Other Referrals Made\")\nplt.title(\" Referrals and attendances for outpatient admissions, over Years\")\nplt.xlabel(\"Year\")\nplt.ylabel(\" Inpatient activity\")\nplt.legend()\n\nplt.show()","5b9cd4c5":"plt.plot(df[\"date\"], df[\"Subsequent Attendances DNA\"], label=\"Subsequent Attendances DNA\")\nplt.plot(df[\"date\"], df[\"First Attendances DNA\"], label=\"First Attendances DNA\")\nplt.title(\" Outpatient appointment DNA\")\nplt.xlabel(\"Year\")\nplt.ylabel(\" Attendances activity\")\nplt.legend()\n\nplt.show()","c9e48b1b":"plt.figure(figsize=(22,10))\nplt.plot(df[\"date\"],df[\"Admissions\"])\nplt.title(\"Admissions over Years\")\nplt.xlabel(\"Year\")\nplt.ylabel(\"Number of Admissions\")\nplt.show()","1becf7db":"plt.figure(figsize=(22,10))\nplt.plot(df[\"date\"],df[\"Removals\"])\nplt.title(\"Removals over Years\")\nplt.xlabel(\"Year\")\nplt.ylabel(\"Number of Removals\")\nplt.show()","27521ef5":"plt.figure(figsize=(22,10))\nplt.plot(df[\"date\"],df[\"Failed to Attend\"])\nplt.title(\"Failed to Attend over Years\")\nplt.xlabel(\"Year\")\nplt.ylabel(\"Number of Failed to Attend\")\nplt.show()","3a33f67b":"sns.set()\nseason = df\n\nspivot = pd.pivot_table(season, index='Month', columns = 'Year', values = 'Failed to Attend', aggfunc=np.mean)\nspivot.plot(figsize=(20,10), linewidth=3)\nplt.show()","dad7789c":"sns.set()\nseason = df\n\nspivot = pd.pivot_table(season, index='Month', columns = 'Year', values = 'Removals', aggfunc=np.mean)\nspivot.plot(figsize=(20,10), linewidth=3)\nplt.show()","05fed07f":"sns.set()\nseason = df\n\nspivot = pd.pivot_table(season, index='Month', columns = 'Year', values = 'Admissions', aggfunc=np.mean)\nspivot.plot(figsize=(20,10), linewidth=3)\nplt.show()","f70c818b":"sns.set()\nseason = df\n\nspivot = pd.pivot_table(season, index='Month', columns = 'Year', values = 'GP Referrals Made', aggfunc=np.mean)\nspivot.plot(figsize=(20,10), linewidth=3)\nplt.show()\n","3a7aa16a":"sns.set()\nseason = df\n\nspivot = pd.pivot_table(season, index='Month', columns = 'Year', values = 'Decisions to Admit', aggfunc=np.mean)\nspivot.plot(figsize=(20,10), linewidth=3)\nplt.show()\n","b7021df1":"\ncorr = df.corr() #Correlation matrix for CB player\ncorr","50c1f6ee":"fig = plt.figure(figsize=(8,8))\nplt.matshow(corr, cmap='RdBu', fignum=fig.number)\nplt.xticks(range(len(corr.columns)), corr.columns, rotation='vertical');\nplt.yticks(range(len(corr.columns)), corr.columns);","81206bc9":"df2=df.drop(['Subsequent Attendances DNA'], axis = 1)\ncorr2 = df2.corr() \ncorr2\n","e64265ee":"fig = plt.figure(figsize=(8,8))\nplt.matshow(corr2, cmap='RdBu', fignum=fig.number)\nplt.xticks(range(len(corr2.columns)), corr2.columns, rotation='vertical');\nplt.yticks(range(len(corr2.columns)), corr2.columns);","a70e89a3":"df2bis=df2.drop(['Day','Month'], axis = 1)\ncorr2bis = df2bis.corr() \ncorr2bis\n","9c5e31da":"fig = plt.figure(figsize=(8,8))\nplt.matshow(corr2bis, cmap='RdBu', fignum=fig.number)\nplt.xticks(range(len(corr2bis.columns)), corr2bis.columns, rotation='vertical');\nplt.yticks(range(len(corr2bis.columns)), corr2bis.columns);","760390b0":"admissionsplt = df.groupby('date')['date','Admissions'].mean().dropna()\nadmissionsplt.plot(figsize=(10,8))\nplt.show()","3e8c83ef":"\ndf3 = df[['date', 'Admissions']]\ndf3.head()","483c84a9":"df3.set_index('date', inplace=True, drop=True)","48d353a7":"df3.index = pd.to_datetime(df3.index)","3f004eab":"df3.plot()","af470f08":"def TestStationaryPlot(ts):\n    rol_mean = ts.rolling(window = 12, center = False).mean()\n    rol_std = ts.rolling(window = 12, center = False).std()\n    \n    plt.plot(ts, color = 'blue',label = 'Original Data')\n    plt.plot(rol_mean, color = 'red', label = 'Rolling Mean')\n    plt.plot(rol_std, color ='black', label = 'Rolling Std')\n    plt.xticks(fontsize = 25)\n    plt.yticks(fontsize = 25)\n    \n    plt.xlabel('Time in Years', fontsize = 25)\n    plt.ylabel('Total Admissions', fontsize = 25)\n    plt.legend(loc='best', fontsize = 25)\n    plt.title('Rolling Mean & Standard Deviation', fontsize = 25)\n    plt.show(block= True)\n","e5a60622":"df3=df3.sort_values(by = 'date', ascending = True)","a32b308f":"TestStationaryPlot(df3)","33ca0d31":"def TestStationaryAdfuller(ts, cutoff = 0.01):\n    ts_test = adfuller(ts, autolag = 'AIC')\n    ts_test_output = pd.Series(ts_test[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    \n    for key,value in ts_test[4].items():\n        ts_test_output['Critical Value (%s)'%key] = value\n    print(ts_test_output)\n    \n    if ts_test[1] <= cutoff:\n        print(\"Strong evidence against the null hypothesis, reject the null hypothesis. Data has no unit root, hence it is stationary\")\n    else:\n        print(\"Weak evidence against null hypothesis, time series has a unit root, indicating it is non-stationary \")","5514c3fc":"TestStationaryAdfuller(df3)","e0810bd7":"moving_avg = df3.rolling(12).mean()\nplt.plot(df3)\nplt.plot(moving_avg, color='red')\nplt.xticks(fontsize = 25)\nplt.yticks(fontsize = 25)\nplt.xlabel('Time (years)', fontsize = 25)\nplt.ylabel('Admission', fontsize = 25)\nplt.title('Admission over years', fontsize = 25)\nplt.show()","2e2d1c50":"df3_moving_avg_diff = df3 - moving_avg\ndf3_moving_avg_diff.head(13)","735c0492":"df3_moving_avg_diff.dropna(inplace=True)\nTestStationaryPlot(df3_moving_avg_diff)","6dfa6926":"TestStationaryAdfuller(df3_moving_avg_diff)","40e3dbdd":"df3_first_difference = df3 - df3.shift(1)  \nTestStationaryPlot(df3_first_difference.dropna(inplace=False))","c94c7bcd":"TestStationaryAdfuller(df3_first_difference.dropna(inplace=False))","3d8c56ac":"df3_seasonal_difference = df3 - df3.shift(12)  \nTestStationaryPlot(df3_seasonal_difference.dropna(inplace=False))\nTestStationaryAdfuller(df3_seasonal_difference.dropna(inplace=False))","9d7d5520":"df3_seasonal_first_difference = df3_first_difference - df3_first_difference.shift(12)  \nTestStationaryPlot(df3_seasonal_first_difference.dropna(inplace=False))","1caa3354":"TestStationaryAdfuller(df3_seasonal_first_difference.dropna(inplace=False))","8944747a":"decomposition = seasonal_decompose(df3)\n\ntrend = decomposition.trend\nseasonal = decomposition.seasonal\nresidual = decomposition.resid\n\nplt.subplot(411)\nplt.plot(df3, label='Original')\nplt.legend(loc='best')\nplt.subplot(412)\nplt.plot(trend, label='Trend')\nplt.legend(loc='best')\nplt.subplot(413)\nplt.plot(seasonal,label='Seasonality')\nplt.legend(loc='best')\nplt.subplot(414)\nplt.plot(residual, label='Residuals')\nplt.legend(loc='best')\nplt.tight_layout()","e19ffe73":"df3_decompose = residual\ndf3_decompose.dropna(inplace=True)\nTestStationaryPlot(df3_decompose)\nTestStationaryAdfuller(df3_decompose)","e65f6011":"fig = plt.figure(figsize=(12,8))\n#ax1 = fig.add_subplot(211)\n#fig = sm.graphics.tsa.plot_acf(df3_seasonal_first_difference.iloc[13:], lags=40, ax=ax1)\nax2 = fig.add_subplot(212)\nfig = sm.graphics.tsa.plot_pacf(df3_seasonal_first_difference.iloc[13:], lags=40, ax=ax2)","597a6d62":"p = d = q = range(0, 2) # Define the p, d and q parameters to take any value between 0 and 2\npdq = list(itertools.product(p, d, q)) # Generate all different combinations of p, q and q triplets\npdq_x_QDQs = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))] # Generate all different combinations of seasonal p, q and q triplets\nprint('Examples of Seasonal ARIMA parameter combinations for Seasonal ARIMA...')\nprint('SARIMAX: {} x {}'.format(pdq[1], pdq_x_QDQs[1]))\nprint('SARIMAX: {} x {}'.format(pdq[2], pdq_x_QDQs[2]))","2404e13f":"for param in pdq:\n    for seasonal_param in pdq_x_QDQs:\n        try:\n            mod = sm.tsa.statespace.SARIMAX(mte,\n                                            order=param,\n                                            seasonal_order=seasonal_param,\n                                            enforce_stationarity=False,\n                                            enforce_invertibility=False)\n            results = mod.fit()\n            print('ARIMA{}x{} - AIC:{}'.format(param, param_seasonal, results.aic))\n        except:\n            continue","12f963fe":"mod = sm.tsa.statespace.SARIMAX(df3, \n                                order=(1,1,1), \n                                seasonal_order=(0,1,1,12),   \n                                enforce_stationarity=False,\n                                enforce_invertibility=False)\nresults = mod.fit()\nprint(results.summary())","9d5f1879":"results.resid.plot()","2815094f":"print(results.resid.describe())","9cc983ab":"results.resid.plot(kind='kde')","5d3c340d":"results.plot_diagnostics(figsize=(15, 12))\nplt.show()","5b0aafec":"pred = results.get_prediction(start = 40, end = 50, dynamic=False)\npred_ci = pred.conf_int()\npred_ci.head()","21b15549":"ax = df3['1990':].plot(label='observed')\npred.predicted_mean.plot(ax=ax, label='One-step ahead forecast', alpha=.7)\n\nax.fill_between(pred_ci.index,\n                pred_ci.iloc[:, 0],\n                pred_ci.iloc[:, 1], color='r', alpha=.5)\n\nax.set_xlabel('Time (years)')\nax.set_ylabel('Admissions')\nplt.legend()\n\nplt.show()","aeb6e776":"df3_forecast = pred.predicted_mean\ndf3_truth = df3['2018-03-01':]","e8f787d0":"df3_pred_concat = pd.concat([df3_truth, df3_forecast])","229e058e":"pred_dynamic = results.get_prediction(start=pd.to_datetime('2018-03-01'), dynamic=True, full_results=True)\npred_dynamic_ci = pred_dynamic.conf_int()","5f110b88":"ax = df3['1973':].plot(label='observed', figsize=(20, 15))\npred_dynamic.predicted_mean.plot(label='Dynamic Forecast', ax=ax)\n\nax.fill_between(pred_dynamic_ci.index,\n                pred_dynamic_ci.iloc[:, 0],\n                pred_dynamic_ci.iloc[:, 1], \n                color='r', \n                alpha=.3)\n\nax.fill_betweenx(ax.get_ylim(), \n                 pd.to_datetime('2018-03-01'), \n                 df3.index[-1],\n                 alpha=.1, zorder=-1)\n\nax.set_xlabel('Time (years)')\nax.set_ylabel('Admissions')\n\nplt.legend()\nplt.show()","05ab0f9c":"# Get forecast of 10 years or 120 months steps ahead in future\nforecast = results.get_forecast(steps= 12)\n# Get confidence intervals of forecasts\nforecast_ci = forecast.conf_int()\nforecast_ci.head()","5d849a8c":"ax = df3.plot(label='observed', figsize=(20, 15))\nforecast.predicted_mean.plot(ax=ax, label='Forecast')\nax.fill_between(forecast_ci.index,\n                forecast_ci.iloc[:, 0],\n                forecast_ci.iloc[:, 1], color='g', alpha=.4)\nax.set_xlabel('Time (year)')\nax.set_ylabel('Admissions')\n\nplt.legend()\nplt.show()","f357e04e":"# Get forecast of 10 years or 120 months steps ahead in future\nforecast = results.get_forecast(steps= 45)\n# Get confidence intervals of forecasts\nforecast_ci = forecast.conf_int()\nforecast_ci.tail()","ff51926f":"ax = df3.plot(label='observed', figsize=(20, 15))\nforecast.predicted_mean.plot(ax=ax, label='Forecast')\nax.fill_between(forecast_ci.index,\n                forecast_ci.iloc[:, 0],\n                forecast_ci.iloc[:, 1], color='g', alpha=.4)\nax.set_xlabel('Time (year)')\nax.set_ylabel('Admissions')\n\nplt.legend()\nplt.show()","a1d1a86d":"# Correlation Analysis","cfafba42":"### Next line is to order the data regarding date","61ddabf4":"# First we need to test stationarity of the time series","00ac783d":"## Reshape of  a new dataframe to only keep values for dates and Admissions ","4f7496ba":"We drop 'Patients Suspended ','Deferred admissions' because of the Huge lack of values","7e9f91fd":"![image.png](attachment:image.png)","47aae40a":"### We plot our New dataframe to make sure it's the same as expected. We confirm that it is.","f463be39":"#  Eliminating trend and seasonality: Decomposing","5e931aa8":"# Prediction for 2021 : Admission time series","4188c9d2":"On this Correlation Matrix we are not able to draw a lot of conclusions because some parameters are causing noise in our results. We start to drop the \" subsequent attenances DNA\" column because its so RED that all of the other cases are dark blue.","8d28ace2":"# Data Import and Excel reading","b2184a0e":"The Test Statistic is smaller than the 10% 5%, and 1% of critical values. So, we can say with 99% confidence level that the dataset is a stationary series.","c6b18870":"# Forecasting over 2031","b91fc228":"So we can see that this method made our serie stationary too; of course its not particulary \" more stationary \" than the first method because \" more stationary\" makes no sense.","d1155297":"The emissions mean and the variation in standard deviation (black line) clearly vary with time. This shows that the series has a trend. So, it is not a stationary. Also, the Test Statistic is greater than the critical values with 90%, 95% and 99% confidence levels. Hence, no evidence to reject the null hypothesis. Therefore the series is nonstationary.","af48b83c":"# END of correlation study","aea852fb":"### Next line is to solve a plot issue ","8d1af306":"# Knowing the dataset is not stationary, we must transform it to be stationary","9b7b6db7":"## Method 1 : The moving average","14995a19":"Finally we have an interesting matrix! We can draw many conclusions such as the high correlation between Admissions and Decision to admit.\nWe stop the Correlation Matrix study here to start developing the prediction model","8d619160":"# Data Inspection","1e1640a0":"# Forecasting over 2021","fa0cf1a7":"# Find optimal parameters and build SARIMA model","cf96cce0":"# Error Validation","9116099a":"![image.png](attachment:image.png)","90e9bb51":"# Descriptive statistics","d7ccb443":"## Visualisation of the admissions evolution over years","a888af16":"We transform the Dataframe to have a date reference; it will be necessary for the rest of the study.","1d73e956":"We focus the study on the admission parameter, obviously the same study can be conducted on every parameter following the same methodology","7138cc9d":"# Librairies import","81bf8ade":"### P-value\nBefore we try to understand about the p-value, we need to know about the null hypothesis.\n\n**Null hypothesis** is a general statement that there is no relationship between two measured phenomena.\n\nTesting (accepting, approving, rejecting, or disproving) the null hypothesis\u2014and thus concluding that there are or are not grounds for believing that there is a relationship between two phenomena (e.g. that a potential treatment has a measurable effect)\u2014is a central task in the modern practice of science; the field of statistics gives precise criteria for rejecting a null hypothesis.\n\nSource: Wikipedia\n\nFor more info about the null hypothesis check the above Wikipedia article\n\n\n**What is p-value**?\nP-value or probability value or asymptotic significance is a probability value for a given statistical model that, if the null hyothesis is true, a set of statistical observations more commonly known as the statistical summary is greater than or equal in magnitude to the observed results.\n\nHow does p-value help in feature selection?\nRemoval of different features from the dataset will have different effects on the p-value for the dataset. We can remove different features and measure the p-value in each case. These measured p-values can be used to decide whether to keep a feature or not.","78194c0b":"Sources : \nDataset : Quarterly activity data relating to GP and other referrals for an outpatient appointment, the total number of attendances at consultant outpatient clinics; including patients seen for their first appointments as well as those attending for subsequent or follow up appointments.\nhttps:\/\/www.england.nhs.uk\/statistics\/statistical-work-areas\/hospital-activity\/quarterly-hospital-activity\/qar-data\/\n","d5a69757":"### We begin to do it using the Dickey-Fuller method","3de99e7b":"![image.png](attachment:image.png)","288a2c26":"So the red line shows the rolling mean; because the rolling mean parameter = 12 we don't have values for the 11 first values of the series.","2f298902":"## Second method :  Differencing ","4a1b462e":"# End of Inspection","06e5d5cd":"We can now conduct a correlation Analysis to better understand the relations between all of our variables.\n","a0e33c03":"![image.png](attachment:image.png)","459dce0b":"![image.png](attachment:image.png)","80d02f71":"In this technique,the idea is to take of \u2018k\u2019 consecutive values depending on the frequency of time series (in this case 12 monthes per year). Here, we will take the average over the past 1 year.","cb5adb10":"This Second correlation matrix is better but its not enouth; we need no supress Month and Day of this matrix to have our final matrix."}}