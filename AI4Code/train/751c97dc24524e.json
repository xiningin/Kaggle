{"cell_type":{"4b92af83":"code","1c125bb1":"code","60136523":"code","7d96e511":"code","837e1758":"code","98b11467":"code","712286a2":"code","c13db866":"code","8521b05f":"code","cde35997":"code","8c6f81ce":"code","8f1f3828":"code","62ac68bb":"code","b5bf91d3":"code","551ddee0":"code","d1da9e7a":"code","56cfdc17":"code","43f83040":"code","6612e1f6":"code","57c000b2":"code","5cd3cd21":"code","2d486d11":"code","4aabbd31":"code","be6fa6c4":"code","a8a1df9d":"code","88f6520d":"markdown","5b92de1a":"markdown"},"source":{"4b92af83":"import numpy as np\nimport pandas as pd\nimport cv2\nfrom matplotlib import pyplot as plt","1c125bb1":"def add_status(train):\n    \n    # It has been done this way in order to avoid unnecessary warnings\n    train['status'] = 0\n    train['label'] = 0\n    \n    train.loc[train.healthy == 1, 'status'] = 'healthy'\n    train.loc[train.healthy == 1, 'label'] = 0\n    train.loc[train.multiple_diseases == 1, 'status'] = 'multiple_diseases'\n    train.loc[train.multiple_diseases == 1, 'label'] = 1\n    train.loc[train.rust == 1, 'status'] = 'rust'\n    train.loc[train.rust == 1, 'label'] = 2\n    train.loc[train.scab == 1, 'status'] = 'scab'\n    train.loc[train.scab == 1, 'label'] = 3\n    \n    return train","60136523":"def load_images(train, directory):\n    \n    # This function loads the images, resizes them and puts them into an array\n    \n    img_size = 900\n    train_image = []\n    for name in train['image_id']:\n        path = directory + 'images\/' + name + '.jpg'\n        img = cv2.imread(path)\n        image = cv2.resize(img, (img_size, img_size))\n        train_image.append(image)\n    train_image_array = np.array(train_image)\n    \n    return train_image_array","7d96e511":"def save_images(folder_name, x, y):\n    healthy_count = 0\n    multiple_diseases_count = 0\n    rust_count = 0\n    scab_count = 0\n\n    for i in range(0, len(x)):\n        if y[i] == 0:\n            healthy_count += 1\n            name = 'healthy_' + str(healthy_count) + '.jpg'\n            cv2.imwrite(folder_name + 'healthy\/' + name, x[i])\n        elif y[i] == 1:\n            multiple_diseases_count +=1\n            name = 'multiple_diseases_' + str(multiple_diseases_count) + '.jpg'\n            cv2.imwrite(folder_name + 'multiple_diseases\/' + name, x[i])\n        elif y[i] == 2:\n            rust_count +=1\n            name = 'rust_' + str(rust_count) + '.jpg'\n            cv2.imwrite(folder_name + 'rust\/' + name, x[i])\n        elif y[i] == 3:\n            scab_count +=1\n            name = 'scab_' + str(scab_count) + '.jpg'\n            cv2.imwrite(folder_name + 'scab\/' + name, x[i])","837e1758":"def make_folders(directory):\n    import os\n    classes = ['healthy', 'multiple_diseases', 'rust', 'scab']\n    os.mkdir(directory + 'image_generator')\n    os.mkdir(directory + 'image_generator\/train')\n    for cls in classes:\n        os.mkdir(directory + 'image_generator\/train\/' + cls )\n    os.mkdir(directory + 'image_generator\/validation')\n    for cls in classes:\n        os.mkdir(directory + 'image_generator\/validation\/' + cls )","98b11467":"directory = '..\/input\/plant-pathology-2020-fgvc7\/'\ndf_train = pd.read_csv(directory + 'train.csv')\ndf_train = add_status(df_train)\ntrain_img = load_images(df_train, directory)\ndirectory_output = '\/kaggle\/working\/'\nmake_folders(directory_output)","712286a2":"from sklearn.model_selection import train_test_split\n\nx_train, x_val, y_train, y_val = train_test_split(train_img, df_train['label'].to_numpy(), \n                                                  stratify = df_train['label'].to_numpy(), test_size = 0.2)","c13db866":"save_images(directory_output + 'image_generator\/train\/', x_train, y_train)\nsave_images(directory_output + 'image_generator\/validation\/', x_val, y_val)","8521b05f":"def show_distribution():\n    n_healthy = 413\n    n_multiple = 73\n    n_rust = 497\n    n_scab = 473\n\n    print('Number of Healthy images:', n_healthy)\n    print('Number of Multiple_diseases images:', n_multiple)\n    print('Number of Rust images:', n_rust)\n    print('Number of Scab images:', n_scab)\n    \n    distribution_dictionary = {'healthy' : n_healthy,\n                               'multiple_diseases' : n_multiple,\n                               'rust' : n_rust,\n                               'scab' : n_scab}\n    \n    return distribution_dictionary","cde35997":"def load_images_new(dir_name, n_img):\n    \n    # This function loads the images, resizes them and puts them into an array\n    \n    img_size = 900\n    train_image = []\n    counter = 0\n    for i in range(1, n_img+1):\n        counter += 1\n        if (counter % 100 == 0):\n            print('we have loaded', counter , 'images')\n        path = directory + dir_name + '\/' + dir_name + '_' + str(i) + '.jpg'\n#         print(path)\n        img = cv2.imread(path)\n        image = cv2.resize(img, (img_size, img_size))\n        train_image.append(image)\n    train_image_array = np.array(train_image)\n    \n    return train_image_array","8c6f81ce":"def append_images(name, add_images):\n    \n    train_add = train_img.copy()\n    \n    if name == 'rust': # Don't add anything\n        print('rust')\n\n    elif name == 'multiple_diseases': # Add 4 times the amount of images and more\n        for i in range(0,4):\n            train_add = np.concatenate((train_add, train_img))\n        train_add = np.concatenate((train_add, train_img[0:59]))\n        \n    else: # Add the needed amount.\n        train_add = train_img[0:add_images]\n        \n    return train_add","8f1f3828":"def write_images(directory, train_img, len_previous, name):\n    \n    for i in range(0, len(train_img)):\n        img_name =  name + '_' + str(len_previous + i + 1) + '.jpg'\n        cv2.imwrite(directory + name + '\/' + img_name, train_img[i])","62ac68bb":"directory = '\/kaggle\/working\/image_generator\/train\/'\nnames = ['healthy', 'multiple_diseases', 'rust', 'scab']\ndistr_dict = show_distribution()\nprint()\n\nfor name in names:\n    if name == 'rust':\n        print('Russt!')\n        \n    else:\n        df_len_previous = distr_dict[name] # The length before adding more images\n\n        train_img = load_images_new(name, df_len_previous)\n        print()\n#         train_img = train_img[df_train[name] == 1] # Takes the images of the label\n        n_samples = distr_dict[name] # Takes the number of samples of that images\n\n        add_images = distr_dict['rust'] - n_samples # The amount of images we have to add\n        print('images we have to add:', add_images)\n\n        train_add = append_images(name, add_images)\n\n#         df_train = append_dataframe(df_train, name, train_add)\n\n        write_images(directory, train_add, df_len_previous, name)","b5bf91d3":"import numpy as np\nimport pandas as pd\nimport cv2\nfrom matplotlib import pyplot as plt\nimport keras\nfrom keras import models, Sequential\nfrom keras.layers import Dense\nfrom keras.layers import AveragePooling2D, MaxPooling2D\nfrom keras.models import Sequential\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nfrom keras import losses\nfrom keras.models import model_from_json","551ddee0":"def predict_and_save(model, x_test, name):\n    x_pred = model.predict(x_test, verbose = 1)\n    df_test['healthy'] = x_pred[:,0]\n    df_test['multiple_diseases'] = x_pred[:,1]\n    df_test['rust'] = x_pred[:,2]\n    df_test['scab'] = x_pred[:,3]\n    df_test.to_csv(name, index = None)","d1da9e7a":"def model_plot(history):\n\n    plt.plot(history.history['categorical_accuracy'])\n    plt.plot(history.history['val_categorical_accuracy'])\n    plt.title('Model accuracy')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'])\n    plt.show()\n\n    # Plot training & validation loss values\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'validation'], loc='upper left')\n    plt.show()","56cfdc17":"def print_score(model, x_test, y_test):\n    score = model.evaluate(x_test, y_test, verbose = 0)\n    print('Test loss:', score[0])\n    print('Test accuracy:', score[1])","43f83040":"from keras import backend as K\nfrom keras.layers import Layer, InputSpec\nfrom keras.legacy import interfaces\n\nclass GlobalKMaxPooling2D(Layer): #Inherits the properties of Layer class    \n    \n\n    def __init__(self, data_format=None, k = 10, **kwargs):\n        super(GlobalKMaxPooling2D, self).__init__(**kwargs)\n        self.data_format = K.normalize_data_format(data_format)\n        self.input_spec = InputSpec(ndim=4)\n        self.k = k\n\n    def compute_output_shape(self, input_shape):\n        if self.data_format == 'channels_last':\n            return (input_shape[0], input_shape[3])\n        else:\n            return (input_shape[0], input_shape[1])\n\n    def get_config(self):\n        config = {'data_format': self.data_format, 'k' : self.k}\n        base_config = super(GlobalKMaxPooling2D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n    \n        \n    def call(self, inputs):\n        if self.data_format == 'channels_last':\n            # Here first sort\n            # Then take K maximum values\n            # Then average them\n            k = self.k\n\n            input_reshaped = tf.reshape(inputs, [tf.shape(inputs)[0], -1, tf.shape(inputs)[3]])\n            input_reshaped = tf.reshape(input_reshaped, [tf.shape(input_reshaped)[0], tf.shape(input_reshaped)[2], tf.shape(input_reshaped)[1]])\n            top_k = tf.math.top_k(input_reshaped, k=k, sorted = True, name = None)[0]\n            mean = tf.keras.backend.mean(top_k, axis = 2)\n            #assert ((input_reshaped.get_shape()[0], input_reshaped.get_shape()[-1]) == mean.get_shape())\n        \n        return mean","6612e1f6":"def build_lrfn(lr_start=0.00001, lr_max=0.00005, \n               lr_min=0.00001, lr_rampup_epochs=8, \n               lr_sustain_epochs=0, lr_exp_decay=.8):\n    lr_max = lr_max #* strategy.num_replicas_in_sync\n\n    def lrfn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) \/ lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) * lr_exp_decay**(epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min\n        return lr\n    return lrfn\n\nlrfn = build_lrfn()\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)","57c000b2":"def load_generators_flow_from_directory():\n\n    from sklearn.model_selection import train_test_split\n\n    from keras.preprocessing.image import ImageDataGenerator\n\n    train_datagen = ImageDataGenerator(rescale = 1.\/255, rotation_range = 40,\n                                       width_shift_range = 0.25, height_shift_range = 0.25, \n                                       shear_range = 0.25, zoom_range = 0.25, \n                                       horizontal_flip = True, vertical_flip = True,\n                                       fill_mode = 'nearest')\n\n    directory_train = '\/kaggle\/working\/image_generator\/train'\n    directory_val = '\/kaggle\/working\/image_generator\/validation'\n    validation_datagen = ImageDataGenerator(rescale = 1.\/255)\n\n    train_generator = train_datagen.flow_from_directory(directory_train, \n                                                        target_size = (448,448),\n                                                        batch_size = 4, \n                                                        shuffle = True, \n                                                        class_mode = 'categorical')\n    \n    validation_generator = validation_datagen.flow_from_directory(directory_val,\n                                                                  target_size = (448,448),\n                                                                  batch_size = 4,\n                                                                  shuffle = True,\n                                                                  class_mode = 'categorical')    \n    return (train_generator, validation_generator)","5cd3cd21":"def build_model():\n    \n    from keras.applications.resnet import ResNet50\n    import tensorflow as tf\n    from tensorflow.keras.metrics import AUC\n    import keras\n    from keras.layers import Dense\n    from keras.models import Sequential\n    import matplotlib.pyplot as plt\n    # import efficientnet.keras as efn \n    # from keras.applications.inception_resnet_v2 import InceptionResNetV2\n    from keras.applications.xception import Xception\n        \n    input_shape = (448, 448, 3)\n    # model_efficientnet = efn.EfficientNetB5(weights='imagenet', include_top = False, input_shape = input_shape)\n    # model_resnet = ResNet50(include_top = False, weights = 'imagenet', input_shape = input_shape)\n    # model_inception = InceptionResNetV2(include_top = False, weights = 'imagenet', input_shape = input_shape)\n    model_xception = Xception(include_top = False, weights = 'imagenet', input_shape = input_shape)\n    model = Sequential()\n    # base_model =  efn.EfficientNetB7(weights='imagenet', include_top=False, pooling='avg', input_shape= input_shape)\n#         base_model = base_model.output\n\n    model.add(model_xception)\n    model.add(GlobalKMaxPooling2D(data_format = 'channels_last' , k = 20))\n    model.add(Dense(4, activation = 'softmax'))\n    \n    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy',\n                              metrics = ['categorical_accuracy', AUC()]) \n    print('Model Compiled!')\n    model.summary()\n\n    return model","2d486d11":"def save_model(name, model):\n        \"\"\" Saves the model as a Json file\"\"\"\n        # serialize model to JSON\n        model_json = model.to_json()\n        with open( str(name) + \".json\", \"w\") as json_file:\n            json_file.write(model_json)\n        # serialize weights to HDF5\n        model.save_weights(name + \".h5\")\n        # print(\"Saved model to disk\")  ","4aabbd31":"model = build_model()","be6fa6c4":"train_generator, validation_generator = load_generators_flow_from_directory()\nhistory = model.fit_generator(train_generator, epochs = 40, verbose = 1, validation_data = validation_generator,\n                              callbacks = [lr_schedule])","a8a1df9d":"name = 'Plants_balanced_xception_img448_V2'\nsave_model(name, model)","88f6520d":"# Now Data Balancing","5b92de1a":"# Model"}}