{"cell_type":{"ff645fe6":"code","61c279e6":"code","3a656625":"code","b9245ba5":"code","2f806301":"code","8125014f":"code","3db073d6":"code","3809cc2c":"code","d4ec9871":"code","e0029eef":"code","0bda50cd":"code","f7a18f26":"code","0df534eb":"code","cf20d96c":"code","7753b70f":"code","b0763515":"code","c20b0acd":"code","e0f63314":"code","e4940fb2":"code","4c6aaa7a":"code","f9eaeb12":"code","d9d01780":"code","e52e2432":"code","e2ba8078":"code","02f44014":"code","6c79d0db":"code","81bbfea3":"code","7ec5cbb3":"code","40af53a2":"code","dd62405e":"code","fc468020":"code","2337a793":"code","63c99e5b":"markdown","50bef56f":"markdown","0e6fc2da":"markdown"},"source":{"ff645fe6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","61c279e6":"original_file = pd.read_csv(\"..\/input\/india-national-education-policy2020-tweets-dataset\/NEP_2020_english_tweet.csv\")","3a656625":"original_file.head()","b9245ba5":"original_file.info()","2f806301":"#Checking for Null values\nnp.sum(original_file.isnull().any(axis=1))","8125014f":"#Dropping the first column\noriginal_file.drop(columns=[\"Unnamed: 0\",\"Author_ID\",\"User_handle\"],inplace=True)\n\noriginal_file.info()","3db073d6":"import nltk\nimport re","3809cc2c":"nltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('wordnet')\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\n\n#defining a function to get rid of stopwords, punctuation, hashtags, mentions, links, and one or two-letter words\ndef process_tweets(original_tweet):\n\n  # Removes links\n  original_tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', original_tweet, flags=re.MULTILINE)\n    \n  # Removes mentions and hashtag\n  original_tweet = re.sub(r'\\@\\w+|\\#','', original_tweet)\n    \n  # Tokenizes the words\n  tokenized = word_tokenize(original_tweet)\n\n  # Removes the stop words from the tokens\n  tokenized = [token for token in tokenized if token not in stopwords.words(\"english\")] \n\n  # Lemmatizes the adjectives in the tokens\n  tokenized = [WordNetLemmatizer().lemmatize(token, pos='a') for token in tokenized]\n\n  # Removes non-alphabetic characters and keeps the words that contain three or more letters\n  tokenized = [token for token in tokenized if token.isalpha() and len(token)>2]\n    \n  return tokenized\n\n# Applies the process tweet function to tweets and stores it in new column\noriginal_file[\"Processed\"] = original_file[\"Tweet\"].str.lower().apply(process_tweets)\n\ndisplay(original_file[[\"Processed\"]].head())","d4ec9871":"original_file.to_csv(\"new_file.csv\")","e0029eef":"new_data = pd.read_csv(\"new_file.csv\",index_col=[0])\nnew_data.head()","0bda50cd":"from textblob import TextBlob\n# Adds polarity and subjectivity column  \nnew_data[\"Polarity\"] = new_data[\"Processed\"].apply(lambda word: TextBlob(word).sentiment.polarity)\nnew_data[\"Subjectivity\"] = new_data[\"Processed\"].apply(lambda word: TextBlob(word).sentiment.subjectivity)\n\n# Display the Polarity and Subjectivity columns\nnew_data[[\"Polarity\",\"Subjectivity\",\"Tweet\"]].head()","f7a18f26":"import seaborn as sns\nimport matplotlib.pyplot as plt \n\n# Plots histogram of polarity \nplt.subplot()\nnew_data[\"Polarity\"].hist(bins=20,color='blue')\nplt.title(\"Histogram of Polarity \")\nplt.grid(b=None)","0df534eb":"# Displays the most popular tweets\nnew_data.sort_values(by=[\"Likes_on_tweet\" ], ascending=False)[[\"Tweet\",\"Likes_on_tweet\"]].head(10)","cf20d96c":"# Removes outliers\nTop_Tweets = new_data[new_data[\"Likes_on_tweet\"]<2000]\n\n# Relationship between Top tweets and polarity\nsns.relplot(x=\"Polarity\", y=\"Likes_on_tweet\", data=Top_Tweets)\n# Relationship between Top tweets and subjectivity\nsns.relplot(x=\"Subjectivity\", y=\"Likes_on_tweet\", data=Top_Tweets)","7753b70f":"# Function that classifies polarities\ndef classify_polarity(polarity):\n    if polarity > 0:\n        return \"Positive\"\n    if polarity == 0:\n        return \"Neutral\"\n    if polarity < 0:\n        return \"Negative\"\n\n# Applies the funtion on Polarity column and add the results into a new column \"Label\"\nnew_data[\"Label\"] = new_data[\"Polarity\"].apply(classify_polarity)\n\n# Displays the Polarity and Subjectivity Analysis\nnew_data[[\"Label\"]].head()","b0763515":"# Visualising the Label count\nsns.countplot(x=new_data[\"Label\"])\nplt.title(\"Polarity Scores\")\nplt.show()","c20b0acd":"# Plots pie chart\nnew_data['Label'].value_counts().plot(kind='pie',autopct='%1.0f%%')","e0f63314":"# Visualizing the Polarity scores\nplt.figure() \nsns.scatterplot(x=\"Polarity\", y=\"Subjectivity\", hue=\"Label\", data=new_data)\nplt.title(\"Subjectivity vs Polarity\")\nplt.show()","e4940fb2":"from wordcloud import WordCloud\nfrom PIL import Image\nimport urllib\nimport requests","4c6aaa7a":"positive_words = ' '.join(text for text in new_data['Processed'][new_data['Polarity']==1])\nnegative_words = ' '.join(text for text in new_data['Processed'][new_data['Polarity']==-1])\n","f9eaeb12":"# Combines the image with the dataset\nMask = np.array(Image.open(requests.get('http:\/\/clipart-library.com\/image_gallery2\/Twitter-PNG-Image.png', stream=True).raw))\n\n# Forms wordcloud\nwc = WordCloud(background_color='black', mask= Mask).generate(positive_words)\n\n# Size of the image generated \nplt.figure(figsize=(10,20))\n \nplt.imshow(wc.recolor())\nplt.axis('off')","d9d01780":"# Forms wordcloud\nwc = WordCloud(background_color='black', height=1000, width=4000).generate(negative_words)\n\n# Size of the image generated \nplt.figure(figsize=(10,20))\n \nplt.imshow(wc.recolor())\n\nplt.axis('off')","e52e2432":"from sklearn.preprocessing import LabelEncoder\n#Encodes the labels\nl = LabelEncoder()\nnew_data[\"LabelEnc\"] = l.fit_transform(new_data[\"Label\"])\ndisplay(new_data[[\"LabelEnc\"]].head())","e2ba8078":"#Selects the features and the target\nX = new_data['Processed']\ny = new_data[\"LabelEnc\"]","02f44014":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=34, stratify=y)","6c79d0db":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n# Creation the tf-idf vectorizer\nvectorizer = TfidfVectorizer()\n# Fits the vectorizer with our training set\ntfidf_train = vectorizer.fit_transform(X_train)\n# Fits our test data with the vectorizer\ntfidf_test = vectorizer.transform(X_test)","81bbfea3":"\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.metrics import f1_score\n\n# Bernoulli Naive Bayes classifier\nnb = BernoulliNB()\n# Fits the model\nnb.fit(tfidf_train, y_train)\n\n# Prints the accuracy score\naccuracy_nb = cross_val_score(nb, tfidf_test, y_test, cv=10, scoring='accuracy').mean()\nprint(\"Accuracy:\",accuracy_nb)\n\n# Prints the recall score\nrecall_nb = cross_val_score(nb, tfidf_test, y_test, cv=10, scoring='recall_weighted').mean()\nprint(\"Recall:\",recall_nb)\n\n# Prints the f1 score\nf1_nb = cross_val_score(nb, tfidf_test, y_test, cv=10, scoring='f1_weighted').mean()\nprint(\"F1 score:\",f1_nb)\n\n# Predicts the labels\ny_pred = nb.predict(tfidf_test)\n# Prints the confusion matrix \ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix\\n\")\nprint(cm)","7ec5cbb3":"from sklearn.linear_model import LogisticRegression\n\n# Logistic Regression\nlg= LogisticRegression()\n# Fit the model\nlg.fit(tfidf_train, y_train)\n\n# Prints the accuracy score\naccuracy_lg = cross_val_score(lg, tfidf_test, y_test, cv=10, scoring='accuracy').mean()\nprint(\"Accuracy:\",accuracy_lg)\n\n# Prints the recall score\nrecall_lg = cross_val_score(lg, tfidf_test, y_test, cv=10, scoring='recall_weighted').mean()\nprint(\"Recall:\",recall_lg)\n\n# Prints the f1 score\nf1_lg = cross_val_score(lg, tfidf_test, y_test, cv=10, scoring='f1_weighted').mean()\nprint(\"F1 score:\",f1_lg)\n\n# Predicts the labels\ny_pred = lg.predict(tfidf_test)\n# Prints the confusion matrix \ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix\\n\")\nprint(cm)","40af53a2":"from sklearn.tree import DecisionTreeClassifier\n\n# Decision Tree Classifier\ndct = DecisionTreeClassifier()\n# Fits the model\ndct.fit(tfidf_train, y_train)\n\n# Prints the accuracy score\naccuracy_dct = cross_val_score(dct, tfidf_test, y_test, cv=10, scoring='accuracy').max()\nprint(\"Accuracy:\",accuracy_dct)\n\n# Prints the recall score\nrecall_dct = cross_val_score(dct, tfidf_test, y_test, cv=10, scoring='recall_weighted').mean()\nprint(\"Recall:\",recall_dct)\n\n# Prints the f1 score\nf1_dct = cross_val_score(dct, tfidf_test, y_test, cv=10, scoring='f1_weighted').mean()\nprint(\"F1 score:\",f1_dct)\n\n# Predicts the labels\ny_pred = dct.predict(tfidf_test)\n# Prints the confusion matrix \ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix\\n\")\nprint(cm)","dd62405e":"Algo=['Bernoulli Naive Bayes(TF-IDF)','LogisticRegression(TF-IDF)','DecisionTree(TF-IDF)']\nscore = [accuracy_nb,accuracy_lg,accuracy_dct]\ncompare=pd.DataFrame({'Model':Algo,'Accuracy':score},index=[i for i in range(1,4)])\ncompare.T","fc468020":"Algo=['Bernoulli Naive Bayes(TF-IDF)','LogisticRegression(TF-IDF)','DecisionTree(TF-IDF)']\nscore = [f1_nb,f1_lg,f1_dct]\ncompare=pd.DataFrame({'Model':Algo,'F1 score':score},index=[i for i in range(1,4)])\ncompare.T","2337a793":"plt.figure(figsize=(18,5))\n\nsns.pointplot(x='Model',y='F1 score',data=compare)\n\nplt.title('Model Vs F1 score')\nplt.xlabel('MODEL')\nplt.ylabel('F1 SCORE')\n\nplt.show()","63c99e5b":"# **Data Visualization**","50bef56f":"# **Data Preprocessing**","0e6fc2da":"# **Building Machine Learning Model**"}}