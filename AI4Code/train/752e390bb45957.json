{"cell_type":{"00fad281":"code","9ea37408":"code","7ec98cbb":"code","711fb667":"code","284a7584":"code","55a60e85":"code","70093469":"code","8925aa2c":"code","a3d5322f":"code","37a044d5":"code","942e22a2":"code","020d4d05":"code","c73e53d8":"code","fd0309b4":"code","b828d9b2":"code","8c463541":"code","8944ce3b":"code","542e8a0f":"code","f055b51f":"code","1defb9b2":"code","8df01590":"code","f46bca5d":"code","94628f69":"code","12a7470d":"code","3f9870ae":"code","9d9ae4e6":"code","5e716e14":"code","2bdc1636":"code","2b47469f":"code","d5027d8c":"markdown","1ec34031":"markdown","f4fb8e53":"markdown","91b7eadc":"markdown","8d19d6d3":"markdown","589f6796":"markdown"},"source":{"00fad281":"import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport itertools\nimport warnings\n\nwarnings.filterwarnings('ignore')","9ea37408":"df = pd.read_csv(\"..\/input\/bikerslogistics\/Train.csv\")","7ec98cbb":"df.head().T","711fb667":"print(df.shape)\n# df.head().T","284a7584":"## Drop duplicated columns\ncombinations = list(itertools.combinations(df.columns,2))\nremove = []\nfor f1, f2 in combinations:\n    if(f1 not in remove) & (f2 not in remove):\n        if df[f1].equals(df[f2]):\n            remove.append(f1)\n\nprint(remove)\ndf['dom'] = df['Order_Confirm_Day_of_Month']\ndf['wom'] = df['Order_Confirm_Day_of_Weekday']\ndf.drop(remove, axis=1, inplace=True)","55a60e85":"## Drop irrelevant and 0 variance columns\ndrp_list = ['User_ID', 'Tranport_Vehicle', 'Latitude_Pickup', 'Longitude_Pickup', 'Latitude_Destination', 'Longitude_Destination']\ndf.drop(columns=drp_list, inplace = True)","70093469":"## fill Missing values\ndf['Temperation'] = df['Temperation'].fillna(round(df['Temperation'].mean(), 1))\n\n#-> However on Precipitation, I'm guessing if the record was not collected then it meant it was of low quantity, it did not rain at all. So I will make this into a factor - Raining or not.datetime\ndef cat_rain(value):\n    if value > 7.9:\n        return 1 # Raining\n    else:\n        return 0 # Not Raining\n\ndf['Precipitation_in_millimeters_CAT'] = df.apply(lambda df: cat_rain(df['Precipitation_in_millimeters']), axis = 1)\ndf.drop(columns = 'Precipitation_in_millimeters', inplace=True)","8925aa2c":"df['Purpose'].value_counts()","a3d5322f":"lst = ['Time_of_Order', 'Time_of_Confirmation',\t'Arrival_at_Pickup_Time', 'Pickup_Time', 'Delivery_Time']\n\nfor i in lst:\n    j = i + '_in_hours'\n    df[j] = df[i]\n    df.drop(columns = i, inplace = True)\n    df[j] = pd.to_datetime(df[j]) \n    ## corce to hours past midnight\n    df[j] = df[j].apply(lambda x: round((((x.value -1628122036000000000)\/ 10**9)\/60),2) )","37a044d5":"from sklearn.preprocessing import LabelEncoder\n\nLE = LabelEncoder()\ndf['Purpose_CAT'] = LE.fit_transform(df['Purpose']) \ndf['Platform_CAT'] = LE.fit_transform(df['Platform'])\n\ndf.drop(columns = ['Purpose', 'Platform'], inplace = True)","942e22a2":"new_Columns_list = ['Order_Day_of_Month', 'Order_Week_of_Month', 'Delivery_MonthDay',\n       'Delivery_Weekday', 'DistanceCovered_KM', 'Temperation',\n       'Precipitation_in_millimeters_CAT', 'Time_of_Order_in_hours',\n       'Time_of_Confirmation_in_hours', 'Arrival_at_Pickup_Time_in_hours',\n       'Pickup_Time_in_hours', 'Delivery_Time_in_hours', 'Purpose_CAT',\n       'Platform_CAT',\n       'Time_Elapsed_from_Pickup_to_Delivery_in_Min']\n\ndf = df[new_Columns_list]","020d4d05":"## Import Libraries\n\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_squared_log_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor","c73e53d8":"\nX = df.drop(columns='Time_Elapsed_from_Pickup_to_Delivery_in_Min').values\ny = df['Time_Elapsed_from_Pickup_to_Delivery_in_Min'].values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                    test_size=0.25,\n                                                    random_state=10)\n\nprint('Size of x_train = ', X_train.shape)\nprint('Size of x_test  = ', X_test.shape)\nprint('Size of y_train = ', y_train.shape)\nprint('Size of y_test  = ', y_test.shape)","fd0309b4":"\n## Normalizing: Feature Scaling\nsc = StandardScaler()\n\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","b828d9b2":"## Model Selection \n# -> To save computing time two models thatdid not perform well were commented \n\nmodels = []\nmodels.append(('LR', LinearRegression()))\n# models.append(('RF', RandomForestRegressor())) \nmodels.append(('RDG', Ridge()))\n# models.append(('GBR', GradientBoostingRegressor()))","8c463541":"## Model Evaluation\nresults = []\nnames = []\nfor name, model in models:\n    fit_model = model.fit(X_train, y_train)\n    y_pred = fit_model.predict(X_test)\n\n    r2 = r2_score(y_test, y_pred)\n    mse = mean_squared_error(y_test, y_pred)\n    rmse = np.sqrt(mse)\n\n    ## Cross Validation\n    cv = cross_val_score(model, X, y, cv=7)\n\n    results.append((r2_score, rmse))\n    names.append(name)\n    print()\n    print(cv)\n    print()\n    print('{}:R2 {} - RMSE {}'.format(name, round(r2, 3), rmse))","8944ce3b":"### Hyper Parameter Tuning\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = {\n    'alpha': [3, 2, 1.5, 1, .75],\n    'normalize': [True, False],\n    'max_iter': [500, 3000, 1000],\n    'tol': [3, 2, 1.5, 1, .75],\n    'solver' : ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n}\n\nRDG = Ridge()\nRDG_cv = GridSearchCV(estimator=RDG, param_grid=param_grid, verbose=0)\nRDG_cv.fit(X_train, y_train)","542e8a0f":"RDG_params = RDG_cv.best_params_\nprint(RDG_params)","f055b51f":"## Model Evaluation Function\ndef evaluate_model(model, X_test, y_test, modelName, DataImb):\n    print('------------------------------------------------')\n    print(\"Model \", modelName, end=\"\\n\")\n    print(\"Data Balancing Type \", DataImb)\n    ### Model must be ran outside the function\n    y_pred = model.predict(X_test)\n    r2 = r2_score(y_test, y_pred)\n    mse = mean_squared_error(y_test, y_pred)\n    rmse = np.sqrt(mse)\n    print(\"R2 Score\", r2)\n    print(\"RMSE\", rmse)\n    return[modelName, DataImb, r2, rmse]","1defb9b2":"# print(LR.get_params())","8df01590":"param_grid = {\n    'fit_intercept': [True, False],\n    'normalize': [True, False],\n    'copy_X': [True, False],\n    'n_jobs': [True, False]\n}\n\nLR = LinearRegression()\nLR_cv = GridSearchCV(estimator=LR, param_grid=param_grid, verbose=1)\nLR_cv.fit(X_train, y_train)","f46bca5d":"LR_params = LR_cv.best_params_\nprint(LR_params)\n\n### Pipeline\n# from sklearn.pipeline import make_pipeline\nLR_model = LinearRegression(fit_intercept = LR_params['fit_intercept'],\n                            normalize = LR_params['normalize'],\n                            copy_X = LR_params['copy_X'],\n                            n_jobs = LR_params['n_jobs'])\n#=> Fitting Model\nLR_model.fit(X_train, y_train)\n#=> Evaluate Model\nevaluate_model(LR_model, X_test, y_test, 'Tuned_Linear Regressor', \"Auctual Data\")","94628f69":"model_4 = LinearRegression()\nmodel_4.fit(X_train, y_train)\nevaluate_model(model_4, X_test, y_test, 'ORDINARY_LR', \"Auctual Data\")","12a7470d":"#=> Save\/Pickle Model\n# import pickle\n\n# model_name = \"model.pk_dsn_0805\"\n# pickle.dump(model, open(model_name, \"wb\"))","3f9870ae":"## Validation\n\ndf_2 = pd.read_csv(\"..\/input\/bikerslogistics\/test.csv\")\n\ndata_id = df_2['User_ID']\n\n## Functions\ndef cat_rain(value):\n    if value > 7.9:\n        return 1 # Raining\n    else:\n        return 0 # Not Raining\n\ndf_2['Precipitation_in_millimeters_CAT'] = df_2.apply(lambda df_2: cat_rain(df_2['Precipitation_in_millimeters']), axis=1)\ndf_2.drop(columns = 'Precipitation_in_millimeters', inplace = True)\n\ndef data_preproc(df_2):\n    df_2['Temperation'] = df_2['Temperation'].fillna(round(df_2['Temperation'].mean(), 1))\n\n    lst = ['Time_of_Order', 'Time_of_Confirmation',\t'Arrival_at_Pickup_Time', 'Pickup_Time', 'Delivery_Time']\n\n    for i in lst:\n        j = i + '_in_hours'\n        df_2[j] = df_2[i]\n        df_2.drop(columns = i, inplace = True)\n        df_2[j] = pd.to_datetime(df_2[j]) \n        ## corce to hours past midnight\n        df_2[j] = df_2[j].apply(lambda x: round((((x.value -1628122036000000000)\/ 10**9)\/3600),2) )\n\n    LE = LabelEncoder()\n    df_2['Purpose_CAT'] = LE.fit_transform(df_2['Purpose'])\n    df_2['Platform_CAT'] = LE.fit_transform(df_2['Platform'])\n\n\n    drp_list = ['User_ID', 'Tranport_Vehicle',\n                    'Latitude_Pickup', 'Longitude_Pickup',\n                    'Latitude_Destination', 'Longitude_Destination',\n                    'Order_Confirm_Day_of_Month', 'Order_Confirm_Day_of_Weekday',\n                    'Arrival_At_Pickup_MonthDay', 'Arrival_At_Pickup_Weekday',\n                    'Pickup_MonthDay', 'Pickup_WeekDay',\n                    'Purpose', 'Platform']\n\n\n    new_Columns_list = ['Order_Day_of_Month', 'Order_Week_of_Month', 'Delivery_MonthDay',\n                            'Delivery_Weekday', 'DistanceCovered_KM', 'Temperation',\n                            'Precipitation_in_millimeters_CAT', 'Time_of_Order_in_hours',\n                            'Time_of_Confirmation_in_hours', 'Arrival_at_Pickup_Time_in_hours',\n                            'Pickup_Time_in_hours', 'Delivery_Time_in_hours', 'Purpose_CAT',\n                            'Platform_CAT']\n\n\n    df_2.drop(columns=drp_list, inplace=True)\n\n    df_2 = df_2[new_Columns_list]\n\ndata_preproc(df_2)","9d9ae4e6":"sc = StandardScaler()\ndf_2 = sc.fit_transform(df_2)","5e716e14":"predict = LR_model.predict(df_2)","2bdc1636":"index_list = []\nfor i in data_id:\n    index_list.append(i)\n\nsubmission_dta = pd.DataFrame(list(zip(index_list, predict)), columns = ['User_ID','Time_Elapsed_from_Pickup_to_Delivery_in_Min'])\n\nsubmission_dta['Time_Elapsed_from_Pickup_to_Delivery_in_Min'] = round(submission_dta['Time_Elapsed_from_Pickup_to_Delivery_in_Min'], 2)\n\nsubmission_dta.head()","2b47469f":"# submission_dta.to_csv(\"submission\/submission_AMAH_AD.csv\", index=False)","d5027d8c":"## Data Cleaning\nDrop Irrelevant columns","1ec34031":"COMPLIMENTARY\u00b6\nA copy of this work can be found on this [repository](https:\/\/github.com\/AkanimohOD19A\/DSN-Deliveries-Analysis).\n\nThis work has been productionize and a real-time application can be found on this [webApp](https:\/\/delivery-stuber-dsn.herokuapp.com\/)","f4fb8e53":"## Build Model","91b7eadc":"# Prepping Submission Work\n1. Checking the model's accuracy on the validation\/test set\n1. Saving the result for submission","8d19d6d3":"Due to the numeric structure of our data the accuracy would be evaluated using the Root Mean Squared Error [RMSE] which produces the standard deviation of Predicted values from the Auctual Values, basically the lower this score the better.","589f6796":"## Model Evaluation"}}