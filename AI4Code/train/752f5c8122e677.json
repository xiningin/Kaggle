{"cell_type":{"61adbd02":"code","5c7ba717":"code","5e6a00a9":"code","992bf55e":"code","64866894":"code","0b2a65c0":"code","f013b26f":"code","e6b33787":"code","c55500c4":"code","064e4ce2":"code","9c06d602":"code","ee12047d":"code","d25aed85":"code","9405d7f3":"code","8c14bd84":"code","59759f5d":"code","9d453992":"code","36166bd2":"code","93be61b6":"code","83f51c2a":"code","e4bf98c2":"code","0300eee3":"code","15b067ce":"code","9912661c":"code","e9bf7ede":"code","147dddf1":"code","2e26af80":"code","434ec986":"code","58adabd3":"code","35609881":"code","75ffe5c0":"markdown","2bb8b454":"markdown","c02f033c":"markdown","e176314b":"markdown","74f81efc":"markdown","f2134023":"markdown","afbd00b6":"markdown","431f2679":"markdown","ccefa74f":"markdown","c78924c1":"markdown","b9ab4ed4":"markdown","8831fba4":"markdown","6a5d1d20":"markdown"},"source":{"61adbd02":"import json\nimport tensorflow as tf\nimport csv\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nprint(\"Setup Complete\")","5c7ba717":"columns = ['target', 'ids', 'date', 'flag' ,'user', 'text']","5e6a00a9":"path = '..\/input\/sentiment140\/training.1600000.processed.noemoticon.csv'\ndf = pd.read_csv(path, names = columns, encoding='latin-1')\nprint('Dataset loaded successfully.')","992bf55e":"df.head()","64866894":"df['target'].unique()","0b2a65c0":"# Check one example\ndf.iloc[-1]","f013b26f":"sentences = list(df['text'])\ndf[df['target'] == 4] = 1\nlabels = list(df['target'])\nsamples_size = len(df)","e6b33787":"labels[:5]","c55500c4":"# Check one example\nsentences[-1]","064e4ce2":"vocab_size = 100000\nmax_length = 32 # 32 words in each sentence\noov_token = \"<OOV>\"","9c06d602":"from tensorflow.keras.preprocessing.text import Tokenizer\ntokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)\ntokenizer.fit_on_texts(sentences)","ee12047d":"word_index = tokenizer.word_index\nindex_word = tokenizer.index_word","d25aed85":"# Check one example\nword_index['mother']","9405d7f3":"# check the index of one word\nindex_word[1050]","8c14bd84":"# check one example\nsentences[0]","59759f5d":"sequences = tokenizer.texts_to_sequences(sentences)","9d453992":"i = 0\nprint(sentences[i])\nprint(sequences[i])","36166bd2":"index_word[1956]","93be61b6":"from tensorflow.keras.preprocessing.sequence import pad_sequences\npadded = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')","83f51c2a":"padded[0]","e4bf98c2":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(padded, labels, test_size = 0.2, random_state = 101)\ny_train = np.array(y_train)\ny_test = np.array(y_test)","0300eee3":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","15b067ce":"embedding_dim = 100\nfrom keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, Dense, LSTM\nmodel = Sequential()\nmodel.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim ,input_length=max_length))\nmodel.add(LSTM(64))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","9912661c":"model.summary()","e9bf7ede":"num_epochs = 1\nhistory = model.fit(X_train, y_train,\n                    epochs = num_epochs, validation_data = [X_test,y_test],\n                    verbose = 1)","147dddf1":"model.evaluate(X_test, y_test)","2e26af80":"text1 = 'I hate my life, everything is awful!'\ntext2 = 'I Love my life. I like everyone and everything!'","434ec986":"seq1 = tokenizer.texts_to_sequences([text1])\npad1 = pad_sequences(seq1, maxlen=max_length, padding='post', truncating='post')\nseq2 = tokenizer.texts_to_sequences([text2])\npad2 = pad_sequences(seq2, maxlen=max_length, padding='post', truncating='post')\n\nprint(model.predict(pad1))\nprint(model.predict(pad2))","58adabd3":"def happy_sad(arr):\n    if arr[[0]] >= 0.5: # Personn is happy\n        print(\"The mood of the writer of the text is: \\U0001F60A\") # Happy face\n    else: # Personn is not happy\n        print('The mood of the writer of the text is: \\U0001F630') # Sad face","35609881":"print(text1)\nhappy_sad(model.predict(pad1))\nprint()\nprint(text2)\nhappy_sad(model.predict(pad2))","75ffe5c0":"#### Replace 4 to 1 in the 'target' column","2bb8b454":"***\n\nMany thanks for your time and consideration.\n\nSincerely,\n\nSiavash Damari \n\n[siavashdamari77@gmail.com](mailto:siavashdamari77@gmail.com) \n\n[www.linkedin.com\/in\/siavash-damari\/](https:\/\/www.linkedin.com\/in\/siavash-damari\/)","c02f033c":"### Set columns","e176314b":"### Train the model","74f81efc":"### LSTM Model","f2134023":"**Siavash Damari | [siavashdamari77@gmail.com](mailto:siavashdamari77@gmail.com) | [www.linkedin.com\/in\/siavash-damari\/](https:\/\/www.linkedin.com\/in\/siavash-damari\/)**\n***","afbd00b6":"### Context\nThis is the sentiment140 dataset. It contains 1,600,000 tweets extracted using the twitter api . The tweets have been annotated (0 = negative, 4 = positive) and they can be used to detect sentiment.","431f2679":"### Evaluate the model","ccefa74f":"### Check the 'target' column","c78924c1":"### Use Tokenizer","b9ab4ed4":"### Import Libraries","8831fba4":"### Finally, testing the model with two interesting examples!","6a5d1d20":"### Load the dataset"}}