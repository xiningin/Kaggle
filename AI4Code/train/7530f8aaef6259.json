{"cell_type":{"2d915ce8":"code","a5251d65":"code","02d960e6":"code","3c8e0882":"code","9a1f5571":"code","4f8f0208":"code","eb9ec29a":"code","f2e34fe9":"code","ef671cea":"code","4618eab3":"code","c9f61f9f":"code","d828f34b":"code","cde43f33":"code","ca0b3769":"code","7390d7df":"code","e12a4025":"code","e3a00e86":"code","4b27b89e":"code","be531ac3":"code","55e236d3":"code","07a3ba24":"code","97d598a2":"code","24f9cde4":"code","af6ea962":"markdown","496b900f":"markdown","e877f391":"markdown","83f16496":"markdown","2d0bc1b0":"markdown","5c0b75f2":"markdown","01347cbd":"markdown","3bae5051":"markdown","8ad40600":"markdown","a7a1872b":"markdown","0aa9b54a":"markdown","ce3562e6":"markdown","eda0e92f":"markdown","d84f5b37":"markdown","0246f921":"markdown","be03c0c3":"markdown","49d5e336":"markdown"},"source":{"2d915ce8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport warnings\nwarnings.simplefilter(action=\"ignore\", category=FutureWarning)\n\n# keras imports\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.preprocessing import image\nfrom keras.models import Model\nfrom keras.layers import Input\n\n# other imports\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\nimport glob\nimport cv2\nimport h5py\nimport os\nimport datetime\nimport time\nimport re\nfrom tqdm import tqdm\n\n\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","a5251d65":"# path to training dataset\ntrain_path = '..\/input\/train\/'\nlabels = pd.read_csv('..\/input\/labels.csv')\n\nmodel_dir = '..\/input\/'\nlist_images = [train_path+f for f in os.listdir(train_path) if re.search('jpg|JPG', f)]\n\nprint(list_images[0:4])\ntrain_labels = os.listdir(train_path)\n","02d960e6":"labels.head(5)\n","3c8e0882":"n = len(labels)\nbreed = set(labels['breed'])\nn_class = len(breed)\nclass_to_num = dict(zip(breed, range(n_class)))\nn_class = len(breed)\n","9a1f5571":"print(n)","4f8f0208":"print(n_class)","eb9ec29a":"\nyy = pd.value_counts(labels['breed'])\nprint(yy[0:5])","f2e34fe9":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfig, ax = plt.subplots()\nfig.set_size_inches(20,10)\nsns.set_style(\"whitegrid\")\n\nax = sns.barplot(x = yy.index, y = yy, data = labels)\nax.set_xticklabels(ax.get_xticklabels(), rotation = 90, fontsize = 10)\nax.set(xlabel='Dog Breed', ylabel='Count')\nax.set_title('Distribution of the Dog Breeds')","ef671cea":"targets_series = pd.Series(labels['breed'])\none_hot = pd.get_dummies(targets_series, sparse = True)\none_hot_labels = np.asarray(one_hot)\n","4618eab3":"import cv2\nwidth = 224\norig_label = []\nX = np.zeros((n, width, width, 3), dtype=np.uint8)\ny = np.zeros((n, n_class), dtype=np.uint8)\norig_label = []\nfor i in tqdm(range(n)):\n    X[i] = cv2.resize(cv2.imread('..\/input\/train\/%s.jpg' % labels['id'][i]), (width, width))\n    y[i] = one_hot_labels[i]\n    orig_label.append(labels['breed'][i])\n","c9f61f9f":"print(orig_label[0:5])","d828f34b":"print(\"Number of Samples:\",X.shape[0])\nprint(y.shape)\nnum_class = y.shape[1]\nprint(\"Number of training lables:\",num_class)","cde43f33":"import random\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nplt.figure(figsize=(12, 6))\nfor i in range(8):\n    random_index = random.randint(0, n-1)\n    plt.subplot(2, 4, i+1)\n    plt.imshow(X[random_index][:,:,::-1])\n    plt.title(orig_label[random_index])\n    plt.axis('off')","ca0b3769":"df_test = pd.read_csv('..\/input\/sample_submission.csv')","7390d7df":"n_test = len(df_test)\nX_test = np.zeros((n_test, width, width, 3), dtype=np.uint8)\nfor i in tqdm(range(n_test)):\n    X_test[i] = cv2.resize(cv2.imread('..\/input\/test\/%s.jpg' % df_test['id'][i]), (width, width))\n","e12a4025":"print(len(X_test))","e3a00e86":"from keras.layers import *\nfrom keras.models import *\nfrom keras.applications import *\nfrom keras.optimizers import *\nfrom keras.regularizers import *\n\ndef get_features(MODEL, data=X):\n    cnn_model = MODEL(include_top=False, input_shape=(width, width, 3), weights='imagenet')\n    \n    inputs = Input((width, width, 3))\n    x = inputs\n    x = Lambda(preprocess_input, name='preprocessing')(x)\n    x = cnn_model(x)\n    x = GlobalAveragePooling2D()(x)\n    cnn_model = Model(inputs, x)\n\n    features = cnn_model.predict(data, batch_size=64, verbose=1)\n    return features","4b27b89e":"vgg16_features = get_features(VGG16, X)","be531ac3":"inputs = Input(vgg16_features.shape[1:])\nx = inputs\nx = Dropout(0.5)(x)\nx = Dense(n_class, activation='softmax')(x)\nmodel = Model(inputs, x)\nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\nh = model.fit(vgg16_features, y, batch_size=128, epochs=10, validation_split=0.1)","55e236d3":"vgg16_feature_test = get_features(VGG16, X_test)","07a3ba24":"y_pred = model.predict(vgg16_feature_test, batch_size=128)","97d598a2":"for b in breed:\n    df_test[b] = y_pred[:,class_to_num[b]]","24f9cde4":" \ndf_test.to_csv('submission.csv', index=None)","af6ea962":"How many samples and lables do we have","496b900f":"Resize the images","e877f391":"Normalize the train data","83f16496":"Change the labels to one hot encodeded lables","2d0bc1b0":"Breed count  per label","5c0b75f2":"How many labels do we have?","01347cbd":"Distribution of breeds","3bae5051":"From the above barplot we see relevant size of sample data, each breed is having count between 65-126., which seems to be reasonable size.","8ad40600":"number of samples in the train data","a7a1872b":"Train samples","0aa9b54a":"There are 120 - breeds that are available in training set ","ce3562e6":"**Read the test data**","eda0e92f":"**Load test images**","d84f5b37":"**Feature Extraction using VGG**","0246f921":"**Loading packages and data**","be03c0c3":"**Read the training images**","49d5e336":"Resize the test images same as train"}}