{"cell_type":{"f8f799c8":"code","72929be4":"code","13413e95":"code","428617c8":"code","f71a81a9":"code","a8c45115":"code","bc723b24":"code","0a793c8b":"code","527773cf":"code","57ae35ff":"code","ed747b64":"code","ec15931c":"code","1198c515":"code","105cb774":"code","cf9588e1":"code","adfb3742":"code","eaf15713":"code","a749b34e":"code","bea93234":"code","129bfae2":"code","adb86056":"code","b7088e9e":"code","f86bad54":"code","ee1f7916":"code","223ad552":"code","27b6653e":"code","ee39e029":"code","07f29f19":"code","6019ba7e":"code","81b0e513":"code","9044a383":"code","2dcda431":"code","c9cc9fdf":"code","e543fe0e":"code","9d865142":"code","fa713506":"code","00cc0046":"code","e4b5db9a":"code","f1ec9d6b":"code","60ce483a":"code","16c1884c":"code","d7b80870":"code","082d0c79":"code","13f7e4d3":"code","9d25f804":"code","cc813862":"code","e8bb6027":"code","0565fa7f":"code","0abaf9a7":"code","98cab7f9":"code","cae76e10":"code","28ad3c3c":"code","323c6fe9":"code","e29bd1c2":"code","e3b80b31":"code","6d0674c9":"code","a12a8356":"code","13dc9de2":"code","60378866":"code","9f6e0fc8":"code","97c37da0":"code","66fb9499":"markdown","9e65450f":"markdown","2426d522":"markdown","fe058ad1":"markdown","2e06e59f":"markdown","613695a2":"markdown","819b58e1":"markdown","074b2763":"markdown","1cbe9961":"markdown","c1d1dc50":"markdown","2c51f79f":"markdown","4d558164":"markdown","b5fefb79":"markdown","69c14640":"markdown","1d388226":"markdown","aa5950b9":"markdown","cabf12bf":"markdown","9d8e872e":"markdown"},"source":{"f8f799c8":"import numpy as np\nimport pandas as pd\nimport os\nimport scipy\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.linear_model import LogisticRegression\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","72929be4":"train = pd.read_csv('\/kaggle\/input\/cat-in-the-dat\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/cat-in-the-dat\/test.csv')","13413e95":"train.head()","428617c8":"test.head()","f71a81a9":"train.nunique()","a8c45115":"train.isna().sum()","bc723b24":"bin_cols = [col  for col in train.columns.values if col.startswith('bin')]\nnom_cols = [col  for col in train.columns.values if col.startswith('nom')]\nord_cols = [col  for col in train.columns.values if col.startswith('ord')]","0a793c8b":"def ord_to_num(df, col):\n    keys=np.sort(df[col].unique())\n    values=np.arange(len(keys))\n    map = dict(zip(keys, values))\n    df[col] = df[col].replace(map)","527773cf":"ord_to_num(test, 'ord_3')\nord_to_num(train, 'ord_3')","57ae35ff":"ord_to_num(train, 'ord_4')\nord_to_num(test,'ord_4')","ed747b64":"ord_to_num(train, 'ord_5')\nord_to_num(test,'ord_5')","ec15931c":"keys_ord_1=train.ord_1.unique()\nkeys_ord_1","1198c515":"values_ord_1=[3,4,0,1,2]","105cb774":"map_ord_1 = dict(zip(keys_ord_1, values_ord_1))\nmap_ord_1","cf9588e1":"train['ord_1'] = train['ord_1'].replace(map_ord_1)\ntest['ord_1'] = test['ord_1'].replace(map_ord_1)","adfb3742":"keys_ord_2=train.ord_2.unique()\nkeys_ord_2","eaf15713":"values_ord_2=[1,3,5,4,0,2]","a749b34e":"map_ord_2 = dict(zip(keys_ord_2, values_ord_2))\nmap_ord_2","bea93234":"train['ord_2'] = train['ord_2'].replace(map_ord_2)\ntest['ord_2'] = test['ord_2'].replace(map_ord_2)","129bfae2":"train[ord_cols].head()","adb86056":"train[ord_cols].nunique()","b7088e9e":"train['ord_4_band'] = pd.qcut(train['ord_4'], 6)\nbands=train.ord_4_band.unique()\nkeys_bands=np.sort(bands)\nvalues_bands=np.arange(len(keys_bands))\nmap_bands = dict(zip(keys_bands, values_bands))","f86bad54":"train['ord_4_band'] = train['ord_4_band'].replace(map_bands)\ntest['ord_4_band']=pd.cut(test.ord_4,pd.IntervalIndex(keys_bands))","ee1f7916":"test['ord_4_band'] = test['ord_4_band'].replace(map_bands)\ntest.ord_4_band.head()","223ad552":"train['ord_5_band'] = pd.qcut(train['ord_5'], 6)\nbands=train.ord_5_band.unique()\nkeys_bands=np.sort(bands)\nvalues_bands=np.arange(len(keys_bands))\nmap_bands = dict(zip(keys_bands, values_bands))","27b6653e":"train['ord_5_band'] = train['ord_5_band'].replace(map_bands)\ntest['ord_5_band']=pd.cut(test.ord_5,pd.IntervalIndex(keys_bands))","ee39e029":"test['ord_5_band'] = test['ord_5_band'].replace(map_bands)\ntest.ord_5_band.head()","07f29f19":"train[nom_cols].nunique()","6019ba7e":"test[nom_cols].nunique()","81b0e513":"for col in [\"nom_7\", \"nom_8\", \"nom_9\"]:\n    train_vals = set(train[col].unique())\n    test_vals = set(test[col].unique())\n   \n    ex=train_vals ^ test_vals\n    if ex:\n        train.loc[train[col].isin(ex), col]=\"x\"\n        test.loc[test[col].isin(ex), col]=\"x\"","9044a383":"train[nom_cols].nunique()","2dcda431":"test[nom_cols].nunique()","c9cc9fdf":"train[train.nom_7=='x']","e543fe0e":"train=train[train.nom_7!='x']","9d865142":"train[train.nom_7=='x']","fa713506":"labelEnc=LabelEncoder()","00cc0046":"for col in nom_cols:\n    train[col]=labelEnc.fit_transform(train[col])\n    test[col]=labelEnc.fit_transform(test[col])\n","e4b5db9a":"train[nom_cols].head()","f1ec9d6b":"train[bin_cols].head()","60ce483a":"for col in ['bin_3', 'bin_4']:\n    train[col]=labelEnc.fit_transform(train[col])\n    test[col]=labelEnc.fit_transform(test[col])\n","16c1884c":"test[bin_cols].head()","d7b80870":"X_temp=train.drop('target', axis=1)\nY=train.target","082d0c79":"from sklearn.mixture import GaussianMixture","13f7e4d3":"gm = GaussianMixture(n_components=4)\ngm.fit(X_temp)","9d25f804":"X_temp['Gaussian_Mixture']=gm.predict(X_temp)","cc813862":"test['Gaussian_Mixture']=gm.predict(test)","e8bb6027":"X_oh_temp=pd.get_dummies(X_temp.drop('id', axis=1), columns=X_temp.drop('id', axis=1).columns, drop_first=True, sparse=True)","0565fa7f":"X_oh=scipy.sparse.csr_matrix(X_oh_temp.values)","0abaf9a7":"X_oh","98cab7f9":"test_oh_temp=pd.get_dummies(test.drop('id', axis=1), columns=test.drop('id', axis=1).columns, drop_first=True, sparse=True)","cae76e10":"test_oh_temp.shape","28ad3c3c":"test_oh=scipy.sparse.csr_matrix(test_oh_temp.values)","323c6fe9":"X_train, X_valid, Y_train, Y_valid = train_test_split(X_oh, \n                                                      Y, \n                                                      test_size = 0.20,\n                                                      random_state=42)\n","e29bd1c2":"lr=LogisticRegression(C=0.15, solver=\"lbfgs\", tol=0.00005, max_iter=10000)  \n\nlr.fit(X_train, Y_train)","e3b80b31":"y_pred_lr=lr.predict_proba(X_valid)","6d0674c9":"roc_auc_score(Y_valid.values, y_pred_lr[:,1])","a12a8356":"lr.fit(X_oh, Y)","13dc9de2":"y_pred=lr.predict_proba(X_oh)\nroc_auc_score(Y.values, y_pred[:,1])","60378866":"test_pred_lr=lr.predict_proba(test_oh)","9f6e0fc8":"output_dict = {'id': test.id,\n                       'target': test_pred_lr[:,1]}\n\n\noutput = pd.DataFrame(output_dict, columns = ['id', 'target'])\noutput.head(10)","97c37da0":"output.to_csv('submission_One_Hot.csv', index=False)","66fb9499":"## One-Hot Encoding","9e65450f":"We will one-hot encode all features.","2426d522":"We are going to stratify ord_4 and ord_5.","fe058ad1":"We do the same for the test set.","2e06e59f":"Now we create column classes defined by their type of data.","613695a2":"Now we take a look at the bin_cols.","819b58e1":"## This kernel use tuning from the my kernel [Logistic Regression with my tuning](https:\/\/www.kaggle.com\/vbmokin\/logistic-regression-with-my-tuning)","074b2763":"We need to encode the data. The next functio converts the original data to integer using map from keys to values. The keys are generated by a sorted array of the unique strings of the column, the values by an array of integers from 0 to the length of the keys, or by a manually sorted array.","1cbe9961":"We split X_oh into train and validation sets.","c1d1dc50":"# Import and explore data","2c51f79f":"## Nominal Columns","4d558164":"Now we label encode the nom_cols.","b5fefb79":"# Logistic Regression","69c14640":"## Ordinal Columns","1d388226":"We see that the are columns with different number of values on the train and test set.  We will\nchange those values with the same one","aa5950b9":"# This kernel based on the kernel [One-Hot, Stratified, Logistic Regression](https:\/\/www.kaggle.com\/bustam\/one-hot-stratified-logistic-regression) ","cabf12bf":"We need to encode bin_3 and bin_4.","9d8e872e":"## Binary Columns"}}