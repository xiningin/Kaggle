{"cell_type":{"2be7f167":"code","450815cf":"code","315e9eac":"code","7fbce151":"code","94377815":"code","210d185f":"code","2410e2f9":"code","1bbbcc2d":"code","1fdef9ab":"code","7e2f2b14":"code","28a69d21":"code","a52a4458":"code","86b53587":"code","c755a0d5":"code","3a2059de":"code","db08c993":"code","03ef693b":"code","e1e95146":"code","4a4fd215":"code","4d963702":"code","7f0afd30":"code","8ba225ee":"code","288bcc5f":"code","ef37fff2":"code","d6aa2b0f":"code","98e64b53":"code","e962d9ae":"code","ebbefdd0":"code","e81ae3eb":"code","a21cadcf":"code","c091d450":"code","0f77be7b":"code","a453073a":"code","b7453ef5":"code","bdb3ecb2":"code","4462cfdb":"code","e61681b1":"code","407ecdcd":"code","561bed08":"code","af58f81c":"code","71f578e6":"code","9bb5fe8e":"code","46978a59":"code","cee906e0":"code","953d0853":"code","01d6a044":"markdown","f353c5be":"markdown","ad8b129c":"markdown","0fc38e45":"markdown","e7a64879":"markdown","222ebb9a":"markdown","a6568ab0":"markdown","72082eeb":"markdown","1e0a25e3":"markdown","092d52d5":"markdown","8aef5cee":"markdown","d8b1ea3e":"markdown","d4cc5991":"markdown","aae91e01":"markdown","9b8f8b58":"markdown","63c6117f":"markdown","c260b6c9":"markdown","2663531b":"markdown","8e007b29":"markdown","dd302ebc":"markdown","a102390f":"markdown","fc1f7aa2":"markdown","2e4c768d":"markdown","feb7452a":"markdown","3a7f79c3":"markdown","759b94c1":"markdown","c4f5361c":"markdown","71e4741f":"markdown","41b71731":"markdown","1f07da55":"markdown","fab8f5c9":"markdown","f588d1e2":"markdown","7c346bf5":"markdown","284c1b0a":"markdown","473e9bf5":"markdown","befe67e3":"markdown","2f3fcf65":"markdown","737cf297":"markdown","f6afff34":"markdown","29ef7792":"markdown","8cf4e97d":"markdown","cf01fff9":"markdown","cc0934a1":"markdown","64c30484":"markdown","cc13dfa7":"markdown","e3aeae6e":"markdown","d4269479":"markdown"},"source":{"2be7f167":"import numpy as np\nimport pandas as pd\n\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.io as pio\npio.templates.default = \"plotly_dark\"\nfrom plotly.subplots import make_subplots\nimport folium \nfrom folium import plugins\nfrom tqdm.notebook import tqdm as tqdm\n\n\nfrom pathlib import Path\ndata_dir = Path('..\/input\/covid19-global-forecasting-week-1')\n\nimport os\nos.listdir(data_dir)\n\nimport warnings\nwarnings.filterwarnings('ignore')","450815cf":"data = pd.read_csv(data_dir\/'train.csv',parse_dates=['Date'])\ndata.head()","315e9eac":"cleaned_data = pd.read_csv('..\/input\/corona-virus-report\/covid_19_clean_complete.csv', parse_dates=['Date'])\ncleaned_data.head()","7fbce151":"# cases \ncases = ['Confirmed', 'Deaths', 'Recovered', 'Active']\n\n# Active Case = confirmed - deaths - recovered\ncleaned_data['Active'] = cleaned_data['Confirmed'] - cleaned_data['Deaths'] - cleaned_data['Recovered']\n\n# filling missing values \ncleaned_data[['Province\/State']] = cleaned_data[['Province\/State']].fillna('')\ncleaned_data[cases] = cleaned_data[cases].fillna(0)\n\ncleaned_data.head()","94377815":"# Creating a dataframe with total no of cases for every country\nconfirmiedcases = pd.DataFrame(cleaned_data.groupby('Country\/Region')['Confirmed'].sum())\nconfirmiedcases['Country\/Region'] = confirmiedcases.index\nconfirmiedcases.index = np.arange(1,181)\n\nDeathcases = pd.DataFrame(cleaned_data.groupby('Country\/Region')['Deaths'].sum())\nDeathcases['Country\/Region'] = Deathcases.index\nDeathcases.iodex = np.arange(1,181)\n\nRecoveredcases = pd.DataFrame(cleaned_data.groupby('Country\/Region')['Recovered'].sum())\nRecoveredcases['Country\/Region'] = Recoveredcases.index\nRecoveredcases.iodex = np.arange(1,181)\n\nActivecases = pd.DataFrame(cleaned_data.groupby('Country\/Region')['Active'].sum())\nActivecases['Country\/Region'] = Activecases.index\nActivecases.iodex = np.arange(1,181)\n\nglobal_Activecases = Activecases[['Country\/Region','Active']]\nglobal_Deathcases = Deathcases[['Country\/Region','Deaths']]\nglobal_Recoveredcases = Recoveredcases[['Country\/Region','Recovered']]\nglobal_confirmiedcases = confirmiedcases[['Country\/Region','Confirmed']]\n\nfig = px.bar(global_confirmiedcases.sort_values('Confirmed',ascending=False)[:20][::-1],x='Confirmed',y='Country\/Region',title='Confirmed Cases Worldwide',text='Confirmed', height=900, orientation='h')\nfig.show()\n\nfig = px.bar(global_Deathcases.sort_values('Deaths',ascending=False)[:20][::-1],x='Deaths',y='Country\/Region',title='Deaths Cases Worldwide',text='Deaths', height=900, orientation='h')\nfig.show()\n\nfig = px.bar(global_Recoveredcases.sort_values('Recovered',ascending=False)[:20][::-1],x='Recovered',y='Country\/Region',title='Recovered Cases Worldwide',text='Recovered', height=900, orientation='h')\nfig.show()\n\nfig = px.bar(global_Activecases.sort_values('Active',ascending=False)[:20][::-1],x='Active',y='Country\/Region',title='Active Cases Worldwide',text='Active', height=900, orientation='h')\nfig.show()","210d185f":"date_c = cleaned_data.groupby('Date')['Confirmed','Deaths','Recovered','Active'].sum().reset_index()\n\n\nfrom plotly.subplots import make_subplots\nfig = make_subplots(rows=1, cols=4, subplot_titles=(\"Comfirmed\", \"Deaths\", \"Recovered\",'Active'))\n\ntrace1 = go.Scatter(\n                x=date_c['Date'],\n                y=date_c['Confirmed'],\n                name=\"Confirmed\",\n                line_color='orange',\n                mode='lines+markers',\n                opacity=0.8)\ntrace2 = go.Scatter(\n                x=date_c['Date'],\n                y=date_c['Deaths'],\n                name=\"Deaths\",\n                line_color='red',\n                mode='lines+markers',\n                opacity=0.8)\n\ntrace3 = go.Scatter(\n                x=date_c['Date'],\n                y=date_c['Recovered'],\n                name=\"Recovered\",\n                mode='lines+markers',\n                line_color='green',\n                opacity=0.8)\n\ntrace4 = go.Scatter(\n                x=date_c['Date'],\n                y=date_c['Active'],\n                name=\"Active\",\n                line_color='blue',\n                mode='lines+markers',\n                opacity=0.8)\n\nfig.append_trace(trace1, 1, 1)\nfig.append_trace(trace2, 1, 2)\nfig.append_trace(trace3, 1, 3)\nfig.append_trace(trace4, 1, 4)\nfig.update_layout(template=\"plotly_dark\",title_text = '<b>Global Spread of the Coronavirus Over Time <\/b>',\n                  font=dict(family=\"Arial, Balto, Courier New, Droid Sans\",color='white'))\nfig.show()","2410e2f9":"grouped_china = cleaned_data[cleaned_data['Country\/Region'] == \"China\"].reset_index()\ngrouped_china_date = grouped_china.groupby('Date')['Date', 'Confirmed', 'Deaths','Recovered','Active'].sum().reset_index()\n\ngrouped_italy = cleaned_data[cleaned_data['Country\/Region'] == \"Italy\"].reset_index()\ngrouped_italy_date = grouped_italy.groupby('Date')['Date', 'Confirmed', 'Deaths','Recovered','Active'].sum().reset_index()\n\ngrouped_iran = cleaned_data[cleaned_data['Country\/Region'] == \"Iran\"].reset_index()\ngrouped_iran_date = grouped_iran.groupby('Date')['Date', 'Confirmed', 'Deaths','Recovered','Active'].sum().reset_index()\n\ngrouped_korea = cleaned_data[cleaned_data['Country\/Region'] == \"South Korea\"].reset_index()\ngrouped_korea_date = grouped_korea.groupby('Date')['Date', 'Confirmed', 'Deaths','Recovered','Active'].sum().reset_index()\n\ngrouped_spain = cleaned_data[cleaned_data['Country\/Region'] == \"Spain\"].reset_index()\ngrouped_spain_date = grouped_spain.groupby('Date')['Date', 'Confirmed', 'Deaths','Recovered','Active'].sum().reset_index()\n\ngrouped_rest = cleaned_data[~cleaned_data['Country\/Region'].isin(['China', 'Italy', 'iran', 'South Korea', 'Spain'])].reset_index()\ngrouped_rest_date = grouped_rest.groupby('Date')['Date', 'Confirmed', 'Deaths','Recovered','Active'].sum().reset_index()","1bbbcc2d":"fig = make_subplots(rows=1, cols=4, subplot_titles=(\"Comfirmed\", \"Deaths\", \"Recovered\",'Active'))\n\ntrace1 = go.Scatter(x=grouped_china_date['Date'],y=grouped_china_date['Confirmed'],name=\"Confirmed\",line_color='orange',mode='lines+markers',opacity=0.8)\ntrace2 = go.Scatter(x=grouped_china_date['Date'],y=grouped_china_date['Deaths'],name=\"Deaths\",line_color='red',mode='lines+markers',opacity=0.8)\ntrace3 = go.Scatter(x=grouped_china_date['Date'],y=grouped_china_date['Recovered'],name=\"Recovered\",mode='lines+markers',line_color='green',opacity=0.8)\ntrace4 = go.Scatter(x=grouped_china_date['Date'],y=grouped_china_date['Active'],name=\"Active\",line_color='blue',mode='lines+markers',opacity=0.8)\n\nfig.append_trace(trace1, 1, 1)\nfig.append_trace(trace2, 1, 2)\nfig.append_trace(trace3, 1, 3)\nfig.append_trace(trace4, 1, 4)\nfig.update_layout(template=\"plotly_dark\",title_text = '<b>Spread of the Coronavirus Over Time in CHINA (TOP 1)<\/b>',\n                  font=dict(family=\"Arial, Balto, Courier New, Droid Sans\",color='white'))\nfig.show()\n\n\n# create map and display it\nlatitude = 39.91666667\nlongitude = 116.383333\nworld_map = folium.Map(location=[latitude, longitude], zoom_start=3.5,tiles='Stamen Toner')\n\nfor lat, lon, Confirmed,Deaths,Recovered,name in zip(grouped_china['Lat'], grouped_china['Long'], grouped_china['Confirmed'],grouped_china['Deaths'],grouped_china['Recovered'], grouped_china['Country\/Region']):\n    folium.CircleMarker([lat, lon],\n                        radius=10,\n                        popup = ('<strong>Country<\/strong>: ' + str(name).capitalize() + '<br>'\n                                '<strong>Confirmed Cases<\/strong>: ' + str(Confirmed) + '<br>'\n                                '<strong>Recovered Cases<\/strong>: ' + str(Recovered) +'<br>'\n                                '<strong>Deaths Cases<\/strong>: ' + str(Deaths) +'<br>'),\n                        color='red',\n                        \n                        fill_color='red',\n                        fill_opacity=0.7 ).add_to(world_map)\nworld_map","1fdef9ab":"fig = make_subplots(rows=1, cols=4, subplot_titles=(\"Comfirmed\", \"Deaths\", \"Recovered\",'Active'))\n\ntrace1 = go.Scatter(x=grouped_italy_date['Date'],y=grouped_italy_date['Confirmed'],name=\"Confirmed\",line_color='orange',mode='lines+markers',opacity=0.8)\ntrace2 = go.Scatter(x=grouped_italy_date['Date'],y=grouped_italy_date['Deaths'],name=\"Deaths\",line_color='red',mode='lines+markers',opacity=0.8)\ntrace3 = go.Scatter(x=grouped_italy_date['Date'],y=grouped_italy_date['Recovered'],name=\"Recovered\",mode='lines+markers',line_color='green',opacity=0.8)\ntrace4 = go.Scatter(x=grouped_italy_date['Date'],y=grouped_italy_date['Active'],name=\"Active\",line_color='blue',mode='lines+markers',opacity=0.8)\n\nfig.append_trace(trace1, 1, 1)\nfig.append_trace(trace2, 1, 2)\nfig.append_trace(trace3, 1, 3)\nfig.append_trace(trace4, 1, 4)\nfig.update_layout(template=\"plotly_dark\",title_text = '<b>Global Spread of the Coronavirus Over Time in ITALY (TOP 2)<\/b>',\n                  font=dict(family=\"Arial, Balto, Courier New, Droid Sans\",color='white'))\nfig.show()","7e2f2b14":"fig = make_subplots(rows=1, cols=4, subplot_titles=(\"Comfirmed\", \"Deaths\", \"Recovered\",'Active'))\n\ntrace1 = go.Scatter(x=grouped_iran_date['Date'],y=grouped_iran_date['Confirmed'],name=\"Confirmed\",line_color='orange',mode='lines+markers',opacity=0.8)\ntrace2 = go.Scatter(x=grouped_iran_date['Date'],y=grouped_iran_date['Deaths'],name=\"Deaths\",line_color='red',mode='lines+markers',opacity=0.8)\ntrace3 = go.Scatter(x=grouped_iran_date['Date'],y=grouped_iran_date['Recovered'],name=\"Recovered\",mode='lines+markers',line_color='green',opacity=0.8)\ntrace4 = go.Scatter(x=grouped_iran_date['Date'],y=grouped_iran_date['Active'],name=\"Active\",line_color='blue',mode='lines+markers',opacity=0.8)\n\nfig.append_trace(trace1, 1, 1)\nfig.append_trace(trace2, 1, 2)\nfig.append_trace(trace3, 1, 3)\nfig.append_trace(trace4, 1, 4)\nfig.update_layout(template=\"plotly_dark\",title_text = '<b>Global Spread of the Coronavirus Over Time in IRAN (TOP 3)<\/b>',\n                  font=dict(family=\"Arial, Balto, Courier New, Droid Sans\",color='white'))\nfig.show()","28a69d21":"fig = make_subplots(rows=1, cols=4, subplot_titles=(\"Comfirmed\", \"Deaths\", \"Recovered\",'Active'))\n\ntrace1 = go.Scatter(x=grouped_korea_date['Date'],y=grouped_korea_date['Confirmed'],name=\"Confirmed\",line_color='orange',mode='lines+markers',opacity=0.8)\ntrace2 = go.Scatter(x=grouped_korea_date['Date'],y=grouped_korea_date['Deaths'],name=\"Deaths\",line_color='red',mode='lines+markers',opacity=0.8)\ntrace3 = go.Scatter(x=grouped_korea_date['Date'],y=grouped_korea_date['Recovered'],name=\"Recovered\",mode='lines+markers',line_color='green',opacity=0.8)\ntrace4 = go.Scatter(x=grouped_korea_date['Date'],y=grouped_korea_date['Active'],name=\"Active\",line_color='blue',mode='lines+markers',opacity=0.8)\n\nfig.append_trace(trace1, 1, 1)\nfig.append_trace(trace2, 1, 2)\nfig.append_trace(trace3, 1, 3)\nfig.append_trace(trace4, 1, 4)\nfig.update_layout(template=\"plotly_dark\",title_text = '<b>Global Spread of the Coronavirus Over Time in South Korea (TOP 4)<\/b>',\n                  font=dict(family=\"Arial, Balto, Courier New, Droid Sans\",color='white'))\nfig.show()","a52a4458":"fig = make_subplots(rows=1, cols=4, subplot_titles=(\"Comfirmed\", \"Deaths\", \"Recovered\",'Active'))\n\ntrace1 = go.Scatter(x=grouped_spain_date['Date'],y=grouped_spain_date['Confirmed'],name=\"Confirmed\",line_color='orange',mode='lines+markers',opacity=0.8)\ntrace2 = go.Scatter(x=grouped_spain_date['Date'],y=grouped_spain_date['Deaths'],name=\"Deaths\",line_color='red',mode='lines+markers',opacity=0.8)\ntrace3 = go.Scatter(x=grouped_spain_date['Date'],y=grouped_spain_date['Recovered'],name=\"Recovered\",mode='lines+markers',line_color='green',opacity=0.8)\ntrace4 = go.Scatter(x=grouped_spain_date['Date'],y=grouped_spain_date['Active'],name=\"Active\",line_color='blue',mode='lines+markers',opacity=0.8)\n\nfig.append_trace(trace1, 1, 1)\nfig.append_trace(trace2, 1, 2)\nfig.append_trace(trace3, 1, 3)\nfig.append_trace(trace4, 1, 4)\nfig.update_layout(template=\"plotly_dark\",title_text = '<b>Global Spread of the Coronavirus Over Time in SPAIN (TOP 5)<\/b>',\n                  font=dict(family=\"Arial, Balto, Courier New, Droid Sans\",color='white'))\nfig.show()","86b53587":"fig = make_subplots(rows=1, cols=4, subplot_titles=(\"Comfirmed\", \"Deaths\", \"Recovered\",'Active'))\n\ntrace1 = go.Scatter(x=grouped_rest_date['Date'],y=grouped_rest_date['Confirmed'],name=\"Confirmed\",line_color='orange',mode='lines+markers',opacity=0.8)\ntrace2 = go.Scatter(x=grouped_rest_date['Date'],y=grouped_rest_date['Deaths'],name=\"Deaths\",line_color='red',mode='lines+markers',opacity=0.8)\ntrace3 = go.Scatter(x=grouped_rest_date['Date'],y=grouped_rest_date['Recovered'],name=\"Recovered\",mode='lines+markers',line_color='green',opacity=0.8)\ntrace4 = go.Scatter(x=grouped_rest_date['Date'],y=grouped_rest_date['Active'],name=\"Active\",line_color='blue',mode='lines+markers',opacity=0.8)\n\nfig.append_trace(trace1, 1, 1)\nfig.append_trace(trace2, 1, 2)\nfig.append_trace(trace3, 1, 3)\nfig.append_trace(trace4, 1, 4)\nfig.update_layout(template=\"plotly_dark\",title_text = '<b>Global Spread of the Coronavirus Over Time in REST OF ALL OTHER <\/b>',\n                  font=dict(family=\"Arial, Balto, Courier New, Droid Sans\",color='white'))\nfig.show()\n\n# create map and display it\nworld_map = folium.Map(location=[10, -20], zoom_start=2.5,tiles='Stamen Toner')\n\nfor lat, lon, Confirmed,Deaths,Recovered,name in zip(grouped_rest['Lat'], grouped_rest['Long'], grouped_rest['Confirmed'],grouped_rest['Deaths'],grouped_rest['Recovered'], grouped_rest['Country\/Region']):\n    folium.CircleMarker([lat, lon],\n                        radius=7,\n                        popup = ('<strong>Country<\/strong>: ' + str(name).capitalize() + '<br>'\n                                '<strong>Confirmed Cases<\/strong>: ' + str(Confirmed) + '<br>'\n                                '<strong>Recovered Cases<\/strong>: ' + str(Recovered) +'<br>'\n                                '<strong>Deaths Cases<\/strong>: ' + str(Deaths) +'<br>'),\n                        color='red',\n                        \n                        fill_color='red',\n                        fill_opacity=0.7 ).add_to(world_map)\nworld_map","c755a0d5":"temp = cleaned_data.groupby('Date')['Recovered', 'Deaths', 'Active'].sum().reset_index()\ntemp = temp.melt(id_vars=\"Date\", value_vars=['Recovered', 'Deaths', 'Active'],\n                 var_name='case', value_name='count')\n\n\nfig = px.area(temp, x=\"Date\", y=\"count\", color='case',\n             title='Cases over time: Area Plot', color_discrete_sequence = ['cyan', 'red', 'orange'])\nfig.show()","3a2059de":"rest = cleaned_data[cleaned_data['Country\/Region'] != 'China']\nrest_grouped = rest.groupby('Date')['Recovered', 'Deaths', 'Active'].sum().reset_index()\n\ntemp = rest_grouped.melt(id_vars=\"Date\", value_vars=['Recovered', 'Deaths', 'Active'],\n                 var_name='case', value_name='count')\n\n\nfig = px.area(temp, x=\"Date\", y=\"count\", color='case',\n             title='Cases - Rest of the World: Area Plot', color_discrete_sequence = ['cyan', 'red', 'orange'])\nfig.show()","db08c993":"cleaned_latest = cleaned_data[cleaned_data['Date'] == max(cleaned_data['Date'])]\nflg = cleaned_latest.groupby('Country\/Region')['Confirmed', 'Deaths', 'Recovered', 'Active'].sum().reset_index()\n\nflg['mortalityRate'] = round((flg['Deaths']\/flg['Confirmed'])*100, 2)\ntemp = flg[flg['Confirmed']>100]\ntemp = temp.sort_values('mortalityRate', ascending=False)\n\nfig = px.bar(temp.sort_values(by=\"mortalityRate\", ascending=False)[:10][::-1],\n             x = 'mortalityRate', y = 'Country\/Region', \n             title='Deaths per 100 Confirmed Cases', text='mortalityRate', height=800, orientation='h',\n             color_discrete_sequence=['darkred']\n            )\nfig.show()","03ef693b":"formated_gdf = cleaned_data.groupby(['Date', 'Country\/Region'])['Confirmed', 'Deaths'].max()\nformated_gdf = formated_gdf.reset_index()\nformated_gdf['Date'] = pd.to_datetime(formated_gdf['Date'])\nformated_gdf['Date'] = formated_gdf['Date'].dt.strftime('%m\/%d\/%Y')\nformated_gdf['size'] = formated_gdf['Confirmed'].pow(0.3)\n\nfig = px.scatter_geo(formated_gdf, locations=\"Country\/Region\", locationmode='country names', \n                     color=\"Confirmed\", size='size', hover_name=\"Country\/Region\", \n                     range_color= [0, 1500], \n                     projection=\"natural earth\", animation_frame=\"Date\", \n                     title='COVID-19: Spread Over Time', color_continuous_scale=\"portland\")\n# fig.update(layout_coloraxis_showscale=False)\nfig.show()","e1e95146":"formated_gdf = cleaned_data.groupby(['Date', 'Country\/Region'])['Confirmed', 'Deaths'].max()\nformated_gdf = formated_gdf.reset_index()\nformated_gdf['Date'] = pd.to_datetime(formated_gdf['Date'])\nformated_gdf['Date'] = formated_gdf['Date'].dt.strftime('%m\/%d\/%Y')\nformated_gdf['size'] = formated_gdf['Deaths'].pow(0.3)\n\nfig = px.scatter_geo(formated_gdf, locations=\"Country\/Region\", locationmode='country names', \n                     color=\"Deaths\", size='size', hover_name=\"Country\/Region\", \n                     range_color= [0, 100], \n                     projection=\"natural earth\", animation_frame=\"Date\", \n                     title='COVID-19: Deaths Over Time', color_continuous_scale=\"peach\")\n# fig.update(layout_coloraxis_showscale=False)\nfig.show()","4a4fd215":"formated_gdf = cleaned_data.groupby(['Date', 'Country\/Region'])['Confirmed', 'Deaths', 'Active', 'Recovered'].max()\nformated_gdf = formated_gdf.reset_index()\nformated_gdf['Date'] = pd.to_datetime(formated_gdf['Date'])\nformated_gdf['Date'] = formated_gdf['Date'].dt.strftime('%m\/%d\/%Y')\nformated_gdf['size'] = formated_gdf['Active'].pow(0.3)\nformated_gdf['size'].fillna(formated_gdf['size'].mean(),inplace=True)\n\nfig = px.scatter_geo(formated_gdf, locations=\"Country\/Region\", locationmode='country names', \n                     color=\"Active\", size='size', hover_name=\"Country\/Region\", \n                     range_color= [0, 1000], \n                     projection=\"natural earth\", animation_frame=\"Date\", \n                     title='COVID-19: Active Cases Over Time', color_continuous_scale=\"portland\")\nfig.update(layout_coloraxis_showscale=False)\nfig.show()","4d963702":"train_dataset = pd.read_csv('..\/input\/novel-corona-virus-2019-dataset\/time_series_covid_19_confirmed.csv')\ndrop_clo = ['Province\/State','Country\/Region','Lat','Long']\ntrain_dataset=train_dataset.drop(drop_clo,axis=1)\ndatewise= list(train_dataset.columns)\nval_dataset = train_dataset[datewise[-30:]]","7f0afd30":"fig = make_subplots(rows=3, cols=1)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines+markers', y=train_dataset.loc[0].values, marker=dict(color=\"dodgerblue\"), showlegend=False,),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[0].values, mode='lines+markers', marker=dict(color=\"darkorange\"), showlegend=False,),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines+markers', y=train_dataset.loc[1].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[1].values, mode='lines+markers', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines+markers', y=train_dataset.loc[2].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[2].values, mode='lines+markers', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.update_layout(height=1200, width=800, title_text=\"Train (blue) vs. Validation (orange) sales\")\nfig.show()","8ba225ee":"predictions = []\nfor i in range(len(val_dataset.columns)):\n    if i == 0:\n        predictions.append(train_dataset[train_dataset.columns[-1]].values)\n    else:\n        predictions.append(val_dataset[val_dataset.columns[i-1]].values)\n    \npredictions = np.transpose(np.array([row.tolist() for row in predictions]))\nerror_naive = np.linalg.norm(predictions[:3] - val_dataset.values[:3])\/len(predictions[0])","288bcc5f":"pred_1 = predictions[0]\npred_2 = predictions[1]\npred_3 = predictions[2]\n\nfig = make_subplots(rows=3, cols=1)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines', y=train_dataset.loc[0].values, marker=dict(color=\"dodgerblue\"),\n               name=\"Train\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[0].values, mode='lines', marker=dict(color=\"darkorange\"),\n               name=\"Val\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=pred_1, mode='lines', marker=dict(color=\"seagreen\"),\n               name=\"Pred\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines', y=train_dataset.loc[1].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[1].values, mode='lines', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=pred_2, mode='lines', marker=dict(color=\"seagreen\"), showlegend=False,\n               name=\"Denoised signal\"),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines', y=train_dataset.loc[2].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[2].values, mode='lines', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=pred_3, mode='lines', marker=dict(color=\"seagreen\"), showlegend=False,\n               name=\"Denoised signal\"),\n    row=3, col=1\n)\n\nfig.update_layout(height=1200, width=800, title_text=\"Naive approach\")\nfig.show()","ef37fff2":"predictions = []\nfor i in range(len(val_dataset.columns)):\n    if i == 0:\n        predictions.append(np.mean(train_dataset[train_dataset.columns[-30:]].values, axis=1))\n    if i < 31 and i > 0:\n        predictions.append(0.5 * (np.mean(train_dataset[train_dataset.columns[-30+i:]].values, axis=1) + \\\n                                  np.mean(predictions[:i], axis=0)))\n    if i > 31:\n        predictions.append(np.mean([predictions[:i]], axis=1))\n    \npredictions = np.transpose(np.array([row.tolist() for row in predictions]))\nerror_avg = np.linalg.norm(predictions[:3] - val_dataset.values[:3])\/len(predictions[0])","d6aa2b0f":"pred_1 = predictions[0]\npred_2 = predictions[1]\npred_3 = predictions[2]\n\nfig = make_subplots(rows=3, cols=1)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines', y=train_dataset.loc[0].values, marker=dict(color=\"dodgerblue\"),\n               name=\"Train\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[0].values, mode='lines', marker=dict(color=\"darkorange\"),\n               name=\"Val\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=pred_1, mode='lines', marker=dict(color=\"seagreen\"),\n               name=\"Pred\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines', y=train_dataset.loc[1].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[1].values, mode='lines', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=pred_2, mode='lines', marker=dict(color=\"seagreen\"), showlegend=False,\n               name=\"Denoised signal\"),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines', y=train_dataset.loc[2].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[2].values, mode='lines', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=pred_3, mode='lines', marker=dict(color=\"seagreen\"), showlegend=False,\n               name=\"Denoised signal\"),\n    row=3, col=1\n)\n\nfig.update_layout(height=1200, width=800, title_text=\"Moving average\")\nfig.show()","98e64b53":"from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n\npredictions = []\nfor row in tqdm(train_dataset[train_dataset.columns[-30:]].values[:3]):\n    fit = Holt(row).fit(smoothing_level = 0.3, smoothing_slope = 0.01)\n    predictions.append(fit.forecast(30))\npredictions = np.array(predictions).reshape((-1, 30))\nerror_holt = np.linalg.norm(predictions - val_dataset.values[:len(predictions)])\/len(predictions[0])","e962d9ae":"pred_1 = predictions[0]\npred_2 = predictions[1]\npred_3 = predictions[2]\n\nfig = make_subplots(rows=3, cols=1)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines', y=train_dataset.loc[0].values, marker=dict(color=\"dodgerblue\"),\n               name=\"Train\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[0].values, mode='lines', marker=dict(color=\"darkorange\"),\n               name=\"Val\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=pred_1, mode='lines', marker=dict(color=\"seagreen\"),\n               name=\"Pred\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines', y=train_dataset.loc[1].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[1].values, mode='lines', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=pred_2, mode='lines', marker=dict(color=\"seagreen\"), showlegend=False,\n               name=\"Denoised signal\"),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines', y=train_dataset.loc[2].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[2].values, mode='lines', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=pred_3, mode='lines', marker=dict(color=\"seagreen\"), showlegend=False,\n               name=\"Denoised signal\"),\n    row=3, col=1\n)\n\nfig.update_layout(height=1200, width=800, title_text=\"Holt linear\")\nfig.show()","ebbefdd0":"predictions = []\nfor row in tqdm(train_dataset[train_dataset.columns[-30:]].values[:3]):\n    fit = ExponentialSmoothing(row, seasonal_periods=3).fit()\n    predictions.append(fit.forecast(30))\npredictions = np.array(predictions).reshape((-1, 30))\nerror_exponential = np.linalg.norm(predictions[:3] - val_dataset.values[:3])\/len(predictions[0])","e81ae3eb":"pred_1 = predictions[0]\npred_2 = predictions[1]\npred_3 = predictions[2]\n\nfig = make_subplots(rows=3, cols=1)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines', y=train_dataset.loc[0].values, marker=dict(color=\"dodgerblue\"),\n               name=\"Train\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[0].values, mode='lines', marker=dict(color=\"darkorange\"),\n               name=\"Val\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=pred_1, mode='lines', marker=dict(color=\"seagreen\"),\n               name=\"Pred\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines', y=train_dataset.loc[1].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[1].values, mode='lines', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=pred_2, mode='lines', marker=dict(color=\"seagreen\"), showlegend=False,\n               name=\"Denoised signal\"),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines', y=train_dataset.loc[2].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[2].values, mode='lines', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=pred_3, mode='lines', marker=dict(color=\"seagreen\"), showlegend=False,\n               name=\"Denoised signal\"),\n    row=3, col=1\n)\n\nfig.update_layout(height=1200, width=800, title_text=\"Exponential smoothing\")\nfig.show()","a21cadcf":"import statsmodels.api as sm\nfrom statsmodels.tsa.arima_model import ARIMA\n\npredictions = []\nfor row in tqdm(train_dataset[train_dataset.columns[-30:]].values[:3]):\n    fit = sm.tsa.statespace.SARIMAX(row, seasonal_order=(0, 1, 1, 7)).fit()\n    predictions.append(fit.forecast(30))\npredictions = np.array(predictions).reshape((-1, 30))\nerror_arima = np.linalg.norm(predictions[:3] - val_dataset.values[:3])\/len(predictions[0])","c091d450":"pred_1 = predictions[0]\npred_2 = predictions[1]\npred_3 = predictions[2]\n\nfig = make_subplots(rows=3, cols=1)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines', y=train_dataset.loc[0].values, marker=dict(color=\"dodgerblue\"),\n               name=\"Train\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[0].values, mode='lines', marker=dict(color=\"darkorange\"),\n               name=\"Val\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=pred_1, mode='lines', marker=dict(color=\"seagreen\"),\n               name=\"Pred\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines', y=train_dataset.loc[1].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[1].values, mode='lines', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=pred_2, mode='lines', marker=dict(color=\"seagreen\"), showlegend=False,\n               name=\"Denoised signal\"),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines', y=train_dataset.loc[2].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[2].values, mode='lines', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=pred_3, mode='lines', marker=dict(color=\"seagreen\"), showlegend=False,\n               name=\"Denoised signal\"),\n    row=3, col=1\n)\n\nfig.update_layout(height=1200, width=800, title_text=\"ARIMA\")\nfig.show()","0f77be7b":"train_dataset = pd.read_csv('..\/input\/novel-corona-virus-2019-dataset\/time_series_covid_19_deaths.csv')\ndrop_clo = ['Province\/State','Country\/Region','Lat','Long']\ntrain_dataset=train_dataset.drop(drop_clo,axis=1)\ndatewise= list(train_dataset.columns)\nval_dataset = train_dataset[datewise[-30:]]","a453073a":"fig = make_subplots(rows=3, cols=1)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines+markers', y=train_dataset.loc[0].values, marker=dict(color=\"dodgerblue\"), showlegend=False,),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[0].values, mode='lines+markers', marker=dict(color=\"darkorange\"), showlegend=False,),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines+markers', y=train_dataset.loc[1].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[1].values, mode='lines+markers', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines+markers', y=train_dataset.loc[2].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[2].values, mode='lines+markers', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.update_layout(height=1200, width=800, title_text=\"Train (blue) vs. Validation (orange) sales\")\nfig.show()","b7453ef5":"predictions = []\nfor i in range(len(val_dataset.columns)):\n    if i == 0:\n        predictions.append(train_dataset[train_dataset.columns[-1]].values)\n    else:\n        predictions.append(val_dataset[val_dataset.columns[i-1]].values)\n    \npredictions = np.transpose(np.array([row.tolist() for row in predictions]))\nerror_naive = np.linalg.norm(predictions[:3] - val_dataset.values[:3])\/len(predictions[0])","bdb3ecb2":"pred_1 = predictions[0]\npred_2 = predictions[1]\npred_3 = predictions[2]\n\nfig = make_subplots(rows=3, cols=1)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines', y=train_dataset.loc[0].values, marker=dict(color=\"dodgerblue\"),\n               name=\"Train\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[0].values, mode='lines', marker=dict(color=\"darkorange\"),\n               name=\"Val\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=pred_1, mode='lines', marker=dict(color=\"seagreen\"),\n               name=\"Pred\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines', y=train_dataset.loc[1].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[1].values, mode='lines', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=pred_2, mode='lines', marker=dict(color=\"seagreen\"), showlegend=False,\n               name=\"Denoised signal\"),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines', y=train_dataset.loc[2].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[2].values, mode='lines', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=pred_3, mode='lines', marker=dict(color=\"seagreen\"), showlegend=False,\n               name=\"Denoised signal\"),\n    row=3, col=1\n)\n\nfig.update_layout(height=1200, width=800, title_text=\"Naive approach\")\nfig.show()","4462cfdb":"predictions = []\nfor i in range(len(val_dataset.columns)):\n    if i == 0:\n        predictions.append(np.mean(train_dataset[train_dataset.columns[-30:]].values, axis=1))\n    if i < 31 and i > 0:\n        predictions.append(0.5 * (np.mean(train_dataset[train_dataset.columns[-30+i:]].values, axis=1) + \\\n                                  np.mean(predictions[:i], axis=0)))\n    if i > 31:\n        predictions.append(np.mean([predictions[:i]], axis=1))\n    \npredictions = np.transpose(np.array([row.tolist() for row in predictions]))\nerror_avg = np.linalg.norm(predictions[:3] - val_dataset.values[:3])\/len(predictions[0])","e61681b1":"pred_1 = predictions[0]\npred_2 = predictions[1]\npred_3 = predictions[2]\n\nfig = make_subplots(rows=3, cols=1)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines', y=train_dataset.loc[0].values, marker=dict(color=\"dodgerblue\"),\n               name=\"Train\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[0].values, mode='lines', marker=dict(color=\"darkorange\"),\n               name=\"Val\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=pred_1, mode='lines', marker=dict(color=\"seagreen\"),\n               name=\"Pred\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines', y=train_dataset.loc[1].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[1].values, mode='lines', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=pred_2, mode='lines', marker=dict(color=\"seagreen\"), showlegend=False,\n               name=\"Denoised signal\"),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines', y=train_dataset.loc[2].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[2].values, mode='lines', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=pred_3, mode='lines', marker=dict(color=\"seagreen\"), showlegend=False,\n               name=\"Denoised signal\"),\n    row=3, col=1\n)\n\nfig.update_layout(height=1200, width=800, title_text=\"Moving average\")\nfig.show()","407ecdcd":"train_dataset = pd.read_csv('..\/input\/novel-corona-virus-2019-dataset\/time_series_covid_19_recovered.csv')\ndrop_clo = ['Province\/State','Country\/Region','Lat','Long']\ntrain_dataset=train_dataset.drop(drop_clo,axis=1)\ndatewise= list(train_dataset.columns)\nval_dataset = train_dataset[datewise[-30:]]","561bed08":"fig = make_subplots(rows=3, cols=1)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines+markers', y=train_dataset.loc[0].values, marker=dict(color=\"dodgerblue\"), showlegend=False,),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[0].values, mode='lines+markers', marker=dict(color=\"darkorange\"), showlegend=False,),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines+markers', y=train_dataset.loc[1].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[1].values, mode='lines+markers', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines+markers', y=train_dataset.loc[2].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[2].values, mode='lines+markers', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.update_layout(height=1200, width=800, title_text=\"Train (blue) vs. Validation (orange) sales\")\nfig.show()","af58f81c":"predictions = []\nfor i in range(len(val_dataset.columns)):\n    if i == 0:\n        predictions.append(train_dataset[train_dataset.columns[-1]].values)\n    else:\n        predictions.append(val_dataset[val_dataset.columns[i-1]].values)\n    \npredictions = np.transpose(np.array([row.tolist() for row in predictions]))\nerror_naive = np.linalg.norm(predictions[:3] - val_dataset.values[:3])\/len(predictions[0])","71f578e6":"pred_1 = predictions[0]\npred_2 = predictions[1]\npred_3 = predictions[2]\n\nfig = make_subplots(rows=3, cols=1)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines', y=train_dataset.loc[0].values, marker=dict(color=\"dodgerblue\"),\n               name=\"Train\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[0].values, mode='lines', marker=dict(color=\"darkorange\"),\n               name=\"Val\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=pred_1, mode='lines', marker=dict(color=\"seagreen\"),\n               name=\"Pred\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines', y=train_dataset.loc[1].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[1].values, mode='lines', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=pred_2, mode='lines', marker=dict(color=\"seagreen\"), showlegend=False,\n               name=\"Denoised signal\"),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines', y=train_dataset.loc[2].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[2].values, mode='lines', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=pred_3, mode='lines', marker=dict(color=\"seagreen\"), showlegend=False,\n               name=\"Denoised signal\"),\n    row=3, col=1\n)\n\nfig.update_layout(height=1200, width=800, title_text=\"Naive approach\")\nfig.show()","9bb5fe8e":"predictions = []\nfor i in range(len(val_dataset.columns)):\n    if i == 0:\n        predictions.append(np.mean(train_dataset[train_dataset.columns[-30:]].values, axis=1))\n    if i < 31 and i > 0:\n        predictions.append(0.5 * (np.mean(train_dataset[train_dataset.columns[-30+i:]].values, axis=1) + \\\n                                  np.mean(predictions[:i], axis=0)))\n    if i > 31:\n        predictions.append(np.mean([predictions[:i]], axis=1))\n    \npredictions = np.transpose(np.array([row.tolist() for row in predictions]))\nerror_avg = np.linalg.norm(predictions[:3] - val_dataset.values[:3])\/len(predictions[0])","46978a59":"pred_1 = predictions[0]\npred_2 = predictions[1]\npred_3 = predictions[2]\n\nfig = make_subplots(rows=3, cols=1)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines', y=train_dataset.loc[0].values, marker=dict(color=\"dodgerblue\"),\n               name=\"Train\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[0].values, mode='lines', marker=dict(color=\"darkorange\"),\n               name=\"Val\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=pred_1, mode='lines', marker=dict(color=\"seagreen\"),\n               name=\"Pred\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines', y=train_dataset.loc[1].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[1].values, mode='lines', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=pred_2, mode='lines', marker=dict(color=\"seagreen\"), showlegend=False,\n               name=\"Denoised signal\"),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines', y=train_dataset.loc[2].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[2].values, mode='lines', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=pred_3, mode='lines', marker=dict(color=\"seagreen\"), showlegend=False,\n               name=\"Denoised signal\"),\n    row=3, col=1\n)\n\nfig.update_layout(height=1200, width=800, title_text=\"Moving average\")\nfig.show()","cee906e0":"full_latest_grouped = cleaned_data.groupby('Country\/Region')['Confirmed', 'Deaths', 'Recovered', 'Active'].sum().reset_index()\nepidemics = pd.DataFrame({\n    'epidemic' : ['COVID-19', 'SARS', 'EBOLA', 'MERS', 'H1N1'],\n    'start_year' : [2019, 2003, 2014, 2012, 2009],\n    'end_year' : [2020, 2004, 2016, 2017, 2010],\n    'confirmed' : [full_latest_grouped['Confirmed'].sum(), 8096, 28646, 2494, 6724149],\n    'deaths' : [full_latest_grouped['Deaths'].sum(), 774, 11323, 858, 19654]\n})\n\nepidemics['mortality'] = round((epidemics['deaths']\/epidemics['confirmed'])*100, 2)\n\nepidemics.head()","953d0853":"temp = epidemics.melt(id_vars='epidemic', value_vars=['confirmed', 'deaths', 'mortality'],\n                      var_name='Case', value_name='Value')\n\nfig = px.bar(temp, x=\"epidemic\", y=\"Value\", color='epidemic', text='Value', facet_col=\"Case\",\n             color_discrete_sequence = px.colors.qualitative.Bold)\nfig.update_traces(textposition='outside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\nfig.update_yaxes(showticklabels=False)\nfig.layout.yaxis2.update(matches=None)\nfig.layout.yaxis3.update(matches=None)\nfig.show()","01d6a044":"The cleaned data from [COVID-19 Complete Dataset (Updated every 24hrs)](https:\/\/www.kaggle.com\/imdevskp\/corona-virus-report) is used for visualizations.","f353c5be":"<font size=5 style=\"color:red\"> Please give an UPVOTE if you like this notebook<\/font>","ad8b129c":"## Comparison with similar Disease","0fc38e45":"## Mortality and Recovery Rates\u00b6\n\n**It is worth seeing these stats as well. It might have a story for sure.**","e7a64879":"## Naive approach <a id=\"3.2\"><\/a>:","222ebb9a":"We can see that the forecasts made by the naive approach are not that accurate and it is to be expected of such a simple model. We need more complex models that use several time stamps to make forecasts.","a6568ab0":"## COVID-19: Active Cases Over Time","72082eeb":"# Preprocessing","1e0a25e3":"**lets see the sample data points**","092d52d5":"**so by we can we can upderstand that**\n\n* china is the most Confirmed , Deaths , Recovered and having Active people as china is teh population and adter the COVID-19 by taking care they are now with most\n    Active people\n* followed by  Italy , Iran ,South Korea ,Spain in top 4 places and then the rest of the Countries \n* so lets make visualizations accordingly to the above result ","8aef5cee":"## SPAIN ","d8b1ea3e":"## Next Update \n\n* actually i am working on <font size=4 style=\"color:red\"> Drug discovery<\/font> ,soon i will update with the Drug discovery for COVID-19 .\n* will update the notebook with latest data ","d4cc5991":"## Introduction (Although it doesn't need any) \n\n\n<img align=\"left\" src=\"https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcS7ovkoWSZdub9adLaiuFEdXYUzjZ6bSSNXPA6vT3z3gmCccuMr\"><\/img>\n\n\n\n\n# Corona Virus\n\n   * Coronaviruses are **zoonotic** viruses (means transmitted between animals and people).  \n   * Symptoms include from fever, cough, respiratory symptoms, and breathing difficulties. \n   * In severe cases, it can cause pneumonia, severe acute respiratory syndrome (SARS), kidney failure and even death.\n   * Coronaviruses are also **asymptomatic**, means a person can be a carrier for the infection but experiences no symptoms\n\n# Novel coronavirus (nCoV)\n* A **novel coronavirus (nCoV)** is a new strain that has not been previously identified in humans.\n\n# COVID-19 (Corona Virus Disease 2019)\n* Caused by a **SARS-COV-2** corona virus.  \n* First identified in **Wuhan, Hubei, China**. Earliest reported symptoms reported in **November 2019**. \n* First cases were linked to contact with the Huanan Seafood Wholesale Market, which sold live animals. \n* On **30 January** the WHO declared the outbreak to be a **Public Health Emergency of International Concern** ","aae91e01":"# time_series_covid_19_deaths","9b8f8b58":"Taking China out of the equation to see the effects elsewhere.","63c6117f":"# Modeling <a id=\"3\"><\/a>\n\nNow, I will demonstrate how sales can be forecasted using various methods, namely: **naive approach, moving average, Holt linear, exponential smoothing, ARIMA, and Prophet**\n\n## Train\/Val split <a id=\"3.1\"><\/a>\n\nFirst, we need to create miniature training and validation sets to train and validate our models. I will take the last 30 days as the validation data and the 70 days before that as the training data. We need to predict the sales in the validation data using the sales in the training data.","c260b6c9":"# time_series_covid_19_confirmed","2663531b":"* Below are the sales from three sample data points. I will use these samples to demonstrate the working of the models.","8e007b29":"## References and Acknowledgements\n**Data:**\n* [Novel Coronavirus (COVID-19) Cases, provided by JHU CSSE](https:\/\/github.com\/CSSEGISandData\/COVID-19)\n\n* [COVID19 Global Forecasting (Week 1)](https:\/\/www.kaggle.com\/c\/covid19-global-forecasting-week-1)\n\n* [Novel Corona Virus 2019 Dataset](https:\/\/www.kaggle.com\/sudalairajkumar\/novel-corona-virus-2019-dataset)\n\n* [COVID-19 Complete Dataset (Updated every 24hrs)](https:\/\/www.kaggle.com\/imdevskp\/corona-virus-report)","dd302ebc":"## Holt linear <a id=\"3.4\"><\/a>\n\nThe **Holt linear** is completely different from the first two methods. Holt linear attempts to capture the high-level trends in the time series data and fits the data with a straight line. The method can be summarized as follows:\n\n### Forecast, level, and trend equations respectively","a102390f":"## COVID-19: Deaths Over Time","fc1f7aa2":"## ARIMA <a id=\"3.6\"><\/a>\n\nAutoregressive integrated moving average (ARIMA) models were popularised by Box and Jenkins (1970). An ARIMA model describes a univariate time series as a combination of autoregressive (AR) and moving average (MA) lags which capture the autocorrelation within the time series. The order of integration denotes how many times the series has been differenced to obtain a stationary series.\n\nWe write an ARIMA(p,d,q) model for some time series data yt, where p is the number of autoregressive lags, d is the degree of differencing and q is the number of moving average lags as:\n\n![](https:\/\/www.machinelearningplus.com\/wp-content\/uploads\/2019\/02\/Equation-3-min.png)\n\nARIMA models are associated with a Box-Jenkins approach to time series. According to this approach, you should difference the series until it is stationary, and then use information criteria and autocorrelation plots to choose the appropriate lag order for an ARIMA process. You then apply inference to obtain latent variable estimates, and check the model to see whether the model has captured the autocorrelation in the time series. For example, you can plot the autocorrelation of the model residuals. Once you are happy, you can use the model for retrospection and forecasting.","2e4c768d":"## Cleaning Data","feb7452a":"## SOUTH KOREA ","3a7f79c3":"<img src=\"https:\/\/i.imgur.com\/MHgcgGo.png\" width=\"180px\">\n<img src=\"https:\/\/i.imgur.com\/3ImRHEO.png\" width=\"300px\">\n<img src=\"https:\/\/i.imgur.com\/XExnvMX.png\" width=\"300px\">\n\n\nIn the above equations, $\\alpha$ and $\\beta$ are constants which can be configured. The values *l<sub>t<\/sub>* and *b<sub>t<\/sub>* represent the **level** and **trend** values repsectively. The trend value is the slope of the linear forecast function and the level value is the *y*-intercept of the linear forecast function. The slope and *y*-intercept values are continuously updated using the second and third update equations. Finally, the slope and *y*-intercept are used to calculate the forecast *y<sub>t+h<\/sub>* (in equation 1), which is *h* time steps ahead of the current time step. Now let us see how this model performs on our miniature dataset. The training data is in <font color=\"blue\">blue<\/font>, validation data in <font color=\"darkorange\">orange<\/font>, and predictions in <font color=\"green\">green<\/font>.","759b94c1":"## STAY SAFE \n\n## actually i am working on <font size=4 style=\"color:red\"> Drug discovery<\/font> ,soon i will update with the Drug discovery for COVID-19 .\n\n<font size=4 style=\"color:red\"> PLEASE upvote the notebook if you like thank you<\/font> ","c4f5361c":"## Naive approach <a id=\"3.2\"><\/a>\n\n\nThe first approach is the very simple **naive approach**. It simply forecasts the next day's sales as the current day's sales. The model can be summarized as:\n\n<img src=\"https:\/\/i.imgur.com\/r8wjrzk.png\" width=\"120px\">\n\nIn the above equation, y<sub>t+1<\/sub> is the predicted value for the next day's sales and y<sub>t<\/sub> is today's sales. The model predicts tomorrow's sales as today's sales. Now let us see how this simple model performs on our miniature dataset. The training data is in <font color=\"blue\">blue<\/font>, validation data in <font color=\"darkorange\">orange<\/font>, and predictions in <font color=\"green\">green<\/font>.","71e4741f":"## COVID-19: Spread Over Time","41b71731":"## ITALY","1f07da55":"* There have now been more than 81,000 cases in China, and the death toll has reached 3,277.\n* we can ","fab8f5c9":"## REST OF THE WORLD ","f588d1e2":"## IRAN ","7c346bf5":"## Comparisions\n\n**How about comparing the cases to better assess the situation**","284c1b0a":"## Moving average <a id=\"3.3\"><\/a>:","473e9bf5":"**lets just see Confirmed , Deaths , Recovered abd Active in world wide in all over Country\/Region and lets dig deeper into the top 5 Country\/Region **","befe67e3":"## Moving average <a id=\"3.3\"><\/a>\n\nThe **moving average** method is more complex than the naive approach. It calculates the mean sales over the previous 30 days and forecasts that as the next day's sales. This method takes the previous 30 timesteps into consideration, and is therefore less prone to short term fluctuations than the naive approach. The model can be summarized as:\n\n<img src=\"https:\/\/i.imgur.com\/5uJvt7H.png\" width=\"220px\">\n\nIn the above equation, y<sub>t+1<\/sub> is tomorrow's sales. On the right hand side, all the sales for the previous 30 days are added up and divided by 30 to find the average. This forms the model's prediction, y<sub>t+1<\/sub>. Now let us see how this new model performs on our miniature dataset. The training data is in <font color=\"blue\">blue<\/font>, validation data in <font color=\"darkorange\">orange<\/font>, and predictions in <font color=\"green\">green<\/font>.","2f3fcf65":"https:\/\/www.kaggle.com\/imdevskp\/covid19-vs-sars-vs-mers-vs-ebola-vs-h1n1","737cf297":"* Active cases rising up completely all together leaving recoveries way behind and deaths also staring to increase and might see a big rise if the trend continues.\n* China's recent recovery waves might be the reason for so much from this graph.","f6afff34":"lets see sample data first to make the visual of the predictions better ","29ef7792":"**now we will see the Forcasting of all the important attribute like <font size=4 style=\"color:red\"> Confirmed<\/font>,<font size=4 style=\"color:red\"> Deaths<\/font>,<font size=4 style=\"color:red\"> Recovered<\/font> **","8cf4e97d":"# time_series_covid_19_recovered","cf01fff9":"## CHINA ","cc0934a1":"* the adove is visual is the Global Spread of the COVID-19 in all over time \n* the Comfirmed id cases are more than 350K and Deaths is more than 14K \n* the Recovered is more tha 100K and the active is nearly 200K","64c30484":"## Exponential smoothing <a id=\"3.5\"><\/a>\n\nThe **exponential smoothing** method uses a different type of \"smoothing\" which differs from average smoothing. The previous time steps are exponentially weighted and added up to generate the forecast. The weights decay as we move further backwards in time. The model can be summarized as follows:\n\n<img src=\"https:\/\/i.imgur.com\/IqqjOFc.png\" width=\"520px\">\n<img src=\"https:\/\/i.imgur.com\/GiyHyZf.png\" width=\"255px\">\n\nIn the above equations, $\\alpha$ is the smoothing parameter. The forecast *y<sub>t+1<\/sub>* is a weighted average of all the observations in the series *y<sub>1<\/sub>, \u2026 ,y<sub>t<\/sub>*. The rate at which the weights decay is controlled by the parameter \u03b1. This method gives different weightage to different time steps, instead of giving the same weightage to all time steps (like the moving average method). This ensures that recent sales data is given more importance than old sales data while making the forecast. Now let us see how this new smoothing method performs on our miniature dataset. The training data is in <font color=\"blue\">blue<\/font>, validation data in <font color=\"darkorange\">orange<\/font>, and predictions in <font color=\"green\">green<\/font>.","cc13dfa7":"## Naive approach <a id=\"3.2\"><\/a>:","e3aeae6e":"lets see sample data first to make the visual of the predictions better ","d4269479":"## Moving average <a id=\"3.3\"><\/a>:"}}