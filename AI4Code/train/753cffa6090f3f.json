{"cell_type":{"c752a582":"code","7950c853":"code","166b3363":"code","7a161cdd":"code","5bbd46c4":"code","696c546a":"code","87c90335":"code","6b3d8293":"code","a20c6c29":"code","1065b3ee":"code","1836db93":"code","3d0d7f7e":"code","192267b4":"code","a08c8be2":"code","d1bc4716":"code","5e9d1f77":"code","59fb8280":"code","b78f6672":"code","36991d40":"code","36e91221":"code","872582b5":"code","1de01503":"code","73414c3d":"code","5cf63ef1":"code","68c81b12":"code","4558131f":"code","b2f95591":"code","4bed7566":"code","17fe26f3":"code","4c8d8838":"code","9edfcf82":"code","a06ff953":"code","2681fc58":"code","fdd1eb70":"code","ef1d75f5":"code","1bda8fea":"code","a5690460":"code","06d89d37":"code","b983b5f1":"code","dc97cdef":"code","970a991f":"markdown","bcb22f53":"markdown","196ff397":"markdown","ced7c24e":"markdown","bcb705a8":"markdown","12553cfb":"markdown","722b74fb":"markdown","8ccb0e1c":"markdown","7123fce4":"markdown","a45be333":"markdown","797368f9":"markdown","b8dd5ca8":"markdown","c6f8a8cf":"markdown","8952ca61":"markdown","f35762b8":"markdown","28071858":"markdown","9e1cccbb":"markdown","34686106":"markdown","3a56a0e1":"markdown","9c532af5":"markdown","9fa380ab":"markdown","70be6eee":"markdown","89b0be71":"markdown","e28cb433":"markdown","cade9ba4":"markdown","9dee7dd3":"markdown","ead37a91":"markdown","ee5f08b9":"markdown","0c723bac":"markdown","29f17435":"markdown","1f00cba0":"markdown","c8fde4ae":"markdown","dd0da6c5":"markdown","68cfd4d6":"markdown"},"source":{"c752a582":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom collections import Counter\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\n\nsns.set(style='white', context='notebook', palette='deep')\n","7950c853":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","166b3363":"# Load train and Test data\n\ntrain = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\n\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n\n","7a161cdd":"df_all =  pd.concat([train, test], axis=0).reset_index(drop=True)","5bbd46c4":"train.head(3)","696c546a":"train.shape","87c90335":"train.info()","6b3d8293":"train.isnull().sum()","a20c6c29":"train.describe()","1065b3ee":"plt.figure(figsize=(15,15))\ncor=train.corr()\nsns.heatmap(cor,annot=True,cmap=plt.cm.Reds)\nplt.show()","1836db93":"test.shape","3d0d7f7e":"test.isnull().sum()","192267b4":"plt.figure(figsize=(15,15))\ncor=test.corr()\nsns.heatmap(cor,annot=True,cmap=plt.cm.Reds)\nplt.show()","a08c8be2":"df_all.groupby(\"Embarked\").Embarked.count()","d1bc4716":"df_all['Embarked']=df_all['Embarked'].fillna('S')\ndf_all.isnull().sum()","5e9d1f77":"median_fare = df_all.groupby('Pclass').Fare.median()[3]\n# median_fare\ndf_all['Fare'] = df_all['Fare'].fillna(median_fare)","59fb8280":"df_all_correlation = df_all.corr().abs().unstack().sort_values(kind=\"quicksort\", ascending=False).reset_index()\ndf_all_correlation.rename(columns={\"level_0\": \"col-1\", \"level_1\": \"col-2\", 0: 'Coefficient'}, inplace=True)\ndf_all_correlation[df_all_correlation['col-1'] == 'Age']","b78f6672":"df_all.groupby(['Sex', 'Pclass'])['Age'].median()","36991d40":"df_all['Age'] = df_all.groupby(['Sex', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))","36e91221":"# Let's drop Cabin column since it has more than 70% of missing values\ndf_all.drop(\"Cabin\",axis=1,inplace=True)","872582b5":"# Let's drop Ticket column since it hasn't any informative data to be extracted\ndf_all.drop([\"Ticket\",\"PassengerId\"],axis=1,inplace=True)","1de01503":"# Split the titles from the names\ndf_all=df_all.copy()\ndf_all['Title'] = df_all.Name.str.extract(' ([A-Za-z]+)\\.')","73414c3d":"pd.crosstab(df_all['Title'], df_all['Sex'])","5cf63ef1":"df_all['Title'] = df_all['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Other')\ndf_all['Title'] = df_all['Title'].replace('Mlle', 'Miss')\ndf_all['Title'] = df_all['Title'].replace('Ms', 'Miss')\ndf_all['Title'] = df_all['Title'].replace('Mme', 'Mrs')","68c81b12":"df_all.drop(['Name'], axis=1,inplace=True)\npd.crosstab(df_all['Title'], df_all['Sex'])","4558131f":"sns.factorplot('Pclass','Survived',order=[1,2,3], data=df_all,size=5)","b2f95591":"\ndf_all=df_all.copy()\n\n# Introduce new dummy variables for Pclass column, & drop 3rd class as it has the lowest average of survived passengers\n\npclass_dummies  = pd.get_dummies(df_all['Pclass'])\npclass_dummies.columns = ['Class_1','Class_2','Class_3']\npclass_dummies.drop(['Class_3'], axis=1, inplace=True)\n\ndf_all.drop(['Pclass'],axis=1,inplace=True)\n\ndf_all = df_all.join(pclass_dummies)\ndf_all","4bed7566":"# Creating new feature called Have_Family\n# we can create one column that represents whether if the passenger had any family member(siblings\/parents\/children..) with or not\ndf_all=df_all.copy()\ndf_all['Have_Family'] =  df_all[\"Parch\"] + df_all[\"SibSp\"]\ndf_all['Have_Family'].loc[df_all['Have_Family'] > 0] = 1\ndf_all['Have_Family'].loc[df_all['Have_Family'] == 0] = 0\n\n\n# drop Parch & SibSp\ndf_all = df_all.drop(['SibSp','Parch'], axis=1)\n\n# plot\nfig, (axis1,axis2) = plt.subplots(1,2,sharex=True,figsize=(10,5))\nsns.countplot(x='Have_Family', data=df_all, order=[1,0], ax=axis1)\n\n# average of survived for those who had\/didn't have any family member\nwith_fam_survived_percentage = df_all[[\"Have_Family\", \"Survived\"]].groupby(['Have_Family'],as_index=False).mean()\n\nsns.barplot(x='Have_Family', y='Survived', data=with_fam_survived_percentage, order=[1,0], ax=axis2)\n\naxis1.set_xticklabels([\"Have Family\",\"Single\"], rotation=0)","17fe26f3":"\ndf_all=df_all.copy()\n\nsns.factorplot('Embarked','Survived', data=df_all,size=4,aspect=3)\n\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(15,5))\nsns.countplot(x='Embarked', data=df_all, ax=axis1)\nsns.countplot(x='Survived', hue=\"Embarked\", data=df_all, order=[1,0], ax=axis2)\n\n\nembark_perc = df_all[[\"Embarked\", \"Survived\"]].groupby(['Embarked'],as_index=False).mean()\nsns.barplot(x='Embarked', y='Survived', data=embark_perc,order=['S','C','Q'],ax=axis3)\n\n\n\nembark_dummies_titanic  = pd.get_dummies(df_all['Embarked'])\n\n# S column can be droped since it contributes to low survival percentage\nembark_dummies_titanic.drop(['S'], axis=1, inplace=True)\n\ndf_all = df_all.join(embark_dummies_titanic)\ndf_all.drop(['Embarked'], axis=1,inplace=True)\n","4c8d8838":"df_all['Fare'] = pd.qcut(df_all['Fare'], 13)\ndf_all","9edfcf82":"df_all['Age'] = pd.qcut(df_all['Age'], 10)\ndf_all","a06ff953":"df_all.head(4)","2681fc58":"non_numeric_features_list = ['Title', 'Sex', 'Age', 'Fare']\nfor feature in non_numeric_features_list:\n    df_all[feature] = LabelEncoder().fit_transform(df_all[feature])\ndf_all","fdd1eb70":"cat_features = [ 'Sex', 'Title', 'Have_Family']\nencoded_features = []\n\n\nfor feature in cat_features:\n    encoded_feat = OneHotEncoder().fit_transform(df_all[feature].values.reshape(-1, 1)).toarray()\n    n = df_all[feature].nunique()\n    cols = ['{}_{}'.format(feature, n) for n in range(1, n + 1)]\n    encoded_df = pd.DataFrame(encoded_feat, columns=cols)\n    encoded_df.index = df_all.index\n    encoded_features.append(encoded_df)\n\ndf_all = pd.concat([df_all, *encoded_features[:6]], axis=1)\ndf_all","ef1d75f5":"df_all.columns","1bda8fea":"drop_cols=[ 'Sex','Title', 'Have_Family']\n","a5690460":"# define training and testing sets\nX_train=df_all.copy()[:len(train)]\nY_train=X_train.pop(\"Survived\")\nX_test  = df_all.copy()[len(train):]\nX_test.pop(\"Survived\")","06d89d37":"X_train = StandardScaler().fit_transform(X_train.drop(columns=drop_cols))\nX_test = StandardScaler().fit_transform(X_test.drop(columns=drop_cols))","b983b5f1":"clf = RandomForestClassifier(n_estimators=100)","dc97cdef":"clf = RandomForestClassifier(n_estimators=100)\n\nclf.fit(X_train, Y_train)\n\nY_pred = clf.predict(X_test)\n\nprint(clf.score(X_train, Y_train))\n\nclf.score(X_train, Y_train)\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": Y_pred.astype(int)\n    })\nsubmission.to_csv('submission.csv', index=False)","970a991f":"### 4.6 Age","bcb22f53":"#### 4.2 Pclass","196ff397":"### 2.3 Explore the train dataset","ced7c24e":"Create bins for Age","bcb705a8":"## 4. Feature Engineering\n\n#### 4.1 Names column","12553cfb":"**Features**\n    Categorical : Survived, Sex, and Embarked ;\n    Ordinal: Pclass;\n    Continous: Fare;\n    Discrete: SibSp, Parch,Age \n\nAs we can see there are some columns with missing values(age, cabin, embarked). Cabin column hasn't more than 70% of its values\n\n\n**Describing training dataset**","722b74fb":"### 4.7 Encoding Features","8ccb0e1c":"As we can see Age and Pclass have a high corelation. Using median age of the Pclass to missing age will be benefitial rather using median of whole data set. Since there are both Males and Females in the every Pclass median age of the Plcass according to the gender may be the best way to fill the missing Age values.","7123fce4":"### 2.4 Explore the test dataset","a45be333":"#### 3.5 Ticket & PassengerId","797368f9":"Let's replace less common features with 'other' and combine similar titles.","b8dd5ca8":"## 5. Modeling\n\n#### 5.1 Scaling and RandomForest model initialization","c6f8a8cf":"## 3. Filling missing values\n\n#### 3.1 Embarked","8952ca61":"Cabin, Age and Fare columns have missing values.","f35762b8":"1. **PassengerId:** An unique index for passenger rows.\n2. **Survived:** 1 stands for survived and 0 stands for not survived (target variable)\n\n3. **Pclass:** Ticket classes:\n                1 - First class ticket\n                2 - Second class ticket\n                3 - Third class ticket\n\n4. **Name:** Passenger's name. Name contains title like \"Mr\"\/Mrs and surname.\n\n5. **Sex:** Passenger's sex. It's either Male or Female.\n\n6. **Age:** Passenger's age.\n\n7. **SibSp:** Number of siblings or spouses travelling with each passenger.\n8. **Parch:** Number of parents or children travelling with each passenger.\n9. **Ticket:** Ticket number.\n10. **Fare:** Ticket price.\n11. **Cabin:** Cabin number of the passenger.\n12. **Embarked:** Port name where passenger was boarded.\n    C = Cherbourg\n    Q = Queenstown\n    S = Southampton","28071858":"### 4.5 Fare","9e1cccbb":"#### 5.2 Predictions & Generating submission File","34686106":"#### 3.2 Fare","3a56a0e1":"Correlation of test data","9c532af5":"# Feature engineering for Titanic dataset\n\n\n* **1 Introduction**\n* **2 Exploratory analysis**\n    * 2.1 load data\n    * 2.2 joining train and test set\n    * 2.3 Explore the train dataset\n    * 2.4 Explore the test dataset\n* **3 Filling missing values**\n    * 3.1 Embarked\n    * 3.2 Fare\n    * 3.3 Age\n    * 3.4 Cabin\n    * 3.5 Ticket & PassengerId\n        \n\n* **4 Feature engineering**\n    * 4.1 Name\n    * 4.2 Pclass\n    * 4.3 Parch & SibSp\n    * 4.4 Embarked\n    * 4.5 Fare\n    * 4.6 Age\n    * 4.7 Encoding Features\n    \n    \n* **5 Modeling**\n    * 5.1 Scaling and RandomForest model initialization \n    * 5.2 Predictions & Generating submission File","9fa380ab":"As graph shows class 3 has low survival rate","70be6eee":"Correlations of train data","89b0be71":"### 2.2 Joining train and test data frames","e28cb433":"## 2. Exploratory analysis\n### 2.1 Load data","cade9ba4":"There is one valu missing in the fare column. Since fare is related to Pclass feature, median Fare value of a third class ticket may be a good choice to fill the missing value.","9dee7dd3":"## 1. Introduction\n\nThis notebook consists:\n\n* **Exploratory analysis**\n* **Filling missing values**\n* **Feature engineering**\n* **Modeling**","ead37a91":"### 4.3 Parch & SibSp","ee5f08b9":"#### 3.3 Age","0c723bac":"There are 891 rows and 12 columns in the dataset","29f17435":"Most of the Embarked values are from Southampton(S), because of that replace missing two values of the Embarked column with 'S' value.","1f00cba0":"Create bins for Fare values","c8fde4ae":"There are 418 entries and 11 columns in test dataset(no target column here)","dd0da6c5":"### 4.4 Embarked","68cfd4d6":"#### 3.4 Cabin"}}