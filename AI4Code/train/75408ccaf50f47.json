{"cell_type":{"7b886005":"code","1bb80b0e":"code","049b9bd0":"code","ae7db351":"code","74797982":"code","8bf98035":"code","5024b4f2":"code","c0980ddb":"code","b169e854":"code","87db1d9a":"code","2d6e3416":"code","4f4b1808":"code","62ac8ddd":"code","d31538eb":"code","f9a7b41b":"code","5a1350f5":"code","6c708b5f":"code","8e894e45":"code","c8dbc8d3":"code","e0e2e310":"code","1dacfc2d":"code","2055cc38":"markdown","77629307":"markdown","8768d103":"markdown","b1e3f419":"markdown","071fb459":"markdown","d95d2ce4":"markdown","e41b96e2":"markdown","312c983c":"markdown","bbb98b4e":"markdown","78729b8d":"markdown","5aee665c":"markdown","e928a4e1":"markdown","3816afd5":"markdown","80706a6c":"markdown"},"source":{"7b886005":"import os\nimport numpy as np \nimport pandas as pd \nimport tensorflow as tf\nfrom tensorflow.estimator import Estimator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom tensorflow_estimator.python.estimator.mode_keys import ModeKeys","1bb80b0e":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        data = pd.read_csv(os.path.join(dirname, filename))\ndata.head()","049b9bd0":"data.describe().T.style.bar()","ae7db351":"data.info()","74797982":"print('We have', data.shape[0], 'Rows and', data.shape[1], 'features')","8bf98035":"df = data.copy()\ndf.columns","5024b4f2":"y = df['ProdTaken']\ndf = df.drop(['ProdTaken', 'CustomerID', 'TypeofContact'], axis = 1)","c0980ddb":"df.isnull().sum(axis=0)","b169e854":"df.fillna(df.mean(), inplace=True)","87db1d9a":"categorical_cl = [ 'Occupation',  'Gender',\n                  'ProductPitched', 'MaritalStatus',  'Designation']\n\n\nfor i in categorical_cl:\n    le = LabelEncoder()\n    n = str(i)+'_n'\n    df[n] = le.fit_transform(df[i])\n    del df[i]","2d6e3416":"scale = StandardScaler()\nscale.fit(df)\ndf = scale.transform(df)\ndf = pd.DataFrame(df)","4f4b1808":"feature = []\nfor i in range(len(df.columns)):\n  feature.append(str(i))\n\ncol_rename = {i:j for i,j in zip(df.columns, feature)}\ndf = df.rename(columns=col_rename, inplace=False)\ndf.head()","62ac8ddd":"X = df","d31538eb":"dftrain, dfeval, y_train, y_eval = train_test_split(\n    X, y, test_size=0.3, random_state=2)","f9a7b41b":"dftrain = dftrain.astype(\"int64\")\ny_train = y_train.astype(\"int64\")\ndfeval = dfeval.astype(\"int64\")\ny_eval = y_eval.astype(\"int64\")","5a1350f5":"NUM_EXAMPLES = len(y_train)\n\n\ndef make_input_fn(X, y, n_epochs=None, shuffle=True):\n    def input_fn():\n        dataset = tf.data.Dataset.from_tensor_slices((dict(X), y))\n        if shuffle:\n            dataset = dataset.shuffle(NUM_EXAMPLES)\n\n        dataset = dataset.repeat(n_epochs)\n\n        dataset = dataset.batch(NUM_EXAMPLES)\n        return dataset\n    return input_fn","6c708b5f":"train_input_fn = make_input_fn(dftrain, y_train)\neval_input_fn = make_input_fn(dfeval, y_eval, shuffle=False, n_epochs=1)\n\n\nNUMERIC_COLUMNS = featuer\n\n\nfeature_columns = []\n\n\nfor feature_name in NUMERIC_COLUMNS:\n    feature_columns.append(tf.feature_column.numeric_column(feature_name,\n                                                            dtype=tf.float32))\n\n\nest = tf.estimator.BoostedTreesClassifier(feature_columns,\n                                          n_batches_per_layer=1,\n                                          n_classes=2,\n                                          n_trees=100,\n                                          max_depth=10,\n                                          learning_rate=0.1,\n                                          center_bias=True)\n\nest.train(train_input_fn, max_steps=100)\n","8e894e45":"history = est.evaluate(eval_input_fn)","c8dbc8d3":"items = list(history.items())\narray = np.array(items)\nprint('Accuracy:', '{0:.0f}%'.format(array[0, 1].astype('float64') * 100))","e0e2e310":"pred_dicts = list(est.experimental_predict_with_explanations(eval_input_fn))","1dacfc2d":"labels = y_eval.values\nprobs = pd.Series([pred['probabilities'][1] for pred in pred_dicts])\ndf_dfc = pd.DataFrame([pred['dfc'] for pred in pred_dicts])\ndf_dfc.describe().T","2055cc38":"# About this Notebook\n\n\n<h3> Dataset <\/h3>\nIn the following notebook, I tried to analyze the attached dataset and explore it more to find the relationship between different features.\nThen I applied the EDA, PCA, and feature engineering.\n\n<h4> EDA <\/h4>\n\n<h3> Model Selection <\/h3>\nFo modeling the dataset, I considered the Boosted Tree Classifier from the TensorFlow library. \n\n<h4> Metrics <\/h4>\nThe metric I used to measure the model performance is the accuracy of the classifier.\n\n<h4> DFCs <\/h4>\nIn this NoteBook, after training the model, I tried to move on to have more detail about the trained model by applying directional feature contributions (DFCs).\n\n<\/br>\n\n<img src=\"https:\/\/miro.medium.com\/max\/3798\/1*RbBwF9pMlxQm45cVjDch4w.jpeg\" alt=\"Travel\" width=\"500\" height=\"600\">\n\n<hr>\nI tried to explain each cell in a markdown cell above.\n\n\n<h5>If you are interested in this problem and detailed analysis, you can copy this Notebook as follows<\/h5>\n\n<img src=\"https:\/\/www.googleapis.com\/download\/storage\/v1\/b\/kaggle-user-content\/o\/inbox%2F1101107%2F8187a9b84c9dde4921900f794c6c6ff9%2FScreenshot%202020-06-28%20at%201.51.53%20AM.png?generation=1593289404499991&alt=media\" alt=\"Copyandedit\" width=\"300\" height=\"300\" class=\"center\">","77629307":"# DFCs","8768d103":"Changing datatype to be compatible with the model","b1e3f419":"# Check the missing values","071fb459":"## Feature engineering","d95d2ce4":"Replace the header with String value ","e41b96e2":"# Importing the dataset","312c983c":"# Data info","bbb98b4e":"# Training input functions","78729b8d":"# Importing Libs","5aee665c":"# Model Evaluation","e928a4e1":"# Normalizing the input","3816afd5":"# Building Model","80706a6c":"<h5> To deal with the <span style='background:yellow'> missing values <\/span> as we have to different feature types, I considered two different scenarios, the average for numerical missed values and high frequency used values for the categorical ones. <\/h5>\n"}}