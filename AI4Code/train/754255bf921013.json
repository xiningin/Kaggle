{"cell_type":{"d2a3f607":"code","878fea59":"code","ea0027b1":"code","86bdd82e":"code","b5f01df5":"code","565ff1b0":"code","9769ec73":"code","6907f552":"code","0af8e6cf":"code","772e1aed":"code","8448cb3e":"code","d6b53ca7":"code","09d82491":"code","5b8d383d":"code","02002e77":"code","376cc41f":"code","234143c6":"code","62e7f427":"code","ea6518d2":"code","95d938a9":"code","4e0becc4":"code","195867d9":"code","c3b33a31":"code","6cfe5310":"code","29067359":"code","a4fea03f":"code","1e30213b":"code","0c74561b":"code","12a51491":"code","05b01301":"code","203a1357":"code","5178b80f":"code","e7a3dede":"code","516cf735":"code","3c321992":"code","d7b6ce24":"code","a47da297":"code","e34c7563":"code","df496d6b":"code","445edae3":"code","23264c84":"code","1d3c67da":"code","bbc6ea02":"code","c85c78bb":"code","0167e0bd":"code","62134c92":"code","8f90d6cb":"code","0e1a9764":"code","b5fb16c6":"code","3dac9aaf":"code","b1a83a4b":"code","fff58392":"code","fbf6443b":"code","2889e563":"code","b233a1d3":"code","397f92e9":"code","299eef2d":"code","14270ea0":"markdown","a4bdee57":"markdown","c1d70263":"markdown","8ca732b4":"markdown","27049d38":"markdown","93dd08f3":"markdown","5b6ff399":"markdown","c42d0dbf":"markdown","93a63048":"markdown","4e3e537f":"markdown","b87b172b":"markdown","c286c736":"markdown","ba3dcd76":"markdown","07322afb":"markdown","c83d4ca0":"markdown","b485c185":"markdown","c52b8832":"markdown","1fa6490a":"markdown","00b6fd4c":"markdown","b495722c":"markdown","52cd2399":"markdown","e2dbbee9":"markdown","ba83db57":"markdown","8401fd61":"markdown","a4bc4b19":"markdown","ea7dea5b":"markdown","69e53e83":"markdown","64bc8c66":"markdown","7ae98b6d":"markdown","13e5b854":"markdown","58057caf":"markdown","30ef5ed3":"markdown","e5c3003a":"markdown","d2acc81e":"markdown","4088e4b6":"markdown","852e034a":"markdown","07eb41a0":"markdown","618c4e6b":"markdown","996a7988":"markdown","3aafb2d7":"markdown","810b5ceb":"markdown","7477b08b":"markdown","6c5cb791":"markdown"},"source":{"d2a3f607":"# Python libraries\n# Classic,data manipulation and linear algebra\nimport pandas as pd\nimport numpy as np\n\n# Plots\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport plotly.offline as py\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly.tools as tls\nimport plotly.figure_factory as ff\npy.init_notebook_mode(connected=True)\nimport squarify\n\n# Data processing, metrics and modeling\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split, GridSearchCV, RandomizedSearchCV\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix,  roc_curve, precision_recall_curve, accuracy_score, roc_auc_score\nimport lightgbm as lgbm\n\n# Stats\nimport scipy.stats as ss\nfrom scipy.stats import randint as sp_randint\nfrom scipy.stats import uniform as sp_uniform\n\n# Time\nfrom contextlib import contextmanager\n@contextmanager\ndef timer(title):\n    t0 = time.time()\n    yield\n    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n\n#ignore warning messages \nimport warnings\nwarnings.filterwarnings('ignore') ","878fea59":"# Reading dataset\ntrain = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")","ea0027b1":"# Head train and test\ndisplay(train.head(),test.head())","86bdd82e":"# Adding a column in each dataset before merging\ntrain['Type'] = 'train'\ntest['Type'] = 'test'\n\n# Merging train and test\ndata = train.append(test) # The entire data: train + test.\n\n# How many rows and columns in dataset\ndata.shape","b5f01df5":"# Defining missing plot to detect all missing values in dataset\ndef missing_plot(dataset, key) :\n    null_feat = pd.DataFrame(len(dataset[key]) - dataset.isnull().sum(), columns = ['Count'])\n    percentage_null = pd.DataFrame((len(dataset[key]) - (len(dataset[key]) - dataset.isnull().sum()))\/len(dataset[key])*100, columns = ['Count'])\n    percentage_null = percentage_null.round(2)\n\n    trace = go.Bar(x = null_feat.index, y = null_feat['Count'] ,opacity = 0.8, text = percentage_null['Count'],  textposition = 'auto',marker=dict(color = '#7EC0EE',\n            line=dict(color='#000000',width=1.5)))\n\n    layout = dict(title =  \"Missing Values (count & %)\")\n\n    fig = dict(data = [trace], layout=layout)\n    py.iplot(fig)","565ff1b0":"# Plotting \nmissing_plot(data, 'PassengerId')","9769ec73":"# Plotting target (count and %)\ntrain = data[data['Type']=='train']\n\n#------------COUNT-----------------------\ntrace = go.Bar(\n        x = (train['Survived'].value_counts().values.tolist()), \n        y = ['Died', 'Survived'], \n        orientation = 'h', opacity = 0.8, \n        text=train['Survived'].value_counts().values.tolist(), \n        textfont=dict(size=15),\n        textposition = 'auto',\n        marker=dict(\n        color=['pink', 'lightblue'],\n        line=dict(color='#000000',width=1.5)\n        ))\n\nlayout = dict(title =  'Count of target variable',\n                        autosize = False,\n                        height  = 500,\n                        width   = 800)\n                    \nfig = dict(data = [trace], layout=layout)\npy.iplot(fig)\n\n#------------PERCENTAGE-------------------\ntrace = go.Pie(labels = ['Died', 'Survived'], values = train['Survived'].value_counts(), \n               textfont=dict(size=15), opacity = 0.8,\n               marker=dict(colors=['pink', 'lightblue'], \n                           line=dict(color='#000000', width=1.5)))\n\n\nlayout = dict(title =  'Distribution of target variable',\n                        autosize = True,\n                        height  = 500,\n                        width   = 750)\n           \nfig = dict(data = [trace], layout=layout)\npy.iplot(fig)","6907f552":"# Defining horizontal bar plot to visualize each variable of dataset (train and test)\ndef barploth(var_select) :\n    colors = ['gold', 'lightgreen', 'lightcoral', 'lightskyblue', 'lightgrey', 'orange', 'white', 'lightpink']\n    trace1 = go.Bar(\n        y=data[var_select].value_counts().keys().tolist(),\n        x=data[var_select].value_counts().values.tolist(),\n        text=data[var_select].value_counts().values.tolist(),\n        textposition = 'auto',\n        orientation = 'h',\n        name=str(var_select),opacity = 0.8, marker=dict(color = colors,\n        line=dict(color = 'black',width=1)))\n\n    layout = dict(autosize = True,\n                  height  = 500,\n                  width   = 800,\n                  title =  'Total'+' '+str(var_select)+' '+'(train and test)',\n                  xaxis=dict(), \n                  margin=go.layout.Margin(\n                    l=50))\n\n    fig = go.Figure(data=[trace1], layout=layout)\n    py.iplot(fig)","0af8e6cf":"# Defining bar plot to visualize each variable vs target (train)\ndef barplot(var_select,title) :\n    S = data[data['Survived']==1]\n    D = data[data['Survived']==0]\n    tmp1 = S\n    tmp2 = D\n\n    color=['lightskyblue','gold']\n    trace2 = go.Bar(\n        x=tmp1[var_select].value_counts().keys().tolist(),\n        y=tmp1[var_select].value_counts().values.tolist(),\n        text=tmp1[var_select].value_counts().values.tolist(),\n        textposition = 'auto',\n        name='Survived',opacity = 1, marker=dict(\n        color='lightskyblue',\n        line=dict(color='#000000',width=1)))\n\n    trace1 = go.Bar(\n        x=tmp2[var_select].value_counts().keys().tolist(),\n        y=tmp2[var_select].value_counts().values.tolist(),\n        text=tmp2[var_select].value_counts().values.tolist(),\n        textposition = 'auto',\n        name='Died', opacity = 1, marker=dict(\n        color='pink',\n        line=dict(color='#000000',width=1)))\n\n    layout = dict(title = title,\n                  autosize = True,\n                  height  = 500,\n                  width   = 800,\n                  #barmode = 'stack',\n                  xaxis=dict(), \n                  yaxis=dict(title= 'Count'),\n                 legend=dict(x=-.1, y=1.5),\n                 margin=go.layout.Margin(\n                    b=30))\n\n    fig = go.Figure(data=[trace1, trace2], layout=layout)\n    py.iplot(fig)","772e1aed":"# Defining pie plot to visualize each variable repartition vs target modalities : Survived or Died (train)\ndef plot_pie(var_select) :\n    S = data[data['Survived']==1]\n    D = data[data['Survived']==0]\n    \n    col =['Silver', 'gold','#CF5C36','lightblue','magenta', '#FF5D73','#F2D7EE','mediumturquoise']\n    \n    trace1 = go.Pie(values  = D[var_select].value_counts().values.tolist(),\n                    labels  = D[var_select].value_counts().keys().tolist(),\n                    textfont=dict(size=15), opacity = 0.8,\n                    hole = 0.5, \n                    hoverinfo = \"label+percent+name\",\n                    domain  = dict(x = [.0,.48]),\n                    name    = \"Died passenger\",\n                    marker  = dict(colors = col, line = dict(width = 1.5)))\n    trace2 = go.Pie(values  = S[var_select].value_counts().values.tolist(),\n                    labels  = S[var_select].value_counts().keys().tolist(),\n                    textfont=dict(size=15), opacity = 0.8,\n                    hole = 0.5,\n                    hoverinfo = \"label+percent+name\",\n                    marker  = dict(line = dict(width = 1.5)),\n                    domain  = dict(x = [.52,1]),\n                    name    = \"Survived passenger\" )\n\n    layout = go.Layout(dict(title = var_select + \" distribution by target \",\n                            annotations = [ dict(text = \"Died\"+\" : \"+\"549\",\n                                                font = dict(size = 13),\n                                                showarrow = False,\n                                                x = .22, y = -0.1),\n                                            dict(text = \"Survived\"+\" : \"+\"342\",\n                                                font = dict(size = 13),\n                                                showarrow = False,\n                                                x = .8,y = -.1)]))\n                                          \n\n    fig  = go.Figure(data = [trace1,trace2],layout = layout)\n    py.iplot(fig)","8448cb3e":"# Pandas crosstab %\ndef stats(var_select):\n    stats = pd.crosstab(train['Survived'], train[var_select]).apply(lambda r: r\/r.sum(), axis=0)\n    return stats.style.format(\"{:.2%}\")","d6b53ca7":"# Sex EDA \nbarploth('Sex')","09d82491":"stats('Sex')","5b8d383d":"barplot('Sex', 'Sex vs Survived')","02002e77":"plot_pie('Sex')","376cc41f":"# Creating variable Title\ndata['Title'] = data['Name']\n# Cleaning name and extracting Title\nfor name_string in data['Name']:\n    data['Title'] = data['Name'].str.extract('([A-Za-z]+)\\.', expand=True)","234143c6":"barplot('Title', 'Title vs Survived')","62e7f427":"# Replacing rare titles \nmapping = {'Mlle': 'Miss', \n           'Ms': 'Miss', \n           'Mme': 'Mrs',\n           'Major': 'Other', \n           'Col': 'Other', \n           'Dr' : 'Other', \n           'Rev' : 'Other',\n           'Capt': 'Other', \n           'Jonkheer': 'Royal',\n           'Sir': 'Royal', \n           'Lady': 'Royal', \n           'Don': 'Royal',\n           'Countess': 'Royal', \n           'Dona': 'Royal'}\ndata.replace({'Title': mapping}, inplace=True)\ntitles = ['Miss', 'Mr', 'Mrs', 'Royal', 'Other', 'Master']","ea6518d2":"barploth('Title')","95d938a9":"barplot('Title', 'Title vs Survived')","4e0becc4":"plot_pie('Title')","195867d9":"# Plotting age distribution vs target\nS = data[data['Survived']==1]\nD = data[data['Survived']==0]\n\ndef plot_distribution(var_select, title) :  \n    tmp1 = S[var_select]\n    tmp2 = D[var_select]\n    \n    trace0 = go.Histogram(\n        x=tmp1, opacity=1, name='Survived', marker=dict(\n        color='lightblue')\n    )\n    trace1 = go.Histogram(\n        x=tmp2, opacity=1, name='Died', marker=dict(\n        color='pink')\n    )\n    \n    data = [trace0, trace1]\n    layout = go.Layout(barmode='stack', title = title,\n                  autosize = True,\n                  height  = 500,\n                  width   = 800,\n                  #barmode = 'stack',\n                  xaxis=dict(), \n                  yaxis=dict(title= 'Count'), \n                  yaxis2=dict(range= [-0, 75], \n                              overlaying= 'y', \n                              anchor= 'x', \n                              side= 'right',\n                              zeroline=False,\n                              showgrid= False, \n                              title= '% Died'\n                             ),\n                 legend=dict(x=-.1, y=1.5),\n                 margin=go.layout.Margin(\n                    b=0))\n    fig = go.Figure(data=data, layout=layout)\n\n    py.iplot(fig, filename = 'Density plot')\n\n","c3b33a31":"plot_distribution('Age', 'Age vs Survived')","6cfe5310":"# Plotting age vs sex vs target\ntrain = data[data[\"Type\"]==\"train\"]\ng = sns.FacetGrid(train, col=\"Sex\", hue=\"Survived\", palette=\"Set1\")\ng.map(sns.distplot, \"Age\")\ng = g.add_legend()\ng.fig.suptitle('Age vs Sex vs Survived', fontsize=16)\ng.fig.set_size_inches(15,8)","29067359":"# Plotting title vs age vs sex\ntrain = data[data[\"Type\"]==\"train\"]\ng = sns.FacetGrid(train, col=\"Title\", hue=\"Sex\")\ng.map(sns.distplot, \"Age\")\ng = g.add_legend()\ng.set(ylim=(0, 0.1))\ng.fig.suptitle('Title vs Age', fontsize=16)\ng.fig.set_size_inches(15,8)","a4fea03f":"# Replacing missing age by median\/title \nfor title in titles:\n    age_to_impute = data.groupby('Title')['Age'].median()[titles.index(title)]\n    data.loc[(data['Age'].isnull()) & (data['Title'] == title), 'Age'] = age_to_impute","1e30213b":"# EDA sibsp and parch\nbarplot('SibSp', 'SibSp vs Survived')\nbarplot('Parch', 'Parch vs Survived')","0c74561b":"# Creating new feature : family size\ndata['Family_Size'] = data['Parch'] + data['SibSp'] + 1\ndata.loc[:,'FsizeD']='Alone'\ndata.loc[(data['Family_Size']>1),'FsizeD']='Small'\ndata.loc[(data['Family_Size']>4),'FsizeD']='Big'","12a51491":"# EDA family size\nbarplot('Family_Size', 'Family_size vs Survived')","05b01301":"def moscaicplot(var):\n    x = 0.\n    y = 0.\n    width = 50.\n    height = 50.\n    type_list = list(data[var].unique())\n    values = [len(data[data[var] == i]) for i in type_list]\n    percent = [(len(data[data[var] == i])\/len(data[var])*100) for i in type_list]\n\n    normed = squarify.normalize_sizes(values, width, height)\n    rects = squarify.squarify(normed, x, y, width, height)\n\n    color_brewer =['#FF5D73','#F2D7EE','mediumturquoise','#7C7A7A','#CF5C36','lightblue','magenta']\n    shapes = []\n    annotations = []\n    counter = 0\n\n    for r in rects:\n        shapes.append( \n            dict(type = 'rect', \n                x0 = r['x'], \n                y0 = r['y'], \n                x1 = r['x']+r['dx'], \n                y1 = r['y']+r['dy'],\n                line = dict( width = 1.5, color = 'black'),\n                fillcolor = color_brewer[counter]))\n        annotations.append(\n            dict(x = r['x']+(r['dx']\/2),\n                y = r['y']+(r['dy']\/2),\n                text = \"{}<br>{}<br>{:.0f}%\".format(type_list[counter], values[counter], percent[counter]), font=dict(color='black', size = 14),\n                showarrow = False))\n        counter = counter + 1\n        if counter >= len(color_brewer):\n            counter = 0\n\n    # For hover text\n    trace0 = go.Scatter(\n        x = [ r['x']+(r['dx']\/2) for r in rects ], \n        y = [ r['y']+(r['dy']\/2) for r in rects ],\n        text = [ str(v) for v in values ], \n        mode = 'text')\n\n    layout = dict(\n        autosize = True,\n        height=700, \n        width=800,\n        xaxis=dict(showgrid=False,zeroline=False),\n        yaxis=dict(showgrid=False,zeroline=False),\n        title = var +' '+ '- Distribution',\n        shapes=shapes,\n        annotations=annotations,\n        hovermode='closest',\n        font=dict(color=\"Black\"))\n\n    # With hovertext\n    figure = dict(data=[trace0], layout=layout)\n    iplot(figure, filename='squarify-treemap')","203a1357":"moscaicplot(\"FsizeD\")","5178b80f":"barplot('FsizeD', 'FsizeD vs Survived')","e7a3dede":"plot_pie('FsizeD')","516cf735":"data[data[\"Fare\"].isnull()]","3c321992":"g = sns.FacetGrid(train, col=\"Pclass\", hue=\"Survived\", palette=\"Set1\")\ng.map(sns.distplot, \"Fare\")\ng.set(ylim=(0, 0.1),xlim = (-0, 200))\ng = g.add_legend()\ng.fig.suptitle('Pclass vs Fare vs Survived', fontsize=16)\ng.fig.set_size_inches(15,8)","d7b6ce24":"def plot_distribution(var_select, title, bin_size) : \n    tmp1 = data[data[\"Pclass\"] == 3]\n    tmp1 = tmp1[var_select].dropna()\n    hist_data = [tmp1]\n    \n    group_labels = [var_select]\n    colors = ['gold']\n\n    fig = ff.create_distplot(hist_data, group_labels, colors = colors, show_hist = True, curve_type='kde', bin_size = bin_size)\n    \n    fig['layout'].update(title = title, autosize = True,\n                        height  = 500,\n                        width   = 800,annotations=[\n        dict(\n            x=data[data[\"Pclass\"]==3].loc[:,\"Fare\"].median(),\n            y=0.086,\n            xref='x',\n            yref='y',\n            text=data[data[\"Pclass\"]==3].loc[:,\"Fare\"].median(),\n            showarrow=True,\n            arrowhead=7,\n            ax=20,\n            ay=-40,\n             font=dict(\n                size=16,\n                color='black'))])\n\n    py.iplot(fig, filename = 'Density plot')\n    \nplot_distribution('Fare', 'Fare (Pclass = 3)',1)","a47da297":"fa = data[data[\"Pclass\"]==3]\ndata['Fare'].fillna(fa['Fare'].median(), inplace = True)","e34c7563":"data.loc[:,'Child']=1\ndata.loc[(data['Age']>=18),'Child']=0","df496d6b":"barploth('Child')","445edae3":"barplot('Child', 'Child vs Survived')","23264c84":"plot_pie('Child')","1d3c67da":"data['Last_Name'] = data['Name'].apply(lambda x: str.split(x, \",\")[0])\n\nDEFAULT_SURVIVAL_VALUE = 0.5\ndata['Family_Survival'] = DEFAULT_SURVIVAL_VALUE\n\nfor grp, grp_df in data[['Survived','Name', 'Last_Name', 'Fare', 'Ticket', 'PassengerId',\n                           'SibSp', 'Parch', 'Age', 'Cabin']].groupby(['Last_Name', 'Fare']):\n    \n    if (len(grp_df) != 1):\n        # A Family group is found.\n        for ind, row in grp_df.iterrows():\n            smax = grp_df.drop(ind)['Survived'].max()\n            smin = grp_df.drop(ind)['Survived'].min()\n            passID = row['PassengerId']\n            if (smax == 1.0):\n                data.loc[data['PassengerId'] == passID, 'Family_Survival'] = 1\n            elif (smin==0.0):\n                data.loc[data['PassengerId'] == passID, 'Family_Survival'] = 0\n\nprint(\"Number of passengers with family survival information:\", \n      data.loc[data['Family_Survival']!=0.5].shape[0])","bbc6ea02":"for _, grp_df in data.groupby('Ticket'):\n    if (len(grp_df) != 1):\n        for ind, row in grp_df.iterrows():\n            if (row['Family_Survival'] == 0) | (row['Family_Survival']== 0.5):\n                smax = grp_df.drop(ind)['Survived'].max()\n                smin = grp_df.drop(ind)['Survived'].min()\n                passID = row['PassengerId']\n                if (smax == 1.0):\n                    data.loc[data['PassengerId'] == passID, 'Family_Survival'] = 1\n                elif (smin==0.0):\n                    data.loc[data['PassengerId'] == passID, 'Family_Survival'] = 0\n                        \nprint(\"Number of passenger with family\/group survival information: \" \n      +str(data[data['Family_Survival']!=0.5].shape[0]))","c85c78bb":"data = data.drop(columns = [\n                            'Age',\n                            'Cabin', \n                            'Embarked',\n                            'Name',\n                            'Last_Name',\n                            'Parch', \n                            'SibSp', \n                            'Ticket', \n                            'Family_Size',\n                           ])\ndata.head()","0167e0bd":"target_col = [\"Survived\"]\nid_dataset = [\"Type\"]\ncat_cols   = data.nunique()[data.nunique() < 12].keys().tolist()\ncat_cols   = [x for x in cat_cols ]\n#numerical columns\nnum_cols   = [x for x in data.columns if x not in cat_cols + target_col + id_dataset]\n#Binary columns with 2 values\nbin_cols   = data.nunique()[data.nunique() == 2].keys().tolist()\n#Columns more than 2 values\nmulti_cols = [i for i in cat_cols if i not in bin_cols]\n\n#Label encoding Binary columns\nle = LabelEncoder()\nfor i in bin_cols :\n    data[i] = le.fit_transform(data[i])\n    \n#Duplicating columns for multi value columns\ndata = pd.get_dummies(data = data,columns = multi_cols )\n\n#Scaling Numerical columns\nstd = StandardScaler()\nscaled = std.fit_transform(data[num_cols])\nscaled = pd.DataFrame(scaled,columns=num_cols)\n\n#dropping original values merging scaled values for numerical columns\ndf_data_og = data.copy()\ndata = data.drop(columns = num_cols,axis = 1)\ndata = data.merge(scaled,left_index=True,right_index=True,how = \"left\")\n\ndata = data.drop(columns = ['PassengerId'],axis = 1)","62134c92":"def correlation_plot():\n    #correlation\n    correlation = data.drop(columns=['Type', 'Survived']).corr()\n    #tick labels\n    matrix_cols = correlation.columns.tolist()\n    #convert to array\n    corr_array  = np.array(correlation)\n    trace = go.Heatmap(z = corr_array,\n                       x = matrix_cols,\n                       y = matrix_cols,\n                       colorscale='Viridis',\n                       colorbar   = dict() ,\n                      )\n    layout = go.Layout(dict(title = 'Correlation Matrix for variables',\n                            #autosize = False,\n                            #height  = 1400,\n                            #width   = 1600,\n                            margin  = dict(r = 0 ,l = 100,\n                                           t = 0,b = 100,\n                                         ),\n                            yaxis   = dict(tickfont = dict(size = 9)),\n                            xaxis   = dict(tickfont = dict(size = 9)),\n                           )\n                      )\n    fig = go.Figure(data = [trace],layout = layout)\n    py.iplot(fig)","8f90d6cb":"correlation_plot()","0e1a9764":"# Cutting train and test\ntrain = data[data['Type'] == 1]\ntest = data[data['Type'] == 0]\n\ntrain = train.drop(columns = ['Type'])\ntest = test.drop(columns = ['Type'])","b5fb16c6":"X = train.drop('Survived', 1)\ny = train['Survived']\nX_test = test\nX_test = X_test.drop(columns = ['Survived'\n                           ])","3dac9aaf":"# Train_test split\nrandom_state = 42\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.2, random_state = random_state)","b1a83a4b":"fit_params = {\"early_stopping_rounds\" : 100, \n             \"eval_metric\" : 'auc', \n             \"eval_set\" : [(X_train,y_train)],\n             'eval_names': ['valid'],\n             'verbose': 0,\n             'categorical_feature': 'auto'}\n\nparam_test = {'learning_rate' : [0.01, 0.02, 0.03, 0.04, 0.05, 0.08, 0.1, 0.2, 0.3, 0.4],\n              'n_estimators' : [100, 200, 300, 400, 500, 600, 800, 1000, 1500, 2000],\n              'num_leaves': sp_randint(6, 50), \n              'min_child_samples': sp_randint(100, 500), \n              'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n              'subsample': sp_uniform(loc=0.2, scale=0.8), \n              'max_depth': [-1, 1, 2, 3, 4, 5, 6, 7],\n              'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n              'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n              'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}\n\n#number of combinations\nn_iter = 500 \n\n#intializing lgbm and lunching the search\nlgbm_clf = lgbm.LGBMClassifier(random_state=random_state, silent=True, metric='None', n_jobs=4)\ngrid_search = RandomizedSearchCV(\n    estimator=lgbm_clf, param_distributions=param_test, \n    n_iter=n_iter,\n    scoring='accuracy',\n    cv=5,\n    refit=True,\n    random_state=random_state,\n    verbose=True)\n\ngrid_search.fit(X, y, **fit_params)\nprint('Best score reached: {} with params: {} '.format(grid_search.best_score_, grid_search.best_params_))\n\nopt_parameters =  grid_search.best_params_","fff58392":"def model_performance(model) : \n    #Conf matrix\n    conf_matrix = confusion_matrix(y_valid, y_pred)\n    trace1 = go.Heatmap(z = conf_matrix  ,x = [\"0 (pred)\",\"1 (pred)\"],\n                        y = [\"0 (true)\",\"1 (true)\"],xgap = 2, ygap = 2, \n                        colorscale = 'Viridis', showscale  = False)\n\n    #Show metrics\n    tp = conf_matrix[1,1]\n    fn = conf_matrix[1,0]\n    fp = conf_matrix[0,1]\n    tn = conf_matrix[0,0]\n    Accuracy  =  ((tp+tn)\/(tp+tn+fp+fn))\n    Precision =  (tp\/(tp+fp))\n    Recall    =  (tp\/(tp+fn))\n    F1_score  =  (2*(((tp\/(tp+fp))*(tp\/(tp+fn)))\/((tp\/(tp+fp))+(tp\/(tp+fn)))))\n\n    show_metrics = pd.DataFrame(data=[[Accuracy , Precision, Recall, F1_score]])\n    show_metrics = show_metrics.T\n\n    colors = ['gold', 'lightgreen', 'lightcoral', 'lightskyblue']\n    trace2 = go.Bar(x = (show_metrics[0].values), \n                    y = ['Accuracy', 'Precision', 'Recall', 'F1_score'], text = np.round_(show_metrics[0].values,4),\n                    textposition = 'auto', textfont=dict(color='black'),\n                    orientation = 'h', opacity = 1, marker=dict(\n            color=colors,\n            line=dict(color='#000000',width=1.5)))\n    \n    #Roc curve\n    model_roc_auc = round(roc_auc_score(y_valid, y_score) , 3)\n    fpr, tpr, t = roc_curve(y_valid, y_score)\n    trace3 = go.Scatter(x = fpr,y = tpr,\n                        name = \"Roc : \" + str(model_roc_auc),\n                        line = dict(color = ('rgb(22, 96, 167)'),width = 2), fill='tozeroy')\n    trace4 = go.Scatter(x = [0,1],y = [0,1],\n                        line = dict(color = ('black'),width = 1.5,\n                        dash = 'dot'))\n    \n    # Precision-recall curve\n    precision, recall, thresholds = precision_recall_curve(y_valid, y_score)\n    trace5 = go.Scatter(x = recall, y = precision,\n                        name = \"Precision\" + str(precision),\n                        line = dict(color = ('lightcoral'),width = 2), fill='tozeroy')\n    \n    #Feature importance\n    coefficients  = pd.DataFrame(eval(model).feature_importances_)\n    column_data   = pd.DataFrame(list(train))\n    coef_sumry    = (pd.merge(coefficients,column_data,left_index= True,\n                              right_index= True, how = \"left\"))\n    coef_sumry.columns = [\"coefficients\",\"features\"]\n    coef_sumry    = coef_sumry.sort_values(by = \"coefficients\",ascending = False)\n    coef_sumry = coef_sumry[coef_sumry[\"coefficients\"] !=0]\n    trace6 = go.Bar(x = coef_sumry[\"features\"],y = coef_sumry[\"coefficients\"],\n                    name = \"coefficients\", \n                    marker = dict(color = coef_sumry[\"coefficients\"],\n                                  colorscale = \"Viridis\",\n                                  line = dict(width = .6,color = \"black\")))\n    \n    #Cumulative gain\n    pos = pd.get_dummies(y_valid).as_matrix()\n    pos = pos[:,1] \n    npos = np.sum(pos)\n    index = np.argsort(y_score) \n    index = index[::-1] \n    sort_pos = pos[index]\n    #cumulative sum\n    cpos = np.cumsum(sort_pos) \n    #recall\n    recall = cpos\/npos \n    #size obs test\n    n = y_valid.shape[0] \n    size = np.arange(start=1,stop=369,step=1) \n    #proportion\n    size = size \/ n \n    #plots\n    model = model\n    trace7 = go.Scatter(x = size,y = recall,\n                        line = dict(color = ('gold'),width = 2), fill='tozeroy') \n    \n    #Subplots\n    fig = tls.make_subplots(rows=4, cols=2, print_grid=False,\n                          specs=[[{}, {}], \n                                 [{}, {}],\n                                 [{'colspan': 2}, None],\n                                 [{'colspan': 2}, None]],\n                          subplot_titles=('Confusion Matrix',\n                                          'Metrics',\n                                          'ROC curve'+\" \"+ '('+ str(model_roc_auc)+')',\n                                          'Precision - Recall curve',\n                                          'Cumulative gains curve',\n                                          'Feature importance'\n                                          ))\n    \n    fig.append_trace(trace1,1,1)\n    fig.append_trace(trace2,1,2)\n    fig.append_trace(trace3,2,1)\n    fig.append_trace(trace4,2,1)\n    fig.append_trace(trace5,2,2)\n    fig.append_trace(trace6,4,1)\n    fig.append_trace(trace7,3,1)\n    \n    fig['layout'].update(showlegend = False, title = '<b>Model performance report<\/b><br>'+str(model),\n                         autosize = False, \n                         height = 1500,\n                         width = 800,\n                         plot_bgcolor = 'black',\n                         paper_bgcolor = 'black',\n                         margin = dict(b = 195), \n                         font=dict(color='white')\n                        )\n    \n    fig[\"layout\"][\"xaxis1\"].update(dict(color = 'white'),showgrid=False)\n    fig[\"layout\"][\"yaxis1\"].update(dict(color = 'white'),showgrid=False)\n    fig[\"layout\"][\"xaxis2\"].update((dict(range=[0, 1], color = 'white')),showgrid=False)\n    fig[\"layout\"][\"yaxis2\"].update(dict(color = 'white'),showgrid=False)\n    fig[\"layout\"][\"xaxis3\"].update(dict(title = \"false positive rate\"),showgrid=False)\n    fig[\"layout\"][\"yaxis3\"].update(dict(title = \"true positive rate\"),color = 'white',showgrid=False)\n    fig[\"layout\"][\"xaxis4\"].update(dict(title = \"recall\"), range = [0,1.05],color = 'white',showgrid=False)\n    fig[\"layout\"][\"yaxis4\"].update(dict(title = \"precision\"), range = [0,1.05],color = 'white',showgrid=False)\n    fig[\"layout\"][\"xaxis5\"].update(dict(title = \"Percentage contacted\"),color = 'white',showgrid=False)\n    fig[\"layout\"][\"yaxis5\"].update(dict(title = \"Percentage positive targeted\"),color = 'white',showgrid=False)\n    fig[\"layout\"][\"xaxis6\"].update(dict(color = 'white'),showgrid=False)\n    fig[\"layout\"][\"yaxis6\"].update(dict(color = 'white'),showgrid=False)\n    for i in fig['layout']['annotations']:\n        i['font'] = titlefont=dict(color='white', size = 14)\n    py.iplot(fig)","fbf6443b":"%%time\nlgbm_clf = lgbm.LGBMClassifier(**opt_parameters)\n\nlgbm_clf.fit(X_train, y_train)\ny_pred = lgbm_clf.predict(X_valid)\ny_score = lgbm_clf.predict_proba(X_valid)[:,1]\n\nmodel_performance('lgbm_clf')","2889e563":"scores = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\nres = []\nfor sc in scores:\n    scores = cross_val_score(lgbm_clf, X, y, cv = 5, scoring = sc)\n    #print(sc, scores)\n    res.append(scores)\ndf = pd.DataFrame(res).T\ndf.loc['mean'] = df.mean()\ndf.loc['std'] = df.std()\ndf= df.rename(columns={0: 'accuracy', 1:'precision', 2:'recall',3:'f1',4:'roc_auc'})\n\ntrace = go.Table(\n    header=dict(values=['<b>Fold', '<b>Accuracy', '<b>Precision', '<b>Recall', '<b>F1 score', '<b>Roc auc'],\n                line = dict(color='#7D7F80'),\n                fill = dict(color='#a1c3d1'),\n                align = ['center'],\n                font = dict(size = 15)),\n    cells=dict(values=[('1','2','3','4','5','mean', 'std'),\n                       np.round(df['accuracy'],4),\n                       np.round(df['precision'],4),\n                       np.round(df['recall'],4),\n                       np.round(df['f1'],4),\n                       np.round(df['roc_auc'],4)],\n               line = dict(color='#7D7F80'),\n               fill = dict(color='#EDFAFF'),\n               align = ['center'], font = dict(size = 15)))\n\nlayout = dict(width=800, height=400, title = '<b>Cross validation - 5 folds', font = dict(size = 15))\nfig = dict(data=[trace], layout=layout)\npy.iplot(fig, filename = 'styled_table')","b233a1d3":"lgbm_clf = lgbm.LGBMClassifier(**opt_parameters)\nlgbm_clf.fit(X, y)\ny_pred = lgbm_clf.predict(X_test)","397f92e9":"from yellowbrick.classifier import DiscriminationThreshold\nvisualizer = DiscriminationThreshold(lgbm_clf)\n\nvisualizer.fit(X, y)  \nvisualizer.poof()   ","299eef2d":"temp = pd.DataFrame(pd.read_csv(\"..\/input\/test.csv\")['PassengerId'])\ntemp['Survived'] = y_pred\ntemp.to_csv(\"..\/working\/submission.csv\", index = False)","14270ea0":"# <a id='2'>2. Overview<\/a> ","a4bdee57":"## <a id='4.3'>4.3. Correlation plot<\/a> ","c1d70263":"## <a id='5.2'>5.2. Light GBM - Model performance report<\/a> ","8ca732b4":"# <a id='3'>3. Exploratory analysis and data processing<\/a> ","27049d38":"* 3\/4 of Cabin are empty, we drop this variable\n* 32 % of target (Survived) is missing, this is test data\n* 20 % of Age is missing\n* 1 Fare is empty\n* 2 Embarqued are empty","93dd08f3":"## <a id='5.1'>5.1. Light GBM -  RandomizedSearchCV to optimise hyperparameters<\/a> ","5b6ff399":"## <a id='4.4'>4.4. Define (X,  y)<\/a> ","c42d0dbf":"## <a id='5.4'>5.4. Light GBM - Cross Validation - 5 folds - 0.8496 (+\/- 0.017)<\/a> ","93a63048":"# <a id='4'>4. Prepare dataset<\/a> ","4e3e537f":"![](http:\/\/image.noelshack.com\/fichiers\/2019\/05\/1\/1548690862-0.jpg)","b87b172b":"## <a id='2.3'>2.3 Target<\/a> ","c286c736":"* **Survival**\t: 0 = No, 1 = Yes \n* **Pclass** : Ticket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n* **Sex** : Sex\t Male or Female\n* **Age** : Age in years\t\n* **Sibsp** : number of siblings \/ spouses aboard the Titanic\t\n* **Parch** : number of parents \/ children aboard the Titanic\t\n* **Ticket** : Ticket number\t\n* **Fare** : Passenger fare\t\n* **Cabin** : Cabin number\t\n* **Embarked** : Port of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton\n* **Type** : train or test ","ba3dcd76":"## <a id='4.5'>4.5. Train test split<\/a> ","07322afb":"## <a id='1.2'>1.2. Read data<\/a> ","c83d4ca0":"## <a id='5.5'>5.5. Discrimination Threshold<\/a> ","b485c185":"## <a id='3.3'>3.3. New feature : Title (From Name)<\/a> ","c52b8832":"Merge train and test facilitates the exploratory analysis and the feature engineering. ","1fa6490a":"## <a id='3.6'>3.6. Processing Fare (Replace missing value by Pclass = 3 's median)<\/a> ","00b6fd4c":"----------\n**Titanic - Data Analysis + LGBM : 0.82296**\n=====================================\n\n* **Accuracy - Valid  : 0.8547**\n* **Accuracy - CV    : 0.8496 (+\/- 0.017)**\n* **Accuracy - Public    : 0.82296**\n\n***Vincent Lugat***\n\n*January 2019*\n\n----------","b495722c":"## <a id='4.2'>4.2. Standard scaler & dummies<\/a> ","52cd2399":"## <a id='3.7'>3.7. New feature : Child (From Age)<\/a> ","e2dbbee9":"This feature is from this kernel : https:\/\/www.kaggle.com\/konstantinmasich\/titanic-0-82-0-83","ba83db57":"This function parses the names and extracts the titles.\n\nExemple : Wilkes, **Mrs**. James (Ellen Needs)","8401fd61":"## <a id='3.8'>3.8. New feature : Family_Survival<\/a> ","a4bc4b19":"## <a id='2.1'>2.1. Head<\/a> ","ea7dea5b":"**Competition description :** The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n\nOne of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n\nIn this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.","69e53e83":"## <a id='3.1'>3.1. Define plots<\/a> ","64bc8c66":"![](http:\/\/image.noelshack.com\/fichiers\/2019\/05\/1\/1548689481-0-0-0.jpg)","7ae98b6d":"# <a id='5'>5. Light GBM model<\/a> ","13e5b854":"# <a id='6'>6. Submission - 0.82296<\/a> ","58057caf":"## <a id='2.2'>2.2. Missing values<\/a> ","30ef5ed3":"We have seen that the Age variable was missing 263 values ( ~ 20 % of the dataset). ","e5c3003a":"Some modalities can be grouped : \n* Mlle : Miss in french \n* Mme : Mrs in french\n* Ms : used with the last name or full name of a woman, intended as a default form of address for women regardless of marital status\n* Major: Military rank\n* Col: Military rank\n* Dr : Academic\n* Rev : Christian clergy\n* Capt: Military rank\n* Jonkheer :  Honorific in the Low Countries denoting the lowest rank within the nobility for men\n* Sir :Formal Honorific address for men\n* Lady : Honorific address for men\n* Don : Honorific prefix primarly used in Italy, Spain, Portugal for men\n* Countness : Honorific address for women\n* Dona : Honorific prefix primarly used in Italy, Spain, Portugal for women","d2acc81e":"## <a id='5.3'>5.3. Light GBM - 0.8547<\/a> ","4088e4b6":"## <a id='3.2'>3.2. Sex<\/a> ","852e034a":"## <a id='3.4'>3.4. Age<\/a> ","07eb41a0":"**Thank you all ! Merci \u00e0 tous ! :)**","618c4e6b":"## <a id='3.5'>3.5. New feature : Family Size (From SibSp and Parch)<\/a> ","996a7988":"## <a id='1.1'>1.1. Load libraries<\/a> ","3aafb2d7":"## <a id='4.1'>4.1. Drop some features<\/a> ","810b5ceb":"- <a href='#1'>1. Load libraries and read the data<\/a>  \n    - <a href='#1.1'>1.1. Load libraries<\/a> \n    - <a href='#1.2'>1.2. Read the data<\/a> \n- <a href='#2'>2. Overview<\/a> \n    - <a href='#2.1'>2.1. Head<\/a> \n    - <a href='#2.2'>2.2. Missing values<\/a> \n    - <a href='#2.3'>2.3. Target<\/a> \n- <a href='#3'>3. Exploratory analysis and data processing<\/a>\n    - <a href='#3.1'>3.1. Define plots<\/a> \n    - <a href='#3.2'>3.2. Sex<\/a> \n    - <a href='#3.3'>3.3. New feature : Title (From Name)<\/a>\n    - <a href='#3.4'>3.4. Age<\/a>\n    - <a href='#3.5'>3.5. New features : Family Size and FsizeD (From SibSp and Parch)<\/a>\n\t- <a href='#3.6'>3.6. Processing Fare (Replace missing value by Pclass = 3 's median)<\/a> \n    - <a href='#3.7'>3.7. New feature : Child (From Age)<\/a> \n    - <a href='#3.8'>3.8. New feature : Family_Survival<\/a>\n- <a href='#4'>4. Prepare dataset<\/a>\n\t- <a href='#4.1'>4.1. Drop some features<\/a> \n\t- <a href='#4.2'>4.2. Standard scaler & dummies transformation<\/a>\n    - <a href='#4.3'>4.3. Correlation plot<\/a> \n\t- <a href='#4.4'>4.4. Define (X, y)<\/a>\n    - <a href='#4.5'>4.5. Train test split <\/a> \n- <a href='#5'>5. Light GBM Model<\/a> \n    - <a href='#5.1'>5.1. Light GBM - RandomizedSearchCV to optimise hyperparameters<\/a> \n    - <a href='#5.2'>5.2. Light GBM - Model performance report<\/a>\n    - <a href='#5.3'>5.3. Light GBM - 0.8547<\/a>\n    - <a href='#5.4'>5.4. Light GBM - Cross Validation - 5 folds - 0.8496 (+\/- 0.017)<\/a>\n\t- <a href='#5.4'>5.5. Discrimination Threshold<\/a>\n- <a href='#6'>6. Submission - 0.82296<\/a> ","7477b08b":"# <a id='1'>1. Load libraries and read the data<\/a> ","6c5cb791":"![](http:\/\/image.noelshack.com\/fichiers\/2019\/05\/1\/1548689192-0-0-0-0lgbm.jpg)"}}