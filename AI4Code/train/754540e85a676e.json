{"cell_type":{"821f2f3f":"code","d5f8a262":"code","fbb07ba0":"code","7949070b":"code","ed218f22":"code","7e5fc42c":"code","7567370e":"code","0a690cf9":"code","cf5f15d6":"code","851fe6a5":"code","d1a02424":"code","1bf6fa4c":"code","dc4a1d2c":"code","d5929b4a":"code","aa773abd":"code","3c465983":"code","4949d12e":"code","36152e57":"code","c8424d25":"code","d44be847":"code","2b701624":"code","5069d414":"code","b82eecc0":"code","0567c00b":"code","9934e663":"code","e73f02f1":"code","38611b4c":"code","ceb0c97a":"code","2ceb0e79":"code","92f6ecf9":"code","812bc4cc":"code","a1970c84":"code","3122b635":"code","c4b83e65":"code","d89df64e":"code","3b226ef9":"code","5902ca52":"code","10cb5ac2":"code","4f3600a2":"markdown","76040f6f":"markdown","ff09fd57":"markdown","4a8c3df7":"markdown","fb87ad27":"markdown","ff3ce26d":"markdown","0c5c55ea":"markdown","9e1c80e5":"markdown","14cb37b4":"markdown","d44a672a":"markdown","7d46edc1":"markdown","f70d9254":"markdown","85fbf0fa":"markdown","02567139":"markdown","532948c9":"markdown","39aa710f":"markdown","c439e612":"markdown","211620ab":"markdown","6dd7a22e":"markdown","d3b21851":"markdown","c8ecb8fd":"markdown","52becbd5":"markdown","3a11fac6":"markdown","2828e997":"markdown","895c1b21":"markdown"},"source":{"821f2f3f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d5f8a262":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","fbb07ba0":"df2015=pd.read_csv(\"..\/input\/world-happiness\/2015.csv\")\ndf2015.info()\ndf2015.head()","7949070b":"sns.pairplot(df2015)\nplt.show()","ed218f22":"sns.heatmap(df2015.corr(), annot=True, fmt='1.1f')\nplt.show()","7e5fc42c":"df2016=pd.read_csv(\"..\/input\/world-happiness\/2016.csv\")\ndf2016.info()\ndf2016.head()","7567370e":"sns.heatmap(df2016.corr(), annot=True, fmt='1.1f')\nplt.show()","0a690cf9":"df2017=pd.read_csv(\"..\/input\/world-happiness\/2017.csv\")\ndf2017.info()","cf5f15d6":"sns.heatmap(df2017.corr(), annot=True, fmt='1.1f')\nplt.show()","851fe6a5":"df2018=pd.read_csv(\"..\/input\/world-happiness\/2018.csv\")\ndf2018.info()\ndf2018.head()","d1a02424":"sns.heatmap(df2018.corr(), annot=True, fmt='1.1f')\nplt.show()","1bf6fa4c":"df2019=pd.read_csv(\"..\/input\/world-happiness\/2019.csv\")\ndf2019.info()","dc4a1d2c":"sns.heatmap(df2019.corr(), annot=True, fmt='1.1f')\n# *.corr is calculation of heatmap value, annot=True means visualization the value in heatmap cells\nplt.show()","d5929b4a":"# Visualization of happiness score\nfrom plotly.offline import plot, iplot, init_notebook_mode\ninit_notebook_mode(connected=True)\nimport plotly.express as px\n\nfig = px.choropleth(df2015, locations='Country',\n                    locationmode='country names',\n                    color='Happiness Score',\n                    hover_name='Country',\n                    title='Happiness Index 2015',\n                    color_continuous_scale=px.colors.sequential.Plasma)\nfig.show()","aa773abd":"fig = px.choropleth(df2016, locations='Country',\n                    locationmode='country names',\n                    color='Happiness Score',\n                    hover_name='Country',\n                    title='Happiness Index 2016',\n                    color_continuous_scale=px.colors.sequential.Plasma)\nfig.show()","3c465983":"fig = px.choropleth(df2017, locations='Country',\n                    locationmode='country names',\n                    color='Happiness.Score',\n                    hover_name='Country',\n                    title='Happiness Index 2017',\n                    color_continuous_scale=px.colors.sequential.Plasma)\nfig.show()","4949d12e":"fig = px.choropleth(df2018, locations='Country or region',\n                    locationmode='country names',\n                    color='Score',\n                    hover_name='Country or region',\n                    title='Happiness Index 2018',\n                    color_continuous_scale=px.colors.sequential.Plasma)\nfig.show()","36152e57":"fig = px.choropleth(df2019, locations='Country or region',\n                    locationmode='country names',\n                    color='Score',\n                    hover_name='Country or region',\n                    title='Happiness Index 2019',\n                    color_continuous_scale=px.colors.sequential.Plasma)\nfig.show()","c8424d25":"from sklearn.tree import DecisionTreeRegressor #DecisionTree Regressor\nfrom sklearn.ensemble import RandomForestRegressor # RandomForest Regressor\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing # sklearn preprocessing, if it's necessary\n\n# Squeeze data\n# dataset2015_y = df2015['Happiness Score'] # Pandas.Series (x.values -> numpy.ndarray)\ndataset2015_y = df2015[['Happiness Score']] # Pandas.DataFrame\n# dataset2015_x = df2015[['Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)', 'Freedom', 'Trust (Government Corruption)', 'Dystopia Residual']]\n# Delete 'Dystopia Residual', since this is not applicable for the year 2018 and 2019.\ndataset2015_x = df2015[['Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)', 'Freedom', 'Trust (Government Corruption)']]\n\n(train_x, test_x, train_y, test_y) = train_test_split(dataset2015_x, dataset2015_y, test_size=0.2, random_state=0) # just practice\n\n# Create model\n# Regression models\nRandomForest_model = RandomForestRegressor()\nDecisionTree_model = DecisionTreeRegressor()\n\n# Learning model (just compare DecisionTree vs RandomForest)\nDecisionTree_model.fit(train_x, train_y)\nRandomForest_model.fit(train_x, train_y)\n# DecisionTree_pred_y = DecisionTree_model.predict(test_x)\n# RandomForest_pred_y = RandomForest_model.predict(test_x)\nprint(f\"Decision Tree accuracy score: {DecisionTree_model.score(test_x, test_y)}\") #*.socre -->> R^2. Best case is R^2=1.0\nprint(f\"Random Forest accuracy score: {RandomForest_model.score(test_x, test_y)}\")\n# print(f\"Accuracy:{accuracy_score(test_y, predict_y)}\") # accuracy_score is applicable for classification model","d44be847":"from sklearn.model_selection import GridSearchCV\n\nmodel_param_grid = {RandomForestRegressor(): {\"n_estimators\": [i for i in range(100,120)],\n                                                  \"criterion\": [\"mse\",\"mae\"],\n                                                  \"max_depth\": [j for j in range(3,11)],\n                                                  \"random_state\":[0]}}\n\n# initialization\nbest_score = 0 \nbest_param = None\n\nfor model, param in model_param_grid.items():\n    reg = GridSearchCV(model, param)\n    reg.fit(train_x, train_y)\n    score = reg.score(test_x, test_y)\n    if best_score < score:\n        best_score = score\n        best_param = reg.best_params_ # .best_param_ -->> output best parameter\n        \nprint(f\"best parameters: {best_param}\")\nprint(f\"best score: {best_score}\")\n# Run this code takes time..., please wait.\n# Running Result:\n# best parameters: {'criterion': 'mae', 'max_depth': 5, 'n_estimators': 111, 'random_state': 0}\n# best score: 0.6759142902560764","2b701624":"# Since Dystopia Residual is not applicable for 2018 and 2019 year, let's delete it.\ndataset2016_y = df2016[['Happiness Score']]\ndataset2016_x = df2016[['Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)', 'Freedom', 'Trust (Government Corruption)']]\n\ndataset2017_y = df2017[['Happiness.Score']]\ndataset2017_x = df2017[['Economy..GDP.per.Capita.', 'Family', 'Health..Life.Expectancy.', 'Freedom', 'Trust..Government.Corruption.']]\n\ndataset2018_y = df2018[['Score']]\ndataset2018_x = df2018[['GDP per capita', 'Social support', 'Healthy life expectancy', 'Freedom to make life choices', 'Perceptions of corruption']]\n\ndataset2019_y = df2019[['Score']]\ndataset2019_x = df2019[['GDP per capita', 'Social support', 'Healthy life expectancy', 'Freedom to make life choices', 'Perceptions of corruption']]\n\nreg = RandomForestRegressor(n_estimators=104, criterion=\"mse\", max_depth=11, random_state=0) # set model parameters based on 2015 year data\nreg.fit(train_x, train_y)\nprint(f\"Random Forest 2015 accuracy score: {reg.score(test_x, test_y)}\")\nprint(f\"Random Forest 2016 accuracy score: {reg.score(dataset2016_x, dataset2016_y)}\")\nprint(f\"Random Forest 2017 accuracy score: {reg.score(dataset2017_x, dataset2017_y)}\")\n# print(f\"Random Forest 2018 accuracy score: {reg.score(dataset2018_x, dataset2018_y)}\") # not working because some cells are NaN\n# Change from NaN value to 0 the year 2018.\ndataset2018_y = dataset2018_y.fillna(0)\ndataset2018_x = dataset2018_x.fillna(0)\nprint(f\"Random Forest 2018 accuracy score: {reg.score(dataset2018_x, dataset2018_y)}\")\nprint(f\"Random Forest 2019 accuracy score: {reg.score(dataset2019_x, dataset2019_y)}\")","5069d414":"# Predict 2015 y data using model\n# Model name is \"reg\"\n# Original data: df_2015, dataset2015_y, dataset2015_x\ndataset2015_y_pred = reg.predict(dataset2015_x)\n# dataset2015_y_pred = pd.DataFrame(dataset2015_y_pred) # change type from numpy.ndarray to pandas DataFrame\ndataset2015_y_pred = pd.Series(dataset2015_y_pred) # change type from numpy.ndarray to pandas Series\n# Country dataset\ndataset2015_country = df2015['Country'] # pandas.Series, x-axis\ndataset2015_rank = df2015['Happiness Rank'] # pandas.Series, x-axis\n# Take Socre out from df2015 as Series\ndataset2015_score = df2015['Happiness Score'] # y-axis\n# Visualization\nfig = plt.figure(figsize=(24, 8))\nax1 = fig.add_subplot(121)\nax1.set_title('Original Score')\nax1.grid(True)\nax1.plot(dataset2015_rank, dataset2015_score, marker=\"o\")\nax2 = fig.add_subplot(122)\nax2.set_title('Predicted Score')\nax2.grid(True)\nax2.plot(dataset2015_rank, dataset2015_y_pred, marker=\"o\")\nplt.show()","b82eecc0":"# SMA = Sample Moving Average\nSMA3_2015_y_pred = dataset2015_y_pred.rolling(window=3).mean()\nSMA3_2015_y_pred = SMA3_2015_y_pred.fillna(0)\nSMA5_2015_y_pred = dataset2015_y_pred.rolling(window=5).mean()\nSMA5_2015_y_pred = SMA5_2015_y_pred.fillna(0)\nSMA7_2015_y_pred = dataset2015_y_pred.rolling(window=7).mean()\nSMA7_2015_y_pred = SMA5_2015_y_pred.fillna(0)\n\nfig = plt.figure(figsize=(24, 8))\nax1 = fig.add_subplot(121)\nax1.plot(dataset2015_rank, dataset2015_score, marker='o', color='black', alpha=0.6, label='original')\nax1.plot(dataset2015_rank, dataset2015_y_pred, marker='o', color='red', alpha=0.6, label='predicted')\nax1.plot(dataset2015_rank, SMA3_2015_y_pred, marker='s', color='green', alpha=0.6, label='3 SMA')\nax1.plot(dataset2015_rank, SMA5_2015_y_pred, marker='o', color='blue', alpha=0.6, label='5 SMA')\nax1.plot(dataset2015_rank, SMA7_2015_y_pred, marker='v', color='magenta', alpha=0.6, label='7 SMA')\nax1.grid(True)\nax1.legend()\nax2 = fig.add_subplot(122)\nax2.plot(dataset2015_rank, dataset2015_score, color='black', linestyle='solid', linewidth=3.0, label='original')\nax2.plot(dataset2015_rank, SMA3_2015_y_pred, marker='s', color='none', markeredgecolor='green', label='3 SMA')\nax2.plot(dataset2015_rank, SMA5_2015_y_pred, marker='o', color='none', markeredgecolor='blue', label='5 SMA')\nax2.plot(dataset2015_rank, SMA7_2015_y_pred, marker='v', color='none', markeredgecolor='magenta', label='7 SMA')\nax2.grid(True)\nax2.legend()\nplt.show()","0567c00b":"# Substitute predicted value from dataset2015_y_pred\nSMA5_2015_y_pred[0] = dataset2015_y_pred[0]\nSMA5_2015_y_pred[1] = dataset2015_y_pred[1]\nSMA5_2015_y_pred[2] = dataset2015_y_pred[2]\nSMA5_2015_y_pred[3] = dataset2015_y_pred[3]","9934e663":"# Calculate R^2 value (same as reg.score, refer to comment above)\nu = ((dataset2015_score - SMA5_2015_y_pred)**2).sum()\nv = ((dataset2015_score - dataset2015_score.mean())**2).sum()\nR2_score2015 = 1 - u\/v","e73f02f1":"# Predict 2016 y data using model\n# Model name is \"reg\"\n# Original data: df_2016, dataset2016_y, dataset2016_x\ndataset2016_y_pred = reg.predict(dataset2016_x)\ndataset2016_y_pred = pd.Series(dataset2016_y_pred) # change type from numpy.ndarray to pandas Series\n# Country dataset\ndataset2016_rank = df2016['Happiness Rank'] # pandas.Series, x-axis\n# Take Socre out from df2015 as Series\ndataset2016_score = df2016['Happiness Score'] # y-axis\n# Visualization\nfig = plt.figure(figsize=(24, 8))\nax1 = fig.add_subplot(121)\nax1.set_title('Original Score')\nax1.grid(True)\nax1.plot(dataset2016_rank, dataset2016_score, marker=\"o\")\nax2 = fig.add_subplot(122)\nax2.set_title('Predicted Score')\nax2.grid(True)\nax2.plot(dataset2016_rank, dataset2016_y_pred, marker=\"o\")\nplt.show()","38611b4c":"# SMA = Sample Moving Average\nSMA3_2016_y_pred = dataset2016_y_pred.rolling(window=3).mean()\nSMA3_2016_y_pred = SMA3_2016_y_pred.fillna(0)\nSMA5_2016_y_pred = dataset2016_y_pred.rolling(window=5).mean()\nSMA5_2016_y_pred = SMA5_2016_y_pred.fillna(0)\nSMA7_2016_y_pred = dataset2016_y_pred.rolling(window=7).mean()\nSMA7_2016_y_pred = SMA5_2016_y_pred.fillna(0)\n\nfig = plt.figure(figsize=(24, 8))\nax1 = fig.add_subplot(121)\nax1.plot(dataset2016_rank, dataset2016_score, marker='o', color='black', alpha=0.6, label='oroginal')\nax1.plot(dataset2016_rank, dataset2016_y_pred, marker='o', color='red', alpha=0.6, label='predicted')\nax1.plot(dataset2016_rank, SMA3_2016_y_pred, marker='s', color='green', alpha=0.6, label='3 SMA')\nax1.plot(dataset2016_rank, SMA5_2016_y_pred, marker='o', color='blue', alpha=0.6, label='5 SMA')\nax1.plot(dataset2016_rank, SMA7_2016_y_pred, marker='v', color='magenta', alpha=0.6, label='7 SMA')\nax1.grid(True)\nax1.legend()\nax2 = fig.add_subplot(122)\nax2.plot(dataset2016_rank, dataset2016_score, color='black', linestyle='solid', linewidth=3.0, label='original')\nax2.plot(dataset2016_rank, SMA3_2016_y_pred, marker='s', color='none', markeredgecolor='green', label='3 SMA')\nax2.plot(dataset2016_rank, SMA5_2016_y_pred, marker='o', color='none', markeredgecolor='blue', label='5 SMA')\nax2.plot(dataset2016_rank, SMA7_2016_y_pred, marker='v', color='none', markeredgecolor='magenta', label='7 SMA')\nax2.grid(True)\nax2.legend()\nplt.show()","ceb0c97a":"# Substitute predicted value from dataset2016_y_pred\nSMA5_2016_y_pred[0] = dataset2016_y_pred[0]\nSMA5_2016_y_pred[1] = dataset2016_y_pred[1]\nSMA5_2016_y_pred[2] = dataset2016_y_pred[2]\nSMA5_2016_y_pred[3] = dataset2016_y_pred[3]\n\nu = 0\nv = 0\n# Calculate R^2 value (same as reg.score, refer to comment above)\nu = ((dataset2016_score - SMA5_2016_y_pred)**2).sum()\nv = ((dataset2016_score - dataset2016_score.mean())**2).sum()\nR2_score2016 = 1 - u\/v","2ceb0e79":"# Predict 2017 y data using model\n# Model name is \"reg\"\n# Original data: df_2017, dataset2017_y, dataset2017_x\ndataset2017_y_pred = reg.predict(dataset2017_x)\ndataset2017_y_pred = pd.Series(dataset2017_y_pred) # change type from numpy.ndarray to pandas Series\n# Country dataset\ndataset2017_rank = df2017['Happiness.Rank'] # pandas.Series, x-axis\n# Take Socre out from df2015 as Series\ndataset2017_score = df2017['Happiness.Score'] # y-axis\n# Visualization\nfig = plt.figure(figsize=(24, 8))\nax1 = fig.add_subplot(121)\nax1.set_title('Original Score')\nax1.grid(True)\nax1.plot(dataset2017_rank, dataset2017_score, marker=\"o\")\nax2 = fig.add_subplot(122)\nax2.set_title('Predicted Score')\nax2.grid(True)\nax2.plot(dataset2017_rank, dataset2017_y_pred, marker=\"o\")\nplt.show()","92f6ecf9":"# SMA = Sample Moving Average\nSMA3_2017_y_pred = dataset2017_y_pred.rolling(window=3).mean()\nSMA3_2017_y_pred = SMA3_2017_y_pred.fillna(0)\nSMA5_2017_y_pred = dataset2017_y_pred.rolling(window=5).mean()\nSMA5_2017_y_pred = SMA5_2017_y_pred.fillna(0)\nSMA7_2017_y_pred = dataset2017_y_pred.rolling(window=7).mean()\nSMA7_2017_y_pred = SMA5_2017_y_pred.fillna(0)\n\nfig = plt.figure(figsize=(24, 8))\nax1 = fig.add_subplot(121)\nax1.plot(dataset2017_rank, dataset2017_score, marker='o', color='black', alpha=0.6, label='oroginal')\nax1.plot(dataset2017_rank, dataset2017_y_pred, marker='o', color='red', alpha=0.6, label='predicted')\nax1.plot(dataset2017_rank, SMA3_2017_y_pred, marker='s', color='green', alpha=0.6, label='3 SMA')\nax1.plot(dataset2017_rank, SMA5_2017_y_pred, marker='o', color='blue', alpha=0.6, label='5 SMA')\nax1.plot(dataset2017_rank, SMA7_2017_y_pred, marker='v', color='magenta', alpha=0.6, label='7 SMA')\nax1.grid(True)\nax1.legend()\nax2 = fig.add_subplot(122)\nax2.plot(dataset2017_rank, dataset2017_score, color='black', linestyle='solid', linewidth=3.0, label='original')\nax2.plot(dataset2017_rank, SMA3_2017_y_pred, marker='s', color='none', markeredgecolor='green', label='3 SMA')\nax2.plot(dataset2017_rank, SMA5_2017_y_pred, marker='o', color='none', markeredgecolor='blue', label='5 SMA')\nax2.plot(dataset2017_rank, SMA7_2017_y_pred, marker='v', color='none', markeredgecolor='magenta', label='7 SMA')\nax2.grid(True)\nax2.legend()\nplt.show()","812bc4cc":"# Substitute predicted value from dataset2017_y_pred\nSMA5_2017_y_pred[0] = dataset2017_y_pred[0]\nSMA5_2017_y_pred[1] = dataset2017_y_pred[1]\nSMA5_2017_y_pred[2] = dataset2017_y_pred[2]\nSMA5_2017_y_pred[3] = dataset2017_y_pred[3]\n\nu = 0\nv = 0\n# Calculate R^2 value (same as reg.score, refer to comment above)\nu = ((dataset2017_score - SMA5_2017_y_pred)**2).sum()\nv = ((dataset2017_score - dataset2017_score.mean())**2).sum()\nR2_score2017 = 1 - u\/v","a1970c84":"# predict 2018 y data using model\n# Model name is \"reg\"\n# Original data: df_2018, dataset2018_y, dataset2018_x\ndataset2018_y_pred = reg.predict(dataset2018_x)\ndataset2018_y_pred = pd.Series(dataset2018_y_pred) # change type from numpy.ndarray to pandas Series\n# Country dataset\ndataset2018_rank = df2018['Overall rank'] # pandas.Series, x-axis\n# Take Socre out from df2015 as Series\ndataset2018_score = df2018['Score'] # y-axis\n# Visualization\nfig = plt.figure(figsize=(24, 8))\nax1 = fig.add_subplot(121)\nax1.set_title('Original Score')\nax1.grid(True)\nax1.plot(dataset2018_rank, dataset2018_score, marker=\"o\")\nax2 = fig.add_subplot(122)\nax2.set_title('Predicted Score')\nax2.grid(True)\nax2.plot(dataset2018_rank, dataset2018_y_pred, marker=\"o\")\nplt.show()","3122b635":"# SMA = Sample Moving Average\nSMA3_2018_y_pred = dataset2018_y_pred.rolling(window=3).mean()\nSMA3_2018_y_pred = SMA3_2018_y_pred.fillna(0)\nSMA5_2018_y_pred = dataset2018_y_pred.rolling(window=5).mean()\nSMA5_2018_y_pred = SMA5_2018_y_pred.fillna(0)\nSMA7_2018_y_pred = dataset2018_y_pred.rolling(window=7).mean()\nSMA7_2018_y_pred = SMA5_2018_y_pred.fillna(0)\n\nfig = plt.figure(figsize=(24, 8))\nax1 = fig.add_subplot(121)\nax1.plot(dataset2018_rank, dataset2018_score, marker='o', color='black', alpha=0.6, label='oroginal')\nax1.plot(dataset2018_rank, dataset2018_y_pred, marker='o', color='red', alpha=0.6, label='predicted')\nax1.plot(dataset2018_rank, SMA3_2018_y_pred, marker='s', color='green', alpha=0.6, label='3 SMA')\nax1.plot(dataset2018_rank, SMA5_2018_y_pred, marker='o', color='blue', alpha=0.6, label='5 SMA')\nax1.plot(dataset2018_rank, SMA7_2018_y_pred, marker='v', color='magenta', alpha=0.6, label='7 SMA')\nax1.grid(True)\nax1.legend()\nax2 = fig.add_subplot(122)\nax2.plot(dataset2018_rank, dataset2018_score, color='black', linestyle='solid', linewidth=3.0, label='original')\nax2.plot(dataset2018_rank, SMA3_2018_y_pred, marker='s', color='none', markeredgecolor='green', label='3 SMA')\nax2.plot(dataset2018_rank, SMA5_2018_y_pred, marker='o', color='none', markeredgecolor='blue', label='5 SMA')\nax2.plot(dataset2018_rank, SMA7_2018_y_pred, marker='v', color='none', markeredgecolor='magenta', label='7 SMA')\nax2.grid(True)\nax2.legend()\nplt.show()\n","c4b83e65":"# Substitute predicted value from dataset2018_y_pred\nSMA5_2018_y_pred[0] = dataset2018_y_pred[0]\nSMA5_2018_y_pred[1] = dataset2018_y_pred[1]\nSMA5_2018_y_pred[2] = dataset2018_y_pred[2]\nSMA5_2018_y_pred[3] = dataset2018_y_pred[3]\n\nu = 0\nv = 0\n# Calculate R^2 value (same as reg.score, refer to comment above)\nu = ((dataset2018_score - SMA5_2018_y_pred)**2).sum()\nv = ((dataset2018_score - dataset2018_score.mean())**2).sum()\nR2_score2018 = 1 - u\/v","d89df64e":"# Predict 2019 y data using model\n# Model name is \"reg\"\n# Original data: df_2019, dataset2019_y, dataset2019_x\ndataset2019_y_pred = reg.predict(dataset2019_x)\ndataset2019_y_pred = pd.Series(dataset2019_y_pred) # change type from numpy.ndarray to pandas Series\n# Country dataset\ndataset2019_rank = df2019['Overall rank'] # pandas.Series, x-axis\n# Take Socre out from df2015 as Series\ndataset2019_score = df2019['Score'] # y-axis\n# Visualization\nfig = plt.figure(figsize=(24, 8))\nax1 = fig.add_subplot(121)\nax1.set_title('Original Score')\nax1.grid(True)\nax1.plot(dataset2019_rank, dataset2019_score, marker=\"o\")\nax2 = fig.add_subplot(122)\nax2.set_title('Predicted Score')\nax2.grid(True)\nax2.plot(dataset2019_rank, dataset2019_y_pred, marker=\"o\")\nplt.show()","3b226ef9":"# SMA = Sample Moving Average\nSMA3_2019_y_pred = dataset2019_y_pred.rolling(window=3).mean()\nSMA3_2019_y_pred = SMA3_2019_y_pred.fillna(0)\nSMA5_2019_y_pred = dataset2019_y_pred.rolling(window=5).mean()\nSMA5_2019_y_pred = SMA5_2019_y_pred.fillna(0)\nSMA7_2019_y_pred = dataset2019_y_pred.rolling(window=7).mean()\nSMA7_2019_y_pred = SMA5_2019_y_pred.fillna(0)\n\nfig = plt.figure(figsize=(24, 8))\nax1 = fig.add_subplot(121)\nax1.plot(dataset2019_rank, dataset2019_score, marker='o', color='black', alpha=0.6, label='oroginal')\nax1.plot(dataset2019_rank, dataset2019_y_pred, marker='o', color='red', alpha=0.6, label='predicted')\nax1.plot(dataset2019_rank, SMA3_2019_y_pred, marker='s', color='green', alpha=0.6, label='3 SMA')\nax1.plot(dataset2019_rank, SMA5_2019_y_pred, marker='o', color='blue', alpha=0.6, label='5 SMA')\nax1.plot(dataset2019_rank, SMA7_2019_y_pred, marker='v', color='magenta', alpha=0.6, label='7 SMA')\nax1.grid(True)\nax1.legend()\nax2 = fig.add_subplot(122)\nax2.plot(dataset2019_rank, dataset2019_score, color='black', linestyle='solid', linewidth=3.0, label='original')\nax2.plot(dataset2019_rank, SMA3_2019_y_pred, marker='s', color='none', markeredgecolor='green', label='3 SMA')\nax2.plot(dataset2019_rank, SMA5_2019_y_pred, marker='o', color='none', markeredgecolor='blue', label='5 SMA')\nax2.plot(dataset2019_rank, SMA7_2019_y_pred, marker='v', color='none', markeredgecolor='magenta', label='7 SMA')\nax2.grid(True)\nax2.legend()\nplt.show()","5902ca52":"# Substitute predicted value from dataset2019_y_pred\nSMA5_2019_y_pred[0] = dataset2019_y_pred[0]\nSMA5_2019_y_pred[1] = dataset2019_y_pred[1]\nSMA5_2019_y_pred[2] = dataset2019_y_pred[2]\nSMA5_2019_y_pred[3] = dataset2019_y_pred[3]\n\nu = 0\nv = 0\n# Calculate R^2 value (same as reg.score, refer to comment above)\nu = ((dataset2019_score - SMA5_2019_y_pred)**2).sum()\nv = ((dataset2019_score - dataset2019_score.mean())**2).sum()\nR2_score2019 = 1 - u\/v","10cb5ac2":"print(f\"Random Forest 2015 accuracy score: {reg.score(test_x, test_y)}\")\nprint(f\"Random Forest 2016 accuracy score: {reg.score(dataset2016_x, dataset2016_y)}\")\nprint(f\"Random Forest 2017 accuracy score: {reg.score(dataset2017_x, dataset2017_y)}\")\nprint(f\"Random Forest 2018 accuracy score: {reg.score(dataset2018_x, dataset2018_y)}\")\nprint(f\"Random Forest 2019 accuracy score: {reg.score(dataset2019_x, dataset2019_y)}\")\nprint()\nprint(f\"RandoForest Regressor + 5 Sample Moving Average 2015 accuracy score: {R2_score2015}\")\nprint(f\"RandoForest Regressor + 5 Sample Moving Average 2016 accuracy score: {R2_score2016}\")\nprint(f\"RandoForest Regressor + 5 Sample Moving Average 2017 accuracy score: {R2_score2017}\")\nprint(f\"RandoForest Regressor + 5 Sample Moving Average 2018 accuracy score: {R2_score2018}\")\nprint(f\"RandoForest Regressor + 5 Sample Moving Average 2019 accuracy score: {R2_score2019}\")\n\nlists = ['RF only', 'RF+5SMA']\nscore_2015 = [reg.score(test_x, test_y), R2_score2015]\nscore_2016 = [reg.score(dataset2016_x, dataset2016_y), R2_score2015]\nscore_2017 = [reg.score(dataset2017_x, dataset2017_y), R2_score2016]\nscore_2018 = [reg.score(dataset2018_x, dataset2018_y), R2_score2017]\nscore_2019 = [reg.score(dataset2019_x, dataset2019_y), R2_score2019]\nplt.figure(figsize=(8,6))\nplt.plot(lists, score_2015, label=\"2015\", marker=\"o\")\nplt.plot(lists, score_2016, label=\"2016\", marker=\"s\")\nplt.plot(lists, score_2018, label=\"2017\", marker=\"^\")\nplt.plot(lists, score_2018, label=\"2018\", marker=\"+\")\nplt.plot(lists, score_2019, label=\"2019\", marker=\"x\")\nplt.title(\"Score Visualization\", fontsize=16)\nplt.legend()\nplt.show()","4f3600a2":"> # 1.4 See 2018 Data Set","76040f6f":"> # 1.3 See 2017 Data Set","ff09fd57":"# 1. See Data Contents\nImport pyhton modules.","4a8c3df7":"> # 1.6 Overall Summery\nScore is releated with:\n**GDP(Economy), Social support(Family), Health, Freedom, Dystopia Residual(2015-2017) and Perception of corruption(Trust)**","fb87ad27":"R^2 is calculated by following formula.\n![image.png](attachment:image.png)","ff3ce26d":"Result:\nbest parameters: {'criterion': 'mae', 'max_depth': 5, 'n_estimators': 111, 'random_state': 0}\nbest score: 0.6759142902560764\n\nLet's decide happiness score model as following:\n1. Method: Randomforest\n2. criterion: mae\n3. max_depth: 5\n4. n_estimators: 111","0c5c55ea":"Accuracy score is up!\n* 2015 accuracy score: 0.6328252075110332 (RandomForest only)-> 0.9610705695304208 (RandomForest + 5 SMA)\n* 2016 accuracy score: 0.6789739643887525 (RandomForest only)-> 0.8298372434032892 (RandomForest + 5 SMA)\n* 2017 accuracy score: 0.7360540732247438 (RandomForest only)-> 0.8328173340076496 (RandomForest + 5 SMA)\n* 2018 accuracy score: 0.7635168040261362 (RandomForest only)-> 0.8706264800074008 (RandomForest + 5 SMA)\n* 2019 accuracy score: 0.7090733869747737 (RandomForest only)-> 0.8007021950491932 (RandomForest + 5 SMA)","9e1c80e5":"> # 3.2 Apply Sample Moving Average to Smooth","14cb37b4":"It looks like ***random forest algorithm*** is better than ***decision tree algorithrm***.\nLet's do **grid search** using Random Forest Regressor","d44a672a":"It looks like **5 SMA (5 Simple Moving Average)** is good.\nLet's use this. And get the score again.\n*Note: Need to substitute some initial value (from row 0 to 3)","7d46edc1":"2017 result looks like:\n\n1. Positive Correlationhip (over 0.5)\n    * Happiness Score VS Whisker.high, Whisker.low, Economy, Family, Health, Freedom, Dystopia Residual\n    * Whisker.high VS Whisker.low, Economy, Family, Health, Freedom, Dystopia Residual\n    * Whisker.low VS Economy, Family, Health, Freedom, Dystopia Residual\n    * Economy VS Family, Health\n    * Family VS Health\n    * Freedom VS Trust\n\n\n2. Negative Correlationship (less -0.5)\n    * Happiness Rank VS Happiness Score, Whisker.high, Whisker.low, Economy, Family, Health, Freedom, Dystopia Residual\n\nTherefore, it seems that:\nHappiness Score is related with **Whisker.high, Whisker.low, Economy, Family, Health, Freedom, Dystopia Residual and Trust**\n","f70d9254":"> # 1.7 Visualize Happiness Score in the world map","85fbf0fa":"> # 1.1 See 2015 Data Set\nBasic visulalization by seaborn (pairplot, heatmap) in order to see the correlation.","02567139":"# 3. Improve the Model\n> # 3.1 Visualize Hapiness Score predicted by the Model\nLet's visualize model vs real data!","532948c9":"Result:\n* Random Forest 2015 accuracy score: 0.6328252075110332\n* Random Forest 2016 accuracy score: 0.6789739643887525\n* Random Forest 2017 accuracy score: 0.7360540732247438\n* Random Forest 2018 accuracy score: 0.7635168040261362\n* Random Forest 2019 accuracy score: 0.7090733869747737\n\nThe score of year 2016 is not good, but except that, it looks good (maybe).\nSo, let's predict 2020 hapiness socre.\nFirstly, we need to get the predicted value of 'GDP per capita', 'Social support', 'Healthy life expectancy', 'Freedom to make life choices', 'Perceptions of corruption' based on hitorical data from 2015-2019.","39aa710f":"# 4. Conclusion: Model Comparion ","c439e612":"> # 2.2 Define Best Parameters by GridSearch","211620ab":"2016 result looks like:\n\n1. Positive Correlationhip (over 0.5)\n\n    * Happiness Score VS Low Confidence Interval, Upper Confidence Interval, Economy, Family, Health, Freedom, Dystopia Residual\n    * Low Confidence Interval VS Upper Confidence Interval, Economy, Family, Health, Freedom, Dystopia Residual\n    * Upper Confidence Interval VS Economy, Family, Health, Freedom, Dystopia Residual\n    * Economy VS Family, Health\n    * Family VS Health\n    * Freedom VS Trust\n\n\n2. Negative Correlationship (less -0.5)\n    * Happiness Rank VS Happiness Score, Low Confidence Interval, Upper Confidence Interval, Economy, Family, Health, Freedom, Dystopia Residual \n\nTherefore, it seems that:\nHappiness Score is related with **Low Confidence Interval, Upper Confidence Interval, Economy, Family, Health, Freedom, Dystopia Residual and Trust**","6dd7a22e":"2018 result looks like:\n\n1. Positive Correlationhip (over 0.5)\n    * Score VS GDP(Economy), Social support(Family), Health, Freedom, Perception of corruption(Trust)\n    * GDP(Economy) VS Social support(Family), Health\n    * Social support(Family) VS Health, Freedom\n    * Freedom VS Perception of corruption(Trust)\n\n\n2. Negative Correlationship (less -0.5)\n    * Overall rank VS Score, GDP(Economy), Social support(Family), Health\n\nTherefore, it seems that:\nScore is related with **GDP(Economy), Social support(Family), Health, Freedom and Perception of corruption(Trust)**","d3b21851":"2019 result looks like:\n\n1. Positive Correlationhip (over 0.5)\n    * Score VS GDP(Economy), Social support(Family), Health, Freedom, Perception of corruption(Trust)\n    * GDP(Economy) VS Social support(Family), Health\n    * Social support(Family) VS Health, Freedom\n    * Freedom VS Perception of corruption(Trust)\n\n\n2. Negative Correlationship (less -0.5)\n    * Overall rank VS Score, GDP(Economy), Social support(Family), Health\n\nTherefore, it seems that:\nScore is related with **GDP(Economy), Social support(Family), Health, Freedom and Perception of corruption(Trust)**\n","c8ecb8fd":"> # 2.3 Apply the Model to 2016-2019 data","52becbd5":"2015 result looks like:\n\n1. Positive Correlationhip (over 0.5)\n    * Happiness Score VS Economy, Family, Health, Freedom, Dystopia Residual\n    * Economy VS Family, Health\n    * Family VS Health\n    * Freedom VS Trust\n\n\n2. Negative Correlationship (less -0.5)\n    * Happiness Rank VS Happiness Score, Economy, Family, Health, Freedom, Dystopia Residual \n\nTherefore, it seems that:\nHappiness Score is related with: **Economy, Family, Health, Freedom, Dystopia Residual and Trust**\n","3a11fac6":"> # 1.5 See 2019 Data Set","2828e997":"> # 1.2 See 2016 Data Set","895c1b21":"# 2. Create Model\n> # 2.1 Create Machine Learning by uing 2015 data\nLet's predict it by machine learning method. Firstly, create a model by using 2015 data."}}