{"cell_type":{"996ebcb1":"code","daea1d23":"code","4465038e":"code","f1302384":"code","3021f48d":"code","fa3f91db":"code","497c56b8":"code","f43150fa":"code","e4c15550":"code","64d81434":"code","33e713d3":"code","4463d9d7":"code","0b4cba3a":"code","62657ab4":"code","9c3f73f3":"code","9ef371c4":"code","7e9a1c16":"code","ad5f27d2":"code","9e369388":"code","d0ec8c70":"code","27d9a0c2":"code","32b1a141":"code","e9f82ae6":"code","d35dfcf1":"code","76de5ede":"code","47b08889":"markdown","3e2042b6":"markdown"},"source":{"996ebcb1":"import os\nimport random\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, models,Sequential\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import KFold\n\nimport tensorflow_addons as tfa\n\nimport cv2, numpy as np","daea1d23":"train_data_csv = '..\/input\/petfinder-pawpularity-score\/train.csv'\ntest_data_csv  = '..\/input\/petfinder-pawpularity-score\/test.csv'\ntrain_folder = '..\/input\/petfinder-pawpularity-score\/train'\ntest_folder  = '..\/input\/petfinder-pawpularity-score\/test'","4465038e":"## parameter setting\ny = 'Pawpularity'\n# validation_size = 0.3\nautotune = tf.data.experimental.AUTOTUNE\nimg_size = 299\nbatch_size = 8\ndropout = 0.3\nlr = 1e-3\ndecay_steps = 100\ndecay_rate = 0.95\nepochs = 100\nKFOLD = 3","f1302384":"def id_to_path(img_id,dir):\n    return os.path.join(dir, f'{img_id}.jpg')","3021f48d":"def get_image(path):\n    image = tf.image.decode_jpeg(tf.io.read_file(path), channels=3)\n    image = tf.cast(tf.image.resize_with_pad(image, img_size, img_size), dtype=tf.float32)\n    return tf.keras.applications.inception_resnet_v2.preprocess_input(image)","fa3f91db":"def process_dataset(path, label):\n    return get_image(path), label","497c56b8":"def get_dataset(x, y=None):\n    if y is not None:\n        ds = tf.data.Dataset.from_tensor_slices((x, y))\n        return ds.map(process_dataset, num_parallel_calls=autotune) \\\n            .batch(batch_size).prefetch(buffer_size=autotune)\n    else:\n        ds = tf.data.Dataset.from_tensor_slices(x)\n        return ds.map(get_image, num_parallel_calls=autotune) \\\n            .batch(batch_size).prefetch(buffer_size=autotune)","f43150fa":"data_train = pd.read_csv(train_data_csv)\ndata_train.head()","e4c15550":"data_test = pd.read_csv(test_data_csv)\ndata_test.head()","64d81434":"data_train['path'] = data_train['Id'].apply(lambda x: id_to_path(x, train_folder))\ndata_test['path'] = data_test['Id'].apply(lambda x: id_to_path(x, test_folder))\n\n# train_subset, valid_subset = train_test_split(\n#     data_train[['path', y]],\n#     test_size=validation_size, shuffle=True, random_state=777\n# )\n\nskf = KFold(n_splits=KFOLD, random_state=777, shuffle=True)\ndata_train['fold'] = -1\nfor nth, (_, valid_index) in enumerate(skf.split(data_train)):\n    data_train.loc[valid_index, 'fold'] = nth","33e713d3":"data_train.head()","4463d9d7":"data_train.path","0b4cba3a":"data_train","62657ab4":"data_train.fold.value_counts()","9c3f73f3":"model = tf.keras.models.load_model('..\/input\/keras-applications-models\/InceptionResNetV2.h5')\nmodel.trainable = False","9ef371c4":"inputs = tf.keras.layers.Input(shape=(img_size, img_size, 3))\nx = tf.keras.layers.experimental.preprocessing.RandomFlip(mode=\"horizontal_and_vertical\")(inputs)\nx = tf.keras.layers.experimental.preprocessing.RandomRotation(0.2)(x)\nx = tf.keras.layers.experimental.preprocessing.RandomZoom(0.2)(x)\nx = tf.keras.layers.experimental.preprocessing.RandomHeight(0.2)(x)\nx = tf.keras.layers.experimental.preprocessing.RandomWidth(0.2)(x)\n# x = tf.keras.layers.experimental.preprocessing.RandomContrast(0.2)(x)\nx = model(x)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.Dropout(dropout, name='top_dropout')(x)\nx = tf.keras.layers.Dense(32, activation='relu')(x)\nx = tf.keras.layers.Dropout(dropout, name='second_dropout')(x)\nx = tf.keras.layers.Dense(16, activation='relu')(x)\noutputs = tf.keras.layers.Dense(1,activation='linear')(x)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)","7e9a1c16":"lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=lr,\n    decay_steps=decay_steps, decay_rate=decay_rate,staircase=True)\n\nearly_stop = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', patience=10, restore_best_weights=True)","ad5f27d2":"from tensorflow.keras import backend as K\ndef rmse(y_true, y_pred):\n    return K.sqrt(K.mean(K.square(y_true*100 - y_pred*100)))\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n                    loss=rmse,\n                    metrics=[rmse])","9e369388":"##modeling\nprediction_lists = pd.DataFrame()\nfor i in range(0,KFOLD):\n    train_subset = data_train[data_train['fold'] != i]\n    train_subset = train_subset[['path',y]]\n    valid_subset = data_train[data_train['fold'] == i]\n    valid_subset = valid_subset[['path',y]]\n    train_data = get_dataset(x=train_subset['path'], y=train_subset[y]\/100.)\n    valid_data = get_dataset(x=valid_subset['path'], y=valid_subset[y]\/100.)\n    test_data = get_dataset(x=data_test['path'])\n\n    history=model.fit(train_data,validation_data=valid_data, epochs=epochs,verbose=1,callbacks=[early_stop],use_multiprocessing=True, workers=-1)\n    history_frame = pd.DataFrame(history.history)\n    history_frame.loc[:, ['loss', 'val_loss']].plot()\n    history_frame.loc[:, ['rmse', 'val_rmse']].plot()\n\n    ##prediction\n    data_test[y+str(i)] = model.predict(test_data,use_multiprocessing=True, workers=os.cpu_count())*100\n    data_test[y+str(i)] = data_test[y+str(i)].round()\n    prediction_lists = pd.concat([prediction_lists,data_test[[y+str(i)]]],axis=1)","d0ec8c70":"# import pandas as pd\n\n# history_frame = pd.DataFrame(history.history)\n\n# history_frame.loc[:, ['loss', 'val_loss']].plot()\n# history_frame.loc[:, ['rmse', 'val_rmse']].plot()","27d9a0c2":"prediction_lists","32b1a141":"prediction_lists.mean(axis=1)","e9f82ae6":"data_test[y] = prediction_lists.mean(axis=1).round()\ndata_test[['Id', y]].to_csv('submission.csv', index=False)\ndata_test[['Id', y]].head()","d35dfcf1":"# ##prediction\n# data_test[y] = model.predict(test_data,use_multiprocessing=True, workers=os.cpu_count())*100\n# data_test[y] = data_test[y].round()","76de5ede":"###\ndef InputData():\n    pass\n\ndef Modeling():\n    pass\n\ndef Prediction():\n    pass\n\ndef main():\n    InputData()\n    \n    Modeling()\n    \n    Prediction()\n","47b08889":"## Hyperparameter for our newtowk","3e2042b6":"### It rewrite the notebook \"https:\/\/www.kaggle.com\/vijayshankar756\/inception-rethink\" from using Siquential input keras to Functional API. <br>\n### You can use multiple Deep Neural Network model this notebook. <br>\n### please upvote \"https:\/\/www.kaggle.com\/vijayshankar756\/inception-rethink\" notebook. <br>\n### It simple and easy to understand code! <br>"}}