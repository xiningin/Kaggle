{"cell_type":{"1bd354cd":"code","97f0e6a4":"code","f157c004":"code","6f15cf08":"code","885a46a4":"code","bdd9b87d":"code","22d82abb":"code","3dbeb000":"code","5b28c863":"code","27599550":"code","46ed9c8e":"code","d4525f80":"code","79c319b6":"code","8fd3871d":"code","5a136ce5":"code","539e19aa":"code","91634e99":"code","9f5736c4":"code","cb30d399":"code","d8c5886c":"code","20675af9":"code","ac1633ab":"code","d4a3df25":"code","181b0c15":"code","d52b0725":"code","5a26f54e":"code","1310bee7":"code","e63268f4":"code","ca40a32b":"code","96232ad8":"code","274f4e8c":"code","78c93d0d":"code","cb865c40":"code","c534747c":"code","fb64d495":"code","72c207d9":"code","c3c4a6c2":"code","7835c0bf":"code","88ac0ceb":"code","26b883ca":"code","0abced55":"code","a797c953":"code","f43a285a":"code","d085508c":"code","1854f9bc":"code","14b4634b":"code","fc2396e1":"code","10711af1":"code","9962cfce":"code","2e5f60bb":"code","c7270bda":"code","acf47d9f":"code","b91fb623":"code","a24f258f":"code","e95d0725":"code","c6ff9fb1":"code","76a0ec23":"code","69a0d240":"code","7f778323":"code","3dcf94cb":"markdown","779b45bd":"markdown","0b573f76":"markdown","793f4bdb":"markdown","1fc60ffe":"markdown","826907fa":"markdown","bc36e187":"markdown","502f9d5e":"markdown","d2ee69ba":"markdown","6eb1e0c2":"markdown","d20ab946":"markdown","c1062649":"markdown","d479ac14":"markdown","c224c358":"markdown","69190024":"markdown","f9779271":"markdown","13d074a0":"markdown","f5e81e14":"markdown","d157d421":"markdown","21338330":"markdown","e2598a44":"markdown","206db77b":"markdown","69efe2b5":"markdown"},"source":{"1bd354cd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","97f0e6a4":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","f157c004":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\")\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn.compose import ColumnTransformer","6f15cf08":"train.head()","885a46a4":"train.isnull().sum()","bdd9b87d":"train = train.drop([\"PassengerId\"], axis=1)\ntrain = train.drop([\"Survived\"], axis=1)\ntrain = train.drop([\"Ticket\"], axis=1)","22d82abb":"train.Embarked = train.Embarked.fillna('S')","3dbeb000":"train['Title'] = train.Name.apply(lambda name: name.split(',')[1].split('.')[0].strip())","5b28c863":"normalized_titles = {\n    \"Capt\":       \"Officer\",\n    \"Col\":        \"Officer\",\n    \"Major\":      \"Officer\",\n    \"Jonkheer\":   \"Royalty\",\n    \"Don\":        \"Royalty\",\n    \"Sir\" :       \"Royalty\",\n    \"Dr\":         \"Officer\",\n    \"Rev\":        \"Officer\",\n    \"the Countess\":\"Royalty\",\n    \"Dona\":       \"Royalty\",\n    \"Mme\":        \"Mrs\",\n    \"Mlle\":       \"Miss\",\n    \"Ms\":         \"Mrs\",\n    \"Mr\" :        \"Mr\",\n    \"Mrs\" :       \"Mrs\",\n    \"Miss\" :      \"Miss\",\n    \"Master\" :    \"Master\",\n    \"Lady\" :      \"Royalty\"\n}\ntrain.Title = train.Title.map(normalized_titles)\ntrain = train.drop([\"Name\"], axis=1)\n\nTitle_Medians = train.groupby('Title').median()\nTitle_Medians.Age","27599550":"train.Title.value_counts()","46ed9c8e":"#train.loc[train['Title'] == \"Officer\"].Age = train.loc[train['Title'] == \"Officer\"].Age.fillna(train.loc[train['Title'] == 'Officer'][\"Age\"].mean(skipna = True))","d4525f80":"#MrT = train.loc[train['Title'] == \"Mr\"]\n#MissT = train.loc[train['Title'] == \"Miss\"]\n#MrsT = train.loc[train['Title'] == \"Mrs\"]\n#MasterT = train.loc[train['Title'] == \"Master\"]\n#OfficerT = train.loc[train['Title'] == \"Officer\"]\n#RoyaltyT = train.loc[train['Title'] == \"Royalty\"]","79c319b6":"#MrT.Age = MrT.Age.fillna(Title_Medians[\"Age\"][\"Mr\"])\n#MissT.Age = MissT.Age.fillna(Title_Medians[\"Age\"][\"Miss\"])\n#MrsT.Age = MrsT.Age.fillna(Title_Medians[\"Age\"][\"Mrs\"])\n#MasterT.Age = MasterT.Age.fillna(Title_Medians[\"Age\"][\"Master\"])\n#OfficerT.Age = OfficerT.Age.fillna(Title_Medians[\"Age\"][\"Officer\"])\n#RoyaltyT.Age = RoyaltyT.Age.fillna(Title_Medians[\"Age\"][\"Royalty\"])","8fd3871d":"#X = pd.concat([MrT,MissT,MrsT,MasterT,OfficerT,RoyaltyT])\n#train = X.sort_index()\n#train","5a136ce5":"grouped = train.groupby(['Title'])  \ngrouped","539e19aa":"train.Age = grouped.Age.apply(lambda x: x.fillna(x.median()))","91634e99":"train.Cabin = train.Cabin.fillna('U')\ntrain.Cabin = train.Cabin.str.slice(0,1)\ntrain[\"Cabin\"].value_counts()","9f5736c4":"train.head()","cb30d399":"corr = train.corr()\ncorr[\"Age\"].sort_values(ascending=False)","d8c5886c":"def data_preparation(X):\n    \n    X = X.drop([\"Ticket\",\"PassengerId\"], axis=1)\n    \n    X.Embarked = X.Embarked.fillna('S')\n    X.Fare = X.Fare.fillna(X.Fare.median())\n    \n    X['Title'] = X.Name.apply(lambda name: name.split(',')[1].split('.')[0].strip())\n    normalized_titles = {\n        \"Capt\":       \"Officer\",\n        \"Col\":        \"Officer\",\n        \"Major\":      \"Officer\",\n        \"Jonkheer\":   \"Royalty\",\n        \"Don\":        \"Royalty\",\n        \"Sir\" :       \"Royalty\",\n        \"Dr\":         \"Officer\",\n        \"Rev\":        \"Officer\",\n        \"the Countess\":\"Royalty\",\n        \"Dona\":       \"Royalty\",\n        \"Mme\":        \"Mrs\",\n        \"Mlle\":       \"Miss\",\n        \"Ms\":         \"Mrs\",\n        \"Mr\" :        \"Mr\",\n        \"Mrs\" :       \"Mrs\",\n        \"Miss\" :      \"Miss\",\n        \"Master\" :    \"Master\",\n        \"Lady\" :      \"Royalty\"\n    }\n    X.Title = X.Title.map(normalized_titles)\n    X = X.drop([\"Name\"], axis=1)\n    \n    grouped = X.groupby(['Title'])  \n    X.Age = grouped.Age.apply(lambda x: x.fillna(x.median()))\n    \n    X.Cabin = X.Cabin.fillna('U')\n    X.Cabin = X.Cabin.str.slice(0,1)\n    \n    return X","20675af9":"from sklearn.preprocessing import OneHotEncoder\n\nnum_features = [\"Age\", \"Fare\", \"SibSp\", \"Parch\"]\nnum_pipeline = make_pipeline(StandardScaler())\n\ncat_features = [\"Pclass\", \"Sex\", \"Cabin\", \"Embarked\", \"Title\"]\ncat_pipeline = make_pipeline(OneHotEncoder(handle_unknown=\"ignore\"))\n\npreprocessor = ColumnTransformer(transformers=[\n    (\"num\", num_pipeline, num_features),\n    (\"cat\", cat_pipeline, cat_features)\n])","ac1633ab":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","d4a3df25":"Xpreprocessed = data_preparation(train)\n\nX_train, X_test, y_train, y_test = train_test_split(Xpreprocessed,Xpreprocessed.Survived,test_size=100, random_state = 50)\nX_test = X_test.drop([\"Survived\"], axis = 1)\nX_train = X_train.drop([\"Survived\"], axis = 1)\n\nmodel = RandomForestClassifier()\nclassification_process = make_pipeline(preprocessor, model)\nclassification_process.fit(X_train, y_train)\n\naccuracy_score(y_test, classification_process.predict(X_test))","181b0c15":"X_test = data_preparation(test)\nX_train = data_preparation(train)\ny_train = X_train.Survived\nX_train = X_train.drop([\"Survived\"], axis = 1)","d52b0725":"classification_process.fit(X_train, y_train)\npredictions = classification_process.predict(X_test)\nresult = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\n#result.to_csv('first_result.csv', index=False)\nprint(result)","5a26f54e":"train[\"Parch\"].value_counts()","1310bee7":"train[\"SibSp\"].value_counts()","e63268f4":"X_train = data_preparation(train)","ca40a32b":"features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Cabin\", \"Embarked\", \"Title\", \"Survived\", \"Fare\", \"Age\"]\ncorrcheck = pd.get_dummies(X_train[features])\ncorrcheck.head()","96232ad8":"corr = corrcheck.corr()\ncorr[\"Survived\"].sort_values(ascending=False)","274f4e8c":"X_train[\"Title\"].value_counts()","78c93d0d":"plt.scatter(X_train[\"Age\"], X_train[\"Survived\"])\nplt.show()","cb865c40":"plt.scatter(X_train[\"Fare\"], X_train[\"Survived\"])\nplt.show()","c534747c":"plt.scatter(X_train[\"SibSp\"], X_train[\"Survived\"])\nplt.show()","fb64d495":"plt.scatter(X_train[\"Parch\"], X_train[\"Survived\"])\nplt.show()","72c207d9":"plt.scatter(X_train[\"Age\"], X_train[\"Fare\"], c = X_train[\"Survived\"])\nplt.show()","c3c4a6c2":"plt.scatter(X_train[\"Title\"], X_train[\"Age\"], c = X_train[\"Survived\"])\nplt.show()","7835c0bf":"plt.scatter(X_train[\"Cabin\"], X_train[\"Age\"], c = X_train[\"Survived\"])\nplt.show()","88ac0ceb":"X_train.Cabin = X_train.Cabin.replace(\"T\",\"U\")\nX_train.Cabin = X_train.Cabin.replace(\"U\",\"unknown\")\nX_train.Cabin = X_train.Cabin.replace(\"C\",\"known\")\nX_train.Cabin = X_train.Cabin.replace(\"E\",\"known\")\nX_train.Cabin = X_train.Cabin.replace(\"G\",\"known\")\nX_train.Cabin = X_train.Cabin.replace(\"D\",\"known\")\nX_train.Cabin = X_train.Cabin.replace(\"A\",\"known\")\nX_train.Cabin = X_train.Cabin.replace(\"B\",\"known\")\nX_train.Cabin = X_train.Cabin.replace(\"F\",\"known\")","26b883ca":"bins = [-1, 0.5, 1.5, np.inf]\nlabels = ['0', '1', '2+']\nX_train['SibSp'] = pd.cut(X_train[\"SibSp\"], bins, labels = labels)","0abced55":"bins = [-1, 0.5, 1.5, np.inf]\nlabels = ['0', '1', '2+']\nX_train['Parch'] = pd.cut(X_train[\"Parch\"], bins, labels = labels)","a797c953":"features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Cabin\", \"Embarked\", \"Title\", \"Survived\", \"Fare\", \"Age\"]\ncorrcheck = pd.get_dummies(X_train[features])\ncorr = corrcheck.corr()\ncorr[\"Survived\"].sort_values(ascending=False)","f43a285a":"num_features = [\"Fare\"]\nnum_pipeline = make_pipeline(StandardScaler())\n\ncat_features = [\"Pclass\", \"Cabin\", \"Title\", \"SibSp\", \"Parch\", \"Embarked\", \"Sex\"]\ncat_pipeline = make_pipeline(OneHotEncoder(handle_unknown=\"ignore\"))\n\npreprocessor = ColumnTransformer(transformers=[\n    (\"num\", num_pipeline, num_features),\n    (\"cat\", cat_pipeline, cat_features)\n])","d085508c":"Xpreprocessed = X_train\n\nX_train, X_test, y_train, y_test = train_test_split(Xpreprocessed,Xpreprocessed.Survived,test_size=100, random_state = 50)\nX_test = X_test.drop([\"Survived\"], axis = 1)\nX_train = X_train.drop([\"Survived\"], axis = 1)\n\nmodel = RandomForestClassifier()\nclassification_process = make_pipeline(preprocessor, model)\nclassification_process.fit(X_train, y_train)\n\naccuracy_score(y_test, classification_process.predict(X_test))","1854f9bc":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","14b4634b":"num_features = [\"Age\", \"Fare\"]\nnum_pipeline = make_pipeline(StandardScaler())\n\ncat_features = [\"Pclass\", \"Cabin\", \"Title\", \"SibSp\", \"Parch\", \"Embarked\"]\ncat_pipeline = make_pipeline(OneHotEncoder(handle_unknown=\"ignore\"))\n\npreprocessor = ColumnTransformer(transformers=[\n    (\"num\", num_pipeline, num_features),\n    (\"cat\", cat_pipeline, cat_features)\n])","fc2396e1":"def data_preparation(X):\n    \n    X = X.drop([\"Ticket\",\"PassengerId\"], axis=1)\n    \n    X.Embarked = X.Embarked.fillna('S')\n    X.Fare = X.Fare.fillna(X.Fare.median())\n    \n    X['Title'] = X.Name.apply(lambda name: name.split(',')[1].split('.')[0].strip())\n    normalized_titles = {\n        \"Capt\":       \"Officer\",\n        \"Col\":        \"Officer\",\n        \"Major\":      \"Officer\",\n        \"Jonkheer\":   \"Royalty\",\n        \"Don\":        \"Royalty\",\n        \"Sir\" :       \"Royalty\",\n        \"Dr\":         \"Officer\",\n        \"Rev\":        \"Officer\",\n        \"the Countess\":\"Royalty\",\n        \"Dona\":       \"Royalty\",\n        \"Mme\":        \"Mrs\",\n        \"Mlle\":       \"Miss\",\n        \"Ms\":         \"Mrs\",\n        \"Mr\" :        \"Mr\",\n        \"Mrs\" :       \"Mrs\",\n        \"Miss\" :      \"Miss\",\n        \"Master\" :    \"Master\",\n        \"Lady\" :      \"Royalty\"\n    }\n    X.Title = X.Title.map(normalized_titles)\n    X = X.drop([\"Name\"], axis=1)\n    \n    grouped = X.groupby(['Title'])  \n    X.Age = grouped.Age.apply(lambda x: x.fillna(x.median()))\n      \n    X.Cabin = X.Cabin.str.slice(0,1)\n    X.Cabin = X.Cabin.fillna(\"unknown\")\n    X.Cabin = X.Cabin.replace(\"T\",\"unknown\")\n    X.Cabin = X.Cabin.replace(\"C\",\"known\")\n    X.Cabin = X.Cabin.replace(\"E\",\"known\")\n    X.Cabin = X.Cabin.replace(\"G\",\"known\")\n    X.Cabin = X.Cabin.replace(\"D\",\"known\")\n    X.Cabin = X.Cabin.replace(\"A\",\"known\")\n    X.Cabin = X.Cabin.replace(\"B\",\"known\")\n    X.Cabin = X.Cabin.replace(\"F\",\"known\")\n    \n    bins = [-1, 0.5, 1.5, np.inf]\n    labels = ['0', '1', '2+']\n    X['SibSp'] = pd.cut(X[\"SibSp\"], bins, labels = labels)\n    \n    bins = [-1, 0.5, 1.5, np.inf]\n    labels = ['0', '1', '2+']\n    X['Parch'] = pd.cut(X[\"Parch\"], bins, labels = labels)\n    \n    \n    return X","10711af1":"X_test = data_preparation(test)\nX_train = data_preparation(train)\ny_train = X_train.Survived\nX_train = X_train.drop([\"Survived\"], axis = 1)\n\nmodel = RandomForestClassifier()\nclassification_process = make_pipeline(preprocessor, model)\nclassification_process.fit(X_train, y_train)","9962cfce":"classification_process.fit(X_train, y_train)\npredictions = classification_process.predict(X_test)\nresult = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\n#result.to_csv('second_result.csv', index=False)\nprint(result)","2e5f60bb":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","c7270bda":"num_features = [\"Fare\"]\nnum_pipeline = make_pipeline(StandardScaler())\n\ncat_features = [\"Pclass\", \"Cabin\", \"Title\", \"SibSp\", \"Parch\", \"Embarked\", \"Sex\"]\ncat_pipeline = make_pipeline(OneHotEncoder(handle_unknown=\"ignore\"))\n\npreprocessor = ColumnTransformer(transformers=[\n    (\"num\", num_pipeline, num_features),\n    (\"cat\", cat_pipeline, cat_features)\n])\n\nmodel = RandomForestClassifier()","acf47d9f":"#Train data\n\nXpreprocessed = data_preparation(train)\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Cabin\", \"Title\", \"Embarked\"]\n\ny_train = Xpreprocessed.Survived\nX_train = Xpreprocessed.drop([\"Survived\"], axis = 1)\n\n\n#X_train, X_test, y_train, y_test = train_test_split(Xpreprocessed,Xpreprocessed.Survived,test_size=100, random_state = 50)\n#X_test = X_test.drop([\"Survived\"], axis = 1)\n#X_train = X_train.drop([\"Survived\"], axis = 1)\nX_train = pd.get_dummies(X_train[features])\n#X_test = pd.get_dummies(X_test[features])","b91fb623":"param_grid = {\n    'bootstrap': [True],\n    'max_depth': [90, 100, 110, 120],\n    'max_features': [2, 3, 4, 5],\n    'min_samples_leaf': [2, 3, 4, 5],\n    'min_samples_split': [6, 7, 8, 10, 12],\n    'n_estimators': [100, 200, 300, 1000]\n}","a24f258f":"grid_search = GridSearchCV(estimator = model, param_grid = param_grid, \n                          cv = 4, n_jobs = -1, verbose = 2)\n\ngrid_search.fit(X_train, y_train)\n\ngrid_search.best_params_","e95d0725":"X_test = data_preparation(test)\nX_train = data_preparation(train)\ny_train = X_train.Survived\nX_train = X_train.drop([\"Survived\"], axis = 1)\n\n#model = RandomForestClassifier(bootstrap = True,\n#                              max_depth = 90,\n#                              max_features = 5,\n#                              min_samples_leaf = 2,\n#                              min_samples_split = 6,\n#                              n_estimators = 100)\n\n#classification_process = make_pipeline(preprocessor, model)\n#classification_process.fit(X_train, y_train)","c6ff9fb1":"param_grid = {\n    'bootstrap': [True],\n    'max_depth': [90, 100, 110],\n    'max_features': [4, 5, 6, 7],\n    'min_samples_leaf': [1, 2, 3, 4],\n    'min_samples_split': [5, 6, 7],\n    'n_estimators': [75, 100, 125]\n}","76a0ec23":"y_train = Xpreprocessed.Survived\nA = Xpreprocessed.Age\nF = Xpreprocessed.Fare\nX_train = Xpreprocessed.drop([\"Survived\"], axis = 1)\nX_train = pd.get_dummies(X_train[features])\nX_train[\"Age\"] = A\nX_train[\"Fare\"] = F","69a0d240":"model = RandomForestClassifier()\ngrid_search = GridSearchCV(model, param_grid, \n                          cv = 4, n_jobs = -1, verbose = 2)\n\ngrid_search.fit(X_train, y_train)\n\ngrid_search.best_params_","7f778323":"X_test = data_preparation(test)\nA = X_test.Age\nF = X_test.Fare\nX_test = pd.get_dummies(X_test[features])\nX_test[\"Age\"] = A\nX_test[\"Fare\"] = F\n\npredictions = grid_search.predict(X_test)\nresult = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\nresult.to_csv('aftergrid.csv', index=False)\nprint(result)","3dcf94cb":"Like this:","779b45bd":"## Prediction","0b573f76":"### Embarked","793f4bdb":"...","1fc60ffe":"# Optimization!\n### To do:\n* Check which data are correlated with survived\n* Eliminate *White noise data* Sex-Title?, Embarked?\n* Are SibSp & Parch numerical or categorical? If categorical combine it into categories [0, 1, 2+]?\n* Filling Age before or after split, is that cheating?\n* GridSearch the heck out of Random Forest","826907fa":"## More cleaning!","bc36e187":"## GridSearchCV Best Params","502f9d5e":"# Get it all together into function\n(also wth it doesn't get PassengerId?)","d2ee69ba":"# Data Preparation","6eb1e0c2":"# Pipeline","d20ab946":"# For whole data","c1062649":"## Second test\n### Corrected pipeline","d479ac14":"# Importing & Downloading","c224c358":"## Plan of action\n\n* PassengerId  - drop\n* Survived     - prediction axis\n* Pclass       - pipeline\n* Name         - get the title, drop the rest\n* Sex          - pipeline\n* Age          - approximate age basing on title\n* SibSp        - pipeline\n* Parch        - pipeline\n* Ticket       - drop\n* Fare         - ONE MISSING VALUE IN TEST FILE! pipeline\n* Cabin        - get the deck and room, fillna deck with 'N'\n* Embarked     - Change NaNs to 'S' **or** drop","69190024":"* SibSp got low 3% corr with survived, remove it?\n* Cabin change to Known\/Unknown\n* Embarked?\n* Title combine Officer & Royalty what about crew?\n* Age has low correlation, what about different relationship?","f9779271":"### It scored 0.76076","13d074a0":"### Drops","f5e81e14":"There must be simpler way to do it than this, probably using lambda:","d157d421":"# Test on train data","21338330":"## Result score is 0.76555","e2598a44":"### Title and Age","206db77b":"## Dis gut\n\n# Corrected everything","69efe2b5":"### Cabin"}}