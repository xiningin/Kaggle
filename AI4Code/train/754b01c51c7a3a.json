{"cell_type":{"fd03c3dc":"code","735993eb":"code","ba3274a5":"code","4c2655c7":"code","7d489a99":"code","6af77635":"code","7f5cbf66":"code","1197dbd8":"code","75c72cc2":"code","fd2d4d6c":"code","cb0edcd0":"code","eeb6564e":"code","58473f7c":"code","7ad96283":"code","c46c4e21":"code","6258a5dc":"code","49155610":"code","b7eb2cc1":"code","917619e3":"code","ef09fd6b":"code","332d9532":"code","df0bc80b":"code","895b7d62":"code","d1eed5b2":"code","bdec141c":"code","d6c86e9b":"code","50b4c9a4":"code","bbe63341":"code","abfe7b77":"code","2cd2eb04":"code","e8d2494a":"code","e1aa3d66":"code","74b6420f":"markdown","cc70900a":"markdown"},"source":{"fd03c3dc":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import make_scorer, mean_squared_error\nimport sklearn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import VotingRegressor\n\npd.set_option('display.max_columns', 5000)\npd.set_option('display.max_row', 500)\nnp.random.seed(51)","735993eb":"train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\n\ny_train = train['SalePrice']\nX_train = train.drop(['Id','SalePrice'], axis=1)\nX_test = test.drop(['Id'], axis=1)\nprint(X_train.shape, y_train.shape)","ba3274a5":"X_train.head()","4c2655c7":"X_train_corr = X_train.corrwith(y_train)\nX_train_corr.sort_values(ascending=False).head(10)","7d489a99":"plt.scatter(X_train['GrLivArea'], y_train)","6af77635":"outliers = X_train.loc[(X_train['GrLivArea']>4000.0) & (y_train<300000.0)].index\nprint(outliers)\n\nX_train = X_train.drop(outliers)\ny_train = y_train.drop(outliers)","7f5cbf66":"train_samples = X_train.shape[0]\nX = pd.concat((X_train, X_test), sort=False).reset_index(drop=True)","1197dbd8":"X['MSSubClass'] = X['MSSubClass'].astype('object')","75c72cc2":"X.isna().sum().sort_values(ascending=False).head(40)","fd2d4d6c":"fake_nans_cols = ['Alley', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'FireplaceQu', \n         'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature']\nX[fake_nans_cols] = X[fake_nans_cols].fillna('None')","cb0edcd0":"X['Utilities'].value_counts()","eeb6564e":"X = X.drop(['Utilities'], axis=1)","58473f7c":"numerical = (X.dtypes != 'object')\ncategorical = (X.dtypes == 'object')","7ad96283":"X.isna().sum().sort_values(ascending=False).head(10)","c46c4e21":"imputer = SimpleImputer(missing_values=np.nan)\nX.loc[:, numerical] = imputer.fit_transform(X.loc[:, numerical])","6258a5dc":"imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\nX.loc[:, categorical] = imputer.fit_transform(X.loc[:, categorical])\n","49155610":"X.isna().sum().sort_values(ascending=False).head(10)","b7eb2cc1":"ord_encoder=OrdinalEncoder()\nX.loc[:, categorical] = ord_encoder.fit_transform(X.loc[:, categorical])","917619e3":"sns.distplot(X['LotArea'])","ef09fd6b":"X.loc[:, numerical].skew().sort_values(ascending=False).head(25)","332d9532":"skewed = X.loc[:, numerical].skew() > 10\nX.loc[:, numerical & skewed] = np.log1p(X.loc[:, numerical & skewed])","df0bc80b":"sns.distplot(X['LotArea'])","895b7d62":"X['TotalSF'] = X['TotalBsmtSF'] + X['1stFlrSF'] + X['2ndFlrSF']","d1eed5b2":"numerical = (X.dtypes != 'object')\ncategorical = (X.dtypes == 'object')","bdec141c":"X_train = X[:train_samples]\nX_test  = X[train_samples:]\nX_train.shape","d6c86e9b":"cols = X_train.columns\n\nscaler= RobustScaler()\nX_train = np.hstack([X_train.loc[:, categorical], scaler.fit_transform(X_train.loc[:, numerical])])\nX_test = np.hstack([X_test.loc[:, categorical], scaler.transform(X_test.loc[:, numerical])])\n\nX_train = pd.DataFrame(X_train, columns=cols)\nX_test = pd.DataFrame(X_test, columns=cols)\nX_train","50b4c9a4":"y_train = np.log1p(y_train)","bbe63341":"lr = LinearRegression(fit_intercept=False)\nMSEs=cross_val_score(lr, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\nmeanMSE=np.mean(MSEs)\nprint('RMSE = '+str(np.sqrt(-meanMSE)))","abfe7b77":"lr = LinearRegression(fit_intercept=False)\nlr.fit(X_train, y_train)\ny_pred = lr.predict(X_test)\npd.DataFrame({'Id': test.Id, 'SalePrice': np.exp(y_pred)}).to_csv('lr_full_2019-11-20.csv', index =False)","2cd2eb04":"xgb= XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=0.5, gamma=0,\n             importance_type='gain', learning_rate=0.01, max_delta_step=0,\n             max_depth=3, min_child_weight=0, missing=None, n_estimators=4000,\n             n_jobs=1, nthread=None, objective='reg:squarederror', random_state=0,\n             reg_alpha=0.0001, reg_lambda=0.01, scale_pos_weight=1, seed=None,\n             silent=None, subsample=1, verbosity=1)\nMSEs=cross_val_score(xgb, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\nmeanMSE=np.mean(MSEs)\nprint('RMSE = '+str(np.sqrt(-meanMSE)))","e8d2494a":"vote_reg = VotingRegressor([('Linear', lr), ('XGBRegressor', xgb)])\nMSEs=cross_val_score(vote_reg, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\nmeanMSE=np.mean(MSEs)\nprint('RMSE = '+str(np.sqrt(-meanMSE)))","e1aa3d66":"vote_reg = VotingRegressor([('Linear', lr), ('XGBRegressor', xgb)])\nvote_reg.fit(X_train, y_train)\ny_pred = vote_reg.predict(X_test)\npd.DataFrame({'Id': test.Id, 'SalePrice': np.exp(y_pred)}).to_csv('vote_reg_2019-11-21.csv', index =False)","74b6420f":"Some columns have nans which mean instead that the there is none of the values. Imputing with mode doesn't make sense.","cc70900a":"From EDA we know that MSsubclass is categorical even if the values are integers"}}