{"cell_type":{"ff7555ef":"code","07ecbe8d":"code","05e201f2":"code","08a7e296":"code","79c353d6":"code","b4f7b807":"code","06aca9d1":"code","4178f42a":"code","d0dcfe18":"code","80cda5df":"code","02f8ad3b":"code","a67acf6d":"code","f07ed3c3":"code","54e26313":"code","9beed996":"code","07d23161":"code","b3650270":"code","e9cd82b6":"code","a946c4e4":"code","db5bbc58":"code","89c951b1":"code","96c2763f":"code","3d6e4a1c":"markdown","292e9c47":"markdown","cdb9a0a1":"markdown","170fd608":"markdown","9d8ed87b":"markdown","4e164873":"markdown","570ee054":"markdown","e7b78519":"markdown","3baa9e91":"markdown","77867f7f":"markdown","520fcb2b":"markdown"},"source":{"ff7555ef":"import pandas as pd\n# Load the data set\ndf = pd.read_csv('..\/input\/data.csv')","07ecbe8d":"df.head()","05e201f2":"# drop ID - we don't need that\ndf.drop('id',axis=1,inplace=True)\n# there's an additional column 'unnamed' with no data. delete as well\ndf.drop('Unnamed: 32',axis=1,inplace=True)","08a7e296":"df.describe().T","79c353d6":"# check for missing data\nall_data_na = (df.isnull().sum() \/ len(df)) * 100\nall_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\nmissing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\nmissing_data.head(20)","b4f7b807":"from scipy.stats import skew \n\n# find skewed features\nnumeric_feats = df.dtypes[df.dtypes != \"object\"].index\n\n# Check the skew of all numerical features\nskewed_feats = df[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nskewness = pd.DataFrame({'Skew' :skewed_feats})\nskewness.head(10)","06aca9d1":"# \"unskew\" the features\nskewness = skewness[abs(skewness) > 0.75]\n\nfrom scipy.special import boxcox1p\nskewed_features = skewness.index\nlam = 0.15\nfor feat in skewed_features:\n    df[feat] = boxcox1p(df[feat], lam)","4178f42a":"# Replace the target values (M = malignant, B = benign) with 1 for malignant and 0 for begnin tumors\ndf['diagnosis']= df['diagnosis'].map({'M':1,'B':0})","d0dcfe18":"# split into target (y) and features (X)\ny = df['diagnosis']\nX = df.drop('diagnosis',axis=1)","80cda5df":"# Scale the feature values\nfrom sklearn.preprocessing import StandardScaler\nX = StandardScaler().fit_transform(X)","02f8ad3b":"# and split into train and test data sets\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)","a67acf6d":"import numpy as np\n\n# scoring function for the model\n# we score with the mean AUC from 5 folds of the training data\nfrom sklearn.model_selection import KFold, cross_val_score\ndef score_model(model):\n    kf = KFold(5, shuffle=True, random_state=42).get_n_splits(X_train)\n    model_score = np.mean(cross_val_score(model, X_train, y_train, scoring=\"recall\", cv = kf))\n    return((type(model).__name__,model_score))","f07ed3c3":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom xgboost import XGBClassifier\n\nmodel_scores = pd.DataFrame(columns=['model','Recall score'])\nclfs = [KNeighborsClassifier(),  MLPClassifier(), SVC(), GaussianProcessClassifier(), DecisionTreeClassifier()\n        , RandomForestClassifier(), AdaBoostClassifier(), GaussianNB(), QuadraticDiscriminantAnalysis(), XGBClassifier()]\nfor clf in clfs:\n    sc = score_model(clf)\n    model_scores = model_scores.append({'model':sc[0],'Recall score':sc[1]},ignore_index=True)    ","54e26313":"model_scores.sort_values('Recall score',ascending=False)","9beed996":"# SVC\nfrom sklearn.model_selection import GridSearchCV\n\nparameter_space = {\n    'C': np.logspace(-2, 10, 20,base=2),\n    'gamma': np.logspace(-9, 3, 13),\n}\ngrid_search = GridSearchCV(SVC(kernel='rbf'), parameter_space, n_jobs=-1, cv=5,scoring=\"recall\")\ngrid_search.fit(X_train, y_train)\ngrid_search.best_params_","07d23161":"# MLP\nparameter_space = {\n    'hidden_layer_sizes': [(20,20), (100,), (50,), (30,)],\n    'activation': ['tanh', 'relu'],\n    'solver': ['sgd', 'adam'],\n    'alpha': [0.0001, 0.05],\n    'learning_rate': ['constant','adaptive'],\n}\ngrid_search = GridSearchCV(MLPClassifier(), parameter_space, n_jobs=-1, cv=5,scoring=\"recall\")\ngrid_search.fit(X_train, y_train)\ngrid_search.best_params_","b3650270":"model_scores = pd.DataFrame(columns=['model','Recall score'])\nclfs = [SVC(kernel=\"rbf\", gamma=0.001, C=47),MLPClassifier(max_iter=300,activation='relu',\n                                                         hidden_layer_sizes=(30,),alpha=0.0001, learning_rate=\"adaptive\",\n                                                        solver=\"adam\")]\nfor clf in clfs:\n    sc = score_model(clf)\n    model_scores = model_scores.append({'model':sc[0],'Recall score':sc[1]},ignore_index=True) ","e9cd82b6":"model_scores","a946c4e4":"# train and then validate with the test data set\nfrom sklearn.metrics import recall_score\n\nclf = SVC(kernel=\"rbf\", gamma=0.001, C=47)\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint(\"Test Recall: {}\".format(recall_score(y_test, y_pred)))\n","db5bbc58":"# calculate the confusion matrix\nfrom sklearn.metrics import confusion_matrix\ncnf_matrix = confusion_matrix(y_test,y_pred)","89c951b1":"# Confusion matrix with Seaborn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nclass_names = [0,1]\nfig,ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks,class_names)\nplt.yticks(tick_marks,class_names)\n\n#create a heat map\nsns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'YlGnBu',\n           fmt = 'g')\nax.xaxis.set_label_position('top')\nplt.tight_layout()\nplt.title('Confusion matrix for SVC classifier', y = 1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()","96c2763f":"from sklearn.metrics import precision_score\nfrom sklearn.metrics import accuracy_score\nprint(\"Precision: {}\".format(precision_score(y_test,y_pred)))\nprint(\"Accuracy: {}\".format(accuracy_score(y_test,y_pred)))","3d6e4a1c":"SVC, MLP are the top performers. We'll tune the hyperparameters for these two next to squeeze out the maximum score.","292e9c47":"## Hyperparameter tuning\nI'm doing the hyperparameter tuning with GridSearch for each of the three top performing standard models seperately.","cdb9a0a1":"We were able to increase the recall scores a bit.","170fd608":"no missing values in this data set. Nice :)","9d8ed87b":"# Training classifiers on the Breast Cancer dataset\n\n## Feature engineering","4e164873":"## Train models\n\nFirst define some functions for code that we'll use a few times for training models","570ee054":"Now let's loop through some classifier models with standard hyper parameters and check the scores for each of them","e7b78519":"## Train the final model, validate and results","3baa9e91":"Now let's take a final look at the scores for the tuned models.","77867f7f":"1. The final classifier is has one false negatives and no false positives out of a total of 143 validation samples","520fcb2b":"Accuracy is 99.3%"}}