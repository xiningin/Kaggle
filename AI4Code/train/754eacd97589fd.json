{"cell_type":{"0091ec3e":"code","169eb8c2":"code","aadac3b8":"code","7f8e9125":"code","23e9338e":"code","b8341649":"code","99acfe50":"code","c0272ad6":"code","d4fff317":"code","0a14b21e":"code","32f78350":"code","1a0ca27d":"code","a9b4da00":"code","a55d57c1":"code","3e3c00a6":"code","6853dd9d":"code","7e523050":"code","00f9e590":"code","8b3c3ebb":"markdown","565e0ac8":"markdown","b2a71557":"markdown","19c6d342":"markdown","b795dfd8":"markdown","acfd3599":"markdown","a2b1d8e7":"markdown","db4ecbb4":"markdown","be59b796":"markdown","dd57c354":"markdown","897dca88":"markdown","66a79e72":"markdown","983e75ff":"markdown","ed6f9101":"markdown","c2447959":"markdown","9c3db188":"markdown","c945d39a":"markdown","e9be2406":"markdown"},"source":{"0091ec3e":"import numpy as np\nimport pandas as pd # only used to read the MNIST data set\nfrom scipy.signal import convolve2d\nimport matplotlib.pyplot as plt","169eb8c2":"IMG_ROWS, IMG_COLS = 28,28    # number of rows and columns in mnist images\n\nIMG_PAIR_LABELS = ['similar', 'rot90', 'zoom', 'blur', 'different']    # image pair comparison labels\nN_IMG_PAIR_LABELS = len(IMG_PAIR_LABELS)                               # number of comparison types\nIMG_PAIR_LABEL_ONE_HOT = np.eye(N_IMG_PAIR_LABELS, dtype=np.float)     # array of one-hot label encodings","aadac3b8":"N_TEACH_IMG_PAIRS = 50    # number of image pairs per comparison type to teach with. Total teaching comparision = 5*50 = 250\nN_TEST_IMG_PAIRS = 200    # number of image pairs per comparison type to test with. Total testing comparisons = 5*200 = 1000","7f8e9125":"np.random.random(42)\nALL_DIGITS = np.arange(10)\nTEACH_DIGITS = np.random.choice(ALL_DIGITS, size=5, replace=False)\nTEST_DIGITS = np.setdiff1d(ALL_DIGITS, TEACH_DIGITS)\n\nprint('teach digits:', TEACH_DIGITS)\nprint('test  digits:', TEST_DIGITS)\n","23e9338e":"def create_weights(shape, low=-1.0, high=1.0, sparsity=None, spectral_radius=None):\n    w = (high - low)*np.random.ranf(shape[0]*shape[1]).reshape(shape) + low      # create the weight matrix\n    if not sparsity is None:                                                     # if sparsity is defined\n        s = np.random.ranf(shape[0]*shape[1]).reshape(shape) < (1.0 - sparsity)  #     create a sparse boolean matrix\n        w *= s                                                                   #     set weight matrix values to 0.0\n    if not spectral_radius is None:                                              # if spectral radius is defined\n        sp = np.max(np.abs(np.linalg.eig(w)[0]))                                 #     compute current spectral radius\n        w *= (spectral_radius)\/sp                                                #     adjust weight matrix to acheive specified spectral radius\n    return w\n","b8341649":"def operate_reservoir(w_u, w_x, img_1, img_2):\n    n_cols = img_1.shape[1]    # number of image columns = number teaching steps\n    x_size = w_x.shape[0]      # reservoir size\n    u_size = w_u.shape[1]      # input vector size\n\n    x = np.zeros((x_size,1))    # start with zero reservoir value for each image pair\n    for col in range(n_cols):   # step through image columns\n        img_col_1 = img_1[:,col].reshape((u_size-1,1))\n        img_col_2 = img_2[:,col].reshape((u_size-1,1))\n        #\n        # this technique is somewhat different than what is described in either paper\n        #\n        u_1 = np.dot(w_u, np.vstack((1, img_col_1)))    # stack up bias (=1) for img_1 column and transform by input weights (1\/2 reservoir size)\n        u_2 = np.dot(w_u, np.vstack((1, img_col_2)))    # stack up bias (=1) for img_2 column and transform by input weights (1\/2 reservoir size)\n        u_total = np.concatenate((u_1, u_2))            # join the transformed inputs to get to 100% reservoir size\n        x = np.tanh(u_total + np.dot(w_x, x))           # update the reservoir\n        #\n        # collect reservoir to reservoir state\n        #\n        if col == 0:                              # if this is first column\n            x_state = (x)                         #     initialize state\n        else:                                     # subsequently\n            x_state = np.hstack((x_state, (x)))   #     append latest reservoir to state\n\n    return x_state\n","99acfe50":"def display_reservoir_damping(w, n_steps):\n    x_size = w.shape[0]\n    x = (2.0*np.random.ranf(x_size) - 1.0).reshape(x_size,1)    # initialize reservoir to random values\n    for i in range(n_steps):                                    # for a given number of steps\n        x = np.tanh((np.dot(w,x)))                              #     operate the reservoie\n        if i == 0:                                              #     and collect the interim states\n            M = x\n        else:\n            M = np.hstack((M,x))\n\n    n_plots = min(M.shape[0], 20)                               # format the plot area\n    rows = int(np.floor(np.sqrt(n_plots)))\n    cols = int(np.ceil(n_plots\/rows))\n    x_size = M.shape[0]\n    if n_plots > 20:                                            # if reservoir size is greater than 20\n        cells = np.random.choice(np.arange(x_size), 20)         #    select 20 random neurons for display\n    else:\n        cells = np.arange(x_size)\n\n    n_steps = M.shape[1]\n    x_axis = np.arange(n_steps, dtype=np.int)\n    fig, _axs = plt.subplots(nrows=rows, ncols=cols)\n    for p in range(n_plots):\n        idx = cells[p] \n        row = p\/\/cols\n        col = p % cols\n        _axs[row][col].plot(x_axis, M[idx, :])\n    fig.tight_layout()\n    plt.show()\n","c0272ad6":"def choose_img_pair(digits, img_pair_label):\n    digit_1 = np.random.choice(digits)                     #     pick a random base digit\n    digit_idx_1 = np.random.choice(len(images[digit_1]))   #     pick a random instance of the base digit\n    img_1 = images[digit_1][digit_idx_1, :, :]             #     get the base digit image\n    if img_pair_label == 'different':\n        # choose a digit different from digit_1\n        digit_2 = np.random.choice([digit for digit in ALL_DIGITS if digit != digit_1])\n        digit_idx_2 = np.random.choice(len(images[digit_2]))             # pick a random instance of the comparison digit\n        img_2 = images[digit_2][digit_idx_2, :, :]                       # get the comparison image\n    else:\n        digit_idx_2 = np.random.choice(len(images[digit_1]))    # pick a random instance of the base digit\n        img_2 = images[digit_1][digit_idx_2, :, :]              # get the comparison digit\n        if img_pair_label == 'similar':\n            screen_1 = np.random.rand(IMG_ROWS, IMG_COLS)           # create a random screen to choose which pixels to change\n            screen_2 = np.random.rand(IMG_ROWS, IMG_COLS)           # create a random screen of values to change the selected pixels to\n            img_2[screen_1 > 0.80] = screen_2[screen_1 > 0.80]*0.3  # add random noise at random locations\n        elif img_pair_label == 'rot90':\n            img_2 = np.fliplr(img_2.T)                              # rotate the image 90 degrees\n        elif img_pair_label == 'zoom':\n            img_2 = img_2.repeat(2,axis=0).repeat(2,axis=1)[IMG_ROWS\/\/2:IMG_ROWS\/\/2 + IMG_ROWS, IMG_COLS\/\/2:IMG_COLS\/\/2 + IMG_COLS]\n        elif img_pair_label == 'blur':                              # blur the image using the convolution kernel\n            img_2 = convolve2d(img_2, KERNEL, boundary='wrap', mode='same')\n        else:\n            raise ValueError('illegal image pair label')\n    return img_1, img_2","d4fff317":"df = pd.read_csv('..\/input\/train.csv', sep=',')\nlbl = df['label'].values\nimg = df.loc[:, df.columns != 'label'].values\nimages = {}\nfor digit in range(10):\n    images[digit] = np.array([((image - np.min(image))\/np.ptp(image)).reshape((28,28)) for image in img[lbl == digit]], dtype=np.float)","0a14b21e":"#\n# these are examples of the image transformations - this code box may be safely skipped\n#\nimg_base = images[3][0]\nimg_noisy = images[3][1]                                     # create the 'similar' (noisy) version\nscreen_1 = np.random.rand(IMG_ROWS, IMG_COLS)                #     create a random screen to choose which pixels to change\nscreen_2 = np.random.rand(IMG_ROWS, IMG_COLS)                #     create a random screen of values to change the selected pixels to\nimg_noisy[screen_1 > 0.80] = screen_2[screen_1 > 0.80]*0.3   #     add the random noise in at random locations\nimg_rot90 = images[3][2]                                     # create the 'rot90' version\nimg_rot90 = np.fliplr(img_rot90.T)                           #     rotate the image 90 degrees\nimg_zoom = images[3][3]                                      # create the zoomed version \nimg_zoom = img_zoom.repeat(2,axis=0).repeat(2,axis=1)[IMG_ROWS\/\/2:IMG_ROWS\/\/2 + IMG_ROWS, IMG_COLS\/\/2:IMG_COLS\/\/2 + IMG_COLS]\nimg_blur = images[3][4]                                      # create the blurred version\nimg_blur = convolve2d(img_blur, np.ones((6, 6), dtype=\"float\") * (1.0 \/ 36.0), boundary='wrap', mode='same')\nimg_different = images[5][0]\n\nfig, (ax1, ax2, ax3, ax4, ax5, ax6) = plt.subplots(1,6)\nax1.imshow(img_base, cmap='gray')\nax1.set_title('Base')\n\nax2.imshow(img_noisy, cmap='gray')\nax2.set_title('Similar')\n\nax3.imshow(img_rot90, cmap='gray')\nax3.set_title('Rotated')\n\nax4.imshow(img_zoom, cmap='gray')\nax4.set_title('Zoomed')\n\nax5.imshow(img_blur, cmap='gray')\nax5.set_title('Blurred')\n\nax6.imshow(img_different, cmap='gray')\nax6.set_title('Different')\n\nplt.tight_layout()\nplt.show()","32f78350":"U_SIZE = IMG_ROWS + 1       # image is input column-wise, input vector is size of row (+1 for bias)\nX_SIZE = 1000               # reservoir size\nO_SIZE = N_IMG_PAIR_LABELS  # image pair one-hot label size","1a0ca27d":"SPARSITY = 0.9          # sparsity of reservoir node connections\nSPECTRAL_RADIUS = 0.5   # determines reservoir echo state property","a9b4da00":"w_x = create_weights(shape=(X_SIZE, X_SIZE), low=-1.0, high=1.0, sparsity=SPARSITY, spectral_radius=SPECTRAL_RADIUS)    # 1000 by 1000\nw_u = create_weights(shape=(X_SIZE\/\/2, U_SIZE), low=-1.0, high=1.0)                                                     # 500 x 29\ndisplay_reservoir_damping(w_x, 25)","a55d57c1":"KERNEL_SIZE = 6\nKERNEL = np.ones((KERNEL_SIZE, KERNEL_SIZE), dtype=\"float\") * (1.0 \/ (KERNEL_SIZE * KERNEL_SIZE))","3e3c00a6":"for img_pair_label in IMG_PAIR_LABELS:                         # for each comparison type\n    img_pair_label_idx = IMG_PAIR_LABELS.index(img_pair_label)\n    for img_pair_teach in range(N_TEACH_IMG_PAIRS):            # for the number of teaching examples\n        img_1, img_2 = choose_img_pair(TEACH_DIGITS, img_pair_label)\n        x_state = operate_reservoir(w_u=w_u, w_x=w_x, img_1=img_1, img_2=img_2)  # x_state 1000 x 28, y_state 5 x 28\n        #\n        # create label state for image pair\n        #\n        y_state = np.repeat(IMG_PAIR_LABEL_ONE_HOT[img_pair_label_idx], repeats=IMG_COLS).reshape(N_IMG_PAIR_LABELS, IMG_COLS)\n        #\n        # append the current (x_size by n_cols) reservoir state and (n_labels by n_cols) label state to total teaching matricies\n        #\n        if img_pair_label_idx == 0 and img_pair_teach == 0:  # if this is first time through the loop\n            X = x_state                                      #     init the reservoir state\n            Y = y_state                                      #     and output state\n        else:                                                # subsequently\n            X = np.hstack((X, x_state))                      #     accumulate reservoir state by stacking\n            Y = np.hstack((Y, y_state))                      #     accumulate corresponding labels by stacking\n","6853dd9d":"err = 1e-8\nw_out = np.dot(np.dot(Y, X.T), np.linalg.inv(np.dot(X, X.T) + err*np.eye(X_SIZE)))","7e523050":"y_true = []\ny_pred = []\nfor img_pair_label in IMG_PAIR_LABELS:                              # for each comparison type\n    img_pair_label_idx = IMG_PAIR_LABELS.index(img_pair_label)\n    for img_pair_test in range(N_TEST_IMG_PAIRS):                   # for each testing example\n        img_1, img_2 = choose_img_pair(TEST_DIGITS, img_pair_label)\n        x_state = operate_reservoir(w_u=w_u, w_x=w_x, img_1=img_1, img_2=img_2)  # x_state 1000 x 28, y_state 5 x 28\n        #\n        # predict label\n        #\n        y_state = np.tanh(np.dot(w_out, x_state))   # compute the label values for all image columns\n        y_mean = y_state.mean(axis=1)               # compute the mean of each value in the label\n        y_norm = y_mean\/sum(y_mean)                 # normalize by dividing by the sum of the means\n        pair_label_pred = np.argmax(y_norm)         # the predicted label is the index of maxium value\n\n        y_true.append(img_pair_label_idx)\n        y_pred.append(pair_label_pred)\n","00f9e590":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nprint()\nprecision = precision_score(y_true, y_pred, average=None)\nrecall = recall_score(y_true, y_pred, average=None)\nf_score = f1_score(y_true, y_pred, average=None)\nprint('label      precision\\trecall\\tf1_score')\nprint('----------------------------------------')\nfor img_pair_label in IMG_PAIR_LABELS:    # for image pair label\n    img_pair_label_idx = IMG_PAIR_LABELS.index(img_pair_label)\n    print('{:11s}{:4.4f}\\t{:4.4f}\\t{:4.4f}'.format(img_pair_label, precision[img_pair_label_idx], recall[img_pair_label_idx], f_score[img_pair_label_idx]))\nprint()\nf_score_aggregate = f1_score(y_true, y_pred, average='micro')\nprint('f1_score aggregate: {:4.4f}'.format(f_score_aggregate))\n","8b3c3ebb":"The reservoir connection matrix is normally sparse - 90% in this case. A spectral radius < 1.0 guarantees reservoir stability. ","565e0ac8":"We choose 5 random digits to teach the network and use the other 5 digits to test with.","b2a71557":"### Create and Initialize Weight Matrices\nCreate the reservoir weight matrix with specified sparsity and spectral radius. Create the input weight matrix with full connectivity and no spectral radius constraints. The input weight matrix is not recurrent and so does not have a stability requirement. The same input weight matrix is used to transform the columns of both images being compared. The output of the input  weight matrix is only half the size of the reservoir, however the outputs of both image column transformations are concatenated to form a single input vector the same size as the reservoir which allows it to be added to the reservoir state during reservoir operation.\n\nOptionally display the reservoir transient behavior.","19c6d342":"### operate_reservoir\nGiven two images and the input and reservoir weights, we operate the reservoir with the following steps:\n* initialize the reservoir to all zeros\n* for each column in the images\n    * form the input vector\n        * augment each column by 1 to include the bias value\n        * transform (dot product) the augmented columns from each image using the same input weights\n        * concatenate the transformed columns to form the input vector\n    * update the reservoir using the reservoir weights\n    * add the input vector to the transformed reservoir\n    * form the reservoir state variable by collecting interim reservoir values","b795dfd8":"### Display Image Transformation Examples (optional)\nThe following code block may be executed to display examples of the image transformations used in the experiment.","acfd3599":"### Choose an Image Pair for Teaching\/Testing\nIn the course of teaching and testing, two images are repeatedly chosen at random. This method chooses two images at random for comparison using the image pair label as a guide for what transformation (if any) to apply.","a2b1d8e7":"### Imports","db4ecbb4":"### create_weights\nInput and reservoir weight matrices are populated with random values and never changed. The weight matices may be (usually are) sparse. It is important that **reservoir** weights demonstrate the \"echo state property\", which means that the reservoir is stable under all input conditions, that the reservoir transient response dies out. Stability is guaranteed when the reservoir weight matrix **spectral radius** is less than 1.0. The matrix spectral radius is defined as the maximum matrix eigenvalue.\n\nThis method creates weight matrices of arbitrary shape with optional sparsity and spectral radius. (NOTE - reservoir weight matrices are, by definition, square matrices.)","be59b796":"Create the \"blur\" convolution kernal.","dd57c354":"### Compute Readout Weight Matrix\nUse Ridge Regression to compute the readout weight matrix matching collected reservoir state to collected label state. Ridge regression is used to add some regularization to situations where data points tend to be co-linear. \n\n\\begin{equation}\nW_{out} = YX^T(XX^T + \\gamma I)^{-1}\n\\end{equation}","897dca88":"### Results\nCompute and display the **precision**, **recall**, and **f1_score** for each classification as well as the **aggregate f1_score**. Note that in this case, the recall scores are the same as the accuracy scores for each class.","66a79e72":"### Initialize Some Experiment Paramters\nRC networks are inherently recurrent and applicable to time- or sequence-series data. In this experiment we \"serialize\" the images by feeding them to the reservoir one column at a time. The input vector size is therefore the number of rows in the image, plus one for a bias.\n\nWe set the reservoir size (number of reservoir neurons) to be 1000.\n\nThe output vector size is the size of the one-hot representation of the image comparison class label.","983e75ff":"### Program Constants\n\nThere are five different comparison types. Four of them are transformations of different instances of the same digit. The fifth is a comparison of one digit with an instance of a different digit.\n","ed6f9101":"### Teach\nTeaching the reservoir is done with the following steps\n* iterate through each of the 5 comparison types, 'similar', 'rot90', 'zoom', 'blur', and 'different'\n    * for the specified number of examples\n        * select a base and comparison image instance (use a different digit for the 'different' comparison type, a different instance of the same digit for all others)\n        * transform the comparison image using the current comparison type (except for the 'different' comparison type)\n        * operate the reservoir for the image pair\n        * accumulate the resulting reservoir state\n        * accumulate the corresponding comparison type (label) state\n","c2447959":"# A Reservoir Computing Approach to Generalized Learning\nImplementing the experiment from \"*Similarity Learning and Generalization with Limited Data: A Reservoir Computing Approach*\", Krishnagopal, Aloimonos, and Girvan (https:\/\/www.researchgate.net\/publication\/328691984_Similarity_Learning_and_Generalization_with_Limited_Data_A_Reservoir_Computing_Approach)\n\nIn the reservoir computing model, a \"reservoir\" of neurons is recurrently connected by a (sparse) set of randomly generated weights. The reservoir weights are fixed at the time of their creation. From the paper abstract, \"... the reservoir acts as a nonlinear filter projecting the input into a higher dimensional space in which the relationships are separable.\" Because reservoir computing networks do not use back-propogation learning, the neuron activation function need not be differentiable. In the Liquid State Machine implementation, 3rd generation spiking neurons are commonly used. However, in the Echo State Network reservoir implementation used in this experiment, the neurons are continuous output perceptrons.\n\nThe nonlinear projected space is linearly separable, evoking superficial similarities to Support Vector Machines, and the \"readout\" weight matrix is directly computed using Ridge Regression.\n\nIn this experiment an Echo State Network attempts to classify the relationship between two images. The MNIST digit data set is used and various transformations are applied to produce versions of the digits. A digit image along with one of the transformed versions is applied to the network and the network is taught to recognize the relationship between the two images. \n\nThe experiment is remarkable on two counts. First, the network learns the transformation types using only half the randomly chosen digits, for instance using only digits 1,3,4,6, and 9, but performs as well when tested using the other half of the digits, 0,2,5,7, and 8 which the network never saw during training. This demonstrates that the network is learning the relationships between the images and is not merely memorizing pairs of images. By way of contrast, a deep Siamese network similarly trained performs as well when tested with digits it is trained with, but poorly when tested with the other digits. Second, the network requires relatively little training data, just 250 examples in this experiment.\n\nThe network is implemented in pure python using just Numpy and takes less than 30 seconds to run.","9c3db188":"### display_reservoir_damping\nThis method displays the transient behavior of the reservoir by initializing the reservoir to random values and operating the reservoir over a number of time steps. Display the values of 20 randomly chosen reservoir neurons.","c945d39a":"### Data Preparation\nNow that we're done with the preliminaries, code execution begins here with data perparation. For this network, we don't need separate teaching and testing data sets. We read in the MNIST train data and create two numpy arrays, one for labels and one for images, then create a dictionary where the keys are the digits 0-9 and the values are arrays of 28x28 pixel images. The image data is scaled to values in the range [0.0 .. 1.0]","e9be2406":"### Test\nTest the network using digits not used in the teaching phase. This demonstrates that the network is learning the relationship between the images and not just memorizing image pairs.\n\nOperate the reservoir as before in the teaching phase using the number of examples specified for testing. Instead of collecting label state, compute the label state using the readout weight matrix. The label is computed as each image column is applied to the reservoir. The collected labels for each image pair are then normalized by taking the mean of each label value and dividing by the sum of the means. The label is then selected as the index of maxium label value.\n\nCollect the results into two arrays representing the true and predicted labels."}}