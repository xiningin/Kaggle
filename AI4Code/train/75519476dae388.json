{"cell_type":{"f329fa49":"code","c0c0cd50":"code","c8215984":"code","27cb5443":"code","2429f494":"code","fa469450":"code","69a78c72":"code","68142b22":"code","49d29a57":"code","f822385b":"code","927ec5be":"code","639968b3":"markdown","b6a65b45":"markdown","624906b0":"markdown","7373ac2d":"markdown","1e2936f7":"markdown","954f498b":"markdown","f260ed75":"markdown","a4553e3a":"markdown","9219c15e":"markdown","03f3c6a3":"markdown","b133b8c8":"markdown","e848e0da":"markdown"},"source":{"f329fa49":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\nimport cv2\nfrom tqdm import tqdm, tqdm_notebook\nimport matplotlib.pyplot as plt\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, Model\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, TensorBoard\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nseed = 4529\nnp.random.seed(seed)","c0c0cd50":"base_dir = os.path.join(\"..\", \"input\") # set base directory\ntrain_df = pd.read_csv(os.path.join(base_dir, \"train.csv\"))\ntrain_dir = os.path.join(base_dir, \"train\/train\")\ntest_dir = os.path.join(base_dir, \"test\/test\")\n\n# print(os.listdir(train_dir))\nprint(train_df.head())","c8215984":"%load_ext tensorboard.notebook\n%tensorboard --logdir logs","27cb5443":"# train_images = []\n# train_labels = []\n# images = train_df['id'].values\n\n# for image_id in tqdm_notebook(images):\n#     image = np.array(cv2.imread(train_dir + \"\/\" + image_id))\n#     train_images.append(image)\n    \n#     label = train_df[train_df['id'] == image_id]['has_cactus'].values[0]\n#     train_labels.append(label)\n    \n# train_images = np.asarray(train_images)\n# train_images = train_images \/ 255.0\n# train_labels = np.asarray(train_labels)\n\n# print(\"Number of Training images: \" + str(len(train_images)))","2429f494":"train_df['has_cactus'] = train_df['has_cactus'].astype(str)\n\nbatch_size = 64\ntrain_size = 15750\nvalidation_size = 1750\n\ndatagen = ImageDataGenerator(\n    rescale=1.\/255,\n    horizontal_flip=True,\n    vertical_flip=False,\n    brightness_range=(1, 1.3),\n    shear_range=0.05,\n    validation_split=0.1)\n\ndata_args = {\n    \"dataframe\": train_df,\n    \"directory\": train_dir,\n    \"x_col\": 'id',\n    \"y_col\": 'has_cactus',\n    \"shuffle\": True,\n    \"target_size\": (32, 32),\n    \"batch_size\": batch_size,\n    \"class_mode\": 'binary'\n}\n\ntrain_generator = datagen.flow_from_dataframe(**data_args, subset='training')\nvalidation_generator = datagen.flow_from_dataframe(**data_args, subset='validation')","fa469450":"model = Sequential([\n    Conv2D(64, (3,3), padding='same', activation=\"relu\", input_shape=(32, 32, 3)),\n    BatchNormalization(),\n    Conv2D(64, (3,3), padding='same', activation=\"relu\"),\n    BatchNormalization(),\n    Conv2D(64, (3,3), padding='same', activation=\"relu\"),\n    BatchNormalization(),\n    MaxPooling2D(2,2),\n    Dropout(0.4),\n    Conv2D(128, (3,3), padding='same', activation=\"relu\"),\n    BatchNormalization(),\n    Conv2D(128, (3,3), padding='same', activation=\"relu\"),\n    BatchNormalization(),\n    Conv2D(128, (3,3), padding='same', activation=\"relu\"),\n    BatchNormalization(),\n    MaxPooling2D(2,2),\n    Dropout(0.4),\n    Conv2D(256, (3,3), padding='same', activation=\"relu\"),\n    BatchNormalization(),\n    Conv2D(256, (3,3), padding='same', activation=\"relu\"),\n    BatchNormalization(),\n    MaxPooling2D(2,2),\n    Dropout(0.4),\n    Conv2D(256, (3,3), padding='same', activation=\"relu\"),\n    BatchNormalization(),\n    Conv2D(256, (3,3), padding='same', activation=\"relu\"),\n    BatchNormalization(),\n    MaxPooling2D(2,2),\n    Dropout(0.4),\n    GlobalAveragePooling2D(),\n    Dense(units=256, activation='relu'),\n    Dropout(0.5),\n    Dense(units=256, activation='relu'),\n    Dropout(0.5),\n    Dense(units=1, activation='sigmoid')\n])\n\nmodel.compile(optimizer=Adam(lr=0.001), \n                 loss='binary_crossentropy',\n                 metrics=['acc'])\nmodel.summary()","69a78c72":"ckpt_path = 'aerial_cactus_detection.hdf5'\n\nearlystop = EarlyStopping(monitor='val_acc', patience=10, verbose=1, restore_best_weights=True)\nreducelr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=3, verbose=1, min_lr=1.e-6)\nmodelckpt_cb = ModelCheckpoint(ckpt_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\ntb = TensorBoard()\n\ncallbacks = [earlystop, reducelr, modelckpt_cb, tb]","68142b22":"history = model.fit_generator(train_generator,\n              validation_data=validation_generator,\n              steps_per_epoch=train_size\/\/batch_size,\n              validation_steps=validation_size\/\/batch_size,\n              epochs=100, verbose=1, \n              shuffle=True,\n              callbacks=callbacks)","49d29a57":"# Training plots\nepochs = [i for i in range(1, len(history.history['loss'])+1)]\n\nplt.plot(epochs, history.history['loss'], color='blue', label=\"training_loss\")\nplt.plot(epochs, history.history['val_loss'], color='red', label=\"validation_loss\")\nplt.legend(loc='best')\nplt.title('loss')\nplt.xlabel('epoch')\nplt.show()\n\nplt.plot(epochs, history.history['acc'], color='blue', label=\"training_accuracy\")\nplt.plot(epochs, history.history['val_acc'], color='red',label=\"validation_accuracy\")\nplt.legend(loc='best')\nplt.title('accuracy')\nplt.xlabel('epoch')\nplt.show()","f822385b":"test_df = pd.read_csv(os.path.join(base_dir, \"sample_submission.csv\"))\nprint(test_df.head())\ntest_images = []\nimages = test_df['id'].values\n\nfor image_id in images:\n    test_images.append(cv2.imread(os.path.join(test_dir, image_id)))\n    \ntest_images = np.asarray(test_images)\ntest_images = test_images \/ 255.0\nprint(\"Number of Test set images: \" + str(len(test_images)))","927ec5be":"pred = model.predict(test_images)\ntest_df['has_cactus'] = pred\ntest_df.to_csv('aerial-cactus-submission.csv', index = False)","639968b3":"### Set callbacks for training","b6a65b45":"### Train vs Validation Visualization\n\nThese plots can help realize cases of overfitting.","624906b0":"### Get Test Set images","7373ac2d":"### Set train and test directories","1e2936f7":"### Tensorboard visualizations\n\nHelps visualizing the training loss and accuracy after each epoch. ","954f498b":"### Get training images and labels\n\nThis process provides little scope for data augmentation. I commented this out to use Image Generators, which is mor esuited for augmentation. ","f260ed75":"These are some standard callbacks which keras provides. \n1. EarlyStopping: Stops the training process if the monitored parameter stops improving with 'patience' number of epochs.\n2. ReduceLROnPlateau: Reduces learning rate by a factor if monitored parameter stops improving with 'patience' number of epochs. This helps fit the training data better.\n3. TensorBoard: Helps in visualization.\n4. ModelCheckpoint: Stores the best weights after each epoch in the path provided.\n\nFor further details, refer [this link.](https:\/\/keras.io\/callbacks)","a4553e3a":"### Build the model","9219c15e":"### Make predictions on test set","03f3c6a3":"### Using Image Generators for preprocessing input images","b133b8c8":"Image Generators have been used to augment the existing data. Training set is split in a 90:10 into train and validation set. Generators are created for each split. ","e848e0da":"### Train the model"}}