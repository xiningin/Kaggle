{"cell_type":{"20096fd0":"code","e66d42ba":"code","42eaced6":"code","f631da6f":"code","e1f99e5b":"code","b5ea444a":"code","a9d9ab8b":"code","c5c0b6ad":"code","8d54621c":"code","875bf817":"code","2b063a37":"code","638f437f":"code","92a8e169":"code","6d1e5fa7":"code","a39a250a":"code","54153758":"code","48716f38":"code","211ebd9d":"code","0378c90e":"code","e7697c58":"code","2142ba3a":"code","c8e84d4c":"markdown","c5e91811":"markdown","3583ea5d":"markdown","6d9cc47b":"markdown","f5d74f55":"markdown","80878b94":"markdown","6d41a4ab":"markdown","ee911f4b":"markdown","32b693b0":"markdown"},"source":{"20096fd0":"import argparse\nimport os           # OS will be used traverse through files.\nimport numpy as np  # Numpy will be used to do maths stuff.\nimport math         # Math for maths.\n\nimport torchvision.transforms as transforms  # Transforms will be used for Data Augmentation.\nfrom torchvision.utils import save_image     # save_image will be used to save output images.\n\nfrom torch.utils.data import DataLoader      # DataLoader is our Compiler which compiles\n                                             # everything that revolves around preprocessing.\nfrom torchvision import datasets             # Using this to import the MNIST Dataset. \nfrom torch.autograd import Variable          \n\n# Everything below is used to define our Generator and Discriminator\nimport torch.nn as nn                  \nimport torch.nn.functional as F\nimport torch\n\nimport matplotlib.pyplot as plt              # Matplotlib will be used to plot output.","e66d42ba":"# Creating a new folder where our output will exist.\nos.makedirs('output', exist_ok = True)","42eaced6":"# Creating a new folder where our we have to put our input dataset.\nos.makedirs('input', exist_ok = True)","f631da6f":"# image_shape refers to the shape of the input images.\nimg_shape = (1, 28, 28)","e1f99e5b":"# Generator refers to the part of our Network which Generates noise.\nclass Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()     \n        self.fc1 = nn.Linear(100, 128)\n        self.fc2 = nn.Linear(128, 512)\n        self.fc3 = nn.Linear(512, 1024)\n        self.fc4 = nn.Linear(1024, 28*28)\n        self.in1 = nn.BatchNorm1d(128)\n        self.in2 = nn.BatchNorm1d(512)\n        self.in3 = nn.BatchNorm1d(1024)\n        \n    def forward(self, x):\n        x = F.leaky_relu(self.fc1(x), 0.2)\n        x = F.leaky_relu(self.in2(self.fc2(x)), 0.2)\n        x = F.leaky_relu(self.in3(self.fc3(x)), 0.2)\n        x = F.leaky_relu(self.fc4(x))\n        return x.view(x.shape[0],*img_shape)\n    ","b5ea444a":"# Discriminator will attack the noise produced by the Generator for not being like the input images.\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.fc1 = nn.Linear(28*28, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 128)\n        self.fc4 = nn.Linear(128, 1)\n        \n    def forward(self, x):\n        x = x.view(x.size(0), -1)\n        x = F.leaky_relu((self.fc1(x)), 0.2)\n        x = F.leaky_relu((self.fc2(x)), 0.2)\n        x = F.leaky_relu((self.fc3(x)), 0.2)\n        x = F.sigmoid(self.fc4(x))\n        return x","a9d9ab8b":"# Defining the Loss Function:\nloss_func = torch.nn.BCELoss()","c5c0b6ad":"# Making the Generator and Discriminator classes usable:\ngenerator = Generator()\n\ndiscriminator = Discriminator()","8d54621c":"data = torch.utils.data.DataLoader(\n    datasets.MNIST('.\/input\/',download = True,           # Downloading the Dataset.\n                   train=True,                           # Yes, we will be training this bad boy.\n              transform = transforms.Compose([           # Finally, transforming the data.\n                  transforms.ToTensor(),                 # Converting the images into Tensors.\n                  transforms.Normalize([0.5],[0.5])])),  # Normalizing the Tensors.\n    batch_size = 64, shuffle = True)                     # Defining the batchsize and shuffling the data. ","875bf817":"if torch.cuda.is_available():\n    generator.cuda()\n    discriminator.cuda()\n    loss_func.cuda()","2b063a37":"optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002,betas=(0.4,0.999))\noptimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002,betas=(0.4,0.999))","638f437f":"Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor","92a8e169":"\nfor epoch in range(150):\n    for i, (imgs, _) in enumerate(data):\n\n        #ground truths\n        val = Tensor(imgs.size(0), 1).fill_(1.0)\n        fake = Tensor(imgs.size(0), 1).fill_(0.0)\n\n        real_imgs = imgs.cuda()\n\n\n        optimizer_G.zero_grad()\n\n        gen_input = Tensor(np.random.normal(0, 1, (imgs.shape[0],100)))\n\n        gen = generator(gen_input)\n\n        #measure of generator's ability to fool discriminator\n        g_loss = loss_func(discriminator(gen), val)\n\n        g_loss.backward()\n        optimizer_G.step()\n\n        optimizer_D.zero_grad()\n\n        real_loss = loss_func(discriminator(real_imgs), val)\n        fake_loss = loss_func(discriminator(gen.detach()), fake)\n        d_loss = (real_loss + fake_loss) \/ 2\n\n        d_loss.backward()\n        optimizer_D.step()\n\n        print (\"[Epoch %d\/%d] [Batch %d\/%d] [D loss: %f] [G loss: %f]\" % (epoch, 150, i, len(data),\n                                                            d_loss.item(), g_loss.item()))\n        \n        total_batch = epoch * len(data) + i\n        if total_batch % 400 == 0:\n            save_image(gen.data[:25], 'output\/%d.png' % total_batch, nrow=5, normalize=True)","6d1e5fa7":"# This literally nothing but noise becuase it is the first output.\nplt.imshow(plt.imread(\".\/output\/0.png\"))","a39a250a":"# These are improving I guess:\nplt.imshow(plt.imread(\".\/output\/10000.png\"))","54153758":"# Lets see it again:\nplt.imshow(plt.imread(\".\/output\/20000.png\"))","48716f38":"plt.imshow(plt.imread(\".\/output\/60000.png\"))","211ebd9d":"plt.imshow(plt.imread(\".\/output\/70000.png\"))","0378c90e":"plt.imshow(plt.imread(\".\/output\/80000.png\"))","e7697c58":"plt.imshow(plt.imread(\".\/output\/100000.png\"))","2142ba3a":"plt.imshow(plt.imread(\".\/output\/110000.png\"))","c8e84d4c":"# Training the Model:\nFinally training the model for 150 Epochs.","c5e91811":"# Generator and Discriminator\nMore like defining the conman printing counterfeit money and the currency checker!","3583ea5d":"So I came across a [video](https:\/\/www.youtube.com\/watch?v=aZpsxMZbG14) on this [paper](https:\/\/arxiv.org\/abs\/1406.2661) which lead to the founding of Generative Adversarial Networks by Ian Goodfellow. It kinda explained it pretty well on how these two parts of the same model but different neural networks, namely Generator and Discriminator. The Generator is like a conman, he likes to print counterfeit currency and tries to put these into the bank. The bank has this dude who basically checks these currencies. \nEverytime the currency is not exactly like the real currency, it gives the conman a negative reward. The goal of the conman or the Generator was to produce the exact looking currency.","6d9cc47b":"# Table of Content\n\n1. Importing Libraries\n2. Generator and Discriminator\n3. DataLoader\n4. Training the Model\n5. Results","f5d74f55":"![](https:\/\/nypost.com\/wp-content\/uploads\/sites\/2\/2015\/11\/26t-linda_catch1-c-ta.jpg?quality=80&strip=all&w=618&h=410&crop=1)","80878b94":"# DataLoader\nDataLoader is the compiler tool which grabs all the things required to make the data usable and put it into the model.","6d41a4ab":"# Importing Libraries\nBelow are the libraries that we need.","ee911f4b":"# Results\nLets take a look at our efforts:","32b693b0":"What we saw above was how the Discriminator struck down Generator's images. After 150 epochs what we see is how the model improved the images\nthat were initially just raw noises and slowly became rough images of numbers. "}}