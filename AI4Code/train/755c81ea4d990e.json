{"cell_type":{"5bf97617":"code","48c881d4":"code","228a7422":"code","3d90ab95":"code","c7f74c01":"code","c2bbfe0d":"code","aa941482":"code","c5a99ddd":"code","90d3a730":"code","f5d3be03":"code","0999fdcd":"code","f9f3e2e7":"code","d527a87e":"code","a8a92892":"code","fbe95d38":"code","12e88f87":"code","13b5a951":"code","bd041ebe":"markdown","6ac50ea3":"markdown","2e4f8c7c":"markdown","bc00de56":"markdown","45cdd7db":"markdown","6ee24b75":"markdown","90b44f8a":"markdown","8b560a27":"markdown","f49d0f50":"markdown","72bff1bc":"markdown","de6606ee":"markdown"},"source":{"5bf97617":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport xgboost as xgb\nfrom xgboost import XGBRegressor , XGBClassifier \nimport lightgbm as lgb\nfrom lightgbm import LGBMRegressor , LGBMClassifier\nimport catboost as cat\nfrom catboost import CatBoostRegressor , CatBoostClassifier\n\nfrom sklearn.model_selection import train_test_split","48c881d4":"df = pd.read_csv('..\/input\/hepatitis-c-virus-blood-biomarkers\/hcvdat0.csv')\ndf.head()","228a7422":"df[\"Category\"].value_counts()","3d90ab95":"df.nunique()","c7f74c01":"df.describe()","c2bbfe0d":"sns.heatmap(df.corr() , annot = True)","aa941482":"g = sns.PairGrid(df)\ng.map_upper(sns.histplot , log_scale = True)\ng.map_lower(sns.kdeplot, fill=True , log_scale = True)\ng.map_diag(sns.histplot, kde=True , log_scale = True)","c5a99ddd":"df = pd.read_csv('..\/input\/hepatitis-c-virus-blood-biomarkers\/hcvdat0.csv')\ndf","90d3a730":"#df.info()\n\ndf['Sex'].loc[df['Sex'] == 'm'] = 1\n\ndf['Sex'].loc[df['Sex'] == 'f'] = 0\ndf['Sex']","f5d3be03":"df['Sex'] = df['Sex'].astype('int')","0999fdcd":"df = df.drop(columns = ['Unnamed: 0'])","f9f3e2e7":"\ndf_train  , df_eval = train_test_split(df , test_size = 0.2 , shuffle = True)\n\ntargets = ['Category']\n\ny_train = df_train[targets]\nx_train = df_train.drop(columns = targets) \n\ny_test = df_eval[targets]\nx_test = df_eval.drop(columns = targets) \n\nx_train","d527a87e":"model_xgboost = XGBClassifier( colsample_bytree=0.7, learning_rate = 0.03 ,\n                                  n_estimators=100, subsample=0.7,alpha=0.9) # define\n    \nmodel_xgboost.fit(x_train,  y_train) #fit\npreds = model_xgboost.predict(x_test) #predict ","a8a92892":"preds","fbe95d38":"\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nprint(classification_report(preds , y_test))\nsns.set(rc={\"figure.figsize\":(10, 7)})\nsns.heatmap(pd.DataFrame(confusion_matrix(preds , y_test)) , cmap=\"magma\" , annot = True)\n","12e88f87":"#https:\/\/scikit-learn.org\/stable\/modules\/model_evaluation.html#scoring-parameter\nfrom sklearn.model_selection import RandomizedSearchCV\n\n\nparams = {\n    'learning_rate' : [0.01 , 0.05 , 0.1 ,0.2],\n    'max_depth'  : [3 ,4 , 15],\n    'min_child_weight' : [1,3,5,7],\n    'gamma' : [0.0 , 0.1 , 0.2 , 0.3],\n    'colsample_bytree' : [0.3 , 0.4 , 0.5],\n    'n_estimators' : [750, 1000]}\n\nmodel_xgboost = XGBClassifier() \n\nrandom_search = RandomizedSearchCV(model_xgboost , param_distributions = params , \n                                   n_iter = 3 , cv = 3 , scoring = 'accuracy', n_jobs=-1 , verbose= 3 )\n\nrandom_search.fit(x_train, y_train)\n\nprint(random_search.best_estimator_)\nprint(random_search.best_params_)\n\n\nmodel_xgboost11 = random_search.best_estimator_\n\nmodel_xgboost11.fit(x_train, y_train) #fit\n\npreds = model_xgboost11.predict(x_test) #predict \n\nprint(classification_report(preds , y_test))\nsns.set(rc={\"figure.figsize\":(10, 7)})\nsns.heatmap(pd.DataFrame(confusion_matrix(preds , y_test)) , cmap=\"magma\" , annot = True)\n","13b5a951":"model_xgboost = XGBClassifier() \n\nrandom_search = RandomizedSearchCV(model_xgboost , param_distributions = params , \n                                   n_iter = 1 , cv = 3 , scoring = 'f1_macro' , n_jobs=-1 , verbose= 3 )\n\nrandom_search.fit(x_train, y_train)\n\nprint(random_search.best_estimator_)\nprint(random_search.best_params_)\n\n\nmodel_xgboost11 = random_search.best_estimator_\n\nmodel_xgboost11.fit(x_train, y_train) #fit\n\npreds = model_xgboost11.predict(x_test) #predict \n\nprint(classification_report(preds , y_test))\nsns.set(rc={\"figure.figsize\":(10, 7)})\nsns.heatmap(pd.DataFrame(confusion_matrix(preds , y_test)) , cmap=\"magma\" , annot = True)\n","bd041ebe":"This dataset contains 14 columns, labelled into 4 classes.\n\n## 4 Classes\n\n1. Blood donors\n2. Hepatitis C \n   - 'just' Hepatitis C\n   - with Fibrosis\n   - with Cirrhosis\n   \n(values: '0=Blood Donor', '0s=suspect Blood Donor', '1=Hepatitis', '2=Fibrosis', '3=Cirrhosis')","6ac50ea3":"Each cell in the correlation matrix is a \u2018correlation coefficient\u2018 between the two variables corresponding to the row and column of the cell.\n\n## A **Correlation coefficient** is a number that denotes the strength of the relationship between two variables.\n\nThere are several correlation coefficients, \n\n1. Pearson\u2019s coefficient(denotted by \u03c1 (rho)) - most common used \nIt is defined as the covariance between two variables divided by the product of the standard deviations of the two variables.\n\n## Formula for correlation coefficient between two variables\n\nWhere the covariance between X and Y COV(X, Y) is further defined as the \u2018expected value of the product of the deviations of X and Y from their respective means\u2019.\n\n- The value of \u03c1 lies between -1 and +1.\n- Values nearing +1 indicate the presence of a strong positive relation between X and Y, whereas those nearing -1 indicate a strong negative relation between X and Y.\n- Values near to zero mean there is an absence of any relationship between X and Y.\n","2e4f8c7c":"## Our interpretation from Data\n\n### There seems to be some correlations in Biomarker levels. Lets first note them done, and then lets try to make sense out of them.\n\n### More than 0.5 \n - Prot - ALB\n\n### 0.4 - 0.5 \n - ALP - GGT\n - AST - GGT\n \n\n### Less than 0 \/ Negative values\n - CHOL \/ ALB \/ CHE - GGT\n - CHOL \/Age \/ ALB \/ CHE - CREA\n - BIL \/ ALB - CHE\n \n       ","bc00de56":"All the values seeem logical.\nAge is in logical range.\n\nALB \tALP \tALT \tAST \tBIL \tCHE \tCHOL \tCREA \tGGT \tPROT - Seem in medically possible ranges(healthy or Diseased patient)","45cdd7db":"# Exploratory data analysis","6ee24b75":"# Randomized Search in XGBoost","90b44f8a":"# Hepatitis C\n\n# Notebook with EDA and AutoML - [EDA notebook Link](https:\/\/www.kaggle.com\/amritpal333\/hepatitis-c-virus-detection-eda-automl)\nHi, I am Dr. Amrit. In this notebook, we will try to dive deep into this dataset.\n\nHepatitis C is one of the most commonly spread infections during Blood donation. Its detection is often complex, expensive and time-taking.\n\nSo rather than going through traditional pathway, new approaches are trying to detect Hepatitis C status using Blood biomarkers. In certain cases, attempts have been made to even sub-categorize the stage of Hepatitis C.\n\nHepatitis C is a dangerous disease, with high fatility, hence prevention is the best remedy the keep in mind.\n\n\n![hepatitis_cells_colorful_stain.jpg](attachment:98b822bc-a765-4f4a-9587-22c5fed97dab.jpg)\n\nDataset - https:\/\/www.kaggle.com\/amritpal333\/hepatitis-c-virus-blood-biomarkers\n\n","8b560a27":"Lets get started by importing things we need","f49d0f50":"As we can see, model isnt really doing good. Its mostly predicting everything as Class0. Lets try to improve on this.","72bff1bc":"# Train simple XGBoost","de6606ee":"# 14 columns \n\n1. X (Patient ID\/No.)\n2. Category (diagnosis) \n3. Age (in years)\n4. Sex (f,m)\n5. ALB\n6. ALP\n7. ALT\n8. AST\n9. BIL\n10. CHE\n11. CHOL\n12. CREA\n13. GGT\n14. PROT"}}