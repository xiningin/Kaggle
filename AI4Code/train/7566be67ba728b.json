{"cell_type":{"6f98e628":"code","7db1a074":"code","13edc787":"code","ace471a8":"code","c8919d4a":"code","508c2464":"code","6c0936b1":"code","8840c73a":"code","46192ac5":"code","063a0216":"code","04bfbc2d":"code","f27fda96":"code","8f63f6ae":"code","2c16a66f":"code","a8a3637a":"code","d5568478":"code","d2e4d6a6":"code","f24dfb95":"code","9eca6507":"code","9d5ca26e":"code","8fb3a2a1":"code","e426830e":"code","f471f048":"code","d93b395b":"code","04de41d5":"code","6a534336":"code","4f88911b":"code","0f872652":"code","ecaa8a72":"code","5583b60a":"code","abb4ea41":"code","50433735":"code","94725478":"code","a0870bd5":"code","1f08d348":"code","e9d78ceb":"code","b3ba7ed6":"code","1e62d9d2":"code","bb835754":"code","4d7b3165":"code","5a78aa2c":"code","cf1189b0":"markdown","b6c8fdd6":"markdown","98c474ba":"markdown","1fc48ed1":"markdown","ac17d3fe":"markdown","686cc312":"markdown","4d62219f":"markdown","1800e1a2":"markdown","fbf36dbe":"markdown","04434fac":"markdown","f3cb2a37":"markdown","3e8a3850":"markdown","61f20ff4":"markdown","e64a322e":"markdown","fdb9229f":"markdown","69e4f95f":"markdown","92770f1e":"markdown","55d2e5d3":"markdown","beb75e13":"markdown","b53dae13":"markdown","40f3d0c2":"markdown","aa1d8fcf":"markdown","8b716369":"markdown","0c508ed5":"markdown","77f5debc":"markdown","6f2f0d36":"markdown","48e089f3":"markdown","32bc4153":"markdown","35f250fc":"markdown","e4ca7352":"markdown","382be3fb":"markdown","078a1b82":"markdown"},"source":{"6f98e628":"# pivot_results","7db1a074":"# Import libraries for data manipulation\nimport numpy as np\nimport pandas as pd\nfrom pandas.plotting import scatter_matrix\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('seaborn')\n\nimport seaborn as sns\n\n# Import library for modeling\nimport statsmodels.api as sm\nfrom statsmodels.tsa.stattools import adfuller","13edc787":"# Read in csv file\ndf_in = pd.read_csv('..\/input\/data.csv')","ace471a8":"# Peek at data\ndf_in.head()","c8919d4a":"# Get general description of numerical fields in input dataframe\ndesc = df_in.describe()\ndesc.apply(lambda x: x.apply(lambda y: \"{:.1f}\".format(y)))","508c2464":"# Get general information on input dataframe\ndf_in.info()","6c0936b1":"# Locate any nulls in the dataset\ndf_in.isnull().sum(0)","8840c73a":"# Determine the granularity of the weather data\n\n# Is it daily?\ndaily = df_in[['year', 'month', 'week', 'day', 'events', 'temperature']].drop_duplicates().shape[0] \\\n            == df_in[['year', 'month', 'week', 'day']].drop_duplicates().shape[0]\n\n# Is it hourly?\nhourly = df_in[['year', 'month', 'week', 'day', 'hour', 'events', 'temperature']].drop_duplicates().shape[0] \\\n            == df_in[['year', 'month', 'week', 'day', 'hour']].drop_duplicates().shape[0]\nprint(\"Daily?\", daily, \"; Hourly?\", hourly)","46192ac5":"# Add date column for starting date\ndf_in['start_date'] = df_in['starttime'].str[:10]\ndf_in = df_in.sort_values(by=['starttime']).reset_index(drop=True)","063a0216":"# Create new summarized dataset at the hourly level\ndf_in['tripcount'] = 1\ndf_hourly = df_in.groupby(['start_date', 'year', 'month', 'week', 'day', 'hour', 'temperature', 'events']) \\\n                 .agg({'tripcount':'sum', 'tripduration':'sum'}).reset_index()\ndf_hourly['avg_duration'] = df_hourly['tripduration'] \/ df_hourly['tripcount']\ndf_hourly.head()","04bfbc2d":"# Create daily level dataset\ndf_daily = df_hourly.groupby(['start_date', 'year', 'month', 'week', 'day']) \\\n                    .agg({'temperature':'mean', 'events':lambda x:x.value_counts().index[0],\n                          'tripcount':'sum', 'tripduration':'sum'}).reset_index()\n    \ndf_daily['avg_duration'] = df_daily['tripduration'] \/ df_daily['tripcount']\ndf_daily.head()","f27fda96":"# Create flags for weekends\ndf_hourly['weekend'] = np.where(df_hourly.day > 4 , 1, 0)\ndf_daily['weekend'] = np.where(df_daily.day > 4 , 1, 0)","8f63f6ae":"# Ingest holidays \nbank_holidays = [\n    '2014-01-01', '2014-01-20', '2014-02-17', '2014-05-26', \n    '2014-07-04', '2014-09-01', '2014-10-13', '2014-11-11', \n    '2014-11-27', '2014-12-25', '2015-01-01', '2015-01-19', \n    '2015-02-16', '2015-05-25', '2015-07-03', '2015-09-07', \n    '2015-10-12', '2015-11-11', '2015-11-26', '2015-12-25', \n    '2016-01-01', '2016-01-18', '2016-02-15', '2016-05-30', \n    '2016-07-04', '2016-09-05', '2016-10-10', '2016-11-11', \n    '2016-11-24', '2016-12-25', '2017-01-02', '2017-01-16', \n    '2017-02-20', '2017-05-29', '2017-07-04', '2017-09-04', \n    '2017-10-09', '2017-11-10', '2017-11-23', '2017-12-25'\n]\n\n# Add holiday flags\ndf_hourly['holiday'] = df_hourly['start_date'].apply(lambda x: 1*any([k in x for k in bank_holidays]))\ndf_daily['holiday'] = df_daily['start_date'].apply(lambda x: 1*any([k in x for k in bank_holidays]))\n\n# Add holiday weekend flags (if weekend is within 2 days of a holiday)\ncond = (df_daily['holiday'].shift(1) == 1) |  \\\n        (df_daily['holiday'].shift(2) == 1) |  \\\n        (df_daily['holiday'].shift(-1) == 1) |  \\\n        (df_daily['holiday'].shift(-2) == 1) |  \\\n        (df_daily['holiday'] == 1)\n\ndf_daily['weekend_holiday'] = np.where((cond * df_daily['weekend']) == 1, 1, 0)\n\n# Add the second day of the holiday weekend if the other weekend day was flagged\ncond = (df_daily['weekend_holiday'].shift(1) == 1) |  \\\n        (df_daily['weekend_holiday'].shift(-1) ==  1) |  \\\n        (df_daily['weekend_holiday'] == 1)\ndf_daily['weekend_holiday'] = np.where((cond * df_daily['weekend']) == 1, 1, 0)\ndf_daily.to_csv(\"holiday_weekends.csv\")\n\n# Finalize holiday weekend column\ndf_hweekends = df_daily[['start_date', 'weekend_holiday']]\ndf_hourly = pd.merge(df_hourly, df_hweekends, how = 'left', on = 'start_date')\ndf_hourly.head()","2c16a66f":"df_daily[['start_date','tripcount']].plot(kind = 'area', figsize = (18,5));","a8a3637a":"df_daily[['start_date','avg_duration']].plot(kind = 'area', figsize = (18,5));","d5568478":"# Add datetime columns for later use\ndf_hourly['start_datetime'] = pd.to_datetime(df_hourly['start_date'] + ' ' + df_hourly['hour'].astype(str) + ':00')\ndf_daily['start_datetime'] = pd.to_datetime(df_daily['start_date'])","d2e4d6a6":"df_in.hist(figsize=(15, 18), bins=23, xlabelsize=10, ylabelsize=8);","f24dfb95":"# Plot histograms for categorical columns \nfig, axs = plt.subplots(1,3, figsize=(15, 4))\naxs = axs.ravel()\nfor i, categorical_col in enumerate(['usertype', 'gender', 'events']):\n    df = df_in[categorical_col].value_counts() \/ df_in.shape[0]\n    df.plot(kind='bar', title = categorical_col, ax = axs[i])","9eca6507":"df_total = pd.DataFrame(df_hourly['events'].value_counts() \/ df_hourly.shape[0]).reset_index()\ndf_rides = pd.DataFrame(df_in['events'].value_counts() \/ df_in.shape[0]).reset_index()\ndf_total.columns = ['events', 'percentage_of_time']\ndf_rides.columns = ['events', 'percentage_of_rentals']\npd.merge(df_rides, df_total, on = 'events').set_index('events').plot(kind = 'bar');","9d5ca26e":"tmp = pd.DataFrame(np.vstack((range(0,100,10), np.histogram(df_in['temperature'], range = (0,100))[0]\/df_in.shape[0],\n                              np.histogram(df_hourly['temperature'], range = (0, 100))[0]\/df_hourly.shape[0])).T)\ntmp.columns = ['degrees', 'percentage_of_rentals', 'percentage_of_time']\ntmp = tmp.set_index('degrees')\ntmp.plot(kind = 'bar');","8fb3a2a1":"# Plot average for categorical columns \nfig, axs = plt.subplots(3,3, figsize=(15, 15))\naxs = axs.ravel()\nfor i, categorical_col in enumerate(['year', 'month', 'week', 'day', 'temperature',\n                                    'latitude_start', 'latitude_end', 'longitude_start', 'longitude_end']):\n    b = len(df_in[categorical_col].value_counts())\n    if b > 50 :\n        tmp = df_in.groupby(pd.cut(df_in[categorical_col], min(b, 11)))['tripduration'].mean().reset_index()\n        tmp[categorical_col] = [np.round((a.left + a.right)\/2,1) for a in tmp[categorical_col]]\n    else:\n        tmp = df_in.groupby([categorical_col])['tripduration'].mean().reset_index()\n    tmp = tmp.set_index(categorical_col)\n    del tmp.index.name\n    tmp.plot(kind = 'bar', title = categorical_col, ax = axs[i], legend = False, width = 0.9)","e426830e":"# Plot average for categorical columns \nfig, axs = plt.subplots(1,3, figsize=(15, 4))\naxs = axs.ravel()\nfor i, categorical_col in enumerate(['usertype', 'gender', 'events']):\n    tmp = df_in.groupby([categorical_col]).agg({'tripduration':np.mean})\n    del tmp.index.name\n    tmp.plot(kind='bar', ax = axs[i], title = categorical_col)","f471f048":"scatter_matrix(df_daily[['month', 'day', 'temperature',\n       'tripcount', 'avg_duration']], alpha=0.4, figsize=(18, 18), diagonal='kde', grid = True);","d93b395b":"tmp = df_hourly[['month', 'temperature', 'avg_duration', 'tripcount']].corr()\nsns.heatmap(tmp, xticklabels=tmp.columns,yticklabels=tmp.columns, annot= True, linewidths = 0.5);","04de41d5":"# Daily level\ntc_counts = df_daily.set_index('start_datetime')[['tripcount']].tripcount\ntc_daily = sm.tsa.seasonal_decompose(tc_counts, freq=365)\nresplot = tc_daily.plot()","6a534336":"# Hourly level\ntc_counts = df_hourly.set_index('start_datetime')[['tripcount']].tripcount\ntc_hourly = sm.tsa.seasonal_decompose(tc_counts, freq=8760)\nresplot = tc_hourly.plot()","4f88911b":"# Daily level\navg_dur = df_daily.set_index('start_datetime')[['avg_duration']].avg_duration\ndur_daily = sm.tsa.seasonal_decompose(avg_dur, freq=365)\nresplot = dur_daily.plot()","0f872652":"# Hourly level\navg_dur = df_hourly.set_index('start_datetime')[['avg_duration']].avg_duration\ndur_hourly = sm.tsa.seasonal_decompose(avg_dur, freq=8760)\nresplot = dur_hourly.plot()","ecaa8a72":"# Remove un-needed variables\ndf_hourly_regr = df_hourly.drop(['start_date', 'tripduration'], axis = 1).reset_index(level=0)\ndf_daily_regr = df_daily.drop(['start_date', 'tripduration'], axis = 1).reset_index(level=0)\ndf_hourly_regr.head()","5583b60a":"# Create separate dataframes for residuals\ndf_daily_regr_resid = pd.merge(df_daily_regr, pd.DataFrame(dur_daily.resid).reset_index(), how = 'left', on = 'start_datetime')\ndf_daily_regr_resid = pd.merge(df_daily_regr_resid, pd.DataFrame(tc_daily.resid).reset_index(), how = 'left', on = 'start_datetime')\n\ndf_daily_regr_resid = df_daily_regr_resid[df_daily_regr_resid['avg_duration_y'].notnull()]\ndf_daily_regr_resid = df_daily_regr_resid.drop(['index', 'year', 'month', 'week', 'day', 'tripcount_x', \n                                                'avg_duration_x', 'weekend'], axis = 1)\n\ndf_hourly_regr_resid = pd.merge(df_hourly_regr, pd.DataFrame(dur_hourly.resid).reset_index(), how = 'left', on = 'start_datetime')\ndf_hourly_regr_resid = pd.merge(df_hourly_regr_resid, pd.DataFrame(tc_hourly.resid).reset_index(), how = 'left', on = 'start_datetime')\n\ndf_hourly_regr_resid = df_hourly_regr_resid[df_hourly_regr_resid['avg_duration_y'].notnull()]\ndf_hourly_regr_resid = df_hourly_regr_resid.drop(['index', 'year', 'month', 'week', 'day',\n                                                  'hour', 'tripcount_x', 'avg_duration_x', 'weekend'], axis = 1)\n\n\ndf_hourly_regr_resid.head()","abb4ea41":"# Add dummy variables for time variables\nfor col in ['year', 'month', 'week', 'day']:\n    df_hourly_regr[col] = df_hourly_regr[col].astype(str)\n    df_daily_regr[col] = df_daily_regr[col].astype(str)\ndf_hourly_regr['hour'] = df_hourly_regr['hour'].astype(str)\n\ndf_daily_regr = pd.get_dummies(df_daily_regr, prefix = ['year', 'month', 'week', 'day', 'events'])\ndf_hourly_regr = pd.get_dummies(df_hourly_regr, prefix = ['year', 'month', 'week', 'day', 'hour', 'events'])\n\ndf_daily_regr_resid = pd.get_dummies(df_daily_regr_resid, prefix = ['events'])\ndf_hourly_regr_resid = pd.get_dummies(df_hourly_regr_resid, prefix = ['events'])","50433735":"# List of coefficients that we care about\nweather_vars = ['temperature', 'events_clear', 'events_cloudy',\n                'events_not clear', 'events_rain or snow', 'events_tstorms', 'events_unknown']\n\nmodel_results = pd.DataFrame(columns = ['level', 'data_type', 'dependent_var', 'var', 'coef', 'pvalue'])\n\n# Define function to append new results to dataframe\ndef add_to_results(m, level, d_type, d_var):\n    out = model_results\n    d = {}\n    d['level'] = level\n    d['data_type'] = d_type\n    d['dependent_var'] = d_var\n    for v in weather_vars:\n        if v in model.params.index:\n            d['var'] = v\n            d['coef'] = m.params[v]\n            d['pvalue'] = m.pvalues[v]\n            out = out.append(d, ignore_index = True)\n    return out","94725478":"# Daily Model - Raw data\nX = df_daily_regr.drop(['avg_duration', 'tripcount', 'start_datetime'], axis = 1)\nY = df_daily_regr['tripcount']\n\nX = sm.add_constant(X)\nmodel = sm.OLS(Y, X).fit()\nmodel_results = add_to_results(model, 'daily', 'original', 'tripcount')\nmodel.summary()","a0870bd5":"# Hourly Model - Raw Data\nX = df_hourly_regr.drop(['avg_duration', 'tripcount', 'start_datetime'], axis = 1)\nY = df_hourly_regr['tripcount']\n\nX = sm.add_constant(X)\nmodel = sm.OLS(Y, X).fit()\nmodel_results = add_to_results(model, 'hourly', 'original', 'tripcount')\nmodel.summary()","1f08d348":"# Daily Model - Residuals data\nX = df_daily_regr_resid.drop(['avg_duration_y', 'tripcount_y', 'start_datetime'], axis = 1)\nY = df_daily_regr_resid['tripcount_y']\n\nX = sm.add_constant(X)\nmodel = sm.OLS(Y, X).fit()\nmodel_results = add_to_results(model, 'daily', 'residuals', 'tripcount')\nmodel.summary()","e9d78ceb":"# Hourly Model - Raw Data\nX = df_hourly_regr_resid.drop(['avg_duration_y', 'tripcount_y', 'start_datetime'], axis = 1)\nY = df_hourly_regr_resid['tripcount_y']\n\nX = sm.add_constant(X)\nmodel = sm.OLS(Y, X).fit()\nmodel_results = add_to_results(model, 'hourly', 'residuals', 'tripcount')\nmodel.summary()","b3ba7ed6":"# Daily Model - Raw Data\nX = df_daily_regr.drop(['avg_duration', 'tripcount', 'start_datetime'], axis = 1)\nY = df_daily_regr['avg_duration']\n\nX = sm.add_constant(X)\nmodel = sm.OLS(Y, X).fit()\nmodel_results = add_to_results(model, 'daily', 'original', 'avg_duration')\nmodel.summary()","1e62d9d2":"# Hourly Model - Raw Data\nX = df_hourly_regr.drop(['avg_duration', 'tripcount', 'start_datetime'], axis = 1)\nY = df_hourly_regr['avg_duration']\n\nX = sm.add_constant(X)\nmodel = sm.OLS(Y, X).fit()\nmodel_results = add_to_results(model, 'hourly', 'original', 'avg_duration')\nmodel.summary()","bb835754":"# Daily Model - Residuals data\nX = df_daily_regr_resid.drop(['avg_duration_y', 'tripcount_y', 'start_datetime'], axis = 1)\nY = df_daily_regr_resid['avg_duration_y']\n\nX = sm.add_constant(X)\nmodel = sm.OLS(Y, X).fit()\nmodel_results = add_to_results(model, 'daily', 'residuals', 'avg_duration')\nmodel.summary()","4d7b3165":"# Hourly Model - Raw Data\nX = df_hourly_regr_resid.drop(['avg_duration_y', 'tripcount_y', 'start_datetime'], axis = 1)\nY = df_hourly_regr_resid['avg_duration_y']\n\nX = sm.add_constant(X)\nmodel = sm.OLS(Y, X).fit()\nmodel_results = add_to_results(model, 'hourly', 'residuals', 'avg_duration')\nmodel.summary()","5a78aa2c":"filtered_results = model_results[model_results['pvalue']<0.05]\npivot_results = pd.pivot_table(filtered_results, index = ['dependent_var','var'], columns = ['level', 'data_type'], values = 'coef', aggfunc = np.mean, fill_value = 'n\/a')\npivot_results","cf1189b0":"The final summary of weather variable results are shown below, which show a general relationship between weather patterns both at the daily and hourly level on duration and number of trips. ","b6c8fdd6":"### Flags for Weekends and Holidays\nAdd flags for weekends, bank holidays, and weekends that are within 2 days of holidays (a.k.a. holiday weekends).","98c474ba":"## Future Analyses\nIt would be interesting to see how much the effect of weather differs by the time of year and types of days. For example, it could be that an unexpected weather event on a weekend holiday would be much more detrimental to trip volume than an unexpected event during a winter weekday. To test that, we could separate the data by the type of day or into months and run similar cuts and regression analyses to see the weather impact.","1fc48ed1":"### Trip Duration\nBoth daily and hourly level decompositions look reasonable, which both show that in the summer months the average duration tends to be higher. There also seems to be somewhat of a trend that trip duration has been increasing, however, in the last year or so it has been flattening out or even decreasing a bit.","ac17d3fe":"### Feature Relationships\n","686cc312":"Since the weather data is at the hourly level, we'll summarize the dataset by the hour but also keep a daily level dataframe as comparison. To summarize weather event and temperature at the daily level, we'll use mode and mean respectively. ","4d62219f":"## Data Manipulation","1800e1a2":"## Exploratory Data Analysis","fbf36dbe":"#### Regression with raw data and time dummies","04434fac":"### Trip Count Analysis","f3cb2a37":"Next, we do a similar analysis for temperature. We see that the range between 70 to 80 degrees sees the most disproportionately high number rentals, with 80-90 next. The distribution begins to change at around 50 degrees where the rental distribution goes below the percentage of time distribution. ","3e8a3850":"### Trip Counts","61f20ff4":"# Divvy Bicycle Sharing Weather Analysis","e64a322e":"From these charts we see that 1) the users of the service are predominately male, and 2) cloudy events see the largest amount of volume; however, this could be because the distribution of weather in chicago is skewed towards cloudy or that more rentals occur on cloudy days. This is a point we can test below, which shows the percentage of hours that the rides are disproportionately on cloudy days even though Chicago sees cloudy days almost 80% of the year. Rain or snow seems the most disproportionately low, followed by clear surprisingly. ","fdb9229f":"From the average trip duration plot we can see a couple of interesting hyptheses worth testing:\n- **Warm weather:** higher temperature leads to longer trips, and does not generally taper off at the high temperatures as trip counts did\n- **Weekend trips:** weekend trips are longer than weekday trips on average, as they are likely to be for leisure instead of commute\n- **Seasonality:** as expected, the summer months has longer trips which also corresponds to when there are higher temperatures in Chicago\n\nAnother observation to note is that there is fairly little fluctuation in the average trip times whereas there is a lot more variation in the number of trips as seen previously. ","69e4f95f":"#### Regression with decomposed residuals","92770f1e":"Most weather events have pretty consistent average ride time of ~11min but does shortten significantly with rain or snow. ","55d2e5d3":"### Trip Count\nInterestingly, the daily level decomposition for trip count looks more appropriate as it has more reasonable residuals; the hourly decomposition shows some cyclicality in the residuals. ","beb75e13":"## Preparation","b53dae13":"### Data preparation","40f3d0c2":"In this notebook we'll be exploring the effect of weather on bicycle sharing volume as provided by Divvy. The data is available on [Kaggle](https:\/\/www.kaggle.com\/yingwurenjian\/chicago-divvy-bicycle-sharing-data). \n\nThe analysis approach is as follows:\n- **Preparation:** ensuring there are no missing values and that we're familiar with the data that is presented and their representations.\n\n\n- **Data Manipulation:**\n    1. Create summarized views of the data at reasonable granularities, which were daily and hourly\n    2. Add in flags for special events such as weekends, holidays, and holiday weekends\n    \n    \n- **Exploratory Data Analysis:** quick views of the data to see general trends on both average trip time and trip counts; get a sense of some of the major correlations, especially for weather variables\n\n\n- **Decomposing Trend \/ Seasonality:** this is done to try and remove the seasonality and trend components from the time series to isolate the residuals which could then be modeled with just the weather variables\n\n\n- **Regression Analysis:** linear regressions are run on both un-decomposed data (with dummies for time variables) and the decomposed data; results are then compiled and summarized for the weather variables\n\n## Key Takeaways\n- **Warm Temperature:** \n    - Bike volume tend to increase when it's quite warm (between 60 and 80 degrees); however, as temperature increases beyond 80, the volume drops off as it's perhaps too hot out to be biking; the optimal range is about 70-80 degrees\n    - Average trip duration increases with temperature as well; it has very high correlation with trip count and duration (~50% for both)\n    - Temperature is also correlated to the number of months \/ annual seasonality which is why in the regression analysis it was important to separate out the effect of seasonality to get a sense of how important is temperature in excess of what is expected at that time of the year\n    \n    \n- **Weather Events:** Cloudy days sees the most disproportionately high number of trips (80% of the time it's cloudy yet 85% of trips are on cloudy days); clear and snow \/ rain sees a disproportionately low number of trips; weather events doesn't have a material effect on trip duration except for snow \/ rain which decreases the average ride time by up to a minute. \n\n\n- **Weekend vs. Weekdays:** weekdays show a high amount of volume for commuters and the daily ride volume is about ~40% on weekdays than on weekends. Also the rides on weekdays are more concentrated around rush hour (9am and 6pm). However, the average ride times are higher on the weekends as they are more likely for leisure. \n\n\n- **Regression Coefficients** are summarized in the table below; they only include coefficients that were tested to be statistically significant (p-value < 0.05). There are two levels to the columns: 1) the data_type which specifies whether the original (un-decomposed) data was used or the residuals from the trend\/seasonality decomposition; and 2) which specifies whether the data was aggregated at the daily level or the hourly level. Some interesting insights from here are:\n    - Generally weather events do not have a huge impact on average duration, however we do see that in rain or snow, the trip lengths decrease about 0.5-1min on average; similar story for temperature - hotter -> longer rides but not by much\n    - For trip counts we do see generally thunderstorms have the biggest impact on rental volume (decrease of 100+ rentals per hour) whereas the other events are similar but there isn't a clear ordering or significance\n    - The residuals showed much fewer weather variables of significance than the original data (with dummies); this is likely because the decomposition algorithm captures a lot of the weather patterns as part of the cyclicality and so the leftover variance is difficult to be explained by weather -- it could only be explained by unexpected weather events","aa1d8fcf":"## Regression Analysis\n\nWe now run linear regression analysis on both the residual data from the decomposition as well as the original data. Some dummy variables will need to be added for date and categorical fields. The coefficients and p-values for the weather variables are saved for summarization. ","8b716369":"#### Regression with raw data and time dummies","0c508ed5":"### Level of Granularity\nWe need to determine the level of granularity that further analysis should be done at. There are two factors that will influence this decision:\n1. At what level will the data have a good enough signal without losing too much fidelity, that is, we don't want the data to be too sparse and spikey, at the same time, we want the grouping to conceal the effects of some of the factors \n2. What level is the weather data at? Are the temperature and events fields at a very granular level, and if we wanted to group it, how do we summarize those fields?","77f5debc":"### Trip Duration Analysis","6f2f0d36":"## Decomposing Trend and Seasonality\n\nHere we use trend and seasonality decomposition to separate out the components of the trip count and duration time series. This is done for both the hourly and daily data. The residuals are then used for the regression analysis in the next section. ","48e089f3":"## Table of Contents\n0. [Preparation](#Preparation)\n1. [Data Manipulation](#Data-Manipulation)\n2. [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n3. [Decomposing Trend and Seasonality](#Decomposing-Trend-and-Seasonality)\n4. [Regression Analysis](#Regression-Analysis)","32bc4153":"### Trip Length","35f250fc":"This feature matrix corroborates some of the observations that we've made before around temperature being positively correlated with both trip count and duration. Looking at the bottom 3 graphs of the left-most column, we see that month is  correlated with temperature in a similar manner as trip count and duration. \n\nTo test this, we run a correlation matrix on the 4 variables. Interestingly, month is shown to have fairly low correlation with the other 3 variables. However, temperature is confirmed to have very high correlation with trip count and duration.","e4ca7352":"#### Regression with decomposed residuals","382be3fb":"Next we initialize the data structure that will hold the results so they'll be easily comparable.","078a1b82":"From this initial view, we can note a few observations and possible analyses that we can further dive into, for example:\n- **Growth Trend:** There seems to be an overall increase in the total volume of bike rentals, indicating there is likely a trend in the dataset\n- **Warm Temperature:** The temperature histogram shows that bike volume tend to increase when it's quite warm (between 60 and 80 degrees); however, as temperature increases beyond 80, the volume drops off since it's perhaps too hot out to be biking\n- **Monthly Seasonality:** The summer months seem to be the most popular time for bike rentals, which corroborates the finding above, which is that warmer temperatures correspond to higher volumes\n- **Hourly Seasonality:** The most popular times for bike rental occur around 9am and 5pm, which is rush hour for commuters\n- **Weekdays vs. Weekends:** Surprisingly, the weekday volumes look to be higher per day than the weekend volumes; this might be because a lot of bicycle renters are using them for commuting (more than the incremental volume that comes from leisure on the weekends)\n- **Location Concetration:** The vast majority of the rental activity is within a narrow range of longitude and latitude coordinates\n- **Short Rides:** The majority of the rides are fairly short (less than 15 minutes)"}}