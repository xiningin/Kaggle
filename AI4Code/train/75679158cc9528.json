{"cell_type":{"513ab30b":"code","d8020ff4":"code","10501e05":"code","7dd4c687":"code","6aea14c6":"code","1d3ca439":"code","1ec98d5a":"code","20d87c15":"code","c7f98025":"code","5a026b12":"code","9aa1b480":"code","bbb46abb":"code","b893774e":"code","879204b3":"code","fecb8eb4":"code","e8fa00b6":"code","3ae2d750":"code","d2663bce":"code","5b5ae892":"code","e2cd6500":"code","1976773a":"code","3f619a9a":"code","f00e0a37":"code","3bb96a8a":"code","cb952d5a":"code","06d85d84":"code","c51835d3":"code","a694be63":"code","fcd4a425":"code","fcde2dc3":"code","21dcfd59":"code","0f6a33e0":"code","4f581b79":"code","a706e3b6":"code","9d1704db":"code","ddc87357":"code","ec7df326":"code","588e66cc":"code","5b5b805d":"code","7a970054":"code","9267f702":"code","be44aa1c":"code","796a97db":"code","c06f4e6d":"code","059a0854":"code","04a98724":"code","0a0be44c":"code","a6183406":"code","ce6d86bb":"code","4728d2c3":"code","0ddeaca4":"code","28f55948":"code","d80eb840":"code","f3690957":"code","4ac78bdd":"code","18d02b2b":"code","5f8e9b1d":"code","e2cb5ead":"code","a09abaeb":"code","5a73e610":"code","f464b220":"code","98ca6857":"code","28586f05":"code","c32ad177":"code","e0daea61":"code","5ed9771c":"code","991bffc8":"code","b0f4213a":"code","1daf8c63":"code","ec407ab5":"code","ea8e7384":"code","d8df5996":"code","61ac5ea1":"code","8125168c":"code","dd82975f":"code","b6ecfbba":"code","9be6ac99":"code","892f5d87":"code","b32463d9":"code","37444d0f":"code","6daa65ba":"code","1b4b15fa":"code","40f5dac2":"code","198aa3d8":"code","588dde0c":"code","d9a40c09":"code","50c9f46d":"code","badef168":"code","c8caa50f":"code","67e52e9c":"code","d8a7a0ef":"code","a131056d":"code","891be147":"code","aac045ff":"code","6ce33ac1":"code","ecc0ff55":"code","9ddfe7b7":"code","952a7468":"code","c23ff22c":"code","979a748c":"code","720b271a":"code","01be6247":"code","dfe902f8":"code","d605eae5":"code","bf32c2a7":"code","7871f613":"code","c032b7bf":"code","1b6e43a7":"code","518cd70f":"code","dc211d8d":"code","d2c762d2":"code","7bedf6e6":"code","2b9bdaa1":"code","2b94e55f":"code","c6206a17":"code","7662b6a2":"code","80c4a221":"code","c3b5eae2":"code","f2ef1d5e":"code","f54bf889":"code","2b490cbc":"code","11667d55":"code","92c92cdf":"code","78502e99":"code","8f6208c2":"code","f7a61da0":"code","428dc434":"code","5e8be3e0":"code","78066a99":"code","2f04e024":"markdown","2beecbe8":"markdown","8670e4bd":"markdown","4cb3d1d7":"markdown","b56dcc43":"markdown","f809de89":"markdown","cb66ba58":"markdown","0409493f":"markdown","82ceeda0":"markdown","59222dd8":"markdown","e06aa327":"markdown","661bca47":"markdown","a43ac6fe":"markdown","74ec07c7":"markdown","2ad9f093":"markdown","672a37fa":"markdown","f690d3e5":"markdown","e0b1caf1":"markdown","3c2567a1":"markdown","35b5f5d2":"markdown","5e706894":"markdown","760da52f":"markdown","16cc514e":"markdown","912dd090":"markdown","2fa0a55d":"markdown","3051eee0":"markdown","97fbadb3":"markdown","722647f9":"markdown","c3f11b81":"markdown","924bec5a":"markdown","d62e69a3":"markdown","adb6b059":"markdown","89e16407":"markdown","2307b638":"markdown","cdb755c1":"markdown","0f29c40d":"markdown","b524b446":"markdown","59573df5":"markdown","5509b255":"markdown","8e492538":"markdown","6e6fc548":"markdown","1f2a54b9":"markdown","208ee4cc":"markdown","377fdd7d":"markdown","c24f41a7":"markdown","78bb34c8":"markdown","e881136e":"markdown","67e8f45f":"markdown","1281b6c6":"markdown","cb4f468b":"markdown","fa4bc776":"markdown","b9ca2c3a":"markdown","003d94a3":"markdown","13ba6de1":"markdown","9b89d35d":"markdown","066f8565":"markdown","68c4d4c3":"markdown","9e3a807a":"markdown","25f49dcd":"markdown","eab8b080":"markdown","a801f9d5":"markdown","cec9a15b":"markdown","b43446c3":"markdown","e4a0b99a":"markdown","e6980a9d":"markdown","b096abb7":"markdown","779e7f87":"markdown","168894e9":"markdown","f3813f3d":"markdown","247ea43c":"markdown","56fcbc52":"markdown","136fc74e":"markdown","0b7c233c":"markdown","115bb573":"markdown","b7ed667a":"markdown","f4c13154":"markdown","55f7c50b":"markdown","86495d5b":"markdown","13500afd":"markdown","e57ae187":"markdown","f266b8d5":"markdown","e42821de":"markdown","11f93917":"markdown","88d72106":"markdown","78c2c0e8":"markdown","076519dc":"markdown","4b7c42c0":"markdown","18feac50":"markdown","19c941eb":"markdown","cdf058f9":"markdown","4c24d0e5":"markdown","49600769":"markdown","94c0ff23":"markdown","c0a3efe2":"markdown","cc486ec4":"markdown","fae8b305":"markdown","96844b8c":"markdown","c30a2e21":"markdown","0da42ee5":"markdown","72a0e1ce":"markdown","1be2b477":"markdown","fd70f6fa":"markdown","57a6d2aa":"markdown","7715f9b7":"markdown","4bd967fb":"markdown","859d3a16":"markdown","0468253d":"markdown","2bcccab5":"markdown","473757cf":"markdown","3007d4c8":"markdown","95a047b5":"markdown","1e172cef":"markdown","790a7f5e":"markdown","1d9dd255":"markdown","82286df0":"markdown","efa31081":"markdown","6c7d6d11":"markdown","e31ec717":"markdown","fc9a2ed0":"markdown","e2b40a26":"markdown","a50e0a2c":"markdown","9a37e9e3":"markdown","936216d2":"markdown","a2b19406":"markdown","adb371d7":"markdown","bb22bc22":"markdown","f0942ae1":"markdown","922e0d6b":"markdown","4fdaf226":"markdown","cb38ec2e":"markdown","a4de7a49":"markdown","ef773b9d":"markdown","47d2fb6b":"markdown","582bb3dc":"markdown","2bc88454":"markdown","d64cf85d":"markdown","bdeaa48b":"markdown","ee7d3d32":"markdown","b3a2fb85":"markdown","c71c459c":"markdown","ea44e419":"markdown","caa41e54":"markdown","b822f74e":"markdown","f0767b14":"markdown","3af159f3":"markdown","e33ece93":"markdown","54289b1e":"markdown","230d6180":"markdown","c60e9206":"markdown","c4aa759d":"markdown","31100da3":"markdown","7108823c":"markdown","12f4716b":"markdown","65c96d9b":"markdown","125f7411":"markdown","5618f373":"markdown","7e002295":"markdown","76caeaa8":"markdown","5d36c0a8":"markdown","30fcf267":"markdown","7a3c57d1":"markdown","e71acde8":"markdown","f09eb0ce":"markdown","a9bab5fc":"markdown"},"source":{"513ab30b":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nfrom matplotlib_venn import venn2, venn3\n\n\nimport missingno as msno  #utilizamos para graficar valores missings\n%matplotlib inline\nimport decimal\nfrom scipy.stats import chi2_contingency\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import preprocessing\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\nfrom math import sqrt\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import  cross_val_score\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn import metrics\nfrom sklearn.ensemble import BaggingClassifier\n\nfrom flask import Flask, make_response, request\nimport io\nfrom io import StringIO\nimport pickle\nimport csv","d8020ff4":"import warnings \n\nwarnings.filterwarnings('ignore')","10501e05":"metabric = pd.read_csv('METABRIC_RNA_Mutation_f.csv', sep=';')\n\nprint(metabric.shape)  #se obtiene el tama\u00f1o del conjunto\nmetabric.head(3) #previsualizaci\u00f3n de los datos cargados","7dd4c687":"#Breve descripci\u00f3n de las variables que conforman nuestro dataset\n\nmetabric.info(memory_usage = \"deep\")","6aea14c6":"def downcast(df):\n    for column in df: \n        #iteramos el dataset \n         if df[column].dtype == 'float64': #si el tipo de variable es float64, lo convertir\u00e1 a float32\n                df[column]=pd.to_numeric(df[column], downcast='float')\n                if df[column].dtype == 'int64': #mismo escenario pero para enteros\n                    df[column]=pd.to_numeric(all_data[column], downcast='integer')\n    ","1d3ca439":"downcast(metabric)","1ec98d5a":"msno.bar(metabric, figsize=(15,20), color=(0.2, 0.4, 0.6), fontsize=14)","20d87c15":"null_list = metabric.isnull().sum() #se crea una lista con los valores nulos de cada variable","c7f98025":"# Se obtiene la cantidad de valores nulos de la variable tumor_stage.\nnull_list['tumor_stage']","5a026b12":"for i in metabric:\n    #print(i)\n    metabric[i].value_counts()","9aa1b480":"metabric['mutation_count'] = metabric['mutation_count'].fillna(metabric['mutation_count'].mean())\nmetabric['tumor_size'] = metabric['tumor_size'].fillna(metabric['tumor_size'].mean())\n\nmetabric['tumor_stage'] = metabric['tumor_stage'].fillna(metabric['tumor_stage'].mode()[0])\nmetabric['death_from_cancer'] = metabric['death_from_cancer'].fillna(metabric['death_from_cancer'].mode()[0])\nmetabric['3-gene_classifier_subtype'] = metabric['3-gene_classifier_subtype'].fillna(metabric['3-gene_classifier_subtype'].mode()[0])\nmetabric['oncotree_code'] = metabric['oncotree_code'].fillna(metabric['oncotree_code'].mode()[0])\nmetabric['primary_tumor_laterality'] = metabric['primary_tumor_laterality'].fillna(metabric['primary_tumor_laterality'].mode()[0])\nmetabric['tumor_other_histologic_subtype'] = metabric['tumor_other_histologic_subtype'].fillna(metabric['tumor_other_histologic_subtype'].mode()[0])\nmetabric['neoplasm_histologic_grade'] = metabric['neoplasm_histologic_grade'].fillna(metabric['neoplasm_histologic_grade'].mode()[0])\nmetabric['er_status_measured_by_ihc'] = metabric['er_status_measured_by_ihc'].fillna(metabric['er_status_measured_by_ihc'].mode()[0])\nmetabric['tumor_other_histologic_subtype'] = metabric['tumor_other_histologic_subtype'].fillna(metabric['tumor_other_histologic_subtype'].mode()[0])\nmetabric['cellularity'] = metabric['cellularity'].fillna(metabric['cellularity'].mode()[0])\nmetabric['cancer_type_detailed'] = metabric['cancer_type_detailed'].fillna(metabric['cancer_type_detailed'].mode()[0])\nmetabric['type_of_breast_surgery'] = metabric['type_of_breast_surgery'].fillna(metabric['type_of_breast_surgery'].mode()[0])","bbb46abb":"## Edad: Se itera cada uno de los registros utilizando *lambda* para convertir a entero.\n\nmetabric['age_at_diagnosis'] = metabric['age_at_diagnosis'].apply(lambda x : int(x))  ","b893774e":"m6 = metabric[metabric['patient_id']==6]\nm6['overall_survival_months']","879204b3":"m0 = metabric[metabric['patient_id']==0]\nm0['overall_survival_months']","fecb8eb4":"#si la longitud de la variable es mayor a 13, entonces que tome los 4 primeros caracteres, caso contrario se deja el valor sin modificarlo\nmetabric['overall_survival_months'] = metabric['overall_survival_months'].map(lambda x: x[:4] if (len(x) >= 13) else x) \n#si la longitud de la variable que hemos guardado en el paso previo es igual a 4, se reemplaza el '.' sin dejar espacios, caso contrario se deja el valor sin modificarlos\nmetabric['overall_survival_months'] = metabric['overall_survival_months'].map(lambda x: x.replace(\".\", \"\") if (len(x) == 4) else x)\n#se convierte el valor a float\nmetabric['overall_survival_months'] = metabric['overall_survival_months'].map(lambda x: float(x))","e8fa00b6":"metabric['relapse_free_months'] = metabric['relapse_free_months'].map(lambda x: float(x))","3ae2d750":"metabric['overall_survival_years'] = metabric['overall_survival_months'].map(lambda x: x\/12)\nmetabric['relapse_free_years'] = metabric['relapse_free_months'].map(lambda x: x\/12)","d2663bce":"m6 = metabric[metabric['patient_id']==6]\nm6['overall_survival_months']","5b5ae892":"m0 = metabric[metabric['patient_id']==0]\nm0['overall_survival_months']","e2cd6500":"m6218 = metabric[metabric['patient_id']==6218]\nm6218['brca1']","1976773a":"#si la longitud de la variable es mayor a 6, entonces que tome el primer caracter,sino deja el valor original\n\nmetabric['nottingham_prognostic_index'] = metabric['nottingham_prognostic_index'].map(lambda x: x[:1] if (len(x) >=6 ) else x)#se convierte el valor a float\nmetabric['nottingham_prognostic_index'] = metabric['nottingham_prognostic_index'].apply(lambda x : float(x))","3f619a9a":"integer = metabric.loc[:,'brca1':'apc'].select_dtypes(include= ['object']).columns \n\nfor col in integer:\n    metabric[col] = metabric[col].map(lambda x: x[:4] if (len(x) >= 6) else x)\n    metabric[col] =metabric[col].map(lambda x: float(x))","f00e0a37":"m6218 = metabric[metabric['patient_id']==6218]\nm6218['brca1']","3bb96a8a":"metabric.describe()","cb952d5a":"#guardo en metabric_cat las variables de tipo objeto para convertirlas a categoricas\nmetabric_cat = metabric.select_dtypes(include=['object']).columns.tolist()  \n#se utiliza T para realizar una transpuesta, y dejar las variables como \u00edndice\nmetabric[metabric_cat].astype('category').describe().T ","06d85d84":"sns.set(font_scale = 1)\n#Seteo un fondo blanco\nsns.set_style(style='whitegrid')\n#Tom\u00e9 esta paleta de colores que contiene una gama de rosados, ya que es el color que est\u00e1 identificado para el cancer de mama\nsequential_colors = sns.color_palette(\"RdPu\", 6)","c51835d3":"from IPython.core.display import HTML\nHTML(\"\"\"\n<style>\n.output_png {\n    display: table-cell;\n    text-align: center;\n    vertical-align: middle;\n}\n<\/style>\n\"\"\")","a694be63":"plt.figure(figsize=(12,6)) #se define el tama\u00f1o del gr\u00e1fico\n#se utiliza un histograma para graficar la edad\nsns.distplot(metabric['age_at_diagnosis'],color='darkred') \nplt.xlabel('Edad diagn\u00f3stico')","fcd4a425":"#Utilizo countplot para representar la variable categ\u00f3rica\nsns.countplot(x=\"type_of_breast_surgery\", data=metabric, palette =sequential_colors)\n\n#Seteo los labels de los ejes\nplt.xlabel('Tipo de cirug\u00eda')\nplt.ylabel('Cantidad de pacientes')","fcde2dc3":"metabric['type_of_breast_surgery'].value_counts()","21dcfd59":"sns.countplot(y=\"cancer_type_detailed\", data=metabric, palette =sequential_colors)\nplt.xlabel('Cantidad de pacientes')\nplt.ylabel('Tipo de cancer')","0f6a33e0":"# Ordeno los valores de mayor a menor, para lograr una mejor visualizaci\u00f3n\n\nsns.countplot(y=\"cancer_subtype\",  data=metabric, palette = sequential_colors,order = metabric['cancer_subtype'].value_counts().index)\nplt.xlabel('Cantidad de pacientes')","4f581b79":"sns.countplot(x=\"death_from_cancer\", data=metabric, palette =sequential_colors)\nplt.ylabel('Cantidad de pacientes')\nplt.xlabel('Causa de muerte')","a706e3b6":"metabric['death_from_cancer'].value_counts()","9d1704db":"#se utiliza 'hue' para estratificar el gr\u00e1fico, en este caso por el estado de recidiva\nc = sns.relplot(x=\"age_at_diagnosis\", y=\"overall_survival_years\",hue=\"relapse_free_status\", data=metabric, palette = \"ch:r=-.1,l=.70\")\nc._legend.set_title('Estado recidiva')\nplt.xlabel('Edad diagnosis')\nplt.ylabel('A\u00f1os supervivencia')","ddc87357":"metabric['relapse_free_status'].value_counts()","ec7df326":"c = sns.catplot(x=\"relapse_free_status\", y=\"age_at_diagnosis\", hue=\"death_from_cancer\", kind=\"bar\", data=metabric,palette = sequential_colors)\nc._legend.set_title('Causa muerte')\nplt.xlabel('\u00cdndice de recidiva')\nplt.ylabel('Edad diagn\u00f3stico')","588e66cc":"sns.boxplot(y=\"cancer_type_detailed\", x=\"age_at_diagnosis\", data=metabric, palette = sequential_colors)\nplt.xlabel('Edad diagn\u00f3stico')\nplt.ylabel('Tipo de c\u00e1ncer')","5b5b805d":"sns.catplot(y=\"tumor_other_histologic_subtype\", x=\"overall_survival_years\", data=metabric, palette = sequential_colors)\n\nplt.xlabel('A\u00f1os supervivencia')\nplt.ylabel('Histolog\u00eda del tumor')","7a970054":"sns.catplot(y=\"tumor_other_histologic_subtype\", x=\"relapse_free_years\", data=metabric, palette = sequential_colors)\n\nplt.xlabel('A\u00f1os reincidencia')\nplt.ylabel('Histolog\u00eda del tumor')","9267f702":"sns.violinplot(x='tumor_other_histologic_subtype', y=\"tumor_size\", data=metabric,palette = sequential_colors)\n#Utilizo una rotaci\u00f3n en los labels del eje x\nplt.xticks(rotation=45)\n\nplt.ylabel('Tama\u00f1o tumor (mm)')\nplt.xlabel('Histolog\u00eda del tumor')","be44aa1c":"sns.barplot(y=\"tumor_other_histologic_subtype\", x=\"neoplasm_histologic_grade\", data=metabric, palette = sequential_colors)\n\nplt.xlabel('Estad\u00edo del tumor')\nplt.ylabel('Histolog\u00eda del tumor')","796a97db":"sns.barplot(y=\"tumor_other_histologic_subtype\", x=\"nottingham_prognostic_index\", data=metabric, palette = sequential_colors)\n\nplt.xlabel('\u00cdndice de Nottingham')\nplt.ylabel('Histolog\u00eda del tumor')","c06f4e6d":"plt.figure(figsize=(12,6))\nsns.boxplot(y=\"cancer_type_detailed\", x= 'nottingham_prognostic_index',hue=\"inferred_menopausal_state\", data=metabric,palette = sequential_colors)\n\nplt.xlabel('\u00cdndice de Nottinhgam')\nplt.ylabel('Tipo c\u00e1ncer')","059a0854":"c = sns.relplot( x=\"brca2\", y=\"age_at_diagnosis\",hue = 'relapse_free_status',data=metabric, palette = 'ch:r=-.1,l=.70')\nc._legend.set_title('\u00cdndice de recidiva')\nplt.xlabel('Gen BRCA2')\nplt.ylabel('Edad diagn\u00f3stico')","04a98724":"c = sns.relplot( x=\"brca1\", y=\"age_at_diagnosis\",hue = 'relapse_free_status',data=metabric, palette = 'ch:r=-.1,l=.70')\nc._legend.set_title('\u00cdndice de recidiva')\nplt.xlabel('Gen BRCA1')\nplt.ylabel('Edad diagn\u00f3stico')","0a0be44c":"sns.countplot(y=\"cancer_type_detailed\", hue='overall_survival', data=metabric, palette =sequential_colors )\nplt.xlabel('Cantidad Pacientes')\nplt.ylabel('Tipo de c\u00e1ncer')","a6183406":"sns.countplot(x=\"cancer_subtype\", hue=\"overall_survival\", data=metabric,palette = sequential_colors)\n\nplt.xlabel('Subtipo')\nplt.ylabel('Cantidad Pacientes')","ce6d86bb":"sns.countplot(x=\"relapse_free_status\", hue=\"overall_survival\", data=metabric,palette = sequential_colors)\n\nplt.xlabel('\u00cdndice de Recidiva')\nplt.ylabel('Cantidad Pacientes')","4728d2c3":"sns.countplot(x=\"inferred_menopausal_state\",  hue=\"overall_survival\", data=metabric, palette = sequential_colors)\n\nplt.xlabel('Estado menopausico')\nplt.ylabel('Cantidad Pacientes')","0ddeaca4":"plt.figure(figsize=(12,6))\nsns.distplot(metabric['age_at_diagnosis'][metabric['overall_survival']==0], color='g', label = 'survived')\nsns.distplot(metabric['age_at_diagnosis'][metabric['overall_survival']==1], color='r', label = 'died')\nplt.xlabel('Edad diagn\u00f3stico')\nplt.legend(loc='best')","28f55948":"plt.figure(figsize=(12,6))\nsns.distplot(metabric['relapse_free_years'][metabric['overall_survival']==0], color='g', label = 'survived')\nsns.distplot(metabric['relapse_free_years'][metabric['overall_survival']==1], color='r', label = 'died')\nplt.xlabel('A\u00f1os de recidiva')\nplt.legend(loc='best')","d80eb840":"\nplt.figure(figsize=(12,6))\nsns.distplot(metabric_['tp53'][metabric_['cancer_subtype']==1], color='g', label = 'LumA')\nsns.distplot(metabric_['tp53'][metabric_['cancer_subtype']==2], color='r', label = 'LumB')\nsns.distplot(metabric_['tp53'][metabric_['cancer_subtype']==3], color='b', label = 'Her2')\n\nsns.distplot(metabric_['tp53'][metabric_['cancer_subtype']==5], color='y', label = 'Basal')\n\nplt.xlabel('TP53')\nplt.legend(loc='best')","f3690957":"plt.figure(figsize=(12,6))\nsns.distplot(metabric_['ki67'][metabric_['cancer_subtype']==1], color='g', label = 'LumA')\nsns.distplot(metabric_['ki67'][metabric_['cancer_subtype']==2], color='r', label = 'LumB')\nsns.distplot(metabric_['ki67'][metabric_['cancer_subtype']==3], color='b', label = 'Her2')\n\nsns.distplot(metabric_['ki67'][metabric_['cancer_subtype']==5], color='y', label = 'Basal')\n\nplt.xlabel('KI67')\nplt.legend(loc='best')","4ac78bdd":"sns.barplot(x=\"overall_survival\", y=\"lymph_nodes_examined_positive\", data=metabric, palette = sequential_colors)\n\nplt.xlabel('Overall Survival')\nplt.ylabel('Ganglios linf\u00e1ticos positivos')","18d02b2b":"sns.countplot(x=\"chemotherapy\",  hue=\"overall_survival\", data=metabric, palette = sequential_colors)\n\nplt.xlabel('Quimioterapia')\nplt.ylabel('Cantidad Pacientes')","5f8e9b1d":"sns.countplot(x=\"hormone_therapy\",  hue=\"overall_survival\", data=metabric, palette = sequential_colors)\n\nplt.xlabel('Hormonaterapia')\nplt.ylabel('Cantidad Pacientes')","e2cb5ead":"sns.countplot(x=\"radio_therapy\",  hue=\"overall_survival\", data=metabric, palette = sequential_colors)\nplt.xlabel('Radioterapia')\nplt.ylabel('Cantidad Pacientes')","a09abaeb":"chemo = metabric[(metabric[\"chemotherapy\"]==1) & (metabric[\"radio_therapy\"]==0) & (metabric[\"hormone_therapy\"]==0)]\nradio = metabric[(metabric[\"chemotherapy\"]==0) & (metabric[\"radio_therapy\"]==1) & (metabric[\"hormone_therapy\"]==0)]\nhormonal = metabric[(metabric[\"chemotherapy\"]==0) & (metabric[\"radio_therapy\"]==0) & (metabric[\"hormone_therapy\"]==1)]\nchemo_radio = metabric[((metabric[\"chemotherapy\"]==1) & (metabric[\"radio_therapy\"]==1)) & (metabric[\"hormone_therapy\"]==0)]\nradio_hormonal = metabric[(metabric[\"chemotherapy\"]==0) & ((metabric[\"radio_therapy\"]==1) & (metabric[\"hormone_therapy\"]==1))]\nhormonal_chemo = metabric[((metabric[\"chemotherapy\"]==1) & (metabric[\"hormone_therapy\"]==1)) & (metabric[\"radio_therapy\"]==0) ]\nall_3 = metabric[((metabric[\"chemotherapy\"]==1) & (metabric[\"radio_therapy\"]==1) & (metabric[\"hormone_therapy\"]==1))]\n\n'''\nEl orden de los tratamientos se modifica debido a que, dependiendo el orden es como se grafica el diagrama de Venn,\npor ejemplo, supongamos los siguientes valores:\n\nvalor=[1,2,3,4,5,6,7]\netiquetas=A,B,C\n\nCon lo cual:\n\nA=1,B=2,A \u2229 B=3, C=4, A\u2229C =5, B\u2229C =6, A\u2229B\u2229C = 7\n'''\n\ntratamientos = [chemo, radio, chemo_radio,hormonal, hormonal_chemo, radio_hormonal,all_3]","5a73e610":"'''\nSe crea una lista con las variables obtenidas previamente,y\nse declaran dos listas vac\u00edas.\n'''\nsizes=[]\nproportiondeath=[]\n\n\nfor i in tratamientos:\n    sizes.append(np.shape(i)[0])\n    #proportiondeath.append(np.mean(i[\"overall_survival\"]))","f464b220":"plt.subplots(figsize=(8,6))\n\n#con alfa, se indica el grado de transparencia\n\nvenn3(subsets=sizes, set_labels=(\"Quimio\", \"Radio \", \"Hormonal\"),  alpha=0.2, set_colors= sequential_colors)\n    \nplt.show()","98ca6857":"metabric_ =  pd.DataFrame.copy(metabric, deep = True)","28586f05":"#Se utiliza get_dummies para la variable 'cancer_type_detailed' y se procede a borrar la variable original\n\ncancer_type = pd.get_dummies(metabric['cancer_type_detailed']).astype(int) \n#dado que cancer_type es un dataframe, hay que concatenar con el resto del conjunto\nmetabric_ = pd.concat([metabric_,cancer_type], axis=1)\n#Borro la variable original\nmetabric_.drop(['cancer_type_detailed'], axis=1, inplace=True)","c32ad177":"#type_of_breast_surgery\n\nmetabric_.type_of_breast_surgery.replace(('MASTECTOMY','BREAST CONSERVING'),(1,2),inplace=True)\n\n#cancer_type\n\nmetabric_.cancer_type.replace(('Breast Cancer','Breast Sarcoma'),(1,2),inplace=True)\n\n#cellularity\n\nmetabric_.cellularity.replace(('High','Moderate','Low'),(2,1,0),inplace=True)\n\n#cancer_subtype\n\nmetabric_.cancer_subtype.replace(('LumA','LumB','Her2','claudin-low','Basal','Normal','NC'),\n                                             (1,2,3,4,5,6,7),inplace=True)\n#er_status_measured_by_ihc\n\nmetabric_.er_status_measured_by_ihc.replace(('Positve','Negative'),(1,0),inplace=True)\n\n#er_status\n\nmetabric_.er_status.replace(('Positive','Negative'),(1,0),inplace=True)\n\n#her2_status_measured_by_snp6\n\nmetabric_.her2_status_measured_by_snp6.replace(('NEUTRAL','LOSS','GAIN','UNDEF'),(1,0,2,3),inplace=True)\n\n#her2_status\n\nmetabric_.her2_status.replace(('Positive','Negative'),(1,0),inplace=True)\n\n#tumor_other_histologic_subtype\n\nmetabric_.tumor_other_histologic_subtype.replace(('Ductal\/NST','Mixed','Lobular','Medullary','Mucinous','Tubular\/ cribriform',\n                                                'Other','Metaplastic')\n                                                ,(1,2,3,4,5,6,7,8),inplace=True)\n#inferred_menopausal_state\n\nmetabric_.inferred_menopausal_state.replace(('Post','Pre'),(1,0),inplace=True)\n\n#integrative_cluster     \n\n##4ER+ = 4\n##4ER- = 0\n\nmetabric_['integrative_cluster'] = np.where((metabric_['integrative_cluster'] == '4ER+'), 4, metabric_['integrative_cluster'])\nmetabric_['integrative_cluster'] = np.where((metabric_['integrative_cluster'] == '4ER-'), 0, metabric_['integrative_cluster'])\nmetabric_['integrative_cluster'] = metabric_['integrative_cluster'].astype('int')\n\n#primary_tumor_laterality\n\nmetabric_.primary_tumor_laterality.replace(('Left','Right'),(1,2),inplace=True)\n\n#pr_status\n\nmetabric_.pr_status.replace(('Positive','Negative'),(1,0),inplace=True)\n\n#3-gene_classifier_subtype\n\nmetabric_['gene3_classifier_subtype'] = metabric_['3-gene_classifier_subtype']\nmetabric_.gene3_classifier_subtype.replace(('ER+\/HER2- Low Prolif','ER+\/HER2- High Prolif','ER-\/HER2-','HER2+'),(1,2,3,4),inplace=True)\n","e0daea61":"metabric_.drop(['3-gene_classifier_subtype','oncotree_code','relapse_free_months','overall_survival_months','death_from_cancer'], axis=1, inplace=True)","5ed9771c":"def cramers_V(var1,var2): \n    '''Se crea una crosstab con las dos variables que se pasan por argumento'''\n    crosstab =np.array(pd.crosstab(var1,var2, rownames=None, colnames=None)) \n    '''Aplico el test de chi2 para evaluar la independencia de las variables'''\n    stat = chi2_contingency(crosstab)[0] \n    '''Numero de observaciones'''\n    obs = np.sum(crosstab)\n    '''Toma el m\u00ednimo valor entre las columnas y las filas de la crosstable'''\n    mini = min(crosstab.shape)-1 \n    return (stat\/(obs*mini))","991bffc8":"metabric_clinic_cramer = metabric_.drop(metabric_.loc[:,'brca1':'apc'], axis=1, inplace=False)\nmetabric_clinic_cramer.drop(['neoplasm_histologic_grade','tumor_stage','cohort','age_at_diagnosis','tumor_size','overall_survival_years','relapse_free_years'], axis=1, inplace=True)","b0f4213a":"rows= []\ni=0\nj=0\n'''itero el dataframe con las variables categ\u00f3ricas dos veces, ya que se ir\u00e1 comparando cada una de las variables'''\nfor i in metabric_clinic_cramer:\n    col = []\n    for j in metabric_clinic_cramer :\n        '''Aplico la funci\u00f3n declarada previamente donde compara cada una de las variables entre s\u00ed'''\n        cramers =cramers_V(metabric_clinic_cramer[i], metabric_clinic_cramer[j]) \n        '''Redondeo el valor a dos d\u00edgitos'''\n        col.append(round(cramers,2))\n    rows.append(col)","1daf8c63":"cramers_results = np.array(rows)\n'''Se crea un dataframe con los valores obtenidos y utilizo las variables del dataframe para crear el nuevo'''\ndf_cramer = pd.DataFrame(data=cramers_results, columns = metabric_clinic_cramer.columns, index =metabric_clinic_cramer.columns)","ec407ab5":"plt.figure(figsize=(16, 20))\nheatmap = sns.heatmap(df_cramer, vmin=-1, vmax=1, cmap='BrBG')\n\nheatmap.set_title('Correlaci\u00f3n entre variables cl\u00ednicas', fontdict={'fontsize':12}, pad=12);","ea8e7384":"metabric_gen = metabric.loc[:,'brca1':'apc']","d8df5996":"plt.figure(figsize=(16, 10))\nheatmap = sns.heatmap(metabric_gen.corr(), vmin=-1, vmax=1, cmap='BrBG')\nheatmap.set_title('Correlaci\u00f3n entre los genes', fontdict={'fontsize':18}, pad=16);","61ac5ea1":"#Creo la lista de genes\ngen_list = ['chek2','ki67','tp53','brca1']","8125168c":"# Escalado de valores solamente para los genes declarados en gen_list\n\nsc = StandardScaler()\ngen_scale = pd.DataFrame(sc.fit_transform(metabric_gen[gen_list]))\n#Renombro las columnas para que luego los gr\u00e1ficos se visualicen correctamente\ngen_scale.rename(columns = {0:'chek2',1:'ki67',2:'tp53',3:'brca1'}, inplace=True)\n#Agrego la variable objetivo a gen_scale\ngen_scale['overall_survival'] = metabric_['overall_survival']","dd82975f":"j=0\nfig = plt.figure(figsize = (20, 25))\n\n'''\nSe itera el dataframe a excepci\u00f3n de la \u00faltima columna\nque corresponde a la variable objetivo\n'''\nfor i in gen_scale.iloc[:,:-1].columns: \n    '''\n    Seteo la distribuci\u00f3n de los gr\u00e1ficos y declaro los labels y colores para cada uno de los valores\n    que asume la variable objetivo.\n    '''\n    plt.subplot(4, 2, j+1)  \n    j += 1 \n    sns.distplot(gen_scale[i][gen_scale['overall_survival']==0], color='g', label = 'survived', kde=False)\n    sns.distplot(gen_scale[i][gen_scale['overall_survival']==1], color='r', label = 'died', kde=False)\n    #Ubicaci\u00f3n de la leyenda\n    plt.legend(loc='best')\n    \n#Se a\u00f1ade un t\u00edtulo centrado al gr\u00e1fico    \nfig.suptitle('An\u00e1lisis de los genes con respecto a Overall Survival', fontsize=15)\n#fig.tight_layout()\nfig.subplots_adjust(top=0.95)\nplt.show()","b6ecfbba":"#Se crea una lista a partir de todas las columnas del dataset\nfeatures = list(metabric_.columns)\n#Aislo la variable objetivo del resto de las columnas\ntarget = 'overall_survival'\n#Quito la variable objetivo\nfeatures.remove('overall_survival')\n#Asigno a x_sv todo el dataframe sin ovverall_survival\nx_sv = metabric_[features]\n#Asigno en y_sv solamente overall_survival\ny_sv = metabric_[target]","9be6ac99":"#Se setea un umbral que luego servir\u00e1 para seleccionar las variables de mayor importancia\nvar_th = VarianceThreshold(threshold=0.40)\n#Se aplica el umbral al conjunto guardado en x_sv\nx_var = var_th.fit_transform(x_sv)","892f5d87":"#Listado de las variables\nprint('La cantidad de variables que posee varianza alta es:', x_var.shape[1])\nnp.asarray(list(x_sv))[var_th.get_support()]","b32463d9":"x_sv = x_sv[np.asarray(list(x_sv))[var_th.get_support()]]","37444d0f":"print('La cantidad de pacientes que sobrevive es: ', metabric_[metabric_['overall_survival'] == 1].shape[0])\nprint('La cantidad de pacientes que no sobrevive es: ', metabric_[metabric_['overall_survival'] == 0].shape[0])","6daa65ba":"metabric_.drop(['patient_id'], axis=1, inplace=True)","1b4b15fa":"downcast(metabric_)","40f5dac2":"'''\nLa variable X contendr\u00e1 todo el conjunto de datos menos la variable objetiva,\ny almacenar\u00e1 la variable objetivo.\n'''\n\nX = metabric_.drop([\"overall_survival\"], axis=1)\ny = metabric_[\"overall_survival\"]\n\n'''Guardo en metabric_num las variables de tipo num\u00e9ricas para utilizarlo en el escalado.'''\nmetabric_num = X.select_dtypes(include=['int64','int32','float32']).columns.tolist()  \n\n\n#En este caso, se aplica una semilla para poder reproducir el c\u00e1lculo y obtener los mismos valores\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nprint('El tama\u00f1o del conjunto de entrenamiento es: ', X_train.shape)\nprint('El tama\u00f1o del conjunto de entrenamiento es: ', X_test.shape)","198aa3d8":"#Se crea el escalador, dejando los par\u00e1metros por defecto\nscaler = StandardScaler()\n#Se ajusta el escalador pasando los datos de entrenamiento, y adem\u00e1s transforma los datos\nX_train[metabric_num] =  scaler.fit_transform(X_train[metabric_num])\n#Se aplica misma l\u00f3gica para el conjunto de test, ya que los datos tienen que ser consistentes\nX_test[metabric_num] = scaler.fit_transform(X_test[metabric_num])","588dde0c":"#En este caso, se aplica una semilla para poder reproducir el c\u00e1lculo y obtener los mismos valores\nX_train_sv, X_test_sv, y_train_sv, y_test_sv = train_test_split(x_sv, y_sv, test_size=0.2, random_state=42)\n\nprint('El tama\u00f1o del conjunto de entrenamiento es: ', X_train_sv.shape)\nprint('El tama\u00f1o del conjunto de entrenamiento es: ', X_test_sv.shape)","d9a40c09":"downcast(x_sv)","50c9f46d":"metabric_num_sv = x_sv.select_dtypes(include=['float32','int64','int32']).columns.tolist()  #guardo en metabric_cat las variables de tipo objeto para convertirlas a categoricas]#se utiliza T para realizar una transpuesta, y dejar las variables como \u00edndice","badef168":"#Se crea el escalador, dejando los par\u00e1metros por defecto\nscaler = StandardScaler()\n#Se ajusta el escalador pasando los datos de entrenamiento, y adem\u00e1s transforma los datos\nX_train_sv[metabric_num_sv] =  scaler.fit_transform(X_train_sv[metabric_num_sv])\n#Se aplica misma l\u00f3gica para el conjunto de test, ya que los datos tienen que ser consistentes\nX_test_sv[metabric_num_sv] = scaler.fit_transform(X_test_sv[metabric_num_sv])","c8caa50f":"kfold = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)","67e52e9c":"#Inicializo las variables de tipo lista que ir\u00e9 a utilizar.\nacc_train = []\nacc_test = []\nmodel = []","d8a7a0ef":"def metricas(y_test, y_pred, y_train, models, X_train, X_test):\n    conf_matrix = confusion_matrix(y_test, y_pred)\n    plt.figure(figsize=(10, 5))\n    sns.heatmap(conf_matrix, annot=True, fmt=\"d\");\n    plt.title(\"Matriz confusi\u00f3n\")\n    plt.ylabel('Clase real')\n    plt.xlabel('Clase predicha')\n    plt.show()\n    \n    metrics.plot_roc_curve(models, X_test, y_test)\n\n    '''\n    Tambi\u00e9n se a\u00f1aden a listas vac\u00edas los resultados de cada uno de los modelos para \n    realizar una comparaci\u00f3n posterior.    \n    Con append, se va insertando los valores a nuestra lista vac\u00eda.\n    '''\n    model.append(models)\n    acc_train.append(accuracy_score(y_train, models.predict(X_train)))\n    acc_test.append(accuracy_score(y_test, y_pred))\n    \n    print (classification_report(y_test, y_pred))\n    print('El accuracy para el conjunto de entrenamiento es de :', accuracy_score(y_train, models.predict(X_train)))\n    print('El accuracy para el conjunto de testing es de :', accuracy_score(y_test, y_pred))","a131056d":"def metricas_redes(y_test, y_pred, y_train, models, X_train):\n    conf_matrix = confusion_matrix(y_test, y_pred)\n    plt.figure(figsize=(10, 5))\n    sns.heatmap(conf_matrix, annot=True, fmt=\"d\");\n    plt.title(\"Matriz confusi\u00f3n\")\n    plt.ylabel('Clase real')\n    plt.xlabel('Clase predicha')\n    plt.show()\n    \n\n    '''\n    Tambi\u00e9n se a\u00f1aden a listas vac\u00edas los resultados de cada uno de los modelos para \n    realizar una comparaci\u00f3n posterior.    \n    Con append, se va insertando los valores a nuestra lista vac\u00eda.\n    '''\n    model.append(models)\n    acc_train.append(accuracy_score(y_train, models.predict_classes(X_train)))\n    acc_test.append(accuracy_score(y_test, y_pred))\n    \n    print (classification_report(y_test, y_pred))\n    print('El accuracy para el conjunto de entrenamiento es de :', accuracy_score(y_train, models.predict_classes(X_train)))\n    print('El accuracy para el conjunto de testing es de :', accuracy_score(y_test, y_pred))\n    ","891be147":"#Seteo una semilla para obtener siempre los mimos resultados\nmodel_RL = LogisticRegression(random_state=42)\n#Se entrena con los valores escalados\nmodel_RL.fit(X_train, y_train)\n#Se predice la variable objetiva con los datos de testing\ny_pred = model_RL.predict(X_test)\n\nmetricas(y_test, y_pred, y_train, model_RL, X_train, X_test)","aac045ff":"#Se setean los par\u00e1metros utilizados para RL\nmodel_RL = LogisticRegression(random_state=42)\n#Se entrena con los valores escalados\nmodel_RL.fit(X_train_sv, y_train_sv)\ny_pred_sv = model_RL.predict(X_test_sv)\n\nmetricas(y_test_sv, y_pred_sv, y_train_sv, model_RL, X_train_sv, X_test_sv)","6ce33ac1":"model_SVC = SVC(random_state=42)\nmodel_SVC.fit(X_train, y_train)\ny_pred = model_SVC.predict(X_test)\n\nmetricas(y_test, y_pred, y_train, model_SVC, X_train, X_test)","ecc0ff55":"model_NB = GaussianNB()\nmodel_NB.fit(X_train, y_train)\ny_pred = model_NB.predict(X_test)\n\nmetricas(y_test, y_pred, y_train, model_NB, X_train, X_test)","9ddfe7b7":"model_DT = DecisionTreeClassifier(random_state=42)\nmodel_DT.fit(X_train, y_train)\ny_pred = model_DT.predict(X_test)\n\nmetricas(y_test, y_pred, y_train, model_DT, X_train, X_test)","952a7468":"model_RF = RandomForestClassifier(random_state=42)\nmodel_RF.fit(X_train, y_train)\n\ny_pred = model_RF.predict(X_test)\n\nmetricas(y_test, y_pred, y_train, model_RF, X_train, X_test)","c23ff22c":"from numpy.random import seed\nseed(42)\n\n#Se declara un modelo de tipo secuencial\nmodel_RN = tf.keras.models.Sequential()\n#Se tienen 61 caracter\u00edsticas con lo cual, es la cantidad que tendr\u00e1 el input\nmodel_RN.add(tf.keras.Input(shape=(61,),name='input'))\n#Comienzo con 132 neuronas para la primera capa, y decido realizar una activaci\u00f3n de tipo relu\nmodel_RN.add(layers.Dense(132, activation='relu', name='layer1'))\n#Agrego una capa de Dropout para evitar el overfitting\nmodel_RN.add(layers.Dropout(0.7))\nmodel_RN.add(layers.Dense(64, activation='relu', name='layer2'))\n\n\n#La ultima capa es sigmoid ya que es un problema de clasificaicion binaria\nmodel_RN.add(layers.Dense(1,  name='output', activation='sigmoid'))  ","979a748c":"#Dado que es un problema de clasificaci\u00f3n binaria, utilizamos binary_cossentropy\nes_callback = keras.callbacks.EarlyStopping(  #aplico earlystopping para que el modelo se detenga cuando no haya mejora en la m\u00e9trica\n    monitor='accuracy',  \n    patience=30,  \n    verbose=1,\n    )\n\nmodel_RN.compile(optimizer='sgd',loss=['binary_crossentropy'],metrics=['accuracy'])   #quitamos accuracy ya que es una medida para problemas de clasificacion","720b271a":"model_RN.fit(X_train,y_train,epochs=300,batch_size=32, verbose=1,callbacks=[es_callback], shuffle=True)","01be6247":"results_test = model_RN.evaluate(X_test, y_test, verbose=1)\nresults_train = model_RN.evaluate(X_train, y_train, verbose=1)\nprint('M\u00e9tricas conjunto testing: {}'.format(results_test))\nprint('M\u00e9tricas conjunto entrenamiento: {}'.format(results_train))","dfe902f8":"y_pred = model_RN.predict_classes(X_test)\nmetricas_redes(y_test, y_pred, y_train, model_RN, X_train)","d605eae5":"model_XG = XGBClassifier(random_state=42,objective= 'binary:logistic')\nmodel_XG.fit(X_train, y_train)\n\ny_pred = model_XG.predict(X_test)\npredictions = [round(value) for value in y_pred]\n\nmetricas(y_test, predictions, y_train, model_XG, X_train, X_test)","bf32c2a7":"model_AB = AdaBoostClassifier(random_state=42)\nmodel_AB.fit(X_train, y_train)\n\ny_pred = model_AB.predict(X_test)\nmetricas(y_test, y_pred, y_train, model_AB, X_train, X_test)","7871f613":"params = {\n    \"penalty\": [\"l1\", \"l2\"],\n    \"C\": np.logspace(-2,4,100)\n    }\n\nmodel_grid = GridSearchCV(model_RL, param_grid=params, n_jobs=-1, cv=kfold)\nmodel_grid.fit(X_train, y_train)\nprint(model_grid.best_params_)","c032b7bf":"model_RL = LogisticRegression(C= 0.08111308307896872, penalty= 'l2',random_state=42)\nmodel_RL.fit(X_train, y_train)\ny_pred = model_RL.predict(X_test)\n\nmetricas(y_test, y_pred, y_train, model_RL, X_train, X_test)","1b6e43a7":"from sklearn.svm import SVC\n\nparam_grid = {'C': [0.1, 1, 10, 100, 1000], \n              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n              'kernel': ['rbf']} \n  \nmodel_grid = GridSearchCV(SVC(class_weight='balanced'), param_grid=param_grid, refit = True, verbose = 4,cv=kfold)\n\nmodel_grid.fit(X_train, y_train)\nprint(model_grid.best_params_)","518cd70f":"model_SVC = SVC(C= 1, gamma= 0.01, kernel= 'rbf', random_state=42,class_weight='balanced')\n\nmodel_SVC.fit(X_train, y_train)\ny_pred = model_SVC.predict(X_test)\n\nmetricas(y_test, y_pred, y_train, model_SVC, X_train, X_test)","dc211d8d":"param_grid = {\n    'criterion': ['gini', 'entropy'],\n    'max_depth' : range(1,10),\n    'min_samples_split': range(1,10),\n    'min_samples_leaf':range(1,10)\n}\n\n\nmodel_grid = GridSearchCV(DecisionTreeClassifier(class_weight='balanced'), param_grid=param_grid, scoring='accuracy',cv=kfold, n_jobs=-1)\n\nmodel_grid.fit(X_train, y_train)\nprint(model_grid.best_params_)","d2c762d2":"model_DT = DecisionTreeClassifier(class_weight='balanced',random_state=42,criterion= 'entropy', max_depth=6, min_samples_leaf= 9, min_samples_split= 2)\nmodel_DT.fit(X_train, y_train)\ny_pred = model_DT.predict(X_test)\n\nmetricas(y_test, y_pred, y_train, model_DT, X_train, X_test)","7bedf6e6":"grid_param = {\n    'n_estimators': [300, 500, 800, 1000],\n    'criterion': ['gini', 'entropy'],\n    'bootstrap': [True, False],\n}\n\nmodel_grid = GridSearchCV(estimator=RandomForestClassifier(random_state=42,class_weight='balanced'),param_grid=grid_param,scoring='accuracy',cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),n_jobs=-1)\n\nmodel_grid.fit(X_train, y_train)\nprint(model_grid.best_params_)","2b9bdaa1":"model_RF = RandomForestClassifier(bootstrap= False, criterion= 'entropy', n_estimators= 800, random_state=42,class_weight='balanced')\nmodel_RF.fit(X_train, y_train)\n\ny_pred = model_RF.predict(X_test)\n\nmetricas(y_test, y_pred, y_train, model_RF, X_train, X_test)\n","2b94e55f":"grid_param = {\n    'max_depth': range (2, 10, 1),\n    'n_estimators': range(60, 220, 40),\n    'learning_rate': [0.1, 0.01, 0.05]\n}\n\nmodel_grid = GridSearchCV(estimator=XGBClassifier(),param_grid=grid_param,cv=kfold,n_jobs=-1)\n\nmodel_grid.fit(X_train, y_train)\nprint(model_grid.best_estimator_)","c6206a17":"model_XG = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.05, max_delta_step=0, max_depth=3,\n              min_child_weight=1, monotone_constraints='()',\n              n_estimators=140, n_jobs=8, num_parallel_tree=1, random_state=42,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n              tree_method='exact', validate_parameters=1, verbosity=None)\n\nmodel_XG.fit(X_train, y_train)\n\ny_pred = model_XG.predict(X_test)\npredictions = [round(value) for value in y_pred]\n\nmetricas(y_test, predictions, y_train, model_XG, X_train, X_test)","7662b6a2":"grid_param = {\n    'n_estimators': [10, 50, 100, 500],\n    'learning_rate': [0.0001, 0.001, 0.01, 0.1, 1.0]\n}\n\nmodel_grid = GridSearchCV(estimator=AdaBoostClassifier(),param_grid=grid_param,cv=kfold,n_jobs=-1)\n\nmodel_grid.fit(X_train, y_train)\nprint(model_grid.best_estimator_)","80c4a221":"model_AB = AdaBoostClassifier(learning_rate=0.1, n_estimators=100, random_state=42)\nmodel_AB.fit(X_train, y_train)\n\ny_pred = model_AB.predict(X_test)\nmetricas(y_test, y_pred, y_train, model_AB, X_train, X_test)","c3b5eae2":"bc_params = {\"base_estimator__max_depth\": [3,5,10,20],\n          \"base_estimator__min_samples_leaf\": [1, 3, 5, 7, 10],\n          \"base_estimator__min_samples_split\": [2, 5, 7],\n          'n_estimators': [20,50,100,200]\n}\n\nmodel_grid = GridSearchCV(BaggingClassifier(DecisionTreeClassifier(class_weight='balanced',random_state=42)),bc_params,cv=kfold)\n\nmodel_grid.fit(X_train, y_train)\nprint(model_grid.best_estimator_)","f2ef1d5e":"model_BC = BaggingClassifier(DecisionTreeClassifier(max_depth=10,\n                                                        min_samples_split=7,class_weight='balanced'),\n                   n_estimators=100, random_state=42)\n\nmodel_BC.fit(X_train, y_train)\n\ny_pred = model_BC.predict(X_test)\nmetricas(y_test, y_pred, y_train, model_BC, X_train, X_test)","f54bf889":"metrics = pd.DataFrame({'Algoritmos':model, 'Accuracy Train': acc_train, 'Accuracy Test':acc_test})\nmetrics","2b490cbc":"metrabric_fe = pd.DataFrame.copy(metabric_, deep = True)","11667d55":"metrabric_fe['age_group'] = pd.cut(x=metrabric_fe['age_at_diagnosis'], bins=[30, 55, 65, 70, 80,100],\n                    labels=['Menor 30 a\u00f1os', '31-55 a\u00f1os', '56-65 a\u00f1os','66-70 a\u00f1os','Mayor 80'], include_lowest=True)","92c92cdf":"metrabric_fe['survival_group'] = pd.cut(x=metrabric_fe['overall_survival_years'], bins=[5, 10, 15, 80],\n                    labels=['5 a\u00f1os', '10-15 a\u00f1os', 'Mas de 20 a\u00f1os'], include_lowest=True)","78502e99":"metrabric_fe['relapse_group'] = pd.cut(x=metrabric_fe['relapse_free_years'], bins=[1, 5, 10, 15,80],\n                    labels=['2 a\u00f1os', '5-10 a\u00f1os', '11-15 a\u00f1os','Mas de 20 a\u00f1os'], include_lowest=True)","8f6208c2":"X_train_clinic = X_train.drop(X_train.loc[:,'brca1':'apc'].columns,axis=1)\nX_test_clinic = X_test.drop(X_test.loc[:,'brca1':'apc'].columns,axis=1)","f7a61da0":"model_BC = BaggingClassifier(DecisionTreeClassifier(max_depth=10,\n                                                        min_samples_split=7,class_weight='balanced'),\n                   n_estimators=100, random_state=42)\n\nmodel_BC.fit(X_train_clinic, y_train)\n\ny_pred = model_BC.predict(X_test_clinic)\nmetricas(y_test, y_pred, y_train, model_BC, X_train_clinic, X_test_clinic)","428dc434":"def modelo_existente():\n    import pandas as pd\n    from sklearn.preprocessing import StandardScaler\n    from sklearn.model_selection import train_test_split\n    from sklearn import metrics\n    from sklearn.preprocessing import LabelEncoder\n    from sklearn.model_selection import GridSearchCV\n    from sklearn.ensemble import BaggingClassifier\n    from sklearn.model_selection import StratifiedKFold\n    from sklearn.ensemble import BaggingClassifier\n    from sklearn.tree import DecisionTreeClassifier\n    import pickle\n    \n\n    dataset = pd.read_csv('METABRIC_RNA_Mutation_f.csv', sep=';')\n    '''\n    Mantengo estas transformaciones por si el usuario ingresa en un formato err\u00f3neo\n    '''\n    dataset['mutation_count'] = dataset['mutation_count'].fillna(dataset['mutation_count'].mean())\n    dataset['tumor_size'] = dataset['tumor_size'].fillna(dataset['tumor_size'].mean())\n\n    dataset['tumor_stage'] = dataset['tumor_stage'].fillna(dataset['tumor_stage'].mode()[0])\n    dataset['death_from_cancer'] = dataset['death_from_cancer'].fillna(dataset['death_from_cancer'].mode()[0])\n    dataset['3-gene_classifier_subtype'] = dataset['3-gene_classifier_subtype'].fillna(dataset['3-gene_classifier_subtype'].mode()[0])\n    dataset['oncotree_code'] = dataset['oncotree_code'].fillna(dataset['oncotree_code'].mode()[0])\n    dataset['primary_tumor_laterality'] = dataset['primary_tumor_laterality'].fillna(dataset['primary_tumor_laterality'].mode()[0])\n    dataset['tumor_other_histologic_subtype'] = dataset['tumor_other_histologic_subtype'].fillna(dataset['tumor_other_histologic_subtype'].mode()[0])\n    dataset['neoplasm_histologic_grade'] = dataset['neoplasm_histologic_grade'].fillna(dataset['neoplasm_histologic_grade'].mode()[0])\n    dataset['er_status_measured_by_ihc'] = dataset['er_status_measured_by_ihc'].fillna(dataset['er_status_measured_by_ihc'].mode()[0])\n    dataset['tumor_other_histologic_subtype'] = dataset['tumor_other_histologic_subtype'].fillna(dataset['tumor_other_histologic_subtype'].mode()[0])\n    dataset['cellularity'] = dataset['cellularity'].fillna(dataset['cellularity'].mode()[0])\n    dataset['cancer_type_detailed'] = dataset['cancer_type_detailed'].fillna(dataset['cancer_type_detailed'].mode()[0])\n    dataset['type_of_breast_surgery'] = dataset['type_of_breast_surgery'].fillna(dataset['type_of_breast_surgery'].mode()[0])\n    \n    dataset['age_at_diagnosis'] = dataset['age_at_diagnosis'].apply(lambda x : int(x))\n    dataset['overall_survival_months'] = dataset['overall_survival_months'].map(lambda x: x[:4] if (len(x) >= 13) else x) \n    dataset['overall_survival_months'] = dataset['overall_survival_months'].map(lambda x: x.replace(\".\", \"\") if (len(x) == 4) else x)\n    dataset['overall_survival_months'] = dataset['overall_survival_months'].map(lambda x: float(x))\n    dataset['relapse_free_months'] = dataset['relapse_free_months'].map(lambda x: float(x))\n    dataset['overall_survival_years'] = dataset['overall_survival_months'].map(lambda x: x\/12)\n    dataset['relapse_free_years'] = dataset['relapse_free_months'].map(lambda x: x\/12)\n    integer = dataset.loc[:,'brca1':'apc'].select_dtypes(include= ['object']).columns \n\n    for col in integer:\n        dataset[col] = dataset[col].map(lambda x: x[:4] if (len(x) >= 6) else x)\n        dataset[col] =dataset[col].map(lambda x: float(x))\n        \n    '''\n    Convierto cancer_type a dummies\n    '''\n    \n    cancer_type = pd.get_dummies(dataset['cancer_type_detailed']).astype(int) \n    dataset = pd.concat([dataset,cancer_type], axis=1)\n    dataset.drop(['cancer_type_detailed'], axis=1, inplace=True)\n    \n    '''\n    Convierto variables categ\u00f3ricas a num\u00e9ricas\n    '''\n    \n    dataset['nottingham_prognostic_index'] = dataset['nottingham_prognostic_index'].map(lambda x: x[:1] if (len(x) >=6 ) else x)#se convierte el valor a float\n    dataset['nottingham_prognostic_index'] = dataset['nottingham_prognostic_index'].apply(lambda x : float(x))\n    dataset.type_of_breast_surgery.replace(('MASTECTOMY','BREAST CONSERVING'),(1,2),inplace=True)\n    dataset.cancer_type.replace(('Breast Cancer','Breast Sarcoma'),(1,2),inplace=True)\n    dataset.cellularity.replace(('High','Moderate','Low'),(2,1,0),inplace=True)\n    dataset.cancer_subtype.replace(('LumA','LumB','Her2','claudin-low','Basal','Normal','NC'),\n                                                 (1,2,3,4,5,6,7),inplace=True)\n\n    dataset.er_status_measured_by_ihc.replace(('Positve','Negative'),(1,0),inplace=True)\n\n    dataset.er_status.replace(('Positive','Negative'),(1,0),inplace=True)\n    dataset.her2_status_measured_by_snp6.replace(('NEUTRAL','LOSS','GAIN','UNDEF'),(1,0,2,3),inplace=True)\n    dataset.her2_status.replace(('Positive','Negative'),(1,0),inplace=True)\n    dataset.tumor_other_histologic_subtype.replace(('Ductal\/NST','Mixed','Lobular','Medullary','Mucinous','Tubular\/ cribriform',\n                                                    'Other','Metaplastic'),(1,2,3,4,5,6,7,8),inplace=True)\n    \n    dataset.inferred_menopausal_state.replace(('Post','Pre'),(1,0),inplace=True)\n    dataset['integrative_cluster'] = np.where((dataset['integrative_cluster'] == '4ER+'), 4, dataset['integrative_cluster'])\n    dataset['integrative_cluster'] = np.where((dataset['integrative_cluster'] == '4ER-'), 0, dataset['integrative_cluster'])\n    dataset['integrative_cluster'] = dataset['integrative_cluster'].astype('int')\n    dataset.primary_tumor_laterality.replace(('Left','Right'),(1,2),inplace=True)\n    dataset.pr_status.replace(('Positive','Negative'),(1,0),inplace=True)\n    dataset['gene3_classifier_subtype'] = dataset['3-gene_classifier_subtype']\n    dataset.gene3_classifier_subtype.replace(('ER+\/HER2- Low Prolif','ER+\/HER2- High Prolif','ER-\/HER2-','HER2+'),(1,2,3,4),inplace=True)\n\n    dataset.drop(['patient_id','3-gene_classifier_subtype','oncotree_code','relapse_free_months','overall_survival_months','death_from_cancer'], axis=1, inplace=True)\n    \n    downcast(dataset)\n    \n    X = dataset.drop([\"overall_survival\"], axis=1)\n    y = dataset[\"overall_survival\"]\n\n    '''Guardo en metabric_num las variables de tipo num\u00e9ricas para utilizarlo en el escalado.'''\n    metabric_num = X.select_dtypes(include=['int64','int32','float32']).columns.tolist()  \n\n    kfold = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    \n    scaler = StandardScaler()\n    X_train[metabric_num] =  scaler.fit_transform(X_train[metabric_num])\n    X_test[metabric_num] = scaler.fit_transform(X_test[metabric_num])\n    \n    model_BC = BaggingClassifier(DecisionTreeClassifier(max_depth=10,\n                                                        min_samples_leaf=10, class_weight='balanced'),\n                  max_features=0.7, max_samples=0.7, n_estimators=100,\n                  random_state=42)\n    \n    model_BC.fit(X_train,y_train)\n    y_pred = model_BC.predict(X_test)\n    \n    filename = 'finalized_model.pkl'\n    pickle.dump(model_BC, open(filename, 'wb'))\n    \n    return filename   ","5e8be3e0":"def pipeline_modelo_nuevo(dataset):\n    import pandas as pd\n    from sklearn.preprocessing import StandardScaler\n    from sklearn.model_selection import train_test_split\n    from sklearn import metrics\n    from sklearn.preprocessing import LabelEncoder\n    from sklearn.model_selection import GridSearchCV\n    from sklearn.ensemble import BaggingClassifier\n    from sklearn.model_selection import StratifiedKFold\n    from sklearn.ensemble import BaggingClassifier\n    from sklearn.tree import DecisionTreeClassifier\n    \n    '''\n    Mantengo estas transformaciones por si el usuario ingresa en un formato err\u00f3neo\n    '''\n    \n    dataset['age_at_diagnosis'] = dataset['age_at_diagnosis'].apply(lambda x : int(x))\n    dataset['overall_survival_months'] = dataset['overall_survival_months'].map(lambda x: x[:4] if (len(x) >= 13) else x) \n    dataset['overall_survival_months'] = dataset['overall_survival_months'].map(lambda x: x.replace(\".\", \"\") if (len(x) == 4) else x)\n    dataset['overall_survival_months'] = dataset['overall_survival_months'].map(lambda x: float(x))\n    dataset['relapse_free_months'] = dataset['relapse_free_months'].map(lambda x: float(x))\n    dataset['overall_survival_years'] = dataset['overall_survival_months'].map(lambda x: x\/12)\n    dataset['relapse_free_years'] = dataset['relapse_free_months'].map(lambda x: x\/12)\n    #dataset['nottingham_prognostic_index'] = dataset['nottingham_prognostic_index'].map(lambda x: x[:1] if (len(x) >=6 ) else x)\n    #dataset['nottingham_prognostic_index'] = dataset['nottingham_prognostic_index'].map(lambda x : float(x))\n    \n    integer = dataset.loc[:,'brca1':'apc'].select_dtypes(include= ['object']).columns \n\n    for col in integer:\n        dataset[col] = dataset[col].map(lambda x: x[:4] if (len(x) >= 6) else x)\n        dataset[col] =dataset[col].map(lambda x: float(x))\n        \n    '''\n    Convierto variables categ\u00f3ricas a num\u00e9ricas\n    '''\n\n    dataset.type_of_breast_surgery.replace(('MASTECTOMY','BREAST CONSERVING'),(1,2),inplace=True)\n    dataset.cancer_type.replace(('Breast Cancer','Breast Sarcoma'),(1,2),inplace=True)\n    dataset.cellularity.replace(('High','Moderate','Low'),(2,1,0),inplace=True)\n    dataset.cancer_subtype.replace(('LumA','LumB','Her2','claudin-low','Basal','Normal','NC'),\n                                                 (1,2,3,4,5,6,7),inplace=True)\n\n    dataset.er_status_measured_by_ihc.replace(('Positve','Negative'),(1,0),inplace=True)\n\n    dataset.er_status.replace(('Positive','Negative'),(1,0),inplace=True)\n    dataset.her2_status_measured_by_snp6.replace(('NEUTRAL','LOSS','GAIN','UNDEF'),(1,0,2,3),inplace=True)\n    dataset.her2_status.replace(('Positive','Negative'),(1,0),inplace=True)\n    dataset.tumor_other_histologic_subtype.replace(('Ductal\/NST','Mixed','Lobular','Medullary','Mucinous','Tubular\/ cribriform',\n                                                    'Other','Metaplastic'),(1,2,3,4,5,6,7,8),inplace=True)\n    \n    dataset.inferred_menopausal_state.replace(('Post','Pre'),(1,0),inplace=True)\n    dataset['integrative_cluster'] = np.where((dataset['integrative_cluster'] == '4ER+'), 4, dataset['integrative_cluster'])\n    dataset['integrative_cluster'] = np.where((dataset['integrative_cluster'] == '4ER-'), 0, dataset['integrative_cluster'])\n    dataset['integrative_cluster'] = dataset['integrative_cluster'].astype('int')\n    dataset.primary_tumor_laterality.replace(('Left','Right'),(1,2),inplace=True)\n    dataset.pr_status.replace(('Positive','Negative'),(1,0),inplace=True)\n    dataset['gene3_classifier_subtype'] = dataset['3-gene_classifier_subtype']\n    dataset.gene3_classifier_subtype.replace(('ER+\/HER2- Low Prolif','ER+\/HER2- High Prolif','ER-\/HER2-','HER2+'),(1,2,3,4),inplace=True)\n\n    dataset.drop(['patient_id','3-gene_classifier_subtype','oncotree_code','relapse_free_months','overall_survival_months','death_from_cancer'], axis=1, inplace=True)\n    \n    downcast(dataset)\n\n    '''Guardo en metabric_num las variables de tipo num\u00e9ricas para utilizarlo en el escalado.'''\n    metabric_num = dataset.select_dtypes(include=['int64','int32','float32']).columns.tolist()  \n\n    scaler = StandardScaler()\n    dataset[metabric_num] =  scaler.fit_transform(dataset[metabric_num])\n\n    return dataset\n\n    ","78066a99":"app = Flask(__name__)\n\ndef transform(text_file_contents):\n    return text_file_contents.replace(\"=\", \",\")\n\n\n@app.route('\/')\ndef form():\n    return \"\"\"\n        <html>\n            <body>\n                <h1>Predicci\u00f3n de superviviencia en pacientes con c\u00e1ncer de mama<\/h1>\n                <\/br>\n                <\/br>\n                <p> Seleccione el archivo .csv a subir\n                <form action=\"\/transform\" method=\"post\" enctype=\"multipart\/form-data\">\n                    <input type=\"file\" name=\"data_file\" class=\"btn btn-block\"\/>\n                    <\/br>\n                    <\/br>\n                    <button type=\"submit\" class=\"btn btn-primary btn-block btn-large\">Obtener predicci\u00f3n<\/button>\n                <\/form>\n            <\/body>\n        <\/html>\n    \"\"\"\n@app.route('\/transform', methods=[\"POST\"])\n\ndef transform_view():\n    f = request.files['data_file']\n    if not f:\n        return \"No file\"\n\n    stream = io.StringIO(f.stream.read().decode(\"UTF8\"), newline=None)\n    csv_input = csv.reader(stream)\n    \n    for row in csv_input:\n        print(row)\n\n    stream.seek(0)\n    result = transform(stream.read())\n    print(result)\n\n    X_test = pd.read_csv(StringIO(result), sep=';')\n    \n    patient_id = X_test['patient_id']\n    \n    df = pipeline_modelo_nuevo(X_test)\n\n    # load the model from disk\n    loaded_model = pickle.load(open(modelo_existente(), 'rb'))\n\n    df['prediction'] = loaded_model.predict(df)\n    df['patient_id'] = patient_id   \n    \n    response = make_response(df[['prediction','patient_id']].to_csv(index=False))\n    response.headers[\"Content-Disposition\"] = \"attachment; filename=result.csv\"\n    return response\n\nif __name__ == \"__main__\":\n    app.run(debug=False,port=9000)","2f04e024":"## Productivizar modelo\n\n<br>\n<div>Para esto se crean dos funciones, una de ella con el dataset original y otra donde se utilizar\u00e1 para el conjunto de datos a predecir (nuevo conjunto).\nTambi\u00e9n se opt\u00f3 por crear mediante Flask una interfaz en html, donde el usuario subir\u00e1 el archivo en formato .csv, y autom\u00e1ticamente se descarga un archivo .csv con las predicciones hechas.<\/div>\n\n![image.png](attachment:image.png)\n\nPara la funci\u00f3n de `modelo_existente` hay partes de c\u00f3digo que se repite, ya que la idea es que el c\u00f3digo pueda ser utilizado en un nuevo notebook, y no falle por falta de dependencia.\nEn la funci\u00f3n `pipeline_modelo_nuevo` se parte con un .csv, donde las variables dummies ya est\u00e1n creadas. Esto se realiz\u00f3, ya que es posible que los nuevos datos que quiero predecir la variable objetivo, no tengan los 6 tipos de c\u00e1nceres, con lo cual, el modelo dar\u00e1 error.","2beecbe8":"De los modelos de boosting, XGBoost sobresale, los valores obtenidos son similares a la RL, sin embargo para el conjunto de entrenamiento se obtuvo un 1.","8670e4bd":"# Imports","4cb3d1d7":"En este caso, sucede la inversa a la comparativa previa, el contraste de las pacientes que han recibido un tratamiento de hormonas y no han sobrevivido predomina, siempre hablando del mismo tipo de carcinoma.","b56dcc43":"Se valida el formato:","f809de89":"En el gr\u00e1fico de dispersi\u00f3n, se representa en el eje `x` la edad que la paciente fue diagnosticada, mientras que en el  `y`, tendremos los a\u00f1os de supervivencia.\nEstratificamos estos datos por el estado de recidiva, siendo 0 un no, y 1 si es si.\n\nSe identifica una menor dispersi\u00f3n de los valores entorno a las pacientes cuya supervivencia gira entorno a los 20 a\u00f1os y pareciera que la enfermedad no ha reincidido, en cambio en la franja de 20-40 a\u00f1os se nota una predominancia de pacientes que volvieron a enfermar.\n\nA nivel general, el 60% de las pacientes no presenta \u00edndice de recidiva.","cb66ba58":"#### BRCA1, BRCA2","0409493f":"<div>Dependiendo el tipo de tumor que las pacientes han desarollado se visualiza como se relaciona con los a\u00f1os de supervivencia. Esta variable es muy precisa, ya que la clasificaci\u00f3n est\u00e1 basada de una toma histol\u00f3gica, es decir, una vez que se realiza la biopsia del tejido, se determina su clasificaci\u00f3n, por tanto, es m\u00e1s espec\u00edfica que el tipo de c\u00e1ncer por ejemplo. <\/div>\nLos primeros tres tumores son los m\u00e1s comunes de encontrar, siendo el ductal el que mayor cantidad de pacientes tiene, en cambio si comparamos contra el tubular o medular, la probabilidad que lleguen a 40 a\u00f1os de supervivencia es m\u00e1s escasa. Adem\u00e1s, se visualizan algunos outliers pasando la barrera de los 40 a\u00f1os.","82ceeda0":"Se procede a eliminar del conjunto la columna correspondiente a `3-gene_classifier_subtype`,\nya que se encuentra creada con otro nombre, tambi\u00e9n se elimina `oncotree_code` ya que la clasificaci\u00f3n que aparece corresponde al tipo de c\u00e1ncer, Breast Invasive Ductal Carcinoma = IDC.\n<div> Adem\u00e1s, se elimina las variables que contienen meses, ya que se han creado con a\u00f1os para un mejor entendimiento. <\/div>\n<div> Por otra parte, se elimina la variable `death_from_cancer` ya que indica si la paciente vive, fallece de la enfermedad u otra causa, lo cual estar\u00eda 'ayudando' a la variable objetivo. <\/div>","59222dd8":"<u>Conclusi\u00f3n:<\/u>\n\n- La terapia m\u00e1s utilizada es la Hormonoterapia con 405 pacientes.\n- La combinaci\u00f3n de terapia m\u00e1s empleada es Radio y Hormono terapia con 586 pacientes.\n- La menos utilizada es hormono y quimio terapia con 28 pacientes\n- Las 3 terapias juntas se aplican a 155 pacientes.","e06aa327":"## Entrenamiento\/Testing","661bca47":"El \u00edndice de Nottingham se determina partiendo de tres criterios patol\u00f3gicos, tama\u00f1o del tumor, su estad\u00edo y la cantidad de ganglios linf\u00e1ticos positivos asociados.\n\nEl tumor medular posee mayor \u00edndice, mientras que el tubular es el menor. El metapl\u00e1sico no muestra un valor representativo ya que solamente existe un registro de \u00e9l.","a43ac6fe":"En los casos donde las pacientes han recibido quimioterapia, el valor de la variable objetivo est\u00e1 balanceado. Sin embargo, en caso de no recibir quimioterapia (alrededor de 1500 casos), el 60% no sobrevive.","74ec07c7":"* El tipo luminal, constituye alrededor de un 75-80% de los carcinomas de mama. El luminal A, representa un 50-60%, luego el luminal B un 10-20%.\n* El LumA posee mejor pron\u00f3stico, ya que tiene menor incidencia, y una mayor tasa de repuesta ante la hormonoterapia.\n* El LumB posee una mayor expresi\u00f3n de genes de proliferaci\u00f3n, y un mal pron\u00f3stico ante la quimio y hormonoterapia.\n* El HER2 posee alto grado histol\u00f3gico, alta tasa de proliferaci\u00f3n y suele ser bastante agresivo.\n* Claudin-Low se asocia con un pron\u00f3stico precario.\n* Basal o triple negativo posee un mal pron\u00f3stico, sin embargo puede tener una alta tasa de respuesta ante la quimioterapia.\n* Normal, es llamado as\u00ed ya que las c\u00e9lulas simulan a un tipo \"normal\"","2ad9f093":"### SVC","672a37fa":"## Conclusi\u00f3n","f690d3e5":"Este m\u00e9todo utiliza un hiperplano para separar las clases.\n\nContras:\n\n* Es m\u00e1s complicado de interpretar\n* Para largos datasets suele ser lento.\n* Consume bastante memoria.","e0b1caf1":"### Selecci\u00f3n de variables\n\nSe aplica el mismo procedimiento para el dataframe de selecci\u00f3n de variables:","3c2567a1":"A continuaci\u00f3n, se itera el dataset para visualizar que valores est\u00e1n presentes en cada una de las variables. A fines de evitar largas salidas en el notebook, se evita el print.","35b5f5d2":"En el eje `x` se representa el \u00edndice de recidiva y la edad de diagnosis en el eje de las ordenadas. Tambi\u00e9n, estar\u00e1 estratificado por la causa de muerte asociado.\n\nSe detecta que cuando no hubo reincidida en la enfermedad, ninguna paciente falleci\u00f3 de c\u00e1ncer.","5e706894":"Se filtra por el id_paciente = 6, para obtener la cantidad de meses de supervivencia de dicho paciente.","760da52f":"![image.png](attachment:image.png)","16cc514e":"La diferencia m\u00e1s notoria corresponde al carcinoma ductal, considerando que \u00e9ste est\u00e1 presente en 1500 pacientes, el 60% no sobrevive.","912dd090":"##### Paciente 0","2fa0a55d":"Con este algoritmo el modo ha mejorado, en especial para la clase 1. Por otro lado, la precisi\u00f3n que se obtiene para el conjunto de entrenamiento es muy buena.","3051eee0":"### Resumen modelos","97fbadb3":"#### Ganglios linf\u00e1ticos positivos ---- GANGLIOS CENTINELAS","722647f9":"#### M\u00e9tricas\n\nLas medidas que se toman en cuenta para la toma decisiones ser\u00e1n la matriz de confusi\u00f3n con los par\u00e1metros asociados, el accuracy de cada conjunto (entrenamiento y testing) y curva ROC","c3f11b81":"<div>Cuando se tienen valores num\u00e9ricos como es este caso, una buena pr\u00e1ctica es escalar los datos, realizando esto, se asume que la distribuci\u00f3n es de tipo gaussiana.<\/div>\nEsto lo realizo antes de comenzar con los modelos ya que provoca que todas las caracter\u00edsticas est\u00e9n bajo un mismo rango. Tal como se realiz\u00f3 al principio, se realiza un downcasting del tipo de variable.","924bec5a":"#### Edad de diagn\u00f3stico vs A\u00f1os de supervivencia vs Estado de recidiva","d62e69a3":"Una comprobaci\u00f3n que quiero realizar, es tomar el modelo ganador y entrenarlo para un dataframe considerando solamente las variables cl\u00ednicas.","adb6b059":"#### XGBClassifier","89e16407":"Par\u00e1metros: cada uno de ellos se expresa mediante una f\u00f3rmula\n\n* Precision: mide la calidad del modelo en tareas de clasificaci\u00f3n. Su formula expresa la cantidad de verdaderos positivos dividido la cantidad de positivos detectados por el predictor.\n* Recall: indica cuan bien el modelo puede detectar una clase. Su f\u00f3rmula es la cantidad de verdaderos positivos divido la cantidad de muestras que deber\u00edan ser positivas.    \n* F1 score: es la mezcla entre ambas m\u00e9tricas. Es usado para medir el accuracy del conjunto de testing. \n* Curva ROC: nos dice qu\u00e9 tan bueno es el modelo para distinguir las clases dadas, en t\u00e9rminos de probabilidad predicha. El \u00e1rea cubierta por la curva es el \u00e1rea entre la l\u00ednea azul (ROC) y el eje. Esta \u00e1rea cubierta es AUC. Cuanto mayor sea el \u00e1rea cubierta, mejores ser\u00e1n los modelos de aprendizaje autom\u00e1tico para distinguir las clases dadas. Sobre el eje de las ordenadas, se encuentra el True Positive Rate, que equivale a la sensibilidad del modelo y coincide con la m\u00e9trica de recall. En las abscisas, se tiene False Positive Rate, que su equivalente es la Especificidad,es la proporci\u00f3n de negativos que fueron considerados como positivos. El intervalo de valores que tiene la curva es [0,1], con lo cual, cuanto m\u00e1s cerca de 1 se encuentre mejor es la performance del mismo\n","2307b638":"Si bien el dataset es peque\u00f1o, una buena pr\u00e1ctica es ejecutar el siguiente c\u00f3digo que ayudar\u00e1 a reducir la memoria usada cuando tratemos con grandes vol\u00famenes de datos, esto se debe a que se realiza un downcast del tipo de variable, es decir, si se tiene `int64` , el nuevo tipo ser\u00e1 `int32`.","cdb755c1":"Se valida que los valores est\u00e9n en el formato correcto:","0f29c40d":"#### Histolog\u00eda del tumor vs Tama\u00f1o del tumor","b524b446":"#### Menopausia vs Tipo de c\u00e1ncer vs \u00cdndice de Nottingham","59573df5":"Se observa que el modelo clasific\u00f3 a 40 pacientes con un pron\u00f3stico que iban a sobrevivir cuando en realidad es incorrecto, y 29 pacientes alreves.\nAdem\u00e1s, si se observa en la m\u00e9trica de `precision`, predice mejor la clase 0 que la que 1, por otro lado con la m\u00e9trica de `recall` sucede lo mismo.\nEs m\u00e1s comodo visualizar la m\u00e9trica f1, ya que combina las dos primeras, est\u00e1 claro que hay que mejorar los valores para la clase 1.","5509b255":"#### \u00cdndice de recidiva","8e492538":"#### Quimioterapia","6e6fc548":"#### Histolog\u00eda del Tumor vs Estad\u00edo","1f2a54b9":"#### A\u00f1os de recidiva\n\nSe presenta un punto de corte entorno a los 8 a\u00f1os, donde la variable objetivo est\u00e1 discriminada.","208ee4cc":"#### SVC\n\nA nivel de precisi\u00f3n es peor si se compara con el algoritmo sin parametrizar. Si se visualiza la MC los verdaderos positivos aumentaron, sin embargo los falsos positivos tambi\u00e9n, y la idea es minimizar los falsos.","377fdd7d":"La matriz de confusi\u00f3n consta de 4 valores:\n\n* TN = True Negative\n* FP = False Positive\n* FN = False Negative\n* TN = True Negative\n\nLa mejor forma de entender estos valores es con la siguiente imagen:\n\n![image-4.png](attachment:image-4.png)","c24f41a7":"Se observa en el histograma que el rango de edad es entre los 20 hasta los 95 a\u00f1os aproximadamente, es posible que los 95 a\u00f1os sea un outlier, pero se opta por conservarlo. Se acent\u00faan dos picos entornos a los 60-62 a\u00f1os y 65-67 a\u00f1os.","78bb34c8":"#### Gen KI67 vs Subtipo de c\u00e1ncer\n\nEn este caso, la curva para el LumA, LumB y HER2 es similar, en los valores negativos predomina el HER2, mientras que para los valores positivos el Basal.","e881136e":"#### Histolog\u00eda del tumor vs A\u00f1os de recidiva","67e8f45f":"#### Tipo de c\u00e1ncer","1281b6c6":"En este caso, el modelo ha mejorado. Se observa una mejora del f1 score, tambi\u00e9n pareciera que se ha tratado el overfitting.\nEn la MC hay una disminuci\u00f3n de los falsos positivos (de 40 a 19), sin embargo los falsos negativos han aumentado.\n","cb4f468b":"Primero, observo el tipo de cada una de las variables y la cantidad de valores no nulos de cada una de ellas. Adem\u00e1s, se obtiene la cantidad de memoria que ocupa el conjunto de datos, en este caso 5.6 MB.","fa4bc776":"<div>El dataset elegido presenta un problema de clasificaci\u00f3n binaria, ya que la variable objetivo <u>overall_survival<\/u> tomar\u00e1 dos valores:<\/div>\n\n- 1:Sobrevive\n- 0:No Sobrevive. \n\nEs por esto, que he seleccionado los siguientes modelos a utilizar:\n\n* Regresi\u00f3n Log\u00edstica\n* Naive Bayes\n* Support Vector Classification\n* \u00c1rbol de Decisi\u00f3n\n* Random Forest\n* Redes Neuronales\n* XGBClassifier\n\nA cada uno de estos modelos se le aplicar\u00e1 GridSearch con sus respectivos par\u00e1metros.","b9ca2c3a":"##  Variables vs Target","003d94a3":"Se a\u00f1ade un nuevo modelo que pertenece a la clasificaci\u00f3n de Ensemble Methods, solamente se ejecuta con parametrizaci\u00f3n","13ba6de1":"En el c\u00e1ncer de mama, existen diferentes subtipos. En este estudio, la mayor\u00eda de las pacientes ha desarrollado un `carcinoma ductal invasivo (IDC)`, aproximadamente 8 de 10 c\u00e1nceres de mama son de este tipo. \n<div>El IDC comienza en las c\u00e9lulas que revisten el conducto galactoforo en la mama, a partir de ah\u00ed, el c\u00e1ncer invade la pared del conducto, y crece en los tejidos mamarios adyacentes.<\/div>\n\nEn tercer lugar, est\u00e1 con el `carcinoma lobular invasivo` (ILC), aproximadamente 1 de cada 10 c\u00e1nceres de mama invasivos son de este tipo, este carcinoma comienza en las gl\u00e1ndulas productoras de leche y al igual que el IDC tambi\u00e9n puede extenderse.\n\nEn segundo lugar, est\u00e1 el  `carcinoma mixto`,  es una combinaci\u00f3n de los dos anteriores.\n\nLuego, se tiene una categor\u00eda que es mama, se asume que no pertenece a ninguna clasificaci\u00f3n en particular.\n\nEn quinto lugar, existe con el `carcinoma mucinoso(carcinoma coloideo)`, es una forma poco frecuente de carcinoma ductal invasivo. El carcinoma mucinoso representa el 2-3 % de todos los casos de canceres.\n\nPor \u00faltimo, el `carcinoma metapl\u00e1sico`, representa el 0.2-5% del total. En general, son de mal pron\u00f3stico, porque no responden bien a los tratamientos de quimioterapia.\n","9b89d35d":"### Regresi\u00f3n log\u00edstica\n\n#### Dataset completo","066f8565":"Con Naive Bayes el modelo ha empeorado, en especial para la clase 1. En este caso, no se aplica GridSearch, ya que Naive Bayes no tiene hiperpar\u00e1metro con lo cual no tiene sentido utilizar GridSearch.","68c4d4c3":"Con el estudio de este trabajo, queda demostrado que no se puede prescindir de ninguna variable. Como se ha visto, no es una ciencia exacta donde se puede afirmar que a una paciente bajo un determinado diagn\u00f3stico, le funcionar\u00e1 `x` tratamiento.\nPacientes con el mismo diagn\u00f3stico, mismas caracter\u00edsticas cl\u00ednicas tienen diferente respuestas a los tratamientos, esto se debe a la expresi\u00f3n gen\u00e9tica.\nConsidero que una futura mejora es incluir en el dataset el tipo de mutaci\u00f3n de los genes que se ha estudiado, ya que existe dos tipos de mutaciones gen\u00e9ticas, adquirida o de l\u00ednea germinal. La primera ocurre durante el transcurso de vida de una persona y puede ser dada por m\u00faltiples causas, la segunda tiene un componente hereditario, un ejemplo de esto es el BRCA1\/BRCA2.\n\nBas\u00e1ndome en las variables que se han visto, considero que ser\u00eda muy interesante saber por ejemplo, que tipo de mutaciones est\u00e1n asociadas con el TP53, ya que m\u00e1s del 50% de los c\u00e1nceres involucran este gen (mutado por supuesto), lo cual de esta forma se tendr\u00eda un diagn\u00f3stico completo de cada paciente.\n","9e3a807a":"### Random Forest\n\nEs una combinaci\u00f3n de \u00e1rboles de decisi\u00f3n, entrenados con diferentes subset de datos. Cuando un elemento se introduce para obtener su predicci\u00f3n, cada \u00e1rbol obtiene una salida La predicci\u00f3n toma el valor de la opci\u00f3n m\u00e1s votada","25f49dcd":"Presenta mejoras que con DecisionTree, pero no se consigue valores buenos.","eab8b080":"Los valores obtenidos han empeorado considerablemente, a simple vista con la matriz de confusi\u00f3n, se nota un gran aumento de los falsos tanto negativos como positivos, esto es una mala se\u00f1al. Por otro lado, los verdaderos han disminuido","a801f9d5":"Se procede a rellenar las variables categ\u00f3ricas por la moda y las num\u00e9ricas por la media.","cec9a15b":"La variable `overall_survival_months` indica la duraci\u00f3n desde la primera intervenci\u00f3n hasta la muerte del paciente, est\u00e1 expresada en meses, pero considero que ser\u00eda m\u00e1s pr\u00e1ctico tenerlo en a\u00f1os.\n\nPor otro lado, se presentan valores extra\u00f1os,por ejemplo: 11.766.666.670.000.000, que tambi\u00e9n se pueden encontrar en las variables relacionadas con los genes. Esto no es un error de datos, ya que fue contrastada con la p\u00e1gina oficial:\n\n> https:\/\/www.cbioportal.org\/study\/summary?id=brca_metabric\n\n\nLa justificaci\u00f3n de esto es el idioma, es decir, son datos que utilizan el **.** para marcar un decimal, entonces al manipular el conjunto de datos se ve afectado, provocando valores \"extra\u00f1os\" como el marcado previamente.","b43446c3":"Se obtiene para las variables expresadas en meses, su correspondiente en a\u00f1os. Es por esto, que se divide por 12.\n\n<u> Ejemplo<\/u>:\n\n```python\n\n12m  --- 1 a\u00f1o\n400m --- x = (400 * 1) \/12 = 33.3 a\u00f1os\n\n```","e4a0b99a":"Se realiza la carga del dataset en formato .csv, el archivo consta de 60 columnas y 1904 registros.","e6980a9d":"Se toma como ejemplo, el paciente 6 y 0, la primera imagen corresponde a la p\u00e1gina mencionada previamente. Considero que es una buena forma para contrastar como el dato debe aparecer.\nEn este caso, el *paciente 0* contiene un formato correcto, mientras que el *paciente 6* no.","b096abb7":"Se crea el dataframe con las variables obtenidas en el paso anterior, tambi\u00e9n se visualiza que los genes son considerados en la selecci\u00f3n de variables.","779e7f87":"#### \u00cdndice de Nottingham vs Histolog\u00eda del tumor","168894e9":"A continuaci\u00f3n, se acota el dataframe para los genes, donde su tipo de dato es *object*. De esta forma, se itera para cada una de sus columnas aplicando una l\u00f3gica muy similar a la realizada en *overall_survival_months*.","f3813f3d":"Utilizo **value_counts** para visualizar la distribuci\u00f3n en cada una de las clases de la variable categ\u00f3rica.","247ea43c":"#### Diagrama Venn de las 3 terapias","56fcbc52":"Sin lugar a dudas, cuando la enfermedad reincide, la probabilidad de supervivencia disminuye significativamente. Por ejemplo, se tiene aproximadamente 800 pacientes que la enfermedad ha reincidido, donde el 87% no ha sobrevivido.\nPor el contrario, alrededor de 1100 pacientes no ha vuelto a tener la enfermedad y el 36% no ha sobrevivido. ","136fc74e":"## Modelos","0b7c233c":"#### Motivos muerte","115bb573":"#### Edad vs Tipo de Cancer","b7ed667a":"Al tener variables categ\u00f3ricas, utilizar la correlaci\u00f3n cl\u00e1sica bajo el m\u00e9todo de Pearson como realizar\u00e9 para las variables num\u00e9ricas no es la mejor opci\u00f3n, es por esto que se utiliza V de Cramer.\nA continuaci\u00f3n defino una funci\u00f3n que calcula el coeficiente de Cramer para en el paso siguiente utilizarlo en el dataframe.","f4c13154":"<div>En muchos casos, las pacientes pueden recibir tratamientos combinados, cada uno de ellos no es excluente de otro. Es por esto, que considero que un Diagrama de Venn puede aportar una idea en cuanto a proporciones.<\/div>\nPrimero, se crea cada una de las combinaciones posibles, por ejemplicar se tiene que la variable `chemo` ser\u00e1 el resultado de `chemotherapy` = <span style=\"color:green\"> 1 <\/span>, `radio_therapy`= <span style=\"color:red\">0<\/span> y `hormone_therapy` = <span style=\"color:red\">0<\/span>.\n\n<div>Este paso, se realiza para las tres terapias por separado. Luego, contemplo las posibles combinaciones de terapias, donde `chemo_radio` ser\u00e1 que la paciente se realiz\u00f3 quimioterapia y radioterapia, `radio_hormonal` ser\u00e1 radioterapia combinado con hormonoterapia y `hormonal_chemo` es igual a hormonoterapia junto a quimioterapia.<\/div>\nPor \u00faltimo, tambi\u00e9n se considera las tres terapias en conjunto.","55f7c50b":"##### Paciente 6","86495d5b":"Una de las mejoras que se puede contemplar es crear rangos para la edad y las variables expresadas en a\u00f1os:","13500afd":"### BaggingClassifier\n\nParece que con este modelo se han obtenido los mejores resultados, por un lado la cantidad de falsos negativos es peque\u00f1a en comparaci\u00f3n a otros modelos, y los verdaderos negativos es significante.\nPor el otro lado, los valores obtenidos para el f1 score son buenos, sobresale la clase 0, pero la precisi\u00f3n obtenida para el conjunto de testing es casi 0.85, dir\u00eda que es la mejor hasta el momento.","e57ae187":"#### Decision Tree","f266b8d5":"Continuando con la histolog\u00eda de tumores, se grafica contra el tama\u00f1o del tumor. Los tumores que mayor tama\u00f1o pueden alcanzar son los ductales y los lobulares.","e42821de":"# EDA","11f93917":"#### Tipo de c\u00e1ncer","88d72106":"![image.png](attachment:image.png)","78c2c0e8":"Se aplica una l\u00f3gica similar para los genes, ya que existen casuisticas parecidas. Filtrando por el *patient_id* 6218, se obtiene el valor del gen BRCA1","076519dc":"Esta es una relaci\u00f3n importante ya que el estadio indica el grado de \"agresividad\" que tendr\u00e1 el tumor, muchas veces puede ir acompa\u00f1ado del tipo de tumor que la paciente tenga, debido a que hay carcinomas que presentan peor pron\u00f3stico que otros.","4b7c42c0":"Se identifica en la muestra que el 42% de las pacientes sobrevivi\u00f3, el 32,6% ha fallecido por c\u00e1ncer y el 25% se debe a otras causas.","18feac50":"#### Subtipo de c\u00e1ncer\n\nTal como se mencion\u00f3 previamente, el LumB y HER2 poseen mal pron\u00f3stico con lo cual tiene sentido que la brecha que existe entre los valores de la variable objetivo sea significativa. ","19c941eb":"### Transformaci\u00f3n de las variables\n\nSe realiza una copia del dataframe original a otra variable, para mantener el original.","cdf058f9":"Para evaluar el modelo se utilizar\u00e1 la funci\u00f3n `mostrar_resultados` que devolver\u00e1 la matriz de confusi\u00f3n, recall, precision y f1.\n* recall = indica cuan bien el modelo puede detectar una clase\n* precision = mide la calidad del modelo en tareas de clasificaci\u00f3n\n* f1 = \n<div>Tambi\u00e9n utilizar\u00e9 accuracy_score, el error cuadr\u00e1tico medio (MSE) <\/div>","4c24d0e5":"Se observa que solamente var\u00eda la precisi\u00f3n y recall un 0.01, el resto de las m\u00e9tricas se mantiene igual. Con lo cual, utilizar GridSearchCV no ha modificado el accuracy.","49600769":"<div>Antes de comenzar de con los modelos, se realiza una divisi\u00f3n del conjunto a trabajar. Se considera la proporci\u00f3n 80-20, donde el 20% corresponde al conjunto de testing.<\/div> \n\nTambi\u00e9n, se asigna a la variable `X` el dataframe excluyendo la variable objetivo, que ser\u00e1 asignada a la variable `y`. Por otro lado, tambi\u00e9n se considera quitar la variable `patient_id`, ya que no nos aporta informaci\u00f3n al respecto, por m\u00e1s que en la selecci\u00f3n de variables sea considerada significativa.  \n","94c0ff23":"Ordenado de mayor a menor, el LumA est\u00e1 presente en casi 700 pacientes","c0a3efe2":"#### Adaboost","cc486ec4":"##### Overall survival months","fae8b305":"1. En el siguiente c\u00f3digo se realizan diferentes comprobaciones, en la primer l\u00ednea de c\u00f3digo, si la longitud de `overall_survival_months` es mayor o igual a 13, entonces se sobreescribe el valor con los primeros 4 caracteres, caso contrario se mantiene el valor original.\n\n```python\nx = \"16.493.333.330.000.000\"\nprint(x[:4])\n\n'16.4'\n```\n\n2. En la segunda l\u00ednea, se reemplaza el *.* por un vac\u00edo si la longitud del valor guardado previamente es igual a 4, caso contrario se mantiene el valor original.\n\n```python\nx = '16.4'\nprint(len(x))\n'4'\n\nprint(x.replace(\".\", \"\")\n'164'\n```\n\n3. En la \u00faltima l\u00ednea, se convierte a decimal.","96844b8c":"A continuaci\u00f3n se analiza el comportamiento de la variable objetivo `overall_survival` con el resto de las variables.","c30a2e21":"### DecisionTree\n\nRealiza predicciones a trav\u00e9s de construcciones l\u00f3gicas, similares a los sistemas basados en reglas\n\nContras:\n\n* Los \u00e1rboles de decisi\u00f3n son propensos a generar overfitting.\n* Los \u00e1rboles complejos son dif\u00edciles de interpretar\n","0da42ee5":"## Feature Engineering","72a0e1ce":"Se opta por crear un dataframe para tener cada una de las m\u00e9tricas en un formato de tabla, de esta forma ser\u00e1 m\u00e1s c\u00f3modo visualizar los valores al mismo tiempo.","1be2b477":"Generalmente la mujer comienza la menopausia entre los 45 y 55 a\u00f1os, siendo el promedio de 51 a\u00f1os, pero puede darse antes en algunas mujeres. Se observa que en las pacientes pre menopa\u00fasicas el carcinoma es m\u00e1s agresivo que en las pacientes post menop\u00e1usicas. Esto puede deberse a que se presenten en una etapa avanzada o tengan un diagn\u00f3stico tard\u00edo debido a un bajo \u00edndice de sospecha por parte de la paciente y de su m\u00e9dico.","fd70f6fa":"Similar al paso anterior, realizo un an\u00e1lisis para las variables categ\u00f3ricas. Donde en la primera l\u00ednea de c\u00f3digo, incluyo las variables de tipo objeto para convertirlas en una lista.\n<div>Paso posterior, utilizo la lista obtenida como \u00edndice e indico que son variables de tipo categ\u00f3rica.<\/div>\n<div>En las columnas de la tabla, se observa la cantidad de valores \u00fanicos para cada columna, y la frecuencia del valor que m\u00e1s se repite.<\/div>\n\nPor ejemplo, para `type_of_breast_surgery`, se tienen dos valores \u00fanicos, donde Mastectom\u00eda predomina.","57a6d2aa":"##### Relapse Free Months","7715f9b7":"#### Subtipo de c\u00e1ncer","4bd967fb":"Se crea un dataframe contemplando solamente los genes para visualizar la correlaci\u00f3n entre ellos.","859d3a16":"#### Edad de diagn\u00f3stico\n\nSe visualiza un punto de corte entorno a los 63 a\u00f1os aproximadamente, por encima de este valor el pron\u00f3stico es m\u00e1s favorable.","0468253d":"La Matriz de Confusi\u00f3n presenta un incremento en los casos donde fue pronosticado que la paciente sobrevir\u00e1 cuando no es correcto. Tambi\u00e9n, se visualiza un incremento en los verdaderos positivos que se ve reflejado en el f1, ya que se es el mejor valor obtenido hasta el momento para la clase 1.","2bcccab5":"#### Distribuci\u00f3n de la edad","473757cf":"#### Selecci\u00f3n de variables","3007d4c8":"#### Estado menop\u00e1usico\n\nSe tiene alrededor de 410 pacientes pre menop\u00e1usicas, donde el 40% no consigue sobrevivir. Por el contrario, de 1495 pacientes post menop\u00e1usicas, el 60% no sobrevive.","95a047b5":"A rasgos generales, se visualiza lo siguiente:\n\n* La edad tiene formato decimal, lo cual ser\u00e1 convertida a entero, ya que no tiene sentido en decimal.\n* La mitad del dataset est\u00e1 formado por variables categ\u00f3ricas, ya que son parte de una clasificaci\u00f3n, por ejemplo, si la cirug\u00eda que le han realizado a la paciente es una mastectom\u00eda o una conservaci\u00f3n mamaria. Si el grado de celularidad es Alta, Media o Baja, si la paciente est\u00e1 con vida, o falleci\u00f3 de c\u00e1ncer o de otra causa.\n* Muchas variables tomar\u00e1n valores booleanos, por ejemplo, si la paciente se ha realizado quimioterapia o no, o si el an\u00e1lisis de los receptores de estr\u00f3geno es positivo (1) o negativo (0), con lo cual, se unificar\u00e1 todas las variables de estas caracter\u00edsticas para que asuman 1 o 0. \n* Se presentan algunas caracter\u00edsticas de tipo string que tienen que ser n\u00fameros, como los genes, las variables expresadas en meses, el \u00edndice de Nottingham. Es por esto que se aplica diferentes transformaciones validando la longitud de las mismas, ya que se encuentran expresadas en un formato err\u00f3neo. Adicionalmente, las variables expresadas en meses post transformaci\u00f3n son convertidas a a\u00f1os para una mejor manipulaci\u00f3n en los gr\u00e1ficos.","1e172cef":"Al ser un problema de clasificaci\u00f3n, hay que comprobar que el conjunto se encuentre balanceado, esto es que la cantidad de registros que haya en cada clase sea parecida y no exista una clase con el 90% de las observaciones.","790a7f5e":"### Discusi\u00f3n de los resultados","1d9dd255":"# Master en Big Data y Data Science - Trabajo Fin de Master \n\n## Universidad Complutense de Madrid\n\n\nEl conjunto de datos que he elegido es de la plataforma Kaggle:\n\n> <a href=\"https:\/\/www.kaggle.com\/raghadalharbi\/breast-cancer-gene-expression-profiles-metabric\">Breast Cancer Gene Expression METABRIC<\/a>\n\n\nEl archivo consta de 700 columnas, de las cuales previo an\u00e1lisis de investigaci\u00f3n he considerado las variables m\u00e1s relevantes para el an\u00e1lisis.\n\nEste dataset est\u00e1 compuesto por registros de mujeres que han padecido c\u00e1ncer de mama y la finalidad del trabajo es predecir la supervivencia de las pacientes para lo cual comenzar\u00e9 explicando las variables que he considerado.\n\nPor lo que tengo en este trabajo 30 variables, que corresponden a un an\u00e1lisis cl\u00ednico, entre ellas cito,edad de las pacientes, tipo de c\u00e1ncer, subtipo, grado asociado, si realizaron tratamientos como quimioterapia, radioterapia o terapia hormonal.\nA continuaci\u00f3n, desarrollo las variables para comprender as\u00ed los conceptos a tratar.\n\nInclu\u00ed en este dataset genes asociados al c\u00e1ncer de mama, en este apartado realic\u00e9 un pre filtrado tomando como referencia una monograf\u00eda que pertenece a la Asociaci\u00f3n Espa\u00f1ola de Senolog\u00eda y Patolog\u00eda Mamaria. La misma ser\u00e1 adjuntada en la entrega como parte de la bibliograf\u00eda utilizada.\n\nIncluyo en dicho notebook, un archivo con la definici\u00f3n de cada uno de los campos para una mejor interpretaci\u00f3n del conjunto.\n\n\n*** ","82286df0":"#### Random Forest \n\nLas m\u00e9tricas son similares a las obtenidas sin par\u00e1metros con una peque\u00f1a mejora.","efa31081":"#### Radioterapia","6c7d6d11":"Como se mencion\u00f3, esta variable es importante ya que es el primer lugar donde se disemina el c\u00e1ncer. La \u00fanica forma de saber si el c\u00e1ncer se ha extendido, es examinar el ganglio centinela, el pat\u00f3logo observa en el microscopio si es positivo, y en dicho caso se extirparan mas ganglios.\n<div>Mayor cantidad de ganglios positivos implica un aumento en las c\u00e9lulas malignas.<\/div>","e31ec717":"La franja de a\u00f1os en que la enfermedad reincide es de 25 a\u00f1os aproximadamente.\nSe presentan algunos valores en 65,82 a\u00f1os para el carcinoma ductal, que podr\u00edan ser outliers.","fc9a2ed0":"#### Tipo de cirug\u00eda ","e2b40a26":"Una vez tratado los valores nulos y los valores con un formato err\u00f3neo, se procede a realizar un an\u00e1lisis descriptivo de las variables num\u00e9ricas.\nLa tabla da un resumen de los valores de cada una de las variables num\u00e9ricas. Por ejemplo, si se toma la columna `age_at_diagnosis`, se tiene que el m\u00e1ximo valor presente en la columna es 96 a\u00f1os, el m\u00ednimo es 21 a\u00f1os, la edad promedio ronda en los 60 a\u00f1os.\nTambi\u00e9n, describe los percentiles, donde el 50% es el equivalente a la media.","a50e0a2c":"El boxplot est\u00e1 aperturado por tipo de c\u00e1ncer y edad, a la izquierda se visualizan algunos outliers. En general, la media de carcinomas se encuentra entre los 60-65 a\u00f1os aproximadamente. El carcinoma metapl\u00e1sico contiene una l\u00ednea ya que existe un solo registro de \u00e9ste.\nEn el carcinoma ductal, la brecha entre los valores m\u00e1ximos y m\u00ednimos es muy amplia en comparaci\u00f3n con el resto, se puede interpretar que, al ser un carcinoma muy com\u00fan, afecta a un rango de edad mayoritario.","9a37e9e3":"Para una mejor interpretaci\u00f3n de estas variables, se grafica algunos genes contra la variable objetivo. Hay que tener en cuenta que la expresi\u00f3n gen\u00e9tica de estos genes es completamente diferente a una persona que no ha padecido c\u00e1ncer, ya que la cantidad de prote\u00ednas se ve modificada.\n\n* chek2: la mutaci\u00f3n germinal de este gen est\u00e1 implicada en el desarrollo de c\u00e1ncer de mama, representando menos del 0,5% de los casos\n* ki67: gen que mide qu\u00e9 tan r\u00e1pido crecen y se dividen las c\u00e9lulas cancerosas.\n* tp53: en estado normal ayuda act\u00faa como un supresor tumoral, sin embargo cuando se modifica act\u00faa de forma opuesta.\n* brca1:  gen supresor de tumores, est\u00e1 relacionado con la parte hereditaria.","936216d2":"### Automatizaci\u00f3n GridSearchCV\n\nDe cada uno de los modelos mencionados previamente a excepci\u00f3n de Naive Bayes, se utilizar\u00e1 GridSearchCV, que es una t\u00e9cnica usada para la selecci\u00f3n de hiper par\u00e1metros del entrenamiento de un modelo.\n\nTambi\u00e9n, se incluye como par\u00e1metro en los modelos que permitan class_weight = 'balanced', ya que esto puedo ayudar a mejorar las m\u00e9tricas en un problema de clasificaci\u00f3n.","a2b19406":"En la secci\u00f3n previa, con la salida de cada uno de los modelos se fue contrastando las diferencias a nivel de precisi\u00f3n de cada uno de ellos. La curva ROC no fue mencionada ya que en rasgos generales, todas fueron muy buenas. En muchos modelos se ha obtenido un valor de 0.90, lo cual es sumamento positivo.\n<div>Hay m\u00e1s variables a considerar como la MC, la precisi\u00f3n, el f1 score. A simple vista, los modelos que mejor precisi\u00f3n tienen son SVC y Bagging, sin embargo, en la MC el SVC posee mayor cantidad de falsos. Es por esto que escogo el BaggingClassifier como modelo ganador. <\/div>\n\nA modo resumen se tiene:\n\n* 202 TN, que significa pacientes que no sobreviven a la enfermedad.\n* 120 TP, que corresponden a pacientes que sobreviven a la enfermedad.\n* 32 FP, corresponde a pacientes que sobreviven a la enfermedad cuando no es correcto.\n* 27 FN, pacientes que sobreviven a la enfermedad, pero le diagnosticaron que no lo har\u00edan.","adb371d7":"#### AdaBoost\n\nPara este caso la precisi\u00f3n del conjunto de testing ha mejorado mientras que la de entrenamiento ha disminuido.\nA nivel de f1 score, la clase 0 ha mejorado.","bb22bc22":"# Load data","f0942ae1":"#### Estado de recidiva vs Edad del diagn\u00f3stico vs Causa de muerte","922e0d6b":"Para realizar la transformaci\u00f3n de variables, se procede a utilizar OneHotEnconder para los tipos de canceres y luego la funci\u00f3n `replace` de pandas. En este caso, no se utilizar\u00e1 LabelEnconder, ya que quiero evitar que alguna clase pondere sobre otras. ","4fdaf226":"En este caso, si bien se obtiene una buena precisi\u00f3n, se observa que los casos de falsos se incrementaron. Por otro lado, la m\u00e9trica de recall predomina en la clase 0, en cambio en el modelo previo se manten\u00eda en los mismos valores para ambas clases.","cb38ec2e":"### Correlaci\u00f3n entre variables","a4de7a49":"### Selecci\u00f3n de variables\n\nActualmente el dataset consta de 62 columnas, se ha visto en la matriz de correlaci\u00f3n que no todas impactan en la variable objetivo. Es por ello, que incorporo una selecci\u00f3n de variables para visualizar cuales son consideradas las m\u00e1s signfificativas en el modelo.","ef773b9d":"La regresi\u00f3n log\u00edstica es utilizada para predecir la probabilidad de una salida binaria. Parte de la base que para predecir una observaci\u00f3n, si la misma est\u00e1 por encima de un umbral ser\u00e1 a la clase que pertenecer\u00e1. Por defecto, se utiliza un umbal de 0.5\n\nContras:\n\n* No es capaz de aprender relaciones complejas.\n* Tiene dificultad de procesar relaciones no-lineales sin previa transformaci\u00f3n.","47d2fb6b":"### Correlaci\u00f3n Genes","582bb3dc":"### Naive Bayes\n\nSe trata de un clasificador bayesiano (basado en el teorema de Bayes), es utilizado para calcular la probabilidad de un suceso, teniendo informaci\u00f3n de antemano sobre ese suceso..\n\nContras:\n\n* Problemas si existe relaciones entre variables.","2bc88454":"## Futuras mejoras","d64cf85d":"## Relaciones entre variables\n\nAntes de comenzar a visualizar la interacci\u00f3n entre cada variable, considero que es importante entender primero las variables aisladas y luego, estudiar el comportamiento entre ellas.\n\nSe setean algunos par\u00e1metros que ser\u00e1n utilizados en los gr\u00e1ficos:","bdeaa48b":"En el gr\u00e1fico predomina mayor dispersi\u00f3n para los valores positivos de BRCA2, se visualiza un \u00edndice de recidiva en pacientes entre 20-30 a\u00f1os.\nNo se puede realizar afirmaciones, pero se podr\u00eda suponer que al ser tan j\u00f3venes, est\u00e1n diagnosticadas con un c\u00e1ncer avanzado o grave, y es por eso que ha reincidido.","ee7d3d32":"A continuaci\u00f3n se ejemplifica el c\u00f3digo del `for` para la variable `chemo`:\n\n```python\nprint(chemo.shape)\n(45, 62)\n\nprint(chemo.shape[0])\n45\n\nprint('La cantidad de pacientes que han sobrevivido es de :', (chemo[chemo['overall_survival'] == 1]).shape[0])\nLa cantidad de pacientes que han sobrevivido es de : 17\n    \nprint('La media de sobrevivientes es de: ', 17\/45)\n\nLa media de sobrevivientes es de:  0.377\n    \nprint('La media de sobrevivientes es de: ', np.mean(chemo[\"overall_survival\"]))\n\nLa media de sobrevivientes es de:  0.377\n```\n","b3a2fb85":"Considero que es necesario utilizar `StratifiedKFold` a la hora de entrenar los diferentes modelos. De esta forma, aseguro que la proporci\u00f3n de registros con clase=1 y clase=0, sea la misma. \n<div>En otras palabras, por ejemplo, se tiene que 801 registros pertenecen a la clase 1 y 1103 a la clase 0.<\/div>\n\nCuando se aplica `StratifiedKFold` y seteo el valor k (decide en cu\u00e1ntos pliegues se dividir\u00e1 el conjunto de datos), se asegura que la cantidad de valores para cada clase sea de la misma proporci\u00f3n.\nSi se considera un k =4, la clase 1 tendr\u00e1 640 valores mientras que la clase 0 tendr\u00e1 882.\nMismo sucede para el conjunto de test, de esta forma, sabemos que est\u00e1 dividido manteniendo las proporciones.\n\n```python\nClase 1 = 801 registros\nClase 0 = 1103 registros\n\nTrain dataset:\n    \n    801 --- 100 %         \n640 = x --- 80  %\n\n   1103 --- 100 %\n882 = x --- 80 %\n\n```","c71c459c":"Misma l\u00f3gica para `nottingham_prognostic_index`:","ea44e419":"#### Gen TP53 vs Subtipo de c\u00e1ncer\n\nPara este gr\u00e1fico se consider\u00f3 los subtipos de c\u00e1ncer m\u00e1s comunes, LumA, LumB, HER2 y Basal. El comportamiento de los 4 valores es similar, a excepci\u00f3n del Basal que pareciera m\u00e1s suavizada la curva.\nSe observa que existe mayor presencia del TP53 con valores negativos para el HER2.","caa41e54":"Los valores que toma el tipo de cirug\u00eda son dos, mastectom\u00eda y conservaci\u00f3n de la mama. El 60% de las pacientes ha sido sometida a una mastectom\u00eda, mientras que el 40% restante a la conservaci\u00f3n de mama. Se recuerda que el total es 1904, con lo cual, 1127\/1904 = 0.59 ~ 60 %","b822f74e":"#### Hormonaterapia","f0767b14":"Este caso marca una diferencia en las pacientes que no han recibido radioterapia como tratamiento.","3af159f3":"#### XGBClassifier\n\nLas m\u00e9tricas son muy similares con respecto al algoritmo sin parametrizar. ","e33ece93":"### Redes Neuronales\n\nLas redes neuronales pueden aprender patrones complejos utilizando capas de neuronas que transforman matem\u00e1ticamente los datos.\n\nContras:\n\n* El modelo es una \"caja negra\", con lo cual no es posible explicar.\n* Requiere gran cantidad de datos.","54289b1e":"<div>Con el estudio de este trabajo, queda demostrado que no se puede prescindir de ninguna variable. Como bien se sabe, no es una ciencia exacta donde se puede afirmar que, una paciente bajo un determinado diagn\u00f3stico, le funcionar\u00e1 x tratamiento. \nComo el c\u00e1ncer es una enfermedad gen\u00e9tica, multifactorial, se entiende que pacientes con el mismo diagn\u00f3stico,y mismas caracter\u00edsticas cl\u00ednicas tengan diferentes respuestas a los tratamientos.<\/div>\n<br>\n<div>Considero que una futura mejora es incluir en el dataset el tipo de mutaci\u00f3n de los genes involucrados en el estudio, ya que existe dos tipos de mutaciones gen\u00e9ticas, adquirida o de l\u00ednea germinal. La primera ocurre durante el transcurso de vida de una persona y puede ser dada por m\u00faltiples causas, la segunda tiene un componente hereditario, un ejemplo de esto es el BRCA1\/BRCA2.\nBas\u00e1ndome en las variables vistas, ser\u00eda oportuno saber, por ejemplo, que tipo de mutaciones est\u00e1n asociadas con el TP53, ya que m\u00e1s del 50% de los c\u00e1nceres involucran este gen (mutado), lo cual de esta forma se tendr\u00eda un diagn\u00f3stico preciso de cada paciente.<\/div>\n<br>\n<div>El prop\u00f3sito de este trabajo, no es quedarse con el pron\u00f3stico predicho, sino que ayude a identificar con rapidez los casos desfavorables y se profundice en el estudio de las mutaciones de los genes ya que el mejor conocimiento de las mutaciones gen\u00e9ticas ayuda al mejor entendimiento de la biolog\u00eda del c\u00e1ncer.<\/div>\n<br>\n<div>Actualmente se est\u00e1n llevando a cabo investigaciones sobre la Terapia G\u00e9nica, por supuesto, es una terapia dirigida a cada paciente de manera individual. Consiste en reemplazar un gen mutado por uno funcional para corregir un defecto gen\u00e9tico causante de una patolog\u00eda. <\/div>\n<br>\n\n<div>Es fundamental el aporte de la tecnolog\u00eda para crecer en la ciencia de la medicina, y los modelos de machine learning\/inteligencia artificial tienen un papel primordial en este rol. Avanzar en el estudio gen\u00e9tico tiene un impacto crucial, ya que integrados podr\u00edan usarse para formular m\u00e9todos m\u00e1s afines para el diagn\u00f3stico y tratamiento del c\u00e1ncer, as\u00ed como para mejorar los m\u00e9todos de predicci\u00f3n de riesgo de c\u00e1ncer, pron\u00f3stico y reacci\u00f3n al tratamiento. Las herramientas gen\u00f3micas ser\u00e1n tambi\u00e9n esenciales para analizar resultados de estudios cl\u00ednicos de medicina de precisi\u00f3n.\n<\/div>\n","230d6180":"## The dataset contains clinics and genetics features without mutations. This is a master's thesis , that's the reason of the language . ","c60e9206":"#### Valores nulos","c4aa759d":"Hay que considerar que, si bien el conjunto total es 1904, en el eje x el valor llega hasta 1300 aproximadamente porque hay que contemplar la distribuci\u00f3n en el resto de las clases, donde su totalidad es 1904.","31100da3":"Creo el nuevo dataframe contemplando las variables cl\u00ednicas.","7108823c":"#### Regresi\u00f3n Log\u00edstica","12f4716b":"#### Histolog\u00eda del tumor vs A\u00f1os de supervivencia","65c96d9b":"Es posible heredar una mutaci\u00f3n en\u00a0BRCA1\u00a0o en\u00a0BRCA2\u00a0de uno de sus padres. Los hijos de una persona portadora de cualquiera de las mutaciones en uno de estos genes tiene una probabilidad del 50\u00a0% de heredar la mutaci\u00f3n y desarrolle c\u00e1ncer.","125f7411":"Se crea una lista `null_list` y se observa que hay *501 valores nulos*, lo cual mantiene una relaci\u00f3n con el gr\u00e1fico de barras previo.","5618f373":"De las 63 columnas que se encuentra en el dataset sin contar la variable objetivo, aplicando el m\u00e9todo de VarianceThreshold obtenemos que 41 variables son las que superan el umbral que se ha asignado.\nEn mi caso, primero utilizar\u00e9 todas las variables, si noto que el accuracy es demasiado peque\u00f1o, voy a contemplar las variables que obtuve en el paso anterior.","7e002295":"Como se mencionaba en las contras, se observa que el accuracy del training es 1, tambi\u00e9n las m\u00e9tricas han empeorado. Podr\u00edamos generalizar que en casi todos los modelos que se han probado hasta el momento, la clase 1 es la que presenta mayor dificultades para ser clasificada.","76caeaa8":"Si bien, en la lista anterior se tiene un detalle de la cantidad de no nulos por cada una de las variables, un gr\u00e1fico siempre es mejor visualizaci\u00f3n.\nLa columna de la derecha indica la cantidad de valores que posee cada una de las variables, si se visualiza `tumor_stage` por ejemplo, se obtiene que solamente contiene 1403 valores, con lo cual 1904-1403 = 501 valores son nulos.","5d36c0a8":"Las variables representadas muestran cierta discriminaci\u00f3n en general alrededor del punto 0, por ejemplo para el gen KI67 se nota en los valores 0 y negativos, para el chek2 en el valor 0 y positivos.","30fcf267":"Se utiliza el siguiente c\u00f3digo HTML para centrar la salida de cada uno de los gr\u00e1ficos.","7a3c57d1":"Queda como \u00faltimo paso declarar el diagrama de Venn, indicando como argumento la lista con los tama\u00f1os asociados a cada tratamiento, tambi\u00e9n se reutiliza la paleta de colores usada en todos los gr\u00e1ficos previos.","e71acde8":"### Ensemble Methods\n\nSe tratan de m\u00e9todos combinados que utilizan m\u00faltiples algoritmos de machine learning para obtener un mejor rendimiento predictivo. En el caso del boosting, cada modelo intenta arreglar los errores de los modelos anteriores. Tras la primera clasificaci\u00f3n, se dar\u00e1 m\u00e1s peso a las muestras mal clasificadas. En el caso de bagging, es un meta algoritmo que consigue combinaciones de modelos a trav\u00e9s de una familia inicial, provocando un menos overfitting y varianza. Consigue que los errores se compensen entre s\u00ed, entrenando cada modelo con subconjuntos del dataset original. El resultado es una combinaci\u00f3n.\n\nContras:\n\n* No siempre es bueno utilizarlo.\n* Suelen ser m\u00e1s complicados de interpretar.\n* Suele costar entrenarlos.","f09eb0ce":"En este caso, hubo mejoras en los datos obtenidos pero son casi insignificantes.","a9bab5fc":"El gr\u00e1fico de correlaci\u00f3n, nos da una idea de como se relacionan las variables, cuales est\u00e1n correlacionadas entre s\u00ed,y cuales no.\nPor ejemplo:\n\n* La histolog\u00eda del tumor est\u00e1 muy relacionado con los tipos de carcinoma (variables dummies que se crearon).\n* El tipo de c\u00e1ncer est\u00e1 asociado al \u00edndice de Nottingham.\n* El \u00edndice de Nottingham est\u00e1 relacionado con casi todas las variables.\n* El estado de los receptores de estr\u00f3geno, progesterona est\u00e1n relacionadon con el tratamiento de quimioterapia y el subtipo de c\u00e1ncer.\n"}}