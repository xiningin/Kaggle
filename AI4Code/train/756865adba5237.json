{"cell_type":{"c4fd7df1":"code","96b85f3f":"code","642dfe89":"code","92104b62":"code","8629238b":"code","f2e51a95":"code","ba5a7052":"code","8634014b":"code","57d49f62":"code","304e7cfb":"markdown","a97f9752":"markdown","a73a578a":"markdown","40b38ee9":"markdown","bcc2a69c":"markdown","00ca8ce7":"markdown"},"source":{"c4fd7df1":"fast_sub = True # set this to False to generate the whole dataset\ntrain = True # set this to True to generate the train set\ntest = True # set this to True to generate the test set","96b85f3f":"%%capture\n!python -m pip install gwpy\n!pip install astropy==4.2.1","642dfe89":"from gwpy.timeseries import TimeSeries\nfrom gwpy.plot import Plot\nimport numpy as np\nfrom scipy import signal\nfrom PIL import Image\n\nimport os\nimport pandas as pd\nimport numpy as np\nfrom tqdm.auto import tqdm\nfrom joblib import Parallel, delayed\nfrom pathlib import Path","92104b62":"def sig2rgb(fname, whiten = True, window=0.2, bandpass=False, f_range = (30,400), q_range = (16,32), q_max = 10):\n    \n    # Load the file \n    data = np.load(fname)\n    # Split each chanel and convert to TimeSeries\n    data = map(lambda x: TimeSeries(x, sample_rate=2048), data)\n    # Whiten the signal and apply a tukey window\n    data = map(lambda x: x.whiten(window=(\"tukey\", window)), data)\n    # (optional) bandpass filter\n    if bandpass:\n        data = map(lambda x: x.bandpass(*f_range), data)\n    # Q-transform\n    data = map(lambda x: x.q_transform(qrange=q_range, frange=f_range, logf=True, whiten=False), data)\n    # Convert to RGB image\n    img = np.stack(list(data), axis = -1)\n    img = np.clip(img, 0, q_max)\/q_max * 255\n    img = img.astype(np.uint8)\n    img = Image.fromarray(img).rotate(90, expand=1)\n    return img","8629238b":"sig2rgb('..\/input\/g2net-gravitational-wave-detection\/train\/0\/0\/0\/000a5b6e5c.npy')","f2e51a95":"def save_img(x, folder_out, **kwargs):\n    fname = Path('..\/input\/g2net-gravitational-wave-detection\/' + folder_out + '\/' + '\/'.join([x[0], x[1], x[2], x]) + '.npy')\n    file_out = folder_out + '\/' + fname.with_suffix('.jpg').name\n    x = sig2rgb(fname, **kwargs)\n    x.save(file_out)","ba5a7052":"from zipfile import ZipFile\nimport shutil\nimport os\ndef zip_folder(folder, rm_original = True):\n    # iterate over all the files in directory\n    for folderName, subfolders, filenames in os.walk(folder):\n        # create a ZipFile object\n        with ZipFile(folderName.split('\/')[-1] + '.zip', 'w') as zipObj:\n            for filename in filenames:\n                # create complete filepath of file in directory\n                filePath = os.path.join(folderName, filename)\n                # add file to zip\n                zipObj.write(filePath, os.path.basename(filePath))\n                # delete the file to open space\n                if rm_original:\n                    os.remove(filePath)\n    if rm_original:\n        shutil.rmtree(folder)","8634014b":"test_df = pd.read_csv('..\/input\/g2net-gravitational-wave-detection\/sample_submission.csv')\nif fast_sub: test_ids = test_df['id'][:100]\nelse: test_ids = test_df['id']\nif test:\n    os.makedirs('test', exist_ok = True)\n    o = Parallel(n_jobs=4)(delayed(save_img)(x, 'test') for x in tqdm(test_ids))\n    zip_folder('test')","57d49f62":"test_df = pd.read_csv('..\/input\/g2net-gravitational-wave-detection\/training_labels.csv')\nif fast_sub: test_ids = test_df['id'][:100]\nelse: test_ids = test_df['id']\nif train:\n    os.makedirs('train', exist_ok = True)\n    o = Parallel(n_jobs=4)(delayed(save_img)(x, 'train') for x in tqdm(test_ids))\n    zip_folder('train')","304e7cfb":"# Constant-Q Transform Preprocessing for G2Net Gravitational Wave Detection\n\nIf you find this notebook and dataset helpful, please, consider upvoting it. I took inspiration from the notebook of Geir Drange: https:\/\/www.kaggle.com\/mistag\/data-preprocessing-with-gwpy, so if give him an upvote too.\n\nIf you would like to use the pre-baked dataset I made, here are the links, but if you are here to learn how I did it, you are in the right place =)\n\n## Link to the dataset\n* **TRAIN DATASET PT1** https:\/\/www.kaggle.com\/coldfir3\/g2net-cqt-dataset-pt1-jpgrgb\n* **TRAIN DATASET PT2** https:\/\/www.kaggle.com\/coldfir3\/g2net-cqt-dataset-pt2-jpgrgb\n* **TRAIN DATASET PT3**: https:\/\/www.kaggle.com\/coldfir3\/g2net-cqt-dataset-pt3-jpgrgb\n* **TEST DATASET**: https:\/\/www.kaggle.com\/coldfir3\/g2net-cqt-dataset-test-jpgrgb\n\n## Explanation\nThis notebook inputs raw waveform data and outputs RGB images. For this, I employed the following pipeline:\n\n1. Read the .npy file and store it as a NumPy array.\n1. Convert each channel to a gwpy TimeSeries\n1. Whiten the signal and apply a Tukey window.\n1. (optional) Apply a bandpass filter. It is optional as `q_transform` will already do this. I also noticed that by not using this step the borders of the image are sharper.\n1. Apply the q-transform\n1. Convert to RGB:\n    1. Stack each channel on `dim = -1`\n    1. Clip the values to q_max and scale it from `[0, q_max]` to `[0, 255]`\n    1. Convert the array to unsigned 8 bits\n    1. Create the image and rotate it 90\u00ba, with frequency on the vertical axis and time on the horizontal axis.\n1. Save it as a .jpeg file\n\nThe main difference from Geir's notebook is the way I built the RGB images. Geir uses `MinMaxScaler` to normalize each channel to [0 - 1] before assembling the images in the original code. I think there are a couple of problems with this approach. 1) when using min-max coupled with the subsequent 8-bits discretization, outliers could wash out all the information contained in the image (i.e. the image would be mostly black). Secondly, if the signal is more potent in detector A when compared to detector B, you will lose this information by normalizing each channel independently.\n\nIt is worth noticing, though, that the default value I chose for the max_q was utterly arbitrary, and different values could lead to different results. The other defaults were ported from Geir's notebook, and I encourage you to experiment with different values and be kind to share your findings in the comment section below.","a97f9752":"## Installing and loading the dependencies","a73a578a":"### Test data","40b38ee9":"## Main processing function","bcc2a69c":"### Train data","00ca8ce7":"## Generating the dataset and ziping the files"}}