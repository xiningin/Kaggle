{"cell_type":{"9519c12b":"code","1899bbc6":"code","d1442768":"code","3f9e0c06":"code","29f59acb":"code","d5da33e0":"code","9d893395":"code","261e9584":"code","9ce4e5d1":"code","3e3bda08":"code","2fde8448":"code","366e4b53":"code","f96fbf67":"code","f3fc1439":"code","5acd11d7":"code","0d54f3ff":"code","a96408dd":"code","44181651":"code","f548103f":"code","d10c0f2c":"code","03997cf5":"code","e3adcf3c":"code","27567fa9":"code","8c927f4b":"code","e487a415":"code","2e9f8c0d":"code","01eabd5f":"code","8d85c8c8":"code","19f939a1":"code","032cb4e3":"code","76adc59d":"code","e0216961":"code","f69937da":"code","9a65590b":"code","8b5a93d6":"code","75a46c5c":"markdown","d716c234":"markdown"},"source":{"9519c12b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1899bbc6":"train_data = pd.read_csv('..\/input\/titanic\/train.csv')\ntrain_data.info()","d1442768":"train_data['Sex'] = [1 if sex == 'male' else 0 for sex in train_data['Sex']]","3f9e0c06":"train_data.groupby(['Pclass', 'Cabin'])['Fare'].mean()","29f59acb":"pd.qcut(train_data['Age'], q=5).value_counts()","d5da33e0":"data_corr = train_data.corr().abs().unstack().reset_index()\ndata_corr.rename(columns={'level_0': 'Feature 1', 'level_1': 'Feature 2', 0: 'Correlation Coefficient'},\n                 inplace=True)\ndata_corr.loc[data_corr['Feature 1'] == 'Age'].sort_values(by='Correlation Coefficient', ascending=False)","9d893395":"print(train_data.groupby(['Pclass', 'Parch', 'SibSp'])['Fare'].median().index)\ntrain_data.groupby(['Pclass', 'Parch', 'SibSp'])['Fare'].median()[3][0][0]","261e9584":"train_data.corr().unstack()","9ce4e5d1":" train_data[train_data['Pclass'] == 3]","3e3bda08":"train_data['Pclass'].unique()","2fde8448":"# Fill missing values in Age\nfor pc in [1, 2, 3]:\n    train_data.loc[train_data['Pclass'] == pc & train_data.Age.isnull(), 'Age'] = train_data.groupby('Pclass')['Age'].median()[pc]","366e4b53":"train_data.Age.isnull().any()","f96fbf67":"train_data.loc[train_data.Age.isnull(), 'Pclass'].unique()","f3fc1439":"def missing_counts(df):\n    for col in df.columns.tolist():\n        print('{} missing values:{}'.format(col, df[col].isnull().sum()))","5acd11d7":"missing_counts(train_data)","0d54f3ff":"train_data.head()","a96408dd":"train_data['Ticket'].describe()\n","44181651":"train_data['Sex'].value_counts()","f548103f":"train_data.loc[:, 'FamilySize'] = train_data['SibSp'] + train_data['Parch'] + 1\ntrain_data[['FamilySize', 'Survived']].groupby('FamilySize', as_index=False).mean().sort_values \\\n('FamilySize', ascending=False)","d10c0f2c":"train_data['IsAlone'] = 0\ntrain_data.loc[train_data.FamilySize == 1, ['IsAlone']] = 1\ntrain_data.IsAlone.value_counts(), train_data[['IsAlone', 'Survived']].groupby('IsAlone').mean()","03997cf5":"# 1. Deal with column Cabin - replace the existing values with 'Yes' and fill the missing values with 'No'\n\ndata_copy = train_data.copy()\ndata_copy.loc[data_copy.Cabin.notnull(), ['Cabin']] = 'Yes'\ndata_copy.loc[data_copy.Cabin.isnull(), ['Cabin']] = 'No'\nCabin_transformed = data_copy[['Cabin']]\n\nCabin_transformed['Cabin'].value_counts()","e3adcf3c":"train_data[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values \\\n(by='Survived', ascending=False)","27567fa9":"# 2. Deal with columns with categorical data\nSex_dm = pd.get_dummies(train_data['Sex'], prefix='Sex')\nCabin_dm = pd.get_dummies(Cabin_transformed, prefix='Cabin')\nEmbarked_dm = pd.get_dummies(train_data['Embarked'], prefix='Embarked')","8c927f4b":"# 3. Deal with column Age, which contains missing values\n\nAge_raw = train_data[['Age']]\nAge_full = Age_raw.fillna(train_data['Age'].mean())\nAge_full.isnull().any()","e487a415":"# 4. Concatenate DataFrames above \n\ntrain_X = pd.concat([Sex_dm, Age_full, train_data[['SibSp', 'Parch']], Cabin_dm, Embarked_dm], axis=1)\ntrain_y = train_data['Survived']","2e9f8c0d":"# Evaluate how different models perform. Here we choose four of the most representative models for classification -\n# random forest, logistic regression, adaptive boost, XGBoost\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import cross_val_score\n\n# 1. RandomForestClassifier\nrf = RandomForestClassifier()\nscore = cross_val_score(rf,\n                       train_X, train_y,\n                       scoring='roc_auc',\n                       cv=5).mean()\nprint('The mean roc_auc score for random forest is:', score)\n\n# 2. LogisticRegression\nlogit_reg = LogisticRegression()\nscore = cross_val_score(logit_reg,\n                       train_X, train_y,\n                       scoring='roc_auc',\n                       cv=5).mean()\nprint('The mean roc_auc score for logistic regression is:', score)\n\n# 3. AdaBoostClassifier\nada = AdaBoostClassifier()\nscore = cross_val_score(ada,\n                       train_X, train_y,\n                       scoring='roc_auc',\n                       cv=5).mean()\nprint('The mean roc_auc score for adaptive boost is:', score)\n\n# 4. XGBClassifier\nxgb = XGBClassifier()\nscore = cross_val_score(xgb,\n                       train_X, train_y,\n                       scoring='roc_auc',\n                       cv=5).mean()\nprint('The mean roc_auc score for XGBoost is:', score)","01eabd5f":"from sklearn.model_selection import GridSearchCV\n\nparams = {'n_estimators': [1000, 2000, 3000, 4000],\n          'max_depth': [5, 6, 7, 8],\n          'learning_rate': [0.05, 0.1, 0.2, 0.3]}\n\ngsCV = GridSearchCV(estimator=xgb,\n                   param_grid=params,\n                   scoring='roc_auc',\n                   cv=5)\n\ngsCV.fit(train_X, train_y)\nprint(gsCV.best_score_)\ngsCV.best_params_","8d85c8c8":"# Preprocess the test data similarly to training data\n\ntest_data = pd.read_csv('..\/input\/titanic\/test.csv')","19f939a1":"# 1. Deal with column Cabin - replace the existing values with 'Yes' and fill the missing values with 'No'\n\ntest_data_copy = test_data.copy()\ntest_data_copy.loc[test_data_copy.Cabin.notnull(), ['Cabin']] = 'Yes'\ntest_data_copy.loc[test_data_copy.Cabin.isnull(), ['Cabin']] = 'No'\ntest_Cabin_transformed = test_data_copy[['Cabin']]\n\ntest_Cabin_transformed['Cabin'].value_counts()","032cb4e3":"test_data['Sex'] = [1 if sex == 'male' else 0 for sex in test_data['Sex']]","76adc59d":"# 2. Deal with columns with categorical data\n\ntest_Sex_dm = pd.get_dummies(test_data['Sex'], prefix='Sex')\ntest_Cabin_dm = pd.get_dummies(test_Cabin_transformed, prefix='Cabin')\ntest_Embarked_dm = pd.get_dummies(test_data['Embarked'], prefix='Embarked')\ntest_Cabin_dm","e0216961":"# 3. Deal with column Age, which contains missing values\n\ntest_Age_raw = test_data[['Age']]\ntest_Age_full = test_Age_raw.fillna(test_data['Age'].mean())","f69937da":"# 4. Concatenate DataFrames above \n\ntest_X = pd.concat([test_Sex_dm, test_Age_full, test_data[['SibSp', 'Parch']], test_Cabin_dm, test_Embarked_dm], axis=1)\ntest_X","9a65590b":"# Make predictions for test data using the best found parametres\npredictions = gsCV.predict(test_X)\npredictions","8b5a93d6":"# Create output and upload it\noutput = pd.DataFrame({'PassengerId': test_data['PassengerId'], 'Survived': predictions})\noutput.to_csv('submission_V8.csv', index=False)","75a46c5c":"## Parametre Tuning","d716c234":"#### XGBoost yields best performance. And thus we choose it as our final model."}}