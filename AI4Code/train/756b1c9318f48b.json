{"cell_type":{"c7874964":"code","ef3c8f5e":"code","d9a4e8c0":"code","8988ad72":"code","fb5aa039":"code","26badf08":"code","56591331":"code","d5501497":"code","fcc7b833":"code","96e777db":"code","c54e887d":"code","6909989f":"code","ae5178c9":"markdown","609c7ca2":"markdown","4823c277":"markdown","d9d7cbea":"markdown","84c05114":"markdown"},"source":{"c7874964":"import numpy as np\nimport pandas as pd\nimport pathlib\n\nfrom sklearn.metrics import confusion_matrix\nfrom fastai import *\nfrom fastai.vision import *","ef3c8f5e":"DATA_DIR='..\/input\/dataset'","d9a4e8c0":"os.listdir(f'{DATA_DIR}')","8988ad72":"torch.cuda.is_available()","fb5aa039":"data = ImageDataBunch.from_folder(DATA_DIR, train=\".\",\n                                  valid_pct=0.2,\n                                  size=224, bs=10,\n                                  num_workers=0).normalize(imagenet_stats)","26badf08":"print(f'Classes: \\n {data.classes}')","56591331":"data.show_batch(rows=3, figsize=(7,6))","d5501497":"learn1 = cnn_learner(data, models.resnet18, metrics=accuracy, model_dir=\"\/tmp\/model\/\")\nlearn2 = cnn_learner(data, models.squeezenet1_0, metrics=accuracy, model_dir=\"\/tmp\/model\/\")\nlearn3 = cnn_learner(data, models.densenet201, metrics=accuracy, model_dir=\"\/tmp\/model\/\")","fcc7b833":"learn1.fit_one_cycle(5)\nlearn2.fit_one_cycle(5)\nlearn3.fit_one_cycle(5)","96e777db":"interp1 = ClassificationInterpretation.from_learner(learn1)\ninterp2 = ClassificationInterpretation.from_learner(learn2)\ninterp3 = ClassificationInterpretation.from_learner(learn3)","c54e887d":"interp1.plot_top_losses(15, figsize=(15,11))\ninterp2.plot_top_losses(15, figsize=(15,11))\ninterp3.plot_top_losses(15, figsize=(15,11))","6909989f":"interp1.plot_confusion_matrix(figsize=(8,8), dpi=60)\ninterp2.plot_confusion_matrix(figsize=(8,8), dpi=60)\ninterp3.plot_confusion_matrix(figsize=(8,8), dpi=60)","ae5178c9":"# Constru\u00e7\u00e3o do modelo\n\nTrecho retirado de https:\/\/docs.fast.ai\/vision.models.html\n\n\nThe fastai library includes several pretrained models from torchvision, namely:\n\n* resnet18, resnet34, resnet50, resnet101, resnet152\n* squeezenet1_0, squeezenet1_1\n* densenet121, densenet169, densenet201, densenet161\n* vgg16_bn, vgg19_bn\n* alexnet","609c7ca2":"Base de dados: https:\/\/www.kaggle.com\/cactus3\/basicshapes\n\nKernel de refer\u00eancia: https:\/\/www.kaggle.com\/kageyama\/fastai-shape-recognition-using-vgg16","4823c277":"# Verificando os resultados","d9d7cbea":"# Treino do modelo","84c05114":"# Leitura dos dados"}}