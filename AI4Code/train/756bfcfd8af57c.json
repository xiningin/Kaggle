{"cell_type":{"3770884a":"code","1c8accfa":"code","1c4e3064":"code","b809c702":"code","54aaeeab":"code","44e74b7c":"code","9903f356":"code","277e33b0":"code","a51854a1":"code","7361be90":"code","98c93c06":"code","7e4e52fa":"code","16229cc4":"code","2759a4f8":"code","3f441873":"code","cbd776c5":"code","157b9deb":"code","cdec51fe":"code","752cf68f":"code","b2230600":"markdown","2d4d43be":"markdown"},"source":{"3770884a":"import numpy as np, os \nimport pandas as pd, gc \nfrom tqdm import tqdm\nfrom sklearn.metrics import accuracy_score","1c8accfa":"VERSION = \"d14\" # \u4e3b\u9898\u8bcd\u7248\u672c\n\nSAVE_TOPWORD_NUM = 50 # \u7c7b\u578b\u8bcd \u6570\u91cf\uff08\u6bcf\u7c7b\uff09\n\nRUN_TYPE_KEYWORDS = False # \u662f\u5426\u91cd\u65b0\u8dd1 \u201c\u7c7b\u578b\u8bcd\u201c\n\nUSE_STOPWODS2 = True\nHANDLE_ERRER = False # \u76ee\u524d\u8fd8\u5f85\u4fee\u6539\u7684\u5730\u65b9","1c4e3064":"train_df = pd.read_csv('..\/input\/feedback-prize-2021\/train.csv')\nprint( train_df.shape )\ntrain_df.head()","b809c702":"discourse_types = ['Lead', 'Position', 'Claim', 'Counterclaim','Rebuttal','Evidence', 'Concluding Statement']","54aaeeab":"from collections import defaultdict\nfrom nltk.corpus import stopwords as nltk_stopwords\nfrom tqdm import tqdm\nfrom ast import literal_eval","44e74b7c":"import re\nimport pandas as pd\nfrom nltk import word_tokenize, pos_tag\nfrom nltk.corpus import wordnet\nfrom nltk.stem import WordNetLemmatizer\nimport string\nfrom nltk.stem import PorterStemmer\nfrom nltk.corpus import stopwords as nltk_stopwords\n\n# \u76ee\u5730\uff1a\u53e5\u5b50\u5904\u7406\uff0c\u53e5\u5b50\u7279\u5f81\u6316\u6398\n\ndef get_stopwords(): \n    # \u5907\u6ce8\uff1a \u5927\u8bcd\u8868\u4e0d\u597d\uff1a \u53ef\u80fd\u8bcd\u8868\u4e2d \u6709\u5927\u91cf\u8bcd\u8bed \u9700\u8981\u4fdd\u7559\uff0c\u5982because\u3001against\u7b49\u7b49 \n\n    stop_words = set(nltk_stopwords.words('english')) # \u5c0f\u8bcd\u8868\uff1a\u4e0d\u5230200\u8bcd\n    # print(len(stop_words),stop_words)\n    remain_words = ['should','can',\"can't\",\"couldn\",\"couldn't\",\"must\",\"mustn't\",\"mustn\",\"need\",\"needn't\", \"wouldn\",\"wouldn't\",\"shouldn\",\"shouldn't\",\"mightn't\",\"against\",\"because\"]\n    for w in remain_words:\n        if w in stop_words:\n            stop_words.remove(w)\n    # print(len(stop_words),stop_words)\n\n    customized_stopwords = ['student', 'people', 'make', 'school', 'teacher', 'be', 'college']\n    for token in customized_stopwords:\n        stop_words.add(token)\n\n    print(f'There are {len(stop_words)} default stop-words inlcuding customization.\\n')\n    print(\"-\"*100)\n    # print(f'There are {len(stopwords)} stop-words after customization.')\n    return stop_words\n\n\ndef split_charachers(text):\n    result_list = re.split('(\u3002|\uff01|\\!|\\.|\uff1f|\\?|,|\uff0c)| \\n', text)\n    return result_list\n\ndef remove_charachers(text):\n    _text = re.sub(r'(\u3002|\uff01|\\!|\\.|\uff1f|\\?|,|\\n)', \" \",text)\n    return _text\n\ndef sent2rawwords(sent):\n    #  \u83b7\u53d6\u5355\u8bcd\u7684\u8bcd\u6027\n    def get_wordnet_pos(tag):\n        if tag.startswith('J'):\n            return wordnet.ADJ\n        elif tag.startswith('V'):\n            return wordnet.VERB\n        elif tag.startswith('N'):\n            return wordnet.NOUN\n        elif tag.startswith('R'):\n            return wordnet.ADV\n        else:\n            return None\n    tagged_sent = pos_tag(sent)  # \u83b7\u53d6\u8bcd\u6027\n    wnl = WordNetLemmatizer()\n    lemmas_sent = []\n    for tag in tagged_sent:\n        wordnet_pos = get_wordnet_pos(tag[1]) or wordnet.NOUN\n        lemmas_sent.append(wnl.lemmatize(tag[0], pos=wordnet_pos))  # \u8bcd\u5f62\u8fd8\u539f\n    return lemmas_sent\n\n\ndef clean_text(sentence, stopwords, lemma = False):\n    sentence = sentence.lower()\n    # 1. \u4f7f\u7528EduNLP\n    # tokenzier = PureTextTokenizer()\n    # token_item = tokenzier([sentence])\n    # text = [word for word in next(token_item) if word not in stopwords]\n    \n    # 2. \u4f7f\u7528nltk \n    # \uff081\uff09\u7b26\u53f7\u6e05\u6d17 #\uff08\u6ce8\u610f\u662f\u5426\u9700\u8981\u4fee\u6539\uff09\n    sent = remove_charachers(sentence) # V2 \n    # print(\"check 1:::\", sentence)\n    text_raw_list = sent.split() # Vb # \u4e0d\u7528strip()\n    # print(\"check 2:::\", text_raw_list)\n    # \uff082\uff09. \u8bcd\u5f62\u8fd8\u539f\n    if lemma:\n        text_raw_list = sent2rawwords(text_raw_list) # V1-5\n    # print(\"check 3:::\", text_raw_list)\n    # print(\"text_raw_list : \",text_raw_list)\n    # \uff083\uff09. \u505c\u7528\u8bcd \u8fc7\u6ee4\n    text = [word for word in text_raw_list if word not in stopwords]\n    if \"student\" in text:\n        raise ValueError(\"What the fuck???!!!\")\n    # print(\"check 4:::\", text)\n    return \" \".join(text).strip()\n\n\n# \u8bcd\u5f62\u8fd8\u539f2\uff08\u6548\u679c\u4e0d\u597d\uff1a\u4e0d\u4f7f\u7528\uff09\ndef stem_text(sentence):\n    ps = PorterStemmer()\n    sent = []\n    for word in sentence:\n        sent.append(ps.stem(word))\n    return \" \".join(sent)\n\n# if STEM_TEXT:\n#     text = [t.split() for t in train_text_df[\"text\"].tolist()]\n\n#     stemmed_text = []\n#     ps = PorterStemmer()\n#     for sentence in tqdm(text):\n#         stemmed_text.append(stem_text(sentence))\n\n#     train_text_df[\"text_stemmed\"] = [\" \".join(l) for l in stemmed_text]\n#     train_text_df.to_csv(f\"..\/..\/input\/feedback-prize-2021\/train_essay_stemmed_{DATA_VERSION}.csv\", index=False, sep=',')\n# else:\n#     train_text_df = pd.read_csv(f\"..\/..\/input\/feedback-prize-2021\/train_essay_stemmed_{DATA_VERSION}.csv\")\n\n\n\n# if CLEAN_TEXT:\n#     stopwords = get_stopwords()\n#     texts = []\n#     for sentence in tqdm(train_text_df[\"text_stemmed\"].values):\n#         sentence = clean_text(sentence, stopwords)\n#         if not sentence:\n#             sentence = \"\"\n#         texts.append(sentence)\n#     train_text_df[\"text_stemmed_cleaned\"] = texts\n#     train_text_df.to_csv(f\".\/train_essay_stemmed_cleaned_{DATA_VERSION}.csv\", index=False, sep=',')\n# else:\n#     train_text_df = pd.read_csv(f\".\/train_essay_stemmed_cleaned_{DATA_VERSION}.csv\")","9903f356":"# # \u6d4b\u8bd5\u8bcd\u6027\u8fd8\u539f\n# test_sent = \"In mars, If the Students asks both his Friends and his doctors, he wouldn't able to use his judgemental skills to determing which choice will be best for him in the long run.\"\n\n# _s1 = stem_text(test_sent.split()) # \u4e0d\u591f\u667a\u80fd\uff0c\u8bcd\u5f62\u8fd8\u539f\u6709\u65f6\u9519\u8bef\u8fd8\u539f\n# _s2 = \" \".join(sent2rawwords(test_sent.lower().split())) # \u4e0d\u591f\u667a\u80fd\uff0c\u8bcd\u5f62\u8fd8\u539f\u6709\u65f6\u9519\u8bef\u8fd8\u539f\n# stopwords = get_stopwords()\n# _s3 = clean_text(test_sent, stopwords, lemma=True)\n\n# print(\"-\"*50,\"\\n\",_s1)\n# print(\"-\"*50,\"\\n\",_s2)\n# print(\"-\"*50,\"\\n\",_s3)\n# -------------------------------------------------- \n#  in mars, if the student ask both hi friend and hi doctors, he wouldn't abl to use hi judgement skill to determ which choic will be best for him in the long run.\n# -------------------------------------------------- \n#  in mars, if the student ask both his friend and his doctors, he wouldn't able to use his judgemental skill to determing which choice will be best for him in the long run.\n# -------------------------------------------------- \n#  mars, ask friend doctors, wouldn't able use judgemental skill determing choice best long run.","277e33b0":"def get_frequent_stopwords(corpus, _stop_words):\n    dic= defaultdict(int)\n    for word in corpus:\n        if word in _stop_words:\n            dic[word]+=1\n\n    # getting the top 20 most frequent stop words        \n    top=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:20]\n    \n    return top, dic\n\ncorpus = []\ntrain_df[\"words\"] = train_df[\"discourse_text\"].apply(lambda x: x.split())\nfor item in tqdm(train_df[\"words\"].values):\n    # print(item)\n    corpus.extend(item)\n# corpus\n\n_stop_words = get_stopwords()\ntop, dic = get_frequent_stopwords(corpus, _stop_words)\n\nprint(f'Total number of stop words in spacy: {len(_stop_words)}')\nprint(f'Total number of stop words in the given text data which are part of the spacy\\'s stop words list: {len(dic)}')\nprint(f\"top words: {top}\")\n\nimport matplotlib.pyplot as plt\n# top 20 most frequent stop words in our corpus:\nplt.figure(figsize = (15,4))\nx,y=zip(*top)\nplt.bar(x,y, color='goldenrod')","a51854a1":"import pickle\nfrom sklearn.feature_extraction.text import TfidfVectorizer","7361be90":"# topic_set","98c93c06":"# ------------------------------------ \u52a0\u8f7d\u4e3b\u9898\u8bcd -------------------------------------- #\nwith open(f'..\/input\/myfeedbackdata\/predata\/topic\/topic_words_{VERSION}.pkl', 'rb') as pkl_file:\n  all_topic_words = pickle.load(pkl_file)\n\ntopic_set = [] # [(word, weight)]\ntopic_num = 0\nfor _list in all_topic_words:\n  topic_set.extend(_list)\n  topic_num +=1\n\ntopic_set = set(topic_set)\n\ntopic_word_2_weight = {k:v for k,v in topic_set} # \u65e0\u9700\u4e0d\u8003\u8651\u91cd\u590d\u7684\u4e3b\u9898\u8bcd\u7684\u6743\u503c\ntopic_word_set = set(topic_word_2_weight.keys())\n\nprint(f\"There are {len(topic_word_2_weight)} topic words in {topic_num} topic !\")\n\n# ---------------------------------- \u5904\u7406\u7c7b\u578b\u8bcd ---------------------------------------- #\nMY_STOPWORDS = get_stopwords()  # \u505c\u7528\u8bcd\n\ndef get_tfdif_keywords(text_list):\n  from sklearn.feature_extraction.text import TfidfVectorizer\n  text_list = [\"i am  a fucking student\"] + text_list\n  for text in text_list:\n    # if 'car' in text.split():\n    #   raise ValueError(\"3 car Something wrong!, car in still in _text_list_f\")\n    if HANDLE_ERRER and \"student\" in text.split():\n        raise ValueError(\"3 student Something wrong!, car in still in _text_list_f\")\n\n  _stop_words = \"english\" if USE_STOPWODS2 else None\n  _tfidf = TfidfVectorizer(stop_words=_stop_words, binary=True, max_features=25_000) # stop_words='english'\n  text_embeddings = _tfidf.fit_transform( text_list ).toarray()\n  print(\"shape of text_embeddings\",text_embeddings.shape)\n  print(\"len of features\",len(_tfidf.get_feature_names()))\n  mm = np.mean( text_embeddings, axis=0 )\n  ii = np.argsort(mm)[-SAVE_TOPWORD_NUM:][::-1].tolist()\n  # print(\"test ii:::\",ii)\n  # print(ii)\n  top_words = [(_tfidf.get_feature_names()[i], mm[i]) for i in ii]\n  # print(_tfidf.get_feature_names())\n  # if 'car' in _tfidf.get_feature_names():\n  #   raise ValueError(\"4 car Something wrong!, car in still in _text_list_f\")\n  if HANDLE_ERRER and  \"student\" in _tfidf.get_feature_names():\n    raise ValueError(\"4 student Something wrong!, car in still in _text_list_f\")\n\n  print(f\"{SAVE_TOPWORD_NUM} top words: \\n\",*top_words[:15])\n  return top_words\n\ndef clean_discourse(text):\n  # \u8fc7\u6ee4\u505c\u7528\u8bcd\n  text = clean_text(text, MY_STOPWORDS, lemma=True)\n  # \u8fc7\u6ee4\u4e3b\u9898\u8bcd\n  text_list = text.strip().split()\n  # for word in text_list:\n  #   if word not in topic_word_set:\n  #     text_list.append(word)\n    \n  _text_list_f = [word for word in text_list if word not in topic_word_set]\n  if HANDLE_ERRER and  'car' in _text_list_f or \"student\" in _text_list_f:\n    raise ValueError(\"2 Something wrong!, car in still in _text_list_f\")\n  return \" \".join(_text_list_f)\n\ndef get_keywords_by_type(_type):\n\n  \n  text_list = train_df.loc[train_df[\"discourse_type\"] == _type, \"discourse_text\"].values\n  text_list2 = []\n  for text in  tqdm(text_list):\n    _text = clean_discourse(text)\n    if HANDLE_ERRER and 'car' in _text.split() or \"student\" in _text.split():\n      raise ValueError(\"1 Something wrong!, car in still in _text_list_f\")\n    text_list2.append(_text)\n  text_list2 = [\"i am a fucking student\"] + text_list2\n  print(text_list2[:5])\n  top_words = get_tfdif_keywords(text_list2)    \n\n  return top_words","7e4e52fa":"# \u6d4b\u8bd5\ntext_list2 = []\ntext = \"the fucking students,and student ,the cars, is in the outside, you are good!\"\ntext = clean_discourse(text)\nprint(text.split())\ntext_list2.append(text)\n\ntop_wprds = get_tfdif_keywords(text_list2)\ntop_wprds","16229cc4":"XX = np.array([[1,2,3,4]])\nprint(XX)\nprint(XX.flatten())\n","2759a4f8":"# # \u6d4b\u8bd5 TFIDF\n# from sklearn.feature_extraction.text import TfidfVectorizer\n# corpus = [\n#      'This is the first document.',\n#      'This document is the second document.',\n#      'And this is the third one.',\n#      'Is this the first document?',\n#  ]\n# vectorizer = TfidfVectorizer()\n# X = vectorizer.fit_transform(corpus).toarray()\n# pre = vectorizer.get_feature_names()\n# print(pre)\n# print(X.shape)\n\n# mm = np.mean( X, axis=0 )\n# print(mm)\n# x1 = np.argsort(mm)\n# print(\"x1\",type(x1),x1.shape,x1)\n# # print(\"x1\", np.array(x1).flatten())\n# # print(\"x1\", x1.tolist()[0])\n\n# # x2 = x1[-3:][::1]\n# # print(\"x2\", x2)\n\n# ii = np.argsort(mm)[-3:][::-1].tolist()\n# print(ii)\n# # print(ii)\n# top_words = [(vectorizer.get_feature_names()[i], mm[i]) for i in ii]\n# print(top_words)\n# print(vectorizer.vocabulary_[\"this\"])\n\n# # \u6d4b\u8bd5\n# get_tfdif_keywords(corpus)","3f441873":"# \u6d4b\u8bd5\uff0c\u6709\u8fc7\u6ee4\u4e0d\u5f7b\u5e95\u7684\u95ee\u9898\uff01\uff01\uff01\uff01\uff01\uff01\n# tt = get_keywords_by_type(\"Lead\")","cbd776c5":"if RUN_TYPE_KEYWORDS: # \u5904\u7406 \u7c7b\u578b\u8bcd\n  all_type_words = dict()\n  for _type in discourse_types:\n    all_type_words[_type] = get_keywords_by_type(_type)\n  print(\"Save the results.....\")\n  # \u4fdd\u5b58 \u7c7b\u578b\u8bcd\n  with open(f'type_words_{VERSION}.pkl', 'wb') as output:\n    pickle.dump(all_type_words, output)\n\nelse: # \u76f4\u63a5\u52a0\u8f7d \u7c7b\u578b\u8bcd\n  with open(f'..\/input\/myfeedbackdata\/predata\/type\/type_words_{VERSION}.pkl', 'rb') as pkl_file:\n    all_type_words = pickle.load(pkl_file)\n  ","157b9deb":"# \u67e5\u770b\u7c7b\u578b\u8bcd\u8bed\nfor k,v in all_type_words.items():\n  print(f\"---------{k}--------------\")\n  tt = [t for t, _ in  v]\n  print(tt)","cdec51fe":"# The wrong res\n# ---------Lead--------------\n# ['think', 'car', 'advice', 'ask', 'like', 'good', 'time', 'way', 'help', 'use', 'know', 'want', 'class', 'home', 'person', 'need', 'electoral', 'thing', 'phone', 'learn', 'online', 'school', 'driverless', 'summer', 'say', 'opinion', 'work', 'face', 'activity', 'life', 'technology', 'new', 'project', 'drive', 'idea', 'world', 'learning', 'come', 'cell', 'vote', 'attend', 'talk', 'able', 'multiple', 'day', 'extracurricular', 'change', 'year', 'president', 'really']\n# ---------Position--------------\n# ['think', 'good', 'car', 'believe', 'use', 'electoral', 'idea', 'opinion', 'class', 'benefit', 'phone', 'help', 'driverless', 'project', 'multiple', 'community', 'able', 'home', 'activity', 'advice', 'ask', 'service', 'policy', 'summer', 'participate', 'change', 'agree', 'vote', 'extracurricular', 'attend', 'choice', 'person', 'cell', 'way', 'online', 'seek', 'great', 'venus', 'reason', 'design', 'limit', 'face', 'popular', 'like', 'thing', 'usage', 'technology', 'allow', 'designed', 'drive']\n# ---------Claim--------------\n# ['help', 'good', 'car', 'time', 'reason', 'work', 'think', 'learn', 'need', 'class', 'use', 'like', 'electoral', 'thing', 'phone', 'know', 'want', 'way', 'vote', 'able', 'different', 'home', 'advice', 'project', 'activity', 'community', 'kid', 'opinion', 'venus', 'person', 'allow', 'ask', 'new', 'online', 'drive', 'life', 'driverless', 'lot', 'school', 'idea', 'feel', 'state', 'president', 'cell', 'say', 'technology', 'benefit', 'face', 'sport', 'cause']\n# ---------Counterclaim--------------\n# ['say', 'think', 'electoral', 'argue', 'class', 'time', 'good', 'car', 'like', 'work', 'online', 'home', 'project', 'phone', 'want', 'vote', 'thing', 'know', 'use', 'believe', 'help', 'need', 'way', 'learn', 'reason', 'idea', 'hand', 'bad', 'kid', 'benefit', 'state', 'yes', 'driverless', 'alien', 'face', 'able', 'learning', 'design', 'drive', 'president', 'problem', 'summer', 'understand', 'attend', 'community', 'life', 'cell', 'designed', 'service', 'school']\n# ---------Rebuttal--------------\n# ['time', 'think', 'help', 'good', 'thing', 'like', 'vote', 'work', 'need', 'way', 'know', 'want', 'class', 'learn', 'use', 'phone', 'project', 'car', 'true', 'really', 'online', 'wrong', 'say', 'electoral', 'life', 'home', 'able', 'happen', 'benefit', 'problem', 'reason', 'state', 'come', 'kid', 'school', 'believe', 'lot', 'idea', 'change', 'mean', 'president', 'best', 'feel', 'day', 'try', 'actually', 'design', 'community', 'allow', 'popular']\n# ---------Evidence--------------\n# ['help', 'like', 'time', 'good', 'know', 'want', 'work', 'think', 'need', 'thing', 'say', 'car', 'way', 'use', 'class', 'example', 'able', 'state', 'person', 'phone', 'vote', 'ask', 'learn', 'home', 'life', 'day', 'school', 'lot', 'really', 'friend', 'come', 'drive', 'tell', 'kid', 'try', 'feel', 'electoral', 'new', 'different', 'advice', 'look', 'reason', 'cause', 'president', 'best', 'talk', 'bad', 'grade', 'sport', 'project']\n# ---------Concluding Statement--------------\n# ['good', 'think', 'help', 'way', 'time', 'conclusion', 'need', 'thing', 'car', 'like', 'want', 'use', 'life', 'know', 'reason', 'learn', 'idea', 'opinion', 'work', 'electoral', 'change', 'ask', 'best', 'phone', 'believe', 'advice', 'say', 'able', 'class', 'person', 'benefit', 'new', 'school', 'great', 'choice', 'really', 'vote', 'world', 'multiple', 'community', 'different', 'future', 'lot', 'come', 'allow', 'activity', 'driverless', 'feel', 'policy', 'drive']\n\n#------------------ \u7ecf\u8fc7\u5904\u7406\u540e-------------------------#\n\n# ---------Lead--------------\n# ['imagine', 'question', 'big', 'everyday', 'start', 'wonder', 'consider', 'mean', 'actually', 'sure', 'debate', 'society', 'write', 'instead', 'issue', 'dont', 'family', 'mind', 'student', 'end', 'certain', 'daily', 'designed', 'teacher', 'sound', 'fact', 'difficult', 'usually', 'america', 'letter', 'negative', 'public', 'father', 'course', 'argue', 'making', 'type', 'possible', 'positive', 'disagree', 'probably', 'thought', 'today', 'order', 'second', 'past', 'explain', 'driverless', 'chance', 'real']\n# ---------Position--------------\n# ['designed', 'disagree', 'shouldn', 'student', 'yes', 'personally', 'teacher', 'favor', 'suggest', 'actually', 'strongly', 'instead', 'dont', 'development', 'useful', 'venus', 'fact', 'argue', 'consider', 'positive', 'face', 'claim', 'worth', 'rid', 'explain', 'mandatory', 'big', 'number', 'smart', 'matter', 'capacity', 'driveless', 'america', 'start', 'negative', 'wouldn', 'self', 'position', 'belive', 'write', 'develop', 'society', 'type', 'im', 'greatly', 'collage', 'possible', 'mean', 'provide', 'completely']\n# ---------Claim--------------\n# ['chance', 'second', 'actually', 'big', 'dont', 'family', 'mean', 'skill', 'provide', 'wouldn', 'start', 'issue', 'improve', 'certain', 'student', 'fact', 'instead', 'lastly', 'shouldn', 'increase', 'finally', 'sure', 'self', 'mind', 'outcome', 'meet', 'lose', 'prevent', 'ability', 'designed', 'worry', 'spend', 'responsibility', 'possible', 'freedom', 'end', 'secondly', 'probably', 'avoid', 'case', 'health', 'open', 'matter', 'type', 'receive', 'smart', 'final', 'outside', 'test', 'public']\n# ---------Counterclaim--------------\n# ['argue', 'yes', 'designed', 'disagree', 'waste', 'teacher', 'student', 'argument', 'dont', 'course', 'sure', 'case', 'actually', 'claim', 'wouldn', 'fact', 'probably', 'avoid', 'true', 'public', 'possible', 'outcome', 'certain', 'issue', 'mean', 'big', 'chance', 'sound', 'theorist', 'negative', 'lazy', 'wont', 'conspiracy', 'family', 'lose', 'marking', 'haze', 'start', 'positive', 'receive', 'worry', 'provide', 'cheat', 'downside', 'instead', 'skill', 'opponent', 'question', 'flaw', 'cool']\n# ---------Rebuttal--------------\n# ['true', 'mean', 'actually', 'fact', 'case', 'dont', 'end', 'big', 'wouldn', 'chance', 'matter', 'reality', 'start', 'thats', 'worth', 'sure', 'real', 'simply', 'skill', 'student', 'disagree', 'shouldn', 'instead', 'public', 'easily', 'certain', 'possible', 'designed', 'trust', 'far', 'leave', 'issue', 'self', 'course', 'realize', 'provide', 'wish', 'argument', 'avoid', 'yes', 'completely', 'positive', 'false', 'teacher', 'question', 'hurt', 'freedom', 'flaw', 'negative', 'probably']\n# ---------Evidence--------------\n# ['mean', 'start', 'dont', 'wouldn', 'big', 'family', 'instead', 'end', 'chance', 'actually', 'sure', 'probably', 'test', 'leave', 'fact', 'lose', 'certain', 'mind', 'spend', 'question', 'worry', 'case', 'house', 'matter', 'skill', 'group', 'result', 'type', 'second', 'thats', 'issue', 'far', 'self', 'possible', 'public', 'small', 'number', 'wont', 'trust', 'old', 'pass', 'young', 'large', 'hold', 'outside', 'order', 'stuff', 'accord', 'include', 'real']\n# ---------Concluding Statement--------------\n# ['end', 'overall', 'chance', 'dont', 'shouldn', 'big', 'sure', 'instead', 'consider', 'improve', 'fact', 'matter', 'student', 'mean', 'provide', 'start', 'skill', 'actually', 'family', 'mind', 'possible', 'wouldn', 'designed', 'finally', 'thats', 'positive', 'worth', 'conclude', 'leave', 'disagree', 'self', 'trust', 'society', 'question', 'open', 'remember', 'yes', 'smart', 'outcome', 'real', 'meet', 'teacher', 'issue', 'increase', 'worry', 'lose', 'public', 'probably', 'useful', 'effect']\n\n\n#------------------ \u6700\u7ec8\u5904\u7406\u540e\uff08TFIDF\u7edf\u8ba1\u65f6\u4f7f\u7528\u505c\u7528\u8bcd\uff09\uff08d14\u7248\u672c\uff09-------------------------#\n# ---------Lead--------------\n# ['imagine', 'question', 'big', 'everyday', 'start', 'wonder', 'consider', 'mean', 'actually', 'sure', 'debate', 'society', 'write', 'instead', 'issue', 'family', 'dont', 'mind', 'end', 'student', 'certain', 'daily', 'designed', 'teacher', 'sound', 'fact', 'difficult', 'father', 'usually', 'america', 'negative', 'letter', 'public', 'course', 'force', 'argue', 'making', 'possible', 'type', 'positive', 'disagree', 'probably', 'thought', 'today', 'order', 'past', 'explain', 'driverless', 'matter', 'real']\n# ---------Position--------------\n# ['designed', 'disagree', 'shouldn', 'student', 'yes', 'personally', 'teacher', 'favor', 'suggest', 'actually', 'strongly', 'instead', 'dont', 'force', 'development', 'useful', 'fact', 'venus', 'argue', 'consider', 'positive', 'face', 'claim', 'worth', 'rid', 'explain', 'mandatory', 'big', 'number', 'smart', 'matter', 'capacity', 'america', 'driveless', 'start', 'negative', 'wouldn', 'self', 'belive', 'position', 'write', 'develop', 'society', 'im', 'type', 'greatly', 'collage', 'possible', 'provide', 'mean']\n# ---------Claim--------------\n# ['actually', 'big', 'dont', 'family', 'mean', 'skill', 'provide', 'wouldn', 'start', 'issue', 'improve', 'certain', 'student', 'fact', 'instead', 'lastly', 'increase', 'shouldn', 'sure', 'finally', 'self', 'mind', 'meet', 'outcome', 'lose', 'prevent', 'ability', 'designed', 'spend', 'worry', 'responsibility', 'force', 'possible', 'freedom', 'end', 'secondly', 'avoid', 'case', 'probably', 'open', 'health', 'type', 'matter', 'receive', 'smart', 'final', 'public', 'outside', 'real', 'test']\n# ---------Counterclaim--------------\n# ['argue', 'yes', 'designed', 'disagree', 'waste', 'teacher', 'student', 'argument', 'dont', 'course', 'sure', 'case', 'actually', 'claim', 'wouldn', 'fact', 'avoid', 'probably', 'true', 'public', 'possible', 'outcome', 'issue', 'certain', 'big', 'mean', 'sound', 'theorist', 'negative', 'lazy', 'wont', 'lose', 'family', 'conspiracy', 'marking', 'start', 'haze', 'positive', 'receive', 'worry', 'provide', 'cheat', 'downside', 'instead', 'skill', 'opponent', 'flaw', 'question', 'cool', 'difficult']\n# ---------Rebuttal--------------\n# ['true', 'mean', 'actually', 'fact', 'case', 'dont', 'end', 'big', 'wouldn', 'matter', 'reality', 'thats', 'start', 'worth', 'simply', 'sure', 'real', 'skill', 'student', 'disagree', 'shouldn', 'public', 'instead', 'easily', 'force', 'certain', 'possible', 'designed', 'far', 'self', 'leave', 'issue', 'course', 'realize', 'provide', 'argument', 'wish', 'avoid', 'yes', 'completely', 'positive', 'false', 'teacher', 'hurt', 'question', 'freedom', 'flaw', 'negative', 'probably', 'prevent']\n# ---------Evidence--------------\n# ['mean', 'start', 'dont', 'wouldn', 'big', 'family', 'end', 'instead', 'actually', 'sure', 'probably', 'test', 'fact', 'leave', 'lose', 'certain', 'mind', 'spend', 'question', 'worry', 'case', 'house', 'matter', 'group', 'skill', 'type', 'thats', 'result', 'issue', 'far', 'possible', 'self', 'public', 'force', 'small', 'number', 'young', 'wont', 'old', 'pass', 'hold', 'large', 'outside', 'order', 'stuff', 'include', 'accord', 'real', 'explain', 'provide']\n# ---------Concluding Statement--------------\n# ['end', 'overall', 'dont', 'sure', 'shouldn', 'big', 'instead', 'consider', 'improve', 'fact', 'matter', 'student', 'mean', 'provide', 'start', 'actually', 'skill', 'family', 'mind', 'possible', 'force', 'wouldn', 'designed', 'finally', 'thats', 'positive', 'worth', 'conclude', 'leave', 'disagree', 'self', 'society', 'open', 'question', 'remember', 'yes', 'smart', 'outcome', 'real', 'meet', 'teacher', 'issue', 'increase', 'worry', 'lose', 'public', 'useful', 'probably', 'effect', 'ability']\n\n#------------------ (TFIDF\u7edf\u8ba1\u65f6\u4e0d\u7528\u505c\u7528\u8bcd)-------------------------#\n# ---------Lead--------------\n# ['can', 'many', 'one', 'should', 'would', 'get', 'go', 'ever', 'take', 'because', 'could', 'well', 'may', 'even', 'something', 'also', 'give', 'system', 'others', 'someone', 'keep', 'see', 'whether', 'everyone', 'sometimes', 'every', 'around', 'always', 'become', 'might', 'call', 'however', 'much', 'find', 'imagine', 'still', 'least', 'big', 'question', 'seem', 'everyday', 'start', 'although', 'consider', 'two', 'mean', 'wonder', 'part', 'actually', 'must']\n# ---------Position--------------\n# ['should', 'would', 'can', 'one', 'many', 'because', 'keep', 'get', 'go', 'take', 'could', 'well', 'system', 'designed', 'least', 'someone', 'disagree', 'shouldn', 'student', 'give', 'may', 'even', 'against', 'something', 'also', 'others', 'much', 'everyone', 'although', 'yes', 'see', 'teacher', 'personally', 'favor', 'suggest', 'strongly', 'must', 'actually', 'every', 'become', 'the', 'however', 'always', 'instead', 'dont', 'might', 'find', 'development', 'force', 'though']\n# ---------Claim--------------\n# ['can', 'because', 'would', 'get', 'also', 'could', 'should', 'one', 'take', 'go', 'give', 'many', 'another', 'may', 'might', 'something', 'see', 'even', 'less', 'well', 'first', 'others', 'someone', 'much', 'system', 'keep', 'find', 'show', 'everyone', 'still', 'become', 'around', 'always', 'put', 'big', 'call', 'actually', 'dont', 'skill', 'every', 'provide', 'family', 'mean', 'last', 'sometimes', 'without', 'wouldn', 'already', 'start', 'issue']\n# ---------Counterclaim--------------\n# ['may', 'would', 'because', 'can', 'might', 'many', 'argue', 'could', 'get', 'although', 'take', 'also', 'should', 'go', 'one', 'even', 'though', 'however', 'still', 'yes', 'well', 'others', 'see', 'keep', 'system', 'give', 'much', 'designed', 'something', 'disagree', 'sometimes', 'another', 'waste', 'everyone', 'teacher', 'someone', 'student', 'side', 'less', 'always', 'argument', 'dont', 'sure', 'course', 'call', 'seem', 'claim', 'case', 'actually', 'become']\n# ---------Rebuttal--------------\n# ['would', 'can', 'because', 'however', 'get', 'should', 'take', 'still', 'could', 'go', 'one', 'many', 'also', 'even', 'may', 'well', 'true', 'give', 'something', 'much', 'others', 'see', 'system', 'though', 'always', 'mean', 'everyone', 'actually', 'might', 'although', 'find', 'fact', 'show', 'case', 'every', 'keep', 'put', 'less', 'that', 'dont', 'enough', 'another', 'end', 'without', 'someone', 'around', 'big', 'wouldn', 'matter', 'since']\n# ---------Evidence--------------\n# ['can', 'get', 'would', 'because', 'go', 'could', 'also', 'one', 'take', 'even', 'should', 'give', 'many', 'something', 'see', 'may', 'might', 'someone', 'well', 'much', 'another', 'show', 'always', 'around', 'still', 'find', 'keep', 'mean', 'others', 'put', 'system', 'everyone', 'every', 'become', 'start', 'dont', 'back', 'big', 'less', 'without', 'sometimes', 'call', 'wouldn', 'first', 'instead', 'anything', 'end', 'family', 'actually', 'since']\n# ---------Concluding Statement--------------\n# ['should', 'can', 'because', 'would', 'get', 'one', 'many', 'go', 'take', 'could', 'also', 'give', 'see', 'well', 'even', 'something', 'may', 'keep', 'much', 'others', 'everyone', 'always', 'system', 'someone', 'might', 'still', 'find', 'put', 'less', 'show', 'become', 'every', 'around', 'end', 'overall', 'that', 'never', 'dont', 'without', 'big', 'sure', 'instead', 'shouldn', 'next', 'consider', 'least', 'though', 'please', 'improve', 'fact']","752cf68f":"import matplotlib.pyplot as plt\n\nSHOW_NUM = 20\nx=range(0, SHOW_NUM)\n\nfig, ax = plt.subplots( len(discourse_types) , 1, figsize = (20, 50))\nfig.suptitle(F'Top {SHOW_NUM} Bigrams of the TF-IDF', fontsize= 18)\n\n\nfor i, _type in enumerate(discourse_types):\n  _pairs = all_type_words[_type]\n  \n  sorted(_pairs,key=(lambda x:x[1]),reverse=True)\n  \n  y, words = [], []\n  for k,v in _pairs[:SHOW_NUM]:\n    y.append(v)\n    words.append(k)\n\n  print(len(y))\n  ax[i].plot(x, y, 'bo')\n  ax[i].set_title(_type, fontsize= 14)\n  ax[i].set_xticks(x)\n  ax[i].set_xticklabels(words, rotation='vertical', fontsize=10)\n\nfig.subplots_adjust(hspace=1.5)\nplt.show()","b2230600":"## \u6587\u672c\u6e05\u7406","2d4d43be":"## \u63d0\u53d6\u7c7b\u578b\u5173\u952e\u8bcd"}}