{"cell_type":{"77b3c6e0":"code","c233ca2f":"code","b79e5efe":"code","9c0e2fe1":"code","79687cb8":"code","9570d442":"code","f14f47a7":"code","3233f4c0":"code","c02c623d":"code","3c8245a8":"code","f1118e47":"code","223bb5e9":"code","3b7aaf19":"code","6819a6fb":"code","ed7f2e80":"code","ecd33b99":"markdown","8dcbe2c5":"markdown","daf17ea6":"markdown","26e1e641":"markdown","bba9a947":"markdown","65b03969":"markdown","159b50ee":"markdown","e7214fd3":"markdown","41bc119c":"markdown","d3e8833e":"markdown"},"source":{"77b3c6e0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c233ca2f":"import pandas as pd\nimport seaborn as sns \nimport matplotlib.pyplot as plt\nimport json\nfrom sklearn.feature_extraction.text import CountVectorizer","b79e5efe":"df = pd.read_csv('..\/input\/top50websites\/sites.csv', index_col='Rank')","9c0e2fe1":"plt.figure(figsize=(10,5))\nplt.title('Daily Minutes on Site')\nsns.histplot(data=df['Daily Minutes on Site'], color='Orange')","79687cb8":"plt.figure(figsize=(10,5))\nplt.title('Daily Minutes on Site')\nsns.kdeplot(data=df[(df['Daily Minutes on Site'] > 20) & (df['Daily Minutes on Site'] < 140)]['Daily Minutes on Site'], shade=True, color='Orange')\n\n","9570d442":"df_minutes = df[df['Daily Minutes on Site'] > 60].reset_index(drop=True)\ndf_minutes[['Site', 'Daily Minutes on Site']].set_index('Site').plot(kind='barh', figsize=(10,5),\n                                                                    title='More than 60 minutes a day, websites',\n                                                                    color='Orange')\n","f14f47a7":"df[['Site','Total Sites Linking In']].sort_values(by='Total Sites Linking In', ascending=False).head(7).reset_index(drop=True)","3233f4c0":"df_medias = df[['Site','Total Sites Linking In','Daily Minutes on Site']].sort_values(by='Total Sites Linking In', ascending=False).head(7).reset_index(drop=True)\n\ndf_medias_plot = data=df_medias[['Site','Daily Minutes on Site']].set_index('Site', drop=True).plot(kind='barh', color='Orange', figsize=(10,5), title='Minutes per day on major entertainment sites')\ndf_medias_plot","c02c623d":"df.corr().style.background_gradient(cmap='coolwarm')","3c8245a8":"with open('..\/input\/top50websites\/countries.json', 'r') as json_file:\n    df_js = json.load(json_file)","f1118e47":"df_country = pd.DataFrame.from_dict(df_js)","223bb5e9":"df_country.to_csv('top50_websites_per_country.csv')","3b7aaf19":"df_country","6819a6fb":"x = df_js.values()\nlista = []\nfor i in x:\n    for y in i.values():\n        lista.append(y)","ed7f2e80":"data_lista = pd.DataFrame()\ndata_lista['sites'] = lista\ndata_lista.sites.value_counts().head(50).plot(kind='barh', figsize=(10,13),\n                                                            color='Orange',\n                                                            title='50 Most accessed sites')\n","ecd33b99":"If the data is sorted according to the Total Sites Linking In column, you can see that we get the top entertainment \/ social networking sites today.\n\nNow let's see how many minutes people spend on these sites","8dcbe2c5":"I decided to use correlation to try to see relationships between the variables and thus make more analyzes, but the relationship in this case does not need further analysis to prove it.","daf17ea6":"# Frequencies of minutes on social networks","26e1e641":"* There are few sites where more than 60 minutes are spent.\n* It is also noted that the quantity has suddenly decreased.\n* In other words, there is a select group of sites that users prefer to spend their time with.","bba9a947":"# Conclusion\nI think that for an initial analysis on the dataset, the main questions were answered. However, if you have any further questions, feel free to say that I will work more on the analysis to try to answer it.\n","65b03969":"# Dataset with rank of websites accessed in the countries","159b50ee":"You can see that most people stay on sites for about 20 minutes","e7214fd3":"The most interesting thing is that entertainment sites like facebook, youtube, etc., do not dominate the rank considering the time of use","41bc119c":"# Frequencies of minutes on websites","d3e8833e":"# Hello, \nI am a beginner in the data analysis area and I tried to do an analysis in order to get some insights from the data set.\nThis is an initial work that will take place and I decide to post it even though it is not complete because I am a beginner and would like tips to improve my analysis. Thanks.\n"}}