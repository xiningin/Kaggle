{"cell_type":{"c2598dc8":"code","d8918ed5":"code","0db2b49b":"code","d3845de9":"code","51bf8f46":"code","853b3fb9":"code","c7b20933":"code","578a2729":"code","ff326f87":"code","4224342f":"code","fe206f0b":"code","73e691ab":"code","3b312ee5":"code","c920a9bf":"code","0c71a023":"code","099d36d4":"code","c083a2fb":"code","d046a48b":"code","6db526ca":"code","ee3b2ceb":"code","4ebf43f0":"code","ed1776a5":"code","598b140b":"code","66f8bec3":"code","ad47e00b":"code","f8adaa56":"code","fdc5645c":"code","d05cf50f":"code","5d0d79b1":"code","8268c597":"code","af7a438c":"code","0bbd5842":"code","efa9b01e":"code","0beada31":"code","104fc65f":"code","9480c7b3":"markdown","023007ea":"markdown","da0597fa":"markdown","b307407f":"markdown","7e9be2c2":"markdown","d098082a":"markdown","c030a25a":"markdown","3f8d4675":"markdown","2f2379e3":"markdown","20e783bf":"markdown","d603775e":"markdown"},"source":{"c2598dc8":"#importing libraries\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import PassiveAggressiveClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve\nfrom sklearn.metrics import average_precision_score,accuracy_score, confusion_matrix\nfrom sklearn.metrics import precision_recall_curve, roc_curve, auc\nimport matplotlib.pyplot as plt\nfrom sklearn.pipeline import Pipeline\nimport numpy as np\nfrom sklearn.model_selection import GridSearchCV","d8918ed5":"#reading data\nNews = pd.read_csv('\/kaggle\/input\/fake-news\/train.csv')","0db2b49b":"print('The shape of the dataset is {} \\n'.format(News.shape))\nNews.head()","d3845de9":"#creating a copy of the dataset with only two columns\nnews_copy = News[['title','text']]\n\n#extracting labels\nlabels = News[['label']]\nnews_copy.head()","51bf8f46":"#checking null values in label\nlabels.isnull().sum()","853b3fb9":"#checking null values in the training dataset\nnews_copy.isnull().sum()","c7b20933":"# making a loop to replace the text data with the headline if the text\/news is not present\n# then checking the null values in the text column\n\nfor i in range(0,news_copy.shape[0]-1):\n    if(news_copy.text.isnull()[i]):\n        news_copy.text[i] = news_copy.title[i]\n        \nnews_copy.isnull().sum()","578a2729":"#Splitting data\nx_train, x_test, y_train, y_test = train_test_split(news_copy, labels, test_size = 0.2, random_state = 42)","ff326f87":"print('x_train:{}'.format(x_train.shape))\nprint('y_train:{}'.format(y_train.shape))\nprint('x_test:{}'.format(x_test.shape))\nprint('y_test:{}'.format(y_test.shape))","4224342f":"x_train_text = x_train['text'].copy()\nx_test_text = x_test['text'].copy()","fe206f0b":"#vectoring using Tfidvectorizer with stop words english\ntfid = TfidfVectorizer(stop_words='english',max_features=2000,max_df=0.7)\n\n#fit and transform\ntf_train = tfid.fit_transform(x_train_text)\ntf_test = tfid.transform(x_test_text)\n\nprint('tf_train shape is {} tf_test shape is {}'.format(tf_train.shape,tf_test.shape))\nprint('y_train shape is {} y_test shape is {}'.format(y_train.shape,y_test.shape))","73e691ab":"# using Passive Agressive Classifier\nclassifer = PassiveAggressiveClassifier(max_iter=50)\n\n# fitting data to the classifier\nclassifer.fit(tf_train,y_train)\n\n# predicting the test data \ny_pred = classifer.predict(tf_test)\n\nscore = accuracy_score(y_test,y_pred)\nprint('Accuracy before thresholding is : {}'.format(round(score*100,2)))","3b312ee5":"#x_train_text = pd.DataFrame(x_train_text)\n#x_train_text['text'] = x_train_text['text'].str.lower()","c920a9bf":"#Build confusion matrix\nconfusion_matrix(y_test,y_pred, labels=[1,0])","0c71a023":"# getting precision, recall and threshold values from the curve and then plotting them\nprec, rec, tre = precision_recall_curve(y_test, y_pred)","099d36d4":"def plot_prec_recall_vs_tresh(precisions, recalls, thresholds):\n    plt.plot(thresholds, precisions[:-1], 'b--', label='precision')\n    plt.plot(thresholds, recalls[:-1], 'g--', label = 'recall')\n    plt.xlabel('Threshold')\n    plt.legend(loc='upper left')\n    plt.ylim([0,1])\n\nplot_prec_recall_vs_tresh(prec, rec, tre)\nplt.show()","c083a2fb":"# plotting ROC curve\nfpr, tpr, thresh= roc_curve(y_test, y_pred)\n\nroc_auc = auc(fpr, tpr)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, label='AUC = %0.4f'% roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([-0.001, 1])\nplt.ylim([0, 1.001])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show();","d046a48b":"optimal_proba_cutoff = sorted(list(zip(np.abs(prec - rec), thresh)), key=lambda i: i[0], reverse=False)[0][1]\nroc_predictions = [1 if i >= optimal_proba_cutoff else 0 for i in y_pred]","6db526ca":"print(\"Accuracy Score Before and After Thresholding: {}, {}\".format(accuracy_score(y_test, y_pred), accuracy_score(y_test, roc_predictions)))\nprint(\"Precision Score Before and After Thresholding: {}, {}\".format(precision_score(y_test, y_pred), precision_score(y_test, roc_predictions)))\nprint(\"Recall Score Before and After Thresholding: {}, {}\".format(recall_score(y_test, y_pred), recall_score(y_test, roc_predictions)))\nprint(\"F1 Score Before and After Thresholding: {}, {}\".format(f1_score(y_test, y_pred), f1_score(y_test, roc_predictions)))\n","ee3b2ceb":"fpr, tpr, thresh= roc_curve(y_test, roc_predictions)\n\nroc_auc = auc(fpr, tpr)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, label='AUC = %0.4f'% roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([-0.001, 1])\nplt.ylim([0, 1.001])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show();","4ebf43f0":"# Creating a pipeline with inital classifier as PassiveAggressiveClassifier\n\ntext = Pipeline([\n                ('tfidf', TfidfVectorizer( stop_words='english')),\n                ('classifier', PassiveAggressiveClassifier())\n            ])","ed1776a5":"# Assigning different parameters, along with multiple classifiers to search from\n\nparameters = [{'tfidf__max_df': (0.75, 1.0),\n               'tfidf__max_features' : (None,1000),\n               'tfidf__ngram_range': ((1,1),(1,2)),\n               'tfidf__norm': ('l1','l2')},\n              {'classifier':[PassiveAggressiveClassifier()],\n             'classifier__C':[1, 10, 100, 1000],\n             'classifier__max_iter':[1000,2000]},\n             ]","598b140b":"# initializing the gridsearchCV\n\ngrid = GridSearchCV(text,parameters,refit = True, verbose=2)","66f8bec3":"# fitting the training data in the model\n# or searching for best parameters \nbest_model = grid.fit(x_train_text,y_train)","ad47e00b":"# The best parameters for our model are as follows\nbest_model.best_estimator_","f8adaa56":"# performing predictions on test data set and checking accuracy\npred_HT = best_model.predict(x_test_text)\n\nscore = accuracy_score(y_test,pred_HT)\nprint('Accuracy before thresholding is : {}'.format(round(score*100,2)))","fdc5645c":"#Build confusion matrix\nconfusion_matrix(y_test,pred_HT, labels=[1,0])","d05cf50f":"print(\"Accuracy Score Before and After Hyperparameter Tuning: {}, {}\".format(accuracy_score(y_test, pred_HT), accuracy_score(y_test, roc_predictions)))\nprint(\"Precision Score Before and After Hyperparameter Tuning: {}, {}\".format(precision_score(y_test, pred_HT), precision_score(y_test, roc_predictions)))\nprint(\"Recall Score Before and After Hyperparameter Tuning: {}, {}\".format(recall_score(y_test, pred_HT), recall_score(y_test, roc_predictions)))\nprint(\"F1 Score Before and After Hyperparameter Tuning: {}, {}\".format(f1_score(y_test, pred_HT), f1_score(y_test, roc_predictions)))\n","5d0d79b1":"fpr, tpr, thresh= roc_curve(y_test, pred_HT)\n\nroc_auc = auc(fpr, tpr)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, label='AUC = %0.4f'% roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([-0.001, 1])\nplt.ylim([0, 1.001])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show();","8268c597":"Final_model = Pipeline([(\n    'tfid', TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 encoding='utf-8', input='content',\n                                 lowercase=True, max_df=1, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words='english', strip_accents=None,\n                                 sublinear_tf=False,\n                                 tokenizer=None, use_idf=True,\n                                 vocabulary=None)),\n    ('classifier',PassiveAggressiveClassifier(C=1.0, average=False,\n                                             class_weight=None,\n                                             early_stopping=False,\n                                             fit_intercept=True, loss='hinge',\n                                             max_iter=1000, n_iter_no_change=5,\n                                             n_jobs=None, random_state=None,\n                                             shuffle=True, tol=0.001,\n                                             validation_fraction=0.1, verbose=0,\n                                             warm_start=False))\n    \n])","af7a438c":"# creatinf a final dataset for training the final model\nx_final = news_copy['text'].copy()\n\n# checking their shape\nprint(x_final.shape)\nprint(labels.shape)","0bbd5842":"# Training the final model\nFinal_model.fit(x_final,labels)","efa9b01e":"# here we are loading our test dataset for prediction\n\nTest=pd.read_csv('..\/input\/fake-news\/test.csv') \nTest_id=Test[\"id\"]\n\n# here we are removing these columns as they are not so important\nTest1 = Test['text'].copy()\n\nTest1.fillna('fake fake fake',inplace=True)\nfinal_sub = Final_model.predict(Test1)\n\n#submission = pd.DataFrame({'id':Test_id, 'label':final_sub})","0beada31":"pred=pd.DataFrame(final_sub,columns=['label'])\npred['id']=Test['id']\npred.groupby('label').count()","104fc65f":"pred.to_csv('countvect5.csv', index=False)","9480c7b3":"## Accuracy before thresholding","023007ea":"## After thresholding","da0597fa":"## Training the model with the whole data ","b307407f":"## Plotting PR curve and obtaining threshold","7e9be2c2":"Fake news in today's life is very much common, one joke or misunderstanding of the text can cause great problems for people and the government. In the era of social media, where everyone is always in touch and where information can travel instantly it won't be wrong to say that we are more prone to fake information than ever before.\n\nHere is my basic attempt to create a fake news detector using simple technique with main attempt to deploy it and learn batch training.","d098082a":"### with the text feature taken together","c030a25a":"##  Hyperparameter tuning","3f8d4675":"It can be noticed that the precision before hyperparameter tuning is improved and other evaluation metrics have also improved","2f2379e3":"96.67% of the total area is covered under the curve which is better than the previous ~92% area covered.","20e783bf":"# Preprocessing","d603775e":"The evaluation is exactly the same that means it is already working with highest possible recall and precison.\nLet's try hyperparameters of the vectorizer and the classifer."}}