{"cell_type":{"2faa12f8":"code","2bdf702b":"code","30806e40":"code","90d84922":"code","cf2391af":"code","5383aa5f":"code","dcbf7b9d":"code","9c8a7bc4":"code","cd8de1a8":"code","1e475d53":"code","e6da083e":"code","c62a5ffc":"code","9d10c5de":"markdown","467f6a0a":"markdown","e4273649":"markdown","c9da7293":"markdown","9ab8b91c":"markdown","38e1d44a":"markdown","bcfe61a6":"markdown"},"source":{"2faa12f8":"import numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\nfrom tqdm import tqdm\n\nDATADIR = \"..\/input\/cat-and-dog\/PetImages\/\"\n\nCATEGORIES = [\"Dog\", \"Cat\"]\n\nfor category in CATEGORIES:  # do dogs and cats\n    path = os.path.join(DATADIR,category)  # create path to dogs and cats\n    for img in os.listdir(path):  # iterate over each image per dogs and cats\n        img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n        plt.imshow(img_array, cmap='gray')  # graph it\n        plt.show()  # display!\n\n        break  # we just want one for now so break\n    break  #...and one more!","2bdf702b":"print(img_array)","30806e40":"print(img_array.shape)","90d84922":"IMG_SIZE = 50\n\nnew_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\nplt.imshow(new_array, cmap='gray')\nplt.show()","cf2391af":"new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\nplt.imshow(new_array, cmap='gray')\nplt.show()","5383aa5f":"training_data = []\n\ndef create_training_data():\n    for category in CATEGORIES:  # do dogs and cats\n\n        path = os.path.join(DATADIR,category)  # create path to dogs and cats\n        class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1). 0=dog 1=cat\n\n        for img in tqdm(os.listdir(path)):  # iterate over each image per dogs and cats\n            try:\n                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n                training_data.append([new_array, class_num])  # add this to our training_data\n            except Exception as e:  # in the interest in keeping the output clean...\n                pass\n            #except OSError as e:\n            #    print(\"OSErrroBad img most likely\", e, os.path.join(path,img))\n            #except Exception as e:\n            #    print(\"general exception\", e, os.path.join(path,img))\n\ncreate_training_data()\n\nprint(len(training_data))","dcbf7b9d":"import random\n\nrandom.shuffle(training_data)","9c8a7bc4":"for sample in training_data[:10]:\n    print(sample[1])","cd8de1a8":"X = []\ny = []\n\nfor features,label in training_data:\n    X.append(features)\n    y.append(label)\n\nprint(X[0].reshape(-1, IMG_SIZE, IMG_SIZE, 1))\n\nX = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)","1e475d53":"import pickle\n\npickle_out = open(\"X.pickle\",\"wb\")\npickle.dump(X, pickle_out)\npickle_out.close()\n\npickle_out = open(\"y.pickle\",\"wb\")\npickle.dump(y, pickle_out)\npickle_out.close()","e6da083e":"pickle_in = open(\"X.pickle\",\"rb\")\nX = pickle.load(pickle_in)\n\npickle_in = open(\"y.pickle\",\"rb\")\ny = pickle.load(pickle_in)","c62a5ffc":"import tensorflow as tf\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\n\nimport pickle\n\npickle_in = open(\"X.pickle\",\"rb\")\nX = pickle.load(pickle_in)\n\npickle_in = open(\"y.pickle\",\"rb\")\ny = pickle.load(pickle_in)\n\nX = X\/255.0\n\nmodel = Sequential()\n\nmodel.add(Conv2D(256, (3, 3), input_shape=X.shape[1:]))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(256, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n\nmodel.add(Dense(64))\n\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\nmodel.fit(X, y, batch_size=32, epochs=3, validation_split=0.3)","9d10c5de":"Better. Let's try that. Next, we're going to want to create training data and all that, but, first, we should set aside some images for final testing. I am going to just manually create a directory called Testing and then create 2 directories inside of there, one for Dog and one for Cat. From here, I am just going to move the first 15 images from both Dog and Cat into the training versions. Make sure you move them, not copy. We will use this for our final tests.\n\nNow, we want to begin building our training data!","467f6a0a":"# Part 3.0 is below","e4273649":"# Please upvote this kernel and like the video\n\nThanks harrison\n<iframe width=\"560\" height=\"315\" src=\"https:\/\/www.youtube.com\/embed\/WvoLTXIjBYU\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen><\/iframe>\n","c9da7293":"Let's save this data, so that we don't need to keep calculating it every time we want to play with the neural network model:","9ab8b91c":"# Part 3.0","38e1d44a":"After just three epochs, we have 71% validation accuracy. If we keep going, we can probably do even better, but we should probably discuss how we know how we are doing. To help with this, we can use TensorBoard, which comes with TensorFlow and it helps you visualize your models as they are trained.","bcfe61a6":"Great, we've got the classes nicely mixed in! Time to make our model!"}}