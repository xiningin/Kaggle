{"cell_type":{"e035dce9":"code","ebaa8555":"code","9f4884ba":"code","0ab0d4a1":"code","8094105d":"code","98ee4981":"code","2333f24f":"code","23fe829b":"code","21fb4ecc":"code","8e277224":"code","5875ca45":"code","80208dba":"code","4d3dceeb":"code","8d086e90":"code","fa050b79":"code","f01d8487":"code","10551e11":"code","a447f225":"code","94e889c3":"code","c1e67c6d":"code","aee33fd7":"code","b5cf2169":"code","9f33544b":"code","0793b58e":"code","8d23dce9":"code","b36beac0":"code","facce019":"code","4930f9c1":"code","763e828a":"code","9a17a22b":"code","2cedd7db":"code","eac3e1d5":"code","d8264da2":"code","858d69bf":"code","776fc33c":"code","d7fe42f5":"code","24a31ab8":"code","9cba1907":"code","44469547":"code","04bb1bd6":"code","c7e31b1d":"code","077d1208":"code","5756f0fa":"markdown","42feca1d":"markdown","c4f6d7c9":"markdown","37d1cc03":"markdown","d9d7fe30":"markdown","37d3ba94":"markdown","4f0aea9f":"markdown","0664a236":"markdown","db889939":"markdown","87ade042":"markdown","367ea842":"markdown","13395417":"markdown","b7316b6c":"markdown","d4a37c71":"markdown","df281136":"markdown","6ae260d5":"markdown","baceea67":"markdown","53ac3679":"markdown","42f388a3":"markdown","93a90b80":"markdown","9c57878d":"markdown","44123e69":"markdown","c7ac2dd3":"markdown","53a1e5d9":"markdown","62024214":"markdown","a7bb2da3":"markdown","eadd1636":"markdown","cd0f519d":"markdown","0950ecab":"markdown","de14c0c7":"markdown","dd8c6e38":"markdown","bff6ceb6":"markdown","dd72d34c":"markdown","7b65e15e":"markdown","bf7b7760":"markdown","8382006b":"markdown","95fd9721":"markdown","8990fb43":"markdown","8f36ff9b":"markdown","a4b1e9c7":"markdown","b3130f73":"markdown","fc41a57f":"markdown","5bf4c6c5":"markdown","56f9f6e9":"markdown","13199e22":"markdown","2e00ea3c":"markdown","355a54dd":"markdown","8ca041ff":"markdown","0b5be685":"markdown","ce8a42e0":"markdown","a38acf1e":"markdown","d33ade9c":"markdown","559d63f2":"markdown","aebf79ef":"markdown","c3068d94":"markdown","568c1dc5":"markdown","81b70337":"markdown","39c8acd1":"markdown","a7ab2d27":"markdown","944a9a99":"markdown"},"source":{"e035dce9":"from google.cloud import bigquery","ebaa8555":"# Create a client object\nclient = bigquery.Client()","9f4884ba":"# Construct a reference to the \"hacker_news\" dataset\ndataset_ref = client.dataset(\"hacker_news\", project=\"bigquery-public-data\")\n\n# API request - fetch the dataset\ndataset = client.get_dataset(dataset_ref)","0ab0d4a1":"# construct a reference to the hacker_news dataset\ndataset_ref = client.dataset(\"hacker_news\", project=\"bigquery-public-data\")\n\n# API request - fetch the dataset\ndataset = client.get_dataset(dataset_ref)","8094105d":"# List tables present in \"hacker_news\" dataset\ntables = list(client.list_tables(dataset))\n\n# print names of all tables present in the dataset\nfor table in tables:\n    print(table.table_id)","98ee4981":"# Create a table reference (\"full\")\ntable_ref = dataset_ref.table(\"full\")\n\n# API request - fetch the full table\ntable = client.get_table(table_ref)","2333f24f":"table.schema","23fe829b":"# print first five rows of the \"full\" table\nclient.list_rows(table, max_results=5).to_dataframe()","21fb4ecc":"# print first five rows of \"by\" column (or field) of \"full\" table\nclient.list_rows(table, selected_fields=table.schema[:1], max_results=5).to_dataframe()","8e277224":"# imports \nfrom google.cloud import bigquery\n\n# create a client object \nclient = bigquery.Client()\n\n# create a dataset reference (to openaq)\ndataset_ref = client.dataset(\"openaq\", project=\"bigquery-public-data\")\n\n# api request - fetch data\ndataset = client.get_dataset(dataset_ref)\n\n# create a list of tables present in the dataset\ntables = list(client.list_tables(dataset))\n\n# print all table names\nfor table in tables:\n    print(table.table_id)","5875ca45":"# construct a reference to the table\ntable_ref = dataset_ref.table(\"global_air_quality\")\n\n# api request - fetch table\ntable = client.get_table(table_ref)\n\n# print first five rows \/ lines of \"global_air_quality\" table\nclient.list_rows(table, max_results=5).to_dataframe()","80208dba":"# Query to select all the items from the \"city\" column where the \"country\" column is 'US'\nquery = \"\"\"\n        SELECT city\n        FROM `bigquery-public-data.openaq.global_air_quality`\n        WHERE country = 'US'\n        \"\"\"","4d3dceeb":"client = bigquery.Client()","8d086e90":"query_job = client.query(query)","fa050b79":"# api request - run the query and return a pandas DataFrame\nus_cities = query_job.to_dataframe()","f01d8487":"us_cities.city.value_counts().head()","10551e11":"query = \"\"\"\n        SELECT city, country\n        FROM `bigquery-public-data.openaq.global_air_quality`\n        WHERE country=\"US\"\n        \"\"\"","a447f225":"query = \"\"\"\n        SELECT *\n        FROM `bigquery-public-data.openaq.global_air_quality`\n        WHERE country=\"US\"\n        \"\"\"","94e889c3":"# query to get the score column from every row where the type column has value \"job\"\nquery = \"\"\"\n        SELECT score, title\n        FROM `bigquery-public-data.hacker_news.full`\n        WHERE type = \"job\" \n        \"\"\"\n\n# create 'QueryJobConfig' object to estimate size of query without running it\ndry_run_config = bigquery.QueryJobConfig(dry_run=True)\n\n# api request - dry run query to estimate costs\ndry_run_query_job = client.query(query, job_config=dry_run_config)\n\nprint(\"This query will process {} bytes\".format(dry_run_query_job.total_bytes_processed))","c1e67c6d":"def safe_config_f(max_size):\n    return bigquery.QueryJobConfig(maximum_bytes_billed=max_size)","aee33fd7":"max_size = 1 \nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=max_size)\n\n# setup the query (only run if its less than 100 MB)\nsafe_query_job = client.query(query, job_config=safe_config)\n\n# api request - run the query and return a pandas dataframe\nsafe_query_job.to_dataframe()\n\n\n# strangely this query runs (need to take a look on documentation)","b5cf2169":"# Only run the query if it's less than 1 GB\nONE_GB = 1000*1000*1000\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=ONE_GB)\n\n# Set up the query (will only run if it's less than 1 GB)\nsafe_query_job = client.query(query, job_config=safe_config)\n\n# API request - try to run the query, and return a pandas DataFrame\njob_post_scores = safe_query_job.to_dataframe()\n\n# Print average score for job posts\njob_post_scores.score.mean()","9f33544b":"# imports \nfrom google.cloud import bigquery\n\n# create a client object\nclient = bigquery.Client()\n\n# construct a reference to the hacker_news dataset\ndataset_ref = client.dataset(\"hacker_news\", project=\"bigquery-public-data\")\n\n# api request - fetch dataset\ndataset = client.get_dataset(dataset_ref)\n\n# list tables in the 'hacker_news' dataset\ntables = list(client.list_tables(dataset))\n\n# print all tables present in the dataset\nfor table in tables:\n    print(table.table_id)","0793b58e":"# construct a reference to 'comments' table\ntable_ref = dataset_ref.table('comments')\n\n# api request - fetch dataset\ntable = client.get_table(table_ref)","8d23dce9":"client.list_rows(table, max_results=5).to_dataframe()","b36beac0":"# query to select comments that have more than 10 replies\nquery = \"\"\"\n        SELECT parent, COUNT(id)\n        FROM `bigquery-public-data.hacker_news.comments`\n        GROUP BY parent\n        HAVING COUNT(id) > 10\n        \"\"\"","facce019":"# set up query and QueryJobConfig (To be on safer side)\nsafe_config = bigquery.QueryJobConfig(max_bytes_billed = 10*9)       # 1 GB limit\nquery_job = client.query(query, job_config=safe_config)\n\n# api request - run the query and return a pandas dataframe\npopular_comments = query_job.to_dataframe()\n\n# print first five rows of popular_comments dataframe\npopular_comments.head()","4930f9c1":"# Imporoved version of earlier query with aliasing and improved readability\nquery_improved = \"\"\"\n                 SELECT parent, COUNT(1) AS NumPosts\n                 FROM `bigquery-public-data.hacker_news.comments`\n                 GROUP BY parent\n                 HAVING COUNT(1) > 10\n                 \"\"\"\n\n# set up query and QueryJobConfig (To be on safer side)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**9) \nquery_job = client.query(query_improved, job_config=safe_config)\n\n# api request - run the query and return a pandas dataframe\nimproved_df = query_job.to_dataframe()\n\n# print first five rows of improved_df dataframe\nimproved_df.head()","763e828a":"query_good = \"\"\"\n             SELECT parent, COUNT(id)\n             FROM `bigquery-public-data.hacker_news.comments`\n             GROUP BY parent\n             \"\"\"\n\n# Example of a good query as parent is used with GROUP BY and id is used with COUNT()","9a17a22b":"query_bad = \"\"\"\n            SELECT author, parent, COUNT(id)\n            FROM `bigquery-public-data.hacker_news.comments`\n            GROUP BY parent\n            \"\"\"\n\n# This query will throw an error because author is neither aggregated nor used with GROUP BY","2cedd7db":"# imports\nfrom google.cloud import bigquery\n\n# create a client object\nclient = bigquery.Client()\n\n# construct a reference to the 'nhtsa_traffic_fatalities' database\ndataset_ref = client.dataset(\"nhtsa_traffic_fatalities\", project=\"bigquery-public-data\")\n\n# api request - fetch dataset\ndataset = client.get_dataset(dataset_ref)\n\n# construct a reference to the 'accident_2015' table\ntable_ref = dataset_ref.table(\"accident_2015\")\n\n# api request - fetch the table\ntable = client.get_table(table_ref)\n\n# show first five rows of the table fetched\nclient.list_rows(table, max_results=5).to_dataframe()","eac3e1d5":"# query to find number of accidents on each day of the week\nquery = \"\"\"\n        SELECT EXTRACT(DAYOFWEEK from timestamp_of_crash) AS day_of_week,\n               COUNT(consecutive_number) AS num_accidents\n        FROM `bigquery-public-data.nhtsa_traffic_fatalities.accident_2015`\n        GROUP BY day_of_week\n        ORDER BY num_accidents DESC\n        \"\"\"","d8264da2":"# set up query and QueryJobConfig\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**9)\nquery_job = client.query(query, job_config=safe_config)\n\n# run query and convert the result to a dataframe\ndf = query_job.to_dataframe()\n\ndf","858d69bf":"from google.cloud import bigquery\n\n# Create a \"Client\" object\nclient = bigquery.Client()\n\n# Construct a reference to the \"crypto_bitcoin\" dataset\ndataset_ref = client.dataset(\"crypto_bitcoin\", project=\"bigquery-public-data\")\n\n# API request - fetch the dataset\ndataset = client.get_dataset(dataset_ref)\n\n# Construct a reference to the \"transactions\" table\ntable_ref = dataset_ref.table(\"transactions\")\n\n# API request - fetch the table\ntable = client.get_table(table_ref)\n\n# Preview the first five lines of the \"transactions\" table\nclient.list_rows(table, max_results=5).to_dataframe()","776fc33c":"# Query to select number of transactions per date, sorted by data\nquery = \"\"\"\n        WITH time AS\n        (\n        SELECT DATE(block_timestamp) AS trans_date\n        FROM `bigquery-public-data.crypto_bitcoin.transactions`\n        )\n        SELECT COUNT(1) AS transactions,\n               trans_date\n        FROM time\n        GROUP BY trans_date\n        ORDER BY trans_date\n        \"\"\"","d7fe42f5":"# set up query \nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nquery_job = client.query(query, job_config=safe_config)\n\n# run query return dataframe\ndf = query_job.to_dataframe()\n\ndf.head()","24a31ab8":"df.set_index('trans_date').plot()","9cba1907":"# imports\nfrom google.cloud import bigquery\n\n# create a client object\nclient = bigquery.Client()\n\n# construct a reference to the 'github_repos' dataset\ndataset_ref = client.dataset('github_repos', project=\"bigquery-public-data\")\n\n# api request - fetch dataset\ndataset = client.get_dataset(dataset_ref)","44469547":"tables = list(client.list_tables(dataset))\n\nfor table in tables:\n    print(table.table_id)","04bb1bd6":"# construct a reference to the 'licenses' table\nlicenses_table_ref = dataset_ref.table('licenses')\n\n# api - request - fetch table\nlicenses_table = client.get_table(licenses_table_ref)\n\n# show first five rows of table\nclient.list_rows(licenses_table, max_results=5).to_dataframe()","c7e31b1d":"# construct a reference to the 'sample_files' table\nsample_files_table_ref = dataset_ref.table('sample_files')\n\n# api request - fetch table\nsample_files_table = client.get_table(sample_files_table_ref)\n\n# show first five rows of sample_files table\nclient.list_rows(sample_files_table, max_results=5).to_dataframe()","077d1208":"# Query to determine the number of files per license, sorted by number of files\nquery = \"\"\"\n        SELECT L.license, COUNT(1) AS num_files\n        FROM `bigquery-public-data.github_repos.sample_files` AS sf\n        INNER JOIN `bigquery-public-data.github_repos.licenses` AS L\n            ON sf.repo_name = L.repo_name\n        GROUP BY L.license\n        ORDER BY num_files DESC\n        \"\"\"\n\n# set up query \nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nquery_job = client.query(query, job_config=safe_config)\n\n# run query return dataframe\nfile_count_by_license = query_job.to_dataframe()\n\nfile_count_by_license.head()","5756f0fa":"## Example: How many files are covered by each type of software license?\nGitHub is the most popular place to collaborate on software projects. A GitHub **repository** (or **repo**) is a collection of files associated with a specific project.\n\nMost repos on GitHub are shared under a specific legal license, which determines the legal restrictions on how they are used. For our example, we're going to look at how many different files have been released under each license.","42feca1d":"# Joining Data\nCombine data sources. Critical for almost all real world problems.","c4f6d7c9":"First step in the workflow is to create a `Client` objct. `Client` object plays a central role in retrieving information from bigquery datasets.","37d1cc03":"Now we have the tools to obtain data from a single table. What to do if the data we want is spread across multiple tables? This is where **JOIN** comes in. **JOIN** is very useful in practical **SQL** workflows.\n\n## Example\nWe'll use `pets` table which has three column:\n- `ID` - id number of the pet\n- `Name` - name of the pet\n- `Animal` - type of the animal\n\nWe'll add one more table, called `owners` containing three columns:\n- `ID` - ID number for the owner\n- `Name` - Name of the owner\n- `Pet_ID` - ID number for the pet that belongs to owner\n\n<img src=\"https:\/\/i.imgur.com\/Rx6L4m1.png\"\/>","d9d7fe30":"The query below returns two columns, where `Day` column contains the day corresponding to each entry in the `Date` column.\n<img src=\"https:\/\/i.imgur.com\/PhoWBO0.png\"\/>","37d3ba94":"## Example: Where all the the US citites in the OpenAQ dataset?\nWe'll use [OpenAQ](https:\/\/openaq.org\/) dataset about air quality. ","4f0aea9f":"# Order By\n[Tutorial Link](https:\/\/www.kaggle.com\/dansbecker\/order-by)\n\nIn this tutorial we will learn how to change order of our results using the **ORDER BY** clause and explore a popular use case by applying ordering to dates. We will use slightly modified version of `pets` table to understand **ORDER BY** clause.\n<img src=\"https:\/\/i.imgur.com\/b99zTLv.png\"\/>","0664a236":"write a query that uses information in both tables to determine how many files are released in each license.","db889939":"Next we set up the query with the `query()` method. We will run the method with the default parameters but this method allows us to specify complicated settings as shown in [documentation](https:\/\/google-cloud.readthedocs.io\/en\/latest\/bigquery\/generated\/google.cloud.bigquery.client.Client.query.html#google.cloud.bigquery.client.Client.query).","87ade042":"Next we run the query and convert results to a pandas dataframe","367ea842":"## Example: How many Bitcoin transactions are made per month?","13395417":"* `consecutive_number` column contains unique id for each accident\n* `timestamp_of_crash` contains the date of accident in **DATETIME** format\n\nWe can\n* **EXTRACT** the day of the week (as `day_of_week`) from `timestamp_of_crash` and\n* **GROUP BY** the day of the week, before we **COUNT** the `consecutive_number` column to determine number of accidents on each day of the week. ","b7316b6c":"The second table is the `sample_files` table, which provides, among other information, the GitHub repo that each file belongs to (in the repo_name column).","d4a37c71":"Since they're returned sorted, we can easily plot the raw results to show us the number of Bitcoin transactions per day over the whole timespan of this dataset.","df281136":"Also, it's important to note that CTEs only exist inside the query where we create them, and we can't reference them in later queries. So, any query that uses a CTE is always broken into two parts: (1) first, we create the CTE, and then (2) we write a query that uses the CTE.","6ae260d5":"In the query, **ON** determines which column in each table to use to combine the tables. Notice that since the `ID` column exists in both tables, we have to clarify which one to use. We use `p.ID` to refer to the `ID` column from the `pets` table, and `o.Pet_ID` refers to the `Pet_ID` column from the `owners` table.\n\n>In general, when we're joining tables, it's a good habit to specify which table each of your columns comes from. That way, we don't have to pull up the schema every time we go back to read the query.\n\nThe type of **JOIN** we used here is called **INNER JOIN**. That means that a row will only be put in the final output table if the value in the columns you're using to combine them shows up in both the tables you're joining. For example, if Tom's ID number of 4 didn't exist in the pets table, we would only get 3 rows back from this query.","baceea67":"Exercises of this tutorial are solved [here](https:\/\/www.kaggle.com\/mahendrabishnoi2\/exercise-order-by)","53ac3679":"## Example: Which Hacker News comments generated the most discussion?\nWe will work with `comments` table.","42f388a3":"Each `SchemaField` tells us about a specific column (also referred to as `field`). In order the information is:\n- The **name** of the column\n- The **field type** (or **data type**) of the column\n- The **mode** of the column (`NULLABLE` means the column allows NULL values, default)\n- A **description** of the data in that column\n\nThe first **field** has the `SchemaField`:\n`SchemaField('by', 'STRING', 'NULLABLE', \"The username of the item's author.\", ()),` <br\/>\nThis tells us:\n- The **field** (or **column**) is called `by`,\n- The data in the field is strings,\n- This column allow NULL values,\n- This column contains username of item's author.\n\nWe can use `list_rows()` method to show first five rows of the `full` table to make sure its right. This returns a BigQuery `RowIterator` object which can be converted to pandas DataFrame using `to_dataframe()` method.","93a90b80":"Exercises of this tutorial are solved [here](https:\/\/www.kaggle.com\/mahendrabishnoi2\/exercise-select-from-where)","9c57878d":"We will work with dataset of posts on [Hacker News](https:\/\/news.ycombinator.com\/)\n\nIn BigQuery each dataset in contained in a corresponding project. In this case `hacker_news` dataset is contained in the `bigquery-public-data` project. To access the dataset,\n- Construct a reference to the dataset by using `dataset()` method.\n- Next, use the `get_dataset()` method, along with the reference we just constructed, to fetch the dataset.","44123e69":"## More queries\nIf we want multiple columns we can select them with comma","c7ac2dd3":"A **WHERE** clause can limit your results to rows with certain text using the **LIKE** feature. For example, to select just the third row of the `pets` table from the tutorial, we could use the query in the picture below.\n\n![](https:\/\/i.imgur.com\/RccsXBr.png) \n\nYou can also use `%` as a \"wildcard\" for any number of characters. So you can also get the third row with:\n\n```\nquery = \"\"\"\n        SELECT * \n        FROM `bigquery-public-data.pet_records.pets` \n        WHERE Name LIKE '%ipl%'\n        \"\"\"\n```\n","53a1e5d9":"## GROUP BY ... HAVING\n**HAVING** is used in combination with **GROUP BY** to ignore groups that don't meet certain criteria.\n\nSo this query, for example, will only include groups that have more than one ID in them.\n<img src=\"https:\/\/i.imgur.com\/2ImXfHQ.png\"\/>","62024214":"Above code printed out first five rows of all **fields**, we can also print first five rows of selected fields if we want. For example here we will print first five rows of `by` **field**","a7bb2da3":"We can also specify a parameter when running the query to limit how much data we want to scan. Here's an example with a low limit.","eadd1636":"# Getting Started with SQL and BigQuery\n[Tutorial Link](https:\/\/www.kaggle.com\/dansbecker\/getting-started-with-sql-and-bigquery) <br\/>\n[Notebook Link](https:\/\/www.kaggle.com\/mahendrabishnoi2\/03-intro-to-sql\/) on kaggle.\n\n## Introduction\n- **SQL**(Structured Query Language) - A programming language used with databases. <br>\n- **BigQuery** - A web service that lets us apply SQL to huge datasets.\n\nIn this tutorial we will learn about accessing and examining BigQuery datasets.\n\n## First BigQuery commands\nTo use BigQuery we will import the Python package.","cd0f519d":"Write a query to select `city` column from `global_air_quality` table where `country` is `US`","0950ecab":"If we want to select all columns we can use `*`","de14c0c7":"Similar to how we fetched a dataset, we can fetch a table. In the code below we fetch the `full` table in the `hacker_news` dataset using `get_table()` method.","dd8c6e38":"## Dates\nThere are two ways dates can be stored in BigQuery as a **DATE** or as **DATETIME**\n\nThe **DATE** format has the year first, then month and then day. It looks like this:\n\n``YYYY-[M]M-[D]D``\n* `YYYY`: Four digit year\n* `[M]M`: One or two digit month\n* `[D]D`: One or two digit day\n\nSo `2019-01-10` is interpreted as January 10, 2019.\n\nThe **DATETIME** format is like **DATE** with time added at the end.","bff6ceb6":"## WITH ... AS\n**AS** when combined with **WITH** is called CTE (Common Table Expression).\n\nCTE is a temporary table that we return within our query. Helpful in splitting our queries in readable chunks and we can write queries against them.\n\nFor example, if we want to ask questions from `pets` table about older animals in particular. We could write a CTE which only contains information about animals older than 5 years.\n<img src=\"https:\/\/i.imgur.com\/0Kz8q4x.png\"\/>\n\nAbove query is incomplete, so it doesn't return anything but it creates a CTE named `Seniors` which we can refer to while writing rest of the query.\n\nWe can finish the query by pulling the information we want from CTE named `Seniors`. Below query first creates CTE then return `Id` column from CTE.\n<img src=\"https:\/\/i.imgur.com\/3xQZM4p.png\"\/>","dd72d34c":"From above table we can say that:\n- id column shows id of each comment\n- parent column shows the comment (id) that was replied to \n\nSo we can **GROUP BY** the `parent` and **COUNT()** the `id` column to figure out the number of replies for every comment, and since we are looking for popular comments we can apply a condition using **HAVING** to return only those comments which received more than 10 replies.","7b65e15e":"Exercises of this tutorial are solved [here](https:\/\/www.kaggle.com\/mahendrabishnoi2\/exercise-joining-data)","bf7b7760":"## Working with Big Datasets\nTo avoid scanning too much data at once, we can estimate size of query before we run it. We will see how to estimate query size on very large `hacker_news` dataset.\n\nTo see how much data a query will scan, we create a `QueryJobConfig` object and set the `dry_run` parameter to `True`.","8382006b":"## JOIN\n\nUsing **JOIN** we can write a query to return a table that contains 2 columns, name of the pet and name of the owner\n<img src=\"https:\/\/i.imgur.com\/fLlng42.png\"\/>\n\nWe combine information from both tables by matching rows where the ID column in the pets table matches the Pet_ID column in the owners table.","95fd9721":"Exercises of this tutorial are solved [here](https:\/\/www.kaggle.com\/mahendrabishnoi2\/exercise-as-with)","8990fb43":"## Submitting the query to the dataset\n- Create a client object","8f36ff9b":"## EXTRACT\nIf we want to look at a part of **DATE** such as month or day or year, we can do so with **EXTRACT**. We will show use of **EXTRACT** with this slightly modified table, called `pets_with_date`\n<img src=\"https:\/\/i.imgur.com\/vhvHIh0.png\"\/>","a4b1e9c7":"Each dataset is a collection of tables.\n\nWe use `list_tables()` method to list tables present in the dataset.","b3130f73":"Exercises of this tutorial are solved [here](https:\/\/www.kaggle.com\/mahendrabishnoi2\/exercise-getting-started-with-sql-and-bigquery)","fc41a57f":"We'll work with two tables in the database. The first table is the `licenses` table, which provides the name of each GitHub repo (in the repo_name column) and its corresponding license.","5bf4c6c5":"Following query returns one column with just the week in the year for each date in the `Date` column.\n<img src=\"https:\/\/i.imgur.com\/A5hqGxY.png\"\/>","56f9f6e9":"## GROUP BY\n**GROUP BY** takes the name of one or more columns, and treats all rows with the same value in that column as a single group when you apply aggregate functions like **COUNT()**.\n\nFor example, say we want to know how many of each type of animal we have in the `pets` table. We can use **GROUP BY** to group together rows that have the same value in the `Animal` column, while using **COUNT()** to find out how many ID's we have in each group.\n<img src=\"https:\/\/i.imgur.com\/tqE9Eh8.png\"\/>\nIt returns a table with three rows (one for each distinct animal). We can see that the `pets` table contains 1 rabbit, 1 dog, and 2 cats.","13199e22":"# AS & WITH\nHelps organize our queries for better readability. Important when working with complex queries. To understand **AS** & **WITH** we will use `pets` table, which now includes age of animals.\n<img src=\"https:\/\/i.imgur.com\/MXrsiAZ.png\"\/>\n\n## AS\nAs we have seen earlier **AS** is used to rename the columns generated by queries, also known as **aliasing**. Its similar to how we use `as` in Python. Eg: `import pandas as pd`. Here we kind of renamed `pandas` to `pd`. To use **AS** we insert it just after column name.","2e00ea3c":"## Aliasing and Other Improvements\n- The column resulting from **COUNT(id)** was called `f0__`. That's not a very descriptive name. We can change the name by adding `AS NumPosts` after we specify the aggregation.\n- If we are ever unsure what to put inside the **COUNT()** function, we can do **COUNT(1)** to count the rows in each group. Most people find it especially readable, because we know it's not focusing on other columns. It also scans less data than if supplied column names (making it faster and using less of our data access quota(BigQuery 30 TB quota)).","355a54dd":"In this tutorial we will learn about **GROUP BY**, **HAVING** & **COUNT()**. We will be using following made-up table to understand these techniques\n<img src=\"https:\/\/i.imgur.com\/fI5Pvvp.png\"\/>","8ca041ff":"## ORDER BY\n**ORDER BY** is usually the last clause in our query, used to sort the results returned by rest of our query. \n\nIn the above table we can see that `ID` column is not sorted, we can sort it by following query:\n<img src=\"https:\/\/i.imgur.com\/6o9LuTA.png\"\/>\n\n**ORDER BY** also works on columns containing text(strings), it will sort them alphabetically. Example:\n<img src=\"https:\/\/i.imgur.com\/ooxuzw3.png\"\/>\n\nWe can use **DESC** to reverse the sorting order as shown below:\n<img src=\"https:\/\/i.imgur.com\/IElLJrR.png\"\/>","0b5be685":"## Note on using **GROUP BY**\nNote that because it tells SQL how to apply aggregate functions (like **COUNT()**), it doesn't make sense to use **GROUP BY** without an aggregate function. Similarly, if we have any **GROUP BY** clause, then all variables must be passed to either a\n1. GROUP BY command, or\n2. an aggregation function.","ce8a42e0":"Exercises of this tutorial are solved [here](https:\/\/www.kaggle.com\/mahendrabishnoi2\/exercise-group-by-having-count)","a38acf1e":"What we have learnt so far:\n<img src=\"https:\/\/i.imgur.com\/biYqbUB.png\"\/>\n\n## Table Schema\nStructure of a table is called its schema. We need to understand a table's schema to pull the data we want.\n\nHere we will investigate the `full` table that we fetched earlier.","d33ade9c":"## COUNT()\n**COUNT()**, as the name suggests return the count of things. If we pass name of a column to **COUNT()**, it will return number of items in that column.\n\nFor example if we **SELECT** the **COUNT()** of `ID` columns in `pets` table, it will return 4, because there are 4 IDs.\n<img src=\"https:\/\/i.imgur.com\/Eu5HkXq.png\"\/>","559d63f2":"# Group By, Having & Count\n[Tutorial Link](https:\/\/www.kaggle.com\/dansbecker\/group-by-having-count)\n\nNow that we know how to select raw data, we will learn how to group selected data and count things within those groups to answer questions like: \n- How many of each kind of fruit has our store sold?\n- How many species of animal has the vet office treated?\n\n","aebf79ef":"A SQL query without **AS**\n<img src=\"https:\/\/i.imgur.com\/VelX9tP.png\"\/>\n\nSame query with **AS**\n<img src=\"https:\/\/i.imgur.com\/teF84tU.png\"\/>","c3068d94":"`block_timestamp` column contains date of each transaction in DATETIME format, we will convert it into DATE format using **DATE()**.\n\nWe will do that using CTE, then in next part we will count the number of transactions per month and sort them so earlier dates appear first.","568c1dc5":"## Example: Which day of the week has the most fatal motor accidents?\nWe'll investigate the `accident_2015` table from US Traffic Fatality Records database, which contains information on traffic accidents in the US where at least one person died.","81b70337":"**Setup**\n- import `from google.cloud import bigquery`\n- create a client object `client = bigquery.Client()\n\n**Fetching Dataset**\n- create a reference to dataset `dataset_ref = client.dataset(\"dataset_name\", project=\"project_name\")`\n- fetch dataset `dataset = client.get_dataset(dataset_ref)\n\n**List all tables present in dataset**\n- list tables `tables = list(client.list_tables(dataset))` `print(table[0].table_id)`\n\n**Fetch a table from dataset**\n- create reference to a table `table_ref = dataset_ref.table(\"table_name\")`\n- fetch table `table = client.get_table(table_ref)`\n\n**Schema**\n- schema of a table `table.schema`\n\n**List rows**\n- all rows `client.list_rows(table, max_results=5).to_dataframe()`\n- specific columns `client.list_rows(table, selected_fields=table.schema[:1], max_results=5).to_dataframe()`","39c8acd1":"To get information that applies to a certain pet, we match the `ID` column in the `pets` table to the `Pet_ID` column in the `owners` table.\n\n<img src=\"https:\/\/i.imgur.com\/eXvIORm.png\"\/>\n\nFor example:\n- `pets` table shows that `Moon` is the pet with `ID` no. 2\n- `owners` table shows that pet with ID no. 2 belongs to `Magnus Burnsides`","a7ab2d27":"We can find all the functions we can use with dates in BigQuery in [this documentation](https:\/\/cloud.google.com\/bigquery\/docs\/reference\/legacy-sql#datetimefunctions)","944a9a99":"# SELECT, FROM & WHERE\n[Tutorial Link](https:\/\/www.kaggle.com\/dansbecker\/select-from-where)\n\nNow that we know how to access and examine a dataset, we will start writing SQL queries. SQL queries help us sort through massive datasets, to retrieve only the information we want.\n\nIn this tutorial we will **SELECT**, **FROM** and **WHERE** to get data from specific columns based on specified conditions.\n\nWe will work with an small imaginary dataset `pet_records` which contains just one table, called `pets`.\n<img src=\"https:\/\/i.imgur.com\/fI5Pvvp.png\"\/>\n\n## SELECT ... FROM\nThe most basic SQL query selects single column from a table. To do this \n- specify the column you want after the word **SELECT**, and then\n- specify the table after the word **FROM**\n\nTo select the `Name` column (from the `pets` table, in the `pet_records` databse in the `bigquery-public-data` project), our query would appear as follows:\n<img src=\"https:\/\/i.imgur.com\/c3GxYRt.png\"\/>\n\n> Note: When writing a SQL query, the argument passed to **FROM** is not in single or double quotation marks (' or \"). Its in backticks (\\`).\n\n## WHERE\nBigQuery datasets are huge, so we'll usually want to return rows meeting specific conditions. We can do so using the **WHERE** clause.\n\nThe query below returns the entries from the `name` column that are in rows where the `Animal` column has the text `Cat`.\n<img src=\"https:\/\/i.imgur.com\/HJOT8Kb.png\"\/>\n"}}