{"cell_type":{"f28800a2":"code","8b5199ff":"code","c73ead32":"code","a0ae6144":"code","dc6c92fa":"code","021844de":"code","ff166419":"code","fdf44190":"code","e0a7080e":"code","596db598":"code","ea44c69e":"code","ac38c61c":"code","561fa673":"code","4048efb6":"code","7365d3cd":"code","e5083cd4":"code","aa9f97fe":"code","4ebbecc3":"code","080e6651":"code","bddc0629":"code","d42dc557":"code","a58539cd":"code","41b5ecef":"code","9b2ef82c":"code","ac79df02":"code","3dd0fcf7":"code","13a692d4":"code","a8abab89":"code","a8e64cc6":"code","b39d8023":"code","c5937100":"code","d9bf15d4":"code","631c5c51":"code","d52b05ef":"code","9065d351":"code","29d64268":"code","cd70be6f":"code","eae0727f":"code","f9723c43":"code","8d528403":"code","dbd525e9":"code","8826b1fb":"code","b47c1e7d":"code","febbdf40":"code","04ec0c11":"code","9b3526e7":"code","b85a20bb":"code","96f14754":"code","a41ca240":"code","a406e23e":"code","047697e5":"code","5c3a6c00":"code","cc953ee5":"code","185d36bd":"code","11413927":"code","0b86ecc7":"code","cff04b45":"code","5bff40b7":"code","22d2f7e3":"code","f4196494":"code","f2c8e026":"markdown","5b687bd1":"markdown","2b6af1f1":"markdown","77931795":"markdown","d195dd43":"markdown","ddcd488b":"markdown","c42b6dcf":"markdown","1670f2a2":"markdown"},"source":{"f28800a2":"import numpy as np \nimport pandas as pd \n\nimport re\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfrom tqdm.auto import tqdm\nfrom bs4 import BeautifulSoup\nimport re\nimport string\n\nimport numpy as np\n\nfrom textblob import TextBlob\n#from afinn import Afinn\n#from textstat.textstat import textstat\n\nfrom nltk.corpus import stopwords\n\n#from preprocess import normalize_texttall\n\nfrom datetime import datetime","8b5199ff":"es= pd.read_csv('\/kaggle\/input\/jigsaw-toxic-more-language\/train_es.csv')\nfr= pd.read_csv('\/kaggle\/input\/jigsaw-toxic-more-language\/train_fr.csv')\nde= pd.read_csv('\/kaggle\/input\/jigsaw-toxic-more-language\/train_de.csv')\nen= pd.read_csv('\/kaggle\/input\/jigsaw-toxic-comment-classification-challenge\/train.csv')","c73ead32":"from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = 'all'\nes.head()\nfr.head()\nde.head()","a0ae6144":"weights = {}\nfor c in ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']:\n    weights[c]=(es[c]==1).sum()\n\ntotal_weight = sum(weights.values())\n\nfor c in ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']:\n    weights[c]=np.log(total_weight\/weights[c])\nweights","dc6c92fa":"#3 different labels: weighted score ys,1-0 class y,sum(total 5 classes) y5\nes['ys']=0\nfor c in ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']:\n    es['ys']=es['ys']+es[c]*weights[c]\nes['y5'] = (es[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1)).astype(int)\nes['y'] = (es[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) > 0).astype(int)\n#df = df[['comment_text', 'y']].rename(columns={'comment_text': 'text'})\nes.head(5)\nes['lan']='es'\nes['ys'].value_counts()","021844de":"def label_df(tmp,lan):\n    tmp['ys']=0\n    for c in ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']:\n        tmp['ys']=tmp['ys']+tmp[c]*weights[c]\n    tmp['y5'] = (tmp[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1)).astype(int)\n    tmp['y'] = (tmp[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) > 0).astype(int)\n    #df = df[['comment_text', 'y']].rename(columns={'comment_text': 'text'})\n    tmp.head(5)\n    tmp['lan']=lan\n    tmp['ys'].value_counts()\n    return tmp","ff166419":"fr = label_df(fr,'fr')\nde = label_df(de,'de')\nen = label_df(en,'en')","fdf44190":"def print_step(step):\n    print('[{}]'.format(datetime.now()) + ' ' + step)","e0a7080e":"val = pd.read_csv('..\/input\/jigsaw-toxic-severity-rating\/validation_data.csv')\nval.head()","596db598":"less = val['less_toxic'].to_frame().rename(columns={'less_toxic':'comment_text'})\nmore = val['more_toxic'].to_frame().rename(columns={'more_toxic':'comment_text'})","ea44c69e":"ft_cols = [c for c in less.columns]\n#ft_cols\nft_cols.remove('comment_text')\n#ft_cols.remove('clean_text')","ac38c61c":"less.to_csv('pro_less.csv')\nmore.to_csv('pro_more.csv')","561fa673":"from sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB,ComplementNB\n#lightGBM\nimport optuna\nfrom sklearn.model_selection import train_test_split\nimport lightgbm as lgb\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.sparse import csr_matrix,hstack","4048efb6":"def proba_val(model,xless,xmore):\n    p1 = model.predict_proba(xless)[:,1]\n    p2 = model.predict_proba(xmore)[:,1]\n    return (p1<p2).mean()","7365d3cd":"tf1 = TfidfVectorizer()\nmb = MultinomialNB()","e5083cd4":"X1 = tf1.fit_transform(en['comment_text'])\ny1 = en['y']","aa9f97fe":"X1_p = csr_matrix(en.loc[:,ft_cols].to_numpy())\nX1_p.shape,X1.shape","4ebbecc3":"X1_all = hstack((X1,X1_p))","080e6651":"v1 = tf1.transform(less['comment_text'])\nv2 = tf1.transform(more['comment_text'])","bddc0629":"v1_p = csr_matrix(less.loc[:,ft_cols].to_numpy())\nv2_p = csr_matrix(more.loc[:,ft_cols].to_numpy())\nv1_all = hstack((v1,v1_p))\nv2_all = hstack((v2,v2_p))","d42dc557":"mb.fit(X1,y1)","a58539cd":"proba_val(mb,v1,v2)","41b5ecef":"# use extended feature but reduce correct rate\nmb2 = MultinomialNB()\nmb2.fit(X1_all,y1)\nproba_val(mb2,v1_all,v2_all)","9b2ef82c":"from sklearn.linear_model import Ridge","ac79df02":"def eval_ridge(model,v1,v2):\n    p1 = model.predict(v1)\n    p2 = model.predict(v2)\n    # Validation Accuracy\n    return (p1 < p2).mean()","3dd0fcf7":"ridge1 = Ridge(alpha=1)\nridge1.fit(X1,en['ys'])\nprint('successfully fit')\nprint(eval_ridge(ridge1,v1=v1,v2=v2))\nprint('')","13a692d4":"ridge2 = Ridge(alpha=0.5)\nridge2.fit(X1,en['ys'])\nprint('successfully fit')\nprint(eval_ridge(ridge2,v1=v1,v2=v2))\nprint('')","a8abab89":"ridge3 = Ridge(alpha=2)\nridge3.fit(X1,en['ys'])\nprint('successfully fit')\nprint(eval_ridge(ridge3,v1=v1,v2=v2))\nprint('')","a8e64cc6":"ridge4 = Ridge(alpha=2.5) #alpha=3, correct rate=0.6872\nridge4.fit(X1,en['ys'])\nprint('successfully fit')\nprint(eval_ridge(ridge4,v1=v1,v2=v2))\nprint('')","b39d8023":"tf1es = TfidfVectorizer()\nX1es = tf1es.fit_transform(es['comment_text'])\nyses = es['ys']","c5937100":"tf1fr = TfidfVectorizer()\nX1fr = tf1fr.fit_transform(fr['comment_text'])\nysfr = fr['ys']","d9bf15d4":"tf1de = TfidfVectorizer()\nX1de = tf1de.fit_transform(de['comment_text'])\nysde = de['ys']","631c5c51":"v1de=tf1de.transform(less['comment_text'])\nv2de=tf1de.transform(more['comment_text'])\nv1fr=tf1fr.transform(less['comment_text'])\nv2fr=tf1fr.transform(more['comment_text'])\nv1es=tf1es.transform(less['comment_text'])\nv2es=tf1es.transform(more['comment_text'])","d52b05ef":"ridge1de = Ridge(alpha=1)\nridge1de.fit(X1de,de['ys'])\nprint('successfully fit')\nprint(eval_ridge(ridge1de,\n                 v1=v1de,\n                 v2=v2de))","9065d351":"ridge1fr = Ridge(alpha=1)\nridge1fr.fit(X1fr,fr['ys'])\nprint('successfully fit')\nprint(eval_ridge(ridge1fr,\n                 v1=v1fr,\n                 v2=v2fr))","29d64268":"ridge1es = Ridge(alpha=1)\nridge1es.fit(X1es,es['ys'])\nprint('successfully fit')\nprint(eval_ridge(ridge1es,\n                 v1=v1es,\n                 v2=v2es))","cd70be6f":"ridge2de = Ridge(alpha=0.5)\nridge2de.fit(X1de,de['ys'])\nprint('successfully fit')\nprint(eval_ridge(ridge2de,\n                 v1=v1de,\n                 v2=v2de))\n\nridge2fr = Ridge(alpha=0.5)\nridge2fr.fit(X1fr,fr['ys'])\nprint('successfully fit')\nprint(eval_ridge(ridge2fr,\n                 v1=v1fr,\n                 v2=v2fr))\n\nridge2es = Ridge(alpha=0.5)\nridge2es.fit(X1es,es['ys'])\nprint('successfully fit')\nprint(eval_ridge(ridge2es,\n                 v1=v1es,\n                 v2=v2es))","eae0727f":"ridge3de = Ridge(alpha=2)\nridge3de.fit(X1de,de['ys'])\nprint('successfully fit')\nprint(eval_ridge(ridge3de,\n                 v1=v1de,\n                 v2=v2de))\n\nridge3fr = Ridge(alpha=2)\nridge3fr.fit(X1fr,fr['ys'])\nprint('successfully fit')\nprint(eval_ridge(ridge3fr,\n                 v1=v1fr,\n                 v2=v2fr))\n\nridge3es = Ridge(alpha=2)\nridge3es.fit(X1es,es['ys'])\nprint('successfully fit')\nprint(eval_ridge(ridge3es,\n                 v1=v1es,\n                 v2=v2es))","f9723c43":"#average of four language\np1 = ridge1.predict(v1)+ridge1es.predict(v1es)+ridge1fr.predict(v1fr)+ridge1de.predict(v1de)\np2 = ridge1.predict(v2)+ridge1es.predict(v2es)+ridge1fr.predict(v2fr)+ridge1de.predict(v2de)\n# Validation Accuracy\n(p1 < p2).mean()","8d528403":"#average of four language\np1 = ridge2.predict(v1)+ridge2es.predict(v1es)+ridge2fr.predict(v1fr)+ridge2de.predict(v1de)\np2 = ridge2.predict(v2)+ridge2es.predict(v2es)+ridge2fr.predict(v2fr)+ridge2de.predict(v2de)\n# Validation Accuracy\n(p1 < p2).mean()","dbd525e9":"p1 = ridge3.predict(v1)+ridge3es.predict(v1es)+ridge3fr.predict(v1fr)+ridge3de.predict(v1de)\np2 = ridge3.predict(v2)+ridge3es.predict(v2es)+ridge3fr.predict(v2fr)+ridge3de.predict(v2de)\n# Validation Accuracy\n(p1 < p2).mean()","8826b1fb":"#import random\n#random.seed(2333)\n#len(id0),len(id1)\n#sample_index = random.sample(range(len(id0)),len(id1))\n#id0_s = id0.iloc[list(sample_index)]\n#sample_id = [id1,id0_s]","b47c1e7d":"#extended dataset\next = pd.concat([en,\nes[es['y']==1],\nfr[fr['y']==1],\nde[de['y']==1]])","febbdf40":"tf1ext = TfidfVectorizer()\nX1ext = tf1ext.fit_transform(ext['comment_text'])\nysext = ext['ys']","04ec0c11":"v1ext=tf1ext.transform(less['comment_text'])\nv2ext=tf1ext.transform(more['comment_text'])","9b3526e7":"ridge1ext = Ridge(alpha=1)\nridge1ext.fit(X1ext,ext['ys'])\nprint('successfully fit')\nprint(eval_ridge(ridge1ext,\n                 v1=v1ext,\n                 v2=v2ext))\n\nridge2ext = Ridge(alpha=0.5)\nridge2ext.fit(X1ext,ext['ys'])\nprint('successfully fit')\nprint(eval_ridge(ridge2ext,\n                 v1=v1ext,\n                 v2=v2ext))\n\nridge3ext = Ridge(alpha=2)\nridge3ext.fit(X1ext,ext['ys'])\nprint('succextsfully fit')\nprint(eval_ridge(ridge3ext,\n                 v1=v1ext,\n                 v2=v2ext))","b85a20bb":"#acc2 = mean_squared_error(y2, model2.predict(X2))\/ mean_squared_error(y2,np.repeat(np.mean(y2),len(y2)))","96f14754":"#average of four language\np1 = ridge1.predict(v1)+ridge1es.predict(v1es)+ridge1fr.predict(v1fr)+ridge1de.predict(v1de)+ridge1ext.predict(v1ext)\np2 = ridge1.predict(v2)+ridge1es.predict(v2es)+ridge1fr.predict(v2fr)+ridge1de.predict(v2de)+ridge1ext.predict(v2ext)\n# Validation Accuracy\n(p1 < p2).mean()","a41ca240":"#average of four language\np1 = ridge2.predict(v1)+ridge2es.predict(v1es)+ridge2fr.predict(v1fr)+ridge2de.predict(v1de)+ridge2ext.predict(v1ext)\np2 = ridge2.predict(v2)+ridge2es.predict(v2es)+ridge2fr.predict(v2fr)+ridge2de.predict(v2de)+ridge2ext.predict(v2ext)\n# Validation Accuracy\n(p1 < p2).mean()","a406e23e":"#average of four language\np1 = ridge3.predict(v1)+ridge3es.predict(v1es)+ridge3fr.predict(v1fr)+ridge3de.predict(v1de)+ridge3ext.predict(v1ext)\np2 = ridge3.predict(v2)+ridge3es.predict(v2es)+ridge3fr.predict(v2fr)+ridge3de.predict(v2de)+ridge3ext.predict(v2ext)\n# Validation Accuracy\n(p1 < p2).mean()","047697e5":"df_sub = pd.read_csv(\"..\/input\/jigsaw-toxic-severity-rating\/comments_to_score.csv\")\ndf_sub.head()","5c3a6c00":"X_test1 =tf1.transform(df_sub['text'])\nX_testde=tf1de.transform(df_sub['text'])\nX_testfr=tf1fr.transform(df_sub['text'])\nX_testes=tf1es.transform(df_sub['text'])","cc953ee5":"X_testext=tf1ext.transform(df_sub['text'])","185d36bd":"p3 = 3*ridge3.predict(X_test1)+ridge3es.predict(X_testes)+ridge3fr.predict(X_testfr)+ridge3de.predict(X_testde)+ridge3ext.predict(X_testext)","11413927":"df_sub['score'] = p3","0b86ecc7":"df_sub['score'].count()","cff04b45":"df_sub['score'].count()-df_sub['score'].nunique()","5bff40b7":"df_sub[['comment_id', 'score']].to_csv('submission.csv', index=False)","22d2f7e3":"df_sub.head()","f4196494":"df_sub[['comment_id', 'score']].to_csv('submission.csv', index=False)","f2c8e026":"## only extend positive label","5b687bd1":"# pipeline : only English sample","2b6af1f1":"## submission","77931795":"## use different machine and take average","d195dd43":"## ridge","ddcd488b":"# validation data","c42b6dcf":"# data cleaning","1670f2a2":"## augment ridge"}}