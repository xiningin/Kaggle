{"cell_type":{"99dfc5d2":"code","36171dfc":"code","5f85bbc0":"code","12315f3e":"code","a65c480d":"code","03074e01":"code","9d7d0287":"code","76aad68b":"code","f7d879c9":"code","5e0bf5f4":"code","67011fc2":"code","765394a0":"code","ba265951":"code","903e5b7c":"markdown","014aac82":"markdown","06f0d648":"markdown","6a9cfaf3":"markdown","df748ba0":"markdown","1fb90d76":"markdown","2f944b2c":"markdown","f4de6fdd":"markdown","1abef506":"markdown","239fbc4c":"markdown"},"source":{"99dfc5d2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","36171dfc":"import seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, roc_curve,precision_recall_curve, auc\nimport matplotlib.pyplot as plt\n%matplotlib inline","5f85bbc0":"creditcard_data = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')\ncreditcard_data.head()","12315f3e":"# Question 2 code here.\nX = creditcard_data.drop('Class', axis = 'columns').values\ny = creditcard_data.Class.values\nXtrain, Xtest, ytrain, ytest = train_test_split(X,y, test_size = 0.5,random_state=0)","a65c480d":"# Question 4 code here\nclass_amount_LR = LogisticRegression(penalty = 'none', max_iter=10000)\namount_train = Xtrain[:,-1].reshape(-1, 1) #Amount is the last feature of the\u2423data before the Class and we dropped Class to get Xtrain\nclass_amount_lr = class_amount_LR.fit(amount_train, ytrain)\n#plot\namount_test = Xtest[:,-1].reshape(-1,1)\n#True Test Data\nfig, ax = plt.subplots(dpi = 100)\nax.scatter(x= amount_test, y= ytest, color=\"green\")\nax.set_title('True Test Data')\nax.set_ylabel('Classes')\nax.set_xlabel('Amount')\nax.set_yticks([0,1])\n#Prediction\nxp = np.reshape(np.linspace(0,max(amount_test),50),(-1,1))\nyp = class_amount_lr.predict(xp)\nyp_prop = class_amount_lr.predict_proba(xp)\nax.plot(xp[:,0],yp)\nax.plot(xp[:,0],yp_prop[:,1])\nax.legend([\"Predicted class\", \"Probability\", \"True test data\"],bbox_to_anchor=(1.04,0.5), loc=\"center left\")\nplt.show()","03074e01":"# Calculate performance measures from scratch\n# TP: true postives\n# TN: true negatives\n# FP: False positives\n# FN: False negatives\ndef compute_performance(yhat, y, classes):\n    \n    # First, get tp, tn, fp, fn\n    tp = sum(np.logical_and(yhat == classes[1], y == classes[1]))\n    tn = sum(np.logical_and(yhat == classes[0], y == classes[0]))\n    fp = sum(np.logical_and(yhat == classes[1], y == classes[0]))\n    fn = sum(np.logical_and(yhat == classes[0], y == classes[1]))\n    print(f\"tp: {tp} tn: {tn} fp: {fp} fn: {fn}\")\n    # Accuracy\n    acc = (tp + tn) \/ (tp + tn + fp + fn)\n    # Precision\n    # \"Of the ones I labeled +, how many are actually +?\"\n    precision = tp \/ (tp + fp)\n    # Recall\n    # \"Of all the + in the data, how many do I correctly label?\"\n    recall = tp \/ (tp + fn)\n    # Sensitivity\n    # \"Of all the + in the data, how many do I correctly label?\"\n    sensitivity = recall\n    # Specificity\n    # \"Of all the - in the data, how many do I correctly label?\"\n    specificity = tn \/ (fp + tn)\n    # Print results\n    print(\"Accuracy:\",round(acc,3),\"Recall:\",round(recall,3),\"Precision:\",round(precision,3),\"Sensitivity:\",round(sensitivity,3),\"Specificity:\",round(specificity,3))\n    ## Put code here to compute criteria:\ny_hat_amount = class_amount_lr.predict(amount_test)\ncompute_performance(y_hat_amount, ytest, [0,1])\n## Put code here to compute whatever else you might need to answer the question.\nprint('-------')\nprint(f'Amount corresponds to the unique positive labaled instance is{amount_test[y_hat_amount == 1][0][0]}')\nprint(f'Coefficient of Amount is {class_amount_lr.coef_[0,-1]}') #Amount's\u2423coefficient","9d7d0287":"# Code for Question 6\ncredit_LR = LogisticRegression(penalty = 'none', max_iter=10000)\ncredit_lr = credit_LR.fit(Xtrain, ytrain) #Xtrain has all feature except for\u2423Class\nprint(f'Coefficient of Amount is {credit_lr.coef_[0,-1]}') #Amount's coefficient","76aad68b":"#plot Class against Amount to see if it's getting any better\n#True Test Data\namount_test = Xtest[:,-1].reshape(-1,1)\nfig, ax = plt.subplots(dpi = 100)\ny_hat_all = credit_lr.predict(Xtest)\nsct = ax.scatter(x= amount_test, y=y_hat_all, c= ytest, alpha=0.5, label=ytest)\nax.set_title('Test Data')\nax.set_ylabel('Predicted Classes')\nax.set_xlabel('Amount')\nax.set_yticks([0,1])\nax.legend(handles=sct.legend_elements()[0], labels=[\"True negative\", \"True\u2423positive\"],\nloc=\"center left\", bbox_to_anchor=(1.04,0.5))\nplt.show()\n# It is better indeed","f7d879c9":"# Code for Question 7\ncompute_performance(y_hat_all, ytest, [0,1])","5e0bf5f4":"# ROC curve for Amount-only classifier\npositive_prop_amount = class_amount_lr.predict_proba(amount_test)[:,1]\nfpr1, tpr1, _ = roc_curve(ytest, positive_prop_amount)\nax = sns.lineplot(x=fpr1, y=tpr1)\nax.set_title('ROC curve for Amount-only classifier')\nax.set_xlabel('False Positive Rate (TPR)')\nax.set_ylabel('True Positive Rate (TPR)')\nplt.show()","67011fc2":" # ROC for all-variable classifier\npositive_prop_all = credit_lr.predict_proba(Xtest)[:,1]\nfpr2, tpr2, _ = roc_curve(ytest, positive_prop_all)\nax = sns.lineplot(x=fpr2, y=tpr2)\nax.set_title('ROC curve for All-variables classifier')\nax.set_xlabel('False Positive Rate (TPR)')\nax.set_ylabel('True Positive Rate (TPR)')\nplt.show()","765394a0":"# PRC for Amount-only classifier\nprecision_amount, recall_amount, _ = precision_recall_curve(ytest,positive_prop_amount)\nax = sns.lineplot(x=recall_amount, y=precision_amount)\nax.set_title('Precision-Recall Curve for Amount-only classifier')\nax.set_xlabel('Recall')\nax.set_ylabel('Precision')\nplt.show()","ba265951":"# PRC for all-variable classifier\nprecision, recall, _ = precision_recall_curve(ytest, positive_prop_all)\nax = sns.lineplot(x=recall, y=precision)\nax.set_title('Precision-Recall Curve for All-variables classifier')\nax.set_xlabel('Recall')\nax.set_ylabel('Precision')\nplt.show()","903e5b7c":"## **Question 4: \/15 pts**\nCreate a instance of sklearn\u2019s LogisticRegression object for unpenalized logistic regression. Note:\nIf you get a warning about convergence of coef_, try increasing the max_iter parameter. I used\nmax_iter=10000 which seems to supress the warning.\n<br>\nUsing this object, **run a logisitic regression analysis** of Class (y-variable) against Amount\n(x-variable) using your training data.\n<br>\nThen **make a plot with three main components based on the analysis:** 1. Scatter-plot of\nAmount and Outcome on your test data 2. A curve showing the prediction (0 or 1, using predict - this curve will jump between 0 and 1) as a function of Amount 3. A curve showing the predicted\nprobability of a positive outcome (using predict_proba) as a function of Amount. Note that\npredict_proba will return both p(Outcome=0) and p(Outcome=1) in an array.","014aac82":"## **The Dataset**\nThe dataset contains transactions made by credit cards in September 2013 by European cardholders.\nThis dataset presents transactions that occurred in two days, where we have 492 frauds out of\n284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for\n0.172% of all transactions.\nIt contains only numerical input variables which are the result of a PCA transformation. Unfortu-\nnately, due to confidentiality issues, we cannot provide the original features and more background\ninformation about the data. Features V1, V2, ... V28 are the principal components obtained with\nPCA, the only features which have not been transformed with PCA are \u2018Time\u2019 and \u2018Amount\u2019. [You\nwill learn about PCA in a later Lesson.] Feature \u2018Time\u2019 contains the seconds elapsed between\neach transaction and the first transaction in the dataset. The feature \u2018Amount\u2019 is the transac-\ntion Amount. Feature \u2018Class\u2019 is the response variable and it takes value 1 in case of fraud and 0\notherwise.","06f0d648":"\n## **Question 5: 15 pts**\nCompute the label-based criteria we discussed in the Lesson for your amount-only classifier using\nthe test data. Use a threshold of 0.5. Answer the questions in this text box below.\n<br>\n\u2022 How many of the test instances are labeled positive by your classifier?\n<br>\n**YOUR ANSWER HERE:** Only one.\n<br>\n\u2022 Choose one of the positively-labeled test instances, and explain why the classifier labeled it\npositive.\n<br>\n**YOUR ANSWER HERE:** the one positively-labeled test instance coresponds to amount\n25691.16. As most of the data are legit instances and most of them are well below Amount=10000,\nthe classifier associated high fraud probability with higher amount used. This can be seen by\nlooking at the Amount\u2019s coe\ufb00icient in the fit model.\n\n<br>\n\u2022 Is this classifier useful for finding fraudulent transactions? Explain in one or two sentences.\n<br>\n\n**YOUR ANSWER HERE:** No, it only labeld one instance as positive and it is wrong. As the\nfraud instances are rare in the data, we need more features to better predict them.","6a9cfaf3":"## **Question 9: \/15 pts**\nPlot precision-recall curves for both of your classifiers using the cell below. Be sure to label your axes.\n<br>\n\u2022 Which classifier is preferable if we want to recover at least 60% of fraudulent transactions?\n<br>\n**YOUR ANSWER:** All-variables classifier.","df748ba0":"## **Question 2: \/5 pts**\n<br>\nThen split the data into train and test for the outcome\/response and the predictor variables. Hold\nout 50% of observations as the test set. Pass random_state=0 to train_test_split to ensure you\nget the same train and tests sets as the solution.","1fb90d76":"## **Question 6: \/10 pts**\nNow fit a logistic regression model to the training data and include all the variables in the data\nframe (except for Class) in the cell below. You will want to make a new object like you did for the\nsimpler model. Answer the following question.\n<br>\n\u2022 According to this more complex model, are larger or smaller Amounts more strongly associ-\nated with fraud, if all other variables are held equal?\n<br>\n**YOUR ANSWER HERE:** Amount has a negative coeffecient, so the fraud-Amount relation is\ninversely proportional. Thus, smaller Amounts are more strongly associated with fraud.","2f944b2c":"## **Question 3: \/5 pts**\n<br>\nRead the documentation for sklearn\u2019s LogisticRegression. In no more than 2 sentences per bullet\npoint, answer the following in your own words.\n<br>\n\u2022 Does LogisticRegression use a penalty by default? If yes, what penalty?\n<br>\n\n**YOUR ANSWER HERE**: LogisticRegression uses L2 penalty by default.\n<br>\n\u2022 If we apply a penalty during learning, what difference do you expect to see in the resulting\ncoe\ufb00icients, relative to not applying a penalty during learning?\n<br>\n**YOUR ANSWER HERE:** Coe\ufb00icients in the regularization case tend to be smaller in value\nthan those without regularization.\n<br>\n\u2022 If using the default settings of LogisticRegression in sklearn, should you include a column\nof 1s in your feature\/design matrix? Briefly explain why or why not.\n<br>\n**YOUR ANSWER HERE:** No, because the defualt settings sets fit_intercept=True and this\nadds self.coef_ to the decision function.","f4de6fdd":"## **Question 8: \/15 pts**\nPlot ROC curves for both of your classifiers using the cells below, then answer the following ques-\ntions, computing whatever quantities you need to answer them.\n<br>\n\u2022 Which classifier has a higher estimated probability of correctly distinguishing between a\npositive and a negative instance? How do you know?\n<br>\n**YOUR ANSWER:** All-variables classifier because the area under the ROC curve correspons to\nthe ability of the classifier to correctly distinguishing between a positive and a negative instance.\n<br>\n\u2022 How could you explain a result where a logistic regression classifier produces an AUROC that\nis \u201cworse than random\u201d, i.e. less than 0.5, even on its training set?\n<br>\n**YOUR ANSWER:** This means there is a mistake in the implementation of the classifier, e.g.,\nincorrectly labeled positive class.","1abef506":"## **Question 7: \/15 pts**\nIn the cell below, Compute the label-based criteria we discussed in the Lesson for new classifier\nusing the test data. (You don\u2019t have to copy the function down into this cell; just call it again\nhere.) Use a threshold of 0.5. Answer the questions in this text box below.\n<br>\n\u2022 How many of the test instances are labeled positive by your classifier?\n<br>\n**YOUR ANSWER:** 146+34 = 180 instances\n<br>\n\u2022 Is this classifier better or worse than the amount-only classifier for finding fraudulent\ntransactions? Explain in one or two sentences.\n<br>\n**YOUR ANSWER:** It is better as it predicts 60% of fraud instances with precision 80%, as\nopposed to 0% fraud prediction for the amount-only classifier.","239fbc4c":"## **Question 1: \/5 pts**\n<br>\nRead in the creditcard.csv dataset and display the first 5 rows"}}