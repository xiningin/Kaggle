{"cell_type":{"eace71d8":"code","3eee01a3":"code","95069704":"code","626d3c52":"code","3b7d40ce":"code","b283e36e":"code","1119e0f1":"code","90c09bff":"code","d8c9572f":"code","0f6cdf76":"code","a9eb4c66":"code","ba2154c0":"code","cb88cc1c":"code","78a53da8":"code","a2d320d0":"code","b30bebd2":"code","012e10f2":"code","ebd4b7eb":"code","2eaab098":"code","e1886d8d":"code","a87f6d0f":"code","a946ce36":"code","9c20bcac":"markdown","e0dade75":"markdown","9797b076":"markdown","1a2ca512":"markdown","647ea379":"markdown"},"source":{"eace71d8":"import pandas as pd\nimport numpy as np\nimport matplotlib as plt\nfrom sklearn.model_selection import train_test_split","3eee01a3":"data = pd.read_csv(\"..\/input\/pima-indians-diabetes-database\/diabetes.csv\")","95069704":"data.head()","626d3c52":"data.info()","3b7d40ce":"data.isnull().sum()","b283e36e":"# convert to a numpy array\ntmp = data.to_numpy()\n# separate labels from values\nx_values, y_values = tmp[:,:-1], tmp[:,-1]\n# Free the unnecessary space.\ndel data\ndel tmp","1119e0f1":"# split into training and testing set\nx_train, x_test, y_train, y_test = train_test_split(x_values, y_values, test_size=0.33, random_state=17)","90c09bff":"print(x_train.shape)","d8c9572f":"import tensorflow as tf","0f6cdf76":"\nclass myCallback(tf.keras.callbacks.Callback):\n      def on_epoch_end(self, epoch, logs={}):\n        accuracy = 0.7 # Percentage Accuracy.\n        if(logs.get('accuracy') != None) and (logs.get('accuracy') >= accuracy): # Experiment with changing this value\n          print(f\"\\nReached {accuracy*100}% accuracy so cancelling training!\")\n          self.model.stop_training = True\n\ncallbacks = myCallback()","a9eb4c66":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(16, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    #tf.keras.layers.Dense(32, activation='relu'),\n    #tf.keras.layers.Dropout(0.2),\n    #tf.keras.layers.Dense(64, activation=tf.nn.leaky_relu),\n    #tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dropout(0.4),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(loss='binary_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy'])","ba2154c0":"history = model.fit(\n    x_train, \n    y_train, \n    steps_per_epoch=50,\n    epochs=9, \n    callbacks=[callbacks]\n)","cb88cc1c":"model.evaluate(x_test, y_test)","78a53da8":"from sklearn.ensemble import RandomForestClassifier","a2d320d0":"clf = RandomForestClassifier(\n    max_depth=25,\n    random_state=12,\n    n_estimators=50, \n    bootstrap=True, \n    verbose=0\n)\nclf.fit(x_train, y_train)","b30bebd2":"clf.score(x_test, y_test)","012e10f2":"import xgboost as xgb\nfrom sklearn.metrics import accuracy_score","ebd4b7eb":"train = xgb.DMatrix(x_train, label=y_train)\ntest = xgb.DMatrix(x_test, label=y_test) ","2eaab098":"param = {\n    'max_depth':15,\n    'eta':0.20,\n    'objective':'binary:logistic',\n}\nepoch = 15","e1886d8d":"model = xgb.train(param, train, epoch)","a87f6d0f":"predictions = model.predict(test)\nfor i in range(predictions.shape[0]):\n    predictions[i] = 1 if predictions[i] > 0.5 else 0","a946ce36":"accuracy_score(y_test, predictions)","9c20bcac":"## Attempt using convoluted neural networks\nI will try to solve this using neural networks, using tensorflow \n\nAccuracy plateau at around 68% ~ 69%, so I cancelled the training at 70% using callback.","e0dade75":"# PIMA Indian Diabetes Databse - ML Analysis","9797b076":"## Read, Clean and Prepare data","1a2ca512":"## Attempt using Random Forest\nPlateau at 77.6% accuracy. Better performance than CNN, but not good enough.","647ea379":"## Attempt using XGB Classifier\nAchieved 76.8% accuracy using [xgboost](https:\/\/xgboost.ai\/)."}}