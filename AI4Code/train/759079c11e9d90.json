{"cell_type":{"caf009ec":"code","c551f039":"code","0deb246c":"code","8735cab0":"code","870a85ed":"code","eb6e4ab7":"code","5fa15ebb":"code","d31eb97f":"code","4ff6e3da":"code","5c55d0e5":"code","2c2c4703":"markdown","9f78e934":"markdown","4dc61128":"markdown","f2534336":"markdown","cda67f4b":"markdown","ac2902f8":"markdown"},"source":{"caf009ec":"import numpy as np \nimport pandas as pd \npd.options.display.max_columns = 20\nimport os\nfrom sklearn.metrics import mean_squared_error\nfrom catboost import CatBoostRegressor\nfrom colorama import Fore, Back, Style\nimport seaborn as sns\nimport plotly.express as px\nimport matplotlib\nfrom matplotlib.patches import Patch\nfrom matplotlib import pyplot as plt\nplt.rcParams.update({'figure.max_open_warning': 0})\nplt.style.use('fivethirtyeight')\ncmap_data = plt.cm.Paired\ncmap_cv = plt.cm.coolwarm\nimport warnings\nwarnings.filterwarnings('ignore')","c551f039":"train = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/test.csv')","0deb246c":"target=pd.DataFrame()\n\n#Mug Fin Mart : Mug sold in Finland by KaggleMart\n#Mug hat Mart : Hat sold in Finland by KaggleMart\n#Mug sti Mart : Sitcker sold in Finland by KaggleMart...\n\n# FINLAND :\ntarget['Mug Fin Mart'] = train[((((train['product'] == 'Kaggle Mug') & (train['country']=='Finland'))==True) & (train['store']=='KaggleMart')==True)].groupby('date').sum()['num_sold']\ntarget['Hat Fin Mart'] = train[((((train['product'] == 'Kaggle Hat') & (train['country']=='Finland'))==True) & (train['store']=='KaggleMart')==True)].groupby('date').sum()['num_sold']\ntarget['Sti Fin Mart'] = train[((((train['product'] == 'Kaggle Sticker') & (train['country']=='Finland'))==True) & (train['store']=='KaggleMart')==True)].groupby('date').sum()['num_sold']\ntarget['Mug Fin Rama'] = train[((((train['product'] == 'Kaggle Mug') & (train['country']=='Finland'))==True) & (train['store']=='KaggleRama')==True)].groupby('date').sum()['num_sold']\ntarget['Hat Fin Rama'] = train[((((train['product'] == 'Kaggle Hat') & (train['country']=='Finland'))==True) & (train['store']=='KaggleRama')==True)].groupby('date').sum()['num_sold']\ntarget['Sti Fin Rama'] = train[((((train['product'] == 'Kaggle Sticker') & (train['country']=='Finland'))==True) & (train['store']=='KaggleRama')==True)].groupby('date').sum()['num_sold']\n\n# NORWAY:\ntarget['Mug Nor Mart'] = train[((((train['product'] == 'Kaggle Mug') & (train['country']=='Norway'))==True) & (train['store']=='KaggleMart')==True)].groupby('date').sum()['num_sold']\ntarget['Hat Nor Mart'] = train[((((train['product'] == 'Kaggle Hat') & (train['country']=='Norway'))==True) & (train['store']=='KaggleMart')==True)].groupby('date').sum()['num_sold']\ntarget['Sti Nor Mart'] = train[((((train['product'] == 'Kaggle Sticker') & (train['country']=='Norway'))==True) & (train['store']=='KaggleMart')==True)].groupby('date').sum()['num_sold']\ntarget['Mug Nor Rama'] = train[((((train['product'] == 'Kaggle Mug') & (train['country']=='Norway'))==True) & (train['store']=='KaggleRama')==True)].groupby('date').sum()['num_sold']\ntarget['Hat Nor Rama'] = train[((((train['product'] == 'Kaggle Hat') & (train['country']=='Norway'))==True) & (train['store']=='KaggleRama')==True)].groupby('date').sum()['num_sold']\ntarget['Sti Nor Rama'] = train[((((train['product'] == 'Kaggle Sticker') & (train['country']=='Norway'))==True) & (train['store']=='KaggleRama')==True)].groupby('date').sum()['num_sold']\n\n# SWEDEN:\ntarget['Mug Swe Mart'] = train[((((train['product'] == 'Kaggle Mug') & (train['country']=='Sweden'))==True) & (train['store']=='KaggleMart')==True)].groupby('date').sum()['num_sold']\ntarget['Hat Swe Mart'] = train[((((train['product'] == 'Kaggle Hat') & (train['country']=='Sweden'))==True) & (train['store']=='KaggleMart')==True)].groupby('date').sum()['num_sold']\ntarget['Sti Swe Mart'] = train[((((train['product'] == 'Kaggle Sticker') & (train['country']=='Sweden'))==True) & (train['store']=='KaggleMart')==True)].groupby('date').sum()['num_sold']\ntarget['Mug Swe Rama'] = train[((((train['product'] == 'Kaggle Mug') & (train['country']=='Sweden'))==True) & (train['store']=='KaggleRama')==True)].groupby('date').sum()['num_sold']\ntarget['Hat Swe Rama'] = train[((((train['product'] == 'Kaggle Hat') & (train['country']=='Sweden'))==True) & (train['store']=='KaggleRama')==True)].groupby('date').sum()['num_sold']\ntarget['Sti Swe Rama'] = train[((((train['product'] == 'Kaggle Sticker') & (train['country']=='Sweden'))==True) & (train['store']=='KaggleRama')==True)].groupby('date').sum()['num_sold']\n\ntarget.index = np.arange(0,target.shape[0],1).tolist()\ntarget.head(3)","8735cab0":"train_data = pd.DataFrame()\ntrain_data['date'] = np.unique(train['date']).tolist()\ntrain_data['date'] = pd.to_datetime(train_data['date'])\ntrain_data['year'] = train_data['date'].dt.year\ntrain_data['month'] = train_data['date'].dt.month\ntrain_data['day'] = train_data['date'].dt.day\ntrain_data['dayofweek'] = train_data['date'].dt.dayofweek\ntrain_data['dayofmonth'] = train_data['date'].dt.days_in_month\ntrain_data['dayofyear'] = train_data['date'].dt.dayofyear\ntrain_data['weekday'] = train_data['date'].dt.weekday\n\ntest_data = pd.DataFrame()\ntest_data['date'] = np.unique(test['date']).tolist()\ntest_data['date'] = pd.to_datetime(test_data['date'])\ntest_data['year'] = test_data['date'].dt.year\ntest_data['month'] = test_data['date'].dt.month\ntest_data['day'] = test_data['date'].dt.day\ntest_data['dayofweek'] = test_data['date'].dt.dayofweek\ntest_data['dayofmonth'] = test_data['date'].dt.days_in_month\ntest_data['dayofyear'] = test_data['date'].dt.dayofyear\ntest_data['weekday'] = test_data['date'].dt.weekday\n\ntrain_data.drop('date', axis = 1, inplace = True)\ntest_data.drop('date', axis = 1, inplace = True)\ntrain_data.shape,test_data.shape","870a85ed":"test_pred_cumul = np.zeros((test_data.shape[0],18))\n\ndef training(index_valid_start,index_valid_end,index_test_start,index_test_end): \n    \n    X_train, y_train = train_data.iloc[0:index_valid_start], target.iloc[0:index_valid_start]\n    X_valid, y_valid = train_data.iloc[index_valid_start:index_valid_end], target.iloc[index_valid_start:index_valid_end]\n    \n    param1 = {   \n        'learning_rate': 0.004280047845210125, \n        'depth': 5, \n        'l2_leaf_reg': 0.0010555278350981901, \n        'loss_function': 'MultiRMSE', \n        'eval_metric': 'MultiRMSE', \n        'task_type': 'CPU', \n        'iterations':16962\n        }\n    \n    clf = CatBoostRegressor(**param1)\n    clf.fit(\n                X_train, y_train,\n                eval_set=[(X_valid,y_valid)],\n                early_stopping_rounds = 1000,\n                verbose=0)\n    pred=clf.predict(X_valid)\n    \n    score = np.round(mean_squared_error(y_valid,pred))\n    print(\"fold\",i+1,\"score MSE =\",score,\"RMSE =\",np.round(np.sqrt(score)))\n    \n    pred_test = clf.predict(test_data.loc[index_test_start:index_test_end-1])\n    \n    global test_pred_cumul\n    test_pred_cumul[index_test_start:index_test_end] += pred_test\/3","eb6e4ab7":"index_train_start = 0\nindex_train_end = 0\nindex_valid_end = 0\n\nfor i in range(30):\n    print(\"\\n---------------- FOLD \",i,\"--------------\")\n    if i == 9 :\n        index_train_start = 0\n        index_train_end = 365 + 36 * i\n        index_valid_start = index_train_end\n        index_valid_end = 365 + 36 * (i + 1) \n        index_test_start = 36 * 9\n        index_test_end = 36 * (9 + 1)+5\n        training(index_valid_start,index_valid_end,index_test_start,index_test_end)\n    else :\n        if i == 19 :\n            index_train_start = 0\n            index_train_end = 365 + 36 * i\n            index_valid_start = index_train_end\n            index_valid_end = 365 + 36 * (i + 1)+5 \n            index_test_start = 36 * 9\n            index_test_end = 36 * (9 + 1)+5        \n            training(index_valid_start,index_valid_end,index_test_start,index_test_end)\n        else :\n            if i == 29 :\n                index_train_start = 0\n                index_train_end = 365 + 36 * i\n                index_valid_start = index_train_end\n                index_valid_end = 365 + 36 * (i + 1)+15         \n                index_test_start = 36 * 9\n                index_test_end = 36 * (9 + 1) + 5 \n                training(index_valid_start,index_valid_end,index_test_start,index_test_end)\n            else :\n                if i<9 :\n                    index_train_start = 0\n                    index_train_end = 365 + 36 * i\n                    index_valid_start = index_train_end\n                    index_valid_end = 365 + 36 * (i + 1) \n                    index_test_start = 36 * i\n                    index_test_end = 36 * (i + 1) \n                    training(index_valid_start,index_valid_end,index_test_start,index_test_end)\n                else:\n                    if i<19 :\n                        index_train_start = 0\n                        index_train_end = 365 + 36 * i\n                        index_valid_start = index_train_end\n                        index_valid_end = 365 + 36 * (i + 1) \n                        index_test_start = 36 * (i-10)\n                        index_test_end = 36 * ((i-10) + 1) \n                        training(index_valid_start,index_valid_end,index_test_start,index_test_end)\n                    else :\n                        index_train_start = 0\n                        index_train_end = 365 + 36 * i\n                        index_valid_start = index_train_end\n                        index_valid_end = 365 + 36 * (i + 1) \n                        index_test_start = 36 * (i-20)\n                        index_test_end = 36 * ((i-20) + 1) \n                        training(index_valid_start,index_valid_end,index_test_start,index_test_end)                      ","5fa15ebb":"sub = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/sample_submission.csv')\n\ndef make_submission(df):\n    submission = pd.DataFrame(data=np.zeros((sub.shape[0],2)),index = sub.index.tolist(),columns=['row_id','num_sold'])\n    INDEX = -1\n    for i in range(365):\n        for j in range (18) :\n            INDEX +=1\n            submission['num_sold'].loc[INDEX,1]=df.iloc[i,j]\n    submission['row_id'] = sub['row_id']\n    return submission","d31eb97f":"pred_test_df = pd.DataFrame(test_pred_cumul,columns=target.columns.tolist()) \nsub_1 = make_submission(pred_test_df)","4ff6e3da":"public_submission = pd.read_csv('..\/input\/tps-2022-01\/public_submission.csv')\nsubmission_bonus=sub.copy()\nsub_1['num_sold'] = (sub_1['num_sold']+public_submission['num_sold'])\/2","5c55d0e5":"sub_1.to_csv(\"sub_1.csv\",index = False)\npd.read_csv('sub_1.csv')","2c2c4703":"<h2> Help from the community !","9f78e934":"<h2> Transform data to timeserie with unique dates","4dc61128":"![image.png](attachment:ca84d989-5bd2-413b-9c47-e12c4af60686.png)","f2534336":"<h2> Data Engineering","cda67f4b":"We start training based upon 2015. We split 2016, 2017, 2018 into 30 sets of 36 days\nThe training set increases at each fold of 36 days as well.\nPlease see the picture in first cell for more explanations :-)","ac2902f8":"<h2> We make predictions with the same period for train and test with the splitting tool :"}}