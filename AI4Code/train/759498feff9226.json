{"cell_type":{"dc37f71e":"code","d88e68c9":"code","c5216ce1":"code","a46b8134":"code","e0ed2133":"code","e23c7cdf":"code","a97ad61e":"code","8d7671d4":"code","cee7434f":"code","52ab8d7a":"code","12e97451":"code","458df1cc":"code","855e0df6":"code","349d5270":"code","9a926063":"code","5cfda5f6":"code","ff222fd1":"markdown","be8ffb8d":"markdown","f20904c0":"markdown","a4025b91":"markdown","bea5b2ab":"markdown"},"source":{"dc37f71e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nfrom keras.utils import to_categorical\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\nfrom keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\nfrom keras.models import Sequential\nfrom keras.callbacks import ReduceLROnPlateau, LearningRateScheduler\n\n# Any results you write to the current directory are saved as output.","d88e68c9":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\n\nx = train.drop(labels = [\"label\"],axis = 1)\ny = train[\"label\"]","c5216ce1":"x = np.array(x)\ne =x[10000]\nimage = e.reshape(28,28)\nplt.imshow(image, cmap = plt.cm.binary,\n           interpolation = 'nearest')\nplt.axis('off')\nplt.show()\nprint(y[10000])","a46b8134":"plt.figure(figsize=(15,4.5))\nfor i in range(30):  \n    plt.subplot(3, 10, i+1)\n    plt.imshow(x[i].reshape((28,28)),cmap=plt.cm.binary)\n    plt.axis('off')\nplt.subplots_adjust(wspace=-0.1, hspace=-0.1)\nplt.show()\n\nans = []\nfor i in range(30):\n    ans.append(y[i])\nprint(ans)","e0ed2133":"from sklearn.model_selection import train_test_split\n\nxtrain, xtest, ytrain, ytest = train_test_split(x,y, test_size = 0.2, random_state = 123)\n\nxtrain.shape, xtest.shape, ytrain.shape, ytest.shape","e23c7cdf":"xtrain = xtrain.reshape(-1, 28, 28, 1)\nxtest = xtest.reshape(-1, 28, 28, 1)\ntest = test.values.reshape(-1,28,28,1)","a97ad61e":"xtrain = xtrain.astype(\"float32\")\/255\nxtest = xtest.astype(\"float32\")\/255\ntest = test.astype(\"float32\")\/255\nytrain = to_categorical(ytrain, num_classes=10)\nytest = to_categorical(ytest, num_classes=10)\n","8d7671d4":"# CNN MODEL\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 32,\n                 kernel_size = (3,3),padding = 'Same', activation ='relu', \n                 input_shape = (28,28,1)))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same',  activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(10, activation = \"softmax\"))","cee7434f":"# Model Visulization\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\n\n%matplotlib inline\nSVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))","52ab8d7a":"# Optimizer\noptimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999 )\n# Compiling the model\nmodel.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","12e97451":"model.summary()","458df1cc":"\n\nfrom keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(\n        featurewise_center=False, \n        samplewise_center=False,  \n        featurewise_std_normalization=False, \n        samplewise_std_normalization=False, \n        zca_whitening=False,  \n        rotation_range=10, \n        zoom_range = 0.1,\n        width_shift_range=0.1,  \n        height_shift_range=0.1, \n        horizontal_flip=False,  \n        vertical_flip=False) \ndatagen.fit(xtrain)\n","855e0df6":"# Fitting the model\nbatch_size = 64\nepochs = 50\nreduce_lr = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)\n\nhistory = model.fit_generator(datagen.flow(xtrain, ytrain, batch_size = batch_size), epochs = epochs, \n                              validation_data = (xtest, ytest), verbose=2, \n                              steps_per_epoch=xtrain.shape[0] \/\/ batch_size,\n                              callbacks = [reduce_lr])\n","349d5270":"model.evaluate(xtest, ytest)","9a926063":"plt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(['Train','Test'])\nplt.show()","5cfda5f6":"testprediction=np.argmax(model.predict(test),axis=1)\ntestimage=[]\nfor i in range (len(testprediction)):\n    testimage.append(i+1)\nfinal={'ImageId':testimage,'Label':testprediction}\nsubmission=pd.DataFrame(final)\nsubmission.to_csv('submssion.csv',index=False)","ff222fd1":"# Data Augumentation\n-> Creating more training and test pictures to get higher accuracy. \n-> More pictures mean that computer has more data to learn.","be8ffb8d":"**Creating Training and Test Dataset**","f20904c0":"**Reshaping dataset to fit into CNN model**","a4025b91":"**Checking numbers and pictures**","bea5b2ab":"**Bringing Data**"}}