{"cell_type":{"95d7a9c6":"code","2ba816ed":"code","02c450a4":"code","db86047b":"code","3120f817":"code","eba1b679":"code","5242f301":"code","eedeb718":"code","c015ef14":"code","1bb6d9ba":"code","594515b4":"code","677f493b":"code","071e73b2":"code","c95c195e":"code","b4bdb28b":"code","7c6d7dbd":"code","f8fa944b":"code","25bd35a8":"code","cea5525c":"code","5f922bd2":"code","5e8b672a":"code","c749390a":"code","0e01cf3d":"code","69dc5187":"code","5fb12ea4":"code","fb7af7b0":"code","7ac4a48f":"code","1eaf804f":"code","aaf828f5":"code","61244046":"code","799a4f69":"code","8b48f53f":"code","ef78c15f":"code","4a95ffb3":"code","e4af5484":"code","b4ea9762":"code","d0ef96cd":"code","459b8ffa":"code","e9f114c9":"code","6782af0e":"code","70df26cc":"code","46e0ba53":"code","4e5bc403":"code","fb942ea1":"code","d465efd1":"code","774a3eb0":"code","fd9c5cfb":"code","978b7f67":"code","13b46037":"code","9aa3f301":"code","e9b915e8":"code","c9cbe57a":"code","751ae0dc":"code","bc9a8cd4":"code","39ee2962":"code","2ca5fa8b":"code","092e5634":"code","a222a6c3":"code","ba98a5b4":"code","eac4ff5d":"code","9e21c015":"code","bccd492c":"code","77a8dc0c":"code","bc1003d4":"code","b213c271":"code","e3a5797d":"code","07f23596":"code","f4b22fa3":"code","383d4e93":"code","c0ed08e5":"code","e925828d":"code","eb312b56":"code","3b068da2":"markdown","6b4825d3":"markdown","11becd35":"markdown","782dee24":"markdown","b510cddc":"markdown","cb2a5b5f":"markdown","1f8d7cd8":"markdown","896aa9f4":"markdown","bf6df66e":"markdown","3ede5f1b":"markdown","bccd3dd0":"markdown","5c318bb9":"markdown","83e60359":"markdown","9f983f4d":"markdown","62f958e8":"markdown","786ac169":"markdown","6c1d48e9":"markdown","6b793667":"markdown","306005b2":"markdown","29367107":"markdown","a71292c5":"markdown","e4b5b8d8":"markdown","4fa83fd0":"markdown","f8d3c72a":"markdown","3b6b416d":"markdown","177e4a73":"markdown","0d209ee8":"markdown","7e31c88f":"markdown","cd0685ac":"markdown","8c0ded01":"markdown","22d6bd67":"markdown","776b60d1":"markdown","54ecc35b":"markdown"},"source":{"95d7a9c6":"# Imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","2ba816ed":"train = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntrain.head()","02c450a4":"test = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntest.head()","db86047b":"submission = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\nsubmission.head()","3120f817":"train.columns","eba1b679":"train.describe()","5242f301":"X=train[\"Survived\"].value_counts().index\nY=train[\"Survived\"].value_counts()\nplt.style.use(\"fivethirtyeight\")\nmyexplode=(0.0,0.1)\nmylabel=[\"Not survived\",\"Survived\"]\ncolors=['#2F4F4F','#2E8B57']\nplt.pie(Y,labels=mylabel,autopct=\"%1.1f%%\",startangle=15,shadow=True,explode=myexplode,colors=colors)\nplt.title(\"Proportion of Survived\")\nplt.axis(\"equal\")\nplt.gcf().set_size_inches(12,6)\nplt.show()","eedeb718":"hue_color={0:'#012a4a',1:'#2c7da0'}\nPclass=['class1','class2','class3']\nplt.style.use(\"fivethirtyeight\")\nax=sns.countplot(data=train,x='Pclass',hue='Survived',palette=hue_color)\nplt.xticks(ticks = [0,1,2], labels = Pclass)\nplt.legend(['Percentage not survived or unknown', 'Percentage of survived'])\nplt.gcf().set_size_inches(12,6)\nplt.show()","c015ef14":"# Class2 seem to have nearly a 50% chance of surviving.\nclass2 = train.loc[train.Pclass == 2]['Survived']\nrate_class2 = sum(class2)\/len(class2)\n\nprint(\"% of class2 who survived:\", rate_class2)","1bb6d9ba":"# Class3 seem to have a low chance of survival.\nclass3 = train.loc[train.Pclass == 3]['Survived']\nrate_class3 = sum(class3)\/len(class3)\n\nprint(\"% of class3 who survived:\", rate_class3)","594515b4":"Y=train[\"Sex\"].value_counts()\nmyexplode=(0.0,0.1)\nplt.style.use(\"fivethirtyeight\")\nmylabel=[\"Male\",\"Female\"]\ncolors = ['#4169E1', '#EE82EE']\nplt.pie(Y,labels=mylabel,autopct=\"%1.1f%%\",startangle=15,shadow=True,explode=myexplode,colors=colors)\nplt.title(\"Passengers by Sex\")\nplt.axis(\"equal\")\nplt.gcf().set_size_inches(12,6)\nplt.show()","677f493b":"hue_color={0:'#3F51B5',1:'#E53935'}\nSex=['Female','Male']\nplt.style.use(\"fivethirtyeight\")\nax=sns.countplot(data=train, x='Sex', hue='Survived', palette=hue_color)\nplt.xticks(ticks = [0,1], labels = Sex)\nplt.legend(['Not survived or Unknown', 'Survived'])\nplt.gcf().set_size_inches(12,6)\nplt.show()","071e73b2":"# Women seem to have high chance of surviving.\nwomen = train.loc[train.Sex == 'female']['Survived']\nrate_women = sum(women)\/len(women)\n\nprint(\"% of women who survived:\", rate_women)","c95c195e":"# Men have low chance of surviving.\nmen = train.loc[train.Sex == 'male']['Survived']\nrate_men = sum(men)\/len(men)\n\nprint(\"% of men who survived:\", rate_men)","b4bdb28b":"sns.countplot(x=train['Survived'],hue=pd.cut(train['Age'],5))\nplt.style.use(\"fivethirtyeight\")\nplt.gcf().set_size_inches(12,6)","7c6d7dbd":"# Children have the best surival rate amongst the age groups.\nchildren = train.loc[train.Age < 13]['Survived']\nrate_child = sum(children)\/len(children)\n\nprint(\"% of children aged less than 13 who survived:\", rate_child)","f8fa944b":"# Teens have nearly 50% survival rate.\nteen = train.loc[(train.Age >= 13) & (train.Age < 18)]['Survived']\nrate_teen = sum(teen)\/len(teen)\n\nprint(\"% of adolescents aged older than 13 but less than 18 who survived:\", rate_teen)","25bd35a8":"# Adults have lowest survival rate amongst the age groups.\nadult = train.loc[(train.Age >= 18)]['Survived']\nrate_adult = sum(adult)\/len(adult)\n\nprint(\"% of adults aged 18 or older who survived:\", rate_adult)","cea5525c":"Y=train[\"SibSp\"].value_counts()\nmyexplode=(0.0,0.1,0.2,0.4,0.1,0.3,0.4)\nplt.style.use(\"fivethirtyeight\")\nmylabel=[0,1,2,3,4,5,8]\ncolors = ['#CFD8DC','#B0BEC5','#90A4AE','#546E7A','#455A64','#37474F','#263238']\nplt.pie(Y,labels=mylabel,autopct=\"%1.1f%%\",startangle=15,shadow=True,explode=myexplode,colors=colors)\nplt.axis(\"equal\")\nplt.gcf().set_size_inches(12,6)\nplt.show()","5f922bd2":"hue_color={0:'#78281F',1:'#EC7063'}\nplt.style.use(\"fivethirtyeight\")\nax=sns.countplot(data=train,x='SibSp',hue='Survived',palette=hue_color)\n# plt.xticks(ticks = [0,1], labels = Sex)\nplt.legend(['Not survived or Unknown', 'Survived'])\nplt.gcf().set_size_inches(12,6)\nplt.show()","5e8b672a":"# Set bins to graph.\ntrain['Fare_Category'] = pd.cut(train['Fare'], bins=[0,7.90,14.45,31.28,120], labels=['Low','Mid','High_Mid','High'])\ntrain","c749390a":"hue_color={0:'#0E6251',1:'#1ABC9C'}\nFare_category=['Low','Mid','High_Mid','High']\nplt.style.use(\"fivethirtyeight\")\nax=sns.countplot(data=train,x='Fare_Category',hue='Survived',palette=hue_color)\nplt.legend(['Percentage not survived or unknown', 'Percentage of survived'])\nplt.gcf().set_size_inches(12,6)\nplt.show()","0e01cf3d":"train.nunique()","69dc5187":"Y=train[\"Embarked\"].value_counts()\nmyexplode=(0.0,0.1,0.0)\nplt.style.use(\"fivethirtyeight\")\nmylabel=['Southampton','Cherbourg','Queenstown']\ncolors = ['#8D6E63', '#6D4C41','#4E342E']\nplt.pie(Y,labels=mylabel,autopct=\"%1.1f%%\",startangle=15,shadow=True,explode=myexplode,colors=colors)\nplt.gcf().set_size_inches(12,6)\nplt.show()","5fb12ea4":"sns.countplot(x=train['Embarked'],hue=train['Survived'])\nplt.style.use(\"fivethirtyeight\")\nplt.gcf().set_size_inches(12,6)","fb7af7b0":"train['Embarked'].isna().sum()","7ac4a48f":"# Null values = -1.\n# train['Embarked'] = train['Embarked'].fillna(-1)\n# train['Embarked'].isna().sum()","1eaf804f":"# Checking for duplicates.\ncolumn_names = ['PassengerId', 'Name']\nduplicates = train.duplicated(subset = column_names, keep = False)\ntrain[duplicates]","aaf828f5":"train.isna().sum()","61244046":"train.isna().sum()\nsns.heatmap(train.isnull(), cbar = True).set_title(\"Missing values heatmap\")\nplt.gcf().set_size_inches(16,6)","799a4f69":"# Percentage of missing values within Cabin Column of training data. Extreme volume of missing data, might exclude later.\ntrain_len = len(train)\ntrain_cabin_na_sum = train['Cabin'].isna().sum()\nprint(\"% of values for that are missing:\", (train_cabin_na_sum \/ train_len))","8b48f53f":"train.drop('Cabin', inplace = True, axis = 1)\ntrain.head()","ef78c15f":"# Convert 'Sex' category to numerical.\ntrain['Sex'] = train['Sex'].replace(['female', 'male'],[0, 1])\ntrain.head()","4a95ffb3":"sib_age_mean_0 = train.loc[train.SibSp == 0]['Age'].mean()\ntrain.loc[(train.Age.isna()) & (train.SibSp == 0), 'Age'] = sib_age_mean_0\n\nsib_age_mean_1 = train.loc[train.SibSp == 1]['Age'].mean()\ntrain.loc[(train.Age.isna()) & (train.SibSp == 1), 'Age'] = sib_age_mean_1\n\nsib_age_mean_2 = train.loc[train.SibSp == 2]['Age'].mean()\ntrain.loc[(train.Age.isna()) & (train.SibSp == 2), 'Age'] = sib_age_mean_2\n\nsib_age_mean_3 = train.loc[train.SibSp == 3]['Age'].mean()\ntrain.loc[(train.Age.isna()) & (train.SibSp == 3), 'Age'] = sib_age_mean_3\n\nsib_age_mean_4 = train.loc[train.SibSp == 4]['Age'].mean()\ntrain.loc[(train.Age.isna()) & (train.SibSp == 4), 'Age'] = sib_age_mean_4\n\nsib_age_mean_5 = train.loc[train.SibSp == 5]['Age'].mean()\ntrain.loc[(train.Age.isna()) & (train.SibSp == 5), 'Age'] = sib_age_mean_5\n\ntrain.loc[(train.Age.isna()) & (train.SibSp == 6), 'Age'] = sib_age_mean_5\n\ntrain.loc[(train.Age.isna()) & (train.SibSp == 7), 'Age'] = sib_age_mean_5\n\ntrain.loc[(train.Age.isna()) & (train.SibSp == 8), 'Age'] = sib_age_mean_5\n\ntrain.loc[(train.Age.isna()) & (train.SibSp == 9), 'Age'] = sib_age_mean_5\n\nprint(train['Age'].isna().sum())","e4af5484":"# Try to get useless characters discarded from numbers within Ticket column.\ntrain['Ticket']","b4ea9762":"train[train.Embarked.isna()]","d0ef96cd":"# Credit to https:\/\/www.kaggle.com\/rajwinder2000\/titanic-machine-learning, didn't know how to solve these 2 nulls.\n\n# Create new feature Surname to fill the null values of Embarked column\ntrain['Surname'] = train.Name.map(lambda x: x.split(',')[0])\n\n# From google I came to this point that mostly the people with surname Icard and Stone belongs from Ireland and France\nto_map = {'Icard': 'C',\n          'Stone': 'S'}\n\ntrain.Embarked.fillna(train.Surname.map(to_map), inplace = True)\n\ntrain['Embarked'].replace({'S':1,'C':2,'Q':3},inplace=True)","459b8ffa":"train.isna().sum()","e9f114c9":"train.Fare","6782af0e":"sib_fare_mean_0 = train.loc[train.SibSp == 0]['Fare'].mean()\ntrain.loc[(train.Fare.isna()) & (train.SibSp == 0), 'Fare'] = sib_fare_mean_0\n\nsib_fare_mean_1 = train.loc[train.SibSp == 1]['Fare'].mean()\ntrain.loc[(train.Fare.isna()) & (train.SibSp == 1), 'Fare'] = sib_fare_mean_1\n\nsib_fare_mean_2 = train.loc[train.SibSp == 2]['Fare'].mean()\ntrain.loc[(train.Fare.isna()) & (train.SibSp == 2), 'Fare'] = sib_fare_mean_2\n\nsib_fare_mean_3 = train.loc[train.SibSp == 3]['Fare'].mean()\ntrain.loc[(train.Fare.isna()) & (train.SibSp == 3), 'Fare'] = sib_fare_mean_3\n\nsib_fare_mean_4 = train.loc[train.SibSp == 4]['Fare'].mean()\ntrain.loc[(train.Fare.isna()) & (train.SibSp == 4), 'Fare'] = sib_fare_mean_4\n\nsib_fare_mean_5 = train.loc[train.SibSp == 5]['Fare'].mean()\ntrain.loc[(train.Fare.isna()) & (train.SibSp == 5), 'Fare'] = sib_fare_mean_5\n\ntrain.loc[(train.Fare.isna()) & (train.SibSp == 6), 'Fare'] = sib_fare_mean_5\n\ntrain.loc[(train.Fare.isna()) & (train.SibSp == 7), 'Fare'] = sib_fare_mean_5\n\ntrain.loc[(train.Fare.isna()) & (train.SibSp == 8), 'Fare'] = sib_fare_mean_5\n\ntrain.loc[(train.Fare.isna()) & (train.SibSp == 9), 'Fare'] = sib_fare_mean_5\n\ntrain[train.Fare.isna()]","70df26cc":"train.isna().sum()","46e0ba53":"train.drop(['Ticket', 'Fare_Category', 'Surname', 'Name'], axis=1, inplace = True)\ntrain.head()","4e5bc403":"test.columns","fb942ea1":"# Checking for duplicates. Seems to be good, no deletion needed for duplicates.\ncolumn_names = ['PassengerId', 'Name']\nduplicates = test.duplicated(subset = column_names, keep = False)\ntest[duplicates]","d465efd1":"test.drop(['Ticket', 'Name'], axis=1, inplace = True)","774a3eb0":"test.describe()","fd9c5cfb":"test.isna().sum()","978b7f67":"test.isna().sum()\nsns.heatmap(test.isnull(), cbar = True).set_title(\"Missing values heatmap\")\nplt.gcf().set_size_inches(16,6)","13b46037":"# Percentage of missing values within Cabin Column of testing data. Extreme volume of missing data, might exclude later.\ntest_len = len(test)\ntest_cabin_na_sum = test['Cabin'].isna().sum()\nprint(test_cabin_na_sum \/ test_len)","9aa3f301":"test.drop('Cabin', inplace = True, axis = 1)\ntest.head()","e9b915e8":"test['Sex'] = test['Sex'].replace(['female', 'male'],[0,1])\ntest.head()","c9cbe57a":"sib_age_mean_0 = test.loc[test.SibSp == 0]['Age'].mean()\ntest.loc[(test.Age.isna()) & (test.SibSp == 0), 'Age'] = sib_age_mean_0\n\nsib_age_mean_1 = test.loc[test.SibSp == 1]['Age'].mean()\ntest.loc[(test.Age.isna()) & (test.SibSp == 1), 'Age'] = sib_age_mean_1\n\nsib_age_mean_2 = test.loc[test.SibSp == 2]['Age'].mean()\ntest.loc[(test.Age.isna()) & (test.SibSp == 2), 'Age'] = sib_age_mean_2\n\nsib_age_mean_3 = test.loc[test.SibSp == 3]['Age'].mean()\ntest.loc[(test.Age.isna()) & (test.SibSp == 3), 'Age'] = sib_age_mean_3\n\nsib_age_mean_4 = test.loc[test.SibSp == 4]['Age'].mean()\ntest.loc[(test.Age.isna()) & (test.SibSp == 4), 'Age'] = sib_age_mean_4\n\nsib_age_mean_5 = test.loc[test.SibSp == 5]['Age'].mean()\ntest.loc[(test.Age.isna()) & (test.SibSp == 5), 'Age'] = sib_age_mean_5\n\ntest.loc[(test.Age.isna()) & (test.SibSp == 6), 'Age'] = sib_age_mean_5\n\ntest.loc[(test.Age.isna()) & (test.SibSp == 7), 'Age'] = sib_age_mean_5\n\ntest.loc[(test.Age.isna()) & (test.SibSp == 8), 'Age'] = sib_age_mean_5\n\ntest.loc[(test.Age.isna()) & (test.SibSp == 9), 'Age'] = sib_age_mean_5\n\nprint(test['Age'].isna().sum())","751ae0dc":"test.Embarked.isna().sum()","bc9a8cd4":"test['Embarked'] = test['Embarked'].replace(['C', 'Q', 'S'],[0, 1, 2])\ntest['Embarked'] = test['Embarked'].astype('int')\ntest.head()","39ee2962":"test[test.Fare.isna()]","2ca5fa8b":"sib_fare_mean_0 = test.loc[test.SibSp == 0]['Fare'].mean()\ntest.loc[(test.Fare.isna()) & (test.SibSp == 0), 'Fare'] = sib_fare_mean_0","092e5634":"test.isna().sum()","a222a6c3":"submission.describe()","ba98a5b4":"# No na values for gender data. No need to do computation ratio of missing data.\nsubmission.isna().sum()","eac4ff5d":"X=train.drop(['Survived'], axis=\"columns\")","9e21c015":"y=train['Survived']","bccd492c":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=71)","77a8dc0c":"from sklearn.metrics import accuracy_score","bc1003d4":"from sklearn.linear_model import LinearRegression\n\nlr = LinearRegression()\nlr.fit(X_train, y_train)\nprint(lr.score(X_test, y_test))","b213c271":"from sklearn.neighbors import KNeighborsClassifier\n\nfor n in range(1, 25):\n    knn = KNeighborsClassifier(n_neighbors=n)\n    knn.fit(X_train,y_train)\n    knn_pred = knn.predict(X_test)\n    knn_score = accuracy_score(knn_pred, y_test);\n    print(knn_score)","e3a5797d":"from sklearn import tree\n\ndt = tree.DecisionTreeClassifier()\ndt.fit(X_train,y_train)\ndt_pred= dt.predict(X_test)\ndt_score = accuracy_score(dt_pred, y_test);\nprint(dt_score)","07f23596":"from sklearn.linear_model import SGDClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nsgd = SGDClassifier(random_state = 71, max_iter=5000)\n\nparameters = {'alpha':[0.00001, 0.0001, 0.001, 0.01, 0.1, 1], \n             'loss':['hinge', 'log'], 'penalty':['l1', 'l2']}\nsearcher = GridSearchCV(sgd, parameters, cv=5)\nsearcher.fit(X_train, y_train)\n\nprint(\"Best CV params\", searcher.best_params_)\nprint(\"Best CV accuracy\", searcher.best_score_)\nprint(\"Test accuracy of best grid search hypers:\", searcher.score(X_test, y_test))","f4b22fa3":"knn = KNeighborsClassifier(n_neighbors=23)\nknn.fit(X_train,y_train)\nknn_pred = knn.predict(X_test)\nknn_score = accuracy_score(knn_pred, y_test);\nprint(knn_score)","383d4e93":"test","c0ed08e5":"predictions = knn.predict(test)","e925828d":"submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\":predictions})","eb312b56":"submission.to_csv('submission.csv',index=False)","3b068da2":"<font size=\"7\">Building the Model<\/font>","6b4825d3":"<font size=\"4\">Class 1 has the highest chance of survival.<\/font>\n\n<font size=\"4\">Class 2 has almost a 50% chance of survival.<\/font>\n\n<font size=\"4\">Class 3 has a very low chance of survival.<\/font>","11becd35":"<font size=\"6\">4. Age<\/font>","782dee24":"<font size=\"4\">Majority of men died while the the majority of women survived.<\/font>","b510cddc":"<font size=\"6\">Linear Regresssion<\/font>","cb2a5b5f":"<font size=\"4\">Majority of passengers passed.<\/font>","1f8d7cd8":"<font size=\"6\">Finding Relationships<\/font>","896aa9f4":"<font size=\"4\">Majority of passengers were men.<\/font>","bf6df66e":"# Class1 seem to have the highest chance of surviving amongst classes.\nclass1 = train.loc[train.Pclass == 1]['Survived']\nrate_class1 = sum(class1)\/len(class1)\n\nprint(\"% of class1 who survived:\", rate_class1)","3ede5f1b":"<font size=\"4\">Let's drop the 'Cabin' category.<\/font>","bccd3dd0":"<font size=\"6\">Decision Tree - Decision Tree Classifier<\/font>","5c318bb9":"<font size=\"5\">Will be using KNN model for submission.<\/font>","83e60359":"<font size=\"6\">2. Pclass<\/font>","9f983f4d":"<font size=4>91% of people traveled alone or with one sibling or spouse.<\/font>","62f958e8":"<font size=\"6\">SGD Classifier<\/font>","786ac169":"<font size=\"4\">People who traveled alone or with 1 sibling had a higher chance of surviving.<\/font>","6c1d48e9":"<font size=\"6\">7. Fare<\/font>","6b793667":"<font size=\"4\">Convert 'Sex' from category to numerical.<\/font>","306005b2":"<font size=\"6\">5. Siblings Onboard<\/font>","29367107":"<font size=\"4\">Filling in null values for Age category.<\/font>","a71292c5":"<font size=\"4\">For age 16 and below the number of survived outnumbered those who didn't.<\/font>\n\n<font size=\"4\">For all other age ranges, the number of survivors was less than the number who died.<\/font>","e4b5b8d8":"<font size=\"6\">Nearest Neighbors - KNN Classifier<\/font>","4fa83fd0":"<font size=\"6\">8. Embarked<\/font>","f8d3c72a":"<font size=\"7\">Exploratory Data Analysis.<\/font>","3b6b416d":"<font size=\"7\">Loading Data In.<\/font>","177e4a73":"<font size=\"6\">1. Survived<\/font>","0d209ee8":"<font size=\"7\">Imports<\/font>","7e31c88f":"<font size=\"4\">Lots of missing values within Cabin category.<\/font>\n\n<font size=\"4\">A decent amount missing from Age category.<\/font>","cd0685ac":"<font size=\"4\">Seems like KNN Classifier has the best accuracy when given the best parameters.<\/font>","8c0ded01":"<font size=\"5\">Gender submission data has no missing values.<\/font>","22d6bd67":"<font size=\"6\">3. Sex<\/font>","776b60d1":"<font size=\"6\">Checking Quality of Data.<\/font>","54ecc35b":"<font size=\"4\">No duplicates to delete.<\/font>"}}