{"cell_type":{"2bf1b830":"code","43982001":"code","8e1f0589":"code","5c5e96cc":"code","6316ecee":"code","f3e1a6ba":"code","ad147cfc":"code","81a69aa3":"code","f24f40b8":"code","4ad293a9":"code","0749175d":"code","081f6f38":"code","b5595a88":"code","356d344e":"code","1577ec25":"code","1c3ea838":"code","e0c12f2c":"code","4d38f30f":"code","e2e29c6b":"code","47f36e6d":"code","b02b1f7f":"code","721e8a32":"code","660968b4":"code","5c2ad57b":"code","ea322d17":"code","6e838d2f":"code","5b6e0fa9":"code","6a0f8bdf":"code","d5a21976":"code","123918d0":"code","b18495ba":"code","d926eb49":"code","80e72b43":"code","defc339f":"code","e945976e":"code","4fbce549":"code","76e5fb29":"code","b74a3c90":"code","9bfa85be":"code","41d61ab2":"code","c6abda1e":"code","94091cff":"code","ec82caed":"code","d7bca57d":"code","95e3c017":"markdown","e8e326fe":"markdown","41baa3fd":"markdown","30ae44a1":"markdown","e8f0c097":"markdown","08463202":"markdown","5934d6fc":"markdown","cdd15f4c":"markdown","78a8dbfe":"markdown","b02b1e53":"markdown","531a70d3":"markdown","a3f6730f":"markdown","9db09180":"markdown","640909d5":"markdown","b1c57f43":"markdown","f5c6fd13":"markdown","4b2e12f5":"markdown","deeebeb2":"markdown","c0f70e93":"markdown","87494212":"markdown","9dff9bb9":"markdown","aead7358":"markdown","f40e9dd6":"markdown","8389d896":"markdown","2a487721":"markdown","9e73ca7d":"markdown","9663a441":"markdown","7474baa2":"markdown","a4bd190c":"markdown","50fe8279":"markdown","f95da69f":"markdown","06e0ae6d":"markdown","179c7624":"markdown","6bbba296":"markdown","2464c594":"markdown","da58438e":"markdown"},"source":{"2bf1b830":"# data analysis\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# data visualization\nimport matplotlib.pyplot as plt # for data visualization\nimport seaborn as sns # for data visualization\n\nsns.set_style('dark')\n\n#ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","43982001":"# load train data\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()","8e1f0589":"# load test data\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","5c5e96cc":"print('='*50)\nprint(\"Number of columns in training data\")\nprint('='*50)\nprint(\"\\n\")\nprint(train_data.columns.values)\nprint(\"\\n\")\nprint('='*50)\nprint(\"Number of columns in test data\")\nprint('='*50)\nprint(\"\\n\")\nprint(test_data.columns.values)","6316ecee":"print('='*10)\nprint(\"Train data shape\")\nprint('='*10)\nprint(\"\\n\")\nprint(train_data.shape)\nprint(\"\\n\")\nprint('='*10)\nprint(\"Test data shape\")\nprint('='*10)\nprint(\"\\n\")\nprint(test_data.shape)","f3e1a6ba":"print('='*50)\nprint(\"\\nDescribe traing data\\n\")\nprint('='*50) \nprint(\"\\n\")\nprint(train_data.describe())","ad147cfc":"print(\"Describe test data\")\nprint('='*50)\nprint(test_data.describe())","81a69aa3":"print('='*50)\nprint(\"\\nTraining data info\\n\")\nprint('='*50)\nprint(train_data.info())\nprint(\"\\n\")\nprint('='*50)\nprint(\"\\n Test data info \\n\")\nprint('='*50)\nprint(\"\\n\")\nprint(test_data.info())","f24f40b8":"print('='*50)\nprint('\\nNumber of null values in train data\\n')\nprint('='*50)\nprint('\\n')\nprint(train_data.isnull().sum())\nprint('\\n')\nprint('='*50)\nprint('\\n Number of null values in test data\\n')\nprint('='*50)\nprint(\"\\n\")\nprint(test_data.isnull().sum())","4ad293a9":"train_data['Age'] = train_data['Age'].fillna(train_data['Age'].median())\ntest_data['Age'] = test_data['Age'].fillna(test_data['Age'].median())","0749175d":"train_data = train_data.drop(['Cabin'], axis = 1)\ntest_data = test_data.drop(['Cabin'], axis = 1)","081f6f38":"train_data = train_data.drop(['Ticket'], axis = 1)\ntest_data = test_data.drop(['Ticket'], axis = 1)","b5595a88":"train_data['Embarked'] = train_data['Embarked'].fillna('S')","356d344e":"test_data[\"Fare\"].fillna(test_data[\"Fare\"].median(), inplace=True)","1577ec25":"# let check missing value again\nprint('='*50)\nprint('\\nNumber of null values in train data\\n')\nprint('='*50)\nprint('\\n')\nprint(train_data.isnull().sum())\nprint('\\n')\nprint('='*50)\nprint('\\n Number of null values in test data\\n')\nprint('='*50)\nprint(\"\\n\")\nprint(test_data.isnull().sum())","1c3ea838":"# number of survived passengers\ntrain_data.groupby(['Survived'])['Survived'].count()","e0c12f2c":"# percentage of male and female who survived\ntrain_data[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","4d38f30f":"# percentage of people survived according to their Ticker Class\ntrain_data[[\"Pclass\", \"Survived\"]].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","e2e29c6b":"# Percentage of survived people based on their embarked. \ntrain_data[[\"Embarked\", \"Survived\"]].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)","47f36e6d":"train_data[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)","b02b1f7f":"train_data[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)","721e8a32":"sns.countplot(x = 'Survived', data = train_data)","660968b4":"#draw a bar plot of survival by sex\nsns.barplot(x=\"Sex\", y=\"Survived\", data=train_data)","5c2ad57b":"#draw a bar plot of survival by sex\nsns.barplot(x=\"Pclass\", y=\"Survived\", data=train_data)","ea322d17":"#draw a bar plot of survival by sex\nsns.barplot(x = \"Embarked\", y = \"Survived\", data = train_data)","6e838d2f":"#draw a bar plot of survival by sex\nsns.barplot(x=\"Parch\", y=\"Survived\", data=train_data)","5b6e0fa9":"# peaks for survived\/not survived passengers by their age\nfacet = sns.FacetGrid(train_data, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train_data['Age'].max()))\nfacet.add_legend()\n\n# average survived passengers by age\nfig, axis1 = plt.subplots(1,1,figsize=(18,4))\naverage_age = train_data[[\"Age\", \"Survived\"]].groupby(['Age'],as_index=False).mean()\nsns.barplot(x='Age', y='Survived', data=average_age)","6a0f8bdf":"grid = sns.FacetGrid(train_data, col='Survived', row='Pclass')\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend();","d5a21976":"grid = sns.FacetGrid(train_data, col='Survived', row='Pclass')\ngrid.map(plt.hist, 'SibSp', alpha=.5, bins=20)\ngrid.add_legend();","123918d0":"grid = sns.FacetGrid(train_data, col='Survived', row='Pclass')\ngrid.map(plt.hist, 'Embarked', alpha=.5, bins=20)\ngrid.add_legend();","b18495ba":"sns.heatmap(train_data.corr(),annot=True,cmap='RdYlGn',linewidths=0.2)\nfig=plt.gcf()\nfig.set_size_inches(20,12)\nplt.show()","d926eb49":"train_data['Sex'] = train_data['Sex'].map({'male':1, 'female':0})\ntest_data['Sex'] = test_data['Sex'].map({'male':1, 'female':0})","80e72b43":"train_data['Embarked'] = train_data['Embarked'].map({'Q':2, 'S':1, 'C':0})\ntest_data['Embarked'] = test_data['Embarked'].map({'Q':2, 'S':1, 'C':0})","defc339f":"# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier","e945976e":"X_train = train_data.drop([\"Name\", \"Survived\", \"PassengerId\"], axis=1)\nY_train = train_data[\"Survived\"]\nX_test  = test_data.drop(['Name',\"PassengerId\"], axis=1).copy()\nX_train.shape, Y_train.shape, X_test.shape","4fbce549":"# Support Vector Machine\nsvc = SVC()\nsvc.fit(X_train, Y_train)\nsvm_Y_pred = svc.predict(X_test)\nsvc_accuracy = svc.score(X_train, Y_train)\nsvc_accuracy","76e5fb29":"# k-nearest neighbor\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nknn_Y_pred = knn.predict(X_test)\nknn_accuracy = knn.score(X_train, Y_train)\nknn_accuracy","b74a3c90":"# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\nguassian_Y_pred = gaussian.predict(X_test)\ngaussian_accuracy = gaussian.score(X_train, Y_train)\ngaussian_accuracy","9bfa85be":"# Linear SVC\n\nlinear_svc = LinearSVC()\nlinear_svc.fit(X_train, Y_train)\nlinear_svc_Y_pred = linear_svc.predict(X_test)\nlinear_svc_accuracy = linear_svc.score(X_train, Y_train)\nlinear_svc_accuracy","41d61ab2":"# Stochastic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(X_train, Y_train)\nsgd_Y_pred = sgd.predict(X_test)\nsgd_accuracy = sgd.score(X_train, Y_train)\nsgd_accuracy","c6abda1e":"# Decision Tree\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\ndecision_tree_Y_pred = decision_tree.predict(X_test)\ndecision_tree_accuracy = decision_tree.score(X_train, Y_train)\ndecision_tree_accuracy","94091cff":"# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nrandom_forest_Y_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nrandom_forest_accuracy = random_forest.score(X_train, Y_train)\nrandom_forest_accuracy","ec82caed":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Gaussian Naive Bayes', 'Linear SVC',\n              'Stochastic Gradient Decent', 'Decision Tree','Random Forest'],\n    'Score': [svc_accuracy, knn_accuracy, gaussian_accuracy, linear_svc_accuracy, \n              sgd_accuracy, decision_tree_accuracy, random_forest_accuracy]})\nmodels.sort_values(by='Score', ascending=False)","d7bca57d":"# submission file from each model\nsvm_submission = pd.DataFrame({\"PassengerId\": test_data[\"PassengerId\"], \"Survived\": svm_Y_pred})\nsvm_submission.to_csv('svm_submission.csv', index=False)\n\nknn_submission = pd.DataFrame({\"PassengerId\": test_data[\"PassengerId\"], \"Survived\": knn_Y_pred})\nknn_submission.to_csv('knn_submission.csv', index=False)\n\nguassian_submission = pd.DataFrame({\"PassengerId\": test_data[\"PassengerId\"], \"Survived\": guassian_Y_pred})\nguassian_submission.to_csv('guassian_submission.csv', index=False)\n\nlinear_svc_submission = pd.DataFrame({\"PassengerId\": test_data[\"PassengerId\"], \"Survived\": linear_svc_Y_pred})\nlinear_svc_submission.to_csv('linear_svc_submission.csv', index=False)\n\nsgd_submission = pd.DataFrame({\"PassengerId\": test_data[\"PassengerId\"], \"Survived\": sgd_Y_pred})\nsgd_submission.to_csv('sgd_submission.csv', index=False)\n\ndecision_tree_submission = pd.DataFrame({\"PassengerId\": test_data[\"PassengerId\"], \"Survived\": decision_tree_Y_pred})\ndecision_tree_submission.to_csv('decision_tree_submission.csv', index=False)\n\nrandom_forest_submission = pd.DataFrame({\"PassengerId\": test_data[\"PassengerId\"], \"Survived\": random_forest_Y_pred})\nrandom_forest_submission.to_csv('random_forest_submission.csv', index=False)","95e3c017":"# Support Vector Machine","e8e326fe":"Now we don't have any missing value in train and test data. Let's do some visuaization.","41baa3fd":"We can see that Age, Cabin and Embarked have missing values.\n\nAge and Embarked have only few missing values. Whereas Cabin column have so many missing values.","30ae44a1":"# EDA (Exploratory Data Analysis)","e8f0c097":"Info of training data ","08463202":"# Linear SVC","5934d6fc":"Firt thing first. It is very important to import all necessary python libraries. \nI am going to import NumPy and Pandas for Data Analysis. For visualization I am going to use Matplotlib and Seaborn. ","cdd15f4c":"### Prepare data for train and test model.","78a8dbfe":"# Decision Tree\n","b02b1e53":"### Cabin Feature\nI'll start off by dropping the Cabin feature since not a lot more useful information can be extracted from it.","531a70d3":"From above column name we can see that test data doesn't have Survived column. That's our task to do. For test data we have to find out whethere give passenger will survive or not.","a3f6730f":"### Embarked Features\nThere is two missing embarked values in train data.","9db09180":"Have a look at data shape","640909d5":"# K-Nearest Neighbour","b1c57f43":"## Hello Everyone,\n#### Welcome to this kernel\nI have started this kernel to help beginners to understand Titanic Kaggle Challenge.\n\nI hope that anyone, regardless of their Machine Learning and Python skills can find something useful and helpful.\n\n# <font color='red'> Don't forget to upvote if you like it! <\/font>\n\n## Thanks and be safe!","f5c6fd13":"# First import all required machine learning libraries","4b2e12f5":"Lets have look at each column information.\n\n* PassengerId: An unique index for each passenger. It starts from 1 and increments by 1 for every new passenger.\n* Survived: Shows if the passenger survived or not. 1 stands for survived and 0 stands for not survived.\n\n* Pclass: Ticket class. 1 stands for First class ticket. 2 stands for Second class ticket. 3 stands for Third class ticket.\n\n* Name: Passenger's name. Name also contain title. \"Mr\" for man. \"Mrs\" for woman. \"Miss\" for girl. \"Master\" for boy.\n\n* Sex: Passenger's sex. It's either Male or Female.\n\n* Age: Passenger's age. \"NaN\" values in this column indicates that the age of that particular passenger has not been recorded.\n\n* SibSp: Number of siblings or spouses travelling with each passenger.\n\n* Parch: Number of parents of children travelling with each passenger.\n\n* Ticket: Ticket number.\n\n* Fare: How much money the passenger has paid for the travel journey.\n\n* Cabin: Cabin number of the passenger. \"NaN\" values in this column indicates that the cabin number of that particular passenger has not been recorded.\n\n* Embarked: Port from where the particular passenger was embarked\/boarded.","deeebeb2":"# Looking into Training and Testing Data","c0f70e93":"# Titanic Survive Prediction Tutorial for Beginners\nTitanic is kaggle's beginners competion where goal is to predict where passenger will survive or not.\n\n![](https:\/\/media.giphy.com\/media\/jXJYVWquFTXTG\/giphy.gif)\n\n<center>Gif from [Giphy](https:\/\/giphy.com\/gifs\/titanic-jXJYVWquFTXTG)<\/center>","87494212":"## Converting Categorial data to Numeric\n\nIn our data some of features are represent categorial values, like Sex, Embarked etc. So we have to convert them in numeric value.","9dff9bb9":"# Gaussian Naive Bayes","aead7358":"# Random Forest","f40e9dd6":"### Ticket Feature\nI will also drop the Ticket feature since it's unlikely to yield any useful information.","8389d896":"# Data Visualization","2a487721":"Describing training dataset\n\ndescribe() method can show different values like count, mean, standard deviation, etc. of numeric data types.","9e73ca7d":"### Age Feature\nOne solution is to fill in the null values with the median age.","9663a441":"I am continuesly updating this kernel so I really appriciate you feedback.\n\nI you have any quetion do let me know in comment, I am more than happy to answer.","7474baa2":"Once you are dont with libraries, second step is to import dataset. As you can see in above cell's output. There is 3 files in our input folder. \n1. train.csv -- our training file.\n2. test.csv -- using our machine learning model we have to predict whethere gicen entries in this file will survive or not.\n3. gender_submission.csv -- sample submission file.\n\n\nSo I am going to load train.csv and test.csv in different data frames.","a4bd190c":"## <font color='blue'> I hope you enjoyed this kernel , Please don't forget to appreciate me with an Upvote. <\/font>","50fe8279":"# Stochastic Gradient Descent","f95da69f":"To make some observations and assumptions, we need to quickly analyze some feature correlations by pivoting features against each other. As we cleaned our data, we are able to make this correlation for every feature.\n\n#### Observation: \n\n- It is clear that out of 891 passengers only 342 manage to survive. Which indicated majority of passengers died.\n- **Sex** Female passenger have high priority of survival.\n- **Pclass** First class passenger have higher change of survival, which is >50%.\n- **Embarked** Passger who board the ship from Cherbourg.","06e0ae6d":"## Import Required Libraries","179c7624":"### Fare Feature\nFor only test data we have one missing value so I am going to fill that with median.","6bbba296":"# Model Prediction\nNow our data is ready to prepare model to predict solution. There is plenty of predictive algorithm out there to try. However, our problem is classification problem thus I will try classification models. ","2464c594":"# Load Data","da58438e":"## Contents\n\n* [Import required libraries](#import-required-libraries)\n- [Load Data](#load-data)\n- [Looking into Training and Testing Data](#looking-into-training-and-testing-data)\n- [EDA (Exploratory Data Analysis)](#EDA-exploratory-data-analysis)\n- [Data Visualization](#data-visualization)\n- [Model Prediction](#model-prediction)\n- [Support Vector Machine](#support-vector-machine)\n- [K-Nearest Neighbour](#k-nearest-neighbour)\n- [Gaussian Naive Bayes](#gaussian-naive-bayes)\n- [Linear SVC](#linear-svc)\n- [Stochastic Gradient Descent](#stochastic-gradient-descent)\n- [Decision Tree](#decision-tree)\n- [Random Forest](#random-forest)"}}