{"cell_type":{"fc640212":"code","f96c9ee0":"code","3ec8012c":"code","da6cee40":"code","5564892a":"code","1d6320c5":"code","9946eed1":"code","59a864f3":"code","01dbb767":"code","6dacacbf":"code","70e1c052":"code","154cd943":"code","ebfe96dc":"code","08f84d36":"code","f8d42a7b":"code","92b7431a":"code","c90c1298":"code","50baab9f":"code","58b9a353":"code","b3922f52":"code","60264260":"code","e9932cdd":"code","39946501":"code","18ef7e8e":"code","c497f3e2":"code","b428a158":"code","7d9e7811":"code","a9891af6":"code","5e0a0c3f":"code","101ca8bb":"code","651b6107":"code","f6c2c155":"code","2357eaab":"code","681cde81":"code","08d15b11":"code","a45cb90b":"code","e5e66439":"code","fc8afa1f":"code","61586094":"code","d7aae910":"code","21384a5c":"code","b27be92a":"code","94ad38e2":"code","aa96b167":"code","2b7aa2a7":"code","a7a7fbdd":"code","9199da88":"code","ed6a5daf":"code","cd4c11a1":"code","f271829f":"code","0e348d6a":"code","8c0c4e2f":"code","59e004b2":"code","3599a4d5":"code","f30d0c0d":"code","330a85de":"code","5731c052":"code","6182c377":"code","a8e66fe7":"code","50b790b4":"code","1074a271":"code","77005831":"code","f55fca3f":"code","ab92237b":"code","6d7ac94d":"code","f4928552":"code","1821e99e":"code","e0b8db0c":"code","ab239325":"code","e425ab9f":"code","b26f8f17":"code","7e246985":"code","16101fe5":"code","ee5689db":"code","f1b24780":"code","9f4a27cf":"code","1e0e2b35":"code","725462e6":"code","314f9f30":"code","7acea9fc":"code","9c0ba394":"code","280ae763":"code","28fc965f":"code","0954b05d":"code","80c3e492":"code","d70b00b4":"code","ffb6763a":"code","9aebc77f":"code","b9722b32":"code","8b527449":"code","fd8f0688":"code","10729a77":"code","07407340":"code","3596c985":"code","03b21e7c":"code","86a94a5a":"code","2d2deb28":"code","5645cf3d":"code","6a006095":"code","925f4d57":"code","c7188681":"code","e2e550e1":"code","ae30bf96":"code","cb7733a7":"code","1243e99f":"code","153995b6":"code","650e9e08":"code","145bf87a":"code","455ecd84":"code","8e4e910a":"code","df09ec94":"code","7d226fef":"code","4d94c829":"code","b4e16a26":"code","ae4fe419":"code","f4f22508":"code","5059dc55":"code","56d2026c":"code","325d059a":"code","328a8304":"code","db68c5af":"code","dcfa7ead":"code","89c1169c":"code","c1e29d8a":"code","dc16501a":"code","50515d83":"code","0f0d9c2a":"code","9af5360e":"code","599104de":"code","2369fa47":"code","d738702c":"code","d111c75c":"code","e2be84a0":"code","a16eaa24":"code","e184fbfd":"code","85ca7e94":"code","47fbdb38":"code","dd3cafd8":"code","6c5ffc8f":"code","26aed237":"code","3578a137":"code","d0af1db0":"code","195bf4f9":"code","feff67b6":"code","723ade75":"code","e025b4b5":"code","8140d097":"code","d89a1ec8":"code","343d5e82":"code","9f4a81a1":"code","e43a0464":"markdown","d4fc9bad":"markdown","58632786":"markdown","43f144f5":"markdown","cc9df217":"markdown","ec12fb07":"markdown","b9473f9d":"markdown","d257bde0":"markdown","5157c2dc":"markdown","67d98b59":"markdown","0ea76249":"markdown","0c6a8ba1":"markdown","9905ad9b":"markdown","5f4246cc":"markdown","ca7eb649":"markdown","7cfb633b":"markdown","4eff1885":"markdown","169442c0":"markdown","885dd719":"markdown","fdb0e0db":"markdown","980cb8dc":"markdown","8bfd11eb":"markdown","34b7397c":"markdown","f1bdf404":"markdown","72ed76c3":"markdown","ed31f4b0":"markdown","019f1794":"markdown","bdbdc328":"markdown","0e50006f":"markdown","192d7b50":"markdown","ac206033":"markdown","98259fb2":"markdown","a9024f8d":"markdown","f4a14921":"markdown","0088d4bf":"markdown","1aba003b":"markdown","aea4df21":"markdown","5537550b":"markdown","577cb193":"markdown","71086e01":"markdown","0e71ac60":"markdown","2f1e3320":"markdown","cb47cfcd":"markdown","5c184adf":"markdown","db7cacdc":"markdown","bee2b2f5":"markdown","47afee30":"markdown","b77a61a9":"markdown","9a165508":"markdown","7937cd65":"markdown","70939d1f":"markdown","97094fb9":"markdown","9dbd2491":"markdown","b1f711b7":"markdown","5b8925a2":"markdown","94835ea2":"markdown","2d43ee60":"markdown","4465d4e1":"markdown","e4f879d5":"markdown","61647058":"markdown","61ba4670":"markdown","0f5c752d":"markdown","4be49d45":"markdown","f23f3749":"markdown","7343af60":"markdown","c7438cd2":"markdown","2ae2ae0b":"markdown","bff4eeb8":"markdown","0a1d0dd0":"markdown","ca6a67e2":"markdown","96feaf70":"markdown","d15f9561":"markdown","fcca4b37":"markdown","df86017e":"markdown","f25c2a7f":"markdown","f5981a1c":"markdown","e28d9b73":"markdown","9bcadc49":"markdown","a638a9eb":"markdown","b200559f":"markdown","033e736e":"markdown","ab86929a":"markdown","917ce748":"markdown","4a55e64c":"markdown","7e0b3978":"markdown","d97408f9":"markdown","062595c7":"markdown","3e27003e":"markdown","0f996db8":"markdown","2f0183b2":"markdown","7105d89a":"markdown","c0582e62":"markdown","c442bab5":"markdown","e545c6f2":"markdown","2caad881":"markdown","3a3bfea4":"markdown","eca85cac":"markdown","9d903b05":"markdown","28e968d0":"markdown","208c4298":"markdown","5062dca1":"markdown","d4eccd91":"markdown","42cadfe1":"markdown","f62c8eec":"markdown","6f604d85":"markdown","bf3d186c":"markdown","23dd293e":"markdown","0cd8d638":"markdown","3385888b":"markdown","216ea9cd":"markdown","2058ad99":"markdown","b9a508be":"markdown","42d96500":"markdown","5ef56adc":"markdown","93575106":"markdown","471f7342":"markdown","87e2770c":"markdown","c73309d7":"markdown","336746be":"markdown","1a5fcef2":"markdown","9638a0c3":"markdown","9524d2af":"markdown","835cbc6d":"markdown","0d29f9f1":"markdown","7c573d64":"markdown","be852d83":"markdown","59d3c5fb":"markdown","6cf1bf99":"markdown","459620af":"markdown","f127d057":"markdown","644bcd47":"markdown","853a0567":"markdown","2daca4a7":"markdown","c864b0e7":"markdown","631c9a6f":"markdown","252f231f":"markdown","502c25a7":"markdown","5ec1e048":"markdown","f443ea97":"markdown","4dd8509a":"markdown","302521f8":"markdown","d47def2e":"markdown","0ffdd63a":"markdown","e9abf64c":"markdown","a30e2bb5":"markdown","0de79b7b":"markdown","db764c45":"markdown","7a86ba2c":"markdown","5ef41e83":"markdown","5a99f688":"markdown","8af45c6f":"markdown","27720ad6":"markdown","9daab3e7":"markdown","d3adbc80":"markdown","f98342b8":"markdown","3ca49f69":"markdown","39f97605":"markdown","09cfb343":"markdown","3e986564":"markdown","f68c9d60":"markdown","e9ef4a22":"markdown","cb6bad89":"markdown","ae4d771d":"markdown","76aabd79":"markdown","0d6bf32c":"markdown","caee33ad":"markdown","cb5da1ed":"markdown","e7754bcc":"markdown","42da3e55":"markdown","16043532":"markdown","a8fd390d":"markdown","d8bdac51":"markdown","6f46b349":"markdown","c319f51b":"markdown","da510134":"markdown","3288a555":"markdown","08630ca8":"markdown","a8deaf31":"markdown","0b100475":"markdown","976b3bfe":"markdown","58b7e6ee":"markdown","f1a1f1f2":"markdown","ec775061":"markdown","5ce3a69a":"markdown","2bfc5565":"markdown","18dc8dd2":"markdown","5490efda":"markdown","47b88902":"markdown","102d0d75":"markdown","6d370a68":"markdown","3a4a2d67":"markdown","4055a303":"markdown","1a77aff1":"markdown","d8b6761e":"markdown","a24c6e6e":"markdown","cbf1fc45":"markdown","f68c2ddf":"markdown","9c612ea1":"markdown","a337681c":"markdown","22c97dbd":"markdown","0ae68b96":"markdown","20cdb0ee":"markdown"},"source":{"fc640212":"# import 'Pandas' \nimport pandas as pd \n\n# import 'Numpy' \nimport numpy as np\n\n# import subpackage of Matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\n\n# import 'Seaborn' \nimport seaborn as sns\n\n# to suppress warnings \nfrom warnings import filterwarnings\nfilterwarnings('ignore')\n\n# display all columns of the dataframe\npd.options.display.max_columns = None\n\n# display all rows of the dataframe\npd.options.display.max_rows = None\n \n# to display the float values upto 6 decimal places     \npd.options.display.float_format = '{:.6f}'.format\n\n# import train-test split \nfrom sklearn.model_selection import train_test_split\n\n# import various functions from statsmodels\nimport statsmodels\nimport statsmodels.api as sm\n\n# import StandardScaler to perform scaling\nfrom sklearn.preprocessing import StandardScaler \n\n# import various functions from sklearn \nfrom sklearn import metrics\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score \n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import tree\nfrom sklearn.model_selection import GridSearchCV \n\n# import function to perform feature selection\nfrom sklearn.feature_selection import RFE\n\nfrom sklearn.preprocessing import MinMaxScaler\nimport scipy\nfrom scipy.stats import shapiro\nfrom mlxtend.feature_selection import SequentialFeatureSelector as sfs\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import StackingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.tree import plot_tree\nfrom sklearn.naive_bayes import GaussianNB","f96c9ee0":"# display all columns of the dataframe\npd.options.display.max_columns = None\n# display all rows of the dataframe\npd.options.display.max_rows = None\n# return an output value upto 6 decimals\npd.options.display.float_format = '{:.6f}'.format","3ec8012c":"# load the csv file\n# store the data in 'df_admissions'\ndf_wine = pd.read_csv('..\/input\/d\/nischithasai\/wine-quality\/winequalityN.csv')\n\n# display first five observations using head()\ndf_wine.head(10).style.set_properties(**{'background-color':'black','color':'white','border-color':'red'})","da6cee40":"df_wine.info()","5564892a":"df_wine.shape","1d6320c5":"df_wine.dtypes","9946eed1":"df_wine['quality']=df_wine['quality'].astype('object')","59a864f3":"df_wine.dtypes","01dbb767":"missing_value = pd.DataFrame({\n    'Missing Value': df_wine.isnull().sum(),\n    'Percentage': (df_wine.isnull().sum() \/ len(df_wine))*100\n})","6dacacbf":"missing_value.sort_values(by='Percentage', ascending=False).style.set_properties(**{'background-color':'black','color':'white','border-color':'red'})","70e1c052":"# set the figure size\nplt.figure(figsize=(25,15))\n\n# plot heatmap to check null values\n# isnull(): returns 'True' for a missing value\n# cbar: specifies whether to draw a colorbar; draws the colorbar for 'True' \nsns.heatmap(df_wine.isnull(), cbar=False)\n\n\n# display the plot\nplt.show()","154cd943":"df=df_wine[['fixed_acidity','pH','volatile_acidity','sulphates','citric_acid','chlorides','residual_sugar']]","ebfe96dc":"for column in enumerate(df):\n    plt.figure(figsize=(30,5))\n    #sns.set_theme(style=\"darkgrid\",palette='deep')\n    sns.boxplot(x=column[1], data=  df,color='red')\n    plt.xlabel(column[1],fontsize=18)\n    plt.show()","08f84d36":"for column in df.columns:\n    df_wine[column]= df_wine[column].fillna(df_wine[column].median())","f8d42a7b":"df_wine.isna().sum()","92b7431a":"# set the figure size\nplt.figure(figsize=(10,8))\n\n# plot heatmap to check null values\n# isnull(): returns 'True' for a missing value\n# cbar: specifies whether to draw a colorbar; draws the colorbar for 'True' \nsns.heatmap(df_wine.isnull(), cbar=False)\n\n# display the plot\nplt.show()","c90c1298":"duplicate = df_wine.duplicated().sum()\nprint('There are {} duplicated rows in the data'.format(duplicate))","50baab9f":"df_wine.drop_duplicates(inplace=True)","58b9a353":"duplicate = df_wine.duplicated().sum()\nprint('There are {} duplicated rows in the data'.format(duplicate))","b3922f52":"df_wine.shape","60264260":"df_wine.tail(5).style.set_properties(**{'background-color':'black','color':'white','border-color':'red'})","e9932cdd":"df_wine.reset_index(inplace=True,drop=True)","39946501":"df_wine.tail().style.set_properties(**{'background-color':'black','color':'white','border-color':'red'})","18ef7e8e":"df_wine.shape","c497f3e2":"df_wine.head().style.set_properties(**{'background-color':'black','color':'white','border-color':'red'})","b428a158":"df_wine.describe(include=np.number).style.set_properties(**{'background-color':'black','color':'white','border-color':'red'})","7d9e7811":"df_wine.describe(include = object).style.set_properties(**{'background-color':'black','color':'white','border-color':'red'})","a9891af6":"corr_matrix=df_wine.corr()\ncorr_matrix.style.set_properties(**{'background-color':'black','color':'white','border-color':'red'})","5e0a0c3f":"plt.figure(figsize=(11,9))\ndropSelf = np.zeros_like(corr_matrix)\ndropSelf[np.triu_indices_from(dropSelf)] = True\n\nsns.heatmap(corr_matrix, cmap=sns.diverging_palette(220, 10, as_cmap=True), annot=True, fmt=\".2f\", mask=dropSelf)\n\nsns.set(font_scale=1.5)","101ca8bb":"data = df_wine.groupby('type')['quality'].count()\nfig, ax = plt.subplots(figsize=[10,6])\nlabels = ['red','white']\nax = plt.pie(x=data, autopct=\"%.1f%%\", explode=[0.05]*2, labels=labels, colors=['darkred','white'],\n             wedgeprops={\"edgecolor\":\"black\"},pctdistance=0.5)\nplt.show()","651b6107":"quaity_mapping = { 3 : \"Low\",4 : \"Low\",5: \"Low\",6 : \"High\",7: \"High\",8 : \"High\",9 : \"High\"}\ndf_wine[\"quality\"] =  df_wine[\"quality\"].map(quaity_mapping)","f6c2c155":"df_target = df_wine['quality'].copy()\n\ndf_target.value_counts()\nsns.countplot(x = df_target)\n\n# use below code to print the values in the graph\n# 'x' and 'y' gives position of the text\n# 's' is the text \nplt.text(x = -0.05, y = df_target.value_counts()[0]+1, s = str(round((df_target.value_counts()[0])*100\/len(df_target),2)) + '%')\nplt.text(x = 0.95, y = df_target.value_counts()[1]+1, s = str(round((df_target.value_counts()[1])*100\/len(df_target),2)) + '%')\n\n# add plot and axes labels\n# set text size using 'fontsize'\nplt.yticks([0,1000,2000,3000,4000])\nplt.title('Count Plot for Target Variable (wine_quality)', fontsize = 15)\nplt.xlabel('Target Variable', fontsize = 15)\nplt.ylabel('Count', fontsize = 15)\nplt.tight_layout()\n# to show the plot\nplt.show()","2357eaab":"fig, ax = plt.subplots(figsize=(12,4))\npd.options.display.float_format = '{:,.2f}'.format\n\nbar_chart = df_wine.groupby(['type','quality'])['quality'].count().unstack('type')\nbar_chart= (bar_chart.T\/bar_chart.T.sum()).T\nax = bar_chart.plot(kind='bar', stacked=True, color=['r','w'], edgecolor='black', ax=ax)\n\nlabels = []\nfor j in bar_chart.columns:\n    for i in bar_chart.index:\n          label = str('{0:.2%}'.format(bar_chart.loc[i][j]))\n          labels.append(label)\n\npatches = ax.patches\n\nfor label, rect in zip(labels, patches):\n    width = rect.get_width()\n    if width > 0:\n        x = rect.get_x()\n        y = rect.get_y()\n        height = rect.get_height()\n        ax.text(x + width\/2., y + height\/2., label, ha='center', va='center', color='black')\n\nax.set_xticklabels(labels=ax.get_xticklabels(), rotation=0)\nax.set_yticklabels(labels='')\nax.set_ylabel('% of records')\nplt.legend(bbox_to_anchor = (1, 1.01), edgecolor='black')\nplt.show()","681cde81":"sns.boxplot(data=df_wine, x=\"quality\", y =\"alcohol\").set(title='Quality v\/s Alcohol')","08d15b11":"def KdeAndBox(at1,at2):\n    plt.figure(figsize=(14,9))\n    plt.subplot(2,2,1)\n    sns.kdeplot(df_wine.loc[df_wine[\"quality\"]==\"Low\"][at1],shade=True)\n    sns.kdeplot(df_wine.loc[df_wine[\"quality\"]==\"High\"][at1],shade=True)\n\n    plt.legend([\"Low\",\"High\"])\n    plt.title(at1.upper(),fontsize=15)\n    plt.subplot(2,2,2)\n    sns.kdeplot(df_wine.loc[df_wine[\"quality\"]==\"Low\"][at2],shade=True)\n    sns.kdeplot(df_wine.loc[df_wine[\"quality\"]==\"High\"][at2],shade=True)\n    plt.legend([\"Low\",\"High\"])\n    plt.title(at2.upper(),fontsize=15)\n    plt.subplot(2,2,3)\n    sns.violinplot(data=df_wine,y=at1,x=\"quality\")\n    plt.subplot(2,2,4)\n    sns.violinplot(data=df_wine,y=at2,x=\"quality\")\n    plt.show()","a45cb90b":"KdeAndBox(\"fixed_acidity\",\"volatile_acidity\")","e5e66439":"KdeAndBox(\"citric_acid\",\"alcohol\")","fc8afa1f":"KdeAndBox(\"chlorides\",\"density\")","61586094":"KdeAndBox(\"total_sulfur_dioxide\",\"free_sulfur_dioxide\")","d7aae910":"KdeAndBox(\"pH\",\"sulphates\")","21384a5c":"plt.figure(figsize=(14,4.5))\nplt.subplot(1,2,1)\nsns.kdeplot(df_wine.loc[df_wine[\"quality\"]==\"Low\"][\"residual_sugar\"],shade=True)\nsns.kdeplot(df_wine.loc[df_wine[\"quality\"]==\"High\"][\"residual_sugar\"],shade=True)\n\nplt.legend([\"Low\",\"High\"])\nplt.title(\"residual sugar\".upper(),fontsize=15)\nplt.subplot(1,2,2)\nsns.violinplot(data=df_wine,y=\"residual_sugar\",x=\"quality\")\nplt.show()\n","b27be92a":"# Seaborn pairplot\nsns_plot = sns.pairplot(df_wine,corner=True,hue='type',palette='dark:salmon_r',height=4.0)\nplt.show()","94ad38e2":"df_wine['sulfur_dioxide_ratio'] = df_wine['free_sulfur_dioxide']\/df_wine['total_sulfur_dioxide']","aa96b167":"df_wine.drop(['free_sulfur_dioxide'],axis=1,inplace=True)","2b7aa2a7":"df_wine.head().style.set_properties(**{'background-color':'black','color':'white','border-color':'red'})","a7a7fbdd":"df_num_features=df_wine.select_dtypes(include=np.number)","9199da88":"Q1 = df_num_features.quantile(0.25)\nQ3 = df_num_features.quantile(0.75)\nIQR = Q3 - Q1\nprint(IQR)","ed6a5daf":"outlier = pd.DataFrame((df_num_features < (Q1 - 1.5 * IQR)) | (df_num_features > (Q3 + 1.5 * IQR)))","cd4c11a1":"for i in outlier.columns:\n    print('Total number of Outliers in column {} are {}'.format(i, (len(outlier[outlier[i] == True][i]))))","f271829f":"for column in enumerate(df_num_features):\n    plt.figure(figsize=(30,5))\n    sns.set_theme(style=\"darkgrid\")\n    sns.boxplot(x=column[1], data=  df_num_features,color='red')\n    plt.xlabel(column[1],fontsize=18)\n    plt.show()","0e348d6a":"import scipy\nfrom scipy.stats import shapiro\nstat, p_value = shapiro(df_num_features)\n\n# print the test statistic and corresponding p-value \nprint('Test statistic:', stat)\nprint('P-Value:', p_value)","8c0c4e2f":"df_wine = df_wine[~((df_wine < (Q1 - 1.5 * IQR)) |(df_wine > (Q3 + 1.5 * IQR))).any(axis=1)]\ndf_wine.shape","59e004b2":"df_wine.reset_index(inplace=True,drop=True)","3599a4d5":"df_wine.tail().style.set_properties(**{'background-color':'black','color':'white','border-color':'red'})","f30d0c0d":"data_num_features = df_wine.select_dtypes(include=np.number)\n# print the names of the numeric variables \nprint('The numerical columns in the dataset are: ',data_num_features.columns)","330a85de":"corr =  data_num_features.corr()\n\n# print the correlation matrix\ncorr.style.set_properties(**{'background-color':'black','color':'white','border-color':'red'})","5731c052":"plt.figure(figsize=(11,9))\ndropSelf = np.zeros_like(corr_matrix)\ndropSelf[np.triu_indices_from(dropSelf)] = True\n\nsns.heatmap(corr, cmap=sns.diverging_palette(220, 10, as_cmap=True), annot=True, fmt=\".2f\", mask=dropSelf)\n\nsns.set(font_scale=1.5)","6182c377":"df_wine['type']=pd.get_dummies(df_wine['type'])\nquaity_mapping = {\"Low\":0, \"High\":1}\ndf_wine[\"quality\"] =  df_wine[\"quality\"].map(quaity_mapping)\ndf_wine.head().style.set_properties(**{'background-color':'black','color':'white','border-color':'red'})","a8e66fe7":"df_wine.dtypes","50b790b4":"df_num_features=df_wine.drop(['type','quality'],axis=1)","1074a271":"for col in df_num_features.columns:\n    print(\"Column \", col, \" :\", shapiro(df_num_features[col]))","77005831":"mms = MinMaxScaler()\nmmsfit = mms.fit(df_num_features)\ndfxz = pd.DataFrame(mms.fit_transform(df_num_features), columns = df_num_features.columns)","f55fca3f":"dfxz.head().style.set_properties(**{'background-color':'black','color':'white','border-color':'red'})","ab92237b":"df_cat=df_wine[['type','quality']]","6d7ac94d":"dfxz = pd.concat([dfxz, df_cat], axis = 1)\ndfxz.head().style.set_properties(**{'background-color':'black','color':'white','border-color':'red'})","f4928552":"dfxz.isna().sum()","1821e99e":"X=dfxz.drop('quality',axis=1)\ny=dfxz['quality']","e0b8db0c":"# add a constant column to the dataframe\n# while using the 'Logit' method in the Statsmodels library, the method do not consider the intercept by default\n# I can add the intercept to the set of independent variables using 'add_constant()'\nX = sm.add_constant(X)\n\n# split data into train subset and test subset\n# set 'random_state' to generate the same dataset each time you run the code \n# 'test_size' returns the proportion of data to be included in the testing set\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 10, test_size = 0.3)\n\n# check the dimensions of the train & test subset using 'shape'\n# print dimension of train set\nprint('X_train', X_train.shape)\nprint('y_train', y_train.shape)\n\n# print dimension of test set\nprint('X_test', X_test.shape)\nprint('y_test', y_test.shape)","ab239325":"# create an empty dataframe to store the scores for various algorithms\nscore_card1 = pd.DataFrame(columns=['Probability Cutoff', 'AUC Score', 'Precision Score', 'Recall Score',\n                                       'Accuracy Score', 'Kappa Score', 'f1-score'])\n\n# append the result table for all performance scores\n# performance measures considered for model comparision are 'AUC Score', 'Precision Score', 'Recall Score','Accuracy Score',\n# 'Kappa Score', and 'f1-score'\n# compile the required information in a user defined function \ndef update_score_card1(model, cutoff):\n    \n    # let 'y_pred_prob' be the predicted values of y\n    y_pred_prob = model.predict(X_test[features])\n\n    # convert probabilities to 0 and 1 using 'if_else'\n    y_pred = [ 0 if x < cutoff else 1 for x in y_pred_prob]\n    \n    # assign 'score_card' as global variable\n    global score_card1\n\n    # append the results to the dataframe 'score_card'\n    # 'ignore_index = True' do not consider the index labels\n    score_card1 = score_card1.append({'Probability Cutoff': cutoff,\n                                    'AUC Score' : metrics.roc_auc_score(y_test, y_pred),\n                                    'Precision Score': metrics.precision_score(y_test, y_pred),\n                                    'Recall Score': metrics.recall_score(y_test, y_pred),\n                                    'Accuracy Score': metrics.accuracy_score(y_test, y_pred),\n                                    'Kappa Score':metrics.cohen_kappa_score(y_test, y_pred),\n                                    'f1-score': metrics.f1_score(y_test, y_pred)}, \n                                    ignore_index = True)","e425ab9f":"logreg = sm.Logit(y_train, X_train).fit()\n\n# print the summary of the model\nprint(logreg.summary())","b26f8f17":"sfs_backward=sfs(estimator=LogisticRegression(),k_features='best',forward=False,verbose=0,scoring='accuracy')\nsfs_model=sfs_backward.fit(X_train,y_train)\nfeatures=list(sfs_model.k_feature_names_)\nprint(\"The best features obtained from elimination process:\",features)","7e246985":"logreg_backward = sm.Logit(y_train, X_train[features]).fit()\n\n# print the summary of the model\nprint(logreg_backward.summary())","16101fe5":"# consider a list of values for cut-off\ncutoff = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n\n# use the for loop to compute performance measures for each value of the cut-off\n# call the update_score_card() to update the score card for each cut-off\n# pass the model and cut-off value to the function\nfor value in cutoff:\n    update_score_card1(logreg_backward, value)","ee5689db":"# print the score card \nprint('Score Card for Logistic regression:')\n\n# sort the dataframe based on the probability cut-off values ascending order\n# 'reset_index' resets the index of the dataframe\n# 'drop = True' drops the previous index\nscore_card1 = score_card1.sort_values('Probability Cutoff').reset_index(drop = True)\n\n# color the cell in the columns 'AUC Score', 'Accuracy Score', 'Kappa Score', 'f1-score' having maximum values\n# 'style.highlight_max' assigns color to the maximum value\n# pass specified color to the parameter, 'color'\n# pass the data to limit the color assignment to the parameter, 'subset' \nscore_card1.style.highlight_max(color = 'red', subset = ['Accuracy Score'])","f1b24780":"# let 'y_pred_prob1' be the predicted values of y\ny_pred_prob1 = logreg_backward.predict(X_train[features])\n\n# print the y_pred_prob1\ny_pred_prob1.head()","9f4a27cf":"# convert probabilities to 0 and 1 using 'if_else'\ny_pred1 = [ 0 if x < 0.5 else 1 for x in y_pred_prob1]\ny_pred1[:10]","1e0e2b35":"# let 'y_pred_prob' be the predicted values of y\ny_pred_prob = logreg_backward.predict(X_test[features])\n\n# print the y_pred_prob\ny_pred_prob.head()","725462e6":"# convert probabilities to 0 and 1 using 'if_else'\ny_pred = [ 0 if x < 0.5 else 1 for x in y_pred_prob]\ny_pred[:10]","314f9f30":"# create a confusion matrix\n# pass the actual and predicted target values to the confusion_matrix()\ncm = confusion_matrix(y_test, y_pred)\n\n# label the confusion matrix  \n# pass the matrix as 'data'\n# pass the required column names to the parameter, 'columns'\n# pass the required row names to the parameter, 'index'\nconf_matrix = pd.DataFrame(data = cm,columns = ['Predicted:0','Predicted:1'], index = ['Actual:0','Actual:1'])\n\n# plot a heatmap to visualize the confusion matrix\n# 'annot' prints the value of each grid \n# 'fmt = d' returns the integer value in each grid\n# 'cmap' assigns color to each grid\n# as I do not require different colors for each grid in the heatmap,\n# use 'ListedColormap' to assign the specified color to the grid\n# 'cbar = False' will not return the color bar to the right side of the heatmap\n# 'linewidths' assigns the width to the line that divides each grid\n# 'annot_kws = {'size':25})' assigns the font size of the annotated text \nsns.heatmap(conf_matrix, annot= True, fmt = 'd', cmap ='Reds', cbar = False, linewidths = 0.1, annot_kws = {'size':25})\n\n# set the font size of x-axis ticks using 'fontsize'\nplt.xticks(fontsize = 20)\n\n# set the font size of y-axis ticks using 'fontsize'\nplt.yticks(fontsize = 20)\n\n# display the plot\nplt.show()","7acea9fc":"print(classification_report(y_train, y_pred1))","9c0ba394":"print(classification_report(y_test, y_pred))","280ae763":"# the roc_curve() returns the values for false positive rate, true positive rate and threshold\n# pass the actual target values and predicted probabilities to the function\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n\n# plot the ROC curve\nplt.plot(fpr, tpr)\n\n# set limits for x and y axes\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\n\n# plot the straight line showing worst prediction for the model\nplt.plot([0, 1], [0, 1],'r--')\n\n# add plot and axes labels\n# set text size using 'fontsize'\nplt.title('ROC curve ', fontsize = 15)\nplt.xlabel('False positive rate (1-Specificity)', fontsize = 15)\nplt.ylabel('True positive rate (Sensitivity)', fontsize = 15)\n\n# add the AUC score to the plot\n# 'x' and 'y' gives position of the text\n# 's' is the text \n# use round() to round-off the AUC score upto 4 digits\nplt.text(x = 0.02, y = 0.9, s = ('AUC Score:', round(metrics.roc_auc_score(y_test, y_pred_prob),4)))\n                               \n# plot the grid\nplt.grid(True)","28fc965f":"#defining a score card\nscore_card=pd.DataFrame(columns=['Model_Name','Accuracy(Train)','Accuracy(Test)','Diff_b\/w_train&test(Acc)','AUC_Score','Avg(Acc)'])","0954b05d":"# Predicting Cross Validation Score\ncv_lr = cross_val_score(estimator = LogisticRegression() , X = X_train[features], y = y_train, cv = 10,scoring='accuracy')","80c3e492":"score_card=score_card.append({'Model_Name': 'Logistic Regression',\n                             'Accuracy(Train)': metrics.accuracy_score(y_train, y_pred1),\n                             'Accuracy(Test)':metrics.accuracy_score(y_test, y_pred),\n                             'Diff_b\/w_train&test(Acc)': abs(metrics.accuracy_score(y_train, y_pred1)-metrics.accuracy_score(y_test, y_pred)),\n                             'AUC_Score':metrics.roc_auc_score(y_test, y_pred_prob),\n                             'Avg(Acc)':cv_lr.mean()},ignore_index=True)\nscore_card","d70b00b4":"# create a generalized function to calculate the metrics values for train set\ndef get_train_report(model):\n    \n    # for training set:\n    # train_pred: prediction made by the model on the train dataset 'X_train'\n    # y_train: actual values of the target variable for the train dataset\n\n    # predict the output of the target variable from the train data \n    train_pred = model.predict(X_train)\n\n    # return the performace measures on train set\n    return(classification_report(y_train, train_pred))","ffb6763a":"# create a generalized function to calculate the performance metrics values for test set\ndef get_test_report(model):\n    \n    # for test set:\n    # test_pred: prediction made by the model on the test dataset 'X_test'\n    # y_test: actual values of the target variable for the test dataset\n\n    # predict the output of the target variable from the test data \n    test_pred = model.predict(X_test)\n\n    # return the classification report for test data\n    return(classification_report(y_test, test_pred))","9aebc77f":"# define a to plot a confusion matrix for the model\ndef plot_confusion_matrix(model):\n    \n    # predict the target values using df_test\n    y_pred = model.predict(X_test)\n    \n    # create a confusion matrix\n    # pass the actual and predicted target values to the confusion_matrix()\n    cm = confusion_matrix(y_test, y_pred)\n\n    # label the confusion matrix  \n    # pass the matrix as 'data'\n    # pass the required column names to the parameter, 'columns'\n    # pass the required row names to the parameter, 'index'\n    conf_matrix = pd.DataFrame(data = cm,columns = ['Predicted:0','Predicted:1'], index = ['Actual:0','Actual:1'])\n\n    # plot a heatmap to visualize the confusion matrix\n    # 'annot' prints the value of each grid \n    # 'fmt = d' returns the integer value in each grid\n    # 'cmap' assigns color to each grid\n    # as I do not require different colors for each grid in the heatmap,\n    # use 'ListedColormap' to assign the specified color to the grid\n    # 'cbar = False' will not return the color bar to the right side of the heatmap\n    # 'linewidths' assigns the width to the line that divides each grid\n    # 'annot_kws = {'size':25})' assigns the font size of the annotated text \n    sns.heatmap(conf_matrix, annot = True, fmt = 'd', cmap = 'Reds', cbar = False, \n                linewidths = 0.1, annot_kws = {'size':25})\n\n    # set the font size of x-axis ticks using 'fontsize'\n    plt.xticks(fontsize = 20)\n\n    # set the font size of y-axis ticks using 'fontsize'\n    plt.yticks(fontsize = 20)\n\n    # display the plot\n    plt.show()","b9722b32":"# define a function to plot the ROC curve and print the ROC-AUC score\ndef plot_roc(model):\n    \n    # predict the probability of target variable using X_test\n    # consider the probability of positive class by subsetting with '[:,1]'\n    y_pred_prob = model.predict_proba(X_test)[:,1]\n    \n    # the roc_curve() returns the values for false positive rate, true positive rate and threshold\n    # pass the actual target values and predicted probabilities to the function\n    fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n\n    # plot the ROC curve\n    plt.plot(fpr, tpr)\n\n    # set limits for x and y axes\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.0])\n\n    # plot the straight line showing worst prediction for the model\n    plt.plot([0, 1], [0, 1],'r--')\n\n    # add plot and axes labels\n    # set text size using 'fontsize'\n    plt.title('ROC curve ', fontsize = 15)\n    plt.xlabel('False positive rate (1-Specificity)', fontsize = 15)\n    plt.ylabel('True positive rate (Sensitivity)', fontsize = 15)\n\n    # add the AUC score to the plot\n    # 'x' and 'y' gives position of the text\n    # 's' is the text \n    # use round() to round-off the AUC score upto 4 digits\n    plt.text(x = 0.02, y = 0.9, s = ('AUC Score:',round(metrics.roc_auc_score(y_test, y_pred_prob),4)))\n\n    # plot the grid\n    plt.grid(True)","8b527449":"# Predicting Cross Validation Score\ndef cross_valid_score(obj):\n    cv = cross_val_score(estimator = obj , X = X_train, y = y_train, cv = 10,scoring='accuracy')\n    return cv.mean()","fd8f0688":"def update_score_card(model_name,model):\n    global score_card\n    train_pred = model.predict(X_train)\n    test_pred=model.predict(X_test)\n    y_pred_prob = model.predict_proba(X_test)[:,1]\n    score_card=score_card.append({'Model_Name': model_name,\n                             'Accuracy(Train)': metrics.accuracy_score(y_train, train_pred),\n                             'Accuracy(Test)':metrics.accuracy_score(y_test, test_pred),\n                             'Diff_b\/w_train&test(Acc)': abs(metrics.accuracy_score(y_train, train_pred)-metrics.accuracy_score(y_test, test_pred)),\n                             'AUC_Score':metrics.roc_auc_score(y_test, y_pred_prob),\n                             'Avg(Acc)':cross_valid_score(model)},ignore_index=True)\n    return score_card","10729a77":"# instantiate the 'GaussianNB'\ngnb = GaussianNB()\n\n# fit the model using fit() on train data\ngnb_model = gnb.fit(X_train, y_train)","07407340":"plot_confusion_matrix(gnb_model)","3596c985":"train_report = get_train_report(gnb_model)\n\n# print the performace measures\nprint(train_report)","03b21e7c":"test_report = get_test_report(gnb_model)\n\n# print the performace measures\nprint(test_report)","86a94a5a":"# call the function to plot the ROC curve\n# pass the  gaussian naive bayes model to the function\nplot_roc(gnb_model)","2d2deb28":"update_score_card('Navie Bayes',gnb_model)","5645cf3d":"# create a dictionary with hyperparameters and its values\n# n_neighnors: number of neighbors to consider\n# usually, I consider the odd value of 'n_neighnors' to avoid the equal number of nearest points with more than one class\n# pass the different distance metrics to the parameter, 'metric'\ntuned_paramaters = {'n_neighbors': np.arange(1, 25, 2),\n                   'metric': ['hamming','euclidean','manhattan','Chebyshev']}\n \n# instantiate the 'KNeighborsClassifier' \nknn_classification = KNeighborsClassifier()\n\n# use GridSearchCV() to find the optimal value of the hyperparameters\n# estimator: pass the knn model\n# param_grid: pass the list 'tuned_parameters'\n# cv: number of folds in k-fold i.e. here cv = 5\n# scoring: pass the scoring parameter 'accuracy'\nknn_grid = GridSearchCV(estimator = knn_classification, \n                        param_grid = tuned_paramaters, \n                        cv = 5, \n                        scoring = 'accuracy')\n\n# fit the model on X_train and y_train using fit()\nknn_grid.fit(X_train, y_train)\n\n# get the best parameters\nprint('Best parameters for KNN Classifier: ', knn_grid.best_params_, '\\n')","6a006095":"# instantiate the 'KNeighborsClassifier'\n# n_neighnors: number of neighbors to consider\n# default metric is minkowski, and with p=2 it is equivalent to the euclidean metric\nknn_classification = KNeighborsClassifier(n_neighbors =17,p=2)\n\n# fit the model using fit() on train data\nknn_model = knn_classification.fit(X_train, y_train)","925f4d57":"# consider an empty list to store accuracy rate\naccuracy_rate = []\n\n# use for loop to build a knn model for each K\nfor i in np.arange(1,25,2):\n    \n    # setup a knn classifier with k neighbors\n    # use the 'euclidean' metric \n    knn = KNeighborsClassifier(i, metric = 'euclidean')\n   \n    # fit the model using 'cross_val_score'\n    # pass the knn model as 'estimator'\n    # use 5-fold cross validation\n    score = cross_val_score(knn, X_train, y_train, cv = 5)\n    \n    # calculate the mean score\n    score = score.mean()\n    \n    # compute accuracy rate \n    accuracy_rate.append(score)\n\n# plot the accuracy_rate for different values of K \nplt.plot(range(1,25,2), accuracy_rate,color ='blue',linestyle ='dashed', marker ='o',markerfacecolor ='red', markersize = 10)\n\n# add plot and axes labels\n# set text size using 'fontsize'\nplt.title('accuracy Rate', fontsize = 15)\nplt.xlabel('K', fontsize = 15)\nplt.ylabel('accuracy Rate', fontsize = 15)\n\n# set the x-axis labels\nplt.xticks(np.arange(1, 25, step = 2))\n\n# plot a vertical line across the maximum accuracy rate\nplt.axvline(x = 17, color = 'red')\n\n# display the plot\nplt.show()","c7188681":"# consider an empty list to store error rate\nerror_rate = []\n\n# use for loop to build a knn model for each K\nfor i in np.arange(1,25,2):\n    \n    # setup a knn classifier with k neighbors\n    # use the 'euclidean' metric \n    knn = KNeighborsClassifier(i, metric = 'euclidean')\n   \n    # fit the model using 'cross_val_score'\n    # pass the knn model as 'estimator'\n    # use 5-fold cross validation\n    score = cross_val_score(knn, X_train, y_train, cv = 5)\n    \n    # calculate the mean score\n    score = score.mean()\n    \n    # compute error rate \n    error_rate.append(1 - score)\n\n# plot the error_rate for different values of K \nplt.plot(range(1,25,2), error_rate,color ='blue',linestyle ='dashed', marker ='o',markerfacecolor ='red', markersize = 10)\n\n# add plot and axes labels\n# set text size using 'fontsize'\nplt.title('Error Rate', fontsize = 15)\nplt.xlabel('K', fontsize = 15)\nplt.ylabel('Error Rate', fontsize = 15)\n\n# set the x-axis labels\nplt.xticks(np.arange(1, 25, step = 2))\n\n# plot a vertical line across the minimum error rate\nplt.axvline(x = 17, color = 'red')\n\n# display the plot\nplt.show()","e2e550e1":"plot_confusion_matrix(knn_model)","ae30bf96":"# compute the performance measures on test data\n# call the function 'get_train_report'\n# pass the knn model to the function\ntrain_report = get_train_report(knn_model)\n\n# print the performace measures\nprint(train_report)","cb7733a7":"# compute the performance measures on test data\n# call the function 'get_test_report'\n# pass the knn model to the function\ntest_report = get_test_report(knn_model)\n\n# print the performace measures\nprint(test_report)","1243e99f":"# call the function to plot the ROC curve\n# pass the knn model to the function\nplot_roc(knn_model)","153995b6":"update_score_card('KNeighbors Classifier',knn_model)","650e9e08":"tuned_paramaters = [{'criterion': ['entropy', 'gini'], \n                     'max_depth': [2,4,6,8,10],\n                     'max_features': [\"sqrt\", \"log2\"],\n                     'min_samples_split': [2,4,6,8,10],\n                     'min_samples_leaf': [2,4,6,8,10],\n                     'max_leaf_nodes': [2,4,6,8,10]}]\n \n# instantiate the 'DecisionTreeClassifier' \n# pass the 'random_state' to obtain the same samples for each time you run the code\ndecision_tree_classification = DecisionTreeClassifier(random_state = 10)\n\n# use GridSearchCV() to find the optimal value of the hyperparameters\n# estimator: pass the decision tree classifier model\n# param_grid: pass the list 'tuned_parameters'\n# cv: number of folds in k-fold i.e. here cv = 5\ntree_grid = GridSearchCV(estimator = decision_tree_classification, \n                         param_grid = tuned_paramaters, \n                         cv = 5)\n\n# fit the model on X_train and y_train using fit()\ntree_grid_model = tree_grid.fit(X_train, y_train)\n\n# get the best parameters\nprint('Best parameters for decision tree classifier: ', tree_grid_model.best_params_, '\\n')","145bf87a":"decision_tree = DecisionTreeClassifier(criterion = tree_grid_model.best_params_.get('criterion'),\n                                  max_depth = tree_grid_model.best_params_.get('max_depth'),\n                                  max_features = tree_grid_model.best_params_.get('max_features'),\n                                  max_leaf_nodes = tree_grid_model.best_params_.get('max_leaf_nodes'),\n                                  min_samples_leaf = tree_grid_model.best_params_.get('min_samples_leaf'),\n                                  min_samples_split = tree_grid_model.best_params_.get('min_samples_split'),\n                                  random_state = 10)\n\n# use fit() to fit the model on the train set\ndecision_tree = decision_tree.fit(X_train, y_train)","455ecd84":"plt.figure(figsize=(60,30))\nplot_tree(decision_tree, filled=True);","8e4e910a":"plot_confusion_matrix(decision_tree)","df09ec94":"# compute the performance measures on test data\n# call the function 'get_train_report'\n# pass the decision tree  model to the function\ntrain_report = get_train_report(decision_tree)\n\n# print the performace measures\nprint(train_report)","7d226fef":"# compute the performance measures on test data\n# call the function 'get_test_report'\n# pass the decision tree model to the function\ntest_report = get_test_report(decision_tree)\n\n# print the performace measures\nprint(test_report)","4d94c829":"# call the function to plot the ROC curve\n# pass the decision tree model to the function\nplot_roc(decision_tree)","b4e16a26":"update_score_card('Decision Tree Classifier',decision_tree)","ae4fe419":"tuned_paramaters = [{'criterion': ['entropy', 'gini'],\n                     'n_estimators': [ 30, 50, 70],\n                     'max_depth': [10,15,20],\n                     'max_features': [\"sqrt\", \"log2\"],\n                     'min_samples_split': [2,6,10],\n                     'min_samples_leaf': [2,6,10],\n                     'max_leaf_nodes': [2,6,10]}]\n \n# instantiate the 'RandomForestClassifier' \n# pass the 'random_state' to obtain the same samples for each time you run the code\nrandom_forest_classification = RandomForestClassifier(random_state = 10)\n\n# use GridSearchCV() to find the optimal value of the hyperparameters\n# estimator: pass the random forest classifier model\n# param_grid: pass the list 'tuned_parameters'\n# cv: number of folds in k-fold i.e. here cv = 5\nrf_grid = GridSearchCV(estimator = random_forest_classification, \n                       param_grid = tuned_paramaters, \n                       cv = 5)\n\n# use fit() to fit the model on the train set\nrf_grid_model = rf_grid.fit(X_train, y_train)\n\n# get the best parameters\nprint('Best parameters for random forest classifier: ', rf_grid_model.best_params_, '\\n')","f4f22508":"# instantiate the 'RandomForestClassifier'\n# 'best_params_' returns the dictionary containing best parameter values and parameter name  \n# 'get()' returns the value of specified parameter\n# pass the 'random_state' to obtain the same samples for each time you run the code\nrandom_forest = RandomForestClassifier(criterion = rf_grid_model.best_params_.get('criterion'),\n                                   n_estimators=rf_grid_model.best_params_.get('n_estimators'),\n                                  max_depth = rf_grid_model.best_params_.get('max_depth'),\n                                  max_features = rf_grid_model.best_params_.get('max_features'),\n                                  max_leaf_nodes = rf_grid_model.best_params_.get('max_leaf_nodes'),\n                                  min_samples_leaf = rf_grid_model.best_params_.get('min_samples_leaf'),\n                                  min_samples_split = rf_grid_model.best_params_.get('min_samples_split'),\n                                  random_state = 10)\n\n# use fit() to fit the model on the train set\nrandom_forest = random_forest.fit(X_train, y_train)","5059dc55":"plot_confusion_matrix(random_forest)","56d2026c":"# compute the performance measures on test data\n# call the function 'get_train_report'\n# pass the Random Forest  model to the function\ntrain_report = get_train_report(random_forest)\n\n\n# print the performace measures\nprint(train_report)","325d059a":"# compute the performance measures on test data\n# call the function 'get_test_report'\n# pass the Random Forest model to the function\ntest_report = get_test_report(random_forest)\n\n# print the performace measures\nprint(test_report)","328a8304":"# call the function to plot the ROC curve\n# pass the random forest model to the function\nplot_roc(random_forest)","db68c5af":"update_score_card('Random Forest Classifier',random_forest)","dcfa7ead":"tuning_parameters = {'learning_rate': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6],'n_estimators' : [10,20,30,40,50]}\nada_model = AdaBoostClassifier()\n\n# use GridSearchCV() to find the optimal value of the hyperparameters\n# estimator: pass the AdaBoost classifier model\n# param_grid: pass the list 'tuned_parameters'\n# cv: number of folds in k-fold i.e. here cv = 3\n# scoring: pass a measure to evaluate the model on test set\nada_grid = GridSearchCV(estimator = ada_model, param_grid = tuning_parameters, cv = 3, scoring = 'roc_auc')\n\n# fit the model on X_train and y_train using fit()\nada_grid.fit(X_train, y_train)\n\n# get the best parameters\nprint('Best parameters for ADABoost classifier: ', ada_grid.best_params_, '\\n')","89c1169c":"# instantiate the 'AdaBoostClassifier'\n# n_estimators: number of estimators at which boosting is terminated\n# pass the 'random_state' to obtain the same results for each code implementation\nada_model = AdaBoostClassifier(n_estimators = 40, random_state = 10,learning_rate= 0.4)\n\n# fit the model using fit() on train data\nada_model.fit(X_train, y_train)","c1e29d8a":"plot_confusion_matrix(ada_model)","dc16501a":"# compute the performance measures on test data\n# call the function 'get_train_report'\n# pass the adaboost model to the function\ntrain_report = get_train_report(ada_model)\n\n# print the performace measures\nprint(train_report)","50515d83":"# compute the performance measures on test data\n# call the function 'get_test_report'\n# pass the adaboost model to the function\ntest_report = get_test_report(ada_model)\n\n# print the performace measures\nprint(test_report)","0f0d9c2a":"# call the function to plot the ROC curve\n# pass the adaboost model to the function\nplot_roc(ada_model)","9af5360e":"update_score_card('Ada Boost Classifier',ada_model)","599104de":"tuning_parameters = {'learning_rate': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6],'n_estimators':[30, 50, 70, 90],\n                     'max_depth': [2,6,10],'min_samples_split': [2,6,10],\n                     'min_samples_leaf': [2,6,10]}\ngboost_model = GradientBoostingClassifier()\ngb_grid = GridSearchCV(estimator = gboost_model, param_grid = tuning_parameters, cv = 3, scoring = 'roc_auc')\ngb_grid.fit(X_train, y_train)\nprint('Best parameters for GBoost classifier: ', gb_grid.best_params_, '\\n')","2369fa47":"gboost_model = GradientBoostingClassifier(n_estimators = 70, random_state = 10,learning_rate=0.2,\n                                          min_samples_leaf=10,min_samples_split=2,max_depth= 2)\ngboost_model.fit(X_train, y_train)","d738702c":"plot_confusion_matrix(gboost_model)","d111c75c":"train_report = get_train_report(gboost_model)\n\n# print the performace measures\nprint(train_report)","e2be84a0":"test_report = get_test_report(gboost_model)\n\n# print the performance measures\nprint(test_report)","a16eaa24":"plot_roc(gboost_model)","e184fbfd":"update_score_card('Gradient Boosting Classifier',gboost_model)","85ca7e94":"tuning_parameters = {'learning_rate': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6],\n                     'max_depth': [1,3,5,7,9],\n                     'gamma': [0, 1, 2, 3, 4]}\nxgb_model = XGBClassifier()\nxgb_grid = GridSearchCV(estimator = xgb_model, param_grid = tuning_parameters, cv = 3, scoring = 'roc_auc',verbose=0)\nxgb_grid.fit(X_train, y_train)\n\n# get the best parameters\nprint('Best parameters for XGBoost classifier: ', xgb_grid.best_params_, '\\n')","47fbdb38":"xgb_model = XGBClassifier(learning_rate=0.1, gamma = 1,max_depth=3,verbosity=0)\n\n# fit the model using fit() on train data\nxgb_model.fit(X_train, y_train)","dd3cafd8":"plot_confusion_matrix(xgb_model)","6c5ffc8f":"train_report = get_train_report(xgb_model)\n\n# print the performace measures\nprint(train_report)","26aed237":"test_report = get_test_report(xgb_model)\n\n# print the performance measures\nprint(test_report)","3578a137":"plot_roc(xgb_model)","d0af1db0":"update_score_card('Extreme Gradient Boosting Classifier',xgb_model)","195bf4f9":"# consider the various algorithms as base learners\nbase_learners = [('rf_model', RandomForestClassifier(criterion = 'gini', max_depth = 10, max_features = 'sqrt', \n                                                     max_leaf_nodes = 10, min_samples_leaf = 10, min_samples_split = 2, \n                                                     n_estimators = 50, random_state = 10)),\n                 ('KNN_model', KNeighborsClassifier(n_neighbors = 17, metric = 'euclidean')),\n                 ('NB_model', GaussianNB()),\n                 ('Decision_tree',DecisionTreeClassifier(criterion = 'entropy', max_depth= 6, max_features= 'sqrt',\n                                                         max_leaf_nodes= 10, min_samples_leaf= 10, min_samples_split= 2,random_state = 10))]\n\n# initialize stacking classifier \n# pass the base learners to the parameter, 'estimators'\n# pass the XGB Classifier model as the 'final_estimator'\/ meta model\nstack_model = StackingClassifier(estimators = base_learners, final_estimator = XGBClassifier())\n\n# fit the model on train dataset\nstack_model.fit(X_train, y_train)","feff67b6":"plot_confusion_matrix(stack_model)","723ade75":"train_report = get_train_report(stack_model)\n\n# print the performace measures\nprint(train_report)","e025b4b5":"test_report = get_test_report(stack_model)\n\n# print the performance measures\nprint(test_report)","8140d097":"plot_roc(stack_model)","d89a1ec8":"update_score_card('Stack Generalization',stack_model)","343d5e82":"score_card = score_card.sort_values('Diff_b\/w_train&test(Acc)').reset_index(drop = True)\n\nscore_card.style.highlight_min(color = 'red', subset = ['Diff_b\/w_train&test(Acc)'])","9f4a81a1":"# create a dataframe that stores the feature names and their importance\n# 'feature_importances_' returns the features based on the average gain \nimportant_features = pd.DataFrame({'Features': X_train.columns, \n                                   'Importance': decision_tree.feature_importances_})\n\n# sort the dataframe in the descending order according to the feature importance\nimportant_features = important_features.sort_values('Importance', ascending = False)\n\n# create a barplot to visualize the features based on their importance\nsns.barplot(x = 'Importance', y = 'Features', data = important_features)\n\n# add plot and axes labels\n# set text size using 'fontsize'\nplt.title('Feature Importance', fontsize = 15)\nplt.xlabel('Importance', fontsize = 15)\nplt.ylabel('Features', fontsize = 15)\n\n# display the plot\nplt.show()","e43a0464":"**Interpretation:** From the above output, I can see that the testing model is 74% accurate.","d4fc9bad":"**Interpretation:** The `Pseudo R-squ.` obtained from the above model summary is **0.2312**  which is also the value of `McFadden's R-squared`. This value can be obtained from the formula:\n\n<p style='text-indent:25em'> <strong> McFadden's R-squared = $ 1 - \\frac{Log-Likelihood}{LL-Null} $<\/strong> <\/p>\n\nWhere,<br>\nLog-Likelihood: It is the maximum value of the log-likelihood function<br>\nLL-Null: It is the maximum value of the log-likelihood function for the model containing only the intercept \n\nThe LLR p-value is less than 0.05, implies that the model is significant.\n\nEven though the model is significant there are few features which are insignificant (P-value < 0.05)","58632786":"**Sulfur dioxide ratio**\n\nSince free sulfur dioxide is the unbound part of total sulfur dioxide, I will caculate the ratio of this two features. This feature has higher correlation to quality than each of the individuals","43f144f5":"**Interpretation:** From the above output, I can see that the testing model is 76% accurate.","cc9df217":"**Test Report**","ec12fb07":"**Predictions on the test set.**","b9473f9d":"From the above classification reports,I can infer that there is a little difference when compared to test and train reports.\nHence I conclude that the model is bit overfitted.","d257bde0":"### 4.2.3 Analyse Categorical Variables <a id='analyze_cat_var'><\/a>","5157c2dc":"From the above table , I can infer:\n\n    1. The minimum pH value is 2.7 and maximum pH value found is 4.01 thus all wine are acidic in nature\n    \n    2. The alocohl content in wine range from 8 to 15 with an average of 10.5\n    \n    3. The free_sulfur_dioxide in wine is less than 41 for 75% which is still 4 times less than that of total sulfur dioxide\n    \n    4. The maximum amount of fixed_acidity is 15.9 while 75% of it is less than 7.7 which implies possible outliers","67d98b59":"#### A generalized function to calculate the performance metrics for the train set.","0ea76249":"**Interpretation:** From the above output, I can see that the training model has 73% accuracy.","0c6a8ba1":"**Categorical Variables**","9905ad9b":"Now, let us consider a list of values as cut-off to calculate the different performance measures.","5f4246cc":"Since,there are many outliers present in the data for each column with missing values, I are replacing the null values using median.","ca7eb649":"**Confusion Matrix**","7cfb633b":"From the above graph, I can infer:\n\n     Majority of the wine is high quality and the target column is balanced.","4eff1885":"**Train report**","169442c0":"#### Building a naive bayes model on a training dataset.","885dd719":"**Interpretation:** The above bar plot shows that, of all the features `chlorides` is of most important feature. ","fdb0e0db":"**Interpretation:** \n\nFrom the above plot, I can see that our classifier(Stack Generalized model) is away from the dotted line; with the AUC score **0.7574**.","980cb8dc":"From the above KDE plot, I can infer:\n    1. The distribution for residual_sugar seems to be highly positively skewed for both quality types\n    3. For residual_sugar, values between 0-5 depict highest probability density for both quality types","8bfd11eb":"**Interpretation:** From the above output, I can see that the training model has 77% accuracy.","34b7397c":"**Interpretation:** From the above output, I can see that the training model has 78% accuracy.","f1bdf404":"In order to decrease the overfitting and increase the performance and accuracy of the Decision tree model.I further perform some Bagging and Boosting techniques.","72ed76c3":"## 4.1 Preparing the Dataset <a id='Data_Preparing'><\/a>","ed31f4b0":"## 5.3 Feature Scaling<a id='fea_sca'><\/a>","019f1794":"**Confusion matrix**","bdbdc328":"# Data Dictionary","0e50006f":"**Test report**","192d7b50":"**Score Card**","ac206033":"https:\/\/winesupreme.herokuapp.com\/","98259fb2":"From the above KDE plot, I can infer:\n    1. The distribution for citric_acid when the quality is Low seems to be close to normally distributed whilst when        quality is High it seems to be moderatley positively skewed\n    2. The distribution for alcohol when the quality is Low seems to be highly positively skewed whilst when the quality is High the distribution seems very close to being normally distributed\n    3. For citric_acid, values between 0-0.5 depict highest probability density irrespective of quality and there is a lot  of difference between the probability density for Low and High.\n    4. For alcohol, values between 8-10 depict highest probabilty density for Low quality wine while high quality wine seems to be normally distributed with the highest point between 10-12","a9024f8d":"# 1. Import Libraries <a id='import_lib'><\/a>","f4a14921":"#### Score Card","0088d4bf":"# 6. Logistic Regression<a id=\"log_reg\"><\/a>","1aba003b":"### 5.1.2 Removal of Outliers<a id='rem_out'><\/a>","aea4df21":"**Of all the models built, I see that Decision tree classifier model has been the most effective with no overfitting.**\n\n**Some of the features which contribute more for prediction of quality are chlorides,density,citric acid,volatile_acidity and sulfur_dioxide_ratio.**\n\n**Results can be used by wine manufactures to improve the quality of wine in future and can also be used by consumers for wine selection.**\n\n**I can hereby conclude that I have successfully built a model that can predict quality of wine.**","5537550b":"**Tune the Hyperparameters (GridSearchCV)**","577cb193":"**Test report**","71086e01":"**Interpretation:** From the above output, I can see that the training model has 82% accuracy.","0e71ac60":"### 4.2.5 Analyse Relationship between Target and Independent Variables <a id='analyze_tar_ind_var'><\/a>","2f1e3320":"## 5.4 Train-Test Split<a id=\"split\"><\/a>","cb47cfcd":"From the above KDE plot, I can infer:\n    1. The distribution for total_sulfur_dioxide seems to be normally distributed for both quality types\n    2. The distribution for free_sulfur_dioxide seems to be highly positively skewed for both quality types\n    3. For total_sulfur_dioxide, values between 50-150 depict highest probability density when quality of wine is High       whilst the probably density function seems to be evenly spread across 50-200\n    4. For free_sulfur_dioxide, values between 0-50 depict highest probabilty density irrespective of the quality","5c184adf":"### 4.1.5 Indexing <a id='indexing'><\/a>","db7cacdc":"**Train report**","bee2b2f5":"#### Score Card","47afee30":"#### A generalized function to calculate the performance metrics for the test set.","b77a61a9":"### 4.2.4 Analyse Target Variable <a id='analyze_tar_var'><\/a>","9a165508":"From the above graph:\n\n    I can infer that majority is white wine compared to red wine in both high and low quality.","7937cd65":"**Train Report**","70939d1f":"**Getting rid of duplicate data**","97094fb9":"Before applying various classification techniques to predict the quality of the wine, let us split the dataset in train and test set.","9dbd2491":"**Interpretation:** \nFrom the above plot, I can see that our classifier (ADA Boost) is away from the dotted line; with the AUC score **0.7961**.","b1f711b7":"### 5.1.3 Re-checking Correlation<a id='rec_cor'><\/a>","5b8925a2":"**Test Report**","94835ea2":"**ROC Curve**","2d43ee60":"https:\/\/www.ijsr.net\/archive\/v9i7\/SR20718002904.pdf\n\nhttps:\/\/ijcat.com\/archieve\/volume8\/issue9\/ijcatr08091010.pdf\n\nhttps:\/\/broncoscholar.library.cpp.edu\/bitstream\/handle\/10211.3\/216015\/NelsonGregory_Thesis2020.pdf?sequence=3\n\nhttp:\/\/cs229.stanford.edu\/proj2015\/245_report.pdf\n\nhttps:\/\/scihub.se\/https:\/\/www.sciencedirect.com\/science\/article\/pii\/S1877050917328053","4465d4e1":"#### Score Card","e4f879d5":"Recheck of correlation after treating outliers. There has been a slight change with respect to the correlation between numeric values","61647058":"I have **7 columns with a few missing values** present in the dataset","61ba4670":"# 15. Displaying score summary<a id=\"dis_sco\"><\/a>","0f5c752d":"From the above table, I can infer:\n\n    1. There are two types of wine with white frequenting more\n    \n    2. There are seven unqiue records for the quality of wine with 6 being chosen the most","4be49d45":"From the above classification reports,I can infer that there is a difference when compared to test and train reports.\nHence I conclude that the model is bit overfitted.","f23f3749":"**Train Report**","7343af60":"## 4.2 Understanding the Dataset <a id='Data_Understanding'><\/a>","c7438cd2":"**Interpretation:** From the above output, I can see that the testing model is 75% accurate.","2ae2ae0b":"**Building an Adaboost model on a training dataset.**","bff4eeb8":"# 17. Conclusion<a id=\"conclu\"><\/a>","0a1d0dd0":"**Score Card**","ca6a67e2":"**Train Report**","96feaf70":"#### Score Card","d15f9561":"**Interpretation:** From the above output, I can see that the training model has 79% accuracy.","fcca4b37":"**Interpretation:** From the above classification reports,I can infer that there is a little difference when compared to test and train reports.\nHence I conclude that the model is bit overfitted.","df86017e":"# 12. Gradient Boosting<a id=\"gra_boo\"><\/a>","f25c2a7f":"**Tuning the Hyperparameters (GridSearchCV)**","f5981a1c":"**Finding  Optimal Value of K (using GridSearchCV)**","e28d9b73":"# Problem Statement \ud83c\udf77\ud83c\udf7e","9bcadc49":"# 19. References<a id=\"Refer\"><\/a>","a638a9eb":"# 18.Deployment<a id=\"deploy\"><\/a>","b200559f":"I decided the cut-off to be 0.5. i.e. if 'y_pred_prob1' is less than 0.5, then consider it to be 0 else consider it to be 1.","033e736e":"**Test Report**","ab86929a":"#### Building the model using the above obtained tuned hyperparameters.","917ce748":"**Visualizing outliers using Boxplots**","4a55e64c":"**ROC Curve**","7e0b3978":"# 7. Naive Bayes Algorithm<a id=\"nai_bay\"><\/a>","d97408f9":"**Confusion matrix**","062595c7":"# 16. Feature Importance<a id=\"fea_imp\"><\/a>","3e27003e":"**Interpretation:**  I can see that Decision tree classifier has the lowest difference between train accuracy and test                                   accuracy.Hence,I conclude Decision tree classifier is the `Best_Model`","0f996db8":"**ROC curve**","2f0183b2":"**Interpretation:** From the above output, I can see that the testing model is 72% accurate.","7105d89a":"**Interpretation:** From the above output, I can see that the testing model is 69% accurate.","c0582e62":"**Decision tree with tuned hyperparameters**","c442bab5":"# 4. Exploratory Data Analysis <a id='data_preparation'><\/a>","e545c6f2":"**Interpretation:** \nFrom the above plot, I can see that our classifier (Decision tree) is away from the dotted line; with the AUC score **0.7415**.","2caad881":"**Finding Hyperparameters using GridSearchCV (Decision Tree)**","3a3bfea4":"**Visualising missing values using Heatmap**","eca85cac":"**Test Report**","9d903b05":"**Interpretation:** The `Pseudo R-squ.` obtained from the above model summary is **0.2310**  \nThe LLR p-value is less than 0.05, implies that the model is significant.","28e968d0":"**Predicting the quality of wine with respect to different physiochemical parameters such as alcohol, acidity, density, pH, etc.\u00b6**","208c4298":"**Checking normality for numerical columns**","5062dca1":"**Tune the Hyperparameters (GridSearchCV)**","d4eccd91":"#### Function to plot the confusion matrix.","42cadfe1":"**Interpretation:** From the above output, I can see that the training model has 72% accuracy.","f62c8eec":"**Some Pre-defined functions**","6f604d85":"## 5.1 Outliers <a id='out'><\/a>","bf3d186c":"**ROC Curve**","23dd293e":"**Interpretation:** From the above output, I can see that the testing model is 74% accurate.","0cd8d638":"**Interpretation:** The red dotted line represents the ROC curve of a purely random classifier; a good classifier stays as far away from that line as possible (toward the top-left corner).<br>\nFrom the above plot, I can see that our classifier (logistic regression with features obtained from Backward elimination method) is away from the dotted line; with the AUC score **0.7957**","3385888b":"# 8. K Nearest Neighbors (KNN)<a id=\"knn\"><\/a>","216ea9cd":"Since the numeric features are not normal I are removing the outliers using IQR method","2058ad99":"**Tuning the Hyperparameters using GridSearchCV**","b9a508be":"**Inferences:**\n1. free_sufur_dioxide is highly positively correlated with total_sulfur_dioxide\n    \n2. density is moderatly positively correlated with fixed_acidity and residual_sugar whilst moderately negatively        correlated with alcohol\n    \n3. Relation degrees are very low with each other, such as citric_acid, free_sulfur_dioxide, sulpahtes and pH","42d96500":"### 4.2.2 Correlation <a id='correlation'><\/a>","5ef56adc":"**Visualising missing values using Heatmap**","93575106":"**ROC Curve**","471f7342":"#### Score Card","87e2770c":"#### Line plot to see the accuracy rate and  error rate for each value of K using euclidean distance as a metric of KNN model","c73309d7":"**Confusion Matrix**","336746be":"**Interpretation:** From the above output, I can see that the testing model is 76% accurate.","1a5fcef2":"**Predictions on the train set.**","9638a0c3":"**ROC Curve**","9524d2af":"Now, There are **No missing values** present in the dataset","835cbc6d":"**Interpretation:**\nFrom the above plot, I can see that our classifier (Gaussian NaiveBayes) is away from the dotted line; with the AUC score **0.7455**","0d29f9f1":"From the above boxplot, I can infer:\n\n     Wine with high alcohol content have gotten higher ratings than that of wine with low alcohol content.","7c573d64":"#### Building an Extreme Gradient boost model on a training dataset","be852d83":"**Identifying the Best Cut-off Value**","59d3c5fb":"To obtain the best significant features which are realated to target variable I perform backward elimination process below:","6cf1bf99":"In this dataset I have 6497 records across 13 features","459620af":"From the above KDE plot, I can infer:\n    1. The distribution for both, volatile_acidity and fixed_acidity for Low and High wine quality seem to be highly        positively skewed.\n    2. For fixed_acidity, values between 6-7.5 depict highest probability density irrespective of quality and there is not   much difference between the probability density for Low and High.\n    3. For volatile_acidity, values between 0-0.5 depict highest probabilty density irrespective of quality but the         probabiltity density for High quality wine is greater than that of Low quality.","f127d057":"<table align=\"center\" width=100%>\n    <tr>\n        <td width=\"35%\">\n            <img src=\"https:\/\/www.cnet.com\/a\/img\/TQz8Ib-VK2VLerOOig8ky841Fgs=\/940x0\/2019\/06\/27\/347b8f9c-65a4-448b-b641-73a2becfbf83\/vegan-wine-club.jpg\">\n        <\/td>\n        <td>\n            <div align=\"center\">\n                <font color=\"#7F0542 \";size=300px>\n                    <b>Wine Quality Prediction\n                    <\/b>\n                <\/font>\n            <\/div>\n        <\/td>\n    <\/tr>\n<\/table>","644bcd47":"#### Score Card","853a0567":"**Interpretation:** \nFrom the above plot, I can see that our classifier (random forest) is away from the dotted line; with the AUC score **0.7932**.","2daca4a7":"# 11. AdaBoost<a id=\"ada\"><\/a>","c864b0e7":"**Train Report**","631c9a6f":"# 5. Data Preprocessing <a id='data_pre'><\/a>","252f231f":"#### Function to plot the ROC curve.","502c25a7":"**Interpretation:** From the above output, I can see that the testing model is 71% accurate.","5ec1e048":"**Confusion matrix**","f443ea97":"Now,building a Logistic regression model obtained from the above elimination process","4dd8509a":"**Train report**","302521f8":"**Confusion Matrix**","d47def2e":"#### Building the model using the tuned hyperparameters obtained above.","0ffdd63a":"Since none of the numerical features are normally distributed (p-value<0.05) , I will perform Min-Max normalisation to scale the data","e9abf64c":"**Interpretation:** I can see that the optimal value of K (= 17) obtained from the GridSearchCV() results in a lowest error rate and highest accuracy rate. ","a30e2bb5":"**Confusion Matrix**","0de79b7b":"<table align=\"center\" width=100%>\n    <tr>\n        <td width=\"50%\">\n            <img src=\"https:\/\/media4.giphy.com\/media\/QMkPpxPDYY0fu\/200.gif\">\n        <\/td>\n        <td>\n            <div align=\"center\">\n                <font color=\"#1A040C \" size=24px>\n                    <b>Thank You.\n                    <\/b>\n                <\/font>\n            <\/div>\n        <\/td>\n    <\/tr>\n<\/table>","db764c45":"From the above pie chart, I can infer:\n\n     About 75% of the data is pertaining to white wine while the remaining is of red wine","7a86ba2c":"# 9. Decision Tree for Classification<a id=\"dec_tre\"><\/a>","5ef41e83":"After converting the datatype of **quality** our dataset contains **2 object columns, 1 int column and 11 float columns**","5a99f688":"**Interpretation:** From the above output, I can see that the training model has 76% accuracy.","8af45c6f":"**Test Report**","27720ad6":"**Interpretation:** From the above output, I can see that the training model has 80% accuracy.","9daab3e7":"## 5.2 Categorical Encoding<a id='cat_enc'><\/a>","d3adbc80":"**ROC curve**","f98342b8":"**Confusion Matrix**","3ca49f69":"**Test Report**","39f97605":"#### Score Card","09cfb343":"## Table of Contents\n\n1. **[Import Libraries](#import_lib)**\n2. **[Set Options](#set_options)**\n3. **[Read Data](#Read_Data)**\n4. **[Exploratory Data Analysis](#data_preparation)**\n    - 4.1 - [Preparing the Dataset](#Data_Preparing)\n        - 4.1.1 - [Data Dimension](#Data_Shape)\n        - 4.1.2 - [Data Types](#Data_Types)\n        - 4.1.3 - [Missing Values](#Missing_Values)\n        - 4.1.4 - [Duplicate Data](#duplicate)\n        - 4.1.5 - [Indexing](#indexing)\n        - 4.1.6 - [Final Dataset](#final_dataset)\n    - 4.2 - [Understanding the Dataset](#Data_Understanding)\n        - 4.2.1 - [Summary Statistics](#Summary_Statistics)\n        - 4.2.2 - [Correlation](#correlation)\n        - 4.2.3 - [Analyze Categorical Variables](#analyze_cat_var)\n        - 4.2.4 - [Anaylze Target Variable](#analyze_tar_var)\n        - 4.2.5 - [Analyze Relationship Between Target and Independent Variables](#analyze_tar_ind_var)\n        - 4.2.6 - [Feature Engineering](#feature_eng)\n5. **[Data Pre-Processing](#data_pre)**\n    - 5.1 - [Outliers](#out)\n        - 5.1.1 - [Discovery of Outliers](#dis_out)\n        - 5.1.2 - [Removal of Outliers](#rem_out)\n        - 5.1.3 - [Rechecking of Correlation](#rec_cor)\n    - 5.2 - [Categorical Encoding](#cat_enc)\n    - 5.3 - [Feature Scaling](#fea_sca)\n    - 5.2 - [Train-Test Split](#split)\n6. **[Logistic Regression](#log_reg)**\n7. **[Naive Bayes Algorithm](#nai_bay)**\n8. **[K Nearest Neighbors (KNN)](#knn)**\n9. **[Decision Tree for Classification](#dec_tre)**\n10. **[Random Forest](#ran_for)**\n11. **[AdaBoost](#ada)**\n12. **[Gradient Boosting](#gra_boo)**\n13. **[Extreme Gradient Boosting (XGB)](#xgb)**\n14. **[Stack Generalisation](#stack)**\n15. **[Displaying Score Summary](#dis_sco)**\n16. **[Feature Importance](#fea_imp)**\n17. **[Conclusion](#conclu)**\n18. **[Deployment](#deploy)**\n19. **[References](#Refer)**","3e986564":"**Train Report**","f68c9d60":"**Backward Elimination Model**","e9ef4a22":"# 10. Random Forest<a id=\"ran_for\"><\/a>","cb6bad89":"From the above classification reports,I can infer that there is a little difference when compared to test and train reports.\nHence I conclude that the model is bit overfitted.","ae4d771d":"### 4.2.6 Feature Engineering <a id='feature_eng'><\/a>","76aabd79":"#### Function for  predicting Cross Validation Score","0d6bf32c":"**Checking for duplicate data after removal of duplicates**","caee33ad":"# 2. Set Options <a id='set_options'><\/a>","cb5da1ed":"**Interpretation:** \n\nFrom the above plot, I can see that our classifier(Gradient Boosting model) is away from the dotted line; with the AUC score **0.8136**.","e7754bcc":"### 4.2.1 Summary Statistics <a id='Summary_Statistics'><\/a>","42da3e55":"**Checking the normality of numeric features**","16043532":"**The last 5 index values range from 6491-6496 but I have only 5329 records thus the indexes need to be reset**","a8fd390d":"There are **5329 records** after dropping duplicates","d8bdac51":"#### Building a knn model on a training dataset using the above best parameters.","6f46b349":"**Confusion matrix**","c319f51b":"**Train Report**","da510134":"#### Building a Gradient boost model on a training dataset","3288a555":"**ROC Curve**","08630ca8":"**Identifying outliers using IQR**","a8deaf31":"**Missing Values Replacement**","0b100475":"**Test report**","976b3bfe":"**Interpretation:** \nFrom the above plot, I can see that our classifier (knn_model with n_neighbors = 17) is away from the dotted line; with the AUC score **0.7933**.","58b7e6ee":"**ROC Curve**","f1a1f1f2":"The final dataset has **5329 records and 13 features with no missing and duplicate values**","ec775061":"### 4.1.1 Data Dimensions <a id='Data_Shape'><\/a>","5ce3a69a":"### 4.1.3 Missing Values <a id='Missing_Values'><\/a>","2bfc5565":"**Interpretation:** From the above output, I can see that the model  is 74% accurate.","18dc8dd2":"# 3. Read Data <a id='Read_Data'><\/a>","5490efda":"#### Function to update the score card","47b88902":"# 13 Extreme Gradient Boosting (XGB)<a id=\"xgb\"> <\/a>","102d0d75":"### 4.1.4 Duplicate Data <a id='duplicate'><\/a>","6d370a68":"**Interpretation:** \n\nFrom the above plot, I can see that our classifier(Extreme Gradient Boosting model) is away from the dotted line; with the AUC score **0.8129**.","3a4a2d67":"In this dataset I have **1 object, 11 float and 1 int columns**\nBut according to our metadata , the column **quality** should be off object datatype","4055a303":"### 4.1.6 Final Dataset <a id='final_dataset'><\/a>","1a77aff1":"#### Creating a generalized function to create a dataframe containing the scores for the models.","d8b6761e":"**Numeric Variables**","a24c6e6e":"### 4.1.2 Data Types <a id='Data_Types'><\/a>","cbf1fc45":"**Input variables (based on physicochemical tests):** \n\n**1 - fixed acidity** : Amount of Tartaric acid found\n\n**2 - volatile acidity** : Amount of Acetic acid found\n\n**3 - citric acid** : Amount of Citric acid found\n\n**4 - residual sugar** : Amount of sugar left post fermentation\n\n**5 - chlorides** : Amount of salts present in wine\n\n**6 - free sulfur dioxide** : Amount of Sulfur Dioxide present in free form\n\n**7 - total sulfur dioxide** : Amount of Sulfur Dioxide present in wine\n\n**8 - density** : Density of wine\n\n**9 - pH** : Indicate the pH value of wine ranging from 0 to 14\n\n**10 - sulphates** : Amount of Potassium Sulphate in wine\n\n**11 - alcohol** : Alcohol content in wine\n\n**Output variable (based on sensory data):**\n\n**12 - quality (score between 0 and 10)** : Indicates quality of wine ranging from 1 to 10 where, the higher the value the better the wine","f68c2ddf":"**Interpretation:** From the above output, I can see that the training model has 77% accuracy.","9c612ea1":"From the above KDE plot, I can infer:\n    1. The distribution for chlorides seems to be extremely highly positive skewed irrespective of the quality\n    2. The distribution for density when the quality is Low seems to be negatively skewed whilst when the quality is High   the distribution seems to be positively skewed\n    3. For chlorides, values between 0-0.1 depict highest probability density irrespective of quality and there is a lot  of difference between the probability density for Low and High.\n    4. For density, values between 0.99-1 depict highest probabilty density irrespective of the quality","a337681c":"**Interpretation:** The above dataframe shows that,all the highest scores of different perfomance metrics.\nThe optimal probability cut-off score which is considered for futher analysis is taken by considering the **Accuracy Score**.","22c97dbd":"### 5.1.1 Discovery of Outliers<a id='dis_out'><\/a>","0ae68b96":"From the above KDE plot, I can infer:\n    1. The distribution for pH seems to be normally distributed for both quality types\n    2. The distribution for sulphates seems to be highly positively skewed for both quality types\n    3. For pH, values between 3-3.5 depict highest probability density for both quality types\n    4. For sulphates, values around 0.5 depict highest probabilty density irrespective of the quality","20cdb0ee":"# 14. Stack Generalization<a id=\"stack\"><\/a>"}}