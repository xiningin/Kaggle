{"cell_type":{"afa4329e":"code","fdcea127":"code","efad8885":"code","f8493098":"code","cb1a5c94":"code","b5457253":"code","1f5e23f8":"code","2fcf549c":"code","c2617095":"code","901eb465":"code","045400ed":"code","f17de933":"code","bbba0962":"code","f57ea687":"code","b7de28c2":"code","06ff34e1":"code","4cdf8e9b":"code","c007f6df":"code","d9d78ee9":"code","748fd28e":"code","29046853":"code","6e6c02cb":"code","640ec944":"code","191d8fcd":"code","8337a9ea":"code","7d102cc0":"code","992c78a0":"code","253ba7e1":"code","0ac04168":"code","a5124940":"code","dbd2636a":"code","0bb47b80":"code","2181f5fe":"code","caff15d9":"code","abec1ed7":"code","4e6493e5":"code","749e3124":"code","498c515a":"code","7d6cff65":"code","4ecf9244":"code","76ad66d4":"code","ff6ef2d8":"code","be188baf":"code","9eea63ee":"markdown","0015fb04":"markdown","013fbf5d":"markdown","6532c1d8":"markdown","f8bb27d3":"markdown","cec681cd":"markdown","62aa1d91":"markdown","e501b5e9":"markdown","663b1e98":"markdown","fead28ac":"markdown","a6128280":"markdown","383f0b66":"markdown","d5970a61":"markdown","b3bcb07f":"markdown","7542440d":"markdown","5f088e18":"markdown","4926c404":"markdown","7c85bce8":"markdown","fa79db0b":"markdown","aa4253c8":"markdown","a6d5bf3f":"markdown","bc363dc6":"markdown","013ac994":"markdown","ad4dba0c":"markdown","6a925797":"markdown","fe024830":"markdown","1ab1335b":"markdown","cbbfc0de":"markdown","148b09ae":"markdown","13615bba":"markdown","fc43e15c":"markdown","8ce7c8f8":"markdown","a7a2066a":"markdown","78a89f99":"markdown","5c590d78":"markdown","8b8fa25c":"markdown","6e43ed71":"markdown","cc159d42":"markdown","1c84cdf6":"markdown","b0b2d7c1":"markdown","9cee010f":"markdown","9f437b38":"markdown","5288f3d0":"markdown","aee71677":"markdown","eb81efff":"markdown","dad1d81e":"markdown","14888329":"markdown","ad82abc8":"markdown","f9af536d":"markdown","9d4b109c":"markdown","06c70582":"markdown","41a2d136":"markdown","b99b4476":"markdown","99ad192d":"markdown","8a9635b5":"markdown","8020b501":"markdown","4940142a":"markdown"},"source":{"afa4329e":"# reset environment for reproducibility\n%reset -f","fdcea127":"import os\nimport math\nimport time\nimport glob\nimport warnings\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport itertools\nfrom PIL import Image\n\nimport tensorflow as tf\nfrom tensorflow.keras import applications, backend, callbacks, layers\nfrom tensorflow.keras import models, metrics, optimizers, preprocessing\nfrom tensorflow.keras import regularizers, utils\n\nfrom sklearn.utils import class_weight\nfrom sklearn.metrics import confusion_matrix","efad8885":"# Seed randomness for reproducibility\nSEED = 42\ntf.random.set_seed(SEED)\nrs = np.random.RandomState(np.random.MT19937(np.random.SeedSequence(SEED)))\n\n# Suppress warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Hyperparameters\nEPOCHS = 25\nPATIENCE = 4\nBATCH_SIZE = 50\nVALIDATION_FRAC = 0.30\nINIT_LEARN_RATE = 0.01\nFREEZE_LAYERS_FRAC = 0.94\n\n# Inputs \nCOLOR_MODE = 'grayscale'\nINTERPOLATION = 'hamming'\n\nTRAIN_DOWNSAMPLE_FRAC = 1.00\n\nSCALE_DIM = 2 # Tested 1-7\nXCEPT_DIM = 299\nIMAGE_SIZE = (SCALE_DIM * XCEPT_DIM,\n              SCALE_DIM * XCEPT_DIM)\nIMAGE_SHAPE = IMAGE_SIZE + (1,)\n\n# Model weights persistence\nWEIGHTS_FILE = 'weights_{}_{}_{}_{}.h5'.format(\n    IMAGE_SIZE[0], IMAGE_SIZE[1],\n    int(FREEZE_LAYERS_FRAC * 100),\n    int(TRAIN_DOWNSAMPLE_FRAC * 100))\n\n# Classes\nCLASS_H = 'Healthy'\nCLASS_VPNA = 'Viral PNA'\nCLASS_BPNA = 'Bacterial PNA'\n\n# Stages\nSTAGE_TRAIN = 'train'\nSTAGE_VAL = 'val'\nSTAGE_TEST = 'test'\n\n# Pathing\nDATA_PATH = '\/kaggle\/input\/chest-xray-pneumonia'\n\n# Logging\nVERBOSE = 0","f8493098":"glob.glob(os.path.join(DATA_PATH, 'chest_xray', '*', ''))","cb1a5c94":"glob.glob(os.path.join(DATA_PATH, 'chest_xray', \n                       STAGE_TRAIN, '*', ''))","b5457253":"glob.glob(os.path.join(DATA_PATH, 'chest_xray', \n                       STAGE_TRAIN, 'NORMAL', '*'))[:10]","1f5e23f8":"glob.glob(os.path.join(DATA_PATH, 'chest_xray', \n                       STAGE_TRAIN, 'PNEUMONIA', '*'))[:10]","2fcf549c":"def gather_files_into_dataframe(path):\n  \n  frames = []\n\n  for stage in (STAGE_TRAIN, STAGE_VAL, STAGE_TEST):\n    \n    for target in ('PNEUMONIA', 'NORMAL'):\n\n      # Gather and sort file names\n      filenames = pd.Series(glob.glob(os.path.join(\n          path, 'chest_xray', stage, target, '*.jpeg')))\n      filenames.sort_values(inplace=True)\n\n      # Gather image dimensions\n      widths, heights = zip(*[Image.open(filename).size\n                              for filename in filenames])\n      \n      frames.append(pd.DataFrame({'filename': filenames,\n                                  'width': widths,\n                                  'height': heights,\n                                  'stage': stage,\n                                  'class': target}))\n\n  return pd.concat(frames, ignore_index=True)","c2617095":"df = gather_files_into_dataframe(DATA_PATH)","901eb465":"df.sample(n=10, random_state=rs)","045400ed":"df.plot(x='width', y='height', kind='scatter',\n        title='Image Sizes');","f17de933":"df.loc[:, ['width', 'height']].mean()","bbba0962":"df.loc[:, ['width', 'height']].median()","f57ea687":"df.groupby(['stage', 'class']).size().unstack().plot(\n    kind='bar', title='Class Frequency By Stage');","b7de28c2":"df.loc[df['class'] == 'NORMAL', 'class'] = CLASS_H\n\ndf.loc[(df['class'] == 'PNEUMONIA') \n  & (df['filename'].str.contains('_virus_')), 'class'] = CLASS_VPNA\n  \ndf.loc[(df['class'] == 'PNEUMONIA') \n  & (df['filename'].str.contains('_bacteria_')), 'class'] = CLASS_BPNA","06ff34e1":"df.groupby(['stage', 'class']).size().unstack().plot(\n    kind='bar', title='Class Frequency By Stage');","4cdf8e9b":"df.loc[df['stage'] == STAGE_VAL, 'stage'] = STAGE_TRAIN","c007f6df":"def get_samp_ndx(df, stage, target, frac, random_state):\n  return df[(df['stage'] == stage) \n    & (df['class'] == target)].sample(frac=frac, \n                                      random_state=rs).index","d9d78ee9":"df.loc[get_samp_ndx(df, STAGE_TRAIN, CLASS_H, VALIDATION_FRAC, rs), \n       'stage'] = STAGE_VAL\n\ndf.loc[get_samp_ndx(df, STAGE_TRAIN, CLASS_VPNA, VALIDATION_FRAC, rs), \n       'stage'] = STAGE_VAL\n\ndf.loc[get_samp_ndx(df, STAGE_TRAIN, CLASS_BPNA, VALIDATION_FRAC, rs), \n       'stage'] = STAGE_VAL","748fd28e":"df.groupby(['stage', 'class']).size().unstack().plot(\n    kind='bar', title='Class Frequency By Stage');","29046853":"def plot_image_grid(files, title, \n                    color_mode=COLOR_MODE,\n                    interpolation=INTERPOLATION):\n\n  square = math.ceil(math.sqrt(len(files)))\n\n  fig, axes = plt.subplots(nrows=square,\n                           ncols=square, \n                           figsize=(10, 10))\n  \n  fig.suptitle(title, fontsize='xx-large')\n  axes = axes.flatten()\n\n  for (title, filename), ax in zip(files, axes):\n    ax.set_title(f'{title}', fontsize='x-large')\n    ax.imshow(preprocessing.image.load_img(filename, \n                                           color_mode=color_mode),\n              interpolation=interpolation)\n\n  for ax in axes:\n    ax.axis('off')\n\n  plt.tight_layout(pad=4)\n  plt.show()","6e6c02cb":"def get_sample_files(df, stage, target, n, random_state):\n  return list(df.loc[(df['stage'] == stage) & (df['class'] == target),\n                     ['class', 'filename']].sample(n=n, \n                                                   random_state=random_state)\n                     .itertuples(name=None, index=False))","640ec944":"plot_image_grid(get_sample_files(df, STAGE_TRAIN, CLASS_VPNA, 3, rs) + \n                get_sample_files(df, STAGE_TRAIN, CLASS_H, 3, rs) + \n                get_sample_files(df, STAGE_TRAIN, CLASS_BPNA, 3, rs),\n                'Pneumonia (PNA) Detection X-Rays'\n                ' - 3 Sets Of Random Training Samples')","191d8fcd":"def get_dataframe_sample(df, stage, frac=1.0, random_state=None):\n  return df[df['stage'] == stage].sample(frac=frac, \n                                         random_state=random_state)","8337a9ea":"preproc_gen = preprocessing.image.ImageDataGenerator(\n    preprocessing_function=applications.xception.preprocess_input)\n\nflow_params = dict(\n    batch_size=BATCH_SIZE,\n    class_mode='sparse',\n    target_size=IMAGE_SIZE,\n    color_mode=COLOR_MODE,\n    interpolation=INTERPOLATION,\n    validate_filenames=False,\n    seed=SEED)\n\n# Construct iterators using DataFrame\n\ntrain_iterator = preproc_gen.flow_from_dataframe(\n    get_dataframe_sample(df, STAGE_TRAIN, TRAIN_DOWNSAMPLE_FRAC, rs),\n    **flow_params)\n\nvalidation_iterator = preproc_gen.flow_from_dataframe(\n    get_dataframe_sample(df, STAGE_VAL, TRAIN_DOWNSAMPLE_FRAC, rs),\n    **flow_params)\n\ntest_iterator = preproc_gen.flow_from_dataframe(\n    df[df['stage'] == STAGE_TEST], shuffle=False,\n    **flow_params)","7d102cc0":"# Show pie chart if using partial training data\nif TRAIN_DOWNSAMPLE_FRAC < 1.0:\n  plt.pie([TRAIN_DOWNSAMPLE_FRAC, 1-TRAIN_DOWNSAMPLE_FRAC],\n          labels=[f'Down-sampled Data Employed {TRAIN_DOWNSAMPLE_FRAC:.0%}', \n                   'Down-sampled Data Available'])","992c78a0":"def construct_model():\n\n  # Input layer to functional API model\n  x = input = layers.Input(shape=IMAGE_SHAPE)\n\n  # Conv2D for grayscale to (x, y, 3)\n  x = layers.Conv2D(3, SCALE_DIM,\n                    padding='same',\n                    kernel_regularizer='L2',\n                    activation='relu')(x)\n\n  # Pooling reduction layer, if needed\n  if SCALE_DIM > 1:\n    x = layers.MaxPooling2D(SCALE_DIM)(x)\n\n  # Xception base model\n  Xception = applications.Xception(\n      weights='imagenet',\n      include_top=False,\n      input_shape=(XCEPT_DIM, XCEPT_DIM, 3))\n  \n  # Freeze the first % layers\n  freeze = round(FREEZE_LAYERS_FRAC * len(Xception.layers))\n  for i, layer in enumerate(Xception.layers, start=1):\n    layer.trainable = i > freeze\n\n  # Debug\n  if VERBOSE:\n    trainable_flags = [layer.trainable for layer in Xception.layers]\n    print(trainable_flags)\n    print(sum(trainable_flags)\/len(Xception.layers))\n\n  x = Xception(x)\n\n  # Pool results from Xception\n  x = layers.GlobalMaxPool2D()(x)\n\n  # Inference layer\n  x = output = layers.Dense(3, activation='softmax')(x)\n\n  # Connect functional API model\n  model = models.Model(input, output)\n\n  return model","253ba7e1":"weights_loaded = False\n\nmodel = construct_model()\n\nif os.path.exists(WEIGHTS_FILE):\n  weights_loaded = True  \n  model.load_weights(WEIGHTS_FILE)\n  print(f'Model initialized with weights: {WEIGHTS_FILE}')\nelse:\n  print(f'Model partially initialized with imagenet.')\n\nutils.plot_model(model, show_shapes=True, show_dtype=True)","0ac04168":"model.summary()","a5124940":"def compile_model(model, metrics):\n\n  optimizer = optimizers.RMSprop(learning_rate=INIT_LEARN_RATE)\n\n  model.compile(optimizer=optimizer,\n                loss='sparse_categorical_crossentropy',\n                metrics=metrics) ","dbd2636a":"def fit_model(model, train_iterator, validation_iterator):\n  \n  # Learning rate scheduling\n  def lr_scheduler(epoch, lr):\n    DROP = 0.94\n    EPOCHS_DROP = 2\n    rate = INIT_LEARN_RATE * math.pow(DROP, math.floor((1+epoch)\/EPOCHS_DROP))\n    return rate\n\n  schedule_lr = callbacks.LearningRateScheduler(lr_scheduler)\n\n  # Early stopping\n  stop_early = callbacks.EarlyStopping(patience=PATIENCE,\n                                       monitor='val_accuracy',\n                                       restore_best_weights=True)\n  \n  # Address class imbalance with loss weightings\n  weights = class_weight.compute_class_weight(\n      'balanced',\n      list(train_iterator.class_indices.values()),\n      train_iterator.classes)\n  \n  weight_dict = {i: weights[i] \n                 for i in train_iterator.class_indices.values()}\n\n  if VERBOSE:\n    print('Loss weights:', weight_dict)\n  \n  return model.fit(train_iterator,\n                   validation_data=validation_iterator,\n                   class_weight=weight_dict,\n                   callbacks=[schedule_lr, stop_early],\n                   epochs=EPOCHS,                   \n                   verbose=VERBOSE)","0bb47b80":"compile_model(model, ['accuracy', metrics.TopKCategoricalAccuracy(2)])\n\nif not weights_loaded:\n  backend.clear_session()\n  history = fit_model(model, \n                      train_iterator, \n                      validation_iterator)\n  model.save_weights(WEIGHTS_FILE)\n  print(f'Model weights saved: {WEIGHTS_FILE}')  \nelse:\n  print('Nothing to do.')","2181f5fe":"loss, acc, top2acc = model.evaluate(test_iterator, verbose=VERBOSE)\nprint(f'Test Loss: {loss:.4}')\nprint(f'Test ACC: {acc:.2%}')\nprint(f'Test Top 2 ACC: {top2acc:.2%}')","caff15d9":"def plot_evaluation(loss, acc, history, plot_title):\n\n  # History DataFrame\n  hist_df = pd.DataFrame(history.history)\n  hist_df.insert(0, 'Epoch',\n                 np.arange(1, len(hist_df)+1))\n  hist_df.rename(inplace=True,\n                 columns={\n                     'loss': 'Training Loss',\n                     'val_loss': 'Validation Loss',\n                     'accuracy': 'Training ACC', \n                     'val_accuracy': 'Validation ACC',\n                     'top_k_categorical_accuracy': 'Top 2 Training ACC',\n                     'val_top_k_categorical_accuracy': 'Top 2 Validation ACC',\n                     'lr': 'Learning Rate'\n                     }\n                 )\n\n  # Plots\n  fig, axes = plt.subplots(nrows=1, ncols=2,\n                           figsize=(10, 5))\n  fig.suptitle(plot_title)\n  hist_df.plot(ax=axes[0],\n              title='Validation & Training Loss',\n              x='Epoch', y=['Validation Loss', 'Training Loss'])\n  hist_df.plot(ax=axes[1],\n              title='Validation & Training Accuracy',\n              x='Epoch', y=['Validation ACC', 'Training ACC',\n                            'Top 2 Validation ACC'])\n\n  # Plot evaluation\n  plt.figtext(0.5, -0.1, \n              f'Test Loss={loss:.4} -- Test Accuracy={acc:.2%}',\n              size='x-large', horizontalalignment='center')\n\n  plt.show()\n\n  return hist_df","abec1ed7":"if not weights_loaded:\n  hist_df = plot_evaluation(loss, acc, history,\n                            'X-Ray PNA Classification'\n                            ' With Xception Architecture')","4e6493e5":"hist_df[:-PATIENCE] if not weights_loaded else None","749e3124":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion Matrix',\n                          cmap=plt.cm.Blues):\n  \"\"\"\n  This function prints and plots the confusion matrix.\n  Normalization can be applied by setting `normalize=True`.\n  \"\"\"\n  if normalize:\n      cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n      # print(\"Normalized confusion matrix\")\n  # else:\n      # print('Confusion matrix, without normalization')\n\n  # print(cm)\n\n  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n  plt.title(title)\n  plt.colorbar()\n  tick_marks = np.arange(len(classes))\n  plt.xticks(tick_marks, classes, rotation=45)\n  plt.yticks(tick_marks, classes)\n\n  thresh = cm.max() \/ 2.\n  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n      plt.text(j, i, f'{cm[i, j]:.3}' if normalize else cm[i, j],\n               horizontalalignment=\"center\",\n               color=\"white\" if cm[i, j] > thresh else \"black\")\n\n  plt.tight_layout()\n  plt.ylabel('True Label')\n  plt.xlabel('Predicted Label')\n  plt.show()","498c515a":"preds = model.predict(test_iterator)","7d6cff65":"cm = confusion_matrix(test_iterator.classes, preds.argmax(axis=1))\nplot_confusion_matrix(cm, test_iterator.class_indices.keys(),\n                      cmap=plt.cm.Greens,\n                      normalize=False)","4ecf9244":"def get_error_files(preds, test_iterator):\n  lookup = {v: k for k, v in test_iterator.class_indices.items()}\n  pred_classes = preds.argmax(axis=1)\n  errors, = np.where(pred_classes != test_iterator.classes)\n  return [(f'{lookup[test_iterator.classes[i]]}'\n            '\\n'\n           f'Predicted {lookup[pred_classes[i]]}'\n           f' {preds[i][pred_classes[i]]:.2%}',\n           test_iterator.filenames[i]) for i in errors]","76ad66d4":"plot_image_grid(get_error_files(preds, test_iterator)[-9:],\n                'Pneumonia (PNA) Detection X-Rays - Mispredictions')","ff6ef2d8":"def plot_test_image_sizes(test_set, preds, test_iterator):\n  \n  fig, axes = plt.subplots(nrows=1, ncols=2,\n                           figsize=(10, 5))\n  \n  fig.suptitle('Test Image Sizes')\n\n  test_set[preds.argmax(axis=1) != test_iterator.classes].plot(\n      ax=axes[0],\n      x='width', y='height', kind='scatter',\n      title='Mispredicted')\n  \n  test_set[preds.argmax(axis=1) == test_iterator.classes].plot(\n      ax=axes[1],\n      x='width', y='height', kind='scatter',\n      title='Accurately Predicted')\n  \n  plt.show()","be188baf":"plot_test_image_sizes(df[df['stage'] == STAGE_TEST], preds, test_iterator)","9eea63ee":"# Data","0015fb04":"Here the accuracy and loss, a confusion matrix, sample mispredicted images, and a plot of mispredicted image sizes are presented with analysis. In the confusion matrix it can be seen that bacterial pneumonia is accurately classified in most cases. Viral pneumonia can be frequently recognized, but is also confused with bacterial pneumonia. Healthy samples are more difficult to distinguish and the misclassifications appear to distribute often in a balance among the two pneumonia classes. The more diffuse nature of viral pneumonia appears to cause x-ray appearance to more closely resemble healthy samples. Healthy samples range from mostly clear to having some resemblance to either class. These two observations may underlie certain cases of confusion encountered. In the displayed mispredicted images, a prevalence may be seen of viral cases mispredicted as bacterial or healthy cases mispredicted as either class. Bacterial mispredictions are less likely so may not appear in the random selection.","013fbf5d":"Here the DataFrame constructed above is sampled to illustrate the data structure used during the rest of this notebook.","6532c1d8":"## Summary Of Model","f8bb27d3":"Reviewing the model summary below, it can be seen that unfreezing a small section of trailing layers increases trainable parameters significantly.","cec681cd":"Visualize any down-sampling with a plot.","62aa1d91":"From a review of the class folder structure in the training stage, folders subdivide pneumonia and normal image samples.","e501b5e9":"Each class of data can now be sampled individually from the training set to create a representative validation set.","663b1e98":"## View Accuracy And Loss","fead28ac":"In this notebook, a set of chest x-ray samples representing individuals both healthy and with pneumonia will be used to train a convolutional neural network (convnet) to classify this disease. Many experiments with this data classify between binary healthy and pneumonia classes, but in the approach here pneumonia will be subdivided into viral and bacterial subcategories. The additional division creates more ambiguity in the data adding difficulty to this classification problem.","a6128280":"The predicted classes are shown here in a confusion matrix. As discussed in the analysis, the pneumonia targets exhibit confusion mostly between their classes. Healthy targets exhibit a more even confusion distribution.","383f0b66":"## Explore DataFrame","d5970a61":"* Chollet, F. (2018). *Deep learning with Python*. Manning Publications Co.\n* Elgendy, M. (2020). *Deep learning for vision systems*. Manning Publications Co.\n* Jain, R., Gupta, M., Taneja, S., & Hemanth, D. J. (2021). Deep learning based detection and analysis of COVID-19 on chest X-ray images. *Applied Intelligence, 51*(3), 1690\u20131700. https:\/\/doi.org\/10.1007\/s10489-020-01902-1\n* Xie, Y., & Richmond, D. (2019). Pre-training on grayscale ImageNet improves medical image classification. In L. Leal-Taix\u00e9 & S. Roth (Eds.), Computer Vision \u2013 ECCV 2018 Workshops (Vol. 11134, pp. 476\u2013484). Springer International Publishing. https:\/\/doi.org\/10.1007\/978-3-030-11024-6_37\n\n","b3bcb07f":"The organization of the file data will be explored to familiarize with this  data set.","7542440d":"# Results","5f088e18":"# Summary Of Methods","4926c404":"# References","7c85bce8":"The ```plot_confusion_matrix()``` function here is derived from source at [scikit-learn](https:\/\/scikit-learn.org\/0.18\/auto_examples\/model_selection\/plot_confusion_matrix.html).","fa79db0b":"## View Confusion Matrix","aa4253c8":"The pneumonia class of data is now separated based on each file name's indication of content. The normal class is also relabeled.","a6d5bf3f":"## Description Of Data","bc363dc6":"After the above adjustments, the plot below illustrates the subdivided pneumonia classes and newly drawn validation set.","013ac994":"Construct a model based upon Xception given Jain et al. (2021) experienced highest performance with this architecture when applied to x-ray data. This model base will be applied to grayscale images so the required 3 channels are created from an input convolution layer. According to Xie and Richmond (2019), initialization with ImageNet is an expedient starting point for medical image classification and adapts to grayscale input. As suggested by Elgendy (2020), a portion of trailing layers are unfrozen for tuning. Very few layers are unfrozen because available training parameters increase rapidly as layers are made trainable.","ad4dba0c":"## Construct DataFrame","6a925797":"## View Mispredicted Sizes","fe024830":"## Analysis Of Results","1ab1335b":"Plotting frequencies by stage and class, it can be seen that the training data is imbalanced and the the validation set contains few samples.","cbbfc0de":"## View Data Organization","148b09ae":"## Construct Model","13615bba":"Here are the sizes of mispredicted images to visualize trends in accuracy relative to image size.","fc43e15c":"The data include 5,856 grayscale jpeg images pre-divided into folders for training, validation, and testing stages. Each folder is further subdivided into folders for normal and pneumonia x-ray images. Within the sample filenames are indications of whether a pneumonia sample represents a viral or bacterial case. The image dimensions range from hundreds of pixels to several thousand pixels. In the provided data organization, the validation set is small and contains no viral pneumonia samples. There also is a notable class imbalance within the training set favoring pneumonia. In the x-ray visualizations presented, healthy and pneumonia classes are juxtaposed for comparison. There are subtle characteristics which indicate which of the two pneumonia causes are present. Visually, healthy cases can appear to overlap with both classes of pneumonia.","8ce7c8f8":"The experimental model used for x-ray classification uses the Xception architecture with minor modifications. Xception is introduced without top layers and initialized with provided ImageNet trained weights. The source data is grayscale but since Xception initialized with ImageNet weights requires 3 channels, a single convolution layer with regularization is applied to create the input features. The default shape for Xception (299, 299, 3) is used so inputs have been calibrated to be a scalar multiple of these exact dimensions. This scaling factor and a max pooling layer are used to reduce input into this shape. The final layers of the Xception model are unfrozen to allow for fine-tuning. Very few layers are unfrozen as additional layers increase training parameters dramatically. Lastly, global max pooling and a 3 unit inference layer are appended to the model to create outputs.","a7a2066a":"## Compile And Fit Model","78a89f99":"## View Mispredicted Images","5c590d78":"Given there is limited validation data, available data will be pooled into the training set for resampling.","8b8fa25c":"If a weights file matching configured dimensions is available, load precomputed weights into the newly constructed model. Provide a visualization of model layers.","6e43ed71":"# Prepare Environment","cc159d42":"As seen in the plot below, splitting the pneumonia data into viral and bacterial classes reduces the class imbalance, but samples of bacterial pneumonia are still far more prevalent in the training data.","1c84cdf6":"Here are test set results from the best epoch according to validation accuracy. The top 2 accuracy results are presented for comparison.","b0b2d7c1":"The RMSProp optimizer is used which was employed by Xie and Richmond (2019) in fine-tuning ImageNet models on grayscale medical data.","9cee010f":"To efficiently manage input data, the files are organized into a Pandas DataFrame recording the originally specified class (normal, pneumonia), stage (train, validate, test), and x-ray image size. As will be shown, there is a class imbalance in the testing data and a sparsity of validation data. To remedy the sparsity of validation data using the DataFrame, the sparse validation data are pooled into the training set and a new larger validation set is drawn from this pool using stratified sampling. The sample sets for training, validation, and testing will all be flowed from the DataFrame. The class imbalance will be addressed with loss weightings during model fitting. Images are resized to a scalar multiple of the default Xception image shape of (299, 299, 3). A scaling factor of 2 has been found to have good predictive power and training efficiency while factors as high as 7 produced no consistent improvement in overall accuracy. Lastly, variations of the image interpolation method have been attempted for the required image size standardization. Hamming interpolation produces good visual quality and appears to improve accuracy slightly when compared against Nearest-neighbor, Bicubic, and Bilinear interpolation in selective trials. For benchmarking the scaling factors, Hamming interpolation was kept constant.","9f437b38":"# Model","5288f3d0":"## Construct Generators","aee71677":"Plotting the sizes gathered in the DataFrame illustrates image size distribution.","eb81efff":"To fit the model, a learning rate scheduler with code adapted from Elgendy (2020, p. 229) is used to incrementally decrease learning rate. The learning rate decay is adapted from Xie and Richmond (2019) to more quickly decrease the rate given this model trains quickly. Loss weightings are included to address the class imbalance in training data.","dad1d81e":"From a review of the root data folder structure, there are folders for the train, validation, and test stages.","14888329":"From a review of pneumonia class files in the training stage, jpeg files with person ids and bacteria \/ virus naming conventions appear to indicate type of pneumonia.","ad82abc8":"## View Sample Images","f9af536d":"Here are the mean and median image sizes.","9d4b109c":"Samples of each class are randomly chosen from the training stage to illustrate the relative differences in conditions apparent in x-rays. Healthy patient x-rays span through the center of the matrix to contrast with the pneumonia classes above and below.","06c70582":"Here are the results of training epochs in tabular form. Results after the optimal epoch are truncated leaving the last line to represent the epoch weights used in test evaluation.","41a2d136":"From a review of normal class files in the training stage, jpeg files with varying naming conventions are used.","b99b4476":"Having reviewed the file system structures above, all files are collected into a DataFrame for further exploration.","99ad192d":"To construct selections of the train, validation, and testing stages, iterators are created over slices from the DataFrame. If down-sampling is being used, samples are taken randomly. The testing set is not shuffled to allow predictions to be analyzed.","8a9635b5":"# Overview","8020b501":"Here are the results of training epochs graphically.","4940142a":"Here are the mispredicted samples titled with correct class first followed by the mispredicted class and predicted probability. The last 9 mispredictions are arbitrarily selected."}}