{"cell_type":{"4d819860":"code","6ac99ff0":"code","571badf3":"code","f0b7ba0d":"code","a59a784e":"code","21b9e3d3":"code","1de6c363":"code","ad118242":"code","bd980faf":"code","dcee296d":"code","0d3683d6":"code","3d18a1e0":"code","9d29027e":"code","59e3bb43":"code","0a4aa995":"code","5b405e22":"code","e8cc9fa0":"code","6e0a097e":"code","8b55dd96":"code","824f418c":"code","ee0bc0b2":"code","816637dc":"code","65773cec":"code","249716c8":"code","8e6ec188":"code","f06f24d9":"code","8a19751b":"code","54464a56":"code","ba0d1fc0":"code","1e0d8d46":"code","a1669b6c":"code","906af3ee":"code","48259483":"code","3c21f4d5":"code","3d534012":"code","bfdb8829":"code","9efc7bc7":"code","ac5a95d6":"code","5fa13445":"code","a80b19a0":"code","29a9a1e4":"code","cdbb4fa7":"code","cb13f37e":"code","efd73a83":"code","0fdd1781":"code","ffcb7e34":"code","619a460e":"code","5bf304f3":"code","756ead11":"code","743b2d46":"code","bdecb99a":"code","319f6002":"code","ff5ba073":"code","accb483b":"code","66405998":"code","e8b67da5":"code","b5fdda24":"code","77f24707":"code","34957f1e":"code","745d1f95":"code","87fa6ba1":"code","60ba3629":"markdown"},"source":{"4d819860":"import numpy as np\nimport pandas as pd\nimport math\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n%matplotlib inline \nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nimport plotly.express as px\n\n","6ac99ff0":"data =pd.read_csv('..\/input\/health-care-diabetes-dataset\/health care diabetes.csv') #load first dataset\n","571badf3":"data.head()","f0b7ba0d":"data.isnull().any()","a59a784e":"data.info()","21b9e3d3":"Positive = data[data['Outcome']==1]\nPositive.head(5)","1de6c363":"data['Glucose'].value_counts().head(7)","ad118242":"plt.hist(data['Glucose'])","bd980faf":"data['BloodPressure'].value_counts().head(7)","dcee296d":"plt.hist(data['BloodPressure'])","0d3683d6":"data['SkinThickness'].value_counts().head(7)","3d18a1e0":"plt.hist(data['SkinThickness'])","9d29027e":"data['Insulin'].value_counts().head(7)","59e3bb43":"plt.hist(data['Insulin'])","0a4aa995":"data['BMI'].value_counts().head(7)","5b405e22":"plt.hist(data['BMI'])","e8cc9fa0":"data.describe().transpose()","6e0a097e":"plt.hist(Positive['BMI'],histtype='stepfilled',bins=20)","8b55dd96":"Positive['BMI'].value_counts().head(7)","824f418c":"plt.hist(Positive['Glucose'],histtype='stepfilled',bins=20)","ee0bc0b2":"Positive['Glucose'].value_counts().head(7)","816637dc":"plt.hist(Positive['BloodPressure'],histtype='stepfilled',bins=20)","65773cec":"Positive['BloodPressure'].value_counts().head(7)","249716c8":"plt.hist(Positive['SkinThickness'],histtype='stepfilled',bins=20)","8e6ec188":"Positive['SkinThickness'].value_counts().head(7)","f06f24d9":"plt.hist(Positive['Insulin'],histtype='stepfilled',bins=20)","8a19751b":"Positive['Insulin'].value_counts().head(7)","54464a56":"#Scatter plot","ba0d1fc0":"BloodPressure = Positive['BloodPressure']\nGlucose = Positive['Glucose']\nSkinThickness = Positive['SkinThickness']\nInsulin = Positive['Insulin']\nBMI = Positive['BMI']","1e0d8d46":"plt.scatter(BloodPressure, Glucose, color=['b'])\nplt.xlabel('BloodPressure')\nplt.ylabel('Glucose')\nplt.title('BloodPressure & Glucose')\nplt.show()","a1669b6c":"import seaborn as sns\ng =sns.scatterplot(x= \"Glucose\" ,y= \"BloodPressure\",\n              hue=\"Outcome\",\n              data=data);","906af3ee":"B =sns.scatterplot(x= \"BMI\" ,y= \"Insulin\",\n              hue=\"Outcome\",\n              data=data);","48259483":"S =sns.scatterplot(x= \"SkinThickness\" ,y= \"Insulin\",\n              hue=\"Outcome\",\n              data=data);","3c21f4d5":"### correlation matrix\ndata.corr()","3d534012":"### create correlation heat map\nsns.heatmap(data.corr())","bfdb8829":"plt.subplots(figsize=(8,8))\nsns.heatmap(data.corr(),annot=True,cmap='viridis')  ### gives correlation value","9efc7bc7":"plt.subplots(figsize=(8,8))\nsns.heatmap(data.corr(),annot=True)  ### gives correlation value","ac5a95d6":"# Logistic Regreation and model building","5fa13445":"data.head(5)","a80b19a0":"features = data.iloc[:,[0,1,2,3,4,5,6,7]].values\nlabel = data.iloc[:,8].values","29a9a1e4":"#Train test split\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(features,\n                                                label,\n                                                test_size=0.2,\n                                                random_state =10)","cdbb4fa7":"#Create model\nfrom sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\nmodel.fit(X_train,y_train) ","cb13f37e":"print(model.score(X_train,y_train))\nprint(model.score(X_test,y_test))","efd73a83":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(label,model.predict(features))\ncm","0fdd1781":"from sklearn.metrics import classification_report\nprint(classification_report(label,model.predict(features)))","ffcb7e34":"#Preparing ROC Curve (Receiver Operating Characteristics Curve)\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n\n# predict probabilities\nprobs = model.predict_proba(features)\n# keep probabilities for the positive outcome only\nprobs = probs[:, 1]\n# calculate AUC\nauc = roc_auc_score(label, probs)\nprint('AUC: %.3f' % auc)\n# calculate roc curve\nfpr, tpr, thresholds = roc_curve(label, probs)\n# plot no skill\nplt.plot([0, 1], [0, 1], linestyle='--')\n# plot the roc curve for the model\nplt.plot(fpr, tpr, marker='.')\n\n","619a460e":"#Applying Decission Tree Classifier\nfrom sklearn.tree import DecisionTreeClassifier\nmodel3 = DecisionTreeClassifier(max_depth=5)\nmodel3.fit(X_train,y_train)","5bf304f3":"model3.score(X_train,y_train)","756ead11":"model3.score(X_test,y_test)","743b2d46":"#Applying Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nmodel4 = RandomForestClassifier(n_estimators=11)\nmodel4.fit(X_train,y_train)","bdecb99a":"model4.score(X_train,y_train)","319f6002":"model4.score(X_test,y_test)","ff5ba073":"#Support Vector Classifier\n\nfrom sklearn.svm import SVC \nmodel5 = SVC(kernel='rbf',\n           gamma='auto')\nmodel5.fit(X_train,y_train)","accb483b":"print(model5.score(X_test,y_test))\nprint(model5.score(X_train,y_train))","66405998":"model5.score(X_test,y_test)","e8b67da5":"#Applying K-NN\nfrom sklearn.neighbors import KNeighborsClassifier\nmodel2 = KNeighborsClassifier(n_neighbors=7,\n                             metric='minkowski',\n                             p = 2)\nmodel2.fit(X_train,y_train)","b5fdda24":"#Preparing ROC Curve (Receiver Operating Characteristics Curve)\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n\n# predict probabilities\nprobs = model2.predict_proba(features)\n# keep probabilities for the positive outcome only\nprobs = probs[:, 1]\n# calculate AUC\nauc = roc_auc_score(label, probs)\nprint('AUC: %.3f' % auc)\n# calculate roc curve\nfpr, tpr, thresholds = roc_curve(label, probs)\nprint(\"True Positive Rate - {}, False Positive Rate - {} Thresholds - {}\".format(tpr,fpr,thresholds))\n# plot no skill\nplt.plot([0, 1], [0, 1], linestyle='--')\n# plot the roc curve for the model\nplt.plot(fpr, tpr, marker='.')\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\n","77f24707":"#Precision Recall Curve for Logistic Regression\n\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import auc\nfrom sklearn.metrics import average_precision_score\n# predict probabilities\nprobs = model.predict_proba(features)\n# keep probabilities for the positive outcome only\nprobs = probs[:, 1]\n# predict class values\nyhat = model.predict(features)\n# calculate precision-recall curve\nprecision, recall, thresholds = precision_recall_curve(label, probs)\n# calculate F1 score\nf1 = f1_score(label, yhat)\n# calculate precision-recall AUC\nauc = auc(recall, precision)\n# calculate average precision score\nap = average_precision_score(label, probs)\nprint('f1=%.3f auc=%.3f ap=%.3f' % (f1, auc, ap))\n# plot no skill\nplt.plot([0, 1], [0.5, 0.5], linestyle='--')\n# plot the precision-recall curve for the model\nplt.plot(recall, precision, marker='.')","34957f1e":"#Precision Recall Curve for KNN\n\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import auc\nfrom sklearn.metrics import average_precision_score\n# predict probabilities\nprobs = model2.predict_proba(features)\n# keep probabilities for the positive outcome only\nprobs = probs[:, 1]\n# predict class values\nyhat = model2.predict(features)\n# calculate precision-recall curve\nprecision, recall, thresholds = precision_recall_curve(label, probs)\n# calculate F1 score\nf1 = f1_score(label, yhat)\n# calculate precision-recall AUC\nauc = auc(recall, precision)\n# calculate average precision score\nap = average_precision_score(label, probs)\nprint('f1=%.3f auc=%.3f ap=%.3f' % (f1, auc, ap))\n# plot no skill\nplt.plot([0, 1], [0.5, 0.5], linestyle='--')\n# plot the precision-recall curve for the model\nplt.plot(recall, precision, marker='.')","745d1f95":"#Precision Recall Curve for Decission Tree Classifier\n\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import auc\nfrom sklearn.metrics import average_precision_score\n# predict probabilities\nprobs = model3.predict_proba(features)\n# keep probabilities for the positive outcome only\nprobs = probs[:, 1]\n# predict class values\nyhat = model3.predict(features)\n# calculate precision-recall curve\nprecision, recall, thresholds = precision_recall_curve(label, probs)\n# calculate F1 score\nf1 = f1_score(label, yhat)\n# calculate precision-recall AUC\nauc = auc(recall, precision)\n# calculate average precision score\nap = average_precision_score(label, probs)\nprint('f1=%.3f auc=%.3f ap=%.3f' % (f1, auc, ap))\n# plot no skill\nplt.plot([0, 1], [0.5, 0.5], linestyle='--')\n# plot the precision-recall curve for the model\nplt.plot(recall, precision, marker='.')","87fa6ba1":"#Precision Recall Curve for Random Forest\n\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import auc\nfrom sklearn.metrics import average_precision_score\n# predict probabilities\nprobs = model4.predict_proba(features)\n# keep probabilities for the positive outcome only\nprobs = probs[:, 1]\n# predict class values\nyhat = model4.predict(features)\n# calculate precision-recall curve\nprecision, recall, thresholds = precision_recall_curve(label, probs)\n# calculate F1 score\nf1 = f1_score(label, yhat)\n# calculate precision-recall AUC\nauc = auc(recall, precision)\n# calculate average precision score\nap = average_precision_score(label, probs)\nprint('f1=%.3f auc=%.3f ap=%.3f' % (f1, auc, ap))\n# plot no skill\nplt.plot([0, 1], [0.5, 0.5], linestyle='--')\n# plot the precision-recall curve for the model\nplt.plot(recall, precision, marker='.')","60ba3629":"# Week 2"}}