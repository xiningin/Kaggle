{"cell_type":{"21ef6c97":"code","7215868b":"code","1f7ca588":"code","6205cf20":"code","fcd51ff8":"code","a8e14091":"code","475687fc":"code","89c7a416":"code","fc83de06":"code","6392a896":"code","ff40e5c8":"code","1b771f73":"code","122d883f":"markdown","d875e8d1":"markdown","e493e062":"markdown","6476ec81":"markdown","96d7d4aa":"markdown","3639f486":"markdown","898f8633":"markdown","f4e57576":"markdown","96ba2f2c":"markdown","8052967f":"markdown"},"source":{"21ef6c97":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7215868b":"from keras.utils import np_utils\nnp.random.seed(10)","1f7ca588":"train_data = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')","6205cf20":"x_Train = train_data.drop(['label'],axis=1)\nx_Train = np.array(x_Train)\nx_Test = np.array(test_data)\ny_Train = np.array(train_data['label'])\n\nx_Train_4D = x_Train.reshape(x_Train.shape[0],28,28,1).astype('float32')\nx_Test_4D = x_Test.reshape(x_Test.shape[0],28,28,1).astype('float32')","fcd51ff8":"x_Train_4D_normalize = x_Train_4D\/255.0\nx_Test_4D_normalize = x_Test_4D\/255.0","a8e14091":"y_Train_OneHot = np_utils.to_categorical(y_Train)","475687fc":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\nimport tensorflow as tf\ntf.config.experimental_run_functions_eagerly(True)","89c7a416":"model = Sequential()\nmodel.add(Conv2D(filters=16,\n                kernel_size=(5,5),\n                padding='same',\n                input_shape=(28,28,1),\n                activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Conv2D(filters=36,\n                kernel_size=(5,5),\n                padding='same',\n                activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10,activation='softmax'))\nprint(model.summary())","fc83de06":"model.compile(loss='categorical_crossentropy',\n             optimizer='adam',metrics=['accuracy'])","6392a896":"train_history = model.fit(x = x_Train_4D_normalize,\n                          y = y_Train_OneHot,\n                          validation_split = 0.2,\n                          epochs = 20,\n                          batch_size = 200,\n                          verbose = 2)","ff40e5c8":"prediction = model.predict(x_Test_4D_normalize)\nprediction=np.argmax(prediction,axis=1)\nprediction.shape","1b771f73":"submission = pd.read_csv('\/kaggle\/input\/digit-recognizer\/sample_submission.csv')\nsubmission['Label']=prediction\nsubmission.head()\nsubmission.to_csv(\"submission.csv\",index=False)","122d883f":"## 2.4 Train","d875e8d1":"## 2.3 Complie Model","e493e062":"## 1.3 Data Reshape","6476ec81":"## 1.2 Load Data","96d7d4aa":"# 2. Build Model\n## 2.1 Import Modules","3639f486":"# 1. Data Preprocess\n## 1.1 Import Modules","898f8633":"## 1.5 Label Encoding","f4e57576":"## 2.2 Build","96ba2f2c":"# 3. Prediction","8052967f":"## 1.4 Features Normalize"}}