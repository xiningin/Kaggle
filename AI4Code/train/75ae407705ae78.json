{"cell_type":{"858ff199":"code","d85191f5":"code","92ad83e0":"code","c25463a5":"code","adc3f0be":"code","6469df9e":"code","bdcb345e":"code","e149c7de":"code","86d07d3b":"code","ffd1bc89":"code","3864a7cb":"code","fa1d6ded":"code","3ff7868c":"code","3909a746":"code","5aca61f6":"code","f33b358e":"code","1b02fd57":"code","b859c220":"code","f3c46e74":"code","98f46d7f":"code","bdb51bb1":"code","cdb5958c":"code","d8dd15c7":"code","24d1039b":"code","1ff9d463":"code","36957cb6":"code","ed3815c4":"code","368a1dba":"code","18daed6b":"code","b9dedca9":"code","76e88ba6":"code","3a69870e":"code","d80d44c2":"code","a9b07d79":"code","eb10a13a":"code","85fabbc7":"code","5e17dfb0":"code","fc5e9e74":"code","ff86e8b4":"code","c033e1b0":"code","ce802a72":"code","10077e1f":"code","c82920b9":"code","4aa7cbe7":"code","a1284d3e":"code","6d8c6b1b":"code","6e858e75":"code","e01b4bbe":"code","4215691a":"code","8bd03184":"code","ed0228fc":"code","13a8356c":"code","4845ea57":"code","be548089":"code","e59891c4":"code","3d44dedc":"code","04230338":"code","98101e9a":"code","6fdb3ca7":"code","bb89a003":"code","c0fc794b":"code","b6bd418f":"code","398d4995":"code","64f068d7":"code","c76b075a":"code","26a54c24":"code","07cffc79":"code","3214f46b":"code","8930a45c":"code","657c469a":"code","dfcb6541":"code","49432242":"code","bbf48029":"code","efc659f0":"code","c64f05ac":"code","8360db59":"code","eebc139c":"code","b50fd471":"code","0d2adb6e":"code","b455c460":"code","43a5b11f":"code","fc252b6d":"code","3859e5a4":"code","6a4756c3":"code","da592dfe":"code","6730afc6":"code","3b605288":"code","a7554524":"code","4cbbcb28":"markdown","9a25a6d6":"markdown","402c6a3b":"markdown","872e7ab1":"markdown","341f9d73":"markdown","fbc84ed4":"markdown","29944f7c":"markdown","e349e739":"markdown","b4fd72f1":"markdown","d4502232":"markdown","cdf49323":"markdown","8759f964":"markdown","99ad6e23":"markdown","2eb0deb2":"markdown","f3f1a241":"markdown","3edd0311":"markdown","1b99e8d2":"markdown","9065833a":"markdown","3a37aed6":"markdown","48319f94":"markdown","6b12f6f5":"markdown","268e8c0d":"markdown","be745a55":"markdown","b995a48e":"markdown","f1b44d8a":"markdown","7de9b25c":"markdown"},"source":{"858ff199":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d85191f5":"def showver(col):\n    try:\n        print(\"{} version: {}\". format(col.__name__, col.__version__))\n    except AttributeError:\n        try:\n            print(\"{} version: {}\". format(col.__name__, col.version))\n        except AttributeError:\n            #print('{} Error', format(col))\n            pass # Skip it\n        \nimport sys #access to system parameters https:\/\/docs.python.org\/3\/library\/sys.html\nshowver(sys)    \n\nimport numpy as np # linear algebra\nshowver(np)\n\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nshowver(pd)\n\nimport missingno as miss\nshowver(miss)\n\nimport matplotlib.pyplot as plt\n# showver(matplotlib)\n\nimport squarify\nshowver(squarify)\n\nimport random\nshowver(random)\n\nimport datetime\nshowver(datetime)\n\nimport re\nshowver(re)\n\nfrom collections import Counter\nshowver(Counter)\n\nfrom nltk.corpus import stopwords #removes and, in, the, a ... etc\nshowver(stopwords)\n\nimport plotly.express as px\nshowver(px)\n\n#ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint('-' * 43)\n","92ad83e0":"FILEPATH = '\/kaggle\/input\/60k-stack-overflow-questions-with-quality-rate\/data.csv'","c25463a5":"df = pd.read_csv(FILEPATH)","adc3f0be":"df.describe()","6469df9e":"df.info()","bdcb345e":"df.isnull().sum()","e149c7de":"df.isna().sum()","86d07d3b":"# import missingno as miss","ffd1bc89":"miss.matrix(df)","3864a7cb":"df.head()","fa1d6ded":"# df.duplicated(subset=None, keep='first')","3ff7868c":"len(df[df.duplicated()])","3909a746":"def get_tech_keys(tag):\n    \n    if(not tag):\n        return tag\n    \n    tag = tag.replace('><', ',')\n    \n    tag = tag.replace('<', '')\n    \n    tag = tag.replace('>', '')\n    \n    return tag","5aca61f6":"df['TechKeys'] = df['Tags'].apply(get_tech_keys)","f33b358e":"df.head()","1b02fd57":"df_tech_keys = df[['TechKeys']]","b859c220":"df_tech_keys.head()","f3c46e74":"tech_key_list   = []\ntech_key_values = None\nindex_counter = 0\ntech_key_index_list = []\nfor (columnName, columnData) in df_tech_keys.iteritems():\n    tech_key_values = columnData.values\n    \nfor item in tech_key_values:\n    item_parts = item.split(',')\n    \n    for item_ in item_parts:\n        \n        tech_key_index_list.append(index_counter)\n        tech_key_list.append(item_)\n        \n        index_counter += 1\n    \n# tech_key_list","98f46d7f":"data = {'id' : tech_key_index_list, 'tech_key' : tech_key_list} \n  \n# Create DataFrame \ndf_tech_key_new = pd.DataFrame(data) ","bdb51bb1":"df_tech_key_new.head()","cdb5958c":"len(df_tech_key_new)","d8dd15c7":"df_tech_key_new.tech_key.value_counts().nlargest(10)","24d1039b":"def get_tags_counts(col):\n    \n    if(not col):\n        return 0\n    \n    tags_count = len(col.split(','))\n    \n    return tags_count","1ff9d463":"df['TagsCount'] = df['TechKeys'].apply(get_tags_counts)","36957cb6":"df.head()","ed3815c4":"df_sub = df[['Id', 'Title', 'Tags', 'TagsCount']][0:25]","368a1dba":"df_sub.head()","18daed6b":"def highlight_max_custom(s, color = 'lightgreen'):\n    '''\n    highlight the maximum in a Series yellow.\n    '''\n    is_max = s == s.max()\n    return ['background-color: '+color if v else '' for v in is_max]","b9dedca9":"df_sub.style.apply(highlight_max_custom, color = '#CFFE96',  axis = 0, subset=['TagsCount'])","76e88ba6":"df.Y.unique()","3a69870e":"def get_question_level(level):\n    \n    if(not level):\n        return level\n    \n    if(level == 'LQ_CLOSE'):\n        return 3\n    \n    if(level == 'LQ_EDIT'):\n        return 2\n    \n    if(level == 'HQ'):\n        return 1\n    \n    return level","d80d44c2":"df['Level'] = df['Y'].apply(get_question_level)","a9b07d79":"df.head()","eb10a13a":"# import matplotlib.pyplot as plt\n\ndef show_donut_plot(col):\n    \n    rating_data = df.groupby(col)[['Id']].count().head(10)\n    plt.figure(figsize = (12, 8))\n    plt.pie(rating_data[['Id']], autopct = '%1.0f%%', startangle = 140, pctdistance = 1.1, shadow = True)\n\n    # create a center circle for more aesthetics to make it better\n    gap = plt.Circle((0, 0), 0.5, fc = 'white')\n    fig = plt.gcf()\n    fig.gca().add_artist(gap)\n    \n    plt.axis('equal')\n    \n    cols = []\n    for index, row in rating_data.iterrows():\n        cols.append(index)\n    plt.legend(cols)\n    \n    plt.title('Donut Plot: SOF Questions by ' +str(col), loc='center')\n    \n    plt.show()","85fabbc7":"show_donut_plot('Level')","5e17dfb0":"show_donut_plot('TagsCount')","fc5e9e74":"# import squarify\n\ndef show_treemap(col, max_labels = 10):\n    df_type_series = df.groupby(col)['Id'].count().sort_values(ascending = False).head(20)\n\n    type_sizes = []\n    type_labels = []\n    for i, v in df_type_series.items():\n        type_sizes.append(v)\n        \n        type_labels.append(str(i) + ' ('+str(v)+')')\n\n\n    fig, ax = plt.subplots(1, figsize = (12,12))\n    squarify.plot(sizes=type_sizes, \n                  label=type_labels[:max_labels],  # show labels for only first 10 items\n                  alpha=.2 )\n    \n    plt.title('TreeMap: SOF Questions by '+ str(col))\n    plt.axis('off')\n    plt.show()","ff86e8b4":"show_treemap('Level')","c033e1b0":"# print random body (random column data)\n# import random\n\n# df.at[df.index[random.randint(0, len(df))], 'Body']","ce802a72":"def code_available(content):\n    \n    if('<code>' in content):\n        return True\n    \n    return False","10077e1f":"df['code_available'] = df['Body'].apply(code_available)","c82920b9":"df.head()","4aa7cbe7":"show_donut_plot('code_available')","a1284d3e":"# import datetime\n\ndef get_week(col):\n    \n    return col.strftime(\"%V\")","6d8c6b1b":"# Create new columns for Month, Year Created\ndf['CreationDatetime'] = pd.to_datetime(df['CreationDate']) \ndf['CreationMonth'] = df['CreationDatetime'].dt.month.astype(int)\ndf['CreationYear'] = df['CreationDatetime'].dt.year.astype(int)\ndf['CreationWeek'] = df['CreationDatetime'].apply(get_week).astype(int)","6e858e75":"# df.info()","e01b4bbe":"show_donut_plot('CreationMonth')","4215691a":"show_treemap('CreationMonth')","8bd03184":"show_donut_plot('CreationYear')","ed0228fc":"show_donut_plot('CreationWeek')","13a8356c":"show_treemap('CreationYear')","4845ea57":"show_treemap('CreationWeek', 18)","be548089":"df_tech_key_new","e59891c4":"def show_donut_plot_techkey(col):\n    \n    rating_data = df_tech_key_new.groupby(col)[['id']].count().head(50)\n    plt.figure(figsize = (12, 8))\n    plt.pie(rating_data[['id']], autopct = '%1.0f%%', startangle = 140, pctdistance = 1.1, shadow = True)\n\n    # create a center circle for more aesthetics to make it better\n    gap = plt.Circle((0, 0), 0.5, fc = 'white')\n    fig = plt.gcf()\n    fig.gca().add_artist(gap)\n    \n    plt.axis('equal')\n    \n    cols = []\n    for index, row in rating_data.iterrows():\n        cols.append(index)\n    plt.legend(cols)\n    \n    plt.title('Donut Plot by ' +str(col), loc='center')\n    \n    plt.show()","3d44dedc":"show_donut_plot_techkey('tech_key')","04230338":"def show_treemap_tech_key(col):\n    df_type_series = df_tech_key_new.groupby(col)['id'].count().sort_values(ascending = False).head(50)\n\n    type_sizes = []\n    type_labels = []\n    for i, v in df_type_series.items():\n        type_sizes.append(v)\n        \n        type_labels.append(str(i) + ' ('+str(v)+')')\n\n\n    fig, ax = plt.subplots(1, figsize = (12,12))\n    squarify.plot(sizes=type_sizes, \n                  label=type_labels[:25],  # show labels for only first 10 items\n                  alpha=.2 )\n    plt.title('TreeMap by '+ str(col))\n    plt.axis('off')\n    plt.show()","98101e9a":"show_treemap_tech_key('tech_key')","6fdb3ca7":"def show_donut_plot_2cols(col1, col1_val, col2):\n    \n    df1 = df[df[col1] == col1_val]\n    \n    rating_data = df1.groupby(col2)[['Id']].count().head(10)\n    plt.figure(figsize = (12, 8))\n    plt.pie(rating_data[['Id']], autopct = '%1.0f%%', startangle = 140, pctdistance = 1.1, shadow = True)\n\n    # create a center circle for more aesthetics to make it better\n    gap = plt.Circle((0, 0), 0.5, fc = 'white')\n    fig = plt.gcf()\n    fig.gca().add_artist(gap)\n    \n    plt.axis('equal')\n    \n    cols = []\n    for index, row in rating_data.iterrows():\n        cols.append(index)\n    plt.legend(cols)\n    \n    plt.title('Donut Plot by ' +str(col1) + ' and ' +str(col2), loc='center')\n    \n    plt.show()","bb89a003":"show_donut_plot_2cols('CreationYear', 2016, 'Level')","c0fc794b":"show_donut_plot_2cols('CreationYear', 2016, 'code_available')","b6bd418f":"df.head()","398d4995":"df.Y.unique()","64f068d7":"import re\n\ncode_start = '<code>'\ncode_end   = '<\/code>'\n\ndef get_codes(content):\n    \n    if('<code>' not in content):\n        return None\n    \n    code_list = []\n    \n    loop_counter = 0\n    while(code_start in content):\n\n        code_start_index = content.index(code_start)\n        if(code_end not in content):\n            code_end_index = len(content)\n        else:\n            code_end_index = content.index(code_end)\n\n        substring_1 = content[code_start_index : (code_end_index + len(code_end) )]\n \n        code_list.append(substring_1)\n        \n        content = content.replace(substring_1, '')\n        \n        loop_counter += 1\n\n    \n    return ' '.join(code_list)\n\ndef  clean_text(content):\n    \n    content = content.lower()\n    \n    content = re.sub('<.*?>+', '', content)\n    \n    content = re.sub(r\"(@[A-Za-z0-9]+)|^rt|http.+?\", \"\", content)\n    content = re.sub(r\"(\\w+:\\\/\\\/\\S+)\", \"\", content)\n    content = re.sub(r\"([^0-9A-Za-z \\t])\", \" \", content)\n    content = re.sub(r\"^rt|http.+?\", \"\", content)\n    content = re.sub(\" +\", \" \", content)\n\n    # remove numbers\n    content = re.sub(r\"\\d+\", \"\", content)\n    \n    return content\n\n# Clean the data\ndef clean_text_simple(text):\n    text = text.lower()\n    text = re.sub(r'[^(a-zA-Z)\\s]','', text)\n    return text\n\ndef get_non_codes(content):\n    \n    loop_counter = 0\n    while(code_start in content):\n\n        code_start_index = content.index(code_start)\n        if(code_end not in content):\n            code_end_index = len(content)\n        else:\n            code_end_index = content.index(code_end)\n\n        substring_1 = content[code_start_index : (code_end_index + len(code_end) )]\n\n        content = content.replace(substring_1, ' ')\n        \n        loop_counter += 1\n        \n    content = clean_text_simple(content)\n\n    return content","c76b075a":"df['Body_code'] = df['Body'].apply(get_codes)\ndf['Body_content'] = df['Body'].apply(get_non_codes)","26a54c24":"# from collections import Counter\n# from nltk.corpus import stopwords\n\nstopwords1 = stopwords.words('english')\n\n\n\ndf['content_words'] = df['Body_content'].apply(lambda x:str(x).split())","07cffc79":"def remove_short_words(content):\n\n    new_content_list = []\n    for item in content:\n        \n        if(len(item) > 2):\n            new_content_list.append(item)\n    \n    return new_content_list\n    ","3214f46b":"df['content_words'] = df['content_words'].apply(remove_short_words)","8930a45c":"df.head()","657c469a":"words_collection = Counter([item for sublist in df['content_words'] for item in sublist if not item in stopwords1])\nfreq_word_df = pd.DataFrame(words_collection.most_common(30))\nfreq_word_df.columns = ['frequently_used_word','count']\n\nfreq_word_df.style.background_gradient(cmap='YlGnBu', low=0, high=0, axis=0, subset=None)","dfcb6541":"# import plotly.express as px\n\nfig = px.scatter(freq_word_df, x=\"frequently_used_word\", y=\"count\", color=\"count\", title = 'Frequently used words - Scatter plot')\nfig.show()","49432242":"fig = px.pie(freq_word_df, values='count', names='frequently_used_word', title='Stackoverflow Questions - Frequently Used Word')\nfig.show()","bbf48029":"fig = px.sunburst(df, path=['CreationYear', 'CreationMonth'], values='Level',\n                  color='Level', hover_data=['Level'])\nfig.show()","efc659f0":"fig = px.sunburst(df, path=['CreationYear', 'CreationMonth'], values='code_available',\n                  color='code_available', hover_data=['code_available'])\nfig.show()","c64f05ac":"fig = px.strip(df, x=\"CreationMonth\", y=\"code_available\", orientation=\"h\", color=\"CreationYear\")\nfig.show()","8360db59":"df.head()","eebc139c":"df_text = df.drop(['Title', 'Body', 'Tags', 'CreationDate', 'TechKeys', 'TagsCount', \n                   'Y', 'code_available', 'CreationDatetime', 'CreationMonth', 'CreationYear', \n                   'CreationWeek', 'Body_code', 'content_words', 'Id'], axis = 1)","b50fd471":"df_text.head()","0d2adb6e":"# Define how much percent data you wanna split\nsplit_count = int(0.23 * len(df_text))","b455c460":"# Shuffles dataframe\ndf_text = df_text.sample(frac=1).reset_index(drop=True)\n\n# Training Sets\ntrain = df_text[split_count:]\ntrainX = train['Body_content']\ntrainY = train['Level'].values\n\n# Test Sets\ntest = df_text[:split_count]\ntestX = test['Body_content']\ntestY = test['Level'].values\n\nprint(f\"Training Data Shape: {testX.shape}\\nTest Data Shape: {testX.shape}\")","43a5b11f":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n# Load the vectorizer, fit on training set, transform on test set\nvectorizer = TfidfVectorizer()\ntrainX = vectorizer.fit_transform(trainX)\ntestX = vectorizer.transform(testX)","fc252b6d":"# commenting out as it is taking too much time\n# from sklearn.svm import SVC\n\n# svm_model = SVC(kernel='rbf', random_state=0, gamma=1, C=1).fit(trainX, trainY)\n\n# svm_model","3859e5a4":"from sklearn.tree import DecisionTreeClassifier\n\ndt_model = DecisionTreeClassifier()\ndt_model = dt_model.fit(trainX, trainY)\n\ndt_model","6a4756c3":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier()\n\nknn_model = knn.fit(trainX, trainY)\n\nknn_model","da592dfe":"models = [\n#     svm_model,\n    dt_model,\n    knn_model\n]","6730afc6":"from sklearn.metrics import confusion_matrix, accuracy_score, classification_report","3b605288":"best_model_accuracy = 0\nbest_model = None\n\nfor model in models:\n    \n    model_name = model.__class__.__name__\n    \n    predY = model.predict(testX)\n    accuracy = accuracy_score(testY, predY)\n    \n    print(\"-\" * 43)\n    print(model_name + \": \" )\n    \n    if(accuracy > best_model_accuracy):\n        best_model_accuracy = accuracy\n        best_model = model_name\n    \n    print(\"Accuracy: {:.2%}\".format(accuracy))","a7554524":"print(\"Best Model : {}\".format(best_model))\nprint(\"Best Model Accuracy : {:.2%}\".format(best_model_accuracy))","4cbbcb28":"<font color=\"blue\"><b>Check out my other Notebooks<\/b><\/font>\n\n<table style=\"font-family: 'Trebuchet MS', Arial, Helvetica, sans-serif;border-collapse: collapse;width: 100%;\">\n  <tr>\n    <th style=\"border: 1px solid #ddd;padding: 8px; padding-top: 12px;padding-bottom: 12px;text-align: left;background-color: #2987E7;color: white;\">Notebook<\/th>\n    <th style=\"border: 1px solid #ddd;padding: 8px; padding-top: 12px;padding-bottom: 12px;text-align: left;background-color: #2987E7;color: white;\">Tags<\/th>\n  <\/tr>\n  <tr>\n    <td style=\"text-align: left\"><a href=\"https:\/\/www.kaggle.com\/rajacsp\/sof-questions-eda-and-visual\">SOF Questions - EDA and Visual<\/a> <\/td>\n    <td style=\"text-align: left\">Data Visual, Plotly<\/td>\n  <\/tr>\n  <tr>\n    <td style=\"background-color: #f2f2f2;text-align: left\"><a href=\"https:\/\/www.kaggle.com\/rajacsp\/netflix-visualization-plotly-plots-treemap\">Netflix - Visualization, Plotly, Plots, and Treemap<\/a> <\/td>\n    <td style=\"background-color: #f2f2f2;text-align: left\">Data Visual, Data Cleaning, Plotly<\/td>\n  <\/tr>\n  <tr>\n    <td style=\"text-align: left\"><a href=\"https:\/\/www.kaggle.com\/rajacsp\/prediction-with-various-algorithms\">Prediction with various Algorithms<\/a> <\/td>\n    <td style=\"text-align: left\">Random Forest, Logistic Regression<\/td>\n  <\/tr>\n  <tr>\n    <td style=\"background-color: #f2f2f2;text-align: left\"><a href=\"https:\/\/www.kaggle.com\/rajacsp\/eda-and-visualization\">EDA and Visualization<\/a> <\/td>\n    <td style=\"background-color: #f2f2f2;text-align: left\">Data Cleaning, Data Visual<\/td>\n  <\/tr>\n  <tr>\n    <td style=\"text-align: left\"><a href=\"https:\/\/www.kaggle.com\/rajacsp\/job-analysis-eda-visual\">Job Analysis - EDA and Visual<\/a> <\/td>\n    <td style=\"text-align: left\">Data Visual, EDA, Plotly<\/td>\n  <\/tr>   \n  <tr>\n    <td style=\"background-color: #f2f2f2;text-align: left\"><a href=\"https:\/\/www.kaggle.com\/rajacsp\/estonia-disaster-visualization\">Estonia Disaster - Visualization<\/a> <\/td>\n    <td style=\"background-color: #f2f2f2;text-align: left\">Data Visual, EDA, Data Cleaning<\/td>\n  <\/tr>\n    \n  <tr>\n    <td style=\"text-align: left\"><a href=\"https:\/\/www.kaggle.com\/rajacsp\/pandas-cheatsheet-100-exercices\" >Pandas Cheatsheet: 100+ exercises collection<\/a><\/td>\n    <td style=\"text-align: left\">Pandas, Data Manipulation<\/td>\n  <\/tr>   \n  <tr>\n    <td style=\"background-color: #f2f2f2;text-align: left\"><a href=\"https:\/\/www.kaggle.com\/rajacsp\/prediction-with-various-algorithms\">Credit Card Fraud - Prediction with various algorithms<\/a><\/td>\n    <td style=\"background-color: #f2f2f2;text-align: left\">Various ML Algorithms<\/td>\n  <\/tr>  \n  <tr>\n    <td style=\"text-align: left\"><a href=\"https:\/\/www.kaggle.com\/rajacsp\/linear-equations-real-time\">Linear Equations - Real Time<\/a> <\/td>\n    <td style=\"text-align: left\">Linear Equation<\/td>\n  <\/tr>  \n<\/table>\n\n","9a25a6d6":"Everything is hunky-dory! So, no worries about NA\/null data!","402c6a3b":"**Observation:**\n\n* Almost half of the contents don't have code in the body.","872e7ab1":"Warning:\n\nThere is something in this donut plot which I can't figure it out at the momemnt. However, I will come back and fix them soon.","341f9d73":"### Notes:\n\n* I am keeping the code very simple for newcomers can learn things very easily. This is why you won't see any complex regex options in my code.\n* This code is not production ready. Code is used only for demonstration and learning purpose. You might get some performance issues if you use the same code.\n* I have used various charts for learning purpose. Some of the plots might be redundant. ","fbc84ed4":"### Code Available Sunburst","29944f7c":"**Observation:**\n\n* We can clearly see that Javascript and Python are dominating the questions followed by Java.\n* We know that Java is lagging behind, not able to compete with Python since 2013.\n* I am surprised to see Android comes 4th place. \n* Where is Node.js? Hello?","e349e739":"**Observation:**\n\n* We can see that there is no duplicates involved in this dataset which is a good sign!","b4fd72f1":"### Year, Date and Week Columns\n\nLet's create more columns from the `CreationDatetime`. We will have `CreationMonth`, `CreationYear`, and `CreationWeek`","d4502232":"Let's find if there is any duplicates. ","cdf49323":"## Word Cleanup\n\nAs the body contains both code and content, we will have to remove code from the content. We will start doing it in the code below.\n\nAlso, we will do a little cleaning on the content by removing stop words and less than 3 characters. ","8759f964":"**Observation:**\n\n* As the questions are equally divided, we don't have much to say here.","99ad6e23":"To Do:\n\n* Have to add more models to get the most accurate model.\n* Introduce Quality Level (L1 - High, L2 - Low but open, L3 - Poor)\n* Predict the LQ_Close items based on the question content (like what phrase is used)","2eb0deb2":"### Question Level\n\nLet's come up with a new column called level based on the question quality.\n\n* L1 - High Quality \n* L2 - Low Quality but open\n* L3 - Low Quality Closed\n","f3f1a241":"## About the Dataset:\n\n* Total questions collected is 60,000.\n* Questions are from 2016 to 2020.\n* There are 3 categories involoved: \n    1. HQ: High-quality posts with 30+ score and without a single edit.\n    2. LQ_EDIT: Low-quality posts with a negative score and with multiple community edits. However, they still remain open after the edits.\n    3. LQ_CLOSE: Low-quality posts that were closed by the community without a single edit.","3edd0311":"### Tech Keys\n\nAs Tags come as extra html characters, it is hard to understand which tech keys are mostly used. So, we have to clean them up to get the tech keys.\n","1b99e8d2":"### Code Available Strip Plot","9065833a":"#### Tags Count\n\nLet's try to add a column by counting tags as this might help us to identify the quality of the question (I am guessing).\n\n","3a37aed6":"### Import Libraries","48319f94":"### Question Level Sunburst Plot","6b12f6f5":"## Classification Time\n\nLet's classify the category based on the content.","268e8c0d":"I can get only 77% as the best. I will have to do more work to come up with a better accuracy.","be745a55":"**Final Notes:**\n\nI am adding things still. You can come back and check for more information.\n\nAlso, if you **like my notebook**, <font style=\"color:blue;size:14px;\">please upvote it<\/font> as it will motivate me to come up with better approach in the upcoming notebooks.\n","b995a48e":"**Observation:**\n\n* `code` and `like` are used most in the questions. Everyone is looking for code huh?","f1b44d8a":"### Visual on Null","7de9b25c":"## Data Basics"}}