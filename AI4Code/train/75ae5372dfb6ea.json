{"cell_type":{"08e0ea2e":"code","eb5493eb":"code","57656957":"code","b00df3a6":"code","c2f2c205":"code","2f1a303b":"code","9805c71c":"code","67d8c0b2":"code","d2e6fb65":"code","f0c09aa1":"code","c5a63919":"code","404919cc":"code","9a8935cd":"code","c9bb3b8f":"code","a48a6a39":"code","f3f628a0":"markdown","13105138":"markdown","228cce3d":"markdown","50da4391":"markdown","d236143c":"markdown","1db79878":"markdown","fe44f6ac":"markdown","9013dbac":"markdown","886fcacc":"markdown","e32e5527":"markdown","c06c9d77":"markdown","d662f462":"markdown"},"source":{"08e0ea2e":"# Importing necessary libraries:\nimport os\nimport numpy as np # Linear Algebra\nimport pandas as pd # Data Processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Data Visualization Libraries\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport plotly_express as px # Bubble Chart","eb5493eb":"# Importing competition datasets (from 2017 until 2019):\nmultiple_choice_file_2017 = '..\/input\/kaggle-survey-2017\/multipleChoiceResponses.csv'\nmultiple_choice_file_2018 = '..\/input\/kaggle-survey-2018\/multipleChoiceResponses.csv'\nmultiple_choice_file_2019  = '..\/input\/kaggle-survey-2019\/multiple_choice_responses.csv'\n\ndataset2017  = pd.read_csv(multiple_choice_file_2017, encoding='ISO-8859-1')\ndataset2018  = pd.read_csv(multiple_choice_file_2018)\ndataset2019  = pd.read_csv(multiple_choice_file_2019)\n\n# Importing conversion rates dataset:\nconversion_rates_file_2017 = '..\/input\/kaggle-survey-2017\/conversionRates.csv'\ndataset_conversionRates_2017 = pd.read_csv(conversion_rates_file_2017, usecols=['originCountry', 'exchangeRate'])","57656957":"# Functions to convert range strings to numerical values:\n# Functions inspired by this notebook: https:\/\/www.kaggle.com\/iamleonie\/japan-country-of-the-rising-women\n\ndef convert_string_to_numerical(range_string):\n    mean = 0\n    \n    # Check if there are any number in the string:\n    if any(i.isdigit() for i in range_string):\n        range_string = range_string.replace(',', '').replace('+', '').replace(' ', '').replace('>', '').replace('<', '').replace('$', '').replace('years', '')\n        \n        # Split the string to the numbers of the range:\n        range_array = np.array(range_string.split('-'))\n        range_array = range_array.astype(np.float)\n        \n        # Calculate the mean value of the range:\n        mean = np.mean(range_array)\n    \n    return mean\n\ndef dictionary_from_unique_values(dataframe, column_name):\n    unique_values = dataframe[column_name].unique()\n    dictionary = {}\n    for i in range(len(unique_values)):\n        if type(unique_values[i]) is str:\n            dictionary[unique_values[i]] = convert_string_to_numerical(unique_values[i])\n        else:\n            dictionary[unique_values[i]] = 0\n    \n    return dictionary","b00df3a6":"# Data Preparation for 2017 dataset:\n\n# Selecting just a few columns:\ncolumn_names = ['Age', 'GenderSelect', 'Country', 'FormalEducation', 'CurrentJobTitleSelect', 'CompensationAmount', 'CompensationCurrency']\ndataset2017 = dataset2017[column_names]\n\n# Changing the name of the colummns:\ndataset2017.columns = ['Age', 'Gender', 'Country', 'Education', 'Role', 'Salary', 'CompensationCurrency']\n\n# Converting column 'Salary' from str to float:\ndataset2017 = dataset2017[dataset2017['Salary'].isin(['-99', '-1', '0', '-']) == False]\n\ndataset2017['NumericSalaryFloat'] = dataset2017['Salary'].replace('140000,00', '140000')\ndataset2017['NumericSalaryFloat'] = dataset2017['NumericSalaryFloat'].str.replace(',', '')\ndataset2017['NumericSalaryFloat'] = dataset2017['NumericSalaryFloat'].astype('float32')\n\n# Converting column Salary to USD currency:\ndataset2017 = dataset2017.merge(dataset_conversionRates_2017, how='inner',\n                                left_on='CompensationCurrency', \n                                right_on='originCountry' )\n\n# Calculating the Salary in USD (the original value * the exchange rate):\ndataset2017['NumericSalary'] = dataset2017['NumericSalaryFloat'] * dataset2017['exchangeRate']\n\n# Deleting outliers manually:\ndataset2017.drop(4394, inplace=True)\ndataset2017.drop(3925, inplace=True)\ndataset2017.drop(279, inplace=True)\ndataset2017.drop(1388, inplace=True)\ndataset2017.drop(4451, inplace=True)\ndataset2017.drop(1411, inplace=True)\n\n# Calculating the number of participants per country:\nnumber_of_people = dataset2017.groupby(['Country']).size().to_frame(name='Number_of_people').reset_index()\n\n# Calculating the number of people with Master or Doctoral degree per country:\nhigh_degree = ['Master\u2019s degree','Doctoral degree']\nnumber_of_high_degree = dataset2017[(dataset2017.Education.isin(high_degree))].groupby(['Country']).size().to_frame(name='Number_of_high_degree').reset_index()\n\n# Calculating the mean age per country:\nmean_age = dataset2017.groupby(['Country'])['Age'].mean().to_frame(name='Mean_age').reset_index()\n\n# Calculating the median salary per country:\nmedian_salary = dataset2017.groupby(['Country'])['NumericSalary'].median().to_frame(name='Median_salary').reset_index()\n\n# Merging all previous DataFrames in only one:\nmerge = pd.merge(number_of_people, number_of_high_degree, on='Country')\nmerge = pd.merge(merge, mean_age, on='Country')\ndata2017 = pd.merge(merge, median_salary, on='Country')\n\n# Calculating Proportion of people with a high degree:\ndata2017['Proportion_high_degree'] = data2017['Number_of_high_degree'] * 100 \/ data2017['Number_of_people']\ndata2017['Year'] = 2017","c2f2c205":"# Data Preparation for 2018 dataset:\n\n# Removing first row (same text as the questions):\ndataset2018.drop(0, inplace=True)\n\n# Selecting just a few columns:\ncolumn_names = ['Q2', 'Q1', 'Q3', 'Q4', 'Q6', 'Q9']\ndataset2018 = dataset2018[column_names]\n\n# Changing the name of the colummns:\ndataset2018.columns = ['Age', 'Gender', 'Country', 'Education', 'Role', 'Salary']\n\n# Converting column Salary from string to float:\ndataset2018['NumericSalary'] =  np.where(dataset2018['Salary']=='0-10,000', 5000, \n                            np.where(dataset2018['Salary']=='10-20,000', 15000, \n                            np.where(dataset2018['Salary']=='20-30,000', 25000,\n                            np.where(dataset2018['Salary']=='30-40,000', 35000,\n                            np.where(dataset2018['Salary']=='40-50,000', 45000,\n                            np.where(dataset2018['Salary']=='50-60,000', 55000,\n                            np.where(dataset2018['Salary']=='60-70,000', 65000,\n                            np.where(dataset2018['Salary']=='70-80,000', 75000,\n                            np.where(dataset2018['Salary']=='80-90,000', 85000,\n                            np.where(dataset2018['Salary']=='90-100,000', 95000,\n                            np.where(dataset2018['Salary']=='100-125,000', 112500,       \n                            np.where(dataset2018['Salary']=='125-150,000', 137500, \n                            np.where(dataset2018['Salary']=='150-200,000', 175000, \n                            np.where(dataset2018['Salary']=='200-250,000', 225000,\n                            np.where(dataset2018['Salary']=='250-300,000', 275000,\n                            np.where(dataset2018['Salary']=='300-400,000', 350000,   \n                            np.where(dataset2018['Salary']=='400-500,000', 450000,     \n                            np.where(dataset2018['Salary']=='500,000+', 500000,\n                            np.where(dataset2018['Salary']== 'NaN', 0, 0                                                                      \n                                )))))\n                                )))))\n                                )))))\n                                ))))\ndataset2018['NumericSalary'].astype('float32');\n\n# Converting column Age from string to float:\nlabel_encoding_2018 = {}\nlabel_encoding_2018['Age'] = dictionary_from_unique_values(dataset2018, 'Age')\ndataset2018.replace(label_encoding_2018, inplace=True)\n\n# Calculating the number of participants per country:\nnumber_of_people = dataset2018.groupby(['Country']).size().to_frame(name='Number_of_people').reset_index()\n\n# Calculating the number of people with Master or Doctoral degree per country:\nhigh_degree = ['Master\u2019s degree','Doctoral degree']\nnumber_of_high_degree = dataset2018[(dataset2018.Education.isin(high_degree))].groupby(['Country']).size().to_frame(name='Number_of_high_degree').reset_index()\n\n# Calculating the mean age per country:\nmean_age = dataset2018.groupby(['Country'])['Age'].mean().to_frame(name='Mean_age').reset_index()\n\n# Calculating the median salary per country:\nmedian_salary = dataset2018.groupby(['Country'])['NumericSalary'].median().to_frame(name='Median_salary').reset_index()\n\n# Merging all previous DataFrames in only one:\nmerge = pd.merge(number_of_people, number_of_high_degree, on='Country')\nmerge = pd.merge(merge, mean_age, on='Country')\ndata2018 = pd.merge(merge, median_salary, on='Country')\n\n# Calculating Proportion of people with a high degree:\ndata2018['Proportion_high_degree'] = data2018['Number_of_high_degree'] * 100 \/ data2018['Number_of_people']\ndata2018['Year'] = 2018","2f1a303b":"# Data Preparation for 2019 dataset:\n\n# Removing first row (same text as the questions):\ndataset2019.drop(0, inplace=True)\n\n# Selecting just a few columns:\ncolumn_names = ['Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q10']\ndataset2019 = dataset2019[column_names]\n\n# Changing the name of the colummns:\ndataset2019.columns = ['Age', 'Gender', 'Country', 'Education', 'Role', 'CompanySize', 'Salary']\n\n# Converting column Salary from string to float:\ndataset2019['NumericSalary'] =  np.where(dataset2019['Salary']=='$0-999', 500, \n                            np.where(dataset2019['Salary']=='1,000-1,999', 1500, \n                            np.where(dataset2019['Salary']=='2,000-2,999', 2500,\n                            np.where(dataset2019['Salary']=='3,000-3,999', 3500,\n                            np.where(dataset2019['Salary']=='4,000-4,999', 4500,\n                                     \n                            np.where(dataset2019['Salary']=='5,000-7,499', 6250, \n                            np.where(dataset2019['Salary']=='7,500-9,999', 8750, \n                            np.where(dataset2019['Salary']=='10,000-14,999', 12500,\n                            np.where(dataset2019['Salary']=='15,000-19,999', 17500,\n                            np.where(dataset2019['Salary']=='20,000-24,999', 22500,\n                                     \n                            np.where(dataset2019['Salary']=='25,000-29,999', 27500,\n                            np.where(dataset2019['Salary']=='30,000-39,999', 35000,\n                            np.where(dataset2019['Salary']=='40,000-49,999', 45000,\n                            np.where(dataset2019['Salary']=='50,000-59,999', 55000,\n                            np.where(dataset2019['Salary']=='60,000-69,999', 65000,\n                                     \n                            np.where(dataset2019['Salary']=='70,000-79,999', 75000,\n                            np.where(dataset2019['Salary']=='80,000-89,999', 85000,\n                            np.where(dataset2019['Salary']=='90,000-99,999', 95000,\n                            np.where(dataset2019['Salary']=='100,000-124,999', 112500,\n                            np.where(dataset2019['Salary']=='125,000-149,999', 137500,\n                                     \n                            np.where(dataset2019['Salary']=='150,000-199,999', 175000,\n                            np.where(dataset2019['Salary']=='200,000-249,999', 225000,\n                            np.where(dataset2019['Salary']=='250,000-299,999', 275000,\n                            np.where(dataset2019['Salary']=='300,000-500,000', 400000,\n                            np.where(dataset2019['Salary']=='> $500,000', 500000, \n                            np.where(dataset2019['Salary']== 'NaN', 0, 0                                        \n                                )))))\n                                )))))\n                                )))))\n                                )))))\n                                ))))) )\ndataset2019['NumericSalary'].astype('float32');\n\n# Converting column Age from string to float:\nlabel_encoding_2019 = {}\nlabel_encoding_2019['Age'] = dictionary_from_unique_values(dataset2019, 'Age')\ndataset2019.replace(label_encoding_2019, inplace=True)\n\n# Calculating the number of participants per country:\nnumber_of_people = dataset2019.groupby(['Country']).size().to_frame(name='Number_of_people').reset_index()\n\n# Calculating the number of people with Master or Doctoral degree per country:\nhigh_degree = ['Master\u2019s degree','Doctoral degree']\nnumber_of_high_degree = dataset2019[(dataset2019.Education.isin(high_degree))].groupby(['Country']).size().to_frame(name='Number_of_high_degree').reset_index()\n\n# Calculating the mean age per country:\nmean_age = dataset2019.groupby(['Country'])['Age'].mean().to_frame(name='Mean_age').reset_index()\n\n# Calculating the median salary per country:\nmedian_salary = dataset2019.groupby(['Country'])['NumericSalary'].median().to_frame(name='Median_salary').reset_index()\n\n# Merging all previous DataFrames in only one:\nmerge = pd.merge(number_of_people, number_of_high_degree, on='Country')\nmerge = pd.merge(merge, mean_age, on='Country')\ndata2019 = pd.merge(merge, median_salary, on='Country')\n\n# Calculating Proportion of people with a high degree:\ndata2019['Proportion_high_degree'] = data2019['Number_of_high_degree'] * 100 \/ data2019['Number_of_people']\ndata2019['Year'] = 2019","9805c71c":"# Concatenating all datasets together (2017, 2018 and 2019):\ndata_per_country = pd.concat([data2017, data2018, data2019], axis=0)","67d8c0b2":"# Correcting the name of some countries:\ndata_per_country['Country'] = np.where(data_per_country['Country']=='Hong Kong (S.A.R.)', 'Hong Kong', \n                       np.where(data_per_country['Country']== 'Iran, Islamic Republic of...', 'Iran', \n                       np.where(data_per_country['Country']=='People \\'s Republic of China', 'China',\n                       np.where(data_per_country['Country']=='Republic of China', 'China',\n                       np.where(data_per_country['Country']=='United Kingdom of Great Britain and Northern Ireland', 'United Kingdom', \n                       np.where(data_per_country['Country']=='United States of America', 'United States', data_per_country['Country']\n                               ))))))","d2e6fb65":"# Creating the column Continent:\ndata_per_country['Continent'] = np.where(data_per_country['Country'].isin(['Argentina', 'Brazil', 'Chile', 'Colombia', 'Peru']), 'Latin America',\n                         np.where(data_per_country['Country'].isin(['Canada', 'United States', 'Mexico']), 'North America',\n                         np.where(data_per_country['Country'].isin(['Australia', 'New Zealand']), 'Oceania',\n                         np.where(data_per_country['Country'].isin(['Czech Republic', 'Japan', 'Singapore', 'India', 'Pakistan', 'Bangladesh'\n                                                             , 'Iran', 'Israel', 'Indonesia', 'China', 'South Korea', 'Hong Kong'\n                                                             , 'Malaysia', 'Philippines', 'Republic of Korea', 'Saudi Arabia'\n                                                            ,'Taiwan', 'Thailand', 'Turkey', 'Viet Nam']), 'Asia',\n                         np.where(data_per_country['Country'].isin(['Egypt', 'Nigeria', 'South Africa', 'Algeria', 'Kenya', 'Morocco', 'Tunisia']), 'Africa',\n                         np.where(data_per_country['Country'].isin(['Belgium', 'Denmark', 'Finland', 'France', 'Germany', 'Greece', 'Hungary', \n                                                             'Ireland', 'Italy', 'Netherlands', 'Norway', 'Poland', 'Portugal', 'Romania', \n                                                             'Spain', 'Sweden', 'Switzerland', 'United Kingdom', 'Austria', 'Belarus', \n                                                             'Ukraine', 'Russia']), 'Europe'\n                                  , 'Unknown'\n                                 ))))))\n","f0c09aa1":"# CALCULATING STATISTICS AGGREGATED BY CONTINENT:\n\n# Calculating the number of participants per continent:\nnumber_of_people = data_per_country.groupby(['Year','Continent'])['Number_of_people'].sum().reset_index()\n\n# Calculating the number of people with Master or Doctoral degree per continent:\nnumber_of_high_degree = data_per_country.groupby(['Year','Continent'])['Number_of_high_degree'].sum().reset_index()\n\n# Calculating the mean age per continent:\ndata_per_country['Number_times_Mean'] = data_per_country['Number_of_people'] * data_per_country['Mean_age']\nmean_age = data_per_country.groupby(['Year','Continent'])['Number_times_Mean'].sum().reset_index()\nmean_age['Mean_age'] = mean_age['Number_times_Mean'] \/ number_of_people['Number_of_people']\n\n# Calculating the mean salary per continent:\ndata_per_country['Number_times_Salary'] = data_per_country['Number_of_people'] * data_per_country['Median_salary']\nmean_salary = data_per_country.groupby(['Year','Continent'])['Number_times_Salary'].sum().reset_index()\nmean_salary['Mean_salary'] = mean_salary['Number_times_Salary'] \/ number_of_people['Number_of_people']\n\n# Merging all previous DataFrames in only one:\nmerge = pd.merge(number_of_people, number_of_high_degree, on=['Year', 'Continent'])\nmerge = pd.merge(merge, mean_age, on=['Year', 'Continent'])\ndata_per_continent = pd.merge(merge, mean_salary, on=['Year', 'Continent'])\n\ndata_per_continent['Proportion_high_degree'] = data_per_continent['Number_of_high_degree'] * 100 \/ data_per_continent['Number_of_people']","c5a63919":"# Bubble chart (Per country in 2017):\ndata_per_country2017 = data_per_country[data_per_country['Year']==2017]\n\npx.scatter(data_per_country2017, x='Proportion_high_degree', y='Mean_age', opacity=0.5,\n           size='Median_salary', color='Country', hover_name='Country'\n           ,title='In 2017, planets were sepparated into two clusters: the younger ones with low high degree and the more experienced with some high degree'\n           ,log_x = False , color_discrete_sequence=px.colors.qualitative.Dark24\n           ,size_max=60 , range_x=[0, 50], range_y=[25,41]\n          ,labels=dict(Proportion_high_degree='Level of study (%)', Country='Planet', Number_of_people='# of Kagglers',\n                       Mean_age='Level of experience (years)', Median_salary='Level of welness (USD)')\n          )","404919cc":"# Bubble chart (Per country in 2018):\ndata_per_country2018 = data_per_country[data_per_country['Year']==2018]\n\npx.scatter(data_per_country2018, x='Proportion_high_degree', y='Mean_age', opacity=0.5,\n           size='Median_salary', color='Country', hover_name='Country'\n           ,title='In 2018, after only one year, almost every planet increased the level of study'\n           ,log_x = False , color_discrete_sequence=px.colors.qualitative.Dark24\n           ,size_max=60 , range_x=[30, 95], range_y=[24,36]\n          ,labels=dict(Proportion_high_degree='Level of study (%)', Country='Planet', Number_of_people='# of Kagglers',\n                       Mean_age='Level of experience (years)', Median_salary='Level of welness (USD)')\n          )","9a8935cd":"# Bubble chart (Per country in 2019):\ndata_per_country2019 = data_per_country[data_per_country['Year']==2019]\n\npx.scatter(data_per_country2019, x='Proportion_high_degree', y='Mean_age', opacity=0.5,\n           size='Median_salary', color='Country', hover_name='Country'\n           ,title='In 2019, almost every planet maintained the level of study'\n           ,log_x = False , color_discrete_sequence=px.colors.qualitative.Dark24\n           ,size_max=60 , range_x=[28, 91], range_y=[24,41]\n          ,labels=dict(Proportion_high_degree='Level of study (%)', Country='Planet', Number_of_people='# of Kagglers',\n                       Mean_age='Level of experience (years)', Median_salary='Level of welness (USD)')\n          )","c9bb3b8f":"# Bubble chart (Per country):\npx.scatter(data_per_country, x='Proportion_high_degree', y='Mean_age', animation_frame='Year', animation_group='Country', opacity=0.5,\n           size='Median_salary', color='Continent', hover_name='Country', title='Planets were separated in two groups, but eventually became very similar'\n           ,log_x = False , color_discrete_sequence=px.colors.qualitative.Dark24\n           ,category_orders={'Continent': ['North America', 'Latin America', 'Asia', 'Europe', 'Africa', 'Oceania', 'Unknown']}\n           ,size_max=45 , range_x=[0, 95], range_y=[25,40]\n          ,labels=dict(Proportion_high_degree='Level of study (%)', Country='Planet', Number_of_people='# of Kagglers', Continent='Star Cluster',\n                       Mean_age='Level of experience (years)', Median_salary='Level of welness (USD)')\n          )\n","a48a6a39":"# Bubble chart (Per continent):\npx.scatter(data_per_continent, x='Proportion_high_degree', y='Mean_age', animation_frame='Year', animation_group='Continent', opacity=0.5,\n           size='Mean_salary', color='Continent', hover_name='Continent', title='Asia Star Cluster (green circle) increased more than 3 times its level of study (from 13% to 46%)'\n           ,log_x=False\n           ,color_discrete_sequence=px.colors.qualitative.Dark24\n           ,category_orders={'Continent': ['North America', 'Latin America', 'Asia', 'Europe', 'Africa', 'Oceania', 'Unknown']}\n           ,size_max=45, range_x=[10, 80], range_y=[25, 40]\n          ,labels=dict(Proportion_high_degree='Level of study (%)', Country='Planet', Number_of_people='# of Kagglers', Continent='Star Cluster',\n                       Mean_age='Level of experience (years)', Mean_salary='Level of welness (USD)')\n          )","f3f628a0":"## Data Science Wars - Episode MMXIX - The Youth Menace\n\nThere were a lot of planets in the galaxy competing to see who was the best in Data Science...\nThen, in the year 2017, an **Interplanetarial Organization** appeared to try to put order in the Data Science world. They are called **KAGGLE** and their followers are called **Kagglers**.\n\nThe **KAGGLE** organization started collecting valuable information about their followers living in each planet to rank them regarding their skills in the battlefield of Data Science across the galaxy.\n\nAll planets were measured by the **KAGGLE** according three skills:\n\n**Skills:**\n* Age of their population of Kagglers (the mean of the age): Measure of the **level of experience** of the planet\n* Proportion of their population of Kagglers that posess a high degree (Master's Degree or Doctoral Degree): Measure of the **level of study** of the planet\n* Salary of their population of Kagglers (median of the salary): Measure of the **level of welness** of the planet","13105138":"## 2.  Rescuing information across the galaxy\n\nThe historical records of the planets were not very well organized, so **Kaggler Padawan** had some trouble organizing it, because the information for each year was stored in a different corner of the galaxy.\n\nHere are the steps he took to collect, prepare, clean and combine all of the information...","228cce3d":"### The struggle never ends since the battle continues year after year. In 2019, the level of study of the planets didn't change significantly, but the level of experience increased a little bit...\n\n* On average, the planets were somewhat stable concerning the level of study, but the level of experience went up by less than 10%\n* The United States planet increased again the level of study (~69%) but, on average, the level of experience increased (~36 years). The level of welness increased as well (~USD 85,000)\n* The Egypt planet continues with low level of study (~29%)\n* There are a lot of planets with low level of welness, even though some of them have a high level of study (for example, Morocco, Iran)","50da4391":"## Conclusion\n\nAlthough the planets were separated into two groups, nowadays they are begining to come to an agreement between themselves.\n\nThis is an endless war, which has the society as the biggest winner. The knowledge produced by The Rebels and The Order is priceless. The evolution triggered by these groups is enormous. We can only hope to the next years that the Kaggle followers all over the planets keep engaged on making the galaxy smarter and better...","d236143c":"## 1. Packing all tools necessary to the journey\n\nTo begin the journey through the galaxy, **Kaggler Padawan** first needs to gather all necessary tools onboard his spaceship \"**Kagglenium Falcon**\"...without this tools, he can't do anything, so let's pack everything and start the engines...","1db79878":"### A long time ago, in a Kaggle galaxy far far away...\n\n\n![starwars](https:\/\/img.elo7.com.br\/product\/zoom\/10B3DF6\/painel-star-wars-13-2-00-x-1-00-cenario-de-chao.jpg)","fe44f6ac":"### Now, Kaggler Padawan sent us a hologram with an animation of all planets along the years...\n\nIn the below hologram, each color represent one Star Cluster that exists across the galaxy.\n\nSome planets are not fully discovered yet, so they are identified together in the Unknown Star Cluster.","9013dbac":"### The Kaggle organization selected one proeminent Kaggler apprentice (called Kaggler Padawan) to analyze the scenario of the galaxy in each year and then see the evolution of all planets throughout the years...","886fcacc":"### Back in 2017, planets were gathered into two groups across the galaxy...\n\n* The planets were united into two groups:\n   * **The Rebels**: planets with low experience (younger) and low level of study (low level of high degree)\n   * **The Empire**: planets with more experience (older) and some level of study (some level of high degree)\n\n\n* The United States planet is the one with more Kagglers than any other planet (1243 Kaggle followers). It has the highest welness between the Kagglers (median of USD 108,000 per Kaggler), but the level of study were not very good (~26% the level of high degree) and the population was not the least experienced (~36 years, on average)\n\n\n* Some planets does not belong to any of the groups, they are isolated on the galaxy, as seen on the map below:\n   * The China planet is one of the least experienced (~28 years), but with a good level of study (~33% the level of high degree)\n   * The New Zealand planet is one of the most experienced (~38 years), but even with this level of experience, it has a low level of study (~17% the level of high degree)\n   * The Switzerland planet, altough not the most experienced (36 years), is the one with the highest level of study (~45%)","e32e5527":"### In the below hologram, Kaggler Padawan grouped the information into the Star Clusters...","c06c9d77":"### After a long year of battle, in 2018, almost every planet increased the level of study:\n\n* The planets are much more similar now: **The Rebels** and **The Empire** are fighting in a very fair battlefield, where the planets have approximately the same level of experience and the same level of study, with some exceptions:\n\n    * Some planets located in the African Star Cluster (planets Nigeria and Egypt) have the lowest levels of study, comparing with the other planets (~32% the level of high degree) \n    * The United States planet increased a lot the level of study (~66%) and new volunteers joined the Kaggler's force, so it became younger, on average (~32 years). Because of this, the level of welness went down (~USD 65,000)\n    * The France planet invested a lot in its Kagglers, because the level of study skyrocketed from 33% to 91%, approximately\n    \n","d662f462":"## 3.  Preparing the maps of the galaxy\n\n**Kaggler Padawan** created the maps below of the entire galaxy to see where each planet is inside the Data Science Wars:\n* Map of 2017\n* Map of 2018\n* Map of 2019\n* Hologram of the history of the galaxy, from 2017 to 2019\n* Hologram of the galaxy, grouped by Star Clusters that each planet is located"}}