{"cell_type":{"2288b6a2":"code","c3b31b2a":"code","16073fbb":"code","4382daa1":"code","09f628c8":"code","52c1cd85":"code","9c1de06d":"code","ba41f347":"code","a0cb22e8":"code","50d67929":"code","1ba72aa5":"code","81e6adcd":"code","a61ad23a":"code","e411b97f":"markdown"},"source":{"2288b6a2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","c3b31b2a":"import tensorflow as tf","16073fbb":"tf.reset_default_graph()","4382daa1":"n_inputs = 3\nn_neurons = 5\nn_steps = 2","09f628c8":"X = tf.placeholder(tf.float32,[None,n_steps,n_inputs]) #mini-batch size,time steps,input sequence","52c1cd85":"X_seqs = tf.unstack(tf.transpose(X,perm=[1,0,2]))","9c1de06d":"basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)","ba41f347":"output_seqs , states = tf.contrib.rnn.static_rnn(basic_cell , X_seqs , dtype=tf.float32)","a0cb22e8":"outputs = tf.transpose(tf.stack(output_seqs),perm=[1,0,2])","50d67929":"X_batch = np.array([\n    # t=0     t=1    \n    [[0,1,2],[9,8,7]],     #instance 0\n    [[3,4,5],[0,0,0]],     #instance 1\n    [[6,7,8],[6,5,4]],     #instance 2\n    [[9,0,1],[3,2,1]]      #instance 3\n    \n])","1ba72aa5":"init = tf.global_variables_initializer()","81e6adcd":"with tf.Session() as sess:\n    sess.run(init)\n    outputs_val = outputs.eval(feed_dict={X:X_batch})\n    ","a61ad23a":"print(outputs_val)","e411b97f":"#### X_seqs is a Python list of n_steps tensors of shape [None, n_inputs], where once again the first dimension is the mini-batch size. To do this, we first swap the first two dimensions using the transpose() function, so that the time steps are now the first dimension. Then we extract a Python list of tensors along the first dimension (i.e., one tensor per time step) using the unstack() function"}}