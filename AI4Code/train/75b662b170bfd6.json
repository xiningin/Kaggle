{"cell_type":{"03a9a8f5":"code","b4565278":"code","1f1d80cd":"code","661e54a4":"code","72e10267":"code","767a6c52":"code","44b31395":"code","59592363":"code","66fa22a4":"code","1a841501":"code","aec2a81b":"code","28641086":"code","8642459c":"code","748fe758":"code","9a841495":"code","3ec631e3":"code","6436be19":"code","3d6627b2":"code","1185187d":"code","a5d783ec":"code","6793fc50":"code","455a4290":"code","03630b10":"code","ca21d872":"code","63608e02":"code","504d0d3e":"code","3d429737":"code","0972e5ce":"code","023b49b1":"code","190deeb8":"code","face49dc":"code","c93cf537":"code","10aaa80e":"code","7d9d3b1b":"code","35e6275b":"code","7977cc8f":"code","aedaff62":"markdown","b7cbfced":"markdown","c7fd0903":"markdown","835b1c9f":"markdown","ebdf6437":"markdown","348143b8":"markdown","be7356ae":"markdown","02aae40d":"markdown","247fc35f":"markdown","b69f5e58":"markdown","2a33af54":"markdown","6a5ea8d3":"markdown","c3f56d96":"markdown","80524752":"markdown","22e509ef":"markdown","1204d548":"markdown","a3236e4e":"markdown","69f3be6c":"markdown"},"source":{"03a9a8f5":"#GENERAL\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\n#PATH PROCESS\nimport os\nimport os.path\nfrom pathlib import Path\nimport glob\n#IMAGE PROCESS\nfrom PIL import Image\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\nfrom keras.preprocessing import image\nimport skimage\nfrom skimage.feature import hessian_matrix, hessian_matrix_eigvals\nfrom scipy.ndimage.filters import convolve\nfrom skimage import data, io, filters\n#SCALER & TRANSFORMATION\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers\nfrom sklearn.preprocessing import LabelEncoder\n#ACCURACY CONTROL\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.metrics import mean_squared_error, r2_score\n#OPTIMIZER\nfrom keras.optimizers import RMSprop,Adam,Optimizer,Optimizer, SGD\n#MODEL LAYERS\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN, LSTM, GlobalAveragePooling2D, SeparableConv2D,\\\nZeroPadding2D, Convolution2D, ZeroPadding2D, ReLU\nfrom keras import models\nfrom keras import layers\nimport tensorflow as tf\nfrom keras.applications import VGG16,VGG19,inception_v3\nfrom keras import backend as K\nfrom keras.utils import plot_model\nfrom keras.models import load_model\nfrom keras.regularizers import l1,l2,L1L2\n#SKLEARN CLASSIFIER\nfrom xgboost import XGBClassifier, XGBRegressor\nfrom lightgbm import LGBMClassifier, LGBMRegressor\nfrom catboost import CatBoostClassifier, CatBoostRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.neural_network import MLPClassifier, MLPRegressor\nfrom sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import ElasticNetCV\n#IGNORING WARNINGS\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","b4565278":"Main_Animal_Path = Path(\"..\/input\/danger-of-extinction-animal-image-set\/Danger Of Extinction\")","1f1d80cd":"Animal_JPG = list(Main_Animal_Path.glob(r\"*\/*.jpg\"))","661e54a4":"Animal_Labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],Animal_JPG))","72e10267":"Animal_JPG_Series = pd.Series(Animal_JPG,name=\"JPG\").astype(str)\nAnimal_Labels_Series = pd.Series(Animal_Labels,name=\"CATEGORY\")","767a6c52":"Main_Train_Data = pd.concat([Animal_JPG_Series,Animal_Labels_Series],axis=1)","44b31395":"print(Main_Train_Data.head(-1))","59592363":"Main_Train_Data = Main_Train_Data.sample(frac=1).reset_index(drop=True)","66fa22a4":"print(Main_Train_Data.head(-1))","1a841501":"plt.style.use(\"classic\")","aec2a81b":"print(Main_Train_Data[\"CATEGORY\"].value_counts())","28641086":"Main_Train_Data[\"CATEGORY\"].hist(figsize=(17,8))\nplt.show()","8642459c":"Main_Train_Data[\"CATEGORY\"].value_counts().plot.pie(autopct='%1.1f%%',shadow=True,figsize=(15,8))\nplt.show()","748fe758":"Amur_Leopard = Main_Train_Data[Main_Train_Data[\"CATEGORY\"] == \"Amur_Leopard\"]\nLion = Main_Train_Data[Main_Train_Data[\"CATEGORY\"] == \"Lion\"]\nPanda = Main_Train_Data[Main_Train_Data[\"CATEGORY\"] == \"Panda\"]\nChimpanzee = Main_Train_Data[Main_Train_Data[\"CATEGORY\"] == \"Chimpanzee\"]\nRhino = Main_Train_Data[Main_Train_Data[\"CATEGORY\"] == \"Rhino\"]\nCheetahs = Main_Train_Data[Main_Train_Data[\"CATEGORY\"] == \"cheetahs\"]\nJaguars = Main_Train_Data[Main_Train_Data[\"CATEGORY\"] == \"Jaguars\"]\nPanthers = Main_Train_Data[Main_Train_Data[\"CATEGORY\"] == \"Panthers\"]\nOrangutan = Main_Train_Data[Main_Train_Data[\"CATEGORY\"] == \"Orangutan\"]\nAfrican_Elephant = Main_Train_Data[Main_Train_Data[\"CATEGORY\"] == \"African_Elephant\"]\nArctic_Fox = Main_Train_Data[Main_Train_Data[\"CATEGORY\"] == \"Arctic_Fox\"]\n\nAmur_Leopard = Amur_Leopard.reset_index()\nLion = Lion.reset_index()\nPanda = Panda.reset_index()\nChimpanzee = Chimpanzee.reset_index()\nRhino = Rhino.reset_index()\nCheetahs = Cheetahs.reset_index()\nJaguars = Jaguars.reset_index()\nPanthers = Panthers.reset_index()\nOrangutan = Orangutan.reset_index()\nAfrican_Elephant = African_Elephant.reset_index()\nArctic_Fox = Arctic_Fox.reset_index()","9a841495":"Example_Leopard = cv2.imread(Amur_Leopard[\"JPG\"][80])\nExample_Lion = cv2.imread(Lion[\"JPG\"][80])\nExample_Panda = cv2.imread(Panda[\"JPG\"][80])\nExample_Chimpanzee = cv2.imread(Chimpanzee[\"JPG\"][80])\nExample_Rhino = cv2.imread(Rhino[\"JPG\"][80])\nExample_Cheetahs = cv2.imread(Cheetahs[\"JPG\"][80])\nExample_Jaguars = cv2.imread(Jaguars[\"JPG\"][80])\nExample_Panthers = cv2.imread(Panthers[\"JPG\"][80])\nExample_Orangutan = cv2.imread(Orangutan[\"JPG\"][80])\nExample_African_Elephant = cv2.imread(African_Elephant[\"JPG\"][80])\nExample_Arctic_Fox = cv2.imread(Arctic_Fox[\"JPG\"][80])","3ec631e3":"animal_list = [Example_Leopard,Example_Lion,Example_Panda,\n              Example_Chimpanzee,Example_Rhino,Example_Cheetahs,\n              Example_Jaguars,Example_Panthers,Example_Orangutan,\n              Example_African_Elephant,Example_Arctic_Fox]","6436be19":"figure,axis = plt.subplots(2,5,figsize=(18,10))\n\nfor i,ax in enumerate(axis.flat):\n    \n    Pick_IMG = animal_list[i]\n    Pick_IMG = cv2.cvtColor(Pick_IMG,cv2.COLOR_BGR2RGB)\n    ax.set_xlabel(Pick_IMG.shape)\n    ax.set_ylabel(Pick_IMG.size)\n    ax.imshow(Pick_IMG)\n\nplt.tight_layout()\nplt.show()\n","3d6627b2":"figure,axis = plt.subplots(5,5,figsize=(18,10))\n\nfor i,ax in enumerate(axis.flat):\n    \n    Pick_IMG = cv2.imread(Main_Train_Data[\"JPG\"][i])\n    Pick_IMG = cv2.cvtColor(Pick_IMG,cv2.COLOR_BGR2RGB)\n    ax.set_xlabel(Pick_IMG.shape)\n    ax.set_ylabel(Pick_IMG.size)\n    ax.set_title(Main_Train_Data[\"CATEGORY\"][i])\n    ax.imshow(Pick_IMG)\n\nplt.tight_layout()\nplt.show()","1185187d":"Train_Data,Test_Data = train_test_split(Main_Train_Data,train_size=0.9,random_state=42,shuffle=True)","a5d783ec":"print(Train_Data.shape)","6793fc50":"print(Test_Data.shape)","455a4290":"Train_Image_Generator = ImageDataGenerator(rescale=1.\/255,\n                                          zoom_range=0.3,\n                                          shear_range=0.2,\n                                          rotation_range=25,\n                                          height_shift_range=0.2,\n                                          width_shift_range=0.2,\n                                          horizontal_flip=True,\n                                          validation_split=0.1,\n                                           brightness_range=[0.3,0.9],\n                                           channel_shift_range=0.2)","03630b10":"Test_Image_Generator = ImageDataGenerator(rescale=1.\/255)","ca21d872":"Example_IMG = cv2.imread(Main_Train_Data[\"JPG\"][44])\nTransformation_IMG = cv2.cvtColor(Example_IMG,cv2.COLOR_BGR2RGB)\nArray_IMG = image.img_to_array(Transformation_IMG)\nArray_IMG = Array_IMG.reshape((1,) + Array_IMG.shape)\n\ni = 0\n\nfor batch in Train_Image_Generator.flow(Array_IMG,batch_size=32):\n    plt.figure(i)\n    \n    Image_Pick = plt.imshow(image.img_to_array(batch[0]))\n    \n    i += 1\n    \n    if i % 4 == 0:\n        break\n        \nplt.show()","63608e02":"Train_IMG_Set = Train_Image_Generator.flow_from_dataframe(dataframe=Train_Data,\n                                                         x_col=\"JPG\",\n                                                         y_col=\"CATEGORY\",\n                                                         target_size=(180,180),\n                                                         color_mode=\"rgb\",\n                                                         class_mode=\"categorical\",\n                                                         subset=\"training\")","504d0d3e":"Validation_IMG_Set = Train_Image_Generator.flow_from_dataframe(dataframe=Train_Data,\n                                                         x_col=\"JPG\",\n                                                         y_col=\"CATEGORY\",\n                                                         target_size=(180,180),\n                                                         color_mode=\"rgb\",\n                                                         class_mode=\"categorical\",\n                                                         subset=\"validation\")","3d429737":"Test_IMG_Set = Test_Image_Generator.flow_from_dataframe(dataframe=Test_Data,\n                                                         x_col=\"JPG\",\n                                                         y_col=\"CATEGORY\",\n                                                         target_size=(180,180),\n                                                         color_mode=\"rgb\",\n                                                         class_mode=\"categorical\",\n                                                         shuffle=False)","0972e5ce":"print(\"TRAIN: \")\nprint(Train_IMG_Set.class_indices)\nprint(Train_IMG_Set.classes[0:5])\nprint(Train_IMG_Set.image_shape)\nprint(\"---\"*20)\nprint(\"VALIDATION: \")\nprint(Validation_IMG_Set.class_indices)\nprint(Validation_IMG_Set.classes[0:5])\nprint(Validation_IMG_Set.image_shape)\nprint(\"---\"*20)\nprint(\"TEST: \")\nprint(Test_IMG_Set.class_indices)\nprint(Test_IMG_Set.classes[0:5])\nprint(Test_IMG_Set.image_shape)","023b49b1":"Model = Sequential()\n\nModel.add(Conv2D(24,(3,3),activation=\"relu\",input_shape=(180,180,3)))\nModel.add(BatchNormalization())\nModel.add(MaxPooling2D((2,2),strides=2))\n\nModel.add(Conv2D(64,(3,3),activation=\"relu\",padding=\"same\"))\nModel.add(Dropout(0.3))\nModel.add(MaxPooling2D((2,2),strides=2))\n\nModel.add(Conv2D(64,(3,3),activation=\"relu\",padding=\"same\"))\nModel.add(Dropout(0.3))\nModel.add(MaxPooling2D((2,2),strides=2))\n\nModel.add(Conv2D(128,(3,3),activation=\"relu\",padding=\"same\"))\nModel.add(Conv2D(128,(3,3),activation=\"relu\",padding=\"same\"))\nModel.add(Dropout(0.3))\nModel.add(MaxPooling2D((2,2),strides=2))\n\nModel.add(Conv2D(256,(3,3),activation=\"relu\",padding=\"same\"))\nModel.add(Dropout(0.3))\nModel.add(MaxPooling2D((2,2),strides=2))\n\nModel.add(Flatten())\nModel.add(Dense(2352,activation=\"relu\"))\nModel.add(Dropout(0.5))\nModel.add(Dense(11,activation=\"softmax\"))","190deeb8":"early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"loss\",patience=3,mode=\"min\")","face49dc":"Model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])","c93cf537":"CNN_Model = Model.fit(Train_IMG_Set,validation_data=Validation_IMG_Set,epochs=100,callbacks=early_stop)","10aaa80e":"Grap_Data = pd.DataFrame(CNN_Model.history)\nfigure = plt.figure(figsize=(10,10))\n\nGrap_Data.plot()","7d9d3b1b":"plt.plot(CNN_Model.history[\"accuracy\"])\nplt.plot(CNN_Model.history[\"val_accuracy\"])\nplt.ylabel(\"ACCURACY\")\nplt.legend()\nplt.show()","35e6275b":"plt.plot(CNN_Model.history[\"loss\"])\nplt.plot(CNN_Model.history[\"val_loss\"])\nplt.ylabel(\"LOSS\")\nplt.legend()\nplt.show()","7977cc8f":"Model_Results = Model.evaluate(Test_IMG_Set)\nprint(\"LOSS:  \" + \"%.4f\" % Model_Results[0])\nprint(\"ACCURACY:  \" + \"%.4f\" % Model_Results[1])","aedaff62":"#### ANIMAL PATH","b7cbfced":"#### CHECKING","c7fd0903":"#### HOW TO LOOK BY GENERATOR","835b1c9f":"#### ANIMAL LABELS","ebdf6437":"# HISTORY","348143b8":"# PACKAGES AND LIBRARIES","be7356ae":"#### SHUFFLE","02aae40d":"#### TO DATAFRAME","247fc35f":"# SPLITTING TEST AND TRAIN","b69f5e58":"# IMAGE GENERATOR PROCESS","2a33af54":"* The IUCN Red List of Threatened Species\u2122 is the world's most comprehensive inventory of the global conservation status of plant and animal species. It uses a set of quantitative criteria to evaluate the extinction risk of thousands of species.","6a5ea8d3":"#### STRUCTURE","c3f56d96":"# PATH, LABEL, TRANSFORMATION","80524752":"#### APPLY","22e509ef":"#### MAIN PATH","1204d548":"#### TO SERIES","a3236e4e":"# VISUALIZATION","69f3be6c":"# MODEL"}}