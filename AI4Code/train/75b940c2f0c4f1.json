{"cell_type":{"caef8ec1":"code","9fc4d8f0":"code","c0d0fdeb":"code","d4f46478":"code","509c7df7":"code","e877dc91":"code","db3783e8":"code","cc05d9b6":"code","702ee143":"code","c7c98171":"code","9f86d57b":"code","641a910a":"code","ff88c292":"code","17ac56de":"code","89a7645c":"code","513c8e49":"code","f01bc4f6":"code","d1b23123":"code","63745884":"code","4f1e08e7":"code","f9f35720":"code","47826215":"code","68c32674":"code","b2e1415a":"code","8909212f":"code","f7bc17c2":"code","8b656b58":"code","4e188151":"code","426e63cd":"code","a884469e":"code","fa09a2cd":"code","aab458bd":"code","3b3e0ae9":"code","15794250":"code","c74a0921":"markdown","db171ded":"markdown","a4982097":"markdown","1f88a00d":"markdown","6e929c5a":"markdown","97d1a909":"markdown","cb5c51a6":"markdown","b2b7b828":"markdown","fd26acd8":"markdown","240bc076":"markdown","b7700e1b":"markdown","12f70eed":"markdown","f53032b0":"markdown","f82835fd":"markdown","9f543481":"markdown","17065651":"markdown","d24e8922":"markdown","e99a2264":"markdown","cfa5ded3":"markdown","8975879e":"markdown","3e73e4be":"markdown","3d80158b":"markdown","0acc282a":"markdown","120b7824":"markdown","7f15095c":"markdown","3b2c2a11":"markdown","9c67be83":"markdown"},"source":{"caef8ec1":"import numpy as np # linear algebra\nimport pandas as pd # data processing\n%matplotlib inline\nimport matplotlib.pyplot as plt  # Matlab-style plotting\nimport seaborn as sns\ncolor = sns.color_palette()\nsns.set_style('darkgrid')\n\nfrom scipy import stats\nfrom scipy.stats import norm, skew # statistics\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","9fc4d8f0":"train = pd.read_csv('\/kaggle\/input\/ventes-fonciers-alpes-maritimes-1er-semestre\/data-ventes-fonciers.csv', sep=';')\ntrain.head()","c0d0fdeb":"indices = train[train['Code type local'] == 4.0].index\nprint(\"avant drop \", train.shape)\ntrain.drop(indices, inplace=True)\n\n# on reverifie\nprint(\"apres drop \", train.shape)","d4f46478":"indices = train[train['Code type local'] == 3.0].index\nprint(\"avant drop \", train.shape)\ntrain.drop(indices, inplace=True)\n\n# on reverifie\nprint(\"apres drop \", train.shape)","509c7df7":"# drop lignes, nb lots != 1 or 0\nindices = train[train['Nombre de lots'] > 1].index\nprint(\"avant drop nb lots\", train.shape)\ntrain.drop(indices, inplace=True)\n\n# on reverifie\nprint(\"apres drop nb lots\", train.shape)\n\n","e877dc91":"# lignes n'ayant pas de m^2 batie\nindices = train[train['Surface reelle bati'].isnull()].index\nprint(\"avant drop nb lots\", train.shape)\ntrain.drop(indices, inplace=True)\n\n# on reverifie\nprint(\"apres drop nb lots\", train.shape)\n","db3783e8":"# prix de vente\nindices = train[train['Valeur fonciere'].isnull()].index\nprint(\"avant drop nb lots\", train.shape)\ntrain.drop(indices, inplace=True)\n\nindices = train[train['Valeur fonciere'] <= 1000].index\ntrain.drop(indices, inplace=True)\n\n# on reverifie\nprint(\"apres drop nb lots\", train.shape)","cc05d9b6":"print(len(train.columns))\nprint(train.columns)\n","702ee143":"# drop colonnes inutiles\ntrain = train[['Valeur fonciere','Voie', 'Code postal', 'Code type local','Surface reelle bati', 'Nombre pieces principales', 'Surface terrain']]\ntrain.head()\n\n","c7c98171":"train['Valeur fonciere'].mean()","9f86d57b":"def div_ligne(valeur_fonciere):\n    return valeur_fonciere\/100\n\ntrain['Valeur fonciere'] = train['Valeur fonciere'].apply(div_ligne)\ntrain.head()","641a910a":"train['Valeur fonciere'].mean()","ff88c292":"train.isnull().sum().sum()","17ac56de":"nan_valeurs = train.isna()\nnan_col = nan_valeurs.any()\n\ncol_nan = train.columns[nan_col].tolist()\nprint(col_nan)","89a7645c":"train['Surface terrain'] = train['Surface terrain'].fillna(0)\ntrain.tail()","513c8e49":"train.isnull().sum().sum()","f01bc4f6":"train.shape","d1b23123":"train.duplicated().sum()","63745884":"# lignes dupliqu\u00e9\nindices = train[train.duplicated()].index\nprint(\"avant drop dupliqu\u00e9\", train.shape)\ntrain.drop(indices, inplace=True)\n\n# on reverifie\nprint(\"apres drop dupliqu\u00e9\", train.shape)","4f1e08e7":"corrmat = train.corr()\nplt.subplots(figsize=(12,9))\nsns.heatmap(corrmat, vmax=0.9, square=True)","f9f35720":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ntrain.Voie= le.fit_transform(train.Voie.values)","47826215":"train.head()","68c32674":"corrmat = train.corr()\nplt.subplots(figsize=(12,9))\nsns.heatmap(corrmat, vmax=0.9, square=True)","b2e1415a":"donnee_num = train.dtypes[train.dtypes != \"object\"].index\n\n\nvar_biasee = train[donnee_num].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nprint(\"\\nBias dans les donn\u00e9es: \\n\")\nbias = pd.DataFrame({'Bias' :var_biasee})\nbias.head(10)","8909212f":"#bias = bias[abs(bias) > 0.75]\n#print(\"Il y a {} vars \u00e0 transformer\".format(skewness.shape[0]))\n\n#from scipy.special import boxcox1p\n#var_biasee = bias.index\n#lam = 0.15\n#for var in var_biasee:\n#    train[var] = boxcox1p(train[var], lam)","f7bc17c2":"Y = train['Valeur fonciere']\nX = train[['Voie', 'Code postal', 'Code type local',\n       'Surface reelle bati', 'Nombre pieces principales', 'Surface terrain']]","8b656b58":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.15)","4e188151":"y_test.shape","426e63cd":"from sklearn.metrics import mean_absolute_error\n\ndef score_model(model):\n    model.fit(x_train, y_train)\n    predictions = model.predict(x_test)\n    return mean_absolute_error(y_test, predictions)","a884469e":"from sklearn.ensemble import RandomForestRegressor\nRFR_model = RandomForestRegressor(n_estimators=100, random_state=0)\nprint(score_model(RFR_model))","fa09a2cd":"from xgboost import XGBRegressor\nxgb_model = XGBRegressor(n_estimators=1000, learning_rate=0.05)\nprint(score_model(xgb_model))","aab458bd":"from lightgbm import LGBMRegressor\nlgbm_model = LGBMRegressor(objective='regression', num_leaves=5,learning_rate=0.007, n_estimators=3500,max_bin=163,\n                       bagging_fraction=0.35711,bagging_freq=4, bagging_seed=8,feature_fraction=0.1294, feature_fraction_seed=8,\n                       min_data_in_leaf = 8,  verbose=-1, random_state=42,n_jobs=-1)\nprint(score_model(lgbm_model))","3b3e0ae9":"xgb_model2 = XGBRegressor(\n    learning_rate=0.0139,\n    n_estimators=4500,\n    max_depth=4,\n    min_child_weight=0,\n    subsample=0.7968,\n    colsample_bytree=0.4064,\n    nthread=-1,\n    scale_pos_weight=2,\n    seed=42,\n)\nprint(score_model(xgb_model2))","15794250":"y_train.mean()","c74a0921":"Etonnament la surface a une plus grande importance que la ville","db171ded":"Cr\u00e9eons la fonction pour tester nos mod\u00e8les","a4982097":"On remarque que les prix sont pas exacts. Ceci est d\u00fb au fait que le point virgule n'est pas reconnu par pandas donc une valeur fonciere de 100000,00 s'affiche comme 100000000 donc il faudrait diviser toutes les lignes par 100 pour r\u00e9tablir l'exactitude","1f88a00d":"Notre meilleur mod\u00e8le est donc xgbRegressor mais avec un mae assez \u00e9lev\u00e9 de **26475**. \nEtant donn\u00e9e que le mod\u00e8le LGBMRegressor \u00e9tait assez proche du xgb on aurait pu regrouper les modeles et faire des prediction en donnant plus de poids \u00e0 l'XGBRegressor.\nDans l'ensemble le processus de data cleaning est \u00e0 ameilorer.","6e929c5a":"Il y a encore beaucoup de donn\u00e9es manquantes. Verifions dans quelles colonnes se situent les NaN","97d1a909":"**Ameiloration possible**\n\nutiliser le code voie fantoir, ce code pourra remplacer l'adresse. Mais il n'existe pas d'api pour rentrer l'adresse et obtenir le code fantoir donc cela nous rajouterai beaucoup de travail.","cb5c51a6":"on enleve les donn\u00e9es dupliqu\u00e9","b2b7b828":"Verifions le nb de NaN","fd26acd8":"**Boosting de gradient**","240bc076":"## Testons quelques mod\u00e8les","b7700e1b":"Pas surprenant car les appartements n'ont pas de terrain.\nLa chose logique sera de remplacer les NaN par 0.","12f70eed":"Regardons la correlation entres les variables","f53032b0":"Appliquons la transformation [box cox](http:\/\/onlinestatbook.com\/2\/transformations\/box-cox.html) de 1+x","f82835fd":"separons donn\u00e9es d'entrainement et les donn\u00e9es que nous allons utiliser pour tester","9f543481":"* On ne va garder seulement les type appart et maison pour cette analyse","17065651":"Regardons maintenant le taux de bias dans les variables","d24e8922":"On va voir tous les colonnes afin de voir s'il y en a qu'on pourra enlever encore","e99a2264":"* nous ne prenons que les ventes dont le nb de lots est 0 ou 1, car le dataset affiche le m\u00eame prix globale \u00e0 chaque lot\n* on drop les lignes n'ayant pas de \u33a1 batie\n* on drop les lignes ayant un prix de vente different de zero\n","cfa5ded3":"# Modelling","8975879e":"On donnes des labels numerique aux voies pour faciliter la tache du modele.","3e73e4be":"On remarque que la plupart sont inutiles\non ne va donc garder que : \n* Valeur fonciere\n* Voie\n* Code postal\n* Code type local\n* Surface r\u00e9elle batie\n* Nombre pieces\n* Surface terrain","3d80158b":"# Feature Engineering","0acc282a":"On lit notre fichier csv et on visualise le df","120b7824":"**Random Forest**","7f15095c":"# **Data Cleaning**\n","3b2c2a11":"# Conclusion","9c67be83":"reverifions le nb de NaN"}}