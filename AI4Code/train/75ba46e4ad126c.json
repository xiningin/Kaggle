{"cell_type":{"38129fcb":"code","43699a0d":"code","9ffb7847":"code","7a0298e4":"code","20981339":"code","c1bc6b91":"code","ec447ce9":"code","debbb9e9":"code","8cc3eec2":"code","8e90b1ef":"code","309fbf6d":"code","f23e160d":"code","e22ef1f4":"code","d6250991":"code","8ccfce4a":"code","d283cdb7":"code","e40dc12c":"markdown","c8956039":"markdown","2c652005":"markdown","bf29131d":"markdown","ee656e60":"markdown","079f1f1a":"markdown","175e284c":"markdown","d35dd5fa":"markdown","80a48384":"markdown","e5650ed8":"markdown"},"source":{"38129fcb":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\n\nplt.style.use('ggplot')","43699a0d":"def plot_history(history):\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    \n    x = range(1, len(acc) + 1)\n\n    plt.figure(figsize=(16, 5))\n\n    plt.subplot(1, 2, 1)\n    plt.plot(x, acc, label='training accuracy')\n    plt.plot(x, val_acc, label='validation accuracy')\n    plt.title('Accuracy')\n    plt.legend()\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(x, loss, label='training loss')\n    plt.plot(x, val_loss, label='validation loss')\n    plt.title('Loss')\n    plt.legend()","9ffb7847":"df_newsgroup = pd.read_csv('\/kaggle\/input\/20-newsgroup-preprocessed\/20newsgroup_preprocessed.csv', sep=';', usecols=['target', 'text_cleaned'])\ndf_newsgroup.rename(columns={'text_cleaned' : 'text'}, inplace=True)","7a0298e4":"le = LabelEncoder()\nle.fit(df_newsgroup['target'].unique())","20981339":"df_newsgroup['target'] = le.transform(df_newsgroup['target'])","c1bc6b91":"X = df_newsgroup['text'].astype(str)\ny = tf.keras.utils.to_categorical(df_newsgroup['target'], num_classes=df_newsgroup['target'].nunique())\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=df_newsgroup['target'])","ec447ce9":"tokenizer = tf.keras.preprocessing.text.Tokenizer()\ntokenizer.fit_on_texts(X_train)\n\nvocab_size = len(tokenizer.word_index) + 1","debbb9e9":"train_seq = tokenizer.texts_to_sequences(X_train)\ntest_seq = tokenizer.texts_to_sequences(X_test)","8cc3eec2":"max_length = len(max(train_seq, key=len))\n\ntrain_vector = tf.keras.preprocessing.sequence.pad_sequences(train_seq, maxlen=max_length, padding='post', truncating='post')\ntest_vector = tf.keras.preprocessing.sequence.pad_sequences(test_seq, maxlen=max_length, padding='post', truncating='post')","8e90b1ef":"class StopTrainOnHighAccuracy(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        acc_threshold = 0.9\n        if logs.get('accuracy') > acc_threshold:\n            print(f\"\\nReached {acc_threshold} accuracy, cancelling training\")\n            self.model.stop_training = True\n\ndef model(vocab_size, max_length):\n    model = tf.keras.models.Sequential([\n        tf.keras.layers.Embedding(vocab_size, 64, input_length=max_length),\n        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n        tf.keras.layers.Dense(64, activation='relu'),\n        tf.keras.layers.Dropout(0.5),\n        tf.keras.layers.Dense(20, activation='softmax')\n    ])\n    \n    return model\n    \nmodel = model(vocab_size, max_length)\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()","309fbf6d":"history = model.fit(train_vector, y_train, epochs=10, validation_data=(test_vector, y_test), callbacks=[StopTrainOnHighAccuracy()])","f23e160d":"loss, accuracy = model.evaluate(train_vector, y_train, verbose=False)\nprint(\"Training Accuracy: {:.4f}\".format(accuracy))\n\nloss, accuracy = model.evaluate(test_vector, y_test, verbose=False)\nprint(\"Testing Accuracy:  {:.4f}\".format(accuracy))","e22ef1f4":"plot_history(history)","d6250991":"predictions = model.predict_classes(test_vector)\nground_truth = np.argmax(y_test, axis=1)","8ccfce4a":"list_precision = []\nlist_recall = []\nlist_f1 = []\nfor precision, target_class in zip(precision_score(ground_truth, predictions, labels=le.transform(le.classes_), average=None), le.classes_):\n    list_precision.append({'target' : target_class, 'precision' : precision})\n    \nfor recall in recall_score(ground_truth, predictions, labels=le.transform(le.classes_), average=None):\n    list_recall.append(recall)\n    \nfor recall in f1_score(ground_truth, predictions, labels=le.transform(le.classes_), average=None):\n    list_f1.append(recall)\n        \ndf_metrics = pd.DataFrame(list_precision)\ndf_metrics['recall'] = list_recall\ndf_metrics['f1_score'] = list_f1","d283cdb7":"df_metrics = round(df_metrics, 2)\ndf_metrics.sort_values('f1_score', ascending=False)","e40dc12c":"## Model","c8956039":"## Evaluate","2c652005":"## Encode classes","bf29131d":"### Validation","ee656e60":"## Tokenize words","079f1f1a":"## Read dataset","175e284c":"## Padding","d35dd5fa":"## Text to sentence","80a48384":"### Train","e5650ed8":"## Divide dataset in train and test"}}