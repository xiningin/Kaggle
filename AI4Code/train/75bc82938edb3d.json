{"cell_type":{"070c6419":"code","6b67a7ef":"code","e2f6db07":"code","fcca5e55":"code","68683091":"code","312fb504":"code","6ce9bf8b":"code","ca5ccff5":"code","fe27e7f2":"code","e8e0b788":"code","11fdc927":"code","96864ce0":"code","02f06b3b":"code","f486e01f":"code","cd98e8b9":"code","55d16a11":"code","9896636e":"code","18aaced3":"code","53ec756d":"code","1f0a9aa3":"code","8a33deb3":"code","bd18407b":"code","78ab1586":"code","10c2e06d":"code","bebafa25":"code","d957f789":"markdown","986cb646":"markdown","6b5c9b55":"markdown","5649ee4a":"markdown","9e7a5b5d":"markdown","5f722365":"markdown","88de72de":"markdown","017d31b4":"markdown","3aeb36b8":"markdown","f835dc18":"markdown","2e545599":"markdown","af368815":"markdown","bcc6f71e":"markdown","7a6857e5":"markdown","9f319a21":"markdown","003eeb19":"markdown","d36a2b75":"markdown","5d8b3463":"markdown","9fff6a24":"markdown","d19fe826":"markdown","9ca0421f":"markdown","8b4dc911":"markdown","acc740dc":"markdown"},"source":{"070c6419":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","6b67a7ef":"data = pd.read_csv(\"..\/input\/column_2C_weka.csv\")","e2f6db07":"data.head()","fcca5e55":"data.info()","68683091":"A = data[data[\"class\"] == 'Abnormal']\nN = data[data[\"class\"] == 'Normal']","312fb504":"A.drop([\"class\"],axis = 1,inplace = True)\nN.drop([\"class\"],axis = 1,inplace = True)","6ce9bf8b":"A = (A-np.min(A))\/(np.max(A)-np.min(A))\nN = (N-np.min(N))\/(np.max(N)-np.min(N))","ca5ccff5":"plt.scatter(A.pelvic_incidence ,A[\"pelvic_tilt numeric\"] , color = 'red')\nplt.scatter(N.pelvic_incidence ,N[\"pelvic_tilt numeric\"] , color = 'green')\nplt.xlabel(\"pelvic tilt\")\nplt.ylabel(\"pelvic incidence\")\nplt.show()","fe27e7f2":"sns.countplot(x = \"class\", data = data)\ndata[\"class\"].value_counts()","e8e0b788":"data[\"class\"].replace([\"Normal\",\"Abnormal\"],[1,0],inplace = True)","11fdc927":"y = data[\"class\"].values\nx_data = data.drop([\"class\"],axis = 1)\nx = (x_data-np.min(x_data))\/(np.max(x_data)-np.min(x_data))","96864ce0":"from sklearn.model_selection import train_test_split \nx_train,x_test,y_train, y_test = train_test_split(x,y,test_size = 0.33 ,random_state = 42)","02f06b3b":"x_list =[]\ny_list =[]","f486e01f":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(x_train,y_train)\nprediction = lr.predict(x_test)\nprint(\"Logistic regression score :\",lr.score(x_test,y_test))\nx_list.append(\"Logistic regression\")\ny_list.append(lr.score(x_test,y_test))","cd98e8b9":"from sklearn.neighbors import KNeighborsClassifier\nkn =KNeighborsClassifier(n_neighbors=4)\nkn.fit(x_train,y_train)\nprint(\"Knn classification score :\",kn.score(x_test,y_test))\nscore=[]\nfor i in range(1,20):\n    kn2 = KNeighborsClassifier(n_neighbors=i)\n    kn2.fit(x_train,y_train)\n    score.append(kn2.score(x_test,y_test))\nplt.plot(score)\nx_list.append(\"Knn classification\")\ny_list.append(kn.score(x_test,y_test))","55d16a11":"from sklearn.svm import SVC\nsvm =SVC(random_state=1)\nsvm.fit(x_train,y_train)\nprint(\"svm score : \",svm.score(x_test,y_test))\nx_list.append(\"SVM\")\ny_list.append(svm.score(x_test,y_test))","9896636e":"from sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(x_train,y_train)\nprint(\"Naive bayes score : \",nb.score(x_test,y_test))\nx_list.append(\"Naive Bayes Classification\")\ny_list.append(nb.score(x_test,y_test))","18aaced3":"from sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier()\ndt.fit(x_train,y_train)\nprint(\"desicion tree score : \",dt.score(x_test,y_test))\nx_list.append(\"Desicion tree\")\ny_list.append(dt.score(x_test,y_test))","53ec756d":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=50 , random_state=1)\nrf.fit(x_train,y_train)\nprint(\"random forest score : \",rf.score(x_test,y_test))\nx_list.append(\"Random forest\")\ny_list.append(rf.score(x_test,y_test))","1f0a9aa3":"y_true = y_test\ny_pred = rf.predict(x_test)","8a33deb3":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_true,y_pred)\n\nf,ax = plt.subplots(figsize =(5,5))\nsns.heatmap(cm,annot=True,linewidths =0.5,linecolor = \"red\",fmt = \".0f\",ax = ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nplt.show()\n\n","bd18407b":"scores = zip(x_list,y_list)\nmapped =list(scores)\ndf = pd.DataFrame(mapped,columns =[\"label\",\"result\"])\ndf","78ab1586":"new_df = df[\"result\"].sort_values(ascending = False).index.values\nsorted_df = df.reindex(new_df)","10c2e06d":"sorted_df","bebafa25":"# plot figure\nplt.figure(figsize = (10,6))\nplt.plot(sorted_df.label,sorted_df.result)\nplt.xlabel(\"Score\")\nplt.ylabel(\"Algorithms\")\nplt.xticks(rotation = 90)\nplt.show()","d957f789":"## Naive Bayes Classification (4)","986cb646":"# Contents","6b5c9b55":"# Explanation","5649ee4a":"## Logistic_regression (1)","9e7a5b5d":"### 2) Normalization","5f722365":"### 4) Preprocessing","88de72de":"### 5) Classification Algorithms","017d31b4":"# 3) Visualize data","3aeb36b8":"# 5) Classification Algorithms","f835dc18":"### Evaluating  Models","2e545599":"# 7) Conclusion\nDesicion tree algorithm gives the highest results among the classification methods","af368815":"### 6) Results and Conclusion","bcc6f71e":"## 6) Results","7a6857e5":"In this kernel I compared classification methos which are consist of KNN,Logistic regression ,SVM,Naive Bayes,Desicion tree, Random Forest algorithms.","9f319a21":"### 1) Data manipulation","003eeb19":"## Support vector machine classification (SVM) (3)","d36a2b75":"## Desicion tree algorithm (5)","5d8b3463":"# 1) Data Manipulation","9fff6a24":"# 4) Preprocessing ","d19fe826":"## KNN Classification (2)","9ca0421f":"## Random forest algorithm (6)","8b4dc911":"# 2) Normalization","acc740dc":"### 3) Visualization"}}