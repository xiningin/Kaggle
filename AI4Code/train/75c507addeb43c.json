{"cell_type":{"ddf031aa":"code","8e64eee8":"code","c14f220b":"code","86c8404f":"code","b1bd4969":"code","7b0e4466":"code","af9bc247":"code","132601d1":"code","8eabf167":"code","e16ce0ec":"code","fbe8c6dd":"code","47632a6d":"code","185b13d9":"code","5e5add52":"code","3d6e74be":"code","b1c4b618":"code","1a958121":"code","41903f94":"code","d7b365dd":"code","715f447f":"code","0dc5c255":"code","7e0aecdc":"code","76b23a4a":"code","8dab700c":"code","a260840f":"code","e3406a53":"code","bb160a07":"code","4e6b6dcf":"code","5403e5e6":"code","69b6d782":"code","41f37db0":"code","ed2b0108":"code","fee591a2":"code","754b2647":"code","15185e85":"code","7b7b4087":"code","7d5dce90":"code","219a4639":"code","a2cef575":"code","096c661e":"code","bdf9c920":"code","8106ffc4":"code","a1a346cb":"code","059b2c19":"code","500deefa":"code","1948a2ac":"code","6614ad37":"code","968b560f":"code","34ccddac":"code","68212652":"code","c55daf1b":"code","40a69ff7":"code","0cbe2143":"markdown","da0dc951":"markdown","97be742f":"markdown","eeb0e79c":"markdown","3a9e3853":"markdown","a2b8fcc0":"markdown","6c8974aa":"markdown","904abe25":"markdown"},"source":{"ddf031aa":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\npd.set_option('display.max_columns', 200)\npd.set_option('display.max_rows', 1000)\npd.set_option('display.max_colwidth', -1)","8e64eee8":"import matplotlib.pyplot as plt   \n\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\n\nfrom sklearn.linear_model import ElasticNet\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import preprocessing\nimport math\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import r2_score\nfrom sklearn import linear_model\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import Ridge\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn import dummy\nfrom sklearn.dummy import DummyRegressor\n\nimport time\nimport datetime\n\nimport string\n\npd.set_option('display.max_columns', 200)\npd.set_option('display.max_rows', 1000)\npd.set_option('display.max_colwidth', -1)","c14f220b":"train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntrain.head()","86c8404f":"train.shape","b1bd4969":"train_target = train[['Id', 'SalePrice']]","7b0e4466":"train_red = train.copy().drop(['SalePrice'], axis=1)","af9bc247":"train_red[\"Provenance\"] =  \"train_set\"","132601d1":"train_red.head()","8eabf167":"validation = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","e16ce0ec":"validation[\"Provenance\"] = 'val_set' ","fbe8c6dd":"data = pd.concat([train_red, validation] )","47632a6d":"data.shape","185b13d9":"print('dimension de la base de train', train.shape)\nprint('dimension de la base de test', validation.shape)\nprint('dimension de la base d ensemble', data.shape)","5e5add52":"def nettoyage(data): \n\n\n    liste_colonnes = []\n    serie_nan = data.isna().sum()\/data.shape[0] < .8\n\n    for colonne, booleen in zip(serie_nan.index, serie_nan.values):\n        if booleen :\n            liste_colonnes.append(colonne)\n    \n    data = data[liste_colonnes]\n    \n    data['FireplaceQu'] = np.where(data['FireplaceQu'].isnull() == True, \"NA\", data['FireplaceQu'])\n    data['Utilities'] = np.where(data['Utilities'].isnull() == True, \"NA\", data['Utilities'])\n    \n    data['LotFrontage'] = np.where(data['LotFrontage'].isnull() == True, data['LotFrontage'].median(), data['LotFrontage'])\n    \n    data['GarageType'] = np.where(data['GarageType'].isnull() == True, \"No Garage\", data['GarageType'])\n    data['GarageYrBlt'] = np.where(data['GarageYrBlt'].isnull() == True, \"0\", data['GarageYrBlt'])\n    data['GarageFinish'] = np.where(data['GarageFinish'].isnull() == True, \"No Garage\", data['GarageFinish'])\n    data['GarageQual'] = np.where(data['GarageQual'].isnull() == True, \"No Garage\", data['GarageQual'])\n    data['GarageCond'] = np.where(data['GarageCond'].isnull() == True, \"No Garage\", data['GarageCond'])\n\n    data['BsmtExposure'] = np.where(data['BsmtExposure'].isnull() == True, \"NA\", data['BsmtExposure'])\n    data['BsmtFinType2'] = np.where(data['BsmtFinType2'].isnull() == True, \"NA\", data['BsmtFinType2'])\n    data['BsmtFinType1'] = np.where(data['BsmtFinType1'].isnull() == True, \"NA\", data['BsmtFinType1'])\n    data['BsmtCond'] = np.where(data['BsmtCond'].isnull() == True, \"NA\", data['BsmtCond'])\n    data['BsmtQual'] = np.where(data['BsmtQual'].isnull() == True, \"NA\", data['BsmtQual'])\n\n    data['MasVnrType'] = np.where(data['MasVnrType'].isnull() == True, \"None\", data['MasVnrType'])\n    data['MasVnrArea'] = np.where(data['MasVnrArea'].isnull() == True, \"0\", data['MasVnrArea'])\n    \n    data[\"MasVnrArea\"] = data[\"MasVnrArea\"].astype('float64')\n    data[\"GarageYrBlt\"] = data[\"GarageYrBlt\"].astype('float64')  \n\n    data['MSZoning'] = np.where(data['MSZoning'].isnull() == True, \"NA\", data['MSZoning'])\n\n\n    data['MSZoning'] = np.where(data['MSZoning'].isnull() == True, \"NA\", data['MSZoning'])\n\n\n    data['Functional'] = np.where(data['Functional'].isnull() == True, \"NA\", data['Functional'])\n    data['BsmtFullBath'] = np.where(data['BsmtFullBath'].isnull() == True, 0, data['BsmtFullBath'])\n    data['BsmtHalfBath'] = np.where(data['BsmtHalfBath'].isnull() == True, 0, data['BsmtHalfBath'])\n    data['GarageArea'] = np.where(data['GarageArea'].isnull() == True, 0, data['GarageArea'])\n    data['BsmtFinSF2'] = np.where(data['BsmtFinSF2'].isnull() == True, 0, data['BsmtFinSF2'])\n    data['BsmtUnfSF'] = np.where(data['BsmtUnfSF'].isnull() == True, 0, data['BsmtUnfSF'])\n\n\n    data['TotalBsmtSF'] = np.where(data['TotalBsmtSF'].isnull() == True, 0, data['TotalBsmtSF'])\n    data['Electrical'] = np.where(data['Electrical'].isnull() == True, \"NA\", data['Electrical'])\n    data['Exterior2nd'] = np.where(data['Exterior2nd'].isnull() == True, \"NA\", data['Exterior2nd'])\n    data['Exterior1st'] = np.where(data['Exterior1st'].isnull() == True, \"NA\", data['Exterior1st'])\n    data['KitchenQual'] = np.where(data['KitchenQual'].isnull() == True, \"NA\", data['KitchenQual'])\n\n\n    data['GarageCars'] = np.where(data['GarageCars'].isnull() == True, 0, data['GarageCars'])\n    data['BsmtFinSF1'] = np.where(data['BsmtFinSF1'].isnull() == True, 0, data['BsmtFinSF1'])\n    data['SaleType'] = np.where(data['SaleType'].isnull() == True, \"NA\", data['SaleType'])\n\n   \n    return data ","3d6e74be":"data_nan = data.isna().sum().sort_values(ascending=False).head(20)\n","b1c4b618":"plt.figure(figsize=(10,8))\nplt.title('Proportion de NaN par variable (%)')\nsns.barplot(x=data_nan.values\/data.shape[0]*100, y= data_nan.index)","1a958121":"for colonne in data.columns:\n    print('\\n',colonne)\n    \n    print('Nb de NaN : ', data[colonne].isna().sum())\n    print('Pct NaN : ', round(data[colonne].isna().sum()\/data[colonne].shape[0]*100), '%')\n    print('Uniques : ', data[colonne].nunique())","41903f94":"data_cleaned = nettoyage(data)\n\nprint('dimension validation', data_cleaned.shape)","d7b365dd":"data_cleaned.shape","715f447f":"data_cleaned.isna().sum().sort_values(ascending=False).head(20)\n","0dc5c255":"%matplotlib inline\nfor column in data_cleaned.select_dtypes(include = ['int32', 'int64', 'float64']).columns:\n    f, axes = plt.subplots(1,2, figsize=(12,4))\n    titre = 'Distribution de ' + str(column)\n    plt.title(titre)\n    sns.distplot(data_cleaned[column], bins=30, ax=axes[0])\n    titre = 'Distribution de ' + str(column)\n    plt.title(titre)\n    sns.boxplot(data_cleaned[column], ax=axes[1])\n    plt.show()","7e0aecdc":"data_corr=data_cleaned.corr()\nf,ax=plt.subplots(figsize=(10,9))\nsns.heatmap(data_corr, vmin=-1, cmap='coolwarm')\nplt.title(\"Correlations de Pearson entre les diff\u00e9rentes variables \\n\", \n          weight='bold', \n          fontsize=18)\nplt.show()","76b23a4a":"sns.distplot(train[\"SalePrice\"])\nplt.title('R\u00e9partition du prix de vente ')","8dab700c":"test_log = np.log(train[[\"SalePrice\"]])\ntest1p = np.log1p(train[[\"SalePrice\"]])\ntest2 = np.log2(train[[\"SalePrice\"]])\ntest2p = np.log2(1+train[[\"SalePrice\"]])","a260840f":"plt.title('Distribution de la variable cible apr\u00e8s transformation log (r\u00e9sersible)')\nsns.distplot(test_log)\nsns.distplot(test1p)\nsns.distplot(test2)\nsns.distplot(test2p)\nax = plt.gca()\nax.legend(['log','log1p', 'log2', 'log2p'])","e3406a53":"train_target[\"log2p_SalePrice\"] = np.log2(1+train_target[[\"SalePrice\"]])","bb160a07":"def preparation(features):\n        for column in features.select_dtypes(include = ['object','category']):\n            features = pd.concat([features,pd.get_dummies(features[column], prefix=column)], axis=1)\n            features.drop(column, axis=1, inplace=True)\n        return features","4e6b6dcf":"data_prepa = preparation(data_cleaned)","5403e5e6":"data_prepa.head()","69b6d782":"train_set = data_prepa.loc[data_prepa['Provenance_train_set'] == 1]\nvalidation_set = data_prepa.loc[data_prepa['Provenance_val_set'] == 1]","41f37db0":"train_set.head()","ed2b0108":"train_set = train_set.copy().drop([\"Provenance_train_set\",  'Provenance_val_set'], axis=1)","fee591a2":"train_set = pd.merge(train_set, train_target, how=\"inner\", on=['Id'])\n","754b2647":"validation_set = validation_set.copy().drop([\"Provenance_train_set\",  'Provenance_val_set'], axis=1)","15185e85":"X = train_set.copy().drop([\"log2p_SalePrice\",  'SalePrice'], axis=1)\ny = train_set[{\"log2p_SalePrice\"}]","7b7b4087":"#Cr\u00e9attion de la base de train et de test \nX_train, X_test, y_train, y_test = \\\n                        train_test_split(X, \n                                        y[\"log2p_SalePrice\"],  \n                                         test_size = 0.2, \n                                         random_state = 42)\n","7d5dce90":"print('Dimension de la base de X_train :', X_train.shape )\nprint('Dimension de la base de X_test :', X_test.shape ,'\\n')\n\nprint('Dimension de la base de y_train :', y_train.shape )\nprint('Dimension de la base de y_test :', y_test.shape )","219a4639":"std_scale = preprocessing.StandardScaler().fit(X_train)\nX_train_std = std_scale.transform(X_train)\nX_test_std = std_scale.transform(X_test)","a2cef575":"def fit_models(models, params):\n    for model_name, model in models.items():\n        print(model_name , \"est en cours ....\")\n        start_time = time.time()\n        \n        model.fit(X_train_std, y_train)\n        \n        training_duration = time.time() - start_time\n   \n        cv = GridSearchCV(model, params.get(model_name))\n        cv.fit(X_train_std, y_train)\n    \n        \n         # Train prediction\n        y_train_pred = cv.predict(X_train_std)\n      \n        # Test prediction\n        y_test_pred = cv.predict(X_test_std)\n     \n        #Meilleurs param\u00e8tres \n        best_params = cv.best_params_\n        \n        RMSE_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n        r2_train = r2_score(y_train, y_train_pred)\n        \n        RMSE_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n        r2_test = r2_score(y_test, y_test_pred)\n\n    \n        training_results.append({\n            \"model_name\": type(model).__name__,\n           \n            'RMSE_train' : round(RMSE_train,4),\n            'r2_train' : round(r2_train,4),\n\n            'RMSE_test' : round(RMSE_test,4),\n            'r2_test' : round(r2_test ,4),\n            \"training_duration (secs)\": round(training_duration, 4),\n            \"best_params\" : best_params\n              })","096c661e":"# define the models\n\nmodels = {\n    'Dummy': DummyRegressor(),\n    'Linear': LinearRegression(),\n    'Ridge' : linear_model.Ridge(),\n    'Lasso' : linear_model.Lasso(),\n    'EN' : ElasticNet(), \n    'SVR' : SVR( ),\n    'RFR' : RandomForestRegressor(),\n    'XGB': XGBRegressor()  \n}","bdf9c920":"parameters = { 'Dummy': {},\n           'Linear': {},              \n           'Ridge': {'tol' : [0.1,0.01,0.001,0.0001],\"alpha\": np.logspace(-5, 10, 10),},\n           'Lasso': {'tol' : [0.1,0.01,0.001,0.0001],\"alpha\": np.logspace(-5, 10, 10),},\n            'EN': {'tol' : [0.1,0.01,0.001,0.0001],\"alpha\": np.logspace(-5, 10, 10), \"l1_ratio\": np.arange(0.0, 1.0, 0.1)},\n            'SVR': { 'C' : np.logspace(-5, 5, 5),'tol' : [0.1,0.01,0.001,0.0001],}, \n            'RFR' :{'n_estimators' : [10, 50, 100, 500],'min_samples_leaf' : [1,3,5,10],  \n                  'min_samples_split': [2],'max_features': ['auto'], 'max_depth': [None], },\n            'XGB' :  {'n_estimators' : [100,500,1000,2000],'min_child_weight' : [1],'max_depth' :[5],}\n        }","8106ffc4":"training_results = []\n\n%time fit_models(models, parameters,)\ntraining_results = pd.DataFrame(training_results)","a1a346cb":"training_results","059b2c19":"training_results.sort_values(by=\"RMSE_test\", ascending=True)\n","500deefa":"plt.figure(figsize=(10,7))\nplt.title(\"r\u00e9partition RMSE\")\nchart = sns.barplot(x = training_results.loc[training_results['model_name'] != 'LinearRegression']['model_name'] ,\n           y = training_results['RMSE_test'])\nchart.set_xticklabels(labels = training_results.loc[training_results['model_name'] != 'LinearRegression']['model_name'] , \n                      rotation=45,\n                      horizontalalignment='right',\n                      size=12,\n                     )\nax = plt.gca()\n\nplt.show()\n\n","1948a2ac":"plt.figure(figsize=(10,7))\nplt.title(\"r\u00e9partition R2\")\nchart = sns.barplot(x = training_results.loc[training_results['model_name'] != 'LinearRegression']['model_name'] ,\n           y = training_results['r2_test'])\nchart.set_xticklabels(labels = training_results.loc[training_results['model_name'] != 'LinearRegression']['model_name'], \n                      rotation=45,\n                      horizontalalignment='right',\n                      size=12,\n                     )\nax = plt.gca()\n\nplt.show()","6614ad37":"std_scale = preprocessing.StandardScaler().fit(validation_set)\nvalidation_std = std_scale.transform(validation_set)","968b560f":"best_XCGB =  XGBRegressor(max_depth= 5, min_child_weight= 1, n_estimators= 100)","34ccddac":"best_XCGB.fit(X_train_std, y_train)","68212652":"prediction =   best_XCGB.predict(validation_std)","c55daf1b":"validation_set['SalePrice'] = 2 **  prediction - 1","40a69ff7":"submission = validation_set[['Id', 'SalePrice']]\nsubmission.set_index(\"Id\", inplace = True)\nsubmission","0cbe2143":"## Mod\u00e8le Final ","da0dc951":"# Mod\u00e9lisation ","97be742f":"## Log of the target","eeb0e79c":"## Pr\u00e9processing ","3a9e3853":"# Data Importation ","a2b8fcc0":"# Visualisations \n\n## Univari\u00e9 ","6c8974aa":"## Multivari\u00e9e","904abe25":"## Mod\u00e9lisations"}}