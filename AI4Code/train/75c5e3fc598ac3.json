{"cell_type":{"1b34cc3a":"code","b56e87f0":"code","301fc4b4":"code","c1c12fa8":"code","c8c6ef8f":"code","26c078d8":"code","54604361":"code","a08db368":"code","0036132b":"code","1e814312":"code","12b6a296":"code","27c9719e":"code","47eb773d":"code","dcc3e5aa":"code","ce26b4ce":"code","1660138b":"code","52012e0c":"code","d5f97d34":"code","135fafab":"code","6dcc7894":"code","3f892138":"code","417ff18f":"code","45371746":"code","1c0ec632":"code","52fcabf1":"code","61777ece":"code","9d157d3a":"code","1fdb86d0":"code","2b4d23f6":"code","dd77c3a7":"code","3ac436cd":"code","9831d06f":"code","f6cb4592":"code","974c19ff":"code","4782242c":"markdown"},"source":{"1b34cc3a":"import numpy as np\nimport keras as K\nimport tensorflow as tf\nimport pandas as pd\nimport math\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.externals import joblib\n\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nseed = 78\ntest_size = 0.3\nfrom sklearn.metrics import accuracy_score\n\nfrom numpy import loadtxt\nfrom xgboost import XGBClassifier\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\nfrom keras import optimizers\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\nfrom keras import optimizers\nimport keras as K\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nseed = 78\ntest_size = 0.33\nimport os\n\n\ntrain = pd.read_csv(\"\/kaggle\/input\/datamaestro2020\/astro_train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/datamaestro2020\/astro_test.csv\")\nsample = pd.read_csv(\"\/kaggle\/input\/datamaestro2020\/sample_submission.csv\")","b56e87f0":"del train[\"id\"]\ndel test[\"id\"]\nY = train[\"class\"]\ndel train[\"class\"]\n\ndel train[\"rerun\"]\ndel test[\"rerun\"]\ndel train[\"skyVersion\"]\ndel test[\"skyVersion\"]\ndel train[\"run\"]\ndel test[\"run\"]\ndel train[\"camCol\"]\ndel test[\"camCol\"]\n\n### values donot change","301fc4b4":"train['dered_err_i'] = train[\"dered_i\"] * train[\"err_i\"]\ntrain['dered_err_z'] = train[\"dered_z\"] * train[\"err_z\"]\ntrain['dered_err_u'] = train[\"dered_u\"] * train[\"err_u\"]\ntrain['dered_err_g'] = train[\"dered_g\"] * train[\"err_g\"]\ntrain['dered_err_r'] = train[\"dered_r\"] * train[\"err_r\"]\n\ntest['dered_err_i'] = test[\"dered_i\"] * test[\"err_i\"]\ntest['dered_err_z'] = test[\"dered_z\"] * test[\"err_z\"]\ntest['dered_err_u'] = test[\"dered_u\"] * test[\"err_u\"]\ntest['dered_err_g'] = test[\"dered_g\"] * test[\"err_g\"]\ntest['dered_err_r'] = test[\"dered_r\"] * test[\"err_r\"]","c1c12fa8":"#train.describe()","c8c6ef8f":"#test complete :- no NULL enteries","26c078d8":"print(np.shape(train))\nprint(np.shape(test))","54604361":"from sklearn import preprocessing\ntrain = preprocessing.MinMaxScaler().fit_transform(train)\ntest = preprocessing.MinMaxScaler().fit_transform(test)\n\n","a08db368":"X_train, X_test, y_train, y_test = train_test_split(train, Y, test_size=0.3, random_state=2)\n\nmodel = XGBClassifier(silent=False, \n                      scale_pos_weight=1,\n                      learning_rate=0.01,  \n                      colsample_bytree = 0.4,\n                      subsample = 1,\n                      objective='multi:softmax', \n                      n_estimators=1000, \n                      reg_alpha = 0.3,\n                      max_depth=5, \n                      gamma=0.9,\n                      num_class = 3)\n\nmodel.fit(X_train, y_train)\n\n# make predictions for test data\ny_pred = model.predict(X_test)\npredictions = [round(value) for value in y_pred]\n#print(np.shape(predictions))\n\n# evaluate predictions\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","0036132b":"y_pred = model.predict(test)\npredictions = [round(value) for value in y_pred]\n\n\nsample_submission = pd.read_csv(\"\/kaggle\/input\/datamaestro2020\/sample_submission.csv\")\n\nsubmission_df = pd.DataFrame(columns=['id', 'class'])\nsubmission_df['id'] = sample_submission['id']\nsubmission_df['class'] = predictions\nsubmission_df.to_csv('XGB.csv', header=True, index=False)\nsubmission_df.head(100)","1e814312":"from sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import GridSearchCV","12b6a296":"from sklearn import preprocessing\ny_train = preprocessing.label_binarize(y_train, classes=[0, 1, 2])","27c9719e":"random_state=42\ngbr=GradientBoostingRegressor(random_state=random_state)\nparam_grid={ \n     \"learning_rate\": [0.01, 0.05 , 0.1 , 1],\n    \"max_depth\":[5, 11, 17, 25, 37, 53],\n    \"max_features\":[\"log2\",\"sqrt\"],\n    \"criterion\": [\"friedman_mse\",  \"mae\"],\n    \"n_estimators\":[10, 50, 200, 600, 1000]\n    }\n           \ngrid=GridSearchCV(gbr,param_grid = param_grid ,  verbose = 1, n_jobs = -1)\ngrid.fit(X_train,y_train)\n\nprint(\"Best Score:\" + str(grid.best_score_))\nprint(\"Best Parameters: \" + str(grid.best_params_))","47eb773d":"from keras.utils import to_categorical\n\nY = to_categorical(Y, num_classes = 3)","dcc3e5aa":"all_data=[train,test]\n\nfor dataset in all_data:\n    \n    dataset['dered_i_range'] = pd.cut(dataset['dered_i'], bins=[8.013940, 19.922500, 21.040150, 21.970625, 34.928800 ], labels=[0,1,2,3])\n    \n    dataset['dered_z_range'] = pd.cut(dataset['dered_z'], bins=[7.091240, 19.526400, 20.567300, 21.746125, 30.933600 ], labels=[0,1,2,3])\n    \n    dataset['dered_u_range'] = pd.cut(dataset['dered_u'], bins=[10.007800, 21.839075, 22.834600, 24.217250\t, 32.930400 ], labels=[0,1,2,3])\n    \n    dataset['dered_g_range'] = pd.cut(dataset['dered_g'], bins=[8.067590, 21.439600, 22.576600, 23.739500, 34.980600 ], labels=[0,1,2,3])\n\n    dataset['dered_r_range'] = pd.cut(dataset['dered_r'], bins=[7.067860, 20.527900, 21.713250, 22.691825, 33.911000 ], labels=[0,1,2,3])\n    \n    dataset['err_i_range'] = pd.cut(dataset['err_i'], bins=[0.000070, 0.100398, 0.258745, 0.519050, 2550.904800 ], labels=[0,1,2,3])\n    \n    dataset['err_z_range'] = pd.cut(dataset['err_z'], bins=[0.000030, 0.230547, 0.520850, 1.011320, 752.907850 ], labels=[0,1,2,3])\n    \n    dataset['err_u_range'] = pd.cut(dataset['err_u'], bins=[ 0.000260, 0.531480, 0.933175, 1.578488, 302297.250000 ], labels=[0,1,2,3])\n    \n    dataset['err_g_range'] = pd.cut(dataset['err_g'], bins=[0.000180,0.166480, 0.419025\t, 0.819457, 3688.869000 ], labels=[0,1,2,3])\n    \n    dataset['err_r_range'] = pd.cut(dataset['err_r'], bins=[0.000000, 0.106455, 0.288775, 0.582720, 2421.863800 ], labels=[0,1,2,3])\n    \n   \n    ","ce26b4ce":"train = pd.get_dummies(train, columns = [\"dered_i_range\",\"dered_z_range\",\"dered_u_range\",\"dered_g_range\",\"dered_r_range\", \"err_i_range\", \"err_z_range\",\"err_u_range\",\"err_g_range\",\"err_r_range\"],\n                             prefix=[ \"dered_i\",\"dered_z\",\"dered_u\",\"dered_g\",\"dered_r\",\"err_i\",\"err_z\",\"err_u\",\"err_g\",\"err_r\"])\n\ntest = pd.get_dummies(test, columns = [\"dered_i_range\",\"dered_z_range\",\"dered_u_range\",\"dered_g_range\",\"dered_r_range\", \"err_i_range\", \"err_z_range\",\"err_u_range\",\"err_g_range\",\"err_r_range\"],\n                             prefix=[ \"dered_i\",\"dered_z\",\"dered_u\",\"dered_g\",\"dered_r\",\"err_i\",\"err_z\",\"err_u\",\"err_g\",\"err_r\"])","1660138b":"del train[\"dered_i\"]\ndel test[\"dered_i\"]\ndel train[\"dered_z\"]\ndel test[\"dered_z\"]\ndel train[\"dered_u\"]\ndel test[\"dered_u\"]\ndel train[\"dered_g\"]\ndel test[\"dered_g\"]\ndel train[\"dered_r\"]\ndel test[\"dered_r\"]\n\ndel train[\"err_i\"]\ndel test[\"err_i\"]\ndel train[\"err_z\"]\ndel test[\"err_z\"]\ndel train[\"err_u\"]\ndel test[\"err_u\"]\ndel train[\"err_g\"]\ndel test[\"err_g\"]\ndel train[\"err_r\"]\ndel test[\"err_r\"]","52012e0c":"model = Sequential()\n\nmodel.add(Dense(activation=\"relu\", input_dim=26, units=32, kernel_initializer=\"uniform\"))\n#model.add(Dropout(0.2))\n\nmodel.add(Dense(activation=\"relu\", units= 24, kernel_initializer=\"uniform\"))\n#model.add(Dropout(0.2))\n\n#model.add(Dense(activation=\"relu\", units=18, kernel_initializer=\"uniform\"))\n#model.add(Dropout(0.2))\n\nmodel.add(Dense(activation=\"relu\", units=12, kernel_initializer=\"uniform\"))\n#model.add(Dropout(0.2))\n\n#model.add(Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\"))\n#model.add(Dropout(0.2))\n\nmodel.add(Dense(activation=\"relu\", units=3, kernel_initializer=\"uniform\"))\n#model.add(Dropout(0.2))\n\n\nmodel.add(Dense(activation=\"softmax\", units=3, kernel_initializer=\"uniform\"))","d5f97d34":"#K.optimizers.Adamax(learning_rate=0.0002, beta_1=0.9, beta_2=0.999)\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adamax',\n              metrics=['accuracy'])\n\nfrom keras.callbacks import ReduceLROnPlateau\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1,  factor=0.5,  min_lr=0.00001)\n\nmodel.summary()","135fafab":"model.fit(X_train, y_train, epochs=10, batch_size=8) #epochs = 500 for 70%","6dcc7894":"predictions = model.predict(test)\npredict_class = np.argmax(predictions, axis=1)\npredict_class = predict_class.tolist()\n\n\nsample_submission = pd.read_csv(\"\/kaggle\/input\/datamaestro2020\/sample_submission.csv\")\n\nsubmission_df = pd.DataFrame(columns=['id', 'class'])\nsubmission_df['id'] = sample_submission['id']\nsubmission_df['class'] = predict_class\nsubmission_df.to_csv('submissionsfinal.csv', header=True, index=False)\nsubmission_df.head(10)","3f892138":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","417ff18f":"X_train","45371746":"np.multiply(np.isnan(X_train))","1c0ec632":"# Fitting Random Forest Classification to the Training set\nclassifier = RandomForestClassifier(n_estimators = 300, criterion = 'entropy', random_state = 42)\nclassifier.fit(X_train, y_train)\n","52fcabf1":"y_pred = classifier.predict(X_test)\npredictions = [np.round(value) for value in y_pred]\n#print(np.shape(predictions))\n\n# evaluate predictions\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","61777ece":"classifier = RandomForestClassifier(n_estimators = 300, criterion = 'entropy', random_state = 42)\nclassifier.fit(train, Y)\n\ny_pred = classifier.predict(test)\npredictions = [np.round(value) for value in y_pred]\n\nsample_submission = pd.read_csv(\"\/kaggle\/input\/datamaestro2020\/sample_submission.csv\")\n\nsubmission_df = pd.DataFrame(columns=['id', 'class'])\nsubmission_df['id'] = sample_submission['id']\nsubmission_df['class'] = predictions\nsubmission_df.to_csv('submissionsfinal1.csv', header=True, index=False)\nsubmission_df.head(10)","9d157d3a":"from sklearn.model_selection import validation_curve\nparam_range = np.arange(1, 250, 2)\ntrain_scoreNum, test_scoreNum = validation_curve(\n                                RandomForestClassifier(),\n                                X = X_train, y = y_train, \n                                param_name = 'n_estimators', \n                                param_range = param_range, cv = 3)","1fdb86d0":"from keras.models import Sequential \nfrom keras.layers import Dense, Activation \noutput_dim = nb_classes = 10 \nmodel = Sequential() \nmodel.add(Dense(3, input_dim=16, activation='softmax')) \nbatch_size = 128 \nnb_epoch = 200","2b4d23f6":"model.compile(optimizer='Adamax', loss='categorical_crossentropy', metrics=['accuracy']) \nhistory = model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=3000,verbose=1, validation_data=(X_test, y_test)) \nscore = model.evaluate(X_test, y_test, verbose=0) \nprint('Test score:', score[0]) \nprint('Test accuracy:', score[1])","dd77c3a7":"from sklearn.naive_bayes import GaussianNB\n\n#Create a Gaussian Classifier\ngnb = GaussianNB()\n\n#Train the model using the training sets\ngnb.fit(X_train, y_train)\n\n#Predict the response for test dataset\ny_pred = gnb.predict(X_test)\n\n#Import scikit-learn metrics module for accuracy calculation\nfrom sklearn import metrics\n\n# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","3ac436cd":"from sklearn.ensemble import RandomForestRegressor\nmodel = RandomForestRegressor(n_estimators = 300, oob_score = True, n_jobs = -1,max_features = \"auto\", min_samples_leaf = 10)","9831d06f":"model.fit(X_train,y_train)","f6cb4592":"\npred=np.round(model.predict(X_test))\n#print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\npred","974c19ff":"print(\"Accuracy:\",metrics.accuracy_score(y_test, pred))","4782242c":"grid search\n\n\nhyper parameter tuning\n"}}