{"cell_type":{"eee76b83":"code","1cdfdcdc":"code","ecd9bbda":"code","39e47036":"code","b75bd2fa":"code","043d7108":"code","668041fa":"code","3fdd6e62":"code","872504c3":"code","81ee8af1":"code","88048bb6":"code","4b3338e5":"code","4d7e3a88":"markdown","9bef9ba1":"markdown","06070b96":"markdown","aabfae12":"markdown","418e861e":"markdown","787b9783":"markdown","7efd479a":"markdown","804530ab":"markdown","0f4ca9f0":"markdown","92f31f59":"markdown","02b19dd4":"markdown"},"source":{"eee76b83":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn import datasets\nfrom sklearn.preprocessing import StandardScaler\nimport iris_helper as H\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","1cdfdcdc":"iris = pd.read_csv(\"..\/input\/iris\/Iris.csv\")\nprint(iris.columns)\nprint(iris.describe())","ecd9bbda":"print(iris.head(1))","39e47036":"iris.drop(\"Id\", axis=1, inplace=True)\niris.head(1)","b75bd2fa":"X = iris.iloc[:,:4]\nlabels = iris.iloc[:,4].unique()\nspecies = dict()\nlabel = 0\nfor i in labels:\n    species[i] = label\n    label+=1\ny = iris.iloc[:,4].map(species)","043d7108":"X_train, X_test, y_train, y_test = H.create_test_set(X, y)\nX_train, X_dev, y_train, y_dev = H.create_dev_set(X_train, y_train)","668041fa":"sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_dev = sc.transform(X_dev)\nX_test = sc.transform(X_test)","3fdd6e62":"# run initial versions on training data\n\nresults=list()\ncolumns = [\"CVS_Mean\", \"CVS_Std (x1e-4)\", \"Time (ms)\"]\nindex = [\"Decision Tree\", \"Gaussian NB\", \"KNN\", \"Logistic Reg\", \"MLP\", \"Random Forest\", \"SVM\"]\nclf, _ = H.build_decision_tree()\nresults.append(H.initial_run(clf, X_train, y_train))\nclf, _ = H.build_gnb()\nresults.append(H.initial_run(clf, X_train, y_train))\nclf, _ = H.build_knn()\nresults.append(H.initial_run(clf, X_train, y_train))\nclf, _ = H.build_log_reg()\nresults.append(H.initial_run(clf, X_train, y_train))\nclf, _ = H.build_mlp()\nresults.append(H.initial_run(clf, X_train, y_train))\nclf, _ = H.build_random_forest()\nresults.append(H.initial_run(clf, X_train, y_train))\nclf, _ = H.build_svm()\nresults.append(H.initial_run(clf, X_train, y_train))\ninitial_run = pd.DataFrame(results, columns=columns, index=index)\nprint(initial_run)","872504c3":"## We run GridSearch on them to fine tune them\n\nbest_decision_tree = H.find_best_decision_tree(X_train, y_train)\nbest_svm = H.find_best_svm(X_train,y_train)\nbest_mlp = H.find_best_mlp(X_train,y_train)\nbest_gnb = H.find_best_gnb(X_train,y_train)","81ee8af1":"#\n### Now we see the performance of our fine tuned models on training and CV sets\n#\nresults=list()\ndel results\nresults=list()\ncolumns = [\"CVS_Mean\", \"CVS_Std (x1e-4)\", \"Time (ms)\"]\nindex = [\"Decision Tree\",\"SVM\", \"MLP\", \"GNB\"]\nresults.append(H.best_cvs(best_decision_tree, X_train, y_train))\nresults.append(H.best_cvs(best_svm, X_train, y_train))\nresults.append(H.best_cvs(best_mlp, X_train, y_train))\nresults.append(H.best_cvs(best_gnb, X_train, y_train))\nbest_cvs = pd.DataFrame(results, columns=columns, index=index)\nprint(best_cvs)","88048bb6":"#\n### We find the accuracy of our models on our dev set\n#\ncolumns = [\"Accuracy\", \"Time (us)\"]\nindex = [\"SVM\", \"MLP\", \"GNB\"]\ndel results\nresults = list()\nresults.append(H.find_accuracy(best_svm, X_dev, y_dev))\nresults.append(H.find_accuracy(best_mlp, X_dev, y_dev))\nresults.append(H.find_accuracy(best_gnb, X_dev, y_dev))\naccuracy = pd.DataFrame(results, columns=columns, index=index)\nprint(accuracy)","4b3338e5":"#\n### We find the accuracy of our models on our test set\n#\ncolumns = [\"Accuracy\", \"Time (us)\"]\nindex = [\"SVM\", \"MLP\", \"GNB\"]\ndel results\nresults = list()\nresults.append(H.find_accuracy(best_svm, X_test, y_test))\nresults.append(H.find_accuracy(best_mlp, X_test, y_test))\nresults.append(H.find_accuracy(best_gnb, X_test, y_test))\naccuracy = pd.DataFrame(results, columns=columns, index=index)\nprint(accuracy)","4d7e3a88":"We will now run Standard Scaler on our data.","9bef9ba1":"**Fine Tuning models on the training set**\n\nWe choose Decision Tree, MLP, SVM and Gaussian Naive Bayes for fine tuning usnig GridSearchCV as they have the highest CVS score.","06070b96":"We will split our dataset into 3 parts: Training, Dev and Test. Training set will have 100 samples, and Dev and Test will have 25 samples each.","aabfae12":"We will now take the first 4 columns into our numpy array for *X* and the last column into our numpy array *y*. *X* contains our features and *y* contains our label. Let's also map each of the flower species to a class.\n\nIris-setosa -> 0\n\nIris-versicolor -> 1\n\nIris-virginica -> 2","418e861e":"Here *Id* is the index and *Species* is the label. Let's look at the first row","787b9783":"**Initial Run**\n\nWe will now run initial versions of our models on training data. I chose the following 7 models:\n1. Decision Tree Classifier\n2. Gaussian Naive Bayes\n3. K Nearest Neighbors (KNN)\n4. Logistic Regression\n5. MLP Classifier\n6. Random Forest Classifier\n7. SVM Classifier\n\nWe will save the cross validation score of each one of them and display in a tabular format for easy analysis.","7efd479a":"**Initialize**\n\nLet's start with importing the dataset\n","804530ab":"**Conclusion**\n\nGaussian NB missed one sample, but SVM and MLP were spot on again. Since SVM is much faster than MLP while training, SVM can be preferred if the model needs to be re-trained frequently. Else, both are equally good.","0f4ca9f0":"We do not need the *Id* column. So let's drop it and see how our first row looks.","92f31f59":"**Accuracy on the dev set**\n\nSVM, MLP and Gaussian NB gave similar results, but Decision Tree Classifier performed quite poorly. So we then test the first three on the dev set, to see if there is any overfitting issue.","02b19dd4":"**Accuracy on the testing set**\n\nAll the samples in the dev set were predicted correctly. So we then move on to the test set."}}