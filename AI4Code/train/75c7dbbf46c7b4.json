{"cell_type":{"41e3eb4c":"code","6625dc5d":"code","02c771eb":"code","85f068fb":"code","0be1e56d":"code","a1c464e0":"code","19f8fb9b":"code","8a696317":"code","9402d0bf":"code","d38a4493":"code","a76ee75f":"code","2272dbd0":"code","caa20134":"code","e22fea4b":"code","fadbff88":"markdown"},"source":{"41e3eb4c":"import os\n\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\n\ntf.config.experimental.list_physical_devices()","6625dc5d":"#Decoder for Image\ndef build_decoder(with_labels = True , size=300):\n        \n        def decode(path):\n            \n            file_path = tf.io.read_file(path)\n            img = tf.image.decode_jpeg(file_path, channels=3)\n            \n            img = tf.cast(img, tf.float32) \/ 255.0\n            img = tf.image.resize(img,(size,size))\n            \n            return img\n        \n        def decode_with_labels(path, label):\n            return decode(path), label\n        \n        return decode_with_labels if with_labels else decode\n\ndef build_augmenter(with_labels = True):\n    def img_aug(img):\n        img = tf.image.random_jpeg_quality(img,75,95)\n        img = tf.image.random_flip_left_right(img)\n        img = tf.image.random_flip_up_down(img)\n        img = tf.image.random_brightness(img,0.1)\n        return img\n    def aug_with_labels(img,labels):\n        return img_aug(img) , labels\n    \n    return aug_with_labels if with_labels else img_aug(img)\n\n#Builder for Dataset    \ndef builder(target,labels=None,bsize=16,decoder=None,augment=True,cache_dir=\"\",cache=True):\n    \n    if cache_dir != \"\" and cache == True:\n        os.makedirs(cache_dir,exist_ok=True)\n        \n    if decoder is None :\n        decoder = build_decoder(decoder is not None)\n    if augment is True :\n        augmenter = build_augmenter(with_labels = True)\n    auto = tf.data.experimental.AUTOTUNE\n    slices = target if labels is None else (target , labels)\n    \n    dset = tf.data.Dataset.from_tensor_slices(slices)\n    dset = dset.map(decoder , num_parallel_calls=auto)\n    dset = dset.cache(cache_dir) if cache else dset\n    dset = dset.map(augmenter, num_parallel_calls=auto) if augment else dset\n    dset = dset.batch(bsize).prefetch(auto)\n    \n    return dset","02c771eb":"train_dir = r\"\/kaggle\/input\/ranzcr-clip-catheter-line-classification\/train\/\"\ntest_dir = r\"\/kaggle\/input\/ranzcr-clip-catheter-line-classification\/test\/\"\n\ntrain_df = pd.read_csv(\"\/kaggle\/input\/ranzcr-clip-catheter-line-classification\/train.csv\")\nsample_df = pd.read_csv(\"\/kaggle\/input\/ranzcr-clip-catheter-line-classification\/sample_submission.csv\")\nprint(\"Train Shape : \",train_df.shape)\nprint(train_df.nunique())\ntrain_df.head()","85f068fb":"#Change StudyInstanceUID to match file name for flow_from_dataframe\nif not \".jpg\" in train_df.iloc[0,0]:\n    train_df.iloc[:,0] = train_dir + train_df[\"StudyInstanceUID\"] + \".jpg\"\n\nsample_target = test_dir + sample_df[\"StudyInstanceUID\"] + \".jpg\"\nshuffle(train_df)\ninput_size = [224,240,360,300,380,456,528,600]\nlabels = train_df.columns[1:-1]\nimg_size = input_size[4]\nbatch = 16\nrandom = 13\n\nprint(train_df.loc[0,\"StudyInstanceUID\"])","0be1e56d":"train_x , valid_x , train_y , valid_y = train_test_split(train_df.iloc[:,0],np.array(train_df.iloc[:,1:-1]),test_size=.2,random_state=random)\nprint(train_x[0])\nprint(train_y[0])","a1c464e0":"train_decode = build_decoder(with_labels=True,size=img_size)\ntest_decode = build_decoder(with_labels=False , size=img_size)\nc_dir = \"\/kaggle\/tf_cache\"\n\ntrain = builder(train_x,labels=train_y,bsize=batch,decoder=train_decode,cache_dir=c_dir,cache=True)\nvalid = builder(valid_x,labels=valid_y,bsize=batch,decoder=train_decode,augment=False,cache_dir=c_dir, cache=True)\ntest = builder(sample_target,bsize=batch,decoder=test_decode,augment=False,cache=False)","19f8fb9b":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\nimport tensorflow.keras.applications.efficientnet as efn","8a696317":"weight_path = \"..\/input\/tfkeras-efficientnet-weights\/efficientnetb4_notop.h5\"\nmodel = Sequential([efn.EfficientNetB4(input_shape=(img_size, img_size, 3),weights=weight_path\n                    ,include_top=False,drop_connect_rate=0.6),                    \n                tf.keras.layers.GlobalAveragePooling2D(),\n                tf.keras.layers.Dense(len(labels), activation='sigmoid') ])\nmodel.compile(optimizer='adam',loss='binary_crossentropy',metrics=[tf.keras.metrics.AUC(multi_label=True)],run_eagerly=None)\nmodel.summary()","9402d0bf":"#from tensorflow.keras.utils import plot_model\n#plot_model(model,show_shapes=True, show_layer_names=True, rankdir='TB', expand_nested=True)","d38a4493":"#Create Callback\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(\n    'model_b4.h5', save_best_only=True, monitor='val_auc', mode='max')\n\nlr_reducer = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor=\"val_auc\", patience=3, min_lr=1e-6, mode='max')\n\ncallbacks_list=[checkpoint,lr_reducer]","a76ee75f":"history = model.fit(train,validation_data=valid,steps_per_epoch=len(train),epochs=20\n                    ,callbacks=callbacks_list,verbose=1)","2272dbd0":"model.load_weights('model_b4.h5')\nmodel.save(\"model_b4.h5\")","caa20134":"hist_df = pd.DataFrame(history.history)\nhist_df.to_csv('history.csv')","e22fea4b":"sample_df[labels] = model.predict(test, verbose=1)\nsample_df.to_csv('submission.csv', index=False)\n\nsample_df.head()","fadbff88":"**[xhlulu](https:\/\/www.kaggle.com\/xhlulu) <br>\n[Copied From Here](https:\/\/www.kaggle.com\/c\/ranzcr-clip-catheter-line-classification\/discussion\/204950)**"}}