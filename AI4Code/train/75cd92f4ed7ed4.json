{"cell_type":{"6d850cb1":"code","0e5385c7":"code","a87c5917":"code","dc047c75":"code","be56a64f":"code","d8c7a20f":"code","8f5626a3":"code","377db4b7":"code","77dcafed":"code","e750d5d8":"code","991e982c":"code","f928a06c":"code","0320d2bb":"code","797a185b":"code","6cfe90da":"code","f31d2662":"code","d903a920":"code","f8a8ca6a":"code","067836f5":"code","ca032754":"code","0e60f995":"code","76808002":"code","180812b5":"code","28178ff3":"code","798c1ba7":"code","c9247996":"code","f6935d96":"code","c8b1c206":"code","34d2ea27":"code","3f3b6299":"code","dd4b2954":"code","158fa4c6":"code","ebc0d355":"code","72a0b1e0":"code","23fe8440":"code","03b8681d":"code","b8ae1d54":"code","76e31328":"code","49609cef":"code","518bc763":"code","9d962513":"code","d144f636":"code","0e74486d":"code","66ccabaa":"code","4d3c528c":"code","124f7c6f":"code","1819fdf4":"code","e84e128f":"code","b1e5db4a":"code","1ad50210":"code","fcc262d1":"code","0d43c26b":"code","e2779961":"code","b9677fe2":"code","4624f234":"code","c17b2e49":"code","23597841":"code","4a9ac9d1":"code","a3653c24":"code","e86371c0":"code","4b2a29f2":"code","879181a0":"code","87b78154":"code","1d315134":"code","0c7aaa09":"code","9506c006":"code","02465c79":"code","683a7357":"code","5ced6426":"code","e5a98514":"code","69c933e1":"code","73dd105e":"code","e1d42000":"code","dc4d111f":"code","76778ad0":"code","6bbcbf73":"code","69b37f41":"code","1bb7da13":"code","a4ba18d6":"code","ef95c1b1":"code","7725b9d9":"code","cc2a3734":"code","9a4a392d":"code","3bb311c5":"code","f9653782":"code","820d77bb":"code","83d02fef":"code","dbbbc178":"code","ae226a87":"code","3354b722":"code","e2a9ffa7":"code","6f6f7b16":"code","838e9dd5":"code","3c0989c2":"code","ad527fbc":"code","9588474e":"code","08c28b4a":"code","c005dddc":"code","0fd87097":"code","138b0319":"code","3e11ddda":"code","447b0da6":"code","0f0d4575":"code","62d7c595":"code","81edb3bf":"code","c41d80c9":"code","f27d620c":"code","5cacd848":"code","ad1e8d54":"code","0855b83a":"code","26e054d9":"code","9885aae4":"code","9a159b6d":"code","4320f522":"code","edf4727e":"code","0d1bc2e3":"code","dc65ea97":"code","74f0eab1":"code","8b2f64d4":"code","ef43d59b":"code","63911d02":"code","72b9e47a":"code","05f51ea1":"code","4c3c55b1":"code","e221c928":"code","aa67feb5":"code","ffe82a6a":"code","8686dbf7":"code","faa273d3":"code","45e88275":"code","37c617bf":"code","4a5d57b3":"code","4d83dcf2":"code","2c360ca3":"code","26397671":"code","62be069e":"code","eefb032f":"code","befa562a":"code","de020297":"code","8c9e2622":"code","85762c3e":"code","1f1be0ba":"code","8824c627":"code","8f4b7b43":"code","a56ba5df":"code","e6bfc4f2":"code","0bdad934":"code","061a985a":"code","e15b1027":"code","f725fa45":"code","dadfc633":"code","c6bad93f":"code","a9a72d1d":"code","bda340a9":"code","da0c99e1":"code","30ca5691":"code","01778764":"code","dbb3217a":"code","f9f0adaf":"code","a0989757":"code","b03c6320":"code","adf67c95":"code","ac930eb0":"code","53a40937":"code","bc369422":"code","86250b59":"code","daa8befe":"code","7b303006":"code","29a76c16":"code","b2d650cf":"code","a23c3ce2":"code","78bf7b42":"code","7afe0330":"code","ff9c4a6c":"code","0a7090fd":"code","2571d8f8":"code","326d992a":"code","9cf72bfd":"code","220bc772":"code","6ead4335":"code","6905e9bd":"code","4b25388e":"code","3fc09985":"code","39d41f7a":"code","cac4e021":"code","e7ad8deb":"code","ea588cc6":"code","875e2d40":"code","20bdfb2a":"code","1d61524b":"code","3e589ee7":"code","af5cdf11":"code","74efa080":"code","3b5365f2":"code","9c4a798d":"code","f57a8c0c":"code","1a7d2417":"code","07c61cb7":"code","948adb93":"code","100439aa":"code","7c35c004":"code","5610bb96":"code","7ed519c2":"code","cd334ba3":"code","a926c5df":"code","cc6ce2ca":"code","c30a757d":"code","113e0de9":"code","aac2f312":"code","b88c02b6":"code","42528262":"code","15ae41f7":"code","e5df6b2a":"code","acefc5cb":"code","11a05a54":"code","194129a1":"code","1be9acdd":"code","558e050d":"code","6a7130e4":"code","672119c9":"code","821792bb":"code","604992f2":"code","c73d9b61":"code","b82ba67b":"code","4f7ed453":"code","26695246":"code","7281bdf6":"code","79d81c30":"code","8e128c78":"code","0b11f72c":"code","581f43f9":"code","c9a9dae0":"code","147a36aa":"code","7c236c40":"code","14e1e13a":"code","004c3094":"code","6ae650fd":"code","d806854b":"code","ac44df0c":"code","d636f1ed":"code","dc106bf0":"code","2fdbfb63":"code","a9feed0a":"code","a64da585":"code","d2ca9848":"code","01e83177":"code","b1c24a58":"code","be219d03":"code","de7b8855":"code","24efbe28":"code","c8461474":"code","dc6c4a27":"code","9dc39038":"code","2cd7f4cf":"code","fc53aa5d":"code","4a78c554":"code","c9732fb0":"code","d3bc33f0":"code","c6758ed0":"code","a658b69c":"code","48f93096":"code","7c8a285f":"code","a683b52d":"code","712413cd":"code","05177d3d":"code","6ce550f6":"code","fa363e1c":"code","65ecee60":"code","fa857dd9":"code","2fbe8acf":"code","2d26f41b":"code","edf9d823":"code","15be83eb":"code","8d2dffc1":"code","3f3b4034":"code","4ed69d4e":"code","6451f216":"code","7a851049":"code","d0084e51":"code","74f4357a":"code","1919d1f4":"code","85d71eb3":"code","4d62c143":"code","3e905c84":"code","353639bd":"code","ac0e0772":"code","b826b037":"code","220ca32a":"code","30e0aa16":"code","9ec32750":"code","1b6bdba1":"code","19693113":"code","c31215c6":"code","5c3c3de2":"code","ec6fbb56":"code","ea12c4de":"code","390877e2":"code","beee9e4a":"code","02cc2898":"code","784ba447":"code","7fcbcad1":"code","12ef8775":"code","1436fc26":"code","98888a20":"code","c5930233":"code","03d31fb8":"code","3b28a69e":"code","fa626a05":"code","610e525a":"code","10b4d941":"code","05e0aea1":"code","2d0cd593":"code","ab8ad4b3":"code","77b35d6b":"code","515410ed":"code","49a7bd63":"code","ee272348":"code","f05c9013":"code","8bf1d0c8":"code","79f6c230":"code","64b73fca":"code","e5db792d":"code","2ff9f80c":"code","e2c5b879":"code","548df60b":"code","b26088d9":"code","b6abedc3":"code","c0affa1b":"code","3fd0395c":"code","d9bfb48a":"code","5d6f7a4c":"code","e319a7b6":"code","db99a941":"code","a76fd212":"code","f8d31010":"code","56b4d9a4":"code","9cbd8225":"code","5e2a9e13":"code","5ed3c054":"code","c23c9d19":"code","72ae29fa":"code","3b90a24e":"code","5003069c":"code","ece3d74f":"code","05965691":"markdown","3ddea372":"markdown","8d8a43b7":"markdown","c41181b1":"markdown","bbb4cd6f":"markdown","3c63b033":"markdown","6c86b30e":"markdown","7d53c8e9":"markdown","30c00f06":"markdown","a91a4375":"markdown","7d6101d8":"markdown","ceaf9de3":"markdown","f599b020":"markdown","499189bf":"markdown","0f29ef88":"markdown","bdfde613":"markdown","d66c9cc1":"markdown","a46d48d7":"markdown","6685785d":"markdown","d8d93429":"markdown","a8617d49":"markdown","9da7a1f1":"markdown","bfa25fc8":"markdown","413434ae":"markdown","27ab917f":"markdown","b1cd1474":"markdown","25b12b90":"markdown","05254f34":"markdown","8e5b3296":"markdown","295bf7f0":"markdown","03cccd82":"markdown","f49f3bb6":"markdown","10af2b41":"markdown","cdd27f53":"markdown","453ddd87":"markdown","233c094a":"markdown","aaefa471":"markdown","661ea27c":"markdown","e0b6ad80":"markdown","956f6c76":"markdown","295d60d1":"markdown","170703a7":"markdown","f4aca222":"markdown","45c50cbc":"markdown","2d0932ed":"markdown","a2bf88a4":"markdown","ad64cde1":"markdown","bcea8192":"markdown","453680a9":"markdown","6051cec7":"markdown","63c1891c":"markdown","5a9bc7f9":"markdown","9d71d1c7":"markdown","5deb6b44":"markdown","2993c78c":"markdown","45d1ce02":"markdown","a5ce72dd":"markdown","774c26cc":"markdown","d4de5b47":"markdown","dc7e1121":"markdown","b2d83e96":"markdown","3d45817b":"markdown","9e3569fe":"markdown","fdacf5f7":"markdown","c2e1cd35":"markdown","cd94376a":"markdown","f6f57ea7":"markdown","d063bc83":"markdown","49d7852a":"markdown","11c4e536":"markdown","1ce44462":"markdown","3964942c":"markdown","76cdb6e1":"markdown","1d852876":"markdown","e500b26a":"markdown","ca0bb354":"markdown","f34e6a73":"markdown","1ef00a8d":"markdown","c0fd0260":"markdown","b6c3758d":"markdown","c2fae357":"markdown","d3af5370":"markdown","1851627f":"markdown","b461f50e":"markdown","2a038ceb":"markdown","55224d77":"markdown","4592a647":"markdown","bee68584":"markdown","b1945bad":"markdown","a34b5332":"markdown","058e0184":"markdown","4cc16717":"markdown","ba9a2def":"markdown","249de310":"markdown","92405a7f":"markdown","92687603":"markdown","fa9c6c6d":"markdown","d53b12dc":"markdown","e857d398":"markdown","3843d79b":"markdown","1e23cd83":"markdown","74480fb8":"markdown","5e93a1ce":"markdown","f612a81d":"markdown","bc312298":"markdown","ea5ad373":"markdown","91752d1b":"markdown","a8553529":"markdown","267aa10c":"markdown","feb4ee29":"markdown","b7d3df20":"markdown","dc750484":"markdown","5514b62c":"markdown","0f70d0f0":"markdown","d3545849":"markdown","27fe968a":"markdown","949df4b7":"markdown","93a18624":"markdown","8e1e3ab0":"markdown","bb2a2bff":"markdown","2e45e8eb":"markdown","92d21806":"markdown","f7634b2b":"markdown","67df3683":"markdown","5470da92":"markdown","80772253":"markdown","a6468fbc":"markdown","c8616eac":"markdown","a50ecccd":"markdown","2f307831":"markdown","4c2e4422":"markdown","11e16dfe":"markdown","df9cc988":"markdown","7a605313":"markdown","d8ad5101":"markdown","6fce9dc6":"markdown","62a92edb":"markdown","0edcde6e":"markdown","fefa4500":"markdown","16ec092d":"markdown","b5f8aaf0":"markdown","7b35934e":"markdown","c3f1976e":"markdown","55861276":"markdown","92ebfa4a":"markdown","59e8d926":"markdown","c441661c":"markdown","9d2efa34":"markdown","ef0cbffc":"markdown","b89fc62b":"markdown","2e096311":"markdown","21a2a3f9":"markdown","7a8814f7":"markdown","21d393b2":"markdown","6eed6e5d":"markdown","76a1f1e7":"markdown","2e9e763d":"markdown","528b7894":"markdown","a9a6d176":"markdown","bf74906a":"markdown","1bc09757":"markdown","8c955fdb":"markdown","c6d0ea37":"markdown","ce450f7c":"markdown","1061fbec":"markdown","2f95c426":"markdown","9acdf543":"markdown","fcb4d803":"markdown","833f1cf7":"markdown","ace4d7f5":"markdown","b80749a0":"markdown","67018398":"markdown","4f66f9e2":"markdown","d44dab27":"markdown","3b0a280a":"markdown","ddab5208":"markdown","e5fd4778":"markdown","57e78cb5":"markdown","fbad4926":"markdown","5770d61d":"markdown","63e49c5b":"markdown","427e7acb":"markdown","6fd6dc9d":"markdown","9dc733bf":"markdown","c51ed5ae":"markdown","990f39c5":"markdown","5a498b46":"markdown","d92126a7":"markdown","184dd567":"markdown","5a3bf847":"markdown","06cf46ce":"markdown","6be8fc58":"markdown","e044d559":"markdown","c834a0e3":"markdown","7b0f69fb":"markdown","6708f604":"markdown","ef97a3c3":"markdown","7511ebad":"markdown","ff8f752f":"markdown","7cf2df81":"markdown","3e2b61a5":"markdown","aa09bf3b":"markdown","0a889658":"markdown","abdd52b2":"markdown","0813c5ab":"markdown","339b91e4":"markdown","378fe2bd":"markdown","1fc5f703":"markdown","50fb9af7":"markdown","57e4bb0d":"markdown","0775ab7d":"markdown","281fc70e":"markdown","26d440fd":"markdown","6c5d5a4f":"markdown","630b80d5":"markdown","3bd4dbd8":"markdown","b5f0a63f":"markdown","fa8b040a":"markdown","19ff1e39":"markdown","fdf89088":"markdown","4c139b48":"markdown","44ddf1aa":"markdown","2a2be4b7":"markdown","585b9f80":"markdown","a694120c":"markdown","341d49b8":"markdown","5a63a22d":"markdown","51d47ce2":"markdown","ffc932ac":"markdown","193c8c31":"markdown"},"source":{"6d850cb1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n        \n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0e5385c7":"waterbody_df=pd.read_excel(\"\/kaggle\/input\/acea-water-prediction\/datasets_description.ods\",sheet_name=\"Datasets_Description\")\nwaterbody_df.drop(\"Description\",axis=1,inplace=True)\nwaterbody_df.replace(r'\\n',  '', regex=True,inplace=True)\nwaterbody_df.replace(r' ',  '', regex=True,inplace=True)\nwaterbody_df=waterbody_df.set_index(\"Database\").apply(lambda x: x.str.split(',').explode()).reset_index()","a87c5917":"waterbody_df[[\"VAR_RMSE\",\"VAR_MAE\",\"Catboost_RMSE\",\"Catboost_MAE\"]]=np.nan\nwaterbody_df","dc047c75":"waterbody_path= pd.DataFrame(columns = ['waterbody_name',\"waterbody_path\"])\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    \n    for filename in filenames:\n        waterbody_name = filename.split(\".\")[0]\n        waterbody_path = waterbody_path.append({'waterbody_name': waterbody_name,\"waterbody_path\":os.path.join(dirname, filename) }, ignore_index=True)\n\nwaterbody_path.set_index(\"waterbody_name\",inplace=True)\nwaterbody_path","be56a64f":"import warnings\nwarnings.filterwarnings(\"ignore\")","d8c7a20f":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib import pyplot \nfrom datetime import datetime, date\nfrom matplotlib.pyplot import figure\nimport missingno as msno\n\n\nfrom sklearn.model_selection import train_test_split\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\nimport lightgbm as lgb\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\n\n#VAR\nfrom statsmodels.tsa.api import VAR\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tools.eval_measures import rmse, aic\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\n\nimport sklearn\nimport catboost\nimport hyperopt\nfrom hyperopt import hp, fmin, tpe, STATUS_OK, Trials\nimport colorama\n\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n# Comment this if the data visualisations doesn't work on your side\n%matplotlib inline\n\n#plt.style.use('bmh')","8f5626a3":"waterbody_name = \"Aquifer_Petrignano\"","377db4b7":"waterbody = pd.read_csv(waterbody_path.loc[waterbody_name,\"waterbody_path\"])\nwaterbody.tail(5)","77dcafed":"msno.matrix(waterbody)","e750d5d8":"#Setting date column as index\n\nwaterbody['Date']=pd.to_datetime(waterbody['Date'],format='%d\/%m\/%Y')\nwaterbody.set_index('Date',inplace=True)","991e982c":"def find_start_position(df1):\n    '''\n    This function finds the location of the cell untill which a perticular column start to have real values. \n    It stores this data into an array and slices the dataframe based on the location of cell with maximum NaN value at start for a column.\n    '''\n    \n    df = df1.copy()\n\n    # Dropping the columns which do not have null values at the start\n\n    col_drop = []\n    col_names = pd.Series(df.columns)\n    for j in range(len(df.columns)):\n        if pd.notnull(df.iloc[0,j]):\n            col_drop.append(j)\n    for i in col_drop:\n        df.drop(labels = col_names[i],axis=1,inplace=True)\n\n    # Finding the position in the dataframe which we will be considered for further analysis\n\n    pos = []\n    for j in range(len(col_names)-len(col_drop)):\n        for i in range(len(df)):\n            if pd.notnull(df.iloc[i,j]):\n                pos.append(i)\n                break\n                \n    # returning the new dataset \n    return df1[max(pos):]\n\n","f928a06c":"waterbody = find_start_position(waterbody)\nmsno.matrix(waterbody)","0320d2bb":"def date_continuity(waterbody):\n    \n    '''\n    Checks whether the dates are continous and the difference in dates should be one, so that we can know, if at all any rows are missing.\n    '''\n    \n    date_check=pd.DataFrame()\n    date_check['real']=waterbody.index\n    date_check['shifted']=date_check['real'].shift(-1)\n    date_check['dist']=date_check['real']-date_check['shifted']\n    print(date_check['dist'].value_counts())\n    \n\n","797a185b":"date_continuity(waterbody)","6cfe90da":"def categorical_list(df):\n    \n    '''\n    Based on the string groups the name of the columns into different categorical lists and return these lists as an output.\n    '''\n        \n    groundwater_col_list = [s for s in df.columns if \"Depth_to_Groundwater\" in s]\n    rainfall_col_list = [s for s in df.columns if \"Rainfall\" in s]\n    temperature_col_list=[s for s in df.columns if \"Temperature\" in s]\n    volume_col_list = [s for s in df.columns if \"Volume\" in s]\n    hydrometry_col_list = [s for s in df.columns if \"Hydrometry\" in s]\n    flow_rate_col_list = [s for s in df.columns if \"Flow\" in s]\n    lake_level_col_list = [s for s in df.columns if \"Level\" in s]\n    return groundwater_col_list, rainfall_col_list, temperature_col_list, volume_col_list, hydrometry_col_list,flow_rate_col_list, lake_level_col_list\n","f31d2662":"dim=len(waterbody.columns)*4\naxes = waterbody.plot.line(subplots=True,figsize=(18,dim))\ntype(axes)","d903a920":"def violin_plots(df):\n    row_num=(len(df.columns)\/\/3)+1\n    fig, ax = pyplot.subplots(nrows=row_num,ncols=3,figsize =(18, row_num*6))   \n    ax1=ax.flatten()\n    for i,t in enumerate(df.columns):\n        sns.violinplot(ax=ax1[i],y=t, data=df) ","f8a8ca6a":"violin_plots(waterbody)","067836f5":"def removeoutlier(group,stds):\n    \n    '''\n    Here group stands for the column values and stds stands for standard deviation.\n    If the absolute value od data points are greater than given threshold standard deviation then it is replaced by NaN value\n    '''\n    \n    group[np.abs(group - group.mean()) > stds * group.std()]=np.nan","ca032754":"col_names = waterbody.columns\n\n#Removing outlier for columns other than Rainfall\nfor col in col_names[~col_names.str.contains('Rainfall',regex=True)]:\n    removeoutlier(waterbody[col],3)","0e60f995":"waterbody[['Temperature_Bastia_Umbra','Temperature_Petrignano']].plot.line(figsize=(18,5))","76808002":"waterbody.loc[((waterbody.index>=datetime(2015,1,1)) & (waterbody.index<=datetime(2016,1,1)) & (waterbody[col_names[4]]==0)),col_names[4]]=np.nan","180812b5":"def missing_prcnt(df):\n    \n    \n    '''\n    Stores the sum of missing values in an array known as total, and percentage is calculated by dividing the sum with the no. of rows.\n    These two columns are concatenated and those rows are shown as an output where the percentage is greater than zero\n    '''\n    \n    total = df.isnull().sum().sort_values(ascending=False)\n    percent = ((df.isnull().sum()\/df.isnull().count())*100).sort_values(ascending=False)\n    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    # We are going to consider just the feaures that have at least 1 missing value\n    return missing_data[missing_data['Percent'] > 0]\n","28178ff3":"missing_data=missing_prcnt(waterbody)\nmissing_data","798c1ba7":"def missing_prcnt_yearly(missing_data,df1):\n    \n    '''\n    Groups by the data yearly, and finds the percentage of missing values year wise.\n    Also gives colour gradient based on the missing values present each year.\n    '''\n        \n    df=df1.copy()\n    df['Date'] = pd.to_datetime(df.index, format = '%d\/%m\/%Y')\n\n    df['year'] = df['Date'].dt.year\n\n    nan_by_year = pd.DataFrame(index = df['year'].unique())\n\n    for col in missing_data.index.tolist():\n        count = df[col].isnull().groupby(df['year']).sum().astype(int).reset_index(name='count')\n        nan_by_year[col] = count['count'].values\n    nan_by_year\n\n    figure(figsize= (22, 10))\n    missing_percent = (nan_by_year\/365)*100\n    sns.heatmap(missing_percent, annot = True,  linewidths=.5, cmap = 'rocket_r')\n\n    ax = plt.gca()\n    ax.set_ylabel(\"Year\", fontsize = 25)\n    ax.set_xlabel(\"Variable\", fontsize = 25)\n    plt.xticks(fontsize=18)\n    plt.yticks(fontsize=18, rotation=0)\n\n    ax.set_title(\"% of Missing values per year\", fontsize = 35, pad = 25)\n\n    #plt.savefig('Petrignano_missing.png', bbox_inches='tight')\n\n","c9247996":"missing_prcnt_yearly(missing_data=missing_data,df1=waterbody)","f6935d96":"groundwater_col_list, rainfall_col_list, temperature_col_list, volume_col_list, hydrometry_col_list,flow_rate_col_list, lake_level_col_list= categorical_list(waterbody)\noutput_columns = groundwater_col_list","c8b1c206":"temp = waterbody['Temperature_Petrignano'].copy().rename('Temperature_Petrignano')\ntemp = temp.to_frame()\ntemp['Filled by interpolation'] = temp['Temperature_Petrignano'].interpolate(method='linear')\ntemp.plot.line(y=['Filled by interpolation','Temperature_Petrignano'],figsize=(18,5))","34d2ea27":"\ndef interpolate_df(df,col_no,method='linear'):\n    for col in df.columns[col_no]:\n        df[col]=df[col].interpolate(method='linear')\n        \n","3f3b6299":"interpolate_df(df=waterbody,col_no=[1,2,5])","dd4b2954":"lr_set=waterbody.filter([col_names[3],col_names[4]],axis=1)\nlr_set1=lr_set.dropna()\n\nmodel=LinearRegression()\nX = np.array(lr_set1[col_names[3]]).reshape(-1, 1)\ny= np.array(lr_set1[col_names[4]]).reshape(-1, 1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\nmodel.fit(X=X_train,y=y_train)\n\nfor i in range(len(waterbody)):\n    if np.isnan(waterbody.iloc[i,4]):\n        waterbody.iloc[i,4]=model.predict(waterbody.iloc[i,3].reshape(1, -1))[0][0]","158fa4c6":"waterbody.plot.line(y=col_names[4],figsize=(18,5))","ebc0d355":"col_names","72a0b1e0":"#Creating a new temporary dataframe just for fixing the values of Hydrometry of Chiasco river\ntemp_df=waterbody.filter([col_names[6]],axis=1).copy()\n#Feature engineering date columns\ntemp_df['Year']=pd.DatetimeIndex(temp_df.index).year\ntemp_df['month']=pd.DatetimeIndex(temp_df.index).month\ntemp_df['day']=pd.DatetimeIndex(temp_df.index).day\nmonth_in_year = 12\n#Cyclical Features are also encoded, so as to show a continuity in the months like January and December\ntemp_df['month_sin'] = np.sin(2*np.pi*temp_df.month\/month_in_year)\ntemp_df['month_cos'] = np.cos(2*np.pi*temp_df.month\/month_in_year)\ntemp_df['season'] = temp_df.month%12 \/\/ 3 + 1\n\ntemp_df['day_of_year'] = pd.DatetimeIndex(temp_df.index).dayofyear\ndays_in_year = 365.25\ntemp_df['day_of_year_sin'] = np.sin(2*np.pi*temp_df.day_of_year\/days_in_year)\ntemp_df['day_of_year_cos'] = np.cos(2*np.pi*temp_df.day_of_year\/days_in_year)\n\ntemp_df['week_of_year'] = pd.DatetimeIndex(temp_df.index).weekofyear\nweeks_in_year = 52.1429\ntemp_df['week_of_year_sin'] = np.sin(2*np.pi*temp_df.week_of_year\/weeks_in_year)\ntemp_df['week_of_year_cos'] = np.cos(2*np.pi*temp_df.week_of_year\/weeks_in_year)","23fe8440":"X1 = waterbody\nimp = IterativeImputer(RandomForestRegressor(), max_iter=15, random_state=1)\nresult_X1 = imp.fit_transform(X1)\nresult_X1 = pd.DataFrame(result_X1, columns=X1.columns, index= X1.index)\nresult_X1[col_names[-1]].plot.line(figsize=(18,3))\n\nwaterbody['Hydrometry_Fiume_Chiascio_Petrignano'] = result_X1[col_names[-1]]","03b8681d":"annual_resampled_data=waterbody.resample('A').mean()\nmonth_resampled_data=waterbody.resample('M').mean()\nweek_resampled_data=waterbody.resample('W').mean()\nmonth_groupby=waterbody.groupby([waterbody.index.month_name()], sort=False).mean()","b8ae1d54":"def yearlytrend_and_seasonality(df):\n    \n    '''\n    Plots yearly plots and seasonal plot for the given dataframe\n    '''\n    \n    fig, axes = plt.subplots(nrows=(len(df.columns)),ncols=2,figsize=(18,2*(len(df.columns))))\n    annual_resampled_data.plot(ax = axes[:,0], subplots=True) \n    month_groupby.plot(ax = axes[:,1], subplots=True)\n    \n","76e31328":"yearlytrend_and_seasonality(waterbody)","49609cef":"import matplotlib.pyplot as plt\n\n\ndef scatter_colour(df,xx,yy,title_string):\n    plt.figure(figsize = (10, 6))\n    ax = plt.axes()\n\n    p1=sns.scatterplot(x=xx,y=yy,data=df,hue='Date')\n    p1.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n\n    ax.set_title(title_string)\n\n    for l1 in range(0,df.shape[0]):\n         p1.text(df[xx][l1]+0.01, \n                 df[yy][l1], \n                 df.index[l1], \n                 horizontalalignment='left', \n                 size='medium', color='black')\n            \n\n","518bc763":"scatter_colour(month_groupby,col_names[-1],col_names[1],\"Petrignano: Variation of depth of groundwater with Chiascio River\")","9d962513":"\ndef yearwise_lineplots(df,colname):\n    year_array = pd.Series(df.index.year.values).unique()\n    plt.figure(figsize = (10, 6))\n    plt.title(\"Yearwise distribuation of \"+ colname)\n    m=60\n    if 'Rainfall' in colname:\n        m=150\n        \n    plt.xlabel(\"time\")\n    plt.ylabel(str(m)+\"-day rolling average\")\n    \n    colors = sns.color_palette(\"rocket_r\", n_colors=len(year_array))  # get a number of colors\n    j=0\n    for i in year_array:\n        \n        plt.plot(df[df.index.year == i][colname].reset_index(drop=True).rolling(m).mean(),label=i,color=colors[j])\n        j=j+1\n        \n    \n    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n    if 'Rainfall' in colname:\n        print('For Rainfall columns the moving average is taken to be 150,ignore legend')\n\n\n","d144f636":"yearwise_lineplots(waterbody,col_names[2])\n# for col in col_names:\n#     yearwise_lineplots(waterbody,col)","0e74486d":"from statsmodels.tsa.stattools import grangercausalitytests\nmaxlag=14\ntest = 'ssr_chi2test'\ndef grangers_causation_matrix(data, variables, test='ssr_chi2test', verbose=False):    \n    \n    \"\"\"Check Granger Causality of all possible combinations of the Time series.\n    The rows are the response variable, columns are predictors. The values in the table \n    are the P-Values. P-Values lesser than the significance level (0.05), implies \n    the Null Hypothesis that the coefficients of the corresponding past values is \n    zero, that is, the X does not cause Y can be rejected.\n\n    data      : pandas dataframe containing the time series variables\n    variables : list containing names of the time series variables.\n    \"\"\"\n    warnings.filterwarnings(\"ignore\")\n    df = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n    for c in df.columns:\n        for r in df.index:\n            test_result = grangercausalitytests(data[[r, c]], maxlag=maxlag, verbose=False)\n            p_values = [round(test_result[i+1][0][test][1],4) for i in range(maxlag)]\n            if verbose: print(f'Y = {r}, X = {c}, P Values = {p_values}')\n            min_p_value = np.min(p_values)\n            df.loc[r, c] = min_p_value\n    df.columns = [var + '_x' for var in variables]\n    df.index = [var + '_y' for var in variables]\n    return df\n\n","66ccabaa":"grangers_causation_matrix(waterbody, variables = waterbody.columns) ","4d3c528c":"#No. of observation we would like to predict\n\nnobs = 182\n\n#Selecting top 1500 points to capture the recency in the data\n\nif len(waterbody)>1500:\n    model_df = waterbody[-1500:]\nelse:\n    model_df = waterbody[:]\nmodel_df_train, model_df_test = model_df[0:-nobs], model_df[-nobs:]","124f7c6f":"def adfuller_test(series, signif=0.05, name='', verbose=False):\n    \n    \"\"\"Perform ADFuller to test for Stationarity of given series and print report\"\"\"\n    \n    r = adfuller(series, autolag='AIC')\n    \n    output = {'test_statistic':round(r[0], 4), 'pvalue':round(r[1], 4), 'n_lags':round(r[2], 4), 'n_obs':r[3]}\n    p_value = output['pvalue'] \n\n    if p_value <= signif:\n        x =0\n    else:\n        x = 1\n        \n    return x","1819fdf4":"# ADF Test on each column\ndef differencing_till_stationary(model_df_train):  \n    \n    '''\n    Based on the ADF tests, differences the data untill it gets stationary. Hence, returns the differenced dataframe and also no. of differences done.\n    This no. of differences variable is again used while inverting the dataframe\n    '''\n    \n    no_of_differencing = 0\n    for i in range(0,10):\n        flag =0\n        \n        for name, column in model_df_train.iteritems():\n            x = adfuller_test(column, name=column.name)\n            flag = flag + x\n\n\n        if flag != 0:\n            model_df_train = model_df_train.diff().dropna()\n            no_of_differencing = no_of_differencing + 1\n            \n        elif flag == 0:\n            break\n\n        i = i+1\n    return model_df_train, no_of_differencing\n\n\n","e84e128f":"model_df_train_differenced,no_of_differencing=differencing_till_stationary(model_df_train)","b1e5db4a":"#Creating a model for VAR\n\nmodel = VAR(model_df_train_differenced)\n\n#Optimizing with the best lag\n\nresult = model.fit(maxlags=30, ic='aic')\n#print('lag - {}'.format(result.k_ar))\n\n#Storing the best lag in a variable\n\nlag = result.k_ar\n\n#Again modelling using the best lag\n\nmodel_lag = VAR(model_df_train_differenced)\nresult_lag = model_lag.fit(lag)\nresult_lag.summary()\n\nforecast_input = model_df_train_differenced.values[-lag:]\n\n# Forecast\nfc = result_lag.forecast(y=forecast_input, steps=nobs)\ndf_forecast = pd.DataFrame(fc, index=model_df.index[-nobs:], columns=model_df.columns)","1ad50210":"def invert_transformation(df_train, df_forecast,no_of_differencing):\n    \n    \"\"\"Revert back the differencing to get the forecast to original scale.\"\"\"\n    \n    df_fc = df_forecast.copy()\n    columns = df_train.columns\n    if no_of_differencing != 0:\n        for col in columns:        \n           # Roll back 2nd Diff\n            if no_of_differencing==2:\n                df_fc[str(col)] = (df_train[col].iloc[-1]-df_train[col].iloc[-2]) + df_fc[str(col)].cumsum()\n          #  Roll back 1st Diff\n            df_fc[str(col)+'_forecast'] = df_train[col].iloc[-1] + df_fc[str(col)].cumsum()\n    else:\n        df_fc[str(col)+'_forecast'] = df_fc[str(col)]\n    return df_fc","fcc262d1":"forecasted_df= invert_transformation(model_df,df_forecast, no_of_differencing)\n","0d43c26b":"def predict_store_VAR(forecasted_df,model_df_test,output_columns):\n    \n    '''This function stores the required error metrics in their corresponding cells in waterbody_df.'''\n    for output_col in output_columns:\n        y_predicted = forecasted_df[str(output_col)+'_forecast']\n        y_test =model_df_test[str(output_col)]\n        waterbody_df.loc[(waterbody_df.Database==waterbody_name)& (waterbody_df.Output==output_col),\"VAR_RMSE\"] = mean_squared_error(y_predicted, y_test)\n        print(output_col+\" RMSE: \"+str(mean_squared_error(y_predicted, y_test)))\n        waterbody_df.loc[(waterbody_df.Database==waterbody_name)& (waterbody_df.Output==output_col),\"VAR_MAE\"] = mean_absolute_error(y_predicted, y_test)\n        print(output_col+\" MAE: \"+str(mean_absolute_error(y_predicted, y_test)))","e2779961":"predict_store_VAR(forecasted_df,model_df_test,output_columns)","b9677fe2":"corr=waterbody.corr()\nplt.figure(figsize=(0.8*len(waterbody.columns),0.5*len(waterbody.columns)))\nsns.heatmap(corr, xticklabels=corr.columns,yticklabels=corr.columns,annot=True)","4624f234":"\ndef Principal_Component_Analysis(df,prefix_string,org_db):\n    \n    '''Returns a dataframe with the replaced columns that captures 90% of the data of the given list of columns as a list as an input.'''\n    scaler = StandardScaler().fit(df)\n    X_std = scaler.transform(df)\n   \n    k = len(df.columns)\n    pca = PCA(n_components = k)\n    pca.fit(X_std)\n    x_pca = pca.transform(X_std)\n    v = pca.explained_variance_ratio_.round(2)\n   \n    # setting variance capture limit as 90%\n    var_limit = 0.90\n    cummulative = np.cumsum(v)\n    for i in range(len(cummulative)):\n        if cummulative[i]>=var_limit:\n            PCA_comp = i+1\n            break\n   \n    pca = PCA(n_components = PCA_comp).fit(X_std)\n    X = pca.transform(X_std)\n    columns = []\n    for i in range(0,PCA_comp):\n        columns.append(prefix_string+\"_\"+str(i))\n    pf = pd.DataFrame(X, columns=columns,index=df.index)\n    org_db.drop(df.columns, axis = 1,inplace=True)\n    org_db = pd.concat([org_db,pf],axis=1)\n    return org_db","c17b2e49":"prefix_string = \"Temperature\"\n\nwaterbody=Principal_Component_Analysis(df=waterbody[temperature_col_list],prefix_string=prefix_string,org_db=waterbody)\n#updating col_list\ngroundwater_col_list, rainfall_col_list, temperature_col_list, volume_col_list, hydrometry_col_list,flow_rate_col_list, lake_level_col_list= categorical_list(waterbody)\n#re_assgining\ncol_names = waterbody.columns","23597841":"def create_lags(df,col_list):\n    for col in col_list:\n        df[col+'_lag7']=df[col].shift(7)\n        df[col+'_lag14']=df[col].shift(14)\n        df[col+'_lag30']=df[col].shift(30)\n        df[col+'_lag90']=df[col].shift(90)","4a9ac9d1":"create_lags(waterbody,rainfall_col_list)\ncreate_lags(waterbody,hydrometry_col_list)\n#create_lags(waterbody,groundwater_col_list)","a3653c24":"def cumsum_column_add(df,column_list,lagging_array=[7,30,60]):\n        \n    for col in column_list:\n        \n        for lag_end in lagging_array:\n            temp3=pd.DataFrame()\n            temp2=pd.DataFrame()\n            for lag in range(1,lag_end):\n                temp2[col+'lag_'+str(lag)]=df[col].shift(lag)\n                \n            temp3[col+'_cumsum_'+str(lag_end)]=temp2.mean(numeric_only=True, axis=1)\n            df = pd.concat([df,temp3],axis=1)\n            df.dropna(inplace=True)\n    return df","e86371c0":"#waterbody =cumsum_column_add(waterbody,rainfall_col_list)\n#waterbody = cumsum_column_add(waterbody,hydrometry_col_list)\nwaterbody = cumsum_column_add(waterbody,['Rainfall_Bastia_Umbra_lag7'])\nwaterbody = cumsum_column_add(waterbody,['Hydrometry_Fiume_Chiascio_Petrignano_lag7'])\n","4b2a29f2":"def effect_of_evaporation(df,temp_col,eva_affected_list):\n    for col in eva_affected_list:\n        df['Temp_max_byyear']=df.groupby(df.index.year)[temp_col].transform(max)\n        df['Temp_min_byyear']=df.groupby(df.index.year)[temp_col].transform(min)\n        df['eva_factor']=(df[temp_col]-df['Temp_min_byyear'])\/(df['Temp_max_byyear']-df['Temp_min_byyear'])\n        df['effective_'+col]=df[col]*(1-df['eva_factor'])\n        df.drop(['Temp_max_byyear','Temp_min_byyear','eva_factor'],axis=1,inplace=True)","879181a0":"effect_of_evaporation(waterbody,temperature_col_list[0],['Rainfall_Bastia_Umbra_lag7'])\n#effect_of_evaporation(waterbody,temperature_col_list[0],['Hydrometry_Fiume_Chiascio_Petrignano_lag7'])","87b78154":"def get_decomp_list(df,output_columns):\n    col_list = waterbody.columns.tolist()\n    for col in output_columns:\n        col_list.remove(col)\n    return col_list","1d315134":"decomp_list = get_decomp_list(df=waterbody,output_columns=output_columns)","0c7aaa09":"def decompose_store_trend(df,col_list):\n    for col in col_list:\n        result = seasonal_decompose(df[col], model='add', period=182)\n        df[col+'_trend']=result.trend\n        df[col+'_seasonal']=result.seasonal\n        df.drop(col,inplace=True,axis=1)\n","9506c006":"decompose_store_trend(waterbody,decomp_list)","02465c79":"def columns_greaterthancorr(df,output_column,columns,threshold=0.05):\n    '''To reduce the dimensionality, and unnecessary columns, this filter is used to limit our no. of features'''\n    cfeature = []\n    for col in columns:\n        corr = df[output_column].corr(df[col])\n        if abs(corr) > threshold:\n            cfeature.append(col)\n    return cfeature","683a7357":"def get_catboost_params(space):\n    '''Stores all the parameters in a dictionary.'''\n    params = dict()\n    params['learning_rate'] = space['learning_rate']\n    params['depth'] = int(space['depth'])\n    params['l2_leaf_reg'] = space['l2_leaf_reg']\n    params['border_count'] = space['border_count']\n    #params['rsm'] = space['rsm']\n    return params","5ced6426":"import shap\n\n\ndef ABS_SHAP(adv_pool,model,df,output_col):\n    #import matplotlib as plt\n    # Make a copy of the input data\n    explainer = shap.TreeExplainer(model)\n    df_shap = explainer.shap_values(adv_pool)\n    shap_v = pd.DataFrame(df_shap)\n    feature_list = df.columns\n    shap_v.columns = feature_list\n    df_v = df.copy() #.reset_index().drop('index',axis=1)\n    \n    # Determine the correlation in order to plot with different colors\n    corr_list = list()\n    for i in feature_list:\n        b = np.corrcoef(shap_v[i],df_v[i])[1][0]\n        corr_list.append(b)\n    corr_df = pd.concat([pd.Series(feature_list),pd.Series(corr_list)],axis=1).fillna(0)\n    # Make a data frame. Column 1 is the feature, and Column 2 is the correlation coefficient\n    corr_df.columns  = ['Variable','Corr']\n    corr_df['Sign'] = np.where(corr_df['Corr']>0,'red','blue')\n    \n    # Plot it\n    shap_abs = np.abs(shap_v)\n    k=pd.DataFrame(shap_abs.mean()).reset_index()\n    k.columns = ['Variable','SHAP_abs']\n    k2 = k.merge(corr_df,left_on = 'Variable',right_on='Variable',how='inner')\n    k2 = k2.sort_values(by='SHAP_abs',ascending = True)\n    colorlist = k2['Sign']\n    ax = k2.plot.barh(x='Variable',y='SHAP_abs',color = colorlist, figsize=(10,0.5*len(feature_list)),legend=False)\n    ax.set_xlabel(\"SHAP Value for \"+output_col+\" (Red = Positive Impact)\")\n    \n","e5a98514":"def testvsmodel(y_test,pred,output_col):\n    fig, ax = plt.subplots(figsize=(15, 4))\n    idxs = np.array(range(len(pred))) + 1\n    ax.plot(idxs, np.array(y_test), linestyle=\"solid\", label='Data')\n    ax.plot(idxs, np.array(pred), linestyle=\"dashed\", label='Model')\n    legend = ax.legend(bbox_to_anchor=(1.2, 1), loc='upper right', shadow=True, borderaxespad=0, fontsize=16)\n    plt.title(\"Comparison of data and prediction results Catboost: \"+output_col, fontsize=18)","69c933e1":"obj_call_count =0\ncur_best_loss =np.inf","73dd105e":"def mycatboost(waterbody,output_col,output_columns,putDate = False):\n    \n    # storing the features in a list, which are other than the output columns\n    features = list(set(waterbody.columns.tolist()).difference(set(output_columns)))\n    features = columns_greaterthancorr(waterbody,output_col,features)\n\n    #creating date features if putDate is true\n    if putDate == True:\n        waterbody['Date_Year']=pd.DatetimeIndex(waterbody.index).year\n        waterbody['Date_month']=pd.DatetimeIndex(waterbody.index).month\n\n        month_in_year = 12\n        waterbody['Date_month_sin'] = np.sin(2*np.pi*waterbody.Date_month\/month_in_year)\n        waterbody['Date_month_cos'] = np.cos(2*np.pi*waterbody.Date_month\/month_in_year)\n        waterbody['Date_season'] = waterbody.Date_month%12 \/\/ 3 + 1\n\n    #Only selecting the lag values, so as to understand the relationships of lags of meteorological factor, which will give an hollistic view in a way were we can understand how the output variable behaves based on present meteorological values.\n    features = [s for s in features if 'lag'   in s]\n    #If date columns are present will be appended to feature list\n    features.extend([s for s in waterbody.columns if 'Date_'   in s])\n\n    set1=waterbody.dropna()\n    #Selecting only the recent data\n    if len(set1)>1500:\n        set2 = set1[-1500:] \n    else:\n        set2 = set1\n        \n    X1 = set2[features]\n    \n    #standardizing all features that will be used for training\n    scaler = StandardScaler().fit(X1)\n    scaled_df = scaler.transform(X1)\n    X=pd.DataFrame(scaled_df, columns=X1.columns)\n    y = set2[output_col]\n\n    #Splitting the dataset\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=False)\n\n    #Setting up hyper-opt parameters\n    N_HYPEROPT_PROBES = 60\n    HYPEROPT_ALGO = tpe.suggest\n    colorama.init()\n\n    D_train = catboost.Pool(X_train, y_train)\n    D_test = catboost.Pool(X_test, y_test)\n\n    #Defining a function for parameter tunning in hyperopt\n    def objective(space):\n\n        global obj_call_count\n        global cur_best_loss\n        obj_call_count += 1\n\n        #print('\\nCatBoost objective call #{} cur_best_loss={:7.5f}'.format(obj_call_count,cur_best_loss) )\n\n        params = get_catboost_params(space)\n\n        sorted_params = sorted(space.items(), key=lambda z: z[0])\n        params_str = str.join(' ', ['{}={}'.format(k, v) for k, v in sorted_params])\n        #print('Params: {}'.format(params_str) )\n\n        model = catboost.CatBoostRegressor(iterations=5000,\n                                            learning_rate=params['learning_rate'],\n                                            depth=int(params['depth']),\n                                            use_best_model=True,\n    #                                         task_type=\"GPU\",\n                                            eval_metric='RMSE',\n                                            l2_leaf_reg=params['l2_leaf_reg'],\n                                            early_stopping_rounds=800,\n                                            od_type=\"Iter\",\n                                            border_count=int(params['border_count']),\n                                            verbose=False\n                                            )\n        model.fit(D_train, eval_set=D_test, verbose=False)\n        nb_trees = model.tree_count_\n\n        #print('nb_trees={}'.format(nb_trees))\n\n        y_pred = model.predict(D_test.get_features())\n\n        test_loss = sklearn.metrics.mean_squared_error(y_pred, y_test)\n        #acc = sklearn.metrics.accuracy_score(D_test.get_label(), np.argmax(y_pred, axis=1))\n        #auc = sklearn.metrics.roc_auc_score(D_test.get_label(), y_pred[:,1])\n\n        #log_writer.write('loss={:<7.5f}  Params:{} nb_trees={}\\n'.format(test_loss,nb_trees ))\n        #log_writer.flush()\n\n        if test_loss<cur_best_loss:\n            cur_best_loss = test_loss\n            #print(colorama.Fore.GREEN + 'NEW BEST LOSS={}'.format(cur_best_loss) + colorama.Fore.RESET)\n\n\n        return{'loss':test_loss, 'status': STATUS_OK }\n\n    #Defining the space of hyperparameters\n    space = {\n            'depth': hp.quniform(\"depth\", 1, 6, 1),\n            'border_count': hp.uniform ('border_count', 32, 200),\n            'learning_rate': hp.loguniform('learning_rate', -4.0, -1),\n            'l2_leaf_reg': hp.uniform('l2_leaf_reg', 3, 6),\n           }\n\n    trials = Trials()\n    #hyperparameter tuning\n    best = hyperopt.fmin(fn=objective,\n                         space=space,\n                         algo=HYPEROPT_ALGO,\n                         max_evals=N_HYPEROPT_PROBES,\n                         trials=trials,\n                         verbose=False)\n    print('-'*50)\n    print('The best params for '+output_col+' :')\n    print( best )\n    print('\\n\\n')\n\n    #resetting the border count\n    best.update({'border_count': int(best['border_count'])})\n    #Creating the best model\n    model = catboost.CatBoostRegressor(iterations=2000,\n                                        use_best_model=True,\n    #                                     task_type=\"GPU\",\n                                        eval_metric='RMSE',\n                                        early_stopping_rounds=500,\n                                        od_type=\"Iter\",\n                                        verbose=2000,\n                                        **best\n                                        )\n\n    model.fit(D_train,eval_set=D_test,verbose=2000) \n\n    #Feature importance\n    ABS_SHAP(D_train,model,X_train,output_col) \n\n    pred = model.predict(X_test)\n    pred = np.array(pred)\n    #Plotting test set and prediciton\n    testvsmodel(y_test,pred,output_col)\n    \n    #Stroing the error metrics\n    waterbody_df.loc[(waterbody_df.Database==waterbody_name)& (waterbody_df.Output==output_col),\"Catboost_RMSE\"] = mean_squared_error(y_test, pred)\n    waterbody_df.loc[(waterbody_df.Database==waterbody_name)& (waterbody_df.Output==output_col),\"Catboost_MAE\"] = mean_absolute_error(y_test, pred)\n\n    \n    print('-----'+output_col+'-----')\n    print(\"RMSE: \"+str(mean_squared_error(y_test, pred)))\n    print(\"MAE: \"+ str(mean_absolute_error(y_test, pred)))","e1d42000":"for output_col in output_columns:\n    mycatboost(waterbody,output_col,output_columns)","dc4d111f":"waterbody_df","76778ad0":"waterbody_name = \"Lake_Bilancino\"","6bbcbf73":"waterbody = pd.read_csv(waterbody_path.loc[waterbody_name,\"waterbody_path\"])\nwaterbody.tail(5)","69b37f41":"msno.matrix(waterbody)","1bb7da13":"#Setting date column as index\n\nwaterbody['Date']=pd.to_datetime(waterbody['Date'],format='%d\/%m\/%Y')\nwaterbody.set_index('Date',inplace=True)","a4ba18d6":"waterbody = find_start_position(waterbody)\nmsno.matrix(waterbody)","ef95c1b1":"date_continuity(waterbody)","7725b9d9":"dim=len(waterbody.columns)*4\naxes = waterbody.plot.line(subplots=True,figsize=(18,dim))\ntype(axes)","cc2a3734":"violin_plots(waterbody)","9a4a392d":"col_names = waterbody.columns\n\n#Removing outlier for columns other than Rainfall\nfor col in col_names[~col_names.str.contains('Rainfall',regex=True)]:\n    removeoutlier(waterbody[col],3)","3bb311c5":"missing_data=missing_prcnt(waterbody)\nmissing_data","f9653782":"missing_prcnt_yearly(missing_data=missing_data,df1=waterbody)","820d77bb":"interpolate_df(df=waterbody,col_no=[-1])","83d02fef":"annual_resampled_data=waterbody.resample('A').mean()\nmonth_resampled_data=waterbody.resample('M').mean()\nweek_resampled_data=waterbody.resample('W').mean()\nmonth_groupby=waterbody.groupby([waterbody.index.month_name()], sort=False).mean()","dbbbc178":"yearlytrend_and_seasonality(waterbody)","ae226a87":"scatter_colour(month_groupby,col_names[-1],col_names[1],\"Luco: Variation of Flow rate with rainfall\")","3354b722":"yearwise_lineplots(waterbody,col_names[-2])\n# for col in col_names:\n#     yearwise_lineplots(waterbody,col)","e2a9ffa7":"groundwater_col_list, rainfall_col_list, temperature_col_list, volume_col_list, hydrometry_col_list,flow_rate_col_list, lake_level_col_list= categorical_list(waterbody)\n\noutput_columns = flow_rate_col_list+lake_level_col_list","6f6f7b16":"grangers_causation_matrix(waterbody, variables = waterbody.columns) ","838e9dd5":"nobs = 182\nif len(waterbody)>1500:\n    model_df = waterbody[-1500:]\nelse:\n    model_df = waterbody[:]\nmodel_df_train, model_df_test = model_df[0:-nobs], model_df[-nobs:]\n\n# # Check size\n# print(model_df_train.shape) \n# print(model_df_test.shape)  ","3c0989c2":"model_df_train_differenced,no_of_differencing=differencing_till_stationary(model_df_train)","ad527fbc":"model = VAR(model_df_train_differenced)\nresult = model.fit(maxlags=30, ic='aic')\n#print('lag - {}'.format(result.k_ar))\nlag = result.k_ar\n\nmodel_lag = VAR(model_df_train_differenced)\nresult_lag = model_lag.fit(lag)\nresult_lag.summary()\n\nforecast_input = model_df_train_differenced.values[-lag:]\n\n\n\n# Forecast\nfc = result_lag.forecast(y=forecast_input, steps=nobs)\ndf_forecast = pd.DataFrame(fc, index=model_df.index[-nobs:], columns=model_df.columns)","9588474e":"forecasted_df= invert_transformation(model_df,df_forecast, no_of_differencing)","08c28b4a":"predict_store_VAR(forecasted_df,model_df_test,output_columns)","c005dddc":"corr=waterbody.corr()\nplt.figure(figsize=(0.8*len(waterbody.columns),0.5*len(waterbody.columns)))\nsns.heatmap(corr, xticklabels=corr.columns,yticklabels=corr.columns,annot=True)","0fd87097":"prefix_string = \"Rainfall\"\n\nwaterbody=Principal_Component_Analysis(df=waterbody[rainfall_col_list],prefix_string=prefix_string,org_db=waterbody)\n\n#updating col_list\ngroundwater_col_list, rainfall_col_list, temperature_col_list, volume_col_list, hydrometry_col_list,flow_rate_col_list, lake_level_col_list= categorical_list(waterbody)\n\n#re_assgining\ncol_names = waterbody.columns#","138b0319":"create_lags(waterbody,rainfall_col_list)\n#create_lags(waterbody,lake_level_col_list)\n#create_lags(waterbody,flow_rate_col_list)","3e11ddda":"waterbody.columns","447b0da6":"#waterbody =cumsum_column_add(waterbody,rainfall_col_list)\n#waterbody = cumsum_column_add(waterbody,hydrometry_col_list)\nwaterbody = cumsum_column_add(waterbody,['Rainfall_0_lag7'])\n#waterbody = cumsum_column_add(waterbody,['Hydrometry_Fiume_Chiascio_Petrignano_lag7'])\n","0f0d4575":"effect_of_evaporation(waterbody,temperature_col_list[0],['Rainfall_0_lag7'])\n#effect_of_evaporation(waterbody,temperature_col_list[0],['Hydrometry_Fiume_Chiascio_Petrignano_lag7'])","62d7c595":"waterbody.columns","81edb3bf":"decomp_list = get_decomp_list(df=waterbody,output_columns=output_columns)","c41d80c9":"decompose_store_trend(waterbody,decomp_list)","f27d620c":"obj_call_count = 0\ncur_best_loss = np.inf\n#log_writer = open( 'catboost-hyperopt-log.txt', 'w' )","5cacd848":"for output_col in output_columns:\n    mycatboost(waterbody,output_col,output_columns)","ad1e8d54":"waterbody_df","0855b83a":"waterbody_name = \"Water_Spring_Amiata\"","26e054d9":"waterbody = pd.read_csv(waterbody_path.loc[waterbody_name,\"waterbody_path\"])\nwaterbody.tail(5)","9885aae4":"msno.matrix(waterbody)","9a159b6d":"#Setting date column as index\n\nwaterbody['Date']=pd.to_datetime(waterbody['Date'],format='%d\/%m\/%Y')\nwaterbody.set_index('Date',inplace=True)","4320f522":"waterbody = find_start_position(waterbody)\nmsno.matrix(waterbody)","edf4727e":"date_continuity(waterbody)","0d1bc2e3":"dim=len(waterbody.columns)*4\naxes = waterbody.plot.line(subplots=True,figsize=(18,dim))\ntype(axes)","dc65ea97":"violin_plots(waterbody)","74f0eab1":"col_names = waterbody.columns\n\n#Removing outlier for columns other than Rainfall\nfor col in col_names[~col_names.str.contains('Rainfall',regex=True)]:\n    removeoutlier(waterbody[col],3)\n    print(col)","8b2f64d4":"missing_data=missing_prcnt(waterbody)\nmissing_data","ef43d59b":"missing_prcnt_yearly(missing_data=missing_data,df1=waterbody)","63911d02":"#interpolate_df(df=waterbody,col_no=[-1])","72b9e47a":"groundwater_col_list, rainfall_col_list, temperature_col_list, volume_col_list, hydrometry_col_list,flow_rate_col_list, lake_level_col_list= categorical_list(waterbody)\noutput_columns = flow_rate_col_list","05f51ea1":"corr=waterbody.corr()\nplt.figure(figsize=(0.8*len(waterbody.columns),0.5*len(waterbody.columns)))\nsns.heatmap(corr, xticklabels=corr.columns,yticklabels=corr.columns,annot=True)","4c3c55b1":"X1 = waterbody[rainfall_col_list]\nimp = IterativeImputer(RandomForestRegressor(), max_iter=15, random_state=1)\nresult_X1 = imp.fit_transform(X1)\nresult_X1 = pd.DataFrame(result_X1, columns=X1.columns, index= X1.index)\nwaterbody[rainfall_col_list] = result_X1","e221c928":"X1 = waterbody[groundwater_col_list]\nimp = IterativeImputer(RandomForestRegressor(), max_iter=15, random_state=1)\nresult_X1 = imp.fit_transform(X1)\nresult_X1 = pd.DataFrame(result_X1, columns=X1.columns, index= X1.index)\nwaterbody[groundwater_col_list] = result_X1","aa67feb5":"X1 = waterbody[temperature_col_list]\nimp = IterativeImputer(RandomForestRegressor(), max_iter=15, random_state=1)\nresult_X1 = imp.fit_transform(X1)\nresult_X1 = pd.DataFrame(result_X1, columns=X1.columns, index= X1.index)\nwaterbody[temperature_col_list] = result_X1","ffe82a6a":"X1 = waterbody[flow_rate_col_list]\nimp = IterativeImputer(RandomForestRegressor(), max_iter=15, random_state=1)\nresult_X1 = imp.fit_transform(X1)\nresult_X1 = pd.DataFrame(result_X1, columns=X1.columns, index= X1.index)\nwaterbody[flow_rate_col_list] = result_X1","8686dbf7":"annual_resampled_data=waterbody.resample('A').mean()\nmonth_resampled_data=waterbody.resample('M').mean()\nweek_resampled_data=waterbody.resample('W').mean()\nmonth_groupby=waterbody.groupby([waterbody.index.month_name()], sort=False).mean()","faa273d3":"yearlytrend_and_seasonality(waterbody)","45e88275":"scatter_colour(month_groupby,col_names[-1],col_names[6],\"Luco: Variation of Flow rate with rainfall\")","37c617bf":"yearwise_lineplots(waterbody,col_names[-3])\n# for col in col_names:\n#     yearwise_lineplots(waterbody,col)","4a5d57b3":"grangers_causation_matrix(waterbody, variables = waterbody.columns)","4d83dcf2":"nobs = 182\nif len(waterbody)>1500:\n    model_df = waterbody[-1500:]\nelse:\n    model_df = waterbody[:]\nmodel_df_train, model_df_test = model_df[0:-nobs], model_df[-nobs:]\n\n# # Check size\n# print(model_df_train.shape)\n# print(model_df_test.shape) ","2c360ca3":"model_df_train_differenced,no_of_differencing=differencing_till_stationary(model_df_train)","26397671":"model = VAR(model_df_train_differenced)\nresult = model.fit(maxlags=30, ic='aic')\n#print('lag - {}'.format(result.k_ar))\nlag = result.k_ar\n\nmodel_lag = VAR(model_df_train_differenced)\nresult_lag = model_lag.fit(lag)\nresult_lag.summary()\n\nforecast_input = model_df_train_differenced.values[-lag:]\n\n# Forecast\nfc = result_lag.forecast(y=forecast_input, steps=nobs)\ndf_forecast = pd.DataFrame(fc, index=model_df.index[-nobs:], columns=model_df.columns)","62be069e":"forecasted_df= invert_transformation(model_df,df_forecast, no_of_differencing)","eefb032f":"predict_store_VAR(forecasted_df,model_df_test,output_columns)","befa562a":"corr=waterbody.corr()\nplt.figure(figsize=(0.8*len(waterbody.columns),0.5*len(waterbody.columns)))\nsns.heatmap(corr, xticklabels=corr.columns,yticklabels=corr.columns,annot=True)","de020297":"prefix_string = \"Rainfall\"\n\nwaterbody=Principal_Component_Analysis(df=waterbody[rainfall_col_list],prefix_string=prefix_string,org_db=waterbody)\n\nprefix_string = \"Depth\"\n\nwaterbody=Principal_Component_Analysis(df=waterbody[groundwater_col_list],prefix_string=prefix_string,org_db=waterbody)\n#updating col_list\nprefix_string = \"Temperature\"\n\nwaterbody=Principal_Component_Analysis(df=waterbody[temperature_col_list],prefix_string=prefix_string,org_db=waterbody)\n\ngroundwater_col_list, rainfall_col_list, temperature_col_list, volume_col_list, hydrometry_col_list,flow_rate_col_list, lake_level_col_list= categorical_list(waterbody)\n\n#re_assgining\ncol_names = waterbody.columns","8c9e2622":"create_lags(waterbody,rainfall_col_list)\ncreate_lags(waterbody,groundwater_col_list)\n#create_lags(waterbody,flow_rate_col_list)","85762c3e":"waterbody.columns","1f1be0ba":"#waterbody =cumsum_column_add(waterbody,rainfall_col_list)\n#waterbody = cumsum_column_add(waterbody,hydrometry_col_list)\nwaterbody = cumsum_column_add(waterbody,['Rainfall_0_lag7'])\n#waterbody = cumsum_column_add(waterbody,['Hydrometry_Fiume_Chiascio_Petrignano_lag7'])\n","8824c627":"effect_of_evaporation(waterbody,temperature_col_list[0],['Rainfall_0_lag7'])\n#effect_of_evaporation(waterbody,temperature_col_list[0],['Hydrometry_Fiume_Chiascio_Petrignano_lag7'])","8f4b7b43":"waterbody.columns","a56ba5df":"decomp_list = get_decomp_list(df=waterbody,output_columns=output_columns)","e6bfc4f2":"decompose_store_trend(waterbody,decomp_list)","0bdad934":"obj_call_count = 0\ncur_best_loss = np.inf\n#log_writer = open( 'catboost-hyperopt-log.txt', 'w' )","061a985a":"for output_col in output_columns:\n    mycatboost(waterbody,output_col,output_columns)","e15b1027":"waterbody_df","f725fa45":"waterbody_name = \"River_Arno\"","dadfc633":"waterbody = pd.read_csv(waterbody_path.loc[waterbody_name,\"waterbody_path\"])\nwaterbody.tail(5)","c6bad93f":"msno.matrix(waterbody)","a9a72d1d":"#Setting date column as index\n\nwaterbody['Date']=pd.to_datetime(waterbody['Date'],format='%d\/%m\/%Y')\nwaterbody.set_index('Date',inplace=True)","bda340a9":"waterbody = find_start_position(waterbody)\nmsno.matrix(waterbody)","da0c99e1":"waterbody.drop(['Rainfall_Vernio',\"Rainfall_Stia\",\"Rainfall_Consuma\",\"Rainfall_Incisa\",\"Rainfall_Montevarchi\",\"Rainfall_S_Savino\",\"Rainfall_Laterina\",\"Rainfall_Bibbiena\",\"Rainfall_Camaldoli\"],axis=1,inplace=True)","30ca5691":"date_continuity(waterbody)","01778764":"dim=len(waterbody.columns)*4\naxes = waterbody.plot.line(subplots=True,figsize=(18,dim))\ntype(axes)","dbb3217a":"violin_plots(waterbody)","f9f0adaf":"col_names = waterbody.columns\n\n#Removing outlier for columns other than Rainfall\nfor col in col_names[~col_names.str.contains('Rainfall',regex=True)]:\n    removeoutlier(waterbody[col],3)\n    ","a0989757":"missing_data=missing_prcnt(waterbody)\nmissing_data","b03c6320":"missing_prcnt_yearly(missing_data=missing_data,df1=waterbody)","adf67c95":"#interpolate_df(df=waterbody,col_no=[-1])","ac930eb0":"groundwater_col_list, rainfall_col_list, temperature_col_list, volume_col_list, hydrometry_col_list,flow_rate_col_list, lake_level_col_list= categorical_list(waterbody)\noutput_columns = hydrometry_col_list","53a40937":"corr=waterbody.corr()\nplt.figure(figsize=(0.8*len(waterbody.columns),0.5*len(waterbody.columns)))\nsns.heatmap(corr, xticklabels=corr.columns,yticklabels=corr.columns,annot=True)","bc369422":"temp_df=waterbody.filter(temperature_col_list,axis=1).copy()\ntemp_df['Year']=pd.DatetimeIndex(temp_df.index).year\ntemp_df['month']=pd.DatetimeIndex(temp_df.index).month\ntemp_df['day']=pd.DatetimeIndex(temp_df.index).day\nmonth_in_year = 12\ntemp_df['month_sin'] = np.sin(2*np.pi*temp_df.month\/month_in_year)\ntemp_df['month_cos'] = np.cos(2*np.pi*temp_df.month\/month_in_year)\ntemp_df['season'] = temp_df.month%12 \/\/ 3 + 1\n\ntemp_df['day_of_year'] = pd.DatetimeIndex(temp_df.index).dayofyear\ndays_in_year = 365.25\ntemp_df['day_of_year_sin'] = np.sin(2*np.pi*temp_df.day_of_year\/days_in_year)\ntemp_df['day_of_year_cos'] = np.cos(2*np.pi*temp_df.day_of_year\/days_in_year)\n\ntemp_df['week_of_year'] = pd.DatetimeIndex(temp_df.index).weekofyear\nweeks_in_year = 52.1429\ntemp_df['week_of_year_sin'] = np.sin(2*np.pi*temp_df.week_of_year\/weeks_in_year)\ntemp_df['week_of_year_cos'] = np.cos(2*np.pi*temp_df.week_of_year\/weeks_in_year)","86250b59":"X1 = temp_df\nimp = IterativeImputer(RandomForestRegressor(), max_iter=15, random_state=1)\nresult_X1 = imp.fit_transform(X1)\nresult_X1 = pd.DataFrame(result_X1, columns=X1.columns, index= X1.index)\nwaterbody[temperature_col_list] = result_X1[temperature_col_list]","daa8befe":"interpolate_df(df=waterbody,col_no=[-1])","7b303006":"annual_resampled_data=waterbody.resample('A').mean()\nmonth_resampled_data=waterbody.resample('M').mean()\nweek_resampled_data=waterbody.resample('W').mean()\nmonth_groupby=waterbody.groupby([waterbody.index.month_name()], sort=False).mean()","29a76c16":"yearlytrend_and_seasonality(waterbody)","b2d650cf":"scatter_colour(month_groupby,col_names[6],col_names[1],\"Arno: Variation of Flow rate with rainfall\")","a23c3ce2":"yearwise_lineplots(waterbody,col_names[6])\n# for col in col_names:\n#     yearwise_lineplots(waterbody,col)","78bf7b42":"waterbody[col_names[-1]].plot.line(figsize=(18,5))","7afe0330":"grangers_causation_matrix(waterbody, variables = waterbody.columns)","ff9c4a6c":"nobs = 182\nif len(waterbody)>1500:\n    model_df = waterbody[-1500:]\nelse:\n    model_df = waterbody[:]\nmodel_df_train, model_df_test = model_df[0:-nobs], model_df[-nobs:]\n\n# # Check size\n# print(model_df_train.shape)\n# print(model_df_test.shape) ","0a7090fd":"model_df_train_differenced,no_of_differencing=differencing_till_stationary(model_df_train)","2571d8f8":"model = VAR(model_df_train_differenced)\nresult = model.fit(maxlags=30, ic='aic')\n#print('lag - {}'.format(result.k_ar))\nlag = result.k_ar\n\nmodel_lag = VAR(model_df_train_differenced)\nresult_lag = model_lag.fit(lag)\nresult_lag.summary()\n\nforecast_input = model_df_train_differenced.values[-lag:]\n\n# Forecast\nfc = result_lag.forecast(y=forecast_input, steps=nobs)\ndf_forecast = pd.DataFrame(fc, index=model_df.index[-nobs:], columns=model_df.columns)","326d992a":"forecasted_df= invert_transformation(model_df,df_forecast, no_of_differencing)","9cf72bfd":"predict_store_VAR(forecasted_df,model_df_test,output_columns)","220bc772":"corr=waterbody.corr()\nplt.figure(figsize=(0.8*len(waterbody.columns),0.5*len(waterbody.columns)))\nsns.heatmap(corr, xticklabels=corr.columns,yticklabels=corr.columns,annot=True)","6ead4335":"prefix_string = \"Rainfall\"\n\nwaterbody=Principal_Component_Analysis(df=waterbody[rainfall_col_list],prefix_string=prefix_string,org_db=waterbody)\n#updating col_list\n\ngroundwater_col_list, rainfall_col_list, temperature_col_list, volume_col_list, hydrometry_col_list,flow_rate_col_list, lake_level_col_list= categorical_list(waterbody)\n\n#re_assgining\ncol_names = waterbody.columns","6905e9bd":"create_lags(waterbody,rainfall_col_list)\n#create_lags(waterbody,hydrometry_col_list)\n","4b25388e":"waterbody.columns","3fc09985":"#waterbody =cumsum_column_add(waterbody,rainfall_col_list)\n#waterbody = cumsum_column_add(waterbody,hydrometry_col_list)\nwaterbody = cumsum_column_add(waterbody,['Rainfall_0_lag7'])\n#waterbody = cumsum_column_add(waterbody,hydrometry_col_list)\n","39d41f7a":"effect_of_evaporation(waterbody,temperature_col_list[0],['Rainfall_0_lag7'])\n#effect_of_evaporation(waterbody,temperature_col_list[0],hydrometry_col_list)","cac4e021":"waterbody.columns","e7ad8deb":"decomp_list = get_decomp_list(df=waterbody,output_columns=output_columns)","ea588cc6":"decompose_store_trend(waterbody,decomp_list)","875e2d40":"obj_call_count = 0\ncur_best_loss = np.inf\n#log_writer = open( 'catboost-hyperopt-log.txt', 'w' )","20bdfb2a":"for output_col in output_columns:\n    mycatboost(waterbody,output_col,output_columns)","1d61524b":"waterbody_df","3e589ee7":"waterbody_name = \"Water_Spring_Lupa\"","af5cdf11":"waterbody = pd.read_csv(waterbody_path.loc[waterbody_name,\"waterbody_path\"])\nwaterbody.tail(5)","74efa080":"msno.matrix(waterbody)","3b5365f2":"#Setting date column as index\n\nwaterbody['Date']=pd.to_datetime(waterbody['Date'],format='%d\/%m\/%Y')\nwaterbody.set_index('Date',inplace=True)\n\n#Renaming column name Flow_Rate_Madonna_di_Canneto, as it is different from what is present in the waterbody_df\nwaterbody.rename(columns={'Flow_Rate_Lupa': 'Flow_Rate'},inplace=True)","9c4a798d":"waterbody = find_start_position(waterbody)\nmsno.matrix(waterbody)","f57a8c0c":"date_continuity(waterbody)","1a7d2417":"dim=len(waterbody.columns)*4\naxes = waterbody.plot.line(subplots=True,figsize=(18,dim))\ntype(axes)","07c61cb7":"violin_plots(waterbody)","948adb93":"col_names = waterbody.columns\n\n#Removing outlier for columns other than Rainfall\nfor col in col_names[~col_names.str.contains('Rainfall',regex=True)]:\n    removeoutlier(waterbody[col],3)\n","100439aa":"missing_data=missing_prcnt(waterbody)\nmissing_data","7c35c004":"missing_prcnt_yearly(missing_data=missing_data,df1=waterbody)","5610bb96":"waterbody = waterbody[730:]","7ed519c2":"interpolate_df(df=waterbody,col_no=[-1])","cd334ba3":"groundwater_col_list, rainfall_col_list, temperature_col_list, volume_col_list, hydrometry_col_list,flow_rate_col_list, lake_level_col_list= categorical_list(waterbody)\noutput_columns = flow_rate_col_list","a926c5df":"corr=waterbody.corr()\nplt.figure(figsize=(0.8*len(waterbody.columns),0.5*len(waterbody.columns)))\nsns.heatmap(corr, xticklabels=corr.columns,yticklabels=corr.columns,annot=True)","cc6ce2ca":"annual_resampled_data=waterbody.resample('A').mean()\nmonth_resampled_data=waterbody.resample('M').mean()\nweek_resampled_data=waterbody.resample('W').mean()\nmonth_groupby=waterbody.groupby([waterbody.index.month_name()], sort=False).mean()","c30a757d":"yearlytrend_and_seasonality(waterbody)","113e0de9":"scatter_colour(month_groupby,col_names[0],col_names[1],\"Lupa: Variation of Flow rate with rainfall\")","aac2f312":"yearwise_lineplots(waterbody,col_names[1])\n# for col in col_names:\n#     yearwise_lineplots(waterbody,col)","b88c02b6":"grangers_causation_matrix(waterbody, variables = waterbody.columns)","42528262":"nobs = 182\nif len(waterbody)>1500:\n    model_df = waterbody[-1500:]\nelse:\n    model_df = waterbody[:]\nmodel_df_train, model_df_test = model_df[0:-nobs], model_df[-nobs:]\n\n# # Check size\n# print(model_df_train.shape)\n# print(model_df_test.shape) ","15ae41f7":"model_df_train_differenced,no_of_differencing=differencing_till_stationary(model_df_train)","e5df6b2a":"model = VAR(model_df_train_differenced)\nresult = model.fit(maxlags=30, ic='aic')\n#print('lag - {}'.format(result.k_ar))\nlag = result.k_ar\n\nmodel_lag = VAR(model_df_train_differenced)\nresult_lag = model_lag.fit(lag)\nresult_lag.summary()\n\nforecast_input = model_df_train_differenced.values[-lag:]\n\n# Forecast\nfc = result_lag.forecast(y=forecast_input, steps=nobs)\ndf_forecast = pd.DataFrame(fc, index=model_df.index[-nobs:], columns=model_df.columns)","acefc5cb":"forecasted_df= invert_transformation(model_df,df_forecast, no_of_differencing)","11a05a54":"predict_store_VAR(forecasted_df,model_df_test,output_columns)","194129a1":"corr=waterbody.corr()\nplt.figure(figsize=(0.8*len(waterbody.columns),0.5*len(waterbody.columns)))\nsns.heatmap(corr, xticklabels=corr.columns,yticklabels=corr.columns,annot=True)","1be9acdd":"create_lags(waterbody,rainfall_col_list)\n#create_lags(waterbody,flow_rate_col_list)\n","558e050d":"waterbody.columns","6a7130e4":"#waterbody =cumsum_column_add(waterbody,rainfall_col_list)\n#waterbody = cumsum_column_add(waterbody,hydrometry_col_list)\nwaterbody = cumsum_column_add(waterbody,['Rainfall_Terni_lag7'])\n#waterbody = cumsum_column_add(waterbody,hydrometry_col_list)\n","672119c9":"#effect_of_evaporation(waterbody,temperature_col_list[0],['Rainfall_Terni_lag7'])\n#effect_of_evaporation(waterbody,temperature_col_list[0],hydrometry_col_list)","821792bb":"waterbody.columns","604992f2":"decomp_list = get_decomp_list(df=waterbody,output_columns=output_columns)","c73d9b61":"decompose_store_trend(waterbody,decomp_list)","b82ba67b":"obj_call_count = 0\ncur_best_loss = np.inf\n#log_writer = open( 'catboost-hyperopt-log.txt', 'w' )","4f7ed453":"for output_col in output_columns:\n    mycatboost(waterbody,output_col,output_columns,putDate=True)","26695246":"waterbody_df","7281bdf6":"waterbody_name = \"Water_Spring_Madonna_di_Canneto\"","79d81c30":"waterbody = pd.read_csv(waterbody_path.loc[waterbody_name,\"waterbody_path\"])\nwaterbody.tail(5)","8e128c78":"msno.matrix(waterbody)","0b11f72c":"#Setting date column as index\n\nwaterbody['Date']=pd.to_datetime(waterbody['Date'],format='%d\/%m\/%Y')\nwaterbody.set_index('Date',inplace=True)\n\n#Renaming column name Flow_Rate_Madonna_di_Canneto, as it is different from what is present in the waterbody_df\nwaterbody.rename(columns={'Flow_Rate_Madonna_di_Canneto': 'Flow_Rate'},inplace=True)","581f43f9":"waterbody = find_start_position(waterbody)\nmsno.matrix(waterbody)","c9a9dae0":"date_continuity(waterbody)","147a36aa":"dim=len(waterbody.columns)*4\naxes = waterbody.plot.line(subplots=True,figsize=(18,dim))\ntype(axes)","7c236c40":"violin_plots(waterbody)","14e1e13a":"col_names = waterbody.columns\n\n#Removing outlier for columns other than Rainfall\nfor col in col_names[~col_names.str.contains('Rainfall',regex=True)]:\n    removeoutlier(waterbody[col],3)\n","004c3094":"missing_data=missing_prcnt(waterbody)\nmissing_data","6ae650fd":"#interpolate_df(df=waterbody,col_no=[-1])","d806854b":"groundwater_col_list, rainfall_col_list, temperature_col_list, volume_col_list, hydrometry_col_list,flow_rate_col_list, lake_level_col_list= categorical_list(waterbody)\noutput_columns = flow_rate_col_list","ac44df0c":"corr=waterbody.corr()\nplt.figure(figsize=(0.8*len(waterbody.columns),0.5*len(waterbody.columns)))\nsns.heatmap(corr, xticklabels=corr.columns,yticklabels=corr.columns,annot=True)","d636f1ed":"waterbody = waterbody.dropna()","dc106bf0":"grangers_causation_matrix(waterbody, variables = waterbody.columns)","2fdbfb63":"nobs = 182\nif len(waterbody)>1500:\n    model_df = waterbody[-1500:]\nelse:\n    model_df = waterbody[:]\nmodel_df_train, model_df_test = model_df[0:-nobs], model_df[-nobs:]\n\n# # Check size\n# print(model_df_train.shape)\n# print(model_df_test.shape) ","a9feed0a":"model_df_train_differenced,no_of_differencing=differencing_till_stationary(model_df_train)","a64da585":"model = VAR(model_df_train_differenced)\nresult = model.fit(maxlags=30, ic='aic')\n#print('lag - {}'.format(result.k_ar))\nlag = result.k_ar\n\nmodel_lag = VAR(model_df_train_differenced)\nresult_lag = model_lag.fit(lag)\nresult_lag.summary()\n\nforecast_input = model_df_train_differenced.values[-lag:]\n\n# Forecast\nfc = result_lag.forecast(y=forecast_input, steps=nobs)\ndf_forecast = pd.DataFrame(fc, index=model_df.index[-nobs:], columns=model_df.columns)","d2ca9848":"forecasted_df= invert_transformation(model_df,df_forecast, no_of_differencing)","01e83177":"predict_store_VAR(forecasted_df,model_df_test,output_columns)","b1c24a58":"for output_col in output_columns:\n    mycatboost(waterbody,output_col,output_columns,putDate=True)","be219d03":"waterbody_df","de7b8855":"waterbody_name = \"Aquifer_Doganella\"","24efbe28":"waterbody = pd.read_csv(waterbody_path.loc[waterbody_name,\"waterbody_path\"])\nwaterbody.tail(5)","c8461474":"msno.matrix(waterbody)","dc6c4a27":"#Setting date column as index\n\nwaterbody['Date']=pd.to_datetime(waterbody['Date'],format='%d\/%m\/%Y')\nwaterbody.set_index('Date',inplace=True)","9dc39038":"waterbody = find_start_position(waterbody)\n\nmsno.matrix(waterbody)","2cd7f4cf":"waterbody.drop(['Temperature_Monteporzio','Temperature_Velletri'],axis=1,inplace=True)","fc53aa5d":"date_continuity(waterbody)","4a78c554":"dim=len(waterbody.columns)*4\naxes = waterbody.plot.line(subplots=True,figsize=(18,dim))\ntype(axes)","c9732fb0":"violin_plots(waterbody)","d3bc33f0":"col_names = waterbody.columns\n\n#Removing outlier for columns other than Rainfall\nfor col in col_names[~col_names.str.contains('Rainfall',regex=True)]:\n    removeoutlier(waterbody[col],3)","c6758ed0":"missing_data=missing_prcnt(waterbody)\nmissing_data","a658b69c":"missing_prcnt_yearly(missing_data=missing_data,df1=waterbody)","48f93096":"#interpolate_df(df=waterbody,col_no=[-1])","7c8a285f":"groundwater_col_list, rainfall_col_list, temperature_col_list, volume_col_list, hydrometry_col_list,flow_rate_col_list, lake_level_col_list= categorical_list(waterbody)\noutput_columns = groundwater_col_list","a683b52d":"corr=waterbody.corr()\nplt.figure(figsize=(0.8*len(waterbody.columns),0.5*len(waterbody.columns)))\nsns.heatmap(corr, xticklabels=corr.columns,yticklabels=corr.columns,annot=True)","712413cd":"X1 = waterbody[rainfall_col_list]\nimp = IterativeImputer(RandomForestRegressor(), max_iter=15, random_state=1)\nresult_X1 = imp.fit_transform(X1)\nresult_X1 = pd.DataFrame(result_X1, columns=X1.columns, index= X1.index)\nwaterbody[rainfall_col_list] = result_X1","05177d3d":"X1 = waterbody[volume_col_list]\nimp = IterativeImputer(RandomForestRegressor(), max_iter=15, random_state=1)\nresult_X1 = imp.fit_transform(X1)\nresult_X1 = pd.DataFrame(result_X1, columns=X1.columns, index= X1.index)\nwaterbody[volume_col_list] = result_X1","6ce550f6":"\nwaterbody=waterbody.dropna()","fa363e1c":"grangers_causation_matrix(waterbody, variables = waterbody.columns)","65ecee60":"nobs = 182\nif len(waterbody)>1500:\n    model_df = waterbody[-1500:]\nelse:\n    model_df = waterbody[:]\nmodel_df_train, model_df_test = model_df[0:-nobs], model_df[-nobs:]\n\n# # Check size\n# print(model_df_train.shape)\n# print(model_df_test.shape) ","fa857dd9":"model_df_train_differenced,no_of_differencing=differencing_till_stationary(model_df_train)","2fbe8acf":"model = VAR(model_df_train_differenced)\nresult = model.fit(maxlags=30, ic='aic')\n#print('lag - {}'.format(result.k_ar))\nlag = result.k_ar\n\nmodel_lag = VAR(model_df_train_differenced)\nresult_lag = model_lag.fit(lag)\nresult_lag.summary()\n\nforecast_input = model_df_train_differenced.values[-lag:]\n\n# Forecast\nfc = result_lag.forecast(y=forecast_input, steps=nobs)\ndf_forecast = pd.DataFrame(fc, index=model_df.index[-nobs:], columns=model_df.columns)","2d26f41b":"forecasted_df= invert_transformation(model_df,df_forecast, no_of_differencing)","edf9d823":"predict_store_VAR(forecasted_df,model_df_test,output_columns)","15be83eb":"create_lags(waterbody,rainfall_col_list)\n#create_lags(waterbody,flow_rate_col_list)\n","8d2dffc1":"waterbody.columns","3f3b4034":"waterbody =cumsum_column_add(waterbody,rainfall_col_list)\n#waterbody = cumsum_column_add(waterbody,hydrometry_col_list)\n#waterbody = cumsum_column_add(waterbody,['Rainfall_Terni_lag7'])\n#waterbody = cumsum_column_add(waterbody,hydrometry_col_list)\n","4ed69d4e":"decomp_list = get_decomp_list(df=waterbody,output_columns=output_columns)","6451f216":"decompose_store_trend(waterbody,decomp_list)","7a851049":"obj_call_count = 0\ncur_best_loss = np.inf\n#log_writer = open( 'catboost-hyperopt-log.txt', 'w' )","d0084e51":"for output_col in output_columns:\n    mycatboost(waterbody,output_col,output_columns)","74f4357a":"waterbody_df","1919d1f4":"waterbody_name = \"Aquifer_Auser\"","85d71eb3":"waterbody = pd.read_csv(waterbody_path.loc[waterbody_name,\"waterbody_path\"])\nwaterbody.tail(5)","4d62c143":"msno.matrix(waterbody)","3e905c84":"#Setting date column as index\n\nwaterbody['Date']=pd.to_datetime(waterbody['Date'],format='%d\/%m\/%Y')\nwaterbody.set_index('Date',inplace=True)\n\n#The CoS in the waterbody dataframe is different from waterbody_df, renaming the column\nwaterbody.rename(columns={'Depth_to_Groundwater_CoS': 'Depth_to_Groundwater_COS'},inplace=True)","353639bd":"waterbody = find_start_position(waterbody)\n\nmsno.matrix(waterbody)","ac0e0772":"date_continuity(waterbody)","b826b037":"dim=len(waterbody.columns)*4\naxes = waterbody.plot.line(subplots=True,figsize=(18,dim))\ntype(axes)","220ca32a":"waterbody.drop('Temperature_Ponte_a_Moriano', axis =1, inplace=True)","30e0aa16":"waterbody= waterbody[1095:]","9ec32750":"violin_plots(waterbody)","1b6bdba1":"col_names = waterbody.columns\n\n#Removing outlier for columns other than Rainfall\nfor col in col_names[~col_names.str.contains('Rainfall',regex=True)]:\n    removeoutlier(waterbody[col],3)","19693113":"missing_data=missing_prcnt(waterbody)\nmissing_data","c31215c6":"missing_prcnt_yearly(missing_data=missing_data,df1=waterbody)","5c3c3de2":"corr=waterbody.corr()\nplt.figure(figsize=(0.8*len(waterbody.columns),0.5*len(waterbody.columns)))\nsns.heatmap(corr, xticklabels=corr.columns,yticklabels=corr.columns,annot=True)","ec6fbb56":"groundwater_col_list, rainfall_col_list, temperature_col_list, volume_col_list, hydrometry_col_list,flow_rate_col_list, lake_level_col_list= categorical_list(waterbody)\noutput_columns = groundwater_col_list","ea12c4de":"X1 = waterbody[rainfall_col_list]\nimp = IterativeImputer(RandomForestRegressor(), max_iter=15, random_state=1)\nresult_X1 = imp.fit_transform(X1)\nresult_X1 = pd.DataFrame(result_X1, columns=X1.columns, index= X1.index)\nwaterbody[rainfall_col_list] = result_X1","390877e2":"X1 = waterbody[groundwater_col_list]\nimp = IterativeImputer(RandomForestRegressor(), max_iter=15, random_state=1)\nresult_X1 = imp.fit_transform(X1)\nresult_X1 = pd.DataFrame(result_X1, columns=X1.columns, index= X1.index)\nwaterbody[groundwater_col_list] = result_X1","beee9e4a":"X1 = waterbody[temperature_col_list]\nimp = IterativeImputer(RandomForestRegressor(), max_iter=15, random_state=1)\nresult_X1 = imp.fit_transform(X1)\nresult_X1 = pd.DataFrame(result_X1, columns=X1.columns, index= X1.index)\nwaterbody[temperature_col_list] = result_X1","02cc2898":"X1 = waterbody[hydrometry_col_list]\nimp = IterativeImputer(RandomForestRegressor(), max_iter=15, random_state=1)\nresult_X1 = imp.fit_transform(X1)\nresult_X1 = pd.DataFrame(result_X1, columns=X1.columns, index= X1.index)\nwaterbody[hydrometry_col_list] = result_X1","784ba447":"X1 = waterbody[volume_col_list]\nimp = IterativeImputer(RandomForestRegressor(), max_iter=15, random_state=1)\nresult_X1 = imp.fit_transform(X1)\nresult_X1 = pd.DataFrame(result_X1, columns=X1.columns, index= X1.index)\nwaterbody[volume_col_list] = result_X1","7fcbcad1":"dim=len(waterbody.columns)*4\naxes = waterbody.plot.line(subplots=True,figsize=(18,dim))\ntype(axes)","12ef8775":"annual_resampled_data=waterbody.resample('A').mean()\nmonth_resampled_data=waterbody.resample('M').mean()\nweek_resampled_data=waterbody.resample('W').mean()\nmonth_groupby=waterbody.groupby([waterbody.index.month_name()], sort=False).mean()","1436fc26":"yearlytrend_and_seasonality(waterbody)","98888a20":"scatter_colour(month_groupby,col_names[-1],col_names[6],\"Aquifer Auser: Variation of Flow rate with rainfall\")","c5930233":"yearwise_lineplots(waterbody,col_names[-3])\n# for col in col_names:\n#     yearwise_lineplots(waterbody,col)","03d31fb8":"\nwaterbody=waterbody.dropna()","3b28a69e":"grangers_causation_matrix(waterbody.dropna(), variables = waterbody.columns)","fa626a05":"nobs = 182\nif len(waterbody)>1500:\n    model_df = waterbody[-1500:]\nelse:\n    model_df = waterbody[:]\nmodel_df_train, model_df_test = model_df[0:-nobs], model_df[-nobs:]\n\n# # Check size\n# print(model_df_train.shape)\n# print(model_df_test.shape) ","610e525a":"model_df_train_differenced,no_of_differencing=differencing_till_stationary(model_df_train)","10b4d941":"model = VAR(model_df_train_differenced)\nresult = model.fit(maxlags=30, ic='aic')\n#print('lag - {}'.format(result.k_ar))\nlag = result.k_ar\n\nmodel_lag = VAR(model_df_train_differenced)\nresult_lag = model_lag.fit(lag)\nresult_lag.summary()\n\nforecast_input = model_df_train_differenced.values[-lag:]\n\n# Forecast\nfc = result_lag.forecast(y=forecast_input, steps=nobs)\ndf_forecast = pd.DataFrame(fc, index=model_df.index[-nobs:], columns=model_df.columns)","05e0aea1":"forecasted_df= invert_transformation(model_df,df_forecast, no_of_differencing)","2d0cd593":"predict_store_VAR(forecasted_df,model_df_test,output_columns)","ab8ad4b3":"corr=waterbody.corr()\nplt.figure(figsize=(0.8*len(waterbody.columns),0.5*len(waterbody.columns)))\nsns.heatmap(corr, xticklabels=corr.columns,yticklabels=corr.columns,annot=True)","77b35d6b":"prefix_string = \"Rainfall\"\n\nwaterbody=Principal_Component_Analysis(df=waterbody[rainfall_col_list],prefix_string=prefix_string,org_db=waterbody)\n\nprefix_string = \"Temperature\"\n\nwaterbody=Principal_Component_Analysis(df=waterbody[temperature_col_list],prefix_string=prefix_string,org_db=waterbody)\n\n#updating col_list\ngroundwater_col_list, rainfall_col_list, temperature_col_list, volume_col_list, hydrometry_col_list,flow_rate_col_list, lake_level_col_list= categorical_list(waterbody)\n\n#re_assgining\ncol_names = waterbody.columns","515410ed":"create_lags(waterbody,rainfall_col_list)\ncreate_lags(waterbody,hydrometry_col_list)\ncreate_lags(waterbody,volume_col_list)","49a7bd63":"waterbody.columns","ee272348":"#waterbody =cumsum_column_add(waterbody,rainfall_col_list)\n#waterbody = cumsum_column_add(waterbody,hydrometry_col_list)\nwaterbody = cumsum_column_add(waterbody,['Rainfall_0_lag7'])\nwaterbody = cumsum_column_add(waterbody,['Hydrometry_Monte_S_Quirico_lag7','Hydrometry_Piaggione_lag7'])\n","f05c9013":"effect_of_evaporation(waterbody,temperature_col_list[0],['Rainfall_0_lag7'])\neffect_of_evaporation(waterbody,temperature_col_list[0],['Hydrometry_Monte_S_Quirico_lag7','Hydrometry_Piaggione_lag7'])","8bf1d0c8":"decomp_list = get_decomp_list(df=waterbody,output_columns=output_columns)","79f6c230":"decompose_store_trend(waterbody,decomp_list)","64b73fca":"obj_call_count = 0\ncur_best_loss = np.inf\n#log_writer = open( 'catboost-hyperopt-log.txt', 'w' )","e5db792d":"for output_col in output_columns:\n    mycatboost(waterbody,output_col,output_columns)","2ff9f80c":"waterbody_df","e2c5b879":"waterbody_name = \"Aquifer_Luco\"","548df60b":"waterbody = pd.read_csv(waterbody_path.loc[waterbody_name,\"waterbody_path\"])\nwaterbody.tail(5)","b26088d9":"msno.matrix(waterbody)","b6abedc3":"#Setting date column as index\n\nwaterbody['Date']=pd.to_datetime(waterbody['Date'],format='%d\/%m\/%Y')\nwaterbody.set_index('Date',inplace=True)","c0affa1b":"waterbody = find_start_position(waterbody)\nmsno.matrix(waterbody)","3fd0395c":"date_continuity(waterbody)","d9bfb48a":"dim=len(waterbody.columns)*4\naxes = waterbody.plot.line(subplots=True,figsize=(18,dim))\ntype(axes)","5d6f7a4c":"violin_plots(waterbody)","e319a7b6":"col_names = waterbody.columns\n\n#Removing outlier for columns other than Rainfall\nfor col in col_names[~col_names.str.contains('Rainfall',regex=True)]:\n    removeoutlier(waterbody[col],3)","db99a941":"missing_data=missing_prcnt(waterbody)\nmissing_data","a76fd212":"missing_prcnt_yearly(missing_data=missing_data,df1=waterbody)","f8d31010":"waterbody.columns","56b4d9a4":"interpolate_df(df=waterbody,col_no=[12,13,14])","9cbd8225":"waterbody = waterbody.dropna()","5e2a9e13":"groundwater_col_list, rainfall_col_list, temperature_col_list, volume_col_list, hydrometry_col_list,flow_rate_col_list, lake_level_col_list= categorical_list(waterbody)\n\noutput_columns = [groundwater_col_list[0]]","5ed3c054":"corr=waterbody.corr()\nplt.figure(figsize=(0.8*len(waterbody.columns),0.5*len(waterbody.columns)))\nsns.heatmap(corr, xticklabels=corr.columns,yticklabels=corr.columns,annot=True)","c23c9d19":"create_lags(waterbody,rainfall_col_list)","72ae29fa":"waterbody.columns","3b90a24e":"obj_call_count = 0\ncur_best_loss = np.inf\n#log_writer = open( 'catboost-hyperopt-log.txt', 'w' )","5003069c":"for output_col in output_columns:\n    mycatboost(waterbody,output_col,output_columns,putDate=True)","ece3d74f":"waterbody_df","05965691":"As the data available with us is too sparse. And, fixing the missing value donot seem relevent for temperature and rainfall. Similarly, due to high variance, interpolating flow rate, is also not possible. We would scoping this problem with machine learning solution for now.","3ddea372":"The zero values in Depth to groundwater signifies all the variables are useful for prediction.","8d8a43b7":"The data for some columns are missing in initial records. Hence, it is better to drop the rows untill some columns have NULL values","c41181b1":"The data for some columns are missing in initial records. Hence, it is better to drop the rows untill some columns have NULL values","bbb4cd6f":"# Content\n\n1. **Aquifer Petrignano**\n   * About the waterbody\n   * Data Preprocessing\n   * EDA and Visualization\n   * Statistical approach\n   * Feature engineering\n   * Machine Learning approach\n   \n   \n1. **Lake Bilancino**\n\n   * About the waterbody\n   * Data Preprocessing\n   * EDA and Visualization\n   * Statistical approach\n   * Feature engineering\n   * Machine Learning approach\n   \n   \n1. **Water Spring Amiata**\n\n   * About the waterbody\n   * Data Preprocessing\n   * EDA and Visualization\n   * Statistical approach\n   * Feature engineering\n   * Machine Learning approach\n\n\n1. **River Arno**\n\n   * About the waterbody\n   * Data Preprocessing\n   * EDA and Visualization\n   * Statistical approach\n   * Feature engineering\n   * Machine Learning approach\n\n\n1. **Water Spring Lupa**\n\n   * About the waterbody\n   * Data Preprocessing\n   * EDA and Visualization\n   * Statistical approach\n   * Feature engineering\n   * Machine Learning approach\n\n\n1. **Water Spring Madonna Ci Canneto**\n\n   * About the waterbody\n   * Data Preprocessing\n   * EDA and Visualization\n   * Statistical approach\n   * Feature engineering\n   * Machine Learning approach\n   \n1. **Aquifer Doganella**\n\n   * About the waterbody\n   * Data Preprocessing\n   * EDA and Visualization\n   * Statistical approach\n   * Feature engineering\n   * Machine Learning approach\n\n\n1. **Aquifer Auser**\n\n   * About the waterbody\n   * Data Preprocessing\n   * EDA and Visualization\n   * Statistical approach\n   * Feature engineering\n   * Machine Learning approach\n\n\n1. **Aquifer Luco**\n\n   * About the waterbody\n   * Data Preprocessing\n   * EDA and Visualization\n   * Statistical approach\n   * Feature engineering\n   * Machine Learning approach\n       ","3c63b033":"Fitting and forecasting the model","6c86b30e":"**Truncating Dataframe**","7d53c8e9":"**Wait a minute..,infiltration happens everyday** \n\nThe groundwater level will be replinished not only by single day's rainfall in rainfall but it will happen cummilitvely. Just for the sake of simplicity lets consider a cummulative mean of all the rainfall for past 7,30,60 days. And same repeats for Hydrometry.","30c00f06":"There are erronious values present in between the records in some columns, lets remove those data by outlier detection for the columns where the outliers make no sense such as Hydrometry and Volume's columns.\n\nBut for rainfall the irregularity in data is expected as some days it can rain havily and some days it wont.","a91a4375":"There are erronious values present in between the records in some columns, lets remove those data by outlier detection for the columns where the outliers make no sense such as Hydrometry and Volume's columns.\n\nBut for rainfall the irregularity in data is expected as some days it can rain havily and some days it wont.","7d6101d8":"**Train- test split**","ceaf9de3":"**Missing Values**","f599b020":"Here we can see there is a very high correlation in temperature in both the places, instead of using both the columns we can reduce the columns using PCA","499189bf":"# Data Preprocessing","0f29ef88":"**Train- test split**","bdfde613":"Let's first interpolate the column which has very less missing values","d66c9cc1":"The wells field of the alluvial plain between Ospedalicchio di Bastia Umbra and Petrignano is fed by three underground aquifers separated by low permeability septa. The aquifer can be considered a water table groundwater and is also fed by the Chiascio river. The groundwater levels are influenced by the following parameters: rainfall, depth to groundwater, temperatures and drainage volumes, level of the Chiascio river.","a46d48d7":"**Series = Trend + Seasonality + Residual**\n\nA series consist of trend, seasonality and residuals, decomoposing it can help in capuring the relevent columns, and ignore the residuals so as to get a better overview of what component of a time series most affects the dependent variable.","6685785d":"Now lets fix all the missing value present in between the records, But before that lets visualize our data","d8d93429":"Let's first interpolate the column which has very less missing values","a8617d49":"Let's first interpolate the column which has very less missing values","9da7a1f1":"The data for some columns are missing in initial records. Hence, it is better to drop the rows untill some columns have NULL values","bfa25fc8":"There are erronious values present in between the records in some columns, lets remove those data by outlier detection for the columns where the outliers make no sense such as Hydrometry and Volume's columns.\n\nBut for rainfall the irregularity in data is expected as some days it can rain havily and some days it wont.","413434ae":"<a id=\"section-three\"><\/a>\n<h2 style='color:WHITE; background:#50A8E3; border:2px solid #50A8E3'><center>AQUIFER DOGANELLA<\/center><\/h2> ","27ab917f":"## Acea Smart Water Analytics","b1cd1474":"# VAR modeling \n\n\nWe know that water cycles throughout the environemnt, lets see how each of the given features are bi-directionally related, to each other","25b12b90":"**Infilteration takes time**\n\nAs the waterbodyis an aquifier, it takes time to sip in through the rocks to replenish the waterlevel, So, lags of rainfall and River Chiasco's hydrometry can be taken into consideration for finding the groundwater level.","05254f34":"**Series = Trend + Seasonality + Residual**\n\nA series consist of trend, seasonality and residuals, decomoposing it can help in capturing only the trend that is being observed over years","8e5b3296":"Frm observtion we can say that , columns with that perticular group has a very high correlation. Hence iterative imputer, group wise can be useful for filling the missing values\n","295bf7f0":"**Train- test split**","03cccd82":"**Yearly trend and seasonality in all columns**","f49f3bb6":"Here we can see there is a very high correlation in temperature in both the places, instead of using both the columns we can reduce the columns using PCA","10af2b41":"# VAR modeling \n\n\nWe know that water cycles throughout the environemnt, lets see how each of the given features are bi-directionally related, to each other","cdd27f53":"**Effect of evaporation**\n\nWe know that, all the water from rainfall and hydrometry donot goes to the aquifer, some are consumed by vegetation. But sometimes, due to high temperature most of the water gets evaporated and hence donot contribute to the aquifier infilitration. So, in order to consider the effect of evporation, we can factor the rainfall based on the temperature","453ddd87":"**Series = Trend + Seasonality + Residual**\n\nA series consist of trend, seasonality and residuals, decomoposing it can help in capturing only the trend that is being observed over years","233c094a":"Now lets fix all the missing value present in between the records, But before that lets visualize our data","aaefa471":"**Truncating Dataframe**","661ea27c":"Lets now observe the percentage of missing values ","e0b6ad80":"*Before getting into feature engineering lets create lists of columns of different categories*","956f6c76":"# VAR modeling \n\n\nWe know that water cycles runs throughout the environment, lets see how each of the given features are bi-directionally related, to each other","295d60d1":"The data for some columns are missing in initial records. Hence, it is better to drop the rows untill some columns have NULL values","170703a7":"Lets now observe the percentage of missing values ","f4aca222":"# VAR modeling \n\n\nWe know that water cycles throughout the environemnt, lets see how each of the given features are bi-directionally related, to each other","45c50cbc":"**Series = Trend + Seasonality + Residual**\n\nA series consist of trend, seasonality and residuals, decomoposing it can help in capturing only the trend that is being observed over years","2d0932ed":"As Hydrometry has no, columns with which it has good correlation, so lets feature engineer date columns and use [**Iterative Imputer from SK-learn**](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.impute.IterativeImputer.html) to fix hydrometry values.","a2bf88a4":"Let's manually change the value to NAN, which later can be fixed by using Bastia_Umbra's temperature as they have very high correlation","ad64cde1":"\nHere, as we can see rainfall columns has preaty high correlation among itself, so we can use PCA to reduce the dimensionality and also, same we can workout with temperature.","bcea8192":"**Infilteration takes time**\n\nAs the waterbodyis an aquifier, it takes time to sip in through the rocks to replenish the waterlevel, So, lags of rainfall and River Chiasco's hydrometry can be taken into consideration for finding the groundwater level.","453680a9":"There are erronious values present in between the records in some columns, lets remove those data by outlier detection for the columns where the outliers make no sense such as Hydrometry and Volume's columns.\n\nBut for rainfall the irregularity in data is expected as some days it can rain havily and some days it wont.","6051cec7":"**Effect of evaporation**\n\nWe know that, all the water from rainfall and hydrometry donot goes to the aquifer, some are consumed by vegetation. But sometimes, due to high temperature most of the water gets evaporated and hence donot contribute to the aquifier infilitration. So, in order to consider the effect of evporation, we can factor the rainfall based on the temperature","63c1891c":"Yearly missing percentage, gives us an idea about how close the missing values are present and gives an estimate of the technique that can be used to fix there missing values, whether to use interpolation or any better imputation technique.","5a9bc7f9":"There are erronious values present in between the records in some columns, lets remove those data by outlier detection for the columns where the outliers make no sense such as Hydrometry and Volume's columns.\n\nBut for rainfall the irregularity in data is expected as some days it can rain havily and some days it wont.","9d71d1c7":"# Data Prepocessing","5deb6b44":"<a id=\"section-three\"><\/a>\n<h2 style='color:WHITE; background:#50A8E3; border:2px solid #50A8E3'><center>WATER SPRING LUPA<\/center><\/h2> ","2993c78c":"For the columns which has more missing value per year, indicates presence of continous missing values, which can't be simply interpolated as the data filling wont be justifiable as shown below.","45d1ce02":"**Infilteration takes time**\n\nAs the waterbodyis an aquifier, it takes time to sip in through the rocks to replenish the waterlevel, So, lags of rainfall and River Chiasco's hydrometry can be taken into consideration for finding the groundwater level.","a5ce72dd":"# Feature Engineering","774c26cc":"# Feature Engineering","d4de5b47":"# Data Prepocessing","dc7e1121":"**Train- test split**","b2d83e96":"For our case dealing with years of data, daily data, that varies everyday is very difficult to comprehend.\nSo lets create some aggreated dataframes which will give a better understanding of the data,","3d45817b":"Lets now observe the percentage of missing values ","9e3569fe":"**Effect of evaporation**\n\nWe know that, all the water from rainfall and hydrometry donot goes to the aquifer, some are consumed by vegetation. But sometimes, due to high temperature most of the water gets evaporated and hence donot contribute to the aquifier infilitration. So, in order to consider the effect of evporation, we can factor the rainfall based on the temperature","fdacf5f7":"**Missing Values**","c2e1cd35":"Now lets fix all the missing value present in between the records, But before that lets visualize our data","cd94376a":"**Missing Values**","f6f57ea7":"**Disclaimer**\n\nAs there are 9 waterbodies are involved, providing explanation for each of the waterbody would make the notebook very lengthy. So most of the explanation of the approach is covered in the first waterbody itself and functions are created which has been used  for the steps that are repeating , and explanation of those functions are provided as a docstring","d063bc83":"A check for all the simultanious rows to be continous dates, in a sequence","49d7852a":"**Truncating Dataframe**","11c4e536":"# VAR modeling \n\n\nWe know that water cycles throughout the environemnt, lets see how each of the given features are bi-directionally related, to each other","1ce44462":"For our case dealing with years of data, daily data, that varies everyday is very difficult to comprehend.\nSo lets create some aggreated dataframes which will give a better understanding of the data,","3964942c":"The data for some columns are missing in initial records. Hence, it is better to drop the rows untill some columns have NULL values","76cdb6e1":"Due to the presence of very high percentage of missing values in all the columns, fixing them and converting this into a time series problem wont be the write approach, because fixing techniques work on certain assumptions. So we will scope this problem for ML modelling only.","1d852876":"Using linear regression with Temperature_Bastia_Umbra to fix Temperature_Petrignano","e500b26a":"Frm observtion we can say that , columns with that perticular group has a very high correlation. Hence iterative imputer, group wise can be useful for filling the missing values\n","ca0bb354":"Lets now observe the percentage of missing values ","f34e6a73":"Now as all series are made stationary, lets start modelling.","1ef00a8d":"As this is a multi-dataset problem, there are lot of columns involved and each of the columns has different names. So listing them categorically based on the type of column will make our work easy.","c0fd0260":"Now lets fix all the missing value present in between the records, But before that lets visualize our data","b6c3758d":"Defining parameters for Catboost","c2fae357":"For our case dealing with years of data, daily data, that varies everyday is very difficult to comprehend.\nSo lets create some aggreated dataframes which will give a better understanding of the data,","d3af5370":"**Truncating Dataframe**","1851627f":"This shows that different methodologies have to be employed in order to fix the high missing value columns.","b461f50e":"There are erronious values present in between the records in some columns, lets remove those data by outlier detection for the columns where the outliers make no sense such as Hydrometry and Volume's columns.\n\nBut for rainfall the irregularity in data is expected as some days it can rain havily and some days it wont.","2a038ceb":"# Feature Engineering","55224d77":"**Comprehend black box**\n\nTo understand how each of the feature, influences our output variable and how important is that feature. We will be using SHAP for it.","4592a647":"There are erronious values present in between the records in some columns, lets remove those data by outlier detection for the columns where the outliers make no sense such as Hydrometry and Volume's columns.\n\nBut for rainfall the irregularity in data is expected as some days it can rain havily and some days it wont.","bee68584":"Let's first interpolate the column which has very less missing values","b1945bad":"A check for all the simultanious rows to be continous dates, in a sequence","a34b5332":"**Missing Values**","058e0184":"# About ","4cc16717":"There are erronious values present in between the records in some columns, lets remove those data by outlier detection for the columns where the outliers make no sense such as Hydrometry and Volume's columns.\n\nBut for rainfall the irregularity in data is expected as some days it can rain havily and some days it wont.","ba9a2def":"**Truncating Dataframe**","249de310":"**Yearly trend and seasonality in all columns**","92405a7f":"Imporitng all the required packages","92687603":"Lets now observe the percentage of missing values ","fa9c6c6d":"# EDA\n_Now as the data processing is done, its time for some data analysis and innovates some new features from our data_","d53b12dc":"The data for some columns are missing in initial records. Hence, it is better to drop the rows untill some columns have NULL values","e857d398":"Relevent columns are added to the dataframe to store the error metrics.","3843d79b":"Now lets fix all the missing value present in between the records, But before that lets visualize our data","1e23cd83":"Let's first interpolate the column which has very less missing values","74480fb8":"Inverting the transformation done on the data","5e93a1ce":"**Wait a minute..,infiltration happens everyday** \n\nThe groundwater level will be replinished not only by single day's rainfall in rainfall but it will happen cummilitvely. Just for the sake of simplicity lets consider a cummulative mean of all the rainfall for past 7,30,60 days. And same repeats for Hydrometry.","f612a81d":"For our case dealing with years of data, daily data, that varies everyday is very difficult to comprehend.\nSo lets create some aggreated dataframes which will give a better understanding of the data,","bc312298":"# About","ea5ad373":"Climate change is certainly one of the greatest threat to humanity. Temperature changes undoubtedly worry us, and water scarcity which is not a severe problem at this point of time through out the world, but recent years has shown how the important the problem of water and what kind of challenges can be expected in future. As a part of Data Science community we can work to deliver a solution where water availability can be predicted in future and understand what all factors affect the water levels, so that proper planning and water management can be done to avoid the scarcity problem.\nHere, as there are different kinds of waterbodies, for each of the waterbodies there and EDA and statistical(Vector Auto Regression Model) and machine learning model(CatBoost using Hyper-opt) is built by doing some feature engineering\n\nAs the scope of the problem statement is more focused on understanding the features that affects the dependent variable, lags of the dependent variable was not used in making ML models. For some waterbodies the meteorological factors given had very less relevance for model building, so for them date columns were feature engineered to create features. ","91752d1b":"A check for all the simultanious rows to be continous dates, in a sequence","a8553529":"Calling mycatboost for ML modelling","267aa10c":"# Data Prepocessing","feb4ee29":"![image.png](attachment:image.png)","b7d3df20":"<a id=\"section-three\"><\/a>\n<h2 style='color:WHITE; background:#50A8E3; border:2px solid #50A8E3'><center>WATER SPRING MADONNA DI CANNETO<\/center><\/h2> ","dc750484":"# VAR modeling \n\n\nWe know that water cycles throughout the environemnt, lets see how each of the given features are bi-directionally related, to each other","5514b62c":"**Missing Values**","0f70d0f0":"**Missing Values**","d3545849":"**Truncating Dataframe**","27fe968a":"# EDA\n_Now as the data processing is done, its time for some data analysis and innovates some new features from our data_","949df4b7":"A check for all the simultanious rows to be continous dates, in a sequence","93a18624":"Let's first interpolate the column which has very less missing values","8e1e3ab0":"# VAR modeling \n\n\nWe know that water cycles throughout the environemnt, lets see how each of the given features are bi-directionally related, to each other","bb2a2bff":"Listing each of the columns in their corresponding categorical list","2e45e8eb":"But as rainfall columns are highly correlated among themselves using iterative imputer to fix their values.","92d21806":"# EDA\n_Now as the data processing is done, its time for some data analysis and innovates some new features from our data_","f7634b2b":"**Infilteration takes time**\n\nAs the waterbodyis an aquifier, it takes time to sip in through the rocks to replenish the waterlevel, So, lags of rainfall and River Chiasco's hydrometry can be taken into consideration for finding the groundwater level.","67df3683":"# VAR modeling \n\n\nWe know that water cycles throughout the environemnt, lets see how each of the given features are bi-directionally related, to each other","5470da92":"Using iterative imputer for the new dataframe created to solve the missing values for hydrometry column.","80772253":"*Before getting into feature engineering lets create lists of columns of different categories*","a6468fbc":"**Infilteration takes time**\n\nAs the waterbodyis an aquifier, it takes time to sip in through the rocks to replenish the waterlevel, So, lags of rainfall and River Chiasco's hydrometry can be taken into consideration for finding the groundwater level.","c8616eac":"<a id=\"section-three\"><\/a>\n<h2 style='color:WHITE; background:#50A8E3; border:2px solid #50A8E3'><center>RIVER ARNO<\/center><\/h2> ","a50ecccd":"**Granger Causality test**  https:\/\/www.machinelearningplus.com\/time-series\/vector-autoregression-examples-python\/\n\nThe basis behind Vector AutoRegression is that each of the time series in the system influences each other. That is, you can predict the series with past values of itself along with other series in the system.\n\nUsing Granger\u2019s Causality Test, it\u2019s possible to test this relationship before even building the model.\n\nSo what does Granger\u2019s Causality really test?\n\nGranger\u2019s causality tests the null hypothesis that the coefficients of past values in the regression equation is zero.\nIn simpler terms, the past values of time series (X) do not cause the other series (Y). So, if the p-value obtained from the test is lesser than the significance level of 0.05, then, you can safely reject the null hypothesis.\n\nThe below code implements the Granger\u2019s Causality test for all possible combinations of the time series in a given dataframe and stores the p-values of each combination in the output matrix.","2f307831":"**Yearly trend and seasonality in all columns**","4c2e4422":"Lets now observe the percentage of missing values ","11e16dfe":"Now as all series are made stationary, lets start modelling.","df9cc988":"<a id=\"section-three\"><\/a>\n<h2 style='color:WHITE; background:#50A8E3; border:2px solid #50A8E3'><center>LAKE BILANCINO<\/center><\/h2> ","7a605313":"**Effect of evaporation**\n\nWe know that, all the water from rainfall and hydrometry donot goes to the aquifer, some are consumed by vegetation. But sometimes, due to high temperature most of the water gets evaporated and hence donot contribute to the aquifier infilitration. So, in order to consider the effect of evporation, we can factor the rainfall based on the temperature","d8ad5101":"Running Catboost for all the output columns","6fce9dc6":"A check for all the simultanious rows to be continous dates, in a sequence","62a92edb":"Since the VAR model requires the time series to forecast to be stationary, it is customary to check all the time series in the system for stationarity.\nA stationary time series is one whose characteristics like mean and variance does not change over time.\n\nBy the way, if a series is found to be non-stationary, we make it stationary by differencing the series once and repeat the test again until it becomes stationary.\n\nSince, differencing reduces the length of the series by 1 and since all the time series has to be of the same length, we need to difference all the series in the system if you choose to difference at all.","0edcde6e":"Now lets fix all the missing value present in between the records, But before that lets visualize our data","fefa4500":"# EDA\n_Now as the data processing is done, its time for some data analysis and innovates some new features from our data_","16ec092d":"A dataframe is created with all the waterbodies and their corresponding output columns, to compile the error metrics for each of the model built","b5f8aaf0":"**Wait a minute..,infiltration happens everyday** \n\nThe groundwater level will be replinished not only by single day's rainfall in rainfall but it will happen cummilitvely. Just for the sake of simplicity lets consider a cummulative mean of all the rainfall for past 7,30,60 days. And same repeats for Hydrometry.","7b35934e":"Due to the presence of very high NaN values in initial 2 years ,lets drop them","c3f1976e":"**Infilteration takes time**\n\nAs the waterbodyis an aquifier, it takes time to sip in through the rocks to replenish the waterlevel, So, lags of rainfall and River Chiasco's hydrometry can be taken into consideration for finding the groundwater level.","55861276":"**Train- test split**","92ebfa4a":"**Missing Values**","59e8d926":"Here we can see there is a very high correlation in rainfall columns instead of using all of them we can reduce the dimensionality by doing PCA for all rainfall columns","c441661c":"**Wait a minute..,infiltration happens everyday** \n\nThe groundwater level will be replinished not only by single day's rainfall in rainfall but it will happen cummilitvely. Just for the sake of simplicity lets consider a cummulative mean of all the rainfall for past 7,30,60 days. And same repeats for Hydrometry.","9d2efa34":"Bilancino lake is an artificial lake located in the municipality of Barberino di Mugello (about 50 km from Florence). It is used to refill the Arno river during the summer months. Indeed, during the winter months, the lake is filled up and then, during the summer months, the water of the lake is poured into the Arno river.","ef0cbffc":"Dropping some rainfall column, as the recent data on of those columns are unavailable","b89fc62b":"Differencing the dataset till the data become stationary","2e096311":"**Terminology for feature columns**\n\n1. (feature_name)\\_lag\\(x) - The xth lag of a feature column\n2. (feature_name)\\_trend  - Trend component of a feature columns\n3. (feature_name)\\_seasonal - Seasonal component of a feature columns\n4. (effective_(feature_name) - After factoring the particular feature column with temperature,\n5. (feature_name)\\_cumsum_\\(x) - The cumulative mean of a feature value for x no. of past days.\n6. (feature_name)\\_lag\\(x)cumsum_\\(y) - The cumulative mean of a feature value for y no. of past days from xth lag of the same feature column.\n7. (feature_name)\\_lag\\(x)_trend - Trend component of the xth lag of feature column\n\nIn this way, there are various combinations of feature names are present, so as to give a clear picture of what part of a column effects the output variable properly.","21a2a3f9":"Modelling and forecasting for the no. of observations","7a8814f7":"<a id=\"section-three\"><\/a>\n<h2 style='color:WHITE; background:#50A8E3; border:2px solid #50A8E3'><center>AQUIFER LUCO<\/center><\/h2> ","21d393b2":"Now lets fix all the missing value present in between the records, But before that lets visualize our data","6eed6e5d":"**Wait a minute..,infiltration happens everyday** \n\nThe groundwater level will be replinished not only by single day's rainfall in rainfall but it will happen cummilitvely. Just for the sake of simplicity lets consider a cummulative mean of all the rainfall for past 7,30,60 days. And same repeats for Hydrometry.","76a1f1e7":"**Yearly trend and seasonality in all columns**","2e9e763d":"**Series = Trend + Seasonality + Residual**\n\nA series consist of trend, seasonality and residuals, decomoposing it can help in capturing only the trend that is being observed over years","528b7894":"<a id=\"section-three\"><\/a>\n<h2 style='color:WHITE; background:#50A8E3; border:2px solid #50A8E3'><center>AQUIFER AUSER<\/center><\/h2> ","a9a6d176":"<a id=\"section-three\"><\/a>\n<h2 style='color:WHITE; background:#50A8E3; border:2px solid #50A8E3'><center>AQUIFIER PETRIGNANO<\/center><\/h2> ","bf74906a":"**Granger Causality test**  https:\/\/www.machinelearningplus.com\/time-series\/vector-autoregression-examples-python\/\n\nThe basis behind Vector AutoRegression is that each of the time series in the system influences each other. That is, you can predict the series with past values of itself along with other series in the system.\n\nUsing Granger\u2019s Causality Test, it\u2019s possible to test this relationship before even building the model.\n\nSo what does Granger\u2019s Causality really test?\n\nGranger\u2019s causality tests the null hypothesis that the coefficients of past values in the regression equation is zero.\nIn simpler terms, the past values of time series (X) do not cause the other series (Y). So, if the p-value obtained from the test is lesser than the significance level of 0.05, then, you can safely reject the null hypothesis.\n\nThe below code implements the Granger\u2019s Causality test for all possible combinations of the time series in a given dataframe and stores the p-values of each combination in the output matrix.","1bc09757":"Frm observtion we can say that , columns with that perticular group has a very high correlation. Hence iterative imputer, group wise can be useful for filling the missing values\n","8c955fdb":"**Missing Values**","c6d0ea37":"**Why we should use recent data for analysis?**\n\nIn order to capture the recent trends and relationship among the variable columns present we discard the old data and only focus on the recent 1500 data points if more data points are present. Thus, making our analysis and prediction relevant to recent relationships.","ce450f7c":"Now lets fix all the missing value present in between the records, But before that lets visualize our data","1061fbec":"The data for some columns are missing in initial records. Hence, it is better to drop the rows untill some columns have NULL values","2f95c426":"For our case dealing with years of data, daily data, that varies everyday is very difficult to comprehend.\nSo lets create some aggreated dataframes which will give a better understanding of the data,","9acdf543":"Differencing the data untill it achieves stationarity","fcb4d803":"Here we can see there is a very high correlation in temperature in both the places, instead of using both the columns we can reduce the columns using PCA","833f1cf7":"**Infilteration takes time**\n\nAs the waterbodyis an aquifier, it takes time to sip in through the rocks to replenish the waterlevel, So, lags of rainfall and River Chiasco's hydrometry can be taken into consideration for finding the groundwater level.","ace4d7f5":"**Wait a minute..,infiltration happens everyday** \n\nThe groundwater level will be replinished not only by single day's rainfall in rainfall but it will happen cummilitvely. Just for the sake of simplicity lets consider a cummulative mean of all the rainfall for past 7,30,60 days. And same repeats for Hydrometry.","b80749a0":"# Feature Engineering","67018398":"Dropping temperature column due to presence of very high missing values, hence obsolete for analysis and forecasting","4f66f9e2":"# EDA \n_Now as the data processing is done, its time for some data analysis and innovates some new features from our data_","d44dab27":"**Yearly trend and seasonality in all columns**","3b0a280a":"# About","ddab5208":"There are erronious values present in between the records in some columns, lets remove those data by outlier detection for the columns where the outliers make no sense such as Hydrometry and Volume's columns.\n\nBut for rainfall the irregularity in data is expected as some days it can rain havily and some days it wont.","e5fd4778":"But, there is a catch here, for **Temperature_Petrignano**, we see the temperature being continously zero for four months which is not practically possible","57e78cb5":"The Arno is a river in the Tuscany region of Italy. It is the most important river of central Italy after the Tiber. With a length of 241 kilometres (150 mi), it is the largest river in the region. It has many tributaries: Sieve at 60 kilometres (37 mi) long, Bisenzio at 49 kilometres (30 mi), Ombrone Pistoiese at 47 kilometres (29 mi), and the Era, Elsa, Pesa, and Pescia. The drainage basin amounts to more than 8,200 square kilometres (3,200 sq mi).\n\nThe main indicator that will be predicted for the river is hydrometry. The other two features in this dataset are rainfall and temperature. Let's look at their dynamics. Below I'll take some liberties with axes scales in order to make the graphs more visual (somewhere the values will be logarithmized, somewhere they'll be adjusted).","fbad4926":"Lets now observe the percentage of missing values ","5770d61d":"**Train- test split**","63e49c5b":"**Wait a minute..,infiltration happens everyday** \n\nThe groundwater level will be replinished not only by single day's rainfall in rainfall but it will happen cummilitvely. Just for the sake of simplicity lets consider a cummulative mean of all the rainfall for past 7,30,60 days. And same repeats for Hydrometry.","427e7acb":"Now lets fix all the missing value present in between the records, But before that lets visualize our data","6fd6dc9d":"**Truncating Dataframe**","9dc733bf":"**Train- test split**","c51ed5ae":"# About","990f39c5":"# Feature Engineering","5a498b46":"<a id=\"section-three\"><\/a>\n<h2 style='color:WHITE; background:#50A8E3; border:2px solid #50A8E3'><center>WATER SPRING AMAIATA<\/center><\/h2> ","d92126a7":"By observation, from the feature importance charts we can say that, Chiasco water level trend component  and Rainfall for Bastia Umbra's trend component and effective rainfall has a major and positive impact on the depth to groundwater for petrignano aquifer.","184dd567":"Now as all series are made stationary, lets start modelling.","5a3bf847":"**Truncating Dataframe**","06cf46ce":"**Infilteration takes time**\n\nAs the waterbodyis an aquifier, it takes time to sip in through the rocks to replenish the waterlevel, So, lags of rainfall and River Chiasco's hydrometry can be taken into consideration for finding the groundwater level.","6be8fc58":"Lets now observe the percentage of missing values ","e044d559":"\nAbsurdly, there are lots of zero values present in Temperature_Ponte_a_Moriano for last 3 years, so as we have other temperature columns we can drop this column","c834a0e3":"Depth_to_Groundwater_P24 and Depth_to_Groundwater_P25 are completely correlated, and therefore averaged values can be used. There is a strange dip in monthly temperatures for Temperature_Petrignano in 2015. This is most likely due to missing values since, in general, the dynamics are almost identical to Temperature_Bastia_Umbra. The same dip is seen in the Hydrometry metric.\n\nMost of all (judging by the graphs) Depth_to_Groundwater_P24 and Depth_to_Groundwater_P25 are affected by the drainage volume (Volume_C10).","7b0f69fb":"**Series = Trend + Seasonality + Residual**\n\nA series consist of trend, seasonality and residuals, decomoposing it can help in capturing only the trend that is being observed over years","6708f604":"Here we can see there is a very high correlation in temperature in both the places, instead of using both the columns we can reduce the columns using PCA","ef97a3c3":"Reading Petrignano data, into a pandas dataframe.\nHere are the last 5 rows of the dataframe.","7511ebad":"*Before getting into feature engineering lets create lists of columns of different categories*","ff8f752f":"Lets interpolate the columns as it has very less missing values","7cf2df81":"**Missing Values**","3e2b61a5":"Volume columns, have most of the missing values due to outlier removal and the percentage of missing values year wise is quite low, hence this can be imputed. Here, we are using iterative imputer to fix the values","aa09bf3b":"The data for some columns are missing in initial records. Hence, it is better to drop the rows untill some columns have NULL values","0a889658":"*Before getting into feature engineering lets create lists of columns of different categories*","abdd52b2":"The Amiata waterbody is composed of a volcanic aquifer not fed by rivers or lakes but fed by meteoric infiltration. This aquifer is accessed through Ermicciolo, Arbure, Bugnano and Galleria Alta water springs. The levels and volumes of the four sources are influenced by the parameters: rainfall, depth to groundwater, hydrometry, temperatures and drainage volumes.","0813c5ab":"Dropping temperature column due to presence of very high missing values, hence obsolete for analysis and forecasting","339b91e4":"# Feature Engineering","378fe2bd":"Defining categorical list for each of the columns","1fc5f703":"Since the VAR model requires the time series to forecast to be stationary, it is customary to check all the time series in the system for stationarity.\nA stationary time series is one whose characteristics like mean and variance does not change over time.\n\nBy the way, if a series is found to be non-stationary, we make it stationary by differencing the series once and repeat the test again until it becomes stationary.\n\nSince, differencing reduces the length of the series by 1 and since all the time series has to be of the same length, we need to difference all the series in the system if you choose to difference at all.","50fb9af7":"*Before getting into feature engineering lets create lists of columns of different categories*","57e4bb0d":"The zero values in Depth to groundwater signifies all the varaibels are useful for prediction.","0775ab7d":"For our case dealing with years of data, daily data, that varies everyday is very difficult to comprehend.\nSo lets create some aggreated dataframes which will give a better understanding of the data,","281fc70e":"The data for some columns are missing in initial records. Hence, it is better to drop the rows untill some columns have NULL values","26d440fd":"**Truncating Dataframe**","6c5d5a4f":"**Necessity of stationarity**\n\nSince the VAR model requires the time series to forecast to be stationary, it is customary to check all the time series in the system for stationarity.\nA stationary time series is one whose characteristics like mean and variance does not change over time.\n\nBy the way, if a series is found to be non-stationary, we make it stationary by differencing the series once and repeat the test again until it becomes stationary.\n\nSince, differencing reduces the length of the series by 1 and since all the time series has to be of the same length, we need to difference all the series in the system if you choose to difference at all.","630b80d5":"**Yearly trend and seasonality in all columns**","3bd4dbd8":"Also created one more dataframe which stores waterbody name and its corresponding dataset path","b5f0a63f":"Frm observtion we can say that , columns with that perticular group has a very high correlation. Hence iterative imputer, group wise can be useful for filling the missing values\n","fa8b040a":"**Train- test split**","19ff1e39":"As differencing is done on the data, inverse transformation has to be done, so as to check our predictions and finding the error metrics","fdf89088":"# EDA\n_Now as the data processing is done, its time for some data analysis and innovates some new features from our data_","4c139b48":"# Feature Engineering","44ddf1aa":"Data points are not avaiable for doing decomposition","2a2be4b7":"Defining categorical list for each of the columns","585b9f80":"**Effect of evaporation**\n\nWe know that, all the water from rainfall and hydrometry donot goes to the aquifer, some are consumed by vegetation. But sometimes, due to high temperature most of the water gets evaporated and hence donot contribute to the aquifier infilitration. So, in order to consider the effect of evporation, we can factor the rainfall based on the temperature","a694120c":"\nAs the data for Volume_CSA and Volume_CSAL till 2014 are absurdly zero, planning to slice the dataset till that, as we are more concerned with the analysis of recent data and trends","341d49b8":"**Series = Trend + Seasonality + Residual**\n\nA series consist of trend, seasonality and residuals, decomoposing it can help in capturing only the trend that is being observed over years","5a63a22d":"In 2012, there was a significant decrease in rainfall that also accompanied by a change in drainage volume. After 2012 up to 2014, with an increase in annual rainfall, the depth of groundwater and drainage volume became less that looks logical. There is no rainfall data for 2008.\n","51d47ce2":"Lets now observe the percentage of missing values ","ffc932ac":"The zero values in Depth to groundwater signifies all the varaibels are useful for prediction.","193c8c31":"# Feature Engineering"}}