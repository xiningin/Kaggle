{"cell_type":{"80f12ef0":"code","a9e7084b":"code","48f5229c":"code","5f0f0f79":"code","1fc573cc":"code","c1236014":"code","04fe9a2c":"code","e8c3317f":"code","268d236c":"code","60ae0186":"code","874768c8":"code","de5fee72":"code","58828a39":"code","223998cc":"code","5f47c5ed":"code","4623f54d":"code","e3cfcd0a":"code","f81db359":"code","2453c3bb":"code","6eb20b95":"code","94d8beb0":"code","874661df":"code","48206a60":"code","c7296884":"code","d979d5e2":"markdown","3195db00":"markdown"},"source":{"80f12ef0":"from fastai.vision import *\nfrom fastai.metrics import *\nPATH = Path('..\/input')","a9e7084b":"ann_file = '..\/input\/train2019.json'\nwith open(ann_file) as data_file:\n        train_anns = json.load(data_file)\n\ntrain_anns_df = pd.DataFrame(train_anns['annotations'])[['image_id','category_id']]\ntrain_img_df = pd.DataFrame(train_anns['images'])[['id', 'file_name']].rename(columns={'id':'image_id'})\ndf_train_file_cat = pd.merge(train_img_df, train_anns_df, on='image_id')\ndf_train_file_cat['category_id']=df_train_file_cat['category_id'].astype(str)\ndf_train_file_cat = df_train_file_cat.drop(['image_id'],axis=1)\ndf_train_file_cat.head()","48f5229c":"%%time\n# Try Oversampling\n\nres = None\nsample_to = df_train_file_cat.category_id.value_counts().max() # which is 500\n\nfor grp in df_train_file_cat.groupby('category_id'):\n    n = grp[1].shape[0]\n    additional_rows = grp[1].sample(0 if sample_to < n  else sample_to - n, replace=True)\n    rows = pd.concat((grp[1], additional_rows))\n    \n    if res is None: res = rows\n    else: res = pd.concat((res, rows))","5f0f0f79":"res.category_id.value_counts()[:10]","1fc573cc":"test_ann_file = '..\/input\/test2019.json'\nwith open(test_ann_file) as data_file:\n        test_anns = json.load(data_file)\ntest_img_df = pd.DataFrame(test_anns['images'])[['file_name','id']].rename(columns={'id':'image_id'})\ntest_img_df.head()","c1236014":"src = (\nImageList.from_df(df=res,path=PATH\/\"train_val2019\")\n    .use_partial_data(0.3)\n    .split_by_rand_pct(0.1)\n    .label_from_df()\n    .add_test(ImageList.from_df(df=test_img_df,path=PATH\/\"test2019\"))\n)","04fe9a2c":"data = (\n    src\n    .transform(get_transforms(),size=128)\n    .databunch(bs=64*2)\n    .normalize(imagenet_stats)\n)","e8c3317f":"!pip install efficientnet_pytorch","268d236c":"from efficientnet_pytorch import EfficientNet","60ae0186":"model_name = 'efficientnet-b3'\ndef getModel(pret):\n    model = EfficientNet.from_pretrained(model_name)\n#     model._bn1 = nn.Identity()\n    model._fc = nn.Linear(1536,data.c)\n    return model","874768c8":"# learn = cnn_learner(data,models.densenet201,metrics=[error_rate],model_dir='\/kaggle\/working',pretrained=True,loss_func=LabelSmoothingCrossEntropy()).mixup()","de5fee72":"learn = Learner(data,getModel(False),metrics=[error_rate],model_dir='\/kaggle\/working',loss_func=LabelSmoothingCrossEntropy()).mixup().to_fp16()","58828a39":"learn.lr_find()\nlearn.recorder.plot()","223998cc":"learn.fit_one_cycle(3,1e-3)","5f47c5ed":"SZ=224\ncutout_frac = 0.25\np_cutout = 0.75\ncutout_sz = round(SZ*cutout_frac)\ncutout_tfm = cutout(n_holes=(1,1), length=(cutout_sz, cutout_sz), p=p_cutout)","4623f54d":"learn.data = (\n    src\n    .transform(get_transforms(xtra_tfms=[cutout_tfm]),size=SZ)\n    .databunch(bs=64)\n    .normalize(imagenet_stats)\n)","e3cfcd0a":"learn.fit_one_cycle(7,1e-3)","f81db359":"learn.save('cutout-efficient')","2453c3bb":"# learn.unfreeze()\n# learn.fit_one_cycle(8,slice(1e-6,1e-4))","6eb20b95":"preds,y = learn.get_preds(DatasetType.Test)","94d8beb0":"results = torch.topk(preds,5)","874661df":"out = []\nfor i in results[1].numpy():\n    temp = \"\"\n    for j in i:\n        temp += (\" \"+str(data.classes[j])) \n    out.append(temp)\n# print(out)","48206a60":"sam_sub_df = pd.read_csv('..\/input\/kaggle_sample_submission.csv')\n# sam_sub_df.head()\nsam_sub_df[\"predicted\"] = out\nsam_sub_df.head()","c7296884":"sam_sub_df.to_csv(\"submission.csv\",index=False)","d979d5e2":"Reference\n- https:\/\/www.kaggle.com\/sujoykg\/xception-keras","3195db00":"Try\n\n- Use mixup\n- fp_16\n- Oversampling\n- cutout\n- efficientnet b3"}}