{"cell_type":{"28a61143":"code","30ce66c7":"code","4e6c2680":"code","370edb40":"code","fa0c2d87":"code","738bca92":"code","a654462a":"code","2aa96446":"code","a21f2de7":"code","ea68f47d":"code","9de31b77":"code","ce13b44b":"code","ce93b1c1":"code","6c2652fc":"code","80f74120":"code","3c70dd5c":"code","be430772":"code","059762fe":"code","d64817e9":"code","7d4f6fd3":"code","b0225bc5":"code","1c8f176d":"code","667fb788":"code","dfbd12a3":"code","f7043123":"code","57407a1d":"code","5064ddac":"code","76b5c9f3":"code","16abde38":"code","bf8e7d16":"code","8bf2cc8f":"code","b27a2171":"markdown","45bc685e":"markdown","a97b96c1":"markdown","fa1e1cda":"markdown","61b3cffe":"markdown","43206427":"markdown","017457c7":"markdown","88b46ce6":"markdown","d6b2cd0f":"markdown","e8a06d6b":"markdown","b5891f31":"markdown","53fdc73b":"markdown"},"source":{"28a61143":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","30ce66c7":"from pandas import read_csv\nfrom pandas import datetime\nimport pandas as pd\nimport missingno as msno\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nfrom math import sqrt\nimport numpy as np\nimport matplotlib.pyplot as plt, seaborn as sns\nfrom sklearn.preprocessing import MinMaxScaler\nimport tensorflow as tf","4e6c2680":"#from tensoforflow import keras\n#from keras.models import Sequential, Input, Model\n#from keras.layers import Dense, Dropout\n#from keras.layers import LSTM, CuDNNLSTM, MaxPooling1D, Conv1D, Flatten\nfrom numpy.random import randn\nimport os\nimport random\nimport numpy as np\nimport time\n\n# load dataset\nseries = pd.read_csv(\"\/kaggle\/input\/wind-power-forecasting\/Turbine_Data.csv\")","370edb40":"#the dataset shows 118224 observations for 22 features but some of the features have significant periods of missing data. We need to discard some periods and fill in the missing periods, otherwise our LSTM model will not converge or we may end up feeding it with garbage data.\n#the rightmost part of the msno matrix plot shows completess of data, it indicates that the last half of dataset is more complete. We will strive to use this part for training and testing.\nmsno.matrix(series)","fa0c2d87":"#correlation plot shows high positive correlation between a number of features, which will make them redundant. Discarting these features will help avoid the curse of dimensionality.\n#For this demonstration, we will only focus on the Target Y - \"ActivePower\", and Predictor feature - \"WindSpeed\". This further simplifies our task.\n#If you happen to have the mechanical engineering expertise knowledge about wind turbines, you will know that the wind power out is mostly dependent upon the weather conditions (e.g., wind speed), and you can therefore you can discard the rest of features.\nplt.subplots(figsize=(16, 16))\nsns.heatmap(series.corr(), annot=True, square=True)\nplt.show()","738bca92":"#we select the required data features we will in this demo\n#the \"unnamed:0\" feature is the timestamp\n#we will discard the timesetamp feature and then build a new one in a datetime format for the same period with the same time steps\ndf_selected = series[['Unnamed: 0','ActivePower','WindSpeed']]","a654462a":"#start of dataset is 2017-12-31 00:00:00+00:00\nprint(df_selected.head())\n#end of dataset is 2020-03-30 23:50:00+00:00 \nprint(df_selected.tail())","2aa96446":"#we select the input features\ninput_df = df_selected[['ActivePower', 'WindSpeed']]\n\n#generate timestamp for the observations mimicking the \"unnamed:0\" feature\nrng = pd.date_range('2017-12-31', periods=118224, freq='10T')\ntime_df = pd.DataFrame(rng)\n#fill in missing values with zero using the fillforward function\ninput_df = input_df.fillna(0).astype(float)\n#concatenate both the timestamp range and filled in features\ninput_df = pd.concat((time_df, input_df), axis=1)\n#set up index\ninput_df = input_df.set_index(0)\n#select a subset of data period from second half of original dataset, to ensure we have better quality signal (see completness comment of msno matrix plot above in the code)\ninput_df = input_df.loc['2019-12-17':]\ninput_df.head()","a21f2de7":"#check for NAN values\ninput_df.isna().sum()","ea68f47d":"# split data into train and test, for baseline we only need the Y target = \"ActivePower\" feature\nX = input_df['ActivePower'].values\ntrain, test = X[0:-144], X[-144:]\n# walk-forward validation\nhistory = [x for x in train]\npredictions = list()\nfor i in range(len(test)):\n\t# make prediction\n\tpredictions.append(history[-144])\n\t# observation\n\thistory.append(test[i])\n# report performance\nrmse = sqrt(mean_squared_error(test, predictions))\nprint('RMSE: %.3f' % rmse)\n# line plot of observed vs predicted\nplt.figure(figsize=(15, 8))\nplt.title('Predicted vs Actual Power Baseline')\nplt.plot(test, color='C0', marker='o', label='Actual Power')\nplt.plot(predictions, color='C1', marker='o', label='Predicted Power')\nplt.legend()\nplt.savefig('example.png')\nplt.show()","9de31b77":"#evaluation metrics\ndef forecast_accuracy(forecast, actual):\n    forecast = np.array(forecast)\n    actual = np.array(actual)\n    mape = np.mean(np.abs(forecast - actual)\/np.abs(actual))  # MAPE\n    me = np.mean(forecast - actual)             # ME\n    mae = np.mean(np.abs(forecast - actual))    # MAE\n    mpe = np.mean((forecast - actual)\/actual)   # MPE\n    rmse = np.mean((forecast - actual)**2)**.5  # RMSE\n    corr = np.corrcoef(forecast, actual)[0,1]   # corr\n    mins = np.amin(np.hstack([forecast[:,None], \n                              actual[:,None]]), axis=1)\n    maxs = np.amax(np.hstack([forecast[:,None], \n                              actual[:,None]]), axis=1)\n    minmax = 1 - np.mean(mins\/maxs)             # minmax\n    return({'mape':mape, 'me':me, 'mae': mae, \n            'mpe': mpe, 'rmse':rmse, \n            'corr':corr, 'minmax':minmax})","ce13b44b":"#results from baseline model (some may display \"inf\" or \"nan\" due to metric calculation errors such as division by zero)\nt = pd.DataFrame(test)\nc = pd.DataFrame(predictions)\nforecast_accuracy(c, t)","ce93b1c1":"#using the MachineLearningMastery formula for splitting up the dataset to predictors and target\n#reference: https:\/\/towardsdatascience.com\/single-and-multi-step-temperature-time-series-forecasting-for-vilnius-using-lstm-deep-learning-b9719a0009de\ndef create_X_Y(ts: np.array, lag=1, n_ahead=1, target_index=0) -> tuple:\n    \"\"\"\n    A method to create X and Y matrix from a time series array for the training of \n    deep learning models \n    \"\"\"\n    # Extracting the number of features that are passed from the array \n    n_features = ts.shape[1]\n    \n    # Creating placeholder lists\n    X, Y = [], []\n\n    if len(ts) - lag <= 0:\n        X.append(ts)\n    else:\n        for i in range(len(ts) - lag - n_ahead):\n            Y.append(ts[(i + lag):(i + lag + n_ahead), target_index])\n            X.append(ts[i:(i + lag)])\n\n    X, Y = np.array(X), np.array(Y)\n\n    # Reshaping the X array to an LSTM input shape \n    X = np.reshape(X, (X.shape[0], lag, n_features))\n\n    return X, Y","6c2652fc":"# Number of lags (steps back in 10min intervals) to use for models\nlag = 360\n# Steps in future to forecast (steps in 10min intervals)\nn_ahead = 144\n# ratio of observations for training from total series\ntrain_share = 0.8\n# training epochs\nepochs = 20\n# Batch size , which is the number of samples of lags\nbatch_size = 512\n# Learning rate\nlr = 0.001\n# The features for the modeling \nfeatures_final = ['ActivePower','WindSpeed']","80f74120":"# Subseting only the needed columns \nts = input_df[features_final]","3c70dd5c":"#Scaling data between 0 and 1\nscaler = MinMaxScaler()\nscaler.fit(ts)\nts_scaled = scaler.transform(ts)","be430772":"# Creating the X and Y for training, the formula is set up to assume the target Y is the left most column = target_index=0\nX, Y = create_X_Y(ts_scaled, lag=lag, n_ahead=n_ahead)","059762fe":"# Spliting into train and test sets \nXtrain, Ytrain = X[0:int(X.shape[0] * train_share)], Y[0:int(X.shape[0] * train_share)]\nXtest, Ytest = X[int(X.shape[0] * train_share):], Y[int(X.shape[0] * train_share):]","d64817e9":"#Neural Network Model configuration, this is a Vanilla LSTM model\nmodel = tf.keras.Sequential()\nmodel.add(tf.keras.layers.LSTM(16, activation='relu', return_sequences=False))\n#model.add(tf.keras.layers.CuDNNLSTM(32, return_sequences=False)) you can try to use the 10x faster GPU accelerated CuDNNLSTM instaed of the Vanilla LSTM above, but do not forget to set up the notebook accelerator to \"GPU\"\nmodel.add(tf.keras.layers.Dense(144))\n\n#set up early stop function to stop training when val_loss difference is higher than 0.001\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, min_delta=0.001)\nmodel.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001), loss='mae', metrics='mae')","7d4f6fd3":"#Train model on train data and use test data for validation\n#If the model does not converge accurately, you need check if it is a input data quality issue, introduce a dropout layer, or you can try adjusting the number of hidden nodes\nhistory = model.fit(Xtrain, Ytrain,epochs=epochs, validation_data=(Xtest, Ytest), shuffle=False, callbacks=[early_stopping])\nplt.plot(history.history['loss'], label='Training loss')\nplt.plot(history.history['val_loss'], label = 'Validation loss')\nplt.legend()","b0225bc5":"#predict based on test data\nyhat = model.predict(Xtest)","1c8f176d":"# Creating the predictions date range\ndays = time_df.values[-len(yhat):-len(yhat) + n_ahead]\ndays_df = pd.DataFrame(days)","667fb788":"#prepare resulting series for inverse scaling transformation\n#pay attention we will select only the first prediction we have made, therefore [0] used to select this window (we have generated multiple prediction sequences of 144 steps ahead, starting from each interval step in the test dataset)\npred_n_ahead = pd.DataFrame(yhat[0])\nactual_n_ahead = pd.DataFrame(Ytest[0])\n\n#repeat the column series 2 times, to make shape compatible for scale inversion\npr_p = pd.concat([pred_n_ahead]*2, axis=1)\nac_p = pd.concat([actual_n_ahead]*2, axis=1)","dfbd12a3":"#inverse scale tranform the series back to kiloWatts of power\npr_p = pd.DataFrame(scaler.inverse_transform(pr_p))\nac_p = pd.DataFrame(scaler.inverse_transform(ac_p))\n\n#rename columns\npr_p = pr_p.rename(columns={0:'PredPower'})\nac_p = ac_p.rename(columns={0:'ActualPower'})\n\n#concatenate together into one dataframe and set index\ndf_final = pd.concat([days_df, pr_p['PredPower'], ac_p['ActualPower']], axis=1).set_index(0)","f7043123":"#plot n_steps ahead for predicted and actual data\nplt.figure(figsize=(15, 8))\nplt.plot(df_final.index, df_final.ActualPower, color='C0', marker='o', label='Actual Power')\nplt.plot(df_final.index, df_final.PredPower, color='C1', marker='o', label='Predicted Power', alpha=0.6)\nplt.title('Predicted vs Actual Power')\nplt.gcf().axes[0].yaxis.get_major_formatter().set_scientific(False)\nplt.legend()\nplt.savefig('forecast_example.png')\nplt.show","57407a1d":"#evaluate result\nforecast_accuracy(df_final['PredPower'], df_final['ActualPower'], )","5064ddac":"##residuals summary stats\ndf_final['Residuals'] =  df_final['PredPower'] - df_final['ActualPower']\ndf_final['Residuals'].describe()","76b5c9f3":"#residuals histogram shows the bias (Mean Error)\ndf_final['Residuals'].hist(color = ('C0'))\nplt.title('Residuals histrogram plot')\nplt.xlabel('Bins')\nplt.ylabel('Occurance count')","16abde38":"#density plot shows the bias (Mean Error)\ndf_final['Residuals'].plot(kind='kde')","bf8e7d16":"#Q-Q plot showing normal distrubition of data\nfrom statsmodels.graphics.gofplots import qqplot\nqqplot(df_final['Residuals'])","8bf2cc8f":"#autocorrelation (excursions from the boundry lines) show that the model is doing a good job of incorporating relationship between observtations and lagged overvations\nfrom pandas.plotting import autocorrelation_plot\nautocorrelation_plot(df_final['Residuals'])\nplt.show()","b27a2171":"# Configure the LSTM model","45bc685e":"# Set up parameters for input to LSTM network","a97b96c1":"# Get data ready for LSTM model","fa1e1cda":"# Inverse Scale\nWhen doing this inverse scale exercise, it is important to match the shape of data on which the data was used to scale in first place. Otherwise it will throw an incompatible shape error message.","61b3cffe":"Creating the X-predictors and Y-target for training","43206427":"# First build a baseline model\nThe model for baseline we will build will be based on last observations for the same period as the prediction window. This is called a multi-step prediction. E.g. if we want to predict the next 15 days of wind power, we will use the last 15 days of data. It is probably not a great approach, but it only has to serve as a baseline.","017457c7":"Result comments:\n1. The algorithm seems to forecast the daily trend somewhat accurately, but it is not precise down to the 10-min intervals. This is explained by the 0.91 correlation coefficient\n2. The MAE & RMSE metrics show reduced error for this sequence compared to the one used in the baseline. However, it will be best to do a like for like comparison by using the same forecasting window.\n3. The MAPE metric has failed to produce meaningful result\n4. The ME metric shows on average we have an overshooting bias of 50kW. So we will forecast we have supply for 50kW more than what we will end up having, this is generally a small error which can be tolerated by grid operators.\n5. The algorithm requires more thorough training, turning and testing, to capture the relationship of wind speed and active power\n6. For the 15 days ahead a forecasting request, a resampling technique can be used to turn the dataset into hourly steps but this risks losing high quality data points ","88b46ce6":"# Import Dataset and required python libraries","d6b2cd0f":"# Intro comments\n\n**Dataset:**\n\nWhen analysing the dataset, you will notice large chunks of missing data. These unfortunally have to be trimmed off, because most imputation (filling) techniques will likely not do this forecasting any justice. As per one famous saying in the Machine Learning Field - \"Garbage in is equal to garbage out\". To implement successfully a forecasting problem, you need to ensure good data completness and quality. Here we will apply a basic zero-fill mechanism the least as possible.\n\n**Scaling and shape tranformation:**\n\nThe scaling and shape transformation may look intimidating at first, but do not be discouraged and take the time to understand them. Here we apply a simple MinMaxScaler, and use a formula for shaping the train\/test dataset for the LSTM algorithm. The prediction results are then inverse scaled back to be interpreted.\n\n**Models:**\nThe solution covers a demo of couple of forecasting techniques for time series\n\n1. Baseline - Simple approach using the previous data of same horizon size as the prediction window. (e.g. if we want to predict next day, we use what the last day was)\n2. Neural Network appraoch - Vanilla LSTM with 32 hidden nodes. This network uses the CPU resources in the notebook, but it is possible to use the GPU accelerated CuDNNLSTM which produces similar results it some small drawbacks in flexibility of configuration.","e8a06d6b":"Scaling of data. **!Pay attention!** to the shape of input dataset, because after predictions are made the dataset has to be inverse scaled using the same shape.","b5891f31":"# Visualisations and missing values","53fdc73b":"The dataset is recorded in 10min intervals, meaning 15 days is equivalent to 360 hours, or 2160 steps of 10mins. It is important to understand that a prediction for so many staps ahead is surely to fail, due to accumulation of error with expanding prediction horizon. Furthermore, the forecasting steps are a lot and will make any Neural Network slow down and very slow to converge. Therefore, we will shorten the prediction window to 1 day, or 24hours equal to 144 steps ahead. The code can be easily adjusted to accomodate shorter or longer prediction horizon by chaging the input\/output parameters from \"144\" to the desired output horizon."}}