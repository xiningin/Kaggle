{"cell_type":{"a3f40f90":"code","8577d362":"code","e3a96f80":"code","c87769c6":"code","777c8af5":"code","eefb691c":"code","66a4e35b":"code","63a91f1e":"code","63fe39c5":"code","025ec977":"code","90d27cdb":"code","4051baf2":"code","f055ace4":"code","b200ffb2":"code","98312094":"code","edb3abe9":"code","cef4914a":"code","e49511c9":"code","29cd80c0":"code","2f700227":"markdown","1b0c980c":"markdown","58bf6adf":"markdown","9b1c1fb1":"markdown","52152d67":"markdown","ea5b5263":"markdown","4027a9a5":"markdown","dab2c74c":"markdown","a1a265b7":"markdown","b577dce8":"markdown","4d2597d4":"markdown","c3db1fef":"markdown","01ecb429":"markdown","2199e646":"markdown","51642dc5":"markdown","ce3c9890":"markdown","7d6cd33f":"markdown","cab1385c":"markdown","e5250e86":"markdown","7fc3b603":"markdown","e735b4ac":"markdown","07b562d7":"markdown","00fb143b":"markdown","bfd48e94":"markdown"},"source":{"a3f40f90":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8577d362":"import seaborn as sb\nimport plotly.express as px\nimport sklearn.neighbors as KNN\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom matplotlib import pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import make_scorer\nfrom sklearn.model_selection import train_test_split","e3a96f80":"df_train = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ndf_train.describe()","c87769c6":"df_train_x = df_train.drop('label',axis =1)\ndf_train_y = df_train[['label']]","777c8af5":"pca = PCA().fit(df_train_x)\npca.explained_variance_ratio_","eefb691c":"a = []\ns = 0\na.append([0,(1-s)*100,'Percentage varience lost is :'+str((1-s)*100)+'%'])\nfor i in range(len(pca.explained_variance_ratio_)):\n    s+=pca.explained_variance_ratio_[i]\n    a.append([i+1,(1-s)*100,'Percentage varience lost is : '+\n              str((((1-s)*100)\/\/0.0001)\/10000)+'%'])\narr = pd.DataFrame(a)\narr = arr.rename(columns = {0:'No of components used:', \n                            1:'Total varience lost (in percentage)'} )\npx.line(data_frame = arr,x = 'No of components used:',\n        y = 'Total varience lost (in percentage)',\n        range_x = [0,784],range_y = [0,100],hover_name = 2,\n        title = 'Graph depicting the loss in varience as we reduce the number of components.')","66a4e35b":"components = 300\npca = PCA(n_components = components).fit(df_train_x)\nnumpy_train_x = df_train_x.to_numpy()\npca_trans = pca.transform(numpy_train_x)\npca_invtrans = pca.inverse_transform(pca_trans)\nrow = 10\ncolumn = 7\n\nfor i in range(row):\n    for j in range(column):\n        if j ==0:\n            a = numpy_train_x[0+(i*column)].reshape(28,28)\n            a = np.pad(a, pad_width=1, mode='constant', constant_values=400)\n            b = pca_invtrans[0+(i*column)].reshape(28,28)\n            b = np.pad(b, pad_width=1, mode='constant', constant_values=450)\n            stack = np.hstack((a,b))\n        else:\n            a = numpy_train_x[j+(i*column)].reshape(28,28)\n            a = np.pad(a, pad_width=1, mode='constant', constant_values=400)\n            b = pca_invtrans[j+(i*column)].reshape(28,28)\n            b = np.pad(b, pad_width=1, mode='constant', constant_values=450)\n            stack = np.hstack((stack,a))\n            stack = np.hstack((stack,b))\n    if i ==0:\n        final = stack\n    else:\n        final = np.vstack((final,stack))\nfinal = np.pad(final,pad_width=2, mode='constant', constant_values=500)\nimg = final","63a91f1e":"a = df_train_y['label'][0:row*column].to_numpy()\nlabel = []\nfor i in a:\n    label.append(\"The Label for the digit is: \"+str(i))\nfinal = []\nborder = ['Border']*604\nfinal.append(border)\nfinal.append(border)\nfor i in range(row):\n    final.append(border)\n    a = ['Border','Border']\n    for j in range(column):\n        for k in range(2):\n            a.append('Border')\n            for l in range(28):\n                a.append(label[i*column+j])\n            a.append('Border')\n    a.append('Border')\n    a.append('Border')\n    for i in range(28):\n        final.append(a)\n    final.append(border)\nfinal.append(border)\nfinal.append(border)\nlabel = final","63fe39c5":"fig = go.Figure(data = go.Heatmap(z = img,colorbar = None,\n                                  colorscale = [[0,'black'],[0.7,'white'],\n                                                [0.8,'red'],[0.9,'blue'],\n                                                [1.0,'rgb(255,0,255)']],\n                                  zmin = 0,zmax = 500,zauto = False,\n                                  hovertext = label))\nfig['layout']['yaxis']['autorange'] = \"reversed\"\nfig.update_layout(title = 'The Distortion induced due to PCA while using '+\n                  str(components)+' components.',\n                  height  = 600,width = 1100,yaxis_tickvals = [0],\n                  yaxis_ticktext =[' '],xaxis_tickvals = [0],\n                  xaxis_ticktext =[' '],\n                  xaxis_title = 'The Original images have a red border while a blue one has been used for their PCA transforms.')\nfig.update_traces(showscale = False)\nfig.show()","025ec977":"x_train,x_test,y_train,y_test = train_test_split(pca.transform(numpy_train_x),df_train_y,test_size = 0.1)","90d27cdb":"knn = KNN.KNeighborsClassifier(n_jobs = -1,n_neighbors = 3,algorithm = 'ball_tree')\nknn.fit(x_train,y_train.to_numpy().ravel())\npred = knn.predict(x_test)\npred","4051baf2":"y_test_np = y_test.to_numpy().ravel()\nscore=0\nfor i in range(len(y_test)):\n    if pred[i] == y_test_np[i]:\n        score = score+1\nscore \/=len(y_test)\nprint(str(score*100))","f055ace4":"predictions = pred\ny_test_np = y_test.to_numpy()\nclasses = [0,1,2,3,4,5,6,7,8,9]\n\n\nconfusion_mat = np.zeros((len(classes),len(classes)))\nfor i in range(len(predictions)):\n    confusion_mat[classes.index(predictions[i])][classes.index(y_test_np[i])]+=1\nconfusion_mat = confusion_mat.T\nconfusion_mat_norm = confusion_mat\/len(y_test_np)\nconfusion_mat_norm = (confusion_mat_norm\/\/0.0001)\/10000\n\nfig = ff.create_annotated_heatmap(confusion_mat_norm, x=classes, y=classes, \n                                  annotation_text=confusion_mat_norm,\n                                  colorscale='Viridis',text = confusion_mat,\n                                  hovertemplate='Expected Value: %{y}<br>'+\n                                                'Predicted Value: %{x}<br>'+\n                                                'No. of datapoints in this category are: %{text}<extra><\/extra>')\nfig.update_layout(title_text='<b>Confusion Matrix for the dataset:<\/b>',\n                  xaxis = {'title':'Predicted Values'},width = 900,\n                  yaxis = {'title':'Expected Values','autorange':'reversed'})\nfig.update_traces(showscale = True)\nfig.show()","b200ffb2":"knn.fit(pca.transform(numpy_train_x),df_train_y)","98312094":"df_test = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\ndf_test.describe()","edb3abe9":"np_test = pca.transform(df_test.to_numpy())","cef4914a":"df_test['label'] = knn.predict(np_test)","e49511c9":"a = []\nfor i in range(28000):\n    a.append(i+1)\ndf_test['ImageId'] = a\ndf_test.describe()","29cd80c0":"df_test[['ImageId','label']].to_csv('submission.csv',index=False)","2f700227":"## Exporting output to csv","1b0c980c":"### Plotting the confusion matrix ","58bf6adf":"## Processing of test set","9b1c1fb1":"## Plotting the image matrix.","52152d67":"This graph depicts how the loss in variance decreases as we increase the number of components.\n\n1. We can see that using only 100 components we can retain almost 92% varaiance in the data\n2. As we increase the number of components the variance retained increases rapidly at first and then slowly afterwords.\n3. If we keep increasing the number of components, eventually the variance loss becomes 0 at 784 components.\n4. We can see that if we use 300 components rather than 784 we can still retain 98.7% of the total variance therefore I have used 300 components for creating the model. \n5. If you want a more intuitive feel of how the PCA would transform the dataset when using different numbers of components, check out my other notebook with animated charts for PCA [here!](https:\/\/www.kaggle.com\/sidagar\/pca-explained-with-animated-visuals)","ea5b5263":"# Importing important libraries.","4027a9a5":"We can therefore see that the images are very similar with no significant distortion and in some cases it might even be difficult to spot these distortions with the naked eye.","dab2c74c":"# Loading the Dataset.","a1a265b7":"**If you like my notebook, please upvote my work!**\n\n**If you use parts of this notebook in your scripts\/notebooks, giving some kind of credit for instance link back to this notebook would be very much appreciated. Thanks in advance! :)**\n\nThankyou! :) Hope you like my work!","b577dce8":"## Predicting over test set","4d2597d4":"### Applying PCA transform","c3db1fef":"## Retraining the model over the whole dataset. ","01ecb429":"# Visualising the effect of PCA over input images.","2199e646":"# Machine Learning Model.","51642dc5":"We can see that the confusion matrix shows higher values for digits that look similar and might be confusiong to distinguish between and lower values for the digits that are easy to distinguish between.","ce3c9890":"## Reading test file","7d6cd33f":"## Creating the image matrix for the dataset.","cab1385c":"# Visualising percentage variance loss.","e5250e86":"## Splitting data into train and test set ","7fc3b603":"# Predicting output over the testset.","e735b4ac":"# Splitting the target and predictor variables.","07b562d7":"## Creating matrix of labels for the plot.","00fb143b":"## Fetching the variance ratios for PCA over the given dataset. ","bfd48e94":"## Testing accuracy of the model."}}