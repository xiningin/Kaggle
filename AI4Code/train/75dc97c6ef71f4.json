{"cell_type":{"a3340133":"code","c0391c35":"code","5407b7ff":"code","73827441":"code","fb348613":"code","8fc56aa6":"code","162c3395":"code","1e786ee4":"code","d5add6b1":"markdown","e58be089":"markdown"},"source":{"a3340133":"# useful\nimport numpy as np\nimport pandas as pd\n\n# neural nets\nimport tensorflow as tf\nimport tensorflow.keras.models as M\nimport tensorflow.keras.layers as L\n\n# custom\nimport riiideducation","c0391c35":"# PIVOT DATAFRAMES\npiv1 = pd.read_csv(\"..\/input\/riiid-fixed-infos\/content.csv\")\npiv2 = pd.read_csv(\"..\/input\/riiid-fixed-infos\/task.csv\")\npiv3 = pd.read_csv(\"..\/input\/riiid-fixed-infos\/user.csv\")\n\nfor col, df in zip([\"content_sum\", \"task_container_sum\", \"user_sum\"], [piv1, piv2, piv3]):\n    df[col] = (df[col] - df[col].min()) \/ (df[col].max() - df[col].min())\n#\nm1 = piv1[\"content_sum\"].median()\nm2 = piv2[\"task_container_sum\"].median()\nm3 = piv3[\"user_sum\"].median()\n\n\n# OTHER CONSTABTS\nTARGET = \"answered_correctly\"\nTIME_MEAN = 21000.0\nTIME_MIN = 0.0\nTIME_MAX = 300000.0\nmap_prior = {True:1, False:0}","5407b7ff":"def preprocess(df):\n    df = df.merge(piv1, how=\"left\", on=\"content_id\")\n    df[\"content_emb\"] = df[\"content_emb\"].fillna(0.5)\n    df[\"content_sum\"] = df[\"content_sum\"].fillna(m1)\n    \n    df = df.merge(piv2, how=\"left\", on=\"task_container_id\")\n    df[\"task_container_emb\"] = df[\"task_container_emb\"].fillna(0.5)\n    df[\"task_container_sum\"] = df[\"task_container_sum\"].fillna(m2)\n    \n    df = df.merge(piv3, how=\"left\", on=\"user_id\")\n    df[\"user_emb\"] = df[\"user_emb\"].fillna(0.5)\n    df[\"user_sum\"] = df[\"user_sum\"].fillna(m3)\n    \n    df[\"prior_question_elapsed_time\"] = df[\"prior_question_elapsed_time\"].fillna(TIME_MEAN)\n    df[\"duration\"] = (df[\"prior_question_elapsed_time\"] - TIME_MIN) \/ (TIME_MAX - TIME_MIN)\n    df[\"prior_answer\"] = df[\"prior_question_had_explanation\"].map(map_prior)\n    df[\"prior_answer\"] = df[\"prior_answer\"].fillna(0.5)\n    #df = df.fillna(-1)\n    epsilon = 1e-6\n    df[\"score\"] = 2*df[\"content_emb\"]*df[\"user_emb\"] \/ (df[\"content_emb\"]+ df[\"user_emb\"] + epsilon)\n    return df\n#=========","73827441":"def make_ann(n_in):\n    inp = L.Input(shape=(n_in,), name=\"inp\")\n    d1 = L.Dense(100, activation=\"relu\", name=\"d1\")(inp)\n    d2 = L.Dense(100, activation=\"relu\", name=\"d2\")(d1)\n    preds = L.Dense(1, activation=\"sigmoid\", name=\"preds\")(d2)\n    \n    model = M.Model(inp, preds, name=\"ANN\")\n    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n    return model\n#===================","fb348613":"FE = [\"content_emb\",\"content_sum\" ,\"task_container_emb\", \"task_container_sum\",\n      \"user_emb\", \"user_sum\",\"duration\", \"prior_answer\",\"score\"]","8fc56aa6":"net0 = make_ann(len(FE))\nnet1 = make_ann(len(FE))\nnet2 = make_ann(len(FE))\nnet3 = make_ann(len(FE))\nnet4 = make_ann(len(FE))\nnet5 = make_ann(len(FE))\nnet0.load_weights(\"..\/input\/riiid-nnet\/w0.h5\")\nnet1.load_weights(\"..\/input\/riiid-nnet\/w1.h5\")\nnet2.load_weights(\"..\/input\/riiid-nnet\/w2.h5\")\nnet3.load_weights(\"..\/input\/riiid-nnet\/w3.h5\")\nnet4.load_weights(\"..\/input\/riiid-nnet\/w4.h5\")\nnet5.load_weights(\"..\/input\/riiid-nnet\/w5.h5\")","162c3395":"env = riiideducation.make_env()\niter_test = env.iter_test()\n\nfor test_df, sample_prediction_df in iter_test:\n    test_df = preprocess(test_df)\n    x_te = test_df[FE].values\n    p0 = net0.predict(x_te, batch_size=50_000, verbose=0)[:, 0]\n    p1 = net1.predict(x_te, batch_size=50_000, verbose=0)[:, 0]\n    p2 = net2.predict(x_te, batch_size=50_000, verbose=0)[:, 0]\n    p3 = net3.predict(x_te, batch_size=50_000, verbose=0)[:, 0]\n    p4 = net4.predict(x_te, batch_size=50_000, verbose=0)[:, 0]\n    p5 = net5.predict(x_te, batch_size=50_000, verbose=0)[:, 0]\n    test_df['answered_correctly'] = (0.16*p0+ 0.17*p1 + 0.17*p2+ 0.17*p3 + 0.17*p4+ 0.16*p5)\n    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])\n#","1e786ee4":"test_df.head()","d5add6b1":"## CONSTANTS","e58be089":"## PREDICT"}}