{"cell_type":{"f9c6a3c7":"code","e21c41c6":"code","ae4ce3f7":"code","0e868261":"code","08b07c77":"code","01fbadca":"code","3c12ef30":"code","bee3d7c9":"code","d42beb67":"code","885ca0bd":"code","3485771d":"code","e6ddd55c":"code","2f3bd859":"code","56fc2a73":"code","49c6c643":"code","0f28960f":"code","2d39263e":"code","fdc652e9":"code","f4af9568":"code","a5004fd1":"code","ad26952b":"code","ee91f27d":"code","d3c2f5fa":"code","caeaffad":"code","726d8adf":"code","c7bc7c1f":"code","48da47fe":"code","37cdaa50":"code","544f2d3a":"code","c06b0fb1":"code","60cfab62":"code","f6d0c6be":"code","cfff21be":"code","ed48791a":"code","a19355e1":"markdown","a59692a8":"markdown","78a235dd":"markdown","0249a500":"markdown"},"source":{"f9c6a3c7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom statsmodels.tsa.holtwinters import ExponentialSmoothing, SimpleExpSmoothing\nfrom sklearn.decomposition import TruncatedSVD\nfrom multiprocessing import Pool\n\nfrom warnings import catch_warnings\nfrom warnings import filterwarnings\nfilterwarnings('ignore')\n\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\nplt.rcParams[\"figure.figsize\"] = (20, 6)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","e21c41c6":"def auto_ets(df, seasonal_periods=[None], trend=['add', 'mul'], damped=[True], seasonal=[None], use_boxcox=[False]):\n    min_ic = np.inf\n    best_model = None\n    params = [(sp, t, d, s, b) for sp in seasonal_periods for t in trend for d in damped for s in seasonal for b in use_boxcox]\n    for sp, t, d, s, b in params:\n        try:\n            with catch_warnings():\n                filterwarnings('ignore')\n                ets = ExponentialSmoothing(df, seasonal_periods=sp, trend=t, damped=d, seasonal=s).fit(use_boxcox=b, remove_bias=False)\n            if ets.aicc < min_ic:\n                min_ic = ets.aicc\n                best_model = ets\n        except:\n            pass\n    return best_model\n\ndef naive(df, periods):\n    return df.shift(periods, freq='D')\n\ndef fit_predict(data, forecast_period=43):\n    if sum(data != 0) > 28:\n        first_idx = data.index[data != 0][0]\n        dat = data[first_idx:]\n    else:\n        dat = data.copy()\n    model = auto_ets(dat)\n    fcast = model.forecast(forecast_period)\n    return fcast.dropna(), model\n\ndef fit_predict_pool(data, forecast_period=43):\n    return fit_predict(data, forecast_period)[0]\n\ndef predict_all(dat, n_components=None):\n    pool = Pool()\n    f = pool.map(fit_predict_pool, [dat.loc[i, :] for i in dat.index])\n    fcast = pd.DataFrame(index=dat.index, columns=f[0].index)\n    for i in range(len(dat.index)):\n        fcast.iloc[i, :] = f[i]\n    return fcast","ae4ce3f7":"train = pd.read_csv('..\/input\/covid19-global-forecasting-week-4\/train.csv', parse_dates=['Date'])\ntest = pd.read_csv('..\/input\/covid19-global-forecasting-week-4\/test.csv', parse_dates=['Date'])\nsubmission = pd.read_csv('..\/input\/covid19-global-forecasting-week-4\/submission.csv')","0e868261":"train['key'] = train['Country_Region'].astype('str') + \" \" + train['Province_State'].astype('str')\ntest['key'] = test['Country_Region'].astype('str') + \" \" + test['Province_State'].astype('str')","08b07c77":"test","01fbadca":"len(set(train.key)), len(set(test.key))","3c12ef30":"submission","bee3d7c9":"fatalities = train.pivot('key', 'Date', 'Fatalities')\ncases = train.pivot('key', 'Date', 'ConfirmedCases')\ncases","d42beb67":"cases.sum().plot(label='Confirmed cases', legend=True, logy=True)\nfatalities.sum().plot(label='Fatalities', legend=True, title='COVID19 Global Confirmed Cases and Fatalities (log scale)');","885ca0bd":"new_cases = cases.diff(axis=1).dropna(axis=1)\nnew_fatalities = fatalities.diff(axis=1).dropna(axis=1)\nnew_cases","3485771d":"f, m = fit_predict(new_cases.sum())\nnew_cases.sum()[-43:].plot(title='Aggregated global new cases model')\nf[:29].plot()\nm.summary()","e6ddd55c":"f, m = fit_predict(new_fatalities.sum())\nnew_fatalities.sum()[-43:].plot(title='Aggregated global new fatalities model')\nf[:29].plot()\nm.summary()","2f3bd859":"forecast_new_cases = predict_all(new_cases)\nnew_cases.sum()[-43:].plot()\nforecast_new_cases.sum()[:29].plot()","56fc2a73":"forecast_new_cases.sum()[:29]\/1000","49c6c643":"forecast_new_fatalities = predict_all(new_fatalities)\nnew_fatalities.sum()[-43:].plot()\nforecast_new_fatalities.sum()[:29].plot()","0f28960f":"forecast_new_fatalities.sum()[:29]\/1000","2d39263e":"forecast_cases = cases.iloc[:, -1].values[:, None] + forecast_new_cases.cumsum(axis=1)\nforecast_cases","fdc652e9":"forecast_fatalities = fatalities.iloc[:, -1].values[:, None] + forecast_new_fatalities.cumsum(axis=1)\nforecast_fatalities","f4af9568":"forecast_cases.iloc[:, :29].sum().plot(title='Cumulative Global Confirmed Cases (millions)')\ncases.sum()[-43:].plot();","a5004fd1":"forecast_fatalities.iloc[:, :29].sum().plot(title='Cumulative Global Fatalities')\nfatalities.sum()[-43:].plot();","ad26952b":"(forecast_fatalities.iloc[:, :29].sum() \/ forecast_cases.iloc[:, :28].sum()).plot(title='Global fatalities as proportion of confirmed cases')\n(fatalities.sum() \/ cases.sum())[-43:].plot();","ee91f27d":"cases_melt = forecast_cases.reset_index().melt('key', var_name='Date', value_name='ConfirmedCases')\nfatalities_melt = forecast_fatalities.reset_index().melt('key', var_name='Date', value_name='Fatalities')","d3c2f5fa":"test = test.merge(cases_melt, how='left', on=['key', 'Date'])\ntest = test.merge(fatalities_melt, how='left', on=['key', 'Date'])\ntest","caeaffad":"us_cases = test[test.Country_Region == 'US'].pivot('Province_State', 'Date', 'ConfirmedCases').dropna(axis=1)\nus_cases","726d8adf":"train[train['Country_Region'] == 'US'].pivot('Province_State', 'Date', 'ConfirmedCases').dropna(axis=1).sum()[-14:].plot()\nus_cases.sum()[:29].plot(title='United States Cumulative Confirmed Cases');","c7bc7c1f":"test[test.Country_Region == 'US'].pivot('Province_State', 'Date', 'ConfirmedCases').dropna(axis=1).sum()[:29] \/ 1000","48da47fe":"us_fatalities = test[test.Country_Region == 'US'].pivot('Province_State', 'Date', 'Fatalities').dropna(axis=1)\nus_fatalities","37cdaa50":"train[train['Country_Region'] == 'US'].pivot('Province_State', 'Date', 'Fatalities').dropna(axis=1).sum()[-43:].plot()\nus_fatalities.sum()[:29].plot(title='United State Cumulative Fatalities');","544f2d3a":"test[test.Country_Region == 'US'].pivot('Province_State', 'Date', 'Fatalities').dropna(axis=1).sum()[:29] \/ 1000","c06b0fb1":"(train[train['Country_Region'] == 'US'].pivot('Province_State', 'Date', 'Fatalities').dropna(axis=1).sum()\n \/ train[train['Country_Region'] == 'US'].pivot('Province_State', 'Date', 'ConfirmedCases').dropna(axis=1).sum())[-43:].plot()\n\n(us_fatalities.sum() \/ us_cases.sum())[:29].plot(title='US Fatalities as proportion of confirmed cases');","60cfab62":"test","f6d0c6be":"submission.ConfirmedCases = test.ConfirmedCases.fillna(0)\nsubmission.Fatalities = test.Fatalities.fillna(0)\nsubmission","cfff21be":"submission.to_csv('submission.csv', index=False)","ed48791a":"submission.tail(10)","a19355e1":"## US Projected Cumulative Fatalities (thousands)","a59692a8":"## Global Forecast Daily New Cases (thousands)","78a235dd":"## Global Forecast Daily Fatalities (thousands)","0249a500":"## US Projected Cumulative Confirmed Cases (thousands)"}}