{"cell_type":{"f31706d0":"code","3584a069":"code","3f33eff7":"code","747654b9":"code","a5804633":"code","0df5c759":"code","cfc7b6b0":"code","81aaf6b1":"code","a0d077c6":"code","bd9c1727":"code","36201378":"code","fd17fea6":"code","699e979f":"code","6240a30d":"code","ffdfc2cd":"code","ae03cf37":"code","fb0890b5":"code","38321e62":"code","520fdb12":"code","8ea99ddf":"code","2e7f97f9":"code","ae59725c":"code","028cf615":"code","5c8a9c78":"code","cc7a2b0d":"code","1700807c":"code","1cb30aaf":"code","3844eaaa":"code","174c0428":"code","1483475f":"code","99e7ac3f":"markdown","f011b2c7":"markdown","7dd42ac3":"markdown","6b919730":"markdown","7efd3f0e":"markdown","fb80f06f":"markdown","34656bc2":"markdown","dc415c3f":"markdown"},"source":{"f31706d0":"!pip install ..\/input\/package\/syllables-0.1.0-py2.py3-none-any.whl","3584a069":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom nltk.tokenize import word_tokenize, sent_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nimport nltk\nimport re # Regularexpresion\nimport syllables\nimport seaborn as sns\nimport math\nfrom nltk.corpus import state_union\nfrom nltk.tokenize import PunktSentenceTokenizer\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\ncolor = sns.color_palette()\nsns.set_style('darkgrid')\n%matplotlib inline\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","3f33eff7":"all_stopword = list(set(stopwords.words('english')))+['?','.',',','!',\"''\",\"``\"]","747654b9":"df = pd.read_csv('\/kaggle\/input\/commonlitreadabilityprize\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/commonlitreadabilityprize\/test.csv')","a5804633":"df.head(2)","0df5c759":"df.loc[:,'excerpt']","cfc7b6b0":"print(\"train target min value \",df['target'].min())\nprint(\"train target min value \",df['target'].max())","81aaf6b1":"'''\nfunction for create unique words and remove stop words\n'''\ndef only_words(wordlist):\n    wordwithout_stopword = []\n    for w in wordlist:\n        if not w in all_stopword:\n            wordwithout_stopword.append(w)\n    return list(set(wordwithout_stopword))\n\n'''\ncount total words in sentence\n'''\ndef count_words(wordlist):\n    return len(wordlist)\n\n'''\nTotal sentence in paragraph\n'''\ndef count_sentence(paragraph):\n    return len(paragraph)\n\n'''\nTotal syllables in sentence\n'''\ndef count_syllables(wordlist):  \n    syllables_list = [ syllables.estimate(single_word) for single_word  in wordlist]\n    return sum(syllables_list)\n\n'''\nAverage word length in sentence\n'''\ndef average_word_length(wordlist):        \n    maxword_list = [len(i) for i in wordlist]\n    return sum(maxword_list)\/len(maxword_list)","a0d077c6":"def flesch_reading_level(total_words, total_sentence, total_syllables):\n    flesch_level = 0.39*(total_words\/total_sentence)+11.8*(total_syllables\/total_words)-15.59\n    return flesch_level","bd9c1727":"def flesch_dayani_score(total_words, total_sentence, total_syllables):\n    flesch_dayani = 0.31-8.846*(total_syllables\/total_words)- 1.01*(total_words\/total_sentence)\n    return flesch_dayani","36201378":"train_word_token = list(map(word_tokenize, df.loc[:,'excerpt']))\ntest_word_token = list(map(word_tokenize, test.loc[:,'excerpt']))","fd17fea6":"df['only_words'] = list(map(only_words,train_word_token))\ntest['only_words'] = list(map(only_words,test_word_token))","699e979f":"df['sentence'] = list(map(sent_tokenize,  df.loc[:,'excerpt']))\ntest['sentence'] = list(map(sent_tokenize,  test.loc[:,'excerpt']))","6240a30d":"df['total_words'] = list(map(count_words, df['only_words']))\ntest['total_words'] = list(map(count_words, test['only_words']))","ffdfc2cd":"df['total_sentence'] = list(map(count_sentence, df['sentence']))\ntest['total_sentence'] = list(map(count_sentence, test['sentence']))","ae03cf37":"df['total_syllables'] = list(map(count_syllables,  df['only_words']))\ntest['total_syllables'] = list(map(count_syllables,  test['only_words']))","fb0890b5":"df['average_word_length'] = list(map(average_word_length, df['only_words']))\ntest['average_word_length'] = list(map(average_word_length, test['only_words']))","38321e62":"df['FRL'] = list(map(flesch_reading_level, df['total_words'],df['total_sentence'],df['total_syllables'] ))\ntest['FRL'] = list(map(flesch_reading_level, test['total_words'],test['total_sentence'],test['total_syllables'] ))","520fdb12":"df['FDS'] = list(map(flesch_dayani_score,  df['total_words'],df['total_sentence'],df['total_syllables'] ))\ntest['FDS'] = list(map(flesch_dayani_score,  test['total_words'],test['total_sentence'],test['total_syllables'] ))","8ea99ddf":"def count_verb(wordlist):\n    total_word = []\n    verbs = []\n    singular_nouns  =[]\n    proper_nouns =[]\n    adverb =[]\n    tag = nltk.pos_tag(wordlist)\n    grammar = \"NP: {<RB.?>*<VB.?>*<NNP>*<NN>*}\"\n    cp  =nltk.RegexpParser(grammar)\n    \n    for w in list(tag):\n        if w[1] == 'VB':\n            verbs.append(len(w[0]))\n        total_word.append(len(w[0]))\n    return sum(verbs)\/(sum(total_word)*100)\n\ndf['verbs'] = list(map(count_verb, df.loc[:,'only_words']))\ntest['verbs'] = list(map(count_verb, test.loc[:,'only_words']))","2e7f97f9":"def verb_past(wordlist):\n    total_word = []\n    verbs_past = []\n    tag = nltk.pos_tag(wordlist)    \n    for w in list(tag):\n        if w[1] == 'VBD':\n            verbs_past.append(len(w[0]))\n        total_word.append(len(w[0]))\n    return sum(verbs_past)\/(sum(total_word)*100)\n\ndf['verbs_past'] = list(map(verb_past, df.loc[:,'only_words']))\ntest['verbs_past'] = list(map(verb_past, test.loc[:,'only_words']))","ae59725c":"def count_adverb(wordlist):\n    total_word = []\n    adverb = []\n    tag = nltk.pos_tag(wordlist)    \n    for w in list(tag):\n        if w[1] == 'RB':\n            adverb.append(len(w[0]))\n        total_word.append(len(w[0]))\n    return sum(adverb)\/(sum(total_word)*100)\n\ndf['adverb'] = list(map(count_adverb, df.loc[:,'only_words']))\ntest['adverb'] = list(map(count_adverb, test.loc[:,'only_words']))","028cf615":"df.describe().transpose()","5c8a9c78":"df.describe().transpose()[['mean', 'std']]","cc7a2b0d":"(fig, axs) = plt.subplots(nrows=2, ncols=2, figsize=(12,12))\naxs[0,0].scatter(df['target'],df['total_words'], color='#e6005c80')\naxs[0,0].set_title(\"Total Words\")\naxs[0,1].scatter(df['target'],df['total_sentence'],color='#00666680')\naxs[0,1].set_title(\"Total Sentence\")\naxs[1,0].scatter(df['target'],df['total_syllables'],color='#66990080')\naxs[1,0].set_title(\"Total Syllables\")\naxs[1,1].scatter(df['target'],df['average_word_length'],color='#80008080')\naxs[1,1].set_title(\"Average Word Length\")\nfig.show()\n\n","1700807c":"(fig, axs) = plt.subplots(nrows=3, ncols=3, figsize=(12,12))\naxs[0,0].scatter(df['target'],df['FRL'], color='#1ab2ff80')\naxs[0,0].set_title(\"Flesch-Kincaid reading\")\naxs[0,1].scatter(df['target'],df['standard_error'], color='#80008080')\naxs[0,1].set_title(\"Standard Error\")\naxs[0,2].scatter(df['target'],df['verbs_past'], color='#80008080')\naxs[0,2].set_title(\"Verb Past\")\naxs[1,0].scatter(df['target'],df['FDS'], color='#00666680')\naxs[1,0].set_title(\"Flesch-Dayani Score\")\naxs[1,1].scatter(df['target'],df['verbs'], color='#00666680')\naxs[1,1].set_title(\"verb\")\naxs[1,2].scatter(df['target'],df['adverb'], color='#00666680')\naxs[1,2].set_title(\"adverb\")\n\nfig.show()","1cb30aaf":"sns.pairplot(df[['FRL', 'verbs_past', 'FDS', 'verbs','target']], diag_kind='kde')\nplt.show()","3844eaaa":"#start with one review:\ntext = df.loc[0, 'excerpt']\n\n#Create and generate a word cloud image:\nwordcloud = WordCloud().generate(text)\n\n#Display the Generated image:\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()","174c0428":"wordcloud = WordCloud(max_font_size=50, max_words =100, \n                      background_color='white').generate(text)\nplt.figure()\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","1483475f":"wordcloud.to_file(\"first_review.png\")","99e7ac3f":"# Flesch-Kincaid reading formula\n![](https:\/\/i.ibb.co\/xsYLbCk\/formula1.png)","f011b2c7":"<h1 id=\"introduction\">Introduction <\/h1>\nData preparation is basic process of any machine learning model.  ","7dd42ac3":"<h1 id=\"data_visualisation\"> Data Visualisation <\/h1>","6b919730":"<h1 id=\"wordclouds\"> Word Clouds <\/h1>","7efd3f0e":"<h1 id=\"data_extraction\"> Data Extraction <\/h1>","fb80f06f":"# Data Extraction \n<ol>\n    <li> <a href='#introduction'>Introdction<\/a><\/li>\n    <li> <a href='#data_extraction'> Data Extraction <\/a><\/li>\n    <li> <a href='#data_visualisation'> Data Visualisation <\/a><\/li>\n    <li> <a href='#wordclouds'> Word Clouds <\/a><\/li>\n    <li> <a href='#conclusion'> Conclusion <\/a><\/li>\n<\/ol>","34656bc2":"<h1 id=\"conclusion\">Conclusion <\/h1>\nVery welcome for any suggestions. I am keep working on it also finding a job. \nI wish to change my current job. ","dc415c3f":"# Flesch-Dayani Score\n\n\n\n![](https:\/\/i.ibb.co\/s6FjDF5\/formula2.png)"}}