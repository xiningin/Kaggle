{"cell_type":{"2165e34b":"code","daa57039":"code","2a4acbd7":"code","22d2ebe2":"code","0833749d":"code","1c1a3261":"code","14a208f3":"code","f6dd1506":"code","b5ffd1e9":"code","44bf575e":"code","314d1938":"code","807727e2":"code","6fa8a624":"code","3aed03bf":"code","8f79405e":"code","d58359e8":"code","86fc0fe9":"code","1f790dfe":"code","7da99ee8":"code","397d8b84":"code","bdab9241":"code","31335759":"code","fe5face3":"code","8b61efb7":"code","055897ca":"code","35c3cb30":"code","662d4ee7":"code","40f67b3e":"code","111a6a66":"code","3194848d":"markdown"},"source":{"2165e34b":"import os\nimport nibabel as nib\nfrom tqdm import tqdm\nimport numpy as np\nimport pandas as pd\n\n# from sklearn.preprocessing import StandardScaler\n# from sklearn.decomposition import PCA\n\n# from keras.preprocessing.image import ImageDataGenerator\n# from keras.utils import to_categorical\nfrom keras.layers.merge import concatenate\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nimport keras\nfrom keras.models import Model, load_model\nfrom keras.layers import Input, BatchNormalization, Activation\nfrom keras.layers.convolutional import Conv2D, UpSampling2D\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras import optimizers\nfrom keras import backend as K\n\nimport cv2 as cv2\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","daa57039":"def load_data(path, start, stop):\n    \"\"\"\n    param path: path of the training dataset\n    returns:\n        data: files of type flair, t1. t1_ce and t2\n        gt: segmented tumor in the file types\n    \"\"\"\n    path = path + 'BraTS20_Training_'\n#     my_dir = sorted(os.listdir(path))\n    data = []\n    for p in tqdm(range(start,stop+1)):\n        \n        p = str(p).zfill(3)+'\/'\n        data_list = sorted(os.listdir(path+p))\n        \n#         flair = np.array(nib.load(path+p+'\/'+data_list[0]).get_fdata())\n        \n        seg = np.array(nib.load(path+p+'\/'+data_list[1]).get_fdata())\n        \n        t1 = np.array(nib.load(path+p+'\/'+data_list[2]).get_fdata())\n        \n#         t1ce = np.array(nib.load(path+p+'\/'+data_list[3]).get_fdata())\n        \n#         t2 = np.array(nib.load(path+p+'\/'+data_list[4]).get_fdata())\n        \n#         data.append([flair, t1, t1ce, t2, seg])\n        data.append([t1, seg])\n    data = np.array(data)\n    data = np.rint(data).astype(np.int16)\n    data = data[:, :, :, :]\n    data = np.transpose(data)\n    return data","2a4acbd7":"path= '..\/input\/brats20-dataset-training-validation\/BraTS2020_TrainingData\/MICCAI_BraTS2020_TrainingData\/'\ndata = load_data(path,1,20)","22d2ebe2":"data.shape, data.dtype","0833749d":"data = np.transpose(data, (4,0,1,2,3))\nprint(data.shape)","1c1a3261":"fig = plt.figure(figsize=(5,5))\nimmmg = data[5][100,:,:,0]\nimgplot = plt.imshow(immmg, 'gray')\nplt.show()","14a208f3":"def Data_Concatenate(input_data):\n    counter = 0\n    output = []\n    for i in range(2):\n        print('$')\n        c=0; counter=0;\n        for ii in range(len(input_data)):\n            if (counter < len(input_data)):\n                a = input_data[counter][:,:,:,i]\n                b = input_data[counter+1][:,:,:,i]\n                \n                if (counter == 0):\n                    c = np.concatenate((a,b), axis=0)\n                    print('c1={}'.format(c.shape))\n                    counter += 2\n                else:\n                    c1 = np.concatenate((a,b), axis=0)\n                    c = np.concatenate((c,c1), axis=0)\n                    print('c2={}'.format(c.shape))\n                    counter += 2\n        c = c[:,:,:,np.newaxis]\n        output.append(c)\n    return output","f6dd1506":"indata = Data_Concatenate(data)","b5ffd1e9":"AIO = concatenate(indata, axis=3)\nAIO = np.array(AIO, dtype=np.float32)\nTR = np.array(AIO[:,:,:,0], dtype=np.float32)\nTRL = np.array(AIO[:,:,:,1], dtype=np.float32)","44bf575e":"X_train, X_test, Y_train, Y_test = train_test_split(TR, TRL, test_size=0.15, random_state=32)\nAIO=TRL=0\nprint(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)","314d1938":"fig = plt.figure(figsize=(15,8))\nax1 = fig.add_subplot(121)\nax1.imshow(X_train[190],'gray')\n\nax2 = fig.add_subplot(122)\nax2.imshow(Y_train[190],'gray')","807727e2":"# Converting original image to Stationary wavelet transformed image\nfrom pywt import swt2\n\nfor i in range(len(X_train)):\n    c = swt2(data=X_train[i],wavelet='db1',level=1)\n    X_train[i] = c[0][0]\n    c=0\n\nfor i in range(len(X_test)):\n    c = swt2(data=X_test[i], wavelet='db1',level=1)\n    X_test[i] = c[0][0]\n    c=0","6fa8a624":"X_train[0].shape, X_train[0].dtype","3aed03bf":"def Convolution(input_tensor, filters):\n    \n    x = Conv2D(filters=filters, kernel_size=(3,3), padding='same', strides=(1,1))(input_tensor)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    return x\n\ndef model(input_shape):\n    \n    inputs = Input((input_shape))\n    \n    conv_1 = Convolution(inputs, 32)\n    maxp_1 = MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same')(conv_1)\n    \n    conv_2 = Convolution(maxp_1, 64)\n    maxp_2 = MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same')(conv_2)\n    \n    conv_3 = Convolution(maxp_2, 128)\n    maxp_3 = MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same')(conv_3)\n    \n    conv_4 = Convolution(maxp_3, 256)\n    maxp_4 = MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same')(conv_4)\n    \n    conv_5 = Convolution(maxp_4, 512)\n    upsample_6 = UpSampling2D((2,2))(conv_5)\n    \n    conv_6 = Convolution(upsample_6, 256)\n    upsample_7 = UpSampling2D((2,2))(conv_6)\n    \n    upsample_7 = concatenate([upsample_7, conv_3])\n    \n    conv_7 = Convolution(upsample_7, 128)\n    upsample_8 = UpSampling2D((2,2))(conv_7)\n    \n    conv_8 = Convolution(upsample_8, 64)\n    upsample_9 = UpSampling2D((2,2))(conv_8)\n    \n    upsample_9 = concatenate([upsample_9, conv_1])\n    \n    conv_9 = Convolution(upsample_9, 32)\n    outputs = Conv2D(1, (1,1), activation='sigmoid')(conv_9)\n    \n    model = Model(inputs=[inputs], outputs=[outputs])\n    \n    return model","8f79405e":"# Loading the Light weighted CNN\nmodel = model(input_shape=(240,240,1))\n# model.summary()","d58359e8":"# Computing Dice_Coefficient\ndef dice_coef(y_true, y_pred, smooth=1.0):\n    \n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    \n    return (2. * intersection + smooth) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\n# Computing Precision\ndef precision(y_true, y_pred):\n    \n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives \/ (predicted_positives + K.epsilon())\n    \n    return precision\n\n# Computing Sensitivity\ndef sensitivity(y_true, y_pred):\n    \n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    \n    return true_positives \/ (possible_positives + K.epsilon())\n\n# Computing Specificity\ndef specificity(y_true, y_pred):\n    \n    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n    \n    return true_negatives \/ (possible_negatives + K.epsilon())","86fc0fe9":"# Compiling the model\nAdam = optimizers.Adam(lr=0.001)\nmodel.compile(optimizer=Adam, loss='binary_crossentropy', metrics=['accuracy', dice_coef, precision, sensitivity, specificity])","1f790dfe":"# Fitting the model over the data\n\nhistory = model.fit(X_train, Y_train, batch_size=32, epochs=40, validation_split=0.20,verbose=1,initial_epoch=0)","7da99ee8":"# Evaluating the model on the training and testing data\nmodel.evaluate(x=X_train, y=Y_train, batch_size=32, verbose=1, sample_weight=None, steps=None)\nmodel.evaluate(x=X_test, y=Y_test, batch_size=32, verbose=1, sample_weight=None, steps=None)","397d8b84":"# Accuracy vs Epoch\ndef Accuracy_Graph(history):\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    #plt.title('Model accuracy')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='lower right')\n    plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n                        wspace=0.35)\n    plt.show()\n    \n# Dice Similarity Coefficient vs Epoch\ndef Dice_coefficient_Graph(history):\n\n    plt.plot(history.history['dice_coef'])\n    plt.plot(history.history['val_dice_coef'])\n    #plt.title('Dice_Coefficient')\n    plt.ylabel('Dice_Coefficient')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='upper left')\n    plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n                        wspace=0.35)\n    plt.show()\n    \n# Precision vs Epoch\ndef Precision_Graph(history):\n\n    plt.plot(history.history['precision'])\n    plt.plot(history.history['val_precision'])\n    #plt.title('Dice_Coefficient')\n    plt.ylabel('Precision')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='lower left')\n    plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n                        wspace=0.35)\n    plt.show()\n\n# Loss vs Epoch\ndef Loss_Graph(history):\n\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    #plt.title('Model loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='upper right')\n    plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n                        wspace=0.35)\n    plt.show()","bdab9241":"# Plotting the Graphs of Accuracy, Dice_coefficient, Loss at each epoch on Training and Testing data\nAccuracy_Graph(history)\nDice_coefficient_Graph(history)\nLoss_Graph(history)","31335759":"model.save('.\/BraTs2020_swt_db1_l1.h5')","fe5face3":"model.load_weights('..\/input\/swt-db1-weights\/BraTs2020_swt_haar_l1.h5')","8b61efb7":"X_train=X_test=Y_train=Y_test=0","055897ca":"fig = plt.figure(figsize=(5,5))\nimmmg = TR[210,:,:]\nimgplot = plt.imshow(immmg)\nplt.show()","35c3cb30":"from pywt import swt2\nfor i in range(len(TR)):\n    c = swt2(data=TR[i],wavelet='db1',level=1)\n    TR[i] = c[0][0]\n    c=0","662d4ee7":"pref_tumor = model.predict(TR)","40f67b3e":"a=94\nplt.figure(figsize=(15,10))\n\nplt.subplot(121)\nplt.title('Sample 1')\nplt.axis('off')\nplt.imshow(np.squeeze(TR[a,:,:]),cmap='gray')\nplt.imshow(np.squeeze(pref_tumor[a,:,:]),alpha=0.3,cmap='Reds')\n\nplt.subplot(122)\nplt.title('Original MRI')\nplt.axis('off')\nplt.imshow(np.squeeze(TR[a,:,:]),cmap='gray')","111a6a66":"plt.figure(figsize=(10,7))\nplt.title('Original MRI with tumor highlighted')\nplt.axis('off')\nplt.imshow(np.squeeze(TR[a,:,:]),cmap='gray')\nplt.imshow(np.squeeze(TRL[a,:,:]),alpha=0.3,cmap='Reds')\nplt.show()","3194848d":"## U-Net Model Implementation"}}