{"cell_type":{"64b1372c":"code","a4ad12ca":"code","964e9140":"code","45ea713e":"code","ddc4eceb":"code","7df3666b":"code","858471cf":"code","10a8bffb":"code","aa36851b":"code","45fd02ee":"code","6931ff19":"code","6609c571":"code","57265d7d":"code","8fddf564":"code","f341fb9b":"code","1fcd15de":"code","5769bf23":"code","932b1c92":"markdown"},"source":{"64b1372c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","a4ad12ca":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nimport math\nimport time\n\nfrom keras.preprocessing import image\nfrom keras.applications.imagenet_utils import preprocess_input\nfrom keras.layers import Input, Add, Multiply, Average, Maximum, Dense, Activation, ZeroPadding2D, BatchNormalization, Dropout, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\nfrom keras.models import Model, load_model\nfrom keras.initializers import glorot_uniform, he_uniform\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.utils import to_categorical, layer_utils, plot_model\nfrom keras.utils.data_utils import get_file\nfrom keras.utils.vis_utils import model_to_dot","964e9140":"# Get train and test data\ndata_train = pd.read_csv('..\/input\/fashion-mnist_train.csv')\ndata_test = pd.read_csv('..\/input\/fashion-mnist_test.csv')","45ea713e":"# Preprocess\nCLASSES = [\"T-shirt\/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\nIMG_SHAPE = (28, 28, 1)   # rows, cols, channels","ddc4eceb":"# Train dataset\nX_train = np.array(data_train.iloc[:, 1:])\nX_train = X_train.reshape(X_train.shape[0], IMG_SHAPE[0], IMG_SHAPE[1], IMG_SHAPE[2])\nX_train = X_train.astype('float32')  # string to float\nX_train \/= 255\nY_train = to_categorical(np.array(data_train.iloc[:, 0]))  # CLASSES to one_hot","7df3666b":"# Test dataset\nX_test_orig = np.array(data_test.iloc[:, 1:])\nX_test = X_test_orig.reshape(X_test_orig.shape[0], IMG_SHAPE[0], IMG_SHAPE[1], IMG_SHAPE[2])\nX_test = X_test.astype('float32')\nX_test \/= 255\nY_test = to_categorical(np.array(data_test.iloc[:, 0]))","858471cf":"def plot_image(image, label):\n    if not np.isscalar(label):\n        label = np.argmax(label)\n        \n    # plt.figure(figsize=(10,5))\n    plt.imshow(np.squeeze(image.reshape(IMG_SHAPE[0], IMG_SHAPE[1], IMG_SHAPE[2])), interpolation='nearest')\n    plt.title(CLASSES[int(label)])\n\n\n\nimage_id = 0\nplot_image(X_test[image_id, :], Y_test[image_id])","10a8bffb":"def MyModel(input_shape, num_classes=2):\n    # Define the input placeholder as a tensor with shape input_shape. Think of this as your input image!\n    X_input = Input(input_shape)\n\n    # Zero-Padding: pads the border of X_input with zeroes\n    X = ZeroPadding2D((3, 3))(X_input)\n\n    # CONV -> BN -> RELU Block applied to X\n    X = Conv2D(32, (3, 3), strides = (1, 1), padding='same', kernel_initializer=glorot_uniform(), name = 'Conv1')(X)\n    X = BatchNormalization(axis = 3, name = 'BN1')(X)\n    X = Activation('relu')(X)\n    X = Dropout(0.5)(X)\n    \n    X = Conv2D(64, (3, 3), strides = (1, 1), padding='same', kernel_initializer=glorot_uniform(), name = 'Conv2')(X)\n    X = BatchNormalization(axis = 3, name = 'BN2')(X)\n    X = Activation('relu')(X)\n    X = Dropout(0.5)(X)\n    \n    X = Conv2D(128, (3, 3), strides = (1, 1), padding='same', kernel_initializer=glorot_uniform(), name = 'Conv3')(X)\n    X = BatchNormalization(axis = 3, name = 'BN3')(X)\n    X = Activation('relu')(X)\n    X = Dropout(0.5)(X)\n    \n    # MAXPOOL\n    X = MaxPooling2D((2, 2), name='MP')(X)\n\n    # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n    X = Flatten()(X)\n    \n    # FULLY CONNECTED\n    X = Dense(128, activation='relu', name='FC1')(X)\n    \n    if num_classes > 2:\n        X = Dense(num_classes, activation='softmax', name='FC2')(X)\n    else:\n        X = Dense(1, activation='sigmoid', name='FC2')(X)\n\n    # Create model. This creates your Keras model instance, you'll use this instance to train\/test the model.\n    model = Model(inputs = X_input, outputs = X, name='CNN')\n\n    return model","aa36851b":"model = MyModel(IMG_SHAPE, num_classes=len(CLASSES))\nmodel.summary()","45fd02ee":"model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0003, decay=1e-6, beta_1=0.9, beta_2=0.999), metrics=['accuracy'])","6931ff19":"monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=10, verbose=1, mode='auto')\ncheckpoint = ModelCheckpoint(filepath='best_weights.hdf5', verbose=1, save_best_only=True)   # Save the best model\nhist = model.fit(X_train, Y_train, batch_size=128, callbacks=[monitor, checkpoint], epochs=30, shuffle=True, verbose=1, validation_split=0.01)","6609c571":"def plot_train_history(history):\n    # plot the cost and accuracy \n    loss_list = history['loss']\n    val_loss_list = history['val_loss']\n    accuracy_list = history['acc']\n    val_accuracy_list = history['val_acc']\n    # epochs = range(len(loss_list))\n\n    # plot the cost\n    plt.plot(loss_list, 'b', label='Training cost')\n    plt.plot(val_loss_list, 'r', label='Validation cost')\n    plt.ylabel('cost')\n    plt.xlabel('iterations')\n    plt.title('Training and validation cost')\n    plt.legend()\n    \n    plt.figure()\n    \n    # plot the accuracy\n    plt.plot(accuracy_list, 'b', label='Training accuracy')\n    plt.plot(val_accuracy_list, 'r', label='Validation accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('iterations')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n\n\n\nplot_train_history(hist.history)","57265d7d":"score = model.evaluate(X_test, Y_test)\n\nprint (\"Test Loss = \" + str(score[0]))\nprint (\"Test Accuracy = \" + str(score[1]))","8fddf564":"Y_test_pred = model.predict(X_test, verbose=2)","f341fb9b":"from sklearn.metrics import accuracy_score, mean_squared_error, confusion_matrix, precision_score, recall_score, classification_report\n\ndef analyze(Y, Y_pred, classes, activation=\"softmax\"):\n    if activation == \"sigmoid\":\n        Y_cls = Y\n        Y_pred_cls = (Y_pred > 0.5).astype(float)\n    elif activation == \"softmax\":\n        Y_cls = np.argmax(Y, axis=1)\n        Y_pred_cls = np.argmax(Y_pred, axis=1)\n    \n    \n    accuracy = accuracy_score(Y_cls, Y_pred_cls)\n    print(\"Accuracy score: {}\\n\".format(accuracy))\n    \n    \n    rmse = np.sqrt(mean_squared_error(Y, Y_pred))\n    print(\"RMSE score: {}\\n\".format(rmse))\n\n    \n    # plot Confusion Matrix\n    print(\"Confusion Matrix:\")\n    cm = confusion_matrix(Y_cls, Y_pred_cls)\n    print(cm)\n    # Plot the confusion matrix as an image.\n    plt.matshow(cm)\n    # Make various adjustments to the plot.\n    num_classes = len(classes)\n    plt.colorbar()\n    tick_marks = np.arange(num_classes)\n    plt.xticks(tick_marks, range(num_classes))\n    plt.yticks(tick_marks, range(num_classes))\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    \n    \n    # plot Classification Report\n    print(\"Classification Report:\")\n    print(classification_report(Y_cls, Y_pred_cls, target_names=classes))\n\n\n\nanalyze(Y_test, Y_test_pred, CLASSES, \"softmax\")","1fcd15de":"def plot_mislabeled(X, Y, Y_pred, classes, activation=\"softmax\", num_images = 0):\n    \"\"\"\n    Plots images where predictions and truth were different.\n    \n    X -- original image data - shape(m, img_rows*img_cols)\n    Y -- true labels - eg. [2,3,4,3,1,1]\n    Y_pred -- predictions - eg. [2,3,4,3,1,2]\n    \"\"\"\n    \n    num_col = 5\n    \n    if activation == \"sigmoid\":\n        Y_cls = Y\n        Y_pred_cls = (Y_pred > 0.5).astype(float)\n    elif activation == \"softmax\":\n        Y_cls = np.argmax(Y, axis=1)\n        Y_pred_cls = np.argmax(Y_pred, axis=1)\n    \n    mislabeled_indices = np.where(Y_cls != Y_pred_cls)[0]\n    \n    if num_images < 1:\n        num_images = len(mislabeled_indices)\n    \n    fig, axes = plt.subplots(math.ceil(num_images\/num_col), num_col, figsize=(25,20))\n\n    for i, index in enumerate(mislabeled_indices[:num_images]):\n#         plt.subplot(2, num_images, i + 1)\n#         plt.imshow(X[index, :].reshape(IMG_SHAPE[0], IMG_SHAPE[1], IMG_SHAPE[2]), interpolation='nearest')\n#         plt.axis('off')\n#         plt.title(\"Prediction: \" + classes[p[index]] + \" \\n Class: \" + classes[int(y[index])])\n        row, col = i\/\/num_col, i%num_col\n        img = np.squeeze(X[index, :].reshape(IMG_SHAPE[0], IMG_SHAPE[1], IMG_SHAPE[2]))\n\n        axes[row, col].imshow(img, interpolation='nearest')\n        axes[row, col].axis('off')\n        axes[row, col].set_title(\"Id: {}\\nPrediction: {} - {}\\nClass: {}\".format(index, classes[int(Y_pred_cls[index])], np.amax(Y_pred[index]), classes[int(Y_cls[index])]))\n\n\n\nplot_mislabeled(X_test, Y_test, Y_test_pred, CLASSES, \"softmax\", 20)","5769bf23":"def plot_conv_layers(image, model):\n    layer_names = [layer.name for layer in model.layers]\n    layer_outputs = [layer.output for layer in model.layers]\n    activation_model = Model(inputs=model.input, outputs=layer_outputs)\n    activations = activation_model.predict(np.expand_dims(image, axis=0))\n\n    images_per_row = 16\n    \n    for layer_name, layer_activation in zip(layer_names, activations):\n        if layer_name.startswith('Conv'):\n            _, height, width, num_filters = layer_activation.shape   # image height and width, and size of channel\n            n_rows = num_filters \/\/ images_per_row\n            display_grid = np.zeros((n_rows * height, images_per_row * width))\n\n            for row in range(n_rows):\n                for col in range(images_per_row):\n                    channel_image = layer_activation[0, :, :, row * images_per_row + col]\n                    channel_image -= channel_image.mean()\n                    channel_image \/= channel_image.std()\n                    channel_image *= 64\n                    channel_image += 128\n                    channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n\n                    display_grid[row * height : (row + 1) * height, col * width : (col + 1) * width] = channel_image\n\n            plt.figure(figsize=(images_per_row *2, n_rows *2))\n            plt.title(layer_name)\n            plt.grid(False)\n            plt.axis('off')\n#             plt.imshow(display_grid, aspect='auto', interpolation='nearest', cmap='binary')\n            plt.imshow(display_grid, aspect='auto', interpolation='nearest', cmap='viridis')\n\n\n        \nimage_id = 0\nplot_image(X_test[image_id], Y_test[image_id])\nplot_conv_layers(X_test[image_id], model)","932b1c92":"**Analyze**"}}