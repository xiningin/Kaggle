{"cell_type":{"0ee32fd5":"code","1893cacd":"code","a4640b79":"code","60746872":"code","4eaccae0":"code","db8d5ecd":"code","d5ccd209":"code","9d7f219b":"code","c69295ba":"code","061cd05b":"code","0a0c645f":"code","56f0ebf6":"code","dfbd88ce":"code","64dd62a7":"code","9961a3d4":"code","a301bec0":"code","9cc7de9a":"code","01d70b84":"code","6877a3fb":"code","cbde0bc4":"code","8121b254":"code","854320f2":"code","e75c1444":"code","ec193825":"code","416377e4":"code","72a4f918":"code","81b97bae":"code","e4dfb5cd":"code","b04a64b6":"code","3b60dbe0":"code","1a8cbb2f":"code","a830ba08":"code","2c6e529e":"code","95003a2b":"code","32667d59":"code","31f12e51":"code","2a2009d7":"code","79ee5eb2":"code","13a04170":"code","12fc7cfc":"code","27659f7f":"code","42e16de6":"code","d9153dae":"code","b76db8f4":"code","138dbe8b":"code","da3ccb21":"code","3675d9a5":"code","a50fe818":"code","89861bea":"code","fb8e8f04":"markdown","3e5eb708":"markdown","4da00056":"markdown","aa5f3feb":"markdown","c3535857":"markdown","2779651d":"markdown","276abc83":"markdown","6b642b65":"markdown","79b12384":"markdown","44cfee13":"markdown","e77841ba":"markdown","0f9f9c32":"markdown","2bdfa2f5":"markdown","a3d3c801":"markdown"},"source":{"0ee32fd5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1893cacd":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","a4640b79":"yelp_df = pd.read_csv('..\/input\/yelp-reviews\/yelp.csv')","60746872":"yelp_df.head()","4eaccae0":"yelp_df.tail()","db8d5ecd":"yelp_df.describe()","d5ccd209":"yelp_df.info()","9d7f219b":"yelp_df['text'][0]","c69295ba":"yelp_df['text'][9999]","061cd05b":"yelp_df['length']=yelp_df['text'].apply(len)","0a0c645f":"yelp_df","56f0ebf6":"plt.xlabel('length of the review')\nyelp_df['length'].plot(bins=100,kind='hist')","dfbd88ce":"yelp_df.length.describe()","64dd62a7":"yelp_df[yelp_df['length']== 4997.000000]['text'][55]","9961a3d4":"yelp_df[yelp_df['length']== 1]['text'].iloc[0]","a301bec0":"sns.countplot(y='stars',data=yelp_df)","9cc7de9a":"g = sns.FacetGrid(data=yelp_df,col='stars',col_wrap=3)\ng.map(plt.hist,'length',bins=20,color='r')","01d70b84":"yelp_df_1 = yelp_df[yelp_df['stars']==1]","6877a3fb":"yelp_df_5 = yelp_df[yelp_df['stars']==5]","cbde0bc4":"yelp_df_1","8121b254":"yelp_df_5","854320f2":"yelp_df_1_5 = pd.concat([yelp_df_5,yelp_df_1])","e75c1444":"yelp_df_1_5","ec193825":"print('1 star review percentage:',(len(yelp_df_1)\/len(yelp_df_1_5)*100))","416377e4":"print('5 star review percentage:',81.66911404796868)","72a4f918":"sns.countplot(yelp_df_1_5['stars'])","81b97bae":"import string\nstring.punctuation","e4dfb5cd":"from nltk.corpus import stopwords","b04a64b6":"stopwords.words('english')","3b60dbe0":"from sklearn.feature_extraction.text import CountVectorizer","1a8cbb2f":"def message_cleaning(message):\n    test_punc_removed = [char   for char in message if char not in string.punctuation]\n    test_punc_removed_joined = ''.join(test_punc_removed)\n    test_punc_removed_joined_clean = [word   for word in test_punc_removed_joined.split(' ') if word not in stopwords.words('english')]\n    return test_punc_removed_joined_clean","a830ba08":"vectorizer = CountVectorizer(analyzer=message_cleaning)\nyelp_vectorizer = vectorizer.fit_transform(yelp_df_1_5['text'])","2c6e529e":"print(vectorizer.get_feature_names())","95003a2b":"print(yelp_vectorizer.toarray())","32667d59":"yelp_vectorizer.shape","31f12e51":"from sklearn.naive_bayes import MultinomialNB","2a2009d7":"nb_classifier = MultinomialNB()","79ee5eb2":"label = yelp_df_1_5['stars'].values","13a04170":"label","12fc7cfc":"X = yelp_vectorizer\ny = label","27659f7f":"from sklearn.model_selection import train_test_split","42e16de6":" X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)","d9153dae":"nb_classifier.fit(X_train,y_train)","b76db8f4":"prediction = nb_classifier.predict(X_test)","138dbe8b":"prediction","da3ccb21":"from sklearn.metrics import classification_report,confusion_matrix,accuracy_score","3675d9a5":"sns.heatmap(confusion_matrix(y_test,prediction),annot=True)","a50fe818":"print(classification_report(y_test,prediction))","89861bea":"print(accuracy_score(y_test,prediction))","fb8e8f04":"The length of the reviews corresponding to the star rating doesn't differ in the length as such.","3e5eb708":"This heatmap shows the number of correctly and incorrectly identified labels.","4da00056":"So these are the stopwords we are looking to eliminate.","aa5f3feb":"This matrix shows the occurance of the unique words in each sentence.","c3535857":"Uphere contains all the unique words present in the yelp text.","2779651d":"# Data Visualisation","276abc83":"# Quite high accuracy!","6b642b65":"# Model Training","79b12384":"- In this kernal, Natural Language Processing (NLP) strategies will be used to analyze Yelp reviews data\n- Number of 'stars' indicate the business rating given by a customer, ranging from 1 to 5\n- 'Cool', 'Useful' and 'Funny' indicate the number of cool votes given by other Yelp Users. ","44cfee13":"![image.png](attachment:image.png)","e77841ba":" Importing the libraries that  Remove Punctuation and stopwords.","0f9f9c32":"This is the shortest review","2bdfa2f5":"We are adding a new feature for analysing the data more","a3d3c801":"This is the longest review."}}