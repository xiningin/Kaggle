{"cell_type":{"c2bc588c":"code","5dbffc13":"code","9b03d51a":"code","eccc34d6":"code","de32f166":"code","f0c125b0":"code","19e58a04":"code","d41a3c9e":"code","a4993ce1":"code","a38d0f25":"code","cf9eb86c":"code","0d9a2504":"code","81344890":"code","a4caaa47":"code","72f0ee29":"code","c0e65808":"code","d3763085":"code","db4f794c":"code","40a70ec8":"code","1f5943a7":"code","b921ebe6":"code","1d85869d":"code","1ca7b9f1":"code","562cba4e":"code","3e89ab1a":"markdown","27db6840":"markdown","d133338b":"markdown","ba286277":"markdown","15e36c00":"markdown","5a1551f5":"markdown"},"source":{"c2bc588c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5dbffc13":"#Read Dataset File\ndf = pd.read_csv('\/kaggle\/input\/gufhtugu-publications-dataset-challenge\/GP Orders - 5.csv' ,\n                encoding = \"utf-8\" , delimiter = ',')\n","9b03d51a":"#Get the information about the dataset\ndf.info()","eccc34d6":"#Get the Shape of dataset\nrows,columns = df.shape\nprint(f'(There are {rows} rows and {columns} columns in gufhtugu publication dataset)')","de32f166":"#View first 50 rows of dataset\ndf.head(50)","f0c125b0":"#view last 50 rows of dataset\ndf.tail(50)","19e58a04":"#Get the column names\ndf.columns","d41a3c9e":"#Rename Column names\ndf = df.rename(columns = {'Order Number' : 'Order_Number' , 'Order Status' : 'Order_Status' , 'Book Name' : 'Book_Name' , 'Order Date & Time' : 'Order_Date_Time' , 'City' : 'City_Order', 'Payment Method' : 'Payment_Method', 'Total items' : 'Items_Total', 'Total weight (grams)' : 'Total_weight(gm)'})\ndf.columns","a4993ce1":"#Review the first 5 rows\ndf.head()","a38d0f25":"#Check Null values\ndf.isnull().sum().sort_values(ascending = False)","cf9eb86c":"#Check Missing values in Payment_Method\ndf[df['Payment_Method'].isnull()]","0d9a2504":"#Check Missing Values in Book_Name\ndf[df['Book_Name'].isna()]","81344890":"#Check missing values in City_Order\ndf[df['City_Order'].isnull()]","a4caaa47":"#We drop these Missing Values from our dataset\ndf.dropna(inplace = True)","72f0ee29":"print(df.isnull().sum().sort_values(ascending = False))\nrows,columns = df.shape\nprint(f'There are {rows} rows and {columns} Columns after drop null values')","c0e65808":"#Make a new column Order_Books_Name by exploding the names of book\ndf = df.assign(Order_Books_Name=df.Book_Name.str.split(\"\/\")).explode(\"Book_Name\")\ndf.head(10)","d3763085":"#Find the total count of unique books and cities\nunique_count_books = df.Order_Books_Name.explode().value_counts()#Gives us total count of unique books\n\n#Find Top ten Books\ntop_ten_books = dict(unique_count_books[:10])\nprint(f'\\n \\n Top ten selling books are \\n \\n {top_ten_books}')\n\n#Best Selling Book\nbest_selling_book = dict(unique_count_books[0:1])\nprint(f'\\n \\n Best selling book is \\n \\n{best_selling_book}')\n\n#Visualize top ten books\nnames = top_ten_books.keys()\nquantity = top_ten_books.values()\nplt.figure()\nplt.bar(names,quantity,color = ['red', 'blue', 'purple', 'green', 'orange'])\nplt.xticks(rotation = 90)\nplt.title('Top Selling Books',fontsize=15)\nplt.show()","db4f794c":"#First we check Number of completed, returned and cancelled orders\norder_status = dict(df.value_counts('Order_Status'))\nfor key,value in order_status.items():\n    print(f'{key} orders are {value}')\n\n#Visualize completed, returned and cancelled orders\nstatus = order_status.keys()\nquantity = order_status.values()\nplt.figure(figsize = (20,10))\nplt.bar(status , quantity , color = ('Purple' , 'Green' , 'Red'))\nplt.grid()\nplt.xticks(fontsize = 25)\nplt.yticks(fontsize = 25)\nplt.title('Order Status Insights' , fontsize = 40)\nplt.xlabel('Status', fontsize = 30)\nplt.ylabel('Quantity' , fontsize = 30)\nplt.show()","40a70ec8":"#Find the Correlation of returned books with book name, city and payment method\nreturned_books = df[df['Order_Status'] == 'Returned']\nreturned_books[['Order_Status','Book_Name','City_Order','Payment_Method']]\n","1f5943a7":"#Retuned books correlation with payment method\nprint('The Payment Methods of Returned books are')\nreturned_books.Payment_Method.value_counts()\n","b921ebe6":"#Returned books correlation with book name\nprint(\"The books which returned are\")\nreturned_books.Book_Name.value_counts()","1d85869d":"#Returned books correlation with city\nprint('The cities from which books are returned')\nreturned_books.City_Order.value_counts()","1ca7b9f1":"#correlation of completed orders\ncompleted_orders = df[df['Order_Status'] == 'Completed']\ncompleted_orders[['Order_Status' , 'Book_Name' , 'City_Order' , 'Payment_Method']]\n","562cba4e":"#Correlation of completed orders and book\nprint('The books whose orders are completed are')\ncompleted_orders.Book_Name.value_counts()\n","3e89ab1a":"There are ten null values in Payment_Method, two null values in Book_Name and one null value in City_Order. Let's check it which are those values","27db6840":"# Separate book names for further processing and find the best selling book","d133338b":"After drop the missing values, recheck the dataset","ba286277":"# In Process","15e36c00":"# Order Status Insights","5a1551f5":"After dropping null values, we see that there is not any null values available and rows reduced from 19239 to 19226"}}