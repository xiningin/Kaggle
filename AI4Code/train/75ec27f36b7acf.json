{"cell_type":{"2b59b853":"code","76216824":"code","96846450":"code","3d6ef269":"code","f64a33e5":"code","b1fc950f":"code","b40034a7":"code","ae731fa6":"code","57724253":"code","e0d64757":"code","cac06b0c":"code","61e79a15":"code","bba0c00d":"code","461eaa4b":"code","143b40d2":"code","c8d111ca":"code","56984c09":"code","7c43bf8c":"code","d152fed3":"code","b3530f61":"code","b10c261f":"code","0892659c":"code","4e4bbcfa":"code","b0f2c3cb":"code","0dbcb1c6":"code","a2c6391c":"code","0f0728ff":"code","b45f295a":"code","2503c1fe":"code","a5bb988a":"code","4344397f":"code","53d4ea32":"code","8da0a297":"code","b0548639":"code","36182bf2":"code","019e21ca":"code","4f676f76":"code","6b738067":"code","dcbcd745":"code","1fdb722a":"code","6d278b10":"code","2aaea1cd":"code","dc2fc420":"code","cf3989a5":"code","091a8e69":"code","bde66cf6":"markdown"},"source":{"2b59b853":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","76216824":"directory = '..\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset\/'","96846450":"#Labels\nfilepath = os.listdir(directory)\nprint(filepath)","3d6ef269":"classes = ['Hourse Mackerel', 'Black Sea Sprat', 'Sea Bass', 'Red Mullet', 'Trout',\n             'Striped Red Mullet', 'Shrimp', 'Gilt-Head Bream', 'Red Sea Bream']","f64a33e5":"label = []\npath = []\nfor dir_name, _, filenames in os.walk(directory):\n    for filename in filenames:\n        if os.path.splitext(filename)[1]=='.png':\n            if dir_name.split()[-1] != 'GT':\n                label.append(os.path.split(dir_name)[1])\n                path.append(os.path.join(dir_name, filename))\ndata = pd.DataFrame(columns=['path','label'])\ndata['path'] = path\ndata['label'] = label","b1fc950f":"data.head()","b40034a7":"import seaborn as sns","ae731fa6":"data['label'] = data['label'].astype('category')","57724253":"import matplotlib.pyplot as plt","e0d64757":"data['label'].value_counts()","cac06b0c":"plt.figure(figsize=(20,8))\nsns.countplot(data=data, x='label')","61e79a15":"fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(15,8), constrained_layout=True)\nax = ax.flatten()\nidx=0\nfor i in data['label'].unique():\n    ax[idx].imshow(plt.imread(data[data['label']==i].iloc[0,0]))\n    ax[idx].set_title(i)\n    idx+=1","bba0c00d":"from sklearn.model_selection import train_test_split","461eaa4b":"train, test = train_test_split(data, test_size=0.2)","143b40d2":"print(train.shape)\nprint(test.shape)","c8d111ca":"import torch\nimport torch.nn as nn\nimport torchvision\nfrom PIL import Image\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nfrom torchvision.utils import make_grid\nfrom torchvision.models import vgg16","56984c09":"class ImageTransform():\n    def __init__(self, input_size):\n        self.data_transform = {\n            'train': transforms.Compose([\n                transforms.RandomResizedCrop(input_size),\n                transforms.RandomHorizontalFlip(),\n                transforms.ToTensor(),\n                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n            ]),\n            'test': transforms.Compose([\n                    transforms.Resize(input_size),\n                    transforms.CenterCrop(input_size),\n                    transforms.ToTensor(),\n                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n            ])\n        }\n        \n    def __call__(self, img, phase='train'):\n        return self.data_transform[phase](img)","7c43bf8c":"input_size = 224","d152fed3":"img_file_path = '..\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset\/Gilt-Head Bream\/Gilt-Head Bream\/00001.png'\nimg = Image.open(img_file_path)\nplt.axis('off')\nplt.imshow(img)\nplt.show()\n\ntransform = ImageTransform(input_size)\nimg_transformed = transform(img, phase='train')\n\n# (channel, height, width) -> (height, width, channel)\nimg_transformed = img_transformed.permute(1, 2, 0)\nplt.imshow(img_transformed)\nplt.axis('off')\nplt.show()","b3530f61":"idx_to_class = {i:j for i, j in enumerate(classes)}\nclass_to_idx = {value:key for key,value in idx_to_class.items()}","b10c261f":"print(idx_to_class.items())","0892659c":"print(class_to_idx)","4e4bbcfa":"# test\na = '..\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset\/Black Sea Sprat\/Black Sea Sprat GT'\nprint(a.split()[-1])\nif a.split()[-1] != 'GT':\n    label = os.path.split(a)[1]\n    print(label)","b0f2c3cb":"train.iloc[1,0]","0dbcb1c6":"class MyDataset(Dataset):\n    def __init__(self, img_path, transform=None, phase='train'):\n        self.img_path = img_path\n        self.transform = transform\n        self.phase = phase\n        \n    def __len__(self):\n        return len(self.img_path)\n    \n    def __getitem__(self, idx):\n        img_file_path = self.img_path.iloc[idx,0]\n        img = Image.open(img_file_path)\n        \n        img_transformed = self.transform(img, self.phase)\n        \n        label = self.img_path.iloc[idx,1]\n        label = class_to_idx[label]\n            \n        return img_transformed, label","a2c6391c":"train_ds = MyDataset(train, transform=ImageTransform(input_size), phase='train')\ntest_ds = MyDataset(test, transform=ImageTransform(input_size), phase='test')","0f0728ff":"index = 0\nimg, label = train_ds.__getitem__(index)\nprint(img.size())\nprint(label)","b45f295a":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","2503c1fe":"batch_size = 32\n\ntrain_dataloader = DataLoader(train_ds, batch_size,shuffle=True)\ntest_dataloader = DataLoader(test_ds, batch_size, shuffle=False)\n\ndataloader_dict = {\"train\": train_dataloader, 'test': test_dataloader}","a5bb988a":"batch_iteration = iter(dataloader_dict['train'])\ninputs, labels = next(batch_iteration)","4344397f":"print(inputs.size())\nprint(labels)","53d4ea32":"for img, label in train_dataloader:\n    fig, ax = plt.subplots(figsize=(10,8))\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.imshow(make_grid(img, 6).permute(1,2,0))\n    break\n    ","8da0a297":"use_pretrained = True\nmodel = vgg16(pretrained=use_pretrained)\nprint(model)","b0548639":"model.classifier[6] = nn.Linear(in_features=4096, out_features=9)\nprint(model)\nmodel = model.to(device)","36182bf2":"def params_to_update(model):\n    params_to_update_1 = []\n    params_to_update_2 = []\n    params_to_update_3 = []\n\n    update_param_name_1 = [\"features\"]\n    update_param_name_2 = [\"classifier.0.weight\", \"classifier.0.bias\", \"classifier.3.weight\", \"classifier.3.bias\"]\n    update_param_name_3 = [\"classifier.6.weight\", \"classifier.6.bias\"]\n\n    for name, param in model.named_parameters():\n        if name in update_param_name_1:\n            param.requires_grad = True\n            params_to_update_1.append(param)\n        elif name in update_param_name_2:\n            param.requires_grad = True\n            params_to_update_2.append(param)\n        elif name in update_param_name_3:\n            param.requires_grad = True\n            params_to_update_3.append(param)\n        \n        else:\n            param.requires_grad = False\n    return params_to_update_1, params_to_update_2, params_to_update_3","019e21ca":"def load_model(model, model_path):\n    load_weights = torch.load(model_path,  map_location={\"cuda:0\": \"cpu\"})\n    model.load_state_dict(load_weights)\n\n    \n    return model","4f676f76":"from tqdm import tqdm","6b738067":"def train_model(model, dataloader_dict, criterion, optimizer, device):\n    model = model.train()\n    \n    epoch_loss = 0.0\n    correct_prediction = 0\n    global epoch_accuracy\n    for images, labels in tqdm(dataloader_dict):\n        \n        images = images.to(device)\n        labels = labels.to(device)\n        \n             \n        # Forward\n        outputs = model(images)\n        # Calculate loss\n        loss = criterion(outputs, labels)\n        _, preds = torch.max(outputs, 1)\n        \n        epoch_loss += loss.item()*images.size(0)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        correct_prediction += torch.sum(preds == labels.data)\n        \n        epoch_loss = epoch_loss \/ len(dataloader_dict.dataset)\n        epoch_accuracy = correct_prediction.double() \/ len(dataloader_dict.dataset)\n        \n    return epoch_accuracy, epoch_loss","dcbcd745":"def evaluate_epoch(model, dataloader_dict, criterion, optimizer, device):\n    model.eval()\n    \n    epoch_loss = 0.0\n    correct_prediction = 0\n    global epoch_accuracy\n    with torch.no_grad():\n        for images, labels in tqdm(dataloader_dict):\n            # Load images, labels to device\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(images)\n            \n            loss = criterion(outputs, labels)\n            \n            _, preds = torch.max(outputs, 1)\n            \n            epoch_loss += loss.item()*images.size(0)\n            correct_prediction += torch.sum(preds == labels.data)\n            \n            epoch_loss = epoch_loss \/ len(dataloader_dict.dataset)\n            epoch_accuracy = correct_prediction.double() \/ len(dataloader_dict.dataset)\n            \n        return epoch_accuracy, epoch_loss","1fdb722a":"from collections import defaultdict","6d278b10":"criterion = nn.CrossEntropyLoss()\n# optimizer\nparams1, params2, params3 = params_to_update(model)\noptimizer = optim.SGD([\n        {'params': params1, 'lr': 1e-4}, \n        {'params': params2, 'lr': 5e-4},\n        {'params': params3, 'lr': 1e-3}, \n    ], momentum=0.9)","2aaea1cd":"%%time\nhistory = defaultdict(list)\nbest_val_acc = 0.0\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nEPOCHS = 3\n\nfor epoch in range(EPOCHS):\n    print(f'\\nEpoch: [{epoch+1}\/{EPOCHS}]')\n    print('-'*30)\n    \n    train_acc, train_loss = train_model(model, dataloader_dict['train'], criterion, optimizer,device)\n    val_acc, val_loss = evaluate_epoch(model, dataloader_dict['test'], criterion, optimizer, device)\n    \n    print('Train Loss: {:.4f}\\t Train Acc: {:.4f}'.format(train_loss, train_acc))\n    print('Val Loss: {:.4f}\\t Val Acc: {:.4f}'.format(val_loss, val_acc))\n    \n    history['train_acc'].append(train_acc)\n    history['train_loss'].append(train_loss)\n    history['val_acc'].append(val_acc)\n    history['val_loss'].append(val_loss)\n    \n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        torch.save(model.state_dict(), 'best_restnet.pth')\n        ","dc2fc420":"# Plot results\nplt.title('Loss')\nplt.plot(np.arange(1,4), history['train_loss'], color='blue', label='Train loss')\nplt.plot(np.arange(1,4), history['val_loss'], color='red', label='Test loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nplt.title('Accuracy')\nplt.plot(np.arange(1,4), history['train_acc'], 'bo--', label='Train Acc')\nplt.plot(np.arange(1,4), history['val_acc'], color='red', label='Test Acc')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","cf3989a5":"class Predictor():\n    def __init__(self, classes):\n        self.class_index = classes\n        \n    def predict_max(self, output):\n        max_id = np.argmax(output.detach().numpy())\n        predicted_label = self.class_index[max_id]\n        return predicted_label\n    \npredictor = Predictor(classes)\n\ndef predict(img):\n    use_pretrained = True\n    model = vgg16(pretrained=use_pretrained)\n    model.classifier[6] = nn.Linear(in_features=4096, out_features=9, bias=True)\n    model.eval()\n    \n    \n    model = load_model(model, '.\/best_restnet.pth')\n    \n    #prepare inputdata\n    '''\n    img = transforms.Compose([\n        transforms.Resize(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n    '''\n    transform = ImageTransform(input_size)\n    img = transform(img, phase=\"test\")\n    img = img.unsqueeze(0)\n    \n    output = model(img)\n    response = predictor.predict_max(output)\n    \n    return response","091a8e69":"test_img = Image.open('..\/input\/a-large-scale-fish-dataset\/NA_Fish_Dataset\/Horse Mackerel\/00003.png').convert('RGB')\nplt.imshow(test_img)\nplt.show()\nprint('Predicted image: ' + predict(test_img))","bde66cf6":"**Model**"}}