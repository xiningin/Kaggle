{"cell_type":{"2d9618c0":"code","a2444ec4":"code","14fb8619":"code","27e25b14":"code","ab84cdfe":"code","cbf1d572":"code","0542f6c0":"code","5dd732b2":"code","71ccac54":"code","f7afc93f":"code","de847d8a":"code","487449f7":"code","7fb2250f":"code","a6cabae6":"code","41079c26":"code","136ede19":"code","a454a520":"code","519f211c":"code","e995629f":"code","619a6a46":"code","030c4fb4":"code","ddb5f12b":"code","86012c39":"code","027bd12c":"code","87f952d6":"code","c296e279":"code","a11fced0":"markdown","a56cd9af":"markdown","f658a552":"markdown","746deba0":"markdown","017d9a41":"markdown","f178b96c":"markdown","3ec145be":"markdown","b609825b":"markdown","712327c2":"markdown","d76f7cfe":"markdown","85872e50":"markdown","3e2a2581":"markdown","5b8a812c":"markdown","7feff609":"markdown","ac18a36e":"markdown","d4983547":"markdown","1e0a8e84":"markdown","a64fa5d5":"markdown","4b12dd1f":"markdown","768bfc6b":"markdown"},"source":{"2d9618c0":"import pandas as pd\npd.set_option('display.float_format', lambda x: '%.3f' % x)\npath_dataset = '..\/input\/datos-properati-limpios-model\/datos_properati_limpios_model.csv'\ndf = pd.read_csv(path_dataset)\ndf.tail()","a2444ec4":"# Hac\u00e9 la separaci\u00f3n en esta celda\nX = df.drop(['price_aprox_usd'], axis=1)\ny = df['price_aprox_usd']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)","14fb8619":"X_train.shape, \\\ny_train.shape, \\\nX_test.shape, \\\ny_test.shape\n\n#De esta manera, simplemente corroboramos que la cantidad de Train y de Test tienen la misma geometria","27e25b14":"# Esto es lo que hace\nimport numpy as np\nnp.random.seed(123)\nfrom sklearn.model_selection import train_test_split\nX = df.drop(['price_aprox_usd'], axis=1)\ny = df['price_aprox_usd']\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42)\n\nprint(X_train.shape[0], X_test.shape[0])","ab84cdfe":"# Cre\u00e1 en esta celda la variable param_grid\nimport numpy as np\n\nvalues= [1,2,3,4,5]\n\nparam_grid = [\n    {'max_depth': values, 'max_features': values},\n]","cbf1d572":"# Importa y crea un GridSearchCV en esta celda\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeRegressor\n\ntree_reg = DecisionTreeRegressor()\n\n\ngrid_search = GridSearchCV(tree_reg, param_grid, cv=5,\n                           scoring='neg_mean_squared_error', \n                           return_train_score=True)\n\n","0542f6c0":"# Hace el fit de grid search en esta celda\n\ngrid_search.fit(X_train, y_train)\n","5dd732b2":"grid_search.scorer_","71ccac54":"# Mostr\u00e1 los grid_scores en esta celda\nscore = grid_search.cv_results_['mean_train_score']\nscore","f7afc93f":"# Mostr\u00e1s los resultados en esta celda\ngrid_search.best_score_\n","de847d8a":"grid_search.best_params_","487449f7":"def nmsq2rmse(score):\n    return np.round(np.sqrt(-score), 2)\nnmsq2rmse(score)","7fb2250f":"nmsq2rmse(score).mean()","a6cabae6":"#asignamos los distintos hiperparametros al objeto param_grid, estos seran utilizados luego en el grid_search\n\nmin_samples_split_hiperparams = [2, 10, 20]\nmax_depth_hiperparams = [None, 2, 5, 10, 15]\nmin_samples_leaf_hiperparams = [1, 5, 10, 15]\nmax_leaf_nodes_hiperparams = [None, 5, 10, 20]\n\nparam_grid = [\n    {'min_samples_split': min_samples_split_hiperparams, \n     'max_depth': max_depth_hiperparams ,\n     'min_samples_leaf': min_samples_leaf_hiperparams,\n      'max_leaf_nodes':max_leaf_nodes_hiperparams },\n]","41079c26":"#Asignamos los hiperparametros en grid_search con 5 Folds para el Cross Validation, asignamos el tipo de score y le pedimos que devuelva sus resultados\ngrid_search = GridSearchCV(tree_reg, param_grid, cv=5,\n                           scoring='neg_mean_squared_error', \n                           return_train_score=True)","136ede19":"#Fiteamos para asi entrenar\ngrid_search.fit(X_train, y_train)","a454a520":"#Obtenemos los mejores Hiperparametros para el mejor Score\ngrid_search.best_params_","519f211c":"score = grid_search.cv_results_['mean_train_score']\ngrid_search.best_score_","e995629f":"def nmsq2rmse(score):\n    return np.round(np.sqrt(-score), 2)\nnmsq2rmse(score)","619a6a46":"#Caluclamos la media del RMSE para asi comparar con el entrenamiento de mas arriba ... mejoro sustancialmente, bajando el error.\nnmsq2rmse(score).mean()","030c4fb4":"optimised_decision_tree = grid_search.best_estimator_","ddb5f12b":"from sklearn.metrics import mean_squared_error\ny_opt_pred = optimised_decision_tree.predict(X_test)\nrmse = np.sqrt(mean_squared_error(y_test, y_opt_pred))\nnp.round(rmse)","86012c39":"val_real = pd.Series(y_test.values)\nval_pred = pd.Series(y_opt_pred)","027bd12c":"predicciones = pd.concat([val_real.rename('Valor real'),val_pred.rename('Valor Pred') ,abs(val_real-val_pred).rename('Dif(+\/-)')] ,  axis=1)","87f952d6":"predicciones.head(10)","c296e279":"results = pd.DataFrame(grid_search.cv_results_, columns=['rank_test_score','params','mean_test_score','std_test_score','mean_train_score','std_train_score'])\nresults.sort_values(by=['rank_test_score'],inplace=True)\nresults.head()","a11fced0":"Mostr\u00e1 los grid_scores obtenidos durante el grid_search\n\nEl gridsearch.grid_scores no est\u00e1 disponible desde la versi\u00f3n 0.20 de sklearn. Sin embargo se podr\u00eda hacer lo siguiente para tener una salida similar al grid_scores:","a56cd9af":"**Cre\u00e1** una variable `param_grid` con valores del 1 al 5 para los atributos `max_depth` y `max_features`. ","f658a552":"__Evaluemos en testing el desempe\u00f1o de este modelo.__\n\nComo venimos trabajando, el resultado en testing ser\u00e1 la medici\u00f3n que usaremos como benchmark para comparar este modelos con otros en el futuro, puesto que no estuvo en contacto con el dataset de test para la calibraci\u00f3n.","746deba0":"\u00a1Bienvenidos al cuarto (mini)proyecto de la carrera de Data Science de Acamica! \n\nEn este proyecto vamos a seguir trabajando (por \u00faltima vez) con el dataset de propiedades en venta publicadas en el portal [Properati](www.properati.com.ar). El objetivo en este caso es optimizar los par\u00e1metros de los algoritmos que usamos en el proyecto pasado.\n\nEl dataset es el mismo del proyecto 3. Recordemos que las columnas que se agregan son:\n\n* `barrios_match`: si coincide el barrio publicado con el geogr\u00e1fico vale 1, si no 0.\n\n* `PH`, `apartment`, `house`: variables binarias que indican el tipo de propiedad.\n\n* dummies de barrios: variables binarias con 1 o 0 seg\u00fan el barrio.\n\nLa m\u00e9trica que vamos a usar para medir es RMSE (ra\u00edz del error cuadr\u00e9atico medio), cuya f\u00f3rmula es:\n\n$$RMSE = \\sqrt{\\frac{\\sum_{t=1}^n (\\hat y_t - y_t)^2}{n}}$$","017d9a41":"## Scikit-learn - Entrenamiento","f178b96c":"De esta manera, el valor con mejor resultado (dado el espacio de b\u00fasqueda definido) es `max_depth` 3 y `max_features` 3.","3ec145be":"En primer lugar veamos como hacer cross validation. Para eso necesitamos definir la cantidad de folds, en este caso vamos a usar 5.\n\nGridSearchCV nos permite testear a trav\u00e9s de un espacio de b\u00fasqueda de par\u00e1metros la mejor combinaci\u00f3n posible dado un estimador.\n\nPor ejemplo, en este caso probamos la profundidad m\u00e1xima y la m\u00e1xima cantidad de features para hacer los split. Ambos entre 1 y 5.\nRecordemos que para hacer la optimizaci\u00f3n scikit-learn usa la m\u00e9trica `neg_mean_squared_error` en lugar de `mean_squared_error`.","b609825b":"# MiniProyecto 4: Optimizaci\u00f3n de par\u00e1metros","712327c2":"Recordemos que `GridSearchCV` tiene como par\u00e1metro default `refit=True`. Esto significa que luego de hacer la corrida se ajusta el mejor modelo al conjunto de datos de entrada. De esta manera, se puede predecir directamente usando `best_estimator_`.","d76f7cfe":"Para repasar los par\u00e1metros de \u00e1rboles de decisi\u00f3n en Scikit-learn: \n\nhttp:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.tree.DecisionTreeRegressor.html","85872e50":"**Mostr\u00e1** el mejor score y los mejores par\u00e1metros encontrados por `grid_search`","3e2a2581":"Revisemos los resultados. Recordemos que no est\u00e1n expresados en RMSE.","5b8a812c":"__Encontrar el mejor modelo para el espacio de b\u00fasqueda dado__\n\n* `\"min_samples_split\": [2, 10, 20]`\n* `\"max_depth\": [None, 2, 5, 10, 15]`\n* `\"min_samples_leaf\": [1, 5, 10, 15]`\n* `\"max_leaf_nodes\": [None, 5, 10, 20]`","7feff609":"A continuaci\u00f3n, realiz\u00e1 el `fit` del `grid_search` con el conjunto de entrenamiento","ac18a36e":"**Import\u00e1** `GridSearchCV` y `DecisionTreeRegressor`.\n\n**Cre\u00e1** una variable `grid_search` y asignale un `GridSearchCV` que recorra el `param_grid` que creaste con el algoritmos `DecisionTreeRegressor` y el un scoring de `neg_mean_squared_error`","d4983547":"**Separ\u00e1** el dataset en entrenamiento (80%) y test (20%) utilizando como target la columna `price_aprox_usd`","1e0a8e84":"Convertimos a RMSE.","a64fa5d5":"## Pandas - Levantamos el dataset","4b12dd1f":"Vemos los primeros 10 resultados de la predicci\u00f3n del valor de propiedades.","768bfc6b":"**Mostr\u00e1** los `grid_scores` obtenidos durante el `grid_search`"}}