{"cell_type":{"6d8934e2":"code","88a133ed":"code","a2d4ef25":"code","f561d2d5":"code","3b42969f":"code","b6c7ad81":"code","d9e7ca4b":"code","5208a8b2":"code","13b865ee":"code","a131828b":"code","8a1b20cf":"code","e0109961":"code","8de41647":"code","7c1c146e":"code","b9d93b30":"code","56c56580":"code","156f23f5":"code","de67af8d":"code","f5a10994":"code","c372a6d3":"code","c1dd9302":"code","5969c34f":"code","0fe7768b":"code","9048236a":"code","ec87b91b":"code","0f20be64":"code","93211f1c":"code","1d675889":"code","3ef2ba21":"code","2fba671c":"code","4fb71ce4":"code","48bb43f0":"code","6410234c":"code","5c8e8efa":"code","06790cb9":"code","2d091321":"code","1ccf6eea":"code","6099f747":"code","7de8b9d8":"code","f5d8f4bd":"code","b007fe55":"code","5688e6a9":"code","7fc82430":"code","2ef1d762":"code","9cfe62ed":"code","abfc30b5":"code","be18c304":"code","5c5acfdf":"code","3cc0652c":"code","0b5ef2b7":"code","f4b5d226":"code","4a4ec440":"code","c2a9a867":"code","7ad158bb":"code","fb9417f9":"code","67bb5f87":"code","66f8e4f5":"code","bdf8aafc":"code","fbd22de6":"code","bdf0bc6b":"code","9525400a":"markdown","449de16a":"markdown","cc1c4cbe":"markdown","32396a5a":"markdown","0c36c595":"markdown","f5e1fef4":"markdown","2cb0e4c5":"markdown","76a1dade":"markdown","bad20701":"markdown","1a300878":"markdown","7631167a":"markdown","55399cf2":"markdown","68e70e8d":"markdown","08249222":"markdown","7b02e273":"markdown","7ff086bf":"markdown","e96a5d94":"markdown","50da40e3":"markdown","359cdb04":"markdown","90042339":"markdown","81b8d0e6":"markdown","6ab2f811":"markdown","3fbd8155":"markdown","4d812d5c":"markdown","de2e94c6":"markdown","f308f0a6":"markdown","d29e3291":"markdown","3f4ca658":"markdown","fc4db20b":"markdown","7a8e2ec9":"markdown","0ee41c51":"markdown","be776c47":"markdown","b752a265":"markdown","cd7a4b99":"markdown","dc60b73f":"markdown","a03608df":"markdown","9acc9c34":"markdown","641e436a":"markdown","0d650cf4":"markdown","bce99573":"markdown","04093436":"markdown","143c42f4":"markdown","fd41f0b4":"markdown","773954fc":"markdown","1c21d991":"markdown","f9f044cc":"markdown","ded27b40":"markdown","84414b72":"markdown"},"source":{"6d8934e2":"import numpy as np \nimport pandas as pd \n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import KFold, cross_validate, GridSearchCV, train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\n\nimport statsmodels.formula.api as sm\nfrom sklearn.linear_model import Lasso\nfrom sklearn.tree import DecisionTreeRegressor\n\n\nimport warnings\n\n# seaborn and scipy versions are not aligned in the docker image\nwarnings.filterwarnings(\"ignore\", message=\"Using a non-tuple sequence for multidimensional indexing is deprecated\")","88a133ed":"df_train = pd.read_csv('..\/input\/train.csv')\ndf_test = pd.read_csv('..\/input\/test.csv')\n\ndf_train = df_train[df_train.GrLivArea < 4500].copy()  # the documentation says they are outliers\n\ncombine = [df_train, df_test]\ndf_train.name = 'Train'\ndf_test.name = 'Test'\n\nfor df in combine:\n    # LotFrontage\n    df.loc[df.LotFrontage.isnull(), 'LotFrontage'] = 0\n    # Alley\n    df.loc[df.Alley.isnull(), 'Alley'] = \"NoAlley\"\n    # MSSubClass\n    df['MSSubClass'] = df['MSSubClass'].astype(str)\n    # MissingBasement\n    fil = ((df.BsmtQual.isnull()) & (df.BsmtCond.isnull()) & (df.BsmtExposure.isnull()) &\n          (df.BsmtFinType1.isnull()) & (df.BsmtFinType2.isnull()))\n    fil1 = ((df.BsmtQual.notnull()) | (df.BsmtCond.notnull()) | (df.BsmtExposure.notnull()) |\n          (df.BsmtFinType1.notnull()) | (df.BsmtFinType2.notnull()))\n    df.loc[fil1, 'MisBsm'] = 0\n    df.loc[fil, 'MisBsm'] = 1\n    # BsmtQual\n    df.loc[fil, 'BsmtQual'] = \"NoBsmt\" # missing basement\n    # BsmtCond\n    df.loc[fil, 'BsmtCond'] = \"NoBsmt\" # missing basement\n    # BsmtExposure\n    df.loc[fil, 'BsmtExposure'] = \"NoBsmt\" # missing basement\n    # BsmtFinType1\n    df.loc[fil, 'BsmtFinType1'] = \"NoBsmt\" # missing basement\n    # BsmtFinType2\n    df.loc[fil, 'BsmtFinType2'] = \"NoBsmt\" # missing basement\n    # FireplaceQu\n    df.loc[(df.Fireplaces == 0) & (df.FireplaceQu.isnull()), 'FireplaceQu'] = \"NoFire\" # missing\n    # MisGarage\n    fil = ((df.GarageYrBlt.isnull()) & (df.GarageType.isnull()) & (df.GarageFinish.isnull()) &\n          (df.GarageQual.isnull()) & (df.GarageCond.isnull()))\n    fil1 = ((df.GarageYrBlt.notnull()) | (df.GarageType.notnull()) | (df.GarageFinish.notnull()) |\n          (df.GarageQual.notnull()) | (df.GarageCond.notnull()))\n    df.loc[fil1, 'MisGarage'] = 0\n    df.loc[fil, 'MisGarage'] = 1\n    # GarageYrBlt\n    df.loc[df.GarageYrBlt > 2200, 'GarageYrBlt'] = 2007  # correct mistake\n    df.loc[fil, 'GarageYrBlt'] = 0\n    # GarageType\n    df.loc[fil, 'GarageType'] = \"NoGrg\" # missing garage\n    # GarageFinish\n    df.loc[fil, 'GarageFinish'] = \"NoGrg\" # missing\n    # GarageQual\n    df.loc[fil, 'GarageQual'] = \"NoGrg\" # missing\n    # GarageCond\n    df.loc[fil, 'GarageCond'] = \"NoGrg\" # missing\n    # Fence\n    df.loc[df.Fence.isnull(), 'Fence'] = \"NoFence\" # missing fence\n    # Dropping stuff\n    del df['PoolQC']\n    del df['MiscFeature']\n\n# Fixing some entries in test\ndf_test[['BsmtUnfSF', \n         'TotalBsmtSF', \n         'BsmtFinSF1', \n         'BsmtFinSF2']] = df_test[['BsmtUnfSF', \n                                   'TotalBsmtSF', \n                                   'BsmtFinSF1', \n                                   'BsmtFinSF2']].fillna(0) # checked\n\n# eliminating entries in train with missing values\nfor f in df_train.columns:\n    df_train = df_train[pd.notnull(df_train[f])]\n    \n    \ndf_train['target'] = np.log1p(df_train.SalePrice)","a2d4ef25":"#To find the segment of the missing values, can be useful to impute the missing values\ndef find_segment(df, feat): \n    mis = df[feat].isnull().sum()\n    cols = df.columns\n    seg = []\n    for col in cols:\n        vc = df[df[feat].isnull()][col].value_counts(dropna=False).iloc[0]\n        if (vc == mis): #returns the columns for which the missing entries have only 1 possible value\n            seg.append(col)\n    return seg\n\n# to find the mode of the missing feature, by choosing the right segment to compare (uses find_segment)\ndef find_mode(df, feat): #returns the mode to fill in the missing feat\n    md = df[df[feat].isnull()][find_segment(df, feat)].dropna(axis=1).mode()\n    md = pd.merge(df, md, how='inner')[feat].mode().iloc[0]\n    return md\n\n# identical to the previous one, but with the median\ndef find_median(df, feat): #returns the median to fill in the missing feat\n    md = df[df[feat].isnull()][find_segment(df, feat)].dropna(axis=1).mode()\n    md = pd.merge(df, md, how='inner')[feat].median()\n    return md\n\n# find the mode in a segment defined by the user\ndef similar_mode(df, col, feats): #returns the mode in a segment made by similarity in feats\n    sm = df[df[col].isnull()][feats]\n    md = pd.merge(df, sm, how='inner')[col].mode().iloc[0]\n    return md\n\n# Find the median in a segment defined by the user\ndef similar_median(df, col, feats): #returns the median in a segment made by similarity in feats\n    sm = df[df[col].isnull()][feats]\n    md = pd.merge(df, sm, how='inner')[col].median()\n    return md","f561d2d5":"# Cleaning of test \n\n# MSZoning\nmd = find_mode(df_test, 'MSZoning')\nprint(\"MSZoning {}\".format(md))\ndf_test[['MSZoning']] = df_test[['MSZoning']].fillna(md)\n# Utilities\nmd = 'AllPub'\ndf_test[['Utilities']] = df_test[['Utilities']].fillna(md)\n# MasVnrType\nmd = find_mode(df_test, 'MasVnrType')\nprint(\"MasVnrType {}\".format(md))\ndf_test[['MasVnrType']] = df_test[['MasVnrType']].fillna(md)\n# MasVnrArea\nmd = find_mode(df_test, 'MasVnrArea')\nprint(\"MasVnrArea {}\".format(md))\ndf_test[['MasVnrArea']] = df_test[['MasVnrArea']].fillna(md)\n# BsmtQual\nsimi = ['BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']\nmd = similar_mode(df_test, 'BsmtQual', simi)\nprint(\"BsmtQual {}\".format(md))\ndf_test[['BsmtQual']] = df_test[['BsmtQual']].fillna(md)\n# BsmtCond\nsimi = ['BsmtQual', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']\nmd = similar_mode(df_test, 'BsmtCond', simi)\nprint(\"BsmtCond {}\".format(md))\ndf_test[['BsmtCond']] = df_test[['BsmtCond']].fillna(md)\n# BsmtCond\nsimi = ['BsmtQual', 'BsmtCond', 'BsmtFinType1', 'BsmtFinType2']\nmd = similar_mode(df_test, 'BsmtExposure', simi)\nprint(\"BsmtExposure {}\".format(md))\ndf_test[['BsmtExposure']] = df_test[['BsmtExposure']].fillna(md)\n# BsmtFullBath\nsimi = ['BsmtQual', 'BsmtCond', 'BsmtFinType1', 'BsmtFinType2']\nmd = similar_median(df_test, 'BsmtFullBath', simi)\nprint(\"BsmtFullBath {}\".format(md))\ndf_test[['BsmtFullBath']] = df_test[['BsmtFullBath']].fillna(md)\n# BsmtHalfBath\nsimi = ['BsmtQual', 'BsmtCond', 'BsmtFinType1', 'BsmtFinType2']\nmd = similar_median(df_test, 'BsmtHalfBath', simi)\nprint(\"BsmtHalfBath {}\".format(md))\ndf_test[['BsmtHalfBath']] = df_test[['BsmtHalfBath']].fillna(md)\n# KitchenQual\nmd = df_test.KitchenQual.mode().iloc[0]\nprint(\"KitchenQual {}\".format(md))\ndf_test[['KitchenQual']] = df_test[['KitchenQual']].fillna(md)\n# Functional\nmd = 'Typ'\ndf_test[['Functional']] = df_test[['Functional']].fillna(md)\n# GarageYrBlt\nsimi = ['GarageType', 'MisGarage']\nmd = similar_median(df_test, 'GarageYrBlt', simi)\nprint(\"GarageYrBlt {}\".format(md))\ndf_test[['GarageYrBlt']] = df_test[['GarageYrBlt']].fillna(md)\n# GarageFinish\nmd = 'Unf'\nprint(\"GarageFinish {}\".format(md))\ndf_test[['GarageFinish']] = df_test[['GarageFinish']].fillna(md)\n# GarageArea\nsimi = ['GarageType', 'MisGarage']\nmd = similar_median(df_test, 'GarageArea', simi)\nprint(\"GarageArea {}\".format(md))\ndf_test[['GarageArea']] = df_test[['GarageArea']].fillna(md)\n# GarageQual\nsimi = ['GarageType', 'MisGarage', 'GarageFinish']\nmd = similar_mode(df_test, 'GarageQual', simi)\nprint(\"GarageQual {}\".format(md))\ndf_test[['GarageQual']] = df_test[['GarageQual']].fillna(md)\n# GarageCond\nsimi = ['GarageType', 'MisGarage', 'GarageFinish']\nmd = similar_mode(df_test, 'GarageCond', simi)\nprint(\"GarageCond {}\".format(md))\ndf_test[['GarageCond']] = df_test[['GarageCond']].fillna(md)\n# GarageCars\nsimi = ['GarageType', 'MisGarage']\nmd = similar_median(df_test, 'GarageCars', simi)\nprint(\"GarageCars {}\".format(md))\ndf_test[['GarageCars']] = df_test[['GarageCars']].fillna(md)\n\ncols = df_test.columns\nmis_test = []\nprint(\"Start printing the missing values...\")\nfor col in cols:\n    mis = df_test[col].isnull().sum()\n    if mis > 0:\n        print(\"{}: {} missing, {}%\".format(col, mis, round(mis\/df_test.shape[0] * 100, 3)))\n        mis_test.append(col)\nprint(\"...done printing the missing values\")","3b42969f":"sel_cols = ['MSZoning', 'Alley', 'LotShape', 'Foundation', \n             'Heating', 'GarageQual', 'MasVnrType', 'ExterQual']\n\nfor col in sel_cols:\n    print(col)\n    print(df_train[col].value_counts())\n    print('_'*20)\n    print(df_test[col].value_counts())\n    print('_'*40)\n    print('\\n')","b6c7ad81":"X_train, X_test, y_train, y_test = train_test_split(df_train, df_train.target, test_size=0.20, random_state=42)\n\nkfolds = KFold(n_splits=5, shuffle=True, random_state=14)\n\nprint(f\"Original train set shape: \\t {df_train.shape}\")\nprint(f\"New train set shape: \\t {X_train.shape}\")\nprint(f\"Validation set shape: \\t {X_test.shape}\")","d9e7ca4b":"def OLS_experiment(train, target, validate, val_target):\n    train = train.copy()\n    validate = validate.copy()\n    train['intercept'] = 1 \n    validate['intercept'] = 1\n    \n    regressor_OLS = sm.OLS(endog = target, exog = train).fit()\n    print(regressor_OLS.summary())\n    \n    in_pred = regressor_OLS.predict(train)\n    score = mean_squared_error(y_pred=in_pred, y_true=target)\n    print('\\n')\n    print(f'Score in-sample: \\t {score}')\n    \n    pred = regressor_OLS.predict(validate)\n    score = mean_squared_error(y_pred=pred, y_true=val_target)\n    \n    print('\\n')\n    print(f'Score out of sample: \\t {score}')\n    \n    return pred, in_pred\n\n\ndef get_coef(clsf, ftrs):\n    imp = clsf.coef_.tolist() \n    feats = ftrs\n    result = pd.DataFrame({'feat':feats,'score':imp})\n    result = result.sort_values(by=['score'],ascending=False)\n    return result\n\n\ndef lasso_experiment(train, target, validate, val_target, folds):\n    param_grid = [{'alpha' : [0.0001, 0.0005, 0.00075,\n                                 0.001, 0.005, 0.0075, \n                                 0.01, 0.05, 0.075,\n                                 0.1, 0.5, 0.75, \n                                 1, 5, 7.5]}]\n\n    grid = GridSearchCV(Lasso(), param_grid=param_grid,\n                        cv=folds, scoring='neg_mean_squared_error', \n                        return_train_score=True, n_jobs=-1)\n    grid.fit(train, target)\n    \n    best_lasso = grid.best_estimator_\n    print(best_lasso)\n    print(\"_\"*40)\n    #with its score\n    print(np.sqrt(-grid.best_score_))\n    print(\"_\"*40)\n    \n    print(get_coef(best_lasso, train.columns))\n    \n    pred = best_lasso.predict(validate)\n    score = mean_squared_error(y_pred=pred, y_true=val_target)\n    \n    print(f'Validation score: \\t {score}')\n    \n    return pred\n\n\ndef get_feature_importance(clsf, ftrs):\n    imp = clsf.feature_importances_.tolist() \n    feats = ftrs\n    result = pd.DataFrame({'feat':feats,'score':imp})\n    result = result.sort_values(by=['score'],ascending=False)\n    return result\n\n\ndef tree_experiment(train, target, validate, val_target, folds):\n    param_grid = [{'max_depth': [2, 3, 5, 8, 10, 20], \n                   'max_leaf_nodes': [None, 5, 10, 20]}]\n    \n    grid = GridSearchCV(DecisionTreeRegressor(), param_grid=param_grid,\n                        cv=folds, scoring='neg_mean_squared_error', \n                        return_train_score=True, n_jobs=-1)\n    grid.fit(train, target)\n    \n    best_tree = grid.best_estimator_\n    print(best_tree)\n    print(\"_\"*40)\n    #with its score\n    print(np.sqrt(-grid.best_score_))\n    print(\"_\"*40)\n    \n    print(get_feature_importance(best_tree, train.columns))\n    \n    pred = best_tree.predict(validate)\n    score = mean_squared_error(y_pred=pred, y_true=val_target)\n    \n    print(f'Validation score: \\t {score}')\n    \n    return pred\n\n\ndef plot_predictions(val_target, ols, lasso, tree):\n    line = pd.DataFrame({'x': np.arange(10.5,13.5,0.01), # small hack for a diagonal line\n                         'y': np.arange(10.5,13.5,0.01)})\n    plt.figure(figsize=(10,6))\n    plt.scatter(val_target, ols, label='OLS')\n    plt.scatter(val_target, lasso, label='Lasso')\n    plt.scatter(val_target, tree, label='Tree')\n    plt.plot(line.x, line.y, color='black')\n    plt.xlabel('True value', fontsize=12)\n    plt.ylabel('Prediction', fontsize=12)\n    plt.legend()","5208a8b2":"exp_train = X_train[['OverallQual', 'OverallCond', 'GrLivArea', 'GarageArea']].copy()\nexp_test = X_test[['OverallQual', 'OverallCond', 'GrLivArea', 'GarageArea']].copy()\n\nprint('OLS experiment')\nols_pred, ols_i_pred = OLS_experiment(exp_train, y_train, exp_test, y_test)\nprint('\\n')\nprint('_'*40)\nprint('Lasso experiment')\nlasso_pred = lasso_experiment(exp_train, y_train, exp_test, y_test, kfolds)\nprint('\\n')\nprint('_'*40)\nprint('Tree experiment')\ntree_pred = tree_experiment(exp_train, y_train, exp_test, y_test, kfolds)","13b865ee":"plot_predictions(y_test, ols_pred, lasso_pred, tree_pred)","a131828b":"dum_test = df_train[['MasVnrType']].copy()\ndum_test.head(10)","8a1b20cf":"dum_test.MasVnrType.value_counts(dropna=False)","e0109961":"dum_transf = pd.get_dummies(dum_test)\ndum_transf.head()","8de41647":"for col in dum_transf.columns:\n    print(col)\n    print(dum_transf[col].value_counts())\n    print('\\n')","7c1c146e":"encoder = OneHotEncoder()\ndum_transf = encoder.fit_transform(dum_test)\npd.DataFrame(dum_transf.todense(), columns=encoder.get_feature_names()).head(10)","b9d93b30":"exp_train = X_train[['MasVnrType', 'Alley', 'LotShape']].copy()\nexp_test = X_test[['MasVnrType', 'Alley', 'LotShape']].copy()\n\nexp_train = pd.get_dummies(exp_train)\nexp_test = pd.get_dummies(exp_test)\n\nexp_train.head()","56c56580":"res_ols, res_ols_i = OLS_experiment(exp_train, y_train, exp_test, y_test)","156f23f5":"exp_train = X_train[['MasVnrType', 'Alley', 'LotShape']].copy()\nexp_test = X_test[['MasVnrType', 'Alley', 'LotShape']].copy()\n\nexp_train = pd.get_dummies(exp_train, drop_first=True)\nexp_test = pd.get_dummies(exp_test, drop_first=True)\n\nexp_train.head()","de67af8d":"res_ols_o, res_ols_i = OLS_experiment(exp_train, y_train, exp_test, y_test)","f5a10994":"exp_train = X_train[['MasVnrType', 'Alley', 'LotShape']].copy()\nexp_test = X_test[['MasVnrType', 'Alley', 'LotShape']].copy()\n\nexp_train = pd.get_dummies(exp_train)\nexp_test = pd.get_dummies(exp_test)\n\nres_lasso = lasso_experiment(exp_train, y_train, exp_test, y_test, kfolds)\n\nprint('\\n')\nprint('_'*40)\nprint('Now, let\\'s drop one dummy')\nprint('\\n')\n\nexp_train = X_train[['MasVnrType', 'Alley', 'LotShape']].copy()\nexp_test = X_test[['MasVnrType', 'Alley', 'LotShape']].copy()\n\nexp_train = pd.get_dummies(exp_train, drop_first=True)\nexp_test = pd.get_dummies(exp_test, drop_first=True)\n\nres_lasso = lasso_experiment(exp_train, y_train, exp_test, y_test, kfolds)","c372a6d3":"exp_train = X_train[['MasVnrType', 'Alley', 'LotShape']].copy()\nexp_test = X_test[['MasVnrType', 'Alley', 'LotShape']].copy()\n\nexp_train = pd.get_dummies(exp_train)\nexp_test = pd.get_dummies(exp_test)\n\nres_tree = tree_experiment(exp_train, y_train, exp_test, y_test, kfolds)\n\nprint('\\n')\nprint('_'*40)\nprint('Now, let\\'s drop one dummy')\nprint('\\n')\n\nexp_train = X_train[['MasVnrType', 'Alley', 'LotShape']].copy()\nexp_test = X_test[['MasVnrType', 'Alley', 'LotShape']].copy()\n\nexp_train = pd.get_dummies(exp_train, drop_first=True)\nexp_test = pd.get_dummies(exp_test, drop_first=True)\n\nres_tree = tree_experiment(exp_train, y_train, exp_test, y_test, kfolds)","c1dd9302":"plot_predictions(y_test, res_ols_o, res_lasso, res_tree)","5969c34f":"le = LabelEncoder()\ndum_test['encoded'] = le.fit_transform(dum_test.MasVnrType)\ndum_test.head(10)","0fe7768b":"exp_train = X_train[['MasVnrType', 'Alley', 'LotShape']].copy()\nexp_test = X_test[['MasVnrType', 'Alley', 'LotShape']].copy()\n\nexp_train = exp_train.apply(le.fit_transform)\nexp_test = exp_test.apply(le.fit_transform)\n\nexp_train.head()","9048236a":"tmp,tmp_1 = OLS_experiment(exp_train, y_train, exp_test, y_test)\n\nprint('\\n')\n\ntmp = tree_experiment(exp_train, y_train, exp_test, y_test, kfolds)","ec87b91b":"exp_train = X_train[['MasVnrType']].copy()\nexp_train = pd.get_dummies(exp_train)\nexp_train.head()","0f20be64":"from sklearn import tree\nimport graphviz\n\ndt = DecisionTreeRegressor().fit(exp_train, y_train)\n\ndot_data = tree.export_graphviz(dt, out_file=None, filled=True)  \ngraph = graphviz.Source(dot_data)  \ngraph","93211f1c":"exp_train = X_train[['MasVnrType']].copy()\nexp_train['MasVnrType'] = le.fit_transform(exp_train.MasVnrType)\nexp_train.head()","1d675889":"dt = DecisionTreeRegressor().fit(exp_train, y_train)\n\ndot_data = tree.export_graphviz(dt, out_file=None, filled=True)  \ngraph = graphviz.Source(dot_data)  \ngraph","3ef2ba21":"df_train.ExterQual.value_counts()","2fba671c":"ord_test = df_train[['ExterQual']].copy()\nord_test['encoded'] = le.fit_transform(ord_test.ExterQual)\nord_test.head()","4fb71ce4":"pd.crosstab(ord_test.encoded, ord_test.ExterQual)","48bb43f0":"ord_test = df_train[['ExterQual', 'target']].copy()\nord_test.groupby('ExterQual').agg(['mean', 'median', 'max', 'min', 'count'])","6410234c":"ord_test.loc[ord_test.ExterQual == 'Fa', 'ExtQuGroup'] = 0\nord_test.loc[ord_test.ExterQual == 'TA', 'ExtQuGroup'] = 1\nord_test.loc[ord_test.ExterQual == 'Gd', 'ExtQuGroup'] = 2\nord_test.loc[ord_test.ExterQual == 'Ex', 'ExtQuGroup'] = 3\n\nord_test['LabelEncoded'] = le.fit_transform(ord_test.ExterQual)\n\nx1 = ord_test['ExtQuGroup']\nx2 = ord_test['LabelEncoded']\ny = ord_test['target']\n\nprint('Correlations with target')\nprint(ord_test[['ExtQuGroup','LabelEncoded' ,'target' ]].corr())\n\nfig, ax= plt.subplots(1,2, figsize=(15, 6))\n\nsns.regplot(x = x1, y = y, x_estimator = np.mean, ax=ax[0])\nsns.regplot(x = x2, y = y, x_estimator = np.mean, ax=ax[1])\n\nax[0].set_title('Manual encoding', fontsize=16)\nax[1].set_title('Automatic encoding', fontsize=16)","5c8e8efa":"ord_test = df_train[['HeatingQC', 'target']].copy()\n\nord_test.loc[ord_test.HeatingQC == 'Po', 'HeatQGroup'] = 1\nord_test.loc[ord_test.HeatingQC == 'Fa', 'HeatQGroup'] = 2\nord_test.loc[ord_test.HeatingQC == 'TA', 'HeatQGroup'] = 3\nord_test.loc[ord_test.HeatingQC == 'Gd', 'HeatQGroup'] = 4\nord_test.loc[ord_test.HeatingQC == 'Ex', 'HeatQGroup'] = 5\n\nord_test['LabelEncoded'] = le.fit_transform(ord_test.HeatingQC)\n\nx1 = ord_test['HeatQGroup']\nx2 = ord_test['LabelEncoded']\ny = ord_test['target']\n\nprint('Correlations with target')\nprint(ord_test[['HeatQGroup','LabelEncoded' ,'target' ]].corr())\n\nfig, ax= plt.subplots(1,2, figsize=(15, 6))\n\nsns.regplot(x = x1, y = y, x_estimator = np.mean, ax=ax[0])\nsns.regplot(x = x2, y = y, x_estimator = np.mean, ax=ax[1])\n\nax[0].set_title('Manual encoding', fontsize=16)\nax[1].set_title('Automatic encoding', fontsize=16)","06790cb9":"ord_test = df_train[['HeatingQC', 'target']].copy()\n\nord_test.loc[ord_test.HeatingQC == 'Po', 'HeatQGroup'] = 1\nord_test.loc[ord_test.HeatingQC == 'Fa', 'HeatQGroup'] = 2\nord_test.loc[ord_test.HeatingQC == 'TA', 'HeatQGroup'] = 3\nord_test.loc[ord_test.HeatingQC == 'Gd', 'HeatQGroup'] = 4\nord_test.loc[ord_test.HeatingQC == 'Ex', 'HeatQGroup'] = 5\n\nord_test.loc[ord_test.HeatingQC == 'Po', 'HeatQGroup_2'] = 1\nord_test.loc[ord_test.HeatingQC == 'Fa', 'HeatQGroup_2'] = 1\nord_test.loc[ord_test.HeatingQC == 'TA', 'HeatQGroup_2'] = 3\nord_test.loc[ord_test.HeatingQC == 'Gd', 'HeatQGroup_2'] = 4\nord_test.loc[ord_test.HeatingQC == 'Ex', 'HeatQGroup_2'] = 7\n\nx1 = ord_test['HeatQGroup']\nx2 = ord_test['HeatQGroup_2']\ny = ord_test['target']\n\nprint('Correlations with target')\nprint(ord_test[['HeatQGroup','HeatQGroup_2' ,'target' ]].corr())\n\nfig, ax= plt.subplots(1,2, figsize=(15, 6))\n\nsns.regplot(x = x1, y = y, x_estimator = np.mean, ax=ax[0])\nsns.regplot(x = x2, y = y, x_estimator = np.mean, ax=ax[1])\n\nax[0].set_title('Old encoding', fontsize=16)\nax[1].set_title('New encoding', fontsize=16)","2d091321":"print('With a normal encoding')\nprint('\\n')\n\nexp_train = X_train[['HeatingQC']].copy() # , 'ExterQual', 'KitchenQual'\nexp_test = X_test[['HeatingQC']].copy()\n\nnorm_encode = {'Po': 1, 'Fa': 2, 'TA':3, 'Gd':4, 'Ex': 5}\n\nexp_train['HeatingQC'] = exp_train.HeatingQC.map(norm_encode).astype(int)\nexp_test['HeatingQC'] = exp_test.HeatingQC.map(norm_encode).astype(int)\n#exp_train['ExterQual'] = exp_train.ExterQual.map(norm_encode).astype(int)\n#exp_test['ExterQual'] = exp_test.ExterQual.map(norm_encode).astype(int)\n#exp_train['KitchenQual'] = exp_train.KitchenQual.map(norm_encode).astype(int)\n#exp_test['KitchenQual'] = exp_test.KitchenQual.map(norm_encode).astype(int)\n\nlasso_pred_norm = lasso_experiment(exp_train, y_train, exp_test, y_test, kfolds)\n\nprint('_'*40)\n\nprint('\\n Now by encoding HeatingQC differently')\nprint('\\n')\n\nexp_train = X_train[['HeatingQC']].copy()\nexp_test = X_test[['HeatingQC']].copy()\n\nnorm_encode = {'Po': 1, 'Fa': 2, 'TA':3, 'Gd':4, 'Ex': 5}\nnew_encode = {'Po': 1, 'Fa': 1, 'TA':3, 'Gd':4, 'Ex': 7}\n\nexp_train['HeatingQC'] = exp_train.HeatingQC.map(new_encode).astype(int)\nexp_test['HeatingQC'] = exp_test.HeatingQC.map(new_encode).astype(int)\n#exp_train['ExterQual'] = exp_train.ExterQual.map(norm_encode).astype(int)\n#exp_test['ExterQual'] = exp_test.ExterQual.map(norm_encode).astype(int)\n#exp_train['KitchenQual'] = exp_train.KitchenQual.map(norm_encode).astype(int)\n#exp_test['KitchenQual'] = exp_test.KitchenQual.map(norm_encode).astype(int)\n\nlasso_pred_new = lasso_experiment(exp_train, y_train, exp_test, y_test, kfolds)\n\nprint('_'*40)\n\nprint('\\n Now by getting dummies')\nprint('\\n')\n\nexp_train = X_train[['HeatingQC']].copy()\nexp_test = X_test[['HeatingQC']].copy()\n\n# dirty fix for dummies mismatch\nexp_test.loc[exp_test.HeatingQC == 'Po', 'HeatingQC'] = 'Fa' \n\nexp_train = pd.get_dummies(exp_train, drop_first=True)\nexp_test = pd.get_dummies(exp_test, drop_first=True)\n\nlasso_pred_dum = lasso_experiment(exp_train, y_train, exp_test, y_test, kfolds)","1ccf6eea":"print('With a normal encoding')\nprint('\\n')\n\nexp_train = X_train[['HeatingQC']].copy() # , 'ExterQual', 'KitchenQual'\nexp_test = X_test[['HeatingQC']].copy()\n\nnorm_encode = {'Po': 1, 'Fa': 2, 'TA':3, 'Gd':4, 'Ex': 5}\n\nexp_train['HeatingQC'] = exp_train.HeatingQC.map(norm_encode).astype(int)\nexp_test['HeatingQC'] = exp_test.HeatingQC.map(norm_encode).astype(int)\n#exp_train['ExterQual'] = exp_train.ExterQual.map(norm_encode).astype(int)\n#exp_test['ExterQual'] = exp_test.ExterQual.map(norm_encode).astype(int)\n#exp_train['KitchenQual'] = exp_train.KitchenQual.map(norm_encode).astype(int)\n#exp_test['KitchenQual'] = exp_test.KitchenQual.map(norm_encode).astype(int)\n\ntree_pred_norm = tree_experiment(exp_train, y_train, exp_test, y_test, kfolds)\n\nprint('_'*40)\n\nprint('\\n Now by encoding HeatingQC differently')\nprint('\\n')\n\nexp_train = X_train[['HeatingQC']].copy()\nexp_test = X_test[['HeatingQC']].copy()\n\nnorm_encode = {'Po': 1, 'Fa': 2, 'TA':3, 'Gd':4, 'Ex': 5}\nnew_encode = {'Po': 1, 'Fa': 1, 'TA':3, 'Gd':4, 'Ex': 7}\n\nexp_train['HeatingQC'] = exp_train.HeatingQC.map(new_encode).astype(int)\nexp_test['HeatingQC'] = exp_test.HeatingQC.map(new_encode).astype(int)\n#exp_train['ExterQual'] = exp_train.ExterQual.map(norm_encode).astype(int)\n#exp_test['ExterQual'] = exp_test.ExterQual.map(norm_encode).astype(int)\n#exp_train['KitchenQual'] = exp_train.KitchenQual.map(norm_encode).astype(int)\n#exp_test['KitchenQual'] = exp_test.KitchenQual.map(norm_encode).astype(int)\n\ntree_pred_new = tree_experiment(exp_train, y_train, exp_test, y_test, kfolds)\n\nprint('_'*40)\n\nprint('\\n Now by getting dummies')\nprint('\\n')\n\nexp_train = X_train[['HeatingQC']].copy()\nexp_test = X_test[['HeatingQC']].copy()\n\n# dirty fix for dummies mismatch\nexp_test.loc[exp_test.HeatingQC == 'Po', 'HeatingQC'] = 'Fa' \n\nexp_train = pd.get_dummies(exp_train, drop_first=True)\nexp_test = pd.get_dummies(exp_test, drop_first=True)\n\ntree_pred_dum = tree_experiment(exp_train, y_train, exp_test, y_test, kfolds)","6099f747":"print('Training set')\nexp_train = X_train[['HeatingQC']].copy()\nexp_train = pd.get_dummies(exp_train, drop_first=True)\nexp_train.head()","7de8b9d8":"print('Validation set')\nexp_test= X_test[['HeatingQC']].copy()\nexp_test = pd.get_dummies(exp_test, drop_first=True)\nexp_test.head()","f5d8f4bd":"df_train.HeatingQC.value_counts()","b007fe55":"mis_dum = df_train[['HeatingQC']].copy()\nmis_dum = pd.get_dummies(mis_dum)\n\nmis_d_train, mis_d_test, mis_d_y_train,  mis_d_y_test = train_test_split(mis_dum, df_train.target, test_size=0.20, random_state=42)\n\nprint(mis_d_train.columns)\nprint(f'Number of `Po`: \\t {mis_d_train.HeatingQC_Po.sum()}')\nprint('\\n')\nprint(mis_d_test.columns)\nprint(f'Number of `Po`: \\t {mis_d_test.HeatingQC_Po.sum()}')","5688e6a9":"dum_col = ['HeatingQC', 'GarageQual', 'Condition2', 'Utilities', 'Heating']\n\nexp_train = X_train[dum_col].copy()\nexp_test = X_test[dum_col].copy()\nexp_train = pd.get_dummies(exp_train, drop_first=True)\nexp_test = pd.get_dummies(exp_test, drop_first=True)\n\nprint('Mismatched dummies:')\nprint(list(set(exp_train.columns) - set(exp_test.columns)))\n\nexp_train = exp_train[[col for col in exp_test.columns if col in exp_train.columns]]\nexp_test = exp_test[[col for col in exp_train.columns]]  # yes, it has to be done twice\n\nprint('\\nCommon columns: ')\nprint(list(exp_train.columns))","7fc82430":"rare_cat = ['MSZoning', 'LotShape', 'Foundation', 'MasVnrType']\nrare_ord = ['GarageQual', 'ExterQual']","2ef1d762":"df_train.Foundation.value_counts()","9cfe62ed":"exp_train = X_train[rare_cat].copy()\nexp_test = X_test[rare_cat].copy()\n\nexp_train = pd.get_dummies(exp_train, drop_first=True)\nexp_test = pd.get_dummies(exp_test, drop_first=True)\n\ndel exp_train['Foundation_Wood']\n\nprint('Lasso experiment')\nlasso_pred = lasso_experiment(exp_train, y_train, exp_test, y_test, kfolds)\nprint('\\n')\nprint('Tree experiment')\ntree_pred = tree_experiment(exp_train, y_train, exp_test, y_test, kfolds)","abfc30b5":"exp_train = X_train[rare_cat].copy()\nexp_test = X_test[rare_cat].copy()\n\n# floating villages can be low density residential area\nexp_train.loc[exp_train.MSZoning == 'FV', 'MSZoning'] = 'RL'  \nexp_test.loc[exp_test.MSZoning == 'FV', 'MSZoning'] = 'RL'\n# medium and high density residential areas can be considered, with commercial area, a non low density residential area\nexp_train.loc[exp_train.MSZoning != 'RL', 'MSZoning'] = 'notRL'  \nexp_test.loc[exp_test.MSZoning != 'RL', 'MSZoning'] = 'notRL'\n\n# LotShape is either regular or irregular\nexp_train.loc[exp_train.LotShape != 'Reg', 'LotShape'] = 'IRR'\nexp_test.loc[exp_test.LotShape != 'Reg', 'LotShape'] = 'IRR'\n\n# making foundations simpler\nfond = ['PConc', 'CBlock']\nexp_train.loc[~exp_train.Foundation.isin(fond), 'Foundation'] = 'Other'\nexp_test.loc[~exp_test.Foundation.isin(fond), 'Foundation'] = 'Other'\n\n# MasVnrType doesn't need 2 types of bricks\nexp_train.loc[exp_train.MasVnrType == 'BrkCmn', 'MasVnrType'] = 'BrkFace'\nexp_test.loc[exp_test.MasVnrType == 'BrkCmn', 'MasVnrType'] = 'BrkFace'\n\nexp_train = pd.get_dummies(exp_train, drop_first=True)\nexp_test = pd.get_dummies(exp_test, drop_first=True)\n\ntree_pred = tree_experiment(exp_train, y_train, exp_test, y_test, kfolds)","be18c304":"exp_train = X_train[rare_cat].copy()\nexp_test = X_test[rare_cat].copy()\n\n# floating villages can be low density residential area\nexp_train.loc[exp_train.MSZoning == 'FV', 'MSZoning'] = 'RL'  \nexp_test.loc[exp_test.MSZoning == 'FV', 'MSZoning'] = 'RL'\n\n# Smoothing out the levels or irregularity\nexp_train.loc[exp_train.LotShape == 'IR2', 'LotShape'] = 'IR3'\nexp_test.loc[exp_test.LotShape == 'IR2', 'LotShape'] = 'IR3'\n\n# making foundations simpler\n#exp_train.loc[exp_train.Foundation == 'Stone', 'Foundation'] = 'PConc' # Similar coefficients, but not similar categories\n#exp_test.loc[exp_test.Foundation == 'Stone', 'Foundation'] = 'PConc'\n#exp_train.loc[exp_train.Foundation == 'Wood', 'Foundation'] = 'PConc'\n\n\nexp_train = pd.get_dummies(exp_train, drop_first=True)\nexp_test = pd.get_dummies(exp_test, drop_first=True)\ndel exp_train['Foundation_Wood']\n\nprint('Lasso experiment')\nlasso_pred = lasso_experiment(exp_train, y_train, exp_test, y_test, kfolds)\nprint('\\n')\nprint('Tree experiment')\ntree_pred = tree_experiment(exp_train, y_train, exp_test, y_test, kfolds)","5c5acfdf":"exp_train = X_train[['GarageQual']].copy()\nexp_test = X_test[['GarageQual']].copy()\n\nto_num = {'NoGrg': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\n\nexp_train['GarageQual'] = exp_train['GarageQual'].map(to_num).astype(int)\nexp_test['GarageQual'] = exp_test['GarageQual'].map(to_num).astype(int)\n\nprint('Tree experiment')\ntree_pred = tree_experiment(exp_train, y_train, exp_test, y_test, kfolds)","3cc0652c":"exp_train = X_train[['GarageQual']].copy()\nexp_test = X_test[['GarageQual']].copy()\n\nto_num = {'NoGrg': 0, 'Po': 2, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 4}\n\nexp_train['GarageQual'] = exp_train['GarageQual'].map(to_num).astype(int)\nexp_test['GarageQual'] = exp_test['GarageQual'].map(to_num).astype(int)\n\nprint('Tree experiment')\ntree_pred = tree_experiment(exp_train, y_train, exp_test, y_test, kfolds)","0b5ef2b7":"g = sns.FacetGrid(df_train, hue=\"GarageCars\", height=8)\ng.map(plt.scatter, \"GarageArea\", \"target\", edgecolor=\"w\")\ng.add_legend()","f4b5d226":"exp_train = X_train[['GarageArea']].copy()\nexp_test = X_test[['GarageArea']].copy()\n\nprint('OLS experiment')  # lasso would give the same\nols_pred, ols_i_pred = OLS_experiment(exp_train, y_train, exp_test, y_test)\nprint('\\n')\nprint('Tree experiment')\ntree_pred = tree_experiment(exp_train, y_train, exp_test, y_test, kfolds)\n\nplot_predictions(y_test, ols_pred, ols_pred, tree_pred)  ","4a4ec440":"exp_train = X_train[['GarageCars']].copy()\nexp_test = X_test[['GarageCars']].copy()\n\nprint('OLS experiment')\nols_pred, ols_i_pred = OLS_experiment(exp_train, y_train, exp_test, y_test)\nprint('\\n')\nprint('Tree experiment')\ntree_pred = tree_experiment(exp_train, y_train, exp_test, y_test, kfolds)\n\nplot_predictions(y_test, ols_pred, ols_pred, tree_pred)","c2a9a867":"exp_train = X_train[['GarageCars']].copy()\nexp_test = X_test[['GarageCars']].copy()\n\nexp_train['GarageCars'] = exp_train['GarageCars'].astype(str)\nexp_test['GarageCars'] = exp_test['GarageCars'].astype(str)\n\nexp_train = pd.get_dummies(exp_train)\nexp_test = pd.get_dummies(exp_test)\n\ndel exp_train['GarageCars_4']\n\nprint('OLS experiment')\nols_pred, ols_i_pred = OLS_experiment(exp_train, y_train, exp_test, y_test)\nprint('\\n')\nprint('Tree experiment')\ntree_pred = tree_experiment(exp_train, y_train, exp_test, y_test, kfolds)\n\nplot_predictions(y_test, ols_pred, ols_pred, tree_pred)","7ad158bb":"df_train.Neighborhood.value_counts()","fb9417f9":"exp_train = X_train[['Neighborhood']].copy()\nexp_test = X_test[['Neighborhood']].copy()\n# getting the frequency in the training set only, you can also use the full set if it is available\nfreq_train = exp_train.groupby('Neighborhood').size() \/ len(exp_train) \n\nexp_train['Enc_Neigh'] = exp_train['Neighborhood'].map(freq_train)\nexp_test['Enc_Neigh'] = exp_test['Neighborhood'].map(freq_train)\n\nexp_train.sample(10)","67bb5f87":"from sklearn.feature_extraction import FeatureHasher\n\nm = int(len(set(df_train.Neighborhood)))  # number of unique neighboorhoods\n\nh = FeatureHasher(n_features=m, input_type='string')\n\nf = h.transform(df_train['Neighborhood'])\n\nf","66f8e4f5":"f.toarray()","bdf8aafc":"m = int(len(set(df_train.Neighborhood))\/2)\nh = FeatureHasher(n_features=m, input_type='string')\nf = h.transform(df_train['Neighborhood'])\nf","fbd22de6":"f.toarray()","bdf0bc6b":"exp_train = X_train[['GrLivArea', 'Neighborhood']].copy()\nexp_test = X_test[['GrLivArea', 'Neighborhood']].copy()\n\navg_area = exp_train.groupby('Neighborhood', as_index=False).mean()\n\nconversion = dict(zip(avg_area.Neighborhood, avg_area.GrLivArea))\n\nexp_train['Neigh_avg_area'] = exp_train['Neighborhood'].map(conversion)\nexp_test['Neigh_avg_area'] = exp_test['Neighborhood'].map(conversion)\n\nexp_test.sample(10)","9525400a":"To give a simple ordering to these categories, we can do the following","449de16a":"# Final tips\n\nUnderstanding categorical features can give help you building a solid model, a model that you can explain to a colleague or to a client. I hope the techniques here displayed can inspire you for the next time you will explore further applications on your own.\n\nAmong the things we didn't explore here, there is how to use use a categorical feature together with another one (what we could call an interaction). For example, one can use the average size of the houses in a Neighborhood as a feature","cc1c4cbe":"This example is just to show you the expected output of the 3 experiments: scores on training and validation sets, coefficients or features importance. Do not focus too much on the coefficients of OLS and Lasso since we should first normalize the variables to get some insights out of it (`OverallQual` is on a 1-10 scale, `GrLivArea` is on a much bigger scale).\n\nAll that being said, we will now focus on categorical variables and ignore very powerful predictors such as `GrLivArea`.\n\nBefore moving on, notice how the predictions of the DecisionTree are all distributed in *discrete levels*, I would recommend to think about the reason for that and, then, what would happen if we use a RandomForest instead.\n\n# Dummies and encoders\n\nThe standard approach to deal with categorical variables is to create **dummy variables**. To better understand what a dummy variable is, let's take the following data frame.","32396a5a":"Here, it is easy to argue that `Ex > Gd > TA > Fa` because *Excellent* is better than *Good* and so on. Now using the LabelEncoder would give us","0c36c595":"As in the previous case, our tree is not showing improvements if we drop a dummy.\n\nWe can finally see how the predictions of the 3 experiments on the validation set are.","f5e1fef4":"Now there is only one variable and it is splitting the same amount of times but, if we check what are the values it is splitting on, we notice it is doing the same splits and thus getting the same results.\n\nAll that being said, introducing an ordering when it was not there, at the very least, makes your model less explainable and this is mostly an issue when you have to start correcting something about it (or you have to explain it to a colleague, or a client).\n\n# Ordinal variables and measurement errors\n\nThere are situations where the categories suggest an order. For example, let's have a look at `ExterQual`","2cb0e4c5":"The data are now reasonably clean and we can start working on our experiments. Despite the fact that, as everyone knows already, the powerful predictors in this problem are not the following features, we will focus on a model that takes into consideration only a few categorical (and ordinal) features. Namely\n\n* GarageQual (ordinal\/categorical feature)\n* MSZoning (categorical feature)\n* Alley (categorical feature)\n* LotShape (categorical feature)\n* Foundation (categorical feature)\n* MasVnrType (categorical feature)\n* Heating (categorical feature)\n* KitchenQual (categorical\/ordinal feature)\n* ExterQual (categorical\/ordinal feature)\n\nThis choice is not mandatory, but these features will provide good examples for our experiments.","76a1dade":"While, if we correct for the mentioned sparsity, we get","bad20701":"If we make dummies out of this feature we end up with 25 columns and this can make harder for any model to learn the data. The fancy name of this is **curse of dimensionality** and, from its name, we don't need much to know that we don't want it.\n\nOne approach would be to group some neighborhoods in order to reduce the number of dummies. However, this would require both knowledge of the city in order to group them appropriately (which we don't have) and quite some time to do so. If the first problem is solvable, the second can become worse and worse as the number of categories grows.\n\n## Frequency encoding and hashing\n\nThe idea behind frequency encoding is to label each category by using its frequency of appearance in the dataset. This is useful for two reasons: \n\n* we convert the feature to a numerical type and this ensures that the models can run without errors\n* if there is a relationship between the target and how common (or uncommon) a category is, we can learn that relationship.\n\nAs for everything else, a good understanding of the problem will drive the decision of using this particular encoding or not. In this case, for example, it is not the most useful thing in terms of scoring, but since none of us is here for the scoring it is worth spending a minute to show how to implement it.\n\nA simple way to implement it is the following","1a300878":"In other words, we take all the unique values of the column, we create a new column for each one of them and set the entry to 1 or 0 depending on the values of each observation. This is confirmed by the count of `1`'s in each column that corresponds to the original one.\n\nAnother way of obtaining the same result is to use the sklearn method `OneHotEncoder`","7631167a":"Not only here we see a significant difference between the manual and the automatic encoding (again strongly in favor of the manual one), but we can also notice that it is possible that our encoding is not the optimal one. Although it is often a bad idea to tweak too much the processing of the data and enforce patterns that we believe are important, one may argue that **there is no objective scale that says that Good is 1 point better than Typical and 1 point worse than Excellent**, we are enforcing that pattern as well.\n\nIn this particular case, we don't even know if the data were gathered by the same people, that have the same parameters to judge the quality of the heating. In fact, we can easily find a better numerical encoding.","55399cf2":"Now we are able to see the effects of each variable and any evaluation of the model improved (R-squared, AIC, BIC, etc). The scores, both in sample and out of sample, did not improve that much but we are talking about very simple models, we can't expect too much out of them.","68e70e8d":"We see that using dummies is better than giving a *standard* ordering but they are both worse than our *enhanced* one.\n\nIn summary, the lesson here is that we can't give an ordering to something that is not supposed to have one (as in the previous section) but, when we do, we should keep in mind that **we are making an assumption** when we put numerical values in our data. As such, we should keep track of our choices and how the model is reacting to that.\n\nAll that being said, trees are indeed an amazing thing and, for reasons that should be clear by now given our previous experiment, they really don't care much about what number we put in as far the order stays the same (and yes, they perform poorly all the times but, hey, consistency is a virtue). ","08249222":"We see that the value `Po` is missing in the training set (`Ex` has been dropped in both sets by get_dummies). If we try to run a model now, we will get an error because the columns are different. \n\nThe dirty fix I adopted before is to simply **recode `Po` to `Fa`** before creating the dummies so that the mismatch is not there. This can be justifiable if we look at the counts of each category.","7b02e273":"But we can decide, for example, to half the number of bins to map our feature to, obtaining","7ff086bf":"Which is also a way of encoding Neighborhood to a numerical value (and this is why we used the same technique as in the previous section). Or you can use counts, simple multiplications, anything that your creativity and your understanding of the problem will suggest you.\n\nA word of caution about using several observations to create a feature like in the previous case that we use all the observations from a neighborhood at the same time. If your validation strategy is not solid, this can and will lead to some information leak in your model, meaning that your training data have somehow already seen the test data. This can lead to inflated cross-validation scores and poorer generalization power for your model. \n\nThe last point is especially dangerous if you start using the target variable in your feature engineering (sometimes called target encoding). For example, you can use the mean price of the house in a neighborhood as a feature. Such a feature makes a lot of sense because the average price of a house in an area can be well known a priori, but expose you to the situation where the model *sees* the target more than once. One way is to properly separate training, validation, and test set (as we did here) but it turns out that using a statistics that does not change its distribution with or without any data point can be considered approximatively leakage-proof. This can be achieved, for example, by adding some random noise.","e96a5d94":"And we finally have all models learning the same relation and producing the same poor prediction. From the OLS experiment we see also that, even though we removed the ordering between the various values, the model still thinks that with a bigger garage the house costs more.\n\n# Features with a large number of categories\n\nSometimes it can happen that a categorical feature presents way too many individual values to be made a one-hot-encoded (no matter the technique). For example, let's have a look at the feature `Neighborhood`.","50da40e3":"Here we display only the first 10 lines but it is not hard to see what this dataframe contains","359cdb04":"As we see, the tree does a first split on `MasVnrType_None`, then on `MasVnrType_Stone`, and finally on `MasVnrType_BrkFace`.\n\nNow, if we use the label encoder instead, we get","90042339":"We see that the automatic encoding makes much less sense (the order would not be a problem, of course). All that being said, the weird encoding is only for the `FA` category, which is present only 14 times.\n\nAs a further example, let's take ","81b8d0e6":"For example, thisi is how `Foundation` looks like","6ab2f811":"## Lasso experiment, regularization\n\nLasso is a method that uses variable selection and regularization. This makes the previous issue with multicollinearity more under control as we can see from the next 2 experiments.","3fbd8155":"The error here is that our encoding **forced an order among the categories**. It is saying to our models that `BrkFace < None < Stone` and this can be very harmful to both the performance and the explainability of the model because that ordering does not make any sense. ","4d812d5c":"We see that dropping one dummy changes the coefficients and, marginally, the performance, but the effect is not as drastic as before. The feature selection and the regularization were already taking care of part of the problem (notice how `LotShape_IR1` had already a very small coefficient).\n\n## Tree experiment\n\nAboud DecisionTrees and more complicated models (RandomForest, XGBoost) I wrote more extensively in this other kernel: [Fantastic Trees and How to tune them](https:\/\/www.kaggle.com\/lucabasa\/fantastic-trees-and-how-to-tune-them). In this kernel, we are definitely not going for performance and, as you can see from the functions above, we don't try too hard to make our tree perform well.","de2e94c6":"# From continuous to categorical\n\nThere are situations where it is tempting to take a continuous variable and make bins out it (thus making it a categorical one). While in general this can lead to a model that fits the data less than before (due to the fact that you are being somewhat less accurate with your predictors), there are situations where you can have some success with it. A non-comprehensive list of these situations is\n\n* you don't trust entirely the accuracy of the measurements that led to those data. For example, you have a column containing many distances from a reference point and you are not sure if those distances were measured accurately, you might just group all the distances below 1 Km to a category, then another category with 1-2 Km, etc. In this way, **you are assuming there is no difference inside of the same bin** and, if the measure is really inaccurate as you think, you are removing some noise to make better predictions.\n* you don't think that a variable is influencing in a continuous way your response, then you can force your model to see the data in *steps* \n* A variable is continuous but it takes almost exclusively one specific value. The classic example is a feature that is 0 almost always and then it takes very rare positive values (even really high one). In this case, you can get a clearer signal by simply binarizing this variable (thus transforming every positive value into a 1).\n\nAs before, only knowledge, context, and performance will tell you what is a good idea and what isn't. Let's make some experiment. \n\nA good example is provided by the features `GarageArea` and `GarageCars`. If we plot them both against our target, we see how `GarageCars` could be interpreted as the categorical version of `GarageArea` (which makes a lot of sense, since bigger garages can contain more cars).","f308f0a6":"While, by using the categorical (orginal) variable `GarageCars`","d29e3291":"This kernel is not going to be a high scoring one but, hopefully, will clarify some aspects of categorical variables that can be confusing when approached for the first time.\n\nWe will make experiments together and observe the results. We are going to use only a few categorical features to keep it simple, thus compromising the score since we are not going to use the most relevant features. \n\nTo do so, we are going to use various approaches and see how 3 different models (ordinary least squares, lasso regression, and decision tree) behave.\n\nThe main topics we are going to explore are:\n\n* Categorical vs ordinal features\n* Dummies and Dummy mismatch\n* Multicollinearity\n* Creating categories out of continuous variables\n* Dealing with numerous categories and frequency encoders\n\n***Note***: As everything on the internet, you should not believe to everything you read but, in the spirit of this notebook, it is an excellent idea to run more experiments to prove me wrong. (And please let the feedback coming)\n\n# Data preparation\n\nFollowing [this other kernel of mine](https:\/\/www.kaggle.com\/lucabasa\/an-agile-approach-get-incrementally-better), we can quickly prepare the data by handling missing values and selecting the features we want to focus on. As the linked kernel shows, this is the step that gives the biggest improvement in score (both in cross-validation and on the public LB). However, we won't focus on this step too much since it is not the topic of this kernel.","3f4ca658":"Another approach to obtain a similar result is to use `rankdata` from the library `scipy.stats`, necessary in case of ties. [Here a link to the documentation](https:\/\/docs.scipy.org\/doc\/scipy-0.16.0\/reference\/generated\/scipy.stats.rankdata.html).\n\nAt last, one could try the **hashing trick**.\n\nA hash function maps an integer to a finite integer range \\[1,m\\]. The input can take values larger than *m*, thus allowing us to reduce the number of categories. This also means that multiple numbers may get mapped to the same output (something that is called *collision*). Another advantage is that feature hashing compresses the original feature into a vector of dimension m and, since it can be applied even to strings, this lead to a significant saving on the memory side. \n\nA simple implementation to get a taste of how it works is the following.","fc4db20b":"Since we train on fewer features, we observe a better fit (only for the tree) and a lower score on the validation set and one may argue that this experiment didn't go so well. Again, this gives us the opportunity to think about how the tree algorithm is acting. Having a smaller set of features to choose from, it can finish faster and learn the data better. As an exercise, one could try a different kind of grouping of the above features to see how this changes the result.\n\n## Let a model help you\n\nLooking at the first experiment of this section, we notice that, for example, `MSZoning_FV` and `MSZoning_RL` are getting similar coefficients. Since they also represent similar categories, we can use this information and group them up to reduce the sparsity of our categories. The other values do not look playing a similar role, so we let them separated. We expect to see the Lasso experiment producing slightly better results. \n\nI would not get too greedy with this strategy because it is important to keep in mind the meaning of each feature (thus do I would not group categories only because they have a similar coefficient). To test why it can get too greedy, try to uncomment the lines in the following code and see how the result is changing","7a8e2ec9":"We can use a pandas function called `get_dummies()` to, as the function says, get our dummies","0ee41c51":"It is indeed an annoying little observation and changing it should not compromise our model (to be fair, we should ask ourselves serious questions about the model if it does). \n\nAnother approach can be to **first create the dummies and then split into training and validation set**. In this case, we get","be776c47":"# Not all the dummies show up every time\n\nAs the most curious of you noticed from my hidden code, I made a small hack in the previous cells when I made dummies out of my variable. Indeed, we can see that there is a **mismatch between training and validation set**.","b752a265":"Again, not quite what we want. There is an order, but not a reasonable one. The encoder is assigning an alphabetical order. \n\nLet's see a couple more approaches to get what we want. First, a quick summary of what are we dealing with.","cd7a4b99":"The result is simply an extra column of 0's into the training set.\n\nAnother option would be to only keep the common columns and train with them. This can be annoying if the number of mismatched dummies grows, but we can write a couple of lines of code for that","dc60b73f":"## ***Please comment if something is not clear or completely wrong. Or upvote if you found this kernel useful. Or both. Or neither, really, it is great that you read this far already.***","a03608df":"Now, which one is better? \n\nIn principle, both and neither. Since there is no real rule, we are allowed to make assumptions and go along with them. Indeed, one may even argue that, since the ordering is clear but the magnitude is not, we can again use dummies and let the model decide what is the relation with the target.\n\nThis paves the way to the next set of experiments. This time we will use only a few ordinal variables and see if the models *learn* differently if we use a different encoding.","9acc9c34":"If we use `GarageArea` (thus a continuous variable), we get","641e436a":"Which is significantly worse for OLS (and Lasso, not displayed) and puts us in trouble if we have to explain the model to someone else. \n\nThe result for the DecisionTree is not worse. To understand why, let's visualize the decisions of our tree if only had one variable, like the following","0d650cf4":"We can see that the validation result is not that bad but the model is clearly doing something weird: all the dummies are getting the same coefficient. Moreover, their standard deviation is way too high to trust that coefficient. This means that **a small change in the data could lead to a big change of the coefficients**.\n\nHow can we interpret that?\n\nThe model is not able to distinguish the effect of the individual dummies, an effect of what is called [**multicollinearity**](https:\/\/en.wikipedia.org\/wiki\/Multicollinearity). This happens when two or more variables are linearly related and, in this case, it is happening among every group of dummies.\n\n### Avoiding multicollinearity\n\nTo avoid that, we can simply drop one of the dummies. The same effect can be obtained by not fitting the intercept as well. However, this would mean changing the function for the experiment (and we have no time for that) and also not seeing that pandas provide a very easy way to drop one dummy.","bce99573":"# Introducing the models and making them work\n\nWe are going to use 3 approaches to fit the data and get a prediction.\n\n* Ordinary least squared regression, very simple linear model, very interpretable.\n* Lasso regression, another linear model but with regularization\n* A decision tree, the simplest tree-based model, easy to explain\n\nNone of them can work with entries like `RL` or `NoAlley` and we thus need to do some processing to help them. \n\nLet's first set up the experiment by creating train and validation sets. Moreover, I'd like to have some function to run the experiments quickly without repeating the same code over and over.","04093436":"## Rare ordinal features\n\nThis is way much less of an issue if you have already converted it to numeric values (with any strategy) because this will not throw you an error. For example, `GarageQual` has very rarely the value `Ex` or `Po` but, as we see in the next two cells, correcting for this sparsity has little to no effect.","143c42f4":"We now have a sparse matrix of the dimensions of number of rows times the number of unique Neighboorhoods, which is very close to what we obtain by using `get_dummies` and we have a loss in interpretability, given the fact that the matrix looks like this","fd41f0b4":"## Put the rare categories together by using the documentation\n\nThis approach aims to create less unfrequent categories by putting together 2 or more categories with the suggestion of the documentation. For example, in `LotShape` we could group all the `IR#` categories into a generic `irregular`one.","773954fc":"And we thus are ready to train and validate our model. \n\nNaturally, there is always the *butchery* approach which is **ignore the observations with specific values** (can be tricky with many features to dummify) or **do not train the model with the features that give you this problem** (which would reduce the complexity of the model, not necessarily a bad thing).\n\nAs usual, understanding why the mismatch is happening is crucial to the decision to take about it. My default approach is to not use features that I don't understand but this can sometimes mean accept a drop in accuracy of the model at the advantage of its explainability.\n\nIn the previous examples, the reason for the mismatch was very clear and helps us introduce the next topic\n\n## Features with very rare categories\n\nIn this section, we will focus on those features that have very rare categories and test how our models struggle if we ask them to learn on those categories. Furthermore, we will see if the same behavior can be observed for both categorical and ordinal features.\n\nTo do so, we will focus on the following features","1c21d991":"In this case, we see that the simple models are learning the signal a bit better when we use `GarageCars`. One could argue that, despite the better performance according to our metric, a model that predicts only 4 values is better than the previous one but we are not here to win this competition. This would spark a conversation about evaluating your model with an appropriate metric (not necessarily the one Kaggle suggests), but this is not a kernel for high scoring models.\n\nThere is some difference in the predictions and this is most likely due to some non-linear effect that is difficult for the OLS and Lasso regressors. \n\nJust out of curiosity this is what happens if we make dummies out of `GarageCars`. This means removing the ordering between the values but helping the models to learn potentially non-linear relationships.","f9f044cc":"With 2 more lines of code (we have to fit the encoder, use it transform the data, convert the sparse matrix it returns into a matrix, making a data frame out of it) we get to the same result. I personally prefer the first approach, but OneHotEncoder can be used inside a Pipeline very easily and it can be very handy in some situations. \n\nFor example, your model has to first impute the missing values, then create the dummies, then fit and predict. You are not even sure what kind of dummies are going to be there before the imputation. OneHotEncoder solves the problem and saves you a headache.\n\n## OLS experiment, multicollinearity\n\nLet's assume we want to predict the Sale Price only with from `MasVnrType`, `Alley`, and `LotShape`. Then we have to prepare the data as","ded27b40":"As we see, the 3 models are very much in agreement on getting the predictions wrong and, since we are using only discrete values while before there were continuous features, the predictions tend to be on more definite *levels*.\n\n## The wrong way of handling dummies\n\nSometimes it is tempting to simply encode the unique values into numerical one. One way to do so is to use sklearn's method `LabelEncoder` and we see how it works in the following cell (I keep the original column for clarity)","84414b72":"As we see, `Slab`, `Stone`, and `Wood` are very unfrequent. Let's see if we spot a difference in performance or not. We already have a problem because `Wood` appears only in the train set, but we just drop the column for now."}}